{"hands_on_practices": [{"introduction": "在现代多核处理器中，当一个核心的缓存未命中时，所需数据并非总是必须从缓慢的主内存中获取。通过缓存一致性协议，数据可以直接从另一个核心的缓存中以更快的速度传输。这个练习 [@problem_id:3675527] 引导我们使用一个基于概率的平均访存时间模型，来精确量化这种“缓存到缓存”传输机制所带来的性能增益，从而让你更深刻地理解复杂硬件设计背后的性能考量。", "problem": "一个对称共享内存多处理器实现了修改、独占、共享、无效（MESI）缓存一致性协议，该处理器配备了私有的一级（L1）写回式缓存和一个包容性共享末级缓存（LLC）。考虑一个稳态工作负载，其中每次内存访问都针对单个缓存行，并且根据测量和微架构特性分析，已知以下信息：\n\n- L1 命中延迟为 $t_{L1} = 4$ 个周期，并且在下面考虑的两种设计中，所有核心的该延迟都相同。\n- L1 未命中率为每次访问 $m_1 = 0.08$。\n- 在 L1 未命中的条件下，请求的缓存行当前由另一个核心的私有缓存持有，且其状态允许直接转发的概率为 $p_{\\text{owner}} = 0.35$。\n- 如果一个缓存行通过缓存到缓存传输直接转发，端到端延迟（包括目录查找、一致性消息和数据传输）为 $t_{\\text{c2c}} = 80$ 个周期。\n- 如果一个缓存行不是从另一个核心转发的，则该请求由 LLC 或主内存服务，其有效平均延迟为 $t_{\\text{LLC}} = 140$ 个周期。\n\n假设没有排队、竞争或重叠效应，并且一致性状态分布是稳态的，并且除了上述描述之外，每次访问之间是独立的。考虑两种设计：\n\n- 设计 A 在可能的情况下支持缓存到缓存的转发。\n- 设计 B 不支持缓存到缓存的转发；在 B 中，每次 L1 未命中都由 LLC 或主内存服务。\n\n仅使用未命中率作为概率和预期延迟作为互斥结果的概率加权平均值的基本定义，从基本原理推导设计 A 相对于设计 B 的预期每次访问延迟减少量（以周期为单位）。以周期为单位表示您的最终答案，并四舍五入到 $4$ 位有效数字。", "solution": "问题要求计算支持缓存到缓存转发的多处理器设计（设计 A）相对于不支持该功能的设计（设计 B）的预期每次访问延迟减少量。推导必须从基本原理出发，使用预期延迟作为互斥结果的概率加权平均值的定义。\n\n设 $E[T]$ 表示一次内存访问的预期延迟。一次内存访问可能导致两个主要的互斥结果之一：在私有 L1 缓存中命中或在 L1 缓存中未命中。根据全期望定律，我们可以将预期延迟写为：\n$$\nE[T] = P(\\text{L1 hit}) \\times L_{\\text{hit}} + P(\\text{L1 miss}) \\times L_{\\text{miss}}\n$$\n其中 $P(\\text{L1 hit})$ 和 $P(\\text{L1 miss})$ 分别是 L1 命中和未命中的概率，而 $L_{\\text{hit}}$ 和 $L_{\\text{miss}}$ 是每种结果对应的总延迟。\n\n根据问题陈述，我们已知：\n- L1 未命中率 $m_1 = 0.08$。这是 L1 未命中的概率，因此 $P(\\text{L1 miss}) = m_1$。\n- 因此，L1 命中的概率是 $P(\\text{L1 hit}) = 1 - m_1$。\n- L1 命中延迟为 $t_{L1} = 4$ 个周期。这是命中的总延迟，因此 $L_{\\text{hit}} = t_{L1}$。\n\nL1 未命中时的预期延迟，记为 $E[L_{\\text{miss}}]$，取决于系统设计。将已知值代入通用公式，得到：\n$$\nE[T] = (1 - m_1) t_{L1} + m_1 E[L_{\\text{miss}}]\n$$\n\n我们现在将分别分析这两种设计。\n\n对于不支持缓存到缓存转发的设计 B，任何 L1 未命中都必须由 LLC 或主内存服务。问题陈述指出，这个有效平均延迟为 $t_{\\text{LLC}} = 140$ 个周期。因此，对于设计 B，任何 L1 未命中的延迟始终是 $t_{\\text{LLC}}$。未命中时的预期延迟就是：\n$$\nE[L_{\\text{miss, B}}] = t_{\\text{LLC}}\n$$\n设计 B 的总预期每次访问延迟 $E[T_B]$ 为：\n$$\nE[T_B] = (1 - m_1) t_{L1} + m_1 t_{\\text{LLC}}\n$$\n\n对于支持缓存到缓存转发的设计 A，一次 L1 未命中后续有两种可能的结果：\n1. 请求的缓存行从另一个核心的私有缓存转发。这种情况发生的条件概率为 $p_{\\text{owner}} = 0.35$，此传输的端到端延迟为 $t_{\\text{c2c}} = 80$ 个周期。\n2. 缓存行未被转发，必须从 LLC 或主内存获取。这种情况发生的互补条件概率为 $1 - p_{\\text{owner}}$，延迟为 $t_{\\text{LLC}} = 140$ 个周期。\n\n设计 A 在 L1 未命中时的预期延迟 $E[L_{\\text{miss, A}}]$ 是这两种结果的加权平均值：\n$$\nE[L_{\\text{miss, A}}] = p_{\\text{owner}} \\times t_{\\text{c2c}} + (1 - p_{\\text{owner}}) \\times t_{\\text{LLC}}\n$$\n设计 A 的总预期每次访问延迟 $E[T_A]$ 为：\n$$\nE[T_A] = (1 - m_1) t_{L1} + m_1 E[L_{\\text{miss, A}}] = (1 - m_1) t_{L1} + m_1 (p_{\\text{owner}} t_{\\text{c2c}} + (1 - p_{\\text{owner}}) t_{\\text{LLC}})\n$$\n\n问题要求计算设计 A 相对于设计 B 的预期每次访问延迟减少量，即差值 $\\Delta T = E[T_B] - E[T_A]$。\n$$\n\\Delta T = \\left[ (1 - m_1) t_{L1} + m_1 t_{\\text{LLC}} \\right] - \\left[ (1 - m_1) t_{L1} + m_1 (p_{\\text{owner}} t_{\\text{c2c}} + (1 - p_{\\text{owner}}) t_{\\text{LLC}}) \\right]\n$$\n项 $(1 - m_1) t_{L1}$ 代表 L1 命中带来的延迟贡献，在两个表达式中是相同的，因此可以消去。减少量完全是由于对 L1 未命中的不同处理方式造成的。\n$$\n\\Delta T = m_1 t_{\\text{LLC}} - m_1 (p_{\\text{owner}} t_{\\text{c2c}} + (1 - p_{\\text{owner}}) t_{\\text{LLC}})\n$$\n将右侧的项 $-m_1$ 展开：\n$$\n\\Delta T = m_1 t_{\\text{LLC}} - m_1 p_{\\text{owner}} t_{\\text{c2c}} - m_1(1 - p_{\\text{owner}}) t_{\\text{LLC}}\n$$\n$$\n\\Delta T = m_1 t_{\\text{LLC}} - m_1 p_{\\text{owner}} t_{\\text{c2c}} - m_1 t_{\\text{LLC}} + m_1 p_{\\text{owner}} t_{\\text{LLC}}\n$$\n项 $m_1 t_{\\text{LLC}}$ 和 $-m_1 t_{\\text{LLC}}$相互抵消，得到：\n$$\n\\Delta T = m_1 p_{\\text{owner}} t_{\\text{LLC}} - m_1 p_{\\text{owner}} t_{\\text{c2c}}\n$$\n提取公因式 $m_1 p_{\\text{owner}}$ 得到延迟减少量的最终符号表达式：\n$$\n\\Delta T = m_1 p_{\\text{owner}} (t_{\\text{LLC}} - t_{\\text{c2c}})\n$$\n这个结果是直观正确的：总延迟减少量是因快速的缓存到缓存传输而得到满足的未命中概率（$m_1 \\times p_{\\text{owner}}$）乘以每次此类传输节省的时间（$t_{\\text{LLC}} - t_{\\text{c2c}}$）。\n\n现在，我们代入给定的数值：\n$m_1 = 0.08$\n$p_{\\text{owner}} = 0.35$\n$t_{\\text{LLC}} = 140$ 个周期\n$t_{\\text{c2c}} = 80$ 个周期\n\n$$\n\\Delta T = 0.08 \\times 0.35 \\times (140 - 80)\n$$\n$$\n\\Delta T = 0.08 \\times 0.35 \\times 60\n$$\n$$\n\\Delta T = 0.028 \\times 60\n$$\n$$\n\\Delta T = 1.68\n$$\n延迟减少量为每次访问 $1.68$ 个周期。问题要求答案四舍五入到 $4$ 位有效数字。要将 $1.68$ 表示为四位有效数字，我们写成 $1.680$。", "answer": "$$\\boxed{1.680}$$", "id": "3675527"}, {"introduction": "见识了性能优化的有效性后，我们来探讨一个截然相反的情形：性能瓶颈。当所有处理器核心都试图同时访问和修改同一个共享数据时，就会产生所谓的“热点”争用。这个练习 [@problem_id:3675634] 建立了一个简洁而深刻的模型来分析这种串行化瓶颈，通过推导系统的极限吞吐量，你会发现一个关于可扩展性的关键教训：如果所有核心都在为同一个资源排队等待，那么简单地增加核心数量并不能提升系统总性能。", "problem": "考虑一个共享内存多处理器，它拥有 $N$ 个相同的核心、一个存储在单个缓存行中的共享计数器变量，以及一个基于失效的缓存一致性协议，该协议具有修改（Modified）、独占（Exclusive）、共享（Shared）、无效（Invalid）（简称 MESI）四种状态。系统强制执行顺序一致性，这意味着所有内存操作都以一个与程序顺序一致的单一全局顺序出现。共享计数器的增量操作通过一个原子性的读-修改-写操作来执行，这要求核心在写入之前必须将缓存行保持在修改（Modified）状态。\n\n定义缓存行交接延迟 $t_h$ 为缓存行的独占所有权从当前所有者转移到请求核心所需的端到端时间，包括一致性消息、失效、数据移动以及任何仲裁延迟，但不包括一旦在修改（Modified）状态下持有缓存行后，增量操作本身的本地执行时间。假设系统处于以下压力测试配置：\n- 每个核心重复执行一次对共享计数器的原子性增量操作，然后仅在其他某个核心完成增量后才立即再次请求该缓存行，从而在 $N$ 个核心之间强制执行严格的轮询所有权模式。\n- 当一次交接完成时，总有至少一个核心在请求缓存行，因此该缓存行处于持续竞争状态。\n- 一旦在修改（Modified）状态下获取了缓存行，增量操作的本地执行时间与 $t_h$ 相比可以忽略不计，为了进行吞吐量分析，可将其视为零。\n- 没有其他内存流量干扰，并且除了 $t_h$ 中已包含的排队外，互连不会引入额外的排队。\n\n在这些假设下，以闭合形式推导稳态系统吞吐量 $X(N, t_h)$（单位为每秒完成的增量次数）。你的最终答案必须是仅包含 $N$ 和 $t_h$ 的单一解析表达式。不要提供不等式或待解方程；请提供最终表达式。你无需对结果进行四舍五入。请将吞吐量表示为每秒增量次数。", "solution": "用户要求我推导一个共享内存多处理器系统的稳态系统吞吐量，单位为每秒完成的增量次数。\n\n### 问题验证\n\n首先，我必须验证问题陈述。\n\n#### 步骤1：提取已知条件\n- 系统：具有 $N$ 个相同核心的共享内存多处理器。\n- 共享资源：一个存储在单个缓存行中的共享计数器变量。\n- 一致性协议：基于失效的，具有修改、独占、共享、无效 (MESI) 状态。\n- 一致性模型：顺序一致性。\n- 操作：对计数器进行原子性的读-修改-写增量。这要求执行核心将缓存行保持在修改（M）状态。\n- 延迟定义：$t_h$ 是缓存行交接延迟，定义为独占所有权（修改状态）从当前所有者转移到请求核心的端到端时间。它包括所有通信和仲裁延迟。\n- 假设：\n    1.  在 $N$ 个核心之间强制执行严格的轮询所有权模式。\n    2.  系统处于持续竞争状态；总有一个核心在请求缓存行。\n    3.  一旦在修改状态下获取了缓存行，增量操作本身的本地执行时间可以忽略不计（为零）。\n    4.  没有其他干扰性的内存流量。\n\n#### 步骤2：使用提取的已知条件进行验证\n该问题具有科学依据。它描述了一个经典场景，用于分析多处理器系统中因“热点”（一个高度竞争的共享变量）上的串行化而导致的性能限制。所使用的概念——共享内存、MESI协议、顺序一致性、原子操作和吞吐量——都是计算机体系结构中的标准概念。\n\n该问题提法恰当。其假设清晰、明确且充分，足以构建一个系统行为的确定性模型。$t_h$ 的定义精确地分离出我们关心的延迟，而推导系统吞吐量 $X(N, t_h)$ 的目标也明确无歧义。\n\n该问题是客观且可形式化的。其语言精确且技术性强，没有主观因素。整个设置可以被建模为一系列离散事件。\n\n未发现任何缺陷。该问题是性能建模中一个有效的理论练习。\n\n#### 步骤3：结论与行动\n问题有效。我将继续进行解答。\n\n### 系统吞吐量推导\n\n系统吞吐量 $X$ 定义为单位时间内完成的增量总数。它可以计算为系统中两个连续完成的增量之间所用平均时间的倒数。\n\n问题指出，增量操作是一个原子性的读-修改-写操作，要求核心将缓存行保持在修改（M）状态。因为在任何给定时间只有一个核心能将缓存行保持在 M 状态，所以增量操作在整个系统中被串行化。这意味着在任何时间点，只有一个增量操作能在进行中。\n\n让我们分析系统完成一次增量操作的事件序列。\n假设在时间 $T_0$，核心 $C_i$ 刚刚完成一次增量。它当前将缓存行保持在 M 状态。\n\n1.  根据“持续竞争”和“严格轮询”的假设，序列中的下一个核心 $C_{i+1}$（索引以 $N$ 为模）已经发出了对该缓存行的请求。\n2.  将缓存行的独占所有权从核心 $C_i$ 转移到核心 $C_{i+1}$ 的过程开始。这包括核心 $C_i$ 响应请求，使其副本失效（尽管它从 M 状态转换，但在特定协议实现下可能是必要的步骤），并将数据发送给核心 $C_{i+1}$。然后，核心 $C_{i+1}$ 接收数据并在 M 状态下获得所有权。\n3.  问题将这整个转移过程的总时间定义为缓存行交接延迟 $t_h$。\n4.  因此，核心 $C_{i+1}$ 在时间 $T_0 + t_h$ 时，在 M 状态下获取了该缓存行。\n5.  问题指明，一旦获取了缓存行，增量的本地执行时间可以忽略不计，可视为零。因此，核心 $C_{i+1}$ 实际上在获取缓存行的同一时刻完成其增量操作，即在时间 $T_1 = T_0 + t_h$。\n\n此分析表明，一次增量（由核心 $C_i$ 完成）的完成与系统中紧接着的下一次增量（由核心 $C_{i+1}$ 完成）的完成之间所经过的时间恰好是 $t_h$。\n\n系统每 $t_h$ 秒完成一次增量。完成速率即为系统吞吐量 $X$，是每次增量所需时间的倒数。\n$$\nX = \\frac{1 \\text{ 次增量}}{t_h \\text{ 秒}}\n$$\n因此，吞吐量为：\n$$\nX(N, t_h) = \\frac{1}{t_h}\n$$\n\n核心数量 $N$ 是一个系统参数，它建立了轮询模式并确保了竞争。然而，在这个完全串行化的模型中，瓶颈是单一资源的交接，因此只要 $N > 1$（以发生交接），系统的总吞吐量就与竞争者数量 $N$ 无关。如果我们分析单个核心的吞吐量，它将是 $\\frac{1}{N \\cdot t_h}$，因为一个核心在再次执行增量操作前必须等待其他 $N-1$ 个核心轮流操作，这个周期需要 $N \\cdot t_h$ 的时间。那么，总的系统吞吐量将是 $N$ 个核心吞吐量的总和，即 $N \\times \\frac{1}{N \\cdot t_h} = \\frac{1}{t_h}$，这证实了我们的结果。因此，函数 $X(N, t_h)$ 相对于 $N$ 是一个常数。", "answer": "$$\\boxed{\\frac{1}{t_h}}$$", "id": "3675634"}, {"introduction": "并非所有的性能问题都像热点争用那样显而易见，有时它们以更隐蔽的方式出现，例如“伪共享”（false sharing）。即使不同的线程访问的是完全独立的变量，但如果这些变量恰好位于同一缓存行上，一致性协议仍会视其为冲突，导致不必要的缓存行失效和数据传输开销。这个动手编程练习 [@problem_id:3675600] 让你通过实现一个量化模型，探索缓存行大小对伪共享成本的影响，并找出最优配置。你将从中获得关于数据布局和内存访问模式如何影响硬件性能的宝贵实践经验。", "problem": "考虑一个拥有私有缓存和写-失效缓存一致性协议的共享内存多处理器。一个稀疏矩阵乘法的稠密结果矩阵 $C$ 以行主序存储。设 $C$ 有 $M$ 行和 $N$ 列，每个元素占用 $s$ 字节。为简单起见， $C$ 的基地址设为 $\\text{base} = 0$。元素 $(i,j)$ 的地址定义为 $\\mathrm{addr}(i,j) = s \\cdot (iN + j)$，一个元素映射到的缓存行索引为 $$\\ell(i,j; L_c) = \\left\\lfloor \\frac{s \\cdot (iN + j)}{L_c} \\right\\rfloor,$$ 其中 $L_c$ 是以字节为单位的缓存行大小。假设多个线程并发地写入 $C$ 的不同元素，这是由稀疏乘法中的非零元素分布引起的。尽管线程写入不同的字，但当它们的字位于同一缓存行时，就会发生伪共享，从而引发一致性失效。\n\n我们为给定的缓存行大小 $L_c$ 定义伪共享成本如下。对于每个缓存行索引 $\\ell$，令 $k_{\\ell}$ 为写入至少一个映射到 $\\ell$ 的元素的不同线程的数量。每个缓存行的伪共享事件计数为 $\\max(0, k_{\\ell} - 1)$，因为在写-失效协议下，写入者为了获得独占访问权限，至少需要 $k_{\\ell} - 1$ 次线程间所有权转移。总的伪共享成本为 $$F(L_c) = \\sum_{\\ell} \\max(0, k_{\\ell} - 1).$$ 您的程序必须为每个测试用例，计算每个候选 $L_c$ 的 $F(L_c)$，选择使 $F(L_c)$ 最小化的 $L_c$，并返回所选的 $L_c$ 和最小成本。如果出现平局，选择具有最小 $F(L_c)$ 的那些 $L_c$ 中最小的一个。\n\n$L_c$ 和 $s$ 的所有单位必须是字节。本问题不涉及角度。本问题中没有百分比。\n\n使用以下测试套件。在所有情况下，线程都写入不同的元素（没有真共享）。写入由整数对 $(i,j)$（行索引和列索引）指定，并且对于每个测试用例，候选的缓存行大小以字节为单位的集合形式给出。\n\n- 测试用例 1：\n  - $M = 4$, $N = 16$, $s = 8$, $T = 3$，候选集 $\\{32, 64, 128\\}$。\n  - 线程 $0$ 写入 $\\{(0,0),(0,1),(0,2),(0,3),(1,8),(1,9),(1,10),(1,11)\\}$。\n  - 线程 $1$ 写入 $\\{(0,4),(0,5),(0,6),(0,7),(2,0),(2,1)\\}$。\n  - 线程 $2$ 写入 $\\{(1,0),(1,1),(1,2),(1,3),(2,8),(2,9)\\}$。\n- 测试用例 2：\n  - $M = 3$, $N = 2$, $s = 8$, $T = 3$，候选集 $\\{16, 32, 64\\}$。\n  - 线程 $0$ 写入 $\\{(0,0),(0,1)\\}$。\n  - 线程 $1$ 写入 $\\{(1,0),(1,1)\\}$。\n  - 线程 $2$ 写入 $\\{(2,0),(2,1)\\}$。\n- 测试用例 3：\n  - $M = 1$, $N = 16$, $s = 8$, $T = 4$，候选集 $\\{64, 128\\}$。\n  - 线程 $0$ 写入 $\\{(0,0),(0,1),(0,2),(0,3)\\}$。\n  - 线程 $1$ 写入 $\\{(0,4),(0,5),(0,6),(0,7)\\}$。\n  - 线程 $2$ 写入 $\\{(0,8),(0,9),(0,10),(0,11)\\}$。\n  - 线程 $3$ 写入 $\\{(0,12),(0,13),(0,14),(0,15)\\}$。\n- 测试用例 4：\n  - $M = 4$, $N = 16$, $s = 8$, $T = 3$，候选集 $\\{32, 64, 128\\}$。\n  - 线程 $0$ 写入 $\\{(0,0),(0,8)\\}$。\n  - 线程 $1$ 写入 $\\{(1,0)\\}$。\n  - 线程 $2$ 写入 $\\{(2,0)\\}$。\n\n您的任务是实现一个程序，对于每个测试用例，计算出能够最小化总伪共享成本 $F(L_c)$ 的最优缓存行大小 $L_c$（以字节为单位），以及该最小成本。最终输出格式必须将所有提供的测试用例的结果聚合到单行中，包含一个用方括号括起来的逗号分隔列表，其中对于每个测试用例，您需要输出所选的 $L_c$ 和对应的最小 $F(L_c)$ 作为整数。例如，格式为 $[L_{c,1},F(L_{c,1}),L_{c,2},F(L_{c,2}),\\dots]$，无空格。", "solution": "这个问题是有效的，因为它在科学上基于计算机体系结构的原理，特别是共享内存多处理器中的缓存一致性。问题陈述清晰，提供了所有必要的数据和定义来计算一个唯一的、可验证的解决方案。伪共享的模型虽然是一种简化，却是量化此性能问题的标准且逻辑的方法。\n\n目标是为每个测试用例，从一组给定的候选大小中确定最优的缓存行大小 $L_c$，以最小化总伪共享成本 $F(L_c)$。成本函数定义为\n$$F(L_c) = \\sum_{\\ell} \\max(0, k_{\\ell} - 1),$$\n其中，总和是对所有缓存行索引 $\\ell$ 进行的，而 $k_{\\ell}$ 是写入缓存行 $\\ell$ 的不同线程的数量。\n\n解决方法涉及对每个候选 $L_c$ 直接实现和评估此成本函数。每个测试用例的步骤如下：\n\n1.  将最小成本 $F_{min}$ 初始化为一个大于任何可能结果的值，并将最优缓存行大小 $L_{c,opt}$ 初始化为一个哨兵值。\n\n2.  对于测试用例中提供的每个候选缓存行大小 $L_c$：\n    a.  计算总伪共享成本 $F(L_c)$。此子任务通过首先确定写入每个缓存行的线程集合来执行。\n    b.  $M \\times N$ 矩阵 $C$ 中位于第 $i$ 行和第 $j$ 列的元素的地址由 $\\mathrm{addr}(i,j) = s \\cdot (iN + j)$ 给出，其中 $s$ 是元素大小（以字节为单位）。\n    c.  对应的缓存行索引是 $\\ell(i,j; L_c) = \\left\\lfloor \\frac{\\mathrm{addr}(i,j)}{L_c} \\right\\rfloor = \\left\\lfloor \\frac{s \\cdot (iN + j)}{L_c} \\right\\rfloor$。\n    d.  为了跟踪哪些线程写入了哪个缓存行，我们可以使用一个辅助数据结构。一个由缓存行索引 $\\ell$ 索引的数组（我们称之为 `line_writers`）是合适的。可能的最大缓存行索引由矩阵中的最大地址（即元素 $(M-1, N-1)$ 的地址）和当前的 $L_c$ 决定。\n    e.  对于每个缓存行索引 $\\ell$，我们需要存储写入它的唯一线程的集合。由于线程数 $T$ 很小，一个 $T$ 位的位掩码是一种高效的表示方式。如果线程 $t$ 写入一个映射到缓存行 $\\ell$ 的元素，则该行掩码的第 $t$ 位置为1。我们将这个掩码数组称为 `line_thread_masks`。\n    f.  我们遍历所有线程 $t \\in \\{0, 1, \\dots, T-1\\}$，对于线程 $t$ 执行的每次对元素 $(i,j)$ 的写入，我们计算行索引 $\\ell = \\ell(i,j; L_c)$ 并更新该行的掩码：`line_thread_masks[$\\ell$]` |= ($1 \\ll t$)。\n    g.  在为所有写入填充掩码后，我们计算总成本 $F(L_c)$。我们遍历 `line_thread_masks` 中的每个条目。对于每个行索引 $\\ell$，我们计算其掩码中置位（为1）的位数，从而得到 $k_{\\ell}$。此行的成本是 $\\max(0, k_{\\ell} - 1)$，我们将所有 $\\ell$ 的这些成本相加得到 $F(L_c)$。\n    h.  掩码中置位的位数（population count）可以被高效地计算。\n\n3.  在为当前候选计算出 $F(L_c)$ 后，我们将其与 $F_{min}$进行比较。\n    a.  如果 $F(L_c)  F_{min}$，则找到了一个新的最小值。我们更新 $F_{min} = F(L_c)$ 和 $L_{c,opt} = L_c$。\n    b.  如果 $F(L_c) = F_{min}$，我们应用平局规则：选择最小的 $L_c$。因此，我们更新 $L_{c,opt} = \\min(L_{c,opt}, L_c)$。\n\n4.  在评估了所有候选 $L_c$ 值之后，该对 $(L_{c,opt}, F_{min})$ 构成了该测试用例的解。对所有提供的测试用例重复此过程。然后将最终结果聚合成指定的输出格式。", "answer": "[32,0,16,0,64,2,32,0]", "id": "3675600"}]}