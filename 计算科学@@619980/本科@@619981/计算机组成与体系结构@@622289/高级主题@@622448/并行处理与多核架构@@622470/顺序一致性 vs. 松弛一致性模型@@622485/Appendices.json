{"hands_on_practices": [{"introduction": "理论知识需要通过实践来巩固。本练习将带您直面一个经典的并发问题，以理解顺序一致性 (Sequential Consistency, SC) 与像 x86 处理器采用的总存储顺序 (Total Store Order, TSO) 这样的宽松模型之间的核心差异。通过分析一个简单的双线程程序 [@problem_id:3675141]，您将亲身体会到由于核内存储缓冲区的存在，`Store→Load` 重排序是如何打破我们对程序执行顺序的直观预期的，并探索如何使用内存屏障 (memory fence) 来恢复更严格的顺序保证。", "problem": "考虑一个用于共享内存多处理器的执行模型，该模型由 Leslie Lamport 的顺序一致性（Sequential Consistency, SC）定义：如果执行结果与所有处理器的操作以某种交错方式执行的结果相同，并且每个独立处理器的操作顺序得以保留，则系统是顺序一致的。相比之下，x86 的总存储顺序（Total Store Order, TSO）模型强制 $Load \\rightarrow Load$ 和 $Store \\rightarrow Store$ 顺序像顺序一致性模型一样得以保留，但由于每核存储缓冲区和存储到加载的旁路机制，$Store \\rightarrow Load$ 重排序是可能的。x86 上的完整内存屏障（Memory Fence, $mfence$）会清空核心的存储缓冲区，并阻止任何后续内存操作执行，直到所有先前的内存操作都全局可见。\n\n给定以下双线程程序，其共享变量 $x$ 和 $y$ 初始值设为 $x = 0$ 和 $y = 0$。每个线程还有一个本地寄存器用于保存读取结果。\n\n线程 $0$：\n$1.$ $x \\leftarrow 1$\n$2.$ $r_1 \\leftarrow y$\n\n线程 $1$：\n$1.$ $y \\leftarrow 1$\n$2.$ $r_2 \\leftarrow x$\n\n在 SC 模型下，结果 $r_1 = 0$ 且 $r_2 = 0$ 是被禁止的，因为它要求两个加载操作都观察到初始值，尽管每个线程都执行了一个必须在与程序顺序一致的某个交错中可见的先行存储操作。然而，在 x86 TSO 模型下，$Store \\rightarrow Load$ 重排序允许两个加载操作通过存储缓冲区绕过线程自身的先前存储操作，从而使 $r_1 = 0$ 且 $r_2 = 0$ 成为可能的结果。\n\n你的任务是确定在这个程序中放置单个 $mfence$ 指令的位置，以恢复 SC 禁止的属性（即，使结果 $r_1 = 0$ 且 $r_2 = 0$ 在所有执行中都不可能发生）。选择唯一正确的选项。\n\nA. 在线程 0 的两个操作之间（即在 $x \\leftarrow 1$ 之后和 $r_1 \\leftarrow y$ 之前）插入一个 $mfence$，线程 1 中不插入屏障。\n\nB. 在线程 1 的两个操作之间（即在 $y \\leftarrow 1$ 之后和 $r_2 \\leftarrow x$ 之前）插入一个 $mfence$，线程 0 中不插入屏障。\n\nC. 在线程 0 的开头（即在线程 0 的任何内存操作之前）插入一个 $mfence$，线程 1 中不插入屏障。\n\nD. 在 x86 TSO 模型下，放置单个 $mfence$ 不足以消除 $r_1 = 0, r_2 = 0$ 的结果；要为此程序恢复 SC 禁止的属性，需要在两个线程的存储操作和随后的加载操作之间都插入一个 $mfence$。", "solution": "从基本定义和经过充分检验的事实开始：\n\n- 顺序一致性 (SC) 要求存在一个包含所有线程内存操作的单一全局顺序，该顺序尊重每个线程的程序顺序。如果两个线程各自执行一个 $Store$ 操作，后跟一个对另一个变量的 $Load$ 操作，那么 SC 禁止的结果 $r_1 = 0$ 且 $r_2 = 0$ 不会发生，因为在任何与两个程序顺序一致的交错中，至少有一个存储操作必须出现在另一个线程的加载操作之前，这使得至少有一个加载操作会观察到值 $1$。\n\n- x86 总存储顺序 (TSO) 保证了 $Load \\rightarrow Load$ 和 $Store \\rightarrow Store$ 顺序，但允许 $Store \\rightarrow Load$ 重排序，因为存储操作首先被放入每核的存储缓冲区，可能不会立即全局可见，而后续的加载操作可以绕过待处理的存储操作，从内存或从同一核心的存储缓冲区读取数据（存储转发）。因此，一个较晚的 $Load$ 操作可以在一个较早的 $Store$ 操作变为全局可见之前执行并观察到过时的数据。\n\n- x86 上的内存屏障 ($mfence$) 是一个完全屏障，它会清空存储缓冲区，并阻止后续的加载或存储操作执行，直到所有先前的加载和存储操作都变为全局可见。在给定核心的 $Store$ 和后续 $Load$ 操作之间放置 $mfence$ 可以防止该核心的 $Store \\rightarrow Load$ 重排序。\n\n现在分析给定的程序：\n\n线程 $0$：$x \\leftarrow 1; \\ r_1 \\leftarrow y$。\n线程 $1$：$y \\leftarrow 1; \\ r_2 \\leftarrow x$。\n初始状态：$x = 0$, $y = 0$。\n\n在 SC 模型下：结果 $r_1 = 0$ 且 $r_2 = 0$ 是不可能的。为了得到 $r_1 = 0$，线程 0 的加载操作必须在总顺序中发生在线程 1 的存储操作 $y \\leftarrow 1$ 之前。为了得到 $r_2 = 0$，线程 1 的加载操作必须发生在线程 0 的存储操作 $x \\leftarrow 1$ 之前。在尊重程序顺序的情况下，这将迫使两个加载操作在总顺序中都发生在两个存储操作之前，这与每个线程自身的程序顺序（每个线程内部 $Store$ 先于 $Load$）相矛盾。因此 SC 禁止 $r_1 = 0, r_2 = 0$。\n\n在 x86 TSO 模型下：每个线程的存储操作可以停留在其存储缓冲区中，而后续的加载操作则执行，从内存中读取另一个变量的初始值。具体来说，$x \\leftarrow 1$ 和 $y \\leftarrow 1$ 在 $r_1 \\leftarrow y$ 和 $r_2 \\leftarrow x$ 执行时可能仍然被缓冲而尚未全局可见，从而产生 $r_1 = 0$ 和 $r_2 = 0$。这是允许的，因为 TSO 模型允许 $Store \\rightarrow Load$ 重排序。\n\n我们现在考虑单个 $mfence$ 的放置是否能对所有执行禁止 $r_1 = 0, r_2 = 0$ 的结果。\n\n选项 A：在线程 0 的 $x \\leftarrow 1$ 和 $r_1 \\leftarrow y$ 之间放置单个 $mfence$。\n- 效果：$mfence$ 会清空线程 0 的存储缓冲区，并阻止 $r_1 \\leftarrow y$ 执行，直到 $x \\leftarrow 1$ 全局可见。但与此同时，线程 1 没有屏障，它仍然可以执行其自身的 $Store \\rightarrow Load$ 重排序。例如，线程 1 执行 $y \\leftarrow 1$ (被缓冲) 然后执行 $r_2 \\leftarrow x$，读取到 $0$。之后，线程 0 执行 $x \\leftarrow 1$ (被缓冲)，然后 $mfence$ 刷新 $x$，最后 $r_1 \\leftarrow y$ 读取到 $0$（因为线程 1 的写操作 $y \\leftarrow 1$ 仍可能被缓冲）。因此，结果 $r_1 = 0, r_2 = 0$ 仍然是可能的。结论：不正确。\n\n选项 B：在线程 1 的 $y \\leftarrow 1$ 和 $r_2 \\leftarrow x$ 之间放置单个 $mfence$。\n- 对称的推理同样适用。仅在线程 1 中放置屏障，并不能阻止线程 0 执行其自身的 $Store \\rightarrow Load$ 重排序。因此，结果 $r_1 = 0, r_2 = 0$ 仍然是可能的。结论：不正确。\n\n选项 C：在线程 0 的开头放置单个 $mfence$。\n- 在线程 0 的任何内存操作之前放置 $mfence$ 并不会约束线程 0 内部关键的 $Store \\rightarrow Load$ 重排序，因为没有更早的操作需要强制其可见性。在初始屏障之后，线程 0 仍然执行 $x \\leftarrow 1$ 后跟 $r_1 \\leftarrow y$，它们之间没有屏障；线程 1 也没有屏障。同样的 TSO 行为适用，结果 $r_1 = 0, r_2 = 0$ 仍然是可能的。结论：不正确。\n\n选项 D：单个 $mfence$ 不足；需要在两个线程的 $Store$ 和随后的 $Load$ 之间都放置 $mfence$。\n- 为了在 TSO 模型下使 $r_1 = 0, r_2 = 0$ 不可能发生，每个线程的 $Store \\rightarrow Load$ 都必须被排序，以使存储操作在其后续的加载操作之前变为全局可见。由于 TSO 重排序是独立地由每个核心的存储缓冲区引起的，要防止两个加载操作都读取到初始值这一结果，就要求两个线程在执行其加载操作之前都清空它们的存储缓冲区。仅在一个线程上放置单个屏障无法阻止另一个线程的加载操作绕过其自身的存储操作，因此无法消除该结果。如果在线程 0 的 $x \\leftarrow 1$ 和 $r_1 \\leftarrow y$ 之间以及线程 1 的 $y \\leftarrow 1$ 和 $r_2 \\leftarrow x$ 之间都放置 $mfence$，那么两个存储操作在加载操作执行之前都是全局可见的，从而保证至少有一个加载操作看到值 $1$，正如 SC 所要求的那样。结论：正确。\n\n结论：在 x86 TSO 模型下，放置单个 $mfence$ 不足以恢复此程序的 SC 禁止属性；您必须在两个线程的 $Store$ 和随后的 $Load$ 操作之间都放置 $mfence$。", "answer": "$$\\boxed{D}$$", "id": "3675141"}, {"introduction": "在掌握了如何使用内存屏障来强制执行顺序后，下一个挑战是优化。过多的屏障会带来不必要的性能开销。这个练习 [@problem_id:3675183] 采取了与前一个问题相反的视角：它从一个过度使用屏障、完全保证了顺序一致性的程序出发，要求您“裁剪”掉所有多余的屏障。要成功完成这项任务，您必须精确理解 TSO 模型自身已经提供了哪些顺序保证（例如 `Load→Load` 和 `Store→Store`），从而只保留那些真正必要的屏障，以防止模型所允许的关键重排序行为。", "problem": "考虑一个共享内存系统，该系统有两个线程，每个核心有一个FIFO存储缓冲区，以及一个内存栅栏指令，该指令会排空存储缓冲区并对内存操作进行排序。初始共享状态为 $x = 0$ 和 $y = 0$。目标基线行为是顺序一致性（SC），根据其定义，任何执行的结果都必须如同所有线程的操作在一个遵守每个线程程序顺序的单一全局顺序中执行一样。硬件实现的是完全存储定序（TSO），根据其定义，它会保持读-读、读-写和写-写关系的程序顺序，但由于存在存储缓冲区，它允许后续的加载（load）操作在先前的对不同地址的存储（store）操作之前执行（写-读重排序）。内存栅栏（MFENCE）会排空存储缓冲区，并防止跨越栅栏的此类重排序。\n\n程序如下：\n\n- 线程 $T_0$：\n  - 操作 $1$：存储 $x \\leftarrow 1$\n  - 操作 $2$：FENCE\n  - 操作 $3$：加载 $r_1 \\leftarrow y$\n  - 操作 $4$：FENCE\n\n- 线程 $T_1$：\n  - 操作 $1$：存储 $y \\leftarrow 1$\n  - 操作 $2$：FENCE\n  - 操作 $3$：加载 $r_2 \\leftarrow x$\n  - 操作 $4$：FENCE\n\n上述基线在每次对 $x$ 或 $y$ 的内存访问后都有一个 FENCE，以确保在 $TSO$ 上观察到的行为与 $SC$ 的行为相匹配。你的任务是在 TSO 上尽可能多地移除栅栏，同时保持 $SC$ 行为：也就是说，移除后，在 $TSO$ 上的所有可观察结果必须是该程序在 $SC$ 下结果的子集。请使用基本原理：SC 的定义，TSO 存储缓冲区规则（只允许对不同地址进行写-读重排序），以及 FENCE 排空存储缓冲区并对内存操作进行排序的语义。\n\n哪个选项描述了一个正确的移除方案，该方案在为该程序保持 $TSO$ 上的 $SC$ 行为的同时，移除了最大数量的栅栏？\n\nA. 移除紧跟在加载操作之后的栅栏（两个线程中的操作 $4$），保留紧跟在存储操作之后的栅栏（两个线程中的操作 $2$）。\n\nB. 移除紧跟在存储操作之后的栅栏（两个线程中的操作 $2$），保留紧跟在加载操作之后的栅栏（两个线程中的操作 $4$）。\n\nC. 移除所有栅栏。\n\nD. 保留所有栅栏；任何一个都不能在不丢失 $SC$ 行为的情况下被移除。", "solution": "本问题的目标是在保证顺序一致性 (SC) 行为的前提下，从一个为总存储顺序 (TSO) 模型设计的、过度使用屏障的程序中，移除最大数量的多余内存栅栏 (FENCE)。\n\n1.  **分析 SC 禁止的结果**:\n    在 SC 模型下，所有操作存在一个单一的全局顺序，该顺序尊重每个线程的程序顺序。对于给定的程序：\n    - $T_0$: $x \\leftarrow 1$ (记为 $S_x$); $r_1 \\leftarrow y$ (记为 $L_y$)\n    - $T_1$: $y \\leftarrow 1$ (记为 $S_y$); $r_2 \\leftarrow x$ (记为 $L_x$)\n    在 SC 模型下，结果 $(r_1=0, r_2=0)$ 是被禁止的。因为若要 $r_1=0$，则 $L_y$ 必须在 $S_y$ 之前发生 ($L_y \\rightarrow S_y$)。若要 $r_2=0$，则 $L_x$ 必须在 $S_x$ 之前发生 ($L_x \\rightarrow S_x$)。结合程序顺序 ($S_x \\xrightarrow{PO} L_y$ 和 $S_y \\xrightarrow{PO} L_x$)，这将导致一个循环依赖：$S_x \\xrightarrow{PO} L_y \\rightarrow S_y \\xrightarrow{PO} L_x \\rightarrow S_x$，这在 SC 的线性总序中是不可能的。因此，维持 SC 行为的关键在于禁止 $(r_1=0, r_2=0)$ 这个结果。\n\n2.  **分析 TSO 模型与 FENCE 的作用**:\n    TSO 模型允许“写后读”重排序（Store-Load Reordering），即一个线程的加载操作可以越过其前面未完成的、对不同地址的存储操作。这正是可能导致非 SC 结果 $(r_1=0, r_2=0)$ 的根源。`FENCE` 指令通过清空存储缓冲区来阻止这种重排序，确保栅栏前的所有内存操作在栅栏后的操作开始前全局可见。\n\n3.  **评估栅栏移除方案**:\n    - **移除所有栅栏 (选项 C)**: 如果没有栅栏，每个线程的 `load` 都可以重排到其 `store` 之前生效。$T_0$ 的 $x \\leftarrow 1$ 停留在其写缓冲中，同时它读取主存中 $y=0$。$T_1$ 的 $y \\leftarrow 1$ 也停留在其写缓冲中，同时它读取主存中 $x=0$。这会导致 $(r_1=0, r_2=0)$，违反了 SC。因此，选项 C 不正确。\n    - **移除操作 2 的栅栏 (选项 B)**: 移除了位于 `store` 和 `load` 之间的关键栅栏。这与移除所有栅栏的情况一样，允许了 Store-Load 重排序，从而可以产生 $(r_1=0, r_2=0)$ 的结果。操作 4 的栅栏在加载之后，无法阻止加载之前的重排序。因此，选项 B 不正确。\n    - **保留操作 2 的栅栏，移除操作 4 的栅栏 (选项 A)**:\n        - 程序变为：$T_0$: $x \\leftarrow 1$; FENCE; $r_1 \\leftarrow y$ 和 $T_1$: $y \\leftarrow 1$; FENCE; $r_2 \\leftarrow x$。\n        - 每个线程的 `FENCE` 位于 `store` 和 `load` 之间，这精确地阻止了 TSO 模型允许的 Store-Load 重排序。因此，$(r_1=0, r_2=0)$ 的结果被禁止，维持了 SC 行为。\n        - 操作 4 的栅栏位于加载操作之后，且是程序的最后一步。TSO 模型自身保证了 Load-Load 和 Load-Store 的顺序。由于加载操作之后没有其他内存操作，这个栅栏是多余的。移除它们不会引入任何新的重排序行为，也不会影响程序的可观察结果。\n        - 这个选项移除了最大数量的多余栅栏，同时保留了必要的栅栏。因此，选项 A 正确。\n    - **保留所有栅栏 (选项 D)**: 这个配置确实能保证 SC 行为，但它不是最优解，因为操作 4 的栅栏是多余的。问题要求移除*最大数量*的栅栏。因此，选项 D 不正确。\n\n综上所述，最优化方案是移除每个线程中加载操作之后的栅栏（操作 4），但保留存储和加载之间的栅栏（操作 2）。", "answer": "$$\\boxed{A}$$", "id": "3675183"}, {"introduction": "不同的处理器架构在性能和一致性之间做出了不同的权衡。本练习 [@problem_id:3675167] 将您的视野从 x86 TSO 模型扩展到更弱的内存模型，例如 ARM 架构中常见的模型。这个问题引入了一个带有数据依赖（地址依赖）的场景，旨在揭示一个常见的误解：即便是看似强制的依赖关系，在弱模型中也未必能保证跨线程的内存可见性顺序。通过对比 SC、TSO 和弱模型的行为，并分析如何使用数据内存屏障 (Data Memory Barrier, DMB) 进行修复，您将对内存一致性的复杂性和多样性有更深刻的认识。", "problem": "两个线程使用两个共享位置：一个整型标量 $x$ 和一个包含两个元素 $y[0]$ 和 $y[1]$ 的数组 $y[\\,\\cdot\\,]$。所有共享位置都初始化为 $0$，即 $x=0$，$y[0]=0$，$y[1]=0$。考虑以下并发程序（每个线程在自己的处理器核心上运行）：\n- 线程 $P_0$：首先执行 $y[1] \\leftarrow 1$，然后执行 $x \\leftarrow 1$。\n- 线程 $P_1$：首先执行 $r_1 \\leftarrow x$，然后执行 $r_2 \\leftarrow y[r_1]$。\n\n因此，在 $P_1$ 上，从将 $x$ 加载到 $r_1$ 的操作到后续加载 $y[r_1]$ 所使用的地址之间存在数据（地址）依赖。除非明确说明，否则不存在任何栅栏、屏障或特殊的获取/释放操作。\n\n仅使用内存一致性的核心定义：\n- 顺序一致性 (SC)：所有内存操作存在一个单一的全局总序，该顺序与每个线程的程序顺序一致，并且每次加载都返回该总序中对同一位置最近一次写入的值。\n- 全存储排序 (TSO)：每个线程的加载和存储看起来都按程序顺序执行，但加载操作可以通过一个先进先出（FIFO）的存储缓冲区绕过同一线程中先前对不同地址的存储操作；写操作是多副本原子性的，并在全局可见性顺序中保持每个线程的程序顺序。\n- 类 ARMv8 弱序（代表高级精简指令集机器（ARM）架构）：在没有显式排序的情况下，加载和存储可能被重排序，存储传播到其他核心不一定是即时的，也未必与其他存储在全局上有序，并且仅仅是数据/控制/地址依赖本身并不会创建线程间的可见性顺序；排序可以通过数据内存屏障 (DMB) 或使用获取/释放操作来强制执行。指令同步屏障 (ISB) 在自修改代码或系统状态更改后对指令获取和执行进行排序，而不是对数据内存访问进行排序。\n\n分析在上述模型下是否可能出现 $r_1=1$ 和 $r_2=0$ 的结果，以及在类 ARM 系统上需要哪些屏障才能禁止这种结果。选择所有正确的陈述。\n\nA. 在顺序一致性下，不可能出现 $r_1=1$ 和 $r_2=0$ 的结果。\n\nB. 在全存储排序下，即使 $P_1$ 上存在数据依赖，由于推测性加载，也可能出现 $r_1=1$ 和 $r_2=0$ 的结果。\n\nC. 在没有屏障的类 ARMv8 弱序机器上，尽管 $P_1$ 上存在从 $r_1$ 到 $r_2$ 的数据（地址）依赖，该模型仍然允许出现 $r_1=1$ 和 $r_2=0$ 的结果。\n\nD. 在类 ARMv8 机器上，在 $P_1$ 的两次加载之间插入一条指令同步屏障 (ISB) 足以禁止 $r_1=1$ 和 $r_2=0$ 的结果。\n\nE. 在类 ARMv8 机器上，在 $P_0$ 的两次存储之间插入一条数据内存屏障 (DMB) 并且在 $P_1$ 的两次加载之间插入一条数据内存屏障 (DMB)，可以禁止 $r_1=1$ 和 $r_2=0$ 的结果，从而为此模式产生与顺序一致性等效的行为。", "solution": "问题要求我们分析一个并发程序在不同内存一致性模型下的可能结果。问题的核心在于，处理器或内存系统对内存操作的重排序是否会导致某种特定状态。\n\n共享变量的初始状态为 $x=0$，$y[0]=0$ 和 $y[1]=0$。操作如下：\n- 线程 $P_0$：$S_1: y[1] \\leftarrow 1$；$S_2: x \\leftarrow 1$。\n- 线程 $P_1$：$L_1: r_1 \\leftarrow x$；$L_2: r_2 \\leftarrow y[r_1]$。\n\n需要评估的结果是 $r_1=1$ 和 $r_2=0$。要出现这个结果：\n1. $P_1$ 上的加载操作 $L_1$ 必须读取由 $P_0$ 上的存储操作 $S_2$ 写入的值。这意味着 $P_1$ 观察到了 $S_2$ 的效果。\n2. $P_1$ 上的加载操作 $L_2$（由于 $r_1=1$ 而变为 $r_2 \\leftarrow y[1]$）必须读取 $y[1]$ 的初始值 $0$。这意味着 $P_1$ 必须在观察到 $P_0$ 的存储操作 $S_1$ 的效果*之前*执行此加载。\n\n总而言之，问题在于，在 $P_1$ 自身加载操作之间存在数据依赖的情况下，线程 $P_1$ 是否有可能在没有观察到 $P_0$ 的第一个存储 ($S_1$) 的情况下观察到 $P_0$ 的第二个存储 ($S_2$)。\n\n让我们根据所提供的定义来评估每个陈述。\n\nA. 在顺序一致性下，不可能出现 $r_1=1$ 和 $r_2=0$ 的结果。\n\n顺序一致性 (SC) 要求所有内存操作存在一个单一的全局总序，并且该顺序必须与每个线程的程序顺序一致。\n我们用 `po` 表示程序顺序。在 $P_0$ 上，我们有 $S_1 \\xrightarrow{po} S_2$。在 $P_1$ 上，我们有 $L_1 \\xrightarrow{po} L_2$。\n要使 $r_1=1$ 和 $r_2=0$ 的结果出现，在假设的全局总序中：\n1.  $L_1$ 必须从 $S_2$ 读取。这意味着在总序中，$S_2$ 必须在 $L_1$ 之前。我们将其表示为 $S_2 \\rightarrow L_1$。\n2.  $L_2$（由于 $r_1=1$，它是对 $y[1]$ 的读取）必须读取初始值 $0$，而不是从 $S_1$ 写入的值。这意味着在总序中，$L_2$ 必须在 $S_1$ 之前。我们将其表示为 $L_2 \\rightarrow S_1$。\n\n现在，让我们将这些事实与程序顺序约束结合起来，这些约束也必须在全局总序中得到遵守：\n- 来自 $P_0$ 的程序顺序：$S_1 \\rightarrow S_2$。\n- 来自 $P_1$ 的程序顺序：$L_1 \\rightarrow L_2$。\n\n结合所有关系，我们得到以下循环：\n$L_1 \\rightarrow L_2 \\rightarrow S_1 \\rightarrow S_2 \\rightarrow L_1$。\n在总序中不可能存在循环。因此，没有有效的 SC 执行可以产生此结果。\n该陈述是**正确的**。\n\nB. 在全存储排序下，即使 $P_1$ 上存在数据依赖，由于推测性加载，也可能出现 $r_1=1$ 和 $r_2=0$ 的结果。\n\n全存储排序 (TSO) 的关键属性是，来自单个处理器的写操作对*其他*处理器按程序顺序可见。这是因为存储缓冲区是先进先出 (FIFO) 的。\n当 $P_0$ 执行 $S_1: y[1] \\leftarrow 1$ 然后执行 $S_2: x \\leftarrow 1$ 时，这些存储操作按此顺序进入其存储缓冲区。它们也将以相同的顺序提交到全局内存（从而对 $P_1$ 可见）。\n因此，$P_1$ 不可能在无法观察到 $S_1$ 效果（读取 $y[1]=1$）的情况下观察到 $S_2$ 的效果（读取 $x=1$）。如果 $P_1$ 执行 $L_1$ 并得到 $r_1=1$，那么写操作 $S_2$ 必定已经全局可见。由于 TSO 存储传播的 FIFO 特性，$S_1$ 在那时也必须是全局可见的。\n当 $P_1$ 随后执行 $L_2$（从 $y[1]$ 读取）时，它必然会看到值 $1$。因此，结果 $r_2=0$ 是不可能的。\n“推测性加载”的提法具有误导性。虽然处理器使用推测执行，但如果推测不正确，其效果必须被撤销。$P_1$ 上的地址依赖 ($L_1 \\rightarrow L_2$) 意味着在 $r_1$ 的值已知之前，$L_2$ 不能提交其结果。如果处理器用一个猜测的地址（例如，假设 $r_1=0$）来推测性地执行 $L_2$，一旦 $L_1$ 解析为 $r_1=1$，它就必须取消并用正确的地址 ($y[1]$) 重新执行 $L_2$。到那时，如前所述，$y[1]$ 的值将是 $1$。\n该陈述是**不正确的**。\n\nC. 在没有屏障的类 ARMv8 弱序机器上，尽管 $P_1$ 上存在从 $r_1$ 到 $r_2$ 的数据（地址）依赖，该模型仍然允许出现 $r_1=1$ 和 $r_2=0$ 的结果。\n\n弱序模型，如 ARMv8，不保证来自一个处理器的存储操作会按程序顺序对其他处理器可见。存储操作 $S_1$ 和 $S_2$ 是针对不同的内存位置（$y[1]$ 和 $x$）。内存系统可以自由地重排序它们向其他核心的传播。\n以下事件序列是可能的：\n1.  $P_0$ 执行 $S_1: y[1] \\leftarrow 1$。此写操作在内存系统中正在传输。\n2.  $P_0$ 执行 $S_2: x \\leftarrow 1$。此写操作也正在传输。\n3.  对 $x$ 的写操作通过内存系统传播，并首先对 $P_1$ 可见。\n4.  $P_1$ 执行 $L_1: r_1 \\leftarrow x$ 并读取值 $1$。现在 $r_1=1$。\n5.  对 $y[1]$ 的写操作尚未对 $P_1$ 可见。\n6.  $P_1$ 遵守其内部数据依赖。现在知道 $r_1=1$，它执行 $L_2: r_2 \\leftarrow y[1]$。由于 $y[1]$ 的新值尚不可见，$P_1$ 读取旧值 $0$。现在 $r_2=0$。\n7.  稍后，对 $y[1]$ 的写操作对 $P_1$ 可见。\n\n这个执行导致 $r_1=1$ 和 $r_2=0$。$P_1$ 上的数据依赖得到了遵守（它阻止了 $L_2$ 在 $L_1$ 提供地址之前执行），但是一个核心上的这种局部依赖并不能强制对来自另一个核心的存储操作的可见性进行全局排序。这是弱内存模型的一个基本特征。\n该陈述是**正确的**。\n\nD. 在类 ARMv8 机器上，在 $P_1$ 的两次加载之间插入一条指令同步屏障 (ISB) 足以禁止 $r_1=1$ 和 $r_2=0$ 的结果。\n\n问题中对 ISB 的定义是关键：“指令同步屏障 (ISB) 对指令获取和执行进行排序... 而不是对数据内存访问进行排序。” ISB 会刷新处理器的流水线，并确保 ISB 之后的指令只有在 ISB 之前的指令完成后才被获取。它用于同步指令流，例如在修改代码或系统寄存器之后。它不强制执行与其它核心相关的数据内存访问的任何排序。这里的问题是来自 $P_0$ 的数据写入的相对可见性顺序。$P_1$ 上的 ISB 对此没有影响。在 C 部分描述的存储可见性重排序仍然可能发生。需要一个内存屏障（如 DMB）来对数据访问进行排序。\n该陈述是**不正确的**。\n\nE. 在类 ARMv8 机器上，在 $P_0$ 的两次存储之间插入一条数据内存屏障 (DMB) 并且在 $P_1$ 的两次加载之间插入一条数据内存屏障 (DMB)，可以禁止 $r_1=1$ 和 $r_2=0$ 的结果，从而为此模式产生与顺序一致性等效的行为。\n\n让我们分析修改后的程序：\n- 线程 $P_0$：$y[1] \\leftarrow 1$；`DMB`；$x \\leftarrow 1$。\n- 线程 $P_1$：$r_1 \\leftarrow x$；`DMB`；$r_2 \\leftarrow y[r_1]$。\n\n数据内存屏障 (DMB) 是一种对内存访问进行排序的栅栏。\n在 $P_0$ 上，`DMB` 确保存储操作 $S_1: y[1] \\leftarrow 1$ 在存储操作 $S_2: x \\leftarrow 1$ 变得全局可见之前变得全局可见。任何能看到 $x$ 新值的核心都保证也能看到 $y[1]$ 的新值。\n在 $P_1$ 上，`DMB` 确保加载操作 $L_1$ 在加载操作 $L_2$ 之前执行。（注意：在 ARMv8 上，地址依赖已经强制执行了此顺序，因此这个 `DMB` 在此特定场景下可能多余，但它的存在加强了排序）。\n\n现在，让我们追踪执行过程，看看是否可能出现 $r_1=1, r_2=0$ 的结果。\n1. 为了让 $P_1$ 得到 $r_1=1$，它必须观察到写操作 $S_2: x \\leftarrow 1$。\n2. 由于 $P_0$ 上的 `DMB`，如果 $P_1$ 观察到了 $S_2$，那么可以保证 $S_1: y[1] \\leftarrow 1$ 的效果对 $P_1$ 也是可观察的。\n3. 然后 $P_1$ 执行 $L_2$（在 $L_1$ 之后，由程序顺序、依赖关系和 `DMB` 强制执行）。由于 $r_1=1$，这是一个从 $y[1]$ 的加载。\n4. 此时，可以保证 $y[1]$ 的新值（即 $1$）对 $P_1$ 是可见的。因此，加载操作 $L_2$ 必须返回 $1$。\n5. 这意味着 $r_2$ 不可能为 $0$。\n\nDMB 的组合成功地禁止了 $r_1=1, r_2=0$ 的结果。对于这个程序，这种恢复的行为确实等价于在顺序一致性下可以观察到的行为。\n该陈述是**正确的**。", "answer": "$$\\boxed{ACE}$$", "id": "3675167"}]}