{"hands_on_practices": [{"introduction": "在编程I/O中，一个核心的挑战是在响应延迟和CPU资源消耗之间找到平衡点。频繁地轮询设备可以快速检测到事件，但会占用宝贵的CPU周期；反之，减少轮询频率则会增加延迟。这个练习将引导你通过建立一个数学模型，来量化这种权衡关系，并学习如何在给定的CPU预算下，计算出最小化平均延迟的最佳轮询周期 [@problem_id:3670436]。", "problem": "一个单核中央处理器 (CPU) 通过程序化输入/输出 (I/O) 来管理一个设备，它每隔 $T_{p}$ 秒定期轮询设备的状态寄存器。每次轮询花费固定的 CPU 时间 $c$（单位：秒），并且每个设备事件在被检测到时，需要一个固定的单位事件处理时间 $s$（单位：秒）。事件以平均速率 $\\lambda$（单位：事件/秒）从设备到达，且到达时间与轮询时刻无关。每秒 CPU 时间中的一部分 $U$ 被预算并保留给该设备（即其 CPU 利用率不能超过 $U$）。\n\n假设以下基本事实：\n\n- 在周期为 $T_{p}$ 的周期性轮询下，如果事件到达时刻与轮询调度无关，则预期的检测延迟为 $T_{p}/2$。\n- 从事件到达至其处理完成的平均延迟 $L$ 可以建模为预期检测延迟与单位事件处理时间之和，即 $L = T_{p}/2 + s$，前提是系统稳定，从而排队效应可以忽略不计。\n- 设备每秒消耗的总 CPU 时间等于轮询开销和事件处理时间之和，即 $c/T_{p} + Ts$，其中 $T$ 是已处理的事件速率（吞吐量），单位为事件/秒。\n\n任务：\n\n1) 使用 CPU 预算约束，将最大可持续吞吐量 $T$ 表示为 $T_{p}$、$s$、$c$ 和 $U$ 的函数，假设系统在无积压（稳定状态）下运行。\n\n2) 对于一个给定的外部到达速率 $\\lambda$（必须在不超过 CPU 预算 $U$ 的情况下维持），确定能够最小化平均延迟 $L$ 的轮询周期 $T_{p}^{\\star}$。此过程需满足稳定性约束（即设备吞吐量至少为 $\\lambda$）并遵守 CPU 预算。请陈述参数所需的任何可行性条件。\n\n请以一个关于 $c$、$s$、$\\lambda$ 和 $U$ 的单一闭式表达式给出 $T_{p}^{\\star}$ 的最终答案。最终答案中不要包含单位。如果使用了任何近似，请在推导中从第一性原理出发进行论证。无需进行数值计算。", "solution": "我们从陈述的基本事实出发，建立所需的关系。\n\nCPU 预算下的吞吐量：\n\n- 每次轮询消耗 $c$ 秒的 CPU 时间，并且每 $T_{p}$ 秒发生一次，因此每秒的轮询开销为 $c/T_{p}$。\n- 如果设备每秒处理 $T$ 个事件，每个事件需要 $s$ 秒的 CPU 时间，则事件处理每秒消耗 $Ts$ 秒的 CPU 时间。\n- 在预算 $U$ 下，分配给此设备的总 CPU 时间必须满足\n$$\n\\frac{c}{T_{p}} + Ts \\leq U.\n$$\n在此约束下求解最大可行吞吐量，我们得到\n$$\nT \\leq \\frac{U - \\frac{c}{T_{p}}}{s}.\n$$\n因此，作为 $T_{p}$ 函数的最大可持续吞吐量（容量）为\n$$\nT_{\\max}(T_{p}) = \\frac{U - \\frac{c}{T_{p}}}{s},\n$$\n条件是 $U - \\frac{c}{T_{p}} \\geq 0$，等价于 $T_{p} \\geq \\frac{c}{U}$。这就是任务 1 所要求的表达式。\n\n平均延迟：\n\n- 在具有独立到达的周期性轮询下，预期的检测延迟为 $T_{p}/2$。\n- 单位事件服务时间为 $s$。\n- 在稳定条件下忽略排队效应（即，处理速率等于到达速率且不超过容量），平均延迟建模为\n$$\nL(T_{p}) = \\frac{T_{p}}{2} + s.\n$$\n\n在维持 $\\lambda$ 的约束下的优化问题：\n\n- 为了稳定地维持外部到达速率 $\\lambda$，系统的容量必须满足\n$$\nT_{\\max}(T_{p}) \\geq \\lambda \\quad \\Longleftrightarrow \\quad \\frac{U - \\frac{c}{T_{p}}}{s} \\geq \\lambda.\n$$\n这个不等式等价于\n$$\n\\frac{c}{T_{p}} \\leq U - \\lambda s,\n$$\n（在 $U - \\lambda s  0$ 的情况下）可以重排为\n$$\nT_{p} \\geq \\frac{c}{U - \\lambda s}.\n$$\n条件 $U - \\lambda s  0$ 是一个可行性要求：若不满足此条件，则无论如何选择 $T_{p}$，都无法提供足够的 CPU 时间来以速率 $\\lambda$ 处理事件。\n\n- 平均延迟 $L(T_{p}) = \\frac{T_{p}}{2} + s$ 是关于 $T_{p}$ 的严格递增函数，因此在约束 $T_{p} \\geq \\frac{c}{U - \\lambda s}$ 下最小化 $L$ 的目标是通过选择最小的可行 $T_{p}$ 来实现的，即\n$$\nT_{p}^{\\star} = \\frac{c}{U - \\lambda s},\n$$\n在可行性条件 $U  \\lambda s$ 下。\n\n这个选择也自动满足了容量的非负性条件 $T_{p} \\geq \\frac{c}{U}$，因为 $\\lambda s \\geq 0$ 意味着 $U - \\lambda s \\leq U$，从而 $\\frac{c}{U - \\lambda s} \\geq \\frac{c}{U}$。\n\n总结：\n\n- 作为 $T_{p}$ 函数的最大可持续吞吐量为 $T_{\\max}(T_{p}) = \\frac{U - \\frac{c}{T_{p}}}{s}$，其中 $T_{p} \\geq \\frac{c}{U}$。\n- 在 CPU 预算 $U$ 内维持到达速率 $\\lambda$ 并使延迟最小化的轮询周期是 $T_{p}^{\\star} = \\frac{c}{U - \\lambda s}$，前提是 $U  \\lambda s$。\n\n所要求的最终闭式表达式是 $T_{p}^{\\star} = \\frac{c}{U - \\lambda s}$。", "answer": "$$\\boxed{\\frac{c}{U - \\lambda s}}$$", "id": "3670436"}, {"introduction": "编程I/O的性能不仅取决于系统级的设计，还深受底层微架构行为的影响。一个典型的轮询循环包含一个条件分支，它在每次迭代中检查设备状态。这个练习将带你深入CPU流水线的内部，分析当设备状态从‘未就绪’变为‘就绪’时，分支预测器如何可能发生错误，并计算由此产生的性能惩罚，即CPI（每指令周期数）的增加量 [@problem_id:3670472]。", "problem": "一个中央处理器（CPU）执行一个程序化输入/输出（I/O）轮询循环，该循环重复测试一个实现为内存映射状态位的设备就绪标志。循环体仅由一条指令组成：一个条件后向分支，它在每次迭代中重新评估该标志，并在设备未就绪时向后分支。流水线中的分支预测器使用一种固定策略，即假定设备未就绪。当预测器出错时，流水线会产生 $c_{bm}$ 个周期的分支预测错误刷新惩罚。将设备就绪情况建模为跨迭代的一系列独立试验，其中在每次迭代中，设备以概率 $p$ 就绪，以概率 $1-p$ 未就绪。并假设当设备未就绪时分支结果与预测器匹配，而当设备就绪时则偏离预测。使用以下定义：每指令周期数（CPI）是总周期数除以总已提交指令数；由离散事件引起的预期额外周期数等于该事件周期成本的期望值。\n\n从这些定义出发，推导此轮询循环中仅由分支预测错误引起的CPI膨胀 $\\Delta \\mathrm{CPI}$，并计算其在 $p = 0.08$ 和 $c_{bm} = 17$ 时的数值。以每指令周期数（cycles per instruction）为单位表示你的最终答案，并四舍五入到四位有效数字。", "solution": "问题要求推导和计算在一个特定的程序化I/O轮询循环中，由分支预测错误引起的每指令周期数（CPI）膨胀，记作 $\\Delta \\mathrm{CPI}$。\n\n首先，我们确立问题中给出的定义和关系。每指令周期数（CPI）定义为执行的总周期数与已提交指令总数的比率：\n$$\n\\mathrm{CPI} = \\frac{\\text{总周期数}}{\\text{总指令数}}\n$$\n总周期数可以分解为一个基准部分（$C_{base}$）和一个惩罚部分（$C_{penalty}$）。基准部分表示假设没有流水线停顿或刷新的情况下执行的周期数，而惩罚部分表示由于分支预测错误等事件而产生的额外周期数。\n$$\n\\text{总周期数} = C_{base} + C_{penalty}\n$$\n因此，CPI可以写成一个基准CPI和一个膨胀项 $\\Delta \\mathrm{CPI}$ 的和，该膨胀项代表了惩罚周期带来的贡献。\n$$\n\\mathrm{CPI} = \\frac{C_{base}}{\\text{总指令数}} + \\frac{C_{penalty}}{\\text{总指令数}} = \\mathrm{CPI}_{base} + \\Delta \\mathrm{CPI}\n$$\n问题要求的是仅由分支预测错误引起的CPI膨胀。这对应于以下项：\n$$\n\\Delta \\mathrm{CPI} = \\frac{C_{penalty}}{\\text{总指令数}}\n$$\n由于设备就绪是一个概率过程，我们必须使用期望值。CPI膨胀是每条已提交指令的预期惩罚周期数。\n$$\n\\Delta \\mathrm{CPI} = \\frac{E[C_{penalty}]}{\\text{总指令数}}\n$$\n问题指出，轮询循环由单条指令组成：一个条件后向分支。这意味着循环的每次迭代都恰好提交一条指令。因此，分析“每次迭代”等同于分析“每条指令”。\n\n让我们确定每条指令的预期惩罚周期数。只有在发生分支预测错误时才会产生惩罚。\n分支预测器使用固定策略，总是假定设备未就绪。这意味着预测器总是预测分支会发生（以循环返回）。\n如果实际结果与预测不同，则发生预测错误。分支结果取决于设备状态：\n\\begin{itemize}\n    \\item 如果设备未就绪（以概率 $1-p$ 发生），则条件分支被采纳。预测（“未就绪”/分支采纳）是正确的。\n    \\item 如果设备就绪（以概率 $p$ 发生），则分支不被采纳，循环终止。预测（“未就绪”/分支采纳）是不正确的。\n\\end{itemize}\n因此，当且仅当设备就绪时，才会发生分支预测错误。在任何给定迭代中（因此对于每个执行的分支指令），预测错误的概率是 $p$。\n\n单次分支预测错误的惩罚为 $c_{bm}$ 个周期。如果预测正确，惩罚为 $0$ 个周期。我们可以将单条指令的惩罚周期数建模为一个离散随机变量 $C_{penalty, instr}$，它以概率 $p$ 取值 $c_{bm}$，以概率 $1-p$ 取值 $0$。\n\n每条指令的预期额外周期数是该随机变量的期望值：\n$$\nE[C_{penalty, instr}] = (c_{bm} \\times p) + (0 \\times (1-p)) = p \\times c_{bm}\n$$\n这个期望值代表了在轮询循环中执行的每条指令平均增加的惩罚周期数。根据定义，这就是由分支预测错误引起的CPI膨胀。\n$$\n\\Delta \\mathrm{CPI} = p \\times c_{bm}\n$$\n现在，我们将给定的数值代入这个表达式。我们已知：\n\\begin{itemize}\n    \\item 设备就绪的概率，$p = 0.08$。\n    \\item 分支预测错误惩罚，$c_{bm} = 17$ 个周期。\n\\end{itemize}\n代入这些值，我们计算 $\\Delta \\mathrm{CPI}$：\n$$\n\\Delta \\mathrm{CPI} = 0.08 \\times 17\n$$\n$$\n\\Delta \\mathrm{CPI} = 1.36\n$$\n问题要求答案四舍五入到四位有效数字。计算出的值 $1.36$ 有三位有效数字。为了用四位有效数字表示，我们在末尾追加一个零。\n$$\n\\Delta \\mathrm{CPI} = 1.360 \\text{ 周期/指令}\n$$", "answer": "$$\\boxed{1.360}$$", "id": "3670472"}, {"introduction": "在现代计算系统中，编程I/O常常被用作一种同步机制，例如，CPU通过轮询一个标志位来等待DMA（直接内存访问）传输完成。然而，在弱内存排序模型下，如果缺乏正确的同步指令，CPU可能会在观察到标志位变化之前就读取到过时的数据，从而导致程序错误。这个练习探讨了在CPU和DMA协作的场景下，如何使用内存栅栏（memory fence）或获取/释放语义（acquire/release semantics）来确保数据一致性和操作的正确顺序 [@problem_id:3670422]。", "problem": "一个实现了弱序内存模型的单处理器系统，在直接内存访问 (DMA) 引擎传输数据的同时，通过轮询一个完成标志来执行程序控制输入/输出 (I/O)。内存系统是缓存一致的：DMA 对物理内存的写入会传播到一致性点，并将使 CPU 缓存中的任何缓存副本无效或被更新。考虑以下场景。\n\n一个 DMA 引擎在物理地址范围 $\\left[B, B + N - 1\\right]$ 写入一个连续缓冲区，然后将物理地址 $F$ 上的一个完成标志设置为值 $1$。该 DMA 引擎被编程为按程序顺序发出其写入：它执行一系列对数据缓冲区的写入 $\\{W_d(i)\\}$，然后执行一个将 $1$ 存储到 $F$ 的写入 $W_f$。互连保持 DMA 引擎的程序顺序，即在所有之前的写入 $\\{W_d(i)\\}$ 到达一致性点之前，$W_f$ 对其他代理（agent）是不可见的。CPU 轮询 $F$，当观察到 $F = 1$ 时，读取缓冲区 $\\left[B, B + N - 1\\right]$。\n\n设相关的抽象操作为：\n- 对于 DMA：数据写入 $W_d(0), W_d(1), \\ldots, W_d(k)$，然后是标志写入 $W_f$（将 $1$ 存入 $F$）。\n- 对于 CPU：在轮询循环中重复加载标志 $L_f$，直到 $L_f$ 返回 $1$，然后从 $\\left[B, B + N - 1\\right]$ 加载数据 $L_b(j)$。\n\n假设：\n- 缓存一致性结构为每个位置提供单写多读一致性，并且从特定写入返回的读取意味着该写入对读取者是可见的。\n- 在没有显式排序指令的情况下，CPU 可以将加载与其他加载重排序，以及将加载与更早的加载重排序。\n- CPU 不执行任何显式缓存维护操作。\n\n问题：哪些 CPU 端的排序原语足以保证，在轮询循环观察到 $F = 1$ 之后，所有后续 CPU 对缓冲区的读取 $L_b(j)$ 都能观察到 DMA 写入 $W_d(i)$ 的值，即为所有的 $i, j$ 建立可靠的排序 $$W_d(i) \\rightarrow W_f \\rightarrow L_f \\rightarrow L_b(j) \\text{ for all } i, j$$？选择所有适用的选项。\n\nA. 在轮询循环中使用获取语义（对 $F$ 进行 load-acquire 操作）读取标志 $F$，或者等效地，在 $L_f$ 返回 $1$ 的那次迭代之后、任何 $L_b(j)$ 之前立即执行一个读内存屏障，且不使用其他栅栏。假设 DMA 仅在所有 $W_d(i)$ 在一致性点可见之后才发出 $W_f$。\n\nB. 在进入轮询循环之前执行一次全内存屏障；此后对标志和缓冲区都使用松散加载（relaxed load）。\n\nC. 仅依赖缓存一致性以及 DMA 最后写入标志这一事实；将所有 CPU 加载都作为无栅栏的松散加载（relaxed load）执行。\n\nD. 当 CPU 稍后通过向 $F$ 写入 $0$ 来清除标志以供重用时，在那时对 $F$ 使用存储-释放（store-release）操作；在读取 $F$ 的前后不需要进行排序。\n\nE. 在轮询循环观察到 $F = 1$ 之后，在任何 $L_b(j)$ 之前执行一个全内存屏障，然后使用松散加载（relaxed load）读取缓冲区。", "solution": "### 问题陈述的验证\n\n**步骤 1：提取已知条件**\n-   系统：具有弱序内存模型的单处理器 CPU。\n-   I/O：对完成标志进行程序控制 I/O（轮询）。\n-   数据传输：直接内存访问 (DMA) 引擎。\n-   内存系统：缓存一致。DMA 对物理内存的写入会传播到一致性点，并使 CPU 缓存副本无效或被更新。\n-   DMA 操作：\n    1.  对物理地址范围 $[B, B + N - 1]$ 的连续缓冲区进行写入。将这些写入表示为 $\\{W_d(i)\\}$。\n    2.  将物理地址 $F$ 上的完成标志设置为值 $1$。将此写入表示为 $W_f$。\n-   DMA 排序：DMA 按程序顺序发出写入：$\\{W_d(i)\\}$ 后跟 $W_f$。\n-   互连行为：在所有先前的写入 $\\{W_d(i)\\}$ 到达一致性点之前，$W_f$ 对其他代理不可见。这有效地建立了排序 $W_d(i) \\rightarrow W_f$ 对所有 $i$。\n-   CPU 操作：\n    1.  在轮询循环中重复从地址 $F$ 加载。将这些加载表示为 $L_f$。\n    2.  当加载 $L_f$ 返回值 $1$ 时，循环终止。\n    3.  循环之后，CPU 读取 $[B, B + N - 1]$ 处的缓冲区。将这些加载表示为 $L_b(j)$。\n-   假设：\n    1.  缓存一致性提供单写多读的一致性。从特定写入返回的读取意味着该写入是可见的。\n    2.  在没有显式排序指令的情况下，CPU 可以将加载与其他加载重排序，也可以将加载与更早的加载重排序。\n    3.  CPU 不执行任何显式缓存维护操作。\n-   问题：哪些 CPU 端的排序原语足以保证排序 $W_d(i) \\rightarrow W_f \\rightarrow L_f \\rightarrow L_b(j)$ 对所有相关的 $i, j$ 成立？\n\n**步骤 2：使用提取的已知条件进行验证**\n问题陈述描述了一个在弱序内存模型系统上，DMA 引擎（生产者）和 CPU（消费者）之间的经典生产者-消费者同步问题。\n-   **科学基础：** 该问题牢固地建立在计算机体系结构的既定原则之上，包括内存一致性模型（弱排序）、缓存一致性、DMA 和同步原语（内存屏障、获取/释放语义）。这些都是该领域的基础课题。\n-   **定义明确：** 该问题定义明确。它指明了生产者（DMA）和消费者（CPU）的行为和能力、内存子系统的属性，以及一个明确的目标：确保 CPU 正确观察到 DMA 写入的数据。问题要求的是在 CPU 端实现这一目标所需的充分条件。\n-   **客观性：** 语言技术性强、精确且无歧义。诸如“弱序内存模型”、“缓存一致”、“获取语义”和“内存屏障”等术语在计算机科学中都有标准的、正式的定义。\n-   **完整性与一致性：** 问题提供了所有必要的信息。关于 DMA 的标志写入 $W_f$ 在所有数据写入 $W_d(i)$ 全局可见之前不可见的保证是一条关键信息，它在生产者端模拟了一个“释放序列”（release sequence）。CPU 重排序加载的能力是需要解决的核心挑战。问题中没有矛盾之处。\n\n**步骤 3：结论与行动**\n问题陈述是有效的。这是一个在计算机体系结构领域定义明确、科学合理且清晰的问题。我将继续推导解决方案。\n\n### 解决方案的推导\n\n该问题要求建立一个事件的因果链，以确保 CPU 读取正确的数据。期望的顺序是 $W_d(i) \\rightarrow W_f \\rightarrow L_f \\rightarrow L_b(j)$。让我们逐个环节分析这个链条。\n\n1.  **$W_d(i) \\rightarrow W_f$ (生产者端排序)：** 问题陈述保证了这一点。它指出：“互连保持 DMA 引擎的程序顺序，即在所有之前的写入 $\\{W_d(i)\\}$ 到达一致性点之前，$W_f$ 对其他代理是不可见的。” 这意味着生产者的操作是正确排序的。用内存模型的行话来说，对标志的写入 $W_f$ 充当了一个“释放”(release) 操作，确保所有先前的内存操作（数据写入 $W_d(i)$）在释放操作本身变得可见之前都已完成并可见。\n\n2.  **$W_f \\rightarrow L_f$ (同步)：** CPU 轮询地址 $F$ 上的标志。当其加载操作 $L_f$ 返回值 $1$（由 $W_f$ 写入）时，缓存一致性协议保证了写入 $W_f$ 已经完成并且对 CPU 可见。这建立了从生产者到消费者的交接。\n\n3.  **$L_f \\rightarrow L_b(j)$ (消费者端排序)：** 这是问题的核心。CPU 具有弱序内存模型，并且可以将加载与其他加载重排序。在 CPU 的程序中：\n    ```\n    loop:\n      val = Load(F)\n      if val == 0 goto loop\n    // Exit loop\n    data = Load(B+j)\n    ```\n    CPU 可能会在从标志加载 $L_f$ 确定地返回值 $1$ *之前*，推测性地执行从缓冲区的加载 $L_b(j)$。如果发生这种重排序，$L_b(j)$ 可能会从缓冲区读取到陈旧的数据，从而打破因果链。为防止这种情况，CPU 端需要一个显式排序原语。该原语必须阻止后续的内存操作（如 $L_b(j)$）被重排序到观察到标志变化的关键加载 $L_f$ 之前执行。这就是**获取**(acquire)操作的定义。\n\n一个获取操作确保所有在程序顺序中出现在它*之后*的内存操作都将在获取操作完成*之后*执行。这与生产者的释放操作配对。释放操作保证了之前的写入是可见的；获取操作保证了在执行任何后续操作之前，这种可见性已经建立。\n\n因此，CPU 必须在看到 $F=1$ 之后、读取缓冲区之前执行一个获取操作。这可以通过两种主要方式实现：\n-   使用具有获取语义的加载（`load-acquire`）来读取标志 $F$。\n-   使用常规（松散）加载来读取标志 $F$，然后在退出循环时，执行一个获取栅栏（acquire fence）（也称为读内存屏障，或者更强地，一个全内存屏障）。\n\n### 选项评估\n\n**A. 在轮询循环中使用获取语义（对 $F$ 进行 load-acquire 操作）读取标志 $F$，或者等效地，在 $L_f$ 返回 $1$ 的那次迭代之后、任何 $L_b(j)$ 之前立即执行一个读内存屏障，且不使用其他栅栏。假设 DMA 仅在所有 $W_d(i)$ 在一致性点可见之后才发出 $W_f$。**\n\n该选项提出了两种方法，两者都实现了必要的获取语义。\n-   **对 F 的 load-acquire：** 对 $F$ 执行 `load-acquire` 可确保任何后续的内存操作，包括缓冲区的加载 $L_b(j)$，不能被重排序到此加载之前发生。这正确地强制了 $L_f \\rightarrow L_b(j)$ 的顺序。\n-   **读内存屏障：** 在循环之后（即在 $L_f$ 返回 1 之后）和缓冲区加载 $L_b(j)$ 之前放置一个读内存屏障（一个获取栅栏）也强制了所需的顺序。该屏障阻止后续的加载相对于之前的加载进行重排序。\n两种方法都正确地建立了与生产者的类释放行为配对所需的消费者端排序。\n**结论：正确。**\n\n**B. 在进入轮询循环之前执行一次全内存屏障；此后对标志和缓冲区都使用松散加载（relaxed load）。**\n\n内存屏障对其在程序流中之前出现的操作和之后出现的操作进行排序。将屏障放在轮询循环*之前*并不能阻止屏障*之后*代码内部的操作重排序。弱序 CPU 仍然可以自由地将来自缓冲区的松散加载 $L_b(j)$ 重排序到在来自标志的松散加载 $L_f$ 之前执行。屏障的位置错误，无法强制执行 $L_f \\rightarrow L_b(j)$ 排序。\n**结论：不正确。**\n\n**C. 仅依赖缓存一致性以及 DMA 最后写入标志这一事实；将所有 CPU 加载都作为无栅栏的松散加载（relaxed load）执行。**\n\n这是在弱序系统上会失败的天真方法。缓存一致性保证了写入最终会被传播，并且读取会看到一个一致的值，但它并不对*不同*内存位置（如 $F$ 和 $B$）的读取强加排序。问题明确指出“CPU 可以将加载与其他加载重排序”。没有栅栏或获取语义，加载 $L_b(j)$ 可能会被重排序到最终的 $L_f$ 之前，导致读取到陈旧数据。\n**结论：不正确。**\n\n**D. 当 CPU 稍后通过向 $F$ 写入 $0$ 来清除标志以供重用时，在那时对 $F$ 使用存储-释放（store-release）操作；在读取 $F$ 的前后不需要进行排序。**\n\n该选项涉及一个操作（清除标志），该操作发生在关键数据读取完成*之后*很久。`store-release` 对其*之前*的内存操作与该存储本身进行排序。它对先前的加载（$L_f$ 和 $L_b(j)$）的排序没有影响。排序问题必须在读取时解决，而不是通过后来的、不相关的写入来追溯解决。\n**结论：不正确。**\n\n**E. 在轮询循环观察到 $F = 1$ 之后，在任何 $L_b(j)$ 之前执行一个全内存屏障，然后使用松散加载（relaxed load）读取缓冲区。**\n\n全内存屏障是最强的排序原语。它阻止任何先前的内存操作与任何后续的内存操作之间发生重排序。通过将其放置在轮询循环之后（在 $L_f$ 返回 1 之后）和缓冲区读取（$L_b(j)$）之前，它强制要求所有 $L_b(j)$ 必须在 $L_f$ 之后发生。这提供了获取语义（阻止后续操作上移）以及释放语义（阻止先前操作下移）。这里需要的是获取语义，所以全内存屏障是足够的。这是一个正确但可能比必要条件更强的解决方案。\n**结论：正确。**", "answer": "$$\\boxed{AE}$$", "id": "3670422"}]}