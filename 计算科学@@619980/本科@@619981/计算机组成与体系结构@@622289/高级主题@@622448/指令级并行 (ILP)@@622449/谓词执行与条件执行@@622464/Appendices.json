{"hands_on_practices": [{"introduction": "要精通条件执行，首先必须量化其与传统分支相比的性能优势。本练习将指导你推导出一个数学模型，用于确定条件执行在何种条件下优于分支预测。通过构建这个基于每指令周期数（$CPI$）的分析框架，你将能够从根本上理解这两种控制流机制之间的核心性能权衡。[@problem_id:3667908]", "problem": "考虑一个流水线处理器，它通过谓词执行或控制流分支来实现条件执行。单个程序区域由两个互斥的块组成，一个“真”块和一个“假”块。设条件评估为真的概率为 $p$，评估为假的概率为 $1-p$。在此条件区域之外，程序达到一个基础的每指令周期数 (CPI)，记为 $CPI_0$，这是程序所有其他部分对每条退役指令贡献的期望周期数。\n\n在谓词执行下，假设有一个理想的作废机制：谓词评估为假的指令在消耗执行资源之前被置为无效，因此它们贡献的周期数可以忽略不计。然而，谓词评估为真的谓词指令可能会因谓词评估或保护而产生开销，这包含在它们的执行成本中。设 $C_T$ 表示当其谓词为真时“真”块贡献的平均周期数，设 $C_F$ 表示当其谓词为真时“假”块贡献的平均周期数。所有成本都是非负的，并且在动态实例中保持稳定。\n\n在基于分支的实现下，假设有一个动态分支预测器，其准确率为 $a$，每次误预测的惩罚为 $M$ 个周期。设 $q = 1-a$ 表示误预测率。当预测器正确且分支被解析而没有惩罚时，如果条件为真，执行的块贡献 $B_T$ 个周期；如果条件为假，则贡献 $B_F$ 个周期。所有成本都是非负的，并且在动态实例中保持稳定。\n\n从基本定义出发，即一个区域贡献的期望周期数是所有事件的概率与其周期成本乘积的总和，并且每指令周期数 (CPI) 是每条退役指令的期望周期数，请执行以下操作：\n\n1. 推导在谓词执行下程序CPI的表达式，用 $CPI_0$、$p$、$C_T$ 和 $C_F$ 表示。\n2. 推导在分支执行下程序CPI的表达式，用 $CPI_0$、$p$、$B_T$、$B_F$ 和 $qM$ 表示。\n3. 通过令两个CPI表达式相等，求解使两个CPI相等的临界误预测率 $q^{\\star}$。这个 $q^{\\star}$ 将参数空间划分为几个区域，在其中谓词执行相比分支执行能降低CPI，或分支执行更优。\n\n将你的最终答案表示为关于 $p$、$C_T$、$C_F$、$B_T$、$B_F$ 和 $M$ 的单个闭式解析表达式 $q^{\\star}$。不需要数值，也无需四舍五入。最终答案必须是单个无单位的表达式。", "solution": "让我们将在谓词执行下条件区域的期望周期成本表示为 $E_{pred}$，在分支执行下表示为 $E_{branch}$。\n\n1. 谓词执行下CPI的推导\n\n在谓词执行下，“真”和“假”指令块都会被取指，但只有其谓词为真的块中的指令才会被执行。根据问题陈述，谓词为假的块中的指令会被作废，贡献的周期数可以忽略不计。总周期成本由实际执行的路径决定。\n\n两个互斥的事件是：\n- 条件为真，发生概率为 $p$。在这种情况下，“真”块执行，贡献 $C_T$ 个周期。“假”块被作废，贡献 $0$ 个周期。\n- 条件为假，发生概率为 $1-p$。在这种情况下，“假”块执行，贡献 $C_F$ 个周期。“真”块被作废，贡献 $0$ 个周期。\n\n该区域的期望周期成本 $E_{pred}$ 是每个事件的概率与其相应周期成本乘积的总和：\n$$E_{pred} = p \\cdot C_T + (1-p) \\cdot C_F$$\n\n在谓词执行下程序的总CPI，$CPI_{predication}$，是基础CPI与该区域期望周期贡献的总和。\n$$CPI_{predication} = CPI_0 + p C_T + (1-p) C_F$$\n\n2. 分支执行下CPI的推导\n\n在基于分支的实现下，一条分支指令将控制流导向“真”块或“假”块。总周期成本是两个组成部分的总和：执行正确路径的周期数和由分支误预测引起的惩罚周期数。\n\n首先，让我们确定路径执行的期望周期成本，不考虑任何惩罚。\n- 以概率 $p$，“真”路径被采用，成本为 $B_T$ 个周期。\n- 以概率 $1-p$，“假”路径被采用，成本为 $B_F$ 个周期。\n期望的路径执行成本 $E_{path}$ 是：\n$$E_{path} = p \\cdot B_T + (1-p) \\cdot B_F$$\n\n其次，让我们确定由分支误预测惩罚产生的期望周期成本。分支预测器的误预测率为 $q$。每次误预测会产生 $M$ 个周期的惩罚。每个分支的期望误预测惩罚 $E_{penalty}$ 是误预测率和惩罚成本的乘积：\n$$E_{penalty} = q \\cdot M$$\n\n在分支执行下该区域的总期望周期成本 $E_{branch}$ 是期望路径执行成本和期望惩罚成本的总和。\n$$E_{branch} = E_{path} + E_{penalty} = p B_T + (1-p) B_F + qM$$\n\n因此，在分支执行下程序的总CPI，$CPI_{branching}$，是：\n$$CPI_{branching} = CPI_0 + p B_T + (1-p) B_F + qM$$\n\n3. 求解临界误预测率 $q^{\\star}$\n\n临界误预测率 $q^{\\star}$ 是使两种方案性能相同的 $q$ 值。这发生在 $CPI_{predication} = CPI_{branching}$ 时。\n\n$$CPI_0 + p C_T + (1-p) C_F = CPI_0 + p B_T + (1-p) B_F + q^{\\star}M$$\n\n基础的 $CPI_0$ 项出现在等式两边，可以消掉。这证实了临界点仅取决于条件区域本身的特性。\n\n$$p C_T + (1-p) C_F = p B_T + (1-p) B_F + q^{\\star}M$$\n\n现在，我们通过分离 $q^{\\star}M$ 项来求解 $q^{\\star}$：\n$$q^{\\star}M = p C_T + (1-p) C_F - (p B_T + (1-p) B_F)$$\n\n为了简化，我们可以按 $p$ 和 $(1-p)$ 对各项进行分组：\n$$q^{\\star}M = (p C_T - p B_T) + ((1-p) C_F - (1-p) B_F)$$\n$$q^{\\star}M = p(C_T - B_T) + (1-p)(C_F - B_F)$$\n\n最后，我们除以误预测惩罚 $M$ 以获得 $q^{\\star}$ 的表达式：\n$$q^{\\star} = \\frac{p(C_T - B_T) + (1-p)(C_F - B_F)}{M}$$\n\n这个表达式表示了谓词执行和基于分支的控制流的期望周期成本相等时的分支误预测率。如果实际误预测率 $q$ 大于 $q^{\\star}$，则谓词执行更有效率。如果 $q$ 小于 $q^{\\star}$，则分支执行更有效率。", "answer": "$$ \\boxed{\\frac{p(C_T - B_T) + (1-p)(C_F - B_F)}{M}} $$", "id": "3667908"}, {"introduction": "在利用条件执行进行编译器优化（如“if-conversion”）时，保证程序的正确性至关重要。本练习聚焦于一个关键的正确性问题：如何在使用条件执行指令时正确地维护像栈指针（$SP$）这样的体系结构状态。通过分析这个问题，你将深入理解条件执行的精确语义，特别是为何必须使用锁存的谓词值来确保操作的配对平衡。[@problem_id:3667887]", "problem": "考虑一个支持静态谓词执行（static predication）的指令集架构（ISA）：每条指令都与一个布尔谓词相关联，当该谓词为假时，指令不会产生任何架构可见的效应。该机器使用一个向下增长的栈，栈指针为 $SP$，字长为 $w$。对于一个值 $v$，入栈（push）和出栈（pop）的语义定义如下：入栈操作先执行 $SP := SP - w$，然后执行 $\\mathrm{Mem}[SP] := v$；出栈操作先执行 $v := \\mathrm{Mem}[SP]$，然后执行 $SP := SP + w$。\n\n一个控制相关区域使用谓词执行技术进行了if转换。在进入该区域之前，会计算一个布尔条件 $C$。设 $p$ 表示在区域入口处捕获的 $C$ 的值，并存储在一个谓词寄存器中。在区域内部，一个指令序列在进入 $C$ 为真的路径时，通过一个带谓词的入栈操作来保存一个寄存器，并在重汇合点通过一个带谓词的出栈操作来恢复它。$C$ 为假的路径执行替代的计算。在该区域内，除了入栈和出栈指令外，没有其他指令会写入 $SP$。然而，任一路径中的计算都可能修改用于计算 $C$ 的寄存器和内存，因此稍后在该区域内重新计算 $C$ 可能会得到一个与 $p$ 不同的布尔值。\n\n在重汇合点的正确性要求是：对于所有初始机器状态和 $C$ 的两种结果，由带谓词的入栈和出栈操作引起的栈指针净变化，必须精确地为零（相对于其在区域入口处的值）。\n\n在这些条件下，哪个选项能确保栈指针的正确性？\n\nA. 将入栈操作的谓词设为 $p$，真路径计算的谓词设为 $p$，假路径计算的谓词设为 $\\neg p$，并在出栈点重新计算 $C$ 来定义出栈谓词 $q := C$；使用 $q$ 执行出栈操作。\n\nB. 将入栈操作的谓词设为 $p$，真路径计算的谓词设为 $p$，假路径计算的谓词设为 $\\neg p$，并对出栈操作使用相同的锁存谓词 $p$（即 $q := p$），而不重新计算 $C$。\n\nC. 将入栈操作的谓词设为 $p$，出栈操作的谓词设为 $\\neg p$，以便每个路径恰好执行这两个操作中的一个。\n\nD. 将入栈操作的谓词设为 $p$，但使出栈操作无条件执行（无谓词），以强制两条路径通过平衡的操作数在重汇合点汇合。", "solution": "设 $SP_{entry}$ 是进入谓词执行区域时栈指针的值。设 $SP_{exit}$ 是在重汇合点（在带谓词的入栈和出栈指令之后）栈指针的值。正确性要求是净变化 $\\Delta SP = SP_{exit} - SP_{entry}$ 必须等于 $0$。这必须对谓词 $p$ 的两种可能值（真或假）都成立。\n\n唯一修改栈指针 $SP$ 的指令是带谓词的入栈和带谓词的出栈。\n- 如果一条 `push` 指令被执行（其谓词为真），它会使 $SP$ 改变 $-w$。\n- 如果一条 `pop` 指令被执行（其谓词为真），它会使 $SP$ 改变 $+w$。\n- 如果一条指令的谓词为假，它对 $SP$ 没有影响，所以变化为 $0$。\n\n问题陈述中，入栈与“$C$为真的路径”相关联。这意味着 `push` 指令应以 $p$（捕获的 $C$ 的值）为谓词。我们用 $P_{push}$ 表示 `push` 的谓词，用 $P_{pop}$ 表示 `pop` 的谓词。根据问题描述，自然的选择是 $P_{push} = p$。\n\n我们必须分析初始条件 $C$ 的两种可能结果，这被捕获在 $p$ 中。\n\n**情况 1：$p$ 为真。**\n- `push` 以 $p$ 为谓词。因为 $p$ 为真，所以执行入栈操作。\n- `push` 导致的 $SP$ 变化为 $\\Delta SP_{push} = -w$。\n- 为了满足正确性要求 $\\Delta SP = 0$，`pop` 带来的变化必须是 $\\Delta SP_{pop} = +w$。\n- 为了让 `pop` 使 $SP$ 增加 $+w$，它必须被执行。这意味着它的谓词 $P_{pop}$ 必须为真。\n\n**情况 2：$p$ 为假。**\n- `push` 以 $p$ 为谓词。因为 $p$ 为假，所以不执行入栈操作。\n- `push` 导致的 $SP$ 变化为 $\\Delta SP_{push} = 0$。\n- 为了满足正确性要求 $\\Delta SP = 0$，`pop` 带来的变化也必须是 $\\Delta SP_{pop} = 0$。\n- 为了让 `pop` 使 $SP$ 增加 $0$，它必须不被执行。这意味着它的谓词 $P_{pop}$ 必须为假。\n\n总之，为了保证栈指针的正确性，一次 `push` 必须被一次 `pop`完美抵消。`pop` 指令必须当且仅当 `push` 指令被执行时才执行。这要求 `pop` 的谓词 $P_{pop}$ 在逻辑上等价于 `push` 的谓词 $P_{push}$。由于 $P_{push}$ 基于入口时的条件 $p$，因此必须有 $P_{pop} = p$。必须对两个指令都使用最初锁存的谓词 $p$ 的值。\n\n**逐项分析选项**\n\n**A. 将入栈操作的谓词设为 $p$，真路径计算的谓词设为 $p$，假路径计算的谓词设为 $\\neg p$，并在出栈点重新计算 $C$ 来定义出栈谓词 $q := C$；使用 $q$ 执行出栈操作。**\n- 在此方案中，$P_{push} = p$ 且 $P_{pop} = q$，其中 $q$ 是 $C$ 的重新计算值。\n- 问题明确指出 $q \\neq p$ 是可能的。\n- 让我们考虑一种情况：$p$ 为真，但由于真路径计算的副作用，重新计算的条件 $q$ 为假。\n  - 因为 $p$ 为真，`push` 执行：$\\Delta SP_1 = -w$。\n  - 因为 $q$ 为假，`pop` 不执行：$\\Delta SP_2 = 0$。\n  - 总变化为 $\\Delta SP = -w + 0 = -w \\neq 0$。栈不平衡。\n- 此选项违反了正确性要求。\n- **结论：不正确。**\n\n**B. 将入栈操作的谓词设为 $p$，真路径计算的谓词设为 $p$，假路径计算的谓词设为 $\\neg p$，并对出栈操作使用相同的锁存谓词 $p$（即 $q := p$），而不重新计算 $C$。**\n- 在此方案中，$P_{push} = p$ 且 $P_{pop} = p$。\n- **情况 1：$p$ 为真。**\n  - `push` 执行：$\\Delta SP_1 = -w$。\n  - `pop` 执行：$\\Delta SP_2 = +w$。\n  - 总变化为 $\\Delta SP = -w + w = 0$。这是正确的。\n- **情况 2：$p$ 为假。**\n  - `push` 不执行：$\\Delta SP_1 = 0$。\n  - `pop` 不执行：$\\Delta SP_2 = 0$。\n  - 总变化为 $\\Delta SP = 0 + 0 = 0$。这是正确的。\n- 此选项对 $C$ 的两种结果都满足正确性要求。\n- **结论：正确。**\n\n**C. 将入栈操作的谓词设为 $p$，出栈操作的谓词设为 $\\neg p$，以便每个路径恰好执行这两个操作中的一个。**\n- 在此方案中，$P_{push} = p$ 且 $P_{pop} = \\neg p$。\n- **情况 1：$p$ 为真。**\n  - `push` 执行：$\\Delta SP_1 = -w$。\n  - `pop` 的谓词 $\\neg p$ 为假，所以 `pop` 不执行：$\\Delta SP_2 = 0$。\n  - 总变化为 $\\Delta SP = -w + 0 = -w \\neq 0$。栈不平衡。\n- **情况 2：$p$ 为假。**\n  - `push` 不执行：$\\Delta SP_1 = 0$。\n  - `pop` 的谓词 $\\neg p$ 为真，所以 `pop` 执行：$\\Delta SP_2 = +w$。\n  - 总变化为 $\\Delta SP = 0 + w = +w \\neq 0$。栈不平衡。\n- 此选项保证在 $C$ 的两种结果下栈都会失衡。在假路径上，会在没有相应 `push` 的情况下执行 `pop`，这是一个严重的栈损坏错误。\n- **结论：不正确。**\n\n**D. 将入栈操作的谓词设为 $p$，但使出栈操作无条件执行（无谓词），以强制两条路径通过平衡的操作数在重汇合点汇合。**\n- “无条件”意味着谓词始终为真。所以，$P_{push} = p$ 且 $P_{pop} = \\text{true}$。\n- **情况 1：$p$ 为真。**\n  - `push` 执行：$\\Delta SP_1 = -w$。\n  - `pop` 执行：$\\Delta SP_2 = +w$。\n  - 总变化为 $\\Delta SP = -w + w = 0$。这种情况有效。\n- **情况 2：$p$ 为假。**\n  - `push` 不执行：$\\Delta SP_1 = 0$。\n  - `pop` 执行：$\\Delta SP_2 = +w$。\n  - 总变化为 $\\Delta SP = 0 + w = +w \\neq 0$。栈不平衡。\n- 当原始条件为假时，此选项会失败，因为它执行了一次 `pop` 而没有相应的 `push`。\n- **结论：不正确。**", "answer": "$$\\boxed{B}$$", "id": "3667887"}, {"introduction": "理论模型和实际性能之间有时存在差距，尤其是在现代并行处理器中。本练习将把你带入图形处理器（GPU）的单指令多线程（SIMT）执行世界，探讨一个反直觉的场景。在这里，旨在避免分支分化的条件执行，反而可能因其对内存系统效率的负面影响而导致性能下降，这揭示了性能分析必须考虑整个系统环境的重要性。[@problem_id:3667910]", "problem": "一个采用单指令多线程 (SIMT) 执行模型的图形处理单元 (GPU) 执行大小为 $W = 32$ 的线程束 (warp)。每个线程的全局内存加载操作会获取一个大小为 $s = 4$ 字节的字。内存子系统会合并加载，使得如果一个 warp 中的 $n$ 个线程访问位于单个大小为 $T = 128$ 字节的对齐缓存行内的 $n$ 个连续的字，硬件会恰好发起一次大小为 $T$ 字节的事务。如果一条指令中的活跃线程访问了多个不相交的 $128$ 字节区域，硬件会为每个区域发起一次事务。将一条内存指令的有效带宽利用率定义为算法上有用的字节数与相应内存事务传输的总字节数之比。\n\n考虑一个数据依赖循环，在每个 warp 的第一次迭代 $j = 1$ 中，恰好有 $W/2$ 个线程需要来自数组 $X$ 的数据，另外 $W/2$ 个线程需要来自数组 $Y$ 的数据。这 $W/2$ 个线程对 $X$ 的访问是连续的，并且位于一个对齐的 $128$ 字节区域内；另外 $W/2$ 个线程对 $Y$ 的访问也是连续的，并且位于一个与 $X$ 区域不相交的对齐的 $128$ 字节区域内。所有选择 $X$ 的线程在 $j = 1$ 之后终止并退出。选择 $Y$ 的线程继续进行接下来的 $K - 1$ 次迭代 ($j = 2, 3, \\dots, K$)，并且在每次迭代中，它们对 $Y$ 的访问保持连续且位于一个对齐的 $128$ 字节区域内。\n\n考虑两种内核实现：\n\n- 实现 $\\mathcal{P}$ (通过 if-转换和推测性双重加载进行谓词执行)：编译器对条件进行 if-转换，为每个线程的每次迭代发出两个无条件的全局加载指令，一个从 $X$ 加载，一个从 $Y$ 加载，然后使用谓词传送指令，根据线程的谓词选择所需的值。即使线程的谓词指示该值不会被使用，两次加载也都会访问全局内存。这种方法避免了发散的控制流，但可能会执行冗余的内存操作。\n\n- 实现 $\\mathcal{B}$ (带有提前退出的发散分支)：内核根据谓词进行分支。在 $j = 1$ 时，warp 串行地为需要 $X$ 的 $W/2$ 个线程执行 $X$ 路径，为需要 $Y$ 的 $W/2$ 个线程执行 $Y$ 路径。走 $X$ 路径的线程退出，不参与后续的迭代。对于 $j = 2, \\dots, K$，warp 只为剩余的 $W/2$ 个线程执行 $Y$ 路径。\n\n假设没有其他瓶颈 (例如，延迟隐藏、占用率限制)，并且地址如前所述是可完美合并的。哪个陈述正确地描述了一个反例，其中与带有提前退出的发散分支相比，谓词执行未能充分利用内存带宽，并通过量化 $K$ 次迭代中 $128$ 字节事务的数量和有效带宽利用率来证明？\n\nA. 在 $K$ 次迭代中，实现 $\\mathcal{P}$ 发起 $2K$ 次事务 (每次迭代有两个完全合并的数据流，每个传输 $T$ 字节)，而实现 $\\mathcal{B}$ 发起 $K + 1$ 次事务 (在 $j = 1$ 时为两个半 warp 发起两次事务，然后在后续每次迭代中为持续执行的半 warp 发起一次事务)。由于在 $j = 1$ 之后，算法上只需要 $Y$ 的数据，因此对于较大的 $K$，$\\mathcal{P}$ 传输的字节数大约是 $\\mathcal{B}$ 的两倍，导致有效带宽利用率较低。\n\nB. 两种实现方式在 $K$ 次迭代中发起的事务数量相同，因为 SIMT 再收敛使得谓词执行和分支等效；因此，没有带宽差异。\n\nC. 实现 $\\mathcal{P}$ 发起的事务比 $\\mathcal{B}$ 少，因为谓词执行保留了所有 $W$ 个活跃线程并最大化了合并，而分支将活动性减半并破坏了合并，使得谓词执行在带宽利用率上绝对优越。\n\nD. 实现 $\\mathcal{B}$ 发起的事务严格多于 $\\mathcal{P}$，因为提前退出降低了 warp 占用率并阻止了合并；因此，在这种情况下，谓词执行总是比分支实现更高的有效带宽利用率。", "solution": "让我们分析两种实现在 $K$ 次迭代中的内存流量。给定的常量是 $W=32$，$s=4$ 字节，和 $T=128$ 字节。\n\n首先，我们确定在 $K$ 次迭代中传输的算法上有用的总字节数。\n- 在迭代 $j=1$ 中：$W/2 = 16$ 个线程需要来自 $X$ 的数据，另外 $W/2 = 16$ 个线程需要来自 $Y$ 的数据。有用的数据大小是 $(16 \\times s) + (16 \\times s) = (16 \\times 4) + (16 \\times 4) = 64 + 64 = 128$ 字节。\n- 在随后的 $K-1$ 次迭代中（$j=2, \\dots, K$）：剩下的 $W/2=16$ 个线程需要来自 $Y$ 的数据。每次迭代有用的数据大小是 $16 \\times s = 16 \\times 4 = 64$ 字节。\n- $K$ 次迭代的总有用字节数 = $128 \\text{ 字节 (来自 } j=1) + (K-1) \\times 64 \\text{ 字节} = 128 + 64K - 64 = 64K + 64 = 64(K+1)$ 字节。\n\n接下来，我们分析每种实现。\n\n**实现 $\\mathcal{P}$ (谓词执行)**\n在此模型中，条件逻辑被转换为谓词执行。warp 中的所有 $W=32$ 个线程在所有 $K$ 次迭代中都保持活跃。在每次迭代中，每个线程都推测性地执行从数组 $X$ 和 $Y$ 的加载。\n- **每次迭代的内存访问**：\n    1.  从 $X$ 加载：所有 $W=32$ 个线程都参与。假设它们的地址是连续的 (例如，从 `X[base + threadIdx]` 加载)，它们访问 $32 \\times s = 32 \\times 4 = 128$ 字节。根据合并规则，这恰好填满一个对齐的区域，导致一次大小为 $T=128$ 字节的内存事务。\n    2.  从 $Y$ 加载：类似地，所有 $W=32$ 个线程都参与，导致第二次大小为 $T=128$ 字节的内存事务。\n- **$\\mathcal{P}$ 在 $K$ 次迭代中的总计**：\n    - 每次迭代的事务数 = $2$。\n    - 总事务数 = $2 \\times K = 2K$。\n    - 传输的总字节数 = $2K \\times T = 2K \\times 128 = 256K$ 字节。\n- **$\\mathcal{P}$ 的有效带宽利用率**：\n    $$ U_{\\mathcal{P}} = \\frac{\\text{总有用字节数}}{\\text{传输的总字节数}} = \\frac{64(K+1)}{256K} = \\frac{K+1}{4K} $$\n\n**实现 $\\mathcal{B}$ (发散分支)**\n在此模型中，warp 根据条件分裂。\n- **迭代 $j=1$**：\n    - warp 分裂成两组，每组 $W/2=16$ 个线程。硬件串行执行这两条路径。\n    - 路径 1 (访问 $X$)：$16$ 个线程从 $X$ 访问连续数据。总数据大小为 $16 \\times s = 64$ 字节。由于这些访问位于单个对齐的 $128$ 字节区域内，它们触发一次大小为 $T=128$ 字节的事务。\n    - 路径 2 (访问 $Y$)：路径 1 完成后，另外 $16$ 个线程从 $Y$ 访问连续数据。这同样触发一次大小为 $T=128$ 字节的事务。\n    - 在 $j=1$ 时的总事务数：$1+1=2$。传输的总字节数：$2 \\times T = 256$ 字节。\n    - 来自路径 1 的 $16$ 个线程随后退出并永久变为非活跃状态。\n- **迭代 $j=2, \\dots, K$**：\n    - 在剩下的 $K-1$ 次迭代中，warp 只包含 $16$ 个活跃线程，所有这些线程都走 $Y$ 路径。不存在发散。\n    - 在每次迭代中，这 $16$ 个线程连续地访问 $Y$。和之前一样，这需要 $16 \\times s = 64$ 字节的数据，位于一个 $128$ 字节的区域内，触发一次大小为 $T=128$ 字节的事务。\n    - 这 $K-1$ 次迭代的总事务数 = $K-1$。传输的总字节数：$(K-1) \\times T = 128(K-1)$ 字节。\n- **$\\mathcal{B}$ 在 $K$ 次迭代中的总计**：\n    - 总事务数 = $2 \\text{ (来自 } j=1) + (K-1) \\text{ (来自 } j1) = K+1$。\n    - 传输的总字节数 = $2T + (K-1)T = (K+1)T = 128(K+1)$ 字节。\n- **$\\mathcal{B}$ 的有效带宽利用率**：\n    $$ U_{\\mathcal{B}} = \\frac{\\text{总有用字节数}}{\\text{传输的总字节数}} = \\frac{64(K+1)}{128(K+1)} = \\frac{64}{128} = \\frac{1}{2} $$\n\n**比较**\n当 $U_{\\mathcal{P}}  U_{\\mathcal{B}}$ 时，实现 $\\mathcal{P}$ 相对于 $\\mathcal{B}$ 未充分利用内存带宽。\n$$ \\frac{K+1}{4K}  \\frac{1}{2} $$\n两边乘以 $4K$ (因为 $K \\ge 1$，所以 $4K$ 是正数)：\n$$ K+1  2K $$\n$$ 1  K $$\n因此，对于任何迭代次数 $K > 1$，谓词执行实现的有效带宽利用率都较低。对于较大的 $K$，$U_{\\mathcal{P}} \\approx 1/4$ 而 $U_{\\mathcal{B}} = 1/2$。传输总字节数的比率是 $\\frac{256K}{128(K+1)} = \\frac{2K}{K+1}$，当 $K \\to \\infty$ 时，该比值接近 $2$。这意味着对于长时间运行的循环，谓词执行传输的数据量大约是分支实现的两倍。问题中描述的场景，对于任何 $K>1$，都可作为所要求的反例。\n\n### 逐项分析选项\n\n**A. 在 $K$ 次迭代中，实现 $\\mathcal{P}$ 发起 $2K$ 次事务 (每次迭代有两个完全合并的数据流，每个传输 $T$ 字节)，而实现 $\\mathcal{B}$ 发起 $K + 1$ 次事务 (在 $j = 1$ 时为两个半 warp 发起两次事务，然后在后续每次迭代中为持续执行的半 warp 发起一次事务)。由于在 $j = 1$ 之后，算法上只需要 $Y$ 的数据，因此对于较大的 $K$，$\\mathcal{P}$ 传输的字节数大约是 $\\mathcal{B}$ 的两倍，导致有效带宽利用率较低。**\n- $\\mathcal{P}$ 的事务计数为 $2K$，与我们的推导相符。\n- $\\mathcal{B}$ 的事务计数为 $K+1$，也与我们的推导相符。\n- 两种实现的事务计数理由都是准确的。\n- 对于较大的 $K$，$\\mathcal{P}$ 传输的字节数大约是 $\\mathcal{B}$ 的两倍的分析是正确的 ($\\lim_{K\\to\\infty} \\frac{2K}{K+1} = 2$)。\n- 这导致 $\\mathcal{P}$ 的有效带宽利用率较低的结论是正确的，如我们的比较 $U_{\\mathcal{P}}  U_{\\mathcal{B}}$ (对于 $K > 1$) 所示。\n- **结论**：正确。\n\n**B. 两种实现方式在 $K$ 次迭代中发起的事务数量相同，因为 SIMT 再收敛使得谓词执行和分支等效；因此，没有带宽差异。**\n- 事务数量相同 ($2K = K+1$) 的说法对于任何 $K \\ne 1$ 都是错误的。\n- 推理是有缺陷的。实现 $\\mathcal{B}$ 的关键特性是半数线程的*提前退出*，而不是再收敛。这些线程不会在循环内再收敛；它们完全停止参与。这使得两种执行策略在执行的总工作量方面是不等效的。\n- **结论**：不正确。\n\n**C. 实现 $\\mathcal{P}$ 发起的事务比 $\\mathcal{B}$ 少，因为谓词执行保留了所有 $W$ 个活跃线程并最大化了合并，而分支将活动性减半并破坏了合并，使得谓词执行在带宽利用率上绝对优越。**\n- $\\mathcal{P}$ 发起的事务比 $\\mathcal{B}$ 少 ($2K  K+1$) 的说法对于 $K \\ge 1$ 是错误的。\n- 分支“破坏了合并”的推理是不正确的。在这个问题中，对于实现 $\\mathcal{B}$ 中的活跃线程子组，合并仍然完美发生；它只是一个覆盖半个 warp 请求而不是整个 warp 请求的事务。\n- 谓词执行在带宽利用率上更优的结论与我们对 $K > 1$ 的发现相反。\n- **结论**：不正确。\n\n**D. 实现 $\\mathcal{B}$ 发起的事务严格多于 $\\mathcal{P}$，因为提前退出降低了 warp 占用率并阻止了合并；因此，在这种情况下，谓词执行总是比分支实现更高的有效带宽利用率。**\n- $\\mathcal{B}$ 发起的事务比 $\\mathcal{P}$ 多 ($K+1 > 2K$) 的说法仅在 $K1$ 时成立，这是不可能的。对于任何有效的 $K \\ge 1$，这都是错误的。\n- 其理由重复了 C 中关于阻止合并的错误论断。\n- 谓词执行总是实现更高利用率的结论是错误的。\n- **结论**：不正确。", "answer": "$$\\boxed{A}$$", "id": "3667910"}]}