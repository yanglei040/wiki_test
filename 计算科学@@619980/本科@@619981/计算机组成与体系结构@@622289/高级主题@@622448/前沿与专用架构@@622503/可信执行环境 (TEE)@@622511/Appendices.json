{"hands_on_practices": [{"introduction": "在可信执行环境（TEE）中最常见的漏洞之一是源于数据依赖操作的侧信道泄漏。本练习将探讨一个典型案例：基于一个秘密值进行查表操作。通过该练习，你将学习如何识别泄漏点，并运用“恒定时间”编程原则提出基于软件的修复方案，同时估算其性能开销，这对于在安全区域（enclave）内处理敏感数据的开发者来说是一项基本技能。[@problem_id:3686131]", "problem": "一个程序在可信执行环境（TEE）中运行，例如英特尔软件防护扩展（SGX）安全区。攻击者控制操作系统，可以对共享缓存执行高精度计时和缓存观察攻击，例如 Prime+Probe (P+P)，但无法读取安全区内存。考虑一个大小为 $256\\,\\text{B}$ 的字节查找表 $T$，存储在单个 $4\\,\\text{KiB}$ 的页面中，该页面对齐且连续。代码根据一个秘密字节 $s$ 和一个公开字节 $p$ 计算输出字节 $y$，其过程为 $y \\leftarrow T[x]$，其中 $x \\leftarrow s \\oplus p$。该实现使用一个线性指令序列，没有基于 $x$ 的条件分支。\n\n假设中央处理器（CPU）有一个一级数据缓存（L1D）和一个一级指令缓存（L1I），每个缓存的缓存行大小为 $64\\,\\text{B}$，命中延迟为 $4$ 个周期。在稳态下，CPU每个周期最多可以执行 $2$ 次加载和最多 $2$ 次简单整数操作（例如，按位与和相等性测试）。你不能假设有特殊的密码学指令或向量扩展可用，也不能用代数重计算来替换表的语义；你必须保留查找表的语义。攻击者至少可以通过行粒度的 Prime+Probe 观察到在安全区执行期间访问了 $T$ 的哪些缓存行。\n\n基于微架构侧信道和常数时间编程的基本原理，哪个选项最能准确地识别此场景中的主要泄漏信道，提出一个在所述模型下能消除该信道的常数时间重写方法，并提供相对于朴素实现 $y \\leftarrow T[x]$ 的额外每次查找周期开销 $\\Delta C$ 的合理估计？\n\nA. 主要泄漏来自L1D，因为 $x$ 会在 $4$ 个缓存行（$256\\,\\text{B}$ 对应 $64\\,\\text{B}$ 的行）中进行选择，而由于是线性代码，L1I足迹与 $x$ 无关。一个常数时间的重写方法是按固定顺序扫描所有 $256$ 个条目，并通过掩码选择来计算 $y$：初始化 $r \\leftarrow 0$，然后对于从 $0$ 到 $255$ 的每个 $i$，通过对 $i$ 和 $x$ 进行常数时间相等性测试来计算一个掩码 $m_i \\in \\{0,255\\}$，并更新 $r \\leftarrow r \\,\\texttt{OR}\\, (T[i] \\,\\texttt{AND}\\, m_i)$，最后输出 $y \\leftarrow r$。数据缓存足迹与 $x$ 无关，指令流保持不变。考虑到每次迭代有 $1$ 次加载和大约 $3$ 次简单整数操作，以及所述的执行限制，一旦预热，循环吞吐量约为每个周期 $1$ 次迭代，产生大约 $256$ 个周期，而单次L1D命中约为 $4$ 个周期；因此 $\\Delta C \\approx 200$–$400$ 个周期/每次查找。\n\nB. 主要泄漏来自L1I，因为不同的 $x$ 值会导致为地址计算获取不同的指令字节。一个常数时间的重写方法是将查找展开成一个类似 switch 的代码布局，以便CPU平等地获取所有可能的指令块，使L1I足迹与 $x$ 无关，同时保留用于数据的单个索引加载。这产生的开销可以忽略不计，$\\Delta C \\approx 0$–$10$ 个周期。\n\nC. 主要泄漏来自L1D。一个常数时间的重写方法是为 $T$ 的所有 $4$ 个缓存行发出软件预取指令，然后执行单个索引加载 $T[x]$；因为这些行已被预取，行级足迹与 $x$ 无关。这消除了泄漏，且开销可以忽略不计，$\\Delta C \\approx 0$–$10$ 个周期。\n\nD. 主要泄漏来自L1D。一个常数时间的重写方法是在安全区初始化时一次性加载 $T$ 的 $4$ 个缓存行，并假设它们保持驻留；随后的查找可以使用原始的 $T[x]$ 而不产生泄漏，因为所有行都已在缓存中。这使得足迹与 $x$ 无关，并在此后产生 $\\Delta C \\approx 0$ 个周期的开销。\n\n选择唯一的最佳选项。", "solution": "我们从威胁模型和微架构的核心定义和经过充分检验的事实出发。\n\n首先，可信执行环境（TEE），如英特尔软件防护扩展（SGX），将安全区内存与特权软件隔离，但与不受信任的代码共享包括缓存在内的微架构资源。一个 Prime+Probe (P+P) 攻击者可以通过预填充缓存集，让安全区运行，然后探测驱逐情况，来推断安全区接触了哪些缓存集，从而推断出哪些缓存行。常数时间编程原则要求执行的指令序列和访问的内存地址序列都与秘密无关，这样计时和缓存足迹就不会编码依赖于秘密的信息。\n\n在给定的代码中，指令流被说明为线性的，没有基于 $x$ 的条件分支。因此，从程序计数器值到指令获取的映射与 $x$ 无关。从基本原理的角度来看，一级指令缓存（L1I）的获取是静态指令序列的函数；没有依赖于秘密的控制流，L1I足迹就不会随 $x$ 变化。相比之下，一级数据缓存（L1D）的访问包括从 $T[x]$ 加载，其中 $x$ 源于秘密 $s$。查找表 $T$ 的大小为 $256\\,\\text{B}$，组织为 $4$ 个 $64\\,\\text{B}$ 的缓存行。对于任何给定的 $x \\in \\{0,\\dots,255\\}$，访问 $T[x]$ 会精确地接触这 $4$ 个行中的一个，具体由 $x$ 的高 $\\log_2(256/64)=2$ 位决定。因此，朴素代码所接触的缓存行集合依赖于 $x$，这违反了常数时间要求，并使能够观察行级足迹的攻击者（例如，通过 Prime+Probe）至少能了解到访问了 $4$ 个行中的哪一个。在多次查找中，这种泄漏在密码学上下文中可以组合起来，导致部分或完整的密钥恢复。\n\n为了在所述约束（没有特殊的密码学或向量指令，并保留表查找的语义）下缓解这种泄漏，可以确保数据缓存足迹不依赖于 $x$。一个标准的常数时间模式是按固定顺序访问所有表项，并通过掩码选择所需的值，而不使用条件分支。具体来说，初始化 $r \\leftarrow 0$。对于每个 $i \\in \\{0,\\dots,255\\}$，使用对 $i$ 和 $x$ 的常数时间相等性测试（例如，通过算术运算，如果相等则产生 $255$，否则产生 $0$）来计算一个掩码 $m_i \\in \\{0,255\\}$，并更新 $r \\leftarrow r \\,\\texttt{OR}\\, (T[i] \\,\\texttt{AND}\\, m_i)$。最后，$r$ 等于 $T[x]$。因为循环无论 $x$ 为何值都以相同顺序接触每个 $T[i]$，所以数据地址集以及因此的缓存行足迹是恒定的。\n\n我们使用提供的微架构参数来估计开销 $\\Delta C$。在稳态下且L1D命中的情况下，每次迭代大约执行 $1$ 次从 $T[i]$ 的加载和大约 $3$ 次简单整数操作（产生 $m_i$ 的相等性测试、一次按位与和一次按位或）。CPU每个周期最多可以执行 $2$ 次加载和 $2$ 次简单整数操作。因此，循环体每次迭代大约有 $4$ 个微操作，一旦流水线充满，其吞吐量受限于接近每个周期 $1$ 次迭代，因为每次迭代的 $1$ 次加载和每个周期最多 $2$ 次整数操作可以在连续的迭代中重叠执行；只要迭代之间有足够的独立工作，L1D的 $4$ 周期命中延迟就可以被流水线技术隐藏，而这里确实存在这种情况，因为每次迭代读取不同的地址，数据依赖仅限于运行中的累加器。因此，扫描 $256$ 个条目大约需要 $256$ 个周期。相比之下，朴素查找在最佳情况下执行一次L1D命中，大约需要 $4$ 个周期，额外的整数操作工作可以忽略不计；因此，每次查找的额外开销是\n$$\n\\Delta C \\approx 256 - 4 \\approx 252 \\text{ cycles,}\n$$\n我们可以保守地将其限定在约 $200$–$400$ 个周期，以考虑循环开销、前端效应以及相等性掩码实现的差异。两个版本的指令流都是线性的，所以L1I的行为仍然与 $x$ 无关。\n\n现在我们分析每个选项。\n\n选项 A：它正确地将L1D识别为主要泄漏源，因为数据地址 $T[x]$ 依赖于 $x$；由于是线性指令序列，L1I足迹与 $x$ 无关。提议的常数时间重写方法——带掩码选择的完全线性扫描——确保了固定的内存访问模式，与 $x$ 无关，并保留了表的语义。开销估计是基于给定的执行限制的合理推断：$256$ 次迭代大约每次迭代 $1$ 个周期，而单次L1D命中约为 $4$ 个周期，得出 $\\Delta C$ 在几百个周期的量级。结论：正确。\n\n选项 B：它断言L1I是主要泄漏源，声称根据 $x$ 会获取不同的指令字节。对于线性代码且没有依赖于秘密的控制流，指令获取地址不依赖于 $x$；因此L1I足迹不是泄漏向量。此外，用类似 switch 的布局替换表并不能解决 $T[x]$ 是一个依赖于数据的加载这个核心问题；保留那个单一的索引加载会保留L1D的泄漏。可忽略的开销声明是无关紧要的，因为在所述威胁模型下，该缓解措施是无效的。结论：不正确。\n\n选项 C：它承认L1D泄漏，但提议对所有 $4$ 个行进行软件预取，然后执行依赖于数据的加载，以消除泄漏且开销可忽略。然而，预取指令是建议性的，可能会被忽略；问题明确指出了这一点，这意味着依赖预取来保证安全性不满足常数时间要求。如果预取被丢弃或如果争用导致行被驱逐，随后的依赖于数据的加载会再次产生依赖于秘密的足迹和计时。此外，即使预取被执行，代码仍然执行一个依赖于秘密的内存访问指令；一个健壮的常数时间准则会避免关键路径上任何依赖于秘密的内存地址。结论：不正确。\n\n选项 D：它建议在安全区初始化时加载 $4$ 个缓存行一次，并假设它们保持驻留，此后 $T[x]$ 是安全的。这违反了攻击模型：操作系统可以随时调度冲突的工作负载来驱逐缓存行，并且在调用之间甚至在有争用的调用内部都不能保证缓存驻留。在存在主动攻击者的情况下，安全性不能依赖于关于持久缓存驻留的假设。此外，即使行是驻留的，执行 $T[x]$ 仍然构成一次依赖于秘密的数据访问；虽然足迹可能保持在 $4$ 个行之内，但攻击者原则上仍然可以通过 Prime+Probe 观察到每次调用的接触情况。结论：不正确。\n\n因此，唯一一个正确识别泄漏源，在约束条件下提供了有效的常数时间重写方法，并以合理的理由估计了 $\\Delta C$ 的选项是选项A。", "answer": "$$\\boxed{A}$$", "id": "3686131"}, {"introduction": "本练习将带领我们从应用层代码深入到TEE、操作系统及CPU内存管理单元之间的交互层面。我们将分析一个假设但现实的场景，其中仅靠地址空间隔离并不足以保证安全。该练习揭示了共享且未标记的微体系结构资源，当与“大页”（huge pages）等性能优化特性结合时，会如何产生一个微妙但强大的侧信道，从而促使我们更全面地审视整个系统的安全状况。[@problem_id:3686081]", "problem": "一个在 $64$ 位系统上的可信执行环境（TEE）飞地使用分层分页和页表隔离：该飞地使用自己的控制寄存器 $CR3$ 和一个飞地特定的地址空间标识符（ASID），记为 $ASID_e$。处理器实现的转译后备缓冲区（TLB）条目由进程上下文标识符（PCID）或 ASID 标记，因此非飞地上下文的 TLB 条目不会用于飞地的地址翻译。在 $x86$-$64$ 架构上，内存管理单元（MMU）为 $4$ KB 的页面执行一个 $4$ 级页表的页表遍历：页映射表第 $4$ 级（PML$4$）、页目录指针表（PDPT）、页目录（PD）和页表（PT）。对于更大的页面大小 $P=2^m$，页表遍历会提前终止，并启用页面大小位，因此对于 $2$ MB 的页面（$m=21$），遍历在 PD 级别停止；对于 $1$ GB 的页面（$m=30$），遍历在 PDPT 级别停止。\n\n假设处理器具有微架构分页结构缓存，用于存储最近使用的分页结构条目（例如，缓存的 PML$4$E、PDPTE 和 PDE 条目）。这些分页结构缓存跨地址空间和核心共享，并且不由 ASID 标记。飞地外部的攻击者进程可以通过计时其自身地址空间中的地址翻译来预取和探测这些分页结构缓存。操作系统是不可信的，它控制页面分配以及飞地是接收小页面还是大页。飞地的目标是最小化通过基于翻译的微架构侧信道的信息泄漏，同时保持可接受的性能。\n\n从第一性原理出发，考虑以下事实：\n- 虚拟地址由页内偏移加上一系列在每个分页级别选择条目的索引组成。如果页面大小为 $P=2^m$，那么页内偏移会占用虚拟地址的 $m$ 个低位。\n- 对于一个 $4$ KB 的页面（$m=12$），页表遍历使用所有 $4$ 个级别（PML$4$/PDPT/PD/PT）。对于一个 $2$ MB 的页面（$m=21$），页表遍历使用 $3$ 个级别（PML$4$/PDPT/PD）。对于一个 $1$ GB 的页面（$m=30$），页表遍历使用 $2$ 个级别（PML$4$/PDPT）。\n- 当分页结构缓存是共享且未标记时，它们允许跨上下文的预取和探测攻击：如果攻击者预取了一个 PDE 或 PDPTE，那么任何命中该条目的飞地访问都将减少翻译延迟，攻击者可以通过统计学方法推断出这一点。\n\n构建并分析这样一个场景：飞地在一个大小为 $P=2^m$ 的单个大页内均匀地访问内存，而攻击者在共享的分页结构缓存中预取了相应的上层分页条目。推导 $m$ 的选择如何影响页错误（page faults）的频率（有利于减少来自操作系统的页错误侧信道）以及由于上层条目重用而导致的翻译级别侧信道的放大效应。基于此分析，选择关于是否应在飞地中允许大页的合理策略。\n\n在此模型下，哪项策略最为正确？\n\nA. 无条件允许大页；通过独立的 $CR3$ 和 $ASID_e$ 实现的页表隔离确保了隔离性，并且由于 TLB 是被标记的，分页结构缓存无法泄漏信息。\n\nB. 仅当处理器强制实施按飞地标记（per-enclave tagging）或在飞地进入和退出时完全刷新所有与翻译相关的微架构缓存（包括分页结构缓存）时，才允许使用大页；否则，禁止在飞地中使用大页。\n\nC. 禁止使用大页，因为它们会导致架构混叠（architectural aliasing），即同一个物理帧必须在飞地和非飞地上下文之间共享，即使 $CR3$ 和 $ASID_e$ 不同，这也会破坏隔离性。\n\nD. 允许使用大页，但在启动时随机化飞地的虚拟地址；仅靠随机化就能防止攻击者跨上下文预取相关的分页结构缓存条目。\n\nE. 允许大小不超过 $P \\le 2^{21}$ 的大页，但禁止 $P=2^{30}$ 的大页；$2$ MB 的页面是安全的，而 $1$ GB 的页面本质上是不安全的，这与翻译缓存的标记或刷新无关。", "solution": "本问题的核心在于区分两种不同类型的地址翻译缓存及其安全属性：由地址空间标识符（ASID）标记的转译后备缓冲区（TLB）和共享且未标记的微架构分页结构缓存。\n\n1.  **漏洞根源分析**：问题明确指出，TLB 条目由 ASID 标记，因此飞地（enclave）和非飞地上下文的翻译在 TLB 中是隔离的，不会直接产生跨域泄漏。然而，当发生 TLB 未命中时，处理器必须执行页表遍历，这会访问存储在内存中的页表条目（PML4E, PDPTE, PDE 等）。为了加速此过程，处理器会缓存这些中间条目，这些缓存被称为“分页结构缓存”。关键漏洞在于，这些缓存是**共享且未标记的**。这意味着一个拥有 $ASID_a$ 的攻击者进程可以预取（Prime）一个页表条目到缓存中，然后，如果飞地（拥有 $ASID_e$）的页表遍历访问了同一个缓存集，它可能会驱逐攻击者的条目。随后，攻击者可以通过探测（Probe）自己的翻译延迟来检测这次驱逐，从而推断出飞地访问了特定范围的虚拟地址。\n\n2.  **大页的放大效应**：大页（Huge Pages）显著加剧了这一漏洞。\n    *   对于 **$4$ KB 的小页**，一次页表遍历会访问所有层级的页表。泄漏是细粒度的，与单个页面访问相关。\n    *   对于 **$2$ MB 的大页**，页表遍历在页目录（PD）级别终止。这意味着整个 $2$ MB 虚拟地址空间内的*所有*内存访问，在发生页表遍历时，都会共享完全相同的上层页表条目（PML4E 和 PDPTE）以及同一个 PDE。因此，攻击者只需监控与该 PDE 对应的单个缓存位置，就能检测到飞地在整个 $2$ MB 区域内的*任何*活动。\n    *   对于 **$1$ GB 的大页**，情况更为严重，整个 $1$ GB 区域的活动都可由单个 PDPTE 的缓存状态反映出来。\n    大页将大量不同虚拟地址的访问活动“折叠”到一个单一、可被观测的微架构事件上，从而极大地放大了侧信道的信息带宽。\n\n3.  **策略评估**：一个稳健的安全策略必须解决根本漏洞或避免其放大因素。\n    *   **选项 A** 是不正确的。它错误地假设 TLB 隔离足以提供全面保护，忽略了未标记的分页结构缓存这一核心漏洞。\n    *   **选项 B** 是正确的。它提出了解决该漏洞的两种根本性方法：(1) 在硬件层面通过“按飞地标记”来隔离共享资源；或 (2) 在软件/微码层面，通过在进出飞地时刷新这些缓存来打破攻击链。它正确地断定，在缺乏这些有效缓解措施的情况下，由大页带来的放大风险过高，必须禁止在飞地中使用它们以保证安全。\n    *   **选项 C** 的推理是错误的。该漏洞是微架构层面的，与翻译元数据有关，而不是由于物理内存共享造成的架构级混叠。\n    *   **选项 D** 是不正确的。地址空间布局随机化（ASLR）对于控制页表的恶意操作系统无效，且由于上层页表条目数量少，攻击者仍可进行有效的探测。\n    *   **选项 E** 是不正确的。它做出了一个任意的区分。虽然 $1$ GB 页面的放大效应更强，但 $2$ MB 页面同样存在根本性的漏洞，并非“安全”。安全策略不应容忍已知的漏洞。\n\n因此，唯一正确且审慎的策略是选项 B。", "answer": "$$\\boxed{B}$$", "id": "3686081"}, {"introduction": "在探讨了软件层面的漏洞和系统级的安全风险之后，最后一个练习将审视一种潜在的硬件解决方案：在安全区域转换时清除微体系结构状态。然而，安全并非没有代价。本练习提供了一个具体的计算模型，用于量化此类硬件缓解措施的性能开销，这突显了架构师和系统设计师在现实世界中必须不断权衡的关键点——安全性与性能之间的取舍。[@problem_id:3686085]", "problem": "可信执行环境（TEE）通过对 enclave 代码和数据强制执行机密性和完整性，从而将 enclave 的执行与系统其余部分隔离开来。然而，诸如一级（$\\text{L1}$）缓存、二级（$\\text{L2}$）缓存、分支目标缓冲器（BTB）、返回栈缓冲器（RSB）和转译后备缓冲器（TLB）等硬件微架构结构在域切换时可能保留残余状态，这可能导致侧信道泄漏。考虑以下选择性清理方案以减轻进入 enclave 转换时的泄漏：微架构结构中的每个条目都带有一个一位的域标签，指示它是由 enclave 还是由非 enclave 代码填充的。进入 enclave 时，硬件会扫描这些结构，读取每个条目的标签，并仅使域标签为非 enclave 的条目无效。扫描通过对标签阵列进行 bank 式访问来进行，而失效操作通过清除所选条目的有效位来完成。对于选择性标记不可靠的预测器结构，则执行完全刷新。\n\n假设中央处理器（CPU）实现了以下结构和 bank 式吞吐量。对于缓存，扫描开销为每 bank 每行 $1$ 个周期，失效开销为每 bank 每失效行 $1$ 个周期。对于 TLB，扫描开销为在给定吞吐量下每条目 $1$ 个周期，失效开销为在相同吞吐量下每失效条目 $1$ 个周期。对于预测器结构，使用指定的吞吐量。所有清理操作在不同结构之间是串行执行的。\n\n缓存参数：\n- $\\text{L1}$ 数据缓存：大小 $32 \\times 1024$ 字节，行大小 $64$ 字节，用于清理的 bank 数量 $2$ 个，进入前标记为非 enclave 的缓存行比例 $f_{\\text{L1D}} = \\frac{3}{4}$。\n- $\\text{L1}$ 指令缓存：大小 $32 \\times 1024$ 字节，行大小 $64$ 字节，用于清理的 bank 数量 $2$ 个，进入前标记为非 enclave 的缓存行比例 $f_{\\text{L1I}} = \\frac{1}{2}$。\n- $\\text{L2}$ 统一缓存：大小 $512 \\times 1024$ 字节，行大小 $64$ 字节，用于清理的 bank 数量 $4$ 个，进入前标记为非 enclave 的缓存行比例 $f_{\\text{L2}} = \\frac{1}{2}$。\n\n预测器参数：\n- BTB：$4096$ 个条目，完全刷新吞吐量为每周期 $64$ 个条目。\n- RSB：深度 $32$，完全刷新开销为每条目 $1$ 个周期。\n\nTLB 参数：\n- 数据 TLB（$\\text{DTLB}$）：$64$ 个条目，扫描/刷新吞吐量为每周期 $8$ 个条目，进入前标记为非 enclave 的条目比例 $f_{\\text{DTLB}} = \\frac{3}{4}$。\n- 指令 TLB（$\\text{ITLB}$）：$64$ 个条目，扫描/刷新吞吐量为每周期 $8$ 个条目，进入前标记为非 enclave 的条目比例 $f_{\\text{ITLB}} = \\frac{1}{2}$。\n- 二级 TLB（$\\text{STLB}$）：$1024$ 个条目，扫描/刷新吞吐量为每周期 $16$ 个条目，进入前标记为非 enclave 的条目比例 $f_{\\text{STLB}} = \\frac{5}{8}$。\n\n使用以上定义以及关于 bank 式内存阵列和缓存行组织的标准知识，推导出进入 enclave 时的总清理开销（以周期为单位）$C_{\\text{scrub}}$，即 $\\text{L1}$、$\\text{L2}$、BTB、RSB、$\\text{DTLB}$、$\\text{ITLB}$ 和 $\\text{STLB}$ 的扫描和失效开销之和。假设清理操作在不同结构之间是串行执行的。将 $C_{\\text{scrub}}$ 计算为精确的整数周期数。以总周期数的形式表示您的最终答案，无需任何单位转换。不需要四舍五入。", "solution": "问题要求计算在进入可信执行环境（TEE）enclave 时，一组微架构结构的总清理开销（以周期为单位）$C_{\\text{scrub}}$。问题指出，清理操作在所有结构之间是串行执行的。因此，总开销是每个结构各自开销的总和：一级数据缓存（$\\text{L1D}$）、一级指令缓存（$\\text{L1I}$）、二级统一缓存（$\\text{L2}$）、分支目标缓冲器（BTB）、返回栈缓冲器（RSB）、数据转译后备缓冲器（$\\text{DTLB}$）、指令 TLB（$\\text{ITLB}$）和二级 TLB（$\\text{STLB}$）。\n\n$$C_{\\text{scrub}} = C_{\\text{L1D}} + C_{\\text{L1I}} + C_{\\text{L2}} + C_{\\text{BTB}} + C_{\\text{RSB}} + C_{\\text{DTLB}} + C_{\\text{ITLB}} + C_{\\text{STLB}}$$\n\n我们将根据提供的参数和开销模型计算每个组件的开销。\n\n**1. 缓存清理开销（$C_{\\text{L1D}}$, $C_{\\text{L1I}}$, $C_{\\text{L2}}$）**\n\n对于缓存，清理过程包括两个顺序阶段：扫描标签阵列和使非 enclave 行无效。该架构使用 bank 式访问。\n缓存中的行数由 $N_{\\text{lines}} = \\frac{\\text{缓存大小}}{\\text{行大小}}$ 给出。\n操作在各个 bank 之间并行进行，因此时间由每个 bank 的条目数量决定。\n扫描开销：开销为每 bank 每行 $1$ 个周期。对于 $B$ 个 bank，时间为 $C_{\\text{scan}} = \\frac{N_{\\text{lines}}}{B}$。\n失效开销：开销为每 bank 每失效行 $1$ 个周期。非 enclave 行的数量为 $N_{\\text{non-enclave}} = N_{\\text{lines}} \\times f$，其中 $f$ 是非 enclave 行的比例。失效时间为 $C_{\\text{invalidate}} = \\frac{N_{\\text{non-enclave}}}{B} = \\frac{N_{\\text{lines}} \\times f}{B}$。\n缓存的总开销为 $C_{\\text{cache}} = C_{\\text{scan}} + C_{\\text{invalidate}} = \\frac{N_{\\text{lines}}}{B} (1 + f)$。\n\n- **L1 数据缓存 ($C_{\\text{L1D}}$):**\n  - 大小 = $32 \\times 1024$ 字节 = $32768$ 字节。行大小 = $64$ 字节。\n  - 行数 $N_{\\text{L1D}} = \\frac{32768}{64} = 512$。\n  - bank 数量 $B_{\\text{L1D}} = 2$。\n  - 非 enclave 行的比例 $f_{\\text{L1D}} = \\frac{3}{4}$。\n  - $C_{\\text{L1D}} = \\frac{512}{2} \\left(1 + \\frac{3}{4}\\right) = 256 \\times \\frac{7}{4} = 64 \\times 7 = 448$ 周期。\n\n- **L1 指令缓存 ($C_{\\text{L1I}}$):**\n  - 大小 = $32 \\times 1024$ 字节 = $32768$ 字节。行大小 = $64$ 字节。\n  - 行数 $N_{\\text{L1I}} = \\frac{32768}{64} = 512$。\n  - bank 数量 $B_{\\text{L1I}} = 2$。\n  - 非 enclave 行的比例 $f_{\\text{L1I}} = \\frac{1}{2}$。\n  - $C_{\\text{L1I}} = \\frac{512}{2} \\left(1 + \\frac{1}{2}\\right) = 256 \\times \\frac{3}{2} = 128 \\times 3 = 384$ 周期。\n\n- **L2 统一缓存 ($C_{\\text{L2}}$):**\n  - 大小 = $512 \\times 1024$ 字节 = $524288$ 字节。行大小 = $64$ 字节。\n  - 行数 $N_{\\text{L2}} = \\frac{524288}{64} = 8192$。\n  - bank 数量 $B_{\\text{L2}} = 4$。\n  - 非 enclave 行的比例 $f_{\\text{L2}} = \\frac{1}{2}$。\n  - $C_{\\text{L2}} = \\frac{8192}{4} \\left(1 + \\frac{1}{2}\\right) = 2048 \\times \\frac{3}{2} = 1024 \\times 3 = 3072$ 周期。\n\n**2. 预测器刷新开销（$C_{\\text{BTB}}$, $C_{\\text{RSB}}$）**\n\n预测器结构进行完全刷新。\n\n- **分支目标缓冲器 ($C_{\\text{BTB}}$):**\n  - 条目数 = $4096$。\n  - 吞吐量 = 每周期 $64$ 个条目。\n  - $C_{\\text{BTB}} = \\frac{4096 \\text{ 条目}}{64 \\text{ 条目/周期}} = 64$ 周期。\n\n- **返回栈缓冲器 ($C_{\\text{RSB}}$):**\n  - 深度（条目数）= $32$。\n  - 开销 = 每条目 $1$ 个周期。\n  - $C_{\\text{RSB}} = 32 \\text{ 条目} \\times 1 \\text{ 周期/条目} = 32$ 周期。\n\n**3. TLB 清理开销（$C_{\\text{DTLB}}$, $C_{\\text{ITLB}}$, $C_{\\text{STLB}}$）**\n\nTLB 使用与缓存类似的选择性清理。开销基于吞吐量。对于一个有 $N$ 个条目、吞吐量为 $T$（条目/周期）、非 enclave 比例为 $f$ 的 TLB：\n扫描开销：$C_{\\text{scan}} = \\frac{N}{T}$。\n失效开销：$C_{\\text{invalidate}} = \\frac{N \\times f}{T}$。\nTLB 总开销：$C_{\\text{TLB}} = C_{\\text{scan}} + C_{\\text{invalidate}} = \\frac{N}{T} (1+f)$。\n\n- **数据 TLB ($C_{\\text{DTLB}}$):**\n  - 条目数 $N_{\\text{DTLB}} = 64$。吞吐量 $T_{\\text{DTLB}} = 8$ 条目/周期。\n  - 非 enclave 比例 $f_{\\text{DTLB}} = \\frac{3}{4}$。\n  - $C_{\\text{DTLB}} = \\frac{64}{8} \\left(1 + \\frac{3}{4}\\right) = 8 \\times \\frac{7}{4} = 2 \\times 7 = 14$ 周期。\n\n- **指令 TLB ($C_{\\text{ITLB}}$):**\n  - 条目数 $N_{\\text{ITLB}} = 64$。吞吐量 $T_{\\text{ITLB}} = 8$ 条目/周期。\n  - 非 enclave 比例 $f_{\\text{ITLB}} = \\frac{1}{2}$。\n  - $C_{\\text{ITLB}} = \\frac{64}{8} \\left(1 + \\frac{1}{2}\\right) = 8 \\times \\frac{3}{2} = 4 \\times 3 = 12$ 周期。\n\n- **二级 TLB ($C_{\\text{STLB}}$):**\n  - 条目数 $N_{\\text{STLB}} = 1024$。吞吐量 $T_{\\text{STLB}} = 16$ 条目/周期。\n  - 非 enclave 比例 $f_{\\text{STLB}} = \\frac{5}{8}$。\n  - $C_{\\text{STLB}} = \\frac{1024}{16} \\left(1 + \\frac{5}{8}\\right) = 64 \\times \\frac{13}{8} = 8 \\times 13 = 104$ 周期。\n\n**4. 总清理开销（$C_{\\text{scrub}}$）**\n\n最后，我们将所有结构的开销相加。\n$C_{\\text{scrub}} = C_{\\text{L1D}} + C_{\\text{L1I}} + C_{\\text{L2}} + C_{\\text{BTB}} + C_{\\text{RSB}} + C_{\\text{DTLB}} + C_{\\text{ITLB}} + C_{\\text{STLB}}$\n$C_{\\text{scrub}} = 448 + 384 + 3072 + 64 + 32 + 14 + 12 + 104$\n$C_{\\text{scrub}} = (448 + 384 + 3072) + (64 + 32) + (14 + 12 + 104)$\n$C_{\\text{scrub}} = (3904) + (96) + (130)$\n$C_{\\text{scrub}} = 4000 + 130 = 4130$\n\n进入 enclave 的总清理开销为 $4130$ 个周期。", "answer": "$$\\boxed{4130}$$", "id": "3686085"}]}