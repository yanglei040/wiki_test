{"hands_on_practices": [{"introduction": "多级页表的核心机制在于将虚拟地址逐级分解。这个练习旨在通过一个具体的计算任务，让你亲手实践地址分解的过程，从而巩固对多级页表索引方式的理解。通过分析一个常见的错误解码方法，你将更深刻地体会到精确位操作在系统编程中的重要性。[@problem_id:3660543]", "problem": "一个假设的体系结构使用一个 $p=3$ 级的多级页表。虚拟地址长度为 $L=\\sum_{i=1}^{p} b_i + b_o$，其中 $b_1=11$，$b_2=9$，$b_3=8$，页偏移量大小为 $b_o=12$。某个进程生成了虚拟地址 $v=\\mathrm{0xABCDEF1234}$。\n\n根据定义，一个 $p$ 级页表将虚拟地址 $v$ 从最高有效位到最低有效位划分为 $p$ 个连续的索引字段，其后是页偏移量。具体到这个系统，1 级索引占据比特位 $39$ 到 $29$，2 级索引占据比特位 $28$ 到 $20$，3 级索引占据比特位 $19$ 到 $12$，页偏移量占据比特位 $11$ 到 $0$。\n\n一个有时会给学生的错误教学提示是：“要获取 $i$ 级索引，直接将掩码 $\\left(\\left(1 \\ll b_i\\right)-1\\right)$ 应用于 $v$”，其中 $\\ll$ 表示按位左移。这个提示会导致一个系统性的解码错误：它不会隔离出预期的索引字段，而是产生 $v$ 的最低有效 $b_i$ 个比特位。\n\n假设每个学生在 $i$ 级独立地犯这个错误掩码错误的概率为 $r_i$，否则就正确解码该级别，其中 $r_1=0.2$，$r_2=0.3$，$r_3=0.4$。在这个错误模型下，对于给定的特定地址 $v$，计算在所有 $p=3$ 个级别中产生的错误级别索引的期望数量。将你的答案四舍五入到四位有效数字。最终答案以无量纲数表示。", "solution": "我们首先来确定解题的框架。对于 $p=3$ 个层级中的每一个层级 $i \\in \\{1, 2, 3\\}$，当且仅当学生犯了错误 *并且* 错误的解码结果不等于正确的解码结果时，该层级的索引才是不正确的。\n\n设 $X_i$ 为一个指示随机变量，如果第 $i$ 级的索引不正确，则 $X_i=1$，否则 $X_i=0$。我们要计算的期望值是 $E[\\sum_{i=1}^3 X_i]$。根据期望的线性性质，这等于 $\\sum_{i=1}^3 E[X_i]$。\n\n对于每个层级 $i$，产生不正确索引的概率 $P(X_i=1)$ 是学生在该层级犯错的概率 $r_i$ 乘以一个条件——即犯错所产生的索引 $F_i$ 与正确索引 $C_i$ 不相等。由于给定的虚拟地址 $v$ 是一个常量，对于每个层级，$C_i$ 和 $F_i$ 的值都是确定的。我们可以用一个指示函数 $I(C_i \\neq F_i)$ 来表示这个条件，如果 $C_i \\neq F_i$ 则该函数值为 $1$，否则为 $0$。\n\n因此，$E[X_i] = P(X_i=1) = r_i \\times I(C_i \\neq F_i)$。\n\n现在，我们来为给定的虚拟地址 $v=\\mathrm{0xABCDEF1234}$ 计算每个层级的 $C_i$ 和 $F_i$。\n虚拟地址的二进制表示（40位）为：\n`1010 1011 1100 1101 1110 1111 0001 0010 0011 0100`\n\n**第1级 (i=1, b_1=11):**\n-   **正确索引 $C_1$**: 取自比特位 39 到 29（最高11位）。\n    $C_1 = (10101011110)_2 = (55E)_{16}$。\n-   **错误索引 $F_1$**: 取自最低的 11 位。\n    $F_1 = (\\dots 01000110100)_2 = (234)_{16}$。\n-   比较：$C_1 \\neq F_1$，因此 $I(C_1 \\neq F_1) = 1$。\n-   期望贡献：$E[X_1] = r_1 \\times 1 = 0.2$。\n\n**第2级 (i=2, b_2=9):**\n-   **正确索引 $C_2$**: 取自比特位 28 到 20。\n    $C_2 = (011011110)_2 = (0DE)_{16}$。\n-   **错误索引 $F_2$**: 取自最低的 9 位。\n    $F_2 = (\\dots 100110100)_2 = (134)_{16}$。\n-   比较：$C_2 \\neq F_2$，因此 $I(C_2 \\neq F_2) = 1$。\n-   期望贡献：$E[X_2] = r_2 \\times 1 = 0.3$。\n\n**第3级 (i=3, b_3=8):**\n-   **正确索引 $C_3$**: 取自比特位 19 到 12。\n    $C_3 = (11110001)_2 = (F1)_{16}$。\n-   **错误索引 $F_3$**: 取自最低的 8 位。\n    $F_3 = (\\dots 00110100)_2 = (34)_{16}$。\n-   比较：$C_3 \\neq F_3$，因此 $I(C_3 \\neq F_3) = 1$。\n-   期望贡献：$E[X_3] = r_3 \\times 1 = 0.4$。\n\n**总期望值：**\n不正确级别索引的总期望数量是各级别期望贡献的总和：\n$$ E = E[X_1] + E[X_2] + E[X_3] = 0.2 + 0.3 + 0.4 = 0.9 $$\n根据题目要求，将答案四舍五入到四位有效数字，得到 $0.9000$。", "answer": "$$\n\\boxed{0.9000}\n$$", "id": "3660543"}, {"introduction": "理解了地址转换的机制后，我们来探讨其性能影响。这个练习将引导你对两种极端情况——最优和最差的内存访问模式——进行建模，以量化分析转换后备缓冲区（TLB）命中与未命中时的巨大性能差异。通过计算有效访问时间（EAT），你将直观地感受到内存访问的局部性原理是如何直接影响系统性能的。[@problem_id:3660470]", "problem": "您正在分析多级页表下的内存地址转换开销，目标是对比对抗性访问模式和局部性友好访问模式。考虑一个处理器，其具有一个容量为 $T$ 个条目的全相联转译后备缓冲器 (TLB)，该 TLB 使用最近最少使用 (LRU) 替换策略。处理器还带有一个 $L$ 级页表，每次 TLB 未命中都会强制硬件页表遍历器在主内存中访问恰好 $L$ 个页表项，然后才能获知地址转换结果。假设 TLB 查找必须在任何内存访问开始之前完成（无重叠），没有页错误（所有页面都已驻留），并且对于我们感兴趣的访问，数据缓存和任何页表遍历缓存都不会命中，因此每次所需的内存引用都会产生主内存访问时间的成本。已知以下参数：\n- TLB 容量 $T = 128$ 条目。\n- 页表深度 $L = 4$ 级。\n- TLB 查找时间 $t_{\\mathrm{TLB}} = 0.6 \\text{ ns}$。\n- 主内存访问延迟 $t_{\\mathrm{mem}} = 80 \\text{ ns}$。\n- 页面大小 $P = 4 \\text{ KiB}$。\n\n任务：\n- 构造一个地址序列 $\\{a_i\\}_{i \\ge 0}$，在短暂预热后，能在给定的 $T$ 和 $L$ 条件下产生尽可能小的稳态 TLB 命中率。您的构造必须使用一个与 $P$ 对齐的基地址 $b$，并且每一步生成一个保持在单个页面内的引用。请给出 $a_i$ 关于 $i$、$T$、$P$ 和一个常量页内偏移量的表达式。\n- 使用关于期望时间的第一性原理（基于命中/未命中概率）和 $L$ 级页表遍历的定义，推导在您的对抗性模式下的稳态期望访问时间 (EAT)。\n- 构造一个能产生最大稳态 TLB 命中率的局部性友好访问模式，并在相同假设下推导其稳态 EAT。\n- 最后，计算对抗性 EAT 与友好 EAT 之比 $r$。将 $r$ 四舍五入到四位有效数字。仅报告此比率作为您的最终答案（无单位）。如果您选择给出中间的 EAT 值，请以 $\\text{ns}$ 为单位表示。", "solution": "主要任务是比较两种内存访问模式的期望访问时间 (EAT)：一种是使转译后备缓冲器 (TLB) 命中率最小化的对抗性模式，另一种是使其最大化的局部性友好模式。给定以下参数：\n- TLB 容量：$T = 128$ 条目\n- 页表深度：$L = 4$ 级\n- TLB 查找时间：$t_{\\mathrm{TLB}} = 0.6 \\text{ ns}$\n- 主内存访问延迟：$t_{\\mathrm{mem}} = 80 \\text{ ns}$\n- 页面大小：$P = 4 \\text{ KiB} = 4 \\times 2^{10} \\text{ 字节} = 4096 \\text{ 字节}$\n\n首先，我们推导期望访问时间 $EAT$ 作为 TLB 命中率 $h$ 的函数的通用表达式。一次内存访问包括两个主要阶段：地址转换和数据访问。\n\n任何内存访问的总时间都包括 TLB 查找时间 $t_{\\mathrm{TLB}}$ 和数据的主内存访问时间 $t_{\\mathrm{mem}}$。如果地址转换不在 TLB 中（即 TLB 未命中），则会产生额外的开销。\n\n让我们分解一次内存引用的时间构成：\n1.  总是执行一次 TLB 查找，耗时 $t_{\\mathrm{TLB}}$。\n2.  查找成功的概率为 $h$（命中率）（即 TLB 命中）。此时物理地址已知。然后从主内存获取数据，耗时 $t_{\\mathrm{mem}}$。一次命中的总时间为 $t_{\\mathrm{TLB}} + t_{\\mathrm{mem}}$。\n3.  查找失败的概率为 $1-h$（即 TLB 未命中）。必须执行一次页表遍历。题目说明这需要对主内存进行 $L$ 次访问，且页表项没有缓存命中。这次页表遍历的开销是 $L \\times t_{\\mathrm{mem}}$。页表遍历之后，地址转换确定，然后可以从主内存获取数据，这又需要额外的 $t_{\\mathrm{mem}}$ 时间。一次未命中的总时间为 $t_{\\mathrm{TLB}} + L \\times t_{\\mathrm{mem}} + t_{\\mathrm{mem}}$。\n\n期望访问时间是命中时间和未命中时间的概率加权平均值：\n$$EAT(h) = h \\times (t_{\\mathrm{TLB}} + t_{\\mathrm{mem}}) + (1-h) \\times (t_{\\mathrm{TLB}} + L t_{\\mathrm{mem}} + t_{\\mathrm{mem}})$$\n此表达式可以简化：注意到每次访问都会产生 $t_{\\mathrm{TLB}} + t_{\\mathrm{mem}}$ 的成本，而一次未命中会额外增加 $L t_{\\mathrm{mem}}$ 的开销：\n$$EAT(h) = t_{\\mathrm{TLB}} + t_{\\mathrm{mem}} + (1-h) \\times (L t_{\\mathrm{mem}})$$\n\n现在我们构造这两种访问模式并分析它们各自的 EAT。\n\n**对抗性访问模式**\n为达到尽可能小的稳态 TLB 命中率，我们必须设计一种访问模式，确保所需的页面翻译永远不在 TLB 中。TLB 是一个容量为 $T$ 条目的全相联缓存，并使用 LRU 替换策略。针对这种缓存的对抗性模式涉及循环访问 $T+1$ 个不同的项。\n\n让我们构造这样一个地址序列 $\\{a_i\\}$。我们需要以轮询方式访问 $T+1 = 128+1 = 129$ 个不同的页面。设 $b$ 为一个页对齐的基地址，$o_{\\mathrm{const}}$ 为一个常量页内偏移量（$0 \\le o_{\\mathrm{const}} < P$）。第 $i$ 次访问的地址可以定义为：\n$$a_i = b + (i \\pmod{(T+1)}) \\times P + o_{\\mathrm{const}}$$\n该序列以重复循环的方式访问对应于基地址 $b$, $b+P$, $b+2P$, ..., $b+T \\times P$ 的页面。在经历 $T+1$ 次强制性未命中的初始预热阶段后，TLB 将包含最近访问的 $T$ 个页面的地址转换。下一次访问将指向 $T+1$ 步之前访问过的页面，该页面是最近最少使用的，并且刚刚被替换出去。因此，在稳态下，每一次访问都会导致 TLB 未命中。\n\n可能达到的最小稳态 TLB 命中率为 $h_{adv} = 0$。\n将 $h=0$ 代入我们的通用公式，可以得到相应的 EAT：\n$$EAT_{adv} = EAT(0) = t_{\\mathrm{TLB}} + t_{\\mathrm{mem}} + (1-0) L t_{\\mathrm{mem}} = t_{\\mathrm{TLB}} + (L+1)t_{\\mathrm{mem}}$$\n代入给定值：\n$$EAT_{adv} = 0.6 \\text{ ns} + (4+1) \\times 80 \\text{ ns} = 0.6 \\text{ ns} + 5 \\times 80 \\text{ ns} = 0.6 \\text{ ns} + 400 \\text{ ns} = 400.6 \\text{ ns}$$\n\n**局部性友好访问模式**\n为达到可能的最大稳态 TLB 命中率，访问模式应表现出高时间局部性。这意味着重复访问一组页面，其数量小于或等于 TLB 容量 $T$。理想情况是只重复访问一个页面。\n\n让我们构造这样一个地址序列。例如，所有访问都可以指向单个页面内的同一地址：\n$$a_i = b + o_{\\mathrm{const}} \\quad \\text{for all } i \\ge 0$$\n对该页面的第一次访问将导致一次强制性 TLB 未命中。该页面的地址转换将被获取并存入 TLB。由于所有后续访问都指向同一页面，它们都将是 TLB 命中，因为该地址转换将一直保留在 TLB 中。\n\n可能达到的最大稳态 TLB 命中率为 $h_{friendly} = 1$。\n将 $h=1$ 代入我们的通用公式，可以得到相应的 EAT：\n$$EAT_{friendly} = EAT(1) = t_{\\mathrm{TLB}} + t_{\\mathrm{mem}} + (1-1) L t_{\\mathrm{mem}} = t_{\\mathrm{TLB}} + t_{\\mathrm{mem}}$$\n代入给定值：\n$$EAT_{friendly} = 0.6 \\text{ ns} + 80 \\text{ ns} = 80.6 \\text{ ns}$$\n\n**比率计算**\n最后，我们计算对抗性 EAT 与友好 EAT 之比 $r$：\n$$r = \\frac{EAT_{adv}}{EAT_{friendly}} = \\frac{t_{\\mathrm{TLB}} + (L+1)t_{\\mathrm{mem}}}{t_{\\mathrm{TLB}} + t_{\\mathrm{mem}}}$$\n使用计算出的值：\n$$r = \\frac{400.6}{80.6} \\approx 4.970223325...$$\n按要求四舍五入到四位有效数字，我们得到：\n$$r \\approx 4.970$$", "answer": "$$\\boxed{4.970}$$", "id": "3660470"}, {"introduction": "多级页表不仅是硬件概念，它还与操作系统的核心功能紧密协作。本练习模拟了一个结合了写时复制（Copy-on-Write, COW）机制的复杂场景，要求你分析硬件（设置访问/脏位、产生缺页中断）和软件（处理中断、更新页表）之间的精妙互动。通过这个案例，你将理解在现代操作系统中，虚拟内存管理是如何支持进程创建等高级功能的。[@problem_id:3660505]", "problem": "考虑一个在类 x86-64 架构上实现虚拟内存的系统，该系统具有 $4$ 级页表层级。从 $L_1$ 到 $L_4$ 的每一级分页结构条目（$L_4$ 是叶节点页表条目(PTE)）都包含一个访问位（$A$）。只有叶节点PTE包含一个脏位（$D$），用于大小为 $4$ KiB 的基页。当硬件在翻译过程中使用某个分页结构条目时，会设置其 $A$ 位；当首次成功写入一个其叶节点PTE允许写入的页面时，硬件会设置其 $D$ 位。转译后备缓冲器（TLB）会缓存地址翻译；当使用TLB条目时，硬件不会执行新的页表遍历。操作系统（OS）对`fork()`出的进程采用写时复制（COW）技术：在`fork()`之后，子进程会获得自己的页表页，父进程和子进程的PTE都指向同一个物理帧，但被标记为只读，直到发生写操作。此时，OS会为执行写入的进程分配一个私有帧，并更新该进程的叶节点PTE为可写。\n\n两个由`fork()`创建的用户进程 $P_1$ 和 $P_2$ 在两个不同的中央处理器（CPU）核心 $C_1$ 和 $C_2$ 上运行。它们各自在自己的地址空间中访问相同的虚拟地址 $v$，该地址最初是在父进程中映射的。假设在`fork()`之后，对于 $P_1$ 和 $P_2$ 立即存在以下状态：\n\n- $C_1$ 和 $C_2$ 上的TLB中没有关于 $v$ 的条目。\n- 在每个进程中，用于解析 $v$ 的所有 $4$ 级分页结构中的 $A$ 位都已被清除。\n- 在每个进程中，$v$ 的叶节点PTE是存在的，指向同一个物理帧，并且由于COW而被标记为只读；其 $D$ 位已被清除。\n\n在时间 $t_0$， $P_1$ 和 $P_2$ 并发地从 $v$ 读取数据。稍后，在时间 $t_1$，两者都并发地尝试向 $v$ 写入数据。OS根据上述COW语义处理缺页中断，并且在为每个进程处理完中断后，会重试原始的写指令。\n\n对于此场景，哪个选项最能描述硬件何时设置 $A$/$D$ 位，这些位如何在父子进程的页表条目（PTE）之间传播或不传播，以及在设置这些位时是否存在跨进程的争用？请包括在第一个读取和第一个写入阶段，两个进程中设置 $A$ 和 $D$ 位所产生的不同内存修改的正确计数。\n\nA. 在并发的首次读取（伴随TLB未命中）之后，硬件会在每次页表遍历中为每个进程用到的 $4$ 个分页结构条目设置访问位（$A$），总共产生 $8$ 次不同的 $A$ 位内存修改；在首次尝试写入时，会发生缺页中断，并且在OS为每个进程安装一个私有的可写叶节点PTE之前，脏位（$D$）不会被设置，此后重试的写入操作会为每个进程设置一个叶节点 $D$ 位（共 $2$ 个）。因为fork后父子进程拥有独立的页表页，所以 $A$/$D$ 位的设置不会在进程间传播，设置这些位时也不存在进程间争用。\n\nB. 首次读取后，只有叶节点PTE的 $A$ 位被更新，总共 $2$ 次写入；在导致中断的写入操作上，硬件会在OS运行前在共享的只读PTE中设置 $D$ 位，并且这些 $D$ 位会传播到另一个进程的PTE，可能导致争用。\n\nC. 在每一级，两个进程总共只设置一次 $A$ 位，因为它们都指向同一个物理帧，所有级别总共产生 $4$ 次写入；在COW之后，父进程的叶节点 $D$ 位会因为子进程的写入而被设置，并且由于共享的页表页而对子进程可见。\n\nD. 在首次读取时如果TLB命中，硬件仍然会执行部分页表遍历以懒惰地更新 $A$/$D$ 位，因此在共享的上层条目上存在争用，并且在 $t_0$ 期间可能发生超过 $8$ 次写入。\n\nE. 如果两个进程并发写入并触发COW缺页中断，两个叶节点的 $D$ 位都会在中断被递送之前设置，因此OS必须在之后清除它们以强制执行复制语义，这意味着跨进程的传播和争用。", "solution": "### 解题推导\n\n分析将通过检查 $P_1$ 和 $P_2$ 两个进程在时间 $t_0$ 和 $t_1$ 的事件来进行。\n\n#### 对 $t_0$ 时刻并发读取的分析\n\n1.  **初始状态**：在 $t_0$ 时，核心 $C_1$ 和 $C_2$ 上的TLB中没有关于虚拟地址 $v$ 的条目。\n2.  **页表遍历**：当 $P_1$ 在核心 $C_1$ 上从 $v$ 读取时，内存管理单元（MMU）在TLB中找不到翻译。这会触发一次硬件页表遍历。\n3.  **为 $P_1$ 设置访问位 ($A$)**：遍历过程会穿过 $P_1$ 的 $4$ 级页表层级。根据问题描述，“当硬件在翻译过程中使用某个分页结构条目时，会设置其 $A$ 位。”因此，硬件将设置 $P_1$ 的 $L_1$ 条目、$L_2$ 条目、$L_3$ 条目和叶节点PTE（$L_4$）中的 $A$ 位。这对 $P_1$ 的页表结构构成了 $4$ 次独立的内存修改。\n4.  **为 $P_2$ 设置访问位 ($A$)**：并发地，同样的过程也发生在核心 $C_2$ 上的 $P_2$。$v$ 的TLB未命中触发了一次对其自身分页结构的页表遍历。硬件会设置 $P_2$ 的 $L_1, L_2, L_3$ 和 $L_4$ 条目中的 $A$ 位。这构成了另外 $4$ 次内存修改。\n5.  **不同的修改**：问题说明，在 `fork()` 之后，“子进程会获得自己的页表页”。这意味着包含 $P_1$ 页表的物理内存页与 $P_2$ 的是不同的。因此，对 $P_1$ 的 $4$ 次 $A$ 位修改和对 $P_2$ 的 $4$ 次 $A$ 位修改是在不同的物理内存位置上执行的。这导致总共有 $4 + 4 = 8$ 次不同的内存修改来设置 $A$ 位。\n6.  **读取结果**：两个进程的叶节点PTE都被标记为只读。读取操作是允许的。读取成功完成。$D$ 位与读取操作无关，保持清除状态。遍历之后，在 $C_1$ 和 $C_2$ 上都会为 $v$ 创建TLB条目。\n\n#### 对 $t_1$ 时刻并发写入的分析\n\n1.  **初次尝试**：在 $t_1$ 时， $P_1$ 和 $P_2$ 都尝试向 $v$ 写入。每个核心上的TLB条目（从之前的读取中缓存的）指示该页面映射是只读的。\n2.  **产生缺页中断**：尝试向只读页面写入会导致硬件产生一个保护性中断（一种缺页中断）。写指令不会完成。\n3.  **脏位 ($D$) 状态**：问题说明，硬件“在首次成功写入一个其叶节点PTE允许写入的页面时”设置 $D$ 位。由于PTE不允许写入，并且写入操作不成功（它导致了中断），硬件在此阶段**不会**设置 $D$ 位。\n4.  **OS介入（COW中断处理）**：每个进程的OS缺页中断处理程序被调用。\n    -   对于 $P_1$：OS识别出这是一个COW中断。它分配一个新的物理帧，将原始共享帧的内容复制到新帧中，并更新 $P_1$ 的叶节点PTE（$L_4$）以指向这个新的私有帧。该PTE也被标记为可写。更新后的PTE中的 $D$ 位初始为清除状态。\n    -   对于 $P_2$：OS为 $P_2$ 独立地执行相同的操作，分配第二个新的物理帧，并更新 $P_2$ 的叶节点PTE为可写并指向它。\n5.  **指令重试并设置脏位 ($D$)**：在OS处理程序返回后，每个进程中出错的写指令被重试。\n    -   对于 $P_1$ 的重试：硬件的地址翻译现在找到了一个可写的叶节点PTE。写入成功。由于这是第一次成功写入，硬件会设置 $P_1$ 的叶节点PTE中的 $D$ 位。这是一次内存修改。\n    -   对于 $P_2$ 的重试：发生同样的情况。写入成功，硬件设置 $P_2$ 的叶节点PTE中的 $D$ 位。这是第二次不同的内存修改。\n6.  **总修改次数**：在此阶段，总共有 $2$ 次修改来设置 $D$ 位，每个进程的私有叶节点PTE各一次。\n\n#### 争用与传播分析\n\n-   **传播**：因为“子进程会获得自己的页表页”，所以 $P_1$ 和 $P_2$ 的分页结构在物理上是分离的。在 $P_1$ 的页表中设置 $A$ 位不会影响 $P_2$ 的页表，反之亦然。在COW中断之后，叶节点PTE和数据页也都是私有的。因此，为一个进程设置 $D$ 位对另一个进程没有影响。$A$ 或 $D$ 位的设置在进程的页表之间**没有传播**。\n-   **争用**：当多个代理试图同时访问/修改同一资源时，就会发生资源争用。由于 $A$ 位和 $D$ 位是在物理上不同的内存位置（$P_1$ 和 $P_2$ 的独立页表）中设置的，因此设置这些位时**不存在进程间争用**。\n\n### 逐项分析选项\n\n*   **A. 在并发的首次读取（伴随TLB未命中）之后，硬件会在每次页表遍历中为每个进程用到的 $4$ 个分页结构条目设置访问位（$A$），总共产生 $8$ 次不同的 $A$ 位内存修改；在首次尝试写入时，会发生缺页中断，并且在OS为每个进程安装一个私有的可写叶节点PTE之前，脏位（$D$）不会被设置，此后重试的写入操作会为每个进程设置一个叶节点 $D$ 位（共 $2$ 个）。因为fork后父子进程拥有独立的页表页，所以 $A$/$D$ 位的设置不会在进程间传播，设置这些位时也不存在进程间争用。**\n    该选项准确地描述了整个序列。$8$ 次 $A$ 位写入的计数是正确的。$D$ 位的设置时机（仅在COW中断处理完毕且指令重试后）是正确的，总数 $2$ 也是正确的。关于由于独立的页表而没有传播和争用的推理也是正确的。\n    **结论：正确。**\n\n*   **B. 首次读取后，只有叶节点PTE的 $A$ 位被更新，总共 $2$ 次写入；在导致中断的写入操作上，硬件会在OS运行前在共享的只读PTE中设置 $D$ 位，并且这些 $D$ 位会传播到另一个进程的PTE，可能导致争用。**\n    该选项在多个方面是错误的。首先，$A$ 位是在遍历中所有用到的条目上设置的，而不仅仅是叶节点PTE。其次，对于向只读PTE的失败写入， $D$ 位不会被设置；它是在成功写入可写PTE时设置的。\n    **结论：错误。**\n\n*   **C. 在每一级，两个进程总共只设置一次 $A$ 位，因为它们都指向同一个物理帧，所有级别总共产生 $4$ 次写入；在COW之后，父进程的叶节点 $D$ 位会因为子进程的写入而被设置，并且由于共享的页表页而对子进程可见。**\n    该选项是错误的，因为它错误地假设进程共享页表页。问题明确指出“子进程会获得自己的页表页”。这导致了错误的 $A$ 位写入计数和关于传播的错误论断。\n    **结论：错误。**\n\n*   **D. 在首次读取时如果TLB命中，硬件仍然会执行部分页表遍历以懒惰地更新 $A$/$D$ 位，因此在共享的上层条目上存在争用，并且在 $t_0$ 期间可能发生超过 $8$ 次写入。**\n    该选项是无效的，因为它与问题的一个核心前提相矛盾：“假设...$C_1$ 和 $C_2$ 上的TLB中没有关于 $v$ 的条目。”首次读取时没有TLB命中。\n    **结论：错误。**\n\n*   **E. 如果两个进程并发写入并触发COW缺页中断，两个叶节点的 $D$ 位都会在中断被递送之前设置，因此OS必须在之后清除它们以强制执行复制语义，这意味着跨进程的传播和争用。**\n    该选项是错误的。它在 $D$ 位问题上犯了与选项B相同的根本性错误。硬件是产生中断，*而不是*完成写入并设置 $D$ 位。$D$ 位只在OS准备好可写页面后，重试并成功的写入操作上才被设置。\n    **结论：错误。**", "answer": "$$\\boxed{A}$$", "id": "3660505"}]}