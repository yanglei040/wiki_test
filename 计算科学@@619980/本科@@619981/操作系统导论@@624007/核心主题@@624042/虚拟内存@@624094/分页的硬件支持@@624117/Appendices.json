{"hands_on_practices": [{"introduction": "转译后备缓冲器（TLB）是加速地址翻译的关键硬件。本练习将引导你从第一性原理出发，推导有效内存访问时间（EAT），从而量化TLB高命中率带来的性能优势。这是理解和分析虚拟内存系统性能的基础。[@problem_id:3623054]", "problem": "一台计算机采用单级分页机制，并配备了硬件的转译后备缓冲器（TLB）。页表完全驻留在主存中。设主存访问时间为 $t_{m}$，TLB查找时间为 $t_{tlb}$，TLB命中率为 $h$，其中 $0 \\leq h \\leq 1$。假设TLB查找是串行执行的，不与任何主存访问重叠；TLB未命中时，在访问主存中被引用的数据之前，需要从主存中获取一个页表条目；并且没有页错误或其他延迟。\n\n请仅从分页地址转换的核心定义和全期望定律出发，推导命中路径和未命中路径的访问时间，然后推导有效访问时间（EAT），即这两条路径的期望值。使用第一性原理比较命中路径成本和未命中路径成本的大小。最后，以 $t_{tlb}$、$t_{m}$ 和 $h$ 的形式，提供一个简化的EAT解析表达式。最终时间应以与 $t_{m}$ 和 $t_{tlb}$ 相同的时间单位表示，并给出封闭形式的表达式。", "solution": "首先将对问题的科学合理性、自洽性和客观性进行验证。\n\n### 第1步：提取已知条件\n- 系统类型：单级分页，配备硬件转译后备缓冲器（TLB）。\n- 页表位置：完全在主存中。\n- 主存访问时间：$t_{m}$。\n- TLB查找时间：$t_{tlb}$。\n- TLB命中率：$h$，其中 $0 \\leq h \\leq 1$。\n- 时间假设1：TLB查找是串行执行的，不与任何主存访问重叠。\n- 时间假设2：TLB未命中时，在访问被引用的数据之前，需要从主存中获取一个页表条目。\n- 系统状态：无页错误或其他延迟。\n\n### 第2步：使用提取的已知条件进行验证\n对问题进行严格评估。\n- **科学基础：** 该问题描述了一个简化的、但标准且典型的带有TLB的内存管理单元（MMU）模型。分页、页表、TLB命中、TLB未命中以及相关的时间成本等概念是计算机体系结构和操作系统中的基本原理。该模型是科学合理的。\n- **适定性：** 问题提供了所有必要的变量（$t_{m}$、$t_{tlb}$、$h$），并对TLB命中和TLB未命中的操作序列给出了清晰、明确的描述。它要求一个特定的、可推导的量——有效访问时间（EAT），基于所提供的信息，存在唯一解。\n- **客观性：** 问题以精确、正式的语言陈述，没有主观论断或含糊不清之处。\n- **结论：** 问题是有效的。这是一个适定的、有科学依据的问题，遵循了其领域的基本原理。\n\n### 第3步：裁定与行动\n该问题被判定为**有效**。将提供一个完整的、有理有据的解答。\n\n### 解答推导\n目标是推导有效访问时间（EAT）的表达式。EAT是执行一次内存访问所需时间的期望值。推导从全期望定律开始，该定律指出，一个随机变量的期望值可以通过对一组互斥且穷尽的事件的条件期望，按其各自的概率加权求和得到。\n\n在此背景下，对于任何给定的内存访问，两个可能的事件是TLB命中或TLB未命中。设 $T$ 为表示总访问时间的随机变量。设 $H$ 为TLB命中的事件， $M$ 为TLB未命中的事件。\nTLB命中的概率为 $P(H) = h$。\n由于命中或未命中是仅有的两种结果，因此未命中的概率为 $P(M) = 1 - h$。\n\nEAT是 $T$ 的期望值，记为 $E[T]$，可以表示为：\n$$EAT = E[T|H]P(H) + E[T|M]P(M)$$\n其中 $E[T|H]$ 是命中路径上的访问时间，而 $E[T|M]$ 是未命中路径上的访问时间。\n\n**1. 命中路径上的访问时间 ($T_{hit}$)**\n根据问题陈述，命中路径包括两个顺序操作：\n- 首先，检查TLB以获取页到帧的映射。这需要时间 $t_{tlb}$。\n- 发生命中，物理帧号直接从TLB获得。\n- 利用完整的物理地址，访问主存以检索数据。这需要时间 $t_{m}$。\n命中的总时间是这些顺序非重叠操作的总和：\n$$T_{hit} = E[T|H] = t_{tlb} + t_{m}$$\n\n**2. 未命中路径上的访问时间 ($T_{miss}$)**\n未命中路径涉及一个额外的步骤：\n- 首先，检查TLB。这需要时间 $t_{tlb}$。\n- 发生未命中。\n- 系统现在必须查询驻留在主存中的页表。从主存访问所需的页表条目（PTE）需要一次主存访问时间，即 $t_{m}$。\n- PTE提供了物理帧号。\n- 利用完整的物理地址，访问主存以检索数据。这是第二次独立的主存访问，需要时间 $t_{m}$。\n未命中的总时间是这三个顺序操作的总和：\n$$T_{miss} = E[T|M] = t_{tlb} + t_{m} + t_{m} = t_{tlb} + 2t_{m}$$\n\n**3. 命中路径与未命中路径成本的比较**\n从第一性原理可知，主存访问时间 $t_{m}$ 必须是正数，即 $t_{m} > 0$。比较推导出的两种成本：\n$$T_{miss} = t_{tlb} + 2t_{m} = (t_{tlb} + t_{m}) + t_{m} = T_{hit} + t_{m}$$\n这表明未命中路径的成本比命中路径多出一个主存访问时间 $t_{m}$。这个额外成本代表了TLB未命中的惩罚，即从主存中的页表获取转换所需的时间。\n\n**4. 有效访问时间（EAT）的推导**\n将路径成本和概率代入EAT的公式：\n$$EAT = T_{hit} \\cdot h + T_{miss} \\cdot (1 - h)$$\n$$EAT = (t_{tlb} + t_{m})h + (t_{tlb} + 2t_{m})(1 - h)$$\n为了得到一个简化的封闭形式表达式，我们可以重新排列这些项。一个概念上清晰的方法是围绕基础成本和惩罚成本来分解表达式。\n任何访问的成本至少包括一次TLB查找和一次内存访问，即命中路径的时间。未命中会产生一次额外内存访问的惩罚，即 $t_{m}$。\n$$EAT = (t_{tlb} + t_{m})h + (t_{tlb} + t_{m} + t_{m})(1 - h)$$\n$$EAT = (t_{tlb} + t_{m})h + (t_{tlb} + t_{m})(1-h) + t_{m}(1-h)$$\n提出公因式 $(t_{tlb} + t_{m})$：\n$$EAT = (t_{tlb} + t_{m})(h + 1 - h) + t_{m}(1-h)$$\n$$EAT = (t_{tlb} + t_{m})(1) + t_{m}(1-h)$$\n$$EAT = t_{tlb} + t_{m} + t_{m} - h \\cdot t_{m}$$\n$$EAT = t_{tlb} + 2t_{m} - h \\cdot t_{m}$$\n最后，从后两项中提出 $t_{m}$ 得到简化的解析表达式：\n$$EAT = t_{tlb} + (2 - h)t_{m}$$\n该表达式表示的有效访问时间与 $t_{tlb}$ 和 $t_{m}$ 使用相同的时间单位。", "answer": "$$\\boxed{t_{tlb} + (2 - h)t_{m}}$$", "id": "3623054"}, {"introduction": "将页表扩展到巨大的地址空间（如64位系统）是一个设计挑战。本练习通过比较简单的线性页表与现代的多级页表，让你定量分析它们在内存开销和TLB未命中代价之间的权衡。通过这个练习，你将理解为何现代计算机体系结构普遍采用分层设计。[@problem_id:3646691]", "problem": "一个计算机体系结构课程研究了硬件对分页的支持如何影响内存开销和转译后备缓冲器（TLB）的行为。考虑两个系统，它们都使用大小为 $4$ KiB 的页面。\n\n系统 A 使用 $32$ 位虚拟地址（VA）和单级线性页表。该页表为整个地址空间中的每个虚拟页面包含一个页表条目（PTE），无论实际映射了多少页面。系统 A 中的每个 PTE 为 $4$ 字节。\n\n系统 B 使用 $64$ 位虚拟地址（VA）和一个 $4$ 级基数-$512$ 的页表树（例如，类似于典型的 $x86$-$64$ 设计，其级别对应于 PML4、PDPT、PD 和 PT）。每个级别的页表都恰好占用一个 $4$ KiB 的页面，并包含 $512$ 个条目；每个条目为 $8$ 字节。仅当某个级别的页表页中的至少一个条目需要用于映射某个较低级别的对象时，才会分配该页表页。树的根页面总是被分配的。\n\n假设一个进程从虚拟地址 $0$ 开始，连续映射其虚拟地址空间中恰好 $M = 2^{30}$ 字节，且在页面边界上对齐。映射的粒度是页面大小。对于系统 B，假设连续映射引起的树使用是完全平衡的，并且分配不受页表缓存效应的影响。\n\n对于 TLB 未命中时的行为，假设硬件页表遍历器（page walker）执行每种方案所需的最少页表条目内存读取次数。设数据缓存命中延迟为 $c = 4$ 个周期，主存延迟为 $m = 200$ 个周期。在系统 A 中，TLB 未命中会触发恰好一次 PTE 读取，该读取有 $q_A = 0.9$ 的概率在数据缓存中命中，否则访问主存。在系统 B 中，TLB 未命中会触发每级一次读取，总共 $4$ 次读取，并且每一级的读取以 $q_B = 0.95$ 的概率独立地在数据缓存中命中，否则访问主存。\n\n定义以下两个量：\n\n- 内存开销比 $R_{\\text{mem}}$，定义为在给定映射 $M$ 字节的情况下，系统 A 分配的页表内存总字节数除以系统 B 分配的总字节数。\n- TLB 未命中惩罚比 $R_{\\text{tlb}}$，定义为在给定的缓存命中概率和延迟下，系统 B 中每次 TLB 未命中的预期周期数除以系统 A 中每次 TLB 未命中的预期周期数。\n\n计算复合无量纲度量\n$$\nJ = R_{\\text{mem}} \\times R_{\\text{tlb}}\n$$\n将您的答案四舍五入到四位有效数字。将最终结果表示为一个纯数字（无单位）。", "solution": "该问题被验证为科学上合理、定义明确、客观且自洽。所提供的数据在给定的计算机体系结构背景下是一致且现实的。我们将继续进行解答。\n\n目标是计算复合度量 $J = R_{\\text{mem}} \\times R_{\\text{tlb}}$。这需要计算内存开销比 $R_{\\text{mem}}$ 和 TLB 未命中惩罚比 $R_{\\text{tlb}}$。\n\n首先，我们定义页面大小 $P_S$（以字节为单位）：\n$P_S = 4 \\text{ KiB} = 4 \\times 2^{10} \\text{ bytes} = 2^2 \\times 2^{10} \\text{ bytes} = 2^{12} \\text{ bytes}$。\n\n**1. 内存开销比 ($R_{\\text{mem}}$) 的计算**\n\n我们需要计算系统 A ($\\text{Mem}_A$) 和系统 B ($\\text{Mem}_B$) 中为页表分配的总内存。\n\n对于系统 A：\n系统使用 $32$ 位虚拟地址空间和单级线性页表。虚拟地址空间的总大小是 $2^{32}$ 字节。整个地址空间中的虚拟页面数由总地址空间大小除以页面大小得出：\n$$\nN_{\\text{pages, A}} = \\frac{2^{32} \\text{ bytes}}{2^{12} \\text{ bytes/page}} = 2^{20} \\text{ pages}\n$$\n系统 A 为每个虚拟页面分配一个页表条目（PTE），无论它是否被映射。每个 PTE 的大小给定为 $4$ 字节。\n系统 A 的总内存开销为：\n$$\n\\text{Mem}_A = N_{\\text{pages, A}} \\times (\\text{PTE size}) = 2^{20} \\times 4 \\text{ bytes} = 2^{20} \\times 2^2 \\text{ bytes} = 2^{22} \\text{ bytes}\n$$\n\n对于系统 B：\n系统映射一个大小为 $M = 2^{30}$ 字节的连续内存区域。该进程映射的页面数为：\n$$\nN_{\\text{mapped}} = \\frac{M}{P_S} = \\frac{2^{30} \\text{ bytes}}{2^{12} \\text{ bytes/page}} = 2^{18} \\text{ pages}\n$$\n系统 B 使用一个 $4$ 级基数-$512$ 的页表。任何级别的每个页表都包含 $512 = 2^9$ 个条目，并占用一个 $4$ KiB（$2^{12}$ 字节）的页面。由于映射是从虚拟地址 $0$ 开始的连续映射，我们可以确定所需的页表页数。\n\n虚拟地址被划分为用于 $4$ 级页表的索引和一个页内偏移量。偏移量是 $\\log_2(2^{12}) = 12$ 位。每一级由 $\\log_2(512) = 9$ 位索引。因此，一个 $4$ 级页表的虚拟地址结构是 [索引 (4x9=36 位)][偏移量 (12 位)]。一个 L3 表条目覆盖的地址范围是 $512 \\times 512 \\times P_S = 2^9 \\times 2^9 \\times 2^{12} = 2^{30}$ 字节。正在映射的内存量 $M=2^{30}$ 字节，正好对应于一个 L3 页表（在 x86-64 中，一个 PDPT 条目）中一个条目所跨越的地址空间。\n\n让我们计算分配的页表页数：\n- **第 1 级（L1，页表）：** 每个 L1 表映射 $512$ 个页面。要映射 $2^{18}$ 个页面，我们需要 $N_{L1} = \\frac{2^{18}}{512} = \\frac{2^{18}}{2^9} = 2^9 = 512$ 个 L1 表。\n- **第 2 级（L2，页目录）：** 每个 L2 表可以指向 $512$ 个 L1 表。由于我们需要 $512$ 个 L1 表，这些都可以由单个 L2 表引用。所以，$N_{L2} = 1$。\n- **第 3 级（L3，页目录指针表）：** 我们需要分配 $1$ 个 L2 表。这需要在 L3 表中有一个条目。因此，必须分配一个 L3 页表页。所以，$N_{L3} = 1$。\n- **第 4 级（L4，例如 PML4）：** 根页面总是被分配的。它必须指向我们需要的单个 L3 表。所以，$N_{L4} = 1$。\n\n系统 B 的页表页总数为各级页面数之和：\n$$\nN_{\\text{tables, B}} = N_{L4} + N_{L3} + N_{L2} + N_{L1} = 1 + 1 + 1 + 512 = 515 \\text{ pages}\n$$\n这些页面每个的大小为 $4$ KiB ($2^{12}$ 字节)。系统 B 的总内存开销为：\n$$\n\\text{Mem}_B = N_{\\text{tables, B}} \\times P_S = 515 \\times 2^{12} \\text{ bytes}\n$$\n内存开销比 $R_{\\text{mem}}$ 为：\n$$\nR_{\\text{mem}} = \\frac{\\text{Mem}_A}{\\text{Mem}_B} = \\frac{2^{22}}{515 \\times 2^{12}} = \\frac{2^{10}}{515} = \\frac{1024}{515}\n$$\n\n**2. TLB 未命中惩罚比 ($R_{\\text{tlb}}$) 的计算**\n\n我们需要计算两个系统处理一次 TLB 未命中所需的预期时间（以周期为单位）。\n设 $c = 4$ 个周期为缓存命中延迟，$m = 200$ 个周期为主存延迟。\n\n对于系统 A ($T_A$)：\n一次 TLB 未命中触发一次 PTE 读取。这次读取在数据缓存中命中的概率是 $q_A = 0.9$。预期惩罚是：\n$$\nT_A = q_A \\times c + (1 - q_A) \\times m = (0.9 \\times 4) + (0.1 \\times 200) = 3.6 + 20 = 23.6 \\text{ cycles}\n$$\n\n对于系统 B ($T_B$)：\n一次 TLB 未命中触发一次页表遍历，涉及 $4$ 次内存读取，页表树的每一级一次。每次读取都是一个独立事件，缓存命中概率为 $q_B = 0.95$。\n其中单次读取的预期时间是：\n$$\nT_{\\text{read, B}} = q_B \\times c + (1 - q_B) \\times m = (0.95 \\times 4) + (0.05 \\times 200) = 3.8 + 10 = 13.8 \\text{ cycles}\n$$\n由于总惩罚是 $4$ 次顺序读取的延迟之和，系统 B 的总预期惩罚为：\n$$\nT_B = 4 \\times T_{\\text{read, B}} = 4 \\times 13.8 = 55.2 \\text{ cycles}\n$$\nTLB 未命中惩罚比 $R_{\\text{tlb}}$ 为：\n$$\nR_{\\text{tlb}} = \\frac{T_B}{T_A} = \\frac{55.2}{23.6}\n$$\n\n**3. 复合度量 ($J$) 的计算**\n\n最后，我们计算复合度量 $J$：\n$$\nJ = R_{\\text{mem}} \\times R_{\\text{tlb}} = \\frac{1024}{515} \\times \\frac{55.2}{23.6}\n$$\n为了精确地进行此计算，我们可以使用分数以避免浮点表示错误。\n$$\nR_{\\text{tlb}} = \\frac{55.2}{23.6} = \\frac{552}{236} = \\frac{4 \\times 138}{4 \\times 59} = \\frac{138}{59}\n$$\n现在，将此代入 $J$ 的表达式中：\n$$\nJ = \\frac{1024}{515} \\times \\frac{138}{59} = \\frac{1024 \\times 138}{515 \\times 59} = \\frac{141312}{30385}\n$$\n现在我们计算数值：\n$$\nJ \\approx 4.65070923...\n$$\n问题要求将答案四舍五入到四位有效数字。前四位有效数字是 $4$、$6$、$5$ 和 $0$。第五位有效数字是 $7$，所以我们将第四位数字向上取整。\n$$\nJ \\approx 4.651\n$$", "answer": "$$\n\\boxed{4.651}\n$$", "id": "3646691"}, {"introduction": "硬件设计常常涉及成本与功能之间的权衡，有时一些特性会被简化或省略。本练习探讨了一种在某些RISC架构中常见的情景：操作系统必须通过软件来模拟硬件“访问位”（Accessed Bit）和“脏位”（Dirty Bit）的设置。通过量化这种软件模拟带来的性能开销，你将能更深刻地体会到硬件功能与操作系统性能之间的紧密联系。[@problem_id:3646722]", "problem": "一个$64$位的RISC-V系统实现了分页机制，但处理器不会在硬件中设置页表项（PTE）中的访问/脏（A/D）位。相反，处理器遵循广泛记载的行为：对PTE中访问位$A=0$的页面的任何访问都会引发页错误陷阱；对PTE中脏位$D=0$的页面的任何存储操作都会引发页错误陷阱（存储/原子页错误）。操作系统（OS）在陷阱处理程序中通过软件设置PTE位来模拟A/D位的更新，然后恢复出错的指令。处理程序使用错误原因（加载/存储/执行）来确定要设置哪些位，并且在处理存储错误时，在返回前同时设置$A$和$D$位，以便原始的存储操作能够完成而不会产生第二次陷阱。快表（TLB）由处理程序进行适当的更新，每次陷阱的成本，包括陷阱进入/返回以及任何页表和TLB维护，是一个恒定的$c$个时钟周期。假设一个假设的基准是一种硬件更新PTE的方案，该方案设置A/D位而不会引起陷阱，并且其额外成本对于本分析可以忽略不计。\n\n考虑一个进程在一个性能剖析窗口期间访问$N$个不同的虚拟页面。令：\n- $p_r$为这些页面中在窗口内只被读取（或执行）而从未被写入的页面的比例，\n- $p_{wr}$为这些页面中在窗口内先被读取，之后至少被写入一次的页面的比例，\n- $p_{ww}$为这些页面中首次访问是写入操作的页面的比例（它们也可能被读取，但首次访问是写入）。\n\n假设$p_r + p_{wr} + p_{ww} = 1$。对于每个页面，在窗口开始时，其PTE的$A=0$且$D=0$。\n\n从访问位（任何访问时设置）和脏位（写入时设置）的核心定义以及上述的陷阱行为出发，推导出在窗口期间相对于硬件更新PTE基准，这$N$个页面所产生的总额外时钟周期开销。你的推导应基于每个页面的首次访问和首次写入事件进行推理，确定在稳态访问（不再产生陷阱）之前，每个页面类别会产生多少次陷阱。将你的最终答案表示为一个以时钟周期为单位的、关于$N$、$p_{wr}$和$c$的单一简化闭式表达式。在你最终的方框答案中不要包含单位。", "solution": "这个问题是有效的，因为它在科学上基于操作系统和计算机体系结构的原理，特别是像页表项中访问位（Accessed）和脏位（Dirty）这类硬件特性的软件模拟。该问题提法明确、客观，并包含了推导出唯一解所需的所有信息。\n\n目标是确定通过软件模拟访问（A）和脏（D）位，相对于零成本的硬件基准所产生的总额外时钟周期开销。这个开销是页错误陷阱的总次数乘以每次陷阱的固定成本$c$。给定系统中要分析的有$N$个不同的页面。所有页面开始时其页表项（PTE）的状态都是访问位$A=0$和脏位$D=0$。\n\n我们必须分析每个页面类别产生的陷阱数量。页面总数为$N$，根据其访问模式分为三类。\n\n1.  **只读页面**：\n    只被读取或执行的页面比例为$p_r$。这类页面的数量是$N p_r$。\n    -   **首次访问**：对这些页面的首次访问是读取或执行操作。由于PTE初始时$A=0$，这次访问会触发一个页错误陷阱。\n    -   **陷阱处理**：操作系统的陷阱处理程序会识别出这是一个加载或指令提取错误。它会设置PTE中的访问位，因此状态变为$A=1$和$D=0$。\n    -   **后续访问**：由于这些页面从未被写入，所有后续访问都将是读取或执行操作。CPU此时会发现$A=1$，因此不会再为该页面产生任何陷阱。对于读取/执行访问，从不检查脏位。\n    -   **每页陷阱数**：每个只读页面恰好产生$1$次陷阱。\n\n2.  **先读后写页面**：\n    先被读取，之后再被写入的页面比例为$p_{wr}$。这类页面的数量是$N p_{wr}$。\n    -   **首次访问（读取）**：与只读情况类似，首次访问是对一个$A=0$的页面进行读取。这会触发一个页错误陷阱。\n    -   **陷阱处理（读取错误）**：处理程序将$A \\leftarrow 1$。PTE状态变为$A=1, D=0$。\n    -   **首次写入访问**：在稍后的某个时间点，对该页面的首次写入（存储）发生。此时PTE的状态是$A=1, D=0$。尝试的存储操作会检查脏位，发现$D=0$，从而触发一个存储页错误陷阱。\n    -   **陷阱处理（存储错误）**：问题描述指明，对于存储错误，处理程序会同时设置$A$和$D$位。PTE状态变为$A=1, D=1$。\n    -   **后续访问**：首次写入后，PTE为$A=1, D=1$。任何后续的读取/执行操作会发现$A=1$而不产生陷阱。任何后续的写入操作会发现$D=1$而不产生陷阱。\n    -   **每页陷阱数**：此类别中的每个页面因首次读取产生$1$次陷阱，因首次写入产生$1$次陷阱，总共产生$2$次陷阱。\n\n3.  **首次写入页面**：\n    首次访问是写入操作的页面比例为$p_{ww}$。这类页面的数量是$N p_{ww}$。\n    -   **首次访问（写入）**：首次访问是对一个初始PTE状态为$A=0, D=0$的页面进行写入。一个存储操作既构成一次“访问”（触发A位检查），也构成一次“存储”（触发D位检查）。问题澄清了结果：“在处理存储错误时，[处理程序]在返回前同时设置$A$和$D$位，以便原始的存储操作能够完成而不会产生第二次陷阱。” 这意味着对一个$A=0, D=0$的页面执行单个存储指令只会导致一次存储页错误陷阱。\n    -   **陷阱处理（存储错误）**：处理程序在收到存储错误后，会同时设置这两个位。新的PTE状态变为$A=1, D=1$。\n    -   **后续访问**：当PTE状态为$A=1, D=1$时，该页面不会再因任何类型的访问而产生陷阱。\n    -   **每页陷阱数**：此类别中的每个页面恰好产生$1$次陷阱。\n\n现在，我们可以通过对所有页面的陷阱数求和来计算总陷阱数$T_{total}$。\n-   来自只读页面的陷阱数：$(N p_r) \\times 1$。\n-   来自先读后写页面的陷阱数：$(N p_{wr}) \\times 2$。\n-   来自首次写入页面的陷阱数：$(N p_{ww}) \\times 1$。\n\n总陷阱数是它们的和：\n$$T_{total} = N p_r + 2 N p_{wr} + N p_{ww}$$\n$$T_{total} = N (p_r + 2 p_{wr} + p_{ww})$$\n\n题目要求我们用$N$、$p_{wr}$和$c$来表示结果。为此，我们必须使用给定的约束条件：$p_r + p_{wr} + p_{ww} = 1$来消除$p_r$和$p_{ww}$。\n我们可以通过拆分$2 p_{wr}$项来重写$T_{total}$的表达式：\n$$T_{total} = N (p_r + p_{wr} + p_{ww} + p_{wr})$$\n根据定义，括号中的表达式$(p_r + p_{wr} + p_{ww})$等于$1$。将此代入方程得到：\n$$T_{total} = N (1 + p_{wr})$$\n\n总的额外时钟周期开销$O$是总陷阱数乘以每次陷阱的成本$c$。\n$$O = T_{total} \\times c$$\n$$O = c N (1 + p_{wr})$$\n这就是以时钟周期为单位的总开销的最终简化闭式表达式。", "answer": "$$\n\\boxed{c N (1 + p_{wr})}\n$$", "id": "3646722"}]}