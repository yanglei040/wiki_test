{"hands_on_practices": [{"introduction": "基于结构的粗粒化方法旨在寻找一个能够再现已知结构特性（如径向分布函数 $g(r)$）的有效势。迭代玻尔兹曼反转（Iterative Boltzmann Inversion, IBI）方法是实现这一目标的一项基石技术。这个练习将通过一个解析问题，来检验你对核心IBI更新方程的理解。通过使用给定的目标分布和当前分布的解析函数，你可以将更新机制从运行完整模拟的复杂性中分离出来，从而巩固你对基本原理的掌握。[@problem_id:138327]", "problem": "对关联函数 $g(r)$，也称为径向分布函数，是统计力学中描述流体结构的核心物理量。在粗粒化方法中，研究者通常寻求一种有效的对势 $U(r)$，它可以在计算机模拟中复现一个已知的目标对关联函数 $g_{target}(r)$。迭代玻尔兹曼反演（IBI）方法是用于此目的的一种常用技术。\n\nIBI 算法通过迭代来优化势函数。从势函数的一个初始猜测 $U_0(r)$ 开始，通过模拟得到相应的对关联函数 $g_0(r)$。然后根据以下规则更新势函数：\n$$ U_{i+1}(r) = U_i(r) + k_B T \\ln\\left(\\frac{g_i(r)}{g_{target}(r)}\\right) $$\n其中 $i$ 是迭代次数，$k_B$ 是玻尔兹曼常数，$T$ 是绝对温度。\n\n考虑一个系统，其目标对关联函数由以下解析表达式给出：\n$$ g_{target}(r) = \\left(1 - \\exp\\left(-\\frac{r}{\\lambda}\\right)\\right) \\left( 1 + A \\exp\\left(-\\frac{(r-r_p)^2}{2w^2}\\right) \\right) $$\n在模拟中使用势函数的初始猜测 $U_{guess}(r)$，得到对关联函数为：\n$$ g_{guess}(r) = \\left(1 - \\exp\\left(-\\frac{r}{\\lambda}\\right)\\right) \\left( 1 + \\frac{A}{2} \\exp\\left(-\\frac{(r-r_p)^2}{2w^2}\\right) \\right) $$\n此处，$A$、$\\lambda$、$r_p$ 和 $w$ 均为正常数。\n\n使用 IBI 方法的第一步，计算在对应于结构特征峰值的特定径向距离 $r = r_p$ 处，对势函数的修正量 $\\Delta U(r) = U_1(r) - U_{guess}(r)$。请用 $k_B$、$T$ 和 $A$ 来表示你的答案。", "solution": "1. IBI 修正量：\n   $$\\Delta U(r)=k_B T\\ln\\frac{g_{\\text{guess}}(r)}{g_{\\text{target}}(r)}.$$\n2. 在 $r=r_p$ 处：\n   $$g_{\\text{target}}(r_p)=(1-e^{-r_p/\\lambda})(1+A),$$\n   $$g_{\\text{guess}}(r_p)=(1-e^{-r_p/\\lambda})\\Bigl(1+\\frac{A}{2}\\Bigr).$$\n3. 比值：\n   $$\\frac{g_{\\text{guess}}(r_p)}{g_{\\text{target}}(r_p)}\n     =\\frac{1+\\tfrac{A}{2}}{1+A}.$$\n4. 因此，\n   $$\\Delta U(r_p)=k_B T\\ln\\!\\Bigl(\\frac{1+\\tfrac{A}{2}}{1+A}\\Bigr).$$", "answer": "$$\\boxed{k_B T \\ln\\!\\Bigl(\\frac{1+\\tfrac{A}{2}}{1+A}\\Bigr)}$$", "id": "138327"}, {"introduction": "从理论走向实践，本练习要求你为键合势（如键角和二面角）实现IBI方法。在为聚合物或生物分子开发粗粒化模型时，这是一项常见且至关重要的任务。这个动手编程问题超越了简单的对势更新，要求你处理重要的实践细节，例如几何测量因子（$\\sin\\theta$）以及有界坐标与周期性坐标的不同拓扑结构。掌握这些细节对于构建精确、稳定的复杂分子粗粒化模型至关重要。[@problem_id:3438692]", "problem": "考虑一个在温度为$T$的正则系综中的粗粒化模型，其内坐标为一个键角 $\\theta \\in [0,\\pi]$ 和一个二面角 $\\phi \\in (-\\pi,\\pi]$。任务是推导并实现一个迭代玻尔兹曼反演 (IBI) 过程，从正则分布和平均力势的定义出发，根据预设的目标边缘分布 $P_{\\mathrm{target}}(\\theta)$ 和 $P_{\\mathrm{target}}(\\phi)$ 来参数化一维势 $U_\\theta(\\theta)$ 和 $U_\\phi(\\phi)$。推导必须从以下事实开始：在正则系综中，一个坐标 $\\xi$ 的一维边缘概率密度，其度量因子为 $m(\\xi)$，满足 $P(\\xi) \\propto m(\\xi)\\exp(-\\beta U(\\xi))$，其中 $\\beta = 1/(k_B T)$；平均力势的定义在一个加性常数内为 $U_{\\mathrm{PMF}}(\\xi) = -k_B T\\ln P(\\xi) + C$（当 $m(\\xi)=1$时），或者为 $U_{\\mathrm{PMF}}(\\xi) = -k_B T\\ln\\left(P(\\xi)/m(\\xi)\\right) + C$（当 $m(\\xi)\\neq 1$时）。对于键角，正确的度量因子是 $m(\\theta)=\\sin\\theta$，而对于二面角，度量因子是 $m(\\phi)=1$。仅使用这些基本陈述，推导一个适用于离散直方图的迭代更新规则，该规则调整 $U(\\xi)$ 以驱动模型分布趋向预设的目标分布 $P_{\\mathrm{target}}(\\xi)$，并解释如何包含以下几点：\n- $\\phi$ 在圆上的周期性（在 $\\pm\\pi$ 处环绕），\n- $\\theta \\in [0,\\pi]$ 具有非周期性边界的有界域，\n- $P_{\\mathrm{target}}(\\xi)$ 中的多峰性，同时不移动峰值位置，以及\n- $U(\\xi)$ 在一个加性常数内定义的规范自由度。\n你的实现必须包括受控的更新阻尼和平滑处理，且平滑处理需尊重域的拓扑结构（对 $\\phi$ 使用循环卷积，对 $\\theta$ 使用反射边界平滑）。\n\n你必须实现一个自包含的程序，对每个测试用例执行以下步骤，角度使用弧度，能量使用气体常数 $R$ 以 $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\mathrm{K}^{-1}$ 表示每摩尔的能量。使用 $R = 8.314462618\\times 10^{-3}\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\mathrm{K}^{-1}$ 和 $T=300\\,\\mathrm{K}$，因此每摩尔的 $k_B T$ 等于 $RT$。所有能量单位必须是 $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$。\n\n所有用例的离散化与数值方案：\n- 将 $\\theta$ 在 $[0,\\pi]$（含端点）上离散化为 $N_\\theta=181$ 个等间距点。\n- 将 $\\phi$ 在 $(-\\pi,\\pi]$ 上离散化为 $N_\\phi=360$ 个等间距点。\n- 初始化 $U_\\theta(\\theta)=0$ 和 $U_\\phi(\\phi)=0$。\n- 在每次迭代中，根据当前势能，使用带有正确度量因子的正则形式计算模型分布 $P_{\\mathrm{model}}(\\theta)$ 和 $P_{\\mathrm{model}}(\\phi)$，并将每个分布在离散化下归一化，使其积分为1。\n- 从第一性原理出发，推导并实现一个更新规则，该规则根据 $P_{\\mathrm{model}}(\\xi)$ 和 $P_{\\mathrm{target}}(\\xi)$ 之间的差异来增量调整 $U(\\xi)$，并带有一个标量阻尼因子 $\\alpha$ 和对更新场的平滑处理。平滑必须通过与一个尊重域拓扑结构的零均值核进行离散卷积来完成：对 $\\phi$ 使用循环包裹高斯核，对 $\\theta$ 使用反射边界高斯核。使用一个标准差以直方图箱为单位指定的离散高斯核。\n- 每次更新后，通过从 $U(\\xi)$ 中减去其在网格上的平均值来移除加性常数，从而使势能的均值为零；这固定了规范。\n- 迭代指定的次数 $N_{\\mathrm{iter}}$。\n\n为测试套件定义以下目标分布。在下面的所有定义中，在各自的网格上对目标分布进行数值归一化，使其在离散化下总和为1。\n\n- 角度目标 $P_{\\mathrm{target}}(\\theta)$ 定义为\n$$\nP_{\\mathrm{target}}(\\theta) \\propto \\sin\\theta \\sum_{i=1}^{M} w_i \\exp\\!\\left(-\\tfrac{1}{2}\\left(\\frac{\\theta-\\mu_i}{\\sigma_i}\\right)^2\\right),\n$$\n其中权重满足 $\\sum_i w_i = 1$，均值 $\\mu_i\\in[0,\\pi]$，宽度 $\\sigma_i>0$；$\\sin\\theta$ 因子考虑了几何度量。\n\n- 二面角目标 $P_{\\mathrm{target}}(\\phi)$ 使用三重循环 von Mises 型形式定义\n$$\nP_{\\mathrm{target}}(\\phi) \\propto \\exp\\!\\left(\\kappa \\cos(3\\phi)\\right),\n$$\n其中集中参数 $\\kappa\\ge 0$；当 $\\kappa=0$ 时，目标在圆上是均匀的。\n\n除非明确覆盖，所有用例均使用以下数值参数：阻尼因子 $\\alpha=0.25$，迭代次数 $N_{\\mathrm{iter}}=200$，平滑标准差 $\\sigma_{\\theta,\\mathrm{bins}}=1.25$ 箱（对于 $\\theta$）和 $\\sigma_{\\phi,\\mathrm{bins}}=1.50$ 箱（对于 $\\phi$）。在计算离散概率的对数时，使用一个小的下限值 $\\varepsilon=10^{-12}$ 以避免未定义值。\n\n测试套件。为以下四个独立的用例实现上述 IBI 过程，并为每个用例返回一个定量的标量结果：\n\n1.  用例A（角度，单峰，理想情况）：$\\mu_1=2.09439510239$（等于 $120^\\circ$ 的弧度值），$\\sigma_1=0.20$，$M=1$，$w_1=1$。计算最终模型分布与目标分布之间的离散均方根偏差，定义为\n    $$\n    E_A = \\sqrt{\\sum_{j=1}^{N_\\theta} \\left(P_{\\mathrm{model}}(\\theta_j) - P_{\\mathrm{target}}(\\theta_j)\\right)^2}.\n    $$\n    将 $E_A$ 报告为一个四舍五入到六位小数的十进制数（无量纲）。\n\n2.  用例B（二面角，三重多峰）：集中参数 $\\kappa=2.5$。计算类似的离散均方根偏差\n    $$\n    E_B = \\sqrt{\\sum_{j=1}^{N_\\phi} \\left(P_{\\mathrm{model}}(\\phi_j) - P_{\\mathrm{target}}(\\phi_j)\\right)^2}.\n    $$\n    将 $E_B$ 报告为一个四舍五入到六位小数的十进制数（无量纲）。确保更新和平滑处理能够处理周期性，从而在 $\\pm\\pi$ 处不会出现人为的边缘效应。\n\n3.  用例C（二面角，均匀边缘情况）：$\\kappa=0$。从零势能开始，目标是均匀分布。在完成指定迭代次数后，报告学习到的势能移除其均值后的标准差，\n    $$\n    S_C = \\sqrt{\\frac{1}{N_\\phi}\\sum_{j=1}^{N_\\phi}\\left(U_\\phi(\\phi_j) - \\overline{U_\\phi}\\right)^2},\n    $$\n    报告为一个四舍五入到六位小数的十进制数，单位为 $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$。对均匀目标的正确处理以及周期性平滑应能保持一个除去常数外平坦的势能。\n\n4.  用例D（角度，具有边界敏感性的双峰）：一个双峰目标，其中 $M=2$，权重 $(w_1,w_2)=(0.6,0.4)$，均值 $(\\mu_1,\\mu_2)=(0.15,2.99)$，宽度 $(\\sigma_1,\\sigma_2)=(0.08,0.06)$。计算类似于 $E_A$ 定义的角度分布均方根偏差 $E_D$，并将其报告为一个四舍五入到六位小数的十进制数（无量纲）。此用例旨在探测在 $\\theta=0$ 和 $\\theta=\\pi$ 附近的反射边界平滑效果，而不偏离峰值位置。\n\n最终输出规范：\n- 你的程序必须生成单行输出，包含一个逗号分隔的列表，用方括号括起来，顺序为 $[E_A,E_B,S_C,E_D]$。\n- 角度单位全程必须是弧度；能量单位必须是 $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$；报告的 $E_A$、$E_B$ 和 $E_D$ 是无量纲的；报告的 $S_C$ 单位必须是 $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$。所有四个值在最终输出字符串中必须四舍五入到六位小数。\n- 程序必须完全自包含，不需要任何输入。", "solution": "该问题要求推导并实现迭代玻尔兹曼反演 (IBI) 方法，以参数化键角 $\\theta$ 和二面角 $\\phi$ 的一维粗粒化势。推导和实现必须遵循统计力学原理和特定的数值方案。\n\n### 理论基础与推导\n\n该方法的基础在于正则系综的原理。对于一个广义坐标 $\\xi$，其概率分布 $P(\\xi)$ 通过玻尔兹曼分布与势能 $U(\\xi)$ 和一个度量因子（或雅可比行列式）$m(\\xi)$ 相关联：\n$$\nP(\\xi) = \\frac{1}{Z} m(\\xi) \\exp(-\\beta U(\\xi))\n$$\n其中 $\\beta = 1/(k_B T)$ 是逆温度，$Z = \\int m(\\xi') \\exp(-\\beta U(\\xi'))d\\xi'$ 是配分函数，作为一个归一化常数。键角的度量因子是 $m(\\theta) = \\sin\\theta$，考虑了球坐标系的雅可比行列式，而二面角的度量因子是 $m(\\phi)=1$。\n\n平均力势 (PMF) $U_{\\mathrm{PMF}}(\\xi)$ 被定义为能够精确再现给定概率分布 $P(\\xi)$ 的势。通过反演玻尔兹曼关系，我们可以在一个任意加性常数 $C$ 的范围内找到 PMF：\n$$\nU_{\\mathrm{PMF}}(\\xi) = -k_B T \\ln\\left(\\frac{P(\\xi)}{m(\\xi)}\\right) + C\n$$\nIBI 的目标是迭代地优化势的初始猜测 $U_0(\\xi)$，直到其对应的模型分布 $P_{\\mathrm{model}}(\\xi)$ 与预设的目标分布 $P_{\\mathrm{target}}(\\xi)$ 相匹配。\n\n设 $U_i(\\xi)$ 是第 $i$ 次迭代的势，$P_{\\mathrm{model},i}(\\xi)$ 是它生成的分布。IBI 过程通过增加一个修正项 $\\Delta U_i(\\xi)$ 来更新势：\n$$\nU_{i+1}(\\xi) = U_i(\\xi) + \\Delta U_i(\\xi)\n$$\n一个自然的选择是将修正项设为目标分布的 PMF $U_{\\mathrm{PMF,target}}(\\xi)$ 与当前模型分布的 PMF $U_{\\mathrm{PMF,model},i}(\\xi)$ 之间差异的一部分：\n$$\n\\Delta U_i(\\xi) = \\alpha \\left[ U_{\\mathrm{PMF,target}}(\\xi) - U_{\\mathrm{PMF,model},i}(\\xi) \\right]\n$$\n其中 $\\alpha$ 是一个阻尼因子 ($0  \\alpha \\le 1$)，用于控制更新步长并确保稳定性。代入 PMF 的定义：\n$$\n\\Delta U_i(\\xi) = \\alpha \\left[ \\left(-k_B T \\ln\\frac{P_{\\mathrm{target}}(\\xi)}{m(\\xi)}\\right) - \\left(-k_B T \\ln\\frac{P_{\\mathrm{model},i}(\\xi)}{m(\\xi)}\\right) \\right]\n$$\n$$\n\\Delta U_i(\\xi) = \\alpha k_B T \\left[ \\ln\\frac{P_{\\mathrm{model},i}(\\xi)}{m(\\xi)} - \\ln\\frac{P_{\\mathrm{target}}(\\xi)}{m(\\xi)} \\right]\n$$\n利用对数的性质 $\\ln a - \\ln b = \\ln(a/b)$，上式简化为：\n$$\n\\Delta U_i(\\xi) = \\alpha k_B T \\ln\\left(\\frac{P_{\\mathrm{model},i}(\\xi)}{P_{\\mathrm{target}}(\\xi)}\\right)\n$$\n这是核心的 IBI 更新法则。在离散形式中，对于箱 $j$ 并使用摩尔能量 $RT$ 代替 $k_B T$，对势 $U_i(\\xi_j)$ 的更新为：\n$$\n\\Delta U_i(\\xi_j) = \\alpha RT \\ln\\left(\\frac{P_{\\mathrm{model},i}(\\xi_j)}{P_{\\mathrm{target}}(\\xi_j)}\\right)\n$$\n\n### 算法实现与特性处理\n\n迭代过程在 $\\theta$ 和 $\\phi$ 的离散网格上作为数值算法实现。\n\n1.  **初始化**：创建 $\\theta$ 和 $\\phi$ 的网格，并将势 $U_\\theta$ 和 $U_\\phi$ 初始化为0。根据给定的公式计算目标分布 $P_{\\mathrm{target}}(\\theta)$ 和 $P_{\\mathrm{target}}(\\phi)$，并进行归一化，使其离散值之和为1。\n\n2.  **迭代优化**：算法迭代 $N_{\\mathrm{iter}}$ 步。在每次迭代 $i$ 中：\n    a.  根据当前势 $U_i(\\xi_j)$ 计算当前模型分布 $P_{\\mathrm{model},i}(\\xi_j)$，使用 $P_{\\mathrm{model},i}(\\xi_j) \\propto m(\\xi_j) \\exp(-U_i(\\xi_j)/RT)$ 并归一化使其总和为1。\n    b.  使用推导出的 IBI 法则计算原始势更新 $\\Delta U_i(\\xi_j)$。为防止因 $\\ln(0)$ 引起的数值错误，应用一个小的下限值 $\\varepsilon$，使得更新从 $\\ln(\\max(P, \\varepsilon))$ 计算。\n    c.  通过与一个归一化的、零均值的高斯核进行卷积，对原始更新场 $\\Delta U_i$ 进行平滑处理。这一关键步骤使势能正则化，防止噪声放大，并使势能保持平滑。\n    d.  将平滑后的更新 $\\Delta U_{i, \\text{smooth}}$ 加到势上：$U'(\\xi_j) = U_i(\\xi_j) + \\Delta U_{i, \\text{smooth}}(\\xi_j)$。\n    e.  通过确保势的均值为零来固定规范自由度：$U_{i+1}(\\xi_j) = U'(\\xi_j) - \\overline{U'}$。\n\n3.  **边界与域特定处理**：\n    -   **$\\phi$ 的周期性**：二面角 $\\phi$存在于一个圆上。为了尊重这种拓扑结构，使用**循环卷积**进行平滑。这可以通过使用快速傅里叶变换 (FFT) 的卷积定理高效实现。高斯核也被“包裹”到圆形域上。这防止了在 $\\pm\\pi$ 边界处产生人为的不连续性。\n    -   **$\\theta$ 的有界域**：键角 $\\theta$ 定义在一个有硬壁的、有界区间 $[0, \\pi]$ 上。在这些边界附近的平滑不能引入偏差。这通过对卷积使用**反射边界条件**来实现。在概念上，信号（势更新 $\\Delta U_i$）在边界处被镜像，然后再进行卷积，确保平滑后信号在边界处的梯度为零，从而防止人为地将特征（如概率峰）从边界移开。这通过在进行标准线性卷积之前，用反射值填充 $\\Delta U_i$ 数组来实现。\n    -   **多峰性**：IBI 更新本质上是局域的。它根据模型概率与目标概率在同一点 $\\xi_j$ 的比率来调整该点的势。这自然地塑造了势能，使其具有多个对应于 $P_{\\mathrm{target}}$ 中多个模式的能量阱，而不会人为地移动这些模式的位置。\n    -   **规范自由度**：一个势 $U(\\xi)$ 仅在一个加性常数内定义，因为 $U(\\xi)$ 和 $U(\\xi)+C$ 产生相同的力和相对概率。这种“规范自由度”通过在每次更新后强制 $\\overline{U(\\xi)} = 0$ 来固定，使得势唯一。\n\n这个全面的过程，结合了理论推导的 IBI 更新与数值上稳健的平滑和边界处理，允许从目标分布中准确而稳定地参数化势能。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import fft\n\ndef solve():\n    \"\"\"\n    Main function to derive coarse-grained potentials using Iterative Boltzmann\n    Inversion (IBI) and report the results for the specified test cases.\n    \"\"\"\n\n    # --- Global Constants and Parameters ---\n    R = 8.314462618e-3  # Gas constant in kJ/mol/K\n    T = 300.0          # Temperature in K\n    RT = R * T         # Molar thermal energy in kJ/mol\n    ALPHA = 0.25       # Damping factor\n    N_ITER = 200       # Number of iterations\n    EPS = 1e-12        # Small floor for logarithm arguments\n\n    # --- Discretization ---\n    N_THETA = 181\n    N_PHI = 360\n    theta_grid = np.linspace(0, np.pi, N_THETA)\n    phi_grid = np.linspace(-np.pi + 2 * np.pi / N_PHI, np.pi, N_PHI)\n\n    # --- Smoothing Parameters ---\n    SIGMA_THETA_BINS = 1.25\n    SIGMA_PHI_BINS = 1.50\n\n    def run_ibi(p_target, grid, measure_factor, sigma_bins, boundary_mode):\n        \"\"\"\n        Executes the Iterative Boltzmann Inversion procedure.\n\n        Args:\n            p_target (np.ndarray): The normalized target probability distribution.\n            grid (np.ndarray): The coordinate grid.\n            measure_factor (np.ndarray): The measure factor m(xi) for the coordinate.\n            sigma_bins (float): Standard deviation for Gaussian smoothing, in bin units.\n            boundary_mode (str): 'circular' or 'reflective'.\n\n        Returns:\n            tuple: Final potential (np.ndarray), final model distribution (np.ndarray).\n        \"\"\"\n        n_bins = len(grid)\n        u = np.zeros(n_bins)\n\n        # --- Setup Smoothing Kernel ---\n        if boundary_mode == 'circular':\n            # Create a wrapped Gaussian kernel for circular convolution\n            x = np.arange(n_bins)\n            dx = np.minimum(x, n_bins - x)\n            kernel = np.exp(-dx**2 / (2 * sigma_bins**2))\n            kernel /= np.sum(kernel)\n            kernel_fft = fft.fft(kernel)\n        elif boundary_mode == 'reflective':\n            # Create a standard Gaussian kernel for linear convolution\n            width = int(np.ceil(4 * sigma_bins))\n            x_ker = np.arange(-width, width + 1)\n            kernel = np.exp(-x_ker**2 / (2 * sigma_bins**2))\n            kernel /= np.sum(kernel)\n        else:\n            raise ValueError(\"Unsupported boundary mode.\")\n\n        # --- IBI Iteration Loop ---\n        for _ in range(N_ITER):\n            # 1. Compute model distribution from current potential U\n            p_model_unnormalized = measure_factor * np.exp(-u / RT)\n            p_sum = np.sum(p_model_unnormalized)\n            p_model = p_model_unnormalized / p_sum if p_sum > 0 else p_model_unnormalized\n\n            # 2. Compute the potential update\n            log_p_model = np.log(np.maximum(p_model, EPS))\n            log_p_target = np.log(np.maximum(p_target, EPS))\n            du = ALPHA * RT * (log_p_model - log_p_target)\n\n            # 3. Smooth the update field\n            if boundary_mode == 'circular':\n                du_fft = fft.fft(du)\n                du_smooth_fft = du_fft * kernel_fft\n                du_smooth = np.real(fft.ifft(du_smooth_fft))\n            elif boundary_mode == 'reflective':\n                pad_width = int(np.ceil(4 * sigma_bins))\n                left_pad = du[1:pad_width+1][::-1]\n                right_pad = du[-2:-pad_width-2:-1]\n                padded_du = np.concatenate([left_pad, du, right_pad])\n                du_smooth = np.convolve(padded_du, kernel, mode='valid')\n\n            # 4. Apply the smoothed update and fix the gauge\n            u += du_smooth\n            u -= np.mean(u)\n\n        # --- Final Calculation ---\n        p_model_unnormalized_final = measure_factor * np.exp(-u / RT)\n        p_sum_final = np.sum(p_model_unnormalized_final)\n        p_model_final = p_model_unnormalized_final / p_sum_final if p_sum_final > 0 else p_model_unnormalized_final\n            \n        return u, p_model_final\n\n    results = []\n\n    # === Case A: Angle, unimodal ===\n    mu_A = 2.09439510239\n    sigma_A = 0.20\n    p_target_un_A = np.sin(theta_grid) * np.exp(-0.5 * ((theta_grid - mu_A) / sigma_A)**2)\n    p_target_A = p_target_un_A / np.sum(p_target_un_A)\n    m_theta = np.sin(theta_grid)\n    _, p_model_A = run_ibi(p_target_A, theta_grid, m_theta, SIGMA_THETA_BINS, 'reflective')\n    e_A = np.linalg.norm(p_model_A - p_target_A)\n    results.append(f\"{e_A:.6f}\")\n\n    # === Case B: Dihedral, threefold ===\n    kappa_B = 2.5\n    p_target_un_B = np.exp(kappa_B * np.cos(3 * phi_grid))\n    p_target_B = p_target_un_B / np.sum(p_target_un_B)\n    m_phi = np.ones_like(phi_grid)\n    _, p_model_B = run_ibi(p_target_B, phi_grid, m_phi, SIGMA_PHI_BINS, 'circular')\n    e_B = np.linalg.norm(p_model_B - p_target_B)\n    results.append(f\"{e_B:.6f}\")\n\n    # === Case C: Dihedral, uniform ===\n    kappa_C = 0.0\n    p_target_un_C = np.exp(kappa_C * np.cos(3 * phi_grid)) # This is an array of ones\n    p_target_C = p_target_un_C / np.sum(p_target_un_C)\n    u_final_C, _ = run_ibi(p_target_C, phi_grid, m_phi, SIGMA_PHI_BINS, 'circular')\n    s_C = np.std(u_final_C)\n    results.append(f\"{s_C:.6f}\")\n\n    # === Case D: Angle, bimodal near boundaries ===\n    w_D = [0.6, 0.4]\n    mu_D = [0.15, 2.99]\n    sigma_D = [0.08, 0.06]\n    g1 = np.exp(-0.5 * ((theta_grid - mu_D[0]) / sigma_D[0])**2)\n    g2 = np.exp(-0.5 * ((theta_grid - mu_D[1]) / sigma_D[1])**2)\n    p_target_un_D = np.sin(theta_grid) * (w_D[0] * g1 + w_D[1] * g2)\n    p_target_D = p_target_un_D / np.sum(p_target_un_D)\n    _, p_model_D = run_ibi(p_target_D, theta_grid, m_theta, SIGMA_THETA_BINS, 'reflective')\n    e_D = np.linalg.norm(p_model_D - p_target_D)\n    results.append(f\"{e_D:.6f}\")\n    \n    # --- Final Output ---\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3438692"}, {"introduction": "参数化粗粒化模型的另一种强大思路是“力匹配”（force matching），该方法旨在最小化粗粒化模型中的力与参考全原子模拟中对应力之间的差异。这种方法直接连接了两个尺度的动力学。本练习将力匹配问题看作一个正则化线性回归问题，这一视角将物理建模与现代数据科学联系起来。你将实现吉洪诺夫正则化（Tikhonov regularization）并使用K折交叉验证来选择最优模型，从而学习如何构建具有预测性且稳健的模型，同时避免过拟合——这在任何数据驱动的科学领域都是一项关键技能。[@problem_id:3438724]", "problem": "您将处理一个以无量纲约化单位表示的粗粒化力匹配任务。在基于全原子（AA）模拟的材料粗粒化（CG）建模中，通常将粗粒化力近似为在粗粒化坐标上求值的一组基函数的线性组合。令 $\\mathbf{R}_{t} \\in \\mathbb{R}^{d}$ 表示离散时间 $t$ 时的粗粒化坐标，令 $F^{\\mathrm{AA}\\rightarrow \\mathrm{CG}}_{t} \\in \\mathbb{R}$ 表示映射的全原子力沿选定粗粒化坐标的标量分量。考虑一组基函数 $\\{\\phi_{k}(\\mathbf{R})\\}_{k=1}^{K}$，并假设粗粒化力参数化为 $F^{\\mathrm{CG}}(\\mathbf{R};\\boldsymbol{\\theta}) = \\sum_{k=1}^{K} \\theta_{k}\\,\\phi_{k}(\\mathbf{R})$，其中 $\\boldsymbol{\\theta}\\in\\mathbb{R}^{K}$ 是待推断的未知系数。\n\n从最小二乘法原理和 Tikhonov 正则化出发，定义并最小化一个平衡数据拟合与参数大小的目标函数。构建设计矩阵，使其行对应于样本 $t$，列对应于基函数 $k$。推导最小化器的平稳性条件，并实现一个解决方案，该方案能针对给定的正则化强度 $\\lambda$ 返回 $\\boldsymbol{\\theta}$。解释并实现使用 $K$ 折交叉验证选择 $\\lambda$ 以避免过拟合的方法，包括明确的平局打破规则。所有计算均应在无量纲约化单位下进行。\n\n您必须实现一个单一程序，该程序能够：\n- 根据提供的基函数和样本坐标构建设计矩阵。\n- 使用 Tikhonov 正则化求解 $\\boldsymbol{\\theta}$，其中候选 $\\lambda$ 值通过 $K$ 折交叉验证选出，以最小化平均验证均方误差。\n- 若平均验证误差出现精确相等（在机器精度范围内），则选择最小的 $\\lambda$。\n- 按如下规定，生成单行输出，汇总所有测试用例的结果。\n\n使用以下三个测试用例组成的测试套件，所有用例均采用无量纲约化单位（即无需进行物理单位转换）：\n\n用例 A（良态，留一法）：\n- 基函数：$\\phi_{1}(\\mathbf{R})=1$, $\\phi_{2}(\\mathbf{R})=R$, $\\phi_{3}(\\mathbf{R})=R^{2}$。\n- 真实参数：$\\boldsymbol{\\theta}^{\\mathrm{true}}=[0.4,-1.5,0.7]$。\n- 样本：$R_{t}\\in\\mathbb{R}$，其值为 $[-1.0,-0.5,0.0,0.5,1.0]$。\n- 确定性残差：$\\delta(R)=0.01\\sin(\\pi R)$。\n- 目标值：$F^{\\mathrm{AA}\\rightarrow \\mathrm{CG}}_{t}=\\sum_{k}\\theta^{\\mathrm{true}}_{k}\\,\\phi_{k}(R_{t})+\\delta(R_{t})$。\n- 候选正则化参数：$\\lambda\\in[0.0,10^{-6},10^{-3},10^{-2},10^{-1}]$。\n- 折数：$K=5$。\n\n用例 B（近似共线性基，中等 $K$ 值）：\n- 基函数：$\\phi_{1}(\\mathbf{R})=1$, $\\phi_{2}(\\mathbf{R})=R$, $\\phi_{3}(\\mathbf{R})=R+10^{-8}$。\n- 真实参数：$\\boldsymbol{\\theta}^{\\mathrm{true}}=[1.0,0.5,-0.5]$。\n- 样本：$R_{t}\\in\\mathbb{R}$，其值为 $[-1.0,-0.75,-0.5,-0.25,0.0,0.25,0.5,0.75,1.0]$。\n- 确定性残差：$\\delta(R)=0.02\\sin(\\pi R)$。\n- 目标值：$F^{\\mathrm{AA}\\rightarrow \\mathrm{CG}}_{t}=\\sum_{k}\\theta^{\\mathrm{true}}_{k}\\,\\phi_{k}(R_{t})+\\delta(R_{t})$。\n- 候选正则化参数：$\\lambda\\in[10^{-6},10^{-4},10^{-2},10^{-1},1.0]$。\n- 折数：$K=3$。\n\n用例 C（欠定系统，强正则化）：\n- 基函数：$\\phi_{1}(\\mathbf{R})=1$, $\\phi_{2}(\\mathbf{R})=R$, $\\phi_{3}(\\mathbf{R})=R^{2}$。\n- 真实参数：$\\boldsymbol{\\theta}^{\\mathrm{true}}=[-0.2,0.5,0.3]$。\n- 样本：$R_{t}\\in\\mathbb{R}$，其值为 $[-0.2,0.8]$。\n- 确定性残差：$\\delta(R)=0.05\\sin(\\pi R)$。\n- 目标值：$F^{\\mathrm{AA}\\rightarrow \\mathrm{CG}}_{t}=\\sum_{k}\\theta^{\\mathrm{true}}_{k}\\,\\phi_{k}(R_{t})+\\delta(R_{t})$。\n- 候选正则化参数：$\\lambda\\in[10^{-3},10^{-2},10^{-1},1.0]$。\n- 折数：$K=2$。\n\n算法要求：\n- 对每个用例，在候选 $\\lambda$ 上执行 $K$ 折交叉验证，以选择最小化平均验证均方误差的 $\\lambda$。\n- 使用选定的 $\\lambda$ 对完整数据集进行拟合以得到 $\\boldsymbol{\\theta}$。\n- 如果给定 $\\lambda$ 的线性系统是病态或奇异的，请使用数值稳定的求解器（如伪逆）来获取 $\\boldsymbol{\\theta}$。\n\n输出规范：\n- 对每个用例，输出一个列表，其中包含选定的 $\\lambda$（浮点数）、平均验证均方误差（浮点数），随后是拟合的 $\\boldsymbol{\\theta}$ 的各项分量（按顺序）。\n- 您的程序应生成单行输出，其中包含三个测试用例的结果，格式为一个逗号分隔的列表，并用方括号括起。列表中的每个元素是上述的单个用例列表，例如 $[[\\lambda_{A},\\mathrm{MSE}_{A},\\theta^{A}_{1},\\theta^{A}_{2},\\theta^{A}_{3}],[\\lambda_{B},\\mathrm{MSE}_{B},\\theta^{B}_{1},\\theta^{B}_{2},\\theta^{B}_{3}],[\\lambda_{C},\\mathrm{MSE}_{C},\\theta^{C}_{1},\\theta^{C}_{2},\\theta^{C}_{3}]]$.\n\n角度单位：残差定义中的所有角度均使用弧度。任何地方都不使用百分比；任何比率都应以小数形式返回。所有量均为无量纲约化单位。\n\n确保科学真实性并从第一性原理出发实现：从最小二乘法和正则化开始，显式构建设计矩阵，推导最小化器的一阶最优性条件，并实现基于验证误差的 $K$ 折交叉验证来选择 $\\lambda$。问题陈述本身不提供超出这些原理的公式。", "solution": "问题在于，通过拟合映射的全原子（AA）力数据，来确定最优的粗粒化（CG）力参数 $\\boldsymbol{\\theta}$。粗粒化力 $F^{\\mathrm{CG}}$ 被建模为在粗粒化坐标 $\\mathbf{R}$ 上求值的 $K$ 个基函数 $\\phi_k(\\mathbf{R})$ 的线性组合。\n\n该模型由下式给出：\n$$F^{\\mathrm{CG}}(\\mathbf{R};\\boldsymbol{\\theta}) = \\sum_{k=1}^{K} \\theta_{k}\\,\\phi_{k}(\\mathbf{R})$$\n其中 $\\boldsymbol{\\theta} = [\\theta_1, \\theta_2, \\dots, \\theta_K]^T$ 是未知系数的向量。\n\n给定一组包含 $N$ 个离散时间样本的数据集，在每个时间 $t$，我们有粗粒化坐标 $\\mathbf{R}_t$ 和目标映射力 $y_t = F^{\\mathrm{AA}\\rightarrow \\mathrm{CG}}_{t}$，我们可以用矩阵形式表示此问题。令 $\\mathbf{y} \\in \\mathbb{R}^{N}$ 为目标力向量，令 $\\mathbf{\\Phi}$ 为 $N \\times K$ 的设计矩阵，其中每个元素 $\\Phi_{tk} = \\phi_k(\\mathbf{R}_t)$。那么所有样本的预测力向量为 $\\hat{\\mathbf{y}} = \\mathbf{\\Phi}\\boldsymbol{\\theta}$。\n\n最小二乘法原理旨在通过最小化残差平方和来找到 $\\boldsymbol{\\theta}$，即目标力与预测力之差的欧几里得范数的平方：\n$$J_{\\text{LS}}(\\boldsymbol{\\theta}) = \\sum_{t=1}^{N} (y_t - \\hat{y}_t)^2 = ||\\mathbf{y} - \\mathbf{\\Phi}\\boldsymbol{\\theta}||_2^2$$\n\n为防止过拟合并处理设计矩阵导致病态或奇异系统的情况（例如，基函数近似共线或 $N  K$ 的欠定系统），我们引入 Tikhonov 正则化。这会在目标函数中增加一个惩罚项，该项与参数向量的模平方成正比，由正则化强度参数 $\\lambda \\ge 0$ 控制。新的目标函数是：\n$$J(\\boldsymbol{\\theta}) = ||\\mathbf{y} - \\mathbf{\\Phi}\\boldsymbol{\\theta}||_2^2 + \\lambda ||\\boldsymbol{\\theta}||_2^2$$\n这也称为岭回归。\n\n为找到使 $J(\\boldsymbol{\\theta})$ 最小化的最优参数向量 $\\hat{\\boldsymbol{\\theta}}$，我们通过对 $J(\\boldsymbol{\\theta})$ 关于 $\\boldsymbol{\\theta}$ 求梯度并令其为零来找到平稳性条件。\n展开目标函数：\n$$J(\\boldsymbol{\\theta}) = (\\mathbf{y} - \\mathbf{\\Phi}\\boldsymbol{\\theta})^T(\\mathbf{y} - \\mathbf{\\Phi}\\boldsymbol{\\theta}) + \\lambda \\boldsymbol{\\theta}^T\\mathbf{I}\\boldsymbol{\\theta} = \\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\theta}^T\\mathbf{\\Phi}^T\\mathbf{y} + \\boldsymbol{\\theta}^T\\mathbf{\\Phi}^T\\mathbf{\\Phi}\\boldsymbol{\\theta} + \\lambda \\boldsymbol{\\theta}^T\\mathbf{I}\\boldsymbol{\\theta}$$\n$$J(\\boldsymbol{\\theta}) = \\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\theta}^T\\mathbf{\\Phi}^T\\mathbf{y} + \\boldsymbol{\\theta}^T(\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I})\\boldsymbol{\\theta}$$\n关于 $\\boldsymbol{\\theta}$ 的梯度是：\n$$\\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta}) = -2\\mathbf{\\Phi}^T\\mathbf{y} + 2(\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I})\\boldsymbol{\\theta}$$\n将梯度设为零，$\\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta}) = \\mathbf{0}$，得到正则化系统的正规方程：\n$$(\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I})\\boldsymbol{\\theta} = \\mathbf{\\Phi}^T\\mathbf{y}$$\n$\\boldsymbol{\\theta}$ 的解是：\n$$\\hat{\\boldsymbol{\\theta}} = (\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I})^{-1} \\mathbf{\\Phi}^T\\mathbf{y}$$\n对于 $\\lambda > 0$，矩阵 $(\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I})$ 保证是可逆的，即使对于不适定问题也能提供唯一解。问题陈述要求使用数值稳定的求解器，这对于病态矩阵至关重要。我们将求解线性系统 $A\\boldsymbol{x}=\\boldsymbol{b}$，其中 $A = \\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I}$ 且 $\\boldsymbol{b} = \\mathbf{\\Phi}^T\\mathbf{y}$。\n\n$\\lambda$ 的选择至关重要：如果 $\\lambda$ 太小，模型可能会过拟合；如果太大，则可能欠拟合。我们采用 $K$ 折交叉验证从候选列表中选择一个最优的 $\\lambda$。流程如下：\n1. 将包含 $N$ 个样本的数据集划分为 $K$ 个大小近似相等的互斥子集（折）。\n2. 对每个候选的 $\\lambda$ 值：\n    a. 将平均验证误差初始化为零。\n    b. 对每一折 $k \\in \\{1, \\dots, K\\}$：\n        i. 将第 $k$ 折指定为验证集。剩下的 $K-1$ 折合并成训练集。\n        ii. 使用训练数据和当前的 $\\lambda$ 拟合模型参数 $\\boldsymbol{\\theta}_{\\text{train}}$。\n        iii. 使用拟合好的模型预测验证集中每个样本的力。\n        iv. 计算验证集上的均方误差（MSE）：$\\text{MSE}_k(\\lambda) = \\frac{1}{N_k} ||\\mathbf{y}_{\\text{val}} - \\mathbf{\\Phi}_{\\text{val}}\\boldsymbol{\\theta}_{\\text{train}}||_2^2$，其中 $N_k$ 是第 $k$ 折中的样本数。\n    c. 计算 $\\lambda$ 的平均验证误差为 $\\overline{\\text{MSE}}(\\lambda) = \\frac{1}{K} \\sum_{k=1}^{K} \\text{MSE}_k(\\lambda)$。\n3. 选择使 $\\overline{\\text{MSE}}(\\lambda)$ 最小化的正则化强度作为最优值 $\\lambda^*$。问题指定了平局打破规则：如果多个 $\\lambda$ 值产生相同的最小 $\\overline{\\text{MSE}}$（在机器精度范围内），则选择最小的 $\\lambda$。\n4. 最后，使用选定的 $\\lambda^*$ 在整个数据集上进行训练，以获得最终的模型参数 $\\boldsymbol{\\theta}_{\\text{final}}$。\n\n对三个测试用例中的每一个都执行此完整流程。实现过程为每个用例构建设计矩阵 $\\mathbf{\\Phi}$ 和目标向量 $\\mathbf{y}$，执行 $K$ 折交叉验证以找到 $\\lambda^*$，然后计算最终的 $\\boldsymbol{\\theta}_{\\text{final}}$。结果包括 $\\lambda^*$、对应的最小平均验证 MSE 以及 $\\boldsymbol{\\theta}_{\\text{final}}$ 的分量，这些结果将按照输出规范进行汇总和格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the coarse-grained force-matching problem for three test cases,\n    using Tikhonov regularization with lambda selected by K-fold cross-validation.\n    \"\"\"\n\n    # Case A: Well-conditioned, leave-one-out\n    R_A = np.array([-1.0, -0.5, 0.0, 0.5, 1.0])\n    theta_true_A = np.array([0.4, -1.5, 0.7])\n    basis_A = [lambda R: 1.0, lambda R: R, lambda R: R**2]\n    delta_A = lambda R: 0.01 * np.sin(np.pi * R)\n    phi_matrix_A = np.array([[func(r) for func in basis_A] for r in R_A])\n    y_A = phi_matrix_A @ theta_true_A + delta_A(R_A)\n    lambdas_A = [0.0, 1e-6, 1e-3, 1e-2, 1e-1]\n    K_A = 5\n\n    # Case B: Nearly collinear basis, moderate K\n    R_B = np.linspace(-1.0, 1.0, 9)\n    theta_true_B = np.array([1.0, 0.5, -0.5])\n    basis_B = [lambda R: 1.0, lambda R: R, lambda R: R + 1e-8]\n    delta_B = lambda R: 0.02 * np.sin(np.pi * R)\n    phi_matrix_B = np.array([[func(r) for func in basis_B] for r in R_B])\n    y_B = phi_matrix_B @ theta_true_B + delta_B(R_B)\n    lambdas_B = [1e-6, 1e-4, 1e-2, 1e-1, 1.0]\n    K_B = 3\n\n    # Case C: Underdetermined system, strict regularization\n    R_C = np.array([-0.2, 0.8])\n    theta_true_C = np.array([-0.2, 0.5, 0.3])\n    basis_C = [lambda R: 1.0, lambda R: R, lambda R: R**2]\n    delta_C = lambda R: 0.05 * np.sin(np.pi * R)\n    phi_matrix_C = np.array([[func(r) for func in basis_C] for r in R_C])\n    y_C = phi_matrix_C @ theta_true_C + delta_C(R_C)\n    lambdas_C = [1e-3, 1e-2, 1e-1, 1.0]\n    K_C = 2\n\n    test_cases = [\n        (phi_matrix_A, y_A, lambdas_A, K_A),\n        (phi_matrix_B, y_B, lambdas_B, K_B),\n        (phi_matrix_C, y_C, lambdas_C, K_C),\n    ]\n\n    results = []\n    \n    for Phi, y_targets, lambdas, K_folds in test_cases:\n        num_samples, num_basis = Phi.shape\n        indices = np.arange(num_samples)\n        \n        # We need to handle numpy's deprecation warning for ragged arrays\n        # by creating a list of arrays instead of a single object-dtype array\n        if num_samples % K_folds == 0:\n            fold_indices = np.split(indices, K_folds)\n        else:\n            # np.array_split is more general\n            fold_indices = np.array_split(indices, K_folds)\n\n        avg_mses = []\n\n        for lam in lambdas:\n            fold_mses = []\n            for i in range(K_folds):\n                val_idx = fold_indices[i]\n                train_idx = np.concatenate([fold_indices[j] for j in range(K_folds) if i != j])\n                \n                Phi_train, y_train = Phi[train_idx], y_targets[train_idx]\n                Phi_val, y_val = Phi[val_idx], y_targets[val_idx]\n                \n                A = Phi_train.T @ Phi_train + lam * np.identity(num_basis)\n                b = Phi_train.T @ y_train\n                \n                try:\n                    theta_train = np.linalg.solve(A, b)\n                except np.linalg.LinAlgError:\n                    # Fallback to pseudoinverse for singular matrix (e.g., lambda=0)\n                    theta_train = np.linalg.pinv(A) @ b\n\n                y_pred_val = Phi_val @ theta_train\n                mse = np.mean((y_val - y_pred_val)**2)\n                fold_mses.append(mse)\n            \n            avg_mses.append(np.mean(fold_mses))\n\n        # Select best lambda with tie-breaking\n        min_mse = np.min(avg_mses)\n        best_lambda_candidates = [lam for lam, mse in zip(lambdas, avg_mses) if np.isclose(mse, min_mse)]\n        best_lambda = min(best_lambda_candidates)\n        \n        # Retrieve the MSE for the selected lambda\n        best_avg_mse = avg_mses[lambdas.index(best_lambda)]\n\n        # Final fit on all data with the best lambda\n        A_final = Phi.T @ Phi + best_lambda * np.identity(num_basis)\n        b_final = Phi.T @ y_targets\n        try:\n            theta_final = np.linalg.solve(A_final, b_final)\n        except np.linalg.LinAlgError:\n            theta_final = nplinalg.pinv(A_final) @ b_final\n\n        case_result = [best_lambda, best_avg_mse] + theta_final.tolist()\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3438724"}]}