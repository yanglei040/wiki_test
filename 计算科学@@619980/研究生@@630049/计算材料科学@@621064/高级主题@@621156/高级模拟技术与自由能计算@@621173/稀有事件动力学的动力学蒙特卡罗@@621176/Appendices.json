{"hands_on_practices": [{"introduction": "任何动力学蒙特卡罗（KMC）模拟的准确性都从根本上取决于其输入事件速率的质量。本练习将理论与实践相结合，指导您使用谐波过渡态理论（Harmonic Transition State Theory, TST）计算这些关键速率，从而在第一性原理计算（如密度泛函理论）和介观尺度的KMC模型之间架起桥梁。通过实现Vineyard公式并分析速率对输入参数误差的敏感性，您将深入理解KMC模拟的基础物理输入及其不确定性来源 [@problem_id:3459864]。", "problem": "固体中的一个罕见事件被建模为在由密度泛函理论 (DFT) 计算的势能面上，振动极小点和一阶鞍点（过渡态）之间的热激活跃迁。动力学蒙特卡洛 (KMC) 需要跃迁速率作为温度的函数，以便在长时间尺度上传播系统。从经典过渡态理论和对驻点周围振动运动的谐振近似出发，推导、实现并评估单个罕见事件的跃迁速率。然后分析该速率对振动频率和活化能垒误差的灵敏度。\n\n假设与要求：\n- 经典谐振近似在极小点和过渡态周围均成立。\n- 过渡态恰好有一个不稳定模式，该模式被排除在实振动频率集合之外。\n- 提供了极小点和过渡态的振动简正模式频率，并应将其解释为以太赫兹 (THz) 为单位的常规频率，而非角频率。\n- 活化能垒以电子伏特 (eV) 为单位，是过渡态和极小点之间的总能量差。\n- 使用玻尔兹曼常数 $k_{\\mathrm{B}} = 8.617333262145\\times 10^{-5}\\ \\mathrm{eV/K}$。\n- 通过 $1\\ \\mathrm{THz} = 10^{12}\\ \\mathrm{s^{-1}}$ 将太赫兹转换为赫兹。\n- 跃迁速率 $k(T)$ 必须以 $\\mathrm{s^{-1}}$ 为单位表示，并在最终输出中四舍五入到六位有效数字。\n\n任务：\n1. 仅使用基本统计力学和谐振近似，推导跃迁速率 $k(T)$ 的显式表达式，该表达式用极小点和过渡态的振动频率（不包括不稳定模式）以及活化能垒 $\\Delta E$ 来表示，并在代码中实现它。\n2. 定义一个均匀乘性频率偏差 $(1+\\epsilon_{\\nu})$，该偏差同样应用于极小点和过渡态的所有振动频率，以及一个加性能力误差 $\\epsilon_{E}$，该误差加到 $\\Delta E$上。对于下述每个测试用例，计算以下量：\n   - 基准速率 $k(T)$，单位为 $\\mathrm{s^{-1}}$。\n   - 频率偏差灵敏度因子 $R_{\\nu} = k(T;\\ (1+\\epsilon_{\\nu})\\times\\{\\nu\\},\\ \\Delta E)\\big/ k(T;\\ \\{\\nu\\},\\ \\Delta E)$。\n   - 能垒误差灵敏度因子 $R_{E} = k(T;\\ \\{\\nu\\},\\ \\Delta E+\\epsilon_{E})\\big/ k(T;\\ \\{\\nu\\},\\ \\Delta E)$。\n   - 速率对均匀频率缩放因子的对数灵敏度，$S_{\\mathrm{scale}} = \\dfrac{\\partial \\ln k}{\\partial \\ln s}\\bigg|_{s=1}$，其中 $s$ 乘以两个驻点上的每个振动频率。\n   - 速率对能垒的对数灵敏度，$S_{E} = \\dfrac{\\partial \\ln k}{\\partial \\Delta E}$，单位为 $\\mathrm{eV^{-1}}$。\n3. 所有最终数值输出必须是浮点数。将 $k(T)$ 以 $\\mathrm{s^{-1}}$ 表示，$R_{\\nu}$ 和 $R_{E}$ 为无量纲比率，$S_{\\mathrm{scale}}$ 为无量纲，$S_{E}$ 以 $\\mathrm{eV^{-1}}$ 表示。\n\n测试套件：\n所有用例使用相同的振动数据集。极小点有 $6$ 个实模式，过渡态在排除单个不稳定模式后有 $5$ 个实模式。频率以 $\\mathrm{THz}$ 给出：\n- 极小点频率：$\\{3.2,\\, 5.1,\\, 7.0,\\, 8.4,\\, 10.0,\\, 12.3\\}$。\n- 过渡态频率（仅实频）：$\\{2.9,\\, 4.7,\\, 6.5,\\, 7.9,\\, 11.5\\}$。\n\n四个测试用例是元组 $(\\Delta E\\ \\mathrm{[eV]},\\ T\\ \\mathrm{[K]},\\ \\epsilon_{\\nu}\\ \\mathrm{[dimensionless]},\\ \\epsilon_{E}\\ \\mathrm{[eV]})$：\n- 用例 1：$(0.6,\\ 500,\\ 0.05,\\ 0.05)$\n- 用例 2：$(0.6,\\ 200,\\ 0.05,\\ 0.05)$\n- 用例 3：$(0.6,\\ 1200,\\ 0.05,\\ 0.05)$\n- 用例 4：$(0.05,\\ 500,\\ 0.05,\\ 0.05)$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个各用例结果的列表，每个用例的结果是包含五个浮点数的列表，顺序为 $[k(T),\\ R_{\\nu},\\ R_{E},\\ S_{\\mathrm{scale}},\\ S_{E}]$。\n- 每个浮点数必须四舍五入到六位有效数字。\n- 最终的单行必须是有效的 Python 风格列表字面量，例如：$[[a_1,b_1,c_1,d_1,e_1],[a_2,b_2,c_2,d_2,e_2],\\ldots]$。", "solution": "我们将单个罕见事件建模为势能面上振动极小点和一阶鞍点之间的能垒穿越。动力学蒙特卡洛 (KMC) 需要跃迁速率作为输入，我们通过谐振近似下的经典过渡态理论 (TST) 获得该速率。\n\n基本出发点：在经典 TST 中，速率常数由穿过位于过渡态的分隔面的反应通量给出。在谐振近似中，驻点附近的局域动力学由独立的谐振子描述，其频率源自 Hessian 矩阵（质量加权的二阶导数矩阵）。一组 $n$ 个经典谐振模式的正则配分函数在温度 $T$ 下，其频率为 $\\{\\nu_{i}\\}$，当从完整的量子表达式出发并取高温经典极限时，除了一个与频率无关的乘法常数外，与 $\\prod_{i=1}^{n} \\frac{k_{\\mathrm{B}} T}{h \\nu_{i}}$ 成正比，或者等效地，当常数在分子和分母之间抵消时，配分函数的比率简化为频率乘积的比率。在过渡态，一个不稳定（虚）模式被排除在对分隔面配分函数有贡献的实振动模式集合之外。\n\n基于这些基础，经典谐振 TST 速率的 Vineyard 形式得以出现，它通过计算极小点和过渡态（不包括不稳定模式）之间的谐振配分函数之比，并乘以考虑了活化能垒的玻尔兹曼因子。得到的速率常数为\n$$\nk(T) \\;=\\; \\left(\\frac{\\prod_{i=1}^{N_{\\min}} \\nu^{\\min}_{i}}{\\prod_{j=1}^{N_{\\mathrm{ts}}} \\nu^{\\mathrm{ts}}_{j}}\\right) \\exp\\!\\left(-\\frac{\\Delta E}{k_{\\mathrm{B}} T}\\right),\n$$\n其中 $N_{\\min}$ 是极小点处的实振动模式数，$N_{\\mathrm{ts}}$ 是过渡态在排除不稳定模式后的实振动模式数，$\\nu_{i}^{\\min}$ 是极小点频率，$\\nu_{j}^{\\mathrm{ts}}$ 是过渡态的实频率，$k_{\\mathrm{B}}$ 是玻尔兹曼常数，$\\Delta E$ 是活化能垒。这里的频率是普通频率，单位为 $\\mathrm{s^{-1}}$（不是角频率），指前因子带有 $\\mathrm{s^{-1}}$ 的单位，因为对于一阶鞍点，$N_{\\min} - N_{\\mathrm{ts}} = 1$，这确保了乘积之比具有时间倒数的单位。\n\n对均匀频率缩放因子的灵敏度：考虑将两个驻点的每个振动频率都乘以一个共同因子 $s>0$，即 $\\nu \\mapsto s \\nu$。指前因子随之缩放为\n$$\n\\frac{\\prod_{i=1}^{N_{\\min}} (s \\nu^{\\min}_{i})}{\\prod_{j=1}^{N_{\\mathrm{ts}}} (s \\nu^{\\mathrm{ts}}_{j})}\n= s^{N_{\\min} - N_{\\mathrm{ts}}} \\left(\\frac{\\prod_{i=1}^{N_{\\min}} \\nu^{\\min}_{i}}{\\prod_{j=1}^{N_{\\mathrm{ts}}} \\nu^{\\mathrm{ts}}_{j}}\\right).\n$$\n对于一阶鞍点，$N_{\\min} - N_{\\mathrm{ts}} = 1$，因此指前因子以及速率与 $s$ 呈线性关系。因此，对均匀频率缩放因子的对数灵敏度为\n$$\nS_{\\mathrm{scale}} \\;\\equiv\\; \\frac{\\partial \\ln k}{\\partial \\ln s} \\;=\\; N_{\\min} - N_{\\mathrm{ts}} \\;=\\; 1.\n$$\n\n对能垒的灵敏度：对能垒的依赖性通过玻尔兹曼因子体现，\n$$\n\\ln k(T) \\;=\\; \\ln\\!\\left(\\frac{\\prod_{i=1}^{N_{\\min}} \\nu^{\\min}_{i}}{\\prod_{j=1}^{N_{\\mathrm{ts}}} \\nu^{\\mathrm{ts}}_{j}}\\right) \\;-\\; \\frac{\\Delta E}{k_{\\mathrm{B}} T}.\n$$\n对 $\\Delta E$ 求导，得到对数灵敏度\n$$\nS_{E} \\;\\equiv\\; \\frac{\\partial \\ln k}{\\partial \\Delta E} \\;=\\; -\\,\\frac{1}{k_{\\mathrm{B}} T},\n$$\n当 $\\Delta E$ 以电子伏特表示且 $k_{\\mathrm{B}} T$ 也以电子伏特表示时，其单位为 $\\mathrm{eV^{-1}}$。\n\n有限误差因子：对于应用于所有频率的均匀乘性频率偏差 $(1+\\epsilon_{\\nu})$，有限灵敏度因子为\n$$\nR_{\\nu} \\;\\equiv\\; \\frac{k(T;\\ (1+\\epsilon_{\\nu})\\times\\{\\nu\\},\\ \\Delta E)}{k(T;\\ \\{\\nu\\},\\ \\Delta E)}\n\\;=\\; (1+\\epsilon_{\\nu})^{N_{\\min} - N_{\\mathrm{ts}}}\n\\;=\\; 1+\\epsilon_{\\nu},\n$$\n对于一阶鞍点。对于加性能垒误差 $\\epsilon_{E}$，有限灵敏度因子为\n$$\nR_{E} \\;\\equiv\\; \\frac{k(T;\\ \\{\\nu\\},\\ \\Delta E+\\epsilon_{E})}{k(T;\\ \\{\\nu\\},\\ \\Delta E)}\n\\;=\\; \\exp\\!\\left(-\\frac{\\epsilon_{E}}{k_{\\mathrm{B}} T}\\right).\n$$\n\n算法设计：\n1. 使用 $1\\ \\mathrm{THz} = 10^{12}\\ \\mathrm{s^{-1}}$ 将提供的振动频率从 $\\mathrm{THz}$ 转换为 $\\mathrm{s^{-1}}$。\n2. 计算指前因子的对数以保持数值稳定性：\n   $$\n   \\ln A \\;=\\; \\sum_{i=1}^{N_{\\min}} \\ln \\nu^{\\min}_{i} \\;-\\; \\sum_{j=1}^{N_{\\mathrm{ts}}} \\ln \\nu^{\\mathrm{ts}}_{j},\n   \\quad\n   A \\;=\\; e^{\\ln A}.\n   $$\n3. 评估速率\n   $$\n   k(T) \\;=\\; A \\,\\exp\\!\\left(-\\frac{\\Delta E}{k_{\\mathrm{B}} T}\\right).\n   $$\n4. 通过用乘以 $(1+\\epsilon_{\\nu})$ 的每个频率重新计算速率来评估 $R_{\\nu}$。通过用 $\\Delta E \\mapsto \\Delta E+\\epsilon_{E}$ 重新计算速率来评估 $R_{E}$。\n5. 计算 $S_{\\mathrm{scale}} = 1$（根据模式数差异）和 $S_{E} = -1/(k_{\\mathrm{B}} T)$。\n6. 将所有报告的浮点数四舍五入到六位有效数字，并将各用例结果的列表打印为单行。\n\n科学现实性与解释：\n- 这些频率是固体中吸附物或缺陷模式的典型振动尺度，范围在几到几十 $\\mathrm{THz}$。\n- 能垒值代表了扩散或反应的活化能。\n- 分析强调，在低温下，$\\Delta E$ 的一个小的绝对误差可以通过指数依赖关系主导 $k(T)$ 的不确定性，而均匀的频率偏差则线性地影响 $k(T)$，其灵敏度由极小点和过渡态处实模式数量的差异固定。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef vineyard_rate(freq_min_thz, freq_ts_thz, deltaE_eV, T_K, kB_eV_per_K=8.617333262145e-5):\n    \"\"\"\n    Compute the harmonic Vineyard TST rate:\n        k(T) = (prod_i nu_i^min / prod_j nu_j^ts) * exp(-DeltaE / (kB T))\n    Frequencies are ordinary frequencies (not angular) in THz and converted to Hz.\n    \"\"\"\n    # Convert THz to Hz\n    freq_min_hz = np.array(freq_min_thz, dtype=float) * 1e12\n    freq_ts_hz = np.array(freq_ts_thz, dtype=float) * 1e12\n\n    # Numerical stability: compute log of product difference\n    lnA = np.sum(np.log(freq_min_hz)) - np.sum(np.log(freq_ts_hz))\n    A = np.exp(lnA)  # s^-1\n\n    beta = 1.0 / (kB_eV_per_K * T_K)  # 1/eV\n    k = A * np.exp(-deltaE_eV * beta)\n    return k\n\ndef format_sigfig(x, sig=6):\n    # Format a float to specified significant figures using general format.\n    # Ensure standard 'inf'/'nan' are handled, but they shouldn't occur here.\n    return f\"{x:.{sig}g}\"\n\ndef solve():\n    # Define vibrational datasets (THz)\n    freq_min_thz = [3.2, 5.1, 7.0, 8.4, 10.0, 12.3]\n    freq_ts_thz  = [2.9, 4.7, 6.5, 7.9, 11.5]\n\n    # Test cases: (DeltaE [eV], T [K], eps_nu [dimensionless], eps_E [eV])\n    test_cases = [\n        (0.6, 500.0, 0.05, 0.05),\n        (0.6, 200.0, 0.05, 0.05),\n        (0.6, 1200.0, 0.05, 0.05),\n        (0.05, 500.0, 0.05, 0.05),\n    ]\n\n    kB_eV_per_K = 8.617333262145e-5\n\n    results = []\n    for deltaE_eV, T_K, eps_nu, eps_E in test_cases:\n        # Baseline rate\n        k_base = vineyard_rate(freq_min_thz, freq_ts_thz, deltaE_eV, T_K, kB_eV_per_K)\n\n        # Frequency-bias sensitivity: scale all frequencies by (1 + eps_nu)\n        scale = 1.0 + eps_nu\n        freq_min_scaled = [scale * f for f in freq_min_thz]\n        freq_ts_scaled  = [scale * f for f in freq_ts_thz]\n        k_freq_bias = vineyard_rate(freq_min_scaled, freq_ts_scaled, deltaE_eV, T_K, kB_eV_per_K)\n        R_nu = k_freq_bias / k_base if k_base != 0.0 else np.nan\n\n        # Barrier-error sensitivity: add eps_E to barrier\n        k_E_bias = vineyard_rate(freq_min_thz, freq_ts_thz, deltaE_eV + eps_E, T_K, kB_eV_per_K)\n        R_E = k_E_bias / k_base if k_base != 0.0 else np.nan\n\n        # Logarithmic sensitivities\n        # For first-order saddle: N_min - N_ts = 1\n        S_scale = 1.0\n        S_E = -1.0 / (kB_eV_per_K * T_K)\n\n        results.append([\n            float(format_sigfig(k_base)),\n            float(format_sigfig(R_nu)),\n            float(format_sigfig(R_E)),\n            float(format_sigfig(S_scale)),\n            float(format_sigfig(S_E)),\n        ])\n\n    # Final print statement in the exact required format.\n    # Print as a single Python-style list literal on one line.\n    # Ensure floats are represented without additional quotes.\n    def list_to_str(lst):\n        return \"[\" + \",\".join(map(str, lst)) + \"]\"\n\n    print(\"[\" + \",\".join(list_to_str(case) for case in results) + \"]\")\n\nsolve()\n```", "id": "3459864"}, {"introduction": "当我们拥有包含大量事件及其速率的目录时，下一个计算挑战是如何有效地从中选择一个事件来执行。本练习将介绍现代KMC实现中的一个基石算法，即Bortz-Kalos-Lebowitz (BKL) 算法。您将使用一种称为二叉索引树（或Fenwick树）的高效数据结构来实现事件选择，以达到对选择和更新操作都至关重要的 $O(\\log N)$ 性能 [@problem_id:3459841]。", "problem": "考虑一个动力学蒙特卡洛（KMC）过程，其中由 $i \\in \\{1,2,\\dots,N\\}$ 索引的一组离散事件中的每一个都以非负速率 $r_i$ 发生。KMC 方法根据与 $r_i$ 成正比的概率选择下一个事件，并按一个指数分布的等待时间推进时间，该等待时间的速率参数等于总速率。根据独立泊松过程和连续时间马尔可夫链的理论，到下一个事件的等待时间呈指数分布，参数为 $R_{\\mathrm{tot}} = \\sum_{i=1}^{N} r_i$，事件索引以概率 $r_i / R_{\\mathrm{tot}}$ 被抽取。用于离散事件选择的逆变换采样法的过程是：抽取一个均匀随机变量 $u \\in (0,1)$ 并设置 $y = u \\cdot R_{\\mathrm{tot}}$；所选事件是满足累积和 $\\sum_{i=1}^{k} r_i$ 超过 $y$ 的最小索引 $k$。\n\n您的任务是使用二叉索引树（BIT；也称为 Fenwick 树）来实现事件选择和局部更新操作，该树存储速率 $\\{r_i\\}$ 的部分和。BIT 必须在 $O(\\log N)$ 时间内支持以下操作：\n\n- 从一个速率数组 $\\{r_i\\}_{i=1}^{N}$（其中 $r_i \\ge 0$）构建。\n- 通过逆变换采样进行事件选择：给定 $u \\in (0,1)$，计算 $y = u \\cdot R_{\\mathrm{tot}}$，并找到满足 $\\sum_{i=1}^{k} r_i > y$ 的最小索引 $k$。程序必须返回从零开始的索引 $k-1$，并计算在 BIT 搜索中使用的步数。\n- 局部速率更新：给定一个索引 $j$ 和一个新的速率 $r'_j$，更新 BIT 以反映从 $r_j$到 $r'_j$ 的变化。程序必须计算并报告在所有指定更新中执行的 BIT 更新总步数。\n\n使用的基本原理：将事件 $i$ 的 KMC 选择概率定义为 $r_i / R_{\\mathrm{tot}}$；通过将一个均匀分布的 $u \\in (0,1)$ 映射到一个阈值 $y = u \\cdot R_{\\mathrm{tot}}$ 并选择满足 $\\sum_{i=1}^{k} r_i > y$ 的最小 $k$ 来使用逆变换采样。利用二叉索引树（BIT）的性质进行部分和计算和二进制提升搜索，通过2的幂次分解确保选择和更新操作的时间复杂度均为 $O(\\log N)$。\n\n您的程序必须是自包含的，除了最终打印外不执行任何输入/输出，并为每个测试用例计算以下内容：\n\n- 任何更新之前的所选从零开始的事件索引。\n- 任何更新之前用于选择的 BIT 搜索步数。\n- 任何更新之前的总速率 $R_{\\mathrm{tot}}$。\n- 所有指定更新累计的 BIT 更新总步数。\n- 应用所有更新后的所选从零开始的事件索引。\n- 更新后用于选择的 BIT 搜索步数。\n- 更新后的总速率 $R_{\\mathrm{tot}}$。\n\n所有量均为无量纲。最终输出中的索引必须是从零开始的。BIT 步数是整数。总速率是浮点数。\n\n测试套件：\n提供三个测试用例以验证正确操作、不同方面和边界条件。对于每个用例，指定 $N$、速率 $r$、更新前的均匀分布 $u_{\\mathrm{before}}$、一个由 $(i, r'_i)$（使用从一开始的索引）指定的更新列表，以及更新后的均匀分布 $u_{\\mathrm{after}}$。\n\n- 用例 1（单个事件，平凡边界）：\n  - $N = 1$\n  - $r = [5.0]$\n  - $u_{\\mathrm{before}} = 0.37$\n  - updates $= [(1, 10.0)]$\n  - $u_{\\mathrm{after}} = 0.37$\n\n- 用例 2（混合零速率和非零速率，多次更新）：\n  - $N = 8$\n  - $r = [0.5, 1.0, 0.0, 1.5, 0.2, 0.0, 3.0, 2.3]$\n  - $u_{\\mathrm{before}} = 0.73$\n  - updates $= [(3, 0.8), (7, 2.4)]$\n  - $u_{\\mathrm{after}} = 0.41$\n\n- 用例 3（稀疏速率，接近尾部的边界选择和主要更新）：\n  - $N = 16$\n  - $r = [0.0, 4.2, 0.0, 0.0, 0.3, 0.0, 0.0, 1.1, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 2.0]$\n  - $u_{\\mathrm{before}} = 0.99$\n  - updates $= [(2, 0.0), (16, 4.0)]$\n  - $u_{\\mathrm{after}} = 0.25$\n\n最终输出格式：\n您的程序应生成一行输出，其中包含所有测试用例的结果，形式为一个逗号分隔的列表，并用方括号括起来。每个测试用例的结果是按上述顺序排列的七个值的列表，例如：\n$[[k_{\\mathrm{b}}, s_{\\mathrm{b}}, R_{\\mathrm{b}}, u\\!s, k_{\\mathrm{a}}, s_{\\mathrm{a}}, R_{\\mathrm{a}}], [\\dots], [\\dots]]$。", "solution": "该问题要求实现一个数据结构，以加速动力学蒙特卡洛（KMC）模拟中的两个核心操作：选择下一个事件和更新事件速率。指定的事件选择算法是逆变换采样，它将一个均匀随机数 $u \\in (0,1)$ 映射到一个选择阈值 $y = u \\cdot R_{\\mathrm{tot}}$，其中 $R_{\\mathrm{tot}} = \\sum_{i=1}^{N} r_i$ 是所有 $N$ 个可能事件的总速率。所选事件是满足速率累积和 $S_k = \\sum_{i=1}^{k} r_i$ 大于 $y$ 的最小索引 $k$。\n\n一个简单的实现需要 $O(N)$ 的时间来为每个潜在事件 $k$ 计算 $S_k$，导致选择过程的时间复杂度为 $O(N)$。类似地，如果需要进行大量此类操作，更新单个速率 $r_j$ 并重新计算 $R_{\\mathrm{tot}}$ 的方法虽然直接但效率低下。该问题强制要求使用二叉索引树（BIT），也称为 Fenwick 树，将这些操作优化到对数时间复杂度，即 $O(\\log N)$。\n\n二叉索引树是一种可以高效计算前缀和并对底层值执行更新的数据结构。它通常使用一个大小为 $N+1$ 的数组（例如 `tree`）来实现。对于从 1 开始的索引，`tree[idx]` 既不存储单个值 `rates[idx-1]`，也不存储到 `idx` 的完整前缀和。相反，它存储特定索引子范围内的和。其结构设计使得任何前缀和 $\\sum_{i=1}^{k} r_i$ 都可以通过对 `tree` 数组中仅 $O(\\log k)$ 个条目求和来计算。反之，更新单个速率 $r_j$ 只需要更新 $O(\\log N)$ 个条目。\n\nBIT 的核心操作如下，为清晰起见使用从 1 开始的索引：\n\n$1$. **更新操作 (`update(j, delta)`)：** 要将一个值 `delta` 加到速率 $r_j$ 上，我们必须更新 `tree` 数组中所有在其和中包含 $r_j$ 的条目。需要更新的索引可以通过从 $j$ 开始，并重复加上当前索引的最低有效位的值来找到：$j \\to j + (j \\text{ \\ } -j)$，其中 `` 是按位与运算符。这个过程一直持续到索引超过 $N$。访问的节点数，即时间复杂度，为 $O(\\log N)$。我们将每次节点更新计为一步。\n\n$2$. **前缀和查询 (`prefix_sum(k)`)：** 要计算 $S_k = \\sum_{i=1}^{k} r_i$，我们通过从索引 $k$ 开始，并重复减去最低有效位来对 `tree` 数组中的条目求和：$k \\to k - (k \\text{ \\ } -k)$，直到索引变为 $0$。这也涉及访问 $O(\\log k)$ 个节点。总速率 $R_{\\mathrm{tot}}$ 就是 `prefix_sum(N)`。\n\n$3$. **通过搜索进行事件选择 (`find_k(y)`)：** 关键任务是找到满足 $S_k  y$ 的最小索引 $k$。在索引 $k$ 上进行朴素的二分搜索并结合 `prefix_sum` 调用会导致一个 $O(\\log^2 N)$ 的算法。一个更高效的 $O(\\log N)$ 搜索可以直接在 BIT 上执行。这种技术，通常称为二进制提升或按位搜索，通过从最高有效位到最低有效位确定目标索引的位来工作。我们从小于或等于 $N$ 的最大2的幂 $p$ 开始。我们维护一个当前索引 `idx`（初始为 $0$）和一个 `current_sum`。在每一步，对于一个2的幂 $p$，我们检查是否可以向前“跳跃” $p$。如果 `idx + p` 是一个有效索引，并且将 `tree[idx + p]` 加到 `current_sum` 不会超过阈值 $y$，我们就执行跳跃：`current_sum += tree[idx + p]` 并且 `idx += p`。然后我们继续处理下一个更小的2的幂 $p/2$。这个过程类似于在 BIT 所代表的隐式树结构中向下遍历。在检查了所有2的幂之后，`idx` 将持有其前缀和小于或等于 $y$ 的最大索引。因此，所期望的事件索引是 `idx + 1`。此搜索的步数是所考虑的2的幂的数量，即 $O(\\log N)$。\n\n我们的实现将被封装在一个 `BIT` 类中。这个类将管理一个用于树结构的数组和一个用于存储原始速率的数组，后者对于计算更新的 `delta` 是必需的。该类提供了从一组初始速率构建树、更新特定速率（并计算步数）以及执行高效的事件选择搜索（同样计算步数）的方法。问题中提供的更新索引是从 1 开始的，我们将其转换为从 0 开始的索引以便在 Python 中进行数组访问，而 BIT 内部逻辑方便地使用从 1 开始的索引。\n\n对于每个测试用例，我们执行以下序列：\n$1$. 使用初始速率实例化并构建 `BIT`。\n$2$. 计算总速率 $R_{\\mathrm{before}}$ 和阈值 $y_{\\mathrm{before}} = u_{\\mathrm{before}} \\cdot R_{\\mathrm{before}}$。\n$3$. 使用 `find_k` 方法确定所选事件索引 $k_{\\mathrm{before}}$ 和搜索步数 $s_{\\mathrm{before}}$。\n$4$. 顺序应用所有指定的速率更新，累积 BIT 更新总步数 $us$。\n$5$. 所有更新后，计算新的总速率 $R_{\\mathrm{after}}$ 和新的阈值 $y_{\\mathrm{after}} = u_{\\mathrm{after}} \\cdot R_{\\mathrm{after}}$。\n$6$. 再次使用 `find_k` 找到新的事件索引 $k_{\\mathrm{after}}$ 和搜索步数 $s_{\\mathrm{after}}$。\n$7$. 收集这七个量：$[k_{\\mathrm{b}}, s_{\\mathrm{b}}, R_{\\mathrm{b}}, us, k_{\\mathrm{a}}, s_{\\mathrm{a}}, R_{\\mathrm{a}}]$ 并按要求格式化它们。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass BIT:\n    \"\"\"\n    Binary Indexed Tree (Fenwick Tree) for KMC event selection.\n    This implementation uses 1-based indexing internally for the tree\n    but exposes a 0-based indexing interface for rates.\n    \"\"\"\n    def __init__(self, size: int):\n        if size == 0:\n            # Handle empty case gracefully\n            self.size = 0\n            self.tree = []\n            self.rates = []\n            return\n        if size  0:\n            raise ValueError(\"Size must be non-negative.\")\n        self.size = size\n        self.tree = [0.0] * (size + 1)\n        self.rates = [0.0] * size\n\n    def _add(self, index_1based: int, delta: float) -> int:\n        \"\"\"\n        Private helper to add a delta to the tree.\n        Counts and returns the number of steps (nodes updated).\n        \"\"\"\n        steps = 0\n        idx = index_1based\n        while idx = self.size:\n            self.tree[idx] += delta\n            steps += 1\n            idx += idx  -idx\n        return steps\n\n    def build(self, initial_rates: list[float]):\n        \"\"\"\n        Builds the BIT from an initial list of rates.\n        This is an O(N log N) construction.\n        \"\"\"\n        if self.size == 0: return\n        self.rates = list(initial_rates)\n        for i, rate in enumerate(self.rates):\n            if rate != 0.0:\n                # Use _add but don't count steps for initial build\n                self._add(i + 1, rate)\n\n    def update_rate(self, index_0based: int, new_rate: float) -> int:\n        \"\"\"\n        Updates the rate at a given 0-based index to a new value.\n        Counts and returns the number of steps for this update.\n        \"\"\"\n        if self.size == 0: return 0\n        delta = new_rate - self.rates[index_0based]\n        self.rates[index_0based] = new_rate\n        return self._add(index_0based + 1, delta)\n\n    def get_total_rate(self) -> float:\n        \"\"\"\n        Returns the total sum of all rates, R_tot.\n        This is equivalent to a prefix sum up to N.\n        \"\"\"\n        if self.size == 0: return 0.0\n        total = 0.0\n        idx = self.size\n        # This is a prefix sum query, but we don't count steps for this.\n        while idx > 0:\n            total += self.tree[idx]\n            idx -= idx  -idx\n        return total\n\n    def find_k(self, y: float) -> tuple[int, int]:\n        \"\"\"\n        Finds the smallest 0-based index k-1 such that sum_{i=1 to k} r_i > y.\n        Uses an O(log N) binary lifting search on the BIT.\n        Returns the 0-based index and the number of search steps.\n        \"\"\"\n        idx = 0\n        current_sum = 0.0\n        steps = 0\n        \n        if self.size == 0:\n            return -1, 0\n        \n        # Determine the largest power of 2 less than or equal to self.size\n        p = 1  (self.size.bit_length() - 1)\n\n        while p > 0:\n            steps += 1\n            if idx + p = self.size:\n                test_val = self.tree[idx + p]\n                if current_sum + test_val = y:\n                    current_sum += test_val\n                    idx += p\n            p >>= 1\n            \n        return idx, steps\n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (single event, trivial boundary):\n        {\n            \"N\": 1,\n            \"r\": [5.0],\n            \"u_before\": 0.37,\n            \"updates\": [(1, 10.0)],\n            \"u_after\": 0.37\n        },\n        # Case 2 (mixed zero and nonzero rates, multiple updates):\n        {\n            \"N\": 8,\n            \"r\": [0.5, 1.0, 0.0, 1.5, 0.2, 0.0, 3.0, 2.3],\n            \"u_before\": 0.73,\n            \"updates\": [(3, 0.8), (7, 2.4)],\n            \"u_after\": 0.41\n        },\n        # Case 3 (sparse rates, edge selection near the tail and major update):\n        {\n            \"N\": 16,\n            \"r\": [0.0, 4.2, 0.0, 0.0, 0.3, 0.0, 0.0, 1.1, 0.0, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 2.0],\n            \"u_before\": 0.99,\n            \"updates\": [(2, 0.0), (16, 4.0)],\n            \"u_after\": 0.25\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        N = case[\"N\"]\n        r = case[\"r\"]\n        u_before = case[\"u_before\"]\n        updates = case[\"updates\"]\n        u_after = case[\"u_after\"]\n\n        # --- Initial State ---\n        bit_tree = BIT(N)\n        bit_tree.build(r)\n\n        # --- Before updates ---\n        R_before = bit_tree.get_total_rate()\n        y_before = u_before * R_before if R_before > 0 else 0\n        k_before, s_before = bit_tree.find_k(y_before)\n\n        # --- Apply updates ---\n        total_update_steps = 0\n        for idx_1based, new_rate in updates:\n            total_update_steps += bit_tree.update_rate(idx_1based - 1, new_rate)\n            \n        # --- After updates ---\n        R_after = bit_tree.get_total_rate()\n        y_after = u_after * R_after if R_after > 0 else 0\n        k_after, s_after = bit_tree.find_k(y_after)\n\n        result = [\n            k_before,\n            s_before,\n            R_before,\n            total_update_steps,\n            k_after,\n            s_after,\n            R_after,\n        ]\n        all_results.append(result)\n\n    # Format the final output string exactly as required, avoiding extra spaces.\n    inner_results_str = []\n    for res in all_results:\n        # Manually format each list to control spacing\n        # Example: [0,1,5.0,1,0,1,10.0]\n        inner_str = f\"[{res[0]},{res[1]},{res[2]},{res[3]},{res[4]},{res[5]},{res[6]}]\"\n        inner_results_str.append(inner_str)\n    \n    final_output = f\"[{','.join(inner_results_str)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3459841"}, {"introduction": "在 $O(\\log N)$ 选择时间仍然是性能瓶颈的系统中，或者当速率以可预测的方式演变时，存在更快的算法。这项高级练习将探讨别名法（alias method），它能实现 $O(1)$ 的事件选择时间。您将把它与主导速率方案（majorant rate scheme，或称“瘦身法”）相结合来处理速率变化，并专注于分析快速选择与重建数据结构开销之间的实际权衡 [@problem_id:3459874]。", "problem": "实现一个完整的程序，该程序在速率漂移的情况下，对使用别名方法进行动力学蒙特卡洛（KMC）事件选择的计算成本权衡进行建模，并优化别名表的重建频率。该模型必须基于泊松叠加和稀疏化的第一性原理，以确保随机过程的精确性。\n\n假设在离散的动力学蒙特卡洛步骤索引 $n$ 处，存在 $M$ 个独立事件，其正速率为 $\\{r_i^{(n)}\\}_{i=1}^M$。考虑一种情景，其中速率根据简单的漂移模型 $r_i^{(n)} = r_i^{(0)} (1 + \\lambda n)$ 随时间均匀缩放，其中 $\\lambda \\ge 0$ 是一个常数，对所有 $i$ 都相同，而 $r_i^{(0)}  0$。在每组包含 $L$ 个已接受事件的块的开始，您需要使用当前的基线 $r_i^{(n_0)}$ 构建一个主导（控制）速率向量 $q_i^{\\text{block}} = (1 + \\lambda L) r_i^{(n_0)}$，其中 $n_0$ 是该块开始时的索引，$L$ 是在下次重建之前计划接受的事件数量。在该块内，您执行复合-拒绝（稀疏化）操作：使用具有 $O(1)$ 选择时间的别名方法，从与 $\\{q_i^{\\text{block}}\\}$ 成正比的分布中提议事件，并在步骤 $m \\in \\{0,1,\\dots,L-1\\}$ 以概率 $r_i^{(n_0+m)}/q_i^{\\text{block}}$ 接受每个提议的事件 $i$。由于速率漂移对所有 $i$ 都是均匀的，因此在块内接受概率不依赖于 $i$，并在步骤 $m$ 时等于 $(1+\\lambda m)/(1+\\lambda L)$。\n\n采用以下抽象操作计数成本模型（单位为抽象操作单位；您必须仅报告这些无量纲的计数值）：\n- 为长度为 $M$ 的向量构建一个别名表的成本为 $c_{\\text{build}} \\cdot M$。\n- 每次从别名表中提议抽样的成本为 $c_{\\text{select}}$。\n- 每次接受-拒绝检查的成本为 $c_{\\text{check}}$。\n- 每次已接受事件更新的成本为 $c_{\\text{update}}$。\n\n如果您在每 $K$ 个已接受事件后重建别名表（重建周期），总共将生成 $N$ 个已接受事件。对于一个长度为 $L$ 的块，为实现 $L$ 个已接受事件所需的期望提议数是成功概率为 $\\{p_m\\}_{m=0}^{L-1}$ 的几何期望的总和，其中 $p_m = (1+\\lambda m)/(1+\\lambda L)$。所有块的总期望提议数是线性相加的。作为 $K$ 的函数的总期望成本包括每个块的别名表重建成本、每次提议的成本以及每次已接受事件更新的成本。\n\n您的任务是：\n1. 为 $M$ 个事件上的任意离散分布实现别名方法的设置和 $O(1)$ 采样器。设置函数接收一个非负权重向量并生成别名表；采样器根据归一化的权重进行抽样。\n2. 从第一性原理出发，推导出一个封闭形式的表达式或算法，以计算在所述漂移模型下，一个长度为 $L$ 的块所需的期望提议数。使用此结果计算在重建周期为 $K$ 的情况下生成 $N$ 个已接受事件的总期望成本，并通过使用最后一个（可能是部分的）块的实际长度来对其进行核算。\n3. 给定一个搜索范围 $K \\in \\{K_{\\min}, K_{\\min}+1, \\dots, K_{\\max}\\}$，计算使总期望成本最小化的 $K$ 值。如果有多个 $K$ 使成本最小化，请选择其中最小的那个 $K$。\n\n使用以下测试套件，其中所有符号的定义如上所述：\n- 测试用例 1：$M=100000$, $N=200000$, $\\lambda=1\\times 10^{-5}$, $c_{\\text{build}}=5$, $c_{\\text{select}}=1$, $c_{\\text{check}}=1$, $c_{\\text{update}}=2$, $K_{\\min}=1$, $K_{\\max}=5000$。\n- 测试用例 2：$M=500000$, $N=100000$, $\\lambda=5\\times 10^{-5}$, $c_{\\text{build}}=5$, $c_{\\text{select}}=1$, $c_{\\text{check}}=1$, $c_{\\text{update}}=2$, $K_{\\min}=1$, $K_{\\max}=5000$。\n- 测试用例 3：$M=100000$, $N=100000$, $\\lambda=0$, $c_{\\text{build}}=5$, $c_{\\text{select}}=1$, $c_{\\text{check}}=1$, $c_{\\text{update}}=2$, $K_{\\min}=1$, $K_{\\max}=10000$。\n- 测试用例 4：$M=100000$, $N=50000$, $\\lambda=1\\times 10^{-3}$, $c_{\\text{build}}=5$, $c_{\\text{select}}=1$, $c_{\\text{check}}=1$, $c_{\\text{update}}=2$, $K_{\\min}=1$, $K_{\\max}=2000$。\n\n最终所需的输出格式为：您的程序必须生成单行文本，其中包含一个由四个整数组成的列表，每个整数是对应测试用例的最小化 $K$ 值，以逗号分隔并用方括号括起来，例如，“[3,7,5,2]”。不应打印任何其他文本。\n\n不涉及物理单位；您必须按照规定以无量纲的抽象操作计数来报告所有输出。不涉及角度。任何地方都不得使用百分比；请酌情仅使用小数或整数。[@problem_id:732]", "solution": "本问题设定有效且适定，可进行求解。问题的速率漂移模型描述中存在一个小的歧义。所述的全局模型 $r_i^{(n)} = r_i^{(0)} (1 + \\lambda n)$（其中 $n$ 是全局已接受事件索引）会导致在一个从全局步骤 $n_0$ 开始、长度为 $L$ 的块中，第 $(m+1)$ 个已接受事件的接受概率为 $\\frac{1+\\lambda(n_0+m)}{(1+\\lambda L)(1+\\lambda n_0)}$。这与问题中明确给出的接受概率 $p_m = \\frac{1+\\lambda m}{1+\\lambda L}$ 相矛盾。然而，问题中给出的接受概率表达式与一个局部的块内漂移模型 $r_i^{\\text{in-block}}(m) = r_i^{\\text{block-start}} (1 + \\lambda m)$（其中 $m \\in \\{0, 1, \\dots, L-1\\}$）完全吻合。为保证问题自洽，本解答将采用题目明确提供的接受概率 $p_m = \\frac{1+\\lambda m}{1+\\lambda L}$ 作为推导的物理基础。\n\n解答的结构如下：首先，从第一性原理推导出总期望计算成本。其次，构建一个高效的算法来寻找能够最小化此成本的最佳别名表重建频率 $K$。问题中列出的第一个任务，即实现别名方法，涉及一个标准算法（Vose's method），为完整起见，该算法已按要求包含在最终的程序代码中。它对于成本函数的推导并非核心，因此在本解释部分不作详述。\n\n**1. 单个块的期望成本**\n\n让我们推导生成一个长度为 $L$ 的已接受事件块的总期望成本 $C(L)$。该成本包括三个部分：构建别名表的成本、所有提议（包括接受和拒绝的）的成本，以及处理已接受事件的成本。\n\n- **别名表构建成本：** 在每个块的开始，为 $M$ 个主导速率构建一个新的别名表。这会产生一个固定成本 $c_{\\text{build}} \\cdot M$。\n\n- **已接受事件更新成本：** $L$ 个已接受事件中的每一个都会产生一个成本 $c_{\\text{update}}$。该块的总更新成本为 $L \\cdot c_{\\text{update}}$。\n\n- **提议和接受检查成本：** 生成一个已接受事件的过程涉及一个或多个提议。对于块中的第 $(m+1)$ 个已接受事件（其中 $m \\in \\{0, 1, \\dots, L-1\\}$），一个提议被接受的概率由 $p_m = \\frac{1+\\lambda m}{1+\\lambda L}$ 给出。为获得一次成功所需的提议次数遵循几何分布。因此，在步骤 $m$ 获得一个已接受事件的期望提议数 $E_m$ 为 $E_m = 1/p_m$。\n\n一个长度为 $L$ 的块的总期望提议数，记为 $E_{\\text{proposals}}(L)$，是 $L$ 个已接受事件中每个事件的期望提议数之和：\n$$E_{\\text{proposals}}(L) = \\sum_{m=0}^{L-1} E_m = \\sum_{m=0}^{L-1} \\frac{1}{p_m} = \\sum_{m=0}^{L-1} \\frac{1+\\lambda L}{1+\\lambda m}$$\n将与求和索引 $m$ 无关的项 $(1+\\lambda L)$ 提出，我们得到：\n$$E_{\\text{proposals}}(L) = (1+\\lambda L) \\sum_{m=0}^{L-1} \\frac{1}{1+\\lambda m}$$\n每次提议包括一次从别名表中的选择（成本 $c_{\\text{select}}$）和一次接受/拒绝检查（成本 $c_{\\text{check}}$）。因此，块中所有提议的总期望成本为 $(c_{\\text{select}} + c_{\\text{check}}) \\cdot E_{\\text{proposals}}(L)$。\n\n结合所有部分，一个长度为 $L$ 的块的总期望成本 $C(L)$ 为：\n$$C(L) = c_{\\text{build}} \\cdot M + (c_{\\text{select}} + c_{\\text{check}}) (1+\\lambda L) \\sum_{m=0}^{L-1} \\frac{1}{1+\\lambda m} + L \\cdot c_{\\text{update}}$$\n对于 $\\lambda = 0$ 的特殊情况，所有 $m$ 的接受概率 $p_m = 1$。该和变为 $\\sum_{m=0}^{L-1} 1 = L$，成本函数简化为：\n$$C(L)|_{\\lambda=0} = c_{\\text{build}} \\cdot M + (c_{\\text{select}} + c_{\\text{check}}) L + L \\cdot c_{\\text{update}}$$\n\n**2. 总成本与优化**\n\n目标是生成总共 $N$ 个已接受事件，每 $K$ 个事件重建一次别名表。因此，模拟被划分为一系列的块。\n- 长度为 $K$ 的完整块的数量是 $N_{\\text{full}} = \\lfloor N/K \\rfloor$。\n- 最后一个（可能是部分的）块中的事件数是 $L_{\\text{final}} = N \\pmod K$。\n\n对于给定的重建周期 $K$，总期望成本记为 $C_{\\text{total}}(K)$，是所有块的成本之和。\n$$C_{\\text{total}}(K) = N_{\\text{full}} \\cdot C(K) + C(L_{\\text{final}})$$\n其中 $C(K)$ 是一个长度为 $K$ 的完整块的成本，$C(L_{\\text{final}})$ 是长度为 $L_{\\text{final}}$ 的最后一个块的成本。我们定义 $C(0)=0$。\n\n优化问题是在范围 $[K_{\\min}, K_{\\max}]$ 内找到整数 $K$，以最小化 $C_{\\text{total}}(K)$。\n$$K_{\\text{opt}} = \\arg\\min_{K \\in \\{K_{\\min}, \\dots, K_{\\max}\\}} C_{\\text{total}}(K)$$\n$C_{\\text{total}}(K)$ 的行为代表了一种权衡。对于较小的 $K$，重建成本 ($c_{\\text{build}} \\cdot M$) 占主导地位，因为它被频繁地（$\\lceil N/K \\rceil$ 次）产生。对于较大的 $K$，由于速率与主导速率显著偏离导致接受概率降低，块内每个事件的成本增加，从而增加了提议成本。这种权衡意味着存在一个最优的、非平凡的 $K$。\n\n**3. 算法实现策略**\n\n需要对搜索范围 $[K_{\\min}, K_{\\max}]$ 中的每个 $K$ 直接计算 $C_{\\text{total}}(K)$。一个朴素的实现，即在主循环中为每个块重新计算和 $\\sum_{m=0}^{L-1} \\frac{1}{1+\\lambda m}$，效率会很低，可能导致 $O(K_{\\max}^2)$ 的复杂度。\n\n通过预计算可以实现一个更高效的 $O(K_{\\max})$ 算法。设 $H(L, \\lambda) = \\sum_{m=0}^{L-1} \\frac{1}{1+\\lambda m}$。我们可以为所有需要的块长度 $L \\in \\{1, \\dots, K_{\\max}\\}$ 预计算并存储 $H(L, \\lambda)$ 的值。这是通过迭代完成的：\n- $H(0, \\lambda) = 0$\n- $H(L, \\lambda) = H(L-1, \\lambda) + \\frac{1}{1+\\lambda(L-1)}$ for $L \\ge 1$.\n\n将 $H(L, \\lambda)$ 的值存储在一个数组中后，我们便可以为 $L \\in \\{1, \\dots, K_{\\max}\\}$ 预计算块成本 $C(L)$。\n最后，我们从 $K_{\\min}$ 到 $K_{\\max}$ 遍历 $K$。在每次迭代中，我们使用预计算的块成本 $C(K)$ 和 $C(N \\pmod K)$ 在 $O(1)$ 时间内计算 $C_{\\text{total}}(K)$。跟踪产生最小成本的 $K$ 值，并根据问题要求，在成本相同时确保选择最小的那个 $K$。这使得总时间复杂度为 $O(K_{\\max})$。", "answer": "```python\nimport numpy as np\n\ndef alias_setup(weights):\n    \"\"\"\n    Constructs the probability and alias tables for Vose's Alias Method.\n\n    Args:\n        weights (np.ndarray): A 1D array of non-negative weights.\n\n    Returns:\n        tuple: A tuple containing the probability table (np.ndarray) and the\n               alias table (np.ndarray).\n    \"\"\"\n    m = weights.size\n    if m == 0:\n        return np.array([]), np.array([], dtype=np.int32)\n    \n    total_weight = np.sum(weights)\n    if total_weight == 0.0:\n        # Uniform distribution if all weights are zero.\n        prob_table = np.full(m, 1.0)\n        alias_table = np.arange(m, dtype=np.int32)\n        return prob_table, alias_table\n\n    scaled_probs = weights * (m / total_weight)\n    \n    small_indices = np.where(scaled_probs  1.0)[0].tolist()\n    large_indices = np.where(scaled_probs >= 1.0)[0].tolist()\n    \n    prob_table = np.zeros(m)\n    alias_table = np.zeros(m, dtype=np.int32)\n    \n    while small_indices and large_indices:\n        s_idx = small_indices.pop()\n        l_idx = large_indices.pop()\n        \n        prob_table[s_idx] = scaled_probs[s_idx]\n        alias_table[s_idx] = l_idx\n        \n        scaled_probs[l_idx] = (scaled_probs[l_idx] + scaled_probs[s_idx]) - 1.0\n        \n        if scaled_probs[l_idx]  1.0:\n            small_indices.append(l_idx)\n        else:\n            large_indices.append(l_idx)\n\n    # Handle remaining items due to floating-point inaccuracies.\n    while large_indices:\n        l_idx = large_indices.pop()\n        prob_table[l_idx] = 1.0\n    while small_indices:\n        s_idx = small_indices.pop()\n        prob_table[s_idx] = 1.0\n        \n    return prob_table, alias_table\n\ndef alias_draw(prob_table, alias_table):\n    \"\"\"\n    Draws a random index from the distribution defined by the alias tables.\n\n    Args:\n        prob_table (np.ndarray): The probability table from alias_setup.\n        alias_table (np.ndarray): The alias table from alias_setup.\n\n    Returns:\n        int: A random index drawn from the discrete distribution.\n    \"\"\"\n    m = prob_table.size\n    i = np.random.randint(0, m)\n    if np.random.rand()  prob_table[i]:\n        return i\n    else:\n        return alias_table[i]\n\ndef solve():\n    \"\"\"\n    Solves the KMC cost optimization problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        (100000, 200000, 1e-5, 5, 1, 1, 2, 1, 5000),\n        (500000, 100000, 5e-5, 5, 1, 1, 2, 1, 5000),\n        (100000, 100000, 0.0, 5, 1, 1, 2, 1, 10000),\n        (100000, 50000, 1e-3, 5, 1, 1, 2, 1, 2000)\n    ]\n\n    results = []\n    for case in test_cases:\n        m, n, lam, c_build, c_select, c_check, c_update, k_min, k_max = case\n\n        # Pre-compute the sum H(L, lambda) = sum_{m=0}^{L-1} 1/(1+lam*m)\n        # H_vals array will store H(L, lambda) at index L.\n        H_vals = np.zeros(k_max + 1, dtype=np.float64)\n        if lam == 0.0:\n            # Special case for lambda=0, H(L,0) = L\n            H_vals = np.arange(k_max + 1, dtype=np.float64)\n        else:\n            current_sum = 0.0\n            for l_val in range(1, k_max + 1):\n                current_sum += 1.0 / (1.0 + lam * (l_val - 1))\n                H_vals[l_val] = current_sum\n        \n        # Pre-compute the cost C(L) for a single block of length L.\n        # block_costs[L] will store C(L). block_costs[0] = 0.\n        block_costs = np.zeros(k_max + 1, dtype=np.float64)\n        cost_proposal = c_select + c_check\n        \n        for l_val in range(1, k_max + 1):\n            rebuild_cost = c_build * m\n            update_cost = c_update * l_val\n            \n            if lam == 0.0:\n                expected_proposals = float(l_val)\n            else:\n                expected_proposals = (1.0 + lam * l_val) * H_vals[l_val]\n            \n            proposal_total_cost = cost_proposal * expected_proposals\n            block_costs[l_val] = rebuild_cost + proposal_total_cost + update_cost\n\n        # Find the optimal K by iterating through the search range\n        min_total_cost = float('inf')\n        best_k = -1\n\n        for k in range(k_min, k_max + 1):\n            if k == 0:\n                continue\n\n            num_full_blocks = n // k\n            len_last_block = n % k\n\n            cost_full = block_costs[k]\n            cost_last = block_costs[len_last_block]\n\n            total_cost = num_full_blocks * cost_full + cost_last\n\n            if total_cost  min_total_cost:\n                min_total_cost = total_cost\n                best_k = k\n        \n        results.append(best_k)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3459874"}]}