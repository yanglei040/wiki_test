{"hands_on_practices": [{"introduction": "贝叶斯校准始于为我们的参数定义先验分布。许多材料参数，例如杨氏模量 $E$，在物理上必须是正数。本练习演示了一种施加此类约束的标准而强大的技术：重参数化。通过假设参数的对数服从一个简单的高斯先验，我们可以推导出参数本身所对应的先验分布，即对数正态分布。这项练习将巩固您对概率密度变量替换公式的理解，这是统计建模中的一个基本工具。 [@problem_id:3547099]", "problem": "在计算固体力学中，考虑一个各向同性线弹性材料的杨氏模量（记为 $E$）的贝叶斯校准问题，其中由于物理约束，$E$ 是严格为正的。为了强制其为正并稳定推断过程，引入对数重参数化 $\\eta = \\ln(E)$。假设潜变量 $\\eta$ 的先验信念是均值为 $\\mu$、标准差为 $\\sigma$ 的高斯分布，其中 $\\sigma > 0$，即 $\\eta$ 的先验密度为\n$$\np_{\\eta}(\\eta) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\!\\left(-\\frac{(\\eta - \\mu)^{2}}{2\\sigma^{2}}\\right).\n$$\n从重参数化下的概率守恒和概率密度的定义出发，推导由映射 $E = \\exp(\\eta)$ 所引出的物理模量 $E$ 上的诱导先验密度 $p_{E}(E)$。确定归一化常数，使得\n$$\n\\int_{0}^{\\infty} p_{E}(E)\\,\\mathrm{d}E = 1.\n$$\n将您的最终答案表示为 $p_{E}(E)$ 关于 $E$、$\\mu$ 和 $\\sigma$ 的单一闭式解析表达式。不需要进行数值计算。最终表达式中不应包含单位。最终答案必须是且仅是一个表达式。", "solution": "该问题要求在给定杨氏模量的对数 $\\eta = \\ln(E)$ 的概率密度函数（PDF）的情况下，推导杨氏模量 $E$ 的概率密度函数。两个 PDF 之间的关系由概率守恒原理决定，这引出了概率密度的变量替换公式。\n\n设 $\\eta$ 是一个具有已知 PDF $p_{\\eta}(\\eta)$ 的随机变量，并设 $E = g(\\eta)$ 是一个由可逆、可微的变换 $g$ 定义的新随机变量。其逆变换为 $\\eta = g^{-1}(E)$。$E$ 的 PDF（记为 $p_{E}(E)$）可以通过以下关系找到：\n$$\np_{E}(E) = p_{\\eta}\\left(g^{-1}(E)\\right) \\left| \\frac{\\mathrm{d}}{\\mathrm{d}E} g^{-1}(E) \\right|\n$$\n该公式确保了概率元是守恒的，即 $|p_{E}(E)\\,\\mathrm{d}E| = |p_{\\eta}(\\eta)\\,\\mathrm{d}\\eta|$。\n\n在本问题的背景下，我们已知：\n1.  从潜变量 $\\eta$ 到物理参数 $E$ 的变换：$E = \\exp(\\eta)$。\n2.  因此，逆变换为 $\\eta = \\ln(E)$。所以，$g^{-1}(E) = \\ln(E)$。\n3.  $\\eta$ 上的先验密度，它是一个均值为 $\\mu$、标准差为 $\\sigma$ 的高斯分布：\n$$\np_{\\eta}(\\eta) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\eta - \\mu)^{2}}{2\\sigma^{2}}\\right)\n$$\n$\\eta$ 的定义域是 $(-\\infty, \\infty)$。因为 $E = \\exp(\\eta)$，所以 $E$ 的定义域是 $(0, \\infty)$，这与杨氏模量必须严格为正的物理要求是一致的。\n\n首先，我们计算变换的雅可比行列式，即逆变换导数的绝对值 $\\left| \\frac{\\mathrm{d}\\eta}{\\mathrm{d}E} \\right|$。\n$$\n\\eta(E) = \\ln(E)\n$$\n其导数为：\n$$\n\\frac{\\mathrm{d}\\eta}{\\mathrm{d}E} = \\frac{\\mathrm{d}}{\\mathrm{d}E} \\left( \\ln(E) \\right) = \\frac{1}{E}\n$$\n由于 $E > 0$，其绝对值就是：\n$$\n\\left| \\frac{\\mathrm{d}\\eta}{\\mathrm{d}E} \\right| = \\left| \\frac{1}{E} \\right| = \\frac{1}{E}\n$$\n\n接下来，我们将 $\\eta = \\ln(E)$ 代入 $p_{\\eta}(\\eta)$ 的表达式中：\n$$\np_{\\eta}(\\ln(E)) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln(E) - \\mu)^{2}}{2\\sigma^{2}}\\right)\n$$\n\n现在，我们通过将 $p_{\\eta}(\\ln(E))$ 与雅可比项 $\\left| \\frac{\\mathrm{d}\\eta}{\\mathrm{d}E} \\right|$ 相乘，来构建 $p_{E}(E)$ 的最终表达式：\n$$\np_{E}(E) = p_{\\eta}(\\ln(E)) \\left| \\frac{\\mathrm{d}\\eta}{\\mathrm{d}E} \\right| = \\left( \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln(E) - \\mu)^{2}}{2\\sigma^{2}}\\right) \\right) \\cdot \\left( \\frac{1}{E} \\right)\n$$\n整理各项，得到 $E$ 上先验密度的最终闭式表达式：\n$$\np_{E}(E) = \\frac{1}{E \\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln(E) - \\mu)^{2}}{2\\sigma^{2}}\\right)\n$$\n这是对数正态分布的概率密度函数，其定义域为 $E > 0$。\n\n问题要求确定归一化常数，使得 $\\int_{0}^{\\infty} p_{E}(E)\\,\\mathrm{d}E = 1$。使用变量替换公式的推导过程会自动保持归一化。如果 $p_{\\eta}(\\eta)$ 被归一化为 $1$，那么得到的 $p_{E}(E)$ 也被归一化为 $1$。高斯先验 $p_{\\eta}(\\eta)$ 从 $-\\infty$ 到 $\\infty$ 的积分为 $1$。通过在积分 $\\int_{0}^{\\infty} p_{E}(E)\\,\\mathrm{d}E$ 中进行变量替换，令 $u = \\ln(E)$（因此 $\\mathrm{d}u = \\frac{1}{E} \\mathrm{d}E$，积分限从 $(0, \\infty)$ 变换为 $(-\\infty, \\infty)$），该积分变为 $\\int_{-\\infty}^{\\infty} p_{\\eta}(u)\\,\\mathrm{d}u$，这证实了该积分确实为 $1$。因此，推导出的表达式已经是正确归一化的，“归一化常数”已隐式地包含在表达式中，具体来说就是因子 $\\frac{1}{\\sigma\\sqrt{2\\pi}}$。", "answer": "$$\\boxed{\\frac{1}{E \\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{\\left(\\ln(E) - \\mu\\right)^{2}}{2\\sigma^{2}}\\right)}$$", "id": "3547099"}, {"introduction": "似然函数将我们基于物理的模型与实验数据联系起来。虽然一个方差恒定的简单高斯噪声模型通常是分析的起点，但真实的实验噪声往往更为复杂。本练习将指导您构建一个更切合实际的异方差噪声模型的似然函数，其中测量误差的方差不是恒定的，而是取决于系统的状态。掌握这一点能让您构建更可靠的统计模型，从而更好地捕捉实验不确定性的细微差别，并获得更可信的参数估计。 [@problem_id:3547176]", "problem": "在一个金属试样的单轴拉伸试验中，设施加的工程应变数据为 $\\{\\varepsilon_{i}\\}_{i=1}^{n}$，相应测得的柯西应力数据为 $\\{\\sigma_{i}^{\\text{obs}}\\}_{i=1}^{n}$。考虑一个确定性的本构响应映射 $\\sigma^{\\text{mod}}(\\varepsilon;\\theta)$，其中 $\\theta$ 是一个待标定的未知材料参数向量（例如，模量和硬化参数），并假设测量模型为\n$$\n\\sigma_{i}^{\\text{obs}} \\;=\\; \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta) \\;+\\; \\eta_{i},\n$$\n其中噪声项 $\\eta_{i}$ 代表测量应力与模型应力之间的差异。假设噪声具有如下异方差结构：$\\eta_{i}$ 是相互独立的、均值为零的高斯随机变量，其方差通过一个已知的正尺度函数 $f(\\varepsilon_{i},\\theta)$ 和一个正标量振幅 $\\alpha$ 依赖于应变 $\\varepsilon_{i}$ 和参数 $\\theta$，即\n$$\n\\operatorname{Var}(\\eta_{i}) \\;=\\; \\alpha^{2}\\,f(\\varepsilon_{i},\\theta)^{2}.\n$$\n假设 $\\alpha>0$ 是已知的。从独立高斯误差的定义和联合概率密度函数（PDF）的乘积形式出发，推导由上述模型所蕴含的异方差似然函数 $p(\\{\\sigma_{i}^{\\text{obs}}\\}_{i=1}^{n}\\mid \\theta)$，然后写出相应的对数似然函数 $L(\\theta)$ 作为 $\\theta$ 的函数。你的最终结果应为 $L(\\theta)$ 的一个单一闭式解析表达式，用 $\\{\\sigma_{i}^{\\text{obs}}\\}_{i=1}^{n}$、$\\{\\varepsilon_{i}\\}_{i=1}^{n}$、$\\sigma^{\\text{mod}}(\\cdot;\\theta)$、$f(\\cdot,\\theta)$ 和 $\\alpha$ 表示。不需要进行数值计算。如果在推导过程中省略了任何不依赖于 $\\theta$ 的加性常数，请明确指出，但你最终的 $L(\\theta)$ 表达式应包含所有项。最终答案必须是无单位的单一表达式。", "solution": "该问题是有效的，因为它提出了一个在材料模型标定的统计推断领域中，定义明确、有科学依据且标准的任务。该问题是自洽的，没有矛盾或歧义。我们开始推导。\n\n目标是针对给定的与施加应变 $\\{\\varepsilon_{i}\\}_{i=1}^{n}$ 相对应的观测应力数据 $\\{\\sigma_{i}^{\\text{obs}}\\}_{i=1}^{n}$，推导材料参数 $\\theta$ 的对数似然函数 $L(\\theta)$。\n\n测量模型由下式给出\n$$\n\\sigma_{i}^{\\text{obs}} \\;=\\; \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta) \\;+\\; \\eta_{i}\n$$\n其中 $i = 1, 2, \\ldots, n$。每次测量的噪声项 $\\eta_{i}$ 是一个随机变量。噪声项的属性规定如下：\n1.  它们相互独立。\n2.  它们服从均值为零的高斯（正态）分布，$E[\\eta_{i}] = 0$。\n3.  它们的方差是异方差的，由 $\\operatorname{Var}(\\eta_{i}) = \\alpha^{2}\\,f(\\varepsilon_{i},\\theta)^{2}$ 给出，其中 $\\alpha > 0$ 是一个已知常数，而 $f(\\varepsilon_{i},\\theta)$ 是一个已知的正函数。\n\n根据这些属性，我们可以描述每个噪声项 $\\eta_{i}$ 的概率分布。一个均值为 $\\mu$、方差为 $\\sigma^2$ 的高斯随机变量 $x$ 的概率密度函数（PDF）为\n$$\np(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right).\n$$\n对于噪声项 $\\eta_i$，我们有 $\\mu=0$ 且 $\\sigma^2 = \\operatorname{Var}(\\eta_{i}) = \\alpha^{2}\\,f(\\varepsilon_{i},\\theta)^{2}$。因此，$\\eta_i$ 的概率密度函数为\n$$\np(\\eta_i) = \\frac{1}{\\sqrt{2\\pi\\alpha^{2}\\,f(\\varepsilon_{i},\\theta)^{2}}} \\exp\\left(-\\frac{\\eta_i^2}{2\\alpha^{2}\\,f(\\varepsilon_{i},\\theta)^{2}}\\right).\n$$\n观测应力 $\\sigma_{i}^{\\text{obs}}$ 是随机变量 $\\eta_{i}$ 的一个线性变换：$\\sigma_{i}^{\\text{obs}} = \\eta_{i} + C$，其中对于给定的 $\\theta$ 和 $\\varepsilon_i$，$C = \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta)$ 是一个常数。高斯随机变量的线性变换结果是另一个高斯随机变量。$\\sigma_{i}^{\\text{obs}}$ 的均值为\n$$\nE[\\sigma_{i}^{\\text{obs}}] = E[\\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta) + \\eta_{i}] = \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta) + E[\\eta_{i}] = \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta).\n$$\n$\\sigma_{i}^{\\text{obs}}$ 的方差为\n$$\n\\operatorname{Var}(\\sigma_{i}^{\\text{obs}}) = \\operatorname{Var}(\\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta) + \\eta_{i}) = \\operatorname{Var}(\\eta_{i}) = \\alpha^{2}\\,f(\\varepsilon_{i},\\theta)^{2}.\n$$\n因此，对于参数向量 $\\theta$ 的给定值，每个观测值 $\\sigma_{i}^{\\text{obs}}$ 服从均值为 $\\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta)$、方差为 $\\alpha^{2}\\,f(\\varepsilon_{i},\\theta)^{2}$ 的高斯分布。以 $\\theta$ 为条件，单个观测值 $\\sigma_{i}^{\\text{obs}}$ 的概率密度函数是单个似然：\n$$\np(\\sigma_{i}^{\\text{obs}} \\mid \\theta) = \\frac{1}{\\sqrt{2\\pi\\alpha^{2}\\,f(\\varepsilon_{i},\\theta)^{2}}} \\exp\\left(-\\frac{(\\sigma_{i}^{\\text{obs}} - \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta))^2}{2\\alpha^{2}\\,f(\\varepsilon_{i},\\theta)^{2}}\\right).\n$$\n由于 $\\alpha > 0$ 且 $f(\\cdot,\\cdot) > 0$，平方根中的项可以简化为：$\\sqrt{2\\pi\\alpha^{2}\\,f(\\varepsilon_{i},\\theta)^{2}} = \\alpha f(\\varepsilon_{i},\\theta) \\sqrt{2\\pi}$。\n$$\np(\\sigma_{i}^{\\text{obs}} \\mid \\theta) = \\frac{1}{\\alpha f(\\varepsilon_{i},\\theta) \\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2\\alpha^2} \\left[ \\frac{\\sigma_{i}^{\\text{obs}} - \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta)}{f(\\varepsilon_{i},\\theta)} \\right]^2 \\right).\n$$\n问题指出噪声项 $\\eta_i$ 是相互独立的。这意味着以 $\\theta$ 为条件，观测值 $\\{\\sigma_{i}^{\\text{obs}}\\}_{i=1}^{n}$ 也是相互独立的。因此，整个观测数据集的联合似然函数是各个似然函数的乘积：\n$$\np(\\{\\sigma_{i}^{\\text{obs}}\\}_{i=1}^{n} \\mid \\theta) = \\prod_{i=1}^{n} p(\\sigma_{i}^{\\text{obs}} \\mid \\theta) = \\prod_{i=1}^{n} \\left( \\frac{1}{\\alpha f(\\varepsilon_{i},\\theta) \\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2\\alpha^2} \\left[ \\frac{\\sigma_{i}^{\\text{obs}} - \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta)}{f(\\varepsilon_{i},\\theta)} \\right]^2 \\right) \\right).\n$$\n对数似然函数 $L(\\theta)$ 是似然函数的自然对数：\n$$\nL(\\theta) = \\ln\\left( p(\\{\\sigma_{i}^{\\text{obs}}\\}_{i=1}^{n} \\mid \\theta) \\right) = \\ln\\left( \\prod_{i=1}^{n} p(\\sigma_{i}^{\\text{obs}} \\mid \\theta) \\right).\n$$\n利用对数性质 $\\ln(\\prod a_i) = \\sum \\ln(a_i)$，我们得到：\n$$\nL(\\theta) = \\sum_{i=1}^{n} \\ln\\left( p(\\sigma_{i}^{\\text{obs}} \\mid \\theta) \\right) = \\sum_{i=1}^{n} \\ln\\left( \\frac{1}{\\alpha f(\\varepsilon_{i},\\theta) \\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2\\alpha^2} \\left[ \\frac{\\sigma_{i}^{\\text{obs}} - \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta)}{f(\\varepsilon_{i},\\theta)} \\right]^2 \\right) \\right).\n$$\n利用性质 $\\ln(ab) = \\ln(a) + \\ln(b)$ 和 $\\ln(e^x)=x$：\n$$\nL(\\theta) = \\sum_{i=1}^{n} \\left[ \\ln\\left( \\frac{1}{\\alpha f(\\varepsilon_{i},\\theta) \\sqrt{2\\pi}} \\right) - \\frac{1}{2\\alpha^2} \\left( \\frac{\\sigma_{i}^{\\text{obs}} - \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta)}{f(\\varepsilon_{i},\\theta)} \\right)^2 \\right].\n$$\n使用 $\\ln(1/a) = -\\ln(a)$ 和 $\\ln(abc) = \\ln(a)+\\ln(b)+\\ln(c)$ 进一步简化对数项：\n$$\n\\ln\\left( \\frac{1}{\\alpha f(\\varepsilon_{i},\\theta) \\sqrt{2\\pi}} \\right) = - \\ln(\\alpha f(\\varepsilon_{i},\\theta) \\sqrt{2\\pi}) = -\\left( \\ln(\\alpha) + \\ln(f(\\varepsilon_{i},\\theta)) + \\ln(\\sqrt{2\\pi}) \\right).\n$$\n由于 $\\ln(\\sqrt{2\\pi}) = \\frac{1}{2}\\ln(2\\pi)$，上式变为：\n$$\n-\\ln(\\alpha) - \\ln(f(\\varepsilon_{i},\\theta)) - \\frac{1}{2}\\ln(2\\pi).\n$$\n将此代回 $L(\\theta)$ 的表达式：\n$$\nL(\\theta) = \\sum_{i=1}^{n} \\left[ -\\ln(\\alpha) - \\ln(f(\\varepsilon_{i},\\theta)) - \\frac{1}{2}\\ln(2\\pi) - \\frac{1}{2\\alpha^2} \\left( \\frac{\\sigma_{i}^{\\text{obs}} - \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta)}{f(\\varepsilon_{i},\\theta)} \\right)^2 \\right].\n$$\n最后，我们可以将求和内的项分开。项 $-\\ln(\\alpha)$ 和 $-\\frac{1}{2}\\ln(2\\pi)$ 不依赖于索引 $i$，所以它们对 $n$ 个项的求和就是该项的 $n$ 倍。\n$$\nL(\\theta) = -n\\ln(\\alpha) - \\frac{n}{2}\\ln(2\\pi) - \\sum_{i=1}^{n} \\ln(f(\\varepsilon_{i},\\theta)) - \\frac{1}{2\\alpha^2} \\sum_{i=1}^{n} \\left( \\frac{\\sigma_{i}^{\\text{obs}} - \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta)}{f(\\varepsilon_{i},\\theta)} \\right)^2.\n$$\n合并常数项，我们有 $-n(\\ln(\\alpha) + \\frac{1}{2}\\ln(2\\pi)) = -n\\ln(\\alpha\\sqrt{2\\pi}) = -\\frac{n}{2}\\ln(2\\pi\\alpha^2)$。这给出了对数似然函数的最终表达式，按要求包含了所有项。\n$$\nL(\\theta) = - \\frac{n}{2}\\ln(2\\pi\\alpha^2) - \\sum_{i=1}^{n} \\ln(f(\\varepsilon_{i},\\theta)) - \\frac{1}{2\\alpha^2} \\sum_{i=1}^{n} \\left[ \\frac{\\sigma_{i}^{\\text{obs}} - \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta)}{f(\\varepsilon_{i},\\theta)} \\right]^2.\n$$\n这就是所要求的对数似然函数 $L(\\theta)$ 的闭式解析表达式。", "answer": "$$\n\\boxed{\nL(\\theta) = - \\frac{n}{2}\\ln(2\\pi\\alpha^2) - \\sum_{i=1}^{n} \\ln(f(\\varepsilon_{i},\\theta)) - \\frac{1}{2\\alpha^2} \\sum_{i=1}^{n} \\left( \\frac{\\sigma_{i}^{\\text{obs}} - \\sigma^{\\text{mod}}(\\varepsilon_{i};\\theta)}{f(\\varepsilon_{i},\\theta)} \\right)^2\n}\n$$", "id": "3547176"}, {"introduction": "在校准复杂的材料模型时，从参数到预测的正向映射通常涉及计算密集型仿真，例如有限元（FE）方法。为了使用现代贝叶斯算法（如哈密顿蒙特卡洛或变分推断）高效地探索参数空间，我们需要对数似然函数关于参数的梯度。本问题通过引入伴随法（adjoint method）来正面应对梯度计算的挑战。您将在一个有限元框架内，为一个非线性超弹性模型推导并实现基于伴随法的梯度计算，该技术避免了直接灵敏度分析的巨大计算成本。这项练习在结合先进计算力学与高效贝叶斯推断方面提供了宝贵的经验，是现代不确定性量化的基石。 [@problem_id:3547183]", "problem": "考虑一个一维、无量纲化的超弹性杆，占据参考域 $[0,L]$，其中 $L=1$。该杆使用有限元（FE）方法进行离散化，包含 $N_e$ 个线性单元和 $N_n=N_e+1$ 个节点。节点位移场 $u(X)$ 定义了当前位置 $x=X+u(X)$ 和变形梯度 $F=1+\\frac{du}{dX}$。横截面积为 $A=1$，所有量均为无量纲，因此不涉及物理单位。\n\n假设一个可压缩的新胡克（Neo-Hookean）储存能量密度为\n$$\nW(F;\\theta)=\\frac{\\mu}{2}\\left(F^2-1\\right)-\\mu\\ln F+\\frac{\\lambda}{2}\\left(\\ln F\\right)^2,\n$$\n其中材料参数为 $\\theta=\\{\\lambda,\\mu\\}$。第一皮奥拉-基尔霍夫（Piola-Kirchhoff）应力为\n$$\nP(F;\\theta)=\\frac{\\partial W}{\\partial F}=\\mu F-\\frac{\\mu}{F}+\\frac{\\lambda \\ln F}{F}.\n$$\n杆受到指定的位移边界条件 $u(0)=0$ 和 $u(L)=U_0$ 的约束，没有体力或施加的面力。自由节点自由度的有限元内力残差 $R(u,\\theta)$ 是从虚功原理获得的。在每个长度为 $h=L/N_e$ 的单元上使用单点积分和线性形函数，单元内力贡献为 $[-P(F;\\theta),+P(F;\\theta)]$，并组装到全局残差中。切线矩阵 $A=\\frac{\\partial R}{\\partial u}$ 是通过对残差关于自由节点位移求导得到的，并通过 $\\frac{\\partial F}{\\partial u}$ 涉及到 $\\frac{\\partial P}{\\partial F}$。\n\n您观测到单元中点的应力，这些应力收集在数据向量 $D\\in\\mathbb{R}^m$ 中，其中 $m=N_e$。正向映射 $f(\\theta)$ 计算与边界条件一致的有限元解 $u(\\theta)$，并返回每个单元 $e=1,\\dots,N_e$ 的预测应力值 $P(F_e;\\theta)$。给定参数下数据的似然是高斯（Gaussian）分布的，每次测量的噪声独立且方差为 $\\sigma^2$：\n$$\np(D\\mid \\theta)\\propto \\exp\\left(-\\frac{1}{2}\\left(D-f(\\theta)\\right)^{\\!\\top}\\Sigma^{-1}\\left(D-f(\\theta)\\right)\\right),\\quad \\Sigma=\\sigma^2 I_m.\n$$\n您的任务是：\n- 从虚功原理和高斯似然定义出发，推导基于伴随方法的梯度 $\\frac{\\partial \\log p(D\\mid\\theta)}{\\partial \\theta}$，以避免显式计算 $\\frac{du}{d\\theta}$。用 $\\frac{\\partial f}{\\partial \\theta}$、$\\frac{\\partial f}{\\partial u}$、$\\frac{\\partial R}{\\partial u}$ 和 $\\frac{\\partial R}{\\partial \\theta}$ 表示伴随方程和最终的梯度公式。\n- 实现一个完整的程序，该程序：\n  1. 使用给定的 $W(F;\\theta)$ 和 $P(F;\\theta)$ 为一维杆建立有限元残差 $R(u,\\theta)$ 和切线矩阵 $A=\\frac{\\partial R}{\\partial u}$。\n  2. 使用牛顿法（Newton's method）求解具有指定位移边界条件的非线性有限元平衡方程 $R(u,\\theta)=0$。\n  3. 评估正向映射 $f(\\theta)$ 及其灵敏度 $\\frac{\\partial f}{\\partial \\theta}$ 和 $\\frac{\\partial f}{\\partial u}$，组装伴随系统，求解伴随变量，并使用您推导的公式计算 $\\frac{\\partial \\log p(D\\mid\\theta)}{\\partial \\theta}$。\n\n使用以下测试用例集，所有量均为无量纲：\n- 案例 1（一般情况）：$N_e=4$, $U_0=0.2$, $\\sigma=0.05$, 候选参数 $\\theta=\\{\\lambda=8.0,\\mu=4.0\\}$，数据 $D=[3.0274117,\\,2.9974117,\\,3.0324117,\\,3.0124117]$。\n- 案例 2（有限应变）：$N_e=3$, $U_0=0.5$, $\\sigma=0.08$, 候选参数 $\\theta=\\{\\lambda=12.0,\\mu=6.0\\}$，数据 $D=[8.545232495,\\,8.515232495,\\,8.525232495]$。\n- 案例 3（边界情况，接近单位拉伸）：$N_e=2$, $U_0=0.0$, $\\sigma=0.03$, 候选参数 $\\theta=\\{\\lambda=10.0,\\mu=5.0\\}$，数据 $D=[0.003,\\,-0.004]$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试案例的结果必须是该案例的双分量梯度向量 $[\\frac{\\partial \\log p}{\\partial \\lambda},\\frac{\\partial \\log p}{\\partial \\mu}]$，因此总输出是一个浮点数列表的列表，按测试用例的顺序排列，例如 $[[g_{\\lambda,1},g_{\\mu,1}],[g_{\\lambda,2},g_{\\mu,2}],[g_{\\lambda,3},g_{\\mu,3}]]$。", "solution": "该问题被评估为有效。它在科学上基于计算固体力学和贝叶斯推断的原理，是适定的、客观的且自洽的。提供了唯一解所需的所有必要数据和定义。\n\n问题的核心是为一组材料参数 $\\theta$ 推导并实现对数似然函数的基于伴随方法的梯度。这可以实现高效的灵敏度分析，这对于贝叶斯校准中的基于梯度的优化和采样方法至关重要。\n\n### 基于伴随方法的梯度推导\n\n设材料参数向量为 $\\theta = \\{\\lambda, \\mu\\}$。观测值收集在数据向量 $D$ 中。正向模型 $f(\\theta)$ 预测这些观测值。系统的状态由自由节点位移向量 $u$ 表示，它通过非线性有限元平衡方程 $R(u, \\theta) = 0$ 隐式地依赖于 $\\theta$。\n\n对数似然函数，忽略常数项，由下式给出：\n$$\nJ(\\theta) \\equiv \\log p(D \\mid \\theta) = -\\frac{1}{2\\sigma^2} (D - f(u(\\theta), \\theta))^T (D - f(u(\\theta), \\theta))\n$$\n我们的目标是计算 $J$ 相对于 $\\theta$ 的全导数，记为 $\\frac{dJ}{d\\theta}$。应用链式法则，我们得到：\n$$\n\\frac{dJ}{d\\theta} = \\frac{\\partial J}{\\partial \\theta} + \\frac{\\partial J}{\\partial u} \\frac{du}{d\\theta}\n$$\n其中 $\\frac{\\partial J}{\\partial \\theta}$ 和 $\\frac{\\partial J}{\\partial u}$ 是偏导数，$\\frac{du}{d\\theta}$ 是位移相对于参数的灵敏度。$\\frac{du}{d\\theta}$ 这一项直接计算的代价很高。伴随方法提供了一种绕过其显式计算的优雅方式。\n\n我们通过对平衡方程 $R(u, \\theta) = 0$ 关于 $\\theta$ 求全导数来找到 $\\frac{du}{d\\theta}$ 的表达式：\n$$\n\\frac{dR}{d\\theta} = \\frac{\\partial R}{\\partial \\theta} + \\frac{\\partial R}{\\partial u} \\frac{du}{d\\theta} = 0\n$$\n假设切线刚度矩阵 $A = \\frac{\\partial R}{\\partial u}$ 是可逆的，我们可以写出：\n$$\n\\frac{du}{d\\theta} = - \\left(\\frac{\\partial R}{\\partial u}\\right)^{-1} \\frac{\\partial R}{\\partial \\theta}\n$$\n将此代入 $\\frac{dJ}{d\\theta}$ 的表达式，得到直接灵敏度表达式：\n$$\n\\frac{dJ}{d\\theta} = \\frac{\\partial J}{\\partial \\theta} - \\frac{\\partial J}{\\partial u} \\left(\\frac{\\partial R}{\\partial u}\\right)^{-1} \\frac{\\partial R}{\\partial \\theta}\n$$\n这个表达式仍然需要为 $\\theta$ 中的每个参数求解一个线性系统。为了获得伴随公式，我们重新排列各项。让我们定义一个新向量，即伴随向量 $\\psi$，作为以下称为伴随方程的线性系统的解：\n$$\n\\left(\\frac{\\partial R}{\\partial u}\\right)^T \\psi = \\left(\\frac{\\partial J}{\\partial u}\\right)^T\n$$\n这个定义允许我们将 $\\frac{\\partial J}{\\partial u}$ 写为 $\\psi^T \\frac{\\partial R}{\\partial u}$。将此代入梯度表达式：\n$$\n\\frac{dJ}{d\\theta} = \\frac{\\partial J}{\\partial \\theta} - \\left(\\psi^T \\frac{\\partial R}{\\partial u}\\right) \\left(\\frac{\\partial R}{\\partial u}\\right)^{-1} \\frac{\\partial R}{\\partial \\theta} = \\frac{\\partial J}{\\partial \\theta} - \\psi^T \\frac{\\partial R}{\\partial \\theta}\n$$\n这就是最终的基于伴随方法的梯度公式。要使用它，我们需要 $J$ 的偏导数。从 $J$ 的定义：\n$$\n\\frac{\\partial J}{\\partial u} = \\frac{1}{\\sigma^2} (D - f)^T \\frac{\\partial f}{\\partial u}\n$$\n$$\n\\frac{\\partial J}{\\partial \\theta} = \\frac{1}{\\sigma^2} (D - f)^T \\frac{\\partial f}{\\partial \\theta}\n$$\n将这些代入我们的主要公式，得到可操作的方程：\n\n1.  **伴随方程**：\n    $$\n    \\left(\\frac{\\partial R}{\\partial u}\\right)^T \\psi = \\frac{1}{\\sigma^2} \\left(\\frac{\\partial f}{\\partial u}\\right)^T (D - f)\n    $$\n2.  **梯度公式**：\n    $$\n    \\frac{dJ}{d\\theta} = \\frac{1}{\\sigma^2} (D - f)^T \\frac{\\partial f}{\\partial \\theta} - \\psi^T \\frac{\\partial R}{\\partial \\theta}\n    $$\n\n### 算法实现\n\n计算按以下步骤进行：\n1.  **正向求解**：对于给定的参数集 $\\theta$，求解非线性方程组 $R(u, \\theta) = 0$ 以得到自由度的位移向量 $u$。这通过牛顿法完成，该方法迭代求解 $A \\Delta u = -R$，其中 $A = \\frac{\\partial R}{\\partial u}$ 是切线刚度矩阵。\n2.  **计算模型预测**：使用收敛的位移场 $u$，计算每个单元 $e$ 的变形梯度 $F_e$ 和第一皮奥拉-基尔霍夫应力 $P_e$。这些应力的向量构成了正向模型预测，$f(\\theta) = [P_1, \\dots, P_{N_e}]^T$。\n3.  **计算灵敏度**：在收敛状态 $(u, \\theta)$ 下评估所有必需的偏导数：\n    - $\\frac{\\partial R}{\\partial u}$：切线刚度矩阵 $A$，可从牛顿求解器的最后一步获得。\n    - $\\frac{\\partial R}{\\partial \\theta}$：残差对参数的灵敏度。\n    - $\\frac{\\partial f}{\\partial u}$：预测应力对位移的灵敏度。\n    - $\\frac{\\partial f}{\\partial \\theta}$：预测应力对参数的灵敏度。\n4.  **伴随求解**：组装伴随方程的右侧项，$b_{adj} = \\frac{1}{\\sigma^2} (\\frac{\\partial f}{\\partial u})^T (D - f)$，并求解线性系统 $A^T \\psi = b_{adj}$ 以得到伴随向量 $\\psi$。\n5.  **梯度组装**：计算梯度公式的两项并将它们组合起来，得到最终的梯度向量 $\\frac{dJ}{d\\theta}$。\n\n该过程对问题陈述中提供的每个测试用例都进行了实现。对于这个一维杆问题，由于均匀的几何形状和载荷，平衡位移场是线性的，导致所有单元的变形梯度 $F$ 是均匀的。然而，本实现采用了通用形式，并不依赖此简化。", "answer": "```python\nimport numpy as np\n\ndef solve_fe(params, Ne, U0):\n    \"\"\"\n    Solves the nonlinear FE equilibrium equation R(u, theta) = 0 using Newton's method.\n    \"\"\"\n    lambda_, mu = params\n    L = 1.0\n    h = L / Ne\n    num_free_dof = Ne - 1\n\n    if num_free_dof == 0:\n        # Case with no free DOFs (e.g., Ne=1)\n        u = np.linspace(0, U0, Ne + 1)\n        A = np.array([[]]) # No tangent for free dofs\n        return u, A, True\n\n    # Initial guess: linear displacement profile\n    u_free = np.linspace(0, U0, Ne + 1)[1:-1]\n    \n    max_iter = 20\n    tol = 1e-10\n\n    for _ in range(max_iter):\n        u = np.concatenate(([0], u_free, [U0]))\n        \n        u_diff = np.diff(u)\n        F = 1.0 + u_diff / h\n        \n        if np.any(F = 0):\n            return None, None, False\n\n        lnF = np.log(F)\n        P = mu * F - mu / F + lambda_ * lnF / F\n        \n        R_free = P[1:] - P[:-1]\n        \n        norm_R = np.linalg.norm(R_free)\n        if norm_R  tol:\n            # Converged. Re-compute tangent for return.\n            P_prime = mu + mu / F**2 + lambda_ * (1 - lnF) / F**2\n            diag = -(P_prime[1:] + P_prime[:-1]) / h\n            A = np.diag(diag)\n            if num_free_dof > 1:\n                sup_diag = P_prime[1:-1] / h\n                sub_diag = P_prime[1:-1] / h\n                A += np.diag(sup_diag, k=1) + np.diag(sub_diag, k=-1)\n            return u, A, True\n\n        P_prime = mu + mu / F**2 + lambda_ * (1 - lnF) / F**2\n        \n        diag = -(P_prime[1:] + P_prime[:-1]) / h\n        A = np.diag(diag)\n        if num_free_dof > 1:\n            sup_diag = P_prime[1:-1] / h\n            sub_diag = P_prime[1:-1] / h\n            A += np.diag(sup_diag, k=1) + np.diag(sub_diag, k=-1)\n\n        try:\n            delta_u = np.linalg.solve(A, -R_free)\n            u_free += delta_u\n        except np.linalg.LinAlgError:\n            return None, None, False\n            \n    return None, None, False # Did not converge\n\ndef calculate_gradient(params, Ne, U0, sigma, D):\n    \"\"\"\n    Calculates the adjoint-based gradient of the log-likelihood.\n    \"\"\"\n    lambda_, mu = params\n    h = 1.0 / Ne\n    num_free_dof = Ne - 1\n    \n    # 1. Forward Solve\n    u, A, converged = solve_fe(params, Ne, U0)\n    if not converged:\n        raise RuntimeError(\"FE solver did not converge for the given parameters.\")\n\n    # 2. Compute Model Prediction f(theta) and its derivatives\n    u_diff = np.diff(u)\n    F = 1.0 + u_diff / h\n    lnF = np.log(F)\n    \n    f_theta = mu * F - mu / F + lambda_ * lnF / F\n    misfit = D - f_theta\n    \n    # 3. Compute Sensitivities\n    # Partial derivative of P wrt F\n    P_prime = mu + mu / F**2 + lambda_ * (1 - lnF) / F**2\n\n    # df/dtheta (Ne x 2 matrix)\n    df_dlambda = lnF / F\n    df_dmu = F - 1.0 / F\n    df_dtheta = np.vstack((df_dlambda, df_dmu)).T\n    \n    if num_free_dof > 0:\n        # dR/dtheta ((Ne-1) x 2 matrix)\n        dR_dlambda = df_dlambda[1:] - df_dlambda[:-1]\n        dR_dmu = df_dmu[1:] - df_dmu[:-1]\n        dR_dtheta = np.vstack((dR_dlambda, dR_dmu)).T\n\n        # df/du_free (Ne x (Ne-1) matrix)\n        # u_free[j] corresponds to nodal displacement u_{j+1}\n        # df_e/du_free[j] = dP_e/dF_e * dF_e/du_{j+1}\n        df_du_free = np.zeros((Ne, num_free_dof))\n        for e in range(Ne): # over elements (rows)\n            # Contribution from u_{e+1} dependency\n            if e  num_free_dof: # u_{e+1} is u_free[e]\n                df_du_free[e, e] += P_prime[e] / h\n            # Contribution from u_e dependency\n            if e > 0 and (e - 1)  num_free_dof: # u_e is u_free[e-1]\n                df_du_free[e, e - 1] -= P_prime[e] / h\n        \n        # 4. Adjoint Solve\n        b_adj = df_du_free.T @ misfit / (sigma**2)\n        psi = np.linalg.solve(A.T, b_adj)\n        \n        # 5. Gradient Assembly\n        term1 = (misfit @ df_dtheta) / (sigma**2)\n        term2 = psi.T @ dR_dtheta\n        grad = term1 - term2\n    else: # No free dofs, gradient has no adjoint part\n        term1 = (misfit @ df_dtheta) / (sigma**2)\n        grad = term1\n\n    return grad.tolist()\n\ndef solve():\n    test_cases = [\n        {'Ne': 4, 'U0': 0.2, 'sigma': 0.05, 'params': (8.0, 4.0), \n         'D': np.array([3.0274117, 2.9974117, 3.0324117, 3.0124117])},\n        {'Ne': 3, 'U0': 0.5, 'sigma': 0.08, 'params': (12.0, 6.0), \n         'D': np.array([8.545232495, 8.515232495, 8.525232495])},\n        {'Ne': 2, 'U0': 0.0, 'sigma': 0.03, 'params': (10.0, 5.0), \n         'D': np.array([0.003, -0.004])},\n    ]\n\n    results = []\n    for case in test_cases:\n        grad = calculate_gradient(case['params'], case['Ne'], case['U0'], case['sigma'], case['D'])\n        results.append(grad)\n\n    # Format the output exactly as required.\n    # e.g., [[g_lam1,g_mu1],[g_lam2,g_mu2],[g_lam3,g_mu3]]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3547183"}]}