{"hands_on_practices": [{"introduction": "构建经验插值方法（EIM）近似需要选择合适的插值点。此练习将引导您实现并比较两种不同的点选择策略：一种是基于全局主元 QR 分解的标准方法，另一种是专为间断伽辽金（DG）方法设计的局部贪心策略。通过这个实践，您将深入了解 EIM 背后的算法选择及其对近似效果的影响。[@problem_id:3383616]", "problem": "考虑一维域 $[0,1]$，它被划分为 $E$ 个无重叠单元 $\\{K\\}_{K=1}^{E}$，每个单元都配备了 $n_p$ 个局部配置点。全局节点集由 $i=1,\\dots,M$ 索引，其中 $M=E \\cdot n_p$，每个索引 $i$ 都映射到一个唯一的单元 $K(i) \\in \\{1,\\dots,E\\}$。令 $x_i \\in [0,1]$ 表示与全局索引 $i$ 对应的坐标。\n\n设参数化状态由确定性函数 $u(x;\\mu)$ 给出，其中 $\\mu \\in [0,1]$ 是一个标量参数，并定义一个非线性算子 $\\mathcal{N}(u)$。您的任务是为 $\\mathcal{N}(u)$ 构建一个适用于间断伽辽金 (DG) 离散化的经验插值法 (EIM)，并比较两种点选择策略：\n- 由单元 DG 残差范数驱动的局部贪心策略。\n- 全局主元 QR 策略。\n\n请使用以下精确的数学规范。\n\n- 空间离散与参数化状态：\n  - 使用 $E=10$ 个单元，每个单元 $n_p=6$ 个节点。对于每个单元 $K$，将 $n_p$ 个节点均匀放置在单元内部，以使所有全局节点在不同单元间都是不同的。\n  - 定义\n    $$u(x;\\mu) = \\sin\\!\\big(2\\pi(x+0.3\\mu)\\big) + \\tfrac{1}{2}\\cos\\!\\big(5\\pi(x-0.2\\mu)\\big) + 0.2\\exp\\!\\big(-50(x-0.3-0.4\\mu)^2\\big)。$$\n  - 定义非线性算子\n    $$\\mathcal{N}(u) = u^2 + \\exp(u)。$$\n\n- 快照矩阵与降阶基：\n  - 令训练参数集为 $\\{\\mu_k\\}_{k=1}^{N_\\mathrm{train}}$，其中包含 $[0,1]$ 上的 $N_\\mathrm{train}=24$ 个等距值。\n  - 构建快照矩阵 $S \\in \\mathbb{R}^{M \\times N_\\mathrm{train}}$，其元素为\n    $$S_{i,k} = \\mathcal{N}(u(x_i;\\mu_k))。$$\n  - 计算薄奇异值分解 $S = U \\Sigma V^\\top$，并将 $U$ 的前 $r_{\\max}$ 列定义为降阶空间基，记为 $\\Phi = [\\phi_1,\\dots,\\phi_{r_{\\max}}] \\in \\mathbb{R}^{M \\times r_{\\max}}$，其中 $r_{\\max}=12$。\n\n- 离散经验插值法 (EIM) 近似算子：\n  - 对于基数为 $r$ 的插值索引集 $\\mathcal{I}_r = \\{i_1,\\dots,i_r\\} \\subset \\{1,\\dots,M\\}$，令 $P_{\\mathcal{I}_r} \\in \\mathbb{R}^{M \\times r}$ 为在索引 $\\mathcal{I}_r$ 处提取元素的采样矩阵。\n  - 任意向量 $f \\in \\mathbb{R}^M$ 的秩-r EIM 近似由下式给出\n    $$\\mathcal{P}_r(f) = \\Phi_r \\left(P_{\\mathcal{I}_r}^\\top \\Phi_r\\right)^{-1} P_{\\mathcal{I}_r}^\\top f,$$\n    其中 $\\Phi_r = [\\phi_1,\\dots,\\phi_r]$。\n\n- 需要实现的点选择策略：\n  1. 由单元 DG 残差范数驱动的局部贪心策略：\n     - 用空索引集初始化。对于 $k=1,\\dots,r_{\\max}$：\n       - 使用已选择的索引 $\\mathcal{I}_{k-1}$ 将 $\\phi_k$ 的当前近似定义为\n         $$\\widehat{\\phi}_k = \\begin{cases}\n         0,  k=1,\\\\\n         \\Phi_{k-1} \\left(P_{\\mathcal{I}_{k-1}}^\\top \\Phi_{k-1}\\right)^{-1} P_{\\mathcal{I}_{k-1}}^\\top \\phi_k,  k \\ge 2,\n         \\end{cases}$$\n         以及残差 $r_k = \\phi_k - \\widehat{\\phi}_k \\in \\mathbb{R}^M$。\n       - 对每个单元 $K$，计算单元 DG 残差范数\n         $$\\|r_k\\|_{K} = \\left(\\sum_{i:K(i)=K} r_k(i)^2\\right)^{1/2}。$$\n       - 令 $K^\\star$ 为使 $\\|r_k\\|_K$ 最大化的单元。选择单元 $K^\\star$ 内使 $|r_k(i)|$ 最大化的索引作为新的插值索引 $i_k$。设置 $\\mathcal{I}_k = \\mathcal{I}_{k-1} \\cup \\{i_k\\}$。\n  2. 全局主元 QR：\n     - 计算 $\\Phi^\\top$ 的列主元 QR 分解，并将主元顺序定义为 $\\{1,\\dots,M\\}$ 的一个排列。对于秩 $r$，取前 $r$ 个主元索引作为 $\\mathcal{I}_r$。\n\n- 评估协议：\n  - 定义测试参数集 $\\{\\mu^\\mathrm{test}_j\\}_{j=1}^{N_\\mathrm{test}}$，包含 $N_\\mathrm{test}=4$ 个值 $\\{0.07, 0.31, 0.58, 0.83\\}$。\n  - 对于每个秩 $r \\in \\{1,4,8,12\\}$ 和每个测试参数 $\\mu^\\mathrm{test}_j$：\n    - 构成 $f = \\mathcal{N}(u(\\cdot;\\mu^\\mathrm{test}_j)) \\in \\mathbb{R}^M$。\n    - 使用局部贪心索引 $\\mathcal{I}^{\\mathrm{loc}}_r$ 计算 EIM 近似 $\\widehat{f}_\\mathrm{loc}$，并使用主元 QR 索引 $\\mathcal{I}^{\\mathrm{qr}}_r$ 计算 $\\widehat{f}_\\mathrm{qr}$。\n    - 计算相对误差\n      $$e_\\mathrm{loc}(r,\\mu^\\mathrm{test}_j) = \\frac{\\|f - \\widehat{f}_\\mathrm{loc}\\|_2}{\\|f\\|_2}, \\quad e_\\mathrm{qr}(r,\\mu^\\mathrm{test}_j) = \\frac{\\|f - \\widehat{f}_\\mathrm{qr}\\|_2}{\\|f\\|_2}。$$\n  - 对于每个秩 $r$，计算两种方法在测试集上的平均相对误差：\n    $$\\overline{e}_\\mathrm{loc}(r) = \\frac{1}{N_\\mathrm{test}} \\sum_{j=1}^{N_\\mathrm{test}} e_\\mathrm{loc}(r,\\mu^\\mathrm{test}_j), \\quad \\overline{e}_\\mathrm{qr}(r) = \\frac{1}{N_\\mathrm{test}} \\sum_{j=1}^{N_\\mathrm{test}} e_\\mathrm{qr}(r,\\mu^\\mathrm{test}_j)。$$\n\n您的任务：\n- 完全且确定性地实现上述流程。\n- 仅使用为指定矩阵和向量良好定义的线性代数运算。如果在任何步骤中线性求解是病态或奇异的，请使用最小二乘解而不是失败。\n- 您必须构建您的程序，以针对秩 $r \\in \\{1,4,8,12\\}$ 按此确切顺序生成以下最终输出：\n  $$\\left[\\overline{e}_\\mathrm{loc}(1), \\overline{e}_\\mathrm{qr}(1), \\overline{e}_\\mathrm{loc}(4), \\overline{e}_\\mathrm{qr}(4), \\overline{e}_\\mathrm{loc}(8), \\overline{e}_\\mathrm{qr}(8), \\overline{e}_\\mathrm{loc}(12), \\overline{e}_\\mathrm{qr}(12)\\right]。$$\n\n测试套件和答案规范：\n- 您必须使用上面指定的精确参数值、空间离散和秩。\n- 每个测试用例的输出必须是浮点数。最终输出格式必须是单行，包含一个 Python 风格的列表，其中有八个浮点数，顺序与描述完全一致，不带单位，也没有附加文本。程序必须在没有任何用户输入的情况下运行，并且不得依赖任何外部文件或网络资源。", "solution": "用户提供的问题是数值分析中一个明确定义的任务，具体涉及模型降阶和经验插值法 (EIM)。它具有科学依据、自成体系且算法上是明确的。该问题被认为是有效的。\n\n解决方案是通过逐步遵循指定的流程来构建的。\n\n### 1. 离散化与问题设置\n\n首先，我们建立计算域和离散化。空间域为 $[0,1]$。它被划分为 $E=10$ 个单元，记为 $K_e = [(e-1)/E, e/E]$，其中 $e=1, \\dots, 10$。在每个单元内部，我们均匀放置 $n_p=6$ 个配置点。单元 $K_e$ 中第 $j$ 个节点（$j=1, \\dots, n_p$）的坐标由 $x_{e,j} = \\frac{e-1}{E} + j \\frac{1/E}{n_p+1}$ 给出。这产生了一组 $M = E \\cdot n_p = 60$ 个不同的全局节点，其坐标记为 $x_i$，其中 $i=1, \\dots, M$。一个映射 $K(i)$ 将每个全局节点索引 $i$ 与其对应的单元索引关联起来。\n\n参数化状态函数 $u(x;\\mu)$ 和非线性算子 $\\mathcal{N}(u)$ 定义如下：\n$$u(x;\\mu) = \\sin\\!\\big(2\\pi(x+0.3\\mu)\\big) + \\tfrac{1}{2}\\cos\\!\\big(5\\pi(x-0.2\\mu)\\big) + 0.2\\exp\\!\\big(-50(x-0.3-0.4\\mu)^2\\big)$$\n$$\\mathcal{N}(u) = u^2 + \\exp(u)$$\n其中 $\\mu \\in [0,1]$ 是一个标量参数。\n\n### 2. 降阶基生成\n\n非线性输出的降阶基是使用快照法生成的。\n参数 $\\mu$ 的训练集是 $[0,1]$ 中一个由 $N_{\\mathrm{train}}=24$ 个点组成的等距网格，记为 $\\{\\mu_k\\}_{k=1}^{24}$。\n对于每个 $\\mu_k$，我们在所有全局节点 $x_i$ 上评估非线性算子，以形成快照向量 $f_k \\in \\mathbb{R}^M$，其中 $(f_k)_i = \\mathcal{N}(u(x_i; \\mu_k))$。\n这些快照被收集为快照矩阵的列 $S = [f_1 | f_2 | \\dots | f_{N_{\\mathrm{train}}}] \\in \\mathbb{R}^{M \\times N_{\\mathrm{train}}}$。\n\n然后我们计算快照矩阵的薄奇异值分解 (SVD)：$S = U \\Sigma V^\\top$。$U \\in \\mathbb{R}^{M \\times N_{\\mathrm{train}}}$ 的列，即左奇异向量，构成了由快照张成的空间的最优正交基。降阶基 $\\Phi \\in \\mathbb{R}^{M \\times r_{\\max}}$ 是通过取 $U$ 的前 $r_{\\max}=12$ 列构建的，即 $\\Phi = [\\phi_1, \\dots, \\phi_{r_{\\max}}]$。秩为 $r$ 的基记为 $\\Phi_r = [\\phi_1, \\dots, \\phi_r]$。\n\n### 3. 点选择策略\n\n任务的核心是从 $M$ 个可用节点中选择一组 $r$ 个插值点（或全局节点索引）$\\mathcal{I}_r = \\{i_1, \\dots, i_r\\}$。我们实现并比较两种策略。\n\n#### 3.1. 局部贪心策略\n\n这是一个迭代过程。对于 $k=1, \\dots, r_{\\max}$，我们选择第 $k$ 个索引 $i_k$。选择基于残差向量 $r_k = \\phi_k - \\widehat{\\phi}_k$，其中 $\\widehat{\\phi}_k$ 是使用先前选择的 $k-1$ 个索引对第 $k$ 个基向量 $\\phi_k$ 进行的 EIM 近似。\n对于 $k=1$，尚未选择任何索引，因此残差就是 $r_1 = \\phi_1$。\n对于 $k1$，给定索引集 $\\mathcal{I}_{k-1}=\\{i_1, \\dots, i_{k-1}\\}$，近似为：\n$$\\widehat{\\phi}_k = \\Phi_{k-1} \\left(P_{\\mathcal{I}_{k-1}}^\\top \\Phi_{k-1}\\right)^{-1} P_{\\mathcal{I}_{k-1}}^\\top \\phi_k$$\n其中 $P_{\\mathcal{I}_{k-1}}$ 是在 $\\mathcal{I}_{k-1}$ 中的索引处对向量进行采样的算子。为了数值稳定性，使用最小二乘法（`numpy.linalg.lstsq`）求解系数的线性系统。\n\n一旦计算出残差 $r_k$，我们为每个单元 $K$ 计算其单元 $L_2$ 范数：$\\|r_k\\|_K = (\\sum_{i: K(i)=K} r_k(i)^2)^{1/2}$。我们找出使该范数最大化的单元 $K^\\star$。然后选择 $K^\\star$ 内使残差绝对值 $|r_k(i)|$ 最大化的节点作为新索引 $i_k$。更新索引集：$\\mathcal{I}_k = \\mathcal{I}_{k-1} \\cup \\{i_k\\}$。对 $k=1, \\dots, r_{\\max}$ 重复此过程，以生成有序索引列表 $\\mathcal{I}^{\\mathrm{loc}}_{r_{\\max}}$。\n\n#### 3.2. 全局主元 QR 策略\n\n该策略利用了列主元 QR 分解的特性。它是一种非迭代的直接方法。我们计算基矩阵转置 $\\Phi^\\top$ 的列主元 QR 分解。分解为 $\\Phi^\\top P = QR$，其中 $P$ 是一个置换矩阵，它对 $\\Phi^\\top$ 的列进行重新排序，以确保得到一个良态的上三角矩阵 $R$。$\\Phi^\\top$ 的列对应于全局节点 $\\{1, \\dots, M\\}$。因此，置换 $P$ 定义了对 $\\Phi$ 中最线性无关的行的贪心选择。从置换中获得的主元索引被用作插值点。对于秩为 $r$ 的近似，我们使用前 $r$ 个主元索引。此过程生成有序索引列表 $\\mathcal{I}^{\\mathrm{qr}}_{r_{\\max}}$。\n\n### 4. EIM 近似的评估\n\n我们对两组选定点的 EIM 准确性进行评估。向量 $f \\in \\mathbb{R}^M$ 的秩-r EIM 近似由下式给出：\n$$\\mathcal{P}_r(f) = \\Phi_r \\left(P_{\\mathcal{I}_r}^\\top \\Phi_r\\right)^{-1} P_{\\mathcal{I}_r}^\\top f$$\n同样，逆是通过对系数 $c$ 的系统 $(P_{\\mathcal{I}_r}^\\top \\Phi_r)c = P_{\\mathcal{I}_r}^\\top f$ 进行稳健的最小二乘求解来计算的，然后进行重构 $\\mathcal{P}_r(f) = \\Phi_r c$。\n\n评估使用一组测试参数 $\\mu^\\mathrm{test} = \\{0.07, 0.31, 0.58, 0.83\\}$。对于每个秩 $r \\in \\{1, 4, 8, 12\\}$ 和每个 $\\mu^\\mathrm{test}_j$，我们执行以下操作：\n1.  在所有全局节点上计算“真实”输出向量 $f = \\mathcal{N}(u(\\cdot; \\mu^\\mathrm{test}_j))$。\n2.  使用局部贪心索引 $\\mathcal{I}^{\\mathrm{loc}}_r$ 计算 EIM 近似 $\\widehat{f}_{\\mathrm{loc}}$。\n3.  使用主元 QR 索引 $\\mathcal{I}^{\\mathrm{qr}}_r$ 计算 EIM 近似 $\\widehat{f}_{\\mathrm{qr}}$。\n4.  计算两种方法的相对误差：\n    $$e_{\\mathrm{loc}}(r,\\mu^\\mathrm{test}_j) = \\frac{\\|f - \\widehat{f}_{\\mathrm{loc}}\\|_2}{\\|f\\|_2}, \\quad e_{\\mathrm{qr}}(r,\\mu^\\mathrm{test}_j) = \\frac{\\|f - \\widehat{f}_{\\mathrm{qr}}\\|_2}{\\|f\\|_2}$$\n\n最后，对于每个秩 $r$，我们计算每种方法在测试集上的平均相对误差 $\\overline{e}_\\mathrm{loc}(r)$ 和 $\\overline{e}_\\mathrm{qr}(r)$。最终输出是这八个值的有序列表。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import qr\n\ndef solve():\n    \"\"\"\n    Implements and compares two EIM point-selection strategies:\n    1. Localized greedy based on elementwise DG residual norms.\n    2. Global pivoted QR decomposition.\n    \"\"\"\n    # 1. Define constants and parameters\n    E = 10\n    n_p = 6\n    M = E * n_p\n    N_train = 24\n    r_max = 12\n    \n    mu_train = np.linspace(0, 1, N_train)\n    mu_test = np.array([0.07, 0.31, 0.58, 0.83])\n    ranks_eval = [1, 4, 8, 12]\n\n    # 2. Generate global node coordinates\n    x_nodes = np.zeros(M)\n    h = 1.0 / E\n    for e in range(E):\n        x_min = e * h\n        for j in range(n_p):\n            x_nodes[e * n_p + j] = x_min + (j + 1) * h / (n_p + 1)\n\n    # 3. Define the state function and nonlinear operator\n    def u_func(x, mu):\n        term1 = np.sin(2 * np.pi * (x + 0.3 * mu))\n        term2 = 0.5 * np.cos(5 * np.pi * (x - 0.2 * mu))\n        term3 = 0.2 * np.exp(-50 * (x - 0.3 - 0.4 * mu)**2)\n        return term1 + term2 + term3\n\n    def N_op(u_val):\n        return u_val**2 + np.exp(u_val)\n\n    # 4. Construct the snapshot matrix\n    S = np.zeros((M, N_train))\n    for k, mu in enumerate(mu_train):\n        u_vals = u_func(x_nodes, mu)\n        S[:, k] = N_op(u_vals)\n\n    # 5. Compute SVD and extract the reduced basis Phi\n    U, _, _ = np.linalg.svd(S, full_matrices=False)\n    Phi = U[:, :r_max]\n\n    # 6. Point Selection Strategy 1: Localized Greedy\n    indices_loc = []\n    for k_idx in range(r_max):\n        phi_k = Phi[:, k_idx]\n        \n        if k_idx == 0:\n            residual = phi_k\n        else:\n            Phi_prev = Phi[:, :k_idx]\n            # Solve (P^T Phi_prev) c = P^T phi_k for coefficients c\n            A = Phi_prev[indices_loc, :]\n            b = phi_k[indices_loc]\n            # Use least-squares for robustness as per problem spec\n            coeffs, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n            phi_hat = Phi_prev @ coeffs\n            residual = phi_k - phi_hat\n        \n        # Compute element-wise residual L2 norms\n        # Reshape residual into (E, n_p) to calculate norm per element\n        res_reshaped = residual.reshape((E, n_p))\n        element_norms = np.linalg.norm(res_reshaped, axis=1)\n        \n        # Find element with the maximum residual norm\n        best_element_idx = np.argmax(element_norms)\n        \n        # Find index within that element that maximizes |residual|\n        start_idx = best_element_idx * n_p\n        end_idx = start_idx + n_p\n        local_max_idx = np.argmax(np.abs(residual[start_idx:end_idx]))\n        new_index = start_idx + local_max_idx\n        \n        indices_loc.append(new_index)\n\n    # 7. Point Selection Strategy 2: Global Pivoted QR\n    # Column-pivoted QR of Phi^T gives a row pivot selection for Phi\n    _, _, p = qr(Phi.T, pivoting=True)\n    indices_qr = p[:r_max]\n\n    # 8. Evaluation Protocol\n    final_results = []\n    for r in ranks_eval:\n        errors_loc = []\n        errors_qr = []\n\n        # Get the basis and index sets for the current rank r\n        Phi_r = Phi[:, :r]\n        I_loc_r = indices_loc[:r]\n        I_qr_r = indices_qr[:r]\n\n        for mu_j in mu_test:\n            # Generate the full-order model output for the test parameter\n            f = N_op(u_func(x_nodes, mu_j))\n            f_norm = np.linalg.norm(f)\n\n            # --- Localized Greedy Method Evaluation ---\n            A_loc = Phi_r[I_loc_r, :]\n            b_loc = f[I_loc_r]\n            coeffs_loc, _, _, _ = np.linalg.lstsq(A_loc, b_loc, rcond=None)\n            f_hat_loc = Phi_r @ coeffs_loc\n            err_loc = np.linalg.norm(f - f_hat_loc) / f_norm\n            errors_loc.append(err_loc)\n\n            # --- Pivoted QR Method Evaluation ---\n            A_qr = Phi_r[I_qr_r, :]\n            b_qr = f[I_qr_r]\n            coeffs_qr, _, _, _ = np.linalg.lstsq(A_qr, b_qr, rcond=None)\n            f_hat_qr = Phi_r @ coeffs_qr\n            err_qr = np.linalg.norm(f - f_hat_qr) / f_norm\n            errors_qr.append(err_qr)\n        \n        # Compute mean errors for rank r and append to results\n        avg_err_loc = np.mean(errors_loc)\n        avg_err_qr = np.mean(errors_qr)\n        final_results.extend([avg_err_loc, avg_err_qr])\n\n    # 9. Print the final results in the specified format\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3383616"}, {"introduction": "一个 EIM 代理模型的性能在很大程度上取决于其训练所用的“快照”数据集。这个练习旨在揭示快照选择对 EIM 泛化能力的关键影响。通过比较一个仅在近稳态解上训练的模型与另一个包含瞬态动力学信息的模型，您将能够量化训练数据多样性对于构建稳健代理模型的重要价值。[@problem_id:3383626]", "problem": "考虑离散经验插值法 (EIM)，该方法用于逼近谱方法和间断伽辽金 (DG) 方法中出现的非线性算子。目标是为一个非线性算子构建一个基于插值的代理模型，该算子将离散场映射到离散残差，构建过程使用一组训练快照。您将研究包含瞬态快照对未经训练的马赫数的泛化误差的影响，通过两个典型的流动代理模型进行研究，这两个模型分别对应经典的可压缩欧拉方程测试问题：一个熵稳定激波管代理模型和一个等熵涡代理模型。\n\n基本背景包括以下广泛接受的定义和事实：\n- 间断伽辽金 (DG) 方法是一种使用间断多项式空间的有限元方法，对于非线性守恒律，该方法通常采用分裂形式的离散化和熵稳定的数值通量来控制混叠并确保稳定性。在一维情况下，对于具有光滑测试函数的标量场 $u(x)$，非线性通量导数在谱网格上通过一个离散微分矩阵作用于 $u$ 的一个非线性函数来表示。\n- 谱方法使用全局基函数和在特殊节点上的配置。对于整数 $N \\geq 1$，切比雪夫-高斯-洛巴托 (Chebyshev-Gauss-Lobatto) 节点定义为 $x_j = \\cos(\\pi j / N)$，其中 $j = 0, 1, \\dots, N$，这些节点位于 $[-1,1]$ 区间内。与这些节点相关的谱微分矩阵 $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ 的元素为\n$$\nD_{ij} = \\begin{cases}\n\\frac{c_i}{c_j} \\frac{(-1)^{i+j}}{x_i - x_j},  i \\neq j,\\\\\n-\\frac{x_i}{2(1-x_i^2)},  1 \\leq i = j \\leq N-1,\\\\\n\\frac{2N^2+1}{6},  i=j=0,\\\\\n-\\frac{2N^2+1}{6},  i=j=N,\n\\end{cases}\n$$\n其中 $c_0 = c_N = 2$，$c_j = 1$ 对于 $1 \\leq j \\leq N-1$。\n- 经验插值法 (EIM) 通过投影到由经验基向量张成的子空间上来逼近非线性算子 $\\mathcal{N} : \\mathbb{R}^Q \\rightarrow \\mathbb{R}^Q$，并通过在选定的索引处强制插值来确定系数。一个标准的实用流程是使用本征正交分解 (POD) 从快照中提取主导模态，并使用离散经验插值法 (DEIM) 贪婪地选择插值索引。给定一个快照矩阵 $F \\in \\mathbb{R}^{Q \\times S}$ 及其奇异值分解 $F = U \\Sigma V^\\top$，前 $r$ 个左奇异向量 $U_r \\in \\mathbb{R}^{Q \\times r}$ 作为基。DEIM 通过一个贪婪算法选择索引 $\\{p_1, \\dots, p_r\\}$，该算法基于最大化 $U_r$ 的连续投影在先前选择的插值约束上的绝对残差。一个新向量 $f \\in \\mathbb{R}^Q$ 的 EIM 逼近为 $\\hat{f} = U_r c$，其中系数向量 $c \\in \\mathbb{R}^r$ 通过求解方形线性系统 $U_r[P,:] c = f[P]$ 得到，其中 $P = [p_1,\\dots,p_r]$，$U_r[P,:]$ 是在这些行上的子矩阵。\n\n在本问题中，在切比雪夫-高斯-洛巴托网格上定义两个代理非线性算子：\n\n1. 一维熵稳定激波管代理模型：\n   - 区域：$x \\in [-1,1]$，其中 $N_x = 64$ 给出 $65$ 个节点。\n   - 马赫数参数：$M \\in \\mathbb{R}_{0}$。\n   - 时间参数：$t \\in \\mathbb{R}_{\\geq 0}$。\n   - 代理场：\n     $$\n     \\phi_{\\mathrm{shock}}(x; M, t) = \\frac{M}{2} \\left[1 + \\tanh\\!\\left(k(M)\\,(x - s(M)\\,t)\\right)\\right] + 0.05\\,M\\,\\sin(8\\pi x)\\,e^{-t},\n     $$\n     其中 $k(M) = 6M$，$s(M) = \\frac{M}{2}$。增加的衰减高频项用于模拟瞬态内容。\n   - 非线性算子：\n     $$\n     \\mathcal{N}_{\\mathrm{shock}}(M,t) = D \\left(\\frac{\\phi_{\\mathrm{shock}}(\\cdot;M,t)^2}{2}\\right),\n     $$\n     其中 $D$ 是切比雪夫-高斯-洛巴托微分矩阵。\n\n2. 二维等熵涡代理模型：\n   - 区域：$(x,y) \\in [-1,1] \\times [-1,1]$，其中每个坐标 $N_y = 32$ 给出 $33$ 个节点，并形成张量积配置网格。\n   - 马赫数参数：$M \\in \\mathbb{R}_{0}$。\n   - 时间参数：$t \\in \\mathbb{R}_{\\geq 0}$。\n   - 代理场：\n     $$\n     \\phi_{\\mathrm{vortex}}(x,y; M,t) = M\\,\\exp\\!\\left(-\\alpha(M)\\left[(x - v_x(M)\\,t)^2 + (y - v_y(M)\\,t)^2\\right]\\right)\\,\\sin(\\pi x)\\,\\cos(\\pi y) + 0.05\\,M\\,\\sin(6\\pi(x+y))\\,e^{-t},\n     $$\n     其中 $\\alpha(M) = 1 + M$，$v_x(M) = v_y(M) = \\frac{M}{2}$。高斯包络和三角函数因子模拟了一个带有瞬态高频内容的移动旋转结构。\n   - 非线性算子：\n     $$\n     \\mathcal{N}_{\\mathrm{vortex}}(M,t) = \\partial_x\\!\\left(\\phi_{\\mathrm{vortex}}^2\\right) + \\partial_y\\!\\left(\\phi_{\\mathrm{vortex}}^2\\right),\n     $$\n     通过在每个坐标上应用一维微分矩阵 $D$ 来计算：如果 $G = \\phi_{\\mathrm{vortex}}^2$ 在张量网格上排列成一个矩阵，则 $\\partial_x(G) = D\\,G$ 和 $\\partial_y(G) = G\\,D^\\top$，然后扁平化为一个向量。\n\n训练策略：\n- 策略 $\\mathrm{S0}$ (稳态主导)：使用训练时间 $t \\in \\{0.3,\\,0.4,\\,0.5\\}$。\n- 策略 $\\mathrm{S1}$ (包含瞬态)：使用训练时间 $t \\in \\{0.05,\\,0.2,\\,0.5\\}$。\n\n对于每个代理模型场景，使用以下训练马赫数：\n- 激波管训练马赫数：$M \\in \\{1.2,\\,2.0\\}$。\n- 涡旋训练马赫数：$M \\in \\{0.4,\\,0.8\\}$。\n\n对于每种策略，通过拼接所有指定 $(M,t)$ 对的列 $\\mathcal{N}(M,t)$ 来构建快照矩阵。从此矩阵中，构建一个秩为 $r=6$ 的 POD 基（如果奇异值少于6个，则取 $r$ 等于可用的奇异值数量），然后构建 DEIM 插值索引。使用这些来为每个场景定义两个 EIM 模型：一个用于 $\\mathrm{S0}$，一个用于 $\\mathrm{S1}$。\n\n将未经训练的马赫数 $M^\\star$ 和时间 $t^\\star$ 的泛化误差定义为相对欧几里得范数误差\n$$\n\\epsilon(M^\\star, t^\\star) = \\frac{\\left\\| \\mathcal{N}(M^\\star,t^\\star) - \\widehat{\\mathcal{N}}(M^\\star,t^\\star)\\right\\|_2}{\\left\\|\\mathcal{N}(M^\\star,t^\\star)\\right\\|_2},\n$$\n其中 $\\widehat{\\mathcal{N}}$ 是使用所选策略的 EIM 重构。\n\n测试套件：\n- 激波管测试 (一维)：\n  1. 未经训练的马赫数 $M^\\star = 1.6$ 于 $t^\\star = 0.15$。\n  2. 未经训练的马赫数 $M^\\star = 3.0$ 于 $t^\\star = 0.15$ (较高马赫数的边缘情况)。\n- 等熵涡测试 (二维)：\n  3. 未经训练的马赫数 $M^\\star = 0.6$ 于 $t^\\star = 0.15$。\n  4. 未经训练的马赫数 $M^\\star = 0.2$ 于 $t^\\star = 0.15$ (较低马赫数的边缘情况)。\n\n对于每个测试用例，计算改进量\n$$\n\\Delta = \\epsilon_{\\mathrm{S0}}(M^\\star, t^\\star) - \\epsilon_{\\mathrm{S1}}(M^\\star, t^\\star),\n$$\n这是一个实数。按指定顺序报告所有四个改进量。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，“[result1,result2,result3,result4]”）。角度不出现，且由于所有量都是无量纲的，因此不需要物理单位。\n\n请精确实现上述设置：\n- 使用指定的切比雪夫-高斯-洛巴托节点和微分矩阵。\n- 在一维中使用 $N_x = 64$，在二维中每个坐标使用 $N_y = 32$。\n- 使用所述的训练时间和马赫数。\n- 对两种策略都使用 POD 秩 $r=6$，如果快照数量少于6个，则截断为快照数量。\n\n最终输出必须是四个浮点数改进量 $\\Delta$ 的列表，顺序与测试套件一致：激波管在 $M^\\star=1.6$ 时，激波管在 $M^\\star=3.0$ 时，涡旋在 $M^\\star=0.6$ 时，涡旋在 $M^\\star=0.2$ 时。", "solution": "用户提供了一个问题，要求实现并比较应用于流体动力学模拟中非线性算子的两种经验插值法 (EIM) 训练策略。该问题定义明确、科学上合理且数值上易于处理。所有必要的定义、参数和步骤都已指定。因此，该问题被认为是有效的。\n\n解决方案的步骤是首先实现必要的数学构造，然后构建指定的 EIM 模型，最后在给定的测试用例上评估其性能，以计算所需的改进度量。\n\n### 步骤 1：数学和算法准备\n\n所需的核心组件是切比雪夫-高斯-洛巴托 (CGL) 节点及相关的谱微分矩阵、代理非线性算子，以及本征正交分解-离散经验插值法 (POD-DEIM) 算法。\n\n**切比雪夫-高斯-洛巴托网格和微分矩阵**\n\n对于一个多项式阶数 $N$，在区间 $[-1, 1]$ 上的 $N+1$ 个 CGL 节点由以下公式给出：\n$$\nx_j = \\cos\\left(\\frac{\\pi j}{N}\\right), \\quad j = 0, 1, \\dots, N\n$$\n在这些节点上能够精确微分最高 $N$ 阶多项式的谱微分矩阵 $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ 由其元素 $D_{ij}$ 定义。对于 $i \\neq j$：\n$$\nD_{ij} = \\frac{c_i}{c_j} \\frac{(-1)^{i+j}}{x_i - x_j}\n$$\n其中 $c_0 = c_N = 2$，$c_j = 1$ 对于 $1 \\leq j \\leq N-1$。对角线元素为：\n$$\nD_{jj} = \\begin{cases}\n\\frac{2N^2+1}{6},  j=0, \\\\\n-\\frac{x_j}{2(1-x_j^2)},  1 \\leq j \\leq N-1, \\\\\n-\\frac{2N^2+1}{6},  j=N.\n\\end{cases}\n$$\n此矩阵将为一维激波管问题（$N=N_x=64$）和二维涡旋问题（$N=N_y=32$）分别构建。\n\n### 步骤 2：代理非线性算子\n\n在这些谱网格上定义了两个典型的非线性算子。\n\n**1. 一维激波管代理模型 ($\\mathcal{N}_{\\mathrm{shock}}$)**\n代理场 $\\phi_{\\mathrm{shock}}$ 在具有 $N_x=64$ 的一维 CGL 网格上进行评估，产生一个长度为 $Q = N_x+1 = 65$ 的向量。该场由以下公式给出：\n$$\n\\phi_{\\mathrm{shock}}(x; M, t) = \\frac{M}{2} \\left[1 + \\tanh\\left(k(M)(x - s(M)t)\\right)\\right] + 0.05 M \\sin(8\\pi x) e^{-t}\n$$\n其中 $k(M) = 6M$ 和 $s(M) = M/2$。非线性算子将微分矩阵应用于表示通量 $f(\\phi) = \\phi^2/2$ 的向量：\n$$\n\\mathcal{N}_{\\mathrm{shock}}(M,t) = D \\left(\\frac{\\phi_{\\mathrm{shock}}(\\cdot; M,t)^2}{2}\\right)\n$$\n此处，平方和除法是在场值向量上逐元素执行的。\n\n**2. 二维等熵涡代理模型 ($\\mathcal{N}_{\\mathrm{vortex}}$)**\n代理场 $\\phi_{\\mathrm{vortex}}$ 在每个维度具有 $N_y=32$ 的二维张量积 CGL 网格上进行评估，得到一个 $(N_y+1) \\times (N_y+1) = 33 \\times 33$ 的点网格。总自由度数为 $Q = 33^2 = 1089$。该场为：\n$$\n\\phi_{\\mathrm{vortex}}(x,y; M,t) = M e^{-\\alpha(M)((x - v_x(M)t)^2 + (y - v_y(M)t)^2)}\\sin(\\pi x)\\cos(\\pi y) + 0.05 M \\sin(6\\pi(x+y))e^{-t}\n$$\n其中 $\\alpha(M) = 1+M$ 和 $v_x(M) = v_y(M) = M/2$。非线性算子是二次通量的离散散度：\n$$\n\\mathcal{N}_{\\mathrm{vortex}}(M,t) = \\partial_x(\\phi_{\\mathrm{vortex}}^2) + \\partial_y(\\phi_{\\mathrm{vortex}}^2)\n$$\n令 $G$ 为网格上 $\\phi_{\\mathrm{vortex}}^2$ 值的矩阵，偏导数通过与一维微分矩阵 $D$（大小为 $33 \\times 33$）的矩阵乘法计算。根据问题的明确指示，我们计算 $\\partial_x G = D G$ 和 $\\partial_y G = G D^\\top$。将结果相加并扁平化成一个长度为 $Q=1089$ 的向量。\n\n### 步骤 3：POD-DEIM 模型构建\n\n对于给定的场景（激波或涡旋）和训练策略（S0 或 S1），EIM 模型按如下方式构建：\n\n1.  **快照收集**：对于策略指定的每对训练马赫数 $M$ 和时间 $t$，评估非线性算子 $\\mathcal{N}(M, t)$。将得到的向量作为快照矩阵 $F \\in \\mathbb{R}^{Q \\times S}$ 的列进行收集，其中 $S$ 是快照数量（本问题中 $S=6$）。\n2.  **POD 基生成**：计算快照矩阵的奇异值分解 (SVD)：$F = U \\Sigma V^\\top$。选择左奇异向量矩阵 $U$ 的前 $r=6$ 列作为 POD 基，记为 $U_r \\in \\mathbb{R}^{Q \\times r}$。\n3.  **DEIM 索引选择**：使用离散经验插值法 (DEIM) 选择 $r$ 个插值索引 $P = \\{p_1, \\dots, p_r\\}$。这是一个贪婪算法：\n    *   第一个索引 $p_1$ 被选为第一个基向量 $u_1$ 的绝对值最大值的位置。\n    *   对于 $k=2, \\dots, r$，第 $k$ 个基向量 $u_k$ 通过其在前 $k-1$ 个基向量张成的空间上的投影来逼近，系数由在先前选择的索引 $\\{p_1, \\dots, p_{k-1}\\}$ 处的插值确定。计算此逼近的残差，并将新的索引 $p_k$ 选为此残差绝对值最大值的位置。\n    此过程产生一组 $r$ 个索引 $P$。\n\nEIM 模型由对 $(U_r, P)$ 定义。\n\n### 步骤 4：EIM 逼近和误差评估\n\n给定一个未经训练的参数集的新状态向量 $f_{\\mathrm{new}} = \\mathcal{N}(M^\\star, t^\\star)$，计算其 EIM 逼近 $\\hat{f}_{\\mathrm{new}}$。\n\n1.  **逼近**：逼近为 $\\hat{f}_{\\mathrm{new}} = U_r c$，其中系数向量 $c \\in \\mathbb{R}^r$ 通过求解强制在 DEIM 索引处插值的小型方形线性系统得到：\n    $$\n    (U_r)_{P,:} c = (f_{\\mathrm{new}})_P\n    $$\n    此处，$(U_r)_{P,:}$ 是通过选择 $U_r$ 中对应于 $P$ 中索引的行而形成的 $r \\times r$ 矩阵，而 $(f_{\\mathrm{new}})_P$ 是通过选择 $f_{\\mathrm{new}}$ 的相应条目而形成的向量。\n2.  **误差计算**：给定策略的泛化误差是真实算子输出与 EIM 逼近之间差值的相对欧几里得范数：\n    $$\n    \\epsilon(M^\\star, t^\\star) = \\frac{\\| \\mathcal{N}(M^\\star, t^\\star) - \\widehat{\\mathcal{N}}(M^\\star, t^\\star) \\|_2}{\\| \\mathcal{N}(M^\\star, t^\\star) \\|_2}\n    $$\n3.  **改进度量**：最终关注的量是包含瞬态的策略 (S1) 相对于稳态主导的策略 (S0) 的改进程度，通过它们误差的差异来衡量：\n    $$\n    \\Delta = \\epsilon_{\\mathrm{S0}}(M^\\star, t^\\star) - \\epsilon_{\\mathrm{S1}}(M^\\star, t^\\star)\n    $$\n\n此过程对问题陈述中指定的四个测试用例中的每一个都执行。预期结果是 $\\Delta  0$，这表明在训练中接触了瞬态动力学的策略 S1，能为瞬态测试用例提供更好的逼近。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\n# This solution was executed with numpy==1.23.5 and scipy==1.11.4\n\ndef get_chebyshev_diff_matrix(N: int) - np.ndarray:\n    \"\"\"\n    Computes the Chebyshev spectral differentiation matrix for N+1\n    Chebyshev-Gauss-Lobatto nodes.\n    \"\"\"\n    if N == 0:\n        return np.zeros((1, 1))\n    \n    x = np.cos(np.pi * np.arange(N + 1) / N)\n    D = np.zeros((N + 1, N + 1))\n    \n    c = np.ones(N + 1)\n    c[0] = 2.0\n    c[N] = 2.0\n\n    for i in range(N + 1):\n        for j in range(N + 1):\n            if i == j:\n                if i == 0:\n                    D[i, j] = (2 * N**2 + 1) / 6.0\n                elif i == N:\n                    D[i, j] = -(2 * N**2 + 1) / 6.0\n                else:\n                    D[i, j] = -x[j] / (2 * (1 - x[j]**2))\n            else:\n                D[i, j] = (c[i] / c[j]) * ((-1)**(i + j)) / (x[i] - x[j])\n    return D\n\ndef deim(U: np.ndarray) - np.ndarray:\n    \"\"\"\n    Performs the Discrete Empirical Interpolation Method (DEIM) to select\n    interpolation indices given a basis U.\n    \"\"\"\n    Q, r = U.shape\n    P = np.zeros(r, dtype=int)\n    \n    # First point\n    p1_idx = np.argmax(np.abs(U[:, 0]))\n    P[0] = p1_idx\n    \n    for k in range(1, r):\n        u_k = U[:, k]\n        \n        # Solve for coefficients\n        U_P_k_minus_1 = U[P[:k], :k]\n        u_k_P = u_k[P[:k]]\n        \n        try:\n            coeffs = linalg.solve(U_P_k_minus_1, u_k_P)\n        except linalg.LinAlgError:\n            # Fallback to pseudo-inverse if matrix is singular.\n            # This can happen if basis vectors are nearly linearly dependent at selected points.\n            coeffs = linalg.lstsq(U_P_k_minus_1, u_k_P)[0]\n\n        # Compute residual\n        residual = u_k - U[:, :k] @ coeffs\n        \n        # Select next point\n        p_k_idx = np.argmax(np.abs(residual))\n        P[k] = p_k_idx\n        \n    return P\n\ndef shock_phi(x: np.ndarray, M: float, t: float) - np.ndarray:\n    k = 6.0 * M\n    s = M / 2.0\n    phi = M / 2.0 * (1.0 + np.tanh(k * (x - s * t))) + 0.05 * M * np.sin(8.0 * np.pi * x) * np.exp(-t)\n    return phi\n\ndef shock_op(M: float, t: float, D: np.ndarray, x: np.ndarray) - np.ndarray:\n    phi = shock_phi(x, M, t)\n    flux = 0.5 * phi**2\n    return D @ flux\n\ndef vortex_phi(X: np.ndarray, Y: np.ndarray, M: float, t: float) - np.ndarray:\n    alpha = 1.0 + M\n    v_x = v_y = M / 2.0\n    term1 = M * np.exp(-alpha * ((X - v_x * t)**2 + (Y - v_y * t)**2)) * np.sin(np.pi * X) * np.cos(np.pi * Y)\n    term2 = 0.05 * M * np.sin(6.0 * np.pi * (X + Y)) * np.exp(-t)\n    return term1 + term2\n\ndef vortex_op(M: float, t: float, D: np.ndarray, X: np.ndarray, Y: np.ndarray) - np.ndarray:\n    phi_grid = vortex_phi(X, Y, M, t)\n    G = phi_grid**2\n    # Per problem statement: d_x(G) = D G, d_y(G) = G D^T\n    dG_dx = D @ G\n    dG_dy = G @ D.T\n    op_grid = dG_dx + dG_dy\n    return op_grid.ravel()\n\ndef build_eim_model(scenario: str, strategy: str, params: dict):\n    \"\"\"\n    Builds the POD-DEIM model for a given scenario and strategy.\n    \"\"\"\n    r = params['r']\n    train_times = params['train_times'][strategy]\n    train_machs = params['train_machs'][scenario]\n\n    snapshots = []\n    if scenario == 'shock':\n        N = params['N_shock']\n        D = params['D_shock']\n        x = params['x_shock']\n        for M_train in train_machs:\n            for t_train in train_times:\n                snapshot = shock_op(M_train, t_train, D, x)\n                snapshots.append(snapshot)\n    elif scenario == 'vortex':\n        N = params['N_vortex']\n        D = params['D_vortex']\n        X, Y = params['grid_vortex']\n        for M_train in train_machs:\n            for t_train in train_times:\n                snapshot = vortex_op(M_train, t_train, D, X, Y)\n                snapshots.append(snapshot)\n    \n    F = np.array(snapshots).T\n    \n    # POD basis\n    U, s, Vt = linalg.svd(F, full_matrices=False)\n    num_snaps = F.shape[1]\n    rank = min(r, num_snaps) # Use at most r basis vectors\n    U_r = U[:, :rank]\n    \n    # DEIM indices\n    P = deim(U_r)\n    \n    return U_r, P\n\ndef apply_eim_model(f: np.ndarray, U_r: np.ndarray, P: np.ndarray) - np.ndarray:\n    \"\"\"\n    Applies the EIM model to approximate a vector f.\n    \"\"\"\n    U_r_P = U_r[P, :]\n    f_P = f[P]\n    \n    try:\n        c = linalg.solve(U_r_P, f_P)\n    except linalg.LinAlgError:\n        c = linalg.lstsq(U_r_P, f_P)[0]\n    \n    f_hat = U_r @ c\n    return f_hat\n\ndef calculate_error(f, f_hat):\n    \"\"\"Computes the relative L2 error.\"\"\"\n    norm_f = linalg.norm(f)\n    if norm_f == 0:\n        return 0.0 if linalg.norm(f_hat) == 0 else 1.0\n    return linalg.norm(f - f_hat) / norm_f\n\ndef solve():\n    params = {\n        'N_shock': 64,\n        'N_vortex': 32,\n        'r': 6,\n        'train_times': {\n            'S0': [0.3, 0.4, 0.5],\n            'S1': [0.05, 0.2, 0.5]\n        },\n        'train_machs': {\n            'shock': [1.2, 2.0],\n            'vortex': [0.4, 0.8]\n        },\n        'test_cases': [\n            {'scenario': 'shock', 'M_star': 1.6, 't_star': 0.15},\n            {'scenario': 'shock', 'M_star': 3.0, 't_star': 0.15},\n            {'scenario': 'vortex', 'M_star': 0.6, 't_star': 0.15},\n            {'scenario': 'vortex', 'M_star': 0.2, 't_star': 0.15},\n        ]\n    }\n\n    # Pre-compute shared data\n    N_shock = params['N_shock']\n    params['D_shock'] = get_chebyshev_diff_matrix(N_shock)\n    params['x_shock'] = np.cos(np.pi * np.arange(N_shock + 1) / N_shock)\n    \n    N_vortex = params['N_vortex']\n    params['D_vortex'] = get_chebyshev_diff_matrix(N_vortex)\n    vortex_nodes = np.cos(np.pi * np.arange(N_vortex + 1) / N_vortex)\n    params['grid_vortex'] = np.meshgrid(vortex_nodes, vortex_nodes)\n\n    results = []\n    \n    # Group tests by scenario to avoid re-building models\n    scenarios = ['shock', 'vortex']\n    \n    for scenario in scenarios:\n        # Build models for the scenario\n        U_r_s0, P_s0 = build_eim_model(scenario, 'S0', params)\n        U_r_s1, P_s1 = build_eim_model(scenario, 'S1', params)\n\n        # Run tests for this scenario\n        tests_for_scenario = [tc for tc in params['test_cases'] if tc['scenario'] == scenario]\n        \n        for test in tests_for_scenario:\n            M_star, t_star = test['M_star'], test['t_star']\n            \n            # Generate true solution\n            if scenario == 'shock':\n                f_true = shock_op(M_star, t_star, params['D_shock'], params['x_shock'])\n            else: # vortex\n                f_true = vortex_op(M_star, t_star, params['D_vortex'], *params['grid_vortex'])\n\n            # Apply S0 model and get error\n            f_hat_s0 = apply_eim_model(f_true, U_r_s0, P_s0)\n            eps_s0 = calculate_error(f_true, f_hat_s0)\n            \n            # Apply S1 model and get error\n            f_hat_s1 = apply_eim_model(f_true, U_r_s1, P_s1)\n            eps_s1 = calculate_error(f_true, f_hat_s1)\n            \n            # Calculate improvement\n            delta = eps_s0 - eps_s1\n            results.append(delta)\n\n    # Reorder results to match problem statement order\n    # Test cases original order: shock 1.6, shock 3.0, vortex 0.6, vortex 0.2\n    # My loop processes: shock 1.6, shock 3.0, vortex 0.6, vortex 0.2\n    # The order is already correct.\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3383626"}, {"introduction": "EIM 代理模型可以高精度地近似一个非线性算子，但它是否保留了原算子关键的数学或物理性质？本练习将挑战您将一个为通量限制器构建的 EIM 代理模型集成到有限体积格式中。您将通过测试验证超简化后的格式是否保持了至关重要的 $L^1$ 收缩性质，从而揭示代理模型可能存在的、超出简单精度分析的微妙失效模式。[@problem_id:3383561]", "problem": "考虑周期性域 $[0,1]$ 上的一个一维标量守恒律 $u_t + f(u)_x = 0$。对于线性平流情况，设 $f(u) = a u$，其中常数平流速度 $a  0$。将该域离散为 $N$ 个均匀单元，单元中心为 $x_i$，间距为 $\\Delta x = 1/N$，并使用守恒律单调上游中心格式（Monotonic Upstream-centered Schemes for Conservation Laws, MUSCL）的单步显式前向欧拉有限体积法，在左界面处进行重构，并使用一个由 $\\theta \\in [1,2]$ 参数化的 minmod 族斜率限制器。基于广义 minmod 的通量限制器 $\\phi_\\theta(r)$ 作用于斜率比 $r$ 上，并逐元素定义为\n$$\n\\phi_\\theta(r) = \\max\\left(0,\\min(\\theta r,1),\\min(r,\\theta)\\right)。\n$$\n假设 $a=1$，并为时间步长 $\\Delta t$ 选择一个 Courant–Friedrichs–Lewy (CFL) 数 $\\nu = a \\Delta t / \\Delta x \\in (0,1)$。\n\n为具有周期性边界条件的单元平均向量 $u \\in \\mathbb{R}^N$ 定义一阶、二阶和三阶离散差分算子如下\n$$\n\\delta^- u_i = u_i - u_{i-1}, \\quad \\delta^+ u_i = u_{i+1} - u_i,\n$$\n$$\n\\Delta^{(2,-)} u_i = u_i - 2u_{i-1} + u_{i-2}, \\quad \\Delta^{(2,+)} u_i = u_{i+2} - 2u_{i+1} + u_i,\n$$\n$$\n\\Delta^{(3,-)} u_i = u_i - 3u_{i-1} + 3u_{i-2} - u_{i-3}, \\quad \\Delta^{(3,+)} u_i = u_{i+3} - 3u_{i+2} + 3u_{i+1} - u_i,\n$$\n其中索引以 $N$ 为模。相应的斜率比为\n$$\nr^{(1)}_i = \\frac{\\delta^- u_i}{\\delta^+ u_i + \\varepsilon}, \\quad r^{(2)}_i = \\frac{\\Delta^{(2,-)} u_i}{\\Delta^{(2,+)} u_i + \\varepsilon}, \\quad r^{(3)}_i = \\frac{\\Delta^{(3,-)} u_i}{\\Delta^{(3,+)} u_i + \\varepsilon},\n$$\n其中 $\\varepsilon  0$ 是一个为了数值鲁棒性而设的小量。考虑一个次数为 $p \\in \\{1,2,3\\}$ 的分层重构，通过将界面 $x_{i+\\frac{1}{2}}$ 处的左状态定义为\n$$\nu^-_{i+\\frac{1}{2}} = u_i + \\frac{1}{2}\\,\\phi_\\theta\\!\\left(r^{(1)}_i\\right)\\,\\delta^- u_i + \\mathbf{1}_{\\{p\\ge 2\\}}\\,\\frac{1}{8}\\,\\phi_{\\alpha_2\\theta}\\!\\left(r^{(2)}_i\\right)\\,\\Delta^{(2,-)} u_i + \\mathbf{1}_{\\{p\\ge 3\\}}\\,\\frac{1}{48}\\,\\phi_{\\alpha_3\\theta}\\!\\left(r^{(3)}_i\\right)\\,\\Delta^{(3,-)} u_i,\n$$\n其中 $\\alpha_2 = \\tfrac{1}{2}$ 且 $\\alpha_3 = \\tfrac{1}{4}$，$\\mathbf{1}_{\\{\\cdot\\}}$ 是指示函数。$x_{i+\\frac{1}{2}}$ 处的迎风数值通量为 $F_{i+\\frac{1}{2}} = a\\,u^-_{i+\\frac{1}{2}}$，单元更新为\n$$\nu_i^{(1)} = u_i^{(0)} - \\nu \\left(F_{i+\\frac{1}{2}} - F_{i-\\frac{1}{2}}\\right),\n$$\n其中索引是周期性的。\n\n您将为作用于标量变量 $r$ 的非线性算子 $g(r;\\theta) = \\phi_\\theta(r)$ 实现一个经验插值法 (Empirical Interpolation Method, EIM) 代理模型。EIM 的构建必须从第一性原理出发：\n- 在 $r \\in [-R,R]$ 中选择一个包含 $n_r$ 个点的均匀训练网格，以及一个参数训练集 $\\theta_j \\in [\\theta_{\\min},\\theta_{\\max}]$。\n- 构建快照矩阵 $S \\in \\mathbb{R}^{n_r \\times m}$，其列 $S(:,j) = g(r_{\\ell};\\theta_j)$ 是在 $r$-网格上计算得到的。\n- 计算奇异值分解并选择一个秩为 $k$ 的基 $U_k \\in \\mathbb{R}^{n_r \\times k}$。\n- 通过经典的贪婪残差最大化算法选择 $k$ 个经验插值节点 $\\{r_{p_j}\\}_{j=1}^k$，形成插值矩阵 $P^T U_k = U_k[p_1,\\dots,p_k,:] \\in \\mathbb{R}^{k \\times k}$。\n- 对于给定的 $\\theta$，构建在线近似\n$$\ng_{\\mathrm{EIM}}(\\cdot;\\theta) \\approx U_k \\left(P^T U_k\\right)^{-1} P^T g(\\cdot;\\theta),\n$$\n其中 $P^T g(\\cdot;\\theta)$ 是 $g(r_{p_j};\\theta)$ 在所选节点处的精确值。\n\n通过在密集的 $r$-网格上计算 $g_{\\mathrm{EIM}}(\\cdot;\\theta)$ 并线性插值到所需的 $r$ 值，使用此代理模型来近似 MUSCL 重构中的限制器 $\\phi_\\theta(r)$。当 $p \\ge 2$ 时，对缩放参数 $\\alpha_2 \\theta$ 和 $\\alpha_3 \\theta$ 重用相同的代理模型。\n\n定义三对初始数据 $(u^{(0)}, v^{(0)})$ 来探究 $L^1$ 收缩性质：\n1. 一对具有微小位移的不连续阶梯函数：$u^{(0)}(x) = \\mathbf{1}_{[0,0.5)}(x)$ 和 $v^{(0)}(x) = \\mathbf{1}_{[0,0.52)}(x)$。\n2. 一对具有小相移的平滑正弦波：$u^{(0)}(x) = 0.5 + 0.45 \\sin(2\\pi x)$ 和 $v^{(0)}(x) = 0.5 + 0.45 \\sin(2\\pi (x+\\delta))$，其中 $\\delta = 0.02$。\n3. 一对平滑随机场：从独立标准正态分布中抽取 $w \\in \\mathbb{R}^N$，通过在宽度为 9 个单元的窗口上进行局部平均来平滑以获得 $u^{(0)}$，并设置 $v^{(0)}(x) = u^{(0)}(x) + 0.01\\sin(4\\pi x)$，然后将两者都裁剪到 $[0,1]$ 范围内。\n\n对于每一对，计算离散 $L^1$ 距离 $\\|u^{(0)} - v^{(0)}\\|_1 = \\Delta x \\sum_i |u_i^{(0)} - v_i^{(0)}|$，并在一个更新步后使用以下方法计算 $\\|u^{(1)} - v^{(1)}\\|_1$：\n- 精确限制器 $\\phi_\\theta$ (基准)，以及\n- 替代 $\\phi_\\theta$ 的 EIM 代理模型 $g_{\\mathrm{EIM}}$ (代理)。\n\n如果三对数据中至少有一对满足以下条件，则声明代理模型对于给定的 $(p,\\theta)$ 退化了 $L^1$ 收缩性质：\n$$\n\\|u^{(1)}_{\\mathrm{sur}} - v^{(1)}_{\\mathrm{sur}}\\|_1  \\|u^{(0)} - v^{(0)}\\|_1 + \\varepsilon \\quad \\text{and} \\quad \\|u^{(1)}_{\\mathrm{exact}} - v^{(1)}_{\\mathrm{exact}}\\|_1 \\le \\|u^{(0)} - v^{(0)}\\|_1 + \\varepsilon,\n$$\n其中容差 $\\varepsilon = 10^{-12}$。\n\n使用 $a = 1$, $N = 200$, $\\nu = 0.5$, $\\varepsilon = 10^{-12}$, $R = 6$, $n_r = 401$ 实现上述过程，EIM 训练参数为 $\\theta_{\\min} = 1.2$, $\\theta_{\\max} = 1.8$, $m = 5$ 个均匀间隔的训练参数，以及秩 $k = 4$。\n\n测试套件：\n使用以下八个参数集 $(p,\\theta)：$\n- $(1, 1.0)$，\n- $(1, 1.8)$，\n- $(1, 2.0)$，\n- $(2, 1.0)$，\n- $(2, 1.8)$，\n- $(2, 2.0)$，\n- $(3, 1.3)$，\n- $(3, 2.0)$。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含八个测试用例的布尔退化结果，按给定顺序列出，形式为用方括号括起来的逗号分隔列表（例如，“[True,False,False,True,False,False,True,False]”）。不应打印任何其他文本。不使用角度；输出中没有物理单位。所有计算必须如上所述以纯数学术语执行。", "solution": "该问题要求实现一个高阶 MUSCL 型有限体积格式，以求解周期性域上的一维线性平流方程 $u_t + a u_x = 0$。问题的核心是为非线性的广义 minmod 通量限制器函数 $\\phi_\\theta(r)$ 构建一个经验插值法 (EIM) 代理模型，并评估该代理模型是否会使数值格式的 $L^1$ 收缩性质退化。\n\n该方法包括几个不同的步骤：\n1. 定义和实现最高达 $p \\in \\{1,2,3\\}$ 阶的分层 MUSCL 有限体积格式。\n2. 离线构建限制器函数 $\\phi_\\theta(r)$ 的 EIM 代理模型。\n3. 同时使用精确限制器和 EIM 代理模型在线评估该格式。\n4. 基于离散 $L^1$ 范数进行定量比较，以检查一系列测试用例的收缩性质是否退化。\n\n首先，我们详细介绍数值格式。将域 $[0,1]$ 离散为 $N$ 个宽度为 $\\Delta x = 1/N$ 的单元。在时间步 $n$ 的单元平均量记为 $u_i^{(n)}$。单步前向欧拉时间步通过以下方式更新解：\n$$\nu_i^{(n+1)} = u_i^{(n)} - \\frac{\\Delta t}{\\Delta x} \\left(F_{i+\\frac{1}{2}} - F_{i-\\frac{1}{2}}\\right)\n$$\n其中 $\\nu = a \\Delta t / \\Delta x$ 是 Courant 数。数值通量 $F_{i+\\frac{1}{2}}$ 是一个迎风通量，即 $F_{i+\\frac{1}{2}} = a u^-_{i+\\frac{1}{2}}$，因为平流速度 $a=1$ 是正的。值 $u^-_{i+\\frac{1}{2}}$ 是在界面 $x_{i+\\frac{1}{2}}$ 左侧解的高阶重构。次数为 $p$ 的分层重构由下式给出：\n$$\nu^-_{i+\\frac{1}{2}} = u_i + \\frac{1}{2}\\phi_\\theta(r^{(1)}_i)\\delta^- u_i + \\mathbf{1}_{\\{p\\ge 2\\}}\\frac{1}{8}\\phi_{\\alpha_2\\theta}(r^{(2)}_i)\\Delta^{(2,-)} u_i + \\mathbf{1}_{\\{p\\ge 3\\}}\\frac{1}{48}\\phi_{\\alpha_3\\theta}(r^{(3)}_i)\\Delta^{(3,-)} u_i\n$$\n项 $\\delta^- u_i$、$\\Delta^{(2,-)} u_i$ 和 $\\Delta^{(3,-)} u_i$ 分别是一阶、二阶和三阶后向有限差分算子。相应的斜率比 $r^{(k)}_i$ 是通过将后向差分除以相应的前向差分形成的，例如，$r^{(1)}_i = (\\delta^- u_i) / (\\delta^+ u_i + \\varepsilon)$。函数 $\\phi_\\theta(r)$ 是广义 minmod 限制器：\n$$\n\\phi_\\theta(r) = \\max\\left(0, \\min(\\theta r, 1), \\min(r, \\theta)\\right)\n$$\n此限制器应用于重构的每一阶，并带有一个缩放参数 $\\alpha_k \\theta$，以控制伪振荡。常数给定为 $\\alpha_2 = 1/2$ 和 $\\alpha_3 = 1/4$。所有索引都以 $N$ 为模进行周期性处理。\n\n其次，我们为参数化函数 $g(r; \\theta) = \\phi_\\theta(r)$ 构建 EIM 代理模型。这是一种模型降阶技术，从离线训练阶段开始。\n1. 在区间 $[\\theta_{\\min}, \\theta_{\\max}] = [1.2, 1.8]$ 中均匀选择一组 $m=5$ 的训练参数 $\\{\\theta_j\\}_{j=1}^5$。\n2. 在 $[-R, R] = [-6, 6]$ 中为变量 $r$ 创建一个包含 $n_r = 401$ 个点的均匀训练网格。\n3. 组装一个快照矩阵 $S \\in \\mathbb{R}^{n_r \\times m}$，其中每一列 $S_{:,j}$ 是函数 $g(r; \\theta_j)$ 在 $r$-网格上的计算结果。\n4. 快照矩阵的奇异值分解 (SVD)，$S = U \\Sigma V^T$，为快照张成的空间提供了一个标准正交基 $U$。我们将此基截断为前 $k=4$ 个主导模态，得到降阶基 $U_k \\in \\mathbb{R}^{n_r \\times k}$。\n5. 使用贪婪算法从 $r$-网格中选择一组 $k=4$ 个经验插值节点 $\\{r_{p_j}\\}_{j=1}^k$。该算法迭代地选择一个点，该点在使用由先前选择的点和基向量构建的插值函数来近似下一个基向量时，能够使残差误差最大化。这个过程确保了插值矩阵是良态的。\n设 $I = \\{p_1, \\dots, p_k\\}$ 为插值节点的索引集。我们定义一个矩阵 $M = U_k[I, :]$，它表示在插值节点处计算的基向量。该矩阵的逆矩阵 $M^{-1}$ 被预先计算。离线阶段通过存储 $U_k$、$M^{-1}$、插值节点索引 $I$ 和 $r$-网格来结束。\n\n第三，在在线阶段，对于任何新参数 $\\theta$，都会计算 EIM 代理模型 $g_{\\mathrm{EIM}}(r;\\theta)$。这是通过首先仅在 $k$ 个插值节点处计算精确函数 $g(r;\\theta)$ 来完成的，即 $g_{\\text{nodes}} = g(r_I; \\theta)$。然后在降阶基中近似的系数计算为 $c = M^{-1} g_{\\text{nodes}}$。EIM 近似则由 $g_{\\mathrm{EIM}}(\\cdot ; \\theta) = U_k c$ 给出。问题指定此 EIM 评估应在训练阶段的密集 $r$-网格上执行。当 MUSCL 格式需要根据解数据计算出的特定斜率比 $r_i$ 对应的 $\\phi_\\theta(r_i)$ 值时，该值是通过在密集 $r$-网格上对预先计算的向量 $g_{\\mathrm{EIM}}(\\cdot ; \\theta)$ 进行线性插值得到的。\n\n最后，我们测试代理模型的性能。$L^1$ 收缩性质指出，对于一个有效的格式，两个不同解之间的 $L^1$ 距离不应随时间增加，即 $\\|u^{(n+1)} - v^{(n+1)}\\|_1 \\le \\|u^{(n)} - v^{(n)}\\|_1$。我们使用三对初始条件 $(u^{(0)}, v^{(0)})$ 对此性质进行一个时间步的测试。对于每个测试用例 $(p, \\theta)$，我们使用精确限制器和 EIM 代理模型比较 $L^1$ 距离的演化。如果对于三对初始条件中的任何一对，代理模型导致 $L^1$ 距离显著增加而精确格式没有，则声明代理模型导致“退化”。形式上，如果出现以下情况，则发生退化：\n$$\n\\|u^{(1)}_{\\mathrm{sur}} - v^{(1)}_{\\mathrm{sur}}\\|_1  \\|u^{(0)} - v^{(0)}\\|_1 + \\varepsilon \\quad \\text{and} \\quad \\|u^{(1)}_{\\mathrm{exact}} - v^{(1)}_{\\mathrm{exact}}\\|_1 \\le \\|u^{(0)} - v^{(0)}\\|_1 + \\varepsilon\n$$\n容差为 $\\varepsilon = 10^{-12}$。该实现将对所有指定的 $(p, \\theta)$ 对系统地执行此过程，并报告一个布尔值，指示是否观察到退化。\n\n所有数值参数均在问题中指定：$a=1$，$N=200$，$\\nu=0.5$，$\\varepsilon=10^{-12}$，$R=6$，$n_r=401$，$\\theta_{\\min}=1.2$，$\\theta_{\\max}=1.8$，$m=5$，$k=4$。对于涉及随机场的第三个初始条件，使用固定的随机种子以保证可复现性。\n\n最终的 Python 代码实现了这些步骤。为限制器 $\\phi_\\theta$、EIM 构建、EIM 评估、MUSCL 更新步骤以及初始条件的生成定义了辅助函数。主函数协调所有用例的测试过程，并打印最终的布尔列表。\n该实现使用 `numpy` 进行数组操作，使用 `numpy.linalg.svd` 进行 SVD 分解。使用 `numpy.roll` 来高效地实现带周期性边界条件的有限差分。线性插值使用 `numpy.interp` 执行。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not used as per the allowed library list.\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and produce the final output.\n    \"\"\"\n    # Global parameters as specified in the problem\n    a = 1.0\n    N = 200\n    nu = 0.5\n    eps = 1e-12\n    R = 6.0\n    n_r = 401\n    theta_min = 1.2\n    theta_max = 1.8\n    m = 5\n    k = 4\n    dx = 1.0 / N\n    \n    # EIM surrogate parameters\n    eim_params = {\n        'R': R,\n        'n_r': n_r,\n        'theta_min': theta_min,\n        'theta_max': theta_max,\n        'm': m,\n        'k': k\n    }\n\n    # Test suite from the problem statement\n    test_suite = [\n        (1, 1.0),\n        (1, 1.8),\n        (1, 2.0),\n        (2, 1.0),\n        (2, 1.8),\n        (2, 2.0),\n        (3, 1.3),\n        (3, 2.0)\n    ]\n\n    # Build the EIM surrogate (offline stage)\n    eim_data = build_eim_surrogate(eim_params)\n\n    # Get initial conditions\n    ic_pairs = get_initial_conditions(N, dx)\n\n    results = []\n    for p, theta in test_suite:\n        degradation_found = False\n        for u0, v0 in ic_pairs:\n            l1_dist_0 = dx * np.sum(np.abs(u0 - v0))\n\n            # Run with exact limiter\n            u1_exact = get_update(u0, p, theta, a, nu, dx, N, eps, use_eim=False, eim_data=None)\n            v1_exact = get_update(v0, p, theta, a, nu, dx, N, eps, use_eim=False, eim_data=None)\n            l1_dist_1_exact = dx * np.sum(np.abs(u1_exact - v1_exact))\n\n            # Run with EIM surrogate\n            u1_sur = get_update(u0, p, theta, a, nu, dx, N, eps, use_eim=True, eim_data=eim_data)\n            v1_sur = get_update(v0, p, theta, a, nu, dx, N, eps, use_eim=True, eim_data=eim_data)\n            l1_dist_1_sur = dx * np.sum(np.abs(u1_sur - v1_sur))\n\n            # Check degradation condition\n            if l1_dist_1_sur > l1_dist_0 + eps and l1_dist_1_exact = l1_dist_0 + eps:\n                degradation_found = True\n                break  # One instance of degradation is sufficient for this test case\n        \n        results.append(degradation_found)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef phi_theta(r, theta):\n    \"\"\"\n    Computes the generalized minmod flux limiter.\n    phi_theta(r) = max(0, min(theta*r, 1), min(r, theta))\n    \"\"\"\n    zero = np.zeros_like(r)\n    term1 = np.minimum(theta * r, 1.0)\n    term2 = np.minimum(r, theta)\n    return np.maximum.reduce([zero, term1, term2])\n\ndef build_eim_surrogate(params):\n    \"\"\"\n    Builds the EIM surrogate (offline phase).\n    \"\"\"\n    k = params['k']\n    r_grid = np.linspace(-params['R'], params['R'], params['n_r'])\n    theta_train = np.linspace(params['theta_min'], params['theta_max'], params['m'])\n\n    # 1. Snapshot matrix\n    S = np.zeros((params['n_r'], params['m']))\n    for j, th in enumerate(theta_train):\n        S[:, j] = phi_theta(r_grid, th)\n\n    # 2. SVD and basis\n    U, s, Vh = np.linalg.svd(S, full_matrices=False)\n    U_k = U[:, :k]\n\n    # 3. Greedy selection of interpolation points\n    indices = []\n    # First point\n    p1_idx = np.argmax(np.abs(U_k[:, 0]))\n    indices.append(p1_idx)\n    \n    for j in range(1, k):\n        U_sub = U_k[:, :j]\n        target_vec = U_k[:, j]\n        \n        P_U_sub = U_k[indices, :j]\n        P_target_vec = U_k[indices, j]\n        \n        coeffs = np.linalg.solve(P_U_sub, P_target_vec)\n        \n        residual = target_vec - U_sub @ coeffs\n        p_new_idx = np.argmax(np.abs(residual))\n        indices.append(p_new_idx)\n\n    # 4. Pre-compute inverse of interpolation matrix\n    M = U_k[indices, :]\n    M_inv = np.linalg.inv(M)\n\n    return {'U_k': U_k, 'M_inv': M_inv, 'indices': indices, 'r_grid': r_grid}\n\ndef evaluate_eim_surrogate(eim_data, theta):\n    \"\"\"\n    Evaluates the EIM surrogate for a given theta (online phase).\n    \"\"\"\n    U_k = eim_data['U_k']\n    M_inv = eim_data['M_inv']\n    indices = eim_data['indices']\n    r_grid = eim_data['r_grid']\n\n    r_nodes = r_grid[indices]\n    g_at_nodes = phi_theta(r_nodes, theta)\n    \n    coeffs = M_inv @ g_at_nodes\n    g_eim = U_k @ coeffs\n\n    return g_eim\n\ndef get_update(u, p, theta, a, nu, dx, N, eps, use_eim, eim_data):\n    \"\"\"\n    Computes one time step of the MUSCL scheme.\n    \"\"\"\n    # Difference operators\n    dm1_u = u - np.roll(u, 1)\n    dp1_u = np.roll(u, -1) - u\n    \n    # Ratios\n    r1 = dm1_u / (dp1_u + eps)\n\n    # Limiter application\n    if use_eim:\n        # Evaluate EIM on dense grid\n        g_eim_1 = evaluate_eim_surrogate(eim_data, theta)\n        # Interpolate to find values at required ratios\n        phi1 = np.interp(r1, eim_data['r_grid'], g_eim_1)\n    else:\n        phi1 = phi_theta(r1, theta)\n\n    # Hierarchical Reconstruction\n    u_left = u + 0.5 * phi1 * dm1_u\n\n    alpha2 = 0.5\n    if p >= 2:\n        dm2_u = u - 2 * np.roll(u, 1) + np.roll(u, 2)\n        dp2_u = np.roll(u, -2) - 2 * np.roll(u, -1) + u\n        r2 = dm2_u / (dp2_u + eps)\n        \n        if use_eim:\n            g_eim_2 = evaluate_eim_surrogate(eim_data, alpha2 * theta)\n            phi2 = np.interp(r2, eim_data['r_grid'], g_eim_2)\n        else:\n            phi2 = phi_theta(r2, alpha2 * theta)\n            \n        u_left += (1.0 / 8.0) * phi2 * dm2_u\n\n    alpha3 = 0.25\n    if p >= 3:\n        dm3_u = u - 3 * np.roll(u, 1) + 3 * np.roll(u, 2) - np.roll(u, 3)\n        dp3_u = np.roll(u, -3) - 3 * np.roll(u, -2) + 3 * np.roll(u, -1) - u\n        r3 = dm3_u / (dp3_u + eps)\n\n        if use_eim:\n            g_eim_3 = evaluate_eim_surrogate(eim_data, alpha3 * theta)\n            phi3 = np.interp(r3, eim_data['r_grid'], g_eim_3)\n        else:\n            phi3 = phi_theta(r3, alpha3 * theta)\n            \n        u_left += (1.0 / 48.0) * phi3 * dm3_u\n\n    # Numerical Flux\n    F = a * u_left\n    F_imhalf = np.roll(F, 1)\n\n    # Update\n    u_new = u - nu * (F - F_imhalf)\n    return u_new\n\ndef get_initial_conditions(N, dx):\n    \"\"\"\n    Generates the three pairs of initial condition data.\n    \"\"\"\n    x = (np.arange(N) + 0.5) * dx\n    ic_pairs = []\n\n    # 1. Discontinuous step functions\n    u0_1 = (x  0.5).astype(float)\n    v0_1 = (x  0.52).astype(float)\n    ic_pairs.append((u0_1, v0_1))\n\n    # 2. Smooth sinusoidal waves\n    delta = 0.02\n    u0_2 = 0.5 + 0.45 * np.sin(2 * np.pi * x)\n    v0_2 = 0.5 + 0.45 * np.sin(2 * np.pi * (x + delta))\n    ic_pairs.append((u0_2, v0_2))\n\n    # 3. Smoothed random fields\n    np.random.seed(42) # For reproducibility\n    w = np.random.randn(N)\n    window_width = 9\n    pad_width = window_width // 2\n    w_padded = np.concatenate((w[-pad_width:], w, w[:pad_width]))\n    kernel = np.ones(window_width) / window_width\n    u0_3_raw = np.convolve(w_padded, kernel, mode='valid')\n    \n    v0_3_raw = u0_3_raw + 0.01 * np.sin(4 * np.pi * x)\n    \n    u0_3 = np.clip(u0_3_raw, 0, 1)\n    v0_3 = np.clip(v0_3_raw, 0, 1)\n    ic_pairs.append((u0_3, v0_3))\n\n    return ic_pairs\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3383561"}]}