{"hands_on_practices": [{"introduction": "要掌握基于恢复的误差估计，第一步是理解其核心构件：卷积核。本练习将引导你通过施加矩条件，从零开始构建一个简单的一维单边核。通过这个过程，你将亲手计算核的系数，并推导其截断误差，从而揭示矩条件与多项式再生及局部精度之间的根本联系。这是一个基础性练习，旨在为理解更高级的恢复技术奠定坚实的数学基础。[@problem_id:3411310]", "problem": "考虑在区间 $[0,1]$ 上，对于一个足够光滑的函数 $u$，其一维间断 Galerkin (DG) 近似为 $u_{h}$，网格为均匀网格，尺寸为 $h>0$。我们寻求在边界 $x=0$ 附近，使用一个由单边卷积定义的增滑保精度 (SIAC) 滤波器来恢复超收敛精度\n$$\n(R_{h} u_{h})(x) \\equiv \\int_{0}^{2h} K_{h}(t)\\, u_{h}(x - t)\\, dt,\n$$\n其中核函数 $K_{h}$ 的支集在 $[0,2h]$ 上，并由零次 B 样条（即区间的特征函数）的线性组合构造而成，具体形式为\n$$\nK_{h}(t) = \\frac{a}{h}\\,\\chi_{[0,h]}(t) + \\frac{b}{h}\\,\\chi_{[h,2h]}(t),\n$$\n其中 $a$ 和 $b$ 是待定系数。要求该恢复算子在边界上能以单边方式再生至多一次的多项式，这由以下修正矩条件给出\n$$\n\\int_{0}^{2h} K_{h}(t)\\, dt = 1\n\\quad\\text{and}\\quad\n\\int_{0}^{2h} t\\, K_{h}(t)\\, dt = 0.\n$$\n从卷积和通过矩条件实现多项式再生的定义出发，确定满足上述约束条件的系数 $a$ 和 $b$。然后，计算剩余二阶矩\n$$\nM_{2}(h) \\equiv \\int_{0}^{2h} t^{2}\\, K_{h}(t)\\, dt,\n$$\n并使用基于泰勒级数的一致性论证，来表示局部截断误差\n$$\nE(x) \\equiv (R_{h} u_{h})(x) - u(x)\n$$\n中的主阶项，用 $M_{2}(h)$ 和精确解的二阶导数 $u''(x)$ 来表示。假设 $u$ 足够光滑，其在 $[0,1]$ 上的导数存在且有界，并从第一性原理出发证明所有步骤。以闭合形式给出 $E(x)$ 主阶项的最终表达式。无需四舍五入，你的答案必须是一个单一的解析表达式。", "solution": "用户希望解决一个关于将单边增滑保精度 (SIAC) 滤波器应用于间断 Galerkin (DG) 近似的问题。\n\n### 问题验证\n**第一步：提取已知条件**\n- 一维 DG 近似表示为 $u_{h}$。\n- 精确解是区间 $[0,1]$ 上的一个足够光滑的函数 $u$。\n- 网格是均匀的，尺寸为 $h > 0$。\n- SIAC 恢复算子是一个单边卷积：$(R_{h} u_{h})(x) \\equiv \\int_{0}^{2h} K_{h}(t)\\, u_{h}(x - t)\\, dt$。\n- 卷积核为 $K_{h}(t) = \\frac{a}{h}\\,\\chi_{[0,h]}(t) + \\frac{b}{h}\\,\\chi_{[h,2h]}(t)$，其中 $\\chi_I(t)$ 是区间 $I$ 的特征函数。\n- 系数 $a$ 和 $b$ 待定。\n- 多项式再生条件（修正矩条件）为：\n  1. $\\int_{0}^{2h} K_{h}(t)\\, dt = 1$\n  2. $\\int_{0}^{2h} t\\, K_{h}(t)\\, dt = 0$\n- 剩余二阶矩定义为 $M_{2}(h) \\equiv \\int_{0}^{2h} t^{2}\\, K_{h}(t)\\, dt$。\n- 局部截断误差定义为 $E(x) \\equiv (R_{h} u_{h})(x) - u(x)$。\n- 任务是求出 $a$ 和 $b$，计算 $M_2(h)$，并用 $M_2(h)$ 和 $u''(x)$ 表示 $E(x)$ 的主阶项。\n\n**第二步：使用提取的已知条件进行验证**\n- **科学依据：** 该问题牢固地植根于偏微分方程数值方法的理论，特别是在有限元解（DG 方法）的后处理中。卷积核的使用、用于多项式再生的矩条件以及用于截断误差分析的泰勒级数是该领域的标准且成熟的技术。\n- **适定性：** 该问题提供了一套清晰的定义和约束。两个矩条件为两个未知系数 $a$ 和 $b$ 产生了一个包含两个线性方程的方程组，这足以得到唯一解。后续计算二阶矩和推导误差主阶项的任务是明确定义的数学过程。\n- **客观性：** 该问题使用精确的数学语言陈述，没有任何主观性或模糊性。\n\n**第三步：结论与行动**\n该问题是有效的。它是一个自洽、科学合理且适定的数值分析练习。可以按要求进行求解过程。\n\n### 解答\n\n求解过程主要分三步：\n1. 根据给定的矩条件确定系数 $a$ 和 $b$。\n2. 使用已确定的系数计算二阶矩 $M_{2}(h)$。\n3. 使用泰勒级数展开推导局部截断误差的主阶项。\n\n**第一步：确定系数 $a$ 和 $b$**\n\n我们利用两个给定的矩条件来建立关于 $a$ 和 $b$ 的线性方程组。\n\n第一个矩条件是：\n$$\n\\int_{0}^{2h} K_{h}(t)\\, dt = 1\n$$\n代入 $K_h(t)$ 的定义：\n$$\n\\int_{0}^{2h} \\left( \\frac{a}{h}\\,\\chi_{[0,h]}(t) + \\frac{b}{h}\\,\\chi_{[h,2h]}(t) \\right) dt = 1\n$$\n特征函数的积分是其支集区间的长度：\n$$\n\\frac{a}{h} \\int_{0}^{h} 1\\, dt + \\frac{b}{h} \\int_{h}^{2h} 1\\, dt = 1\n$$\n$$\n\\frac{a}{h} (h) + \\frac{b}{h} (h) = 1\n$$\n这简化为我们的第一个方程：\n$$\na + b = 1 \\quad (1)\n$$\n\n第二个矩条件是：\n$$\n\\int_{0}^{2h} t\\, K_{h}(t)\\, dt = 0\n$$\n代入 $K_h(t)$ 的定义：\n$$\n\\int_{0}^{2h} t \\left( \\frac{a}{h}\\,\\chi_{[0,h]}(t) + \\frac{b}{h}\\,\\chi_{[h,2h]}(t) \\right) dt = 0\n$$\n$$\n\\frac{a}{h} \\int_{0}^{h} t\\, dt + \\frac{b}{h} \\int_{h}^{2h} t\\, dt = 0\n$$\n计算积分：\n$$\n\\frac{a}{h} \\left[ \\frac{t^2}{2} \\right]_{0}^{h} + \\frac{b}{h} \\left[ \\frac{t^2}{2} \\right]_{h}^{2h} = 0\n$$\n$$\n\\frac{a}{h} \\left( \\frac{h^2}{2} - 0 \\right) + \\frac{b}{h} \\left( \\frac{(2h)^2}{2} - \\frac{h^2}{2} \\right) = 0\n$$\n$$\n\\frac{ah}{2} + \\frac{b}{h} \\left( \\frac{4h^2 - h^2}{2} \\right) = 0\n$$\n$$\n\\frac{ah}{2} + \\frac{b}{h} \\left( \\frac{3h^2}{2} \\right) = 0\n$$\n$$\n\\frac{ah}{2} + \\frac{3bh}{2} = 0\n$$\n两边乘以 $\\frac{2}{h}$（因为 $h>0$），得到我们的第二个方程：\n$$\na + 3b = 0 \\quad (2)\n$$\n\n现在我们求解方程组 $(1)$ 和 $(2)$：\n方程 $(2)$ 减去方程 $(1)$：\n$$\n(a + 3b) - (a + b) = 0 - 1\n$$\n$$\n2b = -1 \\implies b = -\\frac{1}{2}\n$$\n将 $b$ 的值代入方程 $(1)$：\n$$\na + \\left(-\\frac{1}{2}\\right) = 1 \\implies a = 1 + \\frac{1}{2} = \\frac{3}{2}\n$$\n因此，系数为 $a = \\frac{3}{2}$ 和 $b = -\\frac{1}{2}$。\n\n**第二步：计算二阶矩 $M_{2}(h)$**\n\n二阶矩定义为：\n$$\nM_{2}(h) = \\int_{0}^{2h} t^{2}\\, K_{h}(t)\\, dt\n$$\n代入 $K_h(t)$ 的定义：\n$$\nM_{2}(h) = \\frac{a}{h} \\int_{0}^{h} t^2\\, dt + \\frac{b}{h} \\int_{h}^{2h} t^2\\, dt\n$$\n计算积分：\n$$\nM_{2}(h) = \\frac{a}{h} \\left[ \\frac{t^3}{3} \\right]_{0}^{h} + \\frac{b}{h} \\left[ \\frac{t^3}{3} \\right]_{h}^{2h}\n$$\n$$\nM_{2}(h) = \\frac{a}{h} \\left( \\frac{h^3}{3} \\right) + \\frac{b}{h} \\left( \\frac{(2h)^3}{3} - \\frac{h^3}{3} \\right)\n$$\n$$\nM_{2}(h) = \\frac{ah^2}{3} + \\frac{b}{h} \\left( \\frac{8h^3 - h^3}{3} \\right)\n$$\n$$\nM_{2}(h) = \\frac{ah^2}{3} + \\frac{b}{h} \\left( \\frac{7h^3}{3} \\right)\n$$\n$$\nM_{2}(h) = \\frac{ah^2}{3} + \\frac{7bh^2}{3} = \\frac{h^2}{3} (a + 7b)\n$$\n现在，代入 $a = \\frac{3}{2}$ 和 $b = -\\frac{1}{2}$ 的值：\n$$\nM_{2}(h) = \\frac{h^2}{3} \\left( \\frac{3}{2} + 7\\left(-\\frac{1}{2}\\right) \\right) = \\frac{h^2}{3} \\left( \\frac{3}{2} - \\frac{7}{2} \\right)\n$$\n$$\nM_{2}(h) = \\frac{h^2}{3} \\left( \\frac{-4}{2} \\right) = \\frac{h^2}{3} (-2)\n$$\n$$\nM_{2}(h) = -\\frac{2h^2}{3}\n$$\n\n**第三步：推导主阶截断误差**\n\n问题要求局部截断误差 $E(x) = (R_{h} u_{h})(x) - u(x)$ 的主阶项。标准的一致性论证包括将算子 $R_h$ 应用于足够光滑的精确解 $u(x)$，并分析其差值 $(R_h u)(x) - u(x)$。\n$$\n(R_{h} u)(x) = \\int_{0}^{2h} K_{h}(t)\\, u(x - t)\\, dt\n$$\n我们将 $u(x-t)$ 在点 $x$ 处按变量 $t$ 进行泰勒级数展开。由于假设 $u$ 足够光滑，这是允许的。\n$$\nu(x-t) = u(x) - t u'(x) + \\frac{t^2}{2!} u''(x) - \\frac{t^3}{3!} u'''(x) + \\dots\n$$\n将此级数代入卷积积分中：\n$$\n(R_{h} u)(x) = \\int_{0}^{2h} K_{h}(t) \\left( u(x) - t u'(x) + \\frac{t^2}{2} u''(x) - \\dots \\right) dt\n$$\n根据积分的线性性质，我们可以将其分配到级数的各项上：\n$$\n(R_{h} u)(x) = u(x) \\int_{0}^{2h} K_{h}(t)\\,dt - u'(x) \\int_{0}^{2h} t K_{h}(t)\\,dt + \\frac{u''(x)}{2} \\int_{0}^{2h} t^2 K_{h}(t)\\,dt - \\dots\n$$\n这些积分恰好是核函数 $K_h(t)$ 的矩。根据问题陈述和我们的计算：\n- 零阶矩：$\\int_{0}^{2h} K_{h}(t)\\,dt = 1$\n- 一阶矩：$\\int_{0}^{2h} t K_{h}(t)\\,dt = 0$\n- 二阶矩：$\\int_{0}^{2h} t^2 K_{h}(t)\\,dt = M_2(h)$\n\n将这些代入展开式中：\n$$\n(R_{h} u)(x) = u(x) \\cdot (1) - u'(x) \\cdot (0) + \\frac{u''(x)}{2} M_2(h) + O(h^3)\n$$\n注意，更高阶的矩 $M_k = \\int t^k K_h(t) dt$ 与 $h^k$ 同阶，因此涉及 $u'''(x)$ 的下一项将是 $h^3$ 阶的。\n$$\n(R_{h} u)(x) = u(x) + \\frac{1}{2} M_2(h) u''(x) + O(h^3)\n$$\n因此，局部截断误差的主阶项为：\n$$\nE(x) \\approx (R_h u)(x) - u(x) = \\left( u(x) + \\frac{1}{2} M_2(h) u''(x) \\right) - u(x) = \\frac{1}{2} M_2(h) u''(x)\n$$\n最后，我们代入 $M_2(h) = -\\frac{2h^2}{3}$ 的值：\n$$\nE(x) \\approx \\frac{1}{2} \\left(-\\frac{2h^2}{3}\\right) u''(x)\n$$\n$$\nE(x) \\approx -\\frac{h^2}{3} u''(x)\n$$\n这就是局部截断误差的闭合形式主阶项。", "answer": "$$\n\\boxed{-\\frac{h^{2}}{3} u''(x)}\n$$", "id": "3411310"}, {"introduction": "在理解了基本核的构造之后，我们将面临一个更实际的挑战：在区域边界处保持超收敛性。标准的对称SIAC核在区域内部表现优异，但在边界处因支撑域不足而失效。本练习要求你设计一个边界修正的单边SIAC核，并从理论上量化边界附近超收敛阶的下降情况。这个练习不仅能加深你对核设计的理解，还能让你体会到理论在应用于实际问题时所做的必要妥协。[@problem_id:3411345]", "problem": "考虑有限区间 $[0,1]$ 上的标量线性平流方程 $u_{t} + a u_{x} = 0$，其中 $a>0$，在 $x=0$ 处有光滑的流入数据，且 $u(x,t)$ 在所有关注的时间内都足够光滑。设 $u_{h}(x,t)$ 表示在尺寸为 $h$ 的均匀网格上，多项式次数为 $p \\geq 1$ 的间断 Galerkin (DG) 近似解，该近似解由相容的数值通量构造，并且对于光滑解，在区域内部具有通常的 DG 精度性质。定义一个光滑算子，其通过与一个增光滑保精度 (SIAC) 核函数进行卷积来实现。在内部，取一个对称的 SIAC 核函数 $K_{h}^{\\mathrm{int}}(x)$，它是通过对一个固定的紧支集核函数 $K^{\\mathrm{int}}(s)$ 进行缩放得到的，$K_{h}^{\\mathrm{int}}(x) = h^{-1} K^{\\mathrm{int}}(x/h)$，使其矩满足精度条件\n$$\n\\mu_{m}^{\\mathrm{int}} := \\int_{\\mathbb{R}} s^{m} K^{\\mathrm{int}}(s) \\,\\mathrm{d}s = \\begin{cases}\n1,  m=0, \\\\\n0,  1 \\leq m \\leq 2p.\n\\end{cases}\n$$\n在边界附近，由于在区域外部缺少支集，内部核函数不能直接应用。设计一个边界修正的单边 SIAC 核函数 $K_{h}^{\\mathrm{bdry}}(x)$，其支集在 $[0,\\infty)$ 上，同样通过对一个固定的紧支集核函数 $K^{\\mathrm{bdry}}(s)$ 进行缩放得到，$K_{h}^{\\mathrm{bdry}}(x) = h^{-1} K^{\\mathrm{bdry}}(x/h)$，使其矩满足单边精度条件\n$$\n\\mu_{m}^{\\mathrm{bdry}} := \\int_{0}^{\\infty} s^{m} K^{\\mathrm{bdry}}(s) \\,\\mathrm{d}s = \\begin{cases}\n1,  m=0, \\\\\n0,  1 \\leq m \\leq q,\n\\end{cases}\n$$\n其中 $q$ 是一个可由固定阶的平移基数 B 样条的有限线性组合表示的紧支集核函数所能达到的最大整数。具体来说，假设 $K^{\\mathrm{bdry}}$ 是 r 阶基数 B 样条的平移的有限线性组合，\n$$\nK^{\\mathrm{bdry}}(s) = \\sum_{j=0}^{J} c_{j} B_{r}(s-j),\n$$\n其中 $B_{r}$ 表示支集在 $[0,r]$ 上的 r 阶基数 B 样条，$\\{c_{j}\\}_{j=0}^{J}$ 是待定的实系数。\n\n仅从卷积定义、光滑函数的泰勒展开以及上述矩（精度）条件出发，完成以下任务：\n- 对于给定的 DG 近似的多项式次数 $p$，确定 $r$ 和 $J$ 的选择以及系数 $\\{c_{j}\\}$ 相应的矩条件，以确保当 $x$ 位于边界的 $\\mathcal{O}(h)$ 邻域内时，边界修正核函数能再生最高 $q$ 次多项式，即对于所有次数至多为 $q$ 的多项式 $\\pi$，都有 $(K_{h}^{\\mathrm{bdry}} * \\pi)(x) = \\pi(x)$。\n- 利用 $u$ 的泰勒展开和矩条件，推导内部的滤波后误差 $(K_{h}^{\\mathrm{int}} * u_{h})(x) - u(x)$ 和边界附近（在 $x=0$ 的 $\\mathcal{O}(h)$ 邻域内）的滤波后误差 $(K_{h}^{\\mathrm{bdry}} * u_{h})(x) - u(x)$ 的渐近阶，并用 $p$ 和 $q$ 表示为 $h$ 的幂次。\n- 在 $K^{\\mathrm{bdry}}$ 的支集在 $[0,\\infty)$ 上，并且如上所述由 $B_{r}$ 的平移构成，且具有满足矩条件所需的最小宽度和最少自由度的约束下，确定在边界附近可以施加的最大 $q$ 值（作为 $p$ 的函数）。然后，用 $p$ 来量化边界附近与内部相比超收敛阶的下降程度。\n\n你的最终答案应该是一个单一的闭式表达式，给出阶的下降作为 $p$ 的函数。不需要数值取整，也不涉及单位。将最终答案表示为关于 $p$ 的解析表达式。", "solution": "问题要求计算一个间断 Galerkin (DG) 解在使用增光滑保精度 (SIAC) 核函数进行后处理时，其超收敛阶的下降值，具体做法是比较区域内部的收敛阶与流入边界附近的收敛阶。求解过程需要分析滤波后误差，确定可达到的收敛阶，并优化边界核函数的构造。\n\n设 $u$ 是精确光滑解，$u_h$ 是多项式次数为 $p$ 的 DG 近似解。后处理（或滤波）解记为 $u_h^* = K_h * u_h$，其中 $K_h$ 是 SIAC 核函数。问题中使用的卷积定义为 $(f*g)(x) = \\int f(y)g(x-y)dy$，因此 $u_h^*(x) = \\int K_h(y) u_h(x-y) dy$。为了使其在边界 $x=0$ 附近良定义（其中 $u_h$ 仅对正自变量有定义），我们假设采用标准方法，即使用由光滑流入边界数据决定的精确解来将 $u_h$ 延拓到 $x<0$。由于在这种延拓下，当 $x<0$ 时误差 $e_h=u_h-u$ 为零，因此误差的卷积积分被有效地限制在区域内。一个等价且更直接的滤波操作公式是 $(K_h \\star u_h)(x) = \\int K_h(x-y) u_h(y) dy$。我们将使用这个公式，因为它能自然地处理区域边界。\n\n在点 $x$ 处的滤波后误差为 $E_h(x) = (K_h \\star u_h)(x) - u(x)$。我们将此误差分解为两部分：\n$$ E_h(x) = \\underbrace{(K_h \\star u_h)(x) - (K_h \\star u)(x)}_{E_h^{(1)}(x)} + \\underbrace{(K_h \\star u)(x) - u(x)}_{E_h^{(2)}(x)} $$\n$E_h^{(1)}(x) = K_h \\star (u_h - u)$ 是来自 DG 离散误差的贡献。\n$E_h^{(2)}(x)$ 是光滑误差，它衡量滤波器再生精确解的好坏程度。\n\n**光滑误差 $E_h^{(2)}(x)$ 的分析**\n\n设 $K_h(z) = h^{-1}K(z/h)$，并设 $\\mu_m = \\int s^m K(s) ds$ 为核函数 $K$ 的 m 阶矩。$s$ 的积分域取决于 $K$ 的支集。\n通过变量代换 $s = (x-y)/h$ 以及将 $u(y)$ 在 $x$ 附近进行泰勒展开，我们得到：\n$$ (K_h \\star u)(x) = \\int K(s) u(x-sh) ds = \\int K(s) \\sum_{m=0}^k \\frac{(-sh)^m}{m!} u^{(m)}(x) ds + \\mathcal{O}(h^{k+1}) $$\n$$ (K_h \\star u)(x) = \\sum_{m=0}^k \\frac{(-h)^m u^{(m)}(x)}{m!} \\mu_m + \\mathcal{O}(h^{k+1}) $$\n如果一个核函数能再生最高 $k$ 次多项式，则称其具有 $k$ 阶精度。这等价于矩条件 $\\mu_m = \\delta_{m0}$ 对 $0 \\le m \\le k$ 成立。\n如果一个核函数具有 $k$ 阶精度，则光滑误差为：\n$$ E_h^{(2)}(x) = u(x) \\mu_0 + \\sum_{m=1}^k \\frac{(-h)^m u^{(m)}(x)}{m!} \\mu_m - u(x) + \\mathcal{O}(h^{k+1}) = u(x) \\cdot 1 + 0 - u(x) + \\mathcal{O}(h^{k+1}) = \\mathcal{O}(h^{k+1}) $$\n具体来说，主误差项是 $\\frac{(-h)^{k+1}}{(k+1)!} u^{(k+1)}(x) \\mu_{k+1}$。\n\n对于内部核函数 $K_h^{\\mathrm{int}}$，题目说明矩条件对 $m \\le 2p$ 成立。因此，它具有 $k=2p$ 阶精度。光滑误差为 $E_h^{(2),\\mathrm{int}}(x) = \\mathcal{O}(h^{2p+1})$。由于核函数是对称的，所有奇数阶矩都为零，即 $\\mu_{2p+1}^{\\mathrm{int}}=0$。所以，光滑误差实际上是 $E_h^{(2),\\mathrm{int}}(x) = \\mathcal{O}(h^{2p+2})$。\n\n对于边界核函数 $K_h^{\\mathrm{bdry}}$，它具有 $q$ 阶精度。光滑误差为 $E_h^{(2),\\mathrm{bdry}}(x) = \\mathcal{O}(h^{q+1})$。\n\n**离散误差贡献 $E_h^{(1)}(x)$ 的分析**\n\n项 $E_h^{(1)}(x) = K_h \\star (u_h - u)$ 包含 DG 误差 $e_h=u_h-u$。DG 方法理论中的一个标准结果是 $L^2$ 误差为 $\\Vert u_h - u \\Vert_{L^2} = \\mathcal{O}(h^{p+1})$。由于 $K_h \\star$ 是一个线性光滑算子，一个基本估计给出 $\\Vert K_h \\star (u_h - u) \\Vert = \\mathcal{O}(h^{p+1})$。\n\n然而，在内部，DG 方法的一个特殊性质与对称核函数相结合，会导致更高的收敛阶。DG 误差 $e_h$ 具有某种结构（与其在每个单元上与 $p$ 次多项式的正交性有关），当与一个精度为 $2p$ 的对称核函数 $K_h^{\\mathrm{int}}$ 卷积时，会产生小得多的误差。这是一个关键的超收敛结果，它表明 $E_h^{(1),\\mathrm{int}}(x) = \\mathcal{O}(h^{2p+1})$。\n\n在边界处，核函数 $K_h^{\\mathrm{bdry}}$ 是单边的，因此不对称。特殊的抵消机制会丢失。$E_h^{(1),\\mathrm{bdry}}$ 的收敛阶受到 DG 解的基础精度的限制。在这种情况下，已有结果表明 $E_h^{(1),\\mathrm{bdry}}(x) = \\mathcal{O}(h^{p+1})$。\n\n**总误差和收敛阶**\n\n总误差是这两个分量的和。总体收敛阶是这两个分量阶数的最小值。\n\n内部收敛阶：\n$$ O_{\\mathrm{int}} = \\text{order of } \\min(E_h^{(1),\\mathrm{int}}, E_h^{(2),\\mathrm{int}}) = \\min(2p+1, 2p+2) = 2p+1 $$\n\n边界收敛阶：\n$$ O_{\\mathrm{bdry}} = \\text{order of } \\min(E_h^{(1),\\mathrm{bdry}}, E_h^{(2),\\mathrm{bdry}}) = \\min(p+1, q+1) $$\n\n**优化边界核函数**\n\n问题要求在最小性约束下求最大 $q$。我们的目标是最大化边界阶 $O_{\\mathrm{bdry}} = \\min(p+1, q+1)$。从这个表达式可以看出，阶数的上限为 $p+1$。将 $q$ 增加到 $p$ 以上（即 $q+1 > p+1$）不会增加总体阶数 $O_{\\mathrm{bdry}}$。因此，我们能达到的最大*有效*阶是 $p+1$，这在任何 $q \\ge p$ 的情况下都会发生。\n\n问题对核函数的宽度和自由度数量施加了最小性约束。我们寻求找到能达到最大有效阶的最少资源构造。这意味着我们应该选择能得到 $p+1$ 阶的最小 $q$，即 $q=p$。\n\n让我们用其他约束来验证这个选择。\n核函数是 $K^{\\mathrm{bdry}}(s) = \\sum_{j=0}^{J} c_j B_r(s-j)$。它是一个次数为 $d=r-1$ 的分段多项式。\n1.  **$q$ 的选择**：为了最大化 $O_{\\mathrm{bdry}}$，我们需要 $q \\ge p$。为满足最小性约束，我们选择最小可能的 $q$，所以我们设定 $q=p$。\n\n2.  **自由度数量**：我们需要满足 $q+1 = p+1$ 个矩条件（$\\mu_m=\\delta_{m0}$ 对 $m=0, \\dots, p$ 成立）。“最少自由度”意味着我们需要 $J+1=p+1$ 个系数，所以 $J=p$。\n\n3.  **B 样条阶数 $r$ 的选择**：逼近论中的一个结果表明，一个由次数为 $d$ 的分段多项式构成、支集在 $[0, W]$ 上的单边核函数，最多可以有 $d$ 个消失矩（即 $q_{max} = d$）。为了达到我们的目标 $q=p$，我们需要一个次数至少为 $d=p$ 的核函数。这意味着 $r-1 \\ge p$，即 $r \\ge p+1$。\n\n4.  **最小宽度**：核函数的宽度（支集大小）为 $W = J+r = p+r$。为了最小化宽度，我们必须选择最小可能的 $r$，即 $r=p+1$。\n\n这在给定的约束下导出了一个唯一的、最优的构造：我们必须选择 $q=p$，这可以通过一个由 $p+1$ 阶 B 样条构成的、包含 $J=p$ 项的核函数来实现。这种构造产生的边界收敛阶为 $O_{\\mathrm{bdry}} = \\min(p+1, p+1) = p+1$。\n\n**超收敛阶的下降**\n\n区域内部的超收敛阶是 $O_{\\mathrm{int}} = 2p+1$。\n边界附近可达到的最大超收敛阶是 $O_{\\mathrm{bdry}} = p+1$。\n超收敛阶的下降是这两者之差：\n$$ \\text{Drop in order} = O_{\\mathrm{int}} - O_{\\mathrm{bdry}} = (2p+1) - (p+1) = p $$", "answer": "$$ \\boxed{p} $$", "id": "3411345"}, {"introduction": "理论与设计最终需要通过实践来检验。本压轴练习将理论付诸实践，要求你编写一个数值程序来研究一个复杂但常见的情景：在几何加密的非均匀网格上，如何处理带奇异性解的恢复问题。你将实现并比较两种不同的梯度恢复算子——算术平均和多项式次数加权平均——对非均匀多项式次数分布下的超收敛性的影响。通过这个编码实践，你将对自适应方法中恢复算子的性能获得深刻的、可量化的认识。[@problem_id:3411332]", "problem": "考虑一维区间 $[0,1]$ 以及一个具有角点奇异性的函数 $u(x) = x^{\\lambda}$，其中 $\\lambda \\in (0,2)$ 确保了在 $x=0$ 附近存在弱奇异性，但对于合适的 $\\lambda$，仍允许进行有意义的有限元和间断Galerkin近似。设一个非均匀网格通过几何分级方法构建，该网格向角点 $x=0$ 处加密，单元尺寸为 $h_K \\sim \\sigma^{\\ell}$，其中分级参数 $\\sigma \\in (0,1)$，层索引 $\\ell$ 随着单元远离角点而增加。\n\n使用间断多项式空间 $V_h$，该空间由每个单元 $K_k$ 上次数为 $p_k$ 的分片多项式构成，无全局连续性约束。对每个单元 $K_k$，将其局部基定义为从参考区间 $[-1,1]$ 映射到 $K_k$ 的 Legendre 多项式 $\\{P_n\\}_{n=0}^{p_k}$。设局部分立近似 $u_h$ 定义为 $u$ 在 $\\mathbb{P}^{p_k}(K_k)$ 上的分片 $L^{2}$ 投影，即唯一的 $u_h \\in V_h$，使得对于每个单元 $K_k$ 和每个基函数 $\\phi \\in \\mathbb{P}^{p_k}(K_k)$，都有\n$$\n\\int_{K_{k}} (u - u_{h}) \\, \\phi \\, dx = 0.\n$$\n\n在每个内部网格节点 $x_i$ 处，定义来自左右单元的离散导数 $\\partial_x u_h$ 的迹，记为 $\\partial_x u_h(x_i^-)$ 和 $\\partial_x u_h(x_i^+)$。考虑在每个内部节点处的两个梯度恢复算子：\n- 算术平均恢复\n$$\nG_{\\mathrm{avg}}(x_i) = \\tfrac{1}{2}\\left( \\partial_x u_h(x_i^-) + \\partial_x u_h(x_i^+) \\right).\n$$\n- 多项式次数加权平均恢复\n$$\nG_{\\mathrm{deg}}(x_i) = \\frac{p_{i-1}}{p_{i-1}+p_i} \\, \\partial_x u_h(x_i^-) + \\frac{p_i}{p_{i-1}+p_i} \\, \\partial_x u_h(x_i^+),\n$$\n其中 $p_{i-1}$ 和 $p_i$ 是与 $x_i$ 相邻的左右单元上的多项式次数。\n\n本问题的目的是测试在使用几何分级的非均匀网格时，恢复算子中的多项式次数加权平均能否为奇异解 $u(x) \\sim r^{\\lambda}$ 恢复角点附近的超收敛行为。对于靠近 $x=0$ 的前 $m$ 个内部节点，定义恢复梯度相对于精确梯度 $\\partial_x u(x) = \\lambda x^{\\lambda-1}$ 的均方根误差，\n$$\nE_{\\star}(K) = \\left( \\frac{1}{m} \\sum_{i=1}^{m} \\left( G_{\\star}(x_i) - \\partial_x u(x_i) \\right)^{2} \\right)^{1/2},\n$$\n其中 $\\star \\in \\{\\mathrm{avg}, \\mathrm{deg}\\}$，$K$ 是单元数量。对于 $K$ 不断增加的分级网格，将在角点附近观测到的收敛率定义为：\n$$\n\\rho_{\\star} = \\frac{\\log\\left( E_{\\star}(K_1) / E_{\\star}(K_2) \\right)}{\\log\\left( K_2 / K_1 \\right)},\n$$\n该值在连续两次网格加密 $K_1$ 和 $K_2$ 之间计算。为了聚合多个加密级别的结果，使用所提供级别中观测到的最小速率，以避免高估收敛率：\n$$\n\\widehat{\\rho}_{\\star} = \\min\\left\\{ \\rho_{\\star}(K_1,K_2) \\right\\}\n$$\n。\n\n从 $L^{2}$ 投影、Legendre 多项式基、迹和恢复算子的核心定义出发，实现一个程序，该程序：\n1. 在 $[0,1]$ 上构建具有 $K$ 个单元的几何分级网格，使用 $h_k \\propto \\sigma^{\\ell}$，并进行归一化以填充整个区间，加密偏向于使最小的单元靠近 $x=0$。\n2. 对每个单元，使用足够高阶的 Gauss-Legendre 求积法计算 $u(x) = x^{\\lambda}$ 在 $\\mathbb{P}^{p_k}(K_k)$ 上的分片 $L^{2}$ 投影 $u_h$，以确保投影的准确性。\n3. 使用映射后的 Legendre 基和精确的雅可比因子，在内部节点处计算 $\\partial_x u_h$ 的左右迹。\n4. 计算前 $m$ 个内部节点的 $E_{\\mathrm{avg}}(K)$ 和 $E_{\\mathrm{deg}}(K)$，以及在提供的加密级别上相应的聚合率 $\\widehat{\\rho}_{\\mathrm{avg}}$ 和 $\\widehat{\\rho}_{\\mathrm{deg}}$。\n5. 判断次数加权恢复是否比算术恢复产生的聚合率严格大出一个裕度 $\\delta>0$，这表明在角点附近恢复了超收敛性（即阶数的提高）。使用 $\\delta = 0.2$。\n\n您的程序必须评估以下测试套件，每个测试由元组 $(\\lambda, \\sigma, p_{\\min}, p_{\\max}, \\text{uniform}, K\\text{-levels}, m)$ 指定：\n- 测试用例1（通用分级，非均匀多项式次数）：$(\\lambda=0.7, \\sigma=0.4, p_{\\min}=1, p_{\\max}=4, \\text{uniform}=\\text{False}, K\\text{-levels}=[32,64,128], m=3)$。\n- 测试用例2（较弱奇异性，非均匀多项式次数）：$(\\lambda=1.2, \\sigma=0.5, p_{\\min}=1, p_{\\max}=4, \\text{uniform}=\\text{False}, K\\text{-levels}=[32,64,128], m=3)$。\n- 测试用例3（均匀多项式次数基线）：$(\\lambda=0.7, \\sigma=0.4, p_{\\min}=2, p_{\\max}=2, \\text{uniform}=\\text{True}, K\\text{-levels}=[32,64,128], m=3)$。\n\n对于非均匀次数分布，设置 $p_k$ 随单元索引线性变化，从角点 ($x=0$) 处的 $p_{\\min}$ 增加到 $x=1$ 处的 $p_{\\max}$，每个单元的次数为整数。对于均匀情况，为所有单元设置 $p_k \\equiv p_{\\min} = p_{\\max}$。\n\n对于每个测试用例，程序必须输出一个布尔值，指示是否满足 $\\widehat{\\rho}_{\\mathrm{deg}} \\ge \\widehat{\\rho}_{\\mathrm{avg}} + \\delta$。您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，“[result1,result2,result3]”）。", "solution": "用户提供的问题根据指定的验证标准进行了严格评估。\n\n### 问题验证\n\n#### 步骤1：提取已知条件\n\n- **域：** 一维区间 $[0,1]$。\n- **函数：** $u(x) = x^{\\lambda}$，奇异性参数 $\\lambda \\in (0,2)$。\n- **精确梯度：** $\\partial_{x}u(x) = \\lambda x^{\\lambda-1}$。\n- **网格：** 非均匀、几何分级，向 $x=0$ 加密。单元尺寸 $h_{K} \\sim \\sigma^{\\ell}$，分级参数 $\\sigma \\in (0,1)$。网格有 $K$ 个单元。\n- **离散空间：** $V_{h}$，每个单元 $K_{k}$ 上的次数为 $p_{k}$ 的分片多项式（间断Galerkin空间）。\n- **局部基：** 从 $[-1,1]$ 映射到 $K_{k}$ 的 Legendre 多项式 $\\{P_{n}\\}_{n=0}^{p_{k}}$。\n- **近似：** $u_{h}$ 是 $u$ 在 $\\mathbb{P}^{p_{k}}(K_{k})$ 上的分片 $L^{2}$ 投影，由 $\\int_{K_{k}} (u - u_{h}) \\, \\phi \\, dx = 0$ 对所有 $\\phi \\in \\mathbb{P}^{p_{k}}(K_{k})$ 定义。\n- **迹：** 在内部节点 $x_{i}$ 处，离散导数的迹为 $\\partial_{x}u_{h}(x_{i}^{-})$（来自左单元）和 $\\partial_{x}u_{h}(x_{i}^{+})$（来自右单元）。\n- **梯度恢复算子：**\n    - 算术平均：$G_{\\mathrm{avg}}(x_{i}) = \\tfrac{1}{2}\\left( \\partial_{x}u_{h}(x_{i}^{-}) + \\partial_{x}u_{h}(x_{i}^{+}) \\right)$。\n    - 多项式次数加权平均：$G_{\\mathrm{deg}}(x_{i}) = \\frac{p_{i-1}}{p_{i-1}+p_{i}} \\, \\partial_{x}u_{h}(x_{i}^{-}) + \\frac{p_{i}}{p_{i-1}+p_{i}} \\, \\partial_{x}u_{h}(x_{i}^{+})$，其中 $p_{i-1}, p_{i}$ 是左右单元的次数。\n- **误差度量：** 前 $m$ 个内部节点上的均方根误差：$E_{\\star}(K) = \\left( \\frac{1}{m} \\sum_{i=1}^{m} \\left( G_{\\star}(x_{i}) - \\partial_{x}u(x_{i}) \\right)^{2} \\right)^{1/2}$，其中 $\\star \\in \\{\\mathrm{avg}, \\mathrm{deg}\\}$。\n- **收敛率：** 加密间的观测率：$\\rho_{\\star} = \\frac{\\log\\left( E_{\\star}(K_{1}) / E_{\\star}(K_{2}) \\right)}{\\log\\left( K_{2} / K_{1} \\right)}$。\n- **聚合率：** 最小观测率：$\\widehat{\\rho}_{\\star} = \\min\\left\\{ \\rho_{\\star}(K_{1},K_{2}) \\right\\}$。\n- **超收敛条件：** $\\widehat{\\rho}_{\\mathrm{deg}} \\ge \\widehat{\\rho}_{\\mathrm{avg}} + \\delta$，其中 $\\delta = 0.2$。\n- **多项式次数分布：**\n    - 非均匀：$p_k$ 随单元索引 $k$ 从 $p_{\\min}$ 到 $p_{\\max}$ 线性变化。\n    - 均匀：$p_{k} \\equiv p_{\\min} = p_{\\max}$。\n- **实现要求：**\n    1. 构建几何分级网格。\n    2. 使用足够高阶的Gauss-Legendre求积法计算分片 $L^{2}$ 投影。\n    3. 计算 $\\partial_{x}u_{h}$ 的左右迹。\n    4. 计算误差 $E_{\\star}(K)$ 和聚合率 $\\widehat{\\rho}_{\\star}$。\n    5. 评估超收敛条件。\n- **测试用例：**\n    1. $(\\lambda=0.7, \\sigma=0.4, p_{\\min}=1, p_{\\max}=4, \\text{uniform}=\\text{False}, K\\text{-levels}=[32,64,128], m=3)$。\n    2. $(\\lambda=1.2, \\sigma=0.5, p_{\\min}=1, p_{\\max}=4, \\text{uniform}=\\text{False}, K\\text{-levels}=[32,64,128], m=3)$。\n    3. $(\\lambda=0.7, \\sigma=0.4, p_{\\min}=2, p_{\\max}=2, \\text{uniform}=\\text{True}, K\\text{-levels}=[32,64,128], m=3)$。\n\n#### 步骤2：使用提取的已知条件进行验证\n\n- **科学依据：** 该问题牢固地植根于偏微分方程的数值分析，特别是有限元和间断Galerkin（DG）方法。奇异函数 $u(x)=x^{\\lambda}$、几何分级网格、$L^2$ 投影和梯度恢复算子的使用都是研究近似性质、误差估计和超收敛现象的标准、成熟概念。\n- **良定的：** 该问题提供了一个清晰、确定性的算法。所有输入（$\\lambda, \\sigma$，多项式次数，网格级别）都已指定。输出（每个测试用例的布尔值）由算法唯一确定。\n- **客观性：** 问题使用精确的数学定义和形式化语言描述，没有主观或含糊的术语。\n- **缺陷检查表：**\n    1. **科学/事实不健全：** 无。这些概念在数值分析中是标准的。\n    2. **非形式化/不相关：** 无。该问题是一个具体的、可形式化的计算任务，与谱/DG方法中基于恢复的误差估计器主题直接相关。\n    3. **不完整/矛盾的设置：** 问题提供了所有必要的信息。使用“足够高阶”求积法的指令是数值计算中的标准指令，意味着实现者必须选择一个足够高的阶数以最小化求积误差，这是该方法设计的标准部分。`p-`分布的定义也很清晰。\n    4. **不切实际/不可行：** 无。该设置是一个常见的数值实验。\n    5. **病态/结构不良：** 无。问题结构逻辑清晰，能得出唯一且有意义的结果。\n    6. **伪高深/琐碎：** 无。该问题需要对几个核心DG概念进行非平凡的实现，并理解网格分级、多项式次数和解的奇异性之间的相互作用。测试用例3提供了一个有价值的健全性检查，因为对于均匀的$p$，$G_{\\text{avg}}$和$G_{\\text{deg}}$是相同的，使得超收敛条件不可能满足。\n    7. **超出科学可验证性：** 无。结果是计算性的，可以独立验证。\n\n#### 步骤3：结论与行动\n问题是**有效的**。将提供一个完整且论证充分的解决方案。\n\n### 基于原则的解决方案设计\n\n该问题要求对多项式次数加权梯度恢复算子在奇异点附近对间断Galerkin（DG）近似的收敛率的影响进行计算研究。解决方案将按照问题陈述中概述的步骤系统地构建。\n\n#### 1. 几何分级网格构建\n当 $\\lambda  1$ 时，函数 $u(x) = x^{\\lambda}$ 的导数在 $x=0$ 处具有奇异性。为了精确逼近这样的函数，必须在奇异点附近加密网格。几何分级网格通过使单元尺寸朝奇异点方向逐渐变小来实现这一点。\n\n设 $[0,1]$ 上的网格由 $K$ 个单元 $K_0, K_1, \\dots, K_{K-1}$ 组成，其中 $K_k = [x_k, x_{k+1}]$。最小的单元 $K_0$ 位于 $x=0$。单元尺寸 $h_k = x_{k+1} - x_k$ 由 $h_k = C \\sigma^{K-1-k}$ 定义，其中 $k \\in \\{0, \\dots, K-1\\}$，分级因子 $\\sigma \\in (0,1)$。这确保了 $h_0$ 是最小的，且单元尺寸从原点开始几何增长。常数 $C$ 是一个归一化因子，确保所有单元尺寸之和为1：\n$$ \\sum_{k=0}^{K-1} h_k = \\sum_{k=0}^{K-1} C \\sigma^{K-1-k} = C \\sum_{j=0}^{K-1} \\sigma^j = C \\frac{1-\\sigma^K}{1-\\sigma} = 1 $$\n因此，$C = \\frac{1-\\sigma}{1-\\sigma^K}$。然后迭代计算节点坐标：$x_0 = 0$ 和 $x_{k+1} = x_k + h_k$ for $k=0, \\dots, K-1$。\n\n#### 2. 多项式次数分布\n对于$hp$-自适应方法，多项式次数$p_k$可以随单元变化。问题指定了两种情况：\n- **均匀$p$：** 对所有单元 $k$，$p_k = p_{\\text{min}} = p_{\\text{max}}$。\n- **非均匀$p$：** 次数随单元索引从 $x=0$ 到 $x=1$ 线性增加。我们可以将其定义为 $p_k = \\text{round}(p_{\\min} + (p_{\\max} - p_{\\min}) \\frac{k}{K-1})$，其中 $k \\in \\{0, \\dots, K-1\\}$，这确保了 $p_0=p_{\\min}$ 和 $p_{K-1}=p_{\\max}$。\n\n#### 3. 逐单元L^2投影\nDG近似$u_h$在每个单元$K_k$上定义为$u(x)$在次数为$p_k$的多项式空间$\\mathbb{P}^{p_k}(K_k)$中的最佳近似（在$L^2$范数意义下）。这通过$L^2$投影实现。我们在映射的Legendre多项式基$\\phi_n(x)$中表示单元$K_k$上的$u_h$：\n$$ u_h(x)|_{K_k} = \\sum_{n=0}^{p_k} c_{k,n} \\phi_n(x) $$\n基函数 $\\phi_n(x)$ 是通过仿射映射 $x(y) = x_k + \\frac{h_k}{2}(y+1)$ 将标准Legendre多项式$L_n(y)$从参考区间$y \\in [-1,1]$映射到物理单元$x \\in K_k = [x_k, x_{k+1}]$得到的，其雅可比行列式为$J = \\frac{dx}{dy} = \\frac{h_k}{2}$。\n\n正交条件 $\\int_{K_k} (u - u_h) \\phi_j dx = 0$ 产生了一个关于系数 $c_{k,n}$ 的方程组。由于Legendre多项式的正交性，质量矩阵是对角的：\n$$ \\int_{K_k} \\phi_n(x) \\phi_j(x) dx = \\int_{-1}^1 L_n(y) L_j(y) J \\, dy = \\frac{h_k}{2} \\frac{2}{2n+1} \\delta_{nj} $$\n这简化了系数的计算：\n$$ c_{k,n} = \\frac{\\int_{K_k} u(x) \\phi_n(x) dx}{\\int_{K_k} \\phi_n^2(x) dx} = \\frac{2n+1}{h_k} \\int_{K_k} u(x) \\phi_n(x) dx $$\n分子中的积分使用变换到单元$K_k$上的Gauss-Legendre求积法进行数值计算：\n$$ \\int_{K_k} u(x) \\phi_n(x) dx = \\int_{-1}^1 u(x(y)) L_n(y) J \\, dy \\approx \\frac{h_k}{2} \\sum_{q=1}^{N_q} w_q u(x(y_q)) L_n(y_q) $$\n其中$\\{y_q, w_q\\}$是$[-1,1]$上的求积点和权重。必须使用大量的求积点($N_q$)来精确积分非多项式函数$u(x)=x^\\lambda$。\n\n#### 4. 梯度迹的计算\n局部近似$u_h$的导数通过链式法则求得：$\\frac{d}{dx} = \\frac{dy}{dx}\\frac{d}{dy} = \\frac{2}{h_k}\\frac{d}{dy}$。\n$$ \\frac{d u_h}{dx}\\bigg|_{K_k} = \\frac{2}{h_k} \\sum_{n=0}^{p_k} c_{k,n} L'_n(y(x)) $$\n在一个内部节点 $x_i$ 处，我们计算来自相邻单元 $K_{i-1}$（左）和 $K_i$（右）的导数。\n- 左迹 $\\partial_x u_h(x_i^-)$ 是来自 $K_{i-1}=[x_{i-1}, x_i]$ 的导数在其右端点 $x=x_i$ 处的值，这对应于参考区间上的 $y=1$。\n$$ \\partial_x u_h(x_i^-) = \\frac{2}{h_{i-1}} \\sum_{n=1}^{p_{i-1}} c_{i-1,n} L'_n(1) $$\n- 右迹 $\\partial_x u_h(x_i^+)$ 是来自 $K_i=[x_i, x_{i+1}]$ 的导数在其左端点 $x=x_i$ 处的值，这对应于 $y=-1$。\n$$ \\partial_x u_h(x_i^+) = \\frac{2}{h_i} \\sum_{n=1}^{p_i} c_{i,n} L'_n(-1) $$\n求和从 $n=1$ 开始，因为 $L'_0(y)=0$。我们使用Legendre多项式在端点处的导数值：$L'_n(1) = \\frac{n(n+1)}{2}$ 和 $L'_n(-1) = (-1)^{n+1} \\frac{n(n+1)}{2}$。\n\n#### 5. 梯度恢复与误差度量\n$\\partial_x u_h$ 在单元边界处的间断性质需要一个恢复算子来获得单值的梯度近似。问题对比了两种常见的算子：\n- **算术平均 ($G_{\\mathrm{avg}}$):** 这是最简单的恢复方法，给予两侧信息相同的权重。\n- **次数加权平均 ($G_{\\mathrm{deg}}$):** 该算子给予多项式次数较高的一侧更大的权重，其假设是更高次的近似提供更精确的梯度估计。对于均匀的 $p$，该算子退化为算术平均。\n\n每个恢复梯度的精度通过均方根误差 $E_{\\star}(K)$ 来衡量，该误差是相对于精确梯度 $\\partial_x u(x) = \\lambda x^{\\lambda-1}$ 计算的，计算范围是受奇异性影响最大的前 $m$ 个内部节点。\n\n#### 6. 收敛率计算\n收敛率揭示了随着单元数量 $K$ 的增加，误差如何减小。收敛率 $\\rho_{\\star}$ 在两个连续的网格加密级别 $K_1$ 和 $K_2$ 之间使用标准的对数-对数公式计算。为了获得对多个加密级别上渐近率的保守估计，使用了最小观测率 $\\widehat{\\rho}_{\\star}$。\n\n#### 7. 最终评估\n核心假设是，对于分级网格上的非均匀多项式次数分布，次数加权的恢复将比简单的平均法表现出更高的收敛率（超收敛）。这通过检查次数加权恢复的聚合率是否比算术平均的聚合率严格大出一个裕度 $\\delta=0.2$ 来测试，即 $\\widehat{\\rho}_{\\mathrm{deg}} \\ge \\widehat{\\rho}_{\\mathrm{avg}} + \\delta$。此检查的布尔结果是每个测试用例的最终输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import eval_legendre\n\n# language: Python\n# version: 3.12\n# libraries:\n#   - name: numpy\n#     version: 1.23.5\n#   - name: scipy\n#     version: 1.11.4\n\ndef solve():\n    \"\"\"\n    Main solver function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (lambda, sigma, p_min, p_max, uniform, K-levels, m)\n        (0.7, 0.4, 1, 4, False, [32, 64, 128], 3),\n        (1.2, 0.5, 1, 4, False, [32, 64, 128], 3),\n        (0.7, 0.4, 2, 2, True, [32, 64, 128], 3),\n    ]\n    delta = 0.2\n    \n    # Store boolean results for each test case\n    final_results = []\n\n    for case in test_cases:\n        lambda_val, sigma, p_min, p_max, is_uniform, K_levels, m = case\n        \n        errors_avg = []\n        errors_deg = []\n\n        for K in K_levels:\n            E_avg_K, E_deg_K = compute_case_errors(K, sigma, p_min, p_max, is_uniform, lambda_val, m)\n            errors_avg.append(E_avg_K)\n            errors_deg.append(E_deg_K)\n\n        rates_avg = []\n        rates_deg = []\n        for i in range(len(K_levels) - 1):\n            K1, K2 = K_levels[i], K_levels[i+1]\n            \n            # Avoid division by zero or log of non-positive if an error is zero\n            if errors_avg[i] > 0 and errors_avg[i+1] > 0:\n                rho_avg = np.log(errors_avg[i] / errors_avg[i+1]) / np.log(K2 / K1)\n                rates_avg.append(rho_avg)\n            \n            if errors_deg[i] > 0 and errors_deg[i+1] > 0:\n                rho_deg = np.log(errors_deg[i] / errors_deg[i+1]) / np.log(K2 / K1)\n                rates_deg.append(rho_deg)\n        \n        # Aggregated rate is the minimum observed rate\n        hat_rho_avg = min(rates_avg) if rates_avg else 0\n        hat_rho_deg = min(rates_deg) if rates_deg else 0\n        \n        # Check for superconvergence condition\n        is_superconvergent = hat_rho_deg >= hat_rho_avg + delta\n        final_results.append(is_superconvergent)\n\n    # Format the final output as a comma-separated list of boolean values\n    print(f\"[{','.join(map(str, final_results))}]\")\n\n\ndef compute_case_errors(K, sigma, p_min, p_max, is_uniform, lambda_val, m):\n    \"\"\"\n    Computes RMS errors for a single configuration (K).\n    \"\"\"\n    nodes = generate_graded_mesh(K, sigma)\n    p_dist = get_p_distribution(K, p_min, p_max, is_uniform)\n    \n    # Function u(x) and its derivative\n    u_func = lambda x: x**lambda_val\n    du_dx_func = lambda x: lambda_val * x**(lambda_val - 1) if x > 0 else np.inf\n\n    # Element data: sizes, coefficients\n    h_elements = np.diff(nodes)\n    coeffs_per_element = []\n    \n    # Number of quadrature points for L2 projection integral\n    num_quad_points = 40  # High order for accuracy with non-polynomial u(x)\n    y_q, w_q = np.polynomial.legendre.leggauss(num_quad_points)\n\n    # Compute L2 projection coefficients for each element\n    for k in range(K):\n        x_k, x_k_plus_1 = nodes[k], nodes[k+1]\n        h_k = h_elements[k]\n        p_k = p_dist[k]\n        \n        # Map quadrature points from [-1, 1] to [x_k, x_{k+1}]\n        x_q = x_k + (h_k / 2.0) * (y_q + 1.0)\n        \n        coeffs = np.zeros(p_k + 1)\n        for n in range(p_k + 1):\n            # Compute integral part of the coefficient formula\n            integrand_vals = u_func(x_q) * eval_legendre(n, y_q)\n            integral = (h_k / 2.0) * np.sum(w_q * integrand_vals)\n            \n            # Full coefficient formula `c_n = (2n+1)/h_k * integral`\n            coeffs[n] = (2 * n + 1) / h_k * integral\n        coeffs_per_element.append(coeffs)\n    \n    # Compute errors at the first m interior nodes\n    sum_sq_err_avg = 0.0\n    sum_sq_err_deg = 0.0\n\n    for i in range(1, m + 1):\n        x_i = nodes[i]\n        \n        # Left element K_{i-1}\n        h_left = h_elements[i-1]\n        p_left = p_dist[i-1]\n        coeffs_left = coeffs_per_element[i-1]\n        \n        # Right element K_i\n        h_right = h_elements[i]\n        p_right = p_dist[i]\n        coeffs_right = coeffs_per_element[i]\n        \n        # Evaluate traces of the derivative\n        trace_left = 0.0\n        for n in range(1, p_left + 1):\n            L_prime_n_at_1 = n * (n + 1) / 2.0\n            trace_left += coeffs_left[n] * L_prime_n_at_1\n        trace_left *= (2.0 / h_left)\n        \n        trace_right = 0.0\n        for n in range(1, p_right + 1):\n            L_prime_n_at_minus_1 = ((-1)**(n + 1)) * n * (n + 1) / 2.0\n            trace_right += coeffs_right[n] * L_prime_n_at_minus_1\n        trace_right *= (2.0 / h_right)\n        \n        # Compute recovered gradients\n        G_avg = 0.5 * (trace_left + trace_right)\n        \n        # Guard against p_left + p_right = 0 (only if p_min=0, not in tests)\n        if p_left + p_right > 0:\n            w_left = p_left / (p_left + p_right)\n            w_right = p_right / (p_left + p_right)\n        else:\n            w_left = 0.5\n            w_right = 0.5\n        G_deg = w_left * trace_left + w_right * trace_right\n        \n        # Exact gradient\n        du_dx_exact = du_dx_func(x_i)\n        \n        # Accumulate squared errors\n        sum_sq_err_avg += (G_avg - du_dx_exact)**2\n        sum_sq_err_deg += (G_deg - du_dx_exact)**2\n            \n    # Compute RMS errors\n    E_avg = np.sqrt(sum_sq_err_avg / m)\n    E_deg = np.sqrt(sum_sq_err_deg / m)\n    \n    return E_avg, E_deg\n\n\ndef generate_graded_mesh(K, sigma):\n    \"\"\"\n    Constructs a geometrically graded mesh on [0, 1] biased towards x=0.\n    \"\"\"\n    if sigma == 1.0: # Uniform mesh\n        return np.linspace(0, 1, K + 1)\n\n    # Normalization constant for h_k = C * sigma^(K-1-k)\n    C = (1.0 - sigma) / (1.0 - sigma**K) if sigma != 1.0 else 1.0 / K\n    \n    nodes = np.zeros(K + 1)\n    for k in range(K):\n        h_k = C * sigma**(K - 1 - k)\n        nodes[k+1] = nodes[k] + h_k\n    \n    # Ensure the last node is exactly 1 due to potential floating point inaccuracies\n    nodes[-1] = 1.0\n    return nodes\n\ndef get_p_distribution(K, p_min, p_max, is_uniform):\n    \"\"\"\n    Generates the polynomial degree distribution across elements.\n    \"\"\"\n    if is_uniform or K == 1:\n        return np.full(K, p_min, dtype=int)\n    \n    p_dist = np.zeros(K, dtype=int)\n    for k in range(K):\n        p_k_float = p_min + (p_max - p_min) * (k / (K - 1))\n        p_dist[k] = int(round(p_k_float))\n    return p_dist\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3411332"}]}