{"hands_on_practices": [{"introduction": "内部罚参数的选择首先要确保数值方法的稳定性。本练习通过一个简化的模型问题，引导你从第一性原理出发，推导保证能量稳定性所需的最小罚参数 [@problem_id:3414296]。这个推导过程将揭示罚参数与多项式次数和网格尺寸之间的内在联系，并阐明为何间断伽辽金方法需要这样一个稳定项。", "problem": "考虑在区间 $\\Omega = (0,L)$ 上带有齐次边界条件的一维扩散初值问题，该问题通过不连续伽辽金 (Discontinuous Galerkin, DG) 族中的对称内罚伽辽金 (Symmetric Interior Penalty Galerkin, SIPG) 方法在空间上进行离散化。令 $\\mathcal{T}_h$ 是 $\\Omega$ 的一个形状正则、拟一致的剖分，包含 $N$ 个尺寸为 $h = L/N$ 的单元，并令每个单元上的试验/测试空间为次数至多为 $p \\geq 1$ 的多项式空间。记离散函数 $w$ 在界面 $x_i$ 处的跳跃为 $[w]_i = w(x_i^{+}) - w(x_i^{-})$，其导数在界面处的平均为 $\\{w'\\}_i = \\tfrac{1}{2}\\big(w'(x_i^{+}) + w'(x_i^{-})\\big)$。对于单位扩散系数的扩散算子，其 SIPG 双线性形式为\n$$\na_h(u,v) = \\sum_{K \\in \\mathcal{T}_h} \\int_{K} u'(x)\\,v'(x)\\,\\mathrm{d}x \\;-\\; \\sum_{i=1}^{N-1} \\{u'\\}_i\\,[v]_i \\;-\\; \\sum_{i=1}^{N-1} \\{v'\\}_i\\,[u]_i \\;+\\; \\sum_{i=1}^{N-1} \\frac{\\sigma}{h}\\,[u]_i\\,[v]_i,\n$$\n其中 $\\sigma>0$ 是待选的内部罚参数。\n\n对于半离散抛物问题，考虑一致质量公式 $M\\,\\dot{u}_h(t) + A\\,u_h(t) = 0$，其中 $M$ 是与分片 $L^2$ 内积相关的标准质量矩阵，$A$ 是与 $a_h(\\cdot,\\cdot)$ 相关的刚度矩阵。定义离散能量为 $E(t) = \\tfrac{1}{2}\\,u_h(t)^{\\top} M\\,u_h(t)$。\n\n现在考虑对角质量集中：将 $M$ 替换为一个对角矩阵 $M_{\\mathrm{l}}$，该矩阵与 $M$ 谱等价，并在所选节点基下保持单元上的 $L^2$ 积分不变，并使用半离散系统 $M_{\\mathrm{l}}\\,\\dot{u}_h(t) + A\\,u_h(t) = 0$。定义集中质量离散能量为 $E_{\\mathrm{l}}(t) = \\tfrac{1}{2}\\,u_h(t)^{\\top} M_{\\mathrm{l}}\\,u_h(t)$。\n\n在您的推导中仅使用以下基本要素：\n- Cauchy–Schwarz 不等式和 Young 不等式。\n- 次数为 $p$ 的多项式的单元反不等式：存在一个仅依赖于形状正则性的常数 $C_{\\mathrm{inv}}>0$，使得对于任何 $K \\in \\mathcal{T}_h$ 和任何 $w \\in \\mathbb{P}_p(K)$，都有 $|w'(x_{K}^{\\pm})|^2 \\leq C_{\\mathrm{inv}}\\,\\dfrac{p^2}{h}\\,\\int_{K} |w'(x)|^2\\,\\mathrm{d}x$，其中 $x_{K}^{\\pm}$ 表示 $K$ 的端点。\n\n任务：\n1. 从一致质量公式的半离散能量恒等式出发，推导出一个充分下界 $\\sigma_{\\min}$（取决于 $C_{\\mathrm{inv}}$、$p$ 和 $h$），该下界保证能量不增，即对于所有 $t \\geq 0$，有 $\\dfrac{\\mathrm{d}}{\\mathrm{d}t}E(t) \\leq 0$。\n2. 对集中质量公式重复此推导，以获得 $\\sigma_{\\min}^{\\mathrm{lumped}}$。然后计算量 $\\Delta \\sigma_{\\min} = \\sigma_{\\min}^{\\mathrm{lumped}} - \\sigma_{\\min}^{\\mathrm{consistent}}$。\n\n您的最终答案必须是 $\\Delta \\sigma_{\\min}$ 的单个实数或封闭形式表达式。不需要四舍五入。答案中不应使用单位。", "solution": "用户提供了一个来自数值分析领域的问题，具体涉及一维扩散问题中对称内罚伽辽金 (SIPG) 方法的稳定性。任务是确定在一致质量公式和集中质量公式之间，为保证能量稳定性所需的最小内部罚参数 $\\sigma$ 的差异。\n\n### 步骤 1：提取已知条件\n-   **问题**：在 $\\Omega = (0,L)$ 上的一维扩散初值问题。\n-   **离散化方法**：对称内罚伽辽金 (Symmetric Interior Penalty Galerkin, SIPG)。\n-   **网格**：$\\mathcal{T}_h$，$\\Omega$ 的一个形状正则、拟一致的剖分，包含 $N$ 个尺寸为 $h=L/N$ 的单元。\n-   **函数空间**：次数至多为 $p \\ge 1$ 的分片多项式。\n-   **算子**：跳跃 $[w]_i = w(x_i^{+}) - w(x_i^{-})$ 和平均 $\\{w'\\}_i = \\tfrac{1}{2}\\big(w'(x_i^{+}) + w'(x_i^{-})\\big)$。\n-   **双线性形式**：$a_h(u,v) = \\sum_{K \\in \\mathcal{T}_h} \\int_{K} u'(x)\\,v'(x)\\,\\mathrm{d}x \\;-\\; \\sum_{i=1}^{N-1} \\{u'\\}_i\\,[v]_i \\;-\\; \\sum_{i=1}^{N-1} \\{v'\\}_i\\,[u]_i \\;+\\; \\sum_{i=1}^{N-1} \\frac{\\sigma}{h}\\,[u]_i\\,[v]_i$，其中 $\\sigma > 0$。\n-   **一致质量系统**：$M\\,\\dot{u}_h(t) + A\\,u_h(t) = 0$，其中 $M$ 为一致质量矩阵，$A$ 为来自 $a_h(\\cdot, \\cdot)$ 的刚度矩阵。\n-   **一致质量能量**：$E(t) = \\tfrac{1}{2}\\,u_h(t)^{\\top} M\\,u_h(t)$。\n-   **集中质量系统**：$M_{\\mathrm{l}}\\,\\dot{u}_h(t) + A\\,u_h(t) = 0$，其中 $M_{\\mathrm{l}}$ 为对角质量矩阵。\n-   **集中质量能量**：$E_{\\mathrm{l}}(t) = \\tfrac{1}{2}\\,u_h(t)^{\\top} M_{\\mathrm{l}}\\,u_h(t)$。\n-   **反不等式**：对于 $w \\in \\mathbb{P}_p(K)$，有 $|w'(x_{K}^{\\pm})|^2 \\leq C_{\\mathrm{inv}}\\,\\dfrac{p^2}{h}\\,\\int_{K} |w'(x)|^2\\,\\mathrm{d}x$，其中 $C_{\\mathrm{inv}} > 0$。\n-   **任务**：\n    1.  求出充分下界 $\\sigma_{\\min}^{\\mathrm{consistent}}$，保证 $\\dfrac{\\mathrm{d}}{\\mathrm{d}t}E(t) \\leq 0$。\n    2.  为集中质量公式重复推导，求出充分下界 $\\sigma_{\\min}^{\\mathrm{lumped}}$（意味着条件 $\\dfrac{\\mathrm{d}}{\\mathrm{d}t}E_{\\mathrm{l}}(t) \\leq 0$）。\n    3.  计算 $\\Delta \\sigma_{\\min} = \\sigma_{\\min}^{\\mathrm{lumped}} - \\sigma_{\\min}^{\\mathrm{consistent}}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题定义明确，并基于不连续伽辽金方法的既有理论。\n-   **科学依据**：问题陈述使用了偏微分方程数值分析中的标准定义和概念。SIPG 公式、质量集中和能量稳定性分析都是标准课题。所提供的反不等式是单元上多项式的一个已知性质。该问题在科学上是合理的。\n-   **适定的**：目标清晰，所提供的信息足以推导出所要求的量。问题要求一个充分下界，这是一个适定的数学任务。\n-   **客观性**：问题以精确、客观的数学语言陈述，没有歧义或主观论断。\n-   **结论**：该问题是有效的。所有条件和定义都是自洽且一致的。\n\n### 步骤 3：判断与行动\n该问题有效。我将继续进行详细求解。\n\n### 解题推导\n\n问题的核心是为扩散方程在两种不同的半离散设置下建立能量稳定性的条件。在这种情况下，能量稳定性意味着所定义的能量泛函随时间不增。\n\n#### 第 1 部分：一致质量公式与稳定性\n\n对于一致质量公式，半离散系统以向量形式给出为 $M\\,\\dot{u}_h(t) + A\\,u_h(t) = 0$。相应的能量为 $E(t) = \\tfrac{1}{2}\\,u_h(t)^{\\top} M\\,u_h(t)$。在函数空间表示法中，此能量对应于 $L^2$-范数的平方：$E(t) = \\frac{1}{2} \\| u_h(\\cdot,t) \\|_{L^2(\\Omega)}^2 = \\frac{1}{2} (u_h, u_h)_{L^2}$。\n\n我们计算能量的时间导数：\n$$\n\\frac{\\mathrm{d}E}{\\mathrm{d}t} = \\frac{\\mathrm{d}}{\\mathrm{d}t} \\left( \\frac{1}{2}\\,u_h(t)^{\\top} M\\,u_h(t) \\right) = \\dot{u}_h(t)^{\\top} M\\,u_h(t)\n$$\n根据半离散方程，我们有 $M\\,\\dot{u}_h(t) = -A\\,u_h(t)$。将其代入能量导数方程，得到：\n$$\n\\frac{\\mathrm{d}E}{\\mathrm{d}t} = -u_h(t)^{\\top} A\\,u_h(t)\n$$\n向量表达式 $u_h(t)^{\\top} A\\,u_h(t)$ 是双线性形式 $a_h(u_h, u_h)$ 的代数表示。因此，能量恒等式为：\n$$\n\\frac{\\mathrm{d}E}{\\mathrm{d}t} = -a_h(u_h, u_h)\n$$\n因此，能量不增的条件 $\\frac{\\mathrm{d}E}{\\mathrm{d}t} \\le 0$ 等价于双线性形式的矫顽性条件：\n$$\na_h(u_h, u_h) \\ge 0 \\quad \\forall u_h \\in V_h\n$$\n我们来分析 $a_h(u_h, u_h)$：\n$$\na_h(u_h, u_h) = \\sum_{K \\in \\mathcal{T}_h} \\int_{K} |u_h'(x)|^2\\,\\mathrm{d}x \\;-\\; 2\\sum_{i=1}^{N-1} \\{u_h'\\}_i\\,[u_h]_i \\;+\\; \\sum_{i=1}^{N-1} \\frac{\\sigma}{h}\\,[u_h]_i^2\n$$\n我们关注界面项。对项 $2\\{u_h'\\}_i\\,[u_h]_i$ 使用 Young 不等式 $2ab \\le \\delta a^2 + \\frac{1}{\\delta}b^2$（对于任意 $\\delta > 0$）：\n$$\n2|\\{u_h'\\}_i\\,[u_h]_i| \\le \\delta |\\{u_h'\\}_i|^2 + \\frac{1}{\\delta}|[u_h]_i|^2\n$$\n这意味着 $-2\\{u_h'\\}_i\\,[u_h]_i \\ge -\\delta |\\{u_h'\\}_i|^2 - \\frac{1}{\\delta}|[u_h]_i|^2$。将其代入 $a_h(u_h, u_h)$ 的表达式中：\n$$\na_h(u_h, u_h) \\ge \\sum_{K} \\int_{K} |u_h'|^2\\,\\mathrm{d}x - \\delta \\sum_{i=1}^{N-1} |\\{u_h'\\}_i|^2 - \\frac{1}{\\delta} \\sum_{i=1}^{N-1} |[u_h]_i|^2 + \\frac{\\sigma}{h} \\sum_{i=1}^{N-1} |[u_h]_i|^2\n$$\n$$\na_h(u_h, u_h) \\ge \\sum_{K} \\int_{K} |u_h'|^2\\,\\mathrm{d}x - \\delta \\sum_{i=1}^{N-1} |\\{u_h'\\}_i|^2 + \\sum_{i=1}^{N-1} \\left(\\frac{\\sigma}{h} - \\frac{1}{\\delta}\\right) |[u_h]_i|^2\n$$\n现在，我们使用给定的反不等式来界定项 $\\sum_{i=1}^{N-1} |\\{u_h'\\}_i|^2$。首先，根据不等式 $(a+b)^2 \\le 2(a^2+b^2)$：\n$$\n|\\{u_h'\\}_i|^2 = \\frac{1}{4}|u_h'(x_i^-) + u_h'(x_i^+)|^2 \\le \\frac{1}{2} \\left(|u_h'(x_i^-)|^2 + |u_h'(x_i^+)|^2\\right)\n$$\n令 $K_i$ 和 $K_{i+1}$ 是与界面 $x_i$ 相邻的单元，使得 $u_h'(x_i^-)$ 是来自 $K_i$ 内部的导数值，$u_h'(x_i^+)$ 是来自 $K_{i+1}$ 的。对每一项应用反不等式：\n$$\n|u_h'(x_i^-)|^2 \\le C_{\\mathrm{inv}}\\,\\frac{p^2}{h}\\,\\int_{K_i} |u_h'|^2\\,\\mathrm{d}x, \\quad |u_h'(x_i^+)|^2 \\le C_{\\mathrm{inv}}\\,\\frac{p^2}{h}\\,\\int_{K_{i+1}} |u_h'|^2\\,\\mathrm{d}x\n$$\n对所有内部界面 $i=1, \\dots, N-1$ 求和：\n$$\n\\sum_{i=1}^{N-1} |\\{u_h'\\}_i|^2 \\le \\sum_{i=1}^{N-1} \\frac{1}{2} \\left( C_{\\mathrm{inv}}\\,\\frac{p^2}{h}\\,\\int_{K_i} |u_h'|^2\\,\\mathrm{d}x + C_{\\mathrm{inv}}\\,\\frac{p^2}{h}\\,\\int_{K_{i+1}} |u_h'|^2\\,\\mathrm{d}x \\right)\n$$\n求和 $\\sum_{i=1}^{N-1} (\\int_{K_i} + \\int_{K_{i+1}})$ 覆盖了单元 $K_1$ 和 $K_N$ 一次，单元 $K_2, \\dots, K_{N-1}$ 两次。因此，这个和的有界为 $2 \\sum_{j=1}^N \\int_{K_j} |u_h'|^2\\,\\mathrm{d}x$。这得出：\n$$\n\\sum_{i=1}^{N-1} |\\{u_h'\\}_i|^2 \\le \\frac{1}{2} \\left( C_{\\mathrm{inv}}\\,\\frac{p^2}{h} \\right) \\left( 2 \\sum_{K \\in \\mathcal{T}_h} \\int_{K} |u_h'|^2\\,\\mathrm{d}x \\right) = C_{\\mathrm{inv}}\\,\\frac{p^2}{h} \\sum_{K \\in \\mathcal{T}_h} \\int_{K} |u_h'|^2\\,\\mathrm{d}x\n$$\n将此界限代回 $a_h(u_h, u_h)$ 的不等式中：\n$$\na_h(u_h, u_h) \\ge \\left(1 - \\delta C_{\\mathrm{inv}}\\,\\frac{p^2}{h}\\right)\\sum_{K} \\int_{K} |u_h'|^2\\,\\mathrm{d}x + \\left(\\frac{\\sigma}{h} - \\frac{1}{\\delta}\\right) \\sum_{i=1}^{N-1} |[u_h]_i|^2\n$$\n为使 $a_h(u_h, u_h) \\ge 0$，我们需要两个非负和的系数为非负。这给出了关于 $\\delta$ 和 $\\sigma$ 的两个条件：\n1.  $1 - \\delta C_{\\mathrm{inv}}\\,\\frac{p^2}{h} \\ge 0 \\implies \\delta \\le \\frac{h}{C_{\\mathrm{inv}}p^2}$\n2.  $\\frac{\\sigma}{h} - \\frac{1}{\\delta} \\ge 0 \\implies \\sigma \\ge \\frac{h}{\\delta}$\n\n我们需要找到一个最小的 $\\sigma$，使得存在一个 $\\delta > 0$ 满足这些条件。为了最小化 $\\sigma$，我们应该最大化 $\\delta$。$\\delta$ 的最大允许值为 $\\delta_{\\max} = \\frac{h}{C_{\\mathrm{inv}}p^2}$。将其代入 $\\sigma$ 的不等式中：\n$$\n\\sigma \\ge \\frac{h}{\\delta_{\\max}} = \\frac{h}{h / (C_{\\mathrm{inv}}p^2)} = C_{\\mathrm{inv}}p^2\n$$\n因此，罚参数的一个充分下界是 $\\sigma_{\\min}^{\\mathrm{consistent}} = C_{\\mathrm{inv}}p^2$。\n\n#### 第 2 部分：集中质量公式与稳定性\n\n对于集中质量公式，半离散系统是 $M_{\\mathrm{l}}\\,\\dot{u}_h(t) + A\\,u_h(t) = 0$。问题将相应的能量定义为 $E_{\\mathrm{l}}(t) = \\tfrac{1}{2}\\,u_h(t)^{\\top} M_{\\mathrm{l}}\\,u_h(t)$。\n我们计算这个能量的时间导数：\n$$\n\\frac{\\mathrm{d}E_{\\mathrm{l}}}{\\mathrm{d}t} = \\frac{\\mathrm{d}}{\\mathrm{d}t} \\left( \\frac{1}{2}\\,u_h(t)^{\\top} M_{\\mathrm{l}}\\,u_h(t) \\right) = \\dot{u}_h(t)^{\\top} M_{\\mathrm{l}}\\,u_h(t)\n$$\n根据集中质量系统，我们有 $\\dot{u}_h(t) = -M_{\\mathrm{l}}^{-1}A\\,u_h(t)$。我们将其代入能量导数方程。由于 $M_{\\mathrm{l}}$ 是对称和对角的，其逆矩阵 $M_{\\mathrm{l}}^{-1}$ 也是对称和对角的。\n$$\n\\frac{\\mathrm{d}E_{\\mathrm{l}}}{\\mathrm{d}t} = \\left(-M_{\\mathrm{l}}^{-1}A\\,u_h(t)\\right)^{\\top} M_{\\mathrm{l}}\\,u_h(t) = -u_h(t)^{\\top} A^{\\top} \\left(M_{\\mathrm{l}}^{-1}\\right)^{\\top} M_{\\mathrm{l}}\\,u_h(t)\n$$\n由于双线性形式 $a_h(\\cdot, \\cdot)$ 是对称的，其对应的矩阵 $A$ 也是对称的（$A^{\\top}=A$）。此外，$(M_{\\mathrm{l}}^{-1})^{\\top} = M_{\\mathrm{l}}^{-1}$。\n$$\n\\frac{\\mathrm{d}E_{\\mathrm{l}}}{\\mathrm{d}t} = -u_h(t)^{\\top} A\\, M_{\\mathrm{l}}^{-1} M_{\\mathrm{l}}\\,u_h(t) = -u_h(t)^{\\top} A\\,u_h(t)\n$$\n这导出了与一致质量情况相同的能量恒等式：\n$$\n\\frac{\\mathrm{d}E_{\\mathrm{l}}}{\\mathrm{d}t} = -a_h(u_h, u_h)\n$$\n因此，集中质量能量不增的条件 $\\frac{\\mathrm{d}E_{\\mathrm{l}}}{\\mathrm{d}t} \\le 0$ 等价于完全相同的矫顽性要求：\n$$\na_h(u_h, u_h) \\ge 0 \\quad \\forall u_h \\in V_h\n$$\n满足此条件所需的最小罚参数 $\\sigma$ 的推导仅依赖于双线性形式 $a_h$ 和函数空间 $V_h$ 的性质（通过反不等式），而与质量矩阵无关。因此，推导过程与第 1 部分完全相同。\n这意味着在集中质量情况下，罚参数的充分下界与一致质量情况下的相同：\n$$\n\\sigma_{\\min}^{\\mathrm{lumped}} = C_{\\mathrm{inv}}p^2\n$$\n\n#### 第 3 部分：最终计算\n\n问题要求计算量 $\\Delta \\sigma_{\\min} = \\sigma_{\\min}^{\\mathrm{lumped}} - \\sigma_{\\min}^{\\mathrm{consistent}}$。使用前面部分的结果：\n$$\n\\Delta \\sigma_{\\min} = C_{\\mathrm{inv}}p^2 - C_{\\mathrm{inv}}p^2 = 0\n$$\n分析表明，对于每个系统与其“自然相关的能量”而言的半离散稳定性，对罚参数的稳定性约束与质量矩阵是一致的还是集中的无关。", "answer": "$$\\boxed{0}$$", "id": "3414296"}, {"introduction": "在掌握了理论基础之后，下一步是将其应用于实际的计算任务中。本练习要求你为一个二维扩散问题编写代码，根据单元的多项式次数、物理系数和几何形状，计算出每个面上的具体罚参数数值 [@problem_id:3414307]。通过这个实践，你将学会如何处理复杂的网格数据，并将抽象的稳定性理论转化为可执行的算法。", "problem": "要求您推导、实现并评估对称内罚伽辽金 (SIPG) 方法中内部罚参数的计算。该方法应用于二维空间中三角形网格上的标量扩散模型问题。目标是从基本原理出发，选择能确保双线性形式矫顽性的内部和边界罚参数，然后实现一个程序，在给定的网格上计算这些罚参数。\n\n您的推导基础必须限定在适用于形状正则单纯形网格上多项式空间的著名不等式和变分论证：\n- 柯西-施瓦茨不等式和杨氏不等式。\n- 针对单纯形上分片多项式函数的逐单元迹不等式，通过基于面的特征尺寸 $h_{K,F}$ 关联面范数和体范数。\n- 针对多项式空间的逐单元逆不等式。\n- 对称内罚伽辽金 (SIPG) 方法中的标准能量范数。\n\n您必须在空间维度 $d=2$ 下，在参考三角形的仿射图像（即直边三角形）上进行操作。您将使用的网格实体和数据如下：\n- $\\mathbb{R}^2$ 中带坐标的节点。\n- 具有节点连接性的三角形单元 $K$。\n- 面 $F$，作为被一个（边界）或两个（内部）三角形共享的无序节点对 $(i,j)$。\n- 每个单元 $K$ 的局部多项式次数 $p_K \\in \\mathbb{N}$。\n- 每个单元 $K$ 的逐单元常数标量扩散系数 $\\kappa_K > 0$。\n- 边界面 $F$ 上的边界条件标签：狄利克雷 ($D$) 或诺伊曼 ($N$)。\n\n根据您的基本原理推导，为罚参数选择一个可计算的下界，以确保模型扩散算子 $-\\nabla \\cdot (\\kappa \\nabla u)$（其中 $\\kappa$ 为分片常数）的 SIPG 双线性形式具有矫顽性。您的推导必须为以下必须在实现中采用的建模选择提供合理解释：\n- 三角形 $K$ 及其面 $F$ 上的基于面的尺寸 $h_{K,F}$ 必须取为 $h_{K,F} = \\dfrac{2|K|}{|F|}$，其中 $|K|$ 是 $K$ 的面积，而 $|F|$ 是面 $F$ 的欧几里得长度。\n- 依赖于维度的多项式因子必须为 $f_d(p) = (p+1)(p+d)$ 的形式，并且您必须使用 $d=2$。\n- 对于由 $K$ 和 $K'$ 共享的内部面 $F$，其上的罚参数必须与两个相邻单元贡献中的较大者成比例（其意义由您的推导证明），并与 $\\kappa$、多项式因子成正比，分别与 $h_{K,F}$ 和 $h_{K',F}$ 成反比。\n- 对于狄利克雷边界面，您的选择必须遵循与内部情况相同的缩放规律，但要通过引入一个由您的推导证明其合理性的因子来考虑边界的单边性质。\n- 对于诺伊曼边界面，不应施加任何罚参数。\n\n固定一个全局安全因子 $s$ 和一个与您的推导一致的边界单边因子。在本问题的数值评估中，您必须设置 $s=2$，并且对于狄利克雷边界面，将单边贡献乘以 $2$。\n\n您的实现应输出下述一组测试用例的罚参数。在每个测试用例中：\n- 按索引 $0,1,2,\\dots$ 枚举节点。\n- 每个三角形由一个节点索引三元组给出。\n- 每个三角形具有数据 $(p_K,\\kappa_K)$。\n- 边界面上的边界条件标签以从无序节点对 $(i,j)$ 到 $D$ 或 $N$ 的映射形式给出。\n\n在所有计算中，取 $d=2$ 和 $f_d(p)=(p+1)(p+2)$。\n\n每个测试用例的输出顺序定义：\n- 首先列出内部面，然后是边界面。\n- 在每个类别中，按其节点索引对 $(\\min(i,j),\\max(i,j))$ 的字典序对面进行排序。\n- 对于每个面，输出罚参数，格式为四舍五入到小数点后六位的浮点数。\n\n您的程序必须将所有测试用例的罚参数按下面给出的测试用例顺序连接成一个扁平列表，并以如下格式打印单行：一个用方括号括起来的逗号分隔列表，例如 $[a_1,a_2,\\dots,a_M]$。\n\n测试套件：\n\n- 测试用例 1（理想情况，中等次数，中等非均匀性）：\n    - 节点：\n        - $0:(0,0)$，$1:(1,0)$，$2:(1,1)$，$3:(0,1)$。\n    - 三角形：\n        - $K_0 = [0,1,2]$，$(p_{K_0}=1,\\ \\kappa_{K_0}=1)$，\n        - $K_1 = [0,2,3]$，$(p_{K_1}=2,\\ \\kappa_{K_1}=5)$。\n    - 边界条件：\n        - 所有边界面均为狄利克雷 ($D$)。\n- 测试用例 2（各向异性和高次数，混合边界条件）：\n    - 节点：\n        - $0:(0,0)$，$1:(0.001,0)$，$2:(0,1)$，$3:(1,0.5)$。\n    - 三角形：\n        - $K_0 = [0,1,2]$，$(p_{K_0}=5,\\ \\kappa_{K_0}=1)$，\n        - $K_1 = [0,2,3]$，$(p_{K_1}=1,\\ \\kappa_{K_1}=1)$。\n    - 边界条件：\n        - 在 $K_0$ 上：面 $(0,1)$ 为 $D$，面 $(1,2)$ 为 $D$。\n        - 在 $K_1$ 上：面 $(2,3)$ 为 $N$，面 $(0,3)$ 为 $D$。\n- 测试用例 3（强扩散对比度，相同次数，混合边界条件）：\n    - 节点：\n        - $0:(0,0)$，$1:(1,0)$，$2:(1,1)$，$3:(0,1)$。\n    - 三角形：\n        - $K_0 = [0,1,2]$，$(p_{K_0}=3,\\ \\kappa_{K_0}=10^{-3})$，\n        - $K_1 = [0,2,3]$，$(p_{K_1}=3,\\ \\kappa_{K_1}=10^{3})$。\n    - 边界条件：\n        - 在 $K_0$ 上：面 $(0,1)$ 和 $(1,2)$ 为 $D$。\n        - 在 $K_1$ 上：面 $(2,3)$ 和 $(0,3)$ 为 $N$。\n\n实现要求和约定：\n- 对于任何具有顶点 $(x_i,y_i)$、$(x_j,y_j)$、$(x_k,y_k)$ 的三角形 $K$，其面积必须计算为 $|K| = \\dfrac{1}{2} |x_i(y_j-y_k)+x_j(y_k-y_i)+x_k(y_i-y_j)|$。\n- 对于任何面 $F=(i,j)$，其欧几里得长度为 $|F| = \\sqrt{(x_i-x_j)^2+(y_i-y_j)^2}$。\n- 对于由 $K$ 和 $K'$ 共享的内部面 $F$，使用由您的推导证明其意义的来自 $K$ 和 $K'$ 的贡献。\n- 对于单元 $K$ 上的狄利克雷面 $F$，使用带有上述指定边界因子的单边贡献。\n- 对于诺伊曼面，罚参数必须为零。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含按顺序排列的测试用例 1、2 和 3 的串联罚参数，每个面罚参数四舍五入到小数点后六位，格式为用方括号括起来的逗号分隔列表，即 $[r_1,r_2,\\dots,r_M]$，其中每个 $r_m$ 是一个浮点数。\n\n不涉及物理单位；不使用角度；不使用百分比。最终输出必须完全由上述说明和指定的测试套件确定。您的实现必须是自包含的，并且不需要任何输入。", "solution": "### **罚参数的推导**\n\n目标是确保 SIPG 双线性形式的矫顽性，这为数值方法提供了稳定性。我们从扩散算子的 SIPG 双线性形式 $A_h(\\cdot, \\cdot)$ 开始，针对来自离散空间 $V_h$（分片多项式空间）的函数 $v$ 进行评估：\n$$\nA_h(v, v) = \\sum_{K \\in \\mathcal{T}_h} \\int_K \\kappa_K |\\nabla v_K|^2 d\\mathbf{x} - 2\\sum_{F \\in \\mathcal{F}_h^{\\text{all}}} \\int_F \\{\\!\\{\\kappa \\nabla v\\}\\!\\} \\cdot [v] ds + \\sum_{F \\in \\mathcal{F}_h^{\\text{all}}} \\int_F \\sigma_F |[v]|^2 ds\n$$\n其中 $\\mathcal{T}_h$ 是所有三角形单元的集合，$\\mathcal{F}_h^{\\text{all}}$ 是所有面（内部和边界）的集合。跳跃 $[v]$ 和平均 $\\{\\!\\{\\cdot\\}\\!\\}$ 算子定义如下：\n- 在由单元 $K$ 和 $K'$ 共享的内部面 $F$ 上，给定一个固定的单位法向量 $\\mathbf{n}$：\n  $[v] = v_K - v_{K'}$, 且 $\\{\\!\\{\\kappa \\nabla v\\}\\!\\} = \\frac{1}{2}(\\kappa_K \\nabla v_K + \\kappa_{K'} \\nabla v_{K'})$。\n- 在单元 $K$ 的边界面 $F$ 上，给定朝外的单位法向量 $\\mathbf{n}$：\n  $[v] = v_K$, 且 $\\{\\!\\{\\kappa \\nabla v\\}\\!\\} = \\kappa_K \\nabla v_K$。\n\n罚参数 $\\sigma_F$ 仅对内部面和狄利克雷边界面非零。根据规定，对于诺伊曼面，$\\sigma_F = 0$。\n\n矫顽性要求对于某个正常数 $C$ 和一个适当的能量范数 $|||v|||$，有 $A_h(v,v) \\ge C |||v|||^2$。$A_h(v,v)$ 中的第一项和第三项是正定的。挑战在于控制第二项（交叉项），该项不是符号确定的。我们必须用正定项来界定它。让我们分析单个面 $F$ 上的这个交叉项，记为 $T_F$：\n$$\nT_F = -2 \\int_F \\{\\!\\{\\kappa \\nabla v\\}\\!\\} \\cdot [v] ds\n$$\n\n**内部面分析**\n对于单元 $K$ 和 $K'$ 之间的内部面 $F$，我们重写 $T_F$ 并应用柯西-施瓦茨不等式：\n$$\n|T_F| = \\left| -\\int_F (\\kappa_K \\nabla v_K \\cdot \\mathbf{n})(v_K - v_{K'}) ds - \\int_F (\\kappa_{K'} \\nabla v_{K'} \\cdot \\mathbf{n})(v_K - v_{K'}) ds \\right|\n$$\n$$\n|T_F| \\le \\|\\sqrt{\\kappa_K}\\nabla v_K \\cdot \\mathbf{n}\\|_{L^2(F)} \\|\\sqrt{\\kappa_K}[v]\\|_{L^2(F)} + \\|\\sqrt{\\kappa_{K'}}\\nabla v_{K'} \\cdot \\mathbf{n}\\|_{L^2(F)} \\|\\sqrt{\\kappa_{K'}}[v]\\|_{L^2(F)}\n$$\n现在我们应用给定的迹-逆不等式框架。对于单元 $K$ 上次数为 $p$ 的多项式 $w$，以下不等式成立：\n$$\n\\|\\nabla w \\cdot \\mathbf{n}\\|_{L^2(F)}^2 \\le C_{TI} \\frac{f_d(p)}{h_{K,F}} \\|\\nabla w\\|_{L^2(K)}^2\n$$\n其中 $C_{TI}$ 是一个仅依赖于网格形状正则性的常数。应用该不等式可得：\n$$\n\\|\\sqrt{\\kappa_K}\\nabla v_K \\cdot \\mathbf{n}\\|_{L^2(F)} \\le \\sqrt{C_{TI} \\kappa_K \\frac{f_d(p_K)}{h_{K,F}}} \\|\\nabla v_K\\|_{L^2(K)} = \\sqrt{C_{TI} \\frac{f_d(p_K)}{h_{K,F}}} \\|\\sqrt{\\kappa_K}\\nabla v_K\\|_{L^2(K)}\n$$\n将此结果代入 $|T_F|$ 的界，并对两个乘积项中的每一项应用杨氏不等式（$ab \\le \\frac{\\epsilon}{2} a^2 + \\frac{1}{2\\epsilon} b^2$）：\n$$\n|T_F| \\le \\frac{\\epsilon_K}{2} \\left( C_{TI} \\frac{f_d(p_K)}{h_{K,F}} \\right) \\|\\sqrt{\\kappa_K}\\nabla v_K\\|_{L^2(K)}^2 + \\frac{1}{2\\epsilon_K} \\|\\sqrt{\\kappa_K}[v]\\|_{L^2(F)}^2 \\\\\n+ \\frac{\\epsilon_{K'}}{2} \\left( C_{TI} \\frac{f_d(p_{K'})}{h_{K',F}} \\right) \\|\\sqrt{\\kappa_{K'}}\\nabla v_{K'}\\|_{L^2(K')}^2 + \\frac{1}{2\\epsilon_{K'}} \\|\\sqrt{\\kappa_{K'}}[v]\\|_{L^2(F)}^2\n$$\n通过选择足够小的参数 $\\epsilon_K$ 和 $\\epsilon_{K'}$，涉及 $\\|\\sqrt{\\kappa}\\nabla v\\|_{L^2(K)}^2$ 的项可以被 $A_h(v,v)$ 中的正体积项 $\\sum_K \\int_K \\kappa_K |\\nabla v_K|^2 d\\mathbf{x}$ 吸收，为其矫顽性留下一部分。对于涉及跳跃 $[v]$ 的剩余项，我们要求罚分项能够控制它们：\n$$\n\\int_F \\sigma_F |[v]|^2 ds > \\frac{1}{2\\epsilon_K} \\int_F \\kappa_K |[v]|^2 ds + \\frac{1}{2\\epsilon_{K'}} \\int_F \\kappa_{K'} |[v]|^2 ds\n$$\n这导出了罚参数的一个充分条件：\n$$\n\\sigma_F > \\frac{\\kappa_K}{2\\epsilon_K} + \\frac{\\kappa_{K'}}{2\\epsilon_{K'}}\n$$\n$\\epsilon_k$ 的选择取决于用多少体积能量项来控制通量。标准分析表明，这导致一个形式如下的下界：\n$$\n\\sigma_F > C \\left( \\kappa_K \\frac{f_d(p_K)}{h_{K,F}} + \\kappa_{K'} \\frac{f_d(p_{K'})}{h_{K',F}} \\right)\n$$\n其中 $C$ 是一个包含 $C_{TI}$ 和其他因素的常数。一个常见、实用且充分的选择是取两个贡献中的最大值，而不是它们的和，前提是使用足够大的安全因子。这与问题陈述一致。我们将单元 $K$ 对面 $F$ 上罚参数的单元贡献定义为 $\\sigma_{F,K} = \\dfrac{\\kappa_K f_d(p_K)}{h_{K,F}}$。那么内部面 $F$ 上的罚参数为：\n$$\n\\sigma_F = s \\cdot \\max(\\sigma_{F,K}, \\sigma_{F,K'})\n$$\n给定安全因子 $s=2$ 和 $f_d(p)=(p+1)(p+2)$，该式变为：\n$$\n\\sigma_F = 2 \\cdot \\max\\left(\\frac{\\kappa_K (p_K+1)(p_K+2)}{h_{K,F}}, \\frac{\\kappa_{K'} (p_{K'}+1)(p_{K'}+2)}{h_{K',F}}\\right)\n$$\n\n**边界面分析**\n对于单元 $K$ 上的狄利克雷边界面 $F$，分析是单边的。交叉项为 $T_F = -2 \\int_F (\\kappa_K \\nabla v_K \\cdot \\mathbf{n}) v_K ds$。同样的不等式链导出一个条件：\n$$\n\\sigma_F > C' \\frac{\\kappa_K f_d(p_K)}{h_{K,F}}\n$$\n问题规定，对于狄利克雷面，除了安全因子 $s=2$ 外，还必须使用一个为 $2$ 的边界因子。这是确保稳定性的常见做法，有时源于边界面和内部面的迹常数不同。\n$$\n\\sigma_F = s \\cdot 2 \\cdot \\frac{\\kappa_K (p_K+1)(p_K+2)}{h_{K,F}} = 4 \\cdot \\frac{\\kappa_K (p_K+1)(p_K+2)}{h_{K,F}}\n$$\n对于诺伊曼边界面，问题陈述其罚参数为零（$\\sigma_F = 0$），这是标准做法，因为这些边界条件是通过相应的线性形式弱施加的，而不是通过罚分项。\n\n**可计算公式总结**\n- 对于 $K$ 和 $K'$ 之间的内部面 $F$：\n  $ \\sigma_F = 2 \\cdot \\max\\left(\\dfrac{\\kappa_K (p_K+1)(p_K+2)}{h_{K,F}}, \\dfrac{\\kappa_{K'} (p_{K'}+1)(p_{K'}+2)}{h_{K',F}}\\right)$\n- 对于单元 $K$ 上的狄利克雷边界面 $F$：\n  $ \\sigma_F = 4 \\cdot \\dfrac{\\kappa_K (p_K+1)(p_K+2)}{h_{K,F}} $\n- 对于诺伊曼边界面 $F$：\n  $ \\sigma_F = 0 $\n\n这些公式用于下面的实现。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the computation of SIPG penalty parameters\n    for a suite of test cases and print the final result.\n    \"\"\"\n    \n    s = 2.0  # Global safety factor\n    d = 2    # Spatial dimension\n\n    # ========= Test Case 1 =========\n    nodes_1 = {\n        0: np.array([0.0, 0.0]), 1: np.array([1.0, 0.0]),\n        2: np.array([1.0, 1.0]), 3: np.array([0.0, 1.0])\n    }\n    triangles_1 = [\n        ([0, 1, 2], (1, 1.0)), \n        ([0, 2, 3], (2, 5.0))\n    ]\n    bcs_1 = {\n        tuple(sorted((0, 1))): 'D', tuple(sorted((1, 2))): 'D',\n        tuple(sorted((2, 3))): 'D', tuple(sorted((0, 3))): 'D'\n    }\n\n    # ========= Test Case 2 =========\n    nodes_2 = {\n        0: np.array([0.0, 0.0]), 1: np.array([0.001, 0.0]),\n        2: np.array([0.0, 1.0]), 3: np.array([1.0, 0.5])\n    }\n    triangles_2 = [\n        ([0, 1, 2], (5, 1.0)), \n        ([0, 2, 3], (1, 1.0))\n    ]\n    bcs_2 = {\n        tuple(sorted((0, 1))): 'D', tuple(sorted((1, 2))): 'D',\n        tuple(sorted((2, 3))): 'N', tuple(sorted((0, 3))): 'D'\n    }\n\n    # ========= Test Case 3 =========\n    nodes_3 = {\n        0: np.array([0.0, 0.0]), 1: np.array([1.0, 0.0]),\n        2: np.array([1.0, 1.0]), 3: np.array([0.0, 1.0])\n    }\n    triangles_3 = [\n        ([0, 1, 2], (3, 1e-3)), \n        ([0, 2, 3], (3, 1e3))\n    ]\n    bcs_3 = {\n        tuple(sorted((0, 1))): 'D', tuple(sorted((1, 2))): 'D',\n        tuple(sorted((2, 3))): 'N', tuple(sorted((0, 3))): 'N'\n    }\n\n    test_cases = [\n        (nodes_1, triangles_1, bcs_1),\n        (nodes_2, triangles_2, bcs_2),\n        (nodes_3, triangles_3, bcs_3)\n    ]\n\n    all_penalties = []\n    for nodes, triangles_data, boundary_conditions in test_cases:\n        penalties = compute_penalties_for_case(nodes, triangles_data, boundary_conditions, s, d)\n        all_penalties.extend(penalties)\n    \n    # Format and print the final output as a single line.\n    formatted_penalties = [f\"{p:.6f}\" for p in all_penalties]\n    print(f\"[{','.join(formatted_penalties)}]\")\n\ndef get_triangle_area(p1, p2, p3):\n    \"\"\"Computes the area of a triangle given its three vertex coordinates.\"\"\"\n    return 0.5 * abs(p1[0]*(p2[1]-p3[1]) + p2[0]*(p3[1]-p1[1]) + p3[0]*(p1[1]-p2[1]))\n\ndef get_edge_length(p1, p2):\n    \"\"\"Computes the Euclidean length of an edge.\"\"\"\n    return np.linalg.norm(p1 - p2)\n\ndef get_poly_factor(p, d):\n    \"\"\"Computes the dimension-dependent polynomial factor.\"\"\"\n    return float((p + 1) * (p + d))\n\ndef compute_penalties_for_case(nodes, triangles_data, boundary_conditions, s, d):\n    \"\"\"\n    Computes penalty parameters for a single test case.\n    \"\"\"\n    face_to_elements = {}\n    for i, (tri_nodes, _) in enumerate(triangles_data):\n        # A triangle is defined by 3 faces (edges)\n        faces = [\n            (tri_nodes[0], tri_nodes[1]),\n            (tri_nodes[1], tri_nodes[2]),\n            (tri_nodes[2], tri_nodes[0])\n        ]\n        for face in faces:\n            # Use a canonical representation for the face (sorted node indices)\n            canonical_face = tuple(sorted(face))\n            if canonical_face not in face_to_elements:\n                face_to_elements[canonical_face] = []\n            face_to_elements[canonical_face].append(i)\n\n    interior_faces = []\n    boundary_faces_map = {} # Maps face to its boundary type, e.g. D or N\n\n    for face, elems in face_to_elements.items():\n        if len(elems) == 2:\n            interior_faces.append(face)\n        else:\n            bc_type = boundary_conditions.get(face)\n            if bc_type is None:\n                raise ValueError(f\"Boundary condition for face {face} not specified.\")\n            boundary_faces_map[face] = bc_type\n    \n    # Sort faces lexicographically as per problem specification.\n    interior_faces.sort()\n    sorted_boundary_faces = sorted(boundary_faces_map.keys())\n    \n    face_penalties = []\n    \n    # Process interior faces\n    for face in interior_faces:\n        elem_idx1, elem_idx2 = face_to_elements[face]\n        \n        elem1_nodes, (p1, k1) = triangles_data[elem_idx1]\n        elem2_nodes, (p2, k2) = triangles_data[elem_idx2]\n        \n        face_p_coords = (nodes[face[0]], nodes[face[1]])\n        face_len = get_edge_length(*face_p_coords)\n        \n        # Contribution from element 1\n        elem1_vtx_coords = [nodes[i] for i in elem1_nodes]\n        area1 = get_triangle_area(*elem1_vtx_coords)\n        h_K1_F = (2.0 * area1 / face_len) if face_len > 0 else float('inf')\n        contrib1 = k1 * get_poly_factor(p1, d) / h_K1_F\n        \n        # Contribution from element 2\n        elem2_vtx_coords = [nodes[i] for i in elem2_nodes]\n        area2 = get_triangle_area(*elem2_vtx_coords)\n        h_K2_F = (2.0 * area2 / face_len) if face_len > 0 else float('inf')\n        contrib2 = k2 * get_poly_factor(p2, d) / h_K2_F\n        \n        penalty = s * max(contrib1, contrib2)\n        face_penalties.append(penalty)\n\n    # Process boundary faces\n    for face in sorted_boundary_faces:\n        bc_type = boundary_faces_map[face]\n        \n        if bc_type == 'N':\n            penalty = 0.0\n        elif bc_type == 'D':\n            elem_idx = face_to_elements[face][0]\n            elem_nodes, (p, k) = triangles_data[elem_idx]\n            \n            face_p_coords = (nodes[face[0]], nodes[face[1]])\n            face_len = get_edge_length(*face_p_coords)\n            \n            elem_vtx_coords = [nodes[i] for i in elem_nodes]\n            area = get_triangle_area(*elem_vtx_coords)\n            h_K_F = (2.0 * area / face_len) if face_len > 0 else float('inf')\n            \n            contrib = k * get_poly_factor(p, d) / h_K_F\n            # Per problem, multiply by a boundary factor of 2.\n            penalty = s * 2.0 * contrib\n        else:\n            raise ValueError(f\"Unknown boundary condition type '{bc_type}' for face {face}\")\n            \n        face_penalties.append(penalty)\n        \n    return face_penalties\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3414307"}, {"introduction": "满足稳定性要求仅仅是选择罚参数的第一步，一个“好”的罚参数还应有助于提升求解效率。本练习引入了一个高级主题：如何通过优化方法自动调节罚参数，以在保证稳定性的前提下最小化非线性求解器的迭代次数 [@problem_id:3414310]。这个问题将带你探索一个结合了数值分析与机器学习思想的前沿方法，理解罚参数选择对整体计算性能的深远影响。", "problem": "考虑用于标量、可能是非线性的扩散算子的对称内罚不连续Galerkin方法（SIPDG），其中内部面由一个罚参数来稳定。设面 $f$ 上的罚参数表示为 $\\sigma_f$。基于迹逆不等式和多项式逆估计的经典矫顽性分析表明，存在一个逐面的下界，形式为 $\\sigma_f \\ge C_f(p,h)$，其中 $C_f(p,h)$ 的尺度为一个正常数乘以 $p^2/h_f$ 再乘以一个依赖于面的形状因子。具体来说，假设每个面 $f$ 上的解析界由以下公式给出：\n$$\nC_f(p,h) \\;=\\; c_0 \\, \\frac{p(p+1)}{h_f}\\, \\theta_f,\n$$\n其中 $c_0>0$ 是用户选择的常数，$p$ 是多项式次数，$h_f$ 是面局部网格尺寸，$\\theta_f$ 是形状因子。\n\n在许多非线性求解器中（例如，带有Krylov子求解的非精确Newton法），迭代次数根据经验与稳定化算子的条件数相关。对于对称内罚，该条件数在 $\\sigma_f$ 中表现出一种权衡：过小的 $\\sigma_f$ 会导致一致性引发的病态，而过大的 $\\sigma_f$ 会导致刚度引发的病态。为了作为迭代负担的光滑代理目标，定义每个面的贡献为\n$$\n\\kappa_f(\\sigma_f) \\;=\\; a_f \\,\\frac{\\sigma_f}{C_f(p,h)} \\;+\\; b_f \\,\\frac{C_f(p,h)}{\\sigma_f},\n$$\n其中 $a_f>0$ 和 $b_f>0$ 是给定的逐面灵敏度系数。对所有内部面进行聚合，得到全局代理\n$$\n\\mathcal{K}(\\boldsymbol{\\sigma}) \\;=\\; \\sum_{f} \\kappa_f(\\sigma_f).\n$$\n通过以下方式将 $\\mathcal{K}$ 映射到预测的非线性求解迭代次数：\n$$\nN(\\boldsymbol{\\sigma}) \\;=\\; \\left\\lceil \\gamma_0 \\;+\\; \\gamma_1 \\,\\sqrt{\\mathcal{K}(\\boldsymbol{\\sigma})}\\right\\rceil,\n$$\n其中 $\\gamma_0>0$ 和 $\\gamma_1>0$ 是给定常数。\n\n您的任务是实现一个强化学习调优过程，该过程为每个面选择一个罚参数 $\\sigma_f\\ge C_f(p,h)$，以最小化 $N(\\boldsymbol{\\sigma})$，同时严格执行解析约束 $\\sigma_f \\ge C_f(p,h)$。对逐面的比率使用确定性策略梯度更新\n$$\nr_f \\;=\\; \\frac{\\sigma_f}{C_f(p,h)} \\;\\;\\text{with}\\;\\; r_f \\ge 1,\n$$\n通过重参数化\n$$\nr_f(y_f) \\;=\\; 1 \\;+\\; \\log\\!\\big(1+\\exp(y_f)\\big),\n$$\n使得对于所有实数 $y_f$ 都有 $r_f(y_f) > 1$，并且当 $y_f\\to -\\infty$ 时 $r_f(y_f)\\to 1$。将所有面的 $y_f$ 初始化为0，并对光滑代理执行 $T$ 次无投影的梯度步\n$$\nJ(\\mathbf{y}) \\;=\\; \\sum_f \\left(a_f\\, r_f(y_f) \\;+\\; \\frac{b_f}{r_f(y_f)}\\right),\n$$\n使用精确梯度\n$$\n\\frac{\\partial J}{\\partial y_f} \\;=\\; \\left(a_f \\;-\\; \\frac{b_f}{r_f(y_f)^2}\\right)\\,\\frac{d r_f}{d y_f}, \n\\quad \\text{with} \\quad \\frac{d r_f}{d y_f} \\;=\\; \\frac{1}{1+\\exp(-y_f)},\n$$\n以及一个递减的步长\n$$\n\\eta_t \\;=\\; \\frac{\\eta_0}{\\sqrt{t+1}}, \\quad t \\in \\{0,1,\\dots,T-1\\}.\n$$\n经过 $T$ 步后，将学习到的策略定义为 $\\sigma_f^{\\mathrm{RL}} = r_f(y_f^{(T)})\\, C_f(p,h)$。作为基准解析策略，使用下界本身，即对所有面都有 $\\sigma_f^{\\mathrm{base}} = C_f(p,h)$。为了与代理的解析约束最优解进行比较，还应考虑逐面的比率\n$$\nr_f^{\\star} \\;=\\; \\max\\!\\left(1, \\sqrt{\\frac{b_f}{a_f}}\\right),\n$$\n并将学习到的比率与 $r_f^{\\star}$ 之间的均方根相对误差定义为\n$$\n\\varepsilon_{\\mathrm{RMS}} \\;=\\; \\sqrt{\\frac{1}{F} \\sum_{f=1}^{F} \\left(\\frac{r_f^{\\mathrm{RL}} - r_f^{\\star}}{r_f^{\\star}}\\right)^2},\n$$\n其中 $F$ 是面的数量。如果 $\\varepsilon_{\\mathrm{RMS}} \\le \\tau$，则声明学习到的策略“在容差范围内”，其中给定的 $\\tau \\in (0,1)$ 以小数形式表示。\n\n实现上述方法，并在以下测试套件上进行评估。在所有情况下，使用 $c_0 = 4.0$, $\\gamma_0 = 3.0$, $\\gamma_1 = 2.0$, $T = 1000$, $\\eta_0 = 0.5$ 和容差 $\\tau = 0.05$。\n\n- 测试用例 1：\n  - 多项式次数 $p = 2$。\n  - 面局部尺寸 $[h_f] = [0.5, 0.5, 0.5]$。\n  - 形状因子 $[\\theta_f] = [1.0, 1.2, 0.8]$。\n  - 灵敏度 $[a_f] = [1.0, 1.5, 0.7]$，$[b_f] = [1.0, 0.5, 1.3]$。\n\n- 测试用例 2：\n  - 多项式次数 $p = 4$。\n  - 面局部尺寸 $[h_f] = [0.2]$。\n  - 形状因子 $[\\theta_f] = [1.0]$。\n  - 灵敏度 $[a_f] = [0.4]$，$[b_f] = [2.5]$。\n\n- 测试用例 3：\n  - 多项式次数 $p = 1$。\n  - 面局部尺寸 $[h_f] = [0.3, 0.1]$。\n  - 形状因子 $[\\theta_f] = [1.0, 1.0]$。\n  - 灵敏度 $[a_f] = [0.8, 0.8]$，$[b_f] = [0.8, 0.1]$。\n\n对于每个测试用例，您的程序必须计算并返回一个列表\n$$\n\\big[\\, N(\\boldsymbol{\\sigma}^{\\mathrm{RL}}),\\; N(\\boldsymbol{\\sigma}^{\\mathrm{base}}),\\; \\text{constraint\\_ok},\\; \\overline{r}^{\\mathrm{RL}},\\; \\overline{r}^{\\mathrm{base}},\\; \\text{within\\_tolerance}\\,\\big],\n$$\n其中 $N(\\cdot)$ 是预测的迭代次数，$\\text{constraint\\_ok}$ 是一个布尔值，指示所有面是否满足 $\\sigma_f^{\\mathrm{RL}} \\ge C_f(p,h)$，$\\overline{r}^{\\mathrm{RL}}$ 是学习到的比率 $r_f^{\\mathrm{RL}}$ 的算术平均值，$\\overline{r}^{\\mathrm{base}}$ 是基准比率的算术平均值（等于 $1.0$），而 $\\text{within\\_tolerance}$ 是由条件 $\\varepsilon_{\\mathrm{RMS}} \\le \\tau$ 定义的布尔值。所有迭代次数必须是整数；平均值必须作为浮点数返回。容差 $\\tau$ 必须用小数表示（而不是百分号）。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素按顺序对应一个测试用例，并且每个测试用例元素本身就是如上所述的列表。例如，打印的结构必须是以下形式\n$$\n\\big[\\,[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],\\;[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],\\;[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot]\\,\\big].\n$$\n此问题中不出现角度或物理单位；因此，不需要进行角度或单位转换。您的程序不得读取任何输入，并且必须按规定计算给定测试套件的结果。", "solution": "用户提供了一个在偏微分方程数值分析领域中定义明确的计算问题，具体涉及对称内罚不连续Galerkin（SIPDG）方法中罚参数的优化。对问题陈述进行细致的验证是首要且最关键的步骤。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n问题提供了以下数据和定义：\n-   **方法背景**：对称内罚不连续Galerkin（SIPDG）。\n-   **解析罚参数下界**：面 $f$ 上的罚参数 $\\sigma_f$ 的下界是 $C_f(p,h) = c_0 \\frac{p(p+1)}{h_f} \\theta_f$。\n-   **约束**：罚参数必须满足 $\\sigma_f \\ge C_f(p,h)$。\n-   **代理目标（逐面）**：$\\kappa_f(\\sigma_f) = a_f \\frac{\\sigma_f}{C_f(p,h)} + b_f \\frac{C_f(p,h)}{\\sigma_f}$。\n-   **代理目标（全局）**：$\\mathcal{K}(\\boldsymbol{\\sigma}) = \\sum_{f} \\kappa_f(\\sigma_f)$。\n-   **预测迭代次数**：$N(\\boldsymbol{\\sigma}) = \\lceil \\gamma_0 + \\gamma_1 \\sqrt{\\mathcal{K}(\\boldsymbol{\\sigma})}\\rceil$。\n-   **优化目标**：在约束条件下最小化 $N(\\boldsymbol{\\sigma})$。\n-   **优化变量**：比率 $r_f = \\frac{\\sigma_f}{C_f(p,h)} \\ge 1$。\n-   **重参数化**：$r_f(y_f) = 1 + \\log(1+\\exp(y_f))$，其中 $y_f \\in \\mathbb{R}$ 是可学习的参数。\n-   **优化算法**：对光滑代理 $J(\\mathbf{y}) = \\sum_f (a_f r_f(y_f) + \\frac{b_f}{r_f(y_f)})$ 进行梯度下降。\n-   **初始化**：所有面的 $y_f^{(0)} = 0$。\n-   **梯度**：$\\frac{\\partial J}{\\partial y_f} = (a_f - \\frac{b_f}{r_f(y_f)^2}) \\frac{dr_f}{dy_f}$，其中 $\\frac{dr_f}{dy_f} = \\frac{1}{1+\\exp(-y_f)}$。\n-   **步长调度**：$\\eta_t = \\frac{\\eta_0}{\\sqrt{t+1}}$，对于 $t \\in \\{0,1,\\dots,T-1\\}$。\n-   **学习到的策略**：$\\sigma_f^{\\mathrm{RL}} = r_f(y_f^{(T)}) C_f(p,h)$。\n-   **基准策略**：$\\sigma_f^{\\mathrm{base}} = C_f(p,h)$，这意味着 $r_f^{\\mathrm{base}}=1$。\n-   **解析最优解**：代理的约束最优解出现在比率 $r_f^{\\star} = \\max(1, \\sqrt{b_f/a_f})$ 处。\n-   **误差度量**：$\\varepsilon_{\\mathrm{RMS}} = \\sqrt{\\frac{1}{F} \\sum_{f=1}^{F} (\\frac{r_f^{\\mathrm{RL}} - r_f^{\\star}}{r_f^{\\star}})^2}$。\n-   **容差条件**：$\\varepsilon_{\\mathrm{RMS}} \\le \\tau$。\n-   **全局常数**：$c_0 = 4.0$, $\\gamma_0 = 3.0$, $\\gamma_1 = 2.0$, $T = 1000$, $\\eta_0 = 0.5$, $\\tau = 0.05$。\n-   **测试用例**：三个不同的测试用例，指定了 $p$, $[h_f]$, $[\\theta_f]$, $[a_f]$ 和 $[b_f]$ 的值。\n-   **要求输出**：对于每个用例，一个列表 $[N(\\boldsymbol{\\sigma}^{\\mathrm{RL}}), N(\\boldsymbol{\\sigma}^{\\mathrm{base}}), \\text{constraint\\_ok}, \\overline{r}^{\\mathrm{RL}}, \\overline{r}^{\\mathrm{base}}, \\text{within\\_tolerance}]$，具有指定的类型（整数、布尔值、浮点数）。\n\n**步骤2：使用提取的已知条件进行验证**\n\n根据既定的验证标准对问题进行评估：\n-   **科学基础**：该问题牢固植根于DG方法的数值分析。罚参数的使用、$p^2/h_f$ 形式的解析下界 $C_f(p,h)$、平衡不同病态来源的概念，以及基于梯度的优化，都是该领域的标准且有效的方法。重参数化 $r_f(y_f) = 1 + \\log(1+\\exp(y_f))$ 是一种常见且数学上合理的技巧（一个移位的softplus函数），用于强制执行 $r_f > 1$ 的约束。所提供的梯度公式通过链式法则推导是正确的。\n-   **适定性**：任务是执行一个完全指定的算法。对于给定的输入集，该算法——具有确定的起点、迭代次数、学习率调度和目标函数的梯度下降——会产生一个确定性的、唯一的输出。因此，该问题是适定的。\n-   **客观性**：该问题完全由数学方程、数值常数和算法步骤定义。它没有任何主观或模糊的语言。\n-   **缺陷清单**：该问题没有表现出任何列出的缺陷。它在数学上是一致的，计算上是可验证的，并且包含了继续进行所需的所有信息。解析最优比率 $r_f^\\star$ 的推导也是正确的：$f(r) = ar + b/r$ 的无约束最小值在 $r=\\sqrt{b/a}$ 处，因此对于 $r \\ge 1$ 的最小值是 $\\max(1, \\sqrt{b/a})$。\n\n**步骤3：结论与行动**\n\n问题陈述是有效的。它是一个严谨且自洽的计算任务。我们可以着手开发解决方案。\n\n### 解决方案\n\n解决方案涉及为每个测试用例实现指定的受强化学习启发的优化过程，并计算一组指定的指标。每个测试用例的总体流程如下。\n\n**1. 初始化和预计算**\n首先，我们定义全局常数：$c_0 = 4.0$, $\\gamma_0 = 3.0$, $\\gamma_1 = 2.0$, $T = 1000$, $\\eta_0 = 0.5$ 和 $\\tau = 0.05$。对于给定的测试用例，其多项式次数为 $p$，逐面数据为 $h_f$, $\\theta_f$, $a_f$ 和 $b_f$，我们将这些列表转换为数值数组以进行高效计算。面的数量 $F$ 是这些数组的长度。\n然后我们计算罚参数的逐面解析下界：\n$$\nC_f = c_0 \\frac{p(p+1)}{h_f} \\theta_f \\quad \\text{对于每个面 } f=1, \\dots, F.\n$$\n\n**2. 基于梯度的优化**\n该过程的核心是梯度下降算法，以最小化光滑代理目标函数 $J(\\mathbf{y})$。可学习的参数是实值变量 $\\mathbf{y} = [y_1, \\dots, y_F]$，它们被初始化为零：$y_f^{(0)} = 0$ 对所有 $f$。\n\n优化过程进行 $T=1000$ 次迭代。在每次迭代 $t \\in \\{0, 1, \\dots, T-1\\}$ 中：\na.  使用重参数化函数从 $y_f^{(t)}$ 计算当前比率 $r_f^{(t)}$：\n    $$\n    r_f^{(t)} = r_f(y_f^{(t)}) = 1 + \\log(1+\\exp(y_f^{(t)})).\n    $$\n    这是通过使用一个数值稳定的 `logaddexp` 函数来实现的，该函数计算 $\\log(\\exp(x) + \\exp(y))$，因此 $\\log(1+\\exp(y_f)) = \\log(\\exp(0) + \\exp(y_f)) = \\text{logaddexp}(0, y_f)$。\n\nb.  计算重参数化对 $y_f$ 的导数：\n    $$\n    \\frac{dr_f}{dy_f} = \\frac{1}{1+\\exp(-y_f^{(t)})}.\n    $$\n    这是sigmoid函数，其值界于0和1之间。\n\nc.  计算目标 $J$ 对每个 $y_f$ 的梯度：\n    $$\n    \\frac{\\partial J}{\\partial y_f}\\bigg|_{t} = \\left(a_f - \\frac{b_f}{(r_f^{(t)})^2}\\right) \\frac{dr_f}{dy_f}.\n    $$\n\nd.  通过递减调度确定当前步的学习率：\n    $$\n    \\eta_t = \\frac{\\eta_0}{\\sqrt{t+1}}.\n    $$\n\ne.  使用梯度下降规则更新参数：\n    $$\n    y_f^{(t+1)} = y_f^{(t)} - \\eta_t \\frac{\\partial J}{\\partial y_f}\\bigg|_{t}.\n    $$\n\n**3. 学习到的策略指标的计算**\n经过 $T$ 次迭代后，最终参数 $y_f^{(T)}$ 定义了学习到的策略。\n-   最终学习到的比率为 $r_f^{\\mathrm{RL}} = r_f(y_f^{(T)})$。\n-   学习到的策略的全局代理目标值为 $\\mathcal{K}(\\boldsymbol{\\sigma}^{\\mathrm{RL}}) = \\sum_f (a_f r_f^{\\mathrm{RL}} + b_f/r_f^{\\mathrm{RL}})$。\n-   预测的迭代次数为 $N(\\boldsymbol{\\sigma}^{\\mathrm{RL}}) = \\lceil \\gamma_0 + \\gamma_1 \\sqrt{\\mathcal{K}(\\boldsymbol{\\sigma}^{\\mathrm{RL}})} \\rceil$。\n-   学习到的比率的算术平均值为 $\\overline{r}^{\\mathrm{RL}} = \\frac{1}{F} \\sum_f r_f^{\\mathrm{RL}}$。\n\n**4. 基准策略指标的计算**\n基准策略使用最小罚参数 $\\sigma_f^{\\mathrm{base}} = C_f(p,h)$，这对应于所有面的 $r_f^{\\mathrm{base}} = 1$。\n-   基准的全局代理为 $\\mathcal{K}(\\boldsymbol{\\sigma}^{\\mathrm{base}}) = \\sum_f (a_f \\cdot 1 + b_f/1) = \\sum_f (a_f+b_f)$。\n-   预测的基准迭代次数为 $N(\\boldsymbol{\\sigma}^{\\mathrm{base}}) = \\lceil \\gamma_0 + \\gamma_1 \\sqrt{\\mathcal{K}(\\boldsymbol{\\sigma}^{\\mathrm{base}})} \\rceil$。\n-   平均基准比率显然为 $\\overline{r}^{\\mathrm{base}} = 1.0$。\n\n**5. 评估和比较**\n将学习到的策略的性能与解析最优解和指定约束进行评估。\n-   约束 $\\sigma_f^{\\mathrm{RL}} \\ge C_f(p,h)$ 等价于 $r_f^{\\mathrm{RL}} \\ge 1$。重参数化 $r_f(y_f) = 1 + \\log(1+\\exp(y_f))$ 保证了对于任何有限的 $y_f \\in \\mathbb{R}$ 都有 $r_f(y_f) > 1$。因此，`constraint_ok` 根据构造恒为 `True`。\n-   解析最优比率为 $r_f^{\\star} = \\max(1, \\sqrt{b_f/a_f})$。\n-   计算学习到的比率 $r_f^{\\mathrm{RL}}$ 和最优比率 $r_f^\\star$ 之间的均方根相对误差 $\\varepsilon_{\\mathrm{RMS}}$。\n-   如果 $\\varepsilon_{\\mathrm{RMS}} \\le \\tau$，则将 `within_tolerance` 标志设置为 `True`，否则为 `False`。\n\n最后，对于每个测试用例，将计算出的结果组装成指定的列表格式：$[N(\\boldsymbol{\\sigma}^{\\mathrm{RL}}), N(\\boldsymbol{\\sigma}^{\\mathrm{base}}), \\text{constraint\\_ok}, \\overline{r}^{\\mathrm{RL}}, \\overline{r}^{\\mathrm{base}}, \\text{within\\_tolerance}]$，并且所有测试用例的结果被聚合成一个最终的列表的列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    \n    # Define the global constants from the problem statement.\n    C0 = 4.0\n    GAMMA0 = 3.0\n    GAMMA1 = 2.0\n    T = 1000\n    ETA0 = 0.5\n    TAU = 0.05\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"p\": 2,\n            \"h_f\": [0.5, 0.5, 0.5],\n            \"theta_f\": [1.0, 1.2, 0.8],\n            \"a_f\": [1.0, 1.5, 0.7],\n            \"b_f\": [1.0, 0.5, 1.3],\n        },\n        {\n            \"p\": 4,\n            \"h_f\": [0.2],\n            \"theta_f\": [1.0],\n            \"a_f\": [0.4],\n            \"b_f\": [2.5],\n        },\n        {\n            \"p\": 1,\n            \"h_f\": [0.3, 0.1],\n            \"theta_f\": [1.0, 1.0],\n            \"a_f\": [0.8, 0.8],\n            \"b_f\": [0.8, 0.1],\n        },\n    ]\n\n    def process_case(p, h_f, theta_f, a_f, b_f):\n        \"\"\"\n        Processes a single test case according to the problem description.\n        \"\"\"\n        # Convert input lists to numpy arrays for vectorized operations.\n        h_f = np.array(h_f, dtype=float)\n        theta_f = np.array(theta_f, dtype=float)\n        a_f = np.array(a_f, dtype=float)\n        b_f = np.array(b_f, dtype=float)\n        num_faces = len(h_f)\n\n        # Initialize the learnable parameters y_f to zero.\n        y_f = np.zeros(num_faces)\n\n        # Perform T gradient descent steps.\n        for t in range(T):\n            # Compute current ratios r_f using the reparameterization.\n            # r_f = 1 + log(1 + exp(y_f)) is computed via numerically stable logaddexp.\n            r_f = 1.0 + np.logaddexp(0, y_f)\n\n            # Compute the derivative of the reparameterization (sigmoid function).\n            # dr/dy = 1 / (1 + exp(-y_f))\n            dr_dy = 1.0 / (1.0 + np.exp(-y_f))\n\n            # Compute the gradient of the surrogate objective J w.r.t. y_f.\n            grad_J = (a_f - b_f / (r_f**2)) * dr_dy\n\n            # Compute the diminishing step size.\n            eta_t = ETA0 / math.sqrt(t + 1)\n\n            # Update the parameters y_f.\n            y_f -= eta_t * grad_J\n\n        # After T steps, compute the final learned ratios.\n        r_f_RL = 1.0 + np.logaddexp(0, y_f)\n\n        # --- Calculate required output metrics ---\n\n        # 1. Predicted iteration count for the learned (RL) policy.\n        K_RL = np.sum(a_f * r_f_RL + b_f / r_f_RL)\n        N_RL = int(math.ceil(GAMMA0 + GAMMA1 * math.sqrt(K_RL)))\n\n        # 2. Predicted iteration count for the baseline policy (r_f = 1).\n        K_base = np.sum(a_f + b_f)\n        N_base = int(math.ceil(GAMMA0 + GAMMA1 * math.sqrt(K_base)))\n\n        # 3. Check if the analytical constraint sigma_f >= C_f(p,h) holds.\n        # This is equivalent to r_f >= 1. The reparameterization guarantees r_f > 1.\n        constraint_ok = bool(np.all(r_f_RL >= 1.0))\n\n        # 4. Arithmetic mean of the learned ratios.\n        r_bar_RL = np.mean(r_f_RL)\n\n        # 5. Arithmetic mean of the baseline ratios (always 1.0).\n        r_bar_base = 1.0\n\n        # 6. Check if the learned policy is within the specified tolerance.\n        # Compute analytical optimum ratios r_f_star.\n        r_f_star = np.maximum(1.0, np.sqrt(b_f / a_f))\n        \n        # Compute RMS relative error.\n        relative_error_sq = ((r_f_RL - r_f_star) / r_f_star)**2\n        rms_error = np.sqrt(np.mean(relative_error_sq))\n        within_tolerance = bool(rms_error = TAU)\n        \n        return [N_RL, N_base, constraint_ok, r_bar_RL, r_bar_base, within_tolerance]\n\n    all_results = []\n    for case_data in test_cases:\n        result = process_case(**case_data)\n        all_results.append(result)\n\n    # The final output must be a string representation of a list of lists\n    # with no whitespace, e.g., [[val1,val2],[val3,val4]].\n    final_output_string = str(all_results).replace(\" \", \"\")\n    print(final_output_string)\n\nsolve()\n```", "id": "3414310"}]}