{"hands_on_practices": [{"introduction": "高维问题，例如多维偏微分方程的数值解，面临着“维度灾难”——其存储需求会随着维度的增加呈指数级增长。张量链（Tensor Train, TT）分解通过利用解的内在低秩结构，为这一挑战提供了有效的解决方案。本练习将通过直接计算和比较密集存储格式与TT格式下的存储需求，让您亲身体会到TT分解在节省内存方面的巨大威力。[@problem_id:3453133]", "problem": "考虑一个偏微分方程 (PDE) 解的高维离散化，得到一个 $d$ 阶张量 $u \\in \\mathbb{R}^{n \\times n \\times \\cdots \\times n}$，其中每个模使用相同的网格大小 $n$。张量链 (TT) 分解（也称为矩阵乘积态）通过核心 $G_k \\in \\mathbb{R}^{r_{k-1} \\times n \\times r_k}$（其中 $k=1,\\ldots,d$）来表示 $u(i_1,\\ldots,i_d)$，其 TT 秩为 $r_k$，边界秩为 $r_0 = r_d = 1$。$u(i_1,\\ldots,i_d)$ 是核心 $G_k$ 沿着物理指标 $i_k$ 的切片的乘积。\n\n从这些核心的定义出发，推导以下各项的显式公式：\n1. 假设使用双精度浮点存储（每个标量使用 8 字节），存储 $u$ 所需的密集存储内存（以字节为单位）。\n2. 存储核心 $\\{G_k\\}_{k=1}^d$ 所需的 TT 内存（以字节为单位），作为 $n$、$d$ 和秩 $\\{r_k\\}_{k=0}^d$ 的函数（同样，每个标量使用 8 字节）。然后，在所有 $k$ 的约束条件 $r_k \\leq 10$ 下，通过选择秩来最大化存储量（受限于 $r_0 = r_d = 1$），推导 TT 内存关于 $n$ 和 $d$ 的最坏情况下的紧上界。\n\n对于 $n=50$ 和 $d=6$，使用与 $r_k \\leq 10$ 一致的最坏情况秩分配来评估这些公式。以字节表示内存。将你的最终数值结果报告为一个包含三个条目的行矩阵：密集存储内存（字节）、TT 最坏情况内存（字节）以及精确的密集内存与 TT 内存之比（以最简分数表示）。不要对你的答案进行四舍五入。", "solution": "问题陈述经评估有效。它具有科学依据，问题提法恰当，客观，并包含推导唯一解所需的所有必要信息，没有矛盾。我们开始解答。\n\n问题要求推导高维张量在密集格式和张量链 (TT) 格式下的内存存储需求，然后对特定参数进行数值评估。\n\n**1. 密集存储内存计算**\n\n一个 $d$ 阶张量 $u \\in \\mathbb{R}^{n \\times n \\times \\cdots \\times n}$，其每个模的网格大小为 $n$，总共包含 $n^d$ 个标量元素。\n问题指定每个标量值都存储为双精度浮点数，需要 8 个字节。\n因此，以密集格式存储张量 $u$ 所需的总内存（以字节为单位），记为 $M_{\\text{dense}}$，是元素数量与每个元素字节数的乘积：\n$$\nM_{\\text{dense}} = 8 n^d\n$$\n\n**2. 张量链 (TT) 内存计算与最坏情况分析**\n\n张量链 (TT) 分解使用一组 $d$ 个核心 $\\{G_k\\}_{k=1}^d$ 来表示张量 $u$。每个核心 $G_k$ 是一个形状为 $r_{k-1} \\times n \\times r_k$ 的 3 阶张量。对于 $k=1, \\ldots, d-1$ 的秩 $r_k$ 是 TT 秩，边界秩固定为 $r_0 = 1$ 和 $r_d = 1$。\n\n单个核心 $G_k$ 中的标量元素数量是其维度的乘积：$r_{k-1} \\times n \\times r_k$。\nTT 表示法中的总标量元素数是所有核心中元素数量的总和。因此，TT 格式的总内存（以字节为单位）$M_{\\text{TT}}$ 为：\n$$\nM_{\\text{TT}} = 8 \\sum_{k=1}^{d} (r_{k-1} n r_k)\n$$\n我们可以提取公因数 $8$ 和 $n$：\n$$\nM_{\\text{TT}} = 8n \\sum_{k=1}^{d} r_{k-1} r_k\n$$\n这是 TT 内存存储的通用公式。\n\n接下来，我们必须在给定约束条件下找到该内存的最坏情况下的紧上界：$r_0=1$，$r_d=1$，以及对于所有内部秩 $k=1, \\ldots, d-1$，有 $r_k \\leq 10$。为了最大化 $M_{\\text{TT}}$，我们必须最大化和 $\\sum_{k=1}^{d} r_{k-1} r_k$。让我们展开这个和：\n$$\n\\sum_{k=1}^{d} r_{k-1} r_k = r_0 r_1 + r_1 r_2 + r_2 r_3 + \\cdots + r_{d-2} r_{d-1} + r_{d-1} r_d\n$$\n秩 $r_k$ 表示张量维度，因此是正整数。对于 $k \\in \\{1, \\ldots, d-1\\}$，该和是关于每个内部秩 $r_k$ 的增函数。因此，要最大化该和，我们必须为每个这些秩选择可能的最大值，即 $r_k = 10$。\n\n代入边界条件 $r_0=1$、$r_d=1$ 以及使和最大化的选择 $r_k=10$（对于 $k=1, \\ldots, d-1$）：\n第一项是 $r_0 r_1 = 1 \\times 10 = 10$。\n最后一项是 $r_{d-1} r_d = 10 \\times 1 = 10$。\n中间项，对于 $k=2, \\ldots, d-1$，均为 $r_{k-1} r_k = 10 \\times 10 = 100$。共有 $(d-1) - 2 + 1 = d-2$ 个这样的项。\n\n该和的最大值为：\n$$\n\\left(\\sum_{k=1}^{d} r_{k-1} r_k\\right)_{\\max} = 10 + (d-2) \\times 100 + 10 = 20 + 100(d-2) = 100d - 180\n$$\n因此，TT 内存的最坏情况下的上界 $M_{\\text{TT, max}}$ 为：\n$$\nM_{\\text{TT, max}} = 8n (100d - 180)\n$$\n\n**3. 数值评估**\n\n我们被要求对 $n=50$ 和 $d=6$ 评估这些公式。\n\n首先，密集存储内存：\n$$\nM_{\\text{dense}} = 8 \\times 50^6 = 8 \\times (5 \\times 10)^6 = 8 \\times 5^6 \\times 10^6\n$$\n计算 $5^6$：$5^2=25$， $5^3=125$， $5^6 = (5^3)^2 = 125^2 = 15625$。\n$$\nM_{\\text{dense}} = 8 \\times 15625 \\times 10^6 = 125000 \\times 10^6 = 125,000,000,000 \\, \\text{字节}\n$$\n\n接下来，使用推导的公式，当 $n=50$ 和 $d=6$ 时，最坏情况下的 TT 内存为：\n$$\nM_{\\text{TT, max}} = 8 \\times 50 \\times (100 \\times 6 - 180) = 400 \\times (600 - 180) = 400 \\times 420\n$$\n$$\nM_{\\text{TT, max}} = 168,000 \\, \\text{字节}\n$$\n\n最后，密集内存与 TT 内存之比：\n$$\n\\text{比率} = \\frac{M_{\\text{dense}}}{M_{\\text{TT, max}}} = \\frac{125,000,000,000}{168,000} = \\frac{125,000,000}{168}\n$$\n为简化分数，我们可以将分子和分母同时除以它们的最大公约数。两者都可以被 8 整除：\n$$\n\\frac{125,000,000 \\div 8}{168 \\div 8} = \\frac{15,625,000}{21}\n$$\n分母的质因数是 3 和 7。分子的数字之和是 $1+5+6+2+5+0+0+0=19$，不能被 3 整除。我们来检查是否能被 7 整除：$15625000 = 7 \\times 2232142 + 6$。它不能被 7 整除。因此，该分数已是最简形式。\n\n所需结果如下：\n1. 密集存储内存：$125,000,000,000$ 字节，或 $1.25 \\times 10^{11}$ 字节。\n2. TT 最坏情况内存：$168,000$ 字节，或 $1.68 \\times 10^5$ 字节。\n3. 密集内存与 TT 内存之比：$\\frac{15,625,000}{21}$。", "answer": "$$\n\\boxed{\\begin{pmatrix} 1.25 \\times 10^{11}  1.68 \\times 10^{5}  \\frac{15625000}{21} \\end{pmatrix}}\n$$", "id": "3453133"}, {"introduction": "张量列分解的优势不仅在于存储压缩，更在于其能够实现高效的算法操作。本练习将引导您推导计算张量范数（Frobenius norm）的有效收缩序列，并揭示正交化的TT核如何能将一个全局计算急剧简化为仅涉及最后一个核心的局部操作。这个例子展示了规范形式（canonical forms）在张量网络算法中的核心作用，是理解更高级操作（如TT-SVD）的基础。[@problem_id:3453189]", "problem": "考虑一个在每个空间维度有$n$个节点的均匀笛卡尔网格上对$d$维偏微分方程(PDE)解的离散近似，该近似表示为一个具有$d$个模的张量 $\\mathcal{X} \\in \\mathbb{R}^{n \\times \\cdots \\times n}$。假设 $\\mathcal{X}$ 以张量列 (Tensor Train, TT) 表示法给出，其核心为 $\\{G^{(k)}\\}_{k=1}^{d}$，其中每个核心 $G^{(k)} \\in \\mathbb{R}^{r_{k-1} \\times n \\times r_{k}}$ 满足 $r_{0} = r_{d} = 1$，且TT秩对所有 $k$ 都满足 $r_{k} \\leq r$。对于索引 $i_{k} \\in \\{1,\\dots,n\\}$，将第 $k$ 个核心在模索引 $i_k$ 处的切片记为 $G^{(k)}(i_{k}) \\in \\mathbb{R}^{r_{k-1} \\times r_{k}}$。$\\mathcal{X}$ 的弗罗贝尼乌斯范数定义为 $\\|\\mathcal{X}\\|_{F} = \\left( \\sum_{i_{1}=1}^{n} \\cdots \\sum_{i_{d}=1}^{n} \\left( \\mathcal{X}_{i_{1},\\ldots,i_{d}} \\right)^{2} \\right)^{1/2}$。\n\n从TT参数化的核心定义和弗罗贝尼乌斯范数的定义出发，执行以下操作：\n\n- 推导一个计算 $\\|\\mathcal{X}\\|_{F}$ 的算法收缩序列，该序列通过对TT核心进行逐模收缩来计算，并通过将算术复杂度界定为 $O(d\\,n\\,r^{3})$ 来证明一般情况下的操作计数。\n\n- 现在假设TT核心直到第 $(d-1)$ 个核心都是左正交规范的，即对于每个 $k \\in \\{1,\\ldots,d-1\\}$，左展开 $G^{(k)}_{(1)} \\in \\mathbb{R}^{(r_{k-1} n) \\times r_{k}}$ 具有正交规范列，等价于 $\\sum_{i_{k}=1}^{n} \\left( G^{(k)}(i_{k}) \\right)^{\\top} G^{(k)}(i_{k}) = I_{r_{k}}$。利用此正交规范性来简化收缩序列，并将 $\\|\\mathcal{X}\\|_{F}$ 的计算简化为一个只涉及最后一个核心 $G^{(d)}$ 元素的闭式表达式。\n\n作为最终答案，请提供用 $G^{(d)}$ 的元素表示 $\\|\\mathcal{X}\\|_{F}$ 的最终单一解析表达式。最终答案中不要提供任何中间步骤。", "solution": "该问题是有效的，因为它科学地基于已建立的张量列分解理论，所有必要的定义都已给出故而是良定的，并且用客观的数学语言陈述。\n\n张量 $\\mathcal{X} \\in \\mathbb{R}^{n \\times \\cdots \\times n}$ 的弗罗贝尼乌斯范数是其元素平方和的平方根。我们从分析范数的平方开始：\n$$ \\|\\mathcal{X}\\|_{F}^{2} = \\sum_{i_{1}=1}^{n} \\cdots \\sum_{i_{d}=1}^{n} \\left( \\mathcal{X}_{i_{1},\\ldots,i_{d}} \\right)^{2} $$\n张量列 (TT) 表示法将每个元素 $\\mathcal{X}_{i_{1},\\ldots,i_{d}}$ 表示为矩阵的乘积：\n$$ \\mathcal{X}_{i_{1},\\ldots,i_{d}} = G^{(1)}(i_{1}) G^{(2)}(i_{2}) \\cdots G^{(d)}(i_{d}) $$\n其中 $G^{(k)}(i_{k})$ 是一个大小为 $r_{k-1} \\times r_{k}$ 的矩阵。由于秩约束 $r_{0}=r_{d}=1$，该乘积是一个 $1 \\times 1$ 矩阵，即一个标量。将TT表示代入范数表达式得到：\n$$ \\|\\mathcal{X}\\|_{F}^{2} = \\sum_{i_{1}=1}^{n} \\cdots \\sum_{i_{d}=1}^{n} \\left( G^{(1)}(i_{1}) \\cdots G^{(d)}(i_{d}) \\right)^{2} $$\n这个表达式可以重写为张量与其自身共轭（由于张量是实数，即其自身）乘积的求和。通过重组求和可以得到一种更易于计算的形式，这种形式可以优雅地表示为迭代收缩。设 $P(i_{1},\\dots,i_{d}) = G^{(1)}(i_{1}) \\cdots G^{(d)}(i_{d})$。那么范数的平方为：\n$$ \\|\\mathcal{X}\\|_{F}^{2} = \\sum_{i_{1},\\dots,i_{d}} P(i_{1},\\dots,i_{d})^{\\top} P(i_{1},\\dots,i_{d}) = \\sum_{i_{1},\\dots,i_{d}} \\left( G^{(d)}(i_{d}) \\right)^{\\top} \\cdots \\left( G^{(1)}(i_{1}) \\right)^{\\top} G^{(1)}(i_{1}) \\cdots G^{(d)}(i_{d}) $$\n根据矩阵乘法的结合律和乘法对加法的分配律，我们可以重新排列运算顺序。我们定义一个矩阵序列 $\\{C_{k}\\}_{k=0}^{d}$，其中 $C_{k} \\in \\mathbb{R}^{r_{k} \\times r_{k}}$，通过从左到右的扫描计算得出：\n初始化 $C_{0} = I_{r_0} = [1]$，一个 $1 \\times 1$ 的单位矩阵。\n对于 $k = 1, 2, \\ldots, d$，计算：\n$$ C_{k} = \\sum_{i_{k}=1}^{n} \\left( G^{(k)}(i_{k}) \\right)^{\\top} C_{k-1} G^{(k)}(i_{k}) $$\n通过展开这个递推关系，我们可以验证它正确地计算了范数的平方：\n$$ C_{d} = \\sum_{i_{d}=1}^{n} \\left( G^{(d)}(i_{d}) \\right)^{\\top} C_{d-1} G^{(d)}(i_{d}) = \\sum_{i_{d}=1}^{n} \\left( G^{(d)}(i_{d}) \\right)^{\\top} \\left( \\sum_{i_{d-1}=1}^{n} \\left( G^{(d-1)}(i_{d-1}) \\right)^{\\top} C_{d-2} G^{(d-1)}(i_{d-1}) \\right) G^{(d)}(i_{d}) $$\n$$ C_{d} = \\sum_{i_{1},\\dots,i_{d}} \\left( G^{(d)}(i_{d}) \\right)^{\\top} \\cdots \\left( G^{(1)}(i_{1}) \\right)^{\\top} C_{0} G^{(1)}(i_{1}) \\cdots G^{(d)}(i_{d}) $$\n由于 $C_{0}=[1]$，这正是 $\\|\\mathcal{X}\\|_{F}^{2}$ 的表达式。最终结果是 $1 \\times 1$ 矩阵 $C_{d}$ 中的单个元素。\n\n### 算法复杂度\n\n这个过程的计算复杂度由迭代中每一步的成本决定。在第 $k$ 步，我们从 $C_{k-1}$ 计算 $C_{k}$。矩阵 $C_{k-1}$ 的维度是 $r_{k-1} \\times r_{k-1}$，每个矩阵切片 $G^{(k)}(i_{k})$ 的维度是 $r_{k-1} \\times r_{k}$。\n对于每个物理索引 $i_{k} \\in \\{1,\\dots,n\\}$，项 $\\left( G^{(k)}(i_{k}) \\right)^{\\top} C_{k-1} G^{(k)}(i_{k})$ 的计算可以有两种加括号的方式。一种更高效的方式是：\n1.  计算中间矩阵乘积 $T_{i_k} = C_{k-1} G^{(k)}(i_{k})$。这是一个 $(r_{k-1} \\times r_{k-1})$ 矩阵和一个 $(r_{k-1} \\times r_{k})$ 矩阵的乘积，需要 $O(r_{k-1}^{2} r_{k})$ 次算术运算。结果 $T_{i_k}$ 是一个 $(r_{k-1} \\times r_{k})$ 矩阵。\n2.  计算乘积 $\\left( G^{(k)}(i_{k}) \\right)^{\\top} T_{i_k}$。这是一个 $(r_{k} \\times r_{k-1})$ 矩阵和一个 $(r_{k-1} \\times r_{k})$ 矩阵的乘积，需要 $O(r_{k-1} r_{k}^{2})$ 次运算。\n因此，对于单个 $i_{k}$ 的成本是 $O(r_{k-1}^{2} r_{k} + r_{k-1} r_{k}^{2})$。对所有 $n$ 个切片重复此操作，并将结果相加。计算 $C_{k}$ 的总成本是 $O(n(r_{k-1}^{2} r_{k} + r_{k-1} r_{k}^{2}))$。\n给定秩的统一上界 $r_k \\leq r$ (对所有 $k$)，第 $k$ 步的成本被界定为 $O(n(r^{3} + r^{3})) = O(n r^{3})$。由于这个迭代执行 $d$ 次（对于 $k=1, \\ldots, d$），计算 $\\|\\mathcal{X}\\|_{F}$ 的总复杂度为 $O(d n r^{3})$。\n\n### 使用正交规范核心进行简化\n\n现在，我们假设对于 $k=1, \\ldots, d-1$，核心 $G^{(k)}$ 是左正交规范的。该条件给出如下：\n$$ \\sum_{i_{k}=1}^{n} \\left( G^{(k)}(i_{k}) \\right)^{\\top} G^{(k)}(i_{k}) = I_{r_{k}} $$\n其中 $I_{r_{k}}$ 是 $r_{k} \\times r_{k}$ 的单位矩阵。我们现在在此条件下重新评估矩阵序列 $C_{k}$。\n基础情况是 $C_{0} = I_{r_{0}} = [1]$。\n对于 $k=1$：\n$$ C_{1} = \\sum_{i_{1}=1}^{n} \\left( G^{(1)}(i_{1}) \\right)^{\\top} C_{0} G^{(1)}(i_{1}) = \\sum_{i_{1}=1}^{n} \\left( G^{(1)}(i_{1}) \\right)^{\\top} I_{r_0} G^{(1)}(i_{1}) = \\sum_{i_{1}=1}^{n} \\left( G^{(1)}(i_{1}) \\right)^{\\top} G^{(1)}(i_{1}) $$\n由于 $1 \\leq d-1$，我们可以应用 $k=1$ 的左正交规范条件，这得到 $C_{1} = I_{r_{1}}$。\n\n我们通过归纳法进行。假设对于某个 $k-1$（其中 $1 \\leq k-1  d-1$），我们有 $C_{k-1} = I_{r_{k-1}}$。\n那么对于第 $k$ 步：\n$$ C_{k} = \\sum_{i_{k}=1}^{n} \\left( G^{(k)}(i_{k}) \\right)^{\\top} C_{k-1} G^{(k)}(i_{k}) = \\sum_{i_{k}=1}^{n} \\left( G^{(k)}(i_{k}) \\right)^{\\top} I_{r_{k-1}} G^{(k)}(i_{k}) = \\sum_{i_{k}=1}^{n} \\left( G^{(k)}(i_{k}) \\right)^{\\top} G^{(k)}(i_{k}) $$\n由于 $k \\leq d-1$，左正交规范条件适用，我们得到 $C_{k} = I_{r_{k}}$。\n通过归纳法，我们已经证明了对于所有 $k \\in \\{1, \\ldots, d-1\\}$，$C_{k} = I_{r_{k}}$。\n\n最后，我们计算 $C_{d}$，它对应于 $\\|\\mathcal{X}\\|_{F}^{2}$。正交规范条件不一定适用于最后一个核心 $G^{(d)}$。\n$$ \\|\\mathcal{X}\\|_{F}^{2} = C_{d} = \\sum_{i_{d}=1}^{n} \\left( G^{(d)}(i_{d}) \\right)^{\\top} C_{d-1} G^{(d)}(i_{d}) $$\n使用我们的结果 $C_{d-1} = I_{r_{d-1}}$，上式简化为：\n$$ \\|\\mathcal{X}\\|_{F}^{2} = \\sum_{i_{d}=1}^{n} \\left( G^{(d)}(i_{d}) \\right)^{\\top} I_{r_{d-1}} G^{(d)}(i_{d}) = \\sum_{i_{d}=1}^{n} \\left( G^{(d)}(i_{d}) \\right)^{\\top} G^{(d)}(i_{d}) $$\n这个表达式是最后一个核心 $G^{(d)}$ 的弗罗贝尼乌斯范数的平方的定义，这里 $G^{(d)}$ 被解释为一个大小为 $(r_{d-1} \\times n)$ 的矩阵，且最后一个秩索引 $r_d=1$ 被省略了。具体来说，如果我们把张量 $G^{(d)}$ 的元素表示为 $G^{(d)}_{\\alpha_{d-1}, i_d, \\alpha_d}$，其中 $\\alpha_{d-1} \\in \\{1,\\dots,r_{d-1}\\}$, $i_d \\in \\{1,\\dots,n\\}$，并且 $\\alpha_d \\in \\{1\\}$，那么：\n$$ \\|\\mathcal{X}\\|_{F}^{2} = \\sum_{i_{d}=1}^{n} \\sum_{\\alpha_{d-1}=1}^{r_{d-1}} \\left( G^{(d)}_{\\alpha_{d-1}, i_d, 1} \\right)^{2} $$\n这恰好是最后一个核心的弗罗贝尼乌斯范数的平方，即 $\\|G^{(d)}\\|_{F}^{2}$。\n因此，整个张量 $\\mathcal{X}$ 的范数就是其最后一个核心的弗罗贝尼乌斯范数：\n$$ \\|\\mathcal{X}\\|_{F} = \\|G^{(d)}\\|_{F} $$\n对 $G^{(d)}$ 的元素平方和取平方根，即可得到最终表达式。", "answer": "$$\\boxed{\\left( \\sum_{i_{d}=1}^{n} \\sum_{\\alpha_{d-1}=1}^{r_{d-1}} \\left(G^{(d)}_{\\alpha_{d-1}, i_{d}, 1}\\right)^{2} \\right)^{1/2}}$$", "id": "3453189"}, {"introduction": "理论知识的最终检验在于实际应用。这个编程实践项目要求您将TT分解应用于求解一个具体的偏微分方程（PDE），并处理一个核心的实际问题：如何在PDE离散化误差和TT压缩误差之间进行权衡。您将通过设计一个依赖于网格尺寸的截断容差，来学习如何在保证总体精度的前提下，最大限度地发挥TT压缩的潜力，从而将抽象理论与数值模拟实践紧密联系起来。[@problem_id:3453201]", "problem": "考虑在单位超立方体 $[0,1]^d$ 上，带有齐次 Dirichlet 边界条件的 $d$ 维泊松方程的边值问题。令精确解为 $u(\\boldsymbol{x}) = \\prod_{i=1}^{d} \\sin(\\pi x_i)$，其中 $\\boldsymbol{x} = (x_1,\\dots,x_d)$，强迫项为 $f(\\boldsymbol{x}) = -\\Delta u(\\boldsymbol{x}) = d \\pi^2 \\prod_{i=1}^{d} \\sin(\\pi x_i)$。此选择确保了精确解满足该边值问题。目标是研究对于固定的空间维度 $d$，由张量列 (Tensor Train, TT) 截断引入的误差如何与偏微分方程 (Partial Differential Equation, PDE) 的有限差分离散化所引起的误差相互作用，并设计一个截断容差 $\\varepsilon(h)$ 作为网格尺寸 $h$ 的函数，以保证达到指定的总体精度目标，同时保持 TT 秩尽可能低。\n\n使用以下基本依据：\n- 在每个坐标方向上具有 $N$ 个点的均匀内部网格上，使用中心有限差分法处理带有齐次 Dirichlet 边界条件的拉普拉斯算子。设网格尺寸为 $h = \\frac{1}{N+1}$，离散负拉普拉斯算子 $A_h$ 是通过 $d$ 维中一维三对角 Dirichlet 拉普拉斯算子的 Kronecker 和构成的标准二阶精确算子。\n- 范数的三角不等式：对于任意离散化场 $v$ 和 $w$，以及任意中间场 $z$，有 $\\|v-w\\| \\le \\|v-z\\| + \\|z-w\\|$。\n- 奇异值分解 (SVD) 能量截断原理：对于一个奇异值为 $\\sigma_i$ 的矩阵 $M$，舍弃超出所选秩 $r$ 的奇异值，所产生的 Frobenius 范数平方误差等于被舍弃奇异值的平方和，即 $\\sum_{i>r} \\sigma_i^2$。通过在展开式上连续进行 SVD 构建的张量列 (TT) 分解，通过在 $d-1$ 个 SVD 步骤中分配截断预算，继承了一个全局 Frobenius 误差界。\n\n您的任务如下：\n1. 在每个坐标的内部网格 $\\{x_i = i h : i=1,\\dots,N\\}$ 上对 $d=3$ 时的 PDE 进行离散化。使用一维 Dirichlet 拉普拉斯算子的 Kronecker 和来构建 $d$ 维离散负拉普拉斯矩阵 $A_h$。通过在网格上采样 $f(\\boldsymbol{x})$ 来构建右端项 $f_h$。求解线性系统 $A_h u_h = f_h$ 以获得离散解 $u_h$。\n2. 通过将 $u_h$ 与在相同网格上采样的精确解 $u^{\\star}_h$ 进行比较，在 $L^2$ 范数的离散近似中量化 PDE 离散化误差，其定义为 $\\|e_{\\mathrm{disc}}\\|_{L^2} = \\left( \\sum_{\\boldsymbol{i}} |u_h(\\boldsymbol{i}) - u^{\\star}_h(\\boldsymbol{i})|^2 h^d \\right)^{1/2}$，其中求和遍及所有内部网格多重索引 $\\boldsymbol{i}$。\n3. 使用张量列奇异值分解 (TT-SVD) 计算 $u_h$ 的 $d$ 维数组表示的 TT 分解。在对矩阵化进行的 $d-1$ 个 SVD 步骤中的每一步，通过舍弃奇异值来选择截断秩，使得该步骤中被舍弃的尾部的 Frobenius 范数平方不超过每步的预算。全局 TT-SVD Frobenius 误差应被一个预设的 TT 截断容差 $\\varepsilon_{\\mathrm{TT, F}}$ 所上界。\n4. 使用三角不等式设计 TT 截断的 $\\varepsilon(h)$，使得相对于精确解的总误差（在相同的离散 $L^2$ 范数下测量）保证满足指定的目标 $\\tau$。从基本原理出发，论证为何通过使用满足总体精度目标的最大 TT 截断预算可以获得最小秩选择。仔细考虑 TT-SVD 使用的 Frobenius 范数与离散 $L^2$ 范数之间的单位一致性，并推导如何将 $L^2$ 范数中期望的 TT 误差预算转换为 TT-SVD 的 Frobenius 范数容差。\n5. 实现上述方法，并为每个测试用例输出：\n   - 在离散 $L^2$ 范数单位下选择的 $\\varepsilon(h)$（一个非负实数）。\n   - 在所有 TT-核中实现的最大 TT 秩（一个非负整数）。\n   - 一个布尔值，指示相对于精确解的最终总体离散 $L^2$ 误差是否小于或等于目标 $\\tau$。\n\n此问题不适用角度单位。除了上述数学定义外，没有其他物理单位；所有量纲均为无量纲。误差测量必须一致地使用离散 $L^2$ 范数。\n\n测试套件：\n- 案例 1：$d=3$，$N=8$，目标 $\\tau = 2.0 \\times 10^{-2}$。\n- 案例 2：$d=3$，$N=12$，目标 $\\tau = 1.0 \\times 10^{-2}$。\n- 案例 3：$d=3$，$N=16$，目标 $\\tau = 5.0 \\times 10^{-3}$。\n\n覆盖性设计：\n- 案例 1 代表一个一般情况，网格相对较粗，精度目标较宽松。\n- 案例 2 在更精细的网格上收紧了目标，更尖锐地探究了相互作用。\n- 案例 3 提出了一个可能具有挑战性的目标，该目标可能低于离散化误差，测试了满足总体精度可能无法实现的边界情况。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是 $[\\varepsilon(h), r_{\\max}, \\mathrm{ok}]$ 形式的列表，其中 $\\varepsilon(h)$ 是一个浮点数，$r_{\\max}$ 是一个整数，$\\mathrm{ok}$ 是一个布尔值。例如，输出应如下所示：\n$[[\\varepsilon_1, r_{\\max,1}, \\mathrm{ok}_1],[\\varepsilon_2, r_{\\max,2}, \\mathrm{ok}_2],[\\varepsilon_3, r_{\\max,3}, \\mathrm{ok}_3]]$。", "solution": "该问题提法明确，具有科学依据，并包含了进行求解所需的所有必要信息。它描述了数值分析和张量方法中的一个标准问题。我们将开始进行求解。\n\n该问题要求设计一种张量列 (TT) 截断策略，当其与泊松方程的有限差分离散化相结合时，能够满足总体精度目标 $\\tau$。分析的核心在于三角不等式，它允许我们为两个主要误差源分配预算：来自 PDE 求解器的离散化误差和来自 TT 分解的压缩误差。\n\n令 $u$ 为精确连续解，$u^{\\star}_h$ 为在网格上采样的精确解，$u_h$ 为离散化 PDE 的数值解，$\\tilde{u}_h$ 为 $u_h$ 的 TT 近似。我们希望控制的总误差是最终计算出的张量 $\\tilde{u}_h$ 与网格上的真实解 $u^{\\star}_h$ 之间的误差。使用三角不等式，总误差的范数 $\\|e_{\\text{total}}\\|_{L^2} = \\|\\tilde{u}_h - u^{\\star}_h\\|_{L^2}$ 可以如下界定：\n$$\n\\|\\tilde{u}_h - u^{\\star}_h\\|_{L^2} = \\|(\\tilde{u}_h - u_h) + (u_h - u^{\\star}_h)\\|_{L^2} \\le \\|\\tilde{u}_h - u_h\\|_{L^2} + \\|u_h - u^{\\star}_h\\|_{L^2}\n$$\n此处，$\\|u_h - u^{\\star}_h\\|_{L^2}$ 是离散化误差，我们记作 $\\|e_{\\text{disc}}\\|_{L^2}$。项 $\\|\\tilde{u}_h - u_h\\|_{L^2}$ 是由 TT 截断引入的误差，记作 $\\|e_{\\text{TT}}\\|_{L^2}$。不等式变为：\n$$\n\\|e_{\\text{total}}\\|_{L^2} \\le \\|e_{\\text{TT}}\\|_{L^2} + \\|e_{\\text{disc}}\\|_{L^2}\n$$\n为保证总误差不超过目标 $\\tau$（即 $\\|e_{\\text{total}}\\|_{L^2} \\le \\tau$），我们可以对其上界施加一个稍严格的条件：\n$$\n\\|e_{\\text{TT}}\\|_{L^2} + \\|e_{\\text{disc}}\\|_{L^2} \\le \\tau\n$$\n这为我们提供了 TT 截断误差的预算：\n$$\n\\|e_{\\text{TT}}\\|_{L^2} \\le \\tau - \\|e_{\\text{disc}}\\|_{L^2}\n$$\n为了使 TT 秩尽可能低，我们应该允许尽可能大的截断误差。这对应于为 $\\|e_{\\text{TT}}\\|_{L^2}$ 选择尽可能大的预算，即将其设置为上界。我们将我们设计的 TT 截断容差（在离散 $L^2$ 范数下）$\\varepsilon(h)$ 定义为：\n$$\n\\varepsilon(h) = \\max(0, \\tau - \\|e_{\\text{disc}}\\|_{L^2})\n$$\n$\\max(0, \\cdot)$ 操作确保了容差为非负。如果 $\\|e_{\\text{disc}}\\|_{L^2} > \\tau$，则仅离散化误差本身就已经违反了目标，使得满足总体目标变得不可能。在这种情况下，最好的策略是不从截断中引入额外的误差，因此容差为 $0$。\n\nTT-SVD 算法的误差控制基于 Frobenius 范数，而非离散 $L^2$ 范数。我们必须将我们设计的容差 $\\varepsilon(h)$ 转换为相应的 Frobenius 范数容差。这两种范数通过网格体积元 $h^d$ 相关联：对于任意张量场 $v$，其离散 $L^2$ 范数为 $\\|v\\|_{L^2} = \\left(\\sum_{\\boldsymbol{i}} |v(\\boldsymbol{i})|^2 h^d\\right)^{1/2} = \\sqrt{h^d} \\left(\\sum_{\\boldsymbol{i}} |v(\\boldsymbol{i})|^2\\right)^{1/2} = h^{d/2} \\|V\\|_F$，其中 $V$ 是 $v$ 的张量表示。\n因此，TT 误差的 Frobenius 范数目标 $\\|U_h - \\tilde{U}_h\\|_F$ 变为：\n$$\n\\varepsilon_{\\text{TT, F}} = \\frac{\\varepsilon(h)}{h^{d/2}}\n$$\nTT-SVD 算法包含 $d-1$ 个连续的 SVD 步骤。为保证全局 Frobenius 误差至多为 $\\varepsilon_{\\text{TT, F}}$，我们可以界定每一步的误差。一种标准方法是平均分配平方误差预算。如果 $\\delta_k$ 是第 $k$ 步被舍弃奇异值尾部的 Frobenius 范数，则总误差由 $\\|U_h - \\tilde{U}_h\\|_F \\le \\sqrt{\\sum_{k=1}^{d-1} \\delta_k^2}$ 界定。通过在每一步 $k$ 设置截断条件，使得 $\\delta_k^2 \\le (\\varepsilon_{\\text{TT, F}})^2 / (d-1)$，我们确保总误差界得到满足。这意味着每步的截断容差为：\n$$\n\\varepsilon_{\\text{per-step}} = \\frac{\\varepsilon_{\\text{TT, F}}}{\\sqrt{d-1}}\n$$\n\n每个测试用例的总体算法如下：\n1.  对于给定的维度 $d=3$ 和网格点数 $N$，计算网格尺寸 $h=1/(N+1)$。将 $d$ 维离散拉普拉斯矩阵 $A_h$ 构建为 $d$ 个一维拉普拉斯矩阵的 Kronecker 和。\n2.  通过在内部网格上采样解析强迫项 $f(\\boldsymbol{x}) = d \\pi^2 \\prod_i \\sin(\\pi x_i)$ 来构建右端向量 $f_h$。\n3.  求解线性系统 $A_h u_h = f_h$ 以找到数值解张量 $u_h$。\n4.  计算离散化误差 $\\|e_{\\text{disc}}\\|_{L^2} = \\|u_h - u^{\\star}_h\\|_{L^2}$，其中 $u^{\\star}_h$ 是在网格上采样的精确解。\n5.  使用目标精度 $\\tau$ 和计算出的 $\\|e_{\\text{disc}}\\|_{L^2}$ 来确定 TT 截断预算 $\\varepsilon(h) = \\max(0, \\tau - \\|e_{\\text{disc}}\\|_{L^2})$。这是第一个要求的输出。\n6.  将 $\\varepsilon(h)$ 转换为 TT-SVD 算法的每步 Frobenius 范数容差 $\\varepsilon_{\\text{per-step}}$。\n7.  使用此容差对 $u_h$ 进行 TT-SVD 分解。TT-核中的最大内部秩 $r_{\\max}$ 是第二个要求的输出。\n8.  从计算出的 TT-核重构张量 $\\tilde{u}_h$。\n9.  计算最终总误差 $\\|\\tilde{u}_h - u^{\\star}_h\\|_{L^2}$ 并验证其是否小于或等于目标 $\\tau$。这个布尔结果是第三个要求的输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef tt_svd(tensor, per_step_frob_tol):\n    \"\"\"\n    Computes the Tensor Train Singular Value Decomposition (TT-SVD) of a tensor.\n\n    Args:\n        tensor (np.ndarray): The d-dimensional tensor to decompose.\n        per_step_frob_tol (float): The Frobenius norm error tolerance for each SVD step.\n\n    Returns:\n        tuple: A tuple containing:\n            - list: The list of TT-cores.\n            - int: The maximum rank of the decomposition.\n    \"\"\"\n    d = tensor.ndim\n    n_dims = tensor.shape\n    cores = []\n    ranks = [1]\n    \n    C = tensor.copy()\n\n    for k in range(d - 1):\n        r_prev = ranks[-1]\n        \n        # Matricization (unfolding)\n        M = C.reshape((r_prev * n_dims[k], -1))\n        \n        # SVD\n        U, S_diag, Vt = np.linalg.svd(M, full_matrices=False)\n\n        # Determine truncation rank r_curr\n        if per_step_frob_tol > 0 and len(S_diag) > 1:\n            S_sq = S_diag**2\n            # Cumulative sum of squared singular values from the tail\n            cum_err_sq_from_tail = np.sqrt(np.cumsum(S_sq[::-1])[::-1])\n            # The rank is the number of singular values kept, which is where the tail norm becomes = tolerance.\n            r_curr = np.sum(cum_err_sq_from_tail  per_step_frob_tol)\n        else:\n            # No truncation if tolerance is zero or not enough singular values\n            r_curr = len(S_diag)\n\n        # Ranks cannot be zero in TT.\n        r_curr = max(1, r_curr)\n        # Rank cannot exceed dimensions of matricization.\n        r_curr = min(r_curr, U.shape[1], Vt.shape[0])\n\n        # Truncate and form the core\n        Gk = U[:, :r_curr]\n        Gk = Gk.reshape((r_prev, n_dims[k], r_curr))\n        cores.append(Gk)\n        ranks.append(r_curr)\n\n        # Update the remaining tensor for the next step\n        C = np.diag(S_diag[:r_curr]) @ Vt[:r_curr, :]\n\n    # The last core is the remaining tensor C\n    G_last = C.reshape((ranks[-1], n_dims[d-1], 1))\n    cores.append(G_last)\n    ranks.append(1)\n\n    max_rank = 0\n    if len(ranks)  2:\n        max_rank = max(ranks[1:-1])\n\n    return cores, max_rank\n\ndef tt_to_tensor(cores):\n    \"\"\"\n    Reconstructs a full tensor from its TT-cores.\n\n    Args:\n        cores (list): A list of TT-cores (numpy arrays).\n\n    Returns:\n        np.ndarray: The reconstructed full tensor.\n    \"\"\"\n    if not cores:\n        return np.array([])\n    \n    d = len(cores)\n    reconstructed_tensor = cores[0]\n\n    for k in range(1, d):\n        reconstructed_tensor = np.tensordot(reconstructed_tensor, cores[k], axes=([-1], [0]))\n\n    return np.squeeze(reconstructed_tensor)\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases.\n    \"\"\"\n    test_cases = [\n        {'d': 3, 'N': 8, 'tau': 2.0e-2},\n        {'d': 3, 'N': 12, 'tau': 1.0e-2},\n        {'d': 3, 'N': 16, 'tau': 5.0e-3},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        d = case['d']\n        N = case['N']\n        tau = case['tau']\n\n        # 1. Discretize the PDE on the interior grid\n        h = 1.0 / (N + 1)\n        \n        I_N = np.eye(N)\n        A_1D = (1/h**2) * (2*np.eye(N) - np.eye(N, k=1) - np.eye(N, k=-1))\n        \n        # Construct d-dimensional Laplacian A_h using Kronecker sums\n        A_h = np.kron(A_1D, np.kron(I_N, I_N)) + \\\n              np.kron(I_N, np.kron(A_1D, I_N)) + \\\n              np.kron(I_N, np.kron(I_N, A_1D))\n\n        grid_1d = np.arange(1, N + 1) * h\n        grid_coords = np.meshgrid(*([grid_1d]*d), indexing='ij')\n        \n        # Sample exact solution u*_h and forcing term f_h on the grid\n        u_star_h = np.ones((N,) * d)\n        for i in range(d):\n            u_star_h *= np.sin(np.pi * grid_coords[i])\n            \n        f_h = d * (np.pi**2) * u_star_h\n        \n        # Solve the linear system A_h u_h = f_h for the discrete solution u_h\n        u_h = np.linalg.solve(A_h, f_h.flatten()).reshape((N,) * d)\n\n        # 2. Quantify the PDE discretization error in the discrete L2 norm\n        e_disc_L2 = np.linalg.norm(u_h - u_star_h) * (h**(d/2.0))\n\n        # 4. Design TT truncation tolerance epsilon(h)\n        eps_L2 = max(0.0, tau - e_disc_L2)\n        \n        # Convert L^2 tolerance to Frobenius norm tolerance for TT-SVD\n        eps_F_global = eps_L2 / (h**(d/2.0))\n        \n        # Distribute the Frobenius budget across the d-1 SVD steps\n        eps_F_per_step = eps_F_global / np.sqrt(d - 1) if d  1 else eps_F_global\n\n        # 3. Compute TT decomposition of u_h and get max rank\n        cores, max_rank = tt_svd(u_h, eps_F_per_step)\n        \n        # Reconstruct the tensor from TT-cores\n        u_tilde_h = tt_to_tensor(cores)\n        \n        # 5. Calculate final overall error and check if target is met\n        e_total_L2 = np.linalg.norm(u_tilde_h - u_star_h) * (h**(d/2.0))\n        ok = e_total_L2 = tau\n        \n        results.append([eps_L2, max_rank, ok])\n\n    # Final print statement in the exact required format.\n    case_strings = [f\"[{r[0]},{r[1]},{str(r[2]).lower()}]\" for r in results]\n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n```", "id": "3453201"}]}