{"hands_on_practices": [{"introduction": "Picard迭代法和Newton-Raphson方法的核心在于它们在每一步中如何为非线性问题构建线性近似。本初级实践旨在提供构建这些迭代核心组成部分的实践基础经验。通过对一个非线性扩散方程进行离散化，你将直接为Picard迭代和Newton法的一个单步迭代组装线性系统矩阵 [@problem_id:3431358]。这项对比练习将揭示两种方法在结构上的根本差异，包括矩阵对称性和条件数等特性，这些对于选择高效的线性求解器至关重要。", "problem": "考虑在单位区间上的具有齐次狄利克雷边界条件的守恒形式的非线性标量偏微分方程 (PDE)，\n$$\n-\\frac{d}{dx}\\left(\\left(1+u(x)^2\\right)\\frac{du}{dx}(x)\\right) = f(x), \\quad x \\in (0,1), \\quad u(0) = 0, \\quad u(1) = 0.\n$$\n你将构建一个具有 $n$ 个内部节点、网格间距 $h = \\frac{1}{n+1}$ 和节点位置 $x_i = i h$（$i = 1,2,\\dots,n$）的均匀一维网格。使用从通量的中心差分导出的守恒有限差分方法进行离散化。具体来说：\n- 定义系数函数 $a(u) = 1 + u^2$。\n- 通过节点中心值的算术平均来近似边中心的系数 $x_{i+\\frac{1}{2}}$，\n$$\na_{i+\\frac{1}{2}} \\approx 1 + \\frac{1}{2}\\left(u_i^2 + u_{i+1}^2\\right),\n$$\n其中 $u_i \\approx u(x_i)$，边界值 $u_0 = u(0)$ 和 $u_{n+1} = u(1)$ 固定为零。\n- 用 $q_{i+\\frac{1}{2}} \\approx a_{i+\\frac{1}{2}} \\frac{u_{i+1} - u_i}{h}$ 近似边上的通量，并用边差分 $\\frac{q_{i+\\frac{1}{2}} - q_{i-\\frac{1}{2}}}{h}$ 近似其散度。\n\n从给定的迭代 $u^{(k)}$ 开始，实现：\n1. 一个 Picard（不动点）线性化步骤：将系数冻结在当前迭代值，并形成与下式对应的线性系统\n$$\n-\\frac{1}{h}\\left(a_{i+\\frac{1}{2}}^{(k)} \\frac{u_{i+1}^{(k+1)} - u_i^{(k+1)}}{h} - a_{i-\\frac{1}{2}}^{(k)} \\frac{u_i^{(k+1)} - u_{i-1}^{(k+1)}}{h}\\right) = f_i, \\quad i = 1,\\dots,n,\n$$\n其中 $u_0^{(k+1)} = 0$ 且 $u_{n+1}^{(k+1)} = 0$。组装相应的矩阵 $A_{\\mathrm{Pic}}(u^{(k)})$ 和右端向量 $\\mathbf{f}$。\n2. 一个 Newton-Raphson 步骤：从守恒离散化中导出离散残差向量 $\\mathbf{R}(u)$，并通过对残差关于内部节点值求导来形成雅可比矩阵 $J(u^{(k)})$。求解\n$$\nJ(u^{(k)}) \\, \\delta^{(k)} = -\\mathbf{R}(u^{(k)}),\n$$\n并在内部节点上更新 $u^{(k+1)} = u^{(k)} + \\delta^{(k)}$（边界值保持不变，不属于未知向量的一部分）。\n\n你的程序必须：\n- 对于每个指定的测试用例，使用上述方案组装 Picard 矩阵 $A_{\\mathrm{Pic}}(u^{(k)})$ 和 Newton 雅可比矩阵 $J(u^{(k)})$。\n- 计算二范数条件数 $\\kappa_2\\left(A_{\\mathrm{Pic}}(u^{(k)})\\right)$ 和 $\\kappa_2\\left(J(u^{(k)})\\right)$。\n- 计算比率 $\\rho = \\kappa_2\\left(J(u^{(k)})\\right) / \\kappa_2\\left(A_{\\mathrm{Pic}}(u^{(k)})\\right)$。\n- 通过检查对称性及其特征值来验证 $A_{\\mathrm{Pic}}(u^{(k)})$ 是否为对称正定 (SPD) 矩阵。\n- 在相对 Frobenius 范数容差内检查 $J(u^{(k)})$ 是否对称。\n\n使用以下参数值测试套件，其中 $n$ 是内部节点数，初始迭代为 $u_i^{(k)} = \\alpha \\sin(\\pi x_i)$，强迫项采样为 $f_i = f(x_i)$：\n- 测试用例 1（理想情况，线性基准）：$n = 8$, $\\alpha = 0$, $f(x) = \\sin(\\pi x)$。\n- 测试用例 2（中度非线性）：$n = 32$, $\\alpha = 0.5$, $f(x) = \\sin(\\pi x)$。\n- 测试用例 3（强非线性和混合强迫项）：$n = 64$, $\\alpha = 2.0$, $f(x) = 1 + \\sin(2\\pi x)$。\n\n三角函数中的角度必须以弧度解释。不涉及物理单位。\n\n最终输出格式：\n- 对于每个测试用例，按顺序生成五个值：$\\kappa_2\\left(A_{\\mathrm{Pic}}\\right)$ (浮点数), $\\kappa_2\\left(J\\right)$ (浮点数), $\\rho$ (浮点数), $\\mathrm{SPD}(A_{\\mathrm{Pic}})$ (布尔值), 和 $\\mathrm{Sym}(J)$ (布尔值)。\n- 将所有浮点数输出四舍五入到六位小数。\n- 将所有测试用例的结果聚合到单行中，以逗号分隔的列表形式打印，并用方括号括起来，跨测试用例展平，例如：\n$$\n[\\text{condP}_1,\\text{condN}_1,\\text{ratio}_1,\\text{SPD}_1,\\text{Sym}_1,\\text{condP}_2,\\dots,\\text{Sym}_3].\n$$\n你的程序必须是一个完整的、可运行的实现，它执行上述步骤并打印所要求的单行输出。", "solution": "用户提供的问题已经过分析，并被确定为 **有效**。这是一个数值分析领域中提法恰当、有科学依据的问题，内容自洽，没有矛盾或歧义。\n\n### 离散化系统分析\n\n该非线性偏微分方程 (PDE) 以守恒形式给出：\n$$\n-\\frac{d}{dx}\\left(\\left(1+u(x)^2\\right)\\frac{du}{dx}(x)\\right) = f(x), \\quad x \\in (0,1)\n$$\n具有齐次狄利克雷边界条件 $u(0) = 0$ 和 $u(1) = 0$。\n问题指定了在具有 $n$ 个内部节点 $x_i = ih$（$i=1, \\dots, n$）和网格间距 $h=1/(n+1)$ 的均匀网格上的有限差分离散化。通量及其散度近似为：\n$$\nq_{i+\\frac{1}{2}} \\approx a_{i+\\frac{1}{2}} \\frac{u_{i+1} - u_i}{h}, \\quad \\text{其中} \\quad a_{i+\\frac{1}{2}} = 1 + \\frac{1}{2}\\left(u_i^2 + u_{i+1}^2\\right)\n$$\n$$\n-\\left.\\frac{dq}{dx}\\right|_{x_i} \\approx -\\frac{q_{i+\\frac{1}{2}} - q_{i-\\frac{1}{2}}}{h}\n$$\n其中 $u_i \\approx u(x_i)$。边界值为 $u_0 = 0$ 和 $u_{n+1}=0$。\n将通量近似代入散度近似，得到每个内部节点 $i$ 处的离散方程：\n$$\n-\\frac{1}{h^2}\\left[ a_{i+\\frac{1}{2}}(u_{i+1} - u_i) - a_{i-\\frac{1}{2}}(u_i - u_{i-1}) \\right] = f_i\n$$\n我们为未知向量 $\\mathbf{u} = [u_1, u_2, \\dots, u_n]^T$ 定义离散残差向量 $\\mathbf{R}(\\mathbf{u})$。残差的第 $i$ 个分量是：\n$$\nR_i(\\mathbf{u}) = -\\frac{1}{h^2}\\left[ \\left(1 + \\frac{u_i^2+u_{i+1}^2}{2}\\right)(u_{i+1} - u_i) - \\left(1 + \\frac{u_{i-1}^2+u_i^2}{2}\\right)(u_i - u_{i-1}) \\right] - f_i\n$$\n问题是找到 $\\mathbf{u}$ 使得 $\\mathbf{R}(\\mathbf{u}) = \\mathbf{0}$。我们现在将推导 Picard 和 Newton-Raphson 方法一步迭代所需的矩阵。\n\n### 1. Picard 线性化\n\nPicard（或不动点）方法通过在先前的迭代值 $\\mathbf{u}^{(k)}$ 处计算非线性系数函数 $a(u)$ 来将问题线性化。新迭代值 $\\mathbf{u}^{(k+1)}$ 的系统为：\n$$\n-\\frac{1}{h^2}\\left[ a_{i+\\frac{1}{2}}^{(k)}(u_{i+1}^{(k+1)} - u_i^{(k+1)}) - a_{i-\\frac{1}{2}}^{(k)}(u_i^{(k+1)} - u_{i-1}^{(k+1)}) \\right] = f_i\n$$\n其中 $a_{i+\\frac{1}{2}}^{(k)} = 1 + \\frac{1}{2}\\left((u_i^{(k)})^2 + (u_{i+1}^{(k)})^2\\right)$。该方程可以写成线性系统 $A_{\\mathrm{Pic}}(\\mathbf{u}^{(k)}) \\mathbf{u}^{(k+1)} = \\mathbf{f}$。通过重新排列各项，我们可以确定矩阵 $A_{\\mathrm{Pic}}(\\mathbf{u}^{(k)})$ 的元素。对于第 $i$ 行，它对应于 $u_i^{(k+1)}$ 的方程，我们有：\n$$\n\\frac{1}{h^2}\\left[ -a_{i-\\frac{1}{2}}^{(k)}u_{i-1}^{(k+1)} + \\left(a_{i+\\frac{1}{2}}^{(k)} + a_{i-\\frac{1}{2}}^{(k)}\\right)u_i^{(k+1)} - a_{i+\\frac{1}{2}}^{(k)}u_{i+1}^{(k+1)} \\right] = f_i\n$$\n因此，矩阵 $A_{\\mathrm{Pic}}(\\mathbf{u}^{(k)})$ 是一个具有以下元素的 $n \\times n$ 三对角矩阵：\n- 对角线：$(A_{\\mathrm{Pic}})_{i,i} = \\frac{1}{h^2} \\left(a_{i+\\frac{1}{2}}^{(k)} + a_{i-\\frac{1}{2}}^{(k)}\\right)$\n- 次对角线：$(A_{\\mathrm{Pic}})_{i,i-1} = -\\frac{1}{h^2} a_{i-\\frac{1}{2}}^{(k)}$\n- 超对角线：$(A_{\\mathrm{Pic}})_{i,i+1} = -\\frac{1}{h^2} a_{i+\\frac{1}{2}}^{(k)}$\n\n矩阵 $A_{\\mathrm{Pic}}$ 是对称的，因为 $(A_{\\mathrm{Pic}})_{i,i+1} = -\\frac{1}{h^2} a_{i+\\frac{1}{2}}^{(k)} = (A_{\\mathrm{Pic}})_{i+1,i}$。由于 $a(u) = 1+u^2 \\geq 1$，所有系数 $a_{i\\pm 1/2}^{(k)}$ 都是正的。该矩阵也是对角占优且不可约的，这保证了它是正定的。因此，$A_{\\mathrm{Pic}}$ 是对称正定 (SPD) 矩阵。\n\n### 2. Newton-Raphson 方法\n\nNewton-Raphson 方法通过从线性系统 $J(\\mathbf{u}^{(k)})\\delta^{(k)} = -\\mathbf{R}(\\mathbf{u}^{(k)})$ 中迭代地找到修正量 $\\delta^{(k)}$ 并更新 $\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + \\delta^{(k)}$ 来求解 $\\mathbf{R}(\\mathbf{u}) = \\mathbf{0}$。矩阵 $J$ 是残差向量 $\\mathbf{R}$ 的雅可比矩阵，其元素为 $J_{ij} = \\frac{\\partial R_i}{\\partial u_j}$。由于 $R_i$ 仅依赖于 $u_{i-1}$、$u_i$ 和 $u_{i+1}$，雅可比矩阵也是一个三对角矩阵。\n我们计算 $R_i(\\mathbf{u})$ 的偏导数（为清晰起见，省略上标 $(k)$）：\n\n- **主对角线，$J_{i,i} = \\frac{\\partial R_i}{\\partial u_i}$:**\n$$\nJ_{i,i} = \\frac{\\partial}{\\partial u_i} \\left( -\\frac{1}{h^2}\\left[ a_{i+\\frac{1}{2}}(u_{i+1} - u_i) - a_{i-\\frac{1}{2}}(u_i - u_{i-1}) \\right] \\right)\n$$\n使用乘法法则和 $\\frac{\\partial a_{i\\pm 1/2}}{\\partial u_i} = u_i$：\n$$\nJ_{i,i} = -\\frac{1}{h^2} \\left[ (u_i(u_{i+1}-u_i) - a_{i+\\frac{1}{2}}) - (u_i(u_i-u_{i-1}) + a_{i-\\frac{1}{2}}) \\right]\n$$\n$$\nJ_{i,i} = \\frac{1}{h^2} \\left[ a_{i+\\frac{1}{2}} + a_{i-\\frac{1}{2}} - u_i(u_{i+1} - 2u_i + u_{i-1}) \\right]\n$$\n\n- **超对角线，$J_{i,i+1} = \\frac{\\partial R_i}{\\partial u_{i+1}}$:**\n$$\nJ_{i,i+1} = \\frac{\\partial}{\\partial u_{i+1}} \\left( -\\frac{1}{h^2} a_{i+\\frac{1}{2}}(u_{i+1} - u_i) \\right)\n$$\n使用乘法法则和 $\\frac{\\partial a_{i+1/2}}{\\partial u_{i+1}} = u_{i+1}$：\n$$\nJ_{i,i+1} = -\\frac{1}{h^2} \\left[ u_{i+1}(u_{i+1}-u_i) + a_{i+\\frac{1}{2}}(1) \\right] = -\\frac{1}{h^2} \\left[ a_{i+\\frac{1}{2}} + u_{i+1}(u_{i+1}-u_i) \\right]\n$$\n\n- **次对角线，$J_{i,i-1} = \\frac{\\partial R_i}{\\partial u_{i-1}}$:**\n$$\nJ_{i,i-1} = \\frac{\\partial}{\\partial u_{i-1}} \\left( \\frac{1}{h^2} a_{i-\\frac{1}{2}}(u_i - u_{i-1}) \\right)\n$$\n使用乘法法则和 $\\frac{\\partial a_{i-1/2}}{\\partial u_{i-1}} = u_{i-1}$：\n$$\nJ_{i,i-1} = \\frac{1}{h^2} \\left[ u_{i-1}(u_i-u_{i-1}) + a_{i-\\frac{1}{2}}(-1) \\right] = \\frac{1}{h^2} \\left[ u_{i-1}(u_i-u_{i-1}) - a_{i-\\frac{1}{2}} \\right]\n$$\n\n雅可比矩阵 $J$ 通常不是对称的。为了检查对称性，我们比较 $J_{i,i+1}$ 和 $J_{i+1,i}$。根据索引为 $i+1$ 的次对角线公式：\n$$\nJ_{i+1,i} = \\frac{1}{h^2} \\left[ u_i(u_{i+1}-u_i) - a_{i+\\frac{1}{2}} \\right]\n$$\n将此与 $J_{i,i+1}$ 比较，我们发现 $J_{i,i+1} \\neq J_{i+1,i}$，除非 $\\mathbf{u}=\\mathbf{0}$，在这种情况下问题是线性的，且 $J=A_{\\mathrm{Pic}}$。\n\n### 计算摘要\n\n对于每个测试用例，我们将：\n1.  基于初始迭代 $\\mathbf{u}^{(k)}$ 构建 $n \\times n$ 矩阵 $A_{\\mathrm{Pic}}$。\n2.  基于 $\\mathbf{u}^{(k)}$ 构建 $n \\times n$ 矩阵 $J$。\n3.  计算 2-范数条件数 $\\kappa_2(A_{\\mathrm{Pic}})$ 和 $\\kappa_2(J)$。\n4.  计算比率 $\\rho = \\kappa_2(J) / \\kappa_2(A_{\\mathrm{Pic}})$。\n5.  通过检查对称性和所有特征值是否为正来验证 $A_{\\mathrm{Pic}}$ 是否为对称正定 (SPD) 矩阵。\n6.  通过检查 $J$ 是否接近其转置 $J^T$ 来验证 $J$ 是否对称。\n\n实现将遵循这些步骤来生成所需的输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases, assembling Picard and Newton\n    matrices, and computing their properties.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (8, 0.0, lambda x: np.sin(np.pi * x)),\n        (32, 0.5, lambda x: np.sin(np.pi * x)),\n        (64, 2.0, lambda x: 1 + np.sin(2 * np.pi * x)),\n    ]\n\n    results = []\n    \n    for n, alpha, f_func in test_cases:\n        # 1. Setup grid and initial iterate\n        h = 1.0 / (n + 1)\n        x_nodes = np.arange(1, n + 1) * h\n        u_k = alpha * np.sin(np.pi * x_nodes)\n        \n        # Create an extended u vector including boundary values u_0 = u_{n+1} = 0\n        u_ext = np.concatenate(([0.0], u_k, [0.0]))\n\n        # Pre-calculate edge-centered coefficients a_{i+1/2}\n        # a_coeffs[i] corresponds to a_{i+1/2} where i is from 0 to n\n        a_coeffs = 1.0 + 0.5 * (u_ext[:-1]**2 + u_ext[1:]**2)\n        \n        # 2. Assemble Picard Matrix A_Pic\n        # Main diagonal of A_Pic\n        diag_p = (a_coeffs[1:] + a_coeffs[:-1]) / h**2\n        # Off-diagonal of A_Pic (symmetric matrix)\n        off_diag_p = -a_coeffs[1:-1] / h**2\n        \n        A_pic = np.diag(diag_p) + np.diag(off_diag_p, k=1) + np.diag(off_diag_p, k=-1)\n\n        # 3. Assemble Newton Jacobian J\n        # Main diagonal of J\n        u_i = u_ext[1:-1]\n        u_im1 = u_ext[:-2]\n        u_ip1 = u_ext[2:]\n        term = -u_i * (u_ip1 - 2*u_i + u_im1)\n        diag_j = (a_coeffs[1:] + a_coeffs[:-1] + term) / h**2\n\n        # Super-diagonal of J\n        term_s = -u_ip1[:-1] * (u_ip1[:-1] - u_i[:-1])\n        super_diag_j = (-a_coeffs[1:-1] + term_s) / h**2\n\n        # Sub-diagonal of J\n        term_l = u_im1[1:] * (u_i[1:] - u_im1[1:])\n        sub_diag_j = (-a_coeffs[1:-1] + term_l) / h**2\n        \n        J = np.diag(diag_j) + np.diag(super_diag_j, k=1) + np.diag(sub_diag_j, k=-1)\n\n        # 4. Compute required values\n        cond_p = np.linalg.cond(A_pic, 2)\n        cond_j = np.linalg.cond(J, 2)\n        ratio = cond_j / cond_p\n        \n        # Check SPD for A_pic.\n        # It is symmetric by construction, so we only check positive definiteness.\n        # Use eigvalsh for symmetric matrices. Small tolerance for floating point.\n        eigvals_p = np.linalg.eigvalsh(A_pic)\n        is_spd = np.all(eigvals_p > 1e-12)\n\n        # Check symmetry for J using a standard tolerance\n        is_sym_j = np.allclose(J, J.T)\n        \n        # Append formatted results\n        results.extend([\n            f\"{cond_p:.6f}\",\n            f\"{cond_j:.6f}\",\n            f\"{ratio:.6f}\",\n            str(is_spd),\n            str(is_sym_j),\n        ])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3431358"}, {"introduction": "虽然牛顿法能提供快速的二次收敛，但这通常只在解的一个小邻域内得到保证。相比之下，更简单的Picard迭代虽然收敛速度是线性的，但通常表现出更稳健的全局收敛行为。一个强大且广泛应用的实用策略是结合两者的优点：首先使用稳健的Picard方法生成一个相当接近最终解的初始猜测，然后切换到快速收敛的牛顿法进行精化。本实践将引导你实现这样一个混合求解器，并根据Picard迭代的收敛行为设计一个智能的切换准则 [@problem_id:3431395]。", "problem": "考虑定义在区间 $[0,1]$ 上的稳态一维非线性反应扩散边值问题，其边界条件为齐次 Dirichlet 边界条件。令 $u:[0,1]\\to\\mathbb{R}$ 为未知函数。该偏微分方程 (PDE) 为\n$$\n-\\frac{d^2 u}{dx^2} + \\beta\\, u^3 = f(x), \\quad x\\in(0,1), \\quad u(0) = 0, \\quad u(1) = 0,\n$$\n其中 $\\beta>0$ 是一个给定参数，$f$ 是一个给定的源项。\n\n使用标准二阶中心有限差分法在 $N$ 个内部网格点上对该偏微分方程进行离散化，网格尺寸为 $h = \\frac{1}{N+1}$，网格节点为 $x_i = i h$ ($i=1,\\dots,N$)，并采用齐次 Dirichlet 边界条件 $u_0 = u_{N+1}=0$。令 $\\mathbf{u}\\in\\mathbb{R}^N$ 为节点值 $u_i \\approx u(x_i)$ 组成的向量，并定义离散拉普拉斯矩阵 $\\mathbf{K}\\in\\mathbb{R}^{N\\times N}$ 为\n$$\n\\mathbf{K} = \\frac{1}{h^2}\\begin{bmatrix}\n2  -1    \\\\\n-1  2  -1   \\\\\n \\ddots  \\ddots  \\ddots  \\\\\n  -1  2  -1 \\\\\n   -1  2\n\\end{bmatrix}.\n$$\n令离散残差映射 $\\mathbf{F}:\\mathbb{R}^N\\to\\mathbb{R}^N$ 为\n$$\n\\mathbf{F}(\\mathbf{u}) = \\mathbf{K}\\,\\mathbf{u} + \\beta\\, \\mathbf{u}^{\\odot 3} - \\mathbf{f},\n$$\n其中 $\\mathbf{u}^{\\odot 3}$ 表示逐元素立方，$\\mathbf{f}\\in\\mathbb{R}^N$ 是离散载荷向量 $f_i = f(x_i)$。\n\n考虑用于求解非线性系统 $\\mathbf{F}(\\mathbf{u})=\\mathbf{0}$ 的两种迭代求解器：\n- Picard 迭代：给定 $\\mathbf{u}^{(k)}$，构造对称正定 (SPD) 矩阵\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)}) = \\mathbf{K} + \\beta\\,\\mathrm{diag}\\!\\left(\\big(\\mathbf{u}^{(k)}\\big)^{\\odot 2}\\right),\n$$\n并将 $\\mathbf{u}^{(k+1)}$ 计算为线性系统\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{u}^{(k+1)} = \\mathbf{f}\n$$\n的解。\n- Newton–Raphson 迭代：给定 $\\mathbf{u}^{(k)}$，构造雅可比矩阵\n$$\n\\mathbf{J}(\\mathbf{u}^{(k)}) = \\mathbf{K} + 3\\beta\\,\\mathrm{diag}\\!\\left(\\big(\\mathbf{u}^{(k)}\\big)^{\\odot 2}\\right),\n$$\n求解\n$$\n\\mathbf{J}(\\mathbf{u}^{(k)})\\, \\boldsymbol{\\delta}^{(k)} = -\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big),\n$$\n中的更新量 $\\boldsymbol{\\delta}^{(k)}$，并设置 $\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + \\boldsymbol{\\delta}^{(k)}$。\n\n定义 Picard 增量 $\\mathbf{d}^{(k)} = \\mathbf{u}^{(k+1)} - \\mathbf{u}^{(k)}$ 和 Picard 收缩因子\n$$\nc_k = \\frac{\\left\\|\\mathbf{d}^{(k)}\\right\\|_2}{\\left\\|\\mathbf{d}^{(k-1)}\\right\\|_2}, \\quad k\\ge 1.\n$$\n通过定义\n$$\n\\gamma_k = \\frac{\\left\\|\\mathbf{d}^{(k)}\\right\\|_2}{\\left\\|\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2}.\n$$\n来设计一个基于残差的指标。\n实现一个从 Picard 迭代切换到 Newton–Raphson 迭代的规则，该规则在 Picard 收缩因子稳定（通过准则\n$$\n\\left|c_k - c_{k-1}\\right| \\le \\varepsilon_c,\n$$\n实施）且基于残差的指标稳定（\n$$\n\\left|\\gamma_k - \\gamma_{k-1}\\right| \\le \\varepsilon_\\gamma,\n$$\n）时触发，其中 $\\varepsilon_c>0$ 和 $\\varepsilon_\\gamma>0$ 为给定的小阈值。\n\n从 $\\mathbf{u}^{(0)} = \\mathbf{0}$ 开始，应用 Picard 迭代直到满足切换规则，然后切换到 Newton–Raphson 迭代，直到离散残差范数 $\\left\\|\\mathbf{F}(\\mathbf{u})\\right\\|_2$ 低于容差 $T>0$ 或达到固定的最大迭代次数。使用以下源项：\n$$\nf(x) = \\sin(\\pi x),\n$$\n以及以下参数集 $(N,\\beta)$ 的测试套件：\n- 测试用例 1 (理想情况)：$(N,\\beta) = (32,\\, 1.0)$。\n- 测试用例 2 (更强的非线性)：$(N,\\beta) = (32,\\, 4.0)$。\n- 测试用例 3 (更粗的网格)：$(N,\\beta) = (16,\\, 0.5)$。\n\n对于每个测试用例，在切换迭代索引 $k_\\star$ 处，计算：\n- 基于残差的指标 $\\gamma_{k_\\star}$。\n- 雅可比矩阵的逆 Lipschitz 常数，对于 SPD 矩阵，这被解释为逆矩阵在欧几里得范数下的算子范数，\n$$\n\\left\\|\\mathbf{J}\\big(\\mathbf{u}^{(k_\\star)}\\big)^{-1}\\right\\|_2 = \\frac{1}{\\lambda_{\\min}\\!\\big(\\mathbf{J}(\\mathbf{u}^{(k_\\star)})\\big)},\n$$\n其中 $\\lambda_{\\min}(\\cdot)$ 表示最小特征值。\n\n对于每个测试用例，你的程序必须输出比率\n$$\nq = \\frac{\\gamma_{k_\\star}}{\\left\\|\\mathbf{J}\\big(\\mathbf{u}^{(k_\\star)}\\big)^{-1}\\right\\|_2},\n$$\n作为一个浮点数。最终输出必须是一行，其中包含测试套件的三个比率，形式为逗号分隔的列表，并用方括号括起来，例如 $[q_1,q_2,q_3]$。\n\n数学任务：\n- 从离散算子和迭代方案的定义出发，推导关系\n$$\n\\mathbf{d}^{(k)} = -\\mathbf{M}\\big(\\mathbf{u}^{(k)}\\big)^{-1}\\,\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big),\n$$\n并证明基于残差的指标 $\\gamma_k$ 等于 $\\mathbf{M}\\big(\\mathbf{u}^{(k)}\\big)^{-1}$ 应用于离散残差时的方向算子范数。证明对于 $\\beta>0$，雅可比矩阵对所有 $\\mathbf{u}$ 满足 Loewner 序 $\\mathbf{J}(\\mathbf{u}) \\succeq \\mathbf{M}(\\mathbf{u})$，这意味着\n$$\n\\left\\|\\mathbf{J}(\\mathbf{u})^{-1}\\right\\|_2 \\le \\left\\|\\mathbf{M}(\\mathbf{u})^{-1}\\right\\|_2.\n$$\n由此得出结论：$\\gamma_k$ 的稳定等价于雅可比矩阵逆 Lipschitz 常数的上界估计的稳定，并解释为什么在所述的稳定准则下触发切换，是由 Picard 迭代在解附近的局部线性行为所证明是合理的。\n\n实现要求：\n- 使用 $\\varepsilon_c = 10^{-3}$，$\\varepsilon_\\gamma = 10^{-3}$，最大 Picard 迭代次数为 $100$，Newton 容差为 $T=10^{-10}$ 且最大 Newton 迭代次数为 $100$。\n- 所有计算都应在一致的无量纲项中进行；不需要物理单位。\n- 你的程序应生成一行输出，其中包含按上述测试用例顺序列出的结果，形式为逗号分隔的列表并用方括号括起来。", "solution": "问题陈述已经过分析，并被认为是有效的。它在非线性偏微分方程的数值分析领域具有科学依据，是适定的，并提供了一套完整且一致的定义、参数和目标。\n\n我们将首先处理所需的数学推导和论证，然后概述数值计算的算法。\n\n令离散非线性系统为 $\\mathbf{F}(\\mathbf{u}) = \\mathbf{0}$，其中残差映射 $\\mathbf{F}:\\mathbb{R}^N\\to\\mathbb{R}^N$ 由下式给出\n$$\n\\mathbf{F}(\\mathbf{u}) = \\mathbf{K}\\,\\mathbf{u} + \\beta\\, \\mathbf{u}^{\\odot 3} - \\mathbf{f}.\n$$\n此处，$\\mathbf{u} \\in \\mathbb{R}^N$ 是未知量向量，$\\mathbf{K} \\in \\mathbb{R}^{N \\times N}$ 是对称正定 (SPD) 的离散拉普拉斯算子，$\\beta > 0$ 是一个常数，$\\mathbf{u}^{\\odot 3}$ 表示向量 $\\mathbf{u}$ 的逐元素立方，$\\mathbf{f} \\in \\mathbb{R}^N$ 是离散化源项。\n\n### 1. 数学推导与分析\n\n**Picard 增量的关系式**\n\nPicard 迭代通过求解线性系统 $\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{u}^{(k+1)} = \\mathbf{f}$ 来获得下一个迭代值 $\\mathbf{u}^{(k+1)}$，给定当前迭代值 $\\mathbf{u}^{(k)}$。矩阵 $\\mathbf{M}(\\mathbf{u}^{(k)})$ 由下式给出\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)}) = \\mathbf{K} + \\beta\\,\\mathrm{diag}\\!\\left(\\big(\\mathbf{u}^{(k)}\\big)^{\\odot 2}\\right).\n$$\nPicard 增量定义为 $\\mathbf{d}^{(k)} = \\mathbf{u}^{(k+1)} - \\mathbf{u}^{(k)}$。为了推导所要求的关系式，我们对 Picard 步骤的定义进行操作：\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{u}^{(k+1)} = \\mathbf{f}.\n$$\n我们从两侧减去 $\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{u}^{(k)}$：\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)}) \\left(\\mathbf{u}^{(k+1)} - \\mathbf{u}^{(k)}\\right) = \\mathbf{f} - \\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{u}^{(k)}.\n$$\n左手边是 $\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{d}^{(k)}$。对于右手边，我们代入 $\\mathbf{M}(\\mathbf{u}^{(k)})$ 的定义：\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{d}^{(k)} = \\mathbf{f} - \\left(\\mathbf{K} + \\beta\\,\\mathrm{diag}\\!\\left(\\big(\\mathbf{u}^{(k)}\\big)^{\\odot 2}\\right)\\right)\\mathbf{u}^{(k)}.\n$$\n注意到对于任何向量 $\\mathbf{v}$，$\\mathrm{diag}(\\mathbf{v}^{\\odot 2})\\mathbf{v} = \\mathbf{v}^{\\odot 3}$，我们有：\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{d}^{(k)} = \\mathbf{f} - \\left(\\mathbf{K}\\mathbf{u}^{(k)} + \\beta\\left(\\mathbf{u}^{(k)}\\right)^{\\odot 3}\\right).\n$$\n括号中的项根据定义是 $\\mathbf{F}(\\mathbf{u}^{(k)}) + \\mathbf{f}$。因此，\n$$\n\\mathbf{M}(\\mathbf{u}^{(k)})\\, \\mathbf{d}^{(k)} = \\mathbf{f} - (\\mathbf{F}(\\mathbf{u}^{(k)}) + \\mathbf{f}) = -\\mathbf{F}(\\mathbf{u}^{(k)}).\n$$\n由于 $\\mathbf{K}$ 是对称正定的，且 $\\beta\\,\\mathrm{diag}\\!\\left(\\big(\\mathbf{u}^{(k)}\\big)^{\\odot 2}\\right)$ 是一个半正定对角矩阵，它们的和 $\\mathbf{M}(\\mathbf{u}^{(k)})$ 是对称正定的，因此是可逆的。我们可以解出 $\\mathbf{d}^{(k)}$：\n$$\n\\mathbf{d}^{(k)} = -\\mathbf{M}\\big(\\mathbf{u}^{(k)}\\big)^{-1}\\,\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big).\n$$\n推导至此完成。\n\n**对基于残差的指标 $\\gamma_k$ 的解释**\n\n指标 $\\gamma_k$ 定义为\n$$\n\\gamma_k = \\frac{\\left\\|\\mathbf{d}^{(k)}\\right\\|_2}{\\left\\|\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2}.\n$$\n使用上一节的结果，我们可以写出\n$$\n\\gamma_k = \\frac{\\left\\|-\\mathbf{M}\\big(\\mathbf{u}^{(k)}\\big)^{-1}\\,\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2}{\\left\\|\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2} = \\frac{\\left\\|\\mathbf{M}\\big(\\mathbf{u}^{(k)}\\big)^{-1}\\,\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2}{\\left\\|\\mathbf{F}\\big(\\mathbf{u}^{(k)}\\big)\\right\\|_2}.\n$$\n这个量度量了矩阵 $\\mathbf{M}(\\mathbf{u}^{(k)})^{-1}$ 应用于特定向量 $\\mathbf{F}(\\mathbf{u}^{(k)})$ 时的放大因子。它不是算子范数 $\\left\\|\\mathbf{M}(\\mathbf{u}^{(k)})^{-1}\\right\\|_2$，该范数是在所有可能的非零向量上的最大放大率。相反，它可以被描述为算子 $\\mathbf{M}(\\mathbf{u}^{(k)})^{-1}$ 在由残差向量 $\\mathbf{F}(\\mathbf{u}^{(k)})$ 张成的一维子空间上的范数。因此，它提供了 Picard 更新对当前残差响应的一个方向性度量。\n\n**雅可比矩阵和 Picard 矩阵的 Loewner 序**\n\n残差映射 $\\mathbf{F}(\\mathbf{u})$ 的雅可比矩阵是偏导数矩阵，$\\mathbf{J}_{ij}(\\mathbf{u}) = \\frac{\\partial F_i}{\\partial u_j}$。\n$$\nF_i(\\mathbf{u}) = \\sum_{j=1}^N K_{ij}u_j + \\beta u_i^3 - f_i.\n$$\n偏导数为：\n$$\n\\frac{\\partial F_i}{\\partial u_j} = K_{ij} + 3\\beta u_i^2 \\delta_{ij},\n$$\n其中 $\\delta_{ij}$ 是克罗内克 δ。以矩阵形式表示为：\n$$\n\\mathbf{J}(\\mathbf{u}) = \\mathbf{K} + 3\\beta\\,\\mathrm{diag}\\!\\left(\\mathbf{u}^{\\odot 2}\\right).\n$$\n为证明 Loewner 序 $\\mathbf{J}(\\mathbf{u}) \\succeq \\mathbf{M}(\\mathbf{u})$，我们必须证明差分矩阵 $\\mathbf{J}(\\mathbf{u}) - \\mathbf{M}(\\mathbf{u})$ 是半正定的 (PSD)。\n$$\n\\mathbf{J}(\\mathbf{u}) - \\mathbf{M}(\\mathbf{u}) = \\left(\\mathbf{K} + 3\\beta\\,\\mathrm{diag}\\!\\left(\\mathbf{u}^{\\odot 2}\\right)\\right) - \\left(\\mathbf{K} + \\beta\\,\\mathrm{diag}\\!\\left(\\mathbf{u}^{\\odot 2}\\right)\\right) = 2\\beta\\,\\mathrm{diag}\\!\\left(\\mathbf{u}^{\\odot 2}\\right).\n$$\n这个差是一个对角矩阵。其对角线元素为 $2\\beta (u_i)^2$。由于 $\\beta > 0$ 且对所有 $i=1,\\dots,N$ 都有 $(u_i)^2 \\ge 0$，所有对角线元素都是非负的。一个对角线上元素非负的对角矩阵，根据定义是半正定的。因此，$\\mathbf{J}(\\mathbf{u}) \\succeq \\mathbf{M}(\\mathbf{u})$。\n\n矩阵分析中的一个标准结果表明，如果 $\\mathbf{A}$ 和 $\\mathbf{B}$ 是对称正定矩阵且 $\\mathbf{A} \\succeq \\mathbf{B}$，那么 $\\mathbf{B}^{-1} \\succeq \\mathbf{A}^{-1}$。由于 $\\mathbf{J}(\\mathbf{u})$ 和 $\\mathbf{M}(\\mathbf{u})$ 对任何 $\\mathbf{u}$ 都是对称正定的（因为它们是对称正定矩阵 $\\mathbf{K}$ 和一个半正定对角矩阵的和），我们可以应用这个结果得出 $\\mathbf{M}(\\mathbf{u})^{-1} \\succeq \\mathbf{J}(\\mathbf{u})^{-1}$。这意味着对于任何向量 $\\mathbf{v}$，$\\mathbf{v}^T \\mathbf{M}(\\mathbf{u})^{-1} \\mathbf{v} \\ge \\mathbf{v}^T \\mathbf{J}(\\mathbf{u})^{-1} \\mathbf{v}$。\n对于任何对称正定矩阵 $\\mathbf{S}$，算子 2-范数为 $\\|\\mathbf{S}\\|_2 = \\lambda_{\\max}(\\mathbf{S})$。由于 $\\mathbf{M}(\\mathbf{u})^{-1} - \\mathbf{J}(\\mathbf{u})^{-1}$ 是半正定的，其特征值非负，所以 $\\lambda_{\\max}(\\mathbf{M}(\\mathbf{u})^{-1} - \\mathbf{J}(\\mathbf{u})^{-1}) \\ge 0$。这导致 $\\lambda_{\\max}(\\mathbf{M}(\\mathbf{u})^{-1}) \\ge \\lambda_{\\max}(\\mathbf{J}(\\mathbf{u})^{-1})$，从而直接推导出：\n$$\n\\left\\|\\mathbf{M}(\\mathbf{u})^{-1}\\right\\|_2 \\ge \\left\\|\\mathbf{J}(\\mathbf{u})^{-1}\\right\\|_2.\n$$\n正如问题所述，对于对称正定 (SPD) 矩阵，逆矩阵的范数也由原矩阵最小特征值的倒数给出。因此，$\\frac{1}{\\lambda_{\\min}(\\mathbf{M}(\\mathbf{u}))} \\ge \\frac{1}{\\lambda_{\\min}(\\mathbf{J}(\\mathbf{u}))}$。\n\n**切换规则的合理性论证**\n\n在求解非线性系统时，从 Picard 迭代切换到 Newton-Raphson 迭代是一种常用技术。\n- **Picard 迭代：** 这是一种定点迭代。它通常表现出全局收敛性（或至少有较大的吸引盆），但收敛速度仅为线性。收敛率由迭代的雅可比矩阵的谱半径决定。\n- **Newton-Raphson 迭代：** 当迭代值足够接近解时，该方法二次收敛，但如果初始点远离解则可能发散。\n\n混合策略利用了两者的优点：使用鲁棒的 Picard 方法生成一系列趋近解的迭代值，一旦迭代值进入 Newton 方法的二次收敛盆，就切换到后者以实现快速收敛。挑战在于确定何时切换。\n\n所提出的切换准则是基于监测 Picard 迭代的收敛行为。\n$1.$ **收缩因子 $c_k$ 的稳定：** 量 $c_k = \\|\\mathbf{d}^{(k)}\\|_2 / \\|\\mathbf{d}^{(k-1)}\\|_2$ 是线性收敛率的经验度量。当迭代进入其渐近线性收敛阶段时，该比率趋于一个常数值。准则 $|c_k - c_{k-1}| \\le \\varepsilon_c$ 检查这种稳定情况，表明迭代已进入一个可预测的线性区域。\n$2.$ **基于残差的指标 $\\gamma_k$ 的稳定：** 量 $\\gamma_k$ 作为 $\\mathbf{M}(\\mathbf{u}^{(k)})^{-1}$ 范数的一个方向性探针。随着 $\\mathbf{u}^{(k)}$ 趋近一个极限，我们期望 $\\mathbf{M}(\\mathbf{u}^{(k)})$ 和残差向量 $\\mathbf{F}(\\mathbf{u}^{(k)})$ 的方向趋于稳定。因此，$\\gamma_k$ 也应趋于一个常数值。准则 $|\\gamma_k - \\gamma_{k-1}| \\le \\varepsilon_\\gamma$ 检测这种稳定。\n\n正如我们已经证明的，$\\left\\|\\mathbf{M}(\\mathbf{u})^{-1}\\right\\|_2$ 为 $\\left\\|\\mathbf{J}(\\mathbf{u})^{-1}\\right\\|_2$ 提供了一个上界。Newton 方法的局部收敛理论取决于雅可比矩阵及其逆矩阵在解附近的性质。$\\gamma_k$ 的稳定表明一个相关量，即逆雅可比矩阵范数估计的上界，也已稳定。\n\n综上所述，$c_k$ 和 $\\gamma_k$ 的稳定提供了一个强有力的启发式方法，表明 Picard 迭代已很好地进入了线性收敛区域，其中局部动力学是稳定且可预测的。这种稳定性意味着当前迭代值 $\\mathbf{u}^{(k)}$ 可能已足够接近真实解，使得 Newton-Raphson 方法能够二次收敛。因此，在此时切换是加速收敛的一个合理论证的策略。\n\n### 2. 算法实现\n\n对于每个测试用例 $(N, \\beta)$，算法按以下步骤进行：\n1.  **初始化：** 设置网格参数 $h = 1/(N+1)$，构建网格点 $x_i$、离散拉普拉斯矩阵 $\\mathbf{K}$ 和源向量 $\\mathbf{f}$。初始化解向量 $\\mathbf{u} = \\mathbf{0}$，并设置数据结构以存储增量、收缩因子和 gamma 指标的历史记录。\n2.  **迭代求解器：** 进入主循环，直到收敛或达到最大迭代次数。\n3.  **Picard 阶段：** 对于初始迭代（最多 $100$ 次或直到触发切换）：\n    a. 计算残差 $\\mathbf{F}(\\mathbf{u}^{(k)})$。\n    b. 构建 Picard 矩阵 $\\mathbf{M}(\\mathbf{u}^{(k)})$。\n    c. 求解线性系统 $\\mathbf{M}(\\mathbf{u}^{(k)}) \\mathbf{u}^{(k+1)} = \\mathbf{f}$ 以找到下一个迭代值 $\\mathbf{u}^{(k+1)}$。\n    d. 计算增量 $\\mathbf{d}^{(k)} = \\mathbf{u}^{(k+1)} - \\mathbf{u}^{(k)}$ 及其范数。\n    e. 计算 $\\gamma_k$，如果 $k \\ge 1$，则计算 $c_k$。存储这些值。\n    f. 如果 $k \\ge 2$，检查切换条件：$|c_k - c_{k-1}| \\le \\varepsilon_c$ 和 $|\\gamma_k - \\gamma_{k-1}| \\le \\varepsilon_\\gamma$。\n    g. 如果条件满足，则当前为切换迭代 $k_\\star = k$。\n        i.  存储 $\\gamma_{k_\\star} = \\gamma_k$。\n        ii. 使用当前迭代值 $\\mathbf{u}^{(k)}$ 构建雅可比矩阵 $\\mathbf{J}(\\mathbf{u}^{(k_\\star)})$。\n        iii.计算其最小特征值 $\\lambda_{\\min}$ 和逆矩阵范数 $\\left\\|\\mathbf{J}^{-1}\\right\\|_2 = 1/\\lambda_{\\min}$。\n        iv. 计算比率 $q = \\gamma_{k_\\star} / \\left\\|\\mathbf{J}^{-1}\\right\\|_2$。\n        v.  设置一个标志为 `True` 以表示已发生切换。\n    h. 更新 $\\mathbf{u} \\leftarrow \\mathbf{u}^{(k+1)}$。\n4.  **Newton-Raphson 阶段：** 一旦切换标志被设置，对于所有后续迭代：\n    a. 计算残差 $\\mathbf{F}(\\mathbf{u}^{(k)})$。检查其范数是否低于容差 $T=10^{-10}$。如果是，则终止。\n    b. 构建雅可比矩阵 $\\mathbf{J}(\\mathbf{u}^{(k)})$。\n    c. 求解线性系统 $\\mathbf{J}(\\mathbf{u}^{(k)}) \\boldsymbol{\\delta}^{(k)} = -\\mathbf{F}(\\mathbf{u}^{(k)})$ 以获得更新量 $\\boldsymbol{\\delta}^{(k)}$。\n    d. 更新解 $\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + \\boldsymbol{\\delta}^{(k)}$。\n5.  **输出：** 在给定测试用例的循环终止后，存储计算出的 $q$ 值。最终输出是所有测试用例的这些 $q$ 值的列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the nonlinear reaction-diffusion problem using a hybrid Picard/Newton-Raphson method\n    and computes the specified ratio q at the switching point for three test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (32, 1.0),  # Test case 1\n        (32, 4.0),  # Test case 2\n        (16, 0.5),  # Test case 3\n    ]\n\n    # Implementation parameters\n    eps_c = 1e-3\n    eps_gamma = 1e-3\n    max_picard_iter = 100\n    max_newton_iter = 100\n    newton_tol = 1e-10\n\n    results = []\n\n    for N, beta in test_cases:\n        # --- Setup for the current test case ---\n        h = 1.0 / (N + 1)\n        x_nodes = np.linspace(h, 1.0 - h, N)\n        f_vec = np.sin(np.pi * x_nodes)\n        \n        # Construct the discrete Laplacian matrix K\n        diag_main = np.full(N, 2.0)\n        diag_sub = np.ones(N - 1)\n        K = (np.diag(diag_main) - np.diag(diag_sub, k=1) - np.diag(diag_sub, k=-1)) / h**2\n\n        # --- Iteration Initialization ---\n        u = np.zeros(N)\n        switched = False\n        q_ratio = np.nan  # Use NaN as a sentinel for the result\n\n        d_norm_hist = []\n        c_hist = []\n        gamma_hist = []\n        \n        total_max_iter = max_picard_iter + max_newton_iter\n\n        # Combined Picard/Newton iteration loop\n        for k in range(total_max_iter):\n            \n            # Since u is updated at the end of the loop, u here is u^(k)\n            # The residual F(u^(k)) is needed by both methods\n            F_u = K @ u + beta * u**3 - f_vec\n            norm_F = np.linalg.norm(F_u)\n\n            if norm_F < newton_tol:\n                break # Converged\n\n            # --- Picard Phase ---\n            if not switched and k < max_picard_iter:\n                u_sq = u**2\n                M_u = K + beta * np.diag(u_sq)\n                \n                try:\n                    u_next = np.linalg.solve(M_u, f_vec)\n                except np.linalg.LinAlgError:\n                    # In case of instability, break and result in NaN\n                    break\n                \n                d = u_next - u\n                norm_d = np.linalg.norm(d)\n                d_norm_hist.append(norm_d)\n                \n                gamma_k = norm_d / norm_F if norm_F > 0 else 0.0\n                gamma_hist.append(gamma_k)\n\n                if k >= 1:\n                    norm_d_prev = d_norm_hist[k-1]\n                    c_k = norm_d / norm_d_prev if norm_d_prev > 0 else 0.0\n                    c_hist.append(c_k)\n\n                # Check for switch condition, requires k>=2 for c_k and c_{k-1}\n                if k >= 2:\n                    c_k_val = c_hist[-1]\n                    c_k_minus_1_val = c_hist[-2]\n                    gamma_k_val = gamma_hist[-1]\n                    gamma_k_minus_1_val = gamma_hist[-2]\n\n                    if abs(c_k_val - c_k_minus_1_val) <= eps_c and \\\n                       abs(gamma_k_val - gamma_k_minus_1_val) <= eps_gamma:\n                        \n                        switched = True\n                        k_star = k\n                        \n                        # --- Compute q at the switching point k_star ---\n                        # Use gamma at k_star\n                        gamma_k_star = gamma_k_val\n\n                        # Use u at k_star (which is the current u)\n                        u_star = u\n                        u_star_sq = u_star**2\n                        J_u_star = K + 3 * beta * np.diag(u_star_sq)\n                        \n                        # J_u_star is symmetric, use eigvalsh for efficiency and stability\n                        eigenvalues = np.linalg.eigvalsh(J_u_star)\n                        lambda_min = np.min(eigenvalues)\n\n                        norm_J_inv = 1.0 / lambda_min\n                        \n                        q_ratio = gamma_k_star / norm_J_inv\n\n                # Update state for the next iteration\n                u = u_next \n\n            # --- Newton-Raphson Phase ---\n            else:\n                u_sq = u**2\n                J_u = K + 3.0 * beta * np.diag(u_sq)\n                \n                try:\n                    delta = np.linalg.solve(J_u, -F_u)\n                except np.linalg.LinAlgError:\n                    break\n                \n                u = u + delta\n        \n        results.append(q_ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3431395"}, {"introduction": "在求解参数化的非线性方程组时，一个重大的挑战是“转折点”或“折叠分岔”的存在，此时解的路径会折回。在这些点上，雅可比矩阵会变得奇异，导致像Picard迭代甚至基本牛顿法这样的标准定参数方法失效。这个高级实践将通过经典的Bratu方程来演示如何克服这一挑战 [@problem_id:3431387]。你将实现并对比一个简单的带阻尼的Picard迭代和一个基于牛顿迭代构建的、更为强大的伪弧长延拓方法，后者能让你追踪穿过转折点的完整解分支，从而深刻体会路径跟踪算法的威力。", "problem": "考虑由 Bratu 方程给出的非线性边值问题的单参数族，这是一个参数化偏微分方程中折叠（转折点）分岔的原型模型：\n$$\n\\text{求 } u: [0,1] \\to \\mathbb{R} \\text{ 使得 } u''(x) + \\lambda \\exp(u(x)) = 0,\\quad u(0) = 0,\\quad u(1) = 0,\n$$\n其中 $\\lambda \\in \\mathbb{R}$ 是一个延拓参数。我们通过在具有 $N$ 个内部点的均匀网格上进行有限差分法离散化来寻求数值解。设 $h = \\frac{1}{N+1}$，并设 $u \\in \\mathbb{R}^N$ 为内部节点 $x_i = ih$, $i=1,\\dots,N$ 处的未知数向量。半离散非线性系统为\n$$\nF(u,\\lambda) = L u + \\lambda \\exp(u) = 0,\n$$\n其中 $L \\in \\mathbb{R}^{N \\times N}$ 是带狄利克雷边界条件的拉普拉斯算子的标准二阶中心差分近似，\n$$\nL = \\frac{1}{h^2}\n\\begin{bmatrix}\n-2  1                   \\\\\n1   -2  1               \\\\\n    \\ddots  \\ddots  \\ddots  \\\\\n            1       -2  1 \\\\\n                    1  -2\n\\end{bmatrix},\n$$\n且 $\\exp(u)$ 表示元素为 $\\exp(u_i)$ 的向量。\n\n你将实现并比较两种迭代策略：\n\n1. 带自适应松弛的 Picard 迭代（阻尼不动点法）：\n   从初始猜测 $u^{(0)}$ 开始，定义线性泊松求解\n   $$\n   L \\tilde{u}^{(k+1)} = -\\lambda \\exp\\left(u^{(k)}\\right),\n   $$\n   然后使用松弛法更新\n   $$\n   u^{(k+1)} = (1-\\omega^{(k)}) u^{(k)} + \\omega^{(k)} \\tilde{u}^{(k+1)},\n   $$\n   其中松弛参数 $\\omega^{(k)} \\in (0,1]$ 在每次迭代中自适应地选择，以确保残差范数 $\\lVert F(u^{(k+1)},\\lambda)\\rVert_2$ 减小（对 $\\omega^{(k)}$ 使用简单的回溯策略）。\n\n2. 带伪弧长延拓的 Newton–Raphson 方法：\n   对于固定的 $\\lambda$，标准的 Newton–Raphson 方法求解\n   $$\n   J(u,\\lambda) \\,\\delta u = -F(u,\\lambda), \\quad \\text{其中 } J(u,\\lambda) = L + \\lambda \\operatorname{diag}(\\exp(u)),\n   $$\n   并更新 $u \\leftarrow u + \\delta u$。为了追踪解分支穿过转折点，使用伪弧长延拓：给定两个先前收敛的解 $(u_0,\\lambda_0)$ 和 $(u_1,\\lambda_1)$，定义基于割线的切线\n   $$\n   s = \\frac{1}{\\sqrt{\\lVert u_1 - u_0 \\rVert_2^2 + (\\lambda_1 - \\lambda_0)^2}} \\left( u_1 - u_0, \\ \\lambda_1 - \\lambda_0 \\right),\n   $$\n   形成一个预测步 $(u_{\\mathrm{pred}},\\lambda_{\\mathrm{pred}}) = (u_1,\\lambda_1) + d s$，其中 $d>0$ 是弧长步长，并通过对增广系统应用牛顿法进行校正\n   $$\n   \\begin{cases}\n   F(u,\\lambda) = 0, \\\\\n   \\langle u - u_{\\mathrm{pred}}, s_u \\rangle + (\\lambda - \\lambda_{\\mathrm{pred}}) s_\\lambda = 0,\n   \\end{cases}\n   $$\n   其中 $s = (s_u,s_\\lambda)$ 且 $\\langle \\cdot,\\cdot \\rangle$ 是欧几里得内积。实现一个基于舒尔补的牛顿校正，该校正仅需求解与 $J(u,\\lambda)$ 相关的系统，并对完整步长 $(\\delta u,\\delta\\lambda)$ 应用 Armijo 型回溯，以确保增广系统残差的减小。\n\n你的任务是在所述的离散化上实现这两种方法，并运行以下测试套件。使用 $N=80$，欧几里得范数残差容差 $\\varepsilon = 10^{-8}$，Picard 迭代的最大迭代次数为 $1000$ 次，每次牛顿校正的最大迭代次数为 $50$ 次。在所有测试中，当未指定先前解时，使用零向量作为初始猜测。\n\n测试套件：\n\n- 测试 1（理想情况）：对于 $\\lambda = 1.0$，从 $u^{(0)} = 0$ 开始运行带自适应松弛的 Picard 迭代。返回一个布尔值，指示是否在迭代限制内达到了收敛（残差范数 $\\le \\varepsilon$）。\n\n- 测试 2（近转折点的定参数尝试）：对于 $\\lambda = 3.2$，从 $u^{(0)} = 0$ 开始运行带自适应松弛的 Picard 迭代。返回一个布尔值，指示是否在迭代限制内达到了收敛（残差范数 $\\le \\varepsilon$）。\n\n- 测试 3（伪弧长穿越）：使用标准的 Newton–Raphson 方法找到 $\\lambda_0 = 0.1$ 和 $\\lambda_1 = 0.2$ 处的解。以弧长步长 $d = 0.05$ 初始化伪弧长延拓，并运行 $40$ 个延拓步。返回一个布尔值，指示延拓是否穿过了一个转折点。转折点定义为参数序列的离散导数发生严格符号变化（即，$\\lambda$ 值的序列先严格增加，然后至少有一次严格减少）。\n\n- 测试 4（覆盖范围比较）：使用带自适应松弛的 Picard 进行朴素参数延拓：从 $\\lambda = 0.1$ 和步长 $\\Delta \\lambda = 0.1$ 开始，使用先前收敛的解作为初始猜测来递增 $\\lambda$，当 Picard 未能在迭代限制内收敛时停止。同时，使用如测试 3 中初始化的伪弧长延拓，并记录其轨迹上达到的最大 $\\lambda$。返回浮点数\n$$\n\\lambda_{\\max}^{\\mathrm{PA}} - \\lambda_{\\mathrm{last}}^{\\mathrm{Picard}},\n$$\n其中 $\\lambda_{\\max}^{\\mathrm{PA}}$ 是伪弧长延拓在其所有步骤中达到的最大 $\\lambda$值，而 $\\lambda_{\\mathrm{last}}^{\\mathrm{Picard}}$ 是 Picard 迭代收敛的最后一个 $\\lambda$ 值。将此答案表示为十进制数。\n\n你的程序应该产生单行输出，其中包含一个用方括号括起来的逗号分隔的结果列表（例如，\"[result1,result2,result3,result4]\"）。这四个条目必须分别是测试 1 到测试 4 的输出，顺序和类型如上所述。", "solution": "问题陈述是有效的。它提出了一个定义明确的数值分析任务，该任务基于求解非线性偏微分方程和分析其分岔的既定理论。所有参数和方法都足够清晰明确，可以进行唯一且可验证的实现。\n\n该问题围绕一维 Bratu 方程的数值解展开，这是一个自燃的典型模型，也是折叠（或转折点）分岔的经典例子。方程为\n$$\nu''(x) + \\lambda \\exp(u(x)) = 0, \\quad x \\in [0,1],\n$$\n带有齐次狄利克雷边界条件 $u(0) = u(1) = 0$。解 $u(x)$ 的行为关键取决于参数 $\\lambda$。\n\n首先，对连续问题进行离散化。我们在一个具有 $N$ 个内部点、间距为 $h = 1/(N+1)$ 的均匀网格上使用二阶中心有限差分格式。节点 $x_i$ 处的二阶导数 $u''(x_i)$ 近似为 $(u_{i-1} - 2u_i + u_{i+1})/h^2$。将此应用于每个内部节点 $i=1, \\dots, N$ 并结合边界条件 $u_0=u_{N+1}=0$，得到一个关于未知向量 $u = (u_1, \\dots, u_N)^T$ 的包含 $N$ 个非线性代数方程的系统。该系统以向量形式写作：\n$$\nF(u, \\lambda) = L u + \\lambda \\exp(u) = 0,\n$$\n其中 $L \\in \\mathbb{R}^{N \\times N}$ 是代表离散负拉普拉斯算子的稀疏三对角矩阵，$\\exp(u)$ 是逐元素指数函数。\n\n为求解这个非线性系统，将实现两种迭代方法。\n\n1.  **带自适应松弛的 Picard 迭代**：该方法是一种不动点迭代。系统 $Lu + \\lambda\\exp(u)=0$ 被重排为不动点形式 $u = -L^{-1}(\\lambda\\exp(u))$。因此，基本迭代为 $u^{(k+1)} = -L^{-1}(\\lambda \\exp(u^{(k)}))$。在实践中，我们求解线性系统 $L \\tilde{u}^{(k+1)} = -\\lambda \\exp(u^{(k)})$ 以得到 $\\tilde{u}^{(k+1)}$。对于 Bratu 问题，该迭代仅对较小的 $\\lambda$ 值收敛。为了扩展收敛半径，引入了松弛（或阻尼）步骤：\n    $$\n    u^{(k+1)} = (1-\\omega^{(k)}) u^{(k)} + \\omega^{(k)} \\tilde{u}^{(k+1)}.\n    $$\n    松弛参数 $\\omega^{(k)} \\in (0, 1]$ 在每次迭代 $k$ 中通过回溯搜索自适应地选择，以确保残差范数减小，即 $\\lVert F(u^{(k+1)}, \\lambda) \\rVert_2 < \\lVert F(u^{(k)}, \\lambda) \\rVert_2$。\n\n2.  **带伪弧长延拓的 Newton-Raphson 方法**：\n    对于一个固定的 $\\lambda$，牛顿法通过迭代求解一个关于校正量 $\\delta u$ 的线性系统来找到 $F(u, \\lambda)=0$ 的根。给定一个迭代点 $u^{(k)}$，更新 $u^{(k+1)} = u^{(k)} + \\delta u$ 是通过求解\n    $$\n    J(u^{(k)}, \\lambda) \\delta u = -F(u^{(k)}, \\lambda),\n    $$\n    得到的，其中 $J(u, \\lambda) = \\frac{\\partial F}{\\partial u} = L + \\lambda \\operatorname{diag}(\\exp(u))$ 是雅可比矩阵。牛顿法在 Bratu 曲线的转折点附近会失效，因为那里的雅可比矩阵 $J$ 变为奇异矩阵。\n\n    伪弧长延拓是一种强大的技术，用于追踪由弧长 $s$ 参数化的整个解曲线 $(u(s), \\lambda(s))$，包括穿过转折点。它由一个预测-校正序列组成：\n    -   **预测步**：通过从最后一个收敛点 $(u_1, \\lambda_1)$ 沿由最近两个点 $(u_0, \\lambda_0)$ 和 $(u_1, \\lambda_1)$ 定义的（归一化）割线向量 $s = (s_u, s_\\lambda)$ 进行外推，来对曲线上的下一个点做出初始猜测。预测值为 $(u_{\\mathrm{pred}}, \\lambda_{\\mathrm{pred}}) = (u_1, \\lambda_1) + d \\cdot s$，其中 $d$ 是弧长步长。\n    -   **校正步**：通过求解一个包含 $N+1$ 个方程、用于求解 $N+1$ 个未知数 $(u, \\lambda)$ 的增广系统，将预测点 $(u_{\\mathrm{pred}}, \\lambda_{\\mathrm{pred}})$ 校正回解曲线上。该系统将原始方程与一个弧长约束耦合起来，该约束将解约束在与切向量 $s$ 正交的超平面上：\n        $$\n        \\begin{cases}\n        F(u, \\lambda) = 0, \\\\\n        g(u,\\lambda) := \\langle u - u_{\\mathrm{pred}}, s_u \\rangle + (\\lambda - \\lambda_{\\mathrm{pred}}) s_\\lambda = 0.\n        \\end{cases}\n        $$\n    这个增广系统用牛顿法求解。其雅可比矩阵是一个在转折点处保持非奇异的增广矩阵。每个牛顿步骤中的线性求解通过舒尔补方法高效处理。对于系统 $\\begin{psmallmatrix} J & \\exp(u) \\\\ s_u^T & s_\\lambda \\end{psmallmatrix} \\begin{psmallmatrix} \\delta u \\\\ \\delta \\lambda \\end{psmallmatrix} = -\\begin{psmallmatrix} F \\\\ g \\end{psmallmatrix}$，我们首先求解两个只涉及原始雅可比矩阵 $J$ 的线性系统，以找到向量 $w_F=J^{-1}F$ 和 $w_\\lambda=J^{-1}\\exp(u)$。这样就可以显式地解出标量校正 $\\delta\\lambda$：\n    $$\n    \\delta\\lambda = \\frac{\\langle s_u, w_F \\rangle - g}{s_\\lambda - \\langle s_u, w_\\lambda \\rangle}.\n    $$\n    然后，向量校正 $\\delta u$ 可恢复为 $\\delta u = -w_F - \\delta\\lambda \\cdot w_\\lambda$。这种方法避免了直接构建和求解完整的 $(N+1) \\times (N+1)$ 增广系统，而是利用了求解稀疏矩阵 $J$ 的高效性。对步长进行回溯可确保校正步的稳健收敛。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\n\ndef solve():\n    \"\"\"\n    Implements and compares Picard and Newton-Raphson-based solvers for the\n    discretized Bratu equation, executing a predefined test suite.\n    \"\"\"\n    # --- Problem Parameters ---\n    N = 80\n    TOL = 1e-8\n    PICARD_MAX_ITER = 1000\n    NEWTON_MAX_ITER = 50\n    H = 1.0 / (N + 1)\n\n    # --- Core Functions ---\n\n    def create_laplacian_sparse(n, h):\n        \"\"\"Creates the 1D finite difference Laplacian as a sparse matrix.\"\"\"\n        diagonals = [np.ones(n - 1), -2 * np.ones(n), np.ones(n - 1)]\n        offsets = [-1, 0, 1]\n        L = sparse.diags(diagonals, offsets, shape=(n, n), format='csc')\n        return L / h**2\n\n    def compute_residual(u, lam, L_sparse):\n        \"\"\"Computes the residual F(u, lam) = L*u + lam*exp(u).\"\"\"\n        return L_sparse @ u + lam * np.exp(u)\n\n    # --- Solver Implementations ---\n\n    def picard_solver(lam, u_init, L_sparse, tol, max_iter):\n        \"\"\"\n        Solves the Bratu equation using Picard iteration with adaptive relaxation.\n        \"\"\"\n        u = u_init.copy()\n        \n        for _ in range(max_iter):\n            res_norm = np.linalg.norm(compute_residual(u, lam, L_sparse))\n            \n            if res_norm < tol:\n                return u, True\n            \n            # Linear solve for Picard update\n            rhs = -lam * np.exp(u)\n            u_tilde = spsolve(L_sparse, rhs)\n\n            # Adaptive relaxation (backtracking on omega)\n            omega = 1.0\n            found_omega = False\n            for _ in range(10):  # Max 10 backtracking steps\n                u_next = (1 - omega) * u + omega * u_tilde\n                res_next_norm = np.linalg.norm(compute_residual(u_next, lam, L_sparse))\n                if res_next_norm < res_norm:\n                    u = u_next\n                    found_omega = True\n                    break\n                omega /= 2.0\n\n            if not found_omega:\n                return u, False\n\n        return u, np.linalg.norm(compute_residual(u, lam, L_sparse)) < tol\n\n    def newton_solver(lam, u_init, L_sparse, tol, max_iter):\n        \"\"\"\n        Solves the Bratu equation for a fixed lambda using Newton-Raphson.\n        \"\"\"\n        u = u_init.copy()\n\n        for _ in range(max_iter):\n            res = compute_residual(u, lam, L_sparse)\n            if np.linalg.norm(res) < tol:\n                return u, True\n            \n            exp_u = np.exp(u)\n            J = L_sparse + sparse.diags(lam * exp_u, 0, format='csc')\n            \n            try:\n                delta_u = spsolve(J, -res)\n            except np.linalg.LinAlgError:\n                return u, False\n            u += delta_u\n        \n        return u, np.linalg.norm(compute_residual(u, lam, L_sparse)) < tol\n\n    def pa_continuation(u0, lam0, u1, lam1, d, num_steps, L_sparse, tol, max_newton_iter):\n        \"\"\"\n        Performs pseudo-arclength continuation.\n        \"\"\"\n        branch = [(u0, lam0), (u1, lam1)]\n        u_curr, lam_curr = u1, lam1\n        u_prev, lam_prev = u0, lam0\n\n        for _ in range(num_steps):\n            # --- Predictor ---\n            u_diff = u_curr - u_prev\n            lam_diff = lam_curr - lam_prev\n            \n            tangent_norm = np.sqrt(np.dot(u_diff, u_diff) + lam_diff**2)\n            if tangent_norm < 1e-12: break # Stalled\n            s_u = u_diff / tangent_norm\n            s_lam = lam_diff / tangent_norm\n\n            u_pred = u_curr + d * s_u\n            lam_pred = lam_curr + d * s_lam\n            \n            u_corr, lam_corr = u_pred, lam_pred\n\n            # --- Corrector (Newton on bordered system) ---\n            converged = False\n            for _ in range(max_newton_iter):\n                res_F = compute_residual(u_corr, lam_corr, L_sparse)\n                res_g = np.dot(s_u, u_corr - u_pred) + s_lam * (lam_corr - lam_pred)\n                aug_res_norm = np.sqrt(np.dot(res_F, res_F) + res_g**2)\n                if aug_res_norm < tol:\n                    converged = True\n                    break\n\n                # Schur complement solve\n                exp_u = np.exp(u_corr)\n                J_corr = L_sparse + sparse.diags(lam_corr * exp_u, 0, format='csc')\n                \n                try:\n                    w_F = spsolve(J_corr, res_F)\n                    w_lam = spsolve(J_corr, exp_u)\n                except (np.linalg.LinAlgError, RuntimeError): break\n\n                delta_lam_den = s_lam - np.dot(s_u, w_lam)\n                if abs(delta_lam_den) < 1e-12: break\n\n                delta_lam_num = np.dot(s_u, w_F) - res_g\n                delta_lam = delta_lam_num / delta_lam_den\n                delta_u = -w_F - delta_lam * w_lam\n\n                # Backtracking line search\n                alpha = 1.0\n                found_alpha = False\n                for _ in range(10):\n                    u_next = u_corr + alpha * delta_u\n                    lam_next = lam_corr + alpha * delta_lam\n                    \n                    res_F_next = compute_residual(u_next, lam_next, L_sparse)\n                    res_g_next = np.dot(s_u, u_next - u_pred) + s_lam * (lam_next - lam_pred)\n                    aug_res_norm_next = np.sqrt(np.dot(res_F_next, res_F_next) + res_g_next**2)\n\n                    if aug_res_norm_next < aug_res_norm:\n                        u_corr, lam_corr = u_next, lam_next\n                        found_alpha = True\n                        break\n                    alpha /= 2.0\n                \n                if not found_alpha: break\n            \n            if not converged: break\n            \n            branch.append((u_corr, lam_corr))\n            u_prev, lam_prev = u_curr, lam_curr\n            u_curr, lam_curr = u_corr, lam_corr\n\n        return branch\n\n    # --- Main Execution ---\n    L = create_laplacian_sparse(N, H)\n    u_zero = np.zeros(N)\n    results = []\n\n    # Test 1: Picard at lam=1.0\n    _, conv1 = picard_solver(1.0, u_zero, L, TOL, PICARD_MAX_ITER)\n    results.append(conv1)\n\n    # Test 2: Picard at lam=3.2\n    _, conv2 = picard_solver(3.2, u_zero, L, TOL, PICARD_MAX_ITER)\n    results.append(conv2)\n\n    # Test 3: PA turning point detection\n    u_sol_01, conv_01 = newton_solver(0.1, u_zero, L, TOL, NEWTON_MAX_ITER)\n    u_sol_02, conv_02 = newton_solver(0.2, u_sol_01, L, TOL, NEWTON_MAX_ITER)\n    \n    pa_branch_test3 = []\n    if conv_01 and conv_02:\n        pa_branch_test3 = pa_continuation(u_sol_01, 0.1, u_sol_02, 0.2, 0.05, 40, L, TOL, NEWTON_MAX_ITER)\n    \n    lams_pa = [p[1] for p in pa_branch_test3]\n    deltas_lam = np.diff(lams_pa)\n    crossed_turning_point = False\n    if len(deltas_lam) > 1 and deltas_lam[0] > 0:\n        if np.any(deltas_lam[1:] < 0):\n            crossed_turning_point = True\n    results.append(crossed_turning_point)\n    \n    # Test 4: Coverage comparison\n    lam_picard = 0.1\n    delta_lam_picard = 0.1\n    u_guess_picard = np.zeros(N)\n    lam_last_picard = 0.0\n    while lam_picard < 4.0: # Safety break\n        _, conv = picard_solver(lam_picard, u_guess_picard, L, TOL, PICARD_MAX_ITER)\n        if conv:\n            u_sol, _ = newton_solver(lam_picard, u_guess_picard, L, TOL, NEWTON_MAX_ITER)\n            lam_last_picard = lam_picard\n            u_guess_picard = u_sol\n            lam_picard += delta_lam_picard\n        else:\n            break\n\n    lam_max_pa = 0.0\n    if lams_pa:\n        lam_max_pa = max(lams_pa)\n\n    result4 = lam_max_pa - lam_last_picard\n    results.append(result4)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3431387"}]}