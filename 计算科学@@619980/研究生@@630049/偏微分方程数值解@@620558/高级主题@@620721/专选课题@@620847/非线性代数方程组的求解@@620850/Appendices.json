{"hands_on_practices": [{"introduction": "在使用 Newton 法求解非线性方程组 $F(u)=0$ 之前，我们必须首先能够推导出残差向量 $F(u)$ 及其 Jacobian 矩阵 $J(u)$ 的表达式。本练习 ([@problem_id:3444537]) 提供了在这一基础步骤上的必要实践，要求你使用有限元方法 (FEM) 对一个非线性偏微分方程进行离散化。通过这个过程，你将亲手推导单元级别的残差和 Jacobian 矩阵，从而深刻理解非线性代数系统如何从连续问题中产生。", "problem": "考虑在一维（$1$D）空间区间 $[x_1,x_2]$ 上的稳态非线性扩散偏微分方程（PDE）\n$$-\\frac{d}{dx}\\left(k(u)\\frac{du}{dx}\\right)=0,$$\n其本构关系为 $k(u)=1+u^2$，并在 $x_1$ 和 $x_2$ 处具有自然（零通量）边界条件。在一个长度为 $h=x_2-x_1$、跨越 $[x_1,x_2]$ 的单元上，使用标准的伽辽金有限元法（FEM）和线性拉格朗日基函数，设有限维近似为 $u_h(x)=N_1(x)u_1+N_2(x)u_2$，其中 $N_1$ 和 $N_2$ 分别是与节点 $x_1$ 和 $x_2$ 相关联的单元形函数，$u_1, u_2$ 是节点未知数。\n\n从弱形式和伽辽金残差的定义出发，推导该非线性代数系统的牛顿线性化所对应的单元级残差向量和单元级雅可比矩阵。将所有积分精确表示（不引入求积法），并将其简化为以 $u_1$、$u_2$ 和 $h$ 表示的封闭形式解析表达式。然后，明确描述对于单单元网格，这些单元级贡献是如何组装成全局残差和全局雅可比矩阵的（即，局部自由度如何映射到全局自由度）。\n\n最后，计算此单单元网格的已组装全局雅可比矩阵的行列式，并将其作为一个简化的精确表达式给出。无需进行数值舍入。", "solution": "该问题陈述具有科学依据、是适定的、客观且自洽的。它提出了一个将有限元法应用于非线性边值问题的标准练习。所有必要的数据和定义都已提供，不存在内部矛盾或违反科学原理的情况。该问题是有效的，可以构建解答。\n\n过程始于推导偏微分方程（PDE）的弱形式。给定的强形式为：\n$$-\\frac{d}{dx}\\left(k(u)\\frac{du}{dx}\\right) = 0 \\quad \\text{for } x \\in [x_1, x_2]$$\n其中 $k(u) = 1+u^2$。为得到弱形式，我们乘以一个检验函数 $v(x)$ 并在定义域 $[x_1, x_2]$ 上积分：\n$$ \\int_{x_1}^{x_2} -v \\frac{d}{dx}\\left(k(u)\\frac{du}{dx}\\right) dx = 0 $$\n分部积分得到：\n$$ \\left[ -v \\cdot k(u)\\frac{du}{dx} \\right]_{x_1}^{x_2} + \\int_{x_1}^{x_2} \\frac{dv}{dx} k(u)\\frac{du}{dx} dx = 0 $$\n项 $-k(u) \\frac{du}{dx}$ 代表通量。问题指定了在 $x=x_1$ 和 $x=x_2$ 处的自然（零通量）边界条件。这意味着边界项 $\\left[ -v \\cdot k(u)\\frac{du}{dx} \\right]_{x_1}^{x_2}$ 为零。因此，弱形式为：寻找一个试验函数 $u$，使得对于所有容许的检验函数 $v$：\n$$ \\int_{x_1}^{x_2} k(u) \\frac{du}{dx} \\frac{dv}{dx} dx = 0 $$\n在伽辽金有限元法中，试验函数 $u$ 和检验函数 $v$ 从同一有限维空间中选取。我们用 $u_h(x) = \\sum_{j} u_j N_j(x)$ 来近似 $u$，其中 $u_j$ 是节点未知数，$N_j(x)$ 是基函数（形函数）。弱形式必须对空间中任何检验函数 $v$ 都成立，因此我们对每个基函数索引 $i$ 选择 $v(x) = N_i(x)$。这导出了一个非线性代数方程组，其中第 $i$ 个方程由残差分量 $R_i$ 给出：\n$$ R_i(\\mathbf{u}) = \\int_{x_1}^{x_2} k(u_h) \\frac{du_h}{dx} \\frac{dN_i}{dx} dx = 0 $$\n对于指定的长度为 $h=x_2-x_1$ 的单个单元，使用线性拉格朗日基函数，其近似为 $u_h(x) = N_1(x)u_1 + N_2(x)u_2$。在局部坐标系 $\\xi \\in [0, 1]$ 中工作会很方便，其中 $x(\\xi) = x_1 + \\xi h$。链式法则给出 $\\frac{d}{dx} = \\frac{d\\xi}{dx}\\frac{d}{d\\xi} = \\frac{1}{h}\\frac{d}{d\\xi}$。局部坐标系中的线性基函数为：\n$$ N_1(\\xi) = 1-\\xi, \\quad N_2(\\xi) = \\xi $$\n它们关于 $\\xi$ 和 $x$ 的导数是：\n$$ \\frac{dN_1}{d\\xi} = -1, \\quad \\frac{dN_2}{d\\xi} = 1 $$\n$$ \\frac{dN_1}{dx} = -\\frac{1}{h}, \\quad \\frac{dN_2}{dx} = \\frac{1}{h} $$\n近似 $u_h$ 及其导数可以表示为：\n$$ u_h(\\xi) = (1-\\xi)u_1 + \\xi u_2 = u_1 + (u_2-u_1)\\xi $$\n$$ \\frac{du_h}{dx} = \\frac{1}{h}\\frac{du_h}{d\\xi} = \\frac{u_2-u_1}{h} $$\n现在，我们可以计算单元级残差向量 $\\mathbf{R}^{(e)} = [R_1, R_2]^T$ 的分量。积分被转换到局部坐标系，其中 $dx = h d\\xi$：\n$$ R_i(\\mathbf{u}) = \\int_{0}^{1} k(u_h(\\xi)) \\left(\\frac{u_2-u_1}{h}\\right) \\left(\\frac{1}{h}\\frac{dN_i}{d\\xi}\\right) h d\\xi = \\frac{u_2-u_1}{h} \\frac{dN_i}{d\\xi} \\int_{0}^{1} (1 + u_h(\\xi)^2) d\\xi $$\n让我们计算这个积分：\n$$ \\int_{0}^{1} \\left(1 + (u_1 + (u_2-u_1)\\xi)^2\\right) d\\xi = \\left[\\xi + \\frac{(u_1 + (u_2-u_1)\\xi)^3}{3(u_2-u_1)}\\right]_0^1 $$\n$$ = 1 + \\frac{u_2^3}{3(u_2-u_1)} - \\frac{u_1^3}{3(u_2-u_1)} = 1 + \\frac{u_2^3-u_1^3}{3(u_2-u_1)} = 1 + \\frac{(u_2-u_1)(u_2^2+u_1u_2+u_1^2)}{3(u_2-u_1)} $$\n$$ = 1 + \\frac{1}{3}(u_1^2 + u_1u_2 + u_2^2) = \\frac{1}{3}(3 + u_1^2 + u_1u_2 + u_2^2) $$\n使用这个结果来求解残差分量：\n对于 $i=1$，$\\frac{dN_1}{d\\xi}=-1$：\n$$ R_1 = \\frac{u_2-u_1}{h} (-1) \\left(\\frac{1}{3}(3 + u_1^2 + u_1u_2 + u_2^2)\\right) = -\\frac{u_2-u_1}{3h}(3 + u_1^2 + u_1u_2 + u_2^2) $$\n对于 $i=2$，$\\frac{dN_2}{d\\xi}=1$：\n$$ R_2 = \\frac{u_2-u_1}{h} (1) \\left(\\frac{1}{3}(3 + u_1^2 + u_1u_2 + u_2^2)\\right) = \\frac{u_2-u_1}{3h}(3 + u_1^2 + u_1u_2 + u_2^2) $$\n单元级残差向量为：\n$$ \\mathbf{R}^{(e)}(\\mathbf{u}) = \\frac{u_2-u_1}{3h}(3 + u_1^2 + u_1u_2 + u_2^2) \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix} $$\n接下来，我们通过对残差分量关于节点未知数求导来推导单元级雅可比矩阵 $\\mathbf{J}^{(e)}$：$J_{ij}^{(e)} = \\frac{\\partial R_i}{\\partial u_j}$。\n很明显，$R_2 = -R_1$。因此，雅可比矩阵的第二行将是第一行的负值：$J_{2j} = -J_{1j}$。\n设 $A = u_2-u_1$ 且 $B = 3 + u_1^2 + u_1u_2 + u_2^2$。则 $R_1 = -\\frac{1}{3h}AB$。\n$$ J_{11} = \\frac{\\partial R_1}{\\partial u_1} = -\\frac{1}{3h} \\left( \\frac{\\partial A}{\\partial u_1}B + A\\frac{\\partial B}{\\partial u_1} \\right) = -\\frac{1}{3h} \\left( (-1)B + (u_2-u_1)(2u_1+u_2) \\right) $$\n$$ J_{11} = -\\frac{1}{3h} \\left( -(3 + u_1^2 + u_1u_2 + u_2^2) + (2u_1u_2+u_2^2-2u_1^2-u_1u_2) \\right) $$\n$$ J_{11} = -\\frac{1}{3h} \\left( -3 - u_1^2 - u_1u_2 - u_2^2 + u_1u_2+u_2^2-2u_1^2 \\right) = -\\frac{1}{3h}(-3 - 3u_1^2) = \\frac{1}{h}(1+u_1^2) $$\n$$ J_{12} = \\frac{\\partial R_1}{\\partial u_2} = -\\frac{1}{3h} \\left( \\frac{\\partial A}{\\partial u_2}B + A\\frac{\\partial B}{\\partial u_2} \\right) = -\\frac{1}{3h} \\left( (1)B + (u_2-u_1)(u_1+2u_2) \\right) $$\n$$ J_{12} = -\\frac{1}{3h} \\left( (3 + u_1^2 + u_1u_2 + u_2^2) + (u_1u_2+2u_2^2-u_1^2-2u_1u_2) \\right) $$\n$$ J_{12} = -\\frac{1}{3h} \\left( 3 + u_1^2 + u_1u_2 + u_2^2 - u_1^2 - u_1u_2 + 2u_2^2 \\right) = -\\frac{1}{3h}(3 + 3u_2^2) = -\\frac{1}{h}(1+u_2^2) $$\n单元级雅可比矩阵为：\n$$ \\mathbf{J}^{(e)}(\\mathbf{u}) = \\begin{pmatrix} J_{11} & J_{12} \\\\ J_{21} & J_{22} \\end{pmatrix} = \\begin{pmatrix} J_{11} & J_{12} \\\\ -J_{11} & -J_{12} \\end{pmatrix} = \\frac{1}{h} \\begin{pmatrix} 1+u_1^2 & -(1+u_2^2) \\\\ -(1+u_1^2) & 1+u_2^2 \\end{pmatrix} $$\n对于一个只包含单个单元的网格，全局自由度与单元的局部自由度相同。映射是恒等映射：局部节点 $1$ 对应于全局节点 $1$，局部节点 $2$ 对应于全局节点 $2$。因此，全局残差向量和全局雅可比矩阵与其单元级对应项完全相同。\n$$ \\mathbf{R}_{global} = \\mathbf{R}^{(e)}, \\quad \\mathbf{J}_{global} = \\mathbf{J}^{(e)} $$\n最后的任务是计算已组装的全局雅可比矩阵的行列式：\n$$ \\det(\\mathbf{J}_{global}) = \\det\\left( \\frac{1}{h} \\begin{pmatrix} 1+u_1^2 & -(1+u_2^2) \\\\ -(1+u_1^2) & 1+u_2^2 \\end{pmatrix} \\right) $$\n对于一个 $n \\times n$ 矩阵，使用性质 $\\det(c \\mathbf{A}) = c^n \\det(\\mathbf{A})$：\n$$ \\det(\\mathbf{J}_{global}) = \\left(\\frac{1}{h}\\right)^2 \\det \\begin{pmatrix} 1+u_1^2 & -(1+u_2^2) \\\\ -(1+u_1^2) & 1+u_2^2 \\end{pmatrix} $$\n$$ \\det(\\mathbf{J}_{global}) = \\frac{1}{h^2} \\left[ (1+u_1^2)(1+u_2^2) - (-(1+u_2^2))(-(1+u_1^2)) \\right] $$\n$$ \\det(\\mathbf{J}_{global}) = \\frac{1}{h^2} \\left[ (1+u_1^2)(1+u_2^2) - (1+u_1^2)(1+u_2^2) \\right] $$\n$$ \\det(\\mathbf{J}_{global}) = \\frac{1}{h^2} [0] = 0 $$\n对于任意的 $u_1$ 和 $u_2$ 值，全局雅可比矩阵的行列式均为零。这种奇异性是预料之中的。带有纯诺伊曼边界条件的原始偏微分方程有一个解 $u(x)=C$（一个常数），但 $C$ 的值是不确定的。这导致代数系统的解不唯一，表现为雅可比矩阵是奇异的。", "answer": "$$\\boxed{0}$$", "id": "3444537"}, {"introduction": "虽然 Newton 法功能强大，但其效率往往受限于每一步都需要重新计算和分解 Jacobian 矩阵的高昂成本。本练习 ([@problem_id:3444521]) 探讨了一种强大的替代方案——拟 Newton 法，它通过近似 Jacobian 矩阵来节省计算资源。你将实现经典的 Broyden 方法，并与标准的 Newton 法进行性能比较，从而量化其在减少昂贵的 Jacobian 计算方面的优势。", "problem": "实现并比较两种牛顿型方法，用于求解源于一维半线性偏微分方程（PDE）有限差分-离散化的非线性代数方程组。从以下基本事实出发：(i) 用中心有限差分-离散化的稳态偏微分方程会产生一个非线性代数方程组，(ii) 求解非线性系统 $\\mathbf{F}(\\mathbf{u})=\\mathbf{0}$ 的牛顿法需要求解包含雅可比矩阵的线性系统，以及 (iii) 多维割线条件通过强制执行 $\\mathbf{J}_{k+1}\\mathbf{s}_k=\\mathbf{y}_k$（其中 $\\mathbf{s}_k=\\mathbf{u}_{k+1}-\\mathbf{u}_k$ 且 $\\mathbf{y}_k=\\mathbf{F}(\\mathbf{u}_{k+1})-\\mathbf{F}(\\mathbf{u}_k)$）来推广标量割线更新。设计一种雅可比矩阵的秩一更新，该更新在满足割线条件的同时，在弗罗贝尼乌斯范数下对 $\\mathbf{J}_k$ 的改变尽可能小，并利用此更新来减少精确雅可比矩阵的组装次数。\n\n考虑在单位区间上的边值问题，其具有齐次狄利克雷边界条件，\n$$-u''(x)+\\alpha u(x)^3=g(x),\\quad x\\in(0,1),\\quad u(0)=0,\\quad u(1)=0,$$\n其中 $\\alpha>0$。使用均匀网格上的 $n$ 个内部点进行离散化，步长为 $h=1/(n+1)$，并对 $-u''$ 使用标准的二阶中心差分，即对于内部节点 $i$，\n$$-u''(x_i)\\approx -\\frac{u_{i-1}-2u_i+u_{i+1}}{h^2}。$$\n令 $\\mathbf{u}\\in\\mathbb{R}^n$ 汇集内部值，并定义非线性残差向量 $\\mathbf{F}(\\mathbf{u})\\in\\mathbb{R}^n$，其分量为\n$$F_i(\\mathbf{u})=-\\frac{u_{i-1}-2u_i+u_{i+1}}{h^2}+\\alpha u_i^3-g_i,$$\n需明确边界值为 $u_0=u_{n+1}=0$。使用应用于离散残差的基本求导法则来组装精确的雅可比矩阵 $\\mathbf{J}(\\mathbf{u})\\in\\mathbb{R}^{n\\times n}$。您还必须从多维割线条件和弗罗贝尼乌斯范数下的最小变化原则出发，推导出一个唯一的秩一更新映射 $\\mathbf{J}_k\\mapsto\\mathbf{J}_{k+1}$，该映射保持割线条件。\n\n算法要求：\n- 实现两种求解器用于求解 $\\mathbf{F}(\\mathbf{u})=\\mathbf{0}$：\n  - 方法A（基线）：经典的牛顿法，在每次迭代中都进行精确的雅可比矩阵组装。在价值函数 $\\phi(\\mathbf{u})=\\tfrac{1}{2}\\|\\mathbf{F}(\\mathbf{u})\\|_2^2$ 上使用回溯线搜索，并采用Armijo型条件、初始试探步长 $t=1$、充分下降常数 $c_1\\in(0,1)$ 以及回溯乘法因子 $\\tau\\in(0,1)$。\n  - 方法B（近似雅可比矩阵）：从一次精确的雅可比矩阵组装开始，然后在每个被接受的步长后，使用您从割线条件和最小变化原则推导出的秩一更新来更新雅可比矩阵。为了促进稳健收敛，每隔 $m$ 个被接受的步长（其中 $m$ 为正整数）通过重新组装精确的雅可比矩阵来周期性地刷新。\n- 使用制造解 $u^\\star(x)=\\sin(\\pi x)$，通过您实现的相同离散算子来设置离散的右端项 $g_i$。即，计算 $g_i$ 使得离散的 $\\mathbf{u}^\\star$ 对于所选的 $\\alpha$ 精确满足 $\\mathbf{F}(\\mathbf{u}^\\star)=\\mathbf{0}$。这消除了建模误差，并确保代数求解器被独立评估。\n- 停止准则：当 $\\|\\mathbf{F}(\\mathbf{u})\\|_2\\le \\varepsilon$（对于给定的容差 $\\varepsilon>0$）时，或达到最大迭代次数时终止。使用一个Armijo回溯法，该方法测试 $\\phi(\\mathbf{u})$ 的下降，并使用与定义步长所用雅可比矩阵一致计算出的方向导数。\n- 成本度量：计算精确雅可比矩阵的组装次数。对于方法A，这等于执行的迭代次数。对于方法B，只计算初始组装和周期性刷新；不要将秩一更新计为组装。\n\n您必须针对给定的离散化，推导并实现半线性问题的精确雅可比矩阵项；并且必须推导并实现由多维割线条件和最小弗罗贝尼乌斯范数变化定义的唯一秩一更新。\n\n测试套件：\n在以下四种情况下运行两种方法。每种情况由 $(n,\\alpha,m,\\varepsilon,\\text{max\\_iter})$ 指定：\n- 情况1：$(n,\\alpha,m,\\varepsilon,\\text{max\\_iter})=(64,1,3,10^{-10},50)$。\n- 情况2：$(n,\\alpha,m,\\varepsilon,\\text{max\\_iter})=(64,10,5,10^{-10},50)$。\n- 情况3：$(n,\\alpha,m,\\varepsilon,\\text{max\\_iter})=(16,1,1000,10^{-10},50)$。\n- 情况4：$(n,\\alpha,m,\\varepsilon,\\text{max\\_iter})=(128,1,2,10^{-10},50)$。\n\n对于每种情况，使用零向量作为初始猜测值进行初始化。对于线搜索，使用 $c_1=10^{-4}$，$\\tau=1/2$，以及最小步长 $t_{\\min}=10^{-8}$。\n\n要求的最终输出：\n- 对于每种情况，按以下顺序生成一个包含八个值的列表：\n  $[\\text{convB},\\text{itB},\\text{assmB},\\|\\mathbf{F}\\|_B,\\text{convA},\\text{itA},\\text{assmA},\\|\\mathbf{F}\\|_A]$，其中：\n  - $\\text{convB}$ 和 $\\text{convA}$ 是布尔值，分别表示方法B和方法A是否在迭代限制内满足 $\\|\\mathbf{F}(\\mathbf{u})\\|_2\\le\\varepsilon$，\n  - $\\text{itB}$ 和 $\\text{itA}$ 是执行的迭代次数，\n  - $\\text{assmB}$ 和 $\\text{assmA}$ 是精确雅可比矩阵的组装次数，\n  - $\\|\\mathbf{F}\\|_B$ 和 $\\|\\mathbf{F}\\|_A$ 是最终的残差范数，以浮点数表示。\n- 您的程序应生成单行输出，其中包含这些按案例排列的列表，不含空白字符，浮点数采用科学记数法，小数点后保留六位数字。例如，单个案例将显示为 $[[\\dots]]$，所有四个案例显示为 $[[\\dots],[\\dots],[\\dots],[\\dots]]$。\n\n角度单位不适用。没有物理单位。所有数值答案必须遵循最终输出的格式规则。", "solution": "用户提供了一个明确定义的数值分析问题。任务是实现并比较两种牛顿型方法，用于求解由一维半线性偏微分方程的有限差分-离散化产生的非线性代数方程组。\n\n### 步骤1：问题公式化与离散化\n\n给定的边值问题是：\n$$ -u''(x)+\\alpha u(x)^3=g(x), \\quad x\\in(0,1) $$\n具有齐次狄利克雷边界条件 $u(0)=0$ 和 $u(1)=0$。区域 $(0,1)$ 使用 $n$ 个内部点 $x_i = i h$（其中 $i=1, \\dots, n$）进行离散化，网格间距为 $h=1/(n+1)$。点 $x_i$ 处的二阶导数 $-u''$ 使用二阶中心差分公式进行近似：\n$$ -u''(x_i) \\approx \\frac{-u(x_{i-1}) + 2u(x_i) - u(x_{i+1})}{h^2} $$\n令 $\\mathbf{u} = [u_1, u_2, \\dots, u_n]^T$ 为内部网格点上未知值的向量，其中 $u_i \\approx u(x_i)$。每个内部节点 $x_i$ 处的离散化方程构成了非线性系统 $\\mathbf{F}(\\mathbf{u})=\\mathbf{0}$ 的一个分量。残差向量 $\\mathbf{F}(\\mathbf{u})$ 的第 $i$ 个分量是：\n$$ F_i(\\mathbf{u}) = \\frac{-u_{i-1} + 2u_i - u_{i+1}}{h^2} + \\alpha u_i^3 - g_i $$\n边界条件 $u_0=0$ 和 $u_{n+1}=0$ 分别用于 $i=1$ 和 $i=n$ 的方程。\n\n该系统可以写成向量形式：\n$$ \\mathbf{F}(\\mathbf{u}) = \\mathbf{A}\\mathbf{u} + \\alpha \\mathbf{u}^{\\circ 3} - \\mathbf{g} = \\mathbf{0} $$\n其中 $\\mathbf{u}^{\\circ 3} = [u_1^3, u_2^3, \\dots, u_n^3]^T$ 是向量 $\\mathbf{u}$ 的逐元素立方，$\\mathbf{A}$ 是表示离散负拉普拉斯算子的 $n \\times n$ 矩阵：\n$$ \\mathbf{A} = \\frac{1}{h^2} \\begin{pmatrix}\n2 & -1 & 0 & \\dots & 0 \\\\\n-1 & 2 & -1 & \\dots & 0 \\\\\n0 & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\vdots &  & -1 & 2 & -1 \\\\\n0 & \\dots & 0 & -1 & 2\n\\end{pmatrix} $$\n为创建一个可验证的问题，使用了一个制造解 $u^\\star(x) = \\sin(\\pi x)$。使用离散版本 $\\mathbf{u}^\\star_i = \\sin(\\pi i h)$ 来定义右端向量 $\\mathbf{g}$，使得 $\\mathbf{F}(\\mathbf{u}^\\star) = \\mathbf{0}$。因此，$\\mathbf{g}$ 计算如下：\n$$ \\mathbf{g} = \\mathbf{A}\\mathbf{u}^\\star + \\alpha (\\mathbf{u}^\\star)^{\\circ 3} $$\n\n### 步骤2：精确雅可比矩阵的推导\n\n牛顿法需要雅可比矩阵 $\\mathbf{J}(\\mathbf{u})$，其元素为 $J_{ij}(\\mathbf{u}) = \\frac{\\partial F_i}{\\partial u_j}$。我们对 $F_i(\\mathbf{u})$ 关于 $u_j$ 求导：\n$$ F_i(\\mathbf{u}) = \\frac{1}{h^2}(-u_{i-1} + 2u_i - u_{i+1}) + \\alpha u_i^3 - g_i $$\n偏导数是：\n-   对于 $j=i$：$\\frac{\\partial F_i}{\\partial u_i} = \\frac{2}{h^2} + 3\\alpha u_i^2$。\n-   对于 $j=i-1$：$\\frac{\\partial F_i}{\\partial u_{i-1}} = -\\frac{1}{h^2}$。\n-   对于 $j=i+1$：$\\frac{\\partial F_i}{\\partial u_{i+1}} = -\\frac{1}{h^2}$。\n-   对于 $|i-j| > 1$：$\\frac{\\partial F_i}{\\partial u_j} = 0$。\n\n因此，雅可比矩阵 $\\mathbf{J}(\\mathbf{u})$ 是一个三对角矩阵，由常数矩阵 $\\mathbf{A}$ 和来自非线性项的对角矩阵组成：\n$$ \\mathbf{J}(\\mathbf{u}) = \\mathbf{A} + 3\\alpha \\cdot \\text{diag}(u_1^2, u_2^2, \\dots, u_n^2) = \\mathbf{A} + 3\\alpha \\cdot \\text{diag}(\\mathbf{u}^{\\circ 2}) $$\n该矩阵是对称的，并且由于 $\\mathbf{A}$ 是对称正定的，且对角线上的加项是非负的，所以 $\\mathbf{J}(\\mathbf{u})$ 也是对称正定的。\n\n### 步骤3：秩一雅可比更新的推导\n\n方法B使用拟牛顿法，用矩阵 $\\mathbf{B}_k$ 来近似雅可比矩阵 $\\mathbf{J}_k = \\mathbf{J}(\\mathbf{u}_k)$。从 $\\mathbf{u}_k$ 到 $\\mathbf{u}_{k+1}$ 的更新步之后，新的近似矩阵 $\\mathbf{B}_{k+1}$ 需要满足割线条件：\n$$ \\mathbf{B}_{k+1}\\mathbf{s}_k = \\mathbf{y}_k, \\quad \\text{其中 } \\mathbf{s}_k = \\mathbf{u}_{k+1} - \\mathbf{u}_k \\text{ 且 } \\mathbf{y}_k = \\mathbf{F}(\\mathbf{u}_{k+1}) - \\mathbf{F}(\\mathbf{u}_k) $$\n具体的更新是通过找到满足此条件同时又与 $\\mathbf{B}_k$ “最接近”的 $\\mathbf{B}_{k+1}$ 来推导的。这被表述为一个约束优化问题：\n$$ \\min_{\\mathbf{B} \\in \\mathbb{R}^{n\\times n}} \\|\\mathbf{B} - \\mathbf{B}_k\\|_F \\quad \\text{受限于} \\quad \\mathbf{B}\\mathbf{s}_k = \\mathbf{y}_k $$\n其中 $\\|\\cdot\\|_F$ 是弗罗贝尼乌斯范数。最小化该范数等价于最小化其平方 $\\frac{1}{2}\\|\\mathbf{B} - \\mathbf{B}_k\\|_F^2$。我们使用拉格朗日乘子法。拉格朗日量为：\n$$ \\mathcal{L}(\\mathbf{B}, \\boldsymbol{\\lambda}) = \\frac{1}{2}\\text{tr}((\\mathbf{B}-\\mathbf{B}_k)^T(\\mathbf{B}-\\mathbf{B}_k)) - \\boldsymbol{\\lambda}^T(\\mathbf{B}\\mathbf{s}_k - \\mathbf{y}_k) $$\n将关于 $\\mathbf{B}$ 的梯度设为零，得到：\n$$ \\nabla_{\\mathbf{B}} \\mathcal{L} = \\mathbf{B} - \\mathbf{B}_k - \\boldsymbol{\\lambda}\\mathbf{s}_k^T = \\mathbf{0} \\implies \\mathbf{B}_{k+1} = \\mathbf{B}_k + \\boldsymbol{\\lambda}\\mathbf{s}_k^T $$\n这证实了该更新是一个秩一矩阵。为了找到拉格朗日乘子向量 $\\boldsymbol{\\lambda}$，我们强制执行割线约束：\n$$ \\mathbf{B}_{k+1}\\mathbf{s}_k = (\\mathbf{B}_k + \\boldsymbol{\\lambda}\\mathbf{s}_k^T)\\mathbf{s}_k = \\mathbf{B}_k\\mathbf{s}_k + \\boldsymbol{\\lambda}(\\mathbf{s}_k^T\\mathbf{s}_k) = \\mathbf{y}_k $$\n求解 $\\boldsymbol{\\lambda}$（注意 $\\mathbf{s}_k^T\\mathbf{s}_k = \\|\\mathbf{s}_k\\|_2^2$ 是一个标量）：\n$$ \\boldsymbol{\\lambda} = \\frac{\\mathbf{y}_k - \\mathbf{B}_k\\mathbf{s}_k}{\\mathbf{s}_k^T\\mathbf{s}_k} $$\n将此代回 $\\mathbf{B}_{k+1}$ 的表达式，得到Broyden更新公式：\n$$ \\mathbf{B}_{k+1} = \\mathbf{B}_k + \\frac{(\\mathbf{y}_k - \\mathbf{B}_k\\mathbf{s}_k)\\mathbf{s}_k^T}{\\mathbf{s}_k^T\\mathbf{s}_k} $$\n\n### 步骤4：算法实现\n\n两种方法都从 $\\mathbf{u}_0 = \\mathbf{0}$ 开始，并进行迭代，直到残差的L2范数低于容差 $\\varepsilon=10^{-10}$ 或达到最大迭代次数。每次迭代都涉及求解一个线性系统以获得搜索方向 $\\mathbf{p}_k$，并执行回溯线搜索以找到步长 $t_k$。\n\n**牛顿步**：在迭代 $k$ 次时，通过求解 $\\mathbf{M}_k \\mathbf{p}_k = -\\mathbf{F}(\\mathbf{u}_k)$ 来找到搜索方向 $\\mathbf{p}_k$，其中 $\\mathbf{M}_k$ 是雅可比矩阵（或其近似）。\n\n**线搜索**：更新为 $\\mathbf{u}_{k+1} = \\mathbf{u}_k + t_k \\mathbf{p}_k$。步长 $t_k$ 的确定方法是：从 $t=1$ 开始，并以因子 $\\tau=1/2$ 递减，直到满足价值函数 $\\phi(\\mathbf{u})=\\frac{1}{2}\\|\\mathbf{F}(\\mathbf{u})\\|_2^2$ 上的Armijo条件：\n$$ \\phi(\\mathbf{u}_k + t \\mathbf{p}_k) \\le \\phi(\\mathbf{u}_k) + c_1 t \\nabla\\phi(\\mathbf{u}_k)^T \\mathbf{p}_k $$\n充分下降常数为 $c_1=10^{-4}$。方向导数项 $\\nabla\\phi(\\mathbf{u}_k)^T \\mathbf{p}_k$ 的计算与用于寻找步长的矩阵保持一致，结果为 $\\mathbf{F}(\\mathbf{u}_k)^T \\mathbf{M}_k \\mathbf{p}_k = -\\mathbf{F}(\\mathbf{u}_k)^T \\mathbf{F}(\\mathbf{u}_k) = -\\|\\mathbf{F}(\\mathbf{u}_k)\\|_2^2$。\n\n**方法A（经典牛顿法）**：\n- 在每次迭代 $k$ 中，组装精确的雅可比矩阵 $\\mathbf{M}_k = \\mathbf{J}(\\mathbf{u}_k)$。\n- 雅可比矩阵的组装次数等于执行的迭代次数。\n\n**方法B（拟牛顿法）**：\n- 使用雅可比矩阵的近似 $\\mathbf{B}_k$，因此 $\\mathbf{M}_k = \\mathbf{B}_k$。\n- 组装一个初始的精确雅可比矩阵 $\\mathbf{B}_0 = \\mathbf{J}(\\mathbf{u}_0)$。\n- 在每个被接受的步长之后，使用推导出的Broyden公式将 $\\mathbf{B}_k$ 更新为 $\\mathbf{B}_{k+1}$。\n- 每隔 $m$ 个被接受的步长，重新组装一次精确的雅可比矩阵，以刷新近似并确保稳健性。组装次数是初始次数加上刷新次数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to implement and compare Newton-type solvers for a discretized\n    semilinear PDE, and to format the results as specified.\n    \"\"\"\n\n    def _get_system_components(n, alpha):\n        \"\"\"\n        Sets up the discrete system components for a given n and alpha.\n        This includes the grid, the manufactured solution u_star, the sparse\n        matrix A for the Laplacian, and the right-hand-side vector g.\n        \"\"\"\n        h = 1.0 / (n + 1)\n        x = np.linspace(h, 1.0 - h, n)\n        u_star = np.sin(np.pi * x)\n\n        # Construct matrix A for the discrete Laplacian\n        diag_val = 2.0 / h**2\n        offdiag_val = -1.0 / h**2\n        A = np.diag(np.full(n, diag_val)) + \\\n            np.diag(np.full(n - 1, offdiag_val), k=1) + \\\n            np.diag(np.full(n - 1, offdiag_val), k=-1)\n        \n        # Compute g from the manufactured solution\n        g = A @ u_star + alpha * u_star**3\n        \n        # Define F and J functions\n        F_func = lambda u: A @ u + alpha * u**3 - g\n        J_func = lambda u: A + np.diag(3 * alpha * u**2)\n        \n        return F_func, J_func\n\n    def _run_solver(F, J, n, m, epsilon, max_iter, method):\n        \"\"\"\n        Executes a Newton-type method (A or B) to solve F(u)=0.\n        Method 'A' is classical Newton.\n        Method 'B' is a quasi-Newton method with Broyden updates and restarts.\n        \"\"\"\n        # Line search parameters\n        c1 = 1e-4\n        tau = 0.5\n        t_min = 1e-8\n\n        # Initialization\n        u = np.zeros(n)\n        Fu = F(u)\n        norm_F = np.linalg.norm(Fu, 2)\n        \n        it = 0\n        assemblies = 0\n        \n        Jacobian = None\n        if method == 'B':\n            Jacobian = J(u)\n            assemblies += 1\n            accepted_steps_since_refresh = 0\n\n        while norm_F > epsilon and it  max_iter:\n            # Assemble Jacobian for Method A at each step, or for Method B on first step\n            if method == 'A':\n                Jacobian = J(u)\n                assemblies += 1\n\n            # Solve the linear system for the Newton step\n            try:\n                # Use a standard solver; for n = 128 this is acceptable.\n                p = np.linalg.solve(Jacobian, -Fu)\n            except np.linalg.LinAlgError:\n                # Jacobian is singular, can't proceed.\n                break\n\n            # Backtracking line search with Armijo condition\n            t = 1.0\n            phi_u = 0.5 * norm_F**2\n            # Directional derivative consistent with the (approximate) Jacobian\n            slope = -norm_F**2 \n            \n            step_found = False\n            while t > t_min:\n                u_trial = u + t * p\n                Fu_trial = F(u_trial)\n                phi_trial = 0.5 * np.linalg.norm(Fu_trial, 2)**2\n                \n                if phi_trial = phi_u + c1 * t * slope:\n                    step_found = True\n                    break\n                t *= tau\n            \n            if not step_found:\n                # Line search failed to find a suitable step.\n                break\n            \n            # Step accepted, update state\n            it += 1\n            u_prev = u\n            Fu_prev = Fu\n            u = u_trial\n            Fu = Fu_trial\n            norm_F = np.linalg.norm(Fu, 2)\n            \n            # Update Jacobian for Method B\n            if method == 'B':\n                accepted_steps_since_refresh += 1\n                if accepted_steps_since_refresh == m and it  max_iter:\n                    Jacobian = J(u)\n                    assemblies += 1\n                    accepted_steps_since_refresh = 0\n                else:\n                    s = u - u_prev\n                    y = Fu - Fu_prev\n                    s_dot_s = np.dot(s, s)\n                    if abs(s_dot_s) > 1e-12: # Avoid division by zero\n                        update_vec = y - Jacobian @ s\n                        Jacobian += np.outer(update_vec, s) / s_dot_s\n\n        converged = norm_F = epsilon\n        \n        # Per problem statement: For Method A, assembly count equals iteration count.\n        # This is naturally handled by the implementation.\n        \n        return converged, it, assemblies, norm_F\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (64, 1, 3, 10**-10, 50),\n        (64, 10, 5, 10**-10, 50),\n        (16, 1, 1000, 10**-10, 50),\n        (128, 1, 2, 10**-10, 50),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        n, alpha, m, epsilon, max_iter = case\n        \n        F_func, J_func = _get_system_components(n, alpha)\n        \n        # Run Method B\n        convB, itB, assmB, normB = _run_solver(\n            F_func, J_func, n, m, epsilon, max_iter, 'B'\n        )\n        # Run Method A\n        convA, itA, assmA, normA = _run_solver(\n            F_func, J_func, n, m, epsilon, max_iter, 'A'\n        )\n        \n        # Format results for the current case as a list of strings\n        case_result_list = [\n            str(convB), str(itB), str(assmB), f\"{normB:.6e}\",\n            str(convA), str(itA), str(assmA), f\"{normA:.6e}\"\n        ]\n        all_results.append(f\"[{','.join(case_result_list)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3444521"}, {"introduction": "并非所有非线性问题都最适合用 Newton 法求解；许多问题天然地呈现为不动点形式 $u=G(u)$。对于这类问题，简单的 Picard 迭代虽然直观，但收敛通常很慢。本练习 ([@problem_id:3444579]) 介绍了一种强大的序列加速技术——Anderson 加速法，它能显著提升不动点迭代的收敛速度，是现代科学计算中的一个关键工具。", "problem": "考虑具有逻辑斯谛反应的自治标量偏微分方程 (PDE)，在每个空间网格点上写作 $\\frac{\\partial u}{\\partial t} = \\alpha\\,u\\,(1-u)$，其中 $\\alpha  0$ 是一个反应速率。应用后向欧拉时间离散化，仅关注反应项，并考虑一个恰好有两个独立网格点的网格。设前一时间步的值为 $u^n = \\begin{bmatrix} u^n_1 \\\\ u^n_2 \\end{bmatrix}$，并将时间步长表示为 $\\Delta t  0$。在新的时间层 $n+1$ 处的后向欧拉更新需要求解非线性代数系统\n$$\nu = u^n + \\Delta t\\,\\alpha\\,u\\,(1-u),\n$$\n其中 $u = \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix}$ 并且乘积是按分量计算的。这引出了一个不动点映射 $G:\\mathbb{R}^2 \\to \\mathbb{R}^2$，定义为\n$$\nG(u) \\equiv u^n + \\Delta t\\,\\alpha\\,u\\,(1-u).\n$$\n将任意迭代 $u$ 的非线性残差定义为\n$$\nr(u) \\equiv G(u) - u,\n$$\n并通过欧几里得范数 $\\|r(u)\\|_2$ (无量纲) 来衡量其大小。\n\n您必须从指定的初始猜测 $u^{(0)}$ 开始，为不動點方程 $u = G(u)$ 实现两种迭代求解器：\n\n1. Picard 迭代 (普通不动点迭代)，其更新方式为 $u^{(k+1)} = G\\!\\left(u^{(k)}\\right)$。\n\n2. 应用于不动点迭代的 Anderson 加速 (AA)，窗口大小 $m = 1$。对于 $m = 1$，在迭代 $k \\geq 1$ 时，使用最近的两个残差和它们在 $G$ 下对应的像，通过求解一个一维最小二乘 (LS) 问题来确定一个混合系数，该问题旨在最小化加速后残差的范数。加速更新必须由最近的 $G$ 映射像的线性组合构成，并与不动点问题的 Anderson 加速构造保持一致。如果最小二乘最小化问题退化 (例如，因为正规方程中的分母为零)，则在该次迭代中将混合系数设置为 $0$。\n\n您的任务是：\n\n- 为反应项的后向欧拉离散化所引出的双变量非线性系统实现映射 $G(u)$ 和残差 $r(u)$。\n- 从 $u^{(0)}$ 开始，精确计算两次 Picard 迭代，得到 $u^{(2)}_{\\mathrm{P}}$，然后计算残差范数 $\\left\\|r\\!\\left(u^{(2)}_{\\mathrm{P}}\\right)\\right\\|_2$。\n- 从相同的 $u^{(0)}$ 开始，应用窗口大小 $m = 1$ 的 Anderson 加速，精确计算两次加速迭代，得到 $u^{(2)}_{\\mathrm{AA}}$，然后计算残差范数 $\\left\\|r\\!\\left(u^{(2)}_{\\mathrm{AA}}\\right)\\right\\|_2$。\n- 对每个测试用例，报告定义为两次迭代后残差范数之差的改进值，\n$$\nI \\equiv \\left\\|r\\!\\left(u^{(2)}_{\\mathrm{P}}\\right)\\right\\|_2 - \\left\\|r\\!\\left(u^{(2)}_{\\mathrm{AA}}\\right)\\right\\|_2,\n$$\n这是一个实数。正数 $I$ 表示 Anderson 加速比 Picard 迭代更多地减小了残差，零 $I$ 表示性能相同，负数 $I$ 表示 Anderson 加速在两步内的残差减小效果更差。\n\n由于所有量都是无量纲的，因此没有物理单位。不涉及角度。所有输出都必须是实数。\n\n使用以下参数值和初始条件的测试套件。在每种情况下，初始猜测都取为 $u^{(0)} = u^n$。\n\n- 情况 A (一般非线性区域)：$\\alpha = 3.0$，$\\Delta t = 0.5$，$u^n = \\begin{bmatrix}0.2 \\\\ 0.8\\end{bmatrix}$。\n- 情况 B (近线性区域)：$\\alpha = 1.0$，$\\Delta t = 0.05$，$u^n = \\begin{bmatrix}0.45 \\\\ 0.55\\end{bmatrix}$。\n- 情况 C (强非线性)：$\\alpha = 4.0$，$\\Delta t = 1.0$，$u^n = \\begin{bmatrix}0.01 \\\\ 0.99\\end{bmatrix}$。\n- 情况 D (退化步)：$\\alpha = 2.5$，$\\Delta t = 0.0$，$u^n = \\begin{bmatrix}0.3 \\\\ 0.7\\end{bmatrix}$。\n\n您的程序应生成单行输出，其中包含四个情况的改进值，以逗号分隔的列表形式包含在方括号中，顺序为 A, B, C, D，例如 $\\left[\\text{result}_A,\\text{result}_B,\\text{result}_C,\\text{result}_D\\right]$。", "solution": "用户提供了一个定义明确的数值问题。我将首先验证问题陈述，然后进行详细的解答。\n\n### 步骤 1：提取已知条件\n- **PDE 离散化**：在每个网格点上，对反应项 $\\frac{\\partial u}{\\partial t} = \\alpha\\,u\\,(1-u)$ 进行后向欧拉离散化，得到非线性代数系统：\n$$u = u^n + \\Delta t\\,\\alpha\\,u\\,(1-u)$$\n其中 $u$ 是新时间步的解向量，$u^n$ 是前一时间步的解，$\\alpha  0$ 是反应速率，$\\Delta t  0$ 是时间步长。该系统是二维的，所以 $u = \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix}$ 且 $u^n = \\begin{bmatrix} u^n_1 \\\\ u^n_2 \\end{bmatrix}$。乘积按分量计算。\n- **不动点映射**：$G(u) \\equiv u^n + \\Delta t\\,\\alpha\\,u\\,(1-u)$。\n- **残差**：$r(u) \\equiv G(u) - u$。\n- **误差度量**：残差的欧几里得范数 $\\|r(u)\\|_2$。\n- **初始猜测**：对于所有迭代，初始猜测为 $u^{(0)} = u^n$。\n\n- **求解器 1 (Picard 迭代)**：\n  - **更新规则**：$u^{(k+1)} = G(u^{(k)})$。\n  - **任务**：计算两次迭代以找到 $u^{(2)}_{\\mathrm{P}}$，然后计算残差范数 $\\|r(u^{(2)}_{\\mathrm{P}})\\|_2$。\n\n- **求解器 2 (Anderson 加速, AA)**：\n  - **配置**：窗口大小 $m = 1$。\n  - **任务**：计算两次迭代以找到 $u^{(2)}_{\\mathrm{AA}}$，然后计算残差范数 $\\|r(u^{(2)}_{\\mathrm{AA}})\\|_2$。\n  - **方法**：第一步是 Picard 步。第二步涉及求解一个一维最小二乘问题以找到混合系数。如果最小二乘问题退化，则系数设置为 $0$。\n\n- **最终输出度量**：改进值 $I \\equiv \\|r(u^{(2)}_{\\mathrm{P}})\\|_2 - \\|r(u^{(2)}_{\\mathrm{AA}})\\|_2$。\n\n- **测试用例**：\n  - **情况 A**: $\\alpha = 3.0$, $\\Delta t = 0.5$, $u^n = \\begin{bmatrix}0.2 \\\\ 0.8\\end{bmatrix}$。\n  - **情况 B**: $\\alpha = 1.0$, $\\Delta t = 0.05$, $u^n = \\begin{bmatrix}0.45 \\\\ 0.55\\end{bmatrix}$。\n  - **情况 C**: $\\alpha = 4.0$, $\\Delta t = 1.0$, $u^n = \\begin{bmatrix}0.01 \\\\ 0.99\\end{bmatrix}$。\n  - **情况 D**: $\\alpha = 2.5$, $\\Delta t = 0.0$, $u^n = \\begin{bmatrix}0.3 \\\\ 0.7\\end{bmatrix}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准对问题进行评估。\n- **科学依据**：该问题基于逻辑斯谛微分方程、后向欧拉法、Picard 迭代和 Anderson 加速，这些都是应用数学和科学计算中的标准和基本概念。\n- **适定性**：问题被严谨地指定。所有参数、初始条件和算法都得到了清晰的定义，从而为每个测试用例得出了唯一的、可计算的结果。\n- **客观性**：问题陈述是精确和数学化的，没有任何主观或模糊的语言。\n- **缺陷分析**：\n  1.  **科学或事实上的不健全性**：无。所用的数学和数值方法都是标准的。\n  2.  **非形式化或不相关**：无。该问题是指定领域内的直接且相关的应用。\n  3.  **不完整或矛盾的设置**：无。提供了所有必要的信息。情况 D 中 $\\Delta t = 0$，代表了一个有效但平凡的极限情况，其中 $G(u) = u^n$，这不会引入矛盾。\n  4.  **不切实际或不可行**：无。这些参数用于数值模拟，不代表物理上的不可能性。\n  5.  **不适定或结构不良**：无。算法是确定性的，将产生唯一的结果。\n  6.  **伪深刻、琐碎或同义反复**：无。虽然情况 D很简单，但它可以作为对实现的一个有效检验。整个问题需要对非平凡算法的正确实现。\n  7.  **超出科学可验证性**：无。结果可以被独立计算和验证。\n\n### 步骤 3：结论与行动\n问题是 **有效的**。将提供详细的解决方案。\n\n### 基于原则的设计\n\n核心任务是求解 $u \\in \\mathbb{R}^2$ 的不动点方程 $u = G(u)$。我们将实现两种迭代方法，并在两步之后比较它们的性能。\n\n**1. Picard 迭代**\n这种方法，也称为不动点迭代，是最直接的方法。给定一个迭代 $u^{(k)}$，下一个迭代通过简单地评估映射来计算：\n$$u^{(k+1)} = G\\left(u^{(k)}\\right)$$\n对于这个问题，我们从 $u^{(0)} = u^n$ 开始计算：\n- 第一次迭代：$u^{(1)}_{\\mathrm{P}} = G(u^{(0)}) = u^n + \\Delta t\\,\\alpha\\,u^{(0)}\\,(1-u^{(0)})$。\n- 第二次迭代：$u^{(2)}_{\\mathrm{P}} = G(u^{(1)}_{\\mathrm{P}}) = u^n + \\Delta t\\,\\alpha\\,u^{(1)}_{\\mathrm{P}}\\,(1-u^{(1)}_{\\mathrm{P}})$。\n最后，我们计算第二次迭代的残差范数：$\\|r(u^{(2)}_{\\mathrm{P}})\\|_2 = \\|G(u^{(2)}_{\\mathrm{P}})-u^{(2)}_{\\mathrm{P}}\\|_2$。\n\n**2. Anderson 加速 (AA)，$m=1$**\nAnderson 加速是加速不动点迭代收敛的一种方法。它不只使用最后一个点 $u^{(k)}$ 来生成 $u^{(k+1)}$，而是使用最近迭代的历史来形成一个更好的下一个猜测。对于窗口大小 $m=1$，它使用最后两个点的信息。\n\n两次迭代的步骤如下：\n- **初始猜测**：$u^{(0)}_{\\mathrm{AA}} = u^n$。\n- **第一次迭代 ($k=0$)**：AA 的第一步始终是标准的 Picard 步，以建立历史。\n$$u^{(1)}_{\\mathrm{AA}} = G\\left(u^{(0)}_{\\mathrm{AA}}\\right)$$\n- **第二次迭代 ($k=1$)**：这是第一个加速步。目标是找到先前函数评估值 $g^{(0)} = G(u^{(0)}_{\\mathrm{AA}})$ 和 $g^{(1)} = G(u^{(1)}_{\\mathrm{AA}})$ 的最优线性组合，以产生下一个迭代 $u^{(2)}_{\\mathrm{AA}}$。更新的形式为：\n$$u^{(2)}_{\\mathrm{AA}} = (1-\\gamma)g^{(1)} + \\gamma g^{(0)} = g^{(1)} - \\gamma(g^{(1)}-g^{(0)})$$\n系数 $\\gamma$（在一些文献中表示为 $\\alpha_1$）是通过求解一个一维线性最小二乘问题来确定的。该问题旨在最小化下一个残差的范数。设 $r^{(k)} = G(u^{(k)}) - u^{(k)}$。系数 $\\gamma$ 通过最小化以下表达式找到：\n$$\\min_{\\gamma} \\left\\| r^{(1)} - \\gamma \\left( r^{(1)} - r^{(0)} \\right) \\right\\|_2^2$$\n这个最小二乘问题的解由正规方程给出：\n$$\\gamma = \\frac{\\left\\langle r^{(1)} - r^{(0)}, r^{(1)} \\right\\rangle}{\\left\\| r^{(1)} - r^{(0)} \\right\\|_2^2}$$\n其中 $\\langle \\cdot, \\cdot \\rangle$ 表示向量内积。根据问题陈述，如果分母 $\\| r^{(1)} - r^{(0)} \\|_2^2$ 为零（或数值上接近于零），我们设置 $\\gamma = 0$。这可以防止除以零，并对应于退回到标准的 Picard 步。\n\nAA 计算的步骤是：\n1. 初始化 $u^{(0)}_{\\mathrm{AA}} = u^n$。\n2. 计算 $u^{(1)}_{\\mathrm{AA}} = G(u^{(0)}_{\\mathrm{AA}})$。\n3. 定义像 $g^{(0)} = u^{(1)}_{\\mathrm{AA}}$ 和 $g^{(1)} = G(u^{(1)}_{\\mathrm{AA}})$。\n4. 计算残差 $r^{(0)} = g^{(0)} - u^{(0)}_{\\mathrm{AA}}$ 和 $r^{(1)} = g^{(1)} - u^{(1)}_{\\mathrm{AA}}$。\n5. 计算残差差值 $\\Delta r^{(0)} = r^{(1)} - r^{(0)}$。\n6. 计算系数 $\\gamma$。如果 $(\\Delta r^{(0)})^T(\\Delta r^{(0)}) \\approx 0$，则设置 $\\gamma=0$。否则，$\\gamma = ((\\Delta r^{(0)})^T r^{(1)}) / ((\\Delta r^{(0)})^T(\\Delta r^{(0)}))$。\n7. 计算第二次迭代：$u^{(2)}_{\\mathrm{AA}} = g^{(1)} - \\gamma(g^{(1)} - g^{(0)})$。\n8. 计算最终残差范数：$\\|r(u^{(2)}_{\\mathrm{AA}})\\|_2 = \\|G(u^{(2)}_{\\mathrm{AA}})-u^{(2)}_{\\mathrm{AA}}\\|_2$。\n\n**3. 改进度量**\n对于每个测试用例，我们计算两次迭代后残差范数的差值，以量化 AA 相对于 Picard 的性能增益：\n$$I = \\|r(u^{(2)}_{\\mathrm{P}})\\|_2 - \\|r(u^{(2)}_{\\mathrm{AA}})\\|_2$$\n\n实现将对每个提供的测试用例遵循这些步骤。数值计算将使用 `numpy` 进行向量运算和范数计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all specified test cases.\n    It implements Picard iteration and Anderson acceleration (m=1) to solve a\n    nonlinear system, then compares their performance.\n    \"\"\"\n\n    def run_case(alpha, dt, un_list):\n        \"\"\"\n        Calculates the improvement metric for a single test case.\n\n        Args:\n            alpha (float): The reaction rate coefficient.\n            dt (float): The time step.\n            un_list (list): The solution vector from the previous time step.\n\n        Returns:\n            float: The improvement metric I.\n        \"\"\"\n        un = np.array(un_list, dtype=np.float64)\n        \n        # Define the fixed-point mapping G(u)\n        def G(u_vec):\n            return un + dt * alpha * u_vec * (1.0 - u_vec)\n\n        # Define the residual function r(u) = G(u) - u\n        def r(u_vec):\n            return G(u_vec) - u_vec\n\n        # --- Solver 1: Picard Iteration ---\n        # Initial guess\n        u0_p = un\n        \n        # First iterate\n        u1_p = G(u0_p)\n        \n        # Second iterate\n        u2_p = G(u1_p)\n        \n        # Compute the norm of the residual at the second iterate\n        residual_p = r(u2_p)\n        norm_res_p = np.linalg.norm(residual_p)\n\n        # --- Solver 2: Anderson Acceleration (m=1) ---\n        # Initial guess\n        u0_aa = un\n        \n        # Iteration k=0 -> k=1: Plain Picard step to build history\n        u1_aa = G(u0_aa)\n\n        # Iteration k=1 -> k=2: First accelerated step\n        # We need g_0 = G(u_0) and g_1 = G(u_1)\n        g0 = u1_aa  # This is G(u0_aa)\n        g1 = G(u1_aa)\n\n        # Compute residuals r_0 = g_0 - u_0 and r_1 = g_1 - u_1\n        r0 = g0 - u0_aa\n        r1 = g1 - u1_aa\n\n        # Compute residual difference delta_r_0 = r_1 - r_0\n        delta_r0 = r1 - r0\n        \n        # Solve the 1D least-squares problem for the mixing coefficient gamma.\n        gamma = 0.0\n        denom = np.dot(delta_r0, delta_r0)\n        if denom > 1e-12: # Check for degeneracy as per problem statement\n            num = np.dot(delta_r0, r1)\n            gamma = num / denom\n            \n        # Compute the second iterate using the Anderson update\n        u2_aa = g1 - gamma * (g1 - g0)\n        \n        # Compute the norm of the residual at the second accelerated iterate\n        residual_aa = r(u2_aa)\n        norm_res_aa = np.linalg.norm(residual_aa)\n        \n        # Calculate the improvement metric\n        improvement = norm_res_p - norm_res_aa\n        return improvement\n\n    # Test suite from the problem description\n    test_cases = {\n        'A': (3.0, 0.5, [0.2, 0.8]),\n        'B': (1.0, 0.05, [0.45, 0.55]),\n        'C': (4.0, 1.0, [0.01, 0.99]),\n        'D': (2.5, 0.0, [0.3, 0.7])\n    }\n    \n    results = []\n    for case_id in ['A', 'B', 'C', 'D']:\n        alpha, dt, un_list = test_cases[case_id]\n        result = run_case(alpha, dt, un_list)\n        results.append(str(result))\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3444579"}]}