{"hands_on_practices": [{"introduction": "在高性能计算中，选择合适的预处理器是优化求解器性能的关键一步。这道练习引导我们建立一个性能模型，用以量化比较两种不同预处理器之间的成本效益，其中一个设置成本较低但求解效率较差，另一个则相反。通过计算“盈亏平衡点”，即更昂贵的预处理器开始展现时间优势所需的最少求解次数，我们可以学会如何在一次性设置成本和重复的求解成本之间做出明智的权衡。", "problem": "一个包含 $K$ 个线性方程组的序列，源于对一个二阶椭圆偏微分方程的参数扫描。该方程使用有限元方法离散化，生成一个对称正定矩阵 $A \\in \\mathbb{R}^{N \\times N}$，此矩阵在求解具有不同右端项的方程时被重复使用。考虑一种克雷洛夫子空间方法，具体为广义最小残差（GMRES）方法，并采用两种可扩展方案之一进行预处理。预处理器 $\\mathcal{P}_{0}$ 是一种基准方法，其设置成本较低但迭代次数较多；而预处理器 $\\mathcal{P}_{1}$ 是一种成本更高的方法，但迭代次数较少。两种预处理器都与 $A$ 谱等价，并假定在目标离散化上，其迭代次数表现出良好的弱扩展性（即迭代次数大致独立于 $N$）。\n\n我们在 $P$ 个进程上采用一个强扩展性性能模型，并作出以下基本假设：\n- 每次迭代的预处理器应用成本被建模为计算和通信贡献之和。计算部分与 $N/P$ 成比例扩展，而通信部分主要由对数深度的归约操作主导，与 $\\ln(P)$ 成比例扩展。\n- 设置成本同样被建模为计算（与 $N/P$ 成正比）和通信（与 $\\ln(P)$ 成正比）部分之和。\n- 对于一个固定的预处理器，求解 $K$ 个右端项的总求解时间等于预处理器的设置时间，加上 $K$ 乘以单次迭代应用成本再乘以迭代次数。\n\n设 $N = 10^{8}$ 且 $P = 1024$。对于预处理器 $\\mathcal{P}_{0}$，每次迭代的应用成本为\n$$\nC_{\\text{apply}}^{(0)}(N,P) \\;=\\; \\alpha_{0}\\,\\frac{N}{P} \\;+\\; \\beta_{0}\\,\\ln(P),\n$$\n其中 $\\alpha_{0} = 4 \\times 10^{-8}$ 且 $\\beta_{0} = 2 \\times 10^{-3}$。其设置成本为\n$$\nC_{\\text{setup}}^{(0)}(N,P) \\;=\\; \\sigma_{0}\\,\\frac{N}{P} \\;+\\; \\theta_{0}\\,\\ln(P),\n$$\n其中 $\\sigma_{0} = 5 \\times 10^{-6}$ 且 $\\theta_{0} = 5 \\times 10^{-1}$。测得的 GMRES 迭代次数为 $m_{0} = 60$。\n\n对于预处理器 $\\mathcal{P}_{1}$，每次迭代的应用成本为\n$$\nC_{\\text{apply}}^{(1)}(N,P) \\;=\\; \\alpha_{1}\\,\\frac{N}{P} \\;+\\; \\beta_{1}\\,\\ln(P),\n$$\n其中 $\\alpha_{1} = 6 \\times 10^{-8}$ 且 $\\beta_{1} = 3 \\times 10^{-3}$。其设置成本为\n$$\nC_{\\text{setup}}^{(1)}(N,P) \\;=\\; \\sigma_{1}\\,\\frac{N}{P} \\;+\\; \\theta_{1}\\,\\ln(P),\n$$\n其中 $\\sigma_{1} = 1.5 \\times 10^{-5}$ 且 $\\theta_{1} = 1.2$。测得的 GMRES 迭代次数为 $m_{1} = 18$。\n\n仅使用上述强扩展性和成本模型的假设，建立一个成本模型来权衡设置成本 $C_{\\text{setup}}$、应用成本 $C_{\\text{apply}}$ 与迭代次数 $m$ 的减少，并计算使得使用 $\\mathcal{P}_{1}$ 的总求解时间与使用 $\\mathcal{P}_{0}$ 的总求解时间相等的盈亏平衡求解次数 $K^{\\star}$。将 $\\ln(P)$ 视为自然对数。将最终答案表示为一个无单位的实数，并四舍五入到三位有效数字。", "solution": "问题要求计算盈亏平衡的求解次数，记为 $K^{\\star}$，在该次数下，两种不同的预处理策略对一个线性方程组序列的总求解时间相同。在 $P$ 个进程上，使用预处理器 $\\mathcal{P}$ 求解 $K$ 个右端项的总时间，由一次性的设置成本和迭代求解的累积成本之和给出。\n\n令 $T^{(i)}(N, P, K)$ 为使用预处理器 $\\mathcal{P}_i$ 的总时间，其中 $i \\in \\{0,1\\}$。所提供的模型为：\n$$\nT^{(i)}(N, P, K) = C_{\\text{setup}}^{(i)}(N,P) + K \\cdot m_{i} \\cdot C_{\\text{apply}}^{(i)}(N,P)\n$$\n此处，$C_{\\text{setup}}^{(i)}(N,P)$ 是设置成本，$m_i$ 是 GMRES 迭代的次数，$C_{\\text{apply}}^{(i)}(N,P)$ 是每次迭代应用一次预处理器的成本。\n\n盈亏平衡点 $K^{\\star}$ 通过令两种预处理器的总时间相等来找到：\n$$\nT^{(0)}(N, P, K^{\\star}) = T^{(1)}(N, P, K^{\\star})\n$$\n代入总时间的表达式：\n$$\nC_{\\text{setup}}^{(0)}(N,P) + K^{\\star} \\cdot m_{0} \\cdot C_{\\text{apply}}^{(0)}(N,P) \\;=\\; C_{\\text{setup}}^{(1)}(N,P) + K^{\\star} \\cdot m_{1} \\cdot C_{\\text{apply}}^{(1)}(N,P)\n$$\n这是一个关于 $K^{\\star}$ 的线性方程。我们可以通过整理各项来求解 $K^{\\star}$：\n$$\nK^{\\star} \\left( m_{0} C_{\\text{apply}}^{(0)}(N,P) - m_{1} C_{\\text{apply}}^{(1)}(N,P) \\right) \\;=\\; C_{\\text{setup}}^{(1)}(N,P) - C_{\\text{setup}}^{(0)}(N,P)\n$$\n假设分母不为零，我们有：\n$$\nK^{\\star} \\;=\\; \\frac{C_{\\text{setup}}^{(1)}(N,P) - C_{\\text{setup}}^{(0)}(N,P)}{m_{0} C_{\\text{apply}}^{(0)}(N,P) - m_{1} C_{\\text{apply}}^{(1)}(N,P)}\n$$\n分子表示预处理器 $\\mathcal{P}_1$ 相对于 $\\mathcal{P}_0$ 的额外设置成本。分母表示每次求解时，使用 $\\mathcal{P}_1$ 相对于 $\\mathcal{P}_0$ 所节省的时间。\n\n现在，我们代入问题陈述中提供的具体成本模型。\n设置成本为 $C_{\\text{setup}}^{(i)}(N,P) = \\sigma_{i}\\frac{N}{P} + \\theta_{i}\\ln(P)$。\n每次迭代的应用成本为 $C_{\\text{apply}}^{(i)}(N,P) = \\alpha_{i}\\frac{N}{P} + \\beta_{i}\\ln(P)$。\n\n将这些代入 $K^{\\star}$ 的表达式中：\n$$\nK^{\\star} \\;=\\; \\frac{\\left(\\sigma_{1}\\frac{N}{P} + \\theta_{1}\\ln(P)\\right) - \\left(\\sigma_{0}\\frac{N}{P} + \\theta_{0}\\ln(P)\\right)}{m_{0}\\left(\\alpha_{0}\\frac{N}{P} + \\beta_{0}\\ln(P)\\right) - m_{1}\\left(\\alpha_{1}\\frac{N}{P} + \\beta_{1}\\ln(P)\\right)}\n$$\n我们可以按计算部分（与 $N/P$ 成正比）和通信部分（与 $\\ln(P)$ 成正比）对各项进行分组：\n$$\nK^{\\star} \\;=\\; \\frac{(\\sigma_{1} - \\sigma_{0})\\frac{N}{P} + (\\theta_{1} - \\theta_{0})\\ln(P)}{(m_{0}\\alpha_{0} - m_{1}\\alpha_{1})\\frac{N}{P} + (m_{0}\\beta_{0} - m_{1}\\beta_{1})\\ln(P)}\n$$\n我们已知以下数值：\n问题规模 $N = 10^{8}$。\n进程数 $P = 1024$。\n对于 $\\mathcal{P}_{0}$：$\\alpha_{0} = 4 \\times 10^{-8}$，$\\beta_{0} = 2 \\times 10^{-3}$，$\\sigma_{0} = 5 \\times 10^{-6}$，$\\theta_{0} = 0.5$，以及 $m_{0} = 60$。\n对于 $\\mathcal{P}_{1}$：$\\alpha_{1} = 6 \\times 10^{-8}$，$\\beta_{1} = 3 \\times 10^{-3}$，$\\sigma_{1} = 1.5 \\times 10^{-5}$，$\\theta_{1} = 1.2$，以及 $m_{1} = 18$。\n\n首先，我们计算公共项 $N/P$ 和 $\\ln(P)$：\n$$\n\\frac{N}{P} = \\frac{10^{8}}{1024} = 97656.25\n$$\n$$\n\\ln(P) = \\ln(1024) = \\ln(2^{10}) = 10 \\ln(2) \\approx 6.93147\n$$\n接下来，我们计算 $K^{\\star}$ 表达式中分子和分母的系数。\n\n对于分子：\n设置计算系数之差：$\\sigma_{1} - \\sigma_{0} = 1.5 \\times 10^{-5} - 5 \\times 10^{-6} = 1.5 \\times 10^{-5} - 0.5 \\times 10^{-5} = 1.0 \\times 10^{-5}$。\n设置通信系数之差：$\\theta_{1} - \\theta_{0} = 1.2 - 0.5 = 0.7$。\n\n对于分母：\n单次求解计算系数之差：$m_{0}\\alpha_{0} - m_{1}\\alpha_{1} = (60)(4 \\times 10^{-8}) - (18)(6 \\times 10^{-8}) = 2.4 \\times 10^{-6} - 1.08 \\times 10^{-6} = 1.32 \\times 10^{-6}$。\n单次求解通信系数之差：$m_{0}\\beta_{0} - m_{1}\\beta_{1} = (60)(2 \\times 10^{-3}) - (18)(3 \\times 10^{-3}) = 0.12 - 0.054 = 0.066$。\n\n现在，我们将这些系数代回 $K^{\\star}$ 的表达式中：\n$$\nK^{\\star} \\;=\\; \\frac{(1.0 \\times 10^{-5}) \\frac{N}{P} + (0.7) \\ln(P)}{(1.32 \\times 10^{-6}) \\frac{N}{P} + (0.066) \\ln(P)}\n$$\n让我们通过代入 $N/P$ 和 $\\ln(P)$ 的值来分别计算分子和分母：\n分子 = $(1.0 \\times 10^{-5})(97656.25) + (0.7)(10 \\ln(2)) = 0.9765625 + 7 \\ln(2)$。\n分母 = $(1.32 \\times 10^{-6})(97656.25) + (0.066)(10 \\ln(2)) = 0.12890625 + 0.66 \\ln(2)$。\n\n数值上：\n分子 $\\approx 0.9765625 + 7 \\times 0.69314718 = 0.9765625 + 4.85203026 = 5.82859276$。\n分母 $\\approx 0.12890625 + 0.66 \\times 0.69314718 = 0.12890625 + 0.45747714 = 0.58638339$。\n\n最后，我们计算比率：\n$$\nK^{\\star} \\approx \\frac{5.82859276}{0.58638339} \\approx 9.9398818\n$$\n问题要求答案四舍五入到三位有效数字。前三位有效数字是 $9$、$9$ 和 $3$。第四位有效数字是 $9$，大于等于 $5$，因此我们将第三位数字向上取整。\n$$\nK^{\\star} \\approx 9.94\n$$\n这意味着当求解次数超过 $9$ 或 $10$ 次时（取决于如何解释实数值的盈亏平衡点），成本更高的预处理器 $\\mathcal{P}_1$ 将比成本更低的基准预处理器 $\\mathcal{P}_0$ 更具时间效率。", "answer": "$$\\boxed{9.94}$$", "id": "3449800"}, {"introduction": "一个预处理器的“可扩展性”并非理所当然，它严重依赖于其核心组件（如粗空间）的正确设计。本练习是一个深刻的思维实验，它模拟了当一个两层区域分解预处理器的粗空间设计存在缺陷（例如，未能包含必要的刚体模态）时所产生的后果。通过从第一性原理推导迭代次数如何随着处理器数量 $P$ 的增加而增长，您将深入理解可扩展性的理论基础，并学会如何诊断那些在并行环境下性能退化的求解器。", "problem": "考虑一个在边长为 $L$ 的 $d$ 维空间超立方体上的二阶线性椭圆偏微分方程，其带有齐次狄利克雷边界条件。我们关注其对称正定离散化的数值解。设离散算子记为 $A \\in \\mathbb{R}^{n \\times n}$，它来自于间距为 $h$ 的拟一致网格上的协调有限元方法。假设采用一个标准的两层区域分解预条件子 $M^{-1}$，该预条件子由 $P$ 个直径相等（在形状正则性意义下）为 $H$ 的不重叠子区域，以及一个通过子区域迹的能量最小化延拓构建的粗空间构成。该预条件子用于预条件共轭梯度（PCG）方法中。\n\n粗空间旨在张成局部诺伊曼算子的近零空间以确保可扩展性，但假设它被错误指定：具体来说，它未能包含每个子区域的 $r$ 个刚体模态，而这些模态属于与底层连续微分算子相关的近零空间（例如，线性弹性力学中的平移和旋转）。为模拟此缺陷对可扩展性的影响，假设：\n\n1. 在由缺失的粗空间分量张成的子空间 $S$ 上，等效的两层方法的行为类似于一个单层方法，其全局庞加莱型常数由子区域图的直径决定。更准确地说，存在与 $P$、$h$ 和 $H$ 无关的正常数 $c_{1}$ 和 $C_{1}$，使得预条件算子 $M^{-1}A$ 的极端特征值满足\n$$\n\\lambda_{\\max}(M^{-1}A) \\leq C_{1}, \\quad \\lambda_{\\min}(M^{-1}A) \\geq c_{1} \\, P^{-2/d}.\n$$\n这个下界通过在子区域图上调用离散庞加莱不等式，模拟了 $S$ 上的最小瑞利商与沿坐标方向的子区域数量的平方成反比的缩放关系。\n\n2. 在 $S$ 之外，谱等价性成立，其界限与 $P$ 无关，因此条件数随 $P$ 的增长主要由在 $S$ 上的行为决定。\n\n采用标准的能量范数PCG误差缩减估计：经过 $m$ 次迭代后，\n$$\n\\frac{\\|e_{m}\\|_{A}}{\\|e_{0}\\|_{A}} \\leq 2 \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^{m},\n$$\n其中 $\\kappa$ 是 $M^{-1}A$ 的谱条件数。\n\n定义强可扩展性机制为固定 $n$ 同时增加 $P$（因此 $H \\approx L \\, P^{-1/d}$ 且 $h$ 固定），弱可扩展性机制为固定每个子区域的局部自由度（因此 $H/h$ 固定）同时增加 $P$（因此 $L \\approx H \\, P^{1/d}$）。在这两种机制下，上述假设都意味着条件数对 $P$ 具有相同的渐近依赖性。\n\n从第一性原理和给定假设出发，推导将能量范数误差减少一个预定因子 $\\varepsilon \\in (0,1)$ 所需的PCG迭代次数 $m_{\\varepsilon}(P)$ 的渐近表达式，该表达式应以 $P$、$d$、$\\varepsilon$ 以及常数 $c_{1}$ 和 $C_{1}$ 表示。将最终答案表示为无单位的单一闭式解析表达式。无需取整。\n\n此外，请提出有数学依据的诊断方法，这些方法能基于并行求解过程中可获取的量，自主检测所述的粗空间缺陷（缺失的刚体模态），并解释为什么这些诊断方法在强可扩展性和弱可扩展性下都能揭示该问题。\n\n你的最终答案必须仅为从上述模型推导出的 $m_{\\varepsilon}(P)$ 的单一解析表达式。", "solution": "问题要求做两件事：第一，推导为达到指定误差缩减所需的预条件共轭梯度（PCG）迭代次数 $m_{\\varepsilon}(P)$ 的渐近表达式；第二，提出用于检测问题陈述中所述的粗空间缺陷的诊断方法。\n\n首先，我们推导 $m_{\\varepsilon}(P)$ 的表达式。\nPCG方法的收敛性由预条件算子 $M^{-1}A$ 的谱条件数 $\\kappa$ 决定。条件数定义为最大特征值与最小特征值之比：\n$$\n\\kappa = \\kappa(M^{-1}A) = \\frac{\\lambda_{\\max}(M^{-1}A)}{\\lambda_{\\min}(M^{-1}A)}\n$$\n问题给出了 $M^{-1}A$ 的极端特征值的界。问题指出，在由缺失的粗空间分量张成的特定子空间 $S$ 上的行为主导了条件数的增长。给定的界是：\n$$\n\\lambda_{\\max}(M^{-1}A) \\leq C_{1}\n$$\n$$\n\\lambda_{\\min}(M^{-1}A) \\geq c_{1} \\, P^{-2/d}\n$$\n其中 $C_{1}$ 和 $c_{1}$ 是与子区域数量 $P$、网格间距 $h$ 和子区域大小 $H$ 无关的正常数。问题指出，这种对 $P$ 的依赖性在强可扩展性和弱可扩展性机制下都成立。\n\n为了找到条件数随 $P$ 增长的渐近行为，我们使用 $\\lambda_{\\max}$ 的上界和 $\\lambda_{\\min}$ 的下界。这给出了 $\\kappa$ 的一个上界，它决定了最坏情况下的收敛率。\n$$\n\\kappa(P) \\leq \\frac{C_{1}}{c_{1} \\, P^{-2/d}} = \\frac{C_{1}}{c_{1}} P^{2/d}\n$$\n让我们将常数前置因子表示为 $C = \\frac{C_1}{c_1}$。因此，条件数的渐近行为是 $\\kappa(P) \\propto P^{2/d}$。\n\n将误差的能量范数减少一个因子 $\\varepsilon \\in (0,1)$（即 $\\frac{\\|e_{m}\\|_{A}}{\\|e_{0}\\|_{A}} \\leq \\varepsilon$）所需的迭代次数 $m$，由标准的PCG误差估计给出：\n$$\n2 \\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^{m} \\leq \\varepsilon\n$$\n我们需要对 $m$ 求解这个不等式。设 $m_{\\varepsilon}(P)$ 是满足此条件的最小整数 $m$。我们寻求对于大的 $P$，$m_{\\varepsilon}(P)$ 的渐近表达式。\n重新整理不等式，我们得到：\n$$\n\\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)^{m} \\leq \\frac{\\varepsilon}{2}\n$$\n对两边取自然对数。由于 $\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}  1$，其对数为负，所以不等号反转：\n$$\nm \\ln\\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right) \\leq \\ln\\left( \\frac{\\varepsilon}{2} \\right)\n$$\n$$\nm \\geq \\frac{\\ln(\\varepsilon/2)}{\\ln\\left( \\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1} \\right)} = \\frac{-\\ln(2/\\varepsilon)}{-\\ln\\left( \\frac{\\sqrt{\\kappa} + 1}{\\sqrt{\\kappa} - 1} \\right)} = \\frac{\\ln(2/\\varepsilon)}{\\ln\\left( \\frac{\\sqrt{\\kappa} + 1}{\\sqrt{\\kappa} - 1} \\right)}\n$$\n我们关心的是当 $P \\rightarrow \\infty$ 时的渐近行为，这意味着 $\\kappa(P) \\rightarrow \\infty$。对于大的 $\\kappa$，我们可以近似分母中的对数项。设 $x = 1/\\sqrt{\\kappa}$。当 $\\kappa \\rightarrow \\infty$ 时，$x \\rightarrow 0$。该项变为 $\\ln\\left( \\frac{1+x}{1-x} \\right)$。\n对小的 $x$ 使用泰勒级数展开 $\\ln(1+x) = x - \\frac{x^2}{2} + O(x^3)$：\n$$\n\\ln\\left( \\frac{1+x}{1-x} \\right) = \\ln(1+x) - \\ln(1-x) = \\left(x - \\frac{x^2}{2} + \\dots\\right) - \\left(-x - \\frac{x^2}{2} - \\dots\\right) = 2x + O(x^3)\n$$\n因此，对于大的 $\\kappa$，我们有近似式：\n$$\n\\ln\\left( \\frac{\\sqrt{\\kappa} + 1}{\\sqrt{\\kappa} - 1} \\right) \\approx \\frac{2}{\\sqrt{\\kappa}}\n$$\n将此代入 $m$ 的表达式中：\n$$\nm_{\\varepsilon}(P) \\approx \\frac{\\ln(2/\\varepsilon)}{2/\\sqrt{\\kappa(P)}} = \\frac{1}{2} \\ln\\left(\\frac{2}{\\varepsilon}\\right) \\sqrt{\\kappa(P)}\n$$\n现在，我们代入条件数的渐近表达式 $\\kappa(P) \\approx \\frac{C_1}{c_1} P^{2/d}$：\n$$\nm_{\\varepsilon}(P) \\approx \\frac{1}{2} \\ln\\left(\\frac{2}{\\varepsilon}\\right) \\sqrt{\\frac{C_{1}}{c_{1}} P^{2/d}}\n$$\n简化表达式得到迭代次数的最终渐近形式：\n$$\nm_{\\varepsilon}(P) \\approx \\frac{1}{2} \\sqrt{\\frac{C_{1}}{c_{1}}} \\ln\\left(\\frac{2}{\\varepsilon}\\right) P^{1/d}\n$$\n这个表达式表明，迭代次数随着子区域数量的 $d$ 次方根增长，这是这类非可扩展两层预条件子的一个标志。\n\n接下来，我们提出有数学依据的诊断方法，以自主检测这种特定的粗空间缺陷。核心问题是预条件子未能与原始算子 $A$ 谱等价，且等价常数与 $P$ 无关。诊断方法应旨在揭示这种可扩展性的缺乏。\n\n1.  **迭代次数可扩展性分析：** 这是最直接和最简单的诊断方法。通过对递增的子区域/处理器数量 $P$ 求解问题来进行可扩展性研究。\n    -   在 **弱可扩展性** 研究中，每个子区域的局部问题规模（$H/h$）保持不变。对于一个可扩展的预条件子，条件数 $\\kappa$ 应有与 $P$ 无关的界，因此达到固定容差 $\\varepsilon$ 所需的迭代次数 $m$ 也应大致恒定。\n    -   在 **强可扩展性** 研究中，全局问题规模 $n$ 是固定的。对于一个可扩展的预条件子，$m$ 也应大致恒定。\n    -   **诊断方法：** 在对数-对数坐标系上绘制测得的迭代次数 $m(P)$ 与 $P$ 的关系图。如果预条件子是可扩展的，该图将是一条水平线（斜率为 $0$）。问题中描述的缺陷导致 $m(P) \\propto P^{1/d}$。因此，观察到一条正斜率约为 $1/d$ 的直线是特定类型粗空间失效的有力证据。由于 $\\kappa(P)$ 的模型被假定为相同，该诊断方法在弱可扩展性和强可扩展性下都有效。\n\n2.  **极端特征值估计：** PCG算法基于Lanczos迭代。Lanczos过程经过 $k$ 步后生成的三对角矩阵 $T_k$ 的特征值（称为Ritz值）是算子 $M^{-1}A$ 特征值的极好近似，尤其是对极端特征值。\n    -   **诊断方法：** 在PCG求解过程中，可以在每次迭代时或求解收敛后计算小型三对角矩阵 $T_k$ 的特征值。通过追踪计算出的最小Ritz值 $\\theta_{\\min}$ 作为 $P$ 的函数，可以直接检验模型的假设。\n    -   模型预测 $\\lambda_{\\min}(M^{-1}A) \\propto P^{-2/d}$，而 $\\lambda_{\\max}(M^{-1}A)$ 保持有界。因此，如果在对数-对数坐标系上绘制估计的 $\\theta_{\\min}(P)$ 与 $P$ 的关系图，应观察到一条斜率为 $-2/d$ 的直线。最大的估计Ritz值 $\\theta_{\\max}(P)$ 应保持大致恒定。这比仅仅依靠迭代次数提供了对问题更根本的确认，因为它直接探测了谱。\n\n3.  **粗问题分析：** 两层预条件子涉及求解一个粗问题，其矩阵为 $A_0 = R_0 A R_0^T$，其中 $R_0^T$ 是从粗空间到细网格的插值算子。粗空间的目的是处理那些不能被局部的子区域求解很好地衰减的低能量模态。\n    -   粗基中缺少刚体模态意味着这些模态在粗网格上没有得到适当的表示。这使得粗问题矩阵 $A_0$ 本身是病态的。全局问题的“松弛性”本应由粗求解来约束，现在却反映在一个条件恶劣的 $A_0$ 中。\n    -   **诊断方法：** 显式地构建粗矩阵 $A_0$ 并计算其条件数 $\\kappa(A_0)$。$A_0$ 的大小与 $P$ 成正比（具体来说，如果每个子区域有 $k$ 个基函数，则大小为 $kP \\times kP$），因此这通常是可行的。对于设计良好、可扩展的预条件子，$\\kappa(A_0)$ 应有界或随 $P$ 的增长非常温和。对于有缺陷的预条件子，$\\kappa(A_0)$ 将随 $P$ 呈现强劲增长，通常具有幂律依赖性，例如 $\\kappa(A_0) \\propto P^{2/d}$，这反映了整个预条件系统的可扩展性。这种诊断方法更具侵入性，但能直接将失败的原因精确定位到预条件子的粗分量上。\n\n总之，从业者会首先注意到迭代次数的不良可扩展性（诊断方法1）。为了确认原因，他们会通过Ritz值分析谱，以观察到一个衰减的最小特征值（诊断方法2）。最后，为证明粗空间是罪魁祸首，他们会分析粗问题矩阵本身（诊断方法3）。", "answer": "$$\\boxed{\\frac{1}{2} \\sqrt{\\frac{C_{1}}{c_{1}}} \\ln\\left(\\frac{2}{\\varepsilon}\\right) P^{1/d}}$$", "id": "3449762"}, {"introduction": "在进行大规模弱扩展性分析时，计算效率并非唯一瓶颈，内存消耗同样至关重要。此练习聚焦于代数多重网格（AMG）方法中的一个实际挑战：随着处理器数量的增加，粗网格上的算子会变得越来越稠密，从而导致单个计算核心的内存压力剧增。您将构建一个模型来量化这种内存压力如何反过来影响计算时间，并评估一种名为“积极剪枝”的算法策略在缓解此问题上的有效性，从而将硬件约束纳入性能优化的考量之中。", "problem": "考虑在Krylov方法中使用的代数多重网格（AMG）预条件子，用于数值求解偏微分方程（PDEs）。重点关注弱扩展性（weak scaling），其中总问题规模与处理单元数量成比例增长，而每个处理单元的局部问题规模保持不变。在此设定下，我们旨在量化粗网格算子密度增长如何影响每核心内存，并进而降低弱扩展性的并行效率。\n\n使用以下基本依据和定义，除所述假设外，不引入任何简化公式：\n\n- 弱扩展性假设每个核心的局部自由度（记为 $n_{\\mathrm{local}}$）随着处理单元数量 $P$ 的增加而保持不变。\n- 弱扩展性下的并行效率（记为 $E(P)$）定义为 $E(P) = \\dfrac{T(1)}{T(P)}$，其中 $T(P)$ 是在 $P$ 个处理单元上每次AMG V-cycle的墙上时钟时间，而 $T(1)$ 是在具有 $n_{\\mathrm{local}}$ 个自由度的单个处理单元上每次V-cycle的时间。\n- AMG算子的每核心内存主要由各层级的非零元素存储决定。设第 $l$ 层的平均每行非零元数量为 $z_l(P)$，由于粗网格上密度的增加，该值可能随 $P$ 增长。设每个非零元的字节数为 $b_{\\mathrm{nz}}$，每个自由度存储的辅助向量数量为 $v_{\\mathrm{mult}}$，每个向量条目占8字节。则每核心的内存占用 $M(P)$（以吉比字节/GiB为单位）建模为\n$$\nM(P) = \\frac{n_{\\mathrm{local}} \\, b_{\\mathrm{nz}} \\sum_{l=1}^{L} z_l(P) + n_{\\mathrm{local}} \\cdot v_{\\mathrm{mult}} \\cdot 8}{1024^3}.\n$$\n- 粗网格密度增长模型由下式给出\n$$\nz_l(P) = z_{l,0} \\left(1 + c_l \\, P^{\\gamma_l}\\right),\n$$\n其中 $z_{l,0}$ 是在 $P=1$ 时每行的基础非零元数量，$c_l \\ge 0$ 控制增长幅度，$\\gamma_l \\ge 0$ 控制增长率。\n- 内存压力通过一个乘法惩罚因子来修正计算时间。惩罚因子 $\\phi(M)$ 定义为\n$$\n\\phi(M) = \n\\begin{cases}\n1,  M \\le M_{\\mathrm{thr}},\\\\\n1 + \\kappa \\, \\dfrac{M - M_{\\mathrm{thr}}}{M_{\\mathrm{thr}}},  M  M_{\\mathrm{thr}},\n\\end{cases}\n$$\n其中 $M_{\\mathrm{thr}}$ 是每核心的内存阈值（GiB），$\\kappa  0$ 量化了对内存压力的敏感度。\n- 每次V-cycle的每核心计算时间与算子复杂度成正比：\n$$\nT_{\\mathrm{comp}}(P) = t_0 \\, \\frac{\\sum_{l=1}^{L} z_l(P)}{\\sum_{l=1}^{L} z_l(1)},\n$$\n其中 $t_0$ 是 $P=1$ 时的基线计算时间。\n- 弱扩展性下的通信时间建模为\n$$\nT_{\\mathrm{comm}}(P) = a \\, \\log_2(P),\n$$\n其中 $a  0$ 代表通信成本的扩展系数。\n- 每次V-cycle的总时间是\n$$\nT(P) = \\phi\\!\\left(M(P)\\right) \\, T_{\\mathrm{comp}}(P) + T_{\\mathrm{comm}}(P).\n$$\n\n定义阈值 $P^\\star$ 为满足 $M(P)  M_{\\mathrm{thr}}$ 的最小整数 $P \\ge 1$。如果在 $P \\le P_{\\max}$ 范围内不存在这样的 $P$，则报告 $P^\\star = -1$。考虑一种积极的插值裁剪策略，该策略将基础模板大小和增长系数都乘以一个因子 $\\rho \\in (0,1)$：\n$$\nz^{\\mathrm{prune}}_l(P) = \\rho \\, z_{l,0} \\left(1 + \\rho \\, c_l \\, P^{\\gamma_l}\\right).\n$$\n在裁剪策略下，类似地重新计算 $M^{\\mathrm{prune}}(P)$、$T^{\\mathrm{prune}}(P)$ 和 $E^{\\mathrm{prune}}(P)$。\n\n任务：\n1. 对每个测试用例，计算阈值 $P^\\star$。\n2. 对每个测试用例，计算裁剪前和裁剪后的弱扩展性并行效率 $E(P_{\\max})$ 和 $E^{\\mathrm{prune}}(P_{\\max})$。时间以秒为单位，内存以吉比字节为单位，效率以四舍五入到六位小数的小数形式报告。\n\n您的程序应使用以下测试套件（每个用例都是独立的，并使用其自己的参数）：\n\n- 用例 A（理想情况）：\n  - $n_{\\mathrm{local}} = 5 \\times 10^5$, $L = 4$, $z_{l,0} = [20, 15, 12, 400]$, $c_l = [0.02, 0.03, 0.05, 0.10]$, $\\gamma_l = [0.25, 0.25, 0.25, 0.5]$, $b_{\\mathrm{nz}} = 12$, $v_{\\mathrm{mult}} = 6$, $M_{\\mathrm{thr}} = 8$, $t_0 = 1.0$, $a = 0.03$, $\\kappa = 0.5$, $P_{\\max} = 4096$, $\\rho = 0.5$.\n- 用例 B（边界情况，无密度增长）：\n  - $n_{\\mathrm{local}} = 5 \\times 10^5$, $L = 4$, $z_{l,0} = [20, 15, 12, 200]$, $c_l = [0, 0, 0, 0]$, $\\gamma_l = [0, 0, 0, 0]$, $b_{\\mathrm{nz}} = 12$, $v_{\\mathrm{mult}} = 6$, $M_{\\mathrm{thr}} = 8$, $t_0 = 1.0$, $a = 0.03$, $\\kappa = 0.5$, $P_{\\max} = 4096$, $\\rho = 0.5$.\n- 用例 C（边缘情况，粗网格上急剧增长）：\n  - $n_{\\mathrm{local}} = 5 \\times 10^5$, $L = 3$, $z_{l,0} = [25, 18, 600]$, $c_l = [0.05, 0.08, 0.20]$, $\\gamma_l = [0.3, 0.3, 0.6]$, $b_{\\mathrm{nz}} = 12$, $v_{\\mathrm{mult}} = 6$, $M_{\\mathrm{thr}} = 12$, $t_0 = 1.4$, $a = 0.04$, $\\kappa = 0.6$, $P_{\\max} = 1024$, $\\rho = 0.4$.\n\n输出规范：\n- 您的程序应生成单行输出，其中包含三个用例的结果，格式为一个无空格、由方括号括起来的逗号分隔列表。每个用例的结果本身是一个形式为 $[P^\\star,E(P_{\\max}),E^{\\mathrm{prune}}(P_{\\max})]$ 的列表。例如：$[[1,0.900000,0.950000],[\\dots],[\\dots]]$。", "solution": "所提供的问题是并行数值算法性能建模的一个有效练习。它描述了代数多重网格（AMG）预条件求解器的弱扩展性场景，并为内存使用、计算时间和通信时间提供了一套相互关联的数学模型。该问题在科学上基于高性能计算和数值线性代数中的既定概念，例如算子复杂度、并行AMG中的粗网格密度增长以及内存限制下的性能下降。该问题是适定的（well-posed），提供了计算所要求数量所需的所有必要参数和函数形式。任务具体且计算上是可行的。因此，我们着手提供详细的解决方案。\n\n问题的核心是计算弱扩展性并行效率 $E(P)$，其定义为：\n$$\nE(P) = \\frac{T(1)}{T(P)}\n$$\n其中 $T(P)$ 是在 $P$ 个处理单元上完成一次V-cycle的总墙上时钟时间。在单个处理器上的时间 $T(1)$ 作为基准。总时间 $T(P)$ 建模为计算部分和通信部分之和：\n$$\nT(P) = T_{\\mathrm{total\\_comp}}(P) + T_{\\mathrm{comm}}(P)\n$$\n通信时间通过一个标准的对数项建模，该项反映了在具有类二分拓扑结构的网络上进行全局归约或数据交换的成本：\n$$\nT_{\\mathrm{comm}}(P) = a \\log_2(P)\n$$\n对于 $P=1$，$T_{\\mathrm{comm}}(1) = a \\log_2(1) = 0$，这在物理上是正确的，因为单个进程不与其它进程通信。\n\n计算时间更为复杂，因为它受到内存压力的影响。它被建模为基线计算时间 $T_{\\mathrm{comp}}(P)$ 乘以内存惩罚因子 $\\phi(M(P))$：\n$$\nT_{\\mathrm{total\\_comp}}(P) = \\phi(M(P)) \\, T_{\\mathrm{comp}}(P)\n$$\n基线计算时间 $T_{\\mathrm{comp}}(P)$ 与算子复杂度成正比，算子复杂度是每个核心存储的AMG层次结构中非零元素的总数。这通过 $P=1$ 时的复杂度进行归一化：\n$$\nT_{\\mathrm{comp}}(P) = t_0 \\, \\frac{\\sum_{l=1}^{L} z_l(P)}{\\sum_{l=1}^{L} z_l(1)}\n$$\n其中 $z_l(P)$ 是在 $P$ 个处理器上运行时，多重网格第 $l$ 层的平均每行非零元数量。注意，$T_{\\mathrm{comp}}(1) = t_0$。\n\n惩罚因子 $\\phi(M)$ 是一个分段函数，仅当每核心内存占用 $M(P)$ 超过阈值 $M_{\\mathrm{thr}}$ 时，其值才大于1：\n$$\n\\phi(M) = \n\\begin{cases}\n1,  M \\le M_{\\mathrm{thr}} \\\\\n1 + \\kappa \\, \\dfrac{M - M_{\\mathrm{thr}}}{M_{\\mathrm{thr}}},  M  M_{\\mathrm{thr}}\n\\end{cases}\n$$\n这模拟了当工作集大小超过高速缓存或可用DRAM容量时导致的性能下降，从而引起更慢的内存访问。\n\n每核心的内存占用 $M(P)$（以吉比字节/GiB为单位）取决于算子非零元和辅助向量的存储：\n$$\nM(P) = \\frac{n_{\\mathrm{local}} \\, b_{\\mathrm{nz}} \\sum_{l=1}^{L} z_l(P) + n_{\\mathrm{local}} \\cdot v_{\\mathrm{mult}} \\cdot 8}{1024^3}\n$$\n该模型中弱扩展性行为的关键是粗网格算子密度的增长，由 $z_l(P)$ 捕获：\n$$\nz_l(P) = z_{l,0} \\left(1 + c_l \\, P^{\\gamma_l}\\right)\n$$\n随着 $P$ 的增加，项 $P^{\\gamma_l}$ 导致 $z_l(P)$ 增长，这反过来又增加了内存使用量 $M(P)$ 和基线计算时间 $T_{\\mathrm{comp}}(P)$。\n\n每个测试用例的计算过程如下：\n\n1.  确定内存压力阈值 $P^\\star$：这是使得 $M(P)  M_{\\mathrm{thr}}$ 成立的最小整数 $P \\ge 1$。我们可以通过从 $1$ 到 $P_{\\max}$ 迭代 $P$ 并在每一步计算 $M(P)$ 来找到它。第一个满足不等式的 $P$ 就是 $P^\\star$。如果在 $P_{\\max}$ 范围内不存在这样的 $P$，则报告 $P^\\star = -1$。\n\n2.  计算并行效率 $E(P_{\\max})$：\n    a.  计算参考时间 $T(1)$。这包括计算 $\\sum z_l(1)$，然后计算 $M(1)$，接着是 $\\phi(M(1))$，最后是 $T(1) = \\phi(M(1)) \\cdot t_0$。\n    b.  计算扩展后的时间 $T(P_{\\max})$。这遵循相同的顺序：计算 $\\sum z_l(P_{\\max})$，然后是 $M(P_{\\max})$、$\\phi(M(P_{\\max}))$、$T_{\\mathrm{comp}}(P_{\\max})$ 和 $T_{\\mathrm{comm}}(P_{\\max})$，以得到最终的 $T(P_{\\max})$。\n    c.  计算效率 $E(P_{\\max}) = T(1)/T(P_{\\max})$。\n\n3.  对裁剪后的情况重复计算：使用修改后的非零元数量模型重复整个计算过程：\n    $$\n    z^{\\mathrm{prune}}_l(P) = \\rho \\, z_{l,0} \\left(1 + \\rho \\, c_l \\, P^{\\gamma_l}\\right)\n    $$\n    所有派生量（$M^{\\mathrm{prune}}(P)$、$T^{\\mathrm{prune}}(P)$ 等）都使用此公式重新评估，以找到 $E^{\\mathrm{prune}}(P_{\\max})$。注意，对 $P^\\star$ 的搜索仅在未裁剪的情况下进行。\n\n对每个测试用例实施这个完整的、分步的过程，以获得所需的结果。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all given test cases.\n    \"\"\"\n    # Define test cases as per the problem statement.\n    test_cases = [\n        # Case A (happy path)\n        {\n            'n_local': 5e5, 'b_nz': 12, 'v_mult': 6,\n            'z_l0': np.array([20, 15, 12, 400]),\n            'c_l': np.array([0.02, 0.03, 0.05, 0.10]),\n            'gamma_l': np.array([0.25, 0.25, 0.25, 0.5]),\n            'M_thr': 8, 't0': 1.0, 'a': 0.03, 'kappa': 0.5,\n            'P_max': 4096, 'rho': 0.5\n        },\n        # Case B (boundary, no density growth)\n        {\n            'n_local': 5e5, 'b_nz': 12, 'v_mult': 6,\n            'z_l0': np.array([20, 15, 12, 200]),\n            'c_l': np.array([0, 0, 0, 0]),\n            'gamma_l': np.array([0, 0, 0, 0]),\n            'M_thr': 8, 't0': 1.0, 'a': 0.03, 'kappa': 0.5,\n            'P_max': 4096, 'rho': 0.5\n        },\n        # Case C (edge, aggressive growth on coarse level)\n        {\n            'n_local': 5e5, 'b_nz': 12, 'v_mult': 6,\n            'z_l0': np.array([25, 18, 600]),\n            'c_l': np.array([0.05, 0.08, 0.20]),\n            'gamma_l': np.array([0.3, 0.3, 0.6]),\n            'M_thr': 12, 't0': 1.4, 'a': 0.04, 'kappa': 0.6,\n            'P_max': 1024, 'rho': 0.4\n        }\n    ]\n\n    all_results = [process_case(case) for case in test_cases]\n\n    # Format the output as specified\n    result_strings = [f\"[{r[0]},{r[1]:.6f},{r[2]:.6f}]\" for r in all_results]\n    print(f\"[[{','.join(result_strings)}]]\")\n\ndef get_sum_z(P, z_l0, c_l, gamma_l, rho, pruned):\n    \"\"\"Calculates the sum of non-zeros per row over all levels.\"\"\"\n    if P == 0: return 0\n    if not pruned:\n        return np.sum(z_l0 * (1 + c_l * (P ** gamma_l)))\n    else:\n        return np.sum(rho * z_l0 * (1 + rho * c_l * (P ** gamma_l)))\n\ndef calculate_time(P, params, pruned):\n    \"\"\"Calculates the total time per V-cycle for a given P.\"\"\"\n    # Unpack parameters\n    t0, a, kappa, M_thr = params['t0'], params['a'], params['kappa'], params['M_thr']\n    n_local, b_nz, v_mult = params['n_local'], params['b_nz'], params['v_mult']\n    z_l0, c_l, gamma_l, rho = params['z_l0'], params['c_l'], params['gamma_l'], params['rho']\n    \n    # Operator complexity (sum of non-zeros)\n    sum_z_P = get_sum_z(P, z_l0, c_l, gamma_l, rho, pruned)\n    sum_z_1 = get_sum_z(1, z_l0, c_l, gamma_l, rho, pruned)\n    \n    # Memory footprint\n    M = (n_local * b_nz * sum_z_P + n_local * v_mult * 8) / (1024**3)\n    \n    # Memory penalty factor\n    phi = 1.0\n    if M > M_thr:\n        phi = 1.0 + kappa * (M - M_thr) / M_thr\n        \n    # Compute time\n    T_comp = t0 * (sum_z_P / sum_z_1)\n    \n    # Communication time\n    T_comm = 0.0\n    if P > 1:\n        T_comm = a * np.log2(P)\n        \n    # Total time\n    return phi * T_comp + T_comm\n\ndef process_case(case_params):\n    \"\"\"\n    Processes a single test case to find P_star, E(P_max), and E_pruned(P_max).\n    \"\"\"\n    P_max = int(case_params['P_max'])\n    \n    # Task 1: Find P_star (only for the unpruned case)\n    P_star = -1\n    for P_val in range(1, P_max + 1):\n        sum_z = get_sum_z(P_val, case_params['z_l0'], case_params['c_l'], case_params['gamma_l'], case_params['rho'], pruned=False)\n        M = (case_params['n_local'] * case_params['b_nz'] * sum_z + \n             case_params['n_local'] * case_params['v_mult'] * 8) / (1024**3)\n        if M > case_params['M_thr']:\n            P_star = P_val\n            break\n            \n    # Task 2: Calculate weak-scaling efficiencies at P_max\n    \n    # Unpruned efficiency\n    T1_unpruned = calculate_time(1, case_params, pruned=False)\n    Tpmax_unpruned = calculate_time(P_max, case_params, pruned=False)\n    E_pmax = T1_unpruned / Tpmax_unpruned\n    \n    # Pruned efficiency\n    T1_pruned = calculate_time(1, case_params, pruned=True)\n    Tpmax_pruned = calculate_time(P_max, case_params, pruned=True)\n    E_prune_pmax = T1_pruned / Tpmax_pruned\n    \n    return [P_star, E_pmax, E_prune_pmax]\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "3449823"}]}