{"hands_on_practices": [{"introduction": "理论的价值在于实践。第一个练习旨在将最速下降法的抽象概念与一个具体的计算问题联系起来。通过将一个简单的偏微分方程离散化，并手动执行一步迭代，你将亲身体验如何确定搜索方向和计算最优步长，从而将能量泛函最小化的思想转化为可操作的步骤。[@problem_id:3421077]", "problem": "考虑一维二阶椭圆边值问题 $-u''(x)=f(x)$，定义在区间 $[0,1]$ 上，其齐次狄利克雷边界条件为 $u(0)=u(1)=0$。用一个均匀网格离散化该定义域，该网格在 $x_{1}=\\frac{1}{3}$ 和 $x_{2}=\\frac{2}{3}$ 处有两个内部点，因此网格间距为 $h=\\frac{1}{3}$。对二阶导数使用标准的二阶中心有限差分近似，即\n$$\n-\\frac{u_{i-1}-2u_{i}+u_{i+1}}{h^{2}}=f(x_{i}),\n$$\n其中边界值取为 $u_{0}=u_{3}=0$。这将得到一个线性系统 $Ax=b$，其中 $A$ 是一个 $2\\times 2$ 的对称正定(SPD)矩阵，$b$ 是一个二维向量。设源项为 $f(x)=\\sin(\\pi x)$，并为该离散化构建相应的 $A$ 和 $b$。\n\n定义与该线性系统相关的二次泛函\n$$\nJ(x)=\\frac{1}{2} x^{\\top} A x - b^{\\top} x,\n$$\n从初始猜测 $x_{0}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$ 开始，执行一次最速下降法迭代：选择搜索方向为 $J$ 在 $x_{0}$ 处的负梯度，并通过在该方向上最小化 $J$ 来选择步长。计算步长 $\\alpha_{0}$、更新后的迭代值 $x_{1}$ 和泛函值 $J(x_{1})$。所有量均需精确表示，无需四舍五入。将你的最终答案以一个单行矩阵的形式给出，其中依次包含 $\\alpha_{0}$、$x_{1}$ 的两个分量和 $J(x_{1})$。", "solution": "用户需要解决一个涉及最速下降法的数值分析问题。\n\n### 步骤 1：提取已知条件\n-   **问题**：一维二阶椭圆边值问题 $-u''(x)=f(x)$，定义在区间 $[0,1]$ 上。\n-   **边界条件**：齐次狄利克雷，$u(0)=u(1)=0$。\n-   **离散化**：均匀网格，有两个内部点 $x_{1}=\\frac{1}{3}$ 和 $x_{2}=\\frac{2}{3}$。\n-   **网格间距**：$h=\\frac{1}{3}$。\n-   **有限差分近似**：$-\\frac{u_{i-1}-2u_{i}+u_{i+1}}{h^{2}}=f(x_{i})$。\n-   **离散化的边界值**：$u_{0}=0$，$u_{3}=0$。\n-   **线性系统**：离散化得到 $Ax=b$，其中 $A$ 是一个 $2\\times 2$ 的对称正定(SPD)矩阵，$x = \\begin{pmatrix} u_1 \\\\ u_2 \\end{pmatrix}$，$b$ 是一个二维向量。\n-   **源项**：$f(x)=\\sin(\\pi x)$。\n-   **二次泛函**：$J(x)=\\frac{1}{2} x^{\\top} A x - b^{\\top} x$。\n-   **初始猜测**：$x_{0}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$。\n-   **任务**：执行一次最速下降法迭代。搜索方向是 $J$ 在 $x_0$ 处的负梯度，步长通过最小化该方向上的 $J$ 来选择。\n-   **要求输出**：步长 $\\alpha_{0}$、更新后的迭代值 $x_{1}$ 和泛函值 $J(x_{1})$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在科学上和数学上是合理的。它描述了有限差分法在一个简单边值问题（一维泊松方程）上的标准应用，然后要求应用经典的迭代法——最速下降法来求解得到的线性系统。所有组成部分（微分方程、离散格式、二次泛函的定义以及最速下降算法）都是数值分析和科学计算中的基本概念。\n\n该问题是适定的。所有构建线性系统 $Ax=b$ 和执行一次指定算法所需的必要数据和定义都已提供。由负二阶导数算子在狄利克雷边界条件下的标准中心差分离散化所得到的矩阵 $A$ 已知是对称正定的，这保证了二次泛函 $J(x)$ 有唯一的最小值，并且最速下降法是良定义的。问题陈述客观，没有歧义。\n\n### 步骤 3：结论与行动\n问题有效。我将继续进行完整解答。\n\n### 解答\n首先，我们构建线性系统 $Ax=b$。计算网格点为 $x_{0}=0$、$x_{1}=\\frac{1}{3}$、$x_{2}=\\frac{2}{3}$ 和 $x_{3}=1$。未知向量为 $x = \\begin{pmatrix} u_1 \\\\ u_2 \\end{pmatrix}$，其中 $u_i \\approx u(x_i)$。网格间距为 $h=\\frac{1}{3}$，所以 $h^2 = \\frac{1}{9}$。\n\n我们在每个内部点应用给定的有限差分公式。\n对于 $i=1$：\n$$-\\frac{u_{0}-2u_{1}+u_{2}}{h^{2}}=f(x_{1})$$\n使用边界条件 $u_{0}=0$ 和 $h^2=\\frac{1}{9}$：\n$$-\\frac{-2u_{1}+u_{2}}{1/9}=f(x_{1}) \\implies 9(2u_{1}-u_{2}) = f(x_{1})$$\n这可以简化为 $18u_1 - 9u_2 = f(x_1)$。\n\n对于 $i=2$：\n$$-\\frac{u_{1}-2u_{2}+u_{3}}{h^{2}}=f(x_{2})$$\n使用边界条件 $u_{3}=0$：\n$$-\\frac{u_{1}-2u_{2}}{1/9}=f(x_{2}) \\implies 9(-u_{1}+2u_{2}) = f(x_2)$$\n这可以简化为 $-9u_1 + 18u_2 = f(x_2)$。\n\n从这两个方程中，我们可以确定矩阵 $A$：\n$$A = \\begin{pmatrix} 18  -9 \\\\ -9  18 \\end{pmatrix}$$\n\n接下来，我们使用源项 $f(x)=\\sin(\\pi x)$ 构建向量 $b$：\n$$b = \\begin{pmatrix} f(x_1) \\\\ f(x_2) \\end{pmatrix} = \\begin{pmatrix} f(1/3) \\\\ f(2/3) \\end{pmatrix} = \\begin{pmatrix} \\sin(\\pi/3) \\\\ \\sin(2\\pi/3) \\end{pmatrix} = \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2} \\end{pmatrix}$$\n\n现在我们执行一次最速下降法迭代。我们从初始猜测 $x_{0}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$ 开始。\n在第 $k$ 步的搜索方向 $p_k$ 是 $J(x)$ 在 $x_k$ 处的负梯度。梯度为 $\\nabla J(x) = Ax - b$。\n因此，搜索方向为 $p_k = - \\nabla J(x_k) = b - Ax_k$。这个向量也称为残差，记为 $r_k$。\n对于第一次迭代（$k=0$），搜索方向为：\n$$p_0 = b - Ax_{0} = \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2} \\end{pmatrix} - \\begin{pmatrix} 18  -9 \\\\ -9  18 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2} \\end{pmatrix}$$\n所以，$p_0 = b$。对于最速下降法，我们让搜索方向等于残差，因此有 $p_0 = r_0 = b$。\n\n步长 $\\alpha_0$ 的选择是为了最小化 $J(x_{0}+\\alpha p_{0})$。对于残差 $r_k$，最优步长的著名公式是：\n$$\\alpha_k = \\frac{r_k^{\\top} r_k}{r_k^{\\top} A r_k}$$\n对于我们的第一次迭代，由于 $r_0=p_0=b$：\n$$\\alpha_0 = \\frac{b^{\\top} b}{b^{\\top} A b}$$\n我们计算所需的向量积：\n$$b^{\\top}b = \\begin{pmatrix} \\frac{\\sqrt{3}}{2}  \\frac{\\sqrt{3}}{2} \\end{pmatrix} \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2} \\end{pmatrix} = \\left(\\frac{\\sqrt{3}}{2}\\right)^{2} + \\left(\\frac{\\sqrt{3}}{2}\\right)^{2} = \\frac{3}{4} + \\frac{3}{4} = \\frac{6}{4} = \\frac{3}{2}$$\n接下来，我们计算 $Ab$：\n$$Ab = \\begin{pmatrix} 18  -9 \\\\ -9  18 \\end{pmatrix} \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2} \\end{pmatrix} = \\begin{pmatrix} 18(\\frac{\\sqrt{3}}{2}) - 9(\\frac{\\sqrt{3}}{2}) \\\\ -9(\\frac{\\sqrt{3}}{2}) + 18(\\frac{\\sqrt{3}}{2}) \\end{pmatrix} = \\begin{pmatrix} 9\\frac{\\sqrt{3}}{2} \\\\ 9\\frac{\\sqrt{3}}{2} \\end{pmatrix} = 9 \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2} \\end{pmatrix} = 9b$$\n然后，我们计算 $b^{\\top}Ab$：\n$$b^{\\top}Ab = b^{\\top}(9b) = 9(b^{\\top}b) = 9 \\left(\\frac{3}{2}\\right) = \\frac{27}{2}$$\n现在我们可以求出 $\\alpha_{0}$：\n$$\\alpha_0 = \\frac{3/2}{27/2} = \\frac{3}{27} = \\frac{1}{9}$$\n\n更新后的迭代值 $x_{1}$ 由下式给出：\n$$x_{1} = x_{0} + \\alpha_0 p_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\frac{1}{9} \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{\\sqrt{3}}{18} \\\\ \\frac{\\sqrt{3}}{18} \\end{pmatrix}$$\n\n最后，我们计算泛函值 $J(x_1)$：\n$$J(x_1) = \\frac{1}{2} x_1^{\\top} A x_1 - b^{\\top} x_1$$\n我们首先计算 $Ax_1$ 和 $b^{\\top}x_1$ 这两项：\n$$A x_1 = \\begin{pmatrix} 18  -9 \\\\ -9  18 \\end{pmatrix} \\begin{pmatrix} \\frac{\\sqrt{3}}{18} \\\\ \\frac{\\sqrt{3}}{18} \\end{pmatrix} = \\frac{\\sqrt{3}}{18} \\begin{pmatrix} 18 - 9 \\\\ -9 + 18 \\end{pmatrix} = \\frac{\\sqrt{3}}{18} \\begin{pmatrix} 9 \\\\ 9 \\end{pmatrix} = \\begin{pmatrix} \\frac{9\\sqrt{3}}{18} \\\\ \\frac{9\\sqrt{3}}{18} \\end{pmatrix} = \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{\\sqrt{3}}{2} \\end{pmatrix} = b$$\n由于 $Ax_1 = b$，这意味着 $x_1$ 是该线性系统的精确解。这是一个特殊情况，发生的原因是初始残差 $r_0=b$ 是矩阵 $A$ 的一个特征向量。\n现在我们计算 $b^{\\top}x_1$:\n$$b^{\\top}x_1 = \\begin{pmatrix} \\frac{\\sqrt{3}}{2}  \\frac{\\sqrt{3}}{2} \\end{pmatrix} \\begin{pmatrix} \\frac{\\sqrt{3}}{18} \\\\ \\frac{\\sqrt{3}}{18} \\end{pmatrix} = \\left(\\frac{\\sqrt{3}}{2}\\right)\\left(\\frac{\\sqrt{3}}{18}\\right) + \\left(\\frac{\\sqrt{3}}{2}\\right)\\left(\\frac{\\sqrt{3}}{18}\\right) = 2 \\left(\\frac{3}{36}\\right) = \\frac{6}{36} = \\frac{1}{6}$$\n我们现在可以计算 $J(x_1)$。由于 $Ax_1 = b$，我们可以写出 $x_1^\\top A x_1 = x_1^\\top b$。但由于 $A$ 是对称的，所以 $x_1^\\top A x_1 = (Ax_1)^\\top x_1 = b^\\top x_1$。\n$$J(x_1) = \\frac{1}{2} x_1^{\\top} (A x_1) - b^{\\top} x_1 = \\frac{1}{2} x_1^{\\top} b - b^{\\top} x_1 = \\frac{1}{2} b^{\\top} x_1 - b^{\\top} x_1 = -\\frac{1}{2} b^{\\top} x_1$$\n代入 $b^{\\top}x_1$ 的值：\n$$J(x_1) = -\\frac{1}{2} \\left(\\frac{1}{6}\\right) = -\\frac{1}{12}$$\n\n所需的量是：\n- 步长：$\\alpha_0 = \\frac{1}{9}$\n- 更新后的迭代值：$x_1 = \\begin{pmatrix} \\frac{\\sqrt{3}}{18} \\\\ \\frac{\\sqrt{3}}{18} \\end{pmatrix}$\n- 泛函值：$J(x_1) = -\\frac{1}{12}$\n\n最终答案以行矩阵的形式呈现。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{9}  \\frac{\\sqrt{3}}{18}  \\frac{\\sqrt{3}}{18}  -\\frac{1}{12}\n\\end{pmatrix}\n}\n$$", "id": "3421077"}, {"introduction": "对于任何迭代方法而言，知道何时停止与知道如何前进同样重要。这个练习将引导你推导一个关键的理论关系，它将我们真正关心的“能量误差”（即当前解与真实解在能量上的差距）与一个在计算中易于获取的量——残差的范数——联系起来。掌握这一关系，你将能够设计出既高效又可靠的收敛判断准则。[@problem_id:3421083]", "problem": "考虑一个定义在有界域上的带有齐次狄利克雷边界条件的线性二阶椭圆偏微分方程（PDE），通过协调有限元法离散化，得到一个线性系统，其具有对称正定（SPD）的刚度矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 和一个载荷向量 $b \\in \\mathbb{R}^{n}$。定义二次能量泛函 $J(x)$ 为 $J(x) = \\frac{1}{2} x^{\\top} A x - b^{\\top} x$，其唯一极小化子 $x^{\\ast}$ 满足 $A x^{\\ast} = b$。设应用最速下降法来最小化 $J(x)$，得到迭代点 $x_{k}$，其残差为 $r_{k} = b - A x_{k}$。假设有一个已知的谱下界 $m > 0$，使得 $A \\succeq m I$，其中 $I$ 是单位矩阵。\n\n从变分刻画 $x^{\\ast} = \\arg\\min_{x \\in \\mathbb{R}^{n}} J(x)$ 和残差 $r_{k}$ 的定义出发，推导一个精确的恒等式，将能量误差 $J(x_{k}) - J(x^{\\ast})$ 与残差范数 $\\| r_{k} \\|_{A^{-1}}$ 联系起来，其中 $\\| r \\|_{A^{-1}}^{2} := r^{\\top} A^{-1} r$。然后，为最速下降法迭代提出一个停止准则，保证能量误差满足给定的容差 $\\delta > 0$，即 $J(x_{k}) - J(x^{\\ast}) \\leq \\delta$。最后，假设只有谱下界 $m$ 可用，并且可计算的量是欧几里得范数 $\\| r_{k} \\|$，确定 $\\| r_{k} \\|$ 的一个关于 $m$ 和 $\\delta$ 的最小显式上界，以确保 $J(x_{k}) - J(x^{\\ast}) \\leq \\delta$。请将最终答案表示为单一的闭式解析表达式。无需四舍五入。", "solution": "所述问题是有效的。它在科学上基于求解偏微分方程的数值线性代数和有限元方法的成熟理论。其前提在数学上是合理的、一致的，并且为推导提供了所有必要的信息。术语精确且客观。没有可识别的缺陷。\n\n该问题要求三个不同的结果：\n1. 一个将能量误差 $J(x_{k}) - J(x^{\\ast})$ 与残差范数 $\\| r_{k} \\|_{A^{-1}}$ 联系起来的精确恒等式。\n2. 一个基于此恒等式的最速下降法迭代的停止准则。\n3. 一个关于残差的欧几里得范数 $\\| r_{k} \\|$ 的可计算上界，该上界保证能量误差在容差 $\\delta$ 之内。\n\n我们将依次处理每个问题。\n\n首先，我们推导能量误差的恒等式。能量泛函由 $J(x) = \\frac{1}{2} x^{\\top} A x - b^{\\top} x$ 给出。唯一极小化子 $x^{\\ast}$ 满足正规方程 $\\nabla J(x^{\\ast}) = A x^{\\ast} - b = 0$，这意味着 $A x^{\\ast} = b$。在第 $k$ 次迭代点 $x_k$ 处的能量误差是差值 $J(x_k) - J(x^{\\ast})$。\n\n让我们展开这个表达式：\n$$ J(x_{k}) - J(x^{\\ast}) = \\left(\\frac{1}{2} x_{k}^{\\top} A x_{k} - b^{\\top} x_{k}\\right) - \\left(\\frac{1}{2} (x^{\\ast})^{\\top} A x^{\\ast} - b^{\\top} x^{\\ast}\\right) $$\n将 $b = A x^{\\ast}$ 代入表达式：\n$$ J(x_{k}) - J(x^{\\ast}) = \\frac{1}{2} x_{k}^{\\top} A x_{k} - (A x^{\\ast})^{\\top} x_{k} - \\frac{1}{2} (x^{\\ast})^{\\top} A x^{\\ast} + (A x^{\\ast})^{\\top} x^{\\ast} $$\n由于矩阵 $A$ 是对称的，所以 $(A x^{\\ast})^{\\top} = (x^{\\ast})^{\\top} A^{\\top} = (x^{\\ast})^{\\top} A$。\n$$ J(x_{k}) - J(x^{\\ast}) = \\frac{1}{2} x_{k}^{\\top} A x_{k} - (x^{\\ast})^{\\top} A x_{k} - \\frac{1}{2} (x^{\\ast})^{\\top} A x^{\\ast} + (x^{\\ast})^{\\top} A x^{\\ast} $$\n$$ J(x_{k}) - J(x^{\\ast}) = \\frac{1}{2} x_{k}^{\\top} A x_{k} - (x^{\\ast})^{\\top} A x_{k} + \\frac{1}{2} (x^{\\ast})^{\\top} A x^{\\ast} $$\n这个表达式是一个可以因式分解的二次型：\n$$ J(x_{k}) - J(x^{\\ast}) = \\frac{1}{2} (x_{k} - x^{\\ast})^{\\top} A (x_{k} - x^{\\ast}) $$\n设误差向量为 $e_{k} = x_{k} - x^{\\ast}$。因此，能量误差为 $\\frac{1}{2} e_{k}^{\\top} A e_{k}$，即误差的 $A$-范数平方的一半，$\\frac{1}{2} \\| e_{k} \\|_{A}^{2}$。\n\n接下来，我们将误差 $e_k$ 与残差 $r_k = b - A x_k$ 联系起来。\n$$ r_{k} = b - A x_{k} = A x^{\\ast} - A x_{k} = A(x^{\\ast} - x_{k}) = -A(x_{k} - x^{\\ast}) = -A e_{k} $$\n由于 $A$ 是对称正定（SPD）的，它是可逆的。因此，我们可以将误差表示为 $e_{k} = -A^{-1} r_{k}$。\n\n将 $e_k$ 的这个表达式代入能量误差的方程中：\n$$ J(x_{k}) - J(x^{\\ast}) = \\frac{1}{2} (-A^{-1} r_{k})^{\\top} A (-A^{-1} r_{k}) $$\n$$ J(x_{k}) - J(x^{\\ast}) = \\frac{1}{2} (r_{k}^{\\top} (A^{-1})^{\\top}) A (A^{-1} r_{k}) $$\n由于 $A$ 是对称的，其逆矩阵 $A^{-1}$ 也是对称的，所以 $(A^{-1})^{\\top} = A^{-1}$。\n$$ J(x_{k}) - J(x^{\\ast}) = \\frac{1}{2} r_{k}^{\\top} A^{-1} A A^{-1} r_{k} = \\frac{1}{2} r_{k}^{\\top} (A^{-1} A) A^{-1} r_{k} = \\frac{1}{2} r_{k}^{\\top} I A^{-1} r_{k} $$\n$$ J(x_{k}) - J(x^{\\ast}) = \\frac{1}{2} r_{k}^{\\top} A^{-1} r_{k} $$\n使用问题中提供的记号 $\\| r \\|_{A^{-1}}^{2} := r^{\\top} A^{-1} r$，我们得到所求的恒等式：\n$$ J(x_{k}) - J(x^{\\ast}) = \\frac{1}{2} \\| r_{k} \\|_{A^{-1}}^{2} $$\n\n其次，我们提出一个停止准则。目标是在 $J(x_{k}) - J(x^{\\ast}) \\leq \\delta$ 时终止迭代，其中 $\\delta > 0$ 是给定的容差。使用刚才推导的恒等式，这个条件等价于：\n$$ \\frac{1}{2} \\| r_{k} \\|_{A^{-1}}^{2} \\leq \\delta \\quad \\iff \\quad \\| r_{k} \\|_{A^{-1}}^{2} \\leq 2\\delta $$\n因此，一个停止准则是在第 $k$ 步，如果 $\\| r_{k} \\|_{A^{-1}}^{2} \\leq 2\\delta$ 则终止迭代。需要注意的是，计算 $\\| r_{k} \\|_{A^{-1}}^{2} = r_{k}^{\\top} A^{-1} r_{k}$ 需要将 $A$ 的逆矩阵应用于一个向量，这在计算上与求解原始线性系统一样昂贵。因此，这个准则并不实用，这也引出了问题的最后一部分。\n\n第三，我们基于可计算的欧几里得范数 $\\|r_k\\|$ 和给定的谱下界 $m > 0$ 推导一个实用的停止准则。条件 $A \\succeq mI$ 意味着对于任何非零向量 $v \\in \\mathbb{R}^n$，我们有 $v^{\\top} A v \\geq m \\|v\\|^2$。这意味着 $A$ 的最小特征值 $\\lambda_{\\min}(A)$ 满足 $\\lambda_{\\min}(A) \\geq m$。\n\n逆矩阵 $A^{-1}$ 的特征值是 $A$ 的特征值的倒数。因此，$A^{-1}$ 的最大特征值 $\\lambda_{\\max}(A^{-1})$ 的界如下：\n$$ \\lambda_{\\max}(A^{-1}) = \\frac{1}{\\lambda_{\\min}(A)} \\leq \\frac{1}{m} $$\n量 $r_{k}^{\\top} A^{-1} r_{k}$ 可以使用矩阵 $A^{-1}$ 的瑞利商来获得上界：\n$$ \\frac{r_{k}^{\\top} A^{-1} r_{k}}{r_{k}^{\\top} r_{k}} \\leq \\lambda_{\\max}(A^{-1}) \\implies r_{k}^{\\top} A^{-1} r_{k} \\leq \\lambda_{\\max}(A^{-1}) \\|r_{k}\\|^{2} $$\n结合这些不等式，我们得到了 $r_{k}^{\\top} A^{-1} r_{k}$ 关于欧几里得范数 $\\|r_k\\|$ 的一个界：\n$$ r_{k}^{\\top} A^{-1} r_{k} \\leq \\frac{1}{m} \\|r_{k}\\|^{2} $$\n现在，我们将这个不等式代入能量误差的表达式中：\n$$ J(x_{k}) - J(x^{\\ast}) = \\frac{1}{2} r_{k}^{\\top} A^{-1} r_{k} \\leq \\frac{1}{2m} \\|r_{k}\\|^{2} $$\n为保证能量误差不超过容差 $\\delta$，即 $J(x_{k}) - J(x^{\\ast}) \\leq \\delta$，我们只需强制执行更严格的条件：\n$$ \\frac{\\|r_{k}\\|^{2}}{2m} \\leq \\delta $$\n对 $\\|r_{k}\\|$ 求解，我们得到：\n$$ \\|r_{k}\\|^{2} \\leq 2m\\delta \\implies \\|r_{k}\\| \\leq \\sqrt{2m\\delta} $$\n这个不等式提供了一个基于残差的欧几里得范数的停止准则，该范数在迭代法的每一步都很容易计算。阈值 $\\sqrt{2m\\delta}$ 表示 $\\|r_k\\|$ 的一个上界，如果满足该上界，就能保证能量误差容差得以满足。在只给定谱下界 $m$ 的情况下，这个界是可能的最紧界，因为如果 $A=mI$，等式可以成立。因此，确保条件满足的 $\\|r_k\\|$ 的最小显式上界是 $\\sqrt{2m\\delta}$。", "answer": "$$\\boxed{\\sqrt{2m\\delta}}$$", "id": "3421083"}, {"introduction": "最速下降法的基础版本在某些情况下收敛缓慢，预处理是提升其性能的关键技术。然而，选择一个好的预处理器并非易事。本练习通过一个精心设计的反例，揭示了当预处理器破坏了原问题的对称性时，可能会导致算法性能下降。这个练习将加深你对预处理本质的理解，即它如何通过改变问题的几何结构来影响收敛性，并强调保持对称性在设计高效迭代法中的核心作用。[@problem_id:3421050]", "problem": "考虑一个一致椭圆自伴二阶偏微分方程（PDE）的有限元离散化，该离散化产生一个对称正定（SPD）的刚度矩阵 $A \\in \\mathbb{R}^{n \\times n}$。变分形式导出二次泛函 $\\phi(x) = \\frac{1}{2} x^{\\top} A x - b^{\\top} x$，其极小值点 $x^{\\ast}$ 求解 $A x^{\\ast} = b$。经典的最速下降法，采用精确线搜索，沿着下降方向 $p_{k}$ 更新 $x_{k+1} = x_{k} + \\alpha_{k} p_{k}$，步长 $\\alpha_{k}$ 使 $\\phi(x_{k} + \\alpha p_{k})$ 在 $\\alpha \\in \\mathbb{R}$ 上最小化。当选择由矩阵 $M$ 导出的内积，即 $(u,v)_{M} = u^{\\top} M v$ 时，最速下降方向是相对于此内积的负梯度，即 $p_{k} = -M^{-1} r_{k}$，其中残差为 $r_{k} = A x_{k} - b$。在实践中，通常将 $M$ 作为近似 $A$ 的预条件子。\n\n提供一个具体的反例，说明对一个非对称 $M$ 的朴素选择会破坏 $A$ 在所选 $(\\cdot,\\cdot)_{M}$-内积中的对称性，并恶化最速下降法的收敛性。使用以下数据：\n- $A = \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix}$，\n- 精确解 $x^{\\ast} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，因此 $b = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，\n- 初始迭代点 $x_{0} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$，\n- 朴素预条件子 $M = \\begin{pmatrix} 1  5 \\\\ 0  1 \\end{pmatrix}$。\n\n执行一步“预条件最速下降”更新 $x_{1} = x_{0} + \\alpha_{0} p_{0}$ 的精确线搜索步骤，其中 $p_{0} = -M^{-1} r_{0}$ 且 $r_{0} = A x_{0} - b$。计算误差在$A$-能量范数下的精确缩减因子，即比率\n$$\\frac{\\|x_{1} - x^{\\ast}\\|_{A}^{2}}{\\|x_{0} - x^{\\ast}\\|_{A}^{2}},$$\n其中 $\\|z\\|_{A}^{2} = z^{\\top} A z$。将您的最终结果表示为一个简化的有理数。\n\n最后，推导关于 $M$ 的一般条件，在这些条件下，方向 $p_{k} = -M^{-1} r_{k}$ 是所选内积中的真正最速下降方向，并且算子 $M^{-1} A$ 关于 $(\\cdot,\\cdot)_{M}$ 是自伴的，从而确保有效的下降和标准的收敛性保证。不要使用任何快捷公式；从内积梯度的定义和沿给定方向对 $\\phi$ 进行精确线搜索最小化开始。缩减因子无需四舍五入；将其精确表示为一个有理数。", "solution": "问题已经过验证。\n\n### 第1步：提取已知条件\n-   该系统源于一个一致椭圆自伴二阶偏微分方程的有限元离散化。\n-   刚度矩阵为 $A = \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix}$，它是对称正定的（SPD）。\n-   需要最小化的二次泛函是 $\\phi(x) = \\frac{1}{2} x^{\\top} A x - b^{\\top} x$。\n-   极小值点 $x^{\\ast}$ 求解 $A x^{\\ast} = b$。\n-   精确解为 $x^{\\ast} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。\n-   右端向量为 $b = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。\n-   初始迭代点为 $x_{0} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n-   该方法是“预条件最速下降法”，更新公式为 $x_{k+1} = x_{k} + \\alpha_{k} p_{k}$。\n-   步长 $\\alpha_{k}$ 通过精确线搜索确定，最小化 $\\phi(x_{k} + \\alpha p_{k})$。\n-   内积定义为 $(u,v)_{M} = u^{\\top} M v$。\n-   搜索方向由 $p_{k} = -M^{-1} r_{k}$ 给出，其中 $r_{k} = A x_{k} - b$。\n-   预条件子矩阵为 $M = \\begin{pmatrix} 1  5 \\\\ 0  1 \\end{pmatrix}$。\n-   需要计算的量是缩减因子 $\\frac{\\|x_{1} - x^{\\ast}\\|_{A}^{2}}{\\|x_{0} - x^{\\ast}\\|_{A}^{2}}$，其中 $\\|z\\|_{A}^{2} = z^{\\top} A z$。\n-   还需要推导关于 $M$ 的一般条件。\n\n### 第2步：使用提取的已知条件进行验证\n1.  **科学基础扎实**：问题设置在数值线性代数和优化的背景下，特别是求解源自偏微分方程的线性系统。所有概念，如SPD矩阵、二次泛函、最速下降法、预条件子和能量范数，都是该领域的标准和成熟概念。\n2.  **适定性**：问题要求基于一套完整的初始数据进行特定计算，并推导一个标准的理论结果。计算会得出一个唯一的数值。推导是迭代方法分析中的一个标准练习。\n3.  **客观性**：问题陈述精确，使用标准的数学术语，没有任何主观或模棱两可的语言。\n4.  **完整性与一致性**：所有必需的矩阵（$A$, $M$）、向量（$x_0$, $x^*$, $b$）和定义都已提供。这些值是一致的；例如，$x^*=0$ 意味着 $b=Ax^*=0$，这已正确给出。矩阵 $A$ 确实是SPD，因为其特征值为 $4$ 和 $1$。\n5.  **无其他缺陷**：问题既不简单也不病态。选择非对称的 $M$ 是一个有效的教学选择，用以说明预条件子属性的重要性。\n\n### 第3步：结论与行动\n问题有效。将提供完整解答。\n\n### 解答推导\n\n解答包含两部分。首先，我们对所述方法进行一步数值计算。其次，我们推导矩阵 $M$ 的一般条件。\n\n**第1部分：计算缩减因子**\n\n1.  **初始状态**：\n    初始误差为 $e_{0} = x_{0} - x^{\\ast} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n    初始残差为 $r_{0} = A x_{0} - b = \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 1 \\end{pmatrix}$。\n\n2.  **初始误差的A-范数**：\n    初始误差在$A$-能量范数下的平方为：\n    $$ \\|x_{0} - x^{\\ast}\\|_{A}^{2} = e_{0}^{\\top} A e_{0} = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ 1 \\end{pmatrix} = 4 + 1 = 5 $$\n\n3.  **搜索方向**：\n    搜索方向为 $p_{0} = -M^{-1} r_{0}$。首先，我们计算 $M = \\begin{pmatrix} 1  5 \\\\ 0  1 \\end{pmatrix}$ 的逆。行列式为 $\\det(M) = 1 \\cdot 1 - 5 \\cdot 0 = 1$。\n    $$ M^{-1} = \\frac{1}{1} \\begin{pmatrix} 1  -5 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 1  -5 \\\\ 0  1 \\end{pmatrix} $$\n    现在，我们计算 $p_{0}$：\n    $$ p_{0} = - \\begin{pmatrix} 1  -5 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ 1 \\end{pmatrix} = - \\begin{pmatrix} 1 \\cdot 4 - 5 \\cdot 1 \\\\ 0 \\cdot 4 + 1 \\cdot 1 \\end{pmatrix} = - \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} $$\n\n4.  **精确线搜索步长 $\\alpha_{0}$**：\n    我们需要找到最小化 $g(\\alpha) = \\phi(x_{0} + \\alpha p_{0})$ 的 $\\alpha_{0}$。\n    $$ g(\\alpha) = \\frac{1}{2} (x_{0} + \\alpha p_{0})^{\\top} A (x_{0} + \\alpha p_{0}) - b^{\\top} (x_{0} + \\alpha p_{0}) $$\n    由于 $A$ 是对称的且 $b=0$，这简化为：\n    $$ g(\\alpha) = \\frac{1}{2} (x_{0}^{\\top} A x_{0} + 2\\alpha p_{0}^{\\top} A x_{0} + \\alpha^{2} p_{0}^{\\top} A p_{0}) $$\n    为了找到最小值，我们将关于 $\\alpha$ 的导数设为零：\n    $$ g'(\\alpha) = p_{0}^{\\top} A x_{0} + \\alpha p_{0}^{\\top} A p_{0} = 0 $$\n    解出 $\\alpha$ 得到最优步长 $\\alpha_{0}$：\n    $$ \\alpha_{0} = - \\frac{p_{0}^{\\top} A x_{0}}{p_{0}^{\\top} A p_{0}} $$\n    使用 $r_{0} = A x_{0} - b = A x_{0}$，我们可以将分子写成 $p_{0}^{\\top} r_{0}$：\n    $$ \\alpha_{0} = - \\frac{p_{0}^{\\top} r_{0}}{p_{0}^{\\top} A p_{0}} $$\n    我们来计算各项：\n    $$ p_{0}^{\\top} r_{0} = \\begin{pmatrix} 1  -1 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ 1 \\end{pmatrix} = 4 - 1 = 3 $$\n    $$ p_{0}^{\\top} A p_{0} = \\begin{pmatrix} 1  -1 \\end{pmatrix} \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 1  -1 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ -1 \\end{pmatrix} = 4 + 1 = 5 $$\n    所以，步长是：\n    $$ \\alpha_{0} = - \\frac{3}{5} $$\n\n5.  **新的迭代点和误差**：\n    新的迭代点是 $x_{1} = x_{0} + \\alpha_{0} p_{0}$：\n    $$ x_{1} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} - \\frac{3}{5} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{3}{5} \\\\ 1 + \\frac{3}{5} \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{5} \\\\ \\frac{8}{5} \\end{pmatrix} $$\n    新的误差是 $e_{1} = x_{1} - x^{\\ast} = x_{1} = \\begin{pmatrix} \\frac{2}{5} \\\\ \\frac{8}{5} \\end{pmatrix}$。\n\n6.  **新误差的A-范数**：\n    新误差在$A$-能量范数下的平方为：\n    $$ \\|x_{1} - x^{\\ast}\\|_{A}^{2} = e_{1}^{\\top} A e_{1} = \\begin{pmatrix} \\frac{2}{5}  \\frac{8}{5} \\end{pmatrix} \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} \\frac{2}{5} \\\\ \\frac{8}{5} \\end{pmatrix} $$\n    $$ = 4 \\left(\\frac{2}{5}\\right)^{2} + 1 \\left(\\frac{8}{5}\\right)^{2} = 4 \\left(\\frac{4}{25}\\right) + \\frac{64}{25} = \\frac{16}{25} + \\frac{64}{25} = \\frac{80}{25} = \\frac{16}{5} $$\n\n7.  **缩减因子**：\n    缩减因子是新旧误差$A$-范数平方的比值：\n    $$ \\frac{\\|x_{1} - x^{\\ast}\\|_{A}^{2}}{\\|x_{0} - x^{\\ast}\\|_{A}^{2}} = \\frac{16/5}{5} = \\frac{16}{25} $$\n\n**第2部分：关于M的一般条件**\n\n1.  **在$M$-内积下的最速下降方向**：\n    泛函 $\\phi(x)$ 在标准欧几里得内积下的梯度为 $\\nabla \\phi(x) = Ax - b = r$。$\\phi$ 在点 $x$ 沿方向 $v$ 的方向导数为 $D\\phi(x)[v] = (\\nabla \\phi(x))^{\\top} v = r^{\\top}v$。\n    关于双线性形式 $(u,v)_M = u^{\\top} M v$ 的梯度，记为 $\\nabla_{M} \\phi(x)$，由关系式 $D\\phi(x)[v] = (\\nabla_{M} \\phi(x), v)_{M}$ 对所有 $v$ 定义。\n    代入表达式，我们得到：\n    $$ r^{\\top}v = (\\nabla_{M} \\phi(x))^{\\top} M v $$\n    这对所有向量 $v$ 都必须成立，这意味着在左边和右边乘以 $v^{\\top}$ 的向量必须相等：\n    $$ r = M^{\\top} (\\nabla_{M} \\phi(x)) $$\n    解出梯度 $\\nabla_{M} \\phi(x)$ 得：\n    $$ \\nabla_{M} \\phi(x) = (M^{\\top})^{-1} r $$\n    最速下降方向是梯度的负方向。因此，在第 $k$ 步，在 $(\\cdot, \\cdot)_M$ 意义下的真正最速下降方向是 $p_{k, \\text{true}} = -(M^{\\top})^{-1} r_k$。\n    问题中陈述所使用的方向是 $p_k = -M^{-1} r_k$。要使这个方向成为真正的最速下降方向，我们必须有：\n    $$ -M^{-1} r_k = -(M^{\\top})^{-1} r_k $$\n    这必须对任何可能的残差向量 $r_k$ 都成立，所以矩阵必须相等：$M^{-1} = (M^{\\top})^{-1}$。两边取逆得到 $M = M^{\\top}$。\n    因此，矩阵 $M$ 必须是对称的。为了使 $(\\cdot, \\cdot)_{M}$ 成为一个有效的内积， $M$ 还必须是正定的。综合条件是 $M$ 必须是对称正定的（SPD）。\n\n2.  **$M^{-1}A$ 在 $M$-内积下的自伴性**：\n    一个算子 $C$ 关于 $(\\cdot, \\cdot)_M$ 是自伴的（对称的），如果对所有 $u, v$ 都有 $(Cu, v)_M = (u, Cv)_M$。这里，$C = M^{-1}A$。\n    条件是 $((M^{-1}A)u, v)_M = (u, (M^{-1}A)v)_M$。\n    我们展开两边：\n    左边：$((M^{-1}A)u)^{\\top} M v = u^{\\top} A^{\\top} (M^{-1})^{\\top} M v$。\n    右边：$u^{\\top} M (M^{-1}A v) = u^{\\top} I A v = u^{\\top} A v$。\n    令两个表达式相等，我们得到：\n    $$ u^{\\top} A^{\\top} (M^{-1})^{\\top} M v = u^{\\top} A v $$\n    由于这对所有 $u,v$ 都必须成立，矩阵必须相等：\n    $$ A^{\\top} (M^{-1})^{\\top} M = A $$\n    问题指定 $A$ 是自伴的（对称的），所以 $A^{\\top}=A$。条件变为：\n    $$ A (M^{\\top})^{-1} M = A $$\n    由于 $A$ 是SPD，它是可逆的。我们可以从左边乘以 $A^{-1}$：\n    $$ (M^{\\top})^{-1} M = I $$\n    从左边乘以 $M^{\\top}$ 得到 $M = M^{\\top}$。\n    再次，预处理算子 $M^{-1}A$ 在 $M$-内积下自伴的条件是**$M$ 必须是对称的**。\n\n总而言之，为了使预条件最速下降法具有与经典方法相关的标准收敛性质，这些性质依赖于预处理算子($M^{-1}A$)在相应能量内积($(u,v)_M$)下的对称性，预条件子 $M$ 必须是对称的。本题中选择非对称的 $M$ 违反了这一基本要求，导致性能下降，正如数值结果所示。为了保证鲁棒性和收敛性， $M$ 应该是对称正定的（SPD）。", "answer": "$$\n\\boxed{\\frac{16}{25}}\n$$", "id": "3421050"}]}