{"hands_on_practices": [{"introduction": "向量空间的十条公理构成了线性代数的基石。但为什么是这些特定的规则呢？本练习将邀请您探索一个与向量空间非常相似，但刻意违反了其中一条分配律的结构。通过分析该结构在何处“失效”，您将对标准向量空间定义的严谨性和必要性有更深刻的理解。[@problem_id:3600932]", "problem": "设 $n \\geq 1$ 是一个固定的整数，考虑所有实数 $n$-元组构成的集合 $\\mathbb{R}^{n}$，其上定义了通常的向量加法 $+$，即 $(u_{1},\\dots,u_{n}) + (v_{1},\\dots,v_{n}) = (u_{1}+v_{1},\\dots,u_{n}+v_{n})$。定义一个修改后的标量乘法 $\\odot$，规定对于每个标量 $\\alpha \\in \\mathbb{R}$ 和向量 $v \\in \\mathbb{R}^{n}$，有 $\\alpha \\odot v = \\alpha^{2} v$，其中并置表示 $\\mathbb{R}^{n}$ 中的常规标量乘法。\n\n从刻画实数域 $\\mathbb{R}$ 上向量空间的标准公理（加法 $+$ 下的封闭性和阿贝尔群结构、标量乘法与域乘法的相容性、标量 $1$ 的单位作用以及两条分配律公理）出发，分析 $(\\mathbb{R}^{n}, +, \\odot)$ 是否满足每条公理。精确地指出哪条公理不成立，并给出其不成立的严格解释。\n\n对于任意标量 $a, b \\in \\mathbb{R}$ 和任意非零向量 $v \\in \\mathbb{R}^{n}$，定义残差 $r(a,b,v) = (a+b) \\odot v - \\big(a \\odot v + b \\odot v\\big)$。它可以唯一地写成 $r(a,b,v) = c(a,b) \\, v$ 的形式，其中 $c(a,b)$ 是一个标量函数。计算 $c(a,b)$ 作为 $a$ 和 $b$ 的函数的封闭形式表达式。最终答案必须是单个解析表达式。无需四舍五入。", "solution": "问题要求我们确定，对于一个固定的整数 $n \\geq 1$，集合 $\\mathbb{R}^{n}$ 在配备了标准向量加法 $+$ 和由 $\\alpha \\odot v = \\alpha^{2} v$ 定义的修改后的标量乘法 $\\odot$ 的情况下，是否构成实数域 $\\mathbb{R}$ 上的一个向量空间。我们必须找出哪条向量空间公理不成立，然后计算一个与此不成立情况相关的特定系数。\n\n首先，我们将系统地检验使 $(\\mathbb{R}^{n}, +, \\odot)$ 成为 $\\mathbb{R}$ 上向量空间所需的公理。一个结构 $(V, +, \\cdot)$ 是域 $F$ 上的向量空间，如果它对所有的 $u, v, w \\in V$ 和所有的标量 $\\alpha, \\beta \\in F$ 满足以下十条公理。在我们的情况下，$V = \\mathbb{R}^{n}$ 且 $F = \\mathbb{R}$。\n\n前五条公理关注 $(V, +)$ 作为阿贝尔群的结构：\n1.  **加法封闭性**：$u+v \\in \\mathbb{R}^{n}$。\n2.  **加法结合律**：$(u+v)+w = u+(v+w)$。\n3.  **存在加法单位元**：存在一个零向量 $0 \\in \\mathbb{R}^{n}$ 使得 $v+0=v$。\n4.  **存在加法逆元**：对每个 $v \\in \\mathbb{R}^{n}$，存在 $-v \\in \\mathbb{R}^{n}$ 使得 $v+(-v)=0$。\n5.  **加法交换律**：$u+v=v+u$。\n\n问题陈述了向量加法 $+$ 是 $\\mathbb{R}^{n}$ 中通常的逐分量加法。众所周知，集合 $\\mathbb{R}^{n}$ 与此标准加法构成一个阿贝尔群。因此，公理1到5都满足。零向量是 $(0, \\dots, 0)$，而 $(v_1, \\dots, v_n)$ 的加法逆元是 $(-v_1, \\dots, -v_n)$。\n\n剩下的五条公理关注标量乘法 $\\odot$ 及其与向量加法和 $\\mathbb{R}$ 中域运算的相互作用。\n\n6.  **标量乘法封闭性**：对于任何标量 $\\alpha \\in \\mathbb{R}$ 和任何向量 $v \\in \\mathbb{R}^{n}$，乘积 $\\alpha \\odot v$ 必须在 $\\mathbb{R}^{n}$ 中。\n    根据定义，$\\alpha \\odot v = \\alpha^{2} v$。因为 $\\alpha \\in \\mathbb{R}$，其平方 $\\alpha^{2}$ 也是一个实数。表达式 $\\alpha^{2} v$ 表示向量 $v \\in \\mathbb{R}^{n}$ 与标量 $\\alpha^{2}$ 的标准标量乘法。结果是 $\\mathbb{R}^{n}$ 中的一个向量。因此，这条公理满足。\n\n7.  **标量乘法对向量加法的分配律**：$\\alpha \\odot (u+v) = \\alpha \\odot u + \\alpha \\odot v$。\n    我们来计算等式两边。\n    左边 (LHS)：$\\alpha \\odot (u+v) = \\alpha^{2} (u+v) = \\alpha^{2} u + \\alpha^{2} v$。这里我们使用了标准标量乘法的分配性质。\n    右边 (RHS)：$\\alpha \\odot u + \\alpha \\odot v = \\alpha^{2} u + \\alpha^{2} v$。\n    由于 LHS = RHS，此公理满足。\n\n8.  **标量乘法对标量加法的分配律**：$(\\alpha+\\beta) \\odot v = \\alpha \\odot v + \\beta \\odot v$。\n    我们对任意标量 $\\alpha, \\beta \\in \\mathbb{R}$ 和任意向量 $v \\in \\mathbb{R}^{n}$ 计算等式两边。\n    LHS：$(\\alpha+\\beta) \\odot v = (\\alpha+\\beta)^{2} v = (\\alpha^{2} + 2\\alpha\\beta + \\beta^{2}) v$。\n    RHS：$\\alpha \\odot v + \\beta \\odot v = \\alpha^{2} v + \\beta^{2} v = (\\alpha^{2} + \\beta^{2}) v$。\n    为了使此公理成立，等式 $(\\alpha^{2} + 2\\alpha\\beta + \\beta^{2}) v = (\\alpha^{2} + \\beta^{2}) v$ 必须对所有的 $\\alpha, \\beta \\in \\mathbb{R}$ 和所有的 $v \\in \\mathbb{R}^{n}$ 都成立。\n    从两边减去 $(\\alpha^{2} + \\beta^{2}) v$，我们得到 $(2\\alpha\\beta) v = 0$。\n    这个方程必须普遍成立。然而，如果我们选择非零值，例如 $\\alpha = 1$，$\\beta = 1$ 和任何非零向量 $v \\in \\mathbb{R}^{n}$，方程变为 $2v = 0$，这意味着 $v = 0$。这与我们选择非零向量 $v$ 相矛盾。因此，该等式一般不成立。\n    此公理不成立。\n\n9.  **标量乘法与域乘法的相容性**：$(\\alpha\\beta) \\odot v = \\alpha \\odot (\\beta \\odot v)$。\n    LHS：$(\\alpha\\beta) \\odot v = (\\alpha\\beta)^{2} v = \\alpha^{2}\\beta^{2} v$。\n    RHS：$\\alpha \\odot (\\beta \\odot v) = \\alpha \\odot (\\beta^{2} v) = \\alpha^{2}(\\beta^{2} v) = (\\alpha^{2}\\beta^{2})v$。\n    由于 LHS = RHS，此公理满足。\n\n10. **标量乘法的单位元**：$1 \\odot v = v$。\n    LHS：$1 \\odot v = 1^{2} v = 1v = v$。\n    由于 LHS = $v$，此公理满足。\n\n分析表明恰好有一条公理不成立：标量乘法对标量加法的分配律。\n\n现在，我们计算 $c(a,b)$ 的封闭形式表达式。残差定义为 $r(a,b,v) = (a+b) \\odot v - \\big(a \\odot v + b \\odot v\\big)$，对于任意标量 $a, b \\in \\mathbb{R}$ 和任意非零向量 $v \\in \\mathbb{R}^{n}$。我们已知 $r(a,b,v) = c(a,b) v$。\n\n我们将修改后的标量乘法 $\\odot$ 的定义代入残差的表达式中：\n$r(a,b,v) = (a+b)^{2} v - \\left( a^{2} v + b^{2} v \\right)$\n利用标准标量乘法对向量加法的分配律，我们可以将向量 $v$ 因子提取出来：\n$r(a,b,v) = \\left( (a+b)^{2} - (a^{2} + b^{2}) \\right) v$\n接下来，我们展开项 $(a+b)^{2}$：\n$r(a,b,v) = \\left( (a^{2} + 2ab + b^{2}) - (a^{2} + b^{2}) \\right) v$\n简化标量系数：\n$r(a,b,v) = (a^{2} + 2ab + b^{2} - a^{2} - b^{2}) v$\n$r(a,b,v) = (2ab) v$\n我们已知 $r(a,b,v) = c(a,b) v$。通过将其与我们推导出的表达式进行比较，我们得到：\n$c(a,b) v = (2ab) v$\n因为这对任何非零向量 $v \\in \\mathbb{R}^{n}$ 都必须成立，所以标量系数必须相等：\n$c(a,b) = 2ab$\n这个 $c(a,b)$ 的表达式量化了分配律公理不成立的程度。该公理仅在 $c(a,b)=0$ 时成立，而这仅在 $a=0$ 或 $b=0$ 时发生。", "answer": "$$\\boxed{2ab}$$", "id": "3600932"}, {"introduction": "从抽象定义转向具体几何问题时，我们常需要回答两个关键问题：一个给定的向量是否位于某个特定的子空间内？如果不在，它离这个子空间有多“远”？本练习将引导您完成回答这些问题的计算步骤，将向量张成的空间（span）的概念与求解线性方程组联系起来。接着，您将应用正交投影这一强大工具，来寻找子空间中距离外部向量最近的点，这是近似理论和数据分析中的一项基本任务。[@problem_id:3600936]", "problem": "设 $n \\in \\mathbb{N}$，考虑配备了标准欧几里得内积的实向量空间 $\\mathbb{R}^{n}$。向量 $v_{1},\\dots,v_{k} \\in \\mathbb{R}^{n}$ 的生成空间 $\\operatorname{span}\\{v_{1},\\dots,v_{k}\\}$ 是这些向量的所有有限线性组合的集合。一个向量 $w \\in \\mathbb{R}^{n}$ 属于 $\\operatorname{span}\\{v_{1},\\dots,v_{k}\\}$ 当且仅当存在标量 $c_{1},\\dots,c_{k} \\in \\mathbb{R}$ 使得 $w = \\sum_{j=1}^{k} c_{j} v_{j}$，这等价于由以 $v_{1},\\dots,v_{k}$ 为列的矩阵所形成的线性方程组有解。\n\n从这些定义以及线性代数中关于线性系统、秩和正交投影的公认事实出发，对以下具体数据执行下列任务：\n$$\nv_{1} = \\begin{pmatrix}1 \\\\ 0 \\\\ 1 \\\\ 0\\end{pmatrix},\\quad\nv_{2} = \\begin{pmatrix}0 \\\\ 1 \\\\ 1 \\\\ 0\\end{pmatrix},\\quad\nv_{3} = \\begin{pmatrix}1 \\\\ 1 \\\\ 2 \\\\ 0\\end{pmatrix},\\quad\nw = \\begin{pmatrix}2 \\\\ -1 \\\\ 1 \\\\ 3\\end{pmatrix} \\in \\mathbb{R}^{4}.\n$$\n1. 建立表示条件 $w \\in \\operatorname{span}\\{v_{1},v_{2},v_{3}\\}$ 的线性系统，并根据线性系统和秩的定义与性质进行有理有据的推断，确定该系统是否相容。\n2. 利用关于向由向量张成的子空间上作正交投影的基本事实，求解 $w$ 在子空间 $V = \\operatorname{span}\\{v_{1},v_{2},v_{3}\\}$ 上的正交投影，并推导出 $w$ 到 $V$ 的欧几里得距离。\n\n将你的最终答案表示为从 $w$ 到 $V$ 的欧几里得距离（2-范数）的精确值，不要进行四舍五入。", "solution": "该问题是有效的，因为它定义明确、内容自洽，并且基于线性代数的标准原理。\n\n问题包含两部分。首先，我们判断向量 $w$ 是否位于子空间 $V = \\operatorname{span}\\{v_{1}, v_{2}, v_{3}\\}$ 中。其次，我们计算 $w$ 在 $V$ 上的正交投影，并求出 $w$ 到 $V$ 的欧几里得距离。\n\n**第一部分：线性系统的相容性**\n\n一个向量 $w$ 属于向量集合 $\\{v_{1}, v_{2}, v_{3}\\}$ 的生成空间，当且仅当它可以表示为这些向量的线性组合。也就是说，必须存在标量 $c_{1}, c_{2}, c_{3} \\in \\mathbb{R}$ 使得：\n$$ c_{1}v_{1} + c_{2}v_{2} + c_{3}v_{3} = w $$\n这个向量方程可以写成矩阵形式的线性系统 $Ac=w$，其中矩阵 $A$ 以向量 $v_{1}, v_{2}, v_{3}$ 为列，而 $c$ 是系数向量。\n给定向量：\n$$ v_{1} = \\begin{pmatrix}1 \\\\ 0 \\\\ 1 \\\\ 0\\end{pmatrix},\\quad v_{2} = \\begin{pmatrix}0 \\\\ 1 \\\\ 1 \\\\ 0\\end{pmatrix},\\quad v_{3} = \\begin{pmatrix}1 \\\\ 1 \\\\ 2 \\\\ 0\\end{pmatrix},\\quad w = \\begin{pmatrix}2 \\\\ -1 \\\\ 1 \\\\ 3\\end{pmatrix} $$\n矩阵 $A$ 和向量 $c$ 分别是：\n$$ A = \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\\\ 1  1  2 \\\\ 0  0  0 \\end{pmatrix}, \\quad c = \\begin{pmatrix} c_{1} \\\\ c_{2} \\\\ c_{3} \\end{pmatrix} $$\n线性系统相容的充要条件是系数矩阵 $A$ 的秩等于增广矩阵 $[A|w]$ 的秩。\n\n首先，我们通过将矩阵 $A$ 化为行阶梯形来确定其秩。\n$$ A = \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\\\ 1  1  2 \\\\ 0  0  0 \\end{pmatrix} \\xrightarrow{R_3 \\to R_3-R_1} \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\\\ 0  1  1 \\\\ 0  0  0 \\end{pmatrix} \\xrightarrow{R_3 \\to R_3-R_2} \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\\\ 0  0  0 \\\\ 0  0  0 \\end{pmatrix} $$\n$A$ 的行阶梯形有两个非零行，所以 $\\operatorname{rank}(A) = 2$。秩小于向量的个数（$2  3$）这一事实表明集合 $\\{v_{1}, v_{2}, v_{3}\\}$ 是线性相关的。我们可以观察到 $v_{3} = v_{1} + v_{2}$。\n\n接下来，我们确定增广矩阵 $[A|w]$ 的秩。\n$$ [A|w] = \\begin{pmatrix} 1  0  1  2 \\\\ 0  1  1  -1 \\\\ 1  1  2  1 \\\\ 0  0  0  3 \\end{pmatrix} $$\n我们执行相同的行变换：\n$$ \\begin{pmatrix} 1  0  1  2 \\\\ 0  1  1  -1 \\\\ 1  1  2  1 \\\\ 0  0  0  3 \\end{pmatrix} \\xrightarrow{R_3 \\to R_3-R_1} \\begin{pmatrix} 1  0  1  2 \\\\ 0  1  1  -1 \\\\ 0  1  1  -1 \\\\ 0  0  0  3 \\end{pmatrix} \\xrightarrow{R_3 \\to R_3-R_2} \\begin{pmatrix} 1  0  1  2 \\\\ 0  1  1  -1 \\\\ 0  0  0  0 \\\\ 0  0  0  3 \\end{pmatrix} $$\n交换第 $R_3$ 行和第 $R_4$ 行以得到行阶梯形：\n$$ \\begin{pmatrix} 1  0  1  2 \\\\ 0  1  1  -1 \\\\ 0  0  0  3 \\\\ 0  0  0  0 \\end{pmatrix} $$\n$[A|w]$ 的行阶梯形有三个非零行，因此 $\\operatorname{rank}([A|w]) = 3$。\n由于 $\\operatorname{rank}(A) = 2 \\neq \\operatorname{rank}([A|w]) = 3$，该线性系统不相容。这证明了 $w \\notin \\operatorname{span}\\{v_{1}, v_{2}, v_{3}\\}$。\n\n**第二部分：正交投影与距离**\n\n子空间 $V$ 由 $V = \\operatorname{span}\\{v_{1}, v_{2}, v_{3}\\}$ 给出。如前所述，$v_{3} = v_{1} + v_{2}$，因此 $v_{3}$ 是多余的。$V$ 的一个基是 $\\{v_{1}, v_{2}\\}$。所以，$V = \\operatorname{span}\\{v_{1}, v_{2}\\}$。\n\n$w$ 在 $V$ 上的正交投影，我们记作 $p = \\operatorname{proj}_{V}(w)$，是 $V$ 中的唯一向量，使得向量 $w - p$ 与 $V$ 中的每一个向量都正交。$w$ 到 $V$ 的欧几里得距离就是 $\\|w - p\\|$。\n\n投影 $p$ 可以通过解正规方程组得到。设 $A'$ 是一个矩阵，其列是 $V$ 的一组基，即 $A' = [v_{1}|v_{2}]$。\n$$ A' = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\\\ 0  0 \\end{pmatrix} $$\n投影 $p$ 由公式 $p = A'(A'^{T}A')^{-1}A'^{T}w$ 给出。\n首先，我们计算格拉姆矩阵 (Gram matrix) $A'^{T}A'$：\n$$ A'^{T}A' = \\begin{pmatrix} 1  0  1  0 \\\\ 0  1  1  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1\\cdot1+1\\cdot1  1\\cdot0+1\\cdot1 \\\\ 1\\cdot1+0\\cdot1  1\\cdot1+1\\cdot1 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix} $$\n接下来，我们求这个矩阵的逆：\n$$ (A'^{T}A')^{-1} = \\frac{1}{(2)(2) - (1)(1)} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} $$\n现在我们计算 $A'^{T}w$：\n$$ A'^{T}w = \\begin{pmatrix} 1  0  1  0 \\\\ 0  1  1  0 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -1 \\\\ 1 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 1\\cdot2+0\\cdot(-1)+1\\cdot1+0\\cdot3 \\\\ 0\\cdot2+1\\cdot(-1)+1\\cdot1+0\\cdot3 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix} $$\n现在我们可以求出投影 $p$。基向量的线性组合系数为 $c' = (A'^{T}A')^{-1}A'^{T}w$：\n$$ c' = \\frac{1}{3} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3}(6) \\\\ \\frac{1}{3}(-3) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} $$\n投影向量是 $p = A'c' = 2v_{1} - 1v_{2}$：\n$$ p = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix} $$\n代表从 $w$ 到子空间 $V$ 的最短距离的向量是 $w$ 正交于 $V$ 的分量，即 $w - p$：\n$$ w - p = \\begin{pmatrix} 2 \\\\ -1 \\\\ 1 \\\\ 3 \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 3 \\end{pmatrix} $$\n从 $w$ 到 $V$ 的欧几里得距离是这个正交向量的范数：\n$$ \\|w - p\\| = \\left\\| \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 3 \\end{pmatrix} \\right\\| = \\sqrt{0^{2} + 0^{2} + 0^{2} + 3^{2}} = \\sqrt{9} = 3 $$\n因此，$w$ 到子空间 $V$ 的精确欧几里得距离是 $3$。", "answer": "$$ \\boxed{3} $$", "id": "3600936"}, {"introduction": "线性代数基本定理为任何线性变换提供了一幅完整的几何蓝图，将定义域和上域划分为四个相互正交的子空间。这个计算实践将挑战您使用奇异值分解（SVD），这一最重要的矩阵分解方法之一，来实现该定理。通过编程构建列空间、零空间、行空间和左零空间的基，您将以数值方式验证它们的维数和正交性，将抽象的理论转化为具体的计算洞察。[@problem_id:3600957]", "problem": "给定任务是通过编程方式提取与实矩阵 $A$ 相关的四个基本子空间的正交基，并从数值上验证由线性代数基本定理产生的正交关系。这四个基本子空间是列空间 $\\mathcal{R}(A)$、零空间 $\\mathcal{N}(A)$、行空间 $\\mathcal{R}(A^\\top)$ 和左零空间 $\\mathcal{N}(A^\\top)$。起始定义如下：$\\mathbb{R}$ 上向量空间的子空间是指任何对加法和标量乘法封闭的子集；列空间 $\\mathcal{R}(A)$ 是 $\\{A x : x \\in \\mathbb{R}^n\\}$；零空间 $\\mathcal{N}(A)$ 是 $\\{x \\in \\mathbb{R}^n : A x = 0\\}$；行空间 $\\mathcal{R}(A^\\top)$ 是 $\\{A^\\top y : y \\in \\mathbb{R}^m\\}$；左零空间 $\\mathcal{N}(A^\\top)$ 是 $\\{y \\in \\mathbb{R}^m : A^\\top y = 0\\}$。您可以使用奇异值分解 (SVD) 或 QR 分解 (QR)，但正交基的提取必须由这些分解在数值上予以证明。\n\n根据奇异值分解 (SVD)，如果 $A \\in \\mathbb{R}^{m \\times n}$，则 $A = U \\Sigma V^\\top$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 具有正交列（即为正交矩阵），而 $\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是对角矩阵，其对角线上的非负奇异值为 $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_{\\min(m,n)} \\ge 0$。根据由容差确定的数值秩 $r$ 对 $U = [U_r \\; U_0]$ 和 $V = [V_r \\; V_0]$ 进行划分。那么 $\\mathcal{R}(A)$ 由 $U_r$ 的列张成，$\\mathcal{R}(A^\\top)$ 由 $V_r$ 的列张成，$\\mathcal{N}(A)$ 由 $V_0$ 的列张成，而 $\\mathcal{N}(A^\\top)$ 由 $U_0$ 的列张成。基本正交关系为 $\\mathcal{N}(A)$ 与 $\\mathcal{R}(A^\\top)$ 正交，以及 $\\mathcal{N}(A^\\top)$ 与 $\\mathcal{R}(A)$ 正交。\n\n您的程序必须：\n- 对于每个测试矩阵 $A$，计算 SVD $A = U \\Sigma V^\\top$，并使用容差\n$$\\tau = \\max(m,n) \\, \\sigma_{\\max} \\, \\epsilon,$$\n来决定数值秩 $r$，其中 $m \\times n$ 是 $A$ 的形状，$\\sigma_{\\max}$ 是 $A$ 的最大奇异值，$\\epsilon$ 是双精度机器 epsilon ($\\epsilon \\approx 2.22 \\times 10^{-16}$)。\n- 为四个基本子空间构建正交基：\n    1. $\\mathcal{R}(A)$ 的基：$U_r \\in \\mathbb{R}^{m \\times r}$ 的列。\n    2. $\\mathcal{R}(A^\\top)$ 的基：$V_r \\in \\mathbb{R}^{n \\times r}$ 的列。\n    3. $\\mathcal{N}(A)$ 的基：$V_0 \\in \\mathbb{R}^{n \\times (n-r)}$ 的列。\n    4. $\\mathcal{N}(A^\\top)$ 的基：$U_0 \\in \\mathbb{R}^{m \\times (m-r)}$ 的列。\n- 使用 Frobenius 范数，在数值上确认每个基的正交规范性以及子空间间的正交关系：\n    - 对于任何具有 $k$ 列的基矩阵 $Q$，通过计算 $\\|Q^\\top Q - I_k\\|_F$ 来检验 $Q^\\top Q \\approx I_k$。\n    - 检验 $\\|V_r^\\top V_0\\|_F \\approx 0$ 和 $\\|U_r^\\top U_0\\|_F \\approx 0$。\n- 此外，确认截断重构 $A_r = U_r \\Sigma_r V_r^\\top$ 能以较小的相对残差 $\\|A - A_r\\|_F / \\|A\\|_F$ 逼近 $A$（如果 $\\|A\\|_F = 0$，则使用绝对残差 $\\|A - A_r\\|_F$）。\n- 将维数等式 $r + \\dim(\\mathcal{N}(A)) = n$ 和 $r + \\dim(\\mathcal{N}(A^\\top)) = m$ 验证为精确的整数等式。\n\n对于每个测试矩阵，将上述所有残差范数（正交规范性残差、正交性残差和重构残差）中的最大值聚合为一个浮点数，并附带一个布尔值，指示维数等式是否成立。最终输出必须将所有提供的测试用例的结果聚合为单行，格式为方括号括起来的逗号分隔列表，顺序如下\n$$[e_1, b_1, e_2, b_2, e_3, b_3, e_4, b_4],$$\n其中 $e_k$ 是第 $k$ 个测试矩阵的最大残差浮点数，$b_k$ 是对应的布尔值。\n\n测试套件矩阵（必须严格按规定使用）：\n1. 一个高、满列秩的情况 ($4 \\times 3$):\n$$\nA_1 = \\begin{bmatrix}\n2  -1  0 \\\\\n0  1  3 \\\\\n4  -2  1 \\\\\n1  0  -1\n\\end{bmatrix}.\n$$\n2. 一个宽、秩亏且具有行相关性的情况 ($3 \\times 4$):\n$$\nA_2 = \\begin{bmatrix}\n1  0  1  1 \\\\\n0  1  1  2 \\\\\n1  1  2  3\n\\end{bmatrix}.\n$$\n3. 一个方形、秩为 $3$ 的情况 ($5 \\times 5$)，其构造方式为使其两列是前三列的线性组合：\n令列向量为\n$$\nc_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 2 \\\\ 3 \\end{bmatrix},\\quad\nc_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ -1 \\\\ 0 \\end{bmatrix},\\quad\nc_3 = \\begin{bmatrix} 2 \\\\ -1 \\\\ 0 \\\\ 1 \\\\ 1 \\end{bmatrix},\\quad\nc_4 = c_1 + c_2,\\quad\nc_5 = c_2 - c_3,\n$$\n所以\n$$\nA_3 = \\begin{bmatrix}\n1  0  2  1  -2 \\\\\n0  1  -1  1  2 \\\\\n1  2  0  3  2 \\\\\n2  -1  1  1  -2 \\\\\n3  0  1  3  -1\n\\end{bmatrix}.\n$$\n4. 一个近秩亏的对角矩阵情况 ($4 \\times 4$)，其中一个奇异值低于容差：\n$$\nA_4 = \\operatorname{diag}\\!\\left(10,\\; 1\\times 10^{-16},\\; 3,\\; 1\\right).\n$$\n\n角度单位不适用。没有出现物理单位，因此不需要。您的程序必须精确地产生一行输出，包含如上所述的方括号括起来的逗号分隔列表形式的结果，不含多余的空格或文本。", "solution": "该问题要求以编程方式提取并数值验证实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的四个基本子空间的正交基：列空间 $\\mathcal{R}(A)$、零空间 $\\mathcal{N}(A)$、行空间 $\\mathcal{R}(A^\\top)$ 和左零空间 $\\mathcal{N}(A^\\top)$。此任务是线性代数基本定理的直接应用，该定理确立了这些子空间之间的维度和正交关系。奇异值分解 (SVD) 提供了一种强大且数值稳定的工具来计算这些基。\n\n矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的 SVD 是一个因子分解 $A = U \\Sigma V^\\top$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个矩形对角矩阵，其对角线上的非负实数（称为奇异值）按降序排列：$\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_p \\ge 0$，其中 $p = \\min(m, n)$。\n\n核心原理是 $U$ 和 $V$ 的列（奇异向量）为四个基本子空间提供了正交基。区分张成这些空间的向量与其正交补的向量是由数值秩 $r$ 决定的。秩 $r$ 是“显著”大于零的奇异值的数量。在数值计算中，我们使用一个容差 $\\tau$ 来定义这一点。问题指定了此容差的标准选择：\n$$\n\\tau = \\max(m, n) \\cdot \\sigma_{\\max} \\cdot \\epsilon,\n$$\n其中 $\\sigma_{\\max}$ 是最大的奇异值 $\\sigma_1$，$\\epsilon$ 是双精度浮点运算的机器 epsilon。数值秩 $r$ 于是就是奇异值 $\\sigma_i  \\tau$ 的数量。\n\n给定秩 $r$，我们对正交矩阵 $U$ 和 $V$ 进行划分。设 $U$ 的列为 $u_1, \\dots, u_m$，$V$ 的列为 $v_1, \\dots, v_n$。我们形成如下划分：\n- $U_r = [u_1, \\dots, u_r] \\in \\mathbb{R}^{m \\times r}$\n- $U_0 = [u_{r+1}, \\dots, u_m] \\in \\mathbb{R}^{m \\times (m-r)}$\n- $V_r = [v_1, \\dots, v_r] \\in \\mathbb{R}^{n \\times r}$\n- $V_0 = [v_{r+1}, \\dots, v_n] \\in \\mathbb{R}^{n \\times (n-r)}$\n\nSVD 直接给出了四个基本子空间的正交基：\n1.  **列空间 $\\mathcal{R}(A)$**：一个正交基由 $U_r$ 的列给出。其维数为 $r$。\n2.  **左零空间 $\\mathcal{N}(A^\\top)$**：一个正交基由 $U_0$ 的列给出。其维数为 $m-r$。\n3.  **行空间 $\\mathcal{R}(A^\\top)$**：一个正交基由 $V_r$ 的列给出。其维数为 $r$。\n4.  **零空间 $\\mathcal{N}(A)$**：一个正交基由 $V_0$ 的列给出。其维数为 $n-r$。\n\n线性代数基本定理指出，$\\mathcal{R}(A)$ 是 $\\mathcal{N}(A^\\top)$ 在 $\\mathbb{R}^m$ 中的正交补，而 $\\mathcal{R}(A^\\top)$ 是 $\\mathcal{N}(A)$ 在 $\\mathbb{R}^n$ 中的正交补。我们的算法将数值验证这些性质。\n\n对每个测试矩阵 $A$ 的算法流程如下：\n1.  计算完整的 SVD $A = U \\Sigma V^\\top$。矩阵 $U$ 和 $V$ 必须是方阵（正交），而不是半正交的。\n2.  通过计算超过容差 $\\tau$ 的奇异值 $s_i$ 的数量来确定数值秩 $r$。\n3.  根据秩 $r$ 将 $U$ 和 $V$ 划分为 $U_r, U_0, V_r, V_0$。\n4.  执行数值验证并使用 Frobenius 范数 $\\| \\cdot \\|_F$ 计算它们的残差：\n    a. **基的正交规范性**：对于每个非空基矩阵 $Q \\in \\{U_r, U_0, V_r, V_0\\}$，计算残差 $\\|Q^\\top Q - I\\|_F$。这里的 $I$ 是适当大小的单位矩阵。\n    b. **子空间的正交性**：计算残差 $\\|U_r^\\top U_0\\|_F$ 和 $\\|V_r^\\top V_0\\|_F$。这些代表了一个空间与其正交补的基向量之间的点积，应接近于零。\n    c. **重构精度**：计算截断 SVD 重构 $A_r = U_r \\Sigma_r V_r^\\top$，其中 $\\Sigma_r$ 是前 $r$ 个奇异值构成的 $r \\times r$ 对角矩阵。计算相对重构误差 $\\|A - A_r\\|_F / \\|A\\|_F$。\n5.  将维度定理（秩-零度定理）恒等式验证为精确的整数等式：$r + \\dim(\\mathcal{N}(A)) = n$ 和 $r + \\dim(\\mathcal{N}(A^\\top)) = m$。根据我们的构造，$\\dim(\\mathcal{N}(A))$ 是 $V_0$ 的列数，即 $n-r$，而 $\\dim(\\mathcal{N}(A^\\top))$ 是 $U_0$ 的列数，即 $m-r$。因此，检查变为 $r + (n-r) = n$ 和 $r + (m-r) = m$，这是代数上的恒等式。其程序化验证确认了矩阵分区的正确实现。\n6.  将矩阵 $A_k$ 的结果聚合成一对 $(e_k, b_k)$，其中 $e_k$ 是所有计算出的浮点残差中的最大值，而 $b_k$ 是维度等式检查的布尔结果。\n\n该程序将应用于四个提供的每个测试矩阵。最终输出将是连接所有测试用例的 $(e_k, b_k)$ 对的列表。", "answer": "```python\nimport numpy as np\n\ndef analyze_matrix(A):\n    \"\"\"\n    Analyzes a matrix A to find its four fundamental subspaces,\n    validates their properties, and returns aggregated error metrics.\n    \"\"\"\n    m, n = A.shape\n    \n    # Step 1: Compute SVD\n    # full_matrices=True is essential to get square U and V for partitioning.\n    try:\n        U, s, Vt = np.linalg.svd(A, full_matrices=True)\n    except np.linalg.LinAlgError:\n        # Handle cases where SVD does not converge, though unlikely for these examples.\n        return float('inf'), False\n\n    # Initialize a list to store all computed numerical residuals.\n    residuals = []\n\n    # Step 2: Determine numerical rank\n    # s is sorted in descending order.\n    # Handle the case of a zero matrix where s would be empty or all zeros.\n    s_max = s[0] if len(s)  0 else 0.0\n    eps = np.finfo(float).eps\n    tau = max(m, n) * s_max * eps\n    r = np.sum(s  tau)\n    \n    # Step 3: Partition U and V based on rank r\n    V = Vt.T\n    Ur = U[:, :r]\n    U0 = U[:, r:]\n    Vr = V[:, :r]\n    V0 = V[:, r:]\n\n    # Step 4a: Check orthonormality of each basis\n    # Q^T Q should be close to I_k.\n    # The check is only performed if the basis is non-empty (k > 0).\n    if Ur.shape[1]  0:\n        residuals.append(np.linalg.norm(Ur.T @ Ur - np.eye(r), 'fro'))\n    if U0.shape[1]  0:\n        residuals.append(np.linalg.norm(U0.T @ U0 - np.eye(m - r), 'fro'))\n    if Vr.shape[1]  0:\n        residuals.append(np.linalg.norm(Vr.T @ Vr - np.eye(r), 'fro'))\n    if V0.shape[1]  0:\n        residuals.append(np.linalg.norm(V0.T @ V0 - np.eye(n - r), 'fro'))\n\n    # Step 4b: Check orthogonality between subspaces\n    # These products should be close to zero matrices. numpy.linalg.norm handles\n    # products involving empty matrices correctly (norm is 0).\n    residuals.append(np.linalg.norm(Ur.T @ U0, 'fro'))\n    residuals.append(np.linalg.norm(Vr.T @ V0, 'fro'))\n\n    # Step 4c: Check reconstruction accuracy\n    # Ar = Ur @ diag(s_r) @ Vr.T\n    if r  0:\n        Ar = Ur @ np.diag(s[:r]) @ Vr.T\n    else: # If rank is 0, A is the zero matrix\n        Ar = np.zeros_like(A, dtype=float)\n        \n    norm_A = np.linalg.norm(A, 'fro')\n    if norm_A == 0:\n        reconstruction_resid = np.linalg.norm(A - Ar, 'fro')\n    else:\n        reconstruction_resid = np.linalg.norm(A - Ar, 'fro') / norm_A\n    residuals.append(reconstruction_resid)\n\n    # Step 5: Verify dimension equalities\n    dim_N_A = V0.shape[1]\n    dim_N_At = U0.shape[1]\n    dim_check1 = (r + dim_N_A == n)\n    dim_check2 = (r + dim_N_At == m)\n    b_k = dim_check1 and dim_check2\n\n    # Step 6: Aggregate results\n    # If residuals list is empty (can happen for trivial cases), max would error.\n    e_k = max(residuals) if residuals else 0.0\n\n    return e_k, b_k\n\ndef solve():\n    # Define the test cases from the problem statement.\n    A1 = np.array([\n        [2, -1, 0],\n        [0, 1, 3],\n        [4, -2, 1],\n        [1, 0, -1]\n    ], dtype=float)\n\n    A2 = np.array([\n        [1, 0, 1, 1],\n        [0, 1, 1, 2],\n        [1, 1, 2, 3]\n    ], dtype=float)\n\n    c1 = np.array([1, 0, 1, 2, 3])\n    c2 = np.array([0, 1, 2, -1, 0])\n    c3 = np.array([2, -1, 0, 1, 1])\n    c4 = c1 + c2\n    c5 = c2 - c3\n    A3 = np.vstack([c1, c2, c3, c4, c5]).T\n\n    A4 = np.diag([10.0, 1e-16, 3.0, 1.0])\n\n    test_cases = [A1, A2, A3, A4]\n\n    results = []\n    for case in test_cases:\n        e_k, b_k = analyze_matrix(case)\n        results.append(e_k)\n        results.append(b_k)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3600957"}]}