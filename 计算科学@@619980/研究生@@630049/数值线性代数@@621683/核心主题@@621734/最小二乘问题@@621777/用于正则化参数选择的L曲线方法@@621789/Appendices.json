{"hands_on_practices": [{"introduction": "在实现一种数值方法之前，理解其根本局限性至关重要。本练习将引导你通过一个特例进行解析推导，该特例中算子矩阵的奇异值谱是扁平的。通过这个练习，你将亲手证明L曲线的标志性“拐角”在这种情况下会变得模糊不清，从而深刻理解算子的谱特性与该方法性能之间的内在联系。[@problem_id:3554649]", "problem": "考虑 $\\mathbb{R}^{n}$ 中的线性反问题，其由 Tikhonov 正则化最小二乘目标函数定义\n$$\nJ_{\\lambda}(x) \\;=\\; \\|A x - b\\|_{2}^{2} \\;+\\; \\lambda^{2} \\|x\\|_{2}^{2},\n$$\n其中 $A \\in \\mathbb{R}^{n \\times n}$，$b \\in \\mathbb{R}^{n}$ 非零，且 $\\lambda > 0$ 是正则化参数。L 曲线是残差范数对解范数的参数化对数-对数图，\n$$\n\\big(\\ln \\rho(\\lambda), \\, \\ln \\eta(\\lambda)\\big), \\quad \\text{其中} \\quad \\rho(\\lambda) := \\|A x_{\\lambda} - b\\|_{2}, \\quad \\eta(\\lambda) := \\|x_{\\lambda}\\|_{2},\n$$\n其中 $x_{\\lambda}$ 是 $J_{\\lambda}(x)$ 的最小化子。通过采用解析上易于处理的极限情况 $A = \\sigma I_{n}$（其中 $\\sigma > 0$），构造一个奇异值近乎平坦的矩阵 $A$，并分析所得的 L 曲线。\n\n仅从基本定义出发——即最小化子 $x_{\\lambda}$ 的正规方程和平面曲线的曲率定义——推导：\n1. 用 $\\sigma$、$\\lambda$ 和 $\\|b\\|_{2}$ 表示的 $\\rho(\\lambda)$ 和 $\\eta(\\lambda)$ 的表达式。\n2. 参数化平面曲线 $c(\\lambda) = \\big(\\ln \\rho(\\lambda), \\ln \\eta(\\lambda)\\big)$ 及其曲率 $\\kappa(\\lambda)$（作为 $\\lambda$ 的函数），该曲率通过参数化表示的平面曲线的标准曲率定义计算。\n3. 使 $\\kappa(\\lambda)$ 最大化的值 $\\lambda_{\\star} > 0$，以及最大曲率 $\\kappa_{\\max} := \\max_{\\lambda > 0} \\kappa(\\lambda)$。\n\n根据你对 $\\kappa(\\lambda)$ 的解析表达式，解释为什么在这种奇异值平坦的情况下 L 曲线缺少一个尖锐的拐角，从而导致 $\\lambda$ 的选择不明确。\n\n以精确解析形式给出最终结果，即数对 $\\big(\\lambda_{\\star}, \\kappa_{\\max}\\big)$。无需四舍五入。", "solution": "我们从 Tikhonov 正则化的第一性原理开始。\n$$\nJ_{\\lambda}(x) \\;=\\; \\|A x - b\\|_{2}^{2} \\;+\\; \\lambda^{2} \\|x\\|_{2}^{2}\n$$\n的最小化子 $x_{\\lambda}$ 满足正规方程\n$$\nA^{\\top} (A x_{\\lambda} - b) \\;+\\; \\lambda^{2} x_{\\lambda} \\;=\\; 0,\n$$\n可以整理为\n$$\n\\big(A^{\\top} A + \\lambda^{2} I\\big) x_{\\lambda} \\;=\\; A^{\\top} b.\n$$\n在奇异值近乎平坦的解析上易于处理的极限情况下，我们设 $A = \\sigma I_{n}$，其中 $\\sigma > 0$。那么 $A^{\\top} A = \\sigma^{2} I_{n}$ 且 $A^{\\top} b = \\sigma b$，因此正规方程简化为\n$$\n\\big(\\sigma^{2} I_{n} + \\lambda^{2} I_{n}\\big) x_{\\lambda} \\;=\\; \\sigma b\n\\quad\\Longrightarrow\\quad\nx_{\\lambda} \\;=\\; \\frac{\\sigma}{\\sigma^{2} + \\lambda^{2}} \\, b.\n$$\n残差为\n$$\nr_{\\lambda} \\;=\\; A x_{\\lambda} - b\n\\;=\\; \\sigma x_{\\lambda} - b\n\\;=\\; \\left( \\frac{\\sigma^{2}}{\\sigma^{2} + \\lambda^{2}} - 1 \\right) b\n\\;=\\; - \\frac{\\lambda^{2}}{\\sigma^{2} + \\lambda^{2}} \\, b.\n$$\n因此，残差范数和解范数分别为\n$$\n\\rho(\\lambda) \\;=\\; \\|r_{\\lambda}\\|_{2}\n\\;=\\; \\frac{\\lambda^{2}}{\\sigma^{2} + \\lambda^{2}} \\, \\|b\\|_{2},\n\\qquad\n\\eta(\\lambda) \\;=\\; \\|x_{\\lambda}\\|_{2}\n\\;=\\; \\frac{\\sigma}{\\sigma^{2} + \\lambda^{2}} \\, \\|b\\|_{2}.\n$$\n在对数-对数坐标中定义 L 曲线\n$$\ns(\\lambda) \\;=\\; \\ln \\rho(\\lambda)\n\\;=\\; \\ln \\|b\\|_{2} + \\ln \\lambda^{2} - \\ln (\\sigma^{2} + \\lambda^{2}),\n\\qquad\nt(\\lambda) \\;=\\; \\ln \\eta(\\lambda)\n\\;=\\; \\ln \\|b\\|_{2} + \\ln \\sigma - \\ln (\\sigma^{2} + \\lambda^{2}).\n$$\n接下来，计算曲率所需的导数。我们有\n$$\ns'(\\lambda) \\;=\\; \\frac{2}{\\lambda} - \\frac{2\\lambda}{\\sigma^{2} + \\lambda^{2}}\n\\;=\\; \\frac{2 \\sigma^{2}}{\\lambda (\\sigma^{2} + \\lambda^{2})},\n$$\n$$\nt'(\\lambda) \\;=\\; - \\frac{2\\lambda}{\\sigma^{2} + \\lambda^{2}}.\n$$\n再次求导得到\n$$\ns''(\\lambda) \\;=\\; - \\frac{2}{\\lambda^{2}} - \\frac{2(\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{2}},\n\\qquad\nt''(\\lambda) \\;=\\; - \\frac{2(\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{2}}.\n$$\n对于平面参数曲线 $(x(\\lambda), y(\\lambda))$，作为参数 $\\lambda$ 的函数的曲率是\n$$\n\\kappa(\\lambda) \\;=\\;\n\\frac{\\left| x'(\\lambda) y''(\\lambda) - y'(\\lambda) x''(\\lambda) \\right|}\n{\\left( x'(\\lambda)^{2} + y'(\\lambda)^{2} \\right)^{3/2}}.\n$$\n将此应用于 $x(\\lambda) = s(\\lambda)$ 和 $y(\\lambda) = t(\\lambda)$，我们计算分子\n$$\nN(\\lambda) \\;=\\; s'(\\lambda) t''(\\lambda) - t'(\\lambda) s''(\\lambda).\n$$\n使用上述表达式，\n\\begin{align*}\ns'(\\lambda) t''(\\lambda)\n=\\; \\frac{2 \\sigma^{2}}{\\lambda (\\sigma^{2} + \\lambda^{2})} \\cdot \\left( - \\frac{2(\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{2}} \\right)\n\\;=\\; - \\frac{4 \\sigma^{2} (\\sigma^{2} - \\lambda^{2})}{\\lambda (\\sigma^{2} + \\lambda^{2})^{3}}, \\\\\nt'(\\lambda) s''(\\lambda)\n=\\; \\left( - \\frac{2 \\lambda}{\\sigma^{2} + \\lambda^{2}} \\right) \\left( - \\frac{2}{\\lambda^{2}} - \\frac{2(\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{2}} \\right) \\\\\n=\\; \\frac{4}{\\lambda (\\sigma^{2} + \\lambda^{2})} + \\frac{4 \\lambda (\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{3}}.\n\\end{align*}\n相减得到\n\\begin{align*}\nN(\\lambda)\n=\\; - \\frac{4 \\sigma^{2} (\\sigma^{2} - \\lambda^{2})}{\\lambda (\\sigma^{2} + \\lambda^{2})^{3}}\n\\;-\\; \\frac{4}{\\lambda (\\sigma^{2} + \\lambda^{2})}\n\\;-\\; \\frac{4 \\lambda (\\sigma^{2} - \\lambda^{2})}{(\\sigma^{2} + \\lambda^{2})^{3}} \\\\\n=\\; - \\frac{8 \\sigma^{2}}{\\lambda (\\sigma^{2} + \\lambda^{2})^{2}}.\n\\end{align*}\n因此 $\\left|N(\\lambda)\\right| = \\dfrac{8 \\sigma^{2}}{\\lambda (\\sigma^{2} + \\lambda^{2})^{2}}$。\n\n分母是\n\\begin{align*}\nD(\\lambda)\n=\\; \\left( s'(\\lambda)^{2} + t'(\\lambda)^{2} \\right)^{3/2}\n\\;=\\; \\left( \\frac{4 \\sigma^{4}}{\\lambda^{2} (\\sigma^{2} + \\lambda^{2})^{2}} + \\frac{4 \\lambda^{2}}{(\\sigma^{2} + \\lambda^{2})^{2}} \\right)^{3/2} \\\\\n=\\; \\left( \\frac{4}{(\\sigma^{2} + \\lambda^{2})^{2}} \\left( \\frac{\\sigma^{4}}{\\lambda^{2}} + \\lambda^{2} \\right) \\right)^{3/2}\n\\;=\\; \\frac{8}{(\\sigma^{2} + \\lambda^{2})^{3}} \\left( \\frac{\\sigma^{4}}{\\lambda^{2}} + \\lambda^{2} \\right)^{3/2}.\n\\end{align*}\n因此，曲率是\n\\begin{align*}\n\\kappa(\\lambda)\n=\\; \\frac{\\left|N(\\lambda)\\right|}{D(\\lambda)}\n\\;=\\; \\frac{\\dfrac{8 \\sigma^{2}}{\\lambda (\\sigma^{2} + \\lambda^{2})^{2}}}{\\dfrac{8}{(\\sigma^{2} + \\lambda^{2})^{3}} \\left( \\dfrac{\\sigma^{4}}{\\lambda^{2}} + \\lambda^{2} \\right)^{3/2}} \\\\\n=\\; \\frac{\\sigma^{2} (\\sigma^{2} + \\lambda^{2})}{\\lambda \\left( \\dfrac{\\sigma^{4}}{\\lambda^{2}} + \\lambda^{2} \\right)^{3/2}}\n\\;=\\; \\frac{\\sigma^{2} (\\sigma^{2} + \\lambda^{2}) \\lambda^{2}}{(\\sigma^{4} + \\lambda^{4})^{3/2}}.\n\\end{align*}\n引入无量纲变量 $y := \\lambda^{2} / \\sigma^{2}$（其中 $y > 0$）。那么\n$$\n\\kappa(\\lambda) \\;=\\; \\frac{y(1 + y)}{(1 + y^{2})^{3/2}}.\n$$\n为了在 $\\lambda > 0$ 的范围内最大化 $\\kappa(\\lambda)$，我们在 $y > 0$ 的范围内最大化 $g(y) := \\dfrac{y(1 + y)}{(1 + y^{2})^{3/2}}$。求导，\n\\begin{align*}\ng'(y)\n=\\; (1 + 2 y) (1 + y^{2})^{-3/2} - 3 y (y + y^{2}) (1 + y^{2})^{-5/2} \\\\\n=\\; (1 + y^{2})^{-5/2} \\left[ (1 + 2 y)(1 + y^{2}) - 3 y (y + y^{2}) \\right] \\\\\n=\\; (1 + y^{2})^{-5/2} \\left( 1 + 2 y - 2 y^{2} - y^{3} \\right).\n\\end{align*}\n令 $g'(y) = 0$ 得到三次方程\n$$\n1 + 2 y - 2 y^{2} - y^{3} \\;=\\; 0,\n$$\n等价于\n$$\ny^{3} + 2 y^{2} - 2 y - 1 \\;=\\; 0.\n$$\n一个根是 $y = 1$，而 $y^{2} + 3 y + 1 = 0$ 的其余根为负。由于 $y > 0$，唯一的临界点是 $y = 1$。当 $y \\to 0^{+}$ 时，$g(y) \\sim y \\to 0$，而当 $y \\to \\infty$ 时，$g(y) \\sim y^{2}/y^{3} = 1/y \\to 0$，所以 $y = 1$ 是全局最大值点。因此，\n$$\n\\lambda_{\\star}^{2} / \\sigma^{2} \\;=\\; 1\n\\quad\\Longrightarrow\\quad\n\\lambda_{\\star} \\;=\\; \\sigma,\n\\qquad\n\\kappa_{\\max} \\;=\\; g(1) \\;=\\; \\frac{2}{(1 + 1)^{3/2}} \\;=\\; \\frac{1}{\\sqrt{2}}.\n$$\n曲率 $\\kappa(\\lambda)$ 的上界为 $\\dfrac{1}{\\sqrt{2}}$ 并在 $\\lambda = \\sigma$ 处达到其最大值，但这个最大值是缓和且宽泛的，而不是尖锐的峰值。因此，在这种奇异值平坦的情况下，L 曲线没有表现出明显的拐角，这导致使用 L 曲线准则选择 $\\lambda$ 时会产生歧义：不存在一个在几何上突出的、有明显区别的参数值。", "answer": "$$\\boxed{\\begin{pmatrix}\\sigma & \\frac{1}{\\sqrt{2}}\\end{pmatrix}}$$", "id": "3554649"}, {"introduction": "寻找L曲线的拐角需要计算曲率，而曲率的计算又依赖于从离散采样且通常带有噪声的数据中获取的导数。这个过程本质上是一个不适定的数值微分问题。本练习挑战你选择最佳的数值策略，以在离散化带来的截断误差与噪声放大效应之间取得平衡，这是计算科学中一项常见的核心任务。[@problem_id:3554613]", "problem": "考虑带 Tikhonov 正则化的线性反问题：对于给定的矩阵 $A \\in \\mathbb{R}^{m \\times n}$、数据向量 $b \\in \\mathbb{R}^{m}$ 和正则化矩阵 $L \\in \\mathbb{R}^{p \\times n}$，Tikhonov 解 $x_{\\lambda}$ 通过在 $x \\in \\mathbb{R}^{n}$ 上最小化 $\\|A x - b\\|_{2}^{2} + \\lambda^{2} \\|L x\\|_{2}^{2}$ 来定义，其中 $\\lambda > 0$ 是正则化参数。定义残差范数 $\\rho(\\lambda) = \\|A x_{\\lambda} - b\\|_{2}$ 和半范数 $\\eta(\\lambda) = \\|L x_{\\lambda}\\|_{2}$。L-curve 是 $(\\log \\rho(\\lambda), \\log \\eta(\\lambda))$ 相对于 $\\lambda$ 在对数坐标轴上的参数图，识别其拐角通常需要对 $\\log \\rho(\\lambda)$ 和 $\\log \\eta(\\lambda)$ 关于 $\\log \\lambda$ 的一阶和二阶导数进行稳健估计。\n\n假设以下设置基于标准的数值线性代数事实。首先，映射 $\\lambda \\mapsto \\rho(\\lambda)$ 和 $\\lambda \\mapsto \\eta(\\lambda)$ 是光滑且单调的，并且当用广义奇异值分解表示时，它们成为关于 $\\lambda^{2}$ 的光滑有理函数，这意味着 $\\xi \\mapsto \\log \\rho(e^{\\xi})$ 和 $\\xi \\mapsto \\log \\eta(e^{\\xi})$ 是关于 $\\xi = \\log \\lambda$ 的光滑函数。其次，假设计算出的 $\\rho(\\lambda)$ 和 $\\eta(\\lambda)$ 的值受到数据和求解误差引起的微小乘性扰动的影响：对于采样的 $\\lambda_{i}$，观测值满足 $\\rho_{\\mathrm{obs}}(\\lambda_{i}) = \\rho(\\lambda_{i}) (1 + \\delta_{i}^{\\rho})$ 和 $\\eta_{\\mathrm{obs}}(\\lambda_{i}) = \\eta(\\lambda_{i}) (1 + \\delta_{i}^{\\eta})$，其中 $|\\delta_{i}^{\\rho}| \\ll 1$ 和 $|\\delta_{i}^{\\eta}| \\ll 1$ 可能随 $i$ 变化。因此，对数转换后的观测值 $r_{i}^{\\mathrm{obs}} = \\log \\rho_{\\mathrm{obs}}(\\lambda_{i})$ 和 $e_{i}^{\\mathrm{obs}} = \\log \\eta_{\\mathrm{obs}}(\\lambda_{i})$ 满足 $r_{i}^{\\mathrm{obs}} = \\log \\rho(\\lambda_{i}) + \\varepsilon_{i}^{r}$ 和 $e_{i}^{\\mathrm{obs}} = \\log \\eta(\\lambda_{i}) + \\varepsilon_{i}^{e}$，其中加性误差 $\\varepsilon_{i}^{r} \\approx \\delta_{i}^{\\rho}$ 和 $\\varepsilon_{i}^{e} \\approx \\delta_{i}^{\\eta}$。众所周知，对含噪数据进行微分会放大噪声：一阶导数的有限差分估计大约将噪声放大 $1/h$ 倍，二阶导数则放大 $1/h^{2}$ 倍，其中 $h$ 是自变量的采样步长。\n\n您的目标是为 $\\lambda$ 选择一个采样网格，并为 $(\\log \\rho, \\log \\eta)$ 选择一个平滑策略，以产生关于 $\\xi = \\log \\lambda$ 的稳健的一阶和二阶导数估计。特别地，您必须在离散化带来的截断误差与微分带来的噪声放大之间取得平衡。您可以假设正则化参数的范围跨越 $d$ 个数量级，即 $\\lambda_{\\max}/\\lambda_{\\min} = 10^{d}$，其中 $d$ 在 $3$ 和 $8$ 之间，并且计算预算允许进行 $50$ 到 $200$ 次求解。\n\n哪个选项为 $\\lambda$ 提供了一个科学上合理的对数间隔网格选择，以及一个在估计 $(\\log \\rho(\\lambda), \\log \\eta(\\lambda))$ 作为 $\\xi = \\log \\lambda$ 的函数的一阶和二阶导数时，能最好地控制截断误差和噪声放大的平滑策略？\n\nA. 在对数间隔网格 $\\{\\lambda_{i}\\}_{i=1}^{n}$ 上对 $\\lambda$ 进行采样，该网格在 $\\xi = \\log \\lambda$ 中具有恒定步长 $h$，每个数量级选择大约 $20$ 到 $30$ 个点（因此 $h \\approx \\log 10 / 20$ 到 $\\log 10 / 30$），并分别对 $(\\xi_{i}, r_{i}^{\\mathrm{obs}})$ 和 $(\\xi_{i}, e_{i}^{\\mathrm{obs}})$ 拟合加权三次平滑样条 $s_{r}(\\xi)$ 和 $s_{e}(\\xi)$。使用 $\\varepsilon_{i}^{r}$ 和 $\\varepsilon_{i}^{e}$ 方差的估计值 $\\sigma_{i}^{2}$ 设置权重 $w_{i} \\propto 1/\\sigma_{i}^{2}$，并通过广义交叉验证 (GCV) 选择平滑参数。在内部点上评估一阶和二阶导数 $s_{r}^{\\prime}(\\xi)$、$s_{r}^{\\prime \\prime}(\\xi)$、$s_{e}^{\\prime}(\\xi)$ 和 $s_{e}^{\\prime \\prime}(\\xi)$，并舍弃一些边界样本以减轻端点效应。\n\nB. 在原始 $\\lambda$ 尺度上使用 $n$ 个点对 $\\lambda$ 进行线性间隔采样，并使用二阶中心有限差分计算 $r_{i}^{\\mathrm{obs}}$ 和 $e_{i}^{\\mathrm{obs}}$ 的一阶和二阶导数，不进行任何平滑。这确保了 $\\lambda$ 中的均匀截断误差并避免了样条偏差。\n\nC. 在一个非常密集的对数间隔网格上用数千个点对 $\\lambda$ 进行采样（因此 $\\xi$ 中的 $h$ 极小），并拟合通过所有 $(\\xi_{i}, r_{i}^{\\mathrm{obs}})$ 和 $(\\xi_{i}, e_{i}^{\\mathrm{obs}})$ 的插值自然三次样条以保留所有特征。计算插值函数的导数以获得一阶和二阶导数。\n\nD. 在对数间隔网格上用少量点对 $\\lambda$ 进行采样（例如，在 $d \\approx 5$ 个数量级上取 $n \\approx 30$ 个点），并通过最小二乘法将一个高阶全局多项式（阶数接近 $n-1$）拟合到 $r_{i}^{\\mathrm{obs}}$ 和 $e_{i}^{\\mathrm{obs}}$。对该多项式进行解析微分以获得一阶和二阶导数。\n\nE. 在对数间隔网格上以每个数量级 $20$ 到 $30$ 个点的密度对 $\\lambda$ 进行采样，但在原始尺度上进行平滑，即通过 GCV 选择的平滑参数将三次平滑样条拟合到 $(\\lambda_{i}, \\rho_{\\mathrm{obs}}(\\lambda_{i}))$ 和 $(\\lambda_{i}, \\eta_{\\mathrm{obs}}(\\lambda_{i}))$，然后通过取对数进行变换，并通过链式法则进行微分，以获得关于 $\\xi = \\log \\lambda$ 的导数。\n\n在所述假设下，选择最合适的选项，并根据截断误差的缩放、微分下的噪声放大以及平滑模型对观测值误差结构的适用性来证明您的选择。", "solution": "在进行求解之前，首先对问题陈述进行验证，以确保其科学上可靠、适定且完整。\n\n### 步骤 1：提取已知条件\n- **问题表述**：在 $x \\in \\mathbb{R}^{n}$ 上最小化 $\\|A x - b\\|_{2}^{2} + \\lambda^{2} \\|L x\\|_{2}^{2}$ 以找到 Tikhonov 解 $x_{\\lambda}$。\n- **给定数量**：矩阵 $A \\in \\mathbb{R}^{m \\times n}$、数据向量 $b \\in \\mathbb{R}^{m}$、正则化矩阵 $L \\in \\mathbb{R}^{p \\times n}$ 和正则化参数 $\\lambda > 0$。\n- **定义的函数**：残差范数 $\\rho(\\lambda) = \\|A x_{\\lambda} - b\\|_{2}$ 和解的半范数 $\\eta(\\lambda) = \\|L x_{\\lambda}\\|_{2}$。\n- **L-curve**：$(\\log \\rho(\\lambda), \\log \\eta(\\lambda))$ 在对数坐标轴上的参数图。\n- **目标**：找到 L-curve 的拐角，这需要对 $\\log \\rho(\\lambda)$ 和 $\\log \\eta(\\lambda)$ 关于 $\\xi = \\log \\lambda$ 的一阶和二阶导数进行稳健估计。\n- **假设**：\n    1. 函数 $\\rho(\\lambda)$ 和 $\\eta(\\lambda)$ 是光滑且单调的。用广义奇异值分解 (GSVD) 表示，它们是关于 $\\lambda^{2}$ 的光滑有理函数。因此，$r(\\xi) = \\log \\rho(e^{\\xi})$ 和 $e(\\xi) = \\log \\eta(e^{\\xi})$ 是关于 $\\xi = \\log \\lambda$ 的光滑函数。\n    2. 观测值受到微小的乘性扰动：$\\rho_{\\mathrm{obs}}(\\lambda_{i}) = \\rho(\\lambda_{i}) (1 + \\delta_{i}^{\\rho})$ 和 $\\eta_{\\mathrm{obs}}(\\lambda_{i}) = \\eta(\\lambda_{i}) (1 + \\delta_{i}^{\\eta})$，其中 $|\\delta_{i}^{\\rho}| \\ll 1$ 和 $|\\delta_{i}^{\\eta}| \\ll 1$。\n    3. 在对数尺度下，这对应于加性误差：$r_{i}^{\\mathrm{obs}} = \\log \\rho(\\lambda_{i}) + \\varepsilon_{i}^{r}$ 和 $e_{i}^{\\mathrm{obs}} = \\log \\eta(\\lambda_{i}) + \\varepsilon_{i}^{e}$，其中 $\\varepsilon_{i}^{r} \\approx \\delta_{i}^{\\rho}$ 和 $\\varepsilon_{i}^{e} \\approx \\delta_{i}^{\\eta}$。\n    4. 对步长为 $h$ 的含噪数据进行数值微分，会将一阶导数的噪声放大约 $1/h$ 倍，二阶导数的噪声放大约 $1/h^{2}$ 倍。\n- **约束条件**：\n    1. $\\lambda$ 的范围跨越 $d$ 个数量级，即 $\\lambda_{\\max}/\\lambda_{\\min} = 10^{d}$，其中 $d$ 在 $3$ 和 $8$ 之间。\n    2. 计算预算允许进行 $50$ 到 $200$ 次求解，这对应于样本点的数量。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题陈述是数值线性代数和反问题领域中一个表述良好的问题。\n- **科学依据**：关于 Tikhonov 正则化、L-curve、$\\rho(\\lambda)$ 和 $\\eta(\\lambda)$ 的性质、乘性到加性噪声模型的转换，以及数值微分的不适定性质的描述，都是数值分析中标准且正确的概念。\n- **适定性**：该问题要求在一组给定的选项中选择最合适的数值策略，这是评估对数值权衡理解的标准方法。目标定义明确：平衡截断误差和噪声放大，以获得稳健的导数估计。\n- **客观性**：语言精确且技术性强。所有术语在该学科内都是标准的。\n- **完整性和一致性**：问题提供了所有必要信息，包括数学设置、噪声模型、目标和实际约束（计算预算、参数范围）。信息内部一致。\n\n### 步骤 3：结论和行动\n问题是有效的。它在科学上是可靠的、适定的，并包含足够的信息来回答。将继续进行求解过程。\n\n### 推导与分析\n问题的核心是设计一种稳健的数值策略来对含噪数据进行微分。关键的权衡在于截断误差（随采样步长 $h$ 减小而减小）和噪声放大（随 $h$ 减小而增大）之间。任务是从含噪样本 $(r_{i}^{\\mathrm{obs}}, e_{i}^{\\mathrm{obs}})$ 中估计函数 $r(\\xi) = \\log \\rho(e^\\xi)$ 和 $e(\\xi) = \\log \\eta(e^\\xi)$ 的一阶和二阶导数。\n\n1.  **采样策略**：需要计算关于 $\\xi = \\log \\lambda$ 的导数。为了简化数值方法（如有限差分或样条拟合）并使截断误差和噪声放大的分析变得直接，非常理想的做法是在自变量 $\\xi$ 的均匀网格上采样数据。一个步长恒为 $h = \\xi_{i+1} - \\xi_i$ 的均匀网格 $\\{\\xi_i\\}$ 对应于 $\\lambda$ 的对数间隔网格，其中 $\\lambda_{i+1}/\\lambda_i$ 是常数。$\\lambda$ 上的线性网格会导致 $\\xi$ 上的高度非均匀网格，使数值过程复杂化。在 $3-8$ 个数量级的 $\\lambda$ 范围内 $50-200$ 个点的指定预算表明，采样密度大约为每数量级 $50/8 \\approx 6$ 到 $200/3 \\approx 67$ 个点，因此选择每数量级 $20-30$ 个点是一个合理的折中方案。\n\n2.  **噪声模型与平滑**：问题陈述指出，噪声在 $\\rho$ 和 $\\eta$ 上是乘性的，在其对数 $r = \\log \\rho$ 和 $e = \\log \\eta$ 上则变为加性。标准的数据平滑技术，如平滑样条，是为处理加性噪声而设计的。因此，任何平滑都应在对数转换后的数据上进行，即在数据对 $(\\xi_i, r_{i}^{\\mathrm{obs}})$ 和 $(\\xi_i, e_{i}^{\\mathrm{obs}})$ 上进行。在原始的 $(\\lambda, \\rho)$ 尺度上进行平滑对于给定的噪声模型在统计上是不合适的。\n\n3.  **微分策略**：使用有限差分直接对含噪数据进行微分是一个不适定问题，因为它会严重放大高频噪声。标准且稳健的方法是首先将一个平滑函数拟合到数据上，以滤除大部分噪声，然后对这个平滑函数进行解析微分。三次平滑样条是实现此目的的绝佳选择。对于数据集 $(\\xi_i, y_i)$，三次平滑样条 $s(\\xi)$ 是罚化平方和的唯一最小化子：\n    $$ \\sum_{i=1}^{n} w_i (y_i - s(\\xi_i))^2 + \\alpha \\int (s''(\\xi))^2 d\\xi $$\n    第一项强制要求对数据保真，而第二项则惩罚不光滑性。平滑参数 $\\alpha > 0$ 控制了这种权衡。选择 $\\alpha$ 的一种可靠、数据驱动的方法是广义交叉验证 (GCV)。如果噪声方差在样本间不是恒定的，使用与误差项 ($\\varepsilon_i$) 方差成反比的权重 $w_i$ 是统计上的最优方法。\n\n基于这些原则，我们来评估给出的选项。\n\n### 逐项分析\n\n**A. 在对数间隔网格 $\\{\\lambda_{i}\\}_{i=1}^{n}$ 上对 $\\lambda$ 进行采样，该网格在 $\\xi = \\log \\lambda$ 中具有恒定步长 $h$，每个数量级选择大约 $20$ 到 $30$ 个点（因此 $h \\approx \\log 10 / 20$ 到 $\\log 10 / 30$），并分别对 $(\\xi_{i}, r_{i}^{\\mathrm{obs}})$ 和 $(\\xi_{i}, e_{i}^{\\mathrm{obs}})$ 拟合加权三次平滑样条 $s_{r}(\\xi)$ 和 $s_{e}(\\xi)$。使用 $\\varepsilon_{i}^{r}$ 和 $\\varepsilon_{i}^{e}$ 方差的估计值 $\\sigma_{i}^{2}$ 设置权重 $w_{i} \\propto 1/\\sigma_{i}^{2}$，并通过广义交叉验证 (GCV) 选择平滑参数。在内部点上评估一阶和二阶导数 $s_{r}^{\\prime}(\\xi)$、$s_{r}^{\\prime \\prime}(\\xi)$、$s_{e}^{\\prime}(\\xi)$ 和 $s_{e}^{\\prime \\prime}(\\xi)$，并舍弃一些边界样本以减轻端点效应。**\n该选项提出了一个全面且科学上可靠的策略。\n- 网格在 $\\lambda$ 上是对数的，在正确的自变量 $\\xi$ 上是均匀的。\n- 采样密度合理，且与预算一致。\n- 使用三次平滑样条是正则化微分问题的适当技术。\n- 平滑在对数-对数域中进行，这对于该域中的加性噪声模型是正确的。\n- 使用 GCV 选择平滑参数和针对非恒定方差使用权重代表了最佳实践。\n- 对得到的样条进行微分是获得稳健导数估计的正确方法。\n- 承认并减轻边界效应表明对该方法的实际局限性有透彻的理解。\n因此，这个选项是正确解决此类问题的教科书式范例。\n\n**结论：正确**\n\n**B. 在原始 $\\lambda$ 尺度上使用 $n$ 个点对 $\\lambda$ 进行线性间隔采样，并使用二阶中心有限差分计算 $r_{i}^{\\mathrm{obs}}$ 和 $e_{i}^{\\mathrm{obs}}$ 的一阶和二阶导数，不进行任何平滑。这确保了 $\\lambda$ 中的均匀截断误差并避免了样条偏差。**\n该选项有多个严重缺陷。\n- $\\lambda$ 上的线性网格不合适，因为它在 $\\xi = \\log \\lambda$ 中创建了一个高度非均匀的网格，使关于 $\\xi$ 的微分复杂化。\n- 它没有提出平滑方法，而是直接对含噪数据应用有限差分。如问题中所述以及在数值分析中所知，这将灾难性地放大噪声，使导数估计变得无用，特别是对于二阶导数。\n- 其理由是有缺陷的：“$\\lambda$ 中的均匀截断误差”是无关紧要的，“避免样条偏差”是一个糟糕的权衡，因为它用巨大的、不可控的方差替换了一个小的、可控的偏差。\n\n**结论：不正确**\n\n**C. 在一个非常密集的对数间隔网格上用数千个点对 $\\lambda$ 进行采样（因此 $\\xi$ 中的 $h$ 极小），并拟合通过所有 $(\\xi_{i}, r_{i}^{\\mathrm{obs}})$ 和 $(\\xi_{i}, e_{i}^{\\mathrm{obs}})$ 的插值自然三次样条以保留所有特征。计算插值函数的导数以获得一阶和二阶导数。**\n该选项在核心逻辑和可行性上都有缺陷。\n- “数千个点”的采样密度违反了声明的 $50-200$ 次求解的计算预算。\n- 它使用*插值*样条，其设计目的是穿过每个数据点。对于含噪数据，这意味着样条会跟随噪声，导致点之间出现高度振荡的行为。这种样条的导数将极其嘈杂，不能代表真实函数的导数。目标是*平滑*掉噪声，而不是插值噪声。\n\n**结论：不正确**\n\n**D. 在对数间隔网格上用少量点对 $\\lambda$ 进行采样（例如，在 $d \\approx 5$ 个数量级上取 $n \\approx 30$ 个点），并通过最小二乘法将一个高阶全局多项式（阶数接近 $n-1$）拟合到 $r_{i}^{\\mathrm{obs}}$ 和 $e_{i}^{\\mathrm{obs}}$。对该多项式进行解析微分以获得一阶和二阶导数。**\n该选项提出了一个在数值上很差的平滑器选择。\n- 虽然网格是合适的，但选择高阶全局多项式来拟合含噪数据是出了名的问题。此类多项式容易出现剧烈振荡（Runge 现象），尤其是在区间端点附近，并且不太可能为底层的平滑函数提供良好的全局近似。它们倾向于过拟合数据。像样条这样的局部近似方法对于此类任务要稳定和稳健得多。对于 $n$ 个点，阶数接近 $n-1$ 的多项式会近似一个插值多项式，这不适合含噪数据。\n\n**结论：不正确**\n\n**E. 在对数间隔网格上以每个数量级 $20$ 到 $30$ 个点的密度对 $\\lambda$ 进行采样，但在原始尺度上进行平滑，即通过 GCV 选择的平滑参数将三次平滑样条拟合到 $(\\lambda_{i}, \\rho_{\\mathrm{obs}}(\\lambda_{i}))$ 和 $(\\lambda_{i}, \\eta_{\\mathrm{obs}}(\\lambda_{i}))$，然后通过取对数进行变换，并通过链式法则进行微分，以获得关于 $\\xi = \\log \\lambda$ 的导数。**\n该选项在错误的域中执行了关键的平滑步骤。\n- 噪声模型在 $(\\rho, \\eta)$ 上是乘性的，即误差方差不是恒定的，而是取决于函数的大小。标准的平滑样条旨在最小化平方误差和，是为加性、恒定方差的噪声模型设计的。在原始尺度上应用它们在统计上是次优的，可能导致拟合效果不佳，因为算法会不自觉地更努力地去拟合函数值较大的点。正确的程序是将数据转换到噪声是加性且具有更简单统计特性的域——在本例中是对数-对数域——然后进行平滑。\n\n**结论：不正确**\n\n总之，选项 A 是唯一一个结合了正确的采样策略、适当的噪声模型、稳健的平滑技术和正确的数值微分程序的选择，反映了解决此问题的最先进方法。", "answer": "$$\\boxed{A}$$", "id": "3554613"}, {"introduction": "L曲线提供了一种强大的启发式方法，但它也可能被特定的噪声结构所“欺骗”，导致选出的正则化参数并非最优。这项综合性的编程挑战让你不仅能从头开始实现L曲线方法，还将设计并编码一个诊断工具。这个工具能够识别出由于对抗性噪声的存在，L曲线的拐角何时可能指向一个劣质解，从而提升参数选择的可靠性。[@problem_id:3554612]", "problem": "考虑一个带有 Tikhonov 正则化的线性反问题。设 $A \\in \\mathbb{R}^{m \\times n}$，其奇异值分解为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 的对角线元素为 $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_{\\min(m,n)} > 0$。给定数据 $b \\in \\mathbb{R}^{m}$，对于参数 $\\lambda > 0$ 的 Tikhonov 正则化解定义为 $\\|A x - b\\|_2^2 + \\lambda^2 \\|x\\|_2^2$ 的最小化子，记作 $x_{\\lambda} \\in \\mathbb{R}^{n}$。L-曲线是当 $\\lambda$ 变化时 $(\\log \\|A x_{\\lambda} - b\\|_2, \\log \\|x_{\\lambda}\\|_2)$ 的参数图，一个常用的参数选择方法是选取此曲线上曲率最大的点。你的任务是研究能够产生误导性 L-曲线拐角的对抗性噪声，并基于 $x_{\\lambda}$ 与主导右奇异子空间之间的主角分析设计一种诊断方法。\n\n从数值线性代数的核心定义出发，完成以下任务。\n\n1. 使用奇异值分解为基础，将 Tikhonov 解表示为滤波器因子形式。设 $b = \\sum_{i} \\beta_i u_i$，其中 $\\beta_i = u_i^{\\top} b$，并定义滤波器因子 $\\phi_i(\\lambda) = \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda^2}$。推导表达式\n$$\nx_{\\lambda} = \\sum_{i=1}^{\\min(m,n)} \\phi_i(\\lambda) \\beta_i v_i,\n$$\n并证明残差 $r_{\\lambda} = A x_{\\lambda} - b$ 在左奇异向量基下的系数为\n$$\n\\gamma_i(\\lambda) = \\beta_i \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2}\n$$\n，即 $r_{\\lambda} = \\sum_i \\gamma_i(\\lambda) u_i$。\n\n2. 定义 L-曲线的参数化 $X(\\lambda) = \\log \\|r_{\\lambda}\\|_2$ 和 $Y(\\lambda) = \\log \\|x_{\\lambda}\\|_2$。将曲线 $\\lambda \\mapsto (X(\\lambda), Y(\\lambda))$ 视为平面曲线，使用标准的平面曲率公式，推导该参数曲线关于平滑参数 $t$ 的曲率。如果通过 $t = \\log \\lambda$ 进行重新参数化，那么对于 $x(t) = X(\\mathrm{e}^{t})$ 和 $y(t) = Y(\\mathrm{e}^{t})$，证明可以使用数值微分计算出一个数值稳定的曲率\n$$\n\\kappa(t) = \\frac{|x'(t) y''(t) - y'(t) x''(t)|}{\\left(x'(t)^2 + y'(t)^2\\right)^{3/2}},\n$$\n。解释为什么在不适定问题中，通过 $t = \\log \\lambda$ 重新参数化可以提高数值稳定性。\n\n3. 考虑与主导左奇异向量对齐的对抗性噪声。假设数据为 $b = A x_{\\mathrm{true}} + e$，其中 $e = \\eta \\|A x_{\\mathrm{true}}\\|_2 u_1$ (对于某个 $\\eta > 0$)，即与第一个左奇异向量 $u_1$ 对齐。使用 $\\beta_i$ 和 $\\gamma_i(\\lambda)$ 的表达式，定性地论证为什么这种对齐方式会产生一个 L-曲线，其拐角所在的参数 $\\lambda$ 会强调主导奇异子空间，并可能偏离重建 $x_{\\mathrm{true}}$ 的最优权衡。\n\n4. 提出一种基于 L-曲线拐角 $\\lambda_{\\ast}$ 处的解 $x_{\\lambda_{\\ast}}$ 与主导右奇异子空间 $\\mathcal{V}_k = \\mathrm{span}\\{v_1,\\dots,v_k\\}$ 之间主角分析的诊断方法。向量 $x$ 与子空间 $\\mathcal{V}_k$ 之间的最小主角 $\\theta$ 由\n$$\n\\cos \\theta = \\frac{\\|P_{\\mathcal{V}_k} x\\|_2}{\\|x\\|_2},\n$$\n表征，其中 $P_{\\mathcal{V}_k}$ 是到 $\\mathcal{V}_k$ 上的正交投影算子。此外，定义一个数据主导性度量\n$$\nf_{\\mathrm{top}} = \\frac{\\sum_{i=1}^{k} \\beta_i^2}{\\sum_{i=1}^{\\min(m,n)} \\beta_i^2},\n$$\n用于衡量数据能量在前 $k$ 个左奇异方向上的分数。提出一个规则，当 $\\cos \\theta$ 接近 1 且 $f_{\\mathrm{top}}$ 很大时，标记可能存在误导性的 L-曲线拐角，并指定适用于数值实现的量化阈值。所有计算出的角度（若有）必须以弧度为单位。\n\n5. 实现一个程序，该程序构建综合问题，通过数值曲率最大化计算 L-曲线拐角，评估所提出的诊断方法，并为每个测试用例输出一个布尔值，指示该 L-曲线拐角是否被诊断方法标记为可能具有误导性。使用以下测试套件，该套件旨在覆盖典型和对抗性条件：\n\n- 矩阵构建：设置 $m = n = 60$。令奇异值从 $10^0$ 对数衰减到 $10^{-6}$，即 $\\sigma_i = 10^{-\\alpha_i}$，其中 $\\alpha_i$ 在 $0$ 到 $6$ 之间线性间隔，对于 $i = 1,\\dots,60$。将 $U$ 和 $V$ 构建为独立的随机正交矩阵，它们通过对具有固定随机种子的高斯矩阵进行 $\\mathrm{QR}$ 分解获得。设置 $A = U \\Sigma V^{\\top}$。\n- 真值构建：对于 $i \\le \\lfloor 0.4 n \\rfloor$ 设置 $c_i = 0$，对于 $i > \\lfloor 0.4 n \\rfloor$ 设置 $c_i = 1/(i - \\lfloor 0.4 n \\rfloor)$。将 $c$ 归一化为单位 $\\ell_2$-范数，并设置 $x_{\\mathrm{true}} = V c$。定义 $b_{\\mathrm{clean}} = A x_{\\mathrm{true}}$。\n- L-曲线计算：在 $[10^{-10}, 10^{2}]$ 范围内对数间隔的 $\\lambda$ 值网格上评估 L-曲线。使用参数 $t = \\log \\lambda$ 和有限差分计算曲率。选择使曲率最大化的 $\\lambda$ 作为拐角 $\\lambda_{\\ast}$。\n- 诊断细节：对于主导子空间 $\\mathcal{V}_k$ 和 $\\mathcal{U}_k$ 选择 $k = 3$，使用阈值 $\\cos \\theta \\ge 0.995$ 和 $f_{\\mathrm{top}} \\ge 0.2$ 来标记可疑的 L-曲线拐角。\n- 噪声模型和水平（使用固定随机种子以保证可复现性）：\n    1. 良性白噪声：$e = \\delta \\|b_{\\mathrm{clean}}\\|_2 z$，其中 $z \\sim \\mathcal{N}(0, I_m)$ 被归一化为单位范数，$\\delta = 0.05$。\n    2. 对抗性主导方向噪声：$e = \\delta \\|b_{\\mathrm{clean}}\\|_2 u_1$，$\\delta = 0.5$。\n    3. 对抗性末尾方向噪声：$e = \\delta \\|b_{\\mathrm{clean}}\\|_2 u_{n}$，$\\delta = 0.5$。\n    4. 近无噪声情况：白噪声，$\\delta = 10^{-8}$，如情况1。\n\n对于每种情况，令 $b = b_{\\mathrm{clean}} + e$，计算 L-曲线拐角 $\\lambda_{\\ast}$，然后在 $x_{\\lambda_{\\ast}}$ 和相应的 $\\beta_i = u_i^{\\top} b$ 处评估 $\\cos \\theta$ 和 $f_{\\mathrm{top}}$。输出一个布尔值，指示诊断方法是否将该情况标记为可疑。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[True,False,False,True]”），分别对应上述四种情况的结果。任何内部计算的角度（若有）必须以弧度为单位；最终输出是无单位的布尔值。不允许用户输入。\n\n最终输出格式必须是精确的一行：一个 Python 风格的布尔值列表，逗号后没有空格。", "solution": "所提供的问题是数值线性代数领域一个适定且有科学依据的练习，具体涉及 Tikhonov 正则化和 L-曲线方法。它在残差向量系数的定义上存在一个微小的不一致之处，我们将指出这一点，但这并不影响问题的核心逻辑。我们将继续提供完整的解答。\n\n### 第 1 部分：滤波器因子形式的 Tikhonov 解\n\nTikhonov 正则化解 $x_{\\lambda}$ 是使泛函 $J(x) = \\|A x - b\\|_2^2 + \\lambda^2 \\|x\\|_2^2$ 最小化的向量。通过将 $J(x)$ 对 $x$ 的梯度设为零，可以找到该最小化子。这会得到正规方程组：\n$$\n(A^{\\top} A + \\lambda^2 I) x = A^{\\top} b\n$$\n我们使用奇异值分解 $A = U \\Sigma V^{\\top}$，这意味着 $A^{\\top} A = V \\Sigma^{\\top} \\Sigma V^{\\top}$ 和 $A^{\\top} b = V \\Sigma^{\\top} U^{\\top} b$。正规方程组变为：\n$$\n(V \\Sigma^{\\top} \\Sigma V^{\\top} + \\lambda^2 V I V^{\\top}) x_{\\lambda} = V \\Sigma^{\\top} U^{\\top} b\n$$\n利用 $V$ 的正交性（即 $V^{\\top}V = I$），我们可以从左侧乘以 $V^{\\top}$：\n$$\n(\\Sigma^{\\top} \\Sigma + \\lambda^2 I) V^{\\top} x_{\\lambda} = \\Sigma^{\\top} U^{\\top} b\n$$\n让我们定义变换后的解向量 $y = V^{\\top} x_{\\lambda}$ 和变换后的数据向量 $d = U^{\\top} b$。$d$ 的分量是 $d_i = u_i^{\\top} b$，即给定的 $\\beta_i$。矩阵 $\\Sigma^{\\top} \\Sigma + \\lambda^2 I$ 是一个大小为 $n \\times n$ 的对角矩阵，其对角线元素为 $\\sigma_i^2 + \\lambda^2$（对于 $i=1, \\dots, \\min(m,n)$）。$y$ 的第 $i$ 个分量的方程是：\n$$\n(\\sigma_i^2 + \\lambda^2) y_i = \\sigma_i \\beta_i\n$$\n解出 $y_i$ 得到 $y_i = \\frac{\\sigma_i \\beta_i}{\\sigma_i^2 + \\lambda^2}$。为了恢复 $x_{\\lambda}$，我们通过 $x_{\\lambda} = V y = \\sum_{i=1}^{\\min(m,n)} y_i v_i$ 进行逆变换。代入 $y_i$ 的表达式：\n$$\nx_{\\lambda} = \\sum_{i=1}^{\\min(m,n)} \\frac{\\sigma_i \\beta_i}{\\sigma_i^2 + \\lambda^2} v_i\n$$\n这可以使用给定的滤波器因子 $\\phi_i(\\lambda) = \\frac{\\sigma_i}{\\sigma_i^2 + \\lambda^2}$ 来表示，从而得到所需的形式：\n$$\nx_{\\lambda} = \\sum_{i=1}^{\\min(m,n)} \\phi_i(\\lambda) \\beta_i v_i\n$$\n接下来，我们推导残差 $r_{\\lambda} = A x_{\\lambda} - b$ 的系数。我们在左奇异向量基 $\\{u_i\\}$ 中展开 $A x_{\\lambda}$：\n$$\nA x_{\\lambda} = (U \\Sigma V^{\\top}) \\left( \\sum_{j=1}^{\\min(m,n)} y_j v_j \\right) = U \\Sigma \\left( \\sum_{j=1}^{\\min(m,n)} y_j (V^{\\top} v_j) \\right) = U \\Sigma y = \\sum_{i=1}^{\\min(m,n)} \\sigma_i y_i u_i\n$$\n代入 $y_i$：\n$$\nA x_{\\lambda} = \\sum_{i=1}^{\\min(m,n)} \\frac{\\sigma_i^2 \\beta_i}{\\sigma_i^2 + \\lambda^2} u_i\n$$\n数据向量为 $b = \\sum_{i=1}^{m} \\beta_i u_i$。因此残差为：\n$$\nr_{\\lambda} = A x_{\\lambda} - b = \\sum_{i=1}^{\\min(m,n)} \\frac{\\sigma_i^2 \\beta_i}{\\sigma_i^2 + \\lambda^2} u_i - \\sum_{i=1}^{m} \\beta_i u_i\n$$\n在一个共同的求和下合并各项（假设当 $i > \\min(m,n)$ 时 $\\sigma_i=0$）：\n$$\nr_{\\lambda} = \\sum_{i=1}^{m} \\left( \\frac{\\sigma_i^2}{\\sigma_i^2 + \\lambda^2} - 1 \\right) \\beta_i u_i = \\sum_{i=1}^{m} \\left( \\frac{\\sigma_i^2 - (\\sigma_i^2 + \\lambda^2)}{\\sigma_i^2 + \\lambda^2} \\right) \\beta_i u_i = \\sum_{i=1}^{m} \\frac{-\\lambda^2}{\\sigma_i^2 + \\lambda^2} \\beta_i u_i\n$$\n问题陈述中存在一个形式上的不一致。它定义了 $r_{\\lambda} = A x_{\\lambda} - b$，但给出的系数是 $\\gamma_i(\\lambda) = \\beta_i \\frac{\\lambda^2}{\\sigma_i^2 + \\lambda^2}$，这是正数。我们的推导表明系数应为 $-\\gamma_i(\\lambda)$。$\\gamma_i(\\lambda)$ 的表达式对应于另一种残差定义 $r=b - A x_{\\lambda}$。这个可能的符号错误不影响范数 $\\|r_{\\lambda}\\|_2$，因此不会改变 L-曲线的几何形状。我们继续使用所推导系数的绝对值。\n\n### 第 2 部分：L-曲线曲率\n\nL-曲线是 $(\\log \\|r_{\\lambda}\\|_2, \\log \\|x_{\\lambda}\\|_2)$ 的参数图。我们定义 $\\rho(\\lambda) = \\|r_{\\lambda}\\|_2$ 和 $\\eta(\\lambda) = \\|x_{\\lambda}\\|_2$。在对数-对数尺度上，L-曲线由 $\\lambda \\mapsto (X(\\lambda), Y(\\lambda))$ 参数化，其中 $X(\\lambda) = \\log \\rho(\\lambda)$ 和 $Y(\\lambda) = \\log \\eta(\\lambda)$。对于由 $t$ 参数化的一般平面曲线 $c(t) = (x(t), y(t))$，其曲率由问题中给出的公式计算：\n$$\n\\kappa(t) = \\frac{|x'(t) y''(t) - y'(t) x''(t)|}{\\left(x'(t)^2 + y'(t)^2\\right)^{3/2}}\n$$\n重新参数化 $t = \\log \\lambda$（因此 $\\lambda = e^t$）对于不适定问题在数值上是有利的。奇异值 $\\sigma_i$ 通常跨越多个数量级，导致解范数 $\\eta(\\lambda)$ 和残差范数 $\\rho(\\lambda)$ 在 $\\lambda$ 较小时变化迅速，而在 $\\lambda$ 较大时变化缓慢。在 $\\lambda$ 上的均匀网格会无法很好地采样快速变化的区域。而在 $\\lambda$ 上的对数网格（对应于参数 $t=\\log\\lambda$ 上的均匀网格）能更有效地在所有尺度上分布采样点。数值微分方法，例如在实现中使用的有限差分法，在均匀网格上求值时能提供更准确的导数近似。因此，在这个均匀网格上计算关于 $t$ 的导数 $x'(t)$、 $y'(t)$、 $x''(t)$ 和 $y''(t)$，可以产生更稳定和可靠的曲率计算结果。\n\n### 第 3 部分：对抗性噪声分析\n\n当数据被与主导左奇异向量对齐的噪声污染时，即 $b = A x_{\\mathrm{true}} + e$ 且 $e = \\eta \\|A x_{\\mathrm{true}}\\|_2 u_1$，数据系数 $\\beta_i = u_i^{\\top} b$ 会受到如下影响：\n$$\n\\beta_i = u_i^{\\top}(A x_{\\mathrm{true}} + e) = u_i^{\\top} A x_{\\mathrm{true}} + \\eta \\|A x_{\\mathrm{true}}\\|_2 (u_i^{\\top} u_1) = (u_i^{\\top} A x_{\\mathrm{true}}) + (\\eta \\|A x_{\\mathrm{true}}\\|_2) \\delta_{i1}\n$$\n其中 $\\delta_{i1}$ 是克罗内克（Kronecker）δ函数。噪声只扰动第一个系数 $\\beta_1$，使其被人为地放大。解的范数 $\\|x_{\\lambda}\\|_2^2 = \\sum_i (\\phi_i(\\lambda) \\beta_i)^2$ 和残差的范数 $\\|r_{\\lambda}\\|_2^2 = \\sum_i (\\gamma_i(\\lambda))^2$ 现在都由包含 $\\beta_1$ 的第一项主导。\nL-曲线的拐角通常标志着一个过渡点，在该点 $\\lambda$ 在数据拟合和解的大小之间取得平衡。当 $\\beta_1$ 过大时，这种平衡被扭曲。曲线的动态由第一个 SVD 分量控制，权衡拐角将被推向 $\\lambda_{\\ast} \\approx \\sigma_1$。这个 $\\lambda_{\\ast}$ 的选择会严重过滤所有奇异值 $\\sigma_i \\ll \\sigma_1$ 的分量。最终得到的解 $x_{\\lambda_{\\ast}}$ 将由 $v_1$ 分量主导，实质上是将大的、含噪声的数据分量投影回解空间。这个解无法准确地表示 $x_{\\mathrm{true}}$，特别是如果其本质特征被编码在 $i>1$ 的奇异向量 $v_i$ 中。因此，L-曲线的拐角具有误导性，因为它识别出的参数是用于捕获主导噪声的最优参数，而不是用于重建真实信号。\n\n### 第 4 部分：诊断方法提议\n\n第 3 部分的分析表明，一个误导性的拐角 $\\lambda_{\\ast}$ 会产生一个与主导右奇异子空间高度对齐的解 $x_{\\lambda_{\\ast}}$。这启发我们设计一种诊断方法来检测这种情况的发生。\n\n1.  **解的对齐性**：我们使用主角的余弦值 $\\cos \\theta$ 来衡量 $x_{\\lambda_{\\ast}}$ 与主导子空间 $\\mathcal{V}_k = \\mathrm{span}\\{v_1, \\dots, v_k\\}$ 的对齐程度：\n    $$\n    \\cos \\theta = \\frac{\\|P_{\\mathcal{V}_k} x_{\\lambda_{\\ast}}\\|_2}{\\|x_{\\lambda_{\\ast}}\\|_2}\n    $$\n    其中 $P_{\\mathcal{V}_k}$ 是到 $\\mathcal{V}_k$ 上的正交投影算子。$\\cos \\theta$ 的值接近 1 表示强对齐。\n\n2.  **数据主导性**：我们使用度量 $f_{\\mathrm{top}}$ 来衡量数据向量 $b$ 的能量在相应的主导左奇异子空间 $\\mathcal{U}_k = \\mathrm{span}\\{u_1, \\dots, u_k\\}$ 中的集中程度：\n    $$\n    f_{\\mathrm{top}} = \\frac{\\sum_{i=1}^{k} \\beta_i^2}{\\sum_{i=1}^{\\min(m,n)} \\beta_i^2} = \\frac{\\sum_{i=1}^{k} (u_i^{\\top}b)^2}{\\|b\\|_2^2}\n    $$\n    较大的 $f_{\\mathrm{top}}$ 值表明数据由少数几个主导分量驱动。\n\n**诊断规则**：如果解的对齐度高且数据能量集中，则将 L-曲线拐角 $\\lambda_{\\ast}$ 标记为可能具有误导性。对于 $k=3$ 的实际实现，我们提出以下阈值：\n如果满足：\n$$\n\\cos \\theta \\ge 0.995 \\quad \\text{和} \\quad f_{\\mathrm{top}} \\ge 0.2\n$$\n则标记为可疑。此规则识别出正则化参数可能反映了主导的（且可能已损坏的）数据分量，而不是找到了一个有意义的解的情况。", "answer": "```python\nimport numpy as np\n\ndef construct_problem(m, n, seed):\n    \"\"\"Constructs the test problem matrix A and true solution x_true.\"\"\"\n    rng = np.random.default_rng(seed=seed)\n    \n    # Singular values\n    s = np.logspace(0, -6, n)\n    \n    # Orthogonal matrices U and V\n    H1 = rng.standard_normal((m, m))\n    U, _ = np.linalg.qr(H1)\n    \n    H2 = rng.standard_normal((n, n))\n    V, _ = np.linalg.qr(H2)\n        \n    # Full A matrix\n    Sigma_mat = np.zeros((m, n))\n    np.fill_diagonal(Sigma_mat, s)\n    A = U @ Sigma_mat @ V.T\n    \n    # True solution x_true\n    n_cutoff = int(np.floor(0.4 * n))\n    c = np.zeros(n)\n    indices = np.arange(n_cutoff, n)\n    c[indices] = 1.0 / (indices - n_cutoff + 1)\n    c /= np.linalg.norm(c)\n    \n    x_true = V @ c\n    \n    return A, U, s, V, x_true\n\ndef get_lcurve_corner(U, s, b, lambda_grid):\n    \"\"\"Computes the L-curve and finds the lambda at maximum curvature.\"\"\"\n    m = U.shape[0]\n    n = len(s)\n    \n    # Data coefficients in U basis\n    beta_full = U.T @ b\n    beta = beta_full[:n]\n\n    log_res_norms = []\n    log_sol_norms = []\n    \n    s2 = s**2\n    beta2 = beta**2\n    \n    for lam in lambda_grid:\n        lam2 = lam**2\n        den = s2 + lam2\n        \n        # Solution norm calculation\n        sol_coeffs_sq = (s2 * beta2) / (den**2)\n        norm_x2 = np.sum(sol_coeffs_sq)\n        \n        # Residual norm calculation\n        res_coeffs_sq = (lam2**2 * beta2) / (den**2)\n        # Add residual from components of b orthogonal to U's first n columns\n        if m > n:\n            norm_r2 = np.sum(res_coeffs_sq) + np.sum(beta_full[n:]**2)\n        else:\n            norm_r2 = np.sum(res_coeffs_sq)\n        \n        # Avoid log(0) for extremely small norms\n        if norm_x2 > 1e-300 and norm_r2 > 1e-300:\n            log_sol_norms.append(0.5 * np.log(norm_x2))\n            log_res_norms.append(0.5 * np.log(norm_r2))\n        else: # Mark as invalid\n            log_sol_norms.append(np.nan) \n            log_res_norms.append(np.nan)\n\n    log_res_norms = np.array(log_res_norms)\n    log_sol_norms = np.array(log_sol_norms)\n    t = np.log(lambda_grid)\n    \n    # Filter out invalid (nan) values from numerical issues\n    valid_indices = ~np.isnan(log_sol_norms) & ~np.isnan(log_res_norms)\n    t_valid = t[valid_indices]\n    log_res_valid = log_res_norms[valid_indices]\n    log_sol_valid = log_sol_norms[valid_indices]\n    \n    # Compute derivatives w.r.t. t = log(lambda)\n    x_prime = np.gradient(log_res_valid, t_valid)\n    y_prime = np.gradient(log_sol_valid, t_valid)\n    \n    x_double_prime = np.gradient(x_prime, t_valid)\n    y_double_prime = np.gradient(y_prime, t_valid)\n    \n    # Curvature calculation\n    numerator = np.abs(x_prime * y_double_prime - y_prime * x_double_prime)\n    denominator = (x_prime**2 + y_prime**2)**1.5\n    \n    # Avoid division by zero\n    curvature = np.zeros_like(denominator)\n    valid_denom = denominator > 1e-12\n    curvature[valid_denom] = numerator[valid_denom] / denominator[valid_denom]\n    \n    idx_max_curv = np.argmax(curvature)\n    lambda_star = (lambda_grid[valid_indices])[idx_max_curv]\n    \n    return lambda_star\n\ndef evaluate_diagnostic(U, s, V, b, lambda_star, k, cos_theta_thresh, f_top_thresh):\n    \"\"\"Evaluates the diagnostic for a given b and lambda_star.\"\"\"\n    m, n = U.shape[0], V.shape[0]\n    \n    beta_full = U.T @ b\n    beta = beta_full[:n]\n        \n    s2 = s**2\n    lam_star2 = lambda_star**2\n    x_coeffs_V = (s * beta) / (s2 + lam_star2)\n    \n    # Calculate cos(theta)\n    norm_x = np.linalg.norm(x_coeffs_V)\n    norm_proj_x = np.linalg.norm(x_coeffs_V[:k])\n    \n    cos_theta = 0.0\n    if norm_x > 1e-16:\n      cos_theta = norm_proj_x / norm_x\n      \n    # Calculate f_top\n    norm_beta_full_sq = np.sum(beta_full**2)\n    norm_beta_top_k_sq = np.sum(beta[:k]**2)\n    \n    f_top = 0.0\n    if norm_beta_full_sq > 1e-16:\n      f_top = norm_beta_top_k_sq / norm_beta_full_sq\n\n    is_suspect = (cos_theta >= cos_theta_thresh) and (f_top >= f_top_thresh)\n    \n    return is_suspect\n\ndef solve():\n    \"\"\"Main function to run the test suite and print results.\"\"\"\n    m, n = 60, 60\n    k = 3\n    matrix_seed = 0\n    noise_seed = 1\n\n    cos_theta_thresh = 0.995\n    f_top_thresh = 0.2\n    \n    A, U, s, V, x_true = construct_problem(m, n, matrix_seed)\n    b_clean = A @ x_true\n    norm_b_clean = np.linalg.norm(b_clean)\n    \n    lambda_grid = np.logspace(-10, 2, 400)\n    \n    rng_noise = np.random.default_rng(noise_seed)\n    \n    e_white = rng_noise.standard_normal(m)\n    e_white /= np.linalg.norm(e_white)\n    \n    noise_cases = [\n        (0.05 * norm_b_clean * e_white),    # 1. Benign white noise\n        (0.5 * norm_b_clean * U[:, 0]),     # 2. Adversarial leading-direction\n        (0.5 * norm_b_clean * U[:, -1]),    # 3. Adversarial trailing-direction\n        (1e-8 * norm_b_clean * e_white)     # 4. Near noise-free\n    ]\n    \n    results = []\n    \n    for e in noise_cases:\n        b = b_clean + e\n        lambda_star = get_lcurve_corner(U, s, b, lambda_grid)\n        is_suspect = evaluate_diagnostic(U, s, V, b, lambda_star, k, cos_theta_thresh, f_top_thresh)\n        results.append(is_suspect)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3554612"}]}