{"hands_on_practices": [{"introduction": "特征值的绝对条件数是衡量其对矩阵扰动敏感性的关键指标。本练习将指导你从第一性原理出发计算这个数值。通过编写程序寻找左右特征向量，你将巩固对定义 $\\kappa_{\\mathrm{abs}}(\\lambda) = \\frac{\\|x\\|_2 \\|y\\|_2}{|y^* x|}$ 的理解，以及矩阵 $A$ 的左特征向量与其共轭转置 $A^*$ 的右特征向量之间的基本关系。[@problem_id:3576442]", "problem": "考虑一个复方阵 $A \\in \\mathbb{C}^{n \\times n}$，其有一个单特征对 $(\\lambda, x)$，其中 $\\lambda \\in \\mathbb{C}$ 且 $x \\in \\mathbb{C}^{n} \\setminus \\{0\\}$ 满足 $A x = \\lambda x$。如果一个向量 $y \\in \\mathbb{C}^{n} \\setminus \\{0\\}$ 满足 $y^{*} A = \\lambda y^{*}$，则称其为对应于 $\\lambda$ 的左特征向量，其中 $y^{*}$ 表示 $y$ 的埃尔米特（共轭）转置。仅从特征对、左特征向量和线性算子一阶微扰的定义出发，推导在谱2-范数下度量的 $A$ 的小扰动下，特征值 $\\lambda$ 的主阶变化的一个界，并用此为单特征值定义一个在2-范数下的严格的绝对特征值条件数估计量。\n\n设计并实现一个程序，给定一个矩阵 $A$ 和一个用于识别期望特征值的目标标量 $\\lambda_{\\text{target}} \\in \\mathbb{C}$，该程序执行以下步骤：\n\n- 计算 $A$ 的右特征值和右特征向量，并选择与差的绝对值最接近 $\\lambda_{\\text{target}}$ 的特征值 $\\lambda$ 相关联的右特征向量 $x$。\n- 仅使用定义 $y^{*} A = \\lambda y^{*}$ 和埃尔米特转置的性质，计算对应于同一特征值的左特征向量 $y$。\n- 使用您的推导，为所选的单特征值构建一个在2-范数下数值稳定的绝对特征值条件数估计量，记为 $\\kappa_{\\text{abs}}(\\lambda)$。\n\n您的程序必须实现此过程，并为下面的每个测试用例生成估计量 $\\kappa_{\\text{abs}}(\\lambda)$。不涉及物理单位。所有可能出现的角度都应以弧度为单位，尽管此任务不需要角度量。\n\n测试套件：\n\n1. 一个非正规实上三角矩阵，用于测试直接的单特征值选择：$A_{1} = \\begin{bmatrix} 1  4 \\\\ 0  2 \\end{bmatrix}$，其中 $\\lambda_{\\text{target},1} = 2$。\n2. 一个具有紧密特征值的近乎缺陷（但仍可对角化）的实上三角矩阵，用于测试灵敏度放大效应：$A_{2} = \\begin{bmatrix} 1  1 \\\\ 0  1 + 10^{-6} \\end{bmatrix}$，其中 $\\lambda_{\\text{target},2} = 1 + 10^{-6}$。\n3. 一个实埃尔米特对角矩阵，用于测试左右特征向量对齐的正规情况：$A_{3} = \\begin{bmatrix} -2  0 \\\\ 0  3 \\end{bmatrix}$，其中 $\\lambda_{\\text{target},3} = 3$。\n4. 一个具有复特征值的实正交旋转矩阵，用于测试复特征对的处理：$A_{4} = \\begin{bmatrix} 0  -1 \\\\ 1  0 \\end{bmatrix}$，其中 $\\lambda_{\\text{target},4} = \\mathrm{i}$。\n\n测试套件中的所有特征值都是单特征值。您的程序应生成单行输出，其中包含按测试用例（1）到（4）的顺序排列的四个估计条件数 $\\kappa_{\\text{abs}}(\\lambda)$，四舍五入到8位小数，并以方括号括起来的逗号分隔列表形式表示（例如 $[r_{1},r_{2},r_{3},r_{4}]$）。每个 $r_{k}$ 必须是实值浮点数。", "solution": "该问题是有效的，因为它具有科学依据、提法恰当且客观。它提出了数值线性代数中的一个标准任务——特征值条件数的推导与计算——并提供了一套清晰的定义、约束和测试用例。该问题是自洽的，没有矛盾或歧义。\n\n在此，我们从第一性原理出发推导绝对特征值条件数的估计量，然后概述其计算过程。\n\n### 特征值条件数的推导\n\n设 $A \\in \\mathbb{C}^{n \\times n}$ 为一个方阵。设 $(\\lambda, x)$ 是 $A$ 的一个单特征对，这意味着 $\\lambda \\in \\mathbb{C}$ 是一个单特征值，而 $x \\in \\mathbb{C}^{n} \\setminus \\{0\\}$ 是其对应的右特征向量。这由以下方程定义：\n$$A x = \\lambda x$$\n设 $y \\in \\mathbb{C}^{n} \\setminus \\{0\\}$ 为对应的左特征向量，由以下方程定义：\n$$y^{*} A = \\lambda y^{*}$$\n其中 $y^{*}$ 是 $y$ 的埃尔米特转置。\n\n考虑矩阵 $A$ 的一个小扰动 $\\delta A$。受扰矩阵为 $A' = A + \\delta A$。我们假设特征对 $(\\lambda, x)$ 相应地扰动为 $(\\lambda', x') = (\\lambda + \\delta \\lambda, x + \\delta x)$。新的特征对满足受扰的特征值方程：\n$$(A + \\delta A)(x + \\delta x) = (\\lambda + \\delta \\lambda)(x + \\delta x)$$\n我们展开这个方程：\n$$A x + A \\delta x + (\\delta A) x + (\\delta A) \\delta x = \\lambda x + \\lambda \\delta x + (\\delta \\lambda) x + (\\delta \\lambda) \\delta x$$\n使用原始的未扰动方程 $A x = \\lambda x$，我们可以消去等式两边的第一项：\n$$A \\delta x + (\\delta A) x + (\\delta A) \\delta x = \\lambda \\delta x + (\\delta \\lambda) x + (\\delta \\lambda) \\delta x$$\n对于一阶微扰分析，我们假设扰动 $\\delta A$、$\\delta x$ 和 $\\delta \\lambda$ 很小。因此，我们可以忽略二阶及更高阶的项，例如 $(\\delta A) \\delta x$ 和 $(\\delta \\lambda) \\delta x$。这得到一阶近似式：\n$$A \\delta x + (\\delta A) x \\approx \\lambda \\delta x + (\\delta \\lambda) x$$\n整理各项，我们得到：\n$$(\\delta A) x - (\\delta \\lambda) x \\approx (\\lambda I - A) \\delta x$$\n其中 $I$ 是 $n \\times n$ 的单位矩阵。\n\n为了分离出包含 $\\delta \\lambda$ 的项，我们用左特征向量的共轭转置 $y^{*}$ 左乘整个方程：\n$$y^{*} ((\\delta A) x - (\\delta \\lambda) x) \\approx y^{*} (\\lambda I - A) \\delta x$$\n$$y^{*} (\\delta A) x - y^{*} (\\delta \\lambda) x \\approx (y^{*} \\lambda - y^{*} A) \\delta x$$\n根据左特征向量的定义，$y^{*} A = \\lambda y^{*}$，这意味着 $y^{*} A - \\lambda y^{*} = 0$。因此，近似式的右边为零：\n$$(y^{*} \\lambda - y^{*} A) \\delta x = (\\lambda y^{*} - y^{*} A) \\delta x = (0) \\delta x = 0$$\n该近似式简化为：\n$$y^{*} (\\delta A) x - y^{*} (\\delta \\lambda) x \\approx 0$$\n由于 $\\delta \\lambda$ 是一个标量，我们可以写成 $y^{*} (\\delta \\lambda) x = (\\delta \\lambda) y^{*} x$。这得到：\n$$y^{*} (\\delta A) x \\approx (\\delta \\lambda) y^{*} x$$\n因为 $\\lambda$ 是一个单特征值，其对应的左右特征向量不正交，即 $y^{*} x \\neq 0$。因此，我们可以解出特征值的一阶变化 $\\delta \\lambda$：\n$$\\delta \\lambda \\approx \\frac{y^{*} (\\delta A) x}{y^{*} x}$$\n为了建立一个界，我们对两边取绝对值：\n$$|\\delta \\lambda| \\approx \\left| \\frac{y^{*} (\\delta A) x}{y^{*} x} \\right| = \\frac{|y^{*} (\\delta A) x|}{|y^{*} x|}$$\n分子可以使用柯西-施瓦茨不等式和谱2-范数 $\\|\\cdot\\|_2$ 的定义来界定。表达式 $y^{*} ((\\delta A) x)$ 是一个标量。\n$$|y^{*} ((\\delta A) x)| \\le \\|y\\|_2 \\|(\\delta A) x\\|_2$$\n此外，根据诱导矩阵范数的定义：\n$$\\|(\\delta A) x\\|_2 \\le \\|\\delta A\\|_2 \\|x\\|_2$$\n结合这些不等式，我们有：\n$$|y^{*} (\\delta A) x| \\le \\|y\\|_2 \\|\\delta A\\|_2 \\|x\\|_2$$\n将这个界代回到 $|\\delta \\lambda|$ 的表达式中，得到主阶变化的关系式：\n$$|\\delta \\lambda| \\lesssim \\frac{\\|y\\|_2 \\|x\\|_2}{|y^{*} x|} \\|\\delta A\\|_2$$\n绝对特征值条件数 $\\kappa_{\\text{abs}}(\\lambda)$ 是将特征值的变化与矩阵的扰动联系起来的因子。它被定义为当 $\\|\\delta A\\|_2 \\to 0$ 时，比率 $|\\delta \\lambda| / \\|\\delta A\\|_2$ 的上确界。根据我们的一阶分析，这给出了估计量：\n$$\\kappa_{\\text{abs}}(\\lambda) = \\frac{\\|x\\|_2 \\|y\\|_2}{|y^{*} x|}$$\n这个表达式与特征向量 $x$ 和 $y$ 的缩放无关，因为分子中的任何缩放因子都会与分母中相应的因子相消。如果特征向量被归一化，使得 $\\|x\\|_2 = 1$ 且 $\\|y\\|_2 = 1$，则公式简化为 $\\kappa_{\\text{abs}}(\\lambda) = 1 / |y^{*} x|$。量 $y^{*} x$ 可以与特征向量之间的夹角 $\\theta$ 相关联，即 $|y^{*} x| = \\|y\\|_2 \\|x\\|_2 |\\cos(\\theta)|$，因此 $\\kappa_{\\text{abs}}(\\lambda) = 1/|\\cos(\\theta)|$。对于正规矩阵（$A A^{*} = A^{*} A$），左右特征向量是平行的，所以 $|\\cos(\\theta)|=1$ 且 $\\kappa_{\\text{abs}}(\\lambda)=1$。对于非正规矩阵， $|\\cos(\\theta)|$ 可能非常小，导致条件数很大。\n\n### 计算过程\n\n给定一个矩阵 $A$ 和一个目标标量 $\\lambda_{\\text{target}}$，计算 $\\kappa_{\\text{abs}}(\\lambda)$ 的过程如下：\n\n1.  **计算右特征对**：计算矩阵 $A$ 的特征值 $w_j$ 和对应的右特征向量 $v_j$。这是通过求解标准特征值问题 $A v = w v$ 来完成的。\n2.  **选择目标特征对**：从集合 $\\{w_j\\}$ 中找出在复平面上与 $\\lambda_{\\text{target}}$ 最接近的特征值 $\\lambda$，即最小化 $|\\lambda - \\lambda_{\\text{target}}|$。设其对应的右特征向量为 $x$。\n3.  **计算左特征向量**：特征值 $\\lambda$ 的左特征向量 $y$ 由 $y^{*} A = \\lambda y^{*}$ 定义。为了计算 $y$，我们对这个方程取埃尔米特转置：$(y^{*} A)^{*} = (\\lambda y^{*})^{*}$。这得到 $A^{*} (y^{*})^{*} = \\bar{\\lambda} (y^{*})^{*}$，简化为 $A^{*} y = \\bar{\\lambda} y$。因此，矩阵 $A$ 对应于特征值 $\\lambda$ 的左特征向量 $y$ 是其埃尔米特转置矩阵 $A^{*}$ 对应于特征值 $\\bar{\\lambda}$ 的右特征向量。我们计算 $A^{*}$ 的特征对，并选择与特征值 $\\bar{\\lambda}$ 最接近的特征向量。\n4.  **计算条件数**：使用所选的右特征向量 $x$ 和计算出的左特征向量 $y$，我们使用推导出的公式计算条件数：\n    $$\\kappa_{\\text{abs}}(\\lambda) = \\frac{\\|x\\|_2 \\|y\\|_2}{|y^{*} x|}$$\n    在数值上，$\\|v\\|_2$ 是向量 $v$ 的欧几里得范数或$L_2$范数，而 $y^{*}x$ 是复数点积，计算方式为 $\\sum_{i=1}^{n} \\overline{y_i} x_i$。\n\n对每个给定的测试用例实施此过程，以找到各自的特征值条件数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_condition_number(A: np.ndarray, lambda_target: complex) -> float:\n    \"\"\"\n    Computes the absolute condition number for a simple eigenvalue of a matrix.\n\n    Args:\n        A (np.ndarray): A square complex matrix.\n        lambda_target (complex): A scalar value to identify the eigenvalue of interest.\n\n    Returns:\n        float: The estimated absolute eigenvalue condition number in the 2-norm.\n    \"\"\"\n    n = A.shape[0]\n    if A.shape != (n, n):\n        raise ValueError(\"Input matrix must be square.\")\n\n    # Step 1: Compute right eigenvalues and eigenvectors of A.\n    # w contains the eigenvalues, v contains the corresponding eigenvectors in columns.\n    w, v = np.linalg.eig(A)\n\n    # Step 2: Select the right eigenpair (lambda, x) closest to lambda_target.\n    idx = np.argmin(np.abs(w - lambda_target))\n    eigenvalue_lambda = w[idx]\n    right_eigenvector_x = v[:, idx]\n\n    # Step 3: Compute the left eigenvector y.\n    # The left eigenvector y of A for eigenvalue lambda is the right\n    # eigenvector of the Hermitian transpose A* for eigenvalue conj(lambda).\n    A_hermitian = A.conj().T\n    w_left, v_left = np.linalg.eig(A_hermitian)\n    \n    # Select the eigenvector of A* corresponding to the eigenvalue closest to conj(lambda).\n    idx_left = np.argmin(np.abs(w_left - np.conj(eigenvalue_lambda)))\n    left_eigenvector_y = v_left[:, idx_left]\n\n    # Step 4: Compute the absolute eigenvalue condition number.\n    # Formula: kappa_abs(lambda) = (||x||_2 * ||y||_2) / |y* x|\n    # where y* x is the dot product sum(conj(y_i) * x_i).\n    # np.linalg.norm computes the L2 norm by default.\n    norm_x = np.linalg.norm(right_eigenvector_x)\n    norm_y = np.linalg.norm(left_eigenvector_y)\n    \n    # np.vdot(a, b) computes a*.b, which is exactly y* x\n    y_star_x = np.vdot(left_eigenvector_y, right_eigenvector_x)\n    \n    # Handle the case where y_star_x is zero (defective eigenvalue), though\n    # the problem statement guarantees simple eigenvalues.\n    if abs(y_star_x)  1e-15: # Using a tolerance for floating point comparison\n        return float('inf')\n\n    kappa = (norm_x * norm_y) / abs(y_star_x)\n    \n    return float(kappa)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([[1, 4], [0, 2]], dtype=float), 2.0),\n        (np.array([[1, 1], [0, 1 + 1e-6]], dtype=float), 1.0 + 1e-6),\n        (np.array([[-2, 0], [0, 3]], dtype=float), 3.0),\n        (np.array([[0, -1], [1, 0]], dtype=float), 1j),\n    ]\n\n    results = []\n    for A, lambda_target in test_cases:\n        kappa = compute_condition_number(A, lambda_target)\n        results.append(kappa)\n\n    # Format the output as a comma-separated list of floats rounded to 8 decimal places.\n    formatted_results = [f\"{r:.8f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "3576442"}, {"introduction": "尽管条件数提供了敏感性的理论度量，但观察其在实际中的作用是建立直觉的关键。本练习展示了一个经典的非正规矩阵例子，其中一个大的非对角元素导致左右特征向量近乎正交，从而产生巨大的条件数。你将解析地推导这个条件数，并用它来量化一个微小的后向误差（即很小的残差）如何被放大为特征值上一个巨大的前向误差，这是数值计算中的一个核心概念。[@problem_id:3576422]", "problem": "考虑由下式给出的上三角矩阵族 $A(M) \\in \\mathbb{C}^{2 \\times 2}$\n$$\nA(M) \\;=\\; \\begin{pmatrix} 1  M \\\\ 0  2 \\end{pmatrix},\n$$\n其中 $M  0$ 是一个实参数。设 $\\lambda$ 表示单特征值 $\\lambda = 1$，并设 $v \\in \\mathbb{C}^{2}$ 和 $w \\in \\mathbb{C}^{2}$ 分别是与 $\\lambda$ 相关联的右、左特征向量。某算法返回一个计算出的特征对 $(\\widehat{\\lambda}, \\widehat{v})$，其中 $\\widehat{v}$ 被归一化为 $\\|\\widehat{v}\\|_{2} = 1$，且有一个范数为 $\\|r\\|_{2} = \\varepsilon$ 的微小特征对残差 $r := A(M)\\widehat{v} - \\widehat{\\lambda}\\widehat{v}$，其中 $0  \\varepsilon \\ll 1$。根据特征对后向误差的定义，满足 $(A(M) + \\Delta A)\\widehat{v} = \\widehat{\\lambda}\\widehat{v}$ 的最小扰动 $\\Delta A$（在谱范数意义下）的范数等于后向误差。\n\n从左、右特征向量和单特征值一阶扰动的定义出发，推导矩阵 $A(M)$ 特征值 $\\lambda = 1$ 的绝对特征值条件数 $\\kappa_{\\mathrm{abs}}(\\lambda)$ 的显式表达式，并解释为何一个残差方向 $r$ 即使在后向误差 $\\|\\Delta A\\|_{2} = \\varepsilon$ 很小的情况下，仍可能导致一个被放大的前向特征值误差 $|\\widehat{\\lambda} - \\lambda|$。然后，利用你的推导，计算当 $M = 10^{6}$ 和 $\\varepsilon = 10^{-10}$ 时，最坏情况下的前向特征值误差大小 $|\\widehat{\\lambda} - \\lambda|$。将你的最终数值答案四舍五入到四位有效数字。", "solution": "该问题陈述科学合理、适定、客观且完整。这是数值线性代数中一个关于非正规矩阵特征值敏感性的标准问题。因此，我们可以着手给出一个完整的解答。\n\n我们的目标有三个：首先，推导矩阵 $A(M)$ 的特征值 $\\lambda = 1$ 的绝对条件数；其次，解释微小残差如何导致计算出的特征值出现较大误差的机制；第三，计算在给定的 $M$ 和 $\\varepsilon$ 值下的最坏情况前向误差。\n\n给定的矩阵族为\n$$\nA(M) = \\begin{pmatrix} 1  M \\\\ 0  2 \\end{pmatrix}\n$$\n其中 $M  0$。由于 $A(M)$ 是一个上三角矩阵，其特征值即为对角线元素，$\\lambda_1 = 1$ 和 $\\lambda_2 = 2$。我们关心的是单特征值 $\\lambda = 1$。\n\n首先，我们确定与 $\\lambda = 1$ 相关联的右特征向量 $v$ 和左特征向量 $w$。\n\n右特征向量 $v = \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix}$ 是一个满足方程 $A(M)v = \\lambda v$ 的非零向量，这等价于 $(A(M) - \\lambda I)v = 0$。对于 $\\lambda = 1$，我们有：\n$$\n(A(M) - 1 \\cdot I)v = \\begin{pmatrix} 1-1  M \\\\ 0  2-1 \\end{pmatrix} \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix} = \\begin{pmatrix} 0  M \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n该矩阵方程产生以下线性方程组：\n$$\nM v_2 = 0\n$$\n$$\nv_2 = 0\n$$\n由于 $M  0$，两个方程都意味着 $v_2 = 0$。第一个分量 $v_1$ 不受约束，因此我们可以选择任何非零值。一个规范的选择是 $v_1 = 1$。因此，$\\lambda = 1$ 的一个右特征向量是：\n$$\nv = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n\n左特征向量 $w = \\begin{pmatrix} w_1 \\\\ w_2 \\end{pmatrix}$ 是一个满足 $w^H A(M) = \\lambda w^H$ 的非零向量，这等价于 $w^H (A(M) - \\lambda I) = 0$。对于 $\\lambda = 1$，并且由于 $A(M)$ 是实矩阵，我们可以使用 $w^T$：\n$$\nw^T (A(M) - 1 \\cdot I) = \\begin{pmatrix} w_1  w_2 \\end{pmatrix} \\begin{pmatrix} 0  M \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 0  0 \\end{pmatrix}\n$$\n这给出了单个方程 $M w_1 + w_2 = 0$。我们可以选择 $w_1 = 1$，这得到 $w_2 = -M$。因此，$\\lambda = 1$ 的一个左特征向量是：\n$$\nw = \\begin{pmatrix} 1 \\\\ -M \\end{pmatrix}\n$$\n\n对于一个单特征值 $\\lambda$，其绝对特征值条件数 $\\kappa_{\\mathrm{abs}}(\\lambda)$ 定义为：\n$$\n\\kappa_{\\mathrm{abs}}(\\lambda) = \\frac{\\|w\\|_2 \\|v\\|_2}{|w^H v|}\n$$\n我们使用推导出的特征向量计算必要的组成部分：\n$$\n\\|v\\|_2 = \\sqrt{1^2 + 0^2} = 1\n$$\n$$\n\\|w\\|_2 = \\sqrt{1^2 + (-M)^2} = \\sqrt{1 + M^2}\n$$\n$$\nw^H v = w^T v = \\begin{pmatrix} 1  -M \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 1 \\cdot 1 + (-M) \\cdot 0 = 1\n$$\n将这些值代入条件数的公式：\n$$\n\\kappa_{\\mathrm{abs}}(1) = \\frac{(\\sqrt{1+M^2})(1)}{|1|} = \\sqrt{1+M^2}\n$$\n这就是特征值 $\\lambda = 1$ 的绝对条件数的显式表达式。\n\n接下来，我们解释微小的残差如何导致大的前向误差。一阶扰动理论指出，对于矩阵 $A$ 的一个微小扰动 $\\Delta A$，一个单特征值 $\\lambda$ 会被扰动为 $\\widehat{\\lambda}$，使得前向误差 $|\\widehat{\\lambda} - \\lambda|$ 的界为：\n$$\n|\\widehat{\\lambda} - \\lambda| \\lesssim \\kappa_{\\mathrm{abs}}(\\lambda) \\|\\Delta A\\|_2\n$$\n问题陈述中提到，$(\\widehat{\\lambda}, \\widehat{v})$ 是一个计算出的特征对，其残差为 $r = A(M)\\widehat{v} - \\widehat{\\lambda}\\widehat{v}$，范数为 $\\|r\\|_2 = \\varepsilon$。数量 $\\varepsilon$ 是使得 $(\\widehat{\\lambda}, \\widehat{v})$ 成为 $A(M) + \\Delta A$ 的精确特征对所需的最小扰动 $\\Delta A$ 的范数；这就是后向误差。因此，$\\|\\Delta A\\|_2 = \\varepsilon$。\n\n因此，最坏情况下的前向误差近似为：\n$$\n|\\widehat{\\lambda} - \\lambda|_{\\text{worst}} \\approx \\kappa_{\\mathrm{abs}}(\\lambda) \\|\\Delta A\\|_2 = \\varepsilon \\sqrt{1+M^2}\n$$\n这个关系式表明，条件数 $\\kappa_{\\mathrm{abs}}(\\lambda)$ 起到了放大因子的作用。对于大的 $M$，我们有 $\\kappa_{\\mathrm{abs}}(1) \\approx M$。因此，一个微小的后向误差 $\\varepsilon$ 可以被放大为大小约为 $M\\varepsilon$ 的前向误差。\n\n这个大的条件数是矩阵 $A(M)$ 非正规性的一种表现（因为当 $M0$ 时，$A(M)A(M)^H \\neq A(M)^HA(M)$）。在非正规矩阵中，左、右特征向量不一定正交。$v$ 和 $w$ 之间夹角 $\\theta$ 的余弦由下式给出：\n$$\n\\cos(\\theta) = \\frac{|w^H v|}{\\|w\\|_2 \\|v\\|_2} = \\frac{1}{\\sqrt{1+M^2}}\n$$\n对于大的 $M$，$\\cos(\\theta) \\to 0$，意味着 $\\theta \\to \\pi/2$。左、右特征向量变得近乎正交。条件数可以表示为 $\\kappa_{\\mathrm{abs}}(\\lambda) = 1/|\\cos(\\theta)|$，随着特征向量趋于正交，该值变得非常大。\n\n这种放大效应也可以通过将残差方程左乘 $w^H$ 推导出的精确关系看出：\n$$\nw^H r = w^H(A(M)\\widehat{v} - \\widehat{\\lambda}\\widehat{v}) = (\\lambda w^H)\\widehat{v} - \\widehat{\\lambda} w^H \\widehat{v} = (\\lambda - \\widehat{\\lambda})w^H\\widehat{v}\n$$\n这给出了前向误差的表达式：\n$$\n\\widehat{\\lambda} - \\lambda = -\\frac{w^H r}{w^H \\widehat{v}}\n$$\n误差的大小为 $|\\widehat{\\lambda} - \\lambda| = \\frac{|w^H r|}{|w^H \\widehat{v}|}$。分子可以通过选择残差 $r$ 的方向来最大化。根据柯西-施瓦茨不等式， $|w^H r| \\le \\|w\\|_2 \\|r\\|_2 = \\varepsilon \\sqrt{1+M^2}$。当残差向量 $r$ 与左特征向量 $w$ 平行时，达到这个最大值。分母 $|w^H \\widehat{v}|$ 通常接近 $|w^H v|=1$，因为 $\\widehat{v}$ 是 $v$ 的一个近似。因此，当前向误差最大化时，残差 $r$ 指向左特征向量 $w$ 的方向，这种最坏情况下的误差大小约为 $\\varepsilon \\sqrt{1+M^2}$。\n\n最后，我们计算当 $M = 10^6$ 和 $\\varepsilon = 10^{-10}$ 时，最坏情况下的前向特征值误差大小。\n$$\n|\\widehat{\\lambda} - \\lambda|_{\\text{worst}} = \\kappa_{\\mathrm{abs}}(1) \\varepsilon = \\varepsilon \\sqrt{1+M^2}\n$$\n代入给定值：\n$$\n|\\widehat{\\lambda} - \\lambda|_{\\text{worst}} = 10^{-10} \\sqrt{1 + (10^6)^2} = 10^{-10} \\sqrt{1 + 10^{12}}\n$$\n我们可以从平方根中提出 $10^{12}$：\n$$\n|\\widehat{\\lambda} - \\lambda|_{\\text{worst}} = 10^{-10} \\sqrt{10^{12}(10^{-12} + 1)} = 10^{-10} \\cdot 10^6 \\sqrt{1 + 10^{-12}} = 10^{-4} \\sqrt{1 + 10^{-12}}\n$$\n对于一个值 $x \\ll 1$，二项式近似给出 $\\sqrt{1+x} \\approx 1 + \\frac{1}{2}x$。这里，$x = 10^{-12}$，非常小。\n$$\n\\sqrt{1 + 10^{-12}} \\approx 1 + \\frac{1}{2} \\cdot 10^{-12} = 1.0000000000005\n$$\n所以，误差为：\n$$\n|\\widehat{\\lambda} - \\lambda|_{\\text{worst}} \\approx 10^{-4} \\times (1 + 0.5 \\times 10^{-12}) = 10^{-4} + 0.5 \\times 10^{-16}\n$$\n第二项太小，不会影响前四位有效数字。该值为 $1.0000000000005 \\times 10^{-4}$。四舍五入到四位有效数字得到 $1.000 \\times 10^{-4}$。", "answer": "$$\n\\boxed{1.000 \\times 10^{-4}}\n$$", "id": "3576422"}, {"introduction": "特征值敏感性的概念可以从单一的数值度量，扩展为由伪谱提供的几何视图。本练习将探究一个具有几乎重合特征值的矩阵，这种情况会急剧增加敏感性。你将分析当特征值彼此靠近时条件数如何发散，然后将此行为与矩阵伪谱的结构联系起来，通过一个计算实验来验证一阶关系 $|z - \\lambda| \\approx \\kappa(\\lambda) \\delta$。[@problem_id:3576428]", "problem": "考虑由实标量 $ \\alpha $ 和 $ \\epsilon $ 参数化的 $2 \\times 2$ 上三角非正规矩阵 $A$，\n$$\nA = \\begin{bmatrix} 1  \\alpha \\\\ 0  1+\\epsilon \\end{bmatrix}.\n$$\n$A$ 的特征值为 $ \\lambda_1 = 1 $ 和 $ \\lambda_2 = 1+\\epsilon $。对于 $ \\epsilon \\neq 0 $ 时的单特征值 $ \\lambda_1 = 1 $，令 $ x $ 和 $ y $ 分别表示对应的右特征向量和左特征向量，即 $ A x = \\lambda_1 x $ 和 $ y^* A = \\lambda_1 y^* $。特征值 $ \\lambda_1 $ 的条件数定义为\n$$\n\\kappa(\\lambda_1) = \\frac{\\|x\\|_2 \\, \\|y\\|_2}{|y^* x|},\n$$\n其中 $ \\|\\cdot\\|_2 $ 是欧几里得向量范数。$ \\delta $-伪谱 $ \\Lambda_{\\delta}(A) $ 定义为\n$$\n\\Lambda_{\\delta}(A) = \\{ z \\in \\mathbb{C} : \\sigma_{\\min}(z I - A) \\le \\delta \\},\n$$\n其中 $ \\sigma_{\\min}(\\cdot) $ 表示最小奇异值，$ I $ 是单位矩阵。根据一阶特征值扰动理论和伪谱的预解式刻画可知，对于一个单特征值，在 $ \\lambda_1 $ 附近的 $ \\Lambda_{\\delta}(A) $ 的局部边界，对于小的 $ \\delta $，其一阶尺度近似为 $ |z - \\lambda_1| \\approx \\kappa(\\lambda_1) \\, \\delta $。\n\n从这些核心定义和事实出发，推导矩阵 $ A $ 的 $ \\kappa(\\lambda_1) $ 关于 $ \\epsilon $ 的尺度变化行为，并解释该尺度变化如何反映在 $ \\lambda_1 $ 附近伪谱 $ \\Lambda_{\\delta}(A) $ 的局部行为中。然后实现一个算法，对于给定的 $ (\\alpha, \\epsilon) $ 和一个小的实位移 $ r $，计算：\n- 使用数值计算的左右特征向量计算条件数 $ \\kappa(\\lambda_1) $；\n- 使用奇异值分解（SVD）计算最小奇异值 $ \\delta_{\\text{actual}} = \\sigma_{\\min}\\big((1+r) I - A\\big) $；\n- 一阶预测值 $ \\delta_{\\text{pred}} = \\frac{|r|}{\\kappa(\\lambda_1)} $；\n- 比率 $ \\rho = \\frac{\\delta_{\\text{actual}}}{\\delta_{\\text{pred}}} $。\n\n对向量使用欧几里得范数，对矩阵使用由奇异值分解诱导的谱范数。将所有量视为无量纲。假设 $ \\alpha $ 和 $ \\epsilon $ 为实数，并使用实数算术。\n\n您的程序必须为以下测试套件计算这些量，每个测试用例指定为一个三元组 $ (\\alpha, \\epsilon, r) $：\n1. $ (\\alpha, \\epsilon, r) = (1.0, 10^{-1}, 10^{-3}) $,\n2. $ (\\alpha, \\epsilon, r) = (1.0, 10^{-3}, 10^{-4}) $,\n3. $ (\\alpha, \\epsilon, r) = (10.0, 10^{-3}, 10^{-4}) $,\n4. $ (\\alpha, \\epsilon, r) = (10^{-3}, 10^{-1}, 10^{-3}) $,\n5. $ (\\alpha, \\epsilon, r) = (2.0, 2 \\cdot 10^{-2}, 10^{-3}) $,\n6. $ (\\alpha, \\epsilon, r) = (1.0, 10^{-12}, 10^{-9}) $.\n\n您的程序应产生单行输出，包含一个用方括号括起来的、无空格的逗号分隔列表，其中每个测试用例的结果本身是包含五个浮点数的列表，顺序为 $ [\\kappa_{\\text{eig}}, \\kappa_{\\text{analytic}}, \\delta_{\\text{actual}}, \\delta_{\\text{pred}}, \\rho] $。此处，$ \\kappa_{\\text{eig}} $ 是从数值计算的左右特征向量得到的条件数，$ \\kappa_{\\text{analytic}} $ 是从您为该矩阵 $ A $ 推导的闭式解得到的条件数，$ \\delta_{\\text{actual}} $ 是在 $ z = 1 + r $ 处的最小奇异值，$ \\delta_{\\text{pred}} = |r| / \\kappa_{\\text{eig}} $，以及 $ \\rho = \\delta_{\\text{actual}} / \\delta_{\\text{pred}} $。例如，总体格式应如下所示：\n$$\n[\\,[\\kappa_{\\text{eig}}, \\kappa_{\\text{analytic}}, \\delta_{\\text{actual}}, \\delta_{\\text{pred}}, \\rho],\\,\\dots\\,].\n$$\n不应产生任何其他输出。", "solution": "该问题要求针对一个特定的非正规矩阵，推导其特征值条件数，分析其尺度行为，并通过相应的数值实现来验证一阶扰动理论的结果。\n\n设给定矩阵为\n$$\nA = \\begin{bmatrix} 1  \\alpha \\\\ 0  1+\\epsilon \\end{bmatrix}\n$$\n其中 $\\alpha, \\epsilon \\in \\mathbb{R}$，我们假设 $\\epsilon \\neq 0$ 以确保特征值 $\\lambda_1 = 1$ 和 $\\lambda_2 = 1+\\epsilon$ 是单特征值。我们关注特征值 $\\lambda_1 = 1$。\n\n**1. 推导右特征向量和左特征向量**\n\n首先，我们必须找到对应于 $\\lambda_1 = 1$ 的右特征向量 $x$ 和左特征向量 $y$。\n\n右特征向量 $x$ 满足方程 $(A - \\lambda_1 I)x = 0$。\n$$\n(A - 1 \\cdot I)x = \\begin{bmatrix} 1-1  \\alpha \\\\ 0  (1+\\epsilon)-1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 0  \\alpha \\\\ 0  \\epsilon \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\n$$\n该方程组得出 $\\alpha x_2 = 0$ 和 $\\epsilon x_2 = 0$。由于我们关心的是 $\\alpha \\neq 0$ 的非正规情况和 $\\epsilon \\neq 0$ 的不同特征值情况，这些方程要求 $x_2 = 0$。分量 $x_1$ 不受约束。为简单起见，我们可以选择 $x_1 = 1$。因此，一个右特征向量是：\n$$\nx = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}\n$$\n\n左特征向量 $y$ 满足方程 $y^* (A - \\lambda_1 I) = 0^*$。由于所有参数都是实数，共轭转置 $y^*$ 就是转置 $y^T$。\n$$\ny^T (A - 1 \\cdot I) = \\begin{bmatrix} y_1  y_2 \\end{bmatrix} \\begin{bmatrix} 0  \\alpha \\\\ 0  \\epsilon \\end{bmatrix} = \\begin{bmatrix} 0  0 \\end{bmatrix}\n$$\n该矩阵-向量乘积得到单个方程 $\\alpha y_1 + \\epsilon y_2 = 0$。存在一个一维解空间。可以通过设 $y_1 = \\epsilon$ 来找到一个非平凡解，这意味着 $y_2 = -\\alpha$。因此，一个左特征向量是：\n$$\ny = \\begin{bmatrix} \\epsilon \\\\ -\\alpha \\end{bmatrix}\n$$\n\n**2. 推导特征值条件数 $\\kappa(\\lambda_1)$**\n\n单特征值 $\\lambda_1$ 的条件数由以下公式给出：\n$$\n\\kappa(\\lambda_1) = \\frac{\\|x\\|_2 \\|y\\|_2}{|y^* x|}\n$$\n使用上面推导的特征向量，我们计算必要的分量：\n- $x$ 的欧几里得范数：$\\|x\\|_2 = \\sqrt{1^2 + 0^2} = 1$。\n- $y$ 的欧几里得范数：$\\|y\\|_2 = \\sqrt{\\epsilon^2 + (-\\alpha)^2} = \\sqrt{\\alpha^2 + \\epsilon^2}$。\n- 内积 $y^* x$：由于向量是实数， $y^* x = y^T x = \\begin{bmatrix} \\epsilon  -\\alpha \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\epsilon \\cdot 1 + (-\\alpha) \\cdot 0 = \\epsilon$。\n\n将这些代入 $\\kappa(\\lambda_1)$ 的定义，我们得到解析表达式：\n$$\n\\kappa(\\lambda_1) = \\frac{1 \\cdot \\sqrt{\\alpha^2 + \\epsilon^2}}{|\\epsilon|} = \\frac{\\sqrt{\\alpha^2 + \\epsilon^2}}{|\\epsilon|}\n$$\n这就是 $\\kappa_{\\text{analytic}}$ 的闭式表达式。\n\n**3. 尺度行为及与伪谱的关系**\n\n现在我们分析当特征值几乎重合时，即 $\\epsilon \\to 0$ 时，$\\kappa(\\lambda_1)$ 的尺度行为。该表达式可以改写为：\n$$\n\\kappa(\\lambda_1) = \\sqrt{\\frac{\\alpha^2}{\\epsilon^2} + 1}\n$$\n对于固定的非零 $\\alpha$，当 $|\\epsilon| \\to 0$ 时，平方根下的项 $(\\alpha/\\epsilon)^2$ 远大于 $1$。因此，条件数的渐进行为如下：\n$$\n\\kappa(\\lambda_1) \\approx \\sqrt{\\frac{\\alpha^2}{\\epsilon^2}} = \\frac{|\\alpha|}{|\\epsilon|}\n$$\n这表明 $\\kappa(\\lambda_1)$ 的尺度为 $O(|\\epsilon|^{-1})$。当矩阵 $A$ 接近一个带有非平凡若尔当块（Jordan block）的亏损矩阵时（对于 $\\alpha \\neq 0$，这在 $\\epsilon=0$ 时发生），条件数会任意增大。大的条件数意味着特征值对扰动高度敏感。\n\n这种敏感性被伪谱 $\\Lambda_{\\delta}(A)$ 所捕捉。量 $\\delta_{\\text{actual}} = \\sigma_{\\min}((1+r)I - A)$ 是最小扰动 $E$ 的大小（在谱范数意义下），使得 $A+E$ 在 $z = 1+r$ 处有一个特征值。因此，$z=1+r$ 位于 $\\Lambda_{\\delta_{\\text{actual}}}(A)$ 的边界上。\n\n一阶扰动理论预测，如果一个点 $z$ 位于单特征值 $\\lambda_1$ 附近，并且 $|z - \\lambda_1| \\approx \\kappa(\\lambda_1) \\delta$，则该点位于 $\\delta$-伪谱的边界上。对 $\\delta$ 进行整理，我们得到 $\\delta \\approx |z - \\lambda_1| / \\kappa(\\lambda_1)$。在我们的例子中，$z = 1+r$ 且 $\\lambda_1 = 1$，所以 $|z-\\lambda_1|=|r|$。这给出了一阶预测：\n$$\n\\delta_{\\text{pred}} = \\frac{|r|}{\\kappa(\\lambda_1)}\n$$\n问题要求计算比率 $\\rho = \\delta_{\\text{actual}} / \\delta_{\\text{pred}}$。这个比率衡量了一阶近似的准确性。对于足够小的扰动（即小的 $|r|$），我们期望 $\\rho \\to 1$。分析证实，大的条件数 $\\kappa(\\lambda_1)$（尺度为 $O(|\\epsilon|^{-1})$）意味着一个小的扰动 $\\delta$ 可以在特征值的位置上引起一个大得多的变化 $|r|$。\n\n将要实现的算法将通过数值方法（通过特征向量）和解析方法计算 $\\kappa(\\lambda_1)$，然后将使特征值移动 $r$ 所需的实际扰动大小 $\\delta_{\\text{actual}}$ 与一阶预测 $\\delta_{\\text{pred}}$ 进行比较。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes eigenvalue condition numbers and pseudospectral quantities\n    for a parameterized 2x2 non-normal matrix.\n    \"\"\"\n    test_cases = [\n        (1.0, 1e-1, 1e-3),\n        (1.0, 1e-3, 1e-4),\n        (10.0, 1e-3, 1e-4),\n        (1e-3, 1e-1, 1e-3),\n        (2.0, 2e-2, 1e-3),\n        (1.0, 1e-12, 1e-9),\n    ]\n\n    results = []\n\n    for alpha, epsilon, r in test_cases:\n        # Define the matrix A\n        A = np.array([[1.0, alpha], [0.0, 1.0 + epsilon]])\n\n        # 1. Compute numerical condition number kappa_eig\n        # Eigenvalue lambda_1 is 1.0\n        target_lambda = 1.0\n\n        # Right eigenvectors of A\n        eigvals_r, eigvecs_r = np.linalg.eig(A)\n        # Find index of eigenvalue closest to target_lambda\n        idx_r = np.argmin(np.abs(eigvals_r - target_lambda))\n        x = eigvecs_r[:, idx_r]\n\n        # Left eigenvectors of A are right eigenvectors of A.T\n        eigvals_l, eigvecs_l_T = np.linalg.eig(A.T)\n        # Find index of eigenvalue closest to target_lambda\n        idx_l = np.argmin(np.abs(eigvals_l - target_lambda))\n        y = eigvecs_l_T[:, idx_l]\n\n        # np.linalg.eig returns normalized eigenvectors, so ||x||=||y||=1\n        # kappa = (||x|| * ||y||) / |y* x| becomes 1 / |y* x|\n        kappa_eig = 1.0 / np.abs(np.dot(y.conj(), x))\n\n        # 2. Compute analytic condition number kappa_analytic\n        # kappa = sqrt(alpha^2 + epsilon^2) / |epsilon|\n        kappa_analytic = np.sqrt(alpha**2 + epsilon**2) / np.abs(epsilon)\n\n        # 3. Compute actual perturbation size delta_actual\n        # delta_actual = sigma_min((1+r)I - A)\n        M = (1.0 + r) * np.identity(2) - A\n        # svd returns singular values in descending order\n        singular_values = np.linalg.svd(M, compute_uv=False)\n        delta_actual = singular_values[-1]\n\n        # 4. Compute predicted perturbation size delta_pred\n        # delta_pred = |r| / kappa_eig\n        delta_pred = np.abs(r) / kappa_eig\n\n        # 5. Compute the ratio rho\n        rho = delta_actual / delta_pred\n        \n        # Collect the results for this case\n        case_results = [kappa_eig, kappa_analytic, delta_actual, delta_pred, rho]\n        results.append(case_results)\n\n    # Format the final output string as a list of lists, with no spaces\n    # Example: [[v1,v2],[v3,v4]]\n    # str(results) produces '[[v1, v2], [v3, v4]]', so we remove spaces.\n    output_str = str(results).replace(\" \", \"\")\n\n    print(output_str)\n\nsolve()\n```", "id": "3576428"}]}