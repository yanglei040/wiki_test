{"hands_on_practices": [{"introduction": "在编写复杂的数值算法之前，通过一个具体的例子手动演算一遍，是掌握其核心机制的有效方法。本练习将带领你对一个经典的 $3 \\times 3$ 希尔伯特矩阵进行无主元 LU 分解。通过这个过程，你不仅能熟悉 LU 分解求逆的步骤，还能亲眼见证在处理病态矩阵时，分解过程中可能会出现极小的对角线元素，这为理解数值不稳定性埋下伏笔 ([@problem_id:2161030])。", "problem": "在数值线性代数中，某些矩阵被称为“病态”的（ill-conditioned），这意味着输入的微小误差可能导致输出的巨大误差。一个经典的例子是希尔伯特矩阵（Hilbert matrix）。$n \\times n$ 的希尔伯特矩阵，记为 $H_n$，其元素由公式 $H_{ij} = \\frac{1}{i+j-1}$ 给出。\n\n考虑一个 $3 \\times 3$ 的希尔伯特矩阵 $H_3$。计算矩阵 $A$ 的逆矩阵的一种常用方法是先找到其 LU 分解（Lower-Upper decomposition），即 $A = LU$，其中 $L$ 是一个对角线上元素为 1 的下三角矩阵（这种约定称为 Doolittle 方法），而 $U$ 是一个上三角矩阵。然后可以通过逐列求解方程组 $AX=I$ 来求得逆矩阵 $A^{-1}$，其中 $I$ 是单位矩阵。这等价于求解 $LUX=I$。\n\n在不使用任何形式的主元选择（pivoting）的情况下，对 $3 \\times 3$ 的希尔伯特矩阵 $H_3$ 进行 LU 分解。然后，使用这个分解来计算其逆矩阵的第 3 行第 3 列的元素 $(H_3^{-1})_{33}$。该元素的整数值是多少？", "solution": "我们从 $3 \\times 3$ 的希尔伯特矩阵开始\n$$\nH_{3}=\\begin{pmatrix}\n1  \\frac{1}{2}  \\frac{1}{3} \\\\\n\\frac{1}{2}  \\frac{1}{3}  \\frac{1}{4} \\\\\n\\frac{1}{3}  \\frac{1}{4}  \\frac{1}{5}\n\\end{pmatrix}.\n$$\n我们进行无主元选择的 Doolittle LU 分解，因此 $H_{3}=LU$，其中 $L$ 是单位下三角矩阵，$U$ 是上三角矩阵。\n\n设 $u_{11}=a_{11}=1$, $u_{12}=a_{12}=\\frac{1}{2}$, $u_{13}=a_{13}=\\frac{1}{3}$。那么\n$$\nl_{21}=\\frac{a_{21}}{u_{11}}=\\frac{1}{2}, \\qquad l_{31}=\\frac{a_{31}}{u_{11}}=\\frac{1}{3}.\n$$\n在消去第一列后，更新 $(2,2)$、$(2,3)$、$(3,2)$ 和 $(3,3)$ 处的元素：\n$$\na_{22}'=a_{22}-l_{21}u_{12}=\\frac{1}{3}-\\frac{1}{2}\\cdot\\frac{1}{2}=\\frac{1}{12}, \\quad\na_{23}'=a_{23}-l_{21}u_{13}=\\frac{1}{4}-\\frac{1}{2}\\cdot\\frac{1}{3}=\\frac{1}{12},\n$$\n$$\na_{32}'=a_{32}-l_{31}u_{12}=\\frac{1}{4}-\\frac{1}{3}\\cdot\\frac{1}{2}=\\frac{1}{12}, \\quad\na_{33}'=a_{33}-l_{31}u_{13}=\\frac{1}{5}-\\frac{1}{3}\\cdot\\frac{1}{3}=\\frac{4}{45}.\n$$\n现在设 $u_{22}=a_{22}'=\\frac{1}{12}$ 和 $u_{23}=a_{23}'=\\frac{1}{12}$。那么\n$$\nl_{32}=\\frac{a_{32}'}{u_{22}}=\\frac{\\frac{1}{12}}{\\frac{1}{12}}=1,\n$$\n最后\n$$\nu_{33}=a_{33}'-l_{32}u_{23}=\\frac{4}{45}-1\\cdot\\frac{1}{12}=\\frac{1}{180}.\n$$\n因此\n$$\nL=\\begin{pmatrix}\n1  0  0 \\\\\n\\frac{1}{2}  1  0 \\\\\n\\frac{1}{3}  1  1\n\\end{pmatrix},\n\\qquad\nU=\\begin{pmatrix}\n1  \\frac{1}{2}  \\frac{1}{3} \\\\\n0  \\frac{1}{12}  \\frac{1}{12} \\\\\n0  0  \\frac{1}{180}\n\\end{pmatrix}.\n$$\n\n为了求出 $(H_{3}^{-1})_{33}$，我们通过 $LUx=e_{3}$ 求解 $H_{3}x=e_{3}$。首先求解 $Ly=e_{3}$，其中 $e_{3}=(0,0,1)^{T}$：\n$$\ny_{1}=0, \\qquad \\frac{1}{2}y_{1}+y_{2}=0 \\Rightarrow y_{2}=0, \\qquad \\frac{1}{3}y_{1}+y_{2}+y_{3}=1 \\Rightarrow y_{3}=1.\n$$\n所以 $y=(0,0,1)^{T}$。接下来求解 $Ux=y$：\n$$\n\\frac{1}{180}x_{3}=1 \\Rightarrow x_{3}=180,\n$$\n$$\n\\frac{1}{12}x_{2}+\\frac{1}{12}x_{3}=0 \\Rightarrow \\frac{1}{12}x_{2}+15=0 \\Rightarrow x_{2}=-180,\n$$\n$$\nx_{1}+\\frac{1}{2}x_{2}+\\frac{1}{3}x_{3}=0 \\Rightarrow x_{1}-90+60=0 \\Rightarrow x_{1}=30.\n$$\n因此，$H_{3}^{-1}$ 的第三列是 $\\begin{pmatrix}30 \\\\ -180 \\\\ 180\\end{pmatrix}$，并且第 $(3,3)$ 个元素是\n$$\n(H_{3}^{-1})_{33}=180.\n$$", "answer": "$$\\boxed{180}$$", "id": "2161030"}, {"introduction": "理论上，矩阵求逆有多种方法，但在实践中，不同算法的数值表现却有天壤之别。本练习要求你从底层实现两种矩阵求逆算法：基于带主元 LU 分解的方法和基于经典余子式/伴随矩阵的方法。通过在一系列精心设计的测试矩阵上比较它们的数值误差，你将深刻体会到为何 LU 分解是现代科学计算中求解线性系统和矩阵求逆的首选方法，其数值稳定性远超理论上的伴随矩阵法 ([@problem_id:3275824])。", "problem": "你必须编写一个完整的、可运行的程序，对于一组给定的 $4 \\times 4$ 方阵，用两种不同的方法计算矩阵的逆，并使用一种基于线性代数核心定义的、以残差为基础的度量标准，比较每种方法的数值误差。这两种方法是：(i) 一种源于带部分主元的高斯消元法定义以及将非奇异矩阵分解为下三角矩阵和上三角矩阵的算法，以及 (ii) 一种通过子式的代数余子式展开构建伴随矩阵，并通过子式的递归展开计算标量行列式的方法。你的程序必须明确地实现这两种方法，不能调用任何内置的求逆函数。比较必须基于从第一性原理计算的相对弗罗贝尼乌斯范数残差。\n\n使用的基础和定义：\n- 一个非奇异方阵 $A \\in \\mathbb{R}^{n \\times n}$ 的逆矩阵是满足 $A X = I$ 的矩阵 $X \\in \\mathbb{R}^{n \\times n}$，其中 $I$ 是大小为 $n \\times n$ 的单位矩阵。$X$ 的存在性意味着 $A$ 是非奇异的。\n- 带部分主元的高斯消元法将一个非奇异矩阵 $A$ 转换为一个置换后矩阵的分解 $P A = L U$，其中 $P$ 是一个置换矩阵，$L$ 是一个单位下三角矩阵（对角线元素等于 $1$），$U$ 是一个上三角矩阵。求解线性方程组 $A x = b$ 时，在考虑置换后，对 $L$ 和 $U$ 使用前向替换和后向替换。\n- 基于代数余子式的伴随矩阵是由 $A$ 的带符号子式构成的，这些子式通过行列式的子式递归展开（拉普拉斯展开）计算得出。不要使用任何内置或封闭形式的求逆公式；而是要通过代数余子式构建伴随矩阵，并通过递归子式展开计算行列式。\n\n需要计算的误差度量：\n- 对于每种方法产生的候选逆矩阵 $X$，定义相对逆残差误差\n$$\ne = \\frac{\\lVert I - A X \\rVert_F}{\\lVert I \\rVert_F},\n$$\n其中 $\\lVert \\cdot \\rVert_F$ 表示弗罗贝尼乌斯范数。该度量直接源于逆矩阵的定义 $A X = I$，并量化了计算出的 $X$ 在多大程度上满足该恒等关系。\n\n你的程序必须为每个测试矩阵 $A$ 执行的算法任务：\n1. 通过以下步骤计算 $X_{\\mathrm{LU}}$：\n   - 通过仅使用算术运算的行交换和消元乘数，利用带部分主元的高斯消元法构建分解 $P A = L U$。\n   - 通过对右侧各列应用置换，然后对 $L$ 进行前向替换，接着对 $U$ 进行后向替换，求解 $A X = I$ 的所有列，从而得到 $X_{\\mathrm{LU}}$。\n2. 通过以下步骤计算 $X_{\\mathrm{cof}}$：\n   - 通过沿某一行的递归子式展开计算 $A$ 的行列式。\n   - 从带符号的子式构建代数余子式矩阵，然后将其转置以获得伴随矩阵。使用此伴随矩阵和标量行列式来生成 $X_{\\mathrm{cof}}$，不使用任何内置的求逆函数。\n3. 对每种方法，使用上述残差公式计算 $e_{\\mathrm{LU}}$ 和 $e_{\\mathrm{cof}}$。\n\n测试套件：\n在以下五个维度均为 $n = 4$ 的矩阵集合上评估你的程序：\n- 案例 1 (单位矩阵边界情况):\n$$\nA_1 = I_4 =\n\\begin{bmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1\n\\end{bmatrix}.\n$$\n- 案例 2 (良态整数值结构):\n$$\nA_2 =\n\\begin{bmatrix}\n4  2  0  1 \\\\\n0  1  3  2 \\\\\n1  0  2  0 \\\\\n2  3  1  0\n\\end{bmatrix}.\n$$\n- 案例 3 (经典病态例子，希尔伯特矩阵):\n$$\nA_3 = H_4, \\quad (A_3)_{i j} = \\frac{1}{i + j - 1}, \\quad i,j \\in \\{1,2,3,4\\}.\n$$\n- 案例 4 (具有小行列式的近奇异块上三角结构):\n令 $\\varepsilon = 10^{-6}$。定义\n$$\nA_4 =\n\\begin{bmatrix}\n1  1  1  1 \\\\\n1  1+\\varepsilon  1  1 \\\\\n0  0  1  0 \\\\\n0  0  0  1\n\\end{bmatrix}.\n$$\n- 案例 5 (具有宽动态范围的范德蒙德矩阵):\n令 $x = [10^{-4}, 1, 2, 5]$。定义范德蒙德矩阵\n$$\nA_5 = V(x), \\quad (A_5)_{i j} = x_i^{j-1}, \\quad i,j \\in \\{1,2,3,4\\}.\n$$\n\n输出规格：\n- 对于每个测试案例 $k \\in \\{1,2,3,4,5\\}$，将 $e_{\\mathrm{LU}}^{(k)}$ 和 $e_{\\mathrm{cof}}^{(k)}$ 计算为浮点数。\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果的顺序必须完全如下\n$$\n[e_{\\mathrm{LU}}^{(1)}, e_{\\mathrm{cof}}^{(1)}, e_{\\mathrm{LU}}^{(2)}, e_{\\mathrm{cof}}^{(2)}, e_{\\mathrm{LU}}^{(3)}, e_{\\mathrm{cof}}^{(3)}, e_{\\mathrm{LU}}^{(4)}, e_{\\mathrm{cof}}^{(4)}, e_{\\mathrm{LU}}^{(5)}, e_{\\mathrm{cof}}^{(5)}].\n$$\n- 每个浮点数必须以小数点后有 $6$ 位数字的科学记数法打印（例如，$1.234567\\mathrm{e}{-08}$），并且输出字符串中不得有空格。\n\n不涉及物理单位。不涉及角度。所有输出均为无单位的实数。\n\n你的实现必须是完全自包含的，对于所需的步骤仅使用你自行编程的基本算术运算和矩阵运算（不调用任何内置的求逆函数），并遵守指定的打印格式。运行环境是带有 Numerical Python ($\\mathrm{NumPy}$) 的 Python。", "solution": "该问题被评估为有效。这是一个在数值线性代数领域中定义明确、有科学依据且客观的问题。任务是实现并比较两种不同的矩阵求逆算法——一种基于 LU 分解，另一种基于代数余子式/伴随矩阵方法——并使用一个标准的、基于残差的误差度量来量化它们的数值精度。所有的定义、约束和测试用例都经过了形式化的指定，并且在数学上是一致的。解决方案将首先概述每种方法的理论基础和误差度量，然后提供一个实现这些概念的程序。\n\n### 方法一：通过带部分主元的 LU 分解进行矩阵求逆\n第一种方法通过求解矩阵方程 $AX = I$ 来计算非奇异矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的逆矩阵 $X$，其中 $I$ 是单位矩阵。此方法的核心是带部分主元的 $A$ 的 LU 分解。该分解将 $A$ 的一个置换版本分解为一个单位下三角矩阵 $L$ 和一个上三角矩阵 $U$ 的乘积，使得 $PA = LU$。这里，$P$ 是一个置换矩阵，记录了高斯消元过程中为确保数值稳定性（通过避免除以小的或零的主元）而进行的行交换。\n\n矩阵方程 $AX = I$ 使用此分解重新排列：\n$$PAX = PI \\implies LUX = P$$\n这个单一的矩阵方程对应于 $n$ 个独立的线性方程组，每个方程组对应 $X$ 的一列。设 $x_j$ 为 $X$ 的第 $j$ 列，$p_j$ 为 $P$ 的第 $j$ 列。然后，对于每个 $j \\in \\{1, \\dots, n\\}$，我们求解：\n$$LU x_j = p_j$$\n对于每一列 $j$，这通过一个两步过程求解：\n1.  **前向替换：** 求解 $L y_j = p_j$ 以得到中间向量 $y_j$。由于 $L$ 是单位下三角矩阵（对角线上为 $1$），这个过程很高效：\n    $$y_{j,i} = p_{j,i} - \\sum_{k=1}^{i-1} L_{ik} y_{j,k} \\quad \\text{for } i = 1, \\dots, n$$\n2.  **后向替换：** 求解 $U x_j = y_j$ 以得到列向量 $x_j$。由于 $U$ 是上三角矩阵，这也容易通过后向替换求解：\n    $$x_{j,i} = \\frac{1}{U_{ii}} \\left( y_{j,i} - \\sum_{k=i+1}^{n} U_{ik} x_{j,k} \\right) \\quad \\text{for } i = n, \\dots, 1$$\n列向量 $x_j$ 的集合构成了逆矩阵 $X_{\\mathrm{LU}} = [x_1, x_2, \\dots, x_n]$。由于其计算效率（对于一个大小为 $n$ 的稠密矩阵，总共约需要 $\\frac{8}{3}n^3$ 次浮点运算）和在使用部分主元时良好的数值稳定性，该方法是数值计算中的标准方法。\n\n### 方法二：通过伴随矩阵公式进行矩阵求逆\n第二种方法基于使用行列式和伴随矩阵的经典解析求逆公式：\n$$A^{-1} = \\frac{1}{\\det(A)} \\mathrm{adj}(A)$$\n该方法需要计算两个部分：$A$ 的标量行列式 $\\det(A)$，和 $A$ 的伴随矩阵 $\\mathrm{adj}(A)$。如规定，两者都通过代数余子式展开计算。\n\n1.  **行列式计算**：行列式使用沿某一行（例如，第一行，$i=1$）的拉普拉斯展开计算：\n    $$\\det(A) = \\sum_{j=1}^{n} (-1)^{1+j} A_{1j} \\det(M_{1j})$$\n    其中 $M_{1j}$ 是通过删除第 $1$ 行和第 $j$ 列从 $A$ 得到的 $(n-1) \\times (n-1)$ 子矩阵（一个子式）。这个定义是递归的；每个子式 $M_{1j}$ 的行列式都通过相同的展开来计算，直到达到 $1 \\times 1$ 矩阵的基准情况，其中 $\\det([a]) = a$。\n\n2.  **伴随矩阵构造**：$A$ 的伴随矩阵是其代数余子式矩阵 $C$ 的转置：\n    $$\\mathrm{adj}(A) = C^T$$\n    代数余子式矩阵的元素 $C_{ij}$ 是带符号的子式：\n    $$C_{ij} = (-1)^{i+j} \\det(M_{ij})$$\n    其中 $M_{ij}$ 是通过从 $A$ 中删除第 $i$ 行和第 $j$ 列形成的子矩阵。这需要计算 $n^2$ 个大小为 $(n-1) \\times (n-1)$ 的行列式。\n结合这些部分得到逆矩阵 $X_{\\mathrm{cof}}$。这种方法的计算成本非常高，如果递归实现，其复杂度为 $O(n!)$，并且通常数值不稳定。大量的交替加减法可能导致浮点运算中的灾难性舍入误差。它主要具有理论和教学上的重要性，对于较大的矩阵而言不具备实用价值。\n\n### 误差度量\n为了比较两个计算出的逆矩阵 $X_{\\mathrm{LU}}$ 和 $X_{\\mathrm{cof}}$ 的数值精度，我们使用相对逆残差误差。对于一个计算出的逆矩阵 $X$，误差 $e$ 定义为：\n$$e = \\frac{\\lVert I - A X \\rVert_F}{\\lVert I \\rVert_F}$$\n这里，$\\lVert \\cdot \\rVert_F$ 是弗罗贝尼乌斯范数，对于一个矩阵 $B \\in \\mathbb{R}^{m \\times n}$ 定义为 $\\lVert B \\rVert_F = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |B_{ij}|^2}$。项 $I-AX$ 是残差矩阵，如果 $X$ 是精确的逆矩阵，它理想情况下应该是零矩阵。这个残差的范数衡量了与真实单位矩阵的偏差大小。通过单位矩阵的范数 $\\lVert I \\rVert_F$ 进行归一化，使得误差度量是相对的，并且与矩阵的维度尺度无关。对于指定的 $n=4$ 的情况，$\\lVert I_4 \\rVert_F = \\sqrt{1^2 + 1^2 + 1^2 + 1^2} = \\sqrt{4} = 2$。\n该度量直接且可靠地衡量了计算出的逆矩阵 $X$ 在多大程度上满足基本定义 $A^{-1}A=I$。预计病态测试用例（$A_3, A_4, A_5$）将在基于 LU 的方法和基于代数余子式的方法之间显示出此误差度量的显著差异，从而突显前者的优越数值稳定性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef lu_decomposition_pivoting(A_in):\n    \"\"\"\n    Performs LU decomposition with partial pivoting: PA = LU.\n    L is unit lower-triangular, U is upper-triangular.\n    \"\"\"\n    n = A_in.shape[0]\n    A = A_in.copy()\n    L = np.zeros((n, n), dtype=float)\n    P = np.identity(n, dtype=float)\n\n    for k in range(n):\n        # Find pivot (largest element in column k below diagonal)\n        pivot_row_index = k + np.argmax(np.abs(A[k:, k]))\n        \n        # Swap rows in A and P\n        if pivot_row_index != k:\n            A[[k, pivot_row_index]] = A[[pivot_row_index, k]]\n            P[[k, pivot_row_index]] = P[[pivot_row_index, k]]\n            # Swap previously computed parts of L\n            if k > 0:\n                L[[k, pivot_row_index], :k] = L[[pivot_row_index, k], :k]\n\n        # Check for singularity\n        if np.isclose(A[k, k], 0.0):\n            # This indicates singularity but we proceed to allow for large errors.\n            continue\n            \n        # Compute multipliers and update the matrix\n        for i in range(k + 1, n):\n            multiplier = A[i, k] / A[k, k]\n            L[i, k] = multiplier\n            A[i, k:] -= multiplier * A[k, k:]\n            \n    np.fill_diagonal(L, 1.0)\n    U = np.triu(A)\n    return P, L, U\n\ndef forward_substitution(L, b):\n    \"\"\"Solves Ly = b for y, where L is lower-triangular.\"\"\"\n    n = L.shape[0]\n    y = np.zeros(n, dtype=float)\n    for i in range(n):\n        y[i] = b[i] - np.dot(L[i, :i], y[:i])\n    return y\n\ndef backward_substitution(U, y):\n    \"\"\"Solves Ux = y for x, where U is upper-triangular.\"\"\"\n    n = U.shape[0]\n    x = np.zeros(n, dtype=float)\n    for i in range(n - 1, -1, -1):\n        if np.isclose(U[i, i], 0.0):\n            x[i] = np.inf\n        else:\n            x[i] = (y[i] - np.dot(U[i, i + 1:], x[i + 1:])) / U[i, i]\n    return x\n\ndef inverse_lu(A):\n    \"\"\"Computes matrix inverse using LU decomposition.\"\"\"\n    n = A.shape[0]\n    P, L, U = lu_decomposition_pivoting(A)\n    I = np.identity(n)\n    X_LU = np.zeros((n, n), dtype=float)\n    \n    for j in range(n):\n        b_permuted = P @ I[:, j]\n        y = forward_substitution(L, b_permuted)\n        x_col = backward_substitution(U, y)\n        X_LU[:, j] = x_col\n        \n    return X_LU\n\ndef get_minor_matrix(A, i, j):\n    \"\"\"Returns the minor matrix by deleting row i and column j.\"\"\"\n    return np.delete(np.delete(A, i, axis=0), j, axis=1)\n\ndef determinant_recursive(A):\n    \"\"\"Computes determinant by recursive cofactor expansion.\"\"\"\n    n = A.shape[0]\n    if n == 1:\n        return A[0, 0]\n    if n == 2:\n        return A[0, 0] * A[1, 1] - A[0, 1] * A[1, 0]\n    \n    det = 0.0\n    for j in range(n):\n        sign = (-1)**j\n        minor_matrix = get_minor_matrix(A, 0, j)\n        det += sign * A[0, j] * determinant_recursive(minor_matrix)\n    return det\n\ndef inverse_cofactor(A):\n    \"\"\"Computes matrix inverse using the adjugate method.\"\"\"\n    n = A.shape[0]\n    det_A = determinant_recursive(A)\n    \n    if np.isclose(det_A, 0.0):\n        return np.full((n, n), np.nan)\n\n    cofactor_matrix = np.zeros((n, n), dtype=float)\n    for i in range(n):\n        for j in range(n):\n            sign = (-1)**(i + j)\n            minor_matrix = get_minor_matrix(A, i, j)\n            cofactor_matrix[i, j] = sign * determinant_recursive(minor_matrix)\n    \n    adjugate_matrix = cofactor_matrix.T\n    return adjugate_matrix / det_A\n\ndef calculate_error(A, X):\n    \"\"\"Computes the relative Frobenius norm residual error.\"\"\"\n    n = A.shape[0]\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        return np.inf\n\n    I = np.identity(n)\n    residual_matrix = I - A @ X\n    norm_residual = np.linalg.norm(residual_matrix, 'fro')\n    norm_identity = np.sqrt(n)\n    \n    return norm_residual / norm_identity\n\ndef solve():\n    # Define the test cases from the problem statement.\n    A1 = np.identity(4, dtype=float)\n    \n    A2 = np.array([\n        [4., 2., 0., 1.],\n        [0., 1., 3., 2.],\n        [1., 0., 2., 0.],\n        [2., 3., 1., 0.]\n    ], dtype=float)\n    \n    A3 = np.zeros((4, 4), dtype=float)\n    for i in range(4):\n        for j in range(4):\n            A3[i, j] = 1.0 / (i + j + 1.0)\n            \n    epsilon = 1e-6\n    A4 = np.array([\n        [1., 1., 1., 1.],\n        [1., 1. + epsilon, 1., 1.],\n        [0., 0., 1., 0.],\n        [0., 0., 0., 1.]\n    ], dtype=float)\n    \n    x_vals = np.array([1e-4, 1.0, 2.0, 5.0], dtype=float)\n    A5 = np.vander(x_vals, 4, increasing=True)\n\n    test_cases = [A1, A2, A3, A4, A5]\n    results = []\n\n    for A in test_cases:\n        # Method 1: LU Inversion\n        X_lu = inverse_lu(A)\n        e_lu = calculate_error(A, X_lu)\n        results.append(e_lu)\n        \n        # Method 2: Cofactor Inversion\n        X_cof = inverse_cofactor(A)\n        e_cof = calculate_error(A, X_cof)\n        results.append(e_cof)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6e}' for r in results)}]\")\n\nsolve()\n```", "id": "3275824"}, {"introduction": "理解数值误差的来源是数值分析的核心挑战之一。本练习将引导你超越仅仅“观察”误差的层面，去探索误差与矩阵内在谱结构之间的深刻联系。你将构造一系列具有已知谱分解（即已知特征值和特征向量）的矩阵，然后通过 LU 分解计算其逆矩阵，并与精确的解析解进行比较。通过在矩阵的特征基下分析误差，你将揭示矩阵的谱（特别是特征值的分布）如何直接影响数值计算的精度，从而直观地理解条件数的威力 ([@problem_id:3539201])。", "problem": "要求您设计并实现一个完整的、可运行的程序，该程序对一族结构化矩阵通过下三角-上三角 (LU) 分解构建矩阵逆的过程进行基准测试，并定量地解释观测到的数值误差如何与矩阵的谱相关联。请完全以纯数学术语进行工作，并生成在多次执行中确定且可复现的数值输出。\n\n从以下基础出发：\n- 一个非奇异矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的带部分主元选择的 LU 分解由一个排列矩阵 $P$、一个单位下三角矩阵 $L$ 和一个上三角矩阵 $U$ 定义，满足 $P A = L U$。求解 $A x = b$ 可以在应用 $P$ 之后，通过对 $(L, U)$ 进行前向和后向代入来稳定地实现。\n- 逆矩阵 $A^{-1}$ 是满足 $A A^{-1} = I$ 和 $A^{-1} A = I$ 的线性算子，其中 $I$ 是单位矩阵。$A^{-1}$ 的各列可以作为线性方程组 $A x_j = e_j$ 的唯一解来获得，其中 $e_j$ 是第 $j$ 个标准基向量。\n- 一个正交矩阵 $Q \\in \\mathbb{R}^{n \\times n}$ 满足 $Q^\\top Q = I$。一个对角矩阵 $D = \\mathrm{diag}(d_1,\\dots,d_n)$ 的对角线上元素为 $d_i \\neq 0$，其他位置为 $0$。\n\n问题设定：\n- 对于每个测试用例，考虑一个矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其构造为 $A = Q^\\top D Q$，其中 $Q$ 是正交矩阵，$D$ 是对角元素非零的对角矩阵。其逆矩阵 $A^{-1}$ 的解析形式是已知的，必须仅使用上述正交矩阵和对角矩阵的性质从第一性原理推导得出。不要使用任何预先推导的公式；从基本定义出发进行推理，以获得解析表达式。\n- 通过计算 $A$ 的 LU 分解并使用三角求解方法求解 $A X = I$ 来构造 $A^{-1}$ 的数值近似 $X$。这个 $X$ 就是您基于 LU 分解得到的 $A^{-1}$ 的近似值。\n- 将 Frobenius 范数下的全局相对误差定义为\n$$\n\\mathrm{frel} = \\frac{\\lVert X - A^{-1}\\rVert_F}{\\lVert A^{-1}\\rVert_F}.\n$$\n- 为将误差模式映射到编码在 $D$ 中的谱，通过计算\n$$\nE = X - A^{-1}, \\quad \\widetilde{E} = Q\\, E\\, Q^\\top,\n$$\n将误差转换到 $A$ 的特征基下，使得 $\\widetilde{E}$ 在 $A$ 是对角矩阵的基中表示。对于每个特征方向 $i \\in \\{1,\\dots,n\\}$，定义每个方向上的相对对角误差\n$$\n\\epsilon_i = \\frac{\\left| \\widetilde{E}_{ii} \\right|}{\\left| (A^{-1})_{ii} \\text{ in the eigenbasis} \\right|}.\n$$\n通过计算 $\\log_{10}(|d_i|)$ 和 $\\log_{10}(\\epsilon_i)$ 之间的 Pearson 相关系数来聚合每个方向上的趋势，在对 $\\epsilon_i$ 应用的对数中使用一个小的加性正则化项 $\\delta$ 以避免计算 $\\log_{10}(0)$。使用 $\\delta = 10^{-300}$。如果 $\\log_{10}(|d_i|)$ 的方差为零（例如，当所有 $|d_i|$ 都相等时），则按惯例将相关性定义为 $0.0$。\n- 通过 2-范数条件数来量化谱条件\n$$\n\\kappa_2(A) = \\frac{\\sigma_{\\max}(A)}{\\sigma_{\\min}(A)},\n$$\n对于对称矩阵 $A$，这等于 $\\max_i |d_i| / \\min_i |d_i|$。\n\n测试套件规范：\n对于所有测试用例，使用维度 $n = 12$。对于每个用例，通过以下过程生成 $Q$ 以确保可复现性和定义良好的分布：使用指定的伪随机数生成器种子 $s$，抽取一个具有独立标准正态分布元素的矩阵 $Z \\in \\mathbb{R}^{n \\times n}$；计算一个瘦 QR 分解 $Z = Q R$；令 $S = \\mathrm{diag}(\\mathrm{sign}(R_{11}), \\dots, \\mathrm{sign}(R_{nn}))$，其中 $\\mathrm{sign}(0)$ 定义为 $1$；设置 $Q \\leftarrow Q S$。这将得到一个正交矩阵 $Q$。然后用指定的对角矩阵 $D$ 构成 $A = Q^\\top D Q$。\n\n提供以下四个用例，涵盖理想情况、病态条件、不定性和谱聚类：\n- 用例 1（理想情况，良态）：种子 $s = 0$，$D = \\mathrm{diag}(1,1,\\dots,1)$。\n- 用例 2（对称正定，高度病态）：种子 $s = 1$，$D = \\mathrm{diag}(10^{-6}, 10^{-6 + \\Delta}, \\dots, 10^{6})$，其中包含 $n$ 个从 $10^{-6}$ 到 $10^{6}$ 对数等距分布的量值。\n- 用例 3（对称不定，中度病态，符号交替）：种子 $s = 2$，$D = \\mathrm{diag}(\\sigma_1,\\dots,\\sigma_n)$，其中 $|\\sigma_i|$ 从 $10^{-3}$ 到 $10^{3}$ 对数等距分布，并且 $\\mathrm{sign}(\\sigma_i) = (-1)^{i}$。\n- 用例 4（谱聚类，含微小和中等尺度）：种子 $s = 3$，$D$ 有十个对角元素等于 $10^{-6}$，两个元素等于 $1$，它们的顺序使用相同的种子 $s$ 随机排列。\n\n每个测试用例的所需输出：\n- 计算并返回一个包含三个实数的列表，顺序为 $[\\mathrm{frel}, \\mathrm{corr}, \\kappa_2(A)]$，其中 $\\mathrm{corr}$ 是上文描述的 Pearson 相关系数。\n- 您的程序应生成单行输出，其中包含四个用例的结果，格式为一个由逗号分隔的列表，并用方括号括起来，其中每个元素本身都是按指定顺序排列的三元素列表（例如，$[[a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3],[a_4,b_4,c_4]]$）。不应打印任何其他文本。\n\n所有数值量必须以浮点运算计算，并以无单位的裸实数形式报告。如果出现角度，必须理解为弧度，但本任务中不使用角度。", "solution": "该问题要求我们分析对一类特定矩阵 $A = Q^\\top D Q$ 使用 LU 分解计算矩阵逆的数值误差，并将此误差与矩阵的谱相关联。我们必须首先验证问题的各项前提，如果前提有效，则提供一个完整的解析解和数值解。该问题是适定的，在数值线性代数方面有科学依据，并为确定性和可复现的解决方案提供了所有必要信息。因此，我们可以着手解决。\n\n解决过程包括三个主要阶段：\n1.  从第一性原理推导逆矩阵 $A^{-1}$ 的解析形式。这将作为我们误差计算的基准真相。\n2.  指定使用 LU 分解计算逆矩阵近似值（我们表示为 $X$）的数值算法。\n3.  定义并计算指定的误差度量（$\\mathrm{frel}$、$\\mathrm{corr}$）和条件数（$\\kappa_2(A)$）。\n\n**1. 逆矩阵的解析推导**\n\n矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 由 $A = Q^\\top D Q$ 给出，其中 $Q$ 是满足 $Q^\\top Q = Q Q^\\top = I$ 的正交矩阵，$D = \\mathrm{diag}(d_1, \\dots, d_n)$ 是对角元素非零 $d_i \\neq 0$ 的对角矩阵。逆矩阵 $A^{-1}$ 由属性 $A A^{-1} = I$ 定义。\n\n为了找到 $A^{-1}$ 的表达式，我们从定义开始：\n$$\n(Q^\\top D Q) A^{-1} = I\n$$\n我们试图分离出 $A^{-1}$。我们可以在等式两边同时左乘 $Q$：\n$$\nQ (Q^\\top D Q) A^{-1} = Q I\n$$\n利用矩阵乘法的结合律，我们对各项进行分组：\n$$\n(Q Q^\\top) (D Q) A^{-1} = Q\n$$\n由于 $Q$ 是正交的，$Q Q^\\top = I$。方程简化为：\n$$\nI (D Q) A^{-1} = Q \\implies (D Q) A^{-1} = Q\n$$\n接下来，我们左乘 $D$ 的逆矩阵。由于 $D$ 是一个对角元素非零 $d_i$ 的对角矩阵，其逆矩阵 $D^{-1}$ 就是对角元素为 $1/d_i$ 的对角矩阵，即 $D^{-1} = \\mathrm{diag}(1/d_1, \\dots, 1/d_n)$。左乘得到：\n$$\nD^{-1} (D Q) A^{-1} = D^{-1} Q\n$$\n$$\n(D^{-1} D) (Q A^{-1}) = D^{-1} Q\n$$\n由于 $D^{-1} D = I$，我们有：\n$$\nI (Q A^{-1}) = D^{-1} Q \\implies Q A^{-1} = D^{-1} Q\n$$\n最后，为了分离出 $A^{-1}$，我们左乘 $Q^\\top$。由于 $Q^{-1}=Q^\\top$：\n$$\nQ^\\top (Q A^{-1}) = Q^\\top D^{-1} Q\n$$\n$$\n(Q^\\top Q) A^{-1} = Q^\\top D^{-1} Q\n$$\n由于 $Q^\\top Q = I$，我们得到解析逆矩阵的闭式表达式：\n$$\nA^{-1} = Q^\\top D^{-1} Q\n$$\n该表达式将用作与数值近似进行比较的精确基准真相。\n\n**2. 逆矩阵的数值计算**\n\n逆矩阵的数值近似（表示为 $X$）通过求解矩阵方程 $AX=I$ 来找到。这是一个标准方法，其中 $X$ 的每一列（例如 $x_j$）是线性方程组 $Ax_j = e_j$ 的解，其中 $e_j$ 是第 $j$ 个标准基向量（即单位矩阵 $I$ 的第 $j$ 列）。\n\n该过程利用带部分主元选择的 LU 分解。首先，我们将 $A$ 分解为 $P A = L U$，其中 $P$ 是一个排列矩阵，$L$ 是一个单位下三角矩阵，$U$ 是一个上三角矩阵。然后，方程组 $A x_j = e_j$ 被重写为 $P^{-1} L U x_j = e_j$，或 $L U x_j = P e_j$。对于每一列 $e_j$，我们分两步求解该方程组：\n- 前向代入：求解 $L y_j = P e_j$ 以得到中间向量 $y_j$。\n- 后向代入：求解 $U x_j = y_j$ 以得到解向量 $x_j$。\n\n对所有列 $j=1, \\dots, n$ 执行这些步骤，以构建完整的矩阵 $X = [x_1, \\dots, x_n]$。\n\n**3. 误差度量与谱分析**\n\n有了精确逆矩阵 $A^{-1}$ 及其数值近似 $X$，我们就可以量化误差及其与 $A$ 的谱之间的关系。\n\n- **全局相对误差 ($\\mathrm{frel}$)**：总误差在 Frobenius 范数下度量。误差矩阵为 $E = X - A^{-1}$。相对误差为：\n$$\n\\mathrm{frel} = \\frac{\\lVert X - A^{-1}\\rVert_F}{\\lVert A^{-1}\\rVert_F} = \\frac{\\lVert E \\rVert_F}{\\lVert A^{-1}\\rVert_F}\n$$\n其中矩阵 $M$ 的 Frobenius 范数是 $\\lVert M \\rVert_F = \\sqrt{\\sum_{i,j} |M_{ij}|^2}$。\n\n- **特征基中的误差与相关性 ($\\mathrm{corr}$)**：矩阵构造 $A = Q^\\top D Q$ 是 $A$ 的谱分解，因为 $A$ 是对称的（$A^\\top = (Q^\\top D Q)^\\top = Q^\\top D^\\top Q = Q^\\top D Q = A$）。$A$ 的特征值是 $D$ 的对角元素 $d_i$，相应的特征向量是 $Q^\\top$ 的列向量。为了分析在此特征基下的误差，我们将误差矩阵 $E$ 转换到这个基中：\n$$\n\\widetilde{E} = Q E Q^\\top\n$$\n在这个基中，矩阵 $A$ 是对角矩阵（$Q A Q^\\top = D$），其逆矩阵也是对角矩阵（$Q A^{-1} Q^\\top = D^{-1}$）。$\\widetilde{E}$ 的对角元素（表示为 $\\widetilde{E}_{ii}$）代表了沿每个特征方向的误差分量。每个方向上的相对对角误差 $\\epsilon_i$ 定义为误差分量的大小与该方向上真实逆矩阵分量大小的比值：\n$$\n\\epsilon_i = \\frac{\\left| \\widetilde{E}_{ii} \\right|}{\\left| (A^{-1})_{ii} \\text{ in the eigenbasis} \\right|} = \\frac{|\\widetilde{E}_{ii}|}{|(D^{-1})_{ii}|} = |\\widetilde{E}_{ii}| |d_i|\n$$\n然后我们计算向量 $u$ 和 $v$ 之间的 Pearson 相关系数 $\\mathrm{corr}$，其分量分别为 $u_i = \\log_{10}(|d_i|)$ 和 $v_i = \\log_{10}(\\epsilon_i + \\delta)$，其中 $\\delta=10^{-300}$ 是一个小的正则化项。正相关表示误差对于较大的特征值更大，而负相关表示误差对于较小的特征值更大。按照惯例，如果 $u_i$ 的方差为零（即所有 $|d_i|$ 都相等），则相关系数定义为 $0.0$。\n\n- **条件数 ($\\kappa_2(A)$)**：一个矩阵的 2-范数条件数是其最大奇异值与最小奇异值的比值，$\\kappa_2(A) = \\sigma_{\\max}(A) / \\sigma_{\\min}(A)$。对于像 $A$ 这样的对称矩阵，奇异值是特征值的绝对值。由于 $A$ 的特征值是 $D$ 的元素 $d_i$，所以奇异值是 $|d_i|$。因此，条件数由下式给出：\n$$\n\\kappa_2(A) = \\frac{\\max_i |d_i|}{\\min_i |d_i|}\n$$\n这个量衡量了 $Ax=b$ 的解对 $A$ 和 $b$ 中扰动的敏感性。一个大的 $\\kappa_2(A)$ 表明矩阵是病态的，对于这类矩阵，数值计算的准确性预计会较低。\n\n实现将按以下步骤进行：为每个测试用例构造矩阵，执行所述的数值计算，并报告三个指定的量：$[\\mathrm{frel}, \\mathrm{corr}, \\kappa_2(A)]$。", "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Computes and benchmarks matrix inverse via LU factorization for four test cases.\n    \"\"\"\n    \n    n = 12\n    delta = 10**-300.0\n\n    test_cases_spec = [\n        {'s': 0, 'case_type': 'identity'},\n        {'s': 1, 'case_type': 'spd_ill_cond'},\n        {'s': 2, 'case_type': 'indefinite_ill_cond'},\n        {'s': 3, 'case_type': 'clustered_spectrum'},\n    ]\n\n    all_results = []\n\n    for spec in test_cases_spec:\n        s = spec['s']\n        case_type = spec['case_type']\n\n        # 1. Generate the orthogonal matrix Q\n        rng = np.random.default_rng(s)\n        Z = rng.standard_normal((n, n))\n        Q_qr, R_qr = np.linalg.qr(Z)\n        \n        # Ensure a unique Q by forcing the diagonal of R to be positive\n        signs = np.sign(np.diag(R_qr))\n        signs[signs == 0] = 1.0  # As per problem, sign(0) is 1\n        S = np.diag(signs)\n        Q = Q_qr @ S\n\n        # 2. Construct the diagonal matrix D for the current case\n        if case_type == 'identity':\n            d = np.ones(n)\n        elif case_type == 'spd_ill_cond':\n            d = np.logspace(-6, 6, n)\n        elif case_type == 'indefinite_ill_cond':\n            mags = np.logspace(-3, 3, n)\n            sign_vec = (-1.0) ** np.arange(n)\n            d = mags * sign_vec\n        elif case_type == 'clustered_spectrum':\n            d_vals = [10**-6.0] * 10 + [1.0] * 2\n            rng_permute = np.random.default_rng(s)\n            rng_permute.shuffle(d_vals)\n            d = np.array(d_vals)\n        \n        D = np.diag(d)\n        \n        # 3. Construct the matrix A\n        A = Q.T @ D @ Q\n\n        # 4. Compute the analytical inverse A_inv_true\n        D_inv = np.diag(1.0 / d)\n        A_inv_true = Q.T @ D_inv @ Q\n\n        # 5. Compute the numerical inverse X using LU factorization\n        lu, piv = linalg.lu_factor(A)\n        I = np.eye(n)\n        X = linalg.lu_solve((lu, piv), I)\n\n        # 6. Compute the required metrics\n        \n        # frel: Global relative error\n        E = X - A_inv_true\n        frel = np.linalg.norm(E, 'fro') / np.linalg.norm(A_inv_true, 'fro')\n        \n        # kappa_2: Condition number\n        kappa_2 = np.max(np.abs(d)) / np.min(np.abs(d))\n        \n        # corr: Pearson correlation coefficient\n        log_d_abs = np.log10(np.abs(d))\n        \n        if np.var(log_d_abs) == 0:\n            corr = 0.0\n        else:\n            E_tilde = Q @ E @ Q.T\n            E_tilde_diag = np.diag(E_tilde)\n            \n            # Per-direction relative diagonal error\n            epsilon = np.abs(E_tilde_diag) * np.abs(d)\n            \n            log_epsilon = np.log10(epsilon + delta)\n            \n            # Pearson correlation\n            corr_matrix = np.corrcoef(log_d_abs, log_epsilon)\n            corr = corr_matrix[0, 1]\n\n        all_results.append(f\"[{frel},{corr},{kappa_2}]\")\n\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3539201"}]}