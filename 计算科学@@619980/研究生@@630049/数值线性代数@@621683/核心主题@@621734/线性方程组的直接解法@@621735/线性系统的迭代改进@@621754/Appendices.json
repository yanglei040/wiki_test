{"hands_on_practices": [{"introduction": "迭代求精的核心思想是在速度和精度之间取得平衡。本练习将指导您从零开始实现一个混合精度迭代求精求解器 [@problem_id:3245146]。您将使用低精度（单精度）浮点运算来执行计算密集的 LU 分解，同时利用高精度（双精度）来计算残差，这是保证最终解准确性的关键步骤。通过这个实践，您将掌握迭代求精的底层机制，并学会在实际代码中有效管理不同精度的算术运算。", "problem": "实现一个程序，该程序使用混合精度迭代求精方法求解线性方程组。给定一个非奇异方阵 $A \\in \\mathbb{R}^{n \\times n}$ 和一个右端向量 $b \\in \\mathbb{R}^{n}$。目标是通过使用低精度分解和求解，并结合高精度残差计算，来计算 $A x = b$ 的一个改进解。您的程序必须在单精度（即使用 $32$ 位浮点算术）下对 $A$ 进行带部分主元分解的 LU 分解，用它来获得一个单精度的初始解，然后使用残差校正，在双精度（即使用 $64$ 位浮点算术）下迭代求精解，直到满足指定的停止准则或达到最大迭代次数。\n\n使用以下基础和定义作为您设计的基础：\n- $A x = b$ 的一个近似解 $\\hat{x}$ 的残差为 $r = b - A \\hat{x}$。\n- 向量 $v$ 的诱导无穷范数为 $\\lVert v \\rVert_{\\infty} = \\max_{i} |v_{i}|$。矩阵 $A$ 的诱导无穷范数为 $\\lVert A \\rVert_{\\infty} = \\max_{i} \\sum_{j} |a_{i j}|$。\n- 浮点舍入模型为 $fl(z) = z (1 + \\delta)$，其中 $|\\delta| \\leq u$，$u$ 是单位舍入误差。您将通过对分解和三角求解显式使用单精度算术来模拟低精度，并通过对残差计算和解的更新使用双精度算术来模拟高精度。\n\n您的实现的算法要求：\n- 对每个测试矩阵 $A$，在单精度下构造带部分主元分解的 LU 分解 $P A = L U$，其中 $P$ 是一个置换矩阵，$L$ 是单位下三角矩阵，$U$ 是上三角矩阵。\n- 通过完全在单精度下求解 $L U \\hat{x}_{0} = P b$ 来计算初始近似解 $\\hat{x}_{0}$，然后将 $\\hat{x}_{0}$ 转换为双精度。\n- 对于求精迭代 $k = 0, 1, 2, \\dots$，在双精度下计算残差 $r_{k} = b - A \\hat{x}_{k}$ 和相对向后误差类度量\n$$\n\\eta_{k} = \\frac{\\lVert r_{k} \\rVert_{\\infty}}{\\lVert A \\rVert_{\\infty} \\, \\lVert \\hat{x}_{k} \\rVert_{\\infty} + \\lVert b \\rVert_{\\infty}}.\n$$\n如果分母为 $0$（即 $\\lVert \\hat{x}_{k} \\rVert_{\\infty}$ 和 $\\lVert b \\rVert_{\\infty}$ 均为 $0$），则定义 $\\eta_{k} = 0$。\n- 如果 $\\eta_{k} \\le \\tau$，则停止并报告到目前为止所采取的求精步骤数（即实际执行的校正求解次数，如果初始解已满足容差，则为 $0$）。\n- 否则，在单精度下通过求解 $L U d_{k} = P r_{k}$ 计算校正量 $d_{k}$，将 $d_{k}$ 转换为双精度，并在双精度下设置 $\\hat{x}_{k+1} = \\hat{x}_{k} + d_{k}$。重复此过程直到收敛或达到最大 $K_{\\max}$ 次求精步骤。如果在 $K_{\\max}$ 步内未达到收敛，则报告失败，值为 $-1$。\n\n对所有情况使用以下固定参数：\n- 容差 $\\tau = 10^{-12}$。\n- 最大求精步骤数 $K_{\\max} = 20$。\n\n测试套件：\n在以下四个测试用例上实现并运行您的求解器。对于每个用例，完全按照下文定义 $A$ 和 $b$，并应用相同的算法和参数。\n\n- 情况 $1$（对称正定，通用右端项）：\n  $$\n  A = \\begin{bmatrix}\n  4   1  0 \\\\\n  1   3  1 \\\\\n  0   1  2\n  \\end{bmatrix},\n  \\quad\n  b = \\begin{bmatrix}\n  1 \\\\ 2 \\\\ 3\n  \\end{bmatrix}.\n  $$\n\n- 情况 $2$（零右端项，直接边界情况）：\n  $$\n  A = \\begin{bmatrix}\n  2  -1 \\\\\n  -1  2\n  \\end{bmatrix},\n  \\quad\n  b = \\begin{bmatrix}\n  0 \\\\ 0\n  \\end{bmatrix}.\n  $$\n\n- 情况 $3$（希尔伯特矩阵，病态但非奇异，已知精确解 $x = \\mathbf{1}$）：\n  对于 $n = 5$，令 $H \\in \\mathbb{R}^{5 \\times 5}$ 的元素为 $h_{i j} = \\frac{1}{i + j + 1}$，其中 $i, j \\in \\{0, 1, 2, 3, 4\\}$，并设置 $A = H$ 和 $b = H \\mathbf{1}$，其中 $\\mathbf{1}$ 是 $\\mathbb{R}^{5}$ 中所有元素为一的向量。\n\n- 情况 $4$（缩放的，弱耦合，混合数量级）：\n  $$\n  A = \\begin{bmatrix}\n  10^{-3}  10^{-6}  0  0 \\\\\n  10^{-6}  1  10^{-3}  0 \\\\\n  0  10^{-3}  10^{3}  2 \\\\\n  0  0  2  2 \\times 10^{2}\n  \\end{bmatrix},\n  \\quad\n  b = \\begin{bmatrix}\n  1 \\\\ 2 \\\\ 3 \\\\ 4\n  \\end{bmatrix}.\n  $$\n\n输出规范：\n- 您的程序必须产生单行输出，其中包含一个完全由四个整数组成的列表，按测试用例的顺序排列，每个整数是该用例达到容差所用的求精步骤数，如果方法在 $K_{\\max}$ 步内未收敛，则为 $-1$。该行必须格式化为方括号内由逗号分隔的列表，例如 $[n_{1},n_{2},n_{3},n_{4}]$。\n\n不提供外部输入；所有数据必须在程序内定义。此问题不涉及角度、物理单位或百分比。所有量都是纯数学的，无量纲。", "solution": "该问题要求实现一种混合精度迭代求精算法，用于求解线性方程组 $A x = b$。该方法的核心原理是利用低精度算术的速度来处理计算密集型任务，同时使用高精度算术进行对精度要求高的计算。具体来说，矩阵 $A$ 的计算密集型 LU 分解和随后的三角求解在单精度（$32$ 位浮点算术）下执行。残差计算容易发生灾难性抵消，因此需要更高的精度，故在双精度（$64$ 位浮点算术）下执行。\n\n算法流程如下：\n\n1.  **数据准备与精度管理**：\n    输入矩阵 $A$ 和向量 $b$ 最初被视作双精度实体，我们将其表示为 $A_{dp}$ 和 $b_{dp}$。我们在双精度下计算它们的无穷范数 $\\lVert A \\rVert_{\\infty}$ 和 $\\lVert b \\rVert_{\\infty}$，因为这些值在整个过程中是恒定的，并用于停止准则。对于算法的低精度部分，我们通过对双精度版本进行类型转换，创建矩阵和向量的单精度副本 $A_{sp}$ 和 $b_{sp}$。在 `NumPy` 中，这对应于使用 `numpy.float64` 表示双精度，`numpy.float32` 表示单精度。\n\n2.  **单精度 LU 分解**：\n    我们对单精度矩阵 $A_{sp}$ 进行带部分主元分解的 LU 分解。此分解产生 $P A_{sp} = L_{sp} U_{sp}$，其中 $P$ 是表示行交换的置换矩阵，$L_{sp}$ 是单位下三角矩阵，$U_{sp}$ 是上三角矩阵。由于 `NumPy` 没有提供直接函数以方便的形式获取 $P, L, U$ 因子，我们必须手动实现此分解。我们的实现将生成一个紧凑矩阵，其中包含 $L_{sp}$（在严格下三角部分）和 $U_{sp}$（在上三角部分，包括对角线）的元素，以及一个表示 $P$ 的置换向量。\n\n3.  **初始解**：\n    第一个近似解 $\\hat{x}_{0}$ 完全在单精度下计算。利用该分解，原始方程组 $A x = b$ 被转换为 $L_{sp} U_{sp} \\hat{x}_{0} = P b_{sp}$。这通过两个步骤求解：\n    a.  **前向代换**：求解 $L_{sp} y = P b_{sp}$ 得到中间向量 $y$。\n    b.  **后向代换**：求解 $U_{sp} \\hat{x}_{0} = y$ 得到初始解 $\\hat{x}_{0}$。\n    得到的单精度向量 $\\hat{x}_{0}$ 随后被转换为双精度，用于高精度求精循环。\n\n4.  **迭代求精循环**：\n    求精过程通过迭代来提高解的精度。循环最多运行 $K_{\\max} = 20$ 次求精步骤。设 $\\hat{x}_k$ 为第 $k$ 次迭代时的近似解（其中 $\\hat{x}_0$ 为初始解）。\n\n    a.  **残差计算（双精度）**：残差 $r_k = b_{dp} - A_{dp} \\hat{x}_k$ 使用双精度算术计算。此步骤至关重要，因为它恢复了在单精度计算中丢失的误差信息。\n\n    b.  **收敛准则**：我们评估相对向后误差类度量 $\\eta_k$：\n        $$\n        \\eta_{k} = \\frac{\\lVert r_{k} \\rVert_{\\infty}}{\\lVert A \\rVert_{\\infty} \\, \\lVert \\hat{x}_{k} \\rVert_{\\infty} + \\lVert b \\rVert_{\\infty}}\n        $$\n        所有范数均在双精度下计算。如果 $\\eta_k$ 小于或等于指定的容差 $\\tau = 10^{-12}$，则认为解已收敛，过程终止。报告已执行的求精步骤数 $k$。对于初始检查（$k=0$），如果 $\\eta_0 \\le \\tau$，则报告 $0$ 步。\n\n    c.  **校正步骤（单精度）**：如果解尚未收敛，我们通过求解方程组 $A d_k = r_k$ 来计算校正项 $d_k$。为了效率，我们重用单精度的 LU 因子：$L_{sp} U_{sp} d_k = P r_k$。首先将双精度的残差 $r_k$ 转换为单精度。然后使用单精度的前向和后向代换求解该系统得到 $d_k$。\n\n    d.  **解的更新（双精度）**：将单精度的校正向量 $d_k$ 转换回双精度，并加到当前解上：$\\hat{x}_{k+1} = \\hat{x}_k + d_k$。此更新在双精度下执行，以精确累加校正量。\n\n5.  **终止**：\n    循环在满足收敛准则 $\\eta_k \\le \\tau$ 或完成 $K_{\\max}$ 次求精步骤后终止。如果在检查解 $\\hat{x}_{K_{max}}$ 后循环完成但仍未收敛，则认为该方法失败，并报告值 $-1$。求精次数定义为执行的校正求解的次数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef lu_pivot(A_in):\n    \"\"\"\n    Computes LU factorization with partial pivoting for a matrix A.\n    The matrix A_in is expected to be of single precision (np.float32).\n    \n    Returns:\n    - LU: A matrix containing U in its upper triangle and L in its strict lower triangle.\n    - p: A permutation vector.\n    \"\"\"\n    n = A_in.shape[0]\n    LU = A_in.copy()\n    p = np.arange(n)\n    \n    for j in range(n - 1):\n        # Find pivot in column j (from row j downwards)\n        max_row_idx_local = np.argmax(np.abs(LU[j:, j]))\n        max_row_idx_global = j + max_row_idx_local\n        \n        # Swap rows in LU and permutation vector p\n        if max_row_idx_global != j:\n            LU[[j, max_row_idx_global], :] = LU[[max_row_idx_global, j], :]\n            p[[j, max_row_idx_global]] = p[[max_row_idx_global, j]]\n            \n        # Elimination\n        pivot_val = LU[j, j]\n        # Use a small tolerance for checking non-singularity\n        if np.abs(pivot_val)  np.finfo(np.float32).tiny:\n            multipliers = LU[j + 1:, j] / pivot_val\n            LU[j + 1:, j] = multipliers\n            # Vectorized update of the submatrix\n            LU[j + 1:, j + 1:] -= np.outer(multipliers, LU[j, j + 1:])\n            \n    return LU, p\n\ndef solve_lu_sp(LU_sp, p_sp, b_sp):\n    \"\"\"\n    Solves the system LUx = Pb using the output of lu_pivot.\n    All computations are in single precision (np.float32).\n    \"\"\"\n    n = LU_sp.shape[0]\n    \n    # Apply permutation to the right-hand side vector\n    b_perm = b_sp[p_sp]\n    \n    # Forward substitution (solves Ly = b_perm)\n    y = np.zeros(n, dtype=np.float32)\n    for i in range(n):\n        y[i] = b_perm[i] - np.dot(LU_sp[i, :i], y[:i])\n        \n    # Backward substitution (solves Ux = y)\n    x = np.zeros(n, dtype=np.float32)\n    for i in range(n - 1, -1, -1):\n        dot_product = np.dot(LU_sp[i, i + 1:], x[i + 1:])\n        diag_val = LU_sp[i, i]\n        if np.abs(diag_val)  np.finfo(np.float32).tiny:\n             x[i] = (y[i] - dot_product) / diag_val\n        else:\n             # This case should ideally not be hit with non-singular matrices\n             # and proper pivoting, but provides a fallback.\n             x[i] = (y[i] - dot_product) / np.finfo(np.float32).tiny\n    return x\n\ndef mixed_precision_refinement(A_in, b_in, K_max, tau):\n    \"\"\"\n    Performs mixed-precision iterative refinement to solve Ax = b.\n    \"\"\"\n    n = A_in.shape[0]\n    \n    # Master copies and norms in double precision (np.float64)\n    A_dp = A_in.astype(np.float64)\n    b_dp = b_in.astype(np.float64)\n    norm_A_inf = np.linalg.norm(A_dp, ord=np.inf)\n    norm_b_inf = np.linalg.norm(b_dp, ord=np.inf)\n    \n    # Factorization in single precision (np.float32)\n    A_sp = A_dp.astype(np.float32)\n    b_sp = b_dp.astype(np.float32)\n    LU_sp, p_sp = lu_pivot(A_sp)\n    \n    # Initial solution computed in single precision\n    x_k_sp = solve_lu_sp(LU_sp, p_sp, b_sp)\n    x_k_dp = x_k_sp.astype(np.float64)\n    \n    # --- Start of the iterative refinement loop ---\n    # k represents the number of refinement steps performed.\n    for k in range(K_max + 1):\n        # Calculate residual in double precision\n        r_k_dp = b_dp - (A_dp @ x_k_dp)\n        \n        # Check stopping criterion\n        norm_r_inf = np.linalg.norm(r_k_dp, ord=np.inf)\n        norm_x_inf = np.linalg.norm(x_k_dp, ord=np.inf)\n        \n        denominator = norm_A_inf * norm_x_inf + norm_b_inf\n        eta_k = norm_r_inf / denominator if denominator != 0.0 else 0.0\n        \n        if eta_k = tau:\n            return k\n            \n        # If max iterations reached, break before next correction\n        if k == K_max:\n            break\n            \n        # Solve for correction in single precision\n        r_k_sp = r_k_dp.astype(np.float32)\n        d_k_sp = solve_lu_sp(LU_sp, p_sp, r_k_sp)\n        \n        # Update solution in double precision\n        d_k_dp = d_k_sp.astype(np.float64)\n        x_k_dp += d_k_dp\n        \n    # If the loop completes without converging\n    return -1\n\ndef solve():\n    # Define fixed parameters\n    tau = 1e-12\n    K_max = 20\n\n    # Define the test cases from the problem statement.\n    # Case 1\n    A1 = np.array([\n        [4.0, 1.0, 0.0],\n        [1.0, 3.0, 1.0],\n        [0.0, 1.0, 2.0]\n    ])\n    b1 = np.array([1.0, 2.0, 3.0])\n\n    # Case 2\n    A2 = np.array([\n        [2.0, -1.0],\n        [-1.0, 2.0]\n    ])\n    b2 = np.array([0.0, 0.0])\n\n    # Case 3\n    n3 = 5\n    # Use double precision for construction\n    H3 = np.zeros((n3, n3), dtype=np.float64)\n    for i in range(n3):\n        for j in range(n3):\n            H3[i, j] = 1.0 / (i + j + 1.0)\n    A3 = H3\n    b3 = A3 @ np.ones(n3, dtype=np.float64)\n\n    # Case 4\n    A4 = np.array([\n        [1e-3, 1e-6, 0.0, 0.0],\n        [1e-6, 1.0, 1e-3, 0.0],\n        [0.0, 1e-3, 1e3, 2.0],\n        [0.0, 0.0, 2.0, 2e2]\n    ])\n    b4 = np.array([1.0, 2.0, 3.0, 4.0])\n\n    test_cases = [\n        (A1, b1),\n        (A2, b2),\n        (A3, b3),\n        (A4, b4)\n    ]\n\n    results = []\n    for A, b in test_cases:\n        num_steps = mixed_precision_refinement(A, b, K_max, tau)\n        results.append(num_steps)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3245146"}, {"introduction": "理解了迭代求精的实现方式后，下一个自然的问题是：它究竟有多有效？本练习 [@problem_id:3245403] 将通过一个经典的病态问题——求解以希尔伯特矩阵为系数的线性系统——来量化该方法的收敛效果。您的任务是跟踪每次迭代后解的有效数字位数的变化，从而直观地看到迭代求精是如何逐步“恢复”因病态性而损失的精度。这个过程将加深您对算法性能及其在挑战性问题中作用的理解。", "problem": "您需要实现并分析用于求解带有希尔伯特矩阵（一个经典的病态矩阵）的线性系统的迭代求精方法。目标是量化每次迭代中解的精度能获得多少位十进制数字的提升。\n\n使用的基本依据和定义如下：\n- 线性系统的形式为 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$，$x \\in \\mathbb{R}^{n}$，$b \\in \\mathbb{R}^{n}$。希尔伯特矩阵 $H \\in \\mathbb{R}^{n \\times n}$ 定义为 $H_{ij} = \\frac{1}{i + j - 1}$，其中 $i, j \\in \\{1, \\dots, n\\}$。\n- 第 $k$ 次迭代的残差为 $r^{(k)} = b - A x^{(k)}$。\n- 第 $k$ 次迭代的迭代求精更新通过求解 $A d^{(k)} = r^{(k)}$ 生成修正量 $d^{(k)}$，并设置 $x^{(k+1)} = x^{(k)} + d^{(k)}$。\n- 第 $k$ 次迭代时正确的十进制数字位数由下式定义：\n$$\nD^{(k)} = -\\log_{10}\\!\\left(\\frac{\\lVert x^{(k)} - x^\\star \\rVert_\\infty}{\\lVert x^\\star \\rVert_\\infty}\\right),\n$$\n其中 $x^\\star$ 是精确解。为了在双精度算术中保持数值稳定性，报告在 $16$ 位饱和的 $D^{(k)}$，即使用：\n$$\n\\tilde{D}^{(k)} = -\\log_{10}\\!\\left(\\max\\!\\left(\\frac{\\lVert x^{(k)} - x^\\star \\rVert_\\infty}{\\lVert x^\\star \\rVert_\\infty},\\,10^{-16}\\right)\\right).\n$$\n- 每次迭代中正确数字位数的增益为 $G^{(k)} = \\tilde{D}^{(k)} - \\tilde{D}^{(k-1)}$，其中 $k \\ge 1$。初始精度 $\\tilde{D}^{(0)}$ 对应于在进行任何求精迭代之前，通过单次直接求解 $A x = b$ 所得解的精度。\n\n科学真实性与设置：\n- 希尔伯特矩阵是众所周知的病态矩阵，其条件数随 $n$ 的增加而迅速增长。迭代求精可以通过求解残差方程来校正累积误差，从而改善解的质量。\n- 所有计算均使用双精度（64位）浮点运算。\n\n程序要求：\n- 将 $A$ 构造为大小为 $n$ 的希尔伯特矩阵。\n- 将真实解设置为 $x^\\star = \\mathbf{1}$（长度为 $n$ 的全1向量）。计算 $b = A x^\\star$。\n- 通过直接求解 $A x = b$ 来计算初始解 $x^{(0)}$。\n- 按照上述描述执行 $m$ 步迭代求精。\n- 在每次迭代 $k \\in \\{1, \\dots, m\\}$ 后，计算并记录 $G^{(k)}$。\n- 对每个测试用例，输出列表 $[G^{(1)}, G^{(2)}, \\dots, G^{(m)}]$。\n\n测试套件：\n- 用例 1：$n = 2$，$m = 5$（边界情况，相对良态）。\n- 用例 2：$n = 5$，$m = 5$（中度病态）。\n- 用例 3：$n = 8$，$m = 5$（具有挑战性的病态）。\n- 用例 4：$n = 12$，$m = 5$（严重病态的边缘情况）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含所有测试用例的每次迭代增益，格式为逗号分隔的列表的列表，不含空格，并用方括号括起来。例如，输出应类似于 $[[g_{1,1},\\dots,g_{1,m}],[g_{2,1},\\dots,g_{2,m}],\\dots]$，其中 $g_{i,k}$ 是测试用例 $i$ 中第 $k$ 次迭代的增益。\n- 所有数字都应以标准十进制浮点数格式打印，本问题不涉及任何物理单位。", "solution": "用户提供的问题陈述已经过独立验证，被确定为数值线性代数领域中一个定义明确、有科学依据且客观的问题。该问题没有矛盾、歧义和事实错误。因此，下面提供一个完整的解决方案。\n\n该问题要求实现并分析用于求解线性系统 $A x = b$ 的迭代求精算法，其中 $A$ 是臭名昭著的病态希尔伯特矩阵。目标是量化在每个求精步骤中解的精度增益，以十进制位数度量。\n\n大小为 $n \\times n$ 的希尔伯特矩阵 $H$ 由其元素 $H_{ij} = \\frac{1}{i + j - 1}$ 定义，其中行和列索引 $i, j$ 从 1 开始。其条件数随 $n$ 的增加而极快增长，使其成为数值稳定性的经典测试用例。对于系统 $A x = b$，当 $A$ 是病态矩阵时，使用如LU分解等直接方法求解会累积显著的浮点误差，导致计算出的解不准确。\n\n迭代求精是一种旨在提高计算解精度的过程。设 $x^{(0)}$ 是通过直接求解器获得的初始解。由于有限精度算术， $x^{(0)}$ 与真实解 $x^\\star$ 相差一个误差 $e^{(0)} = x^\\star - x^{(0)}$。该方法的基础在于估计并校正这个误差。\n\n近似解 $x^{(k)}$ 的残差向量定义为 $r^{(k)} = b - A x^{(k)}$。通过代入 $b = A x^\\star$，残差可以与真实误差 $e^{(k)} = x^\\star - x^{(k)}$ 相关联：\n$$\nr^{(k)} = A x^\\star - A x^{(k)} = A (x^\\star - x^{(k)}) = A e^{(k)}\n$$\n这个方程表明，真实误差 $e^{(k)}$ 是线性系统 $A e^{(k)} = r^{(k)}$ 的解。尽管我们无法精确计算 $e^{(k)}$（因为这等同于完美解决原始问题），但我们可以通过求解残差系统来计算它的一个近似值，我们将其表示为 $d^{(k)}$：\n$$\nA d^{(k)} = r^{(k)}\n$$\n向量 $d^{(k)}$ 作为对当前解的计算修正。下一个（希望更精确的）解 $x^{(k+1)}$ 是通过应用此修正获得的：\n$$\nx^{(k+1)} = x^{(k)} + d^{(k)}\n$$\n此过程迭代重复。迭代求精的一个关键方面是，残差 $r^{(k)}$ 理想上应以比其余计算更高的精度进行计算。然而，本问题指定对所有运算使用标准的双精度（64位浮点数），这使我们能够观察到在没有更高精度可用时该方法的局限性。\n\n为了量化算法的性能，我们在每一步测量解的精度。解 $x^{(k)}$ 中正确的十进制数字位数是相对于真实解 $x^\\star$ 定义的：\n$$\nD^{(k)} = -\\log_{10}\\!\\left(\\frac{\\lVert x^{(k)} - x^\\star \\rVert_\\infty}{\\lVert x^\\star \\rVert_\\infty}\\right)\n$$\n其中 $\\lVert \\cdot \\rVert_\\infty$ 是无穷范数（向量各分量绝对值的最大值）。由于双精度浮点运算具有大约 $16$ 位十进制数字的有限精度，因此使用一个不超过此限制并避免对零取对数的饱和精度度量是实用的：\n$$\n\\tilde{D}^{(k)} = -\\log_{10}\\!\\left(\\max\\!\\left(\\frac{\\lVert x^{(k)} - x^\\star \\rVert_\\infty}{\\lVert x^\\star \\rVert_\\infty},\\,10^{-16}\\right)\\right)\n$$\n第 $k$ 次迭代的精度增益是与上一步正确位数的差异：\n$$\nG^{(k)} = \\tilde{D}^{(k)} - \\tilde{D}^{(k-1)} \\quad \\text{for } k \\ge 1\n$$\n此处，$\\tilde{D}^{(0)}$ 是通过直接求解得到的初始解 $x^{(0)}$ 的精度。\n\n每个测试用例 $(n, m)$ 的算法流程如下：\n1.  **系统设置**：\n    *   构造 $n \\times n$ 的希尔伯特矩阵 $A$，其中基于零的行 $i$ 和列 $j$ 处的元素为 $A_{ij} = \\frac{1}{(i+1) + (j+1) - 1} = \\frac{1}{i+j+1}$。\n    *   将真实解定义为全1向量，$x^\\star = \\mathbf{1} \\in \\mathbb{R}^n$。\n    *   计算右端向量 $b = A x^\\star$。这确保了误差计算有一个已知的基准真相。由于对所有 $j$ 都有 $x^\\star_j = 1$，每个分量 $b_i$ 是 $A$ 的第 $i$ 行的和：$b_i = \\sum_{j=1}^{n} \\frac{1}{i+j-1}$。\n\n2.  **初始解**：\n    *   使用标准的直接数值求解器求解系统 $A x = b$，计算初始近似解 $x^{(0)}$。\n    *   计算初始精度 $\\tilde{D}^{(0)}$。\n\n3.  **迭代求精**：\n    *   初始化当前解 $x \\leftarrow x^{(0)}$ 和先前的精度 $D_{prev} \\leftarrow \\tilde{D}^{(0)}$。\n    *   对于 $k$ 从 $1$ 到 $m$：\n        a. 计算残差：$r = b - A x$。\n        b. 求解修正量：$A d = r$。\n        c. 更新解：$x \\leftarrow x + d$。\n        d. 计算新精度：$D_{current} = \\tilde{D}^{(k)}$。\n        e. 计算并记录增益：$G^{(k)} = D_{current} - D_{prev}$。\n        f. 更新先前的精度：$D_{prev} \\leftarrow D_{current}$。\n\n4.  **输出**：报告每个测试用例的增益列表 $[G^{(1)}, G^{(2)}, \\dots, G^{(m)}]$。\n\n对于条件数较低的矩阵（例如，$n=2$），初始解已经非常精确，求精几乎不产生增益。随着 $n$ 的增加（$n=5, 8$），条件数增长，初始解质量下降，预计迭代求精将在最初几次迭代中提供显著的精度增益。对于 $n=12$，希尔伯特矩阵的条件数超过 $10^{16}$，这是双精度数的近似精度极限。此时，计算出的残差被噪声主导，求精过程预计会停滞或失败，产生极小甚至负的增益。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and analyzes iterative refinement for linear systems involving\n    the Hilbert matrix for a suite of test cases.\n    \"\"\"\n    # Test cases are defined as tuples (n, m), where n is the matrix size\n    # and m is the number of refinement iterations.\n    test_cases = [\n        (2, 5),   # Case 1: Well-conditioned\n        (5, 5),   # Case 2: Moderately ill-conditioned\n        (8, 5),   # Case 3: Challenging ill-conditioning\n        (12, 5),  # Case 4: Severe ill-conditioning\n    ]\n\n    all_results = []\n\n    for n, m in test_cases:\n        # Step 1: System Setup\n        # Construct the n x n Hilbert matrix A.\n        # For 0-based indices i, j, the formula is H_ij = 1 / (i + j + 1).\n        A = np.fromfunction(lambda i, j: 1.0 / (i + j + 1), (n, n), dtype=float)\n\n        # Define the true solution as the all-ones vector.\n        x_star = np.ones(n, dtype=float)\n\n        # Calculate the right-hand side vector b = A * x_star.\n        b = A @ x_star\n\n        # Define a helper function to calculate the number of correct digits.\n        def get_saturated_digits(x_approx, x_true):\n            \"\"\"\n            Calculates the saturated number of correct base-10 digits.\n            \"\"\"\n            # The infinity norm of x_star is always 1.0.\n            norm_x_true_inf = 1.0\n            \n            # Calculate relative error using the infinity norm.\n            relative_error = np.linalg.norm(x_approx - x_true, np.inf) / norm_x_true_inf\n            \n            # Apply saturation at 10^-16 to handle finite precision and avoid log(0).\n            effective_error = max(relative_error, 1e-16)\n            \n            return -np.log10(effective_error)\n\n        # Step 2: Initial Solution\n        # Compute the initial solution x^(0) using a direct solver.\n        x_k = np.linalg.solve(A, b)\n\n        # Calculate the initial number of correct digits, D_tilde^(0).\n        D_prev = get_saturated_digits(x_k, x_star)\n\n        # Step 3: Iterative Refinement\n        gains_for_case = []\n        for _ in range(m):\n            # a. Compute the residual in double precision.\n            r_k = b - A @ x_k\n\n            # b. Solve for the correction vector d.\n            d_k = np.linalg.solve(A, r_k)\n\n            # c. Update the solution.\n            x_k = x_k + d_k\n\n            # d. Calculate the new accuracy.\n            D_current = get_saturated_digits(x_k, x_star)\n\n            # e. Calculate and record the gain.\n            gain = D_current - D_prev\n            gains_for_case.append(gain)\n\n            # f. Update the previous accuracy for the next iteration.\n            D_prev = D_current\n        \n        all_results.append(gains_for_case)\n\n    # Final print statement in the exact required format.\n    # Format each sublist of gains into a comma-separated string \"[g1,g2,...]\".\n    formatted_sublists = [f\"[{','.join(map(str, sublist))}]\" for sublist in all_results]\n    # Join all formatted sublists into the final output string.\n    print(f\"[{','.join(formatted_sublists)}]\")\n\nsolve()\n```", "id": "3245403"}, {"introduction": "在现代高性能计算中，算法的性能与数值稳定性和精度同等重要。本练习 [@problem_id:3552192] 将数值分析与计算机体系结构性能建模相结合，要求您为在 GPU 上运行的混合精度迭代求精构建一个基于 Roofline 模型的性能分析器。您的目标是在满足给定精度要求的前提下，通过搜索不同的精度组合来找到总执行时间最短的“最优”配置。这项实践将使您能够量化不同精度选择对计算时间和内存带宽的实际影响，从而做出性能最优的决策。", "problem": "考虑在图形处理器（GPU）上使用混合精度迭代细化方法求解一个稠密线性系统 $A x = b$。设 $A \\in \\mathbb{R}^{n \\times n}$ 为非奇异矩阵，其条件数 $\\kappa(A)$ 在相容范数下度量。混合精度迭代细化算法包括对 $A$ 的初始低精度分解、一次初始求解，然后是重复的细化迭代，在每次迭代中，以更高精度计算残差，通过使用低精度因子求解三角系统获得修正量，并以指定精度更新解。\n\n您需要构建一个基于 Roofline 的性能模型，并用它来选择精度和细化步数，以在达到指定精度目标的同时最小化总时间。您必须将总时间建模为各个核函数时间的总和，每个核函数的时间都由 Roofline 模型估算。最终答案必须是一个完整的可运行程序，该程序为提供的测试套件实现此模型，并以确切指定的格式打印结果。\n\n使用以下基本依据：\n- Roofline 模型：对于一个以精度 $p$ 运行、浮点运算次数为 $f$、数据移动量为 $b$（单位为字节）的核函数，其时间为\n$$ T_{\\mathrm{kernel}}(p) = \\max\\left( \\frac{f}{P_p}, \\frac{b}{B} \\right), $$\n其中 $P_p$ 是精度 $p$ 的峰值浮点吞吐量（单位为每秒浮点运算次数），$B$ 是持续内存带宽（单位为每秒字节数）。\n- 混合精度迭代细化收缩：将收缩因子 $\\rho$ 定义为\n$$ \\rho = \\kappa(A) \\, u_{p_f}, $$\n其中 $u_{p_f}$ 是分解精度 $p_f$ 的单位舍入误差。经典迭代细化收敛的一个充分条件是 $\\rho  1$。将几何项减小到目标安全余量以下所需的细化步数 $k$ 可通过以下模型计算\n$$ k = \\left\\lceil \\frac{\\log(\\delta - \\delta_{\\mathrm{floor}})}{\\log(\\rho)} \\right\\rceil, $$\n假设 $\\delta  \\delta_{\\mathrm{floor}}$ 且 $\\rho \\in (0,1)$，其中 $\\delta$ 是所需的目标界限，$\\delta_{\\mathrm{floor}}$ 是由于残差计算和更新中的有限精度而导致的可达到的误差下界。\n- 误差下界模型：将下界定义为\n$$ \\delta_{\\mathrm{floor}} = u_{p_r} + u_{p_u}, $$\n其中 $u_{p_r}$ 和 $u_{p_u}$ 分别是残差精度和更新精度的单位舍入误差。\n\n使用稠密运算的浮点运算计数和字节模型：\n- 分解（稠密 LU，不考虑主元选择的成本建模）：浮点运算次数 $f_{\\mathrm{LU}} = \\frac{2}{3} n^3$，字节数 $b_{\\mathrm{LU}} = c_{\\mathrm{LU}} \\, n^2 \\, s_{p_f}$，其中 $c_{\\mathrm{LU}}$ 是一个给定常数，$s_{p}$ 是精度 $p$ 的浮点类型的大小（单位为字节）。\n- 一次三角求解：浮点运算次数 $f_{\\mathrm{TS}} = n^2$，字节数 $b_{\\mathrm{TS}} = n^2 \\, s_{p_f}$。初始求解需要两次三角求解，每次细化迭代需要两次三角求解。\n- 残差计算 $r = b - A x$：浮点运算次数 $f_{\\mathrm{RES}} = 2 n^2$，字节数 $b_{\\mathrm{RES}} = (n^2 + 3 n) \\, s_{p_r}$。\n- 更新 $x \\leftarrow x + \\Delta x$：浮点运算次数 $f_{\\mathrm{UP}} = n$，字节数 $b_{\\mathrm{UP}} = 3 n \\, s_{p_u}$。\n\n单位舍入误差与精度的关系如下：\n- 半精度（$16$ 位）：$u_{16} = 2^{-11}$，$s_{16} = 2$。\n- 单精度（$32$ 位）：$u_{32} = 2^{-24}$，$s_{32} = 4$。\n- 双精度（$64$ 位）：$u_{64} = 2^{-53}$，$s_{64} = 8$。\n\n总建模时间为\n$$ T_{\\mathrm{total}} = T_{\\mathrm{LU}}(p_f) + 2 T_{\\mathrm{TS}}(p_f) + k \\left[ T_{\\mathrm{RES}}(p_r) + 2 T_{\\mathrm{TS}}(p_f) + T_{\\mathrm{UP}}(p_u) \\right]. $$\n\n可行性约束：\n- 收敛性：$\\rho = \\kappa(A) \\, u_{p_f}  1$。\n- 精度目标：$\\delta_{\\mathrm{floor}}  \\delta$，其中 $\\delta$ 是最终误差代理的给定目标界限。\n\n搜索空间：\n- 分解精度 $p_f \\in \\{16,32\\}$。\n- 残差精度 $p_r \\in \\{32,64\\}$。\n- 更新精度 $p_u \\in \\{32,64\\}$。\n\n您的程序必须对下面的测试套件中的每个测试用例，搜索上述离散空间，测试可行性，使用给定的模型计算所需的细化步数 $k$，计算总时间 $T_{\\mathrm{total}}$，并返回最小化 $T_{\\mathrm{total}}$ 的组合 $(p_f, p_r, p_u, k)$。如果没有任何组合是可行的，则为该测试用例返回哨兵值 $[-1,-1,-1,-1,-1.0]$。\n\n测试套件和参数：\n- 测试用例 1：\n    - $n = 4096$，\n    - $\\kappa(A) = 10^5$，\n    - 目标 $\\delta = 10^{-8}$，\n    - 硬件峰值：$P_{16} = 3.00 \\times 10^{14}$，$P_{32} = 2.00 \\times 10^{13}$，$P_{64} = 1.00 \\times 10^{13}$，\n    - 带宽：$B = 1.50 \\times 10^{12}$，\n    - $c_{\\mathrm{LU}} = 6$。\n- 测试用例 2：\n    - $n = 2048$，\n    - $\\kappa(A) = 2.00 \\times 10^{3}$，\n    - 目标 $\\delta = 10^{-5}$，\n    - 硬件峰值：$P_{16} = 3.00 \\times 10^{14}$，$P_{32} = 2.00 \\times 10^{13}$，$P_{64} = 1.00 \\times 10^{13}$，\n    - 带宽：$B = 9.00 \\times 10^{11}$，\n    - $c_{\\mathrm{LU}} = 6$。\n- 测试用例 3：\n    - $n = 1024$，\n    - $\\kappa(A) = 1.00 \\times 10^{2}$，\n    - 目标 $\\delta = 10^{-18}$，\n    - 硬件峰值：$P_{16} = 3.00 \\times 10^{14}$，$P_{32} = 2.00 \\times 10^{13}$，$P_{64} = 1.00 \\times 10^{13}$，\n    - 带宽：$B = 1.50 \\times 10^{12}$，\n    - $c_{\\mathrm{LU}} = 6$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。此列表中的每个元素本身必须是一个形式为 $[p_f, p_r, p_u, k, T_{\\mathrm{total}}]$ 的列表，其中 $p_f$、$p_r$ 和 $p_u$ 是来自 $\\{16,32,64\\}$ 的整数，$k$ 是一个非负整数，$T_{\\mathrm{total}}$ 是一个以秒为单位的浮点数。对于不可行的测试用例，输出 $[-1,-1,-1,-1,-1.0]$。例如，一个有效的输出可能看起来像 $[[32,64,64,4,0.0032],[32,32,32,2,0.00043],[-1,-1,-1,-1,-1.0]]$。", "solution": "用户提供的问题是数值线性代数和高性能计算领域中一个定义明确的优化任务。它要求构建并应用一个性能模型，为混合精度迭代细化求解器选择最优配置。问题陈述具有科学依据、自成体系且逻辑一致。所有参数、模型和约束都已明确定义。因此，该问题是有效的，并且可以构建一个解。\n\n解决方法是对迭代细化算法所有可能的精度配置组成的离散空间进行穷举搜索。对于每种配置，我们根据数值稳定性和精度要求检查其可行性。对于所有可行的配置，我们使用提供的 Roofline 性能模型计算总执行时间，并找出使该时间最小化的配置。\n\n首先，我们根据问题中的规定定义与浮点精度相关的基本常数：\n- 单位舍入误差：$u_{16} = 2^{-11}$，$u_{32} = 2^{-24}$，$u_{64} = 2^{-53}$。这些值被存储以便于查找。\n- 数据类型大小（字节）：$s_{16} = 2$，$s_{32} = 4$，$s_{64} = 8$。\n\n精度配置 $(p_f, p_r, p_u)$ 的搜索空间给定如下：\n- 分解精度 $p_f \\in \\{16, 32\\}$。\n- 残差计算精度 $p_r \\in \\{32, 64\\}$。\n- 解更新精度 $p_u \\in \\{32, 64\\}$。\n这对每个测试用例定义了总共 $2 \\times 2 \\times 2 = 8$ 种可能的配置进行评估。\n\n对于每个由矩阵维度 $n$、条件数 $\\kappa(A)$、精度目标 $\\delta$ 和硬件特性 ($P_p, B$) 定义的测试用例，我们遍历这 $8$ 种配置中的每一种。\n\n对于一个给定的配置 $(p_f, p_r, p_u)$，我们首先执行两个可行性检查：\n\n1.  **收敛性约束**：迭代过程必须收敛。收缩因子 $\\rho$ 的模型是 $\\rho = \\kappa(A) \\, u_{p_f}$。收敛的条件是 $\\rho  1$。如果不满足此条件，则该配置被视为不可行，我们继续评估下一个配置。\n\n2.  **精度约束**：算法必须能够达到所需的精度 $\\delta$。可达误差受误差下界 $\\delta_{\\mathrm{floor}}$ 的限制，该下界取决于残差计算和解更新的精度。该下界的模型是 $\\delta_{\\mathrm{floor}} = u_{p_r} + u_{p_u}$。只有当 $\\delta_{\\mathrm{floor}}  \\delta$ 时，该配置才是可行的。如果违反此条件，则舍弃该配置。\n\n如果一个配置是可行的，我们继续计算所需的细化迭代次数 $k$。提供的模型是：\n$$ k = \\left\\lceil \\frac{\\log(\\delta - \\delta_{\\mathrm{floor}})}{\\log(\\rho)} \\right\\rceil $$\n此公式在 $\\rho \\in (0,1)$ 和 $\\delta  \\delta_{\\mathrm{floor}}$ 的条件下有效，这已由我们的可行性检查确保。如果 $\\delta - \\delta_{\\mathrm{floor}} \\ge 1$，则会出现一个特殊情况。在这种情况下，分子 $\\log(\\delta - \\delta_{\\mathrm{floor}})$ 是非负的，而分母 $\\log(\\rho)$ 是负的。得到的分数是非正的，向上取整后为 $0$ 或一个负整数。从物理意义上讲，这意味着初始解已经足够精确，不需要进行细化步骤。因此，在这种情况下我们设置 $k=0$。总而言之，$k = \\max\\left(0, \\left\\lceil \\frac{\\log(\\delta - \\delta_{\\mathrm{floor}})}{\\log(\\rho)} \\right\\rceil\\right)$。\n\n确定 $k$ 之后，我们计算总执行时间 $T_{\\mathrm{total}}$。这是初始分解和求解的时间，加上 $k$ 次细化迭代的时间之和。\n$$ T_{\\mathrm{total}} = T_{\\mathrm{LU}}(p_f) + 2 T_{\\mathrm{TS}}(p_f) + k \\left[ T_{\\mathrm{RES}}(p_r) + 2 T_{\\mathrm{TS}}(p_f) + T_{\\mathrm{UP}}(p_u) \\right] $$\n每个核函数的时间使用 Roofline 模型计算：\n$$ T_{\\mathrm{kernel}}(p) = \\max\\left( \\frac{f}{P_p}, \\frac{b}{B} \\right) $$\n其中 $f$ 是浮点运算次数，$b$ 是数据移动量（字节），$P_p$ 是核函数操作精度的峰值性能，$B$ 是内存带宽。\n\n每个核函数的具体参数如下：\n-   **LU 分解 ($T_{\\mathrm{LU}}$)**：以精度 $p_f$ 运行。\n    -   $f_{\\mathrm{LU}} = \\frac{2}{3} n^3$\n    -   $b_{\\mathrm{LU}} = c_{\\mathrm{LU}} \\, n^2 \\, s_{p_f}$\n    -   时间：$T_{\\mathrm{LU}}(p_f) = \\max\\left( \\frac{f_{\\mathrm{LU}}}{P_{p_f}}, \\frac{b_{\\mathrm{LU}}}{B} \\right)$\n-   **三角求解 ($T_{\\mathrm{TS}}$)**：使用分解后的因子，因此以精度 $p_f$ 运行。\n    -   $f_{\\mathrm{TS}} = n^2$\n    -   $b_{\\mathrm{TS}} = n^2 \\, s_{p_f}$\n    -   时间：$T_{\\mathrm{TS}}(p_f) = \\max\\left( \\frac{f_{\\mathrm{TS}}}{P_{p_f}}, \\frac{b_{\\mathrm{TS}}}{B} \\right)$\n-   **残差计算 ($T_{\\mathrm{RES}}$)**：以精度 $p_r$ 运行。\n    -   $f_{\\mathrm{RES}} = 2 n^2$\n    -   $b_{\\mathrm{RES}} = (n^2 + 3 n) \\, s_{p_r}$\n    -   时间：$T_{\\mathrm{RES}}(p_r) = \\max\\left( \\frac{f_{\\mathrm{RES}}}{P_{p_r}}, \\frac{b_{\\mathrm{RES}}}{B} \\right)$\n-   **解更新 ($T_{\\mathrm{UP}}$)**：以精度 $p_u$ 运行。\n    -   $f_{\\mathrm{UP}} = n$\n    -   $b_{\\mathrm{UP}} = 3 n \\, s_{p_u}$\n    -   时间：$T_{\\mathrm{UP}}(p_u) = \\max\\left( \\frac{f_{\\mathrm{UP}}}{P_{p_u}}, \\frac{b_{\\mathrm{UP}}}{B} \\right)$\n\n我们计算当前可行配置的 $T_{\\mathrm{total}}$，并将其与当前测试用例迄今为止找到的最小时间进行比较。如果当前时间更低，我们更新最小时间，并将当前配置 $(p_f, p_r, p_u, k, T_{\\mathrm{total}})$ 存储为最佳配置。\n\n在遍历所有 $8$ 种配置后，存储的最佳配置即为该测试用例的解。如果没有找到可行的配置，我们返回指定的哨兵值 $[-1, -1, -1, -1, -1.0]$。然后对测试套件中的每个测试用例重复这整个过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the mixed-precision iterative refinement optimization problem\n    for a suite of test cases.\n    \"\"\"\n    \n    # Define precision properties: unit roundoff and size in bytes\n    u = {16: 2**-11, 32: 2**-24, 64: 2**-53}\n    s = {16: 2, 32: 4, 64: 8}\n\n    # Define the search space for precisions\n    pf_space = [16, 32]\n    pr_space = [32, 64]\n    pu_space = [32, 64]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"n\": 4096, \"kappa_A\": 1e5, \"delta\": 1e-8,\n            \"P\": {16: 3.00e14, 32: 2.00e13, 64: 1.00e13},\n            \"B\": 1.50e12, \"c_LU\": 6\n        },\n        {\n            \"n\": 2048, \"kappa_A\": 2.00e3, \"delta\": 1e-5,\n            \"P\": {16: 3.00e14, 32: 2.00e13, 64: 1.00e13},\n            \"B\": 9.00e11, \"c_LU\": 6\n        },\n        {\n            \"n\": 1024, \"kappa_A\": 1.00e2, \"delta\": 1e-18,\n            \"P\": {16: 3.00e14, 32: 2.00e13, 64: 1.00e13},\n            \"B\": 1.50e12, \"c_LU\": 6\n        }\n    ]\n\n    def _find_optimal_config(case):\n        \"\"\"\n        Processes a single test case to find the optimal configuration.\n        \"\"\"\n        n, kappa_A, delta = case[\"n\"], case[\"kappa_A\"], case[\"delta\"]\n        P, B, c_LU = case[\"P\"], case[\"B\"], case[\"c_LU\"]\n\n        min_time = float('inf')\n        best_config = None\n\n        for pf in pf_space:\n            for pr in pr_space:\n                for pu in pu_space:\n                    # Step 1: Feasibility Check\n                    # Convergence constraint\n                    rho = kappa_A * u[pf]\n                    if rho = 1:\n                        continue\n                    \n                    # Accuracy constraint\n                    delta_floor = u[pr] + u[pu]\n                    if delta_floor = delta:\n                        continue\n\n                    # Step 2: Calculate number of iterations k\n                    k = 0\n                    # The term inside the log must be less than 1 for its log to be negative,\n                    # which when divided by log(rho) (negative) yields a positive number.\n                    if delta - delta_floor  1:\n                        # Handle the case where delta is very close to delta_floor\n                        if np.log(rho) != 0:\n                           k_val = np.log(delta - delta_floor) / np.log(rho)\n                           # k must be non-negative\n                           if k_val > 0:\n                               k = int(np.ceil(k_val))\n                    \n                    # Step 3: Calculate total time\n                    def t_kernel(f, b, p_val, B_val):\n                        return max(f / P[p_val], b / B_val)\n\n                    # Flops and Bytes for each kernel\n                    f_LU = (2/3) * n**3\n                    b_LU = c_LU * n**2 * s[pf]\n                    \n                    f_TS = n**2\n                    b_TS = n**2 * s[pf]\n                    \n                    f_RES = 2 * n**2\n                    b_RES = (n**2 + 3*n) * s[pr]\n                    \n                    f_UP = n\n                    b_UP = 3*n * s[pu]\n                    \n                    # Kernel times\n                    T_LU = t_kernel(f_LU, b_LU, pf, B)\n                    T_TS = t_kernel(f_TS, b_TS, pf, B)\n                    T_RES = t_kernel(f_RES, b_RES, pr, B)\n                    T_UP = t_kernel(f_UP, b_UP, pu, B)\n\n                    # Total time\n                    T_total = T_LU + 2 * T_TS + k * (T_RES + 2 * T_TS + T_UP)\n                    \n                    # Step 4: Update minimum\n                    if T_total  min_time:\n                        min_time = T_total\n                        best_config = [pf, pr, pu, k, T_total]\n        \n        if best_config is None:\n            return [-1, -1, -1, -1, -1.0]\n        else:\n            return best_config\n\n    results = []\n    for case in test_cases:\n        result = _find_optimal_config(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The map(str,...) is used to format numbers without trailing '.0' for integers.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3552192"}]}