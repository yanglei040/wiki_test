{"hands_on_practices": [{"introduction": "选择先验是贝叶斯推断的关键步骤。我们如何客观地做出选择？最大熵（Maximum Entropy, MaxEnt）原理提供了一种方法，它允许我们在满足已知信息的同时，构建一个引入最少额外假设的先验分布。本练习 [@problem_id:3414194] 将展示，对期望 $L^1$ 范数施加一个简单的约束（这通常用于鼓励稀疏性），如何自然地推导出拉普拉斯分布，从而为其在稀疏正则化问题中的广泛应用提供了坚实的理论基础。", "problem": "考虑一个欠定线性反问题，其中未知参数向量为 $u \\in \\mathbb{R}^{n}$。在反问题和数据同化的背景下，您需要为 $u$ 建立一个先验分布模型。假设有以下建模要求：\n- 各坐标间相互独立：联合先验密度可分解为 $\\pi(u) = \\prod_{i=1}^{n} p_{i}(u_{i})$。\n- 坐标的可交换性：每个坐标都用相同的边缘分布 $p_{i} = p$ 进行建模。\n- 唯一可用的全局约束是期望 $\\ell^{1}$ 范数，$\\mathbb{E}\\!\\left[\\|u\\|_{1}\\right] = c$ (对于给定的 $c > 0$)，其中 $\\|u\\|_{1} = \\sum_{i=1}^{n} |u_{i}|$ 且期望是关于先验分布计算的。\n\n使用带有香农微分熵的最大熵（MaxEnt）原理，并从矩约束下熵最大化的第一性原理出发，推导在约束 $\\mathbb{E}\\!\\left[\\|u\\|_{1}\\right] = c$ 条件下，$\\mathbb{R}^{n}$ 上熵最大的独立先验的形式。具体来说：\n1. 证明最大熵边缘分布 $p$ 必须仅依赖于 $|x|$，且对应的联合先验是相同边缘分布的乘积。\n2. 在归一化和 $\\mathbb{E}\\!\\left[|U|\\right] = c/n$（其中 $U \\sim p$ 是单个坐标）的约束下，通过最大化熵推导出边缘密度 $p$ 的显式函数形式。\n3. 计算该边缘分布的尺度参数，用 $c$ 和 $n$ 表示。\n\n您的最终答案必须是边缘先验分布尺度参数的单一闭式解析表达式，用 $c$ 和 $n$ 表示。不需要四舍五入。最终答案中不要包含任何单位。", "solution": "问题在于使用最大熵（MaxEnt）原理，在一组指定约束条件下，推导向量 $u \\in \\mathbb{R}^{n}$ 的先验分布 $\\pi(u)$ 的形式。解将通过遵循最大熵程序的逻辑步骤来构建。\n\n首先，我们将问题形式化。我们希望最大化联合先验分布 $\\pi(u)$ 的香农微分熵，其表达式为：\n$$H[\\pi] = -\\int_{\\mathbb{R}^{n}} \\pi(u) \\ln \\pi(u) \\, du$$\n问题陈述了对 $\\pi(u)$ 的两个建模要求：\n1.  各坐标间相互独立：联合密度分解为边缘密度的乘积，$\\pi(u) = \\prod_{i=1}^{n} p_{i}(u_{i})$。\n2.  坐标的可交换性：边缘密度相同，$p_{i} = p$ 对所有 $i=1, \\dots, n$ 成立。\n\n在这两个要求下，联合先验为 $\\pi(u) = \\prod_{i=1}^{n} p(u_{i})$。我们可以简化联合熵的表达式：\n$$H[\\pi] = -\\int_{\\mathbb{R}^{n}} \\left(\\prod_{j=1}^{n} p(u_{j})\\right) \\ln\\left(\\prod_{i=1}^{n} p(u_{i})\\right) \\, du$$\n$$H[\\pi] = -\\int_{\\mathbb{R}^{n}} \\left(\\prod_{j=1}^{n} p(u_j)\\right) \\left(\\sum_{i=1}^{n} \\ln p(u_i)\\right) \\, du$$\n$$H[\\pi] = -\\sum_{i=1}^{n} \\int_{\\mathbb{R}^{n}} \\ln p(u_i) \\left(\\prod_{j=1}^{n} p(u_j)\\right) \\, du_1 \\dots du_n$$\n对于和中的每一项 $i$，我们可以分离积分。对于 $j \\neq i$ 的 $u_j$ 上的积分是 $\\int_{\\mathbb{R}} p(u_j) \\, du_j$，由于边缘概率密度 $p$ 的归一化性质，该积分等于 $1$。这样剩下：\n$$H[\\pi] = -\\sum_{i=1}^{n} \\int_{\\mathbb{R}} p(u_i) \\ln p(u_i) \\, du_i$$\n和中的每一项都是边缘分布 $p$ 的熵，记为 $H[p]$。由于有 $n$ 个相同的项，总熵为：\n$$H[\\pi] = n H[p] = -n \\int_{\\mathbb{R}} p(x) \\ln p(x) \\, dx$$\n因此，最大化联合熵 $H[\\pi]$ 等价于最大化边缘熵 $H[p]$。\n\n接下来，我们处理关于期望 $\\ell^1$ 范数的全局约束：\n$$\\mathbb{E}_{\\pi}\\!\\left[\\|u\\|_{1}\\right] = c$$\n其中 $\\|u\\|_{1} = \\sum_{i=1}^{n} |u_{i}|$。利用期望的线性性质：\n$$\\mathbb{E}_{\\pi}\\!\\left[\\sum_{i=1}^{n} |u_{i}|\\right] = \\sum_{i=1}^{n} \\mathbb{E}_{\\pi}[|u_{i}|] = c$$\n$|u_i|$ 关于联合分布 $\\pi(u)$ 的期望是：\n$$\\mathbb{E}_{\\pi}[|u_{i}|] = \\int_{\\mathbb{R}^{n}} |u_i| \\pi(u) \\, du = \\int_{\\mathbb{R}^{n}} |u_i| \\prod_{j=1}^{n} p(u_j) \\, du_1 \\dots du_n$$\n同样，对所有 $j \\neq i$ 的 $u_j$ 进行积分得到 $1$，剩下：\n$$\\mathbb{E}_{\\pi}[|u_{i}|] = \\int_{\\mathbb{R}} |u_i| p(u_i) \\, du_i$$\n这是 $|X|$ 的期望，其中 $X$ 是一个服从分布 $p$ 的随机变量。我们将其记为 $\\mathbb{E}_{p}[|X|]$。由于边缘分布相同，这个期望对所有 $i$ 都一样。约束变为：\n$$\\sum_{i=1}^{n} \\mathbb{E}_{p}[|X|] = n \\mathbb{E}_{p}[|X|] = c$$\n这就得出了对边缘密度 $p$ 的一个约束：\n$$\\mathbb{E}_{p}[|X|] = \\int_{-\\infty}^{\\infty} |x| p(x) \\, dx = \\frac{c}{n}$$\n\n问题现在简化为找到边缘密度 $p(x)$，使其在满足以下两个约束条件的情况下最大化 $H[p]$：\n1.  归一化：$\\int_{-\\infty}^{\\infty} p(x) \\, dx = 1$\n2.  矩约束：$\\int_{-\\infty}^{\\infty} |x| p(x) \\, dx = \\frac{c}{n}$\n\n我们使用变分法来解决这个问题。我们定义要最大化的泛函，通过拉格朗日乘子 $\\lambda_0$ 和 $\\lambda_1$ 引入约束：\n$$L[p] = -\\int_{-\\infty}^{\\infty} p(x) \\ln p(x) \\, dx - (\\lambda_0-1) \\left(\\int_{-\\infty}^{\\infty} p(x) \\, dx - 1\\right) - \\lambda_1 \\left(\\int_{-\\infty}^{\\infty} |x| p(x) \\, dx - \\frac{c}{n}\\right)$$\n求 $L[p]$ 关于 $p(x)$ 的泛函导数并令其为零，得到：\n$$\\frac{\\delta L}{\\delta p(x)} = -\\ln p(x) - 1 - (\\lambda_0-1) - \\lambda_1 |x| = 0$$\n$$\\ln p(x) = -\\lambda_0 - \\lambda_1 |x|$$\n$$p(x) = \\exp(-\\lambda_0) \\exp(-\\lambda_1 |x|)$$\n这个形式明确表明 $p(x)$ 只依赖于 $|x|$，这解决了任务1的第一部分。联合先验的分解是一个初始假设，这里被证实与最大熵解的结构是一致的。\n\n现在，我们确定拉格朗日乘子。令 $Z = \\exp(\\lambda_0)$。密度函数为 $p(x) = \\frac{1}{Z} \\exp(-\\lambda_1 |x|)$。\n\n使用归一化约束：\n$$\\int_{-\\infty}^{\\infty} \\frac{1}{Z} \\exp(-\\lambda_1 |x|) \\, dx = 1$$\n被积函数是偶函数，因此我们可以写成：\n$$\\frac{2}{Z} \\int_{0}^{\\infty} \\exp(-\\lambda_1 x) \\, dx = 1$$\n为使积分收敛，我们需要 $\\lambda_1 > 0$。\n$$\\frac{2}{Z} \\left[-\\frac{1}{\\lambda_1} \\exp(-\\lambda_1 x)\\right]_{0}^{\\infty} = \\frac{2}{Z} \\left(0 - \\left(-\\frac{1}{\\lambda_1}\\right)\\right) = \\frac{2}{Z \\lambda_1} = 1$$\n这得到 $Z = \\frac{2}{\\lambda_1}$。将其代回到 $p(x)$ 的表达式中，得到其显式函数形式，即拉普拉斯分布：\n$$p(x) = \\frac{\\lambda_1}{2} \\exp(-\\lambda_1 |x|)$$\n这完成了任务2。\n\n使用矩约束：\n$$\\int_{-\\infty}^{\\infty} |x| p(x) \\, dx = \\frac{c}{n}$$\n$$\\int_{-\\infty}^{\\infty} |x| \\frac{\\lambda_1}{2} \\exp(-\\lambda_1 |x|) \\, dx = \\lambda_1 \\int_{0}^{\\infty} x \\exp(-\\lambda_1 x) \\, dx = \\frac{c}{n}$$\n左边的积分可以用分部积分法求解。令 $u=x$ 和 $dv=\\exp(-\\lambda_1 x) dx$。那么 $du=dx$ 且 $v = -\\frac{1}{\\lambda_1}\\exp(-\\lambda_1 x)$。\n$$\\int_{0}^{\\infty} x \\exp(-\\lambda_1 x) \\, dx = \\left[-\\frac{x}{\\lambda_1} \\exp(-\\lambda_1 x)\\right]_{0}^{\\infty} - \\int_{0}^{\\infty} \\left(-\\frac{1}{\\lambda_1}\\right) \\exp(-\\lambda_1 x) \\, dx$$\n$$= (0 - 0) + \\frac{1}{\\lambda_1} \\int_{0}^{\\infty} \\exp(-\\lambda_1 x) \\, dx = \\frac{1}{\\lambda_1} \\left[-\\frac{1}{\\lambda_1} \\exp(-\\lambda_1 x)\\right]_{0}^{\\infty} = \\frac{1}{\\lambda_1^2}$$\n将此结果代入矩约束方程中：\n$$\\lambda_1 \\left(\\frac{1}{\\lambda_1^2}\\right) = \\frac{1}{\\lambda_1} = \\frac{c}{n}$$\n这意味着 $\\lambda_1 = \\frac{n}{c}$。因为 $n>0$ 且 $c>0$，所以条件 $\\lambda_1>0$ 得到满足。\n\n边缘密度的最终形式是：\n$$p(x) = \\frac{n}{2c} \\exp\\left(-\\frac{n|x|}{c}\\right)$$\n\n最后，对于任务3，我们计算尺度参数。对于位置参数为 $\\mu$、尺度参数为 $b > 0$ 的拉普拉斯分布，其概率密度函数为：\n$$f(x; \\mu, b) = \\frac{1}{2b} \\exp\\left(-\\frac{|x-\\mu|}{b}\\right)$$\n在我们的情况下，位置参数 $\\mu$ 为 $0$。将我们推导出的密度 $p(x)$ 与标准形式 $f(x; 0, b)$进行比较，我们有：\n$$p(x) = \\frac{n}{2c} \\exp\\left(-\\frac{n|x|}{c}\\right) = \\frac{1}{2(c/n)} \\exp\\left(-\\frac{|x|}{c/n}\\right)$$\n通过直接比较，尺度参数 $b$ 是：\n$$b = \\frac{c}{n}$$\n这就是边缘先验的尺度参数，用 $c$ 和 $n$ 表示。", "answer": "$$\\boxed{\\frac{c}{n}}$$", "id": "3414194"}, {"introduction": "许多现实世界中的反问题，其未知量是函数而非有限维向量。我们通常直接在这些函数空间上定义先验（例如，基于平滑度假设）。然而，为了进行计算，我们必须将模型离散化。本练习 [@problem_id:3414123] 提出了一个关键问题：我们如何确保离散化的先验能够一致地表示底层的连续模型，而不会任意地依赖于我们选择的网格分辨率？通过一个具体的编码实践，您将学习如何使用有限元方法来离散化一个定义在函数空间上的高斯先验，并验证其在不同网格下的不变性，这是构建稳健计算模型的关键一步。", "problem": "考虑单位区间上的一个零均值高斯先验，其具有齐次狄利克雷边界条件，由以下精度双线性形式定义：对于索博列夫空间 $H_0^1([0,1])$ 中的函数 $u$ 和 $v$，精度算子 $L$ 导出对称双线性形式\n$$\na(u,v) = \\kappa^2 \\int_0^1 u(x) v(x)\\, dx + \\int_0^1 \\frac{du}{dx}(x)\\frac{dv}{dx}(x)\\, dx,\n$$\n其中 $\\kappa > 0$ 是一个实参数。该高斯先验由协方差算子 $C = L^{-1}$ 表征，该算子在弱意义下进行解释。\n\n要求您使用有限元（FE）方法，在单位区间的两个均匀网格上，通过连续分段线性基函数，对与同一连续高斯先验相关联的离散化协方差矩阵进行推导、实现和比较。这两个网格分别对应于具有 $N$ 个单元的粗网格和具有 $2N$ 个单元的细网格。离散化过程必须从第一性原理出发，使用上述弱形式和标准伽辽金方法：通过在单元上对 $a(u,v)$ 的相应项进行积分，来组装有限元刚度矩阵和质量矩阵。通过在排除边界基函数的子空间中进行操作，来施加齐次狄利克雷边界条件。\n\n在这些基础上，构建两个网格上的离散精度矩阵，并通过求离散精度矩阵的逆来获得相应的离散协方差矩阵。为了以一种网格无关的方式比较两种离散化，将细网格协方差矩阵限制到粗网格的节点子集上：由于细网格是粗网格按因子2均匀加密得到的，因此每个粗网格的内部节点都与一个细网格的内部节点重合。通过选取细网格协方差矩阵中与粗网格内部节点对应的行和列，来构成受限的细网格协方差子矩阵。\n\n对于每个指定的测试用例，定义并计算以下两个定量度量，用于比较粗网格协方差 $C_h$ 与受限的细网格协方差 $C_{h/2 \\to h}$ 之间的离散化不变性：\n1. 最大相对方差差异\n$$\n\\delta_{\\mathrm{var}} = \\max_{i} \\left| \\frac{ \\left(C_h\\right)_{ii} - \\left(C_{h/2 \\to h}\\right)_{ii} }{ \\left(C_h\\right)_{ii} } \\right|.\n$$\n2. 相对弗罗贝尼乌斯范数差异\n$$\n\\delta_{\\mathrm{F}} = \\frac{ \\left\\| C_h - C_{h/2 \\to h} \\right\\|_F }{ \\left\\| C_h \\right\\|_F },\n$$\n其中 $\\|\\cdot\\|_F$ 表示弗罗贝尼乌斯范数。\n\n您的实现必须使用以下参数值测试套件，每个测试用例由一对 $(N,\\kappa)$ 组成：\n- 测试用例1（一般情况）：$(N,\\kappa) = (16, 1.0)$。\n- 测试用例2（具有较粗糙场的边缘情况）：$(N,\\kappa) = (8, 0.3)$。\n- 测试用例3（具有较平滑场的边缘情况）：$(N,\\kappa) = (32, 3.0)$。\n\n所有计算都是纯数学的；不涉及物理单位，也不需要角度单位。\n\n您的程序必须输出一行，其中包含一个由六个浮点数组成的扁平列表，按以下顺序排列\n$$\n\\left[ \\delta_{\\mathrm{var}}^{(1)}, \\delta_{\\mathrm{F}}^{(1)}, \\delta_{\\mathrm{var}}^{(2)}, \\delta_{\\mathrm{F}}^{(2)}, \\delta_{\\mathrm{var}}^{(3)}, \\delta_{\\mathrm{F}}^{(3)} \\right],\n$$\n对应于三个测试用例。每个数字必须四舍五入到八位小数。输出格式必须是严格的一行，结果为一个用方括号括起来的逗号分隔列表，例如，\n$$\n[\\delta_{\\mathrm{var}}^{(1)},\\delta_{\\mathrm{F}}^{(1)},\\delta_{\\mathrm{var}}^{(2)},\\delta_{\\mathrm{F}}^{(2)},\\delta_{\\mathrm{var}}^{(3)},\\delta_{\\mathrm{F}}^{(3)}].\n$$", "solution": "我们从先验的定义开始。设 $u$ 为 $H_0^1([0,1])$ 中的一个随机函数，服从零均值高斯分布，该分布由精度算子 $L$ 表征，其弱形式由下式给出\n$$\na(u,v) = \\kappa^2 \\int_0^1 u(x) v(x)\\, dx + \\int_0^1 \\frac{du}{dx}(x)\\frac{dv}{dx}(x)\\, dx.\n$$\n协方差算子 $C = L^{-1}$ 在弱意义下定义为其逆：对于对偶空间中的任意 $f,g$，$\\langle f, C g \\rangle$ 对所有 $v$ 求解方程 $a(C g, v) = \\langle g, v \\rangle$。\n\n为了在具有 $N$ 个单元的网格上离散化此先验，我们选择标准的有限元（FE）空间，该空间由在节点 $x_i = i h$（其中 $i=0,1,\\ldots,N$ 且 $h = 1/N$）上的连续分段线性函数构成。齐次狄利克雷边界条件意味着自由度对应于内部节点 $x_i$（其中 $i = 1,\\ldots,N-1$）。令 $\\{\\phi_i\\}_{i=1}^{N-1}$ 表示与这些内部节点相关联的有限元基函数。使用伽辽金方法，离散精度矩阵 $Q_h \\in \\mathbb{R}^{(N-1)\\times(N-1)}$ 定义为\n$$\n(Q_h)_{ij} = a(\\phi_i, \\phi_j) = \\kappa^2 \\int_0^1 \\phi_i(x)\\phi_j(x)\\, dx + \\int_0^1 \\frac{d\\phi_i}{dx}(x)\\frac{d\\phi_j}{dx}(x)\\, dx.\n$$\n第一项是有限元质量矩阵，第二项是有限元刚度矩阵。在有限元方法中，一个基本的构造是通过局部单元贡献来组装质量和刚度矩阵，从而得到这些积分。对于均匀网格和分段线性基，刚度矩阵的项由梯度项导出，并涉及单元长度的倒数，而质量矩阵的项由 $L^2$ 内积导出，并涉及单元长度。具体来说，由于基函数的支集仅在相邻单元上重叠，这些矩阵是三对角的。\n\n根据构造，$Q_h$ 是对称正定的。离散协方差矩阵是离散精度的逆：\n$$\nC_h = Q_h^{-1}.\n$$\n这个在有限元系数上的离散化高斯分布近似了连续先验，其中有限元解最小化了由 $a(\\cdot,\\cdot)$ 导出的能量。该离散化先验是一致的，即当网格加密到 $2N$ 个单元时，定义了一个包含粗网格空间的空间，并且在细网格上的伽辽金离散化（其精度矩阵为 $Q_{h/2}$，协方差为 $C_{h/2} = Q_{h/2}^{-1}$）能更精细地近似同一个连续先验。\n\n为了以网格无关的方式比较粗网格协方差 $C_h$ 与细网格协方差 $C_{h/2}$，我们将细网格协方差限制到粗网格节点子集上。由于细网格是粗网格按因子2均匀加密得到的，粗网格的内部节点与细网格在位置 $x_j = j h = 2 j h_f$（其中 $j=1,\\ldots,N-1$）上的内部节点重合，这里 $h_f = 1/(2N)$ 是细网格的尺寸。从索引的角度看，粗网格的内部节点对应于细网格的内部索引 $2j$（在使用1-based索引时）或 $2j-1$（在使用0-based索引的数组时）。通过选择 $C_{h/2}$ 中与这些细网格索引对应的行和列构成的子矩阵来定义限制。将此受限子矩阵记为 $C_{h/2 \\to h}$。\n\n为了评估离散化不变性，我们计算两个度量：\n1. 最大相对方差差异\n$$\n\\delta_{\\mathrm{var}} = \\max_{i} \\left| \\frac{ \\left(C_h\\right)_{ii} - \\left(C_{h/2 \\to h}\\right)_{ii} }{ \\left(C_h\\right)_{ii} } \\right|,\n$$\n该度量比较了粗网格节点上的边际方差。\n2. 相对弗罗贝尼乌斯范数差异\n$$\n\\delta_{\\mathrm{F}} = \\frac{ \\left\\| C_h - C_{h/2 \\to h} \\right\\|_F }{ \\left\\| C_h \\right\\|_F },\n$$\n该度量衡量了协方差结构上的全局差异。\n\n与这些原则一致的算法步骤如下：\n- 对于给定的 $N$ 和 $\\kappa$，计算均匀网格尺寸 $h = 1/N$ 并组装有限元质量矩阵和刚度矩阵。对于均匀网格上的分段线性基，全局质量矩阵 $M_h$ 和刚度矩阵 $K_h$ 是三对角的，其元素为\n$$\n(M_h)_{ii} = \\frac{2h}{3},\\quad (M_h)_{i,i\\pm 1} = \\frac{h}{6},\\quad (K_h)_{ii} = \\frac{2}{h},\\quad (K_h)_{i,i\\pm 1} = -\\frac{1}{h},\n$$\n对于 $i=1,\\ldots,N-1$，当索引超出内部范围时，非对角元素为零。\n- 构建离散精度矩阵 $Q_h = \\kappa^2 M_h + K_h$ 并对其进行数值求逆以获得 $C_h = Q_h^{-1}$。\n- 对具有 $2N$ 个单元的细网格重复组装过程以获得 $C_{h/2}$。\n- 通过选择与粗网格内部节点对应的细网格索引的行和列，将 $C_{h/2}$ 限制到粗网格内部节点上，以获得 $C_{h/2 \\to h}$。\n- 为每个测试用例计算 $\\delta_{\\mathrm{var}}$ 和 $\\delta_{\\mathrm{F}}$。\n\n这些步骤实现了弱形式精度的伽辽金离散化，通过排除边界自由度来施加边界条件，并利用粗、细有限元空间之间的子空间关系为比较提供了一致的限制。由于离散化源自相同的连续先验，且细网格空间包含粗网格空间，当 $N$ 足够大且离散化一致时，$C_{h/2 \\to h}$ 应能精确近似 $C_h$，从而导致两个差异度量的值都很小。测试套件包括一个一般情况和两个边缘情况，旨在探究当 $\\kappa$ 变化时模型的行为，其中较小的 $\\kappa$ 会产生较粗糙的场，而较大的 $\\kappa$ 会产生较平滑的场。\n\n程序将为指定的测试用例计算这些度量，并打印一行包含六个结果，按 $[\\delta_{\\mathrm{var}}^{(1)},\\delta_{\\mathrm{F}}^{(1)},\\delta_{\\mathrm{var}}^{(2)},\\delta_{\\mathrm{F}}^{(2)},\\delta_{\\mathrm{var}}^{(3)},\\delta_{\\mathrm{F}}^{(3)}]$ 的顺序排列，每个结果四舍五入到八位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef assemble_fe_matrices(N: int):\n    \"\"\"\n    Assemble mass and stiffness matrices for 1D FE with N uniform elements\n    on [0,1] and homogeneous Dirichlet boundary conditions.\n    Returns M, K of size (N-1) x (N-1).\n    \"\"\"\n    if N  2:\n        raise ValueError(\"N must be at least 2 to have interior degrees of freedom.\")\n    n = N - 1  # number of interior nodes\n    h = 1.0 / N\n\n    # Mass matrix (tridiagonal)\n    diag_M = np.full(n, 2.0 * h / 3.0)\n    off_M = np.full(n - 1, h / 6.0)\n    M = np.diag(diag_M)\n    if n > 1:\n        M += np.diag(off_M, 1) + np.diag(off_M, -1)\n\n    # Stiffness matrix (tridiagonal)\n    diag_K = np.full(n, 2.0 / h)\n    off_K = np.full(n - 1, -1.0 / h)\n    K = np.diag(diag_K)\n    if n > 1:\n        K += np.diag(off_K, 1) + np.diag(off_K, -1)\n\n    return M, K\n\ndef covariance_matrix(N: int, kappa: float):\n    \"\"\"\n    Compute the discrete covariance matrix C_h = Q_h^{-1} for mesh with N elements.\n    \"\"\"\n    M, K = assemble_fe_matrices(N)\n    Q = (kappa ** 2) * M + K\n    # Invert Q using solve with identity for numerical stability\n    n = Q.shape[0]\n    I = np.eye(n)\n    C = np.linalg.solve(Q, I)\n    return C\n\ndef restrict_fine_to_coarse(C_fine: np.ndarray, N_coarse: int):\n    \"\"\"\n    Restrict the fine covariance matrix to the coarse interior nodes.\n    Fine mesh assumed to have 2*N_coarse elements.\n    Coarse interior indices j=1..N_coarse-1 correspond to fine indices i=2*j (1-based),\n    which are (2*j - 1) in 0-based array indexing.\n    \"\"\"\n    n_coarse = N_coarse - 1\n    fine_indices = [2 * j - 1 for j in range(1, N_coarse)]  # 0-based\n    C_restricted = C_fine[np.ix_(fine_indices, fine_indices)]\n    return C_restricted\n\ndef invariance_metrics(N: int, kappa: float):\n    \"\"\"\n    Compute the two discrepancy metrics:\n    - delta_var: maximum relative difference of variances (diagonal entries)\n    - delta_F: relative Frobenius norm difference\n    \"\"\"\n    # Coarse covariance\n    C_coarse = covariance_matrix(N, kappa)\n    # Fine covariance with twice as many elements\n    C_fine = covariance_matrix(2 * N, kappa)\n    # Restrict fine covariance to coarse nodes\n    C_fine_to_coarse = restrict_fine_to_coarse(C_fine, N)\n\n    # Variance discrepancy\n    diag_coarse = np.diag(C_coarse)\n    diag_fine_restricted = np.diag(C_fine_to_coarse)\n    # Avoid division by zero: diagonals of covariance should be positive\n    rel_var = np.abs((diag_coarse - diag_fine_restricted) / diag_coarse)\n    delta_var = float(np.max(rel_var)) if rel_var.size > 0 else 0.0\n\n    # Frobenius norm discrepancy\n    fro_diff = np.linalg.norm(C_coarse - C_fine_to_coarse, ord='fro')\n    fro_coarse = np.linalg.norm(C_coarse, ord='fro')\n    delta_F = float(fro_diff / fro_coarse) if fro_coarse > 0 else 0.0\n\n    return delta_var, delta_F\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (16, 1.0),  # general case\n        (8, 0.3),   # rougher field (smaller kappa)\n        (32, 3.0),  # smoother field (larger kappa)\n    ]\n\n    results = []\n    for N, kappa in test_cases:\n        d_var, d_F = invariance_metrics(N, kappa)\n        results.append(d_var)\n        results.append(d_F)\n\n    # Final print statement in the exact required format with 8 decimal places.\n    formatted = \",\".join(f\"{x:.8f}\" for x in results)\n    print(f\"[{formatted}]\")\n\nsolve()\n```", "id": "3414123"}, {"introduction": "最后，我们介绍一种用于构建高度灵活和富有表现力的先验的现代强大技术。本练习 [@problem_id:3414140] 将引导您了解归一化流（normalizing flows）或输运映射（transport maps）的概念，其中一个简单的基础分布通过一个可逆的、可微的映射被变换成一个复杂的分布。这种借鉴自机器学习的方法，使我们能够创建能够捕捉解空间中复杂、多峰或非线性结构的先验，为解决具有挑战性的反问题提供了新的可能性。您将通过推导、计算和分析，亲身体验这一前沿技术的核心机制。", "problem": "您正在通过一个微分同胚映射来传输一个简单的参考测度，从而为贝叶斯逆问题和数据同化中的未知量 $u \\in \\mathbb{R}^{d}$ 建立先验分布模型。设 $Z \\in \\mathbb{R}^{d}$ 是一个随机向量，其关于勒贝格测度的已知概率密度函数为 $p_{Z}$。设 $T:\\mathbb{R}^{d} \\to \\mathbb{R}^{d}$ 是一个双射的、连续可微且其逆也连续可微的映射，并定义 $U = T(Z)$。\n\n任务：\n1) 从前推测度的定义和微分同胚下积分的变量替换法则出发，推导 $U$ 的密度表达式，用 $p_{Z}$、$T^{-1}$ 以及 $T^{-1}$ 的雅可比行列式表示。您的推导必须解释每一步及其测度论依据。\n\n2) 考虑三维情况 $d=3$，其中三角传输（归一化流）映射 $T:\\mathbb{R}^{3}\\to\\mathbb{R}^{3}$ 的分量形式如下：\n$$\nu_{1} = \\alpha_{1} z_{1}, \\quad\nu_{2} = \\alpha_{2} z_{2} + \\beta_{21} \\tanh(z_{1}), \\quad\nu_{3} = \\alpha_{3} z_{3} + \\beta_{31} z_{1} + \\beta_{32} \\sin(z_{2}),\n$$\n参数为 $\\alpha_{1} = 2$，$\\alpha_{2} = 1.5$，$\\alpha_{3} = 0.5$，$\\beta_{21} = 0.8$，$\\beta_{31} = -0.3$，以及 $\\beta_{32} = 1.2$。假设基础密度是三维标准正态分布，$p_{Z}(z) = (2\\pi)^{-3/2} \\exp\\!\\left(-\\frac{1}{2}\\|z\\|_{2}^{2}\\right)$。对于目标点 $u = (1.0,\\,-0.2,\\,0.5)$，计算此流所导出的先验密度值 $p_{U}(u)$。使用 $\\tanh(\\cdot)$ 和 $\\sin(\\cdot)$ 的常规定义，并以弧度解释角度。将最终数值答案四舍五入到四位有效数字。\n\n3) 在高维情况下，评估 $p_{U}(u)$ 需要对 $T$ 在 $u$ 点求逆，并计算雅可比行列式项。对于一个 $d$ 维的自回归三角流，其中评估单个分量变换的计算成本为 $C$（例如，如果每个分量使用一个具有 $L$ 层和隐藏层宽度 $h$ 的前馈神经网络，可以认为 $C = \\mathcal{O}(L h^{2})$），请用大O表示法讨论以下操作的渐近计算复杂度：\n- 在单点 $u$ 处评估 $p_{U}(u)$，\n- 在单点 $u$ 处计算 $\\nabla_{u} \\log p_{U}(u)$，以及\n- 这些与需要通用雅可比行列式的密集、非三角流相比如何。\n\n您的最终答案应该是任务2中得到的 $p_{U}(u)$ 的单个经过四舍五入的数值。最终答案中不应包含任何其他输出。最终答案请表示为不带单位的数值。", "solution": "这个问题包含三个任务，都与使用传输映射（也称为归一化流）构建先验概率分布有关。在验证问题陈述后，我将按顺序处理每个任务。\n\n### 问题验证\n\n**步骤1：提取已知信息**\n-   未知参数向量：$u \\in \\mathbb{R}^{d}$。\n-   参考随机向量：$Z \\in \\mathbb{R}^{d}$，其关于勒贝格测度的已知概率密度函数为 $p_Z$。\n-   映射：$T:\\mathbb{R}^{d} \\to \\mathbb{R}^{d}$ 是一个双射的、连续可微且其逆也连续可微的映射（$T$ 是一个微分同胚）。\n-   目标随机向量：$U=T(Z)$。\n-   任务1：推导 $U$ 的密度 $p_U$。\n-   任务2具体细节：\n    -   维度：$d=3$。\n    -   映射 $T:\\mathbb{R}^{3}\\to\\mathbb{R}^{3}$：\n        $$u_{1} = \\alpha_{1} z_{1}$$\n        $$u_{2} = \\alpha_{2} z_{2} + \\beta_{21} \\tanh(z_{1})$$\n        $$u_{3} = \\alpha_{3} z_{3} + \\beta_{31} z_{1} + \\beta_{32} \\sin(z_{2})$$\n    -   参数：$\\alpha_{1} = 2$，$\\alpha_{2} = 1.5$，$\\alpha_{3} = 0.5$，$\\beta_{21} = 0.8$，$\\beta_{31} = -0.3$，$\\beta_{32} = 1.2$。\n    -   参考密度：$p_{Z}(z) = (2\\pi)^{-3/2} \\exp\\left(-\\frac{1}{2}\\|z\\|_{2}^{2}\\right)$，即 $\\mathbb{R}^3$中的标准正态分布。\n    -   评估点：$u = (1.0, -0.2, 0.5)$。\n    -   舍入要求：最终数值答案四舍五入到四位有效数字。\n-   任务3：讨论自回归三角流的渐近计算复杂度：\n    -   评估 $p_U(u)$。\n    -   计算 $\\nabla_{u} \\log p_{U}(u)$。\n    -   与密集、非三角流的比较。\n    -   单个分量变换的成本：$C$。\n\n**步骤2：使用提取的已知信息进行验证**\n-   **科学依据：**该问题基于概率论的基本原理，特别是概率分布的变量替换公式。这种技术，被称为归一化流或传输映射，是现代统计学、机器学习和计算科学（包括逆问题和数据同化）中一种标准且广泛使用的方法。该问题在科学上和数学上都是合理的。\n-   **适定性：**所有任务都定义明确。任务1是标准的推导。任务2提供了一个特定的、良态的（三角形的，对变换后的变量是仿射的）映射，一个明确定义的基础分布，以及计算唯一答案所需的所有数值。指定的映射是可逆的，其雅可比矩阵计算简单。任务3是对算法计算复杂度的标准分析，这是计算机科学和数值分析的核心课题。\n-   **客观性：**该问题以精确的数学语言陈述，没有任何主观性或歧义。\n-   **完整性和一致性：**该问题提供了所有必要的信息。映射被完全指定，参数已给出，基础密度已定义，评估点也已提供。没有内部矛盾。\n\n**步骤3：结论与行动**\n问题有效。我将继续提供完整解答。\n\n### 解答\n\n**任务1：前推测度密度的推导**\n\n设 $\\mu_Z$ 和 $\\mu_U$ 分别是与随机向量 $Z$ 和 $U$ 相关联的概率测度。根据定义，这些测度在 $\\mathbb{R}^d$ 上关于勒贝格测度 $m$ 的密度分别为 $p_Z$ 和 $p_U$。关系 $U = T(Z)$ 意味着 $\\mu_U$ 是 $\\mu_Z$ 在映射 $T$ 下的前推。\n\n根据前推测度的定义，对于任何可测集 $A \\subset \\mathbb{R}^d$，$U$ 属于 $A$ 的概率等于 $Z$ 属于 $A$ 在 $T$ 映射下的原像的概率。原像是 $T^{-1}(A) = \\{z \\in \\mathbb{R}^d | T(z) \\in A\\}$。用数学公式表示为：\n$$ \\mu_U(A) = \\mu_Z(T^{-1}(A)) $$\n用密度表示，我们有：\n$$ \\int_A p_U(u) \\, du = \\int_{T^{-1}(A)} p_Z(z) \\, dz $$\n我们现在对右侧的积分应用积分的变量替换定理。我们使用替换 $u = T(z)$，这意味着 $z = T^{-1}(u)$。微分体积元根据 $dz = |\\det(J_{T^{-1}}(u))| \\, du$ 进行变换，其中 $J_{T^{-1}}(u)$ 是逆变换 $T^{-1}$ 在 $u$ 处求值的雅可比矩阵。雅可比矩阵是一阶偏导数矩阵，$(J_{T^{-1}})_{ij} = \\frac{\\partial (T^{-1})_i}{\\partial u_j}$。\n\n$z$ 空间中的积分区域 $T^{-1}(A)$ 被映射到 $u$ 空间中的区域 $A$。代入 $z = T^{-1}(u)$ 和 $dz$ 的表达式，积分变为：\n$$ \\int_{T^{-1}(A)} p_Z(z) \\, dz = \\int_A p_Z(T^{-1}(u)) \\, |\\det(J_{T^{-1}}(u))| \\, du $$\n结合我们的方程，我们得到：\n$$ \\int_A p_U(u) \\, du = \\int_A p_Z(T^{-1}(u)) \\, |\\det(J_{T^{-1}}(u))| \\, du $$\n由于这个等式必须对任意可测集 $A$ 成立，所以被积函数必须几乎处处相等。这就得到了我们想要的密度 $p_U(u)$ 的表达式：\n$$ p_U(u) = p_Z(T^{-1}(u)) \\, |\\det(J_{T^{-1}}(u))| $$\n这个公式表明，变换后的变量 $U$ 在点 $u$ 处的密度由基础变量 $Z$ 在对应点 $z=T^{-1}(u)$ 处的密度，乘以逆映射的雅可比行列式的绝对值得到。这个行列式因子解释了由变换引起的局部体积变化。\n\n**任务2：先验密度的数值计算**\n\n我们需要使用推导出的公式计算 $u = (1.0, -0.2, 0.5)$ 时的 $p_U(u)$。这包括三个步骤：\n1.  计算 $z = T^{-1}(u)$。\n2.  计算雅可比行列式 $|\\det(J_{T^{-1}}(u))|$。\n3.  结合这些来评估 $p_U(u) = p_Z(z) |\\det(J_{T^{-1}}(u))|$。\n\n**步骤2.1：在 $u$ 点对映射 $T$ 求逆**\n映射 $T$ 是三角形的，可以进行顺序求逆。\n给定 $u_1=1.0$，$u_2=-0.2$，$u_3=0.5$ 以及参数：\n$$ z_1 = \\frac{u_1}{\\alpha_1} = \\frac{1.0}{2} = 0.5 $$\n$$ z_2 = \\frac{u_2 - \\beta_{21} \\tanh(z_1)}{\\alpha_2} = \\frac{-0.2 - 0.8 \\tanh(0.5)}{1.5} $$\n使用 $\\tanh(0.5) \\approx 0.46211716$，我们得到：\n$$ z_2 \\approx \\frac{-0.2 - 0.8 \\times 0.46211716}{1.5} = \\frac{-0.2 - 0.36969373}{1.5} = \\frac{-0.56969373}{1.5} \\approx -0.37979582 $$\n$$ z_3 = \\frac{u_3 - \\beta_{31} z_1 - \\beta_{32} \\sin(z_2)}{\\alpha_3} = \\frac{0.5 - (-0.3) \\times 0.5 - 1.2 \\sin(-0.37979582)}{0.5} $$\n使用 $\\sin(-0.37979582) \\approx -0.37072529$（角度以弧度为单位），我们得到：\n$$ z_3 \\approx \\frac{0.5 + 0.15 - 1.2 \\times (-0.37072529)}{0.5} = \\frac{0.65 + 0.44487035}{0.5} = \\frac{1.09487035}{0.5} \\approx 2.18974070 $$\n所以，$z = T^{-1}(u) \\approx (0.5, -0.37979582, 2.18974070)$。\n\n**步骤2.2：计算雅可比行列式**\n变换 $z = T^{-1}(u)$ 的形式为：\n$z_1 = f_1(u_1)$, $z_2 = f_2(u_1, u_2)$, $z_3 = f_3(u_1, u_2, u_3)$.\n因此，雅可比矩阵 $J_{T^{-1}}(u)$ 是下三角矩阵。其行列式是其对角元素的乘积：\n$$ \\det(J_{T^{-1}}(u)) = \\frac{\\partial z_1}{\\partial u_1} \\frac{\\partial z_2}{\\partial u_2} \\frac{\\partial z_3}{\\partial u_3} $$\n从 $z_i$ 的方程可知：\n$$ \\frac{\\partial z_1}{\\partial u_1} = \\frac{1}{\\alpha_1}, \\quad \\frac{\\partial z_2}{\\partial u_2} = \\frac{1}{\\alpha_2}, \\quad \\frac{\\partial z_3}{\\partial u_3} = \\frac{1}{\\alpha_3} $$\n因此，雅可比行列式是一个常数：\n$$ \\det(J_{T^{-1}}(u)) = \\frac{1}{\\alpha_1 \\alpha_2 \\alpha_3} = \\frac{1}{2 \\times 1.5 \\times 0.5} = \\frac{1}{1.5} = \\frac{2}{3} $$\n其绝对值为 $|\\det(J_{T^{-1}}(u))| = 2/3$。\n\n**步骤2.3：评估 $p_U(u)$**\n首先，我们计算 $z = T^{-1}(u)$ 的 $L_2$ 范数的平方：\n$$ \\|z\\|_2^2 = z_1^2 + z_2^2 + z_3^2 \\approx (0.5)^2 + (-0.37979582)^2 + (2.18974070)^2 $$\n$$ \\|z\\|_2^2 \\approx 0.25 + 0.14424486 + 4.79495415 \\approx 5.18919901 $$\n现在，我们评估基础密度 $p_Z(z)$：\n$$ p_Z(z) = (2\\pi)^{-3/2} \\exp\\left(-\\frac{1}{2}\\|z\\|_2^2\\right) \\approx (2\\pi)^{-1.5} \\exp\\left(-\\frac{5.18919901}{2}\\right) $$\n$$ p_Z(z) \\approx (0.06349364) \\exp(-2.5945995) \\approx (0.06349364)(0.07467649) \\approx 0.00474122 $$\n最后，我们计算 $p_U(u)$：\n$$ p_U(u) = p_Z(z) |\\det(J_{T^{-1}}(u))| \\approx 0.00474122 \\times \\frac{2}{3} \\approx 0.003160813 $$\n四舍五入到四位有效数字，我们得到 $p_U(u) \\approx 0.003161$。\n\n**任务3：计算复杂度分析**\n\n设 $d$ 是空间维度，设 $C$ 是评估单个分量变换的计算成本，即从 $z_1, \\dots, z_i$ 计算 $u_i$ 或其逆的成本。\n\n**$p_U(u)$ 的评估**\n要计算 $p_U(u) = p_Z(T^{-1}(u)) |\\det(J_{T^{-1}}(u))|$，需要进行两个主要计算：\n1.  **求逆 $z = T^{-1}(u)$**：对于三角/自回归流，求逆是顺序进行的。$z_1$ 从 $u_1$ 计算，然后 $z_2$ 从 $u_1, u_2$ 计算，依此类推。计算 $z_i$ 需要 $u_1, \\dots, u_i$ 的值和已经计算出的 $z_1, \\dots, z_{i-1}$，这与分量成本模型一致。由于有 $d$ 个分量需要顺序计算，求逆的总成本为 $\\mathcal{O}(dC)$。\n2.  **雅可比行列式 $|\\det(J_{T^{-1}}(u))|$**：如任务2所示，自回归映射的雅可比矩阵是三角形的（在我们的例子中，$T^{-1}$ 的雅可比矩阵是下三角矩阵）。行列式是对角线元素的乘积。第 $i$ 个对角线元素是 $\\partial z_i / \\partial u_i$。对于给定的仿射自回归映射，这仅仅是 $1/\\alpha_i$，其计算成本为 $\\mathcal{O}(1)$。在一般的自回归流中，计算 $\\partial z_i / \\partial u_i$ 的复杂度通常与计算 $z_i$ 本身的复杂度同阶，因此我们可以说它是 $\\mathcal{O}(C)$。为了找到行列式，我们计算 $d$ 个这样的项并将它们相乘。因此，总成本为 $\\mathcal{O}(dC)$。\n\n评估 $p_U(u)$ 的总成本是这些成本的总和，再加上评估 $p_Z(z)$ 的成本（通常为 $\\mathcal{O}(d)$），因此总复杂度为 $\\mathcal{O}(dC)$。\n\n**计算 $\\nabla_u \\log p_U(u)$**\n梯度可以使用反向模式自动微分（反向传播）高效计算。$\\log p_U(u)$ 的计算图涉及顺序求逆 $z=T^{-1}(u)$、对数行列式的计算以及 $\\log p_Z(z)$ 的评估。计算标量值 $\\log p_U(u)$ 的前向传播成本为 $\\mathcal{O}(dC)$。自动微分的一个基本结果是，标量值函数的梯度可以通过一次反向传播来计算，其计算成本是前向传播成本的一个小的常数倍。因此，计算 $\\nabla_u \\log p_U(u)$ 的复杂度也是 $\\mathcal{O}(dC)$。\n\n**与密集流的比较**\n对于密集、非三角流，计算成本要高得多：\n-   **评估 $p_U(u)$**：\n    -   对映射求逆 $z = T^{-1}(u)$，通常需要迭代数值求解器（例如，牛顿法），因为通常没有闭式逆。这在计算上是密集的，并且可能不收敛。\n    -   假设找到了 $z$，则必须计算雅可比行列式。对于一个密集的 $d \\times d$ 矩阵，这个计算（通常通过LU分解）的复杂度为 $\\mathcal{O}(d^3)$。这种立方级扩展使得密集流对于高维问题来说是令人望而却步的。总体复杂度由行列式计算主导，为 $\\mathcal{O}(d^3)$。\n-   **计算 $\\nabla_u \\log p_U(u)$**：梯度计算涉及诸如雅可比矩阵的逆 $(J_T(z))^{-1}$ 和对数行列式的梯度等项。这些操作的复杂度也至少为 $\\mathcal{O}(d^3)$。\n\n**比较结论：** 自回归三角流在可扩展性方面提供了关键优势。它们的密度评估和梯度计算的复杂度为 $\\mathcal{O}(dC)$，在维度 $d$ 上是线性的（对于固定的 $C$），而密集流的复杂度为 $\\mathcal{O}(d^3)$。这使得三角流成为高维贝叶斯推断的实用选择，而密集流通常仅限于低维问题。", "answer": "$$\\boxed{0.003161}$$", "id": "3414140"}]}