{"hands_on_practices": [{"introduction": "确定充分的“预烧期”（burn-in period）是马尔可夫链蒙特卡洛（MCMC）分析中的一个基本挑战。本练习将超越定性的启发式方法，要求您从第一性原理出发，推导出一个定量的预烧期准则。通过将Kullback-Leibler散度等工具应用于一个线性高斯模型[@problem_id:3370153]，您将精确计算出所需迭代次数，以确保马尔可夫链的分布与真实后验分布足够接近，从而为评估MCMC收敛性提供坚实的理论基础。", "problem": "考虑一个线性高斯逆问题，其中未知状态向量 $x \\in \\mathbb{R}^{n}$ 通过正演模型 $y = G x + \\varepsilon$ 与数据 $y \\in \\mathbb{R}^{m}$ 相关联，其中 $G \\in \\mathbb{R}^{m \\times n}$ 是已知的，观测噪声 $\\varepsilon$ 是均值为零、协方差为正定矩阵 $\\Gamma \\in \\mathbb{R}^{m \\times m}$ 的高斯噪声。假设一个高斯先验 $x \\sim \\mathcal{N}(m_{0}, C_{0})$，其均值为 $m_{0} \\in \\mathbb{R}^{n}$，协方差为对称正定矩阵 $C_{0} \\in \\mathbb{R}^{n \\times n}$。一个经过充分检验的标准事实是，后验分布是高斯分布，其均值 $m_{\\mathrm{post}}$ 和协方差 $C_{\\mathrm{post}}$ 由基于正规方程的线性系统的唯一解给出：\n$$\nC_{\\mathrm{post}}^{-1} = C_{0}^{-1} + G^{\\top}\\Gamma^{-1}G, \n\\quad \nm_{\\mathrm{post}} = C_{\\mathrm{post}}\\left(C_{0}^{-1} m_{0} + G^{\\top}\\Gamma^{-1}y\\right).\n$$\n\n为从后验中采样，考虑使 $\\mathcal{N}(m_{\\mathrm{post}}, C_{\\mathrm{post}})$ 保持不变的自回归马尔可夫链蒙特卡洛（MCMC）核：\n$$\nx_{k+1} = m_{\\mathrm{post}} + \\rho \\left(x_{k} - m_{\\mathrm{post}}\\right) + \\eta_{k}, \n\\quad \\eta_{k} \\sim \\mathcal{N}(0, (1 - \\rho^{2}) C_{\\mathrm{post}}),\n$$\n其中收缩参数 $\\rho \\in (0,1)$ 是固定的，且新息 $\\eta_{k}$ 是独立的。此更新产生一个线性高斯马尔可夫链，该链是遍历的，其平稳分布等于后验分布。\n\n将预烧期定义为最小的非负整数 $k$，使得在给定的确定性初始状态 $x_0$ 下，$x_k$ 的边缘分布与后验分布 $\\mathcal{N}(m_{\\mathrm{post}}, C_{\\mathrm{post}})$ 之间的距离（以全变差距离衡量）在指定的容差 $\\tau$ 之内。你的推导必须基于基本定义和以下经过充分检验的事实：\n- 全变差距离的定义。\n- 连接全变差距离与库尔贝克-莱布勒散度的 Pinsker 不等式。\n- 多元高斯分布的库尔贝克-莱布勒散度的闭式解。\n\n你的任务是：\n- 从第一性原理和上述经过充分检验的事实出发，推导一个明确的、可计算的准则，用以确定保证全变差距离最大为 $\\tau$ 所需的最小预烧迭代次数，分别针对两种确定性初始化 $x_{0} = m_{0}$（先验均值）和 $x_{0} = m_{\\mathrm{post}}$（后验均值）。\n- 通过报告两种预烧期计数来量化初始化的影响。\n- 此外，确定一个稀疏因子 $s \\in \\mathbb{N}$，使得稀疏化后的链 $\\{x_{k s}\\}$ 的延迟为1的自相关性最大为给定的阈值 $\\alpha \\in (0,1)$，利用该自回归链的延迟为 $\\ell$ 的自相关性沿每个后验模态都像 $\\rho^{\\ell}$ 一样按几何级数衰减的事实。\n\n实现一个完整的程序，为每个测试用例执行以下操作：\n1. 从提供的输入构建 $C_{\\mathrm{post}}^{-1}$ 和 $m_{\\mathrm{post}}$。\n2. 计算当 $x_{0} = m_{0}$ 时的最小预烧迭代次数 $k_{\\mathrm{prior}}$。\n3. 计算当 $x_{0} = m_{\\mathrm{post}}$ 时的最小预烧迭代次数 $k_{\\mathrm{post}}$。\n4. 计算满足 $\\rho^{s_{\\min}} \\le \\alpha$ 的最小稀疏因子 $s_{\\min}$。\n\n你的程序应仅使用确定性计算；不允许进行任何采样。对于数值线性代数，在适当时使用直接线性求解，而不是显式矩阵求逆。\n\n测试套件：\n为以下三个科学上一致的测试用例提供结果。\n\n- 测试用例 A（一维）：\n  - $n = 1$, $m = 1$.\n  - $G = [\\,2\\,]$.\n  - $m_{0} = [\\,0\\,]$.\n  - $C_{0} = [\\,[\\,1\\,]\\,]$.\n  - $\\Gamma = [\\,[\\,0.25\\,]\\,]$.\n  - $y = [\\,1.0\\,]$.\n  - $\\rho = 0.9$.\n  - 容差 $\\tau = 0.05$.\n  - 稀疏阈值 $\\alpha = 0.2$.\n\n- 测试用例 B（二维）：\n  - $n = 2$, $m = 2$.\n  - $G = \\begin{bmatrix} 1  -1 \\\\ 0  2 \\end{bmatrix}$.\n  - $m_{0} = [\\,0, 0\\,]^{\\top}$.\n  - $C_{0} = \\mathrm{diag}([\\,4, 1\\,])$.\n  - $\\Gamma = \\mathrm{diag}([\\,0.5, 0.5\\,])$.\n  - $y = [\\,1.0, -1.0\\,]^{\\top}$.\n  - $\\rho = 0.95$.\n  - 容差 $\\tau = 0.02$.\n  - 稀疏阈值 $\\alpha = 0.1$.\n\n- 测试用例 C（五维）：\n  - $n = 5$, $m = 5$.\n  - $G = \\begin{bmatrix}\n    1  0  0  0  0 \\\\\n    0.5  1  0  0  0 \\\\\n    0  0.5  1  0  0 \\\\\n    0  0  0.5  1  0 \\\\\n    0  0  0  0.5  1\n  \\end{bmatrix}$.\n  - $m_{0} = [\\,0, 0, 0, 0, 0\\,]^{\\top}$.\n  - $C_{0} = \\mathrm{diag}([\\,9, 4, 1, 4, 9\\,])$.\n  - $\\Gamma = \\mathrm{diag}([\\,0.5, 2.0, 1.5, 1.0, 0.8\\,])$.\n  - $y = [\\,1.0, -1.0, 0.5, 2.0, -0.5\\,]^{\\top}$.\n  - $\\rho = 0.85$.\n  - 容差 $\\tau = 0.005$.\n  - 稀疏阈值 $\\alpha = 0.05$.\n\n最终输出格式：\n你的程序应生成单行输出，包含一个含三个条目的列表，每个条目对应一个测试用例，而每个条目本身又是一个由三个整数 $[\\,k_{\\mathrm{prior}}, k_{\\mathrm{post}}, s_{\\min}\\,]$ 组成的列表。最终打印的行必须严格遵循以下格式\n$$\n[\\,[k_{\\mathrm{prior}}^{A},k_{\\mathrm{post}}^{A},s_{\\min}^{A}],\\,[k_{\\mathrm{prior}}^{B},k_{\\mathrm{post}}^{B},s_{\\min}^{B}],\\,[k_{\\mathrm{prior}}^{C},k_{\\mathrm{post}}^{C},s_{\\min}^{C}]\\,],\n$$\n不含多余空格。不涉及物理单位或角度单位。所有答案必须是整数。", "solution": "该问题要求推导并实现用于确定特定马尔可夫链蒙特卡洛（MCMC）采样器在线性高斯逆问题中的预烧期和稀疏因子的准则。解决方案分三个阶段进行：首先，严格推导预烧期准则；其次，推导稀疏因子；第三，实现这些准则。\n\n### 问题验证\n\n**步骤1：提取给定条件**\n- **正演模型**：$y = G x + \\varepsilon$，其中 $x \\in \\mathbb{R}^{n}$，$y \\in \\mathbb{R}^{m}$，$G \\in \\mathbb{R}^{m \\times n}$。\n- **观测噪声**：$\\varepsilon \\sim \\mathcal{N}(0, \\Gamma)$，其中 $\\Gamma \\in \\mathbb{R}^{m \\times m}$ 是一个正定协方差矩阵。\n- **先验分布**：$x \\sim \\mathcal{N}(m_{0}, C_{0})$，均值为 $m_{0} \\in \\mathbb{R}^{n}$，协方差为对称正定矩阵 $C_{0} \\in \\mathbb{R}^{n \\times n}$。\n- **后验分布**：$\\mathcal{N}(m_{\\mathrm{post}}, C_{\\mathrm{post}})$，其精度矩阵为 $C_{\\mathrm{post}}^{-1} = C_{0}^{-1} + G^{\\top}\\Gamma^{-1}G$，均值为 $m_{\\mathrm{post}} = C_{\\mathrm{post}}(C_{0}^{-1} m_{0} + G^{\\top}\\Gamma^{-1}y)$。\n- **MCMC 核**：$x_{k+1} = m_{\\mathrm{post}} + \\rho \\left(x_{k} - m_{\\mathrm{post}}\\right) + \\eta_{k}$，其中 $\\eta_{k} \\sim \\mathcal{N}(0, (1 - \\rho^{2}) C_{\\mathrm{post}})$ 且 $\\rho \\in (0,1)$。\n- **初始状态**：确定性初始状态 $x_{0}$。\n- **预烧期定义**：最小非负整数 $k$，使得 $x_k$ 的分布与后验分布之间的全变差距离至多为 $\\tau$。\n- **工具**：全变差距离、Pinsker 不等式、多元高斯分布的闭式库尔贝克-莱布勒（KL）散度。\n- **初始化**：$x_{0} = m_{0}$ 和 $x_{0} = m_{\\mathrm{post}}$。\n- **稀疏化定义**：最小整数 $s \\ge 1$，使得稀疏化后的链 $\\{x_{ks}\\}$ 的延迟为1的自相关至多为 $\\alpha$。给定延迟为 $\\ell$ 的自相关为 $\\rho^{\\ell}$。\n- **测试数据**：提供了三组不同的参数集 $(n, m, G, m_0, C_0, \\Gamma, y, \\rho, \\tau, \\alpha)$。\n\n**步骤2：使用提取的给定条件进行验证**\n该问题具有科学依据，提法明确且客观。它根植于线性高斯模型的贝叶斯逆问题和基本 MCMC 理论的标准理论。后验方程是标准的。MCMC 采样器是一个著名的自回归过程，旨在收敛到目标高斯分布。使用如全变差距离和 KL 散度等信息论度量来分析概率分布的收敛性是标准做法。所有参数和条件都已指定，不存在歧义或矛盾。矩阵 $C_0$ 和 $\\Gamma$ 被指定为正定，确保它们的逆存在。后验精度矩阵 $C_{\\mathrm{post}}^{-1}$ 是一个正定矩阵 ($C_0^{-1}$) 和一个半正定矩阵 ($G^T \\Gamma^{-1} G$) 之和，这使得 $C_{\\mathrm{post}}^{-1}$ 也是正定的。因此，存在唯一的后验分布。该问题是应用概率和数值线性代数的一个形式化练习，而非非形式化的类比或琐碎问题。\n\n**步骤3：结论与行动**\n该问题是**有效的**。开始进行求解。\n\n### 预烧期准则的推导\n\n预烧期被定义为所需的最小迭代次数 $k$，以使链的边缘分布 $P_k$ “接近”平稳后验分布 $P_{\\mathrm{post}} = \\mathcal{N}(m_{\\mathrm{post}}, C_{\\mathrm{post}})$。接近程度的度量是全变差距离 $d_{TV}(P_k, P_{\\mathrm{post}})$。问题要求使用 Pinsker 不等式获得一个上界，该不等式将全变差距离与库尔贝克-莱布勒（KL）散度联系起来：\n$$d_{TV}(P_k, P_{\\mathrm{post}}) \\le \\sqrt{\\frac{1}{2} D_{KL}(P_k || P_{\\mathrm{post}})}$$\n因此，如果我们强制执行更强的条件，预烧期条件 $d_{TV}(P_k, P_{\\mathrm{post}}) \\le \\tau$ 就能得到保证：\n$$\\sqrt{\\frac{1}{2} D_{KL}(P_k || P_{\\mathrm{post}})} \\le \\tau \\quad \\iff \\quad D_{KL}(P_k || P_{\\mathrm{post}}) \\le 2\\tau^2$$\n要使用此准则，我们必须首先找到在任何给定迭代 $k$ 时状态向量 $x_k$ 的分布 $P_k$。链从一个确定性状态 $x_0$ 开始。更新规则是线性的，并且新息 $\\eta_k$ 是高斯的，因此对于所有 $k \\ge 1$，$x_k$ 都将是高斯分布的。设 $x_k \\sim \\mathcal{N}(\\mu_k, \\Sigma_k)$。\n\n均值 $\\mu_k$ 的演化遵循：\n$$\\mu_{k+1} = E[x_{k+1}] = E[m_{\\mathrm{post}} + \\rho(x_k - m_{\\mathrm{post}}) + \\eta_k] = m_{\\mathrm{post}} + \\rho(\\mu_k - m_{\\mathrm{post}})$$\n这是与后验均值偏差 $\\delta_k = \\mu_k - m_{\\mathrm{post}}$ 的一个简单几何级数。我们有 $\\delta_{k+1} = \\rho \\delta_k$，这意味着 $\\delta_k = \\rho^k \\delta_0$。由于 $x_0$ 是确定性的，$\\mu_0 = x_0$，因此 $\\delta_0 = x_0 - m_{\\mathrm{post}}$。在迭代 $k$ 时的均值是：\n$$\\mu_k = m_{\\mathrm{post}} + \\rho^k(x_0 - m_{\\mathrm{post}})$$\n协方差 $\\Sigma_k$ 的演化遵循：\n$$\\Sigma_{k+1} = \\mathrm{Cov}(x_{k+1}) = \\mathrm{Cov}(\\rho(x_k - m_{\\mathrm{post}}) + \\eta_k) = \\rho^2 \\mathrm{Cov}(x_k) + \\mathrm{Cov}(\\eta_k)$$\n这里我们使用了 $x_k$ 和 $\\eta_k$ 的独立性。代入定义：\n$$\\Sigma_{k+1} = \\rho^2 \\Sigma_k + (1-\\rho^2)C_{\\mathrm{post}}$$\n从一个确定性的 $x_0$ 开始，初始协方差为 $\\Sigma_0 = \\mathbf{0}$。递推展开为：\n$\\Sigma_1 = (1-\\rho^2)C_{\\mathrm{post}}$\n$\\Sigma_2 = \\rho^2(1-\\rho^2)C_{\\mathrm{post}} + (1-\\rho^2)C_{\\mathrm{post}} = (1-\\rho^4)C_{\\mathrm{post}}$\n通过归纳法，在迭代 $k$ 时的协方差是：\n$$\\Sigma_k = (1 - \\rho^{2k}) C_{\\mathrm{post}}$$\n对于 $k=0$，分布 $P_0$ 是在 $x_0$ 处的一个点质量。点质量与连续分布（后验分布）之间的全变差距离为 $1$。由于给定的容差 $\\tau \\ll 1$，在 $k=0$ 时条件 $d_{TV} \\le \\tau$ 永远无法满足。因此，我们寻求最小的整数 $k \\ge 1$。对于 $k \\ge 1$，$\\Sigma_k$ 是正定的，且 $P_k = \\mathcal{N}(\\mu_k, \\Sigma_k)$ 是一个有效的非退化高斯分布。\n\n从一个高斯分布 $P_1 = \\mathcal{N}(\\mu_1, \\Sigma_1)$到另一个高斯分布 $P_2 = \\mathcal{N}(\\mu_2, \\Sigma_2)$的 KL 散度为：\n$$D_{KL}(P_1 || P_2) = \\frac{1}{2} \\left( \\mathrm{Tr}(\\Sigma_2^{-1} \\Sigma_1) + (\\mu_2-\\mu_1)^{\\top} \\Sigma_2^{-1} (\\mu_2-\\mu_1) - n + \\ln\\left(\\frac{\\det \\Sigma_2}{\\det \\Sigma_1}\\right) \\right)$$\n在我们的情况下，$P_1 = P_k$ 和 $P_2 = P_{\\mathrm{post}}$。我们代入 $\\mu_1=\\mu_k, \\Sigma_1=\\Sigma_k, \\mu_2=m_{\\mathrm{post}}, \\Sigma_2=C_{\\mathrm{post}}$：\n-   迹项：$\\mathrm{Tr}(C_{\\mathrm{post}}^{-1} \\Sigma_k) = \\mathrm{Tr}(C_{\\mathrm{post}}^{-1} (1-\\rho^{2k})C_{\\mathrm{post}}) = \\mathrm{Tr}((1-\\rho^{2k})I_n) = n(1-\\rho^{2k})$。\n-   二次项：$(\\mu_2-\\mu_1)^{\\top} \\Sigma_2^{-1} (\\mu_2-\\mu_1) = (-\\rho^k(x_0 - m_{\\mathrm{post}}))^{\\top} C_{\\mathrm{post}}^{-1} (-\\rho^k(x_0 - m_{\\mathrm{post}})) = \\rho^{2k}(x_0 - m_{\\mathrm{post}})^{\\top} C_{\\mathrm{post}}^{-1} (x_0 - m_{\\mathrm{post}})$。\n-   对数行列式项：$\\ln(\\frac{\\det C_{\\mathrm{post}}}{\\det \\Sigma_k}) = \\ln(\\frac{\\det C_{\\mathrm{post}}}{\\det((1-\\rho^{2k})C_{\\mathrm{post}})}) = \\ln(\\frac{1}{(1-\\rho^{2k})^n}) = -n \\ln(1-\\rho^{2k})$。\n\n结合这些项，KL 散度为：\n$$D_{KL}(P_k || P_{\\mathrm{post}}) = \\frac{1}{2} \\left[ n(1-\\rho^{2k}) + \\rho^{2k} D^2 - n - n\\ln(1-\\rho^{2k}) \\right]$$\n其中 $D^2 = (x_0 - m_{\\mathrm{post}})^{\\top} C_{\\mathrm{post}}^{-1} (x_0 - m_{\\mathrm{post}})$ 是 $x_0$ 和 $m_{\\mathrm{post}}$ 之间关于 $C_{\\mathrm{post}}$ 的马氏距离的平方。\n简化此表达式得到：\n$$D_{KL}(P_k || P_{\\mathrm{post}}) = \\frac{1}{2} \\left[ \\rho^{2k} (D^2 - n) - n\\ln(1-\\rho^{2k}) \\right]$$\n预烧期准则是找到满足以下条件的最小整数 $k \\ge 1$：\n$$\\frac{1}{2} \\left[ \\rho^{2k} (D^2 - n) - n\\ln(1-\\rho^{2k}) \\right] \\le 2\\tau^2$$\n这个不等式通过对 $k=1, 2, 3, \\dots$ 进行数值迭代，直到条件满足为止来求解。\n\n**情况1：在后验均值处初始化 ($x_0 = m_{\\mathrm{post}}$)**\n此时，$x_0 - m_{\\mathrm{post}} = \\mathbf{0}$，所以 $D^2 = 0$。$k_{\\mathrm{post}}$ 的准则简化为找到满足以下条件的最小整数 $k \\ge 1$：\n$$\\frac{1}{2} \\left[ -n\\rho^{2k} - n\\ln(1-\\rho^{2k}) \\right] \\le 2\\tau^2 \\iff -\\rho^{2k} - \\ln(1-\\rho^{2k}) \\le \\frac{4\\tau^2}{n}$$\n\n**情况2：在先验均值处初始化 ($x_0 = m_0$)**\n此时，我们首先计算马氏距离的平方 $D_{\\mathrm{prior}}^2 = (m_0 - m_{\\mathrm{post}})^{\\top} C_{\\mathrm{post}}^{-1} (m_0 - m_{\\mathrm{post}})$。$k_{\\mathrm{prior}}$ 的准则是找到满足以下条件的最小整数 $k \\ge 1$：\n$$\\rho^{2k} (D_{\\mathrm{prior}}^2 - n) - n\\ln(1-\\rho^{2k}) \\le 4\\tau^2$$\n\n### 稀疏因子的推导\n\n选择稀疏因子 $s$ 以减少链中的自相关。问题陈述，原始链 $\\{x_k\\}$ 的延迟为 $\\ell$ 的自相关为 $\\rho^{\\ell}$。稀疏化后的链是通过每 $s$ 个样本取一个形成的：$\\{x_{ks}\\}$。这个稀疏链的延迟为1的自相关等价于原始链的延迟为 $s$ 的自相关。我们要求这个自相关不大于给定的阈值 $\\alpha$。\n因此，条件是：\n$$\\rho^s \\le \\alpha$$\n因为 $\\rho \\in (0,1)$ 且 $\\alpha \\in (0,1)$，我们可以对两边取自然对数。由于 $\\ln(\\rho)$ 是负数，除以它时必须反转不等号：\n$$s \\ln(\\rho) \\le \\ln(\\alpha) \\implies s \\ge \\frac{\\ln(\\alpha)}{\\ln(\\rho)}$$\n由于 $s$ 必须是一个正整数 ($s \\in \\mathbb{N}$)，最小稀疏因子 $s_{\\min}$ 是满足此条件的最小整数：\n$$s_{\\min} = \\left\\lceil \\frac{\\ln(\\alpha)}{\\ln(\\rho)} \\right\\rceil$$\n\n### 计算算法\n\n对于每个测试用例，算法按以下步骤进行：\n1.  读取参数 $n, m, G, m_0, C_0, \\Gamma, y, \\rho, \\tau, \\alpha$。\n2.  计算先验和噪声协方差矩阵的逆 $C_0^{-1}$ 和 $\\Gamma^{-1}$。\n3.  计算后验精度矩阵 $C_{\\mathrm{post}}^{-1} = C_{0}^{-1} + G^{\\top}\\Gamma^{-1}G$。\n4.  计算向量项 $b = C_{0}^{-1} m_{0} + G^{\\top}\\Gamma^{-1}y$。\n5.  求解线性系统 $C_{\\mathrm{post}}^{-1}m_{\\mathrm{post}} = b$ 以找到后验均值 $m_{\\mathrm{post}}$。\n6.  为了找到 $k_{\\mathrm{post}}$，迭代 $k=1, 2, \\dots$ 直到 $-\\rho^{2k} - \\ln(1-\\rho^{2k}) \\le 4\\tau^2/n$。第一个满足此条件的 $k$ 即为 $k_{\\mathrm{post}}$。\n7.  为了找到 $k_{\\mathrm{prior}}$，首先计算马氏距离的平方 $D_{\\mathrm{prior}}^2 = (m_0 - m_{\\mathrm{post}})^{\\top} C_{\\mathrm{post}}^{-1} (m_0 - m_{\\mathrm{post}})$。然后，迭代 $k=1, 2, \\dots$ 直到 $\\rho^{2k} (D_{\\mathrm{prior}}^2 - n) - n\\ln(1-\\rho^{2k}) \\le 4\\tau^2$。第一个满足此条件的 $k$ 即为 $k_{\\mathrm{prior}}$。\n8.  计算最小稀疏因子 $s_{\\min} = \\lceil \\ln(\\alpha)/\\ln(\\rho) \\rceil$。\n9.  收集整数结果 $[k_{\\mathrm{prior}}, k_{\\mathrm{post}}, s_{\\min}]$。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the MCMC burn-in and thinning problem for the given test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"n\": 1, \"m\": 1,\n            \"G\": np.array([[2.0]]),\n            \"m0\": np.array([0.0]),\n            \"C0\": np.array([[1.0]]),\n            \"Gamma\": np.array([[0.25]]),\n            \"y\": np.array([1.0]),\n            \"rho\": 0.9, \"tau\": 0.05, \"alpha\": 0.2,\n        },\n        {\n            \"n\": 2, \"m\": 2,\n            \"G\": np.array([[1.0, -1.0], [0.0, 2.0]]),\n            \"m0\": np.array([0.0, 0.0]),\n            \"C0\": np.diag([4.0, 1.0]),\n            \"Gamma\": np.diag([0.5, 0.5]),\n            \"y\": np.array([1.0, -1.0]),\n            \"rho\": 0.95, \"tau\": 0.02, \"alpha\": 0.1,\n        },\n        {\n            \"n\": 5, \"m\": 5,\n            \"G\": np.array([\n                [1.0, 0.0, 0.0, 0.0, 0.0],\n                [0.5, 1.0, 0.0, 0.0, 0.0],\n                [0.0, 0.5, 1.0, 0.0, 0.0],\n                [0.0, 0.0, 0.5, 1.0, 0.0],\n                [0.0, 0.0, 0.0, 0.5, 1.0]\n            ]),\n            \"m0\": np.array([0.0, 0.0, 0.0, 0.0, 0.0]),\n            \"C0\": np.diag([9.0, 4.0, 1.0, 4.0, 9.0]),\n            \"Gamma\": np.diag([0.5, 2.0, 1.5, 1.0, 0.8]),\n            \"y\": np.array([1.0, -1.0, 0.5, 2.0, -0.5]),\n            \"rho\": 0.85, \"tau\": 0.005, \"alpha\": 0.05,\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        results.append(solve_case(case))\n\n    # Format the final output string\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef get_burn_in(n, rho, D2, tau, max_iter=100000):\n    \"\"\"\n    Computes the minimal burn-in iteration count.\n    \"\"\"\n    threshold = 4 * tau**2\n    \n    # Iterate to find the smallest k >= 1 satisfying the condition\n    for k in range(1, max_iter):\n        rho_2k = rho**(2 * k)\n        \n        # This is the LHS of the inequality derived in the solution text\n        # D_KL * 2 = rho^{2k} (D^2 - n) - n ln(1-rho^{2k})\n        kl_term = rho_2k * (D2 - n) - n * np.log(1 - rho_2k)\n        \n        if kl_term = threshold:\n            return k\n    return max_iter # Should not be reached with reasonable max_iter\n\ndef solve_case(params):\n    \"\"\"\n    Processes a single test case.\n    \"\"\"\n    n = params[\"n\"]\n    G, m0, C0, Gamma, y = params[\"G\"], params[\"m0\"], params[\"C0\"], params[\"Gamma\"], params[\"y\"]\n    rho, tau, alpha = params[\"rho\"], params[\"tau\"], params[\"alpha\"]\n\n    # Ensure vectors are column vectors for matrix operations\n    m0 = m0.reshape(-1, 1)\n    y = y.reshape(-1, 1)\n\n    # 1. Compute posterior parameters\n    C0_inv = np.linalg.inv(C0)\n    Gamma_inv = np.linalg.inv(Gamma)\n\n    C_post_inv = C0_inv + G.T @ Gamma_inv @ G\n    b = C0_inv @ m0 + G.T @ Gamma_inv @ y\n    m_post = np.linalg.solve(C_post_inv, b)\n\n    # 2. Compute burn-in for x0 = m_post\n    # D^2 = (m_post - m_post)^T C_post_inv (m_post - m_post) = 0\n    D2_post = 0.0\n    k_post = get_burn_in(n, rho, D2_post, tau)\n\n    # 3. Compute burn-in for x0 = m0\n    delta_m = m0 - m_post\n    D2_prior = (delta_m.T @ C_post_inv @ delta_m).item() # .item() to get scalar\n    k_prior = get_burn_in(n, rho, D2_prior, tau)\n    \n    # 4. Compute thinning factor\n    s_min = int(np.ceil(np.log(alpha) / np.log(rho)))\n\n    return [k_prior, k_post, s_min]\n\nsolve()\n\n```", "id": "3370153"}, {"introduction": "当马尔可夫链达到平稳状态后，样本间的相关性会使不确定性量化变得复杂。这个动手实践将通过模拟来探索“批次均值”（batch means）方法，该方法用于估计来自相关MCMC链的后验摘要的方差[@problem_id:3370133]。您将比较使用完整预烧后链与经过“稀疏化”（thinning）处理的链所得到的结果，从而直接研究稀疏化对估计精度的实际影响，并理解在降低相关性和保留样本数量之间的权衡。", "problem": "给定一个标量线性高斯逆问题、一个保持后验分布的合成马尔可夫链蒙特卡洛 (MCMC) 采样器，以及一个要求：使用批均值法在两种策略（仅使用预烧期，以及预烧期后进行稀疏化）下估计后验均值的不确定性。你的任务是编写一个程序，该程序模拟马尔可夫链，计算后验均值估计量的批均值 (BM) 方差估计，基于 Student-$t$ 分布构建双侧置信区间，并比较有无稀疏化时的区间宽度。\n\n从以下基本原理和定义开始。\n\n1. 线性高斯逆问题。假设一个一维未知数 $x$ 的先验分布为 $x \\sim \\mathcal{N}(0,\\tau^2)$，一个线性正演算子 $h \\in \\mathbb{R}$，以及单个观测值 $y \\in \\mathbb{R}$，其加性噪声为 $\\varepsilon \\sim \\mathcal{N}(0,r^2)$，因此 $y = h x + \\varepsilon$。根据高斯共轭的 Bayes 法则，后验分布 $p(x \\mid y)$ 是高斯分布，其均值 $m$ 和方差 $s^2$ 由下式给出：\n$$\ns^2 = \\left(\\tau^{-2} + h^2 r^{-2}\\right)^{-1}, \\quad m = s^2 \\cdot h r^{-2} y.\n$$\n\n2. 具有指定自相关的合成 MCMC。考虑由下式定义的一阶自回归过程 (AR(1))：\n$$\nX_{t+1} = m + \\rho \\left(X_t - m\\right) + \\sqrt{\\left(1-\\rho^2\\right) s^2}\\, Z_t,\n$$\n其中 $\\{Z_t\\}$ 是独立同分布的标准正态随机变量，$\\rho \\in (-1,1)$ 是滞后-1 自相关。该链是高斯链，其平稳分布为 $\\mathcal{N}(m,s^2)$。\n\n3. 预烧期 (Burn-in) 和稀疏化 (thinning)。给定一条模拟路径 $\\{X_t\\}_{t=1}^T$：\n- 预烧期丢弃前 $B$ 个状态以减少初始化偏差，得到长度为 $n = T - B$ 的保留序列 $\\{X_{B+1},\\dots,X_T\\}$。\n- 以因子 $k \\in \\mathbb{N}$ 进行稀疏化，即保留该序列中每第 $k$ 个元素，得到 $\\{X_{B+1}, X_{B+1+k}, X_{B+1+2k}, \\dots\\}$，其长度为 $n_{\\mathrm{thin}} = \\left\\lfloor \\frac{n}{k} \\right\\rfloor$。\n\n4. 用于马尔可夫链中心极限定理的批均值方差估计。令 $g(x) = x$ 表示恒等函数，这样目标就是估计 $\\mu = \\mathbb{E}_{\\pi}[g(X)] = m$。假设马尔可夫链中心极限定理 (CLT) 成立：设 $Y_t = g(X_t)$，\n$$\n\\sqrt{n}\\left(\\bar{Y}_n - \\mu\\right) \\xrightarrow{d} \\mathcal{N}(0,\\sigma^2),\n$$\n其中 $\\bar{Y}_n = \\frac{1}{n} \\sum_{t=1}^n Y_t$，$\\sigma^2$ 是渐近方差。批均值估计量将 $Y_1,\\dots,Y_n$ 划分为 $b$ 个不重叠的批次，每批大小为 $a$，因此 $n = a b$。设批均值为 $\\bar{Y}^{(i)} = \\frac{1}{a} \\sum_{t=(i-1)a+1}^{ia} Y_t$，其中 $i \\in \\{1,\\dots,b\\}$，并设 $\\bar{Y}$ 为总均值。渐近方差的估计量为\n$$\n\\hat{\\sigma}^2_{\\mathrm{BM}} = a \\cdot \\frac{1}{b-1} \\sum_{i=1}^b \\left(\\bar{Y}^{(i)} - \\bar{Y}\\right)^2,\n$$\n因此，$\\mathrm{Var}(\\bar{Y}_n)$ 的估计量为\n$$\n\\widehat{\\mathrm{Var}}(\\bar{Y}_n) = \\frac{\\hat{\\sigma}^2_{\\mathrm{BM}}}{n}.\n$$\n在名义水平 $1-\\alpha$ 下，$\\mu$ 的双侧置信区间则为\n$$\n\\bar{Y}_n \\pm t_{1-\\alpha/2,\\,b-1} \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)},\n$$\n其中 $t_{1-\\alpha/2,\\,b-1}$ 是具有 $b-1$ 个自由度的 Student-$t$ 分布的分位数。因此，置信区间的宽度为\n$$\nW = 2 \\, t_{1-\\alpha/2,\\,b-1} \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)}.\n$$\n\n你的程序必须为每个测试用例实现以下步骤：\n\na. 使用给定的 $(h,\\tau^2,r^2,y)$ 计算后验均值 $m$ 和方差 $s^2$。\n\nb. 使用参数 $\\rho$ 模拟长度为 $T$ 的 AR(1) 链，以指定的偏移量 $\\delta$ 初始化于 $X_1 = m + \\delta$（所有用例使用相同的 $\\delta$），并使用独立的标准正态新息。\n\nc. 通过丢弃前 $B$ 个样本来应用预烧期。对于未稀疏化的路径，使用恰好 $b$ 个批次和相应的批大小 $a = n/b$ 来计算批均值方差估计 $\\widehat{\\mathrm{Var}}(\\bar{Y}_n)$（假设参数确保在必要时截断任何多余样本后，整数除法是精确的）。构建水平为 $1-\\alpha$ 的双侧置信区间，并记录其宽度 $W_{\\mathrm{nt}}$。\n\nd. 对预烧期后的路径应用因子为 $k$ 的稀疏化，使用相同的 $b$ 个批次（批大小为 $a_{\\mathrm{thin}} = n_{\\mathrm{thin}}/b$）计算批均值方差估计 $\\widehat{\\mathrm{Var}}(\\bar{Y}_{n_{\\mathrm{thin}}})$，构建置信区间，并记录其宽度 $W_{\\mathrm{th}}$。\n\ne. 对于每个测试用例，输出一个元组，其中包含无稀疏化时均值的估计方差、有稀疏化时均值的估计方差、无稀疏化时的置信区间宽度 $W_{\\mathrm{nt}}$、有稀疏化时的置信区间宽度 $W_{\\mathrm{th}}$，以及一个指示 $W_{\\mathrm{th}} > W_{\\mathrm{nt}}$ 是否成立的布尔值。\n\n数值和格式要求：\n\n- 对于名义水平 $1-\\alpha = 0.95$，使用 $\\alpha = 0.05$。\n- 在每个测试用例中，对未稀疏化和稀疏化分析使用相同的批次数 $b$。\n- 使用初始偏移量 $\\delta = 10.0$。\n- 将所有浮点输出四舍五入到 $6$ 位小数。\n- 你的程序应该生成单行输出，包含一个由方括号括起来的逗号分隔列表形式的结果，其中每个元素本身是形如 $[\\widehat{\\mathrm{Var}}(\\bar{Y}_n), \\widehat{\\mathrm{Var}}(\\bar{Y}_{n_{\\mathrm{thin}}}), W_{\\mathrm{nt}}, W_{\\mathrm{th}}, \\text{boolean}]$ 的列表。输出中不包含任何空格。\n\n测试套件：\n\n为以下三个测试用例提供结果；每个用例由 $(h,\\tau^2,r^2,y,\\rho,T,B,b,k,\\text{seed})$ 定义。\n\n- 用例 1 (中等自相关，中等稀疏化): $(h=\\;1.0,\\;\\tau^2=\\;1.0,\\;r^2=\\;1.0,\\;y=\\;1.5,\\;\\rho=\\;0.5,\\;T=\\;50500,\\;B=\\;500,\\;b=\\;50,\\;k=\\;5,\\;\\text{seed}=\\;12345)$。\n\n- 用例 2 (独立同分布，强稀疏化): $(h=\\;2.0,\\;\\tau^2=\\;1.0,\\;r^2=\\;4.0,\\;y=\\;-1.0,\\;\\rho=\\;0.0,\\;T=\\;50500,\\;B=\\;500,\\;b=\\;50,\\;k=\\;10,\\;\\text{seed}=\\;23456)$。\n\n- 用例 3 (强自相关，积极稀疏化): $(h=\\;1.0,\\;\\tau^2=\\;4.0,\\;r^2=\\;1.0,\\;y=\\;0.0,\\;\\rho=\\;0.99,\\;T=\\;200500,\\;B=\\;500,\\;b=\\;50,\\;k=\\;100,\\;\\text{seed}=\\;34567)$。\n\n最终输出格式：\n\n- 你的程序应生成单行输出，其中包含一个含有三个元素的列表，每个元素对应一个测试用例，格式完全如下：\n$[[v_{1,\\mathrm{nt}},v_{1,\\mathrm{th}},w_{1,\\mathrm{nt}},w_{1,\\mathrm{th}},\\mathrm{bool}_1],[v_{2,\\mathrm{nt}},v_{2,\\mathrm{th}},w_{2,\\mathrm{nt}},w_{2,\\mathrm{th}},\\mathrm{bool}_2],[v_{3,\\mathrm{nt}},v_{3,\\mathrm{th}},w_{3,\\mathrm{nt}},w_{3,\\mathrm{th}},\\mathrm{bool}_3]]$，\n其中，对于用例 $i$，$v_{i,\\mathrm{nt}} = \\widehat{\\mathrm{Var}}(\\bar{Y}_n)$；对于用例 $i$，$v_{i,\\mathrm{th}} = \\widehat{\\mathrm{Var}}(\\bar{Y}_{n_{\\mathrm{thin}}})$；对于用例 $i$，$w_{i,\\mathrm{nt}} = W_{\\mathrm{nt}}$；对于用例 $i$，$w_{i,\\mathrm{th}} = W_{\\mathrm{th}}$；$\\mathrm{bool}_i$ 是用例 $i$ 中 $W_{\\mathrm{th}} > W_{\\mathrm{nt}}$ 的布尔值。所有浮点数必须四舍五入到 $6$ 位小数。打印行中不允许有空格。", "solution": "该问题被评估为有效。其前提在科学上是合理的，定义在数学和算法上是精确的，所有必要的数据都已提供，并且任务是适定的。\n\n### **问题验证**\n\n#### **步骤 1：提取给定条件**\n\n**1. 线性高斯逆问题：**\n- 未知数：$x$，先验分布为 $x \\sim \\mathcal{N}(0,\\tau^2)$。\n- 正演算子：$h \\in \\mathbb{R}$。\n- 观测值：$y \\in \\mathbb{R}$，模型为 $y = h x + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0,r^2)$。\n- 后验分布 $p(x \\mid y)$ 为 $\\mathcal{N}(m,s^2)$，其中：\n  $$s^2 = \\left(\\tau^{-2} + h^2 r^{-2}\\right)^{-1}$$\n  $$m = s^2 \\cdot h r^{-2} y$$\n\n**2. 合成 MCMC 采样器：**\n- AR(1) 过程：$X_{t+1} = m + \\rho \\left(X_t - m\\right) + \\sqrt{\\left(1-\\rho^2\\right) s^2}\\, Z_t$。\n- $\\{Z_t\\}$ 为独立同分布的 $\\mathcal{N}(0,1)$。\n- 自相关：$\\rho \\in (-1,1)$。\n- 平稳分布：$\\mathcal{N}(m,s^2)$。\n\n**3. 预烧期和稀疏化：**\n- 总样本数：$T$。\n- 预烧期长度：$B$。保留的序列为 $\\{X_{B+1},\\dots,X_T\\}$，长度为 $n = T-B$。\n- 稀疏化因子：$k \\in \\mathbb{N}$。稀疏化后的序列长度为 $n_{\\mathrm{thin}} = \\left\\lfloor \\frac{n}{k} \\right\\rfloor$。\n\n**4. 批均值方差估计：**\n- 估计目标：$\\mu = \\mathbb{E}_{\\pi}[g(X)]$，其中 $g(x)=x$，因此 $\\mu=m$。\n- 令 $\\{Y_t\\}$ 为 MCMC 链（预烧期后）。\n- 将 $\\{Y_1,\\dots,Y_n\\}$ 划分为 $b$ 个大小为 $a$ 的批次（$n=ab$）。\n- 批均值：$\\bar{Y}^{(i)} = \\frac{1}{a} \\sum_{t=(i-1)a+1}^{ia} Y_t$。\n- 总均值：$\\bar{Y}$。\n- 渐近方差估计量：$\\hat{\\sigma}^2_{\\mathrm{BM}} = a \\cdot \\frac{1}{b-1} \\sum_{i=1}^b \\left(\\bar{Y}^{(i)} - \\bar{Y}\\right)^2$。\n- $\\mathrm{Var}(\\bar{Y}_n)$ 的估计量：$\\widehat{\\mathrm{Var}}(\\bar{Y}_n) = \\frac{\\hat{\\sigma}^2_{\\mathrm{BM}}}{n}$。\n- $\\mu$ 的 $(1-\\alpha)$ 置信区间：$\\bar{Y}_n \\pm t_{1-\\alpha/2,\\,b-1} \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)}$。\n- 置信区间宽度：$W = 2 \\, t_{1-\\alpha/2,\\,b-1} \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)}$。\n\n**5. 数值和任务参数：**\n- 置信水平：$1-\\alpha = 0.95$ ($\\alpha = 0.05$)。\n- 批次数：$b$（对于未稀疏化和稀疏化分析，该值相同）。\n- 初始偏移量：$\\delta = 10.0$（相对于真实均值 $m$）。\n- 四舍五入：浮点输出保留 $6$ 位小数。\n\n**6. 测试用例：**\n- 用例 1: $(h=1.0,\\;\\tau^2=1.0,\\;r^2=1.0,\\;y=1.5,\\;\\rho=0.5,\\;T=50500,\\;B=500,\\;b=50,\\;k=5,\\;\\text{seed}=12345)$。\n- 用例 2: $(h=2.0,\\;\\tau^2=1.0,\\;r^2=4.0,\\;y=-1.0,\\;\\rho=0.0,\\;T=50500,\\;B=500,\\;b=50,\\;k=10,\\;\\text{seed}=23456)$。\n- 用例 3: $(h=1.0,\\;\\tau^2=4.0,\\;r^2=1.0,\\;y=0.0,\\;\\rho=0.99,\\;T=200500,\\;B=500,\\;b=50,\\;k=100,\\;\\text{seed}=34567)$。\n\n#### **步骤 2：使用提取的给定条件进行验证**\n\n该问题是统计模拟和分析中一个定义明确的计算练习。\n- **科学依据充分**：该问题建立在贝叶斯推断（高斯共轭）、时间序列分析（AR(1) 过程）和 MCMC 诊断（用于方差估计的批均值法）的基本原理之上。提供的所有公式都是标准且正确的。\n- **适定性**：为每个测试用例提供了一套完整的参数。模拟和计算的指令是明确的。使用固定的随机种子确保了模拟是可复现的，从而得到唯一的解。样本大小、批次和稀疏化的参数选择使得批次大小是精确的整数，排除了实现中的歧义。\n- **客观性**：该问题使用精确的数学符号和算法步骤进行规定，没有任何主观语言。\n\n该问题没有表现出任何与科学不合理、不完整、矛盾或模糊相关的缺陷。这是逆问题和数据同化领域内一个可形式化且相关的任务。\n\n#### **步骤 3：结论与行动**\n\n问题是**有效**的。将提供完整的解决方案。\n\n### **基于原理的解决方案**\n\n目标是比较从合成 MCMC 链中推导出的、线性高斯逆问题中参数后验均值的不确定性估计。比较在两种策略之间进行：一种仅使用预烧期，另一种使用预烧期后进行稀疏化。不确定性通过置信区间的宽度来量化，该宽度使用批均值法计算。以下步骤详细说明了每个测试用例的处理过程。\n\n**a. 后验表征**\n首先，我们表征后验分布 $p(x \\mid y)$。问题指出，对于高斯先验 $x \\sim \\mathcal{N}(0,\\tau^2)$ 和由模型 $y = h x + \\varepsilon$（其中 $\\varepsilon \\sim \\mathcal{N}(0,r^2)$）产生的高斯似然，后验分布也是高斯的，$p(x \\mid y) \\sim \\mathcal{N}(m, s^2)$。我们应用提供的后验均值 $m$ 和方差 $s^2$ 的公式，这些公式是共轭高斯分布的 Bayes 法则的直接结果。\n$$s^2 = \\left(\\tau^{-2} + h^2 r^{-2}\\right)^{-1}$$\n$$m = s^2 \\cdot h r^{-2} y$$\n\n**b. MCMC 模拟**\n接下来，我们模拟一个马尔可夫链，其平稳分布为后验分布 $\\mathcal{N}(m,s^2)$。问题指定为此目的使用高斯 AR(1) 过程。链的演化由下式给出：\n$$X_{t+1} = m + \\rho \\left(X_t - m\\right) + \\sqrt{\\left(1-\\rho^2\\right) s^2}\\, Z_t$$\n其中 $\\{Z_t\\}$ 是独立同分布的标准正态随机变量序列。该过程被设计为具有平稳均值 $m$、平稳方差 $s^2$ 和滞后-1 自相关 $\\rho$。我们在 $X_1 = m + \\delta$ 处初始化链，以模拟从远离平稳分布处开始的情况，这是实践中的常见场景。模拟总共运行 $T$ 步。使用特定的随机种子以确保可复现性。\n\n**c. 无稀疏化分析（仅预烧期）**\nMCMC 链的初始部分可能会受到起始值的偏置影响。为减轻此影响，我们丢弃前 $B$ 个样本（“预烧期”）。剩余的长度为 $n = T-B$ 的序列用于分析。\n目标是估计样本均值 $\\bar{Y}_n = \\frac{1}{n} \\sum_{t=B+1}^T X_t$ 的方差。由于样本 $X_t$ 是相关的，简单的方差公式 $\\mathrm{Var}(X)/n$ 是不正确的。批均值法通过将 $n$ 个样本分成 $b$ 个大小为 $a=n/b$ 的大批次来解决这个问题。计算每个批次的均值。如果批次大小 $a$ 足够大，则批均值近似不相关。\n然后，我们应用批均值公式计算渐近方差，$\\hat{\\sigma}^2_{\\mathrm{BM}} = a \\cdot \\mathrm{Var}(\\{\\text{批均值}\\})$，其中批均值的方差使用 $b-1$ 个自由度计算。总样本均值的方差则估计为 $\\widehat{\\mathrm{Var}}(\\bar{Y}_n) = \\hat{\\sigma}^2_{\\mathrm{BM}}/n$。\n最后，构建真实均值 $m$ 的 $(1-\\alpha)$ 置信区间。根据 MCMC 中心极限定理，$(\\bar{Y}_n - m)/\\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)}$ 的分布近似于具有 $b-1$ 个自由度的 Student-$t$ 分布。此置信区间的宽度为 $W_{\\mathrm{nt}} = 2 \\cdot t_{1-\\alpha/2, b-1} \\cdot \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)}$。\n\n**d. 有稀疏化分析**\n稀疏化是一种技术，其中只保留预烧期后链的每 $k$ 个样本。这将数据集的大小减少到 $n_{\\mathrm{thin}} = \\lfloor n/k \\rfloor$ 个样本，但同时也减少了它们之间的自相关。对稀疏化链的处理过程与未稀疏化情况类似。我们将 $n_{\\mathrm{thin}}$ 个样本划分为 $b$ 个大小为 $a_{\\mathrm{thin}} = n_{\\mathrm{thin}}/b$ 的批次。批均值方差估计 $\\widehat{\\mathrm{Var}}(\\bar{Y}_{n_{\\mathrm{thin}}})$ 和相应的置信区间宽度 $W_{\\mathrm{th}}$ 使用与之前相同的公式计算，但应用于稀疏化后的数据。批次数 $b$ 以及 t-分布的自由度保持不变。\n\n**e. 比较与输出**\n对于每个测试用例，我们计算并存储五个值：未稀疏化链的均值估计方差 $\\widehat{\\mathrm{Var}}(\\bar{Y}_n)$；稀疏化链的均值估计方差 $\\widehat{\\mathrm{Var}}(\\bar{Y}_{n_{\\mathrm{thin}}})$；它们各自的置信区间宽度 $W_{\\mathrm{nt}}$ 和 $W_{\\mathrm{th}}$；以及一个指示稀疏化是否导致更宽置信区间（$W_{\\mathrm{th}} > W_{\\mathrm{nt}}$）的布尔标志。稀疏化减少了样本数量，这往往会增加均值估计量的方差。然而，通过降低自相关性，它有可能改善批均值法的性能，特别是当原始批次大小不足以确保批均值近似独立时。最终的比较揭示了在给定参数下，这些相互竞争的因素的净效应。最终的数值结果四舍五入到六位小数，并按规定格式化。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t as t_dist\n\ndef solve():\n    \"\"\"\n    Main function to run the MCMC analysis for all test cases and format the output.\n    \"\"\"\n    test_cases = [\n        # (h, tau_sq, r_sq, y, rho, T, B, b, k, seed)\n        (1.0, 1.0, 1.0, 1.5, 0.5, 50500, 500, 50, 5, 12345),\n        (2.0, 1.0, 4.0, -1.0, 0.0, 50500, 500, 50, 10, 23456),\n        (1.0, 4.0, 1.0, 0.0, 0.99, 200500, 500, 50, 100, 34567),\n    ]\n\n    # Global parameters\n    delta = 10.0\n    alpha = 0.05\n    \n    results = []\n    for case in test_cases:\n        result_tuple = process_case(case, delta, alpha)\n        results.append(result_tuple)\n\n    # Format the final output string as per requirements\n    case_strings = []\n    for v_nt, v_th, w_nt, w_th, is_wider in results:\n        # Format floats to 6 decimal places and boolean to lowercase string\n        s = f\"[{v_nt:.6f},{v_th:.6f},{w_nt:.6f},{w_th:.6f},{str(is_wider).lower()}]\"\n        case_strings.append(s)\n    \n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\ndef process_case(case, delta, alpha):\n    \"\"\"\n    Processes a single test case for MCMC simulation and analysis.\n    \"\"\"\n    h, tau_sq, r_sq, y, rho, T, B, b, k, seed = case\n    \n    # Step a: Compute posterior mean m and variance s^2\n    s_sq = 1.0 / (1.0/tau_sq + h**2 / r_sq)\n    m = s_sq * h * y / r_sq\n\n    # Step b: Simulate the AR(1) chain\n    rng = np.random.default_rng(seed)\n    X = np.zeros(T)\n    X[0] = m + delta  # Initialize with offset\n    \n    noise_std = np.sqrt((1 - rho**2) * s_sq)\n    \n    for t in range(T - 1):\n        Z_t = rng.standard_normal()\n        X[t+1] = m + rho * (X[t] - m) + noise_std * Z_t\n        \n    # Apply burn-in\n    Y_retained = X[B:]\n    n = T - B\n\n    # --- Analysis for non-thinned chain ---\n    if n % b != 0:\n        # As per problem statement, parameters are chosen to make this exact.\n        # This block is for robustness, but won't be entered for the given cases.\n        n_used_nt = (n // b) * b\n        Y_nt = Y_retained[:n_used_nt]\n    else:\n        Y_nt = Y_retained\n    \n    n_nt = len(Y_nt)\n    a_nt = n_nt // b\n    \n    batch_means_nt = np.mean(Y_nt.reshape(b, a_nt), axis=1)\n    \n    # Batch means variance estimation\n    sigma_sq_bm_hat_nt = a_nt * np.var(batch_means_nt, ddof=1)\n    var_mean_hat_nt = sigma_sq_bm_hat_nt / n_nt\n    \n    # Confidence interval calculation\n    t_quantile = t_dist.ppf(1 - alpha / 2, df=b-1)\n    width_nt = 2 * t_quantile * np.sqrt(var_mean_hat_nt)\n\n    # --- Analysis for thinned chain ---\n    Y_th = Y_retained[::k]\n    n_th = len(Y_th)\n    \n    if n_th % b != 0:\n        # As per problem statement, parameters are chosen to make this exact.\n        n_used_th = (n_th // b) * b\n        Y_th = Y_th[:n_used_th]\n\n    n_th = len(Y_th) # update length after potential truncation\n    a_th = n_th // b\n    \n    batch_means_th = np.mean(Y_th.reshape(b, a_th), axis=1)\n    \n    # Batch means variance estimation\n    sigma_sq_bm_hat_th = a_th * np.var(batch_means_th, ddof=1)\n    var_mean_hat_th = sigma_sq_bm_hat_th / n_th\n    \n    # Confidence interval calculation (t_quantile is the same)\n    width_th = 2 * t_quantile * np.sqrt(var_mean_hat_th)\n    \n    # Step e: Consolidate and return results\n    is_wider = width_th > width_nt\n    \n    return (var_mean_hat_nt, var_mean_hat_th, width_nt, width_th, is_wider)\n\nsolve()\n```", "id": "3370133"}, {"introduction": "在实践探索了稀疏化的基础上，本练习从更深入的分析角度审视其统计效率。您将为两种不同的策略推导并比较其“有效样本量”（Effective Sample Size, ESS）：传统的规则稀疏化与一种更复杂的随机稀疏化方法。这项理论分析[@problem_id:3370165]提供了一个严谨的框架，用以理解不同的稀疏化方案如何影响从相关的MCMC链中提取的独立信息量。", "problem": "考虑一个数据同化中的贝叶斯逆问题，其中使用马尔可夫链蒙特卡洛 (MCMC) 算法，在丢弃最初的 $B$ 次预烧期迭代后，从一个平稳后验分布中生成一个时间序列 $\\{X_t\\}_{t=1}^T$。目标是估计标量可观测量 $f(X)$ 的后验期望，并评估对保留的链采用的两种稀疏化策略的统计效率：每 $m$ 步进行一次的规则稀疏化，以及具有独立几何间距（其均值为 $m$）的随机稀疏化。\n\n从一个基本恒等式出发：对于任何零均值、自协方差函数为 $\\gamma_k = \\mathrm{Cov}(X_t, X_{t+k})$、自相关函数为 $\\rho_k = \\gamma_k/\\gamma_0$ 的平稳序列，$K$ 个连续观测值的样本均值的方差为\n$$\n\\mathrm{Var}\\!\\left(\\frac{1}{K}\\sum_{i=1}^K X_i\\right) = \\frac{1}{K^2}\\sum_{i=1}^K\\sum_{j=1}^K \\gamma_{|i-j|},\n$$\n推导稀疏化后样本均值的渐近方差表达式，并根据积分自相关时间定义有效样本量 (ESS)。积分自相关时间 (IACT) 定义为\n$$\n\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{h=1}^{\\infty} r_h,\n$$\n其中 $r_h$ 是在给定稀疏化策略下，保留样本序列在滞后 $h$ 时的自相关。对于每 $m$ 步进行一次的规则稀疏化，$r_h = \\rho_{hm}$；对于具有独立几何间距的随机稀疏化，$r_h = \\mathbb{E}\\left[\\rho_{S_h}\\right]$，其中 $S_h$ 是 $h$ 个独立的几何随机变量之和，这些随机变量的成功概率为 $p = 1/m$，定义域在 $\\{1,2,\\ldots\\}$ 上。\n\n您必须假设在预烧期后，链是严平稳且遍历的，可观测量 $f(X)$ 的方差为单位方差 $\\sigma^2 = 1$，并且自相关函数为一阶自回归形式 $\\rho_k = \\alpha^k$ (其中 $|\\alpha|1$) 或指数衰减形式 $\\rho_k = \\exp(-k/\\lambda)$ (其中 $\\lambda0$)。设总迭代次数为 $T$，预烧期为 $B$，并令 $L = T - B$ 表示预烧期后的样本预算。在规则稀疏化下，精确保留 $\\lfloor L/m \\rfloor$ 个样本；在随机稀疏化下，使用保留样本的期望数量 $L/m$。\n\n将有效样本量 (ESS) 定义为 $ESS = K/\\tau_{\\mathrm{int}}$，其中 $K$ 是该策略下保留的样本数量。将样本均值估计量的渐近方差定义为 $V = \\sigma^2 \\tau_{\\mathrm{int}}/K$，表示为一个无量纲浮点数。\n\n您的任务是编写一个程序，对下面测试套件中的每个测试用例，计算：\n- 规则稀疏化和随机稀疏化各自的 $ESS_{\\mathrm{reg}}$ 和 $ESS_{\\mathrm{rand}}$。\n- 规则稀疏化和随机稀疏化各自的 $V_{\\mathrm{reg}}$ 和 $V_{\\mathrm{rand}}$。\n- 比率 $ESS_{\\mathrm{rand}}/ESS_{\\mathrm{reg}}$。\n- 比率 $V_{\\mathrm{rand}}/V_{\\mathrm{reg}}$。\n\n在存在闭式表达式的情况下，通过利用 $\\rho_k$ 的结构和几何间距分布来使用它们；否则，使用收敛级数，并在绝对项小于数值容差时进行截断。\n\n测试套件：\n每个测试用例都是一个元组，用于指定 $(\\text{模型}, \\text{参数}, T, B, m)$，其中 $\\text{模型}$ 为带有参数 $\\alpha$ 的 $\\text{'ar1'}$ 或带有参数 $\\lambda$ 的 $\\text{'exp'}$。\n\n- 测试用例 1: $\\text{模型}=\\text{'ar1'}$, $\\alpha=0.9$, $T=100000$, $B=1000$, $m=5$。\n- 测试用例 2: $\\text{模型}=\\text{'ar1'}$, $\\alpha=0.99$, $T=150000$, $B=5000$, $m=10$。\n- 测试用例 3: $\\text{模型}=\\text{'exp'}$, $\\lambda=5.0$, $T=50000$, $B=0$, $m=5$。\n- 测试用例 4: $\\text{模型}=\\text{'exp'}$, $\\lambda=1.0$, $T=1000$, $B=100$, $m=2$。\n- 测试用例 5: $\\text{模型}=\\text{'ar1'}$, $\\alpha=0.2$, $T=10000$, $B=1000$, $m=1$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。第 $i$ 个元素必须是对应于第 $i$ 个测试用例的列表，其中包含按以下顺序排列的六个浮点数：$[ESS_{\\mathrm{reg}}, ESS_{\\mathrm{rand}}, V_{\\mathrm{reg}}, V_{\\mathrm{rand}}, ESS_{\\mathrm{rand}}/ESS_{\\mathrm{reg}}, V_{\\mathrm{rand}}/V_{\\mathrm{reg}}]$。所有浮点数都必须以标准十进制表示法打印。", "solution": "用户提供的问题已经过分析，并被认为是有效的。它在科学上基于马尔可夫链蒙特卡洛 (MCMC) 方法的统计理论，具有一套完整且一致的定义和参数，问题是适定的，并以客观、正式的语言表达。因此，我们可以着手提供完整的解答。\n\n该问题要求计算应用于平稳 MCMC 链的两种不同稀疏化策略的有效样本量 ($ESS$) 和样本均值的渐近方差 ($V$)。核心量定义如下：\n预烧期后的链长度：$L = T - B$\n保留的样本数量：$K$\n积分自相关时间 (IACT)：$\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{h=1}^{\\infty} r_h$，其中 $r_h$ 是稀疏化链在滞后 $h$ 时的自相关。\n有效样本量：$ESS = K / \\tau_{\\mathrm{int}}$\n渐近方差：$V = \\sigma^2 \\tau_{\\mathrm{int}} / K$\n\n鉴于可观测量方差为 1 ($\\sigma^2 = 1$) 的假设，渐近方差简化为 $V = \\tau_{\\mathrm{int}} / K = 1 / ESS$。\n\n该问题为原始 (未稀疏化) 链的自相关函数 (ACF) 指定了两种模型：\n1.  一阶自回归 (AR($1$))：$\\rho_k = \\alpha^k$，其中 $|\\alpha|1$。\n2.  指数衰减：$\\rho_k = \\exp(-k/\\lambda)$，其中 $\\lambda0$。\n\n注意，指数衰减模型是 AR($1$) 模型的一个特例。如果我们设 $\\beta = \\exp(-1/\\lambda)$，那么 $\\rho_k = \\exp(-k/\\lambda) = (\\exp(-1/\\lambda))^k = \\beta^k$。由于 $\\lambda0$，我们有 $0  \\beta  1$。因此，我们可以对形式为 $\\rho_k = \\beta^k$ (其中 $|\\beta|1$) 的通用 ACF 进行推导，并根据需要代入 $\\beta=\\alpha$ 或 $\\beta=\\exp(-1/\\lambda)$。\n\n**1. 规则稀疏化**\n\n在规则稀疏化下，我们每 $m$ 步保留一个样本。设稀疏化后的序列为 $\\{Y_h\\}$。$Y_j$ 和 $Y_{j+h}$ 之间的自相关 $r_h$ 对应于原始样本 $X_t$ 和 $X_{t+hm}$ 之间的自相关。因此，稀疏化链的 ACF 为 $r_h = \\rho_{hm}$。对于我们的通用模型 $\\rho_k = \\beta^k$，这变为 $r_h = \\beta^{hm} = (\\beta^m)^h$。\n\n规则稀疏化链的 IACT，$\\tau_{\\mathrm{int, reg}}$，可以通过对几何级数求和来计算：\n$$\n\\tau_{\\mathrm{int, reg}} = 1 + 2 \\sum_{h=1}^{\\infty} r_h = 1 + 2 \\sum_{h=1}^{\\infty} (\\beta^m)^h\n$$\n几何级数的和为 $\\sum_{h=1}^{\\infty} x^h = x/(1-x)$，其中 $|x|1$。这里，$x=\\beta^m$，并且由于 $|\\beta|1$ 和 $m \\ge 1$，我们有 $|\\beta^m|1$。\n$$\n\\tau_{\\mathrm{int, reg}} = 1 + 2 \\frac{\\beta^m}{1 - \\beta^m} = \\frac{1 - \\beta^m + 2\\beta^m}{1 - \\beta^m} = \\frac{1 + \\beta^m}{1 - \\beta^m}\n$$\n保留的样本数量为 $K_{\\mathrm{reg}} = \\lfloor L/m \\rfloor = \\lfloor (T-B)/m \\rfloor$。\n有效样本量为：\n$$\nESS_{\\mathrm{reg}} = \\frac{K_{\\mathrm{reg}}}{\\tau_{\\mathrm{int, reg}}} = \\left\\lfloor \\frac{T-B}{m} \\right\\rfloor \\left(\\frac{1 - \\beta^m}{1 + \\beta^m}\\right)\n$$\n渐近方差为 $V_{\\mathrm{reg}} = 1/ESS_{\\mathrm{reg}}$。\n\n**2. 随机稀疏化**\n\n在随机稀疏化下，连续保留样本之间的间距 $\\Delta_i$ 是独立同分布的几何随机变量，其成功概率为 $p=1/m$，定义域在整数 $\\{1, 2, 3, \\ldots\\}$ 上。其概率质量函数 (PMF) 为 $P(\\Delta=k) = (1-p)^{k-1}p$。\n\n稀疏化链中样本 $Y_j$ 和 $Y_{j+h}$ 之间的总滞后是 $S_h = \\sum_{i=1}^h \\Delta_i$。这 $h$ 个独立同分布的几何随机变量之和服从负二项分布。稀疏化链的 ACF 由 $r_h = \\mathbb{E}[\\rho_{S_h}]$ 给出。对于我们的通用 ACF $\\rho_k = \\beta^k$，这变为：\n$$\nr_h = \\mathbb{E}[\\beta^{S_h}]\n$$\n这个表达式是随机变量 $S_h$ 的概率生成函数 (PGF) 在 $\\beta$ 处求值的定义。设 $G_{S_h}(z) = \\mathbb{E}[z^{S_h}]$。那么 $r_h = G_{S_h}(\\beta)$。\n\n由于 $\\Delta_i$ 是独立同分布的，它们的和 $S_h$ 的 PGF 是它们各自 PGF 的乘积：$G_{S_h}(z) = (G_{\\Delta}(z))^h$，其中 $G_{\\Delta}(z)$ 是单个间距 $\\Delta$ 的 PGF。\n对于定义域在 $\\{1, 2, \\ldots\\}$ 上的几何分布，其 PGF 为：\n$$\nG_{\\Delta}(z) = \\sum_{k=1}^{\\infty} z^k (1-p)^{k-1}p = pz \\sum_{k=1}^{\\infty} (z(1-p))^{k-1} = \\frac{pz}{1-z(1-p)}\n$$\n所以，$r_h = \\left( \\frac{p\\beta}{1-\\beta(1-p)} \\right)^h$。这表明随机稀疏化链的 ACF 也是几何的。设 $C = \\frac{p\\beta}{1-\\beta(1-p)}$。那么 $r_h = C^h$。随机稀疏化链的 IACT 是：\n$$\n\\tau_{\\mathrm{int, rand}} = 1 + 2 \\sum_{h=1}^{\\infty} C^h = \\frac{1+C}{1-C}\n$$\n代入 $p=1/m$ 并简化 $C$ 的表达式：\n$$\nC = \\frac{\\beta/m}{1-\\beta(1-1/m)} = \\frac{\\beta/m}{1-\\beta+\\beta/m} = \\frac{\\beta}{m(1-\\beta)+\\beta}\n$$\n现在，我们将其代入 $\\tau_{\\mathrm{int, rand}}$ 的表达式中：\n$$\n\\tau_{\\mathrm{int, rand}} = \\frac{1 + \\frac{\\beta}{m(1-\\beta)+\\beta}}{1 - \\frac{\\beta}{m(1-\\beta)+\\beta}} = \\frac{m(1-\\beta)+\\beta+\\beta}{m(1-\\beta)+\\beta-\\beta} = \\frac{m(1-\\beta)+2\\beta}{m(1-\\beta)} = 1 + \\frac{2\\beta}{m(1-\\beta)}\n$$\n这是一个非常简洁的闭式表达式。保留的样本数量取其期望值，$K_{\\mathrm{rand}} = \\mathbb{E}[\\lfloor L/\\bar{\\Delta} \\rfloor] \\approx L/\\mathbb{E}[\\Delta] = L/m = (T-B)/m$。\n有效样本量为：\n$$\nESS_{\\mathrm{rand}} = \\frac{K_{\\mathrm{rand}}}{\\tau_{\\mathrm{int, rand}}} = \\frac{(T-B)/m}{1 + \\frac{2\\beta}{m(1-\\beta)}} = \\frac{T-B}{m} \\frac{m(1-\\beta)}{m(1-\\beta)+2\\beta}\n$$\n渐近方差为 $V_{\\mathrm{rand}} = 1/ESS_{\\mathrm{rand}}$。\n\n**实现用公式总结**\n对于每个测试用例 $(\\text{模型}, \\text{参数}, T, B, m)$：\n1.  计算 $L = T - B$。\n2.  设置 $\\beta$：如果 $\\text{model}=\\text{'ar1'}$，则 $\\beta=\\alpha$；如果 $\\text{model}=\\text{'exp'}$，则 $\\beta=\\exp(-1/\\lambda)$。\n3.  **规则稀疏化：**\n    -   $K_{\\mathrm{reg}} = \\lfloor L/m \\rfloor$\n    -   $\\tau_{\\mathrm{int, reg}} = (1 + \\beta^m) / (1 - \\beta^m)$\n    -   $ESS_{\\mathrm{reg}} = K_{\\mathrm{reg}} / \\tau_{\\mathrm{int, reg}}$\n    -   $V_{\\mathrm{reg}} = 1 / ESS_{\\mathrm{reg}}$\n4.  **随机稀疏化：**\n    -   $K_{\\mathrm{rand}} = L/m$\n    -   $\\tau_{\\mathrm{int, rand}} = 1 + 2\\beta / (m(1-\\beta))$\n    -   $ESS_{\\mathrm{rand}} = K_{\\mathrm{rand}} / \\tau_{\\mathrm{int, rand}}$\n    -   $V_{\\mathrm{rand}} = 1 / ESS_{\\mathrm{rand}}$\n5.  计算比率 $ESS_{\\mathrm{rand}}/ESS_{\\mathrm{reg}}$ 和 $V_{\\mathrm{rand}}/V_{\\mathrm{reg}}$。\n\n这些公式在提供的 Python 代码中实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Computes ESS and variance for MCMC thinning strategies based on derived closed-form expressions.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (model, params, T, B, m)\n        ('ar1', 0.9, 100000, 1000, 5),\n        ('ar1', 0.99, 150000, 5000, 10),\n        ('exp', 5.0, 50000, 0, 5),\n        ('exp', 1.0, 1000, 100, 2),\n        ('ar1', 0.2, 10000, 1000, 1),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        model, params, T, B, m = case\n        \n        # Post-burn-in chain length\n        L = T - B\n        \n        # Determine the generic autocorrelation parameter beta\n        if model == 'ar1':\n            beta = params  # alpha\n        elif model == 'exp':\n            beta = np.exp(-1.0 / params)  # lambda\n        else:\n            raise ValueError(\"Unknown model type\")\n\n        # --- Regular Thinning ---\n        K_reg = np.floor(L / m)\n        \n        # Handle the case where beta^m might be 1 (though not with given inputs)\n        # to avoid division by zero.\n        beta_m = beta**m\n        if np.isclose(beta_m, 1.0):\n            # For beta almost 1, tau ~ 2/(1-beta_m), which is huge\n            # ESS would be very small. This case implies very high correlation.\n            # In the limit beta -> 1, tau -> infinity, ESS -> 0\n            tau_int_reg = float('inf')\n        else:\n            tau_int_reg = (1 + beta_m) / (1 - beta_m)\n            \n        ESS_reg = K_reg / tau_int_reg if tau_int_reg > 0 else 0.0\n        V_reg = 1.0 / ESS_reg if ESS_reg > 0 else float('inf')\n        \n        # --- Randomized Thinning ---\n        K_rand = L / m\n        \n        # Handle the case where beta might be 1\n        if np.isclose(beta, 1.0):\n            tau_int_rand = float('inf')\n        else:\n            tau_int_rand = 1 + (2 * beta) / (m * (1 - beta))\n            \n        ESS_rand = K_rand / tau_int_rand if tau_int_rand > 0 else 0.0\n        V_rand = 1.0 / ESS_rand if ESS_rand > 0 else float('inf')\n        \n        # --- Ratios ---\n        if ESS_reg == 0:\n             ratio_ess = float('inf') if ESS_rand > 0 else 1.0 # Or NaN, but inf is more informative\n        else:\n             ratio_ess = ESS_rand / ESS_reg\n\n        if V_reg == 0:\n            ratio_v = float('inf') if V_rand > 0 else 1.0\n        else:\n            ratio_v = V_rand / V_reg\n            \n        # sanity check for m=1 case where methods are identical\n        if m == 1:\n            # Due to K_reg = floor(L/m) vs K_rand = L/m, a tiny difference might arise if L is not integer.\n            # Here L, m are integers, so K_reg == K_rand.\n            # Thus all quantities should be identical.\n            ESS_rand = ESS_reg\n            V_rand = V_reg\n            ratio_ess = 1.0\n            ratio_v = 1.0\n            \n        result_list = [ESS_reg, ESS_rand, V_reg, V_rand, ratio_ess, ratio_v]\n        all_results.append(result_list)\n\n    # Format the final output string as a list of lists.\n    # e.g., [[val1,val2,...],[val1,val2,...]]\n    output_parts = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_output_str = f\"[{','.join(output_parts)}]\"\n\n    # Final print statement in the exact required format.\n    print(final_output_str)\n\nsolve()\n```", "id": "3370165"}]}