{"hands_on_practices": [{"introduction": "迭代方法的经典停止准则之一是差异原则（discrepancy principle）。该原则指出，当数据残差的范数降低到与数据中的噪声水平相当时，应停止迭代，以避免对噪声进行过拟合。此练习 [@problem_id:3423231] 提供了一个基于卡方检验（$\\chi^2$检验）的差异原则的动手实现。通过该练习，您将探索当噪声模型被错误指定时（即估计的噪声协方差 $\\Gamma_{\\text{est}}$ 与真实协方差 $\\Gamma$ 不符），停止点会如何受到影响，这对于理解统计假设在算法性能中的关键作用至关重要。", "problem": "考虑数据同化中的线性观测模型，其中测量向量 $y \\in \\mathbb{R}^m$ 由 $y = A x^\\star + \\varepsilon$ 给出。矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 是一个已知的前向算子，$x^\\star \\in \\mathbb{R}^n$ 是未知状态，$\\varepsilon \\in \\mathbb{R}^m$ 是加性噪声，建模为零均值多元高斯分布，其协方差为 $\\Gamma \\in \\mathbb{R}^{m \\times m}$，即 $\\varepsilon \\sim \\mathcal{N}(0, \\Gamma)$。在第 $k$ 次迭代时的加权残差为 $r_k = y - A x_k$。使用估计的协方差 $\\Gamma_{\\text{est}}$ 定义加权残差统计量为 $S_k(\\Gamma_{\\text{est}}) = r_k^\\top \\Gamma_{\\text{est}}^{-1} r_k$。\n\n在假设 $x_k$ 已充分解释数据且 $\\Gamma_{\\text{est}} = \\Gamma$ 的情况下，统计量 $S_k(\\Gamma_{\\text{est}})$ 近似服从自由度为 $m$ 的卡方随机变量分布。一种常见的基于偏差的停止准则是，在 $S_k(\\Gamma_{\\text{est}})$ 首次降至自由度为 $m$、概率为 $0.95$ 的卡方分布上分位数以下时，终止迭代。目标是计算此事件首次发生的迭代索引，并论证使用 $\\Gamma_{\\text{est}}$ 而非 $\\Gamma$ 所引入的第一类和第二类错误的权衡。\n\n使用以下设置使计算具体且可复现：\n\n- 设 $m = 500$ 且 $n = 50$。\n- 生成矩阵 $A$，其元素独立地从标准正态分布中抽取，然后将每列归一化为单位欧几里得范数。\n- 生成真实协方差 $\\Gamma$，它是一个对角矩阵，其元素为 $\\Gamma_{ii} = 0.5 + 1.5 u_i$，其中 $u_i$ 是从 $[0,1]$ 上的均匀分布中独立抽取的。\n- 生成真实状态 $x^\\star$，其元素独立地从标准正态分布中抽取。\n- 生成噪声向量 $\\varepsilon$，其为独立的高斯分量，方差等于 $\\Gamma$ 的相应对角线元素。\n- 构建 $y = A x^\\star + \\varepsilon$。\n- 初始化 $x_0 = 0$，并使用协方差加权的 Landweber 迭代进行迭代\n  $$x_{k+1} = x_k + \\alpha A^\\top \\Gamma_{\\text{est}}^{-1} r_k,$$\n  其中 $r_k = y - A x_k$，步长 $\\alpha$ 选择为\n  $$\\alpha = \\frac{0.95}{\\lambda_{\\max}\\!\\left(A^\\top \\Gamma_{\\text{est}}^{-1} A\\right)},$$\n  其中 $\\lambda_{\\max}(\\cdot)$ 表示最大特征值。此选择确保了对于具有利普希茨连续梯度的凸二次目标函数的收敛性。\n\n- 使用自由度为 $m$、概率为 $0.95$ 的卡方上分位数，记为 $q_{0.95}(m)$，作为停止阈值：\n  $$q_{0.95}(m) = \\inf\\{q \\in \\mathbb{R} : \\mathbb{P}(\\chi^2_m \\le q) \\ge 0.95\\}.$$\n\n- 迭代方法应最多运行 $K_{\\max} = 200$ 次迭代。最早的迭代索引是满足 $S_k(\\Gamma_{\\text{est}}) \\le q_{0.95}(m)$ 的最小 $k \\in \\{0,1,2,\\dots,K_{\\max}\\}$。如果在 $K_{\\max}$ 之前不存在这样的 $k$，则报告 $-1$。\n\n为了评估停止准则的不同方面，使用一个测试套件，通过一个标量误设因子 $s$ 来改变估计的协方差，定义 $\\Gamma_{\\text{est}} = s \\Gamma$：\n\n- 测试用例 1：$s = 1.0$ (正确指定的协方差，一般情况)。\n- 测试用例 2：$s = 2.0$ (过度离散的估计协方差，更容易停止；保守停止的边界)。\n- 测试用例 3：$s = 0.5$ (欠离散的估计协方差；难以停止)。\n- 测试用例 4：$s = 0.25$ (严重欠离散的估计协方差；可能在 $K_{\\max}$ 内永远不会停止的极端情况)。\n\n所有伪随机抽样必须使用等于 $314159$ 的固定种子生成，以确保可复现性。此问题不涉及物理单位。输入或输出中不出现角度和百分比。\n\n您的程序应为每个测试用例计算满足 $S_k(\\Gamma_{\\text{est}}) \\le q_{0.95}(m)$ 的最早迭代索引 $k$，如果到 $K_{\\max}$ 仍未达到，则返回 $-1$。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[k_1,k_2,k_3,k_4]$）。", "solution": "问题陈述经过验证。\n\n### 步骤 1：提取给定条件\n- **模型**：线性观测模型 $y = A x^\\star + \\varepsilon$。\n- **维度**：$m = 500$ (测量空间)，$n = 50$ (状态空间)。\n- **正向算子**：$A \\in \\mathbb{R}^{500 \\times 50}$，其元素从 $\\mathcal{N}(0, 1)$ 生成，并且列被归一化为单位欧几里得范数。\n- **真实状态**：$x^\\star \\in \\mathbb{R}^{50}$，其元素来自 $\\mathcal{N}(0, 1)$。\n- **噪声模型**：$\\varepsilon \\in \\mathbb{R}^{500}$，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\Gamma)$。\n- **真实噪声协方差**：$\\Gamma \\in \\mathbb{R}^{500 \\times 500}$ 是对角矩阵，其中 $\\Gamma_{ii} = 0.5 + 1.5 u_i$，且 $u_i \\sim U[0, 1]$。\n- **数据向量**：$y = A x^\\star + \\varepsilon$。\n- **迭代**：协方差加权的 Landweber 迭代：\n  $$x_{k+1} = x_k + \\alpha A^\\top \\Gamma_{\\text{est}}^{-1} r_k$$\n- **初始状态**：$x_0 = 0$。\n- **残差**：$r_k = y - A x_k$。\n- **估计协方差**：$\\Gamma_{\\text{est}} = s \\Gamma$，其中 $s$ 是一个标量误设因子。\n- **步长**：$\\alpha = \\frac{0.95}{\\lambda_{\\max}(A^\\top \\Gamma_{\\text{est}}^{-1} A)}$。\n- **停止统计量**：$S_k(\\Gamma_{\\text{est}}) = r_k^\\top \\Gamma_{\\text{est}}^{-1} r_k$。\n- **停止准则**：在满足 $S_k(\\Gamma_{\\text{est}}) \\le q_{0.95}(m)$ 的最小 $k \\in \\{0, 1, \\dots, K_{\\max}\\}$ 处终止。\n- **停止阈值**：$q_{0.95}(m)$ 是 $\\chi^2_m$ 分布在概率 $0.95$ 处的上分位数。\n- **最大迭代次数**：$K_{\\max} = 200$。\n- **失败时的返回值**：如果在 $K_{\\max}$ 之前未满足条件，则返回 $-1$。\n- **随机种子**：$314159$。\n- **测试用例**：\n    - 用例 1：$s = 1.0$\n    - 用例 2：$s = 2.0$\n    - 用例 3：$s = 0.5$\n    - 用例 4：$s = 0.25$\n- **输出格式**：一个逗号分隔的最早迭代索引列表 $[k_1, k_2, k_3, k_4]$。\n\n### 步骤 2：使用提取的给定条件进行验证\n1.  **科学性或事实性**：该问题在科学和数学上是合理的。它采用了标准的线性逆问题公式、一种众所周知的迭代求解器（Landweber 迭代，一种梯度下降形式）以及一种广泛使用的统计停止准则（基于卡方检验的偏差原则）。步长的选择在理论上是为了确保收敛。\n2.  **不可形式化或不相关**：该问题可直接形式化，并且是逆问题和数据同化中迭代方法停止准则这一主题的核心。\n3.  **设置不完整或矛盾**：问题已完全指定。所有参数、常数和数据生成过程都已定义。没有矛盾之处。\n4.  **不切实际或不可行**：该设置是测试数值方法的常见且现实的模拟。指定的矩阵和向量生成在计算上是可行的。\n5.  **不适定或结构不良**：该问题是适定的。使用固定的随机种子确保了单一、确定性且可复现的解。最大迭代次数防止了无限执行。\n6.  **伪深刻、琐碎或同义反复**：该问题并非琐碎。它需要实现一个数值算法，并理解迭代求解器、统计误差模型和停止准则之间的相互作用。协方差误设的分析是该领域的核心概念。\n7.  **超出科学可验证范围**：该问题完全可以通过数学计算进行验证。\n\n### 步骤 3：结论与行动\n该问题被认为是**有效的**。将提供一个解决方案。\n\n### 基于原则的设计\n该问题要求实现一个迭代算法来解决一个线性逆问题，其停止准则基于残差的统计特性。我们将首先按照规定生成合成数据，然后为每个测试用例实现迭代求解器，最后收集结果来解决这个问题。\n\n**1. 数据生成**\n首先，我们使用指定的种子建立一个可复现的伪随机环境。我们只生成一次问题数据，因为所有测试用例都共用这些数据。\n- 正向算子 $A \\in \\mathbb{R}^{500 \\times 50}$ 的元素从标准正态分布中生成。然后其列被归一化。归一化列至关重要，因为它标准化了状态向量 $x$ 的每个分量对测量值 $y$ 的影响。\n- 真实状态向量 $x^\\star \\in \\mathbb{R}^{50}$ 从标准正态分布中抽取。\n- 真实噪声协方差矩阵 $\\Gamma \\in \\mathbb{R}^{500 \\times 500}$ 是对角矩阵。其对角线元素 $\\Gamma_{ii}$ 从一个缩放的均匀分布中抽取，这确保了测量之间的噪声方差是异构的，这是一个现实的场景。\n- 噪声向量 $\\varepsilon \\in \\mathbb{R}^{500}$ 从多元正态分布 $\\mathcal{N}(0, \\Gamma)$ 生成。由于 $\\Gamma$ 是对角矩阵，这等同于独立地从 $\\mathcal{N}(0, \\Gamma_{ii})$ 生成每个分量 $\\varepsilon_i$。\n- 然后合成测量向量为 $y = Ax^\\star + \\varepsilon$。\n\n**2. 迭代解法与停止准则**\n该问题使用协方差加权的 Landweber 迭代。此方法是用于最小化加权最小二乘泛函 $J(x) = \\frac{1}{2} (y - Ax)^\\top \\Gamma_{\\text{est}}^{-1} (y - Ax)$ 的梯度下降算法。此泛函的梯度为 $\\nabla_x J(x) = -A^\\top \\Gamma_{\\text{est}}^{-1} (y - Ax)$。梯度下降更新为 $x_{k+1} = x_k - \\alpha \\nabla_x J(x_k)$，这给出了指定的迭代公式：\n$$ x_{k+1} = x_k + \\alpha A^\\top \\Gamma_{\\text{est}}^{-1} r_k $$\n其中 $r_k = y - A x_k$ 是第 $k$ 次迭代的残差。\n\n步长 $\\alpha$ 的选择是为了保证收敛。梯度 $\\nabla_x J(x)$ 是利普希茨连续的，其常数为 $L = \\lambda_{\\max}(A^\\top \\Gamma_{\\text{est}}^{-1} A)$。为保证收敛，步长必须满足 $0  \\alpha  2/L$。选择 $\\alpha = 0.95/L$ 属于这个范围，并提供了一个稳健的下降率。\n\n停止准则是偏差原则的一种实现。统计量 $S_k(\\Gamma_{\\text{est}}) = r_k^\\top \\Gamma_{\\text{est}}^{-1} r_k$ 测量了残差的马氏距离的平方。在理想假设下，即迭代 $x_k$ 已收敛到一个能够完美解释数据（除了噪声）的解（即 $r_k \\approx \\varepsilon$），并且估计的协方差是正确的（即 $\\Gamma_{\\text{est}} = \\Gamma$），量 $r_k^\\top \\Gamma^{-1} r_k$ 将近似于 $\\varepsilon^\\top \\Gamma^{-1} \\varepsilon$。后一个量服从自由度为 $m$ 的卡方分布，即 $\\chi^2_m$。停止规则 $S_k(\\Gamma_{\\text{est}}) \\le q_{0.95}(m)$ 测试加权残差范数在给定噪声模型下是否统计上是合理的。当残差小到在统计上与假定的噪声无法区分时，我们停止迭代。使用 $95\\%$ 的分位数是为了提供一个高置信度的界限。\n\n**3. 协方差误设 ($s$) 分析**\n测试用例探讨了误设噪声协方差幅度的影响。\n- **情况 $s = 1.0$ ($\\Gamma_{\\text{est}} = \\Gamma$)**：这是理想情况，其中用于反演的统计模型与现实相符。停止准则预计会按设计工作，当残差与真实噪声水平一致时停止迭代。\n- **情况 $s = 2.0$ ($\\Gamma_{\\text{est}} = 2\\Gamma$)**：这里，我们高估了噪声方差。这使得逆协方差 $\\Gamma_{\\text{est}}^{-1} = \\frac{1}{2}\\Gamma^{-1}$ 变小。停止统计量 $S_k$ 变为 $S_k(2\\Gamma) = r_k^\\top (2\\Gamma)^{-1} r_k = \\frac{1}{2} r_k^\\top \\Gamma^{-1} r_k$。对于给定的残差 $r_k$，该准则变得更容易满足。这会带来第一类错误的风险：在 $x_k$ 尚未充分收敛到接近 $x^\\star$ 之前过早停止，因为算法对大残差过于“容忍”。\n- **情况 $s = 0.5$ ($\\Gamma_{\\text{est}} = 0.5\\Gamma$)**：这里，我们低估了噪声方差。逆协方差 $\\Gamma_{\\text{est}}^{-1} = 2\\Gamma^{-1}$ 变大。统计量变为 $S_k(0.5\\Gamma) = 2 r_k^\\top \\Gamma^{-1} r_k$。现在，该准则更难满足。算法对残差的“容忍度”降低，可能会在找到合理解决方案后继续迭代很长时间，试图拟合数据中的噪声。这会带来第二类错误的风险：未能及时停止，可能导致过拟合。\n- **情况 $s = 0.25$ ($\\Gamma_{\\text{est}} = 0.25\\Gamma$)**：这是对噪声方差的严重低估。统计量 $S_k(0.25\\Gamma) = 4 r_k^\\top \\Gamma^{-1} r_k$ 被显著放大。残差范数很可能永远无法减小到足以满足停止准则的程度，特别是因为真实噪声基底是 $\\mathbb{E}[\\varepsilon^\\top\\Gamma^{-1}\\varepsilon] = m$。停止准则将要求 $4 r_k^\\top \\Gamma^{-1} r_k \\le q_{0.95}(m)$，或者 $r_k^\\top \\Gamma^{-1} r_k \\le q_{0.95}(m)/4$。对于 $m=500$，$q_{0.95}(500) \\approx 545$。这要求残差范数远小于其期望值，这可能是无法达到的。\n\n**4. 计算算法**\n对于测试套件中的每个 $s$ 值：\n1.  设置 $\\Gamma_{\\text{est}} = s \\Gamma$。由于 $\\Gamma$ 是对角矩阵，$\\Gamma_{\\text{est}}$ 也是对角矩阵，其逆矩阵可以轻易计算。\n2.  计算矩阵 $H = A^\\top \\Gamma_{\\text{est}}^{-1} A$。由于该矩阵是对称的，其最大特征值 $\\lambda_{\\max}(H)$ 可以高效计算。\n3.  计算步长 $\\alpha = 0.95 / \\lambda_{\\max}(H)$。\n4.  从 $\\chi^2_m$ 分布确定停止阈值 $q_{0.95}(m)$。\n5.  初始化 $x_k = \\vec{0}$ 并设置一个标志 `found_k = -1`。\n6.  从 $k=0$ 到 $K_{\\max}=200$ 开始迭代。\n7.  在每次迭代 $k$ 时，检查停止条件。如果 $S_k(\\Gamma_{\\text{est}}) \\le q_{0.95}(m)$，则将 $k$ 存储为结果，并中断此测试用例的内循环。\n8.  如果未满足条件，则更新状态 $x_{k+1} = x_k + \\alpha A^\\top \\Gamma_{\\text{est}}^{-1} r_k$。\n9.  循环结束后，将找到的索引（如果未找到则为 $-1$）附加到结果列表中。\n对所有四个 $s$ 值重复此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Solves the data assimilation problem with a chi-square stopping rule\n    for different covariance mis-specification factors.\n    \"\"\"\n    # Define parameters from the problem statement\n    m = 500\n    n = 50\n    K_max = 200\n    seed = 314159\n    \n    # Test cases for covariance mis-specification factor 's'\n    test_cases = [1.0, 2.0, 0.5, 0.25]\n\n    # --- 1. Data Generation (common for all test cases) ---\n    rng = np.random.default_rng(seed)\n    \n    # Generate A and normalize its columns\n    A = rng.normal(size=(m, n))\n    col_norms = np.linalg.norm(A, axis=0)\n    A = A / col_norms\n    \n    # Generate true state x_star\n    x_star = rng.normal(size=n)\n    \n    # Generate true diagonal covariance Gamma\n    u = rng.uniform(size=m)\n    gamma_diag = 0.5 + 1.5 * u\n    \n    # Generate noise epsilon from N(0, Gamma)\n    epsilon = rng.normal(loc=0.0, scale=np.sqrt(gamma_diag))\n    \n    # Form the measurement vector y\n    y = A @ x_star + epsilon\n    \n    # --- 2. Iteration and Stopping Criterion Evaluation ---\n    \n    # Calculate the chi-square stopping threshold\n    # q_{0.95}(m)\n    q_threshold = stats.chi2.ppf(0.95, df=m)\n    \n    results = []\n    \n    for s in test_cases:\n        # Initialize x_k for the current test case\n        x_k = np.zeros(n)\n        \n        # Define estimated covariance and its inverse\n        gamma_est_diag = s * gamma_diag\n        gamma_est_inv_diag = 1.0 / gamma_est_diag\n        \n        # Calculate the step size alpha\n        # H = A^T * Gamma_est^{-1} * A\n        # This is an efficient way to compute for diagonal Gamma_est^{-1}\n        # It's A.T @ (D * A) where D is the diagonal matrix\n        H = (A.T * gamma_est_inv_diag) @ A\n        \n        # The matrix H is symmetric, use eigvalsh for efficiency\n        lambda_max = np.linalg.eigvalsh(H)[-1]\n        alpha = 0.95 / lambda_max\n        \n        found_k = -1\n\n        for k in range(K_max + 1):\n            # Calculate residual r_k\n            r_k = y - A @ x_k\n            \n            # Calculate the stopping statistic S_k\n            # S_k = r_k^T * Gamma_est^{-1} * r_k\n            S_k = np.sum(r_k**2 * gamma_est_inv_diag)\n            \n            # Check the stopping criterion\n            if S_k = q_threshold:\n                found_k = k\n                break\n            \n            # If not stopping, perform the Landweber update\n            # We don't need to update if k == K_max, but it does no harm\n            grad = A.T @ (gamma_est_inv_diag * r_k)\n            x_k = x_k + alpha * grad\n\n        results.append(found_k)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3423231"}, {"introduction": "在处理更复杂的非线性问题时，单一的停止准则往往不够稳健。一个实用的策略是将统计检验与数值收敛指标相结合。此练习 [@problem_id:3423267] 指导您实现一种混合停止规则，它融合了基于卡方检验（$\\chi^2$检验）的残差分析和基于迭代步长 $\\|x_{k+1} - x_k\\|_2$ 大小的收敛性判断。这种双重方法确保了迭代在两种情况下均能有效终止：一是在解已经充分拟合数据时，二是在算法无法取得进一步显著进展时。", "problem": "考虑一个非线性参数估计问题，其中 $m$ 个观测值 $y_i$ 被建模为参数化正演模型 $g(x;t_i)$ 的输出，并受到加性噪声的干扰。假设噪声为均值为 $0$、方差为 $\\sigma^2$ 的独立同分布（IID）高斯噪声，并定义残差向量 $r(x) \\in \\mathbb{R}^m$ 为 $r_i(x) = y_i - g(x;t_i)$，其中 $i \\in \\{1,\\dots,m\\}$。令缩放平方和为 $S(x) = \\|r(x)\\|_2^2 / \\sigma^2$。在所述假设下，在真实参数 $x^\\star$ 处计算的 $S(x^\\star)$ 服从自由度为 $m$ 的卡方分布。在用于反问题和数据同化的迭代方法中，人们寻求一种能在统计一致性与数值稳定性之间取得平衡的、有原则的停止法则。设计一个结合了卡方失配检验和小步长条件的组合停止准则。具体来说，定义一个由高斯-牛顿类型更新生成的迭代序列 $x_k \\in \\mathbb{R}^p$ ($p \\in \\mathbb{N}$)，并在满足卡方失配检验通过或步长足够小的最小索引 $k$ 处停止。失配检验使用自由度为 $m$ 的卡方分布的上 $(1-\\alpha)$-分位数 $q_{m,1-\\alpha}$，小步长条件为 $\\|x_{k+1} - x_k\\|_2 \\le \\varepsilon \\,(1 + \\|x_k\\|_2)$，其中给定 $\\alpha \\in (0,1)$ 和 $\\varepsilon  0$。如果在预设的最大迭代次数 $k_{\\max}$ 内两个条件都未满足，则返回 $k_{\\max}$。\n\n为以下数据同化场景实现此停止法则。使用非线性正演模型 $g(x;t) = x_1 \\exp(-x_2 t)$，其中参数 $x = (x_1,x_2) \\in \\mathbb{R}^2$。在迭代次数 $k$ 时，通过求解线性系统 $(J(x_k)^\\top J(x_k) + \\lambda I) s_k = - J(x_k)^\\top r(x_k)$ 来计算高斯-牛顿步长 $s_k \\in \\mathbb{R}^2$，其中 $J(x_k) \\in \\mathbb{R}^{m \\times 2}$ 是 $g$ 在 $x_k$ 处的雅可比矩阵，$I \\in \\mathbb{R}^{2 \\times 2}$ 是单位矩阵，$\\lambda  0$ 是一个固定的阻尼参数。使用 $x_{k+1} = x_k + s_k$进行更新。在整个过程中必须使用欧几里得范数 $\\|\\cdot\\|_2$。\n\n使用以下三个案例的测试套件计算停止索引，该索引定义为满足 $S(x_k) \\le q_{m,1-\\alpha}$ 或 $\\|x_{k+1} - x_k\\|_2 \\le \\varepsilon \\,(1 + \\|x_k\\|_2)$ 的最小 $k \\in \\{0,1,\\dots,k_{\\max}\\}$；如果在 $k_{\\max}$ 之前两个条件均未满足，则输出 $k_{\\max}$。对于每个案例，通过 $y_i = g(x^\\mathrm{true};t_i) + v_i$ 从真实参数 $x^\\mathrm{true}$ 和指定的噪声向量 $v \\in \\mathbb{R}^m$ 确定性地构建观测数据 $y_i$。\n\n案例 1（统计上一致的噪声，失配检验预计会通过）：\n- $m = 20$， $t_i$ 在 $[0,2]$ 区间内线性分布，其中 $i \\in \\{1,\\dots,20\\}$，\n- $x^\\mathrm{true} = (1.0, 0.5)$，\n- $\\sigma = 0.05$, $v_i = \\sigma \\cdot 0.3 \\cdot (-1)^i$，\n- 初始猜测值 $x_0 = (0.8, 0.8)$，\n- $\\alpha = 0.05$, $\\varepsilon = 10^{-6}$, $k_{\\max} = 50$, $\\lambda = 10^{-4}$。\n\n案例 2（不匹配的噪声尺度，小步长条件预计会触发）：\n- $m = 20$， $t_i$ 在 $[0,2]$ 区间内线性分布，其中 $i \\in \\{1,\\dots,20\\}$，\n- $x^\\mathrm{true} = (1.0, 0.5)$，\n- $\\sigma = 0.02$, $v_i = 0.15 \\cos(2 t_i)$，\n- 初始猜测值 $x_0 = (0.9, 0.3)$，\n- $\\alpha = 0.05$, $\\varepsilon = 10^{-6}$, $k_{\\max} = 100$, $\\lambda = 10^{-3}$。\n\n案例 3（在迭代上限内两个条件均未满足）：\n- $m = 5$, $t_i$ 在 $[0,1]$ 区间内线性分布，其中 $i \\in \\{1,\\dots,5\\}$，\n- $x^\\mathrm{true} = (1.0, 0.5)$，\n- $\\sigma = 0.01$, $v_i = 0.1 + 0.05 t_i$，\n- 初始猜测值 $x_0 = (0.2, 1.5)$，\n- $\\alpha = 0.01$, $\\varepsilon = 10^{-12}$, $k_{\\max} = 3$, $\\lambda = 10^{-3}$。\n\n您的程序必须使用所述的组合规则计算每个案例的停止索引，并生成一行输出，其中包含三个整数索引，以逗号分隔并用方括号括起来，例如 $[k_1,k_2,k_3]$。不涉及物理单位，所有角度（如有）都必须作为不带角度单位的实数处理。最终输出是整数。", "solution": "该问题要求为一个应用于非线性参数估计问题的阻尼高斯-牛顿迭代法实现一个组合停止法则。解决方案涉及基于所提供的数学框架开发算法，并对三个不同的测试案例执行该算法。\n\n首先，我们形式化迭代算法的各个组成部分。正演模型由 $g(x;t) = x_1 \\exp(-x_2 t)$ 给出，其中 $x = (x_1, x_2)$ 是参数向量。雅可比矩阵 $J(x) \\in \\mathbb{R}^{m \\times 2}$ 的元素对应于模型函数关于参数的偏导数，并在每个时间点 $t_i$ 进行求值。雅可比矩阵的列为：\n$$\n\\frac{\\partial g}{\\partial x_1}(x;t) = \\exp(-x_2 t)\n$$\n$$\n\\frac{\\partial g}{\\partial x_2}(x;t) = -x_1 t \\exp(-x_2 t)\n$$\n对于给定的参数估计 $x$，残差向量为 $r(x)$，其分量为 $r_i(x) = y_i - g(x; t_i)$，其中 $y_i$ 是观测数据。数量 $S(x) = \\|r(x)\\|_2^2 / \\sigma^2$ 是缩放的残差平方和，它作为我们的失配函数。\n\n迭代过程从一个初始猜测值 $x_0$ 开始，并为 $k=0, 1, 2, \\dots$ 生成一系列参数估计值 $x_k$。在每次迭代 $k$ 中，通过计算步长 $s_k$ 并设置 $x_{k+1} = x_k + s_k$ 来找到下一个迭代值 $x_{k+1}$。步长 $s_k$ 是通过求解阻尼正规方程组得到的，这是Levenberg-Marquardt算法（高斯-牛顿法的一种改进）的一个特征：\n$$\n(J(x_k)^\\top J(x_k) + \\lambda I) s_k = - J(x_k)^\\top r(x_k)\n$$\n这里，$J(x_k)$ 是在 $x_k$ 处求值的雅可比矩阵，$r(x_k)$ 是在 $x_k$ 处的残差，$I$ 是 $2 \\times 2$ 的单位矩阵，而 $\\lambda  0$ 是一个阻尼参数，它确保系统是良态的并能提高稳定性。\n\n问题的核心是组合停止准则。迭代在满足以下两个条件之一的第一个索引 $k$（从 $k=0$ 开始）处停止：\n1.  **卡方失配检验**：$S(x_k) \\le q_{m,1-\\alpha}$。这是Morozov差异原则的一种形式。当模型的预测误差（失配）与数据中预期的噪声水平在统计上一致时，它会停止迭代。阈值 $q_{m,1-\\alpha}$ 是自由度为 $m$ 的卡方分布的 $(1-\\alpha)$ 分位数，根据问题的假设，这也是真实参数 $x^\\star$ 处的 $S(x^\\star)$ 所服从的分布。\n2.  **小步长条件**：$\\|x_{k+1} - x_k\\|_2 \\le \\varepsilon \\,(1 + \\|x_k\\|_2)$。这个条件表明算法已经收敛到一个稳定点，因为后续的迭代在参数向量上产生的变化可以忽略不计。缩放因子 $(1 + \\|x_k\\|_2)$ 提供了一个相对容差，对参数范数的大小都有效。\n\n对于 $k = 0, 1, \\dots, k_{\\max}-1$，整个算法流程如下：\n1.  给定当前迭代值 $x_k$，计算残差 $r(x_k)$ 和失配 $S(x_k) = \\|r(x_k)\\|_2^2 / \\sigma^2$。\n2.  检查失配检验：如果 $S(x_k) \\le q_{m,1-\\alpha}$，则停止索引为 $k$。终止。\n3.  如果失配检验失败，通过求解上述线性系统来计算高斯-牛顿步长 $s_k$。\n4.  检查小步长条件：如果 $\\|s_k\\|_2 \\le \\varepsilon(1 + \\|x_k\\|_2)$，则停止索引为 $k$。终止。\n5.  如果两个检验都失败，更新参数估计：$x_{k+1} = x_k + s_k$。继续下一次迭代，令 $k \\leftarrow k+1$。\n如果循环在达到 $k=k_{\\max}-1$ 时仍未满足任何一个条件，则过程停止，返回的索引为 $k_{\\max}$。\n\n该算法应用于指定的三个测试案例，使用它们各自的数据和控制参数，以确定每种情况下的停止索引。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    使用组合停止准则为阻尼高斯-牛顿迭代法在三种数据同化场景中求解停止索引。\n    \"\"\"\n\n    def g(x, t):\n        \"\"\"\n        非线性正演模型 g(x;t) = x1 * exp(-x2 * t)。\n\n        Args:\n            x (np.ndarray): 参数向量 [x1, x2]。\n            t (np.ndarray): 时间点。\n\n        Returns:\n            np.ndarray: 模型输出。\n        \"\"\"\n        x1, x2 = x\n        return x1 * np.exp(-x2 * t)\n\n    def jacobian(x, t):\n        \"\"\"\n        计算正演模型 g(x;t) 的雅可比矩阵。\n\n        Args:\n            x (np.ndarray): 参数向量 [x1, x2]。\n            t (np.ndarray): 时间点。\n\n        Returns:\n            np.ndarray: m x 2 的雅可比矩阵。\n        \"\"\"\n        x1, x2 = x\n        m = len(t)\n        J = np.zeros((m, 2))\n        exp_term = np.exp(-x2 * t)\n        J[:, 0] = exp_term\n        J[:, 1] = -x1 * t * exp_term\n        return J\n\n    def run_iteration(params):\n        \"\"\"\n        为单个测试案例执行迭代算法。\n        \"\"\"\n        m, t, x_true, sigma, v, x0, alpha, epsilon, k_max, lam = params\n\n        # Generate observed data y\n        y = g(x_true, t) + v\n\n        # Calculate the chi-square quantile for the misfit test\n        q_chi2 = chi2.ppf(1 - alpha, df=m)\n\n        # Identity matrix for the damped system\n        I = np.identity(2)\n\n        # Initialize the iteration\n        x_k = np.array(x0, dtype=float)\n        \n        for k in range(k_max):\n            # Compute residual and scaled sum of squares (misfit) at x_k\n            r_k = y - g(x_k, t)\n            S_k = np.linalg.norm(r_k)**2 / sigma**2\n\n            # 1. Chi-square Misfit Test\n            if S_k = q_chi2:\n                return k\n\n            # Compute the Jacobian at x_k\n            J_k = jacobian(x_k, t)\n\n            # Formulate and solve the damped linear system for the step s_k\n            # (J^T J + lambda*I) s_k = -J^T r_k\n            A = J_k.T @ J_k + lam * I\n            b = -J_k.T @ r_k\n            s_k = np.linalg.solve(A, b)\n\n            # 2. Small-Step Condition\n            step_norm = np.linalg.norm(s_k)\n            x_k_norm = np.linalg.norm(x_k)\n            threshold = epsilon * (1.0 + x_k_norm)\n            \n            if step_norm = threshold:\n                return k\n\n            # Update the parameter estimate for the next iteration\n            x_k += s_k\n            \n        # If loop completes without stopping, return k_max\n        return k_max\n\n    # Define the test cases from the problem statement.\n    case1_t = np.linspace(0, 2, 20)\n    case1_v = 0.05 * 0.3 * ((-1)**np.arange(1, 21))\n    \n    case2_t = np.linspace(0, 2, 20)\n    case2_v = 0.15 * np.cos(2 * case2_t)\n\n    case3_t = np.linspace(0, 1, 5)\n    case3_v = 0.1 + 0.05 * case3_t\n\n    test_cases = [\n        # Case 1\n        (20, case1_t, np.array([1.0, 0.5]), 0.05, case1_v, \n         np.array([0.8, 0.8]), 0.05, 1e-6, 50, 1e-4),\n        # Case 2\n        (20, case2_t, np.array([1.0, 0.5]), 0.02, case2_v, \n         np.array([0.9, 0.3]), 0.05, 1e-6, 100, 1e-3),\n        # Case 3\n        (5, case3_t, np.array([1.0, 0.5]), 0.01, case3_v,\n         np.array([0.2, 1.5]), 0.01, 1e-12, 3, 1e-3),\n    ]\n\n    results = []\n    for case in test_cases:\n        stop_index = run_iteration(case)\n        results.append(stop_index)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3423267"}, {"introduction": "除了差异原则，另一类先进的停止策略是基于后验参数选择的平衡原则，其中以Lepskii原则最为著名。与依赖精确噪声水平 $\\delta$ 的差异原则不同，这种后验方法通过在不同正则化水平 $j$ 上比较解 $x_j$ 的稳定性来工作，从而在逼近误差和噪声传播之间找到一个平衡点。此练习 [@problem_id:3423230] 旨在实现这一高级准则，您将为一系列Tikhonov正则化解确定最佳的停止点 $k$，从而深入了解这类能自适应于真实解未知光滑度的强大方法。", "problem": "考虑一个定义在具有欧几里得范数的有限维实希尔伯特空间中的线性反问题。设 $A \\in \\mathbb{R}^{m \\times n}$ 为一个已知的正向算子，$x^{\\ast} \\in \\mathbb{R}^{n}$ 为未知的真实状态，含噪数据 $b^{\\delta} \\in \\mathbb{R}^{m}$ 服从加性噪声模型 $b^{\\delta} = A x^{\\ast} + \\eta$，其中 $\\|\\eta\\|_{2} \\leq \\delta$，$\\delta \\geq 0$ 是已知的噪声水平。对于一个正正则化参数序列 $\\{\\alpha_{j}\\}_{j=0}^{J-1}$（其中 $\\alpha_{j}  0$），Tikhonov正则化迭代解 $x_{j} \\in \\mathbb{R}^{n}$ 被定义为二次泛函的唯一最小化子（等价地，由正规方程给出），使得 $x_{j}$ 是以下问题的解\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\|A x - b^{\\delta}\\|_{2}^{2} + \\alpha_{j} \\|x\\|_{2}^{2},\n$$\n这等价于\n$$\n(A^{\\top} A + \\alpha_{j} I) x_{j} = A^{\\top} b^{\\delta}.\n$$\nLepskii型停止准则选择最小的索引 $k$，使得对于所有 $j  k$，稳定化条件\n$$\n\\|x_{k} - x_{j}\\|_{2} \\leq c \\, \\theta(j)\n$$\n成立。其中 $c \\geq 1$ 是给定的安全因子，$\\theta(j)$ 是一个依赖于正则化参数 $\\alpha_{j}$ 和已知噪声水平 $\\delta$ 的噪声依赖界。您的任务是基于Tikhonov解算子的谱表征，计算一个可接受的紧界 $\\theta(j)$，然后实现Lepskii型准则来确定停止索引 $k$。\n\n您的界 $\\theta(j)$ 应基于以下原则：对于每个 $\\alpha_{j}$，从 $b^{\\delta}$ 到 $x_{j}$ 的Tikhonov解映射是线性的，并且由噪声 $\\eta$ 引起的扰动由将 $\\eta$ 映射到 $\\alpha_{j}$ 处解的扰动的线性滤波器的算子范数控制。使用此算子范数和已知的噪声水平 $\\delta$ 来构造 $\\theta(j)$，构造方式不依赖于未知量。本文中所有范数均为欧几里得范数，所有矩阵范数均为谱范数（算子2-范数）。\n\n实现以下算法步骤：\n- 对于每个测试用例，根据提供的 $A$、$x^{\\ast}$ 和 $\\eta$ 构建 $b^{\\delta} = A x^{\\ast} + \\eta$。\n- 对于 $\\{0,1,\\dots,J-1\\}$ 中的每个 $j$，通过求解 $(A^{\\top} A + \\alpha_{j} I) x_{j} = A^{\\top} b^{\\delta}$ 来计算 $x_{j}$。\n- 对于每个 $j$，根据在 $\\alpha_{j}$ 处的Tikhonov滤波器的谱表征和噪声水平 $\\delta$ 计算一个可接受的界 $\\theta(j)$。\n- 找到最小的 $k$，使得对于所有 $j  k$，$\\|x_{k} - x_{j}\\|_{2} \\leq c \\, \\theta(j)$ 均成立。如果不存在这样的 $k$，则设 $k := J-1$。\n\n所有向量计算均使用欧几里得范数 $\\|\\cdot\\|_{2}$。允许使用奇异值分解来计算谱范数。\n\n测试套件：\n- 测试 1：\n  - $A = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  0.1 \\end{bmatrix}$，\n  - $x^{\\ast} = \\begin{bmatrix} 1.0 \\\\ 1.0 \\end{bmatrix}$，\n  - $\\eta = \\begin{bmatrix} 0.01 \\\\ 0.0 \\end{bmatrix}$，因此 $\\delta = 0.01$，\n  - $\\{\\alpha_{j}\\}_{j=0}^{5} = \\{1.0,\\,0.5,\\,0.25,\\,0.125,\\,0.0625,\\,0.03125\\}$，\n  - $c = 1.2$。\n- 测试 2（精确数据的边界情况）：\n  - $A = \\begin{bmatrix} 2.0  0.0 \\\\ 0.0  0.5 \\end{bmatrix}$，\n  - $x^{\\ast} = \\begin{bmatrix} 1.0 \\\\ -1.0 \\end{bmatrix}$，\n  - $\\eta = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$，因此 $\\delta = 0.0$，\n  - $\\{\\alpha_{j}\\}_{j=0}^{2} = \\{1.0,\\,0.1,\\,0.01\\}$，\n  - $c = 1.5$。\n- 测试 3（病态条件情况）：\n  - $A = \\begin{bmatrix} 1.0  0.0  0.0 \\\\ 0.0  0.01  0.0 \\\\ 0.0  0.0  0.001 \\end{bmatrix}$，\n  - $x^{\\ast} = \\begin{bmatrix} 1.0 \\\\ 1.0 \\\\ 1.0 \\end{bmatrix}$，\n  - $\\eta = \\begin{bmatrix} 0.0 \\\\ 0.005 \\\\ 0.0 \\end{bmatrix}$，因此 $\\delta = 0.005$，\n  - $\\{\\alpha_{j}\\}_{j=0}^{3} = \\{1.0,\\,0.5,\\,0.25,\\,0.125\\}$，\n  - $c = 1.0$。\n- 测试 4：\n  - $A = \\begin{bmatrix} 1.0  0.2  0.0 \\\\ 0.0  0.5  0.0 \\\\ 0.0  0.0  0.3 \\end{bmatrix}$，\n  - $x^{\\ast} = \\begin{bmatrix} 1.0 \\\\ 2.0 \\\\ -1.0 \\end{bmatrix}$，\n  - $\\eta = \\begin{bmatrix} 0.02 \\\\ 0.0 \\\\ 0.0 \\end{bmatrix}$，因此 $\\delta = 0.02$，\n  - $\\{\\alpha_{j}\\}_{j=0}^{3} = \\{1.0,\\,0.3,\\,0.09,\\,0.027\\}$，\n  - $c = 1.3$。\n\n您的程序应生成单行输出，其中包含上述测试的停止索引，格式为方括号括起来的逗号分隔列表，形如 $[k_{1},k_{2},k_{3},k_{4}]$，其中每个 $k_{i}$ 都是整数。不允许有其他输出。不涉及角度。不涉及物理单位。所有计算都使用实数和欧几里得范数。", "solution": "该问题是有效的。它在科学上基于反问题和Tikhonov正则化理论，问题提法良好，目标明确，并提供了推导唯一解所需的所有信息。\n\n任务是为Tikhonov正则化实现一个Lepskii型停止准则。该准则从给定的序列 $\\{\\alpha_j\\}_{j=0}^{J-1}$ 中选择一个最优的正则化参数 $\\alpha_k$。任务的核心是首先推导出一个合适的界 $\\theta(j)$，然后用它来找到停止索引 $k$。\n\n首先，我们将问题形式化。对于给定的正则化参数 $\\alpha_j > 0$，Tikhonov正则化解 $x_j$ 是泛函 $\\|A x - b^{\\delta}\\|_{2}^{2} + \\alpha_j \\|x\\|_{2}^{2}$ 的最小化子。该解由正规方程给出：\n$$\n(A^{\\top} A + \\alpha_j I) x_j = A^{\\top} b^{\\delta}\n$$\n其中 $I$ 是单位矩阵。解可以写为：\n$$\nx_j = (A^{\\top} A + \\alpha_j I)^{-1} A^{\\top} b^{\\delta}\n$$\n含噪数据建模为 $b^{\\delta} = A x^{\\ast} + \\eta$，其中 $x^{\\ast}$ 是真实解，$\\eta$ 是噪声向量，其范数有已知界 $\\|\\eta\\|_{2} \\leq \\delta$。\n\n我们可以将解 $x_j$ 分解为两部分：一部分对应于无噪声数据 $b=Ax^{\\ast}$，另一部分由噪声 $\\eta$ 引起。\n令 $x_j^{\\ast}$ 为使用无噪声数据所能获得的“理想”正则化解：\n$$\nx_j^{\\ast} = (A^{\\top} A + \\alpha_j I)^{-1} A^{\\top} (A x^{\\ast})\n$$\n那么，实际解 $x_j$ 是：\n$$\nx_j = (A^{\\top} A + \\alpha_j I)^{-1} A^{\\top} (A x^{\\ast} + \\eta) = x_j^{\\ast} + (A^{\\top} A + \\alpha_j I)^{-1} A^{\\top} \\eta\n$$\n因此，由噪声引起的解的扰动为 $x_j - x_j^{\\ast} = (A^{\\top} A + \\alpha_j I)^{-1} A^{\\top} \\eta$。我们定义线性滤波器算子 $R_j = (A^{\\top} A + \\alpha_j I)^{-1} A^{\\top}$。噪声引起的扰动为 $R_j \\eta$。\n\n问题指出，界 $\\theta(j)$ 应基于该滤波器的算子范数和已知的噪声水平 $\\delta$ 来构造。扰动的范数可以被界定为：\n$$\n\\|x_j - x_j^{\\ast}\\|_{2} = \\|R_j \\eta\\|_{2} \\leq \\|R_j\\|_{2} \\|\\eta\\|_{2} \\leq \\|R_j\\|_{2} \\delta\n$$\n此处，$\\|R_j\\|_{2}$ 是矩阵 $R_j$ 的谱范数（算子2-范数）。问题要求我们由此构造 $\\theta(j)$。基于此原则，对于噪声依赖界最直接且可接受的选择是将 $\\theta(j)$ 定义为噪声传播的一个界：\n$$\n\\theta(j) = \\|R_j\\|_{2} \\delta\n$$\n为了计算 $\\|R_j\\|_{2}$，我们使用矩阵 $A$ 的奇异值分解（SVD）。令 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个包含奇异值 $\\sigma_i \\geq 0$ 的对角矩阵。\n\n将SVD代入 $R_j$ 的表达式中：\n$$\nA^{\\top}A = (U \\Sigma V^{\\top})^{\\top} (U \\Sigma V^{\\top}) = V \\Sigma^{\\top} U^{\\top} U \\Sigma V^{\\top} = V \\Sigma^{\\top} \\Sigma V^{\\top}\n$$\n由于 $A^{\\top}A$ 是一个 $n \\times n$ 矩阵，$\\Sigma^{\\top}\\Sigma$ 是一个 $n \\times n$ 对角矩阵，其对角元素为 $\\sigma_i^2$。\n$$\nA^{\\top}A + \\alpha_j I = V (\\Sigma^{\\top}\\Sigma + \\alpha_j I) V^{\\top}\n$$\n其逆为：\n$$\n(A^{\\top}A + \\alpha_j I)^{-1} = V (\\Sigma^{\\top}\\Sigma + \\alpha_j I)^{-1} V^{\\top} = V \\text{diag}\\left(\\frac{1}{\\sigma_i^2 + \\alpha_j}\\right) V^{\\top}\n$$\n现在，我们构造 $R_j$：\n$$\nR_j = (A^{\\top}A + \\alpha_j I)^{-1} A^{\\top} = \\left(V \\text{diag}\\left(\\frac{1}{\\sigma_i^2 + \\alpha_j}\\right) V^{\\top}\\right) (V \\Sigma^{\\top} U^{\\top}) = V \\text{diag}\\left(\\frac{\\sigma_i}{\\sigma_i^2 + \\alpha_j}\\right) U^{\\top}\n$$\n这是 $R_j$ 的SVD。$R_j$ 的奇异值是那些非负值 $g_j(\\sigma_i) = \\frac{\\sigma_i}{\\sigma_i^2 + \\alpha_j}$。谱范数是这些奇异值中的最大值：\n$$\n\\|R_j\\|_{2} = \\max_{i} \\left\\{ \\frac{\\sigma_i}{\\sigma_i^2 + \\alpha_j} \\right\\}\n$$\n其中最大值是在 $A$ 的所有非零奇异值 $\\sigma_i$ 上取的。\n\n这为我们提供了 $\\theta(j)$ 的一个可计算的表达式：\n$$\n\\theta(j) = \\delta \\cdot \\max_{i} \\left\\{ \\frac{\\sigma_i}{\\sigma_i^2 + \\alpha_j} \\right\\}\n$$\n\n完整的算法如下：\n1.  对于每个测试用例，给定 $A$、$x^{\\ast}$、$\\eta$、$\\{\\alpha_j\\}_{j=0}^{J-1}$ 和 $c$。\n2.  计算含噪数据 $b^{\\delta} = A x^{\\ast} + \\eta$ 和噪声水平 $\\delta = \\|\\eta\\|_{2}$。\n3.  计算 $A$ 的奇异值 $\\sigma_i$。\n4.  计算正规方程的右端项：$v = A^{\\top}b^{\\delta}$。\n5.  对于每个 $j \\in \\{0, 1, \\dots, J-1\\}$：\n    a. 构造矩阵 $M_j = A^{\\top}A + \\alpha_j I$。\n    b. 求解线性系统 $M_j x_j = v$ 以找到Tikhonov迭代解 $x_j$。存储所有的 $x_j$。\n6.  实现Lepskii型停止准则：\n    a. 用索引 $k$ 从 $0$ 到 $J-2$ 进行迭代。\n    b. 对于每个 $k$，假设它是一个有效的停止索引。设置一个标志 `is_k_valid = True`。\n    c. 用索引 $j$ 从 $k+1$ 到 $J-1$ 进行迭代。\n    d. 计算差的范数：$d_{kj} = \\|x_k - x_j\\|_{2}$。\n    e. 计算界 $\\theta(j) = \\delta \\cdot \\max_{i} \\{ \\frac{\\sigma_i}{\\sigma_i^2 + \\alpha_j} \\}$。\n    f. 检查条件：如果 $d_{kj} > c \\cdot \\theta(j)$，则该条件对于此 $k$ 不满足。设置 `is_k_valid = False` 并中断内部关于 $j$ 的循环。\n    g. 如果内部循环完成且 `is_k_valid` 保持为 `True`，则 $k$ 是满足对所有 $j>k$ 条件的最小停止索引。搜索完成，此 $k$ 即为结果。\n7. 如果关于 $k$ 的外层循环完成而没有找到这样的索引，则准则规定停止索引为 $k = J-1$。\n\n对每个提供的测试用例都执行此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef find_stopping_index(A, x_star, eta, alphas, c):\n    \"\"\"\n    Implements the Lepskii-type stopping rule for Tikhonov regularization.\n\n    Args:\n        A (np.ndarray): The forward operator matrix.\n        x_star (np.ndarray): The true state vector.\n        eta (np.ndarray): The noise vector.\n        alphas (list or np.ndarray): Sequence of regularization parameters.\n        c (float): The safety factor.\n\n    Returns:\n        int: The stopping index k.\n    \"\"\"\n    m, n = A.shape\n    J = len(alphas)\n\n    # Step 1: Construct b_delta and find noise level delta\n    b_delta = A @ x_star + eta\n    delta = np.linalg.norm(eta)\n\n    # Step 2: Pre-compute necessary components\n    AtA = A.T @ A\n    Atb = A.T @ b_delta\n    \n    # Use SVD to get singular values for norm calculation of the filter operator\n    # We only need the singular values, not U and V.\n    # Exclude tiny singular values that are numerical artifacts\n    sigmas = np.linalg.svd(A, compute_uv=False)\n    sigmas = sigmas[sigmas > 1e-15] \n\n    # Step 3: Compute all Tikhonov solutions x_j\n    solutions = []\n    for alpha_j in alphas:\n        # Tikhonov normal equation: (A^T A + alpha_j I) x_j = A^T b_delta\n        I = np.identity(n)\n        matrix_to_invert = AtA + alpha_j * I\n        x_j = np.linalg.solve(matrix_to_invert, Atb)\n        solutions.append(x_j)\n\n    # Step 4: Find the stopping index k\n    for k in range(J - 1):\n        is_k_valid = True\n        for j in range(k + 1, J):\n            # Calculate the norm of the difference between iterates\n            diff_norm = np.linalg.norm(solutions[k] - solutions[j])\n\n            # Calculate the bound theta(j)\n            alpha_j = alphas[j]\n            \n            if delta == 0.0:\n                # If data is exact, the bound is 0. The condition becomes\n                # ||x_k - x_j|| = 0, which is only true if x_k = x_j.\n                # Since alphas are distinct, this is generally not true.\n                theta_j = 0.0\n            else:\n                if len(sigmas) > 0:\n                    filter_gains = sigmas / (sigmas**2 + alpha_j)\n                    norm_Rj = np.max(filter_gains)\n                else: # Zero matrix case\n                    norm_Rj = 0.0\n                theta_j = delta * norm_Rj\n            \n            # Check the Lepskii-type condition\n            if diff_norm > c * theta_j:\n                is_k_valid = False\n                break  # This k is not the stopping index, try the next k\n\n        if is_k_valid:\n            # Smallest k found that satisfies the condition for all j > k\n            return k\n\n    # If no such k is found in the loop, return the last index as per the rule\n    return J - 1\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the Lepskii-type stopping rule.\n    \"\"\"\n    test_cases = [\n        {\n            \"A\": np.array([[1.0, 0.0], [0.0, 0.1]]),\n            \"x_star\": np.array([1.0, 1.0]),\n            \"eta\": np.array([0.01, 0.0]),\n            \"alphas\": [1.0, 0.5, 0.25, 0.125, 0.0625, 0.03125],\n            \"c\": 1.2\n        },\n        {\n            \"A\": np.array([[2.0, 0.0], [0.0, 0.5]]),\n            \"x_star\": np.array([1.0, -1.0]),\n            \"eta\": np.array([0.0, 0.0]),\n            \"alphas\": [1.0, 0.1, 0.01],\n            \"c\": 1.5\n        },\n        {\n            \"A\": np.array([[1.0, 0.0, 0.0], [0.0, 0.01, 0.0], [0.0, 0.0, 0.001]]),\n            \"x_star\": np.array([1.0, 1.0, 1.0]),\n            \"eta\": np.array([0.0, 0.005, 0.0]),\n            \"alphas\": [1.0, 0.5, 0.25, 0.125],\n            \"c\": 1.0\n        },\n        {\n            \"A\": np.array([[1.0, 0.2, 0.0], [0.0, 0.5, 0.0], [0.0, 0.0, 0.3]]),\n            \"x_star\": np.array([1.0, 2.0, -1.0]),\n            \"eta\": np.array([0.02, 0.0, 0.0]),\n            \"alphas\": [1.0, 0.3, 0.09, 0.027],\n            \"c\": 1.3\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        k = find_stopping_index(\n            case[\"A\"],\n            case[\"x_star\"],\n            case[\"eta\"],\n            case[\"alphas\"],\n            case[\"c\"]\n        )\n        results.append(k)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3423230"}]}