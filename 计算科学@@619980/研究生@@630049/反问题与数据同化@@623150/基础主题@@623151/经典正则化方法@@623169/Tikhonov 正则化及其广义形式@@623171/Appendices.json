{"hands_on_practices": [{"introduction": "为了真正掌握广义吉洪诺夫正则化，第一步是亲自动手进行数学推导。这个练习提供了一个简单具体的例子，要求你手动计算广义吉洪诺夫泛函的最小值[@problem_id:1031979]。通过展开泛函、求偏导数并求解线性方程组，你将直观地理解正则化项（控制解的光滑性）如何与数据保真项（拟合观测数据）相互作用，从而为更复杂的问题打下坚实的数学基础。", "problem": "考虑超定线性系统 $A \\mathbf{u} = \\mathbf{b}$，其中 $A$ 是一个 $3 \\times 2$ 矩阵\n$$  \nA = \\begin{bmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\end{bmatrix},  \n$$  \n且 $\\mathbf{b}$ 是向量 $\\mathbf{b} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}$。广义 Tikhonov 正则化泛函包含一个导数算子 $L$，定义为\n$$  \nJ(\\mathbf{u}) = \\| A \\mathbf{u} - \\mathbf{b} \\|^2 + \\lambda \\| L \\mathbf{u} \\|^2,  \n$$  \n其中 $\\mathbf{u} = \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix} \\in \\mathbb{R}^2$，$\\lambda > 0$ 是一个正则化参数，$L$ 是由 $1 \\times 2$ 矩阵 $L = \\begin{bmatrix} -1  1 \\end{bmatrix}$ 给出的一阶导数算子。计算 $J(\\mathbf{u})$ 在所有 $\\mathbf{u} \\in \\mathbb{R}^2$ 上的最小值。", "solution": "1. 写出泛函。\n$$\nJ(u_1,u_2)=(u_1-1)^2+u_2^2+(u_1+u_2)^2+\\lambda(u_2-u_1)^2.\n$$\n2. 展开并合并各项。\n$$\nJ(u_1, u_2) = (2+\\lambda)u_1^2 + (2+\\lambda)u_2^2 + (2-2\\lambda)u_1u_2 - 2u_1 + 1.\n$$\n3. 平稳性条件为梯度等于零。\n$$\n\\frac{\\partial J}{\\partial u_1}=2(2+\\lambda)u_1+(2-2\\lambda)u_2-2=0\n$$\n$$\n\\frac{\\partial J}{\\partial u_2}=2(2+\\lambda)u_2+(2-2\\lambda)u_1=0\n$$\n4. 求解 $(u_1,u_2)$ 的线性方程组。解为\n$$\nu_1=\\frac{2+\\lambda}{3(1+2\\lambda)},\\quad\nu_2=-\\frac{1-\\lambda}{3(1+2\\lambda)}.\n$$\n5. 将结果代回 $J$：经过代数运算可得\n$$\nJ_{\\min}\n=\\frac{10\\lambda^2+7\\lambda+1}{3(1+2\\lambda)^2}\n=\\frac{5\\lambda+1}{3(2\\lambda+1)}.\n$$\n因此 $J$ 的最小值为 $(5\\lambda+1)/[3(2\\lambda+1)]\\,$。", "answer": "$$\\boxed{\\frac{5\\lambda+1}{3(2\\lambda+1)}}$$", "id": "1031979"}, {"introduction": "在掌握了如何计算正则化解之后，下一个关键问题是：“这种方法在什么条件下是有效的？”。这个练习将引导你从计算转向概念理解，探讨广义吉洪诺夫正则化解的存在性和唯一性[@problem_id:3283916]。通过分析算子矩阵的零空间（null space），你将发现确保问题适定（well-posed）并产生唯一稳定解的核心理论条件，这对于在实际应用中避免不确定性和不稳定性至关重要。", "problem": "考虑一个可能病态的线性模型的 Tikhonov 正则化问题：给定 $A \\in \\mathbb{R}^{m \\times n}$，$b \\in \\mathbb{R}^{m}$，$\\Gamma \\in \\mathbb{R}^{p \\times n}$，以及一个正则化参数 $\\alpha > 0$，定义目标函数\n$$\nJ_{\\alpha}(x) \\;=\\; \\lVert A x - b \\rVert_{2}^{2} \\;+\\; \\alpha \\,\\lVert \\Gamma x \\rVert_{2}^{2}, \\quad x \\in \\mathbb{R}^{n}.\n$$\n假设 $\\Gamma$ 可能是奇异的（秩亏的）。令 $\\mathcal{N}(M) = \\{x \\in \\mathbb{R}^{n} : M x = 0\\}$ 表示矩阵 $M$ 的零空间，令 $\\mathcal{R}(M)$ 表示其值域（列空间）。当 $\\Gamma$ 是奇异的时，仅使用关于最小二乘和零空间与值域性质的基本线性代数事实，分析最小化子的存在性、唯一性以及结构。\n\n下列哪个陈述是正确的？\n\nA. 对于任意 $\\alpha > 0$ 和任意 $A$、$b$ 以及奇异的 $\\Gamma$，关于 $J_{\\alpha}$ 的最小化问题至少有一个解 $x_{\\alpha}$。\n\nB. 最小化子是唯一的，当且仅当 $\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma) = \\{0\\}$。\n\nC. 如果 $\\Gamma$ 是奇异的，则对于所有 $\\alpha > 0$，$J_{\\alpha}$ 相关的二次型都是奇异的，因此最小化子永远不是唯一的。\n\nD. 如果 $\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma) \\neq \\{0\\}$，则最小化子集合是一个仿射子空间，形式为 $x_{\\alpha}^{\\star} + \\big(\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma)\\big)$，其中 $x_{\\alpha}^{\\star}$ 是某个特定的最小化子。\n\nE. 如果 $A$ 是满列秩但 $\\Gamma$ 是奇异的，则存在某个 $b$，使得 Tikhonov 最小化子不存在。", "solution": "首先验证问题陈述的正确性和清晰性。\n\n### 步骤 1：提取已知条件\n- 矩阵：$A \\in \\mathbb{R}^{m \\times n}$，$\\Gamma \\in \\mathbb{R}^{p \\times n}$。\n- 向量：$b \\in \\mathbb{R}^{m}$，$x \\in \\mathbb{R}^{n}$。\n- 标量：正则化参数 $\\alpha > 0$。\n- 目标函数：$J_{\\alpha}(x) = \\lVert A x - b \\rVert_{2}^{2} + \\alpha \\lVert \\Gamma x \\rVert_{2}^{2}$。\n- 条件：矩阵 $\\Gamma$ 可能奇异。\n- 记号：零空间 $\\mathcal{N}(M) = \\{x \\in \\mathbb{R}^{n} : M x = 0\\}$，值域 $\\mathcal{R}(M)$。\n- 任务：分析 $J_{\\alpha}(x)$ 的最小化子的存在性、唯一性和结构。\n\n### 步骤 2：使用提取的已知条件进行验证\n问题陈述具有科学依据，是适定的、客观的。它提出了广义 Tikhonov 正则化的标准形式，这是数值方法和科学计算中的一个基本课题。目标函数定义清晰，任务是对一个优化问题进行标准的数学分析。语言精确且无歧义。所有必要的组成部分都已提供，且没有内部矛盾。\n\n### 步骤 3：结论和行动\n问题陈述是有效的。我将对每个选项进行完整的推导和分析。\n\n### 推导\n目标函数 $J_{\\alpha}(x)$ 可以重写为一个堆叠系统的欧几里得范数的平方。\n$$\nJ_{\\alpha}(x) = \\lVert A x - b \\rVert_{2}^{2} + \\alpha \\lVert \\Gamma x \\rVert_{2}^{2} = \\lVert A x - b \\rVert_{2}^{2} + \\lVert \\sqrt{\\alpha} \\Gamma x - 0 \\rVert_{2}^{2}\n$$\n这等价于最小化最小二乘问题 $\\lVert A_{\\alpha} x - b_{\\alpha} \\rVert_{2}^{2}$，其中 $A_{\\alpha}$ 和 $b_{\\alpha}$ 是增广矩阵和向量：\n$$\nA_{\\alpha} = \\begin{pmatrix} A \\\\ \\sqrt{\\alpha} \\Gamma \\end{pmatrix} \\in \\mathbb{R}^{(m+p) \\times n}, \\quad b_{\\alpha} = \\begin{pmatrix} b \\\\ 0 \\end{pmatrix} \\in \\mathbb{R}^{(m+p)}\n$$\n这个最小二乘问题的最小化子是正规方程组的解：\n$$\nA_{\\alpha}^{T} A_{\\alpha} x = A_{\\alpha}^{T} b_{\\alpha}\n$$\n我们来计算正规方程组的各部分。\n矩阵是：\n$$\nA_{\\alpha}^{T} A_{\\alpha} = \\begin{pmatrix} A^T  \\sqrt{\\alpha} \\Gamma^T \\end{pmatrix} \\begin{pmatrix} A \\\\ \\sqrt{\\alpha} \\Gamma \\end{pmatrix} = A^T A + \\alpha \\Gamma^T \\Gamma\n$$\n右侧向量是：\n$$\nA_{\\alpha}^{T} b_{\\alpha} = \\begin{pmatrix} A^T  \\sqrt{\\alpha} \\Gamma^T \\end{pmatrix} \\begin{pmatrix} b \\\\ 0 \\end{pmatrix} = A^T b\n$$\n因此，正规方程组为：\n$$\n(A^T A + \\alpha \\Gamma^T \\Gamma) x = A^T b\n$$\n我们把二次型的 Hessian 矩阵表示为 $H_{\\alpha} = A^T A + \\alpha \\Gamma^T \\Gamma$。目标函数为 $J_{\\alpha}(x) = x^T H_{\\alpha} x - 2x^T A^T b + b^T b$。由于 $A^T A$ 和 $\\Gamma^T \\Gamma$ 是半正定的，且 $\\alpha > 0$，所以 $H_{\\alpha}$ 也是半正定的。这证实了 $J_{\\alpha}(x)$ 是一个凸函数。\n\n### 逐项分析\n\n**A. 对于任意 $\\alpha > 0$ 和任意 $A$、$b$ 以及奇异的 $\\Gamma$，关于 $J_{\\alpha}$ 的最小化问题至少有一个解 $x_{\\alpha}$。**\n\n最小化 $J_{\\alpha}(x)$ 的问题是一个线性最小二乘问题。线性代数的一个基本定理指出，任何线性最小二乘问题 $\\min_{x \\in \\mathbb{R}^n} \\lVert Kx - d \\rVert_2^2$ 的解总是存在的。这是因为解集等价于满足 $Kx = \\text{proj}_{\\mathcal{R}(K)}(d)$ 的向量 $x$ 的集合，该集合非空，因为 $d$ 在 $K$ 的列空间上的投影总是存在的。\n或者，解集与正规方程组 $K^T K x = K^T d$ 的解集相同。一个线性系统 $Mx=c$ 有解当且仅当 $c \\in \\mathcal{R}(M)$。这里，$M = K^T K$ 且 $c = K^T d$。因为对于任何矩阵 $K$ 都有 $\\mathcal{R}(K^T K) = \\mathcal{R}(K^T)$，并且 $c = K^T d$ 根据定义位于 $\\mathcal{R}(K^T)$ 中，所以该系统总是相容的，并且至少有一个解。\n对于任意 $A, b, \\Gamma$ 和任意 $\\alpha > 0$，解的存在性是无条件的。$\\Gamma$ 是否奇异对最小化子的存在性没有影响。\n\n结论：**正确**。\n\n**B. 最小化子是唯一的，当且仅当 $\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma) = \\{0\\}$。**\n\n最小二乘问题 $\\min_{x} \\lVert A_{\\alpha} x - b_{\\alpha} \\rVert_{2}^{2}$ 的最小化子是唯一的，当且仅当矩阵 $A_{\\alpha}$ 是满列秩，这等价于其零空间是平凡的，即 $\\mathcal{N}(A_{\\alpha}) = \\{0\\}$。\n我们来描述这个零空间。一个向量 $x \\in \\mathbb{R}^n$ 属于 $\\mathcal{N}(A_{\\alpha})$ 当且仅当 $A_{\\alpha} x = 0$。\n$$\nA_{\\alpha} x = \\begin{pmatrix} A x \\\\ \\sqrt{\\alpha} \\Gamma x \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n这成立当且仅当 $A x = 0$ 且 $\\sqrt{\\alpha} \\Gamma x = 0$。由于 $\\alpha > 0$，第二个条件等价于 $\\Gamma x = 0$。\n所以，$x \\in \\mathcal{N}(A_{\\alpha})$ 当且仅当 $x \\in \\mathcal{N}(A)$ 且 $x \\in \\mathcal{N}(\\Gamma)$。这意味着：\n$$\n\\mathcal{N}(A_{\\alpha}) = \\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma)\n$$\n因此，最小化子是唯一的当且仅当 $\\mathcal{N}(A_{\\alpha}) = \\{0\\}$，这等价于条件 $\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma) = \\{0\\}$。\n\n结论：**正确**。\n\n**C. 如果 $\\Gamma$ 是奇异的，则对于所有 $\\alpha > 0$，$J_{\\alpha}$ 相关的二次型都是奇异的，因此最小化子永远不是唯一的。**\n\n该二次型与 Hessian 矩阵 $H_{\\alpha} = A^T A + \\alpha \\Gamma^T \\Gamma$ 相关。该矩阵奇异当且仅当其零空间非平凡。如 B 的分析所示，$\\mathcal{N}(H_{\\alpha}) = \\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma)$。\n该陈述声称，如果 $\\Gamma$ 是奇异的（即 $\\mathcal{N}(\\Gamma) \\neq \\{0\\}$），那么 $H_{\\alpha}$ 总是奇异的（即 $\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma) \\neq \\{0\\}$）。这是不正确的。$\\mathcal{N}(\\Gamma)$ 可能是一个非平凡子空间，而它与 $\\mathcal{N}(A)$ 的交集是平凡的。\n考虑以下反例。令 $n=2$，$A = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}$，以及 $\\Gamma = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}$。\n那么 $\\mathcal{N}(A) = \\text{span}\\left\\{ \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\right\\}$ 和 $\\mathcal{N}(\\Gamma) = \\text{span}\\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\right\\}$。\n这里，$\\Gamma$ 是奇异的。然而，$\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma) = \\{0\\}$。\n根据 B 的结果，这种情况下最小化子是唯一的。矩阵 $H_{\\alpha}$ 是 $A^T A + \\alpha \\Gamma^T \\Gamma = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} + \\alpha \\begin{pmatrix} 0  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  \\alpha \\end{pmatrix}$。由于 $\\alpha > 0$，$H_\\alpha$ 是可逆的。\n该陈述是错误的。\n\n结论：**错误**。\n\n**D. 如果 $\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma) \\neq \\{0\\}$，则最小化子集合是一个仿射子空间，形式为 $x_{\\alpha}^{\\star} + \\big(\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma)\\big)$，其中 $x_{\\alpha}^{\\star}$ 是某个特定的最小化子。**\n\n最小化子集合是正规方程组 $H_{\\alpha} x = A^T b$ 的解集，其中 $H_{\\alpha} = A^T A + \\alpha \\Gamma^T \\Gamma$。根据线性代数，一个相容线性系统 $Mx=c$ 的通解由 $x = x_p + z$ 给出，其中 $x_p$ 是任意一个特解，$z$ 是 $M$ 的零空间 $\\mathcal{N}(M)$ 中的任意向量。解集是仿射子空间 $x_p + \\mathcal{N}(M)$。\n在我们的例子中，我们已经确定了问题总是有解（因此系统是相容的），并且相关矩阵的零空间是 $\\mathcal{N}(H_{\\alpha}) = \\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma)$。\n因此，如果 $\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma) \\neq \\{0\\}$，解不是唯一的，并且所有最小化子的集合恰好是由任意一个特定的最小化子 $x_{\\alpha}^{\\star}$ 加上零空间 $\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma)$ 构成的仿射子空间。该陈述准确地描述了这种结构。\n\n结论：**正确**。\n\n**E. 如果 $A$ 是满列秩但 $\\Gamma$ 是奇异的，则存在某个 $b$，使得 Tikhonov 最小化子不存在。**\n\n这个陈述从根本上是错误的。正如在选项 A 的分析中所确立的，对于任意选择的 $A$、$b$、$\\Gamma$ 和任意 $\\alpha > 0$，最小化子*总是*存在的。存在性是无条件的。\n此外，这个陈述的前提导出了唯一解的结论，这与不存在解是相反的。如果 $A$ 是满列秩，那么 $\\mathcal{N}(A) = \\{0\\}$。这意味着 $\\mathcal{N}(A) \\cap \\mathcal{N}(\\Gamma) = \\{0\\} \\cap \\mathcal{N}(\\Gamma) = \\{0\\}$。根据 B 的结果，在此条件下，无论 $\\Gamma$ 是否奇异，最小化子总是唯一的。唯一性意味着存在性。因此该陈述是错误的。\n\n结论：**错误**。\n\n正确选项的最终总结：A、B、D。", "answer": "$$\\boxed{ABD}$$", "id": "3283916"}, {"introduction": "将理论付诸实践是检验理解的最终标准，但实践中充满了需要警惕的陷阱。这个编码练习将让你面对一个在计算科学中被称为“反演犯罪”（inverse crime）的典型问题[@problem_id:3427382]。通过亲手实现并对比两种数据生成方案——一种是“犯罪”方案，另一种是更真实的交错网格方案——你将深刻体会到模型误差的重要性，并学会如何正确地设计验证实验来评估正则化方法的真实性能。", "problem": "考虑一个线性逆问题，旨在从由第一类弗雷德霍姆积分方程建模的模糊观测中恢复单位区间 $[0,1]$ 上的未知函数 $x$\n$$\ny(s) \\;=\\; \\int_{0}^{1} k(s,t)\\,x(t)\\,dt, \\quad s \\in [0,1],\n$$\n其高斯模糊核为\n$$\nk(s,t) \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp\\!\\Big(-\\frac{(s-t)^2}{2\\sigma^2}\\Big),\n$$\n其中 $\\sigma > 0$ 是模糊宽度。离散 Tikhonov 正则化问题旨在寻找一个 $x \\in \\mathbb{R}^N$ 来最小化\n$$\nJ(x) \\;=\\; \\|A x - y\\|_2^2 \\;+\\; \\alpha^2 \\|L x\\|_2^2,\n$$\n其中 $A \\in \\mathbb{R}^{N \\times N}$ 离散化正向算子，$L \\in \\mathbb{R}^{(N-1) \\times N}$ 离散化一阶导数惩罚项，$\\alpha > 0$ 是正则化参数，$y \\in \\mathbb{R}^N$ 是观测数据。\n\n您的任务是构建一个完整的“逆问题犯罪”测试和一个交错离散化诊断，以比较两种数据生成机制下的重构结果：\n\n- 逆问题犯罪（网格匹配）：通过将与反演中使用的相同离散算子应用于同一网格上离散化的基准真相，来生成合成数据。这种做法可能会夸大表面性能。\n- 交错离散化（非匹配）：通过一个更精细且有移位的、与反演网格不对齐的求积方法来生成合成数据，从而揭示建模误差并诊断真实的正则化效果。\n\n从以下基本出发点开始：\n\n- Tikhonov 正则化的定义，即凸泛函 $J(x)$ 的最小化子。\n- 针对严格凸二次型的一阶最优性（欧拉-拉格朗日条件），导出正规方程组\n$$\n(A^\\top A + \\alpha^2 L^\\top L)\\,x^\\star \\;=\\; A^\\top y.\n$$\n- 在均匀网格上使用标准矩形求积法离散化积分，并使用前向有限差分法离散化一阶导数。\n\n需要实现的离散化细节：\n\n- 反演网格：对于 $i=0,\\dots,N-1$，选择 $N$ 个位于中点 $s_i = (i+\\tfrac{1}{2})/N$ 的点。用 $x$ 在相同中点处的采样值来表示它。反演矩阵 $A \\in \\mathbb{R}^{N\\times N}$ 使用权重为 $w = 1/N$ 的矩形求积法，\n$$\nA_{ij} \\;=\\; k\\!\\big(s_i, s_j\\big)\\,w \\quad \\text{其中} \\quad 0 \\le i,j \\le N-1.\n$$\n- 正则化算子 $L \\in \\mathbb{R}^{(N-1)\\times N}$ 是在同一反演网格上对一阶导数的前向有限差分近似，间距为 $h = 1/N$，\n$$\n(Lx)_j \\;=\\; \\frac{x_{j+1}-x_j}{h}, \\quad j = 0,\\dots,N-2.\n$$\n- 基准真相：使用平滑函数\n$$\nx_{\\text{true}}(t) \\;=\\; \\exp\\!\\big(-50\\,(t-0.3)^2\\big) \\;+\\; 0.5\\,\\sin(6\\pi t) \\;+\\; 0.2,\n$$\n角度以弧度为单位。为进行比较，反演网格上的参考向量为 $x_{\\text{true,inv}} = \\big(x_{\\text{true}}(s_i)\\big)_{i=0}^{N-1}$。\n- 数据生成：\n  - 逆问题犯罪：$y_{\\text{clean}} = A\\,x_{\\text{true,inv}}$。\n  - 交错离散化：对于每个反演网格点 $s_i$，使用一个更精细、有移位的求积方法来近似积分，该方法有 $N_f$ 个点 $t_\\ell = (\\ell + \\delta)/N_f$（其中 $\\ell=0,\\dots,N_f-1$），权重为 $w_f = 1/N_f$，固定移位为 $\\delta = 0.125$，\n  $$\n  y_{\\text{clean},i} \\;=\\; \\sum_{\\ell=0}^{N_f-1} k\\!\\big(s_i, t_\\ell\\big)\\,x_{\\text{true}}(t_\\ell)\\,w_f.\n  $$\n  除非另有说明，对于交错情况，取 $N_f = 4N$。\n- 噪声模型：加性独立高斯噪声 $n \\sim \\mathcal{N}(0,\\sigma_n^2 I)$，每个分量的标准差为\n$$\n\\sigma_n \\;=\\; \\eta\\,\\frac{\\|y_{\\text{clean}}\\|_2}{\\sqrt{N}},\n$$\n其中 $\\eta$ 是指定的相对噪声水平，$I$ 是单位矩阵。\n- 重构：对于给定的 $(A,L,\\alpha,y)$，从正规方程组计算 $x^\\star$，并报告相对重构误差\n$$\n\\varepsilon \\;=\\; \\frac{\\|x^\\star - x_{\\text{true,inv}}\\|_2}{\\|x_{\\text{true,inv}}\\|_2}.\n$$\n\n测试套件与覆盖范围：\n\n实现以下五个测试用例，每个用例由 $(N, N_f, \\sigma, \\alpha, \\eta, \\text{mode})$ 指定，其中 $\\text{mode} \\in \\{\\text{crime},\\text{staggered}\\}$ 表示数据生成机制：\n\n- 用例 1（理想路径，逆问题犯罪）：$(N, N_f, \\sigma, \\alpha, \\eta, \\text{mode}) = (80, 80, 0.03, 0.01, 0.001, \\text{crime})$。\n- 用例 2（理想路径，交错离散化）：$(N, N_f, \\sigma, \\alpha, \\eta, \\text{mode}) = (80, 320, 0.03, 0.01, 0.001, \\text{staggered})$。\n- 用例 3（更强的模糊和噪声，交错离散化）：$(N, N_f, \\sigma, \\alpha, \\eta, \\text{mode}) = (80, 320, 0.05, 0.05, 0.01, \\text{staggered})$。\n- 用例 4（更粗的反演网格，交错离散化）：$(N, N_f, \\sigma, \\alpha, \\eta, \\text{mode}) = (40, 160, 0.03, 0.01, 0.005, \\text{staggered})$。\n- 用例 5（正则化不足，逆问题犯罪）：$(N, N_f, \\sigma, \\alpha, \\eta, \\text{mode}) = (80, 80, 0.03, 0.00001, 0.001, \\text{crime})$。\n\n随机性：\n\n- 为保证可复现性，使用固定种子：对所有噪声抽样，使用种子 $0$ 初始化伪随机数生成器。\n\n要求的程序输出：\n\n- 对于每个用例，计算如上定义的相对误差 $\\varepsilon$。\n- 您的程序应生成单行输出，其中包含五个结果，形式为逗号分隔的列表并用方括号括起，四舍五入到 $6$ 位小数（例如，$[0.123456,0.234567,0.345678,0.456789,0.567890]$）。\n- 不涉及物理单位，所有三角函数角度必须以弧度为单位。\n\n您的实现必须是一个完整、可运行的程序，该程序构建 $A$、$L$，根据机制生成 $y$，求解 Tikhonov 正规方程组，并以指定格式报告所有测试用例的误差。", "solution": "用户提供的问题是逆问题领域一个定义明确的数值练习，特别关注 Tikhonov 正则化。该问题在科学上是合理的，数学上是一致的，并且所有参数和过程都得到了明确的定义。任务是实现一个数值方案来求解第一类弗雷德霍姆积分方程，在不同的数据生成场景（“逆问题犯罪”与“交错离散化”）下进行测试，并量化重构误差。该问题是有效的，可以构建一个解。\n\n求解过程通过离散化连续模型、构建线性代数算子、根据指定机制生成合成数据、求解经 Tikhonov 正则化的正规方程组，并最终计算重构误差来进行。\n\n1. **网格与基准真相的离散化**：\n该问题在 $N$ 个点的均匀网格上进行离散化。反演网格点 $s_i$ 是 $[0,1]$ 子区间的中点：\n$$s_i = \\frac{i + 0.5}{N}, \\quad i = 0, 1, \\dots, N-1.$$\n基准真相函数由下式给出：\n$$x_{\\text{true}}(t) = \\exp\\big(-50(t - 0.3)^2\\big) + 0.5 \\sin(6\\pi t) + 0.2.$$\n通过在网格点 $s_i$ 上对 $x_{\\text{true}}(t)$ 进行采样，得到反演网格上的参考解 $x_{\\text{true,inv}} \\in \\mathbb{R}^N$：\n$$(x_{\\text{true,inv}})_i = x_{\\text{true}}(s_i).$$\n\n2. **算子的离散化**：\n积分算子使用反演网格上的中点矩形法则进行离散化。每个长度为 $h = \\frac{1}{N}$ 的子区间的权重是 $w=\\frac{1}{N}$。矩阵 $A \\in \\mathbb{R}^{N \\times N}$ 的元素为：\n$$A_{ij} = k(s_i, s_j) w = \\frac{1}{N} k(s_i, s_j),$$\n其中核函数为 $k(s,t) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\Big(-\\frac{(s-t)^2}{2\\sigma^2}\\Big)$。\n\n一阶导数正则化算子 $L$ 使用前向有限差分格式进行离散化。对于向量 $x \\in \\mathbb{R}^N$，$Lx$ 的第 $j$ 个分量是点 $s_j$ 处导数的近似：\n$$(Lx)_j = \\frac{x_{j+1} - x_j}{h} = N(x_{j+1} - x_j), \\quad j = 0, 1, \\dots, N-2.$$\n这定义了矩阵 $L \\in \\mathbb{R}^{(N-1) \\times N}$。对于给定的行 $j$，该矩阵在第 $j$ 列的元素为 $-N$，在第 $j+1$ 列的元素为 $N$。\n\n3. **数据生成 ($y$)**：\n观测数据 $y \\in \\mathbb{R}^N$ 的生成过程是首先创建“干净”数据 $y_{\\text{clean}}$，然后添加噪声。\n\n-   **逆问题犯罪机制**：数据使用与反演相同的离散化方法生成。\n    $$y_{\\text{clean}} = A x_{\\text{true,inv}}.$$\n    这被称为“逆问题犯罪”，因为用于反演的模型与数据生成过程完全匹配，这在实践中很少发生，并可能导致不切实际的好结果。\n\n-   **交错离散化机制**：数据使用一个更精细、有移位的网格生成，以模拟模型失配。使用一个包含 $N_f$ 个点的精细网格，$t_\\ell = \\frac{\\ell + \\delta}{N_f}$（其中 $\\ell=0,\\dots,N_f-1$），移位 $\\delta=0.125$。干净数据是积分的近似值：\n    $$ (y_{\\text{clean}})_i = \\sum_{\\ell=0}^{N_f-1} k(s_i, t_\\ell) x_{\\text{true}}(t_\\ell) w_f, $$\n    其中 $w_f = \\frac{1}{N_f}$。这种更现实的方法有助于诊断正则化方法的真实性能。\n\n-   **噪声模型**：将加性高斯噪声 $n \\sim \\mathcal{N}(0, \\sigma_n^2 I)$ 添加到 $y_{\\text{clean}}$。噪声的标准差 $\\sigma_n$ 由相对噪声水平 $\\eta$ 决定：\n    $$\\sigma_n = \\eta \\frac{\\|y_{\\text{clean}}\\|_2}{\\sqrt{N}}.$$\n    最终的观测数据是 $y = y_{\\text{clean}} + n$。为保证可复现性，使用固定的随机种子 $0$。\n\n4. **求解重构结果**：\nTikhonov 正则化解 $x^\\star$ 最小化 $J(x) = \\|Ax - y\\|_2^2 + \\alpha^2 \\|Lx\\|_2^2$。通过求解正规方程组来找到最小化子，该方程组构成一个适定的线性系统：\n$$(A^\\top A + \\alpha^2 L^\\top L) x^\\star = A^\\top y.$$\n我们构造矩阵 $M = A^\\top A + \\alpha^2 L^\\top L$ 和向量 $b = A^\\top y$，并使用标准线性求解器求解系统 $Mx^\\star = b$ 以得到 $x^\\star$。\n\n5. **误差计算**：\n重构结果 $x^\\star$ 的质量通过相对于在反演网格上采样的真实解 $x_{\\text{true,inv}}$ 的相对误差 $\\varepsilon$ 来衡量：\n    $$\\varepsilon = \\frac{\\|x^\\star - x_{\\text{true,inv}}\\|_2}{\\|x_{\\text{true,inv}}\\|_2}.$$\n\n实现将为所提供的五个测试用例中的每一个执行这些步骤。使用 `numpy` 库的 Python 脚本非常适合这些矩阵和向量运算。对于每个用例，我们将配置参数 $(N, N_f, \\sigma, \\alpha, \\eta, \\text{mode})$，构建必要的组件，求解 $x^\\star$，并计算 $\\varepsilon$。最终结果将被收集并按指定格式化。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Tikhonov regularization problem for a series of test cases\n    and prints the relative reconstruction errors.\n    \"\"\"\n    \n    # Use a fixed seed for reproducibility for all noise draws.\n    RNG = np.random.default_rng(0)\n    \n    # Shift for staggered grid, as specified in the problem.\n    DELTA = 0.125\n\n    def x_true_func(t):\n        \"\"\"Computes the ground truth function x_true(t).\"\"\"\n        return np.exp(-50 * (t - 0.3)**2) + 0.5 * np.sin(6 * np.pi * t) + 0.2\n\n    def kernel_func(s, t, sigma):\n        \"\"\"Computes the Gaussian blur kernel k(s,t).\"\"\"\n        return (1.0 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-(s - t)**2 / (2 * sigma**2))\n\n    def compute_reconstruction_error(params):\n        \"\"\"Computes the reconstruction error for a single test case.\"\"\"\n        N, Nf, sigma, alpha, eta, mode = params\n\n        # 1. Discretization of Grids and Ground Truth\n        h = 1.0 / N\n        s_grid = (np.arange(N) + 0.5) * h\n        x_true_inv = x_true_func(s_grid)\n\n        # 2. Discretization of Operators\n        # Forward operator A for inversion\n        s_i_mesh, s_j_mesh = np.meshgrid(s_grid, s_grid, indexing='ij')\n        A = kernel_func(s_i_mesh, s_j_mesh, sigma) * h\n\n        # Regularization operator L\n        L = np.zeros((N - 1, N))\n        idx = np.arange(N - 1)\n        L[idx, idx] = -1.0\n        L[idx, idx + 1] = 1.0\n        L /= h\n\n        # 3. Data Generation (y)\n        if mode == 'crime':\n            y_clean = A @ x_true_inv\n        elif mode == 'staggered':\n            h_f = 1.0 / Nf\n            t_grid = (np.arange(Nf) + DELTA) * h_f\n            x_true_fine = x_true_func(t_grid)\n            \n            s_mesh, t_mesh = np.meshgrid(s_grid, t_grid, indexing='ij')\n            K_staggered = kernel_func(s_mesh, t_mesh, sigma)\n            \n            y_clean = K_staggered @ x_true_fine * h_f\n        else:\n            raise ValueError(f\"Invalid mode: {mode}\")\n\n        # Add noise\n        norm_y_clean = np.linalg.norm(y_clean)\n        if norm_y_clean == 0:\n            sigma_n = 0.0\n        else:\n            sigma_n = eta * norm_y_clean / np.sqrt(N)\n        \n        noise = RNG.normal(loc=0.0, scale=sigma_n, size=N)\n        y = y_clean + noise\n\n        # 4. Solving for the Reconstruction\n        M = A.T @ A + alpha**2 * (L.T @ L)\n        b = A.T @ y\n        x_star = np.linalg.solve(M, b)\n\n        # 5. Error Calculation\n        error_num = np.linalg.norm(x_star - x_true_inv)\n        error_den = np.linalg.norm(x_true_inv)\n        epsilon = error_num / error_den\n        \n        return epsilon\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, Nf, sigma, alpha, eta, mode)\n        (80, 80, 0.03, 0.01, 0.001, 'crime'),\n        (80, 320, 0.03, 0.01, 0.001, 'staggered'),\n        (80, 320, 0.05, 0.05, 0.01, 'staggered'),\n        (40, 160, 0.03, 0.01, 0.005, 'staggered'),\n        (80, 80, 0.03, 1e-5, 0.001, 'crime'),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_reconstruction_error(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "3427382"}]}