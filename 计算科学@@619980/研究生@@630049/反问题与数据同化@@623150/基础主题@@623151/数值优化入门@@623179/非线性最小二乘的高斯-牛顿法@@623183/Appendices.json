{"hands_on_practices": [{"introduction": "高斯-牛顿方法的核心在于用线性模型逼近非线性问题。这个过程的关键就是雅可比矩阵（Jacobian matrix），它不仅是数学推导的工具，更深刻地揭示了数据对模型参数的敏感度。本练习将指导您从第一性原理出发，为一个简化的地球物理模型构建雅可比矩阵([@problem_id:3599237])，并学习如何解读其物理含义，从而将抽象的数学与具体的物理洞察联系起来。", "problem": "考虑一个双参数地球物理模型 $m=\\begin{pmatrix} m_1 \\\\ m_2 \\end{pmatrix}$，其中 $m_1$ 代表控制带限振幅响应的标量属性，$m_2$ 代表与各向异性相关的耦合参数。正演映射 $F:\\mathbb{R}^2\\to\\mathbb{R}^2$ 定义为 $F(m)=\\begin{pmatrix} \\sin(\\alpha m_1) \\\\ m_1 m_2 \\end{pmatrix}$，其中 $\\alpha>0$ 是一个已知的缩放常数，其单位的选择使得正弦函数的参数为无量纲。数据加权矩阵是单位矩阵 $W_d=I$。非线性最小二乘残差定义为 $\\phi(m)=\\tfrac{1}{2}\\|F(m)-d\\|_2^2$，其中 $d\\in\\mathbb{R}^2$ 是观测数据。\n\n从 $F(m)$ 的雅可比矩阵和残差的高斯-牛顿线性化的核心定义出发，显式地推导出以 $m_1$、$m_2$ 和 $\\alpha$ 表示的雅可比矩阵 $J(m)$。然后，解释 $J(m)$ 的每个元素如何反映数据对参数的物理敏感度，并阐释这些元素的大小和符号如何影响高斯-牛顿法向矩阵的条件数。你的推导应从第一性原理出发，而不直接引用 $F(m)$ 的雅可比矩阵或高斯-牛顿法的现成公式。\n\n给出 $J(m)$ 的显式闭式解析表达式作为最终答案。不需要进行数值取整。如果引入任何角度，必须以弧度为单位。由于最终答案是符号形式，最终表达式中不要包含单位。", "solution": "该问题要求针对给定的正演模型 $F(m)$ 推导雅可比矩阵 $J(m)$，并解释其元素的物理意义及其对高斯-牛顿法的影响。对问题陈述的验证确认了其具有科学依据、是适定的且客观的。我们可以开始求解。\n\n正演模型是一个函数 $F: \\mathbb{R}^2 \\to \\mathbb{R}^2$，它将模型参数向量 $m=\\begin{pmatrix} m_1 \\\\ m_2 \\end{pmatrix}$ 映射到数据向量。正演映射的分量为：\n$$\nF(m) = \\begin{pmatrix} F_1(m_1, m_2) \\\\ F_2(m_1, m_2) \\end{pmatrix} = \\begin{pmatrix} \\sin(\\alpha m_1) \\\\ m_1 m_2 \\end{pmatrix}\n$$\n其中 $\\alpha > 0$ 是一个已知常数。\n\n根据定义，向量值函数 $F(m)$ 的雅可比矩阵 $J(m)$ 是所有一阶偏导数组成的矩阵。对于一个从 $\\mathbb{R}^2$ 映射到 $\\mathbb{R}^2$ 的函数，它是一个 $2 \\times 2$ 矩阵：\n$$\nJ(m) = \\begin{pmatrix} \\frac{\\partial F_1}{\\partial m_1}  \\frac{\\partial F_1}{\\partial m_2} \\\\ \\frac{\\partial F_2}{\\partial m_1}  \\frac{\\partial F_2}{\\partial m_2} \\end{pmatrix}\n$$\n\n我们从第一性原理出发，利用偏微分法则计算 $J(m)$ 的每一个元素。\n\n第一个元素 $J_{11}$ 是 $F_1(m_1, m_2) = \\sin(\\alpha m_1)$ 对 $m_1$ 的偏导数。应用链式法则，我们得到：\n$$\nJ_{11} = \\frac{\\partial}{\\partial m_1} \\left( \\sin(\\alpha m_1) \\right) = \\cos(\\alpha m_1) \\cdot \\frac{\\partial}{\\partial m_1}(\\alpha m_1) = \\alpha \\cos(\\alpha m_1)\n$$\n\n第二个元素 $J_{12}$ 是 $F_1(m_1, m_2) = \\sin(\\alpha m_1)$ 对 $m_2$ 的偏导数。由于 $F_1$ 不依赖于 $m_2$，该导数为零：\n$$\nJ_{12} = \\frac{\\partial}{\\partial m_2} \\left( \\sin(\\alpha m_1) \\right) = 0\n$$\n\n第三个元素 $J_{21}$ 是 $F_2(m_1, m_2) = m_1 m_2$ 对 $m_1$ 的偏导数：\n$$\nJ_{21} = \\frac{\\partial}{\\partial m_1} \\left( m_1 m_2 \\right) = m_2\n$$\n\n第四个元素 $J_{22}$ 是 $F_2(m_1, m_2) = m_1 m_2$ 对 $m_2$ 的偏导数：\n$$\nJ_{22} = \\frac{\\partial}{\\partial m_2} \\left( m_1 m_2 \\right) = m_1\n$$\n\n将这些偏导数组合成矩阵，便得到雅可比矩阵 $J(m)$ 的显式形式：\n$$\nJ(m) = \\begin{pmatrix} \\alpha \\cos(\\alpha m_1)  0 \\\\ m_2  m_1 \\end{pmatrix}\n$$\n\n接下来，我们解释这些元素的物理意义及其对高斯-牛顿法向矩阵条件数的影响。每个元素 $J_{ij} = \\frac{\\partial F_i}{\\partial m_j}$ 代表第 $i$ 个数据分量对第 $j$ 个模型参数无穷小变化的敏感度。\n- $J_{11} = \\alpha \\cos(\\alpha m_1)$: 该项量化了第一个数据 $F_1 = \\sin(\\alpha m_1)$ 对参数 $m_1$ 变化的敏感度。敏感度是振荡的，在 $|\\cos(\\alpha m_1)| = 1$ 时（即当 $\\alpha m_1$ 是 $\\pi$ 的整数倍时）其幅度最大。在这些点，函数 $F_1$ 穿过零点，斜率最陡。相反，当 $\\cos(\\alpha m_1) = 0$ 时（即当 $\\alpha m_1 = (n + \\frac{1}{2})\\pi$ 对任意整数 $n$ 成立时），敏感度为零。这些点对应于正弦波的峰值和谷值，在这些点上，$m_1$ 的微小变化对 $F_1$ 产生的影响可以忽略不计。\n- $J_{12} = 0$: 这表示第一个数据 $F_1$ 对参数 $m_2$ 的变化完全不敏感。根据此模型，带限振幅响应的测量与各向异性参数完全解耦。\n- $J_{21} = m_2$: 这是第二个数据 $F_2 = m_1 m_2$ 对 $m_1$ 扰动的敏感度。该敏感度与耦合参数 $m_2$ 的值成正比。如果 $m_2$ 接近于零，第二个数据对 $m_1$ 变得不敏感，意味着耦合较弱。\n- $J_{22} = m_1$: 这是第二个数据 $F_2$ 对 $m_2$ 变化的敏感度。该敏感度与 $m_1$ 的值成正比。如果 $m_1$ 接近于零，第二个数据对各向异性参数 $m_2$ 不敏感。\n\n高斯-牛顿法用矩阵 $H_{GN} = J(m)^T J(m)$ 来近似残差函数 $\\phi(m)$ 的海森矩阵（因为数据加权矩阵 $W_d = I$）。这个法向矩阵的条件数对于反演的稳定性和收敛性至关重要。一个病态或奇异的 $H_{GN}$ 会导致不稳定的参数更新。\n法向矩阵为：\n$$\nH_{GN} = J^T J = \\begin{pmatrix} \\alpha \\cos(\\alpha m_1)  m_2 \\\\ 0  m_1 \\end{pmatrix} \\begin{pmatrix} \\alpha \\cos(\\alpha m_1)  0 \\\\ m_2  m_1 \\end{pmatrix} = \\begin{pmatrix} \\alpha^2 \\cos^2(\\alpha m_1) + m_2^2  m_1 m_2 \\\\ m_1 m_2  m_1^2 \\end{pmatrix}\n$$\n局部线性问题的适定性取决于 $H_{GN}$ 是否可逆。这等价于 $J(m)$ 的列向量是线性无关的。$H_{GN}$ 的行列式提供了对此的度量。对于方阵 $A$，使用性质 $\\det(A^T A) = (\\det A)^2$，我们可以计算：\n$$\n\\det(J) = (\\alpha \\cos(\\alpha m_1))(m_1) - (0)(m_2) = \\alpha m_1 \\cos(\\alpha m_1)\n$$\n因此，法向矩阵的行列式为：\n$$\n\\det(H_{GN}) = (\\det(J))^2 = \\alpha^2 m_1^2 \\cos^2(\\alpha m_1)\n$$\n如果 $\\det(H_{GN}) = 0$，法向矩阵 $H_{GN}$ 变为奇异矩阵，反演问题变为病态问题。这在两种情况下发生：\n1. $m_1 = 0$: 如果振幅参数 $m_1$ 为零，雅可比矩阵变为 $J = \\begin{pmatrix} \\alpha  0 \\\\ m_2  0 \\end{pmatrix}$，其列向量是线性相关的。从物理上讲，如果 $m_1=0$，那么对于任何 $m_2$ 的值，$F(m) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。数据中不包含关于 $m_2$ 的任何信息，使其恢复变得不可能。\n2. $\\cos(\\alpha m_1) = 0$: 这发生在 $\\alpha m_1_k = \\frac{\\pi}{2} + k\\pi$（对于任何整数 $k$）时。在这种情况下，雅可比矩阵为 $J = \\begin{pmatrix} 0  0 \\\\ m_2  m_1 \\end{pmatrix}$。第一行为零，使得矩阵秩亏。物理上，这对应于如前所述的第一个数据 $d_1$ 相对于 $m_1$ 的零敏感度点。在 $F_1$ 的这些极值点，$m_1$ 的微小扰动无法在第一个数据中“被看到”，导致信息丢失和系统病态。\n\n元素的大小也影响条件数。如果 $m_1$ 非常小，$\\det(H_{GN})$ 会变得非常小，导致病态。类似地，如果模型接近于 $\\cos(\\alpha m_1) \\approx 0$ 的点，问题也接近病态。雅可比矩阵元素的符号虽然不直接影响 $J^T J$ 的条件数（由于项的平方），但对于确定高斯-牛顿算法中参数更新步长 $\\delta m$ 的方向至关重要，因为更新依赖于乘积 $J^T (d - F(m))$。", "answer": "$$\n\\boxed{\nJ(m) = \\begin{pmatrix}\n\\alpha \\cos(\\alpha m_1)  0 \\\\\nm_2  m_1\n\\end{pmatrix}\n}\n$$", "id": "3599237"}, {"introduction": "在实际的逆问题中，“病态性”（ill-posedness）或“非唯一性”（non-uniqueness）是一个常见挑战，即不同的模型参数组合可能产生几乎相同的数据。本实践([@problem_id:3384262])将通过一个精心设计的数值实验，让您亲身体验标准高斯-牛顿法在存在“可识别性脊”（identifiability ridge）时的不稳定性。更重要的是，您将动手实现两种经典的正则化（regularization）技术来约束解空间并获得一个稳定且唯一的解，这是解决实际逆问题的关键一步。", "problem": "考虑一个双参数的非线性最小二乘反问题，其中正向映射仅依赖于单个可辨识组合。设参数向量为 $x = (x_1, x_2) \\in \\mathbb{R}^2$，正向模型 $f: \\mathbb{R}^2 \\to \\mathbb{R}^2$ 定义为\n$$\nf(x) = \\begin{bmatrix}\n\\alpha \\left( \\exp(x_1 + x_2) - 1 \\right) \\\\\n\\beta \\sin(x_1 + x_2)\n\\end{bmatrix},\n$$\n其中 $\\alpha$ 和 $\\beta$ 为已知的正常数。观测数据 $y \\in \\mathbb{R}^2$ 是通过选择一个真实值 $x^{\\star}$ 并令 $y = f(x^{\\star})$ 来综合生成的。残差为 $r(x) = f(x) - y$，代价函数为 $F(x) = \\tfrac{1}{2} \\| r(x) \\|_2^2$。该结构产生了一个可辨识性脊，因为 $f(x)$ 仅依赖于 $s = x_1 + x_2$，所以当 $s$ 与 $y$ 中编码的可辨识组合匹配时，$F(x)$ 在正交方向 $v = x_1 - x_2$ 上是平坦的。\n\n您的任务是：\n- 从线性化和最小二乘法的基本原理出发，推导用于最小化 $F(x)$ 的高斯-牛顿（GN）方法是如何得到的。具体来说，从残差 $r(x)$ 的定义开始，进行一阶泰勒线性化 $r(x + \\delta) \\approx r(x) + J(x)\\,\\delta$（其中 $J(x)$ 是 $r(x)$ 的雅可比矩阵），并说明 GN 步长是如何通过求解每次迭代中的线性化最小二乘子问题得到的。\n- 利用 $f(x)$ 的结构，论证为什么在 $s = x_1 + x_2$ 保持常数的方向上存在一个可辨识性脊，并描述其对近似高斯-牛顿海森矩阵 $J(x)^{\\top} J(x)$ 的影响。\n- 提出并实现通过二次先验或结构约束进行曲率注入以消除该脊。使用一个二次先验，通过选择 $L \\in \\mathbb{R}^{1 \\times 2}$ 和一个正则化权重 $\\lambda > 0$ 来惩罚不可辨识方向 $v = x_1 - x_2$，并推导由此产生的修正高斯-牛顿法向方程。\n\n实现一个程序，该程序：\n- 使用常数 $\\alpha = 1$、$\\beta = \\tfrac{1}{2}$ 和真实值 $x^{\\star} = (0.5, -0.3)$，使得 $y = f(x^{\\star})$。角度以弧度为单位。\n- 实现一个高斯-牛顿求解器，在没有正则化的情况下最小化 $F(x)$，针对以下三个初始猜测值：\n  1. $x^{(0)}_{\\mathrm{A}} = (1.6, -1.0)$，\n  2. $x^{(0)}_{\\mathrm{B}} = (0.7, -0.5)$，\n  3. $x^{(0)}_{\\mathrm{C}} = (-0.5, 0.7)$。\n  对于每次运行，报告收敛后 $v = x_1 - x_2$ 的最终值。这证明了沿着可辨识性脊的漂移（即 $F(x)$ 对 $v$ 的有效不敏感性）。\n- 实现一个带有二次先验（Tikhonov型曲率注入）的高斯-牛顿求解器，通过最小化以下函数来惩罚不可辨识方向 $v$：\n$$\n\\Phi(x) = \\tfrac{1}{2} \\| r(x) \\|_2^2 + \\tfrac{\\lambda}{2} \\| L(x - x_{\\mathrm{ref}}) \\|_2^2,\n$$\n其中 $L = \\begin{bmatrix} 1  -1 \\end{bmatrix}$，$x_{\\mathrm{ref}} = (0,0)$，且 $\\lambda = 1$。对于与上述相同的三个初始猜测值，运行正则化的高斯-牛顿求解器，并报告收敛后 $v = x_1 - x_2$ 的最终值。这演示了如何通过先验进行曲率注入，通过在脊上选择一个唯一解来消除漂移。\n- 通过拟合一个轻微扰动的正向模型，实现一个额外的边缘情况结构测试：\n$$\nf_{\\gamma}(x) = \\begin{bmatrix}\n\\alpha \\left( \\exp(x_1 + x_2) - 1 \\right) \\\\\n\\beta \\sin(x_1 + x_2) + \\gamma (x_1 - x_2)\n\\end{bmatrix},\n$$\n其中 $\\gamma = 10^{-3}$，数据 $y$ 与上面生成的数据相同（来自 $\\gamma = 0$ 的情况）。这模拟了正向映射中的一种结构约束，该约束在先前平坦的方向上注入了曲率。对于两个初始猜测值 $x^{(0)}_{\\mathrm{B}}$ 和 $x^{(0)}_{\\mathrm{C}}$，运行非正则化的高斯-牛顿求解器，并报告 $v = x_1 - x_2$ 的最终值。\n\n数值和算法要求：\n- 每次迭代的高斯-牛顿子问题必须基于线性化推导，并作为线性最小二乘问题求解。您不得使用绕过“线性化加最小二乘法”原理的闭式解。\n- 如有需要，使用简单的回溯线搜索以确保目标函数的单调递减。当步长范数低于一个小的容差或达到最大迭代次数时停止。\n- 此问题中没有物理单位。\n- 测试套件：\n  - 情况1：非正则化高斯-牛顿法，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{A}}$ 开始；输出最终的 $v$。\n  - 情况2：非正则化高斯-牛顿法，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{B}}$ 开始；输出最终的 $v$。\n  - 情况3：非正则化高斯-牛顿法，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{C}}$ 开始；输出最终的 $v$。\n  - 情况4：带先验的正则化高斯-牛顿法，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{A}}$ 开始；输出最终的 $v$。\n  - 情况5：带先验的正则化高斯-牛顿法，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{B}}$ 开始；输出最终的 $v$。\n  - 情况6：带先验的正则化高斯-牛顿法，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{C}}$ 开始；输出最终的 $v$。\n  - 情况7：使用扰动正向模型 $f_{\\gamma}$ 的非正则化高斯-牛顿法，$\\gamma = 10^{-3}$，从 $x^{(0)}_{\\mathrm{B}}$ 开始；输出最终的 $v$。\n  - 情况8：使用扰动正向模型 $f_{\\gamma}$ 的非正则化高斯-牛顿法，$\\gamma = 10^{-3}$，从 $x^{(0)}_{\\mathrm{C}}$ 开始；输出最终的 $v$。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的结果按上述情况的精确顺序排列，例如 $[v_1,v_2,v_3,v_4,v_5,v_6,v_7,v_8]$。将每个 $v$ 表示为浮点数。\n\n此问题的最终答案必须是一个完整的、可运行的程序，该程序实现所述的求解器并打印所需的单行输出。不需要用户输入。所有三角函数求值均使用弧度。", "solution": "该问题要求推导并实现高斯-牛顿方法，以解决一个具有结构性不可辨识性特征的非线性最小二乘问题，并演示正则化如何解决此问题。\n\n### 第1部分：高斯-牛顿方法的推导\n\n目标是找到一个参数向量 $x$，以最小化由以下代价函数给出的残差平方和：\n$$\nF(x) = \\frac{1}{2} \\|r(x)\\|_2^2 = \\frac{1}{2} (f(x) - y)^T (f(x) - y)\n$$\n高斯-牛顿法是一种迭代算法，在每次迭代 $k$ 中，它使用当前估计值 $x^{(k)}$ 周围的线性函数来近似非线性残差函数 $r(x)$。设建议的更新量为 $\\delta$，使得下一个估计值为 $x^{(k+1)} = x^{(k)} + \\delta$。残差向量 $r(x)$ 在 $x^{(k)}$ 周围的一阶泰勒展开为：\n$$\nr(x^{(k)} + \\delta) \\approx r(x^{(k)}) + J(x^{(k)}) \\delta\n$$\n其中 $J(x^{(k)})$ 是在 $x^{(k)}$ 处求值的残差函数 $r(x)$ 的雅可比矩阵。由于 $r(x) = f(x) - y$ 且 $y$ 是一个常数向量，因此 $r(x)$ 的雅可比矩阵与正向模型 $f(x)$ 的雅可比矩阵相同。\n\n将此线性近似代入代价函数 $F(x)$，我们得到 $F(x)$ 在 $x^{(k)}$ 周围的二次模型：\n$$\nF(x^{(k)} + \\delta) \\approx \\frac{1}{2} \\|r(x^{(k)}) + J(x^{(k)}) \\delta\\|_2^2\n$$\n高斯-牛顿方法通过在每次迭代中最小化这个二次近似来确定步长 $\\delta$。这是一个线性最小二乘问题：\n$$\n\\delta^{(k)} = \\arg \\min_{\\delta} \\frac{1}{2} \\| J(x^{(k)}) \\delta - (-r(x^{(k)})) \\|_2^2\n$$\n这个标准线性最小二乘问题的解由法向方程给出：\n$$\n(J(x^{(k)})^T J(x^{(k)})) \\delta^{(k)} = -J(x^{(k)})^T r(x^{(k)})\n$$\n矩阵 $H_{GN}(x^{(k)}) = J(x^{(k)})^T J(x^{(k)})$ 是代价函数 $F(x)$ 的海森矩阵的高斯-牛顿近似。因此，迭代更新由 $x^{(k+1)} = x^{(k)} + \\delta^{(k)}$ 给出，其中 $\\delta^{(k)}$ 是法向方程的解。通常采用线搜索来确定步长 $\\eta^{(k)}$，使得 $x^{(k+1)} = x^{(k)} + \\eta^{(k)} \\delta^{(k)}$ 能确保代价函数 $F(x)$ 的值减小。\n\n### 第2部分：可辨识性脊的分析\n\n正向模型由以下公式给出：\n$$\nf(x) = \\begin{bmatrix}\n\\alpha \\left( \\exp(x_1 + x_2) - 1 \\right) \\\\\n\\beta \\sin(x_1 + x_2)\n\\end{bmatrix}\n$$\n该模型仅依赖于和 $s = x_1 + x_2$。因此，代价函数 $F(x) = \\frac{1}{2}\\|f(x_1, x_2) - y\\|_2^2$ 在任何 $x_1 + x_2$ 为常数的直线上都将是常数。这就产生了一个最小代价的“脊”或谷。在保持 $s$ 不变的方向上扰动 $x$ 不会改变 $f(x)$ 的值，因此也不会改变代价函数的值。这样一个方向由任何与 $s(x) = x_1 + x_2$ 的梯度 $\\nabla s = [1, 1]^T$ 正交的向量给出。这个方向的一个基是向量 $u = [1, -1]^T$。这个方向对应于在保持 $s$ 固定的同时改变 $v = x_1 - x_2$。\n\n这种结构性不可辨识性体现在高斯-牛顿海森矩阵中。$f(x)$ 的雅可比矩阵使用链式法则计算：$J(x) = \\frac{\\partial f}{\\partial s} \\frac{\\partial s}{\\partial x}$。\n$$\n\\frac{\\partial f}{\\partial s} = \\begin{bmatrix} \\alpha \\exp(s) \\\\ \\beta \\cos(s) \\end{bmatrix}, \\quad \\frac{\\partial s}{\\partial x} = \\begin{bmatrix} 1  1 \\end{bmatrix}\n$$\n因此，雅可比矩阵为：\n$$\nJ(x) = \\begin{bmatrix} \\alpha \\exp(x_1+x_2) \\\\ \\beta \\cos(x_1+x_2) \\end{bmatrix} \\begin{bmatrix} 1  1 \\end{bmatrix} = \\begin{bmatrix} \\alpha e^{x_1+x_2}  \\alpha e^{x_1+x_2} \\\\ \\beta \\cos(x_1+x_2)  \\beta \\cos(x_1+x_2) \\end{bmatrix}\n$$\n$J(x)$ 的两列是相同的，这意味着 $J(x)$ 的秩为1。它的零空间由向量 $u = [1, -1]^T$ 张成，因为 $J(x)u = 0$。\n\n高斯-牛顿海森矩阵是 $H_{GN} = J(x)^T J(x)$。对于 $J(x)$ 零空间中的任何向量 $u$：\n$$\nH_{GN} u = J(x)^T J(x) u = J(x)^T (0) = 0\n$$\n这表明 $H_{GN}$ 有一个零特征值，对应的特征向量为 $u = [1, -1]^T$。该海森矩阵是奇异的。结果，法向方程 $(J^T J) \\delta = -J^T r$ 对于步长 $\\delta$ 没有唯一解。$\\delta$ 在零空间方向上的分量是不确定的，这导致在优化过程中会沿着可辨识性脊发生漂移。\n\n### 第3部分：曲率注入\n\n为了获得唯一解，我们必须引入信息来区分可辨识性脊上的点。这可以通过在缺失方向上为目标函数增加曲率来实现。\n\n**方法1：二次先验（Tikhonov正则化）**\n\n我们修改代价函数以包含一个惩罚项：\n$$\n\\Phi(x) = \\frac{1}{2} \\| r(x) \\|_2^2 + \\frac{\\lambda}{2} \\| L(x - x_{\\mathrm{ref}}) \\|_2^2\n$$\n其中 $\\lambda > 0$ 是正则化权重，$L \\in \\mathbb{R}^{1 \\times 2}$ 是一个惩罚算子，$x_{\\mathrm{ref}}$ 是一个参考状态。当 $L = [1, -1]$ 和 $x_{\\mathrm{ref}} = 0$ 时，惩罚项变为 $\\frac{\\lambda}{2} (x_1 - x_2)^2$。该项惩罚那些 $v = x_1 - x_2$ 远离0的解，从而有效地在脊上选择最接近直线 $x_1 = x_2$ 的解。\n\n为了推导修正的高斯-牛顿步长，我们将 $\\Phi(x)$ 中的两项在 $x^{(k)}$ 周围线性化：\n$$\n\\Phi(x^{(k)} + \\delta) \\approx \\frac{1}{2} \\|r(x^{(k)}) + J(x^{(k)}) \\delta\\|_2^2 + \\frac{\\lambda}{2} \\|L(x^{(k)} - x_{\\mathrm{ref}}) + L \\delta\\|_2^2\n$$\n这可以通过定义一个增广残差和增广雅可比矩阵，表述为单个线性最小二乘问题：\n$$\n\\tilde{r}(x) = \\begin{bmatrix} r(x) \\\\ \\sqrt{\\lambda} L(x - x_{\\mathrm{ref}}) \\end{bmatrix}, \\quad \\tilde{J}(x) = \\begin{bmatrix} J(x) \\\\ \\sqrt{\\lambda} L \\end{bmatrix}\n$$\n步长 $\\delta^{(k)}$ 最小化 $\\frac{1}{2} \\|\\tilde{r}(x^{(k)}) + \\tilde{J}(x^{(k)}) \\delta\\|_2^2$。相应的法向方程是 $(\\tilde{J}^T \\tilde{J}) \\delta = -\\tilde{J}^T \\tilde{r}$。展开此式可得：\n$$\n(J(x^{(k)})^T J(x^{(k)}) + \\lambda L^T L) \\delta^{(k)} = -(J(x^{(k)})^T r(x^{(k)}) + \\lambda L^T L(x^{(k)} - x_{\\mathrm{ref}}))\n$$\n新的近似海森矩阵是 $H_{GN} + \\lambda L^T L$。矩阵 $L^T L = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} [1, -1] = \\begin{bmatrix} 1  -1 \\\\ -1  1 \\end{bmatrix}$ 的零空间由 $[1, 1]^T$ 张成，它与 $H_{GN}$ 的零空间正交。因此，这两个矩阵的和是正定的且可逆的，从而产生一个唯一的、定义明确的步长 $\\delta^{(k)}$，解决了不可辨识性问题。\n\n**方法2：正向模型中的结构约束**\n\n另一种方法是修改正向模型以打破对称性，例如：\n$$\nf_{\\gamma}(x) = \\begin{bmatrix}\n\\alpha \\left( \\exp(x_1 + x_2) - 1 \\right) \\\\\n\\beta \\sin(x_1 + x_2) + \\gamma (x_1 - x_2)\n\\end{bmatrix}\n$$\n对于一个小的 $\\gamma \\neq 0$，模型现在弱依赖于 $v = x_1 - x_2$。新的雅可比矩阵是：\n$$\nJ_{\\gamma}(x) = \\begin{bmatrix} \\alpha e^{x_1+x_2}  \\alpha e^{x_1+x_2} \\\\ \\beta \\cos(x_1+x_2) + \\gamma  \\beta \\cos(x_1+x_2) - \\gamma \\end{bmatrix}\n$$\n$J_{\\gamma}(x)$ 的列现在是线性无关的。向量 $u = [1, -1]^T$ 不再位于零空间中：\n$$\nJ_{\\gamma}(x) u = \\begin{bmatrix} 0 \\\\ 2\\gamma \\end{bmatrix} \\neq 0\n$$\n由于 $J_{\\gamma}(x)$ 是满秩的，高斯-牛顿海森矩阵 $J_{\\gamma}(x)^T J_{\\gamma}(x)$ 是非奇异的，标准的（非正则化的）高斯-牛顿方法将收敛到一个唯一的最小值。这表明，即使对先前不可辨识的参数组合有轻微的结构依赖性，也足以使问题正则化。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a nonlinear least-squares problem with an identifiability ridge\n    using Gauss-Newton, and demonstrates regularization techniques.\n    \"\"\"\n    # Problem Constants\n    alpha = 1.0\n    beta = 0.5\n    x_star = np.array([0.5, -0.3])\n    \n    # Generate synthetic data y = f(x_star)\n    s_star = x_star[0] + x_star[1]\n    y_obs = np.array([\n        alpha * (np.exp(s_star) - 1.0),\n        beta * np.sin(s_star)\n    ])\n\n    # Initial guesses\n    x0_A = np.array([1.6, -1.0])\n    x0_B = np.array([0.7, -0.5])\n    x0_C = np.array([-0.5, 0.7])\n    \n    # Regularization parameters\n    lmbda_reg = 1.0\n    L_reg = np.array([[1.0, -1.0]])\n    xref_reg = np.array([0.0, 0.0])\n    \n    # Structural perturbation parameter\n    gamma_pert = 1e-3\n\n    # Algorithmic parameters\n    max_iter = 100\n    tol = 1e-8\n\n    def gauss_newton_solver(x_init, gamma, lmbda, L, xref):\n        \"\"\"\n        Generic Gauss-Newton solver for the problem.\n        - gamma: structural perturbation parameter\n        - lmbda: Tikhonov regularization weight\n        - L, xref: Tikhonov operator and reference\n        \"\"\"\n        x = x_init.copy()\n        \n        for _ in range(max_iter):\n            s = x[0] + x[1]\n            v = x[0] - x[1]\n\n            # Forward model f(x)\n            f_val = np.array([\n                alpha * (np.exp(s) - 1.0),\n                beta * np.sin(s) + gamma * v\n            ])\n            \n            # Residual r(x)\n            r = f_val - y_obs\n\n            # Jacobian J(x)\n            J = np.array([\n                [alpha * np.exp(s), alpha * np.exp(s)],\n                [beta * np.cos(s) + gamma, beta * np.cos(s) - gamma]\n            ])\n\n            if lmbda == 0:\n                # Standard or structurally-regularized GN\n                # Solve the linear least squares problem: min ||J*delta - (-r)||^2\n                delta, _, _, _ = np.linalg.lstsq(J, -r, rcond=None)\n            else:\n                # Tikhonov-regularized GN (as augmented least squares)\n                # min || [ J_aug * delta - (-r_aug) ] ||^2\n                r_prior = np.sqrt(lmbda) * L @ (x - xref)\n                r_aug = np.concatenate([r, r_prior])\n                J_aug = np.vstack([J, np.sqrt(lmbda) * L])\n                delta, _, _, _ = np.linalg.lstsq(J_aug, -r_aug, rcond=None)\n\n            if np.linalg.norm(delta)  tol:\n                break\n                \n            # Backtracking line search\n            step_size = 1.0\n            def cost_func(xk):\n                sk = xk[0] + xk[1]\n                vk = xk[0] - xk[1]\n                fk = np.array([\n                    alpha * (np.exp(sk) - 1.0),\n                    beta * np.sin(sk) + gamma * vk\n                ])\n                res_cost = 0.5 * np.linalg.norm(fk - y_obs)**2\n                if lmbda > 0:\n                    reg_cost = (lmbda / 2.0) * np.linalg.norm(L @ (xk - xref))**2\n                    return res_cost + reg_cost\n                return res_cost\n\n            cost_current = cost_func(x)\n            while step_size > 1e-8:\n                x_new = x + step_size * delta\n                if cost_func(x_new)  cost_current:\n                    x = x_new\n                    break\n                step_size /= 2.0\n            else: # Line search failed to find a decrease\n                break\n        \n        return x[0] - x[1] # Return the final v\n\n    # Test Cases\n    results = []\n\n    # Cases 1-3: Unregularized GN (gamma=0, lambda=0)\n    v1 = gauss_newton_solver(x0_A, gamma=0.0, lmbda=0.0, L=L_reg, xref=xref_reg)\n    results.append(v1)\n    \n    v2 = gauss_newton_solver(x0_B, gamma=0.0, lmbda=0.0, L=L_reg, xref=xref_reg)\n    results.append(v2)\n    \n    v3 = gauss_newton_solver(x0_C, gamma=0.0, lmbda=0.0, L=L_reg, xref=xref_reg)\n    results.append(v3)\n    \n    # Cases 4-6: Regularized GN with prior (gamma=0, lambda=1)\n    v4 = gauss_newton_solver(x0_A, gamma=0.0, lmbda=lmbda_reg, L=L_reg, xref=xref_reg)\n    results.append(v4)\n    \n    v5 = gauss_newton_solver(x0_B, gamma=0.0, lmbda=lmbda_reg, L=L_reg, xref=xref_reg)\n    results.append(v5)\n    \n    v6 = gauss_newton_solver(x0_C, gamma=0.0, lmbda=lmbda_reg, L=L_reg, xref=xref_reg)\n    results.append(v6)\n\n    # Cases 7-8: Unregularized GN with perturbed model (gamma=1e-3, lambda=0)\n    v7 = gauss_newton_solver(x0_B, gamma=gamma_pert, lmbda=0.0, L=L_reg, xref=xref_reg)\n    results.append(v7)\n    \n    v8 = gauss_newton_solver(x0_C, gamma=gamma_pert, lmbda=0.0, L=L_reg, xref=xref_reg)\n    results.append(v8)\n\n    # Final output format\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "3384262"}, {"introduction": "局部优化算法（如高斯-牛顿法）的一个主要弱点是容易陷入代价函数的局部极小值，而错失全局最优解，这一现象在波形反演中被称为“周波跳跃”（cycle skipping）。本练习([@problem_id:3599323])将带您直面这个棘手的难题，通过一个一维地震波形反演的例子，展示传统最小二乘目标函数为何会失效。随后，您将探索并实现一种基于信号包络（envelope）的替代目标函数，通过平滑代价函数的地形来有效规避周波跳跃，这是解决高度非线性问题的一种高级策略。", "problem": "您需要实现一个完整的、可运行的程序，该程序构建一个一维波形反演玩具模型。在此模型中，正演模拟算子生成一个作为时移 Ricker 子波的单反射脉冲。反演目标是单个未知参数，即恒定声速，而数据是在地表测量的合成地震图。目标是检验高斯-牛顿法在标准的基于振幅的最小二乘残差和另一种基于包络的失配函数下的行为，前者用以说明周波跳跃现象，后者用以展示高斯-牛顿步长的变化。\n\n使用以下基本设置和定义：\n\n- 观测数据是在深度为 $z$ 的单个平坦地下反射层上采集的，介质为速度未知（模型变量为 $m$）的恒速介质。双程旅行时为 $ \\tau(m) = \\dfrac{2 z}{m} $。\n- 震源子波是 Ricker 子波 $ s(t) = \\left(1 - 2 a t^2\\right) \\exp\\left(- a t^2\\right) $，其中 $ a = \\left(\\pi f_0\\right)^2 $，$ f_0 $ 是中心频率。\n- 无噪声正演模型是合成地震图 $ d\\!\\left(t; m\\right) = s\\!\\left(t - \\tau(m)\\right) $。\n- 基于振幅的最小二乘目标函数是 $ \\Phi_{\\mathrm{wf}}(m) = \\dfrac{1}{2} \\left\\| r_{\\mathrm{wf}}(m) \\right\\|_2^2 $，其残差为 $ r_{\\mathrm{wf}}(t; m) = d_{\\mathrm{obs}}(t) - d\\!\\left(t; m\\right) $。\n- 基于包络的替代失配函数使用振幅包络 $ e\\!\\left(t; m\\right) = \\sqrt{ d\\!\\left(t; m\\right)^2 + \\left( \\mathcal{H}\\{ d\\!\\left(t; m\\right) \\} \\right)^2 } $，其中 $ \\mathcal{H}\\{\\cdot\\} $ 表示希尔伯特变换，目标函数为 $ \\Phi_{\\mathrm{env}}(m) = \\dfrac{1}{2} \\left\\| r_{\\mathrm{env}}(m) \\right\\|_2^2 $，其残差为 $ r_{\\mathrm{env}}(t; m) = e_{\\mathrm{obs}}(t) - e\\!\\left(t; m\\right) $。\n\n从第一性原理出发，推导每种目标函数的高斯-牛顿步长：\n\n- 从非线性最小二乘目标函数的定义 $ \\Phi(m) = \\dfrac{1}{2} \\left\\| r(m) \\right\\|_2^2 $ 和高斯-牛顿近似开始，该近似用 $ J(m)^\\top J(m) $ 替代精确的海森矩阵，其中 $ J(m) $ 是残差关于 $ m $ 的雅可比矩阵。\n- 对于波形残差，使用链式法则和 Ricker 子波的导数，推导雅可比矩阵的元素 $ J_{\\mathrm{wf}}(t; m) = \\dfrac{\\partial}{\\partial m} d\\!\\left(t; m\\right) $。Ricker 子波的导数为 $ s'(t) = \\exp\\!\\left(- a t^2\\right) \\, t \\left( - 6 a + 4 a^2 t^2 \\right) $。请用 $ z $、$ m $ 和 $ s'\\!\\big(t - \\tau(m)\\big) $ 明确表示 $ J_{\\mathrm{wf}}(t; m) $。\n- 对于包络残差，利用 $ \\mathcal{H}\\{\\cdot\\} $ 是线性算子这一事实，通过链式法则推导雅可比矩阵的元素 $ J_{\\mathrm{env}}(t; m) = \\dfrac{\\partial}{\\partial m} e\\!\\left(t; m\\right) $：$ e(t; m) = \\sqrt{x(t; m)^2 + y(t; m)^2} $，其中 $ x = d(t; m) $ 且 $ y = \\mathcal{H}\\{ d(t; m) \\} $。证明 $ \\dfrac{\\partial e}{\\partial m}(t; m) = \\dfrac{ x \\, \\dfrac{\\partial x}{\\partial m} + y \\, \\dfrac{\\partial y}{\\partial m} }{ e } $ 并将 $ \\dfrac{\\partial y}{\\partial m} $ 与 $ \\mathcal{H}\\!\\left\\{ \\dfrac{\\partial x}{\\partial m} \\right\\} $ 联系起来。\n\n然后，为每个目标函数编写单个参数 $ m $ 的高斯-牛顿更新公式：\n$$\n\\Delta m_{\\bullet} = \\dfrac{ \\sum_t J_{\\bullet}(t; m_0) \\, r_{\\bullet}(t; m_0) }{ \\sum_t J_{\\bullet}(t; m_0)^2 },\n$$\n其中 $ \\bullet \\in \\{ \\mathrm{wf}, \\mathrm{env} \\} $，$ m_0 $ 是当前模型迭代值。解释为什么当 $ m_0 $ 与真实值相距足够远时，基于波形的残差 $ r_{\\mathrm{wf}} $ 会表现出周波跳跃，这表现为多周期的相位失配，导致 $ J_{\\mathrm{wf}}^\\top r_{\\mathrm{wf}} $ 的符号错误或量级过小，从而产生一个糟糕的 $ \\Delta m_{\\mathrm{wf}} $。将此与基于包络的残差进行对比，后者抑制了振荡相位效应，通常能提供一个更稳健的、朝向真实解的步长 $ \\Delta m_{\\mathrm{env}} $。\n\n物理和数值参数：\n\n- 深度 $ z = 1000\\,\\mathrm{m} $。\n- 真实速度 $ m_\\star = 2000\\,\\mathrm{m/s} $。\n- 中心频率 $ f_0 = 10\\,\\mathrm{Hz} $。\n- 时间采样间隔 $ \\Delta t = 0.001\\,\\mathrm{s} $。\n- 记录长度 $ T = 2.5\\,\\mathrm{s} $。\n\n角度，包括任何可能隐含在解析信号中的相位，都应以弧度为单位。\n\n初始模型速度测试集 $ m_0 $：\n\n- 情况 1（完美匹配）：$ m_0 = 2000\\,\\mathrm{m/s} $。\n- 情况 2（接近，低于半个周期的失配）：$ m_0 = 2100\\,\\mathrm{m/s} $。\n- 情况 3（中度周波跳跃，约一个周期的失配）：$ m_0 = 1800\\,\\mathrm{m/s} $。\n- 情况 4（严重周波跳跃，多个周期的失配）：$ m_0 = 1500\\,\\mathrm{m/s} $。\n\n您的程序必须：\n\n- 使用 $ m_\\star $ 构建 $ d_{\\mathrm{obs}}(t) $，并对测试集中的每个 $ m_0 $，根据上述高斯-牛顿公式计算 $ \\Delta m_{\\mathrm{wf}} $ 和 $ \\Delta m_{\\mathrm{env}} $。\n- 使用希尔伯特变换计算包络和包络的雅可比矩阵，并采用适当的数值保护措施以避免当包络振幅极小时发生除以零的错误。\n- 将每个 $ \\Delta m $ 以米/秒（$\\mathrm{m/s}$）为单位表示，并四舍五入到 $6$ 位小数。\n\n最终输出格式：\n\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表。此列表的每个元素对应一个测试用例，并且本身必须是一个包含该用例的高斯-牛顿步长 $ \\Delta m_{\\mathrm{wf}} $ 和 $ \\Delta m_{\\mathrm{env}} $（按此顺序）的双元素列表。例如，输出应类似于 $ \\left[ [\\Delta m_{\\mathrm{wf}}^{(1)}, \\Delta m_{\\mathrm{env}}^{(1)}], \\ldots, [\\Delta m_{\\mathrm{wf}}^{(4)}, \\Delta m_{\\mathrm{env}}^{(4)}] \\right] $，其中每个数字都以 $6$ 位小数打印，单位默认为 $\\mathrm{m/s}$。", "solution": "用户提供了一个有效的问题陈述。任务是分析用于一维波形反演问题的高斯-牛顿优化方法，比较一个标准的基于波形的目标函数和一个基于包络的替代函数。分析的重点是周波跳跃现象。解决方案要求为每个目标函数推导高斯-牛顿步长，然后实现一个数值模拟来为几个初始模型计算这些步长。\n\n首先，我们建立理论框架。目标是找到模型参数 $m$（声速），以最小化形式为 $\\Phi(m) = \\frac{1}{2} \\|r(m)\\|_2^2$ 的非线性最小二乘目标函数，其中 $r(m)$ 是观测数据与预测数据之间的残差向量。对于离散时间序列，这表示为 $\\Phi(m) = \\frac{1}{2} \\sum_t [r(t; m)]^2$。\n\n高斯-牛顿法用 $J(m)^\\top J(m)$ 来近似目标函数的海森矩阵 $\\nabla^2 \\Phi(m)$，其中 $J(m)$ 是残差向量 $r(m)$ 关于模型参数 $m$ 的雅可比矩阵。雅可比矩阵的元素是 $J(t; m) = \\frac{\\partial r(t; m)}{\\partial m}$。模型参数的更新步长通过求解正规方程 $J(m)^\\top J(m) \\Delta m = -J(m)^\\top r(m)$ 得到。在我们的例子中，由于只有一个参数 $m$，这简化为一个标量方程。问题将残差定义为 $r(t;m) = d_{\\mathrm{obs}}(t) - d(t;m)$，所以其雅可比矩阵为 $J(t;m) = \\frac{\\partial r}{\\partial m} = -\\frac{\\partial d}{\\partial m}$。目标函数的梯度是 $\\nabla \\Phi(m) = \\sum_t r(t;m) \\frac{\\partial r(t;m)}{\\partial m} = - \\sum_t r(t;m) \\frac{\\partial d(t;m)}{\\partial m}$。标准的高斯-牛顿更新是 $m_{k+1} = m_k - (\\nabla^2 \\Phi)^{-1} \\nabla \\Phi$。步长是 $\\delta m = - (J^\\top J)^{-1} J^\\top r$。\n问题陈述中提供的步长公式 $\\Delta m$ 省略了负号：\n$$\n\\Delta m = \\left( \\sum_t J(t; m_0)^2 \\right)^{-1} \\left( \\sum_t J(t; m_0) r(t; m_0) \\right)\n$$\n这意味着如果 $J = \\frac{\\partial d}{\\partial m}$，更新规则的形式是 $m_{k+1} = m_k - \\Delta m$；或者如果 $J = -\\frac{\\partial d}{\\partial m}$，更新规则的形式是 $m_{k+1} = m_k + \\Delta m$。我们将遵循所提供的公式，并注意到校正方向取决于残差与数据敏感度之间的局部相关性。\n\n合成数据的正演模型是一个时移的 Ricker 子波：$d(t; m) = s(t - \\tau(m))$，其中 $s(t) = (1 - 2 a t^2) \\exp(-a t^2)$，$a = (\\pi f_0)^2$，双程旅行时为 $\\tau(m) = \\frac{2z}{m}$。\n\n**1. 基于波形的目标函数 $\\Phi_{\\mathrm{wf}}(m)$**\n\n残差是 $r_{\\mathrm{wf}}(t; m) = d_{\\mathrm{obs}}(t) - d(t; m)$。该残差关于 $m$ 的雅可比矩阵是 $J_{\\mathrm{wf}}(t; m) = \\frac{\\partial r_{\\mathrm{wf}}}{\\partial m} = -\\frac{\\partial d(t; m)}{\\partial m}$。\n使用链式法则：\n$$\n\\frac{\\partial d(t; m)}{\\partial m} = \\frac{\\partial}{\\partial m} s(t - \\tau(m)) = s'(t - \\tau(m)) \\cdot \\left( -\\frac{\\partial \\tau(m)}{\\partial m} \\right)\n$$\n旅行时的导数是 $\\frac{\\partial \\tau(m)}{\\partial m} = \\frac{\\partial}{\\partial m}\\left(\\frac{2z}{m}\\right) = -\\frac{2z}{m^2}$。\n代入此式，我们得到：\n$$\n\\frac{\\partial d(t; m)}{\\partial m} = s'(t - \\tau(m)) \\cdot \\left( - \\left( -\\frac{2z}{m^2} \\right) \\right) = \\frac{2z}{m^2} s'(t - \\tau(m))\n$$\n因此，残差的雅可比矩阵是 $J_{\\mathrm{wf}}(t; m) = -\\frac{2z}{m^2} s'(t - \\tau(m))$。问题提供的步长公式使用的 $J$ 未指定是针对残差还是正演模型。为确保步长是修正性的，让我们分析梯度。$\\nabla\\Phi = J_{\\mathrm{wf}}^\\top r_{\\mathrm{wf}}$。如果我们使用问题中的公式计算 $\\Delta m$，它代表了沿梯度的步长。更新 $m_{k+1} = m_k - \\lambda \\Delta m$ 将是梯度下降法。我们将根据提供的公式计算 $\\Delta m$，并将雅可比矩阵定义为*正演模型*的敏感度，即 $J(t;m) = \\frac{\\partial d(t;m)}{\\partial m}$。\n$$\nJ_{\\mathrm{wf}}(t; m) = \\frac{2z}{m^2} s'(t - \\tau(m))\n$$\n其中 Ricker 子波的导数由 $s'(t) = \\exp(- a t^2) \\, t \\, (-6 a + 4 a^2 t^2)$ 给出。\n高斯-牛顿步长则为：\n$$\n\\Delta m_{\\mathrm{wf}} = \\frac{\\sum_t J_{\\mathrm{wf}}(t; m_0) \\, r_{\\mathrm{wf}}(t; m_0)}{\\sum_t J_{\\mathrm{wf}}(t; m_0)^2}\n$$\n\n**2. 基于包络的目标函数 $\\Phi_{\\mathrm{env}}(m)$**\n\n残差是 $r_{\\mathrm{env}}(t; m) = e_{\\mathrm{obs}}(t) - e(t; m)$，其中 $e(t; m)$ 是信号 $d(t; m)$ 的振幅包络，定义为 $e(t; m) = |d(t;m) + i \\mathcal{H}\\{d(t;m)\\}|$，$\\mathcal{H}\\{\\cdot\\}$ 表示希尔伯特变换。\n令 $x(t; m) = d(t; m)$ 和 $y(t; m) = \\mathcal{H}\\{d(t; m)\\}$。那么 $e(t; m) = \\sqrt{x^2 + y^2}$。正演模型 $e(t; m)$ 的雅可比矩阵是：\n$$\nJ_{\\mathrm{env}}(t; m) = \\frac{\\partial e}{\\partial m} = \\frac{1}{2\\sqrt{x^2+y^2}} \\left( 2x \\frac{\\partial x}{\\partial m} + 2y \\frac{\\partial y}{\\partial m} \\right) = \\frac{x \\frac{\\partial x}{\\partial m} + y \\frac{\\partial y}{\\partial m}}{e}\n$$\n我们有 $\\frac{\\partial x}{\\partial m} = \\frac{\\partial d}{\\partial m} = J_{\\mathrm{wf}}(t; m)$。因为希尔伯特变换是线性算子，其应用与对 $m$ 的微分运算可交换：\n$$\n\\frac{\\partial y}{\\partial m} = \\frac{\\partial}{\\partial m} \\mathcal{H}\\{d(t; m)\\} = \\mathcal{H}\\left\\{\\frac{\\partial d(t; m)}{\\partial m}\\right\\} = \\mathcal{H}\\{J_{\\mathrm{wf}}(t; m)\\}\n$$\n代入这些结果，我们得到包络雅可比矩阵的显式公式：\n$$\nJ_{\\mathrm{env}}(t; m) = \\frac{d(t; m) J_{\\mathrm{wf}}(t; m) + \\mathcal{H}\\{d(t; m)\\} \\mathcal{H}\\{J_{\\mathrm{wf}}(t; m)\\}}{e(t; m)}\n$$\n因此，包络目标函数的高斯-牛顿步长是：\n$$\n\\Delta m_{\\mathrm{env}} = \\frac{\\sum_t J_{\\mathrm{env}}(t; m_0) \\, r_{\\mathrm{env}}(t; m_0)}{\\sum_t J_{\\mathrm{env}}(t; m_0)^2}\n$$\n\n**3. 周波跳跃分析**\n\n基于波形的目标函数 $\\Phi_{\\mathrm{wf}}$ 作为模型参数 $m$ 的函数是高度振荡的，表现出众多的局部极小值。当预测子波 $d(t; m_0)$ 与观测数据 $d_{\\mathrm{obs}}(t)$ 的错位是子波半周期的整数倍时，就会出现这些局部极小值。$\\Delta m_{\\mathrm{wf}}$ 公式中的分子 $\\sum_t J_{\\mathrm{wf}} r_{\\mathrm{wf}}$ 表示残差与雅可比矩阵的互相关。当初始猜测 $m_0$ 远离真实值 $m_\\star$ 时，时移 $\\tau(m_0) - \\tau(m_\\star)$ 可能很大。如果这个时移超过了子波主周期的大约一半，相关性可能变得很小甚至符号反转。符号反转会导致高斯-牛顿步长指向错误的方向，远离真实解。这种无法找到正确极小值的情况被称为周波跳跃。\n\n相比之下，包络 $e(t; m)$ 是一个平滑、非振荡的时间函数，其最大值位于群到时 $\\tau(m)$。因此，基于包络的目标函数 $\\Phi_{\\mathrm{env}}$ 在更宽的 $m$ 值范围内更为平滑和凸。其围绕全局最小值的吸引盆更大，使得优化不易受周波跳跃的影响。残差 $r_{\\mathrm{env}}$ 捕捉了到时失配而没有振荡干扰，其与雅可比矩阵 $J_{\\mathrm{env}}$ 的相关性通常能提供一个稳健的更新方向，即使对于 $m_0$ 的较大初始误差也是如此。\n\n以下程序为指定的测试用例实现了这些计算，展示了包络失配相对于波形失配的稳健性。在 $J_{\\mathrm{env}}$ 的分母中的包络上添加了一个小的常数 $\\epsilon$ 以确保数值稳定性。计算出的步长 $\\Delta m$ 是标准高斯-牛顿公式中的搜索方向乘以 $-1$。对于更新规则 $m_{k+1} = m_k + \\Delta m_{step}$，我们计算的 $\\Delta m$ 应等于 $-\\Delta m_{step}$。这意味着如果 $m_0  m_\\star$，我们期望一个正的 $\\Delta m$，如果 $m_0  m_\\star$，则期望一个负的 $\\Delta m$。然而，对梯度的分析表明，我们的 $\\Delta m = (J^TJ)^{-1}J^Tr$ 项在 $m_0  m_\\star$ 时应为正，在 $m_0  m_\\star$ 时应为负。实现将遵循此推导，期望一个正的步长会增加模型值。", "answer": "```python\nimport numpy as np\nfrom scipy.signal import hilbert\n\ndef solve():\n    \"\"\"\n    Computes and compares Gauss-Newton steps for waveform and envelope\n    misfit functions in a 1D seismic inversion toy problem.\n    \"\"\"\n    # Physical and numerical parameters\n    z = 1000.0  # Reflector depth in meters\n    m_true = 2000.0  # True velocity in m/s\n    f0 = 10.0  # Central frequency in Hz\n    dt = 0.001  # Time sampling interval in seconds\n    t_max = 2.5  # Record length in seconds\n    epsilon = 1e-9 # Small constant for numerical stability\n\n    # Time vector\n    t = np.arange(0, t_max, dt)\n\n    # Ricker wavelet and its derivative\n    a = (np.pi * f0)**2\n    def ricker(time_vec):\n        return (1.0 - 2.0 * a * time_vec**2) * np.exp(-a * time_vec**2)\n\n    def ricker_derivative(time_vec):\n        return np.exp(-a * time_vec**2) * time_vec * (-6.0 * a + 4.0 * a**2 * time_vec**2)\n\n    # Forward modeling operator\n    def forward_model(m, time_vec):\n        tau = 2.0 * z / m\n        return ricker(time_vec - tau)\n\n    # Generate observed data\n    d_obs = forward_model(m_true, t)\n\n    # Test cases for initial model velocities\n    test_cases = [2000.0, 2100.0, 1800.0, 1500.0]\n\n    results = []\n    \n    for m0 in test_cases:\n        # Calculate predicted data for the current model parameter m0\n        d_pred = forward_model(m0, t)\n\n        # --- 1. Waveform-based inversion step ---\n        r_wf = d_obs - d_pred\n        \n        # Calculate Jacobian for waveform misfit\n        tau0 = 2.0 * z / m0\n        # The Jacobian is d(d)/dm = s'(t-tau) * d(-tau)/dm = s'(t-tau) * (2z/m^2)\n        J_wf = (2.0 * z / m0**2) * ricker_derivative(t - tau0)\n\n        # Calculate Gauss-Newton step for waveform\n        numerator_wf = np.sum(J_wf * r_wf)\n        denominator_wf = np.sum(J_wf**2)\n        \n        if np.isclose(denominator_wf, 0):\n            delta_m_wf = 0.0\n        else:\n            # We follow the problem's formula, which is (J^T J)^-1 J^T r.\n            # This is the standard Gauss-Newton step/correction.\n            # If m0 > m_true, we expect a negative step.\n            # If m0  m_true, we expect a positive step.\n            delta_m_wf = numerator_wf / denominator_wf\n\n        # --- 2. Envelope-based inversion step ---\n        \n        # Calculate analytic signals and envelopes\n        analytic_obs = hilbert(d_obs)\n        analytic_pred = hilbert(d_pred)\n        \n        e_obs = np.abs(analytic_obs)\n        e_pred = np.abs(analytic_pred)\n\n        r_env = e_obs - e_pred\n        \n        # Calculate Jacobian for envelope misfit\n        # J_env = d(e)/dm = [d*d(d)/dm + H{d}*d(H{d})/dm] / e\n        #       = [d*J_wf + H{d}*H{J_wf}] / e\n        analytic_J_wf = hilbert(J_wf)\n        \n        # The numerator is the real part of (analytic_pred_conj * analytic_J_wf)\n        numerator_J_env = np.real(np.conj(analytic_pred) * analytic_J_wf)\n        J_env = np.divide(numerator_J_env, e_pred + epsilon, \n                          out=np.zeros_like(numerator_J_env), \n                          where=(e_pred + epsilon) != 0)\n\n        # Calculate Gauss-Newton step for envelope\n        numerator_env = np.sum(J_env * r_env)\n        denominator_env = np.sum(J_env**2)\n\n        if np.isclose(denominator_env, 0):\n            delta_m_env = 0.0\n        else:\n            delta_m_env = numerator_env / denominator_env\n\n        results.append([round(delta_m_wf, 6), round(delta_m_env, 6)])\n\n    # Format the final output string\n    output_str = \"[\" + \",\".join([f\"[{res[0]:.6f},{res[1]:.6f}]\" for res in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3599323"}]}