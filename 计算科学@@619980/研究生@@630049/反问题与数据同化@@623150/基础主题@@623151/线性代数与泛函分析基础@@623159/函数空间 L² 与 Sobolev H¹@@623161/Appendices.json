{"hands_on_practices": [{"introduction": "将偏微分方程（PDE）约束下的优化问题转化为可计算的形式，是数据同化和反问题的核心步骤。本练习 [@problem_id:3383674] 将指导你完成这一基本流程，首先通过乘以一个测试函数并分部积分，推导出泊松方程的弱形式。然后，你将基于此，使用伴随状态法推导一个典型的数据同化目标泛函的梯度，这是进行梯度下降优化的关键第一步。", "problem": "设 $\\Omega \\subset \\mathbb{R}^{d}$ 是一个有界Lipschitz域，其边界为 $\\partial \\Omega$。考虑在 $\\Omega$ 中的偏微分方程 (PDE) $-\\Delta u = f$，其带有齐次Dirichlet边界条件 $u|_{\\partial \\Omega} = 0$，其中 $f \\in L^{2}(\\Omega)$。\n\n任务1 (弱形式)：从Sobolev空间 $H_{0}^{1}(\\Omega)$ 的核心定义和Gauss-Green恒等式出发，通过将PDE乘以一个测试函数 $v \\in H_{0}^{1}(\\Omega)$ 并进行分部积分来推导其弱形式。明确定义弱形式中出现的双线性形式 $a(u,v)$ 和线性泛函 $\\ell(v)$，并确保严格说明所有函数的空间归属。\n\n任务2 (数据同化泛函及梯度)：定义观测算子 $C : H_{0}^{1}(\\Omega) \\to \\mathbb{R}^{m}$ 为\n$$\nC(u)_{k} = \\int_{\\Omega} u(x)\\,\\phi_{k}(x)\\,\\mathrm{d}x,\\quad k=1,\\dots,m,\n$$\n其中 $\\phi_{k} \\in L^{2}(\\Omega)$ 是给定的基函数，并假设 $d = (d_{1},\\dots,d_{m}) \\in \\mathbb{R}^{m}$ 是给定的数据。对于一个固定的正则化参数 $\\lambda > 0$，定义最小二乘数据同化目标函数\n$$\nJ(f) = \\frac{1}{2}\\sum_{k=1}^{m}\\left(C(u(f))_{k} - d_{k}\\right)^{2} + \\frac{\\lambda}{2}\\,\\|f\\|_{L^{2}(\\Omega)}^{2},\n$$\n其中 $u(f) \\in H_{0}^{1}(\\Omega)$ 表示通过任务1得到的、与源 $f \\in L^{2}(\\Omega)$ 相关联的唯一弱解。推导 $J$ 在任意 $f$ 处的 $L^{2}(\\Omega)$-梯度，该表达式仅用 $f$、状态 $u(f)$ 以及一个你必须引入并通过弱形式指定的伴随状态 $p \\in H_{0}^{1}(\\Omega)$ 来表示。\n\n你的最终答案必须是 $J(f)$ 的 $L^{2}(\\Omega)$-梯度的一个单一闭式解析表达式，用 $f$ 和 $p$ 表示。无需四舍五入，也不涉及物理单位。", "solution": "这个问题包含两个任务。第一个是为泊松问题推导弱形式。第二个是使用伴随方法推导数据同化目标泛函的梯度。我们将依次解决每个任务。\n\n**任务1：弱形式**\n\n给定的偏微分方程(PDE)是带有齐次Dirichlet边界条件的泊松方程：\n$$\n-\\Delta u = f \\quad \\text{in } \\Omega\n$$\n$$\nu|_{\\partial \\Omega} = 0\n$$\n此处，$f$ 是一个源项，属于定义在域 $\\Omega$ 上的平方可积函数空间 $L^{2}(\\Omega)$。解 $u$ 在Sobolev空间 $H_{0}^{1}(\\Omega)$ 中寻找。空间 $H_{0}^{1}(\\Omega)$ 是在 $H^{1}$ 范数下，由在 $\\Omega$ 中具有紧支集的无限可微函数空间 $C_{c}^{\\infty}(\\Omega)$ 的闭包。$H_{0}^{1}(\\Omega)$ 中的函数可以被认为是在广义（迹）意义下满足边界 $\\partial \\Omega$ 上的条件 $u=0$。\n\n为推导弱形式，我们将PDE乘以一个任意的测试函数 $v \\in H_{0}^{1}(\\Omega)$ 并在域 $\\Omega$ 上积分：\n$$\n\\int_{\\Omega} (-\\Delta u(x)) v(x) \\, \\mathrm{d}x = \\int_{\\Omega} f(x) v(x) \\, \\mathrm{d}x\n$$\n我们对左侧应用Gauss-Green恒等式（一种分部积分形式）。对于定义在域 $\\Omega$（其边界为 $\\partial\\Omega$，外单位法向量为 $n$）上的足够光滑的函数 $u$ 和 $v$，该恒等式为：\n$$\n\\int_{\\Omega} (-\\Delta u) v \\, \\mathrm{d}x = \\int_{\\Omega} \\nabla u \\cdot \\nabla v \\, \\mathrm{d}x - \\int_{\\partial \\Omega} v (\\nabla u \\cdot n) \\, \\mathrm{d}S\n$$\n该恒等式可以推广到Sobolev空间中的函数。由于测试函数 $v$ 属于 $H_{0}^{1}(\\Omega)$，其在边界 $\\partial \\Omega$ 上的迹为零，即 $v|_{\\partial \\Omega} = 0$。因此，边界积分为零：\n$$\n\\int_{\\partial \\Omega} v (\\nabla u \\cdot n) \\, \\mathrm{d}S = 0\n$$\n因此，我们得到弱形式：寻找 $u \\in H_{0}^{1}(\\Omega)$，使得\n$$\n\\int_{\\Omega} \\nabla u(x) \\cdot \\nabla v(x) \\, \\mathrm{d}x = \\int_{\\Omega} f(x) v(x) \\, \\mathrm{d}x\n$$\n对所有测试函数 $v \\in H_{0}^{1}(\\Omega)$ 成立。\n\n该方程具有一般形式 $a(u,v) = \\ell(v)$。双线性形式 $a(\\cdot, \\cdot)$ 和线性泛函 $\\ell(\\cdot)$ 定义如下：\n1.  双线性形式 $a: H_{0}^{1}(\\Omega) \\times H_{0}^{1}(\\Omega) \\to \\mathbb{R}$ 由下式给出：\n    $$\n    a(u,v) = \\int_{\\Omega} \\nabla u(x) \\cdot \\nabla v(x) \\, \\mathrm{d}x\n    $$\n2.  线性泛函 $\\ell: H_{0}^{1}(\\Omega) \\to \\mathbb{R}$ 由下式给出：\n    $$\n    \\ell(v) = \\int_{\\Omega} f(x) v(x) \\, \\mathrm{d}x\n    $$\n对于任意给定的 $f \\in L^2(\\Omega)$，解 $u \\in H_{0}^{1}(\\Omega)$ 的存在性和唯一性由 Lax-Milgram 定理保证，因为 $a(\\cdot,\\cdot)$ 在 $H_{0}^{1}(\\Omega)$ 上是连续且强制的，并且 $\\ell(\\cdot)$ 是 $H_{0}^{1}(\\Omega)$ 上的一个连续线性泛函。\n\n**任务2：数据同化泛函及梯度**\n\n需要最小化的目标泛函由下式给出：\n$$\nJ(f) = \\frac{1}{2}\\sum_{k=1}^{m}\\left(C(u(f))_{k} - d_{k}\\right)^{2} + \\frac{\\lambda}{2}\\,\\|f\\|_{L^{2}(\\Omega)}^{2}\n$$\n其中 $u(f)$ 是给定源 $f \\in L^{2}(\\Omega)$ 的泊松问题的唯一弱解。我们寻求 $J(f)$ 的 $L^{2}(\\Omega)$-梯度，记作 $\\nabla_{f} J(f)$，它是 $L^{2}(\\Omega)$ 中的一个元素，由以下关系定义：\n$$\nDJ(f)[\\delta f] = \\langle \\nabla_{f} J(f), \\delta f \\rangle_{L^{2}(\\Omega)} = \\int_{\\Omega} (\\nabla_{f} J(f))(x) \\delta f(x) \\, \\mathrm{d}x\n$$\n对于所有扰动 $\\delta f \\in L^{2}(\\Omega)$，其中 $DJ(f)[\\delta f]$ 是 $J$ 在 $f$ 点沿方向 $\\delta f$ 的Gâteaux导数。\n\nGâteaux导数计算如下：\n$$\nDJ(f)[\\delta f] = \\lim_{\\epsilon \\to 0} \\frac{J(f + \\epsilon \\delta f) - J(f)}{\\epsilon} = \\frac{d}{d\\epsilon} \\left. J(f + \\epsilon \\delta f) \\right|_{\\epsilon=0}\n$$\n首先，我们分析状态 $u$ 对源 $f$ 的依赖性。由于弱形式的线性，映射 $f \\mapsto u(f)$ 是线性的。设 $u(f+\\epsilon\\delta f)$ 是对应于源 $f+\\epsilon\\delta f$ 的解。根据线性性质，$u(f+\\epsilon\\delta f) = u(f) + \\epsilon u(\\delta f)$。我们记 $\\delta u := u(\\delta f)$。函数 $\\delta u \\in H_{0}^{1}(\\Omega)$ 是源为 $\\delta f$ 的PDE的唯一弱解，即它满足：\n$$\na(\\delta u, v) = \\int_{\\Omega} \\delta f(x) v(x) \\, \\mathrm{d}x \\quad \\forall v \\in H_{0}^{1}(\\Omega)\n$$\n现在我们计算 $J(f)$ 的导数。\n第一项（失配项）的导数是：\n$$\n\\frac{d}{d\\epsilon} \\left. \\left( \\frac{1}{2}\\sum_{k=1}^{m}\\left(C(u(f+\\epsilon\\delta f))_{k} - d_{k}\\right)^{2} \\right) \\right|_{\\epsilon=0}\n$$\n使用链式法则以及 $C$ 和 $u(f)$ 的线性性质：\n$$\n= \\sum_{k=1}^{m} \\left(C(u(f))_{k} - d_{k}\\right) \\left( \\frac{d}{d\\epsilon} \\left. C(u(f) + \\epsilon \\delta u)_{k} \\right|_{\\epsilon=0} \\right)\n$$\n$$\n= \\sum_{k=1}^{m} \\left(C(u(f))_{k} - d_{k}\\right) C(\\delta u)_{k}\n$$\n代入 $C(\\delta u)_k$ 的定义：\n$$\n= \\sum_{k=1}^{m} \\left(C(u(f))_{k} - d_{k}\\right) \\int_{\\Omega} \\delta u(x) \\phi_{k}(x) \\, \\mathrm{d}x\n$$\n$$\n= \\int_{\\Omega} \\delta u(x) \\left( \\sum_{k=1}^{m} (C(u(f))_{k} - d_{k}) \\phi_{k}(x) \\right) \\, \\mathrm{d}x\n$$\n第二项（正则化项）的导数是：\n$$\n\\frac{d}{d\\epsilon} \\left. \\left( \\frac{\\lambda}{2}\\,\\|f + \\epsilon \\delta f\\|_{L^{2}(\\Omega)}^{2} \\right) \\right|_{\\epsilon=0} = \\frac{\\lambda}{2} \\frac{d}{d\\epsilon} \\left. \\langle f + \\epsilon \\delta f, f + \\epsilon \\delta f \\rangle_{L^2} \\right|_{\\epsilon=0}\n$$\n$$\n= \\frac{\\lambda}{2} \\frac{d}{d\\epsilon} \\left. (\\|f\\|_{L^2}^2 + 2\\epsilon \\langle f, \\delta f \\rangle_{L^2} + \\epsilon^2 \\|\\delta f\\|_{L^2}^2) \\right|_{\\epsilon=0} = \\lambda \\langle f, \\delta f \\rangle_{L^{2}(\\Omega)} = \\lambda \\int_{\\Omega} f(x) \\delta f(x) \\, \\mathrm{d}x\n$$\n结合两项，Gâteaux导数为：\n$$\nDJ(f)[\\delta f] = \\int_{\\Omega} \\delta u(x) \\left( \\sum_{k=1}^{m} (C(u(f))_{k} - d_{k}) \\phi_{k}(x) \\right) \\, \\mathrm{d}x + \\lambda \\int_{\\Omega} f(x) \\delta f(x) \\, \\mathrm{d}x\n$$\n这个表达式依赖于 $\\delta u$，而 $\\delta u$ 又依赖于 $\\delta f$。为了找到梯度，我们必须将 $DJ(f)[\\delta f]$ 表示为与 $\\delta f$ 的单个内积。这通过引入一个伴随状态 $p \\in H_{0}^{1}(\\Omega)$ 来实现。我们定义伴随问题来消除包含 $\\delta u$ 的项。设 $p \\in H_{0}^{1}(\\Omega)$ 是以下伴随方程的唯一弱解：\n$$\na(v,p) = \\int_{\\Omega} v(x) \\left( \\sum_{k=1}^{m} (C(u(f))_{k} - d_{k}) \\phi_{k}(x) \\right) \\, \\mathrm{d}x \\quad \\forall v \\in H_{0}^{1}(\\Omega)\n$$\n双线性形式 $a(\\cdot, \\cdot)$ 是对称的，即 $a(v,p) = a(p,v)$。伴随方程的强形式是 $-\\Delta p = \\sum_{k=1}^{m}(C(u(f))_k - d_k)\\phi_k$，在 $\\Omega$ 中，且 $p|_{\\partial\\Omega}=0$。\n\n在伴随弱形式中选择测试函数 $v = \\delta u \\in H_{0}^{1}(\\Omega)$，我们得到：\n$$\na(\\delta u, p) = \\int_{\\Omega} \\delta u(x) \\left( \\sum_{k=1}^{m} (C(u(f))_{k} - d_{k}) \\phi_{k}(x) \\right) \\, \\mathrm{d}x\n$$\n这恰好是我们 $DJ(f)[\\delta f]$ 表达式中的第一项。因此，我们可以写成：\n$$\nDJ(f)[\\delta f] = a(\\delta u, p) + \\lambda \\langle f, \\delta f \\rangle_{L^{2}(\\Omega)}\n$$\n现在，我们使用 $\\delta u$ 的弱形式，即对于所有 $v \\in H_{0}^{1}(\\Omega)$ 都有 $a(\\delta u, v) = \\langle \\delta f, v \\rangle_{L^{2}(\\Omega)}$。在此形式中选择测试函数 $v=p \\in H_{0}^{1}(\\Omega)$ 得到：\n$$\na(\\delta u, p) = \\langle \\delta f, p \\rangle_{L^{2}(\\Omega)} = \\int_{\\Omega} \\delta f(x) p(x) \\, \\mathrm{d}x\n$$\n将此代回 $DJ(f)[\\delta f]$ 的表达式中：\n$$\nDJ(f)[\\delta f] = \\int_{\\Omega} p(x) \\delta f(x) \\, \\mathrm{d}x + \\lambda \\int_{\\Omega} f(x) \\delta f(x) \\, \\mathrm{d}x\n$$\n$$\nDJ(f)[\\delta f] = \\int_{\\Omega} (\\lambda f(x) + p(x)) \\delta f(x) \\, \\mathrm{d}x = \\langle \\lambda f + p, \\delta f \\rangle_{L^{2}(\\Omega)}\n$$\n根据Riesz表示定理（该定理定义了希尔伯特空间中的梯度），我们可以将 $J$ 在 $f$ 处的 $L^2(\\Omega)$-梯度识别为与 $\\delta f$ 内积中的那一项。\n\n因此，$J(f)$ 的 $L^{2}(\\Omega)$-梯度是：\n$$\n\\nabla_{f} J(f) = \\lambda f + p\n$$\n其中 $p \\in H_{0}^{1}(\\Omega)$ 是由上述弱形式定义的伴随状态，它依赖于状态 $u(f)$ 和数据 $d$。", "answer": "$$\n\\boxed{\\lambda f + p}\n$$", "id": "3383674"}, {"introduction": "在反问题中，正则化的选择深刻地影响着解的性质。这个练习 [@problem_id:3383644] 探讨了控制变量（或先验）空间的几何结构如何决定梯度的表达形式。你将推导同一个问题在$L^2$和$H^1_0$两种不同内积下的梯度，并揭示$H^1$梯度如何通过Riesz映射实现对解的平滑，这对于理解Sobolev空间正则化的优越性至关重要。", "problem": "考虑一个有界开区间区域 $\\Omega = (0,\\pi)$，以及由具有齐次狄利克雷边界条件的索博列夫空间 $H^{1}_{0}(\\Omega)$ 给出的控制空间。设状态 $u \\in H^{1}_{0}(\\Omega)$ 由一个带有源控制 $m \\in H^{1}_{0}(\\Omega)$ 的线性椭圆偏微分方程 (PDE) 确定：\n$$\n-\\frac{d^{2}u}{dx^{2}} + \\beta\\, u = m \\quad \\text{in } \\Omega, \\qquad u(0)=u(\\pi)=0,\n$$\n其中 $\\beta > 0$ 是一个固定常数。观测算子为恒等算子，代价泛函是一个勒贝格 $L^{2}(\\Omega)$ 失配：\n$$\nJ(m) = \\frac{1}{2} \\int_{\\Omega} \\left(u(x) - d(x)\\right)^{2}\\, dx,\n$$\n其中给定数据 $d \\in L^{2}(\\Omega)$。在反问题和数据同化的背景下，梯度是通过 Riesz 表示定理相对于控制空间的几何结构来定义的。具体而言，$L^{2}(\\Omega)$ 内积由 $\\langle a,b \\rangle_{L^{2}}=\\int_{\\Omega} a\\,b\\,dx$ 给出，而 $H^{1}_{0}(\\Omega)$ 内积由 $\\langle a,b \\rangle_{H^{1}_{0}}=\\int_{\\Omega} \\nabla a \\cdot \\nabla b\\,dx$ 给出。\n\n从第一性原理出发——即 $J$ 的 Gâteaux 导数的定义、状态方程以及基于偏微分方程变分结构的伴随方法——推导相对于 $L^{2}(\\Omega)$ 内积的伴随梯度，然后使用与 $H^{1}_{0}(\\Omega)$ 相关联的 Riesz 映射来表示 $H^{1}_{0}(\\Omega)$ 几何中的梯度。清晰地解释 Riesz 映射如何在 $J$ 的迭代最小化过程中改变梯度的表达式以及随之产生的下降方向。\n\n然后，对于具体选择 $d(x)=0$ 和 $m(x) = \\sin(x) + \\sin(2x)$，进行显式推导，并给出索博列夫 $H^{1}_{0}(\\Omega)$-梯度 $\\nabla_{H^{1}} J(m)$ 作为 $x$ 和 $\\beta$ 的函数的最终解析表达式。\n\n你的最终答案必须是单一的闭式解析表达式。无需进行四舍五入。", "solution": "该问题是有效的。这是一个在偏微分方程约束优化和反问题领域内定义明确的数学问题，它基于泛函分析和变分法的既定原理。所有必要的组成部分，包括状态方程、代价泛函和函数空间定义，都已提供并且是相互一致的。\n\n我们首先推导代价泛函 $J(m)$ 相对于控制变量 $m \\in H^{1}_{0}(\\Omega)$ 的梯度。推导过程分为三个主要阶段：首先，我们求出 $J(m)$ 的 Gâteaux 导数；其次，我们引入伴随状态，将该导数表示为一个内积，从而得到在 $L^{2}(\\Omega)$ 几何下的梯度；第三，我们利用 $H^{1}_{0}(\\Omega)$ 中的 Riesz 表示定理，求出在索博列夫几何下的梯度。\n\n设 $u(m)$ 表示给定控制 $m$ 下状态方程的解。代价泛函为\n$$\nJ(m) = \\frac{1}{2} \\int_{\\Omega} (u(m)(x) - d(x))^{2}\\, dx\n$$\n\n**1. Gâteaux 导数**\n\n$J$ 在 $m$ 点沿方向 $h \\in H^{1}_{0}(\\Omega)$ 的 Gâteaux 导数定义为\n$$\nJ'(m; h) = \\lim_{\\epsilon \\to 0} \\frac{J(m+\\epsilon h) - J(m)}{\\epsilon}\n$$\n设 $u(m+\\epsilon h)$ 是对应于受扰动控制 $m+\\epsilon h$ 的状态。状态方程是线性的，因此 $u(m+\\epsilon h) = u(m) + \\epsilon u_{h}$，其中 $u_h$ 是线性化状态方程的解：\n$$\n-\\frac{d^{2}u_{h}}{dx^{2}} + \\beta u_{h} = h \\quad \\text{in } \\Omega, \\qquad u_{h}(0)=u_{h}(\\pi)=0\n$$\n将此代入 Gâteaux 导数的定义中：\n\\begin{align*}\nJ(m+\\epsilon h) = \\frac{1}{2} \\int_{\\Omega} (u(m)(x) + \\epsilon u_{h}(x) - d(x))^{2}\\, dx \\\\\n= \\frac{1}{2} \\int_{\\Omega} \\left[ (u(m)(x) - d(x))^{2} + 2\\epsilon (u(m)(x) - d(x))u_{h}(x) + \\epsilon^{2} u_{h}(x)^{2} \\right] dx \\\\\n= J(m) + \\epsilon \\int_{\\Omega} (u(m)(x) - d(x))u_{h}(x)\\, dx + O(\\epsilon^{2})\n\\end{align*}\n因此，Gâteaux 导数为\n$$\nJ'(m; h) = \\int_{\\Omega} (u(m)(x) - d(x)) u_{h}(x)\\, dx\n$$\n\n**2. 伴随方法与 $L^{2}$ 梯度**\n\n$J'(m; h)$ 的表达式依赖于 $u_h$，而 $u_h$ 又通过一个微分方程依赖于 $h$。伴随方法提供了一种将该导数直接表示为与 $h$ 的内积的方式。我们引入一个伴随状态 $p \\in H^{1}_{0}(\\Omega)$，它是伴随方程的解。\n\n设 $\\mathcal{L} = -\\frac{d^{2}}{dx^{2}} + \\beta$ 为状态算子。扰动的状态方程为 $\\mathcal{L}u_{h} = h$。带有齐次狄利克雷边界条件的算子 $\\mathcal{L}$ 相对于 $L^{2}(\\Omega)$ 内积是自伴的。也就是说，对于任意 $v,w \\in H^{1}_{0}(\\Omega)$，有 $\\langle \\mathcal{L}v, w \\rangle_{L^{2}} = \\langle v, \\mathcal{L}w \\rangle_{L^{2}}$。\n\n我们将伴随状态 $p$ 定义为以下方程的解：\n$$\n\\mathcal{L}p = u(m) - d \\iff -\\frac{d^{2}p}{dx^{2}} + \\beta p = u(m) - d \\quad \\text{in } \\Omega, \\qquad p(0)=p(\\pi)=0\n$$\n现在，我们使用伴随状态重写 Gâteaux 导数：\n$$\nJ'(m; h) = \\int_{\\Omega} (u(m) - d) u_{h}\\, dx = \\int_{\\Omega} (\\mathcal{L}p) u_{h}\\, dx = \\langle \\mathcal{L}p, u_{h} \\rangle_{L^{2}}\n$$\n利用 $\\mathcal{L}$ 的自伴性质：\n$$\nJ'(m; h) = \\langle p, \\mathcal{L}u_{h} \\rangle_{L^{2}} = \\int_{\\Omega} p (\\mathcal{L}u_{h})\\, dx\n$$\n由于 $\\mathcal{L}u_{h} = h$，我们有：\n$$\nJ'(m; h) = \\int_{\\Omega} p(x) h(x)\\, dx = \\langle p, h \\rangle_{L^{2}}\n$$\n根据 $L^{2}(\\Omega)$ 中的 Riesz 表示定理，相对于 $L^{2}$ 内积的梯度就是伴随状态本身：\n$$\n\\nabla_{L^{2}} J(m) = p\n$$\n\n**3. Riesz 映射与 $H^{1}_{0}$ 梯度**\n\n我们现在寻求相对于 $H^{1}_{0}(\\Omega)$ 内积的梯度，我们将其记为 $g = \\nabla_{H^{1}} J(m)$。根据定义，$g \\in H^{1}_{0}(\\Omega)$ 必须满足\n$$\nJ'(m; h) = \\langle g, h \\rangle_{H^{1}_{0}} \\quad \\forall h \\in H^{1}_{0}(\\Omega)\n$$\n其中 $\\langle g, h \\rangle_{H^{1}_{0}} = \\int_{\\Omega} \\nabla g \\cdot \\nabla h\\, dx = \\int_{0}^{\\pi} g'(x) h'(x)\\, dx$。\n令导数 $J'(m; h)$ 的两个表达式相等：\n$$\n\\langle g, h \\rangle_{H^{1}_{0}} = \\langle p, h \\rangle_{L^{2}} \\implies \\int_{0}^{\\pi} g'(x) h'(x)\\, dx = \\int_{0}^{\\pi} p(x) h(x)\\, dx\n$$\n这是关于 $g$ 的一个边值问题的弱形式。为了找到其强形式，我们对左侧进行分部积分：\n$$\n\\int_{0}^{\\pi} g'(x) h'(x)\\, dx = - \\int_{0}^{\\pi} g''(x) h(x)\\, dx + [g'(x)h(x)]_{0}^{\\pi}\n$$\n由于 $h \\in H^{1}_{0}(\\Omega)$，$h(0) = h(\\pi) = 0$，所以边界项消失。该恒等式变为：\n$$\n\\int_{0}^{\\pi} (-g''(x)) h(x)\\, dx = \\int_{0}^{\\pi} p(x) h(x)\\, dx\n$$\n由于这对所有 $h \\in H^{1}_{0}(\\Omega)$ 都成立，根据变分法基本引理，被积函数必然相等：\n$$\n-g''(x) = p(x) \\quad \\text{in } \\Omega\n$$\n梯度 $g=\\nabla_{H^{1}} J(m)$ 必须在控制空间 $H^{1}_{0}(\\Omega)$ 中，因此它满足齐次狄利克雷边界条件，$g(0)=g(\\pi)=0$。\n\n从 $L^{2}$ 梯度 $p$到 $H^{1}_{0}$ 梯度 $g$ 的变换是一个 Riesz 映射。它涉及到求解一个泊松方程，这是一个椭圆平滑算子。在一个迭代优化方案（$m_{k+1} = m_{k} - \\alpha_{k} \\nabla J(m_k)$）中，使用 $H^{1}_{0}$ 梯度 $g$ 而不是 $L^{2}$ 梯度 $p$ 构成了一种预处理。下降方向 $g$ 是 $p$ 的一个平滑版本，它惩罚高频振荡，并通过采取更适应控制空间拓扑结构的步长，通常能导致收敛速度显著加快。\n\n**4. 针对特定情况的显式计算**\n\n给定 $d(x)=0$ 和 $m(x)=\\sin(x)+\\sin(2x)$。我们分步进行计算。\n\n首先，求解状态方程 $-\\frac{d^{2}u}{dx^{2}} + \\beta u = \\sin(x)+\\sin(2x)$，边界条件为 $u(0)=u(\\pi)=0$，以求得状态 $u(x)$。由于 $\\{\\sin(kx)\\}_{k=1}^\\infty$ 是 $-\\frac{d^2}{dx^2}$ 的特征函数，其特征值为 $k^2$，我们假设解的形式为 $u(x) = c_1 \\sin(x) + c_2 \\sin(2x)$。\n$$\n(1^{2}c_1 \\sin(x) + 2^{2}c_2 \\sin(2x)) + \\beta (c_1 \\sin(x) + c_2 \\sin(2x)) = \\sin(x)+\\sin(2x)\n$$\n$$\n(1+\\beta)c_1 \\sin(x) + (4+\\beta)c_2 \\sin(2x) = \\sin(x)+\\sin(2x)\n$$\n匹配系数可得 $c_1 = \\frac{1}{1+\\beta}$ 和 $c_2 = \\frac{1}{4+\\beta}$。因此，状态为：\n$$\nu(x) = \\frac{1}{1+\\beta}\\sin(x) + \\frac{1}{4+\\beta}\\sin(2x)\n$$\n其次，求解伴随方程 $-\\frac{d^{2}p}{dx^{2}} + \\beta p = u(x) - d(x) = u(x)$，边界条件为 $p(0)=p(\\pi)=0$，以求得伴随状态 $p(x)$。\n$$\n-\\frac{d^{2}p}{dx^{2}} + \\beta p = \\frac{1}{1+\\beta}\\sin(x) + \\frac{1}{4+\\beta}\\sin(2x)\n$$\n再次假设解的形式为 $p(x) = p_1 \\sin(x) + p_2 \\sin(2x)$：\n$$\n(1+\\beta)p_1 \\sin(x) + (4+\\beta)p_2 \\sin(2x) = \\frac{1}{1+\\beta}\\sin(x) + \\frac{1}{4+\\beta}\\sin(2x)\n$$\n匹配系数可得 $p_1 = \\frac{1}{(1+\\beta)^{2}}$ 和 $p_2 = \\frac{1}{(4+\\beta)^{2}}$。伴随状态（即 $L^2$ 梯度）为：\n$$\np(x) = \\frac{1}{(1+\\beta)^{2}}\\sin(x) + \\frac{1}{(4+\\beta)^{2}}\\sin(2x)\n$$\n第三，求解方程 $-g''(x) = p(x)$，边界条件为 $g(0)=g(\\pi)=0$，以求得 $H^{1}_{0}$ 梯度 $g(x) = \\nabla_{H^{1}} J(m)$。\n$$\n-g''(x) = \\frac{1}{(1+\\beta)^{2}}\\sin(x) + \\frac{1}{(4+\\beta)^{2}}\\sin(2x)\n$$\n假设解的形式为 $g(x) = g_1 \\sin(x) + g_2 \\sin(2x)$：\n$$\n-(-(1)^{2}g_1 \\sin(x) - (2)^{2}g_2 \\sin(2x)) = g_1 \\sin(x) + 4 g_2 \\sin(2x)\n$$\n将此式与 $p(x)$ 相等：\n$$\ng_1 \\sin(x) + 4g_2 \\sin(2x) = \\frac{1}{(1+\\beta)^{2}}\\sin(x) + \\frac{1}{(4+\\beta)^{2}}\\sin(2x)\n$$\n匹配系数可得 $g_1 = \\frac{1}{(1+\\beta)^{2}}$ 和 $4g_2 = \\frac{1}{(4+\\beta)^{2}}$，这意味着 $g_2 = \\frac{1}{4(4+\\beta)^{2}}$。\n$H^{1}_{0}$ 梯度的最终解析表达式为：\n$$\ng(x) = \\nabla_{H^{1}} J(m) = \\frac{1}{(1+\\beta)^{2}}\\sin(x) + \\frac{1}{4(4+\\beta)^{2}}\\sin(2x)\n$$", "answer": "$$\\boxed{\\frac{\\sin(x)}{(1+\\beta)^{2}} + \\frac{\\sin(2x)}{4(4+\\beta)^{2}}}$$", "id": "3383644"}, {"introduction": "Sobolev空间的精确定义，特别是边界条件，对变分问题的解有着微妙而深远的影响。本练习 [@problem_id:3383641] 通过对比狄利克雷（Dirichlet）和周期性两种边界条件，让你亲身体验这一点。你将分析为何一个仅依赖于导数的目标泛函会导致解的不唯一性，以及边界条件如何通过施加不同约束来确定或限制解空间。", "problem": "考虑以下在空间域 $\\Omega = (0,1)$ 上的数据同化问题。给定一个目标场 $y \\in L^{2}(0,1)$，其表达式为 $y(x) = 1 + \\cos(2\\pi x)$。您希望通过最小化一个二次 Tikhonov 泛函来重构未知状态 $u \\in H^{1}(0,1)$，该泛函仅惩罚 Sobolev $H^{1}$ 半范数：\n$$\nJ(u) \\;=\\; \\int_{0}^{1} \\big(u'(x) - y(x)\\big)^{2} \\, dx \\;+\\; \\alpha \\int_{0}^{1} \\big|u'(x)\\big|^{2} \\, dx,\n$$\n其中正则化参数 $\\alpha > 0$。假设观测是精确的（不需要随机噪声模型），并回想一下，$L^{2}(0,1)$ 空间是 $(0,1)$ 上的平方可积函数空间，而 $H^{1}(0,1)$ 是具有平方可积弱导数的 Sobolev 空间。\n\n您将研究两个仅在边界条件上有所不同的容许函数空间：\n- Dirichlet 容许空间 $V_{D} = \\{ u \\in H^{1}(0,1) \\,:\\, u(0) = 0 \\}$，\n- 周期容许空间 $V_{P} = \\{ u \\in H^{1}(0,1) \\,:\\, u(0) = u(1) \\}$。\n\n从第一性原理出发，使用 $L^{2}(0,1)$ 和 $H^{1}(0,1)$ 的定义、弱导数以及基本的变分法来：\n- 解释为什么 $J(u)$ 只依赖于 $u'$，因此在给 $u$ 加上一个常数时保持不变，从而使得 $u$ 中的常数偏移仅由边界条件控制。\n- 推导最小化子 $u_{D}^{\\star} \\in V_{D}$ 和 $u_{P}^{\\star} \\in V_{P}$ 的导数表达式，并表达出相应的最小目标值 $J(u_{D}^{\\star})$ 和 $J(u_{P}^{\\star})$。\n\n最后，对于给定的 $y(x) = 1 + \\cos(2\\pi x)$，计算显式差值\n$$\n\\Delta J \\;=\\; J(u_{P}^{\\star}) \\;-\\; J(u_{D}^{\\star})\n$$\n并将其表示为关于 $\\alpha$ 的闭式解析表达式。\n\n将您的最终答案以单个关于 $\\alpha$ 的闭式表达式形式给出。无需四舍五入。不涉及单位。", "solution": "在尝试解答之前，对问题进行验证。\n\n### 第 1 步：提取已知条件\n- 空间域：$\\Omega = (0,1)$。\n- 目标场：$y \\in L^{2}(0,1)$，其表达式为 $y(x) = 1 + \\cos(2\\pi x)$。\n- 未知状态：$u \\in H^{1}(0,1)$。\n- 待最小化的泛函：$J(u) = \\int_{0}^{1} (u'(x) - y(x))^{2} \\, dx + \\alpha \\int_{0}^{1} |u'(x)|^{2} \\, dx$。\n- 正则化参数：$\\alpha > 0$。\n- 容许函数空间：\n  - Dirichlet 空间：$V_{D} = \\{ u \\in H^{1}(0,1) \\,:\\, u(0) = 0 \\}$。\n  - 周期空间：$V_{P} = \\{ u \\in H^{1}(0,1) \\,:\\, u(0) = u(1) \\}$。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题是 Tikhonov 正则化在数据同化背景下的一个标准变分问题。\n- **科学依据：** $L^2$ 和 $H^1$ 空间、Tikhonov 泛函和变分法等概念是泛函分析和反问题数值分析的基本支柱。该问题在数学上是合理的，并遵循既定原则。\n- **适定性：** 泛函 $J(u)$ 关于 $u'$ 是严格凸的，容许集 $V_D$ 和 $V_P$ 是 Hilbert 空间 $H^1(0,1)$ 的闭凸子集。这种结构保证了两种情况下最小化子导数的存在性和唯一性。存在一个显式最小化子 $u$，它在 $V_D$ 中是唯一的，在 $V_P$ 中在相差一个加性常数的意义下是唯一的。\n- **目标：** 该问题使用精确、无歧义的数学语言陈述。\n- 问题设置完整且自洽，提供了所有必要的定义和条件。它没有矛盾、不切实际、不适定或微不足道之处。\n\n### 第 3 步：结论与行动\n该问题有效。将提供完整解答。\n\n### 解答\n\n给定的 Tikhonov 泛函为：\n$$\nJ(u) = \\int_{0}^{1} \\big(u'(x) - y(x)\\big)^{2} \\, dx + \\alpha \\int_{0}^{1} \\big|u'(x)\\big|^{2} \\, dx\n$$\n该泛函是为函数 $u \\in H^{1}(0,1)$ 定义的。项 $u'$ 表示 $u$ 的弱导数。\n\n**泛函的不变性及边界条件的作用**\n\n泛函 $J(u)$ 仅显式地依赖于导数 $u'(x)$，而不依赖于 $u(x)$ 本身。我们可以证明在给 $u$ 加上一个常数时其不变性。设 $\\tilde{u}(x) = u(x) + C$，其中 $C \\in \\mathbb{R}$ 为某个常数。其导数为 $\\tilde{u}'(x) = u'(x)$。将此代入泛函：\n$$\nJ(\\tilde{u}) = J(u+C) = \\int_{0}^{1} \\big((u+C)'(x) - y(x)\\big)^{2} \\, dx + \\alpha \\int_{0}^{1} \\big|(u+C)'(x)\\big|^{2} \\, dx\n$$\n$$\nJ(\\tilde{u}) = \\int_{0}^{1} \\big(u'(x) - y(x)\\big)^{2} \\, dx + \\alpha \\int_{0}^{1} \\big|u'(x)\\big|^{2} \\, dx = J(u)\n$$\n这表明如果 $u$ 是 $J$ 的一个最小化子，那么任何函数 $u+C$ 也最小化 $J$。具体的最小化子是通过确保它属于指定的容许空间来选择的。\n- 对于 Dirichlet 空间 $V_D = \\{ u \\in H^{1}(0,1) \\,:\\, u(0) = 0 \\}$，如果 $u^\\star$ 是一个最小化子，则 $u^\\star(0)=0$。要使 $u^\\star+C$ 属于 $V_D$，我们需要 $(u^\\star+C)(0) = u^\\star(0)+C = 0+C = 0$，这意味着 $C=0$。因此，边界条件固定了常数偏移，确保了唯一的最小化子 $u_D^\\star$。\n- 对于周期空间 $V_P = \\{ u \\in H^{1}(0,1) \\,:\\, u(0) = u(1) \\}$，如果 $u^\\star$ 是一个最小化子，则 $u^\\star(0)=u^\\star(1)$。要使 $u^\\star+C$ 属于 $V_P$，我们需要 $(u^\\star+C)(0) = (u^\\star+C)(1)$，这可以简化为 $u^\\star(0)+C = u^\\star(1)+C$。因为 $u^\\star(0)=u^\\star(1)$，所以这对任何 $C$ 都成立。因此，最小化子 $u_P^\\star$ 不是唯一的，而是在相差一个任意加性常数的意义下定义的。周期边界条件并不固定这个常数；相反，根据微积分基本定理，它对导数施加了一个约束：$\\int_0^1 u'(x) dx = u(1)-u(0) = 0$。\n\n**最小化子导数的推导**\n\n令 $v(x) = u'(x)$。由于 $u \\in H^1(0,1)$，其弱导数 $v$ 属于 $L^2(0,1)$。该泛函可以用 $v$ 表示：\n$$\nJ(v) = \\int_{0}^{1} (v(x) - y(x))^{2} \\, dx + \\alpha \\int_{0}^{1} v(x)^{2} \\, dx\n$$\n我们可以通过对变量 $v$ 配方来重写此泛函：\n$$\nJ(v) = \\int_{0}^{1} \\big(v^{2} - 2v y + y^2 + \\alpha v^2 \\big) \\, dx = \\int_{0}^{1} \\big((1+\\alpha)v^{2} - 2v y + y^2 \\big) \\, dx\n$$\n$$\nJ(v) = (1+\\alpha) \\int_{0}^{1} \\left(v^2 - \\frac{2}{1+\\alpha} v y \\right) dx + \\int_{0}^{1} y^2 dx\n$$\n$$\nJ(v) = (1+\\alpha) \\int_{0}^{1} \\left[ \\left(v - \\frac{y}{1+\\alpha}\\right)^2 - \\left(\\frac{y}{1+\\alpha}\\right)^2 \\right] dx + \\int_{0}^{1} y^2 dx\n$$\n$$\nJ(v) = (1+\\alpha) \\int_{0}^{1} \\left(v - \\frac{y}{1+\\alpha}\\right)^2 dx - \\frac{1}{1+\\alpha}\\int_{0}^{1} y^2 dx + \\int_{0}^{1} y^2 dx\n$$\n$$\nJ(v) = (1+\\alpha)\\left\\|v - \\frac{y}{1+\\alpha}\\right\\|_{L^2}^2 + \\frac{\\alpha}{1+\\alpha}\\|y\\|_{L^2}^2\n$$\n最小化 $J(v)$ 等价于最小化范数的平方项。\n\n**情况 1：$V_D$ 中的最小化子**\n对于 $u \\in V_D$，其导数 $u'$ 除了属于 $L^2(0,1)$ 之外没有其他约束。因此，我们可以自由选择 $v=u'$ 以在所有 $v \\in L^2(0,1)$ 上最小化该泛函。范数项的最小值为 0，在以下条件下达到：\n$$\nu_{D}^{\\star \\prime}(x) = v^\\star(x) = \\frac{1}{1+\\alpha}y(x)\n$$\n泛函对应的最小值为：\n$$\nJ(u_{D}^{\\star}) = \\frac{\\alpha}{1+\\alpha}\\|y\\|_{L^2}^2 = \\frac{\\alpha}{1+\\alpha}\\int_{0}^{1} y(x)^2 \\, dx\n$$\n\n**情况 2：$V_P$ 中的最小化子**\n对于 $u \\in V_P$，导数 $v=u'$ 必须满足约束 $\\int_0^1 v(x) dx = 0$。我们必须在此约束下最小化 $J(v)$。这等价于将无约束最小化子 $f(x) = \\frac{y(x)}{1+\\alpha}$ 在 $L^2$ 意义下投影到均值为零的 $L^2(0,1)$ 函数子空间上。\n一个函数 $f$ 在该子空间上的投影由 $f - \\bar{f}$ 给出，其中 $\\bar{f} = \\int_0^1 f(x) dx$。\n首先，我们计算 $f(x)$ 的均值：\n$$\n\\bar{f} = \\int_{0}^{1} \\frac{y(x)}{1+\\alpha} \\, dx = \\frac{1}{1+\\alpha} \\int_0^1 y(x) \\, dx = \\frac{\\bar{y}}{1+\\alpha}\n$$\n其中 $\\bar{y} = \\int_0^1 y(x) \\, dx$。\n因此，周期情况下的最优导数为：\n$$\nu_{P}^{\\star \\prime}(x) = f(x) - \\bar{f} = \\frac{y(x)}{1+\\alpha} - \\frac{\\bar{y}}{1+\\alpha} = \\frac{y(x)-\\bar{y}}{1+\\alpha}\n$$\n为了求得最小值 $J(u_P^\\star)$，我们将此导数代回泛函中：\n$$\nJ(u_{P}^{\\star}) = \\int_{0}^{1} \\left( (1+\\alpha)(u_{P}^{\\star \\prime})^2 - 2y u_{P}^{\\star \\prime} + y^2 \\right) \\, dx\n$$\n$$\nJ(u_{P}^{\\star}) = \\int_{0}^{1} \\left( (1+\\alpha)\\frac{(y-\\bar{y})^2}{(1+\\alpha)^2} - 2y\\frac{y-\\bar{y}}{1+\\alpha} + y^2 \\right) \\, dx\n$$\n$$\nJ(u_{P}^{\\star}) = \\frac{1}{1+\\alpha} \\int_{0}^{1} \\left( (y-\\bar{y})^2 - 2y(y-\\bar{y}) + (1+\\alpha)y^2 \\right) \\, dx\n$$\n$$\nJ(u_{P}^{\\star}) = \\frac{1}{1+\\alpha} \\int_{0}^{1} \\left( y^2 - 2y\\bar{y} + \\bar{y}^2 - 2y^2 + 2y\\bar{y} + y^2 + \\alpha y^2 \\right) \\, dx\n$$\n$$\nJ(u_{P}^{\\star}) = \\frac{1}{1+\\alpha} \\int_{0}^{1} \\left( \\alpha y^2 + \\bar{y}^2 \\right) \\, dx = \\frac{\\alpha}{1+\\alpha}\\int_{0}^{1} y(x)^2 \\, dx + \\frac{1}{1+\\alpha}\\int_{0}^{1} \\bar{y}^2 \\, dx\n$$\n由于 $\\bar{y}$ 是一个常数，所以 $\\int_0^1 \\bar{y}^2 dx = \\bar{y}^2$。因此，\n$$\nJ(u_{P}^{\\star}) = \\frac{\\alpha}{1+\\alpha}\\|y\\|_{L^2}^2 + \\frac{\\bar{y}^2}{1+\\alpha}\n$$\n\n**差值 $\\Delta J$ 的计算**\n\n我们需要计算 $\\Delta J = J(u_P^\\star) - J(u_D^\\star)$：\n$$\n\\Delta J = \\left(\\frac{\\alpha}{1+\\alpha}\\|y\\|_{L^2}^2 + \\frac{\\bar{y}^2}{1+\\alpha}\\right) - \\left(\\frac{\\alpha}{1+\\alpha}\\|y\\|_{L^2}^2\\right)\n$$\n$$\n\\Delta J = \\frac{\\bar{y}^2}{1+\\alpha}\n$$\n这是一个普适的结果。现在我们使用 $y(x) = 1 + \\cos(2\\pi x)$ 的具体形式来计算 $\\bar{y}$：\n$$\n\\bar{y} = \\int_{0}^{1} (1 + \\cos(2\\pi x)) \\, dx = \\left[ x + \\frac{1}{2\\pi}\\sin(2\\pi x) \\right]_0^1\n$$\n$$\n\\bar{y} = \\left(1 + \\frac{\\sin(2\\pi)}{2\\pi}\\right) - \\left(0 + \\frac{\\sin(0)}{2\\pi}\\right) = (1+0) - (0+0) = 1\n$$\n将 $\\bar{y}=1$ 代入 $\\Delta J$ 的表达式中：\n$$\n\\Delta J = \\frac{1^2}{1+\\alpha} = \\frac{1}{1+\\alpha}\n$$\n这就是最小目标值差值的最终闭式表达式。", "answer": "$$\\boxed{\\frac{1}{1+\\alpha}}$$", "id": "3383641"}]}