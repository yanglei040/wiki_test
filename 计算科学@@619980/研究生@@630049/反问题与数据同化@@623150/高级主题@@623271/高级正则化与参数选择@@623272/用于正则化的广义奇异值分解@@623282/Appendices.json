{"hands_on_practices": [{"introduction": "掌握了GSVD的理论之后，首要任务是将其应用于求解正则化问题。这个练习将引导你推导Tikhonov正则化解在GSVD基下的显式表达式，揭示广义奇异值如何作为“滤波器”来调节解的构成。通过此练习[@problem_id:3386295]，你将深入理解GSVD如何将复杂的优化问题对角化，从而为分析和计算提供便利。", "problem": "考虑矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和 $L \\in \\mathbb{R}^{p \\times n}$，其性质为堆叠矩阵 $\\begin{pmatrix} A \\\\ L \\end{pmatrix}$ 具有满列秩 $n$。假设矩阵对 $(A,L)$ 容许广义奇异值分解 (GSVD)，即存在正交矩阵 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{p \\times p}$，以及一个可逆矩阵 $Z \\in \\mathbb{R}^{n \\times n}$，连同满足对所有 $i \\in \\{1,\\dots,n\\}$ 都有 $\\alpha_i^{2} + \\beta_i^{2} = 1$ 的正标量 $\\{\\alpha_i\\}_{i=1}^{n}$ 和 $\\{\\beta_i\\}_{i=1}^{n}$，使得\n$$\nA = U \\,\\operatorname{diag}(\\alpha_1,\\dots,\\alpha_n,0,\\dots,0)\\, Z^{-1}, \\quad\nL = V \\,\\operatorname{diag}(\\beta_1,\\dots,\\beta_n,0,\\dots,0)\\, Z^{-1}.\n$$\n令 $\\{u_i\\}_{i=1}^{m}$ 表示 $U$ 的列向量，令 $\\{z_i\\}_{i=1}^{n}$ 表示 $Z$ 的列向量。给定一个数据向量 $b \\in \\mathbb{R}^{m}$，其展开式为 $b = \\sum_{i=1}^{m} c_i \\, u_i$，其中 $c_i = u_i^{\\top} b$，考虑 Tikhonov 正则化反问题\n$$\nx_{\\lambda} \\in \\underset{x \\in \\mathbb{R}^{n}}{\\arg\\min} \\ \\|A x - b\\|_{2}^{2} + \\lambda^{2} \\|L x\\|_{2}^{2}, \\quad \\lambda > 0.\n$$\n通过映射 $b \\mapsto A x_{\\lambda} = S_{\\lambda} b$ 定义影响矩阵 $S_{\\lambda} \\in \\mathbb{R}^{m \\times m}$。通过 GSVD 坐标系下的解耦法方程，引入与 $(A,L)$ 和正则化参数 $\\lambda$ 相关的标量滤波因子 $f_i(\\lambda)$。仅使用 Tikhonov 泛函和 GSVD 的基本性质，推导 $x_{\\lambda}$ 和 $S_{\\lambda}$ 关于 $f_i(\\lambda)$、系数 $c_i$ 以及向量 $u_i$ 和 $z_i$ 的解析表达式。你的最终表达式必须是闭式解，并且在所述秩条件下对所有 $\\lambda > 0$ 有效。最终答案必须是单一的解析表达式。不需要数值计算，也不涉及单位。", "solution": "所述问题是有效的。它在科学上基于反问题和数值线性代数的理论，特别是 Tikhonov 正则化和广义奇异值分解 (GSVD)。该问题是适定的、客观的，并包含获得唯一解所需的所有信息。\n\n对于给定的正则化参数 $\\lambda > 0$，Tikhonov 正则化解 $x_{\\lambda}$ 是泛函\n$$\nJ(x) = \\|A x - b\\|_{2}^{2} + \\lambda^{2} \\|L x\\|_{2}^{2}\n$$\n的唯一极小值点。通过将 $J(x)$ 关于 $x$ 的梯度设为零来找到极小值点。梯度为\n$$\n\\nabla_{x} J(x) = 2 A^{\\top}(A x - b) + 2 \\lambda^{2} L^{\\top}(L x).\n$$\n令 $\\nabla_{x} J(x) = 0$ 可得出 Tikhonov 问题的法方程：\n$$\n(A^{\\top}A + \\lambda^{2} L^{\\top}L) x = A^{\\top}b.\n$$\n问题陈述，堆叠矩阵 $\\begin{pmatrix} A \\\\ L \\end{pmatrix}$ 具有满列秩 $n$。这保证了对于任何 $\\lambda > 0$，矩阵 $(A^{\\top}A + \\lambda^{2} L^{\\top}L)$ 都是正定的，因此是可逆的，从而确保了 $x_{\\lambda}$ 的唯一解。\n\n现在我们将给定的矩阵对 $(A,L)$ 的 GSVD 代入法方程。分解如下：\n$$\nA = U C Z^{-1}, \\quad L = V S Z^{-1}\n$$\n其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{p \\times p}$ 是正交矩阵，$Z \\in \\mathbb{R}^{n \\times n}$ 是可逆矩阵，而 $C \\in \\mathbb{R}^{m \\times n}$ 和 $S \\in \\mathbb{R}^{p \\times n}$ 是定义如下的矩形对角矩阵\n$$\nC_{ij} = \\begin{cases} \\alpha_i  \\text{if } i=j \\le n \\\\ 0  \\text{otherwise} \\end{cases}, \\quad S_{ij} = \\begin{cases} \\beta_i  \\text{if } i=j \\le n \\\\ 0  \\text{otherwise} \\end{cases}.\n$$\n标量 $\\{\\alpha_i\\}_{i=1}^{n}$ 和 $\\{\\beta_i\\}_{i=1}^{n}$ 是正的，并满足 $\\alpha_i^2 + \\beta_i^2 = 1$。\n\n$A$ 和 $L$ 的转置分别为 $A^{\\top} = (Z^{-1})^{\\top} C^{\\top} U^{\\top}$ 和 $L^{\\top} = (Z^{-1})^{\\top} S^{\\top} V^{\\top}$。\n将这些代入法方程的左侧，得到：\n$$\nA^{\\top}A + \\lambda^{2} L^{\\top}L = (Z^{-1})^{\\top} C^{\\top} U^{\\top} U C Z^{-1} + \\lambda^{2} (Z^{-1})^{\\top} S^{\\top} V^{\\top} V S Z^{-1}.\n$$\n由于 $U$ 和 $V$ 是正交的，所以 $U^{\\top}U = I_m$ 且 $V^{\\top}V = I_p$。表达式简化为：\n$$\nA^{\\top}A + \\lambda^{2} L^{\\top}L = (Z^{-1})^{\\top} (C^{\\top}C + \\lambda^{2} S^{\\top}S) Z^{-1}.\n$$\n乘积 $C^{\\top}C$ 和 $S^{\\top}S$ 是 $n \\times n$ 的对角矩阵：\n$$\nC^{\\top}C = \\operatorname{diag}(\\alpha_1^2, \\alpha_2^2, \\dots, \\alpha_n^2) \\equiv \\Sigma_A^2\n$$\n$$\nS^{\\top}S = \\operatorname{diag}(\\beta_1^2, \\beta_2^2, \\dots, \\beta_n^2) \\equiv \\Sigma_L^2\n$$\n法方程的右侧是 $A^{\\top}b$。使用展开式 $b=\\sum_{j=1}^{m} c_j u_j$ 其中 $c_j = u_j^{\\top} b$，我们可以写出 $b = U c$，其中 $c = (c_1, \\dots, c_m)^{\\top}$。\n$$\nA^{\\top}b = (Z^{-1})^{\\top} C^{\\top} U^{\\top} (U c) = (Z^{-1})^{\\top} C^{\\top} c.\n$$\n向量 $C^{\\top}c$ 是一个 $n$ 维向量 $(\\alpha_1 c_1, \\dots, \\alpha_n c_n)^{\\top}$。\n\n法方程现在变为：\n$$\n(Z^{-1})^{\\top} (\\Sigma_A^2 + \\lambda^{2} \\Sigma_L^2) Z^{-1} x_{\\lambda} = (Z^{-1})^{\\top} C^{\\top} c.\n$$\n从左侧乘以 $Z^{\\top}$（由于 $Z$ 可逆，故 $Z^{\\top}$ 存在），我们得到：\n$$\n(\\Sigma_A^2 + \\lambda^{2} \\Sigma_L^2) Z^{-1} x_{\\lambda} = C^{\\top} c.\n$$\n我们定义一个新变量 $y = Z^{-1} x_{\\lambda}$。由于 $Z= [z_1, \\dots, z_n]$，我们有 $x_{\\lambda} = Z y = \\sum_{i=1}^n y_i z_i$。以 $y$ 表示的方程为：\n$$\n(\\Sigma_A^2 + \\lambda^{2} \\Sigma_L^2) y = C^{\\top} c.\n$$\n这是一个由 $n$ 个线性方程组成的解耦系统。第 $i$ 个方程是：\n$$\n(\\alpha_i^2 + \\lambda^2 \\beta_i^2) y_i = \\alpha_i c_i, \\quad i=1, \\dots, n.\n$$\n求解 $y_i$：\n$$\ny_i = \\frac{\\alpha_i c_i}{\\alpha_i^2 + \\lambda^2 \\beta_i^2}.\n$$\n解 $x_{\\lambda}$ 随后被重构为：\n$$\nx_{\\lambda} = \\sum_{i=1}^{n} y_i z_i = \\sum_{i=1}^{n} \\frac{\\alpha_i c_i}{\\alpha_i^2 + \\lambda^2 \\beta_i^2} z_i.\n$$\n根据要求，我们引入标量滤波因子 $f_i(\\lambda)$。在 Tikhonov 正则化的背景下，这些因子的一个标准定义是：\n$$\nf_i(\\lambda) = \\frac{\\alpha_i^2}{\\alpha_i^2 + \\lambda^2 \\beta_i^2}.\n$$\n使用此定义，$x_\\lambda$ 求和式中 $z_i$ 的系数可以被重写。由于 $\\alpha_i > 0$，我们有：\n$$\n\\frac{\\alpha_i c_i}{\\alpha_i^2 + \\lambda^2 \\beta_i^2} = \\frac{\\alpha_i^2}{\\alpha_i^2 + \\lambda^2 \\beta_i^2} \\frac{c_i}{\\alpha_i} = f_i(\\lambda) \\frac{c_i}{\\alpha_i}.\n$$\n因此，$x_{\\lambda}$ 用滤波因子表示的表达式为：\n$$\nx_{\\lambda} = \\sum_{i=1}^{n} f_i(\\lambda) \\frac{c_i}{\\alpha_i} z_i.\n$$\n接下来，我们推导影响矩阵 $S_{\\lambda}$ 的表达式，其定义为 $A x_{\\lambda} = S_{\\lambda} b$。我们计算 $A x_{\\lambda}$：\n$$\nA x_{\\lambda} = A \\left( \\sum_{j=1}^{n} y_j z_j \\right) = A Z y = (U C Z^{-1}) Z y = U C y.\n$$\n向量 $C y \\in \\mathbb{R}^m$ 的分量为 $(C y)_i = \\sum_{j=1}^n C_{ij} y_j$。由于 $C$ 的结构，当 $i \\le n$ 时有 $(C y)_i = \\alpha_i y_i$，当 $i > n$ 时有 $(C y)_i = 0$。代入 $y_i$ 的表达式：\n$$\n(C y)_i = \\alpha_i \\left( \\frac{\\alpha_i c_i}{\\alpha_i^2 + \\lambda^2 \\beta_i^2} \\right) = \\frac{\\alpha_i^2}{\\alpha_i^2 + \\lambda^2 \\beta_i^2} c_i = f_i(\\lambda) c_i, \\quad \\text{for } i=1, \\dots, n.\n$$\n现在我们可以将 $A x_{\\lambda}$ 写成 $U$ 的列向量的线性组合：\n$$\nA x_{\\lambda} = U (C y) = \\sum_{i=1}^{m} (C y)_i u_i = \\sum_{i=1}^{n} f_i(\\lambda) c_i u_i.\n$$\n为了求出 $S_{\\lambda}$，我们将此结果表示为一个作用于 $b$ 的矩阵。回想一下 $c_i = u_i^{\\top} b$：\n$$\nA x_{\\lambda} = \\sum_{i=1}^{n} f_i(\\lambda) (u_i^{\\top} b) u_i = \\sum_{i=1}^{n} f_i(\\lambda) u_i (u_i^{\\top} b) = \\left( \\sum_{i=1}^{n} f_i(\\lambda) u_i u_i^{\\top} \\right) b.\n$$\n通过将其与定义 $A x_{\\lambda} = S_{\\lambda} b$ 进行比较，我们确定影响矩阵 $S_{\\lambda}$：\n$$\nS_{\\lambda} = \\sum_{i=1}^{n} f_i(\\lambda) u_i u_i^{\\top}.\n$$\n这是一个 $m \\times m$ 矩阵，是外积之和。$x_{\\lambda}$ 和 $S_{\\lambda}$ 的表达式作为最终答案提供。", "answer": "$$\n\\boxed{x_{\\lambda} = \\sum_{i=1}^{n} f_i(\\lambda) \\frac{c_i}{\\alpha_i} z_i, \\quad S_{\\lambda} = \\sum_{i=1}^{n} f_i(\\lambda) u_i u_i^{\\top}}\n$$", "id": "3386295"}, {"introduction": "在实际应用中，问题设置的标度（scaling）往往是任意的，这引出了一个关键问题：解的结构是否依赖于这些选择？本练习探讨Tikhonov正则化在算子标度变换下的不变性。你将通过推导[@problem_id:3386267]发现，如何调整正则化参数以确保解的等价性，从而加深对正则化方法鲁棒性的理解。", "problem": "考虑一个带 Tikhonov 正则化的线性逆问题：给定矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和 $L \\in \\mathbb{R}^{p \\times n}$ 以及数据 $b \\in \\mathbb{R}^{m}$，定义 Tikhonov 正则化解\n$$\nx_{\\lambda} \\in \\arg\\min_{x \\in \\mathbb{R}^{n}} \\left\\{ \\|A x - b\\|_{2}^{2} + \\lambda^{2} \\|L x\\|_{2}^{2} \\right\\},\n$$\n其中 $\\lambda > 0$ 是正则化参数。假设矩阵对 $(A,L)$ 存在广义奇异值分解 (GSVD)，即存在正交矩阵 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{p \\times p}$、一个可逆矩阵 $X \\in \\mathbb{R}^{n \\times n}$，以及满足 $C^{\\top}C + S^{\\top}S = I$ 的非负对角矩阵 $C$ 和 $S$（尺寸相容），使得\n$$\nA = U \\begin{bmatrix} C  0 \\end{bmatrix} Q X^{-1}, \n\\qquad\nL = V \\begin{bmatrix} S  0 \\end{bmatrix} Q X^{-1},\n$$\n对于某个尺寸合适的正交矩阵 $Q$。广义奇异值定义为 $\\gamma_{i} = c_{i}/s_{i}$，适用于所有满足 $s_{i} > 0$ 的索引 $i$。\n\n现在考虑用正常数 $\\alpha > 0$ 和 $\\beta > 0$ 对算子进行重缩放：\n$$\n\\tilde{A} = \\alpha A, \n\\qquad \n\\tilde{L} = \\beta L.\n$$\n令 $\\tilde{\\gamma}_{i}$ 表示矩阵对 $(\\tilde{A},\\tilde{L})$ 的广义奇异值，其通过 $(\\tilde{A},\\tilde{L})$ 的 GSVD 进行类似定义。对于数据向量 $\\tilde{b} \\in \\mathbb{R}^{m}$，定义\n$$\n\\tilde{x}_{\\tilde{\\lambda}} \\in \\arg\\min_{x \\in \\mathbb{R}^{n}} \\left\\{ \\|\\tilde{A} x - \\tilde{b}\\|_{2}^{2} + \\tilde{\\lambda}^{2} \\|\\tilde{L} x\\|_{2}^{2} \\right\\}.\n$$\n\n任务：\n1. 从 GSVD 定义和正规方程出发，说明在缩放 $(\\tilde{A},\\tilde{L}) = (\\alpha A,\\beta L)$ 下广义奇异值如何变换，并用 $\\gamma_{i}$、$\\alpha$ 和 $\\beta$ 表示 $\\tilde{\\gamma}_{i}$。\n2. 确定 $\\tilde{b}$ 的选择和一个显式变换 $\\tilde{\\lambda} = \\tilde{\\lambda}(\\lambda,\\alpha,\\beta)$，使得对于任意数据向量 $b$，都有 $\\tilde{x}_{\\tilde{\\lambda}} = x_{\\lambda}$ 成立。你的最终答案必须是 $\\tilde{\\lambda}$ 作为 $\\lambda$、$\\alpha$ 和 $\\beta$ 的函数的单个显式闭式表达式（无单位）。", "solution": "对问题陈述进行分析后，认定其有效。该问题在科学上基于逆问题理论和数值线性代数，特别是 Tikhonov 正则化和广义奇异值分解 (GSVD)。此问题是适定的、客观的，并包含足够的信息来推导所要求的量。GSVD 的表述虽然因包含正交矩阵 $Q$ 而略显非标准，但在数学上等同于标准定义，且不引入矛盾。\n\n解题过程按问题陈述要求分为两部分。\n\n第 1 部分：广义奇异值 $\\gamma_i$ 的变换。\n\n矩阵对 $(A, L)$ 的广义奇异值 $\\gamma_i$ 定义为矩阵束 $(A^{\\top}A, L^{\\top}L)$ 的广义特征值 $\\mu_i = \\gamma_i^2$ 的平方根。这些特征值是广义特征值问题的解\n$$\nA^{\\top}A v_i = \\mu_i L^{\\top}L v_i\n$$\n其中 $v_i \\in \\mathbb{R}^n$ 为某个广义特征向量。\n\n现在，考虑缩放后的矩阵 $\\tilde{A} = \\alpha A$ 和 $\\tilde{L} = \\beta L$，其中 $\\alpha > 0$ 且 $\\beta > 0$。新的广义奇异值（记为 $\\tilde{\\gamma}_i$）对应于新矩阵束 $(\\tilde{A}^{\\top}\\tilde{A}, \\tilde{L}^{\\top}\\tilde{L})$ 的广义特征值 $\\tilde{\\mu}_i = \\tilde{\\gamma}_i^2$。新的广义特征值问题是\n$$\n\\tilde{A}^{\\top}\\tilde{A} w_i = \\tilde{\\mu}_i \\tilde{L}^{\\top}\\tilde{L} w_i.\n$$\n代入 $\\tilde{A}$ 和 $\\tilde{L}$ 的定义，我们得到\n$$\n(\\alpha A)^{\\top}(\\alpha A) w_i = \\tilde{\\mu}_i (\\beta L)^{\\top}(\\beta L) w_i\n$$\n$$\n\\alpha^2 (A^{\\top}A) w_i = \\tilde{\\mu}_i \\beta^2 (L^{\\top}L) w_i.\n$$\n由于 $\\alpha$ 和 $\\beta$ 非零，我们可以将方程重排为\n$$\nA^{\\top}A w_i = \\left( \\frac{\\beta^2}{\\alpha^2} \\tilde{\\mu}_i \\right) L^{\\top}L w_i.\n$$\n该方程与原始广义特征值问题具有相同的形式。这意味着广义特征向量是相同的（即，我们可以选择 $w_i = v_i$），并且广义特征值之间有如下关系\n$$\n\\mu_i = \\frac{\\beta^2}{\\alpha^2} \\tilde{\\mu}_i.\n$$\n解出 $\\tilde{\\mu}_i$ 可得\n$$\n\\tilde{\\mu}_i = \\frac{\\alpha^2}{\\beta^2} \\mu_i.\n$$\n广义奇异值是广义特征值的正平方根，因此 $\\gamma_i = \\sqrt{\\mu_i}$ 且 $\\tilde{\\gamma}_i = \\sqrt{\\tilde{\\mu}_i}$。对上述关系式取平方根可得\n$$\n\\tilde{\\gamma}_i = \\sqrt{\\frac{\\alpha^2}{\\beta^2} \\mu_i} = \\frac{\\alpha}{\\beta} \\sqrt{\\mu_i} = \\frac{\\alpha}{\\beta} \\gamma_i,\n$$\n因为 $\\alpha, \\beta, \\gamma_i, \\tilde{\\gamma}_i$ 都被定义为非负（且在数值有意义时为正）。\n\n第 2 部分：为确保解不变性，确定 $\\tilde{b}$ 和 $\\tilde{\\lambda}$。\n\n原始的 Tikhonov 正则化解 $x_{\\lambda}$ 是目标泛函的最小化子\n$$\nJ(x) = \\|A x - b\\|_{2}^{2} + \\lambda^{2} \\|L x\\|_{2}^{2}.\n$$\n缩放后的问题旨在寻找目标泛函的最小化子 $\\tilde{x}_{\\tilde{\\lambda}}$\n$$\n\\tilde{J}(x) = \\|\\tilde{A} x - \\tilde{b}\\|_{2}^{2} + \\tilde{\\lambda}^{2} \\|\\tilde{L} x\\|_{2}^{2}.\n$$\n我们的任务是找到 $\\tilde{b}$ 的一个选择和 $\\tilde{\\lambda}$ 的一个关系式，使得对于任何数据向量 $b$，都有 $\\tilde{x}_{\\tilde{\\lambda}} = x_{\\lambda}$。这意味着对于任何 $b$，$J(x)$ 和 $\\tilde{J}(x)$ 的最小化子集合必须相同。如果一个目标泛函是另一个目标泛函的正数倍加上一个不依赖于优化变量 $x$ 的常数项，则两者具有相同的最小化子。\n\n我们将 $\\tilde{A} = \\alpha A$ 和 $\\tilde{L} = \\beta L$ 代入 $\\tilde{J}(x)$：\n$$\n\\tilde{J}(x) = \\|\\alpha A x - \\tilde{b}\\|_{2}^{2} + \\tilde{\\lambda}^{2} \\|\\beta L x\\|_{2}^{2}.\n$$\n从范数中提出缩放常数 $\\alpha$ 和 $\\beta$，我们得到\n$$\n\\tilde{J}(x) = \\alpha^2 \\|A x - \\frac{1}{\\alpha}\\tilde{b}\\|_{2}^{2} + \\beta^2 \\tilde{\\lambda}^{2} \\|L x\\|_{2}^{2}.\n$$\n为了使 $J(x)$ 和 $\\tilde{J}(x)$ 的最小化子相同，这两个泛函必须在结构上等价。让我们比较一下 $J(x)$ 和 $\\tilde{J}(x)$。\n$$\nJ(x) = \\|A x - b\\|_{2}^{2} + \\lambda^{2} \\|L x\\|_{2}^{2}\n$$\n$$\n\\tilde{J}(x) = \\alpha^2 \\|A x - \\frac{1}{\\alpha}\\tilde{b}\\|_{2}^{2} + \\beta^2 \\tilde{\\lambda}^{2} \\|L x\\|_{2}^{2}\n$$\n确保这两个泛函等价的最直接方法是使 $\\tilde{J}(x)$ 成为 $J(x)$ 的常数倍。我们尝试令 $\\tilde{J}(x) = \\alpha^2 J(x)$。这需要匹配相应的项。\n首先，对于数据保真项（第一项），我们需要\n$$\n\\alpha^2 \\|A x - \\frac{1}{\\alpha}\\tilde{b}\\|_{2}^{2} = \\alpha^2 \\|A x - b\\|_{2}^{2}.\n$$\n如果我们选择\n$$\n\\frac{1}{\\alpha}\\tilde{b} = b \\implies \\tilde{b} = \\alpha b,\n$$\n则该条件得到满足。这是对 $\\tilde{b}$ 的一个有效选择，它依赖于 $b$，这是允许的。通过这个选择，保真项相匹配。\n\n接下来，我们匹配正则化项（第二项）：\n$$\n\\beta^2 \\tilde{\\lambda}^{2} \\|L x\\|_{2}^{2} = \\alpha^2 (\\lambda^{2} \\|L x\\|_{2}^{2}).\n$$\n这个等式必须对任何 $x$ 都成立，因此我们必须使系数相等：\n$$\n\\beta^2 \\tilde{\\lambda}^{2} = \\alpha^2 \\lambda^{2}.\n$$\n由于 $\\alpha, \\beta, \\lambda, \\tilde{\\lambda}$ 均为正数，我们可以对两边取平方根：\n$$\n\\beta \\tilde{\\lambda} = \\alpha \\lambda.\n$$\n解出 $\\tilde{\\lambda}$ 得到所需变换：\n$$\n\\tilde{\\lambda} = \\lambda \\frac{\\alpha}{\\beta}.\n$$\n通过选择 $\\tilde{b} = \\alpha b$ 和 $\\tilde{\\lambda} = \\lambda \\frac{\\alpha}{\\beta}$，缩放后的泛函变为 $\\tilde{J}(x) = \\alpha^2 J(x)$。由于 $\\alpha^2 > 0$，最小化 $\\tilde{J}(x)$ 等价于最小化 $J(x)$，因此对于任何数据向量 $b$，都有 $\\tilde{x}_{\\tilde{\\lambda}} = x_{\\lambda}$。\n\n问题要求给出 $\\tilde{\\lambda}$ 的单个显式闭式表达式。", "answer": "$$\n\\boxed{\\lambda \\frac{\\alpha}{\\beta}}\n$$", "id": "3386267"}, {"introduction": "理论与实践的桥梁在于处理含噪数据。GSVD提供了一个理想的框架来区分信号和噪声，但如何系统地做到这一点呢？本练习将指导你设计一个基于GSVD系数的统计诊断工具，用于识别数据中可能由噪声主导的成分。这个练习[@problem_id:3386249]将代数分解与统计假设检验相结合，展示了如何在实践中做出关于数据可信度的明智决策。", "problem": "考虑一个带Tikhonov型正则化的线性反问题，其中矩阵对 $(A,L) \\in \\mathbb{R}^{6 \\times 6} \\times \\mathbb{R}^{6 \\times 6}$ 具有广义奇异值分解 (GSVD) 形式 $A = U C Z^{-1}$ 和 $L = V S Z^{-1}$，其中 $U, V \\in \\mathbb{R}^{6 \\times 6}$ 是正交矩阵，$Z \\in \\mathbb{R}^{6 \\times 6}$ 是可逆矩阵，$C = \\operatorname{diag}(c_{1},\\dots,c_{6})$，$S = \\operatorname{diag}(s_{1},\\dots,s_{6})$ 是对角矩阵，且对所有 $i$ 满足 $c_{i}^{2} + s_{i}^{2} = 1$。在本问题中，假设一个由 $U = I_{6}$、$V = I_{6}$、$Z = I_{6}$ 给出的特别简单的 GSVD 三元组，其中\n$$\nC = \\operatorname{diag}(c_{1},\\dots,c_{6}), \\quad c = \\big(0.98,\\,0.80,\\,0.50,\\,0.25,\\,0.10,\\,0.05\\big),\n$$\n且 $S = \\operatorname{diag}(s_{1},\\dots,s_{6})$ 由 $s_{i} = \\sqrt{1 - c_{i}^{2}}$ 确定。\n\n您观测到形式为 $y = A x_{\\text{true}} + e$ 的含噪数据 $y \\in \\mathbb{R}^{6}$，其中 $x_{\\text{true}} \\in \\mathbb{R}^{6}$ 未知，噪声 $e$ 是协方差为 $\\sigma^{2} I_{6}$ 的零均值高斯噪声。噪声水平为 $\\sigma = 0.05$，观测到的数据为\n$$\ny = \\begin{pmatrix} 0.82 \\\\ 0.56 \\\\ 0.17 \\\\ 0.06 \\\\ 0.03 \\\\ 0.02 \\end{pmatrix}.\n$$\n\n在由 $U$ 定义的 GSVD 数据基中，数据系数为 $\\widehat{y}_{i} = u_{i}^{\\top} y$，其中 $i \\in \\{1,\\dots,6\\}$（$u_{i}$ 表示 $U$ 的第 $i$ 列）。请仅使用关于高斯噪声的基本概率事实和适用于独立高斯变量最大值的基本界，设计一个诊断方法，以识别一个过渡索引 $k^{\\star}$，使得在总体族系假警报概率至多为 $\\alpha = 0.05$ 的情况下，所有系数 $\\{ \\widehat{y}_{i} \\}_{i \\ge k^{\\star}}$ 都与噪声主导的情况一致。然后将您的诊断方法应用于给定的 $y$ 并计算得到的整数索引 $k^{\\star}$。报告 $k^{\\star}$ 的单个整数值；无需四舍五入，不涉及单位。", "solution": "问题陈述已经过验证，被认为是有效的。它在科学上基于线性反问题和统计学领域，是适定的、客观的，并包含构建和解决问题所需的所有必要信息。\n\n该问题要求我们设计一种诊断方法，为一组数据系数找到一个过渡索引 $k^{\\star}$。该索引应标记一个点，在此点之后的所有系数都与被噪声主導的情况一致。该诊断方法必须遵守指定的族系假警报概率。\n\n数据模型由 $y = A x_{\\text{true}} + e$ 给出，其中 $A \\in \\mathbb{R}^{6 \\times 6}$，$x_{\\text{true}} \\in \\mathbb{R}^{6}$，$e \\in \\mathbb{R}^{6}$ 是一个噪声分量向量。噪声 $e$ 被指定为协方差为 $\\sigma^{2} I_{6}$ 的零均值高斯噪声，其中 $\\sigma = 0.05$。这意味着 $e$ 的分量（记为 $e_i$）是来自正态分布 $\\mathcal{N}(0, \\sigma^2)$ 的独立同分布 (i.i.d.) 随机变量。\n\n数据系数在 GSVD 基中定义为 $\\widehat{y}_{i} = u_{i}^{\\top} y$，其中 $u_i$ 是正交矩阵 $U$ 的第 $i$ 列。问题指定了一个简化的 GSVD，其中 $U=I_{6}$。单位矩阵 $I_6$ 的列是标准基向量 $u_i = e_i$。因此，数据系数就是数据向量本身的分量：\n$$\n\\widehat{y}_{i} = e_{i}^{\\top} y = y_i\n$$\n观测到的数据向量为 $y = \\begin{pmatrix} 0.82 & 0.56 & 0.17 & 0.06 & 0.03 & 0.02 \\end{pmatrix}^{\\top}$。因此，系数为 $|\\widehat{y}_1| = 0.82$、 $|\\widehat{y}_2| = 0.56$、 $|\\widehat{y}_3| = 0.17$、 $|\\widehat{y}_4| = 0.06$、 $|\\widehat{y}_5| = 0.03$ 和 $|\\widehat{y}_6| = 0.02$。\n\n我们需要为每个系数 $\\widehat{y}_i$ 确定它是否“与噪声主导的情况一致”。我们将其形式化为一个统计假设检验。对于每个索引 $i \\in \\{1, \\dots, 6\\}$，我们陈述原假设 $H_{0,i}$，即第 $i$ 个系数仅由噪声构成。\n第 $i$ 个系数的完整表达式是 $\\widehat{y}_i = u_i^\\top(A x_{\\text{true}} + e)$。给定 $A = U C Z^{-1}$ 以及特定值 $U=I_6, Z=I_6$，表达式变为 $\\widehat{y}_i = e_i^\\top(C x_{\\text{true}} + e) = c_i x_{\\text{true},i} + e_i$。因此，原假设 $H_{0,i}$ 对应于信号部分为零：$c_i x_{\\text{true},i} = 0$。在 $H_{0,i}$ 之下，系数 $\\widehat{y}_i = e_i$ 是一个从 $\\mathcal{N}(0, \\sigma^2)$ 中抽样的随机变量。\n\n任务要求诊断方法的“总体族系假警报概率至多为 $\\alpha = 0.05$”。如果我们拒绝实际上为真的 $H_{0,i}$（即，当系数实际上只是噪声时，我们将其分类为信号），就会发生假警报。族系错误率 (FWER) 是在全部 $N=6$ 个检验中发生一次或多次此类假警报的概率。\n\n为了将 FWER 控制在水平 $\\alpha$，我们采用 Bonferroni 校正。这是并集界（Boole 不等式）的直接应用，这与问题提示中“使用适用于独立高斯变量最大值的基本界”相符。Bonferroni 方法要求对于 $N$ 个检验中的每一个，显著性水平必须设置为 $\\alpha/N$。\n\n对于单个系数 $\\widehat{y}_i$，我们进行双边检验。如果 $|\\widehat{y}_i|$ 异常大，我们就拒绝 $H_{0,i}$。在 $H_{0,i}$ 之下，量 $\\widehat{y}_i/\\sigma$ 服从标准正态分布，$Z \\sim \\mathcal{N}(0,1)$。对于第 $i$ 个检验，假警报的概率是 $P(|\\widehat{y}_i| > T)$，其中 $T$ 是某个阈值。我们将此概率设置为 $\\alpha/N$。\n$$\nP(|\\widehat{y}_i| > T \\mid H_{0,i}) = P\\left(\\left|\\frac{\\widehat{y}_i}{\\sigma}\\right| > \\frac{T}{\\sigma}\\right) = P\\left(|Z| > \\frac{T}{\\sigma}\\right) = \\frac{\\alpha}{N}\n$$\n这意味着 $2 \\left(1 - \\Phi\\left(\\frac{T}{\\sigma}\\right)\\right) = \\frac{\\alpha}{N}$，其中 $\\Phi$ 是标准正态分布的累积分布函数 (CDF)。解出阈值 $T$：\n$$\n\\Phi\\left(\\frac{T}{\\sigma}\\right) = 1 - \\frac{\\alpha}{2N} \\implies T = \\sigma \\cdot \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2N}\\right)\n$$\n我们现在使用给定值计算此阈值 $T$：\n- 噪声水平 $\\sigma = 0.05$。\n- 检验数量 $N = 6$。\n- 族系显著性水平 $\\alpha = 0.05$。\n\n反 CDF 的参数是 $1 - \\frac{0.05}{2 \\times 6} = 1 - \\frac{0.05}{12} \\approx 1 - 0.0041667 = 0.9958333$。\n使用标准统计软件或表格查找正态分布的反 CDF，我们找到临界值：\n$$\nz_{\\text{crit}} = \\Phi^{-1}(0.9958333) \\approx 2.638\n$$\n现在我们可以计算决策阈值 $T$：\n$$\nT = \\sigma \\cdot z_{\\text{crit}} = 0.05 \\times 2.638 = 0.1319\n$$\n诊断方法如下：如果 $|\\widehat{y}_i| > T$，则系数 $\\widehat{y}_i$ 被分类为信号主导的；如果 $|\\widehat{y}_i| \\le T$，则与噪声一致。\n\n我们将此诊断方法应用于我们的数据系数 $|\\widehat{y}_i| = |y_i|$：\n- $|\\widehat{y}_1| = 0.82 > 0.1319$ (信号)\n- $|\\widehat{y}_2| = 0.56 > 0.1319$ (信号)\n- $|\\widehat{y}_3| = 0.17 > 0.1319$ (信号)\n- $|\\widehat{y}_4| = 0.06 \\le 0.1319$ (噪声)\n- $|\\widehat{y}_5| = 0.03 \\le 0.1319$ (噪声)\n- $|\\widehat{y}_6| = 0.02 \\le 0.1319$ (噪声)\n\n问题将过渡索引 $k^{\\star}$ 定义为最小的整数索引，使得所有系数 $\\{\\widehat{y}_i\\}_{i \\ge k^{\\star}}$ 都与噪声主导的情况一致。这意味着我们在寻找最小的 $k$，使得对于所有 $i \\ge k$，条件 $|\\widehat{y}_i| \\le T$ 都成立。\n\n- 当 $k=1$ 时，条件不成立，因为 $|\\widehat{y}_1| > T$。\n- 当 $k=2$ 时，条件不成立，因为 $|\\widehat{y}_2| > T$。\n- 当 $k=3$ 时，条件不成立，因为 $|\\widehat{y}_3| > T$。\n- 当 $k=4$ 时，条件要求 $|\\widehat{y}_4| \\le T$、 $|\\widehat{y}_5| \\le T$ 和 $|\\widehat{y}_6| \\le T$。这三个都为真。\n\n由于 $k=4$ 是使该条件成立的最小索引，因此过渡索引为 $k^{\\star} = 4$。", "answer": "$$\n\\boxed{4}\n$$", "id": "3386249"}]}