{"hands_on_practices": [{"introduction": "理论学习的下一步是将其应用于具体情境。本练习将通过一个经典的线性高斯逆问题，把主动子空间维数约减的抽象概念与参数可辨识性这一核心问题联系起来。通过推导主动子空间矩阵 $C$ 并计算其特征向量，您将亲手揭示这些特征向量如何精确地对应于由前向算子奇异值分解所确定的可辨识参数方向。[@problem_id:3362741]", "problem": "考虑一个带有加性高斯噪声的线性逆问题，由 $y = A \\theta + \\eta$ 给出，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个已知的前向算子，$\\theta \\in \\mathbb{R}^{n}$ 是我们感兴趣的参数，$\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\eta})$ 是高斯噪声，其协方差矩阵 $\\Gamma_{\\eta} \\in \\mathbb{R}^{m \\times m}$ 是已知的对称正定矩阵。负对数似然（不考虑与 $\\theta$ 无关的加性常数）定义为\n$\\ell(\\theta; y) = \\frac{1}{2} (y - A \\theta)^{\\top} \\Gamma_{\\eta}^{-1} (y - A \\theta)$。\n定义主动子空间矩阵\n$C = \\mathbb{E}_{y \\mid \\theta} \\left[ \\nabla_{\\theta} \\ell(\\theta; y) \\, \\nabla_{\\theta} \\ell(\\theta; y)^{\\top} \\right]$，\n其中期望是关于给定 $\\theta$ 时 $y$ 的条件分布计算的。仅使用高斯似然的基本定义以及梯度和期望的基本性质来：\n\n1. 用 $A$ 和 $\\Gamma_{\\eta}$ 显式地推导出 $C$，并证明 $C$ 的特征向量与 $\\Gamma_{\\eta}^{-1/2} A$ 的非零奇异值所对应的右奇异向量重合。解释非主动方向（即与 $C$ 的零特征值相关联的方向）与逆问题中的不可辨识性之间的关系。\n\n2. 对于具体实例\n$A = \\begin{pmatrix} 2  0  0 \\\\ 0  1  1 \\end{pmatrix}$ 和 $\\Gamma_{\\eta} = \\mathrm{diag}(1, 4)$，\n计算 $C$ 的特征值，并确定最小主动维度 $r$，使得最大的 $r$ 个特征值之和至少占 $C$ 的迹的 $\\alpha = 0.95$；也就是说，找到最小的整数 $r$，满足\n$\\sum_{i=1}^{r} \\lambda_{i} \\ge \\alpha \\sum_{i=1}^{n} \\lambda_{i}$，\n其中 $\\lambda_{1} \\ge \\lambda_{2} \\ge \\cdots \\ge \\lambda_{n} \\ge 0$ 是 $C$ 按非增序排列的特征值。\n\n最终答案以 $r$ 的单个整数值形式给出。无需单位。除精确算术外，无需进行四舍五入。", "solution": "该问题分为两部分。首先，我们为一个线性高斯逆问题推导主动子空间矩阵 $C$ 并分析其性质。其次，我们为一个具体实例计算 $C$，并根据其特征值谱确定最小主动维度 $r$。\n\n### 第1部分：主动子空间矩阵 $C$ 的推导与分析\n\n负对数似然函数由下式给出\n$$ \\ell(\\theta; y) = \\frac{1}{2} (y - A \\theta)^{\\top} \\Gamma_{\\eta}^{-1} (y - A \\theta) $$\n其中 $y \\in \\mathbb{R}^{m}$，$\\theta \\in \\mathbb{R}^{n}$，$A \\in \\mathbb{R}^{m \\times n}$，且 $\\Gamma_{\\eta} \\in \\mathbb{R}^{m \\times m}$ 是对称正定的。\n\n**1. $C$ 的推导**\n\n首先，我们计算 $\\ell(\\theta; y)$ 关于 $\\theta$ 的梯度。展开二次型：\n$$ \\ell(\\theta; y) = \\frac{1}{2} (y^{\\top}\\Gamma_{\\eta}^{-1}y - y^{\\top}\\Gamma_{\\eta}^{-1}A\\theta - \\theta^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}y + \\theta^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}A\\theta) $$\n由于 $\\ell(\\theta; y)$ 是一个标量，项 $y^{\\top}\\Gamma_{\\eta}^{-1}A\\theta$ 等于其转置。因为 $\\Gamma_{\\eta}$ 是对称的，所以矩阵 $\\Gamma_{\\eta}^{-1}$ 也是对称的。因此，$(y^{\\top}\\Gamma_{\\eta}^{-1}A\\theta)^{\\top} = \\theta^{\\top}A^{\\top}(\\Gamma_{\\eta}^{-1})^{\\top}y = \\theta^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}y$。表达式简化为：\n$$ \\ell(\\theta; y) = \\frac{1}{2} (y^{\\top}\\Gamma_{\\eta}^{-1}y - 2 \\theta^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}y + \\theta^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}A\\theta) $$\n使用标准的矩阵微积分恒等式，对于对称矩阵 $B$，有 $\\nabla_{x}(c^{\\top}x) = c$ 和 $\\nabla_{x}(x^{\\top}Bx) = 2Bx$，我们求得关于 $\\theta$ 的梯度：\n$$ \\nabla_{\\theta} \\ell(\\theta; y) = \\frac{1}{2} (-2 A^{\\top}\\Gamma_{\\eta}^{-1}y + 2 A^{\\top}\\Gamma_{\\eta}^{-1}A\\theta) = A^{\\top}\\Gamma_{\\eta}^{-1}A\\theta - A^{\\top}\\Gamma_{\\eta}^{-1}y = A^{\\top}\\Gamma_{\\eta}^{-1}(A\\theta - y) $$\n主动子空间矩阵 $C$ 定义为此梯度的外积的期望：\n$$ C = \\mathbb{E}_{y \\mid \\theta} \\left[ \\nabla_{\\theta} \\ell(\\theta; y) \\, \\nabla_{\\theta} \\ell(\\theta; y)^{\\top} \\right] $$\n代入梯度的表达式：\n$$ C = \\mathbb{E}_{y \\mid \\theta} \\left[ \\left( A^{\\top}\\Gamma_{\\eta}^{-1}(A\\theta - y) \\right) \\left( A^{\\top}\\Gamma_{\\eta}^{-1}(A\\theta - y) \\right)^{\\top} \\right] $$\n$$ C = \\mathbb{E}_{y \\mid \\theta} \\left[ A^{\\top}\\Gamma_{\\eta}^{-1}(A\\theta - y)(A\\theta - y)^{\\top}\\Gamma_{\\eta}^{-1}A \\right] $$\n由于 $A$ 和 $\\Gamma_{\\eta}$ 相对于关于 $y$ 的期望是常数，我们可以将它们移到期望外面：\n$$ C = A^{\\top}\\Gamma_{\\eta}^{-1} \\mathbb{E}_{y \\mid \\theta} \\left[ (A\\theta - y)(A\\theta - y)^{\\top} \\right] \\Gamma_{\\eta}^{-1}A $$\n根据问题陈述，$y = A\\theta + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\eta})$。这意味着 $A\\theta - y = -\\eta$。因此，期望是关于 $(-\\eta)(-\\eta)^{\\top} = \\eta\\eta^{\\top}$ 的。\n$$ \\mathbb{E}_{y \\mid \\theta} \\left[ (A\\theta - y)(A\\theta - y)^{\\top} \\right] = \\mathbb{E}[\\eta\\eta^{\\top}] $$\n根据定义，零均值随机向量 $\\eta$ 的协方差矩阵是 $\\text{Cov}(\\eta) = \\mathbb{E}[(\\eta-\\mathbb{E}[\\eta])(\\eta-\\mathbb{E}[\\eta])^{\\top}] = \\mathbb{E}[\\eta\\eta^{\\top}]$。我们已知 $\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\eta})$，所以 $\\mathbb{E}[\\eta\\eta^{\\top}] = \\Gamma_{\\eta}$。\n将此代回 $C$ 的表达式：\n$$ C = A^{\\top}\\Gamma_{\\eta}^{-1} \\Gamma_{\\eta} \\Gamma_{\\eta}^{-1}A = A^{\\top}\\Gamma_{\\eta}^{-1}A $$\n这就是 $C$ 的显式形式。它也是 $\\theta$ 的费雪信息矩阵。\n\n**2. $C$ 的特征向量与 $\\Gamma_{\\eta}^{-1/2} A$ 的奇异向量**\n\n令 $B = \\Gamma_{\\eta}^{-1/2} A$。由于 $\\Gamma_{\\eta}$ 是对称正定的，其逆矩阵 $\\Gamma_{\\eta}^{-1}$ 和平方根 $\\Gamma_{\\eta}^{-1/2}$ 存在且也是对称正定的。我们可以将 $C$ 表示为：\n$$ C = A^{\\top}\\Gamma_{\\eta}^{-1}A = A^{\\top}(\\Gamma_{\\eta}^{-1/2})^{\\top}\\Gamma_{\\eta}^{-1/2}A = ( \\Gamma_{\\eta}^{-1/2} A )^{\\top} ( \\Gamma_{\\eta}^{-1/2} A ) = B^{\\top}B $$\n设 $B = \\Gamma_{\\eta}^{-1/2} A$ 的奇异值分解 (SVD) 为 $B = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是由奇异值 $\\sigma_{i} \\ge 0$ 构成的对角矩阵。$V$ 的列向量是 $B$ 的右奇异向量。\n现在，将 SVD 代入 $C$ 的表达式中：\n$$ C = B^{\\top}B = (U \\Sigma V^{\\top})^{\\top} (U \\Sigma V^{\\top}) = (V \\Sigma^{\\top} U^{\\top}) (U \\Sigma V^{\\top}) $$\n由于 $U$ 是正交的，所以 $U^{\\top}U = I_{m}$。\n$$ C = V \\Sigma^{\\top} (U^{\\top}U) \\Sigma V^{\\top} = V (\\Sigma^{\\top}\\Sigma) V^{\\top} $$\n矩阵 $V$ 是正交的，所以 $V^{\\top} = V^{-1}$。方程 $C = V (\\Sigma^{\\top}\\Sigma) V^{-1}$ 是 $C$ 的特征分解。$V$ 的列向量是 $C$ 的特征向量。矩阵 $\\Sigma^{\\top}\\Sigma$ 是一个 $n \\times n$ 的对角矩阵，其对角线上的元素对于 $i=1, \\dots, \\min(m,n)$ 是 $\\sigma_i^2$，其余为零。因此，$C$ 的特征值是 $B = \\Gamma_{\\eta}^{-1/2} A$ 的奇异值的平方。\n因此，$C$ 的特征向量恰好是 $\\Gamma_{\\eta}^{-1/2} A$ 的右奇异向量。\n\n**3. 非主动方向与不可辨识性**\n\n非主动方向定义为与零特征值相关联的 $C$ 的特征向量。设 $v$ 是 $C$ 的一个特征值为 $\\lambda=0$ 的特征向量。那么，$Cv=0$。\n$$ C v = (A^{\\top}\\Gamma_{\\eta}^{-1}A)v = 0 $$\n从左侧乘以 $v^{\\top}$：\n$$ v^{\\top}A^{\\top}\\Gamma_{\\eta}^{-1}A v = 0 $$\n这可以写成 $(Av)^{\\top}\\Gamma_{\\eta}^{-1}(Av) = 0$。令 $w = Av$。那么 $w^{\\top}\\Gamma_{\\eta}^{-1}w = 0$。由于 $\\Gamma_{\\eta}$ 是对称正定的，$\\Gamma_{\\eta}^{-1}$ 也是对称正定的。根据正定性的定义，对于任何非零向量 $w \\in \\mathbb{R}^m$，都有 $w^{\\top}\\Gamma_{\\eta}^{-1}w > 0$。因此，$w^{\\top}\\Gamma_{\\eta}^{-1}w=0$ 意味着 $w=0$。\n所以，我们必须有 $Av = 0$。这意味着 $v$ 位于前向算子 $A$ 的零空间中。$A$ 的零空间中的任何向量都无法从数据中辨识出来。具体来说，如果我们用 $v$ 的一个倍数来扰动参数向量 $\\theta$，即 $\\theta' = \\theta + k v$（对于某个标量 $k$），模型的预测保持不变：\n$$ A \\theta' = A(\\theta + k v) = A\\theta + k(Av) = A\\theta + k(0) = A\\theta $$\n由于数据 $y$ 仅通过 $A\\theta$ 依赖于 $\\theta$，数据无法提供任何信息来区分 $\\theta$ 和 $\\theta'$。沿方向 $v$ 的参数组合是不可辨识的。由 $C$ 的零特征值所对应的特征向量张成的空间就是 $A$ 的零空间，它代表了所有不可辨识的参数方向的集合。\n\n### 第2部分：具体计算\n\n我们得到具体实例：\n$$ A = \\begin{pmatrix} 2  0  0 \\\\ 0  1  1 \\end{pmatrix} \\quad \\text{和} \\quad \\Gamma_{\\eta} = \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix} $$\n首先，我们计算协方差矩阵的逆：\n$$ \\Gamma_{\\eta}^{-1} = \\begin{pmatrix} 1^{-1}  0 \\\\ 0  4^{-1} \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  \\frac{1}{4} \\end{pmatrix} $$\n接下来，我们计算主动子空间矩阵 $C = A^{\\top}\\Gamma_{\\eta}^{-1}A$。$A$ 的转置是：\n$$ A^{\\top} = \\begin{pmatrix} 2  0 \\\\ 0  1 \\\\ 0  1 \\end{pmatrix} $$\n现在，我们进行矩阵乘法：\n$$ C = \\begin{pmatrix} 2  0 \\\\ 0  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  \\frac{1}{4} \\end{pmatrix} \\begin{pmatrix} 2  0  0 \\\\ 0  1  1 \\end{pmatrix} $$\n$$ C = \\begin{pmatrix} 2  0 \\\\ 0  \\frac{1}{4} \\\\ 0  \\frac{1}{4} \\end{pmatrix} \\begin{pmatrix} 2  0  0 \\\\ 0  1  1 \\end{pmatrix} = \\begin{pmatrix} (2)(2) + (0)(0)  (2)(0) + (0)(1)  (2)(0) + (0)(1) \\\\ (0)(2) + (\\frac{1}{4})(0)  (0)(0) + (\\frac{1}{4})(1)  (0)(0) + (\\frac{1}{4})(1) \\\\ (0)(2) + (\\frac{1}{4})(0)  (0)(0) + (\\frac{1}{4})(1)  (0)(0) + (\\frac{1}{4})(1) \\end{pmatrix} $$\n$$ C = \\begin{pmatrix} 4  0  0 \\\\ 0  \\frac{1}{4}  \\frac{1}{4} \\\\ 0  \\frac{1}{4}  \\frac{1}{4} \\end{pmatrix} $$\n为了求 $C$ 的特征值 $\\lambda$，我们解特征方程 $\\det(C - \\lambda I) = 0$：\n$$ \\det \\begin{pmatrix} 4-\\lambda  0  0 \\\\ 0  \\frac{1}{4}-\\lambda  \\frac{1}{4} \\\\ 0  \\frac{1}{4}  \\frac{1}{4}-\\lambda \\end{pmatrix} = 0 $$\n$$ (4-\\lambda) \\left[ \\left(\\frac{1}{4}-\\lambda\\right)^2 - \\left(\\frac{1}{4}\\right)^2 \\right] = 0 $$\n这个方程立即给出一个特征值：$\\lambda = 4$。另外两个特征值可以从方括号中的项求得：\n$$ \\left(\\frac{1}{4}-\\lambda\\right)^2 - \\frac{1}{16} = 0 \\implies \\left(\\frac{1}{4}-\\lambda\\right)^2 = \\frac{1}{16} $$\n$$ \\frac{1}{4}-\\lambda = \\pm \\frac{1}{4} $$\n这给出了两种可能性：\n1. $\\frac{1}{4}-\\lambda = \\frac{1}{4} \\implies \\lambda = 0$\n2. $\\frac{1}{4}-\\lambda = -\\frac{1}{4} \\implies \\lambda = \\frac{1}{4} + \\frac{1}{4} = \\frac{1}{2}$\n$C$ 的特征值为 $\\{4, \\frac{1}{2}, 0\\}$。我们按非增序排列它们：$\\lambda_{1} = 4$，$\\lambda_{2} = \\frac{1}{2}$，$\\lambda_{3} = 0$。\n\n$C$ 的迹是其特征值之和：\n$$ \\text{Tr}(C) = \\sum_{i=1}^{3} \\lambda_{i} = 4 + \\frac{1}{2} + 0 = 4.5 $$\n我们需要找到最小的整数 $r$，使得前 $r$ 个最大特征值的和至少是总和（迹）的 $\\alpha = 0.95$。阈值为：\n$$ \\alpha \\sum_{i=1}^{3} \\lambda_{i} = 0.95 \\times 4.5 = \\frac{19}{20} \\times \\frac{9}{2} = \\frac{171}{40} = 4.275 $$\n我们检查有序特征值的累积和：\n对于 $r=1$：\n$$ \\sum_{i=1}^{1} \\lambda_{i} = \\lambda_{1} = 4 $$\n由于 $4  4.275$，条件未满足。\n对于 $r=2$：\n$$ \\sum_{i=1}^{2} \\lambda_{i} = \\lambda_{1} + \\lambda_{2} = 4 + \\frac{1}{2} = 4.5 $$\n由于 $4.5 \\ge 4.275$，条件满足。\n满足条件的最小整数 $r$ 是 $2$。", "answer": "$$\\boxed{2}$$", "id": "3362741"}, {"introduction": "现实世界中的模型往往是高度非线性的，这给灵敏度分析带来了挑战。本练习通过一个精心设计的非线性问题，旨在揭示全局灵敏度分析（主动子空间法）与局部灵敏度分析（基于线性化的方法，如似然通知子空间 LIS）之间的根本区别。通过计算并比较这两个子空间，您将理解为什么在非线性模型中，仅依赖于某一点的局部信息可能会产生误导，以及全局平均思想的重要性。[@problem_id:3362773]", "problem": "考虑一个贝叶斯逆问题，其参数向量为二维向量 $x \\in \\mathbb{R}^{2}$，先验为高斯分布 $x \\sim \\mathcal{N}(0, I)$，观测模型为带有单位噪声协方差的高斯模型。正向模型是一个非线性映射 $G:\\mathbb{R}^{2} \\to \\mathbb{R}^{2}$，由下式给出\n$$\nG(x) = \\begin{pmatrix} x_{1} \\\\ x_{2}^{3} \\end{pmatrix}.\n$$\n设观测数据为 $y = G(0) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。定义负对数后验（忽略一个加性常数）为\n$$\n\\Phi(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2} + \\frac{1}{2}\\|x\\|_{2}^{2},\n$$\n其中 $\\|\\cdot\\|_{2}$ 表示欧几里得范数。假设最大后验（MAP）点为 $x_{\\ast} = 0$。\n\n我们关心两种子空间的构造方法：\n- 似然信息子空间（Likelihood-Informed Subspace, LIS），它由负对数似然函数在MAP点处的海森矩阵的高斯-牛顿近似构造而来。对于单位噪声协方差，该近似简化为矩阵 $J(x_{\\ast})^{\\top}J(x_{\\ast})$，其中 $J(x)$ 是 $G$ 在 $x$ 处的雅可比矩阵。\n- 针对最小二乘失配 $m(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2}$ 的梯度协方差主动子空间，定义为矩阵\n$$\nC = \\mathbb{E}_{x \\sim \\mathcal{N}(0, I)}\\left[\\nabla m(x)\\,\\nabla m(x)^{\\top}\\right]\n$$\n的主特征向量所张成的空间。\n\n计算此问题得到的一维LIS与一维梯度协方差主动子空间之间的主角。最终答案以弧度表示的精确值给出。然后，从第一性原理出发，解释为什么在这个非线性例子中这两个子空间不同，并指出这两种构造方法之间产生差异的根源。", "solution": "该问题要求计算从一个贝叶斯逆问题设置中派生出的两个一维子空间——似然信息子空间（LIS）和梯度协方差主动子空间——之间的主角。问题还要求从第一性原理出发解释为什么这两个子空间不同。\n\n首先，我们验证问题陈述的有效性。\n给定的信息是：\n- 参数向量：$x = (x_1, x_2)^{\\top} \\in \\mathbb{R}^{2}$\n- 先验分布：$x \\sim \\mathcal{N}(0, I)$，其中 $I$ 是 $2 \\times 2$ 单位矩阵。\n- 正向模型：$G(x) = \\begin{pmatrix} x_{1} \\\\ x_{2}^{3} \\end{pmatrix}$\n- 观测模型：高斯模型，带有单位噪声协方差。\n- 观测数据：$y = G(0) = (0, 0)^{\\top}$\n- 负对数后验（忽略一个常数）：$\\Phi(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2} + \\frac{1}{2}\\|x\\|_{2}^{2}$\n- 最大后验（MAP）点：$x_{\\ast} = (0, 0)^{\\top}$\n- LIS 定义：负对数似然函数在MAP点处的海森矩阵的高斯-牛顿近似 $J(x_{\\ast})^{\\top}J(x_{\\ast})$ 的主特征向量所张成的空间。\n- 主动子空间（AS）定义：矩阵 $C = \\mathbb{E}_{x \\sim \\mathcal{N}(0, I)}\\left[\\nabla m(x)\\,\\nabla m(x)^{\\top}\\right]$ 的主特征向量所张成的空间，其中 $m(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2}$。\n\n该问题在逆问题和不确定性量化领域有其科学依据，是数学上适定的，内部一致，并使用了精确、客观的语言。所有必要信息均已提供。因此，该问题是有效的。\n\n我们分三部分进行求解：计算LIS，计算主动子空间，以及计算主角，最后给出所要求的解释。\n\n**1. 计算似然信息子空间（LIS）**\n\nLIS 是由负对数似然函数的海森矩阵在 MAP 点 $x_{\\ast} = 0$ 处的高斯-牛顿近似构造的。负对数似然函数为 $l(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2}$。高斯-牛顿海森矩阵由 $H_{GN} = J(x_{\\ast})^{\\top}J(x_{\\ast})$ 给出，其中 $J(x)$ 是正向模型 $G(x)$ 的雅可比矩阵。\n\n正向模型为 $G(x) = \\begin{pmatrix} x_{1} \\\\ x_{2}^{3} \\end{pmatrix}$。其雅可比矩阵 $J(x)$ 为：\n$$\nJ(x) = \\frac{\\partial G}{\\partial x} = \\begin{pmatrix} \\frac{\\partial (x_1)}{\\partial x_1}  \\frac{\\partial (x_1)}{\\partial x_2} \\\\ \\frac{\\partial (x_2^3)}{\\partial x_1}  \\frac{\\partial (x_2^3)}{\\partial x_2} \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  3x_{2}^{2} \\end{pmatrix}\n$$\n我们在 MAP 点 $x_{\\ast} = (0, 0)^{\\top}$ 处计算雅可比矩阵：\n$$\nJ(x_{\\ast}) = J(0) = \\begin{pmatrix} 1  0 \\\\ 0  3(0)^{2} \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}\n$$\n现在，我们计算高斯-牛顿海森矩阵：\n$$\nH_{GN} = J(0)^{\\top}J(0) = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}^{\\top} \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}\n$$\n$H_{GN}$ 的特征值为 $\\lambda_1 = 1$ 和 $\\lambda_2 = 0$。对应的特征向量分别为 $u_1 = (1, 0)^{\\top}$ 和 $u_2 = (0, 1)^{\\top}$。一维LIS是由最大特征值对应的特征向量所张成的空间。\n因此，LIS由向量 $u_1 = (1, 0)^{\\top}$ 张成。\n\n**2. 计算梯度协方差主动子空间（AS）**\n\n主动子空间由矩阵 $C = \\mathbb{E}_{x \\sim \\mathcal{N}(0, I)}\\left[\\nabla m(x)\\,\\nabla m(x)^{\\top}\\right]$ 的特征系统定义。\n首先，我们求出标量值函数 $m(x)$，即最小二乘失配。当 $y = (0, 0)^{\\top}$ 时，我们有：\n$$\nm(x) = \\frac{1}{2}\\|G(x) - y\\|_{2}^{2} = \\frac{1}{2}\\left\\| \\begin{pmatrix} x_1 \\\\ x_2^3 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\right\\|_{2}^{2} = \\frac{1}{2}(x_1^2 + x_2^6)\n$$\n接下来，我们计算 $m(x)$ 的梯度：\n$$\n\\nabla m(x) = \\begin{pmatrix} \\frac{\\partial m}{\\partial x_1} \\\\ \\frac{\\partial m}{\\partial x_2} \\end{pmatrix} = \\begin{pmatrix} x_1 \\\\ 3x_2^5 \\end{pmatrix}\n$$\n现在我们构造外积 $\\nabla m(x)\\,\\nabla m(x)^{\\top}$：\n$$\n\\nabla m(x)\\,\\nabla m(x)^{\\top} = \\begin{pmatrix} x_1 \\\\ 3x_2^5 \\end{pmatrix} \\begin{pmatrix} x_1  3x_2^5 \\end{pmatrix} = \\begin{pmatrix} x_1^2  3x_1x_2^5 \\\\ 3x_1x_2^5  9x_2^{10} \\end{pmatrix}\n$$\n矩阵 $C$ 是这个矩阵在先验分布 $x \\sim \\mathcal{N}(0, I)$ 下的期望。这意味着 $x_1$ 和 $x_2$ 是独立的标准正态随机变量，即 $x_1, x_2 \\sim \\mathcal{N}(0, 1)$。我们计算每个元素的期望：\n$$\nC = \\begin{pmatrix} \\mathbb{E}[x_1^2]  \\mathbb{E}[3x_1x_2^5] \\\\ \\mathbb{E}[3x_1x_2^5]  \\mathbb{E}[9x_2^{10}] \\end{pmatrix}\n$$\n对于一个标准正态变量 $Z \\sim \\mathcal{N}(0, 1)$，其矩为：当 $k$ 为奇数时 $\\mathbb{E}[Z^k] = 0$；当 $k=2n$ 为偶数时 $\\mathbb{E}[Z^{2n}] = (2n-1)!! = (2n-1)(2n-3)\\cdots 1$。\n- $\\mathbb{E}[x_1^2] = 1$。\n- 由于独立性，$\\mathbb{E}[3x_1x_2^5] = 3\\,\\mathbb{E}[x_1]\\,\\mathbb{E}[x_2^5] = 3 \\cdot 0 \\cdot 0 = 0$。\n- $\\mathbb{E}[x_2^{10}] = (10-1)!! = 9!! = 9 \\cdot 7 \\cdot 5 \\cdot 3 \\cdot 1 = 945$。\n- $\\mathbb{E}[9x_2^{10}] = 9 \\cdot \\mathbb{E}[x_2^{10}] = 9 \\cdot 945 = 8505$。\n\n将这些值代回矩阵 $C$：\n$$\nC = \\begin{pmatrix} 1  0 \\\\ 0  8505 \\end{pmatrix}\n$$\n这个对角矩阵的特征值为 $\\mu_1 = 8505$ 和 $\\mu_2 = 1$。对应的特征向量分别为 $v_1 = (0, 1)^{\\top}$ 和 $v_2 = (1, 0)^{\\top}$。一维主动子空间是由最大特征值对应的特征向量所张成的空间。\n因此，主动子空间由向量 $v_1 = (0, 1)^{\\top}$ 张成。\n\n**3. 计算主角**\n\n由单位向量 $u = (1, 0)^{\\top}$（对于LIS）和 $v = (0, 1)^{\\top}$（对于AS）张成的两个一维子空间（直线）之间的主角 $\\theta$ 由以下公式给出：\n$$\n\\cos(\\theta) = |u^{\\top}v|\n$$\n计算内积：\n$$\nu^{\\top}v = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = 1 \\cdot 0 + 0 \\cdot 1 = 0\n$$\n因此，$\\cos(\\theta) = 0$。主角为 $\\theta = \\arccos(0) = \\frac{\\pi}{2}$ 弧度。这两个子空间是正交的。\n\n**4. 差异的解释**\n\nLIS和主动子空间之间差异的根本原因在于它们的构造方式：LIS是一种*局部*方法，而主动子空间是一种*全局*方法。\n\n**似然信息子空间（LIS）** 基于正向模型 $G(x)$ 在单个点（即MAP估计 $x_{\\ast}$）周围的线性化。高斯-牛顿海森矩阵 $J(x_{\\ast})^{\\top}J(x_{\\ast})$ 衡量了模型输出对 $x_{\\ast}$ 周围无穷小扰动的敏感性。在这个问题中，$x_{\\ast}=0$。在该点，雅可比矩阵为 $J(0) = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}$。第(2,2)个元素为零，是因为非线性项 $x_2^3$ 的导数 $3x_2^2$ 在 $x_2=0$ 时为0。因此，模型在原点附近的局部线性近似 $G(\\delta x) \\approx J(0)\\delta x = (\\delta x_1, 0)^{\\top}$ 完全对 $x_2$ 方向的扰动不敏感。LIS的构造完全依赖于这个局部信息，因此正确地得出结论：在*MAP点*，$x_1$ 方向是受似然函数信息影响的方向。它对远离该特定点的任何敏感性都是“盲目”的。\n\n相比之下，**主动子空间（AS）** 基于全局敏感性分析。矩阵 $C = \\mathbb{E}[\\nabla m(x) \\nabla m(x)^{\\top}]$ 计算了失配函数 $m(x)$ 的敏感性在整个参数空间上的平均值，并由先验概率分布进行加权。失配函数的梯度是 $\\nabla m(x) = (x_1, 3x_2^5)^{\\top}$。项 $3x_2^5$ 在 $x_2=0$ 时为零，但随着 $|x_2|$ 的增加而迅速增长。计算 $C$ 的 (2,2) 分量的期望积分涉及 $\\mathbb{E}[9x_2^{10}]$，它将这种快速增长的敏感性在先验分布决定的所有可能的 $x_2$ 值上进行累加。这导致了一个非常大的值（8505），表明失配函数对参数 $x_2$ 具有巨大的平均敏感性。而对 $x_1$ 分量的期望 $\\mathbb{E}[x_1^2]$ 仅为1。因此，主动子空间的构造正确地识别出 $x_2$ 方向是失配函数平均变化最大的方向，使其成为从全局角度看参数敏感性的主导方向。\n\n总之，这种差异是正向模型在 $x_2$ 变量上强非线性的直接结果。LIS方法是局部的，因此被 $x_2^3$ 在线性化点 $x_2=0$ 处的消失导数所“欺骗”。主动子空间方法是全局的，它在整个先验上进行积分，并正确地捕捉到了高度非线性的 $x_2$ 项的主导影响。这两个子空间的正交性表明，对于此问题，局部和全局敏感性分析得出了完全不一致的结论。", "answer": "$$\\boxed{\\frac{\\pi}{2}}$$", "id": "3362773"}, {"introduction": "在实际应用中，我们永远无法精确知道主动子空间矩阵 $C$，而只能通过有限的样本来估计它。这个练习直面这一挑战，探讨了估计子空间的稳定性和可靠性问题。您将运用矩阵扰动理论中的经典结果（Davis-Kahan 定理）来量化由采样误差导致的子空间估计误差，从而理解谱间隙等因素如何影响降维结果的置信度。[@problem_id:3362760]", "problem": "考虑在逆问题和数据同化中，为一个可微的参数到可观测量映射构造主动子空间，其中矩阵 $C \\in \\mathbb{R}^{d \\times d}$ 定义为在已知概率密度下的期望梯度外积 $C = \\mathbb{E}\\left[\\nabla f(x)\\nabla f(x)^{\\top}\\right]$。假设 $C$ 是对称半正定矩阵，其有序特征值为 $\\lambda_{1} \\ge \\lambda_{2} \\ge \\cdots \\ge \\lambda_{d} \\ge 0$，对应的标准正交特征向量构成矩阵 $U = \\left[u_{1}, \\ldots, u_{d}\\right]$。$r$ 维主动子空间是由前 $r$ 个特征向量张成的空间，这里 $r=2$。设 $\\widehat{C}$ 是通过有限数量样本得到的 $C$ 的经验估计量，并定义扰动 $E = \\widehat{C} - C$。真实与经验的 2 维主动子空间之间的子空间误差，由主夹角正弦的算子范数度量，即 $\\lVert \\sin \\Theta \\rVert_{2}$，其中 $\\Theta$ 是 $C$ 的主特征向量矩阵 $U_{2} \\in \\mathbb{R}^{d \\times 2}$ 和 $\\widehat{C}$ 的主特征向量矩阵 $\\widehat{U}_{2} \\in \\mathbb{R}^{d \\times 2}$ 的列空间之间的主夹角。\n\n假设 $C$ 的主要特征值为 $\\lambda_{1} = 10$，$\\lambda_{2} = 9.5$ 和 $\\lambda_{3} = 1$，其余特征值均不超过 $\\lambda_{3}$。此外，假设扰动的谱范数为 $\\lVert E \\rVert_{2} = 0.2$。\n\n仅利用这些事实和适用于对称矩阵不变子空间的相应扰动理论，计算 $\\lVert \\sin \\Theta \\rVert_{2}$ 的最精确可证上界（用给定数值表示）。将最终的数值界四舍五入到四位有效数字。答案是无量纲的，应以单个实数形式给出。", "solution": "用户希望找到主动子空间与其经验估计之间子空间误差的最精确可证上界，该误差由 $\\lVert \\sin \\Theta \\rVert_{2}$ 度量。\n\n### 步骤 1：问题验证\n\n**1.1. 提取已知条件：**\n- 一个对称半正定矩阵 $C \\in \\mathbb{R}^{d \\times d}$ 定义为 $C = \\mathbb{E}\\left[\\nabla f(x)\\nabla f(x)^{\\top}\\right]$。\n- $C$ 的特征值按序排列为 $\\lambda_{1} \\ge \\lambda_{2} \\ge \\cdots \\ge \\lambda_{d} \\ge 0$。\n- 2 维主动子空间是由 $C$ 的前两个特征向量（对应于 $\\lambda_1$ 和 $\\lambda_2$）张成的空间。设这些特征向量构成的矩阵为 $U_2 \\in \\mathbb{R}^{d \\times 2}$。\n- 给定 $C$ 的一个经验估计 $\\widehat{C}$。扰动为 $E = \\widehat{C} - C$。\n- $\\widehat{C}$ 的两个最大特征值对应的特征向量构成矩阵 $\\widehat{U}_2 \\in \\mathbb{R}^{d \\times 2}$，该矩阵张成经验主动子空间。\n- 误差为 $\\lVert \\sin \\Theta \\rVert_{2}$，其中 $\\Theta$ 表示 $U_2$ 和 $\\widehat{U}_2$ 的列空间之间的主夹角。\n- $C$ 的主要特征值为 $\\lambda_{1} = 10$，$\\lambda_{2} = 9.5$ 和 $\\lambda_{3} = 1$。\n- 所有其他特征值满足 $\\lambda_{i} \\le \\lambda_{3} = 1$（对于 $i  3$）。\n- 扰动的谱范数给定为 $\\lVert E \\rVert_{2} = 0.2$。\n\n**1.2. 验证：**\n- **科学依据：** 该问题牢固地植根于主动子空间的数学理论，这是不确定性量化和降维中的一种标准技术。扰动下子空间稳定性的分析是数值线性代数的核心课题，其在此处的应用是标准实践。该问题在科学上和数学上都是合理的。\n- **适定性：** 该问题要求使用所提供的信息计算“最精确可证上界”。这引导我们应用矩阵扰动理论中一个已知的、严谨的定理。像 Davis-Kahan $\\sin\\Theta$ 定理这样的结果保证了此界的存在性。该问题是适定的。\n- **客观性：** 该问题用精确的数学语言和客观的量进行了规定。\n- **缺陷检查：** 该问题不违反任何无效性标准。它是完整的、一致的、现实的且可验证的。\n\n**1.3. 结论：**\n该问题有效。\n\n### 步骤 2：求解\n\n该问题是对称特征值问题的矩阵扰动理论的经典应用。给定一个对称矩阵 $C$ 及其扰动 $\\widehat{C} = C + E$。我们需要找到与 $C$ 的两个最大特征值相关联的不变子空间和与 $\\widehat{C}$ 的相应子空间之间距离的上界。此距离由 $\\lVert \\sin \\Theta \\rVert_{2}$ 给出。\n\n完成此任务的合适理论工具是 Davis-Kahan $\\sin\\Theta$ 定理。我们首先需要划分 $C$ 的谱并确定谱隙。\n\n我们感兴趣的不变子空间，即主动子空间，与特征值集合 $\\Lambda_{\\text{active}} = \\{\\lambda_1, \\lambda_2\\} = \\{10, 9.5\\}$ 相关联。矩阵 $U_2$ 包含相应的标准正交特征向量。\n\n互补的不变子空间，即非主动子空间，与其余特征值 $\\Lambda_{\\text{inactive}} = \\{\\lambda_3, \\lambda_4, \\ldots, \\lambda_d\\}$ 相关联。包含相应特征向量的矩阵可表示为 $U_{d-2}$。\n\nDavis-Kahan 定理根据扰动范数和谱隙 $\\delta$ 提供了 $\\lVert \\sin \\Theta \\rVert_2$ 的一个界。谱隙是与主动子空间相关联的特征值和与非主动子空间相关联的特征值之间的最小距离。\n\n在数学上，谱隙 $\\delta$ 定义为：\n$$\n\\delta = \\min_{\\lambda \\in \\Lambda_{\\text{active}}, \\mu \\in \\Lambda_{\\text{inactive}}} |\\lambda - \\mu|\n$$\n$\\Lambda_{\\text{active}}$ 中的最小特征值为 $\\lambda_2 = 9.5$。\n$\\Lambda_{\\text{inactive}}$ 中的最大特征值为 $\\lambda_3 = 1$（因为所有其他 $\\lambda_i \\le \\lambda_3$）。\n因此，谱隙为：\n$$\n\\delta = \\lambda_2 - \\lambda_3 = 9.5 - 1 = 8.5\n$$\nDavis-Kahan $\\sin\\Theta$ 定理（一个常见且直接的表述，例如，参见 Y. Saad 的《大型特征值问题的数值方法》）指出，对于对称矩阵 $C$、其对称扰动 $\\widehat{C}=C+E$ 以及由 $U_2$ 的列张成的不变子空间，该子空间与相应的扰动子空间之间主夹角 $\\Theta$ 的正弦由以下公式界定：\n$$\n\\lVert \\sin \\Theta \\rVert_{2} \\le \\frac{\\lVert U_{d-2}^{\\top} E U_2 \\rVert_{2}}{\\delta}\n$$\n项 $\\lVert U_{d-2}^{\\top} E U_2 \\rVert_{2}$ 表示扰动矩阵 $E$ 在 $C$ 的特征基下的非对角块的范数。由于除了谱范数 $\\lVert E \\rVert_{2}$ 之外，矩阵 $E$ 没有被进一步指定，我们必须考虑分子的最坏情况。利用算子范数的次可乘性以及 $U_2$ 和 $U_{d-2}$ 具有标准正交列（$\\lVert U_2 \\rVert_2 = 1$，$\\lVert U_{d-2}^{\\top} \\rVert_2 = 1$）的事实，我们有：\n$$\n\\lVert U_{d-2}^{\\top} E U_2 \\rVert_{2} \\le \\lVert U_{d-2}^{\\top} \\rVert_{2} \\lVert E \\rVert_{2} \\lVert U_2 \\rVert_{2} = \\lVert E \\rVert_{2}\n$$\n问题要求*仅*基于给定信息得出一个“可证”上界。因此，我们必须使用这个上限作为分子。将给定值 $\\lVert E \\rVert_{2} = 0.2$ 和计算出的谱隙 $\\delta = 8.5$ 代入该定理，得到最精确的可证上界：\n$$\n\\lVert \\sin \\Theta \\rVert_{2} \\le \\frac{\\lVert E \\rVert_{2}}{\\delta} = \\frac{0.2}{8.5}\n$$\n该定理存在其他形式，其中一些会产生类似 $\\frac{\\lVert E \\rVert_2}{\\delta - \\lVert E \\rVert_2}$ 的界。然而，界 $\\frac{\\lVert E \\rVert_2}{\\delta}$ 源自该定理的经典版本，并且在本例中更紧（因为 $\\frac{0.2}{8.5}  \\frac{0.2}{8.3}$）。它是利用所提供数据可以证明的最精确的界。\n\n现在，我们计算数值并按要求将其四舍五入到四位有效数字。\n$$\n\\frac{0.2}{8.5} = \\frac{2}{85} \\approx 0.02352941176\\ldots\n$$\n四舍五入到四位有效数字得到 $0.02353$。", "answer": "$$\\boxed{0.02353}$$", "id": "3362760"}]}