{"hands_on_practices": [{"introduction": "这第一个练习为弱约束四维变分同化（4D-Var）提供了一个基础性的、解析的视角。通过从第一性原理出发求解一个简单的标量系统，你将推导出最优解的精确形式。这项实践极具价值，它揭示了同化过程的内在机制，清晰地展示了背景误差协方差（$B$）、模式误差协方差（$Q$）和观测误差协方差（$R$）如何权衡不同信息来源，从而生成最终的分析场。[@problem_id:3431128]", "problem": "在一个弱约束四维变分(4D-Var)数据同化公式中，考虑一个经过两个连续模型步长的标量线性动力系统。设初始状态为 $x_0$，定义单步线性模型算子 $M \\in \\mathbb{R}$，该算子在两个步长上均相同地应用，并带有加性模型误差 $\\eta_0$ 和 $\\eta_1$。状态演化遵循\n$$\nx_1 = M x_0 + \\eta_0, \\quad x_2 = M x_1 + \\eta_1.\n$$\n在最终时刻，有一个标量观测值 $y \\in \\mathbb{R}$ 可用，其标量线性观测算子为 $H \\in \\mathbb{R}$，观测误差方差为 $R > 0$，因此观测方程为\n$$\ny = H x_2 + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, R).\n$$\n初始条件的背景（先验）为 $x_b \\in \\mathbb{R}$，背景误差方差为 $B > 0$。两个步长上的加性模型误差是独立同分布的，服从 $\\eta_k \\sim \\mathcal{N}(0, Q)$，其中 $Q > 0$。在弱约束 4D-Var 设置中，控制变量是三元组 $(x_0, \\eta_0, \\eta_1)$。标准的二次代价泛函为\n$$\nJ(x_0, \\eta_0, \\eta_1) = \\frac{1}{2} \\left[ \\frac{(x_0 - x_b)^2}{B} + \\frac{\\eta_0^2}{Q} + \\frac{\\eta_1^2}{Q} + \\frac{\\left(y - H x_2\\right)^2}{R} \\right],\n$$\n其中 $x_2 = M^2 x_0 + M \\eta_0 + \\eta_1$。\n\n从高斯误差下的线性最小二乘估计的基本原理出发，推导 $J$ 的最小值点 $(x_0^\\ast, \\eta_0^\\ast, \\eta_1^\\ast)$ 作为标量 $B$, $Q$, $R$, $M$, $H$, $x_b$ 和 $y$ 的解析函数的闭式表达式。将您的最终答案表示为顺序为 $(x_0^\\ast, \\eta_0^\\ast, \\eta_1^\\ast)$ 的单个 $1 \\times 3$ 行矩阵。提供精确的符号表达式；不要进行任何数值舍入。", "solution": "该问题提出了一个针对标量线性系统的标准弱约束四维变分(4D-Var)数据同化问题。任务是找到控制变量——初始状态 $x_0$ 和两个时间步的模型误差 $\\eta_0$ 和 $\\eta_1$——的最优值，以最小化给定的二次代价泛函 $J(x_0, \\eta_0, \\eta_1)$。\n\n首先，我们对问题陈述进行验证。\n\n### 步骤1：提取已知条件\n- 状态演化模型：$x_1 = M x_0 + \\eta_0$, $x_2 = M x_1 + \\eta_1$，这意味着 $x_2 = M^2 x_0 + M \\eta_0 + \\eta_1$。所有变量都是标量。\n- 观测模型：$y = H x_2 + \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, R)$ 且 $R > 0$。\n- 先验信息：初始状态 $x_0$ 有一个背景估计 $x_b$，其误差方差为 $B > 0$。\n- 模型误差统计：模型误差 $\\eta_0$ 和 $\\eta_1$ 独立同分布，服从 $\\mathcal{N}(0, Q)$，其中 $Q > 0$。\n- 控制变量：$(x_0, \\eta_0, \\eta_1)$。\n- 代价泛函：$J(x_0, \\eta_0, \\eta_1) = \\frac{1}{2} \\left[ \\frac{(x_0 - x_b)^2}{B} + \\frac{\\eta_0^2}{Q} + \\frac{\\eta_1^2}{Q} + \\frac{\\left(y - H x_2\\right)^2}{R} \\right]$。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题具有科学依据，是数据同化中线性二次估计的一个典型例子，等价于高斯假设下的贝叶斯推断。该问题是适定的；代价泛函 $J$ 是关于控制变量的严格凸二次函数（因为 $B, Q, R > 0$），这保证了唯一最小值的存在。问题陈述是客观、完整且数学上一致的。未检测到任何缺陷。\n\n### 步骤3：结论与行动\n该问题是有效的。我们继续推导解答。\n\n代价泛函 $J$ 的最小值点 $(x_0^\\ast, \\eta_0^\\ast, \\eta_1^\\ast)$ 位于 $J$ 相对于控制变量的梯度为零的驻点。我们必须求解方程组：\n$$\n\\frac{\\partial J}{\\partial x_0} = 0, \\quad \\frac{\\partial J}{\\partial \\eta_0} = 0, \\quad \\frac{\\partial J}{\\partial \\eta_1} = 0.\n$$\n首先，我们将 $x_2$ 的表达式代入代价泛函：\n$$\nJ(x_0, \\eta_0, \\eta_1) = \\frac{1}{2} \\left[ \\frac{(x_0 - x_b)^2}{B} + \\frac{\\eta_0^2}{Q} + \\frac{\\eta_1^2}{Q} + \\frac{\\left(y - H(M^2 x_0 + M \\eta_0 + \\eta_1)\\right)^2}{R} \\right].\n$$\n现在，我们计算关于每个控制变量的偏导数。\n\n1.  关于 $x_0$ 的导数：\n    $$\n    \\frac{\\partial J}{\\partial x_0} = \\frac{x_0 - x_b}{B} + \\frac{1}{R}\\left(y - H(M^2 x_0 + M \\eta_0 + \\eta_1)\\right) \\cdot (-H M^2) = 0.\n    $$\n\n2.  关于 $\\eta_0$ 的导数：\n    $$\n    \\frac{\\partial J}{\\partial \\eta_0} = \\frac{\\eta_0}{Q} + \\frac{1}{R}\\left(y - H(M^2 x_0 + M \\eta_0 + \\eta_1)\\right) \\cdot (-H M) = 0.\n    $$\n\n3.  关于 $\\eta_1$ 的导数：\n    $$\n    \\frac{\\partial J}{\\partial \\eta_1} = \\frac{\\eta_1}{Q} + \\frac{1}{R}\\left(y - H(M^2 x_0 + M \\eta_0 + \\eta_1)\\right) \\cdot (-H) = 0.\n    $$\n\n令解表示为 $(x_0^\\ast, \\eta_0^\\ast, \\eta_1^\\ast)$，并令 $x_2^\\ast = M^2 x_0^\\ast + M \\eta_0^\\ast + \\eta_1^\\ast$。最小值点的方程组可以以一种更具洞察力的形式重写。我们定义残差项 $\\delta^\\ast = y - H x_2^\\ast$。方程变为：\n$$\n\\frac{x_0^\\ast - x_b}{B} = \\frac{H M^2}{R} \\delta^\\ast \\quad (1)\n$$\n$$\n\\frac{\\eta_0^\\ast}{Q} = \\frac{H M}{R} \\delta^\\ast \\quad (2)\n$$\n$$\n\\frac{\\eta_1^\\ast}{Q} = \\frac{H}{R} \\delta^\\ast \\quad (3)\n$$\n从这些方程中，我们可以将最优控制变量表示为未知残差 $\\delta^\\ast$ 的函数：\n$$\nx_0^\\ast = x_b + \\frac{B H M^2}{R} \\delta^\\ast\n$$\n$$\n\\eta_0^\\ast = \\frac{Q H M}{R} \\delta^\\ast\n$$\n$$\n\\eta_1^\\ast = \\frac{Q H}{R} \\delta^\\ast\n$$\n为了求出 $\\delta^\\ast$，我们将这些表达式代回其定义 $\\delta^\\ast = y - H x_2^\\ast = y - H(M^2 x_0^\\ast + M \\eta_0^\\ast + \\eta_1^\\ast)$ 中：\n$$\n\\delta^\\ast = y - H \\left[ M^2\\left(x_b + \\frac{B H M^2}{R} \\delta^\\ast\\right) + M\\left(\\frac{Q H M}{R} \\delta^\\ast\\right) + \\left(\\frac{Q H}{R} \\delta^\\ast\\right) \\right]\n$$\n现在，我们重新整理方程以求解 $\\delta^\\ast$：\n$$\n\\delta^\\ast = y - H M^2 x_b - H \\left[ \\frac{B H M^4}{R} + \\frac{Q H M^2}{R} + \\frac{Q H}{R} \\right] \\delta^\\ast\n$$\n$$\n\\delta^\\ast = y - H M^2 x_b - \\frac{H^2}{R} \\left( B M^4 + Q M^2 + Q \\right) \\delta^\\ast\n$$\n$$\n\\delta^\\ast \\left[ 1 + \\frac{H^2}{R} \\left( B M^4 + Q M^2 + Q \\right) \\right] = y - H M^2 x_b\n$$\n$$\n\\delta^\\ast \\left[ \\frac{R + H^2 (B M^4 + Q M^2 + Q)}{R} \\right] = y - H M^2 x_b\n$$\n求解 $\\delta^\\ast$ 得：\n$$\n\\delta^\\ast = \\frac{R (y - H M^2 x_b)}{R + H^2(B M^4 + Q M^2 + Q)}\n$$\n项 $y - H M^2 x_b$ 是新息，即观测值与背景平均值预报值之间的差异。分母代表观测空间中的总方差，包括观测误差方差 $R$ 以及从 $x_0$、$\\eta_0$ 和 $\\eta_1$ 传播的先验方差。\n\n最后，我们将 $\\delta^\\ast$ 的这个表达式代回到 $x_0^\\ast$、$\\eta_0^\\ast$ 和 $\\eta_1^\\ast$ 的方程中。\n\n对于 $x_0^\\ast$：\n$$\nx_0^\\ast = x_b + \\frac{B H M^2}{R} \\left[ \\frac{R (y - H M^2 x_b)}{R + H^2(B M^4 + Q M^2 + Q)} \\right] = x_b + \\frac{B H M^2 (y - H M^2 x_b)}{R + H^2(B M^4 + Q M^2 + Q)}\n$$\n\n对于 $\\eta_0^\\ast$：\n$$\n\\eta_0^\\ast = \\frac{Q H M}{R} \\left[ \\frac{R (y - H M^2 x_b)}{R + H^2(B M^4 + Q M^2 + Q)} \\right] = \\frac{Q H M (y - H M^2 x_b)}{R + H^2(B M^4 + Q M^2 + Q)}\n$$\n\n对于 $\\eta_1^\\ast$：\n$$\n\\eta_1^\\ast = \\frac{Q H}{R} \\left[ \\frac{R (y - H M^2 x_b)}{R + H^2(B M^4 + Q M^2 + Q)} \\right] = \\frac{Q H (y - H M^2 x_b)}{R + H^2(B M^4 + Q M^2 + Q)}\n$$\n这些是最小值点 $(x_0^\\ast, \\eta_0^\\ast, \\eta_1^\\ast)$ 的闭式表达式。我们以所要求的矩阵格式呈现它们。", "answer": "$$\n\\boxed{\\begin{pmatrix} x_b + \\frac{B H M^2 (y - H M^2 x_b)}{R + H^2(B M^4 + Q M^2 + Q)},  \\frac{Q H M (y - H M^2 x_b)}{R + H^2(B M^4 + Q M^2 + Q)},  \\frac{Q H (y - H M^2 x_b)}{R + H^2(B M^4 + Q M^2 + Q)} \\end{pmatrix}}\n$$", "id": "3431128"}, {"introduction": "虽然直接的解析解具有深刻的洞察力，但对于复杂的高维系统而言并不可行。本练习将向你介绍功能强大的拉格朗日和伴随方法，它们构成了现代变分资料同化系统的核心。通过为一个小型问题手动推导并求解卡罗需-库恩-塔克（KKT）条件，你将亲身体验在实际情景中用于寻找最优状态和模式误差校正的计算机制。[@problem_id:3431086]", "problem": "考虑一个具有标量状态的两步线性动力学模型的弱约束四维变分(4D-Var)同化。设动力学由带有加性模型误差的正向模型给出，\n$$\nx_{1} = m_{0}\\,x_{0} + \\eta_{0}, \\qquad x_{2} = m_{1}\\,x_{1} + \\eta_{1},\n$$\n观测为线性，观测算子为单位算子，\n$$\ny_{1} = x_{1} + \\epsilon_{1}, \\qquad y_{2} = x_{2} + \\epsilon_{2}.\n$$\n假设弱约束4D-Var代价函数为，\n$$\nJ(x_{0},\\eta_{0},\\eta_{1}) = \\frac{1}{2}(x_{0}-x_{b})^{2}B^{-1} + \\frac{1}{2}(y_{1}-x_{1})^{2}R_{1}^{-1} + \\frac{1}{2}(y_{2}-x_{2})^{2}R_{2}^{-1} + \\frac{1}{2}\\eta_{0}^{2}Q_{0}^{-1} + \\frac{1}{2}\\eta_{1}^{2}Q_{1}^{-1},\n$$\n其中所有协方差均为正标量。取以下具体的、科学上一致的值\n$$\nm_{0} = 2, \\quad m_{1} = 1, \\quad x_{b} = 0, \\quad B = 1, \\quad R_{1} = 1, \\quad R_{2} = 1, \\quad Q_{0} = 1, \\quad Q_{1} = 2, \\quad y_{1} = 3, \\quad y_{2} = 1.\n$$\n通过为模型方程引入拉格朗日乘子来构建约束优化问题，并从第一性原理推导Karush–Kuhn–Tucker (KKT) 平稳性方程。明确计算：\n- 在最小化轨迹上的伴随变量（拉格朗日乘子）$\\lambda_{1}$ 和 $\\lambda_{2}$，\n- 在最小化轨迹上求值的、相对于控制变量的降阶代价函数的梯度，即 $g_{x_{0}}$、$g_{\\eta_{0}}$ 和 $g_{\\eta_{1}}$。\n\n您必须验证KKT最优性方程对于计算出的值是精确成立的。以单行矩阵的形式报告您的最终答案，顺序如下\n$$\n\\left(x_{0}^{\\ast},\\,\\eta_{0}^{\\ast},\\,\\eta_{1}^{\\ast},\\,\\lambda_{1}^{\\ast},\\,\\lambda_{2}^{\\ast},\\,g_{x_{0}},\\,g_{\\eta_{0}},\\,g_{\\eta_{1}}\\right),\n$$\n使用精确的有理数值。无需四舍五入。这些量没有单位。", "solution": "在尝试任何解答之前，对问题进行验证。\n\n### 步骤 1：提取已知条件\n给定信息如下：\n- **动力学模型**：\n  $x_{1} = m_{0}\\,x_{0} + \\eta_{0}$\n  $x_{2} = m_{1}\\,x_{1} + \\eta_{1}$\n- **观测模型**：\n  $y_{1} = x_{1} + \\epsilon_{1}$\n  $y_{2} = x_{2} + \\epsilon_{2}$\n- **弱约束4D-Var的代价函数**：\n  $J(x_{0},\\eta_{0},\\eta_{1}) = \\frac{1}{2}(x_{0}-x_{b})^{2}B^{-1} + \\frac{1}{2}(y_{1}-x_{1})^{2}R_{1}^{-1} + \\frac{1}{2}(y_{2}-x_{2})^{2}R_{2}^{-1} + \\frac{1}{2}\\eta_{0}^{2}Q_{0}^{-1} + \\frac{1}{2}\\eta_{1}^{2}Q_{1}^{-1}$\n- **参数值**：\n  $m_{0} = 2$, $m_{1} = 1$\n  $x_{b} = 0$, $B = 1$\n  $R_{1} = 1$, $R_{2} = 1$\n  $Q_{0} = 1$, $Q_{1} = 2$\n- **观测值**：\n  $y_{1} = 3$, $y_{2} = 1$\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题是使用弱约束4D-Var方法进行数据同化的一个标准、定义明确的练习。\n- **科学基础**：该公式基于变分数据同化和优化理论的既定原则。使用二次代价函数对应于高斯分布误差的假设，这是该领域的标准做法。\n- **适定性**：该问题是一个凸优化问题（在线性约束下最小化一个严格凸二次函数），这保证了唯一解的存在。所有必要的参数和数据都已提供，使问题自成体系。代价函数记法 $J(x_0, \\eta_0, \\eta_1)$ 中的轻微模糊性通过其定义得以解决，该定义包含了依赖于 $x_1$ 和 $x_2$ 的项。使用拉格朗日乘子的指令阐明了预期的“一体化”求解方法，其中 $(x_0, x_1, x_2, \\eta_0, \\eta_1)$ 被视为受约束的独立变量。\n- **客观性**：该问题使用精确的数学术语陈述，不含任何主观或基于观点的内容。\n\n该问题没有违反任何无效标准。它在科学上是合理的，完全指定的，客观的，并且代表了其领域核心原则的一个非平凡应用。\n\n### 步骤 3：结论和行动\n问题被视为**有效**。将提供完整解答。\n\n### 解答\n问题是在动力学模型施加的约束下，求代价函数 $J$ 的最小值。这是一个约束优化问题。我们采用拉格朗日乘子法。优化变量是初始状态 $x_0$、模型误差 $\\eta_0$ 和 $\\eta_1$，以及后续状态 $x_1$ 和 $x_2$。\n\n作为完整状态和误差向量的函数，代价函数为：\n$$\nJ(x_0, x_1, x_2, \\eta_0, \\eta_1) = \\frac{1}{2}(x_{0}-x_{b})^{2}B^{-1} + \\frac{1}{2}(y_{1}-x_{1})^{2}R_{1}^{-1} + \\frac{1}{2}(y_{2}-x_{2})^{2}R_{2}^{-1} + \\frac{1}{2}\\eta_{0}^{2}Q_{0}^{-1} + \\frac{1}{2}\\eta_{1}^{2}Q_{1}^{-1}\n$$\n约束条件是模型方程：\n$$\nc_1(x_0, x_1, \\eta_0) = x_1 - m_0 x_0 - \\eta_0 = 0\n$$\n$$\nc_2(x_1, x_2, \\eta_1) = x_2 - m_1 x_1 - \\eta_1 = 0\n$$\n我们通过使用拉格朗日乘子（即伴随变量 $\\lambda_1$ 和 $\\lambda_2$）将约束条件附加到代价函数上，构建拉格朗日函数 $\\mathcal{L}$：\n$$\n\\mathcal{L}(x_0, x_1, x_2, \\eta_0, \\eta_1, \\lambda_1, \\lambda_2) = J + \\lambda_1 (x_1 - m_0 x_0 - \\eta_0) + \\lambda_2 (x_2 - m_1 x_1 - \\eta_1)\n$$\n通过将 $\\mathcal{L}$ 对其所有变量的偏导数设为零，可以找到 Karush-Kuhn-Tucker (KKT) 平稳性条件。\n\n1.  $\\frac{\\partial\\mathcal{L}}{\\partial x_0} = (x_0-x_b)B^{-1} - \\lambda_1 m_0 = 0$\n2.  $\\frac{\\partial\\mathcal{L}}{\\partial x_1} = -(y_1-x_1)R_1^{-1} + \\lambda_1 - \\lambda_2 m_1 = 0$\n3.  $\\frac{\\partial\\mathcal{L}}{\\partial x_2} = -(y_2-x_2)R_2^{-1} + \\lambda_2 = 0$\n4.  $\\frac{\\partial\\mathcal{L}}{\\partial \\eta_0} = \\eta_0 Q_0^{-1} - \\lambda_1 = 0$\n5.  $\\frac{\\partial\\mathcal{L}}{\\partial \\eta_1} = \\eta_1 Q_1^{-1} - \\lambda_2 = 0$\n6.  $\\frac{\\partial\\mathcal{L}}{\\partial \\lambda_1} = x_1 - m_0 x_0 - \\eta_0 = 0$\n7.  $\\frac{\\partial\\mathcal{L}}{\\partial \\lambda_2} = x_2 - m_1 x_1 - \\eta_1 = 0$\n\n方程 $(6)$ 和 $(7)$ 是原始的正向模型方程。这七个方程构成了一个关于最优变量 $(x_0^*, x_1^*, x_2^*, \\eta_0^*, \\eta_1^*, \\lambda_1^*, \\lambda_2^*)$ 的线性系统。\n\n我们代入给定的数值：$m_0 = 2$，$m_1 = 1$，$x_b = 0$，$B = 1$，$y_1 = 3$，$y_2 = 1$，$R_1 = 1$，$R_2 = 1$，$Q_0 = 1$，$Q_1 = 2$。\n该系统变为：\n1.  $(x_0-0)(1)^{-1} - \\lambda_1 (2) = 0 \\implies x_0 - 2\\lambda_1 = 0$\n2.  $-(3-x_1)(1)^{-1} + \\lambda_1 - \\lambda_2 (1) = 0 \\implies x_1 - 3 + \\lambda_1 - \\lambda_2 = 0$\n3.  $-(1-x_2)(1)^{-1} + \\lambda_2 = 0 \\implies x_2 - 1 + \\lambda_2 = 0$\n4.  $\\eta_0 (1)^{-1} - \\lambda_1 = 0 \\implies \\eta_0 - \\lambda_1 = 0$\n5.  $\\eta_1 (2)^{-1} - \\lambda_2 = 0 \\implies \\frac{1}{2}\\eta_1 - \\lambda_2 = 0$\n6.  $x_1 - 2x_0 - \\eta_0 = 0$\n7.  $x_2 - x_1 - \\eta_1 = 0$\n\n我们求解这个系统。从方程 $(1)$、$(3)$、$(4)$ 和 $(5)$，我们可以用伴随变量来表示状态和误差变量：\n从(1)式得：$x_0 = 2\\lambda_1$\n从(4)式得：$\\eta_0 = \\lambda_1$\n从(5)式得：$\\eta_1 = 2\\lambda_2$\n从(3)式得：$x_2 = 1-\\lambda_2$\n\n将这些代入模型方程 $(6)$ 和 $(7)$ 中：\n从(6)式得：$x_1 - 2(2\\lambda_1) - \\lambda_1 = 0 \\implies x_1 = 5\\lambda_1$\n从(7)式得：$(1-\\lambda_2) - x_1 - (2\\lambda_2) = 0 \\implies x_1 = 1 - 3\\lambda_2$\n\n令关于 $x_1$ 的两个表达式相等：\n$$\n5\\lambda_1 = 1 - 3\\lambda_2 \\implies 5\\lambda_1 + 3\\lambda_2 = 1 \\quad (\\text{式 A})\n$$\n现在，将 $x_1 = 5\\lambda_1$ 代入方程 $(2)$：\n$$\n(5\\lambda_1) - 3 + \\lambda_1 - \\lambda_2 = 0 \\implies 6\\lambda_1 - \\lambda_2 = 3 \\quad (\\text{式 B})\n$$\n我们现在得到一个关于 $(\\lambda_1, \\lambda_2)$ 的 $2 \\times 2$ 系统：\nA: $5\\lambda_1 + 3\\lambda_2 = 1$\nB: $6\\lambda_1 - \\lambda_2 = 3$\n\n从式 B，我们用 $\\lambda_1$ 表示 $\\lambda_2$：$\\lambda_2 = 6\\lambda_1 - 3$。\n将此代入式 A：\n$$\n5\\lambda_1 + 3(6\\lambda_1 - 3) = 1\n$$\n$$\n5\\lambda_1 + 18\\lambda_1 - 9 = 1\n$$\n$$\n23\\lambda_1 = 10 \\implies \\lambda_1^* = \\frac{10}{23}\n$$\n现在，我们求 $\\lambda_2^*$：\n$$\n\\lambda_2^* = 6\\lambda_1^* - 3 = 6\\left(\\frac{10}{23}\\right) - 3 = \\frac{60}{23} - \\frac{69}{23} = -\\frac{9}{23}\n$$\n这些是伴随变量（拉格朗日乘子）的最优值。\n\n接下来，我们计算状态和模型误差的最优值：\n$x_0^* = 2\\lambda_1^* = 2\\left(\\frac{10}{23}\\right) = \\frac{20}{23}$\n$\\eta_0^* = \\lambda_1^* = \\frac{10}{23}$\n$\\eta_1^* = 2\\lambda_2^* = 2\\left(-\\frac{9}{23}\\right) = -\\frac{18}{23}$\n$x_1^* = 5\\lambda_1^* = 5\\left(\\frac{10}{23}\\right) = \\frac{50}{23}$\n$x_2^* = 1 - \\lambda_2^* = 1 - \\left(-\\frac{9}{23}\\right) = 1 + \\frac{9}{23} = \\frac{32}{23}$\n\n问题要求在最小值处，降阶代价函数相对于控制变量 ($x_0, \\eta_0, \\eta_1$) 的梯度。该梯度的分量 $g_{x_0}$、$g_{\\eta_0}$ 和 $g_{\\eta_1}$ 由拉格朗日函数 $\\mathcal{L}$ 对这些控制变量的偏导数在最优轨迹上的求值给出。KKT 条件本身要求这些梯度为零。我们明确地验证这一点。\n\n梯度为：\n$g_{x_0} = \\frac{\\partial\\mathcal{L}}{\\partial x_0} = x_0 - 2\\lambda_1$\n$g_{\\eta_0} = \\frac{\\partial\\mathcal{L}}{\\partial \\eta_0} = \\eta_0 - \\lambda_1$\n$g_{\\eta_1} = \\frac{\\partial\\mathcal{L}}{\\partial \\eta_1} = \\frac{1}{2}\\eta_1 - \\lambda_2$\n\n在最优点求值：\n对于 $g_{x_0}$：\n$$\ng_{x_0} = x_0^* - 2\\lambda_1^* = \\frac{20}{23} - 2\\left(\\frac{10}{23}\\right) = \\frac{20}{23} - \\frac{20}{23} = 0\n$$\n对于 $g_{\\eta_0}$：\n$$\ng_{\\eta_0} = \\eta_0^* - \\lambda_1^* = \\frac{10}{23} - \\frac{10}{23} = 0\n$$\n对于 $g_{\\eta_1}$：\n$$\ng_{\\eta_1} = \\frac{1}{2}\\eta_1^* - \\lambda_2^* = \\frac{1}{2}\\left(-\\frac{18}{23}\\right) - \\left(-\\frac{9}{23}\\right) = -\\frac{9}{23} + \\frac{9}{23} = 0\n$$\nKKT 最优性方程确实得到满足，并且降阶代价函数在最小值处的梯度均为零，符合预期。\n\n最终答案要求按顺序排列以下值：$(x_0^*, \\eta_0^*, \\eta_1^*, \\lambda_1^*, \\lambda_2^*, g_{x_0}, g_{\\eta_0}, g_{\\eta_1})$。\n这些值为：\n$x_0^* = \\frac{20}{23}$\n$\\eta_0^* = \\frac{10}{23}$\n$\\eta_1^* = -\\frac{18}{23}$\n$\\lambda_1^* = \\frac{10}{23}$\n$\\lambda_2^* = -\\frac{9}{23}$\n$g_{x_0} = 0$\n$g_{\\eta_0} = 0$\n$g_{\\eta_1} = 0$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{20}{23},  \\frac{10}{23},  -\\frac{18}{23},  \\frac{10}{23},  -\\frac{9}{23},  0,  0,  0\n\\end{pmatrix}\n}\n$$", "id": "3431086"}, {"introduction": "弱约束4D-Var的一个关键优势是能够估计和校正系统性的模式误差，例如一个恒定的偏差项。然而，一个至关重要的初始问题是：我们希望估计的参数是否能从可用的观测中被“识别”出来？本练习将引导你推导结构可识别性的数学条件，并将其与由模式算子（$M$）和观测算子（$H$）构建的敏感性矩阵的秩联系起来。[@problem_id:3431150]", "problem": "考虑一个在弱约束四维变分同化（4D-Var）中使用的离散时间线性动力系统，其状态演化遵循 $x_{k+1} = M x_{k} + b + \\eta_{k}$，观测由 $y_{k} = H x_{k} + \\epsilon_{k}$ 给出。其中，$x_{k} \\in \\mathbb{R}^{n}$ 是系统在时间 $k$ 的状态，$M \\in \\mathbb{R}^{n \\times n}$ 是一个已知的线性模型传播算子，$b \\in \\mathbb{R}^{n}$ 是一个待估计的未知恒定模型误差偏差向量，$\\eta_{k}$ 和 $\\epsilon_{k}$ 分别是模拟过程噪声和观测噪声的零均值随机向量，$H \\in \\mathbb{R}^{m \\times n}$ 是一个已知的线性观测算子。假设初始状态 $x_{0}$ 已知，同化窗口包含 $L = 3$ 个连续的观测时间 $k = 1, 2, 3$。在弱约束设定下，$b$ 的可识别性指的是存在一个唯一的 $b$，与该窗口内的无噪声观测映射相一致。\n\n从上述定义以及线性系统传播和测量的第一性原理出发，使用 $x_{k}$ 的递推关系，推导从 $b$ 到堆叠观测值 $(y_{1}, y_{2}, y_{3})$ 的无噪声线性映射。利用此结果，根据由 $M$、$H$ 和 $L$ 构造的一个适当的灵敏度矩阵的满列秩，阐述 $b$ 的结构可识别性条件。然后，对于 $n = 2$，$m = 1$，\n$$\nM = \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix}, \n\\quad\nH = \\begin{pmatrix} 1  0 \\end{pmatrix},\n$$\n和 $L = 3$ 的具体选择，计算相关的 $2 \\times 2$ 格拉姆矩阵 $S^{\\top} S$ 的行列式，其中 $S$ 是将 $b$ 映射到堆叠的无噪声观测值 $(y_{1}, y_{2}, y_{3})$ 的灵敏度矩阵。请以整数形式给出你的答案（不进行四舍五入）。", "solution": "该问题要求在弱约束 4D-Var 框架内，推导一个恒定模型误差偏差向量 $b$ 的结构可识别性条件，并计算一个特定的格拉姆矩阵行列式。\n\n首先，我们在无噪声条件下建立偏差向量 $b$ 与观测值 $y_k$ 之间的关系。问题将系统动力学和观测模型定义为：\n$$\nx_{k+1} = M x_{k} + b + \\eta_{k}\n$$\n$$\ny_{k} = H x_{k} + \\epsilon_{k}\n$$\n为了研究结构可识别性，我们通过将所有 $k$ 的噪声项 $\\eta_{k}$ 和 $\\epsilon_{k}$ 设置为零来考虑无噪声情况。\n$$\nx_{k+1} = M x_{k} + b\n$$\n$$\ny_{k} = H x_{k}\n$$\n初始状态 $x_0$ 给定为已知。同化窗口包含 $L=3$ 个观测时间，分别为 $k=1, 2, 3$。我们从 $x_0$ 开始传播状态向量 $x_k$：\n\n对于 $k=1$：\n$$\nx_{1} = M x_{0} + b\n$$\n相应的观测是：\n$$\ny_{1} = H x_{1} = H M x_{0} + H b\n$$\n\n对于 $k=2$：\n$$\nx_{2} = M x_{1} + b = M (M x_{0} + b) + b = M^{2} x_{0} + M b + b = M^{2} x_{0} + (I + M) b\n$$\n其中 $I$ 是大小为 $n \\times n$ 的单位矩阵。观测是：\n$$\ny_{2} = H x_{2} = H M^{2} x_{0} + H (I + M) b\n$$\n\n对于 $k=3$：\n$$\nx_{3} = M x_{2} + b = M (M^{2} x_{0} + (I + M) b) + b = M^{3} x_{0} + M(I+M)b + b = M^{3} x_{0} + (I + M + M^{2}) b\n$$\n观测是：\n$$\ny_{3} = H x_{3} = H M^{3} x_{0} + H (I + M + M^{2}) b\n$$\n\n我们可以将观测值 $y_1, y_2, y_3$ 堆叠成一个单一向量 $\\mathbf{y} \\in \\mathbb{R}^{mL}$：\n$$\n\\mathbf{y} = \\begin{pmatrix} y_{1} \\\\ y_{2} \\\\ y_{3} \\end{pmatrix} = \\begin{pmatrix} H M x_{0} \\\\ H M^{2} x_{0} \\\\ H M^{3} x_{0} \\end{pmatrix} + \\begin{pmatrix} H \\\\ H(I+M) \\\\ H(I+M+M^{2}) \\end{pmatrix} b\n$$\n这个方程是从未知偏差向量 $b$ 到堆叠观测向量 $\\mathbf{y}$ 的一个线性映射。由于 $x_0$、$M$ 和 $H$ 是已知的，右侧的第一项是一个已知量。$b$ 的可识别性取决于与之相乘的矩阵的性质。这个矩阵是灵敏度矩阵 $S$，它描述了观测值如何响应偏差 $b$ 的变化。\n$$\nS = \\begin{pmatrix} H \\\\ H(I+M) \\\\ H(I+M+M^{2}) \\end{pmatrix}\n$$\n偏差向量 $b \\in \\mathbb{R}^{n}$ 是结构可识别的，当且仅当线性系统 $\\mathbf{y}_{\\text{adj}} = S b$（其中 $\\mathbf{y}_{\\text{adj}}$ 是根据已知项调整后的观测向量）对 $b$ 有唯一解。这要求矩阵 $S$ 具有满列秩，即 $\\text{rank}(S) = n$。$S$ 具有满列秩的一个充要条件是相关的格拉姆矩阵 $S^{\\top}S$ 是可逆的。矩阵 $S^{\\top}S$ 是一个 $n \\times n$ 矩阵，其可逆性等价于其行列式不为零，即 $\\det(S^{\\top}S) \\neq 0$。\n\n现在，我们将其应用于给定的具体情况：$n = 2$，$m = 1$，$L=3$，\n$$\nM = \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix}, \\quad H = \\begin{pmatrix} 1  0 \\end{pmatrix}\n$$\n首先，我们计算 $M$ 的必要幂次：\n$M^{0} = I = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$\n$M^{1} = M = \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix}$\n$M^{2} = M \\times M = \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 1  1+1 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 1  2 \\\\ 0  1 \\end{pmatrix}$\n\n接下来，我们计算 $S$ 的行所需的矩阵和：\n对于 $k=1$ 的和： $I = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$\n对于 $k=2$ 的和： $I + M = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 0  2 \\end{pmatrix}$\n对于 $k=3$ 的和： $I + M + M^{2} = \\begin{pmatrix} 2  1 \\\\ 0  2 \\end{pmatrix} + \\begin{pmatrix} 1  2 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 3  3 \\\\ 0  3 \\end{pmatrix}$\n\n现在我们构造灵敏度矩阵 $S$ 的行。由于 $m=1$，每一行都是一个 $1 \\times 2$ 的向量。\n第 1 行： $H I = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\end{pmatrix}$\n第 2 行： $H (I+M) = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 2  1 \\\\ 0  2 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\end{pmatrix}$\n第 3 行： $H (I+M+M^2) = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 3  3 \\\\ 0  3 \\end{pmatrix} = \\begin{pmatrix} 3  3 \\end{pmatrix}$\n\n灵敏度矩阵 $S$ 是一个通过堆叠这些行形成的 $3 \\times 2$ 矩阵：\n$$\nS = \\begin{pmatrix} 1  0 \\\\ 2  1 \\\\ 3  3 \\end{pmatrix}\n$$\n为了找到格拉姆矩阵 $S^{\\top}S$，我们首先求 $S$ 的转置：\n$$\nS^{\\top} = \\begin{pmatrix} 1  2  3 \\\\ 0  1  3 \\end{pmatrix}\n$$\n现在我们计算乘积 $S^{\\top}S$：\n$$\nS^{\\top}S = \\begin{pmatrix} 1  2  3 \\\\ 0  1  3 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 2  1 \\\\ 3  3 \\end{pmatrix}\n$$\n得到的 $2 \\times 2$ 矩阵的元素是：\n$$\n(S^{\\top}S)_{11} = (1)(1) + (2)(2) + (3)(3) = 1 + 4 + 9 = 14\n$$\n$$\n(S^{\\top}S)_{12} = (1)(0) + (2)(1) + (3)(3) = 0 + 2 + 9 = 11\n$$\n$$\n(S^{\\top}S)_{21} = (0)(1) + (1)(2) + (3)(3) = 0 + 2 + 9 = 11\n$$\n$$\n(S^{\\top}S)_{22} = (0)(0) + (1)(1) + (3)(3) = 0 + 1 + 9 = 10\n$$\n所以格拉姆矩阵是：\n$$\nS^{\\top}S = \\begin{pmatrix} 14  11 \\\\ 11  10 \\end{pmatrix}\n$$\n最后一步是计算该矩阵的行列式：\n$$\n\\det(S^{\\top}S) = (14)(10) - (11)(11) = 140 - 121 = 19\n$$\n由于行列式不为零，对于这个特定的系统配置，偏差向量 $b$ 是可识别的。", "answer": "$$\n\\boxed{19}\n$$", "id": "3431150"}]}