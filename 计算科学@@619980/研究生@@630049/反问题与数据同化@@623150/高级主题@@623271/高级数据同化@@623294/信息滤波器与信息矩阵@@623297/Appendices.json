{"hands_on_practices": [{"introduction": "信息矩阵并非一个纯粹抽象的数学构造，它直接编码了我们先验知识和观测系统的结构。这个练习将指导你从一个常见的状态空间模型（随机游走模型）出发，构建其先验信息矩阵，并通过局部观测来更新它。通过这个过程，你将亲身体会到模型的局部依赖性如何转化为信息矩阵的稀疏性（在此例中为三对角结构），而稀疏性正是信息滤波器在处理大规模问题时的关键计算优势。[@problem_id:3390748]", "problem": "考虑一个由 $n=5$ 个隐状态 $x_1, x_2, x_3, x_4, x_5$ 构成的一维链。假设一个随机游走高斯先验，其转移模型为 $x_{i+1} \\mid x_i \\sim \\mathcal{N}(x_i, q)$（其中 $i=1,2,3,4$），过程方差为 $q>0$；并假设一个锚定先验 $x_1 \\sim \\mathcal{N}(0, \\sigma_0^2)$，其方差为 $\\sigma_0^2>0$。该先验导出了一个关于 $\\mathbf{x} = (x_1, x_2, x_3, x_4, x_5)^{\\top}$ 的联合高斯分布，其精度（信息）矩阵是三对角的。\n\n你通过一个带状线性观测算子和独立高斯噪声收集了三个局部观测值：$y_1 = x_1 + v_1$，$y_3 = x_3 + v_3$ 和 $y_{45} = x_4 - x_5 + v_{45}$，其中 $v_1 \\sim \\mathcal{N}(0, r_1)$，$v_3 \\sim \\mathcal{N}(0, r_3)$ 和 $v_{45} \\sim \\mathcal{N}(0, r_{45})$，且 $r_1>0$，$r_3>0$，$r_{45}>0$。因此，观测算子 $H$ 和噪声协方差 $R$ 分别为\n$$\nH \\;=\\;\n\\begin{pmatrix}\n1  0  0  0  0 \\\\\n0  0  1  0  0 \\\\\n0  0  0  1  -1\n\\end{pmatrix},\n\\quad\nR \\;=\\; \\operatorname{diag}(r_1, r_3, r_{45}).\n$$\n\n从高斯模型的第一性原理以及精度（信息）矩阵作为负对数密度中二次型的定义出发，推导随机游走先验在 $\\mathbf{x}$ 上的先验精度矩阵，然后推导在同化这三个观测值后的后验精度矩阵。将你的最终结果表示为后验精度矩阵关于 $q$, $\\sigma_0^2$, $r_1$, $r_3$ 和 $r_{45}$ 的单个显式解析表达式。", "solution": "该问题是适定的，具有科学依据，并为求得唯一解提供了所有必要信息。它是反问题和数据同化领域的一个标准问题，特别涉及线性高斯状态空间模型及其信息形式的表示。\n\n根据贝叶斯定理，后验概率密度函数 $p(\\mathbf{x}|\\mathbf{y})$ 与似然 $p(\\mathbf{y}|\\mathbf{x})$ 和先验 $p(\\mathbf{x})$ 的乘积成正比。对于联合高斯分布，这种关系最方便的表示方式是使用它们的负对数，即二次型。后验精度（或信息）矩阵，记作 $\\Lambda_{\\text{post}}$，是先验精度矩阵 $\\Lambda_{\\text{prior}}$ 与似然相关的精度矩阵 $\\Lambda_{\\text{likelihood}}$ 之和。\n$$\n\\Lambda_{\\text{post}} = \\Lambda_{\\text{prior}} + \\Lambda_{\\text{likelihood}}\n$$\n我们分别推导每一项。\n\n首先，我们推导先验精度矩阵 $\\Lambda_{\\text{prior}}$。状态向量 $\\mathbf{x} = (x_1, x_2, x_3, x_4, x_5)^{\\top}$ 上的先验分布由链式法则给出：\n$$\np(\\mathbf{x}) = p(x_1) \\prod_{i=1}^{4} p(x_{i+1}|x_i)\n$$\n问题指定了分布：$x_1 \\sim \\mathcal{N}(0, \\sigma_0^2)$ 和 $x_{i+1}|x_i \\sim \\mathcal{N}(x_i, q)$。负对数先验（不计加性常数）为：\n$$\n-\\ln p(\\mathbf{x}) = -\\ln p(x_1) - \\sum_{i=1}^{4} \\ln p(x_{i+1}|x_i) = \\frac{1}{2\\sigma_0^2}x_1^2 + \\sum_{i=1}^{4}\\frac{1}{2q}(x_{i+1}-x_i)^2 + \\text{const.}\n$$\n这个表达式是关于 $\\mathbf{x}$ 的二次型，可以写成 $\\frac{1}{2}\\mathbf{x}^{\\top}\\Lambda_{\\text{prior}}\\mathbf{x}$。通过展开求和项并合并同类项，我们可以确定对称矩阵 $\\Lambda_{\\text{prior}}$ 的元素。\n$$\n\\frac{1}{2}\\mathbf{x}^{\\top}\\Lambda_{\\text{prior}}\\mathbf{x} = \\frac{1}{2\\sigma_0^2}x_1^2 + \\frac{1}{2q}\\left( (x_2-x_1)^2 + (x_3-x_2)^2 + (x_4-x_3)^2 + (x_5-x_4)^2 \\right)\n$$\n展开平方项：\n$$\n= \\frac{1}{2\\sigma_0^2}x_1^2 + \\frac{1}{2q}\\left( (x_1^2 - 2x_1x_2 + x_2^2) + (x_2^2 - 2x_2x_3 + x_3^2) + (x_3^2 - 2x_3x_4 + x_4^2) + (x_4^2 - 2x_4x_5 + x_5^2) \\right)\n$$\n收集每个二次项 $\\frac{1}{2}x_i x_j$ 的系数：", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{\\sigma_0^{2}} + \\frac{1}{q} + \\frac{1}{r_1}  -\\frac{1}{q}  0  0  0 \\\\\n-\\frac{1}{q}  \\frac{2}{q}  -\\frac{1}{q}  0  0 \\\\\n0  -\\frac{1}{q}  \\frac{2}{q} + \\frac{1}{r_3}  -\\frac{1}{q}  0 \\\\\n0  0  -\\frac{1}{q}  \\frac{2}{q} + \\frac{1}{r_{45}}  -\\frac{1}{q} - \\frac{1}{r_{45}} \\\\\n0  0  0  -\\frac{1}{q} - \\frac{1}{r_{45}}  \\frac{1}{q} + \\frac{1}{r_{45}}\n\\end{pmatrix}\n}\n$$", "id": "3390748"}, {"introduction": "理解了如何构建信息矩阵后，我们来探讨如何用它来同化新数据。这个练习将展示信息的可加性，并证明一个关键属性：对于线性高斯系统，逐个处理独立的观测数据（序贯更新）与一次性处理所有数据（批次更新）得到的结果是完全相同的。这种等价性是信息滤波器灵活性的基础，它揭示了信息在贝叶斯框架下是如何累积的。[@problem_id:3390747]", "problem": "考虑一个信息形式的线性高斯逆问题，其状态向量为 $x \\in \\mathbb{R}^{2}$，先验密度正比于 $\\exp\\!\\big(-\\tfrac{1}{2}\\,x^{\\top} Y x + y^{\\top} x\\big)$，其中先验信息矩阵和先验信息向量为\n$$\nY \\,=\\, \\begin{pmatrix} 3  1 \\\\ 1  2 \\end{pmatrix}, \\qquad y \\,=\\, \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}.\n$$\n您收到两个形式为 $z_{i} = h_{i}^{\\top} x + v_{i}$ 的独立标量观测，其中 $v_{i} \\sim \\mathcal{N}(0, r_{i})$，数据如下：\n$$\nh_{1} \\,=\\, \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\quad r_{1} \\,=\\, \\tfrac{1}{2}, \\quad z_{1} \\,=\\, \\tfrac{3}{2}; \n\\qquad\nh_{2} \\,=\\, \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}, \\quad r_{2} \\,=\\, 2, \\quad z_{2} \\,=\\, -\\tfrac{1}{2}.\n$$\n从贝叶斯法则和高斯似然出发，仅使用基本代数操作（例如，展开和配方法）作为基础，完成以下任务：\n\n1. 对于单个标量观测 $z = h^{\\top} x + v$（其中 $v \\sim \\mathcal{N}(0, r)$），推导其信息形式的后验更新。将更新后的信息矩阵 $Y^{+}$ 和更新后的信息向量 $y^{+}$ 表示为 $Y, y, h, r, z$ 的函数。\n\n2. 对上述两个观测顺序应用您的标量更新，以获得 $Y_{\\mathrm{seq}}$ 和 $y_{\\mathrm{seq}}$。\n\n3. 现在建立多观测模型 $z = H x + v$，其中\n$$\nH \\,=\\, \\begin{pmatrix} h_{1}^{\\top} \\\\ h_{2}^{\\top} \\end{pmatrix} \\,=\\, \\begin{pmatrix} 1  1 \\\\ 2  -1 \\end{pmatrix}, \n\\qquad \nR \\,=\\, \\operatorname{diag}(r_{1}, r_{2}) \\,=\\, \\begin{pmatrix} \\tfrac{1}{2}  0 \\\\ 0  2 \\end{pmatrix}, \n\\qquad \nz \\,=\\, \\begin{pmatrix} z_{1} \\\\ z_{2} \\end{pmatrix} \\,=\\, \\begin{pmatrix} \\tfrac{3}{2} \\\\ -\\tfrac{1}{2} \\end{pmatrix}.\n$$\n再次从高斯似然和配方法出发，推导批处理信息形式的后验更新，以获得 $Y_{\\mathrm{bat}}$ 和 $y_{\\mathrm{bat}}$。\n\n最后，定义标量\n$$\nS \\,=\\, \\big\\|\\, Y_{\\mathrm{seq}} - Y_{\\mathrm{bat}} \\,\\big\\|_{F}^{2} \\;+\\; \\big\\|\\, y_{\\mathrm{seq}} - y_{\\mathrm{bat}} \\,\\big\\|_{2}^{2},\n$$\n其中 $\\|\\cdot\\|_{F}$ 是弗罗贝尼乌斯范数，$\\|\\cdot\\|_{2}$ 是欧几里得范数。精确计算 $S$。将您的最终结果以单个实数的形式给出。无需四舍五入，也无需单位。", "solution": "该问题要求推导并应用线性高斯系统的信息形式更新，包括顺序更新和批处理更新两种形式，然后对结果进行比较。状态向量为 $x \\in \\mathbb{R}^{2}$。\n\n分析从对数形式的贝叶斯法则开始，该法则指出，对数后验与对数似然和对数先验之和成正比，相差一个加性常数：\n$$\n\\ln p(x|\\text{data}) = \\ln p(\\text{data}|x) + \\ln p(x) + C\n$$\n先验概率密度 $p(x)$ 以信息形式给出，正比于 $\\exp(-\\frac{1}{2}x^{\\top} Y x + y^{\\top} x)$。指数部分，我们记为 $J_{\\text{prior}}(x)$，是：\n$$\nJ_{\\text{prior}}(x) = -\\frac{1}{2}x^{\\top} Y x + y^{\\top} x\n$$\n\n1. 标量更新法则的推导。\n\n对于单个标量观测 $z = h^{\\top} x + v$，其中噪声 $v$ 服从 $\\mathcal{N}(0, r)$ 分布，似然函数 $p(z|x)$ 是一个高斯函数：\n$$\np(z|x) = \\frac{1}{\\sqrt{2\\pi r}} \\exp\\left(-\\frac{1}{2r}(z - h^{\\top} x)^2\\right)\n$$\n对数似然，忽略与 $x$ 无关的常数项，正比于指数部分，我们称之为 $J_{\\text{like}}(x)$：\n$$\nJ_{\\text{like}}(x) = -\\frac{1}{2r}(z - h^{\\top} x)^2\n$$\n展开这个二次型：\n$$\nJ_{\\text{like}}(x) = -\\frac{1}{2r}(z^2 - 2z h^{\\top} x + (h^{\\top} x)^2) = -\\frac{1}{2r}(z^2 - 2z x^{\\top} h + x^{\\top} h h^{\\top} x)\n$$\n省略与 $x$ 无关的项 $-\\frac{z^2}{2r}$，我们得到：\n$$\nJ_{\\text{like}}(x) = \\frac{z}{r} x^{\\top} h - \\frac{1}{2r} x^{\\top} h h^{\\top} x = -\\frac{1}{2} x^{\\top} \\left( \\frac{1}{r} h h^{\\top} \\right) x + \\left( \\frac{z}{r} h \\right)^{\\top} x\n$$\n后验对数密度的指数部分 $J_{\\text{post}}(x)$ 是先验和似然指数部分之和：\n$$\nJ_{\\text{post}}(x) = J_{\\text{prior}}(x) + J_{\\text{like}}(x) = \\left(-\\frac{1}{2}x^{\\top} Y x + y^{\\top} x\\right) + \\left(-\\frac{1}{2} x^{\\top} \\left(\\frac{1}{r} h h^{\\top}\\right) x + \\left(\\frac{z}{r} h\\right)^{\\top} x\\right)\n$$\n合并关于 $x$ 的二次项和一次项：\n$$\nJ_{\\text{post}}(x) = -\\frac{1}{2} x^{\\top} \\left(Y + \\frac{1}{r} h h^{\\top}\\right) x + \\left(y + \\frac{z}{r} h\\right)^{\\top} x\n$$\n将此与一般信息形式 $-\\frac{1}{2}x^{\\top} Y^{+} x + (y^{+})^{\\top} x$ 进行比较，我们可以确定更新后的信息矩阵 $Y^{+}$ 和信息向量 $y^{+}$：\n$$\nY^{+} = Y + \\frac{1}{r} h h^{\\top}\n$$\n$$\ny^{+} = y + \\frac{z}{r} h\n$$\n\n2. 顺序应用标量更新。\n\n我们从先验信息 $Y = \\begin{pmatrix} 3  1 \\\\ 1  2 \\end{pmatrix}$ 和 $y = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$ 开始。\n\n第一次观测更新：$h_{1} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, r_{1} = \\frac{1}{2}, z_{1} = \\frac{3}{2}$。\n来自此观测的信息贡献为 $\\frac{1}{r_1}h_{1}h_{1}^{\\top}$ 和 $\\frac{z_1}{r_1}h_1$。\n$$\n\\frac{1}{r_1}h_{1}h_{1}^{\\top} = \\frac{1}{1/2}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\begin{pmatrix} 1  1 \\end{pmatrix} = 2\\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix} = \\begin{pmatrix} 2  2 \\\\ 2  2 \\end{pmatrix}\n$$\n$$\n\\frac{z_1}{r_1}h_1 = \\frac{3/2}{1/2}\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = 3\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix}\n$$\n中间后验信息矩阵 $Y_{1}$ 和向量 $y_{1}$ 为：\n$$\nY_{1} = Y + \\frac{1}{r_1}h_{1}h_{1}^{\\top} = \\begin{pmatrix} 3  1 \\\\ 1  2 \\end{pmatrix} + \\begin{pmatrix} 2  2 \\\\ 2  2 \\end{pmatrix} = \\begin{pmatrix} 5  3 \\\\ 3  4 \\end{pmatrix}\n$$\n$$\ny_{1} = y + \\frac{z_1}{r_1}h_1 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} + \\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 1 \\end{pmatrix}\n$$\n第二次观测更新：$h_{2} = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}, r_{2} = 2, z_{2} = -\\frac{1}{2}$。\n此更新应用于中间后验 $(Y_1, y_1)$。\n$$\n\\frac{1}{r_2}h_{2}h_{2}^{\\top} = \\frac{1}{2}\\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}\\begin{pmatrix} 2  -1 \\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix} 4  -2 \\\\ -2  1 \\end{pmatrix} = \\begin{pmatrix} 2  -1 \\\\ -1  \\frac{1}{2} \\end{pmatrix}\n$$\n$$\n\\frac{z_2}{r_2}h_2 = \\frac{-1/2}{2}\\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} = -\\frac{1}{4}\\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix}\n$$\n最终的顺序后验信息矩阵 $Y_{\\mathrm{seq}}$ 和向量 $y_{\\mathrm{seq}}$ 为：\n$$\nY_{\\mathrm{seq}} = Y_{1} + \\frac{1}{r_2}h_{2}h_{2}^{\\top} = \\begin{pmatrix} 5  3 \\\\ 3  4 \\end{pmatrix} + \\begin{pmatrix} 2  -1 \\\\ -1  \\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 7  2 \\\\ 2  \\frac{9}{2} \\end{pmatrix}\n$$\n$$\ny_{\\mathrm{seq}} = y_{1} + \\frac{z_2}{r_2}h_2 = \\begin{pmatrix} 4 \\\\ 1 \\end{pmatrix} + \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix} = \\begin{pmatrix} \\frac{7}{2} \\\\ \\frac{5}{4} \\end{pmatrix}\n$$\n\n3. 批处理更新的推导和应用。\n\n对于多观测模型 $z = Hx + v$（其中 $v \\sim \\mathcal{N}(0, R)$），忽略常数项，对数似然的指数部分为：\n$$\nJ_{\\text{like}}(x) = -\\frac{1}{2}(z - Hx)^{\\top} R^{-1} (z - Hx)\n$$\n展开此表达式：\n$$\nJ_{\\text{like}}(x) = -\\frac{1}{2}(z^{\\top}R^{-1}z - z^{\\top}R^{-1}Hx - x^{\\top}H^{\\top}R^{-1}z + x^{\\top}H^{\\top}R^{-1}Hx)\n$$\n省略项 $-\\frac{1}{2}z^{\\top}R^{-1}z$ 并合并两个线性项（它们是标量，互为转置）：\n$$\nJ_{\\text{like}}(x) = -\\frac{1}{2}x^{\\top}(H^{\\top}R^{-1}H)x + (H^{\\top}R^{-1}z)^{\\top}x\n$$\n批处理后验的指数部分是 $J_{\\text{post}}(x) = J_{\\text{prior}}(x) + J_{\\text{like}}(x)$：\n$$\nJ_{\\text{post}}(x) = \\left(-\\frac{1}{2}x^{\\top} Y x + y^{\\top} x\\right) + \\left(-\\frac{1}{2}x^{\\top}(H^{\\top}R^{-1}H)x + (H^{\\top}R^{-1}z)^{\\top}x\\right)\n$$\n$$\nJ_{\\text{post}}(x) = -\\frac{1}{2}x^{\\top}(Y + H^{\\top}R^{-1}H)x + (y + H^{\\top}R^{-1}z)^{\\top}x\n$$\n这给出了批处理更新法则：\n$$\nY_{\\mathrm{bat}} = Y + H^{\\top}R^{-1}H\n$$\n$$\ny_{\\mathrm{bat}} = y + H^{\\top}R^{-1}z\n$$\n现在我们使用给定的批处理数据应用此法则：$H = \\begin{pmatrix} 1  1 \\\\ 2  -1 \\end{pmatrix}$, $R = \\begin{pmatrix} \\frac{1}{2}  0 \\\\ 0  2 \\end{pmatrix}$, $z = \\begin{pmatrix} \\frac{3}{2} \\\\ -\\frac{1}{2} \\end{pmatrix}$。\n协方差矩阵的逆为 $R^{-1} = \\begin{pmatrix} 2  0 \\\\ 0  \\frac{1}{2} \\end{pmatrix}$。\n首先，我们计算信息贡献矩阵 $H^{\\top}R^{-1}H$：\n$$\nH^{\\top}R^{-1}H = \\begin{pmatrix} 1  2 \\\\ 1  -1 \\end{pmatrix} \\begin{pmatrix} 2  0 \\\\ 0  \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} 1  1 \\\\ 2  -1 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 2  -\\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} 1  1 \\\\ 2  -1 \\end{pmatrix} = \\begin{pmatrix} 4  1 \\\\ 1  \\frac{5}{2} \\end{pmatrix}\n$$\n然后，我们计算信息贡献向量 $H^{\\top}R^{-1}z$：\n$$\nH^{\\top}R^{-1}z = \\begin{pmatrix} 1  2 \\\\ 1  -1 \\end{pmatrix} \\begin{pmatrix} 2  0 \\\\ 0  \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} \\frac{3}{2} \\\\ -\\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 1  2 \\\\ 1  -1 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ -\\frac{1}{4} \\end{pmatrix} = \\begin{pmatrix} 3-\\frac{1}{2} \\\\ 3+\\frac{1}{4} \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{2} \\\\ \\frac{13}{4} \\end{pmatrix}\n$$\n现在，我们求出批处理后验信息矩阵 $Y_{\\mathrm{bat}}$ 和向量 $y_{\\mathrm{bat}}$：\n$$\nY_{\\mathrm{bat}} = Y + H^{\\top}R^{-1}H = \\begin{pmatrix} 3  1 \\\\ 1  2 \\end{pmatrix} + \\begin{pmatrix} 4  1 \\\\ 1  \\frac{5}{2} \\end{pmatrix} = \\begin{pmatrix} 7  2 \\\\ 2  \\frac{9}{2} \\end{pmatrix}\n$$\n$$\ny_{\\mathrm{bat}} = y + H^{\\top}R^{-1}z = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} + \\begin{pmatrix} \\frac{5}{2} \\\\ \\frac{13}{4} \\end{pmatrix} = \\begin{pmatrix} \\frac{2+5}{2} \\\\ \\frac{-8+13}{4} \\end{pmatrix} = \\begin{pmatrix} \\frac{7}{2} \\\\ \\frac{5}{4} \\end{pmatrix}\n$$\n\n最后，我们计算标量 $S$。\n通过比较顺序更新和批处理更新的结果，我们发现它们是相同的：\n$$\nY_{\\mathrm{seq}} = \\begin{pmatrix} 7  2 \\\\ 2  \\frac{9}{2} \\end{pmatrix} = Y_{\\mathrm{bat}}\n$$\n$$\ny_{\\mathrm{seq}} = \\begin{pmatrix} \\frac{7}{2} \\\\ \\frac{5}{4} \\end{pmatrix} = y_{\\mathrm{bat}}\n$$\n因此，差值为零矩阵和零向量：\n$$\nY_{\\mathrm{seq}} - Y_{\\mathrm{bat}} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}\n$$\n$$\ny_{\\mathrm{seq}} - y_{\\mathrm{bat}} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n标量 $S$ 定义为 $S = \\big\\|\\, Y_{\\mathrm{seq}} - Y_{\\mathrm{bat}} \\,\\big\\|_{F}^{2} \\;+\\; \\big\\|\\, y_{\\mathrm{seq}} - y_{\\mathrm{bat}} \\,\\big\\|_{2}^{2}$。\n零矩阵的弗罗贝尼乌斯范数的平方是：\n$$\n\\big\\|\\, Y_{\\mathrm{seq}} - Y_{\\mathrm{bat}} \\,\\big\\|_{F}^{2} = 0^2 + 0^2 + 0^2 + 0^2 = 0\n$$\n零向量的欧几里得范数的平方是：\n$$\n\\big\\|\\, y_{\\mathrm{seq}} - y_{\\mathrm{bat}} \\,\\big\\|_{2}^{2} = 0^2 + 0^2 = 0\n$$\n因此，$S$ 的值为：\n$$\nS = 0 + 0 = 0\n$$\n这个结果证明了线性高斯系统的一个基本性质：顺序贝叶斯更新等价于一个同时包含所有数据的批处理更新。", "answer": "$$\\boxed{0}$$", "id": "3390747"}, {"introduction": "信息矩阵不仅是计算工具，更是决策制定的指南，尤其在最优实验设计中。本练习深入探讨了信息矩阵的谱特性（即其特征值和特征向量），展示了矩阵的特征值如何与状态估计在不同方向上的不确定性一一对应。通过策略性地布设一个新传感器来增大最小的特征值，我们可以精确地瞄准并减小状态估计中最大的不确定性来源，从而实现高效的数据采集。[@problem_id:3390762]", "problem": "考虑一个数据同化背景下的状态向量 $x \\in \\mathbb{R}^{3}$ 的线性高斯逆问题。在同化了初始的一组传感器之后，当前的后验信息（精度）矩阵 $Y_{\\text{post}}$ 具有一个标准正交特征基 $\\{v_{1}, v_{2}, v_{3}\\}$，其谱分解为 $Y_{\\text{post}} = U \\,\\mathrm{diag}(\\lambda_{1}, \\lambda_{2}, \\lambda_{3})\\, U^{\\top}$，其中 $U = [v_{1}\\ v_{2}\\ v_{3}]$，特征值为 $\\lambda_{1} = 9$，$\\lambda_{2} = 2$ 和 $\\lambda_{3} = 0.08$。您正在考虑通过增加一个额外的标量传感器来增强传感网络，该传感器产生 $y_{\\star}$，由线性观测算子 $H_{\\star}$ 和独立高斯噪声 $\\varepsilon_{\\star}$ 建模：\n$$\ny_{\\star} = H_{\\star} x + \\varepsilon_{\\star}, \\quad \\varepsilon_{\\star} \\sim \\mathcal{N}(0, R_{\\star}),\n$$\n其中 $H_{\\star} = \\gamma\\, v_{3}^{\\top}$，$\\gamma = 0.2$ 且 $R_{\\star} = 0.04$。从线性高斯模型的第一性原理和对数后验海森矩阵的定义出发，推导增加的传感器如何改变后验信息矩阵的最小特征值，并计算其精确数值。然后，定性地解释这一变化如何对应于沿观测不佳方向 $v_{3}$ 的不确定性减少。\n\n您的最终答案必须是新的后验信息矩阵最小特征值的单一数值。无需四舍五入。", "solution": "该问题要求我们确定新的传感器测量对状态向量 $x \\in \\mathbb{R}^{3}$ 的后验信息矩阵的影响。我们必须首先推导信息矩阵的更新规则，将其应用于给定问题，计算新的最小特征值，然后提供定性解释。\n\n在同化新测量值 $y_{\\star}$ 后，状态 $x$ 的后验概率密度函数（PDF）由贝叶斯定理给出：\n$$\np(x | y_{\\star}, \\text{previous data}) \\propto p(y_{\\star} | x) \\, p(x | \\text{previous data})\n$$\n项 $p(x | \\text{previous data})$ 表示当前的后验信念，它作为此次更新的先验。在线性高斯框架中，此分布为高斯分布，$x \\sim \\mathcal{N}(\\mu_{\\text{post}}, P_{\\text{post}})$，其中后验协方差为 $P_{\\text{post}} = Y_{\\text{post}}^{-1}$。信息矩阵 $Y_{\\text{post}}$ 是先前同化步骤中负对数后验的海森矩阵。PDF 正比于 $\\exp(-\\frac{1}{2}(x - \\mu_{\\text{post}})^{\\top} Y_{\\text{post}} (x - \\mu_{\\text{post}}))$。\n\n项 $p(y_{\\star} | x)$ 是新测量的似然，由传感器模型 $y_{\\star} = H_{\\star}x + \\varepsilon_{\\star}$ 给出，其中噪声 $\\varepsilon_{\\star} \\sim \\mathcal{N}(0, R_{\\star})$。这对应于 PDF $p(y_{\\star} | x) \\propto \\exp(-\\frac{1}{2}(y_{\\star} - H_{\\star}x)^{\\top} R_{\\star}^{-1} (y_{\\star} - H_{\\star}x))$。\n\n因此，新的后验 PDF 正比于这些指数项的乘积。新后验的负对数，记为 $J_{\\text{new}}(x)$，（在相差一个加性常数的情况下）为：\n$$\nJ_{\\text{new}}(x) = \\frac{1}{2}(x - \\mu_{\\text{post}})^{\\top} Y_{\\text{post}} (x - \\mu_{\\text{post}}) + \\frac{1}{2}(y_{\\star} - H_{\\star}x)^{\\top} R_{\\star}^{-1} (y_{\\star} - H_{\\star}x)\n$$\n新的后验信息矩阵 $Y_{\\text{new}}$ 定义为该负对数后验的海森矩阵，$Y_{\\text{new}} = \\nabla_x^2 J_{\\text{new}}(x)$。为计算海森矩阵，我们首先求梯度 $\\nabla_x J_{\\text{new}}(x)$：\n$$\n\\nabla_x J_{\\text{new}}(x) = Y_{\\text{post}}(x - \\mu_{\\text{post}}) + H_{\\star}^{\\top} R_{\\star}^{-1} (H_{\\star}x - y_{\\star})\n$$\n再次对 $x$ 求导得到海森矩阵：\n$$\n\\nabla_x^2 J_{\\text{new}}(x) = Y_{\\text{post}} + H_{\\star}^{\\top}R_{\\star}^{-1}H_{\\star}\n$$\n因此，信息更新规则为：\n$$\nY_{\\text{new}} = Y_{\\text{post}} + H_{\\star}^{\\top}R_{\\star}^{-1}H_{\\star}\n$$\n现在，我们将此规则应用于问题的具体情况。我们已知当前后验信息矩阵的谱分解：\n$$\nY_{\\text{post}} = \\sum_{i=1}^{3} \\lambda_i v_i v_i^{\\top} = \\lambda_1 v_1 v_1^{\\top} + \\lambda_2 v_2 v_2^{\\top} + \\lambda_3 v_3 v_3^{\\top}\n$$\n其特征值为 $\\lambda_1 = 9$，$\\lambda_2 = 2$ 和 $\\lambda_3 = 0.08$。特征向量 $\\{v_1, v_2, v_3\\}$ 构成一个标准正交基。\n新传感器的观测模型由 $H_{\\star} = \\gamma v_3^{\\top}$ 定义，其中 $\\gamma = 0.2$，噪声方差为 $R_{\\star} = 0.04$。由于 $R_{\\star}$ 是一个标量，其逆为 $R_{\\star}^{-1} = 1/R_{\\star}$。\n\n更新项是一个秩一矩阵：\n$$\nH_{\\star}^{\\top}R_{\\star}^{-1}H_{\\star} = (\\gamma v_3) (R_{\\star}^{-1}) (\\gamma v_3^{\\top}) = \\frac{\\gamma^2}{R_{\\star}} v_3 v_3^{\\top}\n$$\n将此代入更新规则：\n$$\nY_{\\text{new}} = \\left( \\lambda_1 v_1 v_1^{\\top} + \\lambda_2 v_2 v_2^{\\top} + \\lambda_3 v_3 v_3^{\\top} \\right) + \\frac{\\gamma^2}{R_{\\star}} v_3 v_3^{\\top}\n$$\n我们可以将与每个特征向量相关的项归集起来：\n$$\nY_{\\text{new}} = \\lambda_1 v_1 v_1^{\\top} + \\lambda_2 v_2 v_2^{\\top} + \\left(\\lambda_3 + \\frac{\\gamma^2}{R_{\\star}}\\right) v_3 v_3^{\\top}\n$$\n这个表达式是新信息矩阵 $Y_{\\text{new}}$ 的谱分解。特征向量 $v_1$, $v_2$, 和 $v_3$ 保持不变。新的特征值，记为 $\\lambda_i^{\\text{new}}$，是 $v_i v_i^{\\top}$ 项的系数：\n$$\n\\lambda_1^{\\text{new}} = \\lambda_1 = 9\n$$\n$$\n\\lambda_2^{\\text{new}} = \\lambda_2 = 2\n$$\n$$\n\\lambda_3^{\\text{new}} = \\lambda_3 + \\frac{\\gamma^2}{R_{\\star}}\n$$\n现在我们计算 $\\lambda_3^{\\text{new}}$ 的数值。我们已知 $\\lambda_3 = 0.08$，$\\gamma = 0.2$ 且 $R_{\\star} = 0.04$。\n$$\n\\frac{\\gamma^2}{R_{\\star}} = \\frac{(0.2)^2}{0.04} = \\frac{0.04}{0.04} = 1\n$$\n因此，新的第三个特征值为：\n$$\n\\lambda_3^{\\text{new}} = 0.08 + 1 = 1.08\n$$\n新的特征值集合为 $\\{9, 2, 1.08\\}$。因此，新后验信息矩阵的最小特征值是 $1.08$。\n\n定性地看，信息矩阵的特征值与协方差矩阵的特征值成反比关系（$Y = P^{-1}$）。协方差矩阵的特征值表示状态估计在相应特征向量方向上的方差（不确定性的度量）。因此，信息矩阵的一个小特征值 $\\lambda_i$ 对应于 $v_i$ 方向上的大方差（高不确定性）。\n最初，最小的特征值是 $\\lambda_3 = 0.08$，这表明 $v_3$ 方向是观测最差的方向，即它具有最高的后验不确定性。\n新传感器的观测算子为 $H_{\\star} = \\gamma v_3^{\\top}$，这意味着它测量状态向量 $x$ 沿 $v_3$ 方向的分量（因为 $H_{\\star}x = \\gamma v_3^{\\top}x$）。该传感器专门设计用于在现有不确定性最大的方向上收集关于状态的信息。\n同化这次测量增加了信息，特别是在 $v_3$ 方向上。这在数学上反映为只有 $\\lambda_3$ 被更新，而 $\\lambda_1$ 和 $\\lambda_2$ 保持不变。新特征值 $\\lambda_3^{\\text{new}} = 1.08$ 远大于原来的 $\\lambda_3 = 0.08$。信息特征值的增加对应于 $v_3$ 方向后验方差（不确定性）的显著减小。该传感器成功地减少了先前最不确定方向上的不确定性。更新后系统的最小特征值现在是 $1.08$，相比之前的 $0.08$ 有了显著的改善。", "answer": "$$\n\\boxed{1.08}\n$$", "id": "3390762"}]}