{"hands_on_practices": [{"introduction": "本练习将引导你完成将拉普拉斯近似应用于经典贝塔-二项模型的分步过程。这是一个基础性练习，旨在让你理解如何找到后验模式（MAP），并利用该点的曲率（Hessian）来构建高斯近似。通过这个具体的计算，你将亲身体验拉普拉斯近似的核心思想。[@problem_id:3281857]", "problem": "一枚偏差未知（$\\theta \\in (0,1)$）的硬币使用贝塔-二项分布框架建模：先验分布为 $\\theta \\sim \\mathrm{Beta}(\\alpha,\\beta)$，在给定 $\\theta$ 的条件下，$n$ 次独立投掷中正面朝上的次数 $X$ 服从 $X \\mid \\theta \\sim \\mathrm{Binomial}(n,\\theta)$。观测到 $n=200$ 次投掷和 $k=120$ 次正面朝上。先验分布为 $\\mathrm{Beta}(\\alpha,\\beta)$，其中 $\\alpha=8$ 且 $\\beta=12$。令 $\\pi(\\theta \\mid k)$ 表示给定数据时 $\\theta$ 的后验密度。\n\n使用泰勒定理，对数后验 $\\ln \\pi(\\theta \\mid k)$ 在其最大后验 (MAP) 值附近进行二阶展开，从而获得后验分布的拉普拉斯（高斯）近似。使用此近似估计后验概率 $P(\\theta > 0.5 \\mid k)$。你的推理必须从贝塔先验和二项似然的基本定义开始，经过对数后验的构建，然后使用泰勒定理推导出围绕最大后验值的二次近似。在此，只要你证明最大后验值相对于曲率而言，远在 $(0,1)$ 区间内部，那么用 $\\mathbb{R}$ 上的高斯分布来近似后验是可以接受的。将最终概率表示为小数，并四舍五入到四位有效数字。", "solution": "用户希望找到贝塔-二项后验分布的拉普拉斯近似，并用它来估计一个概率。\n\n以下是分步推导过程：\n\n### 第 1 步：问题验证\n\n**1. 提取给定信息：**\n*   模型：贝塔-二项分布框架。\n*   先验：$\\theta \\sim \\mathrm{Beta}(\\alpha, \\beta)$，其中 $\\alpha = 8$ 且 $\\beta = 12$。\n*   似然：$X \\mid \\theta \\sim \\mathrm{Binomial}(n, \\theta)$。\n*   数据：$n = 200$ 次投掷，$k = 120$ 次正面朝上。\n*   后验密度：$\\pi(\\theta \\mid k)$。\n*   任务：\n    1.  对对数后验 $\\ln \\pi(\\theta \\mid k)$ 在最大后验 (MAP) 值附近进行二阶泰勒展开。\n    2.  推导后验分布的拉普拉斯（高斯）近似。\n    3.  使用此近似估计后验概率 $P(\\theta > 0.5 \\mid k)$。\n    4.  将最终答案四舍五入到四位有效数字。\n\n**2. 使用提取信息进行验证：**\n*   **科学依据：**该问题使用了贝叶斯统计中标准的、成熟的模型（贝塔-二项分布）和方法（拉普拉斯近似）。它在科学上是合理的。\n*   **适定性：**该问题提供了所有必要的信息（$\\alpha, \\beta, n, k$），可以唯一确定后验分布及其近似。问题具体，且有唯一答案。\n*   **客观性：**该问题使用精确的数学和统计术语进行陈述。\n*   **完整性和一致性：**给定的参数（$\\alpha=8, \\beta=12$）和数据（$n=200, k=120$）在指定的模型中是有效且一致的。例如，$0 \\le k \\le n$。\n*   **相关性：**该问题直接涉及应用泰勒定理来构建近似，这是数值方法和科学计算中的一个核心概念。\n\n**3. 结论与行动：**\n问题是有效的。我们将继续进行解答。\n\n### 第 2 步：解答推导\n\n解题过程首先确定后验分布，然后找到其众数（最大后验值），最后围绕该众数构建一个高斯近似。\n\n**1. 后验分布**\n$\\theta$ 的先验概率密度函数 (PDF) 是贝塔分布：\n$$ \\pi(\\theta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} $$\n对于此问题，$\\alpha = 8$ 且 $\\beta = 12$。\n\n在 $n=200$ 次投掷中观测到 $k=120$ 次正面的似然由二项概率质量函数给出：\n$$ P(k \\mid \\theta) = \\binom{n}{k} \\theta^k (1-\\theta)^{n-k} $$\n\n根据贝叶斯定理，后验 PDF 正比于似然与先验的乘积：\n$$ \\pi(\\theta \\mid k) \\propto P(k \\mid \\theta) \\pi(\\theta) $$\n$$ \\pi(\\theta \\mid k) \\propto \\left[ \\binom{n}{k} \\theta^k (1-\\theta)^{n-k} \\right] \\left[ \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} \\right] $$\n忽略不依赖于 $\\theta$ 的常数，我们得到后验分布的核：\n$$ \\pi(\\theta \\mid k) \\propto \\theta^k (1-\\theta)^{n-k} \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} $$\n$$ \\pi(\\theta \\mid k) \\propto \\theta^{k+\\alpha-1} (1-\\theta)^{n-k+\\beta-1} $$\n这是一个贝塔分布的核，其更新后的参数为 $\\alpha' = k+\\alpha$ 和 $\\beta' = n-k+\\beta$。\n代入给定值：\n$$ \\alpha' = 120 + 8 = 128 $$\n$$ \\beta' = (200 - 120) + 12 = 80 + 12 = 92 $$\n因此，确切的后验分布是 $\\theta \\mid k \\sim \\mathrm{Beta}(128, 92)$。\n\n**2. 对数后验及其导数**\n对数后验，记为 $L(\\theta) = \\ln \\pi(\\theta \\mid k)$，在相差一个加性常数的情况下为：\n$$ L(\\theta) = (\\alpha' - 1) \\ln(\\theta) + (\\beta' - 1) \\ln(1-\\theta) $$\n$$ L(\\theta) = (128 - 1) \\ln(\\theta) + (92 - 1) \\ln(1-\\theta) = 127 \\ln(\\theta) + 91 \\ln(1-\\theta) $$\n\n关于 $\\theta$ 的一阶导数是：\n$$ \\frac{dL}{d\\theta} = \\frac{127}{\\theta} - \\frac{91}{1-\\theta} $$\n\n二阶导数是：\n$$ \\frac{d^2L}{d\\theta^2} = -\\frac{127}{\\theta^2} - \\frac{91}{(1-\\theta)^2} $$\n\n**3. 最大后验 (MAP) 估计**\n最大后验估计 $\\hat{\\theta}_{MAP}$ 是后验分布的众数，通过将对数后验的一阶导数设为零求得：\n$$ \\frac{127}{\\hat{\\theta}_{MAP}} - \\frac{91}{1-\\hat{\\theta}_{MAP}} = 0 $$\n$$ 127(1-\\hat{\\theta}_{MAP}) = 91\\hat{\\theta}_{MAP} $$\n$$ 127 - 127\\hat{\\theta}_{MAP} = 91\\hat{\\theta}_{MAP} $$\n$$ 127 = (91 + 127)\\hat{\\theta}_{MAP} = 218\\hat{\\theta}_{MAP} $$\n$$ \\hat{\\theta}_{MAP} = \\frac{127}{218} $$\n\n**4. 泰勒展开和拉普拉斯近似**\n拉普拉斯近似基于对数后验 $L(\\theta)$ 在其最大值 $\\hat{\\theta}_{MAP}$ 附近的二阶泰勒级数展开：\n$$ L(\\theta) \\approx L(\\hat{\\theta}_{MAP}) + \\frac{dL}{d\\theta}\\bigg|_{\\hat{\\theta}_{MAP}} (\\theta - \\hat{\\theta}_{MAP}) + \\frac{1}{2} \\frac{d^2L}{d\\theta^2}\\bigg|_{\\hat{\\theta}_{MAP}} (\\theta - \\hat{\\theta}_{MAP})^2 $$\n由于根据最大后验的定义 $\\frac{dL}{d\\theta}\\big|_{\\hat{\\theta}_{MAP}} = 0$，这可以简化为：\n$$ L(\\theta) \\approx L(\\hat{\\theta}_{MAP}) + \\frac{1}{2} \\left( \\frac{d^2L}{d\\theta^2}\\bigg|_{\\hat{\\theta}_{MAP}} \\right) (\\theta - \\hat{\\theta}_{MAP})^2 $$\n后验密度为 $\\pi(\\theta \\mid k) = \\exp(L(\\theta))$。对其进行近似得到：\n$$ \\pi(\\theta \\mid k) \\approx \\exp\\left(L(\\hat{\\theta}_{MAP})\\right) \\exp\\left( \\frac{1}{2} \\left( \\frac{d^2L}{d\\theta^2}\\bigg|_{\\hat{\\theta}_{MAP}} \\right) (\\theta - \\hat{\\theta}_{MAP})^2 \\right) $$\n这个表达式具有高斯（正态）密度函数 $N(\\mu, \\sigma^2)$ 的形式，该函数正比于 $\\exp\\left(-\\frac{(\\theta-\\mu)^2}{2\\sigma^2}\\right)$。\n通过比较指数部分，我们可以确定近似高斯分布的均值 $\\mu$ 和方差 $\\sigma^2$：\n$$ \\mu = \\hat{\\theta}_{MAP} = \\frac{127}{218} $$\n$$ -\\frac{1}{\\sigma^2} = \\frac{d^2L}{d\\theta^2}\\bigg|_{\\hat{\\theta}_{MAP}} $$\n让我们计算在最大后验值处的二阶导数：\n$$ \\frac{d^2L}{d\\theta^2}\\bigg|_{\\hat{\\theta}_{MAP}} = -\\frac{127}{\\hat{\\theta}_{MAP}^2} - \\frac{91}{(1-\\hat{\\theta}_{MAP})^2} $$\n我们有 $\\hat{\\theta}_{MAP} = \\frac{127}{218}$ 且 $1 - \\hat{\\theta}_{MAP} = 1 - \\frac{127}{218} = \\frac{91}{218}$。\n$$ \\frac{d^2L}{d\\theta^2}\\bigg|_{\\hat{\\theta}_{MAP}} = -\\frac{127}{(127/218)^2} - \\frac{91}{(91/218)^2} = -\\frac{218^2}{127} - \\frac{218^2}{91} $$\n$$ = -218^2 \\left( \\frac{1}{127} + \\frac{1}{91} \\right) = -218^2 \\left( \\frac{91+127}{127 \\times 91} \\right) = -218^2 \\left( \\frac{218}{11557} \\right) = -\\frac{218^3}{11557} $$\n因此，高斯近似的方差是：\n$$ \\sigma^2 = - \\left( \\frac{d^2L}{d\\theta^2}\\bigg|_{\\hat{\\theta}_{MAP}} \\right)^{-1} = \\frac{11557}{218^3} $$\n对后验的拉普拉斯近似为 $\\theta \\mid k \\approx N(\\mu, \\sigma^2)$，其中：\n$$ \\mu = \\frac{127}{218} \\approx 0.5825688 $$\n$$ \\sigma^2 = \\frac{11557}{10365032} \\approx 0.00111596 $$\n后验贝塔分布的参数 $\\alpha' = 128$ 和 $\\beta' = 92$ 很大，并且众数 $\\hat{\\theta}_{MAP} \\approx 0.583$ 相对于标准差 $\\sigma = \\sqrt{\\sigma^2} \\approx 0.0334$ 而言，远离边界 0 和 1。这证明了在实数线上使用高斯近似的合理性。\n\n**5. 概率计算**\n我们需要使用高斯近似 $Z \\sim N(\\mu, \\sigma^2)$ 来估计 $P(\\theta > 0.5 \\mid k)$，其中 $Z$ 是我们对 $\\theta$ 的近似。我们对变量进行标准化：\n$$ P(Z > 0.5) = P\\left(\\frac{Z - \\mu}{\\sigma} > \\frac{0.5 - \\mu}{\\sigma}\\right) $$\n让我们计算 z-score：\n$$ z = \\frac{0.5 - \\mu}{\\sigma} = \\frac{0.5 - \\frac{127}{218}}{\\sqrt{\\frac{11557}{218^3}}} = \\frac{\\frac{109-127}{218}}{\\frac{\\sqrt{11557}}{218\\sqrt{218}}} = \\frac{-18}{\\frac{\\sqrt{11557}}{\\sqrt{218}}} = -18\\sqrt{\\frac{218}{11557}} $$\n$$ z \\approx -2.47163 $$\n概率为 $P(Y > z)$，其中 $Y \\sim N(0, 1)$。根据标准正态分布的对称性，$P(Y > z) = P(Y < -z) = \\Phi(-z)$，其中 $\\Phi$ 是标准正态累积分布函数 (CDF)。\n$$ P(\\theta > 0.5 \\mid k) \\approx \\Phi(-z) = \\Phi(2.47163) $$\n使用标准正态累积分布函数计算器，$\\Phi(2.47163) \\approx 0.993275$。\n四舍五入到四位有效数字，概率为 $0.9933$。", "answer": "$$\n\\boxed{0.9933}\n$$", "id": "3281857"}, {"introduction": "在掌握了基础知识后，这个问题将探讨后验分布不对称的场景。通过在泊松-伽马模型中比较精确的伽马后验分布与其拉普拉斯近似，你将量化在估计后验均值和期望损失等量时的误差。这个练习揭示了近似性能的一个关键方面：近似的准确性与后验分布的对称性密切相关。[@problem_id:3137250]", "problem": "考虑以下贝叶斯单参数模型，其中独立观测值来自泊松分布，先验为伽马分布。设 $\\{y_i\\}_{i=1}^n$ 是来自 $\\text{Poisson}(\\lambda)$ 的独立抽样，其中未知率 $\\lambda > 0$。使用伽马先验 $\\lambda \\sim \\text{Gamma}(a,b)$，其形状参数为 $a > 0$，率参数为 $b > 0$。使用贝叶斯定理以及泊松似然和伽马先验的定义作为基本基础。最大后验（MAP）估计量是后验众数。拉普拉斯近似通过以众数为中心的高斯分布来近似最大后验估计附近的后验密度，其方差等于对数后验在众数处的负二阶导数（对于标量即负海森矩阵）的逆。\n\n你的任务：\n- 推导后验密度（不含归一化常数），并将其表示为一种公认的参数形式。\n- 通过对对数后验求导，推导后验均值和后验众数。\n- 使用以验后众数为中心的拉普拉斯近似，从对数后验在众数处的二阶导数推导出标量高斯方差。\n- 对于由平方损失 $L(\\lambda; t) = (\\lambda - t)^2$ 给出的凸风险，计算在精确后验和拉普拉斯近似下的期望损失。仅使用这些分布的期望定义和你推导出的量。\n- 实现一个程序，对于下面测试套件中的每个测试用例，计算精确期望损失与拉普拉斯近似期望损失之间的绝对差。\n\n测试套件：\n- 用例 $1$：先验 $(a,b) = (2.5, 1.0)$，数据 $y = (0,1,2)$，损失目标 $t$ 等于此用例的后验众数。\n- 用例 $2$：先验 $(a,b) = (0.3, 1.0)$，数据 $y = (1)$，损失目标 $t$ 等于此用例数据的样本均值。\n- 用例 $3$：先验 $(a,b) = (2.0, 1.0)$，数据 $y = (10,12,9,11,8)$，损失目标 $t = 10.0$。\n- 用例 $4$：先验 $(a,b) = (3.0, 0.5)$，数据 $y = (0,0,0,1)$，损失目标 $t = 0.8$。\n\n程序要求：\n- 对每个用例，计算后验形状参数 $\\alpha$ 和率参数 $\\beta$、后验均值和众数、在众数处的拉普拉斯方差，以及在精确后验和拉普拉斯近似下的期望平方损失。\n- 对每个用例，以浮点数形式输出精确期望损失与拉普拉斯近似期望损失之间的绝对差。\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个数字四舍五入到六位小数（例如，$[0.123456,0.000001,2.718282,1.000000]$）。\n\n本问题陈述中的所有数学符号、变量、函数、运算符和数字均使用LaTeX编写。本问题不涉及物理单位、角度或百分比；所有数值输出必须是无单位的实数。", "solution": "该问题要求对一个涉及泊松似然和伽马先验的贝叶斯单参数模型进行深入分析。此框架是贝叶斯统计中共轭族的一个经典例子。我们将首先验证问题陈述的合理性（已确认其合理），然后系统地推导所需的量。\n\n模型规定如下：\n- 数据 $\\{y_i\\}_{i=1}^n$ 是来自参数为 $\\lambda$ 的泊松分布的独立同分布抽样：$y_i \\mid \\lambda \\sim \\text{Poisson}(\\lambda)$。\n- 未知参数 $\\lambda$ 的先验分布是形状参数为 $a$、率参数为 $b$ 的伽马分布：$\\lambda \\sim \\text{Gamma}(a, b)$。\n\n泊松分布的概率质量函数（PMF）为 $P(y \\mid \\lambda) = \\frac{e^{-\\lambda}\\lambda^y}{y!}$，其中 $y \\in \\{0, 1, 2, \\dots\\}$。伽马分布的概率密度函数（PDF）为 $p(\\lambda \\mid a, b) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}$，其中 $\\lambda > 0$。\n\n首先，我们推导 $\\lambda$ 的后验密度。根据贝叶斯定理，后验密度与似然和先验密度的乘积成正比：\n$$ p(\\lambda \\mid y_1, \\dots, y_n) \\propto P(y_1, \\dots, y_n \\mid \\lambda) \\, p(\\lambda) $$\n鉴于观测值是独立的，似然是单个概率质量函数的乘积：\n$$ P(y_1, \\dots, y_n \\mid \\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} = \\frac{e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} $$\n作为 $\\lambda$ 的函数，似然与 $e^{-n\\lambda} \\lambda^{\\sum y_i}$ 成正比。先验密度与 $\\lambda^{a-1}e^{-b\\lambda}$ 成正比。\n结合这些，后验密度为：\n$$ p(\\lambda \\mid \\mathbf{y}) \\propto \\left(e^{-n\\lambda} \\lambda^{\\sum_{i=1}^n y_i}\\right) \\left(\\lambda^{a-1}e^{-b\\lambda}\\right) $$\n$$ p(\\lambda \\mid \\mathbf{y}) \\propto \\lambda^{(\\sum y_i + a) - 1} e^{-(n+b)\\lambda} $$\n该表达式是伽马分布的核。因此，后验分布也是一个伽马分布，这证明了伽马先验对于泊松似然的共轭性。后验分布为 $\\lambda \\mid \\mathbf{y} \\sim \\text{Gamma}(\\alpha, \\beta)$，更新后的参数为：\n- 后验形状参数：$\\alpha = \\sum_{i=1}^n y_i + a$\n- 后验率参数：$\\beta = n + b$\n\n其次，我们推导后验均值和后验众数。对于伽马分布 $\\text{Gamma}(\\alpha, \\beta)$，其均值和众数是众所周知的量。\n- 后验均值为 $E[\\lambda \\mid \\mathbf{y}] = \\frac{\\alpha}{\\beta} = \\frac{\\sum y_i + a}{n + b}$。\n- 后验众数（最大后验估计，$\\lambda_{\\text{MAP}}$）通过最大化后验密度得到。对于形状参数 $\\alpha > 1$ 的伽马分布，众数为 $\\lambda_{\\text{MAP}} = \\frac{\\alpha - 1}{\\beta} = \\frac{\\sum y_i + a - 1}{n + b}$。问题中提供的所有测试用例都满足条件 $\\alpha > 1$。\n\n第三，我们推导拉普拉斯近似的方差。拉普拉斯近似使用以验后众数 $\\lambda_{\\text{MAP}}$ 为中心的高斯（正态）分布来近似后验密度。我们记方差为 $\\sigma_L^2$，其值是对数后验密度在众数处求值的负二阶导数的逆。\n对数后验（不含加法常数）为：\n$$ \\log p(\\lambda \\mid \\mathbf{y}) = (\\alpha-1)\\log\\lambda - \\beta\\lambda + C $$\n关于 $\\lambda$ 的一阶导数为：\n$$ \\frac{d}{d\\lambda} \\log p(\\lambda \\mid \\mathbf{y}) = \\frac{\\alpha-1}{\\lambda} - \\beta $$\n二阶导数为：\n$$ \\frac{d^2}{d\\lambda^2} \\log p(\\lambda \\mid \\mathbf{y}) = -\\frac{\\alpha-1}{\\lambda^2} $$\n在众数 $\\lambda_{\\text{MAP}} = \\frac{\\alpha - 1}{\\beta}$ 处计算负二阶导数（观测到的费雪信息）：\n$$ J(\\lambda_{\\text{MAP}}) = -\\left(-\\frac{\\alpha-1}{(\\frac{\\alpha-1}{\\beta})^2}\\right) = \\frac{\\alpha-1}{(\\alpha-1)^2 / \\beta^2} = \\frac{\\beta^2}{\\alpha-1} $$\n拉普拉斯近似的方差是这个量的逆：\n$$ \\sigma_L^2 = [J(\\lambda_{\\text{MAP}})]^{-1} = \\frac{\\alpha-1}{\\beta^2} $$\n因此，后验的拉普拉斯近似为 $\\lambda_{\\text{approx}} \\sim N(\\mu_L, \\sigma_L^2)$，其中均值为 $\\mu_L = \\lambda_{\\text{MAP}} = \\frac{\\alpha-1}{\\beta}$，方差为 $\\sigma_L^2 = \\frac{\\alpha-1}{\\beta^2}$。\n\n第四，我们计算期望平方损失 $L(\\lambda; t) = (\\lambda - t)^2$。在 $\\lambda$ 的某个概率分布下，期望损失由 $E[(\\lambda-t)^2]$ 给出。这可以使用方差的定义 $\\text{Var}(\\lambda) = E[\\lambda^2] - (E[\\lambda])^2$ 来展开：\n$$ E[(\\lambda-t)^2] = E[\\lambda^2 - 2t\\lambda + t^2] = E[\\lambda^2] - 2tE[\\lambda] + t^2 $$\n$$ E[(\\lambda-t)^2] = (\\text{Var}(\\lambda) + (E[\\lambda])^2) - 2tE[\\lambda] + t^2 = \\text{Var}(\\lambda) + (E[\\lambda] - t)^2 $$\n这个公式将期望损失与方差以及分布均值相对于目标 $t$ 的偏差平方联系起来。\n\n我们将此公式应用于精确后验和拉普拉斯近似。\n- 对于精确后验，$\\lambda \\mid \\mathbf{y} \\sim \\text{Gamma}(\\alpha, \\beta)$：\n  - 均值：$E_{\\text{post}}[\\lambda] = \\frac{\\alpha}{\\beta}$\n  - 方差：$\\text{Var}_{\\text{post}}(\\lambda) = \\frac{\\alpha}{\\beta^2}$\n  - 期望损失：$E_{\\text{exact}} = \\text{Var}_{\\text{post}}(\\lambda) + (E_{\\text{post}}[\\lambda] - t)^2 = \\frac{\\alpha}{\\beta^2} + \\left(\\frac{\\alpha}{\\beta} - t\\right)^2$。\n- 对于拉普拉斯近似，$\\lambda_{\\text{approx}} \\sim N(\\mu_L, \\sigma_L^2)$：\n  - 均值：$E_{\\text{Laplace}}[\\lambda] = \\mu_L = \\frac{\\alpha-1}{\\beta}$\n  - 方差：$\\text{Var}_{\\text{Laplace}}(\\lambda) = \\sigma_L^2 = \\frac{\\alpha-1}{\\beta^2}$\n  - 期望损失：$E_{\\text{Laplace}} = \\text{Var}_{\\text{Laplace}}(\\lambda) + (E_{\\text{Laplace}}[\\lambda] - t)^2 = \\frac{\\alpha-1}{\\beta^2} + \\left(\\frac{\\alpha-1}{\\beta} - t\\right)^2$。\n\n程序将实现这些最终公式，以计算每个测试用例的绝对差 $|E_{\\text{exact}} - E_{\\text{Laplace}}|$。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite by calculating the absolute difference\n    between the expected squared loss under the exact posterior and under the Laplace approximation.\n    \"\"\"\n    \n    # Test suite definition: (prior_a, prior_b, data_y, t_config)\n    # t_config is a tuple (type, value) where type is 'mode', 'mean', or 'value'.\n    test_cases = [\n        (2.5, 1.0, [0, 1, 2], ('mode', None)),\n        (0.3, 1.0, [1], ('mean', None)),\n        (2.0, 1.0, [10, 12, 9, 11, 8], ('value', 10.0)),\n        (3.0, 0.5, [0, 0, 0, 1], ('value', 0.8)),\n    ]\n\n    results = []\n\n    for case in test_cases:\n        a_prior, b_prior, y, t_config = case\n        \n        # Convert y to a numpy array for easier calculations\n        y = np.array(y)\n        \n        # Calculate sufficient statistics from data\n        n = len(y)\n        sum_y = np.sum(y)\n        \n        # Calculate posterior parameters\n        # Posterior is Gamma(alpha, beta)\n        alpha_post = sum_y + a_prior\n        beta_post = float(n + b_prior)\n\n        # Ensure posterior mode is well-defined (alpha > 1)\n        if alpha_post <= 1:\n            # This case is not expected based on problem validation\n            # but good practice to handle.\n            results.append(np.nan)\n            continue\n\n        # Determine the loss target t based on the configuration\n        t_type, t_val = t_config\n        t = 0.0\n        if t_type == 'value':\n            t = t_val\n        elif t_type == 'mode':\n            # Posterior mode (MAP)\n            t = (alpha_post - 1) / beta_post\n        elif t_type == 'mean':\n            # Sample mean of the data\n            t = np.mean(y)\n\n        # === Calculations for the exact posterior: Gamma(alpha_post, beta_post) ===\n        \n        # Mean of the exact posterior\n        mean_exact = alpha_post / beta_post\n        # Variance of the exact posterior\n        var_exact = alpha_post / (beta_post**2)\n        # Expected squared loss for the exact posterior\n        expected_loss_exact = var_exact + (mean_exact - t)**2\n\n        # === Calculations for the Laplace approximation: Normal(mu_L, sigma_L^2) ===\n        \n        # Mean of the Laplace approximation is the posterior mode\n        mean_laplace = (alpha_post - 1) / beta_post\n        # Variance of the Laplace approximation\n        var_laplace = (alpha_post - 1) / (beta_post**2)\n        # Expected squared loss for the Laplace approximation\n        expected_loss_laplace = var_laplace + (mean_laplace - t)**2\n\n        # Calculate the absolute difference between the two expected losses\n        abs_diff = abs(expected_loss_exact - expected_loss_laplace)\n        results.append(abs_diff)\n    \n    # Format the output as a comma-separated list of strings with 6 decimal places\n    output_str = \",\".join([f\"{res:.6f}\" for res in results])\n    print(f\"[{output_str}]\")\n\nsolve()\n```", "id": "3137250"}, {"introduction": "最后的练习将理论与实际应用联系起来，解决一个多维线性反问题。这个练习侧重于基本的计算线性代数任务——Hessian矩阵的构建、矩阵向量乘积、求解线性系统和计算对数行列式。这些都是在更复杂、高维的环境中使用拉普拉斯近似的基础。[@problem_id:3395961]", "problem": "考虑一个贝叶斯线性逆问题，其中未知参数向量 $u \\in \\mathbb{R}^n$ 是在有高斯先验和高斯观测噪声的条件下，从带噪观测 $y \\in \\mathbb{R}^m$ 中推断出来的。正向映射是线性的，因此数据模型为 $y = A u + \\eta$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个已知矩阵，$\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\text{noise}})$ 是协方差矩阵已知的 $\\Gamma_{\\text{noise}}$ 的高斯噪声。先验分布为 $u \\sim \\mathcal{N}(m_0, \\Gamma_{\\text{prior}})$，其中先验均值为 $m_0 \\in \\mathbb{R}^n$，先验协方差矩阵为 $\\Gamma_{\\text{prior}}$。在对后验进行 Laplace 近似时，计算实现需要高效地评估 Hessian 作用、Hessian 线性求解以及 Hessian 的对数行列式。\n\n从高斯数据似然和高斯先验的基本定义以及由此产生的负对数后验目标函数出发，推导线性正向模型中关于 $u$ 的负对数后验的 Hessian 矩阵，并用它来：\n- 计算 Hessian 矩阵对给定向量 $v$ 的作用（即计算 $H v$），\n- 对给定的右端向量 $b$ 求解线性系统 $H z = b$，\n- 计算 $H$ 行列式的自然对数 $\\log \\det(H)$。\n\n所有推导必须从最基本的内容开始：给定 $u$ 时 $y$ 的数据似然定义、$u$ 的先验定义，以及作为负对数似然和负对数先验之和（相差一个无关的加性常数）的后验密度负对数。不要使用任何简便结论；从这些定义出发推导 Hessian 所需的表达式。\n\n假设 $\\Gamma_{\\text{noise}}$ 和 $\\Gamma_{\\text{prior}}$ 是对角且正定的。你可以在计算实现中利用由这些假设产生的任何结构特性。本问题不涉及物理单位。\n\n对于下面的每个测试用例，程序必须：\n- 构建由模型和协方差所蕴含的 Hessian 矩阵 $H$，\n- 计算指定 $v$ 的 Hessian 作用 $H v$，\n- 求解指定 $b$ 的 $H z = b$，\n- 计算 $\\log \\det(H)$。\n\n使用以下测试套件。每个测试用例都指定了 $(m, n)$、矩阵 $A$、$\\Gamma_{\\text{noise}}$ 的对角线元素、$\\Gamma_{\\text{prior}}$ 的对角线元素以及向量 $v$ 和 $b$。\n\n测试用例 1（正常路径，中等条件数）：\n- $m = 4$, $n = 3$,\n- $$A = \\begin{bmatrix}\n1.0  & 0.5  & 0.0 \\\\\n0.0  & 1.0  & 0.5 \\\\\n0.5  & 0.0  & 1.0 \\\\\n1.0  & -0.5  & 0.5\n\\end{bmatrix},$$\n- $$\\operatorname{diag}(\\Gamma_{\\text{noise}}) = \\begin{bmatrix} 0.1 \\\\ 0.2 \\\\ 0.15 \\\\ 0.3 \\end{bmatrix}, \\quad \\operatorname{diag}(\\Gamma_{\\text{prior}}) = \\begin{bmatrix} 1.0 \\\\ 0.5 \\\\ 2.0 \\end{bmatrix},$$\n- $$v = \\begin{bmatrix} 1.0 \\\\ -1.0 \\\\ 0.5 \\end{bmatrix}, \\quad b = \\begin{bmatrix} 0.2 \\\\ -0.1 \\\\ 0.3 \\end{bmatrix}.$$\n\n测试用例 2（弱先验，A 的列向量近似共线）：\n- $m = 6$, $n = 5$,\n- $$A = \\begin{bmatrix}\n1.0  & 0.9  & 0.0  & 0.1  & -0.2 \\\\\n0.8  & 0.7  & 0.1  & 0.0  & 0.2 \\\\\n0.6  & 0.59  & -0.1  & 0.1  & 0.0 \\\\\n0.4  & 0.41  & 0.2  & -0.2  & 0.1 \\\\\n0.2  & 0.21  & -0.2  & 0.2  & -0.1 \\\\\n0.1  & 0.09  & 0.0  & -0.1  & 0.0\n\\end{bmatrix},$$\n- $$\\operatorname{diag}(\\Gamma_{\\text{noise}}) = \\begin{bmatrix} 0.05 \\\\ 0.05 \\\\ 0.1 \\\\ 0.2 \\\\ 0.3 \\\\ 0.4 \\end{bmatrix}, \\quad \\operatorname{diag}(\\Gamma_{\\text{prior}}) = \\begin{bmatrix} 10.0 \\\\ 10.0 \\\\ 10.0 \\\\ 10.0 \\\\ 10.0 \\end{bmatrix},$$\n- $$v = \\begin{bmatrix} 0.5 \\\\ 0.0 \\\\ -0.5 \\\\ 1.0 \\\\ -1.0 \\end{bmatrix}, \\quad b = \\begin{bmatrix} -0.1 \\\\ 0.2 \\\\ 0.0 \\\\ 0.3 \\\\ -0.2 \\end{bmatrix}.$$\n\n测试用例 3（强先验，A 是病态的但被先验稳定）：\n- $m = 4$, $n = 4$,\n- $$A = \\begin{bmatrix}\n1.0  & 0.99  & 0.98  & 0.97 \\\\\n0.5  & 0.495  & 0.49  & 0.485 \\\\\n0.2  & 0.198  & 0.196  & 0.194 \\\\\n-0.1  & -0.099  & -0.098  & -0.097\n\\end{bmatrix},$$\n- $$\\operatorname{diag}(\\Gamma_{\\text{noise}}) = \\begin{bmatrix} 0.2 \\\\ 0.25 \\\\ 0.3 \\\\ 0.35 \\end{bmatrix}, \\quad \\operatorname{diag}(\\Gamma_{\\text{prior}}) = \\begin{bmatrix} 0.01 \\\\ 0.02 \\\\ 0.015 \\\\ 0.03 \\end{bmatrix},$$\n- $$v = \\begin{bmatrix} 1.0 \\\\ 1.0 \\\\ 1.0 \\\\ 1.0 \\end{bmatrix}, \\quad b = \\begin{bmatrix} 0.5 \\\\ -0.5 \\\\ 0.5 \\\\ -0.5 \\end{bmatrix}.$$\n\n测试用例 4（边界情况，标量参数）：\n- $m = 2$, $n = 1$,\n- $$A = \\begin{bmatrix}\n2.0 \\\\\n-1.0\n\\end{bmatrix},$$\n- $$\\operatorname{diag}(\\Gamma_{\\text{noise}}) = \\begin{bmatrix} 0.5 \\\\ 0.25 \\end{bmatrix}, \\quad \\operatorname{diag}(\\Gamma_{\\text{prior}}) = \\begin{bmatrix} 0.1 \\end{bmatrix},$$\n- $$v = \\begin{bmatrix} 1.0 \\end{bmatrix}, \\quad b = \\begin{bmatrix} 0.3 \\end{bmatrix}.$$\n\n你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，输出三元组 $[H v, z, \\log \\det(H)]$，其中 $H v$ 和 $z$ 是浮点数列表（向量的条目），而 $\\log \\det(H)$ 是一个浮点数。最终输出必须是按顺序聚合四个测试用例三元组的单个列表，例如：\n$$[ [Hv_1, z_1, \\log\\det(H_1)], [Hv_2, z_2, \\log\\det(H_2)], [Hv_3, z_3, \\log\\det(H_3)], [Hv_4, z_4, \\log\\det(H_4)] ].$$", "solution": "该问题要求针对具有高斯先验和噪声的贝叶斯线性逆问题，推导负对数后验的 Hessian 矩阵，并将其应用于特定的计算任务。推导过程必须从基本原理出发。\n\n令未知参数向量为 $u \\in \\mathbb{R}^n$，观测向量为 $y \\in \\mathbb{R}^m$。它们之间的关系由以下线性正向模型给出：\n$$\ny = A u + \\eta\n$$\n其中 $A \\in \\mathbb{R}^{m \\times n}$ 是正向算子，$\\eta \\in \\mathbb{R}^m$ 是观测噪声。\n\n该问题为 $u$ 的先验和噪声 $\\eta$ 都指定了高斯模型。\n$u$ 的先验分布为 $u \\sim \\mathcal{N}(m_0, \\Gamma_{\\text{prior}})$，其中 $m_0 \\in \\mathbb{R}^n$ 是先验均值，$\\Gamma_{\\text{prior}} \\in \\mathbb{R}^{n \\times n}$ 是先验协方差矩阵。先验的概率密度函数 (PDF) 为：\n$$\np(u) \\propto \\exp\\left(-\\frac{1}{2} (u - m_0)^T \\Gamma_{\\text{prior}}^{-1} (u - m_0)\\right)\n$$\n观测噪声为 $\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\text{noise}})$，其中 $\\Gamma_{\\text{noise}} \\in \\mathbb{R}^{m \\times m}$ 是噪声协方差矩阵。这意味着对于给定的 $u$，观测 $y$ 的分布为 $y|u \\sim \\mathcal{N}(Au, \\Gamma_{\\text{noise}})$。相应的数据似然函数为：\n$$\np(y|u) \\propto \\exp\\left(-\\frac{1}{2} (y - Au)^T \\Gamma_{\\text{noise}}^{-1} (y - Au)\\right)\n$$\n根据贝叶斯定理，给定数据 $y$ 时 $u$ 的后验分布与似然和先验的乘积成正比：\n$$\np(u|y) \\propto p(y|u) p(u)\n$$\n代入高斯似然和先验的表达式，我们得到：\n$$\np(u|y) \\propto \\exp\\left(-\\frac{1}{2} (y - Au)^T \\Gamma_{\\text{noise}}^{-1} (y - Au)\\right) \\exp\\left(-\\frac{1}{2} (u - m_0)^T \\Gamma_{\\text{prior}}^{-1} (u - m_0)\\right)\n$$\n$$\np(u|y) \\propto \\exp\\left(-\\frac{1}{2} \\left[ (y - Au)^T \\Gamma_{\\text{noise}}^{-1} (y - Au) + (u - m_0)^T \\Gamma_{\\text{prior}}^{-1} (u - m_0) \\right]\\right)\n$$\nLaplace 近似涉及用一个以以后验众数为中心的高斯分布来近似后验分布。众数通过最大化 $p(u|y)$ 来找到，这等价于最小化后验密度的负对数。令 $\\Phi(u)$ 表示负对数后验（相差一个加性常数）：\n$$\n\\Phi(u) = -\\log p(u|y) = \\frac{1}{2} (y - Au)^T \\Gamma_{\\text{noise}}^{-1} (y - Au) + \\frac{1}{2} (u - m_0)^T \\Gamma_{\\text{prior}}^{-1} (u - m_0) + C\n$$\n其中 $C$ 是一个不依赖于 $u$ 的常数。\n\n负对数后验的 Hessian 矩阵 $H$ 是 $\\Phi(u)$ 关于 $u$ 各分量的二阶偏导数矩阵，即 $H = \\nabla_u^2 \\Phi(u)$。为求 $H$，我们首先计算梯度 $\\nabla_u \\Phi(u)$。让我们展开 $\\Phi(u)$ 中的各项：\n$$\n\\Phi(u) = \\frac{1}{2} (y^T - u^T A^T) \\Gamma_{\\text{noise}}^{-1} (y - Au) + \\frac{1}{2} (u^T - m_0^T) \\Gamma_{\\text{prior}}^{-1} (u - m_0) + C\n$$\n第一项展开为：\n$$\n\\frac{1}{2} (y^T \\Gamma_{\\text{noise}}^{-1} y - y^T \\Gamma_{\\text{noise}}^{-1} Au - u^T A^T \\Gamma_{\\text{noise}}^{-1} y + u^T A^T \\Gamma_{\\text{noise}}^{-1} Au)\n$$\n由于 $\\Gamma_{\\text{noise}}^{-1}$ 是对称的，两个交叉项是相等的标量：$u^T A^T \\Gamma_{\\text{noise}}^{-1} y = (y^T \\Gamma_{\\text{noise}}^{-1} Au)^T = y^T \\Gamma_{\\text{noise}}^{-1} Au$。所以，上式变为：\n$$\n\\frac{1}{2} (y^T \\Gamma_{\\text{noise}}^{-1} y - 2 u^T A^T \\Gamma_{\\text{noise}}^{-1} y + u^T A^T \\Gamma_{\\text{noise}}^{-1} Au)\n$$\n类似地，$\\Phi(u)$ 中的第二项展开为：\n$$\n\\frac{1}{2} (u^T \\Gamma_{\\text{prior}}^{-1} u - 2 u^T \\Gamma_{\\text{prior}}^{-1} m_0 + m_0^T \\Gamma_{\\text{prior}}^{-1} m_0)\n$$\n现在我们对 $\\Phi(u)$ 关于 $u$ 求导。使用矩阵微积分恒等式 $\\nabla_x (c^T x) = c$ 和 $\\nabla_x (x^T B x) = 2Bx$（其中 $B$ 为对称矩阵）：\n$$\n\\nabla_u \\Phi(u) = \\frac{1}{2} (-2 A^T \\Gamma_{\\text{noise}}^{-1} y + 2 A^T \\Gamma_{\\text{noise}}^{-1} A u) + \\frac{1}{2} (2 \\Gamma_{\\text{prior}}^{-1} u - 2 \\Gamma_{\\text{prior}}^{-1} m_0)\n$$\n$$\n\\nabla_u \\Phi(u) = A^T \\Gamma_{\\text{noise}}^{-1} (Au - y) + \\Gamma_{\\text{prior}}^{-1} (u - m_0)\n$$\nHessian 矩阵 $H$ 是梯度关于 $u^T$ 的导数。对 $\\nabla_u \\Phi(u)$ 关于 $u$ 求导：\n$$\nH = \\nabla_u (\\nabla_u \\Phi(u)) = \\nabla_u (A^T \\Gamma_{\\text{noise}}^{-1} A u - A^T \\Gamma_{\\text{noise}}^{-1} y + \\Gamma_{\\text{prior}}^{-1} u - \\Gamma_{\\text{prior}}^{-1} m_0)\n$$\n不含 $u$ 的项的导数为零。我们得到：\n$$\nH = A^T \\Gamma_{\\text{noise}}^{-1} A + \\Gamma_{\\text{prior}}^{-1}\n$$\n这就是负对数后验的 Hessian 矩阵。值得注意的是，对于这个线性高斯模型，Hessian 矩阵是一个常数矩阵，它不依赖于参数 $u$、数据 $y$ 和先验均值 $m_0$。\n\n问题陈述了 $\\Gamma_{\\text{noise}}$ 和 $\\Gamma_{\\text{prior}}$ 是正定的。它们的逆矩阵 $\\Gamma_{\\text{noise}}^{-1}$ 和 $\\Gamma_{\\text{prior}}^{-1}$ 也是正定的。矩阵 $A^T \\Gamma_{\\text{noise}}^{-1} A$ 是半正定的。一个正定矩阵 ($\\Gamma_{\\text{prior}}^{-1}$) 和一个半正定矩阵 ($A^T \\Gamma_{\\text{noise}}^{-1} A$) 的和是一个正定矩阵。因此，Hessian 矩阵 $H$ 是对称正定的 (SPD)。此性质保证了线性系统 $Hz=b$ 有唯一解，且 $\\det(H) > 0$。\n\n协方差矩阵 $\\Gamma_{\\text{noise}}$ 和 $\\Gamma_{\\text{prior}}$ 也被指定为对角矩阵。这简化了计算，因为它们的逆矩阵也是对角矩阵，其对角线元素是原始对角线元素的倒数。令 $d_{\\text{noise}}$ 和 $d_{\\text{prior}}$ 分别为 $\\Gamma_{\\text{noise}}$ 和 $\\Gamma_{\\text{prior}}$ 的对角线元素组成的向量。那么 $\\Gamma_{\\text{noise}}^{-1} = \\operatorname{diag}(1/d_{\\text{noise}})$ 且 $\\Gamma_{\\text{prior}}^{-1} = \\operatorname{diag}(1/d_{\\text{prior}})$。\n\n三个所需的计算任务可以按如下方式执行：\n1.  **计算 Hessian 作用 $H v$**：使用推导出的 $H$ 表达式，其对向量 $v \\in \\mathbb{R}^n$ 的作用为：\n    $$\n    H v = (A^T \\Gamma_{\\text{noise}}^{-1} A + \\Gamma_{\\text{prior}}^{-1}) v = A^T \\Gamma_{\\text{noise}}^{-1} (A v) + \\Gamma_{\\text{prior}}^{-1} v\n    $$\n    在计算上，这通过首先构造矩阵 $H = A^T \\operatorname{diag}(1/d_{\\text{noise}}) A + \\operatorname{diag}(1/d_{\\text{prior}})$，然后计算矩阵向量乘积 $H v$ 来执行。\n\n2.  **求解线性系统 $H z = b$**：由于 $H$ 是一个 SPD 矩阵，该系统可以被高效且稳定地求解。像 Cholesky 分解或 LU 分解（对于 SPD 矩阵可简化为 Cholesky 分解）这样的标准方法都是适用的。我们将构造矩阵 $H$，然后使用数值线性代数求解器来找到 $z$。\n\n3.  **计算 $H$ 行列式的自然对数 $\\log \\det(H)$**：一种数值稳定的计算方法是通过 $H$ 的 Cholesky 分解。如果 $H = LL^T$，其中 $L$ 是一个下三角矩阵（Cholesky 因子），那么 $\\det(H) = \\det(L L^T) = \\det(L) \\det(L^T) = (\\det(L))^2$。三角矩阵的行列式是其对角线元素的乘积，因此 $\\det(L) = \\prod_{i=1}^n L_{ii}$。所以，\n    $$\n    \\log \\det(H) = \\log\\left(\\left(\\prod_{i=1}^n L_{ii}\\right)^2\\right) = 2 \\sum_{i=1}^n \\log(L_{ii})\n    $$\n    这种方法避免了直接计算行列式，因为对于大矩阵，直接计算可能导致上溢或下溢。也可以使用像 `numpy.linalg.slogdet` 这样的专用函数，它能直接且稳健地计算行列式的符号和对数。由于 $H$ 是正定的，符号将为 $+1$。\n\n实现将针对每个提供的测试用例遵循这些步骤。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases as specified.\n    - Constructs the Hessian of the negative log-posterior.\n    - Computes Hessian action, solves a linear system, and finds the log-determinant.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"m\": 4, \"n\": 3,\n            \"A\": np.array([\n                [1.0, 0.5, 0.0],\n                [0.0, 1.0, 0.5],\n                [0.5, 0.0, 1.0],\n                [1.0, -0.5, 0.5]\n            ]),\n            \"diag_gamma_noise\": np.array([0.1, 0.2, 0.15, 0.3]),\n            \"diag_gamma_prior\": np.array([1.0, 0.5, 2.0]),\n            \"v\": np.array([1.0, -1.0, 0.5]),\n            \"b\": np.array([0.2, -0.1, 0.3])\n        },\n        {\n            \"m\": 6, \"n\": 5,\n            \"A\": np.array([\n                [1.0, 0.9, 0.0, 0.1, -0.2],\n                [0.8, 0.7, 0.1, 0.0, 0.2],\n                [0.6, 0.59, -0.1, 0.1, 0.0],\n                [0.4, 0.41, 0.2, -0.2, 0.1],\n                [0.2, 0.21, -0.2, 0.2, -0.1],\n                [0.1, 0.09, 0.0, -0.1, 0.0]\n            ]),\n            \"diag_gamma_noise\": np.array([0.05, 0.05, 0.1, 0.2, 0.3, 0.4]),\n            \"diag_gamma_prior\": np.array([10.0, 10.0, 10.0, 10.0, 10.0]),\n            \"v\": np.array([0.5, 0.0, -0.5, 1.0, -1.0]),\n            \"b\": np.array([-0.1, 0.2, 0.0, 0.3, -0.2])\n        },\n        {\n            \"m\": 4, \"n\": 4,\n            \"A\": np.array([\n                [1.0, 0.99, 0.98, 0.97],\n                [0.5, 0.495, 0.49, 0.485],\n                [0.2, 0.198, 0.196, 0.194],\n                [-0.1, -0.099, -0.098, -0.097]\n            ]),\n            \"diag_gamma_noise\": np.array([0.2, 0.25, 0.3, 0.35]),\n            \"diag_gamma_prior\": np.array([0.01, 0.02, 0.015, 0.03]),\n            \"v\": np.array([1.0, 1.0, 1.0, 1.0]),\n            \"b\": np.array([0.5, -0.5, 0.5, -0.5])\n        },\n        {\n            \"m\": 2, \"n\": 1,\n            \"A\": np.array([\n                [2.0],\n                [-1.0]\n            ]),\n            \"diag_gamma_noise\": np.array([0.5, 0.25]),\n            \"diag_gamma_prior\": np.array([0.1]),\n            \"v\": np.array([1.0]),\n            \"b\": np.array([0.3])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        A = case[\"A\"]\n        diag_gamma_noise = case[\"diag_gamma_noise\"]\n        diag_gamma_prior = case[\"diag_gamma_prior\"]\n        v = case[\"v\"]\n        b = case[\"b\"]\n        \n        # Invert diagonal covariance matrices\n        # Gamma_noise_inv is m x m, Gamma_prior_inv is n x n\n        gamma_noise_inv_diag = 1.0 / diag_gamma_noise\n        gamma_prior_inv_diag = 1.0 / diag_gamma_prior\n        \n        # Construct the Hessian H = A^T * Gamma_noise_inv * A + Gamma_prior_inv\n        # Using numpy's broadcasting for efficiency with diagonal Gamma_noise_inv\n        # (A.T * diag_vec) is equivalent to A.T @ diag(diag_vec)\n        term1 = (A.T * gamma_noise_inv_diag) @ A\n        term2 = np.diag(gamma_prior_inv_diag)\n        H = term1 + term2\n        \n        # 1. Compute Hessian action Hv\n        Hv = H @ v\n        \n        # 2. Solve Hz = b for z\n        # H is symmetric positive definite, so np.linalg.solve is stable.\n        z = np.linalg.solve(H, b)\n        \n        # 3. Compute log(det(H))\n        # np.linalg.slogdet returns (sign, logdet).\n        # Since H is positive definite, sign is 1.\n        sign, log_det_H = np.linalg.slogdet(H)\n        \n        # Format results for output: vectors as lists of floats, logdet as float\n        results.append([Hv.tolist(), z.tolist(), log_det_H])\n\n    # Final print statement must match the required format exactly.\n    # The default str() representation of lists is used.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3395961"}]}