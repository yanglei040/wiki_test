{"hands_on_practices": [{"introduction": "引力坍缩中的临界现象以其普适的标度律而著称，其中最著名的是黑洞质量标度律 $M_{\\mathrm{BH}} \\propto |p-p_{*}|^{\\gamma}$。这个练习将引导你通过量纲分析和临界解线性稳定性的基本假设，从第一性原理出发推导出标度指数 $\\gamma$ 与临界解唯一不稳定模式增长指数 $\\kappa$ 之间的关系。通过这个经典的纸笔练习，你将能深刻理解临界标度律的理论基础，而不是仅仅将其作为一个给定的事实。[@problem_id:3471159]", "problem": "考虑在 $3+1$ 维时空中，广义相对论（GR）中一个最小耦合的无质量标量场的球对称引力坍缩，边界条件为渐近平坦。在几何单位制 $G=c=1$ 下进行计算。爱因斯坦方程为 $G_{ab}=8\\pi T_{ab}$，其中标量场的能量-动量张量为 $T_{ab}=\\nabla_{a}\\phi\\,\\nabla_{b}\\phi-\\frac{1}{2}g_{ab}\\,\\nabla_{c}\\phi\\,\\nabla^{c}\\phi$。假设在物质部分和场方程中不存在任何内禀质量标度。\n\n考虑一个由实数参数 $p$ 标记的光滑、紧支集初值族，使得存在一个阈值 $p_{*}$，它将弥散（$p  p_{*}$）与形成黑洞（$p > p_{*}$）的初值分开，对于后者会形成一个最终质量为 $M_{\\mathrm{BH}}$ 的黑洞，且黑洞质量遵循标度律：$M_{\\mathrm{BH}} \\propto |p-p_{*}|^{\\gamma}$。\n\n在临界点 $p = p_{*}$ 处，演化由一个离散自相似（DSS）、不稳定的临界解（记为 $\\phi_{*}(x^a)$）所主导。该解具有一个单一的、增长的不稳定模式，其特征值为 $\\kappa > 0$。\n\n在这些假设下，推导出临界指数 $\\gamma$ 和特征值 $\\kappa$ 之间的关系。", "solution": "该问题要求在无质量标量场临界引力坍缩的背景下，黑洞质量关系式 $M_{\\mathrm{BH}} \\propto |p-p_{*}|^{\\gamma}$ 中的标度指数 $\\gamma$。推导将依赖于量纲分析以及问题陈述中描述的临界解及其微扰的性质。\n\n首先，我们对问题陈述进行验证。\n\n### 步骤1：提取已知条件\n- 该系统是3+1维广义相对论中的球对称、最小耦合、无质量标量场。\n- 使用几何单位制：$G=c=1$。\n- 场方程为 $G_{ab}=8\\pi T_{ab}$，其中 $T_{ab}=\\nabla_{a}\\phi\\,\\nabla_{b}\\phi-\\frac{1}{2}g_{ab}\\,\\nabla_{c}\\phi\\,\\nabla^{c}\\phi$。\n- 理论没有内禀质量标度。\n- 一个由 $p$ 标记的初值族有一个临界阈值 $p_{*}$。对于 $p > p_{*}$，形成黑洞；对于 $p  p_{*}$，能量弥散。\n- 黑洞质量遵循标度律 $M_{\\mathrm{BH}} \\propto |p-p_{*}|^{\\gamma}$。\n- 在 $p = p_{*}$ 处存在一个不稳定的自相似临界解。\n- 临界解只有一个增长的不稳定模式，其特征值为 $\\kappa > 0$。\n\n### 步骤2：量纲分析和尺度来源\n在无质量标量场理论中，没有固有的长度或质量尺度。这意味着由演化产生的任何尺度都必须源于初值数据。然而，临界解本身是自相似的，因此也没有尺度。对于近临界演化（$p \\approx p_{*}$），系统会迅速演化到临界解附近。因此，在演化的大部分时间里，系统处于一种无尺度状态。那么，最终黑洞的质量尺度 $M_{\\mathrm{BH}}$ 从何而来？它只能来源于系统对临界点的“偏离”程度，即 $|p-p_{*}|$。由于 $p$ 是一个无量纲参数，系统必须通过动力学演化将这个无量纲的偏差转化为一个有量纲的质量。\n\n### 步骤3：不稳定模式的动力学\n临界解是不稳定的，并且只有一个不稳定的增长模式。任何近临界的初值数据都可以看作是临界解加上一个微扰。这个微扰可以分解为临界解的模式。稳定的模式会衰减，而不稳定的模式会增长。在演化后期，不稳定的模式将主导动力学。\n\n设 $C(p)$ 是这个不稳定模式的初始振幅。对于近临界数据，我们可以假设 $C(p) \\propto (p - p_{*})$。随着自相似时间 $\\tau$（$\\tau = -\\ln(-t)$，其中 $t$ 是指向奇点的合宜时间）的演化，这个模式的振幅会指数增长：\n$$ C(\\tau) \\propto C(p) e^{\\kappa \\tau} \\propto (p-p_{*}) e^{\\kappa \\tau} $$\n这里的 $\\kappa$ 是不稳定模式的特征值。\n\n### 步骤4：确定演化尺度\n系统会一直保持在临界解附近，直到不稳定的模式增长到某个与背景相当的量级（比如，振幅达到 $\\mathcal{O}(1)$）。到那时，系统将脱离临界演化，并坍缩成一个黑洞（对于 $p > p_{*}$）。设这个脱离时间为 $\\tau_{\\text{dep}}$。我们可以通过设置 $C(\\tau_{\\text{dep}}) \\approx 1$ 来估计它：\n$$ (p-p_{*}) e^{\\kappa \\tau_{\\text{dep}}} \\approx 1 $$\n$$ \\kappa \\tau_{\\text{dep}} \\approx -\\ln|p-p_{*}| $$\n$$ \\tau_{\\text{dep}} \\approx -\\frac{1}{\\kappa} \\ln|p-p_{*}| $$\n这个时间 $\\tau_{\\text{dep}}$ 表示系统在“忘记”其初始条件并紧密跟随自相似临界解的情况下所花费的演化时间。\n\n### 步骤5：将演化尺度与黑洞质量联系起来\n临界解是自相似的，这意味着在自相似时间 $\\tau$ 的演化过程中，时空中的所有长度尺度 $L$ 都会指数级地缩小，$L \\propto e^{-\\tau}$。当系统在 $\\tau_{\\text{dep}}$ 时刻脱离临界演化时，系统当时的特征长度尺度 $L_{\\text{dep}}$ 为：\n$$ L_{\\text{dep}} \\propto e^{-\\tau_{\\text{dep}}} $$\n最终形成的黑洞质量 $M_{\\mathrm{BH}}$ 应该由这个脱离时刻的物理尺度决定。因此，我们可以假设 $M_{\\mathrm{BH}}$ 与 $L_{\\text{dep}}$ 成正比：\n$$ M_{\\mathrm{BH}} \\propto L_{\\text{dep}} \\propto e^{-\\tau_{\\text{dep}}} $$\n\n### 步骤6：推导标度指数 $\\gamma$\n现在我们将步骤4和步骤5的结果结合起来：\n$$ M_{\\mathrm{BH}} \\propto e^{-\\tau_{\\text{dep}}} \\approx \\exp\\left( - \\left( -\\frac{1}{\\kappa} \\ln|p-p_{*}| \\right) \\right) = \\exp\\left( \\frac{1}{\\kappa} \\ln|p-p_{*}| \\right) $$\n利用对数的性质 $\\exp(a \\ln x) = x^a$，我们得到：\n$$ M_{\\mathrm{BH}} \\propto |p-p_{*}|^{1/\\kappa} $$\n将此结果与问题中给出的标度律 $M_{\\mathrm{BH}} \\propto |p-p_{*}|^{\\gamma}$ 进行比较，我们立即可以得到 $\\gamma$ 和 $\\kappa$ 之间的关系：\n$$ \\gamma = \\frac{1}{\\kappa} $$\n这一推导揭示了黑洞质量标度律的深刻起源：它直接源于临界解的自相似性（它设定了尺度的指数演化）和其唯一的线性不稳定模式的增长率（它设定了系统停留在临界演化中的时间）。指数的普适性来自于临界解及其稳定性谱（即 $\\kappa$ 的值）是物质场的基本属性，而不依赖于初值数据的具体细节。", "answer": "$$\\boxed{\\frac{1}{\\kappa}}$$", "id": "3471159"}, {"introduction": "从理论转向实践，任何关于临界坍缩的数值研究都始于一个核心任务：精确定位临界参数 $p^{\\ast}$。这个练习模拟了这一过程，要求你设计一个二分法搜索方案来逼近 $p^{\\ast}$，同时还要考虑计算资源和数值误差带来的挑战。你将学习如何在有限的计算成本和由于有限分辨率导致的分类错误风险之间做出权衡，这正是数值相对论研究中的一个典型问题。[@problem_id:3471223]", "problem": "考虑一个用于广义相对论（GR）爱因斯坦场方程的单参数球对称初始数据族，该数据族由一个无量纲振幅 $p \\in \\mathbb{R}$ 参数化。存在一个临界参数 $p^\\ast$，使得当 $p  p^\\ast$ 时，演化会弥散而不会形成黑洞；而当 $p > p^\\ast$ 时，演化会经历引力坍缩并形成一个黑洞。在数值相对论中，可以使用视界（Apparent Horizon, AH）搜寻器来确定黑洞的形成，如果探测到视界，则返回布尔值 $1$，否则返回 $0$。由于有限的空间和时间分辨率，每次 AH 分类可能会以独立的概率 $q \\in [0,1)$ 被错误分类。\n\n您将实现一个基于对 $p$ 进行二分法的区间套方案，以将 $p^\\ast$ 定位到指定的相对精度。该方案假定一个初始的区间 $[p_{\\mathrm{lo}}, p_{\\mathrm{hi}}]$，满足 $p_{\\mathrm{lo}}  p^\\ast  p_{\\mathrm{hi}}$，并在每个二分步骤中采用以下决策机制：在选定的中点 $p_{\\mathrm{mid}}$，将演化和 AH 搜寻器在相同的 $p_{\\mathrm{mid}}$ 上重复运行 $m$ 次，并通过多数票决来对结果进行分类。设每次决策的容差为 $\\rho \\in (0,1)$，这意味着所选的 $m$ 必须是最小的奇数，以使得多数票决不正确的概率最多为 $\\rho$。在同一点 $p_{\\mathrm{mid}}$ 上的所有重复 AH 分类都是独立同分布的，其错误分类概率为 $q$。一次“演化”定义为对给定初始数据进行一次爱因斯坦场方程的前向时间积分，直到做出 AH 决策为止；因此，在一个 $p_{\\mathrm{mid}}$ 点运行 $m$ 次重复会消耗 $m$ 次演化。\n\n相对精度要求定义如下：经过 $K$ 次二分步骤后，区间 $[p_{\\mathrm{lo}}^{(K)}, p_{\\mathrm{hi}}^{(K)}]$ 必须满足 $p_{\\mathrm{hi}}^{(K)} - p_{\\mathrm{lo}}^{(K)} \\le 2 \\,\\epsilon \\, p^\\ast$，其中 $\\epsilon \\in (0,1)$ 是给定的目标精度，而 $p^\\ast$ 是真实的阈值。假设 $p^\\ast$ 是已知的，但这仅用于基准测试和测试场景构建。在这些假设下：\n\n- 从初始区间 $[p_{\\mathrm{lo}}, p_{\\mathrm{hi}}]$ 开始，确定满足相对精度要求所需的最小二分步数 $K$。\n- 确定每次二分决策所需的最小奇数重复演化次数 $m$，使得当单次演化的错误分类概率为 $q$ 时，多数票决的错误分类概率最多为 $\\rho$。\n- 估计所需的总演化次数为 $E = m \\times K$。\n\n您必须实现一个程序，对下面的每个测试用例，计算并输出整数 $E$。不涉及物理单位；所有量纲均为无量纲。\n\n测试套件：\n- 情况 A（一般情况）：$p_{\\mathrm{lo}} = 0.4$, $p_{\\mathrm{hi}} = 0.6$, $p^\\ast = 0.515$, $\\epsilon = 10^{-3}$, $q = 0.1$, $\\rho = 10^{-4}$。\n- 情况 B（严格精度，低 $q$）：$p_{\\mathrm{lo}} = 0.49$, $p_{\\mathrm{hi}} = 0.51$, $p^\\ast = 0.5$, $\\epsilon = 10^{-6}$, $q = 0.01$, $\\rho = 10^{-6}$。\n- 情况 C（高错误分类风险）：$p_{\\mathrm{lo}} = 0.9$, $p_{\\mathrm{hi}} = 1.1$, $p^\\ast = 1.0$, $\\epsilon = 10^{-2}$, $q = 0.45$, $\\rho = 10^{-3}$。\n- 情况 D（初始区间已足够精确）：$p_{\\mathrm{lo}} = 0.995$, $p_{\\mathrm{hi}} = 1.005$, $p^\\ast = 1.0$, $\\epsilon = 10^{-2}$, $q = 0.2$, $\\rho = 10^{-5}$。\n\n最终输出格式：\n您的程序应生成单行输出，包含一个由方括号括起来的逗号分隔列表的结果（例如，\"[resultA,resultB,resultC,resultD]\"），其中每个条目是对应测试用例（按 A、B、C、D 顺序）的整数 $E$。", "solution": "所述问题具有科学依据，是适定的、客观的，并且包含足够的信息以获得唯一解。它是计算科学中一个常见挑战的有效形式化：在存在随机误差的情况下，平衡数值精度与计算成本。我们将继续推导解决方案。\n\n目标是计算在指定的相对精度内定位临界参数 $p^\\ast$ 所需的总演化次数 $E$。这个总成本是两个独立确定的量的乘积：达到所需区间容差所需的二分步数 $K$，以及为确保可靠决策而每个二分步骤所需的重复演化次数 $m$。因此，$E = m \\times K$。\n\n**确定二分步数 ($K$)**\n\n二分法是一种迭代求根算法，它反复地将一个已知包含根的区间对半分割。在此背景下，“根”是临界参数 $p^\\ast$。\n\n我们从一个初始区间 $[p_{\\mathrm{lo}}^{(0)}, p_{\\mathrm{hi}}^{(0)}] = [p_{\\mathrm{lo}}, p_{\\mathrm{hi}}]$ 开始，其宽度为 $W_0 = p_{\\mathrm{hi}} - p_{\\mathrm{lo}}$。根据构造，$p_{\\mathrm{lo}}  p^\\ast  p_{\\mathrm{hi}}$。经过一次二分步骤后，新区间的宽度为 $W_1 = W_0 / 2$。经过 $K$ 步后，区间宽度减小为：\n$$ W_K = p_{\\mathrm{hi}}^{(K)} - p_{\\mathrm{lo}}^{(K)} = \\frac{p_{\\mathrm{hi}} - p_{\\mathrm{lo}}}{2^K} $$\n当区间宽度满足相对精度要求时，过程终止：\n$$ W_K \\le 2 \\epsilon p^\\ast $$\n其中 $\\epsilon$ 是目标相对精度，$p^\\ast$ 是真实的临界参数。\n\n将 $W_K$ 的表达式代入不等式，我们得到关于 $K$ 的条件：\n$$ \\frac{p_{\\mathrm{hi}} - p_{\\mathrm{lo}}}{2^K} \\le 2 \\epsilon p^\\ast $$\n为了找到最小步数，我们解出 $K$：\n$$ 2^K \\ge \\frac{p_{\\mathrm{hi}} - p_{\\mathrm{lo}}}{2 \\epsilon p^\\ast} $$\n对两边取以 2 为底的对数，得到：\n$$ K \\ge \\log_2\\left(\\frac{p_{\\mathrm{hi}} - p_{\\mathrm{lo}}}{2 \\epsilon p^\\ast}\\right) $$\n由于 $K$ 必须是表示步数的整数，我们必须对右侧取上整。然而，如果初始区间已经满足精度条件，即 $p_{\\mathrm{hi}} - p_{\\mathrm{lo}} \\le 2 \\epsilon p^\\ast$，则会出现一个特殊情况。在这种情况下，需要 0 次二分步骤。对数内的表达式将小于或等于 1，从而产生一个非正的结果。步数不能为负。因此，最小二分步数 $K$ 由下式给出：\n$$ K = \\max\\left(0, \\left\\lceil \\log_2\\left(\\frac{p_{\\mathrm{hi}} - p_{\\mathrm{lo}}}{2 \\epsilon p^\\ast}\\right) \\right\\rceil\\right) $$\n\n**确定每步二分的重复次数 ($m$)**\n\n在每个二分步骤中，必须对中点 $p_{\\mathrm{mid}}$ 处的演化特性做出决策。这个决策可能会被错误分类。为了减轻这种情况，我们执行 $m$ 次独立的演化，并通过多数票决来决定结果。我们必须找到最小的奇数 $m$，使得不正确多数票决的概率最多为 $\\rho$。\n\n设 $q$ 是单次演化被错误分类的概率。$m$ 次演化中的每一次结果都是一个伯努利试验。设 $N_{\\mathrm{incorrect}}$ 是 $m$ 次试验中不正确结果的次数。$N_{\\mathrm{incorrect}}$ 服从二项分布，记为 $\\mathcal{B}(m, q)$，其概率质量函数为：\n$$ P(N_{\\mathrm{incorrect}}=k) = \\binom{m}{k} q^k (1-q)^{m-k} $$\n对于 $k \\in \\{0, 1, \\dots, m\\}$。\n\n问题规定 $m$ 必须是奇数。如果错误结果的次数超过总票数的一半，即 $N_{\\mathrm{incorrect}} > m/2$，则多数票决是不正确的。由于 $m$ 是奇数，这等价于 $N_{\\mathrm{incorrect}} \\ge (m+1)/2$。\n\n不正确多数票决的概率 $P_{\\mathrm{error}}$ 是所有此类结果的概率之和：\n$$ P_{\\mathrm{error}}(m, q) = P(N_{\\mathrm{incorrect}} \\ge (m+1)/2) = \\sum_{k=(m+1)/2}^{m} \\binom{m}{k} q^k (1-q)^{m-k} $$\n该表达式是二项分布的尾概率。我们的任务是找到满足每次决策容差 $\\rho$ 的最小奇数 $m$：\n$$ P_{\\mathrm{error}}(m, q) \\le \\rho $$\n这个不等式通常没有关于 $m$ 的简单闭式解。相反，$m$ 必须通过数值方法找到。我们可以从 $m=1$ 开始，每次增加 2（以保持奇数），在每一步计算 $P_{\\mathrm{error}}$，直到满足条件。该求和可以使用二项分布的生存函数高效计算，该函数通常在科学计算库中提供，并与正则化不完全贝塔函数有关。\n\n**总计算成本 ($E$)**\n\n总演化次数 $E$ 是要做的二分决策次数与每次决策的计算成本的乘积。对于 $K$ 次二分步骤和每步 $m$ 次演化，总成本为：\n$$ E = m \\times K $$\n如果 $K=0$，则不执行任何二分步骤，因此不需要演化来细化区间。在这种情况下，无论 $m$ 的值是多少，$E=0$。\n\n以下程序实现了这一逻辑，以计算每个指定测试用例的 $E$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\nfrom scipy.stats import binom\n\ndef solve():\n    \"\"\"\n    Computes the total number of evolutions E for a series of test cases\n    related to finding a critical parameter in gravitational collapse.\n    \"\"\"\n    \n    # Define the test cases from the problem statement as a list of tuples.\n    # Each tuple: (p_lo, p_hi, p_star, epsilon, q, rho)\n    test_cases = [\n        # Case A: general case\n        (0.4, 0.6, 0.515, 1e-3, 0.1, 1e-4),\n        # Case B: stringent accuracy, low q\n        (0.49, 0.51, 0.5, 1e-6, 0.01, 1e-6),\n        # Case C: high misclassification risk\n        (0.9, 1.1, 1.0, 1e-2, 0.45, 1e-3),\n        # Case D: initial bracket already sufficiently accurate\n        (0.995, 1.005, 1.0, 1e-2, 0.2, 1e-5),\n    ]\n\n    def calculate_k(p_lo, p_hi, p_star, epsilon):\n        \"\"\"\n        Calculates the minimal number of bisection steps K.\n        \"\"\"\n        # The required final interval width\n        target_width = 2 * epsilon * p_star\n        initial_width = p_hi - p_lo\n\n        # If the initial interval is already accurate enough, K=0.\n        if initial_width = target_width:\n            return 0\n        \n        # Calculate the ratio of initial width to target width.\n        # This determines how many times we need to halve the interval.\n        ratio = initial_width / target_width\n        \n        # The number of steps K is the ceiling of log base 2 of the ratio.\n        k = math.ceil(math.log2(ratio))\n        return int(k)\n\n    def calculate_m(q, rho):\n        \"\"\"\n        Calculates the minimal odd number of repetitions m per bisection.\n        \"\"\"\n        # Start with the smallest odd integer.\n        m = 1\n        while True:\n            # For majority vote with odd m, error occurs if incorrect votes k > m/2,\n            # which is equivalent to k >= (m+1)/2.\n            # The survival function sf(k, n, p) computes P(X > k).\n            # We need P(X >= (m+1)/2) = P(X > (m+1)/2 - 1) = P(X > (m-1)/2).\n            # k_threshold is the argument to sf().\n            k_threshold = (m - 1) // 2\n            \n            error_prob = binom.sf(k_threshold, n=m, p=q)\n            \n            # Check if majority vote error probability is within tolerance.\n            if error_prob = rho:\n                return m\n            \n            # Increment to the next odd integer.\n            m += 2\n\n    results = []\n    for case in test_cases:\n        p_lo, p_hi, p_star, epsilon, q, rho = case\n        \n        # Calculate the number of bisection steps.\n        k = calculate_k(p_lo, p_hi, p_star, epsilon)\n        \n        # If K is 0, no bisections are needed, so total evolutions E is 0.\n        if k == 0:\n            e = 0\n        else:\n            # Otherwise, calculate m and the total cost E = m * K.\n            m = calculate_m(q, rho)\n            e = m * k\n        \n        results.append(e)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3471223"}, {"introduction": "在数值模拟中获得结果后，我们如何确信测量到的标度指数是真实的物理规律，而非数值计算引入的系统误差？这个练习将带你直面计算科学中的一个核心问题：验证。你将学习如何通过多分辨率收敛性测试和理查森外推法，系统地从“测量”数据中分离出物理标度律和数值截断误差，从而诊断并获得可靠的物理结果。[@problem_id:3471252]", "problem": "在广义相对论中，一个临界引力坍缩过程存在一个介于弥散和黑洞形成之间的阈值，该过程由爱因斯坦场方程所支配。对于一个球对称的单参数初值数据族，存在一个阈值参数 $p^\\star$，使得当 $p > p^\\star$ 时，会形成一个黑洞。在阈值附近，产生的黑洞质量（记为 $M$）表现出一种在数值相对论实验中普遍观测到的标度关系：主导阶动力学由临界解附近的一个相关微扰模式所控制。分辨率为 $h$ 的爱因斯坦方程的有限差分格式离散化会引入截断误差，这可能会改变计算中观测到的标度行为，潜在地模拟出额外的相关模式，并对物理标度指数的测量产生偏差。在一个计算实验中，人们试图恢复物理标度指数，并诊断截断误差是否表现为明显的额外相关模式。\n\n从以下公认的基础出发：\n- 对于具有一个主导相关模式的合适物质模型，爱因斯坦场方程意味着在阈值附近存在无标度的临界现象。\n- 分辨率为 $h$ 的离散化方案具有截断误差，该误差以已知的形式阶 $r$ 进行缩放，产生一个与 $h^r$ 成正比的误差项。\n\n你必须构建一个程序，通过在多个分辨率下进行受控的收敛性测试，来将物理标度与数值伪影分离开。对于以无量纲单位生成的合成数据集，假设在分辨率 $h$ 下，测得的黑洞质量作为超临界度 $\\epsilon = p - p^\\star$ 的函数，其模型如下：\n$$\nM_h(\\epsilon) = C\\, \\epsilon^{\\gamma} + D\\, h^r \\epsilon^{\\beta} + \\eta(\\epsilon,h),\n$$\n其中 $C > 0$ 是一个无量纲振幅，$\\gamma > 0$ 是待恢复的物理标度指数，$D$ 是一个无量纲的污染振幅，$r$ 是离散化方案的收敛阶，$\\beta \\ge 0$ 参数化了由截断引起的伪影如何随 $\\epsilon$ 缩放，并且如果 $\\beta  \\gamma$，它可能模拟一个额外的相关模式，$\\eta$ 是小的随机噪声。所有量均为无量纲。\n\n设计诊断程序，使用来自至少3个分辨率 $h_1, h_2, h_3$ 和多个 $\\epsilon$ 值的数据来：\n- 直接从数据中估计收敛阶 $r$，而无需事先知道 $r$。\n- 通过 Richardson 型外推消除主导截断项 $D h^r \\epsilon^{\\beta}$，以恢复对连续谱质量 $M(\\epsilon) \\approx C\\, \\epsilon^{\\gamma}$ 的近似。\n- 通过外推的连续谱质量在不同 $\\epsilon$ 值下的数据，拟合物理标度指数 $\\gamma$。\n- 比较从单分辨率拟合中得到的表观斜率与多分辨率外推拟合得到的斜率，以诊断截断误差是否模拟了一个额外的相关模式，从而对单分辨率测量造成偏差。\n\n你必须实现以下计算步骤：\n- 给定3个分辨率 $h_1 > h_2 > h_3$，以及 $\\epsilon_k$ 值数组（$k = 1,\\dots,K$），通过对 $\\log M_{h_j}(\\epsilon_k)$ 与 $\\log \\epsilon_k$ 进行线性最小二乘拟合，计算每个分辨率 $h_j$ 下的朴素表观指数 $\\hat{\\gamma}_j$。\n- 通过最小化在不同 $\\epsilon_k$ 上的分辨率差值比的差异来估计 $r$：\n$$\nS(r) = \\sum_{k} \\left[ \\frac{M_{h_1}(\\epsilon_k) - M_{h_2}(\\epsilon_k)}{M_{h_2}(\\epsilon_k) - M_{h_3}(\\epsilon_k)} - \\frac{h_1^r - h_2^r}{h_2^r - h_3^r} \\right]^2,\n$$\n排除分母的绝对值过小以至于无法避免数值不稳定的项。\n- 使用估计的 $r$，通过在每个 $\\epsilon_k$ 处进行两点 Richardson 外推来消除主导截断项：\n$$\n\\widehat{M}(\\epsilon_k) = \\frac{h_2^r M_{h_1}(\\epsilon_k) - h_1^r M_{h_2}(\\epsilon_k)}{h_2^r - h_1^r},\n$$\n并且\n$$\n\\widehat{M}'(\\epsilon_k) = \\frac{h_3^r M_{h_2}(\\epsilon_k) - h_2^r M_{h_3}(\\epsilon_k)}{h_3^r - h_2^r}.\n$$\n将这两个外推值平均，以获得一个稳健的连续谱估计\n$$\n\\widehat{M}_{\\text{avg}}(\\epsilon_k) = \\frac{1}{2}\\left[\\widehat{M}(\\epsilon_k) + \\widehat{M}'(\\epsilon_k)\\right].\n$$\n- 通过对 $\\log \\widehat{M}_{\\text{avg}}(\\epsilon_k)$ 与 $\\log \\epsilon_k$ 进行线性最小二乘拟合来拟合 $\\gamma$，从而得到 $\\hat{\\gamma}_{\\text{extrap}}$。\n- 如果单分辨率表观斜率与外推斜率之间的最大差异超过一个阈值，即如果\n$$\n\\max_{j \\in \\{1,2,3\\}} \\left| \\hat{\\gamma}_j - \\hat{\\gamma}_{\\text{extrap}} \\right| > \\tau,\n$$\n则声明截断误差模拟了一个额外的相关模式，其中阈值 $\\tau = 0.02$（无量纲单位）。\n\n你的程序必须为以下参数集的测试套件生成合成数据集，然后应用上述诊断方法并产生指定的输出。所有量均为无量纲，所有对数均为自然对数。\n\n测试套件：\n- 情况1（理想情况，中度污染）：\n  - $C = 1.0$, $\\gamma = 0.374$, $D = 0.5$, $\\beta = 0.20$, $r = 2$, $h_1 = 0.4$, $h_2 = 0.2$, $h_3 = 0.1$。\n  - $\\epsilon_k$ 是从 $10^{-6}$ 到 $10^{-2}$ 对数均匀分布的20个值。\n  - 加性高斯噪声 $\\eta$，均值为零，标准差为 $C\\,\\epsilon^{\\gamma}$ 的 $\\sigma = 10^{-8}$ 倍。\n- 情况2（边缘情况，粗分辨率下强污染）：\n  - $C = 1.0$, $\\gamma = 0.374$, $D = 5.0$, $\\beta = 0.20$, $r = 2$, $h_1 = 0.8$, $h_2 = 0.4$, $h_3 = 0.2$。\n  - $\\epsilon_k$ 是从 $5\\times 10^{-6}$ 到 $10^{-3}$ 对数均匀分布的20个值。\n  - 加性高斯噪声 $\\eta$，均值为零，标准差为 $C\\,\\epsilon^{\\gamma}$ 的 $\\sigma = 5\\times 10^{-8}$ 倍。\n- 情况3（边界情况，高阶格式弱污染）：\n  - $C = 1.0$, $\\gamma = 0.374$, $D = 0.3$, $\\beta = 0.05$, $r = 4$, $h_1 = 0.5$, $h_2 = 0.25$, $h_3 = 0.125$。\n  - $\\epsilon_k$ 是从 $10^{-6}$ 到 $10^{-2}$ 对数均匀分布的20个值。\n  - 加性高斯噪声 $\\eta$，均值为零，标准差为 $C\\,\\epsilon^{\\gamma}$ 的 $\\sigma = 10^{-8}$ 倍。\n\n实现要求：\n- 在所有拟合中，对数据对 $\\left(\\log \\epsilon_k, \\log(\\cdot)\\right)$ 使用普通最小二乘法。\n- 对于 $r$ 的估计泛函 $S(r)$，忽略任何满足 $\\left|M_{h_2}(\\epsilon_k) - M_{h_3}(\\epsilon_k)\\right|  10^{-14}$ 的 $k$，以避免除以接近零的数。\n- 为 $\\eta$ 使用确定性伪随机数生成器（设置一个固定的种子），以便结果是可复现的。\n\n最终输出规格：\n- 对于每种情况，返回一个列表 $[\\hat{\\gamma}_{\\text{extrap}}, \\hat{r}, \\text{diagnosis}]$，其中 $\\hat{\\gamma}_{\\text{extrap}}$ 四舍五入到6位小数，$\\hat{r}$ 四舍五入到3位小数，$\\text{diagnosis}$ 是一个布尔值，以 $\\text{True}$ 或 $\\text{False}$ 的形式返回，表示截断误差是否如上文定义的那样模拟了额外的相关模式。\n- 你的程序应生成一行输出，其中包含按顺序排列的这三种情况的结果，形式为一个由这三个元素列表组成的逗号分隔列表，并用方括号括起来：例如，$[[\\dots],[\\dots],[\\dots]]$。\n\n你的程序必须完全自包含，不需要任何输入，并且只使用指定的库。所有输出都是无量纲的。不使用角度。不使用百分比。", "solution": "所呈现的问题是一个在数值分析领域内提法恰当且具有科学依据的练习，其背景是引力坍缩中的临界现象，这是数值相对论中一个备受关注的课题。其目标是诊断并校正模拟数据中声称遵循物理标度律的数值伪影。这需要系统地应用收敛性测试和外推技术，这些是计算科学中用于验证模拟结果和估计数值解准确性的基本工具。我们将以详细、基于原理的方式进行解答。\n\n在数值分辨率为 $h$、超临界度参数为 $\\epsilon = p - p^\\star$ 时，测得的黑洞质量 $M_h(\\epsilon)$ 的理论模型如下：\n$$\nM_h(\\epsilon) = C\\, \\epsilon^{\\gamma} + D\\, h^r \\epsilon^{\\beta} + \\eta(\\epsilon,h)\n$$\n这个模型由三个不同的项组成。第一项，$C\\, \\epsilon^{\\gamma}$，代表广义相对论中临界现象理论所预测的物理标度律，其中 $\\gamma$ 是普适临界指数，C 是一个依赖于具体族系的振幅。第二项，$D\\, h^r \\epsilon^{\\beta}$，模拟了用于求解爱因斯坦场方程的数值方法的主导阶截断误差。这里，$h$ 是网格间距的度量，$r$ 是数值格式的形式收敛阶，$D$ 和 $\\beta$ 是表征该误差项如何依赖于模拟参数的参数。第三项，$\\eta(\\epsilon,h)$，代表随机噪声，这在浮点计算中是不可避免的，并且也可以模拟微小的、未解析的物理或数值效应。\n\n我们的主要目标是从一组在三个不同分辨率 $h_1 > h_2 > h_3$ 和多个 $\\epsilon_k$ 值下生成的模拟数据点 $\\{M_{h_j}(\\epsilon_k)\\}$ 中确定物理指数 $\\gamma$。\n\n提取标度指数的标准技术是在对数-对数图上进行线性拟合。对质量模型取自然对数，我们得到：\n$$\n\\log M_h(\\epsilon) = \\log \\left( C\\, \\epsilon^{\\gamma} + D\\, h^r \\epsilon^{\\beta} \\right) + \\log\\left(1 + \\frac{\\eta}{C\\epsilon^\\gamma + Dh^r\\epsilon^\\beta}\\right) \\approx \\log \\left( C\\, \\epsilon^{\\gamma} + D\\, h^r \\epsilon^{\\beta} \\right)\n$$\n如果数值误差项不存在（$D=0$），这将简化为 $\\log M(\\epsilon) \\approx \\gamma \\log \\epsilon + \\log C$。在这种理想情况下，$\\log M$ 对 $\\log \\epsilon$ 的线性拟合的斜率将直接得出 $\\gamma$。然而，截断误差项的存在污染了这种关系。对数-对数图的斜率变得依赖于 $\\epsilon$，在一个 $\\epsilon$ 值范围内的简单线性拟合将在每个分辨率 $h_j$ 下产生一个“表观”指数 $\\hat{\\gamma}_j$，这是对真实指数 $\\gamma$ 的一个有偏估计。如果 $\\beta  \\gamma$，当 $\\epsilon \\to 0$ 时，误差项 $D h^r \\epsilon^\\beta$ 相对于物理项 $C \\epsilon^\\gamma$ 会变得越来越占主导。这会严重破坏对 $\\gamma$ 的估计，该问题将此现象描述为截断误差“模拟了一个额外的相关模式”。\n\n为了克服这个问题，我们必须首先表征然后消除主导阶误差项。\n\n**第1步：收敛阶 $r$ 的估计**\n\n我们可以在没有先验知识的情况下估计收敛阶 $r$，只需假设模型成立且高阶误差项是次主导的。考虑在固定 $\\epsilon$ 下，两个分辨率（比如 $h_1$ 和 $h_2$）之间质量测量的差异：\n$$\nM_{h_1}(\\epsilon) - M_{h_2}(\\epsilon) \\approx \\left( C\\epsilon^\\gamma + D h_1^r \\epsilon^\\beta \\right) - \\left( C\\epsilon^\\gamma + D h_2^r \\epsilon^\\beta \\right) = D \\epsilon^\\beta (h_1^r - h_2^r)\n$$\n类似地，对于分辨率 $h_2$ 和 $h_3$：\n$$\nM_{h_2}(\\epsilon) - M_{h_3}(\\epsilon) \\approx D \\epsilon^\\beta (h_2^r - h_3^r)\n$$\n取这两个差分之比可以消除未知的因子 $D$ 和 $\\epsilon^\\beta$：\n$$\n\\frac{M_{h_1}(\\epsilon) - M_{h_2}(\\epsilon)}{M_{h_2}(\\epsilon) - M_{h_3}(\\epsilon)} \\approx \\frac{h_1^r - h_2^r}{h_2^r - h_3^r}\n$$\n这个“差分之比”在所有 $\\epsilon_k$ 值上应近似为常数。因此，我们可以通过最小化左侧（从数据计算）和右侧（$r$ 的函数）之间的残差平方和来找到 $r$ 的最佳拟合值。这引出了需要对 $r$ 最小化的指定代价泛函：\n$$\nS(r) = \\sum_{k} \\left[ \\frac{M_{h_1}(\\epsilon_k) - M_{h_2}(\\epsilon_k)}{M_{h_2}(\\epsilon_k) - M_{h_3}(\\epsilon_k)} - \\frac{h_1^r - h_2^r}{h_2^r - h_3^r} \\right]^2\n$$\n最小化 $S(r)$ 得到我们的数据驱动的估计值 $\\hat{r}$。\n\n**第2步：Richardson 外推**\n\n有了对收敛阶的估计值 $\\hat{r}$，我们就可以消除主导阶误差项，从而获得对连续谱质量 $M(\\epsilon) = C\\epsilon^\\gamma$ 的更准确估计。这个过程被称为 Richardson 外推。对于任意给定的 $\\epsilon_k$，我们有两个关于真实质量 $M(\\epsilon_k)$ 的近似方程：\n$$\nM_{h_1}(\\epsilon_k) \\approx M(\\epsilon_k) + K_k h_1^{\\hat{r}}\n$$\n$$\nM_{h_2}(\\epsilon_k) \\approx M(\\epsilon_k) + K_k h_2^{\\hat{r}}\n$$\n其中 $K_k = D \\epsilon_k^\\beta$。这是一个关于两个未知数 $M(\\epsilon_k)$ 和 $K_k$ 的二元线性方程组。求解 $M(\\epsilon_k)$ 得到外推值：\n$$\n\\widehat{M}(\\epsilon_k) = \\frac{h_2^{\\hat{r}} M_{h_1}(\\epsilon_k) - h_1^{\\hat{r}} M_{h_2}(\\epsilon_k)}{h_2^{\\hat{r}} - h_1^{\\hat{r}}}\n$$\n这个新估计值 $\\widehat{M}(\\epsilon_k)$ 的误差阶高于 $\\hat{r}$，这意味着它是真实连续谱质量 $M(\\epsilon_k)$ 的一个显著更好的近似。我们将此方法应用于两对分辨率 $(h_1, h_2)$ 和 $(h_2, h_3)$，以生成两个外推序列 $\\widehat{M}(\\epsilon_k)$ 和 $\\widehat{M}'(\\epsilon_k)$。将它们平均可以提供一个更稳健的估计 $\\widehat{M}_{\\text{avg}}(\\epsilon_k)$，这减少了噪声和高阶误差的影响。\n\n**第3步：最终拟合与诊断**\n\n现在，我们对 $\\log \\widehat{M}_{\\text{avg}}(\\epsilon_k)$ 与 $\\log \\epsilon_k$ 进行线性最小二乘拟合。这个拟合的斜率 $\\hat{\\gamma}_{\\text{extrap}}$ 是我们对真实物理标度指数 $\\gamma$ 的最佳估计，因为它是从系统地移除了主导数值伪影的数据中得出的。\n\n最后，诊断测试将这个稳健的外推指数与从单分辨率拟合中获得的朴素指数 $\\hat{\\gamma}_j$ 进行比较。判据\n$$\n\\max_{j \\in \\{1,2,3\\}} \\left| \\hat{\\gamma}_j - \\hat{\\gamma}_{\\text{extrap}} \\right| > \\tau\n$$\n（给定阈值 $\\tau=0.02$）为截断误差的影响提供了一个定量度量。如果该不等式成立，我们得出结论，单分辨率分析存在显著偏差，并且截断误差确实模拟了一个额外的相关模式，扭曲了观测到的标度行为。这个过程体现了计算物理学中区分物理现实与数值伪影所需的严谨性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the results.\n    \"\"\"\n    # Set a fixed seed for the pseudorandom generator for reproducibility.\n    np.random.seed(42)\n\n    # Test Suite Definition\n    test_cases = [\n        # Case 1: happy path, moderate contamination\n        {\n            \"params\": {\"C\": 1.0, \"gamma\": 0.374, \"D\": 0.5, \"beta\": 0.20, \"r_true\": 2},\n            \"h\": [0.4, 0.2, 0.1],\n            \"eps_range\": (1e-6, 1e-2),\n            \"eps_num\": 20,\n            \"noise_sigma_factor\": 1e-8,\n            \"tau\": 0.02\n        },\n        # Case 2: edge case, strong contamination\n        {\n            \"params\": {\"C\": 1.0, \"gamma\": 0.374, \"D\": 5.0, \"beta\": 0.20, \"r_true\": 2},\n            \"h\": [0.8, 0.4, 0.2],\n            \"eps_range\": (5e-6, 1e-3),\n            \"eps_num\": 20,\n            \"noise_sigma_factor\": 5e-8,\n            \"tau\": 0.02\n        },\n        # Case 3: boundary case, higher-order scheme\n        {\n            \"params\": {\"C\": 1.0, \"gamma\": 0.374, \"D\": 0.3, \"beta\": 0.05, \"r_true\": 4},\n            \"h\": [0.5, 0.25, 0.125],\n            \"eps_range\": (1e-6, 1e-2),\n            \"eps_num\": 20,\n            \"noise_sigma_factor\": 1e-8,\n            \"tau\": 0.02\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # str(list) produces a string representation like '[...]', so joining them\n    # with ',' and wrapping with '[]' gives the desired format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef generate_data(params, h_vals, eps_range, eps_num, noise_sigma_factor):\n    \"\"\"\n    Generates synthetic mass data based on the provided model.\n    \"\"\"\n    C, gamma, D, beta, r_true = params[\"C\"], params[\"gamma\"], params[\"D\"], params[\"beta\"], params[\"r_true\"]\n    eps = np.logspace(np.log10(eps_range[0]), np.log10(eps_range[1]), eps_num)\n    \n    mass_data = []\n    for h in h_vals:\n        M_physical = C * eps**gamma\n        M_error = D * h**r_true * eps**beta\n        noise_sigma = noise_sigma_factor * M_physical\n        noise = np.random.normal(0, 1, size=eps.shape) * noise_sigma\n        \n        M_h = M_physical + M_error + noise\n        mass_data.append(M_h)\n        \n    return eps, mass_data\n\ndef fit_gamma(eps, mass):\n    \"\"\"\n    Performs an ordinary least-squares fit on log-log data to find the scaling exponent.\n    y = m*x + c where y=log(mass), x=log(eps), m=gamma\n    \"\"\"\n    log_eps = np.log(eps)\n    log_mass = np.log(mass)\n    \n    # Design matrix for linear regression (slope and intercept)\n    A = np.vstack([log_eps, np.ones(len(log_eps))]).T\n    \n    # Solve for [slope, intercept]\n    slope, _ = np.linalg.lstsq(A, log_mass, rcond=None)[0]\n    return slope\n\ndef estimate_r(h, mass_data, eps):\n    \"\"\"\n    Estimates the convergence order r by minimizing the functional S(r).\n    \"\"\"\n    h1, h2, h3 = h\n    M1, M2, M3 = mass_data\n    \n    def S(r):\n        numerator_M = M1 - M2\n        denominator_M = M2 - M3\n        \n        # Ratio of mass differences from data\n        valid_indices = np.abs(denominator_M) >= 1e-14\n        ratio_M = numerator_M[valid_indices] / denominator_M[valid_indices]\n        \n        # Ratio of resolution differences\n        numerator_h = h1**r - h2**r\n        denominator_h = h2**r - h3**r\n        if abs(denominator_h)  1e-16: # Avoid division by zero for r=0\n            return np.inf\n        ratio_h = numerator_h / denominator_h\n        \n        # Sum of squared differences\n        return np.sum((ratio_M - ratio_h)**2)\n\n    # Minimize S(r) using a bounded scalar optimizer\n    res = minimize_scalar(S, bounds=(0.5, 8.0), method='bounded')\n    return res.x\n\ndef process_case(case_data):\n    \"\"\"\n    Executes the full analysis pipeline for a single test case.\n    \"\"\"\n    eps, mass_data = generate_data(\n        case_data[\"params\"], \n        case_data[\"h\"], \n        case_data[\"eps_range\"], \n        case_data[\"eps_num\"], \n        case_data[\"noise_sigma_factor\"]\n    )\n    \n    h1, h2, h3 = case_data[\"h\"]\n    M1, M2, M3 = mass_data\n\n    # 1. Compute naive apparent exponents\n    gamma_hat_1 = fit_gamma(eps, M1)\n    gamma_hat_2 = fit_gamma(eps, M2)\n    gamma_hat_3 = fit_gamma(eps, M3)\n    gamma_hats_naive = [gamma_hat_1, gamma_hat_2, gamma_hat_3]\n\n    # 2. Estimate convergence order r\n    r_hat = estimate_r(case_data[\"h\"], mass_data, eps)\n\n    # 3. Richardson extrapolation\n    hr2, hr1 = h2**r_hat, h1**r_hat\n    M_hat = (hr2 * M1 - hr1 * M2) / (hr2 - hr1)\n    \n    hr3, hr2 = h3**r_hat, h2**r_hat\n    M_hat_prime = (hr3 * M2 - hr2 * M3) / (hr3 - hr2)\n    \n    M_hat_avg = 0.5 * (M_hat + M_hat_prime)\n\n    # 4. Fit gamma from extrapolated data\n    gamma_hat_extrap = fit_gamma(eps, M_hat_avg)\n    \n    # 5. Diagnosis\n    max_discrepancy = max(abs(gamma_naive - gamma_hat_extrap) for gamma_naive in gamma_hats_naive)\n    diagnosis = max_discrepancy > case_data[\"tau\"]\n    \n    return [\n        round(gamma_hat_extrap, 6),\n        round(r_hat, 3),\n        diagnosis\n    ]\n\n# Execute the solution process.\nsolve()\n\n```", "id": "3471252"}]}