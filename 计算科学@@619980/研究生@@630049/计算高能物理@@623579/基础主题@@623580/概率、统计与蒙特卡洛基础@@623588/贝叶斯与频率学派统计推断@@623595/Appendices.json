{"hands_on_practices": [{"introduction": "在高能物理中，许多分析都归结为一个核心问题：如何在背景事件中寻找稀有的信号事件。这个练习将引导你解决一个典型的“单箱计数”问题，其中背景由一个辅助测量来约束 [@problem_id:3506272]。通过推导信号和背景的最大似然估计量及其不确定性，你将掌握任何物理分析中最基本和最强大的频率论统计方法之一。", "problem": "在大型强子对撞机（LHC）上进行了一项单箱计数实验，以在双μ子通道中寻找重共振。该分析在以下生成模型下进行：信号区域中的观测计数（记为 $n$）被假定服从均值为 $s + b$ 的泊松分布，其中 $s \\ge 0$ 是未知的平均信号产额，$b \\ge 0$ 是未知的平均本底产额。一个独立的辅助本底校准产生了一个对本底的单一高斯测量值 $x$，其标准差 $\\sigma$ 已知，模型为 $x \\sim \\mathcal{N}(b, \\sigma^{2})$。在给定 $b$ 和 $s$ 的条件下，假定泊松计数和高斯校准之间是独立的。\n\n需要使用的经过充分检验的事实和定义是：对于整数 $n \\ge 0$ 和均值 $\\lambda > 0$ 的泊松概率质量函数 $P(n \\mid \\lambda) = \\exp(-\\lambda)\\lambda^{n}/n!$，对于 $x \\in \\mathbb{R}$ 的高斯概率密度函数 $f(x \\mid \\mu,\\sigma^{2}) = (2\\pi\\sigma^{2})^{-1/2}\\exp\\!\\big(- (x - \\mu)^{2}/(2\\sigma^{2})\\big)$，以及最大似然估计（MLE）的定义，即最大化似然函数的参数值。在标准正则性条件下，MLE 的渐近协方差矩阵是通过对观测信息矩阵求逆得到的，该矩阵定义为在 MLE 处评估的对数似然函数的负海森矩阵（二阶导数矩阵）。\n\n给定观测数据 $n = 35$，辅助测量值 $x = 28$，以及已知标准差 $\\sigma = 6$。仅从上述定义和事实出发，推导 $(s,b)$ 的联合 MLE，并通过对在 MLE 处的观测信息求逆来获得它们的渐近协方差矩阵。假设对于所提供的数据，内部解 $s > 0$ 和 $b > 0$ 是有效的。将你的最终答案表示为一个单行矩阵，按顺序包含 $s^{\\ast}$、$b^{\\ast}$、$\\operatorname{Var}(s^{\\ast})$、$\\operatorname{Cov}(s^{\\ast}, b^{\\ast})$、$\\operatorname{Cov}(b^{\\ast}, s^{\\ast})$ 和 $\\operatorname{Var}(b^{\\ast})$。不需要四舍五入，最终数值中也不应包含任何物理单位。", "solution": "问题陈述经过了形式化验证，被认为是自洽的、有科学依据的且适定的。所有必要的数据、模型和定义都已提供，不存在内部矛盾或歧义。该问题是最大似然估计在高能物理数据分析典型背景下的一个标准应用。因此，我们可以开始解题。\n\n目标是求出参数 $s$（信号）和 $b$（本底）的最大似然估计（MLEs）及其渐近协方差矩阵。数据由一个观测计数 $n$ 和一个辅助测量值 $x$ 组成。\n\n该统计模型由两个部分定义：\n1.  计数 $n$ 服从均值为 $s+b$ 的泊松分布：$n \\sim \\text{Poisson}(s+b)$。其概率质量函数为 $P(n \\mid s, b) = \\frac{\\exp(-(s+b))(s+b)^n}{n!}$。\n2.  辅助测量值 $x$ 服从均值为 $b$、方差 $\\sigma^2$ 已知的高斯分布：$x \\sim \\mathcal{N}(b, \\sigma^2)$。其概率密度函数为 $f(x \\mid b, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-b)^2}{2\\sigma^2}\\right)$。\n\n鉴于两次测量是条件独立的，观测到数据对 $(n, x)$ 的联合似然函数 $L(s, b)$ 是各自概率函数的乘积：\n$$L(s, b) = P(n \\mid s, b) \\times f(x \\mid b, \\sigma^2) = \\frac{\\exp(-(s+b))(s+b)^n}{n!} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-b)^2}{2\\sigma^2}\\right)$$\n在计算上，处理似然函数的自然对数，即对数似然函数 $\\ell(s, b) = \\ln L(s, b)$，更为方便：\n$$\\ell(s, b) = -(s+b) + n\\ln(s+b) - \\ln(n!) - \\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{(x-b)^2}{2\\sigma^2}$$\n为了找到 MLE，我们对该函数关于 $s$ 和 $b$ 进行最大化。我们可以忽略 $-\\ln(n!)$ 和 $-\\frac{1}{2}\\ln(2\\pi\\sigma^2)$ 这两项，因为它们是不依赖于参数 $s$ 和 $b$ 的常数。对数似然函数的相关部分是：\n$$\\ell(s, b) = -(s+b) + n\\ln(s+b) - \\frac{(x-b)^2}{2\\sigma^2}$$\nMLE（记为 $s^*$ 和 $b^*$）通过求解 $\\ell(s, b)$ 的一阶偏导数为零的方程组得到：\n$$\\frac{\\partial\\ell}{\\partial s} = 0 \\quad \\text{和} \\quad \\frac{\\partial\\ell}{\\partial b} = 0$$\n我们来计算偏导数：\n$$\\frac{\\partial\\ell}{\\partial s} = -1 + \\frac{n}{s+b}$$\n$$\\frac{\\partial\\ell}{\\partial b} = -1 + \\frac{n}{s+b} + \\frac{x-b}{\\sigma^2}$$\n将第一个方程设为零，得到：\n$$-1 + \\frac{n}{s^*+b^*} = 0 \\implies s^*+b^* = n$$\n将此结果代入设为零的第二个方程：\n$$-1 + \\frac{n}{n} + \\frac{x-b^*}{\\sigma^2} = 0 \\implies -1 + 1 + \\frac{x-b^*}{\\sigma^2} = 0 \\implies \\frac{x-b^*}{\\sigma^2} = 0 \\implies b^* = x$$\n在第一个条件中使用 $b^*$ 的这个结果，我们求得 $s^*$：\n$$s^* + x = n \\implies s^* = n-x$$\nMLE 分别是 $s^* = n-x$ 和 $b^*=x$。给定 $n=35$ 和 $x=28$。\n$$s^* = 35 - 28 = 7$$\n$$b^* = 28$$\n问题陈述要求假设一个内部解（$s>0, b>0$），这与这些结果是一致的。\n\n接下来，我们推导 MLE 的渐近协方差矩阵。它由观测信息矩阵 $I(s^*, b^*)$ 的逆给出，而观测信息矩阵是对数似然函数的海森矩阵在 MLE 处取值的负数。海森矩阵 $H$ 是二阶偏导数矩阵。\n\n我们来计算 $\\ell(s,b)$ 的二阶偏导数：\n$$\\frac{\\partial^2\\ell}{\\partial s^2} = \\frac{\\partial}{\\partial s} \\left(-1 + \\frac{n}{s+b}\\right) = -\\frac{n}{(s+b)^2}$$\n$$\\frac{\\partial^2\\ell}{\\partial b^2} = \\frac{\\partial}{\\partial b} \\left(-1 + \\frac{n}{s+b} + \\frac{x-b}{\\sigma^2}\\right) = -\\frac{n}{(s+b)^2} - \\frac{1}{\\sigma^2}$$\n$$\\frac{\\partial^2\\ell}{\\partial s \\partial b} = \\frac{\\partial}{\\partial b} \\left(-1 + \\frac{n}{s+b}\\right) = -\\frac{n}{(s+b)^2}$$\n根据克莱罗定理，$\\frac{\\partial^2\\ell}{\\partial b \\partial s} = \\frac{\\partial^2\\ell}{\\partial s \\partial b}$。海森矩阵为：\n$$H(s,b) = \\begin{pmatrix} \\frac{\\partial^2\\ell}{\\partial s^2} & \\frac{\\partial^2\\ell}{\\partial s \\partial b} \\\\ \\frac{\\partial^2\\ell}{\\partial b \\partial s} & \\frac{\\partial^2\\ell}{\\partial b^2} \\end{pmatrix} = \\begin{pmatrix} -\\frac{n}{(s+b)^2} & -\\frac{n}{(s+b)^2} \\\\ -\\frac{n}{(s+b)^2} & -\\frac{n}{(s+b)^2} - \\frac{1}{\\sigma^2} \\end{pmatrix}$$\n我们在 MLE 处计算该矩阵，其中 $s^*+b^* = n$：\n$$H(s^*, b^*) = \\begin{pmatrix} -\\frac{n}{n^2} & -\\frac{n}{n^2} \\\\ -\\frac{n}{n^2} & -\\frac{n}{n^2} - \\frac{1}{\\sigma^2} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{n} & -\\frac{1}{n} \\\\ -\\frac{1}{n} & -\\frac{1}{n} - \\frac{1}{\\sigma^2} \\end{pmatrix}$$\n在 MLE 处的观测信息矩阵是 $I(s^*, b^*) = -H(s^*, b^*)$：\n$$I(s^*, b^*) = \\begin{pmatrix} \\frac{1}{n} & \\frac{1}{n} \\\\ \\frac{1}{n} & \\frac{1}{n} + \\frac{1}{\\sigma^2} \\end{pmatrix}$$\n渐近协方差矩阵 $C$ 是 $I(s^*, b^*)$ 的逆矩阵。对于一个 $2 \\times 2$ 矩阵 $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$，其逆矩阵为 $A^{-1} = \\frac{1}{ad-bc}\\begin{pmatrix} d & -b \\\\ -c & a \\end{pmatrix}$。\n$I(s^*, b^*)$ 的行列式为：\n$$\\det(I) = \\left(\\frac{1}{n}\\right)\\left(\\frac{1}{n} + \\frac{1}{\\sigma^2}\\right) - \\left(\\frac{1}{n}\\right)\\left(\\frac{1}{n}\\right) = \\frac{1}{n^2} + \\frac{1}{n\\sigma^2} - \\frac{1}{n^2} = \\frac{1}{n\\sigma^2}$$\n现在我们计算逆矩阵 $C$：\n$$C = [I(s^*, b^*)]^{-1} = \\frac{1}{1/(n\\sigma^2)} \\begin{pmatrix} \\frac{1}{n} + \\frac{1}{\\sigma^2} & -\\frac{1}{n} \\\\ -\\frac{1}{n} & \\frac{1}{n} \\end{pmatrix} = n\\sigma^2 \\begin{pmatrix} \\frac{\\sigma^2+n}{n\\sigma^2} & -\\frac{1}{n} \\\\ -\\frac{1}{n} & \\frac{1}{n} \\end{pmatrix}$$\n$$C = \\begin{pmatrix} n\\sigma^2 \\left(\\frac{\\sigma^2+n}{n\\sigma^2}\\right) & n\\sigma^2 \\left(-\\frac{1}{n}\\right) \\\\ n\\sigma^2 \\left(-\\frac{1}{n}\\right) & n\\sigma^2 \\left(\\frac{1}{n}\\right) \\end{pmatrix} = \\begin{pmatrix} n+\\sigma^2 & -\\sigma^2 \\\\ -\\sigma^2 & \\sigma^2 \\end{pmatrix}$$\n协方差矩阵 $C$ 包含估计量的方差和协方差：\n$$C = \\begin{pmatrix} \\operatorname{Var}(s^*) & \\operatorname{Cov}(s^*, b^*) \\\\ \\operatorname{Cov}(b^*, s^*) & \\operatorname{Var}(b^*) \\end{pmatrix}$$\n所以，我们有：\n$\\operatorname{Var}(s^*) = n+\\sigma^2$\n$\\operatorname{Cov}(s^*, b^*) = \\operatorname{Cov}(b^*, s^*) = -\\sigma^2$\n$\\operatorname{Var}(b^*) = \\sigma^2$\n\n给定 $n=35$ 和 $\\sigma=6$，所以 $\\sigma^2=36$。代入这些值：\n$\\operatorname{Var}(s^*) = 35 + 36 = 71$\n$\\operatorname{Cov}(s^*, b^*) = -36$\n$\\operatorname{Var}(b^*) = 36$\n\n要求以单行矩阵报告的六个值是 $s^{\\ast}$、$b^{\\ast}$、$\\operatorname{Var}(s^{\\ast})$、$\\operatorname{Cov}(s^{\\ast}, b^{\\ast})$、$\\operatorname{Cov}(b^{\\ast}, s^{\\ast})$ 和 $\\operatorname{Var}(b^{\\ast})$。\n这些值为：\n$s^* = 7$\n$b^* = 28$\n$\\operatorname{Var}(s^*) = 71$\n$\\operatorname{Cov}(s^*, b^*) = -36$\n$\\operatorname{Cov}(b^*, s^*) = -36$\n$\\operatorname{Var}(b^*) = 36$\n这些将以指定格式呈现。", "answer": "$$\n\\boxed{\\begin{pmatrix} 7 & 28 & 71 & -36 & -36 & 36 \\end{pmatrix}}\n$$", "id": "3506272"}, {"introduction": "上一个练习处理的是简单的事件计数，但通常情况下，每个事件都带有一系列可区分信号与背景的特征。本练习将你的技能从分箱计数提升到更强大的“非分箱”分析，通过推导费雪信息（Fisher Information）来量化一个实验的统计精度 [@problem_id:3506307]。理解费雪信息是计算最大似然估计量不确定性的理论基础，也是评估实验设计优劣的关键。", "problem": "一项高能物理分析将重建事件的数量和特征建模为两个独立的泊松点过程的叠加：一个期望产额为 $s$ 的信号组分和一个期望产额为 $b$ 的本底组分。感兴趣的参数是信号强度修正因子 $\\mu \\ge 0$，它将期望信号产额缩放为 $\\mu s$。每个事件带有一个实值可观测量 $x \\in \\mathbb{R}$，信号和本底分别具有概率密度函数 (PDF) $f_s(x)$ 和 $f_b(x)$，其中 $f_s$ 和 $f_b$ 在 $\\mathbb{R}$ 上均归一化为 $1$。观测数据是 $n$ 个事件，其值为 $\\{x_i\\}_{i=1}^{n}$。\n\n从独立的泊松点过程叠加的扩展非分箱似然的定义出发，推导 $\\mu$ 的对数似然、得分函数以及观测到的费雪信息 (FI) $J(\\mu)$。然后通过对叠加点过程所诱导的泊松计数和事件特征的联合分布进行平均，计算期望的费雪信息 $I(\\mu)$。最后，将问题特殊化到对所有 $x$ 都有 $f_s(x) = f_b(x)$ 的情况，并推导最大似然估计 (MLE) $\\hat{\\mu}$ 的渐近方差的闭合形式表达式，该方差由在真实信号强度 $\\mu_0$ 处评估的期望费雪信息的倒数给出。\n\n假设与定义：\n- 对于总强度密度为 $\\Lambda_{\\mu}(x) = \\mu s f_s(x) + b f_b(x)$ 的 $\\mathbb{R}$ 上的泊松点过程，其扩展非分箱似然由 $L(\\mu) \\propto \\exp(-\\nu(\\mu)) \\prod_{i=1}^{n} \\Lambda_{\\mu}(x_i)$ 给出，其中 $\\nu(\\mu) = \\int_{\\mathbb{R}} \\Lambda_{\\mu}(x) \\,\\mathrm{d}x = \\mu s + b$。\n- 观测到的费雪信息是在观测数据上评估的 $J(\\mu) = -\\frac{\\partial^2}{\\partial \\mu^2} \\ln L(\\mu)$。\n- 期望的费雪信息是 $I(\\mu) = \\mathbb{E}[J(\\mu)]$，其中期望是在参数为 $\\mu$ 的真实过程下计算的。\n- 对于任何可积函数 $h$，您可以引用泊松点过程的基本恒等式 $\\mathbb{E}\\left[\\sum_{i=1}^{n} h(x_i)\\right] = \\int_{\\mathbb{R}} \\Lambda_{\\mu}(x) h(x)\\,\\mathrm{d}x$。\n- 将 $s>0$ 和 $b>0$ 视为已知常数，并将 $f_s$ 和 $f_b$ 视为已知的归一化 PDF。参数 $\\mu$ 是实值且无量纲的。\n\n在 $f_s(x) = f_b(x)$ 的特殊情况下，以 $\\mu_0$、$s$ 和 $b$ 表示渐近方差 $\\mathrm{Var}(\\hat{\\mu})$，并提供一个单一的闭合形式表达式作为最终答案。无需单位。不要四舍五入。", "solution": "该问题要求为一个扩展非分箱似然模型推导几个统计量，然后在一个特殊情况下计算信号强度修正因子 $\\mu$ 的最大似然估计 (MLE) 的渐近方差。\n\n独立的泊松点过程叠加的似然函数给出为 $L(\\mu) \\propto \\exp(-\\nu(\\mu)) \\prod_{i=1}^{n} \\Lambda_{\\mu}(x_i)$，其中 $n$ 是观测到的事件数。\n总期望产额为 $\\nu(\\mu) = \\int_{\\mathbb{R}} \\Lambda_{\\mu}(x) \\,\\mathrm{d}x = \\mu s + b$。\n强度密度为 $\\Lambda_{\\mu}(x) = \\mu s f_s(x) + b f_b(x)$，其中 $s > 0$ 和 $b > 0$ 是已知常数，$f_s(x)$ 和 $f_b(x)$ 是已知的归一化概率密度函数 (PDF)。观测数据由 $n$ 个事件特征值 $\\{x_i\\}_{i=1}^{n}$ 组成。\n\n首先，我们推导对数似然函数 $\\ell(\\mu) = \\ln L(\\mu)$。忽略相对于 $\\mu$ 为常数的项，我们有：\n$$\n\\ell(\\mu) = -\\nu(\\mu) + \\sum_{i=1}^{n} \\ln(\\Lambda_{\\mu}(x_i))\n$$\n$$\n\\ell(\\mu) = -(\\mu s + b) + \\sum_{i=1}^{n} \\ln(\\mu s f_s(x_i) + b f_b(x_i))\n$$\n由于项 $-b$ 与 $\\mu$ 无关，它对关于 $\\mu$ 的导数没有贡献，因此为了找到 MLE 和费雪信息可以将其省略。\n$$\n\\ell(\\mu) = -\\mu s + \\sum_{i=1}^{n} \\ln(\\mu s f_s(x_i) + b f_b(x_i))\n$$\n接下来，我们推导得分函数，即对数似然函数关于参数 $\\mu$ 的一阶导数：\n$$\nS(\\mu) = \\frac{\\partial \\ell(\\mu)}{\\partial \\mu} = \\frac{\\partial}{\\partial \\mu} \\left( -\\mu s + \\sum_{i=1}^{n} \\ln(\\mu s f_s(x_i) + b f_b(x_i)) \\right)\n$$\n$$\nS(\\mu) = -s + \\sum_{i=1}^{n} \\frac{1}{\\mu s f_s(x_i) + b f_b(x_i)} \\cdot \\frac{\\partial}{\\partial \\mu}(\\mu s f_s(x_i) + b f_b(x_i))\n$$\n$$\nS(\\mu) = -s + \\sum_{i=1}^{n} \\frac{s f_s(x_i)}{\\mu s f_s(x_i) + b f_b(x_i)}\n$$\n观测到的费雪信息 $J(\\mu)$ 定义为对数似然函数的二阶导数的负数：$J(\\mu) = -\\frac{\\partial^2 \\ell(\\mu)}{\\partial \\mu^2}$。我们通过对得分函数求导来计算它：\n$$\n\\frac{\\partial S(\\mu)}{\\partial \\mu} = \\frac{\\partial}{\\partial \\mu} \\left( -s + \\sum_{i=1}^{n} \\frac{s f_s(x_i)}{\\mu s f_s(x_i) + b f_b(x_i)} \\right)\n$$\n$$\n\\frac{\\partial S(\\mu)}{\\partial \\mu} = \\sum_{i=1}^{n} s f_s(x_i) \\left( -1 \\cdot (\\mu s f_s(x_i) + b f_b(x_i))^{-2} \\cdot \\frac{\\partial}{\\partial \\mu}(\\mu s f_s(x_i) + b f_b(x_i)) \\right)\n$$\n$$\n\\frac{\\partial S(\\mu)}{\\partial \\mu} = \\sum_{i=1}^{n} s f_s(x_i) \\left( - \\frac{s f_s(x_i)}{(\\mu s f_s(x_i) + b f_b(x_i))^2} \\right) = - \\sum_{i=1}^{n} \\frac{s^2 f_s(x_i)^2}{(\\mu s f_s(x_i) + b f_b(x_i))^2}\n$$\n因此，观测到的费雪信息是：\n$$\nJ(\\mu) = -\\frac{\\partial^2 \\ell(\\mu)}{\\partial \\mu^2} = \\sum_{i=1}^{n} \\frac{s^2 f_s(x_i)^2}{(\\mu s f_s(x_i) + b f_b(x_i))^2}\n$$\n期望的费雪信息 $I(\\mu)$ 是 $J(\\mu)$ 在由参数值为 $\\mu$ 的模型定义的数据分布上的期望。问题提供了恒等式 $\\mathbb{E}\\left[\\sum_{i=1}^{n} h(x_i)\\right] = \\int_{\\mathbb{R}} \\Lambda_{\\mu}(x) h(x) \\, \\mathrm{d}x$。令 $h(x) = \\frac{s^2 f_s(x)^2}{(\\mu s f_s(x) + b f_b(x))^2}$。那么：\n$$\nI(\\mu) = \\mathbb{E}[J(\\mu)] = \\int_{\\mathbb{R}} \\Lambda_{\\mu}(x) h(x) \\, \\mathrm{d}x = \\int_{\\mathbb{R}} (\\mu s f_s(x) + b f_b(x)) \\frac{s^2 f_s(x)^2}{(\\mu s f_s(x) + b f_b(x))^2} \\, \\mathrm{d}x\n$$\n$$\nI(\\mu) = \\int_{\\mathbb{R}} \\frac{s^2 f_s(x)^2}{\\mu s f_s(x) + b f_b(x)} \\, \\mathrm{d}x\n$$\n这是 $\\mu$ 的期望费雪信息的一般表达式。\n\n现在，我们特殊化到信号和本底 PDF 相同的情况，即对所有 $x$ 都有 $f_s(x) = f_b(x)$。我们将这个共同的 PDF 称为 $f(x)$。将此代入 $I(\\mu)$ 的表达式中：\n$$\nI(\\mu) = \\int_{\\mathbb{R}} \\frac{s^2 f(x)^2}{\\mu s f(x) + b f(x)} \\, \\mathrm{d}x\n$$\n从分母中提出因子 $f(x)$：\n$$\nI(\\mu) = \\int_{\\mathbb{R}} \\frac{s^2 f(x)^2}{(\\mu s + b)f(x)} \\, \\mathrm{d}x = \\int_{\\mathbb{R}} \\frac{s^2 f(x)}{\\mu s + b} \\, \\mathrm{d}x\n$$\n项 $\\frac{s^2}{\\mu s + b}$ 相对于积分变量 $x$ 是常数，所以可以从积分中提出来：\n$$\nI(\\mu) = \\frac{s^2}{\\mu s + b} \\int_{\\mathbb{R}} f(x) \\, \\mathrm{d}x\n$$\n由于 $f(x)$ 是一个归一化的 PDF，$\\int_{\\mathbb{R}} f(x) \\, \\mathrm{d}x = 1$。这为这种特殊情况下的期望费雪信息提供了一个简化的表达式：\n$$\nI(\\mu) = \\frac{s^2}{\\mu s + b}\n$$\nMLE $\\hat{\\mu}$ 的渐近方差由在参数真值 $\\mu_0$ 处评估的期望费雪信息的倒数给出。这就是克拉默-拉奥下界。\n$$\n\\mathrm{Var}(\\hat{\\mu}) = [I(\\mu_0)]^{-1}\n$$\n代入在 $\\mu_0$ 处评估的 $I(\\mu)$ 表达式：\n$$\nI(\\mu_0) = \\frac{s^2}{\\mu_0 s + b}\n$$\n因此，渐近方差为：\n$$\n\\mathrm{Var}(\\hat{\\mu}) = \\left( \\frac{s^2}{\\mu_0 s + b} \\right)^{-1} = \\frac{\\mu_0 s + b}{s^2}\n$$\n这就是在指定条件下 $\\hat{\\mu}$ 的渐近方差的最终闭合形式表达式。", "answer": "$$\\boxed{\\frac{\\mu_0 s + b}{s^2}}$$", "id": "3506307"}, {"introduction": "当新物理信号的探索没有发现显著证据时，一个关键的结果是为该信号的强度设定一个上限。这个计算练习将带你进入高能物理统计实践的前沿，要求你同时实现频率论的 $\\text{CL}_s$ 方法和贝叶斯方法来设定上限 [@problem_id:3506302]。通过这个直接比较，你将深入理解这两种统计思想在处理讨厌参数（nuisance parameters）和解释结果时的根本差异。", "problem": "考虑一个在计算高能物理中典型的单箱计数实验。观测到的计数 $n$ 被建模为一个均值为 $\\mu_s + \\mu_b$ 的泊松随机变量，其中 $\\mu_s \\ge 0$ 是未知的信号强度，而 $\\mu_b > 0$ 是一个服从非高斯先验不确定性的本底贡献。讨厌参数 $\\mu_b$ 服从对数正态先验，其由对数的正态分布指定，即 $\\log \\mu_b \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$。\n\n从第一性原理出发：\n- 泊松概率质量函数为 $P(N=n \\mid \\lambda) = \\exp(-\\lambda) \\lambda^n / n!$，对于整数 $n \\ge 0$ 和率 $\\lambda > 0$。\n- 贝叶斯定理指出 $p(\\mu_s \\mid n) \\propto p(n \\mid \\mu_s) \\, \\pi(\\mu_s)$，其中 $p(n \\mid \\mu_s) = \\int P(N=n \\mid \\mu_s + \\mu_b) \\, \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b$，而 $\\pi(\\mu_s)$、$\\pi(\\mu_b)$ 是先验。\n- $\\mu_b$ 的对数正态先验由 $t=\\log \\mu_b$ 的正态密度定义，其均值为 $\\mu_t$，标准差为 $\\sigma_t$，即 $\\phi(t; \\mu_t, \\sigma_t) = \\frac{1}{\\sqrt{2\\pi}\\sigma_t} \\exp\\left( -\\frac{(t-\\mu_t)^2}{2\\sigma_t^2} \\right)$。\n\n将置信水平 (CL) 度量 $\\text{CL}_s$ 定义为在水平 $\\alpha$ 下对 $\\mu_s$ 上限的比率\n$$\n\\text{CL}_s(\\mu_s; n) = \\frac{p_{\\text{sb}}(n; \\mu_s)}{p_{\\text{b}}(n)},\n$$\n其中 $p_{\\text{sb}}(n; \\mu_s)$ 是信号加本底假设下的单侧向下尾部概率，$p_{\\text{b}}(n)$ 是相应的仅本底假设下的尾部概率：\n$$\np_{\\text{sb}}(n; \\mu_s) = \\int \\left[ \\sum_{k=0}^{n} \\exp\\left( -(\\mu_s+\\mu_b) \\right) \\frac{(\\mu_s+\\mu_b)^k}{k!} \\right] \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b,\n$$\n$$\np_{\\text{b}}(n) = \\int \\left[ \\sum_{k=0}^{n} \\exp\\left( -\\mu_b \\right) \\frac{\\mu_b^k}{k!} \\right] \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b.\n$$\n上限 $\\mu_s^{95}$ 被定义为满足 $\\text{CL}_s(\\mu_s; n) \\le \\alpha$ 的最小 $\\mu_s$，其中 $\\alpha$ 是固定的（对于本问题，取 $\\alpha = 0.05$）。\n\n对于贝叶斯分析，对信号采用不当的无信息先验 $\\pi(\\mu_s) \\propto 1$ (在 $\\mu_s \\ge 0$上)，对讨厌参数 $\\mu_b$ 采用上述的对数正态先验。后验 $p(\\mu_s \\mid n)$ 与通过积分掉 $\\mu_b$ 得到的边际似然 $p(n \\mid \\mu_s)$ 成正比。$\\mu_s$ 的等尾 $(1-\\alpha)$ 贝叶斯可信区间为 $[\\mu_{s,\\text{lo}}, \\mu_{s,\\text{hi}}]$，满足\n$$\n\\int_{0}^{\\mu_{s,\\text{lo}}} p(\\mu_s \\mid n) \\, \\mathrm{d}\\mu_s = \\frac{\\alpha}{2}, \\quad \\int_{0}^{\\mu_{s,\\text{hi}}} p(\\mu_s \\mid n) \\, \\mathrm{d}\\mu_s = 1 - \\frac{\\alpha}{2}.\n$$\n需要报告的区间长度为 $\\mu_{s,\\text{hi}} - \\mu_{s,\\text{lo}}$。\n\n实现一个程序，对于每个测试用例，计算：\n1. $\\text{CL}_s$ $95\\%$ 上限 $\\mu_s^{95}$（无单位），定义为使得 $\\text{CL}_s(\\mu_s; n) \\le 0.05$ 的最小 $\\mu_s$，使用上述的向下尾部定义。\n2. $\\mu_s$ 的 $(1-0.05)=0.95$ 等尾贝叶斯可信区间的长度 $\\mu_{s,\\text{hi}} - \\mu_{s,\\text{lo}}$（无单位）。\n\n所有量都是无量纲的；不需要物理单位。不涉及角度。将区间概率表示为 $[0,1]$ 内的小数。\n\n您的实现必须源自上述定义，使用通过 $\\log \\mu_b \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$ 对 $\\mu_b$ 的对数正态先验参数化。程序不应依赖任何未从这些定义中推导出的封闭形式的快捷公式；它必须基于严谨的推导和数值稳健的算法。\n\n测试套件参数集：\n- 情况 1：$n=0$, $\\mu_t=\\ln(2)$, $\\sigma_t=0.6$。\n- 情况 2：$n=3$, $\\mu_t=\\ln(1)$, $\\sigma_t=1.0$。\n- 情况 3：$n=7$, $\\mu_t=\\ln(5)$, $\\sigma_t=0.3$。\n- 情况 4：$n=10$, $\\mu_t=\\ln(2)$, $\\sigma_t=0.8$。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，并且本身是一个双元素列表 $[\\mu_s^{95}, \\ell]$，其中 $\\ell = \\mu_{s,\\text{hi}} - \\mu_{s,\\text{lo}}$。例如，一个有效的输出行格式为 $[[x_1,y_1],[x_2,y_2],[x_3,y_3],[x_4,y_4]]$。", "solution": "用户提供的问题陈述已经过仔细验证。\n\n### 步骤 1：提取已知信息\n- **模型**：单箱计数实验。\n- **观测值**：一个整数计数 $n \\ge 0$。\n- **似然**：计数 $n$ 是一个泊松随机变量，$N \\sim \\text{Poisson}(\\lambda)$，其概率质量函数为 $P(N=n \\mid \\lambda) = \\exp(-\\lambda) \\lambda^n / n!$。率为 $\\lambda = \\mu_s + \\mu_b$。\n- **信号参数**：$\\mu_s \\ge 0$ 是未知的信号强度。\n- **讨厌参数**：$\\mu_b > 0$ 是本底贡献。\n- **$\\mu_b$ 的先验**：$\\mu_b$ 服从对数正态先验，由 $\\log \\mu_b \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$ 指定。对于 $t = \\log \\mu_b$ 的密度为 $\\phi(t; \\mu_t, \\sigma_t) = \\frac{1}{\\sqrt{2\\pi}\\sigma_t} \\exp\\left( -\\frac{(t-\\mu_t)^2}{2\\sigma_t^2} \\right)$。\n- **频率学派度量**：$\\text{CL}_s(\\mu_s; n) = \\frac{p_{\\text{sb}}(n; \\mu_s)}{p_{\\text{b}}(n)}$。\n  - $p_{\\text{sb}}(n; \\mu_s) = \\int \\left[ \\sum_{k=0}^{n} \\exp\\left( -(\\mu_s+\\mu_b) \\right) \\frac{(\\mu_s+\\mu_b)^k}{k!} \\right] \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b$。\n  - $p_{\\text{b}}(n) = \\int \\left[ \\sum_{k=0}^{n} \\exp\\left( -\\mu_b \\right) \\frac{\\mu_b^k}{k!} \\right] \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b$。\n- **频率学派上限**：$95\\%$ 的上限 $\\mu_s^{95}$ 是使 $\\text{CL}_s(\\mu_s; n) \\le \\alpha$ 的最小 $\\mu_s$，其中 $\\alpha = 0.05$。\n- **$\\mu_s$ 的贝叶斯先验**：对于 $\\mu_s \\ge 0$ 的不当无信息先验 $\\pi(\\mu_s) \\propto 1$。\n- **贝叶斯可信区间**：$\\mu_s$ 的等尾 $(1-\\alpha)$ 可信区间 $[\\mu_{s,\\text{lo}}, \\mu_{s,\\text{hi}}]$ 由 $\\int_{0}^{\\mu_{s,\\text{lo}}} p(\\mu_s \\mid n) \\, \\mathrm{d}\\mu_s = \\alpha/2$ 和 $\\int_{0}^{\\mu_{s,\\text{hi}}} p(\\mu_s \\mid n) \\, \\mathrm{d}\\mu_s = 1 - \\alpha/2$ 定义，其中 $\\alpha=0.05$。\n- **要求的贝叶斯输出**：区间的长度 $\\mu_{s,\\text{hi}} - \\mu_{s,\\text{lo}}$。\n- **测试用例**：\n  1. $n=0$, $\\mu_t=\\ln(2)$, $\\sigma_t=0.6$。\n  2. $n=3$, $\\mu_t=\\ln(1)$, $\\sigma_t=1.0$。\n  3. $n=7$, $\\mu_t=\\ln(5)$, $\\sigma_t=0.3$。\n  4. $n=10$, $\\mu_t=\\ln(2)$, $\\sigma_t=0.8$。\n\n### 步骤 2：使用提取的已知信息进行验证\n- **科学基础**：该问题是高能物理中统计推断的一个典型范例，采用了标准的泊松模型、针对系统不确定性的对数正态先验，以及公认的频率学派 ($\\text{CL}_s$) 和贝叶斯方法论。其前提在事实上是健全的，并植根于概率论。\n- **问题定义良好**：问题提供了所有必要的定义、数据和约束，以确定每个测试用例的唯一解。\n- **客观性**：问题使用精确、无歧义的数学和统计语言陈述。\n\n该问题没有表现出任何无效性缺陷。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。将构建一个有原则的解决方案。\n\n### 解决方案推导\n\n该问题要求计算频率学派的上限和贝叶斯可信区间的长度。这两种计算都依赖于对讨厌参数 $\\mu_b$ 进行平均，该参数具有对数正态先验分布。\n\n**1. 频率学派 $\\text{CL}_s$ 上限计算**\n\n核心量是 $\\text{CL}_s(\\mu_s; n) = p_{\\text{sb}}(n; \\mu_s) / p_{\\text{b}}(n)$。项 $p_{\\text{sb}}$ 和 $p_{\\text{b}}$ 定义为积分。方括号内的表达式是泊松分布的累积分布函数 (CDF)，$F_{\\text{Poisson}}(n; \\lambda) = \\sum_{k=0}^{n} e^{-\\lambda} \\lambda^k / k!$。\n因此，我们有：\n$$\np_{\\text{sb}}(n; \\mu_s) = \\int_0^\\infty F_{\\text{Poisson}}(n; \\mu_s + \\mu_b) \\, \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b\n$$\n$$\np_{\\text{b}}(n) = \\int_0^\\infty F_{\\text{Poisson}}(n; \\mu_b) \\, \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b\n$$\n$\\mu_b$ 的先验是对数正态的，意味着 $t = \\log \\mu_b$ 是正态分布，均值为 $\\mu_t$，方差为 $\\sigma_t^2$。$t$ 的概率密度为 $\\phi(t; \\mu_t, \\sigma_t)$。为了计算这些积分，我们将积分变量从 $\\mu_b$ 更改为 $t = \\log\\mu_b$。这得到 $\\mu_b = e^t$ 和 $\\mathrm{d}\\mu_b = e^t \\, \\mathrm{d}t$。$\\mu_b$ 的先验密度为 $\\pi(\\mu_b) = \\phi(\\log \\mu_b; \\mu_t, \\sigma_t) / \\mu_b$。积分变为：\n$$\np_{\\text{sb}}(n; \\mu_s) = \\int_{-\\infty}^\\infty F_{\\text{Poisson}}(n; \\mu_s + e^t) \\, \\phi(t; \\mu_t, \\sigma_t) \\, \\mathrm{d}t\n$$\n这些对高斯核的积分非常适合使用高斯-埃尔米特求积法。我们进行一次替换以匹配标准的高斯-埃尔米特权重函数 $e^{-x^2}$。令 $x = (t - \\mu_t) / (\\sqrt{2}\\sigma_t)$，因此 $t = \\sqrt{2}\\sigma_t x + \\mu_t$ 且 $\\phi(t; \\mu_t, \\sigma_t) \\, \\mathrm{d}t = \\frac{1}{\\sqrt{\\pi}} e^{-x^2} \\, \\mathrm{d}x$。$p_{\\text{sb}}$ 的积分（$p_{\\text{b}}$ 也类似）变为：\n$$\np_{\\text{sb}}(n; \\mu_s) = \\frac{1}{\\sqrt{\\pi}} \\int_{-\\infty}^\\infty F_{\\text{Poisson}}(n; \\mu_s + e^{\\sqrt{2}\\sigma_t x + \\mu_t}) \\, e^{-x^2} \\, \\mathrm{d}x\n$$\n这可以通过求积和来近似：\n$$\np_{\\text{sb}}(n; \\mu_s) \\approx \\frac{1}{\\sqrt{\\pi}} \\sum_{i=1}^{N_{GH}} w_i F_{\\text{Poisson}}(n; \\mu_s + e^{\\sqrt{2}\\sigma_t x_i + \\mu_t})\n$$\n其中 $x_i$ 和 $w_i$ 是 $N_{GH}$ 阶高斯-埃尔米特求积的节点和权重。因子 $1/\\sqrt{\\pi}$ 在 $\\text{CL}_s$ 比率中被抵消，简化了计算。\n\n上限 $\\mu_s^{95}$ 是方程 $\\text{CL}_s(\\mu_s; n) - 0.05 = 0$ 的根。函数 $\\text{CL}_s(\\mu_s; n)$ 在 $\\mu_s$ 上是单调递减的，确保了唯一的根，可以使用像 Brent 方法这样的数值求解器高效地找到。\n\n**2. 贝叶斯可信区间计算**\n\n$\\mu_s$ 的后验概率密度由贝叶斯定理给出：$p(\\mu_s \\mid n) \\propto p(n \\mid \\mu_s) \\pi(\\mu_s)$。对于 $\\mu_s \\ge 0$ 的平坦先验 $\\pi(\\mu_s) \\propto 1$，后验与边际似然成正比，$p(\\mu_s \\mid n) \\propto p(n \\mid \\mu_s)$。边际似然通过对讨厌参数 $\\mu_b$ 积分得到：\n$$\np(n \\mid \\mu_s) = \\int_0^\\infty P(N=n \\mid \\mu_s + \\mu_b) \\, \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b\n$$\n后验累积分布函数 (CDF) 是 $C(\\mu_s) = \\int_0^{\\mu_s} p(\\mu_s' \\mid n) \\, \\mathrm{d}\\mu_s'$。要计算这个，我们通常会面临一个具有挑战性的双重积分。然而，通过交换积分顺序，我们发现了一个显著的简化：\n$$\n\\int_0^{\\mu_s} p(n \\mid \\mu_s') \\, \\mathrm{d}\\mu_s' = \\int_0^\\infty \\pi(\\mu_b) \\left( \\int_0^{\\mu_s} P(N=n \\mid \\mu_s' + \\mu_b) \\, \\mathrm{d}\\mu_s' \\right) \\mathrm{d}\\mu_b\n$$\n对 $\\mu_s'$ 的内部积分可以解析求解。令 $\\lambda' = \\mu_s'+\\mu_b$。积分为 $\\int_{\\mu_b}^{\\mu_s+\\mu_b} P(N=n \\mid \\lambda') \\, \\mathrm{d}\\lambda' = \\int_{\\mu_b}^{\\mu_s+\\mu_b} \\frac{(\\lambda')^n e^{-\\lambda'}}{n!} \\, \\mathrm{d}\\lambda'$。这等于 $F_{\\text{Poisson}}(n; \\mu_b) - F_{\\text{Poisson}}(n; \\mu_s + \\mu_b)$。将此代回得到：\n$$\n\\int_0^{\\mu_s} p(n \\mid \\mu_s') \\, \\mathrm{d}\\mu_s' = \\int_0^\\infty \\left[ F_{\\text{Poisson}}(n; \\mu_b) - F_{\\text{Poisson}}(n; \\mu_s + \\mu_b) \\right] \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b = p_{\\text{b}}(n) - p_{\\text{sb}}(n; \\mu_s)\n$$\n后验的归一化常数是积分到 $\\mu_s \\to \\infty$ 的值，此时 $p_{\\text{sb}} \\to 0$。因此，归一化常数是 $p_{\\text{b}}(n)$。所以后验 CDF 为：\n$$\nC(\\mu_s) = \\frac{p_{\\text{b}}(n) - p_{\\text{sb}}(n; \\mu_s)}{p_{\\text{b}}(n)} = 1 - \\text{CL}_s(\\mu_s; n)\n$$\n这个简洁的结果将贝叶斯后验 CDF 直接与频率学派的 $\\text{CL}_s$ 度量联系起来。等尾可信区间界 $[\\mu_{s,\\text{lo}}, \\mu_{s,\\text{hi}}]$ 通过求解以下方程找到：\n- $C(\\mu_{s,\\text{lo}}) = \\alpha/2 \\implies 1 - \\text{CL}_s(\\mu_{s,\\text{lo}}; n) = 0.025 \\implies \\text{CL}_s(\\mu_{s,\\text{lo}}; n) = 0.975$\n- $C(\\mu_{s,\\text{hi}}) = 1-\\alpha/2 \\implies 1 - \\text{CL}_s(\\mu_{s,\\text{hi}}; n) = 0.975 \\implies \\text{CL}_s(\\mu_{s,\\text{hi}}; n) = 0.025$\n\n用于找到 $\\mu_s^{95}$ 的相同数值机制可以用来找到 $\\mu_{s,\\text{lo}}$ 和 $\\mu_{s,\\text{hi}}$。\n\n**3. 特殊情况：$n=0$**\n\n对于观测计数为 $n=0$ 的情况，泊松 CDF 为 $F_{\\text{Poisson}}(0; \\lambda) = e^{-\\lambda}$。积分显著简化：\n- $p_{\\text{sb}}(0; \\mu_s) = \\int e^{-(\\mu_s+\\mu_b)} \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b = e^{-\\mu_s} \\int e^{-\\mu_b} \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b$\n- $p_{\\text{b}}(0) = \\int e^{-\\mu_b} \\pi(\\mu_b) \\, \\mathrm{d}\\mu_b$\n比率为 $\\text{CL}_s(\\mu_s; 0) = e^{-\\mu_s}$，这与本底先验无关。这使得测试用例 1 可以得到解析解：\n- $\\mu_s^{95}: e^{-\\mu_s} = 0.05 \\implies \\mu_s^{95} = -\\ln(0.05)$。\n- $\\mu_{s,\\text{lo}}: e^{-\\mu_s} = 0.975 \\implies \\mu_{s,\\text{lo}} = -\\ln(0.975)$。\n- $\\mu_{s,\\text{hi}}: e^{-\\mu_s} = 0.025 \\implies \\mu_{s,\\text{hi}} = -\\ln(0.025)$。\n区间长度为 $\\ell = \\mu_{s,\\text{hi}} - \\mu_{s,\\text{lo}} = -\\ln(0.025) + \\ln(0.975) = \\ln(0.975/0.025) = \\ln(39)$。\n\n实现将对 $n=0$ 使用这些解析形式，并对 $n>0$ 使用数值方法。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import poisson\nfrom scipy.special import roots_hermite\nfrom scipy.optimize import brentq\nimport math\n\n# Global constants for numerical precision and calculations\nN_GH = 64  # Degree of Gauss-Hermite quadrature\nNODES, WEIGHTS = roots_hermite(N_GH)\n\ndef calculate_cls(mu_s, n, mu_t, sigma_t):\n    \"\"\"\n    Calculates the CLs value for a given signal strength mu_s.\n    \n    The calculation is based on the ratio of two integrals, p_sb/p_b, which are\n    evaluated using Gauss-Hermite quadrature.\n    \"\"\"\n    # For n=0, CLs has a simple analytic form, exp(-mu_s), independent of the\n    # background prior. This avoids numerical integration and is exact.\n    if n == 0:\n        # mu_s must be non-negative.\n        if mu_s  0:\n            return 1.0 # By continuous extension as CLs(0)=1\n        return np.exp(-mu_s)\n\n    # Change of variables for Gauss-Hermite quadrature.\n    # The integration is over a standard normal variable 'x', which is related\n    # to t=log(mu_b) by t = sqrt(2)*sigma_t*x + mu_t.\n    t_values = math.sqrt(2) * sigma_t * NODES + mu_t\n    mu_b_values = np.exp(t_values)\n    \n    # Calculate Poisson CDF values for signal+background and background-only hypotheses\n    # at each quadrature node.\n    # poisson.cdf(k, mu) calculates sum_{i=0 to k} exp(-mu) * mu^i / i!\n    poisson_cdf_sb = poisson.cdf(n, mu_s + mu_b_values)\n    poisson_cdf_b = poisson.cdf(n, mu_b_values)\n\n    # The integrals for p_sb and p_b are approximated by the weighted sums.\n    # The factor 1/sqrt(pi) from the change of variables cancels in the ratio.\n    p_sb_integral_sum = np.sum(WEIGHTS * poisson_cdf_sb)\n    p_b_integral_sum = np.sum(WEIGHTS * poisson_cdf_b)\n    \n    # Handle the case where the denominator integral is numerically zero.\n    # This might occur if mu_b is very large, making the Poisson CDF vanish.\n    if p_b_integral_sum == 0.0:\n        return 0.0\n\n    return p_sb_integral_sum / p_b_integral_sum\n\ndef find_mu_s_for_cls_target(cls_target, n, mu_t, sigma_t):\n    \"\"\"\n    Finds the value of mu_s for which CLs(mu_s) equals a given target value.\n    This is achieved by finding the root of f(mu_s) = CLs(mu_s) - cls_target.\n    \"\"\"\n    \n    # Define the function whose root we want to find.\n    def root_func(mu_s):\n        return calculate_cls(mu_s, n, mu_t, sigma_t) - cls_target\n\n    # The CLs function is monotonic decreasing from 1 to 0.\n    # The root must be bracketed for the solver.\n    # root_func(0) = 1 - cls_target, which is > 0 for cls_target  1.\n    lower_bound = 0.0\n    upper_bound = 1.0 # Initial guess for the upper bracket boundary.\n    \n    # Expand the search interval until the root is bracketed.\n    # Failsafe limit to prevent infinite loops.\n    max_search_val = 1000.0\n    while root_func(upper_bound) > 0:\n        upper_bound *= 2.0\n        if upper_bound > max_search_val:\n            raise RuntimeError(f\"Failed to bracket root for CLs target {cls_target}\")\n    \n    # Use Brent's method to find the root with high precision.\n    return brentq(root_func, lower_bound, upper_bound)\n\ndef solve_case(n, mu_t, sigma_t):\n    \"\"\"\n    Computes the CLs 95% upper limit and the Bayesian 95% credible interval length\n    for a single test case.\n    \"\"\"\n    # 1. Compute the CLs 95% upper limit (mu_s^95).\n    # This is the value of mu_s where CLs(mu_s) = 0.05.\n    mu_s_95 = find_mu_s_for_cls_target(0.05, n, mu_t, sigma_t)\n\n    # 2. Compute the Bayesian 95% credible interval length.\n    # Due to the flat prior on mu_s, the posterior CDF C(mu_s) = 1 - CLs(mu_s).\n    # The 95% equal-tailed interval [lo, hi] is found by solving:\n    # C(lo) = 0.025 => CLs(lo) = 0.975\n    # C(hi) = 0.975 => CLs(hi) = 0.025\n    \n    mu_s_lo_bayes = find_mu_s_for_cls_target(0.975, n, mu_t, sigma_t)\n    mu_s_hi_bayes = find_mu_s_for_cls_target(0.025, n, mu_t, sigma_t)\n\n    interval_length = mu_s_hi_bayes - mu_s_lo_bayes\n    \n    return [mu_s_95, interval_length]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0, math.log(2), 0.6),\n        (3, math.log(1), 1.0),\n        (7, math.log(5), 0.3),\n        (10, math.log(2), 0.8),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, mu_t, sigma_t = case\n        result = solve_case(n, mu_t, sigma_t)\n        results.append(result)\n\n    # Format the output exactly as specified: [[x1,y1],[x2,y2],...]\n    formatted_results = [f\"[{r[0]},{r[1]}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3506302"}]}