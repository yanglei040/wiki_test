{"hands_on_practices": [{"introduction": "格点计算的原始输出通常是马尔可夫链蒙特卡洛（MCMC）生成的沿“时间”方向自相关的观测量序列。在进行连续谱外推之前，正确处理这些自相关性并可靠地估计统计误差是至关重要的。本练习 [@problem_id:3509811] 将指导你完成一个完整的统计分析流程：从未经处理的时间序列数据出发，估计积分自相关时间，通过分块（blocking）方法获得近似独立的样本均值，并最终使用块 bootstrap 方法将统计不确定性稳健地传递到连续谱极限的估计值中。", "problem": "您的任务是为一个在多个格距下测量的格点可观测量实现一个统计可靠的连续极限外推，同时要考虑时间序列数据中的自相关性。您编写的程序必须估计积分自相关时间，选择一个能够控制残余相关性的分块大小，并通过分块自助法（blocked bootstrap）程序将统计误差传播到连续极限的估计中。\n\n从以下基本原理开始：\n- 对于一个平稳时间序列，其均值为 $m$，方差为 $\\sigma^{2}$，在整数延迟 $t$ 处的归一化自相关函数为 $\\rho(t)$，那么 $N$ 个相关观测值的样本均值的方差会因积分自相关时间 $\\tau_{\\mathrm{int}}$ 而增大，其定义为\n$$\n\\tau_{\\mathrm{int}}=\\frac{1}{2}+\\sum_{t=1}^{\\infty}\\rho(t),\n$$\n且一个实用的估计量会用一个通过自洽规则选择的有限窗口 $W$ 来代替 $\\infty$。\n- 在 Symanzik 有效理论的假设下，对于一个适当改进的格点作用量和算符，许多可观测量的主要截断效应按 $\\mathcal{O}(a^{2})$ 标度，因此可以将对 $a$ 的依赖性建模为\n$$\n\\mathcal{O}(a)=\\mathcal{O}_{0}+c_{1}\\,a^{2},\n$$\n并通过对 $a^{2}$ 的线性拟合来确定连续极限 $\\mathcal{O}_{0}$。\n\n实现以下内容，所有量均为无量纲（不需要物理单位）：\n\n1) 时间序列生成。对于测试用例中的每个格距 $a$，生成一个确定性的一阶自回归过程 (AR(1))，其均值由 Symanzik 模型给出，新息（innovations）来自一个固定的线性同余生成器 (LCG) 生成的均匀分布。具体来说，对于给定的 $a$，定义目标均值\n$$\n\\mu(a)=\\mathcal{O}_{0}^{\\mathrm{true}}+c_{1}^{\\mathrm{true}}\\,a^{2},\n$$\n并令序列 $\\{X_{t}^{(a)}\\}_{t=1}^{N}$ 的 AR(1) 递归为\n$$\nX_{t+1}^{(a)}=\\mu(a)+\\phi(a)\\left(X_{t}^{(a)}-\\mu(a)\\right)+\\epsilon_{t}^{(a)},\n$$\n其中 $\\phi(a)=1-\\frac{1}{L_{\\mathrm{corr}}(a)}$，新息 $\\epsilon_{t}^{(a)}=\\sigma(a)\\left(2U_{t}^{(a)}-1\\right)$，而 $\\{U_{t}^{(a)}\\}$ 是来自 LCG 的确定性伪随机序列\n$$\ns_{t+1}=(\\alpha s_{t}+\\gamma)\\bmod M,\\quad U_{t}=\\frac{s_{t}}{M},\n$$\n其参数为 $M=2^{32}$, $\\alpha=1664525$, $\\gamma=1013904223$。对每个序列使用为其提供的特定于 $a$ 的整数种子 $s_{0}$。对每个时间序列，生成 $N_{\\mathrm{burn}}=50+10\\,L_{\\mathrm{corr}}(a)$ 个预烧（burn-in）步并丢弃，然后保留接下来的 $N$ 个点作为该 $a$ 的数据集。\n\n2) 积分自相关时间估计。对每个生成的时间序列，使用带自洽窗口选择的标准加窗估计量来估计积分自相关时间 $\\tau_{\\mathrm{int}}$。令 $\\bar{X}$ 为样本均值，$C(t)$ 为延迟 $t$ 处的无偏样本自协方差。定义归一化自相关为 $\\rho(t)=C(t)/C(0)$。对于选定的窗口大小 $W$，定义\n$$\n\\hat{\\tau}_{\\mathrm{int}}(W)=\\frac{1}{2}+\\sum_{t=1}^{W}\\rho(t).\n$$\n选择 $W$ 为满足 $W\\geq c\\,\\hat{\\tau}_{\\mathrm{int}}(W)$（其中 $c=6$）的最小延迟，且需满足 $W\\leq W_{\\max}=\\min\\{N-1,1000\\}$。如果在 $W_{\\max}$ 范围内不存在这样的 $W$，则设 $W=W_{\\max}$。报告估计值 $\\hat{\\tau}_{\\mathrm{int}}=\\max\\{\\frac{1}{2},\\hat{\\tau}_{\\mathrm{int}}(W)\\}$。\n\n3) 分块与分块自助法。对每个时间序列：\n- 选择一个整数块大小 $B_{\\mathrm{blk}}=\\max\\left\\{1,\\left\\lceil 2\\,\\hat{\\tau}_{\\mathrm{int}}\\right\\rceil\\right\\}$。\n- 将序列划分为 $M=\\left\\lfloor N/B_{\\mathrm{blk}}\\right\\rfloor$ 个长度为 $B_{\\mathrm{blk}}$ 的不重叠块，并计算这 $M$ 个块的均值。如果 $M=0$，则使用一个等于整体样本均值的单块。\n- 实现一个包含 $R$ 个自助法副本（bootstrap replicates）的分块自助法。在每个副本中，有放回地重采样 $M$ 个块，并取重采样后块均值的平均值，以获得在每个格距下的均值的一个自助法估计。使用与上面相同的固定 LCG 来生成自助法重采样的索引，副本和格距序列从一个指定的自助法种子开始连续生成。\n\n4) 连续极限外推。对于每个自助法副本，对给定 $a$ 值下的自助法均值 $\\{Y^{(a)}\\}$ 与模型\n$$\nY^{(a)}=\\mathcal{O}_{0}+c_{1}\\,a^{2},\n$$\n进行无权重的线性最小二乘拟合，并记录 $\\mathcal{O}_{0}$ 的自助法估计值。使用 $\\mathcal{O}_{0}$ 的自助法分布的样本均值作为点估计，使用样本标准差（分母为 $R-1$）作为标准误差。\n\n数值要求和测试套件：\n- 您必须为以下三个测试用例实现上述工作流程。下面所有数字都是精确的，必须按原样使用。\n\n测试用例 A:\n- 格距: $a\\in\\{0.12,0.09,0.06\\}$。\n- 序列长度: $N=512$。\n- 相关长度: $L_{\\mathrm{corr}}(a)\\in\\{12,24,48\\}$ 分别对应于 $a=0.12,0.09,0.06$。\n- 真实参数: $\\mathcal{O}_{0}^{\\mathrm{true}}=1.2345$, $c_{1}^{\\mathrm{true}}=2.75$。\n- 新息振幅: 对所有 $a$，$\\sigma(a)\\equiv 0.25$。\n- 新息种子: $s_{0}\\in\\{123456789,987654321,42424242\\}$ 分别对应于 $a=0.12,0.09,0.06$。\n- 自助法副本数: $R=499$。\n- 自助法种子: $s_{0}^{\\mathrm{boot}}=20250601$。\n\n测试用例 B:\n- 格距: $a\\in\\{0.10,0.07,0.05,0.04\\}$。\n- 序列长度: $N=384$。\n- 相关长度: $L_{\\mathrm{corr}}(a)\\in\\{8,16,24,32\\}$ 分别对应于 $a=0.10,0.07,0.05,0.04$。\n- 真实参数: $\\mathcal{O}_{0}^{\\mathrm{true}}=0.5$, $c_{1}^{\\mathrm{true}}=-1.2$。\n- 新息振幅: 对所有 $a$，$\\sigma(a)\\equiv 0.20$。\n- 新息种子: $s_{0}\\in\\{13579,24680,112233,998877\\}$ 分别对应于 $a=0.10,0.07,0.05,0.04$。\n- 自助法副本数: $R=399$。\n- 自助法种子: $s_{0}^{\\mathrm{boot}}=1357911$。\n\n测试用例 C:\n- 格距: $a\\in\\{0.16,0.08,0.04\\}$。\n- 序列长度: $N=256$。\n- 相关长度: $L_{\\mathrm{corr}}(a)\\in\\{2,4,6\\}$ 分别对应于 $a=0.16,0.08,0.04$。\n- 真实参数: $\\mathcal{O}_{0}^{\\mathrm{true}}=-0.2$, $c_{1}^{\\mathrm{true}}=0.8$。\n- 新息振幅: 对所有 $a$，$\\sigma(a)\\equiv 0.15$。\n- 新息种子: $s_{0}\\in\\{314159,271828,161803\\}$ 分别对应于 $a=0.16,0.08,0.04$。\n- 自助法副本数: $R=299$。\n- 自助法种子: $s_{0}^{\\mathrm{boot}}=424242$。\n\n实现规范和输出说明：\n- 对于自协方差估计，使用无偏估计量 $C(t)=\\frac{1}{N-t}\\sum_{i=1}^{N-t}(X_{i}-\\bar{X})(X_{i+t}-\\bar{X})$ 直到 $t=W_{\\max}$，并且在 $C(0)>0$ 时使用 $\\rho(t)=C(t)/C(0)$。如果 $C(0)\\leq 0$，则设 $\\hat{\\tau}_{\\mathrm{int}}=\\frac{1}{2}$。\n- 对于自洽窗口选择，使用 $c=6$ 和 $W_{\\max}=\\min\\{N-1,1000\\}$。\n- 对于分块，使用 $B_{\\mathrm{blk}}=\\max\\left\\{1,\\left\\lceil 2\\,\\hat{\\tau}_{\\mathrm{int}}\\right\\rceil\\right\\}$ 和 $M=\\left\\lfloor N/B_{\\mathrm{blk}}\\right\\rfloor$。如果 $M=0$，则使用一个其均值为样本均值的单块。\n- 对于分块自助法重采样，对每个副本，使用指定的 LCG 从 $\\{0,1,\\dots,M-1\\}$ 中独立均匀地抽取 $M$ 个索引，其状态初始化为给定的自助法种子，并在该测试用例内的所有抽样和格距中顺序推进。\n- 对于线性拟合，对每个自助法副本，执行 $Y$ 对 $a^{2}$ 的普通最小二乘拟合，以估计 $\\mathcal{O}_{0}$ 和 $c_{1}$。\n\n最终输出格式：\n- 对于每个测试用例，报告一个列表，其中包含：\n  1) 按给定 $a$ 的顺序排列的三个或四个 $\\hat{\\tau}_{\\mathrm{int}}$ 值，每个值四舍五入到 $6$ 位小数，\n  2) 对应的三个或四个整数块大小 $B_{\\mathrm{blk}}$，\n  3) 所有副本的 $\\mathcal{O}_{0}$ 的自助法均值，四舍五入到 $6$ 位小数，\n  4) 所有副本的 $\\mathcalO}_{0}$ 的自助法标准差，四舍五入到 $6$ 位小数。\n- 您的程序应生成单行输出，其中包含测试用例 A、测试用例 B 和测试用例 C 的结果，按此顺序排列，形式为一个由方括号括起来的逗号分隔列表，其中每个元素是上述的单个测试列表。例如，输出结构必须是\n$$\n[\\,[\\hat{\\tau}_{\\mathrm{int}}(a_{1}),\\dots,\\hat{\\tau}_{\\mathrm{int}}(a_{K}),B_{\\mathrm{blk}}(a_{1}),\\dots,B_{\\mathrm{blk}}(a_{K}),\\widehat{\\mathcal{O}}_{0},\\mathrm{SE}(\\widehat{\\mathcal{O}}_{0})],\\;[\\dots],\\;[\\dots]\\,].\n$$\n的所有四舍五入操作必须在打印前应用，并且每个数值条目都应是标准的十进制数字。", "solution": "用户提供的问题是计算物理学中一个全面且定义明确的练习，特别关注格点模拟数据的统计分析。任务是执行格点可观测量的连续极限外推，这涉及模拟相关数据，分析其自相关特性，并使用分块自助法将统计不确定性传播到最终的连续极限估计中。该问题在科学上基于统计力学、时间序列分析和用于格点离散化的 Symanzik 有效理论的原理。所有参数、算法和过程都以足够的精度指定，以确保一个唯一的、确定性的解。因此，该问题被认为是有效的，并将提供完整的解决方案。\n\n解决方案通过遵循一系列规定的步骤来实现：\n\n1.  **时间序列生成**：对于每个给定的格距 $a$，生成一个可观测量的合成时间序列。该序列被建模为一阶自回归 (AR(1)) 过程。该过程被构造成围绕一个均值 $\\mu(a)$ 波动，该均值本身根据 Symanzik 有效理论模型依赖于格距，即 $\\mu(a)=\\mathcal{O}_{0}^{\\mathrm{true}}+c_{1}^{\\mathrm{true}}\\,a^{2}$。AR(1) 递归由 $X_{t+1}^{(a)}=\\mu(a)+\\phi(a)\\left(X_{t}^{(a)}-\\mu(a)\\right)+\\epsilon_{t}^{(a)}$ 给出。参数 $\\phi(a)=1-1/L_{\\mathrm{corr}}(a)$ 控制序列的自相关时间，其中 $L_{\\mathrm{corr}}(a)$ 是给定的相关长度。新息 $\\epsilon_{t}^{(a)}$ 是由具有指定参数（$M=2^{32}$, $\\alpha=1664525$, $\\gamma=1013904223$）和种子的确定性线性同余生成器 (LCG) 生成的随机噪声项。每个序列的初始部分，即预烧期 $N_{\\mathrm{burn}}=50+10\\,L_{\\mathrm{corr}}(a)$，被丢弃以确保生成的数据代表过程的平稳状态。\n\n2.  **积分自相关时间估计**：对相关数据进行正确误差分析的关键是积分自相关时间 $\\tau_{\\mathrm{int}}$。对于每个生成的时间序列，我们使用加窗估计量来估计 $\\tau_{\\mathrm{int}}$。首先，计算从延迟 $t=0$ 到最大值 $W_{\\max}$ 的样本自协方差函数 $C(t)$。根据问题的规定，我们使用公式 $C(t)=\\frac{1}{N-t}\\sum_{i=1}^{N-t}(X_{i}-\\bar{X})(X_{i+t}-\\bar{X})$，其中 $\\bar{X}$ 是整个长度为 $N$ 的时间序列的均值。然后归一化自相关函数为 $\\rho(t)=C(t)/C(0)$。对于给定的窗口大小 $W$，估计的积分自相关时间为 $\\hat{\\tau}_{\\mathrm{int}}(W)=\\frac{1}{2}+\\sum_{t=1}^{W}\\rho(t)$。窗口大小 $W$ 通过自洽程序选择：它是满足条件 $W\\geq c\\,\\hat{\\tau}_{\\mathrm{int}}(W)$ 的最小整数延迟 $W$，其中指定常数 $c=6$。当 $\\rho(t)$ 中的噪声开始主导信号时，此过程会截断求和。如果在任何 $W \\leq W_{\\max}$ 内都不满足此条件，则使用 $W=W_{\\max}$。最终报告的估计值为 $\\hat{\\tau}_{\\mathrm{int}}=\\max\\{\\frac{1}{2},\\hat{\\tau}_{\\mathrm{int}}(W)\\}$。\n\n3.  **分块与分块自助法**：为处理自相关并传播统计误差，采用分块自助法。首先，将每个时间序列划分为不重叠的块。这些块的大小 $B_{\\mathrm{blk}}=\\max\\left\\{1,\\left\\lceil 2\\,\\hat{\\tau}_{\\mathrm{int}}\\right\\rceil\\right\\}$，被选择为大于自相关时间，以使块的均值在统计上近似独立。序列被划分为 $M=\\left\\lfloor N/B_{\\mathrm{blk}}\\right\\rfloor$ 个块，并计算每个块的均值。这样，对于每个格距 $a$，就产生了一个新的、短得多的包含 $M$ 个块均值的时间序列。\n    然后进行自助法分析。对于 $R$ 个自助法副本中的每一个，都会创建一个新的数据集。对于每个格距 $a$，从原始的 $M$ 个块均值集合中有放回地重采样 $M$ 个块均值。这些重采样块均值的平均值给出了在该格距下可观测量的一个自助法估计值 $Y^{(a)}$。对所有格距重复此过程，使用一个顺序推进的单个 LCG 实例，为一次自助法副本生成一套完整的 $\\{Y^{(a)}\\}$。\n\n4.  **连续极限外推**：对于 $R$ 个自助法副本中的每一个，估计连续极限 $\\mathcal{O}_{0}$。这是通过对模型 $Y^{(a)}=\\mathcal{O}_{0}+c_{1}\\,a^{2}$ 进行无权重线性最小二乘拟合来完成的，使用自助法均值 $Y^{(a)}$ 对相应 $a^2$ 的值进行拟合。此拟合的截距提供了一个 $\\mathcal{O}_{0}$ 的自助法估计。\n\n5.  **最终估计**：为 $\\mathcal{O}_{0}$ 生成 $R$ 个自助法估计后，就得到了一个自助法分布。连续极限值的最终点估计 $\\widehat{\\mathcal{O}}_{0}$ 是此分布的样本均值。相应的统计不确定性 $\\mathrm{SE}(\\widehat{\\mathcal{O}}_{0})$ 由该分布的样本标准差给出，使用 $R-1$ 作为分母。\n\n由于使用了为 LCG 指定的种子，整个过程是确定性的。每个测试用例的最终结果被收集起来，四舍五入到六位小数，并格式化为指定的嵌套列表结构。", "answer": "```python\nimport numpy as np\nimport math\n\nclass LCG:\n    \"\"\"A Linear Congruential Generator as specified in the problem.\"\"\"\n    def __init__(self, seed, M=2**32, alpha=1664525, gamma=1013904223):\n        self.state = seed\n        self.M = M\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def next_int(self):\n        \"\"\"Generates the next integer in the sequence.\"\"\"\n        self.state = (self.alpha * self.state + self.gamma) % self.M\n        return self.state\n\n    def next_float(self):\n        \"\"\"Generates the next float in [0, 1) in the sequence.\"\"\"\n        return self.next_int() / self.M\n\ndef generate_ar1_series(a, N, L_corr, O0_true, c1_true, sigma, seed):\n    \"\"\"Generates a single AR(1) time series.\"\"\"\n    rng = LCG(seed)\n    mu_a = O0_true + c1_true * a**2\n    phi_a = 1.0 - 1.0 / L_corr\n    N_burn = 50 + 10 * L_corr\n\n    # Initial value at the mean\n    x_t = mu_a\n\n    # Burn-in phase\n    for _ in range(N_burn):\n        u_t = rng.next_float()\n        epsilon_t = sigma * (2 * u_t - 1)\n        x_t = mu_a + phi_a * (x_t - mu_a) + epsilon_t\n\n    # Data generation phase\n    series = np.zeros(N)\n    for t in range(N):\n        u_t = rng.next_float()\n        epsilon_t = sigma * (2 * u_t - 1)\n        x_t = mu_a + phi_a * (x_t - mu_a) + epsilon_t\n        series[t] = x_t\n        \n    return series\n\ndef estimate_tau_int(series, c, W_max):\n    \"\"\"Estimates the integrated autocorrelation time with a self-consistent window.\"\"\"\n    N = len(series)\n    if N  2:\n        return 0.5\n        \n    mean = np.mean(series)\n    series_centered = series - mean\n\n    # Calculate C(0)\n    C0 = np.dot(series_centered, series_centered) / N\n    if C0 = 0:\n        return 0.5\n\n    tau_int_sum = 0.0\n    final_W = W_max\n    \n    for W in range(1, W_max + 1):\n        if W >= N:\n            final_W = W - 1\n            break\n        \n        # Calculate C(W)\n        CW = np.dot(series_centered[:-W], series_centered[W:]) / (N - W)\n        rho_W = CW / C0\n        tau_int_sum += rho_W\n        \n        tau_int_W = 0.5 + tau_int_sum\n        \n        if W >= c * tau_int_W:\n            final_W = W\n            break\n    \n    # Recalculate tau_int up to final_W if the loop finished\n    if W == W_max:\n        tau_int_W_final = 0.5 + tau_int_sum\n    else: # if loop broke early\n        tau_int_W_final = tau_int_W\n\n    return max(0.5, tau_int_W_final)\n\ndef solve_case(case_params):\n    \"\"\"\n    Processes a single test case from data generation to final result.\n    \"\"\"\n    a_s = np.array(case_params['a'])\n    N = case_params['N']\n    L_corrs = case_params['L_corr']\n    O0_true = case_params['O0_true']\n    c1_true = case_params['c1_true']\n    sigmas = case_params['sigma']\n    seeds = case_params['seeds']\n    R = case_params['R']\n    boot_seed = case_params['boot_seed']\n    \n    num_a = len(a_s)\n    \n    all_series = []\n    # Part 1: Generate time series for all lattice spacings\n    for i in range(num_a):\n        series = generate_ar1_series(a_s[i], N, L_corrs[i], O0_true, c1_true, sigmas[i], seeds[i])\n        all_series.append(series)\n\n    tau_ints = []\n    block_sizes = []\n    blocked_data = []\n\n    # Part 2  3: Estimate tau_int and create block means\n    for i in range(num_a):\n        series = all_series[i]\n        W_max = min(N - 1, 1000)\n        \n        tau = estimate_tau_int(series, c=6, W_max=W_max)\n        tau_ints.append(tau)\n        \n        B_blk = max(1, math.ceil(2 * tau))\n        block_sizes.append(B_blk)\n        \n        M = N // B_blk\n        if M == 0:\n            block_means = np.array([np.mean(series)])\n        else:\n            num_pts_to_use = M * B_blk\n            block_means = np.mean(series[:num_pts_to_use].reshape(M, B_blk), axis=1)\n        blocked_data.append(block_means)\n\n    # Part 3  4: Blocked bootstrap and continuum extrapolation\n    boot_rng = LCG(boot_seed)\n    O0_bootstrap_dist = []\n    a_squared = a_s**2\n\n    for _ in range(R):\n        boot_means_Y = []\n        for i in range(num_a):\n            blocks = blocked_data[i]\n            M_i = len(blocks)\n            indices = [int(boot_rng.next_float() * M_i) for _ in range(M_i)]\n            resampled_blocks = blocks[indices]\n            boot_mean = np.mean(resampled_blocks)\n            boot_means_Y.append(boot_mean)\n        \n        # OLS fit to Y = O0 + c1 * a^2\n        Y = np.array(boot_means_Y)\n        X = a_squared\n        \n        X_bar = np.mean(X)\n        Y_bar = np.mean(Y)\n        \n        # Handle case of vertical line (all a are same, not in this problem)\n        if np.sum((X - X_bar)**2) == 0:\n             c1_hat = 0\n        else:\n            c1_hat = np.sum((X - X_bar) * (Y - Y_bar)) / np.sum((X - X_bar)**2)\n        \n        O0_hat = Y_bar - c1_hat * X_bar\n        O0_bootstrap_dist.append(O0_hat)\n    \n    O0_bootstrap_dist = np.array(O0_bootstrap_dist)\n    final_O0_mean = np.mean(O0_bootstrap_dist)\n    final_O0_std_err = np.std(O0_bootstrap_dist, ddof=1)\n\n    # Assemble results\n    results = []\n    for tau in tau_ints:\n        results.append(f\"{tau:.6f}\")\n    for bs in block_sizes:\n        results.append(str(bs))\n    results.append(f\"{final_O0_mean:.6f}\")\n    results.append(f\"{final_O0_std_err:.6f}\")\n    \n    return results\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    test_cases_params = [\n        {\n            'a': [0.12, 0.09, 0.06], 'N': 512, 'L_corr': [12, 24, 48],\n            'O0_true': 1.2345, 'c1_true': 2.75, 'sigma': [0.25, 0.25, 0.25],\n            'seeds': [123456789, 987654321, 42424242], 'R': 499, 'boot_seed': 20250601\n        },\n        {\n            'a': [0.10, 0.07, 0.05, 0.04], 'N': 384, 'L_corr': [8, 16, 24, 32],\n            'O0_true': 0.5, 'c1_true': -1.2, 'sigma': [0.20, 0.20, 0.20, 0.20],\n            'seeds': [13579, 24680, 112233, 998877], 'R': 399, 'boot_seed': 1357911\n        },\n        {\n            'a': [0.16, 0.08, 0.04], 'N': 256, 'L_corr': [2, 4, 6],\n            'O0_true': -0.2, 'c1_true': 0.8, 'sigma': [0.15, 0.15, 0.15],\n            'seeds': [314159, 271828, 161803], 'R': 299, 'boot_seed': 424242\n        }\n    ]\n    \n    all_results = []\n    for params in test_cases_params:\n        case_result = solve_case(params)\n        all_results.append(f\"[{','.join(case_result)}]\")\n\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3509811"}, {"introduction": "拟合分析的可靠性不仅取决于其统计方法，更取决于其模型的有效性。一个看似完美的拟合如果建立在被低估的误差或不恰当的模型假设之上，其结果可能是误导性的。本练习 [@problem_id:3509857] 介绍了一种强大的模型检验技术——后验预测检验（Posterior Predictive Checks, PPCs），它能帮助我们判断观测数据是否“典型”，即是否与模型及其误差假设相符。你将学习如何通过PPC来诊断并修正一个在实际分析中常见的问题：输入统计误差被低估，从而确保你的外推结果的置信区间是可靠的。", "problem": "您将获得一个关于 Schwinger 模型（一维量子电动力学）中玻色子质量的合成格点数据集，该数据集的构造使得其连续谱值可从精确可解理论中得知。在无质量 Schwinger 模型中，玻色子质量为 $m = g / \\sqrt{\\pi}$，因此以耦合常数 $g$ 为单位的连续谱目标值为 $m/g = 1/\\sqrt{\\pi}$。在间距为 $a$ 的格点上，一个可观测量 $O(a)$ 通过离散化展开来逼近其连续谱极限 $O_0$，其中对于一个未经改进的局域算符，领头误差项通常是 $a^2$ 阶的，因此 $O(a) = O_0 + c_2 a^2 + \\text{更高阶项}$。在有限格点间距下的测量报告了统计误差，这些误差可能是准确的，也可能被低估了。您的任务是通过后验预测检验 (PPCs) 来检测并修正被低估的误差，并执行带有严格不确定度估计的连续谱外推。\n\n基本依据：\n- 当 $a \\to 0$ 时，格点间距 $a$ 趋向于连续谱极限。\n- 测量模型是加性的和高斯的：$y_i = O(a_i) + \\epsilon_i$，其中 $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma_{i,\\text{rep}}^2)$，而 $\\sigma_{i,\\text{rep}}$ 是第 $i$ 个数据点报告的标准差。\n- 对于未经改进的作用量，领头离散项是关于 $a$ 的二次方，因此 $O(a) = O_0 + c_2 a^2$ 是一个最小参数模型。\n- 在贝叶斯模型检验中，后验预测检验 (PPCs) 用于量化观测数据是否是后验预测分布的典型抽样。一个常见的 PPC 是中心可信带的覆盖率及其在名义覆盖水平下的相关二项分布尾部概率。\n- 如果报告的误差被低估，一个实用的修正方法是用一个内在散射项 $\\sigma_{\\text{int}}^2$ 来增广每个方差，使得后验预测覆盖率与名义水平在统计上保持一致。\n\n您的程序必须对测试套件中的每个案例执行以下有原则的流程：\n1. 假设参数模型为 $y_i = O_0 + c_2 a_i^2 + \\epsilon_i$，其中 $\\epsilon_i$ 是高斯分布的。将总方差视为 $\\sigma_i^2 = \\sigma_{i,\\text{rep}}^2 + \\sigma_{\\text{int}}^2$，其中 $\\sigma_{\\text{int}} \\ge 0$ 是一个待确定的内在散射项。\n2. 对于给定的 $\\sigma_{\\text{int}}$，使用权重 $w_i = 1/\\sigma_i^2$ 对 $(O_0,c_2)$ 进行加权最小二乘拟合。在无信息先验下，使用得到的参数协方差来近似 $(O_0,c_2)$ 的高斯后验分布。\n3. 使用观测方差和在 $a_i$ 处的参数不确定性之和，为每个 $y_i$ 构建 $95\\%$ 的后验预测区间。计算观测到的 $y_i$ 落入这些区间的覆盖分数（以小数形式表示），以及在名义覆盖率 $0.95$ 下观测到至多那么多次成功的相应二项分布尾部概率。\n4. 通过检查 $\\sigma_{\\text{int}} = 0$ 时的初始 PPC 来检测被低估的误差。如果二项分布尾部概率小于 $0.05$，则宣告失败，并增加 $\\sigma_{\\text{int}}$ 直至 PPC 通过。为此，在一个均匀网格上找到最小的 $\\sigma_{\\text{int}} \\in [0,0.05]$，使其能达到至少 $0.05$ 的二项分布尾部概率。\n5. 从参数协方差中报告最终的连续谱估计值 $O_0$ 及其 $95\\%$ 可信区间。所有报告的量都必须以无量纲比率 $m/g$（即以 $g$ 为单位）表示。覆盖率必须以小数形式报告。通过/失败指示符必须以整数形式报告，其中 $1$ 表示 PPC 在修正后通过，否则为 $0$。\n\n测试套件：\n- 案例 1 (准确的误差，理想路径)：格点间距 $a = [0.30,0.20,0.15,0.10,0.05]$，报告的标准差 $\\sigma_{\\text{rep}} = [0.006,0.005,0.004,0.004,0.003]$，观测值 $y = [0.6221895835,0.5851895835,0.5786895835,0.5681895835,0.5666895835]$。\n- 案例 2 (被低估的误差)：格点间距 $a = [0.30,0.20,0.15,0.10,0.05]$，报告的标准差 $\\sigma_{\\text{rep}} = [0.002,0.002,0.002,0.002,0.002]$，观测值 $y = [0.6251895835,0.5821895835,0.5816895835,0.5651895835,0.5716895835]$。\n- 案例 3 (粗格点占主导)：格点间距 $a = [0.35,0.30,0.25]$，报告的标准差 $\\sigma_{\\text{rep}} = [0.010,0.009,0.008]$，观测值 $y = [0.6214395835,0.6121895835,0.5934395835]$。\n- 案例 4 (最小可辨识性的边界情况)：格点间距 $a = [0.20,0.10]$，报告的标准差 $\\sigma_{\\text{rep}} = [0.006,0.004]$，观测值 $y = [0.5891895835,0.5676895835]$。\n- 案例 5 (被低估的误差，伴有轻微的模型设定错误和一个离群值)：格点间距 $a = [0.30,0.20,0.15,0.12,0.08]$，报告的标准差 $\\sigma_{\\text{rep}} = [0.003,0.003,0.003,0.003,0.003]$，观测值 $y = [0.6169495835,0.5865495835,0.5789870835,0.5807466395,0.5670131995]$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含所有案例的结果，形式为一个以逗号分隔的顶层列表，其中每个案例的结果是一个包含五个元素的列表，顺序为 $[O_0, \\text{CI}_{\\text{low}}, \\text{CI}_{\\text{high}}, \\text{coverage}, \\text{pass}]$。例如，打印的结构必须类似于 $[[\\dots],[\\dots],\\dots]$，所有数字和整数都明确显示。连续谱估计值及其区间必须以 $g$ 为单位报告，即无量纲比率 $m/g$。覆盖率必须是小数，通过/失败指示符必须是整数。", "solution": "该问题要求对格点数据执行连续谱外推，其中包括一种用于评估和修正被低估的统计误差的有原则的方法。该过程涉及拟合一个参数模型，使用后验预测检验 (PPCs) 进行模型验证，并迭代调整一个内在误差项以满足 PPC 的要求。我将首先详细介绍理论和统计框架，然后描述其实现。\n\n### 1. 模型构建\n\n问题的核心是将在几个有限格点间距 $a$ 处测量的可观测量 $O(a)$ 外推至连续谱极限 $a \\to 0$。问题指出，对于一个未经改进的局域算符，领头阶离散化效应是 $a^2$ 阶的。因此，我们可以将可观测量对格点间距的依赖关系建模为：\n$$\nO(a) = O_0 + c_2 a^2 + \\mathcal{O}(a^4)\n$$\n其中 $O_0$ 是所期望的连续谱值，$c_2$ 是一个参数化领头离散效应的系数。在我们的分析中，我们截断此级数并采用以下线性模型：\n$$\nO(a) = O_0 + c_2 a^2\n$$\n在格点间距 $a_i$ 处的观测数据点 $y_i$ 会受到统计涨落的影响。我们用一个加性高斯噪声项 $\\epsilon_i$ 来对此建模。问题假定报告的方差 $\\sigma_{i,\\text{rep}}^2$ 可能被低估。为了解决这个问题，我们引入一个非负的内在散射项 $\\sigma_{\\text{int}}$，它与报告的误差以平方和的形式相加。因此，第 $i$ 次测量的总方差为：\n$$\n\\sigma_i^2 = \\sigma_{i,\\text{rep}}^2 + \\sigma_{\\text{int}}^2\n$$\n第 $i$ 个数据点的完整测量模型是：\n$$\ny_i = O_0 + c_2 a_i^2 + \\epsilon_i, \\quad \\text{其中} \\quad \\epsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2)\n$$\n\n### 2. 通过加权最小二乘法 (WLS) 进行参数估计\n\n给定 $\\sigma_{\\text{int}}$ 的值，也即给定了每个 $\\sigma_i^2$ 的值，参数 $\\theta = (O_0, c_2)^T$ 可以通过最小化加权残差平方和（或 $\\chi^2$）来估计：\n$$\n\\chi^2(\\theta) = \\sum_{i=1}^{N} \\frac{(y_i - (O_0 + c_2 a_i^2))^2}{\\sigma_i^2}\n$$\n这是一个加权最小二乘 (WLS) 问题。用矩阵表示法，令 $y = (y_1, \\dots, y_N)^T$ 为观测向量，令 $X$ 为 $N \\times 2$ 的设计矩阵，其中第 $i$ 行为 $(1, a_i^2)$。令 $W$ 为 $N \\times N$ 的对角权重矩阵，其元素为 $W_{ii} = 1/\\sigma_i^2$。$\\theta$ 的 WLS 估计量为：\n$$\n\\hat{\\theta} = (X^T W X)^{-1} X^T W y\n$$\n假设 $\\theta$ 服从一个无信息（平坦）先验，其后验分布 $p(\\theta|y)$ 近似为一个以 $\\hat{\\theta}$ 为中心、协方差矩阵为 $C$ 的多元高斯分布：\n$$\nC = \\text{Cov}(\\hat{\\theta}) = (X^T W X)^{-1}\n$$\n连续谱外推值为 $\\hat{O}_0 = \\hat{\\theta}_0$，其方差是协方差矩阵的左上角元素，$\\text{Var}(\\hat{O}_0) = C_{00}$。$O_0$ 的 $95\\%$ 可信区间则计算为 $\\hat{O}_0 \\pm z \\sqrt{C_{00}}$，其中 $z = \\Phi^{-1}(0.975) \\approx 1.96$ 是标准正态分布的第 $97.5$ 百分位数。\n\n### 3. 使用后验预测检验 (PPC) 进行模型检验\n\n一项关键任务是验证模型，包括我们对 $\\sigma_{\\text{int}}$ 的选择。我们使用后验预测检验。对于在给定格点间距 $a_i$ 处的一个新（或重复）观测值 $y_i^{\\text{pred}}$，其后验预测分布是在参数 $\\theta$ 的后验分布上平均得到的 $y_i^{\\text{pred}}$ 的分布。对于高斯后验，这将得到一个高斯预测分布：\n$$\ny_i^{\\text{pred}} \\sim \\mathcal{N}(\\mu_{\\text{pred},i}, \\sigma_{\\text{pred},i}^2)\n$$\n均值 $\\mu_{\\text{pred},i}$ 是来自最佳拟合模型的预测：\n$$\n\\mu_{\\text{pred},i} = \\hat{O}_0 + \\hat{c}_2 a_i^2 = (X\\hat{\\theta})_i\n$$\n预测方差 $\\sigma_{\\text{pred},i}^2$ 是两个分量的和：观测方差 $\\sigma_i^2$ 和因参数不确定性导致的均值预测不确定性。这种参数不确定性是从参数协方差矩阵 $C$ 传播而来的：\n$$\n\\text{Var}(\\mu_{\\text{pred},i}) = x_i^T C x_i, \\quad \\text{其中} \\quad x_i = (1, a_i^2)^T\n$$\n因此，总预测方差为：\n$$\n\\sigma_{\\text{pred},i}^2 = \\sigma_i^2 + x_i^T C x_i = (\\sigma_{i,\\text{rep}}^2 + \\sigma_{\\text{int}}^2) + x_i^T C x_i\n$$\n每个观测值 $y_i$ 的 $95\\%$ 后验预测区间为 $[\\mu_{\\text{pred},i} - z \\sigma_{\\text{pred},i}, \\mu_{\\text{pred},i} + z \\sigma_{\\text{pred},i}]$。\n\n检验包括将观测数据 $y_i$ 与这些区间进行比较。我们计算落入各自 $95\\%$ 预测区间内的数据点数量 $k$。如果模型能很好地描述数据，我们期望大约 $95\\%$ 的数据点会发生这种情况。“成功”次数 $k$（在 $N$ 次试验中）应遵循二项分布，$k \\sim B(N, p=0.95)$。一个显著的偏差，特别是成功次数过少，表明模型过于自信，其预测区间过窄。我们通过计算二项分布尾部概率 $P(K \\le k)$ 来量化此偏差，其中 $K \\sim B(N, p=0.95)$。如果此概率小于一个阈值（此处为 $0.05$），我们则断定模型未通过检验。\n\n### 4. 迭代误差修正\n\n总体流程如下：\n1.  以 $\\sigma_{\\text{int}} = 0$ 初始化。\n2.  执行 WLS 拟合，并计算参数估计值 $\\hat{\\theta}$ 和协方差 $C$。\n3.  执行 PPC：构建 $95\\%$ 后验预测区间，并计算被覆盖的数据点数量 $k$。\n4.  计算二项分布尾部概率 $P(K \\le k)$。\n5.  如果此概率大于或等于 $0.05$，则模型通过。分析完成。通过指示符设为 $1$。\n6.  如果概率小于 $0.05$，则模型失败，这很可能是由于误差被低估。然后我们搜索能解决此问题的最小非负 $\\sigma_{\\text{int}}$。具体做法是，在 $[0, 0.05]$ 范围内的均匀网格上迭代 $\\sigma_{\\text{int}}$ 的值，并重复步骤 2-4。选择第一个使尾部概率至少为 $0.05$ 的 $\\sigma_{\\text{int}}$ 值。采纳基于此值的分析结果，并将通过指示符设为 $1$。如果在 $0.05$ 以内的 $\\sigma_{\\text{int}}$ 值都不足以通过检验，则该流程未能找到合适的修正，通过指示符设为 $0$。\n\n最终报告的 $O_0$ 及其 $95\\%$ 可信区间取自对应于最终接受的 $\\sigma_{\\text{int}}$ 值的分析。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import binom, norm\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis on all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case 1: accurate errors, happy path\n        ([0.30, 0.20, 0.15, 0.10, 0.05],\n         [0.006, 0.005, 0.004, 0.004, 0.003],\n         [0.6221895835, 0.5851895835, 0.5786895835, 0.5681895835, 0.5666895835]),\n        # Case 2: underestimated errors\n        ([0.30, 0.20, 0.15, 0.10, 0.05],\n         [0.002, 0.002, 0.002, 0.002, 0.002],\n         [0.6251895835, 0.5821895835, 0.5816895835, 0.5651895835, 0.5716895835]),\n        # Case 3: coarse lattices dominate\n        ([0.35, 0.30, 0.25],\n         [0.010, 0.009, 0.008],\n         [0.6214395835, 0.6121895835, 0.5934395835]),\n        # Case 4: boundary with minimal identifiability\n        ([0.20, 0.10],\n         [0.006, 0.004],\n         [0.5891895835, 0.5676895835]),\n        # Case 5: underestimated errors with mild model misspecification and an outlier\n        ([0.30, 0.20, 0.15, 0.12, 0.08],\n         [0.003, 0.003, 0.003, 0.003, 0.003],\n         [0.6169495835, 0.5865495835, 0.5789870835, 0.5807466395, 0.5670131995])\n    ]\n\n    results = []\n    for case_data in test_cases:\n        a_vals, sigma_rep_vals, y_vals = (np.array(d) for d in case_data)\n        result = process_case(a_vals, sigma_rep_vals, y_vals)\n        results.append(result)\n\n    # Format the final output string as specified in the problem\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef process_case(a, sigma_rep, y):\n    \"\"\"\n    Performs the full analysis for a single case: WLS fit, PPC, and error correction.\n    \"\"\"\n    \n    def perform_analysis(sigma_int_val):\n        \"\"\"\n        Helper function to perform WLS fit and PPC for a given sigma_int.\n        \"\"\"\n        # 1. Total variance calculation\n        total_sigma_sq = sigma_rep**2 + sigma_int_val**2\n        \n        n_pts = len(y)\n        if n_pts  2:\n            return None\n\n        # 2. Weighted Least Squares (WLS) fit\n        X = np.vstack([np.ones(n_pts), a**2]).T\n        W = np.diag(1.0 / total_sigma_sq)\n        \n        try:\n            XT_W_X = X.T @ W @ X\n            param_cov = np.linalg.inv(XT_W_X)\n            XT_W_y = X.T @ W @ y\n            params = param_cov @ XT_W_y\n        except np.linalg.LinAlgError:\n            return None # Should not happen for N>=2 with distinct a_i\n\n        O0_hat = params[0]\n\n        # 3. Posterior Predictive Check (PPC)\n        mu_pred = X @ params\n        var_parametric = np.sum((X @ param_cov) * X, axis=1)\n        var_pred = total_sigma_sq + var_parametric\n\n        z_95 = norm.ppf(1.0 - 0.05 / 2.0)\n        lower_bound = mu_pred - z_95 * np.sqrt(var_pred)\n        upper_bound = mu_pred + z_95 * np.sqrt(var_pred)\n        \n        is_covered = (y >= lower_bound)  (y = upper_bound)\n        coverage_count = np.sum(is_covered)\n        coverage_fraction = coverage_count / n_pts\n        \n        # 4. Binomial tail probability for PPC\n        tail_prob = binom.cdf(coverage_count, n=n_pts, p=0.95)\n        \n        return {\n            \"O0\": O0_hat,\n            \"param_cov\": param_cov,\n            \"coverage\": coverage_fraction,\n            \"tail_prob\": tail_prob\n        }\n\n    # Start with initial check for sigma_int = 0\n    initial_analysis = perform_analysis(sigma_int_val=0.0)\n    \n    if initial_analysis is None:\n        return [float('nan'), float('nan'), float('nan'), float('nan'), 0]\n\n    final_analysis = initial_analysis\n    pass_flag = 1 # Assume success unless proven otherwise\n\n    # If PPC fails, search for a corrective sigma_int\n    if initial_analysis[\"tail_prob\"]  0.05:\n        sigma_int_grid = np.linspace(0, 0.05, 501)\n        correction_found = False\n        \n        last_good_analysis = None\n        for s_int in sigma_int_grid[1:]:\n            current_analysis = perform_analysis(sigma_int_val=s_int)\n            if current_analysis is None:\n                continue\n            last_good_analysis = current_analysis\n\n            if current_analysis[\"tail_prob\"] >= 0.05:\n                final_analysis = current_analysis\n                correction_found = True\n                break\n        \n        if not correction_found:\n            # Correction failed even at max sigma_int, use a valid last result\n            if last_good_analysis:\n                final_analysis = last_good_analysis\n            pass_flag = 0\n\n    # Extract final results from the successful (or final attempted) analysis\n    O0_final = final_analysis[\"O0\"]\n    param_cov_final = final_analysis[\"param_cov\"]\n    coverage_final = final_analysis[\"coverage\"]\n    \n    std_err_O0 = np.sqrt(param_cov_final[0, 0])\n    z_95 = norm.ppf(1.0 - 0.05 / 2.0)\n    CI_low = O0_final - z_95 * std_err_O0\n    CI_high = O0_final + z_95 * std_err_O0\n    \n    # Return formatted list for this case\n    return [O0_final, CI_low, CI_high, coverage_final, pass_flag]\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3509857"}, {"introduction": "在连续谱外推中，选择何种函数形式（ansatz）来描述离散化效应是系统误差的一个主要来源。Symanzik 有效理论虽然指明了可能的 $a$ 的幂次，但通常无法先验地确定哪一项是主导的，或者是否有多项贡献。本练习 [@problem_id:3509855] 引入了贝叶斯模型平均（Bayesian Model Averaging, BMA）作为一种系统地处理这种模型选择不确定性的方法。通过对几种具有物理动机的竞争模型（例如，$\\mathcal{O}(a)$、$\\mathcal{O}(a^2)$ 和 $\\mathcal{O}(a^2 \\ln a)$）进行比较，并根据它们由数据支持的证据（evidence）进行加权，你将计算出一个最终的连续谱极限值，其误差稳健地包含了我们对离散效应真实函数形式的无知。", "problem": "实现一个完整的程序，该程序使用三种竞争的拟设 (ansätze) 对格点数据进行连续区外推的贝叶斯模型平均 (BMA)，并返回模型平均的连续区值及其等尾可信区间。本问题中的所有量均为无量纲量。这三个模型由格点间距 $a$ 的基函数定义如下：\n- $M_1$：常数加线性项，其中 $f(a) = f_0 + c_1\\,a$，\n- $M_2$：常数加二次项，其中 $f(a) = f_0 + c_2\\,a^2$，\n- $M_3$：常数加二次项乘以对数项，其中 $f(a) = f_0 + c_3\\,a^2 \\log a$，其中对数为自然对数，且 $a \\in (0,1)$，因此 $\\log a$ 有良好定义且为负值。\n\n您必须在一个具有高斯观测噪声和系数上独立高斯先验的完全贝叶斯线性模型中处理此问题。具体而言：\n- 似然：给定数据 $(a_i, y_i, \\sigma_i)$，其中 $i=1,\\dots,n$，模型 $M$ 通过一个关于系数的线性设计矩阵来预测 $y_i$，并且数据似然是具有已知标准差 $\\sigma_i$ 的高斯函数的乘积。\n- 每个模型 $M_j$ 的参数先验：系数向量 $\\theta = (f_0, c_j)$ 被赋予一个零均值的高斯先验，其协方差为对角矩阵 $\\mathrm{diag}(\\tau_0^2, \\tau_c^2)$，其中 $\\tau_0 = 10$ 且 $\\tau_c = 1$。\n- 模型先验：模型 $M_1$、$M_2$ 和 $M_3$ 具有相等的先验概率。\n\n您的程序必须：\n1. 对于每个模型 $M_j$，通过在高斯先验和线性高斯似然下对参数进行积分，来计算模型证据。\n2. 对于每个模型 $M_j$，计算在该模型下给定数据的连续区参数 $f_0$（即常数基函数的系数）的后验分布。\n3. 计算每个模型的后验概率。\n4. 构建 $f_0$ 的模型平均后验，作为三个特定模型的高斯后验的离散混合，其权重等于后验模型概率。\n5. 从该混合分布中，计算 $f_0$ 的模型平均后验均值及其置信水平为 $0.68$ 的中心等尾可信区间（即下分位点为 $0.16$，上分位点为 $0.84$）。\n\n您必须使用的基本原理：\n- 用于模型选择和参数推断的贝叶斯定理，\n- 具有高斯先验的线性高斯模型的多元正态分布性质，\n- 中心等尾可信区间的定义。\n\n约束和要求：\n- 将所有输入视为无量纲数。本问题不涉及角度；无需进行单位换算。\n- 实现数值稳定的线性代数。您可以假设观测误差协方差是对角的，其对角线元素为 $\\sigma_i^2$。\n- $\\log a$ 使用自然对数。\n- 可信区间水平应解释为概率 (例如，$0.68$)，而不是百分比。报告区间的端点，而不是半宽度。\n\n测试套件：\n您的程序必须在以下五个数据集上运行。每个数据集提供格点间距 $a$、观测值 $y$ 和观测标准差 $\\sigma$ 的数组。请严格按照给定顺序使用这些值。\n\n- 案例 1 (典型的二次截断效应)：\n  - $a = [\\,0.12,\\, 0.09,\\, 0.06,\\, 0.045\\,]$\n  - $y = [\\,0.52028,\\, 0.50772,\\, 0.50582,\\, 0.50143\\,]$\n  - $\\sigma = [\\,0.005,\\, 0.004,\\, 0.003,\\, 0.003\\,]$\n\n- 案例 2 (主导的线性截断效应)：\n  - $a = [\\,0.16,\\, 0.12,\\, 0.08,\\, 0.04\\,]$\n  - $y = [\\,0.877,\\, 0.902,\\, 0.939,\\, 0.964\\,]$\n  - $\\sigma = [\\,0.01,\\, 0.01,\\, 0.01,\\, 0.01\\,]$\n\n- 案例 3 (对数增强的二次修正)：\n  - $a = [\\,0.10,\\, 0.08,\\, 0.06,\\, 0.05,\\, 0.04\\,]$\n  - $y = [\\,0.189987074535,\\, 0.1909176683392,\\, 0.1954358607098302,\\, 0.1957553346575,\\, 0.19842489934\\,]$\n  - $\\sigma = [\\,0.004,\\, 0.004,\\, 0.004,\\, 0.004,\\, 0.004\\,]$\n\n- 案例 4 (稀疏数据)：\n  - $a = [\\,0.10,\\, 0.05\\,]$\n  - $y = [\\,0.311,\\, 0.29875\\,]$\n  - $\\sigma = [\\,0.02,\\, 0.02\\,]$\n\n- 案例 5 (高噪声情况)：\n  - $a = [\\,0.15,\\, 0.12,\\, 0.09,\\, 0.06,\\, 0.03\\,]$\n  - $y = [\\,0.845,\\, 0.78,\\, 0.805,\\, 0.765,\\, 0.77\\,]$\n  - $\\sigma = [\\,0.05,\\, 0.05,\\, 0.05,\\, 0.05,\\, 0.05\\,]$\n\n输出规范：\n- 对于每种情况，计算 $f_0$ 的模型平均后验均值以及置信水平为 $0.68$ 的中心等尾可信区间的端点。\n- 将报告的每个数字四舍五入到 $6$ 位小数。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，其中每种情况贡献一个形式为 $[\\,\\text{均值},\\, \\text{下界},\\, \\text{上界}\\,]$ 的子列表。例如，整体格式必须类似于 $[[m_1,\\ell_1,u_1],[m_2,\\ell_2,u_2],\\dots,[m_5,\\ell_5,u_5]]$，其中恰好有五个三元组，按顺序对应于上述情况。", "solution": "用户要求实现一个用于格点数据连续区外推的贝叶斯模型平均 (BMA) 程序。该问题提法明确，具有科学依据，并包含了解决该问题所需的所有信息。它直接属于计算物理学和贝叶斯统计学的范畴。\n\n我们将首先推导贝叶斯线性模型的必要数学公式，然后实现这些公式来解决所提供的测试案例。\n\n### 贝叶斯线性回归形式体系\n\n令给定模型 $M_j$ 由线性关系 $\\mathbf{y} = X_j \\boldsymbol{\\theta}_j + \\boldsymbol{\\epsilon}$ 描述，其中：\n- $\\mathbf{y}$ 是观测值的 $n \\times 1$ 向量。\n- $X_j$ 是 $n \\times k$ 设计矩阵，对于所有模型，$k=2$ 个参数。\n- $\\boldsymbol{\\theta}_j$ 是模型参数的 $k \\times 1$ 向量，$(f_0, c_j)^T$。\n- $\\boldsymbol{\\epsilon}$ 是观测误差向量，假设其从均值为 $\\mathbf{0}$、已知对角协方差矩阵为 $\\Sigma = \\mathrm{diag}(\\sigma_1^2, \\dots, \\sigma_n^2)$ 的高斯分布中抽取。\n\n给定参数下数据的似然为：\n$$p(\\mathbf{y} | \\boldsymbol{\\theta}_j, M_j) = \\mathcal{N}(\\mathbf{y} | X_j \\boldsymbol{\\theta}_j, \\Sigma) \\propto \\exp\\left(-\\frac{1}{2}(\\mathbf{y} - X_j \\boldsymbol{\\theta}_j)^T \\Sigma^{-1} (\\mathbf{y} - X_j \\boldsymbol{\\theta}_j)\\right)$$\n\n问题指定了参数 $\\boldsymbol{\\theta}_j$ 上的高斯先验：\n$$p(\\boldsymbol{\\theta}_j | M_j) = \\mathcal{N}(\\boldsymbol{\\theta}_j | \\boldsymbol{\\mu}_0, \\Sigma_0)$$\n其中先验均值为 $\\boldsymbol{\\mu}_0 = \\mathbf{0}$，先验协方差为 $\\Sigma_0 = \\mathrm{diag}(\\tau_0^2, \\tau_c^2)$，且 $\\tau_0 = 10$ 和 $\\tau_c = 1$。\n\n#### 1. 参数后验分布\n由于高斯先验与线性高斯似然的共轭性，参数的后验分布也是一个高斯分布：\n$$p(\\boldsymbol{\\theta}_j | \\mathbf{y}, M_j) = \\mathcal{N}(\\boldsymbol{\\theta}_j | \\boldsymbol{\\mu}_{n,j}, \\Sigma_{n,j})$$\n后验协方差 $\\Sigma_{n,j}$ 和均值 $\\boldsymbol{\\mu}_{n,j}$ 由以下公式给出：\n$$\n\\Sigma_{n,j} = (\\Sigma_0^{-1} + X_j^T \\Sigma^{-1} X_j)^{-1} \\\\\n\\boldsymbol{\\mu}_{n,j} = \\Sigma_{n,j} (X_j^T \\Sigma^{-1} \\mathbf{y})\n$$\n由于 $\\boldsymbol{\\mu}_0=\\mathbf{0}$，涉及先验均值的项消失。令 $W = \\Sigma^{-1}$。方程变为：\n$$\nA_j = \\Sigma_0^{-1} + X_j^T W X_j \\\\\n\\Sigma_{n,j} = A_j^{-1} \\\\\n\\boldsymbol{\\mu}_{n,j} = \\Sigma_{n,j} (X_j^T W \\mathbf{y})\n$$\n我们感兴趣的参数是 $f_0$，即 $\\boldsymbol{\\theta}_j$ 的第一个分量。在模型 $M_j$ 下，其边际后验分布是一个单变量高斯分布：\n$$p(f_0 | \\mathbf{y}, M_j) = \\mathcal{N}(f_0 | \\mu_{f_0, j}, \\sigma_{f_0, j}^2)$$\n其中 $\\mu_{f_0, j} = (\\boldsymbol{\\mu}_{n,j})_1$ 且 $\\sigma_{f_0, j}^2 = (\\Sigma_{n,j})_{11}$。\n\n#### 2. 模型证据 (边际似然)\n模型 $M_j$ 的证据是数据在所有可能参数值上积分的概率：\n$$p(\\mathbf{y} | M_j) = \\int p(\\mathbf{y} | \\boldsymbol{\\theta}_j, M_j) p(\\boldsymbol{\\theta}_j | M_j) d\\boldsymbol{\\theta}_j$$\n对于线性高斯情况，该积分可以解析求解。结果是：\n$$p(\\mathbf{y} | M_j) = \\mathcal{N}(\\mathbf{y} | X_j\\boldsymbol{\\mu}_0, \\Sigma + X_j\\Sigma_0 X_j^T)$$\n为了稳定地计算，我们使用证据的对数。一个方便且稳定的表达式是：\n$$\n\\log p(\\mathbf{y}|M_j) = -\\frac{n}{2} \\log (2\\pi) -\\frac{1}{2}\\left( \\log\\det\\Sigma + \\log\\det\\Sigma_0 + \\log\\det A_j \\right) -\\frac{1}{2}\\left( \\mathbf{y}^T W \\mathbf{y} - \\boldsymbol{\\mu}_{n,j}^T A_j \\boldsymbol{\\mu}_{n,j} \\right)\n$$\n其中 $\\boldsymbol{\\mu}_{n,j}^T A_j \\boldsymbol{\\mu}_{n,j} = (X_j^T W \\mathbf{y})^T \\Sigma_{n,j} (X_j^T W \\mathbf{y})$。\n\n#### 3. 后验模型概率\n使用模型的贝叶斯定理，模型 $M_j$ 的后验概率为：\n$$P(M_j | \\mathbf{y}) = \\frac{p(\\mathbf{y} | M_j) P(M_j)}{\\sum_{k=1}^3 p(\\mathbf{y} | M_k) P(M_k)}$$\n由于先验概率 $P(M_j)$ 相等 ($1/3$)，它们相互抵消，我们得到：\n$$P(M_j | \\mathbf{y}) = \\frac{p(\\mathbf{y} | M_j)}{\\sum_{k=1}^3 p(\\mathbf{y} | M_k)}$$\n为了处理潜在的数值下溢或上溢，我们使用 log-sum-exp 技巧从对数证据 $\\ell_j = \\log p(\\mathbf{y}|M_j)$ 计算这些概率：\n令 $\\ell_{\\max} = \\max(\\ell_1, \\ell_2, \\ell_3)$。则后验权重 $w_j = P(M_j|\\mathbf{y})$ 为：\n$$w_j = \\frac{\\exp(\\ell_j - \\ell_{\\max})}{\\sum_{k=1}^3 \\exp(\\ell_k - \\ell_{\\max})}$$\n\n#### 4. BMA 后验、均值和可信区间\n$f_0$ 的 BMA 后验分布是各个模型后验分布的加权混合：\n$$p(f_0 | \\mathbf{y}) = \\sum_{j=1}^3 w_j \\, p(f_0 | \\mathbf{y}, M_j) = \\sum_{j=1}^3 w_j \\, \\mathcal{N}(f_0 | \\mu_{f_0, j}, \\sigma_{f_0, j}^2)$$\n该混合分布的均值是 BMA 后验均值：\n$$E[f_0 | \\mathbf{y}] = \\sum_{j=1}^3 w_j \\mu_{f_0, j}$$\n中心等尾可信区间由混合分布的分位数定义。对于 $68\\%$ 的可信区间，我们需要 $16\\%$ 和 $84\\%$ 的分位数。混合分布的累积分布函数 (CDF) 是：\n$$F(x) = P(f_0 \\le x | \\mathbf{y}) = \\sum_{j=1}^3 w_j \\, \\Phi\\left(\\frac{x - \\mu_{f_0, j}}{\\sigma_{f_0, j}}\\right)$$\n其中 $\\Phi$ 是标准正态累积分布函数。我们必须找到值 $x_{0.16}$ 和 $x_{0.84}$，使得 $F(x_{0.16}) = 0.16$ 和 $F(x_{0.84}) = 0.84$。这些方程使用求根算法进行数值求解。\n\n### 算法实现\n\n对于每个测试案例，算法按以下步骤进行：\n1.  初始化先验参数：$\\tau_0=10, \\tau_c=1$。\n2.  对于三个模型 ($M_1, M_2, M_3$) 中的每一个：\n    a. 使用模型的基函数 $a_i$、$a_i^2$ 和 $a_i^2 \\log a_i$ 从格点间距 $a_i$ 构建设计矩阵 $X_j$。\n    b. 计算后验均值 $\\boldsymbol{\\mu}_{n,j}$ 和协方差 $\\Sigma_{n,j}$。\n    c. 提取参数 $f_0$ 的均值 $\\mu_{f_0, j}$ 和标准差 $\\sigma_{f_0, j}$。\n    d. 计算对数模型证据 $\\ell_j = \\log p(\\mathbf{y}|M_j)$。\n3.  从对数证据计算后验模型概率 $w_j$。\n4.  计算 $f_0$ 的 BMA 后验均值。\n5.  定义混合累积分布函数 $F(x)$。\n6.  使用数值求根器 (例如 `scipy.optimize.brentq`)，通过求解 $F(x) - q = 0$ (其中 $q=0.16$ 和 $q=0.84$)，找到 $68\\%$ 可信区间的下界 ($x_{0.16}$) 和上界 ($x_{0.84}$)。\n7.  收集并格式化 BMA 均值、下界和上界，四舍五入到六位小数。\n\n将此过程系统地应用于所有五个测试案例，以生成最终结果。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.optimize import brentq\n\ndef bma_extrapolation(a_data, y_data, sigma_data):\n    \"\"\"\n    Performs Bayesian Model Averaging for continuum extrapolation.\n    \"\"\"\n    # Convert inputs to numpy arrays\n    a = np.array(a_data)\n    y = np.array(y_data)\n    sigma = np.array(sigma_data)\n    \n    # Priors\n    tau_0 = 10.0\n    tau_c = 1.0\n    prior_cov_inv = np.diag([1.0 / tau_0**2, 1.0 / tau_c**2])\n    log_det_prior_cov = 2.0 * (np.log(tau_0) + np.log(tau_c))\n\n    # Data-related quantities\n    n = len(y)\n    W = np.diag(1.0 / sigma**2)\n    log_det_obs_cov = np.sum(2.0 * np.log(sigma))\n    yT_W_y = y @ W @ y\n    \n    # Basis functions for the three models\n    basis_functions = [\n        lambda x: x,\n        lambda x: x**2,\n        lambda x: x**2 * np.log(x)\n    ]\n    \n    model_posteriors = []\n    log_evidences = []\n\n    for basis_func in basis_functions:\n        # Build design matrix X\n        phi = basis_func(a)\n        X = np.vstack([np.ones_like(phi), phi]).T\n        \n        # Posterior calculation\n        A = prior_cov_inv + X.T @ W @ X\n        A_inv = np.linalg.inv(A)\n        b = X.T @ W @ y\n        \n        post_mean = A_inv @ b\n        post_cov = A_inv\n        \n        f0_mean = post_mean[0]\n        f0_var = post_cov[0, 0]\n        \n        model_posteriors.append({'mean': f0_mean, 'std': np.sqrt(f0_var)})\n        \n        # Log evidence calculation\n        log_det_A = np.log(np.linalg.det(A))\n        energy_term = yT_W_y - b @ post_mean\n        \n        log_evidence = -0.5 * (n * np.log(2 * np.pi) + log_det_prior_cov +\n                               log_det_obs_cov + log_det_A + energy_term)\n        log_evidences.append(log_evidence)\n    \n    # Model probabilities (weights)\n    log_evidences = np.array(log_evidences)\n    max_log_evidence = np.max(log_evidences)\n    evidences = np.exp(log_evidences - max_log_evidence)\n    post_probs = evidences / np.sum(evidences)\n    \n    # BMA mean\n    bma_mean = np.sum([p['mean'] * w for p, w in zip(model_posteriors, post_probs)])\n    \n    # BMA credible interval\n    def mixture_cdf(x):\n        cdf_val = 0.0\n        for i, p in enumerate(model_posteriors):\n            cdf_val += post_probs[i] * norm.cdf(x, loc=p['mean'], scale=p['std'])\n        return cdf_val\n\n    # Find a reasonable search interval for the root finder\n    all_means = [p['mean'] for p in model_posteriors]\n    all_stds = [p['std'] for p in model_posteriors]\n    search_min = min(all_means) - 10 * max(all_stds)\n    search_max = max(all_means) + 10 * max(all_stds)\n\n    # Functions to find roots for quantiles\n    lower_quantile_func = lambda x: mixture_cdf(x) - 0.16\n    upper_quantile_func = lambda x: mixture_cdf(x) - 0.84\n    \n    # Find lower and upper bounds of the 68% CI\n    ci_lower = brentq(lower_quantile_func, search_min, search_max)\n    ci_upper = brentq(upper_quantile_func, search_min, search_max)\n    \n    return [bma_mean, ci_lower, ci_upper]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {\n            \"a\": [0.12, 0.09, 0.06, 0.045],\n            \"y\": [0.52028, 0.50772, 0.50582, 0.50143],\n            \"sigma\": [0.005, 0.004, 0.003, 0.003]\n        },\n        # Case 2\n        {\n            \"a\": [0.16, 0.12, 0.08, 0.04],\n            \"y\": [0.877, 0.902, 0.939, 0.964],\n            \"sigma\": [0.01, 0.01, 0.01, 0.01]\n        },\n        # Case 3\n        {\n            \"a\": [0.10, 0.08, 0.06, 0.05, 0.04],\n            \"y\": [0.189987074535, 0.1909176683392, 0.1954358607098302, 0.1957553346575, 0.19842489934],\n            \"sigma\": [0.004, 0.004, 0.004, 0.004, 0.004]\n        },\n        # Case 4\n        {\n            \"a\": [0.10, 0.05],\n            \"y\": [0.311, 0.29875],\n            \"sigma\": [0.02, 0.02]\n        },\n        # Case 5\n        {\n            \"a\": [0.15, 0.12, 0.09, 0.06, 0.03],\n            \"y\": [0.845, 0.78, 0.805, 0.765, 0.77],\n            \"sigma\": [0.05, 0.05, 0.05, 0.05, 0.05]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = bma_extrapolation(case[\"a\"], case[\"y\"], case[\"sigma\"])\n        results.append(result)\n\n    # Format the final output string exactly as specified.\n    result_strings = []\n    for res in results:\n        mean, lower, upper = res\n        result_strings.append(f\"[{mean:.6f},{lower:.6f},{upper:.6f}]\")\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3509855"}]}