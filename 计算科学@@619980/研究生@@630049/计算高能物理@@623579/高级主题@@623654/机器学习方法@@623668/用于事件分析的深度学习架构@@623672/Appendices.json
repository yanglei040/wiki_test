{"hands_on_practices": [{"introduction": "将深度学习应用于喷注物理的最早且最直观的方法之一，是把喷注看作图像。本练习深入探讨了卷积神经网络（CNN）的基本运算——卷积（更准确地说是互相关），展示了学习到的核函数如何在喷注的像素化表示上充当特征探测器。通过手动计算一个卷积层的输出，您将具体理解感受野等概念，以及它们如何与高能物理中的物理角尺度（如 $\\Delta R$）相关联，从而在高阶深度学习操作与具体物理分析之间建立联系 [@problem_id:3510623]。", "problem": "您正在分析一个喷注子结构分类器，该分类器基于卷积神经网络（CNN）构建，并应用于高能物理事件分析中离散化的赝快度-方位角平面。该喷注中心位于赝快度 $\\eta \\approx 0$ 处，您使用喷注图像的一个局部 $3 \\times 3$ 图片块，其强度经过单位归一化且无量纲：\n$$\nI \\;=\\; \\begin{pmatrix}\n0.12  & 0.08 & 0.05\\\\\n0.20  & 0.15 & 0.10\\\\\n0.18  & 0.12 & 0.06\n\\end{pmatrix}.\n$$\n一个已学习的 $2 \\times 2$ 核（近似一个定向对比度算子）由下式给出：\n$$\nK \\;=\\; \\begin{pmatrix}\n0.5  & -0.25\\\\\n-0.5 & 0.25\n\\end{pmatrix}.\n$$\n在CNN的前向传播过程中，采用标准的深度学习惯例，即该层执行离散互相关（核不翻转），步长 $s=1$ 且无填充。输出是有效的 $2 \\times 2$ 激活图 $Y$，其元素为\n$$\nY_{i,j} \\;=\\; \\sum_{u=0}^{1}\\sum_{v=0}^{1} K_{u,v}\\, I_{i+u,\\,j+v}, \\quad \\text{对于 } i,j \\in \\{1,2\\}.\n$$\n假设 $\\eta$–$\\phi$ 平面采用方形像素化，其中 $\\Delta \\eta = 0.1$ 且 $\\Delta \\phi = 0.1$，$\\phi$ 以弧度为单位。在标准的喷注分析度量中，角距离定义为 $\\Delta R = \\sqrt{(\\Delta \\eta)^{2} + (\\Delta \\phi)^{2}}$。对于 $Y$ 的单个激活值，其感受野是对应的 $2 \\times 2$ 输入图片块；将其角跨度 $\\Delta R_{\\text{span}}$ 定义为此感受野在 $\\eta$–$\\phi$ 平面对角线的欧几里得长度。\n\n请按顺序计算以下各项：\n- 完整的 $2 \\times 2$ 激活图 $Y$。\n- 标量 $S$，等于 $Y$ 中所有元素的总和。\n- 单个感受野的角跨度 $\\Delta R_{\\text{span}}$。\n- 最终的标量 $P \\equiv S \\times \\Delta R_{\\text{span}}$。\n\n将最终标量 $P$ 表示为一个纯数（无量纲），并四舍五入到四位有效数字。在应用最终的四舍五入指令之前，所有中间量都可以保留精确值。角度以弧度为单位。", "solution": "用户希望我解决这个问题。\n用户希望我遵循特定的角色和格式。\n用户希望我在解决问题之前对其进行验证。\n用户希望每个数学实体都使用 LaTeX 格式。\n用户希望最终答案四舍五入到四位有效数字。\n\n**问题验证**\n\n**步骤 1：提取已知条件**\n- 输入强度矩阵：\n$$\nI \\;=\\; \\begin{pmatrix}\n0.12  & 0.08 & 0.05\\\\\n0.20  & 0.15 & 0.10\\\\\n0.18  & 0.12 & 0.06\n\\end{pmatrix}\n$$\n- 核矩阵：\n$$\nK \\;=\\; \\begin{pmatrix}\n0.5  & -0.25\\\\\n-0.5 & 0.25\n\\end{pmatrix}\n$$\n- 操作：离散互相关，步长 $s=1$，无填充。\n- 输出激活图定义：\n$$\nY_{i,j} \\;=\\; \\sum_{u=0}^{1}\\sum_{v=0}^{1} K_{u,v}\\, I_{i+u,\\,j+v}, \\quad \\text{对于 } i,j \\in \\{1,2\\}\n$$\n- 像素尺寸：$\\Delta \\eta = 0.1$，$\\Delta \\phi = 0.1$ 弧度。\n- 角距离定义：$\\Delta R = \\sqrt{(\\Delta \\eta)^{2} + (\\Delta \\phi)^{2}}$。\n- 感受野角跨度定义：$\\Delta R_{\\text{span}}$ 是 $2 \\times 2$ 感受野在 $\\eta$–$\\phi$ 平面中对角线的欧几里得长度。\n- 待计算量：\n  1. 激活图 $Y$。\n  2. 激活值总和 $S$。\n  3. 角跨度 $\\Delta R_{\\text{span}}$。\n  4. 最终标量 $P \\equiv S \\times \\Delta R_{\\text{span}}$。\n- 最终答案要求：将 $P$ 四舍五入到四位有效数字。\n\n**步骤 2：使用提取的已知条件进行验证**\n根据验证标准对问题进行评估：\n- **科学性**：该问题在计算高能物理和深度学习领域有充分的依据。它使用了标准概念，如 $\\eta$-$\\phi$ 网格上的喷注图像、CNN 操作（互相关）以及 $\\Delta R$ 度量。该场景是一个真实世界应用的标准化、简化模型。\n- **适定性**：所有必要的数据（$I$、$K$、$\\Delta \\eta$、$\\Delta \\phi$）和定义均已提供。计算步骤明确定义，可得出唯一解。\n- **客观性**：问题陈述使用精确的定量语言，没有主观或模糊的元素。\n- **完整性与一致性**：问题是自洽的。$Y_{i,j}$ 公式中的索引是“有效”互相关操作的常规用法。如果我们假设矩阵 $I$ 从 $(1,1)$到 $(3,3)$ 是 1-索引的，而 $K$ 从 $(0,0)$ 到 $(1,1)$ 是 0-索引的，那么该公式是明确的。\n- **现实性**：强度、核权重和像素尺寸的数值对于此类分析是合理的。\n\n该问题未违反任何无效性标准。它是一个基于既定科学和数学原理的、定义明确的计算问题。\n\n**步骤 3：结论与行动**\n该问题被判定为**有效**。将提供完整解答。\n\n**解答**\n\n该问题需要进行四步计算：激活图 $Y$、其总和 $S$、感受野的角跨度 $\\Delta R_{\\text{span}}$ 以及最终乘积 $P$。\n\n首先，我们使用给定的离散互相关公式计算 $2 \\times 2$ 激活图 $Y$。输入矩阵是强度 $I$ 和核 $K$。根据求和公式，我们假设 $I$ 是 1-索引的，而 $K$ 是 0-索引的。\n$$\nI = \\begin{pmatrix} I_{1,1}  & I_{1,2} & I_{1,3} \\\\ I_{2,1} & I_{2,2} & I_{2,3} \\\\ I_{3,1} & I_{3,2} & I_{3,3} \\end{pmatrix} = \\begin{pmatrix}\n0.12  & 0.08 & 0.05\\\\\n0.20  & 0.15 & 0.10\\\\\n0.18  & 0.12 & 0.06\n\\end{pmatrix}, \\quad K = \\begin{pmatrix} K_{0,0} & K_{0,1} \\\\ K_{1,0} & K_{1,1} \\end{pmatrix} = \\begin{pmatrix}\n0.5  & -0.25\\\\\n-0.5 & 0.25\n\\end{pmatrix}\n$$\n$Y$ 的元素计算如下：\n\n$Y_{1,1} = \\sum_{u=0}^{1}\\sum_{v=0}^{1} K_{u,v}\\, I_{1+u,\\,1+v} = K_{0,0}I_{1,1} + K_{0,1}I_{1,2} + K_{1,0}I_{2,1} + K_{1,1}I_{2,2}$\n$Y_{1,1} = (0.5)(0.12) + (-0.25)(0.08) + (-0.5)(0.20) + (0.25)(0.15)$\n$Y_{1,1} = 0.06 - 0.02 - 0.10 + 0.0375 = -0.0225$\n\n$Y_{1,2} = \\sum_{u=0}^{1}\\sum_{v=0}^{1} K_{u,v}\\, I_{1+u,\\,2+v} = K_{0,0}I_{1,2} + K_{0,1}I_{1,3} + K_{1,0}I_{2,2} + K_{1,1}I_{2,3}$\n$Y_{1,2} = (0.5)(0.08) + (-0.25)(0.05) + (-0.5)(0.15) + (0.25)(0.10)$\n$Y_{1,2} = 0.04 - 0.0125 - 0.075 + 0.025 = -0.0225$\n\n$Y_{2,1} = \\sum_{u=0}^{1}\\sum_{v=0}^{1} K_{u,v}\\, I_{2+u,\\,1+v} = K_{0,0}I_{2,1} + K_{0,1}I_{2,2} + K_{1,0}I_{3,1} + K_{1,1}I_{3,2}$\n$Y_{2,1} = (0.5)(0.20) + (-0.25)(0.15) + (-0.5)(0.18) + (0.25)(0.12)$\n$Y_{2,1} = 0.10 - 0.0375 - 0.09 + 0.03 = 0.0025$\n\n$Y_{2,2} = \\sum_{u=0}^{1}\\sum_{v=0}^{1} K_{u,v}\\, I_{2+u,\\,2+v} = K_{0,0}I_{2,2} + K_{0,1}I_{2,3} + K_{1,0}I_{3,2} + K_{1,1}I_{3,3}$\n$Y_{2,2} = (0.5)(0.15) + (-0.25)(0.10) + (-0.5)(0.12) + (0.25)(0.06)$\n$Y_{2,2} = 0.075 - 0.025 - 0.06 + 0.015 = 0.0050$\n\n完整的激活图为：\n$$\nY = \\begin{pmatrix}\n-0.0225 & -0.0225 \\\\\n0.0025  & 0.0050\n\\end{pmatrix}\n$$\n其次，我们计算标量 $S$，即 $Y$ 中所有元素的总和。\n$$\nS = Y_{1,1} + Y_{1,2} + Y_{2,1} + Y_{2,2}\n$$\n$$\nS = (-0.0225) + (-0.0225) + 0.0025 + 0.0050 = -0.0450 + 0.0075 = -0.0375\n$$\n第三，我们计算角跨度 $\\Delta R_{\\text{span}}$。单个激活值的感受野是一个 $2 \\times 2$ 的像素块。每个像素的宽度为 $\\Delta \\eta = 0.1$，高度为 $\\Delta \\phi = 0.1$。$2 \\times 2$ 图片块所覆盖的总区域是 $\\eta$-$\\phi$ 平面中的一个矩形，其边长为 $L_{\\eta} = 2 \\times \\Delta\\eta$ 和 $L_{\\phi} = 2 \\times \\Delta\\phi$。\n$$\nL_{\\eta} = 2 \\times 0.1 = 0.2\n$$\n$$\nL_{\\phi} = 2 \\times 0.1 = 0.2\n$$\n角跨度 $\\Delta R_{\\text{span}}$ 定义为该矩形区域对角线的欧几里得长度。\n$$\n\\Delta R_{\\text{span}} = \\sqrt{L_{\\eta}^2 + L_{\\phi}^2} = \\sqrt{(0.2)^2 + (0.2)^2}\n$$\n$$\n\\Delta R_{\\text{span}} = \\sqrt{0.04 + 0.04} = \\sqrt{0.08} = \\sqrt{\\frac{8}{100}} = \\frac{2\\sqrt{2}}{10} = 0.2\\sqrt{2}\n$$\n第四，我们计算最终标量 $P \\equiv S \\times \\Delta R_{\\text{span}}$。\n$$\nP = (-0.0375) \\times (0.2\\sqrt{2}) = -0.0075\\sqrt{2}\n$$\n最后，我们必须提供 $P$ 的数值，并四舍五入到四位有效数字。使用近似值 $\\sqrt{2} \\approx 1.41421356$，我们得到：\n$$\nP \\approx -0.0075 \\times 1.41421356 \\approx -0.0106066017\n$$\n第一个有效数字是 $1$。前四位有效数字是 $1$、$0$、$6$、$0$。第五位有效数字是 $6$，所以我们将第四位向上取整。\n$$\nP \\approx -0.01061\n$$\n这就是所要求的最终数值结果。", "answer": "$$\n\\boxed{-0.01061}\n$$", "id": "3510623"}, {"introduction": "虽然卷积神经网络功能强大，但它们需要固定的网格结构，而粒子事件更自然的表示是图。图神经网络（GNN）专为直接处理此类数据而设计。本练习聚焦于 GNN 的核心机制：消息传递，演示了来自相邻粒子（节点）的信息如何被聚合以更新一个粒子的表示，并在此过程中融入运动学关系（如 $\\Delta\\eta$ 和 $\\Delta\\phi$） [@problem_id:3510657]。完成这一计算，您将亲身体验 GNN 是如何学习关系特征并构建复杂事件级表示的，从而超越固定网格架构的局限性。", "problem": "一个用于计算高能物理中事件级分析的图神经网络，作用于一个由四个重建粒子（节点）组成的有向完全图上，每个节点都具有运动学特征 $x_i=(p_{T,i},\\eta_i,\\phi_i)$，其中 $p_{T,i}$ 是横向动量，$\\eta_i$ 是赝快度，$\\phi_i$ 是方位角。节点 $i$ 的初始标量隐藏状态由线性嵌入 $h_i^{(0)}=w_p \\ln p_{T,i} + w_{\\eta}\\,\\eta_i$ 定义，该嵌入仅使用 $\\ln p_{T,i}$ 和 $\\eta_i$ 以遵循方位旋转不变性。对于每个有向边 $(i \\leftarrow j)$，定义边特征 $e_{ij}=(\\Delta \\eta_{ij}, \\Delta \\phi_{ij}, \\ln p_{T,j})$，其中 $\\Delta \\eta_{ij}=\\eta_j-\\eta_i$，而 $\\Delta \\phi_{ij}$ 由区间 $[-\\pi,\\pi]$ 上的环绕差（wrapped difference）给出，使其成为方位角上的最小有符号间隔。从节点 $j$ 到节点 $i$ 的消息计算如下：\n$$\nm_{ij}=\\tanh\\!\\left(a\\,h_j^{(0)}+b_1\\,\\Delta \\eta_{ij}+b_2\\,\\cos(\\Delta \\phi_{ij})+b_3\\,\\ln p_{T,j}+c\\right),\n$$\n节点更新使用求和聚合：\n$$\na_i=\\sum_{j\\neq i} m_{ij},\\quad h_i^{(1)}=h_i^{(0)}+\\alpha\\,a_i.\n$$\n给定以下常数和节点特征：\n- 嵌入权重：$w_p=0.6$, $w_{\\eta}=0.3$。\n- 消息权重：$a=0.8$, $b_1=0.15$, $b_2=0.2$, $b_3=0.05$, $c=-0.02$。\n- 更新系数：$\\alpha=0.7$。\n- 节点 1：$(p_{T,1},\\eta_1,\\phi_1)=(50, 0.2, 0.10)$。\n- 节点 2：$(p_{T,2},\\eta_2,\\phi_2)=(40, -0.3, 3.05)$。\n- 节点 3：$(p_{T,3},\\eta_3,\\phi_3)=(25, 1.1, -3.00)$。\n- 节点 4：$(p_{T,4},\\eta_4,\\phi_4)=(10, -2.0, 2.90)$。\n\n所有角度均以弧度为单位，$\\ln$ 表示自然对数。使用上述定义，计算节点2的更新后隐藏状态 $h_2^{(1)}$。将您的最终结果表示为一个实数，并四舍五入到四位有效数字。最终答案无需物理单位。", "solution": "该问题是计算图神经网络中节点2的更新后隐藏状态 $h_2^{(1)}$。问题陈述提供了所有必要的定义、常数和数据，并且在科学和数学上是合理的。因此，该问题有效，可以推导出解。\n\n经过一个消息传递层后，节点 $i$ 的更新后隐藏状态由以下公式给出：\n$$h_i^{(1)} = h_i^{(0)} + \\alpha a_i$$\n其中 $h_i^{(0)}$ 是初始隐藏状态，$\\alpha$ 是更新系数，$a_i$ 是聚合后的消息。\n对于节点 $i=2$，公式变为：\n$$h_2^{(1)} = h_2^{(0)} + \\alpha a_2$$\n聚合消息 $a_2$ 是来自所有其他节点 $j \\neq 2$ 的传入消息之和：\n$$a_2 = \\sum_{j\\neq 2} m_{2j} = m_{21} + m_{23} + m_{24}$$\n该过程需要两个主要阶段：首先，计算所有节点的初始隐藏状态 $h_j^{(0)}$；其次，计算 $j=1, 3, 4$ 到节点2的消息 $m_{2j}$ 以求得 $a_2$。\n\n**1. 计算初始隐藏状态 $h_j^{(0)}$**\n\n节点 $j$ 的初始隐藏状态定义为 $h_j^{(0)} = w_p \\ln p_{T,j} + w_{\\eta} \\eta_j$。\n给定的权重为 $w_p = 0.6$ 和 $w_{\\eta} = 0.3$。节点特征为：\n- 节点 1：$(p_{T,1}, \\eta_1, \\phi_1) = (50, 0.2, 0.10)$\n- 节点 2：$(p_{T,2}, \\eta_2, \\phi_2) = (40, -0.3, 3.05)$\n- 节点 3：$(p_{T,3}, \\eta_3, \\phi_3) = (25, 1.1, -3.00)$\n- 节点 4：$(p_{T,4}, \\eta_4, \\phi_4) = (10, -2.0, 2.90)$\n\n首先，我们计算横向动量的自然对数：\n- $\\ln p_{T,1} = \\ln(50) \\approx 3.91202$\n- $\\ln p_{T,2} = \\ln(40) \\approx 3.68888$\n- $\\ln p_{T,3} = \\ln(25) \\approx 3.21888$\n- $\\ln p_{T,4} = \\ln(10) \\approx 2.30259$\n\n现在，我们计算初始隐藏状态：\n- $h_1^{(0)} = (0.6) \\times (\\ln 50) + (0.3) \\times (0.2) \\approx (0.6)(3.91202) + 0.06 = 2.34721 + 0.06 = 2.40721$\n- $h_2^{(0)} = (0.6) \\times (\\ln 40) + (0.3) \\times (-0.3) \\approx (0.6)(3.68888) - 0.09 = 2.21333 - 0.09 = 2.12333$\n- $h_3^{(0)} = (0.6) \\times (\\ln 25) + (0.3) \\times (1.1) \\approx (0.6)(3.21888) + 0.33 = 1.93133 + 0.33 = 2.26133$\n- $h_4^{(0)} = (0.6) \\times (\\ln 10) + (0.3) \\times (-2.0) \\approx (0.6)(2.30259) - 0.6 = 1.38155 - 0.6 = 0.78155$\n\n**2. 计算到节点2的消息 $m_{2j}$**\n\n从节点 $j$ 到节点 $i$ 的消息由以下公式给出：\n$$m_{ij}=\\tanh\\!\\left(a\\,h_j^{(0)}+b_1\\,\\Delta \\eta_{ij}+b_2\\,\\cos(\\Delta \\phi_{ij})+b_3\\,\\ln p_{T,j}+c\\right)$$\n其中常数为 $a=0.8$, $b_1=0.15$, $b_2=0.2$, $b_3=0.05$, $c=-0.02$。我们需要计算 $m_{21}$、$m_{23}$ 和 $m_{24}$。\n\n**消息 $m_{21}$（从节点 $j=1$ 到节点 $i=2$）：**\n- $\\Delta \\eta_{21} = \\eta_1 - \\eta_2 = 0.2 - (-0.3) = 0.5$\n- $\\Delta \\phi_{21} = \\phi_1 - \\phi_2 = 0.10 - 3.05 = -2.95$。该值在 $[-\\pi, \\pi]$ 范围内，因为 $\\pi \\approx 3.14159$。\n- $\\cos(\\Delta \\phi_{21}) = \\cos(-2.95) \\approx -0.98506$\n令 $Z_{21}$ 为 $\\tanh$ 的参数：\n$Z_{21} = (0.8)h_1^{(0)} + (0.15)\\Delta \\eta_{21} + (0.2)\\cos(\\Delta \\phi_{21}) + (0.05)\\ln p_{T,1} + (-0.02)$\n$Z_{21} \\approx (0.8)(2.40721) + (0.15)(0.5) + (0.2)(-0.98506) + (0.05)(3.91202) - 0.02$\n$Z_{21} \\approx 1.92577 + 0.075 - 0.19701 + 0.19560 - 0.02 = 1.97936$\n$m_{21} = \\tanh(1.97936) \\approx 0.96255$\n\n**消息 $m_{23}$（从节点 $j=3$ 到节点 $i=2$）：**\n- $\\Delta \\eta_{23} = \\eta_3 - \\eta_2 = 1.1 - (-0.3) = 1.4$\n- $\\Delta \\phi_{23} = \\phi_3 - \\phi_2 = -3.00 - 3.05 = -6.05$。这个值超出了 $[-\\pi, \\pi]$ 范围。我们通过加上 $2\\pi$ 来进行环绕处理：$\\Delta \\phi_{23, \\text{wrapped}} = -6.05 + 2\\pi \\approx -6.05 + 6.28318 = 0.23318$。\n- $\\cos(\\Delta \\phi_{23}) = \\cos(0.23318) \\approx 0.97290$\n令 $Z_{23}$ 为 $\\tanh$ 的参数：\n$Z_{23} = (0.8)h_3^{(0)} + (0.15)\\Delta \\eta_{23} + (0.2)\\cos(\\Delta \\phi_{23}) + (0.05)\\ln p_{T,3} + (-0.02)$\n$Z_{23} \\approx (0.8)(2.26133) + (0.15)(1.4) + (0.2)(0.97290) + (0.05)(3.21888) - 0.02$\n$Z_{23} \\approx 1.80906 + 0.21 + 0.19458 + 0.16094 - 0.02 = 2.35458$\n$m_{23} = \\tanh(2.35458) \\approx 0.98207$\n\n**消息 $m_{24}$（从节点 $j=4$ 到节点 $i=2$）：**\n- $\\Delta \\eta_{24} = \\eta_4 - \\eta_2 = -2.0 - (-0.3) = -1.7$\n- $\\Delta \\phi_{24} = \\phi_4 - \\phi_2 = 2.90 - 3.05 = -0.15$。该值在 $[-\\pi, \\pi]$ 范围内。\n- $\\cos(\\Delta \\phi_{24}) = \\cos(-0.15) \\approx 0.98877$\n令 $Z_{24}$ 为 $\\tanh$ 的参数：\n$Z_{24} = (0.8)h_4^{(0)} + (0.15)\\Delta \\eta_{24} + (0.2)\\cos(\\Delta \\phi_{24}) + (0.05)\\ln p_{T,4} + (-0.02)$\n$Z_{24} \\approx (0.8)(0.78155) + (0.15)(-1.7) + (0.2)(0.98877) + (0.05)(2.30259) - 0.02$\n$Z_{24} \\approx 0.62524 - 0.255 + 0.19775 + 0.11513 - 0.02 = 0.66312$\n$m_{24} = \\tanh(0.66312) \\approx 0.58055$\n\n**3. 计算聚合消息 $a_2$ 和更新后状态 $h_2^{(1)}$**\n\n节点2的聚合消息是传入消息的总和：\n$a_2 = m_{21} + m_{23} + m_{24} \\approx 0.96255 + 0.98207 + 0.58055 = 2.52517$\n\n最后，我们使用 $h_2^{(1)} = h_2^{(0)} + \\alpha a_2$ 和 $\\alpha = 0.7$ 来更新节点2的隐藏状态：\n$h_2^{(1)} \\approx 2.12333 + (0.7)(2.52517)$\n$h_2^{(1)} \\approx 2.12333 + 1.76762 = 3.89095$\n\n问题要求将结果四舍五入到四位有效数字。这个数是 $3.89095$。前四位有效数字是 $3$、$8$、$9$ 和 $0$。下一位数字是 $9$，大于或等于 $5$，所以我们将第四位有效数字向上取整。\n$h_2^{(1)} \\approx 3.891$", "answer": "$$\n\\boxed{3.891}\n$$", "id": "3510657"}, {"introduction": "Transformer 和注意力机制为深度学习的许多领域带来了革命。在粒子物理学中，它们为处理可变长度的粒子集合提供了一种强大的方法，无需施加网格或预定义图之类的刚性结构。本练习在一个特定但极具启发性的场景中剖析了缩放点积注意力机制，突出了掩码（masking）在处理可变长度事件批次中的关键作用，并演示了如何利用注意力权重执行排列不变的池化操作 [@problem_id:3510613]。通过这个练习，您将清晰地理解注意力机制处理粒子集合及聚合信息的方式，这是构建先进事件分类器和生成模型的基石。", "problem": "考虑计算高能物理中的一个小批量（mini-batch），其中每个事件是一个可变长度的重建粒子序列，每个粒子由二维特征表示（例如，缩放后的横向动量和赝快度）。两个事件被合并成一个批次，用于事件分析的深度学习架构中的自注意力操作。事件 $1$ 的长度为 $N_{1} = 2$，事件 $2$ 的长度为 $N_{2} = 3$，因此总序列长度为 $N = N_{1} + N_{2} = 5$。设特征维度为 $d = 2$。假设模型使用带查询、键和值投影的缩放点积自注意力。值投影是单位矩阵，查询和键投影是零矩阵，点积的缩放因子是标准的 $\\sqrt{d_{k}}$，其中 $d_{k} = 2$。每个粒子的特征向量（因此也是值向量）按顺序，对于事件 $1$ 为：\n$$\\mathbf{v}_{1} = \\begin{pmatrix}2 \\\\ -1\\end{pmatrix}, \\quad \\mathbf{v}_{2} = \\begin{pmatrix}4 \\\\ 1\\end{pmatrix},$$\n对于事件 $2$ 为：\n$$\\mathbf{v}_{3} = \\begin{pmatrix}1 \\\\ 3\\end{pmatrix}, \\quad \\mathbf{v}_{4} = \\begin{pmatrix}0 \\\\ -2\\end{pmatrix}, \\quad \\mathbf{v}_{5} = \\begin{pmatrix}5 \\\\ 1\\end{pmatrix}.$$\n注意力被掩码以实现事件局部性：一个事件的查询只允许关注同一事件的键，禁止跨事件的注意力。显式地构造块对角注意力掩码矩阵 $\\mathbf{M} \\in \\mathbb{R}^{5 \\times 5}$，其中对应允许的事件内配对的元素为 $0$，禁止的跨事件配对的元素为 $-\\infty$。然后，使用带有此掩码的缩放点积自注意力，计算批次中所有五个查询位置的注意力输出。通过按顺序拼接从 $1$ 到 $5$ 的每个查询位置的输出向量的两个分量，将最终的注意力输出表示为单个行矩阵。无需四舍五入，最终表达式中不包含物理单位。", "solution": "该问题要求计算在特定约束下，包含两个事件的一个批次的自注意力输出。首先，验证问题的正确性和可解性。\n\n### 步骤 1：提取已知条件\n- **事件结构**：事件 $1$ 的长度为 $N_{1} = 2$。事件 $2$ 的长度为 $N_{2} = 3$。\n- **总序列长度**：$N = N_{1} + N_{2} = 5$。\n- **特征维度**：$d = 2$。\n- **注意力机制**：缩放点积自注意力。\n- **模型投影**：\n    - 查询投影矩阵：$W_Q = \\mathbf{0}$，零矩阵。\n    - 键投影矩阵：$W_K = \\mathbf{0}$，零矩阵。\n    - 值投影矩阵：$W_V = \\mathbf{I}$，单位矩阵。\n- **注意力缩放因子**：缩放因子为 $\\frac{1}{\\sqrt{d_k}}$，其中 $d_k = 2$。\n- **输入特征向量**：\n    - 对于事件 1：$\\mathbf{v}_{1} = \\begin{pmatrix}2 \\\\ -1\\end{pmatrix}$，$\\mathbf{v}_{2} = \\begin{pmatrix}4 \\\\ 1\\end{pmatrix}$。\n    - 对于事件 2：$\\mathbf{v}_{3} = \\begin{pmatrix}1 \\\\ 3\\end{pmatrix}$，$\\mathbf{v}_{4} = \\begin{pmatrix}0 \\\\ -2\\end{pmatrix}$，$\\mathbf{v}_{5} = \\begin{pmatrix}5 \\\\ 1\\end{pmatrix}$。\n- **注意力掩码**：掩码是事件局部的，禁止跨事件的注意力。掩码矩阵 $\\mathbf{M} \\in \\mathbb{R}^{5 \\times 5}$ 对允许的配对，其元素为 $0$，对禁止的配对，其元素为 $-\\infty$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，因为它描述了用于粒子物理学深度学习的标准自注意力机制的一个特定（尽管简化了的）实例。该设置，包括用于查询和键投影的零矩阵，是一个在数学上良定义的有效特殊情况。该问题是适定的，为得到唯一解提供了所有必要的数据和约束。语言客观且精确。该问题不违反任何无效性标准。\n\n### 步骤 3：结论与行动\n该问题有效。将提供详细的解决方案。\n\n### 求解过程\n\n缩放点积注意力输出 $\\mathbf{O}$ 的计算公式为：\n$$ \\mathbf{O} = \\text{softmax}\\left(\\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}} + \\mathbf{M}\\right) \\mathbf{V} $$\n其中 $\\mathbf{Q}$、$\\mathbf{K}$ 和 $\\mathbf{V}$ 分别是查询、键和值矩阵，$\\mathbf{M}$ 是注意力掩码。\n\n**1. 构造查询、键和值矩阵**\n\n设输入特征矩阵为 $\\mathbf{X} \\in \\mathbb{R}^{5 \\times 2}$，由堆叠输入特征向量形成：\n$$ \\mathbf{X} = \\begin{pmatrix} \\mathbf{v}_1^T \\\\ \\mathbf{v}_2^T \\\\ \\mathbf{v}_3^T \\\\ \\mathbf{v}_4^T \\\\ \\mathbf{v}_5^T \\end{pmatrix} = \\begin{pmatrix} 2  & -1 \\\\ 4  & 1 \\\\ 1  & 3 \\\\ 0  & -2 \\\\ 5  & 1 \\end{pmatrix} $$\n\n值矩阵 $\\mathbf{V}$ 是通过投影输入特征得到的：$\\mathbf{V} = \\mathbf{X} W_V$。由于 $W_V$ 是单位矩阵 $\\mathbf{I}$，因此值矩阵与输入特征矩阵相同：\n$$ \\mathbf{V} = \\mathbf{X} \\mathbf{I} = \\mathbf{X} = \\begin{pmatrix} 2  & -1 \\\\ 4  & 1 \\\\ 1  & 3 \\\\ 0  & -2 \\\\ 5  & 1 \\end{pmatrix} $$\n\n查询矩阵 $\\mathbf{Q}$ 为 $\\mathbf{Q} = \\mathbf{X} W_Q$。由于 $W_Q$ 是零矩阵，$\\mathbf{Q}$ 是一个 $5 \\times 2$ 的零矩阵：\n$$ \\mathbf{Q} = \\mathbf{X} \\mathbf{0} = \\begin{pmatrix} 0  & 0 \\\\ 0  & 0 \\\\ 0  & 0 \\\\ 0  & 0 \\\\ 0  & 0 \\end{pmatrix} $$\n\n类似地，键矩阵 $\\mathbf{K}$ 为 $\\mathbf{K} = \\mathbf{X} W_K = \\mathbf{X} \\mathbf{0}$，它也是一个 $5 \\times 2$ 的零矩阵。\n\n**2. 计算注意力分数**\n\n未掩码的注意力分数为 $\\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}}$。乘积 $\\mathbf{Q}\\mathbf{K}^T$ 是一个 $5 \\times 5$ 矩阵。由于 $\\mathbf{Q}$ 是零矩阵，该乘积是 $5 \\times 5$ 的零矩阵：\n$$ \\mathbf{Q}\\mathbf{K}^T = \\mathbf{0}_{5 \\times 5} $$\n因此，缩放后的未掩码分数也是 $5 \\times 5$ 的零矩阵：\n$$ \\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}} = \\mathbf{0}_{5 \\times 5} $$\n\n**3. 构造注意力掩码矩阵**\n\n掩码禁止不同事件之间的注意力。事件 1 由粒子 1 和 2 组成。事件 2 由粒子 3、4 和 5 组成。掩码矩阵 $\\mathbf{M}$ 是一个块对角矩阵，其中允许的（事件内）配对具有 $0$ 的加性掩码值，而禁止的（跨事件）配对具有 $-\\infty$ 的值。\n\n$$ \\mathbf{M} = \\begin{pmatrix}\n0  & 0 & -\\infty & -\\infty & -\\infty \\\\\n0  & 0 & -\\infty & -\\infty & -\\infty \\\\\n-\\infty & -\\infty & 0 & 0 & 0 \\\\\n-\\infty & -\\infty & 0 & 0 & 0 \\\\\n-\\infty & -\\infty & 0 & 0 & 0\n\\end{pmatrix} $$\n\n**4. 应用掩码和 Softmax**\n\nsoftmax 函数应用于缩放分数和掩码之和：\n$$ \\mathbf{S}' = \\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d_k}} + \\mathbf{M} = \\mathbf{0}_{5 \\times 5} + \\mathbf{M} = \\mathbf{M} $$\n注意力权重矩阵 $\\mathbf{A}$ 是 $\\mathbf{A} = \\text{softmax}(\\mathbf{S}')$ 逐行应用的结果。我们来计算 $\\mathbf{A}$ 的各行：\n\n- 对于行 $i=1, 2$（事件 1）：softmax 的输入是 $(0, 0, -\\infty, -\\infty, -\\infty)$。\n$$ A_{1,j} = A_{2,j} = \\frac{\\exp(S'_{i,j})}{\\sum_{k=1}^5 \\exp(S'_{i,k})} $$\n分母是 $\\exp(0) + \\exp(0) + \\exp(-\\infty) + \\exp(-\\infty) + \\exp(-\\infty) = 1 + 1 + 0 + 0 + 0 = 2$。\n结果行为 $(\\frac{1}{2}, \\frac{1}{2}, 0, 0, 0)$。\n\n- 对于行 $i=3, 4, 5$（事件 2）：softmax 的输入是 $(-\\infty, -\\infty, 0, 0, 0)$。\n分母是 $\\exp(-\\infty) + \\exp(-\\infty) + \\exp(0) + \\exp(0) + \\exp(0) = 0 + 0 + 1 + 1 + 1 = 3$。\n结果行为 $(0, 0, \\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3})$。\n\n所以，完整的注意力权重矩阵是：\n$$ \\mathbf{A} = \\begin{pmatrix}\n\\frac{1}{2}  & \\frac{1}{2} & 0 & 0 & 0 \\\\\n\\frac{1}{2}  & \\frac{1}{2} & 0 & 0 & 0 \\\\\n0 & 0 & \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3} \\\\\n0 & 0 & \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3} \\\\\n0 & 0 & \\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3}\n\\end{pmatrix} $$\n\n**5. 计算最终输出向量**\n\n最终输出矩阵是 $\\mathbf{O} = \\mathbf{A}\\mathbf{V}$。第 $i$ 个输出向量 $\\mathbf{o}_i$ 是 $\\mathbf{O}$ 的第 $i$ 行，通过 $\\mathbf{o}_i^T = \\sum_{j=1}^N A_{ij} \\mathbf{v}_j^T$ 计算。\n\n- 对于查询位置 $i=1, 2$：输出是事件 1 中值向量的平均值。\n$$ \\mathbf{o}_1 = \\mathbf{o}_2 = \\frac{1}{2}\\mathbf{v}_1 + \\frac{1}{2}\\mathbf{v}_2 = \\frac{1}{2}\\begin{pmatrix}2 \\\\ -1\\end{pmatrix} + \\frac{1}{2}\\begin{pmatrix}4 \\\\ 1\\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix}2+4 \\\\ -1+1\\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix}6 \\\\ 0\\end{pmatrix} = \\begin{pmatrix}3 \\\\ 0\\end{pmatrix} $$\n\n- 对于查询位置 $i=3, 4, 5$：输出是事件 2 中值向量的平均值。\n$$ \\mathbf{o}_3 = \\mathbf{o}_4 = \\mathbf{o}_5 = \\frac{1}{3}\\mathbf{v}_3 + \\frac{1}{3}\\mathbf{v}_4 + \\frac{1}{3}\\mathbf{v}_5 = \\frac{1}{3}\\left(\\begin{pmatrix}1 \\\\ 3\\end{pmatrix} + \\begin{pmatrix}0 \\\\ -2\\end{pmatrix} + \\begin{pmatrix}5 \\\\ 1\\end{pmatrix}\\right) = \\frac{1}{3}\\begin{pmatrix}1+0+5 \\\\ 3-2+1\\end{pmatrix} = \\frac{1}{3}\\begin{pmatrix}6 \\\\ 2\\end{pmatrix} = \\begin{pmatrix}2 \\\\ \\frac{2}{3}\\end{pmatrix} $$\n\n**6. 拼接最终输出**\n\n问题要求将输出向量 $\\mathbf{o}_1, \\mathbf{o}_2, \\mathbf{o}_3, \\mathbf{o}_4, \\mathbf{o}_5$ 的分量拼接成一个单行矩阵。\n分量序列为：\n- $\\mathbf{o}_1$: $(3, 0)$\n- $\\mathbf{o}_2$: $(3, 0)$\n- $\\mathbf{o}_3$: $(2, \\frac{2}{3})$\n- $\\mathbf{o}_4$: $(2, \\frac{2}{3})$\n- $\\mathbf{o}_5$: $(2, \\frac{2}{3})$\n\n最终拼接的行矩阵是 $\\begin{pmatrix} 3 & 0 & 3 & 0 & 2 & \\frac{2}{3} & 2 & \\frac{2}{3} & 2 & \\frac{2}{3} \\end{pmatrix}$。", "answer": "$$ \\boxed{ \\begin{pmatrix} 3 & 0 & 3 & 0 & 2 & \\frac{2}{3} & 2 & \\frac{2}{3} & 2 & \\frac{2}{3} \\end{pmatrix} } $$", "id": "3510613"}]}