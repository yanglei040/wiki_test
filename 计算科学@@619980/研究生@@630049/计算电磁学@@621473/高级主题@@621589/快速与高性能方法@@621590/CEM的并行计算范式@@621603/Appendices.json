{"hands_on_practices": [{"introduction": "在并行计算中，性能的可扩展性常常受限于计算与通信之间的平衡。本练习将引导你通过第一性原理，分析一种常见的三维区域分解策略——“铅笔分解”（pencil decomposition）中的通信开销 [@problem_id:3336971]。通过精确推导不同类型的邻居（面、边）之间的数据交换量，你将掌握量化并行算法通信成本的核心技能，并理解为何随着处理器数量的增加，某些通信模式会成为性能瓶颈。", "problem": "一个用于计算电磁学 (CEM) 的三维时域有限差分 (FDTD) 求解器，使用显式模板在每个时间步更新大小为 $n_{x} \\times n_{y} \\times n_{z}$ 的结构化网格上的电场和磁场分量。该网格使用沿 $z$ 轴对齐的笔状分解分布在 $P$ 个进程上：进程排列在一个大小为 $P_{x} \\times P_{y}$ 的二维网格中，其中 $P = P_{x} P_{y}$，使得每个进程拥有一个大小为 $\\frac{n_{x}}{P_{x}} \\times \\frac{n_{y}}{P_{y}} \\times n_{z}$ 的子域。模板在 $x$ 和 $y$ 方向上所需的晕轮区（鬼影区）厚度为 $\\delta \\geq 1$ 个网格单元。沿着 $z$ 方向，不需要进程间通信，因为每个进程都跨越了完整的 $z$ 范围。\n\n假设代码在每个时间步显式交换以下数据：\n- 与 $x$ 和 $y$ 方向上的四个面相邻进程（$x$ 方向两个，$y$ 方向两个）交换面晕轮。\n- 与 $x$-$y$ 平面内的四个对角相邻进程（$\\pm x$, $\\pm y$ 的组合）交换边晕轮（面内对角线）。这些边区域具有沿 $z$ 轴拉伸的 $\\delta \\times \\delta$ 横截面。\n- 在这种笔状分解下，不存在对应于 $\\pm x$, $\\pm y$, $\\pm z$ 三重相邻的角晕轮，因为沿 $z$ 轴没有进程间相邻。\n\n每个网格单元携带 $c$ 个需要通信的场自由度（例如，在 Yee 格式中，$c=6$，包括三个电场分量和三个磁场分量），每个自由度以 $b$ 字节进行通信。将每个时间步的总通信量定义为所有进程为面、边和角交换发送的字节数之和。\n\n从域分解几何和晕轮交换的基本原理出发，用 $n_{x}$、$n_{y}$、$n_{z}$、$P_{x}$、$P_{y}$、$\\delta$、$c$ 和 $b$ 推导由面、边和角贡献的每个时间步的总字节数表达式。然后，为了进行渐近比较，将其特化到平衡情况 $P_{x} = P_{y} = \\sqrt{P}$ 和近立方体网格 $n_{x} \\approx n_{y} \\approx n_{z}$（可表示为 $n_{x} = n_{y} = n_{z} = n$）。在这种平衡的立方体情况下，确定当 $P$ 变得很大时，三种贡献（面、边、角）中哪一种占主导地位，并为每个时间步的总通信量提供一个单一封闭形式解析表达式的主导项。\n\n以字节为单位表示最终的主导项通信量。无需进行数值计算。", "solution": "首先根据所需标准验证问题陈述。\n\n### 步骤 1：提取已知条件\n- **全局网格尺寸**：$n_{x} \\times n_{y} \\times n_{z}$ 单元。\n- **总进程数**：$P$。\n- **进程网格**：$P_{x} \\times P_{y}$，其中 $P = P_{x} P_{y}$。\n- **分解**：沿 $z$ 轴的笔状分解。\n- **每个进程的子域尺寸**：$\\frac{n_{x}}{P_{x}} \\times \\frac{n_{y}}{P_{y}} \\times n_{z}$。\n- **晕轮厚度**：$x$ 和 $y$ 方向上 $\\delta$ 个网格单元。\n- **通信模式**：\n    - 与 $x-y$ 平面内的四个相邻进程交换面晕轮。\n    - 与 $x-y$ 平面内的四个对角相邻进程交换边晕轮。\n    - 不涉及 $z$ 方向的角晕轮交换。\n- **每个网格单元的数据**：$c$ 个自由度。\n- **数据大小**：每个自由度 $b$ 字节。\n- **总通信量的定义**：每个时间步内，所有进程为面、边和角交换发送的字节数之和。\n- **用于分析的特殊情况**：平衡分解 $P_{x} = P_{y} = \\sqrt{P}$ 和立方体网格 $n_{x} = n_{y} = n_{z} = n$。\n- **目标**：推导面、边和角通信量的表达式；然后，在特殊情况下，确定当 $P$ 较大时的主导贡献，并为总体积提供主导项表达式。\n\n### 步骤 2：使用提取的已知条件进行验证\n- **科学上合理**：该问题基于高性能计算和计算电磁学中的既定概念。笔状域分解和晕轮交换是在结构化网格上并行化偏微分方程（如麦克斯韦方程组）求解器的标准基本技术。该设置在科学上和算法上都是合理的。\n- **问题定义明确**：该问题清晰地定义了所有必要的参数（$n_x, n_y, n_z, P_x, P_y, \\delta, c, b$）和一个精确的几何设置。目标是推导一个解析表达式，这是一个定义明确的数学任务。\n- **目标**：问题陈述使用了精确、无歧义的技术语言，不含主观内容。\n\n该问题没有表现出任何缺陷，如科学上的不合理、不完整、矛盾或歧义。这是并行计算中的一个标准分析问题。\n\n### 步骤 3：结论和行动\n问题是有效的。将提供完整的解答。\n\n### 解答推导\n\n每个时间步的总通信量 $V_{\\text{total}}$ 是面、边和角交换的通信量之和。问题将其定义为所有进程*发送*的所有字节之和。我们可以通过识别所有进程间数据交换，计算每次交换的数据量，然后将它们相加来计算这个值。一种等效的方法是计算不同通信接口的数量，确定通过每个接口发送的数据（双向），并将这些贡献相加。\n\n**1. 面通信量 ($V_{\\text{face}}$)**\n\n面通信发生在 $x$ 和 $y$ 方向上相邻子域的边界上。\n\n- **沿 $x$ 面的通信**：进程网格有 $P_x$ 列和 $P_y$ 行。进程列之间有 $(P_x - 1)$ 个垂直边界。这些边界中的每一个都在 $y$ 方向上跨越 $P_y$ 个进程。因此，在 $x$ 方向上有 $(P_x - 1) P_y$ 个不同的接口。在每个接口上，数据都是双向发送的。发送的数据是一个大小为 $\\delta \\times \\frac{n_y}{P_y} \\times n_z$ 的网格单元板。\n一个进程通过一个 $x$ 面发送的数据量为：\n$$V_{\\text{send}, x} = \\left(\\delta \\times \\frac{n_y}{P_y} \\times n_z\\right) \\times c \\times b$$\n通过所有 $x$ 面发送的总数据量是接口数量的两倍乘以该数据量（每个传输方向一次）：\n$$V_{\\text{face}, x} = 2 \\times (P_x - 1) P_y \\times \\left(\\delta \\cdot \\frac{n_y}{P_y} \\cdot n_z \\cdot c \\cdot b\\right) = 2 (P_x - 1) \\delta n_y n_z c b$$\n\n- **沿 $y$ 面的通信**：类似地，进程行之间有 $(P_y - 1)$ 个水平边界，每个边界跨越 $P_x$ 个进程。这给出了 $(P_y - 1) P_x$ 个接口。发送的数据是一个大小为 $\\frac{n_x}{P_x} \\times \\delta \\times n_z$ 的板。\n通过所有 $y$ 面发送的总数据量是：\n$$V_{\\text{face}, y} = 2 \\times (P_y - 1) P_x \\times \\left(\\frac{n_x}{P_x} \\cdot \\delta \\cdot n_z \\cdot c \\cdot b\\right) = 2 (P_y - 1) \\delta n_x n_z c b$$\n\n总的面通信量是：\n$$V_{\\text{face}} = V_{\\text{face}, x} + V_{\\text{face}, y} = 2 \\delta n_z c b \\left[ (P_x - 1) n_y + (P_y - 1) n_x \\right]$$\n\n**2. 边通信量 ($V_{\\text{edge}}$)**\n\n边通信发生在 $x-y$ 平面内的对角相邻进程之间。这些交换发生在四个进程子域相交的“角点”处。在 $P_x \\times P_y$ 进程网格中，这种内部角点的数量为 $(P_x - 1)(P_y - 1)$。\n在每个这样的角点，四个进程相遇。我们用它们的网格索引来标记它们：$(i, j)$, $(i+1, j)$, $(i, j+1)$, 和 $(i+1, j+1)$。对角线交换发生在 $(i, j)$ 和 $(i+1, j+1)$ 之间，以及 $(i+1, j)$ 和 $(i, j+1)$ 之间。对于每一对，通信都是双向的。例如，进程 $(i,j)$ 向 $(i+1,j+1)$ 发送数据，而 $(i+1,j+1)$ 向 $(i,j)$ 发送数据。这导致在进程网格的每个内部角点处总共发送 4 条消息。\n为边交换发送的数据是一束具有 $\\delta \\times \\delta$ 横截面和完整 $z$ 范围 $n_z$ 的“笔状”单元。这样一条消息的数据量为：\n$$V_{\\text{send}, \\text{edge}} = (\\delta \\times \\delta \\times n_z) \\times c \\times b = \\delta^2 n_z c b$$\n总的边通信量是内部进程角点的数量乘以每个角点发送 4 次，再乘以每次发送的数据量：\n$$V_{\\text{edge}} = (P_x - 1)(P_y - 1) \\times 4 \\times (\\delta^2 n_z c b) = 4 (P_x - 1)(P_y - 1) \\delta^2 n_z c b$$\n\n**3. 角通信量 ($V_{\\text{corner}}$)**\n\n问题陈述明确指出，由于笔状分解（沿 $z$ 轴没有分解），不存在对应于所有三个维度（$\\pm x, \\pm y, \\pm z$）的角的进程间相邻。因此，该通信量为零。\n$$V_{\\text{corner}} = 0$$\n\n**4. 特化与渐近分析**\n\n我们现在将这些表达式特化为平衡、立方体的情况：$n_x = n_y = n_z = n$ 和 $P_x = P_y = \\sqrt{P}$。\n\n- 特化后的面通信量：\n$$V_{\\text{face}} = 2 \\delta n c b \\left[ (\\sqrt{P} - 1) n + (\\sqrt{P} - 1) n \\right] = 2 \\delta n c b \\left[ 2 n (\\sqrt{P} - 1) \\right]$$\n$$V_{\\text{face}} = 4 \\delta n^2 c b (\\sqrt{P} - 1)$$\n\n- 特化后的边通信量：\n$$V_{\\text{edge}} = 4 (\\sqrt{P} - 1)(\\sqrt{P} - 1) \\delta^2 n c b = 4 \\delta^2 n c b (\\sqrt{P} - 1)^2$$\n$$V_{\\text{edge}} = 4 \\delta^2 n c b (P - 2\\sqrt{P} + 1)$$\n\n为了确定当 $P$ 变大时的主导贡献，我们比较 $V_{\\text{face}}$ 和 $V_{\\text{edge}}$ 关于 $P$ 的领头阶项。\n- 对于 $V_{\\text{face}}$，领头项与 $\\sqrt{P}$ 成正比：\n$$V_{\\text{face}} \\approx 4 \\delta n^2 c b \\sqrt{P} \\quad (\\text{对于大的 } P)$$\n扩展性为 $O(\\sqrt{P})$。\n\n- 对于 $V_{\\text{edge}}$，领头项与 $P$ 成正比：\n$$V_{\\text{edge}} \\approx 4 \\delta^2 n c b P \\quad (\\text{对于大的 } P)$$\n扩展性为 $O(P)$。\n\n由于 $P$ 的增长速度快于 $\\sqrt{P}$，因此对于大的 $P$，边通信量 ($V_{\\text{edge}}$) 是主导贡献。\n\n总通信量是 $V_{\\text{total}} = V_{\\text{face}} + V_{\\text{edge}} + V_{\\text{corner}}$。\n$$V_{\\text{total}} = 4 \\delta n^2 c b (\\sqrt{P} - 1) + 4 \\delta^2 n c b (P - 2\\sqrt{P} + 1) + 0$$\n$$V_{\\text{total}} = (4 \\delta^2 n c b) P + (4 \\delta n^2 c b - 8 \\delta^2 n c b) \\sqrt{P} + (4 \\delta^2 n c b - 4 \\delta n^2 c b)$$\n问题要求总通信量的主导项表达式。这是 $P$ 的最高次幂项。\n主导项是从边通信推导出的与 $P$ 成正比的项。\n\n主导项表达式：$4 \\delta^2 n c b P$。\n这表示在大量进程的极限情况下，由于主导通信模式（边交换），每个时间步发送的总字节数。", "answer": "$$\n\\boxed{4 \\delta^{2} n c b P}\n$$", "id": "3336971"}, {"introduction": "理论通信模型为了解并行开销提供了基础，但实际性能优化必须考虑现代硬件的复杂性。本练习聚焦于一个关键的硬件特性——非均匀内存访问（NUMA）架构，在这种架构中，数据局部性至关重要 [@problem_id:3336938]。你将为一个在多节点系统上执行的稀疏矩阵向量乘法（SpMV）操作设计一种优化的数据布局策略，通过智能地复制或划分数据，以最大限度地减少远程内存访问，从而亲身体验真实世界中的性能工程。", "problem": "考虑计算电磁学中麦克斯韦方程组空间离散化产生的稀疏旋度-旋度算子。从旋度方程出发，可得到矢量波公式，在应用基于边的有限元方法后，离散系统涉及作用于未知向量的旋度-旋度矩阵，该操作以稀疏矩阵向量乘积的形式实现。在双插槽非均匀内存访问 (NUMA) 系统中，访问内存的成本取决于数据是从本地插槽的内存还是从远程插槽的内存提供。您必须分析并最小化在两个分区上组装的旋度-旋度矩阵的稀疏矩阵向量乘积中远程内存访问的比例，并量化优化数据放置策略相对于朴素交错放置策略所能实现的加速比。\n\n基础。从麦克斯韦方程组中的旋度方程和标准的有限元离散化开始，这会导出旋度-旋度算子。离散更新涉及计算 $y = A x$，其中 $A$ 是一个稀疏矩阵， $x$ 是一个向量， $A$ 是通过跨越两个插槽的行分区组装的。假设 $A$ 以压缩稀疏行 (CSR) 格式存储，因此对于每个非零元，都会在本地读取一个 $A$ 值和一个 $A$ 的列索引。乘积 $y = A x$ 需要根据 $A$ 的非零元模式索引来读取 $x$ 的条目。在双插槽系统上，每个插槽并发处理其行分区，并读取其行所引用的 $x$ 条目的子集。假设 $A$ 的行和 $y$ 的条目被放置在其所属插槽的本地。\n\n定义。设 $C_0[i]$ 表示在一个稀疏矩阵向量乘积过程中，插槽 0 读取 $x$ 的第 $i$ 个条目的次数，设 $C_1[i]$ 表示插槽 1 读取 $x$ 的第 $i$ 个条目的次数。在插槽 $s$ 上处理的非零元总数为 $\\sum_i C_s[i]$。定义本地带宽 $B_{\\text{local}}$ (单位：字节/秒)，远程带宽 $B_{\\text{remote}}$ (单位：字节/秒)，每次访问 $x$ 读取的字节数 $b_x$ (单位：字节)，以及对于本地数据，$A$ 的每个非零元读取的字节数 $b_A$ (单位：字节)，这包括了 $A$ 的值和 $A$ 的索引。设远程访问率为 $\\rho_s$，即源自插槽 $s$ 的 $x$ 读取中远程读取所占的比例。\n\n朴素放置。通过在插槽间对 $x$ 的页进行朴素交错，每个插槽 $s$ 的 $x$ 读取中远程访问的比例约为 $\\rho_s = 0.5$，即所有 $x$ 访问的一半是远程的。\n\n优化的数据放置策略。您必须提出一种数据放置策略，通过决定将 $x$ 的哪些条目在两个插槽上复制，哪些条目专门分配给一个插槽，来最小化总体远程访问率。该决策必须遵守复制预算 $K$，$K$ 是可以在两个插槽上复制的 $x$ 条目的最大数量。对于未被复制的 $x$ 条目，您可以将每个这样的条目分配给访问它更频繁的插槽，以最小化远程读取。当访问次数相等时，您必须在该 $x$ 条目的页之间进行交错，以使每个插槽对该条目的读取有 $0.5$ 的远程比例。\n\n性能模型。对于每个插槽 $s \\in \\{0,1\\}$，处理其分区的时间由内存受限模型给出：\n$$\nT_s = \\frac{\\sum_i C_s[i]\\; b_A}{B_{\\text{local}}} + \\frac{L_s\\; b_x}{B_{\\text{local}}} + \\frac{R_s\\; b_x}{B_{\\text{remote}}},\n$$\n其中 $L_s$ 是插槽 $s$ 上的本地 $x$ 读取次数，$R_s$ 是插槽 $s$ 上的远程 $x$ 读取次数。稀疏矩阵向量乘积的总时间是：\n$$\nT = \\max\\{T_0, T_1\\}.\n$$\n优化策略相对于朴素策略的加速比是：\n$$\nS = \\frac{T_{\\text{naive}}}{T_{\\text{optimized}}}.\n$$\n\n您的程序必须纯粹以逻辑和数学术语实现以下步骤：\n- 给定 $C_0[i]$ 和 $C_1[i]$，使用两个插槽的 $\\rho_s = 0.5$ 计算 $T_{\\text{naive}}$。\n- 给定复制预算 $K$，选择最多 $K$ 个索引 $i$ 进行复制，以最小化远程 $x$ 读取的总数。对于未复制的索引，将索引 $i$ 分配给具有较大 $C_s[i]$ 的插槽；对于 $C_0[i] = C_1[i]$ 的平局情况，进行交错，使得每个插槽对该索引的读取有 $0.5$ 是远程的， $0.5$ 是本地的。然后相应地计算 $T_{\\text{optimized}}$。\n- 计算加速比 $S$。\n\n单位和输出。带宽 $B_{\\text{local}}$ 和 $B_{\\text{remote}}$ 必须以字节/秒为单位处理。量 $b_x$ 和 $b_A$ 必须以字节为单位处理。将加速比 $S$ 报告为一个无单位的浮点数。\n\n测试套件。您的程序必须运行以下一组测试用例，这些用例覆盖一般情况、高重叠、非共享分区、完全复制下的均等访问和无复制下的均等访问：\n- Case $1$: $C_0 = [120,80,10,60,70,90,5,110]$, $C_1 = [110,90,40,70,80,50,100,60]$, $K = 3$, $B_{\\text{local}} = 80 \\times 10^9$, $B_{\\text{remote}} = 30 \\times 10^9$, $b_x = 8$, $b_A = 12$.\n- Case $2$: $C_0 = [500,450,0,0,300,250,0,0]$, $C_1 = [450,500,0,0,250,300,0,0]$, $K = 2$, $B_{\\text{local}} = 90 \\times 10^9$, $B_{\\text{remote}} = 35 \\times 10^9$, $b_x = 8$, $b_A = 12$.\n- Case $3$: $C_0 = [300,0,0,0,100,0,0,0]$, $C_1 = [0,300,0,0,0,100,0,0]$, $K = 0$, $B_{\\text{local}} = 70 \\times 10^9$, $B_{\\text{remote}} = 25 \\times 10^9$, $b_x = 8$, $b_A = 12$.\n- Case $4$: $C_0 = [100,100,100,100,100,100,100,100]$, $C_1 = [100,100,100,100,100,100,100,100]$, $K = 8$, $B_{\\text{local}} = 60 \\times 10^9$, $B_{\\text{remote}} = 20 \\times 10^9$, $b_x = 8$, $b_A = 12$.\n- Case $5$: $C_0 = [50,50,50,50,50,50,50,50]$, $C_1 = [50,50,50,50,50,50,50,50]$, $K = 0$, $B_{\\text{local}} = 60 \\times 10^9$, $B_{\\text{remote}} = 20 \\times 10^9$, $b_x = 8$, $b_A = 12$.\n\n最终输出格式。您的程序应生成一行输出，其中包含五个案例的加速比结果，格式为逗号分隔的列表并用方括号括起来，例如 $[s_1,s_2,s_3,s_4,s_5]$，其中每个 $s_i$ 是一个浮点值。", "solution": "该问题要求分析双插槽非均匀内存访问 (NUMA) 系统上并行稀疏矩阵向量乘积 ($SpMV$) 的内存访问模式和性能优化。具体操作是 $y = Ax$，其中 $A$ 是一个稀疏矩阵，代表计算电磁学中有限元离散化产生的旋度-旋度算子。向量 $x$ 在两个 NUMA 插槽之间进行分区或复制，以最小化远程内存访问。我们必须计算优化数据放置策略相对于朴素策略的加速比。\n\n该分析基于一个内存受限的性能模型。对于每个插槽 $s \\in \\{0, 1\\}$，计算其部分 $SpMV$ 的时间由以下公式给出：\n$$\nT_s = T_{s,A} + T_{s,x} = \\frac{(\\sum_i C_s[i]) b_A}{B_{\\text{local}}} + \\frac{L_s b_x}{B_{\\text{local}}} + \\frac{R_s b_x}{B_{\\text{remote}}}\n$$\n这里，$C_s[i]$是插槽 $s$ 访问向量 $x$ 的第 $i$ 个元素的次数。项 $T_{s,A}$ 代表读取矩阵数据（值和索引）的时间，假设这些数据存储在本地。插槽 $s$ 上的非零元总数是 $\\sum_i C_s[i]$，$b_A$ 是每个非零元的字节数。项 $T_{s,x}$ 是读取向量 $x$ 元素的时间。$L_s$ 和 $R_s$ 分别是 $x$ 元素的本地和远程读取次数，满足 $L_s + R_s = \\sum_i C_s[i]$。$b_x$ 是 $x$ 一个元素的大小。$B_{\\text{local}}$ 和 $B_{\\text{remote}}$ 是本地和远程内存带宽。$SpMV$ 的总时间由较慢的插槽决定：$T = \\max\\{T_0, T_1\\}$。\n\n**朴素数据放置策略**\n在朴素策略下，向量 $x$ 的页在两个插槽之间交错。这意味着从一个插槽对 $x$ 的任一元素的任何给定访问有 $50\\%$ 的概率是本地的，有 $50\\%$ 的概率是远程的。因此，每个插槽 $s$ 的远程访问率 $\\rho_s$ 为 $0.5$。插槽 $s$ 的本地和远程读取次数可以建模为：\n$$\nL_{s, \\text{naive}} = 0.5 \\sum_i C_s[i]\n$$\n$$\nR_{s, \\text{naive}} = 0.5 \\sum_i C_s[i]\n$$\n使用这些值，我们可以计算 $T_{0, \\text{naive}}$ 和 $T_{1, \\text{naive}}$，总时间为 $T_{\\text{naive}} = \\max\\{T_{0, \\text{naive}}, T_{1, \\text{naive}}\\}$。\n\n**优化数据放置策略**\n优化策略旨在最小化远程内存访问的总数，给定一个复制预算 $K$，表示可以被复制到两个插槽上的 $x$ 条目的数量。\n对每个条目 $x[i]$ 的决策过程如下：\n1.  **复制**：如果一个条目 $x[i]$ 被复制，那么两个插槽对它的所有访问（即 $C_0[i]$ 和 $C_1[i]$）都将变为本地访问。\n2.  **独占放置**：如果 $x[i]$ 未被复制，它将被放置在单个插槽的本地内存中。为了最小化远程访问，它应该被放置在访问它最频繁的插槽上。例如，如果 $C_0[i] > C_1[i]$，将 $x[i]$ 放置在插槽 0上，将导致 $C_0[i]$ 次本地访问（来自插槽0）和 $C_1[i]$ 次远程访问（来自插槽1）。此条目的远程访问总数为 $\\min(C_0[i], C_1[i])$。\n3.  **交错（平局情况）**：如果 $C_0[i] = C_1[i]$ 且该条目未被复制，则进行交错。对于此条目，来自插槽 0 的访问有 $50\\%$ 是本地的， $50\\%$ 是远程的，对插槽 1 也是如此。\n\n复制条目 $x[i]$ 所节省的远程读取总数是 $\\min(C_0[i], C_1[i])$。为了在 $K$ 次复制的预算下实现远程读取的最大减少，贪心方法是最优的：识别出具有最大 $\\min(C_0[i], C_1[i])$ 值的 $K$ 个 $x$ 条目并将它们复制。\n\n优化策略的算法如下：\n1.  对于每个条目 $i$，计算如果被复制，可以减少的远程访问数：$\\text{benefit}_i = \\min(C_0[i], C_1[i])$。\n2.  选择收益最高的 $K$ 个条目进行复制。\n3.  初始化每个插槽的本地和远程访问计数：$L_{0, \\text{opt}} = R_{0, \\text{opt}} = L_{1, \\text{opt}} = R_{1, \\text{opt}} = 0$。\n4.  遍历每个条目 $x[i]$：\n    - 如果 $x[i]$ 被标记为复制：\n        - $L_{0, \\text{opt}} \\leftarrow L_{0, \\text{opt}} + C_0[i]$\n        - $L_{1, \\text{opt}} \\leftarrow L_{1, \\text{opt}} + C_1[i]$\n    - 如果 $x[i]$ 未被复制：\n        - 如果 $C_0[i] > C_1[i]$（放置在插槽 0）：\n            - $L_{0, \\text{opt}} \\leftarrow L_{0, \\text{opt}} + C_0[i]$\n            - $R_{1, \\text{opt}} \\leftarrow R_{1, \\text{opt}} + C_1[i]$\n        - 如果 $C_1[i] > C_0[i]$（放置在插槽 1）：\n            - $R_{0, \\text{opt}} \\leftarrow R_{0, \\text{opt}} + C_0[i]$\n            - $L_{1, \\text{opt}} \\leftarrow L_{1, \\text{opt}} + C_1[i]$\n        - 如果 $C_0[i] = C_1[i]$（交错）：\n            - $L_{0, \\text{opt}} \\leftarrow L_{0, \\text{opt}} + 0.5 \\cdot C_0[i]$\n            - $R_{0, \\text{opt}} \\leftarrow R_{0, \\text{opt}} + 0.5 \\cdot C_0[i]$\n            - $L_{1, \\text{opt}} \\leftarrow L_{1, \\text{opt}} + 0.5 \\cdot C_1[i]$\n            - $R_{1, \\text{opt}} \\leftarrow R_{1, \\text{opt}} + 0.5 \\cdot C_1[i]$\n5.  使用最终的计数 $L_{s, \\text{opt}}$ 和 $R_{s, \\text{opt}}$，使用性能模型计算每个插槽的 $T_{s, \\text{opt}}$。\n6.  总的优化时间是 $T_{\\text{optimized}} = \\max\\{T_{0, \\text{opt}}, T_{1, \\text{opt}}\\}$。\n\n**加速比**\n最终的性能增益由加速比来量化，即朴素执行时间与优化执行时间之比：\n$$\nS = \\frac{T_{\\text{naive}}}{T_{\\text{optimized}}}\n$$\n将为提供的每个测试用例计算此值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_speedups(test_cases):\n    \"\"\"\n    Calculates the speedup for a series of test cases based on the provided NUMA performance model.\n    \"\"\"\n    speedup_results = []\n    \n    for case in test_cases:\n        C0, C1, K, B_local, B_remote, b_x, b_A = case\n        C0 = np.array(C0, dtype=float)\n        C1 = np.array(C1, dtype=float)\n        \n        num_entries = len(C0)\n        \n        # --- Calculate Naive Time ---\n        \n        total_reads_0 = np.sum(C0)\n        total_reads_1 = np.sum(C1)\n        \n        # Naive placement: 50% of x-reads are remote for each socket\n        L0_naive = 0.5 * total_reads_0\n        R0_naive = 0.5 * total_reads_0\n        L1_naive = 0.5 * total_reads_1\n        R1_naive = 0.5 * total_reads_1\n        \n        # Time for socket 0\n        T_A_0 = (total_reads_0 * b_A) / B_local\n        T_x_0_naive = (L0_naive * b_x) / B_local + (R0_naive * b_x) / B_remote\n        T0_naive = T_A_0 + T_x_0_naive\n        \n        # Time for socket 1\n        T_A_1 = (total_reads_1 * b_A) / B_local\n        T_x_1_naive = (L1_naive * b_x) / B_local + (R1_naive * b_x) / B_remote\n        T1_naive = T_A_1 + T_x_1_naive\n        \n        T_naive = max(T0_naive, T1_naive)\n        \n        # --- Calculate Optimized Time ---\n\n        # 1. Determine which entries to replicate\n        # The benefit of replicating is avoiding min(C0[i], C1[i]) remote reads.\n        benefits = []\n        for i in range(num_entries):\n            benefit = min(C0[i], C1[i])\n            benefits.append((benefit, i))\n        \n        # Sort by benefit in descending order\n        benefits.sort(key=lambda x: x[0], reverse=True)\n        \n        replicated_indices = set()\n        if K > 0:\n            replicated_indices = {idx for benefit, idx in benefits[:K]}\n        \n        # 2. Calculate L_opt and R_opt based on the placement strategy\n        L0_opt, R0_opt = 0.0, 0.0\n        L1_opt, R1_opt = 0.0, 0.0\n        \n        for i in range(num_entries):\n            if i in replicated_indices:\n                # Replicated: all accesses are local for both sockets\n                L0_opt += C0[i]\n                L1_opt += C1[i]\n            else:\n                # Not replicated: place according to access frequency\n                if C0[i] > C1[i]:\n                    # Place on socket 0\n                    L0_opt += C0[i]  # Local accesses for socket 0\n                    R1_opt += C1[i]  # Remote accesses for socket 1\n                elif C1[i] > C0[i]:\n                    # Place on socket 1\n                    R0_opt += C0[i]  # Remote accesses for socket 0\n                    L1_opt += C1[i]  # Local accesses for socket 1\n                else: # C0[i] == C1[i]\n                    # Interleave: 50% local, 50% remote for both\n                    L0_opt += 0.5 * C0[i]\n                    R0_opt += 0.5 * C0[i]\n                    L1_opt += 0.5 * C1[i]\n                    R1_opt += 0.5 * C1[i]\n                    \n        # Time for socket 0\n        T_x_0_opt = (L0_opt * b_x) / B_local + (R0_opt * b_x) / B_remote\n        T0_opt = T_A_0 + T_x_0_opt # T_A_0 is the same as in the naive case\n        \n        # Time for socket 1\n        T_x_1_opt = (L1_opt * b_x) / B_local + (R1_opt * b_x) / B_remote\n        T1_opt = T_A_1 + T_x_1_opt # T_A_1 is the same as in the naive case\n        \n        T_optimized = max(T0_opt, T1_opt)\n        \n        # --- Calculate Speedup ---\n        speedup = T_naive / T_optimized if T_optimized > 0 else float('inf')\n        speedup_results.append(speedup)\n        \n    return speedup_results\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: General case\n        (\n            [120, 80, 10, 60, 70, 90, 5, 110], \n            [110, 90, 40, 70, 80, 50, 100, 60], \n            3, 80e9, 30e9, 8, 12\n        ),\n        # Case 2: High overlap\n        (\n            [500, 450, 0, 0, 300, 250, 0, 0], \n            [450, 500, 0, 0, 250, 300, 0, 0], \n            2, 90e9, 35e9, 8, 12\n        ),\n        # Case 3: Unshared partitions\n        (\n            [300, 0, 0, 0, 100, 0, 0, 0], \n            [0, 300, 0, 0, 0, 100, 0, 0], \n            0, 70e9, 25e9, 8, 12\n        ),\n        # Case 4: Equal access, full replication\n        (\n            [100, 100, 100, 100, 100, 100, 100, 100], \n            [100, 100, 100, 100, 100, 100, 100, 100], \n            8, 60e9, 20e9, 8, 12\n        ),\n        # Case 5: Equal access, no replication\n        (\n            [50, 50, 50, 50, 50, 50, 50, 50], \n            [50, 50, 50, 50, 50, 50, 50, 50], \n            0, 60e9, 20e9, 8, 12\n        ),\n    ]\n\n    results = calculate_speedups(test_cases)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```", "id": "3336938"}, {"introduction": "在并行算法中，实现计算与通信的重叠是隐藏通信延迟、提升效率的关键策略。然而，非阻塞通信的理想性能可能会受到网络抖动和异步进度不足等实际因素的影响。本练习提供了一个性能模型，用于量化这些动态效应对并行FDTD求解器性能的敏感性 [@problem_id:3336893]。通过分析和比较有无“进度引擎”两种情况下的性能，你将深入理解保证异步操作真正“在后台”进行的重要性，并学会评估旨在最大化计算与通信重叠度的优化措施。", "problem": "考虑一个在均匀笛卡尔网格上使用 Yee 网格方案的三维时域有限差分 (FDTD) 麦克斯韦方程求解器。Yee 方案通过从电磁学基本定律（特别是法拉第定律和安培-麦克斯韦定律）推导出的局部有限差分，在时间上推进电场 $\\mathbf{E}$ 和磁场 $\\mathbf{H}$。这些定律的微分形式为 $\\nabla \\times \\mathbf{E} = -\\partial \\mathbf{B}/\\partial t$ 和 $\\nabla \\times \\mathbf{H} = \\mathbf{J} + \\partial \\mathbf{D}/\\partial t$，其本构关系为 $\\mathbf{D} = \\varepsilon \\mathbf{E}$ 和 $\\mathbf{B} = \\mu \\mathbf{H}$。在采用空间域分解的并行实现中，每个子域在每个时间步都与其邻居交换晕轮数据，以更新边界单元。非阻塞通信（例如，消息传递接口的非阻塞操作）允许计算与通信之间可能存在的重叠。然而，网络抖动和异步消息进程的缺乏会减少这种重叠。\n\n您将分析这样一个并行 FDTD 求解器对影响非阻塞晕轮交换的网络抖动的敏感性。从第一性原理出发，对每时间步的性能进行建模，并量化在两种情景下的重叠系数和加速比：一是没有专用进程引擎的基准非阻塞通信，二是在计算阶段周期性轮询非阻塞请求以确保消息进程的提议进程引擎。\n\n使用以下基于 FDTD 算法结构和标准并行执行的建模假设：\n\n- 设子域网格维度为 $N_x$、$N_y$ 和 $N_z$ 个单元。总单元数为 $N_{\\text{cells}} = N_x N_y N_z$。\n- Yee 更新是局部的，需要邻近值；边界单元依赖于晕轮数据，而内部单元则不依赖。假设晕轮宽度为单个单元，内部单元（不接触子域任何表面的单元）的数量为 $N_{\\text{int}} = \\max\\{(N_x - 2)(N_y - 2)(N_z - 2), 0\\}$。内部单元比例为 $\\alpha = N_{\\text{int}} / N_{\\text{cells}}$。\n- 假设每次单元更新的计算成本为常数 $c_u$（单位为 $\\mathrm{s}$/单元）。每步的总计算时间为 $T_{\\text{comp}} = c_u N_{\\text{cells}}$，内部计算时间为 $T_{\\text{int}} = c_u N_{\\text{int}}$。\n- 对于一个晕轮单元宽度和每个单元三个场分量（单精度，每分量 $4$ 字节），每步的晕轮交换消息大小为 $s = 2\\big(N_y N_z + N_x N_z + N_x N_y\\big) \\cdot n_f \\cdot b$，其中 $n_f = 3$ 且 $b = 4$ 字节。因子 $2$ 表示每个轴向上的两个面。\n- 无抖动时的网络服务时间为 $T_{\\text{net}} = L + s/B$，其中 $L$ 是延迟（单位为 $\\mathrm{s}$），$B$ 是带宽（单位为 字节/$\\mathrm{s}$）。\n- 将网络抖动建模为附加期望延迟 $\\mu_j$（单位为 $\\mathrm{s}$）。缺乏异步进程意味着非阻塞通信的完成可能需要轮询。如果仅在内部计算阶段结束时进行轮询，则由轮询引起的预期附加延迟为 $T_{\\text{poll,base}} = T_{\\text{int}}/2$。使用在计算阶段以固定间隔 $\\tau_p$（单位为 $\\mathrm{s}$）进行轮询的专用进程引擎，预期的轮询延迟将减少到 $T_{\\text{poll,prog}} = \\frac{1}{2}\\min\\{\\tau_p, T_{\\text{int}}\\}$。\n- 无进程引擎时的有效通信时间为 $T_{\\text{comm,base}} = T_{\\text{net}} + \\mu_j + T_{\\text{poll,base}}$，有进程引擎时的有效通信时间为 $T_{\\text{comm,prog}} = T_{\\text{net}} + \\mu_j + T_{\\text{poll,prog}}$。\n- 在通信进行中时安排内部计算，通信完成后执行剩余的边界计算。每步时间为 $T_{\\text{step}} = T_{\\text{comp}} + T_{\\text{comm}} - \\min\\{T_{\\text{int}}, T_{\\text{comm}}\\}$。将重叠系数定义为\n$$\n\\chi = \\frac{\\min\\{T_{\\text{int}}, T_{\\text{comm}}\\}}{\\min\\{T_{\\text{comp}}, T_{\\text{comm}}\\}} \\in [0,1],\n$$\n并将（因添加进程引擎而产生的）加速比定义为 $S = T_{\\text{step,base}}/T_{\\text{step,prog}}$。\n\n您的任务是实现一个程序，为每个测试用例计算基准重叠系数 $\\chi_{\\text{base}}$、进程引擎重叠系数 $\\chi_{\\text{prog}}$ 和加速比 $S$。\n\n单位与常量：\n- 所有时间必须以 $\\mathrm{s}$ 为单位。\n- 带宽 $B$ 的单位为 字节/$\\mathrm{s}$，消息大小 $s$ 的单位为 字节。\n- 在消息大小公式中，假设 $n_f = 3$ 且 $b = 4$ 字节。\n\n测试套件参数集（每个用例提供 $(N_x, N_y, N_z, c_u, L, B, \\mu_j, \\tau_p)$）：\n- 用例 1（理想路径，中等规模，存在抖动）：$(128, 128, 64, 2.0\\times 10^{-9}\\,\\mathrm{s}, 5.0\\times 10^{-5}\\,\\mathrm{s}, 1.0\\times 10^{9}\\,\\mathrm{bytes/s}, 2.0\\times 10^{-4}\\,\\mathrm{s}, 2.0\\times 10^{-5}\\,\\mathrm{s})$。\n- 用例 2（计算受限边界条件，通信远大于计算）：$(32, 32, 32, 2.0\\times 10^{-9}\\,\\mathrm{s}, 5.0\\times 10^{-5}\\,\\mathrm{s}, 1.0\\times 10^{9}\\,\\mathrm{bytes/s}, 2.0\\times 10^{-4}\\,\\mathrm{s}, 2.0\\times 10^{-5}\\,\\mathrm{s})$。\n- 用例 3（大子域，低延迟，高带宽，近乎完美的重叠）：$(256, 128, 128, 2.0\\times 10^{-9}\\,\\mathrm{s}, 2.0\\times 10^{-5}\\,\\mathrm{s}, 4.0\\times 10^{9}\\,\\mathrm{bytes/s}, 5.0\\times 10^{-5}\\,\\mathrm{s}, 5.0\\times 10^{-5}\\,\\mathrm{s})$。\n- 用例 4（边缘用例，小子域，进程引擎开销可能有害）：$(8, 8, 8, 2.0\\times 10^{-9}\\,\\mathrm{s}, 5.0\\times 10^{-5}\\,\\mathrm{s}, 1.0\\times 10^{9}\\,\\mathrm{bytes/s}, 2.0\\times 10^{-4}\\,\\mathrm{s}, 2.0\\times 10^{-5}\\,\\mathrm{s})$。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，顺序为 $[\\chi_{\\text{base},1}, \\chi_{\\text{prog},1}, S_1, \\chi_{\\text{base},2}, \\chi_{\\text{prog},2}, S_2, \\chi_{\\text{base},3}, \\chi_{\\text{prog},3}, S_3, \\chi_{\\text{base},4}, \\chi_{\\text{prog},4}, S_4]$。每个元素必须是浮点数，加速比的单位为 $\\mathrm{s}/\\mathrm{s}$（无量纲），重叠系数为无量纲，且不含任何附加文本。", "solution": "问题陈述已经过严格验证，并被确定为有效。它在科学上基于计算电磁学和高性能计算的原理，定义清晰，提供了所有必要的定义和数据，并且其表述是客观的。因此，我们可以着手进行正式求解。\n\n该问题要求分析并行时域有限差分 (FDTD) 求解器对网络抖动的性能敏感性。我们需要为两种情景建模并计算重叠系数和性能加速比：一种是基准非阻塞通信实现，另一种是带有专用进程引擎的增强版本。解决方案是根据所提供的第一性原理和模型参数推导出来的。\n\n让我们首先将性能模型的各个组成部分形式化。\n\n单个并行进程的计算域是一个大小为 $N_x \\times N_y \\times N_z$ 单元的笛卡尔网格。每时间步更新的总单元数为：\n$$N_{\\text{cells}} = N_x N_y N_z$$\nFDTD Yee 方案使用一种需要来自直接邻居数据的计算模板。在域分解方法中，子域边界上的单元需要来自相邻子域的数据，这些数据通过晕轮交换进行通信。不接触子域表面的内部单元仅使用本地数据即可更新。假设晕轮区域为单个单元宽度，则内部单元的数量为：\n$$N_{\\text{int}} = \\max\\{(N_x - 2)(N_y - 2)(N_z - 2), 0\\}$$\n`max` 函数确保在一个或多个维度上较薄（即宽度小于 $3$ 个单元）的子域的计数为非负值。\n\n每时间步的总计算工作量被建模为单元数量的线性函数，每次单元更新的成本为常数 $c_u$。总计算时间为：\n$$T_{\\text{comp}} = c_u N_{\\text{cells}}$$\n这部分时间用于内部单元，可以与通信重叠：\n$$T_{\\text{int}} = c_u N_{\\text{int}}$$\n\n通信阶段涉及交换晕轮数据。对于一个跨所有六个面交换数据的子域，每个单元有 $n_f=3$ 个场分量，每个分量 $b=4$ 字节（单精度），总消息大小 $s$ 由下式给出：\n$$s = 2(N_y N_z + N_x N_z + N_x N_y) \\cdot n_f \\cdot b$$\n因子 $2$ 表示沿三个轴中每个轴的两个面。\n\n网络服务时间 $T_{\\text{net}}$ 使用标准的延迟-带宽模型进行建模：\n$$T_{\\text{net}} = L + \\frac{s}{B}$$\n其中 $L$ 是网络延迟， $B$ 是有效带宽。\n\n问题引入了两种情景，它们在处理非阻塞通信操作完成的方式上有所不同，特别是在存在网络抖动 $\\mu_j$ 的情况下。\n\n**情景 1：基准非阻塞通信**\n在此情景中，没有显式轮询就无法保证非阻塞消息的进程。该模型假设轮询仅在内部计算完成后发生。这会引入一个预期的轮询延迟 $T_{\\text{poll,base}}$，其值为内部计算时间间隔的一半，因为消息完成时间在该窗口内是随机的。\n$$T_{\\text{poll,base}} = \\frac{T_{\\text{int}}}{2}$$\n基准情况下的有效通信时间 $T_{\\text{comm,base}}$ 是网络服务时间、抖动引起的延迟和轮询延迟之和：\n$$T_{\\text{comm,base}} = T_{\\text{net}} + \\mu_j + T_{\\text{poll,base}}$$\n\n**情景 2：进程引擎**\n此情景引入了一个进程引擎，它在计算阶段以固定的时间间隔 $\\tau_p$ 轮询消息完成情况。这减少了预期的轮询延迟。现在的延迟是轮询间隔的一半，但不能超过基准情况下的延迟（即，轮询时间不能长于计算间隔本身）。\n$$T_{\\text{poll,prog}} = \\frac{1}{2}\\min\\{\\tau_p, T_{\\text{int}}\\}$$\n那么，使用进程引擎的有效通信时间 $T_{\\text{comm,prog}}$ 为：\n$$T_{\\text{comm,prog}} = T_{\\text{net}} + \\mu_j + T_{\\text{poll,prog}}$$\n\n有了这些组成部分，我们就可以计算两种情景下每步的总时间 $T_{\\text{step}}$。执行计划规定内部计算与通信重叠。总步长时间是所有串行和并行阶段的总和。这可以表示为总计算时间加上总通信时间，再减去它们重叠所节省的时间。重叠量受两个重叠任务中较短者的限制：$T_{\\text{int}}$ 和 $T_{\\text{comm}}$。\n$$T_{\\text{step}} = T_{\\text{comp}} + T_{\\text{comm}} - \\min\\{T_{\\text{int}}, T_{\\text{comm}}\\}$$\n将此应用于我们的两种情景，得到：\n$$T_{\\text{step,base}} = T_{\\text{comp}} + T_{\\text{comm,base}} - \\min\\{T_{\\text{int}}, T_{\\text{comm,base}}\\}$$\n$$T_{\\text{step,prog}} = T_{\\text{comp}} + T_{\\text{comm,prog}} - \\min\\{T_{\\text{int}}, T_{\\text{comm,prog}}\\}$$\n\n接下来，我们评估重叠系数 $\\chi$。问题将其定义为已实现的重叠时间与代表最大可能重叠的参考时间之比。\n$$\\chi = \\frac{\\min\\{T_{\\text{int}}, T_{\\text{comm}}\\}}{\\min\\{T_{\\text{comp}}, T_{\\text{comm}}\\}}$$\n对于我们的两种情景，该系数为：\n$$\\chi_{\\text{base}} = \\frac{\\min\\{T_{\\text{int}}, T_{\\text{comm,base}}\\}}{\\min\\{T_{\\text{comp}}, T_{\\text{comm,base}}\\}}$$\n$$\\chi_{\\text{prog}} = \\frac{\\min\\{T_{\\text{int}}, T_{\\text{comm,prog}}\\}}{\\min\\{T_{\\text{comp}}, T_{\\text{comm,prog}}\\}}$$\n该系数是无量纲的，且在 $[0, 1]$ 范围内。值为 $1$ 表示在给定约束下的理想重叠效率。\n\n最后，使用进程引擎所获得的加速比 $S$ 是基准步长时间与进程引擎步长时间之比。\n$$S = \\frac{T_{\\text{step,base}}}{T_{\\text{step,prog}}}$$\n这也是一个无量纲的量。\n\n为解决该问题，我们将实现这些公式，并将其应用于所提供的四个测试用例中的每一个，为每个用例生成三元组 $(\\chi_{\\text{base}}, \\chi_{\\text{prog}}, S)$。最终输出将是这些结果的扁平化列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates performance metrics for a parallel FDTD solver based on a\n    first-principles performance model.\n    \"\"\"\n    \n    # Test suite parameter sets.\n    # Each case provides (Nx, Ny, Nz, cu, L, B, mu_j, tau_p).\n    test_cases = [\n        (128, 128, 64, 2.0e-9, 5.0e-5, 1.0e9, 2.0e-4, 2.0e-5),\n        (32, 32, 32, 2.0e-9, 5.0e-5, 1.0e9, 2.0e-4, 2.0e-5),\n        (256, 128, 128, 2.0e-9, 2.0e-5, 4.0e9, 5.0e-5, 5.0e-5),\n        (8, 8, 8, 2.0e-9, 5.0e-5, 1.0e9, 2.0e-4, 2.0e-5),\n    ]\n\n    results = []\n    \n    # Constants for message size calculation\n    n_f = 3  # number of field components\n    b = 4    # bytes per component\n\n    for case in test_cases:\n        Nx, Ny, Nz, cu, L, B, mu_j, tau_p = case\n\n        # Step 1: Calculate cell counts\n        N_cells = float(Nx * Ny * Nz)\n        # Use np.maximum to strictly adhere to the problem's max{} notation\n        # and handle potential negative results if dimensions are  3.\n        N_int = np.maximum(0.0, float((Nx - 2) * (Ny - 2) * (Nz - 2)))\n\n        # Step 2: Calculate compute times\n        T_comp = cu * N_cells\n        T_int = cu * N_int\n\n        # Step 3: Calculate communication parameters\n        s = 2.0 * (Ny * Nz + Nx * Nz + Nx * Ny) * n_f * b\n        T_net = L + s / B\n\n        # Step 4: Calculate baseline scenario (no progress engine)\n        T_poll_base = T_int / 2.0\n        T_comm_base = T_net + mu_j + T_poll_base\n        \n        overlap_base = min(T_int, T_comm_base)\n        T_step_base = T_comp + T_comm_base - overlap_base\n        \n        chi_base_denom = min(T_comp, T_comm_base)\n        chi_base = overlap_base / chi_base_denom if chi_base_denom > 0 else 0.0\n\n        # Step 5: Calculate progress engine scenario\n        T_poll_prog = 0.5 * min(tau_p, T_int)\n        T_comm_prog = T_net + mu_j + T_poll_prog\n\n        overlap_prog = min(T_int, T_comm_prog)\n        T_step_prog = T_comp + T_comm_prog - overlap_prog\n\n        chi_prog_denom = min(T_comp, T_comm_prog)\n        chi_prog = overlap_prog / chi_prog_denom if chi_prog_denom > 0 else 0.0\n\n        # Step 6: Calculate speedup\n        S = T_step_base / T_step_prog if T_step_prog > 0 else 1.0\n        \n        results.extend([chi_base, chi_prog, S])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3336893"}]}