{"hands_on_practices": [{"introduction": "在应用任何复杂的数值方法之前，理解其基本的收敛性质至关重要。本练习将引导你从第一性原理出发，推导蒙特卡洛估计量的均方误差(MSE)。这项基础实践旨在阐明蒙特卡洛方法经典的 $\\mathcal{O}(N^{-1/2})$ 收敛率，并揭示样本量、方差与期望精度之间的核心关系 ([@problem_id:3332260])。", "problem": "在计算电磁学中，考虑一个支撑在有界域 $\\Omega \\subset \\mathbb{R}^{3}$ 上的电流分布 $\\mathbf{J}(\\mathbf{r})$，在一个固定观测点 $\\mathbf{r}_{0}$ 处产生电场的频域表示。该电场可以写成一个体积分\n$$\nI \\equiv \\int_{\\Omega} \\mathbf{G}(\\mathbf{r}_{0},\\mathbf{r}) \\cdot \\mathbf{J}(\\mathbf{r}) \\,\\mathrm{d}\\mathbf{r},\n$$\n其中 $\\mathbf{G}(\\mathbf{r}_{0},\\mathbf{r})$ 是电磁并矢格林函数，$\\cdot$ 表示 Euclidean 内积。为了对 $I$ 进行数值计算，采用蒙特卡罗重要性采样方法，其概率密度函数为 $p(\\mathbf{r})$，该函数在 $\\Omega$ 上严格为正，且关于 Lebesgue 测度是绝对连续的。定义随机变量\n$$\nW \\equiv \\frac{f(X)}{p(X)}, \\quad \\text{其中} \\quad f(\\mathbf{r}) \\equiv \\mathbf{G}(\\mathbf{r}_{0},\\mathbf{r}) \\cdot \\mathbf{J}(\\mathbf{r}), \\quad X \\sim p,\n$$\n并使用 $N$ 个独立同分布的样本 $\\{X_{i}\\}_{i=1}^{N}$ 来构建估计量\n$$\nI_{N} \\equiv \\frac{1}{N}\\sum_{i=1}^{N}\\frac{f(X_{i})}{p(X_{i})}.\n$$\n假设 $\\mathbb{E}[W^{2}] \\infty$，从而方差 $\\sigma^{2} \\equiv \\mathrm{Var}(W)$ 是有限的。从第一性原理出发，也即根据蒙特卡罗估计量的无偏性定义以及独立同分布随机变量均值的方差，推导 $I_{N}$ 的均方误差 $\\mathbb{E}\\!\\left[(I_{N}-I)^{2}\\right]$ 的闭式表达式，并用 $\\sigma^{2}$ 和 $N$ 表示。然后，给定均方误差的目标容差 $\\varepsilon > 0$，确定保证 $\\mathbb{E}\\!\\left[(I_{N}-I)^{2}\\right]\\leq \\varepsilon^{2}$ 的最小 $N$，并以 $\\sigma^{2}$ 和 $\\varepsilon$ 的闭式表达式给出。最后，给出此最小 $N$ 的连续近似，并证明其可化为标准的蒙特卡罗复杂度标度。最终答案必须是关于 $N$ 的单个解析表达式，不带单位。", "solution": "本题要求推导蒙特卡罗估计量的均方误差 (MSE)，确定满足给定误差容差的最小样本量 $N$，并分析该样本量的连续近似。推导应从第一性原理出发。\n\n首先，我们分析估计量 $I_{N}$ 的性质。题目将所求积分定义为 $I \\equiv \\int_{\\Omega} f(\\mathbf{r}) \\,\\mathrm{d}\\mathbf{r}$，其中 $f(\\mathbf{r}) \\equiv \\mathbf{G}(\\mathbf{r}_{0},\\mathbf{r}) \\cdot \\mathbf{J}(\\mathbf{r})$。蒙特卡罗方法利用重要性采样，通过一个概率密度函数 (PDF) $p(\\mathbf{r})$ 来估计该积分。从此分布中抽取一个随机变量 $X$，即 $X \\sim p$。该估计量由 $N$ 个独立同分布 (i.i.d.) 的样本 $\\{X_{i}\\}_{i=1}^{N}$ 构建而成。\n\n该方法的核心在于随机变量 $W \\equiv \\frac{f(X)}{p(X)}$。我们首先计算其期望值 $\\mathbb{E}[W]$。根据连续随机变量期望的定义，可得：\n$$\n\\mathbb{E}[W] = \\int_{\\Omega} \\frac{f(\\mathbf{r})}{p(\\mathbf{r})} p(\\mathbf{r}) \\,\\mathrm{d}\\mathbf{r} = \\int_{\\Omega} f(\\mathbf{r}) \\,\\mathrm{d}\\mathbf{r} = I.\n$$\n这表明单个加权样本的期望值就是我们希望计算的积分 $I$。\n\n接下来，我们证明估计量 $I_{N} \\equiv \\frac{1}{N}\\sum_{i=1}^{N} W_{i}$ (其中 $W_{i} \\equiv \\frac{f(X_{i})}{p(X_{i})}$) 是 $I$ 的一个无偏估计量。利用期望算子的线性性：\n$$\n\\mathbb{E}[I_{N}] = \\mathbb{E}\\left[\\frac{1}{N}\\sum_{i=1}^{N} W_{i}\\right] = \\frac{1}{N}\\sum_{i=1}^{N}\\mathbb{E}[W_{i}].\n$$\n由于样本 $\\{X_{i}\\}$ 是同分布的，因此随机变量 $\\{W_{i}\\}$ 也是同分布的。因此，对于所有 $i \\in \\{1, 2, \\dots, N\\}$，都有 $\\mathbb{E}[W_{i}] = \\mathbb{E}[W] = I$。将此结果代入 $\\mathbb{E}[I_{N}]$ 的表达式，可得：\n$$\n\\mathbb{E}[I_{N}] = \\frac{1}{N}\\sum_{i=1}^{N} I = \\frac{1}{N}(NI) = I.\n$$\n因此，估计量 $I_{N}$ 是无偏的。\n\n现在，我们来推导估计量的均方误差 (MSE)，其定义为 $\\mathbb{E}[(I_{N}-I)^{2}]$。由于 $I = \\mathbb{E}[I_{N}]$，均方误差等价于估计量 $I_{N}$ 的方差：\n$$\n\\mathbb{E}[(I_{N}-I)^{2}] = \\mathbb{E}[(I_{N}-\\mathbb{E}[I_{N}])^{2}] \\equiv \\mathrm{Var}(I_{N}).\n$$\n我们继续计算 $\\mathrm{Var}(I_{N})$：\n$$\n\\mathrm{Var}(I_{N}) = \\mathrm{Var}\\left(\\frac{1}{N}\\sum_{i=1}^{N} W_{i}\\right).\n$$\n使用方差性质 $\\mathrm{Var}(aY) = a^{2}\\mathrm{Var}(Y)$，并取 $a = 1/N$，我们得到：\n$$\n\\mathrm{Var}(I_{N}) = \\frac{1}{N^{2}}\\mathrm{Var}\\left(\\sum_{i=1}^{N} W_{i}\\right).\n$$\n题目指出样本 $\\{X_{i}\\}$ 是独立的。这意味着随机变量 $\\{W_{i}\\}$ 也是独立的。对于独立随机变量之和，其和的方差等于方差之和：\n$$\n\\mathrm{Var}\\left(\\sum_{i=1}^{N} W_{i}\\right) = \\sum_{i=1}^{N}\\mathrm{Var}(W_{i}).\n$$\n由于 $\\{W_{i}\\}$ 也是同分布的，它们的方差相等。题目将这个公共方差定义为 $\\sigma^{2} \\equiv \\mathrm{Var}(W)$。注意到，由于 $\\mathrm{Var}(W) = \\mathbb{E}[W^{2}] - (\\mathbb{E}[W])^{2}$，这个有限方差的存在是由 $\\mathbb{E}[W^{2}]  \\infty$ 的假设保证的。因此，对于所有 $i$，$\\mathrm{Var}(W_{i}) = \\sigma^{2}$。\n$$\n\\sum_{i=1}^{N}\\mathrm{Var}(W_{i}) = \\sum_{i=1}^{N}\\sigma^{2} = N\\sigma^{2}.\n$$\n将此结果代回 $\\mathrm{Var}(I_{N})$ 的表达式中，便得到均方误差的闭式表达式：\n$$\n\\mathbb{E}[(I_{N}-I)^{2}] = \\mathrm{Var}(I_{N}) = \\frac{1}{N^{2}}(N\\sigma^{2}) = \\frac{\\sigma^{2}}{N}.\n$$\n\n第二个任务是找到最小整数 $N$，以保证均方误差不大于指定的容差 $\\varepsilon^{2}$（其中 $\\varepsilon > 0$）。该条件为：\n$$\n\\mathbb{E}[(I_{N}-I)^{2}] \\leq \\varepsilon^{2}.\n$$\n代入我们推导出的均方误差表达式：\n$$\n\\frac{\\sigma^{2}}{N} \\leq \\varepsilon^{2}.\n$$\n假设在 $\\sigma^{2} > 0$ 的非平凡情况下，我们可以整理该不等式来求解 $N$：\n$$\nN \\geq \\frac{\\sigma^{2}}{\\varepsilon^{2}}.\n$$\n由于 $N$ 必须是代表样本数量的整数，满足此条件的 $N$ 的最小值是大于或等于 $\\frac{\\sigma^{2}}{\\varepsilon^{2}}$ 的最小整数。这对应于上取整函数（ceiling function）：\n$$\nN_{\\min} = \\left\\lceil \\frac{\\sigma^{2}}{\\varepsilon^{2}} \\right\\rceil.\n$$\n\n最后的任务是给出此最小 $N$ 的连续近似并分析其标度性质。当样本数量很大时，一个数与其上取整之间的差异可以忽略不计。因此，我们可以通过舍去上取整函数来近似最小 $N$：\n$$\nN \\approx \\frac{\\sigma^{2}}{\\varepsilon^{2}}.\n$$\n此表达式揭示了蒙特卡罗方法的标准复杂度标度。均方根误差 (RMSE)，即估计量的标准差，为 $\\sqrt{\\mathbb{E}[(I_{N}-I)^{2}]} = \\sqrt{\\frac{\\sigma^{2}}{N}} = \\frac{\\sigma}{\\sqrt{N}}$。如果我们将此 RMSE 设为容差 $\\varepsilon$，则有 $\\varepsilon = \\frac{\\sigma}{\\sqrt{N}}$，整理后得到 $N = \\frac{\\sigma^{2}}{\\varepsilon^{2}}$。这表明，要达到期望的误差容差 $\\varepsilon$，所需的样本数 $N$ 与 $\\varepsilon^{-2}$ 成正比，即 $N = \\mathcal{O}(\\varepsilon^{-2})$。等价地，误差以 $\\varepsilon = \\mathcal{O}(N^{-1/2})$ 的速率收敛。这是标准蒙特卡罗积分的典型收敛率，我们的推导证实了该估计量遵循此特征标度律。", "answer": "$$\n\\boxed{\\frac{\\sigma^{2}}{\\varepsilon^{2}}}\n$$", "id": "3332260"}, {"introduction": "理论掌握之后，我们转向一个计算电磁学中的常见挑战：奇异核函数的积分。本练习将演示如何运用方差缩减技术，特别是分层抽样，来有效处理这类问题 ([@problem_id:3332310])。通过构建并对比一个正确和一个错误的抽样方案，你将深刻理解权重分配在保证估计无偏性中的关键作用，尤其是在奇异点附近。", "problem": "给定一个计算电磁学背景，其中边界积分公式涉及奇异核，在 $\\mathbf{r}' = \\mathbf{r}$ 附近，其行为类似于 $1/\\lvert \\mathbf{r} - \\mathbf{r}' \\rvert$。考虑一个观测点 $\\mathbf{r}$ 周围的局部平面片，该点位于边界边缘附近，使得积分区域为一个楔形扇区。在表面上，使用极坐标 $(\\rho,\\theta)$ 中的标量函数 $f(\\rho,\\theta) = 1/\\rho$ 对奇异核进行局部建模。设积分域为楔形环\n$$\n\\mathcal{D}(\\alpha,\\varepsilon,R) = \\left\\{ (\\rho,\\theta)\\,:\\, \\varepsilon \\le \\rho \\le R,\\; -\\frac{\\alpha}{2} \\le \\theta \\le \\frac{\\alpha}{2} \\right\\},\n$$\n其中 $\\varepsilon$ 是一个小的正排除半径（用于正则化奇异性），$R$ 是局部片的外半径，$\\alpha$ 是楔形孔径角。角度以弧度为单位，所有长度以米为单位。所关心的积分是\n$$\nI(\\alpha,\\varepsilon,R) = \\iint_{\\mathcal{D}(\\alpha,\\varepsilon,R)} \\frac{1}{\\rho}\\,\\mathrm{d}A,\n$$\n其中 $\\mathrm{d}A = \\rho\\,\\mathrm{d}\\rho\\,\\mathrm{d}\\theta$。\n\n您的任务是构建并分析一个适用于在奇异点附近估计 $I(\\alpha,\\varepsilon,R)$ 的蒙特卡洛 (MC) 估计器的分层抽样方案，并与均匀面积 MC 估计器进行比较。该分析必须量化在奇异点处对偏差的影响。从第一性原理出发，仅使用核心定义和已验证的事实；不要假设任何预先推导的捷径公式。\n\n1. 从积分 $I(\\alpha,\\varepsilon,R)$ 的定义和面积元 $\\mathrm{d}A = \\rho\\,\\mathrm{d}\\rho\\,\\mathrm{d}\\theta$ 出发，推导 $I(\\alpha,\\varepsilon,R)$ 关于 $\\alpha$、$\\varepsilon$ 和 $R$ 的精确闭式表达式。最终结果以米表示。\n\n2. 定义楔形环的总面积\n$$\nA_{\\text{tot}}(\\alpha,\\varepsilon,R) = \\frac{\\alpha}{2}\\left(R^2 - \\varepsilon^2\\right).\n$$\n描述一个正确的将径向区间 $[\\varepsilon,R]$ 划分为 $K$ 个面积相等的层的分层抽样方案，并解释如何对各层的估计进行加权以生成 $I(\\alpha,\\varepsilon,R)$ 的无偏估计器。然后，定义一个错误的将径向区间划分为 $K$ 个等宽区间但在估计 $I(\\alpha,\\varepsilon,R)$ 时对每个区间的均值分配相等权重的分层方案，并解释为什么它在奇异点附近是有偏的。\n\n3. 对于错误的方案，考虑将每区间均值的未加权平均乘以 $A_{\\text{tot}}(\\alpha,\\varepsilon,R)$ 的估计器。计算该估计器的期望值，并推导其相对于精确积分的偏差。您的推导应明确使用 $K$ 个区间边界表示，并且必须揭示偏差如何依赖于 $\\varepsilon$ 和 $K$。偏差以米表示。\n\n4. 实现一个程序，使用确定性计算而非随机抽样，为每个测试用例输出三种估计器的偏差：\n   - 具有正确面积加权的均匀面积 MC 估计器（预期偏差将进行解析计算）。\n   - 具有 $K$ 个等面积径向分层和正确面积加权的正确分层估计器。\n   - 具有 $K$ 个等宽径向分层和每区间均值等权重、并由 $A_{\\text{tot}}(\\alpha,\\varepsilon,R)$ 缩放的错误分层估计器。\n\n使用以下参数值测试套件，它涵盖了内部点、边界边缘点和近角点行为：\n- 测试用例 1：$\\alpha = 2\\pi$（全圆盘），$\\varepsilon = 10^{-3}\\,\\mathrm{m}$，$R = 1.0\\,\\mathrm{m}$，$K = 8$。\n- 测试用例 2：$\\alpha = \\pi$（半圆盘），$\\varepsilon = 10^{-6}\\,\\mathrm{m}$，$R = 1.0\\,\\mathrm{m}$，$K = 16$。\n- 测试用例 3：$\\alpha = \\pi/4$（窄楔形），$\\varepsilon = 10^{-8}\\,\\mathrm{m}$，$R = 0.2\\,\\mathrm{m}$，$K = 12$。\n- 测试用例 4：$\\alpha = 2\\pi$（全圆盘），$\\varepsilon = 0.5\\,\\mathrm{m}$，$R = 1.0\\,\\mathrm{m}$，$K = 4$。\n\n每个测试用例应生成一个包含三个浮点数的列表，单位为米：$\\left[\\text{bias}_{\\text{uniform}}, \\text{bias}_{\\text{strat-correct}}, \\text{bias}_{\\text{strat-wrong}}\\right]$。\n\n最终输出格式：您的程序应生成单行输出，包含一个由方括号括起来的逗号分隔列表，其中每个元素本身就是对应一个测试用例的列表。例如，\n$$\n\\left[ [b_{1,1},\\,b_{1,2},\\,b_{1,3}],\\; [b_{2,1},\\,b_{2,2},\\,b_{2,3}],\\; [b_{3,1},\\,b_{3,2},\\,b_{3,3}],\\; [b_{4,1},\\,b_{4,2},\\,b_{4,3}] \\right].\n$$\n所有角度必须以弧度为单位，所有输出必须以米为单位表示为十进制数。", "solution": "该问题要求分析和比较用于计算电磁学中出现的奇异积分的不同蒙特卡洛 (MC) 积分方案。分析分四个部分进行：首先，直接计算积分；其次，对两种分层抽样方案进行概念性描述；第三，对其中一种方案的偏差进行定量推导；第四，对一系列测试用例，确定性地数值计算三种估计器的偏差。\n\n### 1. 积分的精确计算\n\n所关心的积分由下式给出\n$$\nI(\\alpha,\\varepsilon,R) = \\iint_{\\mathcal{D}(\\alpha,\\varepsilon,R)} \\frac{1}{\\rho}\\,\\mathrm{d}A\n$$\n积分域为楔形环 $\\mathcal{D}(\\alpha,\\varepsilon,R) = \\{ (\\rho,\\theta) \\mid \\varepsilon \\le \\rho \\le R, \\; -\\alpha/2 \\le \\theta \\le \\alpha/2 \\}$，其中 $\\rho$ 是径向坐标，$\\theta$ 是角坐标，$\\varepsilon$ 是内半径，$R$ 是外半径，$\\alpha$ 是总孔径角。极坐标下的微分面积元为 $\\mathrm{d}A = \\rho\\,\\mathrm{d}\\rho\\,\\mathrm{d}\\theta$。\n\n将面积元代入积分表达式，我们得到：\n$$\nI(\\alpha,\\varepsilon,R) = \\int_{-\\alpha/2}^{\\alpha/2} \\int_{\\varepsilon}^{R} \\frac{1}{\\rho} (\\rho\\,\\mathrm{d}\\rho\\,\\mathrm{d}\\theta)\n$$\n来自面积元的项 $\\rho$ 与被积函数中的奇异项 $1/\\rho$ 相抵消，这个过程称为奇异性抵消，是这类极坐标积分的一个关键特征。积分简化为：\n$$\nI(\\alpha,\\varepsilon,R) = \\int_{-\\alpha/2}^{\\alpha/2} \\int_{\\varepsilon}^{R} 1\\,\\mathrm{d}\\rho\\,\\mathrm{d}\\theta\n$$\n现在被积函数是一个常数，积分对于变量 $\\rho$ 和 $\\theta$ 是可分离的。我们可以独立地计算这两个积分：\n$$\n\\int_{-\\alpha/2}^{\\alpha/2} \\mathrm{d}\\theta = \\left[\\theta\\right]_{-\\alpha/2}^{\\alpha/2} = \\frac{\\alpha}{2} - \\left(-\\frac{\\alpha}{2}\\right) = \\alpha\n$$\n$$\n\\int_{\\varepsilon}^{R} \\mathrm{d}\\rho = \\left[\\rho\\right]_{\\varepsilon}^{R} = R - \\varepsilon\n$$\n将这些结果相乘，得到积分的精确闭式表达式：\n$$\nI(\\alpha,\\varepsilon,R) = \\alpha(R - \\varepsilon)\n$$\n由于 $\\alpha$ 以弧度（无量纲）为单位，而 $R$ 和 $\\varepsilon$ 都以米 ($m$) 为单位，因此 $I$ 的单位是米，符合要求。\n\n### 2. 分层抽样方案分析\n\n蒙特卡洛积分的基本原理是通过随机变量 $\\hat{I} = A_{\\text{tot}} \\cdot \\bar{f}$ 来估计积分 $I = \\int_{\\mathcal{D}} f(x) \\, \\mathrm{d}A$，其中 $\\bar{f}$ 是在从总面积为 $A_{\\text{tot}}$ 的域 $\\mathcal{D}$ 中均匀抽样的 $N$ 个点 $x_i$ 上计算的 $f(x_i)$ 的平均值。该估计器是无偏的，因为其期望值为 $E[\\hat{I}] = I$。\n\n分层抽样将域 $\\mathcal{D}$ 划分为 $K$ 个面积为 $A_k$ 的不相交层 $\\mathcal{D}_k$。计算每层上的积分估计值 $I_k = \\int_{\\mathcal{D}_k} f(x)\\,\\mathrm{d}A$。总估计值是各层估计值之和，$\\hat{I}_{\\text{strat}} = \\sum_{k=1}^K \\hat{I}_k$。一个正确加权的估计器保持无偏。对此类估计器期望值的确定性计算涉及使用函数在每层内的真实均值 $\\bar{f}_k = I_k/A_k$。\n\n**正确的分层方案（等面积分层）**\n该方案将域划分为 $K$ 个面积相等的层。由于半径 $\\rho_{k-1}$ 和 $\\rho_k$ 之间的层的面积为 $A_k = \\frac{\\alpha}{2}(\\rho_k^2 - \\rho_{k-1}^2)$，使所有 $A_k$ 等于 $A_{\\text{tot}}/K$ 意味着 $\\rho_k^2 - \\rho_{k-1}^2$ 必须为常数。这导致径向边界为：\n$$\n\\rho_k = \\sqrt{\\varepsilon^2 + \\frac{k}{K}(R^2 - \\varepsilon^2)} \\quad \\text{for } k=0, 1, \\dots, K\n$$\n正确的分层估计器按其面积对每层的贡献进行加权。该估计器的期望值（或其确定性等价物）是：\n$$\nE[\\hat{I}_{\\text{strat-correct}}] = \\sum_{k=1}^K I_k = \\sum_{k=1}^K \\iint_{\\mathcal{D}_k} f(\\rho,\\theta)\\,\\mathrm{d}A = I(\\alpha,\\varepsilon,R)\n$$\n由于其期望值等于积分的真实值，因此该估计器是无偏的。其偏差恰好为 $0$。\n\n**错误的分层方案（等宽径向区间，等权重）**\n该方案将径向区间 $[\\varepsilon, R]$ 划分为 $K$ 个等宽的区间，宽度为 $\\Delta\\rho = (R-\\varepsilon)/K$，边界为 $\\rho_k = \\varepsilon + k \\cdot \\Delta\\rho$。所得分层的面积 $A_k = \\frac{\\alpha}{2}(\\rho_k^2 - \\rho_{k-1}^2)$ 不相等；它们随 $k$ 增大而增大。\n\n指定的错误估计器形式如下：\n$$\n\\hat{I}_{\\text{strat-wrong}} = A_{\\text{tot}} \\left( \\frac{1}{K} \\sum_{k=1}^K \\bar{f}_k \\right)\n$$\n其中 $\\bar{f}_k = I_k/A_k$ 是函数 $f$ 在第 $k$ 层的真实均值。该估计器是有偏的，因为它计算了各层函数平均值 $\\bar{f}_k$ 的未加权算术平均。正确的总积分是各层积分之和，$I = \\sum I_k = \\sum A_k \\bar{f}_k$。对应的 $f$ 在整个域上的真实平均值为 $\\bar{f} = I/A_{\\text{tot}} = \\sum (A_k/A_{\\text{tot}}) \\bar{f}_k$，这是一个加权平均。通过使用相等的权重（$1/K$）而不是正确的与面积成比例的权重（$A_k/A_{\\text{tot}}$），该估计器错误地表示了函数的整体平均值，从而导致偏差。这种偏差在奇异点附近（$\\rho$ 很小）尤其严重，因为在那里 $f=1/\\rho$ 很大，但分层面积很小。错误的方案给予这个小区域内的大函数平均值与最大区域内的小函数平均值相同的权重，导致系统性高估。\n\n### 3. 错误方案的偏差推导\n\n估计器 $\\hat{I}$ 的偏差定义为 $B = E[\\hat{I}] - I$。对于错误的分层估计器，我们首先计算其期望值 $E[\\hat{I}_{\\text{strat-wrong}}]$。\n\n函数 $f(\\rho,\\theta) = 1/\\rho$ 在第 $k$ 层 $\\mathcal{D}_k$（由半径 $\\rho_{k-1}$ 和 $\\rho_k$ 定义）中的均值为：\n$$\n\\bar{f}_k = \\frac{\\int_{\\mathcal{D}_k} f(\\rho,\\theta)\\,\\mathrm{d}A}{\\int_{\\mathcal{D}_k} \\mathrm{d}A} = \\frac{I_k}{A_k} = \\frac{\\alpha(\\rho_k - \\rho_{k-1})}{\\frac{\\alpha}{2}(\\rho_k^2 - \\rho_{k-1}^2)} = \\frac{2(\\rho_k - \\rho_{k-1})}{(\\rho_k - \\rho_{k-1})(\\rho_k + \\rho_{k-1})} = \\frac{2}{\\rho_k + \\rho_{k-1}}\n$$\n等宽区间的边界为 $\\rho_k = \\varepsilon + k \\frac{R-\\varepsilon}{K}$，其中 $k=0, \\dots, K$。\n\n错误估计器的期望值为：\n$$\nE[\\hat{I}_{\\text{strat-wrong}}] = A_{\\text{tot}} \\left( \\frac{1}{K} \\sum_{k=1}^K \\bar{f}_k \\right) = \\frac{A_{\\text{tot}}}{K} \\sum_{k=1}^K \\frac{2}{\\rho_k + \\rho_{k-1}}\n$$\n代入 $A_{\\text{tot}} = \\frac{\\alpha}{2}(R^2 - \\varepsilon^2)$，我们得到：\n$$\nE[\\hat{I}_{\\text{strat-wrong}}] = \\frac{\\alpha(R^2 - \\varepsilon^2)}{2K} \\sum_{k=1}^K \\frac{2}{\\varepsilon + k\\frac{R-\\varepsilon}{K} + \\varepsilon + (k-1)\\frac{R-\\varepsilon}{K}} = \\frac{\\alpha(R^2 - \\varepsilon^2)}{K} \\sum_{k=1}^K \\frac{1}{2\\varepsilon + (2k-1)\\frac{R-\\varepsilon}{K}}\n$$\n偏差是该期望值与真实积分值 $I = \\alpha(R - \\varepsilon)$ 之间的差：\n$$\nB_{\\text{strat-wrong}} = E[\\hat{I}_{\\text{strat-wrong}}] - I = \\left( \\frac{\\alpha(R^2 - \\varepsilon^2)}{K} \\sum_{k=1}^K \\frac{1}{2\\varepsilon + (2k-1)\\frac{R-\\varepsilon}{K}} \\right) - \\alpha(R - \\varepsilon)\n$$\n此表达式揭示了偏差是所有参数 $\\alpha, \\varepsilon, R, K$ 的函数。求和项受到 $k$ 较小的前几项的严重影响，它量化了不正确的平均如何过高地加权了靠近 $\\rho = \\varepsilon$ 的奇异区域的贡献。\n\n### 4. 偏差的确定性计算\n\n程序必须计算三种估计器的偏差。\n1.  **均匀面积 MC 估计器**：如前所述，从面积中均匀抽样的标准 MC 估计器是无偏的。因此，$E[\\hat{I}_{\\text{uniform}}] = I$，其偏差为 $B_{\\text{uniform}} = 0$。\n2.  **正确的分层估计器**：如前所述，正确加权的分层抽样方案是无偏的，无论分层策略如何（等面积或其他）。因此，$E[\\hat{I}_{\\text{strat-correct}}] = I$，其偏差为 $B_{\\text{strat-correct}} = 0$。\n3.  **错误的分层估计器**：偏差 $B_{\\text{strat-wrong}}$ 使用上一节中推导的公式计算。\n\n因此，该实现将为每个测试用例计算 $[0.0, 0.0, B_{\\text{strat-wrong}}]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by deterministically calculating the bias of three\n    Monte Carlo estimators for a singular integral in computational electromagnetics.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (alpha, epsilon, R, K)\n        (2 * np.pi, 1e-3, 1.0, 8),\n        (np.pi, 1e-6, 1.0, 16),\n        (np.pi / 4, 1e-8, 0.2, 12),\n        (2 * np.pi, 0.5, 1.0, 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        alpha, epsilon, R, K = case\n\n        # 1. Uniform-area MC estimator bias\n        # The standard uniform-area MC estimator is unbiased by construction.\n        # Its expected value is the true integral value.\n        bias_uniform = 0.0\n\n        # 2. Correct stratified estimator bias\n        # A correctly weighted stratified sampling scheme is also unbiased by construction.\n        # Its expected value is the sum of the exact integrals over the strata.\n        bias_strat_correct = 0.0\n\n        # 3. Incorrect stratified estimator bias\n        \n        # Calculate the exact value of the integral\n        I_exact = alpha * (R - epsilon)\n\n        # Calculate the total area of the integration domain\n        A_tot = (alpha / 2.0) * (R**2 - epsilon**2)\n\n        # Calculate the expected value of the incorrect estimator\n        # This estimator uses equal-width radial bins and unweighted averaging of\n        # per-stratum function means.\n        \n        delta_rho = (R - epsilon) / K\n        sum_f_bar = 0.0\n        for k in range(1, K + 1):\n            rho_k_minus_1 = epsilon + (k - 1) * delta_rho\n            rho_k = epsilon + k * delta_rho\n            \n            # The mean value of f=1/rho in the k-th stratum is 2 / (rho_k + rho_{k-1})\n            f_bar_k = 2.0 / (rho_k + rho_k_minus_1)\n            sum_f_bar += f_bar_k\n            \n        # Expected value of the estimator\n        E_wrong = (A_tot / K) * sum_f_bar\n        \n        # Bias of the incorrect estimator\n        bias_strat_wrong = E_wrong - I_exact\n\n        results.append([bias_uniform, bias_strat_correct, bias_strat_wrong])\n\n    # Format the final output string according to the problem specification.\n    # The output should be a single line representing a list of lists.\n    outer_parts = []\n    for sublist in results:\n        # Use a high-precision format for the floating point numbers\n        inner_parts = [f\"{x:.15e}\" for x in sublist]\n        outer_parts.append(f\"[{','.join(inner_parts)}]\")\n    final_string = f\"[{','.join(outer_parts)}]\"\n\n    # Final print statement in the exact required format.\n    print(final_string)\n\nsolve()\n```", "id": "3332310"}, {"introduction": "最后，我们将蒙特卡洛方法的应用拓展到更前沿的领域：不确定性下的设计优化。本练习将深入探讨随机优化的核心，即梯度估计问题 ([@problem_id:3332261])。你将从第一性原理推导并实现两种主流的梯度估计方法——路径导数法和得分函数法，并通过数值实验比较它们的性能，从而直观地理解不同方法在实现复杂度和估计量方差之间的权衡。", "problem": "考虑一个简化的计算电磁学设定，其中一个单谐振双端口天线的行为类似于一个带通系统，其功率传输由洛伦兹响应表征。目标泛函定义为频带内积分的传输功率\n$$\nJ(\\theta) \\equiv \\int_{\\omega_{\\min}}^{\\omega_{\\max}} \\lvert S_{21}(\\omega; \\theta, \\epsilon_{\\mathrm{eff}}) \\rvert^2 \\, d\\omega,\n$$\n其中 $\\theta \\in \\mathbb{R}$ 是一个标量形状参数，$\\epsilon_{\\mathrm{eff}}$ 是一个用于模拟材料不确定性的有效介电常数随机变量。为避免单位转换问题，本问题中的所有量均为无量纲量。频带由固定的有限边界 $\\omega_{\\min}$ 和 $\\omega_{\\max}$ 指定，角频率 $\\omega$ 是无量纲的。幅度平方传输由单极点洛伦兹函数建模\n$$\n\\lvert S_{21}(\\omega; \\theta, \\epsilon_{\\mathrm{eff}}) \\rvert^2 = \\frac{\\Gamma^2}{(\\omega - \\omega_0(\\theta,\\epsilon_{\\mathrm{eff}}))^2 + \\Gamma^2},\n$$\n其中带宽参数 $\\Gamma > 0$ 固定，谐振频率为\n$$\n\\omega_0(\\theta,\\epsilon_{\\mathrm{eff}}) = \\frac{\\pi}{L(\\theta)\\sqrt{\\epsilon_{\\mathrm{eff}}}},\n$$\n其中谐振长度依赖于形状参数，关系如下\n$$\nL(\\theta) = L_0 \\left(1 + \\beta \\theta\\right),\n$$\n其中 $L_0 > 0$ 和 $\\beta$ 为固定值，且对于所有测试的 $\\theta$，都有 $1 + \\beta \\theta > 0$。有效介电常数由场填充混合物建模\n$$\n\\epsilon_{\\mathrm{eff}}(\\theta,\\xi) = \\bigl(1 - F(\\theta)\\bigr)\\,\\epsilon_{\\mathrm{air}} + F(\\theta)\\,\\epsilon_{\\mathrm{mat}},\n$$\n其中填充因子 $F(\\theta) = F_0 + \\kappa \\theta$ 在所有测试案例中满足 $0  F(\\theta)  1$，$\\epsilon_{\\mathrm{air}}$ 是固定的，$\\epsilon_{\\mathrm{mat}}$ 是一个标量随机介电常数，其分布为\n$$\n\\epsilon_{\\mathrm{mat}} \\sim \\mathcal{N}(\\mu, \\sigma^2).\n$$\n这种随机性可以通过重参数化 $\\epsilon_{\\mathrm{mat}} = \\mu + \\sigma \\xi$ 表示为一个标准正态变量 $\\xi \\sim \\mathcal{N}(0,1)$。因此，$\\epsilon_{\\mathrm{eff}}$ 的导出分布是高斯分布，其均值和标准差通过 $F(\\theta)$ 依赖于 $\\theta$。\n\n你的任务是从第一性原理出发，推导出 $\\nabla_{\\theta} \\mathbb{E}[J(\\theta)]$ 的两个无偏蒙特卡罗梯度估计器：\n- 一个路径导数（重参数化）梯度估计器，它在关于 $\\xi$ 的期望内部对 $J(\\theta,\\epsilon_{\\mathrm{eff}}(\\theta,\\xi))$ 关于 $\\theta$ 求导。\n- 一个得分函数（似然比）梯度估计器，它将 $\\epsilon_{\\mathrm{eff}}$ 视为从一个依赖于 $\\theta$ 的密度函数中的一次抽样，并使用关于分布参数的期望求导的恒等式，同时考虑 $J$ 对 $\\theta$ 的任何显式依赖。\n\n你必须从散射参数和谐振模型的定义、参数化概率密度下的期望定义，以及积分号下微分法则出发。不要假定或引用任何给定的梯度估计器公式；从这些基础出发进行推导。然后，在以下离散近似设定中，实现这两个梯度估计器，并通过蒙特卡罗方法凭经验比较它们的单样本估计器方差：\n- 在 $[\\omega_{\\min}, \\omega_{\\max}]$ 上使用一个包含 $N_{\\omega}$ 个点的均匀网格，间距为 $\\Delta \\omega$，通过黎曼和来近似积分 $J(\\theta)$。\n- 对于路径导数估计器，使用 $\\xi$ 进行重参数化，并通过对洛伦兹被积函数关于 $\\omega_0$ 求导，然后对 $\\omega_0(\\theta,\\epsilon_{\\mathrm{eff}}(\\theta,\\xi))$ 使用链式法则来计算 $J$ 关于 $\\theta$ 的导数。\n- 对于得分函数估计器，将 $\\epsilon_{\\mathrm{eff}}$ 视为均值和方差依赖于 $\\theta$ 的高斯变量，并使用参数化期望的恒等式，将 $\\nabla_{\\theta} \\mathbb{E}[J(\\theta)]$ 写成一个显式导数项和一个涉及对数密度导数的似然比项之和。\n\n对于数值评估，在所有测试案例中使用以下固定常数：\n- $\\omega_{\\min} = 0$, $\\omega_{\\max} = 10$, $N_{\\omega} = 501$, 且 $\\Gamma = 0.15$。\n- $L_0 = 1$, $\\beta = 0.2$, $F_0 = 0.4$, $\\kappa = 0.3$, 且 $\\epsilon_{\\mathrm{air}} = 1$。\n- $\\mu = 3$, $\\sigma = 0.3$。\n\n实现一个程序，对于下面的每个测试案例，从指定的随机性中抽取独立同分布的样本，为每个样本计算路径导数和得分函数梯度估计器，然后报告：\n- 路径导数梯度估计器的样本均值，\n- 得分函数梯度估计器的样本均值，\n- 路径导数梯度估计器的样本方差，\n- 得分函数梯度估计器的样本方差，\n- 得分函数方差与路径导数方差之比。\n\n使用以下测试套件，该套件在保持 $L(\\theta) > 0$ 和 $0  F(\\theta)  1$ 的同时，探测一个标称情况和两个趋近边界的填充因子情况：\n1. $(\\theta, N, \\text{seed}) = (0.0, 8000, 12345)$,\n2. $(\\theta, N, \\text{seed}) = (-1.1, 8000, 54321)$,\n3. $(\\theta, N, \\text{seed}) = (1.5, 8000, 2024)$.\n\n你的程序应生成单行输出，包含结果，格式为一个逗号分隔的列表，其中包含三个子列表（每个测试案例一个），每个子列表包含上述五个浮点数，保留六位小数，无空格。例如，输出格式必须与此完全一样：\n\"[[m1p,m1s,v1p,v1s,r1],[m2p,m2s,v2p,v2s,r2],[m3p,m3s,v3p,v3s,r3]]\"。", "solution": "所提出的问题是在一个简化的天线模型背景下，推导并实现一个期望值梯度 $\\nabla_{\\theta} \\mathbb{E}[J(\\theta)]$ 的两种不同蒙特卡罗估计器。该问题具有科学依据，在数学上是适定的，并且所有必要的参数和函数形式都已提供。其底层物理模型，即洛伦兹响应，是谐振系统的标准近似。通过高斯随机变量对材料不确定性进行建模是不确定性量化中的一种常规方法。虽然高斯分布的支撑集是整个实数轴，包括非物理的介电常数负值，但所选参数将均值置于离零足够远的位置（多个标准差之外），使得采样到非物理值的概率在计算上可以忽略不计。因此，该问题被认为是有效的，可以构建一个解。\n\n首先，我们将依赖关系形式化。目标泛函是 $J(\\theta, \\xi)$，其中对标准正态随机变量 $\\xi \\sim \\mathcal{N}(0,1)$ 的依赖关系通过以下关系链产生：\n$$ \\epsilon_{\\mathrm{mat}}(\\xi) = \\mu + \\sigma \\xi $$\n$$ \\epsilon_{\\mathrm{eff}}(\\theta, \\xi) = \\bigl(1 - F(\\theta)\\bigr)\\,\\epsilon_{\\mathrm{air}} + F(\\theta)\\,\\epsilon_{\\mathrm{mat}}(\\xi) $$\n$$ \\omega_0(\\theta, \\xi) = \\frac{\\pi}{L(\\theta)\\sqrt{\\epsilon_{\\mathrm{eff}}(\\theta, \\xi)}} $$\n$$ \\lvert S_{21}(\\omega; \\theta, \\xi) \\rvert^2 = \\frac{\\Gamma^2}{(\\omega - \\omega_0(\\theta, \\xi))^2 + \\Gamma^2} $$\n$$ J(\\theta, \\xi) = \\int_{\\omega_{\\min}}^{\\omega_{\\max}} \\lvert S_{21}(\\omega; \\theta, \\xi) \\rvert^2 \\, d\\omega $$\n形状参数 $\\theta$ 也通过 $L(\\theta) = L_0 (1 + \\beta \\theta)$ 影响几何结构，并通过 $F(\\theta) = F_0 + \\kappa \\theta$ 影响材料组成。我们的目标是计算 $\\nabla_{\\theta}\\mathbb{E}_{\\xi}[J(\\theta, \\xi)]$。\n\n### 路径导数梯度估计器推导\n路径导数法，或称重参数化方法，适用于随机性来源可以与微分参数分离的情况。在这里，$\\xi \\sim \\mathcal{N}(0,1)$ 与 $\\theta$ 无关。我们可以将期望的梯度写成梯度的期望，前提是被积函数是关于 $\\theta$ 的连续可微函数，本例中情况如此。\n$$ \\nabla_{\\theta} \\mathbb{E}_{\\xi}[J(\\theta, \\xi)] = \\mathbb{E}_{\\xi}[\\nabla_{\\theta} J(\\theta, \\xi)] $$\n因此，一个无偏单样本估计器是 $G_P(\\theta, \\xi) = \\nabla_{\\theta} J(\\theta, \\xi)$。我们通过应用莱布尼茨积分法则和链式法则来找到这个导数：\n$$ \\nabla_{\\theta} J(\\theta, \\xi) = \\int_{\\omega_{\\min}}^{\\omega_{\\max}} \\nabla_{\\theta} \\lvert S_{21}(\\omega; \\theta, \\xi) \\rvert^2 \\, d\\omega $$\n被积函数的导数是：\n$$ \\nabla_{\\theta} \\lvert S_{21} \\rvert^2 = \\frac{\\partial \\lvert S_{21} \\rvert^2}{\\partial \\omega_0} \\frac{d\\omega_0}{d\\theta} $$\n乘积的第一部分是：\n$$ \\frac{\\partial \\lvert S_{21} \\rvert^2}{\\partial \\omega_0} = \\frac{\\partial}{\\partial \\omega_0} \\left[ \\frac{\\Gamma^2}{(\\omega - \\omega_0)^2 + \\Gamma^2} \\right] = \\frac{2\\Gamma^2(\\omega - \\omega_0)}{[(\\omega - \\omega_0)^2 + \\Gamma^2]^2} $$\n谐振频率 $\\omega_0$ 关于 $\\theta$ 的全导数包括所有依赖关系：\n$$ \\frac{d\\omega_0}{d\\theta} = \\frac{\\partial \\omega_0}{\\partial L} \\frac{dL}{d\\theta} + \\frac{\\partial \\omega_0}{\\partial \\epsilon_{\\mathrm{eff}}} \\frac{d\\epsilon_{\\mathrm{eff}}}{d\\theta} $$\n各个分量是：\n$$ \\frac{dL}{d\\theta} = L_0\\beta $$\n$$ \\frac{dF}{d\\theta} = \\kappa \\implies \\frac{d\\epsilon_{\\mathrm{eff}}}{d\\theta} = (\\epsilon_{\\mathrm{mat}} - \\epsilon_{\\mathrm{air}})\\frac{dF}{d\\theta} = \\kappa(\\epsilon_{\\mathrm{mat}} - \\epsilon_{\\mathrm{air}}) $$\n$$ \\frac{\\partial \\omega_0}{\\partial L} = -\\frac{\\pi}{L^2\\sqrt{\\epsilon_{\\mathrm{eff}}}} = -\\frac{\\omega_0}{L} $$\n$$ \\frac{\\partial \\omega_0}{\\partial \\epsilon_{\\mathrm{eff}}} = \\frac{\\pi}{L}\\left(-\\frac{1}{2}\\epsilon_{\\mathrm{eff}}^{-3/2}\\right) = -\\frac{\\omega_0}{2\\epsilon_{\\mathrm{eff}}} $$\n将这些组合起来得到 $\\omega_0$ 的全导数：\n$$ \\frac{d\\omega_0}{d\\theta} = -\\frac{\\omega_0(\\theta,\\xi)}{L(\\theta)}(L_0\\beta) - \\frac{\\omega_0(\\theta,\\xi)}{2\\epsilon_{\\mathrm{eff}}(\\theta,\\xi)}\\kappa(\\epsilon_{\\mathrm{mat}}(\\xi) - \\epsilon_{\\mathrm{air}}) = -\\omega_0 \\left( \\frac{L_0 \\beta}{L(\\theta)} + \\frac{\\kappa(\\epsilon_{\\mathrm{mat}} - \\epsilon_{\\mathrm{air}})}{2\\epsilon_{\\mathrm{eff}}} \\right) $$\n路径导数梯度估计器即为乘积 $\\frac{\\partial \\lvert S_{21} \\rvert^2}{\\partial \\omega_0} \\frac{d\\omega_0}{d\\theta}$ 的数值积分。\n\n### 得分函数梯度估计器推导\n得分函数法，或称似然比方法，处理随机变量的概率分布依赖于所关注参数的情况。在这里，$\\epsilon_{\\mathrm{eff}} \\sim p(e; \\theta)$ 有一个依赖于 $\\theta$ 的分布。泛函 $J(\\theta, \\epsilon_{\\mathrm{eff}})$ 也通过 $L(\\theta)$ 对 $\\theta$ 有显式依赖。\n$$ \\nabla_{\\theta} \\mathbb{E}[J] = \\nabla_{\\theta} \\int J(\\theta, e) p(e; \\theta) de $$\n使用乘法法则和对数导数恒等式 $\\nabla_{\\theta}p = p \\nabla_{\\theta}\\log p$，我们得到：\n$$ \\nabla_{\\theta}\\mathbb{E}[J] = \\int \\left[ (\\nabla_{\\theta}J(\\theta, e))p(e;\\theta) + J(\\theta, e)(\\nabla_{\\theta}p(e;\\theta)) \\right] de = \\mathbb{E}\\left[ (\\nabla_{\\theta}J(\\theta, e))|_{\\mathrm{e=const}} + J(\\theta, e)\\nabla_{\\theta}\\log p(e;\\theta) \\right] $$\n一个无偏单样本估计器是 $G_S(\\theta, e) = (\\nabla_{\\theta}J(\\theta, e))|_{\\mathrm{e=const}} + J(\\theta, e)\\nabla_{\\theta}\\log p(e;\\theta)$。\n\n第一项，$(\\nabla_{\\theta}J)|_{\\mathrm{explicit}}$，将 $\\epsilon_{\\mathrm{eff}}$ 视为固定值，仅对 $\\theta$ 的显式出现（即通过 $L(\\theta)$）求导：\n$$ (\\nabla_{\\theta}J)|_{\\mathrm{explicit}} = \\int_{\\omega_{\\min}}^{\\omega_{\\max}} \\frac{\\partial \\lvert S_{21} \\rvert^2}{\\partial \\omega_0} \\left( \\frac{\\partial \\omega_0}{\\partial L} \\frac{dL}{d\\theta} \\right) d\\omega = \\int_{\\omega_{\\min}}^{\\omega_{\\max}} \\frac{\\partial \\lvert S_{21} \\rvert^2}{\\partial \\omega_0} \\left( -\\frac{\\omega_0}{L(\\theta)}L_0\\beta \\right) d\\omega $$\n第二项包含得分 $\\nabla_{\\theta}\\log p(e;\\theta)$。$\\epsilon_{\\mathrm{eff}}$ 的分布是高斯分布，$p(e;\\theta) = \\mathcal{N}(e; \\mu_{\\mathrm{eff}}(\\theta), \\sigma^2_{\\mathrm{eff}}(\\theta))$，其中：\n$$ \\mu_{\\mathrm{eff}}(\\theta) = (1 - F(\\theta))\\epsilon_{\\mathrm{air}} + F(\\theta)\\mu $$\n$$ \\sigma^2_{\\mathrm{eff}}(\\theta) = (F(\\theta)\\sigma)^2 $$\n高斯分布对数密度的导数是一个标准结果：\n$$ \\nabla_{\\theta}\\log p(e;\\theta) = \\frac{(e - \\mu_{\\mathrm{eff}})}{\\sigma_{\\mathrm{eff}}^2}\\frac{d\\mu_{\\mathrm{eff}}}{d\\theta} + \\frac{(e - \\mu_{\\mathrm{eff}})^2 - \\sigma_{\\mathrm{eff}}^2}{2(\\sigma_{\\mathrm{eff}}^2)^2}\\frac{d\\sigma_{\\mathrm{eff}}^2}{d\\theta} $$\n矩的所需导数是：\n$$ \\frac{d\\mu_{\\mathrm{eff}}}{d\\theta} = (\\mu - \\epsilon_{\\mathrm{air}})\\frac{dF}{d\\theta} = \\kappa(\\mu - \\epsilon_{\\mathrm{air}}) $$\n$$ \\frac{d\\sigma_{\\mathrm{eff}}^2}{d\\theta} = \\sigma^2 \\frac{d(F(\\theta)^2)}{d\\theta} = 2\\sigma^2 F(\\theta)\\frac{dF}{d\\theta} = 2\\kappa\\sigma^2 F(\\theta) $$\n得分函数估计器是显式导数项与泛函 $J$ 和得分项的乘积之和，所有这些都是为给定的 $\\epsilon_{\\mathrm{eff}}$ 样本计算的。对于数值评估，$J$ 及其导数的积分通过在均匀频率网格上的黎曼和来近似。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements pathwise and score-function gradient estimators for a\n    Monte Carlo simulation in computational electromagnetics, and compares their\n    variances.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 8000, 12345),\n        (-1.1, 8000, 54321),\n        (1.5, 8000, 2024),\n    ]\n    \n    # Fixed constants for all test cases\n    w_min = 0.0\n    w_max = 10.0\n    Nw = 501\n    Gamma = 0.15\n    L0 = 1.0\n    beta = 0.2\n    F0 = 0.4\n    kappa = 0.3\n    eps_air = 1.0\n    mu = 3.0\n    sigma = 0.3\n    \n    omega_grid = np.linspace(w_min, w_max, Nw)\n    delta_omega = (w_max - w_min) / (Nw - 1)\n\n    results = []\n    for theta, N_samples, seed in test_cases:\n        rng = np.random.default_rng(seed)\n        \n        pathwise_grads = np.zeros(N_samples)\n        score_grads = np.zeros(N_samples)\n\n        # Pre-compute theta-dependent parameters\n        F_theta = F0 + kappa * theta\n        L_theta = L0 * (1.0 + beta * theta)\n        \n        grad_L_theta = L0 * beta\n        \n        mu_eff = (1.0 - F_theta) * eps_air + F_theta * mu\n        sigma2_eff = (F_theta * sigma)**2\n        \n        grad_mu_eff = kappa * (mu - eps_air)\n        grad_sigma2_eff = 2.0 * kappa * sigma**2 * F_theta\n\n        for i in range(N_samples):\n            # 1. Sample randomness\n            xi = rng.normal()\n            eps_mat = mu + sigma * xi\n            eps_eff = (1.0 - F_theta) * eps_air + F_theta * eps_mat\n\n            # Model is not physically defined for eps_eff == 0.\n            # Probability is negligible, but we skip the sample for robustness.\n            if eps_eff == 0:\n                # To maintain N_samples, we could resample, but for simplicity\n                # and given the rarity, we can just let it result in nan and filter later\n                # or just live with a slightly smaller N_samples in extreme cases.\n                # For this implementation, we proceed, knowing it won't happen.\n                pass\n            \n            # 2. Compute shared quantities\n            w0 = np.pi / (L_theta * np.sqrt(eps_eff))\n            \n            w_diff = omega_grid - w0\n            denom = w_diff**2 + Gamma**2\n            \n            S21_sq_integrand = Gamma**2 / denom\n            \n            # Common derivative term d|S21|^2/dw0\n            d_S21_sq_d_w0 = (2.0 * Gamma**2 * w_diff) / (denom**2)\n            \n            # --- Pathwise Estimator Calculation ---\n            grad_eps_eff = kappa * (eps_mat - eps_air)\n            d_w0_d_L = -w0 / L_theta\n            d_w0_d_eps_eff = -w0 / (2.0 * eps_eff)\n            \n            # Total derivative of w0\n            grad_w0_pathwise = d_w0_d_L * grad_L_theta + d_w0_d_eps_eff * grad_eps_eff\n            \n            grad_J_integrand_pathwise = d_S21_sq_d_w0 * grad_w0_pathwise\n            grad_J_pathwise = np.sum(grad_J_integrand_pathwise) * delta_omega\n            pathwise_grads[i] = grad_J_pathwise\n            \n            # --- Score-Function Estimator Calculation ---\n            # Part 1: Explicit derivative of J w.r.t. theta\n            grad_w0_explicit = d_w0_d_L * grad_L_theta\n            grad_J_explicit_integrand = d_S21_sq_d_w0 * grad_w0_explicit\n            grad_J_explicit = np.sum(grad_J_explicit_integrand) * delta_omega\n            \n            # Part 2: Score term\n            J = np.sum(S21_sq_integrand) * delta_omega\n            \n            score_term1 = ((eps_eff - mu_eff) / sigma2_eff) * grad_mu_eff\n            score_term2 = (((eps_eff - mu_eff)**2 - sigma2_eff) / (2.0 * sigma2_eff**2)) * grad_sigma2_eff\n            score = score_term1 + score_term2\n            \n            grad_J_score = grad_J_explicit + J * score\n            score_grads[i] = grad_J_score\n\n        # Calculate statistics\n        mean_p = np.mean(pathwise_grads)\n        mean_s = np.mean(score_grads)\n        var_p = np.var(pathwise_grads, ddof=1)\n        var_s = np.var(score_grads, ddof=1)\n        \n        # Handle case where pathwise variance is zero to avoid division by zero\n        if var_p == 0:\n            ratio = np.inf if var_s > 0 else 1.0\n        else:\n            ratio = var_s / var_p\n\n        results.append([\n            round(mean_p, 6),\n            round(mean_s, 6),\n            round(var_p, 6),\n            round(var_s, 6),\n            round(ratio, 6)\n        ])\n\n    # Final print statement in the exact required format.\n    # Convert list of lists to string representation without spaces.\n    formatted_results = \",\".join([f\"[{','.join(map(str, sublist))}]\" for sublist in results])\n    print(f\"[{formatted_results}]\")\n\nsolve()\n\n```", "id": "3332261"}]}