{"hands_on_practices": [{"introduction": "掌握任何算法的第一步都是理解其核心机制。本练习旨在通过一个直接的计算，巩固你对 Metropolis-Hastings 算法心脏——接受概率——的理解。通过计算这个概率，你将亲身体验 MCMC 采样器如何巧妙地平衡后验概率的提升与提议分布的不对称性，从而确保对目标分布的正确探索。[@problem_id:3478680]", "problem": "一个数值宇宙学流程使用 Ia 型超新星和宇宙微波背景摘要统计量，对一个平坦 $\\Lambda$ 冷暗物质模型进行贝叶斯参数推断。该流程通过 Metropolis–Hastings 马尔可夫链蒙特卡洛 (MCMC) 转移对后验分布 $\\boldsymbol{\\theta} = (\\Omega_{\\mathrm{m}}, \\sigma_{8}, H_{0})$ 进行采样，此转移强制满足关于后验密度 $\\pi(\\boldsymbol{\\theta}) \\propto \\mathcal{L}(\\mathbf{d} \\mid \\boldsymbol{\\theta})\\,p(\\boldsymbol{\\theta})$ 的细致平衡条件，并使用一个通常非对称的提议密度 $q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})$。在某次特定的迭代中，从当前状态 $\\boldsymbol{\\theta}$ 到提议状态 $\\boldsymbol{\\theta}'$，代码计算出后验密度比 $\\pi(\\boldsymbol{\\theta}')/\\pi(\\boldsymbol{\\theta}) = 10$ 和提议密度比 $q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')/q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta}) = 2$。\n\n从针对 $\\pi(\\boldsymbol{\\theta})$ 的马尔可夫链的细致平衡基本要求出发，并根据以提议函数和接受函数定义的 Metropolis–Hastings 转移核，确定此次移动的 Metropolis–Hastings 接受概率 $\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}')$。然后，在宇宙学参数采样的背景下，解释该值对此步骤中马尔可夫链行为的意义。请以纯数形式提供接受概率，无需四舍五入。", "solution": "首先对问题进行严格的验证过程。\n\n### 步骤 1：提取给定条件\n问题陈述中明确提供了以下数据和定义：\n- **模型：** 平坦 $\\Lambda$ 冷暗物质 ($\\Lambda$CDM) 模型。\n- **目标参数：** $\\boldsymbol{\\theta} = (\\Omega_{\\mathrm{m}}, \\sigma_{8}, H_{0})$。\n- **推断方法：** Metropolis–Hastings 马尔可夫链蒙特卡洛 (MCMC)。\n- **目标概率密度：** 后验密度 $\\pi(\\boldsymbol{\\theta}) \\propto \\mathcal{L}(\\mathbf{d} \\mid \\boldsymbol{\\theta})\\,p(\\boldsymbol{\\theta})$，其中 $\\mathcal{L}$ 是似然， $p$ 是先验。\n- **提议密度：** 一个通常非对称的密度，$q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})$。\n- **核心原则：** MCMC 转移强制满足关于 $\\pi(\\boldsymbol{\\theta})$ 的细致平衡条件。\n- **在从状态 $\\boldsymbol{\\theta}$ 到 $\\boldsymbol{\\theta}'$ 的某次特定迭代中：**\n    - 后验密度比为 $\\frac{\\pi(\\boldsymbol{\\theta}')}{\\pi(\\boldsymbol{\\theta})} = 10$。\n    - 提议密度比为 $\\frac{q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')}{q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})} = 2$。\n- **目标：** 确定 Metropolis–Hastings 接受概率 $\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}')$ 并解释其含义。\n\n### 步骤 2：使用提取的给定条件进行验证\n根据既定标准评估问题的有效性。\n- **有科学依据：** 该问题牢固地植根于贝叶斯统计推断和计算物理学的标准理论框架。Metropolis-Hastings 算法是 MCMC 方法的基石，其在宇宙学参数估计（特别是针对 $\\Lambda$CDM 模型）中的应用是该领域一项常规且基本的任务。所有概念——后验密度、似然、先验、提议密度、细致平衡以及参数 $\\Omega_{\\mathrm{m}}$、$\\sigma_{8}$、$H_{0}$——都是标准且定义明确的。\n- **适定的：** 该问题提供了计算接受概率所需的所有信息。Metropolis-Hastings 接受规则的定义可以从给定的比率中得出一个唯一且稳定的解。\n- **客观性：** 语言技术性强、精确，且没有任何主观性、模糊性或意见。\n\n该问题未表现出任何列出的无效性缺陷。它在科学上是健全的，可直接形式化，信息完整，描述了一个计算上现实的场景，并且结构良好。\n\n### 步骤 3：结论与行动\n该问题被判定为**有效**。将提供完整的解答。\n\n### 解答推导\n马尔可夫链具有平稳分布 $\\pi(\\boldsymbol{\\theta})$ 的基本要求是细致平衡条件。对于任意两个状态 $\\boldsymbol{\\theta}$ 和 $\\boldsymbol{\\theta}'$，细致平衡要求当链处于其平稳状态时，从 $\\boldsymbol{\\theta}$ 转移到 $\\boldsymbol{\\theta}'$ 的速率等于从 $\\boldsymbol{\\theta}'$ 转移到 $\\boldsymbol{\\theta}$ 的速率。这在数学上表示为：\n$$\n\\pi(\\boldsymbol{\\theta}) P(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta}) = \\pi(\\boldsymbol{\\theta}') P(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')\n$$\n其中 $P(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})$ 是从状态 $\\boldsymbol{\\theta}$ 移动到状态 $\\boldsymbol{\\theta}'$ 的转移概率（或核）。\n\n在 Metropolis–Hastings 算法中，转移是一个两步过程：提议一个新状态，然后接受或拒绝它。从 $\\boldsymbol{\\theta}$ 移动到一个不同的状态 $\\boldsymbol{\\theta}'$ 的转移概率是提议 $\\boldsymbol{\\theta}'$ 的概率与接受它的概率的乘积：\n$$\nP(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta}) = q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta}) \\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') \\quad \\text{for } \\boldsymbol{\\theta} \\neq \\boldsymbol{\\theta}'\n$$\n其中 $q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})$ 是提议密度，$\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}')$ 是接受概率。\n\n将这种形式的转移核代入细致平衡方程，得到：\n$$\n\\pi(\\boldsymbol{\\theta}) q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta}) \\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = \\pi(\\boldsymbol{\\theta}') q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}') \\alpha(\\boldsymbol{\\theta}', \\boldsymbol{\\theta})\n$$\n这个方程可以重新排列，以显示接受概率必须满足的关系：\n$$\n\\frac{\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}')}{\\alpha(\\boldsymbol{\\theta}', \\boldsymbol{\\theta})} = \\frac{\\pi(\\boldsymbol{\\theta}')}{\\pi(\\boldsymbol{\\theta})} \\frac{q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')}{q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})}\n$$\n在 Metropolis–Hastings 算法中，接受概率的标准选择是：\n$$\n\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = \\min \\left( 1, \\frac{\\pi(\\boldsymbol{\\theta}')}{\\pi(\\boldsymbol{\\theta})} \\frac{q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')}{q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})} \\right)\n$$\n该选择在满足此条件的同时最大化了接受率。\n\n问题提供了最小值函数内部两个比率的数值。\n给定的后验密度比为：\n$$\n\\frac{\\pi(\\boldsymbol{\\theta}')}{\\pi(\\boldsymbol{\\theta})} = 10\n$$\n提议密度比，也称为 Hastings 修正因子，为：\n$$\n\\frac{q(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\theta}')}{q(\\boldsymbol{\\theta}' \\mid \\boldsymbol{\\theta})} = 2\n$$\n我们将这些值代入接受概率的公式中：\n$$\n\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = \\min \\left( 1, (10) \\times (2) \\right)\n$$\n$$\n\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = \\min(1, 20)\n$$\n计算最小值函数得到：\n$$\n\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = 1\n$$\n### 解释\n计算出的接受概率为 $\\alpha(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = 1$。这意味着从当前状态 $\\boldsymbol{\\theta}$ 到新状态 $\\boldsymbol{\\theta}'$ 的提议移动被确定性地接受。\n\n在宇宙学参数采样的背景下，这是此步骤中一个非常理想的结果。链在参数空间 $\\{ \\Omega_{\\mathrm{m}}, \\sigma_{8}, H_{0} \\}$ 中找到了一个新点 $\\boldsymbol{\\theta}'$，其后验概率密度是当前点 $\\boldsymbol{\\theta}$ 的 10 倍。这表明，提议的这组宇宙学参数能更好地拟合 Ia 型超新星和宇宙微波背景的组合数据（由似然 $\\mathcal{L}$ 体现），和/或更受编码在 $p(\\boldsymbol{\\theta})$ 中的先验知识的青睐。\n\n尽管提议分布使得正向移动（$\\boldsymbol{\\theta} \\to \\boldsymbol{\\theta}'$）的概率是反向移动（$\\boldsymbol{\\theta}' \\to \\boldsymbol{\\theta}$）的一半（如 Hastings 修正因子 2 所示），但后验密度的巨大提升压倒性地支持接受新状态。采样器正在有效地“攀登”后验概率景观的“山丘”，积极地向最高概率区域移动，这些区域包含了宇宙学参数最可能的值。接受这次移动确保了链能够有效地探索并收敛到真实的后验分布。", "answer": "$$\n\\boxed{1}\n$$", "id": "3478680"}, {"introduction": "一个能够运行的 MCMC 采样器与一个高效的采样器之间存在巨大差异。本练习将引导你从“如何运行”转向“如何高效运行”，特别是在处理高维参数空间时。你将探索随机游走 Metropolis 算法的“最优尺度”理论，这是一个深刻的理论结果，它为在实践中调整提议分布的方差提供了关键指导，以应对“维度灾难”并最大化采样效率。[@problem_id:3528578]", "problem": "一个计算天体物理学小组正在对一个恒星族群合成模型进行贝叶斯参数估计。参数向量是 $d$ 维的，$\\theta \\in \\mathbb{R}^d$，在最大后验概率点附近，后验概率可以局部近似为一个协方差为 $\\Sigma$ 的多元正态分布。该小组采用了随机游走梅特罗波利斯 (RWM) 算法，这是梅特罗波利斯-哈斯廷斯方法的一个特例，其提议分布为高斯形式 $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, s^2 \\Sigma)$，其中 $s > 0$ 是一个标量调节参数，用于缩放提议协方差。对于对称提议，接受概率为 $\\alpha(\\theta, \\theta') = \\min\\{1, \\pi(\\theta') / \\pi(\\theta)\\}$，其中 $\\pi(\\theta)$ 表示后验密度。\n\n为了便于分析，假设参数已经通过线性变换 $x = L^{-1}(\\theta - \\hat{\\theta})$ 进行了白化，其中 $L L^\\top = \\Sigma$ 且 $\\hat{\\theta}$ 是最大后验估计，因此局部目标近似为 $d$ 个独立标准正态分布的乘积，提议为 $x' = x + s z$，其中 $z \\sim \\mathcal{N}(0, I_d)$。考虑 $d \\to \\infty$ 的渐近情况，并分析通过 $s^2$ 缩放提议协方差如何影响接受率和探索效率（例如，混合和单位计算的有效样本量），参考在独立同分布目标下 RWM 的经过充分检验的渐近最优缩放结果。\n\n下列哪个陈述最符合渐近最优缩放理论及其对高维天体物理后验概率进行实际探索的启示？\n\nA. 最佳接受率约为 $0.234$，当选择 $s^2$ 使得每个坐标的平均平方跳跃大小为 $O(d^{-1})$ 时（即 $s \\propto d^{-1/2}$）达到；使 $s$ 远小于此值会使接受率提高到 $0.5$ 以上并加速探索。\n\nB. 对于随机游走梅特罗波利斯算法，最佳接受率约为 $0.574$，并且为了在 $d$ 增加时保持接受率，应将 $s$ 按比例缩放为 $d^{1/2}$，以使每个坐标的典型跳跃幅度保持为 $O(1)$。\n\nC. 当 $\\Sigma$ 与局部后验协方差对齐时，选择 $s \\approx 2.38 / \\sqrt{d}$ 会产生近乎最优的效率；使 $s$ 过小会产生高接受率但探索效果差（混合慢），而使 $s$ 过大会产生极低的接受率和差的探索效果。\n\nD. 在高维情况下，为了保持遍历性，必须在每个坐标上接受大小为 $O(1)$ 的跳跃，因此随着 $d$ 的增长，$s$ 应保持不变，目标接受率应高于 $0.8$，而与 $d$ 无关。\n\nE. 如果将 $\\Sigma$ 取为费雪信息矩阵的逆，预处理会消除最优缩放的维度依赖性，因此应选择与 $d$ 无关的 $s$，并以接近 $0.5$ 的接受率为目标。", "solution": "问题陈述描述了贝叶斯计算中的一个标准情景：使用随机游走梅特罗波利斯（RWM）算法对高维后验分布进行采样。用于验证的关键要素是后验模型、RWM 算法的规范以及所引用的理论框架（渐近最优缩放）。\n\n### 步骤 1：提取已知条件\n- **参数向量：** $\\theta \\in \\mathbb{R}^d$，其中 $d$ 是维度。\n- **后验近似：** 在局部，后验概率 $\\pi(\\theta)$ 近似为一个多元正态分布 $\\mathcal{N}(\\hat{\\theta}, \\Sigma)$，其中 $\\hat{\\theta}$ 是最大后验概率（MAP）估计，$\\Sigma$ 是协方差矩阵。\n- **算法：** 随机游走梅特罗波利斯（RWM）。\n- **提议分布：** 一个对称的高斯提议 $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, s^2 \\Sigma)$，其中 $s > 0$ 是一个标量调节参数。\n- **接受概率：** $\\alpha(\\theta, \\theta') = \\min\\{1, \\pi(\\theta') / \\pi(\\theta)\\}$。\n- **变换：** 定义了一个白化变换 $x = L^{-1}(\\theta - \\hat{\\theta})$，其中 $L L^\\top = \\Sigma$。\n- **变换后的目标：** 白化参数 $x$ 的目标分布近似为 $d$ 个独立标准正态分布的乘积，即 $\\pi(x) \\propto \\exp(-\\frac{1}{2} x^\\top x)$。\n- **变换后的提议：** 在白化空间中的提议是 $x' = x + s z$，其中 $z \\sim \\mathcal{N}(0, I_d)$。\n- **分析体系：** $d \\to \\infty$ 的渐近极限。\n- **目标：** 基于 RWM 的渐近最优缩放理论，评估所提供的陈述。\n\n### 步骤 2：使用提取的已知条件进行验证\n问题陈述是 MCMC 理论中用于推导经典结果的教科书式设置。\n- **科学依据：** 该问题基于 Roberts、Gelman、Gilks 和 Rosenthal 关于梅特罗波利斯-哈斯廷斯算法最优缩放的开创性工作。这是现代计算统计学的基石，其在计算天体物理学等领域的应用是标准做法。后验的拉普拉斯近似和 RWM 算法是基本概念。该问题在科学上和数学上都是合理的。\n- **良态问题：** 该问题提供了一个清晰、理想化的设置（一个独立同分布的高斯目标），从而可以进行精确的理论分析。问题要求找出与此分析的已知结果一致的陈述。在这个已建立的理论框架内，存在一个唯一的正确答案。\n- **客观性：** 语言正式，没有主观性。所有术语都是该领域的标准术语。\n\n问题陈述没有科学或事实上的不健全之处，是正式且相关的，是完整且一致的，描述了一个标准的理论理想化情景，是良态的，并且处理了 MCMC 中一个非平凡且重要的概念。因此，该问题是有效的。\n\n### 步骤 3：结论和行动\n该问题是**有效的**。我将继续推导解决方案并评估各个选项。\n\n### RWM 最优缩放的推导\n\n问题的设置非常适合应用经典的最优缩放理论。在白化坐标 $x$ 中，目标密度为 $\\pi(x) \\propto \\exp(-\\frac{1}{2}x^\\top x)$，提议为 $x' = x + sz$，其中 $z \\sim \\mathcal{N}(0, I_d)$。\n\n接受概率取决于后验密度的比率，而这又取决于对数后验的变化：\n$$ \\log\\left(\\frac{\\pi(x')}{\\pi(x)}\\right) = \\log\\pi(x') - \\log\\pi(x) = -\\frac{1}{2} (x'^\\top x' - x^\\top x) $$\n代入 $x' = x + sz$：\n$$ \\log\\left(\\frac{\\pi(x')}{\\pi(x)}\\right) = -\\frac{1}{2} \\left( (x+sz)^\\top(x+sz) - x^\\top x \\right) = -\\frac{1}{2} \\left( x^\\top x + 2sx^\\top z + s^2 z^\\top z - x^\\top x \\right) = -s x^\\top z - \\frac{1}{2}s^2 z^\\top z $$\n为了在 $d \\to \\infty$ 的极限下进行分析，我们考察这些项的行为。由于 $x$ 和 $z$ 的分量是独立同分布的标准正态变量：\n1.  根据弱大数定律，$z^\\top z / d = \\frac{1}{d} \\sum_{i=1}^d z_i^2 \\to E[Z^2] = 1$（其中 $Z \\sim \\mathcal{N}(0,1)$）。所以，$z^\\top z \\approx d$。\n2.  项 $x^\\top z = \\sum_{i=1}^d x_i z_i$ 是独立同分布随机变量的和，每个变量的均值为 $E[x_i z_i] = E[x_i]E[z_i] = 0$，方差为 $Var(x_i z_i) = E[(x_i z_i)^2] - (E[x_i z_i])^2 = E[x_i^2]E[z_i^2] - 0 = 1 \\cdot 1 = 1$。根据中心极限定理，该和的方差为 $d$，因此对于大的 $d$，$x^\\top z \\sim \\mathcal{N}(0,d)$。\n\n因此，对数后验的变化是一个随机变量，其均值 $E[\\Delta] \\approx -\\frac{1}{2} s^2 d$，方差 $Var(\\Delta) \\approx s^2 d$。为了使接受率在 $d \\to \\infty$ 的极限下不为平凡值（即不为 $0$ 或 $1$），$\\Delta$ 的均值和方差都必须收敛到有限值。这要求 $s^2 d$ 是一个常数，这意味着缩放关系为 $s \\propto d^{-1/2}$。\n\n让我们定义 $s = \\ell / \\sqrt{d}$，其中 $\\ell > 0$ 是某个常数。对数后验的变化变为：\n$$ \\Delta = -\\frac{\\ell}{\\sqrt{d}}x^\\top z - \\frac{1}{2}\\frac{\\ell^2}{d}z^\\top z $$\n当 $d \\to \\infty$ 时，$x^\\top z / \\sqrt{d}$ 在分布上收敛于 $\\mathcal{N}(0,1)$，而 $z^\\top z / d$ 在概率上收敛于 $1$。因此，$\\Delta$ 在分布上收敛于一个正态随机变量 $\\mathcal{N}(-\\ell^2/2, \\ell^2)$。\n\n极限接受率为 $A(\\ell) = E[\\min(1, e^\\Delta)]$，可以证明其为 $A(\\ell) = 2\\Phi(-\\ell/2)$，其中 $\\Phi$ 是标准正态分布的累积分布函数。\n\n采样器的效率与它探索参数空间的速度有关。一个常见的度量是单位计算成本的预期平方跳跃距离（ESJD）。每次迭代的成本是固定的，因此我们的目标是最大化 ESJD。ESJD 与链的均方根位移成正比，即提议步长的方差乘以接受率。在一维情况下，ESJD 为 $E[(x'_i - x_i)^2 \\alpha] = E[(sz_i)^2] \\alpha= s^2 \\alpha = (\\ell^2/d) A(\\ell)$。通过最大化随机游走的速度来最大化整体效率，这可以通过最大化函数 $f(\\ell) = \\ell^2 A(\\ell)$ 来找到。\n\n对 $f(\\ell) = 2\\ell^2 \\Phi(-\\ell/2)$ 关于 $\\ell$ 进行最大化，可以得到最优 $\\ell$ 的数值解，即 $\\ell_{opt} \\approx 2.38$。\n\n使用这个最优值，我们可以找到最优接受率：\n$$ A(\\ell_{opt}) = 2\\Phi(-2.38/2) = 2\\Phi(-1.19) \\approx 2 \\times 0.11702 = 0.23404 \\approx 0.234 $$\n因此，在高维情况下 RWM 的最优策略是：\n1.  选择提议缩放 $s \\approx 2.38/\\sqrt{d}$。\n2.  这应该会得到大约 $0.234$ 的接受率。\n\n如果选择的 $s$ 过小（小的 $\\ell$），接受率 $A(\\ell)$ 趋近于 $1$，但步长 $\\ell^2/d$ 变得微不足道，导致探索非常缓慢（高自相关，“混合差”）。如果选择的 $s$ 过大（大的 $\\ell$），接受率 $A(\\ell)$ 会骤降至 $0$，链几乎不移动，同样导致探索效果差。\n\n### 逐项分析\n\n**A. 最佳接受率约为 $0.234$，当选择 $s^2$ 使得每个坐标的平均平方跳跃大小为 $O(d^{-1})$ 时（即 $s \\propto d^{-1/2}$）达到；使 $s$ 远小于此值会使接受率提高到 $0.5$ 以上并加速探索。**\n这个陈述大部分是正确的。最佳接受率确实约为 $0.234$。每个坐标的平均平方跳跃是 $E[(s z_i)^2] = s^2$，并且当 $s \\propto d^{-1/2}$ 时，我们有 $s^2 \\propto d^{-1}$，即 $O(d^{-1})$。使 $s$ 变小确实会将接受率提高到接近 $1$。然而，最后关于这会*加速*探索的说法是错误的。它会导致极慢的混合和差的探索效果。\n**结论：不正确。**\n\n**B. 对于随机游走梅特罗波利斯算法，最佳接受率约为 $0.574$，并且为了在 $d$ 增加时保持接受率，应将 $s$ 按比例缩放为 $d^{1/2}$，以使每个坐标的典型跳跃幅度保持为 $O(1)$。**\n约 $0.574$ 的最佳接受率是针对梅特罗波利斯调整的朗之万算法（MALA），而不是 RWM。$s \\propto d^{1/2}$ 的缩放是错误的；它应该是 $s \\propto d^{-1/2}$。这样的缩放将导致接受率为 $0$。\n**结论：不正确。**\n\n**C. 当 $\\Sigma$ 与局部后验协方差对齐时，选择 $s \\approx 2.38 / \\sqrt{d}$ 会产生近乎最优的效率；使 $s$ 过小会产生高接受率但探索效果差（混合慢），而使 $s$ 过大会产生极低的接受率和差的探索效果。**\n问题将提议协方差 $s^2 \\Sigma$ 设置为与后验协方差 $\\Sigma$ 对齐。上面的推导表明，最优缩放是 $s \\approx 2.38/\\sqrt{d}$。该陈述随后正确地描述了偏离此最优缩放的后果：\n-   如果 $s$ 太小（步长太小），接受率很高，但链移动非常缓慢（探索效果差）。\n-   如果 $s$ 太大（步长太大），提议几乎总是被拒绝，所以链不移动（探索效果差）。\n这个陈述准确地总结了理论结果及其实际应用。\n**结论：正确。**\n\n**D. 在高维情况下，为了保持遍历性，必须在每个坐标上接受大小为 $O(1)$ 的跳跃，因此随着 $d$ 的增长，$s$ 应保持不变，目标接受率应高于 $0.8$，而与 $d$ 无关。**\n这个陈述根本上是错误的。在 $d$ 个坐标上每个都进行大小为 $O(1)$ 的跳跃，意味着总平方跳跃距离为 $O(d)$。这可能导致对数后验以与 $d$ 成正比的量减少，从而使接受率趋于零。为了保持非零的接受率，每个坐标的跳跃大小必须缩小。缩放因子 $s$ 不应保持不变。大于 $0.8$ 的目标率远非最优的 $0.234$，并且表明步长效率低下地过小。\n**结论：不正确。**\n\n**E. 如果将 $\\Sigma$ 取为费雪信息矩阵的逆，预处理会消除最优缩放的维度依赖性，因此应选择与 $d$ 无关的 $s$，并以接近 $0.5$ 的接受率为目标。**\n使用与后验协方差匹配的提议协方差 $\\Sigma$ 是一种预处理形式。对于高斯目标，费雪信息矩阵的逆就是协方差矩阵 $\\Sigma$。虽然这种预处理对于处理各向异性和不同的参数尺度至关重要，但它并不能消除整体步长的维度依赖性。“维度灾难”仍然存在，需要 $s \\propto d^{-1/2}$ 的缩放。声称 $s$ 应与 $d$ 无关是错误的。$0.5$ 的目标接受率对于 RWM 来说也是错误的。\n**结论：不正确。**", "answer": "$$\\boxed{C}$$", "id": "3528578"}, {"introduction": "本章的最终实践旨在将理论知识转化为可工作的代码，这是计算科学家的必备技能。在处理复杂的天体物理模型时，我们常常需要使用“自适应”MCMC 方法，即在采样过程中动态调整提议分布。这个练习要求你实现一个自适应算法，并以操作方式验证保证其收敛性的理论条件（如递减适应性和收容性），从而弥合高级 MCMC 理论与稳健的科学应用之间的鸿沟。[@problem_id:3528600]", "problem": "考虑一个自适应 Random-Walk Metropolis 算法，该算法用于一个双参数天体物理模型中每个能量箱的光子计数参数推断。设未知参数向量为 $\\theta = (\\log A, \\gamma)$，其中 $A$ 是在枢轴能量 $E_0$ 处的正通量归一化（单位任意），$\\gamma$ 是幂律模型中的谱指数。观测数据由能量箱中独立的的光子计数 $k_i$ 组成，其中心能量为 $E_i$，曝光时间为 $T_i$。模型假设 $k_i \\sim \\text{Poisson}(\\lambda_i)$，其中 $\\lambda_i = A \\, T_i \\, (E_i/E_0)^{-\\gamma}$。假设 $\\log A$ 和 $\\gamma$ 服从高斯先验，且分量之间相互独立。\n\n马尔可夫链蒙特卡洛 (MCMC) 链是通过 Random-Walk Metropolis 转移构建的，其提议为 $\\theta' = \\theta + \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, C_t)$，$C_t$ 是一个依赖于自适应、随迭代索引的提议协方差。设后验密度为 $\\pi(\\theta)$，在迭代 $t$ 时的时变马尔可夫转移核为 $K_t(\\theta, \\cdot)$，该核由 $C_t$ 驱动的 Random-Walk Metropolis 接受准则定义。\n\n自适应 MCMC 理论断言，在诸如适应性递减和约束性等条件下，可以保证收敛到目标 $\\pi(\\theta)$。使用以下基本依据：\n\n- 马尔可夫转移核 $K_t$ 的定义，以及基于 Metropolis-Hastings 准则的 Random-Walk Metropolis 算法的接受概率。\n- 独立计数的泊松似然，$P(k_i \\mid \\lambda_i) = \\frac{\\lambda_i^{k_i} e^{-\\lambda_i}}{k_i!}$，以及 $\\log A$ 和 $\\gamma$ 的独立高斯先验。\n- 适应性递减的定义：$\\lim_{t \\to \\infty} \\sup_{\\theta} \\lVert K_{t+1}(\\theta, \\cdot) - K_t(\\theta, \\cdot) \\rVert = 0$，在操作上解释为监控提议协方差矩阵 $C_t$ 的稳定性。\n- 约束性的概念：自适应过程保持在漂移和次要化条件一致成立的区域内，在操作上解释为限制参数轨迹并将提议协方差的特征值保持在有界范围内。\n\n您的任务是实现一个确定性模拟，在一个现实的天体物理推断问题上对这些条件进行操作性测试。使用以下固定的数据和先验：\n\n- 能量箱中心 (单位为 $\\text{keV}$): $E = [\\,0.5,\\, 1.0,\\, 2.0,\\, 5.0\\,]$。\n- 曝光时间 (单位为 $\\text{s}$): $T = [\\,10000,\\, 10000,\\, 10000,\\, 10000\\,]$。\n- 枢轴能量: $E_0 = 1.0$。\n- 观测到的计数: $k = [\\,80,\\, 20,\\, 5,\\, 1\\,]$。\n- $\\log A$ 的先验: $\\log A \\sim \\mathcal{N}(\\mu_A, \\sigma_A^2)$，其中 $\\mu_A = \\log(0.002)$ 且 $\\sigma_A = 1.0$。\n- $\\gamma$ 的先验: $\\gamma \\sim \\mathcal{N}(\\mu_\\gamma, \\sigma_\\gamma^2)$，其中 $\\mu_\\gamma = 2.0$ 且 $\\sigma_\\gamma = 1.0$。\n\n实现一个自适应 Random-Walk Metropolis 算法，该算法使用数值稳定的更新（例如，在线协方差更新）来维护链的经验协方差 $\\Sigma_t$ 的在线估计，并定义 $C_t = s_t^2 \\, (\\Sigma_t + \\varepsilon I)$，其中 $\\varepsilon > 0$ 是一个小的稳定项。基础缩放因子 $s_t$ 及其演变将在下面指定的测试案例中有所不同。\n\n定义以下操作性诊断指标：\n\n- 适应性递减诊断：计算提议协方差随时间的相对变化，\n$$\nr_t = \\frac{\\lVert C_t - C_{t-1} \\rVert_F}{\\max\\{\\lVert C_{t-1} \\rVert_F, \\delta\\}},\n$$\n其中范数为弗罗贝尼乌斯范数 $\\lVert \\cdot \\rVert_F$，$\\delta > 0$ 是一个小的稳定项。在预烧期后最后的 $L$ 次迭代的尾随窗口内，如果该窗口中 $r_t$ 的平均值小于固定阈值 $\\epsilon_{\\text{dim}}$，则报告适应性递减成立。\n- 约束性诊断：在整个运行过程中监控最大特征值 $\\lambda_{\\max}(C_t)$ 和欧几里得范数 $\\lVert \\theta_t \\rVert_2$；如果 $\\max_t \\lambda_{\\max}(C_t) \\leq V_{\\max}$ 且 $\\max_t \\lVert \\theta_t \\rVert_2 \\leq R_{\\max}$，则报告约束性成立。\n\n对诊断和算法使用以下超参数，这些参数不可更改：\n\n- 维度 $d = 2$，预烧期迭代次数 $N_{\\text{burn}} = 1000$，总迭代次数 $N = 4000$，尾随窗口 $L = 500$，稳定项 $\\varepsilon = 10^{-6}$ 和 $\\delta = 10^{-12}$，基础提议缩放 $s_{\\text{base}} = (2.38)^2 / d$，递减阈值 $\\epsilon_{\\text{dim}} = 0.2$，约束界限 $V_{\\max} = 100.0$ 和 $R_{\\max} = 50.0$。\n- 初始状态: $\\theta_0 = (\\log(0.02), 0.5)$。\n\n在以下三个测试案例上运行该算法，每个案例都定义了预烧期后 $s_t$ 的缩放自适应规则：\n\n- 案例 A（旨在同时满足两个条件）：对所有 $t$，$s_t = s_{\\text{base}}$；自适应仅源于经验协方差 $\\Sigma_t$，该协方差通过对所有样本使用相等权重进行在线更新，因此其增量变化随着 $t$ 的增加而减小。\n- 案例 B（旨在违反适应性递减条件）：对于 $t > N_{\\text{burn}}$，每 $P=50$ 次迭代，交替地将 $s_t$ 乘以 $f$ 和 $1/f$，其中 $f = 3.0$（即，在交替的更新时刻，先 $s_t \\leftarrow f \\, s_t$ 然后 $s_t \\leftarrow s_t / f$）。这种持续的振荡旨在使提议协方差保持显著变化，从而违反适应性递减条件。\n- 案例 C（旨在违反约束性条件）：对于 $t > N_{\\text{burn}}$，在宽度为 $W = 50$ 的滑动窗口上，计算经验接受率 $a_t$，如果 $a_t  0.1$，则通过 $s_t \\leftarrow \\alpha s_t$ 更新 $s_t$；如果 $a_t  0.4$，则通过 $s_t \\leftarrow \\beta s_t$ 更新；否则保持 $s_t$ 不变，其中 $\\alpha = 1.2$ 且 $\\beta = 0.8$。$s_t$ 没有设置上限。此规则可能导致 $C_t$ 无界增长。\n\n对于每个案例，返回一个布尔值，指示是否两个诊断指标都得到满足，即当且仅当该次运行的适应性递减和约束性都成立时，返回 $\\text{True}$；否则返回 $\\text{False}$。\n\n您的程序必须为每个案例使用固定的随机种子来确定性地实现上述模拟和诊断，并生成一行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，“[resultA,resultB,resultC]”）。每个案例的结果必须是布尔值。输出中无需报告任何物理单位，因为要求的结果是布尔值。\n\n测试套件和覆盖范围：\n\n- 案例 A：适应性递减应满足，约束性也应满足；预期的布尔值为 $\\text{True}$。\n- 案例 B：适应性递减会因持续振荡而失败；预期的布尔值为 $\\text{False}$。\n- 案例 C：约束性会因提议的无界增长而失败；预期的布尔值为 $\\text{False}$。\n\n您的程序必须计算并以“[True,False,False]”的精确格式打印结果列表。不应打印任何其他文本。", "solution": "问题陈述经评估为 **有效**。它提出了一个在计算天体物理学领域中定义明确且具有科学依据的任务，特别关注自适应 MCMC 算法收敛条件的运行验证。模型、数据和参数是完整、一致且合理的。任务是实现一个确定性模拟，这是测试算法属性的标准方法。\n\n问题的核心是模拟一个 Random-Walk Metropolis MCMC 算法，从光子计数数据中推断天体物理学幂律模型的两个参数 $\\theta = (\\log A, \\gamma)$。该算法的提议协方差矩阵 $C_t$ 会根据链的历史进行自适应调整。这种自适应的有效性通过两个操作性诊断指标进行评估：适应性递减和约束性。\n\n首先，我们定义目标概率分布，即后验分布 $\\pi(\\theta)$，这是 MCMC 算法旨在采样的分布。根据贝叶斯定理，后验分布与似然和先验的乘积成正比，即 $\\pi(\\theta) \\propto \\mathcal{L}(\\theta | \\text{data}) \\cdot p(\\theta)$。在计算上，处理后验的对数形式更为稳定：\n$$\n\\log \\pi(\\theta) = \\log \\mathcal{L}(\\theta | \\text{data}) + \\log p(\\theta) + \\text{const.}\n$$\n数据由能量箱 $E_i$ 中曝光时间为 $T_i$ 的光子计数 $k_i$ 组成。计数被建模为独立的泊松变量，$k_i \\sim \\text{Poisson}(\\lambda_i)$，其中期望计数率 $\\lambda_i$ 由幂律模型 $\\lambda_i = A T_i (E_i/E_0)^{-\\gamma}$ 给出。根据我们的参数向量 $\\theta = (\\log A, \\gamma) = (\\theta_0, \\theta_1)$，我们有 $A = e^{\\theta_0}$，所以 $\\lambda_i = e^{\\theta_0} T_i (E_i/E_0)^{-\\theta_1}$。对数似然是各个对数泊松概率之和：\n$$\n\\log \\mathcal{L}(\\theta | k) = \\sum_{i} \\left( k_i \\log(\\lambda_i(\\theta)) - \\lambda_i(\\theta) - \\log(k_i!) \\right)\n$$\n项 $\\log(k_i!)$ 对于 $\\theta$ 是一个常数，在 MCMC 计算中可以省略。\n\n$\\log A = \\theta_0$ 和 $\\gamma = \\theta_1$ 的先验概率被指定为独立的高斯分布：$\\theta_0 \\sim \\mathcal{N}(\\mu_A, \\sigma_A^2)$ 和 $\\theta_1 \\sim \\mathcal{N}(\\mu_\\gamma, \\sigma_\\gamma^2)$。对数先验是：\n$$\n\\log p(\\theta) = -\\frac{1}{2} \\left( \\frac{\\theta_0 - \\mu_A}{\\sigma_A} \\right)^2 - \\frac{1}{2} \\left( \\frac{\\theta_1 - \\mu_\\gamma}{\\sigma_\\gamma} \\right)^2 + \\text{const.}\n$$\n未归一化的对数后验函数是未归一化的对数似然和对数先验项之和。\n\nMCMC 模拟通过 Random-Walk Metropolis 算法进行。在每次迭代 $t$ 中，从当前状态 $\\theta_t$ 使用对称提议分布 $\\theta' \\sim \\mathcal{N}(\\theta_t, C_t)$ 提议一个新状态 $\\theta'$。提议的状态以以下概率被接受：\n$$\n\\alpha(\\theta_t, \\theta') = \\min\\left(1, \\frac{\\pi(\\theta')}{\\pi(\\theta_t)}\\right) = \\min\\left(1, \\exp(\\log\\pi(\\theta') - \\log\\pi(\\theta_t))\\right)\n$$\n如果提议被接受，则 $\\theta_{t+1} = \\theta'$；否则，它被拒绝，并且 $\\theta_{t+1} = \\theta_t$。\n\n关键特征是提议协方差 $C_t$ 的自适应。它被定义为 $C_t = \\lambda_t (\\Sigma_t + \\varepsilon I)$，其中 $\\Sigma_t$ 是链的历史 $\\{\\theta_0, \\dots, \\theta_t\\}$ 的经验协方差，$\\varepsilon$ 是一个小的正稳定项，$\\lambda_t$ 是一个缩放因子。为了高效地计算 $\\Sigma_t$，使用了一种数值稳定的在线算法（Welford 算法的变体）来在每次迭代中更新样本均值和离差平方和矩阵。\n\n问题符号中关于缩放因子存在一个细微的歧义。问题将 $C_t$ 定义为 $s_t^2 (\\Sigma_t + \\varepsilon I)$，设置了基准值 $s_{\\text{base}} = (2.38)^2 / d$，并为案例 A 指定 $s_t=s_{\\text{base}}$。字面解释意味着方差缩放因子是 $s_{\\text{base}}^2$，这与理论上的最优值 $(2.38)^2/d$ 有显著差异。鉴于案例 A 预期会通过其诊断，我们推断其可能的意图是，我们称之为 $\\lambda_t$ 的被调整量，其基准值为 $(2.38)^2/d$。因此，我们的实现将使用 $\\lambda_t$作为协方差矩阵的缩放因子，其中 $\\lambda_t$ 根据每个案例给出的规则进行调整（$\\lambda_t$的基准值是问题中称为 $s_{\\text{base}}$ 的量）。\n\n模拟运行 $N=4000$ 次迭代，其中前 $N_{\\text{burn}}=1000$ 次作为预烧期被丢弃。模拟了三个测试案例，每个案例在预烧期后都有不同的缩放因子 $\\lambda_t$ 调整规则：\n- **案例 A**: $\\lambda_t$ 保持其基准值 $\\lambda_{\\text{base}} = (2.38)^2/d$ 不变。自适应仅通过更新 $\\Sigma_t$ 发生。这预计将满足收敛诊断。\n- **案例 B**: $\\lambda_t$ 被一个乘法因子 $f=3.0$ 及其倒数 $1/f$ 周期性地扰动。这种持续的、非递减的提议核变化旨在违反适应性递减条件。\n- **案例 C**: $\\lambda_t$ 基于最近窗口内的接受率进行调整。如果接受率太低，$\\lambda_t$ 增加；如果太高，则减少。对这种调整没有设置上限，可能导致提议协方差不受控制地增长，从而违反约束性条件。\n\n对于每个案例，计算两个诊断指标：\n1. **约束性**: 如果任何提议协方差的最大特征值 $\\max_t \\lambda_{\\max}(C_t)$ 和任何状态的最大范数 $\\max_t \\lVert \\theta_t \\rVert_2$ 保持在它们各自预定义的界限 $V_{\\max}$ 和 $R_{\\max}$ 以下，则该诊断满足。\n2. **适应性递减**: 如果在最后 $L=500$ 次迭代中，提议协方差的平均相对变化 $r_t = \\lVert C_t - C_{t-1} \\rVert_F / \\max(\\lVert C_{t-1} \\rVert_F, \\delta)$ 低于阈值 $\\epsilon_{\\text{dim}}$，则该诊断满足。\n\n每个案例的最终输出是一个单一的布尔值，当且仅当两个诊断都满足时，该值为 `True`。通过为每个案例使用固定的、不同的随机种子来确保确定性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the MCMC simulations and diagnostics for all test cases.\n    \"\"\"\n\n    # --- Problem Definition ---\n    # Fixed data\n    E = np.array([0.5, 1.0, 2.0, 5.0])  # Energy bin centers (keV)\n    T = np.array([10000.0, 10000.0, 10000.0, 10000.0])  # Exposure times (s)\n    E0 = 1.0  # Pivot energy (keV)\n    k = np.array([80, 20, 5, 1])  # Observed counts\n\n    # Prior parameters\n    mu_A = np.log(0.002)\n    sigma_A = 1.0\n    mu_gamma = 2.0\n    sigma_gamma = 1.0\n\n    # Hyperparameters\n    d = 2  # Dimension\n    N_burn = 1000\n    N = 4000\n    L = 500\n    eps = 1e-6\n    delta = 1e-12\n    # This is the variance scaling factor, which the problem confusingly calls s_base\n    variance_scale_base = (2.38**2) / d\n    epsilon_dim = 0.2\n    V_max = 100.0\n    R_max = 50.0\n    theta_0 = np.array([np.log(0.02), 0.5])\n\n    # Case-specific hyperparameters\n    P_B = 50\n    f_B = 3.0\n    W_C = 50\n    alpha_C = 1.2\n    beta_C = 0.8\n\n    # --- Log-Posterior Function ---\n    log_E_ratios = np.log(E / E0)\n\n    def log_posterior(theta):\n        \"\"\"Computes the unnormalized log-posterior probability.\"\"\"\n        log_A, gamma = theta[0], theta[1]\n        \n        if log_A > 20: # Prevent overflow in exp(log_A)\n            return -np.inf\n\n        # Log-likelihood\n        lambda_i = np.exp(log_A) * T * np.exp(-gamma * log_E_ratios)\n\n        # Check for invalid lambda values\n        if np.any(lambda_i = 0):\n            return -np.inf\n\n        log_like = np.sum(k * np.log(lambda_i) - lambda_i)\n\n        # Log-prior\n        log_prior_A = -0.5 * ((log_A - mu_A) / sigma_A)**2\n        log_prior_gamma = -0.5 * ((gamma - mu_gamma) / sigma_gamma)**2\n        log_prior = log_prior_A + log_prior_gamma\n        \n        return log_like + log_prior\n\n    def run_mcmc_case(case_name, seed):\n        \"\"\"Runs the MCMC simulation for a single case.\"\"\"\n        rng = np.random.default_rng(seed)\n\n        # Histories\n        theta_hist = np.zeros((N, d))\n        theta_hist[0] = theta_0\n        acceptance_history = []\n        \n        # Online covariance statistics (Welford's algorithm)\n        mean = theta_0.copy()\n        M2 = np.zeros((d, d))\n        count = 1\n\n        # Adaptive quantities\n        variance_scale = variance_scale_base\n        Sigma = np.zeros((d, d))\n        \n        # Initial proposal covariance C_0\n        C = variance_scale * (Sigma + eps * np.identity(d))\n        if np.all(Sigma == 0):\n             C = variance_scale * eps * np.identity(d) # A more robust initialization\n\n        # History for diagnostics\n        C_history = [C]\n        theta_norm_history = [np.linalg.norm(theta_0)]\n        lambda_max_history = [np.max(np.linalg.eigvalsh(C))]\n\n        # Case B specific state\n        if case_name == 'B':\n            osc_factor = f_B\n\n        # Main MCMC loop\n        for t in range(N - 1): # t from 0 to N-2\n            \n            # --- Propose and Accept/Reject ---\n            current_theta = theta_hist[t]\n            try:\n                proposal = rng.multivariate_normal(current_theta, C)\n            except np.linalg.LinAlgError:\n                # If C is not positive semidefinite, chain is stuck.\n                proposal = current_theta\n\n            logp_curr = log_posterior(current_theta)\n            logp_prop = log_posterior(proposal)\n            \n            accepted = False\n            if logp_prop > -np.inf and (logp_prop - logp_curr >= 0 or np.log(rng.uniform())  logp_prop - logp_curr):\n                theta_hist[t + 1] = proposal\n                accepted = True\n            else:\n                theta_hist[t + 1] = current_theta\n            \n            acceptance_history.append(accepted)\n            \n            # --- Update and Adapt for next step ---\n            # 1. Update online moments\n            count += 1\n            x = theta_hist[t + 1]\n            delta_pre = x - mean\n            mean += delta_pre / count\n            delta_post = x - mean\n            M2 += np.outer(delta_pre, delta_post)\n\n            if count > 1:\n                Sigma = M2 / (count - 1)\n\n            # 2. Adapt variance scale\n            time_idx = t + 1\n            \n            if case_name == 'B' and time_idx > N_burn and (time_idx - N_burn) % P_B == 0:\n                variance_scale *= osc_factor\n                osc_factor = 1.0 / osc_factor\n            \n            if case_name == 'C' and time_idx > N_burn:\n                window_start = max(0, time_idx - W_C)\n                acc_rate = np.mean(acceptance_history[window_start:])\n                if acc_rate  0.1:\n                    variance_scale *= alpha_C\n                elif acc_rate > 0.4:\n                    variance_scale *= beta_C\n            \n            # 3. Form new covariance for next step\n            C = variance_scale * (Sigma + eps * np.identity(d))\n\n            # 4. Store diagnostics for step t+1\n            C_history.append(C)\n            theta_norm_history.append(np.linalg.norm(theta_hist[t + 1]))\n            try:\n                lambda_max_history.append(np.max(np.linalg.eigvalsh(C)))\n            except np.linalg.LinAlgError:\n                lambda_max_history.append(np.inf) # Penalize non-PSD covariance\n\n        # --- Perform Diagnostics ---\n        # 1. Containment\n        containment_ok = (max(lambda_max_history) = V_max) and (max(theta_norm_history) = R_max)\n\n        # 2. Diminishing Adaptation\n        r_ts = []\n        for t in range(N - L, N):\n            C_t = C_history[t]\n            C_t_minus_1 = C_history[t - 1]\n            norm_diff = np.linalg.norm(C_t - C_t_minus_1, 'fro')\n            norm_prev = np.linalg.norm(C_t_minus_1, 'fro')\n            r_t = norm_diff / max(norm_prev, delta)\n            r_ts.append(r_t)\n        \n        avg_r = np.mean(r_ts)\n        diminishing_ok = avg_r  epsilon_dim\n        \n        return containment_ok and diminishing_ok\n\n    # --- Run all cases and collect results ---\n    results = [\n        run_mcmc_case('A', seed=42),\n        run_mcmc_case('B', seed=43),\n        run_mcmc_case('C', seed=44)\n    ]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, [r.item() for r in results]))}]\")\n\nsolve()\n\n```", "id": "3528600"}]}