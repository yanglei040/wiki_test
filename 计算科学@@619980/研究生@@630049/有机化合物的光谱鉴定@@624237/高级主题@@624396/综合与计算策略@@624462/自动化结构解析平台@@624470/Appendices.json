{"hands_on_practices": [{"introduction": "自动化结构解析平台的核心是处理高质量的质谱数据。此实践将带你深入了解质谱数据的基石——质量精度。通过推导以百万分率（ppm）为单位的质量精度公式，并应用锁模（lock-mass）校正这一关键技术，你将亲身体验如何从原始观测数据中获得高置信度的质量信息，这是后续所有解析步骤的根本前提。[@problem_id:3693918]", "problem": "一个自动化结构解析平台依赖于高分辨率质量测量来筛选由串联质谱生成的候选结构。一个核心的评分特征是以百万分率（ppm）表示的质量准确度。从相对误差的基本定义和百万分率（ppm）即百万分之一单位的定义出发，首先推导一个用观测质量和理论质量表示的以百万分率（ppm）为单位的质量准确度表达式。然后，考虑一次高分辨率质谱采集，其中使用背景校准离子进行锁模质量校正。假设测量在正离子模式下进行，电荷为 $z=1$，因此 $m/z$ 在数值上等于质量。在相关质量范围内，假设仪器的质量误差可以很好地近似为一个加性常数偏移。\n\n给定：\n- 理论锁模质量 $m_{\\text{L,theoretical}} = 371.101237$。\n- 观测锁模质量 $m_{\\text{L,observed}} = 371.101737$。\n- 理论分析物单同位素质量 $m_{\\text{A,theoretical}} = 300.123456$。\n- 观测分析物单同位素质量 $m_{\\text{A,observed}} = 300.124011$。\n\n在加性偏移假设下，推导锁模质量校正后的分析物质量，然后使用您推导的表达式计算分析物校正后的质量准确度（以百万分率 ppm 为单位）。将您的最终答案四舍五入到四位有效数字。以 ppm 为单位表示最终答案。", "solution": "首先验证该问题，以确保其具有科学依据、问题设定良好且客观。\n\n### 步骤1：提取已知条件\n明确给出的数据和条件如下：\n-   理论锁模质量：$m_{\\text{L,theoretical}} = 371.101237$\n-   观测锁模质量：$m_{\\text{L,observed}} = 371.101737$\n-   理论分析物单同位素质量：$m_{\\text{A,theoretical}} = 300.123456$\n-   观测分析物单同位素质量：$m_{\\text{A,observed}} = 300.124011$\n-   电荷态：$z=1$\n-   质量误差模型：在相关质量范围内，仪器的质量误差可近似为一个加性常数偏移。\n-   任务1：推导以百万分率（ppm）表示的质量准确度表达式。\n-   任务2：推导锁模质量校正后的分析物质量。\n-   任务3：计算分析物校正后的质量准确度（以ppm为单位）。\n-   四舍五入要求：将最终答案四舍五入到四位有效数字。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题具有科学依据，因为锁模质量校正是高分辨率质谱中用于校正仪器漂移以提高质量准确度的一项标准且基础的技术。给定的质量值对于小分子有机物是符合实际的。加性常数质量误差的假设是在有限质量范围内进行仪器校准时一个常见且合理的一阶近似。问题设定良好，提供了所有必要的数据和清晰、无歧义的目标。语言精确且客观。因此，该问题被认为是有效的。\n\n### 步骤3：结论与行动\n问题有效。将提供一个完整、有理有据的解答。\n\n### 解答推导\n\n解答过程按问题要求分四个阶段进行：\n1.  推导以百万分率（ppm）为单位的质量准确度公式。\n2.  使用锁模质量校准物计算质量误差偏移。\n3.  计算经锁模质量校正的分析物质量。\n4.  计算分析物校正后的质量准确度。\n\n#### 1. ppm 质量准确度的推导\n\n质量准确度是质量测量中误差的度量。绝对误差 $\\Delta m$ 是观测质量 $m_{\\text{observed}}$ 与理论质量 $m_{\\text{theoretical}}$ 之间的差值。\n$$\n\\Delta m = m_{\\text{observed}} - m_{\\text{theoretical}}\n$$\n相对误差 $E_{\\text{rel}}$ 是通过将绝对误差除以理论质量进行归一化，使其成为一个无量纲量。\n$$\nE_{\\text{rel}} = \\frac{\\Delta m}{m_{\\text{theoretical}}} = \\frac{m_{\\text{observed}} - m_{\\text{theoretical}}}{m_{\\text{theoretical}}}\n$$\n单位“百万分率”（ppm）对应于因子 $10^{-6}$。因此，为了以 ppm 表示相对误差，我们将其乘以 $10^6$。记为 $E_{\\text{ppm}}$。\n$$\nE_{\\text{ppm}} = E_{\\text{rel}} \\times 10^6 = \\left( \\frac{m_{\\text{observed}} - m_{\\text{theoretical}}}{m_{\\text{theoretical}}} \\right) \\times 10^6\n$$\n这就是所要求的以 ppm 为单位的质量准确度表达式。\n\n#### 2. 质量误差偏移的计算\n\n问题陈述，仪器的质量误差可以建模为一个加性常数偏移，我们记为 $\\delta$。这意味着对于任何真实质量 $m_{\\text{true}}$，仪器测量的观测质量 $m_{\\text{observed}}$ 由下式给出：\n$$\nm_{\\text{observed}} = m_{\\text{true}} + \\delta\n$$\n锁模质量校准物提供了一个估计此偏移的参考点。使用锁模质量数据，偏移 $\\delta$ 可以计算为观测锁模质量值与理论锁模质量值之差。\n$$\n\\delta = m_{\\text{L,observed}} - m_{\\text{L,theoretical}}\n$$\n代入给定值：\n$$\n\\delta = 371.101737 - 371.101237 = 0.000500\n$$\n假设这个 $0.000500$ Da (道尔顿) 的常数偏移适用于相关质量范围内的所有测量，包括分析物的测量。\n\n#### 3. 锁模质量校正后的分析物质量的计算\n\n为求得校正后的分析物质量 $m_{\\text{A,corrected}}$，我们从观测的分析物质量 $m_{\\text{A,observed}}$ 中减去计算出的质量误差偏移 $\\delta$。\n$$\nm_{\\text{A,corrected}} = m_{\\text{A,observed}} - \\delta\n$$\n代入 $m_{\\text{A,observed}}$ 的给定值和 $\\delta$ 的计算值：\n$$\nm_{\\text{A,corrected}} = 300.124011 - 0.000500 = 300.123511\n$$\n这就是锁模质量校正后的分析物质量。\n\n#### 4. 校正后质量准确度的计算\n\n最后，我们计算锁模质量校正后分析物的质量准确度（以ppm为单位）。我们使用推导出的 $E_{\\text{ppm}}$ 公式，其中校正后的分析物质量 $m_{\\text{A,corrected}}$ 作为“观测”质量，并将其与理论分析物质量 $m_{\\text{A,theoretical}}$ 进行比较。\n$$\nE_{\\text{A,ppm}} = \\left( \\frac{m_{\\text{A,corrected}} - m_{\\text{A,theoretical}}}{m_{\\text{A,theoretical}}} \\right) \\times 10^6\n$$\n首先，我们计算分析物的新绝对误差：\n$$\n\\Delta m_{\\text{A,corrected}} = m_{\\text{A,corrected}} - m_{\\text{A,theoretical}} = 300.123511 - 300.123456 = 0.000055\n$$\n现在，我们计算 ppm 误差：\n$$\nE_{\\text{A,ppm}} = \\left( \\frac{0.000055}{300.123456} \\right) \\times 10^6 \\approx 0.18325609 \\text{ ppm}\n$$\n问题要求将最终答案四舍五入到四位有效数字。第一位有效数字是 $1$，其后是 $8$、$3$ 和 $2$。第五位有效数字是 $5$，因此需要将第四位数字向上舍入。\n$$\nE_{\\text{A,ppm}} \\approx 0.1833 \\text{ ppm}\n$$\n这就是分析物校正后的最终质量准确度。", "answer": "$$\n\\boxed{0.1833}\n$$", "id": "3693918"}, {"introduction": "获得精确的母离子质量后，下一步是解析其串联质谱（MS/MS）图谱。这个实践将你置于算法设计者的位置，任务是将观测到的碎片离子峰与候选结构预测的碎片进行匹配。你将学习如何构建一个包含高斯误差模型、未指认峰惩罚和模型复杂度惩罚的优化目标函数，并将其转化为一个线性总和分配问题来求解，这是自动化平台中连接理论碎片与实验证据的核心步骤。[@problem_id:3693904]", "problem": "您的任务是形式化并解决一个在串联质谱（MS/MS）中为自动化结构解析平台而产生的峰-碎片匹配问题。目标是设计并实现一个程序，给定观测到的MS/MS峰和一组从候选结构预测的碎片质量，该程序将每个观测峰最多分配给一个预测质量，或将其标记为未分配。该分配应最小化一个目标函数，该函数根据高斯仪器误差模型对质量偏差进行惩罚，对未分配的峰进行惩罚，并为避免过拟合而对模型复杂度进行惩罚。所有量在下文中都有精确定义，并且每个符号的使用方式都保持一致且科学真实。\n\n基本原理：假设质量偏差服从高斯测量误差模型，该模型指出观测峰与其真实碎片之间的质量误差被建模为一个均值为 $0$、标准差为 $\\sigma$ 道尔顿的高斯随机变量。设偏差 $\\Delta$ 的负对数似然为\n$$\n\\ell(\\Delta;\\sigma) = \\frac{1}{2}\\left(\\frac{\\Delta}{\\sigma}\\right)^2 + \\ln\\left(\\sqrt{2\\pi}\\,\\sigma\\right).\n$$\n该惩罚项与偏差的平方成正比，这与经过充分测试的仪器质量精度模型一致。\n\n问题形式化：设观测峰质量为 $m_i$（$i \\in \\{1,\\dots,n\\}$），单位为道尔顿，对应的归一化强度为 $w_i \\in [0,1]$。设预测的碎片质量集合为 $c_j$（$j \\in \\{1,\\dots,k\\}$），单位为道尔顿。设 $\\sigma$ 为质量精度（道尔顿），$T$ 为匹配容差（道尔顿），$\\lambda_u$ 为未分配峰的惩罚系数，$\\lambda_c$ 为每个已分配的预测碎片或中性丢失的模型复杂度惩罚系数。设 $M$ 为一个大的不可行常数，用于在绝对偏差超过容差时阻止分配。定义二元分配变量 $x_{i,j} \\in \\{0,1\\}$ 表示峰 $i$ 是否分配给预测质量 $j$，以及二元未分配变量 $u_i \\in \\{0,1\\}$ 表示峰 $i$ 是否未分配。\n\n目标是最小化总成本\n$$\n\\min_{x,u}\\quad \\sum_{i=1}^{n}\\sum_{j=1}^{k} x_{i,j}\\left[w_i\\,\\ell(m_i - c_j;\\sigma) + \\lambda_c\\right] + \\sum_{i=1}^{n} u_i \\left[\\lambda_u\\,w_i\\right],\n$$\n约束条件如下\n$$\n\\sum_{j=1}^{k} x_{i,j} + u_i = 1 \\quad \\text{对所有 } i \\in \\{1,\\dots,n\\},\n$$\n$$\n\\sum_{i=1}^{n} x_{i,j} \\le 1 \\quad \\text{对所有 } j \\in \\{1,\\dots,k\\},\n$$\n$$\nx_{i,j} \\in \\{0,1\\},\\quad u_i \\in \\{0,1\\},\n$$\n并通过以下方式编码可行性\n$$\nx_{i,j} = 0 \\quad \\text{当 } |m_i - c_j| > T,\n$$\n这通过将相应的分配成本设置为一个大的常数 $M$ 来实现，以防止选择不可行的匹配。此形式化将每个峰最多分配给一个预测质量，对未分配的峰进行惩罚，并通过每次分配的复杂度惩罚来抑制过拟合。\n\n单位说明：所有质量 $m_i$ 和 $c_j$ 的单位为道尔顿，$\\sigma$ 和 $T$ 的单位为道尔顿，强度 $w_i$ 是在 $[0,1]$ 区间内的无量纲值，目标函数值也是无量纲的。不使用角度。不使用百分比；任何分数都表示为小数。\n\n您的任务是实现一个程序，将上述优化问题精确地作为一个在 $n$ 行和 $k+n$ 列的矩形成本矩阵上的线性总和分配问题来求解（最后 $n$ 列作为每个峰的虚拟“未分配”槽）。请使用以下具有科学真实参数的测试套件。对于每个测试用例，输出最小化的目标值和峰-候选分配向量，其中已分配的候选由其基于 $0$ 的索引表示，未分配的峰由 $-1$ 表示。\n\n测试套件：\n- 情况 1（理想情况）：$m = [100.0,114.0,128.0]$ 道尔顿, $w = [0.9,0.6,0.4]$, $c = [99.999,114.002,127.999]$ 道尔顿, $\\sigma = 0.01$ 道尔顿, $T = 0.05$ 道尔顿, $\\lambda_u = 1.2$, $\\lambda_c = 0.3$, $M = 10^6$。\n- 情况 2（容差边界情况）：$m = [150.0,200.0]$ 道尔顿, $w = [1.0,0.5]$, $c = [150.04,200.005]$ 道尔顿, $\\sigma = 0.01$ 道尔顿, $T = 0.03$ 道尔顿, $\\lambda_u = 0.8$, $\\lambda_c = 0.2$, $M = 10^6$。\n- 情况 3（无候选）：$m = [300.0,320.0,340.0]$ 道尔顿, $w = [0.7,0.5,0.3]$, $c = []$, $\\sigma = 0.02$ 道尔顿, $T = 0.05$ 道尔顿, $\\lambda_u = 1.0$, $\\lambda_c = 0.0$, $M = 10^6$。\n- 情况 4（存在冲突的过拟合压力情况）：$m = [500.0,500.03,499.97]$ 道尔顿, $w = [1.0,0.8,0.7]$, $c = [500.0,500.02]$ 道尔顿, $\\sigma = 0.01$ 道尔顿, $T = 0.03$ 道尔顿, $\\lambda_u = 0.5$, $\\lambda_c = 0.25$, $M = 10^6$。\n\n要求的最终输出格式：您的程序应生成一行包含结果的文本，该结果是一个用方括号括起来的逗号分隔列表，其中每个测试用例的结果是一个形式为 $[\\text{objective\\_value},\\ \\text{assignment\\_vector}]$ 的双元素列表。例如，输出结构为 $[[o_1,[a_{1,1},\\dots,a_{1,n_1}]], [o_2,[a_{2,1},\\dots]], \\dots]$，其中每个 $o_i$ 是一个浮点数，每个 $a_{i,\\cdot}$ 是候选列表的整数索引，如果未分配则为 $-1$。", "solution": "所呈现的问题是一个旨在将观测到的质谱峰分配给一组预测碎片质量的约束优化任务。这是用于自动化结构解析的计算质谱学领域中一个常见的子问题。我已验证了该问题陈述，并发现其在科学上是合理的、定义明确的，并且在算法上是可解的。\n\n问题的核心是在一组约束条件下最小化一个总成本函数。目标函数是三项之和：\n1. 将观测峰 $m_i$ 分配给预测候选质量 $c_j$ 的拟合优度成本，该成本由峰强度 $w_i$ 加权。此成本基于在高斯误差模型（标准差为 $\\sigma$）下质量偏差 $\\Delta = m_i - c_j$ 的负对数似然 $\\ell(\\Delta;\\sigma)$。\n2. 为防止过拟合，对每个已进行的分配施加模型复杂度惩罚 $\\lambda_c$。\n3. 对每个未分配的峰 $m_i$ 施加惩罚 $\\lambda_u w_i$。\n\n约束条件如下：\n1. 每个观测峰 $m_i$ 必须被精确分配给一个预测候选 $c_j$，或者被标记为未分配。\n2. 每个预测候选 $c_j$ 最多只能被分配给一个观测峰 $m_i$。\n3. 只有当 $m_i$ 和 $c_j$ 之间的绝对质量差 $|m_i - c_j|$ 在指定的容差 $T$ 内时，它们之间的分配才是允许的。\n\n这种结构在形式上等同于**线性总和分配问题**，也称为二分图中的最小权完美匹配问题。我们可以使用标准算法（如匈牙利算法或最小成本最大流算法）高效地解决此问题。`scipy.optimize.linear_sum_assignment` 函数实现了这样一个求解器。\n\n要应用此求解器，我们必须首先构建一个封装了目标函数和约束条件的成本矩阵。假设有 $n$ 个观测峰和 $k$ 个预测候选。任务是分配这 $n$ 个峰中的每一个。每个峰可以分配给 $k$ 个候选之一，或保持未分配。为了在分配框架内对“未分配”选项进行建模，我们引入 $n$ 个“虚拟”或“未分配”槽，每个峰对应一个。这确保了每个峰都有一个分配选项（可以分配给一个真实候选，也可以分配给它自己的未分配槽），并且可以同时将多个峰保持未分配状态。\n\n因此，我们构建一个大小为 $n \\times (k+n)$ 的成本矩阵 $C$。行 $i \\in \\{0, \\dots, n-1\\}$ 对应于观测峰 $m_i$。前 $k$ 列 $j \\in \\{0, \\dots, k-1\\}$ 对应于预测候选 $c_j$。后 $n$ 列 $j \\in \\{k, \\dots, k+n-1\\}$ 对应于虚拟的未分配槽。\n\n成本矩阵的条目 $C_{i,j}$ 定义如下：\n\n1. **分配成本（对于 $j  k$）**：这是将峰 $m_i$ 分配给候选 $c_j$ 的成本。根据目标函数，此成本为 $w_i\\,\\ell(m_i - c_j;\\sigma) + \\lambda_c$。如果条件不满足，则通过将成本设置为一个大的不可行常数 $M$ 来强制执行可行性约束 $|m_i - c_j| \\le T$。\n令 $\\Delta_{i,j} = m_i - c_j$。负对数似然函数为 $\\ell(\\Delta_{i,j};\\sigma) = \\frac{1}{2}\\left(\\frac{\\Delta_{i,j}}{\\sigma}\\right)^2 + \\ln\\left(\\sqrt{2\\pi}\\,\\sigma\\right)$。\n因此，对于 $i \\in \\{0, \\dots, n-1\\}$ 和 $j \\in \\{0, \\dots, k-1\\}$：\n$$\nC_{i,j} =\n\\begin{cases}\nw_i \\left[ \\frac{1}{2}\\left(\\frac{m_i - c_j}{\\sigma}\\right)^2 + \\ln\\left(\\sqrt{2\\pi}\\,\\sigma\\right) \\right] + \\lambda_c  \\text{如果 } |m_i - c_j| \\le T \\\\\nM  \\text{如果 } |m_i - c_j|  T\n\\end{cases}\n$$\n\n2. **未分配成本（对于 $j \\ge k$）**：这是将峰 $m_i$ 保持未分配的成本。我们为每个峰创建一个专用的未分配槽。设第 $k+i$ 列为将峰 $i$ 保持未分配的槽。问题中给出的成本为 $\\lambda_u w_i$。为确保峰 $i$ 只能占用其自身的未分配槽，我们将峰 $i$ 分配给另一个峰的虚拟槽（即第 $k+i'$ 列，其中 $i' \\ne i$）的成本设置为大的常数 $M$。\n因此，对于 $i \\in \\{0, \\dots, n-1\\}$ 和虚拟列索引 $j' = j-k \\in \\{0, \\dots, n-1\\}$：\n$$\nC_{i,j} = C_{i,k+j'} =\n\\begin{cases}\n\\lambda_u w_i  \\text{如果 } j' = i \\\\\nM  \\text{如果 } j' \\ne i\n\\end{cases}\n$$\n\n构建好 $n \\times (k+n)$ 的成本矩阵 $C$ 后，`scipy.optimize.linear_sum_assignment(C)` 会找到 $n$ 个行（峰）到 $n$ 个唯一列的最优分配。求解器返回最优分配的行和列索引。这些索引处的成本总和即为最小化的总目标值。\n\n最后，我们解释得到的列索引以构建最终的分配向量。对于每个峰 $i$，如果它被分配到列 $j  k$，则它与候选 $c_j$ 匹配，我们记录索引 $j$。如果它被分配到列 $j \\ge k$，则表示未分配，我们将其记录为 $-1$。此过程保证了对指定优化问题的精确解。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Test suite from the problem statement\n    test_cases = [\n        {\n            \"m\": [100.0, 114.0, 128.0], \"w\": [0.9, 0.6, 0.4],\n            \"c\": [99.999, 114.002, 127.999], \"sigma\": 0.01,\n            \"T\": 0.05, \"lambda_u\": 1.2, \"lambda_c\": 0.3, \"M\": 1e6\n        },\n        {\n            \"m\": [150.0, 200.0], \"w\": [1.0, 0.5],\n            \"c\": [150.04, 200.005], \"sigma\": 0.01,\n            \"T\": 0.03, \"lambda_u\": 0.8, \"lambda_c\": 0.2, \"M\": 1e6\n        },\n        {\n            \"m\": [300.0, 320.0, 340.0], \"w\": [0.7, 0.5, 0.3],\n            \"c\": [], \"sigma\": 0.02,\n            \"T\": 0.05, \"lambda_u\": 1.0, \"lambda_c\": 0.0, \"M\": 1e6\n        },\n        {\n            \"m\": [500.0, 500.03, 499.97], \"w\": [1.0, 0.8, 0.7],\n            \"c\": [500.0, 500.02], \"sigma\": 0.01,\n            \"T\": 0.03, \"lambda_u\": 0.5, \"lambda_c\": 0.25, \"M\": 1e6\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_assignment_problem(**case)\n        results.append(result)\n\n    # Format the final output string exactly as specified.\n    # str() on a list provides the required internal spacing.\n    # The join then combines the list strings with just a comma.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef solve_assignment_problem(m, w, c, sigma, T, lambda_u, lambda_c, M):\n    \"\"\"\n    Solves the peak-to-fragment assignment problem for a single case.\n\n    Args:\n        m (list): Observed peak masses.\n        w (list): Normalized peak intensities.\n        c (list): Predicted candidate masses.\n        sigma (float): Mass accuracy standard deviation.\n        T (float): Matching tolerance.\n        lambda_u (float): Penalty coefficient for unassigned peaks.\n        lambda_c (float): Model complexity penalty coefficient.\n        M (float): Large infeasibility constant.\n\n    Returns:\n        list: A list containing the minimized objective value (float) and\n              the assignment vector (list of ints).\n    \"\"\"\n    n = len(m)\n    k = len(c)\n\n    # The cost matrix will have n rows (peaks) and k+n columns\n    # (k candidates + n unassigned slots).\n    cost_matrix = np.full((n, k + n), M)\n\n    # Part 1: Calculate assignment costs (first k columns)\n    if k > 0:\n        m_arr = np.array(m)[:, np.newaxis]\n        c_arr = np.array(c)[np.newaxis, :]\n        w_arr = np.array(w)[:, np.newaxis]\n\n        # Mass deviations for all (peak, candidate) pairs\n        delta = m_arr - c_arr\n\n        # Negative log-likelihood calculation\n        # l(d;s) = 0.5 * (d/s)^2 + ln(sqrt(2*pi)*s)\n        log_term = np.log(np.sqrt(2 * np.pi) * sigma)\n        neg_log_likelihood = 0.5 * (delta / sigma)**2 + log_term\n\n        # Full assignment cost, including intensity weight and complexity penalty\n        assignment_costs = w_arr * neg_log_likelihood + lambda_c\n\n        # Apply tolerance T to filter infeasible assignments\n        feasible_mask = np.abs(delta) = T\n        cost_matrix[:, :k] = np.where(feasible_mask, assignment_costs, M)\n\n    # Part 2: Calculate unassignment costs (last n columns)\n    # Each peak i has a dedicated unassigned slot at column k+i.\n    unassignment_costs = lambda_u * np.array(w)\n    for i in range(n):\n        cost_matrix[i, k + i] = unassignment_costs[i]\n\n    # Solve the linear sum assignment problem\n    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n\n    # Calculate the total cost from the optimal assignment\n    min_objective_value = cost_matrix[row_ind, col_ind].sum()\n\n    # Construct the assignment vector from the column indices\n    # col_ind[i] gives the column chosen for peak (row) i.\n    # If col_ind[i]  k, it's an assignment to candidate col_ind[i].\n    # Otherwise, the peak is unassigned.\n    assignment_vector = np.full(n, -1, dtype=int)\n    assigned_mask = col_ind  k\n    assignment_vector[assigned_mask] = col_ind[assigned_mask]\n\n    return [min_objective_value, assignment_vector.tolist()]\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3693904"}, {"introduction": "单独的碎片峰匹配只揭示了故事的一部分。为了完整地重构分子的碎裂过程，我们需要将这些碎片连接成一个连贯的碎裂路径。此高级实践要求你构建一个碎裂图，并定义一个基于概率模型的综合目标函数，用于评估整个碎裂树的合理性。通过寻找最优的有向树（arborescence），你将模拟自动化平台如何整合所有证据——包括峰强度、质量精度和化学先验知识——来推断最可能的分子碎裂途径。[@problem_id:3693961]", "problem": "您正在设计一个简化的自动化结构解析模块，该模块根据观测到的串联质谱（MS/MS）数据对碎裂树进行评分。该模块必须在一个碎裂图上运行，其中节点代表候选的子结构（包括前体），有向边代表产生中性丢失的可能断裂。您的任务是根据所提供的质量数构建碎裂图，定义一个基于概率建模的有原则的目标函数，并计算出能最大化该目标函数的最合理的、以前体为根的有向生成树（有向生成树）。\n\n该问题的基本基础是将MS/MS的强度解释为碎片形成概率的代理，将高斯质量测量误差用于峰与碎片的匹配，以及从中性丢失的经验化学知识中派生的先验概率。您的推导和计算必须从以下几点开始：\n\n- 质量测量误差的高斯概率密度函数，对于一个质荷比 $m/z$ 值为 $x$ 的峰，匹配一个质量为 $m$、质量精度为 $\\sigma$ 的碎片，其函数为 $$\\mathcal{N}(x; m, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - m)^2}{2\\sigma^2}\\right)。$$\n- 中性丢失的经验先验概率（例如，水、氨、甲基、一氧化碳、二氧化碳），指定为从碎裂化学中已知的基本概率。\n\n您必须形式化一个在碎裂图 $G=(V,E)$ 上、以前体节点 $r$ 为根的有向生成树 $T$ 的目标函数。其中节点集为 $V=\\{r, v_1, \\dots, v_n\\}$，有向边集为 $E$。对于 $i \\geq 1$，每个节点 $v_i$ 有一个候选碎片质量 $m_i$（单位为道尔顿，Da），前体节点 $r$ 的质量为 $M_p$（单位为道尔顿）。观测到的MS/MS谱图是一个有限的峰集合 $S=\\{(m_j, I_j)\\}_{j=1}^N$，其中 $m_j$ 的单位为道尔顿，强度 $I_j$ 为非负数，您必须将其归一化，使得 $\\sum_{j=1}^{N} I_j = 1$。设 $\\alpha  0$ 为强度加权指数，$\\sigma  0$ 为质量精度（单位为道尔顿）。\n\n将质量为 $m_v$ 的节点 $v$ 的碎片似然定义为由强度加权的高斯似然混合，\n$$\n\\ell(v) = \\sum_{j=1}^{N} I_j^\\alpha \\, \\mathcal{N}(m_j; m_v, \\sigma).\n$$\n使用以下规则定义有向边 $(u \\to v)$ 的中性丢失先验，其丢失量 $d = m_u - m_v  0$。设已知丢失的集合为\n$$\n\\mathcal{L} = \\{(\\text{H}_2\\text{O}, \\, 18.0106, \\, p_{\\text{H}_2\\text{O}}), \\, (\\text{NH}_3, \\, 17.0265, \\, p_{\\text{NH}_3}), \\, (\\text{CH}_3, \\, 15.0235, \\, p_{\\text{CH}_3}), \\, (\\text{CO}, \\, 27.9949, \\, p_{\\text{CO}}), \\, (\\text{CO}_2, \\, 43.9898, \\, p_{\\text{CO}_2}) \\},\n$$\n其中中间项是丢失质量（单位为道尔顿），最后一项是其基本先验概率。给定一个容差 $\\delta  0$（单位为道尔顿），如果存在一个质量为 $l$ 的已知丢失，使得 $|d - l| \\leq \\delta$，则将先验设置为该丢失的基本概率；否则，设置一个随量值衰减的未知丢失先验，\n$$\n\\pi(d) = p_u \\, \\exp(-\\lambda d),\n$$\n其中 $p_u \\in (0,1)$ 和 $\\lambda  0$ 是常数。\n\n设 $\\beta  0$ 用于加权先验的贡献，$\\gamma \\geq 0$ 用于惩罚较大的丢失。将一个有向生成树 $T$（其边集为 $E_T \\subseteq E$，每个节点 $v \\in V \\setminus \\{r\\}$ 必须有且仅有一条入边）的总目标定义为\n$$\nJ(T) = \\sum_{(u \\to v) \\in E_T} \\left[ \\log \\ell(v) + \\beta \\log \\pi(m_u - m_v) - \\gamma (m_u - m_v) \\right].\n$$\n您必须假设边只允许从质量较大的节点指向质量较小的节点，即，仅当 $m_u  m_v$ 时，才允许 $(u \\to v) \\in E$。在此约束下，碎裂图是一个按质量排序的有向无环图。\n\n您的程序必须：\n\n1. 对于每个测试用例，从前体质量 $M_p$ 和候选碎片质量列表 $m_i$（单位为道尔顿）构建节点集 $V$。通过包含所有满足 $m_u  m_v$ 的节点对 $(u \\to v)$ 来构建有向边集 $E$，包括从前体节点 $r$ 到每个碎片节点 $v$ 的边。\n2. 使用归一化的强度和高斯质量似然，为每个碎片节点计算 $\\ell(v)$。使用一个小的下限值 $\\epsilon = 10^{-12}$，通过将 $\\ell(v)$ 替换为 $\\max(\\ell(v), \\epsilon)$ 来避免对零取对数。\n3. 使用上述已知丢失容差规则为每条边计算 $\\pi(d)$。\n4. 计算边权重 $w(u \\to v) = \\log \\ell(v) + \\beta \\log \\pi(m_u - m_v) - \\gamma (m_u - m_v)$。\n5. 因为图在质量顺序上是无环的，通过为每个碎片节点 $v \\in V \\setminus \\{r\\}$，在所有满足 $m_u  m_v$ 的允许父节点 $u$ 中，选择具有最大权重 $w(u \\to v)$ 的单条入边 $(u \\to v)$，来找到最大目标生成树。总目标 $J(T)$ 则是所有碎片节点上这些选定权重的总和。\n6. 为测试套件生成最终输出，为一行包含每个测试用例的总目标值 $J(T)$ 的列表，四舍五入到六位小数，格式为用方括号括起来的逗号分隔列表。不得打印任何其他文本。\n\n物理和数值单位：所有质量（$m_j$、$m_v$、$M_p$ 和已知丢失质量）均以道尔顿（Da）为单位。最终答案必须是浮点数（小数）。\n\n使用以下测试套件。对于每个案例，输入都已明确提供：\n\n- 案例 A（包含多个已知中性丢失的理想情况）：\n    - 前体质量 $M_p = 180.0630$ Da。\n    - 候选碎片质量 (Da): $[162.0524, \\, 145.0259, \\, 130.0024, \\, 102.0075]$。\n    - 观测到的峰 $(m_j, I_j)$: $[(162.0520, \\, 0.8), \\, (145.0260, \\, 0.6), \\, (130.0020, \\, 0.5), \\, (102.0080, \\, 0.3), \\, (90.0000, \\, 0.1)]$。\n- 案例 B（单一主导碎片的边界条件）：\n    - 前体质量 $M_p = 150.0520$ Da。\n    - 候选碎片质量 (Da): $[132.0414]$。\n    - 观测到的峰 $(m_j, I_j)$: $[(132.0410, \\, 0.9), \\, (120.0000, \\, 0.2), \\, (100.0000, \\, 0.1)]$。\n- 案例 C（直接丢失和逐步丢失之间存在歧义的边缘情况）：\n    - 前体质量 $M_p = 200.0840$ Da。\n    - 候选碎片质量 (Da): $[182.0734, \\, 165.0469, \\, 150.0234]$。\n    - 观测到的峰 $(m_j, I_j)$: $[(165.0470, \\, 0.7), \\, (150.0235, \\, 0.6), \\, (182.0730, \\, 0.05), \\, (140.0000, \\, 0.1)]$。\n\n全局参数（所有测试用例相同）：\n- 质量精度 $\\sigma = 0.01$ Da。\n- 强度指数 $\\alpha = 0.5$。\n- 已知丢失和基本先验：\n  - 水 $\\text{H}_2\\text{O}$：质量 $18.0106$ Da，基本先验 $p_{\\text{H}_2\\text{O}} = 0.3$。\n  - 氨 $\\text{NH}_3$：质量 $17.0265$ Da，基本先验 $p_{\\text{NH}_3} = 0.2$。\n  - 甲基 $\\text{CH}_3$：质量 $15.0235$ Da，基本先验 $p_{\\text{CH}_3} = 0.1$。\n  - 一氧化碳 $\\text{CO}$：质量 $27.9949$ Da，基本先验 $p_{\\text{CO}} = 0.05$。\n  - 二氧化碳 $\\text{CO}_2$：质量 $43.9898$ Da，基本先验 $p_{\\text{CO}_2} = 0.05$。\n- 已知丢失匹配的容差 $\\delta = 0.25$ Da。\n- 未知丢失先验参数：$p_u = 0.02$，$\\lambda = 0.02$ $\\text{Da}^{-1}$。\n- 丢失量惩罚系数 $\\gamma = 0.01$。\n- 先验加权系数 $\\beta = 1.0$。\n- 似然下限值 $\\epsilon = 10^{-12}$。\n\n您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表的结果（例如，$[r_1, r_2, r_3]$），其中每个 $r_i$ 是相应测试用例的总目标值 $J(T)$，四舍五入到六位小数。", "solution": "该问题要求设计并实现一个用于在串联质谱中对碎裂有向生成树进行评分的模块。这涉及构建一个概率性目标函数，并找到最大化该函数的有向生成树。解决方案从第一性原理出发，始于对谱图数据和化学知识的概率性解释，最终形成一个高效的优化算法。\n\n核心任务是在一个碎裂图 $G=(V, E)$ 中找到一个以前体节点 $r$ 为根的最合理的有向生成树 $T$。有向生成树是一个有向生成树，其中除根节点外的每个节点都有且仅有一条入边。这种结构代表了一个关于前体分子如何碎裂以产生观测到的小分子（碎片）的假设。\n\n首先，我们形式化图的结构。节点集 $V$ 包括表示为 $r$ 且质量为 $M_p$ 的前体离子，以及一组候选碎片离子 $\\{v_1, \\dots, v_n\\}$，其对应质量为 $\\{m_1, \\dots, m_n\\}$。当且仅当节点 $u$ 的质量 $m_u$ 大于节点 $v$ 的质量 $m_v$ 时，边集 $E$ 中存在一条有向边 $(u \\to v)$。这个约束条件 $m_u  m_v$ 确保了碎裂总是导致正的质量丢失，$d = m_u - m_v  0$。因此，图 $G$ 是一个有向无环图（DAG），其中节点按质量进行偏序。\n\n接下来，我们为一个有向生成树 $T$ 定义一个有原则的、概率性的目标函数 $J(T)$。整个有向生成树的分数定义为其构成边的分数之和。有向生成树中单条边 $(u \\to v)$ 的分数，记为 $w(u \\to v)$，由三项组成。对于一个边集为 $E_T$ 的有向生成树 $T$，其总目标为：\n$$\nJ(T) = \\sum_{(u \\to v) \\in E_T} w(u \\to v)\n$$\n其中边的权重由下式给出：\n$$\nw(u \\to v) = \\log \\ell(v) + \\beta \\log \\pi(m_u - m_v) - \\gamma (m_u - m_v)\n$$\n边权重中的每一项都有明确的物理和概率意义。使用对数将概率的乘积（一个联合概率模型）转换为对数概率的和，这在数值上更稳定，在分析上也更易于处理。\n\n第一项 $\\log \\ell(v)$ 是碎片节点 $v$ 的对数似然。它量化了基于观测到的MS/MS谱图 $S = \\{(m_j, I_j)\\}_{j=1}^N$ 对一个质量为 $m_v$ 的碎片存在的证据。似然 $\\ell(v)$ 被构造成一个混合模型：\n$$\n\\ell(v) = \\sum_{j=1}^{N} I_j'^\\alpha \\, \\mathcal{N}(m_j; m_v, \\sigma)\n$$\n在这里，$I_j'$ 表示第 $j$ 个峰的归一化强度，使得 $\\sum_{j=1}^{N} I_j' = 1$。指数 $\\alpha$ 是一个调节峰强度影响的加权因子。函数 $\\mathcal{N}(m_j; m_v, \\sigma)$ 是高斯概率密度函数，它模拟了在真实碎片质量为 $m_v$、标准差 $\\sigma$ 代表仪器质量精度的情况下，观测到质量为 $m_j$ 的峰的概率。该项有效地衡量了候选碎片 $v$ 的理论质量被观测到的谱峰解释得有多好。为防止对零取对数时出现数值问题，我们应用一个下限值 $\\epsilon$，将 $\\ell(v)$ 替换为 $\\max(\\ell(v), \\epsilon)$。\n\n第二项 $\\beta \\log \\pi(m_u - m_v)$ 融入了先验的化学知识。函数 $\\pi(d)$ 是质量为 $d = m_u - m_v$ 的中性丢失的先验概率。某些中性丢失（例如，小的、稳定的分子如水或一氧化碳）在化学上是优先的，并以高频率发生。该模型通过定义一组已知的常见丢失 $\\mathcal{L}$ 来捕捉这一点。如果计算出的丢失 $d$ 在给定的容差 $\\delta$ 内与某个已知丢失质量 $l \\in \\mathcal{L}$ 匹配（即 $|d-l| \\le \\delta$），其先验概率就被设为一个预定义的值 $p_l$。如果多个已知丢失匹配，则选择质量差异最小的那个。对于所有其他“未知”丢失，我们分配一个随丢失质量指数衰减的先验：$\\pi(d) = p_u \\, \\exp(-\\lambda d)$。这反映了丢失任意大的、非特异性碎片的可能性越来越小。系数 $\\beta$ 平衡了这一先验信息与数据驱动的似然项之间的贡献。\n\n第三项 $-\\gamma (m_u - m_v)$ 是一个与中性丢失质量成正比的惩罚项。它作为一个正则化项，由系数 $\\gamma \\geq 0$ 控制。在其他条件相同的情况下，该项引入了对具有较小步骤的碎裂路径的偏好，促进了更详细和简约的解释。\n\n最后一步是找到最大化 $J(T)$ 的有向生成树 $T$。因为图是一个DAG，并且边权重是这样定义的，问题被大大简化了。目标函数的结构允许进行贪心优化。总目标是树中所有边的权重之和。由于每个碎片节点 $v \\in V \\setminus \\{r\\}$ 都有且仅有一条入边，我们可以将目标重写为对所有碎片节点的求和，其中为每个节点选择其最佳父节点：\n$$\nJ(T) = \\sum_{v \\in V \\setminus \\{r\\}} \\max_{(u \\to v) \\in E} w(u \\to v)\n$$\n这等价于：\n$$\nJ(T) = \\sum_{v \\in V \\setminus \\{r\\}} \\left( \\log \\ell(v) + \\max_{(u \\to v) \\in E} \\left[ \\beta \\log \\pi(m_u - m_v) - \\gamma(m_u - m_v) \\right] \\right)\n$$\n这种分解表明，节点 $v$ 的最优父节点可以独立于为任何其他节点所做的选择来确定。因此，算法如下：\n1.  对于每个碎片节点 $v_i$，根据谱图数据计算其似然 $\\ell(v_i)$。\n2.  对于每个碎片节点 $v_i$，考虑所有可能的父节点 $u$（即所有质量 $m_u  m_{v_i}$ 的节点）。\n3.  对于每个潜在父节点 $u$，计算相应的边权重 $w(u \\to v_i)$。\n4.  确定为 $v_i$ 产生最大边权重的父节点 $u^*$。这个最大权重是节点 $v_i$ 对总分的贡献。\n5.  总目标 $J(T)$ 是所有碎片节点上这些最大权重之和。\n\n该过程保证在多项式时间内找到得分最高的有向生成树，具体时间复杂度为 $O(n^2)$，其中 $n$ 是节点数，因为 $O(n)$ 个碎片节点中的每一个都考虑了 $O(n)$ 个潜在的父节点。实现将精确遵循此逻辑。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the structure elucidation problem for all test cases.\n    \"\"\"\n    # Global parameters (identical across all test cases)\n    params = {\n        'sigma': 0.01,\n        'alpha': 0.5,\n        'known_losses': [\n            (18.0106, 0.3),   # H2O\n            (17.0265, 0.2),   # NH3\n            (15.0235, 0.1),   # CH3\n            (27.9949, 0.05),  # CO\n            (43.9898, 0.05),  # CO2\n        ],\n        'delta': 0.25,\n        'pu': 0.02,\n        'lambda_': 0.02,\n        'gamma': 0.01,\n        'beta': 1.0,\n        'epsilon': 1e-12,\n    }\n\n    # Test cases\n    test_cases = [\n        # Case A\n        (180.0630, [162.0524, 145.0259, 130.0024, 102.0075],\n         [(162.0520, 0.8), (145.0260, 0.6), (130.0020, 0.5), (102.0080, 0.3), (90.0000, 0.1)]),\n        # Case B\n        (150.0520, [132.0414],\n         [(132.0410, 0.9), (120.0000, 0.2), (100.0000, 0.1)]),\n        # Case C\n        (200.0840, [182.0734, 165.0469, 150.0234],\n         [(165.0470, 0.7), (150.0235, 0.6), (182.0730, 0.05), (140.0000, 0.1)]),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_max_objective(case, params)\n        results.append(round(result, 6))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef gaussian_pdf(x, mu, sigma):\n    \"\"\"\n    Calculates the Gaussian probability density function.\n    N(x; mu, sigma) = (1 / (sigma * sqrt(2*pi))) * exp(-(x - mu)^2 / (2*sigma^2))\n    \"\"\"\n    prefactor = 1.0 / (sigma * np.sqrt(2 * np.pi))\n    exponent = -0.5 * ((x - mu) / sigma)**2\n    return prefactor * np.exp(exponent)\n\ndef get_loss_prior(loss_mass, params):\n    \"\"\"Calculates the neutral loss prior pi(d).\"\"\"\n    min_mass_diff = np.inf\n    best_prior = None\n\n    for l_mass, l_prior in params['known_losses']:\n        diff = abs(loss_mass - l_mass)\n        if diff  min_mass_diff:\n            min_mass_diff = diff\n            best_prior = l_prior\n\n    if min_mass_diff = params['delta']:\n        return best_prior\n    else:\n        return params['pu'] * np.exp(-params['lambda_'] * loss_mass)\n\ndef calculate_likelihood(fragment_mass, peaks, params):\n    \"\"\"Calculates the fragment likelihood l(v).\"\"\"\n    total_intensity = sum(I for _, I in peaks)\n    if total_intensity == 0:\n        return params['epsilon']\n\n    likelihood = 0.0\n    for peak_mass, intensity in peaks:\n        norm_intensity = intensity / total_intensity\n        likelihood += (norm_intensity**params['alpha']) * gaussian_pdf(peak_mass, fragment_mass, params['sigma'])\n    \n    return max(likelihood, params['epsilon'])\n\ndef calculate_max_objective(case, params):\n    \"\"\"Calculates the total objective J(T) for a single test case.\"\"\"\n    precursor_mass, fragment_masses, peaks = case\n    \n    # Node masses include the precursor\n    all_node_masses = [precursor_mass] + fragment_masses\n    \n    # Pre-compute fragment likelihoods\n    fragment_likelihoods = {\n        fm: calculate_likelihood(fm, peaks, params) for fm in fragment_masses\n    }\n\n    total_objective = 0.0\n    \n    # For each fragment, find the best parent and add its edge weight to the total\n    for frag_mass in fragment_masses:\n        max_edge_weight = -np.inf\n        log_likelihood = np.log(fragment_likelihoods[frag_mass])\n\n        # Potential parents are the precursor and any heavier fragments\n        potential_parents = [m for m in all_node_masses if m > frag_mass]\n\n        for parent_mass in potential_parents:\n            loss_mass = parent_mass - frag_mass\n            \n            prior_prob = get_loss_prior(loss_mass, params)\n            \n            # Use a large negative number for log(0)\n            log_prior = np.log(prior_prob) if prior_prob > 0 else -np.inf\n            \n            # Compute edge weight\n            edge_weight = log_likelihood + params['beta'] * log_prior - params['gamma'] * loss_mass\n            \n            if edge_weight > max_edge_weight:\n                max_edge_weight = edge_weight\n        \n        # Add the max weight for this fragment to the total objective\n        total_objective += max_edge_weight\n\n    return total_objective\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3693961"}]}