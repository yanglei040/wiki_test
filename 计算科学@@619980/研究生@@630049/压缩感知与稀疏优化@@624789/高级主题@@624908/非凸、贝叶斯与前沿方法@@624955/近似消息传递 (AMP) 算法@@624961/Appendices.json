{"hands_on_practices": [{"introduction": "近似消息传递（AMP）算法的核心在于其精巧的结构，其中 Onsager 修正项起着至关重要的作用。该项旨在精确抵消迭代过程中产生的统计偏差，从而使高维随机系统在行为上可以被一个简单的一维标量状态演化（State Evolution）所预测。本练习 [@problem_id:3432158] 将引导你在线性去噪器的简化场景下，从第一性原理出发推导这个关键的 Onsager 系数，从而深入理解 AMP 算法为何能够“解耦”并揭示其有效性的根本来源。", "problem": "考虑标准压缩感知线性模型 $y = A x_{0} + w$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 的元素 $A_{ij} \\sim \\mathcal{N}(0, 1/m)$ 是独立同分布的，未知信号 $x_{0} \\in \\mathbb{R}^{n}$ 是固定的，噪声 $w \\in \\mathbb{R}^{m}$ 与 $A$ 无关。令 $\\delta = m/n$ 表示测量比。带有 Onsager 修正系数的近似消息传递 (AMP) 迭代由下式给出\n$$\nx^{t+1} = \\eta_{\\tau_{t}}\\!\\left(x^{t} + A^{\\top} z^{t}\\right), \\qquad z^{t} = y - A x^{t} + \\alpha_{t-1} z^{t-1},\n$$\n其中 $x^{0}$ 和 $z^{-1}$ 是指定的初始化值，$\\eta_{\\tau}(r)$ 是一个逐分量应用的可分离去噪函数。假设去噪器是线性的，定义为 $\\eta_{\\tau}(r) = \\frac{1}{1+\\tau}\\, r$，其中 $\\tau > 0$ 可能依赖于迭代索引。\n\n从高维高斯感知中 AMP 的基本原理出发——具体来说，即解耦原理以及有效预激活 $x^{t} + A^{\\top} z^{t}$ 在状态演化下表现为加性高斯白噪声信道的要求——推导与线性去噪器 $\\eta_{\\tau_{t}}(r)$ 相关的 Onsager 系数 $\\alpha_{t}$ 的显式解析表达式。您的推导应依赖于高斯矩阵的不变性性质和去噪器的散度（平均雅可比）作为核心基础。然后，解释此 $\\alpha_{t}$ 如何在稳定性和记忆性方面影响残差递归 $z^{t} = y - A x^{t} + \\alpha_{t-1} z^{t-1}$。\n\n请提供您的最终答案，作为 $\\alpha_{t}$ 关于 $\\delta$ 和 $\\tau_{t}$ 的闭式解析表达式。不需要进行数值计算，也不需要进行四舍五入。请将您的最终答案表示为无单位的解析表达式。", "solution": "该问题要求推导在特定线性去噪器下，近似消息传递 (AMP) 算法的 Onsager 修正系数 $\\alpha_{t}$。该推导必须基于 AMP 的核心原理，即依赖于大高斯矩阵性质的解耦原理。\n\n我们从问题陈述中定义的 AMP 迭代开始：\n$$x^{t+1} = \\eta_{\\tau_{t}}\\!\\left(x^{t} + A^{\\top} z^{t}\\right)$$\n$$z^{t} = y - A x^{t} + \\alpha_{t-1} z^{t-1}$$\n信号模型为 $y = A x_{0} + w$。将此代入 $z^t$ 的方程中得到：\n$$z^{t} = A x_{0} + w - A x^{t} + \\alpha_{t-1} z^{t-1} = A(x_{0} - x^{t}) + w + \\alpha_{t-1} z^{t-1}$$\nAMP 的基本原理是，在高维极限下（$m, n \\to \\infty$ 且 $m/n \\to \\delta$），算法的行为可以通过一个称为状态演化的更简单的标量递归来严格追踪。这种分析之所以可能，是因为每一步中去噪器的有效输入 $r^t = x^{t} + A^{\\top} z^{t}$ 的行为，就如同真实信号 $x_0$ 被加性高斯白噪声所破坏一样。这就是解耦原理。\n\n为了使这种解耦成立，迭代过程中出现的某些统计依赖性必须被主动抵消。有问题的依赖性源于 $z^t$ 更新式中的 $-A x^t$ 项。注意，$x^t$ 是先前迭代的函数，具体为 $x^t = \\eta_{\\tau_{t-1}}(x^{t-1} + A^\\top z^{t-1})$，因此它依赖于矩阵 $A$。随后在 $-A x^t$ 中乘以 $A$ 会产生一种相关性，如果不加以修正，将使去噪器输入的简单高斯噪声模型失效。\n\nOnsager 修正项 $\\alpha_{t-1} z^{t-1}$ 的引入正是为了抵消 $-A x^t$ 项所引入的统计偏差。其核心思想是令 $\\alpha_{t-1} z^{t-1}$ 等于引入偏差项的条件期望，从而创建一个在统计上表现良好的新的“中心化”残差。偏差项是在给定直至迭代 $t-1$ 的过程历史（我们记为 $\\mathcal{F}_{t-1}$）的情况下，$-A x^t$ 的条件期望。抵消要求是：\n$$\\alpha_{t-1} z^{t-1} = - \\mathbb{E}[ -A x^t \\mid \\mathcal{F}_{t-1} ] = \\mathbb{E}[ A x^t \\mid \\mathcal{F}_{t-1} ]$$\n其中 $x^t = \\eta_{\\tau_{t-1}}(x^{t-1} + A^\\top z^{t-1})$。在对随机矩阵 $A$ 取期望时，向量 $x^{t-1}$ 和 $z^{t-1}$ 被视为固定的。随机矩阵理论中的一个核心结果，即 Stein 引理（或高斯分部积分）的一个推论，指出对于一个具有独立同分布元素 $\\mathcal{N}(0, 1/m)$ 的矩阵 $A \\in \\mathbb{R}^{m \\times n}$，以及对于合适的可分离函数 $\\eta: \\mathbb{R}^n \\to \\mathbb{R}^n$ 和固定向量 $u \\in \\mathbb{R}^n, v \\in \\mathbb{R}^m$：\n$$\\mathbb{E}_A[ A \\, \\eta(u + A^\\top v) ] = \\frac{1}{m} \\mathbb{E}_A[ \\text{div}(\\eta(u + A^\\top v)) ] v$$\n其中 $\\text{div}(\\eta(r)) = \\sum_{j=1}^n \\frac{\\partial \\eta_j(r_j)}{\\partial r_j}$ 是 $\\eta$ 的散度。\n\n将此恒等式应用于我们的偏差表达式，我们识别出 $u = x^{t-1}$，$v = z^{t-1}$，以及 $\\eta = \\eta_{\\tau_{t-1}}$。因此，\n$$\\mathbb{E}[ A x^t \\mid \\mathcal{F}_{t-1} ] \\approx \\frac{1}{m} \\mathbb{E}\\left[ \\sum_{j=1}^n \\eta'_{\\tau_{t-1}}(r_j^{t-1}) \\right] z^{t-1}$$\n其中 $r^{t-1} = x^{t-1} + A^\\top z^{t-1}$ 且 $\\eta'_{\\tau}(r_j) = \\frac{d\\eta_{\\tau}(r_j)}{dr_j}$。右侧的期望是关于 $A$ 的随机性的，这使得 $r^{t-1}$ 成为一个随机向量。\n\n令两个用于偏差抵消的表达式相等，我们发现：\n$$\\alpha_{t-1} z^{t-1} = \\frac{1}{m} \\mathbb{E}\\left[ \\sum_{j=1}^n \\eta'_{\\tau_{t-1}}(r_j^{t-1}) \\right] z^{t-1}$$\n假设 $z^{t-1}$ 不是零向量，我们可以确定标量系数 $\\alpha_{t-1}$：\n$$\\alpha_{t-1} = \\frac{1}{m} \\mathbb{E}\\left[ \\sum_{j=1}^n \\eta'_{\\tau_{t-1}}(r_j^{t-1}) \\right]$$\n在大系统极限下，由于自平均性质，期望内的项收敛到一个确定性值。因此，我们可以用该值本身来近似期望：\n$$\\alpha_{t-1} \\approx \\frac{1}{m} \\sum_{j=1}^n \\eta'_{\\tau_{t-1}}(r_j^{t-1}) = \\frac{n}{m} \\left( \\frac{1}{n} \\sum_{j=1}^n \\eta'_{\\tau_{t-1}}(r_j^{t-1}) \\right)$$\n使用定义 $\\delta = m/n$ 并将平均导数记为 $\\langle \\eta'_{\\tau_{t-1}} \\rangle_n = \\frac{1}{n} \\sum_{j=1}^n \\eta'_{\\tau_{t-1}}(r_j^{t-1})$，我们得到：\n$$\\alpha_{t-1} = \\frac{1}{\\delta} \\langle \\eta'_{\\tau_{t-1}} \\rangle_n$$\n问题要求 $\\alpha_t$ 的表达式。通过移动时间索引，我们得到通用公式：\n$$\\alpha_{t} = \\frac{1}{\\delta} \\langle \\eta'_{\\tau_{t}} \\rangle_n$$\n现在，我们必须为所提供的特定线性去噪器 $\\eta_{\\tau}(r) = \\frac{1}{1+\\tau} r$ 评估此式。此函数关于其自变量的导数是一个常数：\n$$\\eta'_{\\tau_t}(r) = \\frac{d}{dr}\\left(\\frac{1}{1+\\tau_t} r\\right) = \\frac{1}{1+\\tau_t}$$\n由于对所有分量而言导数都是常数，其平均值就是该常数本身：\n$$\\langle \\eta'_{\\tau_{t}} \\rangle_n = \\frac{1}{n} \\sum_{j=1}^n \\frac{1}{1+\\tau_t} = \\frac{1}{n} \\cdot n \\cdot \\frac{1}{1+\\tau_t} = \\frac{1}{1+\\tau_t}$$\n将此结果代入 $\\alpha_t$ 的公式中，我们得到显式解析表达式：\n$$\\alpha_{t} = \\frac{1}{\\delta} \\left(\\frac{1}{1+\\tau_t}\\right) = \\frac{1}{\\delta(1+\\tau_t)}$$\n\n关于 $\\alpha_t$ 对残差递归的影响，其作用是双重的：\n\n1.  **记忆性与解耦**：项 $\\alpha_{t-1} z^{t-1}$ 是一个显式记忆项，将当前残差 $z^t$ 与前一个残差 $z^{t-1}$ 联系起来。递归式 $z^{t} = (y - A x^{t}) + \\alpha_{t-1} z^{t-1}$ 可以看作是一个作用于新息序列 $y - A x^t$ 的 IIR (无限脉冲响应) 滤波器。系数 $\\alpha_t$ 不是任意的；它经过精心计算，以抵消 $-A x^t$ 项所引入的隐式统计记忆。通过添加这个特定的“Onsager 反应项”，该算法有效地消除了迭代值与感知矩阵 $A$ 之间的有害相关性。这种抵消是确保解耦性质的关键，它使得高维算法可以通过简单的一维状态演化进行分析，这是现代 AMP 理论的基石。\n\n2.  **稳定性**：系数序列 $\\{\\alpha_t\\}$ 的幅值对 AMP 迭代的稳定性至关重要。如果 Onsager 系数选择不当，解耦原理就会失效，导致复杂相关性的累积。这可能导致算法的性能显著偏离状态演化的理论预测，并可能导致迭代值的发散。对于残差更新的线性 IIR 滤波器结构，稳定性通常要求系数幅值 $|\\alpha_t|$ 随时间推移小于 $1$。在我们的例子中，$\\alpha_t = \\frac{1}{\\delta(1+\\tau_t)}$。由于 $\\delta > 0$ 和 $\\tau_t > 0$，我们有 $\\alpha_t > 0$。条件 $\\alpha_t  1$ 意味着 $\\delta(1+\\tau_t) > 1$。事实上，这个不等式与使用此线性去噪器的 AMP 的状态演化方程的收敛条件直接相关。因此，正确推导出的 Onsager 系数与整个算法的稳定性和收敛性有着内在的联系。", "answer": "$$\\boxed{\\frac{1}{\\delta(1+\\tau_t)}}$$", "id": "3432158"}, {"introduction": "在稀疏信号恢复的实际应用中，软阈值（soft-thresholding）去噪器因其与 $L_1$ 范数正则化的深刻联系而被广泛使用。然而，该函数在阈值点是不可导的，这为分析带来了挑战。本练习 [@problem_id:3432141] 旨在教会你如何处理这类在实际中非常常见的非光滑函数，通过运用高斯分布的性质和 Stein 引理，推导出适用于软阈值去噪器的 Onsager 修正系数。此过程不仅展示了如何将理论工具应用于实际模型，还揭示了算法参数如何根据信号的先验统计特性（如稀疏度）进行自适应调整。", "problem": "考虑压缩感知的标准线性模型，其测量值为 $y = A x_{0} + w$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 的元素 $A_{ij} \\sim \\mathcal{N}(0, 1/m)$ 是独立同分布的，信号 $x_{0} \\in \\mathbb{R}^{n}$ 是随机的，其元素是独立同分布的，服从 $X$ 的分布，噪声 $w \\in \\mathbb{R}^{m}$ 与 $A$ 和 $x_{0}$ 相互独立。令测量率为 $\\delta = m/n$。在近似消息传递 (AMP) 算法中，其标量状态演化递归涉及一个等效的标量去噪问题，其观测值为 $X + \\sqrt{\\tau_{t}} Z$，其中 $Z \\sim \\mathcal{N}(0,1)$ 与 $X$ 独立，$\\tau_{t} > 0$ 是第 $t$ 次迭代时的状态变量。去噪器是软阈值函数，其阈值为 $\\theta > 0$，定义为 $\\eta(u; \\theta) = \\operatorname{sign}(u) \\max\\{|u| - \\theta, 0\\}$。第 $t$ 次迭代时的 Onsager 校正系数在分布意义上定义为 $\\alpha_{t} = \\frac{1}{\\delta} \\mathbb{E}[\\eta'(X + \\sqrt{\\tau_{t}} Z; \\theta)]$，其中 $\\eta'$ 应在与高斯扰动的 Stein 引理相容的适当意义上理解。\n\n仅使用关于高斯分布的基本事实和 Stein 引理（对于独立于随机变量 $U$ 的 $Z \\sim \\mathcal{N}(0,1)$，以及一个至多为多项式增长的弱可微函数 $f$，有 $\\mathbb{E}[Z f(U + \\sigma Z)] = \\sigma \\mathbb{E}[f'(U + \\sigma Z)]$)，按以下步骤进行：\n\n1. 给出软阈值函数弱导数 $\\eta'(u; \\theta)$ 的一个精确的、几乎处处成立的公式，该公式以指示函数的形式表示，并排除了可微性失效的阈值点。解释为什么这些例外点不影响期望 $\\mathbb{E}[\\eta'(X + \\sqrt{\\tau_{t}} Z; \\theta)]$ 的值。\n\n2. 将 $X$ 的先验分布具体化为伯努利-高斯先验：$X = 0$ 的概率为 $1 - \\rho$，$X \\sim \\mathcal{N}(0, \\sigma_{x}^{2})$ 的概率为 $\\rho$，其中 $\\rho \\in (0,1]$ 且 $\\sigma_{x}^{2} > 0$。利用第 1 部分的结果以及高斯尾部概率，推导出一个关于\n$$\n\\alpha_{t} = \\frac{1}{\\delta} \\mathbb{E}\\big[\\eta'(X + \\sqrt{\\tau_{t}} Z; \\theta)\\big]\n$$\n的闭式解析表达式，该表达式应以 $\\delta$、$\\rho$、$\\theta$、$\\sigma_{x}^{2}$、$\\tau_{t}$ 和标准高斯上尾函数 $Q(x) = \\int_{x}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp(-t^{2}/2) \\, \\mathrm{d}t$ 表示。\n\n请以 $\\delta$、$\\rho$、$\\theta$、$\\sigma_{x}^{2}$、$\\tau_{t}$ 和 $Q(\\cdot)$ 的单个闭式解析表达式形式给出最终答案。无需进行数值计算。", "solution": "该问题要求一个关于近似消息传递 (AMP) 算法状态演化中 Onsager 校正系数的两部分解。我们首先验证问题陈述，然后进行求解。该问题是适定的，在科学上根植于压缩感知和高维统计理论，并为获得唯一解提供了所有必要信息。\n\n第 1 部分：软阈值函数的弱导数。\n\n阈值为 $\\theta > 0$ 的软阈值函数 $\\eta(u; \\theta)$ 定义为 $\\eta(u; \\theta) = \\operatorname{sign}(u) \\max\\{|u| - \\theta, 0\\}$。我们可以将此函数写成分段形式：\n$$\n\\eta(u; \\theta) = \\begin{cases}\nu - \\theta  \\text{若 } u > \\theta \\\\\n0  \\text{若 } -\\theta \\le u \\le \\theta \\\\\nu + \\theta  \\text{若 } u  -\\theta\n\\end{cases}\n$$\n$\\eta(u; \\theta)$ 关于 $u$ 的经典导数可以在其存在的所有点上计算。该函数在除了点 $u = \\theta$ 和 $u = -\\theta$ 之外的所有地方都是可微的。其导数为：\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}u} \\eta(u; \\theta) = \\begin{cases}\n1  \\text{若 } u > \\theta \\\\\n0  \\text{若 } -\\theta  u  \\theta \\\\\n1  \\text{若 } u  -\\theta\n\\end{cases}\n$$\n这可以用指示函数更紧凑地表示。如果 $|u| > \\theta$，导数存在且等于 $1$；如果 $|u|  \\theta$，导数存在且等于 $0$。这两个条件覆盖了 $\\mathbb{R}$ 中除集合 $\\{-\\theta, \\theta\\}$ 之外的所有点。因此，几乎处处 (a.e.) 的导数由下式给出：\n$$\n\\eta'(u; \\theta) = \\mathbf{1}_{|u| > \\theta}(u)\n$$\n其中 $\\mathbf{1}_{S}(u)$ 是指示函数，如果 $u \\in S$ 则为 $1$，否则为 $0$。在这个背景下，这个几乎处处成立的公式是 Stein 引理及相关计算所需的弱导数的正确表达式。\n\n我们需要计算期望 $\\mathbb{E}[\\eta'(X + \\sqrt{\\tau_{t}} Z; \\theta)]$。令 $U = X + \\sqrt{\\tau_{t}} Z$。该期望是关于 $U$ 的概率测度的积分：\n$$\n\\mathbb{E}[\\eta'(U; \\theta)] = \\int_{-\\infty}^{\\infty} \\eta'(u; \\theta) \\, f_U(u) \\, \\mathrm{d}u\n$$\n其中 $f_U(u)$ 是 $U$ 的概率密度函数 (PDF)。在一个测度为零的集合上改变被积函数的值不会影响积分的值。在这里，被积函数 $\\eta'(u; \\theta)$ 在除集合 $\\{-\\theta, \\theta\\}$ 之外的所有地方都有定义。为了使积分良定义且不受这些点的影响，我们必须证明这个集合的概率测度为零，即 $\\mathbb{P}(U \\in \\{-\\theta, \\theta\\}) = 0$。\n\n随机变量 $U$ 是 $X$ 和 $\\sqrt{\\tau_{t}} Z$ 的和。$Z \\sim \\mathcal{N}(0,1)$ 是一个连续随机变量。$X$ 的分布是一个混合分布：$X=0$ 的概率为 $1-\\rho$，$X \\sim \\mathcal{N}(0, \\sigma_{x}^{2})$ 的概率为 $\\rho$。\n我们通过对 $X$ 取条件来分析 $U$ 的分布：\n1.  如果 $X=0$，那么 $U = \\sqrt{\\tau_t} Z$。因为 $Z$ 是高斯变量，$U$ 也是高斯变量，具体为 $U \\sim \\mathcal{N}(0, \\tau_{t})$。这是一个连续分布。\n2.  如果 $X \\sim \\mathcal{N}(0, \\sigma_x^2)$，那么 $U = X + \\sqrt{\\tau_t} Z$ 是两个独立高斯随机变量的和。其和也是高斯变量，均值为 $0+0=0$，方差为 $\\sigma_x^2 + \\tau_t$。因此，$U \\sim \\mathcal{N}(0, \\sigma_x^2 + \\tau_t)$。这也是一个连续分布。\n\n$U$ 的整体分布是两个连续分布的混合。其 PDF 为 $f_U(u) = (1-\\rho)f_{\\mathcal{N}(0, \\tau_t)}(u) + \\rho f_{\\mathcal{N}(0, \\sigma_x^2 + \\tau_t)}(u)$，这是一个有效的 PDF。任何具有 PDF 的随机变量都是连续的。对于任何连续随机变量，它取任何单个特定值的概率为零。因此，$\\mathbb{P}(U = \\theta) = 0$ 且 $\\mathbb{P}(U = -\\theta) = 0$。由于例外点集合 $\\{-\\theta, \\theta\\}$ 的概率测度为零，我们可以在期望计算中明确地使用导数的几乎处处公式。\n\n第 2 部分：Onsager 系数 $\\alpha_t$ 的推导。\n\nOnsager 系数由 $\\alpha_{t} = \\frac{1}{\\delta} \\mathbb{E}[\\eta'(X + \\sqrt{\\tau_{t}} Z; \\theta)]$ 给出。使用第 1 部分的结果，我们有：\n$$\n\\alpha_{t} = \\frac{1}{\\delta} \\mathbb{E}\\left[\\mathbf{1}_{|X + \\sqrt{\\tau_{t}} Z| > \\theta}\\right]\n$$\n指示函数的期望是其所指示事件的概率。令 $U = X + \\sqrt{\\tau_{t}} Z$。\n$$\n\\alpha_{t} = \\frac{1}{\\delta} \\mathbb{P}\\left(|U| > \\theta\\right)\n$$\n我们使用全概率定律计算这个概率，对 $X$ 的先验分布的两种情况进行条件化：\n$$\n\\mathbb{P}(|U| > \\theta) = \\mathbb{P}(|U| > \\theta \\,|\\, X=0)(1-\\rho) + \\mathbb{P}(|U| > \\theta \\,|\\, X \\sim \\mathcal{N}(0, \\sigma_{x}^{2}))\\rho\n$$\n情况 1：$X=0$。\n在这种情况下，$U = \\sqrt{\\tau_{t}} Z \\sim \\mathcal{N}(0, \\tau_{t})$。概率为：\n$$\n\\mathbb{P}(|\\sqrt{\\tau_{t}} Z| > \\theta) = \\mathbb{P}(\\sqrt{\\tau_{t}} Z > \\theta) + \\mathbb{P}(\\sqrt{\\tau_{t}} Z  -\\theta)\n$$\n由于零均值高斯分布的对称性，这两项是相等的。\n$$\n\\mathbb{P}(|\\sqrt{\\tau_{t}} Z| > \\theta) = 2 \\mathbb{P}(\\sqrt{\\tau_{t}} Z > \\theta) = 2 \\mathbb{P}\\left(Z > \\frac{\\theta}{\\sqrt{\\tau_{t}}}\\right)\n$$\n根据标准高斯上尾函数 $Q(x) = \\mathbb{P}(Z > x)$（其中 $Z \\sim \\mathcal{N}(0,1)$）的定义，这个概率是 $2 Q\\left(\\frac{\\theta}{\\sqrt{\\tau_{t}}}\\right)$。\n\n情况 2：$X \\sim \\mathcal{N}(0, \\sigma_{x}^{2})$。\n在这种情况下，$U = X + \\sqrt{\\tau_t} Z$。如第 1 部分所述，这两个独立的、零均值的高斯变量之和是一个零均值的高斯变量，其方差等于它们方差的和。\n$$\nU \\sim \\mathcal{N}(0, \\sigma_{x}^{2} + \\tau_{t})\n$$\n概率为：\n$$\n\\mathbb{P}(|U| > \\theta \\,|\\, X \\sim \\mathcal{N}(0, \\sigma_{x}^{2})) = \\mathbb{P}(|U| > \\theta)\n$$\n根据对称性，这等于 $2 \\mathbb{P}(U > \\theta)$。为了使用 $Q$-函数，我们对 $U$ 进行标准化：\n$$\n2 \\mathbb{P}(U > \\theta) = 2 \\mathbb{P}\\left(\\frac{U}{\\sqrt{\\sigma_{x}^{2} + \\tau_{t}}} > \\frac{\\theta}{\\sqrt{\\sigma_{x}^{2} + \\tau_{t}}}\\right)\n$$\n标准化变量 $\\frac{U}{\\sqrt{\\sigma_{x}^{2} + \\tau_{t}}}$ 是一个标准正态变量 $\\mathcal{N}(0,1)$。因此，概率为 $2 Q\\left(\\frac{\\theta}{\\sqrt{\\sigma_{x}^{2} + \\tau_{t}}}\\right)$。\n\n合并结果：\n我们将两种情况的概率代入全概率定律表达式中：\n$$\n\\mathbb{P}(|U| > \\theta) = (1-\\rho) \\left[ 2 Q\\left(\\frac{\\theta}{\\sqrt{\\tau_{t}}}\\right) \\right] + \\rho \\left[ 2 Q\\left(\\frac{\\theta}{\\sqrt{\\sigma_{x}^{2} + \\tau_{t}}}\\right) \\right]\n$$\n最后，我们将其代入 $\\alpha_{t}$ 的公式中：\n$$\n\\alpha_{t} = \\frac{1}{\\delta} \\left\\{ 2(1-\\rho) Q\\left(\\frac{\\theta}{\\sqrt{\\tau_{t}}}\\right) + 2\\rho Q\\left(\\frac{\\theta}{\\sqrt{\\sigma_{x}^{2} + \\tau_{t}}}\\right) \\right\\}\n$$\n提出常数 $2$ 后，得到最终的闭式表达式：\n$$\n\\alpha_{t} = \\frac{2}{\\delta} \\left[ (1-\\rho) Q\\left(\\frac{\\theta}{\\sqrt{\\tau_{t}}}\\right) + \\rho Q\\left(\\frac{\\theta}{\\sqrt{\\sigma_{x}^{2} + \\tau_{t}}}\\right) \\right]\n$$\n该表达式按要求以问题参数 $\\delta$、$\\rho$、$\\theta$、$\\sigma_{x}^{2}$、$\\tau_{t}$ 和高斯 $Q$-函数的形式给出了 Onsager 系数。", "answer": "$$\\boxed{\\frac{2}{\\delta} \\left[ (1-\\rho) Q\\left(\\frac{\\theta}{\\sqrt{\\tau_{t}}}\\right) + \\rho Q\\left(\\frac{\\theta}{\\sqrt{\\sigma_{x}^{2} + \\tau_{t}}}\\right) \\right]}$$", "id": "3432141"}, {"introduction": "标准的 AMP 算法在面对病态（ill-conditioned）的传感矩阵时常常会发散，这限制了其在许多实际场景中的应用。为了解决这一稳定性问题，引入阻尼（damping）是一种简单而有效的策略，它通过将当前迭代的更新与前一步的估计进行加权平均来平滑迭代轨迹。本练习 [@problem_id:3432089] 将此调优过程构建为一个精确的优化问题，要求你找到最优的阻尼系数，以最小化线性化误差动态的最差收敛速率（即谱半径）。通过解决这个问题，你将掌握一种增强 AMP 算法鲁棒性的重要实用技巧，并理解其背后的稳定性原理。", "problem": "考虑压缩感知中的线性逆估计问题，其测量值为 $y = A x_0 + w$，其中 $x_0 \\in \\mathbb{R}^n$ 是一个稀疏信号，$A \\in \\mathbb{R}^{m \\times n}$ 是一个病态传感矩阵，其右奇异向量构成一个标准正交基，并具有两个不同的奇异值 $s_1$ 和 $s_2$，$w \\in \\mathbb{R}^m$ 是加性高斯白噪声。带阻尼的近似消息传递（AMP）算法通过 $x^{t+1} = (1 - \\alpha_t) x^t + \\alpha_t \\eta(x^t + A^{\\top} r^t)$ 更新估计值，其中 $\\eta$ 是一个可微的去噪器，$r^t = y - A x^t + b_t r^{t-1}$ 是残差，其中的 Onsager 系数 $b_t$ 等于去噪器的平均散度乘以测量率的倒数（测量率为 $\\delta = m/n$），$\\alpha_t \\in (0,1)$ 是阻尼参数。令不动点 $(x^{\\star}, r^{\\star})$ 满足状态演化（SE）一致性条件，并假设在不动点处的平均去噪器导数为 $\\gamma = \\mathbb{E}[\\eta'(u^{\\star})]$。\n\n在不动点 $x^{\\star}$ 附近，将由SE引起的误差动力学在 $A$ 的右奇异向量基中进行线性化。对于与奇异值 $s_1$ 和 $s_2$ 相关的两个病态模式，将线性化映射的无阻尼雅可比矩阵建模为 $J_0 = I - \\kappa \\Sigma$，其中 $\\Sigma = \\mathrm{diag}(s_1^2, s_2^2)$ 且 $\\kappa = \\gamma / \\delta$。如上所述，将阻尼 $\\alpha \\in (0,1)$ 应用于迭代，线性化的带阻尼误差映射的雅可比矩阵为 $J(\\alpha) = (1 - \\alpha) I + \\alpha J_0$，其谱半径为 $\\rho(J(\\alpha)) = \\max\\{ |(1 - \\alpha) + \\alpha \\lambda_1|, |(1 - \\alpha) + \\alpha \\lambda_2| \\}$，其中 $\\lambda_i = 1 - \\kappa s_i^2$ 是无阻尼特征值。\n\n给定一个病态传感矩阵，其两个主要奇异值为 $s_1 = 1$ 和 $s_2 = 3$，测量率 $\\delta = 1$，不动点处的平均去噪器导数为 $\\gamma = \\frac{1}{2}$，选择阻尼参数 $\\alpha \\in (0,1)$ 以最小化不动点附近的线性化SE映射的谱半径 $\\rho(J(\\alpha))$。将最终答案表示为一个未经四舍五入的精确实数。", "solution": "该问题要求找到最优的阻尼参数 $\\alpha \\in (0,1)$，以最小化近似消息传递（AMP）算法的线性化状态演化（SE）映射的谱半径 $\\rho(J(\\alpha))$。谱半径决定了算法在不动点附近的局部收敛速度，较小的谱半径意味着更快的收敛速度。\n\n谱半径由以下表达式给出：\n$$ \\rho(J(\\alpha)) = \\max\\{ |(1 - \\alpha) + \\alpha \\lambda_1|, |(1 - \\alpha) + \\alpha \\lambda_2| \\} $$\n其中 $\\lambda_1$ 和 $\\lambda_2$ 是无阻尼雅可比映射 $J_0$ 的特征值。这些特征值由传感矩阵 $A$ 的奇异值和一个参数 $\\kappa$ 决定。\n\n参数 $\\kappa$ 定义为不动点处的平均去噪器导数 $\\gamma$ 与测量率 $\\delta$ 的比值。问题给出了以下数值：\n-   平均去噪器导数：$\\gamma = \\frac{1}{2}$\n-   测量率：$\\delta = 1$\n\n使用这些值，我们计算 $\\kappa$：\n$$ \\kappa = \\frac{\\gamma}{\\delta} = \\frac{1/2}{1} = \\frac{1}{2} $$\n\n特征值 $\\lambda_i$ 由公式 $\\lambda_i = 1 - \\kappa s_i^2$ 给出，其中 $s_i$ 是矩阵 $A$ 的奇异值。问题指定了两个奇异值：\n-   $s_1 = 1$\n-   $s_2 = 3$\n\n我们现在可以计算特征值 $\\lambda_1$ 和 $\\lambda_2$：\n$$ \\lambda_1 = 1 - \\kappa s_1^2 = 1 - \\frac{1}{2} (1)^2 = 1 - \\frac{1}{2} = \\frac{1}{2} $$\n$$ \\lambda_2 = 1 - \\kappa s_2^2 = 1 - \\frac{1}{2} (3)^2 = 1 - \\frac{9}{2} = -\\frac{7}{2} $$\n\n将这些特征值代入谱半径的表达式中，我们得到需要最小化的关于 $\\alpha$ 的函数：\n$$ \\rho(\\alpha) = \\max\\left\\{ \\left|(1 - \\alpha) + \\alpha \\left(\\frac{1}{2}\\right)\\right|, \\left|(1 - \\alpha) + \\alpha \\left(-\\frac{7}{2}\\right)\\right| \\right\\} $$\n简化绝对值内的项：\n$$ \\rho(\\alpha) = \\max\\left\\{ \\left|1 - \\frac{1}{2}\\alpha\\right|, \\left|1 - \\frac{9}{2}\\alpha\\right| \\right\\} $$\n我们需要找到使该函数最小化的 $\\alpha \\in (0,1)$ 的值。令 $g_1(\\alpha) = 1 - \\frac{1}{2}\\alpha$ 和 $g_2(\\alpha) = 1 - \\frac{9}{2}\\alpha$。目标是最小化 $\\max(|g_1(\\alpha)|, |g_2(\\alpha)|)$。\n\n形如 $\\max(|f_1(x)|, |f_2(x)|)$ 的函数的最小值通常在两个量值相等的地方取到，即 $|f_1(x)| = |f_2(x)|$。这是因为如果一个量值大于另一个，我们通常可以调整 $x$ 来减小较大的量值（从而减小最大值），直到两个量值相等。当一个函数是增函数而另一个是减函数时，这个结论成立。\n\n让我们分析在区间 $\\alpha \\in (0,1)$ 上的函数。\n函数 $|g_1(\\alpha)| = |1 - \\frac{1}{2}\\alpha|$ 在 $\\alpha \\in (0,1)$ 时就是 $1 - \\frac{1}{2}\\alpha$，因为 $1 - \\frac{1}{2}\\alpha > 0$。这是一个线性递减函数。\n函数 $|g_2(\\alpha)| = |1 - \\frac{9}{2}\\alpha|$ 呈V形。当 $\\alpha = \\frac{2}{9}$ 时，其参数 $1 - \\frac{9}{2}\\alpha$ 为零。\n- 对于 $\\alpha \\in (0, \\frac{2}{9})$， $|g_2(\\alpha)| = 1 - \\frac{9}{2}\\alpha$，这是一个递减函数。\n- 对于 $\\alpha \\in (\\frac{2}{9}, 1)$， $|g_2(\\alpha)| = -(1 - \\frac{9}{2}\\alpha) = \\frac{9}{2}\\alpha - 1$，这是一个递增函数。\n\n总函数 $\\rho(\\alpha)$ 是 $|g_1(\\alpha)|$ 和 $|g_2(\\alpha)|$ 的上包络线。这个上包络线的最小值将出现在两个函数相交的点，前提是这个交点位于两个函数各自的最小值点之间。$|g_1(\\alpha)|$ 的最小值在 $\\alpha=2$ 处，$|g_2(\\alpha)|$ 的最小值在 $\\alpha=2/9$ 处。我们寻求在 $\\alpha \\in (0,1)$ 内的最小值。最大值的最小值必须位于 $\\alpha=2/9$ 的右侧，在此处 $|g_1(\\alpha)|$ 是递减的，而 $|g_2(\\alpha)|$ 是递增的。因此，它们最大值的最小值就在它们的交点处。\n\n我们令两个量值相等：\n$$ |1 - \\frac{1}{2}\\alpha| = |1 - \\frac{9}{2}\\alpha| $$\n这会产生两种可能性：\n1.  $1 - \\frac{1}{2}\\alpha = 1 - \\frac{9}{2}\\alpha$。这意味着 $\\frac{8}{2}\\alpha = 0$，所以 $\\alpha=0$。这在定义域的边界上，不能提供最优的平衡。它对应于不进行更新。\n2.  $1 - \\frac{1}{2}\\alpha = -(1 - \\frac{9}{2}\\alpha)$。这对应于递减函数 $|g_1(\\alpha)|$ 和 $|g_2(\\alpha)|$ 的递增部分的交点。\n$$ 1 - \\frac{1}{2}\\alpha = -1 + \\frac{9}{2}\\alpha $$\n求解 $\\alpha$：\n$$ 2 = \\frac{9}{2}\\alpha + \\frac{1}{2}\\alpha $$\n$$ 2 = \\frac{10}{2}\\alpha $$\n$$ 2 = 5\\alpha $$\n$$ \\alpha = \\frac{2}{5} $$\n值 $\\alpha = \\frac{2}{5}$ 位于指定的区间 $(0,1)$ 内。在这一点，函数 $\\rho(\\alpha)$ 从由 $|g_1(\\alpha)|$（递减）决定过渡到由 $|g_2(\\alpha)|$（递增）决定。因此，该点对应于 $\\rho(\\alpha)$ 在 $\\alpha \\in (0,1)$ 上的最小值。\n\n最优的阻尼参数是 $\\frac{2}{5}$。", "answer": "$$\\boxed{\\frac{2}{5}}$$", "id": "3432089"}]}