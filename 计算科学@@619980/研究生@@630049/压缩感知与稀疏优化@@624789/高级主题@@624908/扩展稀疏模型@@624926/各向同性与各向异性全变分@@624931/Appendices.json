{"hands_on_practices": [{"introduction": "要真正掌握各向同性与各向异性总变差之间的区别，没有比直接计算更好的方法了。第一个练习将引导您为一个小的图像块计算两种TV范数，让您能够基于向量范数的基本性质，在像素级别上精确定位它们数值差异的来源。[@problem_id:3491268]", "problem": "考虑一个单位间距的笛卡尔网格上的离散图像模型。设像素点 $(i,j)$ 处的离散梯度由带有齐次诺伊曼边界条件的前向差分算子定义（即，任何会访问越界像素的前向差分都设为零）。具体来说，$(i,j)$ 处的离散梯度是一个二维向量，由 $(i,j)$ 处的前向水平差分和垂直差分组成。一个离散图像的各向异性全变分 (TV) 是每个像素点处离散梯度向量的 $\\ell_{1}$ 范数在所有像素上的总和。各向同性全变分是每个像素点处离散梯度向量的 $\\ell_{2}$ 范数在所有像素上的总和。\n\n给定一个 $3\\times 3$ 的图像块，其像素值为\n$$\nU \\;=\\;\n\\begin{pmatrix}\n1  2  2 \\\\\n1  3  5 \\\\\n2  3  6\n\\end{pmatrix}.\n$$\n仅使用上述基本定义和给定的边界模型，完成以下任务：\n- 明确计算 $U$ 的各向异性全变分和各向同性全变分。\n- 从向量范数的第一性原理出发，简明解释为什么对于这个图像块，这两个值在数值上不同，并从像素层面找出差异的结构性来源。\n\n令 $D$ 表示各向异性全变分与各向同性全变分之间的精确差值，\n$$\nD \\;=\\; \\mathrm{TV}_{\\mathrm{anisotropic}}(U) \\;-\\; \\mathrm{TV}_{\\mathrm{isotropic}}(U).\n$$\n以单一闭式解析表达式的形式报告 $D$。不要对答案进行四舍五入。", "solution": "设离散图像由矩阵 $U$ 表示，其中 $U_{i,j}$ 是第 $i$ 行、第 $j$ 列的像素值。该网格是一个 $3 \\times 3$ 的笛卡尔网格，因此索引 $(i,j)$ 的范围从 $(1,1)$ 到 $(3,3)$。给定的图像是：\n$$\nU =\n\\begin{pmatrix}\n1  2  2 \\\\\n1  3  5 \\\\\n2  3  6\n\\end{pmatrix}\n$$\n像素点 $(i,j)$ 处的离散梯度是一个向量 $\\nabla U_{i,j} = \\begin{pmatrix} (\\nabla_x U)_{i,j} \\\\ (\\nabla_y U)_{i,j} \\end{pmatrix}$。其分量由前向差分定义：\n$$\n(\\nabla_x U)_{i,j} = U_{i,j+1} - U_{i,j}\n$$\n$$\n(\\nabla_y U)_{i,j} = U_{i+1,j} - U_{i,j}\n$$\n齐次诺伊曼边界条件意味着任何需要越界像素的差分都设为零。对于一个 $3 \\times 3$ 的图像，这意味着对于 $i \\in \\{1,2,3\\}$，有 $(\\nabla_x U)_{i,3} = 0$；对于 $j \\in \\{1,2,3\\}$，有 $(\\nabla_y U)_{3,j} = 0$。\n\n首先，我们计算这 $9$ 个像素中每一个的离散梯度向量：\n- 在 $(1,1)$ 处: $\\nabla U_{1,1} = \\begin{pmatrix} U_{1,2} - U_{1,1} \\\\ U_{2,1} - U_{1,1} \\end{pmatrix} = \\begin{pmatrix} 2 - 1 \\\\ 1 - 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$\n- 在 $(1,2)$ 处: $\\nabla U_{1,2} = \\begin{pmatrix} U_{1,3} - U_{1,2} \\\\ U_{2,2} - U_{1,2} \\end{pmatrix} = \\begin{pmatrix} 2 - 2 \\\\ 3 - 2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$\n- 在 $(1,3)$ 处: $\\nabla U_{1,3} = \\begin{pmatrix} 0 \\\\ U_{2,3} - U_{1,3} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 5 - 2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 3 \\end{pmatrix}$\n- 在 $(2,1)$ 处: $\\nabla U_{2,1} = \\begin{pmatrix} U_{2,2} - U_{2,1} \\\\ U_{3,1} - U_{2,1} \\end{pmatrix} = \\begin{pmatrix} 3 - 1 \\\\ 2 - 1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$\n- 在 $(2,2)$ 处: $\\nabla U_{2,2} = \\begin{pmatrix} U_{2,3} - U_{2,2} \\\\ U_{3,2} - U_{2,2} \\end{pmatrix} = \\begin{pmatrix} 5 - 3 \\\\ 3 - 3 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}$\n- 在 $(2,3)$ 处: $\\nabla U_{2,3} = \\begin{pmatrix} 0 \\\\ U_{3,3} - U_{2,3} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 6 - 5 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$\n- 在 $(3,1)$ 处: $\\nabla U_{3,1} = \\begin{pmatrix} U_{3,2} - U_{3,1} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 3 - 2 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$\n- 在 $(3,2)$ 处: $\\nabla U_{3,2} = \\begin{pmatrix} U_{3,3} - U_{3,2} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 6 - 3 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix}$\n- 在 $(3,3)$ 处: $\\nabla U_{3,3} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$\n\n接下来，我们计算各向异性全变分 $\\mathrm{TV}_{\\mathrm{anisotropic}}(U)$，它是这些梯度向量的 $\\ell_1$ 范数的总和。对于一个向量 $v = \\begin{pmatrix} v_x \\\\ v_y \\end{pmatrix}$，其 $\\ell_1$ 范数为 $\\|v\\|_1 = |v_x| + |v_y|$。\n$$\n\\mathrm{TV}_{\\mathrm{anisotropic}}(U) = \\sum_{i=1}^{3} \\sum_{j=1}^{3} \\|\\nabla U_{i,j}\\|_1\n$$\n$$\n\\mathrm{TV}_{\\mathrm{anisotropic}}(U) = (|1|+|0|) + (|0|+|1|) + (|0|+|3|) + (|2|+|1|) + (|2|+|0|) + (|0|+|1|) + (|1|+|0|) + (|3|+|0|) + (|0|+|0|)\n$$\n$$\n\\mathrm{TV}_{\\mathrm{anisotropic}}(U) = 1 + 1 + 3 + 3 + 2 + 1 + 1 + 3 + 0 = 15\n$$\n\n然后，我们计算各向同性全变分 $\\mathrm{TV}_{\\mathrm{isotropic}}(U)$，它是 $\\ell_2$ 范数的总和。对于一个向量 $v = \\begin{pmatrix} v_x \\\\ v_y \\end{pmatrix}$，其 $\\ell_2$ 范数为 $\\|v\\|_2 = \\sqrt{v_x^2 + v_y^2}$。\n$$\n\\mathrm{TV}_{\\mathrm{isotropic}}(U) = \\sum_{i=1}^{3} \\sum_{j=1}^{3} \\|\\nabla U_{i,j}\\|_2\n$$\n$$\n\\mathrm{TV}_{\\mathrm{isotropic}}(U) = \\sqrt{1^2+0^2} + \\sqrt{0^2+1^2} + \\sqrt{0^2+3^2} + \\sqrt{2^2+1^2} + \\sqrt{2^2+0^2} + \\sqrt{0^2+1^2} + \\sqrt{1^2+0^2} + \\sqrt{3^2+0^2} + \\sqrt{0^2+0^2}\n$$\n$$\n\\mathrm{TV}_{\\mathrm{isotropic}}(U) = 1 + 1 + 3 + \\sqrt{5} + 2 + 1 + 1 + 3 + 0 = 12 + \\sqrt{5}\n$$\n\n这两个值之所以不同，是由于 $\\ell_1$ 和 $\\ell_2$ 范数的基本性质。对于 $\\mathbb{R}^n$ 中的任何向量 $v$，不等式 $\\|v\\|_1 \\ge \\|v\\|_2$ 成立。在我们的例子中，对于一个二维梯度向量 $v = \\begin{pmatrix} v_x \\\\ v_y \\end{pmatrix}$，我们有 $\\|v\\|_1 = |v_x|+|v_y|$ 和 $\\|v\\|_2 = \\sqrt{v_x^2+v_y^2}$。等式 $|v_x|+|v_y| = \\sqrt{v_x^2+v_y^2}$ 成立的充分必要条件是至少有一个分量（$v_x$ 或 $v_y$）为零。这对应于一个纯水平或纯垂直的梯度。\n\n$\\mathrm{TV}_{\\mathrm{anisotropic}}(U)$ 与 $\\mathrm{TV}_{\\mathrm{isotropic}}(U)$ 之间的数值差异，源于所有像素点上差值 $\\|\\nabla U_{i,j}\\|_1 - \\|\\nabla U_{i,j}\\|_2$ 的总和。只有当梯度向量的两个分量都非零时，这个差值才非零。\n检查我们计算出的梯度，只有像素点 $(2,1)$ 处的梯度向量有两个非零分量：$\\nabla U_{2,1} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$。对于所有其他像素，梯度向量至少有一个零分量，这意味着对于所有 $(i,j) \\neq (2,1)$，都有 $\\|\\nabla U_{i,j}\\|_1 = \\|\\nabla U_{i,j}\\|_2$。\n因此，差异的结构性来源完全位于像素点 $(2,1)$，该点代表一个角点或一个图像强度同时在水平和垂直方向上都发生变化的点。\n\n最后，我们计算精确差值 $D$：\n$$\nD = \\mathrm{TV}_{\\mathrm{anisotropic}}(U) - \\mathrm{TV}_{\\mathrm{isotropic}}(U)\n$$\n这个差值是逐项差异的总和，可以简化为仅有贡献的那个像素点的差值：\n$$\nD = (\\|\\nabla U_{2,1}\\|_1 - \\|\\nabla U_{2,1}\\|_2) = (|2|+|1|) - \\sqrt{2^2+1^2} = 3 - \\sqrt{5}\n$$\n或者，使用计算出的总值：\n$$\nD = 15 - (12 + \\sqrt{5}) = 3 - \\sqrt{5}\n$$\n结果是一致的。", "answer": "$$\n\\boxed{3 - \\sqrt{5}}\n$$", "id": "3491268"}, {"introduction": "在基础计算之上，本练习将挑战您设计简单的图像，以突显两种TV定义的几何敏感性。通过构建具有相同各向同性TV但不同各向异性TV的图像，您将对这些正则化项如何不同地惩罚轴对齐特征与对角线特征获得更深刻的直觉。[@problem_id:3453942]", "problem": "考虑定义在一个 $2 \\times 2$ 网格上的两个灰度图像，其像素强度分别为 $u_{i,j}$ 和 $v_{i,j}$，其中 $i,j \\in \\{1,2\\}$。使用梯度的标准前向差分离散化，不考虑循环边界条件：对于图像 $w$，定义 $D_{x} w_{i,j} = w_{i+1,j} - w_{i,j}$（如果 $i+1 \\leq 2$），否则 $D_{x} w_{i,j} = 0$；类似地，定义 $D_{y} w_{i,j} = w_{i,j+1} - w_{i,j}$（如果 $j+1 \\leq 2$），否则 $D_{y} w_{i,j} = 0$。各向同性全变分 (TV) 为\n$$\n\\mathrm{TV}_{\\mathrm{iso}}(w) = \\sum_{i=1}^{2} \\sum_{j=1}^{2} \\sqrt{\\left(D_{x} w_{i,j}\\right)^{2} + \\left(D_{y} w_{i,j}\\right)^{2}},\n$$\n各向异性全变分为\n$$\n\\mathrm{TV}_{\\mathrm{aniso}}(w) = \\sum_{i=1}^{2} \\sum_{j=1}^{2} \\left| D_{x} w_{i,j} \\right| + \\left| D_{y} w_{i,j} \\right|.\n$$\n构建以下两个由固定振幅 $A > 0$ 参数化的图像。\n- 图像 $u$：设置 $u_{1,1} = 0$, $u_{2,1} = A$, $u_{1,2} = 0$, 以及 $u_{2,2} = A$。\n- 图像 $v$：设置 $v_{1,1} = 0$, $v_{2,1} = t$, $v_{1,2} = t$, 以及 $v_{2,2} = t + s$，其中 $t > 0$ 和 $s > 0$ 需要被选择以满足 $t = s$ 和 $\\mathrm{TV}_{\\mathrm{iso}}(v) = \\mathrm{TV}_{\\mathrm{iso}}(u)$。\n\n仅从这些定义出发，首先在约束 $t = s$ 下确定使 $\\mathrm{TV}_{\\mathrm{iso}}(v) = \\mathrm{TV}_{\\mathrm{iso}}(u)$ 成立的 $t$ 值。然后计算比率\n$$\nR \\equiv \\frac{\\mathrm{TV}_{\\mathrm{aniso}}(v)}{\\mathrm{TV}_{\\mathrm{aniso}}(u)}.\n$$\n给出 $R$ 的最终答案，形式为一个精确的封闭形式表达式。在推导过程中，简要解释导致即使在 $\\mathrm{TV}_{\\mathrm{iso}}$ 匹配的情况下 $\\mathrm{TV}_{\\mathrm{aniso}}$ 仍然不同的那两个图像的结构特征。无需进行舍入。", "solution": "问题要求我们在两个图像 $u$ 和 $v$ 的各向同性全变分相等的约束下，计算它们的各向异性全变分之比。我们首先分别分析每个图像。\n\n我们将图像 $w$ 解释为一个矩阵，其中第一个索引 $i$ 表示行，第二个索引 $j$ 表示列：\n$$\nw = \\begin{pmatrix} w_{1,1}  w_{1,2} \\\\ w_{2,1}  w_{2,2} \\end{pmatrix}\n$$\n根据所提供的定义，算子 $D_x$ 计算行之间的差异（垂直梯度分量），而算子 $D_y$ 计算列之间的差异（水平梯度分量）。\n\n**1. 对图像 $u$ 的分析**\n图像 $u$ 的像素值给定为 $u_{1,1} = 0$, $u_{2,1} = A$, $u_{1,2} = 0$, 以及 $u_{2,2} = A$。矩阵形式为：\n$$\nu = \\begin{pmatrix} 0  0 \\\\ A  A \\end{pmatrix}\n$$\n我们计算每个像素 $(i,j)$ 处的梯度分量 $(D_x u_{i,j}, D_y u_{i,j})$：\n-   在 $(1,1)$ 处：$D_x u_{1,1} = u_{2,1} - u_{1,1} = A - 0 = A$。$D_y u_{1,1} = u_{1,2} - u_{1,1} = 0 - 0 = 0$。梯度：$(A, 0)$。\n-   在 $(1,2)$ 处：$D_x u_{1,2} = u_{2,2} - u_{1,2} = A - 0 = A$。$D_y u_{1,2} = 0$（边界）。梯度：$(A, 0)$。\n-   在 $(2,1)$ 处：$D_x u_{2,1} = 0$（边界）。$D_y u_{2,1} = u_{2,2} - u_{2,1} = A - A = 0$。梯度：$(0, 0)$。\n-   在 $(2,2)$ 处：$D_x u_{2,2} = 0$（边界）。$D_y u_{2,2} = 0$（边界）。梯度：$(0, 0)$。\n\n现在我们计算图像 $u$ 的全变分度量，给定 $A > 0$：\n$$\n\\mathrm{TV}_{\\mathrm{iso}}(u) = \\sqrt{A^2 + 0^2} + \\sqrt{A^2 + 0^2} + \\sqrt{0^2 + 0^2} + \\sqrt{0^2 + 0^2} = A + A = 2A\n$$\n$$\n\\mathrm{TV}_{\\mathrm{aniso}}(u) = (|A| + |0|) + (|A| + |0|) + (|0| + |0|) + (|0| + |0|) = A + A = 2A\n$$\n\n**2. 对图像 $v$ 的分析**\n在约束 $s=t$ 下，图像 $v$ 的像素值为 $v_{1,1} = 0$, $v_{2,1} = t$, $v_{1,2} = t$, 以及 $v_{2,2} = 2t$。矩阵形式为：\n$$\nv = \\begin{pmatrix} 0  t \\\\ t  2t \\end{pmatrix}\n$$\n我们计算每个像素 $(i,j)$ 处的梯度分量 $(D_x v_{i,j}, D_y v_{i,j})$：\n-   在 $(1,1)$ 处：$D_x v_{1,1} = v_{2,1} - v_{1,1} = t - 0 = t$。$D_y v_{1,1} = v_{1,2} - v_{1,1} = t - 0 = t$。梯度：$(t, t)$。\n-   在 $(1,2)$ 处：$D_x v_{1,2} = v_{2,2} - v_{1,2} = 2t - t = t$。$D_y v_{1,2} = 0$（边界）。梯度：$(t, 0)$。\n-   在 $(2,1)$ 处：$D_x v_{2,1} = 0$（边界）。$D_y v_{2,1} = v_{2,2} - v_{2,1} = 2t - t = t$。梯度：$(0, t)$。\n-   在 $(2,2)$ 处：$D_x v_{2,2} = 0$（边界）。$D_y v_{2,2} = 0$（边界）。梯度：$(0, 0)$。\n\n首先，我们计算图像 $v$ 的各向同性 TV。给定 $t > 0$：\n$$\n\\mathrm{TV}_{\\mathrm{iso}}(v) = \\sqrt{t^2 + t^2} + \\sqrt{t^2 + 0^2} + \\sqrt{0^2 + t^2} + \\sqrt{0^2 + 0^2} = \\sqrt{2t^2} + \\sqrt{t^2} + \\sqrt{t^2} = \\sqrt{2}t + t + t = (2 + \\sqrt{2})t\n$$\n\n**3. 确定参数 $t$**\n问题施加了约束 $\\mathrm{TV}_{\\mathrm{iso}}(v) = \\mathrm{TV}_{\\mathrm{iso}}(u)$。使用我们推导出的表达式：\n$$\n(2 + \\sqrt{2})t = 2A\n$$\n求解 $t$（用 $A$ 表示）：\n$$\nt = \\frac{2A}{2 + \\sqrt{2}} = \\frac{2A(2 - \\sqrt{2})}{(2 + \\sqrt{2})(2 - \\sqrt{2})} = \\frac{2A(2 - \\sqrt{2})}{4 - 2} = \\frac{2A(2 - \\sqrt{2})}{2} = A(2 - \\sqrt{2})\n$$\n\n**4. 计算比率 $R$**\n接下来，我们计算图像 $v$ 的各向异性 TV：\n$$\n\\mathrm{TV}_{\\mathrm{aniso}}(v) = (|t| + |t|) + (|t| + |0|) + (|0| + |t|) + (|0| + |0|) = 2t + t + t = 4t\n$$\n最后，我们计算所求的比率 $R$：\n$$\nR = \\frac{\\mathrm{TV}_{\\mathrm{aniso}}(v)}{\\mathrm{TV}_{\\mathrm{aniso}}(u)} = \\frac{4t}{2A} = \\frac{2t}{A}\n$$\n代入 $t$ 的表达式：\n$$\nR = \\frac{2 \\cdot A(2 - \\sqrt{2})}{A} = 2(2 - \\sqrt{2}) = 4 - 2\\sqrt{2}\n$$\n\n**关于结构差异的简要说明**\n$R \\neq 1$ 的核心原因在于各向同性和各向异性 TV 如何惩罚不同的梯度方向。$\\mathrm{TV}_{\\mathrm{iso}}$ 计算梯度向量的 $L_2$ 范数之和 $(\\| \\nabla w_{i,j} \\|_2 = \\sqrt{(D_x w_{i,j})^2 + (D_y w_{i,j})^2})$，而 $\\mathrm{TV}_{\\mathrm{aniso}}$ 计算 $L_1$ 范数之和 $(\\| \\nabla w_{i,j} \\|_1 = |D_x w_{i,j}| + |D_y w_{i,j}|)$。\n\n这些范数的比率 $\\frac{\\| \\nabla w_{i,j} \\|_1}{\\| \\nabla w_{i,j} \\|_2}$ 取决于梯度的方向。对于像 $(g, 0)$ 这样的轴对齐梯度，该比率为 $\\frac{|g|}{ \\sqrt{g^2}} = 1$。对于像 $(g, g)$ 这样的对角线梯度，该比率为 $\\frac{|g| + |g|}{\\sqrt{g^2 + g^2}} = \\frac{2|g|}{\\sqrt{2}|g|} = \\sqrt{2}$。\n\n图像 $u$ 由纯粹的轴对齐梯度（在我们的坐标系中具体是垂直梯度）构成，因此对于其非零梯度分量，$L_1$ 和 $L_2$ 范数是相同的。因此，$\\mathrm{TV}_{\\mathrm{aniso}}(u) = \\mathrm{TV}_{\\mathrm{iso}}(u) = 2A$。\n\n然而，图像 $v$ 包含混合的梯度方向：一个在 $(1,1)$ 处的对角线梯度，以及两个轴对齐梯度。相对于其 $L_2$ 范数的贡献，$L_1$ 范数（各向异性 TV）对对角线梯度的惩罚更重。通过强制使各向同性 TV（$L_2$ 范数之和）相等，不同的惩罚结构确保了各向异性 TV（$L_1$ 范数之和）将不相等。具体来说，图像 $v$ 中对角线特征的存在，使其相对于图像 $u$ 的各向异性 TV 值升高了。", "answer": "$$\n\\boxed{4 - 2\\sqrt{2}}\n$$", "id": "3453942"}, {"introduction": "总变差的理论性质对其在优化算法中的实际应用有着直接影响。本练习将理论与实践联系起来，要求您计算离散梯度算子的谱范数，这是为诸如原始-对偶混合梯度（PDHG）等算法设置稳定且高效步长的关键参数。[@problem_id:3453908]", "problem": "考虑一个在矩形网格上离散化的二维图像域，其水平方向有 $N_{x}$ 个点，垂直方向有 $N_{y}$ 个点。令 $u \\in \\mathbb{R}^{N_{x} N_{y}}$ 表示向量化的图像。定义具有周期性边界条件的前向有限差分梯度算子为线性映射 $K : \\mathbb{R}^{N_{x} N_{y}} \\to \\mathbb{R}^{2 N_{x} N_{y}}$，由 $K u = \\big(D_{x} u, D_{y} u\\big)$ 给出，其中 $D_{x}$ 和 $D_{y}$ 分别计算水平和垂直方向上单位间距的前向差分，并在边界处回绕。各向同性全变分定义为 $\\mathrm{TV}_{\\mathrm{iso}}(u) = \\sum_{i} \\sqrt{\\big(D_{x} u\\big)_{i}^{2} + \\big(D_{y} u\\big)_{i}^{2}}$，各向异性全变分定义为 $\\mathrm{TV}_{\\mathrm{aniso}}(u) = \\sum_{i} \\left| \\big(D_{x} u\\big)_{i} \\right| + \\left| \\big(D_{y} u\\big)_{i} \\right|$。考虑将原始-对偶混合梯度 (Primal-Dual Hybrid Gradient, PDHG) 方法应用于形式为 $\\min_{u} f(u) + \\lambda \\,\\mathrm{TV}(u)$ 的凸优化模型，其中 $f$ 是一个正常、闭、凸函数。PDHG 的一个标准步长条件要求原始步长 $\\tau > 0$ 和对偶步长 $\\sigma > 0$ 满足 $\\tau \\sigma \\lVert K \\rVert^{2}  1$，其中 $\\lVert K \\rVert$ 表示由欧几里得范数诱导的算子范数。\n\n仅使用周期性网格上离散傅里叶变换的基本性质，以及算子范数定义为 $K^{\\ast} K$ 最大特征值的平方根，通过在傅里叶域中对角化 $K$ 来推导 $\\lVert K \\rVert$ 关于 $N_{x}$ 和 $N_{y}$ 的闭式表达式。然后，使用此表达式，确定乘积 $\\tau \\sigma$ 的最大允许值（即在所有可行的 $\\tau$ 和 $\\sigma$ 上的上确界），该值满足各向同性和各向异性全变分的 PDHG 步长条件。请以仅依赖于 $N_{x}$ 和 $N_{y}$ 的单一解析表达式形式给出最终答案。请勿近似；无需四舍五入。", "solution": "问题的核心是计算算子范数的平方 $\\lVert K \\rVert^2$。根据所给定义，$\\lVert K \\rVert^2 = \\lambda_{\\max}(K^{\\ast} K)$，即算子 $K^{\\ast} K$ 的最大特征值。算子 $K$ 定义在周期性网格上，这使其成为一个循环型算子。这类算子可通过离散傅里叶变换 (DFT) 对角化。\n\n我们将图像表示为一个二维数组 $u = \\{u_{i,j}\\}$，其中 $i \\in \\{0, 1, \\dots, N_x-1\\}$ 且 $j \\in \\{0, 1, \\dots, N_y-1\\}$。具有周期性边界条件的前向差分算子由下式给出：\n$$ (D_x u)_{i,j} = u_{i, j+1} - u_{i,j} $$\n$$ (D_y u)_{i,j} = u_{i+1, j} - u_{i,j} $$\n其中索引分别对 $N_x$ 和 $N_y$ 取模。算子 $K$ 将 $u$ 映射到对 $(D_x u, D_y u)$。\n\n算子范数的平方 $\\lVert K \\rVert^2$ 是 $K^\\ast K$ 的谱半径。我们将通过分析 $K^\\ast K$ 在傅里叶域中的作用来找到其特征值。周期性网格上任何线性移不变算子的特征向量都是离散傅里叶模：\n$$ \\phi_{k,l}(i,j) = \\exp\\left(2\\pi \\mathrm{i} \\left(\\frac{ki}{N_x} + \\frac{lj}{N_y}\\right)\\right) $$\n对于频率索引 $k \\in \\{0, \\dots, N_x-1\\}$ 和 $l \\in \\{0, \\dots, N_y-1\\}$，其中 $\\mathrm{i} = \\sqrt{-1}$。\n\n差分算子 $D_x$ 和 $D_y$ 在这些傅里叶模上的作用是乘法性的。令 $\\mathcal{F}$ 表示二维 DFT。对于任何图像 $u$，我们有：\n$$ \\mathcal{F}(D_x u)_{k,l} = \\left(\\exp\\left(\\frac{2\\pi \\mathrm{i} k}{N_x}\\right) - 1\\right) \\mathcal{F}(u)_{k,l} $$\n$$ \\mathcal{F}(D_y u)_{k,l} = \\left(\\exp\\left(\\frac{2\\pi \\mathrm{i} l}{N_y}\\right) - 1\\right) \\mathcal{F}(u)_{k,l} $$\n因此，$D_x$ 和 $D_y$ 的傅里叶符号为 $\\widehat{D_x}(k) = \\exp(2\\pi \\mathrm{i} k/N_x) - 1$ 和 $\\widehat{D_y}(l) = \\exp(2\\pi \\mathrm{i} l/N_y) - 1$。\n\n算子 $K$ 可以写成分块矩阵 $K = \\begin{pmatrix} D_x \\\\ D_y \\end{pmatrix}$。其伴随算子是 $K^\\ast = \\begin{pmatrix} D_x^\\ast  D_y^\\ast \\end{pmatrix}$。那么算子 $K^\\ast K$ 为 $K^\\ast K = D_x^\\ast D_x + D_y^\\ast D_y$。在傅里叶域中，算子的伴随对应于其符号的共轭。因此，$K^\\ast K$ 的符号是：\n$$ \\widehat{K^\\ast K}(k,l) = \\overline{\\widehat{D_x}(k)}\\widehat{D_x}(k) + \\overline{\\widehat{D_y}(l)}\\widehat{D_y}(l) = |\\widehat{D_x}(k)|^2 + |\\widehat{D_y}(l)|^2 $$\n$K^\\ast K$ 的特征值由所有 $(k,l)$ 的这些符号值给出。我们计算模的平方：\n$$ |\\exp(j\\theta)-1|^2 = (\\cos\\theta-1)^2 + \\sin^2\\theta = \\cos^2\\theta - 2\\cos\\theta + 1 + \\sin^2\\theta = 2 - 2\\cos\\theta = 4\\sin^2(\\theta/2) $$\n应用这个恒等式，我们得到 $K^\\ast K$ 的特征值：\n$$ \\lambda_{k,l}(K^\\ast K) = \\left|\\exp\\left(\\frac{2\\pi \\mathrm{i} k}{N_x}\\right) - 1\\right|^2 + \\left|\\exp\\left(\\frac{2\\pi \\mathrm{i} l}{N_y}\\right) - 1\\right|^2 = 4\\sin^2\\left(\\frac{\\pi k}{N_x}\\right) + 4\\sin^2\\left(\\frac{\\pi l}{N_y}\\right) $$\n算子范数的平方 $\\lVert K \\rVert^2$ 是这些特征值在所有有效的 $k$ 和 $l$ 上的最大值。\n$$ \\lVert K \\rVert^2 = \\max_{k,l} \\lambda_{k,l}(K^\\ast K) = \\max_{\\substack{k \\in \\{0, \\dots, N_x-1\\} \\\\ l \\in \\{0, \\dots, N_y-1\\}}} \\left[ 4\\sin^2\\left(\\frac{\\pi k}{N_x}\\right) + 4\\sin^2\\left(\\frac{\\pi l}{N_y}\\right) \\right] $$\n由于变量 $k$ 和 $l$ 是独立的，我们可以分别最大化和中的两项：\n$$ \\lVert K \\rVert^2 = 4 \\left( \\max_{k \\in \\{0, \\dots, N_x-1\\}} \\sin^2\\left(\\frac{\\pi k}{N_x}\\right) + \\max_{l \\in \\{0, \\dots, N_y-1\\}} \\sin^2\\left(\\frac{\\pi l}{N_y}\\right) \\right) $$\n对于整数 $N$，当选择 $k$ 使参数 $\\pi k/N$ 尽可能接近 $\\pi/2$ 时，可以获得 $\\sin^2(\\pi k/N)$ 在 $k \\in \\{0, \\dots, N-1\\}$ 上的最大值。这在 $k = \\lfloor N/2 \\rfloor$ 时发生。因此，\n$$ \\max_{k \\in \\{0, \\dots, N-1\\}} \\sin^2\\left(\\frac{\\pi k}{N}\\right) = \\sin^2\\left(\\frac{\\pi \\lfloor N/2 \\rfloor}{N}\\right) $$\n将此代入我们关于 $\\lVert K \\rVert^2$ 的表达式中：\n$$ \\lVert K \\rVert^2 = 4 \\left( \\sin^2\\left(\\frac{\\pi \\lfloor N_x/2 \\rfloor}{N_x}\\right) + \\sin^2\\left(\\frac{\\pi \\lfloor N_y/2 \\rfloor}{N_y}\\right) \\right) $$\nPDHG 步长条件为 $\\tau \\sigma \\lVert K \\rVert^2  1$，这等价于 $\\tau \\sigma  1/\\lVert K \\rVert^2$。乘积 $\\tau \\sigma$ 的最大允许值是允许范围的上确界，即 $1/\\lVert K \\rVert^2$。此条件仅取决于算子 $K$ 及其定义域和陪域上的欧几里得范数，而不取决于 TV 泛函（各向同性或各向异性）的具体选择。因此，两种情况下的结果是相同的。\n\n$\\tau \\sigma$ 的最大允许值为：\n$$ \\sup\\{\\tau\\sigma\\} = \\frac{1}{\\lVert K \\rVert^2} = \\frac{1}{4 \\left( \\sin^2\\left(\\frac{\\pi \\lfloor N_x/2 \\rfloor}{N_x}\\right) + \\sin^2\\left(\\frac{\\pi \\lfloor N_y/2 \\rfloor}{N_y}\\right) \\right)} $$", "answer": "$$ \\boxed{\\frac{1}{4 \\left( \\sin^2\\left(\\frac{\\pi \\lfloor N_x/2 \\rfloor}{N_x}\\right) + \\sin^2\\left(\\frac{\\pi \\lfloor N_y/2 \\rfloor}{N_y}\\right) \\right)}} $$", "id": "3453908"}]}