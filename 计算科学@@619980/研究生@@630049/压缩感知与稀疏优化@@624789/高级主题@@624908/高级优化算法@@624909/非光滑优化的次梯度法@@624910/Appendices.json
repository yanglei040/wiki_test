{"hands_on_practices": [{"introduction": "理论学习之后，最好的巩固方式是亲自动手计算。本练习将引导你手动执行投影次梯度方法的一个完整迭代步骤。通过为 $\\ell_1$ 范数这个典型的非光滑函数计算一个具体的次梯度，并执行到概率单纯形上的欧几里得投影，你将对次梯度算法的核心机制建立起牢固的直观理解。[@problem_id:3483166]", "problem": "考虑在标准概率单纯形 $\\Delta := \\{x \\in \\mathbb{R}^{5} : x \\ge 0,\\ \\mathbf{1}^{\\top}x = 1\\}$ 上最小化 $\\ell_{1}$ 范数 $f(x) = \\|x\\|_{1}$ 的非光滑凸优化问题。从初始点 $x^{(0)} \\in \\Delta$ 开始，给定步长 $\\alpha  0$，一次投影次梯度下降迭代的形式为 $x^{+} = \\Pi_{\\Delta}\\big(x^{(0)} - \\alpha\\,g^{(0)}\\big)$，其中 $g^{(0)} \\in \\partial \\|x^{(0)}\\|_{1}$ 是 $f$ 在 $x^{(0)}$ 处的任意一个次梯度，$\\partial \\|x^{(0)}\\|_{1}$ 表示次微分，$\\Pi_{\\Delta}$ 是到 $\\Delta$ 上的欧几里得投影，即对于给定的 $y$，在 $z \\in \\Delta$ 上 $\\frac{1}{2}\\|z - y\\|_{2}^{2}$ 的唯一最小化子。\n\n在您的推导中，请仅使用以下基本事实：\n- 对于凸函数 $f$，在点 $x$ 处的次梯度 $g$ 是满足 $f(y) \\ge f(x) + g^{\\top}(y - x)$ 对所有 $y$ 成立的任意向量。\n- 对于 $f(x)=\\|x\\|_{1}$，一个有效的次梯度是当 $x_{i} \\ne 0$ 时 $g_{i} = \\operatorname{sign}(x_{i})$，当 $x_{i} = 0$ 时 $g_{i}$ 可为 $[-1,1]$ 中的任意值。\n- 到一个闭凸集上的欧几里得投影是相应二次规划的唯一解，该解可由 Karush–Kuhn–Tucker (KKT) 条件刻画。\n\n设初始点为\n$$\nx^{(0)} = \\begin{pmatrix} \\frac{3}{5} \\\\ \\frac{1}{4} \\\\ \\frac{1}{10} \\\\ \\frac{1}{20} \\\\ 0 \\end{pmatrix},\n$$\n步长为 $\\alpha = \\frac{3}{10}$。按分量选择次梯度 $g^{(0)} \\in \\partial \\|x^{(0)}\\|_{1}$，规则为当 $x^{(0)}_{i}  0$ 时 $g^{(0)}_{i} = 1$，当 $x^{(0)}_{i} = 0$ 时 $g^{(0)}_{i} = 0$。\n\n通过推导欧几里得投影子问题的 KKT 条件并求解有效集和阈值，精确计算下一次迭代 $x^{+} = \\Pi_{\\Delta}\\big(x^{(0)} - \\alpha\\,g^{(0)}\\big)$。将您的最终答案表示为单个行向量。不需要四舍五入，且不涉及单位。", "solution": "该问题被评估为有效。这是一个在凸优化领域中定义明确的数学问题，所有必要的数据和条件都得到了一致的提供。没有科学或事实上的不健全、模糊或矛盾之处。\n\n任务是计算一次投影次梯度法迭代，用于在概率单纯形 $\\Delta$ 上最小化函数 $f(x) = \\|x\\|_{1}$。更新由 $x^{+} = \\Pi_{\\Delta}\\big(x^{(0)} - \\alpha\\,g^{(0)}\\big)$ 给出。\n\n该过程包括三个主要步骤：\n1.  确定在初始点 $x^{(0)}$ 处的次梯度 $g^{(0)}$。\n2.  计算中间向量 $y = x^{(0)} - \\alpha\\,g^{(0)}$。\n3.  计算 $y$ 到单纯形 $\\Delta$ 上的欧几里得投影，即 $x^{+} = \\Pi_{\\Delta}(y)$。\n\n**步骤 1：计算次梯度 $g^{(0)}$**\n\n初始点给定为\n$$x^{(0)} = \\begin{pmatrix} \\frac{3}{5} \\\\ \\frac{1}{4} \\\\ \\frac{1}{10} \\\\ \\frac{1}{20} \\\\ 0 \\end{pmatrix}$$\n问题指定了选择次梯度 $g^{(0)} \\in \\partial \\|x^{(0)}\\|_{1}$ 的规则为：当 $x^{(0)}_{i}  0$ 时 $g^{(0)}_{i} = 1$，当 $x^{(0)}_{i} = 0$ 时 $g^{(0)}_{i} = 0$。\n$x^{(0)}$ 的前四个分量是正的，第五个分量是零。应用此规则得出：\n$g^{(0)}_{1} = 1$ 因为 $x^{(0)}_{1} = \\frac{3}{5}  0$。\n$g^{(0)}_{2} = 1$ 因为 $x^{(0)}_{2} = \\frac{1}{4}  0$。\n$g^{(0)}_{3} = 1$ 因为 $x^{(0)}_{3} = \\frac{1}{10}  0$。\n$g^{(0)}_{4} = 1$ 因为 $x^{(0)}_{4} = \\frac{1}{20}  0$。\n$g^{(0)}_{5} = 0$ 因为 $x^{(0)}_{5} = 0$。\n因此，次梯度向量为\n$$g^{(0)} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$$\n\n**步骤 2：计算中间向量 $y$**\n\n中间向量是 $y = x^{(0)} - \\alpha\\,g^{(0)}$，步长为 $\\alpha = \\frac{3}{10}$。\n$$y = \\begin{pmatrix} \\frac{3}{5} \\\\ \\frac{1}{4} \\\\ \\frac{1}{10} \\\\ \\frac{1}{20} \\\\ 0 \\end{pmatrix} - \\frac{3}{10} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{5} - \\frac{3}{10} \\\\ \\frac{1}{4} - \\frac{3}{10} \\\\ \\frac{1}{10} - \\frac{3}{10} \\\\ \\frac{1}{20} - \\frac{3}{10} \\\\ 0 - 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{6-3}{10} \\\\ \\frac{5-6}{20} \\\\ \\frac{1-3}{10} \\\\ \\frac{1-6}{20} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{10} \\\\ -\\frac{1}{20} \\\\ -\\frac{2}{10} \\\\ -\\frac{5}{20} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{10} \\\\ -\\frac{1}{20} \\\\ -\\frac{1}{5} \\\\ -\\frac{1}{4} \\\\ 0 \\end{pmatrix}$$\n所以，要投影的向量是 $y = \\begin{pmatrix} \\frac{3}{10}  -\\frac{1}{20}  -\\frac{1}{5}  -\\frac{1}{4}  0 \\end{pmatrix}^{\\top}$。\n\n**步骤 3：计算投影 $x^{+} = \\Pi_{\\Delta}(y)$**\n\n投影 $x^{+} = \\Pi_{\\Delta}(y)$ 是以下凸优化问题的唯一解：\n$$ \\min_{z \\in \\mathbb{R}^{5}} \\frac{1}{2}\\|z - y\\|_{2}^{2} \\quad \\text{subject to} \\quad z \\ge 0, \\quad \\mathbf{1}^{\\top}z = 1 $$\n我们构建拉格朗日函数，使用拉格朗日乘子 $\\lambda \\in \\mathbb{R}^{5}$ 对应非负性约束 ($z_i \\ge 0$) 和一个乘子 $\\nu \\in \\mathbb{R}$ 对应等式约束 ($\\sum_{i=1}^{5} z_i = 1$) 。\n$$ L(z, \\lambda, \\nu) = \\frac{1}{2}\\sum_{i=1}^{5}(z_i - y_i)^2 - \\sum_{i=1}^{5}\\lambda_i z_i + \\nu\\left(\\sum_{i=1}^{5}z_i - 1\\right) $$\n最优解 $x^{+}$ 的 Karush-Kuhn-Tucker (KKT) 条件是：\n1.  **平稳性 (Stationarity)**：$\\frac{\\partial L}{\\partial z_i} = (x^{+}_i - y_i) - \\lambda_i + \\nu = 0$，对于 $i=1, \\dots, 5$。\n2.  **原始可行性 (Primal Feasibility)**：$x^{+}_i \\ge 0$ 对所有 $i$ 成立，且 $\\sum_{i=1}^{5}x^{+}_i = 1$。\n3.  **对偶可行性 (Dual Feasibility)**：$\\lambda_i \\ge 0$ 对所有 $i$ 成立。\n4.  **互补松弛性 (Complementary Slackness)**：$\\lambda_i x^{+}_i = 0$ 对所有 $i$ 成立。\n\n从平稳性条件，我们有 $x^{+}_i = y_i - \\nu + \\lambda_i$。\n从互补松弛性，如果 $x^{+}_i  0$，则 $\\lambda_i = 0$，这意味着 $x^{+}_i = y_i - \\nu$。为了使此值为正，我们必须有 $y_i  \\nu$。\n如果 $x^{+}_i = 0$，则 $\\lambda_i \\ge 0$。平稳性条件给出 $\\lambda_i = \\nu - y_i$，所以我们必须有 $\\nu - y_i \\ge 0$，或 $y_i \\le \\nu$。\n结合这些情况，每个分量的解由 $x^{+}_i = \\max(0, y_i - \\nu)$ 给出。令 $\\theta = \\nu$，解的形式为 $x^{+}_i = (y_i - \\theta)_+$，其中 $(v)_+ = \\max(0,v)$。\n\n阈值 $\\theta$ 由等式约束 $\\sum_{i=1}^{5} x^{+}_i = 1$ 确定：\n$$ \\sum_{i=1}^{5} (y_i - \\theta)_+ = 1 $$\n为了找到 $\\theta$，我们使用一个标准算法。首先，将 $y$ 的分量按降序排序：$y_{(1)} \\ge y_{(2)} \\ge y_{(3)} \\ge y_{(4)} \\ge y_{(5)}$。\n$y$ 的分量是：$\\{ \\frac{3}{10}, -\\frac{1}{20}, -\\frac{1}{5}, -\\frac{1}{4}, 0 \\}$。以十进制形式表示：$\\{ 0.3, -0.05, -0.2, -0.25, 0 \\}$。\n排序后的分量是：\n$y_{(1)} = \\frac{3}{10}$ (来自 $y_1$)\n$y_{(2)} = 0$ (来自 $y_5$)\n$y_{(3)} = -\\frac{1}{20}$ (来自 $y_2$)\n$y_{(4)} = -\\frac{1}{5}$ (来自 $y_3$)\n$y_{(5)} = -\\frac{1}{4}$ (来自 $y_4$)\n\n我们寻找一个整数 $\\rho \\in \\{1, \\dots, 5\\}$ 和一个值 $\\theta$ 使得 $\\sum_{i=1}^{\\rho} (y_{(i)} - \\theta) = 1$ 并且 $y_{(\\rho)}  \\theta \\ge y_{(\\rho+1)}$ (其中 $y_{(6)} = -\\infty$)。这意味着 $x^{+}$ 恰好有 $\\rho$ 个分量是正的。那么阈值为 $\\theta = \\frac{1}{\\rho}\\left(\\sum_{i=1}^{\\rho} y_{(i)} - 1\\right)$。\n\n让我们测试 $\\rho$ 的值：\n- 对于 $\\rho=1$：$\\theta = y_{(1)} - 1 = \\frac{3}{10} - 1 = -\\frac{7}{10}$。条件检查：$y_{(1)}  \\theta$ 是真的，但 $y_{(2)} \\ge \\theta$ ($0 \\ge -0.7$) 也是真的。条件 $y_{(\\rho)}  \\theta \\ge y_{(\\rho+1)}$ 不成立。\n- 对于 $\\rho=2$：$\\theta = \\frac{y_{(1)} + y_{(2)} - 1}{2} = \\frac{\\frac{3}{10} + 0 - 1}{2} = -\\frac{7}{20}$。条件检查：$y_{(2)}  \\theta$ 是真的，但 $y_{(3)} \\ge \\theta$ ($-\\frac{1}{20} \\ge -\\frac{7}{20}$) 也是真的。不成立。\n- 对于 $\\rho=3$：$\\theta = \\frac{y_{(1)} + y_{(2)} + y_{(3)} - 1}{3} = \\frac{\\frac{3}{10} + 0 - \\frac{1}{20} - 1}{3} = \\frac{\\frac{6}{20}-\\frac{1}{20}-\\frac{20}{20}}{3} = \\frac{-15/20}{3} = -\\frac{1}{4}$。条件检查：$y_{(3)}  \\theta$ ($-\\frac{1}{20}  -\\frac{1}{4}$) 是真的，但 $y_{(4)} \\ge \\theta$ ($-\\frac{1}{5} \\ge -\\frac{1}{4}$) 也是真的。不成立。\n- 对于 $\\rho=4$：$\\theta = \\frac{y_{(1)} + y_{(2)} + y_{(3)} + y_{(4)} - 1}{4} = \\frac{\\frac{3}{10} + 0 - \\frac{1}{20} - \\frac{1}{5} - 1}{4} = \\frac{\\frac{6}{20}-\\frac{1}{20}-\\frac{4}{20}-\\frac{20}{20}}{4} = \\frac{-19/20}{4} = -\\frac{19}{80}$。\n条件检查：$y_{(4)}  \\theta \\ge y_{(5)}$？\n$y_{(4)} = -\\frac{1}{5} = -\\frac{16}{80}$。$-\\frac{16}{80}  -\\frac{19}{80}$ 成立吗？是的。\n$y_{(5)} = -\\frac{1}{4} = -\\frac{20}{80}$。$-\\frac{19}{80} \\ge -\\frac{20}{80}$ 成立吗？是的。\n条件成立。因此，有效（非零）分量的正确数量是 $\\rho=4$，并且阈值是 $\\theta = -\\frac{19}{80}$。\n\n有效集由对应于 $y_{(1)}, y_{(2)}, y_{(3)}, y_{(4)}$ 的分量组成，即 $\\{y_1, y_5, y_2, y_3\\}$。分量 $x^{+}_4$ 将为零。\n\n我们现在使用 $x^{+}_i = (y_i - \\theta)_+$，其中 $\\theta = -\\frac{19}{80}$，来计算 $x^{+}$ 的分量：\n$x^{+}_1 = y_1 - \\theta = \\frac{3}{10} - (-\\frac{19}{80}) = \\frac{24}{80} + \\frac{19}{80} = \\frac{43}{80}$。\n$x^{+}_2 = y_2 - \\theta = -\\frac{1}{20} - (-\\frac{19}{80}) = -\\frac{4}{80} + \\frac{19}{80} = \\frac{15}{80} = \\frac{3}{16}$。\n$x^{+}_3 = y_3 - \\theta = -\\frac{1}{5} - (-\\frac{19}{80}) = -\\frac{16}{80} + \\frac{19}{80} = \\frac{3}{80}$。\n$x^{+}_4 = (y_4 - \\theta)_+ = (-\\frac{1}{4} - (-\\frac{19}{80}))_+ = (-\\frac{20}{80} + \\frac{19}{80})_+ = (-\\frac{1}{80})_+ = 0$。\n$x^{+}_5 = y_5 - \\theta = 0 - (-\\frac{19}{80}) = \\frac{19}{80}$。\n\n得到的向量是 $x^{+} = \\begin{pmatrix} \\frac{43}{80} \\\\ \\frac{3}{16} \\\\ \\frac{3}{80} \\\\ 0 \\\\ \\frac{19}{80} \\end{pmatrix}$。\n作为检验，我们确认各分量是非负的并且总和为 $1$：\n$\\frac{43}{80} + \\frac{3}{16} + \\frac{3}{80} + 0 + \\frac{19}{80} = \\frac{43}{80} + \\frac{15}{80} + \\frac{3}{80} + \\frac{19}{80} = \\frac{43+15+3+19}{80} = \\frac{80}{80} = 1$。\n向量 $x^{+}$ 位于单纯形 $\\Delta$ 中。计算是正确的。最终答案应表示为单个行向量。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{43}{80}  \\frac{3}{16}  \\frac{3}{80}  0  \\frac{19}{80}\n\\end{pmatrix}\n}\n$$", "id": "3483166"}, {"introduction": "在掌握了单步迭代的计算之后，一个自然而然的问题是：我们如何评估当前解的质量，或者说，我们距离最优解还有多远？本练习将介绍 Karush-Kuhn-Tucker (KKT) 残差这一关键概念，它是衡量非光滑优化问题（如 LASSO）最优性条件满足程度的实用指标。你将通过计算 KKT 残差，并利用误差界理论将其与实际的解误差联系起来，从而深入理解算法的收敛分析与终止条件的设定。[@problem_id:3483136]", "problem": "考虑被称为最小绝对收缩和选择算子 (LASSO) 的凸优化问题：最小化函数 $F(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2} + \\lambda \\|x\\|_{1}$，其中 $A \\in \\mathbb{R}^{3 \\times 3}$，$b \\in \\mathbb{R}^{3}$，且 $\\lambda  0$。最优性的 Karush–Kuhn–Tucker (KKT) 平稳性条件为 $0 \\in A^{\\top}(A x - b) + \\lambda \\partial \\|x\\|_{1}$，其中 $\\partial \\|x\\|_{1}$ 是 $\\ell_{1}$ 范数的次微分。在迭代点 $x$ 处的 KKT 残差定义为原点到集合 $A^{\\top}(A x - b) + \\lambda \\partial \\|x\\|_{1}$ 的欧几里得距离：\n$$\n\\operatorname{dist}\\big(0,\\, A^{\\top}(A x - b) + \\lambda \\partial \\|x\\|_{1}\\big) \\;=\\; \\min_{s \\in \\partial \\|x\\|_{1}} \\big\\|A^{\\top}(A x - b) + \\lambda s\\big\\|_{2}.\n$$\n假设误差界条件成立：存在 $\\gamma  0$ 使得对于所有 $x$，$\\operatorname{dist}(x, X^{\\star}) \\leq \\gamma \\,\\operatorname{dist}\\big(0,\\, A^{\\top}(A x - b) + \\lambda \\partial \\|x\\|_{1}\\big)$，其中 $X^{\\star}$ 是 $F$ 的极小点集合。对于具体数据\n$$\nA = \\begin{pmatrix} 2  0  0 \\\\ 0  2  0 \\\\ 0  0  3 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ -2 \\\\ 0 \\end{pmatrix}, \\quad \\lambda = 0.5, \\quad x = \\begin{pmatrix} 0 \\\\ 1 \\\\ -0.2 \\end{pmatrix},\n$$\n并假设误差界常数由 $\\gamma = \\frac{1}{\\lambda_{\\min}(A^{\\top}A)}$ 给出，其中 $\\lambda_{\\min}(A^{\\top}A)$ 表示 $A^{\\top}A$ 的最小特征值，计算 KKT 残差 $\\operatorname{dist}\\big(0,\\, A^{\\top}(A x - b) + \\lambda \\partial \\|x\\|_{1}\\big)$，然后使用误差界得到 $\\operatorname{dist}(x, X^{\\star})$ 的一个数值上界。将你最终的数值上界四舍五入到四位有效数字。", "solution": "我们从带有非光滑项的凸优化的基本 KKT 平稳性条件开始。对于函数 $F(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2} + \\lambda \\|x\\|_{1}$，其次梯度集合为\n$$\n\\partial F(x) = A^{\\top}(A x - b) + \\lambda \\partial \\|x\\|_{1},\n$$\n其中对于每个坐标 $i$，$\\ell_{1}$ 范数的次梯度满足\n$$\n\\big(\\partial \\|x\\|_{1}\\big)_{i} = \n\\begin{cases}\n\\{\\operatorname{sign}(x_{i})\\},  \\text{若 } x_{i} \\neq 0, \\\\\n\\left[-1,\\, 1\\right],  \\text{若 } x_{i} = 0.\n\\end{cases}\n$$\nKKT 残差是 $0$ 到集合 $\\partial F(x)$ 的欧几里得距离：\n$$\n\\operatorname{dist}\\big(0,\\, \\partial F(x)\\big) = \\min_{s \\in \\partial \\|x\\|_{1}} \\left\\|A^{\\top}(A x - b) + \\lambda s\\right\\|_{2}.\n$$\n\n我们对给定的数据计算 $q := A^{\\top}(A x - b)$。首先，\n$$\nA x = \\begin{pmatrix} 2  0  0 \\\\ 0  2  0 \\\\ 0  0  3 \\end{pmatrix}\n\\begin{pmatrix} 0 \\\\ 1 \\\\ -0.2 \\end{pmatrix}\n= \\begin{pmatrix} 0 \\\\ 2 \\\\ -0.6 \\end{pmatrix},\n\\quad\nA x - b = \\begin{pmatrix} 0 \\\\ 2 \\\\ -0.6 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ -2 \\\\ 0 \\end{pmatrix}\n= \\begin{pmatrix} -1 \\\\ 4 \\\\ -0.6 \\end{pmatrix}.\n$$\n由于 $A$ 是对角矩阵，$A^{\\top} = A$，因此\n$$\nq = A^{\\top}(A x - b) = A(A x - b)\n= \\begin{pmatrix} 2  0  0 \\\\ 0  2  0 \\\\ 0  0  3 \\end{pmatrix}\n\\begin{pmatrix} -1 \\\\ 4 \\\\ -0.6 \\end{pmatrix}\n= \\begin{pmatrix} -2 \\\\ 8 \\\\ -1.8 \\end{pmatrix}.\n$$\n\n为了在 $s \\in \\partial \\|x\\|_{1}$ 上最小化 $\\left\\|q + \\lambda s\\right\\|_{2}$，我们根据次梯度的规则处理各个坐标。设 $q_i$ 表示 $q$ 的第 $i$ 个分量。\n\n- 对于 $i = 1$，$x_{1} = 0$，所以 $s_{1} \\in [-1,1]$。我们通过选择 $s_1$ 作为 $-\\frac{q_{1}}{\\lambda}$ 在 $[-1,1]$ 上的投影来最小化 $\\left|q_{1} + \\lambda s_{1}\\right|$。这里，$-\\frac{q_{1}}{\\lambda} = -\\frac{-2}{0.5} = 4$，所以投影是 $s_{1} = 1$。因此 $r_{1} := q_{1} + \\lambda s_{1} = -2 + 0.5 \\cdot 1 = -1.5$ 且 $|r_{1}| = 1.5$。等价地，当 $x_{1} = 0$ 时，可达到的最小量值为 $\\max\\{|q_{1}| - \\lambda, 0\\} = \\max\\{2 - 0.5, 0\\} = 1.5$。\n\n- 对于 $i = 2$，$x_{2} = 1 \\neq 0$，所以 $s_{2} = \\operatorname{sign}(x_{2}) = 1$。那么 $r_{2} := q_{2} + \\lambda s_{2} = 8 + 0.5 \\cdot 1 = 8.5$ 且 $|r_{2}| = 8.5$。\n\n- 对于 $i = 3$，$x_{3} = -0.2 \\neq 0$，所以 $s_{3} = \\operatorname{sign}(x_{3}) = -1$。那么 $r_{3} := q_{3} + \\lambda s_{3} = -1.8 + 0.5 \\cdot (-1) = -2.3$ 且 $|r_{3}| = 2.3$。\n\n综合这些，最小化选择的 $s$ 得到残差向量 $r = q + \\lambda s = \\begin{pmatrix} -1.5 \\\\ 8.5 \\\\ -2.3 \\end{pmatrix}$，所以\n$$\n\\operatorname{dist}\\big(0,\\, A^{\\top}(A x - b) + \\lambda \\partial \\|x\\|_{1}\\big)\n= \\|r\\|_{2}\n= \\sqrt{(-1.5)^{2} + (8.5)^{2} + (-2.3)^{2}}\n= \\sqrt{2.25 + 72.25 + 5.29}\n= \\sqrt{79.79}.\n$$\n\n接下来，我们在由强凸性导出的误差界条件下，将 KKT 残差与到最优解集的距离联系起来。函数 $g(x) := \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 的 Hessian 矩阵是 $A^{\\top}A$。如果 $A^{\\top}A$ 是正定的，其最小特征值为 $\\lambda_{\\min}(A^{\\top}A) = m  0$，那么 $g$ 是 $m$-强凸的，并且 $F(x) = g(x) + \\lambda \\|x\\|_{1}$ 也是 $m$-强凸的。对于一个 $m$-强凸函数 $F$，其次微分映射 $\\partial F$ 是 $m$-强单调的，这意味着以下误差界\n$$\n\\operatorname{dist}(x, X^{\\star}) \\leq \\frac{1}{m} \\,\\operatorname{dist}\\big(0,\\, \\partial F(x)\\big).\n$$\n在我们的例子中，$A^{\\top}A = \\operatorname{diag}(4,4,9)$，所以 $\\lambda_{\\min}(A^{\\top}A) = 4$，因此 $\\gamma = \\frac{1}{\\lambda_{\\min}(A^{\\top}A)} = \\frac{1}{4}$。\n\n因此，\n$$\n\\operatorname{dist}(x, X^{\\star}) \\leq \\gamma \\,\\operatorname{dist}\\big(0,\\, A^{\\top}(A x - b) + \\lambda \\partial \\|x\\|_{1}\\big)\n= \\frac{1}{4} \\sqrt{79.79}.\n$$\n数值上，\n$$\n\\sqrt{79.79} \\approx 8.93253,\n\\quad\n\\frac{1}{4}\\sqrt{79.79} \\approx 2.23313.\n$$\n四舍五入到四位有效数字，$\\operatorname{dist}(x, X^{\\star})$ 的数值上界是 $2.233$。", "answer": "$$\\boxed{2.233}$$", "id": "3483136"}, {"introduction": "最后一个练习将理论分析与算法设计融为一体，旨在解决次梯度法在求解稀疏问题时常见的振荡现象。你将通过编程实践，深入探究 $\\ell_1$ 范数次微分的几何结构，并基于此设计一种更智能的步长策略和次梯度选择规则，以抑制解在零点附近的振荡。这个练习充分展示了深刻的理论洞察力如何转化为算法性能的显著提升，是从“知道怎么做”到“知道如何做得更好”的关键一步。[@problem_id:3483135]", "problem": "考虑稀疏恢复中常用的凸复合目标函数：$$F(x) = \\frac{1}{2}\\|A x - y\\|_2^2 + \\lambda \\|x\\|_1,$$ 其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个感知矩阵，$y \\in \\mathbb{R}^m$ 是一个观测向量，$\\lambda  0$ 是一个正则化参数，$x \\in \\mathbb{R}^n$ 是决策变量。次梯度法的更新方式如下：$$x_{k+1} = x_k - t_k g_k,$$ 其中 $g_k \\in \\partial F(x_k)$ 是一个次梯度，$t_k  0$ 是一个步长。光滑部分的梯度由下式给出：$$\\nabla \\left(\\frac{1}{2}\\|A x - y\\|_2^2\\right) = A^\\top (A x - y),$$ 且 $\\ell_1$ 范数的 Clarke 次微分（对于凸函数，其与凸次微分一致）为：$$\\partial \\|x\\|_1 = \\{s \\in \\mathbb{R}^n : s_i = \\operatorname{sign}(x_i) \\text{ if } x_i \\neq 0,\\ \\ s_i \\in [-1,1] \\text{ if } x_i = 0\\}.$$ 在幅值较小（$|x_i| \\approx 0$）的坐标附近，Clarke 次微分的几何性质表现为一个庞大的可选次梯度集合 $s_i \\in [-1,1]$，这可能导致次梯度迭代在多个近零坐标上产生振荡行为。\n\n从这些基本定义出发，分析 $|x_{k,i}|$ 较小的坐标 $i$ 的更新几何形态，并设计一种有原则的步长方案，以明确避免稀疏恢复过程中多个近零坐标上的振荡。您的方案必须从第一性原理推导得出，通过要求在迭代 $k$ 时，近零坐标上的更新不穿越零点（表示为关于 $x_k$ 和 $g_k$ 的 $t_k$ 不等式约束），并且必须包含一个与 $x_{k,i} = 0$ 处的 Clarke 次微分几何相一致的 $\\ell_1$ 次梯度 $s_k \\in \\partial \\|x_k\\|_1$ 选择规则。\n\n实现两种方法：\n- 一种使用标准递减步长的基准次梯度法。\n- 您提出的次梯度法，采用避免振荡的步长方案，并在 $x_{k,i} = 0$ 处使用一个使非光滑分量与光滑残差对齐的次梯度选择规则。\n\n对于每种方法，运行固定次数的迭代，并按如下方式统计近零坐标上的振荡次数：定义一个阈值 $\\tau  0$；对于每个坐标 $i$，如果在任意两个连续迭代值 $x_{k,i}$ 和 $x_{k+1,i}$ 之间，乘积 $x_{k,i} x_{k+1,i}  0$ 且它们的幅值均满足 $|x_{k,i}| \\le \\tau$ 和 $|x_{k+1,i}| \\le \\tau$，则振荡计数加一。总振荡次数是所有坐标和所有迭代的计数总和。\n\n对于每个测试用例，您的程序必须输出一个布尔值，该值表示所提出的方法是否比基准方法实现了严格更少的振荡，并且最终目标值具有可比性（不大于基准方法最终值的 $\\alpha$ 倍）。将所有结果汇总为单行输出，形式为方括号内以逗号分隔的列表。\n\n使用以下测试套件。每个测试用例指定 $(m,n,k_{\\text{true}},\\lambda,\\sigma,T,\\text{seed})$，其中 $k_{\\text{true}}$ 是真实值 $x^\\star$ 的稀疏度（非零项的数量），$\\sigma$ 是 $y$ 上加性高斯噪声的标准差，$T$ 是迭代次数，$\\text{seed}$ 是随机种子。构造 $A$ 时，除另有规定外，其条目为独立同分布的高斯分布，然后进行列归一化至单位 $\\ell_2$ 范数。构造 $x^\\star$ 时，在随机位置上放置 $k_{\\text{true}}$ 个非零项，其值在 $[0.5,1.5]$ 中均匀分布，并带有随机符号；设 $y = A x^\\star + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2 I_m)$。\n\n- 测试用例 1 (理想情况): $(m,n,k_{\\text{true}},\\lambda,\\sigma,T,\\text{seed}) = (40,100,10,0.05,0.0,600,1234)$。\n- 测试用例 2 (小正则化): $(m,n,k_{\\text{true}},\\lambda,\\sigma,T,\\text{seed}) = (30,80,6,0.005,0.0,700,5678)$。\n- 测试用例 3 (相关列): $(m,n,k_{\\text{true}},\\lambda,\\sigma,T,\\text{seed}) = (35,90,8,0.04,0.0,700,9012)$；构造 $A$ 时，首先生成一个标准高斯矩阵，然后通过设置 $A_{\\cdot,2} = A_{\\cdot,1} + 0.05 \\, u$（其中 $u \\sim \\mathcal{N}(0,I_m)$）使第 1 列和第 2 列在微小扰动下相等，最后进行列归一化。\n- 测试用例 4 (带噪观测): $(m,n,k_{\\text{true}},\\lambda,\\sigma,T,\\text{seed}) = (50,120,12,0.06,0.02,800,2468)$。\n\n设基准步长为 $t_k^{\\text{base}} = \\frac{c}{\\sqrt{k+1}}$，其中 $c = \\frac{0.9}{L}$，$L$ 是 $A$ 的谱范数的平方（即光滑部分梯度的 Lipschitz 常数），并使用次梯度选择规则：当 $x_{k,i} \\neq 0$ 时，$s_{k,i} = \\operatorname{sign}(x_{k,i})$；当 $x_{k,i} = 0$ 时，$s_{k,i} = 0$。对于所提出的方法，使用相同的基准步长 $t_k^{\\text{base}}$，但强制执行一个从不穿越约束推导出的安全上限：$$t_k \\le \\gamma \\min_{i \\in \\mathcal{Z}_k} \\frac{|x_{k,i}| + \\epsilon}{|g_{k,i}| + \\epsilon},$$ 其中 $\\gamma \\in (0,1)$ 是一个安全因子，$\\epsilon  0$ 是一个保护值，$\\mathcal{Z}_k = \\{i : |x_{k,i}| \\le \\delta\\}$ 是带有阈值 $\\delta  0$ 的近零索引集。在 $x_{k,i} = 0$ 处选择 $\\ell_1$ 次梯度为 $$s_{k,i} = \\operatorname{clip}\\left(-\\frac{(A^\\top (A x_k - y))_i}{\\lambda},\\ -1,\\ 1\\right),$$ 这确保了 $g_{k,i} = (A^\\top (A x_k - y))_i + \\lambda s_{k,i}$ 与零点处的 Clarke 次微分几何相符。\n\n在所有测试用例中，使用参数 $\\tau = 10^{-3}$、$\\delta = 10^{-2}$、$\\epsilon = 10^{-12}$ 和 $\\gamma = 0.9$。对于两种方法，均初始化 $x_0 = 0 \\in \\mathbb{R}^n$。对于每个测试用例，返回一个布尔值，表示 $(\\text{osc}_{\\text{proposed}}  \\text{osc}_{\\text{baseline}})$ 且 $F(x_T^{\\text{proposed}}) \\le \\alpha F(x_T^{\\text{baseline}})$，其中 $\\alpha = 1.05$。您的程序应生成一行输出，其中包含一个方括号括起来的逗号分隔列表（例如 $[result_1,result_2,result_3,result_4]$），每个 $result_i$ 为 $\\text{True}$ 或 $\\text{False}$。", "solution": "问题陈述经评估有效。它在科学上基于非光滑凸优化的成熟理论，特别是应用于 LASSO 目标函数的次梯度法。该问题是适定的，所有必需的数据、参数和评估目标标准都已明确定义。其语言是客观的，并且整个设置可以形式化为一个计算任务。\n\n问题的核心是解决次梯度法应用于非光滑目标函数 $F(x) = \\frac{1}{2}\\|A x - y\\|_2^2 + \\lambda \\|x\\|_1$ 时出现的振荡行为。该函数是一个光滑可微部分 $f(x) = \\frac{1}{2}\\|A x - y\\|_2^2$ 与一个非光滑凸部分 $h(x) = \\lambda \\|x\\|_1$ 的和。\n\n次梯度法的迭代如下：\n$$x_{k+1} = x_k - t_k g_k$$\n其中 $k$ 是迭代索引，$t_k  0$ 是步长，$g_k$ 是 $F$ 在 $x_k$ 处的一个次梯度。根据次微分的和法则，任何次梯度 $g_k \\in \\partial F(x_k)$ 都可以写成：\n$$g_k = \\nabla f(x_k) + \\lambda s_k, \\quad \\text{其中 } s_k \\in \\partial \\|x_k\\|_1$$\n光滑部分的梯度是 $\\nabla f(x) = A^\\top(A x - y)$。$\\ell_1$ 范数的次微分 $\\partial \\|x\\|_1$ 是向量 $s$ 的集合，使得对于每个分量 $i$：\n$$s_i = \\begin{cases} \\operatorname{sign}(x_i)  \\text{if } x_i \\neq 0 \\\\ v_i \\in [-1, 1]  \\text{if } x_i = 0 \\end{cases}$$\n振荡行为出现在 $|x_{k,i}|$ 很小的坐标附近。单个坐标 $i$ 的更新是 $x_{k+1,i} = x_{k,i} - t_k g_{k,i}$。如果 $t_k |g_{k,i}|$ 大于 $|x_{k,i}|$，更新将导致 $x_{k,i}$ 穿越零点，即 $\\operatorname{sign}(x_{k+1,i}) \\neq \\operatorname{sign}(x_{k,i})$。对于一个应该收敛到零的坐标，重复的符号变化是低效且不希望看到的。该问题提出了一个有原则的方法，通过设计专门的步长方案和次梯度选择规则来缓解此问题。\n\n### 所提出方法的推导\n\n**1. 避免振荡的步长方案**\n\n主要目标是防止已经接近原点的坐标的迭代值穿越原点。我们定义在迭代 $k$ 时的一个“近零”坐标集为 $\\mathcal{Z}_k = \\{i : |x_{k,i}| \\le \\delta\\}$，其中 $\\delta  0$ 是某个阈值。\n对于任何坐标 $i \\in \\mathcal{Z}_k$，我们希望强制执行更新不改变其符号的条件。这可以表示为要求更新步长的大小 $|t_k g_{k,i}|$ 不超过坐标的当前大小 $|x_{k,i}|$。\n$$|t_k g_{k,i}| \\le |x_{k,i}|$$\n假设 $g_{k,i} \\neq 0$，这得出了步长的上界：\n$$t_k \\le \\frac{|x_{k,i}|}{|g_{k,i}|}$$\n为确保此条件对近零集 $\\mathcal{Z}_k$ 中的所有坐标都成立，步长必须受限于这些界中最严格的一个：\n$$t_k \\le \\min_{i \\in \\mathcal{Z}_k} \\frac{|x_{k,i}|}{|g_{k_i}|}$$\n为了数值稳定性（避免当 $|g_{k,i}|$ 很小时除以零）并引入一个保守的余量，我们在分子和分母上都加上一个小的正常数保护值 $\\epsilon  0$，并乘以一个安全因子 $\\gamma \\in (0,1)$。这就得到了问题中指定的步长上限：\n$$t_k^{\\text{cap}} = \\gamma \\min_{i \\in \\mathcal{Z}_k} \\frac{|x_{k,i}| + \\epsilon}{|g_{k,i}| + \\epsilon}$$\n最终提出的步长 $t_k$ 于是被选为标准递减步长 $t_k^{\\text{base}}$ 和这个自适应上限的最小值：$t_k = \\min(t_k^{\\text{base}}, t_k^{\\text{cap}})$。如果集合 $\\mathcal{Z}_k$ 为空，则不应用上限，$t_k = t_k^{\\text{base}}$。\n\n**2. 有原则的次梯度选择**\n\n所提出方法的第二个组成部分处理了当坐标 $x_{k,i} = 0$ 时次梯度 $s_{k,i}$ 的选择问题。在这些点上，我们可以自由选择任何 $s_{k,i} \\in [-1,1]$。一个有原则的选择是最小化所得次梯度分量 $|g_{k,i}| = |\\left(A^\\top (A x_k - y)\\right)_i + \\lambda s_{k,i}|$ 的大小。这是一种通过从次微分集合 $\\partial F(x_k)$ 中选择“最小”可能次梯度来稳定算法的策略。\n\n为了最小化 $|g_{k,i}|$，我们应该选择 $s_{k,i}$ 来抵消梯度的光滑部分 $(\\nabla f(x_k))_i = \\left(A^\\top (A x_k - y)\\right)_i$。理想值将是 $s_{k,i} = -(\\nabla f(x_k))_i / \\lambda$，这将使 $g_{k,i} = 0$。然而，$s_{k,i}$ 的选择被约束在区间 $[-1, 1]$ 内。因此，$s_{k,i}$ 的最优选择是 $[-1, 1]$ 中最接近 $-(\\nabla f(x_k))_i / \\lambda$ 的值。这可以通过将值裁剪（投影）到该区间上来实现：\n$$s_{k,i} = \\operatorname{clip}\\left(-\\frac{(A^\\top (A x_k - y))_i}{\\lambda}, -1, 1\\right)$$\n这个选择规则与零点处的 Clarke 次微分几何相一致；它代表了一种将非光滑分量与光滑残差对齐的刻意选择，从而促进稳定性和向稀疏解的收敛。这恰恰是著名的迭代软阈值算法 (ISTA) 中使用的规则，ISTA 是解决此类问题的一种更高级的近端梯度法。\n\n自适应步长上限和有原則的次梯度选择规则的结合，构成了一种复杂的、针对稀疏恢復问题结构量身定制的次梯度法，它是从第一性原理出发设计的，旨在减轻困扰标准次梯度法的振荡问题。该实现将把此方法与使用标准步长方案和更简单次梯度选择规则的基准方法进行比较。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulations and generate the final output.\n    \"\"\"\n    # Define problem parameters\n    test_cases = [\n        # (m, n, k_true, lambda, sigma, T, seed)\n        (40, 100, 10, 0.05, 0.0, 600, 1234),\n        (30, 80, 6, 0.005, 0.0, 700, 5678),\n        (35, 90, 8, 0.04, 0.0, 700, 9012),\n        (50, 120, 12, 0.06, 0.02, 800, 2468),\n    ]\n\n    # Algorithm parameters\n    tau = 1e-3\n    delta = 1e-2\n    epsilon = 1e-12\n    gamma = 0.9\n    alpha = 1.05\n\n    results = []\n\n    for i, case in enumerate(test_cases):\n        m, n, k_true, lambda_val, sigma, T, seed = case\n        \n        # --- Data Generation ---\n        rng = np.random.default_rng(seed)\n        A = rng.normal(size=(m, n))\n\n        if i == 2:  # Correlated columns for Test Case 3\n            u = rng.normal(size=m)\n            A[:, 1] = A[:, 0] + 0.05 * u\n\n        col_norms = np.linalg.norm(A, axis=0)\n        A = A / col_norms[np.newaxis, :]\n        \n        x_star = np.zeros(n)\n        support = rng.choice(n, k_true, replace=False)\n        values = rng.uniform(0.5, 1.5, k_true)\n        signs = rng.choice([-1, 1], k_true)\n        x_star[support] = values * signs\n        \n        noise = rng.normal(0, sigma, m)\n        y = A @ x_star + noise\n\n        # --- Helper Functions ---\n        def objective_function(x, A, y, lambda_val):\n            return 0.5 * np.linalg.norm(A @ x - y)**2 + lambda_val * np.linalg.norm(x, 1)\n\n        def grad_smooth(x, A, y):\n            return A.T @ (A @ x - y)\n\n        L = np.linalg.norm(A, 2)**2\n        c = 0.9 / L\n        x0 = np.zeros(n)\n\n        # --- Baseline Subgradient Method ---\n        x_base = x0.copy()\n        osc_base = 0\n        for k in range(T):\n            x_prev = x_base.copy()\n            grad_h = grad_smooth(x_base, A, y)\n            s_k = np.sign(x_base)\n            g_k = grad_h + lambda_val * s_k\n            t_k = c / np.sqrt(k + 1)\n            x_base = x_base - t_k * g_k\n            \n            # Count oscillations\n            crossed_zero = (x_prev * x_base  0)\n            small_mag = (np.abs(x_prev) = tau)  (np.abs(x_base) = tau)\n            osc_base += np.sum(crossed_zero  small_mag)\n\n        final_obj_base = objective_function(x_base, A, y, lambda_val)\n\n        # --- Proposed Subgradient Method ---\n        x_prop = x0.copy()\n        osc_prop = 0\n        for k in range(T):\n            x_prev = x_prop.copy()\n            \n            grad_h = grad_smooth(x_prop, A, y)\n            \n            s_k = np.zeros(n)\n            nonzero_idx = x_prop != 0\n            zero_idx = x_prop == 0\n            \n            s_k[nonzero_idx] = np.sign(x_prop[nonzero_idx])\n            s_k[zero_idx] = np.clip(-grad_h[zero_idx] / lambda_val, -1, 1)\n            \n            g_k = grad_h + lambda_val * s_k\n            \n            t_base = c / np.sqrt(k + 1)\n            \n            near_zero_idx = np.where(np.abs(x_prop) = delta)[0]\n            if near_zero_idx.size  0:\n                numer = np.abs(x_prop[near_zero_idx]) + epsilon\n                denom = np.abs(g_k[near_zero_idx]) + epsilon\n                t_cap = gamma * np.min(numer / denom)\n                t_k = min(t_base, t_cap)\n            else:\n                t_k = t_base\n\n            x_prop = x_prop - t_k * g_k\n            \n            # Count oscillations\n            crossed_zero = (x_prev * x_prop  0)\n            small_mag = (np.abs(x_prev) = tau)  (np.abs(x_prop) = tau)\n            osc_prop += np.sum(crossed_zero  small_mag)\n\n        final_obj_prop = objective_function(x_prop, A, y, lambda_val)\n        \n        # --- Evaluate and Store Result ---\n        osc_check = osc_prop  osc_base\n        obj_check = final_obj_prop = alpha * final_obj_base\n        results.append(osc_check and obj_check)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3483135"}]}