{"hands_on_practices": [{"introduction": "要真正理解高维空间中经典采样方法的局限性，最直观的方式莫过于进行一次直接的定量比较。本练习将引导你计算和对比经典奈奎斯特-香农（Nyquist-Shannon）采样理论与压缩感知（Compressed Sensing）理论在处理一个高维带限函数时所需的样本数量。通过这个计算 [@problem_id:3434276]，你将亲身体会到“维度灾难”的巨大影响，并理解压缩感知在样本复杂度上所带来的革命性优势。", "problem": "考虑一个实值函数 $f : [0,1]^{d} \\to \\mathbb{R}$，该函数是带限的，即其 $d$ 维傅里叶变换的支撑集包含在笛卡尔积 $[-W, W]^{d}$ 内。经典的奈奎斯特-香农采样理论断言，为避免一维中的混叠，需要一个满足 $\\Delta \\leq \\frac{1}{2W}$ 的均匀采样间隔 $\\Delta$。在 $d$ 维均匀网格上，此要求独立地应用于每个坐标轴。因此，每个轴的最小整数网格点数为 $N = \\lceil \\frac{1}{\\Delta} \\rceil$，在 $[0,1]^{d}$ 上的总网格样本数为 $N^{d}$。\n\n在压缩感知中的受限等距性质（RIP）框架下，用于恢复环境维度为 $n$ 的 $s$-稀疏向量的一个标准充分测量界为 $m = C s \\ln\\!\\left(\\frac{n}{s}\\right)$，其中 $\\ln$ 表示自然对数。\n\n使用 $d = 10$, $W = 50$, $[0,1]^{10}$, $n = 10^{6}$, $s = 100$ 和 $C = 5$，计算经典带限采样所需的最小均匀网格样本数与压缩感知界 $m$ 的比值 $R$。将您的最终答案 $R$ 表示为科学记数法，并四舍五入到三位有效数字。不需要单位。", "solution": "用户希望比较两种不同信号采集框架所需的样本数量：经典奈奎斯特-香农采样和压缩感知。题目陈述为这次比较提供了所有必要的公式和参数。\n\n首先，我们计算经典带限采样理论所需的最小均匀网格样本数，我们将其表示为 $N_{\\text{classical}}$。\n题目指定了一个函数 $f : [0,1]^{d} \\to \\mathbb{R}$，其傅里叶变换的支撑集在 $[-W, W]^{d}$ 内。根据奈奎斯特-香农采样定理，沿每个维度的采样间隔 $\\Delta$ 必须满足条件 $\\Delta \\leq \\frac{1}{2W}$。\n为了获得最少的样本数，我们必须使用允许的最大采样间隔，即 $\\Delta = \\frac{1}{2W}$。\n题目提供了带宽参数 $W = 50$。代入该值，我们求出采样间隔：\n$$ \\Delta = \\frac{1}{2 \\times 50} = \\frac{1}{100} $$\n题目将每个轴的最小整数网格点数定义为 $N = \\lceil \\frac{1}{\\Delta} \\rceil$。使用我们计算出的 $\\Delta$ 值：\n$$ N = \\left\\lceil \\frac{1}{1/100} \\right\\rceil = \\lceil 100 \\rceil = 100 $$\n对于一个 $d$ 维函数，在均匀网格上的总网格样本数由 $N_{\\text{classical}} = N^{d}$ 给出。题目指定维度为 $d = 10$。因此，经典采样的总样本数为：\n$$ N_{\\text{classical}} = 100^{10} = (10^{2})^{10} = 10^{20} $$\n\n接下来，我们计算在压缩感知（CS）框架下所需的测量次数，用 $m$ 表示。题目提供了来自受限等距性质（RIP）的标准充分测量界：\n$$ m = C s \\ln\\left(\\frac{n}{s}\\right) $$\n给定的参数是常数 $C = 5$，稀疏度 $s = 100$，以及环境维度 $n = 10^{6}$。我们将这些值代入 $m$ 的公式中：\n$$ m = 5 \\times 100 \\times \\ln\\left(\\frac{10^{6}}{100}\\right) $$\n首先，我们简化自然对数的参数：\n$$ \\frac{n}{s} = \\frac{10^{6}}{10^{2}} = 10^{4} $$\n现在，我们将其代回 $m$ 的表达式中：\n$$ m = 500 \\times \\ln(10^{4}) $$\n使用对数性质 $\\ln(a^{b}) = b \\ln(a)$，我们得到：\n$$ m = 500 \\times 4 \\ln(10) = 2000 \\ln(10) $$\n\n最后，我们计算经典样本数与 CS 测量数的比值 $R$：\n$$ R = \\frac{N_{\\text{classical}}}{m} = \\frac{10^{20}}{2000 \\ln(10)} $$\n为了将其表示为科学记数法，我们可以重写分母：\n$$ R = \\frac{10^{20}}{2 \\times 10^{3} \\ln(10)} = \\frac{10^{17}}{2 \\ln(10)} $$\n为了获得数值，我们使用 $10$ 的自然对数的近似值，即 $\\ln(10) \\approx 2.302585$。\n$$ R \\approx \\frac{10^{17}}{2 \\times 2.302585} = \\frac{10^{17}}{4.60517} $$\n$$ R \\approx 0.217147 \\times 10^{17} $$\n为了将其写成标准的科学记数法，我们调整尾数和指数：\n$$ R \\approx 2.17147 \\times 10^{16} $$\n题目要求最终答案四舍五入到三位有效数字。\n$$ R \\approx 2.17 \\times 10^{16} $$\n这个比率表明，对于高维稀疏信号，与经典的奈奎斯特速率采样相比，压缩感知在所需测量数量上提供了巨大的减少，这一现象规避了“维度灾难”。", "answer": "$$\\boxed{2.17 \\times 10^{16}}$$", "id": "3434276"}, {"introduction": "“维度灾难”并非仅仅局限于傅里叶分析或带限信号模型，它是一个更普遍的现象，影响着众多高维函数近似方法。本练习将我们的视角从傅里叶基扩展到多项式基，这是一个在不确定性量化和高维偏微分方程求解中至关重要的领域。你将通过计算 [@problem_id:3434226]，对比经典的全张量积多项式插值所需的庞大点集，与利用稀疏性进行恢复时更高效的总次数多项式空间的维度，从而深化对高维问题普遍挑战的认识。", "problem": "考虑在一个 $d$ 维超立方体上，使用最大总次数为 $p$ 的总次数多项式空间来逼近一个函数。此空间中基函数（单项式）的数量由计算所有满足 $\\sum_{i=1}^{d} \\alpha_{i} \\leq p$ 的非负整数多重指标 $(\\alpha_{1},\\dots,\\alpha_{d})$ 的数量确定，这是一个标准的“星与杠”计数问题。假设在此基下的目标系数向量是 $s$-稀疏的，并且测量值是通过独立的亚高斯线性泛函获得的。根据压缩感知理论和有限等距性质（RIP），经过充分检验的结果保证，在无噪声情况下，只要测量次数 $m$ 的尺度（在普适常数范围内）满足 $m \\sim s \\ln(n/s)$，就可以精确恢复 $s$-稀疏的系数向量，其中 $n$ 是系数向量的环境维数。\n\n在此框架下：\n- 推导总次数基函数数量 $n$ 关于 $d$ 和 $p$ 的解析公式。\n- 使用基于 RIP 的标准保证对于亚高斯设计，将充分的测量次数 $m$ 表示为 $m=\\lceil C\\, s\\, \\ln(n/s)\\rceil$ 形式的闭式解析表达式，其中 $C>0$ 是一个可以保留为符号的普适常数，$\\ln$ 表示自然对数。\n- 对于旨在唯一确定每个坐标次数最多为 $p$ 的全张量积多项式空间中所有系数的经典张量积采样方法，计算使用每个坐标 $p+1$ 个点时，张量积配置点的最小数量 $N_{\\mathrm{TP}}$。\n\n对于 $d=20$，$p=5$ 和 $s=300$ 的情况，计算这些量的值，并将您的最终答案表示为一个单行向量，按顺序包含 $n$、$m$ 和 $N_{\\mathrm{TP}}$ 的值。不需要四舍五入；以精确的解析形式表示您的答案。对数项请使用自然对数。最终的行向量必须是唯一报告的结果。", "solution": "该问题要求计算与 $d$ 维域上多元函数逼近相关的三个量：总次数多项式空间的环境维数 $n$，稀疏恢复所需的压缩感知测量次数 $m$，以及经典张量积采样点数 $N_{\\mathrm{TP}}$。分析将针对具体参数 $d=20$，$p=5$ 和 $s=300$ 进行。\n\n首先，我们确定在 $d$ 维中，最大总次数为 $p$ 的总次数多项式空间的基函数数量 $n$。该空间由形如 $\\prod_{i=1}^{d} x_i^{\\alpha_i}$ 的单项式张成，其中指数 $\\alpha_i$ 是满足条件 $\\sum_{i=1}^{d} \\alpha_i \\le p$ 的非负整数。因此，维数 $n$ 是该不等式的非负整数解的数量。\n\n这是一个经典的组合问题，可以用“星与杠”法解决。我们引入一个松弛变量 $\\alpha_{d+1} \\ge 0$，将不等式转化为等式：\n$$ \\sum_{i=1}^{d} \\alpha_i + \\alpha_{d+1} = p $$\n问题现在等价于求将 $p$ 个不可区分的物品（星）分配到 $d+1$ 个可区分的箱子（变量 $\\alpha_1, \\dots, \\alpha_{d+1}$）中的方法数。这种划分的数量由多重集系数给出，它等价于一个二项式系数：\n$$ n = \\binom{p + (d+1) - 1}{(d+1) - 1} = \\binom{p+d}{d} $$\n代入给定值 $d=20$ 和 $p=5$：\n$$ n = \\binom{5+20}{20} = \\binom{25}{20} = \\binom{25}{5} $$\n我们计算这个二项式系数的值：\n$$ n = \\frac{25 \\cdot 24 \\cdot 23 \\cdot 22 \\cdot 21}{5 \\cdot 4 \\cdot 3 \\cdot 2 \\cdot 1} = \\frac{25 \\cdot 24 \\cdot 23 \\cdot 22 \\cdot 21}{120} $$\n通过重新整理各项：\n$$ n = \\frac{25}{5} \\cdot \\frac{24}{4 \\cdot 3 \\cdot 2 \\cdot 1} \\cdot 23 \\cdot 22 \\cdot 21 = 5 \\cdot 1 \\cdot 23 \\cdot 22 \\cdot 21 = 53130 $$\n因此，系数向量的环境维数是 $n=53130$。\n\n第二，我们确定稀疏恢复所需的充分测量次数 $m$。问题指出，对于亚高斯测量设计，有限等距性质（RIP）的保证给出了 $m$ 的一个尺度定律。公式如下：\n$$ m = \\lceil C \\, s \\, \\ln(n/s) \\rceil $$\n其中 $C > 0$ 是一个普适常数，$s$ 是稀疏度，$n$ 是环境维数。给定 $s=300$ 且我们已计算出 $n=53130$。我们可以计算比率 $n/s$：\n$$ \\frac{n}{s} = \\frac{53130}{300} = \\frac{5313}{30} = \\frac{1771}{10} = 177.1 $$\n将这些值代回 $m$ 的公式，我们按照要求得到其精确的解析表达式，将 $C$ 保留为符号：\n$$ m = \\left\\lceil 300 C \\ln\\left(\\frac{1771}{10}\\right) \\right\\rceil $$\n\n第三，我们计算经典张量积方法所需的采样点数 $N_{\\mathrm{TP}}$。此方法旨在唯一确定在全张量积多项式空间中所有系数，其中每个 $d$ 坐标的次数最多为 $p$。该空间的基由单项式组成，其中每个指数 $\\alpha_i$ 可以独立地在 $0$ 到 $p$ 之间取值。因此，基函数的总数，即该空间的维数，是 $(p+1)^d$。一种确定系数的标准方法是使用张量积配置点网格。对 $d$ 个坐标中的每一个使用 $p+1$ 个不同的点，会产生一个包含 $(p+1)^d$ 个点的网格，这是在此类网格上保证多项式系数有唯一解所需的最小点数。因此，配置点的数量是：\n$$ N_{\\mathrm{TP}} = (p+1)^d $$\n代入给定值 $d=20$ 和 $p=5$：\n$$ N_{\\mathrm{TP}} = (5+1)^{20} = 6^{20} $$\n这个数字代表了“维度灾难”，而压缩感知正是为了解决稀疏问题的这一难题，因为与 $m$ 相比，$N_{\\mathrm{TP}}$ 是一个天文数字。\n\n所需的三个值为 $n=53130$，$m=\\lceil 300C \\ln(\\frac{1771}{10}) \\rceil$ 和 $N_{\\mathrm{TP}}=6^{20}$。", "answer": "$$\\boxed{\\begin{pmatrix} 53130 & \\lceil 300C \\ln(\\frac{1771}{10}) \\rceil & 6^{20} \\end{pmatrix}}$$", "id": "3434226"}, {"introduction": "在理论上理解了样本数量的巨大差异后，一个自然而然的问题是：在实践中，我们如何设计和评估压缩感知的测量方案？本练习将带你从理论计算走向数值实践，通过一个具体的编码任务来量化和比较两种常见的傅里叶采样策略：均匀随机采样和可分离的变密度采样。你将利用相互干性（mutual coherence）这一核心概念 [@problem_id:3434286]，实现一个评估稀疏恢复性能的代理指标，从而获得设计和分析压缩感知测量矩阵的宝贵实践经验。", "problem": "考虑一个每个轴大小为 $N$ 的离散 $d$ 维信号，因此环境维度为 $n=N^d$。用于精确傅里叶域重建的经典均匀网格采样需要 $n$ 个样本，当 $n$ 极大时，这在高维情况下变得不可行。压缩感知提出，在适当的测量设计和稀疏性假设下，可以从 $m \\ll n$ 次测量中精确恢复 $s$-稀疏信号。您的目标是通过基于核心定义和经过充分检验的结果的原则性估计，来量化经典采样的失效情况，并比较在 $d=4$ 维中两种傅里叶采样策略（均匀随机采样和可分离变密度采样）的预期稀疏恢复质量。\n\n基本基础：\n- 部分离散傅里叶变换测量模型从 $n \\times n$ 酉离散傅里叶变换矩阵中选择 $m$ 行（频率），并观测一个 $s$-稀疏向量 $x \\in \\mathbb{C}^n$ 的相应线性测量值。\n- 测量矩阵（列已归一化）的互相关性 $\\mu$ 定义为任意两个不同列之间归一化内积的最大绝对值，并且是稀疏恢复保证的一个经过充分检验的代理指标。\n- 通过诸如基追踪 (Basis Pursuit) 等凸规划或正交匹配追踪 (Orthogonal Matching Pursuit) 等贪婪方法，精确恢复 $s$-稀疏向量（在无噪声情况下）的一个经典充分条件是不等式 $s  \\frac{1}{2}\\left(1 + \\frac{1}{\\mu}\\right)$，它将恢复与互相关性联系起来。\n\n设置：\n- 维度为 $d=4$，边长为 $N=128$，因此环境维度为 $n=128^4$。\n- 考虑两种采样策略：\n  1. 均匀随机采样：每个傅里叶频率（行）从 $4$ 维频率网格中均匀且独立地随机选择。\n  2. 变密度采样：在 $4$ 维频率网格上的选择概率是可分离的，并且每个轴上都与一个幂律成比例。具体来说，定义一维频率索引集 $\\mathcal{K}=\\{-\\frac{N}{2},\\ldots,-1,0,1,\\ldots,\\frac{N}{2}-1\\}$。一维权重为 $w(k)=(1+|k|)^{-\\alpha}$，对于 $k \\in \\mathcal{K}$，归一化为概率质量函数 $p_1(k)=w(k)/\\sum_{k'\\in\\mathcal{K}} w(k')$。$4$ 维采样概率为 $p(k_1,k_2,k_3,k_4)=\\prod_{r=1}^{4} p_1(k_r)$。\n\n估计任务：\n- 均匀采样的互相关性由列（归一化的 $m$ 长度复指数向量，限制在所选行上）之间的随机相关性驱动。对于均匀独立采样，不同列差之间的最大绝对归一化内积表现得像 $M$ 个亚高斯随机和（单位模复相位）的最大值，其中 $M$ 是不同列差模式的数量。一个保守且经过充分检验的基于联合界的估计得出了数量级代理\n  $$\\mu_{\\text{unif}} \\approx \\sqrt{\\frac{2 \\log n}{m}},$$\n  使用自然对数和 $M \\approx n$。这捕捉到了一个失效现象，即对于固定的 $m$，相关性会随着 $n$ 的增长而恶化。\n- 对于可分离变密度采样，两个空间索引相差 $4$-向量 $\\Delta=(\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4)$ 的列之间的期望归一化内积等于在偏移处评估的 $p_1$ 的一维离散傅里叶变换在各个维度上的乘积：\n  $$\\mathbb{E}\\left[\\langle a_i, a_j \\rangle\\right] = \\prod_{r=1}^{4} \\phi(\\Delta_r), \\quad \\text{其中} \\quad \\phi(t)=\\sum_{k \\in \\mathcal{K}} p_1(k)\\, e^{-2\\pi i k t / N}.$$\n  因为 $\\phi(0)=1$ 且 $|\\phi(t)|$ 通常随 $|t|$ 减小，所以主要的非零相关性发生在其中一个坐标等于 $1$ 而其他坐标为零的差异上，因此变密度平均相关性的一个原则性代理是 $|\\phi(1)|$。有限样本的随机性增加了与均匀情况相同尺度的波动。因此，一个操作性估计是\n  $$\\mu_{\\text{var}} \\approx |\\phi(1)| + \\sqrt{\\frac{2 \\log n}{m}},$$\n  如有必要，裁剪到 $1$。\n- 根据互相关性 $\\mu$，定义基于相关性的稀疏度阈值\n  $$s_{\\max}(\\mu) = \\left\\lfloor \\frac{1}{2}\\left(1 + \\frac{1}{\\mu}\\right) \\right\\rfloor.$$\n- 对于给定的 $(n,s,m)$ 和采样策略，定义一个无量纲恢复质量分数，即比率\n  $$Q = \\frac{s_{\\max}(\\mu)}{s}.$$\n  $Q \\geq 1$ 的值表示基于相关性的充分保证允许在目标稀疏度 $s$ 下精确恢复；$Q  1$ 的值表示该保证在 $s$ 处失效，揭示了在给定 $m$ 的情况下高维度的失效。\n\n编程任务：\n- 实现上述对 $\\mu_{\\text{unif}}$ 和 $\\mu_{\\text{var}}$ 的估计器，并为提供的测试套件计算 $Q$。始终使用 $d=4$ 和 $N=128$。对于变密度情况，使用 $\\alpha=2$（无量纲）。\n- 测试套件（全部使用 $d=4$, $N=128$, 和 $\\alpha=2$）：\n  1. 展示失效的一般高维情况：$n=128^4$, $s=2 \\cdot 10^4$, $m=5 \\cdot 10^4$。\n  2. 在均匀相关性阈值附近校准的边界条件情况：$s=20$，$m$ 的选择使得 $\\mu_{\\text{unif}}\\approx \\frac{1}{2s-1}$；具体使用 $m=\\left\\lfloor \\frac{2 \\log n}{(1/(2s-1))^2} \\right\\rfloor$。\n  3. 均匀采样的理想情况：$s=10$, $m=5 \\cdot 10^6$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个逗号分隔的列表，列表用方括号括起来，其中每个元素对应一个测试用例，并且本身是一个双元素列表 $[Q_{\\text{unif}}, Q_{\\text{var}}]$，每个浮点数四舍五入到六位小数。例如，格式如下\n  $$[[Q_{\\text{unif,1}},Q_{\\text{var,1}}],[Q_{\\text{unif,2}},Q_{\\text{var,2}}],[Q_{\\text{unif,3}},Q_{\\text{var,3}}]].$$\n不涉及物理单位或角度，所有值必须以指定格式报告为无量纲浮点数。", "solution": "提出的问题是在压缩感知的框架内，量化经典采样在高维情况下的失效，并比较两种不同傅里叶采样策略的稀疏恢复能力。这需要基于一组给定的理论模型和估计器进行多步计算。该问题在科学上植根于压缩感知和稀疏信号恢复的既定原则，在数学上是适定的，并且所有必要的参数和公式都已提供。因此，该问题是有效的。\n\n问题的核心在于信号的环境维度 $n$、测量次数 $m$ 和信号稀疏度 $s$ 之间的张力。由奈奎斯特-香农采样定理支配的经典信号处理要求样本数量与信号总大小 $n$ 同量级。对于每个轴上大小为 $N$ 的 $d$ 维信号，环境维度为 $n=N^d$。对于给定的参数 $d=4$ 和 $N=128$，信号元素总数为 $n=128^4 = 268,435,456$，这是一个天文数字，使得经典采样变得不可行。\n\n压缩感知 (CS) 提供了一条实现亚奈奎斯特采样的路径，它假定如果一个信号 $x \\in \\mathbb{C}^n$ 是 $s$-稀疏的（即在某个基中只有 $s$ 个非零项），那么它可以从 $m$ 次线性测量中完美恢复，其中 $m$ 可以远小于 $n$ ($m \\ll n$)。测量过程由线性系统 $y = Ax$ 建模，其中 $y \\in \\mathbb{C}^m$ 是测量向量，$A \\in \\mathbb{C}^{m \\times n}$ 是测量矩阵。对于这个问题，$A$是通过从 $n \\times n$ 离散傅里叶变换 (DFT) 矩阵中选择 $m$ 行来形成的。\n\n恢复算法（如基追踪或正交匹配追踪）的成功与否关键取决于测量矩阵 $A$ 的性质。一个关键性质是互相关性 $\\mu$，定义为 $A$ 的任意两个不同且归一化的列之间的最大绝对内积。小的相关性是理想的。任何 $s$-稀疏信号能够被精确恢复的一个著名充分条件由 $s  \\frac{1}{2}\\left(1 + \\frac{1}{\\mu}\\right)$ 给出。这个不等式通过 $\\mu$ 将测量矩阵的几何性质与最大可恢复稀疏度水平联系起来。为了量化恢复质量，我们首先将给定矩阵的理论最大可恢复稀疏度定义为 $s_{\\max}(\\mu_A) = \\left\\lfloor \\frac{1}{2}\\left(1 + \\frac{1}{\\mu_A}\\right) \\right\\rfloor$。然后我们定义一个无量纲的恢复质量分数 $Q = \\frac{s_{\\max}}{s}$。分数 $Q \\ge 1$ 表示对于稀疏度为 $s$ 的信号，恢复保证得到满足。\n\n我们现在将使用提供的估计器来分析两种提出的采样策略。固定参数为维度 $d=4$，边长 $N=128$，以及幂律指数 $\\alpha=2$。这给出了环境维度 $n=128^4$ 和其自然对数 $\\log n = 4 \\log 128 = 28 \\log 2 \\approx 19.4081$。\n\n**1. 均匀随机采样**\n在这种策略中，$m$ 个傅里叶频率被均匀且独立地随机选择。得到的测量矩阵的列是伪随机向量。相关性受到随机相关的限制，一个经过充分检验的估计是：\n$$\n\\mu_{\\text{unif}} \\approx \\sqrt{\\frac{2 \\log n}{m}}\n$$\n这个估计揭示了高维问题的一个基本挑战：对于固定的测量次数 $m$，随着环境维度 $n$ 的增长，相关性会恶化（增加），使恢复更加困难。\n\n**2. 变密度采样 (VDS)**\n这种策略非均匀地采样频率，对低频有更高的采样概率。采样概率是可分离的，并遵循幂律。$d$ 维概率 $p(k_1, k_2, k_3, k_4)$ 是一维概率质量函数 $p_1(k_r)$ 的乘积，其中对于一维频率集 $\\mathcal{K}=\\{-\\frac{N}{2}, \\dots, \\frac{N}{2}-1\\}$ 中的 $k$，$p_1(k) \\propto (1+|k|)^{-\\alpha}$。这种非均匀性在测量矩阵的列之间引入了系统性的相关性。提供的互相关性代理指标为：\n$$\n\\mu_{\\text{var}} \\approx |\\phi(1)| + \\sqrt{\\frac{2 \\log n}{m}}\n$$\n其中附加项 $|\\phi(1)|$ 代表了这种系统性相关。它源自一维采样概率分布的离散傅里叶变换，$\\phi(t)=\\sum_{k \\in \\mathcal{K}} p_1(k)\\, e^{-2\\pi i k t / N}$。项 $\\sqrt{\\frac{2 \\log n}{m}}$ 代表了与均匀情况相同的随机波动。对于给定的参数 $N=128$ 和 $\\alpha=2$， $|\\phi(1)|$ 的值计算如下\n$$\n|\\phi(1)| = \\left| \\frac{\\sum_{k=-64}^{63} (1+|k|)^{-2} e^{-2\\pi i k / 128}}{\\sum_{k'=-64}^{63} (1+|k'|)^{-2}} \\right| \\approx 0.957597\n$$\n在这个模型中，预计VDS的相关性会比均匀采样更高，因为 $|\\phi(1)| > 0$。这表明，当用对最坏情况下的列相关性敏感的互相关性标准来判断时，其恢复性能可能较差。这个结果凸显了虽然VDS对于在傅里叶域中可压缩的信号（例如自然图像）非常有效，但在空间域的严格稀疏模型下，以互相关性标准衡量时可能不是最优的。\n\n我们现在继续为每个测试用例计算质量分数 $Q$。\n\n**测试用例 1: 高维失效**\n给定：$s = 20,000$, $m = 50,000$。\n- 均匀采样：$\\mu_{\\text{unif}} \\approx \\sqrt{\\frac{2 \\log(128^4)}{50,000}} \\approx 0.027862$。\n  $s_{\\max}(\\mu_{\\text{unif}}) = \\lfloor \\frac{1}{2}(1 + 1/0.027862) \\rfloor = 18$。\n  $Q_{\\text{unif}} = 18 / 20,000 = 0.0009$。\n- VDS：$\\mu_{\\text{var}} \\approx 0.957597 + 0.027862 \\approx 0.985459$。\n  $s_{\\max}(\\mu_{\\text{var}}) = \\lfloor \\frac{1}{2}(1 + 1/0.985459) \\rfloor = 1$。\n  $Q_{\\text{var}} = 1 / 20,000 = 0.00005$。\n两个分数都远低于 $1$，说明在如此高的维度下，当 $m$ 对于给定的稀疏度 $s$ 来说太小时，恢复保证会失败。\n\n**测试用例 2: 边界条件**\n给定：$s = 20$。测量次数 $m$ 的选择使均匀采样处于理论恢复阈值：$m = \\lfloor (2 \\log n)(2s-1)^2 \\rfloor = \\lfloor (2\\log(128^4))(39)^2 \\rfloor = 59,039$。\n- 均匀采样：$\\mu_{\\text{unif}} \\approx \\sqrt{\\frac{2 \\log(128^4)}{59,039}} \\approx 0.025641 \\approx 1/39$。\n  $s_{\\max}(\\mu_{\\text{unif}}) = \\lfloor \\frac{1}{2}(1 + 1/0.025641) \\rfloor = \\lfloor \\frac{1}{2}(1+39) \\rfloor = 20$。\n  $Q_{\\text{unif}} = 20 / 20 = 1.0$。\n- VDS：$\\mu_{\\text{var}} \\approx 0.957597 + 0.025641 \\approx 0.983238$。\n  $s_{\\max}(\\mu_{\\text{var}}) = \\lfloor \\frac{1}{2}(1 + 1/0.983238) \\rfloor = 1$。\n  $Q_{\\text{var}} = 1 / 20 = 0.05$。\n正如设计的那样，均匀采样正好在恢复阈值上（$Q=1$），而VDS则显著失败。\n\n**测试用例 3: 理想情况**\n给定：$s = 10$, $m = 5,000,000$。\n- 均匀采样：$\\mu_{\\text{unif}} \\approx \\sqrt{\\frac{2 \\log(128^4)}{5,000,000}} \\approx 0.002786$。\n  $s_{\\max}(\\mu_{\\text{unif}}) = \\lfloor \\frac{1}{2}(1 + 1/0.002786) \\rfloor = 179$。\n  $Q_{\\text{unif}} = 179 / 10 = 17.9$。\n- VDS：$\\mu_{\\text{var}} \\approx 0.957597 + 0.002786 \\approx 0.960383$。\n  $s_{\\max}(\\mu_{\\text{var}}) = \\lfloor \\frac{1}{2}(1 + 1/0.960383) \\rfloor = 1$。\n  $Q_{\\text{var}} = 1 / 10 = 0.1$。\n根据这个模型，当测量次数很大时，均匀采样策略提供了强大的保证（$Q \\gg 1$），而VDS策略的性能由于其固有的高相关性而仍然很差。\n最终计算出的值将在下面的程序中汇总。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the estimators for sparse recovery quality scores as defined\n    in the problem statement and computes them for the given test suite.\n    \"\"\"\n\n    #\n    # Define fixed parameters from the problem statement.\n    #\n    d = 4                 # Dimension\n    N = 128               # Side length\n    alpha = 2.0           # Power-law exponent for VDS\n    n = float(N**d)       # Ambient dimension\n    log_n = np.log(n)     # Natural logarithm of n\n\n    #\n    # Pre-compute the constant term |phi(1)| for variable-density sampling.\n    # phi(t) is the characteristic function of the 1D sampling probability distribution.\n    #\n    \n    # 1D frequency index set K = {-N/2, ..., N/2-1}\n    k_values = np.arange(-N / 2, N / 2, dtype=np.float64)\n    \n    # 1D weights w(k) = (1+|k|)^-alpha\n    weights = (1 + np.abs(k_values))**(-alpha)\n    \n    # 1D probability mass function p1(k) = w(k) / sum(w)\n    sum_weights = np.sum(weights)\n    p1_k = weights / sum_weights\n    \n    # phi(1) = sum_{k in K} p1(k) * exp(-2*pi*i*k/N)\n    phi1 = np.sum(p1_k * np.exp(-2j * np.pi * k_values / N))\n    phi1_abs = np.abs(phi1)\n\n    #\n    # Define the test suite based on the problem statement.\n    #\n    s_case2 = 20.0\n    # For case 2, m is calibrated to meet the uniform coherence threshold.\n    m_case2 = np.floor(2 * log_n * (2 * s_case2 - 1)**2)\n    \n    test_cases = [\n        (2.0e4, 5.0e4),      # Case 1: General high-dimensional breakdown\n        (s_case2, m_case2),  # Case 2: Boundary condition\n        (10.0, 5.0e6)        # Case 3: Happy-path\n    ]\n\n    #\n    # Define helper functions for the core calculations.\n    #\n    def calculate_s_max(mu):\n        \"\"\"Computes the coherence-based sparsity threshold.\"\"\"\n        if mu  1e-12: # mu is non-negative. Avoid division by zero/small numbers.\n            return float('inf')\n        return np.floor(0.5 * (1.0 + 1.0 / mu))\n\n    def calculate_Q(s_max_val, s_val):\n        \"\"\"Computes the dimensionless recovery-quality score.\"\"\"\n        return s_max_val / s_val\n\n    #\n    # Process each test case and store the results.\n    #\n    results = []\n    for s, m in test_cases:\n        # Common random fluctuation term in coherence estimates\n        rand_term = np.sqrt(2 * log_n / m)\n\n        # 1. Uniform random sampling calculations\n        mu_unif = rand_term\n        s_max_unif = calculate_s_max(mu_unif)\n        Q_unif = calculate_Q(s_max_unif, s)\n\n        # 2. Variable-density sampling calculations\n        mu_var_est = phi1_abs + rand_term\n        mu_var = min(mu_var_est, 1.0) # Coherence is clipped at 1\n        s_max_var = calculate_s_max(mu_var)\n        Q_var = calculate_Q(s_max_var, s)\n\n        # Append the pair of rounded Q-scores to the results list\n        results.append([round(Q_unif, 6), round(Q_var, 6)])\n\n    #\n    # Final print statement in the exact required format.\n    # The output is a list of lists, formatted as a string.\n    #\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3434286"}]}