{"hands_on_practices": [{"introduction": "要真正理解迭代收缩阈值算法（ISTA），最有效的方法就是亲自动手计算。这个练习将引导您完成一次完整的 ISTA 迭代。通过这个具体算例，您将掌握计算梯度、根据 Lipschitz 常数确定步长以及应用软阈值算子的核心步骤，为后续更深入的收敛性分析打下坚实的基础。[@problem_id:3438561]", "problem": "考虑压缩感知和稀疏优化中的复合优化问题，旨在最小化函数 $F(x) = f(x) + \\lambda \\|x\\|_{1}$，其中 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$，且 $\\|\\cdot\\|_{1}$ 和 $\\|\\cdot\\|_{2}$ 分别表示 $\\ell_{1}$范数和欧几里得范数。迭代软阈值算法 (ISTA) 由近端梯度迭代定义：$x^{k+1} = S_{\\alpha \\lambda}\\!\\left(x^{k} - \\alpha \\nabla f(x^{k})\\right)$，其中 $S_{\\tau}$ 是阈值为 $\\tau$ 的软阈值算子，$\\alpha$ 是一个常数步长，其选择需满足基于 $\\nabla f$ 的 Lipschitz 连续性的理论收敛保证。\n\n从以下基本依据开始：\n- 最小二乘函数 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 的梯度由 $\\nabla f(x) = A^{\\top}(A x - b)$ 给出。\n- 梯度 $\\nabla f$ 是 Lipschitz 连续的，其 Lipschitz 常数为 $L = \\|A^{\\top} A\\|_{2}$，即 $A^{\\top} A$ 的谱范数（最大特征值）。\n- 软阈值算子 $S_{\\tau}$ 逐分量定义为 $S_{\\tau}(z)_{i} = \\operatorname{sign}(z_{i})\\max\\{|z_{i}| - \\tau, 0\\}$。\n\n设数据为\n$$\nA = \\begin{pmatrix}\n2  0 \\\\\n0  3 \\\\\n0  0\n\\end{pmatrix}, \\quad\nb = \\begin{pmatrix}\n1 \\\\\n-6 \\\\\n0\n\\end{pmatrix}, \\quad\n\\lambda = 1, \\quad\nx^{0} = \\begin{pmatrix}\n\\frac{1}{3} \\\\\n-\\frac{1}{2}\n\\end{pmatrix}.\n$$\n选择常数步长 $\\alpha = \\frac{1}{L}$，其中 $L$ 是由 $A$ 确定的 $\\nabla f$ 的 Lipschitz 常数。\n\n显式计算一次 ISTA 迭代，\n$$\nx^{1} = S_{\\alpha \\lambda}\\!\\left(x^{0} - \\alpha A^{\\top}(A x^{0} - b)\\right),\n$$\n并将结果 $x^{1}$ 以单个行向量的形式给出。无需四舍五入；请提供精确的有理数值。", "solution": "该问题是有效的，因为它是稀疏优化领域中一个定义明确的数学练习，提供了所有必要的数据和定义。它具有科学依据、内部一致且客观。\n\n目标是计算迭代软阈值算法 (ISTA) 的一次迭代以求得 $x^{1}$，从给定的初始点 $x^{0}$ 开始。ISTA 的更新规则由下式给出：\n$$\nx^{k+1} = S_{\\alpha \\lambda}\\!\\left(x^{k} - \\alpha \\nabla f(x^{k})\\right)\n$$\n对于我们的特定问题，我们需要使用 $k=0$ 来计算 $x^{1}$：\n$$\nx^{1} = S_{\\alpha \\lambda}\\!\\left(x^{0} - \\alpha \\nabla f(x^{0})\\right)\n$$\n函数 $f(x)$ 是最小二乘项 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$，其梯度为 $\\nabla f(x) = A^{\\top}(A x - b)$。\n\n首先，我们必须确定步长 $\\alpha$。问题指明 $\\alpha = \\frac{1}{L}$，其中 $L$ 是 $\\nabla f(x)$ 的 Lipschitz 常数。该 Lipschitz 常数由 $A^{\\top} A$ 的谱范数给出，记为 $L = \\|A^{\\top} A\\|_{2}$。\n\n给定的矩阵为 $A = \\begin{pmatrix} 2  0 \\\\ 0  3 \\\\ 0  0 \\end{pmatrix}$。其转置为 $A^{\\top} = \\begin{pmatrix} 2  0  0 \\\\ 0  3  0 \\end{pmatrix}$。\n我们计算乘积 $A^{\\top} A$：\n$$\nA^{\\top} A = \\begin{pmatrix} 2  0  0 \\\\ 0  3  0 \\end{pmatrix} \\begin{pmatrix} 2  0 \\\\ 0  3 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 4  0 \\\\ 0  9 \\end{pmatrix}\n$$\n对称（或在此例中为对角）矩阵的谱范数是其最大特征值的绝对值。对角矩阵 $\\begin{pmatrix} 4  0 \\\\ 0  9 \\end{pmatrix}$ 的特征值是其对角线元素，即 $4$ 和 $9$。\n因此，Lipschitz 常数为 $L = \\max\\{4, 9\\} = 9$。\n步长为 $\\alpha = \\frac{1}{L} = \\frac{1}{9}$。\n\n接下来，我们计算函数 $f$ 在初始点 $x^{0} = \\begin{pmatrix} \\frac{1}{3} \\\\ -\\frac{1}{2} \\end{pmatrix}$ 处的梯度。\n首先，计算 $A x^{0} - b$：\n$$\nA x^{0} = \\begin{pmatrix} 2  0 \\\\ 0  3 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{3} \\\\ -\\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 2(\\frac{1}{3}) \\\\ 3(-\\frac{1}{2}) \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{3}{2} \\\\ 0 \\end{pmatrix}\n$$\n由于 $b = \\begin{pmatrix} 1 \\\\ -6 \\\\ 0 \\end{pmatrix}$，我们有：\n$$\nA x^{0} - b = \\begin{pmatrix} \\frac{2}{3} \\\\ -\\frac{3}{2} \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ -6 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{3} - 1 \\\\ -\\frac{3}{2} + 6 \\\\ 0 - 0 \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{3} \\\\ \\frac{9}{2} \\\\ 0 \\end{pmatrix}\n$$\n现在，我们计算梯度 $\\nabla f(x^{0}) = A^{\\top}(A x^{0} - b)$：\n$$\n\\nabla f(x^{0}) = \\begin{pmatrix} 2  0  0 \\\\ 0  3  0 \\end{pmatrix} \\begin{pmatrix} -\\frac{1}{3} \\\\ \\frac{9}{2} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2(-\\frac{1}{3}) \\\\ 3(\\frac{9}{2}) \\end{pmatrix} = \\begin{pmatrix} -\\frac{2}{3} \\\\ \\frac{27}{2} \\end{pmatrix}\n$$\n下一步是计算软阈值算子的参数，我们将其记为 $z$：\n$$\nz = x^{0} - \\alpha \\nabla f(x^{0}) = \\begin{pmatrix} \\frac{1}{3} \\\\ -\\frac{1}{2} \\end{pmatrix} - \\frac{1}{9} \\begin{pmatrix} -\\frac{2}{3} \\\\ \\frac{27}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3} \\\\ -\\frac{1}{2} \\end{pmatrix} - \\begin{pmatrix} -\\frac{2}{27} \\\\ \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3} + \\frac{2}{27} \\\\ -\\frac{1}{2} - \\frac{3}{2} \\end{pmatrix}\n$$\n$$\nz = \\begin{pmatrix} \\frac{9}{27} + \\frac{2}{27} \\\\ -\\frac{4}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{11}{27} \\\\ -2 \\end{pmatrix}\n$$\n最后，我们应用软阈值算子 $S_{\\tau}(z)$，其阈值为 $\\tau = \\alpha \\lambda$。给定 $\\lambda = 1$ 和 $\\alpha = \\frac{1}{9}$，阈值为 $\\tau = \\frac{1}{9} \\cdot 1 = \\frac{1}{9}$。\n软阈值算子是逐分量应用的：$S_{\\tau}(z)_{i} = \\operatorname{sign}(z_{i})\\max\\{|z_{i}| - \\tau, 0\\}$。\n\n对于第一个分量，$z_1 = \\frac{11}{27}$：\n$$\nx^{1}_{1} = S_{1/9}\\left(\\frac{11}{27}\\right) = \\operatorname{sign}\\left(\\frac{11}{27}\\right) \\max\\left\\{\\left|\\frac{11}{27}\\right| - \\frac{1}{9}, 0\\right\\}\n$$\n因为 $\\frac{11}{27} > \\frac{1}{9}$（即 $\\frac{11}{27} > \\frac{3}{27}$），所以运算为：\n$$\nx^{1}_{1} = 1 \\cdot \\left(\\frac{11}{27} - \\frac{1}{9}\\right) = \\frac{11}{27} - \\frac{3}{27} = \\frac{8}{27}\n$$\n对于第二个分量，$z_2 = -2$：\n$$\nx^{1}_{2} = S_{1/9}(-2) = \\operatorname{sign}(-2) \\max\\left\\{|-2| - \\frac{1}{9}, 0\\right\\}\n$$\n因为 $|-2|=2 > \\frac{1}{9}$，所以运算为：\n$$\nx^{1}_{2} = -1 \\cdot \\left(2 - \\frac{1}{9}\\right) = -\\left(\\frac{18}{9} - \\frac{1}{9}\\right) = -\\frac{17}{9}\n$$\n因此，一次 ISTA 迭代的结果是向量 $x^{1} = \\begin{pmatrix} \\frac{8}{27} \\\\ -\\frac{17}{9} \\end{pmatrix}$。问题要求以单个行向量的形式给出答案。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{8}{27}  -\\frac{17}{9} \\end{pmatrix}}\n$$", "id": "3438561"}, {"introduction": "理论上，ISTA 能够收敛到稀疏解，但其收敛速度如何？这个练习探讨了一个关键的理论条件——严格互补性（strict complementarity）——及其对收敛行为的影响。您将构造一个特例，其中严格互补性失效，并推导出迭代序列的精确表达式，从而直观地理解为何在这种情况下 ISTA 无法在有限步内识别出真正的稀疏支撑集。[@problem_id:3438522]", "problem": "考虑一维的最小绝对值收敛和选择算子 (LASSO) 问题\n$$\\min_{x \\in \\mathbb{R}} \\; F(x) := \\frac{1}{2}\\,(x - b)^{2} + \\lambda\\,|x|,$$\n其中 $b \\in \\mathbb{R}$ 是一个给定的数据点，$\\lambda > 0$ 是正则化参数。步长为 $\\tau \\in (0,1)$ 的迭代收缩阈值算法 (ISTA, Iterative Shrinkage-Thresholding Algorithm) 生成迭代序列\n$$x^{k+1} \\in \\operatorname{prox}_{\\tau \\lambda |\\cdot|}\\big(x^{k} - \\tau \\nabla f(x^{k})\\big), \\quad f(x) := \\frac{1}{2}\\,(x - b)^{2},$$\n其中，缩放后的绝对值函数的近端算子是软阈值映射\n$$S_{\\alpha}(z) := \\operatorname{sign}(z)\\,\\max\\{|z| - \\alpha, 0\\}.$$\n要求您在严格互补性不成立时，为 ISTA 算法的有限时间支撑集辨识构造一个反例。请按以下步骤进行。\n\n1. 将数据特化到 $b = \\lambda$ 的情形，并证明唯一最小化子是 $x^{\\star} = 0$。验证在 $x^{\\star}$ 处的严格互补性不成立，即 $|\\nabla f(x^{\\star})| = \\lambda$。\n2. 针对此一维实例，用 $\\tau$、$\\lambda$、$b$ 和 $x^{k}$ 显式地写出 ISTA 的更新规则，并在 $b = \\lambda$ 的特化条件下将其化简。\n3. 假设初始点 $x^{0} > 0$。推导 ISTA 迭代点 $x^{k}$ 作为 $k$、$\\tau$ 和 $x^{0}$ 的函数的精确闭式表达式。仅使用上述定义和凸函数的标准最优性条件。\n\n您的最终答案必须是步骤3中推导出的 $x^{k}$ 的闭式解析表达式。无需四舍五入，不涉及单位。", "solution": "该问题要求针对一个特定的一维 LASSO 问题，推导迭代收缩阈值算法 (ISTA) 迭代点的闭式表达式。该问题是在严格互补性不成立时，有限时间支撑集辨识的一个反例。我们将遵循指定的三个步骤进行。\n\nLASSO 问题是最小化 $F(x) := \\frac{1}{2}(x - b)^{2} + \\lambda|x|$，其中 $x \\in \\mathbb{R}$，$b \\in \\mathbb{R}$ 且 $\\lambda > 0$。函数 $F(x)$ 是一个严格凸函数 $f(x) = \\frac{1}{2}(x-b)^2$ 和一个凸函数 $g(x) = \\lambda|x|$ 的和。因此，$F(x)$ 是严格凸的，并有唯一的最小化子 $x^{\\star}$。\n\n**步骤 1：分析 $b = \\lambda$ 时的最小化子和严格互补性**\n\n唯一最小化子 $x^{\\star}$ 由一阶最优性条件 $0 \\in \\partial F(x^{\\star})$ 刻画，其中 $\\partial F(x)$ 是 $F(x)$ 的次微分。\n次微分由 $\\partial F(x) = \\nabla f(x) + \\partial g(x) = (x - b) + \\lambda \\partial|x|$ 给出。\n绝对值函数的次微分是：\n$$\n\\partial|x| =\n\\begin{cases}\n    \\{1\\}  & \\text{if } x > 0 \\\\\n    [-1, 1] & \\text{if } x = 0 \\\\\n    \\{-1\\}  & \\text{if } x  0\n\\end{cases}\n$$\n最优性条件 $0 \\in (x^{\\star} - b) + \\lambda \\partial|x^{\\star}|$ 可以重写为 $b - x^{\\star} \\in \\lambda \\partial|x^{\\star}|$。我们分析关于 $x^{\\star}$ 的三种情况：\n1. 如果 $x^{\\star}  0$：条件变为 $b - x^{\\star} = \\lambda$，这意味着 $x^{\\star} = b - \\lambda$。这种情况仅在 $x^{\\star}  0$ 时自洽，即 $b  \\lambda$。\n2. 如果 $x^{\\star}  0$：条件变为 $b - x^{\\star} = -\\lambda$，这意味着 $x^{\\star} = b + \\lambda$。这种情况仅在 $x^{\\star}  0$ 时自洽，即 $b  -\\lambda$。\n3. 如果 $x^{\\star} = 0$：条件变为 $b - 0 \\in \\lambda[-1, 1]$，这等价于 $|b| \\le \\lambda$。\n\n问题指定了 $b = \\lambda$ 的情形。由于 $\\lambda  0$，我们有 $|b| = |\\lambda| = \\lambda$，这满足条件 $|b| \\le \\lambda$。因此，我们属于第三种情况，唯一最小化子是 $x^{\\star} = 0$。\n\n接下来，我们验证严格互补性的不成立。对于一个解 $x^\\star$，如果其分量 $x^\\star_i=0$，则严格互补性成立的条件是，光滑部分梯度对应的分量 $\\nabla_i f(x^\\star)$ 严格位于非光滑部分在 $x^\\star$ 处次微分的内部。在我们的一维情况中，$x^\\star=0$，该条件为 $|\\nabla f(x^{\\star})|  \\lambda$。\n光滑部分的梯度是 $\\nabla f(x) = x - b$。\n在最小化子 $x^{\\star} = 0$ 处，梯度为 $\\nabla f(0) = 0 - b = -b$。\n在 $b = \\lambda$ 的特化条件下，我们有 $\\nabla f(x^{\\star}) = -\\lambda$。\n其大小为 $|\\nabla f(x^{\\star})| = |-\\lambda| = \\lambda$。\n严格互补性条件要求 $\\lambda  \\lambda$，这是不成立的。我们得到 $|\\nabla f(x^{\\star})| = \\lambda$，这正是严格互补性不成立的边界情况。\n\n**步骤 2：$b = \\lambda$ 时的 ISTA 更新规则**\n\n一般的 ISTA 更新规则由下式给出\n$$x^{k+1} = \\operatorname{prox}_{\\tau \\lambda |\\cdot|}\\left(x^{k} - \\tau \\nabla f(x^{k})\\right)$$\n其中 $\\tau \\in (0,1)$ 是步长。由 $\\tau$ 缩放的 $g(x) = \\lambda|x|$ 的近端算子是软阈值算子 $S_{\\tau\\lambda}(z)$。\n算子的自变量是 $x^{k} - \\tau \\nabla f(x^{k}) = x^{k} - \\tau(x^{k}-b) = (1-\\tau)x^{k} + \\tau b$。\n所以，更新为 $x^{k+1} = S_{\\tau\\lambda}((1-\\tau)x^{k} + \\tau b)$。\n特化到 $b=\\lambda$ 的情况，更新规则变为：\n$$x^{k+1} = S_{\\tau\\lambda}((1-\\tau)x^{k} + \\tau\\lambda)$$\n\n**步骤 3：迭代点 $x^{k}$ 的闭式表达式**\n\n我们被要求在假设初始点 $x^{0}  0$ 的情况下推导 $x^{k}$ 的表达式。我们使用步骤2中的递推关系。\n软阈值算子定义为 $S_{\\alpha}(z) = \\operatorname{sign}(z)\\max\\{|z| - \\alpha, 0\\}$。\n我们通过归纳法进行证明。基础情形是 $x^{0}  0$。\n我们假设对于某个 $k \\ge 0$，有 $x^{k}  0$。我们分析下一个迭代点 $x^{k+1}$。\n软阈值函数的自变量是 $z^{k} = (1-\\tau)x^{k} + \\tau\\lambda$。\n给定 $\\tau \\in (0,1)$，我们有 $1-\\tau  0$。同时，$\\lambda  0$。根据我们的归纳假设，$x^{k}  0$。\n因此，$z^{k}$ 表达式中的每一项都是正的，这意味着 $z^{k}  0$。\n更具体地说，由于 $(1-\\tau)x^k  0$，我们有 $z^k = (1-\\tau)x^k + \\tau\\lambda  \\tau\\lambda$。\n对于一个正自变量 $z  0$，软阈值算子简化为 $S_{\\alpha}(z) = \\max\\{z - \\alpha, 0\\}$。\n在我们的情况中，$\\alpha = \\tau\\lambda$ 且自变量是 $z^k$。\n$$x^{k+1} = \\max\\{z^{k} - \\tau\\lambda, 0\\}$$\n代入 $z^k$ 的表达式：\n$$x^{k+1} = \\max\\{( (1-\\tau)x^{k} + \\tau\\lambda ) - \\tau\\lambda, 0\\} = \\max\\{(1-\\tau)x^{k}, 0\\}$$\n由于 $1-\\tau  0$ 且我们假设了 $x^{k}  0$，项 $(1-\\tau)x^{k}$ 是严格为正的。\n因此，最大值就是该项本身：\n$$x^{k+1} = (1-\\tau)x^{k}$$\n这证实了我们的归纳步骤：如果 $x^{k}  0$，那么 $x^{k+1}  0$。由于我们从 $x^{0}  0$ 开始，可得对于所有 $k \\ge 0$ 都有 $x^{k}  0$。\n递推关系 $x^{k+1} = (1-\\tau)x^{k}$ 是一个简单的等比数列。我们可以将其展开以找到闭式解：\n$x^{1} = (1-\\tau)x^{0}$\n$x^{2} = (1-\\tau)x^{1} = (1-\\tau)^2 x^{0}$\n以此类推。对于任何整数 $k \\ge 0$，迭代点由下式给出：\n$$x^{k} = (1-\\tau)^{k} x^{0}$$\n这就是所求的闭式表达式。由于 $\\tau \\in (0,1)$，我们有 $0  1-\\tau  1$，因此当 $k \\to \\infty$ 时 $x^k \\to 0 = x^\\star$。然而，对于任何有限的 $k$，$x^k$ 永远不会精确等于 $0$，这表明解的支撑集没有在有限时间内被辨识出来。", "answer": "$$\\boxed{(1-\\tau)^{k} x^{0}}$$", "id": "3438522"}, {"introduction": "与上一个练习中严格互补性失效导致收敛缓慢的情形相反，当该条件满足时，ISTA 的收敛行为会发生戏剧性的改变。本练习将通过一个精心设计的例子，展示当算法在有限步内成功识别出解的稀疏支撑集后，其收敛速度会从次线性加速为局部线性。通过计算这个局部线性收敛率，您将深刻体会到问题结构对算法实际性能的决定性影响。[@problem_id:3438565]", "problem": "考虑将迭代收缩阈值算法 (ISTA) 应用于压缩感知中的稀疏优化问题，该问题最小化目标函数\n$$\nF(x) \\triangleq g(x) + h(x) = \\frac{1}{2}\\|A x - y\\|_{2}^{2} + \\lambda \\|x\\|_{1},\n$$\n其中 $A \\in \\mathbb{R}^{3 \\times 3}$，$y \\in \\mathbb{R}^{3}$，且 $\\lambda  0$。光滑部分为 $g(x) = \\frac{1}{2}\\|A x - y\\|_{2}^{2}$，其梯度为 $\\nabla g(x) = A^{\\top}(A x - y)$，该梯度是 Lipschitz 连续的，Lipschitz 常数为 $L = \\|A^{\\top}A\\|_{2}$。非光滑部分为 $h(x) = \\lambda \\|x\\|_{1}$，其近端算子是软阈值算子。迭代收缩阈值算法 (ISTA) 的迭代过程为\n$$\nx^{k+1} = \\operatorname{prox}_{t_{k} h}\\big(x^{k} - t_{k} \\nabla g(x^{k})\\big),\n$$\n其中 $t_{k}  0$ 通过标准的回溯法选择，以确保基于 $\\nabla g$ 的局部 Lipschitz 连续性实现充分下降。在这种复合优化中，一个已知的现象是在严格互补性条件下，活动流形（支撑集和符号）的有限次识别，之后迭代在已识别的流形上线性演化。\n\n构建以下显式实例。令\n$$\nA = \\begin{pmatrix}\n2  0  0\\\\\n0  2  0\\\\\n0  0  100\n\\end{pmatrix}, \\qquad y = \\begin{pmatrix} 2 \\\\ 2 \\\\ 0.005 \\end{pmatrix}, \\qquad \\lambda = 1.\n$$\n这一选择在科学上是现实的且内部一致：与前两个变量对应的列被适度缩放且相互正交，而第三列非常大，产生了一个大的全局 Lipschitz 常数。考虑带有回溯的 ISTA，在识别后，它使用与已识别流形相关联的局部 Lipschitz 常数。\n\n任务：\n- 仅使用凸性、近端算子和一阶最优性（Karush–Kuhn–Tucker 条件）的基本定义，证明唯一的极小值点 $x^{\\star}$ 的支撑集为 $S = \\{1,2\\}$，其元素严格为正，且 $x_{3}^{\\star} = 0$。\n- 在非活动坐标 $3$ 上验证严格互补性。\n- 从基本原理出发论证为什么在这些条件下，ISTA 可以在有限次迭代内识别出支撑集 $S$ 和符号。\n- 一旦识别发生，刻画 ISTA 限制在 $S$ 上的局部线性迭代，并用 $A_{S}^{\\top}A_{S}$ 的谱以及回溯法在流形上收敛到的可接受步长 $t$ 来表示其速率常数。\n- 对于这个实例，计算识别后的局部线性收敛速率常数 $\\rho_{\\mathrm{local}}$ 的精确数值。以单个实数形式给出你的答案。无需四舍五入。", "solution": "该问题要求对应用于 LASSO 型目标函数的迭代收缩阈值算法 (ISTA) 的一个特定实例进行多部分分析。验证过程确认了该问题是适定的、有科学依据的，并提供了所有必要信息。我们按顺序解决每个任务来进行解答。\n\n要最小化的目标函数是 $F(x) = g(x) + h(x)$，其中 $g(x) = \\frac{1}{2}\\|Ax - y\\|_{2}^{2}$ 且 $h(x) = \\lambda \\|x\\|_{1}$。给定的参数值为 $\\lambda = 1$ 以及\n$$\nA = \\begin{pmatrix}\n2  0  0\\\\\n0  2  0\\\\\n0  0  100\n\\end{pmatrix}, \\qquad y = \\begin{pmatrix} 2 \\\\ 2 \\\\ 0.005 \\end{pmatrix}.\n$$\n光滑部分 $g(x)$ 的梯度是 $\\nabla g(x) = A^{\\top}(Ax - y)$。由于 $A$ 是一个对角矩阵，$A^{\\top} = A$，因此 $\\nabla g(x) = A^2 x - Ay$。\n$$\nA^2 = \\begin{pmatrix}\n4  0  0\\\\\n0  4  0\\\\\n0  0  10000\n\\end{pmatrix}, \\qquad Ay = \\begin{pmatrix}\n4 \\\\\n4 \\\\\n0.5\n\\end{pmatrix}.\n$$\n梯度的分量是：\n$(\\nabla g(x))_1 = 4x_1 - 4$\n$(\\nabla g(x))_2 = 4x_2 - 4$\n$(\\nabla g(x))_3 = 10000x_3 - 0.5$\n\n### 任务 1：求唯一极小值点 $x^{\\star}$\n\n函数 $F(x)$ 是严格凸的，因为 $g(x)$ 是严格凸的（$A$ 是可逆的）且 $h(x)$ 是凸的。因此，存在唯一的极小值点 $x^{\\star}$。一个点 $x^{\\star}$ 成为极小值点的一阶最优性条件（或 Karush-Kuhn-Tucker 条件）表明 $0 \\in \\nabla g(x^{\\star}) + \\partial h(x^{\\star})$，其中 $\\partial h(x^{\\star})$ 是 $h(x)$ 在 $x^{\\star}$ 处的次微分。这等价于 $-\\nabla g(x^{\\star}) \\in \\partial (\\lambda \\|x\\|_1)|_{x=x^{\\star}}$。\n\n这个条件可以按分量表示为：\n1.  如果 $x_i^{\\star} \\ne 0$，则 $(\\nabla g(x^{\\star}))_i + \\lambda \\operatorname{sign}(x_i^{\\star}) = 0$。\n2.  如果 $x_i^{\\star} = 0$，则 $|(\\nabla g(x^{\\star}))_i| \\le \\lambda$。\n\n我们假设解的支撑集为 $S = \\{1,2\\}$，即 $x_1^{\\star} \\neq 0$，$x_2^{\\star} \\neq 0$，且 $x_3^{\\star} = 0$。我们进一步假设 $x_1^{\\star}  0$ 且 $x_2^{\\star}  0$。\n\n对于 $i=1$：我们应用条件 (1)，其中 $\\operatorname{sign}(x_1^{\\star}) = 1$ 且 $\\lambda=1$。\n$(\\nabla g(x^{\\star}))_1 + 1 = 0 \\implies (4x_1^{\\star} - 4) + 1 = 0 \\implies 4x_1^{\\star} = 3 \\implies x_1^{\\star} = \\frac{3}{4}$。\n由于 $x_1^{\\star} = \\frac{3}{4}  0$，我们的符号假设是一致的。\n\n对于 $i=2$：类似地，我们应用条件 (1)，其中 $\\operatorname{sign}(x_2^{\\star}) = 1$。\n$(\\nabla g(x^{\\star}))_2 + 1 = 0 \\implies (4x_2^{\\star} - 4) + 1 = 0 \\implies 4x_2^{\\star} = 3 \\implies x_2^{\\star} = \\frac{3}{4}$。\n由于 $x_2^{\\star} = \\frac{3}{4}  0$，这个符号假设也是一致的。\n\n对于 $i=3$：我们使用条件 (2) 来检验我们的假设 $x_3^{\\star} = 0$。我们必须检查是否 $|(\\nabla g(x^{\\star}))_3| \\le \\lambda = 1$。\n我们将 $x_3^{\\star}=0$ 代入梯度分量的表达式中：\n$(\\nabla g(x^{\\star}))_3 = 10000x_3^{\\star} - 0.5 = 10000(0) - 0.5 = -0.5$。\n我们检查条件：$|-0.5| = 0.5 \\le 1$。该条件成立。\n\n候选解 $x^{\\star} = (\\frac{3}{4}, \\frac{3}{4}, 0)^{\\top}$ 满足所有条件。支撑集确实是 $S=\\{1,2\\}$，支撑集上的元素严格为正，且 $x_3^{\\star} = 0$。由于严格凸性，这是唯一的极小值点。\n\n### 任务 2：验证严格互补性\n\n对于一个非活动坐标 $j$（其中 $x_j^{\\star}=0$），严格互补性要求该坐标的次梯度条件以严格不等式成立。对于 $j=3$，我们必须验证 $|(\\nabla g(x^{\\star}))_3|  \\lambda$。\n从上一步我们计算出 $(\\nabla g(x^{\\star}))_3 = -0.5$，而已知 $\\lambda = 1$。\n条件是 $|-0.5|  1$，化简为 $0.5  1$。这是成立的。\n因此，在非活动坐标 $j=3$ 上，严格互补性成立。\n\n### 任务 3：活动流形的有限次识别\n\nISTA 迭代由 $x^{k+1} = \\operatorname{prox}_{t_k h}(x^{k} - t_k \\nabla g(x^{k}))$ 给出。对于 $h(x) = \\lambda \\|x\\|_1$ 的近端算子是分量形式的软阈值函数，$S_{t_k\\lambda}(z)_i = \\operatorname{sign}(z_i)\\max(|z_i|-t_k\\lambda, 0)$。一个坐标 $x_i^{k+1}$ 被设为零当且仅当 $|(x^k - t_k \\nabla g(x^k))_i| \\le t_k\\lambda$。\n\n由于 ISTA 是一个收敛算法，当 $k \\to \\infty$ 时，$x^k \\to x^{\\star}$。我们还假设在回溯线搜索中使用的步长 $t_k$ 收敛到一个正值 $t  0$。令 $z^k = x^k - t_k \\nabla g(x^k)$。那么 $z^k \\to z^{\\star} = x^{\\star} - t \\nabla g(x^{\\star})$。\n\n让我们分析 $z^{\\star}$ 的分量：\n对于非活动坐标 $i=3$：\n$z_3^{\\star} = x_3^{\\star} - t (\\nabla g(x^{\\star}))_3 = 0 - t(-0.5) = 0.5t$。\n第 3 个坐标被置为零的条件是 $|z_3^k| \\le t_k \\lambda$。在极限情况下，这是 $|z_3^{\\star}| \\le t\\lambda$，即 $|0.5t| \\le t(1)$，或 $0.5t \\le t$。对于 $t>0$，这个不等式是严格的。\n由于严格不等式 $0.5  1$（即严格互补性条件），根据连续性，对于任何足够大的 $k$，使得 $x^k$ 位于 $x^{\\star}$ 的一个足够小的邻域内，并且 $t_k$ 接近 $t$，我们将有 $|(x^k - t_k \\nabla g(x^k))_3|  t_k \\lambda$。一旦发生这种情况，$x_3^{k+1}$ 将精确地变为 $0$。在所有后续迭代中它将保持为零，因为对于 $j > k$，第三个分量的迭代将是 $x_3^{j+1} = S_{t_j\\lambda}(-t_j (\\nabla g(x^j))_3)$，其自变量将保持在阈值区间 $[ -t_j\\lambda, t_j\\lambda ]$ 内。\n\n对于活动坐标 $i \\in S = \\{1,2\\}$：\n$z_i^{\\star} = x_i^{\\star} - t(\\nabla g(x^{\\star}))_i$。从 KKT 条件可知，对于 $i=1,2$，$(\\nabla g(x^{\\star}))_i = -\\lambda \\operatorname{sign}(x_i^{\\star}) = -1$。\n$z_1^{\\star} = x_1^{\\star} - t(-1) = \\frac{3}{4} + t$。\n$z_2^{\\star} = x_2^{\\star} - t(-1) = \\frac{3}{4} + t$。\n由于 $t  0$，我们有 $z_{1,2}^{\\star}  t = t\\lambda$。根据连续性，对于足够大的 $k$，$|z_{1,2}^k|  t_k\\lambda$。因此，$x_{1,2}^{k+1}$ 将非零。此外，由于 $z_{1,2}^k$ 将是正的，$x_{1,2}^{k+1}$ 的符号将是正的，与 $x_{1,2}^{\\star}$ 的符号相匹配。\n\n因此，由于解处的严格互补性，该算法将在有限次迭代内识别出正确的支撑集 $S=\\{1,2\\}$ 和符号。\n\n### 任务 4：局部线性迭代和收敛速率\n\n一旦算法对于 $k \\ge K$ 识别了活动流形（即，对于 $i \\notin S$ 有 $x_i^k = 0$，对于 $i \\in S$ 有 $\\operatorname{sign}(x_i^k) = \\operatorname{sign}(x_i^{\\star})$），迭代过程就简化了。令 $x_S$ 表示支撑集 $S=\\{1,2\\}$ 中的分量向量。对于 $k \\ge K$，我们有 $x_{S^c}^k = 0$ 且 $\\operatorname{sign}(x_S^k) = (1, 1)^{\\top}$。对 $x_S$ 的 ISTA 更新为：\n$$\nx_S^{k+1} = \\operatorname{prox}_{t h_S}(x_S^k - t \\nabla_S g(x^k))\n$$\n其中对于正的 $x_S$，$h_S(x_S) = \\lambda \\|x_S\\|_1 = \\lambda \\mathbf{1}^{\\top}x_S$，$t$ 是步长。限制在流形上的梯度为 $\\nabla_S g(x^k) = A_S^{\\top}(A_S x_S^k - y)$。近端操作变为一个简单的平移：\n$$\nx_S^{k+1} = (x_S^k - t(A_S^{\\top}(A_S x_S^k - y))) - t\\lambda \\mathbf{1}.\n$$\n流形上的解 $x_S^{\\star}$ 是此迭代的一个不动点，满足：\n$$\nx_S^{\\star} = (x_S^{\\star} - t(A_S^{\\top}(A_S x_S^{\\star} - y))) - t\\lambda \\mathbf{1},\n$$\n这蕴含了 $A_S^{\\top}(A_S x_S^{\\star} - y) + \\lambda \\mathbf{1} = 0$，与 KKT 条件一致。\n令误差为 $e^k = x_S^k - x_S^{\\star}$。从迭代方程中减去不动点方程，得到：\n$$\ne^{k+1} = e^k - t \\left( A_S^{\\top}A_S x_S^k - A_S^{\\top}A_S x_S^{\\star} \\right) = e^k - t A_S^{\\top}A_S e^k = (I - t A_S^{\\top}A_S) e^k.\n$$\n这是一个线性迭代。收敛速率由迭代矩阵 $M = I - t A_S^{\\top}A_S$ 的谱半径决定。局部线性收敛速率常数为 $\\rho_{\\mathrm{local}} = \\rho(M) = \\|I - t A_S^{\\top}A_S\\|_2$。$M$ 的特征值为 $1 - t\\mu_j$，其中 $\\mu_j$ 是 $A_S^{\\top}A_S$ 的特征值。因此，速率常数由下式给出：\n$$\n\\rho_{\\mathrm{local}} = \\max_j |1 - t \\mu_j(A_S^{\\top}A_S)| = \\max\\left( |1 - t \\mu_{\\min}(A_S^{\\top}A_S)|, |1 - t \\mu_{\\max}(A_S^{\\top}A_S)| \\right).\n$$\n\n### 任务 5：计算局部收敛速率的数值\n\n我们首先计算矩阵 $A_S^{\\top}A_S$。子矩阵 $A_S$ 由 $A$ 的前两列组成：\n$$\nA_S = \\begin{pmatrix} 2  0 \\\\ 0  2 \\\\ 0  0 \\end{pmatrix}.\n$$\n然后，\n$$\nA_S^{\\top}A_S = \\begin{pmatrix} 2  0  0 \\\\ 0  2  0 \\end{pmatrix} \\begin{pmatrix} 2  0 \\\\ 0  2 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 4  0 \\\\ 0  4 \\end{pmatrix} = 4I.\n$$\n$A_S^{\\top}A_S$ 的特征值为 $\\mu_1 = 4$ 和 $\\mu_2 = 4$。所以，$\\mu_{\\min}(A_S^{\\top}A_S) = \\mu_{\\max}(A_S^{\\top}A_S) = 4$。流形上梯度的局部 Lipschitz 常数为 $L_S = \\|A_S^{\\top}A_S\\|_2 = \\mu_{\\max}(A_S^{\\top}A_S) = 4$。\n问题陈述中提到使用了回溯法。ISTA 的标准回溯线搜索将接受任何步长 $t_k \\in (0, 1/L_S]$。该过程通常首先尝试一个大步长然后减小它，因此预期它会收敛到满足下降条件的最大可能步长，即 $t = 1/L_S$。\n使用 $t = 1/L_S = 1/4$，我们计算速率常数：\n$$\n\\rho_{\\mathrm{local}} = \\max(|1 - t \\mu_1|, |1 - t \\mu_2|) = \\max\\left(\\left|1 - \\frac{1}{4} \\cdot 4\\right|, \\left|1 - \\frac{1}{4} \\cdot 4\\right|\\right) = \\max(|1-1|, |1-1|) = 0.\n$$\n速率常数为 $0$ 表示一旦算法完全识别了活动流形并将其步长调整为局部常数 $L_S$，它就会在单步内收敛。", "answer": "$$\n\\boxed{0}\n$$", "id": "3438565"}]}