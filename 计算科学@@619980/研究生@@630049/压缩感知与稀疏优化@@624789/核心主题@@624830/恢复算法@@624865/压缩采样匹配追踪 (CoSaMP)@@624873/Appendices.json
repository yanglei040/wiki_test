{"hands_on_practices": [{"introduction": "在部署像 CoSaMP 这样的压缩感知算法之前，一个基本而实际的问题是：我们需要多少次测量？本练习提供了一种基于成熟理论缩放定律的动手方法来估算这一数值，将受限等距性质（RIP）的抽象理论与具体的实验设计联系起来。通过这个计算，您可以体会到信号维度、稀疏度与所需测量次数之间的定量关系。[@problem_id:3436582]", "problem": "考虑一个$k$-稀疏信号$x \\in \\mathbb{R}^{n}$（其中 $k \\ll n$），该信号通过一个线性系统 $y = A x$ 进行测量。在此系统中，矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的条目是独立同分布的亚高斯随机变量，具有零均值和单位方差。信号的恢复通过压缩感知匹配追踪（Compressive Sampling Matching Pursuit, CoSaMP）算法进行。这是一种贪心算法，它利用信号的稀疏性，通过迭代地识别和优化候选支撑集来恢复信号。对于亚高斯测量系综，一个源于高维概率论和有限等距性质（Restricted Isometry Property, RIP）理论的、被广泛接受且经过充分检验的事实指出，当测量次数 $m$ 的数量级满足 $m \\geq C k \\log(n/k)$ 时，矩阵 $A$ 会以高概率满足一个具有足够小常数的$2k$阶RIP。这里，$C$ 是一个绝对常数，其值取决于所期望的RIP水平和失败概率。\n\n使用此标度律作为CoSaMP算法实现稳定支撑集恢复所需最小测量次数的启发式方法，在 $n=1000$、$k=20$ 和 $C=10$ 的条件下，估算一个合理的 $m$ 值。使用自然对数计算 $\\log$，并将您的答案四舍五入到四位有效数字。根据该启发式方法所蕴含的依赖关系，简要讨论所估计的 $m$ 值对 $C$ 值选择的敏感性，但最终答案只提供 $m$ 的数值估计。", "solution": "该问题要求为一个压缩感知场景估算所需的最小测量次数，记为 $m$。估算需基于一个给定的启发式标度律，该标度律将 $m$ 与信号维度 $n$、稀疏度 $k$ 以及一个绝对常数 $C$ 联系起来。\n\n给定的标度律为：\n$$m \\geq C k \\log\\left(\\frac{n}{k}\\right)$$\n该不等式给出了在测量矩阵 $A$ 满足有限等距性质（RIP）的条件下，使用像压缩感知匹配追踪（CoSaMP）这类算法足以实现稳定信号恢复的测量次数 $m$ 的一个下界。问题要求估算一个合理的 $m$ 值，我们将其取为这个下界。问题指定对数为自然对数，我们记为 $\\ln$。\n\n提供的具体参数如下：\n- 信号维度, $n = 1000$。\n- 稀疏度, $k = 20$。\n- 常数, $C = 10$。\n\n我们将这些值代入 $m$ 的下界表达式中：\n$$m \\approx C k \\ln\\left(\\frac{n}{k}\\right)$$\n$$m \\approx 10 \\times 20 \\times \\ln\\left(\\frac{1000}{20}\\right)$$\n\n首先，我们计算对数内的比值：\n$$\\frac{n}{k} = \\frac{1000}{20} = 50$$\n\n现在，$m$ 的表达式简化为：\n$$m \\approx 200 \\times \\ln(50)$$\n\n使用 $50$ 的自然对数值：\n$$\\ln(50) \\approx 3.91202300543$$\n\n现在我们可以计算 $m$ 的估计值：\n$$m \\approx 200 \\times 3.91202300543$$\n$$m \\approx 782.404601086$$\n\n问题要求答案四舍五入到四位有效数字。前四位有效数字是 $7$、$8$、$2$ 和 $4$。第五位数字是 $0$，所以我们向下舍入。\n$$m \\approx 782.4$$\n\n按照要求，我们简要讨论所估计的 $m$ 值对常数 $C$ 选择的敏感性。该关系由 $m \\approx C k \\ln(n/k)$ 给出。对于固定的信号参数 $n$ 和 $k$，估计的测量次数 $m$ 与常数 $C$ 成正比。这种线性依赖关系意味着 $m$ 的估计值对 $C$ 的选择高度敏感。例如，如果常数 $C$ 翻倍至 $20$，所需的测量次数估计值也将翻倍至约 $1565$。常数 $C$ 本身由期望的RIP强度（即等距常数 $\\delta_{2k}$ 的值）和随机矩阵系综可接受的失败概率决定。更严格的要求（更小的 $\\delta_{2k}$ 或更低的失败概率）会导致更大的 $C$ 值，从而增加保证恢复所需的测量次数。因此，$C$ 的选择是一个关键参数，它直接决定了感知过程的资源需求。", "answer": "$$\\boxed{782.4}$$", "id": "3436582"}, {"introduction": "要真正掌握 CoSaMP 的内部机制，没有什么比手动演练其步骤更好的方法了。本练习题将引导您完成算法的一次完整迭代，从识别潜在的信号分量到剪枝最终估计，从而让您对 CoSaMP 贪婪、迭代的本质有一个具体的认识。这个过程清晰地揭示了算法中每个核心步骤——相关性计算、最小二乘拟合和稀疏化——的作用。[@problem_id:3434637]", "problem": "考虑一个压缩感知中的线性测量模型，其中信号 $x \\in \\mathbb{R}^{5}$ 在规范基下是 $k$-稀疏的（即基变换矩阵是单位矩阵），测量值由 $y = A x$ 给出，其中 $A \\in \\mathbb{R}^{3 \\times 5}$。设 $A = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix}$，$\\Phi = I_{5}$，且 $x = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 0 \\end{bmatrix}$，因此 $y = A x$。从基本定义出发：线性测量 $y = A x$，$x$ 在单位基下的稀疏性，支撑集为非零项的索引集，以及最小二乘拟合为最小化残差的欧几里得范数。执行一次完整的压缩采样匹配追踪（CoSaMP）迭代，目标稀疏度为 $k = 2$，从零初始估计 $x^{(0)} = 0$ 和残差 $r^{(0)} = y$ 开始。遵循以下基本步骤：\n\n- 计算代理 $u = A^{\\top} r^{(0)}$。\n- 识别出 $|u|$ 中幅值最大的 $2k$ 个元素对应的索引集 $\\Omega$。\n- 与当前支撑集合并，形成 $\\mathcal{T} = \\Omega \\cup \\operatorname{supp}(x^{(0)})$。\n- 求解最小二乘问题 $b = \\arg\\min_{z \\in \\mathbb{R}^{5},\\, \\operatorname{supp}(z) \\subseteq \\mathcal{T}} \\| y - A z \\|_{2}$；如果存在多个最小化解，选择欧几里得范数最小的那个。\n- 将 $b$ 剪枝，保留其幅值最大的 $k$ 个元素，得到 $x^{(1)}$。\n- 形成更新后的残差 $r^{(1)} = y - A x^{(1)}$。\n\n更新后的残差的欧几里得范数 $\\| r^{(1)} \\|_{2}$ 是多少？请以闭式解析表达式的形式给出最终答案。不要进行近似或四舍五入。", "solution": "该问题要求执行一次完整的压缩采样匹配追踪（CoSaMP）算法迭代，以求得更新后残差的欧几里得范数 $\\| r^{(1)} \\|_{2}$。我们已知线性测量模型 $y = Ax$，其中信号 $x \\in \\mathbb{R}^{5}$ 在规范基下是稀疏的。\n\n给定的数据如下：\n- 测量矩阵：$A = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix} \\in \\mathbb{R}^{3 \\times 5}$\n- 真实信号：$x = \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 0 \\end{bmatrix} \\in \\mathbb{R}^{5}$\n- 算法的目标稀疏度：$k = 2$\n- 初始信号估计：$x^{(0)} = 0 \\in \\mathbb{R}^{5}$\n- 基变换矩阵是单位矩阵 $\\Phi = I_{5}$。\n\n迭代遵循一个规定的步骤序列。首先，我们计算测量向量 $y$。\n$$y = Ax = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\\\ 2 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1(1) + 1(2) \\\\ 1(2) \\\\ 1(1) \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix}$$\n初始残差为 $r^{(0)} = y = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix}$。\n\n现在，我们继续执行CoSaMP迭代的步骤。\n\n1.  **计算代理**：代理 $u$ 由 $u = A^{\\top} r^{(0)}$ 给出。\n    $$A^{\\top} = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\\\ 0  0  1 \\end{bmatrix}$$\n    $$u = A^{\\top} r^{(0)} = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\\\ 0  0  1 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1(3) + 1(1) \\\\ 1(2) \\\\ 1(3) + 1(2) \\\\ 1(2) + 1(1) \\\\ 1(1) \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ 2 \\\\ 5 \\\\ 3 \\\\ 1 \\end{bmatrix}$$\n\n2.  **识别支撑集**：我们识别出 $|u|$ 中幅值最大的 $2k$ 个元素对应的索引集 $\\Omega$。此处 $k=2$，所以 $2k=4$。向量 $u$ 的所有元素均为正，因此 $|u|=u$。 $u$ 的元素按幅值降序排列为 $5, 4, 3, 2$，对应的索引为 $3, 1, 4, 2$。\n    $$\\Omega = \\{1, 2, 3, 4\\}$$\n\n3.  **合并支撑集**：新的候选支撑集 $\\mathcal{T}$ 是 $\\Omega$ 和前一个估计 $x^{(0)}$ 的支撑集的并集。\n    $$\\operatorname{supp}(x^{(0)}) = \\operatorname{supp}(0) = \\emptyset$$\n    $$\\mathcal{T} = \\Omega \\cup \\operatorname{supp}(x^{(0)}) = \\{1, 2, 3, 4\\}$$\n\n4.  **求解最小二乘问题**：我们必须找到支撑集包含在 $\\mathcal{T}$ 中且能最小化 $\\|y - Az\\|_2$ 的向量 $b$。这等价于在最小二乘意义下从系统 $A_{\\mathcal{T}} b_{\\mathcal{T}} \\approx y$ 求解 $b_{\\mathcal{T}}$，其中 $A_{\\mathcal{T}}$ 是由 $A$ 中索引在 $\\mathcal{T}$ 内的列组成的子矩阵。\n    $$A_{\\mathcal{T}} = \\begin{bmatrix} 1  0  1  0 \\\\ 0  1  1  1 \\\\ 1  0  0  1 \\end{bmatrix}$$\n    问题规定，如果存在多个最小化解，我们选择欧几里得范数最小的那个。这对应于解 $b_{\\mathcal{T}} = A_{\\mathcal{T}}^{\\dagger} y$，其中 $A_{\\mathcal{T}}^{\\dagger}$ 是 $A_{\\mathcal{T}}$ 的摩尔-彭若斯伪逆。由于 $A_{\\mathcal{T}}$ 是一个秩为 3 的 $3 \\times 4$ 矩阵（它具有满行秩），其伪逆由 $A_{\\mathcal{T}}^{\\dagger} = A_{\\mathcal{T}}^{\\top}(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top})^{-1}$ 给出。\n    首先，我们计算 $A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top}$：\n    $$A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top} = \\begin{bmatrix} 1  0  1  0 \\\\ 0  1  1  1 \\\\ 1  0  0  1 \\end{bmatrix} \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} = \\begin{bmatrix} 2  1  1 \\\\ 1  3  1 \\\\ 1  1  2 \\end{bmatrix}$$\n    接下来，我们求这个 $3 \\times 3$ 矩阵的逆。行列式为 $\\det(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top}) = 2(6-1) - 1(2-1) + 1(1-3) = 10 - 1 - 2 = 7$。\n    逆矩阵是：\n    $$(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top})^{-1} = \\frac{1}{7} \\begin{bmatrix} 5  -1  -2 \\\\ -1  3  -1 \\\\ -2  -1  5 \\end{bmatrix}$$\n    现在我们可以计算 $b_{\\mathcal{T}}$：\n    $$b_{\\mathcal{T}} = A_{\\mathcal{T}}^{\\top}(A_{\\mathcal{T}}A_{\\mathcal{T}}^{\\top})^{-1} y = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} \\left( \\frac{1}{7} \\begin{bmatrix} 5  -1  -2 \\\\ -1  3  -1 \\\\ -2  -1  5 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix} \\right)$$\n    $$b_{\\mathcal{T}} = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} \\left( \\frac{1}{7} \\begin{bmatrix} 15-2-2 \\\\ -3+6-1 \\\\ -6-2+5 \\end{bmatrix} \\right) = \\begin{bmatrix} 1  0  1 \\\\ 0  1  0 \\\\ 1  1  0 \\\\ 0  1  1 \\end{bmatrix} \\left( \\frac{1}{7} \\begin{bmatrix} 11 \\\\ 2 \\\\ -3 \\end{bmatrix} \\right) = \\frac{1}{7} \\begin{bmatrix} 11-3 \\\\ 2 \\\\ 11+2 \\\\ 2-3 \\end{bmatrix} = \\frac{1}{7} \\begin{bmatrix} 8 \\\\ 2 \\\\ 13 \\\\ -1 \\end{bmatrix}$$\n    完整的向量 $b \\in \\mathbb{R}^5$ 是通过将这些值放在 $\\mathcal{T}$ 中的相应索引位置，并在其他位置置零来构造的：\n    $$b = \\begin{bmatrix} 8/7 \\\\ 2/7 \\\\ 13/7 \\\\ -1/7 \\\\ 0 \\end{bmatrix}$$\n\n5.  **剪枝估计**：我们通过保留 $b$ 中幅值最大的 $k=2$ 个分量来获得新的信号估计 $x^{(1)}$。$b$ 的非零分量的幅值为 $|8/7|$、 $|2/7|$、 $|13/7|$ 和 $|-1/7|$，即 $8/7$、 $2/7$、 $13/7$ 和 $1/7$。最大的两个是 $13/7$（在索引 3 处）和 $8/7$（在索引 1 处）。\n    因此，我们将所有其他分量设置为零：\n    $$x^{(1)} = \\begin{bmatrix} 8/7 \\\\ 0 \\\\ 13/7 \\\\ 0 \\\\ 0 \\end{bmatrix}$$\n\n6.  **更新残差**：新的残差 $r^{(1)}$ 为 $r^{(1)} = y - Ax^{(1)}$。\n    $$Ax^{(1)} = \\begin{bmatrix} 1  0  1  0  0 \\\\ 0  1  1  1  0 \\\\ 1  0  0  1  1 \\end{bmatrix} \\begin{bmatrix} 8/7 \\\\ 0 \\\\ 13/7 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 8/7 + 13/7 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix} = \\begin{bmatrix} 21/7 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix}$$\n    $$r^{(1)} = y - Ax^{(1)} = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix} - \\begin{bmatrix} 3 \\\\ 13/7 \\\\ 8/7 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 14/7 - 13/7 \\\\ 7/7 - 8/7 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1/7 \\\\ -1/7 \\end{bmatrix}$$\n\n最后，我们计算更新后残差 $r^{(1)}$ 的欧几里得范数。\n$$\\|r^{(1)}\\|_{2} = \\sqrt{0^2 + (1/7)^2 + (-1/7)^2} = \\sqrt{\\frac{1}{49} + \\frac{1}{49}} = \\sqrt{\\frac{2}{49}} = \\frac{\\sqrt{2}}{7}$$\n经过一次迭代后残差的欧几里得范数为 $\\frac{\\sqrt{2}}{7}$。", "answer": "$$\\boxed{\\frac{\\sqrt{2}}{7}}$$", "id": "3434637"}, {"introduction": "像 CoSaMP 这类算法的理论保证依赖于传感矩阵的特定属性，例如受限等距性质（RIP）。这项高级练习要求您构建一个 CoSaMP 失败的场景，亲身证明为何这些理论条件不仅仅是数学形式，而是成功恢复信号的关键。通过分析这个反例，您可以深刻理解矩阵列之间的相关性是如何直接影响算法性能的。[@problem_id:3436625]", "problem": "考虑无噪声线性测量模型 $y = A x^{\\star}$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 且 $x^{\\star} \\in \\mathbb{R}^{n}$，$x^{\\star}$ 是 $k$-稀疏的。压缩感知匹配追踪（Compressive Sampling Matching Pursuit，此后简称为 CoSaMP）算法通过与当前残差的相关性来迭代地识别候选支撑集，在合并的支撑集上求解一个最小二乘问题，然后在更新残差之前剪枝到 $k$ 个条目。CoSaMP 的恢复保证通常在限制等距性质（Restricted Isometry Property, RIP）下给出：如果对于所有 $s$-稀疏向量 $v$，都满足 $(1 - \\delta_{s}) \\|v\\|_{2}^{2} \\le \\|A v\\|_{2}^{2} \\le (1 + \\delta_{s}) \\|v\\|_{2}^{2}$，则矩阵 $A$ 具有阶为 $s$ 的 RIP，其限制等距常数（RIC）为 $\\delta_{s}$。\n\n构建一个感知矩阵 $A \\in \\mathbb{R}^{2 \\times 8}$，其列向量为\n$$\na_{1} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix},\\quad\na_{2} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix},\\quad\na_{3} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix},\\quad\na_{4} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix},\\quad\na_{5} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix},\\quad\na_{6} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix},\\quad\na_{7} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix},\\quad\na_{8} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}.\n$$\n令 $k = 2$，真实信号为 $x^{\\star} \\in \\mathbb{R}^{8}$，其分量为 $x^{\\star}_{1} = 1$，$x^{\\star}_{2} = 1$，且对于 $j \\in \\{3,4,5,6,7,8\\}$ 有 $x^{\\star}_{j} = 0$。因此 $y = A x^{\\star} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$。\n\n从限制等距性质和 CoSaMP 迭代（残差更新、基于相关性识别 $2k$ 个索引、在合并支撑集上进行最小二乘、根据系数幅值剪枝到 $k$ 个，以及残差重新计算）的定义出发，完成以下任务：\n\n- 仅使用上述定义和标准线性代数，确定 CoSaMP 算法在应用于 $(A, y)$ 时第一次迭代中所识别的 $2k$ 个索引的集合，并证明在最小二乘和剪枝步骤之后，CoSaMP 可以选择一个不包含真实索引 $\\{1, 2\\}$ 的支撑集，同时实现零残差。\n- 通过分析在所有 $4k$-稀疏向量 $v$ 上 $\\|A v\\|_{2}^{2}$ 相对于 $\\|v\\|_{2}^{2}$ 的极值偏差，计算所构造矩阵 $A$ 的限制等距常数 $\\delta_{4k}$。\n\n将最终答案表示为 $A$ 的 $\\delta_{4k}$ 的精确值。无需四舍五入。不涉及物理单位。", "solution": "用户在压缩感知领域提供了一个适定问题。该问题要求分析压缩感知匹配追踪（CoSaMP）算法在特定构造的感知矩阵和信号上的第一次迭代，并计算相应的限制等距常数（RIC）。该问题是有效的，因为它是科学有据、自洽且客观的。\n\n该问题分为两部分。首先，我们将分析 CoSaMP 算法的行为。其次，我们将计算限制等距常数 $\\delta_{4k}$。\n\n**第 1 部分：CoSaMP 算法第一次迭代分析**\n\nCoSaMP 算法以估计值 $x^0 = 0$ 和相应的支撑集 $T^0 = \\emptyset$ 进行初始化。初始残差为 $r^0 = y - Ax^0 = y$。\n给定的参数为：\n- 稀疏度：$k=2$。\n- 真实信号：$x^{\\star} \\in \\mathbb{R}^{8}$，其中 $x^{\\star}_{1} = 1$，$x^{\\star}_{2} = 1$，且对于 $j > 2$ 有 $x^{\\star}_{j} = 0$。真实支撑集为 $\\{1, 2\\}$。\n- 感知矩阵 $A \\in \\mathbb{R}^{2 \\times 8}$，其列向量由 $a_{1} = a_5 = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$，$a_{2} = a_6 = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$，以及 $a_{3} = a_{4} = a_{7} = a_{8} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$ 给出。\n- 测量向量：$y = A x^{\\star} = a_1 x^{\\star}_1 + a_2 x^{\\star}_2 = 1 \\cdot \\begin{pmatrix}1 \\\\ 0\\end{pmatrix} + 1 \\cdot \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$。\n\nCoSaMP 的第一次迭代（$\\ell=1$）过程如下：\n\n1.  **使用相关性识别支撑集：**\n    我们计算“代理”向量 $p = A^T r^0 = A^T y$。\n    $$\n    A^T y =\n    \\begin{pmatrix}\n    a_1^T \\\\ a_2^T \\\\ a_3^T \\\\ a_4^T \\\\ a_5^T \\\\ a_6^T \\\\ a_7^T \\\\ a_8^T\n    \\end{pmatrix}\n    \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} =\n    \\begin{pmatrix}\n    a_1^T y \\\\ a_2^T y \\\\ a_3^T y \\\\ a_4^T y \\\\ a_5^T y \\\\ a_6^T y \\\\ a_7^T y \\\\ a_8^T y\n    \\end{pmatrix}\n    $$\n    相关性计算如下：\n    - $a_1^T y = a_5^T y = \\begin{pmatrix}1  0\\end{pmatrix} \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = 1$。\n    - $a_2^T y = a_6^T y = \\begin{pmatrix}0  1\\end{pmatrix} \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = 1$。\n    - $a_3^T y = a_4^T y = a_7^T y = a_8^T y = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1  1\\end{pmatrix} \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\frac{2}{\\sqrt{2}} = \\sqrt{2}$。\n\n    代理向量为 $p = (1, 1, \\sqrt{2}, \\sqrt{2}, 1, 1, \\sqrt{2}, \\sqrt{2})^T$。\n    CoSaMP 识别出与 $p$ 的 $2k = 4$ 个最大幅值分量相对应的索引集合 $\\Omega$。四个最大幅值均为 $\\sqrt{2}$，对应的索引为 $\\{3, 4, 7, 8\\}$。因此，$\\Omega = \\{3, 4, 7, 8\\}$。注意，真实支撑集索引 $\\{1, 2\\}$ 未被选中，因为它们的相关性值较小。\n\n2.  **合并支撑集：**\n    通过将前一个支撑集与新识别的索引合并，形成候选支撑集：$S^1 = T^0 \\cup \\Omega = \\emptyset \\cup \\{3, 4, 7, 8\\} = \\{3, 4, 7, 8\\}$。\n\n3.  **最小二乘估计：**\n    我们在 $S^1$ 上寻找一个能够最好地解释测量值 $y$ 的信号估计 $b$。这通过求解最小二乘问题来完成：\n    $$\n    b_{S^1} = \\arg\\min_z \\| y - A_{S^1} z \\|_2^2\n    $$\n    其中 $A_{S^1}$ 是由 $A$ 中索引为 $S^1$ 的列组成的子矩阵。这些列是 $a_3, a_4, a_7, a_8$，它们都相同：对于 $i \\in S^1$，有 $a_i = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$。\n    $A_{S^1}$ 的列空间是一维的，由向量 $v_0 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$ 张成。向量 $y = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\sqrt{2} v_0$ 完全位于此列空间内。因此，该最小二乘问题的残差为零，任何满足 $A_{S^1} z = y$ 的向量 $z \\in \\mathbb{R}^4$ 都是一个有效的解。\n    设 $z = (z_1, z_2, z_3, z_4)^T$。方程 $A_{S^1} z = y$ 为：\n    $$\n    z_1 a_3 + z_2 a_4 + z_3 a_7 + z_4 a_8 = y\n    $$\n    $$\n    (z_1 + z_2 + z_3 + z_4) \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}\n    $$\n    这可以简化为单个线性方程 $z_1 + z_2 + z_3 + z_4 = \\sqrt{2}$。\n    这个方程有无穷多个解。问题陈述 CoSaMP“可以选择”一个支撑集，这意味着我们可以从这个解集中选择一个特定的解。我们选择一个 2-稀疏解。例如，令 $z_1 = \\frac{\\sqrt{2}}{2}$，$z_2 = \\frac{\\sqrt{2}}{2}$，且 $z_3=z_4=0$。\n    这对应于一个中间信号估计 $b$，其非零分量为 $b_3 = \\frac{\\sqrt{2}}{2}$ 和 $b_4 = \\frac{\\sqrt{2}}{2}$。\n\n4.  **剪枝：**\n    算法对中间信号 $b$ 进行剪枝以获得新的估计 $x^1$。新的支撑集 $T^1$ 由 $b$ 的 $k=2$ 个最大幅值分量的索引组成。在我们的例子中，非零分量是 $b_3$ 和 $b_4$，它们的幅值都是 $\\frac{\\sqrt{2}}{2}$。因此，新的支撑集是 $T^1 = \\{3, 4\\}$。\n    新的信号估计 $x^1$ 是 $b$ 在该支撑集上的限制：$x^1_3 = \\frac{\\sqrt{2}}{2}$，$x^1_4 = \\frac{\\sqrt{2}}{2}$，所有其他分量均为零。\n    这个新的支撑集 $T^1=\\{3, 4\\}$ 不包含真实的支撑集索引 $\\{1, 2\\}$。\n\n5.  **残差更新：**\n    迭代的最后一步是计算新的残差 $r^1 = y - Ax^1$。\n    $$\n    A x^1 = a_3 x^1_3 + a_4 x^1_4 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix} \\left(\\frac{\\sqrt{2}}{2}\\right) + \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix} \\left(\\frac{\\sqrt{2}}{2}\\right) = \\begin{pmatrix}1/2 \\\\ 1/2\\end{pmatrix} + \\begin{pmatrix}1/2 \\\\ 1/2\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}\n    $$\n    由于 $A x^1 = y$，残差为 $r^1 = y - y = 0$。\n    残差为零，算法终止，恢复了一个在支撑集 $\\{3, 4\\}$ 上的错误稀疏信号 $x^1$。这表明了由于感知矩阵 $A$ 的结构，CoSaMP 算法出现了一个失败案例。\n\n**第 2 部分：RIC $\\delta_{4k}$ 的计算**\n\n矩阵 $A$ 的限制等距常数（RIC）$\\delta_s$ 是使得对于所有 $s$-稀疏向量 $v$，以下不等式成立的最小非负数：\n$$ (1 - \\delta_s) \\|v\\|_2^2 \\le \\|Av\\|_2^2 \\le (1 + \\delta_s) \\|v\\|_2^2 $$\n$\\delta_s$ 的一个等价描述是：\n$$ \\delta_s = \\max \\left( \\max_{S:|S|=s} \\lambda_{\\max}(A_S^T A_S) - 1, 1 - \\min_{S:|S|=s} \\lambda_{\\min}(A_S^T A_S) \\right) $$\n其中 $A_S$ 是由 $A$ 中索引集为 $S$ 的列组成的子矩阵，$\\lambda_{\\max}$ 和 $\\lambda_{\\min}$ 分别表示最大和最小特征值。\n\n我们需要计算 $k=2$ 时的 $\\delta_{4k}$，即 $\\delta_8$。矩阵 $A$ 有 $n=8$ 列。$\\mathbb{R}^8$ 中的一个 8-稀疏向量可以是 $\\mathbb{R}^8$ 中的任何向量。因此，我们只需要考虑完整的矩阵 $A$ 本身。大小为 8 的子矩阵集合只包含一个元素，即 $A$。\n$\\delta_8$ 的公式简化为：\n$$ \\delta_8 = \\max \\left( \\lambda_{\\max}(A^T A) - 1, 1 - \\lambda_{\\min}(A^T A) \\right) $$\n为了求 $8 \\times 8$ 矩阵 $A^T A$ 的特征值，计算上更简单的方法是求 $2 \\times 2$ 矩阵 $A A^T$ 的特征值。$A^T A$ 的非零特征值与 $A A^T$ 的特征值相同。\n\n令 $c=1/\\sqrt{2}$。矩阵 $A$ 为：\n$$\nA = \\begin{pmatrix}\n1  0  c  c  1  0  c  c \\\\\n0  1  c  c  0  1  c  c\n\\end{pmatrix}\n$$\n我们计算 $A A^T$：\n$$\nA A^T = \\begin{pmatrix}\n1  0  c  c  1  0  c  c \\\\\n0  1  c  c  0  1  c  c\n\\end{pmatrix}\n\\begin{pmatrix}\n1  0 \\\\ 0  1 \\\\ c  c \\\\ c  c \\\\ 1  0 \\\\ 0  1 \\\\ c  c \\\\ c  c\n\\end{pmatrix}\n$$\n$A A^T$ 的元素 $(A A^T)_{11}$ 是 $A$ 第一行元素的平方和：\n$(A A^T)_{11} = 1^2 + 0^2 + c^2 + c^2 + 1^2 + 0^2 + c^2 + c^2 = 2 + 4c^2 = 2 + 4(1/2) = 4$。\n$A A^T$ 的元素 $(A A^T)_{22}$ 是 $A$ 第二行元素的平方和：\n$(A A^T)_{22} = 0^2 + 1^2 + c^2 + c^2 + 0^2 + 1^2 + c^2 + c^2 = 2 + 4c^2 = 2 + 4(1/2) = 4$。\n非对角线元素 $(A A^T)_{12} = (A A^T)_{21}$ 是 $A$ 的两行向量的点积：\n$(A A^T)_{12} = 1(0) + 0(1) + c(c) + c(c) + 1(0) + 0(1) + c(c) + c(c) = 4c^2 = 4(1/2) = 2$。\n所以，该矩阵为：\n$$\nA A^T = \\begin{pmatrix} 4  2 \\\\ 2  4 \\end{pmatrix}\n$$\n通过求解特征方程 $\\det(A A^T - \\lambda I) = 0$ 来找到特征值 $\\lambda$：\n$$\n\\det \\begin{pmatrix} 4-\\lambda  2 \\\\ 2  4-\\lambda \\end{pmatrix} = (4-\\lambda)^2 - 4 = 0\n$$\n$$\n(4-\\lambda)^2 = 4 \\implies 4-\\lambda = \\pm 2\n$$\n特征值为 $\\lambda_1 = 4-2=2$ 和 $\\lambda_2 = 4+2=6$。\n\n矩阵 $A$ 的秩为 2。因此，$8 \\times 8$ 矩阵 $A^T A$ 的秩也为 2，并拥有两个非零特征值，即 2 和 6。其余的 $8-2=6$ 个特征值均为 0。\n$A^T A$ 的特征值为 $\\{6, 2, 0, 0, 0, 0, 0, 0\\}$。\n因此，$\\lambda_{\\max}(A^T A) = 6$ 且 $\\lambda_{\\min}(A^T A) = 0$。\n\n将这些值代入 $\\delta_8$ 的公式中：\n$$\n\\delta_8 = \\max(6 - 1, 1 - 0) = \\max(5, 1) = 5\n$$\n所构造矩阵 $A$ 的限制等距常数 $\\delta_{4k}$ 为 $5$。", "answer": "$$\n\\boxed{5}\n$$", "id": "3436625"}]}