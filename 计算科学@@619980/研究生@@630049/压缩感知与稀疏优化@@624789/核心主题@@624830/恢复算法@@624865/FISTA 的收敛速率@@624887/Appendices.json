{"hands_on_practices": [{"introduction": "FISTA 保证的收敛速率不仅仅是理论上的一个奇妙结果，它还是一个规划计算资源的实用工具。第一个练习将挑战您将理论界 $F(x_k) - F(x^\\star) \\le \\frac{2L \\|x_0 - x^\\star\\|_2^2}{(k+1)^2}$ 转化为一个具体的迭代预算。通过解决一个特定的 LASSO 问题，您将学习如何计算必要的组成部分，如 Lipschitz 常数 $L$，并确定达到所需精度 $\\epsilon$ 所需的迭代次数。[@problem_id:3439140]", "problem": "考虑压缩感知中的复合凸优化问题\n$$\nF(x) \\equiv f(x) + g(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2} + \\lambda \\|x\\|_{1},\n$$\n其中 $A \\in \\mathbb{R}^{3 \\times 3}$，$b \\in \\mathbb{R}^{3}$，$\\lambda > 0$，$f$ 是一个凸函数，其梯度是 Lipschitz 连续的，而 $g$ 是一个具有可计算近端算子的正常、闭、凸函数。假设将快速迭代收缩阈值算法 (FISTA) 应用于此问题，采用标准的恒定步长选择 $1/L$ 和精确的近端算子求值，其中 $L$ 是 $\\nabla f$ 的 Lipschitz 常数。\n\n使用以下数据：\n- $A = \\operatorname{diag}(5, 3, 1)$，\n- $b = (0, 0, 0)^{\\top}$，\n- $\\lambda = 1$，\n- 初始点 $x_{0} = (3, 4, 0)^{\\top}$。\n\n假设在 $f$ 的 $L$-平滑性和 $g$ 的凸性条件下，复合凸最小化问题的标准 FISTA 收敛率成立，推导出一个显式的迭代次数预算，以保证目标函数间隙满足 $F(x_{k}) - F(x^{\\star}) \\le \\epsilon$（对于给定的容差 $\\epsilon$），然后计算当容差 $\\epsilon = 2 \\times 10^{-2}$ 时所需的最小整数 $k$。\n\n将您的最终答案以单个整数形式提供。除了取满足保证的最小整数外，不需要进行其他舍入。", "solution": "首先对问题进行验证，以确保其具有科学依据、良定性和客观性。\n\n### 第 1 步：提取已知条件\n- **优化问题**：最小化 $F(x) = f(x) + g(x)$，其中 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 且 $g(x) = \\lambda \\|x\\|_{1}$。\n- **定义域**：$A \\in \\mathbb{R}^{3 \\times 3}$，$b \\in \\mathbb{R}^{3}$。\n- **算法**：快速迭代收缩阈值算法 (FISTA)，步长为 $1/L$。\n- **数据**：\n    - $A = \\operatorname{diag}(5, 3, 1)$\n    - $b = (0, 0, 0)^{\\top}$\n    - $\\lambda = 1$\n    - 初始点：$x_{0} = (3, 4, 0)^{\\top}$\n- **性质**：$f(x)$ 是凸函数，其梯度 $\\nabla f$ 是 $L$-Lipschitz 连续的。$g(x)$ 是一个正常、闭、凸函数。\n- **任务**：\n    1. 推导出一个显式的迭代次数预算 $k$，以保证 $F(x_{k}) - F(x^{\\star}) \\le \\epsilon$。\n    2. 计算当容差为 $\\epsilon = 2 \\times 10^{-2}$ 时所需的最小整数 $k$。\n\n### 第 2 步：使用提取的已知条件进行验证\n- **科学依据**：该问题描述了 LASSO 目标函数，它是压缩感知和稀疏回归的基石。FISTA 是解决此类问题的标准、可证明收敛的算法。FISTA 的收敛率是凸优化理论中的一个经典结果。该问题在科学和数学上是合理的。\n- **良定性**：问题提供了确定 FISTA 收敛率公式中所有量所需的所有信息。Lipschitz 常数 $L$ 可以从 $A$ 推导得出。最优解 $x^\\star$ 可以根据给定数据唯一确定。任务是应用一个已知的理论界限，这是一个定义明确的数学练习。\n- **客观性**：问题以精确的数学术语陈述，没有歧义或主观论断。\n\n### 第 3 步：结论与行动\n该问题是有效的，因为它是优化领域中一个成熟理论结果的标准应用。我们继续进行求解。\n\n### 详细解答\n\n问题是找出 FISTA 算法保证目标函数值间隙至多为 $\\epsilon$ 所需的最小迭代次数 $k$。目标函数为 $F(x) = f(x) + g(x)$，其中 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 且 $g(x) = \\lambda \\|x\\|_{1}$。\n\n应用于此复合问题的 FISTA 的标准收敛率表明，迭代序列 $\\{x_k\\}$ 满足：\n$$\nF(x_{k}) - F(x^{\\star}) \\le \\frac{2L \\|x_0 - x^{\\star}\\|_2^2}{(k+1)^2}\n$$\n其中 $x^{\\star}$ 是 $F(x)$ 的一个最小化子，$x_0$ 是初始点，$L$ 是光滑部分梯度 $\\nabla f(x)$ 的 Lipschitz 常数。\n\n为了找到迭代次数预算，我们需要计算 $L$，$x^{\\star}$ 和 $\\|x_0 - x^{\\star}\\|_2^2$。\n\n**1. 计算 Lipschitz 常数 $L$**\n$f(x)$ 的梯度是 $\\nabla f(x) = A^{\\top}(Ax - b)$。Hessian 矩阵是 $\\nabla^2 f(x) = A^{\\top}A$。$\\nabla f(x)$ 的 Lipschitz 常数 $L$ 是 Hessian 矩阵的最大特征值，即 $L = \\lambda_{\\max}(A^{\\top}A)$。\n给定 $A = \\operatorname{diag}(5, 3, 1)$，$A$ 是对称矩阵，所以 $A^{\\top} = A$。\n$$\nA^{\\top}A = A^2 = (\\operatorname{diag}(5, 3, 1))^2 = \\operatorname{diag}(5^2, 3^2, 1^2) = \\operatorname{diag}(25, 9, 1)\n$$\n对角矩阵的特征值是其对角线上的元素。因此，最大特征值为 $\\lambda_{\\max}(A^{\\top}A) = 25$。\n因此，Lipschitz 常数为 $L = 25$。\n\n**2. 求解最优解 $x^{\\star}$**\n目标函数是 $F(x) = \\frac{1}{2}\\|Ax - b\\|_{2}^{2} + \\lambda \\|x\\|_{1}$。\n根据给定的数据，$b = (0, 0, 0)^{\\top}$ 和 $\\lambda=1$，函数变为：\n$$\nF(x) = \\frac{1}{2}\\|Ax\\|_{2}^{2} + \\|x\\|_{1}\n$$\n$f(x) = \\frac{1}{2}\\|Ax\\|_{2}^{2}$ 这一项是非负的。由于 $A = \\operatorname{diag}(5, 3, 1)$ 是可逆的，$Ax=0$ 当且仅当 $x=0$。因此，$f(x) \\ge 0$，且仅在 $x=0$ 时取等号。\n$g(x) = \\|x\\|_{1}$ 这一项也是非负的，且 $g(x)=0$ 当且仅当 $x=0$。\n因此，和 $F(x) = f(x) + g(x)$ 是非负的，且当且仅当两项都为零时，其值为 $0$。这种情况只在 $x=0$ 时发生。\n所以，最小化子是 $x^{\\star} = (0, 0, 0)^{\\top}$，最小目标函数值为 $F(x^{\\star}) = 0$。\n\n**3. 计算初始距离 $\\|x_0 - x^{\\star}\\|_2^2$**\n给定的初始点是 $x_0 = (3, 4, 0)^{\\top}$，并且我们已求得 $x^{\\star} = (0, 0, 0)^{\\top}$。\n欧几里得距离的平方为：\n$$\n\\|x_0 - x^{\\star}\\|_2^2 = \\|(3, 4, 0)^{\\top} - (0, 0, 0)^{\\top}\\|_2^2 = \\|(3, 4, 0)^{\\top}\\|_2^2 = 3^2 + 4^2 + 0^2 = 9 + 16 = 25\n$$\n\n**4. 推导显式迭代预算并计算 $k$**\n我们需要求出迭代次数 $k$，使得 $F(x_k) - F(x^\\star) \\le \\epsilon$。利用 FISTA 的收敛保证，我们需要满足：\n$$\n\\frac{2L \\|x_0 - x^{\\star}\\|_2^2}{(k+1)^2} \\le \\epsilon\n$$\n重新整理这个不等式以求解 $k$，得到显式的迭代次数预算：\n$$\n(k+1)^2 \\ge \\frac{2L \\|x_0 - x^{\\star}\\|_2^2}{\\epsilon}\n$$\n$$\nk+1 \\ge \\sqrt{\\frac{2L \\|x_0 - x^{\\star}\\|_2^2}{\\epsilon}}\n$$\n$$\nk \\ge \\sqrt{\\frac{2L \\|x_0 - x^{\\star}\\|_2^2}{\\epsilon}} - 1\n$$\n这是一般性的迭代次数预算表达式。现在我们代入问题的具体数值：$L=25$，$\\|x_0 - x^{\\star}\\|_2^2=25$ 和 $\\epsilon = 2 \\times 10^{-2}$。\n$$\nk \\ge \\sqrt{\\frac{2 \\times 25 \\times 25}{2 \\times 10^{-2}}} - 1\n$$\n$$\nk \\ge \\sqrt{\\frac{25^2}{10^{-2}}} - 1\n$$\n$$\nk \\ge \\sqrt{625 \\times 100} - 1\n$$\n$$\nk \\ge \\sqrt{62500} - 1\n$$\n$$\nk \\ge 250 - 1\n$$\n$$\nk \\ge 249\n$$\n问题要求满足此条件的最小整数 $k$。大于或等于 $249$ 的最小整数是 $249$。\n因此，至少需要 $k=249$ 次迭代才能保证目标函数间隙小于或等于 $2 \\times 10^{-2}$。", "answer": "$$\\boxed{249}$$", "id": "3439140"}, {"introduction": "FISTA 中的“快速”指的是其加速的 $O(1/k^2)$ 收敛速率，这比标准近端梯度法 (ISTA) 的 $O(1/k)$ 速率有了显著的改进。但它到底快了多少呢？本练习将引导您从第一性原理出发，推导两种算法收敛界中的显式常数。通过比较这些常数，您将对 Nesterov 加速机制的力量有更深刻的定量理解。[@problem_id:3439144]", "problem": "考虑写成复合凸函数 $F(x) = g(x) + h(x)$ 形式的最小绝对收缩和选择算子 (Lasso) 目标函数，其中 $g(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 且 $h(x) = \\lambda \\|x\\|_{1}$，$\\lambda > 0$。设梯度 $\\nabla g$ 是 $L$-利普希茨连续的，其中 $L = \\|A\\|_{2}^{2}$，$\\|A\\|_{2}$ 表示 $A$ 的谱范数（最大奇异值）。迭代收缩阈值算法 (ISTA) 使用步长为 $1/L$ 的近端梯度更新，而快速迭代收缩阈值算法 (FISTA) 使用 Nesterov 型外推和规范的惯性参数序列来加速 ISTA。\n\n仅从凸性、梯度利普希茨连续性的基本定义以及近端算子的性质出发，当 ISTA 和 FISTA 都在同一个 Lasso 实例上使用步长 $1/L$ 时，分别为它们推导以下界限的显式常数：\n$$F(x_{k}) - F(x^{\\star}) \\leq \\frac{C_{\\mathrm{ISTA}}}{k} \\quad \\text{和} \\quad F(x_{k}) - F(x^{\\star}) \\leq \\frac{C_{\\mathrm{FISTA}}}{(k+1)^{2}},$$\n你的推导必须用 $L$ 和 $\\|x_{0} - x^{\\star}\\|_{2}^{2}$ 明确表示常数 $C_{\\mathrm{ISTA}}$ 和 $C_{\\mathrm{FISTA}}$，其中 $x_{0}$ 是初始迭代点，$x^{\\star}$ 是 $F$ 的任意一个最小化点。\n\n然后，在给定以下特定实例的情况下，计算这些常数：\n$$A = \\begin{pmatrix} 3  0  0 \\\\ 0  1  0 \\\\ 0  0  2 \\end{pmatrix}, \\quad b = 0, \\quad \\lambda > 0, \\quad x_{0} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\end{pmatrix}.$$\n计算此实例的 $L = \\|A\\|_{2}^{2}$ 和比率 $C_{\\mathrm{FISTA}} / C_{\\mathrm{ISTA}}$。将该比率作为最终答案。如果需要对任何中间量进行近似，请不要这样做；在整个过程中使用精确计算。最终答案必须是单个实数。", "solution": "所述问题是有效的。它在科学上基于凸优化的成熟理论，特别适用于复合函数的一阶方法。该问题是适定的、客观的，并包含了推导常数和计算其比率所需的所有必要信息。\n\n总体目标函数为 $F(x) = g(x) + h(x)$，其中 $g(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 是凸函数且具有 $L$-利普希茨连续梯度 $\\nabla g(x) = A^T(Ax-b)$，$h(x) = \\lambda \\|x\\|_{1}$ 是凸函数但不可微。梯度的利普希茨常数是 $L = \\|A^T A\\|_2 = \\|A\\|_2^2$。$F$ 的最小化点用 $x^\\star$ 表示。\n\n**第一部分：ISTA 收敛速率常数的推导**\n\n迭代收缩阈值算法 (ISTA) 是一种近端梯度法。对于步长 $\\alpha$，其更新规则由下式给出：\n$$x_{k+1} = \\mathrm{prox}_{\\alpha h}(x_k - \\alpha \\nabla g(x_k))$$\n问题指定步长为 $\\alpha = 1/L$。\n收敛速率的推导依赖于一个我们首先要建立的关键不等式。\n根据定义，具有 $L$-利普希茨梯度的函数 $g$ 满足下降引理：对于任意 $x, y$，\n$$g(y) \\leq g(x) + \\langle \\nabla g(x), y-x \\rangle + \\frac{L}{2} \\|y-x\\|_{2}^{2}$$\n令 $x_k$ 为当前迭代点，$x_{k+1}$ 为步长为 $\\alpha = 1/L$ 的 ISTA 生成的下一个迭代点。\n在下降引理中令 $x=x_k$ 和 $y=x_{k+1}$，我们有：\n$$g(x_{k+1}) \\leq g(x_k) + \\langle \\nabla g(x_k), x_{k+1}-x_k \\rangle + \\frac{L}{2} \\|x_{k+1}-x_k\\|_{2}^{2}$$\n近端算子更新 $x_{k+1} = \\mathrm{prox}_{h/L}(x_k - \\frac{1}{L} \\nabla g(x_k))$ 是函数 $u \\mapsto \\frac{L}{2} \\|u - (x_k - \\frac{1}{L} \\nabla g(x_k))\\|_2^2 + h(u)$ 的唯一最小化子。\n$x_{k+1}$ 的最优性条件是 $0 \\in \\partial h(x_{k+1}) + L(x_{k+1} - (x_k - \\frac{1}{L} \\nabla g(x_k)))$，可简化为\n$$L(x_k - x_{k+1}) - \\nabla g(x_k) \\in \\partial h(x_{k+1})$$\n令 $\\xi_{k+1} = L(x_k - x_{k+1}) - \\nabla g(x_k)$ 为 $\\partial h(x_{k+1})$ 中的这个次梯度。根据凸函数 $h$ 的次梯度定义，对于任意点 $y$：\n$$h(y) \\geq h(x_{k+1}) + \\langle \\xi_{k+1}, y-x_{k+1} \\rangle = h(x_{k+1}) + \\langle L(x_k - x_{k+1}) - \\nabla g(x_k), y-x_{k+1} \\rangle$$\n重新整理得到：\n$$h(x_{k+1}) \\leq h(y) - \\langle L(x_k - x_{k+1}) - \\nabla g(x_k), y-x_{k+1} \\rangle$$\n现在，考虑总函数值 $F(x_{k+1}) = g(x_{k+1}) + h(x_{k+1})$。\n$$F(x_{k+1}) \\leq \\left( g(x_k) + \\langle \\nabla g(x_k), x_{k+1}-x_k \\rangle + \\frac{L}{2} \\|x_{k+1}-x_k\\|_{2}^{2} \\right) + \\left( h(y) - \\langle L(x_k - x_{k+1}) - \\nabla g(x_k), y-x_{k+1} \\rangle \\right)$$\n$$F(x_{k+1}) \\leq g(x_k) + h(y) + \\langle \\nabla g(x_k), y-x_k \\rangle + \\frac{L}{2} \\|x_{k+1}-x_k\\|_{2}^{2} - L\\langle x_k - x_{k+1}, y-x_{k+1} \\rangle$$\n项 $\\langle x_k - x_{k+1}, y-x_{k+1} \\rangle$ 可以使用恒等式 $2\\langle a,b \\rangle = \\|a\\|^2+\\|b\\|^2-\\|a-b\\|^2$ 展开，其中 $a=x_k-x_{k+1}$ 且 $b=y-x_{k+1}$。我们得到 $2\\langle x_k - x_{k+1}, y-x_{k+1} \\rangle = \\|x_k-x_{k+1}\\|^2 + \\|y-x_{k+1}\\|^2 - \\|x_k-y\\|^2$。\n将其代入：\n$$F(x_{k+1}) \\leq g(x_k) + h(y) + \\langle \\nabla g(x_k), y-x_k \\rangle + \\frac{L}{2} \\|x_{k+1}-x_k\\|_{2}^{2} - \\frac{L}{2} \\left( \\|x_k-x_{k+1}\\|^2 + \\|y-x_{k+1}\\|^2 - \\|x_k-y\\|^2 \\right)$$\n$$F(x_{k+1}) \\leq g(x_k) + \\langle \\nabla g(x_k), y-x_k \\rangle + h(y) + \\frac{L}{2} \\left( \\|x_k-y\\|^2 - \\|x_{k+1}-y\\|^2 \\right)$$\n根据 $g$ 的凸性，我们有 $g(y) \\geq g(x_k) + \\langle \\nabla g(x_k), y-x_k \\rangle$。因此，$g(x_k) + \\langle \\nabla g(x_k), y-x_k \\rangle \\leq g(y)$。\n$$F(x_{k+1}) \\leq g(y) + h(y) + \\frac{L}{2} \\left( \\|x_k-y\\|^2 - \\|x_{k+1}-y\\|^2 \\right)$$\n这个不等式对任意 $y$ 都成立。我们选择 $y=x^\\star$，$F$ 的一个最小化点。\n$$F(x_{k+1}) - F(x^\\star) \\leq \\frac{L}{2} \\left( \\|x_k-x^\\star\\|_2^2 - \\|x_{k+1}-x^\\star\\|_2^2 \\right)$$\n令 $\\delta_k = F(x_k) - F(x^\\star)$。上述不等式为 $\\delta_{k+1} \\le \\frac{L}{2} (\\|x_k-x^\\star\\|_2^2 - \\|x_{k+1}-x^\\star\\|_2^2)$。\n将其从 $k=0$ 到 $K-1$ 求和：\n$$\\sum_{k=1}^{K} \\delta_k \\leq \\frac{L}{2} \\sum_{k=0}^{K-1} \\left( \\|x_k-x^\\star\\|_2^2 - \\|x_{k+1}-x^\\star\\|_2^2 \\right) = \\frac{L}{2} \\left( \\|x_0-x^\\star\\|_2^2 - \\|x_K-x^\\star\\|_2^2 \\right)$$\n因为 $\\|x_K-x^\\star\\|_2^2 \\geq 0$，我们有 $\\sum_{k=1}^{K} \\delta_k \\leq \\frac{L}{2} \\|x_0-x^\\star\\|_2^2$。\n对于步长 $\\alpha \\le 1/L$ 的 ISTA，函数值序列 $\\{F(x_k)\\}$ 是非增的。因此，$\\{\\delta_k\\}$ 是一个非增的非负数序列。\n这意味着对所有 $k \\leq K$，$\\delta_K \\leq \\delta_k$。\n因此，$K \\delta_K \\leq \\sum_{k=1}^{K} \\delta_k$。\n结合这些结果：\n$$K \\delta_K \\leq \\frac{L}{2} \\|x_0-x^\\star\\|_2^2 \\implies \\delta_K \\leq \\frac{L \\|x_0-x^\\star\\|_2^2}{2K}$$\n将 $K$ 替换为 $k$，我们得到第 $k$ 次迭代的界限：\n$$F(x_k) - F(x^\\star) \\leq \\frac{L \\|x_0-x^\\star\\|_2^2}{2k}$$\n将此与指定形式 $F(x_k) - F(x^\\star) \\leq \\frac{C_{\\mathrm{ISTA}}}{k}$ 进行比较，我们确定常数为：\n$$C_{\\mathrm{ISTA}} = \\frac{L}{2} \\|x_0-x^\\star\\|_2^2$$\n\n**第二部分：FISTA 收敛速率常数的推导**\n\n快速迭代收缩阈值算法 (FISTA) 使用一种 Nesterov 型加速方案。其 $O(1/k^2)$ 速率的推导要复杂得多。它依赖于一个精心构造的势函数或李雅普诺夫函数以及一个特定的动量参数序列。我们在此概述其主要思想。\n\nFISTA 的更新步骤如下：\n1. $x_k = \\mathrm{prox}_{h/L}(y_k - \\frac{1}{L}\\nabla g(y_k))$\n2. $t_{k+1} = \\frac{1+\\sqrt{1+4t_k^2}}{2}$\n3. $y_{k+1} = x_k + \\frac{t_k-1}{t_{k+1}}(x_k-x_{k-1})$\n初始化为 $t_1=1$, $y_1=x_0$ 和 $x_{-1}=x_0$。\n\n证明策略涉及操作与 ISTA 相同的基本不等式，但应用于迭代点 $x_k$ 和外推点 $y_k$ 的混合。由此建立一个递归关系。证明中的关键不等式（例如，Beck  Teboulle, 2009 的定理 4.4 或 Nocedal  Wright, 2006 \"Numerical Optimization\" 的定理 10.35）具有以下形式：\n$$t_k^2(F(x_k)-F(x^\\star)) - t_{k-1}^2(F(x_{k-1})-F(x^\\star)) \\le \\frac{L}{2}(\\|u_{k-1}\\|^2 - \\|u_k\\|^2)$$\n其中 $u_k$ 是一个与迭代点相关的辅助向量序列。将这个不等式从 $k=1$ 到 $K$ 求和，会在右侧产生一个伸缩和。这导出一个形如下式的不等式：\n$$t_K^2(F(x_K)-F(x^\\star)) \\le \\frac{L}{2}\\|x_0-x^\\star\\|_2^2$$\n参数序列满足 $t_K \\ge \\frac{K+1}{2}$。代入此式可得：\n$$(\\frac{K+1}{2})^2 (F(x_K)-F(x^\\star)) \\le \\frac{L}{2}\\|x_0-x^\\star\\|_2^2$$\n$$F(x_K)-F(x^\\star) \\le \\frac{2L\\|x_0-x^\\star\\|_2^2}{(K+1)^2}$$\n一些证明会得出略有不同的常数，或者对 $k^2$ 与 $(k+1)^2$ 的依赖关系不同。问题中指定的形式 $\\frac{C_{\\mathrm{FISTA}}}{(k+1)^2}$ 是一个标准结果。与我们推导出的界进行比较，我们确定常数为：\n$$C_{\\mathrm{FISTA}} = 2L \\|x_0-x^\\star\\|_2^2$$\n\n**第三部分：针对特定实例的计算**\n\n我们给定了特定实例：\n$$A = \\begin{pmatrix} 3  0  0 \\\\ 0  1  0 \\\\ 0  0  2 \\end{pmatrix}, \\quad b = 0, \\quad \\lambda > 0, \\quad x_{0} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\end{pmatrix}$$\n首先，我们计算必要的量。\n1.  **利普希茨常数 $L$**：\n    $L = \\|A\\|_2^2$。谱范数 $\\|A\\|_2$ 是 $A$ 的最大奇异值。由于 $A$ 是一个对角矩阵，其奇异值是对角线元素的绝对值：$\\{|3|, |1|, |2|\\}$。最大奇异值为 $3$。\n    因此，$L = 3^2 = 9$。\n\n2.  **最优解 $x^\\star$**：\n    我们必须找到 $F(x) = \\frac{1}{2}\\|Ax\\|_2^2 + \\lambda\\|x\\|_1$ 的最小化点。\n    目标函数是 $F(x) = \\frac{1}{2}( (3x_1)^2 + (1x_2)^2 + (2x_3)^2 ) + \\lambda(|x_1|+|x_2|+|x_3|)$。\n    $F(x) = \\frac{1}{2}(9x_1^2 + x_2^2 + 4x_3^2) + \\lambda(|x_1|+|x_2|+|x_3|)$。\n    对于任何 $x$，两项都是非负的。第一项为零当且仅当 $x=0$。第二项为零当且仅当 $x=0$（因为 $\\lambda > 0$）。\n    因此，$F(x)$ 仅在 $x=0$ 处达到其最小值 $0$。唯一最小化点是 $x^\\star = 0$。\n\n3.  **到最优点的初始距离 $\\|x_0 - x^\\star\\|_2^2$**：\n    由于 $x^\\star = 0$，我们有 $x_0 - x^\\star = x_0 = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\end{pmatrix}$。\n    $\\|x_0 - x^\\star\\|_2^2 = 1^2 + 2^2 + 2^2 = 1 + 4 + 4 = 9$。\n\n现在我们可以表示此实例的常数：\n$$C_{\\mathrm{ISTA}} = \\frac{L}{2} \\|x_0 - x^\\star\\|_2^2 = \\frac{9}{2} \\times 9 = \\frac{81}{2}$$\n$$C_{\\mathrm{FISTA}} = 2L \\|x_0 - x^\\star\\|_2^2 = 2 \\times 9 \\times 9 = 162$$\n\n**第四部分：计算比率**\n\n最后一步是计算比率 $C_{\\mathrm{FISTA}} / C_{\\mathrm{ISTA}}$。\n$$\\frac{C_{\\mathrm{FISTA}}}{C_{\\mathrm{ISTA}}} = \\frac{2L \\|x_0 - x^\\star\\|_2^2}{\\frac{L}{2} \\|x_0 - x^\\star\\|_2^2} = \\frac{2}{1/2} = 4$$\n只要 $L$ 和 $\\|x_0-x^\\star\\|_2^2$ 的具体值非零，该比率就与它们无关。它反映了两种算法推导出的上界的根本差异。", "answer": "$$\n\\boxed{4}\n$$", "id": "3439144"}, {"introduction": "在实践中，精确的 Lipschitz 常数 $L$ 可能难以或耗费巨大代价计算，因此人们常常使用一个安全的上界 $L' \\gt L$。本练习探讨了这种选择对 FISTA 性能的实际影响。您将分析将 $L$ 高估一个因子 $c$ 会如何影响理论误差界和达到目标精度所需的迭代次数，从而揭示关于算法鲁棒性的重要见解。[@problem_id:3439173]", "problem": "考虑压缩感知中的复合凸优化问题，其目标是最小化目标函数 $$F(x) = f(x) + g(x),$$ 其中 $$f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2} \\quad \\text{与} \\quad g(x) = \\lambda \\|x\\|_{1},$$ 其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个传感矩阵，$b \\in \\mathbb{R}^{m}$ 是一个给定的测量向量，而 $\\lambda > 0$ 是一个正则化参数。梯度 $\\nabla f$ 是 Lipschitz 连续的，其最小的有效 Lipschitz 常数为 $L = \\sigma_{\\max}(A)^{2}$，其中 $\\sigma_{\\max}(A)$ 表示 $A$ 的最大奇异值。假设应用快速迭代收缩阈值算法（FISTA, Fast Iterative Shrinkage-Thresholding Algorithm），采用恒定步长 $t = 1/L'$ 和标准的 Nesterov 型加速参数，其中 $L' = c L$，因子 $c > 1$（即，Lipschitz 常数被一个乘法因子 $c$ 高估了）。\n\n仅使用 $f$ 的基本平滑上界和 $g$ 的凸性，从不等式\n$$f(y) \\leq f(x) + \\langle \\nabla f(x), y - x \\rangle + \\frac{L}{2}\\|y - x\\|_{2}^{2},$$\n以及用任何 $L' \\geq L$ 构建的代理模型都是 $f$ 的有效上模型的性质出发。从这些原理出发，推导 FISTA 的函数值精度界如何随 $L'$ 变化（不要先验地假设或引用任何显式的收敛速率公式；相反，应从二次上模型的齐次性和加速势能函数的构造进行推理）。然后：\n\n1. 在固定的迭代索引 $k$ 处，确定当 $L'$ 被 $c L$ 替换时，函数值误差界中的确切乘法减速因子。\n2. 对于固定的目标精度水平 $\\varepsilon > 0$，确定迭代复杂度（保证 $F(x_{k}) - F(x^{\\star}) \\leq \\varepsilon$ 所需的迭代次数）中的确切乘法减速因子，同样是在 $L'$ 被 $c L$ 替换的情况下。\n\n最后，通过表达当使用 Frobenius 范数界 $L' = \\|A\\|_{F}^{2}$ 代替谱范数界 $L = \\sigma_{\\max}(A)^{2}$ 时出现的过高估计因子 $c$，在病态传感矩阵的背景下说明这些减速，并解释奇异值分布如何影响减速。你的最终答案必须是第 1 部分和第 2 部分的减速因子对，以行矩阵的形式用 $c$ 表示。不需要四舍五入，也没有物理单位。", "solution": "该问题要求分析当目标函数光滑部分的梯度 Lipschitz 常数被高估时，快速迭代收缩阈值算法（FISTA）的收敛速率。我们需要确定误差界和迭代复杂度方面的减速情况。\n\n优化问题是最小化 $F(x) = f(x) + g(x)$，其中 $f(x) = \\frac{1}{2}\\|A x - b\\|_{2}^{2}$ 且 $g(x) = \\lambda \\|x\\|_{1}$。函数 $f(x)$ 是凸且连续可微的，其梯度 $\\nabla f(x) = A^T(Ax-b)$ 是 Lipschitz 连续的，常数为 $L = \\sigma_{\\max}(A)^2$。函数 $g(x)$ 是凸但非光滑的。\n\nFISTA 是一种加速的近端梯度法。其分析的一个关键要素是 $f(x)$ 的二次上界，该上界由其梯度的 Lipschitz 连续性保证。对于任何 $L' \\geq L$，我们有以下上界不等式：\n$$\nf(y) \\leq f(x) + \\langle \\nabla f(x), y - x \\rangle + \\frac{L'}{2}\\|y - x\\|_{2}^{2}, \\quad \\forall x, y \\in \\mathbb{R}^n.\n$$\n这个不等式是我们推导的起点。\n\nFISTA 算法在第 $k$ 次迭代时，通过执行一个近端梯度步，从搜索点 $y_k$ 生成一个新的迭代点 $x_{k+1}$。这一步可以看作是最小化一个围绕 $y_k$ 的 $F(x)$ 的代理函数：\n$$\nx_{k+1} = \\underset{x \\in \\mathbb{R}^n}{\\arg\\min} \\left\\{ f(y_k) + \\langle \\nabla f(y_k), x - y_k \\rangle + \\frac{L'}{2}\\|x - y_k\\|_{2}^{2} + g(x) \\right\\}.\n$$\n所用的步长是 $t = 1/L'$。令最小化的代理函数为 $Q_{L'}(x, y_k)$。因为 $L' \\geq L$，这是 $F(x)$ 的一个上界：对于所有 $x$，$F(x) \\le Q_{L'}(x, y_k)$。因此，$F(x_{k+1}) \\le Q_{L'}(x_{k+1}, y_k)$。由于 $x_{k+1}$ 是 $Q_{L'}(x, y_k)$ 的最小化子，我们对于任何 $x \\in \\mathbb{R}^n$ 都有 $Q_{L'}(x_{k+1}, y_k) \\le Q_{L'}(x, y_k)$。\n\n将这些事实与 $f$ 和 $g$ 的凸性结合，可以推导出一个控制单次迭代进展的基本不等式。对于任何 $x \\in \\mathbb{R}^n$：\n\\begin{align*}\nF(x_{k+1}) - F(x)  \\le Q_{L'}(x_{k+1}, y_k) - F(x) \\\\\n \\le Q_{L'}(x, y_k) - F(x) \\\\\n = \\left( f(y_k) + \\langle \\nabla f(y_k), x - y_k \\rangle + \\frac{L'}{2}\\|x - y_k\\|_{2}^{2} + g(x) \\right) - (f(x) + g(x)) \\\\\n = (f(y_k) - f(x) + \\langle \\nabla f(y_k), x - y_k \\rangle) + \\frac{L'}{2}\\|x - y_k\\|_{2}^{2}.\n\\end{align*}\n根据 $f$ 的凸性，我们有 $f(y_k) - f(x) + \\langle \\nabla f(y_k), x - y_k \\rangle \\le 0$。这导致 $F(x_{k+1}) - F(x) \\le \\frac{L'}{2}\\|x-y_k\\|_2^2$。虽然这是正确的，但并非最紧的界。按照题目的要求，一个更仔细的推导涉及到使用近端步的最优性条件以及 $f$ 和 $g$ 的凸性定义。这导出了众所周知的不等式：\n$$\nF(x_{k+1}) - F(x) \\le \\frac{L'}{2} \\left[ \\|x - y_k\\|_{2}^{2} - \\|x - x_{k+1}\\|_{2}^{2} \\right].\n$$\n这个不等式是 FISTA 收敛性分析的核心。“加速势能函数构造”指的是将此不等式（在 $x = x_k$ 和 $x = x^{\\star}$ 处求值，其中 $x^{\\star}$ 是 $F$ 的一个最小化子）与 $y_k$ 的特定 Nesterov 动量规则相结合。这个过程构造了一个 Lyapunov 函数来证明收敛速率。标准分析表明，对于动量参数的适当选择，函数值误差 $F(x_k) - F(x^{\\star})$ 的界为：\n$$\nF(x_k) - F(x^{\\star}) \\leq \\frac{\\alpha L' \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2},\n$$\n其中 $\\alpha$ 是一个常数（对于 $t_k \\ge k/2$ 的常见 FISTA 变体，通常 $\\alpha=2$）。关键点在于，该界与算法步长中使用的 Lipschitz 常数 $L'$ 成正比。“二次上模型的齐次性”意味着二次项的系数 $\\frac{L'}{2}$ 随 $L'$ 线性缩放，并且这种线性缩放直接传递到最终的收敛速率界。\n\n我们用 $B(k, L') = \\frac{\\alpha L' \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2}$ 表示误差界。我们感兴趣的是，当用一个高估的常数 $L' = cL$（其中 $c > 1$）替换最优常数 $L = \\sigma_{\\max}(A)^2$ 时会发生什么。\n\n**1. 函数值误差界中的乘法减速因子**\n\n在固定的迭代次数 $k$ 下，我们比较使用 $L$ 得到的误差界和使用 $L' = cL$ 得到的误差界。\n使用最优常数的界是 $B(k, L) = \\frac{\\alpha L \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2}$。\n使用高估常数的界是 $B(k, cL) = \\frac{\\alpha (cL) \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2}$。\n\n误差界的乘法因子增量是其比率：\n$$\n\\frac{B(k, cL)}{B(k, L)} = \\frac{\\frac{\\alpha c L \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2}}{\\frac{\\alpha L \\|x_0 - x^{\\star}\\|_{2}^{2}}{k^2}} = c.\n$$\n因此，将 Lipschitz 常数高估一个因子 $c$，会导致在任何给定的迭代次数 $k$ 下，理论误差界增大 $c$ 倍。\n\n**2. 迭代复杂度中的乘法减速因子**\n\n迭代复杂度指的是达到所需精度 $\\varepsilon > 0$ 所需的迭代次数。设 $K(L', \\varepsilon)$ 是保证 $F(x_k) - F(x^{\\star}) \\leq \\varepsilon$ 所需的最小迭代次数 $k$。\n\n使用常数 $L$，我们需要找到 $k_1 = K(L, \\varepsilon)$ 使得：\n$$\n\\frac{\\alpha L \\|x_0 - x^{\\star}\\|_{2}^{2}}{k_1^2} \\leq \\varepsilon \\implies k_1^2 \\geq \\frac{\\alpha L \\|x_0 - x^{\\star}\\|_{2}^{2}}{\\varepsilon} \\implies k_1 \\geq \\sqrt{\\frac{\\alpha L}{\\varepsilon}} \\|x_0 - x^{\\star}\\|_{2}.\n$$\n使用常数 $L' = cL$，我们需要找到 $k_2 = K(cL, \\varepsilon)$ 使得：\n$$\n\\frac{\\alpha (cL) \\|x_0 - x^{\\star}\\|_{2}^{2}}{k_2^2} \\leq \\varepsilon \\implies k_2^2 \\geq \\frac{\\alpha cL \\|x_0 - x^{\\star}\\|_{2}^{2}}{\\varepsilon} \\implies k_2 \\geq \\sqrt{\\frac{\\alpha cL}{\\varepsilon}} \\|x_0 - x^{\\star}\\|_{2}.\n$$\n迭代复杂度中的乘法减速因子是所需迭代次数的比率：\n$$\n\\frac{k_2}{k_1} \\approx \\frac{\\sqrt{\\frac{\\alpha cL}{\\varepsilon}} \\|x_0 - x^{\\star}\\|_{2}}{\\sqrt{\\frac{\\alpha L}{\\varepsilon}} \\|x_0 - x^{\\star}\\|_{2}} = \\sqrt{c}.\n$$\n因此，将 Lipschitz 常数高估一个因子 $c$，会使达到给定精度所需的迭代次数增加一个因子 $\\sqrt{c}$。\n\n**使用 Frobenius 范数的说明**\n\n问题建议用一个例子来说明，其中紧的 Lipschitz 常数 $L = \\sigma_{\\max}(A)^2$ 被更易于计算的上界 $L' = \\|A\\|_F^2$ 所取代。矩阵 $A$ 的 Frobenius 范数与其奇异值 $\\sigma_i(A)$ 的关系为 $\\|A\\|_F^2 = \\sum_{i=1}^{\\text{rank}(A)} \\sigma_i(A)^2$。最大奇异值为 $\\sigma_{\\max}(A) = \\sigma_1(A)$（假设奇异值已排序 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots$）。\n过高估计因子 $c$ 是：\n$$\nc = \\frac{L'}{L} = \\frac{\\|A\\|_{F}^{2}}{\\sigma_{\\max}(A)^2} = \\frac{\\sum_{i=1}^{\\text{rank}(A)} \\sigma_i(A)^2}{\\sigma_1(A)^2} = 1 + \\frac{\\sum_{i=2}^{\\text{rank}(A)} \\sigma_i(A)^2}{\\sigma_1(A)^2}.\n$$\n由于 $\\sigma_i(A)^2 \\geq 0$，我们有 $c \\geq 1$。$c$ 的大小取决于奇异值的分布。\n- 如果矩阵在数值上是秩为 1 的，或者其奇异值衰减非常快（对于 $i > 1$，有 $\\sigma_1 \\gg \\sigma_i$），那么和 $\\sum_{i=2}^{\\text{rank}(A)} \\sigma_i(A)^2$ 与 $\\sigma_1(A)^2$ 相比会很小，并且 $c$ 将接近于 1。在这种情况下，减速是微不足道的。\n- 如果奇异值相对平坦（许多 $\\sigma_i$ 的量级与 $\\sigma_1$ 相似），那么 $c$ 可能会很大。在所有非零奇异值都相等的极端情况下，$c = \\text{rank}(A)$。\n- 一个“病态”矩阵（大的 $\\sigma_1/\\sigma_{\\text{rank}(A)}$）不一定意味着大的 $c$。如上所示，大的 $c$ 是由奇异值谱的平坦性引起的，而不必是最大和最小奇异值之间的大比率。一个所有 $\\sigma_i$ 都相等的良态矩阵，对于给定的秩，会产生可能的最大 $c$ 值。\n\n因此，当传感矩阵 $A$ 的“能量”（奇异值平方和）分布在许多奇异值上，而不是集中在少数几个主导奇异值上时，使用 Frobenius 范数界是最不利的，会导致因子为 $c$ 和 $\\sqrt{c}$ 的显著减速。\n\n这两个减速因子分别是误差界的 $c$ 和迭代复杂度的 $\\sqrt{c}$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nc  \\sqrt{c}\n\\end{pmatrix}\n}\n$$", "id": "3439173"}]}