{"hands_on_practices": [{"introduction": "要真正掌握蒙特卡洛方法，我们首先需要从最基本的情景开始建立直觉。这个练习将蒙特卡洛方法简化为其最核心的随机成分：估计一个事件发生的概率。通过为一个简单的示性函数推导估计量的方差，我们可以清晰地看到被积函数的性质是如何直接影响估计不确定性的，这是学会评估蒙特卡洛模拟性能的第一步。[@problem_id:3301580]", "problem": "考虑在定义域 $D=[0,1]$ 上对被积函数 $h(x)=\\mathbf{1}\\{x\\le t\\}$ 进行原始蒙特卡洛积分，其中 $t\\in[0,1]$ 是固定的，$\\mathbf{1}\\{\\cdot\\}$ 表示指示函数。设 $X_{1},X_{2},\\dots,X_{n}$ 是来自 $[0,1]$ 上连续均匀分布的独立同分布样本，记为 $X_{i}\\sim\\mathrm{Uniform}(0,1)$，并将积分 $I=\\int_{0}^{1}h(x)\\,dx$ 的原始蒙特卡洛估计量定义为\n$$\n\\hat I_{n}=\\frac{1}{n}\\sum_{i=1}^{n}h(X_{i}).\n$$\n从独立同分布随机变量的期望和方差的核心定义出发，当 $h(x)=\\mathbf{1}\\{x\\le t\\}$ 时，推导 $\\mathrm{Var}(\\hat I_{n})$ 作为 $n$ 和 $t$ 的函数的精确闭式表达式。然后，仅根据 $t$ 来解释 $t$ 的选择如何影响 $\\hat I_{n}$ 的变异性，方法是找出使方差最小化和最大化的 $t$ 值，并解释在 $t\\in[0,1]$ 上的定性行为。最终答案必须是 $\\mathrm{Var}(\\hat I_{n})$ 的闭式表达式。无需四舍五入。", "solution": "该问题陈述定义明确、自成体系，并且在科学上基于概率论和蒙特卡洛方法的原理。它是随机模拟中的一个标准问题。因此，该问题是有效的，并将推导出一个解。\n\n目标是推导原始蒙特卡洛估计量 $\\mathrm{Var}(\\hat I_{n})$ 方差的闭式表达式。该估计量由下式给出\n$$\n\\hat I_{n}=\\frac{1}{n}\\sum_{i=1}^{n}h(X_{i}),\n$$\n其中 $X_{1}, X_{2}, \\dots, X_{n}$ 是来自 $\\mathrm{Uniform}(0,1)$ 分布的独立同分布 (i.i.d.) 随机变量，被积函数为 $h(x)=\\mathbf{1}\\{x\\le t\\}$，对于一个固定的 $t\\in[0,1]$。\n\n我们首先应用方差的性质。鉴于样本 $X_i$ 是独立同分布的，变换后的随机变量 $Y_i = h(X_i)$ 也是独立同分布的。\n估计量 $\\hat I_n$ 的方差是：\n$$\n\\mathrm{Var}(\\hat I_{n}) = \\mathrm{Var}\\left(\\frac{1}{n}\\sum_{i=1}^{n}h(X_{i})\\right)\n$$\n使用性质 $\\mathrm{Var}(aZ) = a^2\\mathrm{Var}(Z)$，其中 $a = \\frac{1}{n}$ 且 $Z = \\sum_{i=1}^{n}h(X_{i})$，我们得到：\n$$\n\\mathrm{Var}(\\hat I_{n}) = \\frac{1}{n^2}\\mathrm{Var}\\left(\\sum_{i=1}^{n}h(X_{i})\\right)\n$$\n由于随机变量 $h(X_i)$ 是独立的，它们和的方差等于它们方差的和：\n$$\n\\mathrm{Var}\\left(\\sum_{i=1}^{n}h(X_{i})\\right) = \\sum_{i=1}^{n}\\mathrm{Var}(h(X_{i}))\n$$\n此外，由于 $h(X_i)$ 是同分布的，它们的方差都相等。设对所有 $i=1,\\dots,n$，$\\mathrm{Var}(h(X_i)) = \\sigma_h^2$。\n$$\n\\sum_{i=1}^{n}\\mathrm{Var}(h(X_{i})) = n \\cdot \\mathrm{Var}(h(X_1))\n$$\n将此代入 $\\mathrm{Var}(\\hat I_{n})$ 的表达式中：\n$$\n\\mathrm{Var}(\\hat I_{n}) = \\frac{1}{n^2} \\left( n \\cdot \\mathrm{Var}(h(X_1)) \\right) = \\frac{1}{n}\\mathrm{Var}(h(X_1))\n$$\n现在，我们必须计算 $\\mathrm{Var}(h(X_1))$。我们使用公式 $\\mathrm{Var}(Z) = \\mathrm{E}[Z^2] - (\\mathrm{E}[Z])^2$。在我们的例子中，$Z = h(X_1) = \\mathbf{1}\\{X_1 \\le t\\}$。\n\n首先，我们计算期望 $\\mathrm{E}[h(X_1)]$。\n随机变量 $h(X_1)$ 只能取两个值：如果 $X_1 \\le t$，则为 $1$；如果 $X_1 > t$，则为 $0$。这是一个伯努利随机变量。它的期望是它等于 $1$ 的概率。\n$$\np = P(h(X_1) = 1) = P(X_1 \\le t)\n$$\n由于 $X_1 \\sim \\mathrm{Uniform}(0,1)$，其概率密度函数 (PDF) 为 $f(x) = 1$（对于 $x \\in [0,1]$）否则为 $0$。其在 $x \\in [0,1]$ 上的累积分布函数 (CDF) 为 $F(x) = x$。对于给定的 $t \\in [0,1]$：\n$$\nP(X_1 \\le t) = \\int_0^t f(x) \\, dx = \\int_0^t 1 \\, dx = t\n$$\n因此，$h(X_1)$ 是一个参数为 $p=t$ 的伯努利随机变量。\n期望是：\n$$\n\\mathrm{E}[h(X_1)] = t\n$$\n接下来，我们计算 $\\mathrm{E}[(h(X_1))^2]$。由于 $h(X_1)$ 是一个指示函数，其值要么是 $0$ 要么是 $1$。因此，$(h(X_1))^2$ 与 $h(X_1)$ 相同，因为 $0^2=0$ 且 $1^2=1$。\n$$\n(h(X_1))^2 = h(X_1)\n$$\n这意味着：\n$$\n\\mathrm{E}[(h(X_1))^2] = \\mathrm{E}[h(X_1)] = t\n$$\n现在我们可以计算 $h(X_1)$ 的方差：\n$$\n\\mathrm{Var}(h(X_1)) = \\mathrm{E}[(h(X_1))^2] - (\\mathrm{E}[h(X_1)])^2 = t - t^2 = t(1-t)\n$$\n这是伯努利($t$)随机变量的众所周知的方差。\n\n最后，我们将此结果代入 $\\mathrm{Var}(\\hat I_{n})$ 的表达式中：\n$$\n\\mathrm{Var}(\\hat I_{n}) = \\frac{1}{n} \\mathrm{Var}(h(X_1)) = \\frac{t(1-t)}{n}\n$$\n这是估计量方差作为 $n$ 和 $t$ 的函数的精确闭式表达式。\n\n对于解释部分，我们分析对于固定的样本数 $n$，方差 $\\mathrm{Var}(\\hat I_{n})$ 如何随 $t \\in [0,1]$ 变化。变异性由项 $v(t) = t(1-t)$ 决定。这是 $t$ 的一个二次函数，表示一个开口向下、根在 $t=0$ 和 $t=1$ 的抛物线。\n- **最小化**：在区间 $[0,1]$ 上，$v(t)$ 的最小值出现在端点处。\n  - 在 $t=0$ 时，$v(0) = 0(1-0) = 0$，所以 $\\mathrm{Var}(\\hat I_n) = 0$。在这种情况下，$h(x) = \\mathbf{1}\\{x \\le 0\\}$，对于所有 $x \\in (0,1]$ 均为 $0$。所有样本 $h(X_i)$ 将以概率 $1$ 为 $0$，因此估计量的方差为零。\n  - 在 $t=1$ 时，$v(1) = 1(1-1) = 0$，所以 $\\mathrm{Var}(\\hat I_n) = 0$。在这种情况下，$h(x) = \\mathbf{1}\\{x \\le 1\\}$，对于所有 $x \\in [0,1]$ 均为 $1$。所有样本 $h(X_i)$ 将为 $1$，因此估计量的方差同样为零。\n在这两种情况下，被积函数在抽样分布的有效支撑集上是常数，导致没有抽样误差。\n- **最大化**：抛物线 $v(t) = -t^2 + t$ 的最大值出现在其顶点，即 $t = -\\frac{1}{2(-1)} = \\frac{1}{2}$。在这一点，值为 $v(\\frac{1}{2}) = \\frac{1}{2}(1-\\frac{1}{2}) = \\frac{1}{4}$。\n  - 方差在 $t=1/2$ 时最大化，得到 $\\mathrm{Var}(\\hat I_n) = \\frac{1}{4n}$。这对应于伯努利试验 $h(X_i)$ 的最大不确定性情况。当 $t=1/2$ 时，一个样本 $X_i$ 小于或大于 $1/2$ 的可能性是相等的，这意味着 $h(X_i)$ 等可能地为 $1$ 或 $0$。单个样本中这种最大的随机性导致了其平均值的可能最高方差。\n\n总而言之，当问题是确定性的（$t=0$ 或 $t=1$）时，蒙特卡洛估计量的变异性为零；而当每个样本的不确定性最高时（$t=1/2$），变异性最大。", "answer": "$$\\boxed{\\frac{t(1-t)}{n}}$$", "id": "3301580"}, {"introduction": "理论理解必须与动手实践相结合。这个练习将引导您完成一个完整的蒙特卡洛工作流程：首先使用拒绝采样方法在一个非标准的复杂定义域上生成样本，然后利用这些样本来估计积分值。这项实践将巩固抽象公式与具体代码之间的联系，这是计算科学家必备的一项关键技能。[@problem_id:3301576]", "problem": "要求您设计、分析并实现一个拒绝采样算法，用于从集合 $$D=\\{x\\in[0,1]^2:\\,x_1+x_2 \\le 1\\}$$ 上的均匀分布 (Unif) 中抽取样本，并使用这些样本进行粗略蒙特卡洛 (MC) 积分。请从基本原理开始：可测集上均匀分布的定义、拒绝采样的定义，以及粗略蒙特卡洛积分的定义——即通过从一个其期望值与目标积分相关的分布中采样来估计积分值。\n\n构建一个拒绝采样方案，该方案使用来自正方形 $$S=[0,1]^2$$ 上均匀分布的提议样本，接受与否取决于提议的点是否位于 $D$ 内。根据基本定义，推导该方案的接受概率，并证明被接受的样本服从 $D$ 上的均匀分布。\n\n实现该算法以生成指定数量的接受样本（将此数量表示为 $N_{\\text{acc}}$），并记录所使用的提议样本总数 $N_{\\text{prop}}$。计算经验接受率 $\\hat{\\alpha}=N_{\\text{acc}}/N_{\\text{prop}}$。使用接受的样本 $\\{X^{(i)}\\}_{i=1}^{N_{\\text{acc}}}$（其中 $X^{(i)}\\in D$），通过将积分与 $D$ 上均匀分布下的期望以及 $D$ 的面积相关联，采用粗略蒙特卡洛积分法估计积分\n$$I_1=\\int_D x_1 x_2\\,\\mathrm{d}x \\quad\\text{and}\\quad I_2=\\int_D (x_1+x_2)\\,\\mathrm{d}x,$$\n\n您的程序必须实现以下确定性测试套件，并为每个测试用例生成结果：\n\n- 测试用例 $1$：随机数生成器 (RNG) 种子 $12345$，接受样本目标数量 $N_{\\text{acc}}=1$。\n- 测试用例 $2$：RNG 种子 $202310$，接受样本目标数量 $N_{\\text{acc}}=5000$。\n- 测试用例 $3$：RNG 种子 $42$，接受样本目标数量 $N_{\\text{acc}}=20000$。\n\n对于每个测试用例，运行拒绝采样器直到正好有 $N_{\\text{acc}}$ 个点被接受，然后：\n- 计算并返回经验接受率 $\\hat{\\alpha}$（浮点数）。\n- 计算并返回 $I_1$ 和 $I_2$ 的粗略蒙特卡洛估计值（浮点数）。\n- 返回提议样本总数 $N_{\\text{prop}}$（整数）。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果本身就是一个列表 $[\\hat{\\alpha},\\,\\widehat{I}_1,\\,\\widehat{I}_2,\\,N_{\\text{prop}}]$。例如，最终输出应类似于 $[[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot]]$。此问题不涉及物理单位或角度。所有随机性必须由指定的 RNG 种子控制，以确保可复现性。在边界上使用包含性接受，即当 $x_1+x_2 \\le 1$ 时接受。", "solution": "该问题是有效的，因为它在科学上基于概率论和数值方法，是适定的、客观的、自洽的，并且在计算上是可行的。我们接下来给出一个完整的解决方案。\n\n该解决方案将从基本原理出发，从相关数学和算法概念的基本定义开始。\n\n**1. 理论框架**\n\n**a. 目标分布**\n目标是从集合 $D = \\{x \\in [0,1]^2 : x_1+x_2 \\le 1\\}$ 上的均匀分布中抽取样本。集合 $D$ 是平面上的一个直角三角形，顶点为 $(0,0)$、$(1,0)$ 和 $(0,1)$。该集合的面积（记作 $\\text{Area}(D)$）是一个标准的几何结论：\n$$\n\\text{Area}(D) = \\frac{1}{2} \\times \\text{base} \\times \\text{height} = \\frac{1}{2} \\times 1 \\times 1 = \\frac{1}{2}\n$$\n均匀分布在可测集 $A \\subset \\mathbb{R}^d$ 上的随机变量 $X$ 的概率密度函数 (PDF) 定义为：\n$$\nf_X(x) = \\begin{cases} 1/\\text{Area}(A)  \\text{if } x \\in A \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n因此，$D$ 上均匀分布的目标 PDF（我们记作 $p(x)$）为：\n$$\np(x) = \\begin{cases} 1/(1/2) = 2  \\text{if } x \\in D \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n这可以使用指示函数紧凑地写为 $p(x) = 2 \\cdot \\mathbb{I}_{D}(x)$。\n\n**b. 拒绝采样**\n拒绝采样是一种从目标分布（其 PDF 为 $p(x)$）生成样本的方法，适用于我们可以轻松地从另一个分布，即提议分布（其 PDF 为 $g(x)$）中采样的情况。一个必要条件是 $g(x)$ 的支撑集必须包含 $p(x)$ 的支撑集。此外，必须存在一个常数 $M  \\infty$，使得对于所有 $x$，都有 $p(x) \\le M \\cdot g(x)$。该算法按以下步骤进行：\n1. 从提议分布 $g(x)$ 中抽取一个样本 $Y$。\n2. 从 $[0, 1]$ 上的均匀分布中抽取一个样本 $U$。\n3. 如果 $U \\le \\frac{p(Y)}{M g(Y)}$，则接受样本 $Y$（即，令 $X=Y$）。否则，拒绝 $Y$ 并返回步骤 1。\n\n**c. 为 $D$ 构建采样器**\n问题指定使用正方形 $S = [0,1]^2$ 上的均匀分布作为提议分布。$S$ 的面积为 $\\text{Area}(S) = 1^2 = 1$。因此，提议 PDF $g(x)$ 为：\n$$\ng(x) = \\begin{cases} 1/\\text{Area}(S) = 1  \\text{if } x \\in S \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n$g(x)$ 的支撑集是 $S$，并且由于 $D \\subset S$，_g_($x$) 的支撑集包含 $p(x)$ 的支撑集。现在我们来寻找常数 $M$。我们需要对所有 $x$ 满足 $p(x) \\le M \\cdot g(x)$。\n- 如果 $x \\in D$，则 $p(x)=2$ 且 $g(x)=1$。条件为 $2 \\le M \\cdot 1$，所以 $M \\ge 2$。\n- 如果 $x \\in S \\setminus D$，则 $p(x)=0$ 且 $g(x)=1$。条件为 $0 \\le M \\cdot 1$，这对任何非负 $M$ 都成立。\n- 如果 $x \\notin S$，则 $p(x)=0$ 且 $g(x)=0$。条件成立。\n处处满足该不等式的最小 $M$ 值为 $M=2$。\n\n现在，我们分析使用 $M=2$ 时的接受条件 $U \\le \\frac{p(Y)}{M g(Y)}$：\n- 如果提议的样本 $Y$ 在 $D$ 内，则 $p(Y)=2$ 且 $g(Y)=1$。比率为 $\\frac{p(Y)}{M g(Y)} = \\frac{2}{2 \\cdot 1} = 1$。条件为 $U \\le 1$，这对于从 $\\text{Unif}(0,1)$ 中抽取的样本 $U$ 总是成立。\n- 如果提议的样本 $Y$ 在 $S \\setminus D$ 内，则 $p(Y)=0$ 且 $g(Y)=1$。比率为 $\\frac{p(Y)}{M g(Y)} = \\frac{0}{2 \\cdot 1} = 0$。条件为 $U \\le 0$，这几乎必然为假。\n\n这极大地简化了拒绝采样算法：\n1. 从 $S=[0,1]^2$ 上的均匀分布中提议一个样本 $Y=(Y_1, Y_2)$。这通过独立抽取 $Y_1 \\sim \\text{Unif}(0,1)$ 和 $Y_2 \\sim \\text{Unif}(0,1)$ 来实现。\n2. 如果 $Y \\in D$（即，如果 $Y_1 + Y_2 \\le 1$），则接受 $Y$。\n3. 否则，拒绝 $Y$ 并重复。\n\n**d. 接受概率与接受样本的分布**\n在单次试验中接受一个提议样本 $Y$ 的概率，记作 $\\alpha$，是 $Y$ 落入接受区域 $D$ 的概率。\n$$\n\\alpha = P(Y \\in D) = \\int_S \\mathbb{I}_D(y) g(y) \\, \\mathrm{d}y = \\int_D g(y) \\, \\mathrm{d}y\n$$\n由于对于所有 $y \\in D \\subset S$，_g_($y$)=1，我们有：\n$$\n\\alpha = \\int_D 1 \\, \\mathrm{d}y = \\text{Area}(D) = \\frac{1}{2}\n$$\n理论接受概率为 $\\alpha = 0.5$。获得一个接受样本所需的提议样本数 $N_{\\text{prop}}$ 服从成功概率为 $\\alpha$ 的几何分布。获得 $N_{\\text{acc}}$ 个样本的期望提议数为 $N_{\\text{acc}} / \\alpha$。\n\n为了确认接受的样本 $X$ 确实在 $D$ 上均匀分布，我们考虑一个接受的样本落入任意可测子集 $A \\subseteq D$ 的概率。\n$$\nP(X \\in A) = P(Y \\in A \\mid Y \\text{ is accepted}) = \\frac{P(Y \\in A \\text{ and } Y \\text{ is accepted})}{P(Y \\text{ is accepted})}\n$$\n由于 $A \\subseteq D$，一个样本 $Y \\in A$ 总会被接受。因此，_P_(_Y_ ∈ _A_ and _Y_ is accepted) = _P_(_Y_ ∈ _A_)。\n$$\nP(Y \\in A) = \\int_A g(y) \\, \\mathrm{d}y = \\int_A 1 \\, \\mathrm{d}y = \\text{Area}(A)\n$$\n分母是总接受概率，$P(Y \\text{ is accepted}) = \\alpha = \\text{Area}(D)$。因此，\n$$\nP(X \\in A) = \\frac{\\text{Area}(A)}{\\text{Area}(D)}\n$$\n这正是 $D$ 上均匀概率测度的定义。因此，得到的样本具有正确的分布。\n\n**2. 蒙特卡洛积分**\n\n我们希望估计形如 $I = \\int_D h(x) \\, \\mathrm{d}x$ 的积分。这个积分可以与 $h(X)$ 的期望相关联，其中 $X$ 是一个 PDF 为 $p(x) = \\text{Unif}(D)$ 的随机变量。\n$$\nE[h(X)] = \\int_D h(x) p(x) \\, \\mathrm{d}x = \\int_D h(x) \\frac{1}{\\text{Area}(D)} \\, \\mathrm{d}x\n$$\n整理后得到恒等式：\n$$\nI = \\int_D h(x) \\, \\mathrm{d}x = \\text{Area}(D) \\cdot E[h(X)]\n$$\n根据大数定律，期望 $E[h(X)]$ 可以通过对从 $p(x)$ 中抽取的 $N_{\\text{acc}}$ 个独立样本 $\\{X^{(i)}\\}_{i=1}^{N_{\\text{acc}}}$ 计算 $h$ 的样本均值来估计：\n$$\nE[h(X)] \\approx \\frac{1}{N_{\\text{acc}}} \\sum_{i=1}^{N_{\\text{acc}}} h(X^{(i)})\n$$\n将此代入 $I$ 的恒等式，得到粗略蒙特卡洛估计量 $\\widehat{I}$：\n$$\n\\widehat{I} = \\text{Area}(D) \\cdot \\frac{1}{N_{\\text{acc}}} \\sum_{i=1}^{N_{\\text{acc}}} h(X^{(i)})\n$$\n已知 $\\text{Area}(D)=1/2$，对于 $I_1 = \\int_D x_1 x_2 \\, \\mathrm{d}x$ 和 $I_2 = \\int_D (x_1+x_2) \\, \\mathrm{d}x$ 的具体估计量为：\n- 对于 $I_1$，令 $h_1(x) = x_1 x_2$。其估计量为：\n$$\n\\widehat{I}_1 = \\frac{1}{2} \\cdot \\frac{1}{N_{\\text{acc}}} \\sum_{i=1}^{N_{\\text{acc}}} X^{(i)}_1 X^{(i)}_2\n$$\n- 对于 $I_2$，令 $h_2(x) = x_1 + x_2$。其估计量为：\n$$\n\\widehat{I}_2 = \\frac{1}{2} \\cdot \\frac{1}{N_{\\text{acc}}} \\sum_{i=1}^{N_{\\text{acc}}} (X^{(i)}_1 + X^{(i)}_2)\n$$\n\n**3. 实现计划**\n实现将包含一个函数，该函数以 RNG 种子和接受样本的目标数量 $N_{\\text{acc}}$ 作为输入。\n1. 使用指定的种子初始化一个随机数生成器，以保证可复现性。\n2. 初始化一个空列表用于存放接受的样本，并将提议计数 $N_{\\text{prop}}$ 设置为 $0$。\n3. 循环直到接受的样本数量达到 $N_{\\text{acc}}$：\n    a. 将 $N_{\\text{prop}}$ 加一。\n    b. 通过从 $\\text{Unif}(0,1)$ 中抽取两个数来生成一个 $2$-维提议点 $x = (x_1, x_2)$。\n    c. 如果 $x_1 + x_2 \\le 1$，则将点 $x$ 添加到接受样本列表中。\n4. 循环终止后，计算所需的量：\n    a. 经验接受率：$\\hat{\\alpha} = N_{\\text{acc}} / N_{\\text{prop}}$。\n    b. 使用上面推导的公式，对收集到的样本应用，计算蒙特卡洛估计值 $\\widehat{I}_1$ 和 $\\widehat{I}_2$。\n    c. 提议样本总数 $N_{\\text{prop}}$。\n5. 返回这四个值：$[\\hat{\\alpha}, \\widehat{I}_1, \\widehat{I}_2, N_{\\text{prop}}]$。主程序将为每个指定的测试用例执行此逻辑，并将结果格式化为单个字符串。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the rejection sampling and Monte Carlo integration as per the problem description.\n    Runs a deterministic test suite and prints the results in the specified format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (RNG seed, Number of accepted samples N_acc)\n        (12345, 1),\n        (202310, 5000),\n        (42, 20000),\n    ]\n\n    all_results = []\n    for seed, N_acc in test_cases:\n        # Initialize the random number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n\n        accepted_samples = []\n        N_prop = 0\n\n        # Run the rejection sampler until exactly N_acc samples are collected.\n        while len(accepted_samples)  N_acc:\n            N_prop += 1\n            # Propose a point from the Uniform distribution on the unit square S = [0,1]^2.\n            # This is done by drawing two independent samples from Unif(0,1).\n            proposal_point = rng.random(size=2)\n            \n            # Acceptance condition: check if the point lies in the target set D.\n            # D = {x in [0,1]^2: x_1 + x_2 = 1}.\n            # The boundary condition x_1 + x_2 = 1 is inclusive as specified.\n            if proposal_point[0] + proposal_point[1] = 1.0:\n                accepted_samples.append(proposal_point)\n\n        # 1. Compute the empirical acceptance rate.\n        # This is the ratio of accepted samples to total proposals.\n        # The theoretical rate is Area(D)/Area(S) = (1/2)/1 = 0.5.\n        alpha_hat = N_acc / N_prop\n\n        # 2. Compute the crude Monte Carlo estimates of the integrals.\n        # The general formula is: I_hat = Area(D) * (1/N_acc) * sum(h(X_i)).\n        # Here, Area(D) = 0.5.\n        area_d = 0.5\n        \n        # Convert the list of samples to a NumPy array for efficient, vectorized calculations.\n        if N_acc  0:\n            samples_np = np.array(accepted_samples)\n            \n            # For I_1 = integral(x_1 * x_2), the function is h_1(x) = x_1 * x_2.\n            h1_values = samples_np[:, 0] * samples_np[:, 1]\n            mean_h1 = np.mean(h1_values)\n            I1_hat = area_d * mean_h1\n            \n            # For I_2 = integral(x_1 + x_2), the function is h_2(x) = x_1 + x_2.\n            h2_values = samples_np[:, 0] + samples_np[:, 1]\n            mean_h2 = np.mean(h2_values)\n            I2_hat = area_d * mean_h2\n        else: # This branch is not hit by the given test cases but is robust.\n            I1_hat = 0.0\n            I2_hat = 0.0\n\n        # 3. N_prop is the total number of proposals.\n        # It's an integer.\n\n        # Package the results for this test case.\n        case_result = [alpha_hat, I1_hat, I2_hat, N_prop]\n        all_results.append(case_result)\n\n    # Format the final output according to the problem specification.\n    # e.g., [[val,val,val,val],[val,val,val,val]]\n    inner_lists_str = []\n    for res in all_results:\n        # Format each inner list as '[v1,v2,v3,v4]' without extra spaces.\n        inner_str = '[' + ','.join(map(str, res)) + ']'\n        inner_lists_str.append(inner_str)\n    \n    final_output_str = '[' + ','.join(inner_lists_str) + ']'\n\n    # Final print statement in the exact required format.\n    print(final_output_str)\n\nsolve()\n```", "id": "3301576"}, {"introduction": "掌握任何一种方法的关键在于理解其适用范围和失效的场景。本问题将带您直面一个标准蒙特卡洛理论假设被打破的场景：被积函数的方差为无穷大。通过分析这个“重尾”分布的案例，您将理解为何中心极限定理可能不再适用，并学会识别这类在金融和物理学等领域中常见的挑战性问题。[@problem_id:3301536]", "problem": "考虑对定义域 $D=[0,1]$ 上的积分 $I=\\int_{0}^{1} h(x)\\,dx$ 进行粗略蒙特卡洛积分。设 $(X_i)_{i\\ge 1}$ 是一个独立同分布序列，其中 $X_i\\sim \\mathrm{Uniform}(0,1)$。粗略蒙特卡洛估计量为 $\\widehat I_n=\\frac{1}{n}\\sum_{i=1}^n h(X_i)$。要求您选出关于一个特定的重尾被积函数 $h$ 及其对方法估计和极限定理的影响的正确陈述。\n\n考虑被积函数 $h:D\\to [1,\\infty)$，其定义为：当 $x\\in(0,1]$ 时，$h(x)=x^{-3/4}$；当 $x=0$ 时，$h(0)=+\\infty$（在勒贝格意义下解释，因此 $h\\in L^1([0,1])$，但 $x=0$ 处的点奇点是可积的）。对于估计量 $\\widehat I_n$，请考虑以下陈述：\n\nA. $h\\in L^1([0,1])$ 但 $h\\notin L^2([0,1])$。\n\nB. $\\widehat I_n$ 是无偏的，满足强大数定律 (SLLN)，并且通常的中心极限定理 (CLT)（具有 $\\sqrt{n}$-归一化和有限的渐近方差）适用。\n\nC. $\\mathrm{Var}(h(X_1))=+\\infty$，且不存在 $\\mathrm{Var}(h(X_1))$ 的一致估计量；特别地，当 $n\\to\\infty$ 时，样本方差 $S_n^2=\\frac{1}{n-1}\\sum_{i=1}^n\\big(h(X_i)-\\widehat I_n\\big)^2$ 几乎必然发散到 $+\\infty$。\n\nD. $\\widehat I_n$ 的涨落遵循一个重尾广义极限定理：$n^{1/4}\\big(\\widehat I_n - I\\big)$ 依分布收敛到一个尾指数为 $\\alpha=\\frac{4}{3}$ 的非退化 $\\alpha$-稳定律（在中心化后），而 $\\sqrt{n}\\big(\\widehat I_n - I\\big)$ 依概率发散。\n\n选择所有正确的陈述。", "solution": "用户希望对问题陈述进行仔细验证，然后提供一个完整的解题过程，推导出正确答案并评估所有选项。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n-   待估计的积分是 $I=\\int_{0}^{1} h(x)\\,dx$。\n-   积分区域是 $D=[0,1]$。\n-   抽样使用独立同分布 (i.i.d.) 的随机变量序列 $(X_i)_{i\\ge 1}$，其中 $X_i\\sim \\mathrm{Uniform}(0,1)$。\n-   粗略蒙特卡洛估计量由 $\\widehat I_n=\\frac{1}{n}\\sum_{i=1}^n h(X_i)$ 给出。\n-   被积函数是 $h:D\\to [1,\\infty)$，定义为当 $x\\in(0,1]$ 时，$h(x)=x^{-3/4}$；当 $x=0$ 时，$h(0)=+\\infty$。\n-   已指明 $h$ 在勒贝格意义下解释，且 $h\\in L^1([0,1])$。\n\n**步骤 2：使用提取的已知条件进行验证**\n-   **科学基础：**该问题牢固地建立在数值积分、概率论和统计学等数学领域，特别是关于蒙特卡洛方法。它测试了对 $L^p$ 空间、大数定律 (LLN)、中心极限定理 (CLT) 以及针对重尾分布的广义中心极限定理（稳定律）的理解。所有概念都是标准的，并有严格的定义。\n-   **适定性：**该问题定义了一个特定的被积函数、一个抽样分布和一个估计量。然后要求验证关于该设置的几个数学性质的陈述。这些都是适定的问题，有唯一的、可验证的答案。\n-   **客观性：**该问题使用精确、客观的数学语言陈述。诸如“无偏”、“强大数定律”、“依分布收敛”和“$\\alpha$-稳定律”等术语都有无歧义的定义。\n-   **缺陷清单：**\n    1.  **科学/事实不健全：**无。该设置是一个经典例子，用来说明标准中心极限定理的失效和稳定律的出现。\n    2.  **无法形式化或不相关：**无。该问题完全可以形式化。\n    3.  **不完整或矛盾的设置：**无。该问题提供了所有必要信息。$h\\in L^1([0,1])$ 这一陈述是一个可以独立验证的前提，证实了设置的一致性。\n    4.  **不切实际或不可行：**不适用，因为这是一个纯数学问题。所用的数学构造是有效的。\n    5.  **不适定或结构不良：**无。\n    6.  **伪深刻、琐碎或同义反复：**该问题既不琐碎也非同义反复。它要求对概率论中可积性条件和极限定理之间不平凡的相互作用有扎实的理解。\n    7.  **超出科学可验证性范围：**所有主张在数学上都是可验证的。\n\n**步骤 3：结论与行动**\n问题陈述有效。我将继续进行解答。\n\n### 解题推导\n\n令 $Y_i = h(X_i)$ 为样本值。由于 $X_i$ 是独立同分布的 $\\mathrm{Uniform}(0,1)$ 变量，因此 $Y_i$ 也是独立同分布的随机变量。粗略蒙特卡洛估计量是这些变量的样本均值，$\\widehat I_n = \\frac{1}{n}\\sum_{i=1}^n Y_i$。\n\n问题的核心在于分析随机变量 $Y_1 = h(X_1)$ 的矩。其 $k$ 阶矩由 $E[Y_1^k] = E[(h(X_1))^k]$ 给出。根据无意识统计学家法则，这等于：\n$$E[(h(X_1))^k] = \\int_0^1 (h(x))^k f_{X_1}(x) dx$$\n由于 $X_1 \\sim \\mathrm{Uniform}(0,1)$，其概率密度函数为 $f_{X_1}(x) = 1$（对于 $x \\in [0,1]$）。因此：\n$$E[(h(X_1))^k] = \\int_0^1 (h(x))^k dx = \\int_0^1 (x^{-3/4})^k dx = \\int_0^1 x^{-3k/4} dx$$\n这个积分是 $\\int_0^1 x^{-p} dx$ 形式的标准 $p$-积分，它收敛当且仅当 $p  1$。在我们的例子中，收敛的条件是 $\\frac{3k}{4}  1$，即 $k  \\frac{4}{3}$。\n\n**1. 一阶矩（期望）：**\n对于 $k=1$，我们有 $p = \\frac{3(1)}{4} = \\frac{3}{4}  1$。积分收敛。\n$$I = E[Y_1] = \\int_0^1 x^{-3/4} dx = \\left[ \\frac{x^{-3/4+1}}{-3/4+1} \\right]_0^1 = \\left[ \\frac{x^{1/4}}{1/4} \\right]_0^1 = [4x^{1/4}]_0^1 = 4(1) - 4(0) = 4$$\n$h(X_1)$ 的期望是有限的，等于 $I=4$。这证实了 $h \\in L^1([0,1])$。\n\n**2. 二阶矩和方差：**\n对于 $k=2$，我们有 $p = \\frac{3(2)}{4} = \\frac{3}{2}  1$。积分发散。\n$$E[Y_1^2] = \\int_0^1 x^{-3/2} dx = \\left[ \\frac{x^{-1/2}}{-1/2} \\right]_0^1 = [-2x^{-1/2}]_0^1$$\n当 $x \\to 0^+$ 时，此表达式发散到 $+\\infty$。\n因此，$E[Y_1^2] = +\\infty$。$Y_1$ 的方差为 $\\mathrm{Var}(Y_1) = E[Y_1^2] - (E[Y_1])^2 = +\\infty - 4^2 = +\\infty$。方差是无穷大的。\n\n有了这些基础结果，我们就可以评估每个陈述了。\n\n### 逐项分析\n\n**陈述 A: $h\\in L^1([0,1])$ 但 $h\\notin L^2([0,1])$。**\n-   $L^p([0,1])$ 空间由满足 $\\int_0^1 |f(x)|^p dx  \\infty$ 的函数 $f$ 组成。\n-   对于 $p=1$，我们检查 $\\int_0^1 |h(x)| \\, dx$。由于 $h(x) = x^{-3/4} \\ge 1 > 0$，这就是 $\\int_0^1 x^{-3/4} dx$。如上所计算，该积分值为 $4$，是有限的。因此，$h \\in L^1([0,1])$。\n-   对于 $p=2$，我们检查 $\\int_0^1 |h(x)|^2 dx = \\int_0^1 (x^{-3/4})^2 dx = \\int_0^1 x^{-3/2} dx$。如上所计算，该积分发散。因此，$h \\notin L^2([0,1])$。\n-   该陈述是两个真实事实的联合。\n-   结论：**正确**。\n\n**陈述 B: $\\widehat I_n$ 是无偏的，满足强大数定律 (SLLN)，并且通常的中心极限定理 (CLT)（具有 $\\sqrt{n}$-归一化和有限的渐近方差）适用。**\n-   **无偏性：**估计量的期望值为 $E[\\widehat I_n] = E[\\frac{1}{n}\\sum_{i=1}^n h(X_i)] = \\frac{1}{n}\\sum_{i=1}^n E[h(X_i)]$。由于对所有 $i$ 都有 $E[h(X_i)] = I = 4$，我们得到 $E[\\widehat I_n] = \\frac{1}{n}(n \\cdot I) = I$。该估计量是无偏的。这部分是正确的。\n-   **强大数定律 (SLLN)：**柯尔莫哥洛夫强大数定律指出，对于一个独立同分布的随机变量序列 $Y_i$，如果 $E[|Y_1|]  \\infty$，那么样本均值几乎必然收敛到期望。这里 $Y_i = h(X_i)$。由于 $h(x) \\ge 1$，所以 $|h(X_1)| = h(X_1)$，并且我们已经发现 $E[h(X_1)] = 4  \\infty$。因此，强大数定律适用，并且 $\\widehat I_n \\to I$ 几乎必然成立。这部分是正确的。\n-   **中心极限定理 (CLT)：**标准的林德伯格-勒维中心极限定理指出，对于一个具有有限均值 $\\mu$ 和有限方差 $\\sigma^2  0$ 的独立同分布随机变量序列 $Y_i$，归一化和 $\\sqrt{n}(\\frac{1}{n}\\sum Y_i - \\mu)$ 依分布收敛到一个正态分布 $N(0, \\sigma^2)$。该定理的一个必要条件是方差 $\\sigma^2 = \\mathrm{Var}(Y_1)$ 必须是有限的。我们已经确定 $\\mathrm{Var}(h(X_1)) = +\\infty$。因此，标准的中心极限定理不适用。\n-   该陈述错误地声称通常的中心极限定理适用。\n-   结论：**不正确**。\n\n**陈述 C: $\\mathrm{Var}(h(X_1))=+\\infty$，且不存在 $\\mathrm{Var}(h(X_1))$ 的一致估计量；特别地，当 $n\\to\\infty$ 时，样本方差 $S_n^2=\\frac{1}{n-1}\\sum_{i=1}^n\\big(h(X_i)-\\widehat I_n\\big)^2$ 几乎必然发散到 $+\\infty$。**\n-   **方差：**如上所示，$\\mathrm{Var}(h(X_1)) = E[(h(X_1))^2] - (E[h(X_1)])^2 = +\\infty$。这部分是正确的。\n-   **样本方差的行为：**令 $Y_i = h(X_i)$。样本方差为 $S_n^2 = \\frac{1}{n-1}\\left(\\sum_{i=1}^n Y_i^2 - n(\\widehat I_n)^2\\right) = \\frac{n}{n-1}\\left(\\frac{1}{n}\\sum_{i=1}^n Y_i^2 - (\\widehat I_n)^2\\right)$。\n    -   当 $n\\to\\infty$ 时，前置因子 $\\frac{n}{n-1} \\to 1$。\n    -   根据强大数定律 (SLLN)（陈述 B），$\\widehat I_n \\to I = 4$ 几乎必然成立。因此 $(\\widehat I_n)^2 \\to 16$ 几乎必然成立。这一项是收敛且有界的。\n    -   考虑项 $\\frac{1}{n}\\sum_{i=1}^n Y_i^2$。变量 $Z_i = Y_i^2 = (h(X_i))^2$ 是独立同分布且非负的。它们的期望是 $E[Z_i] = E[Y_i^2] = +\\infty$。强大数定律的一个已知推广指出，如果 $Z_i$ 是期望 $E[Z_1] = +\\infty$ 的独立同分布非负随机变量，那么 $\\frac{1}{n}\\sum_{i=1}^n Z_i \\to +\\infty$ 几乎必然成立。\n    -   综合这些结果，$S_n^2$ 的行为类似于 $1 \\cdot (+\\infty - 16)$，它几乎必然发散到 $+\\infty$。\n-   $S_n^2$ 几乎必然发散到 $+\\infty$ 的说法是正确的。这是一个对无穷量的估计量所预期的行为。\n-   结论：**正确**。\n\n**陈述 D: $\\widehat I_n$ 的涨落遵循一个重尾广义极限定理：$n^{1/4}\\big(\\widehat I_n - I\\big)$ 依分布收敛到一个尾指数为 $\\alpha=\\frac{4}{3}$ 的非退化 $\\alpha$-稳定律（在中心化后），而 $\\sqrt{n}\\big(\\widehat I_n - I\\big)$ 依概率发散。**\n-   **广义中心极限定理：**由于 $Y_1=h(X_1)$ 的方差是无穷大的，我们必须研究它是否位于某个稳定律的吸引场中。我们分析其尾概率 $P(Y_1 > y)$。对于 $y \\ge 1$：\n    $$P(Y_1 > y) = P(h(X_1) > y) = P(X_1^{-3/4} > y) = P(X_1  y^{-4/3})$$\n    由于 $X_1 \\sim \\mathrm{Uniform}(0,1)$，这个概率是 $P(Y_1 > y) = y^{-4/3}$。\n    这表明 $Y_1$ 分布的尾部是正则变化的，指数为 $\\alpha = 4/3$。\n-   由于 $1  \\alpha  2$，随机变量 $Y_1$ 位于一个 $\\alpha$-稳定律的吸引场中。广义中心极限定理适用。对于来自这样一个分布的独立同分布变量之和，收敛到稳定律的适当归一化是 $n^{1/\\alpha}$。\n-   收敛结果是针对中心化和的：$\\frac{1}{n^{1/\\alpha}} \\sum_{i=1}^n (Y_i - E[Y_i]) \\xrightarrow{d} S$，其中 $S$ 是一个 $\\alpha$-稳定随机变量。\n-   当 $\\alpha = 4/3$ 时，归一化是 $n^{1/(4/3)} = n^{3/4}$。极限定理为：$\\frac{1}{n^{3/4}} \\sum_{i=1}^n (h(X_i) - I) \\xrightarrow{d} S$。\n-   让我们检查陈述中的表达式：\n    $n^{1/4}(\\widehat I_n - I) = n^{1/4}\\left(\\frac{1}{n}\\sum_{i=1}^n h(X_i) - I\\right) = \\frac{n^{1/4}}{n} \\sum_{i=1}^n (h(X_i) - I) = \\frac{1}{n^{3/4}} \\sum_{i=1}^n (h(X_i) - I)$。\n    这正是正确归一化的量。关于它依分布收敛到一个 $\\alpha=4/3$ 的非退化 $\\alpha$-稳定律的陈述是正确的。\n-   **$\\sqrt{n}$-归一化项的发散性：**我们可以将 $\\sqrt{n}(\\widehat I_n - I)$ 写成：\n    $$\\sqrt{n}(\\widehat I_n - I) = n^{1/2}(\\widehat I_n - I) = n^{1/2-1/4} \\cdot \\left(n^{1/4}(\\widehat I_n - I)\\right) = n^{1/4} \\cdot Z_n$$\n    其中 $Z_n = n^{1/4}(\\widehat I_n - I)$。我们刚刚证明了 $Z_n$ 依分布收敛到一个非退化的稳定律 $S$。一个依分布收敛的随机变量序列是随机有界（紧的）。由于 $n^{1/4} \\to \\infty$ 并且 $Z_n$ 收敛到一个几乎必然不为零的随机变量，乘积 $n^{1/4} Z_n$ 必须依概率发散。\n-   结论：**正确**。", "answer": "$$\\boxed{ACD}$$", "id": "3301536"}]}