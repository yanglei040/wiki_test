{"hands_on_practices": [{"introduction": "评估MCMC收敛性不能仅仅依赖于直观的轨迹图观察，更需要严谨的量化指标。本练习将指导你从第一性原理出发，构建一套经典的收敛诊断工具箱，包括著名的Gelman-Rubin统计量（$\\hat{R}$）、自相关性分析和趋势检测。通过亲手实现这些诊断方法并将其应用于典型的模拟场景，你将深入理解如何判断多条链是否已经收敛到平稳分布并充分混合，为可靠的后验推断奠定基础。[@problem_id:3289581]", "problem": "您的任务是，从概率论和统计学的核心定义出发，形式化一种用于从随机模拟中的轨迹图评估收敛性的定量方法。然后，您将实现此方法，并将其应用于一个指定的、由模拟的马尔可夫链蒙特卡洛轨迹组成的测试套件。\n\n基本基础和场景：考虑一个标量参数的 $m$ 个并行模拟序列（“链”）$\\{x_{j,t}\\}_{t=1}^{n}$，其中 $j \\in \\{1,\\dots,m\\}$，每个序列都由一个以可能随时间变化的均值为中心的一阶自回归过程 (AR($1$)) 生成：\n$$\nx_{j,t} \\;=\\; \\mu_{j,t} \\;+\\; \\phi\\left(x_{j,t-1}-\\mu_{j,t}\\right) \\;+\\; \\varepsilon_{j,t},\n$$\n其中 $\\varepsilon_{j,t} \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}\\!\\left(0, \\sigma^2(1-\\phi^2)\\right)$，$\\phi \\in (-1,1)$ 控制相关性，当 $\\mu_{j,t}$ 为常数时 $\\sigma^2$ 是平稳边际方差。对于常数 $\\mu_{j,t} \\equiv \\mu$，平稳分布是 $\\mathcal{N}(\\mu,\\sigma^2)$。\n\n您的目标是推导、实现并应用以下定量“轨迹提取”诊断方法，每种方法都基于核心定义：\n- 一种跨分割链的链间与链内方差比较（用于检测链间不一致性），该方法源于全方差定律和样本方差定义。\n- 一种滞后-1自相关估计量（用于检测混合不良），该方法源于样本自协方差和方差。\n- 一种早期与晚期窗口的标准化漂移幅度（用于检测非平稳趋势），该方法源于样本均值和合并方差。\n- 在AR($1$)近似下的近似总有效样本量，该方法源于积分自相关时间。\n\n使用这些诊断方法，一个链集合当且仅当同时满足以下所有条件时，才被宣告为“收敛”：\n1. 分割链的潜在尺度缩减因子 $\\hat{R}$ 至多为 $\\tau_R = 1.05$。\n2. 跨链的平均滞后-1自相关至多为 $\\tau_\\rho = 0.3$。\n3. 标准化漂移幅度至多为 $\\tau_D = 0.15$。\n4. 总有效样本量至少为 $E_{\\min} = 2000$。\n\n从样本均值、样本方差、自协方差、全方差定律和AR($1$)积分自相关时间的定义出发，推导如下可计算公式：\n\n- 分割链变异性比较：将每条链分成两半，得到 $m_s = 2m$ 个等长序列，长度为 $n_s = n/2$。令 $\\bar{x}_{.j}$ 表示分割序列 $j$ 的样本均值，$s_j^2$ 为其样本方差。令 $\\bar{x}_{..}$ 为所有分割序列的均值。定义链内方差 $W$ 为 $s_j^2$ 的平均值，链间方差 $B$ 与 $\\bar{x}_{.j}$ 的方差成正比，并由此构建过离散方差估计量 $V^+$ 和潜在尺度缩减因子 $\\hat{R}$。推导必须从样本均值和方差定义以及全方差定律开始，且不得假定任何预先包装好的公式。\n\n- 滞后-1自相关：对每条链 $j$，使用样本自协方差和样本方差的定义来估计滞后-1自协方差和自相关，然后计算各链自相关的平均值。\n\n- 标准化漂移幅度：对每条链 $j$，计算前 $k$ 个样本的均值和后 $k$ 个样本的均值，其中 $k = \\lfloor 0.4 n \\rfloor$。将链 $j$ 的漂移定义为这两个均值的绝对差，并用所有链和所有时间的合并标准差进行标准化。对 $j=1,\\dots,m$ 计算该标准化漂移的平均值。\n\n- AR($1$)下的有效样本量：使用AR($1$)近似，从自相关的几何级数中获得积分自相关时间，从而得到一个以滞后-1自相关 $\\rho$ 表示的可计算表达式。由此推导出 $m$ 条长度为 $n$ 的链的总有效样本量。\n\n测试套件：您必须为四种情况模拟数据，每种情况有 $m=4$ 条链，每条链有 $n=2000$ 个样本，高斯噪声方差指定为 $\\sigma^2=1$，并为保证可复现性将随机种子固定为 $12345$。使用上述AR($1$)递归，初始值 $x_{j,1}$ 从每条链的初始均值对应的平稳分布中抽取。对每种情况，按指定方式通过常数或阶梯常数均值定义 $\\mu_{j,t}$。对所有情况，设置 $\\sigma^2=1$。\n\n- 情况A（混合良好，平稳）：$m=4$，$n=2000$，$\\phi=0.2$，且对所有 $j$ 和 $t$，$\\mu_{j,t} \\equiv 0$。\n- 情况B（粘滞，高度自相关）：$m=4$，$n=2000$，$\\phi=0.98$，且对所有 $j$ 和 $t$，$\\mu_{j,t} \\equiv 0$。\n- 情况C（链内均值漂移）：$m=4$，$n=2000$，$\\phi=0.5$，且对每条链 $j$，当 $t \\le n/2$ 时 $\\mu_{j,t} = 0$，当 $t > n/2$ 时 $\\mu_{j,t} = 1$。\n- 情况D（链间位置差异）：$m=4$，$n=2000$，$\\phi=0.5$，其中两条链对所有 $t$ 满足 $\\mu_{j,t} \\equiv 0$，另外两条链对所有 $t$ 满足 $\\mu_{j,t} \\equiv 1$。\n\n角度单位和物理单位不适用；无需单位转换。\n\n您的程序必须：\n- 完全按照规定为每种情况实现模拟，使用相同的自回归递归，其中 $\\sigma^2=1$ 且固定种子为 $12345$。\n- 计算上述推导出的四种诊断指标。\n- 对每种情况，如果所有四个不等式都满足，则输出整数 $1$，否则输出 $0$。\n\n最终输出格式：您的程序应生成单行输出，其中包含四种情况的结果，格式为方括号内以逗号分隔的列表（例如，“[1,0,1,1]”），不含空格。", "solution": "该问题提法清晰且有科学依据，为推导、实现和应用一套MCMC收敛诊断方法提供了完整且一致的要求。任务是从基本统计定义出发，将这些诊断方法形式化，将其应用于指定条件下的模拟数据，并确定模拟是否满足一组收敛标准。该问题是有效的。\n\n解决方案分为两部分：首先，推导所需的四种诊断公式；其次，在程序中实现它们以分析指定的测试用例。\n\n### 收敛诊断的推导\n\n假设有 $m$ 条链，每条长度为 $n$。链 $j$ 的数据是序列 $\\{x_{j,t}\\}_{t=1}^{n}$。\n\n#### 1. 分割链变异性比较 ($\\hat{R}$)\n该诊断方法，被称为潜在尺度缩减因子或Gelman-Rubin统计量，它将单条链内的方差与所有链的总方差估计值进行比较。显著的差异表明各链尚未全部收敛到同一分布。推导过程首先将 $m$ 条长度为 $n$ 的链各自分成两半，得到 $m_s=2m$ 条分割链，每条长度为 $n_s = n/2$。\n\n现在，令 $x_{j,t}$ 表示第 $j$ 条 *分割* 链的第 $t$ 个样本，其中 $j \\in \\{1, \\dots, m_s\\}$ 且 $t \\in \\{1, \\dots, n_s\\}$。\n\n分割链 $j$ 的样本均值定义为：\n$$\n\\bar{x}_{.j} = \\frac{1}{n_s} \\sum_{t=1}^{n_s} x_{j,t}\n$$\n\n分割链 $j$ 的样本方差为：\n$$\ns_j^2 = \\frac{1}{n_s-1} \\sum_{t=1}^{n_s} (x_{j,t} - \\bar{x}_{.j})^2\n$$\n\n**链内方差** $W$ 是这些单个样本方差的平均值。它估计了每个序列内部方差的均值，对应于全方差定律中的 $E[\\text{Var}(\\psi|\\text{chain})]$。\n$$\nW = \\frac{1}{m_s} \\sum_{j=1}^{m_s} s_j^2\n$$\n\n**链间方差** $B$ 与分割链均值的样本方差成正比。它捕捉了序列间均值的方差，与 $\\text{Var}[E(\\psi|\\text{chain})]$ 相关。令 $\\bar{x}_{..}$ 为所有分割链中所有样本的总均值，$\\bar{x}_{..} = \\frac{1}{m_s} \\sum_{j=1}^{m_s} \\bar{x}_{.j}$。\n$$\nB = \\frac{n_s}{m_s-1} \\sum_{j=1}^{m_s} (\\bar{x}_{.j} - \\bar{x}_{..})^2\n$$\n因子 $n_s$ 对均值的方差进行缩放，使其与单个数据点的方差具有可比性。\n\n参数边际方差的过离散估计量，记为 $V^+$，被构造为链内和链间方差的加权平均：\n$$\nV^+ = \\frac{n_s-1}{n_s} W + \\frac{1}{n_s} B\n$$\n该公式结合了两种变异来源，以提供比单独使用 $W$ 更稳健的总体参数方差估计，尤其是在链尚未完全混合时。\n\n最后，**潜在尺度缩减因子** $\\hat{R}$ 是总方差估计与链内方差估计的比值：\n$$\n\\hat{R} = \\sqrt{\\frac{V^+}{W}} = \\sqrt{\\frac{n_s-1}{n_s} + \\frac{B}{n_s W}}\n$$\n如果所有链都已收敛到相同的平稳分布，$B$ 的量级将与 $W$ 相似，$\\hat{R}$ 将接近于 $1$。$\\hat{R} > 1$ 的值表明链尚未完全探索目标分布，并且可以通过延长链的运行时间来减小方差。\n\n#### 2. 滞后-1自相关 ($\\bar{\\rho}_1$)\n链内的高度自相关表明混合不良，因为相邻样本高度相关并提供冗余信息。我们为每条原始链（$j \\in \\{1, \\dots, m\\}$，长度为 $n$）估计滞后-1自相关。\n\n对于每条链 $j$，样本均值为 $\\bar{x}_j = \\frac{1}{n} \\sum_{t=1}^{n} x_{j,t}$。\n滞后 $k$ 的样本自协方差定义为：\n$$\n\\hat{\\gamma}_j(k) = \\frac{1}{n} \\sum_{t=1}^{n-k} (x_{j,t} - \\bar{x}_j)(x_{j,t+k} - \\bar{x}_j)\n$$\n样本方差是滞后 $0$ 的自协方差（为保持一致性，使用除数 $n$）：\n$$\n\\hat{\\gamma}_j(0) = \\frac{1}{n} \\sum_{t=1}^{n} (x_{j,t} - \\bar{x}_j)^2\n$$\n链 $j$ 在滞后 $k=1$ 时的样本自相关是滞后 $1$ 的自协方差与方差的比值：\n$$\n\\hat{\\rho}_j(1) = \\frac{\\hat{\\gamma}_j(1)}{\\hat{\\gamma}_j(0)}\n$$\n最终的诊断指标是所有 $m$ 条链的平均滞后-1自相关：\n$$\n\\bar{\\rho}_1 = \\frac{1}{m} \\sum_{j=1}^{m} \\hat{\\rho}_j(1)\n$$\n\n#### 3. 标准化漂移幅度 ($\\bar{D}_{\\text{std}}$)\n该诊断通过比较链的早期部分均值与晚期部分均值来检测非平稳性。显著的差异表明链仍在趋势中，尚未达到其平稳分布。\n\n对于每条长度为 $n$ 的链 $j$，我们定义两个大小为 $k = \\lfloor 0.4n \\rfloor$ 的窗口。\n前 $k$ 个样本的均值为：\n$$\n\\bar{x}_{j, \\text{early}} = \\frac{1}{k} \\sum_{t=1}^{k} x_{j,t}\n$$\n后 $k$ 个样本的均值为：\n$$\n\\bar{x}_{j, \\text{late}} = \\frac{1}{k} \\sum_{t=n-k+1}^{n} x_{j,t}\n$$\n链 $j$ 的漂移是这两个均值之间的绝对差：\n$$\nD_j = |\\bar{x}_{j, \\text{early}} - \\bar{x}_{j, \\text{late}}|\n$$\n为了使这个量在不同问题间具有可比性，它通过合并标准差 $S$ 进行标准化，该标准差是根据所有 $m \\times n$ 个样本计算的。令 $\\bar{x}_{\\text{grand}}$ 为所有样本的均值。合并样本方差为：\n$$\nS^2 = \\frac{1}{mn-1} \\sum_{j=1}^{m} \\sum_{t=1}^{n} (x_{j,t} - \\bar{x}_{\\text{grand}})^2\n$$\n合并标准差为 $S = \\sqrt{S^2}$。链 $j$ 的标准化漂移为 $D_{j, \\text{std}} = D_j / S$。\n最终的诊断指标是所有链的平均标准化漂移：\n$$\n\\bar{D}_{\\text{std}} = \\frac{1}{m} \\sum_{j=1}^{m} D_{j, \\text{std}}\n$$\n\n#### 4. 有效样本量 ($ESS_{total}$)\n有效样本量通过向下调整名义样本量（$m \\times n$）来解释自相关性。在AR($1$)近似下，滞后 $k$ 的自相关为 $\\rho(k) = (\\rho_1)^k$（$k \\ge 0$），其中 $\\rho_1$ 是滞后-1自相关。\n\n积分自相关时间（IACT），记为 $\\tau$，由所有自相关之和给出：\n$$\n\\tau = 1 + 2\\sum_{k=1}^{\\infty} \\rho(k)\n$$\n将 $\\rho(k)$ 的AR($1$)形式代入，并使用 $|\\rho_1|  1$ 的几何级数公式：\n$$\n\\sum_{k=1}^{\\infty} (\\rho_1)^k = \\frac{\\rho_1}{1-\\rho_1}\n$$\n这给出了IACT作为一个关于 $\\rho_1$ 的简单函数：\n$$\n\\tau = 1 + 2 \\frac{\\rho_1}{1-\\rho_1} = \\frac{1-\\rho_1+2\\rho_1}{1-\\rho_1} = \\frac{1+\\rho_1}{1-\\rho_1}\n$$\n单条长度为 $n$ 的链的有效样本量是 $ESS_{\\text{single}} = n/\\tau$。对于 $m$ 条独立的链，总有效样本量是各个有效样本量之和。使用平均滞后-1自相关 $\\bar{\\rho}_1$（来自第2部分）作为我们对 $\\rho_1$ 的估计：\n$$\nESS_{total} = m \\times \\frac{n}{\\tau} = m \\times n \\times \\frac{1-\\bar{\\rho}_1}{1+\\bar{\\rho}_1}\n$$\n---\n提供的实现现在将为每个测试用例计算这四种诊断指标，并应用指定的阈值规则来确定收敛性。", "answer": "```python\nimport numpy as np\n\ndef simulate_ar1_traces(m, n, phi, mu_func, sigma_sq, seed):\n    \"\"\"\n    Simulates m traces from an AR(1) process.\n    x_jt = mu_jt + phi*(x_j,t-1 - mu_jt) + eps_jt\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    traces = np.zeros((m, n))\n    mu = np.zeros((m, n))\n    for j in range(m):\n        for t in range(n):\n            mu[j, t] = mu_func(j, t, n)\n\n    # Initial values x_j,1 drawn from stationary dist N(mu_j,1, sigma^2)\n    traces[:, 0] = rng.normal(loc=mu[:, 0], scale=np.sqrt(sigma_sq), size=m)\n\n    # Noise standard deviation\n    noise_std = np.sqrt(sigma_sq * (1 - phi**2))\n\n    # Generate traces for t  1\n    for t in range(1, n):\n        epsilon = rng.normal(loc=0, scale=noise_std, size=m)\n        mu_t = mu[:, t]\n        x_prev = traces[:, t - 1]\n        traces[:, t] = mu_t + phi * (x_prev - mu_t) + epsilon\n    \n    return traces\n\ndef calculate_r_hat(traces):\n    \"\"\"Computes the potential scale reduction factor R-hat.\"\"\"\n    m, n = traces.shape\n    if n % 2 != 0:\n        raise ValueError(\"Number of samples n must be even for splitting.\")\n    \n    n_s = n // 2\n    m_s = 2 * m\n    \n    # Split chains into two halves\n    split_traces = traces.reshape(m_s, n_s)\n    \n    # Calculate within-chain means and variances\n    chain_means = np.mean(split_traces, axis=1)\n    chain_vars = np.var(split_traces, axis=1, ddof=1)\n    \n    # Within-sequence variance W\n    W = np.mean(chain_vars)\n    if W == 0: return 1.0 # Avoid division by zero if variance is nil\n\n    # Between-sequence variance B\n    grand_mean = np.mean(chain_means)\n    B = (n_s / (m_s - 1)) * np.sum((chain_means - grand_mean)**2)\n    \n    # Overdispersed variance estimator V+\n    V_plus = ((n_s - 1) / n_s) * W + (1 / n_s) * B\n    \n    r_hat = np.sqrt(V_plus / W)\n    return r_hat\n\ndef calculate_avg_autocorr(traces):\n    \"\"\"Calculates the average lag-1 autocorrelation across chains.\"\"\"\n    m, n = traces.shape\n    autocorrs = []\n    \n    for j in range(m):\n        chain = traces[j, :]\n        mean = np.mean(chain)\n        centered_chain = chain - mean\n        \n        # Autocovariance at lag 1, using n as divisor\n        gamma_1 = np.dot(centered_chain[:-1], centered_chain[1:]) / n\n        \n        # Variance (autocovariance at lag 0)\n        gamma_0 = np.dot(centered_chain, centered_chain) / n\n        \n        if gamma_0 == 0:\n            rho_1 = 0.0\n        else:\n            rho_1 = gamma_1 / gamma_0\n        autocorrs.append(rho_1)\n        \n    return np.mean(autocorrs)\n\ndef calculate_drift(traces):\n    \"\"\"Calculates the average standardized drift magnitude.\"\"\"\n    m, n = traces.shape\n    k = int(0.4 * n)\n    \n    early_means = np.mean(traces[:, :k], axis=1)\n    late_means = np.mean(traces[:, -k:], axis=1)\n    \n    drifts = np.abs(early_means - late_means)\n    \n    # Pooled standard deviation across all samples\n    pooled_std = np.std(traces, ddof=1)\n    \n    if pooled_std == 0:\n        return 0.0 # No drift if there is no variation\n        \n    std_drifts = drifts / pooled_std\n    \n    return np.mean(std_drifts)\n\ndef calculate_ess(traces, avg_rho1):\n    \"\"\"Calculates the total effective sample size.\"\"\"\n    m, n = traces.shape\n    \n    # Ensure rho1 is in a valid range to prevent division by zero or negative ESS\n    if avg_rho1 >= 1.0:\n        return 0.0\n    \n    iact = (1.0 + avg_rho1) / (1.0 - avg_rho1)\n    \n    ess = m * n / iact\n    return ess\n\ndef solve():\n    # Define thresholds\n    tau_R = 1.05\n    tau_rho = 0.3\n    tau_D = 0.15\n    E_min = 2000\n\n    # Common parameters\n    m = 4\n    n = 2000\n    sigma_sq = 1.0\n    seed = 12345\n\n    # Test cases setup\n    test_cases = [\n        # Case A: Well-mixed, stationary\n        {'phi': 0.2, 'mu_func': lambda j, t, n: 0.0},\n        # Case B: Sticky, highly autocorrelated\n        {'phi': 0.98, 'mu_func': lambda j, t, n: 0.0},\n        # Case C: Intra-chain mean shift\n        {'phi': 0.5, 'mu_func': lambda j, t, n: 1.0 if t >= n / 2 else 0.0},\n        # Case D: Between-chain location discrepancy\n        {'phi': 0.5, 'mu_func': lambda j, t, n: 1.0 if j >= m / 2 else 0.0},\n    ]\n\n    results = []\n    for case in test_cases:\n        # Simulate data for the current case\n        traces = simulate_ar1_traces(m, n, case['phi'], case['mu_func'], sigma_sq, seed)\n        \n        # Calculate diagnostics\n        r_hat = calculate_r_hat(traces)\n        avg_rho1 = calculate_avg_autocorr(traces)\n        drift = calculate_drift(traces)\n        ess = calculate_ess(traces, avg_rho1)\n        \n        # Check convergence criteria\n        converged = (\n            r_hat = tau_R and\n            avg_rho1 = tau_rho and\n            drift = tau_D and\n            ess >= E_min\n        )\n        \n        results.append(1 if converged else 0)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3289581"}, {"introduction": "经典诊断方法在面对非正态或重尾后验分布时可能表现不佳。为了解决这一问题，本练习将介绍更为稳健的、基于秩的诊断方法。我们将把前一练习中的$\\hat{R}$统计量推广到其秩归一化版本，并探索为何这种与具体分布无关的方法能在更复杂的场景下提供更可靠的收敛信号。此练习旨在将严谨的统计量与“充分混合”的轨迹图视觉直觉联系起来，加深你对高级诊断工具的理解。[@problem_id:3289568]", "problem": "给定多个针对标量参数 $ \\theta $ 的独立蒙特卡洛马尔可夫链 (MCMC)，您的任务是使用秩归一化迹图和基于秩的潜在尺度缩减因子来评估其收敛性。此评估的基本基础必须从以下几点出发：可交换抽样逼近平稳目标分布的定义、经验秩映射到无分布分位数的概念，以及在比较多条链时将变异性分解为链内和链间分量。\n\n以此为基础，在一个完整、可运行的程序中实现以下算法流程：\n\n1. 构建秩归一化迹：汇集所有链中 $ \\theta $ 的所有抽样值，计算它们的经验秩，通过将标准正态分布的逆累积分布函数应用于重缩放后的秩，将每个汇集后的秩映射到一个近似的标准正态分数，然后重塑回原始的“链×迭代次数”布局。\n\n2. 计算秩归一化的分割式潜在尺度缩减因子（通常称为秩-$ \\hat{R} $）：将每条链分成两半，计算这些分割链的链内方差和链间方差，得出一个混合了这些分量的方差估计，最后构成反映潜在尺度缩减的比率。\n\n3. 为迹图中的视觉秩稳定性定义一个定量代理指标：使用秩归一化迹的后半部分迭代，计算各链均值的标准差，并用该后半部分中所有链和所有迭代的汇集标准差对其进行归一化。该比率量化了相对于迹中典型离散程度的链均值重叠程度。\n\n4. 如果秩归一化的分割式潜在尺度缩减因子严格小于 $ 1.05 $，则声明“小秩-$\\hat{R}$”成立；如果后半段均值重叠比率严格小于 $ 0.1 $，则声明“视觉秩稳定性”成立。对于下面的每个测试用例，报告这两个声明是否一致，即它们是否同时为真或同时为假。\n\n程序必须根据下文的测试套件为 $ \\theta $ 生成合成的 MCMC 输出。必须使用指定的种子使随机数生成过程可复现。所有角度（如果出现）必须以弧度为单位。不涉及物理单位。最终程序必须产生单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。\n\n测试套件：\n\n- 案例 A（良好混合）：$ 4 $ 条链，每条链 $ 2000 $ 次迭代，种子 $ 123 $。每条链的抽样值均独立同分布于均值为 $ 0 $、标准差为 $ 1 $ 的正态分布。\n\n- 案例 B（一条链存在位置偏移）：$ 4 $ 条链，每条链 $ 2000 $ 次迭代，种子 $ 456 $。链 $ 1 $、$ 2 $ 和 $ 3 $ 的抽样值来自均值为 $ 0 $、标准差为 $ 1 $ 的正态分布。链 $ 4 $ 的抽样值来自均值为 $ 1.5 $、标准差为 $ 1 $ 的正态分布。\n\n- 案例 C（链间多模态）：$ 4 $ 条链，每条链 $ 2000 $ 次迭代，种子 $ 789 $。链 $ 1 $ 的抽样值来自均值为 $ -2 $、标准差为 $ 1 $ 的正态分布。链 $ 2 $ 的抽样值来自均值为 $ 2 $、标准差为 $ 1 $ 的正态分布。链 $ 3 $ 的前 $ 1000 $ 次迭代来自均值为 $ -2 $、标准差为 $ 1 $ 的正态分布，其后 $ 1000 $ 次迭代来自均值为 $ 2 $、标准差为 $ 1 $ 的正态分布。链 $ 4 $ 的均值每 $ 25 $ 次迭代在 $ -2 $ 和 $ 2 $ 之间交替，标准差为 $ 1 $。\n\n- 案例 D（短链重尾目标分布）：$ 4 $ 条链，每条链 $ 50 $ 次迭代，种子 $ 321 $。每条链的抽样值独立地来自位置参数为 $ 0 $、尺度参数为 $ 1 $ 的标准柯西分布。\n\n输出规范：\n\n- 对于每个案例 A–D，按所述计算秩归一化的分割式潜在尺度缩减因子和后半段均值重叠比率。设 $ r_{\\text{thresh}} = 1.05 $ 和 $ v_{\\text{thresh}} = 0.1 $。一个案例的结果是语句 $ \\big( \\text{rank-}\\hat{R}  r_{\\text{thresh}} \\big) == \\big( \\text{ratio}  v_{\\text{thresh}} \\big) $ 的布尔值。\n\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表，顺序为 $ [\\text{案例 A 结果},\\text{案例 B 结果},\\text{案例 C 结果},\\text{案例 D 结果}] $。", "solution": "该问题要求针对标量参数 $ \\theta $，实现并比较两种 MCMC 收敛性诊断指标：秩归一化的分割式潜在尺度缩减因子（$ \\hat{R} $）和一种视觉秩稳定性的定量代理指标。评估将在四个代表不同收敛场景的合成测试用例上进行。\n\n这些诊断指标背后的基本原理是评估从不同起始点开始的多条 MCMC 链是否都已收敛到从同一个平稳目标分布中抽样。如果已经收敛，链间变异应与每条链的链内变异在统计上无法区分。使用秩而不是原始参数值使得这些诊断指标对目标分布的具体形状具有稳健性，特别是对于那些具有重尾或其他挑战性几何形状的分布。\n\n假设 MCMC 的输出包含 $ M $ 条链，每条链有 $ N $ 次迭代。抽样值表示为 $ \\theta_{i,j} $，其中链为 $ i \\in \\{1, \\dots, M\\} $，迭代为 $ j \\in \\{1, \\dots, N\\} $。总抽样数为 $ S = MN $。\n\n### 1. 构建秩归一化迹\n\n第一步是将原始抽样值 $ \\theta_{i,j} $ 转换到一个其分布属性标准化的空间中。这通过秩归一化实现。\n\n1.  **汇集与排序**：所有 $ S = MN $ 个抽样值被汇集到一个集合 $\\{ \\theta_k \\}_{k=1}^S$ 中。为每个抽样值 $ \\theta_k $ 计算其经验秩 $ r_k $，该秩表示其在排序后集合中的位置（从 $ 1 $到 $ S $）。\n2.  **重缩放**：每个秩 $ r_k $ 被重缩放到区间 $ (0, 1) $ 以近似其累积概率。一种标准方法是使用连续性校正，得到 $ p_k = \\frac{r_k - 0.5}{S} $。\n3.  **归一化**：通过应用标准正态分布的逆累积分布函数 (CDF) $ \\Phi^{-1} $，将重缩放后的秩转换为标准正态分数。得到的秩归一化抽样值为 $ z_k = \\Phi^{-1}(p_k) $。\n4.  **重塑**：包含 $ S $ 个归一化分数 $\\{ z_k \\}_{k=1}^S$ 的扁平向量被重塑回一个 $ M \\times N $ 的矩阵（我们称之为 $ z_{i,j} $），并保留原始的链和迭代结构。所有后续计算都在这些 $ z_{i,j} $ 值上进行。\n\n### 2. 计算秩归一化的分割式潜在尺度缩减因子（$ \\hat{R} $）\n\n$ \\hat{R} $ 统计量比较了链间方差与链内方差。“分割”版本通过将每条链的前半部分和后半部分视为独立的链，增强了其检测非平稳性的能力。\n\n1.  **分割链**：将 $ M $ 条长度为 $ N $ 的秩归一化链分割成 $ m = 2M $ 条长度为 $ n = N/2 $ 的链。令这些分割链表示为 $ \\phi_{k,l} $，其中 $ k \\in \\{1, \\dots, m\\} $ 且 $ l \\in \\{1, \\dots, n\\} $。\n2.  **链内方差 ($ W $)**：对于每个分割链 $ k $，我们计算其样本方差：\n    $$ s_k^2 = \\frac{1}{n-1} \\sum_{l=1}^{n} (\\phi_{k,l} - \\bar{\\phi}_{k\\cdot})^2 $$\n    其中 $ \\bar{\\phi}_{k\\cdot} $ 是链 $ k $ 的均值。这些方差的平均值即为链内方差：\n    $$ W = \\frac{1}{m} \\sum_{k=1}^{m} s_k^2 $$\n3.  **链间方差 ($ B $)**：我们计算分割链均值的方差：\n    $$ B = \\frac{n}{m-1} \\sum_{k=1}^{m} (\\bar{\\phi}_{k\\cdot} - \\bar{\\phi}_{\\cdot\\cdot})^2 $$\n    其中 $ \\bar{\\phi}_{\\cdot\\cdot} $ 是所有分割链中所有抽样值的均值。因子 $ n $ 对该方差进行缩放，使其与 $ W $ 具有可比性。\n4.  **汇集方差 ($ \\hat{V} $)**：通过对 $ W $ 和 $ B $ 进行加权平均，形成对目标分布边际方差的估计：\n    $$ \\hat{V} = \\frac{n-1}{n} W + \\frac{1}{n} B $$\n5.  **尺度缩减因子 ($ \\hat{R} $)**：最终的统计量是汇集方差估计与链内方差之比，它代表了如果继续抽样，尺度可能缩减的幅度：\n    $$ \\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}} $$\n    如果链已收敛，$ W $ 和 $ \\hat{V} $ 将几乎相等，而 $ \\hat{R} $ 将接近于 $ 1.0 $。问题指定了一个阈值 $ r_{\\text{thresh}} = 1.05 $。\n\n### 3. 视觉秩稳定性的定量代理指标\n\n该指标量化了人们在检查迹图时获得的视觉印象。对于混合良好、已收敛的链，其迹图应该重叠，并且相对于整体离散程度，它们各自的均值应该彼此接近。\n\n1.  **隔离后半部分**：我们只考虑秩归一化迹的后半部分，即 $ z_{i,j} $，其中 $ i \\in \\{1, \\dots, M\\} $ 且 $ j \\in \\{N/2+1, \\dots, N\\} $。\n2.  **每条链的均值**：对于每条链 $ i $，计算其在这后半部分的均值 $ \\bar{z}'_{i\\cdot} $。\n3.  **均值的标准差**：计算这 $ M $ 个链均值的样本标准差，我们称之为 $ \\sigma_{\\text{means}} $。这衡量了各链中心趋势之间的离散程度。\n4.  **汇集标准差**：计算后半部分中所有链的所有抽样值的样本标准差，我们称之为 $ \\sigma_{\\text{pooled}} $。这衡量了迹中抽样值的典型离散程度。\n5.  **比率**：最终的重叠比率为：\n    $$ \\rho = \\frac{\\sigma_{\\text{means}}}{\\sigma_{\\text{pooled}}} $$\n    小的比率表明，与链内的典型波动相比，链均值之间的差异很小，这表明混合和重叠情况良好。问题指定了一个阈值 $ v_{\\text{thresh}} = 0.1 $。\n\n### 4. 决策逻辑\n\n对于每个测试用例，我们计算秩归一化的分割式 $ \\hat{R} $ 和后半段均值重叠比率 $ \\rho $。然后我们评估两个布尔条件：\n- 如果 $ \\hat{R}  1.05 $，则“小秩-$\\hat{R}$”为真。\n- 如果 $ \\rho  0.1 $，则“视觉秩稳定性”为真。\n\n该案例的最终结果是检验这两个条件是否一致的逻辑测试的布尔值，即它们是否同时为真或同时为假：\n$$ \\text{结果} = (\\hat{R}  1.05) == (\\rho  0.1) $$\n这测试了两种诊断措施在不同场景下的一致性。\n- **案例 A** 代表一个理想的、混合良好的场景，两种诊断指标都应指示收敛。\n- **案例 B** 在一条链中引入了位置偏移，这是一个明显的收敛失败，两种诊断指标都应能检测到。\n- **案例 C** 模拟了复杂的非平稳性和多模态，这是诊断指标应能识别的另一种失败模式。\n- **案例 D** 使用来自重尾柯西分布的短链，在一个具有挑战性的高方差、低信息量设置中测试基于秩的方法的稳健性。在这种困难情况下，预计两种诊断指标都会标记为未收敛。\n\n目标是验证这两种不同但相关的度量方法是否提供关于收敛状态的一致信号。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef generate_case_data(case_params):\n    \"\"\"Generates synthetic MCMC data based on case parameters.\"\"\"\n    M = case_params['M']\n    N = case_params['N']\n    seed = case_params['seed']\n    name = case_params['name']\n    \n    np.random.seed(seed)\n    \n    draws = np.zeros((M, N))\n    \n    if name == 'A':\n        # All chains are i.i.d. from a standard normal distribution.\n        draws = np.random.normal(loc=0.0, scale=1.0, size=(M, N))\n    elif name == 'B':\n        # 3 chains from N(0,1), 1 chain from N(1.5, 1).\n        draws[:3, :] = np.random.normal(loc=0.0, scale=1.0, size=(M - 1, N))\n        draws[3, :] = np.random.normal(loc=1.5, scale=1.0, size=N)\n    elif name == 'C':\n        # Complex multi-modality and non-stationarity.\n        N_half = N // 2\n        # Chain 1: N(-2, 1)\n        draws[0, :] = np.random.normal(loc=-2.0, scale=1.0, size=N)\n        # Chain 2: N(2, 1)\n        draws[1, :] = np.random.normal(loc=2.0, scale=1.0, size=N)\n        # Chain 3: Switches from N(-2, 1) to N(2, 1) halfway.\n        draws[2, :N_half] = np.random.normal(loc=-2.0, scale=1.0, size=N_half)\n        draws[2, N_half:] = np.random.normal(loc=2.0, scale=1.0, size=N_half)\n        # Chain 4: Alternates between modes every 25 iterations.\n        alt_size = 25\n        num_blocks = N // alt_size\n        for i in range(num_blocks):\n            start_idx = i * alt_size\n            end_idx = start_idx + alt_size\n            mean = -2.0 if i % 2 == 0 else 2.0\n            draws[3, start_idx:end_idx] = np.random.normal(loc=mean, scale=1.0, size=alt_size)\n    elif name == 'D':\n        # Heavy-tailed Cauchy distribution.\n        draws = np.random.standard_cauchy(size=(M, N))\n        \n    return draws\n\ndef compute_diagnostics(draws):\n    \"\"\"\n    Computes rank-normalized split R-hat and the last-half mean-overlap ratio.\n    \"\"\"\n    M, N = draws.shape\n    if N  2:\n        # Not enough data to split chains or calculate variance\n        return np.inf, np.inf\n\n    # 1. Rank-normalize the traces\n    S = M * N\n    flat_draws = draws.flatten()\n    # Compute ranks from 1 to S\n    ranks = flat_draws.argsort().argsort() + 1\n    # Rescale ranks to (0, 1)\n    rescaled_ranks = (ranks - 0.5) / S\n    # Apply inverse normal CDF (probit function)\n    z_scores_flat = norm.ppf(rescaled_ranks)\n    z_traces = z_scores_flat.reshape(M, N)\n\n    # 2. Compute rank-normalized split R-hat\n    m = 2 * M\n    n = N // 2\n    \n    # Reshape into split chains\n    split_chains = z_traces[:, :2*n].reshape(m, n)\n\n    # Calculate within-chain and between-chain variance\n    chain_means = np.mean(split_chains, axis=1)\n    # ddof=1 for sample variance\n    W = np.mean(np.var(split_chains, axis=1, ddof=1)) \n    \n    if W == 0:\n        # If all chains are constant and identical, W can be 0.\n        # This implies perfect convergence in a trivial case.\n        R_hat = 1.0\n    else:\n        # ddof=1 for sample variance of the means\n        B = n * np.var(chain_means, ddof=1)\n        V_hat = ((n - 1) / n) * W + (1 / n) * B\n        R_hat = np.sqrt(V_hat / W)\n\n    # 3. Compute last-half mean-overlap ratio\n    last_half_traces = z_traces[:, N//2:]\n    \n    # Per-chain means for the last half\n    last_half_means = np.mean(last_half_traces, axis=1)\n    \n    sigma_means = np.std(last_half_means, ddof=1) if M > 1 else 0.0\n    \n    # Pooled standard deviation for the last half\n    # ddof=1 for sample standard deviation\n    sigma_pooled = np.std(last_half_traces, ddof=1)\n    \n    if sigma_pooled == 0:\n        # Chains are constant in the last half.\n        # If means are also identical, ratio is 0. If not, it's undefined.\n        # We can treat this as 0 if sigma_means is also 0, else a large number.\n        ratio = 0.0 if sigma_means == 0.0 else np.inf\n    else:\n        ratio = sigma_means / sigma_pooled\n\n    return R_hat, ratio\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        {'name': 'A', 'M': 4, 'N': 2000, 'seed': 123},\n        {'name': 'B', 'M': 4, 'N': 2000, 'seed': 456},\n        {'name': 'C', 'M': 4, 'N': 2000, 'seed': 789},\n        {'name': 'D', 'M': 4, 'N': 50, 'seed': 321},\n    ]\n\n    r_thresh = 1.05\n    v_thresh = 0.1\n\n    results = []\n    for case in test_cases:\n        draws = generate_case_data(case)\n        rank_R_hat, mean_overlap_ratio = compute_diagnostics(draws)\n        \n        # Check if the declarations agree\n        r_hat_ok = rank_R_hat  r_thresh\n        ratio_ok = mean_overlap_ratio  v_thresh\n        \n        agreement = (r_hat_ok == ratio_ok)\n        results.append(agreement)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3289568"}, {"introduction": "除了常规的收敛问题，MCMC采样器还可能陷入一种更隐蔽的病态行为：近似确定性循环。这种循环在轨迹图上可能被误认为已经收敛，尤其是在方差极小的情况下。本练习将引导你开发一种专门的诊断工具，利用谱分析方法来区分这种欺骗性的循环与真实的平稳行为。这强调了掌握多样化诊断工具集的重要性，以便应对MCMC采样中可能出现的各种复杂问题。[@problem_id:3289543]", "problem": "您的任务是设计并实现一种定量诊断方法，用以区分马尔可夫链蒙特卡洛（MCMC）中表现出极小变异性的迹图（trace plot）是确定性循环还是真正的平稳性。请在由 Gibbs 采样器生成的标量随机过程 $\\{X_t\\}_{t=1}^N$ 的设定下工作。从以下基本要素开始。\n\n- 马尔可夫链是一个随机过程 $\\{X_t\\}$，其性质为，对于任何可测集 $A$，$\\mathbb{P}(X_{t+1} \\in A \\mid X_1,\\dots,X_t) = \\mathbb{P}(X_{t+1} \\in A \\mid X_t)$。平稳分布 $\\pi$ 满足 $\\pi T = \\pi$，其中 $T$ 是该链的转移核。\n- （弱）平稳过程的自协方差函数为 $\\gamma(k) = \\mathrm{Cov}(X_t, X_{t+k})$，其中 $k$ 为整数延迟，谱密度是 $\\gamma(k)$ 的离散时间傅里叶变换。频率 $\\omega_k = 2\\pi k/N$ 处的周期图定义为 $I(\\omega_k) = \\frac{1}{N}\\left|\\sum_{t=1}^N X_t e^{-i \\omega_k t}\\right|^2$。\n- 在近乎确定性的循环中，连续状态几乎以确定性的方式映射到下一个状态，其新息方差趋近于零；而一个真正平稳的链具有非零的新息方差，即使其迹图在视觉上看起来平坦，也能随时间维持其变异性。\n\n您的程序必须实现一个基于以下原则的诊断测试：\n\n1. 计算谱峰比以量化尖锐的周期性。设 $I(\\omega_k)$ 是通过离散傅里叶变换在非负傅里叶频率 $\\omega_k = 2\\pi k/N$（其中 $k \\in \\{0,1,\\dots,\\lfloor N/2 \\rfloor\\}$）上计算的周期图。将低频基线 $S_{\\text{low}}$ 定义为前 $M$ 个正频率纵坐标的算术平均值，即 $S_{\\text{low}} = \\frac{1}{M}\\sum_{k=1}^M I(\\omega_k)$，并将非零频率峰值定义为 $S_{\\text{peak}} = \\max_{k \\ge 1} I(\\omega_k)$。谱峰比为 $R_{\\text{spec}} = \\frac{S_{\\text{peak}}}{S_{\\text{low}}}$。\n2. 计算新息比以量化单步转移的近确定性。设 $a^\\star$ 是最小化 $\\sum_{t=1}^{N-1} (X_{t+1} - a X_t)^2$ 的最小二乘系数，当 $\\mathrm{Var}(X_t) \\neq 0$ 时，其等于 $a^\\star = \\frac{\\mathrm{Cov}(X_t, X_{t+1})}{\\mathrm{Var}(X_t)}$。定义残差 $E_t = X_{t+1} - a^\\star X_t$ 和新息比 $R_{\\text{var}} = \\frac{\\mathrm{Var}(E_t)}{\\mathrm{Var}(X_t)}$。\n3. 当且仅当 $R_{\\text{spec}}  T_{\\text{spec}}$ 和 $R_{\\text{var}}  T_{\\text{var}}$ 同时成立时，将链分类为确定性循环，其中 $T_{\\text{spec}}$ 和 $T_{\\text{var}}$ 是固定阈值。\n\n使用以下适用于高等研究生级别分析的固定常数来实现上述诊断：$N = 4096$，$M = 5$，$T_{\\text{spec}} = 20$ 和 $T_{\\text{var}} = 10^{-3}$。通过实值快速傅里叶变换来使用离散傅里叶变换。通过在适当位置添加一个小的数值稳定常数来稳健地处理退化方差。\n\n测试套件。将您的诊断应用于以下四种合成场景，每种场景产生一个长度为 $N$ 的序列：\n\n- 案例1（带有微小噪声的近确定性周期-2循环）：$X_{t+1} = -X_t + \\varepsilon Z_t$，其中 $X_1 = 1$，$\\varepsilon = 10^{-4}$，且 $\\{Z_t\\}$ 是独立同分布的标准正态随机变量。这模拟了一个具有近确定性全条件分布的 Gibbs 采样器，该采样器产生奇偶交替。\n- 案例2（真正平稳、高度持续但非周期性）：由 $X_{t+1} = \\phi X_t + \\sigma Z_t$ 定义的一阶自回归过程，其中 $\\phi = 0.95$，$\\sigma = 0.05$，且 $\\{Z_t\\}$ 是独立同分布的标准正态随机变量，经过 $B = 512$ 步的预烧期以近似平稳性。返回最后的 $N$ 个值。\n- 案例3（真正平稳、具有负自相关但非确定性）：由 $X_{t+1} = \\phi X_t + \\sigma Z_t$ 定义的一阶自回归过程，其中 $\\phi = -0.8$，$\\sigma = 0.2$，且 $\\{Z_t\\}$ 是独立同分布的标准正态随机变量，经过 $B = 512$ 步的预烧期以近似平稳性。返回最后的 $N$ 个值。\n- 案例4（带有微小噪声的近确定性周期-3循环）：该链按顺序在确定性状态 $\\{1, -\\tfrac{1}{2}, 0.2\\}$ 中循环，其中 $X_{t+1} = s_{(t \\bmod 3) + 1} + \\varepsilon Z_t$，状态元组为 $(s_1, s_2, s_3) = (1, -\\tfrac{1}{2}, 0.2)$，$\\varepsilon = 10^{-4}$，且 $\\{Z_t\\}$ 是独立同分布的标准正态随机变量，从 $X_1 = s_1$ 开始。\n\n您的程序必须：\n\n- 使用固定的随机种子，以使输出完全可复现。\n- 对于每个案例，生成序列并应用诊断，返回一个布尔值，指示是否检测到确定性循环。\n- 生成单行输出，其中包含按案例1到4的顺序排列的结果，格式为方括号内以逗号分隔的列表，例如 $[b_1,b_2,b_3,b_4]$，其中每个 $b_j$ 是 True 或 False。\n\n此问题不涉及物理单位或角度单位。所有随机变量均为实值。此问题中的所有数值常数都是精确的，必须按规定使用。随机种子的选择是任意的，但在单次程序运行的所有案例中必须保持一致固定。最终输出必须是布尔值。", "solution": "区分真正平稳的马尔可夫链蒙特卡洛（MCMC）过程与表现出病态确定性循环的过程，是收敛性诊断的一个关键方面。一个看起来平坦的迹图可能会误导性地表明已收敛，而实际上链可能被困在一个近确定性的周期性循环中。所提供的问题陈述概述了一项有效、适定且有科学依据的任务，即为此目的实现一个特定的由两部分组成的诊断方法。该问题已用所有必要的常数和定义进行了形式化规定，从而可以得到一个唯一且可复现的解决方案。我们将进行逐步的实现和分析。\n\n该诊断由两个度量组成：用于检测尖锐周期性的谱峰比 $R_{\\text{spec}}$，以及用于量化单步确定性的新息比 $R_{\\text{var}}$。只有当一个链同时表现出强周期性和强确定性时，才被分类为确定性循环。\n\n首先，我们分析时间序列 $\\{X_t\\}_{t=1}^N$ 的谱特性。周期性或循环过程会将其方差集中在与循环周期相对应的特定频率上。这表现为其谱密度中的尖锐峰值。周期图 $I(\\omega_k)$ 可作为在一组离散傅里叶频率 $\\omega_k = 2\\pi k/N$ 上谱密度的估计量。其定义为\n$$\nI(\\omega_k) = \\frac{1}{N}\\left|\\sum_{t=1}^N X_t e^{-i \\omega_k t}\\right|^2\n$$\n其中 $N$ 是序列的长度。为了量化主导周期分量的存在，我们定义了谱峰比 $R_{\\text{spec}}$。该度量将任何非零频率下的最大功率 $S_{\\text{peak}}$ 与基线功率水平 $S_{\\text{low}}$ 进行比较。峰值功率为 $S_{\\text{peak}} = \\max_{k \\ge 1} I(\\omega_k)$。基线计算为前 $M$ 个正频率的平均功率：$S_{\\text{low}} = \\frac{1}{M}\\sum_{k=1}^M I(\\omega_k)$。然后比值为 $R_{\\text{spec}} = S_{\\text{peak}} / S_{\\text{low}}$。较大的 $R_{\\text{spec}}$ 值表明某个频率分量比普遍的低频背景强大得多，这是周期性的一个标志。我们使用指定的阈值 $T_{\\text{spec}} = 20$。\n\n其次，我们评估链转移的确定性。近确定性过程是指下一个状态 $X_{t+1}$ 几乎完全由当前状态 $X_t$ 决定，只有非常小的随机新息。我们使用一个简单的一阶自回归模型 $X_{t+1} \\approx a X_t$ 来探究这种关系。问题指定了需要找到最小化平方误差和 $\\sum_{t=1}^{N-1} (X_{t+1} - a X_t)^2$ 的系数 $a^\\star$。这个标准最小二乘问题（对于通过原点的回归）的解是\n$$\na^\\star = \\frac{\\sum_{t=1}^{N-1} X_t X_{t+1}}{\\sum_{t=1}^{N-1} X_t^2}\n$$\n此拟合的残差 $E_t = X_{t+1} - a^\\star X_t$ 代表“新息”，即 $X_{t+1}$ 中不能被 $X_t$ 的线性函数解释的部分。新息比 $R_{\\text{var}}$ 定义为这些残差的方差与原始序列方差的比值：\n$$\nR_{\\text{var}} = \\frac{\\mathrm{Var}(E_t)}{\\mathrm{Var}(X_t)}\n$$\n如果 $R_{\\text{var}}$ 非常小，则意味着简单的线性模型几乎解释了过程中的所有变异性，表明存在高度的单步确定性。指定的阈值为 $T_{\\text{var}} = 10^{-3}$。必须注意，此诊断专门测试*线性*单步可预测性。\n\n最终的分类规则是，当且仅当 $R_{\\text{spec}} > T_{\\text{spec}}$ 和 $R_{\\text{var}}  T_{\\text{var}}$ 这两个条件都满足时，链才被标记为确定性循环。这确保我们识别出既是周期性又高度可预测的过程。\n\n我们使用常数 $N=4096$ 和 $M=5$ 将此诊断应用于四个测试案例。\n案例1：$X_{t+1} = -X_t + \\varepsilon Z_t, \\varepsilon=10^{-4}$。这是一个周期为2的循环。模型 $X_{t+1} \\approx a X_t$ 是一个极好的拟合，其中 $a^\\star \\approx -1$。残差将近似为 $\\varepsilon Z_t$，导致一个非常小的 $\\mathrm{Var}(E_t)$，因此 $R_{\\text{var}}$ 非常小。周期图将在奈奎斯特频率（$\\pi$）处有一个巨大的峰值，导致一个非常大的 $R_{\\text{spec}}$。预计两个条件都将满足，结果分类为 `True`。\n案例2：一个平稳的 AR(1) 过程，其中 $\\phi=0.95$。这个过程是高度持续的，但不是周期性的。其谱密度是平滑的，并在频率零处达到峰值。因此，预计 $R_{\\text{spec}}$ 会很小。新息比 $R_{\\text{var}}$ 将约为 $1-\\phi^2 = 1 - 0.95^2 \\approx 0.0975$，远高于 $T_{\\text{var}}$。分类应为 `False`。\n案例3：一个平稳的 AR(1) 过程，其中 $\\phi=-0.8$。这个过程是交替的，但不是一个确定性循环。其谱密度是平滑的，并在奈奎斯特频率处达到峰值。然而，这个峰值是宽的，不是尖锐的，所以 $R_{\\text{spec}}$ 不太可能超过阈值。新息比 $R_{\\text{var}}$ 将约为 $1-\\phi^2 = 1 - (-0.8)^2 = 0.36$，远高于 $T_{\\text{var}}$。分类应为 `False`。\n案例4：一个周期为3的循环，$X_{t+1} = s_{(t \\bmod 3)+1} + \\varepsilon Z_t$。这个过程具有强周期性，因此由于在对应于周期3的频率处有一个尖锐的峰值，$R_{\\text{spec}}$ 将会非常大。然而，配对序列 $(X_t, X_{t+1})$ 遵循一个三点模式，这个模式无法通过一条穿过原点的直线很好地近似。因此，AR(1) 模型是一个糟糕的拟合，残差方差 $\\mathrm{Var}(E_t)$ 将会很大。因此，$R_{\\text{var}}$ 不会小于 $T_{\\text{var}}$。按规定，该诊断只对线性（或周期为2）的确定性敏感，并将无法检测到这种高阶循环的确定性。预计分类为 `False`。\n\n实现将生成这四个时间序列，应用指定的诊断计算，并为每个序列返回一个布尔分类。通过在可能出现除以零的分母上添加一个小的常数 $\\epsilon = 10^{-15}$ 来确保数值稳定性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the MCMC diagnostic on four test cases.\n    \"\"\"\n    # Fixed parameters from the problem statement\n    N = 4096\n    M = 5\n    T_spec = 20.0\n    T_var = 1e-3\n    B = 512\n    RANDOM_SEED = 123\n    \n    # Numerical stabilization constant\n    STABILIZATION_EPS = 1e-15\n\n    rng = np.random.default_rng(RANDOM_SEED)\n\n    def run_diagnostic(X: np.ndarray) -> bool:\n        \"\"\"\n        Applies the diagnostic test to a time series X.\n\n        Args:\n            X: A 1D numpy array representing the time series.\n\n        Returns:\n            A boolean indicating if deterministic cycling is detected.\n        \"\"\"\n        # Ensure N is the length of X for calculation\n        N_local = len(X)\n        if N_local  M + 2: # Need enough points for M and for AR(1)\n            return False\n\n        # 1. Compute the spectral peak ratio R_spec\n        # Compute real FFT and then the periodogram\n        # The problem defines I(w_k) = (1/N) |FFT(X)_k|^2\n        fft_coeffs = np.fft.rfft(X)\n        periodogram = (1 / N_local) * np.abs(fft_coeffs)**2\n\n        # Positive-frequency ordinates start from index 1 (k=0 is DC component)\n        pos_freq_periodogram = periodogram[1:]\n        \n        # Handle cases with no positive frequency components / flat spectrum\n        if len(pos_freq_periodogram) == 0:\n            return False\n\n        S_peak = np.max(pos_freq_periodogram)\n        \n        # S_low is the mean of the first M positive frequency ordinates\n        S_low = np.mean(pos_freq_periodogram[:M])\n        \n        R_spec = S_peak / (S_low + STABILIZATION_EPS)\n\n        # 2. Compute the innovation ratio R_var\n        var_X = np.var(X)\n        if var_X  STABILIZATION_EPS:\n            # Constant series is stationary, not cycling. R_var is effectively 0.\n            # But it's not 'cycling', so the periodicity test would fail anyway.\n            # A constant series has S_peak=0 so R_spec=0. Diagnostic fails.\n            return False\n\n        X_prefix = X[:-1]\n        X_suffix = X[1:]\n\n        # Calculate a_star from the least-squares minimization of sum((X_{t+1} - a*X_t)^2)\n        # a_star = sum(X_t * X_{t+1}) / sum(X_t^2)\n        sum_xt_xt1 = np.dot(X_prefix, X_suffix)\n        sum_xt_sq = np.dot(X_prefix, X_prefix)\n        a_star = sum_xt_xt1 / (sum_xt_sq + STABILIZATION_EPS)\n\n        # Calculate residuals and their variance\n        E = X_suffix - a_star * X_prefix\n        var_E = np.var(E)\n\n        R_var = var_E / (var_X + STABILIZATION_EPS)\n\n        # 3. Classify the chain\n        is_cycling = (R_spec > T_spec) and (R_var  T_var)\n        return is_cycling\n\n    def generate_case1() -> np.ndarray:\n        epsilon = 1e-4\n        X = np.zeros(N)\n        X[0] = 1.0\n        Z = rng.standard_normal(N - 1)\n        for t in range(N - 1):\n            X[t+1] = -X[t] + epsilon * Z[t]\n        return X\n\n    def generate_case2() -> np.ndarray:\n        phi, sigma = 0.95, 0.05\n        X = np.zeros(N + B)\n        X[0] = 0.0\n        Z = rng.standard_normal(N + B - 1)\n        for t in range(N + B - 1):\n            X[t+1] = phi * X[t] + sigma * Z[t]\n        return X[B:]\n\n    def generate_case3() -> np.ndarray:\n        phi, sigma = -0.8, 0.2\n        X = np.zeros(N + B)\n        X[0] = 0.0\n        Z = rng.standard_normal(N + B - 1)\n        for t in range(N + B - 1):\n            X[t+1] = phi * X[t] + sigma * Z[t]\n        return X[B:]\n\n    def generate_case4() -> np.ndarray:\n        s_tuple = (1.0, -0.5, 0.2)\n        epsilon = 1e-4\n        X = np.zeros(N)\n        X[0] = s_tuple[0]\n        Z = rng.standard_normal(N-1)\n        for t in range(N-1):\n            s_index = (t + 1) % 3\n            X[t+1] = s_tuple[s_index] + epsilon*Z[t]\n        return X\n\n    test_cases = [\n        generate_case1,\n        generate_case2,\n        generate_case3,\n        generate_case4\n    ]\n\n    results = []\n    for gen_func in test_cases:\n        X_series = gen_func()\n        result = run_diagnostic(X_series)\n        results.append(result)\n\n    # Format the final output exactly as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3289543"}]}