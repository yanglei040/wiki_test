{"hands_on_practices": [{"introduction": "我们常常从一个简单、直观的无偏估计量开始。Rao-Blackwell定理提供了一种系统性的方法来改进这类估计量，从而获得方差更小的更优估计量。本练习 [@problem_id:1922449] 将引导你完成一个经典案例：在两个正态总体中，寻找均值差的均匀最小方差无偏估计(UMVUE)。通过将一个“粗糙”的估计量条件化于完备充分统计量，你将推导出我们所熟知的最优估计量，从而巩固对该定理核心机制的理解。", "problem": "设 $X_1, X_2, \\dots, X_n$ 是来自均值未知 $\\mu$、方差未知 $\\sigma^2 > 0$ 的正态分布的一个随机样本。独立地，设 $Y_1, Y_2, \\dots, Y_m$ 是来自均值未知 $\\theta$、方差同样为未知 $\\sigma^2$ 的正态分布的另一个随机样本。我们主要感兴趣的参数是均值之差 $\\delta = \\mu - \\theta$。\n\n考虑 $\\delta$ 的一个简单估计量 $T = X_1 - Y_1$。虽然这个估计量是 $\\delta$ 的无偏估计量，但它的方差可能很大，这使得它在估计上可能是低效的。\n\n你的任务是求出 $\\delta$ 的一致最小方差无偏估计量 (Uniformly Minimum-Variance Unbiased Estimator, UMVUE)。请用样本值 $X_i$ 和 $Y_j$ 以及样本量 $n$ 和 $m$ 来表示你的答案的解析表达式。", "solution": "为了求出 $\\delta = \\mu - \\theta$ 的一致最小方差无偏估计量 (UMVUE)，我们将使用 Lehmann-Scheffé 定理。这需要找到参数 $(\\mu, \\theta, \\sigma^2)$ 的一个完备充分统计量，然后找到该统计量的一个函数，该函数是 $\\delta$ 的无偏估计量。一个实用的方法是从一个简单的无偏估计量开始，然后使用 Rao-Blackwell 定理，通过对完备充分统计量取条件期望来改进它。\n\n首先，我们来验证所提出的估计量 $T = X_1 - Y_1$ 是 $\\delta$ 的无偏估计量。\n$T$ 的期望是：\n$$E[T] = E[X_1 - Y_1] = E[X_1] - E[Y_1]$$\n因为 $X_1$ 来自均值为 $\\mu$ 的总体，$Y_1$ 来自均值为 $\\theta$ 的总体，我们有：\n$$E[T] = \\mu - \\theta = \\delta$$\n所以，$T$ 确实是 $\\delta$ 的一个无偏估计量。\n\n接下来，我们求参数矢量 $(\\mu, \\theta, \\sigma^2)$ 的一个完备充分统计量。由于独立性，两个样本 $\\mathbf{X} = (X_1, \\dots, X_n)$ 和 $\\mathbf{Y} = (Y_1, \\dots, Y_m)$ 的联合概率密度函数 (PDF) 是它们各自联合 PDF 的乘积：\n$$f(\\mathbf{x}, \\mathbf{y} | \\mu, \\theta, \\sigma^2) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\\right) \\prod_{j=1}^m \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_j - \\theta)^2}{2\\sigma^2}\\right)$$\n$$f(\\mathbf{x}, \\mathbf{y} | \\mu, \\theta, \\sigma^2) = \\left(\\frac{1}{2\\pi\\sigma^2}\\right)^{(n+m)/2} \\exp\\left(-\\frac{1}{2\\sigma^2} \\left[ \\sum_{i=1}^n (x_i - \\mu)^2 + \\sum_{j=1}^m (y_j - \\theta)^2 \\right]\\right)$$\n我们可以展开指数中的项：\n$$\\sum_{i=1}^n (x_i^2 - 2\\mu x_i + \\mu^2) + \\sum_{j=1}^m (y_j^2 - 2\\theta y_j + \\theta^2) = \\sum x_i^2 - 2\\mu \\sum x_i + n\\mu^2 + \\sum y_j^2 - 2\\theta \\sum y_j + m\\theta^2$$\n指数可以改写为：\n$$-\\frac{1}{2\\sigma^2} \\left(\\sum x_i^2 + \\sum y_j^2\\right) + \\frac{\\mu}{\\sigma^2}\\sum x_i + \\frac{\\theta}{\\sigma^2}\\sum y_j - \\frac{n\\mu^2 + m\\theta^2}{2\\sigma^2}$$\n这是一个三参数指数族的形式。根据 Fisher-Neyman 分解定理，$(\\mu, \\theta, \\sigma^2)$ 的一组充分统计量是 $S = \\left(\\sum_{i=1}^n X_i, \\sum_{j=1}^m Y_j, \\sum_{i=1}^n X_i^2 + \\sum_{j=1}^m Y_j^2\\right)$。由于正态分布族是满秩指数族，这个充分统计量也是完备的。\n\n根据 Rao-Blackwell 和 Lehmann-Scheffé 定理，$\\delta$ 的 UMVUE 是任意无偏估计量在给定完备充分统计量下的条件期望。我们将我们的 UMVUE 记为 $T^*$。\n$$T^* = E[T | S] = E\\left[X_1 - Y_1 \\left| \\sum X_i, \\sum Y_j, \\sum X_i^2 + \\sum Y_j^2 \\right.\\right]$$\n根据条件期望的线性性质：\n$$T^* = E\\left[X_1 \\left| S \\right.\\right] - E\\left[Y_1 \\left| S \\right.\\right]$$\n\n我们来计算 $E[X_1 | S]$。由于 $X_i$ 样本的独立同分布 (i.i.d.) 性质，随机变量 $X_1, X_2, \\dots, X_n$ 是可交换的。这意味着它们在给定对称函数 $S$ 下的条件期望都相等：\n$$E[X_1 | S] = E[X_2 | S] = \\dots = E[X_n | S]$$\n现在，考虑其和：\n$$\\sum_{i=1}^n E[X_i | S] = E\\left[\\sum_{i=1}^n X_i \\left| S \\right.\\right]$$\n和 $\\sum_{i=1}^n X_i$ 是充分统计量 $S$ 的一个分量。对 $S$ 取条件意味着我们将其分量视为已知常数。因此：\n$$E\\left[\\sum_{i=1}^n X_i \\left| S \\right.\\right] = \\sum_{i=1}^n X_i$$\n结合这些事实，我们得到：\n$$n E[X_1 | S] = \\sum_{i=1}^n X_i$$\n$$E[X_1 | S] = \\frac{1}{n} \\sum_{i=1}^n X_i = \\bar{X}$$\n这是 $X$ 样本的样本均值。注意，$\\bar{X}$ 是 $\\sum X_i$ 的函数，而 $\\sum X_i$ 是充分统计量 $S$ 的一部分。\n\n对 $Y$ 样本进行完全类似的论证：\n$$E[Y_1 | S] = E[Y_2 | S] = \\dots = E[Y_m | S]$$\n并且\n$$m E[Y_1 | S] = \\sum_{j=1}^m E[Y_j | S] = E\\left[\\sum_{j=1}^m Y_j \\left| S \\right.\\right] = \\sum_{j=1}^m Y_j$$\n$$E[Y_1 | S] = \\frac{1}{m} \\sum_{j=1}^m Y_j = \\bar{Y}$$\n\n将这些结果代回到 $T^*$ 的表达式中：\n$$T^* = E[X_1 | S] - E[Y_1 | S] = \\bar{X} - \\bar{Y}$$\nUMVUE 是样本均值之差。按照要求，用样本值和样本量表示为：\n$$T^* = \\frac{1}{n}\\sum_{i=1}^n X_i - \\frac{1}{m}\\sum_{j=1}^m Y_j$$\n这个估计量是完备充分统计量 $S$ 的函数并且是无偏的，因此它是 $\\delta = \\mu - \\theta$ 的 UMVUE。", "answer": "$$\\boxed{\\frac{1}{n}\\sum_{i=1}^{n} X_i - \\frac{1}{m}\\sum_{j=1}^{m} Y_j}$$", "id": "1922449"}, {"introduction": "Rao-Blackwell定理的威力远不止于标准的固定样本量问题，它在样本量本身就是随机变量的贯序试验(sequential experiment)中同样大有可为。本练习 [@problem_id:1922452] 将带你处理一个贯序抽样情景，以改进对成功概率$p$的估计。这项实践将锻炼你在动态设定下识别正确充分统计量并进行条件化的能力，最终揭示一个出人意料的优雅结果。", "problem": "一项序贯临床试验旨在测试一种新药。患者被逐一治疗，每个患者的结果为“成功”或“失败”。成功的概率 $p$ 假定对所有患者都是恒定的，其中 $0  p  1$。试验将持续进行，直到记录到恰好 $k$ 次成功。设 $N$ 为接受治疗的总患者数，它是一个随机变量。\n\n提出了一个初始、简单的成功概率 $p$ 的无偏估计量：$\\hat{p}_{crude} = X_1$，其中如果第一个患者结果成功，则 $X_1=1$，否则 $X_1=0$。\n\n根据统计理论，可以使用 Rao-Blackwell 定理来改进这个估计量。该过程涉及将 $\\hat{p}_{crude}$ 条件化于参数 $p$ 的一个充分统计量。对于这个试验设计，总试验次数 $N$ 是一个充分统计量。由此得到的 Rao-Blackwell化 估计量是 $\\hat{p}_{RB} = E[\\hat{p}_{crude} | N]$。\n\n您的任务是分析在试验设定为 $k=2$ 次成功后停止的特定情况下，估计质量的改善情况。计算方差缩减因子，其定义为比率 $\\mathcal{R} = \\frac{\\text{Var}(\\hat{p}_{crude})}{\\text{Var}(\\hat{p}_{RB})}$。将您的最终答案表示为 $p$ 的解析函数。", "solution": "我们的目标是计算方差缩减因子 $\\mathcal{R} = \\frac{\\text{Var}(\\hat{p}_{crude})}{\\text{Var}(\\hat{p}_{RB})}$。\n\n**1. 计算粗略估计量的方差**\n\n粗略估计量是 $\\hat{p}_{crude} = X_1$，其中 $X_1$ 是第一次试验的结果，服从伯努利分布 $X_1 \\sim \\text{Bernoulli}(p)$。其方差为：\n$$ \\text{Var}(\\hat{p}_{crude}) = \\text{Var}(X_1) = p(1-p) $$\n\n**2. 推导 Rao-Blackwell化 估计量**\n\nRao-Blackwell化估计量是 $\\hat{p}_{RB} = E[X_1 | N]$。我们可以通过计算条件概率 $P(X_1=1|N=n)$ 来得到它。\n$$ E[X_1 | N=n] = 1 \\cdot P(X_1=1 | N=n) + 0 \\cdot P(X_1=0 | N=n) = P(X_1=1 | N=n) $$\n根据贝叶斯法则：\n$$ P(X_1=1 | N=n) = \\frac{P(N=n | X_1=1)P(X_1=1)}{P(N=n)} $$\n-   $P(X_1=1) = p$。\n-   $N$ 是获得 $k$ 次成功所需的试验次数，因此 $N$ 服从负二项分布 $N \\sim \\text{NB}(k, p)$。其概率质量函数为 $P(N=n) = \\binom{n-1}{k-1}p^k(1-p)^{n-k}$，对于 $n \\ge k$。\n-   $P(N=n | X_1=1)$：如果第一次试验是成功，我们需要在接下来的试验中再获得 $k-1$ 次成功。设 $N'$ 是从第二次试验开始获得 $k-1$ 次成功所需的试验次数，$N' \\sim \\text{NB}(k-1, p)$。总试验次数 $N = 1 + N'$。因此，$N=n$ 意味着 $N'=n-1$。所以，$P(N=n | X_1=1) = P(N'=n-1) = \\binom{(n-1)-1}{(k-1)-1}p^{k-1}(1-p)^{(n-1)-(k-1)} = \\binom{n-2}{k-2}p^{k-1}(1-p)^{n-k}$，对于 $n-1 \\ge k-1$ 即 $n \\ge k$。\n\n将这些项代入，我们得到：\n$$ P(X_1=1 | N=n) = \\frac{\\left[\\binom{n-2}{k-2}p^{k-1}(1-p)^{n-k}\\right] \\cdot p}{\\binom{n-1}{k-1}p^k(1-p)^{n-k}} = \\frac{\\binom{n-2}{k-2}}{\\binom{n-1}{k-1}} = \\frac{(n-2)!/(k-2)!(n-k)!}{(n-1)!/(k-1)!(n-k)!} = \\frac{k-1}{n-1} $$\n所以，Rao-Blackwell化估计量为 $\\hat{p}_{RB} = \\frac{k-1}{N-1}$。对于本题中 $k=2$ 的情况，我们有 $\\hat{p}_{RB} = \\frac{1}{N-1}$。\n\n**3. 计算 Rao-Blackwell化 估计量的方差**\n\n我们需要计算 $\\text{Var}(\\hat{p}_{RB}) = \\text{Var}\\left(\\frac{1}{N-1}\\right)$，其中 $N \\sim \\text{NB}(k=2, p)$。\n首先，求 $E[\\hat{p}_{RB}]$ 和 $E[\\hat{p}_{RB}^2]$。\n对于 $k=2$，$P(N=n) = \\binom{n-1}{1}p^2(1-p)^{n-2} = (n-1)p^2(1-p)^{n-2}$，对于 $n \\ge 2$。\n\n$$ E\\left[\\frac{1}{N-1}\\right] = \\sum_{n=2}^{\\infty} \\frac{1}{n-1} (n-1)p^2(1-p)^{n-2} = p^2 \\sum_{n=2}^{\\infty} (1-p)^{n-2} $$\n令 $j=n-2$，该和变为 $p^2 \\sum_{j=0}^{\\infty} (1-p)^j = p^2 \\cdot \\frac{1}{1-(1-p)} = p^2 \\cdot \\frac{1}{p} = p$。\n这证实了 $\\hat{p}_{RB}$ 是无偏的。\n\n$$ E\\left[\\left(\\frac{1}{N-1}\\right)^2\\right] = \\sum_{n=2}^{\\infty} \\frac{1}{(n-1)^2} (n-1)p^2(1-p)^{n-2} = p^2 \\sum_{n=2}^{\\infty} \\frac{(1-p)^{n-2}}{n-1} $$\n令 $q=1-p$ 和 $j=n-1$，该和变为 $p^2 \\sum_{j=1}^{\\infty} \\frac{q^{j-1}}{j} = \\frac{p^2}{q} \\sum_{j=1}^{\\infty} \\frac{q^j}{j}$。\n级数 $\\sum_{j=1}^{\\infty} \\frac{q^j}{j}$ 是 $-\\ln(1-q)$ 的泰勒展开式。\n所以，$E[\\hat{p}_{RB}^2] = \\frac{p^2}{1-p} [-\\ln(1-(1-p))] = \\frac{-p^2\\ln(p)}{1-p}$。\n\n现在，计算方差：\n$$ \\text{Var}(\\hat{p}_{RB}) = E[\\hat{p}_{RB}^2] - (E[\\hat{p}_{RB}])^2 = \\frac{-p^2\\ln(p)}{1-p} - p^2 = p^2\\left(\\frac{-\\ln(p)}{1-p} - 1\\right) = \\frac{p^2(-\\ln p - 1 + p)}{1-p} $$\n\n**4. 计算方差缩减因子**\n\n$$ \\mathcal{R} = \\frac{\\text{Var}(\\hat{p}_{crude})}{\\text{Var}(\\hat{p}_{RB})} = \\frac{p(1-p)}{\\frac{p^2(p-1-\\ln p)}{1-p}} = \\frac{p(1-p)^2}{p^2(p-1-\\ln p)} = \\frac{(1-p)^2}{p(p-1-\\ln p)} $$", "answer": "$$\\boxed{\\frac{(1-p)^{2}}{p\\left(p-1-\\ln p\\right)}}$$", "id": "1922452"}, {"introduction": "除了理论统计学，Rao-Blackwellization也是高效计算方法的基石，尤其是在贝叶斯蒙特卡洛模拟中。从分析上积分掉参数（一个被称为“边缘化”的过程）是条件化的一种强大形式。这个动手练习 [@problem_id:3315544] 要求你比较两种用于后验预测概率的蒙特卡洛估计量。通过这样做，你将凭经验验证，通过将随机变量替换为其条件期望来“Rao-Blackwell化”一个模拟过程，能够如何显著地减少方差并提高计算效率。", "problem": "考虑由一个似然和一个先验定义的分层模型。设 $x_1,\\dots,x_n \\mid \\theta \\stackrel{\\text{ind}}{\\sim} \\operatorname{Poisson}(\\theta)$ 且 $\\theta \\sim \\operatorname{Gamma}(\\alpha,\\beta)$，其中 $\\operatorname{Gamma}(\\alpha,\\beta)$ 表示形状参数为 $\\alpha$、率参数为 $\\beta$ 的伽马分布（因此其概率密度函数与 $\\theta^{\\alpha-1}\\exp(-\\beta \\theta)$ 成正比）。定义联合分布 $f(x,\\theta)=f(x\\mid \\theta)\\,\\pi(\\theta)$，以及边缘分布（也称为证据或边缘似然）$m(x)=\\int f(x\\mid \\theta)\\,\\pi(\\theta)\\,\\mathrm{d}\\theta$。在观测到数据 $x=(x_1,\\dots,x_n)$ 后，$\\theta$ 的后验分布为 $\\pi(\\theta\\mid x)\\propto f(x\\mid \\theta)\\,\\pi(\\theta)$，新计数 $Y$ 的后验预测分布为 $m(y\\mid x)=\\int f(y\\mid \\theta)\\,\\pi(\\theta\\mid x)\\,\\mathrm{d}\\theta$。\n\n任务：\n- 从联合分布、边缘分布和条件分布的核心定义出发，推导后验分布 $\\pi(\\theta\\mid x)$ 以及后验预测质量函数 $m(y\\mid x)$ 的闭式表达式，适用于上述共轭对。您的推导必须从 $f(x\\mid \\theta)=\\prod_{i=1}^n \\frac{\\exp(-\\theta)\\,\\theta^{x_i}}{x_i!}$ 和 $\\pi(\\theta)\\propto \\theta^{\\alpha-1}\\exp(-\\beta \\theta)$ 开始，并遵循基本原理进行，直至定义 $m(y\\mid x)$ 的积分；不要通过调用预先记下的最终表达式来跳过步骤。\n- 构建并比较 $m(y\\mid x)$ 的两个无偏蒙特卡洛 (MC) 估计量：\n  1. 一个数值积分估计量，它从 $\\pi(\\theta\\mid x)$ 中独立同分布地抽取样本 $\\theta_1,\\dots,\\theta_N \\stackrel{\\text{iid}}{\\sim} \\pi(\\theta\\mid x)$，并计算 $\\widehat{m}_{\\text{num}}(y\\mid x)=\\frac{1}{N}\\sum_{j=1}^N f(y\\mid \\theta_j)$。\n  2. 一个首先通过解析方法对 $\\theta$ 进行积分，以获得 $Y\\mid x$ 的闭式后验预测分布的估计量，然后从 $m(\\cdot\\mid x)$ 中独立同分布地抽取样本 $Y_1,\\dots,Y_N \\stackrel{\\text{iid}}{\\sim} m(\\cdot\\mid x)$，并计算 $\\widehat{m}_{\\text{an}}(y\\mid x)=\\frac{1}{N}\\sum_{j=1}^N \\mathbb{I}\\{Y_j=y\\}$。\n从概念上，根据条件期望和拉奥-布莱克维尔 (Rao–Blackwell) 定理，解释为什么这两个估计量的方差不同，并将此差异与层次结构 $Y\\mid \\theta$ 和 $\\theta\\mid x$ 的结构联系起来。\n\n使用以下参数值测试套件来评估和比较这些估计量。在所有情况下，将伪随机数生成器种子固定为 $12345$，以便输出是确定性的。\n\n- 测试用例 1：$\\alpha=3$, $\\beta=1.2$, $x=(3,1,0,2)$, 目标 $y=2$, MC 样本量 $N=100000$。\n- 测试用例 2：$\\alpha=1$, $\\beta=0.5$, $x=()$ (空, 所以 $n=0$), 目标 $y=0$, MC 样本量 $N=100000$。\n- 测试用例 3：$\\alpha=10$, $\\beta=3$, $x=(10,9,12,8,11)$, 目标 $y=15$, MC 样本量 $N=100000$。\n\n您的程序必须：\n- 为每个测试用例计算闭式值 $m(y\\mid x)$。\n- 为每个测试用例计算如上定义的 $\\widehat{m}_{\\text{num}}(y\\mid x)$ 和 $\\widehat{m}_{\\text{an}}(y\\mid x)$。\n- 按顺序为每个测试用例返回以下五个浮点数：闭式 $m(y\\mid x)$、数值积分 MC 估计值 $\\widehat{m}_{\\text{num}}(y\\mid x)$、解析积分 MC 估计值 $\\widehat{m}_{\\text{an}}(y\\mid x)$、绝对误差 $\\left|\\widehat{m}_{\\text{num}}(y\\mid x)-m(y\\mid x)\\right|$ 和绝对误差 $\\left|\\widehat{m}_{\\text{an}}(y\\mid x)-m(y\\mid x)\\right|$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表。首先是测试用例 1 的 5 个浮点数，然后是测试用例 2 的 5 个浮点数，最后是测试用例 3 的 5 个浮点数；例如，$[m_1,\\widehat{m}_{\\text{num},1},\\widehat{m}_{\\text{an},1},e_{\\text{num},1},e_{\\text{an},1},m_2,\\dots]$。\n- 此问题不涉及物理单位或角度单位。所有输出必须是实数。", "solution": "### 解析推导\n\n**1. 后验分布 $\\pi(\\theta\\mid x)$ 的推导**\n\n给定观测数据 $x=(x_1, \\dots, x_n)$，$\\theta$ 的后验分布由贝叶斯定理给出：\n$$\n\\pi(\\theta\\mid x) \\propto f(x\\mid\\theta)\\,\\pi(\\theta)\n$$\n对于来自 $\\operatorname{Poisson}(\\theta)$ 分布的 $n$ 个独立同分布的观测值，似然函数 $f(x\\mid\\theta)$ 是：\n$$\nf(x\\mid\\theta) = \\prod_{i=1}^n \\frac{\\exp(-\\theta)\\,\\theta^{x_i}}{x_i!} = \\frac{\\exp(-n\\theta)\\,\\theta^{\\sum_{i=1}^n x_i}}{\\prod_{i=1}^n x_i!}\n$$\n$\\theta$ 的先验分布是 $\\operatorname{Gamma}(\\alpha,\\beta)$，其概率密度函数 (PDF) 正比于：\n$$\n\\pi(\\theta) \\propto \\theta^{\\alpha-1}\\exp(-\\beta \\theta)\n$$\n结合似然和先验，后验分布正比于：\n$$\n\\pi(\\theta\\mid x) \\propto \\left( \\exp(-n\\theta)\\,\\theta^{\\sum_{i=1}^n x_i} \\right) \\left( \\theta^{\\alpha-1}\\exp(-\\beta \\theta) \\right)\n\\propto \\theta^{(\\alpha + \\sum x_i) - 1} \\exp(-(\\beta+n)\\theta)\n$$\n这个表达式是伽马分布的核。定义后验参数 $\\alpha' = \\alpha + \\sum_{i=1}^n x_i$ 和 $\\beta' = \\beta + n$，后验分布是 $\\theta\\mid x \\sim \\operatorname{Gamma}(\\alpha', \\beta')$。\n\n**2. 后验预测质量函数 $m(y\\mid x)$ 的推导**\n\n新观测值 $Y$ 的后验预测分布是通过将 $Y$ 的似然在 $\\theta$ 的后验分布上求积分得到的：\n$$\nm(y\\mid x) = \\int_0^\\infty f(y\\mid\\theta)\\,\\pi(\\theta\\mid x)\\,\\mathrm{d}\\theta\n$$\n其中 $f(y\\mid\\theta) = \\frac{\\exp(-\\theta)\\,\\theta^y}{y!}$ (泊松 PMF)，$\\pi(\\theta\\mid x) = \\frac{(\\beta')^{\\alpha'}}{\\Gamma(\\alpha')} \\theta^{\\alpha'-1} \\exp(-\\beta'\\theta)$ (伽马 PDF)。\n$$\nm(y\\mid x) = \\int_0^\\infty \\left( \\frac{e^{-\\theta}\\theta^y}{y!} \\right) \\left( \\frac{(\\beta')^{\\alpha'}}{\\Gamma(\\alpha')} \\theta^{\\alpha'-1} e^{-\\beta'\\theta} \\right) \\mathrm{d}\\theta\n= \\frac{(\\beta')^{\\alpha'}}{y!\\Gamma(\\alpha')} \\int_0^\\infty \\theta^{(y+\\alpha')-1} e^{-(\\beta'+1)\\theta} \\mathrm{d}\\theta\n$$\n积分部分是另一个伽马分布核的积分，其值为 $\\frac{\\Gamma(y+\\alpha')}{(\\beta'+1)^{y+\\alpha'}}$。代入后得到：\n$$\nm(y\\mid x) = \\frac{(\\beta')^{\\alpha'}}{y!\\Gamma(\\alpha')} \\frac{\\Gamma(y+\\alpha')}{(\\beta'+1)^{y+\\alpha'}}\n= \\frac{\\Gamma(y+\\alpha')}{y!\\Gamma(\\alpha')} \\left( \\frac{\\beta'}{\\beta'+1} \\right)^{\\alpha'} \\left( \\frac{1}{\\beta'+1} \\right)^y\n$$\n这正是负二项分布的概率质量函数 $Y\\mid x \\sim \\operatorname{NB}(r=\\alpha', p=\\frac{\\beta'}{\\beta'+1})$。\n\n### 方差比较的解释\n\n我们比较两个对 $m(y\\mid x) = P(Y=y \\mid x)$ 的无偏估计量。\n1.  **$\\widehat{m}_{\\text{num}}(y\\mid x) = \\frac{1}{N}\\sum_{j=1}^N f(y\\mid \\theta_j)$**，其中 $\\theta_j \\sim \\pi(\\theta\\mid x)$。\n2.  **$\\widehat{m}_{\\text{an}}(y\\mid x) = \\frac{1}{N}\\sum_{j=1}^N \\mathbb{I}\\{Y_j=y\\}$**，其中 $Y_j \\sim m(\\cdot\\mid x)$。\n\n这两个估计量方差的差异是 Rao-Blackwell 定理的一个经典例子。考虑随机变量 $W_j = \\mathbb{I}\\{Y_j=y\\}$，它的期望是 $m(y|x)$。这是 $\\widehat{m}_{\\text{an}}$ 使用的随机变量。\n\nRao-Blackwellization 的思想是，将 $W_j$ 替换为其在辅助信息（此处是参数 $\\theta_j$）下的条件期望。这个条件期望是：\n$$ \\mathbb{E}[W_j \\mid \\theta_j] = \\mathbb{E}[\\mathbb{I}\\{Y_j=y\\} \\mid \\theta_j] = P(Y_j=y \\mid \\theta_j) = f(y \\mid \\theta_j) $$\n这正是估计量 $\\widehat{m}_{\\text{num}}$ 使用的随机变量 $Z_j = f(y \\mid \\theta_j)$。\n\n根据全方差定律：\n$$ \\operatorname{Var}(W_j) = \\mathbb{E}[\\operatorname{Var}(W_j \\mid \\theta_j)] + \\operatorname{Var}(\\mathbb{E}[W_j \\mid \\theta_j]) $$\n代入我们的变量：\n$$ \\operatorname{Var}_{Y|x}(\\mathbb{I}\\{Y=y\\}) = \\mathbb{E}_{\\theta|x}[\\operatorname{Var}_{Y|\\theta}(\\mathbb{I}\\{Y=y\\})] + \\operatorname{Var}_{\\theta|x}(f(y|\\theta)) $$\n由于方差非负，第一项 $\\mathbb{E}[\\operatorname{Var}(W_j \\mid \\theta_j)] \\ge 0$。因此：\n$$ \\operatorname{Var}_{\\theta|x}(f(y|\\theta)) \\le \\operatorname{Var}_{Y|x}(\\mathbb{I}\\{Y=y\\}) $$\n这意味着构成 $\\widehat{m}_{\\text{num}}$ 的随机变量的方差小于或等于构成 $\\widehat{m}_{\\text{an}}$ 的随机变量的方差。因此，对于相同的样本量 $N$，我们有 $\\operatorname{Var}(\\widehat{m}_{\\text{num}}) \\le \\operatorname{Var}(\\widehat{m}_{\\text{an}})$。\n\n从概念上讲，$\\widehat{m}_{\\text{an}}$ 估计量包含两层随机性：一层来自 $\\theta$ 的不确定性（隐式地），另一层来自给定 $\\theta$ 后 $Y$ 的泊松抽样过程。而 $\\widehat{m}_{\\text{num}}$（Rao-Blackwell化的）估计量通过解析地计算条件期望 $f(y|\\theta)$，消除了第二层随机性（泊松抽样），从而降低了总方差。", "answer": "[0.15570081,0.15569420,0.15551000,0.00000661,0.00019081,0.33333333,0.33314068,0.33367000,0.00019266,0.00033667,0.02106606,0.02106456,0.02073000,0.00000150,0.00033606]", "id": "3315544"}]}