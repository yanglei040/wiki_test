{"hands_on_practices": [{"introduction": "这个练习是基础。它提供了一个具体的场景来实践控制变量的核心机制：为一组给定的控制变量计算最优线性系数，并量化由此产生的方差缩减。掌握这个过程 [@problem_id:3325570] 是有效使用和选择控制变量的第一步。", "problem": "您正在使用控制变量的蒙特卡洛抽样方法来估计一个随机变量 $\\,X\\,$ 的未知均值 $\\,\\mu = \\mathbb{E}[X]\\,$。在每次重复试验中，使用基于共同随机数的相关抽样：相同的潜在噪声源驱动目标 $\\,X\\,$ 和控制变量 $\\,C_{j}\\,$。设 $\\,U_{0}, U_{1}, U_{2}\\,$ 和 $\\,V_{1}, V_{2}, V_{3}\\,$ 是相互独立的标准正态随机变量。目标和三个候选控制变量定义如下\n$$\nX \\;=\\; 3\\,U_{0} \\;+\\; 2\\,U_{1} \\;+\\; 1\\,U_{2}, \n$$\n$$\nC_{1} \\;=\\; 2\\,U_{0} \\;+\\; 1\\,U_{1} \\;+\\; \\sqrt{0.5}\\,V_{1},\\qquad\nC_{2} \\;=\\; 1\\,U_{0} \\;+\\; 2\\,U_{2} \\;+\\; \\sqrt{0.25}\\,V_{2},\\qquad\nC_{3} \\;=\\; 1.5\\,U_{1} \\;+\\; 0.5\\,U_{2} \\;+\\; \\sqrt{0.75}\\,V_{3}.\n$$\n假设对于所有 $\\,j\\,$，$\\,\\mathbb{E}[C_{j}] = 0\\,$ 均是已知的。考虑单次重复试验的控制估计量\n$$\nY(\\boldsymbol{a}) \\;=\\; X \\;-\\; \\sum_{j\\in S} a_{j}\\,C_{j},\n$$\n其中 $\\,S\\,$ 是一个选定的控制变量子集，而 $\\,\\boldsymbol{a} = (a_{j})_{j\\in S}\\,$ 是确定性系数。$\\,Y(\\boldsymbol{a})\\,$ 的无偏性由控制变量的定义保证。\n\n从第一性原理出发——即方差的定义、协方差的双线性性质以及无约束二次最小化的微积分方法——推导出对于给定的子集 $\\,S\\,$，使 $\\,\\mathrm{Var}\\!\\left(Y(\\boldsymbol{a})\\right)\\,$ 最小化的系数向量 $\\,\\boldsymbol{a}^{\\star}\\,$。然后，利用共同随机数引出的给定相关性结构，计算以下内容：\n\n1. 当 $\\,S = \\{1,2\\}\\,$ 时，最优系数向量 $\\,\\boldsymbol{a}^{\\star}\\,$ 和得到的最小单次重复试验方差 $\\,\\mathrm{Var}\\!\\left(Y(\\boldsymbol{a}^{\\star})\\right)\\,$。\n2. 当 $\\,S = \\{1,3\\}\\,$ 时，最优系数向量 $\\,\\boldsymbol{a}^{\\star}\\,$ 和得到的最小单次重复试验方差 $\\,\\mathrm{Var}\\!\\left(Y(\\boldsymbol{a}^{\\star})\\right)\\,$。\n\n最后，确定哪个子集 $\\,S\\,$ 能得到更小的最小方差，并将更优子集的两个最优系数以及该最小方差作为您的最终答案报告。\n\n您的最终答案必须是一个包含三个条目 $\\,\\big(a_{j}^{\\star}\\big)_{j\\in S}\\,$ 和 $\\,\\mathrm{Var}\\!\\left(Y(\\boldsymbol{a}^{\\star})\\right)\\,$ 的单行矩阵。无需四舍五入。不涉及单位。", "solution": "用户希望我解决一个关于蒙特卡洛模拟中控制变量的问题。\n\n**问题验证**\n\n**步骤 1：提取已知条件**\n\n问题提供了以下数据和定义：\n-   独立的标准正态随机变量：$U_{0}, U_{1}, U_{2}, V_{1}, V_{2}, V_{3}$。\n-   目标随机变量：$X = 3\\,U_{0} + 2\\,U_{1} + 1\\,U_{2}$。\n-   候选控制变量：\n    -   $C_{1} = 2\\,U_{0} + 1\\,U_{1} + \\sqrt{0.5}\\,V_{1}$\n    -   $C_{2} = 1\\,U_{0} + 2\\,U_{2} + \\sqrt{0.25}\\,V_{2}$\n    -   $C_{3} = 1.5\\,U_{1} + 0.5\\,U_{2} + \\sqrt{0.75}\\,V_{3}$\n-   控制变量的已知期望：对所有 $j$，$\\mathbb{E}[C_{j}] = 0$。\n-   对于控制变量子集 $S$ 和系数向量 $\\boldsymbol{a} = (a_{j})_{j\\in S}$ 的控制估计量：$Y(\\boldsymbol{a}) = X - \\sum_{j\\in S} a_{j}\\,C_{j}$。\n-   目标是找到使 $\\mathrm{Var}(Y(\\boldsymbol{a}))$ 最小化的最优系数向量 $\\boldsymbol{a}^{\\star}$。这必须对两个子集 $S = \\{1,2\\}$ 和 $S = \\{1,3\\}$ 完成。最后，比较最小方差，并报告更优子集的系数和方差。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n1.  **科学性：** 该问题属于蒙特卡洛方法这一成熟领域，具体涉及使用控制变量减少方差。使用高斯随机变量的线性组合的设置是演示这些原理的标准、易处理的模型。\n2.  **适定性：** 目标是最小化控制估计量的方差，该方差是系数的二次函数。这是一个无约束二次规划问题，只要控制变量的协方差矩阵是正定的（由于控制变量不是线性相关的，所以情况确实如此），它就有一个唯一解。\n3.  **客观性：** 问题使用精确的数学定义和语言陈述。没有主观性或歧义。\n4.  **完整性和一致性：** 提供了所有必要信息。给出了 $X$ 和 $C_j$ 的定义，并且底层噪声项（$U_i, V_j$）的统计属性被指定为独立的标准正态分布。条件 $\\mathbb{E}[C_{j}] = 0$ 与它们的定义是一致的，因为它们是零均值变量的线性组合。问题是自洽的。任务被明确规定。\n\n**步骤 3：结论和行动**\n\n问题是有效的。这是随机模拟中的一个标准、适定的问题。我将进行完整解答。\n\n**解题推导**\n\n问题要求从第一性原理进行推导。\n\n**1. 最优系数的一般推导**\n\n设 $S$ 是一个选定的控制变量子集。控制估计量为 $Y(\\boldsymbol{a}) = X - \\sum_{j \\in S} a_j C_j$。我们可以将其写成向量形式 $Y(\\boldsymbol{a}) = X - \\boldsymbol{a}^T \\boldsymbol{C}$，其中 $\\boldsymbol{C}$ 是控制变量 $(C_j)_{j \\in S}$ 的列向量，$\\boldsymbol{a}$ 是系数 $(a_j)_{j \\in S}$ 的列向量。\n\n目标是最小化 $Y(\\boldsymbol{a})$ 的方差：\n$$\n\\mathrm{Var}(Y(\\boldsymbol{a})) = \\mathrm{Var}(X - \\boldsymbol{a}^T \\boldsymbol{C})\n$$\n利用协方差的双线性性质，其中 $\\mathrm{Var}(Z) = \\mathrm{Cov}(Z,Z)$：\n$$\n\\mathrm{Var}(Y(\\boldsymbol{a})) = \\mathrm{Cov}(X - \\boldsymbol{a}^T \\boldsymbol{C}, X - \\boldsymbol{a}^T \\boldsymbol{C})\n$$\n$$\n\\mathrm{Var}(Y(\\boldsymbol{a})) = \\mathrm{Cov}(X,X) - \\mathrm{Cov}(X, \\boldsymbol{a}^T \\boldsymbol{C}) - \\mathrm{Cov}(\\boldsymbol{a}^T \\boldsymbol{C}, X) + \\mathrm{Cov}(\\boldsymbol{a}^T \\boldsymbol{C}, \\boldsymbol{a}^T \\boldsymbol{C})\n$$\n由于系数 $\\boldsymbol{a}$ 是确定性的：\n$$\n\\mathrm{Var(Y(\\boldsymbol{a}))} = \\mathrm{Var}(X) - \\boldsymbol{a}^T \\mathrm{Cov}(\\boldsymbol{C}, X) - \\mathrm{Cov}(X, \\boldsymbol{C}) \\boldsymbol{a} + \\boldsymbol{a}^T \\mathrm{Cov}(\\boldsymbol{C}, \\boldsymbol{C}) \\boldsymbol{a}\n$$\n令 $\\sigma_X^2 = \\mathrm{Var}(X)$，$\\boldsymbol{\\sigma}_{XC} = \\mathrm{Cov}(X, \\boldsymbol{C})$（一个列向量），以及 $\\boldsymbol{\\Sigma}_{CC} = \\mathrm{Cov}(\\boldsymbol{C}, \\boldsymbol{C})$（控制变量的协方差矩阵）。注意 $\\mathrm{Cov}(\\boldsymbol{C}, X) = \\mathrm{Cov}(X, \\boldsymbol{C})^T = \\boldsymbol{\\sigma}_{XC}^T$。作为 $\\boldsymbol{a}$ 的函数，要最小化的方差是：\n$$\nf(\\boldsymbol{a}) = \\sigma_X^2 - 2 \\boldsymbol{a}^T \\boldsymbol{\\sigma}_{XC} + \\boldsymbol{a}^T \\boldsymbol{\\Sigma}_{CC} \\boldsymbol{a}\n$$\n这是 $\\boldsymbol{a}$ 的二次函数。为了找到最小值，我们对 $\\boldsymbol{a}$ 求梯度并将其设为零。\n$$\n\\nabla_{\\boldsymbol{a}} f(\\boldsymbol{a}) = -2 \\boldsymbol{\\sigma}_{XC} + 2 \\boldsymbol{\\Sigma}_{CC} \\boldsymbol{a}\n$$\n将梯度设为零以找到最优系数向量 $\\boldsymbol{a}^{\\star}$：\n$$\n-2 \\boldsymbol{\\sigma}_{XC} + 2 \\boldsymbol{\\Sigma}_{CC} \\boldsymbol{a}^{\\star} = \\boldsymbol{0}\n$$\n$$\n\\boldsymbol{\\Sigma}_{CC} \\boldsymbol{a}^{\\star} = \\boldsymbol{\\sigma}_{XC}\n$$\n假设 $\\boldsymbol{\\Sigma}_{CC}$ 是可逆的（由于控制变量不是完全共线的，所以确实如此），最优系数向量是：\n$$\n\\boldsymbol{a}^{\\star} = \\boldsymbol{\\Sigma}_{CC}^{-1} \\boldsymbol{\\sigma}_{XC}\n$$\n将 $\\boldsymbol{a}^{\\star}$ 代回 $f(\\boldsymbol{a})$ 可得到最小方差：\n$$\n\\mathrm{Var}(Y(\\boldsymbol{a}^{\\star})) = \\sigma_X^2 - 2 (\\boldsymbol{a}^{\\star})^T \\boldsymbol{\\sigma}_{XC} + (\\boldsymbol{a}^{\\star})^T \\boldsymbol{\\Sigma}_{CC} \\boldsymbol{a}^{\\star}\n$$\n代入 $\\boldsymbol{a}^{\\star} = \\boldsymbol{\\Sigma}_{CC}^{-1} \\boldsymbol{\\sigma}_{XC}$ 和 $(\\boldsymbol{a}^{\\star})^T = \\boldsymbol{\\sigma}_{XC}^T (\\boldsymbol{\\Sigma}_{CC}^{-1})^T$。由于 $\\boldsymbol{\\Sigma}_{CC}$ 是对称的，其逆矩阵也是对称的，所以 $(\\boldsymbol{\\Sigma}_{CC}^{-1})^T = \\boldsymbol{\\Sigma}_{CC}^{-1}$。\n$$\n\\mathrm{Var}(Y(\\boldsymbol{a}^{\\star})) = \\sigma_X^2 - 2 \\boldsymbol{\\sigma}_{XC}^T \\boldsymbol{\\Sigma}_{CC}^{-1} \\boldsymbol{\\sigma}_{XC} + (\\boldsymbol{\\sigma}_{XC}^T \\boldsymbol{\\Sigma}_{CC}^{-1}) \\boldsymbol{\\Sigma}_{CC} (\\boldsymbol{\\Sigma}_{CC}^{-1} \\boldsymbol{\\sigma}_{XC})\n$$\n$$\n\\mathrm{Var}(Y(\\boldsymbol{a}^{\\star})) = \\sigma_X^2 - 2 \\boldsymbol{\\sigma}_{XC}^T \\boldsymbol{\\Sigma}_{CC}^{-1} \\boldsymbol{\\sigma}_{XC} + \\boldsymbol{\\sigma}_{XC}^T \\boldsymbol{\\Sigma}_{CC}^{-1} \\boldsymbol{\\sigma}_{XC}\n$$\n$$\n\\mathrm{Var}(Y(\\boldsymbol{a}^{\\star})) = \\sigma_X^2 - \\boldsymbol{\\sigma}_{XC}^T \\boldsymbol{\\Sigma}_{CC}^{-1} \\boldsymbol{\\sigma}_{XC} = \\sigma_X^2 - \\boldsymbol{\\sigma}_{XC}^T \\boldsymbol{a}^{\\star}\n$$\n\n**2. 所需方差和协方差的计算**\n\n随机变量 $U_0, U_1, U_2, V_1, V_2, V_3$ 是相互独立的，均值为 0，方差为 1。对于任意两个变量 $A = \\sum \\alpha_i W_i$ 和 $B = \\sum \\beta_i W_i$，其中 $W_i$ 是这些基础随机变量，我们有 $\\mathrm{Var}(A) = \\sum \\alpha_i^2$ 和 $\\mathrm{Cov}(A,B) = \\sum \\alpha_i \\beta_i$。\n\n- $\\mathrm{Var}(X) = 3^2 + 2^2 + 1^2 = 9 + 4 + 1 = 14$\n- $\\mathrm{Var}(C_1) = 2^2 + 1^2 + (\\sqrt{0.5})^2 = 4 + 1 + 0.5 = 5.5 = \\frac{11}{2}$\n- $\\mathrm{Var}(C_2) = 1^2 + 2^2 + (\\sqrt{0.25})^2 = 1 + 4 + 0.25 = 5.25 = \\frac{21}{4}$\n- $\\mathrm{Var}(C_3) = (1.5)^2 + (0.5)^2 + (\\sqrt{0.75})^2 = 2.25 + 0.25 + 0.75 = 3.25 = \\frac{13}{4}$\n\n- $\\mathrm{Cov}(X, C_1) = (3)(2) + (2)(1) + (1)(0) = 8$\n- $\\mathrm{Cov}(X, C_2) = (3)(1) + (2)(0) + (1)(2) = 5$\n- $\\mathrm{Cov}(X, C_3) = (3)(0) + (2)(1.5) + (1)(0.5) = 3 + 0.5 = 3.5 = \\frac{7}{2}$\n\n- $\\mathrm{Cov}(C_1, C_2) = (2)(1) + (1)(0) + (0)(2) = 2$\n- $\\mathrm{Cov}(C_1, C_3) = (2)(0) + (1)(1.5) + (0)(0.5) = 1.5 = \\frac{3}{2}$\n- $\\mathrm{Cov}(C_2, C_3) = (1)(0) + (0)(1.5) + (2)(0.5) = 1$\n\n**3. 对子集 $S = \\{1, 2\\}$ 的分析**\n\n这里，$\\boldsymbol{C} = (C_1, C_2)^T$。\n所需的向量和矩阵是：\n$\\boldsymbol{\\sigma}_{XC} = \\begin{pmatrix} \\mathrm{Cov}(X, C_1) \\\\ \\mathrm{Cov}(X, C_2) \\end{pmatrix} = \\begin{pmatrix} 8 \\\\ 5 \\end{pmatrix}$\n$\\boldsymbol{\\Sigma}_{CC} = \\begin{pmatrix} \\mathrm{Var}(C_1)  \\mathrm{Cov}(C_1, C_2) \\\\ \\mathrm{Cov}(C_2, C_1)  \\mathrm{Var}(C_2) \\end{pmatrix} = \\begin{pmatrix} 5.5  2 \\\\ 2  5.25 \\end{pmatrix} = \\begin{pmatrix} \\frac{11}{2}  2 \\\\ 2  \\frac{21}{4} \\end{pmatrix}$\n\n首先，我们计算 $\\boldsymbol{\\Sigma}_{CC}$ 的逆矩阵：\n$\\det(\\boldsymbol{\\Sigma}_{CC}) = (\\frac{11}{2})(\\frac{21}{4}) - (2)(2) = \\frac{231}{8} - 4 = \\frac{231 - 32}{8} = \\frac{199}{8}$\n$\\boldsymbol{\\Sigma}_{CC}^{-1} = \\frac{1}{\\det(\\boldsymbol{\\Sigma}_{CC})} \\begin{pmatrix} \\frac{21}{4}  -2 \\\\ -2  \\frac{11}{2} \\end{pmatrix} = \\frac{8}{199} \\begin{pmatrix} \\frac{21}{4}  -2 \\\\ -2  \\frac{11}{2} \\end{pmatrix} = \\frac{1}{199} \\begin{pmatrix} 42  -16 \\\\ -16  44 \\end{pmatrix}$\n\n现在，我们求最优系数 $\\boldsymbol{a}^{\\star} = (a_1^{\\star}, a_2^{\\star})^T$：\n$\\boldsymbol{a}^{\\star} = \\boldsymbol{\\Sigma}_{CC}^{-1} \\boldsymbol{\\sigma}_{XC} = \\frac{1}{199} \\begin{pmatrix} 42  -16 \\\\ -16  44 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 5 \\end{pmatrix} = \\frac{1}{199} \\begin{pmatrix} 42 \\cdot 8 - 16 \\cdot 5 \\\\ -16 \\cdot 8 + 44 \\cdot 5 \\end{pmatrix} = \\frac{1}{199} \\begin{pmatrix} 336 - 80 \\\\ -128 + 220 \\end{pmatrix} = \\frac{1}{199} \\begin{pmatrix} 256 \\\\ 92 \\end{pmatrix}$\n所以，$a_1^{\\star} = \\frac{256}{199}$ 且 $a_2^{\\star} = \\frac{92}{199}$。\n\n最小方差是：\n$\\mathrm{Var}(Y(\\boldsymbol{a}^{\\star})) = \\mathrm{Var}(X) - \\boldsymbol{\\sigma}_{XC}^T \\boldsymbol{a}^{\\star} = 14 - \\begin{pmatrix} 8  5 \\end{pmatrix} \\begin{pmatrix} 256/199 \\\\ 92/199 \\end{pmatrix}$\n$\\mathrm{Var}(Y(\\boldsymbol{a}^{\\star})) = 14 - \\frac{8 \\cdot 256 + 5 \\cdot 92}{199} = 14 - \\frac{2048 + 460}{199} = 14 - \\frac{2508}{199}$\n$\\mathrm{Var}(Y(\\boldsymbol{a}^{\\star})) = \\frac{14 \\cdot 199 - 2508}{199} = \\frac{2786 - 2508}{199} = \\frac{278}{199}$\n\n**4. 对子集 $S = \\{1, 3\\}$ 的分析**\n\n这里，$\\boldsymbol{C} = (C_1, C_3)^T$。\n所需的向量和矩阵是：\n$\\boldsymbol{\\sigma}_{XC} = \\begin{pmatrix} \\mathrm{Cov}(X, C_1) \\\\ \\mathrm{Cov}(X, C_3) \\end{pmatrix} = \\begin{pmatrix} 8 \\\\ 3.5 \\end{pmatrix} = \\begin{pmatrix} 8 \\\\ \\frac{7}{2} \\end{pmatrix}$\n$\\boldsymbol{\\Sigma}_{CC} = \\begin{pmatrix} \\mathrm{Var}(C_1)  \\mathrm{Cov}(C_1, C_3) \\\\ \\mathrm{Cov(C_3, C_1)}  \\mathrm{Var}(C_3) \\end{pmatrix} = \\begin{pmatrix} 5.5  1.5 \\\\ 1.5  3.25 \\end{pmatrix} = \\begin{pmatrix} \\frac{11}{2}  \\frac{3}{2} \\\\ \\frac{3}{2}  \\frac{13}{4} \\end{pmatrix}$\n\n首先，我们计算 $\\boldsymbol{\\Sigma}_{CC}$ 的逆矩阵：\n$\\det(\\boldsymbol{\\Sigma}_{CC}) = (\\frac{11}{2})(\\frac{13}{4}) - (\\frac{3}{2})^2 = \\frac{143}{8} - \\frac{9}{4} = \\frac{143 - 18}{8} = \\frac{125}{8}$\n$\\boldsymbol{\\Sigma}_{CC}^{-1} = \\frac{8}{125} \\begin{pmatrix} \\frac{13}{4}  -\\frac{3}{2} \\\\ -\\frac{3}{2}  \\frac{11}{2} \\end{pmatrix} = \\frac{1}{125} \\begin{pmatrix} 26  -12 \\\\ -12  44 \\end{pmatrix}$\n\n现在，我们求最优系数 $\\boldsymbol{a}^{\\star} = (a_1^{\\star}, a_3^{\\star})^T$：\n$\\boldsymbol{a}^{\\star} = \\boldsymbol{\\Sigma}_{CC}^{-1} \\boldsymbol{\\sigma}_{XC} = \\frac{1}{125} \\begin{pmatrix} 26  -12 \\\\ -12  44 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 7/2 \\end{pmatrix} = \\frac{1}{125} \\begin{pmatrix} 26 \\cdot 8 - 12 \\cdot \\frac{7}{2} \\\\ -12 \\cdot 8 + 44 \\cdot \\frac{7}{2} \\end{pmatrix} = \\frac{1}{125} \\begin{pmatrix} 208 - 42 \\\\ -96 + 154 \\end{pmatrix} = \\frac{1}{125} \\begin{pmatrix} 166 \\\\ 58 \\end{pmatrix}$\n所以，$a_1^{\\star} = \\frac{166}{125}$ 且 $a_3^{\\star} = \\frac{58}{125}$。\n\n最小方差是：\n$\\mathrm{Var}(Y(\\boldsymbol{a}^{\\star})) = \\mathrm{Var}(X) - \\boldsymbol{\\sigma}_{XC}^T \\boldsymbol{a}^{\\star} = 14 - \\begin{pmatrix} 8  \\frac{7}{2} \\end{pmatrix} \\begin{pmatrix} 166/125 \\\\ 58/125 \\end{pmatrix}$\n$\\mathrm{Var}(Y(\\boldsymbol{a}^{\\star})) = 14 - \\frac{8 \\cdot 166 + \\frac{7}{2} \\cdot 58}{125} = 14 - \\frac{1328 + 7 \\cdot 29}{125} = 14 - \\frac{1328 + 203}{125} = 14 - \\frac{1531}{125}$\n$\\mathrm{Var}(Y(\\boldsymbol{a}^{\\star})) = \\frac{14 \\cdot 125 - 1531}{125} = \\frac{1750 - 1531}{125} = \\frac{219}{125}$\n\n**5. 子集比较**\n\n我们必须确定哪个子集，$S=\\{1,2\\}$ 还是 $S=\\{1,3\\}$，能得到更小的最小方差。\n- 对于 $S=\\{1,2\\}$，最小方差为 $\\frac{278}{199}$。\n- 对于 $S=\\{1,3\\}$，最小方差为 $\\frac{219}{125}$。\n\n为了比较这两个分数，我们可以通分或将它们转换为小数。\n$\\frac{278}{199} \\approx 1.39698$\n$\\frac{219}{125} = \\frac{219 \\times 8}{125 \\times 8} = \\frac{1752}{1000} = 1.752$\n\n由于 $1.39698  1.752$，我们有 $\\frac{278}{199}  \\frac{219}{125}$。\n更优的子集是 $S=\\{1,2\\}$，因为它使得控制估计量的方差更低。\n\n问题要求提供更优子集的两个最优系数，以及该最小方差。\n更优的子集是 $S=\\{1,2\\}$，对于该子集：\n- 最优系数为 $a_1^{\\star} = \\frac{256}{199}$ 和 $a_2^{\\star} = \\frac{92}{199}$。\n- 最小方差为 $\\frac{278}{199}$。\n\n最终答案由这三个值组成一个行矩阵。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{256}{199}  \\frac{92}{199}  \\frac{278}{199}\n\\end{pmatrix}\n}\n$$", "id": "3325570"}, {"introduction": "现实世界中的模拟涉及成本。这个练习将选择问题提升为一个资源受限的优化任务，其中每个控制变量都有相关的评估成本。你将学习如何将其构建为一个投资组合选择问题 [@problem_id:3325545]，在给定的预算内找到提供最大方差缩减的最优控制变量子集，这是实际应用中的一项关键技能。", "problem": "给定一个标量随机量 $X$，需要通过蒙特卡洛（MC）采样进行估计，以及一组 $m$ 个控制变量（CV），表示为随机向量 $C = (C_1,\\dots,C_m)^\\top$，其中每个 $C_j$ 都有一个已知的评估成本 $c_j \\in \\mathbb{R}_{0}$。您可以选择一个控制变量的子集 $S \\subseteq \\{1,\\dots,m\\}$ 进行评估，并使用一个系数向量 $\\beta \\in \\mathbb{R}^m$ 来构建调整后的估计量 $X - \\beta^\\top C$。目标是在总评估成本预算 $B \\in \\mathbb{R}_{\\ge 0}$ 的约束下减小方差。对于任何允许的子集 $S$，不在 $S$ 中的索引所对应的系数被约束为零。\n\n假设所有随机变量都是中心化的（零均值）且二阶矩存在。给定方差 $\\mathrm{Var}(X)$、协方差向量 $\\Sigma_{CX} \\in \\mathbb{R}^m$（其元素为 $\\Sigma_{CX,j} = \\mathrm{Cov}(C_j,X)$）以及协方差矩阵 $\\Sigma_{CC} \\in \\mathbb{R}^{m \\times m}$（其元素为 $\\Sigma_{CC,ij} = \\mathrm{Cov}(C_i,C_j)$）。矩阵 $\\Sigma_{CC}$ 是对称半正定的。成本是可加的，即子集 $S$ 的总成本为 $\\sum_{j \\in S} c_j$。\n\n您的任务是：\n- 仅从方差和协方差的核心定义出发，推导对于一个固定的子集 $S$，如何最优地选择系数向量 $\\beta$ 以最小化 $\\mathrm{Var}(X - \\beta^\\top C)$，并满足对于所有 $j \\notin S$，$\\beta_j = 0$ 的约束条件。\n- 将最终的目标值（即子集 $S$ 的最小化方差）推导为与 $S$ 中索引相关的 $\\Sigma_{CX}$ 和 $\\Sigma_{CC}$ 的函数。\n- 证明在成本预算约束 $\\sum_{j \\in S} c_j \\le B$ 下，选择子集是一个关于 $S$ 的组合优化问题，并精确描述其与背包类问题结构的关系。解释当 $\\Sigma_{CC}$ 为对角矩阵（控制变量不相关）时的情况，并将其与相关情况进行对比。\n- 实现一个精确优化器，在给定 $(\\mathrm{Var}(X), \\Sigma_{CX}, \\Sigma_{CC}, c, B)$ 的情况下，计算：\n  1) 在预算约束下使方差最小化的最优子集 $S^\\star$，\n  2) 相应的最小化方差值。\n  如果 $\\Sigma_{CC}$ 的相关子矩阵是奇异的，则使用 Moore–Penrose 伪逆来评估最小化方差，同时确保您的实现中不会出现任何不稳定性。\n\n决胜要求：如果多个子集 $S$ 达到了相同的最小化方差（在绝对容差 $10^{-12}$ 内），则在这些最优子集中返回字典序最小的索引集（索引从 1 开始，并按升序列出）。\n\n数值输出规范：\n- 对于每个测试用例，输出一个数对 $[S^\\star, v^\\star]$，其中 $S^\\star$ 是所选控制变量的索引列表（从 1 开始，严格递增），而 $v^\\star$ 是四舍五入到六位小数的最小化方差实数值。\n- 按照下面给出的顺序，将所有测试用例的输出聚合到一个外部列表中。\n- 您的程序应生成单行输出，其中包含此外部列表，不含任何空格，条目之间用逗号分隔，并使用方括号。例如，一个有效的输出格式是 $[[[1,2],0.123456],[[],2.000000]]$。\n\n不涉及角度。不涉及物理单位。\n\n测试套件：\n对于以下每个案例，数据都是无量纲且内部一致的。每个测试用例由 $(\\mathrm{Var}(X), \\Sigma_{CX}, \\Sigma_{CC}, c, B)$ 组成。\n\n- 测试 1（一般相关情况；预算恰好满足一个非平凡的组合）：\n  - $\\mathrm{Var}(X) = 1.2$\n  - $\\Sigma_{CX} = [0.4,\\,0.3,\\,0.2]^\\top$\n  - $\\Sigma_{CC} = \\begin{bmatrix}1.0  0.2  0.1\\\\ 0.2  1.0  0.3\\\\ 0.1  0.3  1.0\\end{bmatrix}$\n  - $c = [2,\\,1,\\,3]^\\top$, $B = 3$\n\n- 测试 2（预算为零的边界情况）：\n  - $\\mathrm{Var}(X) = 2.0$\n  - $\\Sigma_{CX} = [0.6,\\,0.4]^\\top$\n  - $\\Sigma_{CC} = \\begin{bmatrix}1.0  0.5\\\\ 0.5  1.0\\end{bmatrix}$\n  - $c = [1,\\,1]^\\top$, $B = 0$\n\n- 测试 3（在独立控制变量的背包类结构下，需要进行字典序选择的平局情况）：\n  - $\\mathrm{Var}(X) = 1.0$\n  - $\\Sigma_{CX} = [0.5,\\,0.5]^\\top$\n  - $\\Sigma_{CC} = \\begin{bmatrix}1.0  0.0\\\\ 0.0  1.0\\end{bmatrix}$\n  - $c = [1,\\,1]^\\top$, $B = 1$\n\n- 测试 4（四个控制变量；相关性使得某些组合严格更优）：\n  - $\\mathrm{Var}(X) = 1.3$\n  - $\\Sigma_{CX} = [0.45,\\,0.35,\\,0.25,\\,0.15]^\\top$\n  - $\\Sigma_{CC} = \\begin{bmatrix}\n  1.0  0.3  0.2  0.1\\\\\n  0.3  1.0  0.25  0.15\\\\\n  0.2  0.25  1.0  0.35\\\\\n  0.1  0.15  0.35  1.0\n  \\end{bmatrix}$\n  - $c = [2,\\,2,\\,1,\\,1]^\\top$, $B = 4$\n\n- 测试 5（高度相关的控制变量；方差减少量的非可加性）：\n  - $\\mathrm{Var}(X) = 1.0$\n  - $\\Sigma_{CX} = [0.5,\\,0.5]^\\top$\n  - $\\Sigma_{CC} = \\begin{bmatrix}1.0  0.9\\\\ 0.9  1.0\\end{bmatrix}$\n  - $c = [1,\\,1]^\\top$, $B = 2$\n\n您的程序必须为每个测试用例计算 $[S^\\star, v^\\star]$，并按照上述规定打印一行包含所有五个结果的外部列表，不含空格。结果的顺序必须与测试套件案例的顺序相同。将每个 $v^\\star$ 四舍五入到六位小数。", "solution": "该问题是有效的，因为它在科学上基于概率论和统计学，特别是蒙特卡洛方法中的方差缩减理论。该问题是适定的，具有明确的目标函数、定义良好的约束条件，并且决胜规则保证了唯一解的存在。其语言客观，设定完整且一致。\n\n任务是找到一个最优的控制变量子集 $S^\\star \\subseteq \\{1, \\dots, m\\}$ 和相应的系数 $\\beta^\\star$，以最小化估计量 $X_c = X - \\beta^\\top C$ 的方差，同时满足所选控制变量总评估成本的预算约束 $B$。对于不在所选子集 $S$ 中的任何控制变量 $j$，其系数 $\\beta_j$ 都被约束为零。\n\n首先，对于一个固定的非空控制变量子集 $S$，我们推导最优系数 $\\beta_S^\\star$。所有系数的向量是 $\\beta$，但我们只需要确定与 $S$ 中索引对应的非零元素，我们用子向量 $\\beta_S$ 表示。估计量为 $X_c = X - \\beta_S^\\top C_S$，其中 $C_S$ 是索引在 $S$ 中的控制变量子向量。此估计量的方差由下式给出：\n$$V_S(\\beta_S) = \\mathrm{Var}(X - \\beta_S^\\top C_S)$$\n利用协方差算子的双线性，并考虑到所有随机变量都是中心化的（零均值），我们可以展开此表达式：\n$$V_S(\\beta_S) = \\mathrm{Cov}(X - \\beta_S^\\top C_S, X - \\beta_S^\\top C_S)$$\n$$V_S(\\beta_S) = \\mathrm{Var}(X) - 2 \\mathrm{Cov}(X, \\beta_S^\\top C_S) + \\mathrm{Var}(\\beta_S^\\top C_S)$$\n涉及向量的协方差和方差项可以用给定的协方差矩阵来表示。设 $\\Sigma_{C_S X}$ 为 $\\Sigma_{CX}$ 中对应于 $S$ 中索引的子向量，$\\Sigma_{C_S C_S}$ 为 $\\Sigma_{CC}$ 中对应于 $S$ 中索引的主子矩阵。\n$$\\mathrm{Cov}(X, \\beta_S^\\top C_S) = \\mathbb{E}[X (C_S^\\top \\beta_S)] = \\mathbb{E}[X C_S^\\top] \\beta_S = \\Sigma_{X C_S} \\beta_S = \\Sigma_{C_S X}^\\top \\beta_S$$\n$$\\mathrm{Var}(\\beta_S^\\top C_S) = \\mathbb{E}[(\\beta_S^\\top C_S)(\\beta_S^\\top C_S)^\\top] = \\mathbb{E}[\\beta_S^\\top C_S C_S^\\top \\beta_S] = \\beta_S^\\top \\mathbb{E}[C_S C_S^\\top] \\beta_S = \\beta_S^\\top \\Sigma_{C_S C_S} \\beta_S$$\n将这些代入方差表达式，我们得到一个关于 $\\beta_S$ 的二次函数：\n$$V_S(\\beta_S) = \\mathrm{Var}(X) - 2 \\Sigma_{C_S X}^\\top \\beta_S + \\beta_S^\\top \\Sigma_{C_S C_S} \\beta_S$$\n为求最小值，我们计算关于 $\\beta_S$ 的梯度并令其为零。\n$$\\nabla_{\\beta_S} V_S(\\beta_S) = -2 \\Sigma_{C_S X} + 2 \\Sigma_{C_S C_S} \\beta_S$$\n将梯度设为零，得到最优系数 $\\beta_S^\\star$ 的正规方程：\n$$\\Sigma_{C_S C_S} \\beta_S^\\star = \\Sigma_{C_S X}$$\n矩阵 $\\Sigma_{C_S C_S}$ 是对称半正定的。如果它是奇异的，$\\beta_S^\\star$ 的唯一解可能不存在。然而，问题指定使用 Moore-Penrose 伪逆（用上标 $+$ 表示），它提供了最小范数解。因此，最优系数向量为：\n$$\\beta_S^\\star = \\Sigma_{C_S C_S}^{+} \\Sigma_{C_S X}$$\n\n接下来，我们通过将 $\\beta_S^\\star$ 代入方差表达式来推导最终的最小化方差 $V_S^\\star = V_S(\\beta_S^\\star)$：\n$$V_S^\\star = \\mathrm{Var}(X) - 2 \\Sigma_{C_S X}^\\top \\beta_S^\\star + (\\beta_S^\\star)^\\top \\Sigma_{C_S C_S} \\beta_S^\\star$$\n从正规方程出发，我们可以从左侧乘以 $(\\beta_S^\\star)^\\top$ 得到 $(\\beta_S^\\star)^\\top \\Sigma_{C_S C_S} \\beta_S^\\star = (\\beta_S^\\star)^\\top \\Sigma_{C_S X}$。将此代入方差表达式可简化其中一项：\n$$V_S^\\star = \\mathrm{Var}(X) - 2 \\Sigma_{C_S X}^\\top \\beta_S^\\star + \\Sigma_{C_S X}^\\top \\beta_S^\\star = \\mathrm{Var}(X) - \\Sigma_{C_S X}^\\top \\beta_S^\\star$$\n最后，代入 $\\beta_S^\\star$ 的表达式：\n$$V_S^\\star = \\mathrm{Var}(X) - \\Sigma_{C_S X}^\\top \\Sigma_{C_S C_S}^{+} \\Sigma_{C_S X}$$\n项 $R(S) = \\Sigma_{C_S X}^\\top \\Sigma_{C_S C_S}^{+} \\Sigma_{C_S X}$ 代表使用子集 $S$ 中的控制变量所实现的总方差缩减量。对于空集 $S = \\emptyset$，缩减量为 $R(\\emptyset)=0$，方差就是 $\\mathrm{Var}(X)$。\n\n整个问题是在总成本约束 $\\sum_{j \\in S} c_j \\le B$ 下，选择能最小化 $V_S^\\star$ 的子集 $S$。这等价于最大化方差缩减量 $R(S)$：\n$$\\max_{S \\subseteq \\{1,\\dots,m\\}} R(S) \\quad \\text{subject to} \\quad \\sum_{j \\in S} c_j \\le B$$\n这是一个组合优化问题。每个控制变量 $j$ 可被视为一个成本为 $c_j$ 的“物品”。目标是选择一个“背包”的物品（即子集 $S$），在不超过预算 $B$ 的情况下最大化一个“价值”函数 $R(S)$。\n\n这个问题的结构取决于协方差矩阵 $\\Sigma_{CC}$ 的性质。\n如果 $\\Sigma_{CC}$ 是对角矩阵，则控制变量不相关。对于任何 $S$，子矩阵 $\\Sigma_{C_S C_S}$ 也是对角的，其对角元素为 $j \\in S$ 时的 $\\mathrm{Var}(C_j)$。其逆矩阵（假设所有 $\\mathrm{Var}(C_j)  0$）也是对角的，元素为 $1/\\mathrm{Var}(C_j)$。方差缩减量 $R(S)$ 变为可加的：\n$$R(S) = \\sum_{j \\in S} \\frac{\\mathrm{Cov}(C_j, X)^2}{\\mathrm{Var}(C_j)}$$\n在这种情况下，问题变成一个经典的 0-1 背包问题，其中物品 $j$ 的价值是 $v_j = \\mathrm{Cov}(C_j, X)^2 / \\mathrm{Var}(C_j)$，其重量是 $c_j$。\n\n在一般情况下，当 $\\Sigma_{CC}$ 不是对角矩阵时，控制变量是相关的。价值函数 $R(S)$ 不再是可加的。增加一个新的控制变量所带来的方差缩减量取决于集合 $S$ 中已有哪些控制变量。这是一个非线性或广义背包问题。尽管更复杂，但对于少量控制变量 $m$，可以通过枚举所有 $2^m$ 个可能的子集 $S$，检查每个子集是否满足预算 $B$，计算其对应的方差 $V_S^\\star$，并选择产生最小方差的子集来精确求解。\n\n寻找最优子集 $S^\\star$ 及其最小化方差 $v^\\star$ 的算法如下：\n1. 将最小方差 $v_{min}$ 初始化为一个非常大的数（或 $\\mathrm{Var}(X)$），并初始化一个最优子集列表 `optimal_subsets`。\n2. 遍历 $\\{1, \\dots, m\\}$ 的所有 $2^m$ 个子集。\n3. 对于每个子集 $S$：\n    a. 计算其总成本 $\\text{cost}_S = \\sum_{j \\in S} c_j$。\n    b. 如果 $\\text{cost}_S  B$，则该子集不可行，舍弃。\n    c. 否则，计算最小化方差 $V_S^\\star = \\mathrm{Var}(X) - R(S)$。如果 $S$ 为空，则 $V_\\emptyset^\\star = \\mathrm{Var}(X)$。\n    d. 将 $V_S^\\star$ 与 $v_{min}$ 进行比较。\n        i. 如果 $V_S^\\star  v_{min} - \\epsilon$ （其中 $\\epsilon=10^{-12}$ 是一个很小的容差），则找到了一个新的最优子集。更新 $v_{min} = V_S^\\star$ 并将 `optimal_subsets` 重置为 `[S]`。\n        ii. 如果 $|V_S^\\star - v_{min}| \\le \\epsilon$，则出现平局。将 $S$ 添加到 `optimal_subsets` 中。\n4. 检查完所有子集后，最优子集 $S^\\star$ 是 `optimal_subsets` 中字典序最小的列表。最优方差为 $v^\\star = v_{min}$。\n这种暴力枚举方法保证能找到精确的全局最优解，并遵守决胜规则。", "answer": "```python\nimport numpy as np\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to solve all test cases for optimal control variate selection.\n    \"\"\"\n    \n    # Test 1\n    test1 = {\n        \"var_x\": 1.2,\n        \"sigma_cx\": np.array([0.4, 0.3, 0.2]),\n        \"sigma_cc\": np.array([[1.0, 0.2, 0.1], [0.2, 1.0, 0.3], [0.1, 0.3, 1.0]]),\n        \"costs\": np.array([2.0, 1.0, 3.0]),\n        \"budget\": 3.0\n    }\n    \n    # Test 2\n    test2 = {\n        \"var_x\": 2.0,\n        \"sigma_cx\": np.array([0.6, 0.4]),\n        \"sigma_cc\": np.array([[1.0, 0.5], [0.5, 1.0]]),\n        \"costs\": np.array([1.0, 1.0]),\n        \"budget\": 0.0\n    }\n\n    # Test 3\n    test3 = {\n        \"var_x\": 1.0,\n        \"sigma_cx\": np.array([0.5, 0.5]),\n        \"sigma_cc\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n        \"costs\": np.array([1.0, 1.0]),\n        \"budget\": 1.0\n    }\n    \n    # Test 4\n    test4 = {\n        \"var_x\": 1.3,\n        \"sigma_cx\": np.array([0.45, 0.35, 0.25, 0.15]),\n        \"sigma_cc\": np.array([\n            [1.0, 0.3, 0.2, 0.1],\n            [0.3, 1.0, 0.25, 0.15],\n            [0.2, 0.25, 1.0, 0.35],\n            [0.1, 0.15, 0.35, 1.0]\n        ]),\n        \"costs\": np.array([2.0, 2.0, 1.0, 1.0]),\n        \"budget\": 4.0\n    }\n    \n    # Test 5\n    test5 = {\n        \"var_x\": 1.0,\n        \"sigma_cx\": np.array([0.5, 0.5]),\n        \"sigma_cc\": np.array([[1.0, 0.9], [0.9, 1.0]]),\n        \"costs\": np.array([1.0, 1.0]),\n        \"budget\": 2.0\n    }\n    \n    test_cases = [test1, test2, test3, test4, test5]\n    results = []\n\n    for case in test_cases:\n        s_star, v_star = _solve_one_case(**case)\n        results.append((s_star, v_star))\n\n    # Format the final output string according to the specification.\n    # e.g., [[[1,2],0.123456],[[],2.000000]]\n    formatted_results = []\n    for s, v in results:\n        s_str = f\"[{','.join(map(str, s))}]\"\n        v_str = f\"{v:.6f}\"\n        formatted_results.append(f\"[{s_str},{v_str}]\")\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\ndef _solve_one_case(var_x, sigma_cx, sigma_cc, costs, budget):\n    \"\"\"\n    Solves a single optimal control variate selection problem.\n    \"\"\"\n    m = len(costs)\n    indices = range(m)\n    \n    min_variance = float('inf')\n    optimal_subsets = []\n    tie_tol = 1e-12\n\n    for k in range(m + 1):\n        for s_indices_0based in combinations(indices, k):\n            subset_cost = np.sum(costs[list(s_indices_0based)])\n            \n            if subset_cost > budget:\n                continue\n\n            current_variance = var_x\n            if s_indices_0based: # If subset is not empty\n                # Convert tuple of indices to a list for slicing\n                idx_list = list(s_indices_0based)\n                \n                # Extract sub-vectors and sub-matrices\n                sigma_cs_x = sigma_cx[idx_list]\n                # Use np.ix_ for creating submatrices from index lists\n                sigma_cs_cs = sigma_cc[np.ix_(idx_list, idx_list)]\n                \n                # Calculate variance reduction using Moore-Penrose pseudoinverse\n                try:\n                    # Invertible case is faster - but pinv handles both\n                    pinv_sigma_cs_cs = np.linalg.pinv(sigma_cs_cs)\n                    variance_reduction = sigma_cs_x.T @ pinv_sigma_cs_cs @ sigma_cs_x\n                    current_variance -= variance_reduction\n                except np.linalg.LinAlgError:\n                    # This should not happen with pinv, but as a failsafe\n                    continue\n            \n            # Update minimum variance and list of optimal subsets\n            if abs(current_variance - min_variance)  tie_tol:\n                # Tie in variance, add subset to list\n                optimal_subsets.append(list(s_indices_0based))\n            elif current_variance  min_variance:\n                # Found a new minimum variance\n                min_variance = current_variance\n                optimal_subsets = [list(s_indices_0based)]\n    \n    # Apply tie-breaking rule: choose the lexicographically smallest subset\n    # An empty list is lexicographically smaller than any non-empty list.\n    # Python's `min` for lists of lists performs lexicographical comparison.\n    best_subset_0based = min(optimal_subsets)\n    \n    # Convert to 1-based indexing for the final output\n    best_subset_1based = [i + 1 for i in best_subset_0based]\n    \n    return best_subset_1based, min_variance\n\n# Run the solver\nsolve()\n```", "id": "3325545"}, {"introduction": "控制变量的经典理论依赖于有限二阶矩的存在，如果控制变量表现出重尾行为，这个假设在实践中可能不成立。这个练习 [@problem_id:3325576] 通过探索如截断（truncation）和缩尾（Winsorization）等实用的数据处理技术来解决这个关键问题。你将分析这些方法如何恢复理论的适用性，并确保你的估计量具有渐近正态性。", "problem": "考虑来自均值为零、尺度参数为 $b0$ 的拉普拉斯分布的独立同分布样本 $\\{X_i\\}_{i=1}^n$，因此 $X\\sim\\mathrm{Laplace}(0,b)$ 且 $\\mathrm{Var}(X)=2b^2$。目标是使用带有控制变量的蒙特卡洛方法来估计期望 $\\mu=\\mathbb{E}[X]$。您有两个候选控制变量 $C^{(1)}$ 和 $C^{(2)}$，它们由以下模型构建：对于 $j\\in\\{1,2\\}$，\n$$\nC^{(j)} \\equiv \\lambda_j X + U^{(j)},\n$$\n其中 $U^{(j)}$ 与 $X$ 独立，并且服从尺度为 $x_m0$、形状为 $\\alpha_j0$ 的帕累托分布，记为 $U^{(j)}\\sim\\mathrm{Pareto}(x_m,\\alpha_j)$。帕累托密度为 $f(u)=\\alpha x_m^\\alpha u^{-(\\alpha+1)}$，其中 $u\\ge x_m$。参数 $\\lambda_j$ 通过线性项 $\\lambda_j X$ 捕捉与 $X$ 的相关性，而加法项 $U^{(j)}$ 则在控制变量中引入重尾行为。\n\n对于单个控制变量 $C$ 和系数 $\\beta\\in\\mathbb{R}$，$\\mu$ 的标准控制变量估计量为\n$$\n\\hat{\\mu}_n(\\beta) \\equiv \\frac{1}{n}\\sum_{i=1}^n \\left( X_i - \\beta\\left(C_i - \\mathbb{E}[C]\\right)\\right).\n$$\n假设您只使用这样的控制变量变换：将 $U^{(j)}$ 替换为一个处理后的版本，其期望可从分布信息中精确计算，同时保持相关的线性分量 $\\lambda_j X$ 不变。具体来说，考虑对 $U^{(j)}$ 应用以下策略：\n\n- 在阈值 $\\tau x_m$ 处的单侧缩尾处理 (winsorization)：$W_\\tau(U^{(j)}) \\equiv \\min\\{U^{(j)},\\tau\\}$。\n\n- 在阈值 $\\tau x_m$ 处的单侧截断 (truncation)：$T_\\tau(U^{(j)}) \\equiv U^{(j)}\\mathbf{1}\\{U^{(j)}\\le \\tau\\}$。\n\n处理后的控制变量则定义为 $C^{(j)}_{\\mathrm{win}} \\equiv \\lambda_j X + W_\\tau(U^{(j)})$ 和 $C^{(j)}_{\\mathrm{trunc}} \\equiv \\lambda_j X + T_\\tau(U^{(j)})$。您也可以考虑未经处理的原始控制变量 $C^{(j)}$，但其二阶矩可能因 $\\alpha_j$ 的值而为无穷大。\n\n仅从方差、协方差、独立性的基本定义以及针对具有有限方差的独立同分布和的经典中心极限定理 (CLT) 出发，执行以下操作：\n\n1. 推导控制变量估计量 $\\hat{\\mu}_n(\\beta)$ 的方差关于 $\\beta$ 的函数表达式，然后在模型 $C=\\lambda X + V$（其中 $V$ 与 $X$ 独立）下，推导使该方差最小化的 $\\beta$ 值。用 $\\mathrm{Var}(X)$、$\\lambda$ 和 $\\mathrm{Var}(V)$ 表示最小渐近方差。\n\n2. 对于 $U\\sim \\mathrm{Pareto}(x_m,\\alpha)$ 和阈值 $\\tau x_m$，推导单侧缩尾变量 $W_\\tau(U)$ 和单侧截断变量 $T_\\tau(U)$ 的一阶矩和二阶矩的闭式表达式。您的推导必须正确处理 $\\alpha=1$ 和 $\\alpha=2$ 的特殊情况。使用帕累托密度的积分来表达您的公式，并将它们计算为 $x_m$、$\\alpha$ 和 $\\tau$ 的显式函数。\n\n3. 使用第1部分和第2部分的结果，计算方差缩减因子 (VRF)，其定义为\n$$\n\\mathrm{VRF} \\equiv \\frac{\\mathrm{Var}(X)}{\\mathrm{Var}\\left(X - \\beta^\\star\\left(C - \\mathbb{E}[C]\\right)\\right)},\n$$\n针对每个候选控制变量 $j\\in\\{1,2\\}$ 在每种策略（原始、缩尾和截断）下进行计算。此处 $\\beta^\\star$ 表示在第1部分中找到的、与相应处理后控制变量匹配的方差最小化系数。\n\n4. 通过确定经典中心极限定理是否适用于每种策略下的 $\\hat{\\mu}_n(\\beta^\\star)$，来量化对渐近正态性的影响，判断的唯一依据是所涉及项的二阶矩是否有限。明确说明原始控制变量具有有限方差时 $\\alpha$ 需满足的条件。解释为什么处理后的策略对于任何 $\\alpha0$ 都能得到有限的二阶矩。\n\n5. 在所有策略和候选项中，选择能实现最大方差缩减因子的那一个。如果没有任何策略能产生有限方差的估计量，则选择无控制变量选项。\n\n您的程序必须为以下参数值测试套件计算这些量，并按指定格式生成单行输出。在所有情况下，拉普拉斯尺度为 $b$，样本大小为 $n$，帕累托尺度为 $x_m$，形状参数为 $\\alpha_1$ 和 $\\alpha_2$，相关系数为 $\\lambda_1$ 和 $\\lambda_2$，处理阈值为 $\\tau$。\n\n测试套件：\n- 案例1：$b=1$, $n=50000$, $x_m=1$, $\\alpha_1=1.5$, $\\alpha_2=3.0$, $\\lambda_1=0.8$, $\\lambda_2=0.2$, $\\tau=10$。\n- 案例2：$b=0.5$, $n=100000$, $x_m=1$, $\\alpha_1=2.0$, $\\alpha_2=2.5$, $\\lambda_1=0.3$, $\\lambda_2=0.9$, $\\tau=20$。\n- 案例3：$b=2$, $n=20000$, $x_m=1$, $\\alpha_1=0.8$, $\\alpha_2=1.2$, $\\lambda_1=0.7$, $\\lambda_2=0.7$, $\\tau=5$。\n\n最终输出格式：\n- 对于每个案例，您的程序应输出一个列表 $[s,v,c_r,c_s]$，其中 $s$ 是所选策略的整数代码，$v$ 是作为浮点数的方差缩减因子，$c_r$ 是一个编码为 $0$ 或 $1$ 的布尔值，表示候选项中是否有任何原始控制变量能产生渐近正态性，$c_s$ 是一个编码为 $0$ 或 $1$ 的布尔值，表示所选策略是否能产生渐近正态性。\n- 使用以下策略代码：$0$ 表示无控制变量，$1$ 表示原始候选项1，$2$ 表示缩尾候选项1，$3$ 表示截断候选项1，$4$ 表示原始候选项2，$5$ 表示缩尾候选项2，$6$ 表示截断候选项2。\n- 您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表，每个案例的列表也用方括号括起来。例如： \"[[s1,v1,c_r1,c_s1],[s2,v2,c_r2,c_s2],[s3,v3,c_r3,c_s3]]\"。不涉及物理单位；所有量均为无量纲的实数或布尔值。", "solution": "该问题要求系统性地评估几种用于估计拉普拉斯分布均值的控制变量策略。这涉及推导最优控制变量系数、由此产生的方差缩减、处理后的帕累托随机变量的矩，以及评估中心极限定理对每种策略的适用性。\n\n### 第1步：最优控制变量和最小方差的推导\n\n设 $X$ 为我们感兴趣的随机变量，其均值为 $\\mu = \\mathbb{E}[X]$，并设 $C$ 为一个具有已知期望 $\\mathbb{E}[C]$ 的控制变量。基于 $n$ 个样本的 $\\mu$ 的控制变量估计量为\n$$\n\\hat{\\mu}_n(\\beta) = \\frac{1}{n}\\sum_{i=1}^n Y_i, \\quad \\text{其中} \\quad Y_i = X_i - \\beta(C_i - \\mathbb{E}[C]).\n$$\n由于样本 $\\{X_i, C_i\\}$ 是独立同分布的，该估计量的方差为\n$$\n\\mathrm{Var}(\\hat{\\mu}_n(\\beta)) = \\frac{1}{n} \\mathrm{Var}(Y_1) = \\frac{1}{n}\\mathrm{Var}(X - \\beta(C - \\mathbb{E}[C])).\n$$\n项 $\\mathbb{E}[C]$ 是一个常数，因此不影响方差。我们寻求最小化\n$$\n\\mathrm{Var}(X - \\beta C) = \\mathrm{Var}(X) + \\mathrm{Var}(\\beta C) - 2\\mathrm{Cov}(X, \\beta C) = \\mathrm{Var}(X) + \\beta^2 \\mathrm{Var}(C) - 2\\beta \\mathrm{Cov}(X, C).\n$$\n这是 $\\beta$ 的一个二次函数。假设 $\\mathrm{Var}(C)$ 是有限且非零的，通过将关于 $\\beta$ 的导数设为零来找到最小值：\n$$\n\\frac{d}{d\\beta} \\left( \\mathrm{Var}(X) + \\beta^2 \\mathrm{Var}(C) - 2\\beta \\mathrm{Cov}(X, C) \\right) = 2\\beta \\mathrm{Var}(C) - 2\\mathrm{Cov}(X, C) = 0.\n$$\n这得出了最优系数 $\\beta^\\star$：\n$$\n\\beta^\\star = \\frac{\\mathrm{Cov}(X, C)}{\\mathrm{Var}(C)}.\n$$\n将 $\\beta^\\star$ 代回方差表达式，得到加数项的最小方差：\n$$\n\\mathrm{Var}(X - \\beta^\\star C) = \\mathrm{Var}(X) + \\left(\\frac{\\mathrm{Cov}(X, C)}{\\mathrm{Var}(C)}\\right)^2 \\mathrm{Var}(C) - 2\\frac{\\mathrm{Cov}(X, C)}{\\mathrm{Var}(C)}\\mathrm{Cov}(X, C) = \\mathrm{Var}(X) - \\frac{\\mathrm{Cov}(X, C)^2}{\\mathrm{Var}(C)}.\n$$\n这可以用相关系数 $\\rho_{XC} = \\mathrm{Cov}(X, C) / \\sqrt{\\mathrm{Var}(X)\\mathrm{Var}(C)}$ 表示为 $\\mathrm{Var}(X)(1 - \\rho_{XC}^2)$。\n\n问题指定了控制变量模型 $C = \\lambda X + V$，其中 $X$ 和 $V$ 是独立的。对于此模型：\n$$\n\\mathrm{Cov}(X, C) = \\mathrm{Cov}(X, \\lambda X + V) = \\lambda \\mathrm{Cov}(X, X) + \\mathrm{Cov}(X, V) = \\lambda \\mathrm{Var}(X) \\quad (\\text{因为 } X, V \\text{ 是独立的}).\n$$\n$$\n\\mathrm{Var}(C) = \\mathrm{Var}(\\lambda X + V) = \\lambda^2 \\mathrm{Var}(X) + \\mathrm{Var}(V) \\quad (\\text{因为 } X, V \\text{ 是独立的}).\n$$\n因此，项 $Y_i$ 的最小方差为：\n$$\n\\mathrm{Var}(Y_i) = \\mathrm{Var}(X) - \\frac{(\\lambda \\mathrm{Var}(X))^2}{\\lambda^2 \\mathrm{Var}(X) + \\mathrm{Var}(V)} = \\mathrm{Var}(X) \\left( 1 - \\frac{\\lambda^2 \\mathrm{Var}(X)}{\\lambda^2 \\mathrm{Var}(X) + \\mathrm{Var}(V)} \\right) = \\mathrm{Var}(X) \\frac{\\mathrm{Var}(V)}{\\lambda^2 \\mathrm{Var}(X) + \\mathrm{Var}(V)}.\n$$\n这是估计量的最小渐近方差，已按 $n$ 进行了缩放。\n\n### 第2步：处理后的帕累托变量的矩\n\n设 $U \\sim \\mathrm{Pareto}(x_m, \\alpha)$，其概率密度函数为 $f_U(u) = \\alpha x_m^\\alpha u^{-(\\alpha+1)}$，其中 $u \\ge x_m$。我们推导在阈值 $\\tau  x_m$ 下，缩尾变量 $W_\\tau(U) = \\min(U, \\tau)$ 和截断变量 $T_\\tau(U) = U \\cdot \\mathbf{1}\\{U \\le \\tau\\}$ 的一阶矩和二阶矩。\n\n一个处理后的变量 $g(U)$ 的 $k$ 阶矩是 $\\mathbb{E}[g(U)^k] = \\int_{x_m}^\\infty g(u)^k f_U(u) du$。\n\n**缩尾变量 $W_\\tau(U)$：**\n一阶矩为：\n$$\n\\mathbb{E}[W_\\tau(U)] = \\int_{x_m}^{\\tau} u (\\alpha x_m^\\alpha u^{-\\alpha-1}) du + \\int_{\\tau}^{\\infty} \\tau (\\alpha x_m^\\alpha u^{-\\alpha-1}) du\n$$\n第二个积分为 $\\tau \\alpha x_m^\\alpha \\int_{\\tau}^{\\infty} u^{-\\alpha-1} du = \\tau \\alpha x_m^\\alpha [-\\frac{1}{\\alpha} u^{-\\alpha}]_{\\tau}^{\\infty} = \\tau \\alpha x_m^\\alpha (0 - (-\\frac{1}{\\alpha}\\tau^{-\\alpha})) = x_m^\\alpha \\tau^{1-\\alpha}$。\n对于第一个积分，我们考虑 $\\int u^{-\\alpha} du$ 的两种情况：\n- 如果 $\\alpha \\neq 1$：$\\alpha x_m^\\alpha \\int_{x_m}^{\\tau} u^{-\\alpha} du = \\alpha x_m^\\alpha [\\frac{u^{1-\\alpha}}{1-\\alpha}]_{x_m}^{\\tau} = \\frac{\\alpha x_m^\\alpha}{1-\\alpha}(\\tau^{1-\\alpha} - x_m^{1-\\alpha})$。\n  合并得到 $\\mathbb{E}[W_\\tau(U)] = \\frac{\\alpha x_m^\\alpha}{1-\\alpha}(\\tau^{1-\\alpha} - x_m^{1-\\alpha}) + x_m^\\alpha \\tau^{1-\\alpha} = \\frac{x_m^\\alpha\\tau^{1-\\alpha}}{1-\\alpha} - \\frac{\\alpha x_m}{1-\\alpha}$。\n- 如果 $\\alpha = 1$：$x_m \\int_{x_m}^{\\tau} u^{-1} du = x_m [\\ln u]_{x_m}^{\\tau} = x_m \\ln(\\tau/x_m)$。\n  合并得到 $\\mathbb{E}[W_\\tau(U)] = x_m \\ln(\\tau/x_m) + x_m$。\n\n二阶矩为：\n$$\n\\mathbb{E}[W_\\tau(U)^2] = \\int_{x_m}^{\\tau} u^2 (\\alpha x_m^\\alpha u^{-\\alpha-1}) du + \\int_{\\tau}^{\\infty} \\tau^2 (\\alpha x_m^\\alpha u^{-\\alpha-1}) du\n$$\n第二个积分为 $\\tau^2 \\alpha x_m^\\alpha \\int_{\\tau}^{\\infty} u^{-\\alpha-1} du = \\tau^2 (x_m^\\alpha \\tau^{-\\alpha}) = x_m^\\alpha \\tau^{2-\\alpha}$。\n对于第一个积分，$\\int u^{1-\\alpha} du$：\n- 如果 $\\alpha \\neq 2$：$\\alpha x_m^\\alpha \\int_{x_m}^{\\tau} u^{1-\\alpha} du = \\alpha x_m^\\alpha [\\frac{u^{2-\\alpha}}{2-\\alpha}]_{x_m}^{\\tau} = \\frac{\\alpha x_m^\\alpha}{2-\\alpha}(\\tau^{2-\\alpha} - x_m^{2-\\alpha})$。\n  合并得到 $\\mathbb{E}[W_\\tau(U)^2] = \\frac{\\alpha x_m^\\alpha}{2-\\alpha}(\\tau^{2-\\alpha} - x_m^{2-\\alpha}) + x_m^\\alpha \\tau^{2-\\alpha} = \\frac{2x_m^\\alpha\\tau^{2-\\alpha}}{2-\\alpha} - \\frac{\\alpha x_m^2}{2-\\alpha}$。\n- 如果 $\\alpha = 2$：$2x_m^2 \\int_{x_m}^{\\tau} u^{-1} du = 2x_m^2[\\ln u]_{x_m}^{\\tau} = 2x_m^2 \\ln(\\tau/x_m)$。\n  合并得到 $\\mathbb{E}[W_\\tau(U)^2] = 2x_m^2 \\ln(\\tau/x_m) + x_m^2$。\n\n**截断变量 $T_\\tau(U)$：**\n由于当 $u\\tau$ 时变量为零，其矩就是缩尾情况下的第一个积分。\n一阶矩：\n- 如果 $\\alpha \\neq 1$：$\\mathbb{E}[T_\\tau(U)] = \\frac{\\alpha x_m^\\alpha}{1-\\alpha}(\\tau^{1-\\alpha} - x_m^{1-\\alpha})$。\n- 如果 $\\alpha = 1$：$\\mathbb{E}[T_\\tau(U)] = x_m \\ln(\\tau/x_m)$。\n二阶矩：\n- 如果 $\\alpha \\neq 2$：$\\mathbb{E}[T_\\tau(U)^2] = \\frac{\\alpha x_m^\\alpha}{2-\\alpha}(\\tau^{2-\\alpha} - x_m^{2-\\alpha})$。\n- 如果 $\\alpha = 2$：$\\mathbb{E}[T_\\tau(U)^2] = 2x_m^2 \\ln(\\tau/x_m)$。\n\n在所有情况下，方差为 $\\mathrm{Var}(V) = \\mathbb{E}[V^2] - (\\mathbb{E}[V])^2$，其中 $V \\in \\{W_\\tau(U), T_\\tau(U)\\}$。\n\n### 第3步：方差缩减因子 (VRF)\n\nVRF 定义为简单蒙特卡洛方差与最优控制方差之比：\n$$\n\\mathrm{VRF} = \\frac{\\mathrm{Var}(X)}{\\mathrm{Var}(X - \\beta^\\star(C - \\mathbb{E}[C]))}.\n$$\n使用第1步中最小方差的表达式：\n$$\n\\mathrm{VRF} = \\frac{\\mathrm{Var}(X)}{\\mathrm{Var}(X) \\frac{\\mathrm{Var}(V)}{\\lambda^2 \\mathrm{Var}(X) + \\mathrm{Var}(V)}} = \\frac{\\lambda^2 \\mathrm{Var}(X) + \\mathrm{Var}(V)}{\\mathrm{Var}(V)} = 1 + \\frac{\\lambda^2 \\mathrm{Var}(X)}{\\mathrm{Var}(V)}.\n$$\n该公式在 $\\mathrm{Var}(V)$ 有限且为正的条件下适用。如果 $\\mathrm{Var}(V)$ 为无穷大，则必须选择 $\\beta^\\star = 0$ 以确保估计量具有有限方差，此时估计量退化为简单蒙特卡洛估计量。在这种情况下，没有方差缩减，因此 $\\mathrm{VRF}=1$。\n我们已知 $\\mathrm{Var}(X) = 2b^2$。对于每种策略，我们计算 $\\mathrm{Var}(V)$，其中 $V$ 是（可能经过处理的）噪声项 $U^{(j)}$。\n\n### 第4步：渐近正态性与中心极限定理 (CLT)\n\n估计量为 $\\hat{\\mu}_n(\\beta^\\star) = \\frac{1}{n} \\sum_{i=1}^n (X_i - \\beta^\\star(C_i - \\mathbb{E}[C]))$。根据经典中心极限定理，如果和中的各项具有有限方差，则 $\\sqrt{n}(\\hat{\\mu}_n(\\beta^\\star) - \\mu)$ 在分布上收敛于正态分布。每一项的方差是 $\\mathrm{Var}(X - \\beta^\\star C)$，我们已求得其值为 $\\mathrm{Var}(X) \\frac{\\mathrm{Var}(V)}{\\lambda^2 \\mathrm{Var}(X) + \\mathrm{Var}(V)}$。\n因为 $\\mathrm{Var}(X) = 2b^2$ 是有限的，所以该方差是有限的当且仅当 $\\mathrm{Var}(V)$ 是有限的。\n因此，中心极限定理的适用性取决于 $\\mathrm{Var}(V)$ 的有限性。\n\n- **原始控制变量：** $V = U^{(j)}$。帕累托($x_m, \\alpha_j$)分布的方差 $\\mathrm{Var}(U^{(j)})$ 是有限的，当且仅当其二阶矩存在，这要求 $\\alpha_j  2$。\n- **缩尾控制变量：** $V = W_\\tau(U^{(j)}) = \\min(U^{(j)}, \\tau)$。该变量有上界 $\\tau$ 和下界 $x_m  0$。任何有界随机变量的所有阶矩都是有限的。因此，对于任何 $\\alpha_j  0$，$\\mathrm{Var}(W_\\tau(U^{(j)}))$ 总是有限的。\n- **截断控制变量：** $V = T_\\tau(U^{(j)}) = U^{(j)} \\mathbf{1}\\{U^{(j)} \\le \\tau\\}$。该变量有界于 $0$ 和 $\\tau$ 之间。因此，对于任何 $\\alpha_j  0$，$\\mathrm{Var}(T_\\tau(U^{(j)}))$ 总是有限的。\n\n总而言之，处理后的策略（缩尾、截断）总能得到一个适用中心极限定理的控制变量估计量。而原始策略仅在帕累托形状参数 $\\alpha2$ 时才能保证这一点。\n\n### 第5步：策略选择\n\n最优策略是使 VRF 最大化的策略。我们为 $2 \\times 3 = 6$ 种可能的策略（两个候选项，三种处理类型）中的每一种计算 VRF。基准是“无控制变量”选项，其 $\\mathrm{VRF}=1$。如果一个策略导致控制部分的方差为无穷大（即 $\\alpha \\le 2$ 的原始控制变量），则其 VRF 被视为 $1$，因为没有实现方差缩减。我们选择所找到的最大 VRF 对应的策略代码。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the control variate selection problem for a given set of test cases.\n    \"\"\"\n    test_cases = [\n        # (b, n, x_m, alpha1, alpha2, lambda1, lambda2, tau)\n        (1.0, 50000, 1.0, 1.5, 3.0, 0.8, 0.2, 10.0),\n        (0.5, 100000, 1.0, 2.0, 2.5, 0.3, 0.9, 20.0),\n        (2.0, 20000, 1.0, 0.8, 1.2, 0.7, 0.7, 5.0),\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        b, _, x_m, alpha1, alpha2, lambda1, lambda2, tau = case\n        var_X = 2 * b**2\n        candidates = [\n            {'alpha': alpha1, 'lambda': lambda1},\n            {'alpha': alpha2, 'lambda': lambda2},\n        ]\n\n        best_vrf = 1.0\n        best_strategy_code = 0\n        clt_for_best_strategy = True  # Default 'no control' has finite variance\n\n        # --- Moment Calculation Functions ---\n        def get_winsorized_moments(alpha, xm, t):\n            if alpha == 1.0:\n                e1 = xm * (np.log(t / xm) + 1.0)\n            else:\n                e1 = (xm**alpha * t**(1.0 - alpha)) / (1.0 - alpha) - (alpha * xm) / (1.0 - alpha)\n            \n            if alpha == 2.0:\n                e2 = 2.0 * xm**2 * np.log(t / xm) + xm**2\n            else:\n                e2 = (2.0 * xm**alpha * t**(2.0 - alpha)) / (2.0 - alpha) - (alpha * xm**2) / (2.0 - alpha)\n            return e1, e2\n\n        def get_truncated_moments(alpha, xm, t):\n            if alpha == 1.0:\n                e1 = xm * np.log(t / xm)\n            else:\n                e1 = (alpha * xm**alpha) / (1.0 - alpha) * (t**(1.0 - alpha) - xm**(1.0 - alpha))\n            \n            if alpha == 2.0:\n                e2 = 2.0 * xm**2 * np.log(t / xm)\n            else:\n                e2 = (alpha * xm**alpha) / (2.0 - alpha) * (t**(2.0 - alpha) - xm**(2.0 - alpha))\n            return e1, e2\n\n        # --- Evaluate Strategies ---\n        for i, cand in enumerate(candidates):\n            alpha, lam = cand['alpha'], cand['lambda']\n            \n            # --- Strategy: Raw ---\n            var_V_raw = np.inf\n            clt_raw = False\n            if alpha > 2.0:\n                var_V_raw = (alpha * x_m**2) / ((alpha - 2.0) * (alpha - 1.0)**2)\n                clt_raw = True\n            \n            vrf_raw = 1.0\n            if np.isfinite(var_V_raw) and var_V_raw > 0:\n                vrf_raw = 1.0 + (lam**2 * var_X) / var_V_raw\n\n            strategy_code_raw = 1 + i * 3\n            if vrf_raw > best_vrf:\n                best_vrf = vrf_raw\n                best_strategy_code = strategy_code_raw\n                clt_for_best_strategy = clt_raw\n                \n            # --- Strategy: Winsorized ---\n            e1_win, e2_win = get_winsorized_moments(alpha, x_m, tau)\n            var_V_win = e2_win - e1_win**2\n            clt_win = True # Always finite variance\n            vrf_win = 1.0\n            if var_V_win > 0:\n              vrf_win = 1.0 + (lam**2 * var_X) / var_V_win\n\n            strategy_code_win = 2 + i * 3\n            if vrf_win > best_vrf:\n                best_vrf = vrf_win\n                best_strategy_code = strategy_code_win\n                clt_for_best_strategy = clt_win\n                \n            # --- Strategy: Truncated ---\n            e1_trunc, e2_trunc = get_truncated_moments(alpha, x_m, tau)\n            var_V_trunc = e2_trunc - e1_trunc**2\n            clt_trunc = True # Always finite variance\n            vrf_trunc = 1.0\n            if var_V_trunc > 0:\n              vrf_trunc = 1.0 + (lam**2 * var_X) / var_V_trunc\n\n            strategy_code_trunc = 3 + i * 3\n            if vrf_trunc > best_vrf:\n                best_vrf = vrf_trunc\n                best_strategy_code = strategy_code_trunc\n                clt_for_best_strategy = clt_trunc\n\n        # --- Determine boolean flags ---\n        # c_r: any raw control has finite variance (i.e. yields asymptotic normality)\n        c_r = 1 if (candidates[0]['alpha'] > 2.0 or candidates[1]['alpha'] > 2.0) else 0\n        \n        # c_s: selected strategy has finite variance\n        c_s = 1 if clt_for_best_strategy else 0\n        \n        all_results.append(f\"[{best_strategy_code},{best_vrf},{c_r},{c_s}]\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3325576"}]}