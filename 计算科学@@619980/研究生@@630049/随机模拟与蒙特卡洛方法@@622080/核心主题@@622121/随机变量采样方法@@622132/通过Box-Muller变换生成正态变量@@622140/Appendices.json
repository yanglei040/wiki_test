{"hands_on_practices": [{"introduction": "这项基础实践将指导您从零开始实现Box-Muller变换，并完成验证过程中的关键第一步：检验生成样本的矩（如均值、方差）是否与其理论值相符。通过将抽象算法与具体、可测试的统计特性联系起来，这项练习 [@problem_id:3324049] 为您打下坚实的基础。", "problem": "您需要在一个可复现的程序中，使用 Box–Muller 变换实现并验证一个独立的标准正态随机变量生成器。验证必须通过从大样本中估计选定的矩，构建置信区间，并检查标准正态分布的已知理论值是否落在这些区间内来进行。程序必须使用极坐标到笛卡尔坐标的变量变换来实现从独立均匀随机变量到独立标准正态随机变量的转换；任何角度都必须以弧度为单位。\n\n从以下基本依据开始：\n- 设 $U_1$ 和 $U_2$ 是服从 $\\mathrm{Uniform}(0,1)$ 分布的独立同分布随机变量。\n- 标准正态分布 $\\mathcal{N}(0,1)$ 的均值为 $0$，方差为 $1$，其偶数阶矩由 $E[X^{2m}] = (2m-1)!!$ 给出（对于整数 $m \\ge 1$），其中 $(2m-1)!!$ 表示从 1 到 $(2m-1)$ 的所有奇数的乘积。\n- 中心极限定理（CLT）表明，对于期望为 $E[Y_i] = \\mu$ 且方差为 $\\mathrm{Var}(Y_i) = \\sigma_Y^2 \\in (0,\\infty)$ 的独立同分布观测值 $\\{Y_i\\}_{i=1}^n$，样本均值 $\\bar{Y}_n$ 满足 $\\sqrt{n}\\,(\\bar{Y}_n - \\mu) \\overset{d}{\\longrightarrow} \\mathcal{N}(0,\\sigma_Y^2)$。\n- 如果 $X_1,\\dots,X_n$ 是独立同分布于 $\\mathcal{N}(0,1)$ 的随机变量，且 $S^2$ 表示无偏样本方差 $S^2 = \\frac{1}{n-1}\\sum_{i=1}^n (X_i - \\bar{X}_n)^2$，则 $(n-1)S^2 \\sim \\chi^2_{n-1}$。\n\n您的程序必须：\n- 实现 Box–Muller 变换，将独立均匀变量映射为一系列独立的标准正态变量。通过避免对 $0$ 取对数来确保数值稳健性。该实现必须适用于任何正整数样本量 $n$，并精确返回 $n$ 个正态变量。所有角度计算均使用弧度。\n- 对于每个指定的参数集，生成一个大小为 $n$ 的样本，并计算：\n  1. 样本均值 $\\bar{X}_n$ 和使用中心极限定理（已知方差为 $1$）为真实均值 $0$ 构建的双侧 $(1-\\alpha)$-置信区间。\n  2. 无偏样本方差 $S^2$ 和使用自由度为 $n-1$ 的卡方分布为真实方差 $1$ 构建的双侧 $(1-\\alpha)$-置信区间。\n  3. 样本二阶原始矩 $\\hat{m}_2 = \\frac{1}{n}\\sum_{i=1}^n X_i^2$ 和使用中心极限定理（方差为 $\\mathrm{Var}(X^2) = E[X^4] - (E[X^2])^2$）为真实二阶原始矩 $E[X^2] = 1$ 构建的双侧 $(1-\\alpha)$-置信区间。\n  4. 对于 $k \\in \\{4\\}$，选择一个更高阶的原始矩 $\\hat{m}_k = \\frac{1}{n}\\sum_{i=1}^n X_i^k$，并使用中心极限定理（方差为 $\\mathrm{Var}(X^k) = E[X^{2k}] - (E[X^k])^2$）为真实原始矩 $E[X^k]$ 构建一个双侧 $(1-\\alpha)$-置信区间。\n- 对于第 3 项和第 4 项，使用恒等式 $E[X^{2m}] = (2m-1)!!$ 计算所需的任何理论矩 $E[X^{2m}]$（对于 $X \\sim \\mathcal{N}(0,1)$）。\n- 对于每个置信区间，报告一个布尔值，指示理论值是否位于计算出的区间内。\n\n测试套件和要求的输出：\n- 使用以下三个参数集，每个都是一个元组 $(n,\\alpha,k,\\mathrm{seed})$：\n  - 情况 1：$(n,\\alpha,k,\\mathrm{seed}) = (400000, 0.01, 4, 314159)$。\n  - 情况 2：$(n,\\alpha,k,\\mathrm{seed}) = (250000, 0.005, 4, 271828)$。\n  - 情况 3：$(n,\\alpha,k,\\mathrm{seed}) = (120000, 0.02, 4, 141421)$。\n- 对于每种情况，按以下顺序生成四个布尔值：均值在区间内、方差在区间内、二阶原始矩在区间内、k阶原始矩在区间内。按顺序汇总这三种情况的结果。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[\\mathrm{result1},\\mathrm{result2},\\mathrm{result3}]$），其中每个结果都是一个布尔值。因此，最终输出必须是一个长度为 12 的扁平列表，按顺序包含三种情况的布尔值。\n\n不涉及物理单位。所有角度计算都必须以弧度为单位。数值结果必须使用双精度浮点运算进行计算。", "solution": "问题陈述是有效的。它在科学上基于概率论和统计学理论，问题阐述清晰，包含具体的指令和可复现的参数，并且语言客观。任务是实现用于生成标准正态变量的 Box-Muller 变换，并使用分布的几个矩的置信区间来验证输出。\n\n解决方案分两个阶段进行：首先，实现随机变量生成器；其次，对生成的样本进行统计验证。\n\n### 第 1 部分：Box-Muller 变换\n\nBox-Muller 变换是一种从一对独立均匀随机变量生成一对独立标准正态随机变量的方法。设 $U_1$ 和 $U_2$ 是来自 $\\mathrm{Uniform}(0,1)$ 分布的独立同分布随机变量。该变换定义如下：\n$$Z_1 = \\sqrt{-2 \\ln U_1} \\cos(2\\pi U_2)$$\n$$Z_2 = \\sqrt{-2 \\ln U_1} \\sin(2\\pi U_2)$$\n得到的随机变量 $Z_1$ 和 $Z_2$ 是独立的，并且均服从标准正态分布 $\\mathcal{N}(0,1)$。\n\n这种变换可以理解为一种使用从笛卡尔坐标到极坐标的变量变换的逆采样方法。一个二维标准正态向量 $(Z_1, Z_2)$ 的半径平方 $R^2 = Z_1^2 + Z_2^2$ 服从自由度为 2 的卡方分布 ($\\chi^2_2$)，这等价于均值为 2 的指数分布。角度 $\\Theta = \\mathrm{atan2}(Z_2, Z_1)$ 在 $[0, 2\\pi)$ 上均匀分布。Box-Muller 变换综合了这些性质。通过设置 $\\Theta = 2\\pi U_2$，我们生成一个分布正确的角度。通过设置 $R^2 = -2 \\ln U_1$，我们生成一个均值为 2 的指数分布的变量。从生成的极坐标 $(R, \\Theta)$ 变换回笛卡尔坐标 $(Z_1, Z_2)$ 就得到了所需的正态变量。\n\n为了生成大小为 $n$ 的样本，我们将生成 $\\lceil n/2 \\rceil$ 对均匀变量 $(U_1, U_2)$，对每对应用变换以获得 $2 \\lceil n/2 \\rceil$ 个正态变量，然后从结果序列中选取前 $n$ 个变量。为保证数值稳健性，我们必须确保对数的参数严格为正。由于 $U_1 \\sim \\mathrm{Uniform}(0,1)$，其值可以任意接近 $0$，并且计算机用于区间 $[0,1)$ 的随机数生成器理论上可能产生精确的 $0$。我们将通过重新采样任何生成为 $0$ 的 $U_1$ 来处理这种情况。\n\n### 第 2 部分：通过置信区间进行统计验证\n\n对于每个参数集 $(n, \\alpha, k, \\mathrm{seed})$，都会生成一个样本 $\\{X_i\\}_{i=1}^n$。然后我们构建四个双侧 $(1-\\alpha)$-置信区间，并检查它们是否包含各自的理论值。令 $z_{\\alpha/2}$ 为标准正态分布的上 $\\alpha/2$ 分位数，使得对于 $Z \\sim \\mathcal{N}(0,1)$ 有 $P(Z > z_{\\alpha/2}) = \\alpha/2$。\n\n1.  **均值的置信区间 ($\\mu=0$)**:\n    真实均值为 $\\mu=0$，真实方差为 $\\sigma^2=1$。样本均值为 $\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i$。根据中心极限定理（CLT），对于大的 $n$，统计量 $\\frac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}}$ 近似服从 $\\mathcal{N}(0,1)$ 分布。$\\mu$ 的 $(1-\\alpha)$-置信区间由 $\\bar{X}_n \\pm z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}$ 给出。我们检查理论均值 $\\mu=0$ 是否落在 $[\\bar{X}_n - z_{\\alpha/2}/\\sqrt{n}, \\bar{X}_n + z_{\\alpha/2}/\\sqrt{n}]$ 内。\n\n2.  **方差的置信区间 ($\\sigma^2=1$)**:\n    真实方差为 $\\sigma^2=1$。无偏样本方差为 $S^2 = \\frac{1}{n-1}\\sum_{i=1}^n(X_i - \\bar{X}_n)^2$。对于来自正态分布的样本，量 $\\frac{(n-1)S^2}{\\sigma^2}$ 服从自由度为 $n-1$ 的卡方分布 $\\chi^2_{n-1}$。令 $\\chi^2_{n-1, 1-\\alpha/2}$ 和 $\\chi^2_{n-1, \\alpha/2}$ 为该分布的下临界值和上临界值。$\\sigma^2$ 的 $(1-\\alpha)$-置信区间为 $\\left[ \\frac{(n-1)S^2}{\\chi^2_{n-1, \\alpha/2}}, \\frac{(n-1)S^2}{\\chi^2_{n-1, 1-\\alpha/2}} \\right]$。我们检查理论方差 $\\sigma^2=1$ 是否落入此区间。\n\n3.  **二阶原始矩的置信区间 ($E[X^2]=1$)**:\n    二阶原始矩为 $E[X^2]$。对于 $X \\sim \\mathcal{N}(0,1)$，$E[X^2] = \\mathrm{Var}(X) + (E[X])^2 = 1 + 0^2 = 1$。样本二阶原始矩为 $\\hat{m}_2 = \\frac{1}{n}\\sum_{i=1}^n X_i^2$。我们对变量 $Y_i = X_i^2$ 应用中心极限定理。$Y_i$ 的方差为 $\\mathrm{Var}(X^2) = E[X^4] - (E[X^2])^2$。理论偶数阶原始矩由 $E[X^{2m}] = (2m-1)!!$ 给出。因此，$E[X^2]=1!!=1$ 且 $E[X^4]=3!!=3$。所以，$\\mathrm{Var}(X^2) = 3 - 1^2 = 2$。$E[X^2]$ 的 $(1-\\alpha)$-置信区间为 $\\hat{m}_2 \\pm z_{\\alpha/2} \\sqrt{\\frac{\\mathrm{Var}(X^2)}{n}}$。我们检查 $1$ 是否在 $[\\hat{m}_2 - z_{\\alpha/2}\\sqrt{2/n}, \\hat{m}_2 + z_{\\alpha/2}\\sqrt{2/n}]$ 内。\n\n4.  **k 阶原始矩的置信区间 ($E[X^k]$ 对于 $k=4$)**:\n    问题指定测试 $k=4$ 的原始矩。理论值为 $E[X^4] = 3!! = 3$。样本 4 阶原始矩为 $\\hat{m}_4 = \\frac{1}{n}\\sum_{i=1}^n X_i^4$。我们对变量 $W_i = X_i^4$ 应用中心极限定理。$W_i$ 的方差为 $\\mathrm{Var}(X^4) = E[X^8] - (E[X^4])^2$。使用矩公式，$E[X^8] = 7!! = 105$。方差为 $\\mathrm{Var}(X^4) = 105 - 3^2 = 96$。$E[X^4]$ 的 $(1-\\alpha)$-置信区间为 $\\hat{m}_4 \\pm z_{\\alpha/2} \\sqrt{\\frac{\\mathrm{Var}(X^4)}{n}}$。我们检查理论值 $3$ 是否在 $[\\hat{m}_4 - z_{\\alpha/2}\\sqrt{96/n}, \\hat{m}_4 + z_{\\alpha/2}\\sqrt{96/n}]$ 内。\n\n程序将对每个提供的测试用例执行这些步骤，使用指定的随机种子以确保可复现性，并为四个检查中的每一个报告一个布尔值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Implements and validates the Box-Muller transform for generating standard normal variates.\n    \"\"\"\n\n    # The test suite as specified in the problem statement.\n    test_cases = [\n        # (n, alpha, k, seed)\n        (400000, 0.01, 4, 314159),\n        (250000, 0.005, 4, 271828),\n        (120000, 0.02, 4, 141421),\n    ]\n\n    results = []\n\n    def box_muller_generate(n, rng):\n        \"\"\"\n        Generates n standard normal variates using the Box-Muller transform.\n        \n        Args:\n            n (int): The number of variates to generate.\n            rng (np.random.Generator): The random number generator instance.\n        \n        Returns:\n            np.ndarray: An array of n standard normal variates.\n        \"\"\"\n        if n == 0:\n            return np.array([])\n        \n        # We generate pairs of variates, so we need ceil(n/2) pairs.\n        num_pairs = (n + 1) // 2\n        \n        # Generate uniform random numbers in [0, 1).\n        u1 = rng.random(num_pairs)\n        \n        # Ensure u1 is not exactly 0 to avoid log(0).\n        # Although extremely unlikely, this ensures robustness.\n        while np.any(u1 == 0):\n            zero_indices = (u1 == 0)\n            u1[zero_indices] = rng.random(np.sum(zero_indices))\n            \n        u2 = rng.random(num_pairs)\n        \n        # Apply the Box-Muller transformation.\n        r = np.sqrt(-2.0 * np.log(u1))\n        theta = 2.0 * np.pi * u2\n        \n        z1 = r * np.cos(theta)\n        z2 = r * np.sin(theta)\n        \n        # Combine the pairs and truncate to the desired length n.\n        z = np.stack((z1, z2), axis=-1).flatten()\n        return z[:n]\n\n    for n, alpha, k, seed in test_cases:\n        # Initialize the random number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n        \n        # Generate the sample of standard normal variates.\n        X = box_muller_generate(n, rng)\n        \n        # --- 1. Confidence Interval for the Mean (mu=0) ---\n        mu_true = 0.0\n        sigma_true = 1.0\n        x_bar = np.mean(X)\n        z_alpha_2 = stats.norm.ppf(1.0 - alpha / 2.0)\n        \n        ci_mean_half_width = z_alpha_2 * (sigma_true / np.sqrt(n))\n        ci_mean_lower = x_bar - ci_mean_half_width\n        ci_mean_upper = x_bar + ci_mean_half_width\n        mean_in_ci = (ci_mean_lower = mu_true = ci_mean_upper)\n        \n        # --- 2. Confidence Interval for the Variance (sigma^2=1) ---\n        var_true = 1.0\n        s_squared = np.var(X, ddof=1)\n        df = n - 1\n        \n        chi2_lower_crit = stats.chi2.ppf(alpha / 2.0, df)\n        chi2_upper_crit = stats.chi2.ppf(1.0 - alpha / 2.0, df)\n        \n        ci_var_lower = df * s_squared / chi2_upper_crit\n        ci_var_upper = df * s_squared / chi2_lower_crit\n        var_in_ci = (ci_var_lower = var_true = ci_var_upper)\n\n        # --- 3. Confidence Interval for the Second Raw Moment (E[X^2]=1) ---\n        m2_true = 1.0\n        # Var(X^2) = E[X^4] - (E[X^2])^2 = 3 - 1^2 = 2\n        var_x2 = 2.0\n        m2_hat = np.mean(X**2)\n        \n        ci_m2_half_width = z_alpha_2 * np.sqrt(var_x2 / n)\n        ci_m2_lower = m2_hat - ci_m2_half_width\n        ci_m2_upper = m2_hat + ci_m2_half_width\n        m2_in_ci = (ci_m2_lower = m2_true = ci_m2_upper)\n        \n        # --- 4. Confidence Interval for the k-th Raw Moment (k=4) ---\n        # For k=4, E[X^4] = 3.\n        # Var(X^4) = E[X^8] - (E[X^4])^2 = 105 - 3^2 = 96.\n        mk_true = 3.0\n        var_xk = 96.0\n        mk_hat = np.mean(X**k)\n        \n        ci_mk_half_width = z_alpha_2 * np.sqrt(var_xk / n)\n        ci_mk_lower = mk_hat - ci_mk_half_width\n        ci_mk_upper = mk_hat + ci_mk_half_width\n        mk_in_ci = (ci_mk_lower = mk_true = ci_mk_upper)\n        \n        # Append the four boolean results for the current case.\n        results.extend([mean_in_ci, var_in_ci, m2_in_ci, mk_in_ci])\n\n    # Print the final aggregated results in the specified format.\n    print(f\"[{','.join(str(b).lower() for b in results)}]\")\n\nsolve()\n\n```", "id": "3324049"}, {"introduction": "矩检验是必要的，但并非充分的。这项实践将您的验证技能提升到一个新水平，引入了更强大的拟合优度检验，并强调了多维生成中的一个关键概念：验证联合分布的正确性。通过精心设计的测试用例 [@problem_id:3323985]，您将了解为何仅检验边缘分布可能产生误导，并学会如何构建更稳健的验证套件。", "problem": "考虑通过对区间 $(0,1)$ 上的独立均匀随机变量进行变换，来生成独立的标准正态随机变量。使用的基本原理如下：当 $(Z_1,Z_2)$ 是一对独立的标准正态随机变量时，通过 $R = \\sqrt{Z_1^2 + Z_2^2}$ 和 $\\Theta = \\operatorname{atan2}(Z_2,Z_1)$ 定义的极坐标变换 $(R,\\Theta)$ 会产生一个服从尺度为 $1$ 的瑞利分布 (Rayleigh distribution) 的半径 $R$ 和一个在 $[0,2\\pi)$ 弧度上均匀分布的角度 $\\Theta$，且 $R$ 和 $\\Theta$ 是独立的。反之，对 $(0,1)$ 上的独立均匀随机变量进行正确的变换，可以生成这样一对 $(Z_1,Z_2)$。Kolmogorov–Smirnov 检验（将经验分布函数与指定的连续累积分布函数进行比较）和 Anderson–Darling 检验（对尾部偏差加权更重）可以应用于一维边缘分布，以评估 $Z_1$ 和 $Z_2$ 是否各自为标准正态分布。然而，这些检验不能直接评估二维联合分布或独立性。\n\n您的任务是编写一个完整的程序，该程序：\n\n1. 实现一个生成器，通过对 $(0,1)$ 上的独立均匀随机变量进行极坐标变换（通常称为 Box–Muller 变换），生成旨在成为独立标准正态随机变量的数对 $(Z_1,Z_2)$，并通过确保所有均匀抽样都严格为正来避免退化输入。\n\n2. 对每个边缘分布 $Z_1$ 和 $Z_2$ 应用一维拟合优度检验：\n   - 在显著性水平 $0.05$ 下进行正态性的 Anderson–Darling 检验（即，如果检验统计量严格小于对应于 $5$ 百分位的列表临界值，则接受）。\n   - 在显著性水平 $0.05$ 下，针对均值为 $0$、方差为 $1$ 的标准正态分布进行 Kolmogorov–Smirnov 检验（即，如果 $p$ 值至少为 $0.05$，则接受）。\n   定义布尔值 $marginals\\_ok$ 为当且仅当所有四个检验（对 $Z_1$ 和 $Z_2$ 各自的 Anderson–Darling 和 Kolmogorov–Smirnov 检验）都接受时为真。\n\n3. 通过增加源自基本原理的联合结构检查，来解决一维检验无法评估二维联合分布的局限性：\n   - 使用双参数反正切函数从 $(Z_1,Z_2)$ 计算角度 $\\Theta \\in [0,2\\pi)$，并通过 Kolmogorov–Smirnov 检验在显著性水平 $0.05$ 下检验其在 $[0,2\\pi)$ 弧度上的均匀性。\n   - 计算半径 $R = \\sqrt{Z_1^2 + Z_2^2}$，并通过 Kolmogorov–Smirnov 检验在显著性水平 $0.05$ 下检验其尺度为 $1$ 的瑞利分布。\n   - 计算 $Z_1$ 和 $Z_2$ 之间的样本皮尔逊相关系数 (sample Pearson correlation coefficient)，如果相关系数的绝对值严格小于 $0.05$ 且皮尔逊相关检验的双边 $p$ 值至少为 $0.05$，则接受该独立性代理指标。\n   定义布尔值 $joint\\_ok$ 为当且仅当所有三个联合检查都接受时为真。\n\n4. 使用以下参数值测试套件，每个测试套件都指定了随机数生成器的种子、样本大小和方法：\n   - 测试用例 1（正常路径）：种子 $12345$，样本大小 $20000$，方法 “box\\_muller”，使用独立均匀输入。\n   - 测试用例 2（中等大小）：种子 $2024$，样本大小 $500$，方法 “box\\_muller”，使用独立均匀输入。\n   - 测试用例 3（展示局限性的边缘案例）：种子 $42$，样本大小 $8000$，方法 “fake\\_pair\\_equal”，该方法从一个原本有效的 “box\\_muller” 生成器构造 $Z_2 = Z_1$，因此边缘分布保持标准正态，但联合分布是退化的。\n   - 测试用例 4（非均匀输入失真）：种子 $777$，样本大小 $10000$，方法 “box\\_muller”，其中 $U_1$ 从非均匀定律 $U_1 = V^2$（其中 $V \\sim \\operatorname{Uniform}(0,1)$）中抽取，而 $U_2 \\sim \\operatorname{Uniform}(0,1)$，旨在有意破坏半径定律而不改变角度定律。\n\n您的程序必须为每个测试用例生成一个列表，其中包含：\n- 布尔值 $marginals\\_ok$，\n- 布尔值 $joint\\_ok$，\n- $Z_1$ 和 $Z_2$ 之间绝对样本皮尔逊相关性的浮点值。\n\n程序的最终输出必须是单行文本，包含所有测试用例的结果，格式为用方括号括起来的逗号分隔列表，其中每个测试结果本身也是一个用方括号括起来的逗号分隔列表。例如：“[ [true,false,0.01234], [true,true,0.00321], ... ]”。在整个过程中，角度必须以弧度处理。此问题不涉及任何物理单位。所有数值答案必须严格按照指定的最终输出格式返回。如上所述，所有检验的接受标准均为显著性水平 $0.05$。", "solution": "该问题要求基于 Box-Muller 变换，实现并统计验证一个用于独立标准正态随机变量 $\\mathcal{N}(0,1)$ 的生成器。验证过程涉及一套全面的检验，旨在评估生成变量的边缘分布及其联合结构。\n\n### 1. Box-Muller 变换：原理与实现\n\nBox-Muller 变换是蒙特卡洛模拟中从均匀分布变量生成标准正态变量的一种基础方法。它源于以下观察：如果 $(Z_1, Z_2)$ 是两个独立的标准正态随机变量，它们在极坐标 $(R, \\Theta)$ 中的表示（其中 $Z_1 = R \\cos \\Theta$ 且 $Z_2 = R \\sin \\Theta$）会得到一个独立的半径 $R$ 和角度 $\\Theta$。具体来说，平方半径 $R^2 = Z_1^2 + Z_2^2$ 服从速率 $\\lambda = 1/2$ 的指数分布，而角度 $\\Theta = \\operatorname{atan2}(Z_2, Z_1)$ 服从 $[0, 2\\pi)$ 上的均匀分布。\n\n该变换反向利用了这一性质。通过从各自的分布中生成 $R$ 和 $\\Theta$，然后转换回笛卡尔坐标，我们便可以产生所需的数对 $(Z_1, Z_2)$。\n生成过程如下：\n1.  从 $(0,1)$ 上的均匀分布生成两个独立的随机变量 $U_1, U_2$，即 $U_1, U_2 \\sim \\operatorname{Uniform}(0,1)$。\n2.  为了从累积分布函数为 $F(x) = 1 - e^{-x/2}$ 的指数分布中生成平方半径 $R^2$，我们使用逆变换采样法。令 $U_1 = F(R^2) = 1 - e^{-R^2/2}$。解出 $R^2$ 得 $R^2 = -2 \\ln(1 - U_1)$。由于 $1-U_1$ 也服从 $\\operatorname{Uniform}(0,1)$ 分布，我们可以将其简化为 $R^2 = -2 \\ln U_1$。由此得到半径为 $R = \\sqrt{-2 \\ln U_1}$。\n3.  为了从 $[0, 2\\pi)$ 中均匀生成角度 $\\Theta$，我们只需缩放 $U_2$：$\\Theta = 2\\pi U_2$。\n4.  最后，我们变换回笛卡尔坐标以获得两个独立的标准正态变量：\n    $$Z_1 = R \\cos \\Theta = \\sqrt{-2 \\ln U_1} \\cos(2\\pi U_2)$$\n    $$Z_2 = R \\sin \\Theta = \\sqrt{-2 \\ln U_1} \\sin(2\\pi U_2)$$\n一个关键的实现细节是 $U_1$ 必须严格为正，以确保 $\\ln U_1$ 有明确定义。我们的实现将把任何出现的 $U_1=0$ 替换为一个非常小的正数，即机器 epsilon，以防止数值错误。\n\n### 2. 统计验证框架\n\n一个稳健的验证需要检查 $Z_1$ 和 $Z_2$ 的个体（边缘）分布以及它们的联合行为。\n\n#### 2.1. 边缘分布检验\n我们必须验证 $Z_1$ 和 $Z_2$ 是否各自都服从标准正态分布。这是通过在显著性水平 $\\alpha=0.05$ 下使用两种标准的拟合优度检验来完成的。\n\n1.  **Anderson-Darling (AD) 检验**：该检验在检测与正态性的偏差方面非常有效。计算检验统计量并与临界值进行比较。如果检验统计量严格小于 $5\\%$ 显著性水平的临界值，则接受原假设（数据是正态的）。\n2.  **Kolmogorov-Smirnov (KS) 检验**：此检验将样本的经验累积分布函数 (ECDF) 与标准正态分布的理论累积分布函数 (CDF) 进行比较。如果检验的 $p$ 值大于或等于显著性水平（即 $p \\ge 0.05$），则接受原假设。\n\n布尔变量 $marginals\\_ok$ 当且仅当所有四个检验（对 $Z_1$ 的 AD 和 KS 检验；对 $Z_2$ 的 AD 和 KS 检验）都通过时为真。\n\n#### 2.2. 联合结构检验\n边缘正态性是一对随机变量成为*独立*标准正态的必要但不充分条件。联合检验旨在探究二维结构。\n\n1.  **角度均匀性检验**：我们将生成的数对 $(Z_1, Z_2)$ 反向变换回极坐标，以获得角度 $\\Theta = \\operatorname{atan2}(Z_2, Z_1)$。根据基本理论，这些角度应在长度为 $2\\pi$ 的区间上均匀分布，例如 $[0, 2\\pi)$。我们使用 KS 检验针对 $[0, 2\\pi)$ 上的均匀分布来检验此假设。如果 $p$ 值至少为 $0.05$，则检验通过。\n2.  **半径分布检验**：同样，我们计算半径 $R = \\sqrt{Z_1^2 + Z_2^2}$。这些半径应服从尺度参数 $\\sigma=1$ 的瑞利分布。这通过 KS 检验进行测试，如果 $p$ 值至少为 $0.05$，则检验通过。\n3.  **独立性检验（通过相关性）**：真正的独立性难以检验。对于正态变量而言，不相关是其独立性的一个常见且必要（但不充分）的条件。我们计算 $Z_1$ 和 $Z_2$ 之间的样本皮尔逊相关系数 $\\rho$。我们采用双重检查：系数的绝对值必须很小 ($|\\rho|  0.05$)，并且用于检验非零相关的检验的 $p$ 值必须不显著 ($p \\ge 0.05$)。\n\n布尔变量 $joint\\_ok$ 当且仅当这三个联合检查都通过时为真。\n\n### 3. 测试用例分析\n\n提供的测试套件旨在展示该验证框架的功效和局限性。\n\n-   **案例 1 和 2（标准 Box-Muller）**：这些案例使用正确的 \"box\\_muller\" 方法，分别采用大样本量 ($N=20000$) 和中等样本量 ($N=500$)。我们期望 $marginals\\_ok$ 和 $joint\\_ok$ 都为真，因为生成器是正确实现的。种子确保了确定性的结果。\n-   **案例 3（退化的联合分布，$Z_2=Z_1$）**：这个案例旨在欺骗边缘检验。初始的一组标准正态变量 $Z_1$ 是正确生成的，但随后将 $Z_2$ 设置为等于 $Z_1$。根据构造，$Z_1$ 和 $Z_2$ 的边缘分布都是标准正态的。因此，我们期望 $marginals\\_ok$ 为真。然而，联合结构是完全退化的。相关性为 $\\rho=1$，半径 $R = \\sqrt{2Z_1^2} = \\sqrt{2}|Z_1|$ 不服从瑞利分布，角度 $\\Theta = \\operatorname{atan2}(Z_1, Z_1)$ 集中在 $\\pi/4$ 和 $-3\\pi/4$ 处。所有联合检验都应该失败，导致 $joint\\_ok$ 为假。\n-   **案例 4（失真的输入）**：在这里，输入均匀变量 $U_1$ 是从一个非均匀定律 $U_1 = V^2$（其中 $V \\sim \\operatorname{Uniform}(0,1)$）生成的。这个 $U_1$ 的概率密度函数 (PDF) 是 $f(u) = 1/(2\\sqrt{u})$，该分布偏向于 $0$。这直接破坏了半径 $R=\\sqrt{-2\\ln U_1}$ 的分布。因此，联合检查中的半径检验将会失败。$R$ 的这种失真也将使得 $Z_1 = R\\cos\\Theta$ 和 $Z_2 = R\\sin\\Theta$ 的边缘分布非正态，因此边缘检验也应失败。角度 $\\Theta=2\\pi U_2$ 不受影响，因为 $U_2$ 仍然是均匀的，所以角度检验可能会通过。相关结构没有明显的线性破坏，但基本的分布属性是不正确的。我们期望 $marginals\\_ok$ 和 $joint\\_ok$ 都为假。\n\n实现将遵循这些原则，使用 `numpy` 进行数值运算，使用 `scipy.stats` 进行统计检验。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Implements and validates a standard normal random variate generator\n    based on the Box-Muller transform, using a suite of statistical tests.\n    \"\"\"\n    test_cases = [\n        {\"seed\": 12345, \"sample_size\": 20000, \"method\": \"box_muller\"},\n        {\"seed\": 2024, \"sample_size\": 500, \"method\": \"box_muller\"},\n        {\"seed\": 42, \"sample_size\": 8000, \"method\": \"fake_pair_equal\"},\n        {\"seed\": 777, \"sample_size\": 10000, \"method\": \"box_muller_distorted\"},\n    ]\n\n    results = []\n    \n    # Significance level for all tests\n    alpha = 0.05\n    \n    # Critical value for Anderson-Darling test at 5% significance\n    # scipy.stats.anderson returns critical values for [15%, 10%, 5%, 2.5%, 1%]\n    ad_crit_val_idx = 2\n\n    for case in test_cases:\n        seed = case[\"seed\"]\n        n = case[\"sample_size\"]\n        method = case[\"method\"]\n        \n        rng = np.random.default_rng(seed)\n\n        z1, z2 = None, None\n\n        if method == \"box_muller\":\n            u1 = rng.uniform(size=n)\n            # Ensure u1 is strictly positive for log calculation\n            u1[u1 == 0.0] = np.finfo(float).eps\n            u2 = rng.uniform(size=n)\n            \n            r = np.sqrt(-2 * np.log(u1))\n            theta_gen = 2 * np.pi * u2\n            \n            z1 = r * np.cos(theta_gen)\n            z2 = r * np.sin(theta_gen)\n\n        elif method == \"fake_pair_equal\":\n            # Generate one set of normal variates and set the other equal\n            # Need n/2 pairs of uniforms to make n variates\n            num_pairs = (n + 1) // 2 \n            u1 = rng.uniform(size=num_pairs)\n            u1[u1 == 0.0] = np.finfo(float).eps\n            u2 = rng.uniform(size=num_pairs)\n            \n            r = np.sqrt(-2 * np.log(u1))\n            theta_gen = 2 * np.pi * u2\n            \n            temp_z1 = r * np.cos(theta_gen)\n            temp_z2 = r * np.sin(theta_gen)\n            \n            z_full = np.concatenate([temp_z1, temp_z2])\n            z1 = z_full[:n]\n            z2 = np.copy(z1)\n\n        elif method == \"box_muller_distorted\":\n            # U1 is from a non-uniform law U1 = V^2\n            v = rng.uniform(size=n)\n            u1 = v**2\n            # Ensure u1 is strictly positive for log calculation\n            u1[u1 == 0.0] = np.finfo(float).eps\n            u2 = rng.uniform(size=n)\n\n            r = np.sqrt(-2 * np.log(u1))\n            theta_gen = 2 * np.pi * u2\n            \n            z1 = r * np.cos(theta_gen)\n            z2 = r * np.sin(theta_gen)\n\n        # 2. Perform marginal tests\n        ad_z1 = stats.anderson(z1, dist='norm')\n        ks_z1 = stats.kstest(z1, 'norm')\n        \n        ad_z2 = stats.anderson(z2, dist='norm')\n        ks_z2 = stats.kstest(z2, 'norm')\n\n        ad1_ok = ad_z1.statistic  ad_z1.critical_values[ad_crit_val_idx]\n        ks1_ok = ks_z1.pvalue >= alpha\n        ad2_ok = ad_z2.statistic  ad_z2.critical_values[ad_crit_val_idx]\n        ks2_ok = ks_z2.pvalue >= alpha\n        \n        marginals_ok = all([ad1_ok, ks1_ok, ad2_ok, ks2_ok])\n\n        # 3. Perform joint structure tests\n        # Angle uniformity\n        thetas = (np.arctan2(z2, z1) + 2 * np.pi) % (2 * np.pi)\n        # Normalize to [0,1) for testing against uniform(0,1)\n        thetas_norm = thetas / (2 * np.pi)\n        ks_theta = stats.kstest(thetas_norm, 'uniform')\n        theta_ok = ks_theta.pvalue >= alpha\n        \n        # Radius Rayleigh distribution\n        radii = np.sqrt(z1**2 + z2**2)\n        ks_radii = stats.kstest(radii, 'rayleigh') # scale=1 is default\n        radii_ok = ks_radii.pvalue >= alpha\n        \n        # Independence via Pearson correlation\n        corr_res = stats.pearsonr(z1, z2)\n        corr_coeff, corr_pvalue = corr_res.statistic, corr_res.pvalue\n        corr_ok = (abs(corr_coeff)  0.05) and (corr_pvalue >= alpha)\n        \n        joint_ok = all([theta_ok, radii_ok, corr_ok])\n\n        # Store results\n        results.append([marginals_ok, joint_ok, abs(corr_coeff)])\n\n    # Format the final output string\n    result_strings = []\n    for res in results:\n        # Convert booleans to lowercase 'true'/'false'\n        formatted_res = [str(v).lower() for v in res[:-1]] + [f\"{res[-1]:.10f}\"]\n        result_strings.append(f\"[{','.join(formatted_res)}]\")\n    \n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "3323985"}, {"introduction": "一个正确的算法只有在高效时才真正有用。最后的这项实践将重点从统计正确性转向计算性能——这是现实世界蒙特卡洛模拟的关键考量。您将分析不同的实现策略（例如缓存），并评估它们在各种应用场景（包括标量、向量化和多线程使用）中对吞吐量的影响 [@problem_id:3323992]。", "problem": "在 Box–Muller 变换中，独立同分布的 Uniform$(0,1)$ 变量 $U_1$ 和 $U_2$ 通过极坐标变换被映射为独立同分布的标准正态变量 $Z_1$ 和 $Z_2$。考虑一个标量随机数生成函数 $\\texttt{next\\_normal}()$，该函数每次调用必须恰好返回 1 个标准正态样本。比较两种实现策略：\n- 策略 $\\mathcal{N}$ (非缓存)：每次调用时，生成新的 $U_1, U_2 \\sim \\text{Uniform}(0,1)$，计算一个 Box–Muller 对 $(Z_1,Z_2)$，返回 $Z_1$ 并丢弃 $Z_2$。\n- 策略 $\\mathcal{C}$ (缓存)：维护一个由一个标志位和一个已存储的正态变量组成的内部状态。如果标志位指示有已存储的 $Z_2$ 可用，则返回它并清除标志位；否则，生成新的 $U_1, U_2$，计算 $(Z_1,Z_2)$，立即返回 $Z_1$ 并为下一次调用存储 $Z_2$，同时设置标志位。\n\n假设以下经过充分检验的事实和成本模型用于分析：\n- Box–Muller 变换使用独立同分布的 $U_1, U_2 \\sim \\text{Uniform}(0,1)$，并通过 $R=\\sqrt{-2\\ln U_1}$ 和 $\\Theta=2\\pi U_2$ 将它们映射为 $Z_1=R\\cos\\Theta$ 和 $Z_2=R\\sin\\Theta$，从而产生独立同分布的 $\\mathcal{N}(0,1)$ 输出 $Z_1$ 和 $Z_2$。\n- 从 $(U_1,U_2)$ 计算 $(Z_1,Z_2)$ 的总成本主要由对每对变量进行一次 $\\ln(\\cdot)$、$\\sqrt{\\cdot}$、$\\sin(\\cdot)$ 和 $\\cos(\\cdot)$ 求值所主导，该成本记为 $c_t0$，再加上生成 2 个均匀分布变量的成本，该成本记为 $c_u0$（对应底层均匀分布生成器的 2 次调用）。\n- 在策略 $\\mathcal{C}$ 中，每次调用都包含一个对缓存标志位的条件分支，该分支可能以概率 $p \\in [0,1]$ 发生错误预测，产生 $c_b \\ge 0$ 的惩罚。在稳态标量使用中，调用在“填充缓存并返回 $Z_1$”和“返回缓存的 $Z_2$”之间交替进行，假设错误预测以某个固定的概率 $p$ 发生，该概率由调用者的访问模式和处理器的预测器决定。\n- 读/写缓存的 $Z_2$ 和标志位会访问通常位于一级数据缓存中的状态；在策略 $\\mathcal{C}$ 下，将此抽象为每个输出的平均额外内存成本 $c_m \\ge 0$，在典型的中央处理器 (CPU) 微架构上，$c_m \\ll c_t$。\n\n同时考虑两种使用模式：\n- 模式 $\\mathsf{S}$ (标量流式)：应用程序重复调用 $\\texttt{next\\_normal}()$ 以获得一长串独立同分布的标准正态样本，并在每个样本交付后立即消耗它。\n- 模式 $\\mathsf{V}$ (向量化批量)：应用程序通过在一个紧凑循环内重复调用 $\\texttt{next\\_normal}()$ 来请求一个长度为 $n$（$n \\gg 1$）的数组。除此之外，该代码适合进行单指令多数据 (SIMD) 向量化。你可以假设 $n$ 是任意的（不一定是偶数）。\n\n选择下面所有正确的陈述，并根据变换的基本原理和成本模型证明你的选择。\n\nA. 在模式 $\\mathsf{S}$ 下，如果 $U_1$ 和 $U_2$ 是独立同分布的，并且底层生成器的状态在各次调用之间是独立的，那么策略 $\\mathcal{C}$ 产生的输出序列是独立同分布的 $\\mathcal{N}(0,1)$；缓存 $Z_2$ 不会引入序列相关性，无论缓存值何时被消耗。\n\nB. 在模式 $\\mathsf{S}$ 下，相对于策略 $\\mathcal{N}$，策略 $\\mathcal{C}$ 将每个正态输出消耗的均匀分布变量数量和高成本的超越函数求值次数都减少了约 2 倍，得到接近 $\\tfrac{1}{2}(c_t+c_u)$ 的预期单样本成本，再加上附加的分支和内存成本 $pc_b + c_m$。\n\nC. 由于策略 $\\mathcal{C}$ 中对缓存标志位的分支是不可避免的，因此在带有分支预测的现代超标量 CPU 上，缓存必然会降低吞吐量，使得对于任何现实的参数，$\\mathcal{C}$ 都比 $\\mathcal{N}$ 慢。\n\nD. 在模式 $\\mathsf{V}$ 且 $n \\gg 1$ 的情况下，缓存会阻碍完全的 SIMD 向量化并引入额外的控制流，从而可能降低吞吐量；一种更高吞吐量的设计是在批量循环内部成对生成输出而不进行缓存，并单独处理长度为 1 的奇数末尾部分。\n\nE. 如果多个线程共享一个带有单个缓存槽的 $\\texttt{next\\_normal}()$ 实例，策略 $\\mathcal{C}$ 可能会在持有标志位和缓存值的共享缓存行上产生争用和伪共享，从而损害吞吐量，除非该状态是线程本地的或受同步机制保护。\n\nF. 即使 $U_1$ 和 $U_2$ 是独立同分布的，缓存 $Z_2$ 也会使偶数次调用的输出分布偏向于更大的量值，因为一对输出共享相同的半径 $R=\\sqrt{-2\\ln U_1}$，所以第二个输出的 $|Z|$ 倾向于在随机意义上大于第一个。", "solution": "首先将对问题陈述进行科学性和逻辑完整性验证。\n\n### 步骤 1：提取已知条件\n\n-   **变换**：Box–Muller 变换将独立同分布 (i.i.d.) 的随机变量 $U_1, U_2 \\sim \\text{Uniform}(0,1)$ 映射为 i.i.d. 的标准正态变量 $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$。\n-   **函数**：一个标量生成器 `next_normal()` 每次调用必须恰好返回 1 个标准正态样本。\n-   **策略 $\\mathcal{N}$ (非缓存)**：在每次调用中，生成新的 $U_1, U_2$；计算对 $(Z_1, Z_2)$；返回 $Z_1$ 并丢弃 $Z_2$。\n-   **策略 $\\mathcal{C}$ (缓存)**：利用内部状态（一个标志位和一个已存储的正态变量）。如果一个值被缓存，则返回它。否则，从新的 $U_1, U_2$ 生成一对新的 $(Z_1, Z_2)$；返回 $Z_1$ 并为下一次调用缓存 $Z_2$。\n-   **公式**：$R=\\sqrt{-2\\ln U_1}$, $\\Theta=2\\pi U_2$, 产生 $Z_1=R\\cos\\Theta$ 和 $Z_2=R\\sin\\Theta$。\n-   **成本模型**：\n    -   生成一对 $(Z_1, Z_2)$ 的成本为 $c_t + c_u$，其中 $c_t0$ 是分别对 $\\ln(\\cdot), \\sqrt{\\cdot}, \\sin(\\cdot), \\cos(\\cdot)$ 进行一次求值的成本，而 $c_u0$ 是生成两个均匀分布变量的成本。\n    -   对于策略 $\\mathcal{C}$，每次调用有来自条件分支的额外成本，其错误预测概率为 $p \\in [0,1]$，惩罚为 $c_b \\ge 0$。\n    -   对于策略 $\\mathcal{C}$，每个输出有额外的平均内存访问成本 $c_m \\ge 0$，其中 $c_m \\ll c_t$。\n    -   在稳态标量使用中，对 $\\mathcal{C}$ 的调用在生成新对和返回缓存值之间交替进行。\n-   **使用模式**：\n    -   **模式 $\\mathsf{S}$ (标量流式)**：对 `next_normal()` 进行一长串串行调用。\n    -   **模式 $\\mathsf{V}$ (向量化批量)**：在一个紧凑循环中调用 `next_normal()` 以填充一个长度为 $n \\gg 1$ 的数组。周围的代码适合 SIMD 向量化。$n$ 可以是奇数或偶数。\n\n### 步骤 2：使用提取的已知条件进行验证\n\n-   **科学依据**：问题陈述准确地描述了 Box-Muller 变换，这是一种用于生成正态变量的标准且已被充分理解的方法。所述的该变换产生独立同分布的 $\\mathcal{N}(0,1)$ 变量的结果是该方法的基石。成本模型是在性能分析中使用的合理且常见的抽象，考虑了超越函数成本、分支预测惩罚和内存层次结构效应。\n-   **适定性**：该问题是适定的。它定义了两种清晰、不同的算法（$\\mathcal{N}$ 和 $\\mathcal{C}$）、一个带有显式参数的成本模型以及特定的使用情境（$\\mathsf{S}$ 和 $\\mathsf{V}$）。任务是基于此框架评估一组陈述，这是一个标准的分析问题。\n-   **客观性**：语言是形式化的、技术性的，并且没有主观或模糊的术语。\n-   **完整性与一致性**：问题提供了执行所需分析的所有必要定义和假设。没有内部矛盾。例如，算法的描述、成本组成部分和使用模式都是自洽的。\n\n### 步骤 3：结论与行动\n\n问题陈述是有效的。它在科学上是合理的，是适定的、客观的，并为分析提供了完整、一致的基础。现在开始对提供的选项进行分析。\n\n### 对所提供选项的分析\n\n**A. 在模式 $\\mathsf{S}$ 下，如果 $U_1$ 和 $U_2$ 是独立同分布的，并且底层生成器的状态在各次调用之间是独立的，那么策略 $\\mathcal{C}$ 产生的输出序列是独立同分布的 $\\mathcal{N}(0,1)$；缓存 $Z_2$ 不会引入序列相关性，无论缓存值何时被消耗。**\n\n设生成的均匀分布对序列为 $(U_{1}^{(k)}, U_{2}^{(k)})$，其中 $k=1, 2, 3, \\ldots$。根据假设，这些对是独立同分布的。\n相应的正态对是 $(Z_{1}^{(k)}, Z_{2}^{(k)})$，其中 $Z_{1}^{(k)}$ 和 $Z_{2}^{(k)}$ 是 $(U_{1}^{(k)}, U_{2}^{(k)})$ 的函数。\nBox-Muller 变换的一个基本结果是，对于给定的 $k$，$Z_{1}^{(k)}$ 和 $Z_{2}^{(k)}$ 是独立同分布的 $\\mathcal{N}(0,1)$ 变量。\n由于均匀分布对在不同的 $k$ 之间是独立的，所以正态对 $(Z_{1}^{(k)}, Z_{2}^{(k)})$ 与 $k \\neq j$ 时的 $(Z_{1}^{(j)}, Z_{2}^{(j)})$ 是独立的。\n这意味着整个随机变量集合 $\\{Z_{1}^{(1)}, Z_{2}^{(1)}, Z_{1}^{(2)}, Z_{2}^{(2)}, \\ldots\\}$ 是一组相互独立、同分布的 $\\mathcal{N}(0,1)$ 变量。\n策略 $\\mathcal{C}$ 产生的输出序列为 $Z_{1}^{(1)}, Z_{2}^{(1)}, Z_{1}^{(2)}, Z_{2}^{(2)}, \\ldots$。由于这只是一组独立同分布随机变量的特定排序，因此结果序列也是独立同分布的。\n独立同分布的性质在排列下是不变的。因此，该序列是独立同分布的 $\\mathcal{N}(0,1)$。关于缓存不引入序列相关性的说法是正确的。\n\n结论：**正确**。\n\n**B. 在模式 $\\mathsf{S}$ 下，相对于策略 $\\mathcal{N}$，策略 $\\mathcal{C}$ 将每个正态输出消耗的均匀分布变量数量和高成本的超越函数求值次数都减少了约 2 倍，得到接近 $\\tfrac{1}{2}(c_t+c_u)$ 的预期单样本成本，再加上附加的分支和内存成本 $pc_b + c_m$。**\n\n让我们分析每种策略下生成单个正态样本的成本。\n-   **策略 $\\mathcal{N}$**：要生成一个正态样本，我们必须执行一次完整的 Box-Muller 变换。这需要 2 个均匀分布变量和一组对 $\\ln, \\sqrt, \\sin, \\cos$ 的求值。每个样本的成本是 $C_{\\mathcal{N}} = c_t + c_u$。\n-   **策略 $\\mathcal{C}$**：在稳态下，策略 $\\mathcal{C}$ 服务两次调用以产生两个正态样本。\n    -   第一次调用（例如，奇数次调用）生成一对新的 $(Z_1, Z_2)$。它产生 $c_t + c_u$ 的成本。它返回 $Z_1$。\n    -   第二次调用（例如，偶数次调用）返回缓存的 $Z_2$。它只产生开销成本。\n    -   因此，要生成 2 个正态样本，我们使用 2 个均匀分布变量并执行一组高成本的函数求值。\n    -   每个正态样本消耗的均匀分布变量的平均数量是 $2/2 = 1$。与策略 $\\mathcal{N}$ 每个样本消耗 2 个均匀分布变量相比，这减少了 2 倍。\n    -   每个正态样本的平均高成本变换次数是 $1/2$。与策略 $\\mathcal{N}$ 每个样本进行 1 次变换相比，这减少了 2 倍。\n    -   因此，每个样本的平均基本成本是 $\\frac{1}{2}(c_t + c_u)$。\n    -   在这个基本成本之上，我们必须加上开销。在策略 $\\mathcal{C}$ 下，每次对 `next_normal()` 的调用都涉及一个分支，产生 $p c_b$ 的预期成本，以及 $c_m$ 的平均内存成本。每个样本的总预期成本是 $C_{\\mathcal{C}} = \\frac{1}{2}(c_t + c_u) + p c_b + c_m$。\n-   该陈述准确地反映了这一分析。它正确地指出了主要成本减少了 2 倍，并正确地描述了最终的平均成本，包括附加的开销。\n\n结论：**正确**。\n\n**C. 由于策略 $\\mathcal{C}$ 中对缓存标志位的分支是不可避免的，因此在带有分支预测的现代超标量 CPU 上，缓存必然会降低吞吐量，使得对于任何现实的参数，$\\mathcal{C}$ 都比 $\\mathcal{N}$ 慢。**\n\n这个陈述声称对于任何现实的参数，都有 $C_{\\mathcal{C}} > C_{\\mathcal{N}}$。\n使用在 B 中推导的成本：\n$ \\frac{1}{2}(c_t + c_u) + p c_b + c_m > c_t + c_u $\n$ p c_b + c_m > \\frac{1}{2}(c_t + c_u) $\n让我们用现实的数值来评估这个不等式。超越函数的成本 $c_t$ 在现代 CPU 上通常非常高（例如，几十到几百个时钟周期）。分支预测错误的成本 $c_b$ 很显著但较小（例如，$15-25$ 个周期）。L1 缓存访问的成本 $c_m$ 很小（例如，几个周期）。对于一个完美的交替模式，现代分支预测器可以学习标志位的简单 `...1,0,1,0...` 模式，因此错误预测概率 $p$ 可以低至 $p=0$。即使使用一个简单的预测器，p ≈ 0.5。\n鉴于 $c_t$ 主导所有其他成本，并且问题本身就说明了 $c_m \\ll c_t$，这个不等式极不可能成立。例如，如果 $c_t = 100, c_u=10, c_b=20, c_m=5$，并且我们取一个悲观的 $p=0.5$，不等式变为：\n$ (0.5)(20) + 5 > \\frac{1}{2}(100 + 10) \\implies 15 > 55 $，这是错误的。\n将 $\\frac{1}{2}(c_t+c_u)$ 项减半所带来的巨大节省几乎总是会使微小的附加开销 $p c_b + c_m$ 相形见绌。因此，该陈述在事实上是不正确的。策略 $\\mathcal{C}$ 的设计正是因为它在标量情境下比 $\\mathcal{N}$ 快得多。\n\n结论：**不正确**。\n\n**D. 在模式 $\\mathsf{V}$ 且 $n \\gg 1$ 的情况下，缓存会阻碍完全的 SIMD 向量化并引入额外的控制流，从而可能降低吞吐量；一种更高吞吐量的设计是在批量循环内部成对生成输出而不进行缓存，并单独处理长度为 1 的奇数末尾部分。**\n\n模式 $\\mathsf{V}$ 涉及填充一个大数组，这是一项非常适合 SIMD (单指令多数据) 向量化的任务。SIMD 依赖于并行地对多个数据元素执行相同的操作。循环 `for (i=0; in; ++i) array[i] = next_normal()` 中对 `next_normal()` 的调用，如果使用策略 $\\mathcal{C}$，则包含一个 `if-else` 结构。这种数据相关的控制流（`if (cached) ... else ...`）是 SIMD 向量化的主要障碍，因为它要求 SIMD 通道中的所有通道都遵循相同的代码路径。\n一个更优越的、向量友好的设计是为批量生成编写一个专用函数。这个函数将在其内部循环中处理成对的数据，例如，一次处理 4、8 或 16 个均匀分布的数字，以产生相同数量的正态数，所有这些都无需分支。如果总数 $n$ 是奇数，则在主向量化循环之后，可以添加一个小的标量步骤来处理最后一个元素。这正是高性能数值库（如 Intel MKL 的 VSL）采用的方法。因此，陈述 D 准确地描述了缓存策略在向量化上下文中的缺点以及一种标准的、更高性能的替代方案。\n\n结论：**正确**。\n\n**E. 如果多个线程共享一个带有单个缓存槽的 $\\texttt{next\\_normal}()$ 实例，策略 $\\mathcal{C}$ 可能会在持有标志位和缓存值的共享缓存行上产生争用和伪共享，从而损害吞吐量，除非该状态是线程本地的或受同步机制保护。**\n\n该陈述描述了在多线程环境中使用带有共享状态的策略 $\\mathcal{C}$ 的经典问题。\n- **争用 (Contention)**：多个线程同时尝试读取和写入共享状态（标志位和缓存值）。这会产生竞争条件。例如，线程 A 计算了一对 $(Z_1, Z_2)$，返回 $Z_1$ 并缓存 $Z_2$。在 A 使用缓存的 $Z_2$ 之前，线程 B 调用函数，发现缓存已满，于是消耗 $Z_2$。然后，线程 A 再次调用，发现缓存是空的，于是生成一对新的。这破坏了预期的交替模式。更糟糕的是，如果两个线程同时发现缓存为空并都生成新对，其中一个线程的缓存写入将被另一个覆盖和丢失。\n- **伪共享 (False Sharing)**：即使线程访问状态的不同部分（不太可能，因为标志位和值很可能在同一个缓存行中），如果这些部分位于同一缓存行中，一个线程的写入将使其他内核中该行的副本失效，迫使它们从主存或更高级别的缓存重新加载，即使它们没有访问被修改的数据。\n- **解决方案**：为了防止这种情况，状态必须是线程本地的（每个线程有自己的 `next_normal` 实例或线程局部存储中的状态），或者访问必须通过互斥锁等同步机制进行序列化，但这会严重损害并行吞吐量。\n- 该陈述准确地指出了这些问题。\n\n结论：**正确**。\n\n**F. 即使 $U_1$ 和 $U_2$ 是独立同分布的，缓存 $Z_2$ 也会使偶数次调用的输出分布偏向于更大的量值，因为一对输出共享相同的半径 $R=\\sqrt{-2\\ln U_1}$，所以第二个输出的 $|Z|$ 倾向于在随机意义上大于第一个。**\n\nBox-Muller 变换生成 $Z_1 = R \\cos\\Theta$ 和 $Z_2 = R \\sin\\Theta$。变量 $R$ 和 $\\Theta$ 是独立的。$Z_1$ 和 $Z_2$ 是独立同分布的 $\\mathcal{N}(0,1)$。\n这个陈述声称 $|Z_2|$ 在随机意义上倾向于大于 $|Z_1|$。\n$|Z_1| = R |\\cos\\Theta|$\n$|Z_2| = R |\\sin\\Theta|$\n由于 $\\Theta$ 在 $[0, 2\\pi)$ 上均匀分布，随机变量 $|\\cos\\Theta|$ 和 $|\\sin\\Theta|$ 具有完全相同的分布（因为 $\\sin(\\theta) = \\cos(\\theta - \\pi/2)$，并且分布对于 $\\pi/2$ 的移位是不变的）。\n由于 $R$ 与 $\\Theta$ 无关，并且 $|\\cos\\Theta|$ 和 $|\\sin\\Theta|$ 具有相同的分布，所以 $R|\\cos\\Theta|$ 和 $R|\\sin\\Theta|$ 也必须具有相同的分布。\n因此，$|Z_1|$ 和 $|Z_2|$ 的分布是相同的。没有理由说一个会系统性地大于另一个。该陈述是基于一个错误的直觉，是错误的。\n\n结论：**不正确**。\n\n### 最终选择\n\n正确的陈述是 A、B、D 和 E。\n因此，答案是 `$$\\boxed{ABDE}$$`。", "answer": "$$\\boxed{ABDE}$$", "id": "3323992"}]}