{"hands_on_practices": [{"introduction": "在实施任何模拟算法之前，理解其计算成本至关重要。本实践问题 [@problem_id:3351329] 将引导您分析复合方法的效率。通过推导生成单个混合分布样本所需的随机数的期望值，您将深入了解各个组分的采样复杂度及其相应权重如何共同影响采样器的整体性能。", "problem": "考虑一个具有 $k$ 个组分的混合分布，其概率密度函数定义为 $f(x) = \\sum_{i=1}^{k} \\alpha_{i} f_{i}(x)$，其中对所有 $i$ 都有 $\\alpha_{i}  0$ 且 $\\sum_{i=1}^{k} \\alpha_{i} = 1$。现在要使用复合方法从 $f(x)$ 中生成一个随机变量。在该方法中，首先根据概率为 $(\\alpha_{1}, \\dots, \\alpha_{k})$ 的分类分布对离散组分索引 $J \\in \\{1, 2, \\dots, k\\}$进行采样，然后从密度为 $f_{J}(x)$ 的条件分布中生成一个抽样 $X$。假设组分索引 $J$ 是通过对分类分布应用逆变换法生成的，该过程消耗一次来自 $\\text{Uniform}(0,1)$ 分布的抽样。对于每个组分 $i$，用 $N_{i}$ 表示生成 $X \\sim f_{i}(x)$ 的采样器所消耗的 $\\text{Uniform}(0,1)$ 抽样的随机数量，并假设其期望值 $\\mathbb{E}[N_{i}] = c_{i}$ 对所有 $i=1,\\dots,k$ 都是有限且已知的。\n\n从混合分布的定义和全期望定律出发，推导复合方法单次迭代所消耗的 $\\text{Uniform}(0,1)$ 随机抽样总数的期望值的解析表达式。最终答案需用 $k$、$\\alpha_{i}$ 和 $c_{i}$（对于 $i=1,\\dots,k$）表示。最终答案必须是单个闭式表达式，无需进行数值计算。", "solution": "问题陈述已经过验证，被认为是有效的。它具有科学依据、是适定的、客观的，并包含所有必要信息，可以根据概率论和随机模拟的既定原理推导出唯一解。\n\n目标是求出使用复合方法从混合分布中生成单个随机变量所需的 $\\text{Uniform}(0,1)$ 随机抽样的期望总数。设 $N_{total}$ 为代表该抽样总数的随机变量。\n\n复合方法包括两个相继的步骤：\n1.  从集合 $\\{1, 2, \\dots, k\\}$ 上的离散分类分布中采样一个组分索引 $J$，其中选择索引 $i$ 的概率为 $P(J=i) = \\alpha_i$。\n2.  从与所选索引 $J$ 对应的概率密度函数 $f_J(x)$ 中生成一个随机变量 $X$。\n\n设 $N_{index}$ 为第一步（采样索引 $J$）中消耗的 $\\text{Uniform}(0,1)$ 抽样数量，设 $N_{sample}$ 为第二步（采样随机变量 $X$）中消耗的 $\\text{Uniform}(0,1)$ 抽样数量。抽样总数是这两个步骤中抽样数量的总和：\n$$N_{total} = N_{index} + N_{sample}$$\n根据期望的线性性质，期望抽样总数为：\n$$\\mathbb{E}[N_{total}] = \\mathbb{E}[N_{index} + N_{sample}] = \\mathbb{E}[N_{index}] + \\mathbb{E}[N_{sample}]$$\n我们现在计算右侧的每一项。\n\n首先，考虑 $\\mathbb{E}[N_{index}]$。问题陈述指出，组分索引 $J$ 是使用逆变换法生成的，该方法恰好消耗一次来自 $\\text{Uniform}(0,1)$ 分布的抽样。因此，在这种情况下，$N_{index}$ 不是一个随机变量，而是一个常数值 $1$。其期望为：\n$$\\mathbb{E}[N_{index}] = 1$$\n\n接下来，我们计算 $\\mathbb{E}[N_{sample}]$。生成随机变量 $X$ 所需的抽样数量 $N_{sample}$ 取决于第一步中选择了哪个组分索引 $J$。为了求 $N_{sample}$ 的期望，我们必须应用全期望定律，也称为迭代期望定律。该定律指出，对于两个随机变量 $A$ 和 $B$，$\\mathbb{E}[A] = \\mathbb{E}[\\mathbb{E}[A|B]]$。将此应用于我们的问题，我们以随机变量 $J$ 为条件：\n$$\\mathbb{E}[N_{sample}] = \\mathbb{E}[\\mathbb{E}[N_{sample} | J]]$$\n内部项 $\\mathbb{E}[N_{sample} | J=i]$ 表示在已选择组分 $i$ 的条件下，生成一个随机变量所需的期望抽样数量。问题将 $N_i$ 定义为生成 $X \\sim f_i(x)$ 的采样器所消耗的 $\\text{Uniform}(0,1)$ 抽样的随机数量，并给出其期望为 $\\mathbb{E}[N_i] = c_i$。因此，条件期望为：\n$$\\mathbb{E}[N_{sample} | J=i] = \\mathbb{E}[N_i] = c_i$$\n外部期望是针对离散随机变量 $J$ 的分布来计算的。$J$ 的概率质量函数由 $P(J=i) = \\alpha_i$ 给出，其中 $i \\in \\{1, 2, \\dots, k\\}$。因此，函数 $g(J) = \\mathbb{E}[N_{sample} | J]$ 的期望为：\n$$\\mathbb{E}[\\mathbb{E}[N_{sample} | J]] = \\sum_{i=1}^{k} \\mathbb{E}[N_{sample} | J=i] \\cdot P(J=i)$$\n代入条件期望和概率的表达式，我们得到：\n$$\\mathbb{E}[N_{sample}] = \\sum_{i=1}^{k} c_i \\alpha_i$$\n最后，我们将这两个阶段的期望相结合，以求出期望抽样总数：\n$$\\mathbb{E}[N_{total}] = \\mathbb{E}[N_{index}] + \\mathbb{E}[N_{sample}] = 1 + \\sum_{i=1}^{k} \\alpha_i c_i$$\n这就是复合方法单次迭代所消耗的 $\\text{Uniform}(0,1)$ 随机抽样总数的期望值的最终解析表达式。", "answer": "$$\\boxed{1 + \\sum_{i=1}^{k} \\alpha_{i} c_{i}}$$", "id": "3351329"}, {"introduction": "理论算法在有限精度算术中常会遇到实际挑战。本练习 [@problem_id:3351355] 直面一个关键问题：当从具有极端参数的混合分布中采样时，如何保持数值稳定性——这在罕见事件模拟等应用中很常见。通过评估不同的实现策略，您将学会编写能够避免下溢和精度损失的稳健代码，确保采样器在严苛条件下依然正确。", "problem": "您的任务是实现复合方法，在蒙特卡洛模拟（定义为通过重复随机抽样来获得数值结果）中从一个截断混合分布中抽取样本。考虑一个双组分指数分布混合，其密度为\n$$\nf(x) \\,=\\, \\pi_1 \\,\\lambda_1 \\,e^{-\\lambda_1 x} \\;+\\; \\pi_2 \\,\\lambda_2 \\,e^{-\\lambda_2 x}, \\quad x \\ge 0,\n$$\n其中 $0  \\pi_1  1$，$\\pi_2 = 1-\\pi_1$，且率满足 $\\lambda_1 \\ll \\lambda_2$。您需要使用复合方法，对于一个大的阈值 $t0$，从给定 $Xt$ 的 $X$ 的条件（截断）分布中抽样：首先根据给定截断的条件混合概率选择一个组分索引，然后从相应的截断组分分布中抽样。\n\n在有限精度算法中，当 $\\lambda_1 \\ll \\lambda_2$ 且 $t$ 很大时，直接的实现可能会在组分选择步骤和随后的截断组分抽样中遭遇严重的下溢或有效位损失。当 $\\lambda_1 \\ll \\lambda_2$ 且 $t$ 很大时，在浮点运算中，以下哪种实现选择是数值稳定且无偏的？选择所有适用项。\n\nA. 在浮点运算中计算截断后组分权重 $w_k=\\pi_k \\, e^{-\\lambda_k t}$，通过除以 $w_1+w_2$ 进行归一化，抽取一个均匀分布 $U \\sim \\text{Unif}(0,1)$ 以使用这些归一化权重选择组分，然后通过抽取 $U' \\sim \\text{Unif}(0,1)$ 并设置 $X=t - \\frac{1}{\\lambda_K}\\log U'$ 来从截断指数分布中抽样。这种直接实现是数值稳定且无偏的。\n\nB. 在对数域中进行组分选择：计算 $\\ell_k=\\log \\pi_k - \\lambda_k t$，并通过 $\\mathrm{Gumbel}$-max 方法抽样组分索引 $K$，即抽取 $G_k \\stackrel{\\mathrm{iid}}{\\sim} \\mathrm{Gumbel}(0,1)$ 并取 $K=\\operatorname{argmax}_{k\\in\\{1,2\\}} \\{\\ell_k+G_k\\}$。然后如选项 A 中所述从截断指数分布中抽样。这避免了选择步骤中的下溢并且是无偏的。\n\nC. 通过提出最小的率来重新缩放截断后权重：令 $\\lambda_\\star=\\min\\{\\lambda_1,\\lambda_2\\}$ 并计算未归一化权重 $w_k'=\\pi_k \\exp\\{-(\\lambda_k-\\lambda_\\star)t\\}$；归一化 $w_k'$ 以形成选择概率。然后如选项 A 中所述从截断指数分布中抽样。这种重新缩放可以防止选择步骤中的下溢并且是无偏的。\n\nD. 如果 $\\lambda_2 t$ 大到使得 $e^{-\\lambda_2 t}$ 在双精度浮点数下会下溢为 $0$，则将相应的权重设置为 $0$，重新归一化剩余的权重，然后继续。由此产生的偏差可以忽略不计。\n\nE. 在截断抽样步骤中，为了在 $t \\gg \\frac{1}{\\lambda_K}$ 时保留小的增量，计算增量为 $Y = -\\frac{1}{\\lambda_K}\\log\\!\\big(1-U\\big)$，但使用补偿函数 $\\log1p(-U)$ 来评估对数以避免相消误差，即设置 $Y = -\\frac{1}{\\lambda_K}\\,\\log1p(-U)$，其中 $U\\sim \\mathrm{Unif}(0,1)$。如果在 $t$ 附近需要高相对精度，则将样本作为两部分表示 $(t,Y)$ 返回，而不是返回四舍五入的浮点和 $t+Y$。这保持了分布规律并提高了数值鲁棒性。\n\n选择所有适用项。", "solution": "在尝试任何解决方案之前，对问题陈述的有效性进行严格评估。\n\n### 步骤1：提取给定条件\n- 双组分指数分布混合的概率密度函数为 $f(x) \\,=\\, \\pi_1 \\,\\lambda_1 \\,e^{-\\lambda_1 x} \\;+\\; \\pi_2 \\,\\lambda_2 \\,e^{-\\lambda_2 x}$，对于 $x \\ge 0$。\n- 混合概率满足 $0  \\pi_1  1$ 和 $\\pi_2 = 1-\\pi_1$。\n- 指数率满足 $\\lambda_1 \\ll \\lambda_2$。\n- 任务是从随机变量 $X$ 在事件 $X  t$（其中 $t  0$ 是一个大阈值）下的条件分布中生成样本。\n- 抽样过程是复合方法：\n    1. 基于给定 $Xt$ 的条件混合概率选择一个组分索引 $K$。\n    2. 从所选组分 $K$ 的截断分布中抽样。\n- 背景是有限精度浮点运算，其中下溢和有效位损失是潜在问题，尤其是在 $\\lambda_1 \\ll \\lambda_2$ 条件下对于大的 $t$。\n- 问题是确定所提供的实现选择中哪些是数值稳定且无偏的。\n\n### 步骤2：使用提取的给定条件进行验证\n该问题在科学上和数学上是合理的。它涉及计算统计学和蒙特卡洛方法中的一个标准主题：从截断混合分布中生成随机变量。所描述的数值挑战（下溢、有效位损失）是浮点运算中真实存在的问题，并且是数值分析领域的核心。设置是自洽的，提供了所有必要的定义。问题是良构的，要求根据稳定性和无偏性的标准评估特定的数值策略。术语是精确和客观的。该问题不违反任何无效性标准。\n\n### 步骤3：结论和行动\n问题陈述是**有效的**。将执行完整的解决方案和选项评估。\n\n### 基于原理的推导\n令 $X$ 是一个具有给定混合密度 $f(x)$ 的随机变量。生存函数是 $S(x) = P(Xx) = \\pi_1 P(X_1x) + \\pi_2 P(X_2x)$，其中 $X_k \\sim \\text{Exp}(\\lambda_k)$。指数分布的生存函数是 $S_k(x) = P(X_kx) = e^{-\\lambda_k x}$。因此，混合生存函数是 $S(t) = \\pi_1 e^{-\\lambda_1 t} + \\pi_2 e^{-\\lambda_2 t}$。\n\n从截断分布 $f(x|Xt)$ 抽样的复合方法需要两个步骤：\n\n1.  **组分选择**：选择一个组分索引 $K \\in \\{1, 2\\}$。选择组分 $k$ 的概率是样本源自组分 $k$ 的条件概率，前提是它大于 $t$。这由贝叶斯定理给出：\n    $$\n    \\pi'_k = P(K=k | Xt) = \\frac{P(Xt|K=k)P(K=k)}{P(Xt)} = \\frac{S_k(t) \\pi_k}{S(t)} = \\frac{\\pi_k e^{-\\lambda_k t}}{\\pi_1 e^{-\\lambda_1 t} + \\pi_2 e^{-\\lambda_2 t}}\n    $$\n    令 $w_k = \\pi_k e^{-\\lambda_k t}$ 为未归一化的后验权重。则 $\\pi'_k = w_k / (w_1 + w_2)$。给定 $\\lambda_1 \\ll \\lambda_2$ 和大的 $t$，项 $e^{-\\lambda_1 t}$ 远大于 $e^{-\\lambda_2 t}$。然而，对于足够大的 $t$，在浮点运算中 $e^{-\\lambda_1 t}$ 和 $e^{-\\lambda_2 t}$ 都可能下溢为 $0$，导致和 $w_1+w_2$ 变为 $0$，从而引发除零错误。这是一个主要的数值稳定性挑战。\n\n2.  **截断抽样**：选择一个组分 $K$ 后，我们必须从以 $X_K  t$ 为条件的 $X_K$ 分布中抽样。由于指数分布的无记忆性，如果 $X_K \\sim \\text{Exp}(\\lambda_K)$，则以 $X_K  t$ 为条件的 $X_K - t$ 的分布也是 $\\text{Exp}(\\lambda_K)$。因此，可以生成一个样本 $Y \\sim \\text{Exp}(\\lambda_K)$ 并将最终样本设置为 $X = t+Y$。生成 $Y$ 的标准方法是逆变换采样：$Y = -\\frac{1}{\\lambda_K} \\log(U)$，其中 $U \\sim \\text{Unif}(0,1)$。这里当 $t$ 很大而 $Y$ 很小时会出现数值稳定性挑战，因为和 $t+Y$ 可能会被舍入为 $t$，从而丢失增量 $Y$ 中的信息。\n\n### 逐项分析选项\n\n**A. 在浮点运算中计算截断后组分权重 $w_k=\\pi_k \\, e^{-\\lambda_k t}$，通过除以 $w_1+w_2$ 进行归一化，抽取一个均匀分布 $U \\sim \\text{Unif}(0,1)$ 以使用这些归一化权重选择组分，然后通过抽取 $U' \\sim \\text{Unif}(0,1)$ 并设置 $X=t - \\frac{1}{\\lambda_K}\\log U'$ 来从截断指数分布中抽样。这种直接实现是数值稳定且无偏的。**\n\n此选项描述了最直接、朴素的实现。正如在推导中确立的，计算 $w_k = \\pi_k e^{-\\lambda_k t}$ 容易发生下溢。如果 $\\lambda_1 t$ 足够大（例如，对于 IEEE 754 双精度，$\\lambda_1 t  709.8$），$e^{-\\lambda_1 t}$ 将计算为 $0$。由于 $\\lambda_2  \\lambda_1$，$e^{-\\lambda_2 t}$ 也将为 $0$。分母 $w_1+w_2$ 将变为 $0$，导致失败。因此，这种实现根本上不是数值稳定的。抽样公式 $X=t - \\frac{1}{\\lambda_K}\\log U'$ 在数学上是正确的，因为对于 $U' \\sim \\text{Unif}(0,1)$，$1-U'$ 等价于一个新的均匀分布随机变量，而 $X = t - \\frac{1}{\\lambda_K} \\log(1-U')$ 是截断指数分布的正确逆变换抽样公式。\n结论：**不正确**。组分选择步骤不是数值稳定的。\n\n**B. 在对数域中进行组分选择：计算 $\\ell_k=\\log \\pi_k - \\lambda_k t$，并通过 $\\mathrm{Gumbel}$-max 方法抽样组分索引 $K$，即抽取 $G_k \\stackrel{\\mathrm{iid}}{\\sim} \\mathrm{Gumbel}(0,1)$ 并取 $K=\\operatorname{argmax}_{k\\in\\{1,2\\}} \\{\\ell_k+G_k\\}$。然后如选项 A 中所述从截断指数分布中抽样。这避免了选择步骤中的下溢并且是无偏的。**\n\n此选项为组分选择步骤提出了一种精巧且稳定的方法。选择概率为 $\\pi'_k \\propto \\exp(\\log \\pi_k - \\lambda_k t) = \\exp(\\ell_k)$。对于给定的对数权重 $\\ell_k$，Gumbel-max 技巧是一种标准且完全正确（无偏）的方法，用于从概率与 $\\exp(\\ell_k)$ 成正比的分类分布中抽样。通过在对数域中工作，此方法避免了直接计算小的指数项，从而防止了困扰选项 A 中朴素方法的下溢问题。$\\ell_k$ 的值是大的负数，在浮点系统中可以很好地表示。因此，此方法对于选择步骤是数值稳定且无偏的。\n结论：**正确**。\n\n**C. 通过提出最小的率来重新缩放截断后权重：令 $\\lambda_\\star=\\min\\{\\lambda_1,\\lambda_2\\}$ 并计算未归一化权重 $w_k'=\\pi_k \\exp\\{-(\\lambda_k-\\lambda_\\star)t\\}$；归一化 $w_k'$ 以形成选择概率。然后如选项 A 中所述从截断指数分布中抽样。这种重新缩放可以防止选择步骤中的下溢并且是无偏的。**\n\n此选项提出了权重的重新缩放。新权重 $w'_k$ 与原始权重 $w_k$ 的关系为 $w'_k = w_k \\cdot e^{\\lambda_\\star t}$。由于我们通过总和进行归一化，这个公共因子 $e^{\\lambda_\\star t}$ 会被抵消，意味着最终的概率与 $\\pi'_k$ 相同。因此该方法是无偏的。\n在数值上，由于 $\\lambda_1 \\ll \\lambda_2$，我们有 $\\lambda_\\star=\\lambda_1$。新权重为 $w'_1 = \\pi_1 \\exp\\{-(\\lambda_1-\\lambda_1)t\\} = \\pi_1$ 和 $w'_2 = \\pi_2 \\exp\\{-(\\lambda_2-\\lambda_1)t\\}$。主导组分的项变成了一个稳定的常数。组分 2 的指数项如果 $(\\lambda_2-\\lambda_1)t$ 很大，仍然可能下溢为 $0$，但这并非灾难性失败；它正确地反映了选择组分 2 的概率可以忽略不计。这是“log-sum-exp”技巧的一个版本，通过提出最大项在线性域中实现。该方法是数值稳定且无偏的。\n结论：**正确**。\n\n**D. 如果 $\\lambda_2 t$ 大到使得 $e^{-\\lambda_2 t}$ 在双精度浮点数下会下溢为 $0$，则将相应的权重设置为 $0$，重新归一化剩余的权重，然后继续。由此产生的偏差可以忽略不计。**\n\n此选项描述了一种实用但最终有偏的近似方法。“由此产生的偏差可以忽略不计”的说法承认了实际上存在偏差。一个方法是无偏的，如果其期望值完全等于目标量。通过故意将一个非零（尽管极小）的权重设置为零，抽样分布被改变了，该方法变得有偏。严谨的分析必须区分数学上精确的算法（如 B 和 C）和明确是近似的算法（如 D）。虽然偏差确实极小，在大多数实际应用中无关紧要，但该过程并非问题所要求的严格“无偏”。此外，这个规定是不完整的；它没有说明如果*所有*组分的权重都下溢该怎么办，而方法 B 和 C 可以优雅地处理这种情况。\n结论：**不正确**。该方法是明确有偏的，尽管偏差可能很小。\n\n**E. 在截断抽样步骤中，为了在 $t \\gg \\frac{1}{\\lambda_K}$ 时保留小的增量，计算增量为 $Y = -\\frac{1}{\\lambda_K}\\log\\!\\big(1-U\\big)$，但使用补偿函数 $\\log1p(-U)$ 来评估对数以避免相消误差，即设置 $Y = -\\frac{1}{\\lambda_K}\\,\\log1p(-U)$，其中 $U\\sim \\mathrm{Unif}(0,1)$。如果在 $t$ 附近需要高相对精度，则将样本作为两部分表示 $(t,Y)$ 返回，而不是返回四舍五入的浮点和 $t+Y$。这保持了分布规律并提高了数值鲁棒性。**\n\n此选项解决了复合方法第二步中的数值问题：生成样本 $X = t+Y$。\n首先，它建议通过公式 $Y = -\\frac{1}{\\lambda_K} \\log(1-U)$ 生成指数增量 $Y$。这在数学上等同于标准的 $Y = -\\frac{1}{\\lambda_K} \\log(U)$，因为 $U$ 和 $1-U$ 是同分布的。要生成一个小的增量 $Y$，需要 $1-U$ 接近 $1$，意味着 $U$ 必须接近 $0$。该选项正确地建议通过函数 `log1p(-U)` 计算 $\\log(1-U)$。`log1p(x)` 函数能为小的 $|x|$ 精确计算 $\\log(1+x)$，因此 `log1p(-U)` 能为小的 $U$ 精确计算 $\\log(1-U)$。这是一种数值鲁棒的技术。\n其次，它正确地指出，对于大的 $t$，浮点加法 $t+Y$ 可能会遭受“淹没”效应，其中小的增量 $Y$ 因舍入而丢失。提议将结果作为未求值的和 $(t,Y)$ 返回是一种保存完整精度的标准有效技术。此选项描述了两个有效且鲁棒的数值改进，它们“保持了分布规律”（即，是无偏的）并增强了稳定性。\n结论：**正确**。", "answer": "$$\\boxed{BCE}$$", "id": "3351355"}, {"introduction": "任何实现的优劣取决于其验证过程。这最后一个实践 [@problem_id:3351387] 提供了使用统计检验来验证复合采样器的综合指南，这是可靠科学计算的基石。您将设计并实施一套测试，包括拟合优度检验和柯尔莫洛哥夫-斯米尔诺夫检验，以严格确认您的代码能从目标分布中生成样本，从而建立对模拟结果的信心。", "problem": "您的任务是设计并编码一个单元测试策略，用于通过对模拟数据进行统计检验来验证混合分布的复合采样器。用于生成随机变量的复合方法通过首先根据权重为 $\\{w_i\\}_{i=1}^k$ 的分类分布（其中 $\\sum_{i=1}^k w_i = 1$ 且 $w_i \\ge 0$）选择一个离散分量索引 $I$ 来构造随机变量 $X$，然后从概率密度函数为 $f_i(x)$、累积分布函数为 $F_i(x)$ 的分量分布中抽取 $X \\mid (I=i)$。最终得到的混合分布的密度为 $f(x) = \\sum_{i=1}^k w_i f_i(x)$，累积分布函数为 $F(x) = \\sum_{i=1}^k w_i F_i(x)$。\n\n从分类分布、独立试验的多项式计数以及累积分布函数属性的基本定义出发，您必须实现单元测试来验证复合方法的两个部分：\n- 分量选择机制，其在大量样本上的选择频率应与指定的权重相匹配。\n- 给定选定分量后的条件抽取，其应与指定的分量分布相匹配。\n\n此外，还需根据其理论累积分布函数验证整体混合分布。\n\n您的程序必须实现以下统计检验，以提供客观的接受标准：\n1. 针对分量选择计数的卡方拟合优度检验。设 $N$ 为模拟样本总数，设 $C_i$ 为分量 $i$ 被选择的观测计数，设 $E_i = N w_i$ 为期望计数。对于所有 $E_i  0$ 的索引，计算卡方检验统计量 $\\chi^2 = \\sum_{i: E_i0} \\frac{(C_i - E_i)^2}{E_i}$ 以及相对于自由度为 $k' - 1$ 的卡方分布的相应 $p$ 值，其中 $k'$ 是 $E_i0$ 的索引数量。如果 $p$ 值超过显著性水平 $\\alpha$，则接受该选择机制。\n2. 针对条件分布的单样本柯尔莫哥洛夫-斯米尔诺夫检验。对于每个 $w_i  0$ 的分量 $i$，令 $\\{X_j : I_j=i\\}$ 为其子样本，并使用柯尔莫哥洛夫-斯米尔诺夫统计量 $D_i = \\sup_x \\left| \\hat{F}_i(x) - F_i(x) \\right|$ 检验该子样本是否遵循 $F_i(x)$，其中 $\\hat{F}_i$ 是子样本的经验累积分布函数。如果其 $p$ 值超过 $\\alpha$，则接受每个条件分布；如果所有 $w_i  0$ 的分量都被接受，则接受该测试用例的整个条件分布套件。\n3. 针对完整混合累积分布 $F(x) = \\sum_{i=1}^k w_i F_i(x)$ 的单样本柯尔莫哥洛夫-斯米尔诺夫检验。如果 $p$ 值超过 $\\alpha$，则接受。\n4. 零权重约束检查。对于任何权重为 $w_i = 0$ 的分量，断言 $C_i = 0$ 必须精确成立。如果所有此类分量都满足此条件，则接受。\n\n您必须实现一个可重用的复合采样器，支持以下分量族：\n- 正态（高斯）分布：$X \\sim \\mathcal{N}(\\mu, \\sigma^2)$，参数为 $\\mu$ 和 $\\sigma$。\n- 指数分布：$X \\sim \\text{Exponential}(\\lambda)$，率参数为 $\\lambda$，其中当 $x \\ge 0$ 时 $F(x) = 1 - e^{-\\lambda x}$，当 $x  0$ 时 $F(x) = 0$。\n\n使用固定的随机种子以确保可复现性，并对所有检验使用单一的显著性水平 $\\alpha = 10^{-6}$。\n\n实现以下参数集测试套件。对于每个测试用例，模拟 $N$ 个样本并执行上述四项验证：\n\n- 测试用例 A（正态混合，双分量）：\n  - $k = 2$。\n  - 权重：$w = [0.3, 0.7]$。\n  - 分量：$\\mathcal{N}(\\mu_1=0, \\sigma_1=1)$ 和 $\\mathcal{N}(\\mu_2=3, \\sigma_2=0.5)$。\n  - 样本量：$N = 100000$。\n\n- 测试用例 B（指数混合，三分量）：\n  - $k = 3$。\n  - 权重：$w = [0.2, 0.5, 0.3]$。\n  - 分量：$\\text{Exponential}(\\lambda_1=1.0)$、$\\text{Exponential}(\\lambda_2=2.0)$ 和 $\\text{Exponential}(\\lambda_3=0.5)$。\n  - 样本量：$N = 100000$。\n\n- 测试用例 C（正态混合，权重接近零的分量）：\n  - $k = 2$。\n  - 权重：$w = [0.999, 0.001]$。\n  - 分量：$\\mathcal{N}(\\mu_1=-2, \\sigma_1=0.8)$ 和 $\\mathcal{N}(\\mu_2=10, \\sigma_2=1.2)$。\n  - 样本量：$N = 200000$。\n\n- 测试用例 D（正态混合，零权重分量）：\n  - $k = 2$。\n  - 权重：$w = [1.0, 0.0]$。\n  - 分量：$\\mathcal{N}(\\mu_1=0, \\sigma_1=1)$ 和 $\\mathcal{N}(\\mu_2=5, \\sigma_2=1)$。\n  - 样本量：$N = 100000$。\n\n您的程序必须生成单行输出，包含四个测试用例中每项验证的布尔通过/失败聚合结果，顺序为 A, B, C, D。对于每个测试用例，按以下顺序输出四个布尔值：选择频率检验、条件分布检验、混合分布检验、零权重约束检查。将所有测试用例的这些结果聚合到一个由方括号括起来的逗号分隔列表中。例如，输出格式必须严格为：\n\"[$b_{A,1},$ $b_{A,2},$ $b_{A,3},$ $b_{A,4},$ $b_{B,1},$ $b_{B,2},$ $b_{B,3},$ $b_{B,4},$ $b_{C,1},$ $b_{C,2},$ $b_{C,3},$ $b_{C,4},$ $b_{D,1},$ $b_{D,2},$ $b_{D,3},$ $b_{D,4}]$\"，其中每个 $b_{\\cdot,\\cdot}$ 是布尔值 True 或 False。", "solution": "该练习要求为复合采样器设计并实现一个全面的单元测试框架，复合采样器是随机模拟中的一个基本算法。任何模拟研究的科学有效性都取决于其随机数生成的正确性，而本题使用既定的统计假设检验来规范化这一验证过程。解决方案围绕两个主要部分构建：首先，是对复合采样器本身的稳健实现；其次，是一套包含四个不同验证程序的测试套件，用于测试采样器输出的不同方面。\n\n如果一个随机变量 $X$ 的概率密度函数 (PDF) $f(x)$ 是其他密度函数 $f_i(x)$ 的加权和，则称其遵循混合分布：\n$$f(x) = \\sum_{i=1}^{k} w_i f_i(x)$$\n其中 $k$ 是分量数量，$\\{w_i\\}_{i=1}^k$ 是总和为 1 的非负权重（$\\sum w_i = 1, w_i \\ge 0$），每个 $f_i(x)$ 是一个分量 PDF。累积分布函数 (CDF) 同样是加权和：\n$$F(x) = \\sum_{i=1}^{k} w_i F_i(x)$$\n复合方法通过两个阶段从此分布中生成一个随机变量：\n1.  从概率为 $P(I=i) = w_i$ 的分类分布中抽取一个分量索引 $I$。\n2.  从所选分量分布（其 CDF 为 $F_I(x)$）中抽取一个随机变量 $X$。\n\n我们的实现将此逻辑封装在一个可重用的采样器中。为生成大小为 $N$ 的数据集，我们首先使用指定的权重 $w_i$ 生成 $N$ 个独立的索引 $I$ 抽样。这可以通过 `numpy.random.choice` 高效完成。然后，对于每个分量索引 $i \\in \\{1, \\dots, k\\}$，我们识别出试验中 $I=i$ 的子集，并使用 `numpy.random` 中用于正态和指数分布族的函数，从相应的分布 $f_i(x)$ 生成所需数量的随机变量。参数化必须小心处理：对于率参数为 $\\lambda$ 的指数分布，`numpy` 和 `scipy` 中的 `scale` 参数均为 $1/\\lambda$。\n\n对该采样器的验证是多方面的，涉及生成数据的四个不同属性。采用固定的随机种子来确保整个过程是确定性和可复现的。所有假设检验均使用 $\\alpha = 10^{-6}$ 的严格显著性水平，以最小化犯 I 类错误（即错误地拒绝一个正确的采样器）的概率。\n\n1.  **分量选择频率（卡方检验）**：第一个检验验证分量选择机制。在大量试验 $N$ 中，每个分量 $i$ 的观测计数 $C_i$ 应接近其期望计数 $E_i = N w_i$。这是一个拟合优度问题，适用皮尔逊卡方检验。检验统计量计算如下：\n    $$\\chi^2 = \\sum_{i: E_i > 0} \\frac{(C_i - E_i)^2}{E_i}$$\n    该统计量与自由度为 $k' - 1$ 的卡方分布进行比较，其中 $k'$ 是期望计数非零（$E_i > 0$）的分量数量。原假设（即观测计数遵循期望分布）在所得 $p$ 值大于 $\\alpha$ 时被接受。使用 `scipy.stats.chi2.sf` 函数计算此 $p$ 值。\n\n2.  **条件分布（柯尔莫哥洛夫-斯米尔诺夫检验）**：第二个检验验证每个分量的随机变量是否从正确的条件分布中抽取。对于每个 $w_i  0$ 的分量 $i$，我们分离出随机变量的子样本 $\\{X_j \\mid I_j=i\\}$，并执行单样本柯尔莫哥洛夫-斯米尔诺夫（KS）检验。KS 检验将该子样本的经验 CDF $\\hat{F}_i(x)$ 与理论分量 CDF $F_i(x)$ 进行比较。检验统计量 $D_i = \\sup_x |\\hat{F}_i(x) - F_i(x)|$ 产生一个 $p$ 值。原假设是子样本从 $F_i(x)$ 中抽取。只有当*每个* $w_i  0$ 的分量的 $p$ 值都超过 $\\alpha$ 时，整个条件分布套件才被视为正确实现。这通过 `scipy.stats.kstest` 实现，并为其提供适当的理论 CDF 可调用对象。\n\n3.  **整体混合分布（柯尔莫哥洛夫-斯米尔诺夫检验）**：第三个检验验证采样器的最终聚合输出。对 $N$ 个随机变量的整个样本与理论混合 CDF $F(x) = \\sum_{i=1}^k w_i F_i(x)$ 进行检验。执行单个单样本 KS 检验。构造一个代表 $F(x)$ 的可调用函数，该函数计算分量 CDF 的加权和。如果从 `scipy.stats.kstest` 得到的 $p$ 值大于 $\\alpha$，则接受原假设（即生成的样本遵循目标混合分布）。\n\n4.  **零权重约束**：最后的验证是一个确定性检查，而不是统计检验。对于任何指定权重为 $w_i = 0$ 的分量 $i$，逻辑上它必须永远不被选中。因此，其观测计数 $C_i$ 必须精确为 $0$。如果所有权重为零的分量都满足此条件，则测试通过。如果没有分量的权重为零，则该测试不证自明地通过。\n\n程序系统地将这四个测试应用于每个指定的测试用例（A、B、C、D），这些测试用例旨在探究采样器行为的不同方面，包括平衡和倾斜的权重、不同的分布族以及关键的零权重情景。四个测试用例中，每个用例的四项测试的布尔结果（通过/失败）被聚合到一个最终列表中。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2, norm, expon, kstest\n\ndef solve():\n    \"\"\"\n    Implements and validates a composition sampler for mixture distributions.\n    \"\"\"\n    \n    # Global parameters for the test suite\n    SEED = 42\n    ALPHA = 1e-6\n    rng = np.random.default_rng(SEED)\n\n    # Test case definitions\n    test_cases = [\n        {\n            \"name\": \"A\",\n            \"N\": 100000,\n            \"weights\": np.array([0.3, 0.7]),\n            \"components\": [\n                {\"dist\": \"norm\", \"params\": {\"loc\": 0.0, \"scale\": 1.0}},\n                {\"dist\": \"norm\", \"params\": {\"loc\": 3.0, \"scale\": 0.5}},\n            ]\n        },\n        {\n            \"name\": \"B\",\n            \"N\": 100000,\n            \"weights\": np.array([0.2, 0.5, 0.3]),\n            \"components\": [\n                {\"dist\": \"expon\", \"params\": {\"rate\": 1.0}},\n                {\"dist\": \"expon\", \"params\": {\"rate\": 2.0}},\n                {\"dist\": \"expon\", \"params\": {\"rate\": 0.5}},\n            ]\n        },\n        {\n            \"name\": \"C\",\n            \"N\": 200000,\n            \"weights\": np.array([0.999, 0.001]),\n            \"components\": [\n                {\"dist\": \"norm\", \"params\": {\"loc\": -2.0, \"scale\": 0.8}},\n                {\"dist\": \"norm\", \"params\": {\"loc\": 10.0, \"scale\": 1.2}},\n            ]\n        },\n        {\n            \"name\": \"D\",\n            \"N\": 100000,\n            \"weights\": np.array([1.0, 0.0]),\n            \"components\": [\n                {\"dist\": \"norm\", \"params\": {\"loc\": 0.0, \"scale\": 1.0}},\n                {\"dist\": \"norm\", \"params\": {\"loc\": 5.0, \"scale\": 1.0}},\n            ]\n        },\n    ]\n\n    def composition_sampler(n_samples, weights, components, specific_rng):\n        \"\"\"\n        Generates samples from a mixture distribution using the composition method.\n        \"\"\"\n        k = len(weights)\n        indices = specific_rng.choice(np.arange(k), size=n_samples, p=weights)\n        samples = np.zeros(n_samples, dtype=float)\n\n        for i in range(k):\n            mask = (indices == i)\n            count = np.sum(mask)\n            if count > 0:\n                comp_def = components[i]\n                if comp_def[\"dist\"] == \"norm\":\n                    samples[mask] = specific_rng.normal(size=count, **comp_def[\"params\"])\n                elif comp_def[\"dist\"] == \"expon\":\n                    rate = comp_def[\"params\"][\"rate\"]\n                    samples[mask] = specific_rng.exponential(size=count, scale=1.0 / rate)\n        return samples, indices\n\n    all_results = []\n    for case in test_cases:\n        N = case[\"N\"]\n        weights = case[\"weights\"]\n        components = case[\"components\"]\n        k = len(weights)\n\n        samples, indices = composition_sampler(N, weights, components, rng)\n        observed_counts = np.bincount(indices, minlength=k)\n        \n        # Test 1: Chi-square test for component selection frequency\n        expected_counts = N * weights\n        positive_mask = expected_counts > 0\n        chisq_passed = True\n        if np.any(positive_mask):\n            df = int(np.sum(positive_mask)) - 1\n            if df > 0:\n                chisq_stat = np.sum(\n                    (observed_counts[positive_mask] - expected_counts[positive_mask])**2\n                    / expected_counts[positive_mask]\n                )\n                p_val_chisq = chi2.sf(chisq_stat, df)\n                chisq_passed = p_val_chisq > ALPHA\n\n        # Test 2: KS tests for conditional distributions\n        cond_ks_passed = True\n        for i in range(k):\n            if weights[i] > 0:\n                sub_samples = samples[indices == i]\n                if len(sub_samples) > 0:\n                    comp_def = components[i]\n                    if comp_def[\"dist\"] == \"norm\":\n                        scipy_cdf = lambda x, mu=comp_def[\"params\"][\"loc\"], s=comp_def[\"params\"][\"scale\"]: norm.cdf(x, loc=mu, scale=s)\n                    elif comp_def[\"dist\"] == \"expon\":\n                        rate = comp_def[\"params\"][\"rate\"]\n                        scipy_cdf = lambda x, r=rate: expon.cdf(x, scale=1.0/r)\n                    \n                    _, p_val = kstest(sub_samples, scipy_cdf)\n                    if p_val = ALPHA:\n                        cond_ks_passed = False\n                        break\n        \n        # Test 3: KS test for the full mixture distribution\n        def mixture_cdf(x):\n            total_cdf = np.zeros_like(np.asarray(x), dtype=float)\n            for i in range(k):\n                if weights[i] > 0:\n                    comp_def = components[i]\n                    if comp_def[\"dist\"] == \"norm\":\n                        total_cdf += weights[i] * norm.cdf(x, **comp_def[\"params\"])\n                    elif comp_def[\"dist\"] == \"expon\":\n                        rate = comp_def[\"params\"][\"rate\"]\n                        total_cdf += weights[i] * expon.cdf(x, scale=1.0/rate)\n            return total_cdf\n        \n        _, p_val_mix = kstest(samples, mixture_cdf)\n        mix_ks_passed = p_val_mix > ALPHA\n\n        # Test 4: Zero-weight constraint check\n        zero_weight_passed = True\n        zero_weight_indices = np.where(weights == 0)[0]\n        if len(zero_weight_indices) > 0:\n            if np.any(observed_counts[zero_weight_indices] != 0):\n                zero_weight_passed = False\n\n        all_results.extend([chisq_passed, cond_ks_passed, mix_ks_passed, zero_weight_passed])\n    \n    # Final print statement in the exact required format\n    print(f\"[{','.join(str(r) for r in all_results)}]\")\n\nsolve()\n```", "id": "3351387"}]}