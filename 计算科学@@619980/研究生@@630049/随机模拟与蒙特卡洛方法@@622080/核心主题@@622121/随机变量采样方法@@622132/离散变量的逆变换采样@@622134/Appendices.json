{"hands_on_practices": [{"introduction": "为了将理论付诸实践，让我们从一个基本练习开始。这个练习将手动引导我们完成离散变量逆变换采样的核心步骤，通过为一个给定的简单概率分布计算累积概率，并确定一个均匀随机数如何映射到一个具体的离san结果，我们能为后续更复杂的应用打下坚实的直观基础。[@problem_id:3314769]", "problem": "考虑一个离散随机变量 $X$，其支撑集为有序集合 $\\{x_{1}, x_{2}, x_{3}, x_{4}\\}$，概率向量为 $p=(0.05, 0.25, 0.4, 0.3)$，其中对于 $i\\in\\{1,2,3,4\\}$，$p_{i}=\\mathbb{P}(X=x_{i})$。从 $(0,1)$ 上的连续均匀分布中观测到一次抽样 $U$，其值为 $U=0.7$。仅使用离散变量的累积分布函数（CDF）的定义以及通过逆累积原理将均匀 $(0,1)$ 变量映射到结果的第一性原理构造方法，完成以下操作：为 $k\\in\\{1,2,3,4\\}$ 构建累积数组 $c_{k}=\\sum_{i=1}^{k}p_{i}$，通过逆变换采样法从这个 $U$ 中确定所选的样本索引 $k$，并识别相应的结果 $x_{k}$。明确阐述根据您使用的定义，如何处理 $U$ 与 CDF 的跳跃点重合的边界情况。仅报告采样索引 $k$作为您的最终答案。无需四舍五入。", "solution": "这个问题是有效的，因为它科学地基于随机模拟的原理，问题设定完整且一致，表述清晰，并且使用了客观、正式的语言。提供的概率向量 $p=(0.05, 0.25, 0.4, 0.3)$ 是有效的，因为其元素均为非负数且总和为 1：$0.05 + 0.25 + 0.4 + 0.3 = 1$。该问题要求直接应用离散随机变量的逆变换采样法，这是蒙特卡洛方法中的一项基本技术。\n\n设 $X$ 是一个离散随机变量，其支撑集为 $\\{x_{1}, x_{2}, x_{3}, x_{4}\\}$，概率质量函数（PMF）由 $\\mathbb{P}(X=x_i) = p_i$ 给出。给定的概率向量为 $p = (p_1, p_2, p_3, p_4) = (0.05, 0.25, 0.4, 0.3)$。\n\n逆变换采样法依赖于 $X$ 的累积分布函数（CDF）。对于离散变量，CDF, $F_X(x) = \\mathbb{P}(X \\le x)$, 是一个阶梯函数。CDF在支撑点 $x_k$ 处的值由累积概率 $c_k$ 给出：\n$$c_k = F_X(x_k) = \\sum_{i=1}^{k} p_i$$\n按照惯例，我们定义 $c_0 = 0$。\n\n首先，我们使用给定的概率构建累积数组 $c = (c_1, c_2, c_3, c_4)$：\n- $c_1 = p_1 = 0.05$\n- $c_2 = p_1 + p_2 = 0.05 + 0.25 = 0.30$\n- $c_3 = c_2 + p_3 = 0.30 + 0.40 = 0.70$\n- $c_4 = c_3 + p_4 = 0.70 + 0.30 = 1.00$\n因此，累积数组为 $(0.05, 0.30, 0.70, 1.00)$。\n\n逆变换采样的原理是从标准均匀分布 $\\mathcal{U}(0,1)$ 中生成一个随机变量 $U$，然后找到满足条件\n$$c_{k-1}  U \\le c_k$$\n的唯一索引 $k$ 对应的结果 $x_k$。\n这个条件将区间 $(0,1)$ 划分成不相交的子区间 $(c_{k-1}, c_k]$，每个子区间的长度为 $c_k - c_{k-1} = p_k$。$U$ 落入特定区间 $(c_{k-1}, c_k]$ 的概率恰好是 $p_k$，从而确保采样的结果 $x_k$ 是以正确的概率被选择的。一个等效且通常更实用的表述规则的方式是，找到满足 $U \\le c_k$ 的最小索引 $k$。\n\n问题明確要求说明如何处理边界情况。给定的抽样值为 $U=0.7$。这个值恰好与累积概率 $c_3$ 相等。不等式 $c_{k-1}  U \\le c_k$ 的选择至关重要。半开区间 $(c_{k-1}, c_k]$ 包含其右端点。因此，如果 $U$ 等于某个 $c_k$，它就落入索引为 $k$ 的区间内。\n\n这个约定是广义逆CDF（或分位数函数）定义的直接结果，对于一个分布函数 $F$，其定义为 $F^{-1}(u) = \\inf\\{x : F(x) \\ge u\\}$。在我们的离散情况下，样本是 $x_k$，其中 $k$ 是满足 $c_k \\ge U$ 的最小整数。\n\n将此规则应用于给定的均匀变量 $U=0.7$：\n我们寻找满足 $c_k \\ge 0.7$ 的最小整数 $k \\in \\{1, 2, 3, 4\\}$。\n- 对于 $k=1$：$c_1 \\ge 0.7$ 吗？$0.05 \\ge 0.7$ 是假的。\n- 对于 $k=2$：$c_2 \\ge 0.7$ 吗？$0.30 \\ge 0.7$ 是假的。\n- 对于 $k=3$：$c_3 \\ge 0.7$ 吗？$0.70 \\ge 0.7$ 是真的。\n\n由于我们已经找到了满足条件的最小索引 $k$，搜索终止。采样得到的索引是 $k=3$。相应的结果将是 $x_3$。\n\n使用区间表示法进行验证：\n- 对于 $k=1$：$c_0  U \\le c_1 \\implies 0  0.7 \\le 0.05$。假的。\n- 对于 $k=2$：$c_1  U \\le c_2 \\implies 0.05  0.7 \\le 0.30$。假的。\n- 对于 $k=3$：$c_2  U \\le c_3 \\implies 0.30  0.7 \\le 0.70$。真的，因为 $U=0.7$ 满足 $\\le$ 条件。\n- 对于 $k=4$：$c_3  U \\le c_4 \\implies 0.70  0.7 \\le 1.00$。假的。\n\n两种表述都确认采样索引为 $k=3$。", "answer": "$$\\boxed{3}$$", "id": "3314769"}, {"introduction": "掌握了基本步骤后，我们可以进一步探讨如何为一个常见的参数化分布——几何分布——推导出一个高效的采样公式。这个实践不仅要求我们从第一性原理出发，为该分布的逆变换采样推导出一个解析的“闭式”解，还将引导我们分析在计算机上实现该公式时可能遇到的数值稳定性问题。通过这个练习，我们将理论推导与实际的数值计算挑战联系起来，这是理论与实践结合的关键一步。[@problem_id:3314823]", "problem": "你的任务是为定义域为正整数的几何分布构建一个反转换采样器。设 $X$ 是一个成功概率为 $p \\in (0,1)$ 的几何随机变量，其定义域为 $\\{1,2,\\ldots\\}$，概率质量函数为 $\\mathbb{P}(X=k)=p(1-p)^{k-1}$，其中 $k \\in \\mathbb{N}$。设 $U$ 是一个在 $(0,1)$ 上的标准均匀随机变量，且与 $X$ 独立。从累积分布函数和离散分布的反转换方法的定义出发，推导出精确的分位数函数 $Q(u)$，使得 $X \\stackrel{d}{=} Q(U)$，并以 $u \\in (0,1)$ 和 $p \\in (0,1)$ 的闭式形式表示。你的推导必须从第一性原理出发，论证每一步不等式操作的合理性，并且必须处理其定义域的离散性。\n\n然后，在具有四舍五入到最近值和单位舍入 $\\varepsilon$ 的标准浮点模型中，比较两种求逆过程在 $p$ 很小时的数值稳定性：\n- 一种前缀和求逆方法，它累加 $S_{k}=\\sum_{j=1}^{k} p(1-p)^{j-1}$ 直到 $S_{k} \\geq u$，以及\n- 一种直接求逆方法，它使用初等函数计算 $Q(u)$。\n\n你的比较必须基于一阶浮点误差传播和相消分析，并应确定当 $p \\to 0$ 时，前缀和方法在接近 $1$ 发生停滞之前仍能递增 $S_{k}$ 的最大 $k$ 值的渐近尺度。解释为什么在 $u \\uparrow 1$ 和 $p \\downarrow 0$ 的情况下，使用补偿函数 $\\mathrm{log1p}$（$1+x$ 的自然对数）和 $\\mathrm{expm1}$（$x$ 的指数减 $1$）的直接求逆实现能够减轻相消问题。\n\n你的最终答案仅需以精确分位数函数 $Q(u)$ 的闭式表达式形式给出。最终表达式不要求进行数值舍入。在表达式中使用自然对数 $\\ln$。", "solution": "所述问题是有效的。它在概率论和数值分析方面有科学依据，问题提法得当，客观且内部一致。\n\n首先，我们推导分位数函数 $Q(u)$ 的闭式表达式。设 $X$ 是一个定义域为 $\\{1, 2, 3, \\ldots\\}$、成功概率为 $p \\in (0,1)$ 的几何随机变量。其概率质量函数 (PMF) 为 $\\mathbb{P}(X=k) = p(1-p)^{k-1}$，其中 $k \\in \\{1, 2, 3, \\ldots\\}$。\n\n累积分布函数 (CDF) $F(k)$ 是概率 $\\mathbb{P}(X \\le k)$。对于整数 $k \\ge 1$，这是直到 $k$ 的所有结果的概率之和：\n$$F(k) = \\mathbb{P}(X \\le k) = \\sum_{j=1}^{k} \\mathbb{P}(X=j) = \\sum_{j=1}^{k} p(1-p)^{j-1}$$\n这是一个首项为 $a=p$、公比为 $r=1-p$ 的有限几何级数。前 $k$ 项的和由 $a\\frac{1-r^k}{1-r}$ 给出。\n$$F(k) = p \\frac{1 - (1-p)^k}{1 - (1-p)} = p \\frac{1 - (1-p)^k}{p} = 1 - (1-p)^k$$\n对于离散随机变量，反转换方法将分位数函数 $Q(u)$（其中 $u \\in (0,1)$）定义为 $X$ 的定义域中使累积分布函数大于或等于 $u$ 的最小整数 $k$。\n$$Q(u) = \\min \\{k \\in \\{1, 2, 3, \\ldots\\} : F(k) \\ge u\\}$$\n我们将累积分布函数的表达式代入并求解 $k$：\n$1 - (1-p)^k \\ge u$\n整理不等式的各项，我们得到：\n$1 - u \\ge (1-p)^k$\n由于 $1-u$ 和 $1-p$ 都在区间 $(0,1)$ 内，我们可以对两边取自然对数。因为自然对数是严格递增函数，不等式的方向保持不变：\n$\\ln(1 - u) \\ge \\ln((1-p)^k)$\n利用对数性质 $\\ln(a^b) = b\\ln(a)$，我们得到：\n$\\ln(1 - u) \\ge k \\ln(1 - p)$\n为了分离出 $k$，我们必须除以 $\\ln(1-p)$。关键要注意的是，由于 $p \\in (0,1)$，所以 $1-p \\in (0,1)$，这意味着 $\\ln(1-p)$ 是一个负数。不等式两边同除以一个负数会使其方向反转：\n$$k \\ge \\frac{\\ln(1 - u)}{\\ln(1 - p)}$$\n分位数函数 $Q(u)$ 是满足此条件的最小整数 $k$。大于或等于一个实数的最小整数由上取整函数 $\\lceil \\cdot \\rceil$ 给出。\n因此，精确的分位数函数是：\n$$Q(u) = \\left\\lceil \\frac{\\ln(1 - u)}{\\ln(1 - p)} \\right\\rceil$$\n\n接下来，我们比较两种求逆过程在 $p$ 很小时的数值稳定性。\n\n第一种方法是前缀和求逆。该方法迭代计算 PMF 的部分和 $S_{k} = \\sum_{j=1}^{k} p(1-p)^{j-1}$，直到 $S_k \\ge u$。在浮点运算中的更新步骤是 $\\hat{S}_{k} = \\mathrm{fl}(\\hat{S}_{k-1} + p(1-p)^{k-1})$，其中 $\\hat{S}_{k-1}$ 是先前计算的和。对于大的 $k$，和 $S_{k-1} = 1-(1-p)^{k-1}$ 接近于 $1$。被加上的项 $p(1-p)^{k-1}$ 变得非常小。在单位舍入为 $\\varepsilon$ 的浮点系统中，如果 $|y|  \\varepsilon|x|$，加法 $x+y$ 的结果为 $x$。这种现象被称为淹没或吸收。在我们的例子中，当新项小于运行和的精度时，求和就会停滞。当 $\\hat{S}_{k-1}$ 接近 $1$ 时，这种情况发生在 $p(1-p)^{k-1} \\lesssim \\varepsilon$ 时。我们可以通过求解 $p(1-p)^{k-1} = \\varepsilon$ 来找到发生这种情况的近似 $k$ 值。\n取对数：$\\ln(p) + (k-1)\\ln(1-p) = \\ln(\\varepsilon)$。\n对于小的 $p$，我们使用近似 $\\ln(1-p) \\approx -p$。\n$\\ln(p) - (k-1)p \\approx \\ln(\\varepsilon)$\n$(k-1)p \\approx \\ln(p) - \\ln(\\varepsilon)$\n$k \\approx 1 + \\frac{\\ln(p) - \\ln(\\varepsilon)}{p}$。\n当 $p \\to 0$ 时，可表示的最大 $k$ 值渐近尺度为 $O(\\frac{\\ln p}{p})$。对于小的成功概率 $p$，分布的均值 $1/p$很大。这种数值限制意味着前缀和方法可能无法生成分布尾部的变量，即使是对于与均值相当的值也是如此。\n\n第二种方法是直接求逆，它使用推导出的公式计算 $Q(u)$。在 $p \\to 0$ 和 $u \\to 1$ 的情况下，如果天真地实现，此方法也可能面临数值挑战。\n要计算的表达式是 $k = \\lceil \\frac{\\ln(1-u)}{\\ln(1-p)} \\rceil$。\n主要的数值问题来自于分母 $\\ln(1-p)$，在 $p$ 很小时。如果 $p$ 相对于 $1$ 小于机器精度，那么 $1-p$ 的浮点计算结果可能就是 $1$，导致 $\\ln(1)=0$ 和除以零的错误。即使 $1-p$ 不完全是 $1$，其计算也涉及从 $1$ 中减去一个小数，这可能导致一个具有较大相对误差的结果，然后该结果被传递给对数函数。通过使用像 `log1p(x)` 这样的补偿函数，可以缓解这个问题，该函数即使在 $|x|$ 非常小的情况下也能精确计算 $\\ln(1+x)$。通过将分母计算为 `log1p(-p)`，我们避免了这种灾难性相消，并获得了 $\\ln(1-p)$ 的精确值。\n\n`expm1(x)` 函数（它能精确计算 $|x|$ 很小时的 $\\exp(x)-1$）对于闭式公式本身的作用不那么直接。然而，问题问的是“直接求逆的一种实现”。一种这样的稳健实现，作为评估可能存在问题的对数比值的上取整函数的替代方法，是执行搜索以找到满足 $F(k) \\ge u$ 的最小整数 $k$。为了高效、准确地做到这一点，我们需要一种稳定的方法来计算 CDF，$F(k) = 1 - (1-p)^k$。\n对于小的 $p$ 和中等的 $k$，$(1-p)^k$ 的值接近于 $1$，因此通过 $1 - (1-p)^k$ 计算 $F(k)$ 会导致灾难性相消。通过重写表达式可以实现稳定的计算：\n$$F(k) = 1 - \\exp(k \\ln(1-p))$$\n设 $x = k \\ln(1-p)$。对于小的 $p$，$x$ 是一个小的负数。计算 $1-\\exp(x)$ 正是 `expm1` 设计用来解决的问题。我们可以写成 $F(k) = -\\text{expm1}(x)$。将此与使用 `log1p` 计算对数相结合，我们得到了一个数值稳定的 CDF 公式：\n$$F(k) = -\\text{expm1}(k \\cdot \\text{log1p}(-p))$$\n然后，求逆算法可以在搜索过程（如二分法）中使用这种稳定的 CDF 计算来找到 $k=Q(u)$。这解释了 `log1p` 和 `expm1` 如何可以在一个稳健的实现中一起使用以执行反转换采样，特别是在 $p$ 小且 $u$ 接近 $1$ 的挑战性情况下，此时预期会有大的 $k$ 值。\n直接公式，当谨慎地实现为 $k = \\lceil \\ln(1-u) / \\text{log1p}(-p) \\rceil$ 时，其性能通常优于基于搜索的方法，并克服了前缀和方法的停滞限制。", "answer": "$$\n\\boxed{\\left\\lceil \\frac{\\ln(1-u)}{\\ln(1-p)} \\right\\rceil}\n$$", "id": "3314823"}, {"introduction": "在许多真实世界的蒙特卡洛模拟中，我们面临一个共同的挑战：随机变量的可能取值范围极其巨大（例如，数百万个），但只有少数取值具有非零概率。直接应用标准方法会因内存和计算开销而变得不可行。这个实践将指导我们设计一种高效的算法和数据结构，其性能取决于“有效”结果的数量（$s$），而不是支撑集的全域大小（$n$），这是构建高性能模拟系统的核心技能。[@problem_id:3314767]", "problem": "给定一个定义在大小为 $n$ 的巨大有限支撑集上的离散分布，其中只有 $s$ 个支撑点具有非零概率质量。非零质量以 $(\\text{index}, \\text{weight})$ 对的多重集形式提供。索引位于 $\\{0,1,\\dots,n-1\\}$ 范围内，权重为严格正实数。任务是设计并实现一个专门针对稀疏情况的逆变换采样（ITS）过程，该过程通过构建一个排序后的稀疏前缀和来完成。然后，通过一个测试套件来量化您实现的性能。实现中不得物化任何长度为 $n$ 的密集数组。\n\n需要使用的基本假设和定义：\n- 概率质量函数（PMF）是任意映射 $p:\\{0,1,\\dots,n-1\\}\\to[0,1]$，满足 $\\sum_{i=0}^{n-1}p(i)=1$。\n- 与PMF关联的累积分布函数（CDF）是 $F(k)=\\sum_{i=0}^{k}p(i)$，其中 $k\\in\\{0,1,\\dots,n-1\\}$。\n- Uniform$(0,1)$ 随机变量在单位区间上具有恒定密度，是蒙特卡洛方法中随机性的标准来源。\n\n您的程序必须：\n- 对每个测试用例，接受一个 $(\\text{index}, \\text{weight})$ 对的列表和一个支撑集大小 $n$ 作为内置数据。\n- 通过对权重求和来聚合相同的索引，使得每个不同的索引只出现一次，并对应其聚合后的权重。丢弃任何索引小于 $0$ 或大于等于 $n$ 的无效对；然而，所提供的测试套件保证了有效性，因此您的程序可以断言此属性，而不是静默丢弃。\n- 将聚合后的权重除以其总和以归一化为概率，并按索引递增的顺序构建概率的排序稀疏前缀和。该前缀和是在具有非零质量的不同索引上求值的稀疏CDF。\n- 实现一个逆变换采样器，该采样器：\n  - 抽取 $u\\sim \\text{Uniform}(0,1)$。\n  - 在稀疏CDF上使用二分搜索，找到其CDF值大于或等于 $u$ 的最小稀疏位置。\n  - 返回 $\\{0,1,\\dots,n-1\\}$ 中对应的原始支撑集索引。\n  - 支持在一次调用中使用一个包含 $m$ 个独立均匀分布随机数的数组，对 $m$ 次独立抽取进行向量化采样。\n- 不要物化任何长度为 $n$ 的密集数组；所有计算都必须基于 $s$ 个非零条目以及该规模的数组进行。\n\n需要在您的输出中分析和反映的复杂度目标：\n- 通过对 $s$ 对进行排序并构建稀疏前缀和来构建采样器，应在时间复杂度 $\\mathcal{O}(s\\log s)$ 和内存复杂度 $\\mathcal{O}(s)$ 内运行。\n- 每个独立样本应通过在稀疏CDF上进行二分搜索，在 $\\mathcal{O}(\\log s)$ 时间内找到。对于 $m$ 次独立抽取的向量化采样，总时间应为 $\\mathcal{O}(m\\log s)$。\n\n测试套件规范：\n- 您的程序必须在内部实现并运行以下三个测试用例，并使用指定的常量和随机数生成器种子以确保可复现性。在所有情况下，程序不得读取任何外部输入。\n  1. 小型、未排序且有重复的输入：\n     - $n=20$。\n     - 对：$(7,2.0)$, $(3,1.0)$, $(7,3.0)$, $(0,4.0)$, $(19,10.0)$。\n     - 采样大小 $m=50000$ 次抽取。\n     - 用于采样的随机数生成器（RNG）种子 $r=20231101$。\n  2. 退化的单支撑点：\n     - $n=10^8$。\n     - 对：$(12345678,1.0)$。\n     - 采样大小 $m=10000$ 次抽取。\n     - 用于采样的RNG种子 $r=20231102$。\n  3. 模拟规模 $n=10^8, s=10^5$ 的大型稀疏情况：\n     - $n=10^8$。\n     - 使用固定的RNG种子 $r_{\\text{build}}=20231103$ 按如下方式程序化地构建 $s=10^5$ 个对：\n       - 从 $\\{0,1,\\dots,n-1\\}$ 上的离散均匀分布中独立同分布地抽取索引。\n       - 从速率 $\\lambda=1$ 的指数分布（即在 $[0,\\infty)$ 上的密度为 $w\\mapsto e^{-w}$）中独立同分布地抽取正权重。\n       - 生成的对的多重集可能包含重复的索引；在归一化之前必须通过求和进行聚合。\n     - 使用相同的种子 $r=20231103$ 进行采样，采样大小为 $m=20000$ 次抽取。\n- 对于每个测试用例，计算以下输出：\n  - 令 $s^{\\star}$ 表示聚合重复项后不同索引的数量。以整数形式报告 $s^{\\star}$。\n  - 以整数形式报告 $\\lceil\\log_2(s^{\\star})\\rceil$，它反映了平衡二分搜索所需的深度。\n  - 令 $\\mu=\\sum_{i}p(i)\\,i$ 为分布下索引的理论均值，令 $M_2=\\sum_{i}p(i)\\,i^2$ 为理论二阶矩。使用 $m$ 个样本，计算经验样本均值 $\\widehat{\\mu}$ 和经验样本二阶矩 $\\widehat{M}_2$。以浮点数形式报告相对绝对误差 $E_1=\\lvert\\widehat{\\mu}-\\mu\\rvert/\\lvert\\mu\\rvert$ 和 $E_2=\\lvert\\widehat{M}_2-M_2\\rvert/\\lvert M_2\\rvert$。使用基于归一化概率的非随机代数计算 $\\mu$ 和 $M_2$，且仅对样本使用随机性。\n- 最终输出格式：\n  - 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。总体结果必须是一个长度为 $3$ 的列表，每个条目对应一个测试用例，并按顺序排列。每个条目本身必须是 $[s^{\\star},\\lceil\\log_2(s^{\\star})\\rceil,E_1,E_2]$ 形式的列表，其中 $E_1$ 和 $E_2$ 四舍五入到小数点后六位。例如，输出必须类似于 $[[s^{\\star}_1,\\lceil\\log_2(s^{\\star}_1)\\rceil,E_{1,1},E_{2,1}],[s^{\\star}_2,\\lceil\\log_2(s^{\\star}_2)\\rceil,E_{1,2},E_{2,2}],[s^{\\star}_3,\\lceil\\log_2(s^{\\star}_3)\\rceil,E_{1,3},E_{2,3}]]$，并带有指定的数值舍入。\n\n科学真实性和约束条件：\n- 所有数组和计算都必须仅由 $s$ 个非零条目和样本大小 $m$ 构建，绝不能由长度为 $n$ 的密集数组构建。\n- 仅使用经过充分测试的数值操作，例如排序、累积和以及在单调数组上的二分搜索。\n- 此问题不涉及角度，因此不需要角度单位。不涉及物理单位。\n\n您的输出必须完全由内置测试和RNG种子决定，因此在不同执行中是可复现的。", "solution": "从指定概率分布生成随机变量是随机模拟的基石。逆变换采样（ITS）方法是完成此任务的一项基础且广泛应用的技术。本题要求我们为定义在一个巨大支撑集 $\\{0, 1, \\dots, n-1\\}$ 上的离散概率分布设计并实现一个高效的ITS过程，但其概率质量集中在 $s$ 个点的稀疏小子集上。主要约束是避免物化任何大小为 $n$ 的数据结构，因为对于大的 $n$ 而言，这在计算上是不可行的。\n\n解决方案包括两个主要阶段：一次性设置稀疏采样器数据结构，以及重复使用此结构生成样本。\n\n**1. 离散变量的逆变换采样原理**\n\n设 $X$ 是一个离散随机变量，其支撑集为 $\\{x_1, x_2, \\dots\\}$，概率质量函数（PMF）为 $p(x_i) = P(X=x_i)$。累积分布函数（CDF）为 $F(x) = P(X \\le x) = \\sum_{x_i \\le x} p(x_i)$。ITS方法依赖于以下性质：如果 $U$ 是一个在 $(0,1)$ 上均匀分布的随机变量，那么随机变量 $X = F^{-1}(U)$ 的CDF就是 $F(x)$。对于离散分布，逆CDF定义为 $F^{-1}(u) = \\inf\\{x: F(x) \\ge u\\}$。\n\n算法上，这意味着要从 $X$ 的分布中抽取一个样本，我们需要：\n1.  从 Uniform$(0,1)$ 分布中抽取一个随机数 $u$。\n2.  从支撑集中找到最小的索引 $k$，使其累积概率 $F(k)$ 大于或等于 $u$。\n3.  这个索引 $k$ 就是我们的样本。\n\n一个简单的实现会涉及计算并存储整个CDF，作为一个长度为 $n$ 的数组。对每个样本搜索这个数组会很高效，但构建和存储它需要 $\\mathcal{O}(n)$ 的时间和内存，这对于指定的问题规模（例如 $n=10^8$）是不可行的。\n\n**2. 针对稀疏分布的算法设计**\n\n关键的洞见在于CDF是一个阶梯函数，其值仅在具有非零概率质量的 $s$ 个点上发生变化。因此，我们可以仅使用这 $s$ 个点来稀疏地表示CDF。这导出了一个时间和内存复杂度依赖于 $s$ 而非 $n$ 的算法。\n\n过程如下：\n\n**步骤 2.1：预处理与聚合**\n\n输入是一个 $(\\text{index}, \\text{weight})$ 对的多重集，其中可能包含重复的索引。我们必须首先聚合这些对，以获得一组唯一的索引，每个索引都关联其权重的总和。哈希映射（Python中的字典）是实现此目的的理想数据结构，它允许在期望 $\\mathcal{O}(s)$ 时间内完成聚合。此步骤产生 $s^{\\star} \\le s$ 个唯一的 $(\\text{index}, \\text{total\\_weight})$ 对。\n\n**步骤 2.2：按索引排序**\n\n为了构建CDF，必须按支撑集索引的顺序排列概率质量。我们将 $s^{\\star}$ 个聚合后的对按索引升序排序。这是设置阶段计算量最大的部分，需要 $\\mathcal{O}(s^{\\star} \\log s^{\\star})$ 的时间。\n\n**步骤 2.3：归一化与稀疏CDF构建**\n\n排序后，我们得到两个有序序列：唯一索引 $j'_1  j'_2  \\dots  j'_{s^{\\star}}$ 和它们对应的聚合权重 $W'_1, W'_2, \\dots, W'_{s^{\\star}}$。\n1.  **归一化**：我们计算总权重 $W_{\\text{total}} = \\sum_{l=1}^{s^{\\star}} W'_l$。然后，每个索引 $j'_l$ 的概率质量为 $p'_l = W'_l / W_{\\text{total}}$。\n2.  **前缀和**：我们通过计算已排序概率的前缀和（累积和）来构建稀疏CDF。设此为数组 $C$，其中 $C_l = \\sum_{k=1}^{l} p'_k$。第 $l$ 个元素 $C_l$ 表示CDF在第 $l$ 个稀疏支撑点的值，即 $C_l = F(j'_l)$。\n\n设置阶段最终产生两个长度为 $s^{\\star}$ 的数组：一个保存排序后的唯一索引（`sparse_indices`），另一个保存相应的累积概率（`sparse_cdf`）。所需内存为 $\\mathcal{O}(s^{\\star})$。总设置时间由排序主导，复杂度为 $\\mathcal{O}(s \\log s)$。\n\n**步骤 2.4：向量化采样**\n\n稀疏数据结构准备好后，抽取 $m$ 个样本的效率非常高：\n1.  从 Uniform$(0,1)$ 生成一个包含 $m$ 个独立随机数 $u_1, u_2, \\dots, u_m$ 的数组。\n2.  对于每个 $u_k$，我们需要在 `sparse_cdf` 中找到第一个大于或等于 $u_k$ 的元素的索引 $l$。由于 `sparse_cdf` 是单调递增的，可以使用二分搜索在 $\\mathcal{O}(\\log s^{\\star})$ 时间内高效地执行此搜索。\n3.  所需的样本是在 `sparse_indices[l]` 处找到的原始支撑集索引。\n\n像 NumPy 这样的现代数值库提供了二分搜索的向量化实现（例如 `numpy.searchsorted`），可以在一次高度优化的调用中找到所有 $m$ 个均匀分布变量在 `sparse_cdf` 数组中的插入点。因此，采样 $m$ 个变量的总时间为 $\\mathcal{O}(m \\log s^{\\star})$。\n\n**3. 验证与分析**\n\n为了验证实现，我们将从生成样本中计算出的经验矩与直接从归一化PMF中推导出的理论对应值进行比较。\n-   理论均值为 $\\mu = \\sum_{l=1}^{s^{\\star}} p'_l \\cdot j'_l$。\n-   理论二阶矩为 $M_2 = \\sum_{l=1}^{s^{\\star}} p'_l \\cdot (j'_l)^2$。\n-   样本均值为 $\\widehat{\\mu} = \\frac{1}{m} \\sum_{k=1}^{m} \\text{sample}_k$。\n-   样本二阶矩为 $\\widehat{M}_2 = \\frac{1}{m} \\sum_{k=1}^{m} (\\text{sample}_k)^2$。\n\n根据大数定律，随着样本大小 $m$ 的增加，经验矩应收敛于理论矩。相对误差 $E_1 = \\lvert\\widehat{\\mu}-\\mu\\rvert/\\lvert\\mu\\rvert$ 和 $E_2 = \\lvert\\widehat{M}_2-M_2\\rvert/\\lvert M_2\\rvert$ 量化了这种收敛性，对于足够大的 $m$ 应该很小。此外，我们报告 $s^{\\star}$ 和 $\\lceil\\log_2(s^{\\star})\\rceil$，它们分别确认了稀疏问题的规模和二分搜索的对数深度。这种全面的方法验证了稀疏逆变换采样器的正确性和效率。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\nclass SparseITSampler:\n    \"\"\"\n    An Inverse Transform Sampler for sparse discrete probability distributions.\n\n    It is initialized with (index, weight) pairs defining a PMF on a large\n    support {0, ..., n-1}. It avoids materializing dense arrays of size n.\n    \"\"\"\n    def __init__(self, pairs, n):\n        \"\"\"\n        Initializes the sampler by processing pairs, sorting, and building a sparse CDF.\n        \n        Complexity: O(s log s) time, O(s) space, where s is the number of pairs.\n        \"\"\"\n        # The problem statement guarantees all indices are in [0, n-1].\n        self.n = n\n\n        # Step 1: Aggregate weights for repeated indices. O(s)\n        agg_weights = {}\n        for index, weight in pairs:\n            agg_weights[index] = agg_weights.get(index, 0.0) + weight\n        \n        if not agg_weights:\n            self.s_star = 0\n            self.indices = np.array([], dtype=np.int64)\n            self.probs = np.array([], dtype=np.float64)\n            self.cdf = np.array([], dtype=np.float64)\n            return\n\n        # Step 2: Sort pairs by index. O(s* log s*)\n        sorted_pairs = sorted(agg_weights.items())\n        \n        self.s_star = len(sorted_pairs)\n        \n        indices_arr = np.array([p[0] for p in sorted_pairs], dtype=np.int64)\n        weights_arr = np.array([p[1] for p in sorted_pairs], dtype=np.float64)\n        \n        self.indices = indices_arr\n        \n        # Step 3: Normalize weights and build sparse CDF. O(s*)\n        total_weight = np.sum(weights_arr)\n        if total_weight > 0:\n            self.probs = weights_arr / total_weight\n        else:\n            # This case is avoided by problem spec (weights > 0)\n            self.probs = np.zeros_like(weights_arr)\n\n        self.cdf = np.cumsum(self.probs)\n        # Ensure the CDF ends precisely at 1.0 to handle u=1.0 correctly,\n        # though numpy's uniform is in [0, 1).\n        if self.s_star > 0:\n            self.cdf[-1] = 1.0\n\n    def sample(self, m, seed):\n        \"\"\"\n        Generates m samples from the distribution.\n        \n        Complexity: O(m log s*) time.\n        \"\"\"\n        if self.s_star == 0:\n            return np.array([], dtype=np.int64)\n        \n        rng = np.random.default_rng(seed)\n        u_samples = rng.uniform(size=m)\n        \n        # Use binary search (vectorized) to find the sample for each u.\n        # np.searchsorted(a, v, side='left') finds the first index `i` such that `a[i] >= v`.\n        # This correctly implements the inverse transform rule: find the smallest index `i` such that `cdf[i] >= u`.\n        sample_indices_in_cdf = np.searchsorted(self.cdf, u_samples, side='left')\n        \n        return self.indices[sample_indices_in_cdf]\n\n    def theoretical_moments(self):\n        \"\"\"\n        Calculates the theoretical mean and second moment of the distribution.\n        \"\"\"\n        if self.s_star == 0:\n            return 0.0, 0.0\n        \n        # Using float64 for indices avoids potential overflow in squaring,\n        # although int64 is sufficient for indices up to ~3e9.\n        indices_f64 = self.indices.astype(np.float64)\n        \n        mu = np.dot(self.probs, indices_f64)\n        m2 = np.dot(self.probs, indices_f64**2)\n        \n        return mu, m2\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases_spec = [\n        # 1. Small, unsorted input with repeats\n        {\n            \"n\": 20,\n            \"pairs\": [(7, 2.0), (3, 1.0), (7, 3.0), (0, 4.0), (19, 10.0)],\n            \"m\": 50000,\n            \"seed\": 20231101,\n        },\n        # 2. Degenerate single support point\n        {\n            \"n\": int(1e8),\n            \"pairs\": [(12345678, 1.0)],\n            \"m\": 10000,\n            \"seed\": 20231102,\n        },\n        # 3. Large sparse case\n        {\n            \"n\": int(1e8),\n            \"s_gen\": int(1e5), \n            \"build_seed\": 20231103,\n            \"m\": 20000,\n            \"seed\": 20231103,\n        }\n    ]\n\n    # Procedurally generate pairs for Test Case 3\n    case3_spec = test_cases_spec[2]\n    rng_build = np.random.default_rng(case3_spec[\"build_seed\"])\n    g_indices = rng_build.integers(0, case3_spec[\"n\"], size=case3_spec[\"s_gen\"])\n    g_weights = rng_build.exponential(scale=1.0, size=case3_spec[\"s_gen\"])\n    case3_spec[\"pairs\"] = list(zip(g_indices, g_weights))\n\n    results = []\n    for case in test_cases_spec:\n        # Initialize the sampler from the specification\n        sampler = SparseITSampler(case[\"pairs\"], case[\"n\"])\n        \n        # 1. s_star: number of distinct indices\n        s_star = sampler.s_star\n        \n        # 2. ceil(log2(s_star)): theoretical binary search depth\n        log2_s_star = 0\n        if s_star > 0:\n            # (s_star - 1).bit_length() is an efficient integer alternative\n            log2_s_star = math.ceil(math.log2(s_star)) if s_star > 1 else 0\n\n        # Calculate theoretical moments\n        mu, m2 = sampler.theoretical_moments()\n        \n        # Generate samples\n        samples = sampler.sample(case[\"m\"], case[\"seed\"])\n        \n        # Calculate empirical moments from samples\n        hat_mu = np.mean(samples)\n        # Cast to float64 before squaring to prevent potential overflow with large indices\n        hat_m2 = np.mean(samples.astype(np.float64)**2)\n\n        # 3. E1: relative error of the mean\n        e1 = abs(hat_mu - mu) / abs(mu) if mu != 0 else (0.0 if hat_mu == 0 else float('inf'))\n\n        # 4. E2: relative error of the second moment\n        e2 = abs(hat_m2 - m2) / abs(m2) if m2 != 0 else (0.0 if hat_m2 == 0 else float('inf'))\n\n        # Format results for the current test case\n        case_result = f\"[{s_star},{log2_s_star},{e1:.6f},{e2:.6f}]\"\n        results.append(case_result)\n    \n    # Print the final output in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3314767"}]}