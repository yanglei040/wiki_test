{"hands_on_practices": [{"introduction": "将理论付诸实践是掌握任何算法的关键。第一个动手实践旨在引导您从头开始实现标准的Metropolis-adjusted Langevin算法（MALA）[@problem_id:3355276]。通过推导接受概率并构建完整的采样循环，您将深入理解算法的每个核心组成部分——从目标密度的梯度计算，到基于Langevin动态的提议生成，再到确保遍历性的Metropolis-Hastings校正步骤。这个练习将为您更高级的MCMC方法学习打下坚实的编程和理论基础。", "problem": "你的任务是，在研究生高阶水平上，研究梅特罗波利斯调整的朗之万算法 (MALA)。你的任务结合了从第一性原理进行推导、算法设计，以及使用确定性测试框架进行实现。\n\n从由随机微分方程 $dX_t = \\frac{1}{2}\\nabla \\log \\pi(X_t)\\,dt + dW_t$ 定义的过阻尼朗之万扩散出发，其中 $W_t$ 是标准维纳过程，$\\pi$ 是一个在归一化常数意义下已知目标密度，通过应用步长为 $h>0$ 的欧拉-丸山方法，可以得到未调整的朗之万算法。为了校正由欧拉-丸山方法引入的离散化偏差，并恢复 $\\pi$ 作为不变分布，可以使用一个 Metropolis–Hastings 接受/拒绝步骤。该步骤使用一个非对称提议，此提议由一个高斯分布给出，其中心位于一个涉及 $\\nabla \\log \\pi$ 的漂移点。这便得到了梅特罗波利斯调整的朗之万算法 (MALA)。提议分布为 $q_h(\\cdot \\mid x) = \\mathcal{N}(x + \\tfrac{h}{2}\\nabla \\log \\pi(x),\\, h I_d)$，其中 $I_d$ 是 $d\\times d$ 的单位矩阵。\n\n任务 A (推导与伪代码):\n- 从以下仅有的条件出发，推导 MALA 的接受概率：\n  - 过阻尼朗之万扩散的定义，\n  - 欧拉-丸山离散化，\n  - Metropolis–Hastings 接受概率 $\\alpha(x,y) = \\min\\{1, \\frac{\\pi(y) q_h(x\\mid y)}{\\pi(x) q_h(y\\mid x)}\\}$。\n- 为 MALA 的单次迭代提供清晰的伪代码，并强调以下几点：\n  - 梯度 $\\nabla \\log \\pi(x)$ 的显式计算，\n  - 高斯向量的采样，\n  - Metropolis–Hastings 接受概率的计算。\n- 根据维度 $d$ 标注每次迭代的计算复杂度，并统计：\n  - 每次迭代执行多少次梯度评估，\n  - 每次迭代采样多少个维度为 $d$ 的高斯随机向量，\n  - 在维度 $d$ 上的主导复杂度类（例如，$O(d)$，$O(d^2)$），假设对于下文的测试目标，评估 $\\nabla \\log \\pi(x)$ 的成本为 $O(d)$ 次操作。\n\n任务 B (实现与测试):\n- 实现一个程序，该程序对 $d$ 维标准正态目标执行 MALA，即 $\\pi(x) \\propto \\exp(-\\tfrac{1}{2}\\|x\\|_2^2)$，因此 $\\log \\pi(x)$ 在相差一个加性常数的意义下可以使用，其梯度为 $\\nabla \\log \\pi(x) = -x$。\n- 使用步长为 $h>0$ 的提议核：\n  - 提议均值 $\\mu(x) = x + \\tfrac{h}{2}\\nabla \\log \\pi(x)$，\n  - 提议协方差 $h I_d$。\n- 使用由 $q_h(y\\mid x)$ 和 $q_h(x\\mid y)$ 构建的 Metropolis–Hastings 接受概率，并相应地接受或拒绝。如果拒绝，状态保持不变。\n- 为了可复现性，使用种子 $12345$ 初始化随机数生成器。计算经验均值 $\\bar{x}_T = \\frac{1}{T}\\sum_{t=1}^T X_t$，其中 $X_t$ 是第 $t$ 次接受/拒绝步骤后的链状态。报告欧几里得范数 $\\|\\bar{x}_T\\|_2$。\n- 对于每次迭代，统计梯度评估的次数和采样的 $d$ 维高斯向量的数量。在此实现中，不要跨迭代缓存梯度；在同一次迭代内计算提议和接受所需的一切。\n\n测试套件:\n在以下三种情况下运行你的程序。对于每种情况，初始状态为指定的 $x_0$，维度为 $d$，步长为 $h$，迭代次数为 $T$。\n1) 用例 1：$d=1$，$h=0.5$，$T=6000$，$x_0 = [3.0]$。\n2) 用例 2：$d=10$，$h=0.3$，$T=8000$，$x_0 = [2.0,2.0,\\dots,2.0]$ (十个条目)。\n3) 用例 3：$d=1$，$h=5.0$，$T=4000$，$x_0 = [0.0]$。\n\n每个测试用例的所需输出:\n- 接受率，浮点数，\n- 经验均值的欧几里得范数 $\\|\\bar{x}_T\\|_2$，浮点数，\n- 每次迭代的梯度评估次数，整数，\n- 每次迭代采样的高斯 $d$-向量数量，整数，\n- 此目标的主导复杂度指数，对于 $O(d)$ 等于 $1$ 的整数。\n\n最终输出格式:\n- 你的程序应生成单行输出，其中包含所有三个测试用例的结果，格式为逗号分隔的列表，用方括号括起来，按测试用例的顺序排列并展平。也就是说，输出应为一个包含 $15$ 个数字的列表：对每个用例，按顺序打印五个输出，然后在用例之间串联起来。\n- 浮点数必须精确到六位小数。整数必须不带小数位打印。\n- 格式示例（仅供说明）：$[\\text{acc}_1,\\|\\bar{x}\\|_{1},g_1,z_1,e_1,\\text{acc}_2,\\|\\bar{x}\\|_{2},g_2,z_2,e_2,\\text{acc}_3,\\|\\bar{x}\\|_{3},g_3,z_3,e_3]$。\n\n角度与物理单位:\n- 不涉及任何角度或物理单位。\n\n你的程序必须是自包含的，不接受任何输入，使用种子 $12345$，并遵守上述输出格式。唯一允许的库是 Python 标准库、NumPy 和 SciPy；你也可以选择不使用 SciPy。", "solution": "该问题要求推导梅特罗波利斯调整的朗之万算法 (MALA) 的接受概率，创建其伪代码，分析其计算复杂度，最后在一个特定目标分布上实现和测试该算法。\n\n### 任务 A：推导、伪代码和复杂度分析\n\n#### MALA 接受概率的推导\n\n梅特罗波利斯调整的朗之万算法是一种 Metropolis-Hastings (MH) 算法，旨在从一个目标概率分布中采样，该分布的密度为 $\\pi(x)$，在归一化常数意义下已知。MALA 使用的提议机制，其灵感来自于过阻尼朗之万扩散随机微分方程 (SDE) 的离散化：\n$$\ndX_t = \\frac{1}{2}\\nabla \\log \\pi(X_t)\\,dt + dW_t\n$$\n其中 $W_t$ 是一个标准的 $d$ 维维纳过程。应用步长为 $h>0$ 的欧拉-丸山离散化，从当前状态 $x$ 得到一个提议 $y$：\n$$\ny = x + \\frac{h}{2}\\nabla \\log \\pi(x) + \\sqrt{h}Z\n$$\n其中 $Z \\sim \\mathcal{N}(0, I_d)$ 是一个标准的 $d$ 维正态随机向量。这定义了一个非对称提议核 $q_h(y \\mid x)$，它是一个正态分布 $y \\sim \\mathcal{N}(\\mu(x), \\Sigma)$ 的概率密度函数，其均值为 $\\mu(x) = x + \\frac{h}{2}\\nabla \\log \\pi(x)$，协方差为 $\\Sigma = hI_d$。其概率密度函数为：\n$$\nq_h(y \\mid x) = \\frac{1}{(2\\pi h)^{d/2}} \\exp\\left(-\\frac{1}{2h} \\|y - \\mu(x)\\|_2^2\\right)\n$$\n\nMetropolis-Hastings 对于从状态 $x$ 移动到提议状态 $y$ 的接受概率 $\\alpha(x, y)$ 由下式给出：\n$$\n\\alpha(x,y) = \\min\\left\\{1, \\frac{\\pi(y) q_h(x\\mid y)}{\\pi(x) q_h(y\\mid x)}\\right\\}\n$$\n为了使该表达式具有实用性，我们处理其比值的对数，通常称为对数接受率 (log-acceptance ratio)，$\\log R$：\n$$\n\\log R = \\log\\left(\\frac{\\pi(y)}{\\pi(x)}\\right) + \\log\\left(\\frac{q_h(x\\mid y)}{q_h(y\\mid x)}\\right)\n$$\n第一项是目标对数密度的差：$\\log\\pi(y) - \\log\\pi(x)$。\n\n第二项涉及提议密度的比率。对数提议密度为：\n$$\n\\log q_h(y \\mid x) = -\\frac{d}{2}\\log(2\\pi h) - \\frac{1}{2h} \\left\\|y - \\left(x + \\frac{h}{2}\\nabla \\log \\pi(x)\\right)\\right\\|_2^2 \\\\\n\\log q_h(x \\mid y) = -\\frac{d}{2}\\log(2\\pi h) - \\frac{1}{2h} \\left\\|x - \\left(y + \\frac{h}{2}\\nabla \\log \\pi(y)\\right)\\right\\|_2^2\n$$\n在差值 $\\log q_h(x \\mid y) - \\log q_h(y \\mid x)$ 中，$-\\frac{d}{2}\\log(2\\pi h)$ 这一项作为常数被抵消：\n$$\n\\log\\left(\\frac{q_h(x\\mid y)}{q_h(y\\mid x)}\\right) = -\\frac{1}{2h} \\left( \\left\\|x - \\left(y + \\frac{h}{2}\\nabla \\log \\pi(y)\\right)\\right\\|_2^2 - \\left\\|y - \\left(x + \\frac{h}{2}\\nabla \\log \\pi(x)\\right)\\right\\|_2^2 \\right)\n$$\n综合所有部分，对数接受率为：\n$$\n\\log R(x,y) = \\log\\pi(y) - \\log\\pi(x) - \\frac{1}{2h} \\left( \\left\\|x - y - \\frac{h}{2}\\nabla \\log \\pi(y)\\right\\|_2^2 - \\left\\|y - x - \\frac{h}{2}\\nabla \\log \\pi(x)\\right\\|_2^2 \\right)\n$$\n最终的接受概率为 $\\alpha(x,y) = \\min\\{1, \\exp(\\log R(x,y))\\}$。在数值实现中，最好是将 $\\log u$ 与 $\\log R(x,y)$ 进行比较，其中 $u \\sim \\text{Uniform}(0,1)$。\n\n一种更高效计算对数提议比率项的方法是观察到 $y - (x + \\frac{h}{2}\\nabla \\log \\pi(x)) = \\sqrt{h}Z$，其中 $Z$ 是用于生成提议的标准正态变量。因此，范数的平方是 $h\\|Z\\|_2^2$，并且 $\\log q_h(y \\mid x) = C - \\frac{1}{2}\\|Z\\|_2^2$。这简化了对数接受率：\n$$\n\\log R(x,y) = \\log\\pi(y) - \\log\\pi(x) - \\frac{1}{2h} \\left\\|x - y - \\frac{h}{2}\\nabla \\log \\pi(y)\\right\\|_2^2 + \\frac{1}{2}\\|Z\\|_2^2\n$$\n这种形式避免了一次范数计算，并且可能在数值上更稳定。\n\n#### 单次 MALA 迭代的伪代码\n\n给定当前状态 $x^{(t)}$，步长 $h$，以及对数目标密度函数 $\\log\\pi$：\n\n1.  **计算当前状态的梯度**：$g^{(t)} \\leftarrow \\nabla \\log \\pi(x^{(t)})$。\n2.  **构建提议均值**：$\\mu^{(t)} \\leftarrow x^{(t)} + \\frac{h}{2} g^{(t)}$。\n3.  **采样提议**：\n    a. 采样一个随机向量 $Z^{(t)} \\sim \\mathcal{N}(0, I_d)$。\n    b. 生成提议状态 $y \\leftarrow \\mu^{(t)} + \\sqrt{h} Z^{(t)}$。\n4.  **计算提议状态的梯度**：$g_y \\leftarrow \\nabla \\log \\pi(y)$。\n5.  **计算对数接受率**：\n    a. 计算前向对数提议项：$\\log q_{fwd} \\leftarrow -\\frac{1}{2} \\|Z^{(t)}\\|_2^2$。\n    b. 计算反向对数提议项：$\\log q_{rev} \\leftarrow -\\frac{1}{2h} \\|x^{(t)} - y - \\frac{h}{2} g_y\\|_2^2$。\n    c. 计算对数比率：$\\log R \\leftarrow (\\log\\pi(y) - \\log\\pi(x^{(t)})) + (\\log q_{rev} - \\log q_{fwd})$。\n6.  **接受或拒绝**：\n    a. 采样一个均匀分布的随机数 $u \\sim \\text{Uniform}(0,1)$。\n    b. 如果 $\\log u  \\log R$：\n        设置 $x^{(t+1)} \\leftarrow y$ (接受)。\n    c. 否则：\n        设置 $x^{(t+1)} \\leftarrow x^{(t)}$ (拒绝)。\n\n#### 计算复杂度分析\n\n我们分析每次迭代的复杂度，以状态维度 $d$ 为基准。\n\n-   **每次迭代的梯度评估次数**：该算法需要当前状态的梯度 $\\nabla \\log \\pi(x^{(t)})$ 来构建提议。然后，它需要提议状态的梯度 $\\nabla \\log \\pi(y)$ 来计算接受概率。根据问题中明确的指示，即不要跨迭代缓存梯度，这两个评估在每一次迭代中都会执行，无论提议是被接受还是被拒绝。\n    - **计数**：$2$ 次梯度评估。\n\n-   **每次迭代采样的高斯随机向量数**：采样一个 $d$ 维标准正态向量 $Z^{(t)}$ 来生成提议 $y$。\n    - **计数**：$1$ 个高斯向量样本。\n\n-   **主导复杂度类**：我们假设评估 $\\nabla \\log \\pi(x)$ 的成本为 $O(d)$，正如为测试目标所指定的那样。\n    1.  步骤 1 (在 $x^{(t)}$ 处的梯度)：$O(d)$。\n    2.  步骤 2 (提议均值)：向量加法和标量-向量乘法是 $O(d)$。\n    3.  步骤 3 (采样提议)：采样一个 $d$ 维正态向量是 $O(d)$，然后是 $O(d)$ 的向量操作。\n    4.  步骤 4 (在 $y$ 处的梯度)：$O(d)$。\n    5.  步骤 5 (对数接受率)：这涉及评估 $\\log\\pi$（对于像目标这样的可分离密度，通常是 $O(d)$）、向量范数（$\\|v\\|_2^2$ 是 $O(d)$）和向量算术（$O(d)$）。总成本是 $O(d)$。\n    6.  步骤 6 (接受/拒绝)：这是一个 $O(d)$ 操作（向量复制）。\n\n由于所有步骤的复杂度最多为 $O(d)$，因此 MALA 单次迭代的主导复杂度类为 $O(d)$。\n- **主导复杂度指数**：对于 $O(d) = O(d^1)$，指数为 $1$。", "answer": "```python\nimport numpy as np\n# No other libraries are needed for this problem.\n\ndef solve():\n    \"\"\"\n    Implements and tests the Metropolis-Adjusted Langevin Algorithm (MALA)\n    for a d-dimensional standard normal target distribution.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (d, h, T, x0)\n        (1, 0.5, 6000, np.array([3.0])),\n        (10, 0.3, 8000, np.full(10, 2.0)),\n        (1, 5.0, 4000, np.array([0.0])),\n    ]\n\n    results = []\n    \n    # Initialize the random number generator with a fixed seed for reproducibility.\n    rng = np.random.default_rng(12345)\n\n    for d, h, T, x0 in test_cases:\n        x_current = np.copy(x0)\n        x_sum = np.zeros(d)\n        accepted_count = 0\n\n        # The number of gradient evaluations and Gaussian samples are constant per iteration.\n        grad_evals_per_iter = 2\n        gauss_samples_per_iter = 1\n        complexity_exponent = 1 # O(d^1)\n\n        for _ in range(T):\n            # 1. Compute gradient at the current state.\n            # For pi(x) propto exp(-0.5*||x||^2), grad(log(pi(x))) = -x.\n            grad_x = -x_current\n\n            # 2. Form proposal by sampling from the proposal distribution.\n            # Proposal mean: mu = x + (h/2) * grad(log(pi(x)))\n            # Proposal distribution: y ~ N(mu, h*I)\n            mu_proposal = x_current + (h / 2.0) * grad_x\n            \n            # Sample a standard normal vector Z\n            z = rng.standard_normal(size=d)\n            y_proposal = mu_proposal + np.sqrt(h) * z\n\n            # 3. Compute gradient at the proposed state.\n            grad_y = -y_proposal\n\n            # 4. Calculate the log of the Metropolis-Hastings acceptance ratio.\n            # log R = log(pi(y)/pi(x)) + log(q(x|y)/q(y|x))\n\n            # Log-target densities (ignoring constants)\n            log_pi_x = -0.5 * np.dot(x_current, x_current)\n            log_pi_y = -0.5 * np.dot(y_proposal, y_proposal)\n\n            # Log-proposal densities (ignoring constants)\n            # Forward: q(y|x)\n            # We can use the generated z to simplify: y-mu_proposal = sqrt(h)*z\n            # The exponent term is -1/(2h) * ||y-mu_proposal||^2 = -1/(2h) * h*||z||^2 = -0.5*||z||^2\n            log_q_y_given_x = -0.5 * np.dot(z, z)\n            \n            # Reverse: q(x|y)\n            # Mean of reverse proposal: mu_rev = y + (h/2)*grad_y\n            mu_reverse = y_proposal + (h / 2.0) * grad_y\n            log_q_x_given_y = -1.0 / (2.0 * h) * np.sum((x_current - mu_reverse)**2)\n\n            # Total log acceptance ratio\n            log_alpha = (log_pi_y - log_pi_x) + (log_q_x_given_y - log_q_y_given_x)\n\n            # 5. Accept or reject the proposal.\n            if np.log(rng.uniform())  log_alpha:\n                x_current = y_proposal\n                accepted_count += 1\n            # If rejected, x_current remains the same.\n            \n            # Add the state of the chain (after accept/reject) to the sum.\n            x_sum += x_current\n\n        # After all iterations, compute the final statistics.\n        acceptance_rate = accepted_count / T\n        empirical_mean = x_sum / T\n        norm_of_mean = np.linalg.norm(empirical_mean)\n\n        results.extend([\n            round(acceptance_rate, 6),\n            round(norm_of_mean, 6),\n            grad_evals_per_iter,\n            gauss_samples_per_iter,\n            complexity_exponent\n        ])\n\n    # Format the final output string as specified.\n    final_output = f\"[{','.join(map(str, results))}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3355276"}, {"introduction": "标准的MALA在处理各向异性的目标分布时（即在不同维度上尺度差异巨大），其采样效率可能会很低。本次实践探讨了一种强大的改进方法：预处理（preconditioning）[@problem_id:3355207]。通过为预处理MALA推导其接受概率，您将学习如何将目标分布的几何信息融入到提议分布中，从而实现更高效的状态空间探索。这是将MALA应用于现实世界高维问题的关键一步。", "problem": "考虑一个在 $\\mathbb{R}^{d}$ 上的目标概率密度 $\\pi(x)$，该密度在忽略归一化常数的情况下是已知的，其对数 $\\ln\\pi(x)$ 连续可微，且存在一个对称正定矩阵 $M \\in \\mathbb{R}^{d \\times d}$。我们使用一种预处理的过阻尼朗之万动力学来为 Metropolis-Hastings (MH) 方法构造提议，该方法的平稳分布为 $\\pi(x)$。从随机微分方程 (SDE) 的基础和 MH 接受机制出发，通过将 Euler–Maruyama 格式应用于以 $\\pi(x)$ 为不变密度的预处理朗之万 SDE，来推导离散时间提议核。利用这个核函数得到精确的高斯提议密度 $q(x' \\mid x)$，然后写出 MH 接受概率 $\\alpha(x,x')$，该概率需要考虑 $q(x' \\mid x)$ 的不对称性。\n\n您的推导必须从以下基本依据开始：\n- 带预处理的过阻尼朗之万 SDE，其漂移项的选择是为了保持 $\\pi(x)$ 作为不变密度，扩散项与 $M$ 对齐。\n- Metropolis-Hastings 接受概率，对于可能不对称的提议，该概率由目标密度与提议密度的比率决定。\n\n假设步长 $h0$ 是固定的。将最终的接受概率表示为一个单一的闭式解析表达式，该表达式明确包含由提议不对称性产生的高斯项。最终答案必须是一个符号数学表达式；不要包含任何数值计算或近似。", "solution": "用户希望为预处理的 Metropolis 调整朗之万算法 (MALA) 推导 Metropolis-Hastings 接受概率。推导必须从底层的随机微分方程 (SDE) 开始，使用 Euler-Maruyama 离散化来找到提议密度，然后应用针对不对称提议的 Metropolis-Hastings 规则。\n\n### 步骤 1：问题验证\n\n**1.1. 提取已知条件**\n-   目标概率密度：$\\pi(x)$，在 $\\mathbb{R}^{d}$ 上，在忽略归一化常数的情况下已知。\n-   对数密度 $\\ln\\pi(x)$ 连续可微。\n-   预处理矩阵：$M \\in \\mathbb{R}^{d \\times d}$，对称且正定。\n-   方法：Metropolis-Hastings (MH)，其提议基于预处理的过阻尼朗之万动力学。\n-   离散化：Euler–Maruyama 格式。\n-   步长：$h0$，固定。\n-   任务：推导提议密度 $q(x' \\mid x)$ 和 MH 接受概率 $\\alpha(x,x')$。\n\n**1.2. 使用提取的已知条件进行验证**\n-   **科学依据**：该问题基于随机微积分（朗之万 SDE）、SDE 的数值方法（Euler-Maruyama）和统计计算（Metropolis-Hastings 算法）的基本原理。这些是计算统计学和物理学中标准且成熟的概念。该问题在科学上是合理的。\n-   **适定性**：该问题陈述清晰，并提供了推导所求量所需的所有信息。对 $\\pi(x)$ 和 $M$ 的假设是标准的，确保了所有数学运算（梯度、矩阵求逆等）都是良定义的。存在唯一的解析解。\n-   **客观性**：该问题用精确、客观的数学语言表述，没有歧义或主观论断。\n\n**1.3. 结论与行动**\n该问题是有效的，因为它具有科学依据、适定性和客观性。我将继续进行完整推导。\n\n### 步骤 2：接受概率的推导\n\n**2.1. 预处理的朗之万 SDE**\n过阻尼朗之万 SDE 是一个随机过程，其平稳分布是给定的目标密度 $\\pi(x)$。对于目标密度 $\\pi(x) \\propto \\exp(-E(x))$，其中 $E(x)$ 是势能，该 SDE 描述了一个粒子在该势能景观中受到随机热涨落影响下的运动。\n\n对于一个具有不变密度 $\\pi(x)$ 且使用恒定预处理器 $M$ 的预处理朗之万 SDE，其一般形式为\n$$\ndX_t = \\frac{1}{2} M \\nabla \\ln \\pi(X_t) dt + \\sqrt{M} dW_t\n$$\n其中 $X_t \\in \\mathbb{R}^d$ 是系统在时间 $t$ 的状态，$\\nabla \\ln \\pi(X_t)$ 是对数目标密度的梯度，$M$ 是对称正定预处理矩阵，$dW_t$ 是一个标准的 $d$ 维维纳过程（即，其增量是均值为 $0$、协方差为 $I_d dt$ 的独立高斯变量，其中 $I_d$ 是 $d \\times d$ 单位矩阵）。\n\n扩散项是 $\\sqrt{M} dW_t$，其中 $\\sqrt{M}$ 是 $M$ 唯一的对称正定平方根。这个噪声项的协方差是 $E[(\\sqrt{M} dW_t)(\\sqrt{M} dW_t)^T] = \\sqrt{M} E[dW_t dW_t^T] \\sqrt{M}^T = \\sqrt{M} (I_d dt) \\sqrt{M} = M dt$。选择漂移项为 $\\frac{1}{2} M \\nabla \\ln \\pi(X_t)$ 是为了确保在 SDE 层面满足细致平衡条件，从而使 $\\pi(x)$ 成为不变密度。\n\n**2.2. 离散化与提议核**\n为了给 Metropolis-Hastings 算法生成提议，我们使用 Euler-Maruyama 格式和一个有限时间步长 $h  0$ 来离散化 SDE。设 $x$ 是第 $n$ 步的当前状态，$x'$ 是第 $n+1$ 步的提议状态。离散化形式如下：\n$$\nx' = x + h \\left(\\frac{1}{2} M \\nabla \\ln \\pi(x)\\right) + \\sqrt{h} \\sqrt{M} Z\n$$\n其中 $Z \\sim \\mathcal{N}(0, I_d)$ 是一个由 $d$ 个独立标准正态随机变量组成的向量。\n\n这个方程定义了提议机制。我们可以看到，$x'$ 是通过将一个确定性漂移项和一个随机高斯涨落加到当前状态 $x$ 上生成的。\n\n**2.3. 高斯提议密度 $q(x' \\mid x)$**\n提议规则可以被重写，以表明 $x'$ 是从一个多元高斯分布中抽取的。设该分布的均值为 $\\mu(x)$:\n$$\n\\mu(x) = x + \\frac{h}{2} M \\nabla \\ln \\pi(x)\n$$\n提议 $x'$ 于是由 $x' = \\mu(x) + \\sqrt{hM}Z$ 给出。这表明，在给定 $x$ 的条件下，提议状态 $x'$ 服从一个均值为 $\\mu(x)$、协方差为 $\\Sigma = E[(\\sqrt{hM}Z)(\\sqrt{hM}Z)^T] = h M E[ZZ^T] = hM$ 的高斯分布。\n\n因此，提议密度 $q(x' \\mid x)$ 是多元正态分布 $\\mathcal{N}(\\mu(x), hM)$ 的概率密度函数：\n$$\nq(x' \\mid x) = \\frac{1}{\\sqrt{(2\\pi)^d \\det(hM)}} \\exp\\left( -\\frac{1}{2} (x' - \\mu(x))^T (hM)^{-1} (x' - \\mu(x)) \\right)\n$$\n代入 $\\mu(x)$ 的表达式，我们得到：\n$$\nq(x' \\mid x) = \\frac{1}{\\sqrt{(2\\pi h)^d \\det(M)}} \\exp\\left( -\\frac{1}{2h} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right)^T M^{-1} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right) \\right)\n$$\n这个提议密度通常是不对称的，即 $q(x' \\mid x) \\neq q(x \\mid x')$，因为漂移项 $\\frac{h}{2} M \\nabla \\ln \\pi(x)$ 依赖于起始状态 $x$。\n\n**2.4. Metropolis-Hastings 接受概率 $\\alpha(x, x'$)**\nMetropolis-Hastings 算法通过引入一个接受-拒绝步骤，确保生成的马尔可夫链以 $\\pi(x)$ 为其平稳分布。从 $x$ 到 $x'$ 的提议移动的接受概率 $\\alpha(x, x')$ 由以下公式给出：\n$$\n\\alpha(x, x') = \\min \\left( 1, \\frac{\\pi(x') q(x \\mid x')}{\\pi(x) q(x' \\mid x)} \\right)\n$$\n为了计算这个概率，我们需要逆向提议密度 $q(x \\mid x')$，即从 $x'$ 提议移动到 $x$ 的概率。根据推导的对称性，它由以下公式给出：\n$$\nq(x \\mid x') = \\frac{1}{\\sqrt{(2\\pi h)^d \\det(M)}} \\exp\\left( -\\frac{1}{2h} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right)^T M^{-1} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right) \\right)\n$$\n提议密度的比率是：\n$$\n\\frac{q(x \\mid x')}{q(x' \\mid x)} = \\frac{\\exp\\left( -\\frac{1}{2h} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right)^T M^{-1} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right) \\right)}{\\exp\\left( -\\frac{1}{2h} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right)^T M^{-1} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right) \\right)}\n$$\n注意，归一化常数 $\\frac{1}{\\sqrt{(2\\pi h)^d \\det(M)}}$ 会被消掉。\n\n将这个比率代入接受概率公式，就得到了 $\\alpha(x, x')$ 的最终表达式。由于 $\\pi(x)$ 在忽略一个常数的情况下是已知的，我们使用比率 $\\pi(x')/\\pi(x)$，这是可计算的。最终的接受概率是：\n$$\n\\alpha(x, x') = \\min\\left(1, \\frac{\\pi(x')}{\\pi(x)} \\frac{\\exp\\left( -\\frac{1}{2h} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right)^T M^{-1} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right) \\right)}{\\exp\\left( -\\frac{1}{2h} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right)^T M^{-1} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right) \\right)}\\right)\n$$\n这个表达式也可以通过合并指数项写得更紧凑：\n$$\n\\alpha(x, x') = \\min\\left(1, \\exp\\left( \\ln\\left(\\frac{\\pi(x')}{\\pi(x)}\\right) + \\ln\\left(\\frac{q(x \\mid x')}{q(x' \\mid x)}\\right) \\right)\\right)\n$$\n其中提议的对数比率由下式给出：\n$$\n\\ln\\left(\\frac{q(x \\mid x')}{q(x' \\mid x)}\\right) = -\\frac{1}{2h} \\left[ \\left\\|x - x' - \\frac{h}{2}M\\nabla\\ln\\pi(x')\\right\\|_{M^{-1}}^2 - \\left\\|x' - x - \\frac{h}{2}M\\nabla\\ln\\pi(x)\\right\\|_{M^{-1}}^2 \\right]\n$$\n其中 $\\|v\\|_{A}^2 = v^T A v$。提示中要求的表达式是首次推导出的显式形式。", "answer": "$$\n\\boxed{\\min\\left(1, \\frac{\\pi(x')}{\\pi(x)} \\frac{\\exp\\left( -\\frac{1}{2h} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right)^T M^{-1} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right) \\right)}{\\exp\\left( -\\frac{1}{2h} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right)^T M^{-1} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right) \\right)}\\right)}\n$$", "id": "3355207"}, {"introduction": "MALA的提议步骤依赖于对Langevin随机微分方程的数值离散化。标准的欧拉-丸山（Euler-Maruyama）格式虽然简单，但在处理“刚性”势能（potential）或使用较大步长$h$时可能导致提议不准确，从而产生高拒绝率。这项高级实践将指导您实现一个基于更高阶积分器（隐式中点法）的MALA提议机制[@problem_id:3355234]。通过将其性能与标准MALA进行比较，您将获得关于单步计算成本与整体采样效率之间权衡的宝贵实践经验。", "problem": "考虑一个一维目标概率密度 $\\pi(x)$（定义在 $\\mathbb{R}$ 上），其定义忽略了归一化常数，为 $\\pi(x) \\propto \\exp(-U(x))$，其中势能为 $U(x) = \\frac{k}{2} x^2 + \\frac{\\lambda}{4} x^4$，刚度参数 $k  0$ 且 $\\lambda \\ge 0$。保持 $\\pi$ 不变的过阻尼朗之万扩散形式为 $dX_t = \\nabla \\log \\pi(X_t)\\, dt + \\sqrt{2}\\, dW_t$，其中 $W_t$ 是标准布朗运动。我们将比较 Metropolis–Hastings (MH) 的两种提议机制：\n\n1. Euler–Maruyama 提议：$Y = X + h \\nabla \\log \\pi(X) + \\sqrt{2h}\\, \\xi$，其中 $\\xi \\sim \\mathcal{N}(0,1)$，步长 $h  0$。\n\n2. 隐式中点 (Crank–Nicolson) 提议：$Y$ 由 $Y = X + \\frac{h}{2} \\left[\\nabla \\log \\pi(X) + \\nabla \\log \\pi(Y)\\right] + \\sqrt{2h}\\, \\xi$ 隐式定义，其中 $\\xi \\sim \\mathcal{N}(0,1)$ 相同。\n\n从 Metropolis–Hastings 的细致平衡条件和概率密度的变量替换公式出发，推导每种提议的接受概率。对于隐式中点法，推导必须包含从标准正态变量到提议状态的变换所产生的雅可比因子。使用 MH 接受概率公式 $\\alpha(x,y) = \\min\\left(1, \\frac{\\pi(y) q(y \\to x)}{\\pi(x) q(x \\to y)}\\right)$，其中 $q(\\cdot\\, \\to\\, \\cdot)$ 是提议密度，并将所有项用 $U$、其导数和 $h$ 显式表示。\n\n将这两种算法实现为马尔可夫链蒙特卡洛 (MCMC) 采样器，该采样器能够：\n- 使用指定的离散化方法生成提议。\n- 计算从第一性原理推导出的正确接受概率。\n- 根据 MH 准则接受或拒绝提议。\n\n使用以下参数集测试套件，评估对于刚性势能，高阶隐式中点格式是否比 Euler–Maruyama 格式降低了拒绝率。对于每种情况，使用给定的随机数生成器种子，从 $x_0 = 0$ 开始运行一条长度为 $N$ 步的单链。所有量均为无量纲。\n\n- 测试用例 1（顺利情况，中等刚性二次势）：$(k, \\lambda, h, N, \\text{seed}) = (100, 0, 0.01, 10000, 123)$。\n- 测试用例 2（非常刚性的二次势）：$(k, \\lambda, h, N, \\text{seed}) = (1000, 0, 0.005, 10000, 456)$。\n- 测试用例 3（中等刚性四次势）：$(k, \\lambda, h, N, \\text{seed}) = (100, 10, 0.004, 10000, 789)$。\n- 测试用例 4（非常刚性的混合二次-四次势，小步长，边界情况）：$(k, \\lambda, h, N, \\text{seed}) = (1000, 50, 0.001, 10000, 42)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，`[result1,result2,result3,result4]`），其中每个条目都是一个布尔值，指示在该测试用例中，隐式中点格式是否比 Euler–Maruyama 产生了更低的拒绝分数（如果隐式中点的拒绝次数更少，则为 true，否则为 false）。", "solution": "我们从过阻尼朗之万扩散 $dX_t = \\nabla \\log \\pi(X_t)\\, dt + \\sqrt{2}\\, dW_t$ 开始，当 $\\nabla \\log \\pi(x) = -\\nabla U(x)$ 时，其不变密度为 $\\pi(x) \\propto \\exp(-U(x))$。在一维情况下，我们有 $\\nabla \\log \\pi(x) = -U'(x)$ 和 $\\nabla^2 \\log \\pi(x) = -U''(x)$，其中 $U'(x)$ 和 $U''(x)$ 分别表示势能关于 $x$ 的一阶和二阶导数。对于 $U(x) = \\frac{k}{2} x^2 + \\frac{\\lambda}{4} x^4$，可以得出 $U'(x) = k x + \\lambda x^3$ 和 $U''(x) = k + 3 \\lambda x^2$。\n\nMetropolis–Hastings 算法以概率\n$$\n\\alpha(x, y) = \\min\\left(1, \\frac{\\pi(y) q(y \\to x)}{\\pi(x) q(x \\to y)}\\right),\n$$\n接受从 $x$ 到 $y$ 的提议移动，其中 $q(u \\to v)$ 是从 $u$ 到 $v$ 的提议密度。由于 $\\pi(x)$ 仅在相差一个比例常数的情况下是已知的，因此使用 $\\log \\pi(x) = -U(x) + C$ 就足够了，常数 $C$ 在比率中会抵消。\n\n对于 Euler–Maruyama 格式，提议为\n$$\nY = X + h \\nabla \\log \\pi(X) + \\sqrt{2h}\\, \\xi = X - h U'(X) + \\sqrt{2h}\\, \\xi,\\quad \\xi \\sim \\mathcal{N}(0,1).\n$$\n在 $X = x$ 的条件下，提议密度 $q_{\\mathrm{EM}}(x \\to y)$ 是均值为 $m_x = x + h \\nabla \\log \\pi(x) = x - h U'(x)$、方差为 $2h$ 的高斯分布，即\n$$\nq_{\\mathrm{EM}}(x \\to y) = \\frac{1}{\\sqrt{4\\pi h}} \\exp\\left(-\\frac{(y - m_x)^2}{4h}\\right).\n$$\n因此，接受概率为\n$$\n\\alpha_{\\mathrm{EM}}(x, y) = \\min\\left(1, \\exp\\left[(\\log \\pi(y) - \\log \\pi(x)) + (\\log q_{\\mathrm{EM}}(y \\to x) - \\log q_{\\mathrm{EM}}(x \\to y))\\right]\\right),\n$$\n其中\n$$\n\\log q_{\\mathrm{EM}}(x \\to y) = -\\frac{1}{2}\\log(4\\pi h) - \\frac{(y - x - h \\nabla \\log \\pi(x))^2}{4h}.\n$$\n在一维情况下，逆向提议 $q_{\\mathrm{EM}}(y \\to x)$ 只需在上述表达式中将 $x$ 替换为 $y$。\n\n对于隐式中点 (Crank–Nicolson) 格式，提议由\n$$\nY = X + \\frac{h}{2} [\\nabla \\log \\pi(X) + \\nabla \\log \\pi(Y)] + \\sqrt{2h}\\, \\xi = X - \\frac{h}{2}[U'(X) + U'(Y)] + \\sqrt{2h}\\, \\xi,\\quad \\xi \\sim \\mathcal{N}(0,1)\n$$\n隐式定义。为了计算提议密度 $q_{\\mathrm{IM}}(x \\to y)$，我们观察到提议 $y$ 是通过对标准正态变量 $\\xi$ 进行变换得到的。定义映射\n$$\ng(y; x) := \\frac{y - x - \\frac{h}{2}[\\nabla \\log \\pi(x) + \\nabla \\log \\pi(y)]}{\\sqrt{2h}} = \\frac{y - x + \\frac{h}{2}[U'(x) + U'(y)]}{\\sqrt{2h}},\n$$\n使得当 $y$ 满足给定 $x$ 和 $\\xi$ 的隐式中点方程时，$g(y; x) = \\xi$。根据变量替换公式，在一维情况下可得\n$$\nq_{\\mathrm{IM}}(x \\to y) = \\phi(g(y; x))\\, \\left|\\frac{\\partial g(y; x)}{\\partial y}\\right|,\n$$\n其中 $\\phi(u) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right)$ 是标准正态密度，且\n$$\n\\frac{\\partial g(y; x)}{\\partial y} = \\frac{1 - \\frac{h}{2} \\nabla^2 \\log \\pi(y)}{\\sqrt{2h}} = \\frac{1 + \\frac{h}{2} U''(y)}{\\sqrt{2h}}.\n$$\n逆向映射 $g(x; y)$ 是\n$$\ng(x; y) = \\frac{x - y - \\frac{h}{2}[\\nabla \\log \\pi(y) + \\nabla \\log \\pi(x)]}{\\sqrt{2h}} = -g(y; x),\n$$\n其关于 $x$ 的导数为\n$$\n\\frac{\\partial g(x; y)}{\\partial x} = \\frac{1 - \\frac{h}{2} \\nabla^2 \\log \\pi(x)}{\\sqrt{2h}} = \\frac{1 + \\frac{h}{2} U''(x)}{\\sqrt{2h}}.\n$$\n因此，\n$$\nq_{\\mathrm{IM}}(y \\to x) = \\phi(g(x; y))\\, \\left|\\frac{\\partial g(x; y)}{\\partial x}\\right| = \\phi(-g(y; x))\\, \\frac{\\left|1 - \\frac{h}{2} \\nabla^2 \\log \\pi(x)\\right|}{\\sqrt{2h}}.\n$$\n由于 $\\phi(-u) = \\phi(u)$，标准正态密度因子在 Metropolis–Hastings 接受率中被抵消，剩下\n$$\n\\alpha_{\\mathrm{IM}}(x, y) = \\min\\left(1, \\frac{\\pi(y)}{\\pi(x)} \\cdot \\frac{\\left|1 - \\frac{h}{2} \\nabla^2 \\log \\pi(x)\\right|}{\\left|1 - \\frac{h}{2} \\nabla^2 \\log \\pi(y)\\right|}\\right) = \\min\\left(1, \\exp\\left[-U(y) + U(x)\\right] \\cdot \\frac{1 + \\frac{h}{2} U''(x)}{1 + \\frac{h}{2} U''(y)}\\right).\n$$\n对于所考虑的 $k  0$ 和 $\\lambda \\ge 0$ 的四次势，我们有 $U''(x) = k + 3 \\lambda x^2 \\ge k  0$，这确保了 $1 + \\frac{h}{2} U''(x)  1$ 以及雅可比因子的正性。隐式中点提议 $y$ 可以通过对每次抽取的 $\\xi$ 求解标量非线性方程\n$$\nf(y) := y - x + \\frac{h}{2}[U'(x) + U'(y)] - \\sqrt{2h}\\, \\xi = 0\n$$\n得到，求解时使用 Newton's method，导数为 $f'(y) = 1 + \\frac{h}{2} U''(y)$。由于对所有 $y$ 都有 $f'(y)  1$，该映射是严格单调的，对于中等大小的 $h$，Newton's method 会快速收敛。\n\n算法设计：\n- 对于 Euler–Maruyama：从状态 $x$ 出发，抽取 $\\xi \\sim \\mathcal{N}(0,1)$，设 $y = x - h U'(x) + \\sqrt{2h}\\, \\xi$，计算\n$$\n\\log \\alpha_{\\mathrm{EM}}(x, y) = [-U(y) + U(x)] + \\left[-\\frac{1}{2}\\log(4\\pi h) - \\frac{(x - y + h U'(y))^2}{4h}\\right] - \\left[-\\frac{1}{2}\\log(4\\pi h) - \\frac{(y - x + h U'(x))^2}{4h}\\right],\n$$\n并以概率 $\\min(1, \\exp(\\log \\alpha_{\\mathrm{EM}}(x, y)))$ 接受。\n- 对于隐式中点：从状态 $x$ 出发，抽取 $\\xi \\sim \\mathcal{N}(0,1)$，求解 $f(y) = 0$ 得到 $y$，并计算\n$$\n\\alpha_{\\mathrm{IM}}(x, y) = \\min\\left(1, \\exp\\left[-U(y) + U(x)\\right] \\cdot \\frac{1 + \\frac{h}{2} U''(x)}{1 + \\frac{h}{2} U''(y)}\\right).\n$$\n\n测试方法：\n- 对于每个给定的 $(k, \\lambda, h, N, \\text{seed})$，从 $x_0 = 0$ 开始运行两条长度为 $N$ 的链：一条使用 Euler–Maruyama 提议及其接受概率，另一条使用隐式中点提议及上面推导的经雅可比因子调整的接受概率。\n- 记录每种方法被拒绝的提议移动的比例。\n- 每个测试用例输出一个布尔值，指示隐式中点格式是否比 Euler–Maruyama 产生了更低的拒绝分数。\n\n边界情况与覆盖范围：\n- 测试用例1评估了一个中等刚性的二次势，步长 $h$ 相对较大，这是一个标准用例。\n- 测试用例2是一个非常刚性的二次势，显式 Euler 提议容易产生大漂移和可能更高的拒绝率，这能揭示中点法的稳健性。\n- 测试用例3引入了四次刚度，检验非线性对雅可比因子的影响。\n- 测试用例4使用非常刚性的混合二次-四次势和较小的步长，探测两种方法接受率都很高且雅可比效应不明显的边界情况。\n\n最终程序实现了这些算法，通过种子确保可复现性，并打印一个单行布尔值列表，指示每个测试用例中隐式中点格式的拒绝率是否更低。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef potential_U(x, k, lam):\n    # U(x) = 0.5*k*x^2 + 0.25*lam*x^4\n    return 0.5 * k * x**2 + 0.25 * lam * x**4\n\ndef grad_U(x, k, lam):\n    # U'(x) = k*x + lam*x^3\n    return k * x + lam * x**3\n\ndef hess_U(x, k, lam):\n    # U''(x) = k + 3*lam*x^2\n    return k + 3.0 * lam * x**2\n\ndef log_pi(x, k, lam):\n    # log pi(x) = -U(x) + const; constant cancels in ratios\n    return -potential_U(x, k, lam)\n\ndef grad_log_pi(x, k, lam):\n    # grad log pi = -U'(x)\n    return -grad_U(x, k, lam)\n\ndef hess_log_pi(x, k, lam):\n    # hess log pi = -U''(x)\n    return -hess_U(x, k, lam)\n\ndef em_propose_accept(x, h, k, lam, rng):\n    # Euler–Maruyama proposal and MH acceptance\n    xi = rng.normal()\n    y = x + h * grad_log_pi(x, k, lam) + np.sqrt(2.0 * h) * xi\n    # log q(x-y)\n    m_x = x + h * grad_log_pi(x, k, lam)\n    log_q_xy = -0.5 * np.log(4.0 * np.pi * h) - ((y - m_x)**2) / (4.0 * h)\n    # log q(y-x)\n    m_y = y + h * grad_log_pi(y, k, lam)\n    log_q_yx = -0.5 * np.log(4.0 * np.pi * h) - ((x - m_y)**2) / (4.0 * h)\n    log_a = (log_pi(y, k, lam) - log_pi(x, k, lam)) + (log_q_yx - log_q_xy)\n    accept = (rng.random()  np.exp(min(0.0, log_a)))\n    return y if accept else x, not accept\n\ndef im_solve_y(x, h, k, lam, xi, max_iter=50, tol=1e-12):\n    # Solve y from implicit midpoint equation:\n    # f(y) = y - x + (h/2)*(U'(x) + U'(y)) - sqrt(2h)*xi = 0\n    # Using Newton's method.\n    # Good initial guess: EM proposal\n    y = x - h * grad_U(x, k, lam) + np.sqrt(2.0 * h) * xi\n    for _ in range(max_iter):\n        f = y - x + 0.5 * h * (grad_U(x, k, lam) + grad_U(y, k, lam)) - np.sqrt(2.0 * h) * xi\n        if abs(f)  tol:\n            break\n        fp = 1.0 + 0.5 * h * hess_U(y, k, lam)\n        # Newton update\n        y_new = y - f / fp\n        # Simple damping if needed\n        if np.isfinite(y_new):\n            y = y_new\n        else:\n            # fallback to smaller step towards x\n            y = 0.5 * (y + x)\n    return y\n\ndef im_propose_accept(x, h, k, lam, rng):\n    # Implicit midpoint proposal and MH acceptance using Jacobian-adjusted ratio\n    xi = rng.normal()\n    y = im_solve_y(x, h, k, lam, xi)\n    # Acceptance ratio:\n    # alpha = min(1, exp(-U(y)+U(x)) * (1 + h/2 U''(x)) / (1 + h/2 U''(y)))\n    jac_x = 1.0 + 0.5 * h * hess_U(x, k, lam)\n    jac_y = 1.0 + 0.5 * h * hess_U(y, k, lam)\n    ratio = np.exp(-potential_U(y, k, lam) + potential_U(x, k, lam)) * (jac_x / jac_y)\n    accept = (rng.random()  min(1.0, ratio))\n    return y if accept else x, not accept\n\ndef run_chain(method, k, lam, h, N, seed):\n    rng = np.random.default_rng(seed)\n    x = 0.0\n    rejects = 0\n    if method == 'EM':\n        step_fn = em_propose_accept\n    elif method == 'IM':\n        step_fn = im_propose_accept\n    else:\n        raise ValueError(\"Unknown method\")\n    for _ in range(N):\n        x, rejected = step_fn(x, h, k, lam, rng)\n        rejects += int(rejected)\n    return rejects / N\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (k, lambda, h, N, seed)\n    test_cases = [\n        (100, 0, 0.01, 10000, 123),   # Test Case 1\n        (1000, 0, 0.005, 10000, 456), # Test Case 2\n        (100, 10, 0.004, 10000, 789), # Test Case 3\n        (1000, 50, 0.001, 10000, 42), # Test Case 4\n    ]\n\n    results = []\n    for k, lam, h, N, seed in test_cases:\n        rej_em = run_chain('EM', k, lam, h, N, seed)\n        rej_im = run_chain('IM', k, lam, h, N, seed)\n        results.append(rej_im  rej_em)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3355234"}]}