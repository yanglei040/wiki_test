{"hands_on_practices": [{"introduction": "本练习旨在揭示斯坦变分梯度下降（SVGD）方法的核心机制。通过一个仅包含两个粒子的简化场景，你将亲手计算单步更新，从而具体地观察目标分布的对数梯度（吸引力）和核函数梯度（排斥力）如何共同驱动粒子的运动。这个基础计算是理解 SVGD 背后复杂动态的第一步 [@problem_id:3348310]。", "problem": "考虑斯坦因变分梯度下降（SVGD），该方法通过在再生核希尔伯特空间（RKHS）中的速度场输运粒子分布，对库尔贝克-莱布勒散度执行函数梯度下降。在一维情况下，对于一个可微的目标密度 $p(x)$，作用于标量检验函数 $f$ 上的斯坦因算子为 $T_{p} f(x) = f^{\\prime}(x) + f(x)\\,\\nabla_{x} \\ln p(x)$。设目标为标准正态密度 $p(x) = \\mathcal{N}(0,1)$，并设 RKHS 由带宽参数 $h > 0$ 的径向基函数（RBF）核 $k_{h}(x,x^{\\prime}) = \\exp\\!\\big(-\\frac{(x-x^{\\prime})^{2}}{2 h^{2}}\\big)$ 导出。给定两个初始粒子，其位置为 $x_{1}^{(0)} = -1$ 和 $x_{2}^{(0)} = 2$。使用 SVGD 框架，从斯坦因算子定义和 RKHS 表示性质出发（不假设任何预先给定的闭式更新），推导单次迭代（步长为 $\\epsilon > 0$）的经验 SVGD 粒子更新，然后将更新后的粒子位置 $x_{1}^{(1)}$ 和 $x_{2}^{(1)}$ 明确计算为 $h$ 和 $\\epsilon$ 的解析函数。以精确的闭式形式（无舍入）表示你的最终结果。最终答案必须是一个包含 $x_{1}^{(1)}$ 和 $x_{2}^{(1)}$（作为 $h$ 和 $\\epsilon$ 的函数）的单行向量。", "solution": "用户要求推导斯坦因变分梯度下降（SVGD）的更新规则，并将其应用于一个特定的双粒子系统。\n\n### 步骤 1：问题验证\n根据指定标准验证问题陈述。\n\n- **已知条件**：\n    -   方法：斯坦因变分梯度下降（SVGD）。\n    -   斯坦因算子（$1D$）：$T_{p} f(x) = f^{\\prime}(x) + f(x)\\,\\nabla_{x} \\ln p(x)$。\n    -   目标密度：$p(x) = \\mathcal{N}(0,1)$，标准正态分布。\n    -   再生核希尔伯特空间（RKHS）：由带宽 $h > 0$ 的径向基函数（RBF）核 $k_{h}(x,x^{\\prime}) = \\exp(-\\frac{(x-x^{\\prime})^{2}}{2 h^{2}})$ 导出。\n    -   初始粒子位置：$x_{1}^{(0)} = -1$ 和 $x_{2}^{(0)} = 2$。\n    -   粒子数量：$N=2$。\n    -   迭代步长：$\\epsilon > 0$。\n-   **验证**：\n    -   **具有科学依据：** 该问题使用了来自贝叶斯推断、机器学习和泛函分析（SVGD、KL散度、RKHS、斯坦因方法）的标准、成熟概念。它在科学上是合理的。\n    -   **适定的：** 该问题提供了计算粒子位置唯一的单步更新所需的所有必要信息（目标密度、核函数、初始条件、步长）。\n    -   **客观的：** 问题以精确的技术语言表述，没有主观或模糊的元素。\n    -   问题是自洽的、一致的且可行的。\n\n-   **结论**：问题有效。\n\n### 步骤 2：SVGD 更新规则的推导\n\nSVGD 的目标是通过对粒子应用一个速度场 $\\phi(x)$，将初始粒子分布 $q_0$ 输运到目标分布 $p$。粒子按 $x' = x + \\epsilon \\phi(x)$ 更新。最优速度场 $\\phi(x)$ 是在每一步中最大程度减小库尔贝克-莱布勒（KL）散度 $KL(q_k || p)$ 的那个。这对应于在 RKHS $\\mathcal{H}$ 中对 KL 散度执行函数梯度下降。\n\nKL 散度关于 $\\phi$ 方向扰动的方向导数由下式给出：\n$$ \\nabla_{\\phi} KL(q || p) = - \\mathbb{E}_{x \\sim q}[T_p \\phi(x)] $$\n其中 $T_p$ 是斯坦因算子。为了实现最速下降，我们必须选择 $\\phi$ 来最大化 $\\mathbb{E}_{x \\sim q}[T_p \\phi(x)]$，约束条件是 $\\phi$ 位于 RKHS 的单位球内，即 $\\|\\phi\\|_{\\mathcal{H}} \\le 1$。\n\n表达式 $F[\\phi] = \\mathbb{E}_{x \\sim q}[T_p \\phi(x)]$ 是 $\\phi$ 的一个线性泛函。根据 Riesz 表示定理，对于 RKHS 上的任何此类线性泛函，都存在一个唯一元素 $\\psi_q \\in \\mathcal{H}$，使得对于所有 $\\phi \\in \\mathcal{H}$，都有 $F[\\phi] = \\langle \\phi, \\psi_q \\rangle_{\\mathcal{H}}$。在范数约束下最大化此内积的函数是 $\\phi = \\psi_q / \\|\\psi_q\\|_{\\mathcal{H}}$。因此，最速上升方向由 $\\psi_q$ 给出。\n\n我们可以使用核函数 $k(x, x')$ 的再生性质来找到 $\\psi_q$。对于任何函数 $f \\in \\mathcal{H}$ 和点 $y$，我们有 $f(y) = \\langle f(\\cdot), k(y, \\cdot) \\rangle_{\\mathcal{H}}$。将此应用于 $\\psi_q$：\n$$ \\psi_q(y) = \\langle \\psi_q(\\cdot), k(y, \\cdot) \\rangle_{\\mathcal{H}} $$\n由于内积是对称的，$\\langle f, g \\rangle_{\\mathcal{H}} = \\langle g, f \\rangle_{\\mathcal{H}}$，并且从 $\\psi_q$ 的定义可知 $\\langle k(y, \\cdot), \\psi_q(\\cdot) \\rangle_{\\mathcal{H}} = F[k(y, \\cdot)]$。因此：\n$$ \\psi_q(y) = F[k(y, \\cdot)] = \\mathbb{E}_{x \\sim q}[T_{p,x} k(y, x)] $$\n这里，$T_{p,x}$ 表示斯坦因算子作用于 $k(y,x)$（将其视为其第二个参数 $x$ 的函数）。\n对于对称核 $k(y,x) = k(x,y)$，在点 $y$ 的最优速度场是：\n$$ \\phi^*(y) = \\psi_q(y) = \\mathbb{E}_{x \\sim q}[T_{p,x} k(x,y)] = \\mathbb{E}_{x \\sim q}[\\nabla_x k(x,y) + k(x,y) \\nabla_x \\ln p(x)] $$\n在实践中，对 $q$ 的期望由当前 $N$ 个粒子集合 $\\{x_i\\}_{i=1}^N$ 上的经验平均来近似：\n$$ \\phi(y) \\approx \\frac{1}{N} \\sum_{i=1}^N [\\nabla_{x_i} k(x_i, y) + k(x_i, y) \\nabla_{x_i} \\ln p(x_i)] $$\n粒子 $x_j$ 的 SVGD 更新则为 $x_j^{(t+1)} = x_j^{(t)} + \\epsilon \\phi(x_j^{(t)})$，其中速度场在粒子的当前位置 $x_j^{(t)}$ 处求值：\n$$ \\phi(x_j^{(t)}) = \\frac{1}{N} \\sum_{i=1}^N [\\nabla_{x_i} k(x_i^{(t)}, x_j^{(t)}) + k(x_i^{(t)}, x_j^{(t)}) \\nabla_{x_i} \\ln p(x_i^{(t)})] $$\n\n### 步骤 3：应用于给定问题\n\n我们将推导出的更新规则应用于问题的具体情况。\n1.  **目标分布**：$p(x) = \\mathcal{N}(0,1) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{x^2}{2})$。对数密度为 $\\ln p(x) = -\\frac{x^2}{2} - \\frac{1}{2}\\ln(2\\pi)$。分数函数（对数密度的梯度）为 $\\nabla_x \\ln p(x) = -x$。\n\n2.  **核函数**：RBF 核为 $k(x, x') = \\exp(-\\frac{(x-x')^2}{2h^2})$。其关于第一个参数的梯度为：\n    $$ \\nabla_x k(x, x') = \\frac{\\partial}{\\partial x} \\exp\\left(-\\frac{(x-x')^2}{2h^2}\\right) = \\exp\\left(-\\frac{(x-x')^2}{2h^2}\\right) \\cdot \\left(-\\frac{2(x-x')}{2h^2}\\right) = -k(x,x') \\frac{x-x'}{h^2} $$\n\n3.  **粒子更新方程**：设迭代 $t=0$ 时的粒子位置为 $\\{x_i^{(0)}\\}_{i=1}^N$。粒子 $x_j^{(0)}$ 的速度场为：\n    $$ \\phi(x_j^{(0)}) = \\frac{1}{N} \\sum_{i=1}^N \\left[ -k(x_i^{(0)}, x_j^{(0)}) \\frac{x_i^{(0)} - x_j^{(0)}}{h^2} + k(x_i^{(0)}, x_j^{(0)}) (-x_i^{(0)}) \\right] $$\n    $$ \\phi(x_j^{(0)}) = \\frac{1}{N} \\sum_{i=1}^N k(x_i^{(0)}, x_j^{(0)}) \\left( -\\frac{x_i^{(0)} - x_j^{(0)}}{h^2} - x_i^{(0)} \\right) $$\n\n4.  **初始条件**：我们有 $N=2$ 个粒子，位于 $x_1^{(0)} = -1$ 和 $x_2^{(0)} = 2$。\n\n5.  **计算 $x_1^{(1)}$ 的更新**：设 $j=1$。\n    $$ \\phi(x_1^{(0)}) = \\frac{1}{2} \\left[ k(x_1^{(0)}, x_1^{(0)}) \\left( -\\frac{x_1^{(0)} - x_1^{(0)}}{h^2} - x_1^{(0)} \\right) + k(x_2^{(0)}, x_1^{(0)}) \\left( -\\frac{x_2^{(0)} - x_1^{(0)}}{h^2} - x_2^{(0)} \\right) \\right] $$\n    我们计算各项：\n    -   $x_1^{(0)} = -1$，$x_2^{(0)} = 2$。\n    -   $k(x_1^{(0)}, x_1^{(0)}) = \\exp(0) = 1$。\n    -   $k(x_2^{(0)}, x_1^{(0)}) = \\exp\\left(-\\frac{(2 - (-1))^2}{2h^2}\\right) = \\exp\\left(-\\frac{9}{2h^2}\\right)$。\n    -   $i=1$ 的项：$1 \\cdot (0 - (-1)) = 1$。\n    -   $i=2$ 的项：$\\exp\\left(-\\frac{9}{2h^2}\\right) \\left( -\\frac{2 - (-1)}{h^2} - 2 \\right) = \\exp\\left(-\\frac{9}{2h^2}\\right) \\left( -\\frac{3}{h^2} - 2 \\right)$。\n    速度为：\n    $$ \\phi(x_1^{(0)}) = \\frac{1}{2} \\left[ 1 - \\left( \\frac{3}{h^2} + 2 \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) \\right] $$\n    更新后的粒子位置为：\n    $$ x_1^{(1)} = x_1^{(0)} + \\epsilon \\phi(x_1^{(0)}) = -1 + \\frac{\\epsilon}{2} \\left[ 1 - \\left( 2 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) \\right] $$\n\n6.  **计算 $x_2^{(1)}$ 的更新**：设 $j=2$。\n    $$ \\phi(x_2^{(0)}) = \\frac{1}{2} \\left[ k(x_1^{(0)}, x_2^{(0)}) \\left( -\\frac{x_1^{(0)} - x_2^{(0)}}{h^2} - x_1^{(0)} \\right) + k(x_2^{(0)}, x_2^{(0)}) \\left( -\\frac{x_2^{(0)} - x_2^{(0)}}{h^2} - x_2^{(0)} \\right) \\right] $$\n    我们计算各项：\n    -   $k(x_1^{(0)}, x_2^{(0)}) = \\exp\\left(-\\frac{(-1 - 2)^2}{2h^2}\\right) = \\exp\\left(-\\frac{9}{2h^2}\\right)$。\n    -   $k(x_2^{(0)}, x_2^{(0)}) = 1$。\n    -   $i=1$ 的项：$\\exp\\left(-\\frac{9}{2h^2}\\right) \\left( -\\frac{-1 - 2}{h^2} - (-1) \\right) = \\exp\\left(-\\frac{9}{2h^2}\\right) \\left( \\frac{3}{h^2} + 1 \\right)$。\n    -   $i=2$ 的项：$1 \\cdot (0 - 2) = -2$。\n    速度为：\n    $$ \\phi(x_2^{(0)}) = \\frac{1}{2} \\left[ \\left( \\frac{3}{h^2} + 1 \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) - 2 \\right] $$\n    更新后的粒子位置为：\n    $$ x_2^{(1)} = x_2^{(0)} + \\epsilon \\phi(x_2^{(0)}) = 2 + \\frac{\\epsilon}{2} \\left[ \\left( 1 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) - 2 \\right] $$\n    这可以简化为：\n    $$ x_2^{(1)} = 2 - \\epsilon + \\frac{\\epsilon}{2} \\left( 1 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) $$\n更新后粒子位置的最终表达式为：\n$$ x_1^{(1)} = -1 + \\frac{\\epsilon}{2} \\left[ 1 - \\left( 2 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) \\right] $$\n$$ x_2^{(1)} = 2 - \\epsilon + \\frac{\\epsilon}{2} \\left( 1 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right) $$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-1 + \\frac{\\epsilon}{2} \\left( 1 - \\left(2 + \\frac{3}{h^2}\\right) \\exp\\left(-\\frac{9}{2h^2}\\right) \\right)  2 - \\epsilon + \\frac{\\epsilon}{2} \\left( 1 + \\frac{3}{h^2} \\right) \\exp\\left(-\\frac{9}{2h^2}\\right)\n\\end{pmatrix}\n}\n$$", "id": "3348310"}, {"introduction": "在掌握了基本的粒子更新规则后，我们将深入探讨粒子间的相互作用动态。SVGD 的一个关键优势在于其内在的排斥机制能有效防止粒子坍缩到同一点，从而更好地捕捉多峰分布。本练习将通过推导吸引力与排斥力达到平衡的临界条件，让你从量化的角度理解 SVGD 如何维持粒子多样性 [@problem_id:3348300]。", "problem": "考虑斯坦因变分梯度下降 (SVGD)，它由一个泛函梯度流定义，该梯度流通过输运一组粒子来近似目标密度 $p(x)$。对于 $\\mathbb{R}^{d}$ 中的一个包含 $n$ 个粒子的有限集合 $\\{x_{i}\\}_{i=1}^{n}$，在粒子 $x_{i}$ 处的经验 SVGD 速度为\n$$\n\\phi(x_{i}) \\;=\\; \\frac{1}{n} \\sum_{j=1}^{n} \\Big( k(x_{j},x_{i}) \\,\\nabla \\ln p(x_{j}) \\;+\\; \\nabla_{x_{j}} k(x_{j},x_{i}) \\Big),\n$$\n其中 $k(x,y)$ 是一个正定核，$\\nabla$ 表示关于其参数的梯度。在 SVGD 中，第一项是朝向高密度区域的吸引力，第二项是分散粒子的排斥力。令核函数为高斯径向基函数 (RBF) 核 $k(x,y) = \\exp\\!\\big(-\\|x-y\\|^{2}/(2 h^{2})\\big)$，其带宽 $h0$。\n\n任务 A (排斥力的尺度变化)：在一维空间 ($d=1$) 中，对于位于 $x_{1}$ 和 $x_{2}$ 的两个粒子 ($n=2$)，其粒子间距离为 $d = |x_{1}-x_{2}|$，请推导出来自 $x_{2}$ 对 $x_{1}$ 速度的成对排斥贡献的大小，该大小应表示为 $d$ 和 $h$ 的函数。您必须仅使用 $d$ 和 $h$ 以闭式形式表达该结果。\n\n任务 B (模式坍塌的量化避免)：考虑一维高斯目标 $p(x) = \\mathcal{N}(0,\\sigma^{2})$，其方差 $\\sigma^{2}  0$。将两个粒子 ($n=2$) 对称地放置在 $x_{1}=a$ 和 $x_{2}=-a$ 处，其中 $a0$。仅使用上述 SVGD 定义和给定的 RBF 核，计算使 $x_{1}$ 处的 SVGD 速度的径向分量朝外（即增大 $|a|$）的精确条件。然后，求解唯一的临界距离 $a_{c}(h,\\sigma)$，在该距离下 $x_{1}$ 处的径向 SVGD 速度恰好为零。您的最终答案必须是关于 $a_{c}(h,\\sigma)$ 的单个闭式解析表达式，不包含未求值的极限或隐式定义。\n\n答案格式要求：最终答案仅提供 $a_{c}(h,\\sigma)$ 的解析表达式。不包含单位。无需四舍五入。", "solution": "用户提供了一个关于斯坦因变分梯度下降 (SVGD) 性质的有效问题陈述。该问题具有科学依据，问题设定良好，并包含了进行严谨数学推导所需的所有必要信息。我将着手给出一个完整的解答。\n\n该问题分为两个任务。我将按顺序解决它们，以得出最终所需的临界距离 $a_{c}(h, \\sigma)$ 的表达式。\n\n首先，让我们建立必要的数学组件。\n粒子 $x_i$ 处的 SVGD 速度由下式给出：\n$$ \\phi(x_{i}) = \\frac{1}{n} \\sum_{j=1}^{n} \\left( k(x_{j},x_{i}) \\nabla \\ln p(x_{j}) + \\nabla_{x_{j}} k(x_{j},x_{i}) \\right) $$\n核函数是一维 ($d=1$) 高斯 RBF 核：\n$$ k(x,y) = \\exp\\left(-\\frac{(x-y)^2}{2h^2}\\right) $$\n核函数对其第一个参数 $x_j$ 的梯度为：\n$$ \\nabla_{x_{j}} k(x_{j},x_{i}) = \\frac{\\partial}{\\partial x_j} \\exp\\left(-\\frac{(x_j-x_i)^2}{2h^2}\\right) = \\exp\\left(-\\frac{(x_j-x_i)^2}{2h^2}\\right) \\cdot \\left(-\\frac{2(x_j-x_i)}{2h^2}\\right) = -\\frac{x_j-x_i}{h^2} k(x_j,x_i) $$\n\n**任务 A：排斥力的尺度变化**\n\n此任务要求计算来自粒子 $x_2$ 对粒子 $x_1$ 速度的成对排斥贡献的大小。粒子数为 $n=2$。排斥贡献是速度更新中涉及核函数梯度的部分。对于速度 $\\phi(x_1)$，对应于 $j=2$ 的项包含来自 $x_2$ 的排斥力。该贡献由 $\\frac{1}{n} \\nabla_{x_2} k(x_2, x_1)$ 给出。\n\n使用 $n=2$ 和上面计算的导数：\n$$ \\text{来自 } x_2 \\text{ 对 } x_1 \\text{ 的排斥力} = \\frac{1}{2} \\nabla_{x_2} k(x_2, x_1) = \\frac{1}{2} \\left( -\\frac{x_2-x_1}{h^2} k(x_2, x_1) \\right) = \\frac{x_1-x_2}{2h^2} k(x_1, x_2) $$\n问题要求的是这一项的大小。令 $d = |x_1 - x_2|$。核函数 $k(x_1, x_2)$ 始终为正。\n$$ k(x_1, x_2) = \\exp\\left(-\\frac{(x_1-x_2)^2}{2h^2}\\right) = \\exp\\left(-\\frac{d^2}{2h^2}\\right) $$\n因此，其大小为：\n$$ \\left| \\frac{x_1-x_2}{2h^2} k(x_1, x_2) \\right| = \\frac{|x_1-x_2|}{2h^2} k(x_1, x_2) = \\frac{d}{2h^2} \\exp\\left(-\\frac{d^2}{2h^2}\\right) $$\n该表达式表示一个粒子对另一个粒子施加的排斥力的大小，它是粒子间距 $d$ 和核函数带宽 $h$ 的函数。\n\n**任务 B：模式坍塌的量化避免**\n\n此任务要求我们在一个特定设置下找到临界距离 $a_c(h, \\sigma)$。\n给定的设置为：\n- 维度：$d=1$。\n- 粒子数：$n=2$。\n- 粒子位置：$x_1 = a$ 和 $x_2 = -a$，其中 $a  0$。\n- 目标密度：$p(x) = \\mathcal{N}(0, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$。\n\n我们首先计算对数目标密度的梯度：\n$$ \\ln p(x) = -\\ln(\\sqrt{2\\pi}\\sigma) - \\frac{x^2}{2\\sigma^2} $$\n$$ \\nabla \\ln p(x) = \\frac{d}{dx} \\ln p(x) = -\\frac{x}{\\sigma^2} $$\n在粒子位置处，我们有：\n$$ \\nabla \\ln p(x_1) = \\nabla \\ln p(a) = -\\frac{a}{\\sigma^2} $$\n$$ \\nabla \\ln p(x_2) = \\nabla \\ln p(-a) = -\\frac{-a}{\\sigma^2} = \\frac{a}{\\sigma^2} $$\n\n接下来，我们计算在 $x_1 = a$ 处的 SVGD 速度。速度表达式为：\n$$ \\phi(x_1) = \\frac{1}{2} \\left[ \\left( k(x_1, x_1) \\nabla\\ln p(x_1) + \\nabla_{x_1} k(x_1, x_1) \\right) + \\left( k(x_2, x_1) \\nabla\\ln p(x_2) + \\nabla_{x_2} k(x_2, x_1) \\right) \\right] $$\n我们计算和中的每一项：\n\n第 1 项 (与自身的相互作用, $j=1$)：\n- $k(x_1, x_1) = k(a,a) = \\exp(0) = 1$。\n- $\\nabla\\ln p(x_1) = -a/\\sigma^2$。\n- $\\nabla_{x_1} k(x_1, x_1) = -\\frac{x_1-x_1}{h^2} k(x_1,x_1) = 0$。\n因此，方括号中的第一项是 $(1 \\cdot (-a/\\sigma^2) + 0) = -a/\\sigma^2$。\n\n第 2 项 (与 $x_2$ 的相互作用, $j=2$)：\n- $x_2 - x_1 = -a - a = -2a$。\n- $k(x_2, x_1) = k(-a, a) = \\exp\\left(-\\frac{(-2a)^2}{2h^2}\\right) = \\exp\\left(-\\frac{2a^2}{h^2}\\right)$。\n- $\\nabla\\ln p(x_2) = a/\\sigma^2$。\n- $\\nabla_{x_2} k(x_2, x_1) = -\\frac{x_2-x_1}{h^2} k(x_2, x_1) = -\\frac{-2a}{h^2} \\exp\\left(-\\frac{2a^2}{h^2}\\right) = \\frac{2a}{h^2} \\exp\\left(-\\frac{2a^2}{h^2}\\right)$。\n所以，方括号中的第二项是：\n$$ \\exp\\left(-\\frac{2a^2}{h^2}\\right) \\cdot \\left(\\frac{a}{\\sigma^2}\\right) + \\frac{2a}{h^2} \\exp\\left(-\\frac{2a^2}{h^2}\\right) = \\exp\\left(-\\frac{2a^2}{h^2}\\right) \\left( \\frac{a}{\\sigma^2} + \\frac{2a}{h^2} \\right) $$\n\n现在，我们组合出 $\\phi(x_1)$ 的完整表达式：\n$$ \\phi(x_1) = \\frac{1}{2} \\left[ -\\frac{a}{\\sigma^2} + \\exp\\left(-\\frac{2a^2}{h^2}\\right) \\left( \\frac{a}{\\sigma^2} + \\frac{2a}{h^2} \\right) \\right] $$\n提出因子 $a/2$：\n$$ \\phi(x_1) = \\frac{a}{2} \\left[ -\\frac{1}{\\sigma^2} + \\exp\\left(-\\frac{2a^2}{h^2}\\right) \\left( \\frac{1}{\\sigma^2} + \\frac{2}{h^2} \\right) \\right] $$\n临界距离 $a_c$ 定义为使速度为零的 $a$ 值，即 $\\phi(x_1) = 0$。由于给定 $a0$，我们需要方括号内的项为零。令 $a = a_c$：\n$$ -\\frac{1}{\\sigma^2} + \\exp\\left(-\\frac{2a_c^2}{h^2}\\right) \\left( \\frac{1}{\\sigma^2} + \\frac{2}{h^2} \\right) = 0 $$\n$$ \\exp\\left(-\\frac{2a_c^2}{h^2}\\right) \\left( \\frac{1}{\\sigma^2} + \\frac{2}{h^2} \\right) = \\frac{1}{\\sigma^2} $$\n$$ \\exp\\left(-\\frac{2a_c^2}{h^2}\\right) = \\frac{1/\\sigma^2}{1/\\sigma^2 + 2/h^2} $$\n为了简化右边部分，我们通分：\n$$ \\frac{1/\\sigma^2}{(h^2 + 2\\sigma^2)/(\\sigma^2 h^2)} = \\frac{1}{\\sigma^2} \\cdot \\frac{\\sigma^2 h^2}{h^2 + 2\\sigma^2} = \\frac{h^2}{h^2 + 2\\sigma^2} $$\n关于 $a_c$ 的方程是：\n$$ \\exp\\left(-\\frac{2a_c^2}{h^2}\\right) = \\frac{h^2}{h^2 + 2\\sigma^2} $$\n为了求解 $a_c$，我们对两边取自然对数：\n$$ -\\frac{2a_c^2}{h^2} = \\ln\\left(\\frac{h^2}{h^2 + 2\\sigma^2}\\right) $$\n使用属性 $\\ln(x/y) = -\\ln(y/x)$：\n$$ \\frac{2a_c^2}{h^2} = \\ln\\left(\\frac{h^2 + 2\\sigma^2}{h^2}\\right) = \\ln\\left(1 + \\frac{2\\sigma^2}{h^2}\\right) $$\n现在，我们求解 $a_c^2$：\n$$ a_c^2 = \\frac{h^2}{2} \\ln\\left(1 + \\frac{2\\sigma^2}{h^2}\\right) $$\n由于 $a  0$，我们取正平方根：\n$$ a_c(h, \\sigma) = \\sqrt{\\frac{h^2}{2} \\ln\\left(1 + \\frac{2\\sigma^2}{h^2}\\right)} $$\n这可以写作：\n$$ a_c(h, \\sigma) = h \\sqrt{\\frac{1}{2} \\ln\\left(1 + \\frac{2\\sigma^2}{h^2}\\right)} $$\n这就是使 $x_1=a$ 处 SVGD 速度为零的唯一临界距离。对于 $a  a_c$，项 $\\exp(-2a^2/h^2)$ 更大，使得速度为正（向外的排斥力占主导）。对于 $a  a_c$，速度为负（朝向 $x=0$ 处模式的向内吸引力占主导）。", "answer": "$$ \\boxed{h \\sqrt{\\frac{1}{2} \\ln\\left(1 + \\frac{2\\sigma^2}{h^2}\\right)}} $$", "id": "3348300"}, {"introduction": "理解算法的力学和动态特性之后，评估其在实际应用中的计算成本至关重要。本练习将焦点转向 SVGD 的可扩展性问题，你将分析标准“密集”实现的计算时间和内存复杂度。此外，该练习还引导你探索如何利用随机傅里叶特征（Random Fourier Features, RFF）等近似方法，来降低算法的计算开销，使其能够应用于大规模问题 [@problem_id:3348282]。", "problem": "考虑斯坦因变分梯度下降 (SVGD)，它更新一组 $n$ 个粒子 $\\{x_i\\}_{i=1}^n \\subset \\mathbb{R}^d$，试图使用由斯坦因算子和正定核 $k(x, x')$ 构建的确定性变换，将经验测度传输到目标密度 $p(x)$。在迭代 $t$ 时对粒子 $x_i$ 的 SVGD 更新可以表示为向量场 $\\phi(x)$ 的形式：$x_i^{(t+1)} = x_i^{(t)} + \\epsilon \\,\\phi(x_i^{(t)})$，其中 $\\phi(x)$ 是由施加于 $k$ 和 $\\nabla \\log p(x)$ 的斯坦因算子在所有粒子上的经验期望构建的，并且其中每个成对的核求值和核梯度都是密集计算的。假设计算一个粒子的分数函数 $\\nabla \\log p(x)$ 需要 $d$ 数量级的算术运算。\n\n对于一个可微的、位移不变的核 $k(x, x') = k(x - x')$，一种随机傅里叶特征 (RFF) 近似使用 $m$ 个特征来近似 $k$，通过 $k(x, x') \\approx z(x)^\\top z(x')$，其中 $z(x) \\in \\mathbb{R}^m$ 是通过从 $k$ 的谱测度中抽取的随机频率构建的。核关于粒子坐标的梯度通过对特征求导获得，使用 $\\nabla_x k(x, x') \\approx \\nabla_x z(x)^\\top z(x')$。您可以假设，当随机频率被预先计算并存储时，为一个粒子计算 $z(x)$ 和 $\\nabla_x z(x)$ 需要 $md$ 数量级的算术运算。\n\n使用密集核求值，计算有 $n$ 个粒子和维度 $d$ 的 SVGD 的每次迭代的时间和内存复杂度，用 $n$ 和 $d$ 表示。然后，为位移不变核提出一个使用 $m$ 个特征的通过随机傅里叶特征 (RFF) 的次二次方近似，并推导基于 RFF 的 SVGD 的每次迭代的时间和内存复杂度，用 $n$、 $d$ 和 $m$ 表示。陈述在什么条件下，对于固定的 $d$，基于 RFF 的复杂度在 $n$ 上是次二次方的。\n\n选择正确描述所有这些复杂度和条件的选项。\n\nA. 密集 SVGD 的每次迭代时间为 $O(n^2 d) + O(n d)$ 且内存为 $O(n d) + O(n^2)$。使用 $m$ 个随机傅里叶特征，每次迭代的时间为 $O(n m d)$ 且内存为 $O(n d) + O(n m) + O(m d)$；对于固定的 $d$，只要 $m = o(n)$，这在 $n$ 上就是次二次方的。\n\nB. 密集 SVGD 的每次迭代时间为 $O(n^2) + O(d)$ 且内存为 $O(n^2 d)$。使用 $m$ 个随机傅里叶特征，每次迭代的时间为 $O(n^2)$ 且内存为 $O(n m)$；RFF 不会产生 $n$ 上的次二次方区域。\n\nC. 密集 SVGD 的每次迭代时间为 $O(n d)$ 且内存为 $O(n d)$。使用 $m$ 个随机傅里叶特征，每次迭代的时间为 $O(n m d)$ 且内存为 $O(n d) + O(m)$；当 $m$ 为常数时，该方法在 $n$ 上是次二次方的。\n\nD. 密集 SVGD 的每次迭代时间为 $O(n^2 d)$ 且内存为 $O(n d)$。使用 $m$ 个随机傅里叶特征，每次迭代的时间为 $O(n m)$ 且内存为 $O(n m)$；无论 $m$ 为何值，该方法在 $n$ 上总是次二次方的。\n\nE. 密集 SVGD 的每次迭代时间为 $O(n^2 d)$ 且内存为 $O(n^2 d)$。使用 $m$ 个随机傅里叶特征，每次迭代的时间为 $O(n m d) + O(n^2)$ 且内存为 $O(n d)$；RFF 不会将渐近时间复杂度降低到二次方以下。", "solution": "用户想要对斯坦因变分梯度下降 (SVGD) 的每次迭代的时间和内存复杂度进行详细分析，包括其密集形式和使用随机傅里叶特征 (RFF) 近似的形式。\n\n### 问题验证\n\n**第一步：提取已知条件**\n-   算法：斯坦因变分梯度下降 (SVGD)。\n-   粒子：$\\mathbb{R}^d$ 中的 $n$ 个粒子 $\\{x_i\\}_{i=1}^n$。\n-   目标密度：$p(x)$。\n-   更新规则：$x_i^{(t+1)} = x_i^{(t)} + \\epsilon \\,\\phi(x_i^{(t)})$。\n-   速度场 $\\phi(x)$：由施加于核 $k(x, x')$ 和分数函数 $\\nabla \\log p(x)$ 的斯坦因算子在粒子上的经验期望构建。\n-   密集求值：所有粒子对的核值 $k(x_i, x_j)$ 和核梯度均被密集计算。\n-   分数函数成本：计算一个粒子的 $\\nabla \\log p(x)$ 成本为 $O(d)$。\n-   RFF 近似：对于位移不变核 $k(x, x') = k(x-x')$，使用 $m$ 个特征的近似由 $k(x, x') \\approx z(x)^\\top z(x')$ 给出，其中 $z(x) \\in \\mathbb{R}^m$。\n-   RFF 梯度近似：$\\nabla_{x'}k(x, x') \\approx (\\nabla_{x'}z(x'))^\\top z(x)$。\n-   RFF 特征成本：为一个粒子计算 $z(x)$ 及其雅可比矩阵 $\\nabla_x z(x)$ 的成本为 $O(md)$。\n\n**第二步：使用提取的已知条件进行验证**\n问题陈述具有科学依据，描述了机器学习和计算统计领域中的一个标准算法 (SVGD) 和一个常见的近似技术 (RFF)。其表述与已有的文献一致。问题是适定的，为基本操作（分数函数的成本为 $O(d)$，RFF 特征的成本为 $O(md)$）提供了成本模型，这足以进行标准的大O复杂度分析。所使用的语言客观而精确。该问题没有违反任何无效标准（它不是不健全、不可形式化、不完整、不切实际、不适定、微不足道或不可验证的）。\n\n**第三步：结论和行动**\n问题是有效的。我将继续推导解决方案。\n\n### 复杂度推导\n\n**第一部分：密集 SVGD 复杂度**\n\nSVGD 中粒子 $x_i$ 的速度场由经验平均给出：\n$$ \\phi(x_i) = \\frac{1}{n} \\sum_{j=1}^n \\left[ k(x_i, x_j) \\nabla_{x_j} \\log p(x_j) + \\nabla_{x_j} k(x_i, x_j) \\right] $$\n其中 $\\nabla_{x_j} k(x_i, x_j)$ 是核关于其第二个参数的梯度，在 $x_j$ 处求值。\n\n**时间复杂度（密集 SVGD）：**\n1.  **分数计算**：我们必须首先计算所有 $j \\in \\{1, \\dots, n\\}$ 的分数函数 $\\nabla_{x_j} \\log p(x_j)$。由于每次计算成本为 $O(d)$，总成本为 $O(nd)$。这 $n$ 个向量可以被存储。\n2.  **速度计算**：为了计算单个粒子 $i$ 的速度 $\\phi(x_i)$，我们必须对所有 $j \\in \\{1, \\dots, n\\}$ 进行求和。\n    *   对于每对 $(i, j)$，我们计算求和内的项。\n    *   计算核 $k(x_i, x_j)$ 需要 $O(d)$ 时间（例如，对于RBF核，这涉及距离计算）。\n    *   分数 $\\nabla_{x_j} \\log p(x_j)$ 已经计算好。标量-向量乘积 $k(x_i, x_j) \\nabla_{x_j} \\log p(x_j)$ 需要 $O(d)$ 时间。\n    *   计算核梯度 $\\nabla_{x_j} k(x_i, x_j)$ 也需要 $O(d)$ 时间。\n    *   将得到的两个 $d$ 维向量相加需要 $O(d)$ 时间。\n    *   因此，计算单个 $j$ 的项成本为 $O(d)$。\n    *   对于固定的 $i$，对所有 $n$ 个粒子求和的成本为 $n \\times O(d) = O(nd)$。\n3.  **总速度计算**：由于我们必须为所有 $i \\in \\{1, \\dots, n\\}$ 计算 $\\phi(x_i)$，总成本为 $n \\times O(nd) = O(n^2 d)$。\n4.  **粒子更新**：更新所有 $n$ 个粒子位置 $x_i \\leftarrow x_i + \\epsilon \\phi(x_i)$ 需要 $n \\times O(d) = O(nd)$。\n\n总的每次迭代时间复杂度是这些成本的总和：$O(nd) + O(n^2 d) + O(nd) = O(n^2 d)$。这可以写成 $O(n^2 d) + O(nd)$。\n\n**内存复杂度（密集 SVGD）：**\n1.  **粒子**：存储位置 $\\{x_i\\}_{i=1}^n$ 需要 $O(nd)$ 内存。\n2.  **分数**：存储预先计算的分数 $\\{\\nabla_{x_j} \\log p(x_j)\\}_{j=1}^n$ 需要 $O(nd)$ 内存。\n3.  **核矩阵**：一个“密集”求值通常意味着计算并存储完整的 $n \\times n$ 核矩阵 $K$，其中 $K_{ij} = k(x_i, x_j)$。这需要 $O(n^2)$ 的内存。虽然如果值在需要时重新计算则不是绝对必要的，但这是一种常见的实现策略。\n4.  **速度**：存储计算出的速度 $\\{\\phi(x_i)\\}_{i=1}^n$ 需要 $O(nd)$ 内存。\n\n主要的内存项是粒子和核矩阵。总内存复杂度为 $O(nd) + O(n^2)$。\n\n**第二部分：RFF 近似的 SVGD 复杂度**\n\n使用 RFF 近似 $k(x, x') \\approx z(x)^\\top z(x')$，梯度近似变为 $\\nabla_{x'}k(x, x') \\approx (\\nabla_{x'}z(x'))^\\top z(x)$。将这些代入 $\\phi(x_i)$ 的 SVGD 更新中：\n$$ \\phi(x_i) \\approx \\frac{1}{n} \\sum_{j=1}^n \\left[ (z(x_i)^\\top z(x_j)) \\nabla_{x_j} \\log p(x_j) + (\\nabla_{x_j}z(x_j))^\\top z(x_i) \\right] $$\n这个表达式可以通过提取 $z(x_i)$ 来重新排列：\n$$ \\phi(x_i) \\approx \\left(\\frac{1}{n} \\sum_{j=1}^n \\left[ \\nabla_{x_j} \\log p(x_j) \\, z(x_j)^\\top + \\nabla_{x_j}z(x_j) \\right]\\right)^\\top z(x_i) $$\n令 $S_j = \\nabla_{x_j} \\log p(x_j)$ 为 $d \\times 1$ 的分数向量。令 $V$ 为 $m \\times d$ 的矩阵，定义为：\n$$ V = \\frac{1}{n} \\sum_{j=1}^n \\left[ z(x_j) S_j^\\top + \\nabla_{x_j}z(x_j) \\right] $$\n然后速度可以计算为 $\\phi(x_i) \\approx V^\\top z(x_i)$。\n\n**时间复杂度 (RFF-SVGD)：**\n这种表述避免了二次方的成对交互。计算分阶段进行：\n1.  **预处理**：计算所有 $j$ 的分数 $S_j$：$O(nd)$。存储用于 RFF 的预计算随机频率。\n2.  **计算矩阵 V**：\n    *   将 $V$ 初始化为大小为 $m \\times d$ 的零矩阵。\n    *   从 $j=1$ 到 $n$ 循环：\n        *   计算 $z(x_j)$ 及其雅可比矩阵 $\\nabla_{x_j}z(x_j)$。根据问题陈述，这需要 $O(md)$ 的成本。\n        *   计算外积 $z(x_j)S_j^\\top$，一个 $m \\times d$ 矩阵。这需要 $O(md)$ 的成本。\n        *   将此项和 $\\nabla_{x_j}z(x_j)$ 加到 $V$ 中。这需要 $O(md)$ 的成本。\n    *   此循环的总成本为 $n \\times O(md) = O(nmd)$。\n3.  **计算速度**：\n    *   对于每个粒子 $i=1$ 到 $n$：\n        *   计算 $z(x_i)$，成本为 $O(md)$。（或者，可以一次性计算所有 $i$ 的这些值并存储）。\n        *   计算矩阵-向量乘积 $\\phi(x_i) = V^\\top z(x_i)$。这是一个 $(d \\times m) \\times (m \\times 1)$ 的乘积，成本为 $O(md)$。\n    *   总成本为 $n \\times O(md) = O(nmd)$。更有效的方法是计算所有特征的矩阵 $Z \\in \\mathbb{R}^{n \\times m}$，总成本为 $O(nmd)$。然后计算完整的速度矩阵 $\\Phi = ZV$，这是一个 $(n \\times m) \\times (m \\times d)$ 的乘法，成本为 $O(nmd)$。\n4.  **粒子更新**：更新所有 $n$ 个粒子：$O(nd)$。\n\n总的每次迭代时间复杂度为 $O(nd) + O(nmd) + O(nmd) + O(nd) = O(nmd)$。\n\n**内存复杂度 (RFF-SVGD)：**\n1.  **粒子和分数**：$\\{x_i\\}$ 需要 $O(nd)$，$\\{S_j\\}$ 需要 $O(nd)$。\n2.  **RFF 频率**：要生成特征 $z(x)$，我们需要存储 $m$ 个随机频率向量，每个向量大小为 $d$。这需要 $O(md)$ 内存。\n3.  **特征矩阵**：为了通过矩阵乘法高效地计算最终速度，我们必须存储所有粒子的特征向量，形成一个矩阵 $Z \\in \\mathbb{R}^{n \\times m}$。这需要 $O(nm)$ 内存。\n4.  **中间矩阵**：必须存储矩阵 $V \\in \\mathbb{R}^{m \\times d}$，需要 $O(md)$ 内存。\n\n总内存复杂度是这些需求的总和：$O(nd) + O(md) + O(nm)$。\n\n**第三部分：次二次方复杂度的条件**\n\n目标是使基于 RFF 的方法的时间复杂度在粒子数量 $n$ 方面渐近地优于（次二次方）密集方法。\n*   密集时间复杂度：$O(n^2 d)$。\n*   RFF 时间复杂度：$O(nmd)$。\n\n为了使 RFF 版本在 $n$ 上是次二次方的，我们需要：\n$$ nmd = o(n^2 d) $$\n假设 $d$ 是固定的，我们可以将其简化为：\n$$ nm = o(n^2) $$\n两边除以 $n$（对于 $n0$），我们得到条件：\n$$ m = o(n) $$\n这意味着特征数量 $m$ 的增长速度必须慢于粒子数量 $n$。\n\n### 逐项分析\n\n*   **A. 密集 SVGD 的每次迭代时间为 $O(n^2 d) + O(n d)$ 且内存为 $O(n d) + O(n^2)$。使用 $m$ 个随机傅里叶特征，每次迭代的时间为 $O(n m d)$ 且内存为 $O(n d) + O(n m) + O(m d)$；对于固定的 $d$，只要 $m = o(n)$，这在 $n$ 上就是次二次方的。**\n    *   **密集 SVGD**：时间 $O(n^2 d) + O(nd) = O(n^2 d)$ 是正确的。内存 $O(nd) + O(n^2)$ 在密集核矩阵计算的标准解释下是正确的。\n    *   **RFF-SVGD**：时间 $O(nmd)$ 是正确的。内存 $O(nd) + O(nm) + O(md)$ 是正确的。\n    *   **条件**：$m=o(n)$ 是正确的条件。\n    *   **结论**：**正确**。\n\n*   **B. 密集 SVGD 的每次迭代时间为 $O(n^2) + O(d)$ 且内存为 $O(n^2 d)$。使用 $m$ 个随机傅里叶特征，每次迭代的时间为 $O(n^2)$ 且内存为 $O(n m)$；RFF 不会产生 $n$ 上的次二次方区域。**\n    *   **密集 SVGD**：时间 $O(n^2) + O(d)$ 不正确；它漏掉了因子 $d$。内存 $O(n^2 d)$ 对应于存储所有成对梯度，这是可能的，但是一种内存开销过大的实现方式，不如存储核矩阵标准。\n    *   **RFF-SVGD**：时间 $O(n^2)$ 不正确。内存 $O(nm)$ 不完整。\n    *   **条件**：声称不存在次二次方区域是错误的。\n    *   **结论**：**不正确**。\n\n*   **C. 密集 SVGD 的每次迭代时间为 $O(n d)$ 且内存为 $O(n d)$。使用 $m$ 个随机傅里叶特征，每次迭代的时间为 $O(n m d)$ 且内存为 $O(n d) + O(m)$；当 $m$ 为常数时，该方法在 $n$ 上是次二次方的。**\n    *   **密集 SVGD**：时间 $O(nd)$ 不正确；它忽略了 $O(n^2)$ 的成对交互。\n    *   **RFF-SVGD**：RFF 内存 $O(nd) + O(m)$ 不正确；它忽略了关键的 $O(nm)$ 项。条件 $m$ 是常数只是通用条件 $m=o(n)$ 的一个特例。\n    *   **结论**：**不正确**。\n\n*   **D. 密集 SVGD 的每次迭代时间为 $O(n^2 d)$ 且内存为 $O(n d)$。使用 $m$ 个随机傅里叶特征，每次迭代的时间为 $O(n m)$ 且内存为 $O(n m)$；无论 $m$ 为何值，该方法在 $n$ 上总是次二次方的。**\n    *   **密集 SVGD**：内存 $O(nd)$ 仅在不存储核矩阵的内存优化实现中是正确的。\n    *   **RFF-SVGD**：时间 $O(nm)$ 不正确；它漏掉了因子 $d$。内存 $O(nm)$ 不完整。\n    *   **条件**：声称它“总是次二次方的”是错误的。如果 $m = \\Omega(n)$，复杂度就不是次二次方的。\n    *   **结论**：**不正确**。\n\n*   **E. 密集 SVGD 的每次迭代时间为 $O(n^2 d)$ 且内存为 $O(n^2 d)$。使用 $m$ 个随机傅里叶特征，每次迭代的时间为 $O(n m d) + O(n^2)$ 且内存为 $O(n d)$；RFF 不会将渐近时间复杂度降低到二次方以下。**\n    *   **密集 SVGD**：如选项 B 所述，内存 $O(n^2 d)$ 很可能是不正确的。\n    *   **RFF-SVGD**：时间 $O(nmd) + O(n^2)$ 不正确；RFF 重构的全部意义就在于消除 $O(n^2)$ 项。声称 RFF 不降低复杂度的说法也是错误的。\n    *   **结论**：**不正确**。\n\n基于详细的推导，选项 A 提供了对所有复杂度和次二次方性能条件的完整而准确的描述。", "answer": "$$\\boxed{A}$$", "id": "3348282"}]}