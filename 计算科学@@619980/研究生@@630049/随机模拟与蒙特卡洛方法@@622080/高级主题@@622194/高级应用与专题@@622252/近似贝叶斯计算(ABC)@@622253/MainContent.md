## 引言
[贝叶斯推断](@entry_id:146958)是现代科学中一块强大的基石，它使我们能够根据观测数据来更新我们对世界模型的信念。这一过程的核心是似然函数——连接模型参数与观测数据的数学桥梁。然而，在许多科学前沿，从宇宙学的大尺度模拟到群体遗传学的演化历程，我们面临着一个共同的困境：我们能构建出极其逼真的计算机模型来*生成*数据，却无法写出这个关键的似然函数。当这座“贝叶斯之桥”断裂时，传统的推断方法便束手无策。

本文旨在系统性地介绍近似贝叶斯计算（Approximate Bayesian Computation, ABC），一种为解决此类“无[似然](@entry_id:167119)”问题而生的革命性方法。它巧妙地绕开了直接计算似然的需要，通过模拟和比较来近似后验分布。

在接下来的内容中，我们将分三步深入探索ABC的世界。首先，在“原理与机制”一章中，我们将揭示ABC从一个简单直观的拒绝算法，到演化为高效的MCMC和SMC变体的核心思想，并剖析其近似性的来源。接着，在“应用与跨学科连接”一章中，我们将领略ABC如何在[群体遗传学](@entry_id:146344)、宇宙学、系统生物学等多个领域中解锁复杂系统的秘密，并进行[模型选择](@entry_id:155601)。最后，“动手实践”部分将提供具体的练习，帮助您将理论知识转化为实践技能。

让我们首先深入其内部，理解ABC是如何在没有[似然函数](@entry_id:141927)的情况下，重建通往后验推断之路的。

## 原理与机制

想象一下贝叶斯推断的宏伟画卷：我们怀着对世界运作方式的初步信念（**先验**），然后我们观察数据（**证据**），并据此更新我们的信念，得到一个更为精确的认识（**后验**）。这幅画卷的核心，是连接信念与证据的桥梁——**似然函数** $p(x|\theta)$。它告诉我们，在给定的参数 $\theta$ 下，观察到数据 $x$ 的可能性有多大。只要有了这座桥，我们就能通过贝叶斯定理 $\pi(\theta|x) \propto p(x|\theta) \pi(\theta)$，让数据“告诉”我们参数最可能是什么。

但如果这座桥断了呢？

### 似然的迷失：当贝叶斯之桥断裂

在许多科学前沿领域，我们面临着一种奇特的困境：我们能够根据物理定律编写出复杂的计算机程序来*模拟*数据，却无法写出似然函数的解析表达式。这些模型被称为**隐式**或**生成式模型**。想象一下，在宇宙学中，科学家们可以输入一套[宇宙学参数](@entry_id:161338)（如暗物质密度、[宇宙膨胀](@entry_id:161474)速率等），然后通过庞大的数值模拟，生成一片模拟的星系[分布](@entry_id:182848) [@problem_id:3489611]。我们能启动这个“宇宙制造机”并得到一个输出 $x = g(\theta, u)$（其中 $u$ 代表所有随机因素，如初始条件的[量子涨落](@entry_id:154889)），但我们无法回答“对于这组特定的参数 $\theta$，观测到我们真实宇宙的星系[分布](@entry_id:182848) $x_{obs}$ 的概率究竟是多少？”。

这个概率，也就是似然 $p(x_{obs}|\theta)$，之所以难以捉摸，可能是因为从参数到数据的过程包含了无数复杂的、[非线性](@entry_id:637147)的相互作用，或者因为似然函数涉及一个维度极高、无法计算的积分（即归一化常数）。从数学的严格意义上讲，当模拟器的输出被限制在一个比数据空间维度更低的[数据流形](@entry_id:636422)上时，[似然](@entry_id:167119)*密度*函数本身甚至可能不存在 [@problem_id:3489611]。

无论如何，没有了似然函数这座桥梁，经典的贝叶斯推断方法便无计可施。我们仿佛拥有一个能制造出完美蛋糕的魔法烤箱，却丢失了它的食谱。我们能品尝蛋糕（观测数据），却无法通过蛋糕反推出配料的精确比例（模型参数）。这就是**近似贝叶斯计算 (ABC)** 诞生的背景：它要做的，就是在[似然](@entry_id:167119)之桥断裂时，重建一条通往后验的路径。

### 一个简单而“野蛮”的想法：拒绝算法

面对无法计算[似然](@entry_id:167119)的困境，让我们回归最质朴的想法。既然我们能从模型中生成数据，那何不利用这个能力呢？我们可以提出一个最简单直接的“暴力”策略：

1.  从**[先验分布](@entry_id:141376)** $\pi(\theta)$ 中随机抽取一个参数候选值 $\theta^*$。
2.  使用这个 $\theta^*$ 和我们的模拟器，生成一个模拟数据集 $x_{sim}$。
3.  比较 $x_{sim}$ 和我们真实观测到的数据 $x_{obs}$。如果它们“看起来很像”，我们就保留这个 $\theta^*$，认为它是一个不错的参数；否则，就扔掉它。
4.  重复这个过程成千上万次，收集所有被保留的 $\theta^*$，它们就构成了对后验分布的一个近似。

这个想法非常直观，但“看起来很像”这个说法太模糊了，必须被精确化。

首先，什么是“像”？最严格的定义是“完全相同”，即 $x_{sim} = x_{obs}$。但这对于连续数据或高维数据来说，几乎是不可能完成的任务。两次模拟不可能产生两个一模一样的高维输出，其发生的概率为零。因此，我们必须放宽标准。我们引入一个**容忍度** $\epsilon$，并定义一个**距离** $\rho(\cdot, \cdot)$。只要模拟数据与真实数据的距离小于这个容忍度，即 $\rho(x_{sim}, x_{obs}) \le \epsilon$，我们就认为它们足够“像”并接受它。

其次，直接比较整个高维数据集（比如一张宇宙微波背景辐射的图像）既计算昂贵，又会遭遇“维度灾难”——在高维空间中，所有点都倾向于彼此远离，使得任何两个点都“不太像”。一个更聪明的做法是，我们不比较原始数据，而是比较它们的低维**摘要统计量** (summary statistic) $s(x)$。这些统计量应该能抓住数据的关键特征。于是，我们的接受准则变成了 $\rho(s(x_{sim}), s(x_{obs})) \le \epsilon$。

综合这两点，我们就得到了最基础的[ABC算法](@entry_id:746190)——**拒绝算法**。它虽然简单，甚至有些“野蛮”，但它抓住了一个深刻的核心：通过模拟并筛选，我们实际上是在近似一个目标分布。这个由ABC方法定义的目标后验可以被正式地写为 [@problem_id:3288743]：
$$
\pi_\epsilon(\theta \mid s_{obs}) \propto \pi(\theta) \int K_\epsilon(\rho(s(x),s_{obs}))p(x\mid\theta)\\,dx
$$
这里的 $K_\epsilon$ 是一个**核函数**，它根据模拟摘要与观测摘要的距离来赋予权重。最简单的均匀核（或称“硬截断”核）就对应于我们上面的拒绝算法：当距离小于 $\epsilon$ 时权重为1，否则为0 [@problem_id:3288743]。这个积分项 $\int K_\epsilon(\dots)p(x|\theta)dx$ 就是ABC对真实似然的替代品，我们称之为**ABC似然**。

### “近似”的代价：两种近似的根源

ABC这个名字里的“近似”二字，并非空穴来风。它坦诚地告诉我们，为了绕开难解的[似然](@entry_id:167119)，我们付出了两种代价，引入了两个层次的近似。

#### 近似 1：容忍度 $\epsilon > 0$

选择一个非零的容忍度 $\epsilon$，意味着我们接受的模拟数据并非与观测数据完美匹配。这会给我们的推断带来什么样的影响呢？

这里有一个非常优美的诠释——**卷积诠释** (convolution interpretation) [@problem_id:3288759]。ABC的平滑过程，在数学上等价于一个思想实验：我们假装正在对一个*被扰动过的模型*进行**精确的**[贝叶斯推断](@entry_id:146958)。在这个假想模型中，我们的观测值 $s_{obs}$ 并非直接来自模拟器，而是模拟器产生的“真实”摘要 $s(x)$ 再加上一个随机噪声 $\eta_\epsilon$ 的结果，即 $s_{obs} = s(x) + \eta_\epsilon$。而ABC中使用的[核函数](@entry_id:145324) $K_\epsilon$ 正好定义了这个假想噪声 $\eta_\epsilon$ 的[分布](@entry_id:182848)。

这个概念可以通过一个具体的例子变得无比清晰 [@problem_id:3288811]。假设我们已知数据的摘要统计量 $s(x)$ 服从均值为 $\theta$、[方差](@entry_id:200758)为 $\sigma^2/n$ 的[正态分布](@entry_id:154414)，即 $s(x) \sim \mathcal{N}(\theta, \sigma^2/n)$。如果我们选择一个[方差](@entry_id:200758)为 $\epsilon^2$ 的高斯核 $K_\epsilon$ 来进行ABC，那么经过推导，我们得到的ABC[似然函数](@entry_id:141927)恰好是一个新的正态分布，其均值仍为 $\theta$，但[方差](@entry_id:200758)扩大为 $(\frac{\sigma^2}{n} + \epsilon^2)$。
$$
L_{\epsilon}(\bar{y} \mid \theta) = \frac{1}{\sqrt{2\pi\left(\frac{\sigma^{2}}{n} + \epsilon^{2}\right)}} \,\exp\left(-\frac{(\bar{y} - \theta)^{2}}{2\left(\frac{\sigma^{2}}{n} + \epsilon^{2}\right)}\right)
$$
这完美地揭示了ABC的本质：容忍度 $\epsilon$ 相当于人为地给我们的模型注入了噪声，使得我们推断出的后验分布比应有的更宽、更不确定。

这直接导向了一个核心的**[偏差-方差权衡](@entry_id:138822)** (bias-variance tradeoff) [@problem_id:3288819]。当 $\epsilon$ 较大时，接受模拟变得容易，我们能用较少的计算量获得大量样本，从而降低估计后验的**[蒙特卡洛](@entry_id:144354)[方差](@entry_id:200758)**；但代价是引入了更大的**偏差**，因为我们的近似模型（带噪声的模型）与真实模型相去甚远。反之，减小 $\epsilon$ 可以降低偏差，使我们的结果更接近理想情况，但会导致接受率急剧下降，计算成本飙升，蒙特卡洛[方差](@entry_id:200758)增大。如何选择合适的 $\epsilon$ 成了ABC实践中的一门艺术。

#### 近似 2：摘要统计量 $s(x)$

第二个近似的来源是我们决定使用摘要统计量 $s(x)$ 而不是全部数据 $x$。这个决策的初衷是为了降低维度和计算量，但它可能导致一个更根本的问题：**信息损失**。

为了理解这一点，我们需要引入**充分统计量** (sufficient statistic) 的概念 [@problem_id:3288740]。一个统计量之所以被称为“充分的”，是因为它已经捕获了数据中关于未知参数 $\theta$ 的**全部**信息。一旦知道了充分统计量的值，原始数据本身对于推断 $\theta$ 就不再提供任何额外的信息。

这对ABC意味着什么呢？

-   如果幸运地，我们选择的摘要统计量 $s(x)$ 是参数 $\theta$ 的充分统计量，那么当我们把容忍度 $\epsilon$ 趋近于0时，ABC的[后验分布](@entry_id:145605) $\pi_\epsilon(\theta|s_{obs})$ 会精确地收敛于真实的后验分布 $\pi(\theta|x_{obs})$ [@problem_id:3288743] [@problem_id:3288740]。在这种理想情况下，唯一的近似误差来源就是由有限样本数量造成的[蒙特卡洛](@entry_id:144354)误差。

-   然而，在绝大多数复杂问题中，找到一个既低维又充分的统计量是极其困难的，我们使用的几乎都是**不充分**的统计量。这时，即便我们将 $\epsilon$ 降为0，ABC后验收敛的目标也不再是真正的后验 $\pi(\theta|x_{obs})$，而是基于摘要统计量所含信息的一个替代后验 $\pi(\theta|s_{obs})$ [@problem_id:3288740] [@problem_id:3288743]。因为我们从一开始就通过摘要“扔掉”了一部分信息，所以无论后续计算多么精确，这部分信息都无法被找回。

一个经典的例子可以阐明这一点 [@problem_id:3288740]：对于正态分布 $\mathcal{N}(\theta, \sigma^2)$（已知 $\sigma^2$），样本均值 $\bar{x}$ 是均值参数 $\theta$ 的充分统计量。但如果我们选择样本[中位数](@entry_id:264877)作为摘要统计量，它就不是充分的。使用[中位数](@entry_id:264877)进行ABC，即使 $\epsilon \to 0$，我们得到的后验分布也会比使用样本均值得到的真实后验更宽，不确定性更大。这正是信息损失的代价。我们可以利用**[费雪信息](@entry_id:144784)** (Fisher Information) 这样的工具来量化这种信息损失，精确计算出因为选择某个摘要统计量我们究竟“支付”了多少信息作为代价 [@problem_id:3288754]。

### 从蛮力到巧思：高级ABC机制

基础的拒绝算法虽然概念清晰，但其效率极其低下。尤其当模型复杂或我们追求一个较小的 $\epsilon$ 时，绝大多数模拟都会被拒绝，接受率可能低到令人绝望，使得算法在实际中不可行。这促使研究者们开发了更智能、更高效的[ABC算法](@entry_id:746190)。

#### [ABC-MCMC](@entry_id:746188) ([马尔可夫链蒙特卡洛](@entry_id:138779))

拒绝算法每次都从头开始，从先验中抽取 $\theta$，这就像在黑暗中随机撒网。一个更聪明的策略是，我们能否在[参数空间](@entry_id:178581)中进行一次“智能”的[随机游走](@entry_id:142620)，倾向于停留在那些能够产生与观测数据匹配的模拟的“好”区域？

这就是**[ABC-MCMC](@entry_id:746188)**背后的思想 [@problem_id:3288820]。它将ABC嵌入了强大的[马尔可夫链蒙特卡洛 (MCMC)](@entry_id:137985) 框架中。在标准的MCMC（如[Metropolis-Hastings算法](@entry_id:146870)）中，我们需要计算[似然比](@entry_id:170863)来决定是否接受一次移动。在[ABC-MCMC](@entry_id:746188)中，我们用ABC[似然](@entry_id:167119)的一个**无偏估计**来代替这个难解的[似然](@entry_id:167119)。这个估计通常是通过在每个MCMC步骤中，对提议的参数 $\theta^*$ 进行少数几次（比如 $R$ 次）模拟得到的。

这里的精妙之处在于，只要我们用来替代似然的估计量是**无偏的**（即其期望等于真实的ABC[似然](@entry_id:167119)），那么整个MCMC过程在理论上就能保证其最终采样的[边际分布](@entry_id:264862)恰好是我们想要的ABC后验 $\pi_\epsilon(\theta|s_{obs})$ [@problem_id:3288820]。[估计量的方差](@entry_id:167223)大小不会影响最终目标的正确性，但它会极大地影响算法的效率（即[马尔可夫链](@entry_id:150828)的混合速度）。实践中存在一个最优的[平衡点](@entry_id:272705)，研究表明，当[对数似然](@entry_id:273783)估计的[方差](@entry_id:200758)在1附近时，算法效率通常最高。

#### SMC-ABC ([序贯蒙特卡洛](@entry_id:147384))

[ABC-MCMC](@entry_id:746188)像一个孤独的探索者在[参数空间](@entry_id:178581)中游走，而**SMC-ABC**则更像一次集体智慧的演化 [@problem_id:3536601]。它不是维护单个参数，而是维护一个由大量参数“粒子”组成的**种群** $\{\theta_i, w_i\}$。

SMC-ABC的过程是分阶段（“序贯”）进行的：

1.  **初始化 (t=0):** 从[先验分布](@entry_id:141376)中抽取一大批粒子，此时的容忍度 $\epsilon_0$ 设为无穷大，所有粒子都被接受。

2.  **迭代演化 (t > 0):** 在每个后续阶段 $t$，算法会收紧容忍度，即 $\epsilon_t  \epsilon_{t-1}$。
    -   **重加权:** 根据粒子在上一阶段 $\epsilon_{t-1}$ 下的表现（即其模拟与观测的匹配程度），重新计算每个粒子的权重。
    -   **[重采样](@entry_id:142583):** 根据新的权重对粒子种群进行重采样。表现好的粒子（权重高）会被多次复制，而表现差的粒子（权重低）则可能被淘汰。
    -   **扰动:** 对重采样后的粒子进行轻微的随机“[抖动](@entry_id:200248)”（通过一个扰动核），让它们在各自的位置附近进行探索，产生新的候选粒子。
    -   **筛选:** 用新的、更严格的容忍度 $\epsilon_t$ 来检验这些新粒子。只有通过筛选的粒子才能存活到下一阶段。

通过这一系列“优胜劣汰、适者生存”的步骤，整个粒子种群仿佛一个漏斗，被逐步地引导和汇聚到后验分布中概率密度最高的区域。这使得在高维空间中找到满足极小 $\epsilon$ 的参数成为可能，极大地提高了算法的效率 [@problem_id:3536601]。理论分析甚至可以指导我们如何设计最优的 $\epsilon$ [退火方案](@entry_id:165208) $\epsilon_n \propto n^{-\alpha}$，以在偏差和计算成本之间取得最佳平衡 [@problem_id:3288750]。

从最简单的[拒绝采样](@entry_id:142084)，到更高效的MCMC和SMC变体，ABC的发展本身就是一场关于如何在信息不完整时进行有效推断的智慧之旅。它始于一个简单直观的想法，通过对近似来源的深刻理解，最终演化成一套强大而灵活的现代统计推断工具箱。