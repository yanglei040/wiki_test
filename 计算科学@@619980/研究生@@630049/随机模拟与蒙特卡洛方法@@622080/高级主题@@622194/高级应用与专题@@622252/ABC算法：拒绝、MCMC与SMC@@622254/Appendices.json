{"hands_on_practices": [{"introduction": "虽然基础的近似贝叶斯计算（ABC）功能强大，但其准确性受到容差 $\\epsilon$ 的限制。本练习深入探讨了回归校正ABC，这是一种减少这种近似误差的先进技术。通过分析该方法的偏差 [@problem_id:3286932]，我们可以更深刻地理解如何从模拟中获得更精确的后验推断，并量化非线性关系所引入的残余误差。", "problem": "考虑一个近似贝叶斯计算 (ABC) 问题，其中包含一个标量参数 $\\,\\theta\\,$、一个标量摘要统计量 $\\,S\\,$ 和一个观测到的摘要 $\\,s_{0}\\,$。设先验为 $\\,\\pi(\\theta)\\,$，数据生成机制导出条件密度 $\\,f_{S\\mid\\theta}(s\\mid\\theta)\\,$。将带核加权的 ABC 后验定义为\n$$\np_{\\epsilon}(\\theta\\mid s_{0}) \\propto \\pi(\\theta) \\int K_{\\epsilon}(s - s_{0}) f_{S\\mid\\theta}(s\\mid\\theta)\\,ds,\\qquad K_{\\epsilon}(u) = \\frac{1}{\\epsilon} K\\!\\left(\\frac{u}{\\epsilon}\\right),\n$$\n其中 $\\,K\\,$ 是一个对称核，满足 $\\,\\int_{\\mathbb{R}} K(u)\\,du = 1\\,$、$\\,\\int_{\\mathbb{R}} u K(u)\\,du = 0\\,$，且具有有限二阶矩 $\\,\\mu_{2}(K) \\equiv \\int_{\\mathbb{R}} u^{2} K(u)\\,du  \\infty\\,$。考虑 Beaumont 等人提出的回归调整 ABC 方法，该方法从联合 $\\,\\pi(\\theta) f_{S\\mid\\theta}(s\\mid\\theta)\\,$ 中模拟独立对 $\\,(\\theta_{i}, S_{i})\\,$，分配权重 $\\,w_{i} \\propto K_{\\epsilon}(S_{i}-s_{0})\\,$，对 $\\,\\theta\\,$ 关于 $\\,S\\,$ 在 $\\,s_{0}\\,$ 附近进行局部线性加权最小二乘回归拟合，\n$$\n(\\hat{\\alpha}, \\hat{\\beta}) \\in \\arg\\min_{\\alpha,\\beta} \\sum_{i=1}^{n} w_{i}\\,\\big(\\theta_{i} - \\alpha - \\beta\\,(S_{i}-s_{0})\\big)^{2},\n$$\n并形成调整值 $\\,\\theta_{i}^{\\star} = \\theta_{i} - \\hat{\\beta}\\,(S_{i}-s_{0})\\,$。回归调整的 ABC 后验即为 $\\,\\{\\theta_{i}^{\\star}\\}\\,$ 的加权经验分布。\n\n假设以下基本条件成立：\n\n- 先验 $\\,\\pi(\\theta)\\,$ 在真实后验支撑集的一个邻域上是连续且为正的。\n- 边缘密度 $\\,g(s) = \\int \\pi(\\theta) f_{S\\mid\\theta}(s\\mid\\theta)\\,d\\theta\\,$ 在 $\\,s_{0}\\,$ 处是二阶连续可微且严格为正的。\n- 条件均值函数 $\\,m(s) \\equiv \\mathbb{E}[\\theta\\mid S=s]\\,$ 在 $\\,s_{0}\\,$ 的一个邻域内是二阶连续可微的，并且条件方差 $\\,\\nu(s) \\equiv \\operatorname{Var}(\\theta\\mid S=s)\\,$ 在 $\\,s_{0}\\,$ 处是连续的。\n- 模拟大小 $\\,n\\,$ 随 $\\,\\epsilon\\,$ 增长，使得当 $\\,\\epsilon \\to 0\\,$ 时 $\\,n\\epsilon \\to \\infty\\,$，以确保随机误差相对于平滑偏差可以忽略不计。\n\nA 部分（线性条件下的收敛性）：假设对于 $\\,s_{0}\\,$ 邻域内的 $\\,s\\,$，条件分布 $\\,\\theta\\mid S=s\\,$ 的均值为 $\\,m(s) = \\alpha_{0} + \\beta_{0}\\,s\\,$（其中 $\\,\\alpha_{0},\\beta_{0}\\in\\mathbb{R}\\,$ 为常数），方差 $\\,\\nu(s) \\equiv \\nu_{0}\\,$ 为常数，并且 $\\,\\theta\\mid S=s\\,$ 在弱收敛意义下对 $\\,s\\,$ 是连续的。从上述定义出发，推导回归调整的 ABC 后验 $\\,p_{\\epsilon}^{\\mathrm{adj}}(\\theta\\mid s_{0})\\,$ 在 $\\,\\epsilon \\to 0\\,$ 时依全变分收敛于精确后验 $\\,p(\\theta\\mid S=s_{0})\\,$ 的条件。\n\nB 部分（非线性条件下的主导偏差）：现在去掉精确线性的假设，改为假设 $\\,m(s)\\,$ 在 $\\,s_{0}\\,$ 处是二阶连续可微的，其中 $\\,m''(s_{0})\\,$ 可能非零，并且 $\\,\\nu(s)\\,$ 在 $\\,s_{0}\\,$ 处是连续的。证明回归调整的 ABC 后验均值 $\\,\\mathbb{E}_{\\epsilon}^{\\mathrm{adj}}[\\theta\\mid s_{0}]\\,$ 具有如下展开式\n$$\n\\mathbb{E}_{\\epsilon}^{\\mathrm{adj}}[\\theta\\mid s_{0}] \\;=\\; m(s_{0}) \\;+\\; B\\,\\epsilon^{2} \\;+\\; o(\\epsilon^{2}) \\qquad \\text{as } \\epsilon \\to 0,\n$$\n并以闭式形式表示主导偏差系数 $\\,B\\,$，用 $\\,m''(s_{0})\\,$ 和上面定义的核二阶矩 $\\,\\mu_{2}(K)\\,$ 来表示。你的最终答案应仅为 $\\,B\\,$ 的解析表达式，写成最简精确形式。不要在最终答案中提供中间步骤。", "solution": "该问题研究了回归调整的近似贝叶斯计算 (ABC) 后验分布的性质。我们在线性假设下分析其向真实后验的收敛性（A 部分），并在非线性条件下推导其均值的主阶偏差（B 部分）。该分析依赖于模拟次数 $n \\to \\infty$ 且容差 $\\epsilon \\to 0$ 使得 $n\\epsilon \\to \\infty$ 的渐近状态。此条件允许我们用总体期望替代蒙特卡洛平均，从而将核平滑引入的偏差与模拟引入的方差分离开来。\n\n在这个总体极限下，函数 $H(\\theta, S)$ 的加权平均由关于一个核加权的伪后验密度的期望给出。\n$$\n\\mathbb{E}_{w}[H(\\theta, S)] = \\frac{\\iint H(\\theta, s) K_{\\epsilon}(s-s_0) p(\\theta, s) d\\theta ds}{\\iint K_{\\epsilon}(s-s_0) p(\\theta, s) d\\theta ds}\n$$\n其中 $p(\\theta, s) = \\pi(\\theta)f_{S|\\theta}(s|\\theta) = p(\\theta|s)g(s)$ 是 $(\\theta, S)$ 的联合密度。该期望可以使用迭代期望来简化：\n$$\n\\mathbb{E}_{w}[H(\\theta, S)] = \\frac{\\int \\mathbb{E}[H(\\theta, S) | S=s] K_{\\epsilon}(s-s_0) g(s) ds}{\\int K_{\\epsilon}(s-s_0) g(s) ds}\n$$\n这表明 ABC 过程计算了在观测摘要 $s_0$ 附近的条件期望的核加权平均值。\n\n**A 部分：线性条件下的收敛性**\n\n目标是推导当 $\\epsilon \\to 0$ 时，回归调整的 ABC 后验 $p_{\\epsilon}^{\\mathrm{adj}}(\\theta\\mid s_{0})$ 依全变分收敛于精确后验 $p(\\theta\\mid S=s_{0})$ 的条件。\n\n此部分的给定假设是：\n1.  条件均值是线性的：$m(s) \\equiv \\mathbb{E}[\\theta\\mid S=s] = \\alpha_0 + \\beta_0 s$，其中 $\\alpha_0, \\beta_0$ 为常数。这可以重写为 $m(s) = m(s_0) + \\beta_0(s-s_0)$，其中 $m(s_0) = \\alpha_0 + \\beta_0 s_0$。\n2.  条件方差是常数：$\\nu(s) \\equiv \\operatorname{Var}(\\theta\\mid S=s) = \\nu_0$。\n3.  $\\theta\\mid S=s$ 的条件分布在弱收敛意义下对 $s$ 是连续的。\n\n回归调整涉及将采样的 $\\theta_i$ 值移动 $\\hat{\\beta}(S_i-s_0)$。在总体极限下，$\\hat{\\beta}$ 收敛于\n$$\n\\beta^* = \\frac{\\operatorname{Cov}_w(\\theta, S)}{\\operatorname{Var}_w(S)} = \\frac{\\mathbb{E}_w[\\theta(S-s_0)] - \\mathbb{E}_w[\\theta]\\mathbb{E}_w[S-s_0]}{\\mathbb{E}_w[(S-s_0)^2] - (\\mathbb{E}_w[S-s_0])^2}\n$$\n在线性假设 $m(s)$ 下，我们可以分析 $\\beta^*$。分子的主导项是\n$\\mathbb{E}_w[\\theta(S-s_0)] = \\mathbb{E}_w[\\mathbb{E}[\\theta|S](S-s_0)] = \\mathbb{E}_w[m(S)(S-s_0)] = \\mathbb{E}_w[(m(s_0) + \\beta_0(S-s_0))(S-s_0)] = m(s_0)\\mathbb{E}_w[S-s_0] + \\beta_0\\mathbb{E}_w[(S-s_0)^2]$。\n因此，协方差是\n$\\operatorname{Cov}_w(\\theta, S) = m(s_0)\\mathbb{E}_w[S-s_0] + \\beta_0\\mathbb{E}_w[(S-s_0)^2] - \\mathbb{E}_w[\\theta]\\mathbb{E}_w[S-s_0]$。\n当 $\\epsilon \\to 0$ 时，标准核平滑结果表明 $\\mathbb{E}_w[\\theta] \\to m(s_0)$。更详细的计算（如 B 部分所示）表明 $\\mathbb{E}_w[\\theta] = m(s_0) + O(\\epsilon^2)$ 且 $\\mathbb{E}_w[S-s_0] = O(\\epsilon^2)$。\n协方差变为 $\\operatorname{Cov}_w(\\theta, S) \\approx \\beta_0 \\mathbb{E}_w[(S-s_0)^2]$。\n方差为 $\\operatorname{Var}_w(S) \\approx \\mathbb{E}_w[(S-s_0)^2]$。\n因此，当 $\\epsilon \\to 0$ 时，$\\beta^* \\to \\beta_0$。局部线性回归一致地估计了真实斜率 $\\beta_0$。\n\n调整后的样本为 $\\theta_i^\\star = \\theta_i - \\hat{\\beta}(S_i-s_0)$。在总体极限下，我们考虑调整后变量 $\\theta^\\star = \\theta - \\beta_0(S-s_0)$ 的分布。让我们分析其在 $s_0$ 邻域内的 $s$ 上以 $S=s$ 为条件的性质。\n调整后变量的条件均值为：\n$$\n\\mathbb{E}[\\theta^\\star | S=s] = \\mathbb{E}[\\theta - \\beta_0(S-s_0) | S=s] = m(s) - \\beta_0(s-s_0)\n$$\n使用线性假设 $m(s) = m(s_0) + \\beta_0(s-s_0)$，这可以简化为：\n$$\n\\mathbb{E}[\\theta^\\star | S=s] = (m(s_0) + \\beta_0(s-s_0)) - \\beta_0(s-s_0) = m(s_0)\n$$\n调整后变量的条件方差为：\n$$\n\\operatorname{Var}(\\theta^\\star | S=s) = \\operatorname{Var}(\\theta - \\beta_0(S-s_0) | S=s) = \\operatorname{Var}(\\theta | S=s) = \\nu(s)\n$$\n使用常数方差假设 $\\nu(s) = \\nu_0$，我们得到：\n$$\n\\operatorname{Var}(\\theta^\\star | S=s) = \\nu_0\n$$\n因此，调整后变量 $\\theta^\\star$ 的条件均值和方差在 $s_0$ 邻域内的所有 $s$ 上都是常数。它们等于真实后验的均值和方差，即 $m(s_0)$ 和 $\\nu(s_0) = \\nu_0$。\n\n回归调整的 ABC 后验 $p_\\epsilon^{\\mathrm{adj}}(\\theta^\\star|s_0)$ 是条件分布 $\\theta^\\star | S=s$ 的核加权平均。设 $f_{\\theta^\\star|S}(\\cdot|s)$ 是给定 $S=s$ 时 $\\theta^\\star$ 的条件密度。那么，\n$$\np_\\epsilon^{\\mathrm{adj}}(t|s_0) = \\frac{\\int f_{\\theta^\\star|S}(t|s) K_\\epsilon(s-s_0)g(s)ds}{\\int K_\\epsilon(s-s_0)g(s)ds}\n$$\n当 $\\epsilon \\to 0$ 时，核 $K_\\epsilon(s-s_0)$ 将其质量集中在 $s=s_0$ 处。鉴于 $g(s)$ 的连续性以及 $\\theta|S=s$ 条件分布的弱连续性假设（这在温和条件下意味着 $f_{\\theta^\\star|S}(t|s)$ 作为 $s$ 的函数对于固定的 $t$ 是连续的），该积分收敛于被积函数在 $s_0$ 处的值。\n$$\n\\lim_{\\epsilon \\to 0} p_\\epsilon^{\\mathrm{adj}}(t|s_0) = f_{\\theta^\\star|S}(t|s_0)\n$$\n$\\theta^\\star|S=s_0$ 的分布是给定 $S=s_0$ 时 $\\theta - \\beta_0(s_0-s_0) = \\theta$ 的分布。这正是真实的后验分布 $p(\\theta|S=s_0)$。\n\n因此，回归调整后验的密度逐点收敛于真实后验的密度。在适当的正则性条件下（例如，由基本条件蕴含的一致可积性），密度的逐点收敛蕴含了 $L_1$ 收敛，这等价于全变分收敛。\n\n因此，此收敛成立的条件是：\n1.  条件均值的线性：$m(s) = \\alpha_0 + \\beta_0 s$。\n2.  同方差性（恒定的条件方差）：$\\nu(s) = \\nu_0$。\n3.  条件分布 $\\theta|S=s$ 对 $s$ 的连续性（例如，在弱收敛意义下）。\n这些条件确保了回归调整产生一个量 $\\theta^\\star$，其分布在 $s_0$ 附近基本上是“枢轴的”（即独立于 $s$），因此最后的核平均步骤能够正确地恢复在 $s_0$ 处的分布。\n\n**B 部分：非线性条件下的主导偏差**\n\n我们现在去掉线性和常数方差的假设，推导回归调整后验均值 $\\mathbb{E}_{\\epsilon}^{\\mathrm{adj}}[\\theta\\mid s_{0}]$ 的主导偏差项。\n调整后的后验均值是（在总体极限下）：\n$$\n\\mathbb{E}_{\\epsilon}^{\\mathrm{adj}}[\\theta\\mid s_{0}] = \\mathbb{E}_w[\\theta] - \\beta^* \\mathbb{E}_w[S-s_0]\n$$\n我们需要找到每一项到 $\\epsilon^2$ 阶的展开式。我们使用核平滑的标准渐近结果。对于一个平滑函数 $f(s)$，其在 $s_0$ 附近的核加权平均具有如下展开式：\n$$\n\\mathbb{E}_w[f(S)] = \\frac{\\int f(s) K_\\epsilon(s-s_0)g(s)ds}{\\int K_\\epsilon(s-s_0)g(s)ds} = f(s_0) + \\frac{\\epsilon^2}{2}\\mu_2(K)\\left(f''(s_0)+2f'(s_0)\\frac{g'(s_0)}{g(s_0)}\\right) + o(\\epsilon^2)\n$$\n这是 Nadaraya-Watson 估计量在 $s_0$ 处对 $f(s)$ 的偏差。\n\n首先，我们通过设置 $f(s) = m(s)$ 来找到 $\\mathbb{E}_w[\\theta]$ 的展开式：\n$$\n\\mathbb{E}_w[\\theta] = m(s_0) + \\frac{\\epsilon^2}{2}\\mu_2(K)\\left(m''(s_0)+2m'(s_0)\\frac{g'(s_0)}{g(s_0)}\\right) + o(\\epsilon^2)\n$$\n这是未调整的 ABC 后验的均值。\n\n接下来，我们通过设置 $f(s) = s-s_0$ 来找到 $\\mathbb{E}_w[S-s_0]$ 的展开式。这里，$f(s_0)=0$, $f'(s)=1$, $f''(s)=0$。\n$$\n\\mathbb{E}_w[S-s_0] = 0 + \\frac{\\epsilon^2}{2}\\mu_2(K)\\left(0+2(1)\\frac{g'(s_0)}{g(s_0)}\\right) + o(\\epsilon^2) = \\mu_2(K)\\frac{g'(s_0)}{g(s_0)}\\epsilon^2 + o(\\epsilon^2)\n$$\n现在我们分析 $\\beta^* = \\operatorname{Cov}_w(\\theta, S) / \\operatorname{Var}_w(S)$。如 A 部分所计算，$\\beta^*$ 收敛于 $m'(s_0)$。更详细的计算表明，修正项的阶为 $\\epsilon^2$，所以 $\\beta^* = m'(s_0) + O(\\epsilon^2)$。这对我们的目的来说已经足够。\n\n我们现在可以组合出调整后后验均值的表达式：\n$$\n\\mathbb{E}_{\\epsilon}^{\\mathrm{adj}}[\\theta\\mid s_{0}] = \\underbrace{\\left( m(s_0) + \\frac{\\epsilon^2}{2}\\mu_2(K)\\left(m''(s_0)+2m'(s_0)\\frac{g'(s_0)}{g(s_0)}\\right) + o(\\epsilon^2) \\right)}_{\\mathbb{E}_w[\\theta]} \\\\ - \\underbrace{\\left( m'(s_0) + O(\\epsilon^2) \\right)}_{\\beta^*} \\underbrace{\\left( \\mu_2(K)\\frac{g'(s_0)}{g(s_0)}\\epsilon^2 + o(\\epsilon^2) \\right)}_{\\mathbb{E}_w[S-s_0]}\n$$\n现在，我们展开并合并 $\\epsilon^2$ 阶的项：\n$$\n\\mathbb{E}_{\\epsilon}^{\\mathrm{adj}}[\\theta\\mid s_{0}] = m(s_0) + \\frac{\\epsilon^2}{2}\\mu_2(K)m''(s_0) + \\epsilon^2\\mu_2(K)m'(s_0)\\frac{g'(s_0)}{g(s_0)} - m'(s_0)\\mu_2(K)\\frac{g'(s_0)}{g(s_0)}\\epsilon^2 + o(\\epsilon^2)\n$$\n包含 $g'(s_0)$ 的项相互抵消：\n$$\n\\epsilon^2\\mu_2(K)m'(s_0)\\frac{g'(s_0)}{g(s_0)} - m'(s_0)\\mu_2(K)\\frac{g'(s_0)}{g(s_0)}\\epsilon^2 = 0\n$$\n这给我们留下了均值的最终表达式：\n$$\n\\mathbb{E}_{\\epsilon}^{\\mathrm{adj}}[\\theta\\mid s_{0}] = m(s_0) + \\frac{1}{2} m''(s_0) \\mu_2(K) \\epsilon^2 + o(\\epsilon^2)\n$$\n这展示了局部线性回归调整的一个关键优势：主导偏差项不依赖于边缘密度 $g(s)$ 的导数，使得估计相对于摘要统计量的分布更加稳定。\n\n从这个展开式中，我们可以确定主导偏差系数 $B$。\n$$\nB = \\frac{1}{2}m''(s_0)\\mu_2(K)\n$$", "answer": "$$ \\boxed{\\frac{1}{2}m''(s_{0})\\mu_{2}(K)} $$", "id": "3286932"}, {"introduction": "比较不同的科学模型是贝叶斯统计中的一个核心任务。本练习探讨了一种常见但存在缺陷的方法，即使用ABC接受率来近似贝叶斯因子。通过批判性地分析为什么这种朴素的方法会失败 [@problem_id:3286937]，我们揭示了摘要统计量在确保模型间有效比较方面所起的决定性作用，并强调了在模型选择中保持摘要统计量一致的重要性。", "problem": "考虑两个相互竞争的模型 $M_{1}$ 和 $M_{2}$，用于描述数据 $y \\in \\mathcal{Y}$。在模型 $M_{j}$下，参数为 $\\theta_{j} \\in \\Theta_{j}$，其先验密度为 $\\pi_{j}(\\theta_{j})$，数据 $y$ 的似然函数为 $p(y \\mid \\theta_{j}, M_{j})$。比较 $M_{1}$ 和 $M_{2}$ 的贝叶斯因子定义为 $BF_{12} = \\dfrac{m(y \\mid M_{1})}{m(y \\mid M_{2})}$，其中 $m(y \\mid M_{j}) = \\int_{\\Theta_{j}} p(y \\mid \\theta_{j}, M_{j}) \\, \\pi_{j}(\\theta_{j}) \\, d\\theta_{j}$。\n\n对每个模型 $M_{j}$ 分别运行一个近似贝叶斯计算（ABC）拒绝采样器，过程如下：抽取 $\\theta_{j} \\sim \\pi_{j}(\\theta_{j})$，模拟 $x \\sim p(\\cdot \\mid \\theta_{j}, M_{j})$，计算一个模型特定的摘要统计量 $s_{j}(x) \\in \\mathbb{R}^{k_{j}}$，如果距离 $d_{j}\\!\\left(s_{j}(x), s_{j}(y)\\right)$ 小于或等于一个容差 $\\epsilon_{j} > 0$，则接受模拟出的 $x$。令 $\\widehat{\\alpha}_{j}$ 表示模型 $M_{j}$ 在大量提议下得到的经验接受率，并假设我们打算用比率 $\\widehat{\\alpha}_{1} / \\widehat{\\alpha}_{2}$ 来近似 $BF_{12}$。\n\n假设 $d_{j}$ 是由 $\\mathbb{R}^{k_{j}}$ 上的范数导出的，并且接受规则是指示是否属于范数球 $B_{k_{j}}(s_{j}(y), \\epsilon_{j}) = \\{u \\in \\mathbb{R}^{k_{j}} : \\|u - s_{j}(y)\\| \\le \\epsilon_{j}\\}$ 的指示函数。考虑渐近情况 $\\epsilon_{j} \\to 0$ 以及有足够多的提议，使得 $\\widehat{\\alpha}_{j}$ 中的蒙特卡洛误差可以忽略不计。不同模型的摘要统计量 $s_{j}$ 可能不同，其维度也可能不同，$k_{1} \\neq k_{2}$。\n\n关于使用 $\\widehat{\\alpha}_{1} / \\widehat{\\alpha}_{2}$ 来近似 $BF_{12}$，以下哪些陈述是正确的？\n\nA. 如果两个模型使用相同的摘要统计量 $s$、相同的维度 $k$、相同的范数和容差 $\\epsilon$，并且 $s$ 满足以下条件：对于每个 $j \\in \\{1, 2\\}$，边际似然可以分解为 $m(y \\mid M_{j}) = g(y) \\, m_{s}\\!\\left(s(y) \\mid M_{j}\\right)$，其中 $g(y)$ 与 $j$无关，那么当 $\\epsilon \\to 0$ 时，接受率之比 $\\widehat{\\alpha}_{1} / \\widehat{\\alpha}_{2}$ 收敛于 $BF_{12}$。\n\nB. 如果每个模型使用其自身的摘要统计量 $s_{j}$、自身的范数和容差 $\\epsilon_{j}$，那么比较接受率 $\\widehat{\\alpha}_{1} / \\widehat{\\alpha}_{2}$ 仍然可以得到 $BF_{12}$ 的一致估计量（当 $\\epsilon_{j} \\to 0$ 时），因为模型特定的常数会在各自模型内部抵消掉。\n\nC. 如果使用了共同的摘要统计量 $s$，但它对于模型索引来说不是联合充分的，即分解式 $m(y \\mid M_{j}) = g(y) \\, m_{s}\\!\\left(s(y) \\mid M_{j}\\right)$ 不成立，因为 $g(y)$ 依赖于 $j$，那么 $\\widehat{\\alpha}_{1} / \\widehat{\\alpha}_{2}$ 会收敛到一个基于摘要统计量似然的比率，而不是真实的边际似然比，即使在 $\\epsilon \\to 0$ 时，对于模型选择也可能是不一致的。\n\nD. 如果 $k_{1} \\neq k_{2}$，并且在不同模型间使用了相同的范数和容差，那么当 $\\epsilon \\to 0$ 时，接受率之比会乘以一个与 $\\epsilon^{k_{1} - k_{2}}$ 成正比的因子，这使得 $\\widehat{\\alpha}_{1} / \\widehat{\\alpha}_{2}$ 偏离 $BF_{12}$，从而产生偏差。\n\nE. 从ABC拒绝采样切换到ABC序列蒙特卡洛（SMC），并使用自适应减小的容差，可以消除对跨模型可比较的摘要统计量的需求，并且无论摘要统计量如何选择，都可以从最终的粒子权重中恢复贝叶斯因子。", "solution": "这个问题要求分析使用近似贝叶斯计算（ABC）接受率之比 $\\widehat{\\alpha}_{1} / \\widehat{\\alpha}_{2}$ 作为贝叶斯因子 $BF_{12}$ 的估计量的有效性。\n\n首先，我们形式化模型 $M_{j}$ 的理论接受概率 $\\alpha_{j}$。如果模拟数据的摘要统计量 $s_{j}(x)$ 落在观测数据摘要统计量 $s_{j}(y)$ 周围一个半径为 $\\epsilon_{j}$ 的 $k_j$ 维球内，则该提议被接受。这个概率是摘要统计量的边际概率密度（我们记为 $m_{s_j}(u | M_j)$）在接受区域 $B_{\\epsilon_j}(s_{j}(y))$ 上的积分：\n$$ \\alpha_j(\\epsilon_j) = P(d_j(s_j(x), s_j(y)) \\le \\epsilon_j | M_j) = \\int_{u \\in B_{\\epsilon_j}(s_j(y))} m_{s_j}(u | M_j) \\, du $$\n在容差 $\\epsilon_j \\to 0$ 的渐近状态下，并假设密度 $m_{s_j}(u|M_j)$ 在 $u=s_j(y)$ 处连续，这个积分可以近似为球心处的密度值乘以球的体积。一个半径为 $\\epsilon_j$ 的 $k_j$ 维球的体积是 $V_j = C_{k_j} \\epsilon_j^{k_j}$，其中 $C_{k_j}$ 是由维度 $k_j$ 和所选范数决定的常数。因此，接受概率可以近似为：\n$$ \\alpha_j(\\epsilon_j) \\approx m_{s_j}(s_j(y) | M_j) \\, C_{k_j} \\, \\epsilon_j^{k_j} $$\n由于题目说明提议数量很大，我们可以将经验接受率 $\\widehat{\\alpha}_j$ 与其理论对应值 $\\alpha_j(\\epsilon_j)$ 等同起来。那么接受率之比为：\n$$ \\frac{\\widehat{\\alpha}_1}{\\widehat{\\alpha}_2} \\approx \\frac{\\alpha_1(\\epsilon_1)}{\\alpha_2(\\epsilon_2)} \\approx \\frac{m_{s_1}(s_1(y) | M_1) \\, C_{k_1} \\, \\epsilon_1^{k_1}}{m_{s_2}(s_2(y) | M_2) \\, C_{k_2} \\, \\epsilon_2^{k_2}} $$\n目标是近似贝叶斯因子 $BF_{12} = \\frac{m(y | M_1)}{m(y | M_2)}$。要使接受率之比成为 $BF_{12}$ 的一致估计量，它必须在极限情况下收敛于 $BF_{12}$。这要求满足两个条件：\n1. 摘要统计量的边际似然之比必须等于完整数据的边际似然之比。\n2. 涉及接受区域体积的项必须等于 $1$。\n\n我们现在基于此框架评估每个陈述。\n\n**选项A评估**\n该选项指明了ABC模型比较的理想条件：\n- 两个模型使用共同的摘要统计量 $s$，因此 $s_1 = s_2 = s$。\n- 维度 $k$、范数和容差 $\\epsilon$ 均相同，因此 $k_1 = k_2 = k$, $C_{k_1} = C_{k_2} = C_k$, 且 $\\epsilon_1 = \\epsilon_2 = \\epsilon$。\n在这些条件下，涉及体积和容差的项变为 $\\frac{C_k \\epsilon^k}{C_k \\epsilon^k} = 1$。因此，接受率之比收敛于摘要统计量的边际似然之比：\n$$ \\lim_{\\epsilon \\to 0} \\frac{\\widehat{\\alpha}_1}{\\widehat{\\alpha}_2} = \\frac{m_s(s(y) | M_1)}{m_s(s(y) | M_2)} $$\n该陈述进一步给出了条件 $m(y \\mid M_{j}) = g(y) \\, m_{s}\\!\\left(s(y) \\mid M_{j}\\right)$，其中 $g(y)$ 与模型索引 $j$ 无关。这是一种用于模型选择的充分性条件，确保使用 $s(y)$ 代替 $y$ 所丢失的信息对于两个模型是相同的。这使得我们可以写出：\n$$ \\frac{m_s(s(y) \\mid M_1)}{m_s(s(y) \\mid M_2)} = \\frac{m(y \\mid M_1) / g(y)}{m(y \\mid M_2) / g(y)} = \\frac{m(y \\mid M_1)}{m(y \\mid M_2)} = BF_{12} $$\n因此，接受率之比收敛于真实的贝叶斯因子。\n结论：**正确**。\n\n**选项B评估**\n该选项声稱使用模型特定的摘要统计量 $s_j$、范数和容差 $\\epsilon_j$ 是可接受的。接受率之比为：\n$$ \\frac{\\widehat{\\alpha}_1}{\\widehat{\\alpha}_2} \\approx \\frac{m_{s_1}(s_1(y) | M_1) \\, C_{k_1} \\, \\epsilon_1^{k_1}}{m_{s_2}(s_2(y) | M_2) \\, C_{k_2} \\, \\epsilon_2^{k_2}} $$\n这个表达式通常不等于 $BF_{12}$。项 $\\frac{C_{k_1} \\epsilon_1^{k_1}}{C_{k_2} \\epsilon_2^{k_2}}$ 不保证为 $1$。“模型特定的常数会抵消掉”的论点是错误的；这些常数是每个模型ABC实现所特有的，除非明确设置为相同，否则在比率中不会抵消。更根本的是，$m_{s_1}(s_1(y) | M_1)$ 和 $m_{s_2}(s_2(y) | M_2)$ 是可能不同的统计量的密度，在不同的空间中进行评估。没有理论基础可以期望它们的比率与 $BF_{12}$ 相关。这种方法不是估计贝叶斯因子的一致方法。\n结论：**不正确**。\n\n**选项C评估**\n该选项考察了使用共同摘要统计量 $s$（意味着共同的 $k$、范数和 $\\epsilon$），但它对于模型选择不是充分的这种情况。这种不充分性通过分解式 $m(y \\mid M_{j}) = g_j(y) \\, m_{s}\\!\\left(s(y) \\mid M_{j}\\right)$ 来形式化，其中 $g_j(y)$ 依赖于模型 $j$。如选项A所建立的，接受率之比收敛于摘要统计量边际似然之比 $\\frac{m_s(s(y) \\mid M_1)}{m_s(s(y) \\mid M_2)}$。使用给定的分解，这变成：\n$$ \\frac{m_s(s(y) \\mid M_1)}{m_s(s(y) \\mid M_2)} = \\frac{m(y \\mid M_1) / g_1(y)}{m(y \\mid M_2) / g_2(y)} = BF_{12} \\cdot \\frac{g_2(y)}{g_1(y)} $$\n由于 $g_1(y)$ 和 $g_2(y)$ 不同，该比率收敛到一个不同于真实贝叶斯因子的值。这个极限通常被称为“部分贝叶斯因子”。因为这个部分贝叶斯因子可以独立于真实的 $BF_{12}$ 而大于或小于 $1$，使用它可能导致不正确的模型选择决策。因此，该估计量对于真实的 $BF_{12}$ 是不一致的。\n结论：**正确**。\n\n**选项D评估**\n该选项解决了使用不同维度 ($k_1 \\neq k_2$) 的摘要统计量的关键问题，即使使用了相同的范数和容差 $\\epsilon$。接受率之比为：\n$$ \\frac{\\widehat{\\alpha}_1}{\\widehat{\\alpha}_2} \\approx \\left( \\frac{m_{s_1}(s_1(y) | M_1) C_{k_1}}{m_{s_2}(s_2(y) | M_2) C_{k_2}} \\right) \\epsilon^{k_1 - k_2} $$\n该陈述正确地指出，该比率与 $\\epsilon^{k_1 - k_2}$ 成正比。当 $\\epsilon \\to 0$ 时，该项在表达式中占主导地位。如果 $k_1 > k_2$，比率趋于 $0$。如果 $k_1  k_2$，比率发散到 $\\infty$（假设密度不为零）。此时的比较不再是关于模型的拟合程度，而是被摘要统计量维度的差异所压倒，引入了严重的偏差，系统性地偏向于具有较低维度摘要统计量的模型。这使得该比率作为贝葉斯因子的近似无效。\n结论：**正确**。\n\n**选项E评估**\n该选项提出，ABC序列蒙特卡洛（SMC）作为ABC的一种高级变体，可以规避对可比较的摘要统计量的需求。这是不正确的。用于模型选择的ABC-SMC方法通过演化一个粒子群来工作，其中每个粒子都是一个模型索引和参数向量的配对。这些粒子在容差 $\\epsilon_t$ 逐渐减小的连续阶段中的生存和加权，取决于它们生成与观测数据接近的模拟的能力。如果使用不同的摘要统计量（$s_1, s_2$）或不同维度的摘要統計量（$k_1 \\neq k_2$），接受概率将随 $\\epsilon_t$ 的变化而有不同的缩放比例，就像在拒绝采样的情况中一样。这将系统性地使粒子群产生偏差，因为与证据无关的原因而偏向某个模型。在所有被比较的模型中使用一个共同的、精心选择的摘要统计量这一基本要求，对于ABC-SMC仍然成立。\n结论：**不正确**。", "answer": "$$\\boxed{ACD}$$", "id": "3286937"}, {"introduction": "模拟的高昂计算成本是ABC方法的一个主要瓶颈。这个动手编程练习 [@problem_id:3286933] 挑战你设计并优化一个多保真度ABC算法。该方法巧妙地利用廉价的低保真度模拟器快速排除不佳的参数，从而将昂贵的高保真度模拟仅用于最可信的候选参数，极大地提升了计算效率。", "problem": "您的任务是设计一个使用延迟接受的多保真度近似贝叶斯计算 (ABC) 算法，用于解决一个具有均匀先验的标量参数估计问题。设计必须从随机模拟和蒙特卡洛方法的基本原理出发，并遵循以下规范。\n\n基本设置：\n- 未知参数为 $\\theta \\in \\mathbb{R}$，其先验密度 $\\pi(\\theta)$ 由区间 $[a,b]$ 上的均匀分布给出，即 $\\pi(\\theta) = \\mathcal{U}[a,b]$。\n- 有两个模拟器：\n  1. 一个低保真度模拟器 $p_L(x \\mid \\theta)$，产生摘要统计量 $S(x_L) = \\bar{x}_L$。\n  2. 一个高保真度模拟器 $p_H(x \\mid \\theta)$，产生摘要统计量 $S(x_H) = \\bar{x}_H$。\n- 观测数据集 $y$ 由 $S(y) = \\bar{y}$ 汇总。\n- 两个模拟器的摘要统计量都是 $m$ 次独立抽样的样本均值。\n- 低保真度模拟器有偏差且方差更高：每次抽样满足 $X_{L,i} \\sim \\mathcal{N}(\\theta + b, \\sigma_L^2)$，因此 $S(x_L) = \\bar{x}_L \\sim \\mathcal{N}(\\theta + b, \\sigma_L^2 / m)$。\n- 高保真度模拟器是无偏的且方差较低：每次抽样满足 $X_{H,i} \\sim \\mathcal{N}(\\theta, \\sigma_H^2)$，因此 $S(x_H) = \\bar{x}_H \\sim \\mathcal{N}(\\theta, \\sigma_H^2 / m)$。\n- 差异度量为绝对差 $\\rho(u,v) = |u-v|$。\n\n延迟接受 ABC 拒绝方案：\n- 对于从 $\\pi(\\theta)$ 中抽取的提议 $\\theta$，模拟 $x_L$ 并计算 $S(x_L)$。\n- 阶段 $1$ 接受测试：如果 $\\rho(S(x_L), S(y)) \\le \\epsilon_L$，则接受该提议进入阶段 $2$。\n- 如果被接受进入阶段 $2$，模拟 $x_H$ 并计算 $S(x_H)$。\n- 最终接受测试：如果 $\\rho(S(x_H), S(y)) \\le \\epsilon_H$，则接受该提议。\n- 每次低保真度模拟产生成本 $c_L$，而每次高保真度模拟（仅在阶段 $1$ 测试通过时执行）产生成本 $c_H$。\n\n基本定义：\n- 令 $\\mu_L(\\theta) = \\theta + b - \\bar{y}$ 和 $\\sigma_L' = \\sigma_L / \\sqrt{m}$。令 $\\mu_H(\\theta) = \\theta - \\bar{y}$ 和 $\\sigma_H' = \\sigma_H / \\sqrt{m}$。\n- 为给定的 $\\theta$ 定义阶段 $1$ 的接受概率：\n  $$A_L(\\theta; \\epsilon_L) = \\mathbb{P}\\left(|D_L| \\le \\epsilon_L \\mid \\theta \\right), \\quad D_L \\sim \\mathcal{N}\\left(\\mu_L(\\theta), (\\sigma_L')^2\\right).$$\n- 为给定的 $\\theta$ 定义阶段 $2$ 的接受概率：\n  $$A_H(\\theta; \\epsilon_H) = \\mathbb{P}\\left(|D_H| \\le \\epsilon_H \\mid \\theta \\right), \\quad D_H \\sim \\mathcal{N}\\left(\\mu_H(\\theta), (\\sigma_H')^2\\right).$$\n- 在给定 $\\theta$ 的条件下，模拟器噪声独立的假设下，对于一个给定的 $\\theta$，最终接受的概率是 $A_L(\\theta; \\epsilon_L) \\cdot A_H(\\theta; \\epsilon_H)$。\n\n先验下的群体级数量：\n- 阶段 $1$ 接受率是\n  $$\\alpha_L(\\epsilon_L) = \\int_{a}^{b} A_L(\\theta; \\epsilon_L) \\, \\frac{d\\theta}{b-a}。$$\n- 最终接受率是\n  $$\\alpha_F(\\epsilon_L, \\epsilon_H) = \\int_{a}^{b} A_L(\\theta; \\epsilon_L) \\cdot A_H(\\theta; \\epsilon_H) \\, \\frac{d\\theta}{b-a}。$$\n- 每个提议参数的预期总成本是\n  $$C_{\\text{per-proposal}}(\\epsilon_L) = c_L + c_H \\cdot \\alpha_L(\\epsilon_L)。$$\n- 延迟接受 ABC 拒绝方案中每个接受样本的预期总成本是\n  $$J_{\\text{cost}}(\\epsilon_L, \\epsilon_H) = \\frac{c_L + c_H \\cdot \\alpha_L(\\epsilon_L)}{\\alpha_F(\\epsilon_L, \\epsilon_H)}。$$\n- 基于高保真度差异的质量惩罚：\n  - 对于给定的 $\\theta$，定义高保真度差异的截断二阶矩：\n    $$M_2^H(\\theta; \\epsilon_H) = \\mathbb{E}\\left[D_H^2 \\cdot \\mathbf{1}\\{|D_H| \\le \\epsilon_H\\} \\mid \\theta\\right], \\quad D_H \\sim \\mathcal{N}\\left(\\mu_H(\\theta), (\\sigma_H')^2\\right)。$$\n  - 定义由阶段 $1$ 接受加权的先验平均截断二阶矩：\n    $$N_2(\\epsilon_L, \\epsilon_H) = \\int_{a}^{b} M_2^H(\\theta; \\epsilon_H) \\cdot A_L(\\theta; \\epsilon_L) \\, \\frac{d\\theta}{b-a}。$$\n  - 给定最终接受的条件期望平方差异是\n    $$Q(\\epsilon_L, \\epsilon_H) = \\frac{N_2(\\epsilon_L, \\epsilon_H)}{\\alpha_F(\\epsilon_L, \\epsilon_H)}。$$\n- 权衡成本与保真度的复合目标：\n  $$J(\\epsilon_L, \\epsilon_H) = J_{\\text{cost}}(\\epsilon_L, \\epsilon_H) + \\lambda \\cdot Q(\\epsilon_L, \\epsilon_H),$$\n  其中 $\\lambda$ 是一个非负权重参数，用于控制对差异的惩罚。\n\n您的任务：\n- 给定测试用例参数，计算 $\\alpha_L(\\epsilon_L)$、$\\alpha_F(\\epsilon_L,\\epsilon_H)$、 $Q(\\epsilon_L,\\epsilon_H)$，并在网格约束的阈值 $\\epsilon_L \\in [\\epsilon_L^{\\min}, \\epsilon_L^{\\max}]$ 和 $\\epsilon_H \\in [\\epsilon_H^{\\min}, \\epsilon_H^{\\max}]$ 上，以指定的步长最小化 $J(\\epsilon_L, \\epsilon_H)$。通过在 $\\theta \\in [a,b]$ 上进行均匀网格平均来近似积分，并使用高斯累积分布函数和截断矩的闭式表达式。\n\n在您的实现中要使用的解析形式：\n- 对于 $D \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 和任意阈值 $\\epsilon  0$，接受概率为\n  $$\\mathbb{P}(|D| \\le \\epsilon) = \\Phi\\left(\\frac{\\epsilon - \\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{-\\epsilon - \\mu}{\\sigma}\\right),$$\n  其中 $\\Phi(\\cdot)$ 是标准正态分布的累积分布函数。\n- 在 $[-\\epsilon,\\epsilon]$ 上的截断二阶矩是\n  $$\\int_{-\\epsilon}^{\\epsilon} d^2 f_{D}(d) \\, dd = \\mu^2 P + 2 \\mu \\sigma \\left[\\phi(a) - \\phi(b)\\right] + \\sigma^2 \\left[P - b \\phi(b) + a \\phi(a)\\right],$$\n  其中 $a = \\frac{-\\epsilon - \\mu}{\\sigma}$，$b = \\frac{\\epsilon - \\mu}{\\sigma}$，$P = \\Phi(b) - \\Phi(a)$，$\\phi(\\cdot)$ 是标准正态概率密度函数。\n\n测试套件规范：\n- 对于每个测试用例 $i$，参数元组以如下形式给出\n  $$\\left(a,b,\\bar{y},m,b_{\\text{bias}},\\sigma_L,\\sigma_H,c_L,c_H,\\lambda,\\epsilon_L^{\\min},\\epsilon_L^{\\max},\\epsilon_H^{\\min},\\epsilon_H^{\\max},\\Delta\\epsilon,\\;T\\right),$$\n  其中 $T$ 是用于近似先验积分的均匀网格点数。\n- 程序必须在指定的网格上评估 $J(\\epsilon_L, \\epsilon_H)$，并为每个测试用例返回最小化器 $(\\epsilon_L^{\\star}, \\epsilon_H^{\\star})$。\n\n使用以下测试套件：\n1.  用例 $1$ (一般情况): $(a,b,\\bar{y},m,b_{\\text{bias}},\\sigma_L,\\sigma_H,c_L,c_H,\\lambda,\\epsilon_L^{\\min},\\epsilon_L^{\\max},\\epsilon_H^{\\min},\\epsilon_H^{\\max},\\Delta\\epsilon,T) = (0.0, 1.0, 0.6, 20, 0.2, 1.5, 1.0, 1.0, 5.0, 5.0, 0.01, 0.50, 0.005, 0.30, 0.01, 400)$。\n2.  用例 $2$ (零保真度惩罚的边界情况): $(0.0, 1.0, 0.6, 20, 0.25, 1.8, 1.0, 1.0, 5.0, 0.0, 0.01, 0.50, 0.005, 0.30, 0.01, 400)$。\n3.  用例 $3$ (高成本高保真度，低成本低保真度): $(0.0, 1.0, 0.6, 20, 0.3, 1.5, 1.0, 1.0, 10.0, 5.0, 0.01, 0.50, 0.005, 0.30, 0.01, 400)$。\n4.  用例 $4$ (近乎无偏的低保真度): $(0.0, 1.0, 0.6, 20, 0.0, 1.2, 1.0, 1.5, 8.0, 5.0, 0.01, 0.50, 0.005, 0.30, 0.01, 400)$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果必须是一个包含 $[\\epsilon_L^{\\star}, \\epsilon_H^{\\star}]$ 浮点值的双元素列表。例如，包含两个结果的输出格式为 $[[0.12,0.08],[0.20,0.10]]$。\n- 不得打印任何其他文本。", "solution": "用户提供了一个科学上合理、定义明确且客观的问题。它基于近似贝叶斯计算 (ABC) 的既定原则，具体来说是使用多保真度、延迟接受的拒绝抽样方案。该问题是可形式化的，包含构建解决方案所需的所有必要定义、常数和解析形式。目标是找到最优的容差参数 $(\\epsilon_L, \\epsilon_H)$，以最小化一个代表计算成本和统计精度之间权衡的复合函数。该任务涉及数值积分和基于网格的优化，这些都是标准的计算方法。该问题是自洽的，没有矛盾或歧义。因此，该问题被认为是有效的，并将提供完整的解决方案。\n\n该问题要求我们为一个延迟接受 ABC 算法最小化复合目标函数 $J(\\epsilon_L, \\epsilon_H)$。此函数捕捉了每个接受样本的计算成本与这些样本质量之间的权衡，其中质量与期望平方差异成反比。最小化是在容差参数 $\\epsilon_L$ 和 $\\epsilon_H$ 的离散网格上执行的。\n\n解决方案的核心涉及对几个关于参数 $\\theta$ 的先验分布（其中 $\\pi(\\theta) = \\mathcal{U}[a,b]$）的积分进行数值评估。这些积分通过数值积分进行近似，具体来说，是通过在区间 $[a,b]$ 上的 $T$ 个点的均匀网格上对被积函数求平均值。\n\n令参数值的均匀网格为 $\\{\\theta_i\\}_{i=1}^T$，其中 $\\theta_i = a + (i-0.5) \\frac{b-a}{T}$。一个函数 $f(\\theta)$ 在先验支撑集上的积分则近似为：\n$$\n\\int_{a}^{b} f(\\theta) \\, \\frac{d\\theta}{b-a} \\approx \\frac{1}{b-a} \\sum_{i=1}^{T} f(\\theta_i) \\frac{b-a}{T} = \\frac{1}{T} \\sum_{i=1}^{T} f(\\theta_i)\n$$\n\n我们必须首先为问题陈述中提供的关键解析组件实现函数。\n\n对于一个正态分布的随机变量 $D \\sim \\mathcal{N}(\\mu, \\sigma^2)$，其绝对值在一个阈值 $\\epsilon  0$ 内的概率由下式给出：\n$$\n\\mathbb{P}(|D| \\le \\epsilon) = \\mathbb{P}(-\\epsilon \\le D \\le \\epsilon) = \\Phi\\left(\\frac{\\epsilon - \\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{-\\epsilon - \\mu}{\\sigma}\\right)\n$$\n其中 $\\Phi(\\cdot)$ 是标准正态分布的累积分布函数 (CDF)。此公式将用于计算接受概率 $A_L(\\theta; \\epsilon_L)$ 和 $A_H(\\theta; \\epsilon_H)$。对于 $A_L(\\theta; \\epsilon_L)$，我们使用 $\\mu = \\mu_L(\\theta) = \\theta + b_{\\text{bias}} - \\bar{y}$ 和 $\\sigma = \\sigma'_L = \\sigma_L / \\sqrt{m}$。对于 $A_H(\\theta; \\epsilon_H)$，我们使用 $\\mu = \\mu_H(\\theta) = \\theta - \\bar{y}$ 和 $\\sigma = \\sigma'_H = \\sigma_H / \\sqrt{m}$。\n\n$D$ 的截断二阶矩由下式给出：\n$$\nM_2(\\mu, \\sigma, \\epsilon) = \\mathbb{E}\\left[D^2 \\cdot \\mathbf{1}\\{|D| \\le \\epsilon\\}\\right] = \\int_{-\\epsilon}^{\\epsilon} d^2 \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(d-\\mu)^2}{2\\sigma^2}} \\, dd\n$$\n问题为此积分提供了一个闭式解：\n$$\nM_2(\\mu, \\sigma, \\epsilon) = \\mu^2 P + 2 \\mu \\sigma \\left[\\phi(\\alpha) - \\phi(\\beta)\\right] + \\sigma^2 \\left[P - \\beta \\phi(\\beta) + \\alpha \\phi(\\alpha)\\right]\n$$\n其中 $\\alpha = \\frac{-\\epsilon - \\mu}{\\sigma}$，$\\beta = \\frac{\\epsilon - \\mu}{\\sigma}$，$P = \\Phi(\\beta) - \\Phi(\\alpha)$，$\\phi(\\cdot)$ 是标准正态分布的概率密度函数 (PDF)。此公式用于计算 $M_2^H(\\theta; \\epsilon_H)$，其中 $\\mu = \\mu_H(\\theta)$ 且 $\\sigma = \\sigma'_H$。\n\n有了这些构建块，我们可以为指定网格上的每一对 $(\\epsilon_L, \\epsilon_H)$ 计算群体级数量。\n\n1.  **阶段 $1$ 接受率, $\\alpha_L(\\epsilon_L)$**:\n    $$\n    \\alpha_L(\\epsilon_L) = \\int_{a}^{b} A_L(\\theta; \\epsilon_L) \\, \\frac{d\\theta}{b-a} \\approx \\frac{1}{T} \\sum_{i=1}^{T} A_L(\\theta_i; \\epsilon_L)\n    $$\n\n2.  **最终接受率, $\\alpha_F(\\epsilon_L, \\epsilon_H)$**:\n    $$\n    \\alpha_F(\\epsilon_L, \\epsilon_H) = \\int_{a}^{b} A_L(\\theta; \\epsilon_L) \\cdot A_H(\\theta; \\epsilon_H) \\, \\frac{d\\theta}{b-a} \\approx \\frac{1}{T} \\sum_{i=1}^{T} A_L(\\theta_i; \\epsilon_L) \\cdot A_H(\\theta_i; \\epsilon_H)\n    $$\n\n3.  **先验平均截断二阶矩, $N_2(\\epsilon_L, \\epsilon_H)$**:\n    $$\n    N_2(\\epsilon_L, \\epsilon_H) = \\int_{a}^{b} M_2^H(\\theta; \\epsilon_H) \\cdot A_L(\\theta; \\epsilon_L) \\, \\frac{d\\theta}{b-a} \\approx \\frac{1}{T} \\sum_{i=1}^{T} M_2^H(\\theta_i; \\epsilon_H) \\cdot A_L(\\theta_i; \\epsilon_L)\n    $$\n\n由此，我们可以计算目标函数的各项：\n\n-   **每个接受样本的预期成本, $J_{\\text{cost}}(\\epsilon_L, \\epsilon_H)$**:\n    $$\n    J_{\\text{cost}}(\\epsilon_L, \\epsilon_H) = \\frac{c_L + c_H \\cdot \\alpha_L(\\epsilon_L)}{\\alpha_F(\\epsilon_L, \\epsilon_H)}\n    $$\n\n-   **条件期望平方差异, $Q(\\epsilon_L, \\epsilon_H)$**:\n    $$\n    Q(\\epsilon_L, \\epsilon_H) = \\frac{N_2(\\epsilon_L, \\epsilon_H)}{\\alpha_F(\\epsilon_L, \\epsilon_H)}\n    $$\n\n复合目标函数则为：\n$$\nJ(\\epsilon_L, \\epsilon_H) = J_{\\text{cost}}(\\epsilon_L, \\epsilon_H) + \\lambda \\cdot Q(\\epsilon_L, \\epsilon_H)\n$$\n如果 $\\alpha_F(\\epsilon_L, \\epsilon_H) \\approx 0$，它表示获得一个样本的概率极低，导致接近无限的成本。在实现中，必须处理这种情况以避免除以零。\n\n整体算法执行网格搜索。对于每个测试用例，我们根据提供的最小值、最大值和步长定义 $\\epsilon_L$ 和 $\\epsilon_H$ 的值网格。然后，我们遍历此网格上的每一对 $(\\epsilon_L, \\epsilon_H)$，计算 $J(\\epsilon_L, \\epsilon_H)$ 的值，并跟踪产生最小 $J$ 值的对。这对 $(\\epsilon_L^{\\star}, \\epsilon_H^{\\star})$ 就是该测试用例的解。\n\n实现将被结构化为首先为每个 $(\\epsilon_L, \\epsilon_H)$ 和 $\\theta_i$ 网格计算 $A_L(\\theta_i)$、 $A_H(\\theta_i)$ 和 $M_2^H(\\theta_i)$ 值的数组，然后使用 `numpy` 中的向量化操作来高效地计算平均值和最终的目标函数值。这避免了在循环内不必要地重新计算值。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to solve the multi-fidelity ABC optimization problem for all test cases.\n    \"\"\"\n\n    test_cases = [\n        # (a, b, y_bar, m, b_bias, sigma_L, sigma_H, c_L, c_H, lambda_val, eL_min, eL_max, eH_min, eH_max, d_eps, T)\n        (0.0, 1.0, 0.6, 20, 0.2, 1.5, 1.0, 1.0, 5.0, 5.0, 0.01, 0.50, 0.005, 0.30, 0.01, 400),\n        (0.0, 1.0, 0.6, 20, 0.25, 1.8, 1.0, 1.0, 5.0, 0.0, 0.01, 0.50, 0.005, 0.30, 0.01, 400),\n        (0.0, 1.0, 0.6, 20, 0.3, 1.5, 1.0, 1.0, 10.0, 5.0, 0.01, 0.50, 0.005, 0.30, 0.01, 400),\n        (0.0, 1.0, 0.6, 20, 0.0, 1.2, 1.0, 1.5, 8.0, 5.0, 0.01, 0.50, 0.005, 0.30, 0.01, 400),\n    ]\n\n    results = []\n    for case in test_cases:\n        optimal_eps = find_optimal_epsilons(case)\n        results.append(list(optimal_eps))\n    \n    # Format the final output as specified\n    output_str = \"[\" + \",\".join(map(str, results)) + \"]\"\n    print(output_str)\n\ndef acceptance_prob(mu, sigma, epsilon):\n    \"\"\"\n    Calculates P(|D| = epsilon) for D ~ N(mu, sigma^2).\n    \"\"\"\n    if sigma == 0:\n        return 0.0\n    z_upper = (epsilon - mu) / sigma\n    z_lower = (-epsilon - mu) / sigma\n    return norm.cdf(z_upper) - norm.cdf(z_lower)\n\ndef truncated_second_moment(mu, sigma, epsilon):\n    \"\"\"\n    Calculates E[D^2 * 1{|D| = epsilon}] for D ~ N(mu, sigma^2).\n    \"\"\"\n    if sigma == 0:\n        return 0.0\n    \n    alpha_std = (-epsilon - mu) / sigma\n    beta_std = (epsilon - mu) / sigma\n    \n    P = norm.cdf(beta_std) - norm.cdf(alpha_std)\n    \n    phi_alpha = norm.pdf(alpha_std)\n    phi_beta = norm.pdf(beta_std)\n    \n    term1 = mu**2 * P\n    term2 = 2 * mu * sigma * (phi_alpha - phi_beta)\n    term3 = sigma**2 * (P - beta_std * phi_beta + alpha_std * phi_alpha)\n    \n    return term1 + term2 + term3\n\ndef find_optimal_epsilons(params):\n    \"\"\"\n    Performs grid search to find the optimal (epsilon_L, epsilon_H)\n    that minimize the objective function J.\n    \"\"\"\n    a, b, y_bar, m, b_bias, sigma_L, sigma_H, c_L, c_H, lambda_val, \\\n    eL_min, eL_max, eH_min, eH_max, d_eps, T = params\n    \n    sigma_L_prime = sigma_L / np.sqrt(m)\n    sigma_H_prime = sigma_H / np.sqrt(m)\n    \n    # Discretize the prior distribution of theta\n    theta_grid = np.linspace(a, b, T, endpoint=False) + (b - a) / (2 * T)\n    \n    # Create grids for epsilon values\n    eps_L_grid = np.arange(eL_min, eL_max + 0.5 * d_eps, d_eps)\n    eps_H_grid = np.arange(eH_min, eH_max + 0.5 * d_eps, d_eps)\n\n    min_J = np.inf\n    optimal_eps = (None, None)\n\n    # Pre-calculate mu values which are constant across epsilon loops\n    mu_L_theta = theta_grid + b_bias - y_bar\n    mu_H_theta = theta_grid - y_bar\n\n    for eps_L in eps_L_grid:\n        # Calculate quantities dependent on eps_L\n        A_L_vals = acceptance_prob(mu_L_theta, sigma_L_prime, eps_L)\n        alpha_L = np.mean(A_L_vals)\n\n        for eps_H in eps_H_grid:\n            # Calculate quantities dependent on eps_H\n            A_H_vals = acceptance_prob(mu_H_theta, sigma_H_prime, eps_H)\n            M2_H_vals = truncated_second_moment(mu_H_theta, sigma_H_prime, eps_H)\n\n            # Compute population-level integrals\n            alpha_F = np.mean(A_L_vals * A_H_vals)\n            N2 = np.mean(M2_H_vals * A_L_vals)\n\n            # Handle case where final acceptance rate is near zero\n            if alpha_F  1e-12:\n                J = np.inf\n            else:\n                J_cost = (c_L + c_H * alpha_L) / alpha_F\n                Q = N2 / alpha_F\n                J = J_cost + lambda_val * Q\n            \n            if J  min_J:\n                min_J = J\n                optimal_eps = (round(eps_L, 4), round(eps_H, 4))\n                \n    return optimal_eps\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3286933"}]}