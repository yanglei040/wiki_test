{"hands_on_practices": [{"introduction": "在固定时间区间内模拟齐次泊松过程（HPP）有两种主要的精确算法：顺序指数生成法（Sequential Exponential Generation, SEG）和计数后排序法（Count-Then-Sort, CTS）。选择哪种算法并非随心所欲，而是取决于过程的参数，特别是区间内的期望事件数 $\\mu = \\lambda T$。这个练习 [@problem_id:3342349] 旨在挑战您为这两种算法的计算成本建模，并推导出一个决策规则来选择更高效的算法。您将通过经验数据验证该规则，并探索算法最优选择发生切换的“相变”点。", "problem": "您的任务是研究在区间 $(0,T]$ 上，速率为 $\\lambda$ 的齐次泊松过程的两种精确模拟算法，并基于一个有原则的计算成本模型设计一个混合选择规则，用以选择更快的算法。然后，您必须在一个蒙特卡洛代理计算成本模型下，验证该混合规则在经验上是最优的。您的程序必须实现这些算法和验证过程，并按照要求的格式为指定的测试套件输出结果。\n\n模拟齐次泊松过程事件时间的两种方法如下，以纯数学术语表述。\n\n- 序贯指数生成法 (Sequential Exponential Generation, SEG)：生成独立的到达间隔时间 $E_1,E_2,\\dots$，其中每个 $E_i \\sim \\text{Exponential}(\\lambda)$，形成累积和 $S_k = \\sum_{i=1}^{k} E_i$，并在第一个满足 $S_M > T$ 的索引 $M$ 处停止。事件时间为 $\\{S_k : S_k \\le T\\}$。根据齐次泊松过程的定义，在 $(0,T]$ 内的事件数 $N_T$ 服从分布 $N_T \\sim \\text{Poisson}(\\lambda T)$，并且生成的指数变量数量几乎必然等于 $M = N_T + 1$。\n\n- 计数后排序法 (Count-Then-Sort, CTS)：生成 $N \\sim \\text{Poisson}(\\lambda T)$，然后生成 $N$ 个独立的均匀分布变量 $U_1,\\dots,U_N \\overset{\\text{iid}}{\\sim} \\text{Uniform}(0,T)$，并将它们排序以获得有序的事件时间。\n\n为了以一种与机器无关的方式比较计算性能，我们使用一个代理成本模型，该模型通过计算基本操作的数量来衡量成本，其中包含代表硬件性能和实现效率的可调常数。\n\n- SEG 代理成本：将单次运行的成本建模为 $C_{\\text{SEG}} = c_s \\cdot M = c_s \\cdot (N_T + 1)$，其中 $c_s > 0$ 是一个抽象常数，它聚合了采样一个指数变量、更新部分和以及进行比较的每步成本。\n\n- CTS 代理成本：将单次运行的成本建模为 $C_{\\text{CTS}} = c_P + c_U \\cdot N + a \\cdot N \\log_2(\\max\\{N,1\\}) + b \\cdot N$，其中 $c_P \\ge 0$ 建模了抽取一个泊松计数的固定开销，$c_U \\ge 0$ 建模了每个均匀变量的采样成本，$a \\ge 0$ 建模了排序的主要成本 $O(N \\log N)$（以 2 为底的对数），而 $b \\ge 0$ 捕捉了线性时间排序的开销，如元素移动。当 $N \\in \\{0,1\\}$ 时，定义 $N \\log_2(\\max\\{N,1\\})$ 项为 $0$。\n\n从 $N_T \\sim \\text{Poisson}(\\lambda T)$ 的特性和指数到达间隔的构造出发，推导一个期望成本的近似值，该近似值仅依赖于乘积 $\\mu = \\lambda T$ 和常数 $c_s, c_P, c_U, a, b$。使用近似 $\\mathbb{E}[N_T] \\approx \\mu$ 和 $\\mathbb{E}[N_T \\log_2(N_T)] \\approx \\mu \\log_2(\\max\\{\\mu,1\\})$ 来获得期望成本的一阶经验法则：\n$$\n\\bar{C}_{\\text{SEG}}(\\mu) \\approx c_s \\cdot (\\mu + 1), \\quad\n\\bar{C}_{\\text{CTS}}(\\mu) \\approx c_P + c_U \\cdot \\mu + a \\cdot \\mu \\log_2(\\max\\{\\mu,1\\}) + b \\cdot \\mu.\n$$\n提出一个混合规则，选择具有较小近似期望成本的算法。这在 $\\mu$ 和硬件常数中定义了一个相变：对于较小的 $\\mu$ 和昂贵的排序，SEG 可能更优；对于较大的 $\\mu$、快速排序和廉价的均匀分布生成，CTS 可能更优，特别是当 $c_s$ 相对于 $a$ 较大时。\n\n经验验证协议。对于测试套件中的每组参数，使用固定的种子执行 $R$ 次蒙特卡洛重复实验，以消除输出格式中的随机性。在每次重复实验中，抽取 $N \\sim \\text{Poisson}(\\mu)$ 并评估代理成本：\n$$\nC_{\\text{SEG}} = c_s \\cdot (N + 1), \\quad\nC_{\\text{CTS}} = c_P + c_U \\cdot N + a \\cdot N \\log_2(\\max\\{N,1\\}) + b \\cdot N.\n$$\n对 $R$ 次重复实验的结果取平均，以获得经验均值 $\\hat{C}_{\\text{SEG}}$ 和 $\\hat{C}_{\\text{CTS}}$。将具有较小经验均值成本的方法定义为经验最优方法（若成本相等，则选择 SEG）。通过为每个测试用例返回一个布尔值来验证混合规则，该布尔值为“真”当且仅当混合选择与经验最优方法匹配。\n\n测试套件。使用下面的五个参数集，通过改变 $\\mu = \\lambda T$ 和硬件常数来探索相变。对于每个用例，使用 $R = 200000$ 次重复实验和相同的固定随机种子。\n\n- 用例 1：$\\lambda = 0.001$, $T = 50.0$, $c_s = 1.0$, $c_P = 5.0$, $c_U = 1.0$, $a = 1.0$, $b = 0.0$。\n\n- 用例 2：$\\lambda = 1.0$, $T = 1.0$, $c_s = 1.0$, $c_P = 5.0$, $c_U = 1.0$, $a = 0.5$, $b = 0.0$。\n\n- 用例 3：$\\lambda = 2.0$, $T = 10.0$, $c_s = 1.0$, $c_P = 5.0$, $c_U = 1.0$, $a = 2.0$, $b = 0.0$。\n\n- 用例 4：$\\lambda = 2.0$, $T = 10.0$, $c_s = 1.0$, $c_P = 2.0$, $c_U = 0.2$, $a = 0.05$, $b = 0.0$。\n\n- 用例 5：$\\lambda = 100.0$, $T = 10.0$, $c_s = 10.0$, $c_P = 2.0$, $c_U = 0.2$, $a = 0.02$, $b = 0.0$。\n\n您的任务。实现一个程序，该程序：\n\n- 对每个用例，根据近似的期望成本计算混合选择。\n\n- 对每个用例执行包含 $R = 200000$ 次重复实验的经验验证，使用固定的伪随机数生成器种子以确保输出是确定性的。\n\n- 对每个用例，返回一个布尔值，指示混合选择是否与经验最优选择相等。\n\n最终输出格式。您的程序应生成单行输出，其中包含五个布尔值，以逗号分隔，并用方括号括起来，例如 $[\\text{True},\\text{False},\\text{True},\\text{True},\\text{True}]$。结果的顺序必须遵循上面列出的用例 1 到 5 的顺序。输出中不允许包含任何额外文本。", "solution": "该问题要求分析在区间 $(0, T]$ 上，常数速率为 $\\lambda > 0$ 的齐次泊松过程的两种模拟算法：序贯指数生成法 (SEG) 和计数后排序法 (CTS)。目标是基于一个理论成本模型开发一个混合选择规则，并根据通过蒙特卡洛模拟获得的经验成本评估来验证该规则。\n\n在区间 $(0, T]$ 内的事件数 $N_T$ 服从均值为 $\\mu = \\lambda T$ 的泊松分布，即 $N_T \\sim \\text{Poisson}(\\mu)$。这个随机变量对两种算法的计算成本都至关重要。\n\n首先，我们形式化理论成本模型和混合选择规则。问题为单次模拟运行提供了代理成本函数：\n- 对于 SEG，成本为 $C_{\\text{SEG}} = c_s \\cdot (N_T + 1)$，其中 $N_T$ 是该次运行中实现的事件数。成本与生成的指数变量数量成正比，即 $N_T + 1$。\n- 对于 CTS，成本为 $C_{\\text{CTS}} = c_P + c_U \\cdot N_T + a \\cdot N_T \\log_2(\\max\\{N_T,1\\}) + b \\cdot N_T$。该成本包括用于采样泊松计数的固定部分 $c_P$，用于采样 $N_T$ 个均匀变量的线性部分，以及用于对它们进行排序的拟线性部分，该部分由 $N \\log N$ 项主导。常数 $c_s, c_P, c_U, a, b$ 是非负的，并取决于具体的计算环境。\n\n为了推导一个独立于单次随机结果的选择规则，我们比较两种算法的期望成本。\nSEG 的期望成本可以精确计算：\n$$\n\\mathbb{E}[C_{\\text{SEG}}] = \\mathbb{E}[c_s \\cdot (N_T + 1)] = c_s \\cdot (\\mathbb{E}[N_T] + 1) = c_s(\\mu + 1)\n$$\n我们将其定义为理论成本估计 $\\bar{C}_{\\text{SEG}}(\\mu) = c_s(\\mu + 1)$。\n\nCTS 的期望成本为：\n$$\n\\mathbb{E}[C_{\\text{CTS}}] = \\mathbb{E}[c_P + c_U N_T + a N_T \\log_2(\\max\\{N_T,1\\}) + b N_T] \\\\\n= c_P + (c_U + b)\\mathbb{E}[N_T] + a\\mathbb{E}[N_T \\log_2(\\max\\{N_T,1\\})] \\\\\n= c_P + (c_U + b)\\mu + a\\mathbb{E}[N_T \\log_2(\\max\\{N_T,1\\})]\n$$\n项 $\\mathbb{E}[N_T \\log_2(\\max\\{N_T,1\\})]$ 没有简单的封闭形式表达式。问题建议基于琴生不等式的一阶近似，$\\mathbb{E}[f(X)] \\approx f(\\mathbb{E}[X])$。应用该近似，我们得到：\n$$\n\\mathbb{E}[N_T \\log_2(\\max\\{N_T,1\\})] \\approx \\mu \\log_2(\\max\\{\\mu,1\\})\n$$\n这得出了 CTS 的近似期望成本：\n$$\n\\bar{C}_{\\text{CTS}}(\\mu) \\approx c_P + (c_U + b)\\mu + a \\mu \\log_2(\\max\\{\\mu,1\\})\n$$\n混合选择规则是选择具有较低近似期望成本的算法。如果 $\\bar{C}_{\\text{SEG}}(\\mu) \\le \\bar{C}_{\\text{CTS}}(\\mu)$，我们选择 SEG，否则选择 CTS。这纯粹基于参数 $\\mu, c_s, c_P, c_U, a, b$ 建立了一个“混合选择”。\n\n接下来，我们设计经验验证协议。其目的是通过使用蒙特卡洛方法高精度地估计真实期望成本 $\\mathbb{E}[C_{\\text{SEG}}]$ 和 $\\mathbb{E}[C_{\\text{CTS}}]$，来确定“经验最优”方法。对于每个测试用例，我们执行 $R=200000$ 次重复实验。使用固定的伪随机数生成器种子以确保结果的可复现性。\n每个测试用例的程序如下：\n1. 生成一个包含 $R$ 个独立随机变量的向量 $\\{N_i\\}_{i=1}^R$，其中每个 $N_i \\sim \\text{Poisson}(\\mu)$。\n2. 对于每个 $N_i$，计算每种算法本应产生的成本：\n   - $C_{\\text{SEG}, i} = c_s(N_i + 1)$\n   - $C_{\\text{CTS}, i} = c_P + c_U N_i + a N_i \\log_2(\\max\\{N_i,1\\}) + b N_i$\n3. 计算这些成本的样本均值，它们是真实期望成本的蒙特卡洛估计：\n   - $\\hat{C}_{\\text{SEG}} = \\frac{1}{R} \\sum_{i=1}^R C_{\\text{SEG}, i}$\n   - $\\hat{C}_{\\text{CTS}} = \\frac{1}{R} \\sum_{i=1}^R C_{\\text{CTS}, i}$\n根据大数定律，对于大的 $R$，有 $\\hat{C}_{\\text{SEG}} \\approx \\mathbb{E}[C_{\\text{SEG}}]$ 和 $\\hat{C}_{\\text{CTS}} \\approx \\mathbb{E}[C_{\\text{CTS}}]$。经验最优方法通过比较这些样本均值来确定。与问题中的平局打破规则一致，如果 $\\hat{C}_{\\text{SEG}} \\le \\hat{C}_{\\text{CTS}}$，我们选择 SEG，否则选择 CTS。\n\n最后，对于每个测试用例，我们将混合选择（预计算）与经验最优选择进行比较。布尔结果 `True` 表示简单的一阶近似足以做出正确的决策，而 `False` 则表示被近似忽略的高阶效应足够显著，以至于改变了结果。实现将使用 `numpy` 对 $R$ 次重复实验进行高效的向量化计算。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Validates a hybrid algorithm selection rule for simulating a homogeneous Poisson process.\n\n    The function iterates through a suite of test cases. For each case, it:\n    1.  Calculates a theoretical choice of algorithm (SEG vs. CTS) based on an\n        approximated expected-cost model.\n    2.  Determines the empirically optimal algorithm by running a Monte Carlo\n        simulation to estimate the average costs of each method.\n    3.  Compares the theoretical choice to the empirical choice and records\n        whether they match.\n\n    The final output is a list of booleans representing the result of this\n    comparison for each test case.\n    \"\"\"\n    \n    # Test suite as defined in the problem statement\n    test_cases = [\n        # Case 1: (lambda, T, c_s, c_P, c_U, a, b)\n        (0.001, 50.0, 1.0, 5.0, 1.0, 1.0, 0.0),\n        # Case 2\n        (1.0, 1.0, 1.0, 5.0, 1.0, 0.5, 0.0),\n        # Case 3\n        (2.0, 10.0, 1.0, 5.0, 1.0, 2.0, 0.0),\n        # Case 4\n        (2.0, 10.0, 1.0, 2.0, 0.2, 0.05, 0.0),\n        # Case 5\n        (100.0, 10.0, 10.0, 2.0, 0.2, 0.02, 0.0),\n    ]\n\n    R = 200000  # Number of Monte Carlo replications\n    SEED = 0 # Fixed seed for deterministic output\n\n    results = []\n\n    for case in test_cases:\n        lambda_rate, T, c_s, c_P, c_U, a, b = case\n        \n        mu = lambda_rate * T\n\n        # Step 1: Hybrid Rule Prediction (Theoretical Choice)\n        c_seg_approx = c_s * (mu + 1)\n        \n        # The term a*mu*log2(max{mu,1}) is zero if mu = 1\n        log_term_approx = 0.0\n        if mu > 1:\n            log_term_approx = a * mu * np.log2(mu)\n        \n        c_cts_approx = c_P + (c_U + b) * mu + log_term_approx\n        \n        hybrid_choice_is_seg = (c_seg_approx = c_cts_approx)\n\n        # Step 2: Empirical Validation\n        # Use a new random number generator with a fixed seed for each independent case\n        rng = np.random.default_rng(SEED)\n        \n        # Generate R Poisson-distributed samples for the event count N\n        n_samples = rng.poisson(mu, R)\n        \n        # Calculate empirical costs for SEG (vectorized)\n        cost_seg_samples = c_s * (n_samples + 1)\n        \n        # Calculate empirical costs for CTS (vectorized)\n        # The N*log2(max{N,1}) term is 0 for N in {0, 1}.\n        log_term_samples = np.zeros_like(n_samples, dtype=float)\n        mask = n_samples > 1\n        log_term_samples[mask] = n_samples[mask] * np.log2(n_samples[mask])\n        \n        cost_cts_samples = c_P + (c_U + b) * n_samples + a * log_term_samples\n        \n        # Compute the mean costs over R replications\n        c_seg_empirical = np.mean(cost_seg_samples)\n        c_cts_empirical = np.mean(cost_cts_samples)\n        \n        # Step 3: Determine Empirically Optimal Choice\n        # Tie-breaking rule: choose SEG if costs are equal\n        empirical_choice_is_seg = (c_seg_empirical = c_cts_empirical)\n        \n        # Step 4: Validate Hybrid Rule\n        # The result is True if the theoretical choice matches the empirical one\n        validation_result = (hybrid_choice_is_seg == empirical_choice_is_seg)\n        results.append(validation_result)\n\n    # Print the final list of boolean results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3342349"}, {"introduction": "选择高效的算法后，关键的下一步是验证模拟输出在统计上是否正确。齐次泊松过程最基本的性质是其到达间隔时间服从指数分布。本练习 [@problem_id:3342341] 将指导您实施一个严格的拟合优度检验来验证此性质。您将学习如何处理一个常见的统计陷阱：当模型参数（例如率参数 $\\lambda$）本身是从数据中估计得到时，如何使用参数自助法（parametric bootstrap）来获得有效的p值。", "problem": "要求您设计并实现一个有原则的拟合优度程序，通过检验其指数性来评估模拟的到达间隔时间是否源自齐次泊松过程。背景是一个具有恒定速率 $\\lambda > 0$ 的齐次泊松过程。该问题的根本基础是齐次泊松过程的定义，即其具有独立且平稳的增量，并且其到达间隔时间是独立同分布的指数随机变量，速率为 $\\lambda$。该检验在使用估计速率进行缩放后，采用柯尔莫哥洛夫–斯米尔诺夫统计量，并且速率的校准必须从模拟的到达间隔数据本身进行。\n\n使用的原则：\n- 一个速率为 $\\lambda$ 的齐次泊松过程，其到达间隔时间 $\\{X_i\\}_{i=1}^n$ 独立同分布于速率为 $\\lambda$ 的指数分布，即累积分布函数为 $F_{\\lambda}(x) = 1 - e^{-\\lambda x}$，其中 $x \\ge 0$。\n- 柯尔莫哥洛夫–斯米尔诺夫 (KS) 统计量通过其绝对差的一致上确界，来比较经验累积分布函数与假设的累积分布函数。当假设的累积分布函数被完全指定且没有从数据中估计参数时，KS 统计量是无分布的。\n- 从相同的数据中估计 $\\lambda$ 会在原假设下引入经验累积分布函数与假设的累积分布函数之间的依赖关系，从而使得简单使用 KS 临界值表的方法失效。为了解决这个问题，应在原假设下使用参数化自举法，其中速率从数据中校准。\n\n您的程序必须为每个测试用例实现以下步骤：\n1. 根据指定的数据生成机制，使用提供的速率和分布规范，模拟 $n$ 个到达间隔时间。所有时间都应被视为无量纲的持续时间；不需要进行物理单位转换。\n2. 使用统计上可靠的方法，从模拟的到达间隔时间中校准速率 $\\lambda$。估计必须基于到达间隔样本本身。不得使用任何外部信息或提示。校准后的速率记为 $\\widehat{\\lambda}$，并且必须通过与指数族性质一致的、基于第一性原理的方法来计算。\n3. 通过 $\\widehat{\\lambda}$ 进行缩放后，构造用于检验指数性的柯尔莫哥洛夫–斯米尔诺夫统计量，如下所示：\n   - 用 $\\widehat{\\lambda}$ 缩放到达间隔时间，即对于 $i = 1, \\ldots, n$，构造 $Y_i = \\widehat{\\lambda} X_i$。\n   - 定义 $\\{Y_i\\}_{i=1}^n$ 的经验累积分布函数 $\\widehat{F}_n(y)$。\n   - 定义假设的累积分布函数 $F_0(y) = 1 - e^{-y}$，它对应于速率为 $1$ 的指数分布。\n   - 计算 KS 统计量 $D_n = \\sup_{y \\ge 0} \\left| \\widehat{F}_n(y) - F_0(y) \\right|$。\n4. 为了获得一个考虑到从数据中估计速率的有效 $p$ 值，需在到达间隔时间为指数分布的原假设下实现参数化自举法：\n   - 从速率为 $\\widehat{\\lambda}$ 的指数分布中生成 $B$ 个大小为 $n$ 的自举样本。\n   - 对于每个自举样本，从该样本中重新估计速率 $\\widehat{\\lambda}^{(b)}$，用 $\\widehat{\\lambda}^{(b)}$ 进行缩放，并计算其相对于 $F_0$ 的 KS 统计量 $D_n^{(b)}$。\n   - 自举 $p$ 值是大于或等于观测统计量的自举统计量的比例，即 $p = \\frac{1}{B} \\sum_{b=1}^B \\mathbf{1}\\{D_n^{(b)} \\ge D_n\\}$。\n5. 您的程序应生成单行输出，其中包含按测试套件顺序排列的结果，形式为方括号内以逗号分隔的列表，每个条目是四舍五入到六位小数的浮点数形式的自举 $p$ 值。\n\n测试套件：\n- 案例 1 (正常路径): 指数到达间隔，真实速率 $\\lambda = 2$，样本大小 $n = 500$，使用 $B = 400$ 次自举重复。\n- 案例 2 (模型设定错误): Gamma 到达间隔，形状参数 $k = 2$，速率参数 $\\beta = 2 \\lambda$ 以使均值等于 $1/\\lambda$，真实 $\\lambda = 2$，样本大小 $n = 500$，使用 $B = 400$ 次自举重复。\n- 案例 3 (小样本边界情况): 指数到达间隔，真实速率 $\\lambda = 1$，样本大小 $n = 20$，使用 $B = 400$ 次自举重复。\n- 案例 4 (污染): 指数分布的混合，其中速率为 $3 \\lambda$ 的概率为 $p = 0.3$，速率为 $\\lambda$ 的概率为 $1 - p$，真实 $\\lambda = 3$，样本大小 $n = 500$，使用 $B = 400$ 次自举重复。\n- 案例 5 (大样本): 指数到达间隔，真实速率 $\\lambda = 5$，样本大小 $n = 2000$，使用 $B = 300$ 次自举重复。\n\n随机性与可复现性：\n- 为每个测试用例使用固定的种子，以确保模拟数据和自举程序的可复现性。五个案例的种子值分别为 $1$、$2$、$3$、$4$ 和 $5$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含上述测试套件的五个自举 $p$ 值，按顺序排列，四舍五入到六位小数，并以逗号分隔的列表形式包含在方括号内（例如：\"[0.532000,0.041000,0.872000,0.010000,0.619000]\"）。", "solution": "验证一系列事件时间是否源自齐次泊松过程的问题，本质上是一个拟合优度问题。其指导原则是这类过程的一个核心属性：到达间隔时间 $\\{X_i\\}_{i=1}^n$ 是服从指数分布的独立同分布 (i.i.d.) 随机变量。齐次泊松过程由一个恒定的速率参数 $\\lambda > 0$ 来表征，其到达间隔时间的累积分布函数 (CDF) 为 $F_{\\lambda}(x) = 1 - e^{-\\lambda x}$，适用于任何时间 $x \\ge 0$。任务是设计一个程序，用于检验原假设 $H_0$，即给定的 $n$ 个到达间隔时间样本 $\\{X_i\\}_{i=1}^n$ 是从某个未知速率为 $\\lambda$ 的指数分布中抽取的。\n\n柯尔莫哥洛夫–斯米尔诺夫 (KS) 检验是检验拟合优度的标准方法。它将数据的经验累积分布函数 (ECDF)，记为 $\\widehat{F}_n(x)$，与假设的累积分布函数 (CDF) $F(x)$ 进行比较。ECDF 定义为样本中小于或等于 $x$ 的比例：$\\widehat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}\\{X_i \\le x\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。KS 检验统计量 $D_n$ 是这两个函数在所有可能的 $x$ 值上的最大绝对差：$D_n = \\sup_{x} |\\widehat{F}_n(x) - F(x)|$。\n\n一个关键的复杂问题在于，速率参数 $\\lambda$ 是未知的，必须从被检验的同一份数据中估计。这个过程违反了标准 KS 检验的假设，因为只有在假设的 CDF 被完全指定而无需参考数据时，其零分布才是无分布的。当参数被估计时，ECDF 往往比它与真实 CDF 更接近于估计的 CDF，从而导致检验统计量被人为地减小。这种效应使得标准 KS 检验的临界值表失效。\n\n为了构建一个有效的检验，我们首先将问题转换到一个无参数的空间。如果 $X_i$ 确实是速率为 $\\lambda$ 的指数分布，那么经过缩放的变量 $Y_i = \\lambda X_i$ 将是速率为 $1$ 的指数分布（一个标准指数分布）。由于 $\\lambda$ 未知，我们使用一个从数据中推导出的有原则的估计值 $\\widehat{\\lambda}$。指数分布速率参数的最大似然估计 (MLE) 是样本均值的倒数，$\\widehat{\\lambda} = 1 / \\overline{X} = n / (\\sum_{i=1}^n X_i)$。然后我们构造缩放后的样本 $\\{Y_i = \\widehat{\\lambda} X_i\\}_{i=1}^n$，并检验它是否服从 CDF 为 $F_0(y) = 1-e^{-y}$ 的标准指数分布。检验统计量变为 $D_n = \\sup_{y \\ge 0} |\\widehat{F}_n(y) - F_0(y)|$，其中 $\\widehat{F}_n(y)$ 是缩放后数据 $\\{Y_i\\}$ 的 ECDF。这是针对指数分布的利里福斯检验的一种形式。\n\n由于在缩放中使用了估计参数 $\\widehat{\\lambda}$，这个新统计量 $D_n$ 的零分布仍然不是标准的 KS 分布。为了正确评估观测值 $D_n$ 的统计显著性，我们必须确定其在原假设下的分布。参数化自举法为此提供了一种稳健的、由计算驱动的方法。该过程通过将我们估计的模型视为真实的数据生成过程来模拟零分布。\n\n算法如下：\n1.  **数据生成与初步分析**：对于给定的测试用例，根据指定的机制生成大小为 $n$ 的主数据样本 $\\{X_i\\}_{i=1}^n$。\n2.  **速率估计**：从此样本中计算速率的 MLE：$\\widehat{\\lambda} = n / \\sum_{i=1}^n X_i$。\n3.  **观测统计量**：缩放数据以获得 $\\{Y_i = \\widehat{\\lambda} X_i\\}_{i=1}^n$，并根据标准指数 CDF 计算观测到的 KS 统计量 $D_n = \\sup_{y \\ge 0} |\\widehat{F}_n(y) - F_0(y)|$。\n4.  **参数化自举法**：为了生成检验统计量的零分布，对 $b = 1, \\dots, B$ 执行以下步骤，其中 $B$ 是自举重复的次数：\n    a. 通过从速率为 $\\widehat{\\lambda}$ 的指数分布中抽取 $n$ 个独立同分布的值，生成一个自举样本 $\\{X_i^{(b)}\\}_{i=1}^n$。这在 $H_0$ 为真且我们对速率的最佳估计是正确的假设下，模拟了一个新的数据集。\n    b. 对于这个自举样本，重复整个分析过程：计算其自身的速率估计 $\\widehat{\\lambda}^{(b)} = n / \\sum_{i=1}^n X_i^{(b)}$；缩放其数据得到 $\\{Y_i^{(b)} = \\widehat{\\lambda}^{(b)} X_i^{(b)}\\}_{i=1}^n$；并计算相应的 KS 统计量 $D_n^{(b)}$。\n5.  **p值计算**：自举统计量的集合 $\\{D_n^{(b)}\\}_{b=1}^B$ 作为我们检验统计量零分布的经验近似。自举 $p$ 值是这些模拟统计量中大于或等于最初观测统计量的比例：$p = \\frac{1}{B} \\sum_{b=1}^B \\mathbf{1}\\{D_n^{(b)} \\ge D_n\\}$。一个小的 $p$ 值（例如 $\\le 0.05$）表明观测数据不大可能源自指数分布，从而提供了反对齐次泊松过程假设的证据。\n\n这个过程正确地考虑了参数估计的影响，并提供了一个有效的拟合优度检验。实现将使用 `scipy.stats.kstest` 来计算相对于标准指数分布（'expon'，其速率为 1）的 KS 统计量。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n\n    def estimate_rate(X):\n        \"\"\"\n        Computes the Maximum Likelihood Estimator (MLE) for the rate parameter\n        of an exponential distribution.\n        \"\"\"\n        # A small epsilon is added to avoid division by zero if mean is zero,\n        # which is practically impossible for non-empty positive-valued data.\n        return 1.0 / (np.mean(X) + np.finfo(float).eps)\n\n    def compute_ks_statistic(X, lambda_hat):\n        \"\"\"\n        Computes the Kolmogorov-Smirnov statistic for exponentiality after\n        scaling by the estimated rate.\n        \"\"\"\n        # Scale the data by the estimated rate.\n        Y = lambda_hat * X\n        # Perform KS test against the standard exponential distribution (rate=1),\n        # which is 'expon' in SciPy. We only need the statistic, not the p-value.\n        statistic, _ = kstest(Y, 'expon')\n        return statistic\n\n    def run_goodness_of_fit_test(case_params):\n        \"\"\"\n        Executes the entire goodness-of-fit procedure for a single test case.\n        \"\"\"\n        case_id = case_params['id']\n        dist_type = case_params['dist_type']\n        params = case_params['params']\n        n = case_params['n']\n        B = case_params['B']\n        seed = case_params['seed']\n\n        # Initialize Random Number Generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # 1. Simulate initial data sample\n        if dist_type == 'exponential':\n            true_lambda = params['lambda']\n            X = rng.exponential(scale=1.0/true_lambda, size=n)\n        elif dist_type == 'gamma':\n            k, beta = params['k'], params['beta']\n            X = rng.gamma(shape=k, scale=1.0/beta, size=n)\n        elif dist_type == 'mixture':\n            p, lambda1, lambda2 = params['p'], params['lambda1'], params['lambda2']\n            rates = np.where(rng.random(size=n)  p, lambda1, lambda2)\n            X = rng.exponential(scale=1.0/rates, size=n)\n        else:\n            raise ValueError(f\"Unknown distribution type: {dist_type}\")\n\n        # 2. Calibrate rate from the data\n        lambda_hat = estimate_rate(X)\n\n        # 3. Compute observed KS statistic\n        D_n_observed = compute_ks_statistic(X, lambda_hat)\n\n        # 4. Perform parametric bootstrap to find the p-value\n        bootstrap_stats = np.zeros(B)\n        for b in range(B):\n            # Generate a bootstrap sample under the null hypothesis (Exp(lambda_hat))\n            X_b = rng.exponential(scale=1.0/lambda_hat, size=n)\n            \n            # Re-estimate rate for the bootstrap sample\n            lambda_hat_b = estimate_rate(X_b)\n            \n            # Compute KS statistic for the bootstrap sample\n            D_n_b = compute_ks_statistic(X_b, lambda_hat_b)\n            bootstrap_stats[b] = D_n_b\n\n        # 5. Calculate bootstrap p-value\n        p_value = np.sum(bootstrap_stats >= D_n_observed) / B\n        \n        return p_value\n\n    # Define the test suite from the problem statement.\n    test_cases = [\n        {'id': 1, 'dist_type': 'exponential', 'params': {'lambda': 2}, 'n': 500, 'B': 400, 'seed': 1},\n        {'id': 2, 'dist_type': 'gamma', 'params': {'k': 2, 'beta': 4}, 'n': 500, 'B': 400, 'seed': 2},\n        {'id': 3, 'dist_type': 'exponential', 'params': {'lambda': 1}, 'n': 20, 'B': 400, 'seed': 3},\n        {'id': 4, 'dist_type': 'mixture', 'params': {'p': 0.3, 'lambda1': 9, 'lambda2': 3}, 'n': 500, 'B': 400, 'seed': 4},\n        {'id': 5, 'dist_type': 'exponential', 'params': {'lambda': 5}, 'n': 2000, 'B': 300, 'seed': 5},\n    ]\n\n    results = []\n    for case in test_cases:\n        p_val = run_goodness_of_fit_test(case)\n        results.append(p_val)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3342341"}, {"introduction": "除了拥有正确的分布，到达间隔时间序列还必须是相互独立的。模拟实现中一些微妙的错误可能会无意中引入序列相关性，从而违反这一核心假设，使整个模拟失效。在最后一个练习 [@problem_id:3342434] 中，您将实施一个综合检验（Ljung-Box检验）来检测模拟的到达间隔时间序列中是否存在序列相关性。这个强大的工具通过聚合多个时间滞后上的信息，为检验独立性提供了一个明确的判决。", "problem": "均匀泊松过程（homogeneous Poisson process）由事件在时间上的发生来定义，其满足：在任意长度为 $t$ 的时间区间内，事件发生的数量服从均值为 $\\lambda t$ 的泊松分布，并且在不相交区间上的增量是独立的。等价地，其到达间隔时间（interarrival times）构成一个独立的、同分布的指数随机变量序列，其率为 $\\lambda$。假设您已经实现了一个模拟器，用于生成均匀泊松过程的到达间隔时间序列，但您希望检测出连续到达间隔时间之间非预期的依赖性（相关性）。您的任务是设计并实现一个统计检验，该检验使用到达间隔时间序列的样本自相关（sample autocorrelations）来检测这种无意的相关性，并证明在独立性假设下的预期零分布（null distribution）。\n\n从基本定义和经过充分检验的事实出发，提出一个检验方法。该方法聚合到达间隔时间序列的有限数量的样本自相关，并在到达间隔时间是具有有限方差的独立同分布序列时，利用其渐近零分布（asymptotic null distribution）来做出决策。然后将该检验实现为一个完整的、可运行的程序，该程序能够：\n- 根据指定的参数集模拟到达间隔时间序列。\n- 计算直至给定最大滞后阶数（maximum lag）的样本自相关。\n- 将这些自相关聚合为单个检验统计量。\n- 使用在独立性假设下证明的渐近零分布计算 $p$ 值。\n- 对每个测试用例，如果独立性的原假设在指定的显著性水平下被拒绝，则输出布尔值 `true`，否则输出 `false`。\n\n到达间隔时间必须以时间单位生成，但本问题不要求进行物理单位转换。不涉及角度。显著性水平必须表示为小数（例如，$0.05$），而不是百分号。\n\n测试套件和参数规范：\n- 每个测试用例是一个参数元组 $(\\lambda, n, m, \\alpha, \\text{mode}, c, \\text{seed})$，其中 $\\lambda$ 是指数到达间隔时间的率参数，$n$ 是序列长度，$m$ 是样本自相关的最大滞后阶数，$\\alpha$ 是小数形式的显著性水平，$\\text{mode}$ 指定序列的生成方式，$c$ 是在某些模式下使用的相关性混合系数，$\\text{seed}$ 是用于可复现性的伪随机数生成器种子。\n- 生成模式如下：\n    - $\\text{mode} = \\text{\"independent\"}$：抽取 $n$ 个率为 $\\lambda$ 的独立指数随机变量。\n    - $\\text{mode} = \\text{\"mix\\_prev\"}$：抽取 $n$ 个率为 $\\lambda$ 的独立指数随机变量 $(Z_t)$，并设置 $X_0 = Z_0$，$X_t = (1-c) Z_t + c Z_{t-1}$（当 $t \\ge 1$ 时），其中 $0 \\le c  1$；这会引入正的1阶滞后相关性，同时保持相同的均值尺度。\n- 使用以下四个测试用例来检验解决方案的不同方面：\n    1. $(\\lambda = 1.0, n = 4000, m = 10, \\alpha = 0.05, \\text{mode} = \\text{\"independent\"}, c = 0.0, \\text{seed} = 20231101)$: 一个大样本独立情况（理想路径）。\n    2. $(\\lambda = 1.0, n = 3000, m = 10, \\alpha = 0.05, \\text{mode} = \\text{\"mix\\_prev\"}, c = 0.7, \\text{seed} = 20231102)$: 一个应能被检测出的中度相关情况。\n    3. $(\\lambda = 2.0, n = 60, m = 8, \\alpha = 0.05, \\text{mode} = \\text{\"independent\"}, c = 0.0, \\text{seed} = 20231103)$: 一个小样本独立情况（渐近近似的边界条件）。\n    4. $(\\lambda = 1.0, n = 2000, m = 15, \\alpha = 0.01, \\text{mode} = \\text{\"mix\\_prev\"}, c = 0.99, \\text{seed} = 20231104)$: 一个具有严格显著性水平的强相关情况（边缘情况）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表，例如 $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$。\n- 每个项目 $\\text{result}_i$ 必须是一个布尔值，表示对于第 $i$ 个测试用例，独立性的原假设是否在指定的显著性水平 $\\alpha$ 下被拒绝。", "solution": "该问题要求设计并实现一个统计检验，以检测来自均匀泊松过程的模拟到达间隔时间序列中非预期的序列相关性。这种过程的基本性质是，其到达间隔时间构成一个独立同分布（i.i.d.）的指数随机变量序列。所提出的检验将通过检查给定观测序列 $\\{X_t\\}_{t=1}^n$ 的样本自相关，来评估该序列是否偏离了此独立同分布假设。\n\n原假设 $H_0$ 是序列 $\\{X_t\\}_{t=1}^n$ 是独立同分布的。备择假设 $H_a$ 是该序列不是独立同分布的，具体而言，存在某种序列相关性，即理论自相关 $\\rho(k) = \\text{Corr}(X_t, X_{t+k})$ 对于至少一个滞后阶数 $k > 0$ 不为零。\n\n为完成此任务而选择的检验是 Ljung-Box Q检验，这是一种广泛使用且备受推崇的用于检测时间序列中序列相关性的方法。此检验的设计源于样本自相关的定义及其在原假设下的渐近性质。\n\n首先，我们为给定的时间序列 $X_1, X_2, \\dots, X_n$ 定义必要的样本统计量：\n样本均值为 $\\bar{X} = \\frac{1}{n} \\sum_{t=1}^{n} X_t$。\n滞后阶数为 $k \\ge 0$ 的样本自协方差定义为 $\\hat{\\gamma}(k) = \\frac{1}{n} \\sum_{t=1}^{n-k} (X_t - \\bar{X})(X_{t+k} - \\bar{X})$。\n滞后阶数为 $k \\ge 1$ 的样本自相关是归一化后的自协方差：$\\hat{\\rho}(k) = \\frac{\\hat{\\gamma}(k)}{\\hat{\\gamma}(0)}$。\n\n对该检验的零分布的论证是时间序列分析的基石之一。一个基于 Bartlett 近似的基本定理描述了具有有限方差的独立同分布序列的样本自相关的大样本行为。在 $\\{X_t\\}$ 是一个独立同分布序列（通常称为白噪声）的原假设下，对于足够大的样本量 $n$，滞后阶数 $k \\ge 1$ 的样本自相关 $\\hat{\\rho}(k)$ 近似独立，并服从均值为 $0$、方差为 $1/n$ 的正态分布。用符号表示为：\n$$\n\\sqrt{n} \\hat{\\rho}(k) \\xrightarrow{d} \\mathcal{N}(0, 1) \\quad \\text{对于 } k \\ge 1\n$$\n其中 $\\xrightarrow{d}$ 表示依分布收敛，$\\mathcal{N}(0, 1)$ 是标准正态分布。\n\n这一结果使得构建一个聚合了多个滞后信息的检验统计量成为可能。如果每个 $\\sqrt{n} \\hat{\\rho}(k)$ 近似是一个标准正态变量，那么它的平方 $(\\sqrt{n} \\hat{\\rho}(k))^2 = n \\hat{\\rho}(k)^2$ 近似是一个自由度为 $1$ 的卡方变量，即 $\\chi^2(1)$。因为在 $H_0$ 下，不同滞后阶数的 $\\hat{\\rho}(k)$ 值是近似独立的，所以 $m$ 个这样的平方项之和将近似服从自由度为 $m$ 的卡方分布。\n\n这一原理引出了 Box-Pierce 统计量，$Q_{BP} = n \\sum_{k=1}^{m} \\hat{\\rho}(k)^2$。一个对于较小 $n$ 更为精确的有限样本修正，是 Ljung-Box 统计量 $Q_{LB}$。我们将使用这个统计量。它定义为：\n$$\nQ_{LB} = n(n+2) \\sum_{k=1}^{m} \\frac{\\hat{\\rho}(k)^2}{n-k}\n$$\n在原假设 $H_0$ 下，$Q_{LB}$ 渐近服从自由度为 $m$ 的卡方分布，记为 $\\chi^2(m)$。自由度 $m$ 对应于被检验的自相关个数。\n\n检验步骤如下：\n1. 对于一个长度为 $n$ 的给定时间序列和选定的最大滞后阶数 $m$，计算样本自相关 $\\hat{\\rho}(1), \\hat{\\rho}(2), \\dots, \\hat{\\rho}(m)$。\n2. 使用上述公式计算 Ljung-Box 统计量 $Q_{LB}$。\n3. 计算 $p$ 值，即在 $H_0$ 为真的假设下，观测到等于或大于当前计算的检验统计量值的概率。这由 $p = P(\\chi^2_m \\ge Q_{LB})$ 给出。\n4. 将 $p$ 值与预先指定的显著性水平 $\\alpha$ 进行比较。如果 $p  \\alpha$，我们拒绝独立性的原假设，并断定数据中存在显著的序列相关性证据。否则，我们不拒绝 $H_0$。\n\n该实现将根据指定的两种模式模拟时间序列数据：\n- **`independent` 模式**：序列 $X_t$ 是通过从率为 $\\lambda$ 的指数分布中抽取 $n$ 个独立同分布样本生成的。其概率密度函数为 $f(x; \\lambda) = \\lambda e^{-\\lambda x}$（当 $x \\ge 0$ 时）。数值计算库中使用的尺度参数是率的倒数，即 $\\beta = 1/\\lambda$。根据其构造，此模式应满足原假设。\n- **`mix_prev` 模式**：首先生成一个率为 $\\lambda$ 的底层独立同分布指数序列 $\\{Z_t\\}$。然后构造观测序列 $\\{X_t\\}$ 为 $X_0 = Z_0$ 和 $X_t = (1-c)Z_t + cZ_{t-1}$（当 $t \\ge 1$ 时）。这种构造，一个应用于独立同分布新息的 1 阶移动平均过程（MA(1)），有意地在连续项之间引入了依赖性。当 $c > 0$ 时，1阶滞后自相关将不为零，从而违反原假设。\n\n对于每个测试用例，程序将生成序列，计算 $Q_{LB}$ 统计量，从 $\\chi^2(m)$ 分布中找到相应的 $p$ 值，并返回一个布尔值，以指示是否在给定的显著性水平 $\\alpha$ 下拒绝 $H_0$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Designs and implements a statistical test to detect serial correlation\n    in simulated interarrival sequences of a homogeneous Poisson process.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (lambda, n, m, alpha, mode, c, seed)\n        (1.0, 4000, 10, 0.05, \"independent\", 0.0, 20231101),\n        (1.0, 3000, 10, 0.05, \"mix_prev\", 0.7, 20231102),\n        (2.0, 60, 8, 0.05, \"independent\", 0.0, 20231103),\n        (1.0, 2000, 15, 0.01, \"mix_prev\", 0.99, 20231104),\n    ]\n\n    results = []\n    for case in test_cases:\n        lambda_val, n, m, alpha, mode, c, seed = case\n\n        # Set up the random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # Step 1: Generate the interarrival sequence\n        if mode == \"independent\":\n            # Generate n i.i.d. exponential random variables\n            x_seq = rng.exponential(scale=1.0 / lambda_val, size=n)\n        elif mode == \"mix_prev\":\n            # Generate underlying i.i.d. sequence Z\n            z_seq = rng.exponential(scale=1.0 / lambda_val, size=n)\n            # Create the correlated sequence X\n            x_seq = np.zeros_like(z_seq)\n            x_seq[0] = z_seq[0]\n            if n > 1:\n                x_seq[1:] = (1 - c) * z_seq[1:] + c * z_seq[:-1]\n        else:\n            raise ValueError(f\"Unknown mode: {mode}\")\n\n        # Step 2: Compute sample autocorrelations up to lag m\n        n_obs = len(x_seq)\n        x_mean = np.mean(x_seq)\n        x_centered = x_seq - x_mean\n        \n        # Autocovariance at lag 0\n        gamma0 = np.sum(x_centered**2) / n_obs\n        \n        # Avoid division by zero if variance is zero\n        if gamma0 == 0:\n            # If variance is zero, all autocorrelations are undefined or 0.\n            # No correlation to detect. Do not reject H0.\n            results.append(False)\n            continue\n\n        rhos = []\n        for k in range(1, m + 1):\n            # Autocovariance at lag k\n            gammak = np.sum(x_centered[:n_obs - k] * x_centered[k:]) / n_obs\n            # Autocorrelation at lag k\n            rhok = gammak / gamma0\n            rhos.append(rhok)\n        \n        rhos_sq = np.array(rhos)**2\n        \n        # Step 3: Compute the Ljung-Box test statistic\n        k_indices = np.arange(1, m + 1)\n        lb_stat = n_obs * (n_obs + 2) * np.sum(rhos_sq / (n_obs - k_indices))\n\n        # Step 4: Compute the p-value using the asymptotic chi-squared distribution\n        # The degrees of freedom is m, the number of lags tested.\n        p_value = chi2.sf(lb_stat, df=m)\n\n        # Step 5: Reject H0 if p-value is less than the significance level\n        reject_h0 = p_value  alpha\n        results.append(reject_h0)\n\n    # Final print statement in the exact required format.\n    # The boolean results are converted to lowercase strings 'true'/'false'.\n    print(f\"[{','.join(map(lambda b: str(b).lower(), results))}]\")\n\nsolve()\n```", "id": "3342434"}]}