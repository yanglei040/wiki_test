{"hands_on_practices": [{"introduction": "本章的第一个练习是基础性的，它要求您亲自动手为一个简单的一维点集计算星偏差 (star discrepancy) [@problem_id:3303337]。通过这个过程，您将揭开抽象定义的神秘面纱，并对“上确界”运算的实际含义以及偏差如何量化不均匀性有一个具体的感受。", "problem": "设 $\\{x_{n}\\}_{n=1}^{N} \\subset [0,1]$ 是一个用于准蒙特卡罗（QMC）方法的点集，回顾 $s$ 维的星偏差定义为\n$$\nD_{N}^{*}(\\{x_{n}\\}_{n=1}^{N}) \\;=\\; \\sup_{\\mathbf{t} \\in [0,1]^{s}} \\left| \\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{1}\\{x_{n} \\in [\\mathbf{0},\\mathbf{t})\\} \\;-\\; \\prod_{j=1}^{s} t_{j} \\right|,\n$$\n其中 $[\\mathbf{0},\\mathbf{t}) = \\prod_{j=1}^{s} [0,t_{j})$ 且 $\\mathbf{1}\\{\\cdot\\}$ 表示指示函数。专用于一维情况 $s=1$，于是\n$$\nD_{N}^{*}(\\{x_{n}\\}_{n=1}^{N}) \\;=\\; \\sup_{t \\in [0,1]} \\left| \\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{1}\\{x_{n}  t\\} \\;-\\; t \\right|.\n$$\n考虑等距点集 $x_{n} = \\frac{n}{N}$，其中 $n=1,2,\\dots,N$。从上述定义出发，推导 $D_{N}^{*}$ 作为 $N$ 的函数的精确闭式表达式。然后，根据一维最优性解释你的结果：将你得到的值与 $[0,1]$ 上任何 $N$ 点集可实现的最小可能星偏差进行比较，并说明等距端点设计在一维中是否最优。\n\n将 $D_{N}^{*}$ 的最终答案表示为 $N$ 的闭式函数。无需四舍五入。", "solution": "这个问题是有效的，因为它具有科学依据、问题明确、客观且自洽。它是均匀分布理论和准蒙特卡罗方法中的一个标准练习。\n\n题目要求我们推导一维点集 $\\{x_n\\}_{n=1}^N$（其中 $x_n = \\frac{n}{N}$，$n=1, 2, \\dots, N$）的星偏差 $D_N^*$ 的闭式表达式。一维星偏差定义为：\n$$\nD_{N}^{*}(\\{x_{n}\\}_{n=1}^{N}) = \\sup_{t \\in [0,1]} \\left| \\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{1}\\{x_{n}  t\\} - t \\right|\n$$\n让我们定义我们要求其上确界的函数：\n$$\nf(t) = E_N(t) - t = \\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{1}\\{x_{n}  t\\} - t\n$$\n这里，$E_N(t)$ 是该点集的经验分布函数。这些点是 $x_1 = \\frac{1}{N}, x_2 = \\frac{2}{N}, \\dots, x_N = \\frac{N}{N} = 1$。这些点将区间 $[0,1]$ 划分为子区间。我们将分析函数 $f(t)$ 在这些子区间上的行为。\n\n定义域 $[0,1]$ 可以写成点 $\\{0\\}$ 和区间 $(\\frac{k}{N}, \\frac{k+1}{N}]$（其中 $k=0, 1, \\dots, N-1$）的并集。\n\n情况1：$t=0$。\n在 $t=0$ 时，没有点 $x_n = \\frac{n}{N}$（它们都是正数）严格小于 $0$。因此，求和为 $0$。\n$$\nf(0) = \\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{1}\\{x_{n}  0\\} - 0 = \\frac{0}{N} - 0 = 0\n$$\n\n情况2：$t \\in (0, \\frac{1}{N}]$。\n对于此区间内的任何 $t$，没有点 $x_n = \\frac{n}{N}$ 严格小于 $t$。最小的点是 $x_1 = \\frac{1}{N}$，对于任何 $t \\in (0, \\frac{1}{N}]$，我们有 $x_n \\ge \\frac{1}{N} \\ge t$。因此，对于所有 $n$，$\\mathbf{1}\\{x_n  t\\} = 0$。\n经验分布函数为 $E_N(t) = 0$。\n函数 $f(t)$ 变为：\n$$\nf(t) = 0 - t = -t\n$$\n我们关心的是 $|f(t)| = t$。在区间 $(0, \\frac{1}{N}]$ 上，此函数在 $t=\\frac{1}{N}$ 处取最大值，此时 $|f(\\frac{1}{N})| = \\frac{1}{N}$。\n\n情况3：$t \\in (\\frac{k}{N}, \\frac{k+1}{N}]$，其中 $k=1, 2, \\dots, N-1$。\n对于此类区间中的任何 $t$，我们需要计算有多少个点 $x_n = \\frac{n}{N}$ 严格小于 $t$。\n条件 $x_n  t$ 即为 $\\frac{n}{N}  t$。\n由于 $t > \\frac{k}{N}$，点 $x_1=\\frac{1}{N}, x_2=\\frac{2}{N}, \\dots, x_k=\\frac{k}{N}$ 都严格小于 $t$。这总共有 $k$ 个点。\n由于 $t \\le \\frac{k+1}{N}$，对于任何 $n \\ge k+1$，我们有 $x_n = \\frac{n}{N} \\ge \\frac{k+1}{N} \\ge t$。所以这些点不严格小于 $t$。\n因此，对于任何 $t \\in (\\frac{k}{N}, \\frac{k+1}{N}]$，恰好有 $k$ 个点满足 $x_n  t$。\n经验分布函数为 $E_N(t) = \\frac{k}{N}$。\n在此区间上，函数 $f(t)$ 为：\n$$\nf(t) = \\frac{k}{N} - t\n$$\n这是一个关于 $t$ 的线性函数，斜率为 $-1$。为了找到它在区间 $(\\frac{k}{N}, \\frac{k+1}{N}]$ 上绝对值的上确界，我们检查端点。\n当 $t$ 从右侧趋近于左端点，即 $t \\to (\\frac{k}{N})^{+}$ 时：\n$$\n\\lim_{t \\to (\\frac{k}{N})^{+}} f(t) = \\frac{k}{N} - \\frac{k}{N} = 0\n$$\n在右端点 $t = \\frac{k+1}{N}$ 处：\n$$\nf\\left(\\frac{k+1}{N}\\right) = \\frac{k}{N} - \\frac{k+1}{N} = -\\frac{1}{N}\n$$\n在区间 $(\\frac{k}{N}, \\frac{k+1}{N}]$ 上，$f(t)$ 的范围从（但不包括）$0$ 到 $-\\frac{1}{N}$。因此，$|f(t)|$ 的范围从 $0$ 到 $\\frac{1}{N}$。在此区间上，$|f(t)|$ 的上确界是 $\\frac{1}{N}$。\n\n综合所有情况，对于任何 $t \\in (0,1]$，存在一个 $k \\in \\{0, \\dots, N-1\\}$ 使得 $t \\in (\\frac{k}{N}, \\frac{k+1}{N}]$。在每一个这样的区间上，$|f(t)|$ 的上确界都是 $\\frac{1}{N}$。在 $t=0$ 时， $|f(0)|=0$。\n因此，在整个区间 $[0,1]$ 上的总上确界是这些值的最大值。\n$$\nD_N^* = \\sup_{t \\in [0,1]} |f(t)| = \\max\\left( |f(0)|, \\sup_{t \\in (0,1]} |f(t)| \\right) = \\max\\left(0, \\frac{1}{N}\\right) = \\frac{1}{N}\n$$\n此点集的星偏差的闭式表达式是 $D_N^* = \\frac{1}{N}$。\n\n对于问题的第二部分，我们必须解释这个结果。在一维中，一个经典的结果是，对于任何 $N$ 个点的集合 $\\{y_n\\}_{n=1}^N \\subset [0,1]$，其星偏差有一个下界：\n$$\nD_N^*(\\{y_n\\}_{n=1}^N) \\ge \\frac{1}{2N}\n$$\n这个下界是紧的（sharp）。它可以由点集 $y_n = \\frac{2n-1}{2N}$（其中 $n=1, \\dots, N$）达到。这个集合由区间 $[\\frac{n-1}{N}, \\frac{n}{N}]$ 的中点组成。这个集合的星偏差恰好是 $\\frac{1}{2N}$。达到最小可能偏差的点集称为最优（optimal）点集。\n问题中给出的点集 $x_n = \\frac{n}{N}$ 产生的偏差为 $D_N^* = \\frac{1}{N}$。\n将我们的结果与最优值比较，我们得到 $\\frac{1}{N}$ 与 $\\frac{1}{2N}$。对于任何 $N > 1$，我们看到 $\\frac{1}{N} > \\frac{1}{2N}$。\n因此，等距端点设计 $x_n = \\frac{n}{N}$ 在一维中不是最优的，因为它的星偏差是最小可能值的两倍。", "answer": "$$\n\\boxed{\\frac{1}{N}}\n$$", "id": "3303337"}, {"introduction": "在掌握了基本计算之后，这项实践将挑战您构建一种广泛使用的低偏差序列——Halton 序列 [@problem_id:3303284]。您将亲手实现其生成算法，并计算其星偏差，从而将理论序列与其在多维空间中的实际均匀性评估联系起来。这个练习是从理论走向实际应用的关键一步。", "problem": "您的任务是为准蒙特卡罗（QMC）方法构建低差异点，并通过星差异来量化其均匀性。请使用以下基本定义。\n\n设 $p \\geq 2$ 为一个整数基，$n \\in \\mathbb{N}$ 为一个正整数。将 $n$ 以 $p$ 为基展开为 $n = \\sum_{k=0}^{K} a_k p^k$，其中数字 $a_k \\in \\{0,1,\\dots,p-1\\}$。以 $p$ 为基的根倒函数是映射 $\\phi_p : \\mathbb{N} \\to [0,1)$，定义如下：\n$$\n\\phi_p(n) = \\sum_{k=0}^{K} a_k p^{-(k+1)}.\n$$\n对于维度 $s \\in \\mathbb{N}$ 和两两互质的整数基 $(p_1,\\dots,p_s)$（传统上使用不同的素数），$s$ 维Halton序列由以下点定义：\n$$\n\\mathbf{x}_n = \\big(\\phi_{p_1}(n),\\dots,\\phi_{p_s}(n)\\big), \\quad n = 1,2,\\dots.\n$$\n\n对于一个有限点集 $P_N = \\{\\mathbf{x}_1,\\dots,\\mathbf{x}_N\\} \\subset [0,1)^s$，其星差异定义为：\n$$\nD_N^*(P_N) = \\sup_{\\mathbf{u} \\in [0,1]^s} \\left| \\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\{\\mathbf{x}_i \\in [\\mathbf{0},\\mathbf{u})\\} - \\prod_{j=1}^s u_j \\right|,\n$$\n其中 $[\\mathbf{0},\\mathbf{u}) = \\prod_{j=1}^s [0,u_j)$ 且 $\\mathbf{1}\\{\\cdot\\}$ 表示指示函数。\n\n您的任务是：\n\n1. 根据其以 $p$ 为基的定义，实现根倒函数 $\\phi_p(n)$，并使用基 $(p_1,\\dots,p_s)$ 构建维度为 $s$ 的Halton序列的前 $N$ 个点 $\\mathbf{x}_1,\\dots,\\mathbf{x}_N$。\n2. 通过在如下定义的有限候选集上评估上确界来计算精确的星差异 $D_N^*(P_N)$：令 $U_j$ 为由所有坐标 $\\{x_{i,j} : i=1,\\dots,N\\}$ 与值 $1$ 组成的集合，并考虑笛卡尔积 $U = U_1 \\times \\dots \\times U_s$。在所有 $\\mathbf{u} \\in U$ 上评估差异表达式并取最大值。这种方法能精确计算星差异 $D_N^*(P_N)$，因为对于锚定框，上确界是在这样的网格点上取得的。\n3. 除了实现计算之外，（在您的解题报告中，而非代码中）请定性地论证，当 $(p_1,\\dots,p_s)$ 是不同的小素数且 $N$ 增加时，$D_N^*(P_N)$ 如何随维度 $s$ 增长。您的论证需基于上述定义以及锚定框的组合结构。此任务不涉及物理单位，也不涉及角度。\n\n测试套件：\n- 案例 A：$N = 1$, $(p_1) = (2)$, $s = 1$。\n- 案例 B：$N = 10$, $(p_1,p_2) = (2,3)$, $s = 2$。\n- 案例 C：$N = 12$, $(p_1,p_2,p_3) = (2,5,3)$, $s = 3$。\n- 案例 D：$N = 20$, $(p_1,p_2,p_3,p_4) = (2,3,5,7)$, $s = 4$。\n\n您的程序应该：\n- 为每个案例构建 $P_N$，\n- 使用上述候选集 $U$ 精确计算 $D_N^*(P_N)$，\n- 生成单行输出，其中包含四个案例的星差异值，格式为方括号内用逗号分隔的列表，顺序为 A、B、C、D，例如，\"[0.5,0.123,0.456,0.789]\"。每个值必须是实数（浮点数）；不应打印任何额外文本。", "solution": "该问题要求实现并分析Halton序列及其星差异。解题过程分为三个部分：首先，我们阐述生成Halton序列点的算法；其次，我们详述按规定计算星差异的步骤；最后，我们对差异在高维下的行为提供一个定性论证。\n\nHalton序列是一种确定性的低差异序列，用于准蒙特卡罗方法中，以生成比伪随机点分布更均匀的点。它的构建基于根倒函数。\n\n设 $p \\geq 2$ 为一个整数基。任何正整数 $n$ 都有唯一的以 $p$ 为基的展开式 $n = \\sum_{k=0}^{K} a_k p^k$，其中数字 $a_k$ 属于 $\\{0, 1, \\dots, p-1\\}$。根倒函数 $\\phi_p: \\mathbb{N} \\to [0,1)$ 的定义是将这个展开式围绕小数点进行翻转：\n$$\n\\phi_p(n) = \\sum_{k=0}^{K} a_k p^{-(k+1)}.\n$$\n为了为给定的整数 $n$ 和基 $p$ 实现这个函数，可以迭代地提取 $n$ 的以 $p$ 为基的各位数字。获取以 $p$ 为基的各位数字的标准算法从最低有效位开始，$a_0 = n \\pmod p$。下一位是 $a_1 = (n // p) \\pmod p$，依此类推。计算 $\\phi_p(n)$ 的算法如下：初始化结果 $r$ 为 $0$，因子 $f$ 为 $1/p$。当 $n>0$ 时，计算数字 $d = n \\pmod p$，将 $d \\cdot f$ 加到 $r$ 上，将 $f$ 更新为 $f/p$，并将 $n$ 更新为 $n // p$。这个过程正确地计算了求和，因为因子 $f$ 依次取值 $p^{-1}, p^{-2}, \\dots$，分别对应于数字 $a_0, a_1, \\dots$。\n\n一个 $s$ 维Halton序列是使用 $s$ 个两两互质的整数基 $(p_1, p_2, \\dots, p_s)$ 构建的，这些基通常选择为前 $s$ 个素数。序列中的第 $n$ 个点（对于 $n=1, 2, \\dots, N$）由下式给出：\n$$\n\\mathbf{x}_n = \\big(\\phi_{p_1}(n), \\phi_{p_2}(n), \\dots, \\phi_{p_s}(n)\\big).\n$$\n生成点集 $P_N = \\{\\mathbf{x}_1, \\dots, \\mathbf{x}_N\\}$ 的过程包括将 $n$ 从 $1$ 迭代到 $N$，并对每个 $n$，使用相应的基通过根倒函数计算 $\\mathbf{x}_n$ 的 $s$ 个分量。\n\n点集 $P_N$ 的均匀性由其星差异 $D_N^*(P_N)$ 来量化。该度量衡量了点的经验分布与所有形如 $[\\mathbf{0}, \\mathbf{u}) = [0, u_1) \\times \\dots \\times [0, u_s)$（其中 $\\mathbf{u} = (u_1, \\dots, u_s) \\in [0,1]^s$）的锚定超矩形（框）上的均匀分布之间的最大偏差。其定义如下：\n$$\nD_N^*(P_N) = \\sup_{\\mathbf{u} \\in [0,1]^s} \\left| \\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\{\\mathbf{x}_i \\in [\\mathbf{0},\\mathbf{u})\\} - \\text{Vol}([\\mathbf{0},\\mathbf{u})) \\right|,\n$$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数，框的体积为 $\\text{Vol}([\\mathbf{0},\\mathbf{u})) = \\prod_{j=1}^s u_j$。项 $\\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\{\\mathbf{x}_i \\in [\\mathbf{0},\\mathbf{u})\\}$ 表示 $P_N$ 中落入框 $[\\mathbf{0}, \\mathbf{u})$ 内的点的比例。\n\n在连续域 $[0,1]^s$ 上直接计算上确界是不可行的。然而，差异理论中的一个已知结果是，上确界总是在一个点 $\\mathbf{u}$ 上取得，该点的坐标取自点集 $P_N$ 中各点的坐标。问题指定了基于此原理的精确计算程序。我们定义一个有限的测试点 $\\mathbf{u}$ 的候选集。对于每个维度 $j \\in \\{1,\\dots,s\\}$，令 $U_j$ 为 $P_N$ 中所有点的第 $j$ 维坐标的集合，并增补值 $1$：$U_j = \\{x_{i,j} : i=1,\\dots,N\\} \\cup \\{1\\}$。完整的候选点集是笛卡尔积 $U = U_1 \\times \\dots \\times U_s$。然后通过在所有 $\\mathbf{u} \\in U$ 上找到差异函数的最大值来计算星差异。算法如下：\n1. 生成点集 $P_N = \\{\\mathbf{x}_1, \\dots, \\mathbf{x}_N\\}$。\n2. 对每个维度 $j=1, \\dots, s$，形成唯一坐标集 $U_j = \\text{unique}(\\{x_{i,j}\\}_{i=1}^N) \\cup \\{1\\}$。\n3. 初始化变量 `max_discrepancy` 为 $0$。\n4. 对于笛卡尔积 $U_1 \\times \\dots \\times U_s$ 中的每个向量 $\\mathbf{u}$：\n   a. 计算体积 $V = \\prod_{j=1}^s u_j$。\n   b. 计数点数 $C = \\sum_{i=1}^N \\mathbf{1}\\{\\mathbf{x}_i  \\mathbf{u}\\}$，其中 $\\mathbf{x}_i  \\mathbf{u}$ 是 $x_{i,j}  u_j$ 对所有 $j=1, \\dots, s$ 成立的简写。\n   c. 计算局部差异 $d = |C/N - V|$。\n   d. 更新 `max_discrepancy` = $\\max(\\text{max\\_discrepancy}, d)$。\n最终的 `max_discrepancy` 就是 $D_N^*(P_N)$ 的精确值。$U$ 中的候选点数量最多为 $(N+1)^s$，对于测试套件中指定的参数，这在计算上是可行的。\n\n最后，我们考虑在固定点数 $N$ 的情况下，当维度 $s$ 增加时 $D_N^*(P_N)$ 的定性行为。随着 $s$ 的增长，单位超立方体 $[0,1)^s$ 的体积越来越集中于其边界附近，这种效应被称为“维度灾难”。在这个高维空间中，固定的点数 $N$ 会变得越来越稀疏，从而使得保持均匀性变得困难得多。潜在的“空”区域或点数不成比例的区域数量会急剧增加。用于差异性测试的空间的组合复杂性也随之增长，因为测试网格 $U$ 的顶点数受 $(N+1)^s$ 的限制。这种爆炸性增长意味着，更容易找到一个框 $[\\mathbf{0}, \\mathbf{u})$，使其经验测度 $C/N$ 与其体积 $V$ 有显著偏离。这种直觉得到了关于Halton序列星差异的理论界的支持，其形式为 $D_N^*(P_N) = O\\left(\\frac{(\\log N)^s}{N}\\right)$。对于固定的 $N$，这个界随 $s$ 呈指数增长（如 $(\\log N)^s$）。因此，我们预期随着维度 $s$ 的增加，$D_N^*(P_N)$ 会增大——点集的质量会下降——特别是当 $N$ 没有相应增加时。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import product\n\ndef radical_inverse(n, base):\n    \"\"\"\n    Computes the radical inverse of an integer n in a given base.\n    This corresponds to the van der Corput sequence, which is the 1D Halton sequence.\n    \"\"\"\n    if n == 0:\n        return 0.0\n    \n    res = 0.0\n    p_inv = 1.0 / base\n    temp_n = n\n    while temp_n > 0:\n        digit = temp_n % base\n        res += digit * p_inv\n        p_inv /= base\n        temp_n //= base\n    return res\n\ndef halton_sequence(n_points, dim, bases):\n    \"\"\"\n    Generates the first n_points of an s-dimensional Halton sequence.\n    \"\"\"\n    points = np.zeros((n_points, dim))\n    for i in range(n_points):\n        # The sequence is defined for n = 1, 2, ...\n        n_val = i + 1\n        for d in range(dim):\n            points[i, d] = radical_inverse(n_val, bases[d])\n    return points\n\ndef compute_star_discrepancy(points, n_points, dim):\n    \"\"\"\n    Computes the exact star discrepancy for a given point set P_N.\n    The supremum is evaluated over a finite grid of test points U,\n    as specified in the problem statement.\n    \"\"\"\n    if n_points == 0:\n        return 0.0\n\n    # Build the candidate coordinate sets U_j for each dimension j\n    # U_j = {x_{i,j} for i=1..N} U {1}\n    candidate_coords = []\n    for j in range(dim):\n        # Get unique coordinates for dimension j and add 1.0\n        coords_j = np.unique(points[:, j]).tolist()\n        coords_j.append(1.0)\n        candidate_coords.append(coords_j)\n    \n    max_discrepancy = 0.0\n    \n    # Iterate through all test vectors u in the Cartesian product U\n    # U = U_1 x U_2 x ... x U_s\n    for u in product(*candidate_coords):\n        u_vec = np.array(u)\n        \n        # Volume of the box [0, u) is the product of its side lengths\n        volume = np.prod(u_vec)\n        \n        # Count points x_i such that x_i  u (element-wise)\n        count = np.sum(np.all(points  u_vec, axis=1))\n        \n        # Empirical measure: fraction of points in the box\n        empirical_measure = count / n_points\n        \n        # Local discrepancy at this test point u\n        discrepancy = np.abs(empirical_measure - volume)\n        \n        # Update the maximum discrepancy found so far\n        if discrepancy > max_discrepancy:\n            max_discrepancy = discrepancy\n            \n    return max_discrepancy\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        # Case A: N=1, s=1, p=(2)\n        {'N': 1, 's': 1, 'bases': [2]},\n        # Case B: N=10, s=2, p=(2,3)\n        {'N': 10, 's': 2, 'bases': [2, 3]},\n        # Case C: N=12, s=3, p=(2,5,3)\n        {'N': 12, 's': 3, 'bases': [2, 5, 3]},\n        # Case D: N=20, s=4, p=(2,3,5,7)\n        {'N': 20, 's': 4, 'bases': [2, 3, 5, 7]},\n    ]\n\n    results = []\n    for case in test_cases:\n        N = case['N']\n        s = case['s']\n        bases = case['bases']\n\n        # 1. Construct the Halton point set P_N\n        points = halton_sequence(N, s, bases)\n        \n        # 2. Compute the star discrepancy D_N*(P_N)\n        discrepancy = compute_star_discrepancy(points, N, s)\n        results.append(discrepancy)\n\n    # Format the final output as a comma-separated list in brackets\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the solver\nsolve()\n```", "id": "3303284"}, {"introduction": "最后的这项实践展示了偏差概念在真实应用中的强大威力 [@problem_id:3303333]。您将探索一种为蒙特卡洛积分构建可靠误差界限的方法，该方法巧妙地将偏差理论应用于函数的输出值，因此即使对于传统误差分析方法（如 Koksma-Hlawka 不等式）失效的不连续函数也同样有效。", "problem": "您的任务是为不连续函数的蒙特卡洛积分估计构建考虑了偏差（discrepancy-aware）的误差棒，该方法在Hardy–Krause变差为无穷大时仍然有效。考虑在$[0,1]^d$上的均匀概率测度下，对一个有界可测函数$f:[0,1]^d \\to \\mathbb{R}$进行积分，目标积分是期望$\\mathbb{E}[f(X)]$，其中$X \\sim \\text{Uniform}([0,1]^d)$。经典的Koksma–Hlawka不等式使用Hardy–Krause变差来界定拟蒙特卡洛方法的积分误差，但当维度$d \\geq 2$时不连续函数$f$的$V_{\\mathrm{HK}}(f)=\\infty$时，该不等式变得无效。您的目标是推导并实现一种替代方法，该方法使用前推样本值$Y_i = f(X_i)$的偏差（discrepancy），并产生有限且严格的误差棒，而不依赖于Hardy–Krause变差。\n\n从第一性原理出发，按以下步骤进行。从前推随机变量$Y = f(X)$的经验累积分布函数（empirical cumulative distribution function, ECDF）的定义开始，记为$F_n(t) = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{Y_i \\le t\\}$，其中$Y_i = f(X_i)$，$X_i$是从$[0,1]^d$上的均匀分布中独立同分布抽取的样本。利用关于ECDF几乎必然一致收敛于真实累积分布函数$F_Y(t)$的成熟结论，并将积分误差$\\left|\\frac{1}{n}\\sum_{i=1}^n f(X_i) - \\mathbb{E}[f(X)]\\right|$严格地与一个使用$Y_i$的ECDF的Kolmogorov–Smirnov偏差表示的界限联系起来。仅根据以下几项，为$\\mathbb{E}[f(X)]$推导出高置信度的误差棒：\n- 样本值$Y_1,\\dots,Y_n$，\n- 函数$f$有界且界限已知，$a \\le f(x) \\le b$对所有$x \\in [0,1]^d$成立，\n- 以及ECDF的标准、免分布不等式。\n\n您必须在一个程序中实现所得的误差棒，并在维度$d \\ge 2$且$V_{\\mathrm{HK}}(f)=\\infty$的不连续函数$f$上展示其行为。在下面的所有测试用例中，$f$是某个几何区域的指示函数，因此$Y = f(X) \\in \\{0,1\\}$且$(a,b) = (0,1)$。使用固定随机种子的独立同分布抽样来获取$X_i$，并计算：\n- 蒙特卡洛估计值$\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^n Y_i$，\n- 一个基于$Y_i$的ECDF偏差、置信水平为$1 - \\alpha$的$\\mathbb{E}[f(X)]$的严格双边置信区间$[\\mathrm{L}, \\mathrm{U}]$，\n- 真实积分值$\\mu^\\star$（对于所选区域，该值可解析得到），\n- 以及一个布尔值，指示$\\mu^\\star \\in [\\mathrm{L},\\mathrm{U}]$是否成立。\n\n推导中需要使用的基本原理：\n- 实值随机变量$Y$的经验累积分布函数$F_n$和真实累积分布函数$F_Y$的定义。\n- 通过尾部积分，用分布函数表示有界随机变量期望的恒等式。\n- 经验累积分布函数一致收敛于真实累积分布函数，并拥有非渐近的免分布指数尾部界限这一事实。\n\n您不得依赖任何从Hardy–Krause变差推导出的界限，并且必须确保所得的误差棒在$V_{\\mathrm{HK}}(f) = \\infty$时有效。您的程序必须仅使用$Y_i$的ECDF的偏差来计算这些误差棒，并按如下规定生成最终结果。\n\n测试套件：\n对于每个测试用例，使用固定的种子在$[0,1]^d$上均匀生成$n$个独立同分布的点$X_i$，计算$Y_i = f(X_i)$，并计算所要求的输出。\n\n- 测试用例1（顺利路径，中等样本量）：\n  - 维度：$d = 2$。\n  - 函数：$f(x) = \\mathbf{1}\\{\\|x - c\\|_2 \\le r\\}$，其中$c = (0.5, 0.5)$且$r = 0.3$。\n  - 该函数$f$在$d \\ge 2$维的弯曲边界上不连续，因此$V_{\\mathrm{HK}}(f) = \\infty$。\n  - 解析积分：单位正方形内半径为$r$的圆盘面积，等于$\\mu^\\star = \\pi r^2$，因为当$r=0.3$时，该圆盘完全位于$[0,1]^2$内。\n  - 样本量：$n = 4096$。\n  - 置信参数：$\\alpha = 0.05$。\n  - 种子：$12345$。\n\n- 测试用例2（更高维度，更多样本）：\n  - 维度：$d = 3$。\n  - 函数：$f(x) = \\mathbf{1}\\{\\|x - c\\|_2 \\le r\\}$，其中$c = (0.5, 0.5, 0.5)$且$r = 0.3$。\n  - 在弯曲边界上的不连续性意味着$V_{\\mathrm{HK}}(f) = \\infty$。\n  - 解析积分：单位立方体内半径为$r$的球体体积，等于$\\mu^\\star = \\frac{4}{3}\\pi r^3$，因为当$r=0.3$时，该球体完全位于$[0,1]^3$内。\n  - 样本量：$n = 8192$。\n  - 置信参数：$\\alpha = 0.01$。\n  - 种子：$67890$。\n\n- 测试用例3（边界情况，小样本量和不同的不连续几何形状）：\n  - 维度：$d = 2$。\n  - 函数：$f(x) = \\mathbf{1}\\{r_1 \\le \\|x - c\\|_2 \\le r_2\\}$（一个环形），其中$c = (0.5, 0.5)$，$r_1 = 0.2$，$r_2 = 0.4$。\n  - 在两个弯曲边界上的不连续性意味着$V_{\\mathrm{HK}}(f) = \\infty$。\n  - 解析积分：该环形的面积，等于$\\mu^\\star = \\pi(r_2^2 - r_1^2)$，因为当$r_2=0.4$且$c=(0.5,0.5)$时，该环形完全位于$[0,1]^2$内。\n  - 样本量：$n = 64$。\n  - 置信参数：$\\alpha = 0.2$。\n  - 种子：$24680$。\n\n输出规范：\n您的程序应生成单行输出，其中包含一个结果列表，每个测试用例对应一个结果，每个结果的结构为一个列表$[\\mathrm{L},\\mathrm{U},\\mu^\\star,\\mathrm{inside}]$，其中：\n- $\\mathrm{L}$和$\\mathrm{U}$是浮点数，表示基于偏差的$\\mathbb{E}[f(X)]$置信区间的下限和上限，\n- $\\mu^\\star$是一个浮点数，表示解析的真实积分值，\n- $\\mathrm{inside}$是一个布尔值，指示$\\mu^\\star$是否在$[\\mathrm{L},\\mathrm{U}]$内。\n\n例如，最终输出应类似于$[[\\mathrm{L}_1,\\mathrm{U}_1,\\mu^\\star_1,\\mathrm{inside}_1],[\\mathrm{L}_2,\\mathrm{U}_2,\\mu^\\star_2,\\mathrm{inside}_2],[\\mathrm{L}_3,\\mathrm{U}_3,\\mu^\\star_3,\\mathrm{inside}_3]]$，其中包含您的程序计算出的实际数值。", "solution": "该问题要求推导并实现一种方法，为不连续有界函数的积分的蒙特卡洛估计构建严格的置信区间。此目标需在不依赖Hardy–Krause变差（对于所考虑的函数，该变差为无穷大）的情况下实现，而是通过利用前推样本的经验累积分布函数（ECDF）的性质来达成。\n\n设目标积分为$I = \\int_{[0,1]^d} f(x) dx$，其中$f: [0,1]^d \\to \\mathbb{R}$是一个有界可测函数。设$X$是均匀分布在$[0,1]^d$上的随机变量。该积分可表示为期望$I = \\mu^\\star = \\mathbb{E}[f(X)]$。蒙特卡洛方法使用$n$个独立同分布（i.i.d.）的$f$的求值结果的样本均值来估计此积分。设$X_1, \\dots, X_n$为从$\\text{Uniform}([0,1]^d)$中抽取的i.i.d.样本，并设$Y_i = f(X_i)$为对应的前推样本。蒙特卡洛估计值为$\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n Y_i$。\n\n函数$f$是有界的，因此存在常数$a$和$b$，使得对于所有$x \\in [0,1]^d$，都有$a \\le f(x) \\le b$。因此，随机变量$Y = f(X)$的支集包含在区间$[a, b]$内。\n\n推导过程始于随机变量的期望与其累积分布函数（CDF）之间的基本关系。对于任何支集在$[a,b]$内的随机变量$Y$，其期望可以写成：\n$$ \\mu^\\star = \\mathbb{E}[Y] = a + \\int_a^b (1 - F_Y(t)) dt $$\n其中$F_Y(t) = P(Y \\le t)$是$Y$的真实CDF。此恒等式由$\\mathbb{E}[Y] = \\int_a^b t dF_Y(t)$进行分部积分得出，并且对任何有界支集的随机变量都成立，无论其CDF是否连续。\n\n蒙特卡洛估计值$\\hat{\\mu}$是关于样本$\\{Y_1, \\dots, Y_n\\}$的经验测度的期望。经验累积分布函数（ECDF）定义为$F_n(t) = \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}\\{Y_i \\le t\\}$。将期望与CDF关联的相同恒等式可以应用于经验测度，从而得到样本均值的精确表达式：\n$$ \\hat{\\mu} = \\mathbb{E}_{F_n}[Y] = a + \\int_a^b (1 - F_n(t)) dt $$\n\n蒙特卡洛估计的误差是$\\hat{\\mu}$与$\\mu^\\star$之差。将两个期望恒等式相减得到：\n$$ \\hat{\\mu} - \\mu^\\star = \\left(a + \\int_a^b (1 - F_n(t)) dt\\right) - \\left(a + \\int_a^b (1 - F_Y(t)) dt\\right) = \\int_a^b (F_Y(t) - F_n(t)) dt $$\n为了获得误差的界限，我们取绝对值：\n$$ |\\hat{\\mu} - \\mu^\\star| = \\left| \\int_a^b (F_Y(t) - F_n(t)) dt \\right| \\le \\int_a^b |F_Y(t) - F_n(t)| dt $$\n项$|F_Y(t) - F_n(t)|$是真实CDF与ECDF之间的逐点差异。这个差异由Kolmogorov–Smirnov偏差一致有界，$D_n = \\sup_{t \\in \\mathbb{R}} |F_Y(t) - F_n(t)|$。\n将此一致界限应用于积分，我们得到：\n$$ |\\hat{\\mu} - \\mu^\\star| \\le \\int_a^b D_n dt = D_n (b-a) $$\n这个不等式将积分误差与一维前推样本的偏差直接联系起来，避免了对$f$的多维结构或其Hardy–Krause变差的任何依赖。\n\n为了使这个界限有用，我们需要对随机变量$D_n$的一个高概率界。Dvoretzky–Kiefer–Wolfowitz (DKW) 不等式提供了一个关于$D_n$超过某个值$\\epsilon$的概率的非渐近、免分布的界限。对于任何$\\epsilon > 0$，该不等式表述为：\n$$ P(D_n > \\epsilon) \\le 2e^{-2n\\epsilon^2} $$\n我们希望为$\\mu^\\star$构建一个置信水平为$1-\\alpha$的置信区间。我们可以将大偏差概率的上限设为$\\alpha$：\n$$ \\alpha = 2e^{-2n\\epsilon^2} $$\n对$\\epsilon$求解得到临界值，我们记为$\\epsilon_{n, \\alpha}$：\n$$ \\ln\\left(\\frac{\\alpha}{2}\\right) = -2n\\epsilon^2 \\implies \\epsilon_{n, \\alpha} = \\sqrt{\\frac{1}{2n}\\ln\\left(\\frac{2}{\\alpha}\\right)} $$\nDKW不等式意味着事件$D_n \\le \\epsilon_{n, \\alpha}$发生的概率至少为$1-\\alpha$。\n\n综合这些结果，我们可以断言，以至少$1-\\alpha$的概率：\n$$ |\\mu^\\star - \\hat{\\mu}| \\le (b-a) D_n \\le (b-a) \\epsilon_{n, \\alpha} $$\n这个不等式定义了$\\mu^\\star$在估计值$\\hat{\\mu}$周围的一个对称置信区间。该置信区间的下限$\\mathrm{L}$和上限$\\mathrm{U}$为：\n$$ \\mathrm{L} = \\hat{\\mu} - (b-a)\\sqrt{\\frac{1}{2n}\\ln\\left(\\frac{2}{\\alpha}\\right)} $$\n$$ \\mathrm{U} = \\hat{\\mu} + (b-a)\\sqrt{\\frac{1}{2n}\\ln\\left(\\frac{2}{\\alpha}\\right)} $$\n此置信区间对任何有界函数$f$均有效，包括那些Hardy–Krause变差$V_{\\mathrm{HK}}(f)$为无穷大的不连续函数。对于所提供的测试用例，$f$是一个指示函数，因此其输出$Y$是一个取值为$\\{0, 1\\}$的伯努利随机变量。因此，界限为$a=0$和$b=1$，项$(b-a)$简化为$1$。样本均值$\\hat{\\mu}$是$f(X_i)=1$的样本所占的比例。这种严格的、免分布的方法为在挑战性场景中评估蒙特卡洛积分误差提供了一种实用的途径。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes discrepancy-aware confidence intervals for Monte Carlo estimates\n    of integrals for several discontinuous functions.\n    \"\"\"\n    test_cases = [\n        {\n            \"d\": 2,\n            \"f_params\": {\"c\": np.array([0.5, 0.5]), \"r\": 0.3},\n            \"f_type\": \"disk\",\n            \"mu_star\": np.pi * 0.3**2,\n            \"n\": 4096,\n            \"alpha\": 0.05,\n            \"seed\": 12345,\n        },\n        {\n            \"d\": 3,\n            \"f_params\": {\"c\": np.array([0.5, 0.5, 0.5]), \"r\": 0.3},\n            \"f_type\": \"ball\",\n            \"mu_star\": (4/3) * np.pi * 0.3**3,\n            \"n\": 8192,\n            \"alpha\": 0.01,\n            \"seed\": 67890,\n        },\n        {\n            \"d\": 2,\n            \"f_params\": {\"c\": np.array([0.5, 0.5]), \"r1\": 0.2, \"r2\": 0.4},\n            \"f_type\": \"annulus\",\n            \"mu_star\": np.pi * (0.4**2 - 0.2**2),\n            \"n\": 64,\n            \"alpha\": 0.2,\n            \"seed\": 24680,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        d = case[\"d\"]\n        n = case[\"n\"]\n        alpha = case[\"alpha\"]\n        seed = case[\"seed\"]\n        f_params = case[\"f_params\"]\n        f_type = case[\"f_type\"]\n        mu_star = case[\"mu_star\"]\n\n        # Set the random seed for reproducibility.\n        rng = np.random.default_rng(seed)\n\n        # Generate n i.i.d. points in the d-dimensional unit cube.\n        X = rng.random((n, d))\n        \n        # Evaluate the function f(x) on the sample points to get Y_i.\n        # Since f is an indicator function, its bounds are a=0, b=1.\n        if f_type == \"disk\" or f_type == \"ball\":\n            c = f_params[\"c\"]\n            r = f_params[\"r\"]\n            # Compute squared Euclidean distance from the center c.\n            dist_sq = np.sum((X - c)**2, axis=1)\n            Y = (dist_sq = r**2).astype(float)\n        elif f_type == \"annulus\":\n            c = f_params[\"c\"]\n            r1 = f_params[\"r1\"]\n            r2 = f_params[\"r2\"]\n            dist_sq = np.sum((X - c)**2, axis=1)\n            Y = ((dist_sq >= r1**2)  (dist_sq = r2**2)).astype(float)\n\n        # Calculate the Monte Carlo estimate (sample mean).\n        mu_hat = np.mean(Y)\n\n        # The function is bounded with a=0 and b=1.\n        a, b = 0.0, 1.0\n\n        # Calculate the error term for the confidence interval based on the DKW inequality.\n        # delta = (b-a) * sqrt( (1/(2n)) * ln(2/alpha) )\n        delta = (b - a) * np.sqrt((1.0 / (2.0 * n)) * np.log(2.0 / alpha))\n\n        # Compute the lower and upper bounds of the confidence interval.\n        L = mu_hat - delta\n        U = mu_hat + delta\n\n        # Check if the true integral value lies within the computed interval.\n        inside = (L = mu_star = U)\n\n        # Append the results for this test case.\n        results.append([L, U, mu_star, inside])\n    \n    # Custom string conversion to match required output format.\n    def format_results(data):\n        outer_list = []\n        for sublist in data:\n            inner_list = []\n            for item in sublist:\n                if isinstance(item, bool):\n                    inner_list.append(str(item))\n                else:\n                    inner_list.append(f\"{item:.17f}\") # Use sufficient precision for floats\n            outer_list.append(f\"[{','.join(inner_list)}]\")\n        return f\"[{','.join(outer_list)}]\"\n\n    # The problem asks for the output of `str(list_of_lists)`.\n    # Let's check `','.join(map(str, results))` against this.\n    # str(results) produces \"[[-0.1, ...], ...]\" with spaces.\n    # The prompt's example format is `[[L_1,U_1...], [L_2...]]`, so `','.join(map(str, results))` is correct.\n    # It will produce a string like `'[...], [...]'`, which then gets wrapped in `[` and `]`. Perfect.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3303333"}]}