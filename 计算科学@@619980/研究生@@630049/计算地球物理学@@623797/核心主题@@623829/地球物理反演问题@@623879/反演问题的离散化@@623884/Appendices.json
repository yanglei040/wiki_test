{"hands_on_practices": [{"introduction": "在大规模反演问题中，伴随状态法是计算梯度的核心工具。然而，由于离散化和编码的复杂性，梯度计算很容易出错。本实践练习将指导您实现离散伴随检验（discrete adjoint test），这是验证梯度计算正确性的基本调试步骤。通过数值验证Jacobian算子与其伴随算子之间内积的对偶关系，您可以确保您的梯度方向是准确的，为后续的优化算法奠定坚实的基础。[@problem_id:3585132]", "problem": "考虑一个在区间上具有齐次狄利克雷边界条件的一维亥姆霍兹方程，作为反问题中的正演模型。连续正演问题是：在区间 $[0,L]$ 上找到一个场 $u(x)$，使得\n$$\n-\\frac{d^2 u}{dx^2} - \\omega^2 m(x) u(x) = q(x), \\quad \\text{for } x \\in (0,L), \\quad \\text{with } u(0) = 0 \\text{ and } u(L) = 0.\n$$\n此处，$L$ 是区域长度，$\\omega$ 是角频率（单位为弧度/秒），$m(x)$ 是未知参数（例如，慢度平方），$q(x)$ 是一个源项。其弱形式涉及 $H_0^1([0,L])$ 中的测试函数 $v(x)$，由下式给出：\n$$\n\\int_0^L \\frac{du}{dx} \\frac{dv}{dx}\\,dx - \\omega^2 \\int_0^L m(x) u(x) v(x)\\,dx = \\int_0^L q(x) v(x)\\,dx.\n$$\n将区间 $[0,L]$ 离散化为 $N$ 个均匀单元，并使用在 $x=0$ 和 $x=L$ 处具有齐次狄利克雷边界条件的线性有限元。假设有 $N+1$ 个节点，并消除两个边界节点，从而得到 $N-1$ 个内部自由度。将参数表示为每个单元上的分片常数，其值为 $\\{m_e\\}_{e=0}^{N-1}$，每个单元一个值。组装全局刚度矩阵 $K \\in \\mathbb{R}^{(N-1)\\times(N-1)}$ 和参数加权的质量矩阵 $M_m \\in \\mathbb{R}^{(N-1)\\times(N-1)}$，后者由 $m_e$ 加权的局部单元质量矩阵求和构造而成。离散正演算子为\n$$\nA(m) u = b, \\quad \\text{其中 } A(m) = K - \\omega^2 M_m,\n$$\n此处 $b \\in \\mathbb{R}^{N-1}$ 是表示源 $q(x)$ 的离散右端项。\n\n定义一个线性采样算子 $P \\in \\mathbb{R}^{n_d \\times (N-1)}$，它在指定的内部节点索引处选择 $u$ 的值，以形成数据向量 $d = P u \\in \\mathbb{R}^{n_d}$。考虑参数中的扰动 $\\delta m \\in \\mathbb{R}^{N}$（每个单元一个分量）和数据中的扰动 $\\delta d \\in \\mathbb{R}^{n_d}$。令 $J$ 表示在背景 $m$ 处参数到数据映射的雅可比矩阵，$J^T$ 表示其在模型空间和数据空间的标准欧几里得内积下的伴随。\n\n你的任务是为该有限元亥姆霍兹求解器实现离散伴随检验，以便对给定的扰动 $\\delta m$ 和 $\\delta d$ 数值验证等式\n$$\n\\langle J \\delta m, \\delta d \\rangle = \\langle \\delta m, J^T \\delta d \\rangle,\n$$\n其中 $\\langle \\cdot,\\cdot \\rangle$ 表示相应离散空间中的标准欧几里得内积。你必须从弱形式和有限元组装规则（均匀网格上线性单元的局部刚度矩阵和局部质量矩阵）出发作为基本依据，推导出离散正演算子 $A(m)$、由 $\\delta m$ 驱动的线性化状态扰动 $\\delta u$、以及与 $\\delta d$ 相关的伴随场的表达式，然后在代码中实现它们。程序必须计算两个内积，并报告一个相对差异度量\n$$\ne = \\frac{\\left| \\langle J \\delta m, \\delta d \\rangle - \\langle \\delta m, J^T \\delta d \\rangle \\right|}{\\max\\left(1, \\left|\\langle J \\delta m, \\delta d \\rangle\\right|, \\left|\\langle \\delta m, J^T \\delta d \\rangle\\right|\\right)}.\n$$\n\n角度单位：$\\omega$ 必须使用弧度/秒。最终输出不需要物理单位，因为差异 $e$ 是无量纲的。\n\n在以下测试套件中实现该检验。为保证可复现性，每个测试用例使用一个由给定种子初始化的均匀随机数生成器，并从中为参数向量 $m$ 和扰动 $\\delta m$、$\\delta d$ 抽取独立的随机变量。\n\n- 测试用例 1 (正常路径): $L = 1.0$, $N = 64$, $\\omega = 5.0$ rad/s。单元参数 $m_e$ 从 $[0.8, 1.2]$ 中均匀抽取。接收器位于内部节点索引 $\\{16, 32, 48\\}$（索引从 $1$ 到 $N-1$ 计数）。种子 $314159$。\n- 测试用例 2 (粗网格边界情况): $L = 1.0$, $N = 8$, $\\omega = 5.0$ rad/s。单元参数 $m_e$ 从 $[0.8, 1.2]$ 中均匀抽取。接收器位于内部节点索引 $\\{2, 4, 6\\}$。种子 $271828$。\n- 测试用例 3 (更高频率，更病态): $L = 1.0$, $N = 64$, $\\omega = 20.0$ rad/s。单元参数 $m_e$ 从 $[0.1, 0.3]$ 中均匀抽取。接收器位于内部节点索引 $\\{10, 30, 50\\}$。种子 $161803$。\n- 测试用例 4 (最少自由度): $L = 1.0$, $N = 2$, $\\omega = 3.0$ rad/s。单元参数 $m_e$ 从 $[0.9, 1.1]$ 中均匀抽取。接收器位于唯一的内部节点索引 $\\{1\\}$。种子 $99$。\n\n使用一个离散源 $b$，定义为施加在中心内部自由度上的单位载荷。对每个测试用例，计算如上定义的差异 $e$。你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[e1,e2,e3,e4]”），每个 $e_i$ 是一个浮点数。", "solution": "基本依据是亥姆霍兹方程的弱形式以及均匀网格上线性（分片仿射）基函数的标准有限元组装。在具有齐次狄利克雷边界条件的闭区间 $[0,L]$ 上，正演问题的弱形式表述为：求 $u \\in H_0^1([0,L])$，使得\n$$\n\\int_0^L \\frac{du}{dx}\\frac{dv}{dx}\\,dx - \\omega^2 \\int_0^L m(x) u(x) v(x)\\,dx = \\int_0^L q(x) v(x)\\,dx \\quad \\text{for all } v \\in H_0^1([0,L]).\n$$\n对于一个有 $N$ 个单元的均匀网格，局部单元长度为 $h = L/N$。线性（双节点）单元具有标准局部矩阵：\n$$\nK^{(e)} = \\frac{1}{h} \\begin{bmatrix} 1  -1 \\\\ -1  1 \\end{bmatrix}, \\quad M^{(e)} = \\frac{h}{6} \\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix}.\n$$\n令 $m_e$ 表示单元 $e$ 上的分片常数参数。单元 $e$ 的参数加权的局部质量矩阵为 $m_e M^{(e)}$。对所有单元进行组装（根据连接性添加贡献，并通过消除边界自由度来应用齐次狄利克雷边界条件），得到全局刚度矩阵 $K$ 和参数加权的质量矩阵 $M_m = \\sum_{e=0}^{N-1} m_e \\mathcal{A}(M^{(e)})$，其中 $\\mathcal{A}$ 表示在适当的内部自由度处插入到全局矩阵中。离散正演算子为\n$$\nA(m) = K - \\omega^2 M_m \\in \\mathbb{R}^{(N-1)\\times(N-1)},\n$$\n离散正演问题为\n$$\nA(m)\\,u = b, \\quad u \\in \\mathbb{R}^{N-1},\n$$\n其中 $b$ 是源 $q$ 的离散表示。在我们的实现中，$b$ 被选为中心内部节点上的单位载荷，这与当 $q$ 是局部化的且测试空间包含节点基函数时的弱形式是一致的。\n\n定义数据采样算子 $P \\in \\mathbb{R}^{n_d \\times (N-1)}$，它选择 $u$ 的指定内部节点值；也就是说，如果接收器内部索引为 $\\{i_r\\}$，那么 $P$ 的行是标准基向量 $e_{i_r}^T$。数据向量为 $d = P u$。\n\n为了推导参数到数据映射的雅可比矩阵 $J$ 及其伴随 $J^T$，我们从正向映射 $F(m) = P u(m)$ 的隐式定义开始，其中 $u(m)$ 求解 $A(m) u(m) = b$。将离散正演方程对 $m$ 沿方向 $\\delta m = (\\delta m_e)_{e=0}^{N-1}$ 求导。$A(m)$ 关于 $m_e$ 的导数为\n$$\n\\frac{\\partial A}{\\partial m_e} = -\\omega^2\\,\\mathcal{A}\\!\\left(M^{(e)}\\right),\n$$\n因为只有参数加权的质量项线性地依赖于 $m_e$。线性化状态扰动 $\\delta u$ 满足\n$$\nA(m)\\,\\delta u + \\left( \\sum_{e=0}^{N-1} \\delta m_e \\frac{\\partial A}{\\partial m_e} \\right) u = 0,\n$$\n所以\n$$\nA(m)\\,\\delta u = -\\sum_{e=0}^{N-1} \\delta m_e \\frac{\\partial A}{\\partial m_e} \\, u = \\omega^2 \\sum_{e=0}^{N-1} \\delta m_e \\,\\mathcal{A}\\!\\left(M^{(e)}\\right) u.\n$$\n因此，\n$$\n\\delta u = A(m)^{-1} \\left( \\omega^2 \\sum_{e=0}^{N-1} \\delta m_e \\,\\mathcal{A}\\!\\left(M^{(e)}\\right) u \\right),\n$$\n作用于 $\\delta m$ 的雅可比矩阵为 $J \\delta m = P\\,\\delta u$。\n\n对于离散伴随，考虑一个任意的数据扰动 $\\delta d \\in \\mathbb{R}^{n_d}$ 并定义伴随场 $\\lambda \\in \\mathbb{R}^{N-1}$ 为\n$$\nA(m)^T \\lambda = P^T \\delta d.\n$$\n由于 $A(m)$ 是由对称的局部矩阵组装而成的，因此它是对称的，从而 $A(m)^T = A(m)$。使用上述表达式，\n$$\n\\langle J \\delta m, \\delta d \\rangle = \\langle P \\delta u, \\delta d \\rangle = \\langle \\delta u, P^T \\delta d \\rangle = \\left\\langle A(m)^{-1} \\left( \\omega^2 \\sum_{e=0}^{N-1} \\delta m_e \\,\\mathcal{A}\\!\\left(M^{(e)}\\right) u \\right),\\, P^T \\delta d \\right\\rangle.\n$$\n令 $\\lambda$ 为 $A(m)\\lambda = P^T \\delta d$ 的唯一解。那么\n$$\n\\langle J \\delta m, \\delta d \\rangle = \\omega^2 \\sum_{e=0}^{N-1} \\delta m_e \\, \\left\\langle \\mathcal{A}\\!\\left(M^{(e)}\\right) u,\\, \\lambda \\right\\rangle.\n$$\n通过对内部自由度求和来解释内积，并注意到 $\\mathcal{A}\\!\\left(M^{(e)}\\right)$ 是对称的，可以得到\n$$\n\\langle J \\delta m, \\delta d \\rangle = \\sum_{e=0}^{N-1} \\delta m_e \\,\\left( \\omega^2\\, u^T \\,\\mathcal{A}\\!\\left(M^{(e)}\\right)\\, \\lambda \\right).\n$$\n因此，参数空间上的伴随作用 $J^T \\delta d$ 的分量为\n$$\n\\left[J^T \\delta d\\right]_e = \\omega^2\\, u^T \\,\\mathcal{A}\\!\\left(M^{(e)}\\right)\\, \\lambda, \\quad e = 0,\\dots,N-1,\n$$\n从而\n$$\n\\langle \\delta m, J^T \\delta d \\rangle = \\sum_{e=0}^{N-1} \\delta m_e \\,\\left[J^T \\delta d\\right]_e.\n$$\n这就在有限元背景下建立了离散伴随关系。\n\n算法设计直接如下：\n- 从 $K^{(e)}$ 和 $m_e M^{(e)}$ 组装 $K$ 和 $M_m$，并构成 $A(m) = K - \\omega^2 M_m$。\n- 求解正演问题 $A(m)u = b$。\n- 对于给定的扰动 $\\delta m$，组装线性化右端项 $r = \\omega^2 \\sum_e \\delta m_e \\,\\mathcal{A}\\!\\left(M^{(e)}\\right) u$，并求解 $A(m)\\delta u = r$。\n- 对于给定的 $\\delta d$，通过在接收器索引处插入 $\\delta d$ 并在其他位置插入零来形成 $P^T \\delta d$，求解 $A(m) \\lambda = P^T \\delta d$，并计算逐单元的伴随作用 $\\left[J^T \\delta d\\right]_e = \\omega^2\\, u^T \\,\\mathcal{A}\\!\\left(M^{(e)}\\right)\\, \\lambda$。\n- 计算内积以获得 $\\langle J \\delta m, \\delta d \\rangle$ 和 $\\langle \\delta m, J^T \\delta d \\rangle$，并报告相对差异 $e$。\n\n关于容差：在精确算术中，离散伴随恒等式精确成立。在浮点运算中，偏差源于舍入和求解器误差。一个有原则的容差与 $A(m)$ 的条件数和机器精度 $\\epsilon$ 相关。如果线性求解以接近机器精度的水平执行，预计会产生量级为\n$$\n\\tau \\approx c \\,\\kappa(A) \\,\\epsilon\n$$\n的差异，其中 $\\kappa(A)$ 是 $A(m)$ 在 2-范数下的条件数，$c$ 是一个考虑到多次求解和求和的适中常数（例如，$c$ 在 10 和 100 之间）。对于良态情况（例如，小的 $\\omega$ 和足够细的网格），$\\kappa(A)$ 很小，在双精度下 $\\tau$ 的范围在 $10^{-12}$ 到 $10^{-10}$ 之间。对于更病态的情况（例如，更高的 $\\omega$ 或更粗的网格），$\\kappa(A)$ 增大，可能需要 $10^{-9}$ 到 $10^{-7}$ 量级的容差。超过此类容差估计的差异表明存在编码错误（例如，不正确的组装、不匹配的内积或错误的边界条件应用），而不是离散化效应。在提供的实现中，使用了直接稀疏求解器，因此观测到的差异应接近由条件数缩放的机器精度。", "answer": "```python\nimport numpy as np\nfrom scipy.sparse import lil_matrix, csr_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef assemble_stiffness(L, N):\n    \"\"\"\n    Assemble global stiffness matrix K for 1D linear finite elements\n    with homogeneous Dirichlet boundary conditions, on a uniform mesh.\n    \"\"\"\n    n = N - 1  # interior DOFs\n    h = L / N\n    K = lil_matrix((n, n))\n    # Standard FE stiffness assembly for interior nodes: tridiagonal matrix\n    for i in range(n):\n        K[i, i] += 2.0 / h\n        if i > 0:\n            K[i, i - 1] += -1.0 / h\n        if i  n - 1:\n            K[i, i + 1] += -1.0 / h\n    return csr_matrix(K)\n\ndef local_mass_matrix(h):\n    \"\"\"\n    Local element mass matrix for linear elements on an interval of length h.\n    \"\"\"\n    return (h / 6.0) * np.array([[2.0, 1.0],\n                                 [1.0, 2.0]])\n\ndef assemble_param_mass_and_locals(L, N, m_elem):\n    \"\"\"\n    Assemble the global parameter-weighted mass matrix M_m and\n    return the list of unweighted local mass matrices per element and\n    the mapping of element-local nodes to interior DOF indices.\n    \"\"\"\n    n = N - 1\n    h = L / N\n    M_m = lil_matrix((n, n))\n    M_local_plain = []\n    interior_pairs = []  # (i0, i1) interior indices for element's two nodes; None if boundary\n    M_plain = local_mass_matrix(h)\n    for e in range(N):\n        # Global node indices for element e are e and e+1\n        g0 = e\n        g1 = e + 1\n        # Map to interior DOF indices (1..N-1 -> 0..N-2)\n        i0 = g0 - 1 if 1 = g0 = N - 1 else None\n        i1 = g1 - 1 if 1 = g1 = N - 1 else None\n        interior_pairs.append((i0, i1))\n        # Parameter-weighted local mass\n        M_loc_weighted = M_plain * m_elem[e]\n        # Assemble into global M_m\n        if i0 is not None:\n            M_m[i0, i0] += M_loc_weighted[0, 0]\n            if i1 is not None:\n                M_m[i0, i1] += M_loc_weighted[0, 1]\n        if i1 is not None:\n            if i0 is not None:\n                M_m[i1, i0] += M_loc_weighted[1, 0]\n            M_m[i1, i1] += M_loc_weighted[1, 1]\n        # Store plain local mass (unweighted) for derivative computations\n        M_local_plain.append(M_plain.copy())\n    return csr_matrix(M_m), M_local_plain, interior_pairs\n\ndef build_A(K, omega, M_m):\n    \"\"\"\n    Construct Helmholtz operator A(m) = K - omega^2 * M_m.\n    \"\"\"\n    return K - (omega**2) * M_m\n\ndef rhs_source(n):\n    \"\"\"\n    Build a discrete right-hand side with unit load at central DOF.\n    \"\"\"\n    b = np.zeros(n)\n    center = n // 2\n    b[center] = 1.0\n    return b\n\ndef compute_linearized_rhs(u, delta_m, M_local_plain, interior_pairs, omega):\n    \"\"\"\n    Compute r = omega^2 * sum_e delta_m[e] * (A(M^{(e)}) * u),\n    where A(M^{(e)}) denotes assembly of unweighted local mass onto the global vector.\n    \"\"\"\n    n = u.shape[0]\n    r = np.zeros(n)\n    for e, (i0, i1) in enumerate(interior_pairs):\n        M_loc = M_local_plain[e]\n        dm = delta_m[e]\n        # Contributions to r at i0 and i1\n        if i0 is not None:\n            val0 = 0.0\n            if i0 is not None:\n                val0 += M_loc[0, 0] * u[i0]\n            if i1 is not None:\n                val0 += M_loc[0, 1] * u[i1]\n            r[i0] += (omega**2) * dm * val0\n        if i1 is not None:\n            val1 = 0.0\n            if i0 is not None:\n                val1 += M_loc[1, 0] * u[i0]\n            if i1 is not None:\n                val1 += M_loc[1, 1] * u[i1]\n            r[i1] += (omega**2) * dm * val1\n    return r\n\ndef compute_adjoint_element_contrib(u, lam, M_local_plain, interior_pairs, omega):\n    \"\"\"\n    Compute J^T * delta_d evaluated per element:\n    g[e] = omega^2 * u^T * A(M^{(e)}) * lam,\n    where A(M^{(e)}) is assembly of local mass.\n    \"\"\"\n    N = len(M_local_plain)\n    g = np.zeros(N)\n    for e, (i0, i1) in enumerate(interior_pairs):\n        M_loc = M_local_plain[e]\n        u_elem = np.zeros(2)\n        l_elem = np.zeros(2)\n        if i0 is not None:\n            u_elem[0] = u[i0]\n            l_elem[0] = lam[i0]\n        if i1 is not None:\n            u_elem[1] = u[i1]\n            l_elem[1] = lam[i1]\n\n        s = float(u_elem.T @ M_loc @ l_elem)\n        g[e] = (omega**2) * s\n    return g\n\ndef adjoint_test_case(L, N, omega, m_range, recv_indices, seed):\n    \"\"\"\n    Execute the adjoint test for a single case and return the relative discrepancy e.\n    recv_indices are interior node indices in 1..N-1 (global interior indexing).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    m_elem = rng.uniform(m_range[0], m_range[1], size=N)\n    \n    K = assemble_stiffness(L, N)\n    M_m, M_local_plain, interior_pairs = assemble_param_mass_and_locals(L, N, m_elem)\n    A = build_A(K, omega, M_m)\n    n = N - 1\n    \n    b = rhs_source(n)\n    u = spsolve(A, b)\n    \n    recv_dofs = [idx - 1 for idx in recv_indices]\n    \n    delta_m = rng.standard_normal(N)\n    delta_d = rng.standard_normal(len(recv_dofs))\n    \n    r = compute_linearized_rhs(u, delta_m, M_local_plain, interior_pairs, omega)\n    delta_u = spsolve(A, r)\n    Jdm = delta_u[recv_dofs]\n    \n    inner_prod1 = np.dot(Jdm, delta_d)\n    \n    adjoint_rhs = np.zeros(n)\n    adjoint_rhs[recv_dofs] = delta_d\n    lam = spsolve(A, adjoint_rhs)\n    \n    J_T_dd_elem = compute_adjoint_element_contrib(u, lam, M_local_plain, interior_pairs, omega)\n    \n    inner_prod2 = np.dot(delta_m, J_T_dd_elem)\n    \n    numerator = np.abs(inner_prod1 - inner_prod2)\n    denominator = max(1.0, np.abs(inner_prod1), np.abs(inner_prod2))\n    e = numerator / denominator if denominator != 0 else 0.0\n    \n    return e\n\ndef solve():\n    \"\"\"\n    Main runner for all test cases.\n    \"\"\"\n    test_cases_params = [\n        {'L': 1.0, 'N': 64, 'omega': 5.0, 'm_range': [0.8, 1.2], 'recv_indices': [16, 32, 48], 'seed': 314159},\n        {'L': 1.0, 'N': 8, 'omega': 5.0, 'm_range': [0.8, 1.2], 'recv_indices': [2, 4, 6], 'seed': 271828},\n        {'L': 1.0, 'N': 64, 'omega': 20.0, 'm_range': [0.1, 0.3], 'recv_indices': [10, 30, 50], 'seed': 161803},\n        {'L': 1.0, 'N': 2, 'omega': 3.0, 'm_range': [0.9, 1.1], 'recv_indices': [1], 'seed': 99},\n    ]\n\n    results = []\n    for params in test_cases_params:\n        e = adjoint_test_case(**params)\n        results.append(e)\n\n    print(f\"[{','.join(f'{x:.8e}' for x in results)}]\")\n\nsolve()\n```", "id": "3585132"}, {"introduction": "我们已经掌握了构建和求解反演问题的工具，但得到的解有多可靠？一个核心问题是“反演犯罪”（inverse crime）现象。当用于生成合成数据的离散化模型与用于反演的离散化模型完全相同时，就会发生这种情况，导致结果过于乐观，因为它忽略了计算模型与真实物理过程之间不可避免的失配。本实践练习将引导您通过系统地改变正演（数据生成）和反演过程中的离散化方案，来量化这种乐观偏差，从而深刻理解建模误差的概念以及稳健测试反演算法的重要性。[@problem_id:3585154]", "problem": "考虑一个一维线性地球物理正演模型，其中数据 $d(x)$ 是由一个平滑积分算子作用于定义域 $s \\in [0,1]$ 上的空间模型 $m(s)$ 生成的，即 $d(x) = \\int_{0}^{1} K(x,s) m(s) \\, ds$。核函数 $K(x,s)$ 是一个宽度参数为 $\\sigma  0$ 的高斯平滑核，具体为 $K(x,s) = \\exp\\!\\big( -\\tfrac{(x - s)^2}{2 \\sigma^2} \\big)$。假设 $m(s)$ 和 $d(x)$ 均为无量纲。反演过程通过对数据空间和模型空间进行离散化，得到一个线性系统，其矩阵算子依赖于所选择的离散化方案。\n\n您将通过系统地改变正演/反演离散化对，并比较恢复的模型和分辨率矩阵，来演示被称为“反演犯罪”（即使用相同的正演和反演离散化方案）的现象，并量化其所带来的乐观偏差。推导和实现必须基于以下基本原理：\n- 在离散化设置下的线性正演关系 $d = G m$，其中 $G$ 是从连续积分模型推导出的离散化正演算子。\n- Tikhonov 正则化（也称为岭回归），对模型粗糙度施加二次惩罚，该惩罚由一个离散的一阶差分算子和一个标量正则化参数 $\\lambda  0$ 指定。\n\n您的程序必须实现以下功能：\n1. 使用一组模型节点 $\\{ s_j \\}_{j=1}^{N_m}$ 对模型域 $[0,1]$ 进行离散化，这些节点将反演模型向量 $m \\in \\mathbb{R}^{N_m}$ 定义为节点值 $m_j = m(s_j)$。\n2. 使用定义在一组（通常是不同的）求积节点 $\\{ s_k^{(q)} \\}_{k=1}^{N_q}$ 及其相关权重 $\\{ w_k \\}_{k=1}^{N_q}$ 上的求积法则，对用于正演建模的积分进行离散化。必须支持两种求积类型：梯形法则和辛普森法则（辛普森法则要求节点数为奇数且间距均匀）。\n3. 当正演和反演离散化使用不同的节点集时，使用线性插值在求积节点 $s_k^{(q)}$ 处评估模型节点值 $m_j$。这将生成一个从模型节点映射到求积节点的矩形插值矩阵。\n4. 构建正演算子矩阵 $G \\in \\mathbb{R}^{M \\times N_m}$，该矩阵将反演模型 $m$ 映射到位于 $[0,1]$ 上均匀分布的 $M$ 个数据位置 $\\{ x_i \\}_{i=1}^{M}$ 处的数据向量 $d \\in \\mathbb{R}^M$。具体来说，$G$ 必须体现离散化的积分 $d_i \\approx \\sum_{k=1}^{N_q} K(x_i, s_k^{(q)}) \\, w_k \\, m(s_k^{(q)})$，其中 $m(s_k^{(q)})$ 在必要时通过模型节点的插值获得。\n5. 实现带有离散一阶差分惩罚的 Tikhonov 反演。设 $L \\in \\mathbb{R}^{(N_m-1) \\times N_m}$ 为一阶差分矩阵，使得 $(L m)_j = m_{j+1} - m_j$。恢复的模型必须求解变分问题 $\\min_{m} \\| G_{\\text{inv}} m - d \\|_2^2 + \\lambda^2 \\| L m \\|_2^2$，其中 $G_{\\text{inv}}$ 是反演所假设的正演算子。解必须从第一性原理出发，通过线性代数计算得出。\n6. 为进行分辨率分析，将分辨率矩阵 $R \\in \\mathbb{R}^{N_m \\times N_m}$ 定义为在无噪声数据条件下，从真实模型（在反演网格上）到恢复模型的线性映射，同时考虑真实正演算子 $G_{\\text{fwd}}$ 和反演算子 $G_{\\text{inv}}$ 之间的潜在不匹配。也就是说，当 $d = G_{\\text{fwd}} m$ 且 $\\hat{m}$ 是用 $G_{\\text{inv}}$ 求解 Tikhonov 问题的解时，计算与映射 $m \\mapsto \\hat{m}$ 对应的 $R$。\n7. 定义一个连续且与离散化无关的解析“地面真实”模型：$m_{\\text{true}}(s) = \\exp\\!\\big( -\\tfrac{(s - 0.3)^2}{2 \\times 0.02^2} \\big) + 0.5 \\exp\\!\\big( -\\tfrac{(s - 0.7)^2}{2 \\times 0.04^2} \\big) + 0.2 s$。通过在求积节点上评估 $m_{\\text{true}}$，使用所选的正演离散化方案生成无噪声的合成数据。然后在所选的反演网格上执行反演。\n8. 通过报告以下数值指标来量化乐观偏差：\n   - 相对模型误差 $E = \\| \\hat{m} - m_{\\text{true},\\text{inv}} \\|_2 / \\| m_{\\text{true},\\text{inv}} \\|_2$，其中 $m_{\\text{true},\\text{inv}} \\in \\mathbb{R}^{N_m}$ 是在反演网格上采样的 $m_{\\text{true}}$。\n   - 分辨率偏差的归一化弗罗贝尼乌斯范数 $N_R = \\| R - I \\|_F / \\| I \\|_F$，其中 $I$ 是大小为 $N_m \\times N_m$ 的单位矩阵。\n   - 对于每个非基准测试用例，计算相对于“反演犯罪”基准的“乐观偏差”差异：$\\Delta E = E - E_{\\text{crime}}$ 和 $\\Delta N_R = N_R - N_{R,\\text{crime}}$，其中基准在下面的测试套件中定义。\n9. 除非测试套件中另有规定，否则所有运行均使用以下固定参数：\n   - 核宽度 $\\sigma = 0.07$。\n   - 数据点数量 $M = 50$，$x_i$ 在 $[0,1]$ 上均匀分布。\n   - 正则化参数 $\\lambda = 10^{-2}$。\n   - 模型和求积节点必须在 $[0,1]$ 上均匀分布。\n\n测试套件：\n提供以下四个离散化对的结果。每一对都指定了反演模型网格大小 $N_m$、反演求积类型、正演求积网格大小 $N_q$ 和正演求积类型。\n\n- 案例 1（“反演犯罪”基准）：$N_m = 64$，反演求积类型 = 梯形法则，$N_q = 64$，正演求积类型 = 梯形法则。\n- 案例 2（正演比反演粗糙）：$N_m = 64$，反演求积类型 = 梯形法则，$N_q = 32$，正演求积类型 = 梯形法则。\n- 案例 3（正演比反演精细）：$N_m = 64$，反演求积类型 = 梯形法则，$N_q = 128$，正演求积类型 = 梯形法则。\n- 案例 4（求积类型不匹配和奇数反演网格）：$N_m = 65$，反演求积类型 = 辛普森法则，$N_q = 128$，正演求积类型 = 梯形法则。\n\n要求的最终输出格式：\n您的程序应生成一行输出，其中包含四个案例的结果，形式为方括号内以逗号分隔的列表。对于每个案例，按以下顺序输出四个浮点数：$[E, N_R, \\Delta E, \\Delta N_R]$，并按案例 1、案例 2、案例 3、案例 4 的顺序将所有结果展平。对于“反演犯罪”基准（案例 1），偏差应报告为零（即 $\\Delta E = 0$ 和 $\\Delta N_R = 0$）。因此，最终输出必须是单个方括号内包含 16 个浮点数的扁平列表。本问题不要求单位，也没有出现角度。", "solution": "所述问题在科学上是合理的，在数学上是适定的，并包含了获得唯一且可验证解所需的所有信息。它探讨了计算地球物理学中“反演犯罪”的概念，这是反演问题理论中的一个标准课题。所有参数和函数形式都已明确定义。因此，该问题是有效的，并将提供解答。\n\n问题的核心是在为正演模型和反演过程选择不同离散化方案的条件下，构建、求解和分析一个线性反演问题。我们将系统地建立所需的数学和算法框架。\n\n### 1. 连续和离散正演问题\n\n该物理过程由第一类弗雷德霍姆积分方程描述：\n$$\nd(x) = \\int_{0}^{1} K(x,s) m(s) \\, ds\n$$\n其中 $d(x)$ 是在位置 $x$ 观测到的数据，$m(s)$ 是在位置 $s$ 的底层模型属性，$K(x,s)$ 是核函数。核函数为高斯函数：\n$$\nK(x,s) = \\exp\\left( -\\frac{(x - s)^2}{2 \\sigma^2} \\right)\n$$\n这代表一个平滑操作。为了进行计算求解，我们必须对该积分进行离散化。我们使用由一组 $N_q$ 个节点 $\\{s_k^{(q)}\\}_{k=1}^{N_q}$ 和相应权重 $\\{w_k\\}_{k=1}^{N_q}$ 定义的数值求积法则来近似该积分。对于单个数据点 $d_i = d(x_i)$，积分近似为：\n$$\nd_i \\approx \\sum_{k=1}^{N_q} w_k K(x_i, s_k^{(q)}) m(s_k^{(q)})\n$$\n模型 $m(s)$ 本身由其在一组 $N_m$ 个离散节点 $\\{s_j\\}_{j=1}^{N_m}$ 上的值表示。我们将这个模型参数向量表示为 $\\mathbf{m} \\in \\mathbb{R}^{N_m}$，其中 $m_j = m(s_j)$。\n\n当求积节点 $\\{s_k^{(q)}\\}$ 与模型节点 $\\{s_j\\}$ 不重合时，会出现一个关键步骤。为了评估 $m(s_k^{(q)})$，我们必须从模型节点进行插值。使用线性插值，我们可以将此关系写为矩阵-向量积。设 $\\mathbf{m}_{\\text{quad}} \\in \\mathbb{R}^{N_q}$ 为模型在求积节点上的值向量。它可以通过一个矩形插值矩阵 $\\mathbf{I} \\in \\mathbb{R}^{N_q \\times N_m}$ 用模型参数向量 $\\mathbf{m}$ 表示：\n$$\n\\mathbf{m}_{\\text{quad}} = \\mathbf{I} \\mathbf{m}\n$$\n将此代入离散化的积分方程，我们得到完全离散的线性正演模型。设 $\\mathbf{d} \\in \\mathbb{R}^M$ 为在 $M$ 个位置 $\\{x_i\\}_{i=1}^M$ 处的数据向量。关系为 $\\mathbf{d} = \\mathbf{G} \\mathbf{m}$，其中 $\\mathbf{G} \\in \\mathbb{R}^{M \\times N_m}$ 是正演算子矩阵。其元素 $G_{ij}$ 由下式给出：\n$$\nG_{ij} = \\sum_{k=1}^{N_q} w_k K(x_i, s_k^{(q)}) I_{kj}\n$$\n这可以紧凑地表示。设 $\\mathbf{K}' \\in \\mathbb{R}^{M \\times N_q}$ 是元素为 $K'_{ik} = K(x_i, s_k^{(q)})$ 的矩阵，$\\mathbf{W} \\in \\mathbb{R}^{N_q \\times N_q}$ 是由求积权重 $w_k$ 构成的对角矩阵。那么正演算子为 $\\mathbf{G} = \\mathbf{K}' \\mathbf{W} \\mathbf{I}$。\n\n### 2. 用于反演的 Tikhonov 正则化\n\n从 $\\mathbf{d}$ 求解 $\\mathbf{m}$ 的反演问题通常是病态的，特别是对于平滑核。我们使用 Tikhonov 正则化来稳定反演。估计的模型 $\\hat{\\mathbf{m}}$ 是最小化复合目标函数的解：\n$$\nJ(\\mathbf{m}) = \\| \\mathbf{G}_{\\text{inv}} \\mathbf{m} - \\mathbf{d} \\|_2^2 + \\lambda^2 \\| \\mathbf{L} \\mathbf{m} \\|_2^2\n$$\n此处，$\\mathbf{G}_{\\text{inv}}$ 是反演过程所假设的正演算子矩阵，它可能与生成数据的真实正演算子 $\\mathbf{G}_{\\text{fwd}}$ 不同。参数 $\\lambda  0$ 控制着数据拟合与满足先验约束之间的权衡。矩阵 $\\mathbf{L} \\in \\mathbb{R}^{(N_m-1) \\times N_m}$ 是一个惩罚模型粗糙度的有限差分算子。对于一阶差分算子，其作用为 $(\\mathbf{L}\\mathbf{m})_j = m_{j+1} - m_j$。\n\n目标函数 $J(\\mathbf{m})$ 是关于 $\\mathbf{m}$ 的二次函数。其最小值可以通过将其关于 $\\mathbf{m}$ 的梯度设为零来找到：\n$$\n\\nabla_{\\mathbf{m}} J(\\mathbf{m}) = 2 \\mathbf{G}_{\\text{inv}}^T (\\mathbf{G}_{\\text{inv}} \\mathbf{m} - \\mathbf{d}) + 2 \\lambda^2 \\mathbf{L}^T \\mathbf{L} \\mathbf{m} = \\mathbf{0}\n$$\n重新整理得到正则化问题的正规方程组：\n$$\n(\\mathbf{G}_{\\text{inv}}^T \\mathbf{G}_{\\text{inv}} + \\lambda^2 \\mathbf{L}^T \\mathbf{L}) \\mathbf{m} = \\mathbf{G}_{\\text{inv}}^T \\mathbf{d}\n$$\n那么，估计模型 $\\hat{\\mathbf{m}}$ 的解为：\n$$\n\\hat{\\mathbf{m}} = (\\mathbf{G}_{\\text{inv}}^T \\mathbf{G}_{\\text{inv}} + \\lambda^2 \\mathbf{L}^T \\mathbf{L})^{-1} \\mathbf{G}_{\\text{inv}}^T \\mathbf{d}\n$$\n\n### 3. 模型分辨率分析\n\n模型分辨率矩阵 $\\mathbf{R}$ 描述了估计模型 $\\hat{\\mathbf{m}}$ 与真实模型 $\\mathbf{m}_{\\text{true}}$ 之间的关系。它量化了反演过程引入的模糊和失真。我们考虑使用“真实”正演算子 $\\mathbf{G}_{\\text{fwd}}$ 从反演网格上的模型 $\\mathbf{m}$ 生成的无噪声数据：$\\mathbf{d} = \\mathbf{G}_{\\text{fwd}} \\mathbf{m}$。\n将此代入 $\\hat{\\mathbf{m}}$ 的表达式中：\n$$\n\\hat{\\mathbf{m}} = \\left[ (\\mathbf{G}_{\\text{inv}}^T \\mathbf{G}_{\\text{inv}} + \\lambda^2 \\mathbf{L}^T \\mathbf{L})^{-1} \\mathbf{G}_{\\text{inv}}^T \\mathbf{G}_{\\text{fwd}} \\right] \\mathbf{m}\n$$\n方括号中的矩阵即为分辨率矩阵 $\\mathbf{R} \\in \\mathbb{R}^{N_m \\times N_m}$：\n$$\n\\mathbf{R} = (\\mathbf{G}_{\\text{inv}}^T \\mathbf{G}_{\\text{inv}} + \\lambda^2 \\mathbf{L}^T \\mathbf{L})^{-1} \\mathbf{G}_{\\text{inv}}^T \\mathbf{G}_{\\text{fwd}}\n$$\n当用于反演的离散化与用于正演模型的离散化完全匹配时，即 $\\mathbf{G}_{\\text{inv}} = \\mathbf{G}_{\\text{fwd}} = \\mathbf{G}$，就会发生“反演犯罪”。在这种情况下，分辨率矩阵简化为标准形式 $\\mathbf{R}_{\\text{crime}} = (\\mathbf{G}^T \\mathbf{G} + \\lambda^2 \\mathbf{L}^T \\mathbf{L})^{-1} \\mathbf{G}^T \\mathbf{G}$。理想的反演会得到 $\\mathbf{R} = \\mathbf{I}$，即单位矩阵，这意味着估计模型完美地恢复了真实模型。\n\n### 4. 量化偏差和误差\n\n为了量化反演性能和“反演犯罪”的乐观偏差，我们使用两个指标：\n1.  **相对模型误差 ($E$)**：该指标衡量恢复模型 $\\hat{\\mathbf{m}}$ 与在反演网格上采样的真实模型 $\\mathbf{m}_{\\text{true,inv}}$ 之间的差异。合成数据 $\\mathbf{d}$ 是使用正演求积方案从连续真实模型 $m_{\\text{true}}(s)$ 生成的。\n    $$\n    E = \\frac{\\| \\hat{\\mathbf{m}} - \\mathbf{m}_{\\text{true,inv}} \\|_2}{\\| \\mathbf{m}_{\\text{true,inv}} \\|_2}\n    $$\n2.  **归一化分辨率偏差 ($N_R$)**：该指标衡量分辨率矩阵 $\\mathbf{R}$ 与理想单位矩阵 $\\mathbf{I}$ 的偏离程度，并以单位矩阵的范数进行归一化。我们使用弗罗贝尼乌斯范数。\n    $$\n    N_R = \\frac{\\| \\mathbf{R} - \\mathbf{I} \\|_F}{\\| \\mathbf{I} \\|_F} = \\frac{\\sqrt{\\sum_{i,j}(R_{ij} - \\delta_{ij})^2}}{\\sqrt{N_m}}\n    $$\n然后，乐观偏差通过差异 $\\Delta E = E - E_{\\text{crime}}$ 和 $\\Delta N_R = N_R - N_{R,\\text{crime}}$ 来量化，其中 $E_{\\text{crime}}$ 和 $N_{R,\\text{crime}}$ 是来自 $\\mathbf{G}_{\\text{inv}} = \\mathbf{G}_{\\text{fwd}}$ 的基准案例的值。这些差异预计为正，表明“反演犯罪”案例得出了不切实际的低误差和低分辨率偏差值。\n\n实现过程将为每个案例构建必要的矩阵（$\\mathbf{G}_{\\text{fwd}}$、$\\mathbf{G}_{\\text{inv}}$、$\\mathbf{L}$），从解析真实模型生成合成数据，求解 $\\hat{\\mathbf{m}}$ 和 $\\mathbf{R}$，最后计算指定的指标。", "answer": "```python\nimport numpy as np\n\ndef m_true_func(s):\n    \"\"\"\n    Computes the ground truth model m_true(s) at given locations s.\n    \"\"\"\n    s = np.asarray(s)\n    term1 = np.exp(-(s - 0.3)**2 / (2 * 0.02**2))\n    term2 = 0.5 * np.exp(-(s - 0.7)**2 / (2 * 0.04**2))\n    term3 = 0.2 * s\n    return term1 + term2 + term3\n\ndef kernel_func(x, s, sigma):\n    \"\"\"\n    Computes the Gaussian kernel K(x,s).\n    \"\"\"\n    return np.exp(-(x - s)**2 / (2 * sigma**2))\n\ndef get_quadrature(N, q_type):\n    \"\"\"\n    Generates nodes and weights for trapezoidal or Simpson's quadrature on [0,1].\n    \"\"\"\n    if N  1:\n        return np.array([]), np.array([])\n    if N == 1: # Center point rule\n        return np.array([0.5]), np.array([1.0])\n        \n    nodes = np.linspace(0.0, 1.0, N)\n    h = 1.0 / (N - 1)\n    \n    if q_type.lower() == 'trapezoidal':\n        weights = np.full(N, h)\n        weights[0] *= 0.5\n        weights[-1] *= 0.5\n    elif q_type.lower() == 'simpson':\n        if N % 2 == 0:\n            raise ValueError(\"Simpson's rule requires an odd number of nodes.\")\n        weights = np.ones(N)\n        weights[1:-1:2] = 4.0\n        weights[2:-2:2] = 2.0\n        weights *= h / 3.0\n    else:\n        raise ValueError(f\"Unknown quadrature type: {q_type}\")\n        \n    return nodes, weights\n\ndef build_interp_matrix(target_nodes, source_nodes):\n    \"\"\"\n    Builds the linear interpolation matrix to map values from source_nodes to target_nodes.\n    \"\"\"\n    Nt, Ns = len(target_nodes), len(source_nodes)\n    if Ns > 0 and np.array_equal(target_nodes, source_nodes):\n        return np.identity(Ns)\n    \n    interp_matrix = np.zeros((Nt, Ns))\n    if Ns > 0:\n        identity_source = np.identity(Ns)\n        for j in range(Ns):\n            interp_matrix[:, j] = np.interp(target_nodes, source_nodes, identity_source[:, j])\n    return interp_matrix\n\ndef assemble_G_matrix(x_nodes, model_nodes, quad_nodes, quad_weights, sigma):\n    \"\"\"\n    Assembles the forward operator matrix G.\n    \"\"\"\n    interp_mat = build_interp_matrix(quad_nodes, model_nodes)\n    \n    kernel_mat = kernel_func(x_nodes[:, None], quad_nodes[None, :], sigma)\n    \n    # G = (K * weights) @ I\n    # K is (M, Nq), weights is (Nq,), I is (Nq, Nm)\n    # (K * weights) is an (M, Nq) matrix\n    G = (kernel_mat * quad_weights) @ interp_mat\n    return G\n\ndef build_L_matrix(Nm):\n    \"\"\"\n    Builds the first-difference matrix L.\n    \"\"\"\n    if Nm = 1:\n        return np.empty((0, Nm))\n    L = np.eye(Nm - 1, Nm, k=1) - np.eye(Nm - 1, Nm, k=0)\n    return L\n    \ndef process_case(case_params, fixed_params):\n    \"\"\"\n    Runs a full inversion scenario for one test case.\n    \"\"\"\n    Nm, inv_q_type, Nq, fwd_q_type = case_params\n    M, sigma, lambda_reg = fixed_params['M'], fixed_params['sigma'], fixed_params['lambda_reg']\n\n    # 1. Setup grids\n    x_grid = np.linspace(0.0, 1.0, M)\n    s_inv_grid = np.linspace(0.0, 1.0, Nm)\n    \n    # 2. Assemble forward operator for inversion (G_inv)\n    s_inv_quad_grid, w_inv_quad = get_quadrature(Nm, inv_q_type)\n    G_inv = assemble_G_matrix(x_grid, s_inv_grid, s_inv_quad_grid, w_inv_quad, sigma)\n\n    # 3. Assemble forward operator for data generation (G_fwd)\n    s_fwd_quad_grid, w_fwd_quad = get_quadrature(Nq, fwd_q_type)\n    G_fwd = assemble_G_matrix(x_grid, s_inv_grid, s_fwd_quad_grid, w_fwd_quad, sigma)\n    \n    # 4. Generate synthetic data from continuous true model\n    m_true_at_fwd_quad = m_true_func(s_fwd_quad_grid)\n    kernel_for_data = kernel_func(x_grid[:, None], s_fwd_quad_grid[None, :], sigma)\n    d = (kernel_for_data * w_fwd_quad) @ m_true_at_fwd_quad\n\n    # 5. Perform Tikhonov inversion\n    L = build_L_matrix(Nm)\n    H = G_inv.T @ G_inv\n    if L.shape[0] > 0:\n        H += lambda_reg**2 * (L.T @ L)\n    \n    Gtd = G_inv.T @ d\n    m_hat = np.linalg.solve(H, Gtd)\n    \n    # 6. Compute Resolution Matrix R\n    RHS_R = G_inv.T @ G_fwd\n    R = np.linalg.solve(H, RHS_R)\n    \n    # 7. Compute Metrics\n    m_true_inv_grid = m_true_func(s_inv_grid)\n    \n    model_error_norm = np.linalg.norm(m_hat - m_true_inv_grid)\n    true_model_norm = np.linalg.norm(m_true_inv_grid)\n    E = model_error_norm / true_model_norm if true_model_norm > 1e-9 else 0.0\n\n    I = np.identity(Nm)\n    resolution_dev_norm = np.linalg.norm(R - I, 'fro')\n    identity_norm = np.linalg.norm(I, 'fro') # sqrt(Nm)\n    NR = resolution_dev_norm / identity_norm if identity_norm > 1e-9 else 0.0\n    \n    return E, NR\n    \ndef solve():\n    \"\"\"\n    Main solver function to orchestrate the test cases and print results.\n    \"\"\"\n    fixed_params = {\n        'sigma': 0.07,\n        'M': 50,\n        'lambda_reg': 1e-2\n    }\n    \n    test_cases = [\n        # (Nm, inv_q_type, Nq, fwd_q_type)\n        (64, 'trapezoidal', 64, 'trapezoidal'),\n        (64, 'trapezoidal', 32, 'trapezoidal'),\n        (64, 'trapezoidal', 128, 'trapezoidal'),\n        (65, 'Simpson', 128, 'trapezoidal')\n    ]\n\n    E_crime, NR_crime = process_case(test_cases[0], fixed_params)\n    results = [E_crime, NR_crime, 0.0, 0.0]\n\n    for i in range(1, len(test_cases)):\n        E, NR = process_case(test_cases[i], fixed_params)\n        delta_E = E - E_crime\n        delta_NR = NR - NR_crime\n        results.extend([E, NR, delta_E, delta_NR])\n\n    print(f\"[{','.join(f'{x:.8f}' for x in results)}]\")\n\nsolve()\n```", "id": "3585154"}]}