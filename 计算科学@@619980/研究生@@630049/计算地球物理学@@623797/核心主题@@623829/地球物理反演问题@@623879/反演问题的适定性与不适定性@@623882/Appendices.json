{"hands_on_practices": [{"introduction": "在理想化的反演问题中，我们常常假设观测数据中的噪声是独立且同分布的。然而，在实际的地球物理勘探中，噪声分量之间往往存在相关性，且方差不尽相同。本练习 [@problem_id:3618824] 将指导您从基本的第一性原理出发，即高斯噪声模型下的最大似然估计，来正确构建一个考虑了相关和异方差噪声的反演问题。通过这个过程，您将推导出加权最小二乘法，并理解“白化”（whitening）变换如何将一个复杂的统计问题转化为一个更易于处理的标准最小二乘问题。", "problem": "在一个用于走时层析成像的线性化计算地球物理反演问题中，观测数据向量建模为 $d \\in \\mathbb{R}^{N}$，未知模型参数为 $m \\in \\mathbb{R}^{M}$。线性化正演算子为 $G \\in \\mathbb{R}^{N \\times M}$，数据服从加性噪声模型 $d = G m + n$，其中噪声 $n$ 是具有异方差和相关分量的零均值高斯噪声。具体来说，$n$ 服从均值为 $0$、协方差矩阵为已知的对称正定矩阵 $C_{n} \\in \\mathbb{R}^{N \\times N}$ 的多元高斯分布。假设 $C_{n}$ 是严格正定的，且 $G$ 是满列秩的。\n\n仅从给定模型下数据的多元高斯概率密度定义和标准最小二乘设置出发，执行以下操作：\n\n1. 推导负对数似然（可相差一个与 $m$ 无关的加性常数），并证明它为 $m$ 定义了一个加权最小二乘失配泛函。\n2. 计算最大似然估计的一阶最优性条件，并用 $G$、$d$ 和 $C_{n}$ 表示所得的正规方程。\n3. 引入数据预处理（也称为白化），即对残差应用一个可逆矩阵 $W \\in \\mathbb{R}^{N \\times N}$，使得变换后的噪声具有单位协方差。推导 $W$ 必须满足的关于 $C_{n}$ 的条件，然后仅用 $C_{n}$ 和标准矩阵函数表示 $W$ 的一个显式闭式选择。\n4. 证明在此选择下，失配泛函变为白化残差的欧几里得范数的平方，并用变换后的算子和数据写出相应的白化正规方程。\n\n在最终答案中仅报告白化矩阵 $W$ 的解析表达式。不需要进行数值计算。如果使用任何缩写，请在首次出现时定义。不包括单位。最终答案必须是单个闭式解析表达式。", "solution": "问题陈述构成了线性反演理论中一个适定的理论练习，特别是在具有相关高斯噪声的线性模型的最大似然估计背景下。所有提供的信息都是自洽的，在统计学和计算地球物理学中有科学依据，并且足以对所要求的量进行唯一且有意义的推导。因此，该问题是有效的。\n\n解答过程按顺序处理四个要求部分。\n\n1. 负对数似然的推导\n\n问题指定了一个具有加性噪声的线性正演模型：\n$$d = Gm + n$$\n其中 $d \\in \\mathbb{R}^{N}$ 是数据向量，$m \\in \\mathbb{R}^{M}$ 是模型参数向量，$G \\in \\mathbb{R}^{N \\times M}$ 是正演算子，$n \\in \\mathbb{R}^{N}$ 是噪声向量。噪声 $n$ 服从均值为 $0$、协方差矩阵为已知的对称正定（SPD）矩阵 $C_{n} \\in \\mathbb{R}^{N \\times N}$ 的多元高斯分布。噪声向量 $n$ 的概率密度函数（PDF）由下式给出：\n$$p(n) = \\frac{1}{\\sqrt{(2\\pi)^{N} \\det(C_{n})}} \\exp\\left(-\\frac{1}{2} n^T C_{n}^{-1} n\\right)$$\n从模型方程中，我们可以将噪声表示为数据残差，$n = d - Gm$。给定模型 $m$ 时观测到数据 $d$ 的似然，记作 $L(m) = p(d|m)$，是通过将 $n = d - Gm$ 代入噪声的概率密度函数得到的。这是因为 $d$ 的分布就是 $n$ 的分布以均值 $Gm$ 平移后的结果。\n$$L(m) = p(d|m) = \\frac{1}{\\sqrt{(2\\pi)^{N} \\det(C_{n})}} \\exp\\left(-\\frac{1}{2} (d - Gm)^T C_{n}^{-1} (d - Gm)\\right)$$\n为了找到 $m$ 的最大似然估计，处理似然函数的对数（即对数似然 $\\ell(m)$）会很方便：\n$$\\ell(m) = \\ln(L(m)) = -\\frac{N}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln(\\det(C_{n})) - \\frac{1}{2} (d - Gm)^T C_{n}^{-1} (d - Gm)$$\n最大化 $\\ell(m)$ 等价于最小化其负数，即负对数似然（NLL）。我们将失配泛函 $\\mathcal{L}(m)$ 定义为 NLL。在相差一个与模型参数 $m$ 无关的加性常数的情况下，该泛函为：\n$$\\mathcal{L}(m) = \\frac{1}{2} (d - Gm)^T C_{n}^{-1} (d - Gm)$$\n该泛函具有加权最小二乘问题的形式。项 $(d-Gm)$ 是残差向量。该表达式是残差的二次型，其中加权矩阵是噪声协方差矩阵的逆 $C_{n}^{-1}$。该矩阵同时考虑了变化的方差（异方差性）和数据点之间的相关性。\n\n2. 正规方程的推导\n\n$m$ 的最大似然估计（记为 $m_{ML}$）是使失配泛函 $\\mathcal{L}(m)$ 最小化的 $m$ 值。该最小化问题的一阶最优性条件要求 $\\mathcal{L}(m)$ 关于 $m$ 的梯度为零：\n$$\\nabla_{m} \\mathcal{L}(m) = 0$$\n为了计算这个梯度，我们首先展开 $\\mathcal{L}(m)$ 的二次型：\n$$\\mathcal{L}(m) = \\frac{1}{2} (d^T - m^T G^T) C_{n}^{-1} (d - Gm)$$\n$$\\mathcal{L}(m) = \\frac{1}{2} (d^T C_{n}^{-1} d - d^T C_{n}^{-1} Gm - m^T G^T C_{n}^{-1} d + m^T G^T C_{n}^{-1} Gm)$$\n由于 $C_{n}$ 是对称的，其逆 $C_{n}^{-1}$ 也是对称的。项 $d^T C_{n}^{-1} Gm$ 是一个标量，所以它的转置等于它本身：$(d^T C_{n}^{-1} Gm)^T = m^T G^T (C_{n}^{-1})^T d = m^T G^T C_{n}^{-1} d$。因此，两个交叉项是相同的。\n$$\\mathcal{L}(m) = \\frac{1}{2} d^T C_{n}^{-1} d - m^T G^T C_{n}^{-1} d + \\frac{1}{2} m^T (G^T C_{n}^{-1} G) m$$\n现在，我们对 $m$ 求梯度。第一项相对于 $m$ 是常数。对于第二项和第三项，我们使用标准矩阵微积分恒等式 $\\nabla_{x} (x^T a) = a$ 和 $\\nabla_{x} (\\frac{1}{2} x^T A x) = Ax$（对于对称矩阵 $A$）。矩阵 $G^T C_{n}^{-1} G$ 是对称的。\n$$\\nabla_{m} \\mathcal{L}(m) = - G^T C_{n}^{-1} d + (G^T C_{n}^{-1} G) m$$\n将梯度设为零，得到一阶最优性条件：\n$$(G^T C_{n}^{-1} G) m = G^T C_{n}^{-1} d$$\n这是最大似然估计的正规方程组。由于 $G$ 是满列秩且 $C_n^{-1}$ 是正定的，矩阵 $G^T C_n^{-1} G$ 是可逆的，从而保证了 $m_{ML}$ 的唯一解。\n\n3. 白化变换的推导\n\n数据预处理，或称白化，旨在将问题转换为一个等价问题，其中噪声具有单位协方差矩阵。设 $W \\in \\mathbb{R}^{N \\times N}$ 是一个可逆矩阵。我们定义一个变换后的噪声向量 $n' = Wn$。变换后噪声的协方差矩阵为：\n$$\\text{Cov}(n') = \\text{Cov}(Wn) = W \\text{Cov}(n) W^T$$\n已知 $\\text{Cov}(n) = C_{n}$，变换后的噪声具有单位协方差矩阵（$\\text{Cov}(n') = I$）的条件是：\n$$W C_{n} W^T = I$$\n为了推导 $W$ 的一个显式形式，我们可以利用 SPD 矩阵 $C_{n}$ 的性质。由于 $C_{n}$ 是 SPD 矩阵，它有一个唯一的 SPD 逆 $C_{n}^{-1}$ 和一个唯一的 SPD 平方根 $C_{n}^{1/2}$。我们来提出一个 $W$ 的选择并进行验证。白化矩阵的一个标准选择是协方差矩阵的对称平方根的逆，或更直接地说，是逆协方差矩阵的对称平方根。我们选择：\n$$W = C_{n}^{-1/2}$$\n其中 $C_{n}^{-1/2}$ 是唯一的 SPD 矩阵，满足 $(C_{n}^{-1/2})^2 = C_{n}^{-1}$。根据定义，该矩阵是对称的，因此 $W^T = (C_{n}^{-1/2})^T = C_{n}^{-1/2} = W$。将此选择代入条件中：\n$$W C_{n} W^T = C_{n}^{-1/2} C_{n} C_{n}^{-1/2} = C_{n}^{-1/2} (C_{n}^{1/2} C_{n}^{1/2}) C_{n}^{-1/2} = (C_{n}^{-1/2} C_{n}^{1/2}) (C_{n}^{1/2} C_{n}^{-1/2}) = I \\cdot I = I$$\n条件得到满足。因此，白化矩阵的一个显式闭式选择是 $W=C_{n}^{-1/2}$。另一个有效的选择可以从 $C_n$ 的 Cholesky 分解中导出，但矩阵平方根是作为 $C_n$ 的矩阵函数的更直接表示。\n\n4. 白化失配和正规方程\n\n使用白化矩阵 $W = C_{n}^{-1/2}$，我们可以重写失配泛函 $\\mathcal{L}(m)$。逆协方差矩阵为 $C_{n}^{-1} = (C_{n}^{-1/2})^2 = W^2$。由于 $W$ 是对称的，$W^2 = W^T W$。\n$$\\mathcal{L}(m) = \\frac{1}{2} (d - Gm)^T C_{n}^{-1} (d - Gm) = \\frac{1}{2} (d - Gm)^T W^T W (d - Gm)$$\n利用转置的性质，这可以写成：\n$$\\mathcal{L}(m) = \\frac{1}{2} (W(d - Gm))^T (W(d - Gm))$$\n我们定义白化数据向量 $d' = Wd$ 和白化正演算子 $G' = WG$。括号内的表达式变为 $Wd - WGm = d' - G'm$。失配泛函现在是：\n$$\\mathcal{L}(m) = \\frac{1}{2} (d' - G'm)^T (d' - G'm) = \\frac{1}{2} \\|d' - G'm\\|_{2}^{2}$$\n这表明原始的加权最小二乘失配等价于白化残差的欧几里得范数平方的一半。这是涉及白化变量 $d'$ 和 $G'$ 的普通最小二乘问题的标准目标函数。\n这个普通最小二乘问题相应的正规方程可以很容易地写成：\n$$(G')^T G' m = (G')^T d'$$\n这些就是白化正规方程。代入 $G'$ 和 $d'$ 的定义以及 $W$ 的性质，可以验证它们与原始正规方程的等价性：\n$$(WG)^T (WG) m = (WG)^T (Wd)$$\n$$G^T W^T W G m = G^T W^T W d$$\n$$G^T C_{n}^{-1} G m = G^T C_{n}^{-1} d$$\n这重新推导了第 2 部分的结果，证实了白化变换的有效性。问题被转换为了一个标准的最小二乘问题，这种问题通常在数值上更稳定且更易于求解。\n\n要求的最终答案是白化矩阵 $W$ 的解析表达式。根据第 3 部分的推导，这是噪声协方差矩阵的逆的主平方根。", "answer": "$$ \\boxed{C_{n}^{-\\frac{1}{2}}} $$", "id": "3618824"}, {"introduction": "反演问题的非唯一性是其不适定性 (ill-posedness) 的一个核心方面，这意味着存在多个不同的模型可以同样好地解释观测数据。这种模糊性通常源于数据采集的局限性。本练习 [@problem_id:3618829] 提供了一个简化的层析成像思想实验，旨在揭示有限的观测孔径如何导致模型空间中存在一个“零空间”（null-space）——即模型中对数据完全“不可见”的部分。通过动手计算零空间的维度，您将能够量化问题的非唯一性程度，并理解为何需要正则化或模型重参数化等策略来获得有意义的解。", "problem": "在一个具有有限源-接收器孔径的矩形区域上，进行了一项二维声波走时层析成像实验。慢度模型是一个定义在均匀网格上的扰动场 $m(x,z)$，该网格具有 $N_x$ 个横向列和 $N_z$ 个深度层。在高频（几何）近似下，对于近垂直射线（最大张角较小），横向位置 $x_i$ 处的一阶走时扰动可以很好地用以下形式的垂直积分灵敏度来近似\n$$\nd_i \\approx \\int_{0}^{Z_{\\max}} w(z)\\, m(x_i,z)\\, dz,\n$$\n其中 $w(z) \\ge 0$ 是一个已知的与深度相关的权重，反映了有限孔径几何结构下的路径长度和灵敏度。离散化后，得到线性正演映射\n$$\nd_i = \\sum_{j=1}^{N_z} w_j\\, m_{i,j}, \\quad i = 1,\\dots,N_x,\n$$\n其中对于所有 $j$，都有 $w_j  0$，而 $m_{i,j}$ 是第 $i$ 列和第 $j$ 层的模型值。令模型向量为按列堆叠的数组 $m \\in \\mathbb{R}^{N_x N_z}$，正演算子 $A \\in \\mathbb{R}^{N_x \\times N_x N_z}$ 满足\n$$\n(A m)_i = \\sum_{j=1}^{N_z} w_j\\, m_{i,j},\n$$\n也就是说，$A$ 有 $N_x$ 个不相交的行块，每个行块都等于作用于单列各层上的行向量 $w^{\\top} \\in \\mathbb{R}^{N_z}$。\n\n- 仅使用线性代数的核心定义和给定的离散化正演映射，确定在 $N_x = 42$ 和 $N_z = 27$ 的情况下模型零空间 $\\mathcal{N}(A)$ 的维数。\n\n- 提出一种重新参数化的方法，通过选择仅保留在有限孔径几何下可观测的 $m$ 分量的参数来减小零空间。然后，计算重新参数化模型的零空间维数。\n\n将您的最终结果以一个双元行矩阵的形式报告，其中依次包含原始零空间维数和重新参数化后的零空间维数。无需四舍五入。", "solution": "该问题要求计算与简化走时层析成像实验相关的线性正演算子 $A$ 的零空间维数，首先是针对原始参数化，然后是针对重新参数化的模型。\n\n首先，我们验证问题陈述的有效性。\n问题提供了一个离散化的线性正演映射 $d_i = \\sum_{j=1}^{N_z} w_j m_{i,j}$，它模拟了一个简化的二维声波层析成像实验。模型向量 $m \\in \\mathbb{R}^{N_x N_z}$ 表示网格上的慢度扰动，数据向量 $d \\in \\mathbb{R}^{N_x}$ 表示走时扰动。正演算子 $A$ 将模型空间映射到数据空间，$d = Am$。$A$ 的结构被明确定义，同时给出了维度 $N_x = 42$ 和 $N_z = 27$，以及权重 $w_j  0$ 的条件。所提出的问题是精确的，可以用线性代数的原理解答。其背景是计算地球物理学中一个标准但简化的情景。该问题具有科学依据、自成体系且提法得当。结论是该问题有效。\n\n我们分两部分进行求解。\n\n第 1 部分：原始模型的零空间 $\\mathcal{N}(A)$ 的维数。\n\n线性算子（或矩阵）的零空间维数通过秩-零度定理与其秩和其定义域的维数相关联：\n$$\n\\text{dim}(\\text{domain of } A) = \\text{rank}(A) + \\text{dim}(\\mathcal{N}(A))\n$$\n算子 $A$ 的定义域是所有可能模型向量 $m$ 的空间。模型向量 $m$ 是慢度值 $m_{i,j}$（其中 $i=1,\\dots,N_x$，$j=1,\\dots,N_z$）按列堆叠的数组。模型中的参数总数为 $N_x N_z$。因此，模型空间为 $\\mathbb{R}^{N_x N_z}$，其维数为：\n$$\n\\text{dim}(\\text{domain of } A) = N_x N_z\n$$\n算子 $A$ 是一个大小为 $N_x \\times (N_x N_z)$ 的矩阵。它对模型向量 $m$ 的作用由 $(A m)_i = \\sum_{j=1}^{N_z} w_j m_{i,j}$ 给出，对每一行 $i=1,\\dots,N_x$ 均成立。我们将模型向量表示为列向量 $m_i \\in \\mathbb{R}^{N_z}$ 的拼接，其中 $m_i = (m_{i,1}, \\dots, m_{i,N_z})^{\\top}$。令 $w = (w_1, \\dots, w_{N_z})^{\\top}$。第 $i$ 个数据点的正演问题是 $d_i = w^{\\top} m_i$。\n\n矩阵 $A$ 可以用分块形式表示。$A$ 的第 $i$ 行仅作用于模型向量的第 $i$ 个分块 $m_i$。第 $i$ 行中对应于 $m_i$ 条目的部分是行向量 $w^{\\top}$。第 $i$ 行中的所有其他条目均为零。因此，矩阵 $A$ 具有以下结构：\n$$\nA = \\begin{pmatrix}\nw^{\\top}  \\mathbf{0}  \\cdots  \\mathbf{0} \\\\\n\\mathbf{0}  w^{\\top}  \\cdots  \\mathbf{0} \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\n\\mathbf{0}  \\mathbf{0}  \\cdots  w^{\\top}\n\\end{pmatrix}\n$$\n其中每个 $w^{\\top}$ 是一个 $1 \\times N_z$ 的行向量，每个 $\\mathbf{0}$ 是一个 $1 \\times N_z$ 的零向量。\n\n$A$ 的秩是其行空间的维数，也就是线性无关行的数量。$A$ 的第 $i$ 行仅在第 $(i-1)N_z + 1$ 列到第 $iN_z$ 列有非零条目。第 $k$ 行（$k \\neq i$）仅在第 $(k-1)N_z + 1$ 列到第 $kN_z$ 列有非零条目。由于对于不同的行，这些列索引的集合是不相交的，因此只要没有行是零向量，这些行就是线性无关的。\n问题陈述 $w_j  0$ 对所有 $j=1,\\dots,N_z$ 成立。这意味着向量 $w$ 不是零向量，因此行向量 $w^{\\top}$ 也不是零向量。因此，$A$ 的所有 $N_x$ 行都是非零且线性无关的。\n因此，$A$ 的秩等于其行数：\n$$\n\\text{rank}(A) = N_x\n$$\n我们现在应用秩-零度定理来求零空间 $\\mathcal{N}(A)$ 的维数：\n$$\n\\text{dim}(\\mathcal{N}(A)) = \\text{dim}(\\text{domain of } A) - \\text{rank}(A) = N_x N_z - N_x = N_x (N_z - 1)\n$$\n代入给定值 $N_x = 42$ 和 $N_z = 27$：\n$$\n\\text{dim}(\\mathcal{N}(A)) = 42 \\times (27 - 1) = 42 \\times 26 = 1092\n$$\n零空间由所有对数据不可见的模型扰动组成。对于每一列 $i$，任何满足 $w^{\\top} \\delta m_i=0$ 的扰动 $\\delta m_i$ 都在零空间中。对于每一列，这是对 $N_z$ 个变量的一个线性约束，留下一个维数为 $N_z-1$ 的子空间。由于有 $N_x$ 个独立的列，零空间的总维数为 $N_x(N_z-1)$。\n\n第 2 部分：重新参数化和新的零空间维数。\n\n问题要求进行重新参数化，只保留实验可观测的 $m$ 的分量。对于每一列 $i$ 的数据 $d_i$ 正是加权平均值 $d_i = \\sum_{j=1}^{N_z} w_j m_{i,j}$。每列的这个单一值是关于该列慢度剖面能够被检索的唯一信息。\n\n一个自然的重新参数化是定义一个新的模型向量，我们称之为 $\\tilde{m}$，其分量就是这些可观测的量本身。令新的模型参数为 $\\tilde{m}_i$（$i=1,\\dots,N_x$），定义为：\n$$\n\\tilde{m}_i = \\sum_{j=1}^{N_z} w_j m_{i,j}\n$$\n新的模型向量是 $\\tilde{m} = (\\tilde{m}_1, \\dots, \\tilde{m}_{N_x})^{\\top} \\in \\mathbb{R}^{N_x}$。用这个新模型表示的正演问题变为：\n$$\nd_i = \\tilde{m}_i\n$$\n以矩阵形式表示，即为 $d = \\tilde{A} \\tilde{m}$，其中 $\\tilde{A}$ 是新的正演算子。从方程 $d_i = \\tilde{m}_i$ 可以清楚地看出，$\\tilde{A}$ 是大小为 $N_x \\times N_x$ 的单位矩阵：\n$$\n\\tilde{A} = I_{N_x}\n$$\n这个新算子 $\\mathcal{N}(\\tilde{A})$ 的零空间由所有满足 $\\tilde{A}\\tilde{m} = \\mathbf{0}$ 的向量 $\\tilde{m} \\in \\mathbb{R}^{N_x}$ 组成。\n$$\nI_{N_x} \\tilde{m} = \\mathbf{0} \\implies \\tilde{m} = \\mathbf{0}\n$$\n零空间中唯一的向量是零向量。零空间是平凡空间 $\\{\\mathbf{0}\\}$。\n因此，重新参数化模型的零空间维数为：\n$$\n\\text{dim}(\\mathcal{N}(\\tilde{A})) = 0\n$$\n这种重新参数化通过重新构建问题，只求解模型中能被数据约束的部分，从而有效地消除了零空间。由此产生的关于 $\\tilde{m}$ 的反问题将是适定的。\n\n所要求的两个值是原始零空间维数 1092，和重新参数化后的零空间维数 0。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1092  0\n\\end{pmatrix}\n}\n$$", "id": "3618829"}, {"introduction": "当反演问题从线性拓展到非线性时，不适定性呈现出新的、更复杂的形式。除了算子本身的性质，我们还必须关注目标函数的地形（landscape）及其对优化算法行为的影响。本练习 [@problem_id:3618869] 通过一个简化但极具启发性的一维全波形反演（FWI）案例，探讨了模型参数化的选择（例如，使用速度或慢度）如何深刻地改变优化问题的局部凸性。通过推导并计算目标函数的Hessian矩阵，您将亲眼见证一个不当的参数化选择如何引入非凸区域，产生可能“捕获”局部优化算法的伪解，从而揭示了非线性问题中“适定性”与优化问题局部可解性之间的紧密联系。", "problem": "考虑一个简化的、能够捕捉全波形反演 (FWI) 中参数化选择所带来的关键非线性的、一维声波反演问题设定。假设存在两个属性未知的水平均匀层，声波从一个公共震源出发，以直射线方式传播到多个接收器。记第 $k$ 层的速度为 $v_k$（单位为 $\\mathrm{m/s}$），慢度为 $s_k$（单位为 $\\mathrm{s/m}$），满足 $s_k = 1 / v_k$。对于接收器索引 $j$，设 $L_{j1}$ 和 $L_{j2}$ 分别表示声波穿过第 1 层和第 2 层的固定路径长度（单位为 $\\mathrm{m}$）。在接收器 $j$ 处的预测单程走时（单位为 $\\mathrm{s}$）为\n- 在慢度参数化 $s = (s_1, s_2) \\in \\mathbb{R}^2$ 下：$t_j(s) = L_{j1} s_1 + L_{j2} s_2$，\n- 在速度参数化 $v = (v_1, v_2) \\in \\mathbb{R}^2$ 下：$t_j(v) = L_{j1} v_1^{-1} + L_{j2} v_2^{-1}$。\n\n给定观测走时 $d_j$（单位为 $\\mathrm{s}$），定义最小二乘目标函数\n$$\nJ(p) = \\frac{1}{2} \\sum_{j=1}^{m} \\left( t_j(p) - d_j \\right)^2,\n$$\n其中 $p$ 代表 $s$ 或 $v$，$m$ 是接收器的数量。根据定义，目标函数 $J$ 在某一点的局部凸性由该点二阶导数的 Hessian 矩阵的半正定性来表征；严格凸性则对应于正定性。Hessian 矩阵的特征值量化了曲率；负特征值表示存在负曲率方向和局部非凸性。\n\n您的任务是：\n1. 从链式法则和残差平方和的 Hessian 矩阵定义出发，推导在慢度 $s$ 和速度 $v$ 两种参数化下，目标函数 $J$ 的精确 Hessian 矩阵表达式。表达式需用路径长度 $L_{jk}$、模型参数 $p$ 和残差 $r_j(p) = t_j(p) - d_j$ 来表示。请勿使用任何预先引用的 FWI 特定公式；直接根据上述定义进行推导。\n2. 实现一个程序，对于下述每个测试用例，在指定的评估点计算两种参数化下的 Hessian 矩阵，计算其特征值，并报告：\n   - 慢度参数化下的最小特征值，\n   - 速度参数化下的最小特征值，\n   - 一个布尔值，说明 Hessian 矩阵是否为半正定（在数值容差内所有特征值 $\\ge 0$），\n   - 一个布尔值，说明 Hessian 矩阵是否为正定（在数值容差内所有特征值 $ 0$）。\n3. 根据整个测试套件中最小特征值的正负号，解释参数化选择如何影响局部凸性，进而影响局部适定性。\n\n测试套件规范：\n- 物理常数与单位：\n  - 路径长度 $L_{jk}$ 的单位为 $\\mathrm{m}$。\n  - 速度 $v_k$ 的单位为 $\\mathrm{m/s}$。\n  - 慢度 $s_k$ 的单位为 $\\mathrm{s/m}$。\n  - 走时 $t_j$ 和 $d_j$ 的单位为 $\\mathrm{s}$。\n- 用于生成数据的真实模型：\n  - $v_1^{\\mathrm{true}} = 2500$ 且 $v_2^{\\mathrm{true}} = 2000$。\n  - $s_k^{\\mathrm{true}} = 1 / v_k^{\\mathrm{true}}$。\n- 接收器与路径长度：\n  - 接收器 1：$(L_{11}, L_{12}) = (1000, 500)$。\n  - 接收器 2：$(L_{21}, L_{22}) = (700, 800)$。\n- 观测数据生成：\n  - 对任意接收器 $j$，设置 $d_j = L_{j1} s_1^{\\mathrm{true}} + L_{j2} s_2^{\\mathrm{true}}$。\n- 三个评估用例：\n  - 用例 A（理想情况，数据充分，位于真实模型处）：\n    - 使用两个接收器 $j \\in \\{1, 2\\}$。\n    - 在 $s = s^{\\mathrm{true}}$ 和 $v = v^{\\mathrm{true}}$ 处评估 Hessian 矩阵。\n  - 用例 B（速度的非线性区域，远离真实模型）：\n    - 使用两个接收器 $j \\in \\{1, 2\\}$。\n    - 在 $v = (100000, 100000)$ 以及对应的 $s = (1/100000, 1/100000)$ 处评估。\n  - 用例 C（边界情况，数据不足，秩亏几何）：\n    - 仅使用接收器 $j = 1$。\n    - 在 $s = s^{\\mathrm{true}}$ 和 $v = v^{\\mathrm{true}}$ 处评估。\n- 定性检查的数值容差：\n  - 使用容差 $\\tau = 10^{-12}$。如果特征值 $\\lambda \\ge -\\tau$，则视其为非负；如果 $\\lambda  \\tau$，则视其为严格正。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个列表，列表内有三个子列表，每个子列表对应一个用例，顺序和内容如下：\n  - 对于用例 A：$[\\lambda_{\\min}^{(s)}, \\lambda_{\\min}^{(v)}, \\mathrm{is\\_psd}^{(s)}, \\mathrm{is\\_psd}^{(v)}, \\mathrm{is\\_pd}^{(s)}, \\mathrm{is\\_pd}^{(v)}]$。\n  - 对于用例 B：结构与用例 A 相同。\n  - 对于用例 C：结构与用例 A 相同。\n- 此处，$\\lambda_{\\min}^{(s)}$ 是慢度参数化下 Hessian 矩阵的最小特征值，$\\lambda_{\\min}^{(v)}$ 是速度参数化下 Hessian 矩阵的最小特征值。布尔标志根据上述容差对应于半正定和正定性测试。\n- 程序必须精确输出一行，例如：\n  - $[[0.1,0.05,True,True,True,True],[...],[...]]$。\n\n程序不应读取任何外部输入；运行程序所需的所有数字均已在上方指定。输出为无单位的浮点数和定义的布尔值。请完全按照规定格式表达最终输出；输出行中无需报告物理单位。", "solution": "本任务旨在分析一个简化的一维声波反演问题，在慢度 $s = (s_1, s_2)$ 和速度 $v = (v_1, v_2)$ 这两种不同参数化下的局部凸性。某一点的局部凸性由目标函数在该点的 Hessian 矩阵的性质决定。具体来说，我们将推导 Hessian 矩阵，实现其计算，并针对三个不同用例解释结果。\n\n### 第 1 步：Hessian 矩阵的推导\n\n最小二乘目标函数由下式给出：\n$$\nJ(p) = \\frac{1}{2} \\sum_{j=1}^{m} \\left( t_j(p) - d_j \\right)^2 = \\frac{1}{2} \\sum_{j=1}^{m} r_j(p)^2\n$$\n其中 $p$ 是参数矢量（$s$ 或 $v$），$t_j(p)$ 是接收器 $j$ 的预测走时，$d_j$ 是观测走时，$r_j(p) = t_j(p) - d_j$ 是残差。\n\nHessian 矩阵 $H$ 的元素为 $H_{kl} = \\frac{\\partial^2 J}{\\partial p_k \\partial p_l}$。我们首先求梯度分量 $\\frac{\\partial J}{\\partial p_k}$：\n$$\n\\frac{\\partial J}{\\partial p_k} = \\frac{\\partial}{\\partial p_k} \\left( \\frac{1}{2} \\sum_{j=1}^{m} r_j(p)^2 \\right) = \\sum_{j=1}^{m} r_j(p) \\frac{\\partial r_j(p)}{\\partial p_k} = \\sum_{j=1}^{m} r_j(p) \\frac{\\partial t_j(p)}{\\partial p_k}\n$$\n因为 $d_j$ 是常数。现在我们使用乘法法则再次对 $p_l$ 求导：\n$$\nH_{kl}(p) = \\frac{\\partial^2 J}{\\partial p_k \\partial p_l} = \\frac{\\partial}{\\partial p_l} \\left( \\sum_{j=1}^{m} r_j(p) \\frac{\\partial t_j(p)}{\\partial p_k} \\right) = \\sum_{j=1}^{m} \\left( \\frac{\\partial r_j(p)}{\\partial p_l} \\frac{\\partial t_j(p)}{\\partial p_k} + r_j(p) \\frac{\\partial^2 t_j(p)}{\\partial p_k \\partial p_l} \\right)\n$$\n代入 $\\frac{\\partial r_j(p)}{\\partial p_l} = \\frac{\\partial t_j(p)}{\\partial p_l}$，我们得到 Hessian 矩阵的一般表达式：\n$$\nH_{kl}(p) = \\sum_{j=1}^{m} \\left( \\frac{\\partial t_j(p)}{\\partial p_k} \\frac{\\partial t_j(p)}{\\partial p_l} + r_j(p) \\frac{\\partial^2 t_j(p)}{\\partial p_k \\partial p_l} \\right)\n$$\n第一项 $\\sum_j \\frac{\\partial t_j}{\\partial p_k} \\frac{\\partial t_j}{\\partial p_l}$ 对应于 Hessian 矩阵的高斯-牛顿 (Gauss-Newton) 近似。第二项涉及正演模型 $t_j(p)$ 的二阶导数，是潜在非凸性的来源。\n\n#### 慢度参数化 $s = (s_1, s_2)$ 的 Hessian 矩阵\n\n正演模型在慢度上是线性的：$t_j(s) = L_{j1}s_1 + L_{j2}s_2$。\n一阶偏导数为：\n$$\n\\frac{\\partial t_j}{\\partial s_1} = L_{j1}, \\quad \\frac{\\partial t_j}{\\partial s_2} = L_{j2}\n$$\n二阶偏导数全为零：\n$$\n\\frac{\\partial^2 t_j(s)}{\\partial s_k \\partial s_l} = 0 \\quad \\text{for } k,l \\in \\{1,2\\}\n$$\n因此，Hessian 矩阵一般表达式中的第二项消失。慢度参数化下的 Hessian 矩阵 $H^{(s)}$ 为：\n$$\nH^{(s)}_{kl}(s) = \\sum_{j=1}^{m} \\frac{\\partial t_j(s)}{\\partial s_k} \\frac{\\partial t_j(s)}{\\partial s_l}\n$$\n其分量为：\n$$\nH^{(s)}_{11} = \\sum_{j=1}^{m} L_{j1}^2, \\quad H^{(s)}_{12} = H^{(s)}_{21} = \\sum_{j=1}^{m} L_{j1}L_{j2}, \\quad H^{(s)}_{22} = \\sum_{j=1}^{m} L_{j2}^2\n$$\n这可以写成矩阵形式 $H^{(s)} = L^T L$，其中 $L$ 是元素为 $L_{jk}$ 的 $m \\times 2$ 矩阵。该 Hessian 矩阵与模型参数 $s$ 和数据残差 $r_j$ 无关。作为一个格拉姆矩阵 (Gram matrix)，$H^{(s)}$ 总是半正定的。\n\n#### 速度参数化 $v = (v_1, v_2)$ 的 Hessian 矩阵\n\n正演模型在速度上是非线性的：$t_j(v) = L_{j1}v_1^{-1} + L_{j2}v_2^{-1}$。\n一阶偏导数为：\n$$\n\\frac{\\partial t_j}{\\partial v_1} = -L_{j1}v_1^{-2}, \\quad \\frac{\\partial t_j}{\\partial v_2} = -L_{j2}v_2^{-2}\n$$\n二阶偏导数为：\n$$\n\\frac{\\partial^2 t_j}{\\partial v_1^2} = 2L_{j1}v_1^{-3}, \\quad \\frac{\\partial^2 t_j}{\\partial v_2^2} = 2L_{j2}v_2^{-3}, \\quad \\frac{\\partial^2 t_j}{\\partial v_1 \\partial v_2} = 0\n$$\n将这些代入 Hessian 矩阵的通用公式，得到 $H^{(v)}(v)$ 的分量：\n$$\nH^{(v)}_{11} = \\sum_{j=1}^{m} \\left( (-L_{j1}v_1^{-2})^2 + r_j(v) (2L_{j1}v_1^{-3}) \\right) = v_1^{-4} \\sum_{j=1}^{m} L_{j1}^2 + 2v_1^{-3} \\sum_{j=1}^{m} r_j(v) L_{j1}\n$$\n$$\nH^{(v)}_{22} = \\sum_{j=1}^{m} \\left( (-L_{j2}v_2^{-2})^2 + r_j(v) (2L_{j2}v_2^{-3}) \\right) = v_2^{-4} \\sum_{j=1}^{m} L_{j2}^2 + 2v_2^{-3} \\sum_{j=1}^{m} r_j(v) L_{j2}\n$$\n$$\nH^{(v)}_{12} = H^{(v)}_{21} = \\sum_{j=1}^{m} \\left( (-L_{j1}v_1^{-2})(-L_{j2}v_2^{-2}) + r_j(v) \\cdot 0 \\right) = v_1^{-2}v_2^{-2} \\sum_{j=1}^{m} L_{j1}L_{j2}\n$$\n其中残差为 $r_j(v) = (L_{j1}v_1^{-1} + L_{j2}v_2^{-1}) - d_j$。由此得到的速度参数化下的 Hessian 矩阵 $H^{(v)}(v)$ 显式地依赖于评估点 $v$ 和数据残差 $r_j(v)$。\n\n### 第 2 步：结果解释\n\nHessian 矩阵的推导形式揭示了两种参数化之间的根本差异。\n\n- **慢度 ($s$)**：因为正演问题在 $s$ 上是线性的，所以目标函数 $J(s)$ 是一个二次函数（抛物面）。它的 Hessian 矩阵 $H^{(s)}$ 处处恒定，仅取决于采集几何 $L$。只要几何矩阵 $L$ 是满列秩的（即，至少有两个接收器的路径长度不成比例），$H^{(s)}$ 就是正定的。这意味着 $J(s)$ 是严格凸的，有唯一的全局最小值。这是一个局部和全局都适定的优化问题。用例 A 将证明这一点，其 Hessian 矩阵是正定的。用例 C 只有一个接收器，导致 $L$ 秩亏，使得 $H^{(s)}$ 仅为半正定；该问题存在一个零空间，对应于一族解。\n\n- **速度 ($v$)**：正演问题在 $v$ 上是非线性的，导致目标函数 $J(v)$ 是非二次函数。Hessian 矩阵 $H^{(v)}$ 包含一个依赖于残差的二阶项。\n  - 在用例 A 中，我们在真实模型处进行评估，此时残差为零（$r_j=0$）。Hessian 矩阵简化为高斯-牛顿 Hessian 矩阵，由于良好的几何结构，该矩阵是正定的。这表明在真实解周围是局部凸的。\n  - 在用例 B 中，我们在远离真实模型处进行评估。预测的走时远小于观测走时，导致较大的负残差。二阶项 $2v_k^{-3} \\sum_j r_j(v) L_{jk}$ 成为一个很大的负数，它可能压倒 $H^{(v)}$ 对角线上的正高斯-牛顿项。这可能导致 Hessian 矩阵出现负特征值，表明存在局部非凸性（鞍点或局部极大值）。这就是 FWI 中的“周波跳跃”问题，局部优化方法可能会陷入远离真实解的陷阱。\n  - 在用例 C 中，虽然在真实模型处（$r_j=0$），但由于几何结构是秩亏的，高斯-牛顿 Hessian 矩阵将是奇异的（半正定但非正定），这反映了由有限数据带来的固有非唯一性。\n\n总而言之，用慢度进行参数化使这个走时问题线性化，保证了目标函数具有简单、凸的形态。而用速度进行参数化，虽然是更符合物理直觉但非线性的选择，却创造了一个复杂的、带有非凸区域的函数形态，这使得反演过程复杂化，并对初始模型变得敏感。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the acoustic inversion problem by calculating Hessians and their eigenvalues\n    for three specified test cases.\n    \"\"\"\n\n    # --- Problem Definition ---\n\n    # True model parameters\n    v_true = np.array([2500.0, 2000.0])  # m/s\n    s_true = 1.0 / v_true                # s/m\n\n    # Receiver path lengths (m)\n    L_full = np.array([\n        [1000.0, 500.0],  # Receiver 1\n        [700.0, 800.0]    # Receiver 2\n    ])\n\n    # Observed data generation (noise-free)\n    d_obs_full = L_full @ s_true\n\n    # Numerical tolerance for definiteness checks\n    tau = 1.0e-12\n\n    # --- Test Case Specifications ---\n\n    test_cases_spec = [\n        # Case A: Happy path, sufficient data, at the true model\n        {\n            \"name\": \"Case A\",\n            \"receivers_slice\": slice(0, 2),\n            \"v_eval\": v_true,\n            \"s_eval\": s_true,\n        },\n        # Case B: Nonlinear regime for velocity, far from the true model\n        {\n            \"name\": \"Case B\",\n            \"receivers_slice\": slice(0, 2),\n            \"v_eval\": np.array([100000.0, 100000.0]),\n            \"s_eval\": np.array([1.0e-5, 1.0e-5]),\n        },\n        # Case C: Boundary case with insufficient data, rank-deficient geometry\n        {\n            \"name\": \"Case C\",\n            \"receivers_slice\": slice(0, 1),\n            \"v_eval\": v_true,\n            \"s_eval\": s_true,\n        },\n    ]\n\n    all_results = []\n\n    for case_spec in test_cases_spec:\n        # Extract parameters for the current case\n        L = L_full[case_spec[\"receivers_slice\"], :]\n        d_obs = d_obs_full[case_spec[\"receivers_slice\"]]\n        v_eval = case_spec[\"v_eval\"]\n        s_eval = case_spec[\"s_eval\"]\n        \n        # --- Hessian for Slowness Parameterization (s) ---\n        # H_s = L' * L, where L is the geometry matrix.\n        H_s = L.T @ L\n        \n        # --- Hessian for Velocity Parameterization (v) ---\n        # H_v = G'G + sum(r_j * H_j), where G is the Jacobian and H_j is the Hessian of t_j.\n        v1, v2 = v_eval[0], v_eval[1]\n        \n        # Calculate residuals r_j(v) = t_j(v) - d_j\n        t_pred = L @ (1.0 / v_eval)\n        residuals = t_pred - d_obs\n        \n        # Summation terms from the derivation\n        sum_L1_sq = np.sum(L[:, 0]**2)\n        sum_L2_sq = np.sum(L[:, 1]**2)\n        sum_L1L2 = np.sum(L[:, 0] * L[:, 1])\n        sum_rL1 = np.sum(residuals * L[:, 0])\n        sum_rL2 = np.sum(residuals * L[:, 1])\n        \n        # Build the Hessian H_v\n        h11_v = v1**(-4.0) * sum_L1_sq + 2.0 * v1**(-3.0) * sum_rL1\n        h22_v = v2**(-4.0) * sum_L2_sq + 2.0 * v2**(-3.0) * sum_rL2\n        h12_v = v1**(-2.0) * v2**(-2.0) * sum_L1L2\n        \n        H_v = np.array([[h11_v, h12_v], [h12_v, h22_v]])\n        \n        # --- Eigenvalue Analysis ---\n        # Use eigvalsh for symmetric matrices\n        evals_s = np.linalg.eigvalsh(H_s)\n        min_eval_s = np.min(evals_s)\n        \n        evals_v = np.linalg.eigvalsh(H_v)\n        min_eval_v = np.min(evals_v)\n        \n        # Definiteness checks using the specified tolerance tau\n        is_psd_s = min_eval_s >= -tau\n        is_pd_s = min_eval_s > tau\n        \n        is_psd_v = min_eval_v >= -tau\n        is_pd_v = min_eval_v > tau\n        \n        # Collect results for the current case\n        case_results = [\n            min_eval_s, \n            min_eval_v,\n            is_psd_s, \n            is_psd_v, \n            is_pd_s, \n            is_pd_v\n        ]\n        all_results.append(case_results)\n\n    # --- Final Output Formatting ---\n    # The output must be a single line containing a list of lists.\n    # Convert Python booleans (True/False) to strings \"True\"/\"False\" for final print.\n    output_str = \"[\"\n    for i, case_res in enumerate(all_results):\n        res_str = f\"[{case_res[0]},{case_res[1]},{case_res[2]},{case_res[3]},{case_res[4]},{case_res[5]}]\"\n        output_str += res_str\n        if i  len(all_results) - 1:\n            output_str += \",\"\n    output_str += \"]\"\n    \n    print(output_str)\n\nsolve()\n```", "id": "3618869"}]}