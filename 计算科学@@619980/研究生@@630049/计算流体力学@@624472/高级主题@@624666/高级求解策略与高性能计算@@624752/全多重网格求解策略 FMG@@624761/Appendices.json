{"hands_on_practices": [{"introduction": "全多重网格（FMG）方法的核心优势在于其卓越的计算效率。本练习将通过一个具体的三维问题，引导你手动分析一个V循环中的计算工作量。通过分解和加总在不同网格层级上进行的光滑、限制、延长和粗网格求解等操作的成本，你将亲身体会到为何多重网格方法的总计算量级仅为最细网格上单次操作成本的常数倍 [@problem_id:3322361]。", "problem": "考虑一个用于三维椭圆问题的全多重网格 (FMG) 求解策略，该问题在嵌套网格上进行离散，网格层级为 $\\ell = 0, 1, 2, 3, 4$，其中 $\\ell = 0$ 是最细层，$\\ell = 4$ 是最粗层。在连续的层级之间，网格在每个空间维度上以因子 $2$ 进行粗化，因此未知数的数量按 $n_{\\ell} = n_{0} \\times 8^{-\\ell}$ 的比例缩放。假设一个层级-$\\ell$ 的稀疏矩阵向量乘积 (SpMV) 的计算工作量与未知数数量成线性关系；因此，一个层级-$\\ell$ 的 SpMV 成本，以最细层 SpMV 为单位表示，为 $r_{\\ell} = 8^{-\\ell}$。\n\n考虑一个从层级 $\\ell = 0$ 开始的单次 V-循环，下降到层级 $\\ell = 4$，在最粗层上求解，然后返回到层级 $\\ell = 0$。在每个层级 $\\ell = 0, 1, 2, 3$ 上，V-循环执行 $\\nu_{1} = 2$ 次前平滑扫描和 $\\nu_{2} = 1$ 次后平滑扫描。在最粗层级 $\\ell = 4$ 上，算法执行一次粗网格求解，不进行平滑。在层级 $\\ell$ 上的单位操作成本，以层级-$\\ell$ 的 SpMV 为单位度量，如下：\n- 一次平滑扫描成本为 $c_{s} = 1$，\n- 一次从层级 $\\ell$ 到层级 $\\ell+1$ 的限制操作成本为 $c_{r} = \\frac{1}{4}$，\n- 一次从层级 $\\ell+1$ 到层级 $\\ell$ 的延拓操作成本为 $c_{p} = \\frac{1}{2}$，\n- 在层级 $\\ell = 4$ 上的粗网格求解成本为 $c_{0} = 16$。\n\n计算此 V-循环的总工作量 $W$，以最细层 SpMV 为单位表示（即，通过单个最细层 SpMV 的成本进行归一化）。然后，在平滑、限制、延拓和粗网格求解这四个类别中，确定哪个单一分量对 $W$ 的贡献最大。使用如下定义的索引 $\\kappa$ 报告主要分量：平滑为 $\\kappa = 1$，限制为 $\\kappa = 2$，延拓为 $\\kappa = 3$，粗网格求解为 $\\kappa = 4$。\n\n精确表示总工作量 $W$（不进行四舍五入），并使用 LaTeX 的 $\\texttt{pmatrix}$ 环境，以最细层 SpMV 为单位，将最终答案表示为一个二元行向量 $(W, \\kappa)$。", "solution": "本题的目标是计算单个 V-循环的总计算工作量 $W$，并确定其主要贡献部分。工作量以最细层级（$\\ell=0$）的稀疏矩阵向量乘积（SpMV）为单位进行归一化。总工作量 $W$ 是平滑（$W_s$）、限制（$W_r$）、延拓（$W_p$）和粗网格求解（$W_c$）的贡献之和。\n\n在网格层级 $\\ell$ 上执行的任何操作的成本，都必须通过乘以相对成本因子 $r_{\\ell} = 8^{-\\ell}$ 来归一化到最细层级的单位。\n\n1.  **平滑工作量 ($W_s$)**\n    平滑在层级 $\\ell = 0, 1, 2, 3$ 上执行。在每个层级，共有 $\\nu_{1} + \\nu_{2} = 2 + 1 = 3$ 次平滑扫描，每次扫描的成本为 $c_s = 1$ 个层级-$\\ell$ SpMV。\n    总平滑工作量是所有相关层级上成本的总和：\n    $$W_s = \\sum_{\\ell=0}^{3} (\\nu_{1} + \\nu_{2}) c_s r_{\\ell} = \\sum_{\\ell=0}^{3} (3)(1) (8^{-\\ell}) = 3 \\sum_{\\ell=0}^{3} 8^{-\\ell}$$\n\n2.  **限制工作量 ($W_r$)**\n    限制操作发生在 $\\ell = 0, 1, 2, 3$。每次操作的成本为 $c_r = \\frac{1}{4}$ 个层级-$\\ell$ SpMV。\n    总限制工作量为：\n    $$W_r = \\sum_{\\ell=0}^{3} c_r r_{\\ell} = \\sum_{\\ell=0}^{3} \\frac{1}{4} (8^{-\\ell}) = \\frac{1}{4} \\sum_{\\ell=0}^{3} 8^{-\\ell}$$\n\n3.  **延拓工作量 ($W_p$)**\n    延拓操作发生在 $\\ell = 0, 1, 2, 3$。每次操作的成本为 $c_p = \\frac{1}{2}$ 个层级-$\\ell$ SpMV（因为操作的目标是更新层级 $\\ell$ 的细网格）。\n    总延拓工作量为：\n    $$W_p = \\sum_{\\ell=0}^{3} c_p r_{\\ell} = \\sum_{\\ell=0}^{3} \\frac{1}{2} (8^{-\\ell}) = \\frac{1}{2} \\sum_{\\ell=0}^{3} 8^{-\\ell}$$\n\n4.  **粗网格求解工作量 ($W_c$)**\n    粗网格求解在最粗层级 $\\ell = 4$ 上执行一次，成本为 $c_0 = 16$ 个层级-4 SpMV。\n    归一化后的工作量贡献为：\n    $$W_c = c_0 r_{4} = 16 \\times 8^{-4} = \\frac{16}{8^4} = \\frac{16}{4096} = \\frac{1}{256}$$\n\n首先，计算几何级数和：\n$$S = \\sum_{\\ell=0}^{3} 8^{-\\ell} = 1 + \\frac{1}{8} + \\frac{1}{64} + \\frac{1}{512} = \\frac{512 + 64 + 8 + 1}{512} = \\frac{585}{512}$$\n\n然后，计算每个分量的工作量：\n- $W_s = 3 \\times S = 3 \\times \\frac{585}{512} = \\frac{1755}{512}$\n- $W_r = \\frac{1}{4} \\times S = \\frac{1}{4} \\times \\frac{585}{512} = \\frac{585}{2048}$\n- $W_p = \\frac{1}{2} \\times S = \\frac{1}{2} \\times \\frac{585}{512} = \\frac{585}{1024}$\n- $W_c = \\frac{1}{256}$\n\n总工作量 $W$ 是这些分量的总和。使用公分母 $2048$：\n$$W = \\frac{1755 \\times 4}{2048} + \\frac{585}{2048} + \\frac{585 \\times 2}{2048} + \\frac{1 \\times 8}{2048} = \\frac{7020 + 585 + 1170 + 8}{2048} = \\frac{8783}{2048}$$\n\n最后，比较各分量的大小（使用公分母 $2048$）：\n- 平滑 ($\\kappa=1$)：$W_s = \\frac{7020}{2048}$\n- 限制 ($\\kappa=2$)：$W_r = \\frac{585}{2048}$\n- 延拓 ($\\kappa=3$)：$W_p = \\frac{1170}{2048}$\n- 粗网格求解 ($\\kappa=4$)：$W_c = \\frac{8}{2048}$\n\n由于 $7020 > 1170 > 585 > 8$，最大的贡献来自平滑。因此，主要分量的索引是 $\\kappa=1$。\n\n最终答案由总工作量 $W = \\frac{8783}{2048}$ 和主要分量索引 $\\kappa = 1$ 组成。", "answer": "$$\n\\boxed{\n\\begin{pmatrix} \\frac{8783}{2048} & 1 \\end{pmatrix}\n}\n$$", "id": "3322361"}, {"introduction": "从线性问题过渡到非线性问题是计算流体力学中的常态。全近似格式（Full Approximation Scheme, FAS）是为非线性问题量身定制的多重网格策略。此练习将聚焦于FAS的核心——“tau校正项” ($\\tau$)，它确保了粗网格问题能正确地模拟细网格上的非线性行为。通过对一个非线性扩散问题进行动手计算，你将揭示该校正项的由来及其在保证算法快速收敛中的关键作用 [@problem_id:3322340]。", "problem": "考虑在区间 $\\Omega=[0,1]$ 上具有齐次狄利克雷边界条件的一维非线性扩散边值问题，\n$$\n- \\partial_{x}\\!\\left(\\kappa(u)\\,\\partial_{x} u\\right) \\;=\\; f(x), \n\\qquad u(0)=0,\\quad u(1)=0,\n$$\n其中 $\\kappa(u)=1+u^{2}$ 且 $f(x)=1$。设该方程在两个嵌套的均匀网格上，采用单元中心的有限差分/有限体积观点以守恒形式进行离散化：一个间距为 $h=1/4$ 的细网格和一个间距为 $H=1/2$ 的粗网格。细网格节点位于 $x_{i}=i h$（$i=0,1,2,3,4$），粗网格节点位于 $X_{J}=J H$（$J=0,1,2$）。\n\n在任一网格上，内部节点的离散扩散算子 $L_{\\Delta}(\\cdot)$（其中 $\\Delta\\in\\{h,H\\}$）定义为\n$$\n\\left[L_{\\Delta}(u)\\right]_{i} \\;=\\; -\\frac{1}{\\Delta^{2}}\\Big( K_{i+\\tfrac{1}{2}}\\,(u_{i+1}-u_{i}) \\;-\\; K_{i-\\tfrac{1}{2}}\\,(u_{i}-u_{i-1}) \\Big),\n$$\n其中，面系数由在相邻节点状态下计算的算术平均值 $K_{i+\\tfrac{1}{2}}=\\tfrac{1}{2}\\big(\\kappa(u_{i+1})+\\kappa(u_{i})\\big)$ 给出。在细网格上，给定的当前近似解为\n$$\nu_{h}(0)=0,\\quad u_{h}(0.25)=0.2,\\quad u_{h}(0.5)=0.3,\\quad u_{h}(0.75)=0.1,\\quad u_{h}(1)=0.\n$$\n\n定义从细网格状态到粗网格的限制（restriction）为重合节点的点注入（point injection），即 $\\hat{u}_{H}(0)=0$，$\\hat{u}_{H}(0.5)=u_{h}(0.5)$，$\\hat{u}_{H}(1)=0$。定义从细网格到粗网格的离散算子值（或残差）的限制为一维中的全加权（full weighting），即对于与细网格节点 $x_{2}=0.5$ 相关的唯一内部粗网格节点 $X_{1}=0.5$：\n$$\n\\left[I_{h}^{H} w_{h}\\right]_{1} \\;=\\; \\tfrac{1}{4}\\,w_{1} \\;+\\; \\tfrac{1}{2}\\,w_{2} \\;+\\; \\tfrac{1}{4}\\,w_{3}.\n$$\n\n设粗网格的右端项由细网格右端项的限制定义，即 $f_{H}=I_{h}^{H} f_{h}$，其中每个细网格内部节点上 $f_{h,i}=1$。\n\n从守恒和非线性多重网格的完全逼近格式（FAS）出发，推导在唯一内部粗网格节点 $X_{1}$ 处的粗网格 $\\tau$-修正的显式公式，并根据上述数据计算其值。然后，写出包含和不包含 $\\tau$-修正的粗网格方程，并基于这些构造解释为什么包含 $\\tau_{H}$ 能改善该非线性问题的双网格收敛性。\n\n将计算出的粗网格 $X_{1}$ 处的 $\\tau$-修正值报告为一个无量纲数，四舍五入到六位有效数字。", "solution": "问题的核心是计算完全逼近格式（Full Approximation Scheme, FAS）中的粗网格 $\\tau$-修正项。FAS 的粗网格方程旨在求解一个完整的解的近似 $u_H$，其形式为：\n$$\nL_H(u_H) = f_H + \\tau_H\n$$\n其中 $f_H = I_h^H f_h$ 是限制后的右端项，而 $\\tau$-修正项定义为：\n$$\n\\tau_H = L_H(\\hat{u}_H) - I_h^H L_h(u_h)\n$$\n这里，$u_h$ 是当前的细网格近似解，$\\hat{u}_H$ 是其到粗网格的限制（通过注入），$L_h$ 和 $L_H$ 分别是细网格和粗网格上的离散算子，$I_h^H$ 是将算子（或残差）从细网格限制到粗网格的全加权算子。我们将为唯一的内部粗网格节点 $X_1 = 0.5$ 计算 $[\\tau_H]_1$ 的值。\n\n给定的细网格近似解为 $u_h = [0, 0.2, 0.3, 0.1, 0]^T$。\n\n**步骤 1：计算细网格算子项 $L_h(u_h)$ 及其限制**\n\n首先，计算非线性系数 $\\kappa(u) = 1+u^2$ 在细网格节点上的值：\n$\\kappa(u_0)=1.00$, $\\kappa(u_1)=1.04$, $\\kappa(u_2)=1.09$, $\\kappa(u_3)=1.01$, $\\kappa(u_4)=1.00$。\n\n然后计算单元交界面上的系数 $K_{i+1/2} = \\frac{1}{2}(\\kappa(u_{i+1}) + \\kappa(u_i))$：\n$K_{1/2}=1.02$, $K_{3/2}=1.065$, $K_{5/2}=1.05$, $K_{7/2}=1.005$。\n\n接下来，在内部节点 $x_1, x_2, x_3$ 处计算细网格算子 $[L_h(u_h)]_i = -1/h^2 \\left( \\dots \\right)$，其中 $h=1/4$：\n- $[L_h(u_h)]_1 = -16 \\left( K_{3/2}(u_2-u_1) - K_{1/2}(u_1-u_0) \\right) = -16(1.065(0.1) - 1.02(0.2)) = 1.56$\n- $[L_h(u_h)]_2 = -16 \\left( K_{5/2}(u_3-u_2) - K_{3/2}(u_2-u_1) \\right) = -16(1.05(-0.2) - 1.065(0.1)) = 5.064$\n- $[L_h(u_h)]_3 = -16 \\left( K_{7/2}(u_4-u_3) - K_{5/2}(u_3-u_2) \\right) = -16(1.005(-0.1) - 1.05(-0.2)) = -1.752$\n\n使用全加权限制算子将 $L_h(u_h)$ 限制到粗网格节点 $X_1=0.5$：\n$[I_h^H L_h(u_h)]_1 = \\frac{1}{4}[L_h(u_h)]_1 + \\frac{1}{2}[L_h(u_h)]_2 + \\frac{1}{4}[L_h(u_h)]_3$\n$= \\frac{1}{4}(1.56) + \\frac{1}{2}(5.064) + \\frac{1}{4}(-1.752) = 0.39 + 2.532 - 0.438 = 2.484$。\n\n**步骤 2：计算粗网格算子项 $L_H(\\hat{u}_H)$**\n\n通过注入得到限制后的解 $\\hat{u}_H = [0, u_h(0.5), 0]^T = [0, 0.3, 0]^T$。\n计算粗网格上的 $\\kappa$ 值：$\\kappa(\\hat{u}_{H,0})=1.00$, $\\kappa(\\hat{u}_{H,1})=1.09$, $\\kappa(\\hat{u}_{H,2})=1.00$。\n粗网格面系数为：$K_{1/2} = \\frac{1}{2}(1.09+1.00) = 1.045$，$K_{3/2} = \\frac{1}{2}(1.00+1.09) = 1.045$。\n\n在内部节点 $X_1=0.5$ 处计算粗网格算子 $[L_H(\\hat{u}_H)]_1 = -1/H^2 \\left( \\dots \\right)$，其中 $H=1/2$：\n$[L_H(\\hat{u}_H)]_1 = -4 \\left( K_{3/2}(\\hat{u}_{H,2}-\\hat{u}_{H,1}) - K_{1/2}(\\hat{u}_{H,1}-\\hat{u}_{H,0}) \\right)$\n$= -4 \\left( 1.045(0-0.3) - 1.045(0.3-0) \\right) = -4(-0.3135 - 0.3135) = 2.508$。\n\n**步骤 3：计算 $\\tau_H$**\n\n现在我们可以计算 $X_1$ 处的 $\\tau$-修正项：\n$[\\tau_H]_1 = [L_H(\\hat{u}_H)]_1 - [I_h^H L_h(u_h)]_1 = 2.508 - 2.484 = 0.024$。\n\n**$\\tau$-修正项的意义**\n\n不含 $\\tau$-修正的粗网格方程为 $L_H(u_H) = I_h^H f_h$。该方程求解的是一个独立的、与细网格问题无关的粗网格离散问题。\n包含 $\\tau$-修正的粗网格方程为 $L_H(u_H) = I_h^H f_h + \\tau_H = I_h^H f_h + L_H(\\hat{u}_H) - I_h^H L_h(u_h)$。\n这个方程可以重写为 $L_H(u_H) - L_H(\\hat{u}_H) = I_h^H(f_h - L_h(u_h))$。右侧是限制后的细网格残差。此形式确保了一个关键的一致性属性：如果细网格解收敛（即残差为零），则粗网格修正量 $u_H - \\hat{u}_H$ 也必须为零。$\\tau$-项修正了粗网格离散与细网格离散之间的差异（即相对截断误差），从而使粗网格问题能够正确地计算出针对细网格光滑误差的修正，这是多重网格方法高效收敛的根本原因。", "answer": "$$\n\\boxed{0.0240000}\n$$", "id": "3322340"}, {"introduction": "为了将理论应用于前沿研究，本练习将挑战一个复杂的多物理场耦合问题：Cahn–Hilliard–Navier–Stokes方程系统。这类描述多相流的鞍点问题对求解器提出了极高要求，需要借助块式光滑器等高级技术在FMG框架下求解。通过完成这个高阶编程实践，你将构建一个完整的FMG求解器，并探索其在不同物理参数下的收敛性能，从而真正打通从理论到复杂应用的关键一环 [@problem_id:3322398]。", "problem": "考虑将 Cahn–Hilliard 方程与不可压缩 Navier–Stokes 方程耦合，该问题定义在单位正方形上，所有场均采用齐次 Dirichlet 边界条件。连续模型包括动量平衡、不可压缩性约束、质量传输和化学势定义。令 $u(x,y)$ 和 $v(x,y)$ 表示速度分量，$p(x,y)$ 为压力，$\\mu(x,y)$ 为化学势，$\\phi(x,y)$ 为相场。在每个时间步需要求解的线性化稳态模型，被抽象为以下在有界域上的方程组，其边界条件为无滑移（$u = 0, v = 0$）以及 $\\mu$ 和 $\\phi$ 的齐次边界条件：\n- 动量平衡：$-\\nu \\Delta u + \\partial_x p + \\gamma \\partial_x \\mu = 0$ 和 $-\\nu \\Delta v + \\partial_y p + \\gamma \\partial_y \\mu = 0$，\n- 不可压缩性：$\\partial_x u + \\partial_y v = 0$，\n- Cahn–Hilliard 扩散：$M \\Delta \\mu = g(x,y)$，\n- 化学势定义（线性化）：$\\mu - \\left(-\\epsilon^2 \\Delta + I\\right)\\phi = 0$，\n其中 $\\nu > 0$ 是粘度，$M > 0$ 是迁移率，$\\epsilon > 0$ 是界面宽度，$\\gamma \\ge 0$ 是耦合强度，而 $I$ 表示单位算子。源项 $g(x,y)$ 是一个光滑、局域化的 Cahn–Hilliard 扩散强迫项，具体形式如下所述。\n\n使用嵌套的、含 $n \\times n$ 内部点的单元中心均匀网格序列对该系统进行离散化。其中，拉普拉斯算子使用二阶有限差分，梯度和散度算子使用满足离散伴随关系 $D = -G^\\top$ 的一阶中心差分。令 $h = 1/(n+1)$，并令离散正定拉普拉斯算子 $L$ 表示在齐次 Dirichlet 边界条件下的 $-\\Delta$。为未知向量 $x = [u; v; p; \\mu; \\phi] \\in \\mathbb{R}^{5N}$（其中 $N = n^2$）构建如下分块线性系统：\n$$\n\\begin{bmatrix}\n\\alpha I + \\nu L  0  G_x  \\gamma G_x  0 \\\\\n0  \\alpha I + \\nu L  G_y  \\gamma G_y  0 \\\\\n-D_x  -D_y  \\beta I  0  0 \\\\\n0  0  0  M L  0 \\\\\n0  0  0  I  -\\left(\\epsilon^2 L + I\\right)\n\\end{bmatrix}\n\\begin{bmatrix}\nu \\\\ v \\\\ p \\\\ \\mu \\\\ \\phi\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0 \\\\ 0 \\\\ 0 \\\\ g \\\\ 0\n\\end{bmatrix},\n$$\n其中 $I$ 是 $\\mathbb{R}^N$ 上的单位矩阵，$G_x$ 和 $G_y$ 是将压力或化学势映射到速度分量的离散梯度算子，$D_x = -G_x^\\top$ 和 $D_y = -G_y^\\top$ 是将速度分量映射到压力的离散散度算子，$\\alpha > 0$ 是一个正反应系数，用于确保速度块是严格正定的，$\\beta > 0$ 是一个小的压力稳定化项，以避免在齐次边界条件下出现奇异的鞍点系统。源项 $g(x,y)$ 由下式给出\n$$\ng(x,y) = \\exp\\left(-100 \\left[(x - 0.5)^2 + (y - 0.5)^2\\right]\\right).\n$$\n在单元中心处对 $g(x,y)$ 进行离散化。\n\n为该耦合鞍点系统设计并实现一个全多重网格（FMG）求解策略，使用适用于不定系统的分块光滑子。使用分块 Jacobi 光滑子，该光滑子通过各分块的对角逆和顺序更新来更新 $[u,v,p,\\mu,\\phi]$ 各块，并遵循分块结构。FMG 过程必须：\n- 建立一个三层的层级结构，每边分别有 $n = 8, 16, 32$ 个内部点（因此 $N = 64, 256, 1024$）。\n- 在最粗糙层上，通过稀疏直接求解计算精确解。\n- 将解延拓到下一层，并在每层执行一次多重网格 V-循环以优化近似解。\n- 在最精细层上，继续执行 V-循环，直到残差的欧几里得范数相对于 FMG 延拓到最精细网格后的范数减小一个指定的因子。\n\n多重网格组件必须是：\n- 限制：对每个场分别应用 $2 \\times 2$ 全加权（简单平均）。\n- 延拓：对每个场分别应用双线性插值。\n- 光滑子：分块 Jacobi，对每个分块进行对角缩放，并选择松弛参数以确保对对称正定分块的阻尼效果；对于压力块，使用稳定化对角项 $\\beta I$。\n\n在所有测试中使用以下固定参数：$\\nu = 1$（无量纲粘度），$\\alpha = 1$（无量纲反应），$\\gamma = 0.1$（无量纲耦合），$\\beta = 10^{-3}$（无量纲压力稳定化）。变化的参数是迁移率 $M$ 和界面宽度 $\\epsilon$，在本练习中两者均视为无量纲。\n\n收敛性跟踪要求：\n- 令 $\\|r\\|_2$ 表示最精细层上残差向量的欧几里得范数。\n- 在完成到最精细网格的 FMG 传输后（即，在该层上完成初始的单次 V-循环后），记录 $\\|r_0\\|_2$。\n- 在最精细层上继续应用 V-循环，直到残差范数 $\\|r_k\\|_2$ 满足 $\\|r_k\\|_2 \\le 10^{-6} \\|r_0\\|_2$ 或直到 $k$ 达到最多 $20$ 次 V-循环。\n- 对于测试套件中的每对参数 $(M,\\epsilon)$，报告在最精细层上使用的 V-循环整数次数 $k$（如果未达到标准，则上限为 $20$）。\n\n测试套件：\n- 情况1（理想路径）：$M = 10^{-2}$，$\\epsilon = 2 \\times 10^{-2}$。\n- 情况2（低迁移率边缘情况）：$M = 10^{-4}$，$\\epsilon = 2 \\times 10^{-2}$。\n- 情况3（窄界面边缘情况）：$M = 10^{-2}$，$\\epsilon = 5 \\times 10^{-3}$。\n- 情况4（宽界面变化）：$M = 10^{-3}$，$\\epsilon = 10^{-1}$。\n\n您的程序应生成单行输出，其中包含一个逗号分隔的整数结果列表，用方括号括起，并按测试用例的顺序排列（例如，$[k_1,k_2,k_3,k_4]$）。在此问题中，所有量都是无量纲的；不需要物理单位。问题不涉及角度；不需要角度单位。百分比必须以小数形式表示为比率；在此问题中，残差减少直接表示为比率 $10^{-6}$。", "solution": "本问题要求为一个耦合的 Cahn-Hilliard-Navier-Stokes 线性系统设计并实现一个全多重网格（FMG）求解器。该系统为鞍点问题，具有非对称和不定的特性。求解策略遵循 FMG 方法，以实现最优的计算效率。\n\n### 1. 离散化与系统构建\n\n该偏微分方程组在一个三层嵌套的单元中心网格上进行离散化，内部单元数分别为 $n \\times n$，其中 $n \\in \\{32, 16, 8\\}$。网格尺寸为 $h = 1/n$。状态向量 $x$ 由五个场（$u, v, p, \\mu, \\phi$）组成，总未知数数量为 $5N = 5n^2$。\n\n使用稀疏矩阵和克罗内克积来构建离散算子：\n- **离散拉普拉斯算子 ($L$)**: 基于标准五点中心差分模板构建，对应于带齐次狄利克雷边界条件的 $-\\Delta$ 算子。\n- **离散梯度 ($G_x, G_y$)**: 基于一阶中心差分构建。\n- **离散散度 ($D_x, D_y$)**: 根据离散伴随关系定义为 $D_x = -G_x^\\top$ 和 $D_y = -G_y^\\top$。\n\n利用这些算子，为每个网格层级组装问题描述中定义的 $5 \\times 5$ 分块矩阵 $A$ 和右端项向量 $b$。源项 $g(x,y)$ 在每个单元的中心点进行求值。\n\n### 2. 多重网格组件\n\n- **光滑子**: 采用分块雅可比（Block Jacobi）光滑子。其迭代格式为 $x_{k+1} = x_k + \\omega D_A^{-1}(b - Ax_k)$，其中 $D_A^{-1}$ 为系统矩阵 $A$ 的块对角部分的逆。在此实现中，该逆被近似为 $A$ 的主对角线元素的逆，从而构成一个计算开销较低的、带阻尼的点式雅可比迭代。松弛参数 $\\omega$ 选择为 $0.7$ 以确保对高频误差的有效平滑。\n\n- **限制算子 ($R$)**: 采用全加权（full weighting）算子，它通过对一个 $2 \\times 2$ 细网格单元块的值进行平均，将其残差贡献映射到一个粗网格单元。该操作对五个场分别独立应用。\n\n- **延拓算子 ($P$)**: 采用双线性插值（bilinear interpolation）将粗网格上的误差校正插值到细网格。此操作对五个场分别独立应用。\n\n### 3. V-循环与全多重网格（FMG）\n\n- **V-循环**: 采用一个标准的递归 V-循环算法。在每一层级（最粗层除外），执行以下步骤：\n  1.  **预平滑**: 进行 $\\nu_1=2$ 次光滑子扫描。\n  2.  **粗网格校正**: 计算残差，将其限制到粗网格，递归调用 V-循环求解粗网格误差方程，将误差校正延拓回细网格，并更新解。\n  3.  **后平滑**: 进行 $\\nu_2=2$ 次光滑子扫描。\n  在最粗层级（$n=8$），使用稀疏直接求解器精确求解方程。\n\n- **全多重网格 (FMG)**: FMG 策略用于为最精细网格生成一个高质量的初始解。\n  1.  在最粗层级（$n=8$）上直接求解得到精确解。\n  2.  将解延拓到下一层更细的网格（$n=16$）。\n  3.  在该网格上执行一次 V-循环来改进解。\n  4.  重复此过程，将解从 $n=16$ 延拓到 $n=32$，并再次执行一次 V-循环。\n\n### 4. 收敛性测试\n\n在最精细网格（$n=32$）上获得 FMG 初始解后，计算其残差范数 $\\|r_0\\|_2$。随后，在该层级上迭代应用 V-循环，直到残差范数 $\\|r_k\\|_2$ 满足 $\\|r_k\\|_2 \\le 10^{-6} \\|r_0\\|_2$。记录达到此收敛标准所需的 V-循环次数 $k$，最大不超过 $20$ 次。对四个指定的参数组合 $(M, \\epsilon)$ 分别执行此过程，并报告 $k$ 值。", "answer": "```python\nimport numpy as np\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\n\ndef get_system(n, params):\n    \"\"\"\n    Assembles the discrete system matrix A and right-hand side b for a given grid size n.\n    \"\"\"\n    nu, alpha, gamma, beta, M, epsilon = params\n    # Use h=1/n for cell-centered grids, consistent with n=8,16,32 sequence.\n    h = 1.0 / n\n    N = n * n\n\n    e = np.ones(n)\n    # 1D Laplacian L1D for -d^2/dx^2 with homogeneous Dirichlet BCs\n    L1D = sparse.spdiags([-e, 2 * e, -e], [-1, 0, 1], n, n, format='csr') / (h * h)\n    # 1D Gradient G1D for d/dx with centered differences\n    G1D = sparse.spdiags([-e, e], [-1, 1], n, n, format='csr') / (2 * h)\n\n    I_n = sparse.identity(n, format='csr')\n    # 2D operators using Kronecker products\n    L = sparse.kron(L1D, I_n) + sparse.kron(I_n, L1D)\n    G_x = sparse.kron(G1D, I_n)\n    G_y = sparse.kron(I_n, G1D)\n    D_x = -G_x.T\n    D_y = -G_y.T\n\n    I_N = sparse.identity(N, format='csr')\n    \n    # Diagonal blocks of the system matrix\n    A_uu = alpha * I_N + nu * L\n    A_vv = alpha * I_N + nu * L\n    A_pp = beta * I_N\n    A_mumu = M * L if M > 0 else sparse.csr_matrix((N, N))\n    A_phiphi = -(epsilon**2 * L + I_N)\n\n    # Assemble the full 5N x 5N system matrix A\n    row1 = [A_uu, sparse.csr_matrix((N, N)), G_x, gamma * G_x, sparse.csr_matrix((N, N))]\n    row2 = [sparse.csr_matrix((N, N)), A_vv, G_y, gamma * G_y, sparse.csr_matrix((N, N))]\n    row3 = [-D_x, -D_y, A_pp, sparse.csr_matrix((N, N)), sparse.csr_matrix((N, N))]\n    row4 = [sparse.csr_matrix((N, N)), sparse.csr_matrix((N, N)), sparse.csr_matrix((N, N)), A_mumu, sparse.csr_matrix((N, N))]\n    row5 = [sparse.csr_matrix((N, N)), sparse.csr_matrix((N, N)), sparse.csr_matrix((N, N)), I_N, A_phiphi]\n    \n    A = sparse.bmat([row1, row2, row3, row4, row5], format='csr')\n\n    # Assemble the RHS vector b\n    b = np.zeros(5 * N)\n    x_coords = np.linspace(h / 2, 1 - h / 2, n)\n    y_coords = np.linspace(h / 2, 1 - h / 2, n)\n    xx, yy = np.meshgrid(x_coords, y_coords)\n    g_grid = np.exp(-100 * ((xx - 0.5)**2 + (yy - 0.5)**2))\n    b[3*N:4*N] = g_grid.flatten()\n\n    return A, b\n\ndef restrict(x_fine, n_fine):\n    \"\"\"Restriction: 2x2 simple averaging.\"\"\"\n    n_coarse = n_fine // 2\n    x_fine_5d = x_fine.reshape(5, n_fine, n_fine)\n    x_coarse_5d = 0.25 * (x_fine_5d[:, 0::2, 0::2] + x_fine_5d[:, 1::2, 0::2] +\n                          x_fine_5d[:, 0::2, 1::2] + x_fine_5d[:, 1::2, 1::2])\n    return x_coarse_5d.flatten()\n\ndef prolongate(x_coarse, n_coarse):\n    \"\"\"Prolongation: Bilinear interpolation for cell-centered grids.\"\"\"\n    n_fine = n_coarse * 2\n    x_coarse_5d = x_coarse.reshape((5, n_coarse, n_coarse))\n    x_fine_5d = np.zeros((5, n_fine, n_fine))\n\n    x_coarse_padded = np.pad(x_coarse_5d, ((0, 0), (1, 1), (1, 1)), 'constant')\n\n    for I in range(n_coarse):\n        for J in range(n_coarse):\n            i_p, j_p = I + 1, J + 1\n\n            v_im1_jm1 = x_coarse_padded[:, i_p - 1, j_p - 1]\n            v_i_jm1   = x_coarse_padded[:, i_p,     j_p - 1]\n            v_im1_j   = x_coarse_padded[:, i_p - 1, j_p]\n            v_i_j     = x_coarse_padded[:, i_p,     j_p]\n            v_ip1_j   = x_coarse_padded[:, i_p + 1, j_p]\n            v_i_jp1   = x_coarse_padded[:, i_p,     j_p + 1]\n            v_ip1_jp1 = x_coarse_padded[:, i_p + 1, j_p + 1]\n            v_im1_jp1 = x_coarse_padded[:, i_p - 1, j_p + 1]\n            v_ip1_jm1 = x_coarse_padded[:, i_p + 1, j_p - 1]\n\n            i_f, j_f = 2 * I, 2 * J\n            \n            x_fine_5d[:, i_f,     j_f]     = (9 * v_i_j + 3 * v_im1_j + 3 * v_i_jm1 + 1 * v_im1_jm1) / 16.0\n            x_fine_5d[:, i_f + 1, j_f]     = (9 * v_i_j + 3 * v_ip1_j + 3 * v_i_jm1 + 1 * v_ip1_jm1) / 16.0\n            x_fine_5d[:, i_f,     j_f + 1] = (9 * v_i_j + 3 * v_im1_j + 3 * v_i_jp1 + 1 * v_im1_jp1) / 16.0\n            x_fine_5d[:, i_f + 1, j_f + 1] = (9 * v_i_j + 3 * v_ip1_j + 3 * v_i_jp1 + 1 * v_ip1_jp1) / 16.0\n            \n    return x_fine_5d.flatten()\n\ndef smoother(A, x, b, n, params, num_sweeps, omega=0.7):\n    \"\"\"Smoother: Damped block-Jacobi with diagonal scaling.\"\"\"\n    nu, alpha, gamma, beta, M, epsilon = params\n    h = 1.0 / n\n    N = n * n\n    \n    diag_L_val = 4.0 / (h*h)\n    \n    inv_diag_uu = 1.0 / (alpha + nu * diag_L_val)\n    inv_diag_vv = 1.0 / (alpha + nu * diag_L_val)\n    inv_diag_pp = 1.0 / beta\n    inv_diag_mumu = 1.0 / (M * diag_L_val) if M > 1e-12 else 0.0\n    inv_diag_phiphi = 1.0 / -(epsilon**2 * diag_L_val + 1.0)\n    \n    inv_diag_A = np.concatenate([np.full(N, inv_diag_uu), np.full(N, inv_diag_vv),\n                                 np.full(N, inv_diag_pp), np.full(N, inv_diag_mumu),\n                                 np.full(N, inv_diag_phiphi)])\n\n    for _ in range(num_sweeps):\n        r = b - A.dot(x)\n        x += omega * inv_diag_A * r\n    return x\n\ndef v_cycle(level, x_guess, b, systems, ns, params, nu1, nu2):\n    \"\"\"Recursive V-cycle implementation.\"\"\"\n    A = systems[level]['A']\n    n = ns[level]\n\n    x = smoother(A, x_guess, b, n, params, nu1)\n    \n    if level  len(systems) - 1: # Not on coarsest level\n        r = b - A.dot(x)\n        r_coarse = restrict(r, n)\n        e_coarse = np.zeros_like(r_coarse)\n        e_coarse = v_cycle(level + 1, e_coarse, r_coarse, systems, ns, params, nu1, nu2)\n        e_fine = prolongate(e_coarse, ns[level+1])\n        x += e_fine\n        x = smoother(A, x, b, n, params, nu2)\n    else: # On coarsest level\n        x = spsolve(A, b)\n    \n    return x\n\ndef fmg_solve(systems, ns, params, nu1, nu2):\n    \"\"\"Full Multigrid (FMG) initial guess computation.\"\"\"\n    coarsest_level = len(systems) - 1\n    x = spsolve(systems[coarsest_level]['A'], systems[coarsest_level]['b'])\n    \n    for level in range(coarsest_level - 1, -1, -1):\n        x = prolongate(x, ns[level+1])\n        b_fine = systems[level]['b']\n        x = v_cycle(level, x, b_fine, systems, ns, params, nu1, nu2)\n    \n    return x\n\ndef solve():\n    \"\"\"Main function to run test cases and print results.\"\"\"\n    test_cases = [\n        (10**-2, 2 * 10**-2),  # Case 1\n        (10**-4, 2 * 10**-2),  # Case 2\n        (10**-2, 5 * 10**-3),  # Case 3\n        (10**-3, 10**-1),      # Case 4\n    ]\n\n    fixed_params = {'nu': 1.0, 'alpha': 1.0, 'gamma': 0.1, 'beta': 1e-3}\n    ns = [32, 16, 8]\n    nu1, nu2 = 2, 2  # Pre- and post-smoothing sweeps\n    \n    results = []\n\n    for M, epsilon in test_cases:\n        params = (fixed_params['nu'], fixed_params['alpha'], fixed_params['gamma'], \n                  fixed_params['beta'], M, epsilon)\n        \n        systems = [{'A': get_system(n, params)[0], 'b': get_system(n, params)[1]} for n in ns]\n        \n        x_k = fmg_solve(systems, ns, params, nu1, nu2)\n\n        A_fine, b_fine = systems[0]['A'], systems[0]['b']\n        \n        r0 = b_fine - A_fine.dot(x_k)\n        norm_r0 = np.linalg.norm(r0)\n        \n        if norm_r0 == 0:\n            results.append(0)\n            continue\n            \n        k = 0\n        max_cycles = 20\n        target_reduction = 1e-6\n        \n        for i in range(1, max_cycles + 1):\n            x_k = v_cycle(0, x_k, b_fine, systems, ns, params, nu1, nu2)\n            r_k = b_fine - A_fine.dot(x_k)\n            norm_rk = np.linalg.norm(r_k)\n            \n            if norm_rk = target_reduction * norm_r0:\n                k = i\n                break\n        else:\n            k = max_cycles\n        \n        results.append(k)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3322398"}]}