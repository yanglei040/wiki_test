{"hands_on_practices": [{"introduction": "在网络推断中，两个基因之间的高度相关性可能并非源于直接相互作用，而可能是由第三个基因共同调控所致，这便是“混淆”（confounding）问题。为了构建更精确的调控网络，我们必须区分直接和间接关联。本练习将通过计算偏相关性（partial correlation），教您如何从数学上消除混杂变量的影响，并解释其在推断高斯图模型（Gaussian Graphical Models, GGM）结构中的意义 [@problem_id:3331773]。", "problem": "在计算系统生物学中，推断无向基因-基因相互作用网络的一个常用方法是将联合基因表达建模为多元正态分布，并利用条件依赖性来判断高斯图模型（GGM）中是否存在边。考虑三个基因，其中心化的表达变量 $X_{1}$、$X_{2}$ 和 $X_{3}$ 联合服从多元正态分布，协方差矩阵为\n$$\n\\Sigma \\;=\\;\n\\begin{pmatrix}\n2.5  1.2  0.8 \\\\\n1.2  3.0  1.5 \\\\\n0.8  1.5  2.0\n\\end{pmatrix}.\n$$\n仅使用协方差、相关性、条件协方差和精度矩阵（协方差矩阵的逆）的基本定义，计算在给定 $X_{3}$ 的条件下 $X_{1}$ 和 $X_{2}$ 之间的偏相关性。然后，解释在给定 $X_{3}$ 的条件下 $X_{1}$ 和 $X_{2}$ 是否条件独立，并讨论这对于在以 $X_{3}$ 为条件的高斯图模型中 $X_{1}$ 和 $X_{2}$ 之间边的存在与否有何影响。\n\n将偏相关性的最终数值答案表示为保留四位有效数字的小数。该答案是无量纲的，并且必须以单个数字的形式给出，不带任何额外的文本或符号（如百分号）。", "solution": "该问题要求在多元正态分布中，计算两个变量 $X_1$ 和 $X_2$ 在给定第三个变量 $X_3$ 的条件下的偏相关性。然后，使用这个值来推断条件独立性以及相应高斯图模型（GGM）的结构。\n\n变量 $X_1$、$X_2$ 和 $X_3$ 联合服从多元正态分布，其均值向量为 $\\boldsymbol{\\mu} = \\mathbf{0}$（因为它们是中心化的），给定的协方差矩阵 $\\Sigma$ 为：\n$$\n\\Sigma \\;=\\;\n\\begin{pmatrix}\n\\sigma_{11}  \\sigma_{12}  \\sigma_{13} \\\\\n\\sigma_{21}  \\sigma_{22}  \\sigma_{23} \\\\\n\\sigma_{31}  \\sigma_{32}  \\sigma_{33}\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n2.5  1.2  0.8 \\\\\n1.2  3.0  1.5 \\\\\n0.8  1.5  2.0\n\\end{pmatrix}\n$$\n在给定 $X_3$ 的条件下 $X_1$ 和 $X_2$ 之间的偏相关性，记作 $\\rho_{12 \\cdot 3}$，是在回归掉 $X_3$ 的影响后，$X_1$ 和 $X_2$ 的残差之间的相关性。对于多元正态分布，这等价于在给定 $X_3=x_3$ 的条件下 $(X_1, X_2)$ 的条件分布的相关性。这个条件相关性不依赖于 $x_3$ 的值。\n\n我们可以按照题目要求，使用两种基本且等价的方法来计算这个偏相关性。\n\n方法 1：使用条件协方差的定义\n\n偏相关性是标准化的条件协方差：\n$$\n\\rho_{12 \\cdot 3} = \\frac{\\text{Cov}(X_1, X_2 | X_3)}{\\sqrt{\\text{Var}(X_1 | X_3) \\text{Var}(X_2 | X_3)}}\n$$\n此表达式中的各项是在给定 $X_3$ 的条件下 $(X_1, X_2)$ 的条件协方差矩阵的元素。该矩阵可以使用 $\\Sigma$ 中块 $\\Sigma_{33}$ 的舒尔补来计算。我们将协方差矩阵分块如下：\n$$\n\\Sigma = \\begin{pmatrix} \\Sigma_{11}  \\Sigma_{12} \\\\ \\Sigma_{21}  \\Sigma_{22} \\end{pmatrix}\n$$\n其中，对应于我们作为条件的变量 $X_3$ 的块是 $\\Sigma_{22} = \\sigma_{33} = 2.0$。我们感兴趣的变量 $(X_1, X_2)$ 对应的块是 $\\Sigma_{11} = \\begin{pmatrix} 2.5  1.2 \\\\ 1.2  3.0 \\end{pmatrix}$。非对角块是 $\\Sigma_{12} = \\begin{pmatrix} 0.8 \\\\ 1.5 \\end{pmatrix}$ 和 $\\Sigma_{21} = \\begin{pmatrix} 0.8  1.5 \\end{pmatrix}$。\n\n在给定 $X_3$ 的条件下 $(X_1, X_2)$ 的条件协方差矩阵由下式给出：\n$$\n\\Sigma_{(1,2)|3} = \\Sigma_{11} - \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21}\n$$\n代入数值：\n$$\n\\Sigma_{(1,2)|3} = \\begin{pmatrix} 2.5  1.2 \\\\ 1.2  3.0 \\end{pmatrix} - \\begin{pmatrix} 0.8 \\\\ 1.5 \\end{pmatrix} (2.0)^{-1} \\begin{pmatrix} 0.8  1.5 \\end{pmatrix}\n$$\n$$\n\\Sigma_{(1,2)|3} = \\begin{pmatrix} 2.5  1.2 \\\\ 1.2  3.0 \\end{pmatrix} - \\frac{1}{2.0} \\begin{pmatrix} 0.8 \\times 0.8  0.8 \\times 1.5 \\\\ 1.5 \\times 0.8  1.5 \\times 1.5 \\end{pmatrix}\n$$\n$$\n\\Sigma_{(1,2)|3} = \\begin{pmatrix} 2.5  1.2 \\\\ 1.2  3.0 \\end{pmatrix} - 0.5 \\begin{pmatrix} 0.64  1.2 \\\\ 1.2  2.25 \\end{pmatrix}\n$$\n$$\n\\Sigma_{(1,2)|3} = \\begin{pmatrix} 2.5 - 0.32  1.2 - 0.6 \\\\ 1.2 - 0.6  3.0 - 1.125 \\end{pmatrix} = \\begin{pmatrix} 2.18  0.6 \\\\ 0.6  1.875 \\end{pmatrix}\n$$\n从这个矩阵中，我们可以确定：\n$\\text{Var}(X_1 | X_3) = 2.18$\n$\\text{Var}(X_2 | X_3) = 1.875$\n$\\text{Cov}(X_1, X_2 | X_3) = 0.6$\n\n现在，我们计算偏相关性：\n$$\n\\rho_{12 \\cdot 3} = \\frac{0.6}{\\sqrt{2.18 \\times 1.875}} = \\frac{0.6}{\\sqrt{4.0875}} \\approx \\frac{0.6}{2.021756} \\approx 0.296772\n$$\n\n方法 2：使用精度矩阵\n\n精度矩阵 $K$ 是协方差矩阵的逆，即 $K = \\Sigma^{-1}$。对于一个GGM，两个变量 $X_i$ 和 $X_j$ 在给定所有其他变量的条件下是条件独立的，这等价于精度矩阵中对应的元素 $K_{ij}$ 为零。偏相关性 $\\rho_{ij \\cdot \\{rest\\}}$ 与 $K$ 的元素直接相关：\n$$\n\\rho_{ij \\cdot \\{rest\\}} = -\\frac{K_{ij}}{\\sqrt{K_{ii}K_{jj}}}\n$$\n在我们的三变量情况下，对于变量对 $(1,2)$，$\\{rest\\}$ 就是 $\\{3\\}$，所以公式为 $\\rho_{12 \\cdot 3} = -K_{12}/\\sqrt{K_{11}K_{22}}$。\n\n首先，我们计算 $K = \\Sigma^{-1}$。逆矩阵由公式 $K = \\frac{1}{\\det(\\Sigma)} \\text{adj}(\\Sigma)$ 给出。\n$\\Sigma$ 的行列式是：\n$$\n\\det(\\Sigma) = 2.5(3.0 \\times 2.0 - 1.5 \\times 1.5) - 1.2(1.2 \\times 2.0 - 1.5 \\times 0.8) + 0.8(1.2 \\times 1.5 - 3.0 \\times 0.8)\n$$\n$$\n\\det(\\Sigma) = 2.5(6.0 - 2.25) - 1.2(2.4 - 1.2) + 0.8(1.8 - 2.4)\n$$\n$$\n\\det(\\Sigma) = 2.5(3.75) - 1.2(1.2) + 0.8(-0.6) = 9.375 - 1.44 - 0.48 = 7.455\n$$\n伴随矩阵 $\\text{adj}(\\Sigma)$ 是代数余子式矩阵的转置。由于 $\\Sigma$ 是对称的，其代数余子式矩阵也是对称的，因此 $\\text{adj}(\\Sigma)$ 就是代数余子式矩阵本身。\n$$\nC_{11} = (3.0 \\times 2.0 - 1.5 \\times 1.5) = 3.75\n$$\n$$\nC_{22} = (2.5 \\times 2.0 - 0.8 \\times 0.8) = 4.36\n$$\n$$\nC_{12} = -(1.2 \\times 2.0 - 1.5 \\times 0.8) = -(2.4 - 1.2) = -1.2\n$$\n精度矩阵为：\n$$\nK = \\frac{1}{7.455}\n\\begin{pmatrix}\n3.75  -1.2  \\dots \\\\\n-1.2  4.36  \\dots \\\\\n\\dots  \\dots  \\dots\n\\end{pmatrix}\n$$\n在我们的计算中，我们只需要左上角的 $2 \\times 2$ 块的元素。\n使用偏相关性的公式：\n$$\n\\rho_{12 \\cdot 3} = -\\frac{K_{12}}{\\sqrt{K_{11}K_{22}}} = -\\frac{-1.2/7.455}{\\sqrt{(3.75/7.455)(4.36/7.455)}} = -\\frac{-1.2}{\\sqrt{3.75 \\times 4.36}}\n$$\n$$\n\\rho_{12 \\cdot 3} = \\frac{1.2}{\\sqrt{16.35}} \\approx \\frac{1.2}{4.043513} \\approx 0.296772\n$$\n两种方法得出了相同的结果，证实了计算的正确性。四舍五入到四位有效数字，偏相关性为 $0.2968$。\n\n解释：\n\n1.  条件独立性：对于多元正态分布，两个变量在给定一组其他变量的条件下是条件独立的，当且仅当它们的偏相关性为零。在这里，我们计算出 $\\rho_{12 \\cdot 3} \\approx 0.2968$。由于这个值非零，因此在给定 $X_3$ 的条件下，$X_1$ 和 $X_2$ **不是**条件独立的。这意味着即使在考虑了基因 $X_3$ 对 $X_1$ 和 $X_2$ 的线性影响之后，它们之间仍然存在残余的相关性。\n\n2.  对 GGM 的影响：在高斯图模型的背景下，两个节点 $i$ 和 $j$ 之间存在一条边，当且仅当变量 $X_i$ 和 $X_j$ 在给定模型中所有其他变量的条件下不是条件独立的。这等价于条件 $K_{ij} \\neq 0$。正如我们所发现的，$\\rho_{12 \\cdot 3} \\neq 0$，这意味着 $K_{12} \\neq 0$。因此，在由这三个变量构建的 GGM 中，代表基因 $X_1$ 和基因 $X_2$ 的节点之间**存在**一条边。这条边表示一种不能被通过 $X_3$ 的路径完全解释的直接关系（或相互作用）。", "answer": "$$\n\\boxed{0.2968}\n$$", "id": "3331773"}, {"introduction": "从高通量数据构建全基因组范围的网络，意味着要进行成千上万次统计检验，这带来了两大挑战：如何确定单个关联的显著性，以及如何对多重检验进行校正以控制错误。本编程练习将指导您完成一个从原始数据到最终网络的完整推断流程。您将亲手实现基于置换检验（permutation testing）的$p$值计算，并应用Benjamini-Hochberg程序来控制伪发现率（False Discovery Rate, FDR），从而将理论知识转化为实用的计算技能 [@problem_id:3331730]。", "problem": "考虑一个由 $n$ 个样本和 $p$ 个基因组成的基因表达数据集，表示为一个矩阵。目标是通过检验成对独立性来推断基因间的无向网络，如果基因 $i$ 和基因 $j$ 之间的独立性原假设被拒绝，则声明它们之间存在一条边。网络推断应基于以下基础：\n\n1. 两个基因 $i$ 和 $j$ 之间的皮尔逊积矩相关系数在标准化数据上定义为其线性关联的样本统计量。\n2. 在两个基因独立的零假设下，一个基因的样本标签是可交换的。可以通过随机置换一个基因的样本标签并重新计算相关性来构建基于置换的零模型。\n3. 每个成对检验的 $p$ 值应定义为在零模型下，观察到至少与观测统计量一样极端的检验统计量的概率。\n4. 当同时检验多个假设时，错误发现率（FDR）是所有拒绝假设中错误拒绝的预期比例。Benjamini–Hochberg 程序是一种在指定水平 $\\alpha$ 下控制 FDR 的方法。\n\n你的任务是实现一个程序，从第一性原理出发执行以下步骤：\n\n- 使用两个变量之间皮尔逊相关系数的定义，计算每对基因的观测绝对相关性。\n- 通过将一个基因的样本标签置换 $B$ 次来为每对基因构建一个基于置换的零模型，同时保持每个基因的边缘分布。使用这些置换来近似独立性假设下绝对相关性的零分布。\n- 将每对基因的 $p$ 值定义为零分布超过或等于观测绝对相关性的尾部概率。在离散置换设置中使用有限样本调整以避免零 $p$ 值。\n- 从错误发现率的定义和原假设下有效 $p$ 值的顺序统计量性质出发，推导 Benjamini–Hochberg 程序，以确定在名义 FDR 水平 $\\alpha$ 下拒绝哪些假设。\n- 通过将被拒绝的假设与已知的真实相关基因对的基准真相集进行比较，评估推断网络的经验错误发现比例。\n\n使用以下测试套件。对于每个测试用例，按如下方式模拟基因表达数据：生成一个 $n \\times p$ 的标准正态随机变量矩阵。对于每个植入的边 $(i,j,\\rho)$，将基因 $j$ 的表达重写为 $x_j = \\rho \\, x_i + \\sqrt{1 - \\rho^2} \\, \\epsilon_j$，其中 $\\epsilon_j$ 是一个独立的标准正态向量，使得 $i$ 和 $j$ 之间的总体相关性约为 $\\rho$。假设植入的边之间的索引是不同的。基因索引使用基于 0 的索引。\n\n- 测试用例 1（一般情况）：$p=20$，$n=60$，$B=200$，$\\alpha=0.1$，随机种子 $7$，植入的边\n  $(0,1,0.8)$, $(2,3,0.7)$, $(4,5,0.75)$, $(6,7,0.6)$, $(8,9,0.65)$。\n- 测试用例 2（全零假设边情况）：$p=15$，$n=50$，$B=200$，$\\alpha=0.1$，随机种子 $13$，无植入边。\n- 测试用例 3（混合效应大小的边界情况）：$p=18$，$n=40$，$B=300$，$\\alpha=0.05$，随机种子 $29$，植入的边\n  中等 $(0,10,0.5)$, $(1,11,0.5)$, $(2,12,0.5)$, $(3,13,0.5)$ 和弱 $(4,14,0.3)$, $(5,15,0.3)$, $(6,16,0.3)$, $(7,17,0.3)$。\n\n需要遵守的实现细节：\n\n- 使用带有样本标准差的标准化变量计算样本皮尔逊相关系数。\n- 对于每对 $(i,j)$，通过将 $j$ 的样本标签精确置换 $B$ 次来近似零分布，每次置换后重新计算绝对相关性，并将 $p$ 值计算为 $(1 + \\text{大于或等于观测绝对相关性的置换绝对相关性数量}) / (1 + B)$。\n- 应用从错误发现率定义推导出的 Benjamini–Hochberg 程序，在每个测试用例的总检验次数 $m = p(p-1)/2$ 中，选择在水平 $\\alpha$ 下的显著基因对。\n\n最终输出规范：\n\n- 对于每个测试用例，计算两个量：被拒绝假设的总数（一个整数）和经验错误发现比例，定义为不在植入边集合中的被拒绝假设数除以被拒绝假设总数，规定当没有拒绝时比例为 $0$。将该比例表示为小数，而非百分比。\n- 你的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表的结果，其中每个测试用例的结果是一个形式为 $[D, F]$ 的双元素列表，$D$ 是拒绝的整数数量，$F$ 是小数形式的经验错误发现比例。例如，输出格式应类似于 $[[D_1,F_1],[D_2,F_2],[D_3,F_3]]$。", "solution": "目标是通过使用皮尔逊相关系数和基于置换的零模型检验每对基因的独立性原假设，来推断基因共表达网络中的边，并使用 Benjamini–Hochberg 程序控制错误发现率。\n\n基本基础和定义：\n\n1. 设 $X \\in \\mathbb{R}^{n \\times p}$ 为包含 $n$ 个样本和 $p$ 个基因的基因表达矩阵。对于基因 $i$ 和基因 $j$，样本向量表示为 $(x_{1i}, \\ldots, x_{ni})$ 和 $(x_{1j}, \\ldots, x_{nj})$。基因 $i$ 的样本均值为 $\\bar{x}_i = \\frac{1}{n} \\sum_{t=1}^n x_{ti}$，样本标准差为 $s_i = \\sqrt{\\frac{1}{n-1} \\sum_{t=1}^n (x_{ti} - \\bar{x}_i)^2}$。标准化变量为 $z_{ti} = \\frac{x_{ti} - \\bar{x}_i}{s_i}$，对 $j$ 也类似。\n2. 基因 $i$ 和 $j$ 之间的皮尔逊积矩相关系数为\n$$\nr_{ij} = \\frac{1}{n-1} \\sum_{t=1}^n z_{ti} z_{tj}.\n$$\n我们使用观测到的绝对相关性 $|r_{ij}|$ 作为双边独立性检验的检验统计量。\n3. 在基因 $i$ 和 $j$ 独立的零假设 $H_{0,ij}$ 下，当样本独立同分布时，$(x_{ti}, x_{tj})$ 的联合分布对其中一个基因的样本标签表现出可交换性。具体来说，置换基因 $j$ 的样本标签会产生与 $H_{0,ij}$ 一致的实现，同时保持 $x_{tj}$ 的边缘分布。当解析形式不便或未知时，这是一种经过充分检验的构建非参数零分布的方法。\n4. 对 $H_{0,ij}$ 的检验的 $p$ 值定义为，在零模型下，观察到至少与观测统计量一样极端的检验统计量的概率。在有 $B$ 次置换的置换设置中，带有有限样本校正的经验 $p$ 值为\n$$\np_{ij} = \\frac{1 + \\sum_{b=1}^B \\mathbf{1}\\left\\{ \\left|r_{ij}^{(b)}\\right| \\ge \\left|r_{ij}\\right| \\right\\}}{1 + B},\n$$\n其中 $r_{ij}^{(b)}$ 是根据第 $b$ 次置换对基因 $j$ 的样本标签进行置换后计算出的相关性。分子加 $1$ 和分母加 $1$ 是为了避免因离散性而产生的零值。\n5. 当同时检验 $m$ 个假设时，错误发现率（FDR）定义为\n$$\n\\mathrm{FDR} = \\mathbb{E}\\left[ \\frac{V}{R \\vee 1} \\right],\n$$\n其中 $V$ 是错误拒绝的数量，$R$ 是总拒绝数量，而 $R \\vee 1$ 表示 $\\max(R, 1)$ 以避免除以零。在 $H_0$ 下，一个有效的 $p$ 值在随机意义上大于或等于一个 Uniform$(0,1)$ 随机变量；在 $p$ 值独立或存在某些正相关形式的情况下，可以使用 $p$ 值的排序来设定拒绝阈值以控制 FDR。\n\nBenjamini–Hochberg 程序的推导：\n\n从 FDR 的定义和在 $H_0$ 下有效 $p$ 值是超均匀分布的性质出发，考虑将计算出的 $m$ 个 $p$ 值排序为 $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$，其对应的索引为 $(i_{(1)}, j_{(1)}), \\ldots, (i_{(m)}, j_{(m)})$。在独立性假设下，如果我们选择一个按 $\\frac{\\alpha k}{m}$ 比例缩放的阈值，那么前 $k$ 个有序 $p$ 值中的预期错误发现数量约为 $\\alpha k$，因为一个零假设下的 $p$ 值低于阈值 $t$ 的概率至多为 $t$。为确保错误拒绝与总拒绝的比例在期望上受 $\\alpha$ 的限制，我们选择满足以下条件的最大索引 $k$\n$$\np_{(k)} \\le \\frac{\\alpha k}{m}.\n$$\n然后，拒绝所有对应于 $p_{(1)}, \\ldots, p_{(k)}$ 的假设。这种自适应阈值方法在 $p$ 值上设置了一个数据驱动的截断点，它补偿了多重性 $m$ 和秩 $k$，在独立性或某些正相关结构下，将期望比率 $V / (R \\vee 1)$ 控制在水平 $\\alpha$。这就是 Benjamini–Hochberg 程序。\n\n整合原理的算法设计：\n\n- 使用样本均值和样本标准差对每个基因的样本进行标准化，以获得每个基因 $i$ 的 $z_{ti}$。\n- 对于每对满足 $i  j$ 的 $(i,j)$，使用标准化变量和样本相关性公式计算观测到的绝对相关性 $|r_{ij}|$。共有 $m = \\frac{p(p-1)}{2}$ 对这样的基因对。\n- 构建基于置换的零分布：生成 $B$ 个样本索引的随机置换。对于每次置换，重新排列基因 $j$ 的标准化向量，并重新计算其与基因 $i$ 的绝对相关性。收集 $B$ 个置换后的绝对相关性，并使用上面指定的有限样本校正计算置换 $p$ 值。\n- 收集所有基因对的 $m$ 个 $p$ 值，并应用推导出的 Benjamini–Hochberg 程序：对 $p$ 值进行排序，找到满足上述不等式的最大 $k$，并拒绝所有 $p$ 值小于或等于自适应阈值 $\\frac{\\alpha k}{m}$ 的假设。如果不存在这样的 $k$，则不拒绝任何假设。\n- 在每个测试用例中，使用已知的植入边，计算经验错误发现比例，公式为 $V / (R \\vee 1)$，其中 $V$ 是不在植入集合中的被拒绝基因对数量，$R$ 是被拒绝基因对的总数。\n- 将测试套件的结果汇总到一个列表中，形式为 $[[D_1,F_1],[D_2,F_2],[D_3,F_3]]$，其中 $D_c$ 是拒绝的数量，$F_c$ 是测试用例 $c$ 的经验错误发现比例。该比例应表示为小数。\n\n该解决方案具有科学依据：皮尔逊相关性量化了线性关联；基于置换的零模型依赖于独立性下的可交换性，这是一种经过充分检验的非参数方法；而 Benjamani-Hochberg 程序源自 FDR 的定义和有效 $p$ 值的顺序统计量，在标准条件下提供了对错误发现率在水平 $\\alpha$ 的控制。虽然互信息为计算系统生物学中的非线性依赖性提供了一个补充度量，但本问题专注于基于置换的相关性推断，以与指定的缩略图保持一致，并从所呈现的基础定义中保持清晰的推导。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef simulate_data(p, n, planted_edges, seed):\n    \"\"\"\n    Simulate gene expression data with planted correlated edges.\n    Args:\n        p (int): number of genes\n        n (int): number of samples\n        planted_edges (list of tuples): [(i, j, rho), ...] with 0-based indices and correlation strength rho\n        seed (int): random seed\n    Returns:\n        X (np.ndarray): n x p data matrix\n        true_edges_set (set): set of (min(i,j), max(i,j)) tuples representing true correlated pairs\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    X = rng.standard_normal((n, p))\n    true_edges_set = set()\n    for (i, j, rho) in planted_edges:\n        # Ensure distinct indices and valid rho\n        assert 0 = i  p and 0 = j  p and i != j\n        assert 0.0 = rho = 1.0\n        # Overwrite gene j to be correlated with gene i\n        eps = rng.standard_normal(n)\n        X[:, j] = rho * X[:, i] + np.sqrt(1.0 - rho**2) * eps\n        a, b = (i, j) if i  j else (j, i)\n        true_edges_set.add((a, b))\n    return X, true_edges_set\n\ndef standardize_columns(X):\n    \"\"\"\n    Standardize each column to zero mean and unit sample standard deviation.\n    \"\"\"\n    X_centered = X - X.mean(axis=0, keepdims=True)\n    std = X_centered.std(axis=0, ddof=1, keepdims=True)\n    # Avoid division by zero: add tiny epsilon if needed\n    std = np.where(std == 0, 1.0, std)\n    X_std = X_centered / std\n    return X_std\n\ndef permutation_pvalues(X_std, B, seed):\n    \"\"\"\n    Compute permutation-based p-values for absolute Pearson correlations for all pairs.\n    Args:\n        X_std (np.ndarray): n x p standardized data\n        B (int): number of permutations\n        seed (int): random seed for permutations\n    Returns:\n        pvals (np.ndarray): array of length m with p-values\n        pairs (list): list of (i, j) pairs in the same order as pvals\n        obs_abs_corrs (np.ndarray): observed absolute correlations for each pair\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    n, p = X_std.shape\n    pairs = [(i, j) for i in range(p) for j in range(i + 1, p)]\n    m = len(pairs)\n\n    # Precompute B permutations of indices\n    perms = np.array([rng.permutation(n) for _ in range(B)], dtype=np.int64)\n\n    pvals = np.empty(m, dtype=float)\n    obs_abs_corrs = np.empty(m, dtype=float)\n    denom = float(n - 1)\n\n    # Compute p-values for each pair\n    for idx, (i, j) in enumerate(pairs):\n        xi = X_std[:, i]\n        yj = X_std[:, j]\n        # Observed absolute correlation\n        obs = abs(np.dot(xi, yj) / denom)\n        obs_abs_corrs[idx] = obs\n        # Permuted correlations: permute yj by each permutation\n        # Vectorized: build matrix of shape (B, n) for yj permuted, then dot with xi\n        yj_perm = yj[perms]  # shape (B, n)\n        perm_corrs = (yj_perm @ xi) / denom  # shape (B,)\n        perm_abs = np.abs(perm_corrs)\n        count_ge = np.sum(perm_abs >= obs)\n        # Finite-sample correction to avoid zero p-values\n        pval = (count_ge + 1.0) / (B + 1.0)\n        pvals[idx] = pval\n\n    return pvals, pairs, obs_abs_corrs\n\ndef benjamini_hochberg(pvals, alpha):\n    \"\"\"\n    Apply the Benjamini–Hochberg procedure to control FDR at level alpha.\n    Args:\n        pvals (np.ndarray): p-values of length m\n        alpha (float): target FDR level\n    Returns:\n        reject_indices (np.ndarray): indices (into pvals) of rejected hypotheses\n        threshold (float): BH threshold used (0 if no rejections)\n    \"\"\"\n    m = pvals.size\n    order = np.argsort(pvals)\n    p_sorted = pvals[order]\n    ranks = np.arange(1, m + 1, dtype=float)\n    thresholds = (ranks / m) * alpha\n    # Find largest k such that p_(k) = (k/m)*alpha\n    valid = np.where(p_sorted = thresholds)[0]\n    if valid.size == 0:\n        return np.array([], dtype=int), 0.0\n    k_idx = valid.max()\n    bh_threshold = p_sorted[k_idx]\n    reject_mask = pvals = bh_threshold\n    reject_indices = np.where(reject_mask)[0]\n    return reject_indices, bh_threshold\n\ndef evaluate_fdp(rejected_pairs, true_edges_set):\n    \"\"\"\n    Compute number of rejections and empirical false discovery proportion (FDP).\n    Args:\n        rejected_pairs (list of tuples): list of (i, j) for rejected hypotheses\n        true_edges_set (set of tuples): ground-truth correlated edges\n    Returns:\n        D (int): total number of rejections\n        fdp (float): false discovery proportion (0.0 if D == 0)\n    \"\"\"\n    D = len(rejected_pairs)\n    if D == 0:\n        return 0, 0.0\n    rejected_set = set((min(i, j), max(i, j)) for (i, j) in rejected_pairs)\n    false_discoveries = len(rejected_set - true_edges_set)\n    fdp = false_discoveries / D\n    return D, fdp\n\ndef run_test_case(p, n, B, alpha, seed, planted_edges):\n    \"\"\"\n    Execute the full pipeline for one test case.\n    Returns:\n        [D, fdp] for the test case.\n    \"\"\"\n    X, true_edges_set = simulate_data(p, n, planted_edges, seed)\n    X_std = standardize_columns(X)\n    pvals, pairs, _ = permutation_pvalues(X_std, B, seed + 12345)  # separate seed for permutations\n    reject_indices, _ = benjamini_hochberg(pvals, alpha)\n    rejected_pairs = [pairs[idx] for idx in reject_indices]\n    D, fdp = evaluate_fdp(rejected_pairs, true_edges_set)\n    return [int(D), float(fdp)]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1: p=20, n=60, B=200, alpha=0.1, seed=7, planted edges given\n        {\n            \"p\": 20, \"n\": 60, \"B\": 200, \"alpha\": 0.1, \"seed\": 7,\n            \"planted_edges\": [(0, 1, 0.8), (2, 3, 0.7), (4, 5, 0.75), (6, 7, 0.6), (8, 9, 0.65)]\n        },\n        # Test case 2: p=15, n=50, B=200, alpha=0.1, seed=13, no planted edges\n        {\n            \"p\": 15, \"n\": 50, \"B\": 200, \"alpha\": 0.1, \"seed\": 13,\n            \"planted_edges\": []\n        },\n        # Test case 3: p=18, n=40, B=300, alpha=0.05, seed=29, mixed effect sizes\n        {\n            \"p\": 18, \"n\": 40, \"B\": 300, \"alpha\": 0.05, \"seed\": 29,\n            \"planted_edges\": [\n                (0, 10, 0.5), (1, 11, 0.5), (2, 12, 0.5), (3, 13, 0.5),\n                (4, 14, 0.3), (5, 15, 0.3), (6, 16, 0.3), (7, 17, 0.3)\n            ]\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(case[\"p\"], case[\"n\"], case[\"B\"], case[\"alpha\"], case[\"seed\"], case[\"planted_edges\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3331730"}]}