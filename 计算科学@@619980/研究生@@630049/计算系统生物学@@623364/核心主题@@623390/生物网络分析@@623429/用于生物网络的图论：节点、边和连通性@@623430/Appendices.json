{"hands_on_practices": [{"introduction": "理解生物网络的韧性通常始于分析其结构冗余度。本练习将生成树概念作为维持网络连通性的最小骨架引入。你将应用优美的矩阵树定理，通过连接图拓扑与线性代数，来计算一个蛋白质相互作用网络中所有可能的生成树数量，从而为其结构鲁棒性提供一个量化指标 [@problem_id:3317542]。", "problem": "一个经过整理的酵母蛋白质-蛋白质相互作用（PPI）网络被建模为一个简单、无向、无权图，其节点集为 $\\{P_1,P_2,P_3,P_4,P_5\\}$（代表蛋白质），边集代表有实验支持的相互作用。该网络是连通的，并具有以下无向边：\n$$(P_1,P_2),\\ (P_2,P_3),\\ (P_3,P_4),\\ (P_4,P_1),\\ (P_2,P_5),\\ (P_3,P_5)。$$\n将该网络视为一个图，其邻接矩阵为 $\\mathbf{A}$，度矩阵为 $\\mathbf{D}$，组合拉普拉斯矩阵为 $\\mathbf{L}=\\mathbf{D}-\\mathbf{A}$：\n\n- 在无向图的背景下，使用 $\\mathbf{L}$ 的一个代数余子式来陈述矩阵树定理。\n- 根据基本原理，使用度和邻接的定义，为该网络构建矩阵 $\\mathbf{A}$、$\\mathbf{D}$，并由此得到 $\\mathbf{L}$。\n- 使用该定理，通过计算 $\\mathbf{L}$ 的任意一个代数余子式（即通过从 $\\mathbf{L}$ 中删除任意一行及对应列得到的 $(n-1)\\times(n-1)$ 主子式的行列式）来计算该网络的生成树数量。展示你使用有效的线性代数运算计算行列式的中间步骤。\n\n请以单个精确整数的形式提供你的最终答案。无需进行四舍五入。", "solution": "该问题是有效的，因为它在科学上基于标准的图论，问题设定良好，给出了清晰而完整的已知条件，并且其表述是客观的。它要求将矩阵树定理直接应用于一个明确定义的图，这是分析生物网络的标准程序。\n\n该问题需要一个包含三部分的解答：陈述矩阵树定理，构建图的拉普拉斯矩阵，以及使用该定理计算生成树的数量。\n\n**第一部分：矩阵树定理**\n\n矩阵树定理指出，对于一个有 $n$ 个顶点的连通无向图 $G$，其不同生成树的总数（记为 $\\tau(G)$）等于该图的组合拉普拉斯矩阵 $\\mathbf{L}$ 的任意一个代数余子式。组合拉普拉斯矩阵定义为 $\\mathbf{L} = \\mathbf{D} - \\mathbf{A}$，其中 $\\mathbf{D}$ 是度矩阵，$\\mathbf{A}$ 是图 $G$ 的邻接矩阵。\n\n$\\mathbf{L}$ 的所有代数余子式都相等。$\\mathbf{L}$ 的一个代数余子式 $C_{ij}$ 由 $C_{ij} = (-1)^{i+j} \\det(\\mathbf{L}_{ij})$ 给出，其中 $\\mathbf{L}_{ij}$ 是从 $\\mathbf{L}$ 中删除第 $i$ 行和第 $j$ 列得到的子矩阵。该定理意味着 $\\tau(G)$ 可以通过计算 $\\mathbf{L}$ 的任意一个主子式（principal minor）的行列式来得到，该主子式是一个子矩阵 $\\mathbf{L}_{ii}$，通过移除任意单一行 $i$ 及其对应的列 $i$ 形成。\n因此，对于任意 $i \\in \\{1, 2, ..., n\\}$，有 $\\tau(G) = \\det(\\mathbf{L}_{ii})$。\n\n**第二部分：矩阵 $\\mathbf{A}$、$\\mathbf{D}$ 和 $\\mathbf{L}$ 的构建**\n\n该网络的节点集为 $V = \\{P_1, P_2, P_3, P_4, P_5\\}$，因此 $n=5$。矩阵的尺寸将是 $5 \\times 5$，其行和列根据蛋白质的索引排序。边集为 $E = \\{(P_1, P_2), (P_2, P_3), (P_3, P_4), (P_4, P_1), (P_2, P_5), (P_3, P_5)\\}$。\n\n首先，我们构建邻接矩阵 $\\mathbf{A}$，其中，如果节点 $i$ 和节点 $j$ 之间存在边，则 $A_{ij} = 1$，否则 $A_{ij} = 0$。\n$$\n\\mathbf{A} = \\begin{pmatrix}\n0  1  0  1  0 \\\\\n1  0  1  0  1 \\\\\n0  1  0  1  1 \\\\\n1  0  1  0  0 \\\\\n0  1  1  0  0\n\\end{pmatrix}\n$$\n接下来，我们确定每个节点的度，即与该节点相连的边的数量。\n$\\deg(P_1) = 2$\n$\\deg(P_2) = 3$\n$\\deg(P_3) = 3$\n$\\deg(P_4) = 2$\n$\\deg(P_5) = 2$\n\n度矩阵 $\\mathbf{D}$ 是一个对角矩阵，其对角线上的元素是这些节点的度。\n$$\n\\mathbf{D} = \\begin{pmatrix}\n2  0  0  0  0 \\\\\n0  3  0  0  0 \\\\\n0  0  3  0  0 \\\\\n0  0  0  2  0 \\\\\n0  0  0  0  2\n\\end{pmatrix}\n$$\n组合拉普拉斯矩阵 $\\mathbf{L}$ 通过 $\\mathbf{L} = \\mathbf{D} - \\mathbf{A}$ 计算得出。\n$$\n\\mathbf{L} = \\begin{pmatrix}\n 2  -1   0  -1   0 \\\\\n-1   3  -1   0  -1 \\\\\n 0  -1   3  -1  -1 \\\\\n-1   0  -1   2   0 \\\\\n 0  -1  -1   0   2\n\\end{pmatrix}\n$$\n\n**第三部分：生成树数量的计算**\n\n根据矩阵树定理，我们可以通过计算 $\\mathbf{L}$ 的任意一个 $(n-1) \\times (n-1)$ 主子式的行列式来计算生成树的数量 $\\tau(G)$。我们选择移除最后一行和最后一列（第5行和第5列）。得到的子矩阵 $\\mathbf{L}_{55}$ 为：\n$$\n\\mathbf{L}_{55} = \\begin{pmatrix}\n 2  -1   0  -1 \\\\\n-1   3  -1   0 \\\\\n 0  -1   3  -1 \\\\\n-1   0  -1   2\n\\end{pmatrix}\n$$\n现在我们使用沿第一行的代数余子式展开来计算这个 $4 \\times 4$ 矩阵的行列式。\n$$\n\\det(\\mathbf{L}_{55}) = 2 \\det \\begin{pmatrix} 3  -1  0 \\\\ -1  3  -1 \\\\ 0  -1  2 \\end{pmatrix} - (-1) \\det \\begin{pmatrix} -1  -1  0 \\\\ 0  3  -1 \\\\ -1  -1  2 \\end{pmatrix} + 0 \\cdot (...) - (-1) \\det \\begin{pmatrix} -1  3  -1 \\\\ 0  -1  3 \\\\ -1  0  -1 \\end{pmatrix}\n$$\n我们分别计算每个 $3 \\times 3$ 行列式。\n\n行列式 $M_1$：\n$$\nM_1 = \\det \\begin{pmatrix} 3  -1  0 \\\\ -1  3  -1 \\\\ 0  -1  2 \\end{pmatrix} = 3(3 \\cdot 2 - (-1)(-1)) - (-1)((-1) \\cdot 2 - (-1) \\cdot 0) + 0 = 3(6-1) + 1(-2) = 15 - 2 = 13\n$$\n\n行列式 $M_2$：\n$$\nM_2 = \\det \\begin{pmatrix} -1  -1  0 \\\\ 0  3  -1 \\\\ -1  -1  2 \\end{pmatrix} = -1(3 \\cdot 2 - (-1)(-1)) - (-1)(0 \\cdot 2 - (-1)(-1)) + 0 = -1(6-1) + 1(0-1) = -5 - 1 = -6\n$$\n\n行列式 $M_3$：\n$$\nM_3 = \\det \\begin{pmatrix} -1  3  -1 \\\\ 0  -1  3 \\\\ -1  0  -1 \\end{pmatrix} = -1((-1)(-1) - 3 \\cdot 0) - 3(0 \\cdot (-1) - 3(-1)) + (-1)(0 \\cdot 0 - (-1)(-1)) = -1(1) - 3(3) - 1(-1) = -1 - 9 + 1 = -9\n$$\n\n将这些值代回到 $\\det(\\mathbf{L}_{55})$ 的表达式中：\n$$\n\\det(\\mathbf{L}_{55}) = 2(13) + (-6) + (-9) = 26 - 6 - 9 = 26 - 15 = 11\n$$\n因此，给定PPI网络中的生成树数量为 $11$。", "answer": "$$\\boxed{11}$$", "id": "3317542"}, {"introduction": "在系统生物学中，依据观测属性来构建网络与分析现有网络同等重要。本实践旨在探索局部特征（即每个节点的度）与全局网络结构之间的联系。你将首先判断一个给定的度序列是否可以实现为一个简单图，然后运用配置模型（Configuration Model）生成一个网络实例，从而研究局部度约束如何塑造全局连通性 [@problem_id:3317546]。", "problem": "您正在研究度约束如何在无向生物相互作用网络中塑造连通性，这些网络被建模为图，其中实体是节点，相互作用是边。设度序列为一个非负整数的有限列表 $d = (d_1,\\dots,d_n)$，其中 $d_i$ 是一个包含 $n$ 个节点的无向图中节点 $i$ 的度。本问题中的任务是判断给定的度序列是否可由某个简单无向图实现（即可图化），使用配置模型 (CM) 构建一个度保持的随机样本，并评估反映 $d$ 影响的连通性属性。\n\n基础知识：\n- 一个包含 $n$ 个节点的简单无向图没有自环，也没有平行边。节点 $i$ 的度是其不同邻居的数量。\n- 握手引理指出 $\\sum_{i=1}^n d_i$ 是偶数。\n- Erdős–Gallai 准则是一个非增度序列可图化的充分必要条件。\n- 配置模型 (CM) 通过在每个节点 $i$ 创建 $d_i$ 个末端，然后将所有末端均匀随机地配对成边来构建一个具有给定度序列的随机多重图，该过程允许自环和平行边。\n- Molloy–Reed 条件基于度序列的一阶和二阶阶乘矩之间的关系，预测了在 CM 的大 $n$ 极限下巨连通分量的出现。\n\n您的程序必须对每个提供的度序列 $d$ 完成以下任务：\n1. 使用 Erdős–Gallai 准则判断 $d$ 是否可图化。您必须仅依赖上述基本定义，而不查找任何超出这些原则的专门快捷公式。\n2. 如果 $d$ 是可图化的，通过均匀配对末端来构建一个配置模型 (CM) 的实现。将结果视为一个无向多重图。为了进行连通性分析，在形成您要分析的底层简单图时，需合并平行边（即将它们视为单一边）并忽略自环。对于从 $0$ 开始的测试用例索引 $i$，使用等于 $2025 + i$ 的固定伪随机种子以确保可复现性。\n3. 计算：\n   - 底层简单图中的连通分量数量，一个整数。\n   - 最大连通分量 (LCC) 中的节点比例（LCC 比例），定义为 $\\lvert \\text{LCC} \\rvert / n$。将此值四舍五入到 $6$ 位小数。\n4. 独立于可实现性，根据 Molloy–Reed (MR) 巨分量条件，评估度约束是否预示着在大 $n$ 极限下存在一个巨分量。返回一个布尔指示符，如果条件预测存在巨分量，则为 $\\mathrm{True}$，否则为 $\\mathrm{False}$。\n\n边界情况处理：\n- 如果 $d$ 不可图化，则跳过 CM 构建和连通性分析。在这种情况下，输出的连通分量数量为 $-1$，LCC 比例为 $-1.000000$。\n- 所有输出都必须是无单位的。\n\n测试套件：\n按指定顺序使用以下度序列。每个序列以整数列表的形式提供。\n- 案例 $0$：$[3,3,2,2,2,2,1,1,1,1]$\n- 案例 $1$：$[4,1,1,1]$\n- 案例 $2$：$[0,0,0,0,0]$\n- 案例 $3$：$[4,1,1,1,1]$\n- 案例 $4$：$[2,2,2,2,2,2]$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个元素按顺序对应一个测试用例。每个测试用例的结果本身必须是一个形如 $[G,C,L,M]$ 的列表，其中 $G$ 是表示可图化的布尔值， $C$ 是连通分量的数量（如果跳过则为 $-1$）的整数， $L$ 是四舍五入到 $6$ 位小数的 LCC 比例（如果跳过则为 $-1.000000$）， $M$ 是 Molloy–Reed 指示符的布尔值。\n- 因此，最终输出的结构形式为 $[[G_0,C_0,L_0,M_0],[G_1,C_1,L_1,M_1],\\dots,[G_4,C_4,L_4,M_4]]$，在单行内，无额外文本。", "solution": "该问题已被验证为具有科学依据、提法明确且内容完整。它要求实现图论中应用于网络科学的几个基本算法和概念。解决方案通过为每个给定的度序列系统地处理四个指定的任务来进行。\n\n对于每个度序列 $d=(d_1, \\dots, d_n)$ 的总体流程如下：\n$1$. 评估 Molloy-Reed 巨分量条件。此项独立于可图性。\n$2$. 使用 Erdős–Gallai 定理测试度序列的可图性。\n$3$. 如果序列是可图化的，则使用指定的、可复现的种子，通过配置模型 (CM) 构建一个随机图。然后计算其底层简单图的连通分量数量和最大连通分量 (LCC) 中的节点比例。\n$4$. 如果序列不可图化，则跳过构建和连通性分析，并对连通分量数量和 LCC 比例使用占位符值 $-1$ 和 $-1.000000$。\n$5$. 将这些步骤的结果编译成指定的输出格式。\n\n**任务 1：Molloy–Reed 巨分量条件**\n\nMolloy–Reed 条件为配置模型在 $n \\to \\infty$ 极限下生成的随机图中是否存在巨连通分量提供了预测。该条件指出，如果以下不等式成立，则预期会出现巨分量：\n$$ \\sum_{i=1}^n d_i(d_i - 2) > 0 $$\n其中 $d_i$ 是节点 $i$ 的度。该准则源于对图上分支过程的分析，并与度分布的一阶矩和二阶矩有关。具体来说，它等效于这样一个条件：沿着一条随机边到达的节点的预期第二代邻居数量大于 $1$。对于每个度序列，我们计算这个总和。如果总和为正，则结果 $M$ 为 $\\mathrm{True}$，否则为 $\\mathrm{False}$。\n\n**任务 2：可图性测试 (Erdős–Gallai 定理)**\n\n如果存在一个具有度序列 $d$ 的简单无向图，则该序列是可图化的。Erdős–Gallai 定理给出了一个序列可图化的充分必要条件。对于一个非负整数的非增序列 $d_1 \\ge d_2 \\ge \\dots \\ge d_n$，它是可图化的当且仅当满足两个条件：\n$1$. 度数之和必须为偶数：$\\sum_{i=1}^n d_i$ 必须是偶数。这源于握手引理，该引理指出度数之和等于边数的两倍。\n$2$. 对于从 $1$ 到 $n$ 的每个整数 $k$，必须满足以下不等式：\n$$ \\sum_{i=1}^k d_i \\le k(k-1) + \\sum_{i=k+1}^n \\min(k, d_i) $$\n算法首先将输入的度序列 $d$ 按非增顺序排序。然后验证度数和为偶数的条件。如果该条件成立，则继续检查所有 $k \\in \\{1, 2, \\dots, n\\}$ 值的不等式。如果对于任何一个 $k$，不等式被违反，则该序列不可图化。如果所有检查都通过，则该序列是可图化的。结果 $G$ 是一个指示可图性的布尔值。\n\n**任务 3：配置模型 (CM) 构建与连通性分析**\n\n如果一个度序列被确定为可图化的 ($G = \\mathrm{True}$)，我们继续构建图的一个实现并分析其连通性。\n\n**CM 构建：** 配置模型生成一个具有给定度序列的随机多重图。过程如下：\n$1$. 对每个节点 $i$（从 $0$到 $n-1$），创建 $d_i$ 个“末端”或“半边”。这会产生总共 $L = \\sum d_i$ 个末端。\n$2$. 将所有 $L$ 个末端的列表进行均匀随机排列。为确保可复现性，使用一个伪随机数生成器，其种子为 $2025 + i$，其中 $i$ 是测试用例的零基索引。\n$3$. 将打乱后的末端顺序配对：第一个和第二个构成一条边，第三个和第四个构成一条边，依此类推。这将创建 $L/2$ 个配对，它们定义了多重图的边。此过程可能会产生自环（一个节点的末端与自身的另一个末端配对）和平行边（同一对节点之间的多条边）。\n\n**连通性分析：** 问题要求分析底层简单图。\n$1$. 从 CM 生成的边对构建图的邻接表表示。在此过程中，忽略自环（即一个末端与来自同一节点的另一个末端配对）。平行边被合并为一条边。\n$2$. 建立简单图结构后，我们计算连通分量的数量 $C$ 和最大连通分量 (LCC) 的大小。这通过广度优先搜索 (BFS) 遍历来完成。我们遍历从 $0$ 到 $n-1$ 的所有节点。如果一个节点尚未被访问，我们从它开始一个新的 BFS，并增加分量计数。BFS 会识别出属于当前分量的所有节点，我们持续跟踪迄今为止发现的最大分量的大小。\n$3$. LCC 比例 $L$ 计算为 LCC 中的节点数与总节点数的比率，即 $\\lvert \\text{LCC} \\rvert / n$。\n\n**边界情况处理与最终输出**\n\n对于不可图化的序列，CM 构建和连通性分析将被跳过。连通分量数量 $C$ 设置为 $-1$，LCC 比例 $L$ 设置为 $-1.000000$。\n\n对于每个测试用例，将计算出的四个值——可图性 ($G$)、连通分量数量 ($C$)、LCC 比例 ($L$) 和 Molloy-Reed 指示符 ($M$)——组合成一个列表 $[G, C, L, M]$。最终输出是一个单行字符串，表示这些结果列表的列表，其格式完全符合要求。", "answer": "```python\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Solves the graph theory problem for a suite of test cases.\n    For each degree sequence, it checks graphicality (Erdős-Gallai),\n    evaluates the Molloy-Reed condition, and if graphical, constructs\n    a graph via the Configuration Model to find connectivity properties.\n    \"\"\"\n    test_cases = [\n        [3, 3, 2, 2, 2, 2, 1, 1, 1, 1],\n        [4, 1, 1, 1],\n        [0, 0, 0, 0, 0],\n        [4, 1, 1, 1, 1],\n        [2, 2, 2, 2, 2, 2],\n    ]\n\n    all_results = []\n    for i, d in enumerate(test_cases):\n        # Task 4: Molloy–Reed condition\n        M = check_molloy_reed(d)\n\n        # Task 1: Graphicality check\n        is_graphical, n, d_sorted = check_graphicality(d)\n        G = is_graphical\n\n        # Tasks 2  3: CM construction and connectivity analysis\n        if is_graphical:\n            # The degree sequence d specifies the multiset of degrees.\n            # We assign the sorted degrees to nodes 0..n-1 for a canonical construction.\n            C, L = run_cm_and_connectivity(d_sorted, n, seed=2025 + i)\n        else:\n            C = -1\n            L = -1.0\n\n        result_item = [G, C, f\"{L:.6f}\" if C != -1 else \"-1.000000\", M]\n        all_results.append(result_item)\n    \n    # Final output generation\n    final_string_parts = []\n    for r in all_results:\n        g_str = str(r[0])\n        c_str = str(r[1])\n        l_str = r[2]\n        m_str = str(r[3])\n        part_str = f\"[{g_str},{c_str},{l_str},{m_str}]\"\n        final_string_parts.append(part_str)\n\n    print(f\"[{','.join(final_string_parts)}]\")\n\ndef check_molloy_reed(d):\n    \"\"\"\n    Evaluates the Molloy-Reed giant component condition: sum(d_i * (d_i-2)) > 0.\n    \"\"\"\n    if not d:\n        return False\n    val = sum(deg * (deg - 2) for deg in d)\n    return val > 0\n\ndef check_graphicality(d):\n    \"\"\"\n    Checks if a degree sequence is graphical using the Erdős–Gallai theorem.\n    Returns a tuple: (is_graphical, num_nodes, sorted_degree_sequence).\n    \"\"\"\n    n = len(d)\n    if n == 0:\n        return True, 0, []\n\n    # Condition 1: Sum of degrees must be even.\n    if sum(d) % 2 != 0:\n        return False, n, sorted(d, reverse=True)\n\n    d_sorted = sorted(d, reverse=True)\n\n    # Condition 2: Erdős–Gallai inequality check for k from 1 to n.\n    # sum_{i=1 to k} d_i = k*(k-1) + sum_{i=k+1 to n} min(k, d_i)\n    lhs = 0\n    for k in range(1, n + 1):\n        lhs += d_sorted[k - 1]\n        \n        rhs_sum_min = 0\n        for i in range(k, n):\n            rhs_sum_min += min(k, d_sorted[i])\n        \n        rhs = k * (k - 1) + rhs_sum_min\n        \n        if lhs > rhs:\n            return False, n, d_sorted\n            \n    return True, n, d_sorted\n\ndef run_cm_and_connectivity(d, n, seed):\n    \"\"\"\n    Constructs a CM realization and computes connectivity statistics.\n    Returns a tuple: (num_components, lcc_fraction).\n    \"\"\"\n    if n == 0:\n        return 0, 0.0\n    \n    if sum(d) == 0:\n        # Graph of n isolated nodes\n        return n, 1.0 / n if n > 0 else 0.0\n\n    # 1. Create stub list\n    stubs = []\n    for node_idx, degree in enumerate(d):\n        stubs.extend([node_idx] * degree)\n\n    # 2. Shuffle stubs for random pairing\n    rng = np.random.default_rng(seed)\n    rng.shuffle(stubs)\n\n    # 3. Form adjacency list of the underlying simple graph\n    adj = {i: set() for i in range(n)}\n    for i in range(0, len(stubs), 2):\n        u, v = stubs[i], stubs[i + 1]\n        if u != v:  # Ignore self-loops\n            adj[u].add(v)\n            adj[v].add(u)\n    \n    # 4. Find connected components using BFS\n    visited = [False] * n\n    num_components = 0\n    lcc_size = 0\n    for i in range(n):\n        if not visited[i]:\n            num_components += 1\n            current_component_size = 0\n            q = deque([i])\n            visited[i] = True\n            while q:\n                u = q.popleft()\n                current_component_size += 1\n                for v_neighbor in adj[u]:\n                    if not visited[v_neighbor]:\n                        visited[v_neighbor] = True\n                        q.append(v_neighbor)\n            lcc_size = max(lcc_size, current_component_size)\n\n    lcc_fraction = lcc_size / n\n    return num_components, lcc_fraction\n\nsolve()\n```", "id": "3317546"}, {"introduction": "除了简单的连通性，生物网络的鲁棒性常常体现在其能够抵抗破坏的、紧密互联的核心区域。本练习聚焦于 $k$-核（$k$-core）这一强大工具，它能有效识别这些具有韧性的子图。你将实现算法来定位网络中最鲁棒的核心，并模拟一种靶向策略来瓦解它，这项任务类似于在病原体的相互作用网络中寻找关键治疗靶点 [@problem_id:3317506]。", "problem": "考虑一个简单的无向图 $G = (V,E)$，其中 $V$ 是一个有限的节点集合，$E$ 是一个边集合，其形式为 $E \\subseteq \\{\\{u,v\\} \\mid u,v \\in V, u \\neq v\\}$。对于每个节点 $v \\in V$，其度记为 $d(v)$。$G$ 的 $k$-核 (k-core) 定义为唯一的最大导出子图 $H \\subseteq G$，其中 $H$ 中的每个节点 $u$ 在 $H$ 内部的度至少为 $k$。图 $G$ 的简并度 (degeneracy) $D(G)$ 定义为使得 $G$ 的 $k$-核非空的最大整数 $k$；等价地，$D(G)$ 是 $G$ 中所有节点的最大核数。对于一个节点 $v \\in V$，用 $G - v$ 表示通过移除 $v$ 及其所有关联边后从 $G$ 得到的导出子图。\n\n在病原体蛋白质-蛋白质相互作用网络或基因调控网络的背景下，高简并度的核可能代表具有冗余连接性的结构稳健区域。在计算系统生物学中，靶向破坏策略旨在高效地降低 $D(G)$。你的任务是针对一系列测试图实现以下计算：\n\n1. 对于每个图 $G$，计算其简并度 $D(G)$。\n2. 对于每个节点 $v \\in V$，计算简并度下降值 $\\Delta_v = D(G) - D(G - v)$。找出节点集合 $S^\\ast \\subseteq V$，其中移除单个节点能最大程度地降低简并度，即 $S^\\ast = \\{v \\in V \\mid \\Delta_v = \\max_{u \\in V} \\Delta_u\\}$。\n3. 对于每个图 $G$ 和一个整数目标 $T$（$0 \\leq T \\leq D(G)$），实现以下贪心靶向破坏策略，以将简并度降低至最多为 $T$：\n   - 在此过程中，令 $D_{\\text{curr}} = D(G)$ 为当前图的简并度。如果 $D_{\\text{curr}} \\leq T$，则停止并返回移除序列。\n   - 计算 $D_{\\text{curr}}$-核子图 $H$。如果 $H$ 为空，则停止（根据定义，如果 $D_{\\text{curr}} > 0$ 这不会发生）。\n   - 设 $H$ 的连通分量为 $\\{H_1, H_2, \\dots, H_m\\}$，其中每个 $H_i$ 的节点集为 $V_i$。选择节点数 $|V_j|$ 最大的分量 $H_j$；如果大小相同，则选择其中最小节点标签最小的那个分量。从所选分量 $H_j$ 中，移除标签最小的节点 $v^\\ast \\in V_j$。更新图 $G := G - v^\\ast$ 并重复此过程，直到 $D(G) \\leq T$。\n   - 返回此过程产生的完整移除序列 $(v_1^\\ast, v_2^\\ast, \\dots)$。\n\n所有节点标签都是非负整数。输出必须将所有测试用例的结果编码为一个单一的扁平化整数列表，每个测试用例按顺序结构如下：首先列出 $S^\\ast$ 的所有元素（按升序排列），然后是哨兵值 $-1$，接着是为达到目标简并度 $T$ 而执行的贪心移除序列，最后是哨兵值 $-2$ 标记该测试用例的结束。哨兵值 $-1$ 和 $-2$ 保证不会作为节点标签出现。\n\n你必须实现你的程序来解决以下测试图和目标的套件：\n\n- 测试用例 1：\n  - 节点：$V = \\{0,1,2,3,4\\}$。\n  - 边：所有 $\\{i,j\\}$ 其中 $0 \\leq i  j \\leq 4$（一个5个节点的完全图）。\n  - 目标：$T = 2$。\n- 测试用例 2：\n  - 节点：$V = \\{0,1,2,3,4,5,6,7,8\\}$。\n  - 边：所有 $\\{i,j\\}$ 其中 $0 \\leq i  j \\leq 3$（一个在 $0,1,2,3$ 上的完全子图）和所有 $\\{i,j\\}$ 其中 $4 \\leq i  j \\leq 7$（一个在 $4,5,6,7$ 上的完全子图），加上 $\\{8,3\\}$ 和 $\\{8,4\\}$（一个度为 $2$ 的桥接节点，连接两个密集区域）。\n  - 目标：$T = 2$。\n- 测试用例 3：\n  - 节点：$V = \\{0,1,2,3,4,5,6\\}$。\n  - 边：所有 $\\{0,i\\}$ 其中 $i \\in \\{1,2,3,4,5,6\\}$（一个以 $0$ 为中心、有六个叶节点的星形图）。\n  - 目标：$T = 0$。\n- 测试用例 4：\n  - 节点：$V = \\{0,1,2,3,4,5\\}$。\n  - 边：无（所有节点都是孤立的）。\n  - 目标：$T = 0$。\n- 测试用例 5：\n  - 节点：$V = \\{0,1,2,3,4,5,6,7,8\\}$。\n  - 边：所有 $\\{i,j\\}$ 其中 $0 \\leq i  j \\leq 4$（一个在 $0,1,2,3,4$ 上的完全子图），加上边 $\\{i,0\\}$ 和 $\\{i,1\\}$ 对于每个 $i \\in \\{5,6,7,8\\}$（外围节点连接到两个核心节点）。\n  - 目标：$T = 3$。\n\n最终所需的输出格式是一行，其中包含五个测试用例的聚合结果，形式为一个用方括号括起来的逗号分隔列表，并严格遵循上述整数编码描述，例如：$[x_1,x_2,\\dots,x_n]$，其内容是所有测试用例的 $[S^\\ast,-1,\\text{移除序列},-2]$ 块的串联。", "solution": "该问题要求在一系列测试图上实现三个图论计算：计算图的简并度，识别移除后能导致简并度最大下降的节点，以及执行一个贪心节点移除策略以将简并度降低到目标值。\n\n首先，我们必须将所提供的定义形式化。一个简单的无向图由 $G = (V, E)$ 给出，其中 $V$ 是节点集，$E$ 是边集。节点 $v$ 的度，记为 $d(v)$，是与其关联的边的数量。\n\n**1. 简并度和k-核的计算**\n\n图 $G$ 的 $k$-核是其中每个节点的度都至少为 $k$ 的最大导出子图。它可以通过一个迭代的“剥离”算法找到：从图中重复移除所有度小于 $k$ 的节点。当没有更多节点可以被移除时，该过程终止。剩余的子图就是 $k$-核。\n\n图的简并度 $D(G)$ 是使得 $k$-核非空的最大整数 $k$。等价地，它是所有节点中*核数*的最大值，其中一个节点的核数是它所属的 $k$-核中最高的 $k$ 值。\n\n一个计算上高效的寻找简并度的算法是基于创建一个简并度排序。这是一个顶点的排序 $v_1, v_2, \\dots, v_n$，使得每个顶点 $v_i$ 在由 $\\{v_i, v_{i+1}, \\dots, v_n\\}$ 导出的子图中具有最小度。图的简并度就是 $\\max_i d_{G_i}(v_i)$，其中 $G_i$ 是由 $\\{v_i, \\dots, v_n\\}$ 导出的子图。一个更简单，但对于此问题规模性能足够的算法可以被实现。它的工作方式如下：\n1. 创建一个图的可变副本。\n2. 当图不为空时：\n   a. 在当前图中找到一个度最小的节点 $v$，设其度为 $d_{\\min}$。\n   b. 简并度至少为 $d_{\\min}$。记录到目前为止所见到的最大 $d_{\\min}$。\n   c. 从图中移除 $v$ 及其关联边。\n3. 记录到的最大最小度即为简并度 $D(G)$。如果在 $|V|$ 个步骤中的每一步都花费 $O(|V|)$ 的时间来寻找最小度节点，则该算法的时间复杂度大约为 $O(|V|^2)$。\n\n**2. 识别关键节点 ($S^\\ast$)**\n\n此任务要求我们评估单独移除每个节点的影响。对于每个节点 $v \\in V$，我们通过移除 $v$ 及其所有关联边来构建子图 $G - v$。然后，我们使用上述算法计算这个新子图的简并度 $D(G-v)$。简并度下降值计算为 $\\Delta_v = D(G) - D(G-v)$。我们遍历 $V$ 中的所有节点，同时追踪找到的最大下降值 $\\max_{u \\in V} \\Delta_u$。集合 $S^\\ast$ 包含所有达到此最大下降值的节点 $v$。\n\n**3. 贪心靶向破坏**\n\n这是一个将图的简并度降低到目标水平 $T$ 的迭代过程。设当前图为 $G_{\\text{curr}}$，初始时为原始图 $G$。过程如下：\n1. 计算当前图的简并度 $D_{\\text{curr}} = D(G_{\\text{curr}})$。\n2. 如果 $D_{\\text{curr}} \\leq T$，过程终止。\n3. 否则，识别 $D_{\\text{curr}}$-核子图，我们将其表示为 $H$。这通过使用固定 $k=D_{\\text{curr}}$ 的剥离算法来完成。\n4. 找到 $H$ 的连通分量。这可以使用标准的图遍历算法来完成，如广度优先搜索 (BFS) 或深度优先搜索 (DFS)。\n5. 根据两个标准选择目标分量：\n   a. 节点数最多的分量。\n   b. 如果大小相同出现平局，则选择其中最小节点标签最小的分量。\n   这个选择是确定性的。我们可以先按大小（降序）对分量进行排序，然后按它们的最小节点标签（升序）排序来找到目标。\n6. 从所选分量中，识别出标签最小的节点 $v^\\ast$。\n7. 在移除序列中记录 $v^\\ast$ 并通过移除它来更新图：$G_{\\text{curr}} := G_{\\text{curr}} - v^\\ast$。\n8. 从步骤1开始重复此过程。\n\n实现将使用一个集合的字典来表示图的邻接表，因为这种结构便于高效地移除节点和边。将为每个不同的算法任务创建辅助函数：简并度计算、k-核提取和寻找连通分量，以确保一个模块化和可验证的解决方案。\n\n对于每个测试用例，这三个任务按顺序执行。结果（排序后的 $S^\\ast$，移除序列）与指定的哨兵值（$-1$ 和 $-2$）串联起来，形成该测试用例的最终输出字符串，然后将它们聚合成一个单一的列表。", "answer": "```python\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Main function to solve the graph theory problem for the given test suite.\n    It orchestrates the processing of each test case and prints the final aggregated result.\n    \"\"\"\n\n    # Helper function to create an adjacency list from nodes and edges.\n    def build_adj(nodes, edges):\n        adj = {node: set() for node in nodes}\n        for u, v in edges:\n            adj[u].add(v)\n            adj[v].add(u)\n        return adj\n\n    # Helper function to create a deep copy of an adjacency list.\n    def copy_adj(adj):\n        return {u: neighbors.copy() for u, neighbors in adj.items()}\n\n    # Helper function to remove a node and its incident edges from an adjacency list.\n    # This function modifies the adjacency list in place for efficiency.\n    def remove_node_inplace(adj, node_to_remove):\n        if node_to_remove in adj:\n            # The neighbors might have been removed in previous steps.\n            neighbors_to_update = adj[node_to_remove]  adj.keys()\n            for neighbor in neighbors_to_update:\n                adj[neighbor].remove(node_to_remove)\n            del adj[node_to_remove]\n\n    # Computes the k-core of a graph.\n    def get_k_core(adj, k):\n        core_adj = copy_adj(adj)\n        while True:\n            nodes_to_remove = {u for u, neighbors in core_adj.items() if len(neighbors)  k}\n            if not nodes_to_remove:\n                break\n            for u in nodes_to_remove:\n                remove_node_inplace(core_adj, u)\n        return core_adj\n\n    # Computes the degeneracy of a graph using iterative removal of min-degree nodes.\n    def get_degeneracy(adj):\n        if not adj:\n            return 0\n        \n        temp_adj = copy_adj(adj)\n        degrees = {u: len(n) for u, n in temp_adj.items()}\n        degeneracy = 0\n        \n        # This loop runs |V| times, simulating the creation of a degeneracy ordering.\n        for _ in range(len(temp_adj)):\n            if not degrees:\n                break\n            \n            # Find a node with minimum degree.\n            min_deg_node = min(degrees, key=degrees.get)\n            min_deg = degrees[min_deg_node]\n            \n            degeneracy = max(degeneracy, min_deg)\n            \n            # \"Remove\" the node by deleting its degree entry and updating its neighbors.\n            neighbors_of_removed = temp_adj[min_deg_node]\n            del degrees[min_deg_node]\n\n            for neighbor in neighbors_of_removed:\n                if neighbor in degrees:\n                    degrees[neighbor] -= 1\n        \n        return degeneracy\n\n    # Finds the connected components of a graph using Breadth-First Search (BFS).\n    def find_connected_components(adj):\n        if not adj:\n            return []\n        \n        nodes_to_visit = set(adj.keys())\n        components = []\n        \n        while nodes_to_visit:\n            start_node = nodes_to_visit.pop()\n            \n            component = {start_node}\n            queue = deque([start_node])\n            \n            while queue:\n                u = queue.popleft()\n                # Ensure neighbors exist in the current component's context.\n                for v in adj.get(u, set()):\n                    if v in nodes_to_visit:\n                        nodes_to_visit.remove(v)\n                        component.add(v)\n                        queue.append(v)\n            components.append(component)\n            \n        return components\n\n    # Processes a single test case.\n    def run_test_case(nodes, edges, target_T):\n        case_result = []\n        original_adj = build_adj(nodes, edges)\n        \n        # Task 1  2: Compute D(G) and find S*\n        D_G = get_degeneracy(original_adj)\n        max_delta = -1\n        s_star = []\n        node_list = sorted(list(original_adj.keys()))\n\n        for v in node_list:\n            adj_minus_v = copy_adj(original_adj)\n            remove_node_inplace(adj_minus_v, v)\n            D_G_minus_v = get_degeneracy(adj_minus_v)\n            delta = D_G - D_G_minus_v\n            \n            if delta  max_delta:\n                max_delta = delta\n                s_star = [v]\n            elif delta == max_delta:\n                s_star.append(v)\n        \n        case_result.extend(sorted(s_star))\n        case_result.append(-1)\n\n        # Task 3: Greedy targeted disruption\n        removal_sequence = []\n        current_adj = copy_adj(original_adj)\n        \n        while True:\n            D_curr = get_degeneracy(current_adj)\n            if D_curr = target_T:\n                break\n                \n            k_core_adj = get_k_core(current_adj, D_curr)\n            components = find_connected_components(k_core_adj)\n            \n            # Sort components by size (desc) and then min node label (asc).\n            if not components: # Should not happen if D_curr  0\n                break\n            components.sort(key=lambda c: (-len(c), min(c)))\n            target_component = components[0]\n            \n            node_to_remove = min(target_component)\n            \n            removal_sequence.append(node_to_remove)\n            remove_node_inplace(current_adj, node_to_remove)\n            \n        case_result.extend(removal_sequence)\n        case_result.append(-2)\n        \n        return case_result\n\n    # Define the test suite from the problem description.\n    test_cases = [\n        {\n            \"nodes\": [0, 1, 2, 3, 4],\n            \"edges\": [(i, j) for i in range(5) for j in range(i + 1, 5)],\n            \"target\": 2,\n        },\n        {\n            \"nodes\": [0, 1, 2, 3, 4, 5, 6, 7, 8],\n            \"edges\": (\n                [(i, j) for i in range(4) for j in range(i + 1, 4)] +\n                [(i, j) for i in range(4, 8) for j in range(i + 1, 8)] +\n                [(8, 3), (8, 4)]\n            ),\n            \"target\": 2,\n        },\n        {\n            \"nodes\": [0, 1, 2, 3, 4, 5, 6],\n            \"edges\": [(0, i) for i in range(1, 7)],\n            \"target\": 0,\n        },\n        {\n            \"nodes\": [0, 1, 2, 3, 4, 5],\n            \"edges\": [],\n            \"target\": 0,\n        },\n        {\n            \"nodes\": [0, 1, 2, 3, 4, 5, 6, 7, 8],\n            \"edges\": (\n                [(i, j) for i in range(5) for j in range(i + 1, 5)] +\n                [(i, 0) for i in range(5, 9)] +\n                [(i, 1) for i in range(5, 9)]\n            ),\n            \"target\": 3,\n        }\n    ]\n\n    # Aggregate results from all test cases.\n    all_results = []\n    for case in test_cases:\n        result_block = run_test_case(case[\"nodes\"], case[\"edges\"], case[\"target\"])\n        all_results.extend(result_block)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3317506"}]}