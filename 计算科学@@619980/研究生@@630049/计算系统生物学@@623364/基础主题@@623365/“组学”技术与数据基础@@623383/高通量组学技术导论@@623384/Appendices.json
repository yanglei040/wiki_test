{"hands_on_practices": [{"introduction": "在进行高通量测序时，一个关键问题是评估测序文库的质量，特别是其复杂度和饱和度。本练习将引导你通过一个概率模型来理解这些概念，它们对于有效规划测序深度和评估数据回报至关重要。通过从第一性原理推导，你将学会如何估计在给定测序读数下预期能观察到的独特分子数量，并理解这一指标如何影响后续的实验决策 [@problem_id:3321409]。", "problem": "在新一代测序（NGS）中，测序文库是为测序而准备的一组不同分子的群体。聚合酶链式反应（PCR）扩增和有限的文库大小导致多个读段(reads)源自同一个原始分子，从而产生重复(duplicates)。定义文库复杂度为文库中不同分子的总数 $M$，并假设每个读段从这 $M$ 个分子中均匀随机且有放回地采样一个分子。如果一个读段对应于一个先前未被观测到的分子，则该读段被认为是唯一的；如果它对应于一个已经产生至少一个读段的分子，则被认为是重复的。\n\n从随机抽样和期望线性性的核心定义出发，推导从一个大小为 $M$ 的文库中进行 $N$ 次独立读取后，至少被观测到一次的不同分子的期望数量。解释该期望数量如何在该随机抽样模型下将重复率和文库复杂度的概念形式化，并证明在规划更深度测序时使用所推导表达式的合理性。\n\n然后，对于一个包含 $M=2\\times 10^{7}$ 个不同分子和 $N=5\\times 10^{7}$ 个读段的全基因组NGS文库，计算你的推导所隐含的唯一读段的期望数量。将您的数值答案四舍五入至四位有效数字。最终答案以不带单位的纯数字形式表示。", "solution": "### 不同分子期望数量的推导\n\n设 $M$ 为文库中不同分子的总数（文库复杂度），设 $N$ 为读段的总数。问题陈述， $N$ 次读段中的每一次都是从 $M$ 个分子中均匀随机且有放回地抽样。我们需要求出至少被观测到一次的不同分子的期望数量。\n\n设 $X$ 为 $N$ 次读取后观测到的不同分子数量的随机变量。为了求 $X$ 的期望 $E[X]$，我们可以使用期望的线性性。我们为文库中的 $M$ 个分子中的每一个定义一组指示随机变量 $X_i$，其中 $i$ 的范围从 $1$ 到 $M$。\n\n设 $X_i$ 定义为：\n$$\nX_i = \n\\begin{cases} \n1  \\text{如果在 } N \\text{ 次读取中分子 } i \\text{ 至少被观测到一次} \\\\\n0  \\text{如果在 } N \\text{ 次读取中分子 } i \\text{ 从未被观测到}\n\\end{cases}\n$$\n观测到的不同分子总数 $X$ 是这些指示变量的和：\n$$\nX = \\sum_{i=1}^{M} X_i\n$$\n根据期望的线性性，$X$ 的期望值是各个指示变量期望值的和：\n$$\nE[X] = E\\left[\\sum_{i=1}^{M} X_i\\right] = \\sum_{i=1}^{M} E[X_i]\n$$\n指示变量的期望是它所指示事件的概率。因此，$E[X_i] = P(X_i = 1)$。\n\n概率 $P(X_i = 1)$ 是分子 $i$ 至少被观测到一次的概率。更直接的方法是先计算其互补概率 $P(X_i = 0)$，即分子 $i$ 从未被观测到的概率。\n\n对于单次读取，由于均匀抽样的假设，抽样到任何特定分子 $i$ 的概率是 $p = \\frac{1}{M}$。因此，在单次读取中*不*抽样到分子 $i$ 的概率是 $1 - p = 1 - \\frac{1}{M}$。\n\n由于 $N$ 次读取是独立事件，因此在 $N$ 次读取中都未观测到分子 $i$ 的概率是每次读取中都未观测到它的概率的乘积：\n$$\nP(X_i = 0) = \\left(1 - \\frac{1}{M}\\right)^N\n$$\n因此，至少观测到一次分子 $i$ 的概率是：\n$$\nP(X_i = 1) = 1 - P(X_i = 0) = 1 - \\left(1 - \\frac{1}{M}\\right)^N\n$$\n这就得到了每个指示变量的期望：$E[X_i] = 1 - \\left(1 - \\frac{1}{M}\\right)^N$。\n\n由于这个概率对于所有分子 $i=1, \\dots, M$ 都是相同的，我们现在可以计算总期望 $E[X]$：\n$$\nE[X] = \\sum_{i=1}^{M} \\left(1 - \\left(1 - \\frac{1}{M}\\right)^N\\right) = M \\left(1 - \\left(1 - \\frac{1}{M}\\right)^N\\right)\n$$\n这就是推导出的观测到的不同分子期望数量的表达式。\n\n### 重复率和文库复杂度的形式化\n\n推导出的表达式 $E[X] = M \\left(1 - \\left(1 - \\frac{1}{M}\\right)^N\\right)$ 将测序深度（$N$）、文库复杂度（$M$）和唯一信息的期望产出之间的关系形式化。\n\n1.  **唯一读段与重复读段**：根据定义，“唯一读段”是从一个给定分子产生的第一个读段。来自同一分子的所有后续读段都是“重复读段”。因此，实验中唯一读段的总数恰好是观测到的不同分子的数量。推导出的量 $E[X]$ 因此是唯一读段的期望数量。重复读段的期望数量是总读段数减去唯一读段的期望数量：$E[\\text{重复读段}] = N - E[X]$。期望重复率是一个关键的质量指标，即重复读段占总读段的比例：\n    $$\n    \\text{期望重复率} = \\frac{N - E[X]}{N} = 1 - \\frac{E[X]}{N} = 1 - \\frac{M}{N}\\left(1 - \\left(1 - \\frac{1}{M}\\right)^N\\right)\n    $$\n\n2.  **文库复杂度（$M$）的影响**：如果 $M$相对于 $N$ 非常大（$M \\gg N$），则重新抽样一个分子的概率很低。项 $\\left(1 - \\frac{1}{M}\\right)^N$ 可以使用二项式展开近似为 $1 - \\frac{N}{M}$。那么，$E[X] \\approx M \\left(1 - \\left(1 - \\frac{N}{M}\\right)\\right) = M \\left(\\frac{N}{M}\\right) = N$。这表明，对于一个高复杂度的文库，几乎每个读段都是唯一的，并且发现的不同分子的数量随测序深度线性增加。\n\n3.  **测序深度（$N$）的影响**：对于固定的 $M$，随着 $N$ 的增加，项 $\\left(1 - \\frac{1}{M}\\right)^N$ 趋近于 $0$。因此，$E[X]$ 趋近于 $M$。这描述了文库饱和现象。随着测序越来越深，发现新分子的概率降低，重复读段的比例也随之增加。最终，几乎所有的 $M$ 个分子都将被抽样到，$E[X]$ 在 $M$ 处达到平台期。\n\n### 规划更深度测序的合理性\n\n这个模型对于实验设计至关重要。在投入资源进行深度测序之前，研究人员可以估计文库复杂度 $M$，这或许可以从一次浅层预实验测序中获得。然后，使用推导出的公式，可以预测在任何给定的测序深度 $N$ 下唯一分子的期望产出。绘制 $E[X]$ 相对于 $N$ 的图表可以揭示收益递减点，在该点， $N$ 的显著增加仅带来 $E[X]$ 的微小增加。这种分析有助于做出成本效益决策：测序应该足够深，以捕获文库复杂度的期望部分，但又不应过深，以至于大多数新读段都是冗余的重复，这将导致资源利用效率低下。\n\n### 数值计算\n\n给定 $M = 2 \\times 10^{7}$ 和 $N = 5 \\times 10^{7}$。我们需要计算 $E[X] = M \\left(1 - \\left(1 - \\frac{1}{M}\\right)^N\\right)$。\n\n对于大的 $M$，表达式 $\\left(1 - \\frac{1}{M}\\right)^N$ 可以使用指数函数的极限定义 $\\lim_{k \\to \\infty} (1 + \\frac{x}{k})^k = \\exp(x)$ 进行精确近似。\n具体来说，$\\left(1 - \\frac{1}{M}\\right)^N = \\exp\\left(N \\ln\\left(1 - \\frac{1}{M}\\right)\\right)$。\n使用 $\\ln(1-y) = -y - \\frac{y^2}{2} - \\dots$ 的泰勒级数展开，并令 $y = \\frac{1}{M}$，我们得到 $\\ln\\left(1 - \\frac{1}{M}\\right) \\approx -\\frac{1}{M}$。由于 $M$ 非常大，这个近似非常精确。\n因此，我们有：\n$$\n\\left(1 - \\frac{1}{M}\\right)^N \\approx \\exp\\left(N \\left(-\\frac{1}{M}\\right)\\right) = \\exp\\left(-\\frac{N}{M}\\right)\n$$\n不同分子期望数量的公式变为：\n$$\nE[X] \\approx M \\left(1 - \\exp\\left(-\\frac{N}{M}\\right)\\right)\n$$\n现在，我们代入给定的值：\n$$\n\\frac{N}{M} = \\frac{5 \\times 10^{7}}{2 \\times 10^{7}} = 2.5\n$$\n将这个比率代入近似公式：\n$$\nE[X] \\approx (2 \\times 10^{7}) \\left(1 - \\exp(-2.5)\\right)\n$$\n使用计算器计算 $\\exp(-2.5)$ 的值：\n$$\n\\exp(-2.5) \\approx 0.0820849986\n$$\n现在，我们计算括号中的表达式：\n$$\n1 - \\exp(-2.5) \\approx 1 - 0.0820849986 = 0.9179150014\n$$\n最后，我们计算唯一分子的期望数量：\n$$\nE[X] \\approx (2 \\times 10^{7}) \\times 0.9179150014 = 18358300.028\n$$\n问题要求将最终答案四舍五入到四位有效数字。\n这个数字是 $18,358,300.028$。用科学记数法表示，大约是 $1.83583 \\times 10^{7}$。\n四舍五入到四位有效数字得到 $1.836 \\times 10^{7}$。\n因此，唯一读段的期望数量是 $18,360,000$。", "answer": "$$\n\\boxed{1.836 \\times 10^{7}}\n$$", "id": "3321409"}, {"introduction": "从原始测序读数到可靠的基因表达量，数据标准化是至关重要的一步。本练习聚焦于转录组学中一个核心的偏好校正问题：基因长度偏好，即更长的转录本在相同表达水平下会天然产生更多的读数。你将通过计算和比较两种常用的标准化方法——每千碱基每百万读数（RPKM）和每百万转录本（TPM），亲身体验 TPM 如何通过其独特的计算顺序有效消除基因长度偏好，从而获得更准确的样本内基因相对表达丰度 [@problem_id:3321416]。", "problem": "在一次单端信使RNA测序实验中，考虑两个基因，分别标记为基因 $1$ 和基因 $2$，其真实的底层read生成遵循以下原理：来自基因 $i$ 的预期read计数与其有效转录本长度和转录本丰度的乘积成正比，并按总测序深度进行缩放。具体来说，假设这两个基因的唯一比对read计数为 $[1000, 1000]$，它们的有效长度为 $[500, 2000]$ 个碱基对。假设文库中所有的read都比对到这两个基因上，因此总比对read数为 $N = 2000$。您可以假设一个标准的抽样模型，其中对于每个基因 $i$，其预期计数满足 $\\mathbb{E}[C_i] \\propto L_i \\,\\theta_i \\, s$，其中 $L_i$ 是以碱基对为单位的有效长度，$\\theta_i$ 是单位碱基的转录本丰度，而 $s$ 是测序深度。\n\n基于此模型基础以及由此推导出的每千碱基每百万比对reads（RPKM）和每百万转录本（TPM）的规范定义，完成以下任务：\n- 从第一性原理出发，推导对于一个基因 $i$ 的样本内度量（通常称为RPKM和TPM）的表达式，用 $C_i$、$L_i$ 和适当的样本水平归一化因子来表示。\n- 使用计数 $[1000, 1000]$、长度 $[500, 2000]$ 碱基对和总比对read数 $N = 2000$，计算基因 $1$ 和基因 $2$ 的RPKM和TPM数值。\n- 利用这些计算结果解释与原始计数相比，长度归一化如何改变表观的相对表达量。\n\n对于最终报告的量，请提供无单位的比率 $\\mathrm{TPM}_1 / \\mathrm{TPM}_2$ 作为单个数字。无需四舍五入，最终答案中不应包含任何单位。在需要时，请一致地表达任何以每千碱基为单位的中间速率，但只有 $\\mathrm{TPM}_1 / \\mathrm{TPM}_2$ 将作为最终答案进行评分。", "solution": "### 第1部分：RPKM和TPM的推导\n\n问题陈述指出，基因 $i$ 的预期read计数 $\\mathbb{E}[C_i]$ 与其有效转录本长度 $L_i$、转录本丰度 $\\theta_i$ 和测序深度 $s$ 的乘积成正比。我们可以将其写为：\n$$\n\\mathbb{E}[C_i] = k \\cdot \\theta_i \\cdot L_i \\cdot s\n$$\n其中 $k$ 是一个比例常数。归一化的目标是通过消除基因长度 $L_i$ 和测序深度 $s$ 的混杂效应，得出一个能更好地代表真实转录本丰度 $\\theta_i$ 的量。我们使用观测到的计数 $C_i$ 作为 $\\mathbb{E}[C_i]$ 的估计值。\n\n**每千碱基每百万比对reads (RPKM)：**\nRPKM指标通过两个连续的步骤对原始read计数 $C_i$ 进行归一化：\n1.  **基因长度归一化：** 为了解释在相同表达水平下，较长的基因自然会产生更多read这一事实，我们将read计数除以基因的有效长度。长度通常以千碱基（kb）表示。以千碱基为单位的有效长度为 $L_i^{\\text{kb}} = L_i / 1000$。这产生了一个每千碱基的reads率：\n    $$\n    \\frac{C_i}{L_i^{\\text{kb}}} = \\frac{C_i}{L_i / 1000}\n    $$\n2.  **测序深度归一化：** 为了能够在不同实验（样本）之间进行比较，我们用文库中总的比对read数 $N$ 进行归一化。总read数通常以百万为单位表示。以百万为单位的总read数为 $N^{\\text{M}} = N / 10^6$。\n\n结合这两种归一化，基因 $i$ 的RPKM被定义为每百万比对reads中，每千碱基转录本长度的reads数。\n$$\n\\mathrm{RPKM}_i = \\frac{C_i / (L_i / 1000)}{N / 10^6} = \\frac{C_i \\cdot 10^3 \\cdot 10^6}{L_i \\cdot N} = \\frac{C_i \\cdot 10^9}{N \\cdot L_i}\n$$\n该表达式提供了根据给定数量的RPKM的正式定义。\n\n**每百万转录本 (TPM)：**\n与RPKM相比，TPM指标提供了对样本间相对丰度更稳定的估计。其推导过程颠倒了归一化操作的顺序。\n1.  **基因长度归一化：** 与RPKM一样，我们首先通过将read计数 $C_i$ 除以以千碱基为单位的基因长度 $L_i^{\\text{kb}} = L_i / 1000$来计算一个比率。我们称这个比率为 $R_i$：\n    $$\n    R_i = \\frac{C_i}{L_i^{\\text{kb}}} = \\frac{C_i}{L_i / 1000}\n    $$\n    该比率与转录本丰度 $\\theta_i$（以及测序深度 $s$）成正比。\n2.  **测序深度归一化（相对于其他基因）：** TPM将一个基因的丰度表示为其在样本中占总转录本的比例，并缩放到一百万。我们计算样本中所有基因 $j$ 的所有此类比率的总和：$\\sum_j R_j$。这个总和代表整个文库的总“每千碱基reads”率。基因 $i$ 的分数表示即为 $\\frac{R_i}{\\sum_j R_j}$。\n3.  **缩放：** 然后将此分数缩放到一百万。\n    $$\n    \\mathrm{TPM}_i = \\left( \\frac{R_i}{\\sum_j R_j} \\right) \\cdot 10^6 = \\left( \\frac{C_i / (L_i / 1000)}{\\sum_j (C_j / (L_j / 1000))} \\right) \\cdot 10^6\n    $$\n    主分数中分子和分母里的因子 $1000$ 被抵消，从而得到一个更简单的表达式：\n    $$\n    \\mathrm{TPM}_i = \\left( \\frac{C_i / L_i}{\\sum_j (C_j / L_j)} \\right) \\cdot 10^6\n    $$\n    这是TPM的正式定义。TPM的一个关键特性是，一个样本中所有基因的TPM值之和总是 $10^6$。\n\n### 第2部分：数值计算\n\n我们有以下给定数据：\n-   Read计数：$C_1 = 1000$, $C_2 = 1000$。\n-   有效长度：$L_1 = 500$ bp, $L_2 = 2000$ bp。\n-   总比对read数：$N = C_1 + C_2 = 1000 + 1000 = 2000$。\n\n**RPKM计算：**\n使用推导出的公式 $\\mathrm{RPKM}_i = \\frac{C_i \\cdot 10^9}{N \\cdot L_i}$：\n对于基因 $1$：\n$$\n\\mathrm{RPKM}_1 = \\frac{1000 \\cdot 10^9}{2000 \\cdot 500} = \\frac{10^3 \\cdot 10^9}{2 \\cdot 10^3 \\cdot 5 \\cdot 10^2} = \\frac{10^{12}}{10 \\cdot 10^5} = \\frac{10^{12}}{10^6} = 1,000,000\n$$\n对于基因 $2$：\n$$\n\\mathrm{RPKM}_2 = \\frac{1000 \\cdot 10^9}{2000 \\cdot 2000} = \\frac{10^3 \\cdot 10^9}{4 \\cdot 10^6} = \\frac{10^{12}}{4 \\cdot 10^6} = 0.25 \\cdot 10^6 = 250,000\n$$\n基因 $1$ 的RPKM值为 $1,000,000$，基因 $2$ 的RPKM值为 $250,000$。\n\n**TPM计算：**\n使用推导出的公式 $\\mathrm{TPM}_i = \\left( \\frac{C_i / L_i}{\\sum_j (C_j / L_j)} \\right) \\cdot 10^6$。\n首先，我们计算比率 $C_i / L_i$：\n-   基因 $1$ 的比率：$C_1 / L_1 = 1000 / 500 = 2$。\n-   基因 $2$ 的比率：$C_2 / L_2 = 1000 / 2000 = 0.5$。\n接下来，我们计算这些比率的总和：\n-   $\\sum_j (C_j / L_j) = (C_1 / L_1) + (C_2 / L_2) = 2 + 0.5 = 2.5$。\n现在我们为每个基因计算TPM：\n对于基因 $1$：\n$$\n\\mathrm{TPM}_1 = \\left( \\frac{2}{2.5} \\right) \\cdot 10^6 = 0.8 \\cdot 10^6 = 800,000\n$$\n对于基因 $2$：\n$$\n\\mathrm{TPM}_2 = \\left( \\frac{0.5}{2.5} \\right) \\cdot 10^6 = 0.2 \\cdot 10^6 = 200,000\n$$\n基因 $1$ 的TPM值为 $800,000$，基因 $2$ 的TPM值为 $200,000$。\n\n### 第3部分：长度归一化效应的解释\n\n两个基因的原始read计数是相同的：$C_1 = 1000$ 和 $C_2 = 1000$。一个朴素的解释会认为这两个基因的表达量相等，相对表达比率为 $C_1/C_2 = 1$。\n\n然而，这两个基因的有效长度有很大差异：$L_1 = 500$ bp 而 $L_2 = 2000$ bp。基因 $2$ 的长度是基因 $1$ 的四倍。底层模型 $\\mathbb{E}[C_i] \\propto \\theta_i \\cdot L_i$ 指出，对于相同的转录本丰度（$\\theta_1 = \\theta_2$），更长的基因预期会产生更多的read。具体来说，如果基因 $1$ 和基因 $2$ 具有相同的丰度，我们预期基因 $2$ 产生的read数大约是基因 $1$ 的四倍。\n\n两个基因都产生了相同数量的read（$1000$）这一观察结果与丰度相等的假设相矛盾。为了产生与一个长度是其四倍的基因相同数量的read，较短的基因（基因 $1$）必须具有显著更高的转录本丰度。\n\n在RPKM和TPM中实现的长度归一化校正了这种偏差。通过将read计数除以基因长度，这些指标估计了底层的转录本丰度。我们的计算显示：\n-   通过RPKM计算的相对表达量：$\\mathrm{RPKM}_1 / \\mathrm{RPKM}_2 = 1,000,000 / 250,000 = 4$。\n-   通过TPM计算的相对表达量：$\\mathrm{TPM}_1 / \\mathrm{TPM}_2 = 800,000 / 200,000 = 4$。\n\n两种归一化指标都表明基因 $1$ 的丰度是基因 $2$ 的四倍。这与最初的推理一致：基因 $1$ 的长度是基因 $2$ 的四分之一，但产生了相同数量的read，这意味着其转录本的浓度高出四倍。因此，长度归一化对于从read计数中准确推断相对基因表达至关重要，它纠正了原始计数给出的误导性印象。\n\n需要报告的最终量是比率 $\\mathrm{TPM}_1 / \\mathrm{TPM}_2$。\n$$\n\\frac{\\mathrm{TPM}_1}{\\mathrm{TPM}_2} = \\frac{800,000}{200,000} = 4\n$$\n或者，使用符号公式：\n$$\n\\frac{\\mathrm{TPM}_1}{\\mathrm{TPM}_2} = \\frac{\\left( \\frac{C_1 / L_1}{\\sum_j (C_j / L_j)} \\right) \\cdot 10^6}{\\left( \\frac{C_2 / L_2}{\\sum_j (C_j / L_j)} \\right) \\cdot 10^6} = \\frac{C_1 / L_1}{C_2 / L_2} = \\frac{C_1 L_2}{C_2 L_1} = \\frac{1000 \\cdot 2000}{1000 \\cdot 500} = \\frac{2000}{500} = 4\n$$\n结果是稳健的。", "answer": "$$\\boxed{4}$$", "id": "3321416"}, {"introduction": "高通量组学研究的本质是在成千上万个假设中寻找显著的信号，这不可避免地带来了多重检验的挑战。本练习将向你介绍一种优雅而强大的统计策略——靶标-诱饵方法（target-decoy approach），用于控制假阳性发现率（FDR）。以蛋白质组学实验为例，你将推导出一个简洁的 FDR 估算公式，深刻理解如何利用“诱饵”数据来量化和控制“靶标”数据中的统计错误，这是确保组学发现可靠性的基石 [@problem_id:3321431]。", "problem": "在一次使用液相色谱-串联质谱（LC-MS/MS）的散弹法蛋白质组学实验中，通过在一个串联的蛋白质序列数据库中搜索每个谱图来鉴定肽段-谱图匹配。该数据库包含一个通过反转每个靶标序列构建的经验零假设（即靶标-诱饵策略）。假设数据库的靶标部分和诱饵部分大小相等，并且每个谱图只保留得分最高的唯一匹配。在固定的得分阈值下，假设您观察到 $T$ 个接受的靶标匹配和 $D$ 个接受的诱饵匹配。\n\n从错误发现率（FDR）的基本定义（即所有报告的阳性结果中假阳性结果的期望比例）出发，并仅使用以下假设：(i) 所有诱饵匹配都是错误的，(ii) 当靶标和诱饵部分大小相等且被对称搜索时，错误匹配落入靶标或诱饵部分的概率相等，以及 (iii) 在选定的阈值下，谱图是从同一数据生成过程中的独立抽样，推导出一个仅用 $T$ 和 $D$ 表示的FDR封闭形式估计量。请清楚地证明将观察到的诱饵计数与预期的假靶标匹配数联系起来的概率步骤。\n\n然后，使用您推导出的估计量，计算当 $D = 50$ 且 $T = 950$ 时的FDR。将最终的FDR表示为一个不带百分号的小数，并四舍五入到四位有效数字。", "solution": "推导从FDR的基本定义开始，问题中将其定义为所有报告的阳性结果中假阳性结果的期望比例。在靶标-诱饵搜索的背景下，“报告的阳性结果”是指得分高于某一阈值并从序列数据库的靶标部分鉴定出的肽段-谱图匹配（PSM）。这类匹配的数量由 $T$ 给出。\n\n设 $T$ 为接受的靶标匹配总数。这组 $T$ 个匹配由两个不相交的子集组成：真阳性（$TP$）和假阳性（$FP_T$）。\n$$T = TP + FP_T$$\nFDR是这个集合中假阳性的期望比例。FDR的一个实用估计量，记为 $\\widehat{FDR}$，是估计的假阳性数量与报告的阳性总数之比。\n$$\\widehat{FDR} = \\frac{\\widehat{E[FP_T]}}{T}$$\n核心任务是找到 $E[FP_T]$（即靶标集中的假阳性期望数量）的估计量。这可以通过使用诱饵匹配来完成。\n\n设 $D$ 为接受的诱饵匹配数。我们现在应用问题中提供的假设。\n\n1.  **假设 (i)：所有诱饵匹配都是错误的。**\n    诱饵序列是人工构建的（本例中通过反转），并假定不对应样本中的任何真实肽段。因此，任何与诱饵序列的匹配，根据定义，都是假阳性。这意味着观察到的诱饵计数 $D$ 是在数据库诱饵部分发现的假阳性数量的直接度量，我们可以将其表示为 $FP_D$。\n    $$D = FP_D$$\n\n2.  **假设 (ii)：错误匹配落入数据库靶标部分或诱饵部分的概率相等。**\n    这个假设是合理的，因为靶标和诱饵数据库大小相等，并且被对称地搜索。这意味着，对于任何产生随机、不正确匹配的谱图，其匹配到靶标序列的概率等于其匹配到诱饵序列的概率。在统计学上，这意味着靶标集中的假阳性期望数量 $E[FP_T]$ 等于诱饵集中的假阳性期望数量 $E[FP_D]$。\n    $$E[FP_T] = E[FP_D]$$\n\n3.  **将观测值与期望值联系起来。**\n    这是关键的概率步骤。我们有观测到的诱饵匹配计数 $D$。由于谱图是独立抽样（假设 iii），$D$ 是随机变量 $FP_D$ 的一次实现。在没有其他信息的情况下，观测到的计数 $D$ 是 $FP_D$ 期望值的最直接且无偏的点估计。\n    $$\\widehat{E[FP_D]} = D$$\n    通过将此与假设 (ii) 中的期望相等性结合，我们可以估计靶标集中的假阳性期望数量。\n    $$\\widehat{E[FP_T]} = \\widehat{E[FP_D]} = D$$\n    因此，观测到的诱饵匹配数 $D$ 作为我们 $T$ 个靶标匹配中潜藏的假阳性期望数量的估计量。\n\n现在，我们可以组装出FDR的最终封闭形式估计量。通过将我们对 $E[FP_T]$ 的估计代入FDR的定义中：\n$$\\widehat{FDR} = \\frac{\\widehat{E[FP_T]}}{T} = \\frac{D}{T}$$\n这就是FDR的封闭形式估计量，仅用可观测的量 $T$ 和 $D$ 表示。\n\n接下来，我们计算给定值的FDR：$D = 50$ 和 $T = 950$。\n将这些值代入我们推导出的估计量中：\n$$\\widehat{FDR} = \\frac{50}{950}$$\n化简分数：\n$$\\widehat{FDR} = \\frac{5}{95} = \\frac{1}{19}$$\n为了将其表示为四舍五入到四位有效数字的小数，我们进行除法运算：\n$$\\frac{1}{19} \\approx 0.0526315789...$$\n第一个非零数字是 $5$，所以这是第一位有效数字。前四位有效数字是 $5$、$2$、$6$ 和 $3$。第五位有效数字是 $1$。由于 $1  5$，我们向下取整（即，在第四位有效数字后截断）。\n$$\\widehat{FDR} \\approx 0.05263$$", "answer": "$$ \\boxed{0.05263} $$", "id": "3321431"}]}