{"hands_on_practices": [{"introduction": "理论学习之后，最好的巩固方式莫过于亲手实践。这项动手实践旨在引导你从头开始构建一个完整的近似贝叶斯计算（Approximate Bayesian Computation, ABC）程序。通过为一个简化的宇宙学模型（弱引力透镜的峰值计数）实现ABC拒绝采样算法，你将深入理解模拟推理的基本工作流程。此练习 [@problem_id:3489626] 的核心在于量化评估不同选择（如距离度量、模拟预算和容忍度 $\\epsilon$）如何影响最终后验推断的质量，这对于在实际研究中做出明智的方法论决策至关重要。", "problem": "实现一个完整、可运行的程序，该程序对一个简化的弱引力透镜峰值计数模型执行近似贝叶斯计算（ABC），并量化名义 $0.68$ 可信区间的后验覆盖率，该覆盖率是距离度量、$N_{\\mathrm{sim}}$ 模拟预算和 $\\epsilon$ 容差的函数。该程序必须为一组改变这些输入的指定测试用例估计覆盖率，并以末尾描述的精确格式单行输出覆盖率结果。\n\n您必须遵守以下具有科学依据的设置。\n\n- 生成模型（弱引力透镜峰值计数直方图）：\n  - 令宇宙学参数向量为 $\\boldsymbol{\\theta} = (\\Omega_{\\mathrm{m}}, \\sigma_8)$。\n  - 先验是均匀分布的：$\\Omega_{\\mathrm{m}} \\sim \\mathcal{U}(0.2, 0.4)$ 和 $\\sigma_8 \\sim \\mathcal{U}(0.6, 1.0)$，两者独立。\n  - 定义 $K = 8$ 个峰高区间，单位区间宽度为 $\\Delta x = 1$，并采用抽象的单位区间中心。令在 $\\boldsymbol{\\theta}$ 下每个区间的期望计数为\n    $$\\lambda_k(\\boldsymbol{\\theta}) = s \\, A_k \\left(\\frac{\\sigma_8}{\\sigma_{8,\\mathrm{ref}}}\\right)^{\\alpha_k} \\left(\\frac{\\Omega_{\\mathrm{m}}}{\\Omega_{\\mathrm{m,ref}}}\\right)^{\\beta_k}, \\quad k = 1,\\dots, K,$$\n    其中 $s = 1$，$\\sigma_{8,\\mathrm{ref}} = 0.8$，$\\Omega_{\\mathrm{m,ref}} = 0.3$，且\n    $$A_k = 200 \\exp\\!\\big(-0.4\\,(k-1)\\big), \\quad \\alpha_k = 1.1 + 0.1\\,(k-1), \\quad \\beta_k = 0.6 + 0.05\\,(k-1).$$\n  - 观测到的峰值计数是作为独立的泊松变量抽取的：\n    $$N_k \\sim \\mathrm{Poisson}\\big(\\lambda_k(\\boldsymbol{\\theta})\\big), \\quad k = 1,\\dots,K.$$\n  - 汇总统计量是归一化直方图（经验概率）$\\mathbf{p} \\in \\mathbb{R}^K$，其分量为\n    $$p_k = \\frac{N_k}{\\sum_{j=1}^K N_j + \\delta}, \\quad \\delta = 10^{-12}.$$\n\n- 两个归一化直方图 $\\mathbf{p}$ 和 $\\mathbf{q}$ 之间的距离度量：\n  1. 欧几里得距离：\n     $$d_{\\mathrm{E}}(\\mathbf{p}, \\mathbf{q}) = \\left(\\sum_{k=1}^K (p_k - q_k)^2\\right)^{1/2}.$$\n  2. 一维切片瓦瑟斯坦距离（等于 $1\\mathrm{D}$ 中的一阶瓦瑟斯坦距离）：\n     $$d_{\\mathrm{SW}}(\\mathbf{p}, \\mathbf{q}) = \\sum_{k=1}^K \\left|F_{\\mathbf{p}}(k) - F_{\\mathbf{q}}(k)\\right| \\, \\Delta x,$$\n     其中 $F_{\\mathbf{p}}(k) = \\sum_{j=1}^k p_j$ 和 $F_{\\mathbf{q}}(k) = \\sum_{j=1}^k q_j$，且 $\\Delta x = 1$。\n\n- 通过拒绝采样的近似贝叶斯计算（ABC）：\n  - 给定一个观测到的归一化直方图 $\\mathbf{p}_{\\mathrm{obs}}$、模拟预算 $N_{\\mathrm{sim}}$、容差 $\\epsilon$ 以及一个选定的距离 $d \\in \\{d_{\\mathrm{E}}, d_{\\mathrm{SW}}\\}$：\n    1. 对于 $i = 1,\\dots, N_{\\mathrm{sim}}$，从先验中抽取 $\\boldsymbol{\\theta}^{(i)}$，模拟计数 $\\{N_k^{(i)}\\}_{k=1}^K$，形成 $\\mathbf{p}^{(i)}$，计算 $d\\big(\\mathbf{p}^{(i)}, \\mathbf{p}_{\\mathrm{obs}}\\big)$；如果 $d \\le \\epsilon$，则接受 $\\boldsymbol{\\theta}^{(i)}$。\n    2. 接受的样本集近似于后验分布。\n  - 如果没有参数被接受，则将该重复定义为非覆盖（见下文覆盖率定义）。\n\n- 覆盖率估计：\n  - 固定真值参数 $\\boldsymbol{\\theta}_\\star = (0.3, 0.8)$。\n  - 对每个测试用例，执行 $R$ 次独立重复，如下所示：\n    1. 从 $\\boldsymbol{\\theta}_\\star$ 生成一个新的观测数据集以获得 $\\mathbf{p}_{\\mathrm{obs}}$。\n    2. 使用指定的 $d$、$N_{\\mathrm{sim}}$ 和 $\\epsilon$ 运行 ABC 以获得接受的样本 $\\{\\boldsymbol{\\theta}^{(i)}\\}_{i=1}^{M}$。\n    3. 如果 $M = 0$，则将此次重复记录为非覆盖。\n    4. 否则，从接受的样本中计算 $\\Omega_{\\mathrm{m}}$ 和 $\\sigma_8$ 的边际等尾 $0.68$ 可信区间：\n       $$I_{\\Omega} = \\big[\\mathrm{Quantile}_{0.16}\\{\\Omega_{\\mathrm{m}}^{(i)}\\},\\ \\mathrm{Quantile}_{0.84}\\{\\Omega_{\\mathrm{m}}^{(i)}\\}\\big],$$\n       $$I_{\\sigma} = \\big[\\mathrm{Quantile}_{0.16}\\{\\sigma_8^{(i)}\\},\\ \\mathrm{Quantile}_{0.84}\\{\\sigma_8^{(i)}\\}\\big].$$\n    5. 当且仅当 $\\Omega_{\\mathrm{m},\\star} \\in I_{\\Omega}$ 和 $\\sigma_{8,\\star} \\in I_{\\sigma}$ 同时成立时，宣布此次重复为覆盖。\n  - 该测试用例的覆盖率是 $R$ 次重复中覆盖重复所占的比例。\n\n- 测试套件：\n  - 每个测试用例使用 $R = 24$ 次重复。\n  - 评估以下六个测试用例，每个用例指定为一个三元组 $(d, N_{\\mathrm{sim}}, \\epsilon)$：\n    1. $(d_{\\mathrm{E}}, 400, 0.12)$\n    2. $(d_{\\mathrm{E}}, 1200, 0.12)$\n    3. $(d_{\\mathrm{E}}, 1200, 0.08)$\n    4. $(d_{\\mathrm{SW}}, 400, 0.40)$\n    5. $(d_{\\mathrm{SW}}, 1200, 0.40)$\n    6. $(d_{\\mathrm{SW}}, 1200, 0.28)$\n\n- 要求的最终输出格式：\n  - 您的程序应生成单行输出，其中包含上述六个测试用例的覆盖率结果，顺序与上文相同，形式为用方括号括起来的逗号分隔列表。\n  - 每个覆盖率值必须是四舍五入到三位小数的小数。\n  - 例如，有效的输出格式如下：\"[0.583,0.625,0.667,0.542,0.708,0.750]\"。\n\n注：\n- 本问题中不需要物理单位；所有量在构造上都是无量纲的。\n- 本问题中未使用角度。\n- 百分比必须表示为小数；不要使用百分号。", "solution": "用户在数值宇宙学和基于模拟的推断领域提供了一个定义明确的计算问题。该问题的所有方面在科学和数学上都是合理的、完整的且无歧义的。该问题被认为是有效的，并将提供一个解决方案。\n\n### 原理 1：正向生成模型\n\n任何基于模拟的推断的基础都是一个正向模型，该模型可以在给定一组参数的情况下生成合成数据。在这里，该模型将宇宙学参数 $\\boldsymbol{\\theta} = (\\Omega_{\\mathrm{m}}, \\sigma_8)$ 映射到一个汇总统计量，即峰值计数的归一化直方图。\n\n1.  **参数到期望的映射**：参数 $\\boldsymbol{\\theta}$ 首先从均匀先验分布中抽取：$\\Omega_{\\mathrm{m}} \\sim \\mathcal{U}(0.2, 0.4)$ 和 $\\sigma_8 \\sim \\mathcal{U}(0.6, 1.0)$。这些参数通过唯象标度关系决定了在 $K=8$ 个区间中每个区间的期望峰值计数 $\\lambda_k$：\n    $$\\lambda_k(\\boldsymbol{\\theta}) = s \\, A_k \\left(\\frac{\\sigma_8}{\\sigma_{8,\\mathrm{ref}}}\\right)^{\\alpha_k} \\left(\\frac{\\Omega_{\\mathrm{m}}}{\\Omega_{\\mathrm{m,ref}}}\\right)^{\\beta_k}$$\n    常数 $s=1$、$\\sigma_{8,\\mathrm{ref}} = 0.8$、$\\Omega_{\\mathrm{m,ref}} = 0.3$ 以及函数 $A_k$、$\\alpha_k$ 和 $\\beta_k$ 在问题中已定义，并封装了结构形成的抽象物理过程。\n\n2.  **随机数据生成**：每个区间中观测到的实际计数值 $N_k$ 是一个随机变量。与计数实验一致，它被建模为从具有先前计算出的期望值的泊松分布中的一次独立抽取：\n    $$N_k \\sim \\mathrm{Poisson}\\big(\\lambda_k(\\boldsymbol{\\theta})\\big), \\quad k = 1,\\dots,K.$$\n\n3.  **汇总统计量**：为了比较数据集，我们使用一个汇总统计量 $\\mathbf{p}$，即计数的归一化直方图。这将数据的维度从计数值降低为在 $K$ 个区间上的经验概率分布。\n    $$p_k = \\frac{N_k}{\\sum_{j=1}^K N_j + \\delta}$$\n    小常数 $\\delta = 10^{-12}$ 确保分母永远不为零。\n\n算法实现将需要一个函数，该函数以参数向量 $\\boldsymbol{\\theta}$ 作为输入，并执行这些步骤以输出模拟的汇总统计量 $\\mathbf{p}$。\n\n### 原理 2：通过 ABC 拒绝采样的无似然推断\n\n在贝叶斯推断中，我们寻求后验分布 $P(\\boldsymbol{\\theta}|\\mathbf{D}_{\\mathrm{obs}}) \\propto P(\\mathbf{D}_{\\mathrm{obs}}|\\boldsymbol{\\theta}) P(\\boldsymbol{\\theta})$，其中 $P(\\mathbf{D}_{\\mathrm{obs}}|\\boldsymbol{\\theta})$ 是似然，$P(\\boldsymbol{\\theta})$ 是先验。对于宇宙学中的许多复杂模型，似然函数难以处理或计算成本过高。ABC 规避了对似然函数的直接评估。\n\nABC 拒绝算法通过从先验中采样，并只接受那些能生成与观测数据“接近”的模拟数据的参数来近似后验分布。“接近度”由汇总统计量上的距离度量 $d$ 来衡量。该算法如下：\n\n1.  给定一个观测到的汇总统计量 $\\mathbf{p}_{\\mathrm{obs}}$、一个模拟预算 $N_{\\mathrm{sim}}$ 和一个容差 $\\epsilon$。\n2.  对于 $i = 1, \\dots, N_{\\mathrm{sim}}$：\n    a. 从其先验 $P(\\boldsymbol{\\theta})$ 中采样一个参数向量 $\\boldsymbol{\\theta}^{(i)}$。\n    b. 使用带有 $\\boldsymbol{\\theta}^{(i)}$ 的正向模型生成一个合成数据集及其汇总统计量 $\\mathbf{p}^{(i)}$。\n    c. 计算距离 $d\\big(\\mathbf{p}^{(i)}, \\mathbf{p}_{\\mathrm{obs}}\\big)$。\n    d. 如果 $d \\le \\epsilon$，则接受 $\\boldsymbol{\\theta}^{(i)}$。\n3.  接受的参数集合 $\\{\\boldsymbol{\\theta}^{(i)}\\}_{\\mathrm{accepted}}$ 构成了对真实后验 $P(\\boldsymbol{\\theta}|\\mathbf{p}_{\\mathrm{obs}})$ 的近似样本。如果 $\\epsilon \\to 0$ 且 $N_{\\mathrm{sim}} \\to \\infty$，这个近似就变得精确。\n\n实现将包含一个主函数，该函数负责协调此循环，调用生成模型和距离函数。\n\n### 原理 3：用于比较数据的距离度量\n\n距离度量 $d$ 的选择至关重要，因为它含蓄地定义了推断所敏感的数据方面。该问题指定了两种度量，用于比较模拟直方图 $\\mathbf{p}$ 与观测直方图 $\\mathbf{q}$：\n\n1.  **欧几里得距离 ($d_{\\mathrm{E}}$)**：这是一个标准的 L2 范数，测量直方图之间的逐点平方差。\n    $$d_{\\mathrm{E}}(\\mathbf{p}, \\mathbf{q}) = \\left(\\sum_{k=1}^K (p_k - q_k)^2\\right)^{1/2}$$\n    它独立地处理每个区间的差异。\n\n2.  **切片瓦瑟斯坦距离 ($d_{\\mathrm{SW}}$)**：在一维空间中，这等同于一阶瓦瑟斯坦距离，它衡量将一个分布转换为另一个分布所需的“功”。它通过计算直方图累积分布函数（CDF）之间的积分绝对差来得到。对于区间宽度为 $\\Delta x = 1$ 的离散分布：\n    $$d_{\\mathrm{SW}}(\\mathbf{p}, \\mathbf{q}) = \\sum_{k=1}^K \\left|F_{\\mathbf{p}}(k) - F_{\\mathbf{q}}(k)\\right| \\Delta x$$\n    其中 $F_{\\mathbf{p}}(k) = \\sum_{j=1}^k p_j$ 是 CDF。与 $d_{\\mathrm{E}}$ 不同，该度量对区间的相对位置敏感，更自然地惩罚分布质量的移动。\n\n将为每种度量实现单独的函数。$d_{\\mathrm{SW}}$ 的实现将涉及计算直方图概率的累积和。\n\n### 原理 4：通过后验覆盖率进行性能评估\n\n任何统计推断方法的关键诊断是其校准。对于贝叶斯方法，我们希望在多次重复实验中，我们的 $X\\%$ 可信区间有 $X\\%$ 的时间包含参数真值。此属性称为频率论覆盖率。名义覆盖率与实际覆盖率之间的不匹配表明后验近似中存在偏差或不准确。\n\n覆盖率估计过程如下：\n\n1.  固定真值参数，此处为 $\\boldsymbol{\\theta}_\\star = (0.3, 0.8)$。\n2.  执行 $R=24$ 次独立重复。对于每次重复：\n    a. 从真值参数 $\\boldsymbol{\\theta}_\\star$ 生成一个新的“观测”数据集 $\\mathbf{p}_{\\mathrm{obs}}$。\n    b. 运行 ABC 算法以获得一组 $M$ 个接受的样本，从而近似后验分布。\n    c. 如果 $M=0$，则宣布该重复为非覆盖。\n    d. 如果 $M>0$，则计算 $\\Omega_{\\mathrm{m}}$ 和 $\\sigma_8$ 的边际 $0.68$ 可信区间。这是通过找到每个参数的接受样本的第 $16$ 和第 $84$ 百分位数来完成的。\n    e. 当且仅当*两个*参数的真值都落在它们各自的可信区间内时，该重复才算“覆盖”：$\\Omega_{\\mathrm{m},\\star} \\in I_{\\Omega}$ 和 $\\sigma_{8,\\star} \\in I_{\\sigma}$。\n3.  给定测试用例（$d$、$N_{\\mathrm{sim}}$ 和 $\\epsilon$ 的特定组合）的估计覆盖率是覆盖的重复所占的比例。\n\n整个过程将被封装在一个主循环中，该循环对六个指定测试用例中的每一个进行 $R=24$ 次重复的迭代，计算覆盖率分数，并存储结果。最终输出是这些覆盖率分数的格式化列表。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates an Approximate Bayesian Computation (ABC) procedure\n    for a simplified weak lensing peak-count model, and computes posterior coverage.\n    \"\"\"\n    # Fix the random seed for reproducibility\n    np.random.seed(42)\n\n    # -- Model and Global Constants --\n    K = 8  # Number of peak-height bins\n    DELTA_X = 1.0  # Bin width\n    S_SCALE = 1.0  # Overall scaling factor\n    SIGMA8_REF = 0.8\n    OMEGAM_REF = 0.3\n    DELTA_STAB = 1e-12  # Stabilization constant for normalization\n\n    # Ground-truth parameters for generating \"observed\" data\n    THETA_STAR = np.array([0.3, 0.8])  # (Omega_m_star, sigma_8_star)\n\n    # Prior bounds\n    PRIOR_BOUNDS = {\n        'om': (0.2, 0.4),\n        's8': (0.6, 1.0)\n    }\n\n    # Pre-compute model constants for k = 1,...,K\n    k_vals = np.arange(1, K + 1)\n    A_k = 200.0 * np.exp(-0.4 * (k_vals - 1))\n    ALPHA_k = 1.1 + 0.1 * (k_vals - 1)\n    BETA_k = 0.6 + 0.05 * (k_vals - 1)\n\n    # -- Generative Model and Distance Functions --\n\n    def get_lambda(theta):\n        \"\"\"Calculates the expected counts lambda_k for a given theta.\"\"\"\n        omega_m, sigma_8 = theta\n        lambda_k = S_SCALE * A_k * \\\n                   (sigma_8 / SIGMA8_REF)**ALPHA_k * \\\n                   (omega_m / OMEGAM_REF)**BETA_k\n        return lambda_k\n\n    def generate_summary_stat(theta):\n        \"\"\"Generates a normalized peak-count histogram for a given theta.\"\"\"\n        lambda_k = get_lambda(theta)\n        # Draw counts from a Poisson distribution\n        N_k = np.random.poisson(lambda_k)\n        # Compute the normalized summary statistic\n        total_counts = np.sum(N_k)\n        p_k = N_k / (total_counts + DELTA_STAB)\n        return p_k\n\n    def distance_euclidean(p, q):\n        \"\"\"Computes Euclidean distance between two histograms.\"\"\"\n        return np.linalg.norm(p - q)\n\n    def distance_sw(p, q):\n        \"\"\"Computes 1D Sliced Wasserstein distance between two histograms.\"\"\"\n        cdf_p = np.cumsum(p)\n        cdf_q = np.cumsum(q)\n        return np.sum(np.abs(cdf_p - cdf_q)) * DELTA_X\n\n    # -- ABC and Coverage Estimation --\n\n    def run_abc(p_obs, N_sim, epsilon, distance_func):\n        \"\"\"Performs ABC rejection sampling.\"\"\"\n        accepted_thetas = []\n        # Sample N_sim parameters from the prior\n        thetas_om = np.random.uniform(PRIOR_BOUNDS['om'][0], PRIOR_BOUNDS['om'][1], N_sim)\n        thetas_s8 = np.random.uniform(PRIOR_BOUNDS['s8'][0], PRIOR_BOUNDS['s8'][1], N_sim)\n        \n        for i in range(N_sim):\n            theta_i = np.array([thetas_om[i], thetas_s8[i]])\n            # Generate simulated summary statistic\n            p_sim = generate_summary_stat(theta_i)\n            # Calculate distance\n            dist = distance_func(p_sim, p_obs)\n            # Accept if distance is within tolerance\n            if dist = epsilon:\n                accepted_thetas.append(theta_i)\n        \n        return np.array(accepted_thetas)\n\n    def check_coverage(accepted_thetas, theta_star):\n        \"\"\"Checks if the true parameters are within the 0.68 credible intervals.\"\"\"\n        if accepted_thetas.shape[0] == 0:\n            return False  # Non-covering if no samples are accepted\n\n        # Calculate 16th and 84th percentiles for each parameter\n        # These define the 68% equal-tailed credible interval\n        ci_om = np.percentile(accepted_thetas[:, 0], [16, 84])\n        ci_s8 = np.percentile(accepted_thetas[:, 1], [16, 84])\n\n        # Check if true parameters fall within their respective intervals\n        om_covered = (ci_om[0] = theta_star[0] = ci_om[1])\n        s8_covered = (ci_s8[0] = theta_star[1] = ci_s8[1])\n\n        # Replicate is covering only if both parameters are covered\n        return om_covered and s8_covered\n\n    # -- Test Suite Execution --\n    R = 24  # Number of replicates per test case\n    test_cases = [\n        ('euclidean', 400, 0.12),\n        ('euclidean', 1200, 0.12),\n        ('euclidean', 1200, 0.08),\n        ('sw', 400, 0.40),\n        ('sw', 1200, 0.40),\n        ('sw', 1200, 0.28),\n    ]\n\n    distance_map = {\n        'euclidean': distance_euclidean,\n        'sw': distance_sw\n    }\n\n    results = []\n    for d_name, N_sim, epsilon in test_cases:\n        n_covering_replicates = 0\n        dist_func = distance_map[d_name]\n        \n        for _ in range(R):\n            # 1. Generate a new \"observed\" data set from the ground truth\n            p_obs = generate_summary_stat(THETA_STAR)\n            \n            # 2. Run ABC to get posterior samples\n            accepted_samples = run_abc(p_obs, N_sim, epsilon, dist_func)\n            \n            # 3. Check if the replicate covers the true parameters\n            if check_coverage(accepted_samples, THETA_STAR):\n                n_covering_replicates += 1\n        \n        # 4. Calculate coverage fraction for the test case\n        coverage = n_covering_replicates / R\n        results.append(f\"{coverage:.3f}\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```", "id": "3489626"}, {"introduction": "掌握了ABC的基本实现后，一个自然而然的问题是：如何最有效地利用有限的计算资源？这项练习 [@problem_id:3489624] 将引导你探索模拟过程中的最优实验设计问题。它从信息论的视角出发，将模拟资源的分配问题构建为最大化参数与数据之间互信息的过程。通过这个多步骤的练习，你将首先推导最优分配的解析解，然后进行数值计算，并最终接触到如汤普森采样这类先进的序贯决策策略，从而深刻理解如何从原则上指导高效的科学模拟。", "problem": "考虑一个用于数值宇宙学中基于模拟的推断（SBI）的基于模拟的设计问题。宇宙学参数空间被划分为两个不相交的区域，记为区域 $1$ 和区域 $2$，其先验质量分别为 $w_{1}$ 和 $w_{2}$，满足 $w_{1} + w_{2} = 1$。对于区域 $k \\in \\{1,2\\}$，对于一个固定的汇总统计量，正向模型允许一个局部线性高斯近似。参数与使用专注于区域 $k$ 的设计抽取的 $n_{k}$ 个独立模拟之间的互信息可以精确地近似为\n$$\n\\frac{1}{2} w_{k} \\ln\\!\\big(1 + \\lambda_{k} n_{k}\\big),\n$$\n其中 $\\lambda_{k}  0$ 是一个信息率参数，它依赖于设计的局部 Fisher 信息以及限制在区域 $k$ 内的先验方差。假设跨区域的模拟在给定区域索引的条件下是条件独立的，并且对预期信息增益有加性贡献，因此对于一个分配 $\\{n_{1}, n_{2}\\}$ 的总互信息为\n$$\n\\mathcal{I}(n_{1}, n_{2}) = \\frac{1}{2} \\sum_{k=1}^{2} w_{k} \\ln\\!\\big(1 + \\lambda_{k} n_{k}\\big).\n$$\n给定总模拟预算为 $N$ 个单位，因此 $n_{1} + n_{2} = N$ 且 $n_{k} \\ge 0$。假设 $n_{k}$ 的连续松弛对于分配大批量是合适的，并且在最优解处两个区域都处于活动状态（因此拉格朗日乘子最优性条件对 $k=1,2$ 均以等式成立）。\n\nA部分。从高斯线性实验的互信息定义和独立设计间信息的可加性出发，推导在约束 $n_{1} + n_{2} = N$ 下最大化 $\\mathcal{I}(n_{1}, n_{2})$ 的最优分配 $\\{n_{1}^{\\star}, n_{2}^{\\star}\\}$。用 $w_{1}$、$w_{2}$、$\\lambda_{1}$、$\\lambda_{2}$ 和 $N$ 以闭式形式表示您的解。\n\nB部分。将问题具体化到以下数值指定、科学上合理的案例\n$$\nw_{1} = 0.6,\\quad w_{2} = 0.4,\\quad \\lambda_{1} = 0.02,\\quad \\lambda_{2} = 0.05,\\quad N = 120.\n$$\n计算相应的最优分配 $\\{n_{1}^{\\star}, n_{2}^{\\star}\\}$。\n\nC部分。现在假设您实施一个单步短视策略，通过对边际信息增量随机变量使用 Thompson 抽样来选择下一个区域。在当前分配 $\\{n_{1}, n_{2}\\}$ 下，将区域 $k$ 的单步边际信息增量定义为\n$$\n\\Delta I_{k}(\\lambda_{k}; n_{k}) = \\frac{1}{2} w_{k} \\ln\\!\\left(\\frac{1 + \\lambda_{k} (n_{k} + 1)}{1 + \\lambda_{k} n_{k}}\\right).\n$$\n假设由于蒙特卡洛估计噪声，您对这些增量维持独立的高斯后验，\n$$\n\\Delta I_{k} \\sim \\mathcal{N}\\!\\big(\\mu_{k}, s_{k}^{2}\\big),\n$$\n其后验均值设为在当前 $n_{k}$ 下的置入值 $\\mu_{k} = \\Delta I_{k}(\\lambda_{k}; n_{k})$，后验方差已知为 $s_{1}^{2} = 1.0 \\times 10^{-6}$ 和 $s_{2}^{2} = 0.8 \\times 10^{-6}$。在 Thompson 抽样下，您从每个后验中抽取一个样本，并选择抽样值较大的区域。对于 $K = 2$ 个区域，下一个选择区域 $1$ 的概率是\n$$\np = \\mathbb{P}\\!\\big(X_{1}  X_{2}\\big) = \\Phi\\!\\left(\\frac{\\mu_{1} - \\mu_{2}}{\\sqrt{s_{1}^{2} + s_{2}^{2}}}\\right),\n$$\n其中 $X_{k} \\sim \\mathcal{N}(\\mu_{k}, s_{k}^{2})$ 独立同分布，$\\Phi$ 是标准正态累积分布函数。使用B部分得到的最优分配作为当前分配 $\\{n_{1}, n_{2}\\}$，计算 $p$ 的小数值。将 $p$ 四舍五入到四位有效数字。\n\n以行向量 $\\big(n_{1}^{\\star}, n_{2}^{\\star}, p\\big)$ 的形式，使用 $\\pmatrix{\\cdot  \\cdot  \\cdot}$ 格式提供您的最终答案。将概率 $p$ 表示为小数（无百分号）。如果需要任何数值四舍五入，请严格遵守所述的有效数字规则。", "solution": "该问题要求在宇宙学背景下对模拟预算进行最优分配，然后计算在短视 Thompson 抽样策略下的决策概率。问题分为三部分，我们将按顺序解决。\n\n### A部分：最优分配\n\n目标是在预算约束下最大化总互信息 $\\mathcal{I}(n_{1}, n_{2})$。\n目标函数是：\n$$\n\\mathcal{I}(n_{1}, n_{2}) = \\frac{1}{2} \\sum_{k=1}^{2} w_{k} \\ln(1 + \\lambda_{k} n_{k}) = \\frac{1}{2} w_{1} \\ln(1 + \\lambda_{1} n_{1}) + \\frac{1}{2} w_{2} \\ln(1 + \\lambda_{2} n_{2})\n$$\n约束条件是总模拟次数固定为 $N$：\n$$\nn_{1} + n_{2} = N\n$$\n我们还知道，对于 $k \\in \\{1, 2\\}$，$n_{k} \\ge 0$。问题陈述最优解是内点解（即 $n_{k}^{\\star}  0$），这允许我们使用拉格朗日乘子法而无需考虑边界约束。\n\n我们通过引入一个拉格朗日乘子 $\\mu$ 来构造拉格朗日函数 $\\mathcal{L}$：\n$$\n\\mathcal{L}(n_{1}, n_{2}, \\mu) = \\mathcal{I}(n_{1}, n_{2}) - \\mu(n_{1} + n_{2} - N)\n$$\n为了找到最优分配 $\\{n_{1}^{\\star}, n_{2}^{\\star}\\}$，我们将 $\\mathcal{L}$ 对 $n_{1}$、$n_{2}$ 和 $\\mu$ 的偏导数设为零。\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial n_{1}} = \\frac{1}{2} \\frac{w_{1} \\lambda_{1}}{1 + \\lambda_{1} n_{1}} - \\mu = 0\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial n_{2}} = \\frac{1}{2} \\frac{w_{2} \\lambda_{2}}{1 + \\lambda_{2} n_{2}} - \\mu = 0\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mu} = N - n_{1} - n_{2} = 0\n$$\n从前两个方程中，我们可以用两种方式表示 $\\mu$ 并使它们相等。这将每个区域每次模拟的边际信息增益（按常数因子 $1/2$ 缩放）相等。\n$$\n\\mu = \\frac{1}{2} \\frac{w_{1} \\lambda_{1}}{1 + \\lambda_{1} n_{1}} = \\frac{1}{2} \\frac{w_{2} \\lambda_{2}}{1 + \\lambda_{2} n_{2}}\n$$\n我们定义一个常数 $C' = 2\\mu$。那么我们有：\n$$\n\\frac{w_{1} \\lambda_{1}}{1 + \\lambda_{1} n_{1}} = C' \\implies 1 + \\lambda_{1} n_{1} = \\frac{w_{1} \\lambda_{1}}{C'} \\implies n_{1} = \\frac{w_{1}}{C'} - \\frac{1}{\\lambda_{1}}\n$$\n$$\n\\frac{w_{2} \\lambda_{2}}{1 + \\lambda_{2} n_{2}} = C' \\implies 1 + \\lambda_{2} n_{2} = \\frac{w_{2} \\lambda_{2}}{C'} \\implies n_{2} = \\frac{w_{2}}{C'} - \\frac{1}{\\lambda_{2}}\n$$\n现在我们使用预算约束 $n_{1} + n_{2} = N$：\n$$\n\\left(\\frac{w_{1}}{C'} - \\frac{1}{\\lambda_{1}}\\right) + \\left(\\frac{w_{2}}{C'} - \\frac{1}{\\lambda_{2}}\\right) = N\n$$\n$$\n\\frac{w_{1} + w_{2}}{C'} - \\left(\\frac{1}{\\lambda_{1}} + \\frac{1}{\\lambda_{2}}\\right) = N\n$$\n使用给定条件 $w_{1} + w_{2} = 1$：\n$$\n\\frac{1}{C'} = N + \\frac{1}{\\lambda_{1}} + \\frac{1}{\\lambda_{2}}\n$$\n现在我们可以将这个关于 $1/C'$ 的表达式代回到 $n_{1}$ 和 $n_{2}$ 的方程中，以找到最优分配，记为 $\\{n_{1}^{\\star}, n_{2}^{\\star}\\}$：\n$$\nn_{1}^{\\star} = w_{1} \\left(N + \\frac{1}{\\lambda_{1}} + \\frac{1}{\\lambda_{2}}\\right) - \\frac{1}{\\lambda_{1}}\n$$\n$$\nn_{2}^{\\star} = w_{2} \\left(N + \\frac{1}{\\lambda_{1}} + \\frac{1}{\\lambda_{2}}\\right) - \\frac{1}{\\lambda_{2}}\n$$\n这些是最优分配的闭式表达式。\n\n### B部分：最优分配的数值计算\n\n给定以下数值：\n$$\nw_{1} = 0.6, \\quad w_{2} = 0.4, \\quad \\lambda_{1} = 0.02, \\quad \\lambda_{2} = 0.05, \\quad N = 120\n$$\n首先，我们计算信息率参数的倒数：\n$$\n\\frac{1}{\\lambda_{1}} = \\frac{1}{0.02} = 50\n$$\n$$\n\\frac{1}{\\lambda_{2}} = \\frac{1}{0.05} = 20\n$$\n现在，我们可以计算A部分解中括号内的项：\n$$\nN + \\frac{1}{\\lambda_{1}} + \\frac{1}{\\lambda_{2}} = 120 + 50 + 20 = 190\n$$\n将这些值代入 $n_{1}^{\\star}$ 和 $n_{2}^{\\star}$ 的表达式中：\n$$\nn_{1}^{\\star} = w_{1} \\left(190\\right) - \\frac{1}{\\lambda_{1}} = 0.6 \\times 190 - 50 = 114 - 50 = 64\n$$\n$$\nn_{2}^{\\star} = w_{2} \\left(190\\right) - \\frac{1}{\\lambda_{2}} = 0.4 \\times 190 - 20 = 76 - 20 = 56\n$$\n作为检验，我们确认 $n_{1}^{\\star} + n_{2}^{\\star} = 64 + 56 = 120 = N$。最优分配是 $\\{64, 56\\}$。\n\n### C部分：Thompson 抽样概率\n\n我们现在考虑一个单步短视策略，其中当前分配是B部分中找到的最优分配，即 $n_{1} = 64$ 和 $n_{2} = 56$。我们需要计算下一个选择区域 $1$ 的概率 $p$，由下式给出：\n$$\np = \\mathbb{P}(X_{1}  X_{2}) = \\Phi\\left(\\frac{\\mu_{1} - \\mu_{2}}{\\sqrt{s_{1}^{2} + s_{2}^{2}}}\\right)\n$$\n其中 $\\Phi$ 是标准正态累积分布函数 (CDF)。\n均值 $\\mu_{k}$ 由边际信息增量给出：\n$$\n\\mu_{k} = \\Delta I_{k}(\\lambda_{k}; n_{k}) = \\frac{1}{2} w_{k} \\ln\\left(\\frac{1 + \\lambda_{k} (n_{k} + 1)}{1 + \\lambda_{k} n_{k}}\\right)\n$$\n让我们使用B部分的值计算 $\\mu_{1}$ 和 $\\mu_{2}$：\n对于区域 $1$：$n_{1} = 64, w_{1} = 0.6, \\lambda_{1} = 0.02$。\n$$\n\\mu_{1} = \\frac{1}{2} (0.6) \\ln\\left(\\frac{1 + 0.02 (64 + 1)}{1 + 0.02 \\times 64}\\right) = 0.3 \\ln\\left(\\frac{1 + 1.3}{1 + 1.28}\\right) = 0.3 \\ln\\left(\\frac{2.3}{2.28}\\right)\n$$\n对于区域 $2$：$n_{2} = 56, w_{2} = 0.4, \\lambda_{2} = 0.05$。\n$$\n\\mu_{2} = \\frac{1}{2} (0.4) \\ln\\left(\\frac{1 + 0.05 (56 + 1)}{1 + 0.05 \\times 56}\\right) = 0.2 \\ln\\left(\\frac{1 + 2.85}{1 + 2.8}\\right) = 0.2 \\ln\\left(\\frac{3.85}{3.8}\\right)\n$$\n现在我们计算它们的数值：\n$$\n\\mu_{1} \\approx 0.3 \\times \\ln(1.0087719) \\approx 0.3 \\times 0.008733602 = 0.0026200806\n$$\n$$\n\\mu_{2} \\approx 0.2 \\times \\ln(1.0131579) \\approx 0.2 \\times 0.013071942 = 0.0026143884\n$$\n均值之差为：\n$$\n\\mu_{1} - \\mu_{2} \\approx 0.0026200806 - 0.0026143884 = 0.0000056922\n$$\n后验方差给定为 $s_{1}^{2} = 1.0 \\times 10^{-6}$ 和 $s_{2}^{2} = 0.8 \\times 10^{-6}$。方差之和为：\n$$\ns_{1}^{2} + s_{2}^{2} = 1.0 \\times 10^{-6} + 0.8 \\times 10^{-6} = 1.8 \\times 10^{-6}\n$$\n差值的标准差是：\n$$\n\\sqrt{s_{1}^{2} + s_{2}^{2}} = \\sqrt{1.8 \\times 10^{-6}} \\approx 0.0013416408\n$$\n现在我们计算标准正态累积分布函数的参数，我们记为 $z$：\n$$\nz = \\frac{\\mu_{1} - \\mu_{2}}{\\sqrt{s_{1}^{2} + s_{2}^{2}}} \\approx \\frac{0.0000056922}{0.0013416408} \\approx 0.00424285\n$$\n最后，我们计算 $p = \\Phi(z)$：\n$$\np = \\Phi(0.00424285) \\approx 0.5016922\n$$\n问题要求将 $p$ 四舍五入到四位有效数字。\n$0.5016922...$ 的前四位有效数字是 $5, 0, 1, 6$。下一位数字是 $9$，所以我们将最后一位有效数字向上取整。\n$$\np \\approx 0.5017\n$$\n最终答案是行向量 $(n_{1}^{\\star}, n_{2}^{\\star}, p)$。\n$$\n(64, 56, 0.5017)\n$$", "answer": "$$ \\boxed{ \\begin{pmatrix} 64  56  0.5017 \\end{pmatrix} } $$", "id": "3489624"}, {"introduction": "作为对高效模拟策略探索的补充，这项实践提供了另一个实用视角。除了最大化互信息这类较为抽象的目标，我们也可以致力于直接提升ABC后验近似的精度。这项练习 [@problem_id:3489634] 探讨了如何通过重新分配模拟预算，从而在保持相同接受率的情况下，获得一个更小的容忍度阈值 $\\epsilon$。在ABC中，更小的 $\\epsilon$ 意味着模拟数据与观测数据更接近，从而得到更精确的后验分布。这个确定性的计算问题清晰地揭示了，一个经过深思熟虑的模拟分配策略如何能在不增加总计算成本的前提下，显著提升推断结果的质量。", "problem": "给定一个有限的参数值网格 $\\{\\theta_i\\}_{i=1}^K$，以及对于每个 $\\theta_i$，一个有效标准差 $\\sigma_i  0$，该标准差描述了在一个良好校准的模拟器下，一维汇总统计量差异的分布。在近似贝叶斯计算 (ABC) 中，如果在 $\\theta_i$ 处的一次抽样的绝对差异 $D_i = |Z_i|$ 小于或等于一个阈值 $\\epsilon \\ge 0$，则该次抽样被接受。这里，$Z_i \\sim \\mathcal{N}(0,\\sigma_i^2)$ 在汇总统计量充分聚合的情况下，根据中心极限定理被建模为高斯分布。因此，在阈值 $\\epsilon$ 下，每个参数的接受概率为\n$$\np_i(\\epsilon) \\equiv \\mathbb{P}\\big(|Z_i| \\le \\epsilon \\mid \\theta_i\\big) = 2 \\Phi\\!\\left(\\frac{\\epsilon}{\\sigma_i}\\right) - 1 = \\operatorname{erf}\\!\\left(\\frac{\\epsilon}{\\sqrt{2}\\,\\sigma_i}\\right),\n$$\n其中 $\\Phi(\\cdot)$ 表示标准正态累积分布函数，$\\operatorname{erf}(\\cdot)$ 是误差函数。\n\n假设模拟预算根据权重 $a_i \\ge 0$（其中 $\\sum_{i=1}^K a_i = 1$）分配到 $\\{\\theta_i\\}$，那么在阈值 $\\epsilon$ 下，预期的总体 ABC 接受率是按分配加权的混合：\n$$\n\\bar{p}(\\epsilon; \\mathbf{a}) \\equiv \\sum_{i=1}^K a_i\\, p_i(\\epsilon) = \\sum_{i=1}^K a_i\\, \\operatorname{erf}\\!\\left(\\frac{\\epsilon}{\\sqrt{2}\\,\\sigma_i}\\right).\n$$\n给定一个目标接受水平 $\\alpha \\in (0,1)$，将在分配方案 $\\mathbf{a}$ 下达到该水平所需的最小阈值定义为以下方程的唯一解 $\\epsilon^\\star(\\mathbf{a};\\alpha)$：\n$$\n\\bar{p}\\big(\\epsilon^\\star(\\mathbf{a};\\alpha);\\mathbf{a}\\big) = \\alpha,\n$$\n该解存在且唯一，因为 $\\bar{p}(\\epsilon;\\mathbf{a})$ 是关于 $\\epsilon$ 的连续、严格递增函数，满足 $\\bar{p}(0;\\mathbf{a}) = 0$，且 $\\lim_{\\epsilon\\to\\infty}\\bar{p}(\\epsilon;\\mathbf{a}) = 1$。\n\n在同一网格上，为您提供了两种分配方案：\n- 一个基线分配 $\\mathbf{a}^{(0)}$，其值等于给定的先验权重向量 $\\mathbf{q}$，其中 $q_i \\ge 0$ 且 $\\sum_{i=1}^K q_i = 1$。\n- 一个根据后验不确定性进行“最优”重分配的方案 $\\mathbf{a}^{(\\mathrm{opt})}$，在分层抽样中 Neyman 分配的意义上：给定正的不确定性得分 $\\{s_i\\}_{i=1}^K$，设置\n$$\na_i^{(\\mathrm{opt})} \\equiv \\frac{s_i}{\\sum_{j=1}^K s_j}.\n$$\n直观地，这将更大份额的模拟分配给具有更大后验标准差得分 $s_i$ 的分层（参数值），这是在线性成本和独立分层假设下的经典方差最小化原则。\n\n对于一个固定的目标接受率 $\\alpha$，将由于重分配导致的阈值预期减少量定义为\n$$\n\\Delta(\\alpha) \\equiv \\epsilon^\\star\\!\\big(\\mathbf{a}^{(0)};\\alpha\\big) - \\epsilon^\\star\\!\\big(\\mathbf{a}^{(\\mathrm{opt})};\\alpha\\big).\n$$\n$\\Delta(\\alpha)$ 的正值意味着重分配允许使用更小的 ABC 阈值来维持相同的目标接受率；负值则意味着阈值必须增加。\n\n您的任务是为以下每个独立指定的测试用例计算 $\\Delta(\\alpha)$。在每个测试用例中，都给定了 $K$、向量 $\\boldsymbol{\\sigma} = (\\sigma_1,\\dots,\\sigma_K)$、$\\mathbf{q} = (q_1,\\dots,q_K)$、$\\mathbf{s} = (s_1,\\dots,s_K)$ 以及标量 $\\alpha$。使用上述定义，除了用于求解 $\\epsilon^\\star(\\cdot;\\alpha)$ 的数值求根外，不进行任何近似。您必须通过求解每个分配方案的单调方程，来精确地找到其唯一根 $\\epsilon^\\star$。不需要进行模拟或采样；该问题是确定性的。\n\n测试套件：\n- 案例 1：$K=4$, $\\boldsymbol{\\sigma} = [\\,0.5,\\,0.7,\\,1.0,\\,1.5\\,]$, $\\mathbf{q} = [\\,0.25,\\,0.25,\\,0.25,\\,0.25\\,]$, $\\mathbf{s} = [\\,2.0,\\,1.5,\\,1.0,\\,0.5\\,]$, $\\alpha = 0.2$。\n- 案例 2：$K=5$, $\\boldsymbol{\\sigma} = [\\,1.0,\\,1.0,\\,1.0,\\,1.0,\\,1.0\\,]$, $\\mathbf{q} = [\\,0.2,\\,0.2,\\,0.2,\\,0.2,\\,0.2\\,]$, $\\mathbf{s} = [\\,1.0,\\,2.0,\\,3.0,\\,4.0,\\,5.0\\,]$, $\\alpha = 0.5$。\n- 案例 3：$K=3$, $\\boldsymbol{\\sigma} = [\\,0.3,\\,1.2,\\,2.0\\,]$, $\\mathbf{q} = [\\,0.2,\\,0.3,\\,0.5\\,]$, $\\mathbf{s} = [\\,3.0,\\,1.5,\\,0.5\\,]$, $\\alpha = 0.9$。\n- 案例 4：$K=3$, $\\boldsymbol{\\sigma} = [\\,0.8,\\,1.5,\\,3.0\\,]$, $\\mathbf{q} = [\\,0.6,\\,0.3,\\,0.1\\,]$, $\\mathbf{s} = [\\,0.5,\\,1.0,\\,3.0\\,]$, $\\alpha = 0.05$。\n- 案例 5：$K=2$, $\\boldsymbol{\\sigma} = [\\,0.2,\\,2.0\\,]$, $\\mathbf{q} = [\\,0.5,\\,0.5\\,]$, $\\mathbf{s} = [\\,5.0,\\,1.0\\,]$, $\\alpha = 0.99$。\n\n最终输出格式：\n- 您的程序应生成单行文本，其中包含一个 Python 风格的列表 $[\\,\\Delta_1,\\,\\Delta_2,\\,\\Delta_3,\\,\\Delta_4,\\,\\Delta_5\\,]$，$\\Delta_j$ 是案例 $j$ 的 $\\Delta(\\alpha)$ 值，顺序与上述相同。每个 $\\Delta_j$ 在打印前必须四舍五入到 6 位小数。例如，格式应严格如 $[x_1,x_2,x_3,x_4,x_5]$，不含空格。\n\n在此设置中，所有答案都是无量纲的，因为阈值 $\\epsilon$ 和差异共享相同的抽象单位并被一致处理；请按规定报告每个案例的实值 $\\Delta(\\alpha)$。不涉及角度单位或百分比。您的程序必须完全自包含，实现一个稳健的单调方程求根器，并且仅使用标准的数值函数。", "solution": "该问题要求计算近似贝叶斯计算 (ABC) 接受阈值的变化量 $\\Delta(\\alpha)$，该变化是由模拟分配策略的改变引起的。这是一个确定性问题，需要在两种不同的分配方案下，通过求解一个关于阈值 $\\epsilon^\\star$ 的非线性方程来解决。\n\n首先，让我们将问题的核心形式化。对于参数网格上一个给定的模拟分配方案 $\\mathbf{a} = \\{a_i\\}_{i=1}^K$，在阈值为 $\\epsilon$ 时的预期总体接受率由以下混合公式给出：\n$$\n\\bar{p}(\\epsilon; \\mathbf{a}) = \\sum_{i=1}^K a_i\\, \\operatorname{erf}\\!\\left(\\frac{\\epsilon}{\\sqrt{2}\\,\\sigma_i}\\right)\n$$\n其中 $\\sigma_i$ 是参数点 $\\theta_i$ 处汇总统计量差异的有效标准差，$\\operatorname{erf}(\\cdot)$ 是误差函数。给定一个目标接受率 $\\alpha \\in (0,1)$，所需的最小阈值 $\\epsilon^\\star(\\mathbf{a};\\alpha)$ 被定义为以下方程的唯一解：\n$$\n\\bar{p}(\\epsilon^\\star; \\mathbf{a}) - \\alpha = 0\n$$\n问题描述正确地指出，$\\bar{p}(\\epsilon; \\mathbf{a})$ 是关于 $\\epsilon \\ge 0$ 的严格单调递增函数，且 $\\bar{p}(0; \\mathbf{a}) = 0$ 以及 $\\lim_{\\epsilon\\to\\infty}\\bar{p}(\\epsilon; \\mathbf{a}) = 1$。这保证了对于任何 $\\alpha \\in (0,1)$，根 $\\epsilon^\\star$ 的存在性和唯一性，使得该问题是适定的。\n\n我们的任务是为两种不同的分配方案找到这个根 $\\epsilon^\\star$：\n1.  一个基线分配 $\\mathbf{a}^{(0)}$，其值被设为给定的先验权重向量 $\\mathbf{q} = \\{q_i\\}_{i=1}^K$。\n2.  一个“最优”分配 $\\mathbf{a}^{(\\mathrm{opt})}$，根据 Neyman 分配原则从一组不确定性得分 $\\{s_i\\}_{i=1}^K$ 中导出：\n    $$\n    a_i^{(\\mathrm{opt})} = \\frac{s_i}{\\sum_{j=1}^K s_j}\n    $$\n\n对于给定的测试用例，我们必须首先计算 $\\epsilon^\\star(\\mathbf{a}^{(0)}; \\alpha)$ 和 $\\epsilon^\\star(\\mathbf{a}^{(\\mathrm{opt})}; \\alpha)$。然后，所求的量，即阈值的预期减少量，是它们的差：\n$$\n\\Delta(\\alpha) = \\epsilon^\\star(\\mathbf{a}^{(0)}; \\alpha) - \\epsilon^\\star(\\mathbf{a}^{(\\mathrm{opt})}; \\alpha)\n$$\n\n核心的算法挑战是求解非线性方程 $\\bar{p}(\\epsilon; \\mathbf{a}) - \\alpha = 0$。鉴于函数 $f(\\epsilon) = \\bar{p}(\\epsilon; \\mathbf{a}) - \\alpha$ 的单调性，这是一个标准的一维求根问题。一个稳健且高效的方法是 Brent-Dekker 算法（如 `scipy.optimize.brentq` 中所实现的），它结合了二分法的确定性以及割线法和反二次插值的速度。要应用此方法，我们必须提供一个区间 $[\\epsilon_{\\text{low}}, \\epsilon_{\\text{high}}]$，使得 $f(\\epsilon_{\\text{low}})$ 和 $f(\\epsilon_{\\text{high}})$ 的符号相反。\n对于任何有效的分配 $\\mathbf{a}$ 和目标 $\\alpha \\in (0,1)$，我们有：\n*   $f(0) = \\bar{p}(0; \\mathbf{a}) - \\alpha = 0 - \\alpha = -\\alpha  0$。\n*   $\\lim_{\\epsilon\\to\\infty} f(\\epsilon) = 1 - \\alpha  0$。\n因此，总能保证在区间 $[0, \\infty)$ 内存在一个根。我们可以选择 $\\epsilon_{\\text{low}} = 0$ 以及一个足够大的 $\\epsilon_{\\text{high}}$ 来确保函数值变为正。\n\n每个测试用例的总体算法如下：\n1.  从输入向量 $\\mathbf{q}$ 和 $\\mathbf{s}$，计算两个分配向量 $\\mathbf{a}^{(0)} = \\mathbf{q}$ 和 $\\mathbf{a}^{(\\mathrm{opt})}$。向量 $\\mathbf{q}$ 已被归一化，而 $\\mathbf{a}^{(\\mathrm{opt})}$ 通过对向量 $\\mathbf{s}$ 进行归一化来构造。\n2.  定义目标函数 $f(\\epsilon, \\mathbf{a}, \\boldsymbol{\\sigma}, \\alpha) = \\left(\\sum_{i=1}^K a_i \\operatorname{erf}\\left(\\frac{\\epsilon}{\\sqrt{2}\\sigma_i}\\right)\\right) - \\alpha$。\n3.  使用一个数值求根器（例如 `scipy.optimize.brentq`）和一个合适的区间（例如 $[0, 1000]$）来求解 $f(\\epsilon, \\mathbf{a}^{(0)}, \\boldsymbol{\\sigma}, \\alpha) = 0$ 以得到 $\\epsilon_0^\\star = \\epsilon^\\star(\\mathbf{a}^{(0)}; \\alpha)$。\n4.  类似地，求解 $f(\\epsilon, \\mathbf{a}^{(\\mathrm{opt})}, \\boldsymbol{\\sigma}, \\alpha) = 0$ 以得到 $\\epsilon_{\\mathrm{opt}}^\\star = \\epsilon^\\star(\\mathbf{a}^{(\\mathrm{opt})}; \\alpha)$。\n5.  计算差值 $\\Delta(\\alpha) = \\epsilon_0^\\star - \\epsilon_{\\mathrm{opt}}^\\star$。\n6.  最终结果按要求四舍五入到 6 位小数。\n\n此过程是确定性的，并依赖于标准的、经过充分验证的数值方法，从而确保了解决方案的准确性和可复现性。实现将使用 `numpy` 进行高效的向量化计算，并使用 `scipy` 来处理误差函数和求根。", "answer": "```python\nimport numpy as np\nfrom scipy.special import erf\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    为五个测试用例计算 ABC 阈值的预期减少量。\n\n    该解决方案涉及为两种不同的模拟分配方案找到一个单调函数的根，并计算这些根的差值。\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (K, sigma, q, s, alpha)\n        (4, [0.5, 0.7, 1.0, 1.5], [0.25, 0.25, 0.25, 0.25], [2.0, 1.5, 1.0, 0.5], 0.2),\n        (5, [1.0, 1.0, 1.0, 1.0, 1.0], [0.2, 0.2, 0.2, 0.2, 0.2], [1.0, 2.0, 3.0, 4.0, 5.0], 0.5),\n        (3, [0.3, 1.2, 2.0], [0.2, 0.3, 0.5], [3.0, 1.5, 0.5], 0.9),\n        (3, [0.8, 1.5, 3.0], [0.6, 0.3, 0.1], [0.5, 1.0, 3.0], 0.05),\n        (2, [0.2, 2.0], [0.5, 0.5], [5.0, 1.0], 0.99)\n    ]\n\n    results = []\n\n    # Define a bracketing interval for the root-finding algorithm.\n    # The lower bound can be 0, where the objective function is -alpha.\n    # The upper bound must be large enough for the function to be positive.\n    # A value of 1000.0 is sufficiently large for all test cases.\n    ROOT_FINDING_BRACKET = [0.0, 1000.0]\n    \n    SQRT2 = np.sqrt(2.0)\n\n    for case in test_cases:\n        K, sigma_list, q_list, s_list, alpha = case\n        \n        # Convert inputs to numpy arrays for vectorized calculations.\n        sigma_vec = np.array(sigma_list)\n        q_vec = np.array(q_list)\n        s_vec = np.array(s_list)\n\n        # Define the objective function whose root (epsilon_star) we seek.\n        # This function computes `p_bar(epsilon) - alpha`.\n        def objective_function(epsilon, allocation_weights, sigma_vals, target_alpha):\n            # Calculate the weighted average acceptance probability p_bar.\n            p_bar = np.sum(allocation_weights * erf(epsilon / (SQRT2 * sigma_vals)))\n            return p_bar - target_alpha\n\n        # 1. Baseline allocation a^(0) = q\n        a_baseline = q_vec\n        \n        # 2. \"Optimal\" allocation a^(opt) from Neyman allocation principle\n        a_optimal = s_vec / np.sum(s_vec)\n        \n        # Find the minimal threshold epsilon_star for the baseline allocation.\n        epsilon_star_baseline = brentq(\n            objective_function,\n            ROOT_FINDING_BRACKET[0],\n            ROOT_FINDING_BRACKET[1],\n            args=(a_baseline, sigma_vec, alpha)\n        )\n        \n        # Find the minimal threshold epsilon_star for the optimal allocation.\n        epsilon_star_optimal = brentq(\n            objective_function,\n            ROOT_FINDING_BRACKET[0],\n            ROOT_FINDING_BRACKET[1],\n            args=(a_optimal, sigma_vec, alpha)\n        )\n        \n        # Compute the threshold reduction, Delta(alpha).\n        delta = epsilon_star_baseline - epsilon_star_optimal\n        \n        # Round the result to 6 decimal places as required.\n        results.append(round(delta, 6))\n\n    # Print the final result in the specified list format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3489634"}]}