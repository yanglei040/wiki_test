{"hands_on_practices": [{"introduction": "在构建模拟器时，首要任务之一是选择合适的方法。本练习旨在对比两种主流的模拟器技术：多项式混沌展开（PCE）和高斯过程（GP）。通过推导PCE对样本量的严格要求，并将其与GP的灵活性进行对比，您将深入理解维度灾难对不同方法的影响，以及它们在计算成本和不确定性量化方面的核心权衡。[@problem_id:3478376]", "problem": "您正在为一个宇宙学可观测量 $y(\\boldsymbol{\\theta})$（例如，固定波数下的非线性物质功率谱）构建一个机器学习模拟器。该可观测量定义在一个有界参数域 $\\Theta \\subset \\mathbb{R}^{d}$上，其中 $\\boldsymbol{\\theta} \\in \\Theta$ 编码了 $d$ 个宇宙学参数。您决定使用非侵入式线性回归，在 $\\Theta$ 中的 $N$ 个不同设计点上进行模型评估（高保真度模拟），以拟合一个总阶数为 $p$ 的多项式混沌展开（PCE）代理模型。假设 $\\Theta$ 上的输入测度是绝对连续且有界的，因此存在一个由多重指标 $\\boldsymbol{\\alpha} \\in \\mathbb{N}_{0}^{d}$ 索引的多元多项式正交基 $\\{\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta})\\}$。您将展开式截断至所有总次数 $\\|\\boldsymbol{\\alpha}\\|_{1} \\le p$ 的多重指标。进一步假设评估是无噪声的，并且设计使得回归设计矩阵在代数上可能的情况下具有满列秩。\n\n从截断的总阶多项式空间的定义以及通过回归唯一确定截断PCE中所有系数的线性代数要求出发，推导用 $d$ 和 $p$ 表示的、唯一识别所有展开系数所需模拟的精确最小数量 $N_{\\min}(d,p)$。\n\n然后，仍然基于第一性原理，讨论在选择此PCE设计与一个在 $d$ 维空间中使用平稳核的高斯过程（GP）模拟器时，在样本复杂度和计算成本方面的关键权衡。讨论内容应包括每种方法如何随 $d$ 和 $p$ 扩展，以及对不确定性量化的影响。您的讨论应是定性的，并基于核心定义和广泛使用的性质进行论证；不要引用任何专门的或预先推导的采样公式。\n\n以单个闭式表达式的形式提供您关于 $N_{\\min}(d,p)$ 的最终答案。不需要进行数值计算。不要包含单位。不要四舍五入。", "solution": "在进行求解之前，对问题陈述的有效性进行了严格评估。\n\n### 步骤 1：提取已知条件\n- 宇宙学可观测量：$y(\\boldsymbol{\\theta})$\n- 参数域：$\\boldsymbol{\\theta} \\in \\Theta \\subset \\mathbb{R}^{d}$\n- 模拟器类型：总阶数为 $p$ 的多项式混沌展开（PCE）。\n- 拟合方法：对 $N$ 次模型评估进行非侵入式线性回归。\n- 设计点：$\\Theta$ 中的 $N$ 个不同点。\n- 输入测度：绝对连续且有界。\n- 多项式基：由 $\\boldsymbol{\\alpha} \\in \\mathbb{N}_{0}^{d}$ 索引的多元多项式正交基 $\\{\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta})\\}$。\n- 截断规则：总次数 $\\|\\boldsymbol{\\alpha}\\|_{1} \\le p$。\n- 评估：无噪声。\n- 设计矩阵：假定在代数上可能的情况下具有满列秩。\n- 第一个目标：推导所需模拟的精确最小数量 $N_{\\min}(d,p)$。\n- 第二个目标：讨论PCE与高斯过程（GP）模拟器在样本复杂度和计算成本方面的权衡，重点关注随 $d$ 和 $p$ 的扩展性以及对不确定性量化的影响。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准对问题进行评估：\n- **科学依据**：该问题在数值宇宙学、不确定性量化和机器学习领域有充分的科学依据。多项式混沌展开和高斯过程是模拟复杂计算机模型的标准、最先进技术。其数学表述是正确且标准的。\n- **良态问题**：该问题是良态的。第一部分要求在清晰且充分的假设下推导一个特定量 $N_{\\min}(d,p)$。设计矩阵具有满列秩的条件是使寻找最小点数问题可解的关键。第二部分要求基于既定原则进行定性但有理有据的讨论，这是一个明确定义的任务。\n- **客观性**：问题以精确、客观、技术性的语言陈述，没有歧义或主观论断。\n- **完整性与一致性**：问题提供了进行推导所需的所有必要信息和定义。这些假设（例如，总阶截断、线性回归、满秩矩阵）是自洽的，并且对于推导是充分的。\n- **可行性与现实性**：所描述的场景是构建代理模型的一个标准（尽管是理想化的）设置。这是该领域的一个基本问题。\n\n问题陈述没有验证清单中列出的任何缺陷。它是科学合理的、良态的、客观的，并且是形式上明确的。\n\n### 步骤 3：结论与行动\n该问题是 **有效的**。将推导解答。\n\n### $N_{\\min}(d,p)$ 的推导\n\n多项式混沌展开（PCE）代理模型 $\\hat{y}(\\boldsymbol{\\theta})$ 近似于真实模型输出 $y(\\boldsymbol{\\theta})$。根据指定的截断方案，展开式包含所有多元多项式 $\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta})$，其中多重指标 $\\boldsymbol{\\alpha} = (\\alpha_1, \\alpha_2, \\ldots, \\alpha_d) \\in \\mathbb{N}_0^d$ 满足其 $L_1$ 范数（总次数）最多为 $p$ 的条件：\n$$ \\hat{y}(\\boldsymbol{\\theta}) = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}} c_{\\boldsymbol{\\alpha}} \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta}) \\quad \\text{其中} \\quad \\mathcal{A} = \\left\\{ \\boldsymbol{\\alpha} \\in \\mathbb{N}_0^d : \\|\\boldsymbol{\\alpha}\\|_1 = \\sum_{i=1}^d \\alpha_i \\le p \\right\\} $$\n待确定的未知量是系数 $\\{c_{\\boldsymbol{\\alpha}}\\}_{\\boldsymbol{\\alpha} \\in \\mathcal{A}}$。为了找到唯一确定这些系数所需的最小模拟次数，我们必须首先求出这些系数的总数。设这个数为 $K = |\\mathcal{A}|$。\n\n求 $K$ 的问题是一个组合问题：计算不等式 $\\alpha_1 + \\alpha_2 + \\ldots + \\alpha_d \\le p$ 的非负整数解的数量。通过引入一个非负松弛变量 $s$，我们可以将此不等式转化为一个方程：\n$$ \\alpha_1 + \\alpha_2 + \\ldots + \\alpha_d + s = p $$\n这是一个经典的“隔板法”问题。我们要求的是将 $p$ 个（“星星”）分配到 $d+1$ 个非负整数箱（变量 $\\alpha_1, \\ldots, \\alpha_d, s$）中的方法数。这等价于排列 $p$ 个星星和 $(d+1)-1 = d$ 个隔板。总的排列方式数，即解的数目，由二项式系数给出：\n$$ K = \\binom{p + (d+1) - 1}{(d+1) - 1} = \\binom{p+d}{d} $$\n因此，有 $K = \\binom{p+d}{d}$ 个系数待确定。\n\n这些系数是通过使用 $N$ 次模拟运行的非侵入式线性回归找到的。我们有 $N$ 个输入-输出对 $(\\boldsymbol{\\theta}_j, y_j)$，其中 $j=1, \\ldots, N$。这建立了一个包含 $N$ 个线性方程的方程组：\n$$ y_j = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}} c_{\\boldsymbol{\\alpha}} \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta}_j), \\quad j=1, \\ldots, N $$\n这可以写成矩阵形式 $\\mathbf{y} = \\mathbf{\\Psi c}$，其中：\n- $\\mathbf{y}$ 是观测到的模拟输出的 $N \\times 1$ 列向量。\n- $\\mathbf{c}$ 是未知PCE系数的 $K \\times 1$ 列向量。\n- $\\mathbf{\\Psi}$ 是 $N \\times K$ 的设计矩阵，其元素为 $\\Psi_{j, \\boldsymbol{\\alpha}} = \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta}_j)$。\n\n为了使系数向量 $\\mathbf{c}$ 被“唯一识别”，线性系统 $\\mathbf{y} = \\mathbf{\\Psi c}$ 必须有唯一解。线性代数的一个基本结果表明，对于一个 $N \\times K$ 的系统，$\\mathbf{c}$ 存在唯一解的充要条件是矩阵 $\\mathbf{\\Psi}$ 具有满列秩，这要求行数大于或等于列数，即 $N \\ge K$。如果 $N  K$，系统是欠定的，$\\mathbf{c}$ 将有无穷多解。\n\n问题陈述中要求假设设计（即点 $\\boldsymbol{\\theta}_j$ 的选择）使得 $\\mathbf{\\Psi}$ 在代数上可能的情况下具有满列秩。使满列秩成为可能的 $N$ 的最小值是 $N=K$。因此，唯一确定所有 $K$ 个系数所需的最小模拟次数是：\n$$ N_{\\min}(d, p) = K = \\binom{p+d}{d} $$\n\n### PCE 与 GP 模拟器权衡的讨论\n\n在此，我们讨论多项式混沌展开（如上所述设计）与高斯过程模拟器之间的权衡。\n\n**样本复杂度和扩展性：**\n\n- **PCE：** 样本复杂度由模型结构严格确定。如上所推导，最小样本数为 $N_{\\min} = \\binom{p+d}{d}$。对于固定的多项式阶数 $p$，当 $d$ 很大时，这个数字随维度 $d$ 多项式增长，即 $N_{\\min} \\propto d^p$。对于固定的维度 $d$，当 $p$ 很大时，它随阶数 $p$ 多项式增长，即 $N_{\\min} \\propto p^d$。这种快速增长，通常被称为“维度灾难”，使得总阶PCE对于中等维度（$d \\gtrsim 10$）和阶数（$p \\gtrsim 3$）的问题变得不切实际，因为所需的高保真度模拟数量会变得过大而令人望而却步。\n- **GP：** GP没有基于其结构参数的样本数 $N$ 的硬性下限。一个GP模型可以用任意数量的点 $N > 0$ 来构建。模拟器的质量（例如，其准确性）随着 $N$ 的增加而提高。然而，GP也受维度灾难的影响，因为参数空间体积随 $d$ 呈指数增长。为了保持给定的采样密度，$N$ 必须指数增长，这意味着在高维空间中对于固定的 $N$，数据点变得非常稀疏。这会降低标准平稳核（例如，平方指数核）的性能，因为它们可能难以学习遥远点之间的相关性。\n\n**计算成本：**\n\n- **PCE：** 通过线性回归拟合PCE的主要计算成本是求解正规方程 $(\\mathbf{\\Psi}^T \\mathbf{\\Psi}) \\mathbf{c} = \\mathbf{\\Psi}^T \\mathbf{y}$。这涉及到对 $K \\times K$ 矩阵 $\\mathbf{\\Psi}^T \\mathbf{\\Psi}$ 求逆，其计算复杂度为 $O(K^3)$，其中 $K = \\binom{p+d}{d}$。因此，训练成本随维度 $d$ 和阶数 $p$ 的增加而急剧增长。然而，一旦系数 $\\mathbf{c}$ 计算出来，进行新的预测就非常快，仅涉及评估一个包含 $K$ 项的多项式和，其计算复杂度为 $O(K)$。\n- **GP：** 训练一个标准GP的主要计算成本是训练数据的 $N \\times N$ 协方差矩阵的求逆，其计算复杂度为 $O(N^3)$。这个成本取决于训练点的数量 $N$，而不直接取决于维度 $d$。对于大数据集（$N \\gg 1000$），这成为主要的瓶颈。在一个新点进行预测需要矩阵-向量运算，对于均值其复杂度为 $O(N)$，对于方差其复杂度为 $O(N^2)$。因此，GP预测在计算上比PCE预测更昂贵。\n\n**对不确定性量化（UQ）的影响：**\n\n- **PCE：** 在所述的非侵入式回归设置中，PCE提供一个确定性的点估计 $\\hat{y}(\\boldsymbol{\\theta})$。它本身不提供对其自身预测（认知）不确定性的度量。要量化对PCE模型本身的置信度，需要使用如自助法（bootstrapping）或交叉验证等外部方法。然而，PCE擅长传播*输入*（偶然）不确定性。如果输入参数 $\\boldsymbol{\\theta}$ 由一个概率分布描述，基多项式的正交性允许对输出 $\\hat{y}$ 的统计矩（例如，均值、方差）进行解析计算。方差就是系数的平方和（不包括常数项），即 $\\text{Var}[\\hat{y}] = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}, \\boldsymbol{\\alpha} \\neq \\mathbf{0}} c_{\\boldsymbol{\\alpha}}^2$。\n- **GP：** UQ是GP框架的一个原生和主要特征。GP是一个概率模型，对于任何新的输入点 $\\boldsymbol{\\theta}_{\\text{new}}$，它都会返回一个完整的后验预测分布（一个高斯分布）。这个分布由一个预测均值（模拟结果）和一个预测方差来表征。这个方差是认知不确定性的度量，它在参数空间中训练数据稀疏的区域自然会增加。这使得GP在像主动学习或贝叶斯优化这样的应用中特别强大，因为这些应用需要对参数空间进行有原则的探索。\n\n总而言之，选择PCE还是GP涉及到一个权衡：PCE具有刚性的全局结构，在高维下有严苛的样本要求但预测速度快；而GP具有灵活的非参数特性，内置UQ功能但对于大的 $N$ 计算成本高。", "answer": "$$\\boxed{\\binom{p+d}{d}}$$", "id": "3478376"}, {"introduction": "一个模拟器的准确性在很大程度上取决于其训练过程，而损失函数的选择是其中的关键。宇宙学可观测量（如物质功率谱）的数值范围可能横跨数个数量级，不恰当的损失函数会导致模型在某些重要尺度上表现不佳。本练习将引导您探讨数据本身的统计特性与最优损失函数之间的联系，以确保在整个动态范围内实现均衡和准确的模拟。[@problem_id:3478347]", "problem": "一个研究团队正在为一个非线性物质功率谱 $P(k,z)$ 构建一个机器学习模拟器。该功率谱的波数范围覆盖了 $R$ 个数量级。该模拟器将被用于一个贝叶斯宇宙学推断流程中，其中分箱谱估计量 $d(k,z)$ 的似然由经过充分检验的噪声模型决定。考虑三种候选的均方训练损失函数，形式如下\n$$\nL_{\\mathrm{abs}} = \\frac{1}{N}\\sum_{i=1}^{N}\\left[\\hat{P}(k_i,z_i)-P(k_i,z_i)\\right]^2,\\qquad\nL_{\\mathrm{rel}} = \\frac{1}{N}\\sum_{i=1}^{N}\\left[\\frac{\\hat{P}(k_i,z_i)-P(k_i,z_i)}{P(k_i,z_i)}\\right]^2,\\qquad\nL_{\\log} = \\frac{1}{N}\\sum_{i=1}^{N}\\left[\\log \\hat{P}(k_i,z_i)-\\log P(k_i,z_i)\\right]^2,\n$$\n其中 $\\hat{P}(k,z)$ 是模拟器的预测值，$P(k,z)$ 是来自高保真模拟的目标值，$N$ 是训练样本的数量，$\\log$ 表示自然对数。假设以下背景和基本事实：\n\n- 在存在样本方差和校准效应的情况下，功率谱的标准估计量方差通常是近似乘性的，这为在固定的 $k$ 和 $z$ 下对 $d(k,z)$ 采用对数正态模型提供了理据：$\\log d(k,z)\\sim \\mathcal{N}(\\log P(k,z),\\sigma^2)$，其中当分数不确定度大致恒定时，$\\sigma$ 在不同的 $k$ 和 $z$ 上近似独立于 $P(k,z)$。\n- 在具有恒定绝对方差的加性高斯噪声模型 $d(k,z)\\sim \\mathcal{N}(P(k,z),\\sigma_{\\mathrm{abs}}^2)$ 下，负对数似然与平方绝对误差成正比。\n- 在感兴趣的定义域内，物质功率谱 $P(k,z)$ 是正的，这确保了 $\\log P(k,z)$ 有良好定义。\n\n基于这些基础，比较 $L_{\\mathrm{abs}}$、$L_{\\mathrm{rel}}$ 和 $L_{\\log}$ 在跨越 $R$ 个数量级的动态范围内对误差进行加权的行为。特别是，确定哪种损失函数在具有恒定分数不确定度的乘性、近似对数正态噪声模型下与最大似然一致，并能在整个动态范围内提供均衡的训练。针对此预期用例，选择最适合训练该模拟器的损失函数，并通过似然模型和损失函数的缩放行为进行推理来证明你的选择。\n\n哪个选项最合适？\n\nA. $L_{\\mathrm{abs}}$ 更可取，因为它对应于具有恒定绝对方差的高斯似然，并将优先处理 $P(k,z)$ 的最高振幅部分，这些部分主导了宇宙学信息。\n\nB. $L_{\\mathrm{rel}}$ 更可取，因为它是尺度不变的，并且与对数正态似然完全匹配，确保了在不同数量级上的均衡训练，而无需计算 $\\log P(k,z)$。\n\nC. $L_{\\log}$ 更可取，因为对数正态似然意味着 $\\log P(k,z)$ 中的高斯性具有恒定方差，因此最小化 $\\log P(k,z)$ 中的平方误差与最大似然一致，并在整个动态范围内产生均衡的加权。\n\nD. 以上都不是；需要一个根据 $k$ 值在 $L_{\\mathrm{abs}}$ 和 $L_{\\mathrm{rel}}$ 之间线性插值的混合损失函数来匹配宇宙方差加权，而这种加权无法在对数空间中捕获。", "solution": "**3. 问题验证：**\n\n*   **步骤1：提取已知条件**\n    *   **目标：**为非线性物质功率谱 $P(k,z)$ 构建一个机器学习模拟器。\n    *   **动态范围：**$P(k,z)$ 跨越 $R$ 个数量级。\n    *   **应用：**该模拟器将用于贝叶斯宇宙学推断流程。\n    *   **似然：**该流程对分箱谱估计量 $d(k,z)$ 使用一个似然，其噪声模型经过充分检验。\n    *   **候选损失函数：**\n        *   绝对损失：$L_{\\mathrm{abs}} = \\frac{1}{N}\\sum_{i=1}^{N}\\left[\\hat{P}(k_i,z_i)-P(k_i,z_i)\\right]^2$\n        *   相对损失：$L_{\\mathrm{rel}} = \\frac{1}{N}\\sum_{i=1}^{N}\\left[\\frac{\\hat{P}(k_i,z_i)-P(k_i,z_i)}{P(k_i,z_i)}\\right]^2$\n        *   对数损失：$L_{\\log} = \\frac{1}{N}\\sum_{i=1}^{N}\\left[\\log \\hat{P}(k_i,z_i)-\\log P(k_i,z_i)\\right]^2$\n    *   **符号：**\n        *   $\\hat{P}(k,z)$：模拟器预测值\n        *   $P(k,z)$：来自高保真模拟的目标值\n        *   $N$：训练样本数量\n        *   $\\log$：自然对数\n    *   **背景/事实：**\n        1.  功率谱的标准估计量方差通常是近似乘性的。这为数据 $d(k,z)$ 在固定 $(k,z)$ 处的对数正态模型提供了理据。\n        2.  模型为 $\\log d(k,z) \\sim \\mathcal{N}(\\log P(k,z), \\sigma^2)$。\n        3.  当分数不确定度大致恒定时，标准差 $\\sigma$ 在不同的 $k$ 和 $z$ 上近似独立于 $P(k,z)$。\n        4.  作为对比，加性高斯噪声模型 $d(k,z) \\sim \\mathcal{N}(P(k,z), \\sigma_{\\mathrm{abs}}^2)$ 的负对数似然与平方绝对误差成正比。\n        5.  $P(k,z)  0$，所以 $\\log P(k,z)$ 有良好定义。\n    *   **问题：**比较三种损失函数在动态范围内对误差加权的行为。确定哪种损失函数在具有恒定分数不确定度的乘性、近似对数正态噪声模型下与最大似然一致，并能提供均衡的训练。选择最合适的损失函数并给出理由。\n\n*   **步骤2：使用提取的已知条件进行验证**\n    *   **科学基础：**是的。问题设置在数值宇宙学这一成熟领域的背景下。物质功率谱 $P(k,z)$、其模拟及其在贝叶斯推断中的应用都是标准课题。所描述的噪声模型（高斯模型、对数正态模型）是宇宙学中使用的标准统计模型。宇宙方差的概念自然地导致了乘性噪声。这些都具有科学合理性。\n    *   **适定性：**是的。问题要求基于所提供的统计模型和背景，对选择三种特定损失函数之一进行比较和论证。目标明确，提供的信息足以做出合理的选择。可以得出一个唯一且有意义的答案。\n    *   **客观性：**是的。语言精确且技术性强。它描述了数学模型，并要求基于这些模型进行逻辑推导。没有主观或基于观点的内容。\n    *   **缺陷清单：**\n        1.  **科学/事实不准确：**否。如前所述，前提是宇宙学中的标准设定。\n        2.  **非形式化/不相关：**否。问题高度形式化，与所述主题直接相关。\n        3.  **不完整/矛盾：**否。问题提供了必要的信息：预期用途（贝叶斯推断）、数据的似然模型（对数正态），以及该模型的属性（对数空间中的恒定方差）。\n        4.  **不现实/不可行：**否。用机器学习模拟功率谱是一个非常活跃的研究领域。所描述的噪声模型和损失函数都是标准的。\n        5.  **不适定/结构不良：**否。术语定义明确（$\\log$ 被指定为自然对数，损失函数由方程给出）。问题是具体的。\n        6.  **故作高深/琐碎：**否。这是一个应用于科学的机器学习中的非琐碎概念性问题。它要求理解损失函数和似然之间的联系，以及它们在大的动态范围内的行为。\n        7.  **超出科学可验证性：**否。这些主张在数学和统计上都是可验证的。\n\n*   **步骤3：结论和行动**\n    *   问题是**有效的**。我将继续进行解题推导和选项分析。\n\n**4. 解题推导：**\n\n*   **目标：**找到最适合训练模拟器 $\\hat{P}(k,z)$ 的损失函数，该模拟器将用于一个贝叶斯流程，其中数据 $d(k,z)$ 由对数正态似然建模。\n\n*   **似然模型：**问题指出，数据 $d(k,z)$ 的似然可以很好地用对数正态分布来近似。它将此模型指定为：\n    $\\log d(k,z) \\sim \\mathcal{N}(\\log P(k,z), \\sigma^2)$\n    这意味着随机变量是 $\\log d$，其均值是 $\\log P$，其方差是 $\\sigma^2$。问题还指出 $\\sigma$ 近似恒定。\n    $\\log d$ 的概率密度函数 (PDF) 是一个高斯分布：\n    $p(\\log d | \\log P, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(\\log d - \\log P)^2}{2\\sigma^2}\\right)$\n\n*   **与训练损失的联系：**在机器学习中，训练可以被构建为一个最大似然估计 (MLE) 问题。我们希望我们模型的预测 $\\hat{P}$ 能够最大化观测到训练数据（我们将其视为基准真相的高保真模拟）的似然。\n    关键的洞见是，模拟器的误差 $\\hat{P}-P$ 理想情况下应遵循与测量误差 $d-P$ 相同的统计分布。如果我们训练模拟器最小化一个等价于数据负对数似然的损失函数，那么模拟器的误差属性将与后续分析流程中假设的属性相匹配。这可以防止“模型不匹配”的情况，即模拟器引入的误差与数据噪声具有不同的统计特性，从而可能使推断产生偏差。\n\n*   **从似然推导损失函数：**\n    问题中的用例是一个具有对数正态数据似然 $d$ 的流程。\n    $d \\sim \\text{Log-Normal}(\\mu = \\log P, \\sigma^2)$\n    这等价于：\n    $\\log d \\sim \\mathcal{N}(\\text{均值} = \\log P, \\text{方差} = \\sigma^2)$\n    单个数据点 $d_i$（在我们的训练案例中，是一个我们视为待预测数据的目标模拟输出 $P_i$）的负对数似然 (NLL) 是：\n    $-\\log p(d_i | P_i) = -\\log \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma^2} d_i} \\exp\\left(-\\frac{(\\log d_i - \\log P_i)^2}{2\\sigma^2}\\right) \\right]$ （这是 $d_i$ 的对数正态分布的PDF）。\n\n    让我们考虑变换后变量 $\\log d_i$ 的负对数似然。这更简单直接。似然是针对数据 $d_i$ 的，但问题将模型指定为 $\\log d(k,z)\\sim \\mathcal{N}(\\log P(k,z),\\sigma^2)$。因此，最大化观测到 $d_i$ 的似然等价于在这个高斯模型下最大化观测到 $\\log d_i$ 的似然。\n\n    给定模型均值 $\\log P_i$，观测到 $\\log d_i$ 的负对数似然是：\n    $-\\log p(\\log d_i | \\log P_i) = -\\log \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(\\log d_i - \\log P_i)^2}{2\\sigma^2}\\right) \\right]$\n    $-\\log p(\\log d_i | \\log P_i) = \\frac{1}{2}\\log(2\\pi\\sigma^2) + \\frac{(\\log d_i - \\log P_i)^2}{2\\sigma^2}$\n\n    为了找到使一组 $N$ 个数据点的似然最大化（或负对数似然最小化）的参数，我们将各个负对数似然相加。如果我们假设数据点是独立的：\n    $\\text{NLL}_{\\text{total}} = \\sum_{i=1}^{N} \\left[ \\frac{1}{2}\\log(2\\pi\\sigma_i^2) + \\frac{(\\log d_i - \\log P_i)^2}{2\\sigma_i^2} \\right]$\n    问题指出 $\\sigma$ 近似恒定，所以 $\\sigma_i = \\sigma$。\n    $\\text{NLL}_{\\text{total}} = \\frac{N}{2}\\log(2\\pi\\sigma^2) + \\frac{1}{2\\sigma^2}\\sum_{i=1}^{N} (\\log d_i - \\log P_i)^2$\n\n    在训练模拟器的背景下，我们的预测 $\\hat{P}$ 扮演模型均值 $P$ 的角色，而高保真模拟输出 $P_{\\text{sim}}$ 扮演数据 $d$ 的角色。关于我们的模型参数（神经网络的权重）最小化负对数似然等价于最小化：\n    $\\sum_{i=1}^{N} (\\log P_{\\text{sim},i} - \\log \\hat{P}_i)^2$\n    这是因为第一项和因子 $1/(2\\sigma^2)$ 相对于模型参数是常数。\n    那么平均损失为：\n    $L = \\frac{1}{N} \\sum_{i=1}^{N} (\\log \\hat{P}_i - \\log P_{\\text{sim},i})^2$\n    这正是 $L_{\\log}$ 的形式。\n\n*   **分析误差加权：**\n    *   **$L_{\\mathrm{abs}}$:** $L_{\\mathrm{abs}} = \\frac{1}{N}\\sum (\\hat{P}-P)^2$。这个损失由 $P$ 值大的区域主导。在 $P = 10^4$ 处 $10\\%$ 的误差对损失的贡献是 $(0.1 \\times 10^4)^2 = 10^6$，而在 $P=10^0$ 处 $10\\%$ 的误差贡献是 $(0.1 \\times 1)^2 = 0.01$。由于 $P(k,z)$ 跨越 $R$ 个数量级，训练将几乎完全集中在正确拟合高 $P$（低 $k$）部分，可能以在低 $P$（高 $k$）部分产生大的*相对*误差为代价。这不是“均衡训练”。该损失对应于 $P$ 上的具有恒定绝对方差的高斯似然，正如问题和选项A中所述。\n\n    *   **$L_{\\mathrm{rel}}$:** $L_{\\mathrm{rel}} = \\frac{1}{N}\\sum \\left(\\frac{\\hat{P}-P}{P}\\right)^2$。这个损失衡量的是平方分数误差。无论 $P$ 的大小如何，$10\\%$ 的误差对总和的贡献都是 $(0.1)^2 = 0.01$。这提供了对整个动态范围内的*分数*误差的均衡加权。现在，让我们研究它与对数正态似然的联系。\n    对于小的分数误差，我们可以使用近似 $\\log(x) \\approx x-1$（当 $x \\approx 1$ 时）。\n    令 $x = \\hat{P}/P$。那么 $\\log(\\hat{P}/P) = \\log\\hat{P} - \\log P$。\n    $\\log\\hat{P} - \\log P \\approx \\frac{\\hat{P}}{P} - 1 = \\frac{\\hat{P}-P}{P}$。\n    因此，对于小误差，$(\\log\\hat{P} - \\log P)^2 \\approx \\left(\\frac{\\hat{P}-P}{P}\\right)^2$。\n    这意味着 $L_{\\log} \\approx L_{\\mathrm{rel}}$。所以 $L_{\\mathrm{rel}}$ 是对数正态MLE损失的一个良好近似，但并不精确。它直接惩罚分数误差，这是均衡训练所期望的行为。\n\n    *   **$L_{\\log}$:** $L_{\\log} = \\frac{1}{N}\\sum (\\log\\hat{P} - \\log P)^2$。如上所述，最小化此损失*完全*等同于在对数空间中具有恒定方差的对数正态模型下执行最大似然估计。这正是问题中描述的情景。对数之差是 $\\log(\\hat{P}/P)$。一个使 $\\hat{P}/P$ 改变某个因子的误差将导致相同的损失项，而与 $P$ 的绝对值无关。例如，一个误差 $\\hat{P} = 1.1 P$ 产生的损失项是 $(\\log 1.1)^2$，无论 $P = 10^4$ 还是 $P=10^0$。这提供了“均衡训练”，即恒定的*分数*误差在所有数量级上受到的惩罚是相等的。这直接满足了要求。\n\n*   **评估选项：**\n\n    *   **A. $L_{\\mathrm{abs}}$ 更可取，因为它对应于具有恒定绝对方差的高斯似然，并将优先处理 $P(k,z)$ 的最高振幅部分，这些部分主导了宇宙学信息。**\n        *   第一部分是正确的：$L_{\\mathrm{abs}}$ 对应于具有恒定绝对方差的高斯似然。\n        *   第二部分也是正确的：它将优先处理 $P(k,z)$ 的最高振幅部分。\n        *   第三部分，“这些部分主导了宇宙学信息”，是一个主观且可能误导的说法。虽然低 $k$ 模的宇宙方差小、信噪比高，但高 $k$ 模包含了关于非线性结构形成、重子物理和 $\\Lambda$CDM 扩展的关键信息。使用一个允许在高 $k$ 处有较大分数误差的损失函数来忽略它们，对于一个通用模拟器来说将是一个糟糕的选择。\n        *   最重要的是，这个选择直接与问题陈述的前提相矛盾，即似然是“近似乘性的，从而支持对数正态模型”。因此，为指定的用例选择基于加性高斯模型的损失是不合适的。\n        *   结论：**错误**。\n\n    *   **B. $L_{\\mathrm{rel}}$ 更可取，因为它是尺度不变的，并且与对数正态似然完全匹配，确保了在不同数量级上的均衡训练，而无需计算 $\\log P(k,z)$。**\n        *   “它是尺度不变的”：是的，在它同等惩罚分数误差的意义上。\n        *   “确保了均衡训练”：是的，如前所述。\n        *   “与对数正态似然完全匹配”：这是不正确的。如上所示，$L_{\\mathrm{rel}}$ 是对数正态模型MLE损失的一个*近似*，仅在小误差时有效。而 $L_{\\log}$ 才是*完全*对应于对数空间中高斯模型的那个。\n        *   “而无需计算 $\\log P(k,z)$”：这是关于公式的一个事实陈述，但不是偏好的有力理由。计算对数是微不足道的。关键点是与似然的数学对应关系。由于匹配不精确，该陈述是有缺陷的。\n        *   结论：**错误**。“完全匹配”的说法是错误的。\n\n    *   **C. $L_{\\log}$ 更可取，因为对数正态似然意味着 $\\log P(k,z)$ 中的高斯性具有恒定方差，因此最小化 $\\log P(k,z)$ 中的平方误差与最大似然一致，并在整个动态范围内产生均衡的加权。**\n        *   “对数正态似然意味着 $\\log P(k,z)$ 中的高斯性具有恒定方差”：这正确地重申了问题的前提：*数据* $d(k,z)$ 的似然模型是对数正态的，这意味着 $\\log d(k,z)$ 是围绕均值 $\\log P(k,z)$ 的高斯分布，其方差 $\\sigma^2$ 被说明为近似恒定。\n        *   “因此最小化 $\\log P(k,z)$ 中的平方误差与最大似然一致”：这是正确的结论。如推导所示，最小化 $\\sum (\\log \\hat{P} - \\log P)^2$ 等价于在假设的模型下最大化训练数据的似然。\n        *   “并在整个动态范围内产生均衡的加权”：这也是正确的。如前所示，该损失对恒定的分数误差给予同等的惩罚，而与 $P$ 的大小无关。\n        *   该陈述的每个部分都是正确的，并且直接从前提推导得出。\n        *   结论：**正确**。\n\n    *   **D. 以上都不是；需要一个根据 $k$ 值在 $L_{\\mathrm{abs}}$ 和 $L_{\\mathrm{rel}}$ 之间线性插值的混合损失函数来匹配宇宙方差加权，而这种加权无法在对数空间中捕获。**\n        *   问题指出噪声模型是*近似*对数正态的，且具有*恒定*的分数不确定度。对于这个给定的模型，$L_{\\log}$ 是理想的损失函数。虽然在现实中，来自宇宙方差的分数不确定度并不完全随 $k$ 恒定，但问题*定义*的背景是这是一个很好的近似。我们必须按照问题的陈述来解决它。\n        *   “而这种加权无法在对数空间中捕获”：这是一个强烈且可能错误的论断。一个更复杂的噪声模型，其中方差 $\\sigma^2$ 是 $k$ 的函数（即 $\\sigma(k)^2$），完全可以在对数空间中处理。相应的损失将是 $L_{\\log}$ 的一个*加权*版本：$\\sum w_i (\\log \\hat{P}_i - \\log P_i)^2$，其中 $w_i \\propto 1/\\sigma(k_i)^2$。所以，即使是更复杂的加权也可以在对数空间中捕获。该选项的前提是有缺陷的。\n        *   问题要求我们根据*给定的*假设，在给出的选项中选择*最合适的*一个。在这些假设下，$L_{\\log}$ 是一个完美的匹配。在更现实的场景中，混合损失可能是一个好主意，但它不是这个问题明确前提所支持的。\n        *   结论：**错误**。该选项引入了问题陈述不支持甚至在某些情况下相矛盾的复杂性和主张。", "answer": "$$\\boxed{C}$$", "id": "3478347"}, {"introduction": "构建模拟器后，我们如何确信其预测的可靠性？评估模拟器的泛化误差是一项微妙的任务，特别是当训练数据点并非独立同分布时。本练习模拟了一个在计算宇宙学中常见的场景：由于昂贵的模拟计算，训练样本在参数空间中呈聚集分布。您需要设计一套严谨的验证方案，以获得对模拟器真实性能的无偏估计，从而学会如何处理由数据相关性带来的挑战。[@problem_id:3478357]", "problem": "您正在构建一个机器学习模拟器，用于模拟以宇宙学参数向量 $\\boldsymbol{\\theta} \\in \\mathbb{R}^6$ 为条件的物质功率谱 $P(k)$。该向量的各分量为 $\\boldsymbol{\\theta} = (\\Omega_{\\mathrm{m}}, \\Omega_{\\mathrm{b}}, h, n_{\\mathrm{s}}, \\sigma_8, w_0)$。该模拟器在固定的波数网格 $k$ 上提供输出 $\\mathbf{y}(\\boldsymbol{\\theta}) \\in \\mathbb{R}^M$。训练设计包含 $N=120$ 次模拟，由于采用了两阶段设计，这些模拟在参数空间中被安排成 $C=10$ 个聚类：8个围绕基准区域的密集聚类和2个位于极端位置的探索性聚类。每个聚类包含 $12$ 个点。距离是相对于一个正定矩阵 $\\mathbf{\\Sigma}^{-1}$（例如，一个受Fisher信息启发的度量）的马氏距离（Mahalanobis metric）来度量的，因此两个参数点之间的距离为\n$$\nd_{\\mathrm{M}}(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = \\sqrt{(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}')^\\top \\mathbf{\\Sigma}^{-1} (\\boldsymbol{\\theta} - \\boldsymbol{\\theta}')}.\n$$\n在每个聚类内部，对于某个相关长度 $\\ell$，所有点对之间的距离都满足 $d_{\\mathrm{M}}(\\boldsymbol{\\theta}_i, \\boldsymbol{\\theta}_j) \\le \\ell/2$；而在聚类之间，距离满足 $d_{\\mathrm{M}}(\\boldsymbol{\\theta}_i, \\boldsymbol{\\theta}_j) \\ge \\ell$。您可以假设模拟器的输出在 $\\gtrsim \\ell$ 的尺度上对于 $\\boldsymbol{\\theta}$ 是平滑的，因此聚类内部的输出是强相关的。\n\n您的目标是，相对于一个目标先验密度 $\\pi(\\boldsymbol{\\theta})$（该密度不等于生成模拟器输入的设计密度 $q(\\boldsymbol{\\theta})$），估计和比较模拟器（例如，高斯过程（GP）或神经网络（NN））的泛化性能。设目标风险为\n$$\nR = \\mathbb{E}_{\\boldsymbol{\\theta} \\sim \\pi}\\left[ L\\!\\left(\\widehat{\\mathbf{y}}(\\boldsymbol{\\theta}), \\mathbf{y}(\\boldsymbol{\\theta})\\right) \\right],\n$$\n对于一个固定的非负损失函数 $L(\\cdot,\\cdot)$，其中 $\\widehat{\\mathbf{y}}(\\boldsymbol{\\theta})$ 是模拟器的预测值。您需要一个评估方案（包括训练/验证/测试集划分和K折交叉验证程序），该方案能够产生对 $R$ 的低偏差估计，并支持可靠的超参数选择，同时要适当地考虑到聚类设计以及 $\\pi \\neq q$ 的情况。\n\n以下哪种评估设计在统计上对实现此目的而言是合理的？选择所有适用项。\n\n- A. 在点的层面上随机将 $N = 120$ 个点划分为80个训练点、20个验证点和20个测试点（忽略聚类成员关系）。在100个非测试点上执行标准的 $K = 10$ 逐点K折交叉验证来选择超参数，并报告在20个测试点上等权重平均的留出测试损失作为 $R$ 的估计值。\n\n- B. 预先保留 $T = 2$ 个完整的聚类作为测试集，选择这些聚类以近似 $\\pi(\\boldsymbol{\\theta})$ 下的高概率质量区域。在剩下的 $C - T = 8$ 个聚类上，执行分组K折交叉验证，其中每个折由完整的聚类构成（即，没有聚类被跨折划分）。在验证折内部使用重要性权重 $w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$，通过最小化加权验证损失来选择超参数。使用选定的超参数在所有 $C - T$ 个训练聚类上重新训练，并报告在2个留出的聚类上的重要性加权测试损失作为 $R$ 的估计值。\n\n- C. 对所有 $C = 10$ 个聚类执行留一聚类交叉验证，使用交叉验证损失（在各聚类上等权重平均）来选择超参数并报告最终性能。不创建单独的测试集，也不使用重要性权重。\n\n- D. 构建一个基于距离分块的K折交叉验证，将点分配到各个折中，使得对于一个折中的任意验证点 $\\boldsymbol{\\theta}_v$，其对应训练集中的所有训练点 $\\boldsymbol{\\theta}_t$ 都满足 $d_{\\mathrm{M}}(\\boldsymbol{\\theta}_v, \\boldsymbol{\\theta}_t) \\ge \\ell$。选择 $K$ 值，使得每个折包含参数空间中的连续区域，而不是许多聚类的碎片。在验证折中使用重要性权重 $w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$ 进行超参数选择。对于最终测试，留出2个空间上连续的聚类或区域，它们与所有训练/验证点不相交，距离满足 $d_{\\mathrm{M}} \\ge \\ell$，并报告在该测试集上的重要性加权损失。\n\n- E. 忽略其他参数和聚类标签，根据 $\\sigma_8$ 和 $w_0$ 的值将 $N = 120$ 个点分箱。在箱内执行逐点的 $K = 10$ 分层K折交叉验证，通过未加权的验证损失选择超参数，并使用一个逐点抽取的随机20点测试集来报告未加权的测试损失。\n\n- F. 从2个探索性聚类中过采样验证点，使得每个折都包含来自所有聚类的相同数量的点。通过在各折上平均未加权的损失来选择超参数，使用选定的超参数在所有 $N = 120$ 个点上重新训练，并报告未加权的交叉验证损失作为最终估计，不使用单独的测试集。", "solution": "问题要求为机器学习模拟器设计一个统计上合理的评估方案。该方案必须能够对目标风险 $R = \\mathbb{E}_{\\boldsymbol{\\theta} \\sim \\pi}\\left[ L\\!\\left(\\widehat{\\mathbf{y}}(\\boldsymbol{\\theta}), \\mathbf{y}(\\boldsymbol{\\theta})\\right) \\right]$ 产生低偏差估计，并能够进行可靠的超参数选择。一个合理的方案必须解决三个主要的统计挑战：\n\n1.  **数据中的依赖性**：训练点不是独立同分布（i.i.d.）的。它们被组织成 $C=10$ 个不同的聚类。在每个聚类内部，点是相近的（$d_{\\mathrm{M}} \\le \\ell/2$），并且模拟器输出 $\\mathbf{y}(\\boldsymbol{\\theta})$ 是平滑的，这意味着邻近点的输出之间存在强相关性。在聚类之间，点是充分分离的（$d_{\\mathrm{M}} \\ge \\ell$）。一个朴素的、逐点的随机划分（划分为训练集和验证/测试集）会将高度相关的点分到划分的两侧。这使得模型能够通过简单地“记忆”或在非常接近的训练样本之间进行插值，从而在验证/测试集上获得人为的低误差，导致对真实泛化误差的评估过于乐观（即被低估）。可交换性的基本假设在点的层面上被违反，但在聚类的层面上成立。因此，任何数据划分（用于交叉验证或最终测试集）都必须在完整聚类的层面上进行，或者更一般地，通过尊重相关性结构的参数空间中的空间块来进行。这确保了验证/测试数据在训练期间对模型来说是真正“未见过”的。\n\n2.  **分布不匹配**：训练数据点 $\\{\\boldsymbol{\\theta}_i\\}$ 是从一个设计密度 $q(\\boldsymbol{\\theta})$ 生成的，但目标风险 $R$ 是相对于一个不同的目标密度 $\\pi(\\boldsymbol{\\theta})$ 定义的。对从 $q(\\boldsymbol{\\theta})$ 抽取的点集上的损失进行未加权经验平均，提供的是 $\\mathbb{E}_{\\boldsymbol{\\theta} \\sim q}[L]$ 的估计，而不是 $\\mathbb{E}_{\\boldsymbol{\\theta} \\sim \\pi}[L]$。为了获得目标风险 $R$ 的低偏差估计，必须使用重要性采样。验证集或测试集中每个点 $\\boldsymbol{\\theta}_i$ 的损失必须通过重要性权重 $w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$ 进行加权。重要性加权的风险估计为 $\\hat{R}_{\\mathrm{IW}} = \\frac{\\sum_i w_i L_i}{\\sum_i w_i}$，如果这些点是从 $q(\\boldsymbol{\\theta})$ 抽取的，那么它就是 $R$ 的一个无偏估计量。\n\n3.  **无偏性能估计**：超参数选择涉及在验证数据上多次训练和评估模型。因此，选定的超参数是适应于验证数据的。如果使用相同的数据报告最终性能（例如，直接报告交叉验证分数），估计将会有过于乐观的偏差。为了获得*最终选定的模型*的泛化性能的真正无偏估计，至关重要的是在一个留出的测试集上对其进行评估，该测试集在训练或超参数选择过程中未以任何方式被使用。\n\n基于这些原则，一个统计上合理的方案必须：\n- 对所有交叉验证和测试集的创建使用分组/分块划分。\n- 在验证集和测试集上都使用重要性加权。\n- 保留一个单独的、留出的测试集用于最终性能评估。\n\n我们现在根据这些标准评估每个选项。\n\n- **A. 在点的层面上随机将 $N = 120$ 个点划分为80个训练点、20个验证点和20个测试点（忽略聚类成员关系）。在100个非测试点上执行标准的 $K = 10$ 逐点K折交叉验证来选择超参数，并报告在20个测试点上等权重平均的留出测试损失作为 $R$ 的估计值。**\n\n该方案在两个关键方面失败。首先，通过执行逐点划分（“忽略聚类成员关系”），它保证了验证集和测试集将包含与训练集高度相关的点。这导致对真实泛化误差的低估。其次，通过使用未加权的平均损失（“等权重平均”），它估计的是关于设计密度 $q(\\boldsymbol{\\theta})$ 的风险，而不是目标密度 $\\pi(\\boldsymbol{\\theta})$，从而导致对 $R$ 的有偏估计。\n\n**结论：** 不正确。\n\n- **B. 预先保留 $T = 2$ 个完整的聚类作为测试集，选择这些聚类以近似 $\\pi(\\boldsymbol{\\theta})$ 下的高概率质量区域。在剩下的 $C - T = 8$ 个聚类上，执行分组K折交叉验证，其中每个折由完整的聚类构成（即，没有聚类被跨折划分）。在验证折内部使用重要性权重 $w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$，通过最小化加权验证损失来选择超参数。使用选定的超参数在所有 $C - T$ 个训练聚类上重新训练，并报告在2个留出的聚类上的重要性加权测试损失作为 $R$ 的估计值。**\n\n该方案正确地解决了所有三个挑战。\n1.  **依赖性：** 它使用基于聚类的划分（“保留 $T=2$ 个完整的聚类”和“分组K折交叉验证，其中每个折由完整的聚类构成”）。这尊重了数据的相关性结构。\n2.  **分布不匹配：** 它正确地采用了重要性权重（“使用重要性权重 $w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$”）用于超参数选择和最终风险估计。\n3.  **无偏估计：** 它使用了一个在超参数调整期间未被触及的、单独的留出测试集。整个流程（划分测试集，用CV选择超参数，重新训练，在测试集上评估）是标准的最佳实践。\n\n**结论：** 正确。\n\n- **C. 对所有 $C = 10$ 个聚类执行留一聚类交叉验证，使用交叉验证损失（在各聚类上等权重平均）来选择超参数并报告最终性能。不创建单独的测试集，也不使用重要性权重。**\n\n该方案有两个主要缺陷。首先，它使用相同的交叉验证程序来选择超参数和报告最终性能。这引入了乐观偏差，因为超参数被选择来优化这个指标本身。需要一个独立的、留出的测试集来进行无偏的最终估计。其次，它不使用重要性权重，因此它估计的是错误的量（$\\mathbb{E}_q[L]$ 而不是 $\\mathbb{E}_{\\pi}[L]$）。尽管留一聚类交叉验证正确地处理了数据依赖性，但其他缺陷使得该程序在统计上不合理。\n\n**结论：** 不正确。\n\n- **D. 构建一个基于距离分块的K折交叉验证，将点分配到各个折中，使得对于一个折中的任意验证点 $\\boldsymbol{\\theta}_v$，其对应训练集中的所有训练点 $\\boldsymbol{\\theta}_t$ 都满足 $d_{\\mathrm{M}}(\\boldsymbol{\\theta}_v, \\boldsymbol{\\theta}_t) \\ge \\ell$。选择 $K$ 值，使得每个折包含参数空间中的连续区域，而不是许多聚类的碎片。在验证折中使用重要性权重 $w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$ 进行超参数选择。对于最终测试，留出2个空间上连续的聚类或区域，它们与所有训练/验证点不相交，距离满足 $d_{\\mathrm{M}} \\ge \\ell$，并报告在该测试集上的重要性加权损失。**\n\n该方案是与选项B中相同原则的更通用、更严谨的实现。\n1.  **依赖性：** 它直接使用距离度量来强制训练集和验证/测试集之间的分离（$d_{\\mathrm{M}} \\ge \\ell$）。这是处理空间相关数据的第一性原理方法，而基于聚类的划分是其一个具体实例。\n2.  **分布不匹配：** 它正确地使用了重要性权重进行超参数选择和最终评估。\n3.  **无偏估计：** 它正确地使用了留出的测试集（“留出2个空间上连续的聚类或区域”），该测试集与训练数据保持了所需空间分离。\n\n这个设计在统计上是合理且稳健的。\n\n**结论：** 正确。\n\n- **E. 忽略其他参数和聚类标签，根据 $\\sigma_8$ 和 $w_0$ 的值将 $N = 120$ 个点分箱。在箱内执行逐点的 $K = 10$ 分层K折交叉验证，通过未加权的验证损失选择超参数，并使用一个逐点抽取的随机20点测试集来报告未加权的测试损失。**\n\n该方案是有缺陷的。在参数子集上进行分层并不能解决由6维参数空间中的聚类引起的相关性的主要问题。通过忽略聚类标签并执行逐点划分，它遭受了与选项A相同的乐观偏差。此外，它没有使用重要性权重，导致对目标风险 $R$ 的有偏估计。\n\n**结论：** 不正确。\n\n- **F. 从2个探索性聚类中过采样验证点，使得每个折都包含来自所有聚类的相同数量的点。通过在各折上平均未加权的损失来选择超参数，使用选定的超参数在所有 $N = 120$ 个点上重新训练，并报告未加权的交叉验证损失作为最终估计，不使用单独的测试集。**\n\n该方案在多个方面都是不合理的。首先，它不使用单独的测试集，将CV损失报告为最终估计，这是有偏的。其次，所提出的划分方案（“每个折都包含来自所有聚类的相同数量的点”）需要打破聚类，这违反了在划分期间保持相关数据组完整的原则。第三，它使用未加权的损失，未能解决分布不匹配问题。过采样是一种临时的(ad-hoc)程序，不像重要性加权那样是基于原则的方法。\n\n**结论：** 不正确。\n\n总之，选项B和D都描述了统计上合理的方法，它们正确地处理了数据依赖性、分布偏移以及对无偏性能估计的需求。", "answer": "$$\\boxed{BD}$$", "id": "3478357"}]}