{"hands_on_practices": [{"introduction": "粗粒化建模的一个关键目标是创建具有*可移植性* (transferability) 的模型，即模型不仅在训练时所用的状态点上表现准确，而且在一系列不同的状态点（如密度或温度）下依然有效。[@problem_id:3456625] 这项实践将通过一个具体的例子，展示一种实现此目标的强大技术。你将通过同时在多个密度的数据上训练模型，来学习如何显著提高模型的泛化能力。", "problem": "考虑将分子动力学中的自上而下粗粒化方法构建为最小化目标分布与粗粒化模型分布之间的 Kullback–Leibler 散度（相对熵）的问题。从正则系综出发：在温度 $T$ 下，一个具有势能 $U$ 的微观态的概率密度正比于 $\\exp(-\\beta U)$，其中 $\\beta = 1/(k_\\mathrm{B} T)$，$k_\\mathrm{B}$ 是玻尔兹曼常数。在均匀各向同性流体中，通过使用球坐标，对间距的分布可以简化为对标量距离 $r$ 的一维积分。从笛卡尔坐标到球坐标的坐标变换的雅可比行列式引入了一个与 $4\\pi r^2$ 成正比的测度因子，因此任何径向对分布都必须对测度 $r^2 \\, \\mathrm{d}r$ 进行积分，其整体常数在归一化概率中会被抵消。\n\n我们采用约化 Lennard–Jones 单位：设 $k_\\mathrm{B} = 1$ 和 $T = 1$，从而 $\\beta = 1$；距离 $r$ 以物种特定的 Lennard-Jones 长度尺度 $\\sigma_\\mathrm{ref}$ 为单位；数密度 $\\rho$ 以 $\\sigma_\\mathrm{ref}^{-3}$ 为单位。能量以 $k_\\mathrm{B} T$ 为单位，是无量纲的。每种稀有气体的参考微观相互作用由 Lennard-Jones 势近似表示：$U_\\mathrm{ref}(r) = 4 \\epsilon_\\mathrm{ref} \\left[ \\left( \\frac{1}{r} \\right)^{12} - \\left( \\frac{1}{r} \\right)^6 \\right]$，其中 $\\epsilon_\\mathrm{ref}$ 是以 $k_\\mathrm{B} T$ 为单位的物种特定势阱深度，而 $\\sigma_\\mathrm{ref}$ 已被吸收到约化坐标 $r$ 中（即，在约化单位中 $\\sigma_\\mathrm{ref} = 1$）。为了在有限密度下捕捉多体关联的密度依赖性，通过平均场修正来近似平均力势 $W(r; \\rho)$：$W(r; \\rho) = U_\\mathrm{ref}(r) + \\rho C \\exp\\!\\left( - \\frac{r}{\\lambda} \\right)$，其中 $C$ 和 $\\lambda$ 是物种特定的常数，满足 $C>0$ 和 $\\lambda>0$。该近似通过反映拥挤效应会增加将粒子聚集在一起的有效自由能惩罚，从而保持了科学真实性。\n\n定义一个由 $\\theta = (\\epsilon, \\sigma)$ 参数化的粗粒化模型势 $U_\\theta(r) = 4 \\epsilon \\left[ \\left( \\frac{\\sigma}{r} \\right)^{12} - \\left( \\frac{\\sigma}{r} \\right)^6 \\right]$，其中 $\\epsilon > 0$ 且 $\\sigma > 0$。在平均场近似下，密度为 $\\rho$ 时的归一化目标径向分布是一个关于 $r$ 的概率密度，其正比于 $r^2 \\exp\\!\\left( - W(r; \\rho) \\right)$；而归一化的粗粒化模型分布则正比于 $r^2 \\exp\\!\\left( - U_\\theta(r) \\right)$。为确保使用正确的测度，雅可比因子 $r^2$ 必须包含在这两个分布中。\n\n您的任务是：\n- 从第一性原理出发，推导多密度相对熵目标函数，该函数是对多个密度下的 Kullback–Leibler 散度求和。需明确展示球面雅可比因子如何进入积分，以及如何强制执行归一化。\n- 使用以上推导，设计一个数值方案，在均匀网格上使用梯形积分法，将积分在有限区间 $[r_\\min, r_\\max]$ 上离散化。选择的 $r_\\min$ 和 $r_\\max$ 需能解析 Lennard-Jones 核心，且分布的尾部可以忽略不计。\n- 通过最小化在 $\\rho_0$ 处相对于 $\\theta$ 的相对熵，对单一密度 $\\rho_0$ 进行 $U_\\theta$ 拟合（单密度拟合）。\n- 通过最小化在 $\\rho_0$ 和 $\\rho_1$ 两处的相对熵之和（相对于同一个 $\\theta$），提出并实现一个多密度相对熵拟合，从而通过正确考虑雅可比重加权来改善跨密度的泛化能力。\n- 通过使用单密度拟合和多密度拟合得到的 $\\theta$ 计算在 $\\rho_1$ 处的测试相对熵，来量化可迁移性，并报告定义为这两个测试散度之差的改善值。\n\n使用以下物种和参数的测试套件，所有参数均采用上述约化单位：\n- 物种 1 (Argon): $\\epsilon_\\mathrm{ref} = 1.0$, $C = 0.25 \\epsilon_\\mathrm{ref}$, $\\lambda = 1.5$, $\\rho_0 = 0.01$, $\\rho_1 = 0.05$。\n- 物种 2 (Krypton): $\\epsilon_\\mathrm{ref} = 1.3$, $C = 0.25 \\epsilon_\\mathrm{ref}$, $\\lambda = 1.5$, $\\rho_0 = 0.02$, $\\rho_1 = 0.02$。\n- 物种 3 (Xenon): $\\epsilon_\\mathrm{ref} = 1.7$, $C = 0.25 \\epsilon_\\mathrm{ref}$, $\\lambda = 1.5$, $\\rho_0 = 0.015$, $\\rho_1 = 0.08$。\n\n对于数值积分，取 $r_\\min = 0.85$ 和 $r_\\max = 4.0$，并使用具有足够多点数的均匀网格以精确解析分布。将粗粒化参数约束在 $0.5 \\le \\epsilon \\le 3.0$ 和 $0.8 \\le \\sigma \\le 1.2$ 范围内，并从初始猜测值 $\\epsilon = 0.8$ 和 $\\sigma = 1.05$ 开始优化。\n\n您的程序必须为每种物种实现以下步骤：\n1. 使用 $W(r; \\rho)$ 和雅可比因子 $r^2$ 构建在 $\\rho_0$ 和 $\\rho_1$ 处的归一化目标径向分布。\n2. 通过最小化在 $\\rho_0$ 处相对于 $\\theta$ 的相对熵，执行单密度拟合。\n3. 通过最小化在 $\\rho_0$ 和 $\\rho_1$ 两处的相对熵之和（相对于 $\\theta$），执行多密度拟合。\n4. 对两个拟合出的 $\\theta$ 值，计算在 $\\rho_1$ 处的测试相对熵。\n5. 计算改善值，即单密度测试相对熵与多密度测试相对熵之差。\n\n不使用角度单位。在上述约化单位中，所有物理量都是无量纲的。每种物种所需的最终输出必须是浮点数。您的程序应生成单行输出，其中包含一个由三个列表组成的逗号分隔列表，每个内部列表对应一种物种，并按顺序包含三个浮点数：$[D_\\mathrm{single}(\\rho_1), D_\\mathrm{multi}(\\rho_1), \\Delta]$，其中 $D_\\mathrm{single}(\\rho_1)$ 是单密度拟合在 $\\rho_1$ 处的测试相对熵，$D_\\mathrm{multi}(\\rho_1)$ 是多密度拟合在 $\\rho_1$ 处的测试相对熵，$\\Delta$ 是定义为 $D_\\mathrm{single}(\\rho_1) - D_\\mathrm{multi}(\\rho_1)$ 的改善值。将每个浮点数打印并四舍五入到六位小数。例如，输出格式必须与以下完全一样：`[[0.123456,0.123000,0.000456],[\\dots],[\\dots]]`。", "solution": "该问题要求设计并实现一个数值方案，使用相对熵最小化的方法对分子相互作用势进行粗粒化。该过程涉及将一个由 $\\theta = (\\epsilon, \\sigma)$ 参数化的简单 Lennard-Jones 势，拟合到一个更复杂的、依赖于密度的目标平均力势。拟合的质量通过其在不同密度间的可迁移性来评估。\n\n### 目标函数的推导\n\n我们从正则系综中的统计力学原理出发。找到一个能量为 $E$ 的微观态系统的概率密度正比于 $\\exp(-\\beta E)$，其中 $\\beta = 1/(k_\\mathrm{B} T)$。在指定的约化单位中，$\\beta=1$。\n\n对于均匀各向同性流体，在标量分离距离 $r$ 处找到一对粒子的概率由径向分布函数描述。概率密度必须考虑对应于 $r$ 和 $r+\\mathrm{d}r$ 之间分离的球壳体积，该体积与 $4\\pi r^2 \\, \\mathrm{d}r$ 成正比。因此，任何径向概率密度函数都必须由一个与 $r^2$ 成正比的雅可比因子加权。\n\n令 $P(r; \\rho)$ 为在给定数密度 $\\rho$ 下粒子间距 $r$ 的目标概率密度。该分布由平均力势 $W(r; \\rho)$ 导出。未归一化的密度正比于雅可比因子和玻尔兹曼因子的乘积：\n$$p'(r; \\rho) = r^2 \\exp(-W(r; \\rho))$$\n归一化常数，或称配分函数，$Z_p(\\rho)$，是全空间上的积分：\n$$Z_p(\\rho) = \\int_0^\\infty r^2 \\exp(-W(r; \\rho)) \\, \\mathrm{d}r$$\n归一化目标概率密度为：\n$$P(r; \\rho) = \\frac{1}{Z_p(\\rho)} r^2 \\exp(-W(r; \\rho))$$\n\n类似地，对于参数为 $\\theta = (\\epsilon, \\sigma)$ 的粗粒化模型势 $U_\\theta(r)$，归一化的模型概率密度为：\n$$Q_\\theta(r) = \\frac{1}{Z_q(\\theta)} r^2 \\exp(-U_\\theta(r))$$\n其中模型配分函数为：\n$$Z_q(\\theta) = \\int_0^\\infty r^2 \\exp(-U_\\theta(r)) \\, \\mathrm{d}r$$\n\n自上而下粗粒化的目标是找到最优参数 $\\theta$，使模型分布 $Q_\\theta(r)$ 尽可能接近目标分布 $P(r; \\rho)$。接近程度由 Kullback–Leibler (KL) 散度（或相对熵）$D_\\mathrm{KL}(P || Q_\\theta)$ 来量化。\n$$D_\\mathrm{KL}(P || Q_\\theta) = \\int_0^\\infty P(r; \\rho) \\log\\left(\\frac{P(r; \\rho)}{Q_\\theta(r)}\\right) \\, \\mathrm{d}r$$\n最小化 KL 散度等价于在给定目标数据的情况下最大化模型的似然。我们可以将 KL 散度重写为：\n$$D_\\mathrm{KL}(P || Q_\\theta) = \\int_0^\\infty P(r; \\rho) \\log(P(r; \\rho)) \\, \\mathrm{d}r - \\int_0^\\infty P(r; \\rho) \\log(Q_\\theta(r)) \\, \\mathrm{d}r$$\n第一项 $\\int P \\log P$ 是目标分布的负熵，相对于模型参数 $\\theta$ 是一个常数。因此，最小化 $D_\\mathrm{KL}$ 等价于最小化交叉熵项 $-\\int P \\log Q_\\theta$。我们来分析这一项：\n$$-\\int_0^\\infty P(r; \\rho) \\log\\left(\\frac{1}{Z_q(\\theta)} r^2 \\exp(-U_\\theta(r))\\right) \\, \\mathrm{d}r$$\n$$= -\\int_0^\\infty P(r; \\rho) \\left( \\log(r^2) - U_\\theta(r) - \\log(Z_q(\\theta)) \\right) \\, \\mathrm{d}r$$\n$$= -\\langle \\log(r^2) \\rangle_P + \\langle U_\\theta(r) \\rangle_P + \\log(Z_q(\\theta))$$\n其中 $\\langle \\cdot \\rangle_P$ 表示在分布 $P(r; \\rho)$ 上的期望值。项 $-\\langle \\log(r^2) \\rangle_P$ 也与 $\\theta$ 无关。因此，需要对 $\\theta$ 最小化的目标函数 $S(\\theta; \\rho)$ 是：\n$$S(\\theta; \\rho) = \\langle U_\\theta(r) \\rangle_P + \\log(Z_q(\\theta))$$\n$$S(\\theta; \\rho) = \\int_0^\\infty P(r; \\rho) U_\\theta(r) \\, \\mathrm{d}r + \\log\\left( \\int_0^\\infty r^2 \\exp(-U_\\theta(r)) \\, \\mathrm{d}r \\right)$$\n这是单密度拟合的目标函数。\n\n对于多密度拟合，我们寻求一组能在多个密度（此处为 $\\rho_0$ 和 $\\rho_1$）下都表现良好的参数 $\\theta$。目标是各个相对熵之和：\n$$D_\\mathrm{total}(\\theta) = D_\\mathrm{KL}(P_0 || Q_\\theta) + D_\\mathrm{KL}(P_1 || Q_\\theta)$$\n其中 $P_0$ 和 $P_1$ 分别是密度为 $\\rho_0$ 和 $\\rho_1$ 时的目标分布。模型分布 $Q_\\theta$ 与密度无关。遵循相同的逻辑，最小化 $D_\\mathrm{total}(\\theta)$ 等价于最小化相应目标函数 $S(\\theta; \\rho)$ 的和：\n$$S_\\mathrm{multi}(\\theta) = S(\\theta; \\rho_0) + S(\\theta; \\rho_1)$$\n$$S_\\mathrm{multi}(\\theta) = \\left( \\langle U_\\theta \\rangle_{P_0} + \\log(Z_q(\\theta)) \\right) + \\left( \\langle U_\\theta \\rangle_{P_1} + \\log(Z_q(\\theta)) \\right)$$\n$$S_\\mathrm{multi}(\\theta) = \\langle U_\\theta \\rangle_{P_0} + \\langle U_\\theta \\rangle_{P_1} + 2 \\log(Z_q(\\theta))$$\n这是用于多密度优化的最终目标函数。\n\n### 数值实现策略\n\n1.  **离散化**：将 $r \\in [r_\\min, r_\\max]$ 上的连续积分在一个具有 $N$ 个点、间距为 $\\Delta r$ 的均匀网格上离散化。使用梯形法则进行数值积分，具体实现如 `numpy.trapz` 所示。为保证精度，选择一个足够大的 $N$ (例如 $N=2048$)。\n\n2.  **势函数**：势被实现为 Python 函数：\n    - 目标势：$W(r; \\rho) = 4 \\epsilon_\\mathrm{ref} \\left[ r^{-12} - r^{-6} \\right] + \\rho C \\exp(-r/\\lambda)$。\n    - 模型势：$U_\\theta(r) = 4 \\epsilon \\left[ (\\sigma/r)^{12} - (\\sigma/r)^6 \\right]$。\n\n3.  **目标分布**：对于每个密度 $\\rho_0$ 和 $\\rho_1$，通过数值积分 $r^2 \\exp(-W(r; \\rho))$ 求得 $Z_p(\\rho)$，然后进行归一化，预先计算出相应的归一化目标分布 $P(r; \\rho)$。\n\n4.  **优化**：使用 `scipy.optimize.minimize` 函数及 `L-BFGS-B` 方法，在给定边界条件下，找到最小化目标函数的最优参数 $\\theta = (\\epsilon, \\sigma)$。\n    - **单密度拟合**：最小化 $S(\\theta; \\rho_0)$ 以找到 $\\theta_\\mathrm{single}$。\n    - **多密度拟合**：最小化 $S_\\mathrm{multi}(\\theta)$ 以找到 $\\theta_\\mathrm{multi}$。\n\n5.  **评估**：\n    - 使用 $\\theta_\\mathrm{single}$ 计算模型分布 $Q_{\\theta_\\mathrm{single}}(r)$。然后计算测试相对熵为 $D_\\mathrm{single}(\\rho_1) = D_\\mathrm{KL}(P_1 || Q_{\\theta_\\mathrm{single}})$。\n    - 使用 $\\theta_\\mathrm{multi}$ 计算模型分布 $Q_{\\theta_\\mathrm{multi}}(r)$。然后计算测试相对熵为 $D_\\mathrm{multi}(\\rho_1) = D_\\mathrm{KL}(P_1 || Q_{\\theta_\\mathrm{multi}})$。\n    - 改善值为 $\\Delta = D_\\mathrm{single}(\\rho_1) - D_\\mathrm{multi}(\\rho_1)$。对于 Krypton 的情况，其中 $\\rho_0 = \\rho_1$，我们预期 $\\theta_\\mathrm{single} = \\theta_\\mathrm{multi}$ 且 $\\Delta = 0$，这为实现提供了一个合理性检查。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves the multi-density coarse-graining problem for three noble gas species.\n    \"\"\"\n    # Numerical integration and optimization parameters\n    r_min = 0.85\n    r_max = 4.0\n    num_points = 2048\n    r_grid = np.linspace(r_min, r_max, num_points)\n    \n    initial_guess = [0.8, 1.05]  # [epsilon, sigma]\n    bounds = [(0.5, 3.0), (0.8, 1.2)] # Bounds for [epsilon, sigma]\n\n    test_cases = [\n        {'name': 'Argon', 'eps_ref': 1.0, 'c_factor': 0.25, 'lambda_val': 1.5, 'rho0': 0.01, 'rho1': 0.05},\n        {'name': 'Krypton', 'eps_ref': 1.3, 'c_factor': 0.25, 'lambda_val': 1.5, 'rho0': 0.02, 'rho1': 0.02},\n        {'name': 'Xenon', 'eps_ref': 1.7, 'c_factor': 0.25, 'lambda_val': 1.5, 'rho0': 0.015, 'rho1': 0.08},\n    ]\n\n    all_results = []\n\n    # --- Potential and Distribution Functions ---\n    def U_ref(r, eps_ref):\n        r_inv = 1.0 / r\n        r6_inv = r_inv**6\n        return 4.0 * eps_ref * (r6_inv**2 - r6_inv)\n\n    def W_pmf(r, rho, eps_ref, C, lambda_val):\n        return U_ref(r, eps_ref) + rho * C * np.exp(-r / lambda_val)\n\n    def U_theta(r, eps, sig):\n        r_inv_scaled = sig / r\n        r6_inv_scaled = r_inv_scaled**6\n        return 4.0 * eps * (r6_inv_scaled**2 - r6_inv_scaled)\n\n    def get_normalized_dist(potential_func, r_grid, params):\n        V_r = potential_func(r_grid, *params)\n        V_r_clipped = np.clip(V_r, -700, 700)\n        p_unnorm = r_grid**2 * np.exp(-V_r_clipped)\n        Z = np.trapz(p_unnorm, r_grid)\n        if Z == 0:\n            return np.full_like(r_grid, 1e-12), Z\n        return p_unnorm / Z, Z\n\n    def objective_function(theta, r_grid, target_dists):\n        epsilon, sigma = theta\n        U_theta_vals = U_theta(r_grid, epsilon, sigma)\n        U_theta_clipped = np.clip(U_theta_vals, -700, 700)\n        q_unnorm = r_grid**2 * np.exp(-U_theta_clipped)\n        Z_q = np.trapz(q_unnorm, r_grid)\n        if Z_q == 0:\n            return np.inf\n        log_Z_q = np.log(Z_q)\n        \n        s_val = 0\n        for dist in target_dists:\n            avg_U = np.trapz(dist * U_theta_vals, r_grid)\n            s_val += avg_U\n        \n        s_val += len(target_dists) * log_Z_q\n        return s_val\n\n    def calculate_kl_divergence(p_dist, q_dist, r_grid):\n        integrand = p_dist * (np.log(p_dist + 1e-12) - np.log(q_dist + 1e-12))\n        return np.trapz(integrand, r_grid)\n\n    for case in test_cases:\n        C = case['eps_ref'] * case['c_factor']\n        \n        # 1. Build target distributions\n        P0_dist, _ = get_normalized_dist(W_pmf, r_grid, (case['rho0'], case['eps_ref'], C, case['lambda_val']))\n        P1_dist, _ = get_normalized_dist(W_pmf, r_grid, (case['rho1'], case['eps_ref'], C, case['lambda_val']))\n\n        # 2. Single-density fit\n        res_single = minimize(objective_function, initial_guess, args=(r_grid, [P0_dist]), method='L-BFGS-B', bounds=bounds)\n        theta_single = res_single.x\n        \n        # 3. Multi-density fit\n        res_multi = minimize(objective_function, initial_guess, args=(r_grid, [P0_dist, P1_dist]), method='L-BFGS-B', bounds=bounds)\n        theta_multi = res_multi.x\n\n        # 4. Evaluate test KL divergences\n        Q_single_dist, _ = get_normalized_dist(U_theta, r_grid, (theta_single[0], theta_single[1]))\n        D_single_rho1 = calculate_kl_divergence(P1_dist, Q_single_dist, r_grid)\n\n        Q_multi_dist, _ = get_normalized_dist(U_theta, r_grid, (theta_multi[0], theta_multi[1]))\n        D_multi_rho1 = calculate_kl_divergence(P1_dist, Q_multi_dist, r_grid)\n\n        # 5. Calculate improvement\n        improvement = D_single_rho1 - D_multi_rho1\n        \n        all_results.append([D_single_rho1, D_multi_rho1, improvement])\n\n    # Format output\n    output_str = \"[\"\n    for i, result in enumerate(all_results):\n        output_str += f\"[{result[0]:.6f},{result[1]:.6f},{result[2]:.6f}]\"\n        if i  len(all_results) - 1:\n            output_str += \",\"\n    output_str += \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3456625"}, {"introduction": "在了解了如何通过多状态点训练来提升模型可移植性之后，我们来探讨模型设计本身所面临的一个关键挑战。[@problem_id:3456623] 本练习通过一个清晰的假设情景阐明，一个为了在特定状态点完美再现结构性质而优化的粗粒化模型，可能在预测其他关键物理性质（如压力或可压缩性）方面表现糟糕。这突显了在选择势函数形式时，必须包含所有相关的物理依赖关系（例如与体积相关的项）的重要性。", "problem": "考虑一个统计力学中简化的自上而下的粗粒化实验，旨在分离粗粒化势中与体积相关的项的作用。设标量集体坐标表示为 $x \\in \\mathbb{R}$，系统体积表示为 $V \\in \\mathbb{R}$。参考系统在等温等压系综中由以下势能定义：\n$$\nU_{\\mathrm{ref}}(x,V) \\;=\\; \\tfrac{1}{2}\\,a\\,x^{2} \\;+\\; \\tfrac{1}{4}\\,\\lambda\\,x^{4} \\;+\\; \\tfrac{1}{2}\\,c\\,(V - V_{0})^{2} \\;+\\; P_{0}\\,V,\n$$\n逆温度 $\\beta = 1$。其中 $a0$，$\\lambda0$，$c0$，$P_{0}$ 和 $V_{0}$ 是固定的无量纲参数。联合目标分布为：\n$$\np_{\\mathrm{ref}}(x,V) \\;\\propto\\; \\exp\\!\\big(-U_{\\mathrm{ref}}(x,V)\\big).\n$$\n\n假设粗粒化模型通过在固定体积 $V=V_{0}$ 的构型上最小化参考分布与模型分布之间的Kullback–Leibler (KL) 散度进行训练，即目标函数比较 $x$ 在 $V=V_{0}$ 处的边缘分布：\n$$\nD_{\\mathrm{KL}}\\big(p_{\\mathrm{ref}}(x)\\,\\|\\,q_{\\theta}(x)\\big)\n\\;=\\;\n\\int_{\\mathbb{R}} p_{\\mathrm{ref}}(x)\\,\\log\\!\\frac{p_{\\mathrm{ref}}(x)}{q_{\\theta}(x)}\\,dx,\n$$\n其中\n$$\np_{\\mathrm{ref}}(x) \\;\\propto\\; \\exp\\!\\Big(-\\tfrac{1}{2}\\,a\\,x^{2} - \\tfrac{1}{4}\\,\\lambda\\,x^{4}\\Big), \\quad\nq_{\\theta}(x) \\;\\propto\\; \\exp\\!\\Big(-\\tfrac{1}{2}\\,\\theta\\,x^{2} - \\tfrac{1}{4}\\,\\lambda\\,x^{4}\\Big).\n$$\n请注意，训练目标有意不包括 $V$。\n\n我们将比较两种粗粒化模型类别。\n\n- 模型 A（无显式体积项）：$U^{\\mathrm{A}}_{\\theta}(x) = \\tfrac{1}{2}\\,\\theta\\,x^{2} + \\tfrac{1}{4}\\,\\lambda\\,x^{4}$。此模型通过最小化 $D_{\\mathrm{KL}}\\big(p_{\\mathrm{ref}}(x)\\,\\|\\,q_{\\theta}(x)\\big)$ 对 $\\theta$ 进行拟合。因为 $q_{\\theta}(x)$ 与 $p_{\\mathrm{ref}}(x)$ 共享四次项系数 $\\lambda$，所以KL目标的最小值点出现在 $\\theta = a$，这使得 $q_{\\theta}(x)$ 在该切片中等于 $p_{\\mathrm{ref}}(x)$，因此在精确算术中 $D_{\\mathrm{KL}}=0$。\n\n- 模型 B（与相同能量尺度相关的显式体积依赖项）：$U^{\\mathrm{B}}_{\\theta}(x,V) = \\tfrac{1}{2}\\,\\theta\\,x^{2} + \\tfrac{1}{4}\\,\\lambda\\,x^{4} + \\tfrac{1}{2}\\,\\theta^{2}\\,(V - V_{0})^{2} + P_{\\mathrm{fit}}\\,V$。此选择编码了一种耦合，其中单个参数 $\\theta$ 同时固定了 $x$ 的曲率和相对于 $V$ 的曲率。为了匹配 $V_{0}$ 处的等温压缩率和机械压力，需要选择 $\\theta=\\sqrt{c}$ 和 $P_{\\mathrm{fit}}=P_{0}$，这反过来将模型在 $V_{0}$ 处的 $x$-边缘分布固定为 $q_{\\sqrt{c}}(x) \\propto \\exp\\!\\big(-\\tfrac{1}{2}\\sqrt{c}\\,x^{2} - \\tfrac{1}{4}\\,\\lambda\\,x^{4}\\big)$。\n\n定义在 $V=V_{0}$ 处评估的以下性质度量：\n\n- $x$ 中的训练目标值：模型 A 为 $D_{\\mathrm{KL}}^{\\mathrm{A}} = D_{\\mathrm{KL}}\\big(p_{\\mathrm{ref}}(x)\\,\\|\\,q_{a}(x)\\big)$，模型 B 为 $D_{\\mathrm{KL}}^{\\mathrm{B}} = D_{\\mathrm{KL}}\\big(p_{\\mathrm{ref}}(x)\\,\\|\\,q_{\\sqrt{c}}(x)\\big)$。\n\n- 固定体积下的压力（仅使用显式 $V$ 依赖性的机械定义）：$P_{\\mathrm{mech}} = -\\big\\langle \\partial U/\\partial V \\big\\rangle_{V=V_{0}}$。在模型 A 下，$U^{\\mathrm{A}}_{\\theta}$ 不依赖于 $V$，因此 $P_{\\mathrm{mech}}^{\\mathrm{A}}=0$。在模型 B 下，当 $P_{\\mathrm{fit}}=P_{0}$ 时，$V=V_{0}$ 处的 $P_{\\mathrm{mech}}^{\\mathrm{B}} = P_{0}$。定义压力误差大小为 $\\Delta P^{\\mathrm{A}} = |P_{0} - P_{\\mathrm{mech}}^{\\mathrm{A}}| = |P_{0}|$ 和 $\\Delta P^{\\mathrm{B}} = |P_{0} - P_{\\mathrm{mech}}^{\\mathrm{B}}| = 0$。\n\n- 可压缩性代理（相对于 $V$ 的曲率）：参考曲率为 $c$。模型 A 没有 $V$ 曲率，意味着曲率为 $0$，误差为 $|c - 0| = c$。模型 B 强制曲率为 $\\theta^{2}=c$，意味着误差为零。\n\n您的任务是编写一个程序，对于下面测试套件中的每个参数集，计算以下三个布尔值：\n- 省略体积项是否能在 $V_{0}$ 处的 $x$-边缘分布上产生更低的训练目标，即 $D_{\\mathrm{KL}}^{\\mathrm{A}}  D_{\\mathrm{KL}}^{\\mathrm{B}}$ 是否成立。\n- 省略体积项是否会导致在 $V_{0}$ 处的压力更差，即 $\\Delta P^{\\mathrm{A}}  \\Delta P^{\\mathrm{B}}$ 是否成立。\n- 根据上述定义，省略体积项是否会导致更差的可压缩性（曲率）不匹配，即 $c  0$ 是否成立。\n\n所有量都是无量纲的。因为 $D_{\\mathrm{KL}}$ 需要归一化常数和期望值，您必须通过数值积分计算\n$$\nZ(a,\\lambda) \\;=\\; \\int_{-\\infty}^{\\infty} \\exp\\!\\Big(-\\tfrac{1}{2}\\,a\\,x^{2} - \\tfrac{1}{4}\\,\\lambda\\,x^{4}\\Big)\\,dx\n$$\n和二阶矩\n$$\nm_{2}(a,\\lambda) \\;=\\; \\frac{1}{Z(a,\\lambda)} \\int_{-\\infty}^{\\infty} x^{2}\\,\\exp\\!\\Big(-\\tfrac{1}{2}\\,a\\,x^{2} - \\tfrac{1}{4}\\,\\lambda\\,x^{4}\\Big)\\,dx,\n$$\n然后，对任意 $\\theta$ 计算\n$$\n\\log Z(\\theta,\\lambda), \\quad\nD_{\\mathrm{KL}}\\big(p_{\\mathrm{ref}}\\,\\|\\,q_{\\theta}\\big)\n\\;=\\;\n\\tfrac{1}{2}\\,(\\theta - a)\\,m_{2}(a,\\lambda) \\;+\\; \\log Z(\\theta,\\lambda) \\;-\\; \\log Z(a,\\lambda).\n$$\n使用上述公式计算 $\\theta=a$ 时的 $D_{\\mathrm{KL}}^{\\mathrm{A}}$ 和 $\\theta=\\sqrt{c}$ 时的 $D_{\\mathrm{KL}}^{\\mathrm{B}}$。\n\n在比较实数以形成布尔值时，使用容差 $\\varepsilon = 10^{-8}$ 进行稳健的浮点数比较。\n\n测试套件（四种情况）：\n- 情况 1：$(a,\\lambda,c,P_{0},V_{0}) = (2.0,\\,1.0,\\,3.0,\\,0.5,\\,10.0)$。\n- 情况 2：$(a,\\lambda,c,P_{0},V_{0}) = (1.0,\\,0.5,\\,1.5,\\,0.0,\\,5.0)$。\n- 情况 3：$(a,\\lambda,c,P_{0},V_{0}) = (2.0,\\,1.0,\\,4.0,\\,0.3,\\,8.0)$。\n- 情况 4：$(a,\\lambda,c,P_{0},V_{0}) = (1.5,\\,0.1,\\,2.0,\\,-0.2,\\,6.0)$。\n\n您的程序应该生成一行输出，其中包含一个逗号分隔的列表的列表，每个内部列表按顺序包含对应情况的三个布尔值：$\\big[$更低的$D_{\\mathrm{KL}}$，更差的压力，更差的可压缩性$\\big]$。例如，一个有效的输出格式是\n$$\n\\texttt{[[True,True,True],[False,False,True],[...],[...]]}.\n$$", "solution": "问题陈述已经过严格验证，并被确定为有效。它在科学上植根于统计力学，特别是粗粒化理论，并且在数学上是适定的。所有参数和目标都已明确定义，前提条件内部一致，没有事实错误或逻辑矛盾。该任务是一个定义明确的计算练习，旨在探索不同粗粒化策略中固有的权衡。\n\n解决方案通过执行一个程序来计算四个不同参数集的三个布尔度量。这些度量比较了两个粗粒化模型（模型 A 和模型 B）在再现参考系统不同性质方面的能力。模型 A 仅针对构型分布进行优化，而模型 B 的构建旨在同时再现宏观热力学性质，如压力和可压缩性。\n\n需要为每个参数集评估的三个布尔条件如下：\n1. $D_{\\mathrm{KL}}^{\\mathrm{A}}  D_{\\mathrm{KL}}^{\\mathrm{B}}$：模型 A（缺少显式体积项）是否具有更低（更好）的训练目标值。训练目标是在固定体积 $V=V_{0}$ 下，模型和参考系统的集体坐标 $x$ 的边缘分布之间计算的 Kullback–Leibler (KL) 散度。\n2. $\\Delta P^{\\mathrm{A}}  \\Delta P^{\\mathrm{B}}$：模型 A 在预测 $V=V_{0}$ 处的机械压力时是否有更差（更大）的误差。\n3. 模型 A 是否在可压缩性代理（定义为势能相对于体积的曲率）方面有更差（更大）的不匹配。\n\n下面将详细说明这些条件的评估，使用浮点比较容差 $\\varepsilon = 10^{-8}$。\n\n**布尔值 1：训练目标比较 ($D_{\\mathrm{KL}}^{\\mathrm{A}}  D_{\\mathrm{KL}}^{\\mathrm{B}}$)**\n\n训练是在边缘分布 $p_{\\mathrm{ref}}(x) \\propto \\exp(-\\tfrac{1}{2}\\,a\\,x^{2} - \\tfrac{1}{4}\\,\\lambda\\,x^{4})$ 上进行的。\n\n对于模型 A，模型分布为 $q_{\\theta}(x) \\propto \\exp(-\\tfrac{1}{2}\\,\\theta\\,x^{2} - \\tfrac{1}{4}\\,\\lambda\\,x^{4})$。问题陈述指出，该模型通过最小化 $D_{\\mathrm{KL}}(p_{\\mathrm{ref}}(x)\\,\\|\\,q_{\\theta}(x))$ 来拟合 $\\theta$。当模型分布与参考分布相同时，达到最小值，这发生在 $\\theta=a$ 时。这使得模型 A 的 KL 散度等于零：$D_{\\mathrm{KL}}^{\\mathrm{A}} = 0$。\n\n对于模型 B，参数 $\\theta$ 不是为训练目标而优化的，而是被固定以匹配一个热力学性质。参数设置为 $\\theta_{\\mathrm{B}} = \\sqrt{c}$ 以匹配参考系统的可压缩性。因此，模型 B 的 KL 散度为 $D_{\\mathrm{KL}}^{\\mathrm{B}} = D_{\\mathrm{KL}}(p_{\\mathrm{ref}}(x)\\,\\|\\,q_{\\sqrt{c}}(x))$。其值由以下公式给出：\n$$\nD_{\\mathrm{KL}}^{\\mathrm{B}} = \\tfrac{1}{2}\\,(\\sqrt{c} - a)\\,m_{2}(a,\\lambda) + \\log Z(\\sqrt{c},\\lambda) - \\log Z(a,\\lambda)\n$$\n其中 $Z(k,\\lambda)$ 是配分函数，$m_{2}(a,\\lambda)$ 是 $x$ 的二阶矩：\n$$\nZ(k,\\lambda) = \\int_{-\\infty}^{\\infty} \\exp\\!\\Big(-\\tfrac{1}{2}\\,k\\,x^{2} - \\tfrac{1}{4}\\,\\lambda\\,x^{4}\\Big)\\,dx\n$$\n$$\nm_{2}(a,\\lambda) = \\frac{1}{Z(a,\\lambda)} \\int_{-\\infty}^{\\infty} x^{2}\\,\\exp\\!\\Big(-\\tfrac{1}{2}\\,a\\,x^{2} - \\tfrac{1}{4}\\,\\lambda\\,x^{4}\\Big)\\,dx\n$$\n这些积分必须进行数值计算。由于被积函数是 $x$ 的偶函数，我们可以从 $0$ 积分到 $\\infty$，然后乘以 $2$。\n\n条件 $D_{\\mathrm{KL}}^{\\mathrm{A}}  D_{\\mathrm{KL}}^{\\mathrm{B}}$ 变为 $0  D_{\\mathrm{KL}}^{\\mathrm{B}}$。考虑容差，即 $D_{\\mathrm{KL}}^{\\mathrm{B}}  \\varepsilon$。除非 $a = \\sqrt{c}$，否则此条件为真，此时 $D_{\\mathrm{KL}}^{\\mathrm{B}} = 0$。\n\n**布尔值 2：压力误差比较 ($\\Delta P^{\\mathrm{A}}  \\Delta P^{\\mathrm{B}}$)**\n\n压力误差定义为 $\\Delta P = |P_{0} - P_{\\mathrm{mech}}|$，其中 $P_{\\mathrm{mech}} = -\\langle \\partial U/\\partial V \\rangle_{V=V_{0}}$。\n\n对于模型 A，势能 $U^{\\mathrm{A}}_{\\theta}(x)$ 不依赖于体积 $V$，因此 $\\partial U^{\\mathrm{A}}/\\partial V = 0$。这意味着 $P_{\\mathrm{mech}}^{\\mathrm{A}} = 0$，压力误差为 $\\Delta P^{\\mathrm{A}} = |P_{0} - 0| = |P_{0}|$。\n\n对于模型 B，势能被构造成与参考压力匹配。当 $P_{\\mathrm{fit}} = P_{0}$ 时，在 $V=V_{0}$ 处的机械压力为 $P_{\\mathrm{mech}}^{\\mathrm{B}} = P_{0}$。这导致压力误差为零：$\\Delta P^{\\mathrm{B}} = |P_{0} - P_{0}| = 0$。\n\n因此，比较 $\\Delta P^{\\mathrm{A}}  \\Delta P^{\\mathrm{B}}$ 简化为 $|P_{0}|  0$。使用容差，此条件为 $|P_{0}|  \\varepsilon$。\n\n**布尔值 3：可压缩性不匹配比较**\n\n可压缩性代理是在 $V=V_{0}$ 处势能相对于体积的二阶导数。\n\n参考系统的曲率为 $c$。\n\n对于模型 A，由于没有体积依赖性，曲率为 $0$。误差大小为 $|c - 0| = c$。\n\n对于模型 B，势能项 $\\tfrac{1}{2}\\,\\theta^{2}\\,(V-V_{0})^{2}$ 在 $\\theta=\\sqrt{c}$ 时产生的曲率为 $(\\sqrt{c})^2 = c$。误差大小为 $|c - c| = 0$。\n\n模型 A 的不匹配比模型 B 更差的条件是其误差更大，即 $c  0$。鉴于问题参数要求 $c  0$，并使用容差，此条件写作 $c  \\varepsilon$。\n\n**实现算法摘要**\n\n对于每个参数集 $(a, \\lambda, c, P_{0}, V_{0})$：\n1. 计算 $D_{\\mathrm{KL}}^{\\mathrm{B}}$。如果 $|a - \\sqrt{c}|  \\varepsilon$，则 $D_{\\mathrm{KL}}^{\\mathrm{B}}=0$。否则，使用数值积分计算 $Z(a, \\lambda)$、$m_{2}(a, \\lambda)$ 和 $Z(\\sqrt{c}, \\lambda)$ 来评估 $D_{\\mathrm{KL}}^{\\mathrm{B}}$ 公式。如果 $D_{\\mathrm{KL}}^{\\mathrm{B}}  \\varepsilon$，则第一个布尔值为真。\n2. 如果 $|P_{0}|  \\varepsilon$，则第二个布尔值为真。\n3. 如果 $c  \\varepsilon$，则第三个布尔值为真。\n将结果收集并按指定格式化。", "answer": "```python\nimport numpy as np\nfrom scipy import integrate\n\ndef solve():\n    \"\"\"\n    Solves the coarse-graining comparison problem for the given test suite.\n    \"\"\"\n    # Test suite: (a, lambda, c, P0, V0)\n    test_cases = [\n        (2.0, 1.0, 3.0, 0.5, 10.0),\n        (1.0, 0.5, 1.5, 0.0, 5.0),\n        (2.0, 1.0, 4.0, 0.3, 8.0),\n        (1.5, 0.1, 2.0, -0.2, 6.0),\n    ]\n\n    # Floating point comparison tolerance\n    epsilon = 1e-8\n    results = []\n\n    # Memoization cache for numerical integration results\n    memo_cache = {}\n\n    def get_logZ_and_m2(k, lam):\n        \"\"\"\n        Calculates log(Z(k, lam)) and m2(k, lam) using numerical quadrature.\n        Results are memoized to avoid re-computation.\n        \"\"\"\n        if (k, lam) in memo_cache:\n            return memo_cache[(k, lam)]\n\n        # Define the integrands for the partition function Z and the numerator of m2.\n        # The potential is U(x) = 0.5*k*x^2 + 0.25*lam*x^4\n        integrand_Z = lambda x: np.exp(-0.5 * k * x**2 - 0.25 * lam * x**4)\n        integrand_m2_num = lambda x: x**2 * np.exp(-0.5 * k * x**2 - 0.25 * lam * x**4)\n\n        # The integrands are even, so integrate from 0 to infinity and multiply by 2.\n        # quad returns (result, error_estimate)\n        Z_val = 2.0 * integrate.quad(integrand_Z, 0, np.inf)[0]\n        m2_numerator = 2.0 * integrate.quad(integrand_m2_num, 0, np.inf)[0]\n        \n        logZ = np.log(Z_val)\n        m2 = m2_numerator / Z_val\n\n        memo_cache[(k, lam)] = (logZ, m2)\n        return logZ, m2\n\n    for case in test_cases:\n        a, lam, c, P0, _ = case\n\n        # --- Boolean 1: D_KL^A  D_KL^B ---\n        # D_KL^A is 0 by definition, as Model A perfectly matches the target distribution.\n        D_KL_A = 0.0\n\n        # For Model B, theta is fixed to match compressibility: theta_B = sqrt(c).\n        theta_B = np.sqrt(c)\n\n        # If theta_B is numerically equal to a, then Model B also perfectly matches\n        # the target distribution, and its D_KL is also 0.\n        if np.abs(theta_B - a)  epsilon:\n            D_KL_B = 0.0\n        else:\n            # Otherwise, compute D_KL^B using the provided formula.\n            # This requires numerical calculation of Z and m2.\n            logZ_a, m2_a = get_logZ_and_m2(a, lam)\n            logZ_theta_B, _ = get_logZ_and_m2(theta_B, lam)\n            \n            D_KL_B = 0.5 * (theta_B - a) * m2_a + logZ_theta_B - logZ_a\n\n        # The condition D_KL^A  D_KL^B is equivalent to 0  D_KL^B.\n        # With tolerance, this is D_KL_B > epsilon.\n        is_lower_DKL = D_KL_B > epsilon\n\n        # --- Boolean 2: Delta_P^A > Delta_P^B ---\n        # Delta_P^A = |P0| and Delta_P^B = 0.\n        # The condition is |P0| > 0.\n        # With tolerance, this is |P0| > epsilon.\n        is_worse_pressure = np.abs(P0) > epsilon\n\n        # --- Boolean 3: Compressibility mismatch A > B ---\n        # Error_A = c and Error_B = 0.\n        # The condition is c > 0.\n        # With tolerance, this is c > epsilon.\n        is_worse_compressibility = c > epsilon\n        \n        results.append([is_lower_DKL, is_worse_pressure, is_worse_compressibility])\n\n    # Format the output as a string representation of a list of lists.\n    # e.g., [[True,True,True],[False,False,True]]\n    output_str = f\"[\" + \",\".join(str(r).replace(\" \", \"\") for r in results) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3456623"}, {"introduction": "当我们确定了模型的基本形式后，下一步便是进行参数的数值优化，而这一过程也充满挑战。[@problem_id:3456655] 这项实践将揭示一个常见的陷阱：在模型势函数中包含线性相关（即冗余）的基函数，会导致优化问题在数值上变得不稳定或“病态” (ill-conditioned)。你将通过解析推导，证明这种冗余性如何导致一个奇异的Hessian矩阵，从而深入理解设计一个稳健且高效的粗粒化工作流程所涉及的实际问题。", "problem": "考虑一个一维粗粒化坐标 $x \\in \\mathbb{R}$，它从一个参考分布 $P_{\\mathrm{ref}}(x)$ 中采样，该分布是均值为零、方差为 $\\sigma^{2}$ 的高斯分布，即 $P_{\\mathrm{ref}}(x) \\propto \\exp\\!\\big(-x^{2}/(2\\sigma^{2})\\big)$。假设使用约化单位，其中玻尔兹曼常数乘以温度 $k_{B}T$ 等于 $1$，因此参考势为 $U_{\\mathrm{ref}}(x) = x^{2}/(2\\sigma^{2})$（不计一个加性常数）。通过玻尔兹曼分布 $P_{\\theta}(x) = \\exp\\!\\big(-U_{\\theta}(x)\\big)/Z_{\\theta}$ 定义一个粗粒化模型族 $P_{\\theta}$，其中 $Z_{\\theta} = \\int_{\\mathbb{R}} \\exp\\!\\big(-U_{\\theta}(x)\\big)\\,dx$ 是配分函数。\n\n从具有势函数 $U_{\\alpha}(x) = \\alpha\\, x^{2}$ 的单参数模型开始，然后考虑一个扩展的、具有基函数 $f_{1}(x) = x^{2}$ 和 $f_{2}(x) = 2 x^{2}$ 的双参数模型，即 $U_{\\boldsymbol{\\theta}}(x) = \\theta_{1} f_{1}(x) + \\theta_{2} f_{2}(x) = (\\theta_{1} + 2 \\theta_{2}) x^{2}$。自上而下的粗粒化目标是从参考分布到模型分布的Kullback–Leibler散度（相对熵），$D_{\\mathrm{KL}}\\!\\big(P_{\\mathrm{ref}} \\,\\|\\, P_{\\theta}\\big) = \\int_{\\mathbb{R}} P_{\\mathrm{ref}}(x)\\, \\ln\\!\\big(P_{\\mathrm{ref}}(x)/P_{\\theta}(x)\\big)\\,dx$，该目标在相对熵最小化（REM）中被最小化。\n\n仅使用以上定义和第一性原理，完成以下任务：\n- 证明单参数模型的可达模型分布集合 $\\{P_{\\alpha}\\}$ 与双参数模型的可达模型分布集合 $\\{P_{\\boldsymbol{\\theta}}\\}$ 相同，并论证 $D_{\\mathrm{KL}}\\!\\big(P_{\\mathrm{ref}} \\,\\|\\, P_{\\theta}\\big)$ 的最小值不受此扩展的影响。\n- 对于双参数模型，推导REM目标函数关于参数的海森矩阵，并在一个使 $P_{\\boldsymbol{\\theta}^{\\star}} = P_{\\mathrm{ref}}$ 的最小化点处计算其值。然后明确计算其特征值。\n\n作为最终答案，报告此海森矩阵的唯一非零特征值，仅用 $\\sigma$ 表示。不需要数值近似；请提供一个闭式符号表达式。", "solution": "首先验证该问题具有科学依据、是良定的且客观的。它提出了一个粗粒化统计力学中的标准练习，具体涉及相对熵最小化（REM）中的参数冗余问题。所有定义都是标准的，任务是可数学形式化的，并能得出一个唯一的、可验证的结果。因此，我们可以着手求解。\n\n问题分为两部分。首先，我们必须证明单参数势和双参数势的模型集是等价的，并论证Kullback-Leibler（KL）散度的最小值不受影响。其次，我们必须计算双参数模型的KL散度在全局最小值处的海森矩阵的特征值。\n\n第一部分：模型集的等价性\n\n单参数模型由势函数 $U_{\\alpha}(x) = \\alpha x^{2}$ 定义，其中 $\\alpha \\in \\mathbb{R}$ 是参数。该模型可实现的势函数集合是 $\\mathcal{U}_{1} = \\{\\alpha x^{2} \\mid \\alpha \\in \\mathbb{R}\\}$。\n\n双参数模型由势函数 $U_{\\boldsymbol{\\theta}}(x) = \\theta_{1} f_{1}(x) + \\theta_{2} f_{2}(x)$ 定义，基函数为 $f_{1}(x) = x^{2}$ 和 $f_{2}(x) = 2x^{2}$。参数向量为 $\\boldsymbol{\\theta} = (\\theta_{1}, \\theta_{2}) \\in \\mathbb{R}^{2}$。代入基函数，势函数变为：\n$$\nU_{\\boldsymbol{\\theta}}(x) = \\theta_{1} x^{2} + \\theta_{2} (2 x^{2}) = (\\theta_{1} + 2 \\theta_{2}) x^{2}\n$$\n我们定义一个复合参数 $\\beta = \\theta_{1} + 2 \\theta_{2}$。由于 $\\theta_{1}$ 和 $\\theta_{2}$ 可以是任何实数，$\\beta$ 也可以是任何实数。对于任何给定的 $\\beta \\in \\mathbb{R}$，我们都可以找到一个对应的参数对 $(\\theta_{1}, \\theta_{2})$，例如，通过设置 $\\theta_{1} = \\beta$ 和 $\\theta_{2} = 0$。因此，双参数模型可实现的势函数集合是 $\\mathcal{U}_{2} = \\{\\beta x^{2} \\mid \\beta \\in \\mathbb{R}\\}$。\n\n经检验，这两个势函数集合是相同的：$\\mathcal{U}_{1} = \\mathcal{U}_{2}$。模型概率分布 $P(x)$ 通过玻尔兹曼公式 $P(x) \\propto \\exp(-U(x))$ 定义，它仅依赖于势函数 $U(x)$。由于单参数模型和双参数模型可实现的势函数集合相同，因此它们可实现的模型分布集合 $\\{P_{\\alpha}\\}$ 和 $\\{P_{\\boldsymbol{\\theta}}\\}$ 也必定相同。\n\nREM的目标函数是KL散度 $D_{\\mathrm{KL}}(P_{\\mathrm{ref}} \\| P_{\\theta})$，它是模型分布 $P_{\\theta}$ 的一个泛函。最小化是在所有可达模型分布的集合上进行的。由于这个集合对于两种参数化是相同的，该泛函能达到的最小值也必定相同。从一个参数扩展到两个参数是冗余的，因为新的基函数 $f_{2}(x)$ 与第一个基函数线性相关，即 $f_{2}(x) = 2 f_{1}(x)$。\n\n第二部分：海森矩阵及其特征值\n\n需要最小化的目标函数是KL散度：\n$$\nD_{\\mathrm{KL}}(P_{\\mathrm{ref}} \\| P_{\\boldsymbol{\\theta}}) = \\int_{\\mathbb{R}} P_{\\mathrm{ref}}(x) \\ln\\left(\\frac{P_{\\mathrm{ref}}(x)}{P_{\\boldsymbol{\\theta}}(x)}\\right) dx\n$$\n使用定义 $P_{\\boldsymbol{\\theta}}(x) = \\exp(-U_{\\boldsymbol{\\theta}}(x))/Z_{\\boldsymbol{\\theta}}$，我们可以写出 $\\ln P_{\\boldsymbol{\\theta}}(x) = -U_{\\boldsymbol{\\theta}}(x) - \\ln Z_{\\boldsymbol{\\theta}}$。最小化 $D_{\\mathrm{KL}}$ 关于 $\\boldsymbol{\\theta}$ 等价于最小化泛函 $L(\\boldsymbol{\\theta})$（与自由能差相关）：\n$$\nL(\\boldsymbol{\\theta}) = \\int_{\\mathbb{R}} P_{\\mathrm{ref}}(x) U_{\\boldsymbol{\\theta}}(x) dx + \\ln Z_{\\boldsymbol{\\theta}} = \\langle U_{\\boldsymbol{\\theta}} \\rangle_{P_{\\mathrm{ref}}} + \\ln Z_{\\boldsymbol{\\theta}}\n$$\n其中 $\\langle \\cdot \\rangle_{P_{\\mathrm{ref}}}$ 表示对参考分布 $P_{\\mathrm{ref}}$ 的平均。\n对于 $U_{\\boldsymbol{\\theta}}(x) = \\sum_{k=1}^{2} \\theta_{k} f_{k}(x)$， $L(\\boldsymbol{\\theta})$ 的梯度分量为：\n$$\n\\frac{\\partial L}{\\partial \\theta_{i}} = \\langle f_{i} \\rangle_{P_{\\mathrm{ref}}} - \\langle f_{i} \\rangle_{P_{\\boldsymbol{\\theta}}}\n$$\n海森矩阵元素 $H_{ij}$ 是 $L(\\boldsymbol{\\theta})$ 的二阶偏导数：\n$$\nH_{ij} = \\frac{\\partial^{2} L}{\\partial \\theta_{i} \\partial \\theta_{j}} = -\\frac{\\partial}{\\partial \\theta_{j}} \\langle f_{i} \\rangle_{P_{\\boldsymbol{\\theta}}} = \\langle f_{i} f_{j} \\rangle_{P_{\\boldsymbol{\\theta}}} - \\langle f_{i} \\rangle_{P_{\\boldsymbol{\\theta}}} \\langle f_{j} \\rangle_{P_{\\boldsymbol{\\theta}}} = \\mathrm{Cov}_{P_{\\boldsymbol{\\theta}}}(f_{i}, f_{j})\n$$\n这是一个普遍的结果：REM目标函数的海森矩阵是基函数的协方差矩阵，该协方差是根据当前模型分布 $P_{\\boldsymbol{\\theta}}$ 计算的。\n\n问题要求在一个最小化点 $\\boldsymbol{\\theta}^{\\star}$ 处计算海森矩阵，该点上模型分布与参考分布完全匹配，即 $P_{\\boldsymbol{\\theta}^{\\star}} = P_{\\mathrm{ref}}$。此时，海森矩阵变为：\n$$\nH_{ij} = \\mathrm{Cov}_{P_{\\mathrm{ref}}}(f_{i}, f_{j}) = \\langle f_{i} f_{j} \\rangle_{P_{\\mathrm{ref}}} - \\langle f_{i} \\rangle_{P_{\\mathrm{ref}}} \\langle f_{j} \\rangle_{P_{\\mathrm{ref}}}\n$$\n基函数为 $f_{1}(x) = x^{2}$ 和 $f_{2}(x) = 2x^{2}$。参考分布 $P_{\\mathrm{ref}}(x)$ 是一个均值为零、方差为 $\\sigma^{2}$ 的高斯分布。关于此分布所需的矩为：\n$\\langle x^{2} \\rangle_{\\mathrm{ref}} = \\sigma^{2}$\n$\\langle x^{4} \\rangle_{\\mathrm{ref}} = 3\\sigma^{4}$\n\n我们计算基函数所需的期望值：\n$\\langle f_{1} \\rangle_{\\mathrm{ref}} = \\langle x^{2} \\rangle_{\\mathrm{ref}} = \\sigma^{2}$\n$\\langle f_{2} \\rangle_{\\mathrm{ref}} = \\langle 2x^{2} \\rangle_{\\mathrm{ref}} = 2\\langle x^{2} \\rangle_{\\mathrm{ref}} = 2\\sigma^{2}$\n$\\langle f_{1}^{2} \\rangle_{\\mathrm{ref}} = \\langle (x^{2})^{2} \\rangle_{\\mathrm{ref}} = \\langle x^{4} \\rangle_{\\mathrm{ref}} = 3\\sigma^{4}$\n$\\langle f_{2}^{2} \\rangle_{\\mathrm{ref}} = \\langle (2x^{2})^{2} \\rangle_{\\mathrm{ref}} = 4\\langle x^{4} \\rangle_{\\mathrm{ref}} = 12\\sigma^{4}$\n$\\langle f_{1} f_{2} \\rangle_{\\mathrm{ref}} = \\langle (x^{2})(2x^{2}) \\rangle_{\\mathrm{ref}} = 2\\langle x^{4} \\rangle_{\\mathrm{ref}} = 6\\sigma^{4}$\n\n现在，我们构建海森矩阵的元素：\n$H_{11} = \\langle f_{1}^{2} \\rangle_{\\mathrm{ref}} - (\\langle f_{1} \\rangle_{\\mathrm{ref}})^{2} = 3\\sigma^{4} - (\\sigma^{2})^{2} = 2\\sigma^{4}$\n$H_{12} = H_{21} = \\langle f_{1} f_{2} \\rangle_{\\mathrm{ref}} - \\langle f_{1} \\rangle_{\\mathrm{ref}} \\langle f_{2} \\rangle_{\\mathrm{ref}} = 6\\sigma^{4} - (\\sigma^{2})(2\\sigma^{2}) = 4\\sigma^{4}$\n$H_{22} = \\langle f_{2}^{2} \\rangle_{\\mathrm{ref}} - (\\langle f_{2} \\rangle_{\\mathrm{ref}})^{2} = 12\\sigma^{4} - (2\\sigma^{2})^{2} = 8\\sigma^{4}$\n\n海森矩阵是：\n$$\nH = \\begin{pmatrix} 2\\sigma^{4}  4\\sigma^{4} \\\\ 4\\sigma^{4}  8\\sigma^{4} \\end{pmatrix} = 2\\sigma^{4} \\begin{pmatrix} 1  2 \\\\ 2  4 \\end{pmatrix}\n$$\n为了找到特征值 $\\lambda$，我们求解特征方程 $\\det(H - \\lambda I) = 0$：\n$$\n\\det \\begin{pmatrix} 2\\sigma^{4} - \\lambda  4\\sigma^{4} \\\\ 4\\sigma^{4}  8\\sigma^{4} - \\lambda \\end{pmatrix} = 0\n$$\n$$\n(2\\sigma^{4} - \\lambda)(8\\sigma^{4} - \\lambda) - (4\\sigma^{4})^{2} = 0\n$$\n$$\n16\\sigma^{8} - 2\\sigma^{4}\\lambda - 8\\sigma^{4}\\lambda + \\lambda^{2} - 16\\sigma^{8} = 0\n$$\n$$\n\\lambda^{2} - 10\\sigma^{4}\\lambda = 0\n$$\n$$\n\\lambda(\\lambda - 10\\sigma^{4}) = 0\n$$\n特征值为 $\\lambda_{1} = 0$ 和 $\\lambda_{2} = 10\\sigma^{4}$。\n\n零特征值 $\\lambda_{1}=0$ 的存在是基函数 $f_{1}(x)$ 和 $f_{2}(x)$ 之间线性相关的直接结果。这种线性相关性在参数空间中创造了一个“软”方向，势函数沿该方向不变，从而导致一个奇异的海森矩阵。问题要求唯一的非零特征值。\n\n唯一的非零特征值是 $\\lambda_{2} = 10\\sigma^{4}$。", "answer": "$$\n\\boxed{10\\sigma^{4}}\n$$", "id": "3456655"}]}