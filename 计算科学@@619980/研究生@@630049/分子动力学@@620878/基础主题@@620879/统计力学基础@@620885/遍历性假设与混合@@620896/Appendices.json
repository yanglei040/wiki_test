{"hands_on_practices": [{"introduction": "Fermi-Pasta-Ulam-Tsingou (FPUT) 问题是混沌理论和非线性动力学中的一个里程碑。最初的数值实验出人意料地揭示了能量并非如统计力学所预期的那样快速均分到各个自由度，从而挑战了遍历性假设。这项实践将指导你复现这一著名的数值实验，通过模拟一个非线性链的动力学，并学习使用谱熵等工具来量化能量在简正模之间的均分过程 [@problem_id:3452493]。", "problem": "考虑一个由 $N$ 个相同质点组成的一维 Fermi–Pasta–Ulam–Tsingou (FPUT) 链，质点间通过最近邻弹簧连接，且链的两端固定。设每个粒子的质量为 $m=1$，弹簧常数的选择应使二次刚度为1，并由一个强度为 $\\beta$ 的小四次非线性项来修正势能。该 $\\beta$-FPUT 链的哈密顿量为\n$$\nH(\\mathbf{x},\\mathbf{v}) \\;=\\; \\sum_{i=1}^{N} \\frac{v_i^2}{2} \\;+\\; \\sum_{i=0}^{N} \\left[ \\frac{1}{2} \\Delta_i^2 \\;+\\; \\frac{\\beta}{4} \\Delta_i^4 \\right],\n$$\n其中 $\\Delta_i = x_{i+1} - x_i$，$x_0 = 0$，$x_{N+1} = 0$，$\\mathbf{x} = (x_1,\\dots,x_N)$ 是位移，$\\mathbf{v} = (v_1,\\dots,v_N)$ 是速度。\n\n根据 Newton 第二运动定律，微正则系综分子动力学（恒定能量系综）遵循以下方程：\n$$\n\\dot{x}_i = v_i, \\qquad \\dot{v}_i = f_i(\\mathbf{x}),\n$$\n其中力 $f_i$ 由总势能的负梯度导出：\n$$\nf_i(\\mathbf{x}) \\;=\\; \\left( \\Delta_i + \\beta \\Delta_i^3 \\right) \\;-\\; \\left( \\Delta_{i-1} + \\beta \\Delta_{i-1}^3 \\right), \\quad i=1,\\dots,N.\n$$\n您必须使用 velocity-Verlet 积分器来模拟这些方程，该积分器对于一个时间步长 $\\Delta t$ 按如下方式更新 $(\\mathbf{x},\\mathbf{v})$：\n$$\n\\mathbf{v}\\left(t+\\frac{\\Delta t}{2}\\right) = \\mathbf{v}(t) + \\frac{\\Delta t}{2}\\,\\mathbf{f}\\left(\\mathbf{x}(t)\\right),\n$$\n$$\n\\mathbf{x}(t+\\Delta t) = \\mathbf{x}(t) + \\Delta t\\,\\mathbf{v}\\left(t+\\frac{\\Delta t}{2}\\right),\n$$\n$$\n\\mathbf{v}(t+\\Delta t) = \\mathbf{v}\\left(t+\\frac{\\Delta t}{2}\\right) + \\frac{\\Delta t}{2}\\,\\mathbf{f}\\left(\\mathbf{x}(t+\\Delta t)\\right).\n$$\n\n为了量化线性简正模上的能量均分，请使用固定端链的线性化简正模。定义标准正交正弦变换\n$$\nQ_k(t) \\;=\\; \\sqrt{\\frac{2}{N+1}} \\sum_{i=1}^{N} x_i(t) \\,\\sin\\!\\left(\\frac{\\pi k i}{N+1}\\right), \\qquad P_k(t) \\;=\\; \\sqrt{\\frac{2}{N+1}} \\sum_{i=1}^{N} v_i(t) \\,\\sin\\!\\left(\\frac{\\pi k i}{N+1}\\right),\n$$\n其谐波频率为\n$$\n\\omega_k^2 \\;=\\; 4\\,\\sin^2\\!\\left(\\frac{\\pi k}{2(N+1)}\\right), \\qquad k = 1,\\dots,N.\n$$\n定义瞬时线性模能量诊断量为\n$$\nE_k^{\\text{lin}}(t) \\;=\\; \\frac{1}{2}\\left[ P_k(t)^2 \\;+\\; \\omega_k^2\\,Q_k(t)^2 \\right],\n$$\n以及归一化能量分数\n$$\nf_k(t) \\;=\\; \\frac{E_k^{\\text{lin}}(t)}{\\sum_{j=1}^{N} E_j^{\\text{lin}}(t)}.\n$$\n定义模能量分布的谱熵\n$$\nH(t) \\;=\\; -\\sum_{k=1}^{N} f_k(t)\\,\\ln f_k(t), \\qquad S(t) \\;=\\; \\frac{H(t)}{\\ln N},\n$$\n其中 $S(t)\\in[0,1]$ 且 $S(t)=1$ 对应于能量在各模上完全均匀的分布。\n\n初始化方案（单模激发）：对于每个总能量 $E_{\\text{tot}}$（由能量密度 $e$ 决定，$E_{\\text{tot}} = e\\,N$），将所有速度设为零，并设置位移以仅激发基模 $k=1$：\n$$\nx_i(0) \\;=\\; A\\,\\sqrt{\\frac{2}{N+1}}\\,\\sin\\!\\left(\\frac{\\pi i}{N+1}\\right),\n$$\n其中振幅 $A$ 的选择应使得用完整的非线性哈密顿量计算的初始总能量等于 $E_{\\text{tot}}$。这一选择确保了与指定能量密度一致的微正则初始条件。\n\n能量均分时间判据：以固定间隔采样谱熵 $S(t)$。通过容差 $\\delta\\in(0,1)$ 和持续窗口长度 $L\\in\\mathbb{N}$ 来定义能量均分阈值。将能量均分时间 $T_{\\text{eq}}$ 定义为最早的采样时间 $t$，使得对于包括 $t$ 在内的 $L$ 个连续采样时间 $t'$，都有 $S(t') \\ge 1 - \\delta$。如果在总模拟时间 $T_{\\max}$ 内从未达到该阈值，则返回 $T_{\\text{eq}} = T_{\\max}$。\n\n您的任务是编写一个完整的程序，该程序：\n- 实现具有固定端的 $\\beta$-FPUT 链的 velocity-Verlet 微正则系综分子动力学。\n- 对于每个指定的能量密度，通过激发模式 $k=1$ 来初始化链，并选择振幅 $A$ 以满足目标能量。\n- 随时间计算线性模能量和谱熵。\n- 检测并报告每个能量密度的能量均分时间 $T_{\\text{eq}}$。\n\n所有时间都必须以与所选时间步长 $\\Delta t$ 一致的无量纲时间单位表示。最终输出必须是包含一个浮点数列表的单行文本。\n\n使用以下参数值作为测试套件，以探究不同的动力学区域：\n- 粒子数：$N = 32$。\n- 非线性强度：$\\beta = 0.1$。\n- 时间步长：$\\Delta t = 0.02$。\n- 最大模拟时间：$T_{\\max} = 800$（即 $40000$ 个积分步）。\n- 谱熵采样步幅：每 $20$ 个积分步。\n- 能量均分容差：$\\delta = 0.2$。\n- 持续窗口长度：$L = 8$ 个连续样本。\n- 能量密度：$e \\in \\{0.005,\\;0.05,\\;0.3\\}$，每种情况下总能量为 $E_{\\text{tot}} = e\\,N$。\n\n您的程序应生成单行输出，其中包含按相同顺序列出的三种能量密度的能量均分时间，格式为方括号内以逗号分隔的列表（例如，“[t_low,t_mid,t_high]”），其中每个 $t$ 是一个无量纲时间单位的浮点数。", "solution": "用户提供了一个来自计算分子动力学领域的计算问题，具体涉及 Fermi–Pasta–Ulam–Tsingou (FPUT) 链。任务是模拟系统动力学，并确定不同初始能量密度下的能量均分时间。\n\n### 问题验证\n\n**第1步：提取已知条件**\n- **系统**：一个由 $N$ 个质量为 $m=1$ 的粒子组成的一维链，具有固定端（$x_0 = 0$, $x_{N+1} = 0$）。\n- **哈密顿量**：$H(\\mathbf{x},\\mathbf{v}) = \\sum_{i=1}^{N} \\frac{v_i^2}{2} + \\sum_{i=0}^{N} \\left[ \\frac{1}{2} (x_{i+1} - x_i)^2 + \\frac{\\beta}{4} (x_{i+1} - x_i)^4 \\right]$。\n- **运动方程**：$\\dot{x}_i = v_i$, $\\dot{v}_i = f_i(\\mathbf{x}) = (\\Delta_i + \\beta \\Delta_i^3) - (\\Delta_{i-1} + \\beta \\Delta_{i-1}^3)$，其中 $\\Delta_i = x_{i+1} - x_i$。\n- **积分器**：Velocity-Verlet，时间步长为 $\\Delta t$。\n- **诊断量**：\n    - 简正模坐标：$Q_k(t) = \\sqrt{\\frac{2}{N+1}} \\sum_{i=1}^{N} x_i(t) \\sin(\\frac{\\pi k i}{N+1})$ 和 $P_k(t)$。\n    - 模频率：$\\omega_k^2 = 4\\sin^2(\\frac{\\pi k}{2(N+1)})$。\n    - 线性模能量：$E_k^{\\text{lin}}(t) = \\frac{1}{2}[P_k(t)^2 + \\omega_k^2 Q_k(t)^2]$。\n    - 谱熵：$S(t) = -\\frac{1}{\\ln N} \\sum_{k=1}^{N} f_k(t)\\ln f_k(t)$，其中 $f_k(t) = E_k^{\\text{lin}}(t) / \\sum_j E_j^{\\text{lin}}(t)$。\n- **初始化**：$k=1$ 模式的单模激发，$v_i(0)=0$，$x_i(0) = A\\sqrt{\\frac{2}{N+1}}\\sin(\\frac{\\pi i}{N+1})$。振幅 $A$ 的设置是为了匹配总能量 $E_{\\text{tot}} = eN$。\n- **能量均分判据**：$T_{\\text{eq}}$ 是第一个采样时间 $t$，在该时间点及之后的 $L-1$ 个连续采样点上，都满足 $S(t') \\ge 1-\\delta$。如果从未满足，则 $T_{\\text{eq}} = T_{\\max}$。\n- **数值参数**：$N=32$，$\\beta=0.1$，$\\Delta t=0.02$，$T_{\\max}=800$，采样步幅 $= 20$ 步，$\\delta=0.2$，$L=8$。\n- **测试用例**：能量密度 $e \\in \\{0.005, 0.05, 0.3\\}$。\n\n**第2步：验证评估**\n该问题是计算统计力学中的一个标准练习。\n- **科学合理性**：FPUT 模型是非线性动力学的基石。所提供的哈密顿量、运动方程和诊断工具（简正模、谱熵）都是标准的且定义正确。\n- **良构性**：问题给出了所有必需的参数、初始条件、确定性的演化算法（velocity-Verlet）以及明确的求解判据，问题是完全指定的。存在唯一的数值解。\n- **客观性**：问题以精确的数学和算法术语陈述，没有任何主观因素。\n- **完整性与一致性**：问题是自洽的，所有提供的信息在内部是一致的。\n\n**第3步：结论**\n问题是**有效的**。\n\n### 基于原理的解决方案设计\n\n解决方案需要实现 $\\beta$-FPUT 链的分子动力学模拟。总体方法是遍历指定的能量密度，对每个能量密度运行一次完整的模拟，以确定能量均分时间 $T_{\\text{eq}}$。\n\n#### 1. 初始化：确定初始振幅 A\n\n系统通过激发基模（$k=1$）进行初始化，所有初始速度都设为零（$\\mathbf{v}(0)=\\mathbf{0}$）。初始位置由 $x_i(0) = A\\sqrt{\\frac{2}{N+1}}\\sin(\\frac{\\pi i}{N+1})$ 给出，$i=1, \\dots, N$。振幅 $A$ 的选择必须使得使用完整的非线性哈密顿量计算的系统总能量与目标能量 $E_{\\text{tot}} = eN$ 相匹配。\n\n由于 $\\mathbf{v}(0)=\\mathbf{0}$，初始总能量纯粹是势能：$E_{\\text{tot}} = V(\\mathbf{x}(0))$。\n$E_{\\text{tot}} = \\sum_{i=0}^{N} \\left[ \\frac{1}{2} \\Delta_i(0)^2 + \\frac{\\beta}{4} \\Delta_i(0)^4 \\right]$。\n初始位移差为 $\\Delta_i(0) = x_{i+1}(0) - x_i(0)$。通过代入 $x_i(0)$ 的形式并对 $i$ 求和，总能量可以表示为 $A$ 的多项式。推导过程涉及三角恒等式以及正弦和余弦级数的求和公式。最终得到的关于 $Y=A^2$ 的方程是一个二次方程：\n$$\n\\left( \\frac{6\\beta}{N+1} \\sin^4\\left(\\frac{\\pi}{2(N+1)}\\right) \\right) Y^2 + \\left( 2 \\sin^2\\left(\\frac{\\pi}{2(N+1)}\\right) \\right) Y - E_{\\text{tot}} = 0\n$$\n这个形如 $aY^2+bY+c=0$ 的方程，求解其唯一的正根 $Y$，然后振幅由 $A = \\sqrt{Y}$ 得到。\n\n#### 2. 数值积分：Velocity-Verlet 算法\n\n系统的时间演化通过使用 velocity-Verlet 算法数值积分牛顿运动方程 $\\ddot{\\mathbf{x}} = \\mathbf{f}(\\mathbf{x})$ 来模拟。这是一种辛积分器，由于其具有良好的长期能量守恒特性，非常适用于哈密顿系统。\n对于每个时间步长 $\\Delta t$，位置 $\\mathbf{x}$ 和速度 $\\mathbf{v}$ 按以下方式更新：\n1. 将速度更新到时间步长的中点：$\\mathbf{v}(t+\\frac{\\Delta t}{2}) = \\mathbf{v}(t) + \\frac{\\Delta t}{2}\\mathbf{f}(\\mathbf{x}(t))$。\n2. 将位置更新到时间步长的终点：$\\mathbf{x}(t+\\Delta t) = \\mathbf{x}(t) + \\Delta t\\,\\mathbf{v}(t+\\frac{\\Delta t}{2})$。\n3. 在新位置计算新的力 $\\mathbf{f}(\\mathbf{x}(t+\\Delta t))$。\n4. 将速度更新到时间步长的终点：$\\mathbf{v}(t+\\Delta t) = \\mathbf{v}(t+\\frac{\\Delta t}{2}) + \\frac{\\Delta t}{2}\\mathbf{f}(\\mathbf{x}(t+\\Delta t))$。\n\n力矢量 $\\mathbf{f}(\\mathbf{x})$ 在每一步都进行计算。第 $i$ 个粒子上的力为 $f_i = T_i - T_{i-1}$，其中 $T_j = \\Delta_j + \\beta \\Delta_j^3$ 是第 $j$ 个弹簧的张力。这可以通过在 `numpy` 中使用矢量化操作高效实现，首先计算所有弹簧伸长量 $\\Delta_i$ 的数组，然后计算张力 $T_i$。\n\n#### 3. 诊断：谱熵计算\n\n在指定的时间间隔（每 $20$ 步），我们通过计算谱熵 $S(t)$ 来诊断系统状态。这个多步骤过程量化了能量在线性简正模之间的均分程度。\n1. **简正模变换**：将粒子位置 $\\mathbf{x}(t)$ 和速度 $\\mathbf{v}(t)$ 投影到简正模基上，得到模坐标 $Q_k(t)$ 和 $P_k(t)$。这通过离散正弦变换实现。预先计算一个变换矩阵 $\\mathbf{M}$，其元素为 $M_{ki} = \\sqrt{\\frac{2}{N+1}} \\sin(\\frac{\\pi ki}{N+1})$，因此 $\\mathbf{Q} = \\mathbf{M}\\mathbf{x}$ 和 $\\mathbf{P} = \\mathbf{M}\\mathbf{v}$。\n2. **模能量**：使用其定义计算每个线性模中的瞬时能量 $E_k^{\\text{lin}}(t)$。所需的简正模频率平方 $\\omega_k^2$ 也被预先计算。\n3. **能量分数**：对能量进行归一化以获得分数 $f_k(t) = E_k^{\\text{lin}}(t) / \\sum_j E_j^{\\text{lin}}(t)$。\n4. **熵**：使用香农熵公式从这些分数计算归一化谱熵 $S(t)$。需要注意处理 $f_k(t)=0$ 的项，因为 $0\\ln 0 \\equiv 0$。\n\n#### 4. 能量均分时间检测\n\n模拟运行至最大时间 $T_{\\max}$。在每个采样点计算的熵值 $S(t)$ 被存储起来。模拟完成后，分析这些样本以找到能量均分时间 $T_{\\text{eq}}$。我们寻找熵 $S(t)$ 首次连续 $L$ 个样本保持在阈值（$1-\\delta$）或以上的实例。该合格序列开始时的时间被报告为 $T_{\\text{eq}}$。如果未找到这样的序列，则将 $T_{\\text{eq}}$ 设置为 $T_{\\max}$。该逻辑通过使用长度为 $L$ 的滑动窗口遍历存储的熵样本来实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function to run the FPUT simulation for the specified test cases\n    and print the results in the required format.\n    \"\"\"\n    \n    # ----------------------------------------------------------------------\n    # Define problem parameters from the statement\n    # ----------------------------------------------------------------------\n    N = 32\n    BETA = 0.1\n    DT = 0.02\n    T_MAX = 800.0\n    SAMPLE_STRIDE = 20\n    ENTROPY_TOLERANCE_DELTA = 0.2\n    PERSISTENCE_WINDOW_L = 8\n    ENERGY_DENSITIES = [0.005, 0.05, 0.3]\n\n    def calculate_force(x, beta, n_particles):\n        \"\"\"\n        Calculates the force on each particle in the FPUT chain.\n        - x: array of particle displacements (shape: (n_particles,))\n        - beta: nonlinearity parameter\n        - n_particles: number of particles\n        \"\"\"\n        # Create a padded array for positions to handle fixed boundaries\n        # x_padded corresponds to (x_0, x_1, ..., x_N, x_{N+1})\n        x_padded = np.concatenate(([0.0], x, [0.0]))\n        \n        # Calculate displacements between adjacent particles, delta_i = x_{i+1} - x_i\n        delta = np.diff(x_padded)\n        \n        # Calculate tension in each spring, T_i = delta_i + beta * delta_i^3\n        tension = delta + beta * delta**3\n        \n        # Force on particle i is T_i - T_{i-1}\n        force = np.diff(tension)\n        \n        return force\n\n    def run_fput_simulation(n, beta, dt, t_max, sample_stride, delta, L, e):\n        \"\"\"\n        Runs a single FPUT simulation for a given energy density `e`.\n        Returns the calculated equipartition time.\n        \"\"\"\n        # 1. INITIALIZATION\n        total_energy = e * n\n\n        # Find initial amplitude A by solving aY^2 + bY + c = 0 for Y = A^2\n        sin_term = np.sin(np.pi / (2 * (n + 1)))\n        a_quad = (6 * beta / (n + 1)) * sin_term**4\n        b_quad = 2 * sin_term**2\n        c_quad = -total_energy\n        \n        # Since a_quad > 0, b_quad > 0, c_quad  0, the discriminant is positive.\n        # We take the positive root for Y = A^2.\n        discriminant = b_quad**2 - 4 * a_quad * c_quad\n        Y = (-b_quad + np.sqrt(discriminant)) / (2 * a_quad)\n        A = np.sqrt(Y)\n\n        # Set initial positions and velocities for k=1 mode excitation\n        i_vals = np.arange(1, n + 1)\n        x = A * np.sqrt(2 / (n + 1)) * np.sin(np.pi * i_vals / (n + 1))\n        v = np.zeros(n)\n        \n        # 2. PRE-COMPUTATION FOR DIAGNOSTICS\n        k_vals = np.arange(1, n + 1)\n        \n        # Sine transform matrix M_ki = sqrt(2/(N+1)) * sin(pi*k*i / (N+1))\n        M = np.sqrt(2 / (n + 1)) * np.sin(np.outer(k_vals, np.pi * i_vals / (n + 1)))\n\n        # Squared harmonic frequencies omega_k^2\n        omega2_k = 4 * np.sin(np.pi * k_vals / (2 * (n + 1)))**2\n\n        # 3. TIME INTEGRATION (VELOCITY-VERLET)\n        num_steps = int(t_max / dt)\n        entropy_samples = []\n        sample_times = []\n\n        # Initial force calculation\n        f = calculate_force(x, beta, n)\n\n        for step in range(num_steps):\n            # Velocity-Verlet integration step\n            v_half = v + 0.5 * dt * f\n            x = x + dt * v_half\n            f = calculate_force(x, beta, n)\n            v = v_half + 0.5 * dt * f\n\n            # Sample diagnostics at specified stride\n            if (step + 1) % sample_stride == 0:\n                current_time = (step + 1) * dt\n                \n                # Project onto normal modes\n                Q_k = M @ x\n                P_k = M @ v\n                \n                # Calculate linear mode energies\n                E_k_lin = 0.5 * (P_k**2 + omega2_k * Q_k**2)\n                \n                total_E_lin = np.sum(E_k_lin)\n                if total_E_lin > 1e-15:\n                    f_k = E_k_lin / total_E_lin\n                    # Filter out zero fractions to avoid log(0)\n                    f_k_positive = f_k[f_k > 1e-15]\n                    H_t = -np.sum(f_k_positive * np.log(f_k_positive))\n                    S_t = H_t / np.log(n)\n                else:\n                    S_t = 0.0\n\n                entropy_samples.append(S_t)\n                sample_times.append(current_time)\n                \n        # 4. DETERMINE EQUIPARTITION TIME\n        threshold = 1.0 - delta\n        num_samples = len(entropy_samples)\n        \n        if num_samples  L:\n            return t_max\n\n        # Check for persistence window\n        for i in range(num_samples - L + 1):\n            window = entropy_samples[i : i + L]\n            if all(s >= threshold for s in window):\n                return sample_times[i] # Return time of first sample in the window\n            \n        return t_max\n\n    # ----------------------------------------------------------------------\n    # Run simulations for all specified test cases\n    # ----------------------------------------------------------------------\n    results = []\n    for energy_density in ENERGY_DENSITIES:\n        t_eq = run_fput_simulation(\n            N, BETA, DT, T_MAX, SAMPLE_STRIDE,\n            ENTROPY_TOLERANCE_DELTA, PERSISTENCE_WINDOW_L, energy_density\n        )\n        results.append(t_eq)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3452493"}, {"introduction": "在认识到系统可能无法满足遍历性之后，掌握一套可靠的诊断工具来验证模拟的正确性就变得至关重要。这项实践旨在构建一个自动化的诊断流程，用于检验恒温分子动力学轨迹是否正确地对正则系综进行采样。你将学习如何通过结合统计检验和多副本策略，系统地区分遍历性破缺与有限时间效应导致的收敛缓慢问题 [@problem_id:3452525]。", "problem": "你的任务是设计一个全自动的诊断程序，用于检验恒温分子动力学轨迹是否对正则系综进行了采样，并能从算法上区分遍历性缺失与有限时间偏差。该诊断程序必须基于第一性原理，且不应依赖任何未指定的外部启发式方法。\n\n你必须实现一个单一程序，该程序针对所提供的一维系统测试套件中的每个成员执行以下任务：\n\n1. 通过在约化单位中对一维朗之万动力学进行积分，生成两条独立的轨迹副本。在约化单位中，玻尔兹曼常数设为 $k_{\\mathrm{B}} = 1$，质量设为 $m = 1$。运动方程为\n$$\n\\frac{dx}{dt} = v, \\qquad \\frac{dv}{dt} = -\\frac{dU(x)}{dx} - \\gamma v + \\sqrt{2 \\gamma T}\\, \\eta(t),\n$$\n其中 $x$ 是位置，$v$ 是速度，$U(x)$ 是给定的势能函数，$\\gamma$ 是摩擦系数，$T$ 是温度，$\\eta(t)$ 是单位方差的高斯白噪声。使用一种尊重这些动力学特性且在指定参数下对小 $dt$ 稳定的时间离散化方案。\n\n2. 在丢弃初始的预烧（burn-in）阶段后，从模拟数据中计算用于检验正则采样和混合的诊断指标：\n   - 正则速度边际检验：在正则系综中，速度分量是均值为 $0$、方差为 $T$ 的独立高斯随机变量。使用诸如柯尔莫哥洛夫-斯米尔诺夫 (KS) 检验之类的假设检验，对照均值为 $0$、标准差为 $\\sqrt{T}$ 的正态分布，评估来自两个副本的合并速度样本是否与此分布一致。同时，计算速度的样本方差，并将其在相对容差范围内与 $T$ 进行比较。\n   - 副本一致性检验：令可观测量为 $A(t) = x(t)$。对于副本 $i \\in \\{1, 2\\}$，计算预烧阶段后轨迹的时间平均值 $\\bar{A}_i$、其样本方差 $s_i^2$ 以及其积分自相关时间 $\\tau_{\\mathrm{int}, i}$，公式如下\n     $$\n     \\tau_{\\mathrm{int}} = \\frac{1}{2} + \\sum_{t=1}^{t^\\star} \\rho(t), \\quad \\rho(t) = \\frac{C(t)}{C(0)},\n     $$\n     其中 $C(t)$ 是自协方差函数，求和在第一个非正的 $\\rho(t)$ 处或在最大可用延迟处截断。通过以下公式估算 $\\bar{A}_i$ 的标准误差\n     $$\n     \\sigma_i \\approx \\sqrt{\\frac{s_i^2 \\, 2 \\tau_{\\mathrm{int}, i}}{N_i}},\n     $$\n     其中 $N_i$ 是副本 $i$ 中预烧阶段后的样本数。使用两个副本，计算 $z$-分数\n     $$\n     z_{\\mathrm{rep}} = \\frac{|\\bar{A}_1 - \\bar{A}_2|}{\\sqrt{\\sigma_1^2 + \\sigma_2^2}},\n     $$\n     以评估两个独立的时间平均值是否在估计的不确定性范围内一致。\n   - 与正则期望值的一致性：对于每个系统，通过对权重 $e^{-U(x)/T}$ 在 $x \\in (-\\infty, \\infty)$ 上进行数值积分，计算精确的正则期望值 $\\langle x \\rangle$，\n     $$\n     \\langle x \\rangle = \\frac{\\int_{-\\infty}^{\\infty} x \\, e^{-U(x)/T} \\, dx}{\\int_{-\\infty}^{\\infty} e^{-U(x)/T} \\, dx}.\n     $$\n     使用根据积分自相关时间计算的合并标准误差，计算一个 $z$-分数，将来自两个副本的合并时间平均值 $\\bar{A}$ 与此理论值进行比较。\n   - 有限时间趋势检验：计算合并轨迹后半部分的累积移动平均值 $\\bar{A}(t)$，并使用最小二乘法对 $\\bar{A}(t)$ 与时间 $t$ 的关系进行直线拟合。使用线性回归得到的斜率的标准误差，计算斜率的 $t$-统计量。一个统计上显著的非零斜率表明时间平均值仍在漂移，这与有限时间偏差一致，而非遍历性破缺。\n\n你的程序必须为每个测试用例返回一个单一的整数分类代码，基于以下规则：\n- 如果正则速度边际检验失败（KS检验在显著性水平 $\\alpha = 10^{-3}$ 下拒绝原假设，或者速度的样本方差与 $T$ 的差异超过 $10\\%$），则输出 $0$。\n- 否则，如果副本之间相互不一致（即 $z_{\\mathrm{rep}}  3$），则输出 $3$，这表明在采样时间尺度上缺乏遍历性或混合破缺。\n- 否则，如果合并的时间平均值与理论正则期望值显著不同（即相应的 $z$-分数超过 $3$），并且有限时间趋势检验表明存在统计上显著的斜率（绝对 $t$-统计量大于 $3$），则输出 $2$，这表明存在有限时间偏差。\n- 否则，输出 $1$，表示轨迹与正则采样一致，并且未检测到混合破缺的证据。\n\n数值和物理单位：使用约化单位，其中 $k_{\\mathrm{B}} = 1$ 和 $m = 1$。时间以与离散化参数 $dt$ 一致的任意单位进行测量。任何输出都不得包含明确的单位。\n\n测试套件：将你的程序应用于以下三种情况。对于每种情况，使用指定的参数模拟两个独立的副本。丢弃指定数量的初始步骤作为预烧阶段。为副本使用独立的随机数种子。\n\n- 情况A（充分混合的谐振子）：\n  - 势能：$U(x) = \\tfrac{1}{2} k x^2$，其中 $k = 1$。\n  - 温度：$T = 1$。\n  - 摩擦系数：$\\gamma = 1$。\n  - 时间步长：$dt = 0.005$。\n  - 每个副本的总步数：$30000$。\n  - 每个副本的预烧步数：$5000$。\n  - 初始条件：两个副本均为 $x(0) = 0$, $v(0) = 0$。\n  - 使用两个不同的随机数种子。\n\n- 情况B（非遍历性双阱，在时间尺度上被捕获）：\n  - 势能：$U(x) = a(x^2 - b^2)^2 + c x$，其中 $a = 5$, $b = 1.5$, $c = 0.3$。\n  - 温度：$T = 0.2$。\n  - 摩擦系数：$\\gamma = 1$。\n  - 时间步长：$dt = 0.002$。\n  - 每个副本的总步数：$20000$。\n  - 每个副本的预烧步数：$2000$。\n  - 初始条件：副本1从 $x(0) = -b$, $v(0) = 0$ 开始；副本2从 $x(0) = +b$, $v(0) = 0$ 开始。\n  - 使用两个不同的随机数种子。\n\n- 情况C（遍历性但在可用时间尺度上存在有限时间偏差）：\n  - 势能：$U(x) = a(x^2 - b^2)^2 + c x$，其中 $a = 1$, $b = 1$, $c = 0.2$。\n  - 温度：$T = 0.5$。\n  - 摩擦系数：$\\gamma = 1$。\n  - 时间步长：$dt = 0.002$。\n  - 每个副本的总步数：$6000$。\n  - 每个副本的预烧步数：$1000$。\n  - 初始条件：两个副本均从 $x(0) = -b$, $v(0) = 0$ 开始。\n  - 使用两个不同的随机数种子。\n\n实现约束：\n- 积分方案、统计估计量和假设检验必须以数值稳定的方式实现。对于 $\\langle x \\rangle$ 的数值积分，使用一种稳定的方法，通过一个恒定的参考能量来平移势能以避免溢出；该平移在分子和分母之间会抵消。\n- 所有阈值必须严格按照规定实现：柯尔莫哥洛夫-斯米尔诺夫速度检验的 $\\alpha = 10^{-3}$，速度方差检查的 $10\\%$ 相对容差，以及 $z$-分数和斜率 $t$-统计量的临界值均为 $3$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[r_A, r_B, r_C]$），其中 $r_A$、$r_B$ 和 $r_C$ 分别是情况A、B和C的整数分类代码。\n\n你的程序必须是自包含的，并且不得接受任何输入。它必须仅使用执行环境中指定的库。所有数值答案在最终打印的列表中必须表示为整数。", "solution": "所提供的问题陈述是有效的。它在科学上基于统计力学和分子动力学的原理，问题设定良好，具有明确的目标和约束，并且没有矛盾或含糊之处。任务是设计并实现一个数值诊断套件，以评估分子动力学轨迹的收敛性和遍历性。我们将继续提供完整的解决方案。\n\n该解决方案围绕一系列应用于由朗之万动力学生成的轨迹的统计检验构建。每个检验都针对正则采样的特定方面，这由遍历性假设决定。遍历性假设假定，对于足够长的轨迹，可观测量的长时间平均值会收敛到其在相应统计系综中的系综平均值——在本例中为正则（NVT）系综。我们的诊断框架旨在检测对此原则的违反，并区分两种主要失效模式：遍历性破缺（或混合不良）和有限时间偏差（收敛缓慢）。\n\n首先，我们必须生成动力学数据。系统根据一维朗之万动力学演化，其运动方程由下式给出：\n$$\nm \\frac{d^2x}{dt^2} = -\\frac{dU(x)}{dx} - \\gamma m v + \\sqrt{2 \\gamma m k_{\\mathrm{B}} T} \\, \\eta(t)\n$$\n在指定的约化单位（$m=1$，$k_{\\mathrm{B}}=1$）中，这简化为：\n$$\n\\frac{dv}{dt} = -\\frac{dU(x)}{dx} - \\gamma v + \\sqrt{2 \\gamma T} \\, \\eta(t)\n$$\n为了对这些方程进行数值积分，我们采用BAOAB分裂方案，这是一种流行且稳健的朗之万动力学算法。该方法是时间可逆的，并能保持正确的正则分布。该方案将一个时间步长 $dt$ 离散为一系列更新步骤：\n1.  **B-步：** 将位置传播半个时间步长：$x \\leftarrow x + v \\frac{dt}{2}$。\n2.  **A-步：** 因保守力传播速度：$v \\leftarrow v - \\frac{dU(x)}{dx} \\frac{dt}{2}$。\n3.  **O-步：** 因恒温器（摩擦力和随机力）传播速度。这对应于速度的Ornstein-Uhlenbeck过程的精确解：$v \\leftarrow v e^{-\\gamma dt} + \\sqrt{T(1 - e^{-2\\gamma dt})} \\mathcal{N}(0,1)$，其中 $\\mathcal{N}(0,1)$ 是一个标准正态随机数。\n4.  **A-步：** 再次因保守力传播速度：$v \\leftarrow v - \\frac{dU(x)}{dx} \\frac{dt}{2}$。\n5.  **B-步：** 将位置传播最后半个时间步长：$x \\leftarrow x + v \\frac{dt}{2}$。\n\n对于每个测试用例，我们从指定的初始条件开始生成两个独立的轨迹（副本），但随机力项使用不同的随机数种子。每个轨迹的初始部分作为预烧阶段被丢弃，以使系统达到平衡。\n\n分析遵循一个严格的层级程序：\n\n**1. 正则速度边际检验（代码 $0$）：**\n基础检查是恒温器是否正确维持系统温度。在正则系综中，速度分布是麦克斯韦-玻尔兹曼分布，对于一维系统，这是一个均值为 $0$、方差为 $T$ 的高斯分布（因为 $m=1, k_{\\mathrm{B}}=1$）。我们使用来自两个预烧后副本的合并速度样本，通过两种方式进行检验：\n-   **分布形状：** 执行柯尔莫哥洛夫-斯米尔诺夫(KS)检验，将采样速度的经验累积分布函数（CDF）与 $\\mathcal{N}(0, T)$ 的理论CDF进行比较。如果p值低于显著性水平 $\\alpha = 10^{-3}$，我们拒绝速度是从目标分布中抽取的原假设。\n-   **分布方差：** 我们计算速度的样本方差。能量均分定理规定，平均动能 $\\frac{1}{2}m \\langle v^2 \\rangle$ 应等于 $\\frac{1}{2}k_{\\mathrm{B}}T$。对于 $m=1, k_{\\mathrm{B}}=1$，这意味着 $\\langle v^2 \\rangle = T$。我们检查样本方差与 $T$ 的偏差是否超过 $10\\%$ 的相对容差。\n这两个检验中任何一个失败，都表明模拟未能对正则系综进行采样，这是一个根本性失败，导致分类代码为 $0$。\n\n**2. 副本一致性检验（代码 $3$）：**\n如果速度分布正确，我们接下来检验遍历性。我们运行两个独立的副本，看它们是否采样到相同的统计特性。如果系统是遍历的，那么来自两个副本的可观测量的长时间平均值应收敛到相同的系综平均值，因此在统计上是不可区分的。我们使用位置 $A(t) = x(t)$ 作为我们的可观测量。\n对于每个副本 $i \\in \\{1, 2\\}$，我们计算其平均值 $\\bar{A}_i$ 及其标准误差 $\\sigma_i$。由于轨迹中的连续样本是相关的，平均值的标准误差不仅仅是样本标准差除以 $\\sqrt{N_i}$。相反，它需要通过积分自相关时间 $\\tau_{\\mathrm{int}, i}$ 进行校正：\n$$\n\\sigma_i^2 \\approx \\frac{s_i^2 \\, 2 \\tau_{\\mathrm{int}, i}}{N_i}\n$$\n其中 $s_i^2$ 是副本 $i$ 中 $A$ 的样本方差，$N_i$ 是样本数量。积分自相关时间由归一化自协方差函数 $\\rho(t)$ 计算得出：\n$$\n\\tau_{\\mathrm{int}} = \\frac{1}{2} + \\sum_{t=1}^{t^\\star} \\rho(t)\n$$\n求和在 $\\rho(t)$ 首次变为非正的延迟 $t$ 处截断，这是一种减少ACF尾部噪声的标准启发式方法。\n然后我们计算一个 $z$-分数来量化两个副本平均值之间的差异：\n$$\nz_{\\mathrm{rep}} = \\frac{|\\bar{A}_1 - \\bar{A}_2|}{\\sqrt{\\sigma_1^2 + \\sigma_2^2}}\n$$\n一个大的 $z$-分数（具体来说，$z_{\\mathrm{rep}}  3$）意味着两个副本产生了统计上显著不同的平均值，这是它们被困在相空间不同区域且系统在模拟时间尺度上没有混合的强烈信号。这表明遍历性破缺，并导致分类代码为 $3$。\n\n**3. 有限时间偏差检验（代码 $2$）：**\n如果副本是一致的，这表明它们正在采样相空间的同一区域。然而，模拟可能仍然太短，尚未完全收敛到真正的正则平均值。这被称为有限时间偏差。我们通过检查两个同时满足的条件来测试这一点：\n-   **与已知理论值不一致：** 将两个副本的合并平均值 $\\bar{A}$ 与精确的正则期望值 $\\langle A \\rangle = \\langle x \\rangle$ 进行比较。理论平均值通过数值积分计算：\n    $$\n    \\langle x \\rangle = \\frac{\\int_{-\\infty}^{\\infty} x \\, e^{-U(x)/T} \\, dx}{\\int_{-\\infty}^{\\infty} e^{-U(x)/T} \\, dx}\n    $$\n    计算一个 $z$-分数，$z_{\\text{canon}} = \\frac{|\\bar{A} - \\langle x \\rangle|}{\\sigma_{\\text{pool}}}$，其中 $\\sigma_{\\text{pool}}$ 是合并平均值的标准误差。一个显著的偏差（$z_{\\text{canon}}  3$）表明时间平均值尚未收敛到系综平均值。\n-   **持续漂移：** 我们检查数据中是否存在残留趋势。在合并轨迹的后半部分计算可观测量的累积移动平均值 $\\bar{A}(t)$。对 $\\bar{A}(t)$ 与时间 $t$ 进行线性回归。一个统计上显著的非零斜率表明平均值仍在系统性地漂移。我们使用斜率的 $t$-统计量（斜率除以其标准误差）进行此检验。$|t_{\\text{slope}}|  3$ 的值被认为是显著的。\n\n如果两个条件都满足——合并平均值与理论值不同，并且存在显著漂移——我们将该运行分类为表现出有限时间偏差，代码为 $2$。这个特征将缓慢收敛与遍历性破缺区分开来，在遍历性破缺的情况下，副本会不一致。\n\n**4. 一致的正则采样（代码 $1$）：**\n如果一个轨迹通过了所有前面的检验，我们得出结论，没有证据表明存在不正确的恒温、遍历性破缺或显著的有限时间偏差。该模拟被认为与正确的正则采样一致，并被赋予分类代码 $1$。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import kstest, linregress\nfrom scipy.integrate import quad\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Main function to run the diagnostic suite on all test cases and print results.\n    \"\"\"\n\n    # Test cases parameter definitions\n    test_cases = [\n        {\n            \"name\": \"Case A (Harmonic)\",\n            \"potential\": lambda x, k=1: 0.5 * k * x**2,\n            \"force\": lambda x, k=1: -k * x,\n            \"potential_params\": {\"k\": 1},\n            \"T\": 1.0,\n            \"gamma\": 1.0,\n            \"dt\": 0.005,\n            \"total_steps\": 30000,\n            \"burn_in_steps\": 5000,\n            \"initial_conditions\": [(0.0, 0.0), (0.0, 0.0)],\n            \"seed\": 101,\n            \"theory_mean_x\": 0.0,\n        },\n        {\n            \"name\": \"Case B (Non-ergodic)\",\n            \"potential\": lambda x, a=5, b=1.5, c=0.3: a * (x**2 - b**2)**2 + c * x,\n            \"force\": lambda x, a=5, b=1.5, c=0.3: -4 * a * x * (x**2 - b**2) - c,\n            \"potential_params\": {\"a\": 5, \"b\": 1.5, \"c\": 0.3},\n            \"T\": 0.2,\n            \"gamma\": 1.0,\n            \"dt\": 0.002,\n            \"total_steps\": 20000,\n            \"burn_in_steps\": 2000,\n            \"initial_conditions\": [(-1.5, 0.0), (1.5, 0.0)],\n            \"seed\": 202,\n            \"theory_mean_x\": \"compute\",\n        },\n        {\n            \"name\": \"Case C (Finite-time bias)\",\n            \"potential\": lambda x, a=1, b=1, c=0.2: a * (x**2 - b**2)**2 + c * x,\n            \"force\": lambda x, a=1, b=1, c=0.2: -4 * a * x * (x**2 - b**2) - c,\n            \"potential_params\": {\"a\": 1, \"b\": 1, \"c\": 0.2},\n            \"T\": 0.5,\n            \"gamma\": 1.0,\n            \"dt\": 0.002,\n            \"total_steps\": 6000,\n            \"burn_in_steps\": 1000,\n            \"initial_conditions\": [(-1.0, 0.0), (-1.0, 0.0)],\n            \"seed\": 303,\n            \"theory_mean_x\": \"compute\",\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result_code = run_diagnostic_case(case)\n        results.append(result_code)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef run_diagnostic_case(case_params):\n    \"\"\"\n    Runs the full diagnostic suite for a single test case.\n    \"\"\"\n    # --- 1. Generate Trajectories ---\n    trajectories = []\n    for i in range(2):  # Two replicas\n        seed = case_params[\"seed\"] + i\n        rng = np.random.default_rng(seed)\n        x0, v0 = case_params[\"initial_conditions\"][i]\n        \n        traj_x, traj_v = langevin_integrator(\n            x0, v0, case_params[\"force\"], case_params[\"potential_params\"],\n            case_params[\"T\"], case_params[\"gamma\"], case_params[\"dt\"],\n            case_params[\"total_steps\"], rng\n        )\n        # Discard burn-in\n        burn_in = case_params[\"burn_in_steps\"]\n        trajectories.append((traj_x[burn_in:], traj_v[burn_in:]))\n    \n    x1, v1 = trajectories[0]\n    x2, v2 = trajectories[1]\n\n    # --- 2. Perform Diagnostics ---\n    \n    # Code 0: Canonical Velocity Marginal Test\n    v_pooled = np.concatenate((v1, v2))\n    ks_stat, ks_pvalue = kstest(v_pooled, 'norm', args=(0, np.sqrt(case_params[\"T\"])))\n    \n    v_var = np.var(v_pooled)\n    v_var_rel_diff = np.abs(v_var - case_params[\"T\"]) / case_params[\"T\"]\n\n    if ks_pvalue  1e-3 or v_var_rel_diff > 0.1:\n        return 0\n\n    # Code 3: Replica Consistency Test\n    stats1 = compute_observable_stats(x1)\n    stats2 = compute_observable_stats(x2)\n    \n    mean_diff = np.abs(stats1['mean'] - stats2['mean'])\n    pooled_se = np.sqrt(stats1['se']**2 + stats2['se']**2)\n    \n    z_rep = mean_diff / pooled_se if pooled_se > 0 else np.inf\n    \n    if z_rep > 3.0:\n        return 3\n\n    # Code 2: Finite-Time Bias Test\n    # Condition 1: Inconsistency with canonical expectation\n    if case_params[\"theory_mean_x\"] == \"compute\":\n        theory_mean_x = compute_canonical_average(\n            case_params[\"potential\"], case_params[\"potential_params\"], case_params[\"T\"]\n        )\n    else:\n        theory_mean_x = case_params[\"theory_mean_x\"]\n\n    x_pooled = np.concatenate((x1, x2))\n    pooled_stats = compute_observable_stats(x_pooled)\n    \n    z_canon = np.abs(pooled_stats['mean'] - theory_mean_x) / pooled_stats['se'] if pooled_stats['se'] > 0 else np.inf\n    \n    inconsistent_with_theory = z_canon > 3.0\n\n    # Condition 2: Finite-time trend\n    second_half_start = len(x_pooled) // 2\n    x_trend_data = x_pooled[second_half_start:]\n    \n    if len(x_trend_data) > 2:\n        running_avg = np.cumsum(x_trend_data) / (np.arange(len(x_trend_data)) + 1)\n        time_points = np.arange(len(x_trend_data))\n        \n        # Linear regression can fail with constant data\n        if np.ptp(running_avg) > 1e-9:\n            lin_reg = linregress(time_points, running_avg)\n            t_stat_slope = np.abs(lin_reg.slope / lin_reg.stderr) if lin_reg.stderr > 0 else 0.0\n        else:\n            t_stat_slope = 0.0\n        \n        has_significant_trend = t_stat_slope > 3.0\n    else:\n        has_significant_trend = False\n\n    if inconsistent_with_theory and has_significant_trend:\n        return 2\n\n    # Code 1: Consistent Canonical Sampling\n    return 1\n\n\ndef langevin_integrator(x0, v0, force_func, force_params, T, gamma, dt, n_steps, rng):\n    \"\"\"\n    BAOAB Langevin integrator.\n    \"\"\"\n    x_traj, v_traj = np.zeros(n_steps), np.zeros(n_steps)\n    x, v = x0, v0\n    \n    c1 = np.exp(-gamma * dt)\n    c2 = np.sqrt(T * (1 - c1**2))\n\n    for i in range(n_steps):\n        # B\n        x = x + v * dt / 2.0\n        # A\n        f = force_func(x, **force_params)\n        v = v + f * dt / 2.0\n        # O\n        v = c1 * v + c2 * rng.normal()\n        # A\n        f = force_func(x, **force_params)\n        v = v + f * dt / 2.0\n        # B\n        x = x + v * dt / 2.0\n        \n        x_traj[i], v_traj[i] = x, v\n    \n    return x_traj, v_traj\n\n\ndef compute_acf(series):\n    \"\"\"\n    Computes the autocorrelation function using FFT.\n    \"\"\"\n    n = len(series)\n    x = series - np.mean(series)\n    \n    # Pad to next power of 2 for performance\n    fft_len = 2**int(np.ceil(np.log2(2 * n - 1)))\n    \n    f = np.fft.fft(x, n=fft_len)\n    acf_full = np.fft.ifft(f * np.conj(f)).real\n    \n    # Normalize\n    acf_normalized = acf_full[:n] / acf_full[0]\n    return acf_normalized\n\n\ndef compute_observable_stats(series):\n    \"\"\"\n    Computes mean, variance, integrated autocorrelation time, and standard error.\n    \"\"\"\n    n = len(series)\n    if n  2:\n        return {'mean': np.mean(series), 'var': 0, 'tau': 0, 'se': np.inf}\n\n    mean = np.mean(series)\n    var = np.var(series, ddof=1)\n    \n    if var  1e-12: # Constant series\n        return {'mean': mean, 'var': var, 'tau': 0, 'se': 0}\n\n    acf = compute_acf(series)\n    \n    # Truncate sum for tau_int at first non-positive value\n    positive_acf = np.where(acf > 0)[0]\n    # Find first non-consecutive index, indicating end of initial positive part\n    if len(positive_acf) > 1:\n        first_zero_crossing_idx = np.where(np.diff(positive_acf) > 1.5)[0]\n        if len(first_zero_crossing_idx) > 0:\n            t_star = positive_acf[first_zero_crossing_idx[0]]\n        else:\n            t_star = len(acf) -1\n    else:\n        t_star = 0\n            \n    # Per problem spec: tau_int = 1/2 + sum_{t=1}^{t*} rho(t)\n    tau_int = 0.5 + np.sum(acf[1:t_star + 1])\n    \n    # Guard against negative tau due to noise\n    if tau_int  0.5:\n        tau_int = 0.5\n\n    # Standard error of the mean for correlated data\n    se = np.sqrt(2 * tau_int * var / n) if n > 0 else np.inf\n    \n    return {'mean': mean, 'var': var, 'tau': tau_int, 'se': se}\n\n\ndef compute_canonical_average(potential_func, potential_params, T):\n    \"\"\"\n    Computes the exact canonical average of x by numerical integration.\n    \"\"\"\n    # Find the minimum of the potential to shift for numerical stability\n    res = minimize_scalar(lambda x: potential_func(x, **potential_params))\n    u_min = res.fun\n    \n    # Integrand for the numerator: x * exp(-(U(x) - u_min) / T)\n    numerator_integrand = lambda x: x * np.exp(-(potential_func(x, **potential_params) - u_min) / T)\n    \n    # Integrand for the denominator: exp(-(U(x) - u_min) / T)\n    denominator_integrand = lambda x: np.exp(-(potential_func(x, **potential_params) - u_min) / T)\n\n    # Perform the numerical integration\n    numerator, _ = quad(numerator_integrand, -np.inf, np.inf, limit=200)\n    denominator, _ = quad(denominator_integrand, -np.inf, np.inf, limit=200)\n    \n    if denominator == 0:\n        return 0.0 # Should not happen for these potentials\n        \n    return numerator / denominator\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3452525"}, {"introduction": "诊断出混合慢或遍历性差的问题后，下一步自然是寻求改进采样效率的方法。这项实践介绍了一种强大的增强采样算法——哈密顿蒙特卡洛（HMC）方法，并探索了部分动量更新这一变体。通过经验性地研究混合时间与算法参数（如积分步长 $\\epsilon$ 和动量持续性 $\\alpha$）之间的关系，你将亲身体验如何设计和优化高级采样算法以克服复杂的能量势垒 [@problem_id:3452503]。", "problem": "考虑使用哈密顿动力学作为一种扩展状态马尔可夫链蒙特卡洛 (MCMC) 方法，用于在分子动力学中对目标密度进行采样。目标是通过经验性地绘制混合时间估计量作为部分动量刷新参数和积分步长的函数，来研究遍历性假说与混合之间的关系。您将实现一个带有部分动量刷新的分子动力学-哈密顿蒙特卡洛 (MD-HMC) 混合方法，模拟以多元标准正态分布为目标的轨迹，并为一个标量可观测量计算经验混合时间统计量。\n\n从以下基本基础开始：\n- 对于一个坐标向量为 $q \\in \\mathbb{R}^d$、动量向量为 $p \\in \\mathbb{R}^d$ 的系统，其哈密顿力学由哈密顿量 $H(q,p) = U(q) + K(p)$ 描述。位置根据 $\\dot{q} = \\partial H / \\partial p$ 演化，动量根据 $\\dot{p} = - \\partial H / \\partial q$ 演化。\n- 对于温度归一化为1的正则系综，目标平稳密度正比于 $\\exp(-H(q,p))$，这意味着 $q$ 的边缘分布正比于 $\\exp(-U(q))$。\n- 对于多元标准正态目标，使用 $U(q) = \\tfrac{1}{2}\\, q^\\top q$ 和 $K(p) = \\tfrac{1}{2}\\, p^\\top p$，因此 $q$ 的精确目标分布是 $\\mathcal{N}(0, I_d)$。\n\n您必须精确实现以下算法：\n- 在每次马尔可夫转移时，首先执行一次部分动量刷新\n$$\np \\leftarrow \\alpha\\, p + \\sqrt{1-\\alpha^2}\\, \\eta,\n$$\n其中 $\\eta \\sim \\mathcal{N}(0, I_d)$ 是一个独立的高斯向量，$\\alpha \\in [0,1)$ 是一个持续性参数。\n- 然后，使用步长为 $\\epsilon$ 的辛蛙跳积分器，对与哈密顿量 $H(q,p)$ 相关的哈密顿流执行 $L$ 步积分：\n  - 一个蛙跳步骤包括：使用 $\\nabla U$ 进行一次半步动量更新，使用新动量进行一次整步位置更新，以及最后使用在新位置上计算的 $\\nabla U$ 进行一次半步动量更新。\n- 使用基于哈密顿量之差的 Metropolis–Hastings 接受/拒绝步骤，以确保马尔可夫链具有正确的不变分布。如果提议被拒绝，则保留当前位置并将动量反向为 $-p$，以维持细致平衡。\n\n您将通过计算平稳时间序列 $\\{A(q_t)\\}_{t=1}^{N}$（舍弃初始的预烧期数据后）的经验自相关函数，来诊断标量可观测量 $A(q) = \\lVert q \\rVert^2 = q^\\top q$ 的混合性。定义经验混合时间 $T_{\\mathrm{mix}}$ 为使得经验自相关绝对值 $\\lvert \\rho_k \\rvert$ 首次达到或低于阈值 $r_0$ 的最小整数延迟 $k \\ge 1$，即\n$$\nT_{\\mathrm{mix}} \\equiv \\min \\left\\{ k \\in \\mathbb{Z}_{\\ge 1} \\,:\\, \\lvert \\rho_k \\rvert \\le r_0 \\right\\}。\n$$\n如果在预定义的最大延迟窗口 $W$ 内不存在这样的延迟，则返回 $T_{\\mathrm{mix}} = W$。经验自相关应通过对序列进行均值中心化后计算，并对每个延迟使用无偏估计量，通过快速傅里叶变换 (FFT) 实现以确保数值效率。\n\n您的程序必须：\n- 实现上述 MD-HMC 混合算法，目标为 $d=4$ 的 $d$ 维标准正态分布。\n- 使用 $N_{\\mathrm{burn}} = 1000$ 次迭代的预烧期 (burn-in)，然后收集 $N_{\\mathrm{keep}}$ 次迭代的数据用于每个测试用例指定的分析。\n- 对每个测试用例，计算 $A(q)$ 的 $T_{\\mathrm{mix}}$，阈值为 $r_0 = 0.1$，最大延迟窗口为 $W = \\lfloor N_{\\mathrm{keep}}/2 \\rfloor$。\n- 根据每个测试用例的指定，使用独立的伪随机数生成器种子以确保可复现性。\n- 所有量均为无量纲；不涉及物理单位。\n\n测试套件：\n对于下面的每个元组 $(\\alpha, \\epsilon, L, N_{\\mathrm{keep}}, \\text{seed})$，运行一次独立的模拟并报告 $T_{\\mathrm{mix}}$：\n1. $(\\alpha, \\epsilon, L, N_{\\mathrm{keep}}, \\text{seed}) = (0.0, 0.1, 10, 5000, 12345)$。\n2. $(\\alpha, \\epsilon, L, N_{\\mathrm{keep}}, \\text{seed}) = (0.8, 0.1, 10, 5000, 12346)$。\n3. $(\\alpha, \\epsilon, L, N_{\\mathrm{keep}}, \\text{seed}) = (0.98, 0.1, 10, 5000, 12347)$。\n4. $(\\alpha, \\epsilon, L, N_{\\mathrm{keep}}, \\text{seed}) = (0.8, 0.3, 10, 5000, 12348)$。\n5. $(\\alpha, \\epsilon, L, N_{\\mathrm{keep}}, \\text{seed}) = (0.8, 1.6, 5, 5000, 12349)$。\n\n附加实现细节：\n- 在每个测试用例开始时，独立地初始化 $q_0 \\sim \\mathcal{N}(0, I_d)$ 和 $p_0 \\sim \\mathcal{N}(0, I_d)$。\n- 接受检验应使用一个涉及均匀分布随机变量的对数的数值稳定的比较方法。\n- 基于 FFT 的自相关计算必须对序列进行中心化，并通过除以 $(N-k)$ 来对每个延迟 $k$ 使用无偏归一化，然后再用零延迟值进行归一化。\n- 如果马尔可夫链暂时变得停滞（例如，由于较大的 $\\epsilon$），估计器仍必须根据上述规则返回一个有限的 $T_{\\mathrm{mix}}$，其上限为 $W$。\n\n最终输出格式：\n您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔的整数列表（例如，“[t1,t2,t3,t4,t5]”），其中每个 $t_i$ 是按上述顺序列出的测试用例 $i$ 返回的 $T_{\\mathrm{mix}}$。", "solution": "用户提供了一个在科学上和数学上都适定的问题，要求实现和分析一个分子动力学-哈密顿蒙特卡洛 (MD-HMC) 混合采样器。该问题是有效的，因为它基于统计力学和计算统计学中已建立的原理，并且所有参数、定义和程序都得到了明确的规定。我将继续提供完整的解决方案。\n\n该解决方案包含两个主要部分：首先，实现指定的 MD-HMC 算法以从目标分布生成样本；其次，分析生成的时间序列以计算经验混合时间统计量。\n\n### 1. MD-HMC 采样算法\n\n目标是从一个位置向量 $q \\in \\mathbb{R}^d$ 的目标概率分布中采样，其密度正比于 $\\exp(-U(q))$。MD-HMC 方法通过在一个包含辅助动量向量 $p \\in \\mathbb{R}^d$ 的扩展相空间中采样来实现这一目标。$(q, p)$ 的联合目标密度被取为正则系综分布 $\\pi(q, p) \\propto \\exp(-H(q,p))$，其中 $H(q,p)$ 是系统的哈密顿量。\n\n指定的哈密顿量是 $H(q,p) = U(q) + K(p)$，其中势能为 $U(q) = \\frac{1}{2} q^\\top q$，动能为 $K(p) = \\frac{1}{2} p^\\top p$。这个选择对应的 $q$ 的目标边缘分布是一个 $d$ 维标准正态分布 $\\mathcal{N}(0, I_d)$，以及一个独立的 $p$ 的标准正态分布。维度给定为 $d=4$。\n\n从状态 $(q_t, p_t)$ 到 $(q_{t+1}, p_{t+1})$ 的单次马尔可夫转移包括三个步骤：\n\n**步骤 1：部分动量刷新**\n为确保遍历性并探索哈密顿量的不同能量水平，在每次转移开始时对动量进行部分刷新。新动量 $p'$ 是旧动量 $p$ 和一个从标准正态分布 $\\mathcal{N}(0, I_d)$ 中抽取的随机向量 $\\eta$ 的线性组合：\n$$\np' = \\alpha p + \\sqrt{1-\\alpha^2} \\eta\n$$\n参数 $\\alpha \\in [0, 1)$ 控制持续程度。当 $\\alpha=0$ 时，动量被完全刷新，对应于标准的 HMC。当 $\\alpha \\to 1$ 时，动力学变得更具确定性，类似于纯粹的分子动力学。\n\n**步骤 2：通过蛙跳积分法实现哈密顿动力学**\n从 $(q_t, p')$ 出发，通过模拟哈密顿运动方程有限时间来生成一个提议状态 $(q_{\\text{prop}}, p_{\\text{prop}})$。方程为 $\\dot{q} = \\partial H / \\partial p = p$ 和 $\\dot{p} = - \\partial H / \\partial q = -\\nabla U(q)$。对于给定的势能，$\\nabla U(q) = q$。\n\n此模拟使用步长为 $\\epsilon$ 的蛙跳（或速度-Verlet）积分器执行 $L$ 步。一个蛙跳步骤，将状态从 $(q, p)$推进到 $(q_{\\text{new}}, p_{\\text{new}})$，定义如下：\n1. 动量的半步更新：$p_{\\text{half}} = p - \\frac{\\epsilon}{2} \\nabla U(q)$。\n2. 位置的整步更新：$q_{\\text{new}} = q + \\epsilon p_{\\text{half}}$。\n3. 动量的最终半步更新：$p_{\\text{new}} = p_{\\text{half}} - \\frac{\\epsilon}{2} \\nabla U(q_{\\text{new}})$。\n\n此序列被应用 $L$ 次以生成最终的提议状态 $(q_{\\text{prop}}, p_{\\text{prop}})$。\n\n**步骤 3：Metropolis-Hastings 接受/拒绝步骤**\n蛙跳积分器会引入微小误差，导致哈密顿量 $H(q,p)$ 不能被完美守恒。为了修正这一点并确保采样器的平稳分布精确地是目标分布 $\\pi(q, p)$，使用了一个 Metropolis-Hastings 步骤。提议以以下概率被接受：\n$$\nP_{\\text{accept}} = \\min\\left(1, \\exp\\left(-\\Delta H\\right)\\right)\n$$\n其中 $\\Delta H = H(q_{\\text{prop}}, p_{\\text{prop}}) - H(q_t, p')$。此比较以数值稳定的方式使用对数进行：对于一个均匀随机数 $u \\sim U(0,1)$，$\\log(u)  -\\Delta H$。\n\n- 如果接受：下一个状态是 $(q_{t+1}, p_{t+1}) = (q_{\\text{prop}}, p_{\\text{prop}})$。\n- 如果拒绝：位置被保留，$q_{t+1} = q_t$，动量被反向，$p_{t+1} = -p'$，以维持扩展空间马尔可夫链的细致平衡。\n\n模拟运行 $N_{\\text{burn}} = 1000$ 次迭代，以使链达到平衡（预烧期）。随后，收集 $N_{\\text{keep}}$ 个 $q$ 的样本用于分析。\n\n### 2. 经验混合时间估计\n\n采样器的效率通过其混合时间来评估，该时间表征了链“忘记”其历史状态的速度。一个快速混合的链能有效地探索状态空间。我们通过分析标量可观测量 $A(q) = \\|q\\|^2 = q^\\top q$ 的时间序列来估计混合时间。\n\n**步骤 1：计算经验自相关**\n给定时间序列 $\\{x_t\\}_{t=1}^{N}$，其中 $x_t = A(q_t)$ 且 $N = N_{\\text{keep}}$，我们计算其经验自相关函数 (ACF) $\\rho_k$，对于延迟 $k \\ge 1$。ACF 衡量了序列与其时间平移版本之间的相关性。\n\n问题指定对每个延迟 $k$ 使用自协方差的无偏估计量，定义为：\n$$\nC'_k = \\frac{1}{N-k} \\sum_{t=1}^{N-k} (x_t - \\bar{x})(x_{t+k} - \\bar{x})\n$$\n其中 $\\bar{x}$ 是序列的样本均值。自相关则为 $\\rho_k = C'_k / C'_0$，其中 $C'_0$ 是样本方差（除数为 $N$）：\n$$\nC'_0 = \\frac{1}{N} \\sum_{t=1}^{N} (x_t - \\bar{x})^2\n$$\n此计算中涉及的求和 $\\sum(x_t - \\bar{x})(x_{t+k} - \\bar{x})$，通过维纳-辛钦定理，使用快速傅里叶变换 (FFT) 高效计算。这是通过 `scipy.signal.correlate` 并设置 `method='fft'` 来实现的。\n\n**步骤 2：确定混合时间 $T_{\\text{mix}}$**\n经验混合时间 $T_{\\text{mix}}$ 定义为经验 ACF 的绝对值首次降至指定阈值 $r_0 = 0.1$ 以下的第一个整数延迟 $k \\ge 1$：\n$$\nT_{\\mathrm{mix}} \\equiv \\min \\left\\{ k \\in \\mathbb{Z}_{\\ge 1} \\,:\\, |\\rho_k| \\le r_0 \\right\\}\n$$\n如果 ACF 在最大延迟窗口 $W = \\lfloor N_{\\text{keep}}/2 \\rfloor$ 内没有穿过此阈值，混合时间的上限则设为 $T_{\\text{mix}} = W$。这为混合缓慢（粘滞）的链提供了一个稳健的估计。\n\n对测试套件中提供的每一组参数 $(\\alpha, \\epsilon, L, N_{\\text{keep}}, \\text{seed})$ 重复整个过程，以描绘出 $T_{\\text{mix}}$ 的变化情况。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import correlate\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (alpha, epsilon, L, N_keep, seed)\n        (0.0, 0.1, 10, 5000, 12345),\n        (0.8, 0.1, 10, 5000, 12346),\n        (0.98, 0.1, 10, 5000, 12347),\n        (0.8, 0.3, 10, 5000, 12348),\n        (0.8, 1.6, 5, 5000, 12349),\n    ]\n\n    results = []\n    for case in test_cases:\n        # Calculate the mixing time for one test case.\n        tmix = run_md_hmc_simulation(*case)\n        results.append(tmix)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef compute_tmix(q_samples):\n    \"\"\"\n    Computes the empirical mixing time T_mix for a given time series of samples.\n    \"\"\"\n    N_keep = q_samples.shape[0]\n    r0 = 0.1\n    W = N_keep // 2\n    \n    # Calculate the scalar observable A(q) = ||q||^2\n    observable_series = np.sum(q_samples**2, axis=1)\n    \n    # Center the series by subtracting its mean\n    series_mean_centered = observable_series - np.mean(observable_series)\n    N = len(series_mean_centered)\n\n    # If the series is constant, its variance is zero, and autocorrelation is ill-defined.\n    # In this case, we return the maximum possible mixing time, W.\n    if np.var(series_mean_centered) == 0:\n        return W\n\n    # Use FFT-based correlation to compute the unnormalized autocovariance sums (S_k).\n    # S[k] = sum_{i=0}^{N-1-k} x_i * x_{i+k}.\n    # We only need the second half of the 'full' correlation result for non-negative lags.\n    S = correlate(series_mean_centered, series_mean_centered, mode='full', method='fft')[N - 1:]\n    \n    # The unbiased variance estimator C'_0 is S_0 / N. This is the normalization factor for rho_k.\n    var_estimator = S[0] / N\n    \n    # Find the smallest lag k >= 1 where |rho_k| = r0.\n    for k in range(1, W + 1):\n        # Unbiased autocovariance estimator at lag k: C'_k = S_k / (N - k).\n        autocov_k = S[k] / (N - k)\n        \n        # Empirical autocorrelation at lag k: rho_k = C'_k / C'_0.\n        rho_k = autocov_k / var_estimator\n        \n        if abs(rho_k) = r0:\n            return k\n            \n    # If the threshold is not met within the lag window W, return W.\n    return W\n\ndef run_md_hmc_simulation(alpha, epsilon, L, N_keep, seed):\n    \"\"\"\n    Runs a single MD-HMC simulation for a given set of parameters.\n    \"\"\"\n    # System and simulation parameters\n    d = 4\n    N_burn = 1000\n\n    # Initialize the random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # Initial state (position and momentum) drawn from the target distribution\n    q = rng.standard_normal(d)\n    p = rng.standard_normal(d)\n    \n    # Array to store samples after burn-in\n    q_samples = np.zeros((N_keep, d))\n    \n    # The gradient of the potential U(q) = 0.5 * q^T * q is nabla_U(q) = q.\n    grad_U = lambda x: x\n    \n    # Main MCMC loop for burn-in and sampling\n    for i in range(N_burn + N_keep):\n        # Store the current position for potential rejection\n        q_current = np.copy(q)\n        \n        # 1. Partial momentum refresh\n        eta = rng.standard_normal(d)\n        p = alpha * p + np.sqrt(1.0 - alpha**2) * eta\n        p_current = np.copy(p)\n        \n        # Store initial Hamiltonian for the Metropolis-Hastings step\n        H_current = 0.5 * (q_current @ q_current + p_current @ p_current)\n        \n        # 2. Propose a new state using L steps of the leapfrog integrator\n        q_prop = np.copy(q_current)\n        p_prop = np.copy(p_current)\n        \n        for _ in range(L):\n            # A single leapfrog (or velocity-Verlet) step\n            p_prop -= 0.5 * epsilon * grad_U(q_prop)\n            q_prop += epsilon * p_prop\n            p_prop -= 0.5 * epsilon * grad_U(q_prop)\n\n        # Calculate Hamiltonian of the proposed state\n        H_prop = 0.5 * (q_prop @ q_prop + p_prop @ p_prop)\n        \n        # 3. Metropolis-Hastings accept/reject step\n        log_accept_prob = H_current - H_prop\n        \n        if np.log(rng.uniform())  log_accept_prob:\n            # Accept the proposal\n            q = q_prop\n            p = p_prop\n        else:\n            # Reject the proposal: retain position and flip momentum\n            q = q_current\n            p = -p_current\n            \n        # Collect sample after the burn-in period\n        if i >= N_burn:\n            q_samples[i - N_burn] = q\n            \n    # Compute and return the mixing time from the collected samples\n    return compute_tmix(q_samples)\n\nsolve()\n```", "id": "3452503"}]}