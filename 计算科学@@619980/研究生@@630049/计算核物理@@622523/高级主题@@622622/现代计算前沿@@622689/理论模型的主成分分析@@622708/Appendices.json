{"hands_on_practices": [{"introduction": "主成分分析不仅是一种降维工具，更是一种强大的分析手段，能够帮助我们剖析复杂模型中的不确定性来源。在核理论计算中，我们常常获得一个包含多阶微扰修正的计算结果系综，此练习将指导您如何利用PCA来分解这些修正中的协方差结构。通过将最终可观测量对各阶修正的敏感度投影到主成分基上，我们可以量化每个主导变化模式（即主成分）对最终预测不确定性的贡献，从而识别出不确定性的主要“传播路径”[@problem_id:3581450]。", "problem": "给定一个理论核模型在不同截断阶上的多体微扰修正的系综。对于索引为 $s \\in \\{0,1,\\dots,N-1\\}$ 的每个系综元素和阶数索引 $n \\in \\{1,2,\\dots,d\\}$，其修正记为 $ \\Delta E_{s}^{(n)} $。将这些修正收集到一个数据矩阵 $ X \\in \\mathbb{R}^{N \\times d} $ 中，其元素为 $ X_{s,n} = \\Delta E_{s}^{(n)} $。你需要根据这些数据执行主成分分析 (PCA)，并量化最终可观测量中的不确定性如何沿着主要修正路径传播。\n\n从以下基本定义开始：\n- 样本均值向量 $ \\mu \\in \\mathbb{R}^{d} $ 的分量为 $ \\mu_n = \\frac{1}{N} \\sum_{s=0}^{N-1} X_{s,n} $。\n- 中心化数据矩阵为 $ Y = X - \\mathbf{1}\\mu^{\\top} $，其中 $ \\mathbf{1} \\in \\mathbb{R}^{N} $ 是全1向量。\n- 无偏样本协方差矩阵为 $ \\Sigma = \\frac{1}{N-1} Y^{\\top} Y \\in \\mathbb{R}^{d \\times d} $。\n- 主成分分析通过 $ \\Sigma = U \\Lambda U^{\\top} $ 对 $ \\Sigma $ 进行对角化，其中 $ U \\in \\mathbb{R}^{d \\times d} $ 具有标准正交列 $ u_i $，$ \\Lambda = \\operatorname{diag}(\\lambda_1,\\dots,\\lambda_d) $，且特征值已排序，满足 $ \\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_d \\ge 0 $。\n- 第 $ i $ 个成分的方差解释率是 $ r_i = \\lambda_i / \\sum_{j=1}^{d} \\lambda_j $（如果分母为正），否则 $ r_i = 0 $。\n\n假设最终可观测能量的形式为 $ E_{\\mathrm{final}} = E_{\\mathrm{ref}} + \\sum_{n=1}^{d} w_n \\Delta E^{(n)} $，其中 $ w \\in \\mathbb{R}^{d} $ 是一个给定的敏感性向量。由 $ \\Delta E^{(n)} $ 的系综涨落引起的最终可观测量误差的传播方差为\n$$\n\\sigma^2 = w^{\\top} \\Sigma w.\n$$\n使用PCA基，将此方差分解为来自每个主成分的贡献，如下所示\n$$\nc_i = \\begin{cases}\n\\frac{\\lambda_i \\left( u_i^{\\top} w \\right)^2}{\\sigma^2},  \\text{if } \\sigma^2 > 0, \\\\\n0,  \\text{if } \\sigma^2 = 0,\n\\end{cases}\n$$\n使得当 $ \\sigma^2 > 0 $ 时，有 $ c_i \\ge 0 $ 且 $ \\sum_{i=1}^{d} c_i = 1 $。定义达到传播方差的目标比例 $ \\tau $ 所需的最小主成分数量 $ m $ 为满足 $ \\sum_{i=1}^{m} c_i \\ge \\tau $ 的最小 $ m $（如果 $ \\sigma^2 = 0 $，则约定 $ m = 0 $ 且对所有 $ i $ 都有 $ c_i = 0 $）。\n\n你在每个测试用例中的任务是：\n- 按指定方式确定性地构建 $ X $。\n- 从中心化数据计算 $ \\Sigma $。\n- 执行PCA以获得按 $ \\lambda_i $ 降序排列的 $ \\lambda_i $ 和 $ u_i $。\n- 计算方差解释率 $ r_i $。\n- 计算传播标准差 $ \\sigma = \\sqrt{\\sigma^2} $，单位为兆电子伏特 (MeV)。\n- 计算贡献比例 $ c_i $ 和满足 $ \\sum_{i=1}^{m} c_i \\ge \\tau $ 的最小 $ m $。\n\n所有浮点输出必须四舍五入到六位小数。最终标准差 $ \\sigma $ 必须以兆电子伏特 (MeV) 为单位表示。在确定性构建中，角度使用弧度单位。百分比必须以小数形式表示。\n\n测试套件：\n- 案例 A (通用，多因素结构)：$ N = 100 $，$ d = 5 $。对于 $ s \\in \\{0,1,\\dots,99\\} $ 和 $ n \\in \\{1,2,3,4,5\\} $，定义\n  - $ L_1(s) = \\cos(0.11\\, s) $，\n  - $ L_2(s) = \\sin(0.07\\, s + 0.3) $，\n  - $ T(s) = \\frac{s}{99} - 0.5 $，\n  - $ \\mathrm{noise}(s,n) = 0.05 \\sin(0.31\\, s + 0.77\\, n) $，\n  - 振幅 $ A = [2.0, 1.0, 0.55, 0.3, 0.15] $，\n  - $ X_{s,n} = A_n \\left( L_1(s) + 0.6\\, L_2(s) + 0.2\\, T(s) \\right) + \\mathrm{noise}(s,n) $。\n  使用 $ w = [1, 1, 1, 1, 1] $ 和 $ \\tau = 0.9 $。\n- 案例 B (各阶之间高度共线性)：$ N = 80 $，$ d = 4 $。对于 $ s \\in \\{0,1,\\dots,79\\} $ 和 $ n \\in \\{1,2,3,4\\} $，定义\n  - $ H(s) = \\cos(0.05\\, s) + 0.1 \\sin(0.13\\, s) $，\n  - $ \\mathrm{noise}(s,n) = 0.02 \\sin(0.2\\, s + 0.5\\, n) $，\n  - 系数 $ C = [1.5, 0.75, 0.38, 0.19] $，\n  - $ X_{s,n} = C_n\\, H(s) + \\mathrm{noise}(s,n) $。\n  使用 $ w = [1, 1, 1, 1] $ 和 $ \\tau = 0.95 $。\n- 案例 C (一个零方差阶)：$ N = 60 $，$ d = 3 $。对于 $ s \\in \\{0,1,\\dots,59\\} $ 和 $ n \\in \\{1,2,3\\} $，定义\n  - $ G_1(s) = 0.8 \\cos(0.09\\, s) $，\n  - $ G_2(s) = 0.6 \\sin(0.04\\, s + 0.2) $，\n  - $ X_{s,1} = 1.2\\, G_1(s) + 0.1 \\sin(0.23\\, s) $，\n  - $ X_{s,2} = 0.6\\, G_2(s) + 0.1 \\cos(0.17\\, s) $，\n  - $ X_{s,3} = 0.3 $ (对所有 $s$ 均为常数，因此中心化后方差为零)。\n  使用 $ w = [1, 0.5, 3.0] $ 和 $ \\tau = 0.8 $。\n\n要求的程序输出格式：\n- 对于每个案例，输出一个列表 $ [m, \\sigma, c\\_list, r\\_list] $，其中 $ m $ 是一个整数，$ \\sigma $ 是一个四舍五入到六位小数的浮点数（单位为 MeV），$ c\\_list $ 是包含 $d$ 个浮点数 $ [c_1,\\dots,c_d] $ 的列表（均四舍五入到六位小数），$ r\\_list $ 是包含 $d$ 个浮点数 $ [r_1,\\dots,r_d] $ 的列表（均四舍五入到六位小数）。\n- 你的程序应生成单行输出，其中包含三个案例的结果，形式为一个用方括号括起来的逗号分隔列表，例如 $ [\\mathrm{caseA\\_result}, \\mathrm{caseB\\_result}, \\mathrm{caseC\\_result}] $。", "solution": "该问题要求应用主成分分析 (PCA)来分析一个理论核模型中不确定性的传播。给定一个多体微扰修正的系综，我们需要构建一个数据矩阵，对其协方差结构执行PCA，并量化最终可观测量的方差如何在各个主成分上分布。\n\n求解过程通过一系列定义明确的统计和线性代数运算来进行。\n\n**1. 数据说明与中心化**\n\n出发点是数据矩阵 $X \\in \\mathbb{R}^{N \\times d}$，其中 $X_{s,n}$ 表示第 $s$ 个系综成员的 $n$ 阶微扰修正。$N$ 是系综成员的数量，$d$ 是微扰理论的最高阶数。\n\n首先，我们计算样本均值向量 $\\mu \\in \\mathbb{R}^{d}$，它表示在整个系综上每个阶的平均修正。其分量由下式给出：\n$$\n\\mu_n = \\frac{1}{N} \\sum_{s=0}^{N-1} X_{s,n}\n$$\n然后，通过从每个系综成员的修正向量中减去该均值来对数据进行中心化。这会得到中心化数据矩阵 $Y \\in \\mathbb{R}^{N \\times d}$：\n$$\nY = X - \\mathbf{1}\\mu^{\\top}\n$$\n其中 $\\mathbf{1} \\in \\mathbb{R}^{N}$ 是一个全1的列向量。$Y$ 的每一行代表一个系综成员围绕平均行为的涨落。\n\n**2. 协方差矩阵与主成分分析**\n\n不同微扰阶上涨落之间的相关性由无偏样本协方差矩阵 $\\Sigma \\in \\mathbb{R}^{d \\times d}$ 反映：\n$$\n\\Sigma = \\frac{1}{N-1} Y^{\\top} Y\n$$\n$\\frac{1}{N-1}$ 因子确保了对真实总体协方差的无偏估计。\n\n主成分分析 (PCA) 是通过对对称半正定的协方差矩阵 $\\Sigma$ 进行特征分解来执行的：\n$$\n\\Sigma = U \\Lambda U^{\\top}\n$$\n此处，$U$ 是一个正交矩阵，其列 $u_i$ 是 $\\Sigma$ 的特征向量，而 $\\Lambda$ 是一个包含相应非负特征值 $\\lambda_i$ 的对角矩阵。特征向量 $u_i$ 是主成分 (PCs)，它们构成了修正向量空间的一个标准正交基。特征值 $\\lambda_i$ 表示数据投影到相应主成分上的方差。按照惯例，特征值按降序排列，$\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_d \\ge 0$，因此 $u_1$ 对应于数据中方差最大的方向。\n\n**3. 方差解释率**\n\n数据集中由第 $i$ 个主成分解释的总方差比例由方差解释率 $r_i$ 给出：\n$$\nr_i = \\frac{\\lambda_i}{\\sum_{j=1}^{d} \\lambda_j}\n$$\n仅当总方差 $\\operatorname{Tr}(\\Sigma) = \\sum_{j=1}^{d} \\lambda_j$ 为正时，该值才有定义。如果总方差为零（即所有数据点都相同），则对所有 $i$ 都有 $r_i=0$。\n\n**4. 不确定性传播与分解**\n\n最终可观测量 $E_{\\mathrm{final}}$ 是微扰修正的线性组合，由敏感性向量 $w \\in \\mathbb{R}^{d}$ 加权。由系综涨落引起的 $E_{\\mathrm{final}}$ 的方差由标准的不确定性传播公式给出：\n$$\n\\sigma^2 = w^{\\top} \\Sigma w\n$$\n量 $\\sigma = \\sqrt{\\sigma^2}$ 是传播标准差。\n\n为了理解这个总传播方差是如何构成的，我们可以将其分解为来自每个主成分的贡献。将 $\\Sigma = U \\Lambda U^{\\top} = \\sum_{i=1}^{d} \\lambda_i u_i u_i^{\\top}$ 代入 $\\sigma^2$ 的表达式中，我们得到：\n$$\n\\sigma^2 = w^{\\top} \\left( \\sum_{i=1}^{d} \\lambda_i u_i u_i^{\\top} \\right) w = \\sum_{i=1}^{d} \\lambda_i (w^{\\top} u_i) (u_i^{\\top} w) = \\sum_{i=1}^{d} \\lambda_i (u_i^{\\top} w)^2\n$$\n因此，第 $i$ 个主成分对总传播方差 $\\sigma^2$ 的贡献比例 $c_i$ 为：\n$$\nc_i = \\begin{cases}\n\\frac{\\lambda_i \\left( u_i^{\\top} w \\right)^2}{\\sigma^2},  \\text{if } \\sigma^2 > 0 \\\\\n0,  \\text{if } \\sigma^2 = 0\n\\end{cases}\n$$\n根据构造，这些贡献是非负的，并且在 $\\sigma^2 > 0$ 的条件下，它们的和为1，即 $\\sum_{i=1}^{d} c_i = 1$。\n\n**5. 最小主成分集合**\n\n最后，我们确定为解释总传播方差中至少目标比例 $\\tau$ 所需的主要主成分的最小数量 $m$。这是满足以下条件的最小整数 $m \\in \\{1, \\dots, d\\}$：\n$$\n\\sum_{i=1}^{m} c_i \\ge \\tau\n$$\n如果 $\\sigma^2 = 0$，则所有贡献 $c_i$ 均为零，我们约定 $m=0$。对于给定的可观测量敏感性 $w$，$m$ 这个值提供了一个衡量不确定性传播有效维度的指标。\n\n**算法步骤**\n\n对于每个测试用例，执行以下计算步骤：\n1.  根据为 $N$ 个样本和 $d$ 个维度指定的函数，确定性地构建数据矩阵 $X$。\n2.  从 $X$ 计算无偏样本协方差矩阵 $\\Sigma$。\n3.  计算 $\\Sigma$ 的特征值 $\\lambda_i$ 和特征向量 $u_i$，并按 $\\lambda_i$ 的降序排序。\n4.  计算方差解释率 $r_i$。\n5.  使用给定的敏感性向量 $w$ 计算传播方差 $\\sigma^2$ 和传播标准差 $\\sigma$。\n6.  计算方差贡献比例 $c_i$。\n7.  通过找到 $c_i$ 的累积和首次超过阈值 $\\tau$ 的点来确定最小成分数 $m$。\n8.  按要求将所有浮点结果（$\\sigma$, $c_i$, $r_i$）四舍五入到六位小数。将最终输出组合成指定的列表格式。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_pca_metrics(X, w, tau):\n    \"\"\"\n    Performs PCA and uncertainty propagation analysis on the data matrix X.\n\n    Args:\n        X (np.ndarray): The N x d data matrix.\n        w (list or np.ndarray): The d-dimensional sensitivity vector.\n        tau (float): The target fraction for cumulative variance contribution.\n\n    Returns:\n        list: A list containing [m, sigma, c_list, r_list] with rounded values.\n    \"\"\"\n    N, d = X.shape\n    w = np.array(w)\n\n    # Handle case with insufficient data for unbiased covariance\n    if N == 1:\n        # Sigma would be undefined or zero.\n        m = 0\n        sigma_rounded = 0.0\n        c_list_rounded = [0.0] * d\n        r_list_rounded = [0.0] * d\n        return [m, sigma_rounded, c_list_rounded, r_list_rounded]\n\n    # Compute the unbiased sample covariance matrix\n    # rowvar=False because columns are variables (orders n)\n    # ddof=1 for the 1/(N-1) factor\n    Sigma = np.cov(X, rowvar=False, ddof=1)\n\n    # Perform eigendecomposition of the covariance matrix\n    # eigh is used for symmetric matrices\n    lambdas, U = np.linalg.eigh(Sigma)\n\n    # Sort eigenvalues and corresponding eigenvectors in descending order\n    sorted_indices = np.argsort(lambdas)[::-1]\n    lambdas = lambdas[sorted_indices]\n    U = U[:, sorted_indices]\n\n    # Compute explained variance ratios r_i\n    total_lambda = np.sum(lambdas)\n    if total_lambda > 1e-12:  # Use a tolerance for floating point comparison\n        r = lambdas / total_lambda\n    else:\n        r = np.zeros(d)\n        \n    # Compute propagated variance sigma^2 and standard deviation sigma\n    sigma_sq = w.T @ Sigma @ w\n    sigma = np.sqrt(sigma_sq) if sigma_sq > 0 else 0.0\n\n    # Compute variance contribution fractions c_i\n    if sigma_sq > 1e-12:\n        # U.T gives eigenvectors as rows, which is convenient for iteration\n        c = np.array([lam * (u.T @ w)**2 / sigma_sq for lam, u in zip(lambdas, U.T)])\n    else:\n        c = np.zeros(d)\n\n    # Find the minimal number of components m\n    if sigma_sq > 1e-12:\n        cumulative_c = np.cumsum(c)\n        # Find the first index where the cumulative sum is >= tau\n        # A small tolerance is added for floating point comparisons\n        m_search = np.where(cumulative_c >= tau - 1e-9)\n        if m_search[0].size > 0:\n            m = m_search[0][0] + 1\n        else:\n            # If tau is not reached (e.g., due to precision with tau=1)\n            # we consider all components to be necessary.\n            m = d\n    else: # sigma_sq is zero\n        m = 0\n\n    # Round all floating point results to six decimal places\n    sigma_rounded = np.round(sigma, 6)\n    c_list_rounded = np.round(c, 6).tolist()\n    r_list_rounded = np.round(r, 6).tolist()\n\n    return [m, sigma_rounded, c_list_rounded, r_list_rounded]\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case A: (N, d, w, tau, 'A')\n        (100, 5, [1, 1, 1, 1, 1], 0.9, 'A'),\n        # Case B: (N, d, w, tau, 'B')\n        (80, 4, [1, 1, 1, 1], 0.95, 'B'),\n        # Case C: (N, d, w, tau, 'C')\n        (60, 3, [1, 0.5, 3.0], 0.8, 'C')\n    ]\n\n    results = []\n    for case in test_cases:\n        N, d, w, tau, case_id = case\n        \n        X = np.zeros((N, d))\n        s_vals = np.arange(N)\n\n        if case_id == 'A':\n            A = np.array([2.0, 1.0, 0.55, 0.3, 0.15])\n            L1 = np.cos(0.11 * s_vals)\n            L2 = np.sin(0.07 * s_vals + 0.3)\n            # s/(N-1) for s in {0,...,N-1} spans [0,1]. N-1 is 99.\n            T = s_vals / (N - 1) - 0.5\n            base_structure = L1 + 0.6 * L2 + 0.2 * T\n            for n_idx in range(d):\n                n = n_idx + 1\n                noise = 0.05 * np.sin(0.31 * s_vals + 0.77 * n)\n                X[:, n_idx] = A[n_idx] * base_structure + noise\n\n        elif case_id == 'B':\n            C = np.array([1.5, 0.75, 0.38, 0.19])\n            H = np.cos(0.05 * s_vals) + 0.1 * np.sin(0.13 * s_vals)\n            for n_idx in range(d):\n                n = n_idx + 1\n                noise = 0.02 * np.sin(0.2 * s_vals + 0.5 * n)\n                X[:, n_idx] = C[n_idx] * H + noise\n\n        elif case_id == 'C':\n            G1 = 0.8 * np.cos(0.09 * s_vals)\n            G2 = 0.6 * np.sin(0.04 * s_vals + 0.2)\n            X[:, 0] = 1.2 * G1 + 0.1 * np.sin(0.23 * s_vals)\n            X[:, 1] = 0.6 * G2 + 0.1 * np.cos(0.17 * s_vals)\n            X[:, 2] = 0.3 # Constant value\n\n        result = calculate_pca_metrics(X, w, tau)\n        results.append(result)\n\n    # Format the final output string\n    # str() on a list converts it to '[...]' format, which is what is needed.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3581450"}, {"introduction": "在标定能量密度泛函等复杂理论模型时，一个核心挑战是诊断和处理参数间的“简并”问题，即不同的参数组合可能导致几乎无法区分的物理效应。本练习将PCA作为一个自动化的诊断工具，用于揭示这种模型病态。您将学习如何从模型对参数变化的线性响应（敏感度矩阵）出发，构建一个可观测量的协方差矩阵，并通过分析其本征谱来识别接近于零的本征值，这些“零模”直接对应于参数空间中的“软”方向或简并方向[@problem_id:3581425]。", "problem": "考虑一个 Skyrme 能量密度泛函 (EDF) 的简化校准设置，其中模型参数向量 $p \\in \\mathbb{R}^d$ 决定了可观测量向量 $y \\in \\mathbb{R}^m$。假设在校准点 $p_0$ 附近，小的微扰 $\\delta p$ 引起的可观测量变化可以通过一个线性化的灵敏度模型来描述，并且参数的变化是具有已知协方差的随机过程。所有量都通过先验归一化处理为无量纲，因此不需要物理单位。\n\n您的任务是设计并实现一个基于主成分分析 (PCA) 的测试，通过分析由参数变化引起的可观测量协方差中的近零特征值来检测参数简并性。该测试必须从第一性原理出发，使用以下基本依据进行推导：校准点周围的线性响应、具有协方差的随机变量，以及对称半正定矩阵的谱分解。您不能在问题陈述中使用任何关于诱导可观测量协方差或 PCA 的预先指定的公式；相反，您必须在解题过程中从所述的基本依据出发推导出它们。\n\n定义一个简并性检测标准如下。设可观测量协方差矩阵的特征值为 $\\{\\lambda_i\\}_{i=1}^m$，其中 $\\lambda_{\\max} = \\max_i \\lambda_i$。给定一个阈值参数 $\\tau > 0$，如果一个主成分的特征值满足 $\\lambda_i \\le \\tau \\lambda_{\\max}$，则宣布该主成分是“简并的”。简并总数 $D$ 是此类特征值的计数。$D$ 值越大，表示简并性越强。\n\n实现一个程序，对每个提供的测试用例，根据给定的灵敏度矩阵和参数协方差计算诱导的可观测量协方差矩阵，执行 PCA，并根据上述标准返回简并计数 $D$。\n\n该测试套件包含四个案例。在每个案例中，$m = d = 6$。为清晰起见，将灵敏度矩阵表示为 $S \\in \\mathbb{R}^{6 \\times 6}$，参数协方差表示为 $C_p \\in \\mathbb{R}^{6 \\times 6}$。阈值为 $\\tau = 10^{-9}$。\n\n案例 1（良态的，预计无简并）：\n- 灵敏度矩阵 $S_1$：\n$$\nS_1 = \\begin{pmatrix}\n1  0  0  0  0  0 \\\\\n0  1  0  0  0  0 \\\\\n0  0  1  0  0  0 \\\\\n0  0  0  1  0  0 \\\\\n0.5  0.2  0.1  0.3  1.0  0.0 \\\\\n0.1  0.4  0.3  0.2  0.0  1.0\n\\end{pmatrix}\n$$\n- 参数协方差 $C_{p,1}$：\n$$\nC_{p,1} = \\mathrm{diag}(1.0, 0.8, 1.2, 0.9, 1.1, 1.0)\n$$\n\n案例 2（两个参数方向之间存在精确的线性相关）：\n- 灵敏度矩阵 $S_2$ 通过将 $S_1$ 的第 5 列复制到第 6 列得到，因此第 5 列和第 6 列完全相同：\n$$\nS_2 = \\begin{pmatrix}\n1  0  0  0  0  0 \\\\\n0  1  0  0  0  0 \\\\\n0  0  1  0  0  0 \\\\\n0  0  0  1  0  0 \\\\\n0.5  0.2  0.1  0.3  1.0  1.0 \\\\\n0.1  0.4  0.3  0.2  0.0  0.0\n\\end{pmatrix}\n$$\n- 参数协方差 $C_{p,2}$：\n$$\nC_{p,2} = \\mathrm{diag}(1.0, 1.0, 1.0, 1.0, 1.0, 1.0)\n$$\n\n案例 3（具有近乎冻结方向的各向异性参数协方差）：\n- 灵敏度矩阵 $S_3$ 等于 $S_1$。\n- 参数协方差 $C_{p,3}$：\n$$\nC_{p,3} = \\mathrm{diag}(1.0, 1.0, 1.0, 1.0, 1.0, 10^{-12})\n$$\n\n案例 4（近简并：两个参数方向几乎线性相关）：\n- 灵敏度矩阵 $S_4$ 通过对 $S_2$ 的第 6 列进行轻微扰动得到，使其与第 5 列几乎但不完全相等。具体来说，设第 5 行和第 6 行的扰动量级为 $10^{-10}$：\n$$\nS_4 = \\begin{pmatrix}\n1  0  0  0  0  0 \\\\\n0  1  0  0  0  0 \\\\\n0  0  1  0  0  0 \\\\\n0  0  0  1  0  0 \\\\\n0.5  0.2  0.1  0.3  1.0  1.0 + 3 \\times 10^{-11} \\\\\n0.1  0.4  0.3  0.2  0.0  -3 \\times 10^{-11}\n\\end{pmatrix}\n$$\n- 参数协方差 $C_{p,4}$：\n$$\nC_{p,4} = \\mathrm{diag}(1.0, 1.0, 1.0, 1.0, 1.0, 1.0)\n$$\n\n您的程序必须对每个案例 $i \\in \\{1,2,3,4\\}$，使用阈值 $\\tau = 10^{-9}$ 通过基于 PCA 的标准计算简并计数 $D_i$，并生成一行输出，其中包含一个方括号内的逗号分隔列表的结果，例如 $\\texttt{[D_1,D_2,D_3,D_4]}$，其中每个 $D_i$ 是案例 $i$ 的整数 $D_i$。程序必须完全自包含，不得读取任何外部输入，并且必须完全按照给定的矩阵和阈值计算结果。此问题中不出现角度，且任何地方都不得使用百分比；任何比率都应表示为小数。", "solution": "该问题要求设计并实现一个基于主成分分析 (PCA) 的测试，用于在线性化理论模型中检测参数简并性。任务的核心是分析由模型参数的随机变化所诱导出的模型可观测量的协方差结构。\n\n基本要素包括：\n1.  线性响应模型：模型参数的微小扰动 $\\delta p \\in \\mathbb{R}^d$ 会引起模型可观测量 $\\delta y \\in \\mathbb{R}^m$ 的变化，其关系为 $\\delta y = S \\delta p$。此处，$S \\in \\mathbb{R}^{m \\times d}$ 是灵敏度矩阵，其元素 $S_{ij} = \\frac{\\partial y_i}{\\partial p_j}$ 表示在参考点 $p_0$ 处，第 $i$ 个可观测量相对于第 $j$ 个参数的偏导数。\n2.  随机参数变化：参数扰动 $\\delta p$ 被视为一个随机向量，其具有已知的协方差矩阵 $C_p \\in \\mathbb{R}^{d \\times d}$。协方差矩阵定义为 $C_p = E[(\\delta p - E[\\delta p]) (\\delta p - E[\\delta p])^T]$，其中 $E[\\cdot]$ 表示期望值。对于围绕中心值的扰动，通常假设其均值为零，$E[\\delta p] = 0$，此时 $C_p = E[\\delta p \\, \\delta p^T]$。\n\n第一步是从给定的参数协方差 $C_p$ 和线性模型中推导出可观测量的协方差矩阵 $C_y$。$\\delta y$ 的协方差矩阵定义为：\n$$C_y = E[(\\delta y - E[\\delta y]) (\\delta y - E[\\delta y])^T]$$\n根据线性模型，$\\delta y$ 的期望为 $E[\\delta y] = E[S \\delta p] = S E[\\delta p]$。将此代入 $C_y$ 的定义中：\n$$C_y = E[(S \\delta p - S E[\\delta p]) (S \\delta p - S E[\\delta p])^T]$$\n利用转置的性质和期望算子的线性性质，我们可以重构表达式：\n$$C_y = E[S (\\delta p - E[\\delta p]) (S (\\delta p - E[\\delta p]))^T]$$\n$$C_y = E[S (\\delta p - E[\\delta p]) (\\delta p - E[\\delta p])^T S^T]$$\n由于灵敏度矩阵 $S$ 是常数，可以将其从期望中提出：\n$$C_y = S E[(\\delta p - E[\\delta p]) (\\delta p - E[\\delta p])^T] S^T$$\n注意到期望内的项即为参数协方差矩阵 $C_p$ 的定义，我们得到最终表达式：\n$$C_y = S C_p S^T$$\n这个 $m \\times m$ 的矩阵概括了由参数变化引起的可观测量的方差和相关性。由于 $C_p$ 是对称半正定矩阵，因此 $C_y$ 也是对称半正定矩阵。这保证了其特征值为实数且非负。\n\n对可观测量进行主成分分析 (PCA) 等同于对其协方差矩阵 $C_y$ 进行谱分解。根据谱定理，任何像 $C_y$ 这样的实对称矩阵都可以被一个正交矩阵对角化：\n$$C_y = V \\Lambda V^T$$\n这里，$\\Lambda$ 是一个对角矩阵，其对角线上的元素 $\\{\\lambda_i\\}_{i=1}^m$ 是 $C_y$ 的特征值。正交矩阵 $V$ 的列是相应的标准正交特征向量 $\\{v_i\\}_{i=1}^m$。这些特征向量代表了主成分：可观测量空间中一组新的正交方向基。特征值 $\\lambda_i$ 是可观测量数据投影到主方向 $v_i$ 上的方差。\n\n当参数变化的不同组合导致可观测量产生几乎无法区分的变化时，就会出现参数简并。这表现为可观测量空间中某个方向的方差近乎为零。$C_y$ 的一个为零或接近零的特征值 $\\lambda_i$ 表明相应的主成分 $v_i$ 几乎没有方差。这种情况是简并的一个明确信号，因为它意味着参数变化传播到可观测量变化的方式存在约束或冗余。\n\n问题提供了一个量化标准来识别这些“简并”分量。给定一个阈值 $\\tau > 0$，如果一个特征值 $\\lambda_i$ 相对于最大特征值 $\\lambda_{\\max} = \\max_j \\lambda_j$ 异常小，则认为它表示一个简并。条件是：\n$$\\lambda_i \\le \\tau \\lambda_{\\max}$$\n简并总数 $D$ 是满足此不等式的特征值的数量。对于本问题，给定的阈值为 $\\tau = 10^{-9}$。\n\n需要为每个测试案例实现的算法如下：\n1.  给定灵敏度矩阵 $S$ 和参数协方差矩阵 $C_p$。在所提供的案例中，$m=d=6$。\n2.  使用推导出的公式计算可观测量协方差矩阵：$C_y = S C_p S^T$。\n3.  计算对称矩阵 $C_y$ 的特征值。设其为 $\\{\\lambda_i\\}_{i=1}^6$。\n4.  确定最大特征值 $\\lambda_{\\max} = \\max_i \\lambda_i$。\n5.  计算满足 $\\lambda_i \\le 10^{-9} \\lambda_{\\max}$ 的特征值数量 $D$。此计数即为该测试案例的最终结果。\n\n此过程将应用于四个测试案例，每个案例旨在探测一种不同的情景：\n- **案例 1**：一个良态系统，预计没有简并（$D_1=0$）。\n- **案例 2**：一个灵敏度矩阵 $S_2$ 的列之间存在精确线性相关的系统。这引入了秩亏，应导致 $C_y$ 恰好有一个零特征值，从而得出 $D_2=1$。\n- **案例 3**：一个其中一个参数的方差被人为抑制到非常小的值（$10^{-12}$）的系统。这种对参数方向的“冻结”预计会在可观测量中诱导出近零方差，从而产生一个非常小的特征值，得出 $D_3=1$。\n- **案例 4**：一个 $S_4$ 的列之间存在近线性相关的系统。这是对案例 2 的一种扰动，旨在使其满秩但病态。这应该会产生一个非常小但非零的特征值，该特征值仍应足够小以被标记为简并，从而得出 $D_4=1$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs PCA-based degeneracy detection on a set of test cases for a \n    linearized model calibration problem.\n    \"\"\"\n    \n    # Define the fixed threshold parameter tau\n    tau = 1e-9\n\n    # Case 1: Well-conditioned, no degeneracy expected\n    S1 = np.array([\n        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n        [0.5, 0.2, 0.1, 0.3, 1.0, 0.0],\n        [0.1, 0.4, 0.3, 0.2, 0.0, 1.0]\n    ])\n    Cp1 = np.diag([1.0, 0.8, 1.2, 0.9, 1.1, 1.0])\n    \n    # Case 2: Exact linear dependence in sensitivity matrix\n    S2 = np.array([\n        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n        [0.5, 0.2, 0.1, 0.3, 1.0, 1.0],\n        [0.1, 0.4, 0.3, 0.2, 0.0, 0.0]\n    ])\n    Cp2 = np.identity(6)\n    \n    # Case 3: Anisotropic parameter covariance, nearly frozen direction\n    S3 = S1\n    Cp3 = np.diag([1.0, 1.0, 1.0, 1.0, 1.0, 1e-12])\n    \n    # Case 4: Near-degeneracy in sensitivity matrix\n    S4 = np.array([\n        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n        [0.5, 0.2, 0.1, 0.3, 1.0, 1.0 + 3e-11],\n        [0.1, 0.4, 0.3, 0.2, 0.0, -3e-11]\n    ])\n    Cp4 = np.identity(6)\n    \n    test_cases = [\n        (S1, Cp1),\n        (S2, Cp2),\n        (S3, Cp3),\n        (S4, Cp4)\n    ]\n    \n    results = []\n    \n    for S, Cp in test_cases:\n        # Step 1: Compute the observable covariance matrix Cy = S * Cp * S^T\n        Cy = S @ Cp @ S.T\n        \n        # Step 2: Compute the eigenvalues of the symmetric matrix Cy.\n        # Use eigvalsh for numerical stability and efficiency with symmetric matrices.\n        eigenvalues = np.linalg.eigvalsh(Cy)\n        \n        # Step 3: Find the maximum eigenvalue.\n        # Check against a small positive number to handle the zero matrix case.\n        lambda_max = np.max(eigenvalues) if eigenvalues.size > 0 else 0.0\n        \n        # Step 4: Count degeneracies based on the criterion.\n        # Ensure lambda_max is not zero to avoid division by zero or spurious results.\n        if lambda_max > 1e-30:  # A small tolerance for a non-zero max eigenvalue\n            degeneracy_count = np.sum(eigenvalues = tau * lambda_max)\n        else:\n            # If all eigenvalues are effectively zero, they are all degenerate.\n            degeneracy_count = len(eigenvalues)\n            \n        results.append(int(degeneracy_count))\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3581425"}, {"introduction": "将复杂的理论模型压缩为基于PCA的快速代理模型或“模拟器”，是现代计算物理的常用策略。然而，任何有效的预测都必须伴随着可靠的不确定性量化。本练习聚焦于为PCA模拟器的预测构建精确的置信区间，这是一个高级但至关重要的任务。您将从第一性原理出发，推导如何正确地合并来自不同源头的误差，包括模拟器自身对主成分得分的预测不确定性以及因截断PCA基而引入的截断误差，最终形成一个统计上严谨的预测区间[@problem_id:3581367]。", "problem": "您正在使用主成分分析 (PCA) 模拟一个理论核模型的观测量。设 $y(\\mathbf{x})$ 表示在参数矢量 $\\mathbf{x}$ 处，某个固定原子核的双中子分离能，单位为兆电子伏特 (MeV)。一组在 $\\mathbf{x}$ 上的模型评估训练集已经过中心化处理以生成一个数据矩阵，并对这个中心化的训练输出进行了主成分分析 (PCA)。对于一个留出的参数矢量 $\\mathbf{x}^{\\ast}$，您使用 $K=2$ 个保留的主成分来重构该观测量，其表达式为\n$$\ny(\\mathbf{x}^{\\ast}) \\approx \\mu + \\sum_{j=1}^{2} \\ell_{j}\\, t_{j}(\\mathbf{x}^{\\ast}) + \\varepsilon_{\\text{trunc}},\n$$\n其中 $\\mu$ 是该观测量在训练集上的均值，$\\ell_{j}$ 是该观测量在主成分 $j$ 上的载荷系数，$t_{j}(\\mathbf{x}^{\\ast})$ 是模拟器在 $\\mathbf{x}^{\\ast}$ 处预测的主成分得分，而 $\\varepsilon_{\\text{trunc}}$ 是由忽略的主成分产生的零均值截断余项。假设如下：\n- 模拟器对得分的输出近似为高斯分布，并且在不同的 $j$ 之间是独立的，其预测分布为 $t_{j}(\\mathbf{x}^{\\ast}) \\sim \\mathcal{N}(m_{j}, v_{j})$。方差 $v_{j}$ 本身是从有限的训练数据中估计得出的，可以视为一个具有 $\\nu_{j}$ 自由度 (DoF) 的缩放卡方量。\n- 截断余项与得分无关，并被建模为 $\\varepsilon_{\\text{trunc}} \\sim \\mathcal{N}(0, \\sigma_{\\text{trunc}}^{2})$，其中 $\\sigma_{\\text{trunc}}^{2}$ 是从留出残差中估计的，并与 $\\nu_{3}$ 自由度相关联。\n- 上述所有估计量都是相互独立的，并且由于模拟器训练机制中的中心极限定理效应，正态性是一个很好的近似。\n\n从第一性原理出发，基于 PCA 重构的定义和全方差定律，推导 $y(\\mathbf{x}^{\\ast})$ 的一个双侧 $100(1-\\alpha)\\,\\%$ 预测区间，该区间应恰当地考虑多个独立方差贡献的估计。您的推导必须明确给出：\n- $y(\\mathbf{x}^{\\ast})$ 的预测均值和方差的解析形式，用 $\\mu$、$\\ell_{j}$、$m_{j}$、$v_{j}$ 和 $\\sigma_{\\text{trunc}}^{2}$ 表示。\n- 当组合多个独立的、已估计的方差分量时，为标准化预测误差构建单一有效自由度的合理解释。\n\n然后，使用您推导的表达式，根据以下数值规格计算双侧 $95\\,\\%$ 预测区间 (即 $\\alpha = 0.05$)：\n- $\\mu = 8.5$ MeV, $K=2$, $\\ell_{1} = 1.2$, $\\ell_{2} = -0.8$,\n- $m_{1} = 1.0$, $m_{2} = -0.5$,\n- $v_{1} = 0.09$, $v_{2} = 0.16$,\n- $\\sigma_{\\text{trunc}}^{2} = 0.25$,\n- $\\nu_{1} = 40$, $\\nu_{2} = 30$, $\\nu_{3} = 50$。\n\n将您的数值端点四舍五入到四位有效数字。最终能量以 MeV 表示。\n\n最后，解释一个基于统计学原理的程序，用于通过样本外测试来经验性地验证您预测区间的名义覆盖率，包括如何量化经验覆盖率估计中的不确定性，以及您将检查哪些诊断方法。该解释本身不是最终数值答案的一部分，但必须包含在您的解题思路中。", "solution": "该问题被评估为有效，因为它在科学上基于统计建模和不确定性量化，问题阐述清晰，给出的条件完整且一致，并以客观、正式的语言表达。没有矛盾、歧义或伪科学主张。该问题需要对统计原理进行标准但非平凡的应用，特别是构建一个涉及多个估计方差分量的预测区间。\n\n我们的任务是为重构的观测量 $y(\\mathbf{x}^{\\ast})$ 推导一个双侧 $100(1-\\alpha)\\%$ 预测区间。该观测量的模型由下式给出\n$$\ny(\\mathbf{x}^{\\ast}) \\approx \\mu + \\sum_{j=1}^{2} \\ell_{j} t_{j}(\\mathbf{x}^{\\ast}) + \\varepsilon_{\\text{trunc}}\n$$\n令 $Y$ 表示 $y(\\mathbf{x}^{\\ast})$ 预测值的随机变量。该模型可以写为\n$$\nY = \\mu + \\ell_{1} t_{1} + \\ell_{2} t_{2} + \\varepsilon_{\\text{trunc}}\n$$\n其中 $t_{1}$、$t_{2}$ 和 $\\varepsilon_{\\text{trunc}}$ 是独立的随机变量。在此预测的背景下，参数 $\\mu$、$\\ell_{1}$ 和 $\\ell_{2}$ 被视为固定常数。\n\n首先，我们推导 $Y$ 的预测均值和方差的解析形式。\n\n预测均值 $E[Y]$ 是通过对 $Y$ 的表达式取期望得到的。根据期望的线性性质，我们有：\n$$\nE[Y] = E[\\mu + \\ell_{1} t_{1} + \\ell_{2} t_{2} + \\varepsilon_{\\text{trunc}}] = \\mu + \\ell_{1} E[t_{1}] + \\ell_{2} E[t_{2}] + E[\\varepsilon_{\\text{trunc}}]\n$$\n我们已知关于随机分量期望的以下信息：\n- 得分 $t_{j}(\\mathbf{x}^{\\ast})$ 的预测分布是 $t_{j} \\sim \\mathcal{N}(m_{j}, v_{j})$，因此 $E[t_{j}] = m_{j}$。\n- 截断余项 $\\varepsilon_{\\text{trunc}}$ 被建模为 $\\varepsilon_{\\text{trunc}} \\sim \\mathcal{N}(0, \\sigma_{\\text{trunc}}^{2})$，因此 $E[\\varepsilon_{\\text{trunc}}] = 0$。\n将这些代入 $E[Y]$ 的表达式，得到预测均值：\n$$\nE[Y] = \\mu + \\ell_{1} m_{1} + \\ell_{2} m_{2}\n$$\n\n预测方差 $\\text{Var}(Y)$ 是通过对 $Y$ 的表达式取方差得到的。由于 $\\mu$、$\\ell_{1}$ 和 $\\ell_{2}$ 是常数，且 $t_1$、$t_2$ 和 $\\varepsilon_{\\text{trunc}}$ 是相互独立的随机变量，因此和的方差是方差的和：\n$$\n\\text{Var}(Y) = \\text{Var}(\\mu + \\ell_{1} t_{1} + \\ell_{2} t_{2} + \\varepsilon_{\\text{trunc}}) = \\text{Var}(\\ell_{1} t_{1}) + \\text{Var}(\\ell_{2} t_{2}) + \\text{Var}(\\varepsilon_{\\text{trunc}})\n$$\n使用性质 $\\text{Var}(aX) = a^2 \\text{Var}(X)$，我们得到：\n$$\n\\text{Var}(Y) = \\ell_{1}^{2} \\text{Var}(t_{1}) + \\ell_{2}^{2} \\text{Var}(t_{2}) + \\text{Var}(\\varepsilon_{\\text{trunc}})\n$$\n问题给出了各分量的方差：\n- $\\text{Var}(t_{j}) = v_j$\n- $\\text{Var}(\\varepsilon_{\\text{trunc}}) = \\sigma_{\\text{trunc}}^{2}$\n代入这些值，得到总预测方差，我们将其表示为 $V_{\\text{tot}}$：\n$$\nV_{\\text{tot}} = \\text{Var}(Y) = \\ell_{1}^{2} v_{1} + \\ell_{2}^{2} v_{2} + \\sigma_{\\text{trunc}}^{2}\n$$\n由于 $Y$ 是独立的（近似）高斯随机变量的线性组合，其预测分布也近似为高斯分布：$Y \\sim \\mathcal{N}(E[Y], V_{\\text{tot}})$。然而，方差 $V_{\\text{tot}}$ 并非精确已知，而是由分量（$v_1, v_2, \\sigma_{\\text{trunc}}^2$）估计而来，这些分量本身是具有有限自由度的估计值。因此，标准化预测误差将服从学生 t 分布 (Student's t-distribution)，而不是标准正态分布。\n\n总方差 $V_{\\text{tot}}$ 是三个独立估计的方差的线性组合。为了找到相应 t 分布的适当自由度，我们必须使用 Welch-Satterthwaite 近似。该近似提供了一种方法，用于为独立均方估计的线性组合找到有效自由度 $\\nu_{\\text{eff}}$。\n设单个估计的方差分量为 $u_{1} = \\ell_{1}^{2} v_{1}$、$u_{2} = \\ell_{2}^{2} v_{2}$ 和 $u_{3} = \\sigma_{\\text{trunc}}^{2}$。与估计值 $v_1$、$v_2$ 和 $\\sigma_{\\text{trunc}}^2$ 相关联的自由度分别为 $\\nu_1$、$\\nu_2$ 和 $\\nu_3$。$\\nu_{\\text{eff}}$ 的 Welch-Satterthwaite 公式为：\n$$\n\\nu_{\\text{eff}} = \\frac{(\\sum_{i=1}^{3} u_i)^2}{\\sum_{i=1}^{3} \\frac{u_i^2}{\\nu_i}} = \\frac{(\\ell_{1}^{2} v_{1} + \\ell_{2}^{2} v_{2} + \\sigma_{\\text{trunc}}^{2})^{2}}{\\frac{(\\ell_{1}^{2} v_{1})^{2}}{\\nu_{1}} + \\frac{(\\ell_{2}^{2} v_{2})^{2}}{\\nu_{2}} + \\frac{(\\sigma_{\\text{trunc}}^{2})^{2}}{\\nu_{3}}}\n$$\n标准化量 $T = \\frac{Y - E[Y]}{\\sqrt{V_{\\text{tot}}}}$ 服从一个具有 $\\nu_{\\text{eff}}$ 自由度的近似学生 t 分布，即 $T \\sim t_{\\nu_{\\text{eff}}}$。\n\n$Y$ 的一个双侧 $100(1-\\alpha)\\%$ 预测区间构造如下：\n$$\nE[Y] \\pm t_{1-\\alpha/2, \\nu_{\\text{eff}}} \\sqrt{V_{\\text{tot}}}\n$$\n其中 $t_{1-\\alpha/2, \\nu_{\\text{eff}}}$ 是具有 $\\nu_{\\text{eff}}$ 自由度的学生 t 分布的上 $(1-\\alpha/2)$ 临界值。\n\n现在，我们使用提供的数值计算 $95\\%$ 预测区间（$\\alpha=0.05$）：\n$\\mu = 8.5$, $\\ell_{1} = 1.2$, $\\ell_{2} = -0.8$, $m_{1} = 1.0$, $m_{2} = -0.5$, $v_{1} = 0.09$, $v_{2} = 0.16$, $\\sigma_{\\text{trunc}}^{2} = 0.25$, $\\nu_{1} = 40$, $\\nu_{2} = 30$, $\\nu_{3} = 50$。\n\n1.  计算预测均值 $E[Y]$：\n    $$\n    E[Y] = 8.5 + (1.2)(1.0) + (-0.8)(-0.5) = 8.5 + 1.2 + 0.4 = 10.1 \\, \\text{MeV}\n    $$\n2.  计算总预测方差 $V_{\\text{tot}}$：\n    $$\n    V_{\\text{tot}} = (1.2)^{2}(0.09) + (-0.8)^{2}(0.16) + 0.25 = (1.44)(0.09) + (0.64)(0.16) + 0.25\n    $$\n    $$\n    V_{\\text{tot}} = 0.1296 + 0.1024 + 0.25 = 0.4820\n    $$\n3.  计算有效自由度 $\\nu_{\\text{eff}}$：\n    方差分量为 $u_1 = 0.1296$，$u_2 = 0.1024$，$u_3 = 0.25$。\n    $$\n    \\nu_{\\text{eff}} = \\frac{(0.4820)^{2}}{\\frac{(0.1296)^{2}}{40} + \\frac{(0.1024)^{2}}{30} + \\frac{(0.25)^{2}}{50}} = \\frac{0.232324}{\\frac{0.01679616}{40} + \\frac{0.01048576}{30} + \\frac{0.0625}{50}}\n    $$\n    $$\n    \\nu_{\\text{eff}} = \\frac{0.232324}{0.000419904 + 0.0003495253\\dots + 0.00125} = \\frac{0.232324}{0.002019429\\dots} \\approx 115.045\n    $$\n4.  构建 $95\\%$ 预测区间。我们需要临界值 $t_{1-0.05/2, 115.045} = t_{0.975, 115.045}$。使用统计计算器，该值约为 $1.9808$。\n    标准差为 $\\sqrt{V_{\\text{tot}}} = \\sqrt{0.4820} \\approx 0.694262$ MeV。\n    误差范围是 $t_{0.975, 115.045} \\times \\sqrt{V_{\\text{tot}}} \\approx 1.9808 \\times 0.694262 \\approx 1.37525$ MeV。\n    区间为 $10.1 \\pm 1.37525$。\n    下界：$10.1 - 1.37525 = 8.72475$ MeV。\n    上界：$10.1 + 1.37525 = 11.47525$ MeV。\n    四舍五入到四位有效数字，下界是 $8.725$，上界是 $11.48$。\n    $95\\%$ 预测区间为 $[8.725, 11.48]$ MeV。\n\n最后，我们被要求解释一个验证这些预测区间名义覆盖率的程序。\n一个基于统计学原理的经验验证程序包括以下步骤：\n1.  **样本外测试集**：需要一个包含 $N$ 个参数矢量的大型测试集 $\\{\\mathbf{x}^{\\text{test}}_i\\}_{i=1}^N$。这些矢量不能用于模拟器的训练或 PCA 基的构建。\n2.  **基准真相计算**：对于每个 $\\mathbf{x}^{\\text{test}}_i$，运行完整的高保真核模型以获得“真实”观测量值 $y^{\\text{true}}_i = y(\\mathbf{x}^{\\text{test}}_i)$。\n3.  **预测与区间构建**：对于每个测试点 $i$，使用模拟器生成一个预测分布。这包括计算预测均值 $E_i[Y]$、总方差 $V_{\\text{tot}, i}$ 和有效自由度 $\\nu_{\\text{eff}, i}$。然后为每个点构建一个 $100(1-\\alpha)\\%$ 的预测区间 $[L_i, U_i]$。请注意，如果模拟器的预测不确定性随输入点而变化，那么 $E_i, V_{\\text{tot}, i}, \\nu_{\\text{eff}, i}$ 可能会因每个 $\\mathbf{x}^{\\text{test}}_i$ 而异。\n4.  **经验覆盖率计算**：经验覆盖率 $\\hat{p}$ 是真实值落在预测区间内的测试点的比例。定义一个指示变量 $C_i = 1$ (如果 $y^{\\text{true}}_i \\in [L_i, U_i]$) 和 $C_i = 0$ (否则)。经验覆盖率为 $\\hat{p} = \\frac{1}{N} \\sum_{i=1}^N C_i$。对于一个校准良好的模型，我们期望 $\\hat{p} \\approx 1-\\alpha$。\n5.  **不确定性量化**：经验覆盖率 $\\hat{p}$ 是对真实覆盖概率的统计估计。“成功”（覆盖事件）的次数可以建模为一个二项随机变量 $K \\sim \\text{Bin}(N, p)$。$\\hat{p}$ 的不确定性可以通过一个置信区间来量化。一个简单的 Wald 区间是 $\\hat{p} \\pm z_{1-\\beta/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N}}$，其中 $1-\\beta$ 是覆盖率区间的置信水平（例如 $95\\%$）。更稳健的方法，如 Wilson 得分区间，是更可取的。名义覆盖率 $1-\\alpha$ 应该落在这个置信区间内。\n6.  **诊断图**：可以通过诊断图进行进一步验证。最有效的是概率积分变换 (PIT) 直方图。对于每个测试点 $i$，我们计算 $z_i = F_{t, \\nu_{\\text{eff},i}}((y^{\\text{true}}_i - E_i[Y])/\\sqrt{V_{\\text{tot},i}})$，其中 $F_{t, \\nu_{\\text{eff},i}}$ 是具有相应自由度的学生 t 分布的累积分布函数 (CDF)。如果预测分布校准良好，则集合 $\\{z_i\\}$ 应在 $[0, 1]$ 上均匀分布。$z_i$ 值的直方图应近似平坦。偏离均匀性表明校准不佳：U 形表明预测方差被低估（区间过窄），而山形表明方差被高估（区间过宽）。", "answer": "$$\n\\boxed{\\begin{pmatrix} 8.725  11.48 \\end{pmatrix}}\n$$", "id": "3581367"}]}