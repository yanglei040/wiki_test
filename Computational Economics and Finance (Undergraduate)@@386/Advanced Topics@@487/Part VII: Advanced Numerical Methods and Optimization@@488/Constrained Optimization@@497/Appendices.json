{"hands_on_practices": [{"introduction": "Before applying constrained optimization to complex economic models, it is crucial to master the core mathematical technique. This first practice problem [@problem_id:4164] provides a clear, geometric scenario: finding the point on a plane that is closest to the origin. By solving it, you will build a solid foundation in setting up and solving the system of equations that arises from the method of Lagrange multipliers.", "id": "4164", "problem": "A particle moves in a three-dimensional space, and its potential energy is described by the function $U(x, y, z) = x^2 + y^2 + z^2$. The particle's motion is constrained to a flat surface defined by the equation $x + 2y + 3z = 6$.\n\nUsing the method of Lagrange multipliers, determine the minimum potential energy the particle can have while remaining on the constrained surface.\n\n", "solution": "We want to minimize $U = x^2 + y^2 + z^2$ subject to $x + 2y + 3z = 6$. Introduce Lagrange multiplier $\\lambda$ and set  \n$$L(x,y,z,\\lambda) = x^2 + y^2 + z^2 - \\lambda\\,(x + 2y + 3z - 6).$$  \nCompute partial derivatives:  \n$$\\frac{\\partial L}{\\partial x} = 2x - \\lambda = 0,$$  \n$$\\frac{\\partial L}{\\partial y} = 2y - 2\\lambda = 0,$$  \n$$\\frac{\\partial L}{\\partial z} = 2z - 3\\lambda = 0,$$  \n$$\\frac{\\partial L}{\\partial \\lambda} = -(x + 2y + 3z - 6) = 0.$$  \n\nFrom the first three equations we get  \n$$2x = \\lambda,\\quad 2y = 2\\lambda,\\quad 2z = 3\\lambda,$$  \nhence  \n$$x = \\frac{\\lambda}{2},\\quad y = \\lambda,\\quad z = \\frac{3\\lambda}{2}.$$  \n\nSubstitute into the constraint:  \n$$\\frac{\\lambda}{2} + 2\\lambda + 3\\cdot\\frac{3\\lambda}{2} = 6.$$  \nCombine terms:  \n$$\\frac{\\lambda}{2} + 2\\lambda + \\frac{9\\lambda}{2} = 6,\\quad\n\\frac{1\\lambda + 4\\lambda + 9\\lambda}{2} = 6,\\quad\n7\\lambda = 6\\quad\\Longrightarrow\\quad \\lambda = \\frac{6}{7}.$$  \n\nThus the critical point is  \n$$x = \\frac{3}{7},\\quad y = \\frac{6}{7},\\quad z = \\frac{9}{7}.$$  \nEvaluate the potential:  \n$$U_{\\min} = \\left(\\frac{3}{7}\\right)^2 + \\left(\\frac{6}{7}\\right)^2 + \\left(\\frac{9}{7}\\right)^2\n= \\frac{9 + 36 + 81}{49} = \\frac{126}{49} = \\frac{18}{7}.$$", "answer": "$$\\boxed{\\frac{18}{7}}$$"}, {"introduction": "With the basics of Lagrange multipliers established, we can now apply this powerful tool to a cornerstone of microeconomic theory: consumer choice. This exercise [@problem_id:2293283] asks you to maximize an individual's utility, represented by a Stone-Geary function, subject to a budget constraint. This practice demonstrates how constrained optimization provides a formal framework for understanding rational economic behavior and resource allocation.", "id": "2293283", "problem": "An economics student, Alex, is analyzing their monthly budget for digital consumption. Alex's satisfaction is modeled by a Stone-Geary utility function, $U(x, y) = (x-x_{0})^{0.4}(y-y_{0})^{0.6}$, where $x$ represents the total monthly mobile data used in Gigabytes (GB) and $y$ represents the number of streaming service subscriptions. Based on past behavior, Alex determines that the subsistence levels of consumption, below which no utility is gained, are $x_0 = 5$ GB of data and $y_0 = 1$ streaming service.\n\nThe price of mobile data is $p_x = \\$2$ per GB, and the price of each streaming service is $p_y = \\$15$. Alex has a total monthly budget of $I = \\$200$ allocated for these two items. To simplify the model, both $x$ and $y$ can be treated as continuous real variables.\n\nAssuming Alex wants to maximize their utility subject to the budget constraint, determine the optimal consumption bundle. Find the values of $x$ and $y$ that maximize Alex's utility. Present your answer as a pair $(x, y)$, with each value rounded to three significant figures.\n\n", "solution": "We maximize the Stone-Geary utility $U(x,y)=(x-x_{0})^{a}(y-y_{0})^{b}$ with $a=0.4$ and $b=0.6$, subject to the budget constraint $p_{x}x+p_{y}y=I$ and the domain constraints $x\\geq x_{0}$, $y\\geq y_{0}$. Since $\\ln$ is strictly increasing and $x>x_{0}$, $y>y_{0}$ at an interior optimum, we equivalently maximize $\\ln U=a\\ln(x-x_{0})+b\\ln(y-y_{0})$ subject to $p_{x}x+p_{y}y=I$.\n\nForm the Lagrangian\n$$\n\\mathcal{L}=a\\ln(x-x_{0})+b\\ln(y-y_{0})+\\lambda\\left(I-p_{x}x-p_{y}y\\right).\n$$\nFirst-order conditions for an interior optimum are\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial x}=\\frac{a}{x-x_{0}}-\\lambda p_{x}=0,\\quad\n\\frac{\\partial \\mathcal{L}}{\\partial y}=\\frac{b}{y-y_{0}}-\\lambda p_{y}=0,\\quad\n\\frac{\\partial \\mathcal{L}}{\\partial \\lambda}=I-p_{x}x-p_{y}y=0.\n$$\nFrom the first two conditions,\n$$\nx-x_{0}=\\frac{a}{\\lambda p_{x}},\\qquad y-y_{0}=\\frac{b}{\\lambda p_{y}}.\n$$\nSubstitute into the budget constraint:\n$$\np_{x}\\left(x_{0}+\\frac{a}{\\lambda p_{x}}\\right)+p_{y}\\left(y_{0}+\\frac{b}{\\lambda p_{y}}\\right)=I\n\\;\\;\\Longrightarrow\\;\\;\np_{x}x_{0}+p_{y}y_{0}+\\frac{a}{\\lambda}+\\frac{b}{\\lambda}=I.\n$$\nHence\n$$\n\\frac{a+b}{\\lambda}=I-p_{x}x_{0}-p_{y}y_{0}\n\\;\\;\\Longrightarrow\\;\\;\n\\lambda=\\frac{a+b}{\\,I-p_{x}x_{0}-p_{y}y_{0}\\,}.\n$$\nTherefore,\n$$\nx^{\\ast}=x_{0}+\\frac{a}{p_{x}}\\cdot\\frac{I-p_{x}x_{0}-p_{y}y_{0}}{a+b},\\qquad\ny^{\\ast}=y_{0}+\\frac{b}{p_{y}}\\cdot\\frac{I-p_{x}x_{0}-p_{y}y_{0}}{a+b}.\n$$\nWith $a=0.4$, $b=0.6$ so that $a+b=1$, $x_{0}=5$, $y_{0}=1$, $p_{x}=2$, $p_{y}=15$, and $I=200$, the discretionary income is\n$$\nI-p_{x}x_{0}-p_{y}y_{0}=200-2\\cdot 5-15\\cdot 1=175>0,\n$$\nso an interior solution exists. Then\n$$\nx^{\\ast}=5+\\frac{0.4}{2}\\cdot 175=5+35=40,\\qquad\ny^{\\ast}=1+\\frac{0.6}{15}\\cdot 175=1+7=8.\n$$\nThis bundle is feasible and exhausts the budget: $2\\cdot 40+15\\cdot 8=200$. Rounding each value to three significant figures gives $x^{\\ast}=40.0$ and $y^{\\ast}=8.00$.", "answer": "$$\\boxed{\\begin{pmatrix}40.0 & 8.00\\end{pmatrix}}$$"}, {"introduction": "While Lagrange multipliers are elegant for problems with analytical solutions, many real-world scenarios require computational methods. This thought experiment [@problem_id:2193334] delves into the logic of penalty methods, a common approach for solving constrained problems numerically. By comparing a correct and an incorrect penalty function for an inequality constraint, you will gain critical insight into how algorithms are designed to handle constraints, a vital concept for any computational economist.", "id": "2193334", "problem": "An engineer is tasked with solving a simple one-dimensional constrained optimization problem:\n\nMinimize the function $f(x) = (x-a)^2$\nsubject to the inequality constraint $g(x) = x-b \\le 0$.\n\nThe parameters $a$ and $b$ are fixed real constants, with the known relationship $a < b$.\n\nThe engineer decides to use a quadratic penalty method to approximate the solution. However, they are unsure about the correct form of the penalty term for the inequality constraint. They consider two different augmented objective functions, where $\\mu > 0$ is the penalty parameter:\n\n**Method 1:** The augmented function is $P_1(x; \\mu) = (x-a)^2 + \\frac{\\mu}{2} \\left(\\max\\{0, x-b\\}\\right)^2$.\n**Method 2:** The augmented function is $P_2(x; \\mu) = (x-a)^2 + \\frac{\\mu}{2} (x-b)^2$.\n\nFor each method, the engineer finds the value of $x$ that minimizes the corresponding augmented function. Let's denote these minimizers as $x_1^*(\\mu)$ for $P_1(x; \\mu)$ and $x_2^*(\\mu)$ for $P_2(x; \\mu)$. The goal of the penalty method is for the sequence of unconstrained minimizers to converge to the true solution of the original constrained problem, $x^*$, as the penalty parameter $\\mu$ approaches infinity.\n\nYour task is to analyze this situation. First, determine the exact solution, $x^*$, to the original constrained problem. Then, for each of the two methods, find the limit of the unconstrained minimizer as $\\mu \\to \\infty$.\n\nPresent your three results—the true solution $x^*$, the limit for Method 1 ($\\lim_{\\mu \\to \\infty} x_1^*(\\mu)$), and the limit for Method 2 ($\\lim_{\\mu \\to \\infty} x_2^*(\\mu)$)—as a row matrix in that specific order.\n\n", "solution": "We first solve the original constrained optimization problem:\nMinimize $f(x) = (x - a)^{2}$ subject to $x - b \\le 0$, i.e., $x \\le b$. The unconstrained minimizer of $f$ is $x = a$. Since $a < b$, the unconstrained minimizer is feasible, so the exact solution is\n$$\nx^{*} = a.\n$$\n\nFor Method 1, the augmented objective is $P_{1}(x; \\mu) = (x - a)^{2} + \\frac{\\mu}{2} \\left(\\max\\{0, x - b\\}\\right)^{2}$. Minimize $P_{1}$ by considering two regions.\n\nIf $x \\le b$, then $\\max\\{0, x - b\\} = 0$, so $P_{1}(x; \\mu) = (x - a)^{2}$. The derivative condition $2(x - a) = 0$ gives $x = a$, which satisfies $x \\le b$ because $a < b$. The value is $P_{1}(a; \\mu) = 0$.\n\nIf $x > b$, then $P_{1}(x; \\mu) = (x - a)^{2} + \\frac{\\mu}{2} (x - b)^{2}$. Differentiating and setting to zero gives\n$$\n2(x - a) + \\mu (x - b) = 0 \\;\\;\\Rightarrow\\;\\; (2 + \\mu) x = 2 a + \\mu b \\;\\;\\Rightarrow\\;\\; x = \\frac{2 a + \\mu b}{2 + \\mu}.\n$$\nCheck feasibility for this region:\n$$\nx - b = \\frac{2 a + \\mu b}{2 + \\mu} - b = \\frac{2(a - b)}{2 + \\mu} < 0 \\quad \\text{since } a < b,\n$$\nso the stationary point lies outside $x > b$. By convexity, the minimum over $x > b$ occurs at the boundary $x = b$, where $P_{1}(b; \\mu) = (b - a)^{2} > 0$. Since $P_{1}(a; \\mu) = 0$, the global minimizer is $x_{1}^{*}(\\mu) = a$ for all $\\mu > 0$. Therefore,\n$$\n\\lim_{\\mu \\to \\infty} x_{1}^{*}(\\mu) = a.\n$$\n\nFor Method 2, the augmented objective is $P_{2}(x; \\mu) = (x - a)^{2} + \\frac{\\mu}{2} (x - b)^{2}$. Differentiating and setting to zero gives\n$$\n2(x - a) + \\mu (x - b) = 0 \\;\\;\\Rightarrow\\;\\; (2 + \\mu) x = 2 a + \\mu b \\;\\;\\Rightarrow\\;\\; x_{2}^{*}(\\mu) = \\frac{2 a + \\mu b}{2 + \\mu}.\n$$\nTaking the limit,\n$$\n\\lim_{\\mu \\to \\infty} x_{2}^{*}(\\mu) = \\lim_{\\mu \\to \\infty} \\frac{2 a + \\mu b}{2 + \\mu} = b.\n$$\n\nThus, the results in the requested order are $x^{*} = a$, $\\lim_{\\mu \\to \\infty} x_{1}^{*}(\\mu) = a$, and $\\lim_{\\mu \\to \\infty} x_{2}^{*}(\\mu) = b$.", "answer": "$$\\boxed{\\begin{pmatrix} a & a & b \\end{pmatrix}}$$"}]}