{"hands_on_practices": [{"introduction": "A cornerstone of analyzing Markov chains is understanding their long-run behavior. For many economic systems that can be modeled as a regular Markov chain, the process eventually settles into a stable equilibrium described by a stationary distribution. This foundational exercise guides you through calculating this stationary distribution, $\\pi$, for a simple model of labor market dynamics, connecting this abstract mathematical concept to the tangible economic indicator of the long-run unemployment rate [@problem_id:2409051].", "id": "2409051", "problem": "Consider a discrete-time, time-homogeneous Markov chain that models a representative worker’s weekly labor market status in an economy. The state space consists of Unemployed ($U$), Part-Time ($P$), and Full-Time ($F$). Transitions between states occur at the end of each week according to the following row-stochastic transition matrix $P$, where the state ordering is $(U, P, F)$:\n$$\nP \\;=\\;\n\\begin{pmatrix}\n\\frac{3}{5} & \\frac{3}{10} & \\frac{1}{10} \\\\\n\\frac{1}{5} & \\frac{1}{2} & \\frac{3}{10} \\\\\n\\frac{1}{20} & \\frac{3}{20} & \\frac{4}{5}\n\\end{pmatrix}.\n$$\nUnder these assumptions, determine the long-run unemployment rate implied by $P$, defined as the stationary (invariant) probability of being in state $U$ in the unique stationary distribution of the chain. Provide your answer as an exact fraction (no rounding), expressed as a decimal or a fraction without a percentage sign.", "solution": "The system is a discrete-time, time-homogeneous Markov chain with a finite state space $\\{U, P, F\\}$. A stationary (invariant) distribution $\\pi$ is a row vector $\\pi = (\\pi_U, \\pi_P, \\pi_F)$ satisfying the defining conditions\n$$\n\\pi = \\pi P, \\quad \\pi_U + \\pi_P + \\pi_F = 1, \\quad \\pi_i \\ge 0 \\text{ for each state } i \\in \\{U, P, F\\}.\n$$\nBecause every entry of $P$ is strictly positive, the chain is irreducible and aperiodic, which by the Perron–Frobenius theorem ensures the existence and uniqueness of the stationary distribution.\n\nLet $\\pi = (x, y, z)$ with $x = \\pi_U$, $y = \\pi_P$, and $z = \\pi_F$. The stationarity condition $\\pi = \\pi P$ yields the system\n$$\n\\begin{aligned}\nx &= \\frac{3}{5}x + \\frac{1}{5}y + \\frac{1}{20}z, \\\\\ny &= \\frac{3}{10}x + \\frac{1}{2}y + \\frac{3}{20}z, \\\\\nz &= \\frac{1}{10}x + \\frac{3}{10}y + \\frac{4}{5}z,\n\\end{aligned}\n$$\ntogether with the normalization condition\n$$\nx + y + z = 1.\n$$\nRewriting the first two equations by moving all terms to the left-hand side:\n$$\n\\begin{aligned}\nx - \\frac{3}{5}x - \\frac{1}{5}y - \\frac{1}{20}z &= 0\n\\;\\;\\Rightarrow\\;\\;\n\\frac{2}{5}x - \\frac{1}{5}y - \\frac{1}{20}z = 0, \\\\\ny - \\frac{3}{10}x - \\frac{1}{2}y - \\frac{3}{20}z &= 0\n\\;\\;\\Rightarrow\\;\\;\n\\frac{1}{2}y - \\frac{3}{10}x - \\frac{3}{20}z = 0.\n\\end{aligned}\n$$\nMultiply the first of these by $20$ and the second by $20$ to clear denominators:\n$$\n\\begin{aligned}\n8x - 4y - z &= 0, \\\\\n-6x + 10y - 3z &= 0.\n\\end{aligned}\n$$\nFrom the first equation,\n$$\nz = 8x - 4y.\n$$\nSubstitute this into the second equation:\n$$\n-6x + 10y - 3(8x - 4y) = 0\n\\;\\;\\Rightarrow\\;\\;\n-6x + 10y - 24x + 12y = 0\n\\;\\;\\Rightarrow\\;\\;\n-30x + 22y = 0\n\\;\\;\\Rightarrow\\;\\;\ny = \\frac{15}{11}x.\n$$\nThen\n$$\nz = 8x - 4y = 8x - 4\\left(\\frac{15}{11}x\\right) = \\left(\\frac{88}{11} - \\frac{60}{11}\\right)x = \\frac{28}{11}x.\n$$\nApply the normalization condition:\n$$\nx + y + z = 1\n\\;\\;\\Rightarrow\\;\\;\nx + \\frac{15}{11}x + \\frac{28}{11}x = 1\n\\;\\;\\Rightarrow\\;\\;\n\\left(1 + \\frac{15}{11} + \\frac{28}{11}\\right)x = 1\n\\;\\;\\Rightarrow\\;\\;\n\\frac{54}{11}x = 1\n\\;\\;\\Rightarrow\\;\\;\nx = \\frac{11}{54}.\n$$\nTherefore, the stationary distribution is\n$\n\\pi = \\left(\\frac{11}{54}, \\frac{15}{54}, \\frac{28}{54}\\right) = \\left(\\frac{11}{54}, \\frac{5}{18}, \\frac{14}{27}\\right),\n$\nand the long-run unemployment rate, which is the stationary probability of being in state $U$, is\n$$\n\\pi_U = \\frac{11}{54}.\n$$\nThis is already an exact fraction, as requested.", "answer": "$$\\boxed{\\frac{11}{54}}$$"}, {"introduction": "While some systems evolve towards a stable, repeating equilibrium, others progress towards a terminal, absorbing state. This is common in finance, where events like bankruptcy or loan default represent irreversible endpoints. This practice introduces the concept of absorbing Markov chains and teaches the essential skill of calculating the expected time to absorption, a critical metric in risk assessment and financial modeling [@problem_id:2409067].", "id": "2409067", "problem": "A firm's credit rating is represented by a discrete-time, time-homogeneous Markov chain with yearly transitions among the ordered states $\\{\\text{AAA}, \\text{AA}, \\text{A}, \\text{BBB}, \\text{BB}, \\text{B}, \\text{CCC}, \\text{D}\\}$, where $\\text{D}$ denotes default and is absorbing. The one-step transition matrix $P$ (rows sum to $1$) in this state order is\n$$\nP \\;=\\;\n\\begin{pmatrix}\n0.5 & 0.5 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0.5 & 0.5 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0.5 & 0.5 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0.5 & 0.5 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0.5 & 0.5 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0.5 & 0.5 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0.5 & 0.5 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n\\end{pmatrix}.\n$$\nAt each year, a firm in a non-default state either remains at its current rating with probability $0.5$ or is downgraded by one notch with probability $0.5$. A firm at state $\\text{CCC}$ either remains at $\\text{CCC}$ with probability $0.5$ or defaults ($\\text{D}$) with probability $0.5$. State $\\text{D}$ is absorbing.\n\nAssuming the firm starts the year at rating $\\text{A}$, determine the expected number of years until it reaches default. Provide your answer as an exact value in years (no rounding).", "solution": "The problem is to determine the expected number of years until a firm, currently at credit rating $\\text{A}$, defaults. This is a classic problem of calculating the expected time to absorption in a discrete-time, time-homogeneous Markov chain.\n\nLet the state space of the Markov chain be $S = \\{s_1, s_2, s_3, s_4, s_5, s_6, s_7, s_8\\}$, where $s_1 = \\text{AAA}$, $s_2 = \\text{AA}$, $s_3 = \\text{A}$, $s_4 = \\text{BBB}$, $s_5 = \\text{BB}$, $s_6 = \\text{B}$, $s_7 = \\text{CCC}$, and $s_8 = \\text{D}$ (default). The state $s_8$ is an absorbing state, while states $\\{s_1, \\dots, s_7\\}$ are transient. The initial state of the firm is $s_3 = \\text{A}$. The transition matrix is given by $P$.\n\nLet $\\mu_i$ be the expected number of years (steps) to reach the absorbing state $s_8$ (default), starting from state $s_i$. Our objective is to find $\\mu_3$.\n\nBy definition, the expected time to absorption from an absorbing state is zero. Thus, we have:\n$$ \\mu_8 = 0 $$\n\nFor any transient state $s_i$ where $i \\in \\{1, 2, \\dots, 7\\}$, we can establish a system of linear equations for $\\mu_i$ by conditioning on the outcome of the first step. The expected time from state $s_i$ is one year plus the expected future time from the state $s_j$ reached after that year, averaged over all possible next states $s_j$. This is formulated as:\n$$ \\mu_i = 1 + \\sum_{j=1}^{8} P_{ij} \\mu_j $$\nwhere $P_{ij}$ is the probability of transitioning from state $s_i$ to state $s_j$ in one step.\n\nFrom the provided transition matrix $P$:\nFor any non-default, non-CCC rating (i.e., for $i \\in \\{1, 2, \\dots, 6\\}$), the firm either remains in state $s_i$ with probability $0.5$ or is downgraded to state $s_{i+1}$ with probability $0.5$. The transition probabilities are $P_{ii} = 0.5$, $P_{i,i+1} = 0.5$, and $P_{ij} = 0$ for all other $j$. The equation for $\\mu_i$ is:\n$$ \\mu_i = 1 + P_{ii}\\mu_i + P_{i,i+1}\\mu_{i+1} = 1 + 0.5\\mu_i + 0.5\\mu_{i+1} $$\nRearranging this equation, we get a recurrence relation for $i \\in \\{1, 2, \\dots, 6\\}$:\n$$ 0.5\\mu_i = 1 + 0.5\\mu_{i+1} $$\n$$ \\mu_i = 2 + \\mu_{i+1} $$\n\nFor the state $s_7 = \\text{CCC}$, the firm either remains in state $s_7$ with probability $P_{77}=0.5$ or defaults to state $s_8$ with probability $P_{78}=0.5$. The equation for $\\mu_7$ is:\n$$ \\mu_7 = 1 + P_{77}\\mu_7 + P_{78}\\mu_8 = 1 + 0.5\\mu_7 + 0.5\\mu_8 $$\nSubstituting $\\mu_8 = 0$, we have:\n$$ \\mu_7 = 1 + 0.5\\mu_7 $$\n$$ 0.5\\mu_7 = 1 $$\n$$ \\mu_7 = 2 $$\nSo, the expected time to default from state $\\text{CCC}$ is $2$ years.\n\nNow we can use the recurrence relation $\\mu_i = 2 + \\mu_{i+1}$ to solve for the remaining $\\mu_i$ by backward substitution, starting from $\\mu_7$:\n\nFor state $s_6 = \\text{B}$:\n$$ \\mu_6 = 2 + \\mu_7 = 2 + 2 = 4 $$\n\nFor state $s_5 = \\text{BB}$:\n$$ \\mu_5 = 2 + \\mu_6 = 2 + 4 = 6 $$\n\nFor state $s_4 = \\text{BBB}$:\n$$ \\mu_4 = 2 + \\mu_5 = 2 + 6 = 8 $$\n\nFinally, for the initial state $s_3 = \\text{A}$:\n$$ \\mu_3 = 2 + \\mu_4 = 2 + 8 = 10 $$\n\nThe expected number of years until the firm defaults, starting from rating $\\text{A}$, is $10$.\nThe problem is now solved. The reasoning is complete and scientifically sound.", "answer": "$$\n\\boxed{10}\n$$"}, {"introduction": "Moving from theory to application, this hands-on exercise demonstrates how to use Markov chains as an empirical tool to analyze real-world data. You will learn to estimate a transition matrix from an observed sequence of events and, more importantly, how to statistically test for a \"structural break\" — a significant change in the system's underlying dynamics between two periods. This practice is a crucial step towards using these models for robust econometric analysis, such as determining if market behavior has fundamentally changed over time [@problem_id:2409049].", "id": "2409049", "problem": "You are asked to implement a self-contained program that evaluates whether there is a statistically significant change in the dynamics of an equity market across two historical periods using a discrete-time, finite-state Markov chain. The two periods are intended to reflect $1980$–$2000$ and $2001$–$2021$, but for this assignment you must use only the provided test cases, which are synthetic yet financially plausible return sequences expressed as decimal returns. A three-state Markov chain is used with states $\\{\\text{Loss}, \\text{Flat}, \\text{Gain}\\}$ defined by classifying each return $r_t$ according to a symmetric band threshold $\\tau &gt; 0$ as follows: $\\text{Loss}$ if $r_t &lt; -\\tau$, $\\text{Flat}$ if $|r_t| \\le \\tau$, and $\\text{Gain}$ if $r_t &gt; \\tau$. For each period, you must estimate the transition probability matrix from the observed sequence of states and test the null hypothesis that the two periods share the same transition matrix against the alternative that they differ. Your program must return, for each test case, a single boolean answering whether the change is statistically significant at a given significance level $\\alpha$.\n\nYour program must interpret the input parameters implicitly from the test suite described below. For each test case $k$, the inputs are:\n- A classification threshold $\\tau_k$ (unitless; returns are decimals).\n- A significance level $\\alpha_k$ (unitless).\n- Two sequences of decimal returns, $\\{r^{(1)}_{t}\\}_{t=1}^{T^{(1)}}$ for period $1$ and $\\{r^{(2)}_{t}\\}_{t=1}^{T^{(2)}}$ for period $2$, where $T^{(1)} \\ge 2$ and $T^{(2)} \\ge 2$.\n\nFrom first principles:\n- Treat the time series of classified states as a realization of a time-homogeneous first-order Markov chain on the state space $\\{\\text{Loss}, \\text{Flat}, \\text{Gain}\\}$.\n- For each period $m \\in \\{1,2\\}$, construct the $3 \\times 3$ transition count matrix $N^{(m)} = [n^{(m)}_{ij}]$ where $n^{(m)}_{ij}$ counts the number of transitions from origin state $i$ to destination state $j$ across consecutive times within that period. Adopt a fixed state order $(\\text{Loss}, \\text{Flat}, \\text{Gain})$ throughout.\n- Estimate each period’s transition probability matrix $\\hat{P}^{(m)} = [\\hat{p}^{(m)}_{ij}]$ by the maximum likelihood estimator $\\hat{p}^{(m)}_{ij} = n^{(m)}_{ij}/\\sum_{j} n^{(m)}_{ij}$ for any origin state $i$ with at least one observed outgoing transition (rows with zero total outgoing transitions contribute no parameters or likelihood).\n- Test the null hypothesis that both periods share a common transition matrix using an appropriate likelihood-based statistical test grounded in the multinomial model for each origin row. The decision rule must be: reject the null if and only if the $p$-value is strictly less than $\\alpha$.\n- If, for a particular origin state, at least one of the two periods has zero total outgoing transitions, then that origin state contributes neither parameters nor degrees of freedom to the test and its likelihood contribution is defined to be zero.\n\nYour program must produce a single line of output containing the results as a comma-separated list of booleans enclosed in square brackets. For example, if there are three test cases, output must look like “[True,False,True]”.\n\nTest Suite:\nUse the following three test cases. In all cases, returns are decimals (for example, $0.01$ denotes one percent). To construct return sequences compactly, use the mapping $\\text{Gain} \\mapsto r_G = 0.01$, $\\text{Flat} \\mapsto r_F = 0.0$, $\\text{Loss} \\mapsto r_L = -0.01$, and build each sequence by repeating a given finite pattern of states a specified number of times. Classification uses the specified $\\tau$ for each case.\n\n- Test case $1$ (general case with clear regime change):\n  - $\\tau_1 = 0.002$, $\\alpha_1 = 0.05$.\n  - Period $1$ sequence: repeat the pattern $(\\text{Gain}, \\text{Gain}, \\text{Gain}, \\text{Gain}, \\text{Loss}, \\text{Loss}, \\text{Loss}, \\text{Loss}, \\text{Flat}, \\text{Flat}, \\text{Flat}, \\text{Flat})$ exactly $20$ times.\n  - Period $2$ sequence: repeat the pattern $(\\text{Gain}, \\text{Loss}, \\text{Gain}, \\text{Loss}, \\text{Gain}, \\text{Loss}, \\text{Flat}, \\text{Gain}, \\text{Flat}, \\text{Gain}, \\text{Flat}, \\text{Gain})$ exactly $20$ times.\n\n- Test case $2$ (no change; boundary without the “Flat” origin row):\n  - $\\tau_2 = 0.002$, $\\alpha_2 = 0.05$.\n  - Period $1$ sequence: repeat the pattern $(\\text{Gain}, \\text{Gain}, \\text{Loss}, \\text{Loss})$ exactly $50$ times.\n  - Period $2$ sequence: repeat the same pattern $(\\text{Gain}, \\text{Gain}, \\text{Loss}, \\text{Loss})$ exactly $50$ times.\n\n- Test case $3$ (edge case with one missing origin row in period $2$ and stringent significance level):\n  - $\\tau_3 = 0.002$, $\\alpha_3 = 1\\times 10^{-6}$.\n  - Period $1$ sequence: repeat the pattern $(\\text{Gain}, \\text{Gain}, \\text{Gain}, \\text{Flat}, \\text{Loss}, \\text{Loss}, \\text{Loss})$ exactly $10$ times.\n  - Period $2$ sequence: repeat the pattern $(\\text{Gain}, \\text{Gain}, \\text{Gain}, \\text{Loss}, \\text{Loss}, \\text{Loss})$ exactly $10$ times.\n\nRequired final output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases, for example, “[result1,result2,result3]”, where each result is a boolean indicating whether the change in transition matrices is statistically significant at the specified $\\alpha$ for that test case.", "solution": "The problem requires a statistical test to determine if the transition dynamics of an equity market, modeled as a discrete-time Markov chain, have changed between two periods. The solution involves discretizing financial return data, estimating transition matrices, and applying a likelihood-ratio test for the homogeneity of Markov chains.\n\nThe state space is defined as $S = \\{S_0, S_1, S_2\\}$, corresponding to $\\{\\text{Loss}, \\text{Flat}, \\text{Gain}\\}$. A return observation $r_t$ at time $t$ is classified into a state based on a given threshold $\\tau > 0$:\n$$\n\\text{State}(r_t) =\n\\begin{cases}\n    S_0 (\\text{Loss}) & \\text{if } r_t < -\\tau \\\\\n    S_1 (\\text{Flat}) & \\text{if } |r_t| \\le \\tau \\\\\n    S_2 (\\text{Gain}) & \\text{if } r_t > \\tau\n\\end{cases}\n$$\nThis classification converts each time series of returns, $\\{r^{(m)}_t\\}_{t=1}^{T^{(m)}}$ for period $m \\in \\{1, 2\\}$, into a sequence of states.\n\nWe model each state sequence as a realization of a first-order, time-homogeneous Markov chain. The core of this model is the transition probability matrix $P^{(m)} = [p_{ij}^{(m)}]$, where $p_{ij}^{(m)}$ is the probability of transitioning from state $S_i$ to state $S_j$ in period $m$. The first step is to estimate these matrices. For each period $m$, we construct a $3 \\times 3$ transition count matrix $N^{(m)} = [n_{ij}^{(m)}]$, where $n_{ij}^{(m)}$ is the observed number of transitions from state $S_i$ to $S_j$. The Maximum Likelihood Estimator (MLE) for the transition probability $p_{ij}^{(m)}$ is given by the ratio of observed transition counts:\n$$\n\\hat{p}_{ij}^{(m)} = \\frac{n_{ij}^{(m)}}{N_i^{(m)}}\n\\quad \\text{where} \\quad\nN_i^{(m)} = \\sum_{j=0}^{2} n_{ij}^{(m)}\n$$\nThis estimation is performed for each origin state $S_i$ where the total number of outgoing transitions $N_i^{(m)}$ is greater than zero.\n\nThe primary objective is to test the null hypothesis $H_0$ that the transition matrices for the two periods are identical, against the alternative hypothesis $H_A$ that they are not:\n$$\nH_0: P^{(1)} = P^{(2)} \\qquad \\text{vs.} \\qquad H_A: P^{(1)} \\neq P^{(2)}\n$$\nThis is a test for the homogeneity of two Markov chains. As transitions from a given state $S_i$ follow a multinomial distribution, the problem simplifies to testing the homogeneity of multinomial distributions for each row $i$ of the transition matrices. The standard procedure for this is the Anderson-Goodman test, which is based on the likelihood-ratio principle.\n\nThe test statistic is calculated row by row for each origin state $S_i$. A row $i$ is included in the test only if it has been observed as an origin state in both periods, i.e., $N_i^{(1)} > 0$ and $N_i^{(2)} > 0$. For each such valid row $i$, we compute a likelihood-ratio test statistic $G_i^2$. The total test statistic $G^2$ is the sum of these individual statistics:\n$$\nG^2 = \\sum_{i \\text{ s.t. } N_i^{(1)}>0, N_i^{(2)}>0} G_i^2\n$$\nThe statistic $G_i^2$ for row $i$ compares the likelihood of the data under the alternative hypothesis (separate probabilities $\\hat{p}_{ij}^{(1)}$ and $\\hat{p}_{ij}^{(2)}$) with the likelihood under the null hypothesis (a common, pooled probability $\\hat{p}_{ij}^{\\text{pool}}$). The pooled probability estimate is:\n$$\n\\hat{p}_{ij}^{\\text{pool}} = \\frac{n_{ij}^{(1)} + n_{ij}^{(2)}}{N_i^{(1)} + N_i^{(2)}} = \\frac{n_{ij}^{\\text{pool}}}{N_i^{\\text{pool}}}\n$$\nThe likelihood-ratio statistic for row $i$ is given by:\n$$\nG_i^2 = 2 \\sum_{m=1}^{2} \\sum_{j=0}^{2} n_{ij}^{(m)} \\log\\left(\\frac{\\hat{p}_{ij}^{(m)}}{\\hat{p}_{ij}^{\\text{pool}}}\\right)\n$$\nwhere terms with $n_{ij}^{(m)} = 0$ are treated as zero. For computational stability, this can be expressed using sums of $n \\log n$ terms:\n$$\nG_i^2 = 2 \\left( \\sum_{m,j} n_{ij}^{(m)}\\log n_{ij}^{(m)} - \\sum_{m} N_i^{(m)}\\log N_i^{(m)} - \\sum_{j} n_{ij}^{\\text{pool}}\\log n_{ij}^{\\text{pool}} + N_i^{\\text{pool}}\\log N_i^{\\text{pool}} \\right)\n$$\nwhere each sum is over terms with non-zero counts.\n\nUnder the null hypothesis, the total statistic $G^2$ follows a chi-squared ($\\chi^2$) distribution. The degrees of freedom ($df$) for the test is the sum of the degrees of freedom from each valid row. For each included row $i$, we are comparing two multinomial distributions with $K=3$ categories, which contributes $K-1=2$ degrees of freedom. Thus, the total degrees of freedom is $df = 2 \\times (\\text{number of valid rows})$. If no rows are valid for comparison, $df=0$, the test is undefined, and we conclude there is no significant evidence of change.\n\nFinally, a decision is made by comparing the calculated p-value with the given significance level $\\alpha_k$. The p-value is the probability of observing a test statistic at least as extreme as the one computed, assuming $H_0$ is true:\n$$\np\\text{-value} = P(\\chi^2_{df} \\ge G^2)\n$$\nThe null hypothesis is rejected if and only if the p-value is strictly less than $\\alpha_k$. Rejection implies a statistically significant change in market dynamics. The program returns `True` if the change is significant and `False` otherwise.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Solves the problem of detecting statistically significant changes\n    in Markov chain dynamics between two periods for a set of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"tau\": 0.002,\n            \"alpha\": 0.05,\n            \"period1_pattern\": ('G','G','G','G','L','L','L','L','F','F','F','F'),\n            \"period1_reps\": 20,\n            \"period2_pattern\": ('G','L','G','L','G','L','F','G','F','G','F','G'),\n            \"period2_reps\": 20,\n        },\n        {\n            \"tau\": 0.002,\n            \"alpha\": 0.05,\n            \"period1_pattern\": ('G','G','L','L'),\n            \"period1_reps\": 50,\n            \"period2_pattern\": ('G','G','L','L'),\n            \"period2_reps\": 50,\n        },\n        {\n            \"tau\": 0.002,\n            \"alpha\": 1e-6,\n            \"period1_pattern\": ('G','G','G','F','L','L','L'),\n            \"period1_reps\": 10,\n            \"period2_pattern\": ('G','G','G','L','L','L'),\n            \"period2_reps\": 10,\n        }\n    ]\n\n    # Mapping from state character to return value and state index\n    # State order: {0: Loss, 1: Flat, 2: Gain}\n    state_info = {\n        'L': {'return': -0.01, 'index': 0},\n        'F': {'return': 0.0, 'index': 1},\n        'G': {'return': 0.01, 'index': 2},\n    }\n    \n    num_states = 3\n    results = []\n\n    for case in test_cases:\n        tau = case[\"tau\"]\n        alpha = case[\"alpha\"]\n\n        # 1. Generate return sequences\n        p1_ret_seq = [state_info[s]['return'] for s in case[\"period1_pattern\"]] * case[\"period1_reps\"]\n        p2_ret_seq = [state_info[s]['return'] for s in case[\"period2_pattern\"]] * case[\"period2_reps\"]\n\n        # 2. Classify returns into states\n        def classify_returns(returns, tau):\n            states = []\n            for r in returns:\n                if r < -tau:\n                    states.append(state_info['L']['index'])\n                elif r > tau:\n                    states.append(state_info['G']['index'])\n                else: # abs(r) <= tau\n                    states.append(state_info['F']['index'])\n            return states\n\n        p1_state_seq = classify_returns(p1_ret_seq, tau)\n        p2_state_seq = classify_returns(p2_ret_seq, tau)\n\n        # 3. Compute transition count matrices\n        def get_transition_counts(state_seq, n_states):\n            counts = np.zeros((n_states, n_states), dtype=np.int64)\n            for i in range(len(state_seq) - 1):\n                origin_state = state_seq[i]\n                dest_state = state_seq[i+1]\n                counts[origin_state, dest_state] += 1\n            return counts\n\n        N1 = get_transition_counts(p1_state_seq, num_states)\n        N2 = get_transition_counts(p2_state_seq, num_states)\n\n        # 4. Perform the Anderson-Goodman test\n        total_g_squared = 0.0\n        total_df = 0\n\n        N1_row_sums = N1.sum(axis=1)\n        N2_row_sums = N2.sum(axis=1)\n\n        for i in range(num_states):\n            # A row is included if it has transitions in BOTH periods\n            if N1_row_sums[i] > 0 and N2_row_sums[i] > 0:\n                # Calculate G^2 statistic for this row\n                g_squared_i = 0.0\n                \n                N_pool_row = N1[i, :] + N2[i, :]\n                N_pool_row_sum = N_pool_row.sum()\n\n                # Use log-likelihood formula resistant to n=0\n                # G^2 = 2 * ( sum(n log n) - sum(row_sum log row_sum) - sum(col_sum log col_sum) + total log total )\n                # For a single row of the transition matrix, this applies to the 2xK contingency table\n                \n                # sum(n log n) term\n                term1 = 0.0\n                for n in np.concatenate((N1[i, :], N2[i, :])):\n                    if n > 0:\n                        term1 += n * np.log(n)\n                \n                # sum(row_sum log row_sum) term\n                term2 = 0.0\n                term2 += N1_row_sums[i] * np.log(N1_row_sums[i])\n                term2 += N2_row_sums[i] * np.log(N2_row_sums[i])\n\n                # sum(col_sum log col_sum) term\n                term3 = 0.0\n                for n_pool in N_pool_row:\n                    if n_pool > 0:\n                        term3 += n_pool * np.log(n_pool)\n\n                # total log total term\n                term4 = 0.0\n                if N_pool_row_sum > 0:\n                    term4 = N_pool_row_sum * np.log(N_pool_row_sum)\n\n                g_squared_i = 2 * (term1 - term2 - term3 + term4)\n                \n                total_g_squared += g_squared_i\n                total_df += (num_states - 1)\n\n        # 5. Calculate p-value and make a decision\n        if total_df == 0:\n            # No basis for comparison, so no evidence to reject H0\n            p_value = 1.0\n        else:\n            # sf is the survival function (1 - cdf)\n            p_value = chi2.sf(total_g_squared, total_df)\n        \n        is_significant = p_value < alpha\n        results.append(is_significant)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(lambda b: str(b), results))}]\")\n\nsolve()\n```"}]}