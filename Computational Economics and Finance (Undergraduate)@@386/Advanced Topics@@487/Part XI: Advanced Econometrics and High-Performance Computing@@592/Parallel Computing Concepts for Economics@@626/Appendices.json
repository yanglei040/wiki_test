{"hands_on_practices": [{"introduction": "Before diving into writing parallel code, it is crucial to understand the theoretical limits of the speedup we can achieve. This exercise [@problem_id:2417876] introduces Amdahl's Law, a fundamental principle highlighting that the non-parallelizable portion of a task creates an inescapable bottleneck, even with infinite processor cores. By working through this calculation based on a financial stress-testing scenario, you will gain a vital intuition for analyzing the potential performance gains of parallelization.", "id": "2417876", "problem": "A central bank runs a large-scale macro-financial stress testing pipeline with $2$ stages: a data-gathering and cleaning stage that is strictly sequential, and a Monte Carlo simulation stage that can be perfectly parallelized across independent scenarios with negligible overhead. On a single-core baseline, the simulation stage accounts for $0.99$ of the total runtime. Let the speedup be defined as the ratio of the single-core runtime to the runtime on a machine with $N$ identical cores, when only the simulation stage is parallelized and the sequential stage remains strictly serial. In the limit as $N \\to \\infty$, what is the theoretical maximum speedup relative to the single-core baseline? Provide the answer as an exact number with no units.", "solution": "The problem as stated will be validated before any attempt at a solution is made.\n\nFirst, we extract the given information verbatim.\n1.  The process consists of $2$ stages: a strictly sequential data-gathering stage and a perfectly parallelizable Monte Carlo simulation stage.\n2.  The fraction of the total single-core runtime corresponding to the parallelizable simulation stage is $0.99$. Let this fraction be denoted by $P$. Therefore, $P = 0.99$.\n3.  The speedup, $S(N)$, is defined as the ratio of the single-core runtime to the runtime on a machine with $N$ identical cores.\n4.  The objective is to find the theoretical maximum speedup in the limit as the number of cores $N$ approaches infinity.\n\nSecond, we validate the problem. The problem is a straightforward application of Amdahl's Law, a fundamental concept in parallel computing. The scenario described is a classic and realistic model for computational pipelines in scientific and engineering domains, including computational finance. The problem is self-contained, scientifically grounded, and well-posed. All terms are clearly defined, and no information is missing or contradictory. Therefore, the problem is deemed valid and a solution will be formulated.\n\nThe solution proceeds from the principles of Amdahl's Law. Let $T_1$ be the total runtime on a single core. This total time can be decomposed into a sequential part and a parallelizable part.\n\nThe fraction of the task that is strictly sequential is $1 - P$. The time taken by this part is $T_{seq} = (1 - P) T_1$.\nThe fraction of the task that is parallelizable is $P$. The time taken by this part on a single core is $T_{par} = P T_1$.\n\nGiven from the problem statement, $P = 0.99$.\nThus, the sequential fraction is $1 - P = 1 - 0.99 = 0.01$.\n\nWhen the task is run on a system with $N$ cores, the sequential part of the task remains unchanged, taking time $T_{seq}$. The parallelizable part, however, is distributed across the $N$ cores. Assuming perfect parallelization with negligible overhead, the time for this part becomes $\\frac{T_{par}}{N}$.\n\nThe total runtime on $N$ cores, $T(N)$, is the sum of the execution times of the two parts:\n$$T(N) = T_{seq} + \\frac{T_{par}}{N} = (1 - P) T_1 + \\frac{P T_1}{N}$$\n\nThe speedup $S(N)$ is defined as the ratio of the single-core runtime to the $N$-core runtime:\n$$S(N) = \\frac{T_1}{T(N)} = \\frac{T_1}{(1 - P) T_1 + \\frac{P T_1}{N}}$$\n\nThe term $T_1$ is a common factor in the numerator and denominator and can be cancelled, which is expected as speedup is a relative measure:\n$$S(N) = \\frac{1}{(1 - P) + \\frac{P}{N}}$$\n\nThe problem asks for the theoretical maximum speedup, which is achieved in the limit as the number of cores $N$ approaches infinity. We must evaluate the limit of $S(N)$ as $N \\to \\infty$.\n$$S_{max} = \\lim_{N \\to \\infty} S(N) = \\lim_{N \\to \\infty} \\frac{1}{(1 - P) + \\frac{P}{N}}$$\n\nAs $N \\to \\infty$, the term $\\frac{P}{N}$ approaches $0$, because $P$ is a finite constant.\n$$\\lim_{N \\to \\infty} \\frac{P}{N} = 0$$\n\nTherefore, the limit of the speedup function is:\n$$S_{max} = \\frac{1}{(1 - P) + 0} = \\frac{1}{1 - P}$$\n\nThis result is the core statement of Amdahl's Law: the maximum speedup is limited by the sequential fraction of the code.\n\nSubstituting the given value $P = 0.99$ into the expression for maximum speedup:\n$$S_{max} = \\frac{1}{1 - 0.99} = \\frac{1}{0.01}$$\n\nEvaluating this expression gives the final answer.\n$$S_{max} = 100$$\nThis is the theoretical maximum speedup for the given pipeline, irrespective of how many more processors are added beyond a certain point. The performance is fundamentally bottlenecked by the $1\\%$ of the work that must be done sequentially.", "answer": "$$\n\\boxed{100}\n$$"}, {"introduction": "Having explored the theoretical limits of parallelization, we now turn to a practical application. This problem [@problem_id:2417855] guides you through solving a neoclassical growth model, a task whose computational core—value function iteration—is an \"embarrassingly parallel\" workload where calculations for each state $(k, z)$ are independent. Tackling this problem provides direct experience with one of the most common and powerful parallel patterns, demonstrating how computationally intensive economic models are prime candidates for massive speedups.", "id": "2417855", "problem": "You are given a discrete-time dynamic programming problem arising from a stochastic neoclassical growth model. The state is a pair $(k,z)$ where $k$ is capital and $z$ is a productivity shock. The control is next-period capital $k'$. Let the production function be $f(k,z)=z k^{\\alpha} + (1-\\delta)k$, and let utility be constant relative risk aversion (CRRA): $u(c)=\\frac{c^{1-\\sigma}-1}{1-\\sigma}$ for $\\sigma \\neq 1$ and $u(c)=\\log(c)$ for $\\sigma=1$, where $c$ is consumption. The one-step Bellman operator applied to a function $V(k,z)$ is\n$$\n(TV)(k,z)=\\max_{k' \\in \\mathcal{K}} \\left\\{ u\\big(f(k,z)-k'\\big) + \\beta \\,\\mathbb{E}\\big[V(k',z')\\mid z\\big] \\right\\},\n$$\nsubject to the feasibility constraint $c=f(k,z)-k' \\ge 0$. The shock $z$ takes finitely many values in a set $\\mathcal{Z}$ and follows a Markov chain with transition matrix $P$, where the element $P_{j\\ell}$ is the probability of transitioning from $z_{j}$ to $z_{\\ell}$ in one period.\n\nOn a finite grid $\\mathcal{K}=\\{k_{1},\\ldots,k_{N_{k}}\\}$ and $\\mathcal{Z}=\\{z_{1},\\ldots,z_{N_{z}}\\}$, define $V_{0}(k,z)=0$ for all $(k,z) \\in \\mathcal{K}\\times\\mathcal{Z}$. Let $V_{1}=T V_{0}$ and $V_{2}=T V_{1}$ computed by restricting the maximization to $k' \\in \\mathcal{K}$. For any function $W$ on the grid, define the sup norm as\n$$\n\\lVert W \\rVert_{\\infty}=\\max_{(k,z)\\in\\mathcal{K}\\times\\mathcal{Z}} |W(k,z)|.\n$$\nFor each parameter set below, compute the single scalar\n$$\nd=\\lVert V_{2}-V_{1}\\rVert_{\\infty}.\n$$\nIf at a given $(k,z)$ no choice $k' \\in \\mathcal{K}$ yields feasible consumption $c \\ge 0$, then by definition set the corresponding value to a very large negative real number to reflect infeasibility.\n\nTest suite:\n- Case A (general two-shock case): $\\alpha=0.33$, $\\beta=0.95$, $\\delta=0.08$, $\\sigma=2.0$, $\\mathcal{Z}=\\{0.9,1.1\\}$, with transition matrix\n$$\nP=\\begin{bmatrix}0.9 & 0.1\\\\ 0.1 & 0.9\\end{bmatrix}.\n$$\nUse a capital grid $\\mathcal{K}$ of $N_{k}=80$ equally spaced points from $k_{\\min}=0.01$ to $k_{\\max}=5.0$ inclusive.\n\n- Case B (single-shock, high depreciation and risk aversion): $\\alpha=0.36$, $\\beta=0.90$, $\\delta=0.30$, $\\sigma=5.0$, $\\mathcal{Z}=\\{1.0\\}$ with transition matrix $P=[1.0]$. Use a capital grid $\\mathcal{K}$ of $N_{k}=100$ equally spaced points from $k_{\\min}=0.01$ to $k_{\\max}=3.0$ inclusive.\n\n- Case C (log utility, three shocks): $\\alpha=0.25$, $\\beta=0.99$, $\\delta=0.05$, $\\sigma=1.0$, $\\mathcal{Z}=\\{0.85, 1.0, 1.15\\}$ with transition matrix\n$$\nP=\\begin{bmatrix}\n0.85 & 0.15 & 0.00\\\\\n0.075 & 0.85 & 0.075\\\\\n0.00 & 0.15 & 0.85\n\\end{bmatrix}.\n$$\nUse a capital grid $\\mathcal{K}$ of $N_{k}=90$ equally spaced points from $k_{\\min}=0.01$ to $k_{\\max}=4.0$ inclusive.\n\nYour program should compute $d$ for each case and produce a single line of output containing the three results as a comma-separated list of decimal numbers rounded to $6$ digits after the decimal point and enclosed in square brackets, for example, \"[x,y,z]\".", "solution": "The problem statement is subjected to validation and is found to be scientifically grounded, well-posed, and objective. It presents a standard computational task in the field of quantitative macroeconomics: the application of value function iteration to a stochastic neoclassical growth model. The model is canonical, defined by a Cobb-Douglas production function and a constant relative risk aversion (CRRA) utility function. All parameters, functional forms, and computational steps are specified with sufficient clarity and precision to permit a unique, verifiable solution. Therefore, we proceed with the solution.\n\nThe objective is to compute the sup-norm distance $d=\\lVert V_{2}-V_{1}\\rVert_{\\infty}$ between the first two non-trivial iterates of the value function, $V_{1}=TV_{0}$ and $V_{2}=TV_{1}$, starting from an initial guess $V_{0}(k,z)=0$. The solution is obtained by discretizing the state space and numerically applying the Bellman operator $T$.\n\nThe state of the system is a pair $(k, z)$, where $k$ is the capital stock and $z$ is a productivity shock. The control variable is the next-period capital stock, $k'$. The state variables belong to finite grids, $k \\in \\mathcal{K}=\\{k_{1},\\ldots,k_{N_{k}}\\}$ and $z \\in \\mathcal{Z}=\\{z_{1},\\ldots,z_{N_{z}}\\}$. The value function $V(k, z)$ is thus represented as a matrix of size $N_{k} \\times N_{z}$.\n\nThe core of the problem is the Bellman operator $T$:\n$$\n(TV)(k,z)=\\max_{k' \\in \\mathcal{K}} \\left\\{ u\\big(f(k,z)-k'\\big) + \\beta \\,\\mathbb{E}\\big[V(k',z')\\mid z\\big] \\right\\}\n$$\nThe procedure involves the following steps:\n\nStep 1: Initialization.\nThe initial value function is given as $V_{0}(k,z)=0$ for all states $(k,z)$ on the grid. This corresponds to an $N_{k} \\times N_{z}$ matrix of zeros.\n\nStep 2: Computation of $V_{1} = TV_{0}$.\nWe apply the Bellman operator to $V_{0}$. For any state $(k_{i}, z_{j})$, the value $V_{1}(k_{i}, z_{j})$ is computed.\nBecause $V_{0} \\equiv 0$, the expectation term vanishes:\n$$\n\\mathbb{E}\\big[V_{0}(k',z')\\mid z_{j}\\big] = \\sum_{\\ell=1}^{N_{z}} P_{j\\ell} V_{0}(k', z_{\\ell}) = \\sum_{\\ell=1}^{N_{z}} P_{j\\ell} \\cdot 0 = 0.\n$$\nThe operator thus simplifies to a static optimization problem for the first iteration:\n$$\nV_{1}(k_{i},z_{j}) = (TV_{0})(k_{i},z_{j}) = \\max_{k'_{m} \\in \\mathcal{K}} \\left\\{ u\\big(f(k_{i},z_{j})-k'_{m}\\big) \\right\\}.\n$$\nThe maximization is subject to the feasibility constraint $c = f(k_{i},z_{j})-k'_{m} > 0$. The utility function is $u(c)=\\frac{c^{1-\\sigma}-1}{1-\\sigma}$ for $\\sigma \\neq 1$ and $u(c)=\\log(c)$ for $\\sigma=1$. For all test cases given ($\\sigma \\ge 1$), utility is undefined or approaches $-\\infty$ as consumption $c \\to 0^{+}$. Thus, we only consider choices $k'_{m}$ that result in strictly positive consumption. If no such $k'_{m}$ exists, the value is set to $-\\infty$. Computationally, for each pair $(k_{i}, z_{j})$, we evaluate the utility for every possible choice $k'_{m} \\in \\mathcal{K}$ and find the maximum. This is performed for all $(k_{i}, z_{j})$ to populate the $V_{1}$ matrix.\n\nStep 3: Computation of $V_{2} = TV_{1}$.\nNext, we apply the operator to $V_{1}$.\n$$\nV_{2}(k_{i},z_{j}) = (TV_{1})(k_{i},z_{j})=\\max_{k'_{m} \\in \\mathcal{K}} \\left\\{ u\\big(f(k_{i},z_{j})-k'_{m}\\big) + \\beta \\,\\mathbb{E}\\big[V_{1}(k'_{m},z')\\mid z=z_{j}\\big] \\right\\}.\n$$\nThe expectation term is now non-zero. For a chosen next-period capital $k'_{m}$ and a current shock $z_{j}$, the expected future value is calculated by summing over all possible future shocks $z'_{\\ell}$:\n$$\n\\mathbb{E}\\big[V_{1}(k'_{m},z')\\mid z=z_{j}\\big] = \\sum_{\\ell=1}^{N_{z}} P_{j\\ell} V_{1}(k'_{m}, z_{\\ell}).\n$$\nThis term represents the expected value of starting the next period with capital $k'_{m}$, given the stochastic nature of the productivity shock $z'$. Let $V_{1}$ be the $N_{k} \\times N_{z}$ matrix of values and $P$ be the $N_{z} \\times N_{z}$ transition matrix. The matrix of expected values, let us call it $E_{V_{1}}$, of size $N_{k} \\times N_{z}$, where $(E_{V_{1}})_{m,j} = \\mathbb{E}\\big[V_{1}(k'_{m},z')\\mid z=z_{j}\\big]$, is efficiently computed via the matrix product $E_{V_{1}} = V_{1} \\cdot P^{\\top}$.\n\nFor each state $(k_{i}, z_{j})$, we compute the value of the expression in the curly braces for every choice $k'_{m} \\in \\mathcal{K}$, again subject to $c > 0$. The maximum of these values is assigned to $V_{2}(k_{i}, z_{j})$.\n\nStep 4: Computation of the Distance $d$.\nFinally, we compute the quantity of interest, $d$, which is the sup-norm of the difference between the two value function iterates:\n$$\nd = \\lVert V_{2}-V_{1}\\rVert_{\\infty} = \\max_{(k_{i},z_{j})\\in\\mathcal{K}\\times\\mathcal{Z}} |V_{2}(k_{i},z_{j}) - V_{1}(k_{i},z_{j})|.\n$$\nThis is found by taking the element-wise absolute difference of the matrices $V_{2}$ and $V_{1}$ and then finding the maximum entry in the resulting matrix. This scalar value is computed for each of the three parameter sets provided.\n\nVectorization is employed for computational efficiency. For a given shock $z_{j}$, we can compute the utilities for all combinations of current capital $k_{i}$ and next-period capital $k'_{m}$ simultaneously. The grids $\\mathcal{K}$ and $\\mathcal{Z}$ are constructed using the specified limits and number of points. This systematic procedure is applied to each test case to obtain the required results.", "answer": "```python\nimport numpy as np\n\ndef compute_d(alpha, beta, delta, sigma, Z, P, Nk, k_min, k_max):\n    \"\"\"\n    Computes the distance d = ||V_2 - V_1||_inf for a given parameter set.\n    \"\"\"\n    # Step 1: Discretize state space\n    k_grid = np.linspace(k_min, k_max, Nk)\n    z_grid = np.array(Z)\n    Nz = len(z_grid)\n    P_matrix = np.array(P)\n\n    # Initialize value functions\n    V0 = np.zeros((Nk, Nz))\n    V1 = np.full((Nk, Nz), -np.inf)\n    V2 = np.full((Nk, Nz), -np.inf)\n\n    # --- Step 2: Compute V1 = T(V0) ---\n    # Since V0 is zero, the expectation term is zero.\n    for j in range(Nz):\n        z = z_grid[j]\n        # Production for all k_i given z_j\n        production = z * k_grid**alpha + (1 - delta) * k_grid\n\n        # Consumption matrix c(k_i, k'_m)\n        consumption_matrix = production.reshape(-1, 1) - k_grid.reshape(1, -1)\n        \n        # We only consider strictly positive consumption, as u(c) for c<=0 is -inf for sigma>=1\n        positive_mask = consumption_matrix > 0\n        c_positive = consumption_matrix[positive_mask]\n        \n        utility_matrix = np.full((Nk, Nk), -np.inf)\n        if sigma == 1.0:\n            utility_matrix[positive_mask] = np.log(c_positive)\n        else:\n            utility_matrix[positive_mask] = (c_positive**(1 - sigma) - 1) / (1 - sigma)\n            \n        V1[:, j] = np.max(utility_matrix, axis=1)\n\n    # --- Step 3: Compute V2 = T(V1) ---\n    # Expected value E[V1(k', z')|z] = V1 @ P.T\n    expected_V1 = V1 @ P_matrix.T\n    \n    for j in range(Nz):\n        z = z_grid[j]\n        # Production for all k_i given z_j\n        production = z * k_grid**alpha + (1 - delta) * k_grid\n\n        # Consumption matrix c(k_i, k'_m)\n        consumption_matrix = production.reshape(-1, 1) - k_grid.reshape(1, -1)\n        \n        positive_mask = consumption_matrix > 0\n        c_positive = consumption_matrix[positive_mask]\n        \n        utility_matrix = np.full((Nk, Nk), -np.inf)\n        if sigma == 1.0:\n            utility_matrix[positive_mask] = np.log(c_positive)\n        else:\n            utility_matrix[positive_mask] = (c_positive**(1 - sigma) - 1) / (1 - sigma)\n            \n        # Continuation value depends on choice k_m (axis 1) and current shock z_j\n        continuation_value = beta * expected_V1[:, j].reshape(1, -1)\n        \n        # Add utility and continuation value using broadcasting\n        value_matrix = utility_matrix + continuation_value\n        \n        V2[:, j] = np.max(value_matrix, axis=1)\n\n    # --- Step 4: Compute d = ||V2 - V1||_inf ---\n    # Mask out -inf values which can arise if no choice is feasible\n    # This shouldn't happen for reasonable parameters, but is good practice.\n    finite_mask = np.isfinite(V1) & np.isfinite(V2)\n    if not np.any(finite_mask):\n        return 0.0 # Or another representation of this edge case\n        \n    diff_matrix = V2[finite_mask] - V1[finite_mask]\n    d = np.max(np.abs(diff_matrix))\n    \n    return d\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the results.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {\n            'alpha': 0.33, 'beta': 0.95, 'delta': 0.08, 'sigma': 2.0,\n            'Z': [0.9, 1.1],\n            'P': [[0.9, 0.1], [0.1, 0.9]],\n            'Nk': 80, 'k_min': 0.01, 'k_max': 5.0\n        },\n        # Case B\n        {\n            'alpha': 0.36, 'beta': 0.90, 'delta': 0.30, 'sigma': 5.0,\n            'Z': [1.0],\n            'P': [[1.0]],\n            'Nk': 100, 'k_min': 0.01, 'k_max': 3.0\n        },\n        # Case C\n        {\n            'alpha': 0.25, 'beta': 0.99, 'delta': 0.05, 'sigma': 1.0,\n            'Z': [0.85, 1.0, 1.15],\n            'P': [[0.85, 0.15, 0.00], [0.075, 0.85, 0.075], [0.00, 0.15, 0.85]],\n            'Nk': 90, 'k_min': 0.01, 'k_max': 4.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        d = compute_d(**case)\n        results.append(d)\n\n    print(f\"[{','.join(f'{x:.6f}' for x in results)}]\")\n\nsolve()\n```"}, {"introduction": "While many problems can be broken into independent tasks, economic models often feature strategic interaction, where 'simultaneous' decisions must be computationally enforced. This problem [@problem_id:2417917] explores the critical concept of synchronization by modeling a Cournot duopoly where firms must choose their next-period quantities based on the same current-period information. By implementing a simulation with and without a synchronization barrier, you will learn why such mechanisms are essential for preserving the economic logic of simultaneous moves and ensuring the correctness of your parallel model.", "id": "2417917", "problem": "You are asked to write a complete, runnable program that models a Cournot duopoly where two firms simultaneously choose quantities in discrete time steps using two separate threads. The program must demonstrate that to correctly model discrete time steps indexed by $t \\in \\{0,1,2,\\dots\\}$ as simultaneous decisions, a barrier synchronization is required so that both firms update from the same state at step $t$ and commit their updates simultaneously to step $t+1$. You will compare a synchronized simulation that uses a barrier with an intentionally unsynchronized sequential-updating simulation that does not impose a simultaneous-read constraint, highlighting the modeling error in the latter.\n\nFundamental base and core definitions to be used:\n- Let the inverse demand be $P(Q) = a - b Q$, where $a &gt; 0$, $b &gt; 0$, total quantity is $Q = q_1 + q_2$, and firm $i$ has constant marginal cost $c_i \\ge 0$. Profit for firm $i$ is $\\pi_i(q_i,q_j) = \\left(P(q_i+q_j) - c_i\\right) q_i$.\n- In Cournot competition, at any time step $t$, each firm $i$ chooses $q_i^{t+1}$ to maximize its profit given the rival's quantity at time $t$. There is a nonnegativity constraint $q_i^{t+1} \\ge 0$.\n- The step update intended by discrete-time simultaneous play is that both firms compute $q_i^{t+1}$ using only information from step $t$, and then commit $q^{t+1}$ atomically. This requires barrier synchronization between the threads to ensure that both firms read the same past state and that their writes are committed at the same discrete time boundary.\n- In contrast, without a barrier to enforce simultaneous read and commit, one thread can update earlier and the other thread may read a partially updated state, thus violating the intended model of simultaneous decisions at the boundary between $t$ and $t+1$.\n\nYour program must:\n1. From first principles, derive and implement the unique best response $BR_i(q_j)$ for firm $i$ given $q_j$ by maximizing $\\pi_i(q_i,q_j)$ subject to $q_i \\ge 0$. Use the derived $BR_i(q_j)$ in all updates.\n2. Implement two-thread simulations for $T$ discrete steps starting from given initial quantities $(q_1^0,q_2^0)$:\n   - Synchronous simulation with a barrier: Two threads represent firms. At each step $t$, both compute $q_i^{t+1} = BR_i(q_j^t)$ using only $(q_1^t,q_2^t)$ and commit the pair $(q_1^{t+1},q_2^{t+1})$ atomically at the barrier so that both read exactly the same state from step $t$.\n   - Unsynchronized sequential simulation without a barrier: Two threads represent firms but do not coordinate a simultaneous read. Within each step, enforce a deterministic sequential update order: firm $1$ updates first using $q_2^t$, and immediately writes $q_1^{t+1}$; then firm $2$ reads this updated $q_1^{t+1}$ and writes $q_2^{t+1}$. This construction intentionally violates simultaneous decisions to illustrate the modeling error in the absence of a barrier.\n3. Compute the static Nash equilibrium $(q_1^\\star,q_2^\\star)$ consistent with $q_i \\ge 0$ by solving for the Cournot equilibrium under nonnegativity constraints. If the unconstrained equilibrium yields $q_i^\\star \\ge 0$ for both $i$, use the interior solution. If one unconstrained $q_i^\\star$ is negative, enforce the corner case by setting that $q_i^\\star = 0$ and recomputing the other firm’s best response to this zero; if both are negative, set $(q_1^\\star,q_2^\\star) = (0,0)$.\n4. For each test case, run both simulations for the specified number of steps $T$, starting from the specified initial state. Then compute and report:\n   - The maximum absolute difference between the synchronous and unsynchronized final quantities at step $T$:\n     $$ d = \\max\\left\\{ \\left| q_1^{T,\\mathrm{sync}} - q_1^{T,\\mathrm{unsync}} \\right|, \\left| q_2^{T,\\mathrm{sync}} - q_2^{T,\\mathrm{unsync}} \\right| \\right\\}. $$\n   - The Euclidean norm of the synchronous final state’s error relative to the static equilibrium:\n     $$ e_{\\mathrm{sync}} = \\sqrt{\\left(q_1^{T,\\mathrm{sync}} - q_1^\\star\\right)^2 + \\left(q_2^{T,\\mathrm{sync}} - q_2^\\star\\right)^2}. $$\n   - The Euclidean norm of the unsynchronized final state’s error relative to the static equilibrium:\n     $$ e_{\\mathrm{unsync}} = \\sqrt{\\left(q_1^{T,\\mathrm{unsync}} - q_1^\\star\\right)^2 + \\left(q_2^{T,\\mathrm{unsync}} - q_2^\\star\\right)^2}. $$\n\nTest suite to cover different facets:\n- Case A (happy path; symmetric costs; single step difference is most pronounced): $a = 100$, $b = 1$, $c_1 = 10$, $c_2 = 10$, $T = 1$, initial $(q_1^0,q_2^0) = (0,0)$.\n- Case B (asymmetric costs; multiple steps; interior equilibrium): $a = 90$, $b = 1.5$, $c_1 = 10$, $c_2 = 30$, $T = 5$, initial $(q_1^0,q_2^0) = (0,0)$.\n- Case C (boundary case with nonnegativity constraint binding for one firm): $a = 40$, $b = 2$, $c_1 = 50$, $c_2 = 4$, $T = 3$, initial $(q_1^0,q_2^0) = (0,0)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of lists, each inner list corresponding to a test case and containing the three floating-point values $[d, e_{\\mathrm{sync}}, e_{\\mathrm{unsync}}]$ in that exact order. The output must be printed as a single line in the format\n  \"[[d_A,e_sync_A,e_unsync_A],[d_B,e_sync_B,e_unsync_B],[d_C,e_sync_C,e_unsync_C]]\"\n  where each floating-point number should be rendered in fixed-point with six digits after the decimal point. No extra text should be printed.\nNo physical units are involved. All angles, if any, are not applicable. All ratios must be expressed as decimals.", "solution": "The problem statement is subjected to validation and is found to be valid. It is scientifically grounded in established economic theory (Cournot competition) and computational science (parallel synchronization). The problem is well-posed, with all necessary parameters and definitions provided for a unique, verifiable solution. There are no contradictions, ambiguities, or factual inaccuracies. We may therefore proceed with a formal solution.\n\nThe core of the problem is to model a discrete-time Cournot duopoly. First, we must derive the best response function for each firm, which defines its optimal quantity choice given its rival's output.\n\nA firm $i$'s profit, $\\pi_i$, is given by its revenue minus its costs:\n$$ \\pi_i(q_i, q_j) = P(Q)q_i - c_i q_i $$\nwhere $Q = q_i + q_j$, the inverse demand is $P(Q) = a - b Q$, and $c_i$ is the constant marginal cost. Substituting the demand function, we have:\n$$ \\pi_i(q_i, q_j) = (a - b(q_i + q_j) - c_i)q_i = aq_i - bq_i^2 - bq_j q_i - c_i q_i $$\nTo find the quantity $q_i$ that maximizes this profit, we take the first-order partial derivative with respect to $q_i$ and set it to zero, which is the first-order condition for a maximum:\n$$ \\frac{\\partial \\pi_i}{\\partial q_i} = a - 2bq_i - bq_j - c_i = 0 $$\nSolving for $q_i$ yields the unconstrained reaction function:\n$$ 2bq_i = a - c_i - bq_j \\implies q_i = \\frac{a - c_i - bq_j}{2b} $$\nThe second-order condition for a maximum is satisfied, as $\\frac{\\partial^2 \\pi_i}{\\partial q_i^2} = -2b < 0$ since it is given that $b > 0$. However, firms cannot produce a negative quantity, so we must enforce the nonnegativity constraint $q_i \\ge 0$. The best response function $BR_i(q_j)$ is therefore:\n$$ BR_i(q_j) = \\max\\left\\{0, \\frac{a - c_i - bq_j}{2b}\\right\\} $$\n\nNext, we determine the static Cournot-Nash equilibrium $(q_1^\\star, q_2^\\star)$, which is the stable state where neither firm has an incentive to unilaterally change its output. This occurs when both firms are on their best response curves simultaneously, i.e., $q_1^\\star = BR_1(q_2^\\star)$ and $q_2^\\star = BR_2(q_1^\\star)$.\nAssuming an interior solution where $q_1^\\star > 0$ and $q_2^\\star > 0$, we solve the system of linear equations:\n$$ q_1^\\star = \\frac{a - c_1 - bq_2^\\star}{2b} $$\n$$ q_2^\\star = \\frac{a - c_2 - bq_1^\\star}{2b} $$\nSubstituting the expression for $q_2^\\star$ into the first equation and solving for $q_1^\\star$ yields:\n$$ q_1^\\star = \\frac{a - 2c_1 + c_2}{3b} $$\nBy symmetry, the equilibrium quantity for firm $2$ is:\n$$ q_2^\\star = \\frac{a - 2c_2 + c_1}{3b} $$\nIf these formulas yield a negative quantity for a firm, e.g., $q_i^\\star < 0$, its equilibrium output must be at the boundary, i.e., $q_i^\\star = 0$. The other firm, $j$, will then react to this zero output: $q_j^\\star = BR_j(0) = \\max\\{0, (a-c_j)/(2b)\\}$. If both unconstrained quantities are negative, the equilibrium is $(q_1^\\star, q_2^\\star) = (0,0)$.\n\nThe problem requires a comparison of two dynamic simulation models over $T$ time steps, from an initial state $(q_1^0, q_2^0)$. Both models are implemented using two threads, one for each firm.\n\n$1$. **Synchronous Simulation**: This correctly models the simultaneous-move nature of Cournot competition in discrete time. At each step $t$, both firms must decide their quantity for step $t+1$ based on the *same* information, which is the state of the market at step $t$, namely $(q_1^t, q_2^t)$.\n$$ q_1^{t+1} = BR_1(q_2^t) $$\n$$ q_2^{t+1} = BR_2(q_1^t) $$\nTo enforce this in a multi-threaded program, a synchronization barrier is necessary. The threads compute their next quantities based on the shared state at time $t$. They then wait at a barrier. After all threads have reached the barrier, the new quantities for step $t+1$ are committed to the shared state. This ensures that no thread can read a partially updated state from step $t+1$ while computing its own value for $t+1$. This is a computational analogue of the Jacobi method for solving linear systems.\n\n$2$. **Unsynchronized Sequential Simulation**: This simulation intentionally introduces a modeling error by omitting the synchronization barrier. It imposes a deterministic update order: firm $1$ updates first, and firm $2$ follows.\n$$ q_1^{t+1} = BR_1(q_2^t) $$\n$$ q_2^{t+1} = BR_2(q_1^{t+1}) $$\nHere, firm $2$'s decision for step $t+1$ is based on firm $1$'s quantity for step $t+1$, not $t$. This violates the principle of simultaneous moves. It models a sequential-move dynamic where firm $1$ is a leader and firm $2$ is a follower within each time step. This corresponds to the Gauss-Seidel method. The discrepancy between this simulation's trajectory and the synchronous one's highlights the critical importance of proper synchronization in modeling parallel or simultaneous events.\n\nThe program will implement these two simulations, calculate the specified metrics ($d$, $e_{\\mathrm{sync}}$, $e_{\\mathrm{unsync}}$) for the given test cases, and demonstrate the divergence caused by the modeling error in the unsynchronized case. The implementation of the synchronous model will use the `threading` module with a `Barrier` to correctly model the simultaneous-read-then-simultaneous-commit logic.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport threading\nfrom collections import namedtuple\n\n# Define data structure for problem parameters\nCaseParams = namedtuple('CaseParams', ['a', 'b', 'c1', 'c2', 'T', 'q0'])\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        # Case A: Happy path, symmetric costs\n        CaseParams(a=100.0, b=1.0, c1=10.0, c2=10.0, T=1, q0=np.array([0.0, 0.0])),\n        # Case B: Asymmetric costs, multiple steps\n        CaseParams(a=90.0, b=1.5, c1=10.0, c2=30.0, T=5, q0=np.array([0.0, 0.0])),\n        # Case C: Boundary case, non-negativity constraint binding\n        CaseParams(a=40.0, b=2.0, c1=50.0, c2=4.0, T=3, q0=np.array([0.0, 0.0])),\n    ]\n\n    results = []\n    for params in test_cases:\n        results.append(solve_case(params))\n\n    # Format the final output string as specified\n    formatted_results = [\n        f\"[{res[0]:.6f},{res[1]:.6f},{res[2]:.6f}]\" for res in results\n    ]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef best_response(q_other, a, b, c):\n    \"\"\"\n    Calculates the best response for a firm given the other's quantity.\n    BR_i(q_j) = max(0, (a - c_i - b*q_j) / (2*b))\n    \"\"\"\n    num = a - c - b * q_other\n    den = 2.0 * b\n    return max(0.0, num / den)\n\ndef calculate_nash_equilibrium(params):\n    \"\"\"\n    Calculates the static Cournot-Nash equilibrium quantities.\n    Handles both interior and corner solutions.\n    \"\"\"\n    a, b, c1, c2 = params.a, params.b, params.c1, params.c2\n    \n    # Calculate unconstrained interior solution\n    q1_star_unconstrained = (a - 2.0 * c1 + c2) / (3.0 * b)\n    q2_star_unconstrained = (a - 2.0 * c2 + c1) / (3.0 * b)\n\n    if q1_star_unconstrained >= 0 and q2_star_unconstrained >= 0:\n        return np.array([q1_star_unconstrained, q2_star_unconstrained])\n    \n    # Handle corner solutions\n    q1_star, q2_star = 0.0, 0.0\n    if q1_star_unconstrained < 0 and q2_star_unconstrained < 0:\n        # If both would be negative, both produce 0\n        q1_star, q2_star = 0.0, 0.0\n    elif q1_star_unconstrained < 0:\n        # Firm 1 is non-competitive, check firm 2's monopoly power\n        q1_star = 0.0\n        q2_star = best_response(0.0, a, b, c2)\n    elif q2_star_unconstrained < 0:\n        # Firm 2 is non-competitive, check firm 1's monopoly power\n        q2_star = 0.0\n        q1_star = best_response(0.0, a, b, c1)\n\n    return np.array([q1_star, q2_star])\n\ndef simulate_synchronized(params):\n    \"\"\"\n    Performs the synchronous simulation using two threads and a barrier.\n    This correctly models simultaneous moves.\n    \"\"\"\n    q_state = [params.q0.copy(), np.zeros(2)] # Double buffer for current and next state\n    read_idx, write_idx = 0, 1\n    \n    barrier = threading.Barrier(2)\n\n    def firm_worker(firm_id):\n        nonlocal read_idx, write_idx\n        my_c = params.c1 if firm_id == 0 else params.c2\n        other_firm_id = 1 - firm_id\n\n        for _ in range(params.T):\n            # Read from the same state (t)\n            q_other = q_state[read_idx][other_firm_id]\n            \n            # Compute own next quantity for state (t+1)\n            my_next_q = best_response(q_other, params.a, params.b, my_c)\n            q_state[write_idx][firm_id] = my_next_q\n            \n            # Wait at barrier for other firm to finish its calculation\n            barrier.wait()\n            \n            # One thread swaps buffers for the next iteration\n            if firm_id == 0:\n                read_idx, write_idx = write_idx, read_idx\n            \n            # Second barrier to ensure buffers are swapped before next read starts\n            barrier.wait()\n\n    thread1 = threading.Thread(target=firm_worker, args=(0,))\n    thread2 = threading.Thread(target=firm_worker, args=(1,))\n    \n    thread1.start()\n    thread2.start()\n    \n    thread1.join()\n    thread2.join()\n    \n    return q_state[read_idx]\n\ndef simulate_unsynchronized(params):\n    \"\"\"\n    Performs the unsynchronized sequential simulation.\n    This demonstrates the modeling error from lack of synchronization.\n    \"\"\"\n    q = params.q0.copy()\n    a, b, c1, c2, T = params.a, params.b, params.c1, params.c2, params.T\n    \n    for _ in range(T):\n        # Firm 1 updates first, based on q from step t\n        q1_next = best_response(q[1], a, b, c1)\n        q[0] = q1_next\n        \n        # Firm 2 updates second, based on the *new* q1 from step t+1\n        q2_next = best_response(q[0], a, b, c2)\n        q[1] = q2_next\n        \n    return q\n\ndef solve_case(params):\n    \"\"\"\n    Solves a single test case: calculates equilibrium, runs simulations,\n    and computes the required output metrics.\n    \"\"\"\n    q_star = calculate_nash_equilibrium(params)\n    \n    q_sync_final = simulate_synchronized(params)\n    q_unsync_final = simulate_unsynchronized(params)\n\n    # Calculate metrics\n    d = np.max(np.abs(q_sync_final - q_unsync_final))\n    e_sync = np.linalg.norm(q_sync_final - q_star)\n    e_unsync = np.linalg.norm(q_unsync_final - q_star)\n    \n    return d, e_sync, e_unsync\n\n# Run the solver\nsolve()\n\n```"}]}