{"hands_on_practices": [{"introduction": "Economic models often build aggregate quantities from the behavior of many individual agents, a process that frequently leads to multi-dimensional integration. This first exercise [@problem_id:2415557] simulates the calculation of a country's total output by integrating a firm-level production function over a distribution of firm productivity and capital. While appearing to require a numerical approach, this problem highlights a crucial skill for any computational economist: recognizing when an integral corresponds to a known theoretical form, such as a moment-generating function, which allows for an elegant and exact analytical solution.", "id": "2415557", "problem": "A large continuum of heterogeneous firms produce output according to the firm-level production function $y(z,k)=z^{\\alpha}k^{\\beta}$, where $z&gt;0$ is firm productivity and $k&gt;0$ is firm capital. In the stationary equilibrium of the model, the joint distribution of $(\\ln Z,\\ln K)$ is bivariate normal with mean vector $\\mu=\\begin{bmatrix}\\mu_z\\\\ \\mu_k\\end{bmatrix}$ and covariance matrix $\\Sigma=\\begin{bmatrix}\\sigma_z^2 & \\rho\\,\\sigma_z\\sigma_k\\\\ \\rho\\,\\sigma_z\\sigma_k & \\sigma_k^2\\end{bmatrix}$, where $\\sigma_z&gt;0$, $\\sigma_k&gt;0$, and $-1&lt;\\rho&lt;1$. Define $Z=\\exp(X_z)$ and $K=\\exp(X_k)$ for $(X_z,X_k)\\sim \\mathcal{N}(\\mu,\\Sigma)$. The aggregate output is the expectation\n$$\nY=\\mathbb{E}\\!\\left[Z^{\\alpha}K^{\\beta}\\right]\n=\\iint_{\\mathbb{R}^2}\\exp(\\alpha x+\\beta y)\\,\\phi(x,y;\\mu,\\Sigma)\\,dx\\,dy,\n$$\nwhere the bivariate normal density is\n$$\n\\phi(x,y;\\mu,\\Sigma)=\\frac{1}{2\\pi\\sqrt{\\det\\Sigma}}\\exp\\!\\left(-\\tfrac{1}{2}\\begin{bmatrix}x-\\mu_z & y-\\mu_k\\end{bmatrix}\\Sigma^{-1}\\begin{bmatrix}x-\\mu_z\\\\ y-\\mu_k\\end{bmatrix}\\right).\n$$\n\nYour task is to compute $Y$ for each parameter set in the test suite below. All quantities are dimensionless. Your program must treat each test case independently and return the aggregate outputs as floating-point numbers rounded to six decimal places.\n\nTest suite (each test case is $(\\alpha,\\beta,\\mu_z,\\mu_k,\\sigma_z,\\sigma_k,\\rho)$):\n- Case 1: $(0.3,0.6,0.1,0.2,0.3,0.4,0.3)$\n- Case 2: $(0.5,0.4,0.0,0.0,10^{-6},10^{-6},0.0)$\n- Case 3: $(0.4,0.5,0.1,-0.1,0.5,0.6,0.0)$\n- Case 4: $(0.2,0.79,0.0,0.0,0.8,0.9,0.95)$\n- Case 5: $(0.45,0.5,-0.2,0.3,1.0,1.0,-0.8)$\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$), where each $r_i$ is the computed $Y$ for the corresponding test case, rounded to six decimal places. No other text should be printed.", "solution": "The problem statement has been subjected to validation and is found to be valid. It is scientifically grounded, well-posed, and objective. It presents a standard problem in economic theory concerning the aggregation of firm-level output under distributional assumptions on firm heterogeneity. I will proceed with a solution.\n\nThe problem asks for the computation of aggregate output $Y$, defined as the expectation of the firm-level production function $y(Z,K) = Z^{\\alpha}K^{\\beta}$ over the joint distribution of firm productivity $Z$ and capital $K$.\n\nThe givens are:\n- Production function: $y(Z,K) = Z^{\\alpha}K^{\\beta}$\n- Log-Normal distribution: It is specified that $(\\ln Z, \\ln K)$ follows a bivariate normal distribution. Let $X_z = \\ln Z$ and $X_k = \\ln K$. Then the random vector $\\begin{bmatrix} X_z \\\\ X_k \\end{bmatrix}$ follows a bivariate normal distribution $\\mathcal{N}(\\mu, \\Sigma)$.\n- The mean vector is $\\mu = \\begin{bmatrix} \\mu_z \\\\ \\mu_k \\end{bmatrix}$.\n- The covariance matrix is $\\Sigma = \\begin{bmatrix} \\sigma_z^2 & \\rho\\,\\sigma_z\\sigma_k\\\\ \\rho\\,\\sigma_z\\sigma_k & \\sigma_k^2 \\end{bmatrix}$.\n\nThe aggregate output $Y$ is the expectation:\n$$\nY = \\mathbb{E}\\left[Z^{\\alpha}K^{\\beta}\\right]\n$$\nBy substituting $Z = \\exp(X_z)$ and $K = \\exp(X_k)$, the expression becomes:\n$$\nY = \\mathbb{E}\\left[\\left(\\exp(X_z)\\right)^{\\alpha}\\left(\\exp(X_k)\\right)^{\\beta}\\right] = \\mathbb{E}\\left[\\exp(\\alpha X_z + \\beta X_k)\\right]\n$$\nThis expectation is precisely the moment-generating function (MGF) of the bivariate normal random vector $X = \\begin{bmatrix} X_z \\\\ X_k \\end{bmatrix}$, evaluated at the point $t = \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}$.\n\nThe definitional integral presented in the problem,\n$$\nY=\\iint_{\\mathbb{R}^2}\\exp(\\alpha x+\\beta y)\\,\\phi(x,y;\\mu,\\Sigma)\\,dx\\,dy\n$$\nis correct but represents a naive path to computation. Numerical integration is unnecessary and computationally inferior when a closed-form analytical solution exists. The rigorous approach is to utilize the properties of the multivariate normal distribution.\n\nThe MGF for a general $d$-dimensional normal random vector $X \\sim \\mathcal{N}(\\mu, \\Sigma)$ is given by the formula:\n$$\nM_X(t) = \\mathbb{E}\\left[\\exp(t^T X)\\right] = \\exp\\left(t^T \\mu + \\frac{1}{2} t^T \\Sigma t\\right)\n$$\nIn our two-dimensional case, we have $t = \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}$, $\\mu = \\begin{bmatrix} \\mu_z \\\\ \\mu_k \\end{bmatrix}$, and $\\Sigma = \\begin{bmatrix} \\sigma_z^2 & \\rho\\sigma_z\\sigma_k \\\\ \\rho\\sigma_z\\sigma_k & \\sigma_k^2 \\end{bmatrix}$.\n\nWe now compute the two terms in the exponent of the MGF.\nThe first term is the linear term:\n$$\nt^T \\mu = \\begin{bmatrix} \\alpha & \\beta \\end{bmatrix} \\begin{bmatrix} \\mu_z \\\\ \\mu_k \\end{bmatrix} = \\alpha\\mu_z + \\beta\\mu_k\n$$\nThe second term is the quadratic term:\n$$\nt^T \\Sigma t = \\begin{bmatrix} \\alpha & \\beta \\end{bmatrix} \\begin{bmatrix} \\sigma_z^2 & \\rho\\sigma_z\\sigma_k \\\\ \\rho\\sigma_z\\sigma_k & \\sigma_k^2 \\end{bmatrix} \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}\n$$\nPerforming the matrix multiplication gives:\n$$\nt^T \\Sigma t = \\begin{bmatrix} \\alpha & \\beta \\end{bmatrix} \\begin{bmatrix} \\alpha\\sigma_z^2 + \\beta\\rho\\sigma_z\\sigma_k \\\\ \\alpha\\rho\\sigma_z\\sigma_k + \\beta\\sigma_k^2 \\end{bmatrix}\n$$\n$$\nt^T \\Sigma t = \\alpha(\\alpha\\sigma_z^2 + \\beta\\rho\\sigma_z\\sigma_k) + \\beta(\\alpha\\rho\\sigma_z\\sigma_k + \\beta\\sigma_k^2)\n$$\n$$\nt^T \\Sigma t = \\alpha^2\\sigma_z^2 + \\alpha\\beta\\rho\\sigma_z\\sigma_k + \\alpha\\beta\\rho\\sigma_z\\sigma_k + \\beta^2\\sigma_k^2\n$$\n$$\nt^T \\Sigma t = \\alpha^2\\sigma_z^2 + \\beta^2\\sigma_k^2 + 2\\alpha\\beta\\rho\\sigma_z\\sigma_k\n$$\nSubstituting these terms back into the MGF formula, we obtain the analytical expression for the aggregate output $Y$:\n$$\nY = \\exp\\left( (\\alpha\\mu_z + \\beta\\mu_k) + \\frac{1}{2}(\\alpha^2\\sigma_z^2 + \\beta^2\\sigma_k^2 + 2\\alpha\\beta\\rho\\sigma_z\\sigma_k) \\right)\n$$\nThis formula is exact and avoids the complexities and potential inaccuracies of numerical integration. The implementation will evaluate this closed-form expression for each provided parameter set.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the aggregate output Y for several parameter sets based on an\n    analytical formula for the expectation of a function of two correlated\n    log-normal random variables.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (alpha, beta, mu_z, mu_k, sigma_z, sigma_k, rho)\n    test_cases = [\n        (0.3, 0.6, 0.1, 0.2, 0.3, 0.4, 0.3),\n        (0.5, 0.4, 0.0, 0.0, 1e-6, 1e-6, 0.0),\n        (0.4, 0.5, 0.1, -0.1, 0.5, 0.6, 0.0),\n        (0.2, 0.79, 0.0, 0.0, 0.8, 0.9, 0.95),\n        (0.45, 0.5, -0.2, 0.3, 1.0, 1.0, -0.8),\n    ]\n\n    results = []\n    for case in test_cases:\n        alpha, beta, mu_z, mu_k, sigma_z, sigma_k, rho = case\n\n        # The aggregate output Y is the moment-generating function of the\n        # bivariate normal vector (ln Z, ln K) evaluated at t = (alpha, beta).\n        # Y = exp(t' * mu + 0.5 * t' * Sigma * t)\n        \n        # Linear term: t' * mu\n        linear_term = alpha * mu_z + beta * mu_k\n        \n        # Quadratic term: t' * Sigma * t\n        quadratic_term = (alpha**2 * sigma_z**2 \n                          + beta**2 * sigma_k**2 \n                          + 2 * alpha * beta * rho * sigma_z * sigma_k)\n        \n        # Combine terms in the exponent and calculate Y\n        exponent = linear_term + 0.5 * quadratic_term\n        y_aggregate = np.exp(exponent)\n        \n        # Append the result rounded to six decimal places\n        results.append(round(y_aggregate, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "Many problems in computational finance, such as pricing exotic options, do not have simple analytical solutions and require robust numerical methods. This practice problem [@problem_id:2415537] challenges you to price a derivative whose payoff depends on the path of stochastic volatility, a core concept in modern asset pricing. You will implement the powerful Gauss-Hermite quadrature method, a deterministic approach that is exceptionally efficient for integrals involving normal distributions, and learn how to handle correlated risk factors through a change of variables.", "id": "2415537", "problem": "Consider a derivative security that pays at maturity time $T$ the amount $g(I)$, where $I$ is the time integral of the squared stochastic volatility over a uniform partition of $[0,T]$ with $d$ subintervals, so that\n$$\nI \\equiv \\sum_{i=1}^{d} \\exp\\left(2 X_i\\right)\\,\\Delta t,\\quad \\Delta t \\equiv \\frac{T}{d}.\n$$\nThe log-volatility vector $\\mathbf{X} = (X_1,\\dots,X_d)^\\top$ is modeled as a correlated Gaussian vector under the risk-neutral measure with mean vector $\\boldsymbol{\\mu} = (m,\\dots,m)^\\top$ and covariance matrix $\\mathbf{C}$ given by\n$$\n\\mathbf{X} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\mathbf{C}),\\quad \\mathbf{C}_{ij} = s^2\\,\\rho^{|i-j|}\\ \\text{for}\\ i,j \\in \\{1,\\dots,d\\},\n$$\nwith volatility-of-volatility parameter $s > 0$ and temporal autocorrelation parameter $\\rho \\in (-1,1)$. The derivative payoff is a call on the integrated variance,\n$$\ng(I) = \\max(I - K, 0),\n$$\nwith strike $K > 0$. The arbitrage-free price at time $0$ under the risk-neutral measure with continuously compounded risk-free interest rate $r$ is\n$$\nV_0 = e^{-rT}\\,\\mathbb{E}\\big[g(I)\\big],\n$$\nwhere the expectation is taken under the joint distribution of $\\mathbf{X}$.\n\nYour task is to write a complete program that computes $V_0$ by numerically evaluating the $d$-dimensional expectation $\\mathbb{E}[g(I)]$ using deterministic product Gauss–Hermite quadrature. Start from the following fundamental base:\n- The risk-neutral pricing principle $V_0 = e^{-rT}\\,\\mathbb{E}[\\text{payoff}]$.\n- The definition of multivariate normal distributions and affine transformations of independent standard normal variables.\n- The classical Gauss–Hermite quadrature rule in one dimension and its tensor-product extension to multiple dimensions.\nYou must derive the appropriate change of variables to transform an expectation with respect to a multivariate normal distribution into a form suitable for product Gauss–Hermite quadrature, first for the independent standard normal case and then for the correlated case via an affine transformation. Do not use Monte Carlo or quasi–Monte Carlo; use only deterministic Gauss–Hermite quadrature in $d$ dimensions.\n\nPrecision and numerical stability requirements:\n- Construct the covariance matrix $\\mathbf{C}$ exactly as specified.\n- Use a Cholesky factorization to map independent standard normals to correlated normals consistently with $\\mathbf{C}$.\n- Implement the $d$-dimensional product Gauss–Hermite quadrature with $q$ nodes per dimension, and ensure weights and nodes are correctly scaled for expectations under the standard normal distribution.\n- Compute $V_0$ to a numerically stable value for the specified test suite.\n\nInput and output format:\n- There is no external input; your program must hard-code the test suite below, compute the corresponding prices, and print a single line containing a comma-separated list of the prices in a Python-style list, in the order of the test cases, with each number output as a decimal in fixed-point notation.\n\nTest suite:\n- Case A (one-dimensional baseline):\n  - $d = 1$, $T = 1.0$, $r = 0.02$, $m = -1.0$, $s = 0.5$, $\\rho = 0.0$, $K = 0.5$, $q = 50$.\n- Case B (two-dimensional, weak correlation):\n  - $d = 2$, $T = 1.0$, $r = 0.01$, $m = -1.0$, $s = 0.6$, $\\rho = 0.3$, $K = 0.8$, $q = 12$.\n- Case C (three-dimensional, stronger correlation and longer horizon):\n  - $d = 3$, $T = 2.0$, $r = 0.03$, $m = -1.2$, $s = 0.7$, $\\rho = 0.5$, $K = 1.0$, $q = 8$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[xA,xB,xC]\"), where $xA$, $xB$, and $xC$ are the prices for Cases A, B, and C, respectively, each printed with exactly $10$ digits after the decimal point.", "solution": "The problem requires the computation of the arbitrage-free price $V_0$ of a European-style derivative security. The price is determined by the fundamental risk-neutral valuation formula:\n$$\nV_0 = e^{-rT}\\,\\mathbb{E}\\big[g(I)\\big]\n$$\nwhere $r$ is the continuously compounded risk-free interest rate, $T$ is the time to maturity, and $g(I) = \\max(I - K, 0)$ is the payoff function, which depends on the integrated squared volatility proxy, $I$. The strike price is $K$.\n\nThe integrated variance proxy $I$ is defined as a sum over a discrete time grid:\n$$\nI = \\sum_{i=1}^{d} \\exp\\left(2 X_i\\right)\\,\\Delta t, \\quad \\text{with } \\Delta t = \\frac{T}{d}\n$$\nThe vector of log-volatilities, $\\mathbf{X} = (X_1, \\dots, X_d)^\\top$, is modeled as a multivariate normal random variable, $\\mathbf{X} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\mathbf{C})$. The mean vector is $\\boldsymbol{\\mu} = (m, \\dots, m)^\\top$ and the covariance matrix is a Toeplitz matrix with elements given by $\\mathbf{C}_{ij} = s^2 \\rho^{|i-j|}$ for specified parameters $s > 0$ and $\\rho \\in (-1, 1)$.\n\nThe core of the task is to numerically evaluate the $d$-dimensional expectation $\\mathbb{E}[g(I)]$. This expectation is an integral over $\\mathbb{R}^d$ with respect to the multivariate normal probability density function, $p(\\mathbf{x}; \\boldsymbol{\\mu}, \\mathbf{C})$:\n$$\n\\mathbb{E}[g(I)] = \\int_{\\mathbb{R}^d} g(I(\\mathbf{x})) \\, p(\\mathbf{x}; \\boldsymbol{\\mu}, \\mathbf{C}) \\, d\\mathbf{x}\n$$\nWe are mandated to use deterministic product Gauss-Hermite quadrature, which requires transforming the integral into a form amenable to this method.\n\nThe classical one-dimensional Gauss-Hermite quadrature rule is designed to approximate integrals against the weighting function $e^{-y^2}$:\n$$\n\\int_{-\\infty}^{\\infty} f(y) e^{-y^2} dy \\approx \\sum_{k=1}^{q} w_k f(y_k)\n$$\nwhere $y_k$ are the $q$ nodes (roots of the Hermite polynomial $H_q(y)$) and $w_k$ are the corresponding weights. To evaluate an expectation with respect to a standard normal variable $Z \\sim \\mathcal{N}(0, 1)$, whose probability density function is $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-z^2/2}$, we perform a change of variable $z = \\sqrt{2}y$. The expectation integral becomes:\n$$\n\\mathbb{E}[h(Z)] = \\int_{-\\infty}^{\\infty} h(z) \\frac{e^{-z^2/2}}{\\sqrt{2\\pi}} dz = \\int_{-\\infty}^{\\infty} h(\\sqrt{2}y) \\frac{e^{-y^2}}{\\sqrt{2\\pi}} \\sqrt{2}dy = \\frac{1}{\\sqrt{\\pi}} \\int_{-\\infty}^{\\infty} h(\\sqrt{2}y) e^{-y^2} dy\n$$\nApplying the quadrature rule yields the approximation:\n$$\n\\mathbb{E}[h(Z)] \\approx \\frac{1}{\\sqrt{\\pi}} \\sum_{k=1}^{q} w_k h(\\sqrt{2}y_k)\n$$\nThis can be expressed more compactly by defining scaled nodes $\\tilde{z}_k = \\sqrt{2}y_k$ and scaled weights $\\tilde{w}_k = w_k / \\sqrt{\\pi}$, leading to:\n$$\n\\mathbb{E}[h(Z)] \\approx \\sum_{k=1}^{q} \\tilde{w}_k h(\\tilde{z}_k)\n$$\nFor a $d$-dimensional vector $\\mathbf{Z} = (Z_1, \\dots, Z_d)^\\top$ of independent standard normal variables, the expectation is approximated using a tensor product of the one-dimensional rule over all $q^d$ grid points:\n$$\n\\mathbb{E}[H(\\mathbf{Z})] \\approx \\sum_{k_1=1}^q \\cdots \\sum_{k_d=1}^q H(\\tilde{z}_{k_1}, \\dots, \\tilde{z}_{k_d}) \\prod_{i=1}^d \\tilde{w}_{k_i}\n$$\nThe log-volatility vector $\\mathbf{X}$ is correlated, not standard normal. We must therefore transform the integration domain from $\\mathbf{X} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\mathbf{C})$ to $\\mathbf{Z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$. This is achieved via the affine transformation:\n$$\n\\mathbf{X} = \\boldsymbol{\\mu} + \\mathbf{L}\\mathbf{Z}\n$$\nwhere $\\mathbf{L}$ is a matrix such that $\\mathbf{L}\\mathbf{L}^\\top = \\mathbf{C}$. Such a matrix $\\mathbf{L}$ is found using the Cholesky decomposition of the symmetric positive-definite covariance matrix $\\mathbf{C}$. The expectation over $\\mathbf{X}$ is then rewritten as an equivalent expectation over $\\mathbf{Z}$:\n$$\n\\mathbb{E}_{\\mathbf{X}}[g(I(\\mathbf{X}))] = \\mathbb{E}_{\\mathbf{Z}}[g(I(\\boldsymbol{\\mu} + \\mathbf{L}\\mathbf{Z}))]\n$$\nThis transformed expectation is now in a suitable form for the product Gauss-Hermite quadrature. Let the new integrand be $H(\\mathbf{Z}) = g(I(\\boldsymbol{\\mu} + \\mathbf{L}\\mathbf{Z}))$. The expectation is approximated by the sum:\n$$\n\\mathbb{E}[g(I)] \\approx \\sum_{k_1, \\dots, k_d \\in \\{1,\\dots,q\\}} \\left( H(\\tilde{z}_{k_1}, \\dots, \\tilde{z}_{k_d}) \\prod_{i=1}^d \\tilde{w}_{k_i} \\right)\n$$\nThe overall algorithm is executed as follows:\n1.  For each test case, assemble the parameters: $d, T, r, m, s, \\rho, K, q$.\n2.  Construct the $d \\times d$ covariance matrix $\\mathbf{C}$ with elements $\\mathbf{C}_{ij} = s^2 \\rho^{|i-j|}$ and the mean vector $\\boldsymbol{\\mu}$.\n3.  Compute the Cholesky decomposition of $\\mathbf{C}$ to find the matrix $\\mathbf{L}$.\n4.  Generate the $q$ one-dimensional Gauss-Hermite nodes $y_k$ and weights $w_k$.\n5.  Scale these to obtain nodes $\\tilde{z}_k = \\sqrt{2} y_k$ and weights $\\tilde{w}_k = w_k/\\sqrt{\\pi}$ appropriate for the standard normal distribution.\n6.  Construct a $d$-dimensional grid of $q^d$ nodes by taking the Cartesian product of the scaled 1D nodes. Similarly, compute the product of weights for each point on the grid.\n7.  For each of the $q^d$ grid points $\\mathbf{z}_{\\mathbf{k}}$:\n    a. Transform the standard normal node to the correlated log-volatility space: $\\mathbf{x}_{\\mathbf{k}} = \\boldsymbol{\\mu} + \\mathbf{L}\\mathbf{z}_{\\mathbf{k}}$.\n    b. Compute the integrated variance: $I_{\\mathbf{k}} = (T/d)\\sum_{i=1}^d \\exp(2 (\\mathbf{x}_{\\mathbf{k}})_i)$.\n    c. Evaluate the payoff: $g(I_{\\mathbf{k}}) = \\max(I_{\\mathbf{k}} - K, 0)$.\n    d. Multiply the payoff by the corresponding product of weights $W_{\\mathbf{k}} = \\prod_{i=1}^d \\tilde{w}_{k_i}$ and add to an accumulating sum.\n8.  The final sum approximates $\\mathbb{E}[g(I)]$. The derivative price is then $V_0 = e^{-rT}$ times this sum. This procedure is implemented in a vectorized manner for efficiency.", "answer": "```python\nimport numpy as np\n\ndef compute_price(d, T, r, m, s, rho, K, q):\n    \"\"\"\n    Computes the derivative price V0 using d-dimensional Gauss-Hermite quadrature.\n\n    Args:\n        d (int): Dimension of the log-volatility vector.\n        T (float): Time to maturity.\n        r (float): Risk-free interest rate.\n        m (float): Mean of the log-volatility components.\n        s (float): Volatility-of-volatility parameter.\n        rho (float): Autocorrelation parameter.\n        K (float): Strike price.\n        q (int): Number of quadrature nodes per dimension.\n\n    Returns:\n        float: The computed arbitrage-free price V0.\n    \"\"\"\n    # Step 1: Construct mean vector and covariance matrix\n    mu = np.full(d, m)\n    indices = np.arange(d)\n    # Using broadcasting to create the Toeplitz covariance matrix efficiently\n    C = s**2 * rho**(np.abs(indices[:, np.newaxis] - indices))\n    \n    # Step 2: Perform Cholesky decomposition of the covariance matrix\n    # L is a lower-triangular matrix such that C = L @ L.T\n    try:\n        L = np.linalg.cholesky(C)\n    except np.linalg.LinAlgError:\n        # This should not happen for valid parameters rho in (-1, 1)\n        # but is good practice for numerical stability.\n        raise ValueError(\"Covariance matrix is not positive-definite.\")\n\n    # Step 3: Generate and scale 1D Gauss-Hermite nodes and weights\n    nodes_hermite, weights_hermite = np.polynomial.hermite.hermgauss(q)\n    # Scale nodes and weights for integration against the standard normal PDF\n    nodes_std_normal = nodes_hermite * np.sqrt(2.0)\n    weights_std_normal = weights_hermite / np.sqrt(np.pi)\n\n    # Step 4: Create d-dimensional grid of nodes and product weights\n    # The meshgrid approach creates all combinations of nodes for a vectorized calculation.\n    # It returns a list of d-dimensional arrays.\n    node_grids = np.meshgrid(*[nodes_std_normal for _ in range(d)])\n    # We stack the raveled grids to get an array of shape (q**d, d) where each row is a point.\n    z_vectors = np.stack([grid.ravel() for grid in node_grids], axis=1)\n    \n    # Similarly, create product weights for each point\n    weight_grids = np.meshgrid(*[weights_std_normal for _ in range(d)])\n    w_products = np.prod(np.stack([grid.ravel() for grid in weight_grids], axis=1), axis=1)\n    \n    # Step 5: Vectorized computation of the expectation\n    # Transform standard normal nodes z to correlated log-volatility nodes x\n    # z_vectors.T has shape (d, q**d). L @ z_vectors.T has shape (d, q**d).\n    # After transposing back, we have (q**d, d). Add mean vector mu.\n    x_vectors = mu + (L @ z_vectors.T).T\n    \n    # Calculate integrated variance I for all points\n    delta_t = T / d\n    I_values = delta_t * np.sum(np.exp(2.0 * x_vectors), axis=1)\n    \n    # Calculate payoffs for all points\n    payoffs = np.maximum(I_values - K, 0.0)\n    \n    # Step 6: Compute the expectation as the dot product of payoffs and weights\n    expectation = np.dot(payoffs, w_products)\n    \n    # Step 7: Discount the expectation to get the final price\n    price = np.exp(-r * T) * expectation\n    \n    return price\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Test suite defined in the problem statement\n    test_cases = [\n        # Case A: 1D baseline\n        {'d': 1, 'T': 1.0, 'r': 0.02, 'm': -1.0, 's': 0.5, 'rho': 0.0, 'K': 0.5, 'q': 50},\n        # Case B: 2D, weak correlation\n        {'d': 2, 'T': 1.0, 'r': 0.01, 'm': -1.0, 's': 0.6, 'rho': 0.3, 'K': 0.8, 'q': 12},\n        # Case C: 3D, stronger correlation\n        {'d': 3, 'T': 2.0, 'r': 0.03, 'm': -1.2, 's': 0.7, 'rho': 0.5, 'K': 1.0, 'q': 8},\n    ]\n\n    results = []\n    for case in test_cases:\n        price = compute_price(**case)\n        # Format the result to 10 decimal places in fixed-point notation\n        results.append(f\"{price:.10f}\")\n\n    # Print the final output in the required format\n    print(f\"[{','.join(results)}]\")\n\n# Execute the solver\nif __name__ == \"__main__\":\n    solve()\n```"}, {"introduction": "Choosing the right tool for numerical integration is paramount, as methods can have vastly different performance characteristics. This final exercise [@problem_id:2415504] pits standard Monte Carlo simulation against a more advanced quasi-Monte Carlo (QMC) method using a Sobol sequence, which often converges faster. By constructing a special, economically plausible payoff function, you will uncover a scenario where the QMC method's performance degrades significantly, teaching the critical lesson that a method's effectiveness is tied to the underlying structure of the problem.", "id": "2415504", "problem": "Consider the integration of an expected payoff that depends on $d$ independent risk factors modeled as a vector $U=(U_{1},\\dots,U_{d})$ of independent Uniform$([0,1])$ random variables. For an integer $m \\ge 1$, define the sample size $N=2^{m}$. Let $p=2^{-(m+1)}$ and $\\tau=1-p=1-2^{-(m+1)}$. Define the following two payoff functions on $[0,1]^{d}$:\n\n1. Pathological but economically plausible extreme-trigger digital payoff (interpretable as a coupon that pays only if at least one period exhibits an extreme positive shock):\n$$\ng_{d,m}(u) \\;=\\; \\mathbf{1}\\Big\\{\\max_{1 \\le i \\le d} u_{i} \\ge \\tau\\Big\\}.\n$$\n\n2. Smooth benchmark payoff:\n$$\nh_{d}(u) \\;=\\; \\exp\\Big(-\\sum_{i=1}^{d} u_{i}\\Big).\n$$\n\nFor each payoff, the target is the risk-neutral expected value (under the Uniform$([0,1])$ factors), namely\n$$\nG(d,m) \\;=\\; \\mathbb{E}\\big[g_{d,m}(U)\\big] \\;=\\; 1 - \\big(1 - p\\big)^{d} \\quad\\text{with}\\quad p=2^{-(m+1)},\n$$\nand\n$$\nH(d) \\;=\\; \\mathbb{E}\\big[h_{d}(U)\\big] \\;=\\; \\prod_{i=1}^{d} \\int_{0}^{1} e^{-u_{i}} \\, du_{i} \\;=\\; \\big(1 - e^{-1}\\big)^{d}.\n$$\n\nYou will implement two estimators of these expectations at the same sample size $N=2^{m}$:\n\n- A low-discrepancy estimator based on the first $2^{m}$ points of a Sobol digital net in base $2$ applied in $d$ dimensions.\n- A standard Monte Carlo estimator based on $N$ independent and identically distributed Uniform$([0,1])$ points in $d$ dimensions.\n\nFor each test case below, compute the absolute error of both estimators with respect to the corresponding exact value ($G(d,m)$ or $H(d)$), and return a boolean indicating whether the Sobol-based absolute error is strictly greater than the standard Monte Carlo absolute error.\n\nTest suite (each item is a tuple specifying which payoff to integrate, the dimension $d$, and the exponent $m$ defining $N=2^{m}$):\n\n- Case $1$: $\\big(\\text{digital},\\, d=100,\\, m=10\\big)$ to evaluate $G(100,10)$.\n- Case $2$: $\\big(\\text{smooth},\\, d=20,\\, m=10\\big)$ to evaluate $H(20)$.\n- Case $3$: $\\big(\\text{digital},\\, d=1,\\, m=10\\big)$ to evaluate $G(1,10)$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite, for example, $[\\text{true},\\text{false},\\text{true}]$ but using the programming language’s canonical boolean literals.\n\nNo physical units are involved. All angles, if any arise, must be in radians, but none are required here. The final outputs per test case are booleans as specified above. Do not read any input; use the test suite given above verbatim.", "solution": "We formalize the estimands and their exact values, then design two sampling-based estimators from first principles. Let $U=(U_{1},\\dots,U_{d})$ with independent and identically distributed components, each Uniform$([0,1])$.\n\nFor the extreme-trigger digital payoff $g_{d,m}$,\n$$\ng_{d,m}(u) = \\mathbf{1}\\Big\\{\\max_{1 \\le i \\le d} u_{i} \\ge \\tau\\Big\\}, \\quad \\tau = 1 - p, \\quad p=2^{-(m+1)}.\n$$\nThe exact expectation is the probability that at least one coordinate exceeds the threshold $\\tau$:\n$$\nG(d,m) = \\mathbb{E}[g_{d,m}(U)] = \\mathbb{P}\\Big(\\max_{1 \\le i \\le d} U_{i} \\ge \\tau\\Big) = 1 - \\mathbb{P}\\Big(\\max_{1 \\le i \\le d} U_{i} < \\tau\\Big).\n$$\nSince the $U_{i}$ are independent and identically distributed,\n$$\n\\mathbb{P}\\Big(\\max_{1 \\le i \\le d} U_{i} < \\tau\\Big) = \\prod_{i=1}^{d} \\mathbb{P}(U_{i} < \\tau) = \\tau^{d} = \\big(1 - p\\big)^{d},\n$$\nhence\n$$\nG(d,m) = 1 - \\big(1 - p\\big)^{d}, \\quad p=2^{-(m+1)}.\n$$\n\nFor the smooth payoff $h_{d}$,\n$$\nh_{d}(u) = \\exp\\Big(-\\sum_{i=1}^{d} u_{i}\\Big) = \\prod_{i=1}^{d} e^{-u_{i}}.\n$$\nUsing independence and Fubini’s theorem,\n$$\nH(d) = \\mathbb{E}[h_{d}(U)] = \\prod_{i=1}^{d} \\int_{0}^{1} e^{-u_{i}} \\, du_{i} = \\big(1 - e^{-1}\\big)^{d}.\n$$\n\nWe consider two integration rules with common sample size $N=2^{m}$:\n\n1. Sobol-based estimator. A Sobol digital net in base $2$ in $d$ dimensions is a deterministic set of $N$ points in $[0,1)^{d}$ with low-discrepancy properties. Denote these points by $\\{x^{(n)}\\}_{n=1}^{N}$. The estimator is\n$$\n\\widehat{I}_{\\text{Sob}} = \\frac{1}{N} \\sum_{n=1}^{N} f\\big(x^{(n)}\\big),\n$$\nwhere $f$ is either $g_{d,m}$ or $h_{d}$. When using precisely $N=2^{m}$ points generated by the power-of-two rule, each coordinate of $x^{(n)}$ is a binary fraction with at most $m$ bits, implying $\\max_{1 \\le n \\le N,\\, 1 \\le i \\le d} x^{(n)}_{i} \\le 1 - 2^{-m}$. For the digital payoff threshold $\\tau = 1 - 2^{-(m+1)}$, we have $1 - 2^{-m} < \\tau$, hence $g_{d,m}(x^{(n)})=0$ for all $n$. Therefore, for $g_{d,m}$,\n$$\n\\widehat{G}_{\\text{Sob}} = 0, \\quad \\big|\\widehat{G}_{\\text{Sob}} - G(d,m)\\big| = G(d,m) = 1 - \\big(1 - 2^{-(m+1)}\\big)^{d}.\n$$\nThis exhibits a deterministic underestimation for this choice, showing a pathological underperformance.\n\nFor the smooth payoff $h_{d}$, no such degeneracy occurs, and low-discrepancy sampling typically reduces integration error relative to independent sampling, although this is not guaranteed problem-by-problem; the estimator is the same average without the degeneracy.\n\n2. Standard Monte Carlo estimator. Draw $N$ independent and identically distributed samples $\\{U^{(n)}\\}_{n=1}^{N}$ from Uniform$([0,1])^{d}$ and compute\n$$\n\\widehat{I}_{\\text{MC}} = \\frac{1}{N} \\sum_{n=1}^{N} f\\big(U^{(n)}\\big).\n$$\nFor $g_{d,m}$, each summand is a Bernoulli random variable with success probability $q = G(d,m)$. The estimator is unbiased with variance\n$$\n\\mathbb{V}\\big[\\widehat{G}_{\\text{MC}}\\big] = \\frac{q(1-q)}{N}.\n$$\nWith the specific choice $p=2^{-(m+1)}$ and $d$ moderately large, $q = 1 - (1-p)^{d} \\approx d\\,p$ for small $p$, so a typical absolute error of order $\\sqrt{q(1-q)/N}$ is expected. In contrast, the Sobol estimator for $g_{d,m}$ at $N=2^{m}$ yields a deterministic absolute error equal to $q$ itself, which can be substantially larger than the Monte Carlo sampling error for the same $N$.\n\nAlgorithmic design. For each test case, we compute the exact value ($G(d,m)$ for the digital payoff and $H(d)$ for the smooth payoff). We then compute two estimates: (i) the Sobol-based average over the first $2^{m}$ points of a $d$-dimensional Sobol digital net and (ii) the standard Monte Carlo average over $N=2^{m}$ independent samples. We then report whether the Sobol-based absolute error is strictly greater than the standard Monte Carlo absolute error. The test suite covers: a pathological digital case in moderately high dimension intended to trigger the deterministic underestimation for the Sobol rule; a smooth case to assess typical behavior on well-behaved integrands; and a boundary digital case in one dimension illustrating the same degeneracy at the most basic dimension. The final program prints a single list of booleans in the order of the test suite.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import qmc\n\ndef digital_payoff_any_tail(samples: np.ndarray, tau: float) -> np.ndarray:\n    \"\"\"\n    Pathological but economically plausible digital payoff:\n    pays 1 if any coordinate exceeds tau, else 0.\n    samples: array of shape (N, d)\n    tau: threshold in (0,1)\n    Returns: array of shape (N,) with 0/1 values.\n    \"\"\"\n    return (samples.max(axis=1) >= tau).astype(float)\n\ndef smooth_payoff(samples: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Smooth benchmark payoff: exp(-sum_i u_i).\n    samples: array of shape (N, d)\n    Returns: array of shape (N,) with positive real values.\n    \"\"\"\n    return np.exp(-samples.sum(axis=1))\n\ndef exact_digital_expectation(d: int, m: int) -> float:\n    p = 2.0 ** (-(m + 1))\n    return 1.0 - (1.0 - p) ** d\n\ndef exact_smooth_expectation(d: int) -> float:\n    return (1.0 - np.exp(-1.0)) ** d\n\ndef sobol_estimate(d: int, m: int, which: str) -> float:\n    \"\"\"\n    Compute Sobol-based estimate using N=2^m points.\n    which: 'digital' or 'smooth'\n    \"\"\"\n    N = 2 ** m\n    engine = qmc.Sobol(d, scramble=False)\n    # Generate exactly 2^m points using the power-of-two method\n    samples = engine.random_base2(m)\n    if which == 'digital':\n        tau = 1.0 - 2.0 ** (-(m + 1))\n        vals = digital_payoff_any_tail(samples, tau)\n    elif which == 'smooth':\n        vals = smooth_payoff(samples)\n    else:\n        raise ValueError(\"Unknown payoff type.\")\n    return float(vals.mean())\n\ndef mc_estimate(d: int, m: int, which: str, seed: int) -> float:\n    \"\"\"\n    Compute standard Monte Carlo estimate with N=2^m IID uniforms.\n    which: 'digital' or 'smooth'\n    \"\"\"\n    N = 2 ** m\n    rng = np.random.default_rng(seed)\n    samples = rng.random((N, d))\n    if which == 'digital':\n        tau = 1.0 - 2.0 ** (-(m + 1))\n        vals = digital_payoff_any_tail(samples, tau)\n    elif which == 'smooth':\n        vals = smooth_payoff(samples)\n    else:\n        raise ValueError(\"Unknown payoff type.\")\n    return float(vals.mean())\n\ndef solve():\n    # Test suite: (which, d, m)\n    test_cases = [\n        (\"digital\", 100, 10),  # Pathological case\n        (\"smooth\", 20, 10),    # Smooth benchmark\n        (\"digital\", 1, 10),    # Boundary digital case\n    ]\n\n    results = []\n    # Use distinct seeds for MC to ensure deterministic but independent sampling per case\n    base_seed = 1234567\n    for idx, (which, d, m) in enumerate(test_cases):\n        # Exact value\n        if which == \"digital\":\n            exact = exact_digital_expectation(d, m)\n        else:\n            exact = exact_smooth_expectation(d)\n\n        # Sobol estimate\n        est_sobol = sobol_estimate(d, m, which)\n        err_sobol = abs(est_sobol - exact)\n\n        # MC estimate\n        est_mc = mc_estimate(d, m, which, seed=base_seed + 1000 * (idx + 1))\n        err_mc = abs(est_mc - exact)\n\n        # Compare absolute errors: True if Sobol performs worse\n        results.append(err_sobol > err_mc)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"}]}