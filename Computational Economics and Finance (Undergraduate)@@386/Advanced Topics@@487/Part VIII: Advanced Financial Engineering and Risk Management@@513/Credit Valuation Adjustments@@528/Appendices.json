{"hands_on_practices": [{"introduction": "The valuation of Credit Valuation Adjustment (CVA) often requires projecting the future value of financial instruments whose worth is uncertain. This practice guides you through constructing a CVA pricing engine from fundamental principles using the powerful Monte Carlo simulation method. You will simulate asset price paths under a risk-neutral Geometric Brownian Motion, calculate the corresponding Expected Positive Exposure, and integrate it with a default model to arrive at the CVA [@problem_id:2386203]. By implementing and comparing a simple looped version against a computationally efficient vectorized model, you will gain essential skills in both the theory of CVA and the high-performance computing practices vital for modern quantitative finance.", "id": "2386203", "problem": "You are asked to build a small, self-contained computational engine for Credit Valuation Adjustment (CVA) in a Monte Carlo framework and to compare two computational backends: a scalar Central Processing Unit (CPU) implementation using explicit loops and a Single Instruction Multiple Data (SIMD)-style vectorized backend that emulates Graphics Processing Unit (GPU) bulk parallel execution using array programming. In contexts where actual Graphics Processing Unit (GPU) execution is unavailable, vectorization is a standard and faithful proxy for Single Instruction Multiple Data (SIMD) parallelism, enabling the same algorithmic structure that would be offloaded to a GPU kernel.\n\nStart from the following fundamental base:\n- Under the risk-neutral measure, the spot price process for a single risky asset is modeled by the Geometric Brownian Motion (GBM): $$dS_t = (r - q) S_t \\, dt + \\sigma S_t \\, dW_t,$$ where $S_t$ is the spot, $r$ is the continuously compounded risk-free rate, $q$ is the continuous dividend yield, $\\sigma$ is the volatility, and $W_t$ is a standard Brownian motion.\n- The value at time $t$ of a long forward contract delivering at maturity $T$ with strike $K$ under continuous dividend yield $q$ is $$V_t = S_t e^{-q (T - t)} - K e^{-r (T - t)}.$$\n- The uncollateralized exposure at time $t$ is $$E_t = \\max(V_t, 0).$$\n- With a constant hazard (default intensity) $\\lambda$ and recovery rate $R$, the loss given default is $$\\text{LGD} = 1 - R,$$ and the survival probability is $$\\mathbb{S}(t) = e^{-\\lambda t}.$$ The risk-neutral default density is $$f(t) = \\lambda e^{-\\lambda t}.$$\n- Continuous-time CVA under independence is $$\\text{CVA} = \\text{LGD} \\int_0^T D(0,t) \\, \\mathbb{E}[E_t] \\, f(t) \\, dt,$$ where $$D(0,t) = e^{-r t}$$ is the discount factor and $$\\mathbb{E}[E_t]$$ is the expected exposure.\n\nTask:\n1) Derive a consistent discrete-time estimator for CVA using a uniform time grid $t_i = i \\Delta t$ for $i = 1, 2, \\dots, M$ with $\\Delta t = T/M$ and a Monte Carlo estimator for the expected exposure. Your derivation must begin from the fundamental base above and must not rely on any shortcut formulas.\n2) Implement two backends for the estimator:\n   - A scalar CPU backend using explicit nested loops over paths and over time.\n   - A vectorized backend that emulates GPU-style parallelism by applying the same operation to whole arrays of simulated states at once (i.e., Single Instruction Multiple Data).\n3) Use the same random numbers for both backends to ensure that any difference arises from the compute strategy and not from different stochastic draws.\n4) Benchmark both backends by measuring wall-clock time. You must compute the timings internally, but your program’s final output must only contain the CVA values requested below.\n5) For each test case, compute the CVA in the same currency units as $S_0$ and $K$, returned as a floating-point number.\n\nDiscretization and estimator design constraints:\n- Use the Euler–Maruyama exact step for the GBM in log form: $$S_{t+\\Delta t} = S_t \\exp\\!\\Big(\\big((r - q) - \\tfrac{1}{2}\\sigma^2\\big) \\Delta t + \\sigma \\sqrt{\\Delta t} \\, Z\\Big),$$ with $Z \\sim \\mathcal{N}(0,1)$ independent across time steps and paths.\n- Approximate the integral with a Riemann sum evaluated on the right endpoints: $$\\text{CVA} \\approx (1-R) \\sum_{i=1}^{M} e^{-r t_i} \\, \\widehat{\\mathbb{E}}[E_{t_i}] \\, \\lambda e^{-\\lambda t_i} \\, \\Delta t,$$ where $\\widehat{\\mathbb{E}}[E_{t_i}]$ is the Monte Carlo average of $E_{t_i}$ across all simulated paths.\n- All probabilities and rates must be expressed as decimals (not percentages).\n\nTest suite:\nImplement your program to compute the CVA for the following parameter sets. Each test case is a tuple $(S_0, K, T, r, q, \\sigma, \\lambda, R, N, M, \\text{seed})$:\n- Case A (happy path): $(\\$100.0, \\$100.0, 1.0, 0.02, 0.0, 0.2, 0.02, 0.4, 20000, 50, 20240501)$\n- Case B (zero hazard boundary): $(\\$100.0, \\$100.0, 1.0, 0.02, 0.0, 0.2, 0.0, 0.4, 20000, 50, 20240501)$\n- Case C (full recovery boundary): $(\\$100.0, \\$100.0, 1.0, 0.02, 0.0, 0.2, 0.02, 1.0, 20000, 50, 20240501)$\n- Case D (deterministic exposure check): $(\\$100.0, \\$90.0, 1.0, 0.01, 0.0, 0.0, 0.05, 0.4, 5000, 50, 7)$\n\nImplementation requirements:\n- Use the same matrix of standard normal draws across both backends for each test case so that numerical differences, if any, are attributable only to the computational strategy.\n- Internally measure and record the runtime of each backend for Case A. No timing results should be printed, but the computations must occur.\n- For each test case, output only the CVA computed by the vectorized backend, rounded to six decimal places. If a case mathematically implies zero CVA (e.g., zero hazard or zero loss given default), the output for that case must be exactly $0.0$ after rounding.\n\nFinal output format:\n- Your program should produce a single line of output containing the CVA results for the four test cases as a comma-separated list enclosed in square brackets, for example, $$[\\text{cva}_A,\\text{cva}_B,\\text{cva}_C,\\text{cva}_D],$$ where each entry is a floating-point number rounded to six decimal places.\n\nNotes:\n- There are no physical units; all monetary outputs are in the same currency units as $S_0$ and $K$.\n- Angles are not applicable.\n- All rates ($r$, $q$, $\\sigma$, $\\lambda$) and the recovery rate $R$ must be passed as decimals, not percentages.", "solution": "The problem presented is a well-defined task in computational finance, requiring the derivation and implementation of a Monte Carlo estimator for Credit Valuation Adjustment (CVA). Before proceeding with a solution, a formal validation is required.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n\nThe problem provides the following explicit information:\n\n- **Asset Price Process**: Geometric Brownian Motion (GBM) under the risk-neutral measure: $$dS_t = (r - q) S_t \\, dt + \\sigma S_t \\, dW_t$$ where $S_t$ is the spot price, $r$ is the risk-free rate, $q$ is the dividend yield, $\\sigma$ is the volatility, and $W_t$ is a standard Brownian motion.\n- **Contract Valuation**: The value of a long forward contract is $$V_t = S_t e^{-q (T - t)} - K e^{-r (T - t)}$$ where $T$ is maturity and $K$ is the strike price.\n- **Exposure Definition**: Uncollateralized exposure is $$E_t = \\max(V_t, 0).$$\n- **Default Model**: Constant hazard rate $\\lambda$, recovery rate $R$, Loss Given Default $\\text{LGD} = 1 - R$, survival probability $\\mathbb{S}(t) = e^{-\\lambda t}$, and risk-neutral default density $f(t) = \\lambda e^{-\\lambda t}$.\n- **CVA Formula**: Continuous-time CVA under independence is $$\\text{CVA} = \\text{LGD} \\int_0^T D(0,t) \\, \\mathbb{E}[E_t] \\, f(t) \\, dt,$$ where $D(0,t) = e^{-r t}$ is the discount factor.\n- **Discretization Scheme**:\n    - Time grid: $t_i = i \\Delta t$ for $i = 1, 2, \\dots, M$ with $\\Delta t = T/M$.\n    - GBM simulation step: $$S_{t+\\Delta t} = S_t \\exp\\!\\Big(\\big((r - q) - \\tfrac{1}{2}\\sigma^2\\big) \\Delta t + \\sigma \\sqrt{\\Delta t} \\, Z\\Big),$$ with $Z \\sim \\mathcal{N}(0,1)$.\n    - CVA estimator: $$\\text{CVA} \\approx (1-R) \\sum_{i=1}^{M} e^{-r t_i} \\, \\widehat{\\mathbb{E}}[E_{t_i}] \\, \\lambda e^{-\\lambda t_i} \\, \\Delta t,$$ where $\\widehat{\\mathbb{E}}[E_{t_i}]$ is the Monte Carlo average of $E_{t_i}$.\n- **Test Suite**: Four parameter sets, each a tuple $(S_0, K, T, r, q, \\sigma, \\lambda, R, N, M, \\text{seed})$.\n    - A: $(\\$100.0, \\$100.0, 1.0, 0.02, 0.0, 0.2, 0.02, 0.4, 20000, 50, 20240501)$\n    - B: $(\\$100.0, \\$100.0, 1.0, 0.02, 0.0, 0.2, 0.0, 0.4, 20000, 50, 20240501)$\n    - C: $(\\$100.0, \\$100.0, 1.0, 0.02, 0.0, 0.2, 0.02, 1.0, 20000, 50, 20240501)$\n    - D: $(\\$100.0, \\$90.0, 1.0, 0.01, 0.0, 0.0, 0.05, 0.4, 5000, 50, 7)$\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is evaluated against the validation criteria.\n- **Scientifically Grounded**: The problem is based on standard, cornerstone models of quantitative finance (GBM, Merton-style default modeling). The formulas provided are correct and widely used. The problem is scientifically sound.\n- **Well-Posed**: The problem is structured with all necessary inputs, a specified numerical method (Monte Carlo with a defined path discretizer and integral approximation), and a clear objective. For a given random seed, the procedure yields a unique numerical solution. The problem is well-posed.\n- **Objective**: All definitions are mathematical, and all inputs are numerical. The language is precise and free of subjectivity. The problem is objective.\n- **Other Flaws**: The problem statement is self-contained, consistent, and feasible. There are no contradictions, ambiguities, or reliance on pseudoscience. The task is a standard exercise in computational economics and finance.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. A solution will be constructed.\n\n**Solution: Design and Implementation**\n\nThe task is to derive a discrete estimator for CVA and implement it using two different computational paradigms: scalar and vectorized.\n\n**1. Discretization and Estimator Derivation**\n\nThe derivation starts from the provided continuous-time CVA formula:\n$$ \\text{CVA} = \\text{LGD} \\int_0^T D(0,t) \\, \\mathbb{E}[E_t] \\, f(t) \\, dt $$\nSubstitute the given definitions for LGD, the discount factor $D(0,t)$, and the default density $f(t)$:\n$$ \\text{CVA} = (1-R) \\int_0^T e^{-rt} \\, \\mathbb{E}[E_t] \\, \\lambda e^{-\\lambda t} \\, dt $$\nThe problem requires approximating this integral using a right Riemann sum over a uniform time grid. The interval $[0, T]$ is partitioned into $M$ subintervals $[t_{i-1}, t_i]$ of width $\\Delta t = T/M$, where $t_i = i \\Delta t$ for $i = 1, \\dots, M$. The integral is approximated by summing the values of the integrand at the right endpoints $t_i$:\n$$ \\int_0^T g(t) \\, dt \\approx \\sum_{i=1}^M g(t_i) \\Delta t $$\nApplying this to the CVA integral yields the discrete estimator:\n$$ \\text{CVA} \\approx (1-R) \\sum_{i=1}^{M} \\left( e^{-r t_i} \\, \\mathbb{E}[E_{t_i}] \\, \\lambda e^{-\\lambda t_i} \\right) \\Delta t $$\nThis matches the formula specified in the problem statement. The next step is to estimate the expected future exposure, $\\mathbb{E}[E_{t_i}]$, using a Monte Carlo simulation with $N$ paths. The expected value is replaced by its sample mean estimator, $\\widehat{\\mathbb{E}}[E_{t_i}]$:\n$$ \\widehat{\\mathbb{E}}[E_{t_i}] = \\frac{1}{N} \\sum_{j=1}^{N} E_{t_i}^{(j)} $$\nwhere $E_{t_i}^{(j)}$ is the exposure on the $j$-th simulated path at time $t_i$. The exposure is a function of the simulated asset price $S_{t_i}^{(j)}$:\n$$ E_{t_i}^{(j)} = \\max\\left( V_{t_i}^{(j)}, 0 \\right) = \\max\\left( S_{t_i}^{(j)} e^{-q (T - t_i)} - K e^{-r (T - t_i)}, 0 \\right) $$\nEach path $S^{(j)}$ is generated step-by-step using the exact solution to the log-price SDE, starting from $S_{t_0}^{(j)}=S_0$:\n$$ S_{t_i}^{(j)} = S_{t_{i-1}}^{(j)} \\exp\\left( \\left( (r - q) - \\frac{1}{2}\\sigma^2 \\right) \\Delta t + \\sigma \\sqrt{\\Delta t} \\, Z_{i,j} \\right) $$\nwhere $Z_{i,j}$ are independent standard normal random variables.\n\nCombining these components gives the full computational formula for the CVA estimator.\n\n**2. Algorithmic Design**\n\nTwo computational backends are designed based on the derived estimator. For a fair comparison, both must use the same underlying matrix of standard normal draws, $Z \\in \\mathbb{R}^{N \\times M}$.\n\n**Scalar (CPU) Backend:**\nThis approach uses explicit, nested loops, which is typical of traditional CPU programming.\n\n1.  Initialize an array `expected_exposures` of size $M$ to all zeros.\n2.  Outer loop over each path $j$ from $1$ to $N$.\n3.  Inside the outer loop, initialize the path's starting price `current_S = S_0`.\n4.  Inner loop over each time step $i$ from $1$ to $M$.\n5.  Inside the inner loop:\n    a. Retrieve the random normal draw $Z_{i,j}$.\n    b. Compute the next asset price $S_{t_i}$ from `current_S` using the GBM step formula.\n    c. Calculate the exposure $E_{t_i}$ at this time step.\n    d. Add this exposure to the running sum for that time step: `expected_exposures[i-1] += E_{t_i}`.\n    e. Update `current_S = S_{t_i}`.\n6.  After the outer loop completes, finalize the average by dividing each element of `expected_exposures` by $N$.\n7.  Compute the final CVA value by summing the terms of the discrete integral approximation, using the now-computed `expected_exposures` array.\n\n**Vectorized (SIMD/GPU-style) Backend:**\nThis approach leverages array programming to perform operations on entire vectors or matrices at once, emulating the Single Instruction, Multiple Data (SIMD) paradigm of parallel processors like GPUs.\n\n1.  Generate the entire $N \\times M$ matrix of standard normal draws, $Z$.\n2.  Initialize a vector `S_current` of size $N$, with all elements set to $S_0$.\n3.  Initialize a results vector `cva_sum_terms` of size $M$ to zeros.\n4.  Loop over each time step $i$ from $1$ to $M$.\n5.  Inside the loop:\n    a. Get the column vector of random draws $Z_{:, i-1}$ for the current step.\n    b. Update the entire `S_current` vector of $N$ asset prices in a single operation.\n    c. Compute the vector of $N$ forward contract values, $V_{t_i}$, simultaneously.\n    d. Compute the vector of $N$ exposures, $E_{t_i} = \\max(V_{t_i}, 0)$, for all paths.\n    e. Calculate the average of this exposure vector to get $\\widehat{\\mathbb{E}}[E_{t_i}]$.\n    f. Compute the $i$-th term of the CVA integrand and store it in `cva_sum_terms[i-1]`.\n6.  After the loop, calculate the final CVA by summing the `cva_sum_terms` vector and multiplying by the constants $\\lambda$, $(1-R)$, and $\\Delta t$.\n\nThis vectorized method avoids explicit loops over the simulation paths, replacing them with highly optimized, low-level array operations provided by libraries like NumPy. This typically results in a significant performance improvement.\n\n**3. Implementation Strategy**\n\nThe solution will be implemented in Python using the NumPy library for numerical computations, particularly for the vectorized backend. For each test case, a random number generator will be seeded to ensure reproducibility. The same matrix of random numbers generated for a case will be passed to both the scalar and vectorized functions to ensure that the only difference in output, if any, is due to floating-point arithmetic ordering, and the performance difference is due to the algorithm. The runtime of both backends for Case A will be measured via `time.perf_counter()` to fulfill the benchmarking requirement, though these timings will not be part of the final printed output. The final CVA values from the vectorized backend will be rounded to six decimal places as required.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport time\n\ndef cva_scalar_cpu(S0, K, T, r, q, sigma, lambda_c, R, N, M, Z):\n    \"\"\"\n    Computes CVA using a scalar (loopy) implementation.\n    \"\"\"\n    dt = T / M\n    \n    if lambda_c == 0.0 or R == 1.0:\n        return 0.0\n\n    # Calculate Expected Exposures\n    expected_exposures = [0.0] * M\n    for j in range(N):  # Loop over paths\n        S_curr = S0\n        for i in range(M):  # Loop over time steps\n            drift = (r - q - 0.5 * sigma**2) * dt\n            diffusion = sigma * np.sqrt(dt) * Z[j, i]\n            S_curr *= np.exp(drift + diffusion)\n            \n            t = (i + 1) * dt\n            forward_val = S_curr * np.exp(-q * (T - t)) - K * np.exp(-r * (T - t))\n            exposure = max(forward_val, 0.0)\n            \n            expected_exposures[i] += exposure\n\n    for i in range(M):\n        expected_exposures[i] /= N\n\n    # Calculate CVA\n    cva_sum = 0.0\n    for i in range(M):\n        t = (i + 1) * dt\n        discount = np.exp(-r * t)\n        default_prob_density = lambda_c * np.exp(-lambda_c * t)\n        cva_sum += discount * expected_exposures[i] * default_prob_density\n\n    cva = (1 - R) * cva_sum * dt\n    return cva\n\ndef cva_vectorized_simd(S0, K, T, r, q, sigma, lambda_c, R, N, M, Z):\n    \"\"\"\n    Computes CVA using a vectorized (SIMD-style) implementation.\n    \"\"\"\n    dt = T / M\n    \n    if lambda_c == 0.0 or R == 1.0:\n        return 0.0\n\n    # Time grid\n    t = np.linspace(dt, T, M)\n    \n    # Generate asset price paths\n    S = np.zeros((N, M + 1))\n    S[:, 0] = S0\n    \n    drift = (r - q - 0.5 * sigma**2) * dt\n    diffusion = sigma * np.sqrt(dt)\n    \n    for i in range(M):\n        S[:, i + 1] = S[:, i] * np.exp(drift + diffusion * Z[:, i])\n    \n    S_paths = S[:, 1:] # Paths at t_1, ..., t_M\n    \n    # Calculate Exposures\n    forward_vals = S_paths * np.exp(-q * (T - t)) - K * np.exp(-r * (T - t))\n    exposures = np.maximum(forward_vals, 0)\n    \n    # Calculate Expected Exposures\n    expected_exposures = np.mean(exposures, axis=0)\n    \n    # Calculate CVA\n    discount = np.exp(-r * t)\n    default_prob_density = lambda_c * np.exp(-lambda_c * t)\n    integrand = (1 - R) * discount * expected_exposures * default_prob_density\n    \n    cva = np.sum(integrand) * dt\n    return cva\n\ndef solve():\n    \"\"\"\n    Main solver function to run test cases and produce the final output.\n    \"\"\"\n    # (S0, K, T, r, q, sigma, lambda_c, R, N, M, seed)\n    test_cases = [\n        (100.0, 100.0, 1.0, 0.02, 0.0, 0.2, 0.02, 0.4, 20000, 50, 20240501), # Case A\n        (100.0, 100.0, 1.0, 0.02, 0.0, 0.2, 0.0, 0.4, 20000, 50, 20240501),  # Case B\n        (100.0, 100.0, 1.0, 0.02, 0.0, 0.2, 0.02, 1.0, 20000, 50, 20240501),  # Case C\n        (100.0, 90.0, 1.0, 0.01, 0.0, 0.0, 0.05, 0.4, 5000, 50, 7),         # Case D\n    ]\n\n    results = []\n\n    # Process Case A separately to perform the required benchmark timing.\n    S0, K, T, r, q, sigma, lambda_c, R, N, M, seed = test_cases[0]\n    rng = np.random.default_rng(seed)\n    Z = rng.standard_normal(size=(N, M))\n    \n    # Time scalar implementation for Case A (computation must occur, but result is not printed)\n    start_time_scalar = time.perf_counter()\n    _ = cva_scalar_cpu(S0, K, T, r, q, sigma, lambda_c, R, N, M, Z)\n    end_time_scalar = time.perf_counter()\n    # scalar_time = end_time_scalar - start_time_scalar # For internal verification\n\n    # Time vectorized implementation for Case A and collect result\n    start_time_vec = time.perf_counter()\n    cva_A = cva_vectorized_simd(S0, K, T, r, q, sigma, lambda_c, R, N, M, Z)\n    end_time_vec = time.perf_counter()\n    # vec_time = end_time_vec - start_time_vec # For internal verification\n    \n    results.append(round(cva_A, 6))\n\n    # Process remaining cases (B, C, D) using only the vectorized backend for output\n    for case in test_cases[1:]:\n        S0, K, T, r, q, sigma, lambda_c, R, N, M, seed = case\n        rng = np.random.default_rng(seed)\n        Z = rng.standard_normal(size=(N, M))\n        cva = cva_vectorized_simd(S0, K, T, r, q, sigma, lambda_c, R, N, M, Z)\n        results.append(round(cva, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "The accuracy of any CVA calculation is critically dependent on the quality of its inputs, particularly the counterparty's probability of default. This exercise elevates our CVA framework by integrating it with a modern, data-driven credit model based on machine learning [@problem_id:2386252]. You will use the output from a logistic regression model, which generates annual default probabilities $p_{\\text{ann}}$ from firm-specific features, to derive a corresponding constant hazard rate $\\lambda = -\\ln(1 - p_{\\text{ann}})$ for your CVA calculation. This practice provides invaluable experience in bridging the disciplines of financial modeling and data science, enabling a more nuanced and empirically grounded approach to pricing credit risk.", "id": "2386252", "problem": "You are given a task to compute the Credit Valuation Adjustment (CVA) of a portfolio where the default probabilities of counterparties are derived from a logistic regression (LR) model trained on firm-specific features. Your goal is to derive from first principles and then implement a program that computes the portfolio CVA under a risk-neutral measure, assuming independence between exposure and default and unilateral counterparty credit risk.\n\nAssumptions and foundational base:\n- Under risk-neutral valuation, the Credit Valuation Adjustment (CVA) for a portfolio can be expressed as the discounted expected loss due to counterparty default over a time horizon. Let $t \\in [0, T]$ denote time, $D(t)$ the risk-free discount factor, $\\text{LGD}$ the loss given default, $E^{\\mathbb{Q}}[\\cdot]$ the risk-neutral expectation, and $\\tau$ the random default time of a counterparty. The general definition is\n$$\n\\text{CVA} \\;=\\; E^{\\mathbb{Q}}\\!\\left[\\int_{0}^{T} D(t)\\,\\text{LGD}\\,\\max(V(t),0)\\,\\mathrm{d}\\mathbf{1}_{\\{\\tau \\le t\\}}\\right].\n$$\n- The point-in-time default probability for a firm is modeled using logistic regression. For each firm with feature vector $x \\in \\mathbb{R}^{d}$, let the LR score be $z = \\beta_0 + \\sum_{i=1}^{d} \\beta_i x_i$. The annual unconditional default probability is $p_{\\text{ann}} = \\sigma(z)$ with the logistic (sigmoid) function $\\sigma(u) = \\frac{1}{1 + e^{-u}}$.\n- The survival function for a constant hazard rate model with intensity $\\lambda$ is $S(t) = e^{-\\lambda t}$, and the unconditional default probability over one year is related by $p_{\\text{ann}} = 1 - e^{-\\lambda \\cdot 1}$. This implies $\\lambda = -\\ln(1 - p_{\\text{ann}})$.\n- For a discrete annual time grid $t_k = k$ for $k = 1, \\dots, K$, with piecewise-constant expected positive exposure (EPE) at the grid points and a flat continuously compounded risk-free rate $r$, the discount factor is $D(t_k) = e^{-r t_k}$.\n- The marginal default probability in the interval $(t_{k-1}, t_k]$ under a constant hazard $\\lambda$ is $S(t_{k-1}) - S(t_k)$, where $S(0) = 1$.\n\nTask:\n1. Starting from the general risk-neutral CVA definition and the above assumptions, derive a discretized expression for the portfolio CVA on an annual grid. Your derivation must clearly show how to combine default likelihoods, discount factors, expected positive exposure (EPE), and loss given default (LGD). Do not use any unproven or unexplained shortcut formulas; derive each step from the definitions of survival probability, hazard rate, and risk-neutral expectation.\n2. Implement a program that:\n   - Uses the LR model to compute the annual default probability $p_{\\text{ann}}$ from features and coefficients via $p_{\\text{ann}} = \\sigma(\\beta_0 + \\sum_{i=1}^{d} \\beta_i x_i)$.\n   - Converts $p_{\\text{ann}}$ to a constant hazard rate $\\lambda = -\\ln(1 - p_{\\text{ann}})$.\n   - Uses an annual grid $t_k = k$ (with $k$ equal to the number of EPE points for the firm) to compute survival $S(t_k) = e^{-\\lambda t_k}$ and marginal default $S(t_{k-1}) - S(t_k)$.\n   - Computes per-firm CVA as the sum over $k$ of discounted expected loss contributions and then sums across firms to obtain portfolio CVA.\n   - Implements numerically stable logistic evaluation and clips probabilities to the open interval $(\\epsilon, 1-\\epsilon)$ with $\\epsilon = 10^{-12}$ before applying the logarithm transformation.\n3. Use the following test suite. Each test case provides a flat rate $r$, an intercept $\\beta_0$, a coefficient vector $\\beta$, and a list of firms, each with a feature vector $x$, a loss given default $\\text{LGD}$, and an annual-grid EPE vector. The time step is one year, so the $k$-th EPE entry corresponds to $t_k = k$.\n   - Test case $1$ (happy path, multiple firms, moderate probabilities, horizon $5$ years):\n     - $r = 0.02$,\n     - $\\beta_0 = -4.0$,\n     - $\\beta = [0.8, -0.5]$,\n     - Firms:\n       - Firm A: $x = [1.2, 0.3]$, $\\text{LGD} = 0.6$, $\\text{EPE} = [1.0, 0.9, 0.8, 0.7, 0.6]$.\n       - Firm B: $x = [0.5, -0.1]$, $\\text{LGD} = 0.6$, $\\text{EPE} = [0.5, 0.5, 0.5, 0.5, 0.5]$.\n       - Firm C: $x = [-0.2, 1.5]$, $\\text{LGD} = 0.6$, $\\text{EPE} = [0.2, 0.25, 0.3, 0.35, 0.4]$.\n   - Test case $2$ (boundary condition: zero exposure implies zero CVA, horizon $3$ years):\n     - $r = 0.01$,\n     - $\\beta_0 = -4.0$,\n     - $\\beta = [0.8, -0.5]$,\n     - Firms:\n       - Firm D: $x = [0.0, 0.0]$, $\\text{LGD} = 0.6$, $\\text{EPE} = [0.0, 0.0, 0.0]$.\n       - Firm E: $x = [1.0, -1.0]$, $\\text{LGD} = 0.6$, $\\text{EPE} = [0.0, 0.0, 0.0]$.\n   - Test case $3$ (edge coverage: high and low probabilities, heterogeneous $\\text{LGD}$, zero risk-free rate, horizon $7$ years):\n     - $r = 0.0$,\n     - $\\beta_0 = -1.0$,\n     - $\\beta = [1.5, 1.0]$,\n     - Firms:\n       - Firm F: $x = [1.0, 1.0]$, $\\text{LGD} = 0.4$, $\\text{EPE} = [0.2, 0.4, 0.6, 0.8, 0.6, 0.4, 0.2]$.\n       - Firm G: $x = [-2.0, -1.0]$, $\\text{LGD} = 0.6$, $\\text{EPE} = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4]$.\n4. Output specification:\n   - For each test case, compute a single portfolio CVA value as a floating-point number.\n   - Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each number must be rounded to $6$ decimal places. For example: $[0.123456,0.000000,1.234568]$.\n5. Angle units are not applicable. Percentages must be expressed as decimals (for instance, $\\text{LGD} = 0.6$ denotes $60\\%$). No physical units are required; monetary values are treated as abstract numerical quantities.\n\nYour implementation must be self-contained, require no input, and follow the output format exactly. Any deviation from the specified format will be considered incorrect. The algorithm should be general enough to handle the listed test suite.", "solution": "The problem of computing the portfolio Credit Valuation Adjustment (CVA) is valid as it is scientifically grounded in established principles of financial engineering, well-posed with a complete and consistent set of data and assumptions, and objectively formulated. The following is a derivation from first principles followed by the implementation of the solution.\n\nThe derivation begins with the general risk-neutral definition of CVA. The CVA represents the market value of counterparty credit risk. For a single counterparty, it is the risk-neutral expected value of the discounted loss incurred at the time of the counterparty's default, $\\tau$.\nThe provided definition is:\n$$ \\text{CVA} = E^{\\mathbb{Q}}\\!\\left[\\int_{0}^{T} D(t)\\,\\text{LGD}\\,\\max(V(t),0)\\,\\mathrm{d}\\mathbf{1}_{\\{\\tau \\le t\\}}\\right] $$\nwhere $E^{\\mathbb{Q}}[\\cdot]$ is the expectation under the risk-neutral measure $\\mathbb{Q}$, $D(t)$ is the risk-free discount factor at time $t$, $\\text{LGD}$ is the loss-given-default (a constant fraction), $V(t)$ is the market value of the portfolio of trades with the counterparty, and $\\tau$ is the random time of default. The term $\\max(V(t),0)$ represents the exposure at default, as loss only occurs if the portfolio has a positive value to us. The integral is a Stieltjes integral, which can be interpreted as evaluating the discounted loss at the instant of default $\\tau$, provided $\\tau \\le T$. A more standard formulation is:\n$$ \\text{CVA} = E^{\\mathbb{Q}}\\!\\left[ \\mathbf{1}_{\\{\\tau \\le T\\}} \\cdot D(\\tau) \\cdot \\text{LGD} \\cdot \\max(V(\\tau), 0) \\right] $$\nThis expresses the CVA as the expectation of the loss, discounted from the time of default $\\tau$. To evaluate this expectation, we can integrate over all possible default times, weighted by their risk-neutral probability density. Let $f_\\tau(t)$ be the probability density function (PDF) of the default time $\\tau$. The CVA is then:\n$$ \\text{CVA} = \\int_{0}^{T} E^{\\mathbb{Q}}\\!\\left[ D(t) \\cdot \\text{LGD} \\cdot \\max(V(t), 0) \\mid \\tau=t \\right] f_\\tau(t) \\, \\mathrm{d}t $$\nA crucial assumption is the independence between the default event and the market risk driving the portfolio's value $V(t)$. This allows us to separate the expectation:\n$$ E^{\\mathbb{Q}}\\!\\left[ D(t) \\cdot \\text{LGD} \\cdot \\max(V(t), 0) \\mid \\tau=t \\right] = D(t) \\cdot \\text{LGD} \\cdot E^{\\mathbb{Q}}\\!\\left[\\max(V(t), 0)\\right] $$\nThe term $E^{\\mathbb{Q}}\\!\\left[\\max(V(t), 0)\\right]$ is the Expected Positive Exposure, denoted $\\text{EPE}(t)$. The formula simplifies to:\n$$ \\text{CVA} = \\int_{0}^{T} D(t) \\cdot \\text{LGD} \\cdot \\text{EPE}(t) \\cdot f_\\tau(t) \\, \\mathrm{d}t $$\nThe PDF $f_\\tau(t)$ is related to the survival probability function $S(t) = P(\\tau > t)$ by $f_\\tau(t) = -\\frac{\\mathrm{d}S(t)}{\\mathrm{d}t}$. Substituting this in, we obtain:\n$$ \\text{CVA} = -\\int_{0}^{T} D(t) \\cdot \\text{LGD} \\cdot \\text{EPE}(t) \\cdot S'(t) \\, \\mathrm{d}t $$\nTo implement this numerically, we discretize the time horizon $[0, T]$ into $K$ intervals $(t_{k-1}, t_k]$ where $t_k = k$ for $k=1, \\dots, K$ and $t_0=0$. The integral is approximated by a sum over these intervals:\n$$ \\text{CVA} \\approx \\sum_{k=1}^{K} \\int_{t_{k-1}}^{t_k} D(t) \\cdot \\text{LGD} \\cdot \\text{EPE}(t) \\cdot f_\\tau(t) \\, \\mathrm{d}t $$\nWe assume that over each small interval $(t_{k-1}, t_k]$, the terms $D(t)$ and $\\text{EPE}(t)$ are approximately constant and can be evaluated at the end of the interval, i.e., $D(t) \\approx D(t_k)$ and $\\text{EPE}(t) \\approx \\text{EPE}(t_k)$. This is a standard first-order approximation.\n$$ \\text{CVA} \\approx \\sum_{k=1}^{K} D(t_k) \\cdot \\text{LGD} \\cdot \\text{EPE}(t_k) \\int_{t_{k-1}}^{t_k} f_\\tau(t) \\, \\mathrm{d}t $$\nThe integral of the PDF over the interval $(t_{k-1}, t_k]$ is simply the probability of defaulting in that interval:\n$$ \\int_{t_{k-1}}^{t_k} f_\\tau(t) \\, \\mathrm{d}t = P(t_{k-1} < \\tau \\le t_k) = S(t_{k-1}) - S(t_k) $$\nThis term is the marginal default probability for the $k$-th period. Substituting this into the sum gives the final discretized formula for a single counterparty's CVA:\n$$ \\text{CVA}_{\\text{firm}} \\approx \\text{LGD} \\sum_{k=1}^{K} D(t_k) \\cdot \\text{EPE}(t_k) \\cdot [S(t_{k-1}) - S(t_k)] $$\nThe portfolio CVA is the sum of the CVAs for each individual counterparty, assuming their defaults are independent events:\n$$ \\text{CVA}_{\\text{portfolio}} = \\sum_{j} \\text{CVA}_{\\text{firm } j} $$\nNow we incorporate the specific models provided. The default process is modeled by a constant hazard rate $\\lambda$. The survival function is $S(t) = e^{-\\lambda t}$. The hazard rate $\\lambda$ is derived from the logistic regression model's output, which is the annual unconditional default probability $p_{\\text{ann}}$. The relation is $p_{\\text{ann}} = P(\\tau \\le 1) = 1 - S(1) = 1 - e^{-\\lambda \\cdot 1}$. Solving for $\\lambda$ yields $\\lambda = -\\ln(1 - p_{\\text{ann}})$. The annual probability $p_{\\text{ann}}$ is given by the sigmoid function $\\sigma(z)$ of a linear score $z = \\beta_0 + \\mathbf{x}^T \\boldsymbol{\\beta}$:\n$$ p_{\\text{ann}} = \\sigma(z) = \\frac{1}{1+e^{-z}} $$\nThe risk-free discount factor for a continuously compounded rate $r$ at time $t_k=k$ is $D(t_k) = e^{-r t_k}$. Assembling all components, we calculate the CVA for a single firm as follows:\n1.  Compute the score $z = \\beta_0 + \\sum_{i=1}^{d} \\beta_i x_i$.\n2.  Compute the annual default probability $p_{\\text{ann}} = \\sigma(z)$, using a numerically stable implementation. Clip $p_{\\text{ann}}$ to $(\\epsilon, 1-\\epsilon)$ for $\\epsilon=10^{-12}$.\n3.  Compute the constant hazard rate $\\lambda = -\\ln(1 - p_{\\text{ann}})$.\n4.  Calculate the CVA contribution for each time interval $k=1, \\dots, K$:\n    $$ \\text{CVA}_{\\text{firm}} = \\text{LGD} \\sum_{k=1}^{K} e^{-r k} \\cdot \\text{EPE}_k \\cdot (e^{-\\lambda (k-1)} - e^{-\\lambda k}) $$\n    where $\\text{EPE}_k$ is the given Expected Positive Exposure for the $k$-th year. The total portfolio CVA is the sum of these values over all firms.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes portfolio CVA based on a logistic regression model for default probabilities.\n    \"\"\"\n    # Test cases defined in the problem statement.\n    test_cases = [\n        # Test case 1\n        {\n            \"r\": 0.02,\n            \"beta0\": -4.0,\n            \"beta\": np.array([0.8, -0.5]),\n            \"firms\": [\n                {\"x\": np.array([1.2, 0.3]), \"lgd\": 0.6, \"epe\": np.array([1.0, 0.9, 0.8, 0.7, 0.6])},\n                {\"x\": np.array([0.5, -0.1]), \"lgd\": 0.6, \"epe\": np.array([0.5, 0.5, 0.5, 0.5, 0.5])},\n                {\"x\": np.array([-0.2, 1.5]), \"lgd\": 0.6, \"epe\": np.array([0.2, 0.25, 0.3, 0.35, 0.4])},\n            ]\n        },\n        # Test case 2\n        {\n            \"r\": 0.01,\n            \"beta0\": -4.0,\n            \"beta\": np.array([0.8, -0.5]),\n            \"firms\": [\n                {\"x\": np.array([0.0, 0.0]), \"lgd\": 0.6, \"epe\": np.array([0.0, 0.0, 0.0])},\n                {\"x\": np.array([1.0, -1.0]), \"lgd\": 0.6, \"epe\": np.array([0.0, 0.0, 0.0])},\n            ]\n        },\n        # Test case 3\n        {\n            \"r\": 0.0,\n            \"beta0\": -1.0,\n            \"beta\": np.array([1.5, 1.0]),\n            \"firms\": [\n                {\"x\": np.array([1.0, 1.0]), \"lgd\": 0.4, \"epe\": np.array([0.2, 0.4, 0.6, 0.8, 0.6, 0.4, 0.2])},\n                {\"x\": np.array([-2.0, -1.0]), \"lgd\": 0.6, \"epe\": np.array([1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4])},\n            ]\n        }\n    ]\n\n    results = []\n    \n    # Numerical precision for clipping\n    epsilon = 1e-12\n\n    def stable_sigmoid(z):\n        \"\"\"Numerically stable sigmoid function.\"\"\"\n        if z >= 0:\n            return 1.0 / (1.0 + np.exp(-z))\n        else:\n            # Use formulation exp(z) / (1 + exp(z)) to avoid overflow\n            exp_z = np.exp(z)\n            return exp_z / (1.0 + exp_z)\n\n    for case in test_cases:\n        r = case[\"r\"]\n        beta0 = case[\"beta0\"]\n        beta = case[\"beta\"]\n        firms = case[\"firms\"]\n        \n        portfolio_cva = 0.0\n        \n        for firm in firms:\n            x = firm[\"x\"]\n            lgd = firm[\"lgd\"]\n            epe = firm[\"epe\"]\n            \n            # 1. Compute LR score\n            z = beta0 + np.dot(beta, x)\n            \n            # 2. Compute annual default probability\n            p_ann = stable_sigmoid(z)\n            \n            # 3. Clip for numerical stability before log\n            p_ann_clipped = np.clip(p_ann, epsilon, 1.0 - epsilon)\n            \n            # 4. Convert to constant hazard rate\n            # If p_ann is 1, lambda would be inf. Clipping handles this.\n            hazard_rate_lambda = -np.log(1.0 - p_ann_clipped)\n            \n            firm_cva = 0.0\n            num_steps = len(epe)\n            \n            if num_steps == 0:\n                portfolio_cva += 0.0\n                continue\n                \n            # Time steps k = 1, 2, ..., K\n            k_steps = np.arange(1, num_steps + 1)\n            \n            # Discount factors D(t_k) = exp(-r*k)\n            discount_factors = np.exp(-r * k_steps)\n            \n            # Survival probabilities S(t_k) = exp(-lambda*k) and S(t_{k-1})\n            s_k_minus_1 = np.exp(-hazard_rate_lambda * (k_steps - 1))\n            s_k = np.exp(-hazard_rate_lambda * k_steps)\n            \n            # Marginal default probabilities in (t_{k-1}, t_k]\n            marginal_pd = s_k_minus_1 - s_k\n            \n            # Expected loss for each period\n            expected_loss_periods = epe * marginal_pd\n            \n            # Discounted expected loss for each period\n            discounted_el = discount_factors * expected_loss_periods\n            \n            # Sum over all periods and multiply by LGD for the firm's CVA\n            firm_cva = lgd * np.sum(discounted_el)\n            \n            portfolio_cva += firm_cva\n            \n        results.append(round(portfolio_cva, 6))\n\n    # Format the final output string\n    print(f\"[{','.join(f'{res:.6f}' for res in results)}]\")\n\nsolve()\n```"}, {"introduction": "In dynamic financial markets, CVA is not a static figure but is constantly re-evaluated as portfolios evolve. This hands-on practice addresses the real-world task of assessing the risk impact of a new trade by calculating the incremental CVA, or $\\Delta\\text{CVA}$ [@problem_id:2386214]. The exercise specifically demonstrates the crucial effect of netting, where the addition of a new trade can either increase or decrease the portfolio's total credit risk depending on how its exposure profile interacts with existing positions. Mastering this calculation is fundamental for effective pre-trade analysis, risk limit monitoring, and understanding the marginal risk contribution of each transaction within a netting set.", "id": "2386214", "problem": "Consider a single-counterparty setting for Credit Valuation Adjustment (CVA). Let time be represented on a discrete grid $\\{t_1,\\dots,t_N\\}$ with $t_0=0$. Let the risk-free continuously compounded rate be constant at $r$, the counterparty default intensity (hazard rate) be constant at $\\lambda$, and the fractional recovery be $R$. Define the survival function by $S(t)=\\exp(-\\lambda t)$ and the discount factor by $D(t)=\\exp(-r t)$. Let the incremental default probability over the interval $(t_{k-1},t_k]$ be $\\Delta \\mathrm{PD}_k=S(t_{k-1})-S(t_k)$, with $S(t_0)=1$. For a deterministic netting-set exposure path, let the existing portfolio’s (pre-positive-part) exposure at $t_k$ be $E^{\\mathrm{old}}_k$, and a newly added trade’s (pre-positive-part) exposure at $t_k$ be $E^{\\mathrm{new}}_k$. The netted positive exposure at $t_k$ is $\\max(x,0)$ applied to the pre-positive-part net exposure. The unilateral CVA, using the discrete-time approximation, is\n$$\n\\mathrm{CVA} = (1-R)\\sum_{k=1}^{N} D(t_k)\\,\\Big(\\max\\big(E_k,0\\big)\\Big)\\,\\Delta \\mathrm{PD}_k,\n$$\nwhere $E_k$ denotes the relevant net exposure at $t_k$. The incremental CVA due to adding the new trade is\n$$\n\\Delta \\mathrm{CVA} = \\mathrm{CVA}\\big(\\max(E^{\\mathrm{old}}+E^{\\mathrm{new}},0)\\big) - \\mathrm{CVA}\\big(\\max(E^{\\mathrm{old}},0)\\big).\n$$\nAll rates $r$ and $\\lambda$ are per year as decimals, time $t_k$ is in years, exposures $E^{\\mathrm{old}}_k$ and $E^{\\mathrm{new}}_k$ are in arbitrary currency units, and the final answer must be reported in the same currency units as a decimal number.\n\nTask: For each test case below, compute $\\Delta \\mathrm{CVA}$ as defined above. Use the given parameters exactly and treat all arrays as ordered by $t_1,\\dots,t_N$.\n\nTest Suite:\n- Test case $1$ (general case with netting effects): $r=0.02$, $\\lambda=0.03$, $R=0.4$, $[t_1,t_2,t_3,t_4]=[0.5,1.0,1.5,2.0]$, $[E^{\\mathrm{old}}_k]_{k=1}^4=[10,8,6,4]$, $[E^{\\mathrm{new}}_k]_{k=1}^4=[-3,-2,1,2]$.\n- Test case $2$ (boundary: zero hazard rate): $r=0.02$, $\\lambda=0.0$, $R=0.4$, $[t_1,t_2,t_3,t_4]=[0.5,1.0,1.5,2.0]$, $[E^{\\mathrm{old}}_k]_{k=1}^4=[2,-1,4,-2]$, $[E^{\\mathrm{new}}_k]_{k=1}^4=[1,-3,2,0]$.\n- Test case $3$ (all exposures strictly positive, zero risk-free rate, zero recovery): $r=0.0$, $\\lambda=0.1$, $R=0.0$, $[t_1,t_2,t_3,t_4]=[0.25,0.5,0.75,1.0]$, $[E^{\\mathrm{old}}_k]_{k=1}^4=[5,5,5,5]$, $[E^{\\mathrm{new}}_k]_{k=1}^4=[2,2,2,2]$.\n- Test case $4$ (boundary: full recovery): $r=0.05$, $\\lambda=0.2$, $R=1.0$, $[t_1,t_2,t_3]=[1.0,2.0,3.0]$, $[E^{\\mathrm{old}}_k]_{k=1}^3=[-1,2,3]$, $[E^{\\mathrm{new}}_k]_{k=1}^3=[4,-1,1]$.\n\nRequired final output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as test cases $1$ to $4$, with each number rounded to exactly six digits after the decimal point (for example, $[0.123456,-0.000001,1.000000]$).", "solution": "The problem statement has been rigorously validated. It is found to be scientifically grounded, well-posed, and free of contradictions or ambiguity. The definitions and formulas provided for Credit Valuation Adjustment (CVA) are standard, albeit simplified, representations used in quantitative finance. All necessary parameters for the specified test cases are provided. The problem is therefore deemed **valid**. We proceed with the derivation of the solution.\n\nThe objective is to compute the incremental CVA ($\\Delta \\mathrm{CVA}$) resulting from the addition of a new trade to an existing portfolio. The $\\Delta \\mathrm{CVA}$ is defined as the difference between the CVA of the combined portfolio and the CVA of the original portfolio:\n$$\n\\Delta \\mathrm{CVA} = \\mathrm{CVA}(\\text{combined}) - \\mathrm{CVA}(\\text{original})\n$$\n\nThe CVA for a given exposure profile is calculated using the discrete-time approximation formula:\n$$\n\\mathrm{CVA} = (1-R)\\sum_{k=1}^{N} D(t_k)\\,\\Big(\\max\\big(E_k,0\\big)\\Big)\\,\\Delta \\mathrm{PD}_k\n$$\nwhere:\n- $R$ is the fractional recovery rate.\n- $N$ is the number of time steps.\n- $t_k$ is the time of the $k$-th step in years.\n- $E_k$ is the net exposure at time $t_k$.\n- $D(t_k)$ is the risk-free discount factor at time $t_k$.\n- $\\Delta \\mathrm{PD}_k$ is the incremental probability of default over the time interval $(t_{k-1}, t_k]$.\n\nThe components of the formula are calculated as follows for each time step $k \\in \\{1, 2, \\dots, N\\}$:\n\n1.  **Discount Factor, $D(t_k)$**: This is the present value of a unit of currency to be received at time $t_k$. With a constant risk-free rate $r$, it is given by:\n    $$\n    D(t_k) = \\exp(-r \\cdot t_k)\n    $$\n\n2.  **Incremental Default Probability, $\\Delta \\mathrm{PD}_k$**: This is the probability that the counterparty defaults in the interval $(t_{k-1}, t_k]$, given it has survived until $t_{k-1}$. It is derived from the survival function $S(t) = \\exp(-\\lambda t)$, where $\\lambda$ is the constant hazard rate. We define $t_0 = 0$.\n    $$\n    \\Delta \\mathrm{PD}_k = S(t_{k-1}) - S(t_k) = \\exp(-\\lambda \\cdot t_{k-1}) - \\exp(-\\lambda \\cdot t_k)\n    $$\n\n3.  **Positive Exposure, $\\max\\big(E_k,0\\big)$**: The CVA calculation applies only when the exposure $E_k$ is positive, meaning we would suffer a loss if the counterparty defaults. For the original portfolio, the exposure is $E_k^{\\mathrm{old}}$. For the combined portfolio, the exposure is the sum of the original and new exposures, $E_k^{\\mathrm{comb}} = E_k^{\\mathrm{old}} + E_k^{\\mathrm{new}}$, reflecting the effect of netting.\n\nThe overall algorithm is as follows:\n\nFirst, calculate the CVA of the original portfolio, $\\mathrm{CVA}^{\\mathrm{old}}$.\n$$\n\\mathrm{CVA}^{\\mathrm{old}} = (1-R)\\sum_{k=1}^{N} \\exp(-r t_k) \\cdot \\max\\big(E_k^{\\mathrm{old}}, 0\\big) \\cdot \\big(\\exp(-\\lambda t_{k-1}) - \\exp(-\\lambda t_k)\\big)\n$$\n\nSecond, calculate the CVA of the combined portfolio, $\\mathrm{CVA}^{\\mathrm{comb}}$. The combined exposure at each time step is $E_k^{\\mathrm{comb}} = E_k^{\\mathrm{old}} + E_k^{\\mathrm{new}}$.\n$$\n\\mathrm{CVA}^{\\mathrm{comb}} = (1-R)\\sum_{k=1}^{N} \\exp(-r t_k) \\cdot \\max\\big(E_k^{\\mathrm{old}} + E_k^{\\mathrm{new}}, 0\\big) \\cdot \\big(\\exp(-\\lambda t_{k-1}) - \\exp(-\\lambda t_k)\\big)\n$$\n\nFinally, the incremental CVA is the difference:\n$$\n\\Delta \\mathrm{CVA} = \\mathrm{CVA}^{\\mathrm{comb}} - \\mathrm{CVA}^{\\mathrm{old}}\n$$\n\nThis procedure will be applied to each test case. The boundary conditions provided in the test suite serve as important checks on the correctness of the implementation:\n- If $\\lambda = 0$, then $\\Delta \\mathrm{PD}_k = 0$ for all $k$, which must result in $\\mathrm{CVA} = 0$ and $\\Delta \\mathrm{CVA} = 0$.\n- If $R = 1$, then the factor $(1-R) = 0$, which must also result in $\\mathrm{CVA} = 0$ and $\\Delta \\mathrm{CVA} = 0$.\n\nThe implementation will utilize vectorized computations for efficiency, where entire arrays of discount factors, default probabilities, and exposures are processed in single operations.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the incremental Credit Valuation Adjustment (Delta CVA)\n    for a series of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"r\": 0.02, \"lambda\": 0.03, \"R\": 0.4,\n            \"t\": [0.5, 1.0, 1.5, 2.0],\n            \"E_old\": [10, 8, 6, 4],\n            \"E_new\": [-3, -2, 1, 2]\n        },\n        {\n            \"r\": 0.02, \"lambda\": 0.0, \"R\": 0.4,\n            \"t\": [0.5, 1.0, 1.5, 2.0],\n            \"E_old\": [2, -1, 4, -2],\n            \"E_new\": [1, -3, 2, 0]\n        },\n        {\n            \"r\": 0.0, \"lambda\": 0.1, \"R\": 0.0,\n            \"t\": [0.25, 0.5, 0.75, 1.0],\n            \"E_old\": [5, 5, 5, 5],\n            \"E_new\": [2, 2, 2, 2]\n        },\n        {\n            \"r\": 0.05, \"lambda\": 0.2, \"R\": 1.0,\n            \"t\": [1.0, 2.0, 3.0],\n            \"E_old\": [-1, 2, 3],\n            \"E_new\": [4, -1, 1]\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        r = case[\"r\"]\n        lam = case[\"lambda\"]\n        R = case[\"R\"]\n        t_k = np.array(case[\"t\"])\n        E_old_k = np.array(case[\"E_old\"])\n        E_new_k = np.array(case[\"E_new\"])\n\n        # Prepend t_0 = 0 to the time grid for calculating intervals.\n        t_prev_k = np.concatenate(([0], t_k[:-1]))\n\n        # Calculate discount factors D(t_k)\n        D_k = np.exp(-r * t_k)\n\n        # Calculate survival probabilities at t_k-1 and t_k\n        S_prev_k = np.exp(-lam * t_prev_k)\n        S_k = np.exp(-lam * t_k)\n        \n        # Calculate incremental default probabilities Delta_PD_k\n        delta_PD_k = S_prev_k - S_k\n\n        # Calculate the CVA contribution factor, common to both portfolios\n        cva_factor = (1 - R) * D_k * delta_PD_k\n\n        # --- CVA for the old portfolio ---\n        # Calculate positive exposure for the old portfolio\n        positive_E_old_k = np.maximum(E_old_k, 0)\n        # Sum the terms to get CVA_old\n        cva_old = np.sum(cva_factor * positive_E_old_k)\n\n        # --- CVA for the combined portfolio ---\n        # Calculate combined exposure\n        E_comb_k = E_old_k + E_new_k\n        # Calculate positive exposure for the combined portfolio\n        positive_E_comb_k = np.maximum(E_comb_k, 0)\n        # Sum the terms to get CVA_comb\n        cva_comb = np.sum(cva_factor * positive_E_comb_k)\n\n        # --- Incremental CVA ---\n        delta_cva = cva_comb - cva_old\n        results.append(delta_cva)\n\n    # Format the results to exactly six decimal places and print.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"}]}