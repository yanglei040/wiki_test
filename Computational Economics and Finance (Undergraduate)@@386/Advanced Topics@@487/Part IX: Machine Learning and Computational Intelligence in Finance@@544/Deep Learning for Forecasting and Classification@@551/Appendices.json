{"hands_on_practices": [{"introduction": "Before we can train sophisticated models, we must first understand their inner workings. This exercise demystifies the feedforward neural network by guiding you through a manual calculation of its output. By tracing how input data propagates through layers of weights, biases, and activation functions, you will gain a concrete understanding of how a network arrives at a prediction in a practical corporate governance context. [@problem_id:2387288]", "id": "2387288", "problem": "You are given a binary classification task motivated by corporate governance analytics in computational economics and finance. Each sample represents a section of a companyâ€™s code of conduct encoded as a real-valued feature vector that summarizes the normalized frequencies of concept categories per section. The goal is to classify whether a section indicates potential weakness in internal controls.\n\nModel definition:\n- Let the input be a vector $x \\in \\mathbb{R}^{8}$ whose components are the normalized frequencies (unitless, in $[0,1]$) of the following eight concept categories, in order: whistleblower reporting clarity, gift policy strictness, conflict-of-interest controls, audit committee independence, segregation of duties, related-party transaction oversight, waivers or exceptions frequency, vague language frequency.\n- Consider a one-hidden-layer feedforward model with Rectified Linear Unit (ReLU) activation and a logistic output. Define\n$$\nh(x) = \\phi\\!\\left(W_1 x + b_1\\right) \\in \\mathbb{R}^{4}, \\quad \\phi(z)_i = \\max\\{0, z_i\\},\n$$\n$$\nz_2(x) = W_2^\\top h(x) + b_2 \\in \\mathbb{R}, \\quad p(x) = \\sigma\\!\\left(z_2(x)\\right) = \\frac{1}{1 + e^{-z_2(x)}} \\in (0,1).\n$$\nClass prediction is $\\hat{y}(x) = 1$ if $p(x) \\geq 0.5$ and $\\hat{y}(x) = 0$ otherwise.\n- The parameters are fixed and given by\n$$\nW_1 =\n\\begin{bmatrix}\n-0.1 & -0.1 & -0.1 & -0.1 & -0.1 & -0.1 & 0.6 & 0.6 \\\\\n0.4 & 0.4 & 0.3 & 0.3 & 0.3 & 0.3 & -0.2 & -0.2 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.8 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0.8 & 0\n\\end{bmatrix},\n\\quad\nb_1 =\n\\begin{bmatrix}\n-0.1 \\\\ -0.05 \\\\ -0.2 \\\\ -0.2\n\\end{bmatrix},\n$$\n$$\nW_2 =\n\\begin{bmatrix}\n0.8 \\\\ -0.6 \\\\ 0.5 \\\\ 0.5\n\\end{bmatrix},\n\\quad\nb_2 = 0.\n$$\n\nTask:\n- For each test input $x$ in the test suite below, compute $p(x)$ and the class prediction $\\hat{y}(x)$ using the model above. You must output only the class predictions as integers.\n\nTest suite (each $x$ is an element of $\\mathbb{R}^{8}$ with entries in $[0,1]$):\n- $x^{(1)} = [\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.0,\\, 0.0 \\,]$\n- $x^{(2)} = [\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.9,\\, 0.9 \\,]$\n- $x^{(3)} = [\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0 \\,]$\n- $x^{(4)} = [\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5 \\,]$\n- $x^{(5)} = [\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 1.0,\\, 0.0 \\,]$\n\nDesign for coverage:\n- The suite includes a case with strong control signals and no risk signals, a case with weak controls and strong risk signals, a boundary case where the input is the zero vector, a mixed moderate case, and a case with low controls and a single risk factor activated.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with no spaces. For example, if the five predictions are $\\hat{y}^{(1)},\\ldots,\\hat{y}^{(5)} \\in \\{0,1\\}$, print exactly \"[y1,y2,y3,y4,y5]\".", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n\n- **Input**: A feature vector $x \\in \\mathbb{R}^{8}$ with components in $[0,1]$.\n- **Model Architecture**: A one-hidden-layer feedforward network.\n- **Hidden Layer**:\n  $$h(x) = \\phi\\!\\left(W_1 x + b_1\\right) \\in \\mathbb{R}^{4}$$\n  where $\\phi(z)_i = \\max\\{0, z_i\\}$ is the Rectified Linear Unit (ReLU) activation function.\n- **Output Layer**:\n  $$z_2(x) = W_2^\\top h(x) + b_2 \\in \\mathbb{R}$$\n  $$p(x) = \\sigma\\!\\left(z_2(x)\\right) = \\frac{1}{1 + e^{-z_2(x)}} \\in (0,1)$$\n- **Classification Rule**:\n  $$\\hat{y}(x) = 1 \\text{ if } p(x) \\geq 0.5$$\n  $$\\hat{y}(x) = 0 \\text{ if } p(x) < 0.5$$\n- **Parameters**:\n  $$\n  W_1 =\n  \\begin{bmatrix}\n  -0.1 & -0.1 & -0.1 & -0.1 & -0.1 & -0.1 & 0.6 & 0.6 \\\\\n  0.4 & 0.4 & 0.3 & 0.3 & 0.3 & 0.3 & -0.2 & -0.2 \\\\\n  0 & 0 & 0 & 0 & 0 & 0 & 0 & 0.8 \\\\\n  0 & 0 & 0 & 0 & 0 & 0 & 0.8 & 0\n  \\end{bmatrix},\n  \\quad\n  b_1 =\n  \\begin{bmatrix}\n  -0.1 \\\\ -0.05 \\\\ -0.2 \\\\ -0.2\n  \\end{bmatrix}\n  $$\n  $$\n  W_2 =\n  \\begin{bmatrix}\n  0.8 \\\\ -0.6 \\\\ 0.5 \\\\ 0.5\n  \\end{bmatrix},\n  \\quad\n  b_2 = 0\n  $$\n- **Test Suite**:\n  - $x^{(1)} = [\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.0,\\, 0.0 \\,]^\\top$\n  - $x^{(2)} = [\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.9,\\, 0.9 \\,]^\\top$\n  - $x^{(3)} = [\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0 \\,]^\\top$\n  - $x^{(4)} = [\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5 \\,]^\\top$\n  - $x^{(5)} = [\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 1.0,\\, 0.0 \\,]^\\top$\n- **Task**: Compute $\\hat{y}(x)$ for each input vector in the test suite.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is evaluated against the established criteria.\n- **Scientifically Grounded**: The problem describes a standard feedforward neural network, a fundamental model in machine learning and deep learning. The mathematical operations (matrix multiplication, ReLU activation, logistic sigmoid function) are standard and correct. The application context is plausible.\n- **Well-Posed**: The problem is fully specified. All parameters ($W_1, b_1, W_2, b_2$), input vectors ($x^{(i)}$), and functions ($\\phi, \\sigma$) are explicitly defined. The dimensionalities of all matrices and vectors are consistent. For example, $W_1$ is $4 \\times 8$ and $x$ is $8 \\times 1$, yielding a $4 \\times 1$ result, which matches the dimension of $b_1$. A unique, stable solution exists for each test case.\n- **Objective**: The problem is stated in precise, quantitative terms, free of ambiguity or subjective claims.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. It is scientifically sound, well-posed, objective, and contains no contradictions or missing information. A rigorous solution can be derived.\n\n**Solution Derivation**\n\nThe classification rule $\\hat{y}(x) = 1$ if $p(x) \\geq 0.5$ is equivalent to classifying based on the sign of the logit $z_2(x)$. Since the logistic function $\\sigma(z)$ is monotonically increasing and $\\sigma(0) = 0.5$, the condition $p(x) \\geq 0.5$ is equivalent to $z_2(x) \\geq 0$. We will compute $z_2(x)$ for each test case.\n\nThe computational steps are:\n1. Compute the pre-activation vector of the hidden layer: $z_1 = W_1 x + b_1$.\n2. Apply the ReLU activation function component-wise: $h = \\phi(z_1) = \\max\\{0, z_1\\}$.\n3. Compute the logit (pre-activation of the output): $z_2 = W_2^\\top h + b_2$.\n4. Determine the class: $\\hat{y} = 1$ if $z_2 \\geq 0$, and $\\hat{y} = 0$ if $z_2 < 0$.\n\n**Case 1: $x^{(1)} = [\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.9,\\, 0.0,\\, 0.0 \\,]^\\top$**\n$z_1^{(1)} = W_1 x^{(1)} + b_1 = \\begin{bmatrix} -0.1(6 \\times 0.9) - 0.1 \\\\ 0.4(2 \\times 0.9) + 0.3(4 \\times 0.9) - 0.05 \\\\ 0 - 0.2 \\\\ 0 - 0.2 \\end{bmatrix} = \\begin{bmatrix} -0.54 - 0.1 \\\\ 1.8 - 0.05 \\\\ -0.2 \\\\ -0.2 \\end{bmatrix} = \\begin{bmatrix} -0.64 \\\\ 1.75 \\\\ -0.2 \\\\ -0.2 \\end{bmatrix}$\n$h^{(1)} = \\phi(z_1^{(1)}) = [\\, 0, 1.75, 0, 0 \\,]^\\top$\n$z_2^{(1)} = W_2^\\top h^{(1)} + b_2 = 0.8(0) - 0.6(1.75) + 0.5(0) + 0.5(0) + 0 = -1.05$\nSince $z_2^{(1)} = -1.05 < 0$, the prediction is $\\hat{y}^{(1)} = 0$.\n\n**Case 2: $x^{(2)} = [\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.1,\\, 0.9,\\, 0.9 \\,]^\\top$**\n$z_1^{(2)} = W_1 x^{(2)} + b_1 = \\begin{bmatrix} -0.1(6 \\times 0.1) + 0.6(2 \\times 0.9) - 0.1 \\\\ 0.4(2 \\times 0.1) + 0.3(4 \\times 0.1) - 0.2(2 \\times 0.9) - 0.05 \\\\ 0.8(0.9) - 0.2 \\\\ 0.8(0.9) - 0.2 \\end{bmatrix} = \\begin{bmatrix} -0.06 + 1.08 - 0.1 \\\\ 0.2 - 0.36 - 0.05 \\\\ 0.72 - 0.2 \\\\ 0.72 - 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.92 \\\\ -0.21 \\\\ 0.52 \\\\ 0.52 \\end{bmatrix}$\n$h^{(2)} = \\phi(z_1^{(2)}) = [\\, 0.92, 0, 0.52, 0.52 \\,]^\\top$\n$z_2^{(2)} = W_2^\\top h^{(2)} + b_2 = 0.8(0.92) - 0.6(0) + 0.5(0.52) + 0.5(0.52) + 0 = 0.736 + 0.26 + 0.26 = 1.256$\nSince $z_2^{(2)} = 1.256 > 0$, the prediction is $\\hat{y}^{(2)} = 1$.\n\n**Case 3: $x^{(3)} = [\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0,\\, 0.0 \\,]^\\top$**\n$z_1^{(3)} = W_1 x^{(3)} + b_1 = W_1 \\cdot 0 + b_1 = b_1 = [\\, -0.1, -0.05, -0.2, -0.2 \\,]^\\top$\n$h^{(3)} = \\phi(z_1^{(3)}) = [\\, 0, 0, 0, 0 \\,]^\\top$\n$z_2^{(3)} = W_2^\\top h^{(3)} + b_2 = W_2^\\top \\cdot 0 + 0 = 0$\nSince $z_2^{(3)} = 0$, the condition $z_2 \\geq 0$ is satisfied. The prediction is $\\hat{y}^{(3)} = 1$.\n\n**Case 4: $x^{(4)} = [\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5,\\, 0.5 \\,]^\\top$**\n$z_1^{(4)} = W_1 x^{(4)} + b_1 = \\begin{bmatrix} (-0.1 \\times 6 + 0.6 \\times 2) \\times 0.5 - 0.1 \\\\ (0.4 \\times 2 + 0.3 \\times 4 - 0.2 \\times 2) \\times 0.5 - 0.05 \\\\ 0.8 \\times 0.5 - 0.2 \\\\ 0.8 \\times 0.5 - 0.2 \\end{bmatrix} = \\begin{bmatrix} (0.6) \\times 0.5 - 0.1 \\\\ (2.0 - 0.4) \\times 0.5 - 0.05 \\\\ 0.4 - 0.2 \\\\ 0.4 - 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.3 - 0.1 \\\\ 1.6 \\times 0.5 - 0.05 \\\\ 0.2 \\\\ 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.2 \\\\ 0.8 - 0.05 \\\\ 0.2 \\\\ 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.2 \\\\ 0.75 \\\\ 0.2 \\\\ 0.2 \\end{bmatrix}$\n$h^{(4)} = \\phi(z_1^{(4)}) = [\\, 0.2, 0.75, 0.2, 0.2 \\,]^\\top$\n$z_2^{(4)} = W_2^\\top h^{(4)} + b_2 = 0.8(0.2) - 0.6(0.75) + 0.5(0.2) + 0.5(0.2) + 0 = 0.16 - 0.45 + 0.1 + 0.1 = -0.09$\nSince $z_2^{(4)} = -0.09 < 0$, the prediction is $\\hat{y}^{(4)} = 0$.\n\n**Case 5: $x^{(5)} = [\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 0.2,\\, 1.0,\\, 0.0 \\,]^\\top$**\n$z_1^{(5)} = W_1 x^{(5)} + b_1 = \\begin{bmatrix} (-0.1 \\times 6 \\times 0.2) + 0.6(1.0) + 0.6(0) - 0.1 \\\\ (0.4 \\times 2 \\times 0.2 + 0.3 \\times 4 \\times 0.2) - 0.2(1.0) - 0.2(0) - 0.05 \\\\ 0.8(0) - 0.2 \\\\ 0.8(1.0) - 0.2 \\end{bmatrix} = \\begin{bmatrix} -0.12 + 0.6 - 0.1 \\\\ (0.16 + 0.24) - 0.2 - 0.05 \\\\ -0.2 \\\\ 0.8 - 0.2 \\end{bmatrix} = \\begin{bmatrix} 0.38 \\\\ 0.4 - 0.2 - 0.05 \\\\ -0.2 \\\\ 0.6 \\end{bmatrix} = \\begin{bmatrix} 0.38 \\\\ 0.15 \\\\ -0.2 \\\\ 0.6 \\end{bmatrix}$\n$h^{(5)} = \\phi(z_1^{(5)}) = [\\, 0.38, 0.15, 0, 0.6 \\,]^\\top$\n$z_2^{(5)} = W_2^\\top h^{(5)} + b_2 = 0.8(0.38) - 0.6(0.15) + 0.5(0) + 0.5(0.6) + 0 = 0.304 - 0.09 + 0.3 = 0.514$\nSince $z_2^{(5)} = 0.514 > 0$, the prediction is $\\hat{y}^{(5)} = 1$.\n\nThe final list of predictions is $[0, 1, 1, 0, 1]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the class predictions for a given set of input vectors\n    using a predefined one-hidden-layer neural network.\n    \"\"\"\n    \n    # Define the model parameters as numpy arrays.\n    W1 = np.array([\n        [-0.1, -0.1, -0.1, -0.1, -0.1, -0.1, 0.6, 0.6],\n        [0.4, 0.4, 0.3, 0.3, 0.3, 0.3, -0.2, -0.2],\n        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8],\n        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0]\n    ])\n\n    b1 = np.array([-0.1, -0.05, -0.2, -0.2])\n\n    W2 = np.array([0.8, -0.6, 0.5, 0.5])\n    \n    # b2 is given as 0.0\n    b2 = 0.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        np.array([0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.0, 0.0]),\n        np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.9, 0.9]),\n        np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n        np.array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n        np.array([0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 1.0, 0.0]),\n    ]\n\n    results = []\n    for x in test_cases:\n        # Step 1: Calculate the pre-activation of the hidden layer.\n        # W1 is (4, 8), x is (8,). The result z1 is (4,).\n        z1 = W1 @ x + b1\n\n        # Step 2: Apply the ReLU activation function.\n        # np.maximum performs an element-wise maximum.\n        h = np.maximum(0, z1)\n\n        # Step 3: Calculate the pre-activation of the output layer (logit).\n        # W2.T is (4,), h is (4,). The result z2 is a scalar.\n        z2 = W2.T @ h + b2\n\n        # Step 4: Determine the class prediction.\n        # The classification rule is y_hat = 1 if p(x) >= 0.5, which is equivalent\n        # to z2(x) >= 0.\n        y_hat = 1 if z2 >= 0 else 0\n        \n        results.append(y_hat)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "A model's true power lies in its ability to learn parameters from data. This practice moves beyond static models to the heart of the learning process: optimization through gradient descent. You will derive the update rules for a classifier from the ground up and implement them to train a model for a geopolitical-economic forecasting task, providing a foundational understanding of how models minimize a loss function to improve their predictive accuracy. [@problem_id:2387257]", "id": "2387257", "problem": "You are given a simplified, fully specified, listwise classification problem modeling the question: among a finite set of candidate countries at a given time, which one is most likely to be the next to join a particular trade bloc, based solely on numeric indicators of economic and political alignment. Each candidate country is represented by a fixed-length feature vector containing normalized alignment metrics. You will approach this as a probabilistic classification task with a single-layer model that assigns a scalar score to each candidate, converts scores to a probability distribution over the candidate set, and is trained by maximizing the joint likelihood of observed past outcomes.\n\nStart from the following fundamental base: given a set of scores $\\{s_k\\}_{k=1}^{n}$ for $n$ mutually exclusive outcomes, the categorical probability distribution is defined by the normalized exponential mapping (softmax), and parameters are estimated by maximizing the likelihood (equivalently, minimizing the negative log-likelihood). The objective shall include a standard $\\ell_2$ penalty on the parameters. The training algorithm should use gradient-based optimization derived from first principles.\n\nMathematical setup:\n\n- For each training event $t$ with $n_t$ candidate countries, there is a matrix of features $X_t \\in \\mathbb{R}^{n_t \\times d}$ where each row $x_{t,k} \\in \\mathbb{R}^{d}$ represents the $d$-dimensional feature vector for candidate $k$, and an observed index $y_t \\in \\{0,1,\\dots,n_t-1\\}$ indicating which candidate actually joined next in that event.\n- Use a single-layer linear scoring model $s_{t,k} = w^\\top x_{t,k} + b$ with parameters $w \\in \\mathbb{R}^{d}$ and $b \\in \\mathbb{R}$, and define the model-implied probabilities for event $t$ by the softmax mapping over the $n_t$ candidates.\n- The total objective over all training events is the sum of the negative log-likelihood plus an $\\ell_2$ penalty with coefficient $\\lambda > 0$ on $w$ (do not regularize $b$).\n\nYour tasks:\n\n1) From the above base, derive the expressions needed to implement the gradient-based learning rule for the parameters $w$ and $b$, explicitly from the likelihood definition and the chain rule, without shortcuts.\n\n2) Implement a training routine using batch gradient descent with a fixed step size. Use numerically stable computation for the softmax. The training must be deterministic and must not rely on any randomness.\n\n3) After training on the provided training set specified below, evaluate the trained model on the provided test suite (candidate sets not used in training) by computing the index (zero-based) of the candidate with the highest predicted probability in each test case.\n\nData specification:\n\n- Dimension of each feature vector: $d = 5$.\n- Feature semantics and ranges (for interpretation only; the program will treat them as pure numbers): \n  - $x_1$: normalized trade share with the bloc in $[0,1]$,\n  - $x_2$: normalized tariff policy alignment in $[0,1]$,\n  - $x_3$: normalized gross domestic product per capita alignment in $[0,1]$,\n  - $x_4$: normalized democracy and governance similarity in $[0,1]$,\n  - $x_5$: normalized foreign policy voting similarity in $[0,1]$.\n\nTraining events (each event is a matrix of candidates followed by the observed joining index):\n- Event $1$ ($n_1 = 3$):\n  - Candidates:\n    - $[0.60, 0.70, 0.50, 0.60, 0.65]$\n    - $[0.40, 0.50, 0.60, 0.50, 0.45]$\n    - $[0.80, 0.80, 0.70, 0.70, 0.80]$\n  - Observed index $y_1 = 2$.\n- Event $2$ ($n_2 = 2$):\n  - Candidates:\n    - $[0.30, 0.40, 0.50, 0.40, 0.40]$\n    - $[0.70, 0.60, 0.60, 0.80, 0.70]$\n  - Observed index $y_2 = 1$.\n- Event $3$ ($n_3 = 4$):\n  - Candidates:\n    - $[0.20, 0.30, 0.40, 0.40, 0.30]$\n    - $[0.50, 0.60, 0.50, 0.50, 0.60]$\n    - $[0.90, 0.90, 0.90, 0.80, 0.85]$\n    - $[0.70, 0.50, 0.70, 0.60, 0.65]$\n  - Observed index $y_3 = 2$.\n\nHyperparameters:\n- Learning rate $\\eta = 0.10$,\n- Regularization coefficient $\\lambda = 10^{-3}$,\n- Number of full-batch iterations (epochs) $T = 2000$.\n\nTest suite (candidate sets for evaluation; output one integer per test case):\n- Test case $1$ ($n = 3$):\n  - $[0.65, 0.70, 0.55, 0.60, 0.60]$\n  - $[0.50, 0.50, 0.55, 0.45, 0.50]$\n  - $[0.75, 0.80, 0.75, 0.75, 0.82]$\n- Test case $2$ ($n = 2$):\n  - $[0.35, 0.45, 0.55, 0.50, 0.48]$\n  - $[0.60, 0.55, 0.50, 0.70, 0.60]$\n- Test case $3$ ($n = 4$):\n  - $[0.55, 0.60, 0.60, 0.60, 0.60]$\n  - $[0.60, 0.55, 0.55, 0.55, 0.55]$\n  - $[0.65, 0.65, 0.65, 0.65, 0.65]$\n  - $[0.50, 0.50, 0.50, 0.50, 0.50]$\n- Test case $4$ ($n = 3$):\n  - $[0.00, 0.00, 0.00, 0.00, 0.00]$\n  - $[0.20, 0.20, 0.20, 0.20, 0.20]$\n  - $[0.10, 0.10, 0.10, 0.10, 0.10]$\n\nFinal output specification:\n- Your program should train on the provided training events using the specified hyperparameters and then produce a single line of output containing the predicted indices (zero-based) for the four test cases, as a comma-separated list enclosed in square brackets, for example, $[a,b,c,d]$ where each of $a$, $b$, $c$, $d$ is an integer in $\\{0,1,2,3\\}$ depending on the test case size.", "solution": "The problem presented is a well-posed, scientifically grounded classification task that can be addressed using a standard multinomial logistic regression model. The validity is confirmed, and a solution is derived from first principles.\n\nThe central task is to train a linear model with parameters $w \\in \\mathbb{R}^{d}$ and $b \\in \\mathbb{R}$ to predict which candidate from a set is most likely to join a trade bloc. The training is performed by minimizing a regularized negative log-likelihood objective function using batch gradient descent.\n\nLet there be $N$ training events, indexed by $t \\in \\{1, 2, \\dots, N\\}$. For each event $t$, we have a set of $n_t$ candidate countries, with their features represented by a matrix $X_t \\in \\mathbb{R}^{n_t \\times d}$. Each row $x_{t,k} \\in \\mathbb{R}^{d}$ is the feature vector for candidate $k \\in \\{0, 1, \\dots, n_t-1\\}$. The observed outcome is the index $y_t$ of the country that joined.\n\nThe score for candidate $k$ in event $t$ is given by a linear function:\n$$s_{t,k} = w^\\top x_{t,k} + b$$\n\nThe probability of candidate $k$ being the chosen one is modeled by the softmax function, which normalizes the scores into a probability distribution over the $n_t$ candidates:\n$$P_{t,k} \\equiv P(y=k | X_t, w, b) = \\frac{\\exp(s_{t,k})}{\\sum_{j=0}^{n_t-1} \\exp(s_{t,j})}$$\n\nThe objective is to find parameters $w$ and $b$ by maximizing the joint likelihood of observing the training data $\\{y_t\\}_{t=1}^N$. This is equivalent to minimizing the total negative log-likelihood, $L_{NLL}$. We add an $\\ell_2$ regularization term for the weight vector $w$ to prevent overfitting. The total objective function, $L(w,b)$, is:\n$$L(w, b) = L_{NLL} + L_{REG} = \\left( \\sum_{t=1}^{N} L_t(w, b) \\right) + \\frac{\\lambda}{2} \\|w\\|^2_2$$\nwhere $\\lambda > 0$ is the regularization coefficient and $L_t$ is the negative log-likelihood for a single event $t$:\n$$L_t(w,b) = -\\log(P_{t, y_t})$$\nSubstituting the expressions for the score and probability, we can write $L_t$ as:\n$$L_t = -\\log\\left(\\frac{\\exp(s_{t,y_t})}{\\sum_{j=0}^{n_t-1} \\exp(s_{t,j})}\\right) = -s_{t,y_t} + \\log\\left(\\sum_{j=0}^{n_t-1} \\exp(s_{t,j})\\right)$$\n\nTo train the model using gradient descent, we must compute the partial derivatives of the total objective function $L$ with respect to the parameters $w$ and $b$. The gradient update rule for a parameter $\\theta$ is $\\theta \\leftarrow \\theta - \\eta \\nabla_{\\theta} L$, where $\\eta$ is the learning rate.\n\nFirst, we derive the gradient with respect to the weight vector $w$. The gradient of the regularization term is straightforward:\n$$\\frac{\\partial}{\\partial w} \\left(\\frac{\\lambda}{2} w^\\top w\\right) = \\lambda w$$\nThe gradient of the negative log-likelihood is the sum of gradients for each event: $\\frac{\\partial L_{NLL}}{\\partial w} = \\sum_{t=1}^N \\frac{\\partial L_t}{\\partial w}$. Let's find the gradient for a single event $t$ using the chain rule. For the $i$-th component of $w$, denoted $w_i$:\n$$\\frac{\\partial L_t}{\\partial w_i} = \\sum_{k=0}^{n_t-1} \\frac{\\partial L_t}{\\partial s_{t,k}} \\frac{\\partial s_{t,k}}{\\partial w_i}$$\nThe derivative of the score $s_{t,k}$ with respect to $w_i$ is:\n$$\\frac{\\partial s_{t,k}}{\\partial w_i} = \\frac{\\partial}{\\partial w_i} \\left(\\sum_{l=1}^{d} w_l (x_{t,k})_l + b\\right) = (x_{t,k})_i$$\nThe derivative of the loss $L_t$ with respect to a score $s_{t,k}$ is:\n$$\\frac{\\partial L_t}{\\partial s_{t,k}} = \\frac{\\partial}{\\partial s_{t,k}} \\left(-s_{t,y_t} + \\log\\left(\\sum_{j=0}^{n_t-1} \\exp(s_{t,j})\\right)\\right) = -\\delta_{k, y_t} + \\frac{\\exp(s_{t,k})}{\\sum_{j=0}^{n_t-1} \\exp(s_{t,j})} = P_{t,k} - \\delta_{k, y_t}$$\nwhere $\\delta_{k, y_t}$ is the Kronecker delta, which is $1$ if $k=y_t$ and $0$ otherwise.\n\nCombining these parts, the gradient of $L_t$ with respect to $w_i$ is:\n$$\\frac{\\partial L_t}{\\partial w_i} = \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t}) (x_{t,k})_i$$\nIn vector form, the gradient for event $t$ is:\n$$\\frac{\\partial L_t}{\\partial w} = \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t}) x_{t,k} = X_t^\\top (p_t - e_{y_t})$$\nwhere $p_t$ is the vector of probabilities $\\{P_{t,k}\\}_{k=0}^{n_t-1}$ and $e_{y_t}$ is the one-hot encoded vector for the true label $y_t$.\n\nThe total gradient for $w$ is the sum over all training events plus the regularization gradient:\n$$\\nabla_w L(w,b) = \\left( \\sum_{t=1}^{N} \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t}) x_{t,k} \\right) + \\lambda w$$\n\nNext, we derive the gradient with respect to the bias term $b$. The regularization term does not depend on $b$. We use the chain rule again:\n$$\\frac{\\partial L_t}{\\partial b} = \\sum_{k=0}^{n_t-1} \\frac{\\partial L_t}{\\partial s_{t,k}} \\frac{\\partial s_{t,k}}{\\partial b}$$\nThe derivative of the score with respect to $b$ is simply:\n$$\\frac{\\partial s_{t,k}}{\\partial b} = \\frac{\\partial}{\\partial b} (w^\\top x_{t,k} + b) = 1$$\nThus, the gradient of $L_t$ with respect to $b$ is:\n$$\\frac{\\partial L_t}{\\partial b} = \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t}) (1) = \\sum_{k=0}^{n_t-1} P_{t,k} - \\sum_{k=0}^{n_t-1} \\delta_{k, y_t} = 1 - 1 = 0$$\nThis is incorrect. The sum is over the error term. $\\sum_{k=0}^{n_t-1} P_{t,k} - \\sum_{k=0}^{n_t-1} \\delta_{k, y_t} = 1 - 1 = 0$. Let me re-verify. Ah, my derivation of $\\frac{\\partial L_t}{\\partial b}$ is correct, the sum of errors $(P_{t,k}-\\delta_{k,y_t})$ is indeed what's used. The reasoning $\\sum P_{t,k} - \\sum \\delta_{k,y_t} = 1-1=0$ is correct in its arithmetic but the terms are used inside a sum over $t$ for the total gradient. The gradient for a single event is the sum of the differences between predicted probabilities and target probabilities.\nLet's restate.\n$$\\frac{\\partial L_t}{\\partial b} = \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t})$$\nThe total gradient for $b$ over all events is:\n$$\\nabla_b L(w,b) = \\sum_{t=1}^{N} \\frac{\\partial L_t}{\\partial b} = \\sum_{t=1}^{N} \\sum_{k=0}^{n_t-1} (P_{t,k} - \\delta_{k, y_t})$$\nThis term is not guaranteed to be zero during training, only at a perfect optimum.\n\nThe batch gradient descent algorithm initializes parameters $w$ and $b$ (e.g., to zero) and iteratively updates them for $T$ epochs:\n$$w^{(i+1)} = w^{(i)} - \\eta \\nabla_w L(w^{(i)}, b^{(i)})$$\n$$b^{(i+1)} = b^{(i)} - \\eta \\nabla_b L(w^{(i)}, b^{(i)})$$\nFor numerical stability, the softmax function is computed by shifting the scores: $s_k \\to s_k - \\max_j(s_j)$. This prevents overflow when exponentiating large scores while leaving the resulting probabilities unchanged.\n\nAfter $T=2000$ iterations with learning rate $\\eta=0.10$ and regularization $\\lambda=10^{-3}$, the final parameters $(w,b)$ are used to make predictions on the test cases. For each test case, we compute the scores for all candidates and select the index of the candidate with the maximum score.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the listwise classification problem using batch gradient descent.\n    \"\"\"\n    # 1. Define problem data and hyperparameters\n    d = 5\n    eta = 0.10\n    lambda_reg = 1e-3\n    T = 2000\n\n    train_events = [\n        (np.array([\n            [0.60, 0.70, 0.50, 0.60, 0.65],\n            [0.40, 0.50, 0.60, 0.50, 0.45],\n            [0.80, 0.80, 0.70, 0.70, 0.80]\n        ]), 2),\n        (np.array([\n            [0.30, 0.40, 0.50, 0.40, 0.40],\n            [0.70, 0.60, 0.60, 0.80, 0.70]\n        ]), 1),\n        (np.array([\n            [0.20, 0.30, 0.40, 0.40, 0.30],\n            [0.50, 0.60, 0.50, 0.50, 0.60],\n            [0.90, 0.90, 0.90, 0.80, 0.85],\n            [0.70, 0.50, 0.70, 0.60, 0.65]\n        ]), 2)\n    ]\n\n    test_cases = [\n        np.array([\n            [0.65, 0.70, 0.55, 0.60, 0.60],\n            [0.50, 0.50, 0.55, 0.45, 0.50],\n            [0.75, 0.80, 0.75, 0.75, 0.82]\n        ]),\n        np.array([\n            [0.35, 0.45, 0.55, 0.50, 0.48],\n            [0.60, 0.55, 0.50, 0.70, 0.60]\n        ]),\n        np.array([\n            [0.55, 0.60, 0.60, 0.60, 0.60],\n            [0.60, 0.55, 0.55, 0.55, 0.55],\n            [0.65, 0.65, 0.65, 0.65, 0.65],\n            [0.50, 0.50, 0.50, 0.50, 0.50]\n        ]),\n        np.array([\n            [0.00, 0.00, 0.00, 0.00, 0.00],\n            [0.20, 0.20, 0.20, 0.20, 0.20],\n            [0.10, 0.10, 0.10, 0.10, 0.10]\n        ])\n    ]\n\n    # 2. Initialize model parameters\n    w = np.zeros(d)\n    b = 0.0\n\n    # 3. Training with Batch Gradient Descent\n    for _ in range(T):\n        grad_w_total = np.zeros(d)\n        grad_b_total = 0.0\n\n        # Loop over all training events to compute the full batch gradient\n        for X_t, y_t in train_events:\n            n_t = X_t.shape[0]\n\n            # Calculate scores: s = Xw + b\n            scores = X_t @ w + b\n            \n            # Numerically stable softmax to compute probabilities\n            scores_stable = scores - np.max(scores)\n            exp_scores = np.exp(scores_stable)\n            probs = exp_scores / np.sum(exp_scores)\n\n            # Create one-hot encoded target vector\n            target = np.zeros(n_t)\n            target[y_t] = 1.0\n            \n            # Calculate the error term (p - y_onehot)\n            error = probs - target\n            \n            # Calculate gradient contribution from this event\n            grad_w_t = X_t.T @ error\n            grad_b_t = np.sum(error)\n            \n            # Accumulate gradients for the batch\n            grad_w_total += grad_w_t\n            grad_b_total += grad_b_t\n            \n        # Add regularization gradient for w (L2 penalty)\n        grad_w_total += lambda_reg * w\n        \n        # Update parameters using the batch gradient\n        w -= eta * grad_w_total\n        b -= eta * grad_b_total\n\n    # 4. Evaluation on test suite\n    results = []\n    for X_test in test_cases:\n        # Calculate scores for the test case\n        scores = X_test @ w + b\n        # Prediction is the index of the highest score\n        predicted_index = np.argmax(scores)\n        results.append(predicted_index)\n\n    # 5. Print the final results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "We now apply our skills to a cornerstone of computational finance: time series forecasting. This practice introduces the Long Short-Term Memory (LSTM) network, an architecture specifically designed to capture patterns in sequential data. You will build an LSTM to forecast financial volatility, a notoriously challenging task, and benchmark its performance against a classic econometric model, the GARCH, offering a direct comparison of traditional and deep learning approaches. [@problem_id:2387303]", "id": "2387303", "problem": "You must write a complete, runnable program that, for a specified synthetic data-generating process, compares a Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model to a Long Short-Term Memory (LSTM) model for one-step-ahead forecasting of daily Bitcoin volatility. Formally, volatility is proxied by next-day squared return. Your program must generate the data, fit both models using only the training portion, produce out-of-sample forecasts on a fixed test portion, evaluate mean squared error, and decide which model performs better for each test case.\n\nThe data-generating process follows these steps. For each test case, there is a sentiment process $\\{s_t\\}$ and a return process $\\{r_t\\}$. Sentiment evolves as an autoregressive process of order one:\n$$ s_t = \\phi s_{t-1} + \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0,\\sigma_\\epsilon^2), \\quad s_0 = 0. $$\nThe conditional variance process is\n$$ h_t = \\omega + \\alpha r_{t-1}^2 + \\beta h_{t-1} + \\gamma \\cdot \\max(s_{t-1},0)^2, $$\nwith the convention $r_{-1}=0$ and $s_{-1}=0$. Returns follow a conditionally Gaussian model\n$$ r_t = \\sqrt{h_t}\\, z_t, \\quad z_t \\sim \\mathcal{N}(0,1). $$\nAll randomness must be produced by a fixed seed specified for each test case. You must generate a sequence of length $N$, split it into a training prefix of length $N_{\\text{train}}$ and a test suffix of length $N_{\\text{test}} = N - N_{\\text{train}}$, and form $N_{\\text{test}}$ one-step-ahead forecast targets $\\{y_{t+1}\\}_{t=t_0}^{t_1}$ with $y_{t+1}=r_{t+1}^2$, where the forecast origin $t$ ranges over the last $N_{\\text{test}}$ in-sample times.\n\nYou must implement and compare the following models:\n\n1) The Generalized Autoregressive Conditional Heteroskedasticity (GARCH) baseline: The GARCH$(1,1)$ conditional variance model is\n$$ h_t = \\omega + \\alpha r_{t-1}^2 + \\beta h_{t-1}, $$\nwith $\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, and $\\alpha+\\beta < 1$. Fit $(\\omega,\\alpha,\\beta)$ by maximum likelihood under the Gaussian quasi-likelihood assumption on the training data, using the recursion to compute $\\{h_t\\}$. Use the fitted parameters to compute one-step-ahead variance forecasts for the test period as\n$$ \\widehat{y}^{\\text{GARCH}}_{t+1} = \\widehat{\\omega} + \\widehat{\\alpha} r_t^2 + \\widehat{\\beta} \\widehat{h}_t, $$\nwhere $\\widehat{h}_t$ is the filtered conditional variance at time $t$. Evaluate the mean squared error on the test targets,\n$$ \\text{MSE}_{\\text{GARCH}} = \\frac{1}{N_{\\text{test}}} \\sum_{t=t_0}^{t_1} \\left(\\widehat{y}^{\\text{GARCH}}_{t+1} - y_{t+1}\\right)^2. $$\n\n2) The Long Short-Term Memory (LSTM) forecast with sentiment: The Long Short-Term Memory (LSTM) is a recurrent neural network cell defined by the following equations at time $t$ for hidden state dimension $H$ and input feature vector $x_t \\in \\mathbb{R}^d$:\n$$ i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i), $$\n$$ f_t = \\sigma(W_f x_t + U_f h_{t-1} + b_f), $$\n$$ o_t = \\sigma(W_o x_t + U_o h_{t-1} + b_o), $$\n$$ g_t = \\tanh(W_g x_t + U_g h_{t-1} + b_g), $$\n$$ c_t = f_t \\odot c_{t-1} + i_t \\odot g_t, \\quad h_t = o_t \\odot \\tanh(c_t), $$\nwhere $\\sigma(u)=1/(1+e^{-u})$ is the logistic sigmoid, $\\odot$ denotes elementwise multiplication, $W_{\\cdot} \\in \\mathbb{R}^{H\\times d}$, $U_{\\cdot} \\in \\mathbb{R}^{H\\times H}$, and $b_{\\cdot} \\in \\mathbb{R}^H$. Use a fixed-length history window of size $W$ with input $x_t = [r_t, s_t]^\\top \\in \\mathbb{R}^2$ and initial states $h_{t-W}=0$, $c_{t-W}=0$. After processing the window ending at time $t$, produce a nonnegative scalar forecast via\n$$ \\widehat{y}^{\\text{LSTM}}_{t+1} = \\log\\left(1 + \\exp\\left(v^\\top h_t + b_y\\right)\\right), $$\nwith $v \\in \\mathbb{R}^H$ and $b_y \\in \\mathbb{R}$. Fit the parameters $\\{W_{\\cdot},U_{\\cdot},b_{\\cdot},v,b_y\\}$ by minimizing the mean squared error over the training windows,\n$$ \\min \\ \\frac{1}{N_{\\text{train}}-W} \\sum_{t=W-1}^{N_{\\text{train}}-2} \\left(\\widehat{y}^{\\text{LSTM}}_{t+1} - r_{t+1}^2\\right)^2. $$\nThen compute the one-step-ahead forecasts on the test period using the same windowing and evaluate\n$$ \\text{MSE}_{\\text{LSTM}} = \\frac{1}{N_{\\text{test}}} \\sum_{t=t_0}^{t_1} \\left(\\widehat{y}^{\\text{LSTM}}_{t+1} - y_{t+1}\\right)^2. $$\n\nYour program must implement the following fixed test suite of three cases, generate data according to the formulas above, and use the specified seeds for all randomness:\n\n- Case A (predictive sentiment): $N=220$, $N_{\\text{train}}=170$, $\\phi=0.8$, $\\sigma_\\epsilon=0.5$, $\\omega=2.5\\times 10^{-5}$, $\\alpha=0.08$, $\\beta=0.86$, $\\gamma=1.5\\times 10^{-4}$, seed $=12345$, window length $W=10$, hidden state dimension $H=6$, input dimension $d=2$.\n- Case B (no sentiment effect, persistent volatility): $N=220$, $N_{\\text{train}}=170$, $\\phi=0.8$, $\\sigma_\\epsilon=0.5$, $\\omega=8\\times 10^{-6}$, $\\alpha=0.08$, $\\beta=0.90$, $\\gamma=0$, seed $=54321$, window length $W=10$, hidden state dimension $H=6$, input dimension $d=2$.\n- Case C (nearly constant volatility): $N=220$, $N_{\\text{train}}=170$, $\\phi=0.8$, $\\sigma_\\epsilon=0.5$, $\\omega=4\\times 10^{-4}$, $\\alpha=0$, $\\beta=0$, $\\gamma=0$, seed $=202311$, window length $W=10$, hidden state dimension $H=6$, input dimension $d=2$.\n\nYour program must produce one decision per case: output the integer $1$ if $\\text{MSE}_{\\text{LSTM}} < \\text{MSE}_{\\text{GARCH}}$ for that case, and $0$ otherwise. Aggregate the three decisions into a single line of output containing a comma-separated list enclosed in square brackets, in the fixed order of cases A, B, C. For example, an output could be\n$$ [1,0,1]. $$\n\nNo physical units are involved. Angles are not used. If you choose to compute intermediate percentages, do not print them; only print the required integers. The final printed line must exactly match the specified format.", "solution": "The problem requires a comparative analysis of a Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model and a Long Short-Term Memory (LSTM) network for one-step-ahead volatility forecasting on synthetically generated data. Volatility is proxied by the squared return, $r_{t+1}^2$. The analysis must be conducted for three specified test cases. My task is to implement the full procedure: data generation, model fitting, forecasting, and evaluation, and to determine which model performs better in each case based on the Mean Squared Error (MSE) criterion.\n\nWe begin by formalizing the data-generating process (DGP). The DGP consists of two interconnected stochastic processes: a sentiment process $\\{s_t\\}$ and a return process $\\{r_t\\}$.\n\nThe sentiment $s_t$ follows an autoregressive process of order one, AR($1$):\n$$ s_t = \\phi s_{t-1} + \\epsilon_t, \\quad \\text{with } s_0 = 0 $$\nwhere the innovations $\\epsilon_t$ are independent and identically distributed (i.i.d.) from a normal distribution $\\mathcal{N}(0, \\sigma_\\epsilon^2)$.\n\nThe return series $\\{r_t\\}$ is generated with a time-varying conditional variance $h_t$. This variance process is a GARCH($1,1$) model augmented with a term for the positive sentiment, $s_{t-1}$:\n$$ h_t = \\omega + \\alpha r_{t-1}^2 + \\beta h_{t-1} + \\gamma \\cdot \\max(s_{t-1}, 0)^2 $$\nThe process is initialized with the conventions $r_{-1}=0$ and $s_{-1}=0$. Assuming $h_{-1}=0$, the initial variance is $h_0 = \\omega$. The returns are then drawn from a conditional Gaussian distribution:\n$$ r_t = \\sqrt{h_t} z_t, \\quad \\text{where } z_t \\sim \\mathcal{N}(0, 1) \\text{ i.i.d.} $$\nFor each test case, a data series of length $N$ is generated, then split into a training set of size $N_{\\text{train}}$ and a test set of size $N_{\\text{test}} = N - N_{\\text{train}}$.\n\nThe first model is the standard GARCH($1,1$) model. It specifies the conditional variance as:\n$$ h_t = \\omega + \\alpha r_{t-1}^2 + \\beta h_{t-1} $$\nThe parameters $(\\omega, \\alpha, \\beta)$ are estimated by maximizing the Gaussian quasi-log-likelihood function on the training data $\\{r_t\\}_{t=0}^{N_{\\text{train}}-1}$. The log-likelihood function to be maximized is:\n$$ \\mathcal{L}(\\omega, \\alpha, \\beta) = \\sum_{t=1}^{N_{\\text{train}}-1} \\left( -\\frac{1}{2}\\log(2\\pi) - \\frac{1}{2}\\log(h_t) - \\frac{r_t^2}{2h_t} \\right) $$\nThe recursion for $h_t$ is initialized by setting $h_0$ to the sample variance of the training returns. The parameters must satisfy the constraints $\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, and $\\alpha+\\beta < 1$. We use a Sequential Least Squares Programming (SLSQP) algorithm for this constrained optimization task. Once the parameters $(\\widehat{\\omega}, \\widehat{\\alpha}, \\widehat{\\beta})$ are estimated, one-step-ahead forecasts are generated for the test period. The forecast for time $t+1$, made at time $t$, is the conditional variance:\n$$ \\widehat{y}^{\\text{GARCH}}_{t+1} = \\widehat{h}_{t+1} = \\widehat{\\omega} + \\widehat{\\alpha} r_t^2 + \\widehat{\\beta} \\widehat{h}_t $$\nwhere $\\widehat{h}_t$ is the filtered variance at time $t$ computed using the estimated parameters.\n\nThe second model is a Long Short-Term Memory (LSTM) network. The LSTM cell updates its cell state $c_t$ and hidden state $h_t$ based on the current input $x_t$ and previous states $(c_{t-1}, h_{t-1})$. The input vector is $x_t = [r_t, s_t]^\\top \\in \\mathbb{R}^2$. The LSTM equations are:\n\\begin{align*}\ni_t &= \\sigma(W_i x_t + U_i h_{t-1} + b_i) & \\text{(Input gate)} \\\\\nf_t &= \\sigma(W_f x_t + U_f h_{t-1} + b_f) & \\text{(Forget gate)} \\\\\no_t &= \\sigma(W_o x_t + U_o h_{t-1} + b_o) & \\text{(Output gate)} \\\\\ng_t &= \\tanh(W_g x_t + U_g h_{t-1} + b_g) & \\text{(Cell input)} \\\\\nc_t &= f_t \\odot c_{t-1} + i_t \\odot g_t & \\text{(Cell state)} \\\\\nh_t &= o_t \\odot \\tanh(c_t) & \\text{(Hidden state)}\n\\end{align*}\nwhere $\\sigma$ is the sigmoid function, $\\tanh$ is the hyperbolic tangent, and $\\odot$ is elementwise multiplication. The model processes a fixed-size window of $W$ past observations. The final hidden state $h_t$ from the window is passed through an output layer to produce a non-negative forecast:\n$$ \\widehat{y}^{\\text{LSTM}}_{t+1} = \\log\\left(1 + \\exp\\left(v^\\top h_t + b_y\\right)\\right) $$\nThis function is known as the softplus function. The full set of LSTM parameters $\\theta = \\{W_{\\cdot}, U_{\\cdot}, b_{\\cdot}, v, b_y\\}$ is fitted by minimizing the Mean Squared Error on the training data:\n$$ \\text{MSE}_{\\text{train}} = \\frac{1}{N_{\\text{train}}-W} \\sum_{t=W-1}^{N_{\\text{train}}-2} \\left(\\widehat{y}^{\\text{LSTM}}_{t+1} - r_{t+1}^2\\right)^2 $$\nThis non-convex optimization problem is solved using a gradient-based method (L-BFGS-B). The required gradients are computed analytically using the backpropagation through time (BPTT) algorithm. Parameter initialization is performed using Glorot uniform initialization to aid convergence.\n\nFor both models, after fitting on the training data, performance is evaluated on the test set. The test period involves making $N_{\\text{test}}$ one-step-ahead forecasts. The forecast origins are $t = N_{\\text{train}}-1, \\ldots, N-2$, and the corresponding targets are $y_{t+1} = r_{t+1}^2$. The Mean Squared Error is computed for each model:\n$$ \\text{MSE} = \\frac{1}{N_{\\text{test}}} \\sum_{t=N_{\\text{train}}-1}^{N-2} \\left(\\widehat{y}_{t+1} - r_{t+1}^2\\right)^2 $$\nThe final decision for each test case is determined by comparing the two MSE values. A value of $1$ is assigned if $\\text{MSE}_{\\text{LSTM}} < \\text{MSE}_{\\text{GARCH}}$, and $0$ otherwise. This procedure is repeated for all three specified cases.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\nclass LSTMModel:\n    \"\"\"\n    Implementation of a single-layer LSTM for time series forecasting.\n    \"\"\"\n    def __init__(self, d, H, W, random_seed):\n        self.d = d  # Input dimension\n        self.H = H  # Hidden dimension\n        self.W = W  # Window size\n        self.rng = np.random.default_rng(random_seed)\n        \n        # Initialize parameters\n        self.params = self._initialize_params()\n\n    def _initialize_params(self):\n        # Glorot initialization\n        limit_w = np.sqrt(6 / (self.d + self.H))\n        limit_u = np.sqrt(6 / (self.H + self.H))\n        limit_v = np.sqrt(6 / (self.H + 1))\n\n        params = {\n            'W_i': self.rng.uniform(-limit_w, limit_w, (self.H, self.d)),\n            'U_i': self.rng.uniform(-limit_u, limit_u, (self.H, self.H)),\n            'b_i': np.zeros(self.H),\n            'W_f': self.rng.uniform(-limit_w, limit_w, (self.H, self.d)),\n            'U_f': self.rng.uniform(-limit_u, limit_u, (self.H, self.H)),\n            'b_f': np.zeros(self.H),\n            'W_o': self.rng.uniform(-limit_w, limit_w, (self.H, self.d)),\n            'U_o': self.rng.uniform(-limit_u, limit_u, (self.H, self.H)),\n            'b_o': np.zeros(self.H),\n            'W_g': self.rng.uniform(-limit_w, limit_w, (self.H, self.d)),\n            'U_g': self.rng.uniform(-limit_u, limit_u, (self.H, self.H)),\n            'b_g': np.zeros(self.H),\n            'v': self.rng.uniform(-limit_v, limit_v, self.H),\n            'b_y': np.zeros(1)\n        }\n        return params\n\n    def _unravel_params(self, param_vec):\n        p = self.params\n        d, H = self.d, self.H\n        s = 0\n        p['W_i'] = param_vec[s:s+H*d].reshape(H, d); s += H*d\n        p['U_i'] = param_vec[s:s+H*H].reshape(H, H); s += H*H\n        p['b_i'] = param_vec[s:s+H]; s += H\n        p['W_f'] = param_vec[s:s+H*d].reshape(H, d); s += H*d\n        p['U_f'] = param_vec[s:s+H*H].reshape(H, H); s += H*H\n        p['b_f'] = param_vec[s:s+H]; s += H\n        p['W_o'] = param_vec[s:s+H*d].reshape(H, d); s += H*d\n        p['U_o'] = param_vec[s:s+H*H].reshape(H, H); s += H*H\n        p['b_o'] = param_vec[s:s+H]; s += H\n        p['W_g'] = param_vec[s:s+H*d].reshape(H, d); s += H*d\n        p['U_g'] = param_vec[s:s+H*H].reshape(H, H); s += H*H\n        p['b_g'] = param_vec[s:s+H]; s += H\n        p['v'] = param_vec[s:s+H]; s += H\n        p['b_y'] = param_vec[s:s+1]; s += 1\n        return p\n\n    def _ravel_params(self):\n        return np.concatenate([p.ravel() for p in self.params.values()])\n\n    def _forward(self, x_window):\n        p = self.params\n        H = self.H\n        \n        # Cache for BPTT\n        cache = {\n            'h_states': { -1: np.zeros(H) },\n            'c_states': { -1: np.zeros(H) },\n            'gates': {},\n            'inputs': x_window,\n        }\n        \n        for t in range(self.W):\n            x_t = x_window[t]\n            h_prev = cache['h_states'][t - 1]\n            c_prev = cache['c_states'][t - 1]\n\n            i_t = self._sigmoid(p['W_i'] @ x_t + p['U_i'] @ h_prev + p['b_i'])\n            f_t = self._sigmoid(p['W_f'] @ x_t + p['U_f'] @ h_prev + p['b_f'])\n            o_t = self._sigmoid(p['W_o'] @ x_t + p['U_o'] @ h_prev + p['b_o'])\n            g_t = np.tanh(p['W_g'] @ x_t + p['U_g'] @ h_prev + p['b_g'])\n            \n            c_t = f_t * c_prev + i_t * g_t\n            h_t = o_t * np.tanh(c_t)\n\n            cache['h_states'][t] = h_t\n            cache['c_states'][t] = c_t\n            cache['gates'][t] = {'i': i_t, 'f': f_t, 'o': o_t, 'g': g_t, 'tanh_c': np.tanh(c_t)}\n\n        h_final = cache['h_states'][self.W - 1]\n        out_arg = p['v'] @ h_final + p['b_y']\n        y_hat = self._softplus(out_arg)\n        cache['out_arg'] = out_arg\n        \n        return y_hat, cache\n\n    def _objective_and_grad(self, param_vec, X_train, Y_train):\n        self.params = self._unravel_params(param_vec)\n        p = self.params\n        d, H = self.d, self.H\n        num_windows = len(X_train)\n        \n        total_mse = 0\n        \n        grad = {k: np.zeros_like(v) for k, v in self.params.items()}\n\n        for i in range(num_windows):\n            x_window, y_true = X_train[i], Y_train[i]\n            y_hat, cache = self._forward(x_window)\n            \n            total_mse += (y_hat - y_true)**2\n            \n            # BPTT\n            dL_dy = 2 * (y_hat - y_true)\n            \n            # Gradient of output layer\n            dL_da = dL_dy * self._sigmoid(cache['out_arg'])\n            grad['v'] += dL_da * cache['h_states'][self.W - 1]\n            grad['b_y'] += dL_da\n            \n            # Backpropagate to final hidden state\n            dh_next = dL_da * p['v']\n            dc_next = np.zeros(H)\n            \n            # Loop backwards through time\n            for t in reversed(range(self.W)):\n                h_t = cache['h_states'][t]\n                c_t = cache['c_states'][t]\n                c_prev = cache['c_states'][t-1]\n                h_prev = cache['h_states'][t-1]\n                x_t = cache['inputs'][t]\n                gates = cache['gates'][t]\n\n                dh = dh_next\n                dc = dc_next + dh * gates['o'] * (1 - gates['tanh_c']**2)\n                \n                # Gradients of gates from cell state\n                di = dc * gates['g']\n                df = dc * c_prev\n                do = dh * gates['tanh_c']\n                dg = dc * gates['i']\n\n                # Gradients of gate pre-activations\n                da_i = di * gates['i'] * (1 - gates['i'])\n                da_f = df * gates['f'] * (1 - gates['f'])\n                da_o = do * gates['o'] * (1 - gates['o'])\n                da_g = dg * (1 - gates['g']**2)\n\n                # Parameter gradients\n                grad['W_i'] += np.outer(da_i, x_t)\n                grad['W_f'] += np.outer(da_f, x_t)\n                grad['W_o'] += np.outer(da_o, x_t)\n                grad['W_g'] += np.outer(da_g, x_t)\n\n                grad['U_i'] += np.outer(da_i, h_prev)\n                grad['U_f'] += np.outer(da_f, h_prev)\n                grad['U_o'] += np.outer(da_o, h_prev)\n                grad['U_g'] += np.outer(da_g, h_prev)\n\n                grad['b_i'] += da_i\n                grad['b_f'] += da_f\n                grad['b_o'] += da_o\n                grad['b_g'] += da_g\n                \n                # Gradients for previous states\n                dh_next = p['U_i'].T @ da_i + p['U_f'].T @ da_f + p['U_o'].T @ da_o + p['U_g'].T @ da_g\n                dc_next = dc * gates['f']\n            \n        avg_mse = total_mse / num_windows\n        avg_grad_vec = np.concatenate([v.ravel() for v in grad.values()]) / num_windows\n\n        return avg_mse, avg_grad_vec\n\n    def fit(self, all_r, all_s):\n        W = self.W\n        N_train = len(all_r)\n        \n        # Create training windows and targets\n        X_train = np.array([np.stack((all_r[i:i+W], all_s[i:i+W]), axis=1) for i in range(N_train - W)])\n        Y_train = all_r[W:N_train]**2\n\n        objective_fn = lambda p: self._objective_and_grad(p, X_train, Y_train)[0]\n        grad_fn = lambda p: self._objective_and_grad(p, X_train, Y_train)[1]\n\n        res = minimize(\n            objective_fn,\n            self._ravel_params(),\n            method='L-BFGS-B',\n            jac=grad_fn,\n            options={'maxiter': 100}\n        )\n        self.params = self._unravel_params(res.x)\n\n    def predict_mse(self, all_r, all_s, N_train):\n        W = self.W\n        N = len(all_r)\n        \n        mse = 0\n        forecasts = []\n        targets = []\n        for t in range(N_train - 1, N - 1):\n            x_window = np.stack((all_r[t-W+1:t+1], all_s[t-W+1:t+1]), axis=1)\n            y_hat, _ = self._forward(x_window)\n            y_true = all_r[t+1]**2\n            mse += (y_hat - y_true)**2\n            forecasts.append(y_hat)\n            targets.append(y_true)\n            \n        return mse / len(targets)\n    \n    @staticmethod\n    def _sigmoid(x): return 1 / (1 + np.exp(-x))\n    @staticmethod\n    def _softplus(x): return np.log(1 + np.exp(x))\n\n\ndef generate_data(N, params, seed):\n    rng = np.random.default_rng(seed)\n    phi, sigma_eps, omega, alpha, beta, gamma = params\n    \n    epsilons = rng.normal(0, sigma_eps, size=N)\n    zs = rng.normal(0, 1, size=N)\n    \n    s = np.zeros(N)\n    h = np.zeros(N)\n    r = np.zeros(N)\n    \n    s[0] = 0\n    h[0] = omega\n    r[0] = np.sqrt(h[0]) * zs[0]\n    \n    for t in range(1, N):\n        s[t] = phi * s[t-1] + epsilons[t]\n        h[t] = omega + alpha * r[t-1]**2 + beta * h[t-1] + gamma * max(s[t-1], 0)**2\n        h[t] = max(h[t], 1e-9) # Ensure positivity\n        r[t] = np.sqrt(h[t]) * zs[t]\n        \n    return r, s\n\ndef garch_loglike(params, r_train):\n    omega, alpha, beta = params\n    N_train = len(r_train)\n    \n    h = np.zeros(N_train)\n    h[0] = np.var(r_train)\n    \n    for t in range(1, N_train):\n        h[t] = omega + alpha * r_train[t-1]**2 + beta * h[t-1]\n        if h[t] <= 0: return 1e9 # Penalize invalid parameters\n    \n    loglikelihood = -np.sum(-0.5 * np.log(2 * np.pi * h[1:]) - 0.5 * r_train[1:]**2 / h[1:])\n    return loglikelihood\n\ndef fit_and_eval_garch(r, N_train):\n    r_train = r[:N_train]\n    \n    # Fit GARCH(1,1)\n    cons = ({'type': 'ineq', 'fun': lambda x: 1 - x[1] - x[2]})\n    bnds = ((1e-9, None), (0, 1), (0, 1))\n    initial_params = [np.var(r_train) * 0.1, 0.1, 0.8]\n    \n    res = minimize(garch_loglike, initial_params, args=(r_train,),\n                   method='SLSQP', bounds=bnds, constraints=cons)\n    omega_hat, alpha_hat, beta_hat = res.x\n    \n    # Evaluate on test set\n    N = len(r)\n    h_filtered = np.zeros(N)\n    h_filtered[0] = np.var(r_train)\n    for t in range(1, N):\n        h_filtered[t] = omega_hat + alpha_hat * r[t-1]**2 + beta_hat * h_filtered[t-1]\n\n    forecasts = omega_hat + alpha_hat * r[N_train-1:N-1]**2 + beta_hat * h_filtered[N_train-1:N-1]\n    targets = r[N_train:]**2\n    \n    mse_garch = np.mean((forecasts - targets)**2)\n    return mse_garch\n\n\ndef solve():\n    test_cases = [\n        # Case A: Predictive sentiment\n        {'phi': 0.8, 'sigma_eps': 0.5, 'omega': 2.5e-5, 'alpha': 0.08, 'beta': 0.86, 'gamma': 1.5e-4, 'seed': 12345, 'W': 10, 'H': 6},\n        # Case B: No sentiment effect\n        {'phi': 0.8, 'sigma_eps': 0.5, 'omega': 8e-6, 'alpha': 0.08, 'beta': 0.90, 'gamma': 0.0, 'seed': 54321, 'W': 10, 'H': 6},\n        # Case C: Nearly constant volatility\n        {'phi': 0.8, 'sigma_eps': 0.5, 'omega': 4e-4, 'alpha': 0.0, 'beta': 0.0, 'gamma': 0.0, 'seed': 202311, 'W': 10, 'H': 6},\n    ]\n\n    N = 220\n    N_train = 170\n    d = 2\n    \n    results = []\n    \n    for case in test_cases:\n        params_dgp = (case['phi'], case['sigma_eps'], case['omega'],\n                      case['alpha'], case['beta'], case['gamma'])\n        \n        # Generate data\n        r, s = generate_data(N, params_dgp, case['seed'])\n        r_train, s_train = r[:N_train], s[:N_train]\n        \n        # Fit and evaluate GARCH\n        mse_garch = fit_and_eval_garch(r, N_train)\n        \n        # Fit and evaluate LSTM\n        # Use a fixed seed for LSTM initialization for reproducibility\n        lstm = LSTMModel(d=d, H=case['H'], W=case['W'], random_seed=case['seed'] + 1)\n        lstm.fit(r_train, s_train)\n        mse_lstm = lstm.predict_mse(r, s, N_train)\n\n        results.append(1 if mse_lstm < mse_garch else 0)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"}]}