{"hands_on_practices": [{"introduction": "The Aiyagari model is a cornerstone of modern macroeconomics, providing a framework to study economies with heterogeneous households facing uninsurable risk. This first exercise guides you through the fundamental process of building and analyzing this model from the ground up [@problem_id:2401138]. You will implement the value function iteration algorithm to solve the household's optimal savings problem and then compute the model's long-run stationary distribution, which describes the cross-sectional dispersion of wealth. Finally, you will connect the model to real-world data by computing the Gini coefficients for wealth and consumption, learning how precautionary savings behavior can generate significant inequality.", "id": "2401138", "problem": "Consider an incomplete-markets economy with infinitely lived, ex-ante identical households facing uninsurable idiosyncratic labor income risk and a borrowing constraint. Prices are exogenous and constant. The household chooses savings to maximize expected discounted utility under the budget constraint and a no-borrowing constraint. Preferences are represented by constant relative risk aversion (CRRA) utility. The environment is given by the following primitive objects and fundamental definitions:\n\n- The household solves the dynamic program with the Bellman equation\n$$\nV(a,y) = \\max_{a' \\in \\mathcal{A}} \\left\\{ u\\big(c\\big) + \\beta \\, \\mathbb{E}\\big[V(a',y') \\mid y\\big] \\right\\}\n$$\nsubject to\n$$\nc = (1+r)\\,a + w\\,y - a', \\quad c \\ge 0,\\quad a' \\ge a_{\\min},\n$$\nwhere $a$ is current assets, $a'$ is next-period assets, $y$ is the idiosyncratic labor productivity state, $r$ is the net interest rate, $w$ is the wage, $\\beta \\in (0,1)$ is the discount factor, and $u(c)$ is the period utility.\n\n- Period utility is CRRA:\n$$\nu(c) =\n\\begin{cases}\n\\dfrac{c^{1-\\gamma}}{1-\\gamma}, & \\gamma \\ne 1, \\\\\n\\log(c), & \\gamma = 1,\n\\end{cases}\n\\quad \\text{with } \\gamma > 0.\n$$\n\n- Idiosyncratic labor productivity follows a finite-state Markov chain $y \\in \\{y_1,\\dots,y_S\\}$ with transition matrix $\\Pi$, where $\\Pi_{ij} = \\Pr(y' = y_j \\mid y = y_i)$.\n\n- A stationary distribution over the joint state $(a,y)$ is a probability vector $\\mu$ on the discretized state space such that\n$$\n\\mu' = \\mu' \\, \\mathcal{T},\n$$\nwhere $\\mathcal{T}$ is the transition matrix induced by the optimal policy function and the income transition matrix $\\Pi$.\n\n- The Gini coefficient for a nonnegative random variable $x$ with weights (probabilities) $w$ is defined from the Lorenz curve. Given a discrete, sorted (ascending) sample $\\{x_i,w_i\\}_{i=1}^N$ with $x_i \\ge 0$, total weight $W = \\sum_i w_i$, and total mass $X = \\sum_i w_i x_i$, let the cumulative weight shares be $p_i = \\left(\\sum_{j=1}^i w_j\\right)/W$ and the cumulative $x$ shares be $L_i = \\left(\\sum_{j=1}^i w_j x_j\\right)/X$. With $p_0 = 0$ and $L_0 = 0$, the Gini coefficient is\n$$\nG = 1 - \\sum_{i=1}^N (p_i - p_{i-1}) \\, (L_i + L_{i-1}).\n$$\nAssume $X > 0$.\n\nTask. Write a program that, for each parameter set below, performs the following steps:\n\n1. Discretize the asset space $\\mathcal{A}$ on a uniform grid from $a_{\\min}$ to $a_{\\max}$ with $N_a$ points. Impose $a_{\\min} \\ge 0$ so that asset holdings are nonnegative and the Gini coefficient for wealth is well-defined.\n\n2. Solve the household problem via value function iteration on the joint grid $(a,y)$ to obtain the optimal savings policy $a'(a,y)$ and implied consumption $c(a,y)$, starting from an initial guess for the value function and iterating until the sup norm of the value function increment is below a tolerance.\n\n3. Construct the Markov transition matrix on $(a,y)$ induced by the optimal policy and the exogenous process for $y$. Compute the stationary distribution $\\mu$ by iterating on the law of motion for the distribution until convergence.\n\n4. Compute the Gini coefficient for wealth using the distribution of assets across $(a,y)$ weighted by $\\mu$, and the Gini coefficient for consumption using the distribution of $c(a,y)$ weighted by $\\mu$.\n\n5. Compare your model-implied Gini coefficients to the empirical targets for the United States given by $G^{\\text{emp}}_{\\text{wealth}} = 0.78$ and $G^{\\text{emp}}_{\\text{cons}} = 0.30$, by reporting absolute deviations.\n\nUse the following test suite of parameter sets:\n\n- Case $1$ (baseline risk and patience):\n  - $\\beta = 0.96$, $\\gamma = 2.0$, $r = 0.02$, $w = 1.0$,\n  - income states $y \\in \\{0.6, 1.4\\}$,\n  - symmetric persistence $p = 0.9$ so that\n    $$\n    \\Pi = \\begin{bmatrix}\n    p & 1-p \\\n$$4pt]\n    1-p & p\n    \\end{bmatrix},\n    $$\n  - assets: $a_{\\min} = 0$, $a_{\\max} = 40$, $N_a = 200$.\n\n- Case $2$ (higher return on savings):\n  - $\\beta = 0.96$, $\\gamma = 2.0$, $r = 0.04$, $w = 1.0$,\n  - income states $y \\in \\{0.6, 1.4\\}$,\n  - symmetric persistence $p = 0.9$ with $\\Pi$ as above,\n  - assets: $a_{\\min} = 0$, $a_{\\max} = 40$, $N_a = 200$.\n\n- Case $3$ (lower income persistence):\n  - $\\beta = 0.96$, $\\gamma = 2.0$, $r = 0.02$, $w = 1.0$,\n  - income states $y \\in \\{0.6, 1.4\\}$,\n  - symmetric persistence $p = 0.5$ with\n    $$\n    \\Pi = \\begin{bmatrix}\n    0.5 & 0.5 \\\n$$4pt]\n    0.5 & 0.5\n    \\end{bmatrix},\n    $$\n  - assets: $a_{\\min} = 0$, $a_{\\max} = 40$, $N_a = 200$.\n\nYour program must output, for the three cases in order, the following $12$ floats:\n$$\n\\big[G^{\\text{cons}}_1,\\, G^{\\text{wealth}}_1,\\, |G^{\\text{cons}}_1 - 0.30|,\\, |G^{\\text{wealth}}_1 - 0.78|,\\, G^{\\text{cons}}_2,\\, G^{\\text{wealth}}_2,\\, |G^{\\text{cons}}_2 - 0.30|,\\, |G^{\\text{wealth}}_2 - 0.78|,\\, G^{\\text{cons}}_3,\\, G^{\\text{wealth}}_3,\\, |G^{\\text{cons}}_3 - 0.30|,\\, |G^{\\text{wealth}}_3 - 0.78|\\big],\n$$\nrounded to four decimals.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[0.3123,0.7456,0.0123,0.0344, ...]\"). No additional text should be printed. No user input is allowed. All quantities are unit-free, so no physical units are required. Angles are not involved. Percentages must be expressed as decimals, not with a percent sign.", "solution": "The problem is valid. It presents a standard, well-posed exercise in computational macroeconomics, specifically the analysis of an incomplete markets model with precautionary savings (an Aiyagari-Huggett model). All parameters and definitions are clear and established within the field. The task is to solve the household's dynamic programming problem, compute the resulting stationary distribution of wealth and consumption, and measure the inequality in these distributions using the Gini coefficient.\n\nThe solution proceeds systematically through the steps outlined in the problem statement.\n\n1.  **Model Discretization and Setup**\n    The continuous state variable for assets, $a$, is discretized into a finite, uniform grid $\\mathcal{A} = \\{a_1, \\dots, a_{N_a}\\}$ ranging from $a_{\\min}$ to $a_{\\max}$. The idiosyncratic labor productivity process is already a discrete finite-state Markov chain with $N_y$ states, $y \\in \\{y_1, \\dots, y_{N_y}\\}$, and a transition matrix $\\Pi$. The complete state of a household is thus a point in the joint discrete space $(a, y)$, which has $N_a \\times N_y$ possible states.\n\n2.  **Value Function Iteration (VFI)**\n    The household's problem is solved using value function iteration. The Bellman equation for a household in state $(a_i, y_k)$ is:\n    $$\n    V(a_i, y_k) = \\max_{a_j \\in \\mathcal{A}} \\left\\{ u\\big(c(a_i, y_k, a_j)\\big) + \\beta \\sum_{l=1}^{N_y} \\Pi_{kl} V(a_j, y_l) \\right\\}\n    $$\n    where consumption $c$ is determined by the budget constraint $c(a_i, y_k, a_j) = (1+r)a_i + w y_k - a_j$. The maximization is performed over the discrete set of possible next-period asset holdings, $\\{a_1, \\dots, a_{N_a}\\}$. Any choice of $a_j$ that results in non-positive consumption ($c \\le 0$) is assigned an extremely low utility (e.g., $-\\infty$) to ensure it is never chosen.\n\n    The algorithm starts with an initial guess for the value function, $V_0$ (e.g., a matrix of zeros), and iterates the Bellman operator:\n    $$\n    V_{t+1}(a_i, y_k) = \\max_{a_j \\in \\mathcal{A}} \\left\\{ u\\big((1+r)a_i + w y_k - a_j\\big) + \\beta \\sum_{l=1}^{N_y} \\Pi_{kl} V_t(a_j, y_l) \\right\\}\n    $$\n    This iteration is repeated until the value function converges, which is guaranteed because the Bellman operator is a contraction mapping for $\\beta \\in (0,1)$. Convergence is declared when the maximum absolute difference between successive value functions, $\\sup |V_{t+1} - V_t|$, falls below a specified tolerance.\n\n    The computation is vectorized for efficiency. The term representing expected future value, $\\mathbb{E}[V_t(a', y') | y] = \\sum_{l=1}^{N_y} \\Pi_{kl} V_t(a', y_l)$, is pre-computed for all combinations of a' and y. The maximization is then performed over a multi-dimensional array representing all possible choices from all possible states.\n\n    Upon convergence, the optimal savings policy, $a'(a_i, y_k)$, is determined by the asset choice $a_j$ that maximizes the right-hand side of the Bellman equation for each state $(a_i, y_k)$. The corresponding consumption policy, $c(a_i, y_k)$, is then computed from the budget constraint.\n\n3.  **Stationary Distribution**\n    The combination of the deterministic optimal savings policy $a'(a,y)$ and the stochastic income process $\\Pi$ defines a Markov chain over the joint state space $(a,y)$. We construct a transition matrix $\\mathcal{T}$ of size $(N_a N_y) \\times (N_a N_y)$ for this process. The element $\\mathcal{T}_{s,s'}$ gives the probability of moving from a combined state $s=(a_i, y_k)$ to state $s'=(a_j, y_l)$. This probability is non-zero only if the policy dictates choosing $a_j$ from state $(a_i, y_k)$, in which case the probability is given by the income transition probability $\\Pi_{kl}$.\n    \n    The stationary distribution $\\mu$ is a probability vector over the state space that remains unchanged over time, satisfying the condition $\\mu' = \\mu' \\mathcal{T}$, where vectors are treated as rows. This distribution is found using power iteration. We start with an initial guess, $\\mu_0$ (e.g., a uniform distribution), and repeatedly apply the transition matrix, $\\mu_{t+1} = \\mu_t \\mathcal{T}$, until the distribution converges, i.e., $\\max |\\mu_{t+1} - \\mu_t|$ is below a small tolerance. The resulting vector $\\mu$ gives the long-run probability of a household being in any given state $(a_i, y_k)$.\n\n4.  **Gini Coefficient Calculation**\n    The Gini coefficient is computed for wealth and consumption using the stationary distribution $\\mu$ as weights. For a variable $x$ with values $\\{x_i\\}$ and corresponding probabilities $\\{w_i\\}$, the Gini is calculated based on the Lorenz curve as specified in the problem statement. The procedure is as follows:\n    - Sort the pairs $(x_i, w_i)$ according to $x_i$ in ascending order.\n    - Compute the cumulative share of the population (weights), $p_i$, and the cumulative share of the variable, $L_i$.\n    - Apply the formula $G = 1 - \\sum_{i=1}^N (p_i - p_{i-1}) (L_i + L_{i-1})$.\n\n    For the wealth Gini, the variable $x$ is the asset grid $\\mathcal{A}$, and the weights are the marginal stationary distribution for assets, $\\mu_a(a_i) = \\sum_{k=1}^{N_y} \\mu(a_i, y_k)$.\n    For the consumption Gini, the variable $x$ is the set of consumption levels $c(a_i, y_k)$ from the policy function, and the weights are the joint stationary distribution probabilities $\\mu(a_i, y_k)$.\n\n    The final step is to calculate the absolute deviations of the computed Gini coefficients from the provided empirical targets for each parameter case and report all results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef gini(x, w):\n    \"\"\"\n    Calculates the Gini coefficient for a discrete distribution.\n    \n    Args:\n        x (np.ndarray): Array of values.\n        w (np.ndarray): Array of corresponding weights (probabilities).\n        \n    Returns:\n        float: The Gini coefficient.\n    \"\"\"\n    # Ensure x and w are flat numpy arrays of the same size\n    x = np.asarray(x).flatten()\n    w = np.asarray(w).flatten()\n\n    # Sort by x values\n    sorted_indices = np.argsort(x)\n    x_sorted = x[sorted_indices]\n    w_sorted = w[sorted_indices]\n\n    # Cumulative weights and value-weighted weights\n    cum_w = np.cumsum(w_sorted)\n    cum_xw = np.cumsum(x_sorted * w_sorted)\n    \n    # Total weight and total value\n    total_w = cum_w[-1]\n    total_xw = cum_xw[-1]\n\n    # Handle case of zero total value (no inequality if total is zero)\n    if total_xw <= 0:\n        return 0.0\n\n    # Lorenz curve coordinates (p, L)\n    p = cum_w / total_w\n    L = cum_xw / total_xw\n\n    # Prepend (0,0) to the Lorenz curve points for the summation formula\n    p = np.insert(p, 0, 0)\n    L = np.insert(L, 0, 0)\n\n    # Gini coefficient from the area under the Lorenz curve\n    # The formula given is G = 1 - sum((p_i - p_{i-1}) * (L_i + L_{i-1}))\n    area_sum = np.sum(np.diff(p) * (L[1:] + L[:-1]))\n    \n    return 1.0 - area_sum\n\ndef run_case(params):\n    \"\"\"\n    Solves the household problem for a given set of parameters.\n    \n    Args:\n        params (tuple): A tuple containing all model and grid parameters.\n        \n    Returns:\n        list: A list of floats containing [G_cons, G_wealth, dev_cons, dev_wealth].\n    \"\"\"\n    # Unpack parameters\n    beta, gamma, r, w, y_states, Pi, a_min, a_max, N_a = params\n    \n    # Numerical tolerances and iteration limits\n    vfi_tol = 1e-7\n    vfi_max_iter = 2000\n    dist_tol = 1e-9\n    dist_max_iter = 5000\n\n    # 1. Discretize state space\n    a_grid = np.linspace(a_min, a_max, N_a)\n    y_grid = np.array(y_states)\n    N_y = len(y_grid)\n\n    # 2. Value Function Iteration\n    V = np.zeros((N_a, N_y))\n    \n    # Define CRRA utility function\n    def u(c):\n        # Note: gamma != 1 is handled by problem statement parameters\n        return (c**(1.0 - gamma)) / (1.0 - gamma)\n\n    for i in range(vfi_max_iter):\n        V_old = V.copy()\n\n        # Expected value component E[V(a',y')|y]\n        EV = V @ Pi.T  # shape (N_a, N_y)\n\n        # Vectorized maximization\n        cash_on_hand = (1 + r) * a_grid[:, None] + w * y_grid[None, :]\n        consumption = cash_on_hand[:, :, None] - a_grid[None, None, :]\n\n        # Calculate utility, handling non-positive consumption with a large penalty\n        utility = np.full(consumption.shape, -1e12)\n        mask = consumption > 1e-9 # Avoid numerical issues at c=0\n        utility[mask] = u(consumption[mask])\n\n        # Bellman operator RHS\n        RHS_val = utility + beta * EV.T[None, :, :]\n        \n        V = np.max(RHS_val, axis=2)\n        \n        if np.max(np.abs(V - V_old)) < vfi_tol:\n            break\n    \n    # Derive optimal policies from the final value function iteration\n    policy_idx = np.argmax(RHS_val, axis=2)\n    a_prime_policy = a_grid[policy_idx]\n    c_policy = (1 + r) * a_grid[:, None] + w * y_grid[None, :] - a_prime_policy\n\n    # 3. Stationary Distribution\n    N_states = N_a * N_y\n    T = np.zeros((N_states, N_states))\n\n    for i_a in range(N_a):\n        for i_y in range(N_y):\n            s_from = i_a * N_y + i_y\n            j_a_to = policy_idx[i_a, i_y]\n            for j_y_to in range(N_y):\n                s_to = j_a_to * N_y + j_y_to\n                T[s_from, s_to] = Pi[i_y, j_y_to]\n    \n    # Power iteration to find stationary distribution mu\n    mu = np.ones(N_states) / N_states\n    for i in range(dist_max_iter):\n        mu_old = mu\n        mu = mu @ T\n        if np.max(np.abs(mu - mu_old)) < dist_tol:\n            break\n            \n    # 4. Gini coefficients\n    # Wealth Gini\n    mu_reshaped = mu.reshape((N_a, N_y))\n    marginal_mu_a = mu_reshaped.sum(axis=1)\n    gini_wealth = gini(a_grid, marginal_mu_a)\n    \n    # Consumption Gini\n    gini_consumption = gini(c_policy.flatten(), mu)\n    \n    # 5. Report deviations from empirical targets\n    G_emp_cons = 0.30\n    G_emp_wealth = 0.78\n    \n    dev_cons = abs(gini_consumption - G_emp_cons)\n    dev_wealth = abs(gini_wealth - G_emp_wealth)\n\n    return [gini_consumption, gini_wealth, dev_cons, dev_wealth]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Case 1: baseline\n    p1 = 0.9\n    pi1 = np.array([[p1, 1 - p1], [1 - p1, p1]])\n    case1 = (0.96, 2.0, 0.02, 1.0, [0.6, 1.4], pi1, 0.0, 40.0, 200)\n\n    # Case 2: higher interest rate\n    p2 = 0.9\n    pi2 = np.array([[p2, 1 - p2], [1 - p2, p2]])\n    case2 = (0.96, 2.0, 0.04, 1.0, [0.6, 1.4], pi2, 0.0, 40.0, 200)\n\n    # Case 3: lower income persistence\n    p3 = 0.5\n    pi3 = np.array([[p3, 1-p3], [1-p3, p3]])\n    case3 = (0.96, 2.0, 0.02, 1.0, [0.6, 1.4], pi3, 0.0, 40.0, 200)\n    \n    test_cases = [case1, case2, case3]\n\n    all_results = []\n    for case in test_cases:\n        results = run_case(case)\n        all_results.extend(results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{x:.4f}' for x in all_results)}]\")\n\nsolve()\n```"}, {"introduction": "While value function iteration is a robust method, its computational cost can be high. This practice introduces the Endogenous Gridpoints Method (EGM), a more efficient and elegant technique that leverages the model's first-order condition (the Euler equation) to solve the household's problem backward in time [@problem_id:2401169]. By implementing EGM in a lifecycle context, you will not only add a powerful tool to your computational toolkit but also make the concept of precautionary savings concrete. You will directly quantify this motive by comparing the savings of an agent facing income uncertainty to one in an equivalent, risk-free world.", "id": "2401169", "problem": "Consider a finite-horizon lifecycle consumption-saving problem under incomplete markets with a binding borrowing constraint. Time is indexed by $t \\in \\{1,\\dots,T\\}$ and the agent faces idiosyncratic labor income risk that follows a time-homogeneous Markov chain over a finite set of income states. The state variable is asset holdings $a_t$ carried into period $t$, and the control variables are consumption $c_t$ and next period’s assets $a_{t+1}$. Markets are incomplete and the only asset is a risk-free bond with gross return $1+r$. There is a hard borrowing constraint $a_{t+1} \\geq 0$ that binds when optimal choices would violate it.\n\nPreferences are time-separable with Constant Relative Risk Aversion (CRRA), with period utility $u(c) = \\frac{c^{1-\\sigma}}{1-\\sigma}$ for $\\sigma > 0$, $\\sigma \\neq 1$. The agent maximizes expected discounted utility $\\mathbb{E}\\left[\\sum_{t=1}^{T} \\beta^{t-1} u(c_t)\\right]$, with discount factor $\\beta \\in (0,1)$. The budget constraint each period is $c_t + a_{t+1} = (1+r)a_t + y_{s_t}$, where $y_{s_t}$ is labor income in income state $s_t$, and $s_t$ evolves according to a known transition matrix $P$ on a finite state space.\n\nFundamental definitions:\n- The period-$t$ Bellman equation is $V_t(a_t,s_t) = \\max_{c_t,a_{t+1} \\geq 0} \\left\\{ u(c_t) + \\beta \\mathbb{E}\\left[V_{t+1}(a_{t+1}, s_{t+1}) \\mid s_t \\right] \\right\\}$ subject to $c_t + a_{t+1} = (1+r)a_t + y_{s_t}$.\n- The Euler condition for interior solutions is $u'(c_t) = \\beta (1+r) \\mathbb{E}\\left[ u'(c_{t+1}) \\mid s_t \\right]$, and the borrowing constraint implies the complementary slackness condition with $a_{t+1} \\geq 0$.\n- At the terminal period $T$, the no-bequest condition implies $a_{T+1} = 0$, so $c_T = (1+r)a_T + y_{s_T}$, and $V_T$ can be computed directly.\n\nTask: Implement the Endogenous Gridpoints Method (EGM) to solve this finite-horizon problem for the optimal consumption function $c_t(m_t, s_t)$ at each age $t$ and income state $s_t$, where cash-on-hand is $m_t \\equiv (1+r) a_t + y_{s_t}$. Your implementation must:\n- Use the Euler condition and the borrowing constraint to construct the endogenous grid for each $(t,s_t)$ without root-finding.\n- Handle the borrowing constraint $a_{t+1} \\geq 0$ exactly by imposing $c_t = m_t$ when the implied optimal $a_{t+1}$ by the Euler condition would otherwise be negative.\n- Use linear interpolation to evaluate $c_{t+1}(m_{t+1}, s_{t+1})$ as needed in expectations.\n\nBenchmark for precautionary savings: For each parameter set below, compute the “precautionary saving” at age $t=1$ as the difference between optimal next-period assets under risk and under a certainty-equivalent, no-risk benchmark. Specifically:\n- Define the risky model using the given $y$ and $P$.\n- Define the certainty-equivalent, no-risk benchmark by replacing stochastic income with a deterministic constant income $\\bar{y}$ equal to the unconditional mean of $y$ under the stationary distribution of $P$. That is, find the stationary distribution $\\pi$ satisfying $\\pi P = \\pi$, $\\sum_i \\pi_i = 1$, and set $\\bar{y} = \\sum_i \\pi_i y_i$. Solve the same lifecycle problem with a single income state equal to $\\bar{y}$ and the same $\\beta$, $\\sigma$, $r$, $T$, and borrowing constraint.\n- For a given initial asset $a_1 = a_0$ and initial income state $s_1$, compute $m_1 = (1+r)a_0 + y_{s_1}$ and evaluate the optimal first-period next assets $a_2^{\\text{risk}} = m_1 - c_1^{\\text{risk}}(m_1,s_1)$ and $a_2^{\\text{det}} = \\bar{m}_1 - c_1^{\\text{det}}(\\bar{m}_1)$ where $\\bar{m}_1 = (1+r)a_0 + \\bar{y}$. Report the precautionary saving as $a_2^{\\text{risk}} - a_2^{\\text{det}}$.\n\nNumerical implementation requirements:\n- Use an evenly spaced grid of $N_a = 200$ points for $a_{t+1}$ on $[0, \\bar{a}]$ with $\\bar{a} = 50$.\n- Use linear interpolation for evaluating consumption functions in expectations and for evaluating $c_t(m_t, s_t)$ at arbitrary $m_t$.\n- Use $T = 10$.\n- Round each reported precautionary saving to $6$ decimal places.\n\nTest suite:\nCompute the precautionary saving for the following $3$ parameter sets. In all cases, report the single float value $a_2^{\\text{risk}} - a_2^{\\text{det}}$ for each parameter set.\n\n- Case $1$ (happy path):\n  - $T = 10$, $\\beta = 0.96$, $\\sigma = 2.0$, $r = 0.02$,\n  - $y = [0.5, 1.5]$, $P = \\begin{bmatrix}0.9 & 0.1 \\\\ 0.1 & 0.9\\end{bmatrix}$,\n  - $a_0 = 0.0$, $s_1 = 2$ (the higher-income state).\n\n- Case $2$ (no risk boundary):\n  - $T = 10$, $\\beta = 0.96$, $\\sigma = 2.0$, $r = 0.02$,\n  - $y = [1.0, 1.0]$, $P = \\begin{bmatrix}0.9 & 0.1 \\\\ 0.1 & 0.9\\end{bmatrix}$,\n  - $a_0 = 0.0$, $s_1 = 2$.\n\n- Case $3$ (high risk, high prudence):\n  - $T = 10$, $\\beta = 0.98$, $\\sigma = 3.0$, $r = 0.01$,\n  - $y = [0.1, 1.9]$, $P = \\begin{bmatrix}0.95 & 0.05 \\\\ 0.05 & 0.95\\end{bmatrix}$,\n  - $a_0 = 0.0$, $s_1 = 2$.\n\nFinal output format:\nYour program should produce a single line of output containing the results for the $3$ cases as a comma-separated list enclosed in square brackets, for example $[x_1,x_2,x_3]$, where each $x_i$ is a float rounded to $6$ decimals corresponding to Case $i$ in the order listed above.", "solution": "The problem requires the solution of a finite-horizon lifecycle consumption-saving model under income uncertainty using the Endogenous Gridpoints Method (EGM). We are tasked with computing the level of precautionary saving at the beginning of the lifecycle for three different parameterizations.\n\nThe agent's problem is to maximize expected lifetime utility, given by:\n$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T} \\beta^{t-1} \\frac{c_t^{1-\\sigma}}{1-\\sigma}\\right]\n$$\nsubject to a sequence of budget constraints:\n$$\nc_t + a_{t+1} = (1+r)a_t + y_{s_t}\n$$\nand a borrowing constraint $a_{t+1} \\geq 0$. Here, $c_t$ is consumption in period $t$, $a_t$ is the asset level at the start of period $t$, $y_{s_t}$ is labor income which depends on the stochastic state $s_t$, $r$ is the risk-free interest rate, $\\beta$ is the discount factor, and $\\sigma$ is the coefficient of relative risk aversion. The income state $s_t$ follows a time-homogeneous Markov chain with transition matrix $P$.\n\nThe problem is solved via backward induction, starting from the final period $T$.\n\n**Period $T$ (Terminal Period):**\nThe agent has no incentive to save, as there is no period $T+1$. The no-bequest motive implies $a_{T+1} = 0$. Thus, the agent consumes all available resources. Cash-on-hand in period $T$ is $m_T = (1+r)a_T + y_{s_T}$. The optimal consumption policy is:\n$$\nc_T(m_T, s_T) = m_T\n$$\nThis policy is identical for all income states $s_T$. The marginal utility of consumption is $u'(c_T) = c_T^{-\\sigma} = m_T^{-\\sigma}$.\n\n**Period $t < T$ (Recursive Solution via EGM):**\nFor any period $t < T$, we solve for the optimal consumption policy $c_t(m_t, s_t)$ assuming we have already found the policy for period $t+1$, $c_{t+1}(m_{t+1}, s_{t+1})$. The EGM approach works as follows:\n\n1.  **Exogenous Grid on Next Period's Assets:** We define a discrete grid of points for the agent's choice of next period's assets, $a_{t+1}$. Let this grid be $A' = \\{a'_0, a'_1, \\dots, a'_{N_a-1}\\}$, where $a'_0=0$ and $a'_{N_a-1}=\\bar{a}$.\n\n2.  **Expectation Calculation:** For each point $a' \\in A'$ and each current income state $s_t$, we use the intertemporal Euler equation, which for an interior solution is $u'(c_t) = \\beta (1+r) \\mathbb{E}[u'(c_{t+1}) | s_t]$. We first compute the expectation term. For a given choice of $a_{t+1} = a'$, cash-on-hand in the next period will be $m_{t+1} = (1+r)a' + y_{s_{t+1}}$. The expected marginal utility is:\n    $$\n    \\mathbb{E}[u'(c_{t+1}) | s_t] = \\sum_{s_{t+1}} P(s_t, s_{t+1}) u'(c_{t+1}((1+r)a' + y_{s_{t+1}}, s_{t+1}))\n    $$\n    where $P(s_t, s_{t+1})$ is the transition probability from state $s_t$ to $s_{t+1}$. The function $c_{t+1}(\\cdot, s_{t+1})$ is known from the previous step of the backward induction and is evaluated using linear interpolation.\n\n3.  **Endogenous Consumption:** With the expectation term calculated for each $a' \\in A'$, we can find the corresponding current consumption $c_t$ by inverting the marginal utility function $u'(c) = c^{-\\sigma}$:\n    $$\n    c_t = \\left( \\beta (1+r) \\mathbb{E}[u'(c_{t+1}) | s_t] \\right)^{-1/\\sigma}\n    $$\n    This step gives us a set of endogenous consumption values, one for each $a' \\in A'$.\n\n4.  **Endogenous Cash-on-Hand Grid:** Using the budget constraint $m_t = c_t + a_{t+1}$, we can find the level of cash-on-hand $m_t$ that corresponds to each pair of $(c_t, a')$. This creates an endogenous grid of cash-on-hand points:\n    $$\n    m_t = c_t + a'\n    $$\n    We now have pairs $(m_t, c_t)$ that satisfy the Euler equation.\n\n5.  **Handling the Borrowing Constraint:** The procedure above characterizes the optimal policy for agents who are not borrowing constrained. The borrowing constraint $a_{t+1} \\geq 0$ binds if an agent's optimal unconstrained choice would be $a_{t+1} < 0$. Such an agent will instead choose $a_{t+1}=0$ and consume all cash-on-hand, $c_t=m_t$. The EGM elegantly handles this. The first point on our exogenous grid is $a'_0 = 0$. The corresponding endogenous point is $(m_t(a'_0), c_t(a'_0))$. From the budget constraint, $m_t(a'_0) = c_t(a'_0) + 0 = c_t(a'_0)$. This point lies on the $c_t=m_t$ line. For any agent with cash-on-hand $m < m_t(a'_0)$, they are borrowing constrained and their policy is $c_t=m_t$.\n    To construct a single policy function, we combine the constrained and unconstrained regions. We form a grid for interpolation using the calculated endogenous $(m_t, c_t)$ pairs, prepended with the point $(0,0)$. Since the point $(m_t(a'_0), c_t(a'_0))$ is equivalent to $(c_t(a'_0), c_t(a'_0))$, linear interpolation between $(0,0)$ and this point correctly recovers the $c_t=m_t$ policy for the constrained region. The full set of ordered pairs `(m, c)` is then used to create a linear interpolant for the consumption function $c_t(m_t, s_t)$.\n\nThis process is repeated backwards from $t=T-1$ down to $t=1$ for each income state $s_t$.\n\n**Precautionary Saving Calculation:**\nPrecautionary saving is the additional saving undertaken due to future income uncertainty. It is computed as the difference in optimal saving between the risky model and a benchmark deterministic model.\n\n1.  **Risky Model Solution:** We solve the model as described above using the provided stochastic income process ($y$, $P$). This yields the policy function $c_1^{\\text{risk}}(m_1, s_1)$. For a given initial asset $a_0$ and initial state $s_1$, we find cash-on-hand $m_1 = (1+r)a_0 + y_{s_1}$, then optimal consumption $c_1^{\\text{risk}}(m_1, s_1)$, and finally optimal next-period assets $a_2^{\\text{risk}} = m_1 - c_1^{\\text{risk}}(m_1, s_1)$.\n\n2.  **Deterministic Model Solution:**\n    a. We first compute the stationary distribution $\\pi$ of the Markov chain, which is the unique vector satisfying $\\pi P = \\pi$ and $\\sum_i \\pi_i = 1$. This is found by computing the eigenvector of $P^T$ corresponding to the eigenvalue $1$.\n    b. We then calculate the unconditional mean income $\\bar{y} = \\sum_i \\pi_i y_i$.\n    c. We resolve the model with a deterministic, constant income stream equal to $\\bar{y}$. This is equivalent to a model with a single income state and transition probability $1$. This yields the policy function $c_1^{\\text{det}}(m_1)$.\n    d. For the same initial asset $a_0$, we find cash-on-hand $\\bar{m}_1 = (1+r)a_0 + \\bar{y}$, then optimal consumption $c_1^{\\text{det}}(\\bar{m}_1)$, and finally assets $a_2^{\\text{det}} = \\bar{m}_1 - c_1^{\\text{det}}(\\bar{m}_1)$.\n\n3.  **Precautionary Saving:** The final measure is the difference: $a_2^{\\text{risk}} - a_2^{\\text{det}}$. This value is computed for each of the three test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import interp1d\n\ndef compute_stationary_dist(P):\n    \"\"\"\n    Computes the stationary distribution of a Markov chain given its transition matrix P.\n    \"\"\"\n    n_states = P.shape[0]\n    # We are looking for a vector pi such that pi * P = pi and sum(pi) = 1.\n    # This is equivalent to finding the eigenvector of P.T for the eigenvalue 1.\n    evals, evecs = np.linalg.eig(P.T)\n    # Find the eigenvector corresponding to the eigenvalue closest to 1\n    idx = np.argmin(np.abs(evals - 1.0))\n    pi = evecs[:, idx].real\n    # Normalize to ensure it's a probability distribution\n    pi /= pi.sum()\n    return pi\n\ndef solve_lifecycle_egm(T, beta, sigma, r, y, P, a_max, n_a):\n    \"\"\"\n    Solves the finite-horizon lifecycle model using the Endogenous Gridpoints Method.\n    \"\"\"\n    n_income_states = len(y)\n    a_grid = np.linspace(0, a_max, n_a)\n    \n    # This will store the consumption policy functions for each period and state\n    policy_functions = [[None] * n_income_states for _ in range(T)]\n\n    # Period T: Consume all cash-on-hand\n    for s_idx in range(n_income_states):\n        # c(m) = m. We create an interpolant for this.\n        # Grid for m can be anything, but should cover expected range.\n        m_T_grid = np.linspace(0, a_max * (1 + r) + np.max(y), 100)\n        c_T_grid = m_T_grid\n        policy_functions[T-1][s_idx] = interp1d(\n            m_T_grid, c_T_grid,\n            kind='linear', bounds_error=False, fill_value=(0.0, m_T_grid[-1])\n        )\n\n    # Backward induction from T-1 to 1\n    for t in range(T - 2, -1, -1):\n        for s_idx in range(n_income_states):\n            # 1. Calculate expected marginal utility for each point in a_grid\n            \n            # E_u_prime will store the expectation\n            E_u_prime = np.zeros(n_a)\n            \n            # Loop over possible next-period states\n            for s_next_idx in range(n_income_states):\n                # Cash on hand tomorrow if we save a_grid today\n                m_next = (1 + r) * a_grid + y[s_next_idx]\n                \n                # Get tomorrow's consumption function\n                c_func_next = policy_functions[t+1][s_next_idx]\n                \n                # Consumption choice tomorrow\n                c_next = c_func_next(m_next)\n\n                # Avoid division by zero if consumption is zero\n                c_next[c_next <= 0] = 1e-9\n\n                # Marginal utility tomorrow\n                mu_prime_next = c_next**(-sigma)\n                \n                # Add to expectation, weighted by transition probability\n                prob = P[s_idx, s_next_idx]\n                E_u_prime += prob * mu_prime_next\n\n            # 2. Invert Euler equation to find endogenous consumption grid\n            c_endog = (beta * (1 + r) * E_u_prime)**(-1/sigma)\n\n            # 3. Find endogenous cash-on-hand grid\n            m_endog = a_grid + c_endog\n            \n            # 4. Handle borrowing constraint and create interpolant\n            # The first point corresponds to a' = 0.\n            # For m < m_endog[0], agent is constrained, so c = m.\n            # We prepend (0,0) to the grid. Interpolation between (0,0) and \n            # (m_endog[0], c_endog[0]) will be c=m because m_endog[0] = c_endog[0] + a_grid[0] = c_endog[0].\n            \n            # Sort grids by m_endog to ensure monotonicity for interpolation\n            sort_indices = np.argsort(m_endog)\n            m_endog_sorted = m_endog[sort_indices]\n            c_endog_sorted = c_endog[sort_indices]\n\n            m_policy_grid = np.concatenate(([0.0], m_endog_sorted))\n            c_policy_grid = np.concatenate(([0.0], c_endog_sorted))\n\n            policy_functions[t][s_idx] = interp1d(\n                m_policy_grid, c_policy_grid,\n                kind='linear', bounds_error=False,\n                fill_value=(0.0, m_policy_grid[-1]) # Extrapolate c=m for large m\n            )\n\n    return policy_functions\n\n\ndef solve():\n    test_cases = [\n        {\n            \"T\": 10, \"beta\": 0.96, \"sigma\": 2.0, \"r\": 0.02,\n            \"y\": np.array([0.5, 1.5]), \"P\": np.array([[0.9, 0.1], [0.1, 0.9]]),\n            \"a0\": 0.0, \"s1_idx\": 1\n        },\n        {\n            \"T\": 10, \"beta\": 0.96, \"sigma\": 2.0, \"r\": 0.02,\n            \"y\": np.array([1.0, 1.0]), \"P\": np.array([[0.9, 0.1], [0.1, 0.9]]),\n            \"a0\": 0.0, \"s1_idx\": 1\n        },\n        {\n            \"T\": 10, \"beta\": 0.98, \"sigma\": 3.0, \"r\": 0.01,\n            \"y\": np.array([0.1, 1.9]), \"P\": np.array([[0.95, 0.05], [0.05, 0.95]]),\n            \"a0\": 0.0, \"s1_idx\": 1\n        }\n    ]\n\n    # Global numerical parameters\n    n_a = 200\n    a_max = 50.0\n\n    results = []\n\n    for case in test_cases:\n        # 1. Solve the risky model\n        policy_risk = solve_lifecycle_egm(\n            case[\"T\"], case[\"beta\"], case[\"sigma\"], case[\"r\"],\n            case[\"y\"], case[\"P\"], a_max, n_a\n        )\n        # Calculate optimal saving under risk\n        m1_risk = (1 + case[\"r\"]) * case[\"a0\"] + case[\"y\"][case[\"s1_idx\"]]\n        c1_risk = policy_risk[0][case[\"s1_idx\"]](m1_risk)\n        a2_risk = m1_risk - c1_risk\n\n        # 2. Solve the certainty-equivalent model\n        # Find stationary distribution and mean income\n        pi = compute_stationary_dist(case[\"P\"])\n        y_bar = np.dot(pi, case[\"y\"])\n        \n        # Define deterministic model parameters\n        y_det = np.array([y_bar])\n        P_det = np.array([[1.0]])\n        \n        policy_det = solve_lifecycle_egm(\n            case[\"T\"], case[\"beta\"], case[\"sigma\"], case[\"r\"],\n            y_det, P_det, a_max, n_a\n        )\n        # Calculate optimal saving under certainty\n        m1_det = (1 + case[\"r\"]) * case[\"a0\"] + y_bar\n        c1_det = policy_det[0][0](m1_det)\n        a2_det = m1_det - c1_det\n        \n        # 3. Compute precautionary saving\n        precautionary_saving = a2_risk - a2_det\n        results.append(round(precautionary_saving, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}, {"introduction": "Understanding an economy's long-run stationary state is crucial, but many key economic questions concern how the economy evolves over time in response to shocks. This practice moves beyond static analysis to explore the transition dynamics of an entire economy of heterogeneous agents [@problem_id:2401170]. You will simulate a classic macroeconomic experiment: a sudden, permanent increase in income uncertainty. By tracking the evolution of the cross-sectional distribution, you will observe firsthand how the aggregate stock of precautionary savings builds up and measure the speed at which the economy adjusts to its new, riskier reality.", "id": "2401170", "problem": "Consider an infinite-horizon heterogeneous-agents endowment economy with incomplete markets and a single risk-free asset. Time is discrete. A representative household (standing in for each ex-ante identical household) solves a dynamic programming problem with constant relative risk aversion preferences and faces idiosyncratic, uninsurable, Markovian labor income. Markets are incomplete, so each household can only self-insure through precautionary savings subject to a borrowing limit. There are no aggregate shocks, and the interest rate is fixed exogenously.\n\nHouseholds solve the problem: choose a saving policy to maximize expected lifetime utility\n$$\n\\max_{\\{a_{t+1}\\}_{t \\ge 0}} \\ \\mathbb{E}_0 \\sum_{t=0}^{\\infty} \\beta^t \\, u(c_t),\n$$\nsubject to the per-period budget constraint\n$$\nc_t + a_{t+1} = R a_t + y_t,\n$$\nand the borrowing constraint\n$$\na_{t+1} \\ge \\underline{a},\n$$\nwhere $a_t$ is assets at the beginning of period $t$, $c_t$ is consumption, $y_t$ is idiosyncratic labor income, $\\beta \\in (0,1)$ is the subjective discount factor, $R = 1 + r$ is the gross risk-free return with $r \\ge 0$, and $\\underline{a}$ is the borrowing limit. Preferences are given by constant relative risk aversion utility\n$$\nu(c) =\n\\begin{cases}\n\\dfrac{c^{1-\\sigma}}{1-\\sigma}, & \\text{if } \\sigma \\ne 1,\\\\\n\\log(c), & \\text{if } \\sigma = 1,\n\\end{cases}\n$$\nwith coefficient of relative risk aversion $\\sigma > 0$. Income $y_t$ follows a $2$-state Markov chain with state space $\\{y_L,y_H\\}$ and transition matrix\n$$\n\\Pi =\n\\begin{bmatrix}\n\\pi_{LL} & \\pi_{LH} \\\\\n\\pi_{HL} & \\pi_{HH}\n\\end{bmatrix},\n$$\nwhere $\\pi_{ij} = \\mathbb{P}(y_{t+1}=y_j \\mid y_t=y_i)$ and the stationary mean of income equals $1$ by construction.\n\nThe dynamic programming problem can be written in Bellman form for the value function $V(a,y)$:\n$$\nV(a,y) = \\max_{a' \\in [\\underline{a},\\bar{a}]} \\left\\{ u(Ra + y - a') + \\beta \\sum_{y' \\in \\{y_L,y_H\\}} \\Pi(y,y') \\, V(a',y') \\right\\},\n$$\nwith $a' \\equiv a_{t+1}$ and numerical asset grid $a \\in \\mathcal{A} = \\{\\underline{a},\\ldots,\\bar{a}\\}$ where $\\bar{a}$ is a sufficiently large upper bound.\n\nA surprise, permanent increase in income risk occurs at time $t=0$: prior to $t=0$, income takes values in $\\{y_L^{\\text{pre}}, y_H^{\\text{pre}}\\}$ with transition matrix $\\Pi^{\\text{pre}}$; at $t=0$, the process switches to $\\{y_L^{\\text{post}}, y_H^{\\text{post}}\\}$ with transition matrix $\\Pi^{\\text{post}}$, and remains there forever. The mean of income remains $1$ in both regimes, but the variance is higher after the shock. Prices $R$ are fixed throughout.\n\nYour task is to:\n\n- Compute the optimal policy $a'(a,y)$ and the stationary cross-sectional distribution $\\mu^{\\text{pre}}$ under the pre-shock environment.\n- Compute the optimal policy $a'(a,y)$ and the stationary cross-sectional distribution $\\mu^{\\text{post}}$ under the post-shock environment.\n- Simulate the transition dynamics of the cross-sectional distribution after the surprise: initialize the distribution at $t=0$ as $\\mu^{\\text{pre}}$, then evolve it forward using the post-shock law of motion to obtain $\\{\\mu_t\\}_{t \\ge 0}$ under the post-shock policy and transition matrix.\n- Track the aggregate (cross-sectional) mean assets $A_t = \\sum_{(a,y)} a \\, \\mu_t(a,y)$ over time, and compute the time $T$ it takes until $|A_t - A^{\\text{post}}| \\le \\varepsilon$ for the first time, where $A^{\\text{post}}$ is the stationary mean assets under the post-shock environment and $\\varepsilon$ is a tolerance.\n\nFoundational base you must use:\n\n- The Bellman principle of optimality for dynamic programming.\n- The definition of a Markov chain and the law of iterated expectations.\n- Concavity of utility for risk-averse preferences and the definition of prudence for precautionary saving motives (you may refer to $u'''(c) > 0$ as a sufficient condition for precautionary saving in the presence of uninsurable risk and borrowing limits).\n- The definition of a stationary distribution of a Markov chain as a fixed point of the forward operator.\n\nNumerical approach constraints:\n\n- Discretize the asset space $\\mathcal{A}$ on a uniform grid between $\\underline{a}$ and $\\bar{a}$.\n- Use value function iteration to compute $V(a,y)$ and an induced policy $a'(a,y)$ by discretizing choices on $\\mathcal{A}$ and enforcing $c \\ge 0$.\n- Construct the endogenous Markov transition matrix over the joint state space $\\mathcal{S} = \\mathcal{A} \\times \\{y_L,y_H\\}$ implied by the optimal policy and exogenous income transition.\n- Compute stationary distributions by forward iteration of the cross-sectional distribution until convergence.\n- Simulate transition dynamics by forward iteration starting from $\\mu^{\\text{pre}}$ under the post-shock transition matrix.\n- All state probabilities must be nonnegative and should sum to $1$ at machine precision.\n\nYour program should take no input and must compute results for the following test suite of parameterizations. In all cases, set the gross return to $R = 1 + r$, discretize assets on a uniform grid with $N_a$ points on $[\\underline{a}, \\bar{a}]$, and use the same $\\bar{a}$ for pre- and post-shock calculations within a test case.\n\nTest Suite (three cases):\n\n- Case $1$ (happy path, stronger risk post-shock):\n  - $\\beta = 0.96$, $r = 0.02$ (so $R = 1.02$), $\\sigma = 2.0$, $\\underline{a} = 0.0$, $\\bar{a} = 50.0$, $N_a = 151$.\n  - Pre-shock income: $(y_L^{\\text{pre}}, y_H^{\\text{pre}}) = (0.8, 1.2)$ with transition matrix\n    $$\n    \\Pi^{\\text{pre}} =\n    \\begin{bmatrix}\n    0.9 & 0.1\\\\\n    0.1 & 0.9\n    \\end{bmatrix}.\n    $$\n  - Post-shock income: $(y_L^{\\text{post}}, y_H^{\\text{post}}) = (0.6, 1.4)$ with the same transition matrix\n    $$\n    \\Pi^{\\text{post}} = \\Pi^{\\text{pre}}.\n    $$\n  - Transition simulation tolerance $\\varepsilon = 10^{-6}$ and maximum simulated horizon $T_{\\max} = 5000$.\n\n- Case $2$ (no change in risk post-shock; a consistency check):\n  - Same parameters as Case $1$, but post-shock income equals pre-shock income, i.e., $(y_L^{\\text{post}}, y_H^{\\text{post}}) = (0.8, 1.2)$ and $\\Pi^{\\text{post}} = \\Pi^{\\text{pre}}$.\n  - Use the same $\\varepsilon$ and $T_{\\max}$ as in Case $1$.\n\n- Case $3$ (log utility, stronger risk post-shock):\n  - $\\beta = 0.96$, $r = 0.02$ (so $R = 1.02$), $\\sigma = 1.0$, $\\underline{a} = 0.0$, $\\bar{a} = 50.0$, $N_a = 151$.\n  - Pre-shock income: $(y_L^{\\text{pre}}, y_H^{\\text{pre}}) = (0.85, 1.15)$ with transition matrix\n    $$\n    \\Pi^{\\text{pre}} =\n    \\begin{bmatrix}\n    0.9 & 0.1\\\\\n    0.1 & 0.9\n    \\end{bmatrix}.\n    $$\n  - Post-shock income: $(y_L^{\\text{post}}, y_H^{\\text{post}}) = (0.65, 1.35)$ with $\\Pi^{\\text{post}} = \\Pi^{\\text{pre}}$.\n  - Transition simulation tolerance $\\varepsilon = 10^{-6}$ and maximum simulated horizon $T_{\\max} = 5000$.\n\nFor each test case, your program must compute and return the following four quantities:\n\n- $A^{\\text{pre}}$: stationary mean assets under the pre-shock environment.\n- $A^{\\text{post}}$: stationary mean assets under the post-shock environment.\n- $T$: the smallest nonnegative integer $t$ such that $|A_t - A^{\\text{post}}| \\le \\varepsilon$ when starting from $\\mu^{\\text{pre}}$ and evolving under the post-shock transition; if no such $t \\le T_{\\max}$ exists, return $T_{\\max}$.\n- $\\Delta A_1$: the one-step impact response, defined as $A_1 - A_0$, where $A_0 = A^{\\text{pre}}$ and $A_1$ is the mean assets after one forward iteration under the post-shock transition.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list of per-case results, each per-case result itself being a list in the order $[A^{\\text{pre}}, A^{\\text{post}}, T, \\Delta A_1]$.\n- The overall output must therefore look like\n  $$\n  \\big[ [A^{\\text{pre}}_1, A^{\\text{post}}_1, T_1, \\Delta A_{1,1}], [A^{\\text{pre}}_2, A^{\\text{post}}_2, T_2, \\Delta A_{1,2}], [A^{\\text{pre}}_3, A^{\\text{post}}_3, T_3, \\Delta A_{1,3}] \\big]\n  $$\n  as a single line. Print $A^{\\text{pre}}$, $A^{\\text{post}}$, and $\\Delta A_1$ as decimal floats, and $T$ as an integer. Round the floats to $6$ decimal places in your printed output.", "solution": "The problem statement is subjected to validation and is found to be valid. It is a well-posed, scientifically grounded problem in computational macroeconomics, specifically a standard heterogeneous-agent incomplete-markets model (a Bewley-Aiyagari model). All parameters, functional forms, and numerical constraints are specified with sufficient precision to admit a unique, computable solution. The parameterizations provided, such as $\\beta=0.96$ and $R=1.02$, satisfy the standard condition $\\beta R < 1$, which ensures that households are sufficiently impatient to prevent unbounded accumulation of assets. The income processes are correctly specified to have a stationary mean of $1$. The tasks are computationally feasible and test a standard economic experiment: the response of aggregate savings to an increase in idiosyncratic income risk.\n\nThe solution proceeds by implementing the numerical approach outlined in the problem statement. This involves three main stages: first, solving for the optimal household policy using value function iteration; second, using the policy to construct a Markov transition operator over the state space and finding the corresponding stationary cross-sectional distribution; and third, simulating the economy's transition from an initial stationary state to a new one following a surprise shock to income risk.\n\n**1. Value Function Iteration and Optimal Policy**\n\nThe household's problem is posed as a dynamic programming problem, summarized by the Bellman equation for each income state $y \\in \\{y_L, y_H\\}$:\n$$\nV(a,y) = \\max_{a'} \\left\\{ u(Ra + y - a') + \\beta \\mathbb{E}[V(a',y') \\mid y] \\right\\}\n$$\nsubject to the borrowing constraint $a' \\ge \\underline{a}$ and the non-negativity of consumption $c = Ra + y - a' \\ge 0$. The expectation is taken over the next period's income $y'$, given by the transition matrix $\\Pi$.\n\nTo solve this numerically, we first discretize the asset space into a uniform grid $\\mathcal{A} = \\{a_1, a_2, \\ldots, a_{N_a}\\}$ of size $N_a$ from $\\underline{a}$ to $\\bar{a}$. The state of a household is thus a pair $(a_i, y_j) \\in \\mathcal{A} \\times \\{y_L, y_H\\}$. We seek to find the value function $V(a_i, y_j)$ for all states.\n\nWe employ value function iteration (VFI), which is guaranteed to converge to the unique true value function because the Bellman operator is a contraction mapping. The iterative procedure is as follows:\n- Initialize the value function, for example, $V^0(a, y) = 0$ for all states.\n- For each iteration $k = 0, 1, 2, \\ldots$:\n    1. Compute the conditional expected continuation value for each possible next-period state $(a', y)$:\n       $$\n       \\mathbb{E}[V^k(a',y') \\mid y] = \\sum_{y' \\in \\{y_L,y_H\\}} \\Pi(y,y') V^k(a',y')\n       $$\n    2. For each current state $(a, y)$, solve the maximization problem on the right-hand side of the Bellman equation. The choice of next-period assets $a'$ is restricted to the discrete grid $\\mathcal{A}$.\n       $$\n       V^{k+1}(a,y) = \\max_{a' \\in \\mathcal{A}, a' \\le Ra+y} \\left\\{ u(Ra + y - a') + \\beta \\mathbb{E}[V^k(a',y') \\mid y] \\right\\}\n       $$\n       The constraint $a' \\le Ra+y$ ensures that consumption is non-negative.\n    3. The iteration stops when the value function has converged, i.e., when the maximum absolute difference between successive iterations is below a small tolerance $\\delta_V$: $\\sup_{a,y} |V^{k+1}(a,y) - V^k(a,y)| < \\delta_V$.\n\nThe output of the VFI algorithm is the converged value function $V(a,y)$ and the associated optimal policy function (or law of motion) $a'(a,y)$, which maps each state $(a,y)$ to the optimal choice of next-period assets. Since choices are discretized, $a'(a,y)$ will be a point on the grid $\\mathcal{A}$.\n\n**2. Stationary Distribution**\n\nThe combination of the exogenous income transitions $\\Pi$ and the endogenous asset choice from the policy function $a'(a,y)$ defines a Markov process on the joint discrete state space $\\mathcal{S} = \\mathcal{A} \\times \\{y_L, y_H\\}$. Let the size of this space be $N_s = N_a \\times 2$. We construct an $N_s \\times N_s$ transition probability matrix $\\mathbf{P}$.\n\nAn element $\\mathbf{P}_{ij}$ of this matrix gives the probability of moving from state $i$ to state $j$ in one period. Let state $i$ correspond to $(a_k, y_m)$ and state $j$ correspond to $(a_l, y_n)$. Given the policy $a'(a_k, y_m) = a_p$ (where $a_p$ is some point on the asset grid), the agent moves to asset level $a_p$ with certainty. The next-period income state will be $y_n$ with probability $\\Pi_{mn}$. Therefore, the transition probability is non-zero only if the destination asset level $a_l$ matches the policy-dictated level $a_p$.\n$$\n\\mathbf{P}((a_k, y_m) \\to (a_l, y_n)) =\n\\begin{cases}\n\\Pi_{mn} & \\text{if } a_l = a'(a_k, y_m) \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nThe stationary distribution $\\mu$ over the state space $\\mathcal{S}$ is the invariant distribution of this Markov process. It represents the long-run cross-sectional distribution of households over assets and income. It is the solution to the fixed-point problem $\\mu \\mathbf{P} = \\mu$, where $\\mu$ is a row vector of probabilities summing to $1$. We compute $\\mu$ by forward iteration: starting with an arbitrary initial distribution $\\mu_0$ (e.g., uniform), we repeatedly apply the transition matrix $\\mu_{t+1} = \\mu_t \\mathbf{P}$ until the distribution converges, i.e., $\\|\\mu_{t+1} - \\mu_t\\|_{\\infty} < \\delta_{\\mu}$ for a small tolerance $\\delta_{\\mu}$.\n\n**3. Simulation of the Shock**\n\nThe experiment involves a surprise, permanent increase in income risk. This is analyzed in three steps for each test case:\n\n- **Pre-shock Steady State:** First, we solve for the optimal policy $a'_{\\text{pre}}(a,y)$ and stationary distribution $\\mu^{\\text{pre}}$ using the pre-shock income process $(\\{y_L^{\\text{pre}}, y_H^{\\text{pre}}\\}, \\Pi^{\\text{pre}})$. From $\\mu^{\\text{pre}}$, we compute the aggregate (mean) assets in the pre-shock stationary equilibrium:\n  $$\n  A^{\\text{pre}} = \\sum_{(a,y) \\in \\mathcal{S}} a \\cdot \\mu^{\\text{pre}}(a,y)\n  $$\n\n- **Post-shock Steady State:** Second, we repeat the entire procedure for the post-shock environment $(\\{y_L^{\\text{post}}, y_H^{\\text{post}}\\}, \\Pi^{\\text{post}})$. This yields the post-shock policy $a'_{\\text{post}}(a,y)$, transition matrix $\\mathbf{P}_{\\text{post}}$, stationary distribution $\\mu^{\\text{post}}$, and stationary aggregate assets:\n  $$\n  A^{\\text{post}} = \\sum_{(a,y) \\in \\mathcal{S}} a \\cdot \\mu^{\\text{post}}(a,y)\n  $$\n  The increase in income risk (variance) with a constant mean, combined with prudent preferences ($u''' > 0$), leads to a stronger precautionary saving motive. We thus expect $A^{\\text{post}} > A^{\\text{pre}}$ when risk is higher post-shock.\n\n- **Transition Dynamics:** Third, we simulate the transition path of the economy's aggregate assets from the pre-shock to the post-shock steady state. At time $t=0$, the economy is in the pre-shock steady state, so the initial distribution is $\\mu_0 = \\mu^{\\text{pre}}$, and initial mean assets are $A_0 = A^{\\text{pre}}$. From $t=0$ onwards, households apply the new, optimal post-shock policy $a'_{\\text{post}}$, and the economy evolves according to the post-shock transition matrix $\\mathbf{P}_{\\text{post}}$. The distribution at any time $t+1$ is given by $\\mu_{t+1} = \\mu_t \\mathbf{P}_{\\text{post}}$. We track the sequence of aggregate assets $\\{A_t\\}_{t \\ge 0}$ where $A_t = \\sum a \\cdot \\mu_t(a,y)$.\n\nWe compute two quantities from this simulation:\n1.  The convergence time $T$, defined as the first non-negative integer time $t$ at which the aggregate asset level is within a tolerance $\\varepsilon$ of its new steady state:\n    $$\n    T = \\min \\{ t \\ge 0 \\mid |A_t - A^{\\text{post}}| \\le \\varepsilon \\}\n    $$\n    If this condition is not met by $T_{\\max}$, we report $T=T_{\\max}$. The check is performed starting from $t=0$.\n2.  The one-step impact response $\\Delta A_1$, defined as the change in aggregate assets in the first period after the shock:\n    $$\n    \\Delta A_1 = A_1 - A_0\n    $$\n    where $A_1$ is calculated from $\\mu_1 = \\mu_0 \\mathbf{P}_{\\text{post}}$. This quantity measures the immediate aggregate response to the change in incentives.\n\nThe entire procedure is applied to each of the three test cases specified in the problem statement. The results are then formatted as requested.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n\n    def get_utility(c, sigma):\n        \"\"\"Computes CRRA utility, handling non-positive consumption.\"\"\"\n        utility = np.full_like(c, -np.inf)\n        positive_c = c > 0\n        if sigma == 1.0:\n            utility[positive_c] = np.log(c[positive_c])\n        else:\n            utility[positive_c] = (c[positive_c]**(1 - sigma)) / (1 - sigma)\n        return utility\n\n    def value_function_iteration(asset_grid, y, Pi, beta, R, sigma, tol=1e-8, max_iter=1000):\n        \"\"\"\n        Solves the household's dynamic programming problem using value function iteration.\n        \"\"\"\n        Na = len(asset_grid)\n        Ny = len(y)\n        V = np.zeros((Na, Ny))\n        policy_idx = np.zeros((Na, Ny), dtype=int)\n\n        for it in range(max_iter):\n            V_new = np.zeros_like(V)\n            # Expected continuation value: E[V] = beta * V * Pi^T\n            continuation_V = beta * V @ Pi.T\n\n            # For each state (a, y), find optimal a'\n            for i_a in range(Na):\n                for i_y in range(Ny):\n                    cash_on_hand = R * asset_grid[i_a] + y[i_y]\n                    \n                    # Available consumption for each choice of a'\n                    consumption = cash_on_hand - asset_grid\n                    \n                    # Current-period utility for each choice of a'\n                    utility = get_utility(consumption, sigma)\n\n                    # Total value for each choice of a'\n                    value_choices = utility + continuation_V[:, i_y]\n                    \n                    # Find optimal choice and value\n                    best_idx = np.argmax(value_choices)\n                    V_new[i_a, i_y] = value_choices[best_idx]\n                    policy_idx[i_a, i_y] = best_idx\n\n            diff = np.max(np.abs(V - V_new))\n            V = V_new\n            if diff < tol:\n                break\n        \n        return V, policy_idx\n\n    def build_transition_matrix(policy_idx, Pi, Na, Ny):\n        \"\"\"\n        Constructs the full Markov transition matrix over the joint state space.\n        \"\"\"\n        Ns = Na * Ny\n        P = np.zeros((Ns, Ns))\n        \n        for i_a in range(Na):      # Current asset index\n            for i_y in range(Ny):  # Current income index\n                current_state_idx = i_a + i_y * Na\n                next_a_idx = policy_idx[i_a, i_y]\n\n                for j_y in range(Ny): # Next income index\n                    next_state_idx = next_a_idx + j_y * Na\n                    prob = Pi[i_y, j_y]\n                    P[current_state_idx, next_state_idx] = prob\n        return P\n\n    def compute_stationary_distribution(P, tol=1e-10, max_iter=10000):\n        \"\"\"\n        Computes the stationary distribution by forward iteration (power method).\n        \"\"\"\n        Ns = P.shape[0]\n        mu = np.ones(Ns) / Ns  # Start with uniform distribution\n\n        for _ in range(max_iter):\n            mu_new = mu @ P\n            if np.max(np.abs(mu_new - mu)) < tol:\n                break\n            mu = mu_new\n        \n        # Ensure it's a valid probability distribution\n        mu /= np.sum(mu)\n        return mu\n\n    def solve_one_case(params):\n        \"\"\"\n        Solves for one complete test case.\n        \"\"\"\n        beta, r, sigma, a_underline, a_bar, Na, y_pre, Pi_pre, y_post, Pi_post, epsilon, T_max = params\n        R = 1 + r\n\n        # Common asset grid and state vector\n        asset_grid = np.linspace(a_underline, a_bar, Na)\n        asset_state_vector = np.tile(asset_grid, 2) # For [a_grid_yL, a_grid_yH]\n\n        # --- Pre-shock analysis ---\n        _, policy_pre = value_function_iteration(asset_grid, y_pre, Pi_pre, beta, R, sigma)\n        P_pre = build_transition_matrix(policy_pre, Pi_pre, Na, 2)\n        mu_pre = compute_stationary_distribution(P_pre)\n        A_pre = np.dot(mu_pre, asset_state_vector)\n\n        # --- Post-shock analysis ---\n        _, policy_post = value_function_iteration(asset_grid, y_post, Pi_post, beta, R, sigma)\n        P_post = build_transition_matrix(policy_post, Pi_post, Na, 2)\n        mu_post = compute_stationary_distribution(P_post)\n        A_post = np.dot(mu_post, asset_state_vector)\n\n        # --- Transition dynamics ---\n        mu_0 = mu_pre\n        A_0 = A_pre\n        \n        # Calculate T\n        T = T_max\n        if np.abs(A_0 - A_post) <= epsilon:\n            T = 0\n        else:\n            mu_t = mu_0\n            for t in range(T_max):\n                mu_t = mu_t @ P_post\n                A_t = np.dot(mu_t, asset_state_vector)\n                if np.abs(A_t - A_post) <= epsilon:\n                    T = t + 1\n                    break\n        \n        # Calculate Delta A_1\n        mu_1 = mu_0 @ P_post\n        A_1 = np.dot(mu_1, asset_state_vector)\n        delta_A_1 = A_1 - A_0\n\n        return [\n            round(A_pre, 6),\n            round(A_post, 6),\n            T,\n            round(delta_A_1, 6)\n        ]\n\n    # Test suite parameters\n    common_params_case12 = {\n        'beta': 0.96, 'r': 0.02, 'a_underline': 0.0, 'a_bar': 50.0,\n        'Na': 151, 'epsilon': 1e-6, 'T_max': 5000\n    }\n    Pi_matrix = np.array([[0.9, 0.1], [0.1, 0.9]])\n\n    test_cases = [\n        # Case 1: Happy path, stronger risk\n        (\n            common_params_case12['beta'], common_params_case12['r'], 2.0,\n            common_params_case12['a_underline'], common_params_case12['a_bar'], common_params_case12['Na'],\n            np.array([0.8, 1.2]), Pi_matrix,\n            np.array([0.6, 1.4]), Pi_matrix,\n            common_params_case12['epsilon'], common_params_case12['T_max']\n        ),\n        # Case 2: Consistency check, no change\n        (\n            common_params_case12['beta'], common_params_case12['r'], 2.0,\n            common_params_case12['a_underline'], common_params_case12['a_bar'], common_params_case12['Na'],\n            np.array([0.8, 1.2]), Pi_matrix,\n            np.array([0.8, 1.2]), Pi_matrix, # Post = Pre\n            common_params_case12['epsilon'], common_params_case12['T_max']\n        ),\n        # Case 3: Log utility, stronger risk\n        (\n            common_params_case12['beta'], common_params_case12['r'], 1.0,\n            common_params_case12['a_underline'], common_params_case12['a_bar'], common_params_case12['Na'],\n            np.array([0.85, 1.15]), Pi_matrix,\n            np.array([0.65, 1.35]), Pi_matrix,\n            common_params_case12['epsilon'], common_params_case12['T_max']\n        ),\n    ]\n\n    results = [solve_one_case(case) for case in test_cases]\n    \n    # Format a list of lists into the required string representation\n    result_str = '[' + ','.join([f\"[{r[0]},{r[1]},{r[2]},{r[3]}]\" for r in results]) + ']'\n    print(result_str)\n\nsolve()\n```"}]}