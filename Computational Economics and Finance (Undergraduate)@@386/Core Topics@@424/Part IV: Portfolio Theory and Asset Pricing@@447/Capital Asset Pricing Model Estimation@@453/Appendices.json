{"hands_on_practices": [{"introduction": "The first step in empirical finance is translating theoretical models into working code. This exercise focuses on the core of Capital Asset Pricing Model (CAPM) estimation: Ordinary Least Squares (OLS). By implementing the OLS estimator for $\\alpha$ and $\\beta$ from first principles, you will find the line of best fit that minimizes the sum of squared errors. Mastering this fundamental practice [@problem_id:2378983] demystifies the estimation process, providing a solid foundation before using pre-built statistical packages or tackling more advanced topics.", "id": "2378983", "problem": "You are given multiple samples of time series data for an asset, the market, and the risk-free rate. For each sample, assume the Capital Asset Pricing Model (CAPM) holds in the form\n$$\nr_{i,t} - r_{f,t} = \\alpha + \\beta \\left(r_{m,t} - r_{f,t}\\right) + \\varepsilon_t,\n$$\nfor periods indexed by $t = 1, \\ldots, T$, where $r_{i,t}$ is the asset’s return, $r_{m,t}$ is the market return, $r_{f,t}$ is the risk-free return, $\\alpha$ is the intercept, $\\beta$ is the slope on the market’s excess return, and $\\varepsilon_t$ is the residual. All returns are provided as decimals, not percentages.\n\nYour task is to compute, for each sample, the pair of parameters $(\\hat{\\alpha}, \\hat{\\beta})$ that minimize the sum of squared residuals\n$$\n\\sum_{t=1}^{T} \\left[\\left(r_{i,t} - r_{f,t}\\right) - \\left(\\alpha + \\beta \\left(r_{m,t} - r_{f,t}\\right)\\right)\\right]^2.\n$$\n\nUse the following test suite. For each test case, $r_i$ denotes the asset return series, $r_m$ denotes the market return series, and $r_f$ denotes the risk-free return series. Each series is given as an ordered list of length $T$.\n\n- Test Case 1 (general case, $T=5$):\n  - $r_m = [\\,0.012,\\, 0.018,\\, -0.005,\\, 0.010,\\, 0.022\\,]$\n  - $r_f = [\\,0.002,\\, 0.002,\\, 0.002,\\, 0.0025,\\, 0.0025\\,]$\n  - $r_i = [\\,0.015,\\, 0.0222,\\, -0.0054,\\, 0.0125,\\, 0.0269\\,]$\n\n- Test Case 2 (boundary with minimal observations, $T=2$):\n  - $r_m = [\\,0.02,\\, 0.05\\,]$\n  - $r_f = [\\,0.0,\\, 0.0\\,]$\n  - $r_i = [\\,0.07,\\, 0.16\\,]$\n\n- Test Case 3 (zero intercept, varying risk-free rate, $T=4$):\n  - $r_m = [\\,0.01,\\, 0.00,\\, 0.03,\\, -0.02\\,]$\n  - $r_f = [\\,0.002,\\, 0.002,\\, 0.0025,\\, 0.0015\\,]$\n  - $r_i = [\\,0.014,\\, -0.001,\\, 0.04375,\\, -0.03075\\,]$\n\n- Test Case 4 (negative intercept and slope, $T=3$):\n  - $r_m = [\\,0.015,\\, -0.010,\\, 0.005\\,]$\n  - $r_f = [\\,0.001,\\, 0.0015,\\, 0.001\\,]$\n  - $r_i = [\\,-0.008,\\, 0.00525,\\, -0.003\\,]$\n\nFor each test case, compute the estimates $(\\hat{\\alpha}, \\hat{\\beta})$ using the above criterion. Express all returns and results as decimals (no percentage signs). Your program should produce a single line of output containing the results for the four test cases as a list of lists, with each inner list containing $[\\hat{\\alpha}, \\hat{\\beta}]$ rounded to six decimal places, in the order of the test cases. The exact required output format is:\n$$\n[[\\hat{\\alpha}_1,\\hat{\\beta}_1],[\\hat{\\alpha}_2,\\hat{\\beta}_2],[\\hat{\\alpha}_3,\\hat{\\beta}_3],[\\hat{\\alpha}_4,\\hat{\\beta}_4]]\n$$\nprinted on a single line with commas separating values and lists, and with each float shown using exactly six digits after the decimal point.", "solution": "The problem presented is a standard exercise in econometrics, requiring the estimation of parameters for the Capital Asset Pricing Model (CAPM) using the method of Ordinary Least Squares (OLS). I will first validate the problem statement according to the required protocol.\n\n### Step 1: Extract Givens\n\nThe problem provides the following:\n\n- The CAPM equation:\n$$\nr_{i,t} - r_{f,t} = \\alpha + \\beta \\left(r_{m,t} - r_{f,t}\\right) + \\varepsilon_t\n$$\nwhere $t = 1, \\ldots, T$. The variables are defined as the asset’s return ($r_{i,t}$), the market return ($r_{m,t}$), the risk-free return ($r_{f,t}$), the intercept ($\\alpha$), the slope ($\\beta$), and the residual ($\\varepsilon_t$).\n\n- The objective function to be minimized is the sum of squared residuals (SSR):\n$$\n\\sum_{t=1}^{T} \\left[\\left(r_{i,t} - r_{f,t}\\right) - \\left(\\alpha + \\beta \\left(r_{m,t} - r_{f,t}\\right)\\right)\\right]^2\n$$\n\n- Four test cases with time series data for $r_m$, $r_f$, and $r_i$:\n  - Test Case 1 ($T=5$):\n    - $r_m = [\\,0.012,\\, 0.018,\\, -0.005,\\, 0.010,\\, 0.022\\,]$\n    - $r_f = [\\,0.002,\\, 0.002,\\, 0.002,\\, 0.0025,\\, 0.0025\\,]$\n    - $r_i = [\\,0.015,\\, 0.0222,\\, -0.0054,\\, 0.0125,\\, 0.0269\\,]$\n  - Test Case 2 ($T=2$):\n    - $r_m = [\\,0.02,\\, 0.05\\,]$\n    - $r_f = [\\,0.0,\\, 0.0\\,]$\n    - $r_i = [\\,0.07,\\, 0.16\\,]$\n  - Test Case 3 ($T=4$):\n    - $r_m = [\\,0.01,\\, 0.00,\\, 0.03,\\, -0.02\\,]$\n    - $r_f = [\\,0.002,\\, 0.002,\\, 0.0025,\\, 0.0015\\,]$\n    - $r_i = [\\,0.014,\\, -0.001,\\, 0.04375,\\, -0.03075\\,]$\n  - Test Case 4 ($T=3$):\n    - $r_m = [\\,0.015,\\, -0.010,\\, 0.005\\,]$\n    - $r_f = [\\,0.001,\\, 0.0015,\\, 0.001\\,]$\n    - $r_i = [\\,-0.008,\\, 0.00525,\\, -0.003\\,]$\n\n- The required output is a single-line string representing a list of lists, with each inner list containing the estimated parameters $[\\hat{\\alpha}, \\hat{\\beta}]$ rounded to six decimal places.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is subjected to validation against the established criteria.\n\n- **Scientifically Grounded**: The problem is an application of linear regression, a fundamental statistical method, to the CAPM, a cornerstone model in financial economics. It is scientifically sound and a classic example in the field.\n- **Well-Posed**: The problem is to find parameters that minimize a sum of squares, which defines a standard Ordinary Least Squares (OLS) estimation. A unique solution for $(\\hat{\\alpha}, \\hat{\\beta})$ exists if and only if the independent variable (market excess return) is not constant. For all given test cases, the market excess return series exhibits variation, thus ensuring the existence of a unique solution. The case where $T=2$ (Test Case 2) is a boundary condition where the two parameters are determined exactly by the two data points, which is a well-defined mathematical problem.\n- **Objective**: The problem is formulated with precise mathematical equations and objective numerical data. There are no subjective or ambiguous statements.\n- **Incomplete or Contradictory Setup**: The problem is self-contained. All necessary data and definitions are provided. There are no contradictions.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is a clear, consistent, and well-posed problem grounded in established financial and statistical theory. I will now proceed with the solution.\n\n### Solution Derivation\n\nThe problem is to find the parameters $\\hat{\\alpha}$ and $\\hat{\\beta}$ by minimizing the sum of squared residuals. This is a classic application of Ordinary Least Squares (OLS). Let us define the excess asset return as $y_t = r_{i,t} - r_{f,t}$ and the excess market return as $x_t = r_{m,t} - r_{f,t}$. The model simplifies to a simple linear regression:\n$$\ny_t = \\alpha + \\beta x_t + \\varepsilon_t\n$$\nThe objective is to minimize the sum of squared residuals, $S(\\alpha, \\beta)$:\n$$\nS(\\alpha, \\beta) = \\sum_{t=1}^{T} \\varepsilon_t^2 = \\sum_{t=1}^{T} (y_t - \\alpha - \\beta x_t)^2\n$$\nTo find the minimum, we take the first-order partial derivatives of $S$ with respect to $\\alpha$ and $\\beta$ and set them to zero.\n\nThe partial derivative with respect to $\\alpha$:\n$$\n\\frac{\\partial S}{\\partial \\alpha} = \\sum_{t=1}^{T} 2(y_t - \\alpha - \\beta x_t)(-1) = -2 \\left( \\sum_{t=1}^{T} y_t - T\\alpha - \\beta \\sum_{t=1}^{T} x_t \\right) = 0\n$$\nThis simplifies to the first normal equation:\n$$\n\\sum_{t=1}^{T} y_t = T\\hat{\\alpha} + \\hat{\\beta} \\sum_{t=1}^{T} x_t\n$$\nDividing by $T$, we get $\\bar{y} = \\hat{\\alpha} + \\hat{\\beta}\\bar{x}$, where $\\bar{y}$ and $\\bar{x}$ are the sample means of $y_t$ and $x_t$, respectively. This allows us to express $\\hat{\\alpha}$ as:\n$$\n\\hat{\\alpha} = \\bar{y} - \\hat{\\beta}\\bar{x}\n$$\n\nThe partial derivative with respect to $\\beta$:\n$$\n\\frac{\\partial S}{\\partial \\beta} = \\sum_{t=1}^{T} 2(y_t - \\alpha - \\beta x_t)(-x_t) = -2 \\left( \\sum_{t=1}^{T} x_t y_t - \\alpha \\sum_{t=1}^{T} x_t - \\beta \\sum_{t=1}^{T} x_t^2 \\right) = 0\n$$\nThis simplifies to the second normal equation:\n$$\n\\sum_{t=1}^{T} x_t y_t = \\hat{\\alpha} \\sum_{t=1}^{T} x_t + \\hat{\\beta} \\sum_{t=1}^{T} x_t^2\n$$\nSubstituting the expression for $\\hat{\\alpha}$ into the second normal equation:\n$$\n\\sum x_t y_t = (\\bar{y} - \\hat{\\beta}\\bar{x}) \\sum x_t + \\hat{\\beta} \\sum x_t^2\n$$\n$$\n\\sum x_t y_t = \\bar{y} \\sum x_t - \\hat{\\beta}\\bar{x} \\sum x_t + \\hat{\\beta} \\sum x_t^2\n$$\nRearranging to solve for $\\hat{\\beta}$:\n$$\n\\hat{\\beta} \\left( \\sum x_t^2 - \\bar{x} \\sum x_t \\right) = \\sum x_t y_t - \\bar{y} \\sum x_t\n$$\nUsing $\\sum x_t = T\\bar{x}$, we have:\n$$\n\\hat{\\beta} \\left( \\sum x_t^2 - T\\bar{x}^2 \\right) = \\sum x_t y_t - T\\bar{x}\\bar{y}\n$$\nThe terms in parentheses are the numerators of the sample variance and covariance, respectively (without the $1/T$ or $1/(T-1)$ scaling factor). Specifically, $\\sum(x_t-\\bar{x})^2 = \\sum x_t^2 - T\\bar{x}^2$ and $\\sum(x_t-\\bar{x})(y_t-\\bar{y}) = \\sum x_t y_t - T\\bar{x}\\bar{y}$. Thus, the estimator for $\\beta$ is given by the well-known formula:\n$$\n\\hat{\\beta} = \\frac{\\sum_{t=1}^{T} (x_t - \\bar{x})(y_t - \\bar{y})}{\\sum_{t=1}^{T} (x_t - \\bar{x})^2} = \\frac{\\text{Cov}(x, y)}{\\text{Var}(x)}\n$$\nThe algorithm will be implemented by first calculating the series $x_t$ and $y_t$ for each test case. Then, the sample means $\\bar{x}$ and $\\bar{y}$ are computed. Finally, $\\hat{\\beta}$ is calculated using the covariance-variance formula, and $\\hat{\\alpha}$ is found using its relationship with the means and $\\hat{\\beta}$. This procedure will be applied to each of the four test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the CAPM parameters alpha and beta for multiple test cases\n    using Ordinary Least Squares (OLS).\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1 (general case, T=5)\n        {\n            'r_m': np.array([0.012, 0.018, -0.005, 0.010, 0.022]),\n            'r_f': np.array([0.002, 0.002, 0.002, 0.0025, 0.0025]),\n            'r_i': np.array([0.015, 0.0222, -0.0054, 0.0125, 0.0269])\n        },\n        # Test Case 2 (boundary with minimal observations, T=2)\n        {\n            'r_m': np.array([0.02, 0.05]),\n            'r_f': np.array([0.0, 0.0]),\n            'r_i': np.array([0.07, 0.16])\n        },\n        # Test Case 3 (zero intercept, varying risk-free rate, T=4)\n        {\n            'r_m': np.array([0.01, 0.00, 0.03, -0.02]),\n            'r_f': np.array([0.002, 0.002, 0.0025, 0.0015]),\n            'r_i': np.array([0.014, -0.001, 0.04375, -0.03075])\n        },\n        # Test Case 4 (negative intercept and slope, T=3)\n        {\n            'r_m': np.array([0.015, -0.010, 0.005]),\n            'r_f': np.array([0.001, 0.0015, 0.001]),\n            'r_i': np.array([-0.008, 0.00525, -0.003])\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        r_m, r_f, r_i = case['r_m'], case['r_f'], case['r_i']\n\n        # Calculate excess returns\n        # y_t = r_i,t - r_f,t (dependent variable)\n        y = r_i - r_f\n        # x_t = r_m,t - r_f,t (independent variable)\n        x = r_m - r_f\n\n        # Calculate sample means\n        x_bar = np.mean(x)\n        y_bar = np.mean(y)\n\n        # Calculate the OLS estimator for beta (slope)\n        # beta_hat = Cov(x, y) / Var(x)\n        # Numerator: sum of cross-products of deviations from mean\n        numerator = np.sum((x - x_bar) * (y - y_bar))\n        # Denominator: sum of squared deviations from mean for x\n        denominator = np.sum((x - x_bar)**2)\n        \n        # Handle the edge case of T=2 where the fit is perfect but division by zero could occur if x values were identical.\n        # The problem validation confirmed this is not an issue for the given test cases.\n        beta_hat = numerator / denominator\n\n        # Calculate the OLS estimator for alpha (intercept)\n        # alpha_hat = y_bar - beta_hat * x_bar\n        alpha_hat = y_bar - beta_hat * x_bar\n\n        results.append([alpha_hat, beta_hat])\n\n    # Format the final output string exactly as required.\n    # The format [v1,v2] does not have a space after the comma.\n    # Using f-strings with a format specifier ensures exactly six decimal places.\n    formatted_results = []\n    for alpha, beta in results:\n        formatted_results.append(f\"[{alpha:.6f},{beta:.6f}]\")\n    \n    final_output_string = f\"[{','.join(formatted_results)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```"}, {"introduction": "Once we have our CAPM estimates, a natural question is how to use them to evaluate an investment's performance. This practice introduces the Information Ratio (IR), a key metric for assessing a portfolio manager's skill. The IR measures the risk-adjusted excess return generated by active management, captured by the CAPM alpha ($ \\alpha $), relative to the volatility of those specific returns, known as idiosyncratic risk ($ \\sigma_{\\epsilon} $). By calculating the IR [@problem_id:2379003], you will learn to connect the statistical outputs of a CAPM regression to a tangible and widely used measure of investment performance.", "id": "2379003", "problem": "A portfolio manager evaluates a portfolio against the market using the Capital Asset Pricing Model (CAPM). Let the monthly excess return of the portfolio be denoted by $y_t$ and the monthly excess return of the market by $x_t$. Over six consecutive months $t=1,\\dots,6$, you observe the following data (returns are decimals, not percentages):\n- Portfolio excess returns: $(y_1,\\dots,y_6) = (0.014,\\; 0.023,\\; -0.0085,\\; 0.0015,\\; 0.035,\\; -0.020)$\n- Market excess returns: $(x_1,\\dots,x_6) = (0.01,\\; 0.02,\\; -0.01,\\; 0.00,\\; 0.03,\\; -0.02)$\n\nAssume the linear CAPM regression holds at the monthly frequency,\n$$\ny_t \\;=\\; \\alpha \\;+\\; \\beta\\, x_t \\;+\\; \\epsilon_t,\n$$\nwhere $\\alpha$ is the CAPM alpha, $\\beta$ is the market beta, and $\\epsilon_t$ is the idiosyncratic disturbance with $\\mathbb{E}[\\epsilon_t]=0$ and $\\operatorname{Var}(\\epsilon_t)=\\sigma_{\\epsilon}^{2}$, satisfying the classical linear regression assumptions. Using the unbiased estimator for the disturbance variance with $T-2$ degrees of freedom (where $T$ is the number of observations), compute the Information Ratio (IR), defined here as the ratio of the CAPM alpha to the idiosyncratic standard deviation,\n$$\n\\text{IR} \\;=\\; \\frac{\\alpha}{\\sigma_{\\epsilon}}.\n$$\nExpress the final number as a decimal with no units, and round your answer to three significant figures.", "solution": "The problem requires the computation of the Information Ratio (IR) for a portfolio, which is defined as the ratio of the estimated Capital Asset Pricing Model (CAPM) alpha, $\\hat{\\alpha}$, to the estimated standard deviation of the idiosyncratic residuals, $\\hat{\\sigma}_{\\epsilon}$. The analysis is based on a simple linear regression model for monthly excess returns:\n$$\ny_t = \\alpha + \\beta x_t + \\epsilon_t\n$$\nwhere $y_t$ is the portfolio's excess return, $x_t$ is the market's excess return, and $\\epsilon_t$ is a disturbance term. We are given $T=6$ monthly observations for $y_t$ and $x_t$.\n\nThe estimation of the parameters $\\alpha$ and $\\beta$ is performed using the method of Ordinary Least Squares (OLS). The OLS estimators, denoted by $\\hat{\\alpha}$ and $\\hat{\\beta}$, are given by:\n$$\n\\hat{\\beta} = \\frac{\\sum_{t=1}^{T} (x_t - \\bar{x})(y_t - \\bar{y})}{\\sum_{t=1}^{T} (x_t - \\bar{x})^2}\n$$\n$$\n\\hat{\\alpha} = \\bar{y} - \\hat{\\beta} \\bar{x}\n$$\nwhere $\\bar{x}$ and $\\bar{y}$ are the sample means of the observations.\n\nFirst, we compute the necessary summary statistics from the provided data:\nThe number of observations is $T=6$.\nThe portfolio excess returns are $y = (0.014, 0.023, -0.0085, 0.0015, 0.035, -0.020)$.\nThe market excess returns are $x = (0.01, 0.02, -0.01, 0.00, 0.03, -0.02)$.\n\nThe sum of portfolio excess returns is:\n$$\n\\sum_{t=1}^{6} y_t = 0.014 + 0.023 - 0.0085 + 0.0015 + 0.035 - 0.020 = 0.045\n$$\nThe sample mean of portfolio excess returns is:\n$$\n\\bar{y} = \\frac{1}{T} \\sum_{t=1}^{T} y_t = \\frac{0.045}{6} = 0.0075\n$$\nThe sum of market excess returns is:\n$$\n\\sum_{t=1}^{6} x_t = 0.01 + 0.02 - 0.01 + 0.00 + 0.03 - 0.02 = 0.03\n$$\nThe sample mean of market excess returns is:\n$$\n\\bar{x} = \\frac{1}{T} \\sum_{t=1}^{T} x_t = \\frac{0.03}{6} = 0.005\n$$\n\nNext, we calculate the sum of squared deviations for $x_t$ and the sum of cross-products:\n$$\n\\sum_{t=1}^{6} (x_t - \\bar{x})^2 = (0.01-0.005)^2 + (0.02-0.005)^2 + (-0.01-0.005)^2 + (0.00-0.005)^2 + (0.03-0.005)^2 + (-0.02-0.005)^2\n$$\n$$\n= (0.005)^2 + (0.015)^2 + (-0.015)^2 + (-0.005)^2 + (0.025)^2 + (-0.025)^2\n$$\n$$\n= 0.000025 + 0.000225 + 0.000225 + 0.000025 + 0.000625 + 0.000625 = 0.00175\n$$\n$$\n\\sum_{t=1}^{6} (x_t - \\bar{x})(y_t - \\bar{y}) = (0.005)(0.014 - 0.0075) + (0.015)(0.023 - 0.0075) + (-0.015)(-0.0085 - 0.0075) + (-0.005)(0.0015 - 0.0075) + (0.025)(0.035 - 0.0075) + (-0.025)(-0.020 - 0.0075)\n$$\n$$\n= (0.005)(0.0065) + (0.015)(0.0155) + (-0.015)(-0.016) + (-0.005)(-0.006) + (0.025)(0.0275) + (-0.025)(-0.0275)\n$$\n$$\n= 0.0000325 + 0.0002325 + 0.00024 + 0.00003 + 0.0006875 + 0.0006875 = 0.00191\n$$\nNow we can compute the OLS estimates for $\\beta$ and $\\alpha$:\n$$\n\\hat{\\beta} = \\frac{0.00191}{0.00175} = \\frac{191}{175} \\approx 1.09142857\n$$\n$$\n\\hat{\\alpha} = \\bar{y} - \\hat{\\beta}\\bar{x} = 0.0075 - \\left(\\frac{191}{175}\\right) (0.005) = 0.0075 - \\frac{0.955}{175} = \\frac{1.3125 - 0.955}{175} = \\frac{0.3575}{175} \\approx 0.00204286\n$$\nThe next step is to compute the unbiased estimator for the variance of the residuals, $\\sigma_{\\epsilon}^2$. The sum of squared residuals (RSS) is first required:\n$$\n\\text{RSS} = \\sum_{t=1}^{T} \\hat{\\epsilon}_t^2 = \\sum_{t=1}^{T} (y_t - \\hat{y}_t)^2\n$$\nA computationally convenient formula for RSS is:\n$$\n\\text{RSS} = \\sum_{t=1}^{T} (y_t - \\bar{y})^2 - \\hat{\\beta} \\sum_{t=1}^{T} (x_t - \\bar{x})(y_t - \\bar{y})\n$$\nWe need $\\sum(y_t - \\bar{y})^2$:\n$$\n\\sum_{t=1}^{6} (y_t - \\bar{y})^2 = (0.0065)^2 + (0.0155)^2 + (-0.016)^2 + (-0.006)^2 + (0.0275)^2 + (-0.0275)^2\n$$\n$$\n= 0.00004225 + 0.00024025 + 0.000256 + 0.000036 + 0.00075625 + 0.00075625 = 0.002087\n$$\nNow, we calculate RSS:\n$$\n\\text{RSS} = 0.002087 - \\left(\\frac{191}{175}\\right) (0.00191) = 0.002087 - \\frac{0.0036481}{1.75} \\approx 0.002087 - 0.0020846286 = 0.0000023714\n$$\nThe problem specifies using the unbiased estimator for the disturbance variance with $T-2$ degrees of freedom. Here, $T-2 = 6-2=4$.\n$$\n\\hat{\\sigma}_{\\epsilon}^2 = \\frac{\\text{RSS}}{T-2} = \\frac{0.0000023714}{4} \\approx 0.00000059285\n$$\nThe standard deviation of the idiosyncratic disturbance is the square root of the variance:\n$$\n\\hat{\\sigma}_{\\epsilon} = \\sqrt{\\hat{\\sigma}_{\\epsilon}^2} = \\sqrt{0.00000059285} \\approx 0.00076997\n$$\nFinally, we can compute the Information Ratio (IR):\n$$\n\\text{IR} = \\frac{\\hat{\\alpha}}{\\hat{\\sigma}_{\\epsilon}} = \\frac{0.00204286}{0.00076997} \\approx 2.65315\n$$\nRounding the result to three significant figures, we obtain $2.65$.", "answer": "$$\\boxed{2.65}$$"}, {"introduction": "The classical assumptions of OLS are often too idealistic for real financial time series, which frequently exhibit characteristics like autocorrelation. This exercise demonstrates how to diagnose and address such issues to ensure the reliability of your statistical inference. You will learn to test for autocorrelation in the regression residuals and apply the Newey-West procedure to compute Heteroskedasticity and Autocorrelation Consistent (HAC) standard errors. This advanced practice [@problem_id:2378979] equips you with the essential tools to work with more realistic data and avoid common pitfalls in empirical finance.", "id": "2378979", "problem": "You are given the task of assessing the validity of the Capital Asset Pricing Model (CAPM) for a single asset by estimating its intercept and slope parameters and evaluating residual autocorrelation. Consider the excess return model defined by the CAPM equation\n$$\ny_t = \\alpha + \\beta m_t + \\varepsilon_t,\n$$\nwhere $y_t$ is the asset excess return at time $t$, $m_t$ is the market excess return at time $t$, $\\alpha$ is the intercept, $\\beta$ is the market loading, and $\\varepsilon_t$ is the error term. All returns must be interpreted in decimal form.\n\nFor each test case specified below, you must simulate the processes for $\\{m_t\\}_{t=1}^T$ and $\\{\\varepsilon_t\\}_{t=1}^T$, construct $\\{y_t\\}_{t=1}^T$, and then:\n1. Estimate $\\alpha$ and $\\beta$ via ordinary least squares using the $T \\times 2$ regressor matrix $X$ with a column of ones and the observed $m_t$.\n2. Test the null hypothesis that the residuals $\\{\\hat{\\varepsilon}_t\\}$ are not autocorrelated up to lag $h$, using the large-sample chi-squared test with $h$ degrees of freedom based on the sample residual autocorrelations $\\{\\hat{r}_k\\}_{k=1}^h$.\n3. Compute the conventional ordinary least squares standard errors for $\\alpha$ and $\\beta$.\n4. Compute the Newey–West heteroskedasticity-and-autocorrelation-consistent standard errors for $\\alpha$ and $\\beta$ using the Bartlett kernel with truncation lag $L$.\n\nAll simulations must use a deterministic pseudo-random number generator with the specified seed per test case. For each test case, simulate according to the following general data-generating process. The market excess return $\\{m_t\\}$ follows\n$$\nm_t = \\mu_m + \\phi_m m_{t-1} + \\sigma_m z_t, \\quad m_0 = 0,\n$$\nand the idiosyncratic component $\\{u_t\\}$ follows\n$$\nu_t = \\rho\\, u_{t-1} + \\sigma_\\varepsilon w_t, \\quad u_0 = 0,\n$$\nwith $z_t$ and $w_t$ independent and identically distributed standard normal shocks, independent across $t$ and between sequences. The CAPM error is specified as\n$$\n\\varepsilon_t =\n\\begin{cases}\nu_t, & \\text{if } \\kappa = 0,\\\\\n\\left(1 + \\kappa \\lvert m_t \\rvert \\right) u_t, & \\text{if } \\kappa > 0.\n\\end{cases}\n$$\nThe observed asset excess return is then $y_t = \\alpha + \\beta m_t + \\varepsilon_t$. The risk-free rate is identically zero in all test cases.\n\nShock generation order must be fixed for reproducibility: for each $t$ from $1$ to $T$, first draw $z_t$ to update $m_t$, then draw $w_t$ to update $u_t$, and finally form $\\varepsilon_t$ and $y_t$. The pseudo-random generator must be initialized with the exact seed specified in each test case before generating any shocks, and all random draws must use that single generator in the stated order.\n\nUse the following test suite of parameter values, which together exercise typical, boundary, and edge-case behaviors. In each case, all parameters are scalars in decimal units, and $\\mu_m = 0$.\n\n- Case A (happy path, no residual autocorrelation): $T = 500$, $\\alpha = 0.001$, $\\beta = 1.2$, $\\phi_m = 0.1$, $\\sigma_m = 0.04$, $\\rho = 0$, $\\sigma_\\varepsilon = 0.02$, $\\kappa = 0$, $h = 4$, $L = 4$, seed $= 20240514$.\n- Case B (strong residual autocorrelation): $T = 500$, $\\alpha = 0.001$, $\\beta = 1.2$, $\\phi_m = 0.1$, $\\sigma_m = 0.04$, $\\rho = 0.6$, $\\sigma_\\varepsilon = 0.02$, $\\kappa = 0$, $h = 4$, $L = 4$, seed $= 20240515$.\n- Case C (small sample, moderate autocorrelation): $T = 60$, $\\alpha = 0.001$, $\\beta = 1.2$, $\\phi_m = 0.2$, $\\sigma_m = 0.05$, $\\rho = 0.5$, $\\sigma_\\varepsilon = 0.02$, $\\kappa = 0$, $h = 4$, $L = 4$, seed $= 20240516$.\n- Case D (heteroskedastic and autocorrelated errors): $T = 500$, $\\alpha = 0.001$, $\\beta = 1.2$, $\\phi_m = 0.1$, $\\sigma_m = 0.04$, $\\rho = 0.3$, $\\sigma_\\varepsilon = 0.02$, $\\kappa = 0.8$, $h = 4$, $L = 4$, seed $= 20240517$.\n\nYour program must compute, for each case, the following seven outputs in this exact order: the estimated $\\alpha$, the estimated $\\beta$, the ordinary least squares standard error of $\\alpha$, the ordinary least squares standard error of $\\beta$, the Newey–West standard error of $\\alpha$, the Newey–West standard error of $\\beta$, and a boolean indicating whether the null hypothesis of no autocorrelation up to lag $h$ is rejected at significance level $0.05$.\n\nFinal output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a list in the order described above for the corresponding test case, with all floating-point values rounded to six decimal places. For example, the overall format must be\n$$\n\\left[ [\\alpha_1,\\beta_1,se^{\\mathrm{OLS}}_{\\alpha,1},se^{\\mathrm{OLS}}_{\\beta,1},se^{\\mathrm{NW}}_{\\alpha,1},se^{\\mathrm{NW}}_{\\beta,1},\\mathrm{Reject}_1], \\ldots \\right].\n$$", "solution": "The problem presented is a well-posed exercise in computational econometrics, specifically concerning the estimation of the Capital Asset Pricing Model (CAPM). It requires the simulation of financial time series data under different assumptions about the error structure, followed by the estimation of model parameters and a critical evaluation of the estimator's properties. The problem is scientifically sound, fully specified, and objective. We shall proceed with a detailed, principle-based solution.\n\nThe CAPM specifies a linear relationship between an asset's excess return, $y_t$, and the market's excess return, $m_t$:\n$$\ny_t = \\alpha + \\beta m_t + \\varepsilon_t\n$$\nwhere $t = 1, \\dots, T$ indexes time. The parameter $\\alpha$ is the asset's \"alpha,\" representing the excess return not explained by the market. The parameter $\\beta$ is the \"beta,\" measuring the asset's sensitivity to market movements. The term $\\varepsilon_t$ is the idiosyncratic error.\n\nThe first task is to simulate the time series $\\{y_t\\}_{t=1}^T$ and $\\{m_t\\}_{t=1}^T$ according to the provided data-generating process (DGP). For each test case, we must adhere strictly to the specified parameters and random number generator seed.\n\nThe market excess return, $\\{m_t\\}$, is generated by an autoregressive process of order one, AR($1$):\n$$\nm_t = \\phi_m m_{t-1} + \\sigma_m z_t, \\quad \\text{with } m_0 = 0\n$$\nwhere $\\{z_t\\}$ is a sequence of independent and identically distributed (i.i.d.) standard normal random variables.\n\nThe CAPM error term, $\\{\\varepsilon_t\\}$, is constructed from an underlying AR($1$) process, $\\{u_t\\}$:\n$$\nu_t = \\rho u_{t-1} + \\sigma_\\varepsilon w_t, \\quad \\text{with } u_0 = 0\n$$\nwhere $\\{w_t\\}$ is another i.i.d. standard normal sequence, independent of $\\{z_t\\}$. The structure of $\\varepsilon_t$ allows for conditional heteroskedasticity:\n$$\n\\varepsilon_t =\n\\begin{cases}\nu_t, & \\text{if } \\kappa = 0 \\text{ (homoskedasticity)},\\\\\n\\left(1 + \\kappa \\lvert m_t \\rvert \\right) u_t, & \\text{if } \\kappa > 0 \\text{ (heteroskedasticity)}.\n\\end{cases}\n$$\nWhen $\\kappa > 0$, the variance of the error term depends on the magnitude of the market return, a common feature in financial data.\n\nWith the simulated data, we perform the following estimations and tests.\n\n**1. Ordinary Least Squares (OLS) Estimation**\nThe parameters $\\alpha$ and $\\beta$ are estimated using OLS. We define the parameter vector $\\theta = [\\alpha, \\beta]^T$, the dependent variable vector $y = [y_1, \\dots, y_T]^T$, and the regressor matrix $X$, which is a $T \\times 2$ matrix with a column of ones and a column of market returns $\\{m_t\\}$.\n$$\nX = \\begin{bmatrix} 1 & m_1 \\\\ 1 & m_2 \\\\ \\vdots & \\vdots \\\\ 1 & m_T \\end{bmatrix}\n$$\nThe OLS estimator $\\hat{\\theta} = [\\hat{\\alpha}, \\hat{\\beta}]^T$ is given by the well-known formula:\n$$\n\\hat{\\theta} = (X^T X)^{-1} X^T y\n$$\n\n**2. OLS Standard Errors**\nUnder the classical OLS assumptions (including homoskedastic and non-autocorrelated errors, i.e., $\\mathbb{E}[\\varepsilon \\varepsilon^T | X] = \\sigma^2 I_T$), the covariance matrix of the estimator $\\hat{\\theta}$ is:\n$$\n\\text{Var}_{\\text{OLS}}(\\hat{\\theta}) = \\sigma^2 (X^T X)^{-1}\n$$\nThe error variance $\\sigma^2$ is unknown and is estimated from the residuals $\\hat{\\varepsilon}_t = y_t - \\hat{\\alpha} - \\hat{\\beta} m_t$. The unbiased estimator for $\\sigma^2$ is:\n$$\n\\hat{\\sigma}^2 = \\frac{1}{T-k} \\sum_{t=1}^T \\hat{\\varepsilon}_t^2\n$$\nwhere $k=2$ is the number of regressors. The estimated covariance matrix is then $\\widehat{\\text{Var}}_{\\text{OLS}}(\\hat{\\theta}) = \\hat{\\sigma}^2 (X^T X)^{-1}$. The standard errors for $\\hat{\\alpha}$ and $\\hat{\\beta}$ are the square roots of the diagonal elements of this matrix.\n\n**3. Test for Residual Autocorrelation**\nTo test the validity of the no-autocorrelation assumption, we use a large-sample test based on the sample autocorrelations of the residuals. We will employ the Ljung-Box Q-test. The null hypothesis is $H_0: r_1 = r_2 = \\dots = r_h = 0$, where $r_k$ is the population autocorrelation at lag $k$. The test statistic is:\n$$\nQ = T(T+2) \\sum_{k=1}^h \\frac{\\hat{r}_k^2}{T-k}\n$$\nwhere $\\hat{r}_k$ is the sample autocorrelation of the residuals at lag $k$. Under the null hypothesis, $Q$ follows a chi-squared distribution with $h$ degrees of freedom, $Q \\sim \\chi^2(h)$. We reject $H_0$ at a significance level of $0.05$ if the computed $Q$ statistic exceeds the $95^{th}$ percentile of the $\\chi^2(h)$ distribution.\n\n**4. Newey–West (HAC) Standard Errors**\nWhen the errors $\\{\\varepsilon_t\\}$ are heteroskedastic and/or autocorrelated, the OLS standard errors are inconsistent. We must use a Heteroskedasticity and Autocorrelation Consistent (HAC) covariance matrix estimator. The Newey-West estimator is a common choice. The HAC covariance matrix for $\\hat{\\theta}$ has the \"sandwich\" form:\n$$\n\\text{Var}_{\\text{NW}}(\\hat{\\theta}) = (X^T X)^{-1} \\hat{S} (X^T X)^{-1}\n$$\nHere, $\\hat{S}$ is an estimator of the long-run variance of the score vector $g_t = X_t \\varepsilon_t$, where $X_t = [1, m_t]^T$. The Newey-West estimator for $\\hat{S}$ is:\n$$\n\\hat{S} = \\sum_{t=1}^T g_t g_t^T + \\sum_{j=1}^L w_j \\sum_{t=j+1}^T (g_t g_{t-j}^T + g_{t-j} g_t^T)\n$$\nwhere $g_t = X_t \\hat{\\varepsilon}_t$. The problem specifies the Bartlett kernel, for which the weights $w_j$ are given by $w_j = 1 - \\frac{j}{L+1}$, and $L$ is the truncation lag. The Newey-West standard errors for $\\hat{\\alpha}$ and $\\hat{\\beta}$ are the square roots of the diagonal elements of the resulting $\\widehat{\\text{Var}}_{\\text{NW}}(\\hat{\\theta})$ matrix.\n\nThe following Python program implements this complete procedure for each specified test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy.stats\n\ndef process_case(T, alpha, beta, phi_m, sigma_m, rho, sigma_eps, kappa, h, L, seed):\n    \"\"\"\n    Simulates time series data, estimates CAPM parameters, and computes standard errors.\n\n    Args:\n        T (int): Number of time periods.\n        alpha (float): True alpha.\n        beta (float): True beta.\n        phi_m (float): AR(1) coefficient for market return.\n        sigma_m (float): Volatility of market return shock.\n        rho (float): AR(1) coefficient for idiosyncratic error component.\n        sigma_eps (float): Volatility of idiosyncratic error shock.\n        kappa (float): Heteroskedasticity parameter.\n        h (int): Lag length for autocorrelation test.\n        L (int): Truncation lag for Newey-West estimator.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        list: A list containing estimated alpha, beta, OLS standard errors,\n              Newey-West standard errors, and autocorrelation test result.\n    \"\"\"\n    # 1. Data Generation\n    rng = np.random.default_rng(seed)\n    \n    m = np.zeros(T)\n    u = np.zeros(T)\n    eps = np.zeros(T)\n    y = np.zeros(T)\n\n    m_prev = 0.0\n    u_prev = 0.0\n    mu_m = 0.0 # As specified in the problem\n\n    for t in range(T):\n        z_t = rng.standard_normal()\n        w_t = rng.standard_normal()\n\n        # Market return process\n        m[t] = mu_m + phi_m * m_prev + sigma_m * z_t\n        m_prev = m[t]\n\n        # Idiosyncratic component process\n        u[t] = rho * u_prev + sigma_eps * w_t\n        u_prev = u[t]\n\n        # CAPM error term\n        if kappa == 0:\n            eps[t] = u[t]\n        else:\n            eps[t] = (1 + kappa * np.abs(m[t])) * u[t]\n        \n        # Asset excess return\n        y[t] = alpha + beta * m[t] + eps[t]\n\n    # 2. OLS Estimation\n    X = np.vstack([np.ones(T), m]).T\n    k = X.shape[1]\n    \n    try:\n        XTX_inv = np.linalg.inv(X.T @ X)\n    except np.linalg.LinAlgError:\n        # Handle cases of perfect multicollinearity, though unlikely here\n        return [np.nan] * 7\n\n    theta_hat = XTX_inv @ X.T @ y\n    alpha_hat, beta_hat = theta_hat[0], theta_hat[1]\n\n    # 3. OLS Standard Errors\n    residuals = y - X @ theta_hat\n    sigma2_hat = np.sum(residuals**2) / (T - k)\n    var_cov_ols = sigma2_hat * XTX_inv\n    se_alpha_ols = np.sqrt(var_cov_ols[0, 0])\n    se_beta_ols = np.sqrt(var_cov_ols[1, 1])\n\n    # 4. Residual Autocorrelation Test (Ljung-Box)\n    res_var = np.sum(residuals**2) / T\n    q_stat = 0.0\n    for j in range(1, h + 1):\n        # Sample autocovariance at lag j\n        res_acov_j = np.sum(residuals[j:] * residuals[:-j]) / T\n        # Sample autocorrelation at lag j\n        res_acor_j = res_acov_j / res_var\n        q_stat += (res_acor_j**2) / (T - j)\n        \n    q_stat *= T * (T + 2)\n    \n    chi2_crit_val = scipy.stats.chi2.ppf(0.95, df=h)\n    reject_h0 = q_stat > chi2_crit_val\n\n    # 5. Newey-West HAC Standard Errors\n    g = X * residuals[:, np.newaxis]  # T x k matrix of scores\n    \n    S_hat = g.T @ g\n    \n    for j in range(1, L + 1):\n        weight = 1.0 - j / (L + 1.0)\n        gamma_j = g[j:].T @ g[:-j]\n        S_hat += weight * (gamma_j + gamma_j.T)\n        \n    var_cov_nw = XTX_inv @ S_hat @ XTX_inv\n    se_alpha_nw = np.sqrt(var_cov_nw[0, 0])\n    se_beta_nw = np.sqrt(var_cov_nw[1, 1])\n\n    # 6. Collate and return results\n    return [alpha_hat, beta_hat, se_alpha_ols, se_beta_ols, se_alpha_nw, se_beta_nw, reject_h0]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # T, alpha, beta, phi_m, sigma_m, rho, sigma_eps, kappa, h, L, seed\n        (500, 0.001, 1.2, 0.1, 0.04, 0.0, 0.02, 0.0, 4, 4, 20240514), # Case A\n        (500, 0.001, 1.2, 0.1, 0.04, 0.6, 0.02, 0.0, 4, 4, 20240515), # Case B\n        (60, 0.001, 1.2, 0.2, 0.05, 0.5, 0.02, 0.0, 4, 4, 20240516),  # Case C\n        (500, 0.001, 1.2, 0.1, 0.04, 0.3, 0.02, 0.8, 4, 4, 20240517), # Case D\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(*case)\n        results.append(result)\n\n    # Format output string without extra spaces, rounding floats to 6 places\n    list_of_strings = []\n    for res_list in results:\n        inner_str_list = []\n        for item in res_list:\n            if isinstance(item, (float, np.floating)):\n                inner_str_list.append(f\"{item:.6f}\")\n            else:\n                inner_str_list.append(str(item))\n        inner_str = ','.join(inner_str_list)\n        list_of_strings.append(f\"[{inner_str}]\")\n    \n    final_output_str = f\"[{','.join(list_of_strings)}]\"\n    print(final_output_str)\n\nsolve()\n```"}]}