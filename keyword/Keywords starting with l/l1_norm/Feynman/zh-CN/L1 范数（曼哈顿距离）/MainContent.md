## 引言
我们如何衡量距离，这一选择从根本上塑造了我们对世界的理解。我们凭直觉熟悉欧几里得距离——即“乌鸦飞行”的直线距离，其正式名称为 L2 范数。但如果运动被限制在网格上，比如一辆在曼哈顿街头穿梭的出租车，情况会怎样呢？这个简单的约束催生了一个不同的距离概念：L1 范数，即距离是沿坐标轴移动的总和。与我们熟悉的 L2 范数相比，这个看似微小的变化开启了一个具有深远而强大影响的几何与分析世界。本文要探讨的核心问题是，这种替代性的度量标准如何彻底改变从圆的形状到我们分析复杂数据的方式等一切事物。

本文将引导您领略 L1 范数这片迷人的领域。在第一章 **“原理与机制”** 中，我们将解构 L1 范数的数学定义，探索其独特的几何形状，并揭示其“尖角”的秘密，正是这些尖角赋予了它在优化问题中创造[稀疏解](@article_id:366617)的能力。在建立了这一基础理解之后，**“应用与跨学科联系”** 一章将展示这一抽象概念如何成为[量子计算](@article_id:303150)、城市规划和机器学习等不同领域中不可或缺的工具，它在这些领域中实现了稳健性和模型的自动简化。

## 原理与机制

你如何测量距离？这个问题似乎简单得近乎幼稚。你拿一把尺子，或者一个激光测距仪，测量两点之间的直线。这是世界的法则，由 Euclid 在几千年前编纂成典，并如此深深地植根于我们的直觉中，以至于我们很少去质疑它。从你的椅子到门的距离，就是一只虫子可以行走的最短、最直路径的长度。我们称之为**欧几里得距离**，或 **L2 范数**。

但如果你不是一只虫子呢？如果你是曼哈顿的一名出租车司机，或仓库里一个只能沿固定网格轨道移动的机械臂呢？ 突然之间，直线路径成了一种幻想。要从 A 点到 B 点，你必须在东西方向上行进一段距离，在南北方向上行进另一段距离。你的总行程是这些移动距离的总和，而不是一个三角形的斜边。这个简单而实用的想法催生了一种全新的看待世界的方式，它由我们所说的**[曼哈顿距离](@article_id:340687)**，或更正式地称为 **L1 范数**所支配。

如果一个向量 $\vec{v} = (v_1, v_2, \dots, v_n)$ 代表一个位移，其 L1 范数就是其各分量[绝对值](@article_id:308102)的总和：
$$
\|\vec{v}\|_1 = \sum_{i=1}^{n} |v_i|
$$
相比之下，我们熟悉的 L2 范数是各分量平方和的平方根：
$$
\|\vec{v}\|_2 = \sqrt{\sum_{i=1}^{n} v_i^2}
$$
定义上的这个微小改变——用[绝对值](@article_id:308102)替换平方和平方根——看似无足轻重。但它却打开了一扇通往一个既奇异又极其有用的几何宇宙的大门。让我们一探究竟。

### 方形城市中的圆形

在我们熟悉的欧几里得世界里，什么是圆？它是一个[中心点](@article_id:641113)[等距](@article_id:311298)的所有点的集合。如果我们站在原点问：“距离恰好为 1 个单位的所有点在哪里？”，答案就是由 $x^2 + y^2 = 1^2$ 描述的我们熟悉的那个圆。

现在，让我们在 L1 范数的世界里问同样的问题。想象一下，正在建造一个公园，规定其边界必须是所有与市中心 $(0,0)$ 的“出租车距离”恰好为 1 公里的点的集合 。这个边界看起来像什么？其定义方程是 $|x| + |y| = 1$。

在第一[象限](@article_id:352519)，其中 $x$ 和 $y$ 均为正，方程就是 $x+y=1$，一条斜率为 -1 的直线。在第二[象限](@article_id:352519) ($x<0, y>0$)，方程是 $-x+y=1$，一条斜率为 +1 的直线。如果你在所有四个[象限](@article_id:352519)中都描绘出这条线，你得到的根本不是一个圆。你得到的是一个旋转了 45 度的正方形，其顶点位于 $(1,0)$、$(0,1)$、$(-1,0)$ 和 $(0,-1)$。这个旋转的正方形就是 L1 几何学中的“[单位圆](@article_id:311954)”。其周界上的任何一点，距离原点的出租车行程都恰好是一个单位。

这不仅仅是一个奇特的现象。它是 L1 范数的基本几何标志。与一个中心点保持恒定 L1 距离的所有点的集合，总是会形成这些旋转的正方形 。改变我们对距离的定义，实实在在地改变了圆的形状。平滑的曲线被尖锐的角所取代。正如我们将要看到的，魔法就蕴藏在这些角中。

### 乌鸦和出租车何[时差](@article_id:316023)异最大？

让我们更直接地比较“乌鸦飞行”的 L2 距离和“出租车”的 L1 距离。它们在什么时候一致，又在什么时候差异最大？

想象一下从原点 $(0,0)$ 移动到点 $(5,0)$。L2 距离是 $\sqrt{5^2 + 0^2} = 5$。L1 距离是 $|5| + |0| = 5$。它们是相同的。这很合理；如果你只沿着一条网格线移动，直线路径和网格路径是一样的。

但现在，让我们从 $(0,0)$ 移动到 $(3,3)$。乌鸦的路径长度是 $\sqrt{3^2 + 3^2} = \sqrt{18} = 3\sqrt{2} \approx 4.24$。而出租车则必须行驶 $|3| + |3| = 6$。这个距离要大得多。事实上，一个有趣的数学练习表明，对于二维平面中的任意两点，它们的 L1 距离与 L2 距离之比，恰好在纯对角线方向移动时达到最大值 $\sqrt{2}$——也就是说，当 $x$ 的绝对变化量等于 $y$ 的绝对变化量时 。

这种差异不仅仅是学术上的。它可以决定一个网络是否连通。想象一下三个无线电塔，如果距离小于某个阈值就形成连接。使用 L2 度量可能会连接两个塔，而使用 L1 度量（代表信号穿过网格状[城市峡谷](@article_id:374290)的传播）可能会认为它们相距太远 。你构建的世界取决于你使用的尺子。这种基本的几何奇异性甚至延伸到像“[垂直平分线](@article_id:342571)”这样的概念。在 L1 空间中，与 A、B 两点[等距](@article_id:311298)的点集不是一条简单的线；它可能是线甚至整个二维区域的奇异组合 ，这进一步凸显了度量的改变如何深刻地改变了我们的几何直觉。

### 诚实的中间人与通往稀疏之路

尽管 L1 范数具有几何魅力，但它在 21 世纪的真正威力来自于它在优化、机器学习和数据科学中的作用。在这里，L1 范数扮演着一种数学上的“[奥卡姆剃刀](@article_id:307589)”的角色，迫使我们的模型尽可能地简单。这个原则被称为**稀疏性**。

让我们想象一个简单的问题。我们有一个包含两个未知数的方程：$2x_1 + x_2 = 4$ 。这个系统是“欠定的”——有无限多个解。例如，$(x_1, x_2) = (2,0)$ 是一个解。$(0,4)$ 和 $(1,2)$ 等等也是解。如果这个方程代表科学或金融中的一个复杂模型，我们应该信任哪个解？我们需要一个额外的原则来指导我们。这被称为**正则化**。

一种方法是**Tikhonov 正则化**，它使用 L2 范数。它主张：在所有可能的解中，找到 L2 范数最小的那个。最小化 $\|x\|_2^2 = x_1^2 + x_2^2$ 意味着我们对大的值施加了重罚。L2 范数不喜欢某个变量值很大的“尖峰”解。它更倾向于分散负载，从而产生一个“平滑”或“稠密”的答案。对于我们的例子，经过一些数学计算，L2 偏好的解是 $x_T = (\frac{8}{5}, \frac{4}{5})$。两个变量都被使用了；解是稠密的。

现在，让我们使用一个不同的原则：**LASSO（最小绝对收缩和选择算子）[正则化](@article_id:300216)**，它使用 L1 范数。它主张：找到 L1 范数最小的解，即最小化 $\|x\|_1 = |x_1| + |x_2|$。L1 范数是“诚实的中间人”。它不像 L2 那样在意少数几个大值；它只是想最小化所使用的*总*值。

回想一下我们的 L1“圆”——那个旋转的正方形。它的“角”位于坐标轴上，那里其中一个变量恰好为零。当我们试图在这个形状上找到最接近满足我们方程的点时，优化过程会自然地被吸引到这些角上。对于我们的问题，结果是解 $x_L = (2, 0)$。这个解是**稀疏的**——它将 $x_2$ 设置为零。它判定 $x_2$ 对于解释数据是不必要的。这种执行自动[特征选择](@article_id:302140)、丢弃不相关信息并产生更简单、更易于解释模型的能力，正是 L1 范数成为现代科学中明星的原因。它帮助生物学家从数千个基因中找出导致某种疾病的少数几个基因 ，并让经济学家能够精确定位市场的关键驱动因素。

### 尖角的秘密

为什么会发生这种情况？秘密再次在于尖角的几何形状。像 $x^2$ 这样的[平滑函数](@article_id:362303)在任何地方都有明确定义的斜率（[导数](@article_id:318324)）。在 L2“碗”的底部，斜率为零，是一个平坦、稳定的最小值。而像 $|x|$ 这样的带有[绝对值](@article_id:308102)的函数则不同。在 $x=0$ 处，它有一个[尖点](@article_id:641085)。左边的斜率是 -1，右边的斜率是 +1。在 $x=0$ 这个点本身，斜率是未定义的。

在优化中，我们使用斜率（或梯度）来告诉我们朝向解的“下坡”方向是哪里。对于像 L1 范数这样的非平滑函数，我们使用一个叫做**次梯度**的概念，它是在某点所有可能的“下坡”方向的集合。对于 $|x|$，在任何非零点，[次梯度](@article_id:303148)就是它的符号（-1 或 +1）。但是在 $x=0$ 这个角点，[次梯度](@article_id:303148)是从 -1 到 1 的整个区间。

这给了优化算法一个特别的选择。当一个变量已经是零时，[算法](@article_id:331821)可以为该变量的方向选择一个为 0 的[次梯度](@article_id:303148)。那么该变量的更新步骤就变成 $x_{\text{new}} = x_{\text{old}} - \alpha \cdot 0 = 0$。这个变量就“卡”在了零上！。L1 范数的尖角就像一个陷阱，或者说是一个引力井，在优化过程中捕获变量。它主动鼓励值恰好为零，而不仅仅是“很小”。平滑的 L2 碗没有这样的陷阱；一个变量可以非常接近零，但它永远不会被鼓励*精确地*变为零。

从一个出租车在城市网格中导航的简单想法出发，我们穿行在一个由旋转方块构成的圆的世界，并发现了一种现代[数据分析](@article_id:309490)中最强大思想背后的数学引擎。L1 范数证明了一个基本定义中的微小变化如何能产生一连串美丽而又惊人实用的结果。这是一种全新的看待世界的方式，一次一个尖角。

