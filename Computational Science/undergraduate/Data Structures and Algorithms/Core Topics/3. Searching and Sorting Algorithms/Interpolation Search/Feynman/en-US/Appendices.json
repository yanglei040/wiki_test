{
    "hands_on_practices": [
        {
            "introduction": "Interpolation search achieves its remarkable $O(\\log \\log n)$ average-case performance by assuming data is uniformly distributed. This exercise challenges that assumption by asking you to trace the algorithm's execution on an exponentially spaced dataset, a classic example of non-uniform data that exposes the algorithm's vulnerabilities . By manually calculating the probe positions, you will gain a concrete understanding of how a skewed data distribution can degrade the search to $O(n)$ performance.",
            "id": "3241458",
            "problem": "Consider a sorted static array $A[0], A[1], \\dots, A[m]$ with $A[i] = 2^{i}$ for all $i \\in \\{0, 1, \\dots, m\\}$. An interpolation search algorithm is used to locate a target key $x$ under the following specification. At each iteration, given current bounds $l$ and $h$ with $0 \\le l \\le h \\le m$ and $A[l] \\le x \\le A[h]$, the algorithm chooses a real-valued estimate $p \\in [l, h]$ by linearly interpolating the value $x$ within the value interval $[A[l], A[h]]$ so as to map back into the index interval $[l, h]$. The algorithm then probes the array at the integer index $q = \\lfloor p \\rfloor$, compares $A[q]$ with $x$, and updates the bounds as follows: if $A[q] = x$ it halts; if $A[q] < x$ it sets $l \\leftarrow q + 1$; and if $A[q] > x$ it sets $h \\leftarrow q - 1$. The loop proceeds only while $l \\le h$ and $A[l] \\le x \\le A[h]$; otherwise, it terminates and reports that $x$ is not present. A “probe” is defined as a single read of some $A[q]$ produced by the interpolation step.\n\nUsing only the linear interpolation principle described above and the definition $A[i] = 2^{i}$, derive the explicit expression for the interpolated estimate $p$ at a general iteration and use it to rigorously trace the algorithm’s behavior on the instance with $m = 60$ and $x = 2^{10} + 1$. Compute the exact total number of probes performed by the algorithm until it terminates. Express your final answer as a single integer. No rounding is required.",
            "solution": "The problem requires the validation of its premises, followed by a detailed derivation of the total number of probes an interpolation search algorithm performs on a specific array instance.\n\nFirst, the problem is validated.\n**Givens:**\n-   Array: $A[i] = 2^{i}$ for $i \\in \\{0, 1, \\dots, m\\}$.\n-   Algorithm: Interpolation search with current bounds $l$ and $h$.\n-   Interpolation formula for index estimate $p$: Linear mapping of value $x \\in [A[l], A[h]]$ to index $p \\in [l, h]$.\n-   Probe index: $q = \\lfloor p \\rfloor$.\n-   Update rules: If $A[q] < x$, $l \\leftarrow q + 1$; if $A[q] > x$, $h \\leftarrow q - 1$.\n-   Termination conditions: Algorithm halts if $A[q] = x$, or if the loop condition ($l \\le h$ and $A[l] \\le x \\le A[h]$) fails.\n-   Instance: $m = 60$, target key $x = 2^{10} + 1$.\n-   Task: Compute the total number of probes.\n\n**Validation Verdict:**\nThe problem is scientifically grounded, well-posed, and objective. It is a standard exercise in algorithm analysis, examining the behavior of interpolation search on a non-uniform data distribution. All parameters and rules are specified, leading to a unique and verifiable sequence of operations. The problem is therefore deemed **valid**.\n\n**Step 1: Derivation of the Interpolation Formula**\nThe problem states that the estimated index $p$ is found by linearly interpolating the value $x$ in the range $[A[l], A[h]]$ to the index range $[l, h]$. This implies that the fractional position of $p$ in its range is equal to the fractional position of $x$ in its range. The relationship is expressed as:\n$$\n\\frac{p - l}{h - l} = \\frac{x - A[l]}{A[h] - A[l]}\n$$\nSolving for $p$, we obtain the general formula for the interpolated index estimate:\n$$\np = l + (h - l) \\frac{x - A[l]}{A[h] - A[l]}\n$$\nSubstituting the given array definition, $A[i] = 2^{i}$, the formula becomes:\n$$\np = l + (h - l) \\frac{x - 2^l}{2^h - 2^l}\n$$\nThis is the explicit expression for $p$ used in each iteration.\n\n**Step 2: Tracing the Algorithm Execution**\nWe trace the algorithm for the specific instance: $m = 60$ and $x = 2^{10} + 1$.\nThe initial search bounds are $l_0 = 0$ and $h_0 = 60$.\n\n**Initial Check:**\nThe main loop proceeds while $l \\le h$ and $A[l] \\le x \\le A[h]$.\n-   $l_0 \\le h_0 \\implies 0 \\le 60$, which is true.\n-   $A[l_0] \\le x \\le A[h_0] \\implies 2^0 \\le 2^{10} + 1 \\le 2^{60}$. This is $1 \\le 1025 \\le 2^{60}$, which is true.\nThe loop begins.\n\n**Probe 1:**\nWith $l=0$ and $h=60$:\n$$\np_1 = 0 + (60 - 0) \\frac{(2^{10} + 1) - 2^0}{2^{60} - 2^0} = 60 \\frac{2^{10}}{2^{60} - 1}\n$$\nThe value of $p_1$ is positive. To find $\\lfloor p_1 \\rfloor$, we check if $p_1 < 1$:\n$$\n60 \\cdot 2^{10} < 2^{60} - 1\n$$\nWe can bound the left side: $60 < 64 = 2^6$, so $60 \\cdot 2^{10} < 2^6 \\cdot 2^{10} = 2^{16}$. The inequality $2^{16} < 2^{60} - 1$ is clearly true.\nThus, $0 < p_1 < 1$, which gives the probe index $q_1 = \\lfloor p_1 \\rfloor = 0$.\nA probe is made at $A[0]$. We find $A[0] = 2^0 = 1$.\nComparing with $x$, we have $A[0] = 1 < x = 2^{10} + 1$.\nThe lower bound is updated: $l \\leftarrow q_1 + 1 = 1$. The state becomes $l=1, h=60$. This completes the first probe.\n\n**General Step (Probes 2 to 11):**\nWe observe a pattern. Let's analyze the state before the $(k+1)$-th probe, for $k \\in \\{1, 2, \\dots, 10\\}$. Assume the current state is $l=k, h=60$.\nFirst, check the loop condition:\n-   $l \\le h \\implies k \\le 60$, which is true for $k \\le 10$.\n-   $A[l] \\le x \\le A[h] \\implies 2^k \\le 2^{10} + 1 \\le 2^{60}$. For $k \\le 10$, we have $2^k \\le 2^{10} < 2^{10} + 1$, so this is true.\nThe loop continues. The $(k+1)$-th probe is calculated:\n$$\np_{k+1} = k + (60 - k) \\frac{(2^{10} + 1) - 2^k}{2^{60} - 2^k}\n$$\nSince $x > A[k]$, the fraction is positive, so $p_{k+1} > k$.\nTo find $q_{k+1} = \\lfloor p_{k+1} \\rfloor$, we check if $p_{k+1} < k+1$. This is equivalent to checking if the fractional part is less than $1$:\n$$\n(60 - k) \\frac{2^{10} + 1 - 2^k}{2^{60} - 2^k} < 1\n$$\n$$\n(60 - k)(2^{10} + 1 - 2^k) < 2^{60} - 2^k\n$$\nFor $k \\le 10$, the left-hand side (LHS) can be bounded:\nLHS $< (60)(2^{10} + 1) < 64 \\cdot 2^{11} = 2^6 \\cdot 2^{11} = 2^{17}$.\nThe right-hand side (RHS) is bounded below by its value at $k=10$: $2^{60} - 2^{10}$.\nThe inequality $2^{17} < 2^{60} - 2^{10}$ is manifestly true.\nTherefore, for $k \\in \\{0, 1, \\dots, 10\\}$, we have $k \\le p_{k+1} < k+1$. This implies that the probe index is $q_{k+1} = \\lfloor p_{k+1} \\rfloor = k$.\n\nSo, for $k=0, 1, \\dots, 10$, the $(k+1)$-th probe will be at index $k$.\n-   Probe 1 queries index $0$.\n-   Probe 2 queries index $1$.\n-   ...\n-   Probe 11 queries index $10$.\n\nFor each of these probes (from index $k=0$ to $k=10$), we compare $A[k]=2^k$ with $x=2^{10}+1$.\nSince $2^k \\le 2^{10} < 2^{10}+1$ for all $k \\le 10$, the condition $A[k] < x$ is always met.\nThe update rule $l \\leftarrow k+1$ is applied at each step.\nAfter Probe 1 ($q_1=0$), the state becomes $l=1, h=60$.\nAfter Probe 2 ($q_2=1$), the state becomes $l=2, h=60$.\n...\nAfter Probe 11 ($q_{11}=10$), the state becomes $l=11, h=60$.\n\n**Step 3: Termination**\nAfter 11 probes have been executed, the state of the algorithm is $l=11, h=60$. The algorithm then re-evaluates the loop condition before starting the 12th iteration.\nThe loop condition is $l \\le h$ AND $A[l] \\le x \\le A[h]$.\n-   $l \\le h \\implies 11 \\le 60$. This is true.\n-   $A[l] \\le x \\implies A[11] \\le 2^{10} + 1$. This is $2^{11} \\le 2^{10}+1$, or $2048 \\le 1025$. This is **false**.\n\nSince one part of the condition $A[l] \\le x \\le A[h]$ is false, the entire logical conjunction is false. The loop terminates. No further probes are made.\nThe algorithm performs a total of 11 probes, at indices $0, 1, 2, ..., 10$, before terminating.\n\n**Conclusion:**\nThe total number of probes is 11.",
            "answer": "$$\\boxed{11}$$"
        },
        {
            "introduction": "A core skill in algorithm design is adapting a textbook method to solve a more general problem robustly. This practice moves beyond finding an exact match to implementing a `lower_bound` function, a common requirement in many applications . Your task is to design an interpolation-based search that correctly handles the full range of edge cases, including duplicate values and keys outside the data range, thereby honing your ability to write correct and resilient code.",
            "id": "3241337",
            "problem": "You are given a sorted sequence that is non-decreasing and finite. For a key value, you must compute the lower bound index: the smallest index that points to an element greater than or equal to the key. Formally, for a sorted array $A$ of length $n$, the lower bound for a key $x$ is the smallest index $i$ such that $A[i] \\ge x$. If no element of $A$ satisfies $A[i] \\ge x$, then the lower bound is $n$. Your task is to generalize the search strategy to use interpolation as the probing rule rather than midpoint selection, and to ensure the method is correct and terminates even for degenerate cases such as duplicate runs and extreme keys.\n\nStart from the following fundamental base:\n- The array $A$ is sorted in non-decreasing order. That is, for any indices $i$ and $j$ with $0 \\le i < j \\le n-1$, one has $A[i] \\le A[j]$.\n- The lower bound index is defined purely by the order property: it is the smallest index $i$ with $A[i] \\ge x$, or $n$ if such $i$ does not exist.\n- The interpolation principle estimates a probe position within the current search interval by assuming a locally linear relationship between values and positions.\n\nDesign a program that, given a set of test cases, uses an interpolation-based search to compute the lower bound indices. The algorithm must:\n- Maintain a logically correct search invariant grounded in monotonicity that guarantees termination and correctness for lower bound selection.\n- Use an interpolation-based probe choice within the current interval, consistent with the assumption of local linearity, without resorting to an unbounded number of midpoint selections.\n- Handle edge cases robustly, including $n=0$, $x$ less than the first element, $x$ greater than the last element, duplicate values forming constant segments, and both integer and real values.\n\nYour program must apply the algorithm to the following test suite. Each test case is a pair $(A, x)$ where $A$ is the array and $x$ is the key:\n- Case 1: $A = [1, 4, 7, 10, 13, 16, 19, 22, 25]$, $x = 15$.\n- Case 2: $A = [1, 2, 2, 2, 3, 5, 8]$, $x = 2$.\n- Case 3: $A = [10, 20, 30]$, $x = 5$.\n- Case 4: $A = [10, 20, 30]$, $x = 100$.\n- Case 5: $A = []$, $x = 42$.\n- Case 6: $A = [7, 7, 7, 7, 7]$, $x = 7$.\n- Case 7: $A = [7, 7, 7, 7, 7]$, $x = 8$.\n- Case 8: $A = [1, 2, 3, 1000, 1000000]$, $x = 999$.\n- Case 9: $A = [0.1, 0.2, 0.5, 1.0, 2.0]$, $x = 0.3$.\n\nFor each case, your program must output the lower bound index as an integer. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases above, for example, `[result_1,result_2,...,result_9]`.",
            "solution": "The problem statement is critically validated as follows.\n\n### Step 1: Extract Givens\n- **Sequence**: A sorted, non-decreasing, finite sequence, denoted as array $A$. For any indices $i$ and $j$ with $0 \\le i < j \\le n-1$, it holds that $A[i] \\le A[j]$, where $n$ is the length of $A$.\n- **Key**: A value $x$.\n- **Objective**: Compute the lower bound index for the key $x$.\n- **Definition of Lower Bound**: The smallest index $i$ such that $A[i] \\ge x$. If no such element exists, the lower bound is $n$.\n- **Algorithmic Constraint**: The search must use an interpolation-based probing rule, not a simple midpoint rule (as in binary search).\n- **Robustness Requirements**: The algorithm must correctly terminate and produce the right index for all cases, including but not limited to:\n    - Empty array ($n=0$).\n    - Key $x$ less than the first element ($x < A[0]$).\n    - Key $x$ greater than the last element ($x > A[n-1]$).\n    - Arrays with duplicate values (constant segments).\n    - Both integer and real number data types for array elements and the key.\n- **Test Suite**:\n    - Case $1$: $A = [1, 4, 7, 10, 13, 16, 19, 22, 25]$, $x = 15$.\n    - Case $2$: $A = [1, 2, 2, 2, 3, 5, 8]$, $x = 2$.\n    - Case $3$: $A = [10, 20, 30]$, $x = 5$.\n    - Case $4$: $A = [10, 20, 30]$, $x = 100$.\n    - Case $5$: $A = []$, $x = 42$.\n    - Case $6$: $A = [7, 7, 7, 7, 7]$, $x = 7$.\n    - Case $7$: $A = [7, 7, 7, 7, 7]$, $x = 8$.\n    - Case $8$: $A = [1, 2, 3, 1000, 1000000]$, $x = 999$.\n    - Case $9$: $A = [0.1, 0.2, 0.5, 1.0, 2.0]$, $x = 0.3$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the validation criteria:\n- **Scientifically Grounded**: The problem is rooted in the field of computer science, specifically algorithms and data structures. Interpolation search and the concept of a lower bound are well-defined and standard topics. The problem is scientifically sound.\n- **Well-Posed**: For any given sorted array $A$ and key $x$, the lower bound index is uniquely defined. The problem requires the design of an algorithm to find this index, which is a standard and well-posed algorithmic task.\n- **Objective**: The problem is stated using precise, formal definitions and quantitative test cases. There is no subjective, ambiguous, or opinion-based language.\n- **Completeness and Consistency**: The problem provides all necessary definitions, constraints, and data to design and test a solution. The constraints are challenging but not contradictory.\n- **Overall Assessment**: The problem does not violate any of the specified invalidity criteria. It is a formal, objective, and solvable problem in algorithm design.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n### Algorithmic Design and Principles\n\nThe task is to design a robust interpolation search algorithm to find the lower bound of a key $x$ in a sorted array $A$. The lower bound is the first index $i$ such that $A[i] \\ge x$. A standard interpolation search is designed for finding an exact match and can fail on non-uniform data distributions or when duplicates are present. A correct algorithm for the lower bound requires careful management of the search interval and robust handling of boundary conditions.\n\nThe proposed algorithm maintains a search interval and a candidate answer, guided by a precise invariant.\n\n**Core Principle**: The algorithm is an adaptation of the classic structure for finding a lower bound, where the probe calculation is replaced by interpolation. The search space is an inclusive interval of indices $[\\text{low}, \\text{high}]$. A variable, $\\text{ans}$, holds the best (smallest) index found so far that satisfies the lower bound condition.\n\n**Search Invariant**: Throughout the execution of the main loop, the true lower bound index is guaranteed to be in the range $[\\text{low}, \\text{ans})$. $\\text{ans}$ is initialized to $n$, the length of the array, representing the case where no suitable element is found.\n\n**Algorithm Steps**:\n\n$1$. **Initialization**:\n   - Let $n$ be the length of the array $A$.\n   - If $n = 0$, the array is empty. The only valid lower bound is $n=0$. Return $0$.\n   - Initialize the search interval boundaries: $\\text{low} = 0$ and $\\text{high} = n-1$.\n   - Initialize the candidate answer: $\\text{ans} = n$.\n\n$2$. **Iterative Search**: The search proceeds in a `while` loop that continues as long as $\\text{low} \\le \\text{high}$. Each iteration narrows the search space.\n\n$3$. **Robustness Checks**: Within the loop, before attempting to interpolate, we perform critical checks to handle edge cases and ensure the preconditions for interpolation are met. This is the key to the algorithm's correctness.\n   - **Case (a): Key is smaller than or equal to the leftmost element of the interval.** If $x \\le A[\\text{low}]$, then $A[\\text{low}]$ is a potential lower bound. We update our best candidate answer, $\\text{ans} = \\text{low}$, and then try to find an even smaller index by moving the search space to the left: $\\text{high} = \\text{low} - 1$.\n   - **Case (b): Key is larger than the rightmost element of the interval.** If $x > A[\\text{high}]$, then no element in the current interval $[\\text{low}, \\text{high}]$ can be the lower bound. The search must continue in the region to the right of the current interval. We update the search space accordingly: $\\text{low} = \\text{high} + 1$.\n   - These two checks are fundamental. They not only handle keys outside the range of values in the interval but also implicitly resolve the degenerate case where $A[\\text{low}] = A[\\text{high}]$. In this scenario of a \"flat\" interval, one of the two conditions must be true, thus preventing any attempt to divide by zero in the interpolation formula.\n\n$4$. **Interpolation Probe**: If neither of the above boundary conditions is met, it is guaranteed that $A[\\text{low}] < x \\le A[\\text{high}]$. This ensures that the denominator in the interpolation formula, $A[\\text{high}] - A[\\text{low}]$, is strictly positive and the formula is well-defined. The probe position, $\\text{pos}$, is calculated as:\n   $$\n   \\text{pos} = \\text{low} + \\left\\lfloor \\left( \\frac{x - A[\\text{low}]}{A[\\text{high}] - A[\\text{low}]} \\right) \\times (\\text{high} - \\text{low}) \\right\\rfloor\n   $$\n   This formula estimates the index of $x$ assuming a linear distribution of values between $A[\\text{low}]$ and $A[\\text{high}]$.\n\n$5$. **Search Space Reduction**: Based on the value at the probe position, the search interval is reduced:\n   - If $A[\\text{pos}] < x$, the lower bound must be at an index strictly greater than $\\text{pos}$. The new search interval starts from $\\text{pos} + 1$, so we set $\\text{low} = \\text{pos} + 1$.\n   - If $A[\\text{pos}] \\ge x$, then $\\text{pos}$ is a valid candidate for the lower bound. It might be the answer, or a smaller index to its left might also satisfy the condition. We record this candidate by setting $\\text{ans} = \\text{pos}$ and continue the search for a better solution in the left sub-interval: $\\text{high} = \\text{pos} - 1$.\n\n$6$. **Termination**: The loop terminates when $\\text{low} > \\text{high}$, meaning the search space is exhausted. The final value stored in $\\text{ans}$ is the guaranteed smallest index $i$ such that $A[i] \\ge x$, or $n$ if no such index was found. This final value is returned.\n\nThis design is robust because it relies on strict boundary checks before interpolation, guaranteeing progress and correctness across all specified edge cases, including duplicate runs, extreme keys, and various data distributions.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the interpolation search lower bound problem for a suite of test cases.\n    \"\"\"\n\n    def interpolation_lower_bound(A: np.ndarray, x: float) -> int:\n        \"\"\"\n        Computes the lower bound index for a key x in a sorted numpy array A\n        using a robust interpolation search algorithm.\n\n        The lower bound is the smallest index i such that A[i] >= x.\n        If no such element exists, the lower bound is n.\n\n        Args:\n            A: A sorted (non-decreasing) numpy array.\n            x: The key to search for.\n\n        Returns:\n            The integer lower bound index.\n        \"\"\"\n        n = len(A)\n        if n == 0:\n            return 0\n\n        low = 0\n        high = n - 1\n        ans = n\n\n        while low <= high:\n            # Robustness Check 1: If x is smaller than or equal to the start of the\n            # current interval, A[low] is a new candidate for the lower bound.\n            if x <= A[low]:\n                ans = low\n                # Search for a potentially better (smaller) index to the left.\n                high = low - 1\n                continue\n\n            # Robustness Check 2: If x is larger than the end of the current\n            # interval, no element within [low, high] can be the answer.\n            # The search must resume to the right.\n            if x > A[high]:\n                low = high + 1\n                continue\n\n            # Pre-conditions for interpolation are now met: A[low] < x <= A[high].\n            # This guarantees that A[high] - A[low] is a positive, non-zero value,\n            # preventing division by zero.\n            val_low = A[low]\n            val_high = A[high]\n\n            # Perform interpolation to estimate the probe position.\n            # Using floating point division for accuracy before flooring to int.\n            pos = low + int(((x - val_low) / (val_high - val_low)) * (high - low))\n            \n            # Update search space based on the probed value.\n            if A[pos] < x:\n                # The lower bound must be at an index greater than pos.\n                low = pos + 1\n            else:  # A[pos] >= x\n                # pos is a candidate for the lower bound.\n                # Update the best answer found so far and search for an even\n                # better one to the left.\n                ans = pos\n                high = pos - 1\n        \n        return ans\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([1, 4, 7, 10, 13, 16, 19, 22, 25], dtype=float), 15.0),\n        (np.array([1, 2, 2, 2, 3, 5, 8], dtype=float), 2.0),\n        (np.array([10, 20, 30], dtype=float), 5.0),\n        (np.array([10, 20, 30], dtype=float), 100.0),\n        (np.array([], dtype=float), 42.0),\n        (np.array([7, 7, 7, 7, 7], dtype=float), 7.0),\n        (np.array([7, 7, 7, 7, 7], dtype=float), 8.0),\n        (np.array([1, 2, 3, 1000, 1000000], dtype=float), 999.0),\n        (np.array([0.1, 0.2, 0.5, 1.0, 2.0], dtype=float), 0.3),\n    ]\n\n    results = []\n    for A, x in test_cases:\n        result = interpolation_lower_bound(A, x)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "True mastery of an algorithm involves knowing not only how it works but also when *not* to use it. This culminating exercise guides you to design a sophisticated hybrid algorithm that combines the best of interpolation and binary search . By implementing a self-tuning mechanism that monitors performance and switches strategies when interpolation is ineffective, you will practice a powerful design pattern used to create adaptive and high-performance systems.",
            "id": "3241345",
            "problem": "You are to design and implement a self-tuning search algorithm over a sorted array that begins with interpolation-based probing and dynamically switches to binary search when its observed progress is consistently poor. The algorithm must operate on an array of real or integer values that is sorted in nondecreasing order and must return an index where a given target value occurs, or $-1$ if the target is not present. The program must be self-contained and must run without any input.\n\nThe design must be driven from fundamental definitions and well-tested facts:\n\n1. A sorted array $A$ of length $n$ satisfies $A[i] \\le A[j]$ for all $0 \\le i \\le j \\le n-1$.\n2. Binary search maintains an invariant subrange $[l,r]$ and, on each probe, reduces the remaining range length $L_t = r - l + 1$ by a factor of at most approximately $1/2$.\n3. Interpolation-based probing relies on a linear model assumption about the monotone mapping $x \\mapsto A[x]$ over indices, which is reasonable when the values are approximately uniformly distributed over the index range. It maintains the invariant $A[l] \\le \\text{key} \\le A[r]$ and chooses a probe position within $[l,r]$ by estimating where the key falls relative to $A[l]$ and $A[r]$.\n\nThe algorithm must monitor its own progress quantitatively. Define the range length at time $t$ as $L_t = r_t - l_t + 1$. After each interpolation probe and the corresponding update to $[l_{t+1}, r_{t+1}]$, define the fractional range reduction\n$$\n\\rho_t = \\frac{L_t - L_{t+1}}{L_t}.\n$$\nUse a fixed window size $w$ and a threshold $\\tau$, and compute the moving average of the last $w$ observed $\\rho_t$ values. If the moving average falls below $\\tau$ (indicating consistently poor reduction per probe), immediately switch to binary search for the remainder of the search range.\n\nAlgorithmic requirements and edge-case handling:\n\n- The algorithm must maintain the invariant subrange $[l,r]$ and count a probe each time it reads and compares $A[i]$ at a chosen index $i$ to guide the search. Accessing $A[l]$ and $A[r]$ to compute an estimate does not itself count as a probe unless a comparison with the target is performed at those indices.\n- If at any point the denominator $A[r] - A[l]$ becomes $0$ within the invariant subrange, the array values are constant over $[l,r]$. In this case, switch directly to binary search in $[l,r]$ to avoid undefined interpolation and continue probing until termination.\n- If the target key is outside the current invariant bounds (that is, $\\text{key} < A[l]$ or $\\text{key} > A[r]$), terminate and return $-1$ with zero probes added for that case.\n- When the target occurs multiple times, returning any valid index within its occurrence range is acceptable.\n- The program must report, for each test case, three outputs: the found index $i$ (or $-1$ if not found), the total number of probes $p$, and a boolean $b$ indicating whether binary search was used at any point ($\\text{True}$ if switched or directly used, $\\text{False}$ otherwise).\n\nTest suite and parameters:\n\nUse the same threshold and window across all cases: $\\tau = 0.3$ and $w = 4$. For each case, define the sorted array $A$ and the target key as follows.\n\n- Case $1$ (uniform distribution, happy path): $A = \\{0,1,2,\\dots,999\\}$ and $\\text{key} = 750$.\n- Case $2$ (nonlinear spacing, skewed mapping): $A = \\{i^3 : i \\in \\{0,1,2,\\dots,199\\}\\}$ and $\\text{key} = 729$.\n- Case $3$ (heavy duplicates causing local flat regions): $A$ contains $1000$ copies of $5$ followed by the sequence $\\{6,7,\\dots,105\\}$, and $\\text{key} = 5$.\n- Case $4$ (target absent boundary condition): $A = \\{0,1,2,\\dots,9999\\}$ and $\\text{key} = 10001$.\n- Case $5$ (extremely skewed growth, approximate exponential): $A = \\{\\lfloor 10^{i/100} \\rfloor : i \\in \\{0,1,2,\\dots,1000\\}\\}$ and $\\text{key}$ equals the element at index $800$ of $A$.\n\nFinal output format:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element of this top-level list corresponds to one test case and must itself be a three-item list in the order $[i,p,b]$, where $i$ is the integer index or $-1$, $p$ is the integer number of probes counted as defined above, and $b$ is a boolean indicating whether binary search was used. For example, the printed line must look like\n$[[i_1,p_1,b_1],[i_2,p_2,b_2],[i_3,p_3,b_3],[i_4,p_4,b_4],[i_5,p_5,b_5]]$.",
            "solution": "The problem requires the design and implementation of a hybrid search algorithm for sorted arrays. This algorithm initiates a search using interpolation-based probing and autonomously switches to binary search if its observed performance is substandard. The solution must be grounded in the fundamental principles of these search algorithms and adhere to specific implementation requirements.\n\n### Principles and Algorithmic Design\n\nA sorted array $A$ of length $n$ exhibits a monotonic non-decreasing relationship between indices and values, i.e., $A[i] \\le A[j]$ for all $0 \\le i < j \\le n-1$. This property is the foundation for search algorithms more efficient than linear scanning.\n\n#### Binary Search\nBinary search is a robust algorithm that guarantees a logarithmic time complexity, $O(\\log n)$. It operates on a search sub-range $[l, r]$ and probes the middle element $A[\\text{mid}]$, where $\\text{mid} = l + \\lfloor(r-l)/2\\rfloor$. Based on the comparison between $A[\\text{mid}]$ and the target key, it halves the search space in each step. The range length $L_t = r_t - l_t + 1$ is reduced such that $L_{t+1} \\approx L_t/2$. Its performance is independent of the value distribution within the array.\n\n#### Interpolation Search\nInterpolation search leverages the values of the elements at the boundaries of the search range $[l, r]$ to estimate the position of the target key. It assumes an approximately linear mapping from indices to values. The probe position, `pos`, is calculated via linear interpolation:\n$$\n\\text{pos} = l + \\left\\lfloor \\frac{(r-l)(key - A[l])}{A[r] - A[l]} \\right\\rfloor\n$$\nFor uniformly distributed data, interpolation search exhibits an average time complexity of $O(\\log \\log n)$, which is asymptotically faster than binary search. However, its performance degrades significantly for non-uniformly distributed data (e.g., exponential or clustered values), with a worst-case complexity of $O(n)$.\n\n#### Hybrid Algorithm with Self-Tuning\nThe proposed algorithm seeks to combine the strengths of both methods: the potential high speed of interpolation search and the guaranteed performance of binary search. It does so by quantitatively monitoring its own progress and switching strategies when interpolation proves ineffective.\n\n**Performance Monitoring:**\nThe progress of the search is measured by the fractional range reduction, $\\rho_t$, after each probe at step $t$. Given the range length $L_t = r_t - l_t + 1$ before a probe and $L_{t+1}$ after, the reduction is:\n$$\n\\rho_t = \\frac{L_t - L_{t+1}}{L_t} = 1 - \\frac{L_{t+1}}{L_t}\n$$\nA value of $\\rho_t$ close to $1$ indicates a very effective probe, while a value near $0$ signifies minimal progress. For binary search, $\\rho_t \\approx 0.5$.\n\n**Switching Logic:**\nTo avoid prematurely switching due to a single unlucky probe, the algorithm computes a simple moving average of the last $w$ observed $\\rho_t$ values. If this average falls below a predefined threshold $\\tau$, it indicates a consistent pattern of poor performance. At this point, the algorithm concludes that the linear model assumed by interpolation search is invalid for the given data distribution and switches to the more robust binary search for the remainder of the search in the current sub-range $[l, r]$.\n\n### Implementation Details and Edge-Case Handling\n\nThe algorithm is implemented as a state machine with two modes: `'interpolation'` and `'binary'`.\n\n1.  **Initialization**: The search range is initialized to the entire array, $[0, n-1]$. An initial check is performed to see if the target `key` is outside the array's value range, i.e., `key < A[0]` or `key > A[n-1]`. If so, the search terminates immediately, returning an index of $-1$ with zero probes, as the key cannot be present.\n\n2.  **Main Loop**: The search proceeds as long as the range is valid ($l \\le r$).\n\n3.  **Interpolation Mode**:\n    *   **Denominator Check**: A critical edge case for the interpolation formula is when $A[r] = A[l]$. This indicates all elements in the current sub-range $[l, r]$ are identical. Attempting to interpolate would cause a division by zero. As per the problem specification, if this occurs, the algorithm switches to binary search. This is because if `key` equals this constant value, binary search can efficiently find an index; if not, it will correctly determine its absence.\n    *   **Probe Calculation**: The `pos` index is calculated. Care must be taken to ensure the calculation is performed using integer arithmetic or correctly cast to an integer index.\n    *   **Probe and Update**: The element $A[\\text{pos}]$ is compared to the `key`, a probe is counted, and the range $[l, r]$ is narrowed.\n    *   **Performance Update**: After updating `l` or `r`, the new $\\rho_t$ is calculated and added to a list (or deque) of recent reductions.\n    *   **Switch Condition Check**: If the reductions list has at least $w$ elements, their average is computed. If it is less than $\\tau$, the mode is switched to `'binary'`, and a boolean flag `used_binary` is set to `True`.\n\n4.  **Binary Search Mode**:\n    *   Once the algorithm enters this mode, it remains in it until termination.\n    *   The standard binary search procedure is followed: calculate `mid`, probe $A[\\text{mid}]$, and narrow the range $[l, r]$. Each probe is counted.\n\n5.  **Termination**: If the loop finishes without finding the key ($l > r$), the key is not in the array, and an index of $-1$ is returned. If the key is found at any point, its index is returned immediately. The final return value aggregates the found index, the total number of probes, and the boolean flag indicating if binary search was ever employed.\n\nThis design provides a robust and adaptive search mechanism that performs well across a variety of data distributions, fulfilling all requirements of the problem statement. The following code implements this logic for the specified test suite.",
            "answer": "```python\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Designs and executes the self-tuning hybrid search algorithm\n    on a predefined test suite.\n    \"\"\"\n\n    def hybrid_search(A: np.ndarray, key: int, tau: float, w: int):\n        \"\"\"\n        Performs a hybrid interpolation-binary search.\n\n        Args:\n            A: Sorted numpy array of numbers.\n            key: The target value to search for.\n            tau: The performance threshold for switching to binary search.\n            w: The window size for the moving average of range reduction.\n\n        Returns:\n            A list containing [found_index, num_probes, used_binary_search].\n        \"\"\"\n        n = A.size\n        l, r = 0, n - 1\n\n        probes = 0\n        used_binary = False\n        mode = 'interpolation'\n        reductions = deque(maxlen=w)\n\n        # Initial bounds check as per problem statement\n        if n == 0 or key < A[l] or key > A[r]:\n            # 'probes' remains 0 as specified\n            return [-1, 0, False]\n\n        while l <= r:\n            if mode == 'binary':\n                if not used_binary:\n                    used_binary = True\n                \n                mid = l + (r - l) // 2\n                probes += 1\n                \n                if A[mid] == key:\n                    return [mid, probes, used_binary]\n                elif A[mid] < key:\n                    l = mid + 1\n                else:\n                    r = mid - 1\n            else:  # mode == 'interpolation'\n                # Invariant check: key must be within A[l] and A[r]\n                # This should hold but is a good safeguard.\n                if key < A[l] or key > A[r]:\n                    break\n\n                # Handle flat region to avoid division by zero and switch to binary search.\n                if A[r] == A[l]:\n                    if A[l] == key:\n                        # The key is in this flat region.\n                        # As specified, switch to binary search to find an index.\n                        mode = 'binary'\n                        continue\n                    else:\n                        # Key is not in this flat region, so it's not in the array.\n                        break\n                \n                old_l, old_r = l, r\n                \n                # Interpolation formula\n                # Pos must be clamped within [l, r] to handle potential floating point inaccuracies\n                # or extreme key values, though theory suggests it's not needed if key is in range.\n                pos_float = l + ((r - l) / (A[r] - A[l])) * (key - A[l])\n                pos = int(pos_float)\n                pos = max(l, min(pos, r))\n\n                probes += 1\n                \n                if A[pos] == key:\n                    return [pos, probes, used_binary]\n                elif A[pos] < key:\n                    l = pos + 1\n                else:\n                    r = pos - 1\n                \n                # Calculate performance metric\n                L_t = old_r - old_l + 1\n                L_t1 = r - l + 1\n                \n                if L_t > 0: # Avoid division by zero if range somehow becomes empty/invalid\n                    rho_t = (L_t - L_t1) / L_t\n                    reductions.append(rho_t)\n                \n                # Check switch condition\n                if len(reductions) == w:\n                    avg_rho = sum(reductions) / w\n                    if avg_rho < tau:\n                        mode = 'binary'\n                        used_binary = True\n\n        return [-1, probes, used_binary]\n\n    # --- Test Suite Definition ---\n    tau = 0.3\n    w = 4\n\n    test_cases = []\n\n    # Case 1: Uniform distribution\n    A1 = np.arange(1000)\n    key1 = 750\n    test_cases.append((A1, key1))\n\n    # Case 2: Nonlinear spacing (cubic)\n    A2 = np.array([i**3 for i in range(200)])\n    key2 = 729  # which is 9^3\n    test_cases.append((A2, key2))\n\n    # Case 3: Heavy duplicates\n    A3 = np.array([5] * 1000 + list(range(6, 106)))\n    key3 = 5\n    test_cases.append((A3, key3))\n\n    # Case 4: Target absent boundary condition\n    A4 = np.arange(10000)\n    key4 = 10001\n    test_cases.append((A4, key4))\n    \n    # Case 5: Extremely skewed growth (exponential-like)\n    A5 = np.array([int(10**(i/100)) for i in range(1001)])\n    key5 = A5[800]\n    test_cases.append((A5, key5))\n    \n    results = []\n    for A, key in test_cases:\n        result = hybrid_search(A, key, tau, w)\n        results.append(result)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}