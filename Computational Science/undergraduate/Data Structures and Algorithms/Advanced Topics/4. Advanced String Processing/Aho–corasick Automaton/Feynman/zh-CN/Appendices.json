{
    "hands_on_practices": [
        {
            "introduction": "第一个动手实践将指导你完整地实现一个 Aho-Corasick 自动机。你不仅需要构建前缀树（Trie）并计算失败指针，还需要管理输出以维护每个模式串匹配次数的动态计数。这个练习旨在巩固你对自动机如何处理文本并正确报告所有匹配（包括通过后缀链接找到的匹配）的理解 。",
            "id": "3204919",
            "problem": "给定一组有限字符串和一个在有限字母表上的更长的文本。目标是设计并实现一个程序，该程序构建 Aho–Corasick 自动机（AC 自动机）并修改其输出行为，以便在从左到右逐个符号扫描文本时，为每个模式维护一个到目前为止找到的总出现次数的动态计数。在处理完文本的特定前缀后的指定检查点，程序必须按照输入模式的顺序输出当前的计数值向量。\n\n从以下正式且广泛使用的基础开始：\n- 有限字符串集合的 trie（字典树）的定义，其中每个节点对应至少一个字符串的唯一前缀，边由字母表中的单个符号标记。\n- 为 trie 构建失败函数，如同在用于多模式匹配的有限状态自动机中一样：对于每个节点，失败链接指向该节点字符串标签的最长真后缀，该后缀同时也是至少一个模式的前缀。\n- 输出函数，将一个节点映射到在该节点结束的模式索引集合。\n- 标准的广度优先搜索（BFS）过程，用于在线性时间内（与模式总长度成正比）计算失败链接。\n\n您的程序必须：\n- 根据给定的一组模式按其输入顺序构建 trie。设模式数量为 $m \\ge 1$，所有模式的总长度为 $L = \\sum_{i=1}^{m} |P_i|$，其中 $P_i$ 表示第 $i$ 个模式， $|\\cdot|$ 表示字符串长度。假设每个模式都是非空的。\n- 通过以广度优先顺序处理 trie 来计算失败链接。对于每个节点，通过包含其失败链接指向的节点的输出集来扩充其自身的输出集，以确保在自动机进入一个节点的同时报告后缀匹配。\n- 从左到右处理长度为 $n \\ge 0$ 的文本 $T$。读取第 $k$ 个字符后（即前缀长度为 $k$），对于在当前自动机状态的输出集中结束的每个模式 $P_i$，将运行计数值向量 $C \\in \\mathbb{N}^m$ 中的 $C_i$ 增加 $1$。必须计算重叠的出现次数，并且多个模式可以在同一位置匹配。\n- 在指定的检查点（每个检查点等于某个 $k$，其中 $1 \\le k \\le n$），以原始模式顺序将当前 $C$ 的快照记录为包含 $m$ 个非负整数的列表。\n\n输入不是从标准输入读取。相反，您的程序必须在内部运行以下测试套件并汇总结果。\n\n测试套件：\n- 测试用例 $1$：\n  - 模式 $P = [\\text{\"a\"}, \\text{\"ab\"}, \\text{\"bab\"}, \\text{\"bc\"}, \\text{\"bca\"}, \\text{\"c\"}, \\text{\"caa\"}]$。\n  - 文本 $T = \\text{\"abccab\"}$，长度 $n = 6$。\n  - 检查点位于前缀长度 $[1, 3, 6]$。\n  - 此用例的结果是在这些检查点处的快照列表，每个快照是长度为 $m$ 的计数值列表 $C$。\n- 测试用例 $2$：\n  - 模式 $P = [\\text{\"aa\"}, \\text{\"aaa\"}]$。\n  - 文本 $T = \\text{\"aaaaa\"}$，长度 $n = 5$。\n  - 检查点 $[1, 2, 3, 4, 5]$。\n- 测试用例 $3$：\n  - 模式 $P = [\\text{\"he\"}, \\text{\"she\"}, \\text{\"his\"}, \\text{\"hers\"}]$。\n  - 文本 $T = \\text{\"ushers\"}$，长度 $n = 6$。\n  - 单个检查点 $[6]$。\n- 测试用例 $4$：\n  - 模式 $P = [\\text{\"xyz\"}, \\text{\"q\"}]$。\n  - 文本 $T = \\text{\"aaaa\"}$，长度 $n = 4$。\n  - 单个检查点 $[4]$。\n- 测试用例 $5$：\n  - 模式 $P = [\\text{\"aba\"}, \\text{\"ba\"}]$。\n  - 文本 $T = \\text{\"ababa\"}$，长度 $n = 5$。\n  - 检查点 $[2, 5]$。\n\n您的程序必须输出单行，其中包含测试套件的聚合结果，该结果是一个单一列表，其元素是按测试用例顺序排列的每个测试用例的结果。每个测试用例的结果是一个快照列表，每个快照是按该测试用例输入模式顺序排列的整数列表。最终所需的输出格式为不含任何空白字符的单行，使用方括号和逗号表示嵌套列表。具体来说，您的程序应打印形如 $[\\text{R}_1,\\text{R}_2,\\dots,\\text{R}_t]$ 的单行，其中 $\\text{R}_j$ 是测试用例 $j$ 的嵌套列表结果，$t$ 是测试用例的数量。\n\n答案纯粹是整数列表；不涉及物理单位或角度。请确保您的实现能正确处理自动机内的重叠匹配和通过后缀链接产生的输出，并确保对每个测试用例，其运行时间与 $|T| + L$ 成线性关系。",
            "solution": "用户提供了一个来自数据结构和算法领域的明确定义的计算问题，要求实现用于多模式字符串匹配的 Aho-Corasick 自动机。问题陈述的有效性验证如下：\n\n-   **科学或事实的可靠性**：该问题基于已确立的有限自动机和字符串算法理论。Aho-Corasick 自动机是一种标准、可靠的计算机科学模型。问题陈述准确地描述了其组成部分和构造方法（trie、失败链接、输出函数）。不存在科学或事实错误。\n-   **适定性**：该问题是适定的。它提供了具体的输入（模式、文本、检查点），并要求清晰、确定性的输出（在指定时间的动态计数值向量）。计数的规则，包括处理重叠匹配和通过失败链接匹配后缀的规则，都得到了明确定义，确保了唯一且有意义的解的存在。\n-   **客观性**：问题以形式化、客观的语言陈述。所有输入和预期输出都是定量的，没有歧义或主观解释的余地。\n-   **完整性和一致性**：问题为每个测试用例提供了所有必要信息——模式、文本和检查点位置。对算法构造和行为的要求在内部是一致且完整的。\n-   **可行性**：所提供的测试用例规模较小，使得该问题在典型的时限内计算上是可行的。所要求的线性时间复杂度是 Aho-Corasick 算法已知的最优性能，证实了该问题的理论基础。\n\n该问题被认为是有效的，因为它满足了一个形式化的、可解的科学问题的所有标准。以下解决方案按规定实现了 Aho-Corasick 算法。\n\n### 算法设计\n\n解决方案分为两个主要阶段：自动机构建和文本处理。\n\n1.  **自动机构建**：\n    -   **Trie 构建**：首先，根据输入的模式集合构建一个 trie（前缀树）。trie 中的每个节点代表一个或多个模式的唯一前缀。根节点代表空字符串。每条边都用一个字符标记。对应于模式 $P_i$ 结尾的节点在其 `output` 集合中存储索引 $i$。\n        -   我们将自动机表示为一个节点列表，其中每个节点是一个字典，包含其 `transitions`（从字符到子节点索引的映射）、一个 `output` 列表（模式索引）和一个 `failure_link`（另一个节点的索引）。\n        -   通过遍历每个模式，并对每个字符从根节点开始遍历，必要时添加新节点来构建 trie。\n\n    -   **失败链接和输出传播**：trie 构建完成后，计算失败链接。对于任何对应于字符串 $w$ 的状态 $s$，其失败链接指向对应于 $w$ 的最长真后缀的状态，该后缀同时也是集合中某个模式的前缀。\n        -   这些链接使用广度优先搜索（BFS）从深度为 $1$ 的节点开始高效计算。对于从父节点 $u$ 通过字符 $c$ 到达的节点 $v$，我们通过跟随 $u$ 的失败链接到一个状态 $f$，并检查 $f$ 是否有关于 $c$ 的转移来找到 $v$ 的失败链接。如果没有，我们继续跟随 $f$ 的失败链接，直到找到这样的转移或到达根节点。\n        -   根据问题要求，一个关键步骤是扩充输出集。节点 $v$ 的输出集被扩展，以包含其失败链接指向的节点的所有输出。这确保了如果我们匹配像 `\"she\"` 这样的字符串，我们也会报告其后缀 `\"he\"` 的匹配（如果 `\"he\"` 在模式集中）。这个传播过程也在 BFS 期间完成。\n\n2.  **文本处理和计数**：\n    -   输入文本 $T$ 被逐个字符地处理。自动机维护一个 `current_state`，初始时为根节点。\n    -   对于文本中的每个字符 $c$，自动机尝试从 `current_state` 进行转移。如果存在关于 $c$ 的转移，则执行该转移。如果没有，自动机将跟随 `current_state` 的失败链接并重试转移。重复此过程，直到找到转移或到达根状态。如果到达根状态并且没有关于 $c$ 的转移，则 `current_state` 保持为根节点。\n    -   每次转移后，`current_state` 代表以文本当前位置结尾且同时是某个模式前缀的最长字符串。\n    -   这个 `current_state` 的 `output` 集合包含所有在此位置结束的模式的索引。对于 `output` 集合中的每个模式索引，计数向量 $C$ 中的相应条目会递增。\n    -   在每个指定的检查点（对应于到目前为止已处理的字符数），会记录当前 `counts` 向量的快照。\n\n这种设计保证了所有出现（包括重叠的以及通过后缀找到的）都被正确计数，并且总时间复杂度与模式总长度和文本长度之和成线性关系，即 $O(L+n)$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\ndef solve():\n    \"\"\"\n    Main function to run the Aho-Corasick algorithm on a suite of test cases.\n    It builds the automaton, processes the text, and collects results\n    as per the problem specification.\n    \"\"\"\n    \n    # Helper function to format the final output list without spaces.\n    def format_list_no_spaces(data):\n        if isinstance(data, list):\n            return f\"[{','.join(format_list_no_spaces(item) for item in data)}]\"\n        else:\n            return str(data)\n\n    def build_automaton(patterns):\n        \"\"\"\n        Builds the Aho-Corasick automaton (trie, failure links, and output propagation).\n        \"\"\"\n        # The automaton is a list of nodes.\n        # Each node is a dict: {'transitions': {}, 'output': [], 'failure_link': 0}\n        nodes = [{'transitions': {}, 'output': [], 'failure_link': 0}]\n        \n        # 1. Build the basic trie structure.\n        for i, pattern in enumerate(patterns):\n            node_idx = 0\n            for char in pattern:\n                if char not in nodes[node_idx]['transitions']:\n                    new_node_idx = len(nodes)\n                    nodes[node_idx]['transitions'][char] = new_node_idx\n                    nodes.append({'transitions': {}, 'output': [], 'failure_link': 0})\n                node_idx = nodes[node_idx]['transitions'][char]\n            nodes[node_idx]['output'].append(i)\n\n        # 2. Compute failure links and propagate outputs using BFS.\n        queue = collections.deque()\n        # Start BFS with all nodes at depth 1. Their failure links point to the root (0).\n        for node_idx in nodes[0]['transitions'].values():\n            queue.append(node_idx)\n            # The failure link is already 0 by default, so no explicit set needed here.\n\n        while queue:\n            current_idx = queue.popleft()\n            \n            for char, next_idx in nodes[current_idx]['transitions'].items():\n                queue.append(next_idx)\n                \n                # Find failure link for next_idx.\n                fail_idx = nodes[current_idx]['failure_link']\n                while char not in nodes[fail_idx]['transitions'] and fail_idx != 0:\n                    fail_idx = nodes[fail_idx]['failure_link']\n                \n                if char in nodes[fail_idx]['transitions']:\n                    nodes[next_idx]['failure_link'] = nodes[fail_idx]['transitions'][char]\n                else:\n                    # If we reach the root and still no transition, failure link is root.\n                    nodes[next_idx]['failure_link'] = 0\n                \n                # Propagate output from the failure node.\n                fail_output_idx = nodes[next_idx]['failure_link']\n                nodes[next_idx]['output'].extend(nodes[fail_output_idx]['output'])\n        \n        return nodes\n\n    def run_search(automaton, text, num_patterns, checkpoints):\n        \"\"\"\n        Processes the text using the automaton and records counts at checkpoints.\n        \"\"\"\n        checkpoints_set = set(checkpoints)\n        snapshots = []\n        counts = np.zeros(num_patterns, dtype=int)\n        current_state_idx = 0\n\n        for k, char in enumerate(text, 1):\n            # Follow failure links until a transition is found or we are at the root.\n            while char not in automaton[current_state_idx]['transitions'] and current_state_idx != 0:\n                current_state_idx = automaton[current_state_idx]['failure_link']\n            \n            # If a transition for the character exists, take it. Otherwise, stay at root.\n            current_state_idx = automaton[current_state_idx]['transitions'].get(char, 0)\n            \n            # Collect all outputs from the current state.\n            if automaton[current_state_idx]['output']:\n                for pattern_idx in automaton[current_state_idx]['output']:\n                    counts[pattern_idx] += 1\n            \n            # Record a snapshot if the current position is a checkpoint.\n            if k in checkpoints_set:\n                snapshots.append(counts.tolist())\n        \n        return snapshots\n\n    # The test suite provided in the problem statement.\n    test_cases = [\n        (\n            [\"a\", \"ab\", \"bab\", \"bc\", \"bca\", \"c\", \"caa\"],\n            \"abccab\",\n            [1, 3, 6]\n        ),\n        (\n            [\"aa\", \"aaa\"],\n            \"aaaaa\",\n            [1, 2, 3, 4, 5]\n        ),\n        (\n            [\"he\", \"she\", \"his\", \"hers\"],\n            \"ushers\",\n            [6]\n        ),\n        (\n            [\"xyz\", \"q\"],\n            \"aaaa\",\n            [4]\n        ),\n        (\n            [\"aba\", \"ba\"],\n            \"ababa\",\n            [2, 5]\n        )\n    ]\n\n    all_results = []\n    for patterns, text, checkpoints in test_cases:\n        num_patterns = len(patterns)\n        automaton = build_automaton(patterns)\n        snapshots = run_search(automaton, text, num_patterns, checkpoints)\n        all_results.append(snapshots)\n    \n    # Final print statement in the exact required format.\n    print(format_list_no_spaces(all_results))\n\nsolve()\n\n```"
        },
        {
            "introduction": "现实世界中的匹配任务通常需要灵活性，例如忽略大小写差异。这个实践将挑战你调整 Aho-Corasick 自动机以实现大小写不敏感的匹配，同时避免低效地存储所有大小写变体。解决问题的关键在于使用规范化（normalization）技术，即在模式串和文本的规范化表示上构建和运行自动机，这是字符串算法设计中一种强大的技巧 。",
            "id": "3205013",
            "problem": "给定一个有限字母表上的有限模式集和一个文本。任务是执行不区分大小写的多模式精确匹配，并且不在底层的字典树中显式存储字母的每一种大小写变体。形式上，设字母表为 $\\Sigma$，模式集为 $P = \\{p_1, p_2, \\dots, p_k\\}$，其中每个 $p_i \\in \\Sigma^{*}$，文本为 $T \\in \\Sigma^{*}$。考虑在标准的 7 位美国信息交换标准代码 (ASCII) 上定义如下映射 $\\phi : \\Sigma \\rightarrow \\Sigma$：对于任意字符 $c \\in \\Sigma$，如果 $c$ 是一个大写英文字母，则 $\\phi(c)$ 是其对应的小写字母，否则 $\\phi(c) = c$。通过同态将 $\\phi$ 扩展到字符串，即对于任意字符串 $s = c_1 c_2 \\cdots c_n$，定义 $\\phi(s) = \\phi(c_1)\\phi(c_2)\\cdots\\phi(c_n)$。在不区分大小写的语义下，当且仅当 $\\phi(p)$ 在 $\\phi(T)$ 的位置 $i$ 处出现时，我们称模式 $p$ 在 $T$ 的位置 $i$ 处出现。一次出现会为该模式的总计数贡献 $1$。\n\n进行推理和设计时需使用的基本原理和约束：\n- 字符串是 $\\Sigma$ 上的序列，通过符号相等性进行比较。\n- 字典树（trie）是一种有根树，以 $\\Sigma$ 的符号为键。从一个节点出发的每条边都由一个符号标记，且从根到任意节点的路径标签序列是唯一的。\n- Aho–Corasick 自动机是通过在字典树上增加失效链接得到的。失效链接通过“同时也是字典树中前缀的最长真后缀”来定义。此外，每个节点还有一个输出函数，用于列出在该节点结束的模式。当字母表固定时，它支持在与文本长度加上匹配数量成线性关系的时间内进行同步模式匹配。\n- 您不能在字典树中显式存储同一字母的所有大小写变体。相反，您必须根据上述基本原理和映射 $\\phi$ 进行推导，构建一个基于简化的有效字母表的自动机，同时仍能报告 $P$ 中所有原始模式的出现次数。\n\n您的任务：\n- 设计并实现一个程序，构建一个能够报告在由 $\\phi$ 诱导的不区分大小写语义下，模式在 $T$ 中出现的总次数的自动机，且不在字典树中复制大小写变体的边。该自动机必须构建在由 $\\phi$ 诱导的规范字母表上，并且输出函数必须考虑到 $P$ 中多个不同的原始模式在 $\\phi$ 作用下可能归一化为相同字符串的情况。\n- 正确性要求：在不区分大小写的匹配下，$P$ 中任何 $p_i$ 在 $T$ 中的每一次出现都必须被计数，包括重叠部分。如果两个不同的模式 $p_i$ 和 $p_j$ 满足 $\\phi(p_i) = \\phi(p_j)$，那么 $\\phi(p_i)$ 在 $\\phi(T)$ 中的单次出现将为 $p_i$ 贡献 $1$ 次计数，为 $p_j$ 也贡献 $1$ 次计数，即被计数两次。\n\n复杂度目标：\n- 确保构建自动机的时间复杂度相对于所构建字典树的大小，与 $\\sum_{i=1}^{k} |p_i|$ 成渐进线性关系，并且扫描文本的时间复杂度与 $|T|$ 加上匹配数量成线性关系。避免任何将同一字母的大小写变体都插入字典树的方法。\n\n测试套件：\n实现您的程序，为以下每个测试用例计算总匹配数。每个测试用例是一个序对 $(P, T)$，其中 $P$ 是模式列表，$T$ 是文本字符串。\n- 测试用例 1：$P = [$\"he\", \"she\", \"his\", \"hers\"$]$, $T =$ \"aHiShErS\".\n- 测试用例 2：$P = [$\"Ab\", \"aB\", \"AB\", \"ab\"$]$, $T =$ \"xxAbYYaBzz\".\n- 测试用例 3：$P = [$\"a\", \"aa\"$]$, $T =$ \"AaA\".\n- 测试用例 4：$P = [$\"C++\", \"c+\"$]$, $T =$ \"C++C+\".\n- 测试用例 5：$P = [$\"Test\"$]$, $T =$ \"\" (空字符串)。\n\n输出规范：\n- 对于每个测试用例，计算一个整数，该整数等于 $P$ 中所有模式的总匹配次数，需要计算重叠部分，并且即使多个模式归一化为相同的 $\\phi$-像，也要对每个模式分别计数。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如：$\"[r_1,r_2,\\dots]\"$），结果的顺序与测试用例 1 到 5 的顺序一致。\n\n此问题不涉及物理单位、角度或百分比。请确保解决方案是根据所提供的基本定义和事实推导得出，而不是基于预先给定的快捷公式。",
            "solution": "该问题要求使用 Aho-Corasick 自动机执行不区分大小写的的多模式匹配，并带有一个特殊约束：底层的字典树不能显式存储大小写变体。这是一个经典的算法任务，涉及将标准算法调整以适应字母表上的特定等价关系。\n\n### 基于原则的设计\n\n解决方案建立在归一化原则之上。问题定义了一个映射 $\\phi$，它将大写英文字母转换为相应的小写形式，并保持其他字符不变。该映射在字母表 $\\Sigma$ 上诱导了一个等价关系，其中两个字符 $c_1$ 和 $c_2$ 在 $\\phi(c_1) = \\phi(c_2)$ 时是等价的。此关系可扩展到字符串：两个字符串 $s_1$ 和 $s_2$ 在 $\\phi(s_1) = \\phi(s_2)$ 时是等价的。匹配规则——模式 $p$ 在文本 $T$ 中出现，当且仅当 $\\phi(p)$ 在 $\\phi(T)$ 中出现——正是利用了这种等价性。\n\n我们可以不在原始字母表 $\\Sigma$ 上执行搜索，而是完全在规范字母表内工作来简化问题。规范字母表是 $\\Sigma$ 在 $\\phi$ 映射下的像（即小写字母和非字母字符）。Aho-Corasick 自动机将使用这些规范字符来构建和操作。\n\n设计主要分三个阶段进行：\n1.  **自动机构建（构建阶段）**：此阶段根据模式集 $P$ 构建不区分大小写的 Aho-Corasick 自动机。\n2.  **文本处理（搜索阶段）**：此阶段使用构建好的自动机在文本 $T$ 中查找所有模式的出现。\n3.  **正确计数**：一个关键细节是确保根据问题规范正确地对每次匹配进行计数，特别是当多个原始模式归一化为同一字符串时。\n\n#### 1. 自动机构建\n\n该自动机建立在由*归一化*模式 $\\{\\phi(p) \\mid p \\in P\\}$ 构建的字典树之上。\n\n**字典树构建**：我们遍历 $P$ 中的每个模式 $p$，计算其归一化形式 $s = \\phi(p)$，然后将 $s$ 插入字典树中。字典树的节点代表归一化模式的前缀。每条边都用规范字母表中的一个字符标记。\n\n**输出函数**：问题规定，如果两个不同的模式 $p_i$ 和 $p_j$ 归一化为同一个字符串（即 $\\phi(p_i) = \\phi(p_j)$），那么这个归一化字符串的单次匹配应该为两者都计数。为处理此情况，我们在字典树的每个节点上关联一个 `direct_output_count`。对于输入集 $P$ 中的每个模式 $p_i$，在沿 $\\phi(p_i)$ 的路径遍历字典树到达节点 $u$ 后，我们将 `direct_output_count[u]` 增加 $1$。这样，`direct_output_count[u]` 就存储了归一化为节点 $u$ 所代表的确切字符串的原始模式数量。\n\n**失效链接**：字典树构建完成后，我们添加失效链接以创建完整的自动机。从节点 $u$（代表字符串 $s$）出发的失效链接指向代表 $s$ 的最长真后缀且该后缀同时也是字典树中一个前缀的节点 $v$。这些链接对于线性时间匹配至关重要，因为它们允许自动机在遇到字符不匹配时平滑地进行状态转换，而无需从文本的开头重新开始搜索。失效链接通过从根节点的子节点开始的广度优先搜索 (BFS) 来计算。对于一个父节点为 $u$、通过字符 $c$ 到达的节点 $v$，其失效链接是通过跟随其父节点的失效链接 `fail[u]` 并尝试在字符 $c$ 上进行转换来找到的。此过程将重复进行，直到找到一个有效的转换或到达根节点。\n\n**输出传播**：一个模式的匹配也意味着其任何同时也是模式的后缀的匹配。例如，匹配 \"she\" 也意味着我们匹配了 \"he\"。为了高效地处理这一点，我们为每个节点计算一个 `aggregated_output_count`。该值是节点自身的 `direct_output_count` 与其失效节点的 `aggregated_output_count` 之和。这可以在计算失效链接的 BFS 过程中完成，因为一个节点的失效链接总是指向一个更浅深度的节点，而该节点已经被处理过。递推关系是：\n$$\n\\text{aggregated\\_output\\_count}[u] = \\text{direct\\_output\\_count}[u] + \\text{aggregated\\_output\\_count}[\\text{fail}[u]]\n$$\n这确保了当自动机到达状态 $u$ 时，我们可以通过简单地查找 `aggregated_output_count[u]`，在 $O(1)$ 时间内找到在当前文本位置结束的模式总数。\n\n#### 2. 文本处理\n\n搜索阶段涉及将*归一化*的文本 $\\phi(T)$ 一次一个字符地输入自动机。\n\n**状态转换**：从根节点（状态 0）开始，对于 $\\phi(T)$ 中的每个字符 $c$，自动机转换到一个新状态。如果当前状态有对应字符 $c$ 的子节点，则转移到该子节点。如果没有，则沿着失效链接移动，直到找到一个对 $c$ 有转换的状态，或者到达根节点。\n\n**计数匹配**：每次转换到状态 $u$ 后，我们将 `aggregated_output_count[u]` 加到一个运行总和上。这会正确地计算出在当前文本位置结束的所有模式（包括重叠的模式和后缀）。\n\n#### 3. 复杂度分析\n\n设 $L = \\sum_{p \\in P} |p|$ 为所有模式的总长度，$N = |T|$ 为文本的长度。规范字母表的大小是一个固定常数 (ASCII)。\n\n-   **模式归一化**：$O(L)$。\n-   **字典树构建**：每个归一化模式的每个字符都被处理一次。这需要 $O(L)$ 时间。字典树中的节点数最多为 $L+1$。\n-   **失效链接和输出计算**：基于 BFS 的计算所需时间与字典树的大小成均摊线性关系，即 $O(L)$。\n-   **总构建时间**：$O(L)$。\n-   **文本归一化**：$O(N)$。\n-   **搜索时间**：对于归一化文本中的 $N$ 个字符中的每一个，自动机执行一次状态转换。失效链接遍历的总次数在整个搜索过程中被均摊，从而使总搜索时间为 $O(N)$。\n-   **总体复杂度**：总时间复杂度为 $O(L+N)$，满足问题的目标。\n\n此设计正确地实现了不区分大小写的匹配，而没有在字典树中显式表示大小写变体，遵守了所有约束并提供了一个高效的解决方案。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the multiple-pattern matching problem for the given test cases.\n    \"\"\"\n\n    class AhoCorasick:\n        \"\"\"\n        An Aho-Corasick automaton for case-insensitive multi-pattern matching.\n        \"\"\"\n        def __init__(self):\n            # The trie is a list of nodes. Each node is a dictionary.\n            # 'children': maps characters to the index of the child node.\n            # 'fail': index of the failure link node.\n            # 'direct_output_count': number of original patterns ending at this node.\n            # 'output_count': total matches found when landing on this state (includes suffixes).\n            self.trie = [{'children': {}, 'fail': 0, 'direct_output_count': 0, 'output_count': 0}]\n            self.patterns_added = False\n\n        def _phi(self, text: str) -> str:\n            \"\"\"Normalizes a string to its canonical form (lowercase).\"\"\"\n            return text.lower()\n\n        def add_pattern(self, pattern: str):\n            \"\"\"\n            Adds a normalized pattern to the trie.\n            The `build_automaton` method should be called after all patterns are added.\n            \"\"\"\n            if self.patterns_added:\n                raise Exception(\"Cannot add patterns after building the automaton.\")\n            \n            normalized_pattern = self._phi(pattern)\n            node_idx = 0\n            for char in normalized_pattern:\n                node = self.trie[node_idx]\n                if char not in node['children']:\n                    node['children'][char] = len(self.trie)\n                    self.trie.append({'children': {}, 'fail': 0, 'direct_output_count': 0, 'output_count': 0})\n                node_idx = node['children'][char]\n            self.trie[node_idx]['direct_output_count'] += 1\n\n        def build_automaton(self):\n            \"\"\"\n            Builds the failure links and computes aggregated output counts.\n            This must be called after all patterns have been added and before searching.\n            \"\"\"\n            if self.patterns_added:\n                return # Avoid rebuilding\n            \n            self.patterns_added = True\n            queue = []\n\n            # Initialize failure links and output counts for depth 1 nodes.\n            for char, child_idx in self.trie[0]['children'].items():\n                self.trie[child_idx]['fail'] = 0\n                queue.append(child_idx)\n                # This direct propagation is the base for the recursive definition\n                self.trie[child_idx]['output_count'] = self.trie[child_idx]['direct_output_count']\n\n            # BFS to build failure links for nodes at depth > 1.\n            head = 0\n            while head  len(queue):\n                current_idx = queue[head]\n                head += 1\n                current_node = self.trie[current_idx]\n\n                for char, next_idx in current_node['children'].items():\n                    queue.append(next_idx)\n                    fail_idx = current_node['fail']\n                    \n                    # Follow failure links until a transition for `char` is found or root is reached.\n                    while char not in self.trie[fail_idx]['children'] and fail_idx != 0:\n                        fail_idx = self.trie[fail_idx]['fail']\n                    \n                    if char in self.trie[fail_idx]['children']:\n                        self.trie[next_idx]['fail'] = self.trie[fail_idx]['children'][char]\n                    else:\n                        self.trie[next_idx]['fail'] = 0\n\n                    # Propagate output counts along the failure links.\n                    fail_node_output = self.trie[self.trie[next_idx]['fail']]['output_count']\n                    self.trie[next_idx]['output_count'] = self.trie[next_idx]['direct_output_count'] + fail_node_output\n\n        def search(self, text: str) - int:\n            \"\"\"\n            Searches for all occurrences of the patterns in the given text.\n            Returns the total count of matches.\n            \"\"\"\n            if not self.patterns_added:\n                self.build_automaton()\n\n            normalized_text = self._phi(text)\n            current_state_idx = 0\n            total_matches = 0\n\n            for char in normalized_text:\n                # Follow failure links if no direct child for the character exists.\n                while char not in self.trie[current_state_idx]['children'] and current_state_idx != 0:\n                    current_state_idx = self.trie[current_state_idx]['fail']\n                \n                # If a transition exists, take it.\n                if char in self.trie[current_state_idx]['children']:\n                    current_state_idx = self.trie[current_state_idx]['children'][char]\n                \n                # Add the aggregated output count of the current state to the total.\n                total_matches += self.trie[current_state_idx]['output_count']\n            \n            return total_matches\n\n    test_cases = [\n        ({\"patterns\": [\"he\", \"she\", \"his\", \"hers\"], \"text\": \"aHiShErS\"}),\n        ({\"patterns\": [\"Ab\", \"aB\", \"AB\", \"ab\"], \"text\": \"xxAbYYaBzz\"}),\n        ({\"patterns\": [\"a\", \"aa\"], \"text\": \"AaA\"}),\n        ({\"patterns\": [\"C++\", \"c+\"], \"text\": \"C++C+\"}),\n        ({\"patterns\": [\"Test\"], \"text\": \"\"})\n    ]\n\n    results = []\n    for case in test_cases:\n        ac = AhoCorasick()\n        for p in case[\"patterns\"]:\n            ac.add_pattern(p)\n        ac.build_automaton()\n        result = ac.search(case[\"text\"])\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "除了找到所有匹配，我们常常需要筛选出最重要的那一个，例如最长的匹配模式。这个进阶实践要求你修改自动机的输出机制，使其在任何位置只报告最长的匹配项。你将学习如何在自动机构建阶段预先计算这些信息，从而在搜索时实现近乎常数时间复杂度的查询，这展示了一种优雅的优化技术 。",
            "id": "3204893",
            "problem": "考虑一个有限字母表 $\\Sigma$，一个在 $\\Sigma$ 上的有限模式串集合 $P = \\{p_0, p_1, \\dots, p_{m-1}\\}$，其中 $|p_j|$ 表示模式串 $p_j$ 的长度，以及一个在 $\\Sigma$ 上长度为 $n$ 的文本 $T$。Aho–Corasick 自动机建立在三个核心组件之上，这些组件源于数据结构和算法中的基础定义：一个包含所有模式串的 trie 树（前缀树），一个将每个 trie 节点映射到其最长真后缀（该后缀同时也是 trie 树中一个前缀）对应状态的失配函数，以及一个将每个状态与在该状态终止的模式串集合相关联的输出函数。标准的 Aho–Corasick 自动机通过从左到右扫描 $T$，遵循 trie 转移和失配转移，并在当前状态的输出集非空时报告匹配，从而实现并发的多模式匹配。\n\n你的任务是设计并实现一个完整的程序，该程序为给定的模式串集合构建 Aho–Corasick 自动机，然后修改其输出报告机制，使得在扫描文本 $T$ 时，在任意位置 $i$（其中 $0 \\le i \\le n-1$），自动机仅报告在位置 $i$ 结束的所有模式串中唯一最长的那一个。如果在此最大长度下有多个模式串，则通过选择在 $P$ 中具有最小原始索引（使用基于 $0$ 的索引）的模式串来打破平局。报告顺序必须是 $T$ 中位置的时间顺序（从 $i = 0$ 到 $i = n-1$）：在每个至少有一个模式串结束的位置，将一个且仅一个索引（所选模式串的索引）附加到输出序列中；在没有模式串结束的位置，不附加任何内容。\n\n从以下符合上下文的基础定义开始：\n- trie 树是 $\\Sigma$ 上的一个有根树，其中每条边都由 $\\Sigma$ 中的一个字符标记，每个模式串 $p_j$ 通过跟随或创建与其字符相对应的边来插入。$p_j$ 的终止节点在其输出集中存储 $j$。\n- 失配函数通过对 trie 树进行广度优先搜索（BFS）来构建：一个节点的失配链接指向一个状态，该状态代表了当前节点字符串的最长真后缀，且该后缀同时也是 trie 树中的一个前缀。这确保了在扫描过程中发生不匹配时，自动机可以转换到一个更短的有效状态，而无需重读输入。\n- 一个节点的输出函数是其终止模式串索引集合与其失配状态输出的并集，这确保了所有在当前位置结束的模式串都被报告。\n\n你必须严格地从这些基本定义出发推导出修改后的报告机制，不得调用任何外部的快捷公式。修改必须保持扫描的渐进时间复杂度，该复杂度应保持为文本长度 $n$ 加上自动机总大小的线性时间。通过适当的预计算来实现这种复杂度的保持，从而使在每个位置选择唯一的、最长的模式串不会在匹配数量上引入超线性开销。\n\n程序要求：\n1. 使用上述原则为提供的测试用例模式串构建 Aho–Corasick 自动机。设 $\\ell_j = |p_j|$ 为模式串 $p_j$ 的长度。\n2. 按如下方式定义修改后的输出语义。如果在处理文本位置 $i$ 后，$out(q)$ 是与当前自动机状态 $q$ 相关联的模式串索引集合，则仅报告\n   $$ j^\\star = \\min\\left\\{ j \\in out(q) \\,:\\, \\ell_j = \\max_{k \\in out(q)} \\ell_k \\right\\} $$\n   并将 $j^\\star$ 附加到结果序列中。如果 $out(q)$ 为空，则对于该位置 $i$ 不附加任何内容。\n3. 通过基于 trie 树和失配函数的适当预计算，确保在运行时选择 $j^\\star$ 的操作对于每个位置是 $\\mathcal{O}(1)$ 的均摊时间复杂度。\n4. 对于每个测试用例，输出报告的模式串索引序列（按文本中的时间顺序）。\n\n测试用例：\n- 测试用例 $1$：$P = [$\"he\", \"she\", \"his\", \"hers\"$]$, $T =$ \"ushers\"。\n- 测试用例 $2$：$P = [$\"a\", \"aa\", \"aaa\"$]$, $T =$ \"aaaaa\"。\n- 测试用例 $3$：$P = [$\"aba\", \"aba\", \"ba\"$]$, $T =$ \"caba\"。此用例包含重复的模式串，以验证按最小索引打破平局的规则。\n- 测试用例 $4$：$P = [$\"xyz\"$]$, $T =$ \"abc\"。\n- 测试用例 $5$：$P = [$\"cat\", \"at\", \"t\"$]$, $T =$ \"catcat\"。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含用方括号括起来的、逗号分隔的结果列表。每个元素对应一个测试用例，并且本身也必须是一个用方括号括起来的、逗号分隔的整数列表，不含空格。例如，最外层结构必须像\n$$ [ [\\dots], [\\dots], [\\dots], [\\dots], [\\dots] ] $$\n这样，任何地方都不能有空格，例如 $[[0,2],[1],[\\,],\\dots]$，其中 $[\\,]$ 表示一个空列表。程序必须是自包含的，并且不需要任何输入。必须为上面给出的测试用例精确计算输出。",
            "solution": "用户的要求是设计一个基于 Aho-Corasick 自动机的算法，在文本 $T$ 的每个位置找到唯一的最长匹配模式串，并根据最小模式串索引来打破平局。此过程必须是高效的，在每个位置选择最佳模式串的均摊时间复杂度为 $\\mathcal{O}(1)$。\n\n该问题在计算上是明确定义的，在科学上以字符串算法理论为基础，并为唯一解提供了足够的信息。因此，该问题被认为是有效的。解决方案如下。\n\n### 基于原则的设计\n\n该问题要求对标准 Aho-Corasick 输出机制进行修改。一个标准的自动机在到达状态 $q$ 时，通过遍历失配链接链：$q, \\text{failure}(q), \\text{failure}(\\text{failure}(q)), \\dots$，直到到达根节点，并收集找到的所有终止模式串，来识别在当前文本位置结束的所有模式串。每次遍历可能需要超常数时间，这违反了性能约束。\n\n为了实现 $\\mathcal{O}(1)$ 的均摊查找时间，我们必须为自动机的每个状态预计算最优输出。让我们为每个状态定义一个 `best_match` 对 $(\\ell, j)$，其中 $\\ell$ 是最佳模式串的长度，$j$ 是其原始索引。问题将“最佳”定义为具有最大长度的模式串，并用最小索引打破平局。如果 $\\ell_1  \\ell_2$ 或者 $(\\ell_1 = \\ell_2 \\text{ 且 } j_1  j_2)$，则称对 $(\\ell_1, j_1)$ 优于 $(\\ell_2, j_2)$。\n\n解决方案分为三个主要阶段：\n$1$. 构建 trie 树和失配函数，这是 Aho-Corasick 自动机的标准组件。\n$2$. 为每个状态预计算 `best_match`。\n$3$. 使用预计算的数据扫描文本以查找匹配项。\n\n#### $1$. 自动机构建（Trie 树和失配链接）\n\n首先，我们从模式串集合 $P = \\{p_0, p_1, \\dots, p_{m-1}\\}$ 构建一个 trie 树。trie 树是一个有根树，其中每条边都用字母表 $\\Sigma$ 中的一个字符标记。每个模式串 $p_j$ 对应于从根节点开始的一条唯一路径。为 $p_j$ 的路径终点所到达的节点是一个终止节点，我们在该节点存储其身份信息——具体来说，是其长度 $|p_j|$ 和索引 $j$。\n\n接下来，我们为每个状态 $q$ 计算失配函数 $\\text{failure}(q)$。失配函数将一个状态 $q$（代表前缀 $s$）映射到代表 $s$ 的最长真后缀（该后缀同时也是 trie 树中的一个前缀）的状态。这是通过从根节点开始的广度优先搜索（BFS）构建的。根节点的失配链接是其自身。对于从其父节点 $p$ 通过字符 $c$ 到达的任何其他状态 $q$，其失配链接通过遍历 $p$ 的失配链接来找到，直到找到一个在 $c$ 上有转移的状态。\n\n#### $2$. 预计算最佳匹配\n\n关键的洞见在于，在一个状态 $q$ 匹配的所有模式串集合，记为 $\\text{out}(q)$，是恰好在 $q$ 结束的模式串集合（我们称之为 $\\text{terminal}(q)$）与在其失配状态 $\\text{out}(\\text{failure}(q))$ 匹配的模式串集合的并集。\n$$ \\text{out}(q) = \\text{terminal}(q) \\cup \\text{out}(\\text{failure}(q)) $$\n\n这个递归定义允许我们使用动态规划为每个状态计算 `best_match`。设 $\\text{best_match}(q)$ 为从集合 $\\text{out}(q)$ 中选出的最佳匹配对 $(\\ell, j)$。设 $\\text{term_best}(q)$ 为仅从 $\\text{terminal}(q)$ 中的模式串选出的最佳匹配对。那么：\n$$ \\text{best_match}(q) = \\text{better_of}(\\text{term_best}(q), \\text{best_match}(\\text{failure}(q))) $$\n\n我们可以在自动机中为所有状态 $q$ 计算 $\\text{best_match}(q)$。由于 $\\text{failure}(q)$ 总是指向 trie 树中深度严格更小的状态，我们可以在一次 BFS 遍历中计算所有状态的 $\\text{best_match}$ 值。在 BFS 期间，当我们处理状态 $q$ 时，$\\text{best_match}(\\text{failure}(q))$ 的值将已经被计算出来。\n算法如下：\n$1$. 对所有状态 $q$，初始化 $\\text{best_match}(q) = (-1, -1)$。\n$2$. 对每个状态 $q$，从 $\\text{terminal}(q)$ 中的模式串计算 $\\text{term_best}(q)$。这包括在终止模式串中找到最大长度，然后找到该长度对应的最小索引。\n$3$. 对 trie 树的状态执行 BFS。对于访问的每个状态 $q$：\n    a. 令 $f = \\text{failure}(q)$。\n    b. 来自失配链接链的最佳匹配是 $\\text{best_match}(f)$。\n    c. 将 $\\text{best_match}(q)$ 更新为其自身的 $\\text{term_best}(q)$ 和 $\\text{best_match}(f)$ 中的更优者。\n\n#### $3$. 文本扫描\n\n在预计算了 `best_match` 数组后，扫描文本 $T$ 变得非常高效。我们根据 $T$ 的字符遍历自动机。\n$1$. 从根状态开始，$q_{current} = 0$。\n$2$. 对于 $T$ 中的每个字符 $c$：\n    a. 通过跟随 $c$ 的转移找到下一个状态。如果从 $q_{current}$ 没有直接的转移，则跟随失配链接直到找到一个转移或到达根节点。这是标准的 Aho-Corasick 状态转移逻辑，具有均摊常数时间复杂度。设新状态为 $q_{next}$。\n    b. 更新 $q_{current} \\leftarrow q_{next}$。\n    c. 查找 $q_{current}$ 的预计算 `best_match`：$(\\ell, j) = \\text{best_match}(q_{current})$。\n    d. 如果存在有效匹配（即 $\\ell \\neq -1$），则将索引 $j$ 附加到结果序列中。\n\n此过程确保在文本的每个位置 $i$，我们都能在 $\\mathcal{O}(1)$ 的均摊时间内找到唯一的最佳匹配模式串，因为它在状态转移后只需要一次数组查找。扫描的总时间复杂度为 $\\mathcal{O}(n)$，其中 $n=|T|$。算法的整体复杂度由构建和预计算阶段主导，为 $\\mathcal{O}(\\sum_{j=0}^{m-1} |p_j|)$，外加扫描时间。\n\n这种方法正确地实现了所需修改，同时保留了 Aho-Corasick 算法的线性时间复杂度特性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Aho-Corasick longest pattern problem for a suite of test cases.\n    \"\"\"\n\n    class AhoCorasick:\n        \"\"\"\n        An implementation of the Aho-Corasick automaton with a modified output\n        mechanism to report only the longest pattern at each position.\n        \"\"\"\n        def __init__(self, patterns):\n            \"\"\"\n            Initializes the automaton from a list of patterns.\n            Args:\n                patterns (list of str): The patterns to search for.\n            \"\"\"\n            self._patterns = patterns\n            \n            # Trie nodes are represented as dicts\n            # 'children': mapping from char to child node index\n            # 'fail': index of the failure link node\n            # 'terminal': list of (length, index) tuples for patterns ending here\n            self._nodes = [{'children': {}, 'fail': 0, 'terminal': []}]\n            \n            # Stores the best match (length, index) for each state, considering failure links\n            self._best_match = [(-1, -1)]\n\n            self._build_trie()\n            self._build_failure_links_and_best_matches()\n\n        def _build_trie(self):\n            \"\"\"Builds the initial trie from the patterns.\"\"\"\n            for i, pattern in enumerate(self._patterns):\n                node_idx = 0\n                for char in pattern:\n                    node = self._nodes[node_idx]\n                    if char not in node['children']:\n                        node['children'][char] = len(self._nodes)\n                        self._nodes.append({'children': {}, 'fail': 0, 'terminal': []})\n                        self._best_match.append((-1, -1))\n                    node_idx = node['children'][char]\n                self._nodes[node_idx]['terminal'].append((len(pattern), i))\n\n        def _build_failure_links_and_best_matches(self):\n            \"\"\"\n            Computes failure links and precomputes the best match for each state\n            using a single Breadth-First Search (BFS) traversal.\n            \"\"\"\n            queue = []\n            # Initialize queue with children of the root (depth 1)\n            for child_idx in self._nodes[0]['children'].values():\n                queue.append(child_idx)\n\n            head = 0\n            while head  len(queue):\n                node_idx = queue[head]\n                head += 1\n\n                # Compute failure link for node_idx's children\n                for char, child_idx in self._nodes[node_idx]['children'].items():\n                    fail_idx = self._nodes[node_idx]['fail']\n                    while char not in self._nodes[fail_idx]['children'] and fail_idx != 0:\n                        fail_idx = self._nodes[fail_idx]['fail']\n                    \n                    if char in self._nodes[fail_idx]['children']:\n                        self._nodes[child_idx]['fail'] = self._nodes[fail_idx]['children'][char]\n                    else: # fail_idx is root and has no transition for char\n                        self._nodes[child_idx]['fail'] = 0\n                    \n                    queue.append(child_idx)\n\n                # --- Precompute best match for the current node_idx ---\n                \n                # Best match from patterns ending exactly at this node\n                term_best = (-1, -1)\n                if self._nodes[node_idx]['terminal']:\n                    # Find max length first\n                    max_len = 0\n                    for l, _ in self._nodes[node_idx]['terminal']:\n                        if l > max_len:\n                            max_len = l\n                    \n                    # Find min index for that max length\n                    min_idx = float('inf')\n                    for l, i in self._nodes[node_idx]['terminal']:\n                        if l == max_len and i  min_idx:\n                            min_idx = i\n                    term_best = (max_len, min_idx)\n                \n                # Best match from the failure link chain\n                fail_idx = self._nodes[node_idx]['fail']\n                fail_best = self._best_match[fail_idx]\n\n                # The best match for this state is the better of its own terminal\n                # and the one inherited from its failure state.\n                l1, i1 = term_best\n                l2, i2 = fail_best\n                if l1 > l2:\n                    self._best_match[node_idx] = term_best\n                elif l2 > l1:\n                    self._best_match[node_idx] = fail_best\n                elif l1 != -1: # l1 == l2\n                    self._best_match[node_idx] = (l1, min(i1, i2))\n                else: # Both are (-1,-1)\n                    self._best_match[node_idx] = (-1, -1)\n\n        def search(self, text):\n            \"\"\"\n            Scans the text and reports the best match at each position.\n            Args:\n                text (str): The text to scan.\n            Returns:\n                list of int: A list of the indices of the best matching patterns found.\n            \"\"\"\n            current_node_idx = 0\n            results = []\n            \n            for char in text:\n                while char not in self._nodes[current_node_idx]['children'] and current_node_idx != 0:\n                    current_node_idx = self._nodes[current_node_idx]['fail']\n                \n                if char in self._nodes[current_node_idx]['children']:\n                    current_node_idx = self._nodes[current_node_idx]['children'][char]\n                # If still no transition (i.e., we are at the root), current_node_idx remains 0.\n\n                match = self._best_match[current_node_idx]\n                if match[0] != -1:\n                    results.append(match[1])\n\n            return results\n    \n    test_cases = [\n        ({\"patterns\": [\"he\", \"she\", \"his\", \"hers\"], \"text\": \"ushers\"}),\n        ({\"patterns\": [\"a\", \"aa\", \"aaa\"], \"text\": \"aaaaa\"}),\n        ({\"patterns\": [\"aba\", \"aba\", \"ba\"], \"text\": \"caba\"}),\n        ({\"patterns\": [\"xyz\"], \"text\": \"abc\"}),\n        ({\"patterns\": [\"cat\", \"at\", \"t\"], \"text\": \"catcat\"}),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        patterns = case[\"patterns\"]\n        text = case[\"text\"]\n        \n        automaton = AhoCorasick(patterns)\n        result = automaton.search(text)\n        all_results.append(result)\n\n    # Format output as a single string: [[1,3],[0,1,2,2,2],[0],[],[0,0]]\n    # No spaces are allowed in the output.\n    results_str = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        }
    ]
}