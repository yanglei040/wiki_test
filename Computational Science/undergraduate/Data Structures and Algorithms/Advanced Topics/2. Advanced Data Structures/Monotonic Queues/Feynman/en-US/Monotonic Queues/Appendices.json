{
    "hands_on_practices": [
        {
            "introduction": "This exercise is fundamental to mastering monotonic data structures. By finding the nearest greater element to the left and right for every position, you will implement the core logic of a monotonic stack, which is the engine behind the more general monotonic queue. This pattern of maintaining a filtered set of \"candidates\" is a powerful technique for solving a wide range of problems that involve finding the \"next\" or \"previous\" element with a certain property in linear time .",
            "id": "3253891",
            "problem": "You are given a sequence of integers $A = [a_0, a_1, \\dots, a_{n-1}]$ of length $n$, using $0$-based indexing. For each position $i$ with $0 \\le i  n$, define two quantities: the nearest strictly greater element to the left and the nearest strictly greater element to the right. More precisely, the nearest strictly greater element to the left of position $i$ is the index $j$ with $0 \\le j  i$ such that $a_j  a_i$ and $i - j$ is minimized; if no such $j$ exists, the output for position $i$ on the left side is $-1$. Similarly, the nearest strictly greater element to the right of position $i$ is the index $k$ with $i  k \\le n-1$ such that $a_k  a_i$ and $k - i$ is minimized; if no such $k$ exists, the output for position $i$ on the right side is $-1$. Your task is to write a complete, runnable program that, for each array in the test suite below, computes two lists: the list of all left-side nearest strictly greater indices for all positions $i$, and the list of all right-side nearest strictly greater indices for all positions $i$.\n\nFundamental base: Use the core definition of a Double-Ended Queue (deque), which is a sequence supporting insertion and removal at both ends while maintaining order, and leverage standard invariants of a monotonic data structure that preserves either non-increasing or non-decreasing order under push and pop operations. From these definitions, derive an algorithm that runs in time $\\mathcal{O}(n)$ for each array without providing any shortcut formulas.\n\nTest suite to evaluate your program:\n- Case $1$: $$A_1 = [3,7,1,7,8,4]$$\n- Case $2$: $$A_2 = [1,2,3,4]$$\n- Case $3$: $$A_3 = [9,7,5,3,1]$$\n- Case $4$: $$A_4 = [5,5,5,5]$$\n- Case $5$: $$A_5 = [10]$$\n- Case $6$: $$A_6 = [2,1,2,1,2]$$\n\nOutput specification:\n- For each case $A_t$, output a pair of lists $[L_t, R_t]$ where $L_t$ contains the indices of the nearest strictly greater elements to the left for all positions $i$, and $R_t$ contains the indices of the nearest strictly greater elements to the right for all positions $i$. If no strictly greater element exists on a side for position $i$, use $-1$ at that position in the corresponding list.\n- Your program should produce a single line of output containing the results for the six cases as a comma-separated list enclosed in square brackets and without spaces. For example, a valid format is $[[L_1,R_1],[L_2,R_2],\\dots,[L_6,R_6]]$.\n\nAll answers are index lists of integers. There are no physical or angle units involved, and no percentages. Ensure that the algorithmic design is universally applicable and logically derived from the monotonic data structure invariants and definitions.",
            "solution": "The problem is assessed to be valid. It is a well-defined, self-contained, and objective algorithmic task grounded in the principles of computer science. It is free from scientific unsoundness, ambiguity, and contradictions.\n\nThe task is to find the nearest strictly greater element for each element in a sequence $A = [a_0, a_1, \\dots, a_{n-1}]$, both to its left and to its right. We are required to derive an algorithm with a time complexity of $\\mathcal{O}(n)$ based on the fundamental properties of a Double-Ended Queue (deque) and monotonic data structures.\n\nLet us first formalize the two subproblems:\n1.  **Nearest Greater to the Left (NGL)**: For each index $i \\in [0, n-1]$, find an index $j$ such that $j  i$, $a_j  a_i$, and the distance $i-j$ is minimized. If no such $j$ exists, the result is $-1$.\n2.  **Nearest Greater to the Right (NGR)**: For each index $i \\in [0, n-1]$, find an index $k$ such that $k  i$, $a_k  a_i$, and the distance $k-i$ is minimized. If no such $k$ exists, the result is $-1$.\n\nThese two problems are symmetric. We can derive a solution for NGL and then apply the same logic in reverse to solve NGR.\n\n### Derivation of the NGL Algorithm\n\nA naive approach for finding the NGL for each element $a_i$ would be to scan all elements to its left, from $j=i-1$ down to $0$. The first $j$ for which $a_j  a_i$ is the answer. This requires a nested loop structure, resulting in a worst-case time complexity of $\\mathcal{O}(n^2)$, for instance, when the input array is sorted in increasing order. This is inefficient and does not meet the problem's performance requirement.\n\nTo achieve an $\\mathcal{O}(n)$ solution, we must process the array in a single pass. Let us iterate through the array from left to right, from $i=0$ to $n-1$. At each step $i$, we need to efficiently find the NGL for $a_i$ among the elements $[a_0, a_1, \\dots, a_{i-1}]$.\n\nConsider the set of elements to the left of $a_i$. Not all of them are viable candidates to be the NGL for future elements. Suppose we have two indices $p$ and $q$ such that $p  q  i$. If $a_p \\le a_q$, then for any future element $a_k$ (where $k  i$), $a_p$ can never be its NGL. This is because if $a_p$ were a potential candidate (i.e., $a_p  a_k$), then $a_q$ must also be a candidate ($a_q \\ge a_p  a_k$), and since $q$ is closer to $k$ than $p$ is, $a_q$ would be chosen over $a_p$. Therefore, $a_p$ is \"obstructed\" by $a_q$ and can be discarded from our set of potential NGL candidates.\n\nThis observation leads to a crucial invariant: the set of indices corresponding to useful NGL candidates, when read from left to right, must correspond to a strictly decreasing sequence of values. Let these candidate indices be stored in a sequence $s = [j_1, j_2, \\dots, j_m]$ where $j_1  j_2  \\dots  j_m  i$. For this set to be useful, it must satisfy $a_{j_1}  a_{j_2}  \\dots  a_{j_m}$. This is the defining property of a **monotonically decreasing stack**.\n\nA deque, used as a stack, is the ideal data structure to maintain this sequence of candidate indices. When we process a new element $a_i$, we perform the following steps:\n\n1.  **Maintain the Monotonic Invariant**: We look at the index $j$ at the top of the stack. If $a_j \\le a_i$, then $a_j$ cannot be the NGL for $a_i$ (as it's not strictly greater), nor can it be the NGL for any future element, because $a_i$ is closer and at least as large. Thus, we can pop $j$ from the stack. We repeat this process until the stack is empty or the element at the top is strictly greater than $a_i$.\n\n2.  **Find the NGL**: After step 1, the stack's state is resolved.\n    *   If the stack is now empty, it means no element to the left of $a_i$ is strictly greater than it. The NGL for $a_i$ is $-1$.\n    *   If the stack is not empty, the index $j$ at the top is the first one to the left of $i$ such that $a_j  a_i$. Since we process indices in increasing order, this $j$ is guaranteed to be the nearest one. So, the NGL for $a_i$ is the index at the top of the stack.\n\n3.  **Add the Current Element**: We push the current index $i$ onto the stack. This makes $a_i$ a candidate for being the NGL for subsequent elements. The invariant is maintained because any smaller elements to its left have already been removed.\n\nEach index is pushed onto the stack exactly once and popped at most once. Therefore, the total number of stack operations is proportional to $n$, leading to an amortized time complexity of $\\mathcal{O}(n)$ for the entire pass.\n\n### Derivation of the NGR Algorithm\n\nThe NGR problem is a mirror image of the NGL problem. We can find the NGR for all elements by applying the exact same monotonic stack logic, but by iterating through the array from right to left (i.e., from $i=n-1$ down to $0$). The logic remains identical: for each $a_i$, we pop from the stack all indices corresponding to values less than or equal to $a_i$. The element remaining at the top of the stack, if any, is the NGR.\n\n### The Complete Algorithm\n\nThe final algorithm consists of two independent passes over the input array, each taking $\\mathcal{O}(n)$ time.\n\n**Pass 1: Nearest Greater to the Left (NGL)**\n1.  Initialize an empty deque/stack, `s`, to store indices.\n2.  Initialize a result array, $L$, of size $n$.\n3.  Iterate with index $i$ from $0$ to $n-1$:\n    a. While `s` is not empty and $a_{\\text{s.top()}} \\le a_i$, pop from `s`.\n    b. Set $L[i] = \\text{s.top()}$ if `s` is not empty, otherwise set $L[i] = -1$.\n    c. Push $i$ onto `s`.\n\n**Pass 2: Nearest Greater to the Right (NGR)**\n1.  Clear the deque/stack `s`.\n2.  Initialize a result array, $R$, of size $n$.\n3.  Iterate with index $i$ from $n-1$ down to $0$:\n    a. While `s` is not empty and $a_{\\text{s.top()}} \\le a_i$, pop from `s`.\n    b. Set $R[i] = \\text{s.top()}$ if `s` is not empty, otherwise set $R[i] = -1$.\n    c. Push $i$ onto `s`.\n\nThe pair of lists $[L, R]$ is the solution for the input array $A$. The total time complexity is $\\mathcal{O}(n) + \\mathcal{O}(n) = \\mathcal{O}(n)$, and the space complexity is $\\mathcal{O}(n)$ for the stack and result arrays. This design is universally applicable and derived directly from the invariant of a monotonic data structure.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the nearest strictly greater element problem for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        [3, 7, 1, 7, 8, 4],       # Case 1\n        [1, 2, 3, 4],             # Case 2\n        [9, 7, 5, 3, 1],          # Case 3\n        [5, 5, 5, 5],             # Case 4\n        [10],                     # Case 5\n        [2, 1, 2, 1, 2],          # Case 6\n    ]\n\n    def compute_nearest_greater_elements(arr):\n        \"\"\"\n        Computes the nearest strictly greater element to the left (NGL) and right (NGR)\n        for each element in the input array using a monotonic stack.\n\n        The algorithm performs two passes, one left-to-right for NGL and one\n        right-to-left for NGR. Each pass has an O(n) time complexity.\n\n        Args:\n            arr (list): The input list of integers.\n\n        Returns:\n            list: A pair of lists, [left_results, right_results], where\n                  left_results contains NGL indices and right_results contains\n                  NGR indices.\n        \"\"\"\n        n = len(arr)\n        if n == 0:\n            return [[], []]\n\n        # Initialize result arrays with -1\n        left_greater = np.full(n, -1, dtype=int)\n        right_greater = np.full(n, -1, dtype=int)\n\n        # Using a standard list as a stack to store indices\n        stack = []\n\n        # Pass 1: Left-to-Right for Nearest Greater to the Left (NGL)\n        for i in range(n):\n            # While stack is not empty and the element at the index on top of the stack\n            # is less than or equal to the current element, pop from the stack.\n            # This maintains the monotonic (strictly decreasing) property of the\n            # values corresponding to the indices in the stack.\n            while stack and arr[stack[-1]] = arr[i]:\n                stack.pop()\n            \n            # If the stack is not empty after popping, the index at the top is the NGL.\n            if stack:\n                left_greater[i] = stack[-1]\n            \n            # Push the current index onto the stack for future comparisons.\n            stack.append(i)\n\n        # Clear the stack for the second pass\n        stack.clear()\n\n        # Pass 2: Right-to-Left for Nearest Greater to the Right (NGR)\n        # The logic is symmetric to the first pass.\n        for i in range(n - 1, -1, -1):\n            while stack and arr[stack[-1]] = arr[i]:\n                stack.pop()\n            \n            if stack:\n                right_greater[i] = stack[-1]\n            \n            stack.append(i)\n            \n        return [left_greater.tolist(), right_greater.tolist()]\n\n    all_results_str = []\n    for case_array in test_cases:\n        # Compute the result pair [L, R]\n        result_pair = compute_nearest_greater_elements(case_array)\n        \n        # Manually format the output strings to avoid spaces, as per the specification.\n        # Format the list of left indices, e.g., \"[-1,-1,1,-1,-1,4]\"\n        left_str = f\"[{','.join(map(str, result_pair[0]))}]\"\n        # Format the list of right indices, e.g., \"[1,4,3,4,-1,-1]\"\n        right_str = f\"[{','.join(map(str, result_pair[1]))}]\"\n        \n        # Combine into the final string for one case, e.g., \"[[-1,-1,1,-1,-1,4],[1,4,3,4,-1,-1]]\"\n        pair_str = f\"[{left_str},{right_str}]\"\n        all_results_str.append(pair_str)\n\n    # Join all case results into a single line, e.g., \"[[...],[...],...]\"\n    final_output = f\"[{','.join(all_results_str)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Building on the monotonic stack, this problem applies the concept to a classic sliding window scenario. You are tasked with finding the closest \"power-up\" within a fixed-length window as it moves across a hypothetical game world. This practice introduces the \"queue\" aspect of the structure, where elements are not only added and removed based on their value but also expire as they slide out of the window, efficiently tracking optimal candidates in a moving frame of reference .",
            "id": "3253942",
            "problem": "You are given a one-dimensional discrete world modeled as an array of binary indicators. Each position $j$ in the world is represented by an entry $B[j] \\in \\{0,1\\}$, where $B[j] = 1$ denotes the presence of a \"power-up\" item at position $j$ and $B[j] = 0$ denotes no item. A player advances forward from position $i = 0$ to position $i = n-1$, where $n$ is the length of the array. At each position $i$, the player considers a forward-scrolling window of fixed length $L$, defined as the interval of indices $[i, \\min(n-1, i + L - 1)]$. Within this window, define the forward distance to the closest power-up item at position $j$ as $d(i) = \\min\\{ j - i \\mid B[j] = 1, i \\le j \\le \\min(n-1, i + L - 1) \\}$, and if no such $j$ exists, define $d(i) = -1$.\n\nStarting from fundamental definitions:\n- A sliding window over an array selects contiguous subarrays of fixed length, advancing the window by one position each step.\n- A double-ended queue (deque) supports insertion and deletion from both ends in constant amortized time.\n- A monotonic queue is a specialized use of a double-ended queue that maintains elements in sorted order (nonincreasing or nondecreasing) according to a comparison key, supporting efficient retrieval of minimum or maximum over sliding windows.\n\nTask: Write a complete, runnable program that, for each test case below, computes the list of distances $[d(0), d(1), \\dots, d(n-1)]$ according to the definition above. The program must implement an algorithm derived from these fundamental definitions, with worst-case time complexity $\\mathcal{O}(n)$ per test case, suitable for large $n$. No physical units, angle units, or percentage formats are applicable; all outputs are integers. The final output must aggregate the results of all test cases into a single line.\n\nTest Suite:\nUse the following test cases to validate different facets of your algorithm, including typical behavior, boundary conditions, and edge cases. In each case, $B$ is the binary array and $L$ is the window length.\n- Case $1$: $B = [0, 1, 0, 0, 1, 0, 0, 1, 0, 0]$, $L = 3$.\n- Case $2$: $B = [0, 1, 1, 0, 1]$, $L = 1$.\n- Case $3$: $B = [0, 0, 0, 0, 0]$, $L = 4$.\n- Case $4$: $B = [1, 1, 1, 1, 1, 1]$, $L = 5$.\n- Case $5$: $B = [0, 1, 0, 0, 0, 1, 0]$, $L = 100$.\n\nRequired Final Output Format:\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each test caseâ€™s result is itself a list of integers. For example, the structure must be like $[\\,\\text{case\\_1\\_result}, \\text{case\\_2\\_result}, \\dots\\,]$ with no spaces inside inner lists. Concretely, the output for the above test suite must have the exact format\n$[ [d_0^{(1)}, d_1^{(1)}, \\dots], [d_0^{(2)}, d_1^{(2)}, \\dots], [d_0^{(3)}, \\dots], [d_0^{(4)}, \\dots], [d_0^{(5)}, \\dots] ]$,\nprinted as a single line, where $d_i^{(k)}$ denotes the distance at index $i$ for test case $k$.",
            "solution": "The problem requires the computation of a distance vector $\\mathbf{d}$ for a one-dimensional discrete world represented by a binary array $B$ of length $n$. For each position $i \\in \\{0, 1, \\dots, n-1\\}$, we must find the distance $d(i)$ to the nearest \"power-up\" (an entry $B[j]=1$) within a forward-looking window of length $L$.\n\nFormally, for each $i \\in \\{0, 1, \\dots, n-1\\}$, the value $d(i)$ is defined as:\n$$\nd(i) = \\begin{cases}\n\\min\\{ j - i \\mid B[j] = 1 \\text{ and } i \\le j \\le \\min(n-1, i + L - 1) \\}  \\text{if such a } j \\text{ exists} \\\\\n-1  \\text{otherwise}\n\\end{cases}\n$$\nThe problem specifies that the algorithm must be be derived from fundamental principles of data structures, including the monotonic queue, and must achieve a worst-case time complexity of $\\mathcal{O}(n)$.\n\nA naive approach would be to iterate through each position $i$ from $0$ to $n-1$, and for each $i$, conduct a linear scan of the window $[i, \\min(n-1, i + L - 1)]$ to find the first occurrence of a $1$. This leads to a time complexity of $\\mathcal{O}(n \\cdot L)$, which is inefficient and fails to meet the problem's performance requirement for large $L$.\n\nTo achieve an $\\mathcal{O}(n)$ complexity, we must avoid redundant computations. The core challenge is a sliding window query, which is the canonical application domain for a monotonic queue. However, the standard monotonic queue algorithm finds the minimum or maximum *value* in a window. Here, we seek the minimum *index* $j$ where the value is $1$. This is a specialized variant of the sliding window problem.\n\nOur strategy is derived from the principle of maintaining a queue of candidate solutions that is pruned as the window slides. Since we are only interested in positions $j$ where $B[j]=1$, we can pre-process the array $B$ to identify all such \"power-up indices.\" Let this ordered set of indices be $P = \\{j_0, j_1, \\dots, j_m\\}$, where $B[j_k]=1$ for all $k$ and $j_0  j_1  \\dots  j_m$. This step takes $\\mathcal{O}(n)$ time.\n\nThese indices are our only candidates for the minimum $j$ for any given $i$. We can store these candidate indices in a double-ended queue (deque), which we will denote as $q$. The indices in $q$ are inherently sorted (monotonic), as they are added in the order they appear in $B$.\n\nThe main algorithm then proceeds by iterating through $i$ from $0$ to $n-1$ to compute each $d(i)$. For each $i$, we are searching for the smallest candidate index $j \\in P$ such that $j \\ge i$. As $i$ increments, any candidate index $j_k$ in our queue $q$ that is less than the new $i$ can never be the solution for the current or any future position, because the window always starts at or after $i$. Therefore, we can permanently discard such indices from the front of the queue.\n\nThis leads to the following $\\mathcal{O}(n)$ algorithm:\n1.  Initialize a deque, $q$, with all indices $j$ for which $B[j]=1$. This can be done in a single pass over $B$. In a `numpy` environment, this is efficiently achieved with `np.where(B == 1)`.\n2.  Initialize an empty list, `results`, to store the computed distances $d(i)$.\n3.  Iterate with index $i$ from $0$ to $n-1$:\n    a.  Remove indices from the front of $q$ while $q$ is not empty and its front element $q[0]$ is less than $i$. This maintains the invariant that $q[0]$ is the smallest available candidate index that is greater than or equal to the current position $i$.\n    b.  After the pruning step, inspect the front of the queue. There are two possibilities:\n        i.  The queue $q$ is not empty, and its front element, let's call it $j_{\\text{cand}} = q[0]$, is the first power-up at or after position $i$. We must check if this candidate falls within the window of length $L$. The window extends to index $i+L-1$, so the condition is $j_{\\text{cand}}  i+L$. If this holds, we have found the closest power-up in the window, and the distance is $d(i) = j_{\\text{cand}} - i$.\n        ii. If the queue is empty, or if $j_{\\text{cand}} \\ge i+L$, then there is no power-up within the window $[i, \\min(n-1, i+L-1)]$. In this case, $d(i)=-1$.\n    c.  Append the computed $d(i)$ to the `results` list.\n4.  After the loop completes, the `results` list contains the required sequence $[d(0), d(1), \\dots, d(n-1)]$.\n\n**Complexity Analysis**:\n-   **Time Complexity**: The initial population of the deque $q$ takes $\\mathcal{O}(n)$ time. The main loop runs $n$ times. Each index from the original `powerup_indices` list is enqueued once and dequeued at most once during the entire execution of the main loop. Thus, the total work done by the `while` loop for pruning is amortized to $\\mathcal{O}(n)$ over all iterations. All other operations inside the loop take constant time. The total time complexity is therefore $\\mathcal{O}(n) + \\mathcal{O}(n) = \\mathcal{O}(n)$.\n-   **Space Complexity**: The deque $q$ stores the indices of all power-ups. In the worst-case scenario where every element of $B$ is $1$, the space required for the deque is $\\mathcal{O}(n)$. Therefore, the space complexity is $\\mathcal{O}(n)$.\n\nThis algorithm correctly solves the problem using principles derived from monotonic queues and meets the specified complexity constraints.",
            "answer": "```python\nimport numpy as np\nimport collections\n\ndef solve():\n    \"\"\"\n    Solves the forward distance to closest power-up problem for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case 1\n        (np.array([0, 1, 0, 0, 1, 0, 0, 1, 0, 0], dtype=np.int8), 3),\n        # Case 2\n        (np.array([0, 1, 1, 0, 1], dtype=np.int8), 1),\n        # Case 3\n        (np.array([0, 0, 0, 0, 0], dtype=np.int8), 4),\n        # Case 4\n        (np.array([1, 1, 1, 1, 1, 1], dtype=np.int8), 5),\n        # Case 5\n        (np.array([0, 1, 0, 0, 0, 1, 0], dtype=np.int8), 100),\n    ]\n\n    all_results = []\n\n    for B, L in test_cases:\n        n = len(B)\n        \n        # 1. Find all power-up indices and store them in a deque.\n        # This deque is monotonically increasing by construction.\n        powerup_indices = np.where(B == 1)[0]\n        q = collections.deque(powerup_indices)\n        \n        distances = []\n        \n        # 2. Iterate through each position i to calculate d(i).\n        for i in range(n):\n            # 3a. Prune indices from the front of the deque that are no longer\n            # reachable from position i (i.e., indices  i).\n            while q and q[0]  i:\n                q.popleft()\n            \n            # 3b. Check the next available power-up.\n            if q:\n                candidate_j = q[0]\n                # Check if the candidate is within the window [i, i + L - 1].\n                if candidate_j  i + L:\n                    # The distance is the difference in indices.\n                    distances.append(candidate_j - i)\n                else:\n                    # The closest power-up is outside the window.\n                    distances.append(-1)\n            else:\n                # No more power-ups to consider.\n                distances.append(-1)\n        \n        all_results.append(distances)\n\n    # Format the final output string according to the specification.\n    # Inner lists should have no spaces, e.g., [d0,d1,d2].\n    # Outer list combines these, e.g., [[...],[...]].\n    formatted_inner_results = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_output = f\"[{','.join(formatted_inner_results)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "This advanced problem demonstrates how to leverage the monotonic stack for more than just finding extrema; you'll use it to solve a complex aggregation problem by calculating the sum of maximums over all contiguous subarrays. The key insight is the \"contribution method,\" where the total sum is found by summing the contributions of each individual element. This exercise  illustrates how finding the nearest greater elements, a skill developed in our first practice , defines an element's \"domain of influence,\" enabling a powerful and efficient counting strategy.",
            "id": "3253905",
            "problem": "You are given an integer array $A$ of length $n$, which may contain negative values. For every contiguous subarray $B$ of $A$, let $\\max(B)$ denote the maximum element of $B$. Your task is to compute the sum of $\\max(B)$ over all non-empty contiguous subarrays $B$ of $A$. If $A$ is empty, the sum is defined to be $0$.\n\nFundamental base for reasoning and derivation:\n- Definition of a contiguous subarray: a sequence $A[\\ell], A[\\ell+1], \\dots, A[r]$ for integers $\\ell$ and $r$ satisfying $0 \\le \\ell \\le r  n$.\n- Definition of maximum: for any finite set of integers $S$, the value $\\max(S)$ is the unique element $m \\in S$ such that $m \\ge s$ for all $s \\in S$.\n- Well-tested facts about double-ended queues: a double-ended queue (also called a deque) supports insertion and deletion at both ends. A monotonic deque maintains an order invariant (non-increasing or non-decreasing) of the values associated with its stored indices, and under standard push-pop rules, each index is inserted and removed at most once, yielding amortized $\\mathcal{O}(1)$ time per operation and total $\\mathcal{O}(n)$ time over $n$ operations.\n- Counting principle: if disjoint groups partition a finite set, then the total size of the set equals the sum of the sizes of the groups.\n\nYour program must implement an algorithm grounded in these base definitions and facts, not relying on any provided shortcut formulas, to derive an $\\mathcal{O}(n)$ method using a monotonic deque to aggregate the contributions of each element of $A$ to the overall sum.\n\nInput and output are fixed by the test suite below. No physical units or angles are involved.\n\nTest suite:\nEvaluate the described sum for each of the following arrays $A$:\n- Test $1$: $[3,1,2,4]$\n- Test $2$: $[2,2,2]$\n- Test $3$: $[5,4,3,2,1]$\n- Test $4$: $[-1,0,-3,2]$\n- Test $5$: $[]$\n- Test $6$: $[7]$\n\nFinal output format:\nYour program should produce a single line of output containing the results for Tests $1$ through $6$ in order, as a comma-separated list enclosed in square brackets, with no spaces. For example, an output with three results should look like \"[r1,r2,r3]\".",
            "solution": "The objective is to calculate the sum of the maximum elements over all non-empty contiguous subarrays of a given integer array $A$. Let this sum be denoted by $S$. The problem is formally stated as:\n$$ S = \\sum_{\\ell=0}^{n-1} \\sum_{r=\\ell}^{n-1} \\max(A[\\ell \\dots r]) $$\nwhere $A[\\ell \\dots r]$ represents the contiguous subarray from index $\\ell$ to $r$, and $n$ is the length of $A$.\n\nA direct computation based on this formula would involve iterating through all $\\mathcal{O}(n^2)$ contiguous subarrays, finding the maximum of each (which can take up to $\\mathcal{O}(n)$ time), leading to an overall time complexity of $\\mathcal{O}(n^3)$, or $\\mathcal{O}(n^2)$ with optimization. This is inefficient for large $n$. The requirement for an $\\mathcal{O}(n)$ solution suggests a different approach.\n\nWe can reframe the problem by applying the counting principle. Instead of summing over subarrays, we can sum over the elements of $A$, calculating the contribution of each element to the total sum. The contribution of an element $A[i]$ is $A[i]$ multiplied by the number of contiguous subarrays for which $A[i]$ is the maximum element.\n$$ S = \\sum_{i=0}^{n-1} A[i] \\cdot (\\text{count of subarrays where } A[i] \\text{ is the maximum}) $$\n\nA crucial aspect is to handle cases where multiple elements in a subarray share the same maximum value. To ensure that each subarray's maximum is counted exactly once, we need a consistent tie-breaking rule. A standard convention is to designate the *first* occurrence of the maximum value within a subarray as its \"official\" maximum.\nTherefore, for an element $A[i]$ to be the designated maximum of a subarray $A[\\ell \\dots r]$ (where $\\ell \\le i \\le r$), two conditions must be met:\n1.  For all other elements $A[k]$ in the subarray (i.e., $k \\in [\\ell, r]$), $A[k] \\le A[i]$.\n2.  For all elements $A[k]$ to the left of $A[i]$ within the subarray (i.e., $k \\in [\\ell, i-1]$), the inequality must be strict: $A[k]  A[i]$.\n\nTo count the number of such subarrays for a fixed index $i$, we need to find the valid range for the start index $\\ell$ and the end index $r$.\nThe condition $A[k]  A[i]$ for all $k \\in [\\ell, i-1]$ implies that the subarray cannot extend to the left to include any element $A[j]$ with $j  i$ and $A[j] \\ge A[i]$. Let $p_i$ be the index of the nearest element to the left of $i$ such that $A[p_i] \\ge A[i]$. This is the \"Previous Greater or Equal\" element. If no such element exists, we define $p_i = -1$. The start index $\\ell$ must be greater than $p_i$, so $\\ell \\in [p_i+1, i]$. The number of choices for $\\ell$ is $i - (p_i+1) + 1 = i - p_i$.\n\nThe condition $A[k] \\le A[i]$ for all $k \\in [i+1, r]$ implies that the subarray cannot extend to the right to include any element $A[j]$ with $j  i$ and $A[j]  A[i]$. Let $q_i$ be the index of the nearest element to the right of $i$ such that $A[q_i]  A[i]$. This is the \"Next Strictly Greater\" element. If no such element exists, we define $q_i = n$. The end index $r$ must be less than $q_i$, so $r \\in [i, q_i-1]$. The number of choices for $r$ is $(q_i-1) - i + 1 = q_i - i$.\n\nThe total number of subarrays for which $A[i]$ is the designated maximum is the product of the number of choices for $\\ell$ and $r$, which is $(i - p_i) \\cdot (q_i - i)$. The contribution of $A[i]$ to the total sum is $A[i] \\cdot (i - p_i) \\cdot (q_i - i)$. The total sum is:\n$$ S = \\sum_{i=0}^{n-1} A[i] \\cdot (i - p_i) \\cdot (q_i - i) $$\n\nThe remaining task is to compute the arrays of indices $p$ (PGE) and $q$ (NSG) in linear time. This is a classic application of a monotonic deque (or stack).\n\n**1. Computing Previous Greater or Equal (PGE) indices ($p_i$):**\nWe iterate from $i=0$ to $n-1$ and use a stack that stores indices of elements in monotonically decreasing order of their values.\nLet `stack` be a deque used as a stack. For each index $i$:\n- While `stack` is not empty and $A[\\text{stack.top()}]  A[i]$, pop from the stack. The popped elements are smaller than $A[i]$ and to its left, so they cannot be the PGE for $A[i]$ or any subsequent element.\n- After the loop, if the `stack` is empty, no element to the left is greater than or equal to $A[i]$, so $p_i = -1$.\n- Otherwise, `stack.top()` holds the index of the nearest element to the left that is greater than or equal to $A[i]$, so $p_i = \\text{stack.top()}$.\n- Push $i$ onto the `stack`. This maintains the monotonic property.\n\n**2. Computing Next Strictly Greater (NSG) indices ($q_i$):**\nA similar monotonic stack approach can be used. An elegant method is to recognize that the NSG for an array $A$ is related to the Previous Strictly Greater (PSG) for the reversed array $A^R$.\nLet $A^R$ be the reversed array, where $A^R[j] = A[n-1-j]$. We compute the PSG for every element of $A^R$.\nThe PSG algorithm is analogous to the PGE one:\n- Let `stack` be a deque. For each index $j=0, \\dots, n-1$ of $A^R$:\n- While `stack` is not empty and $A^R[\\text{stack.top()}] \\le A^R[j]$, pop from the stack.\n- The PSG index for $A^R[j]$ is `stack.top()` if the stack is not empty, or $-1$ otherwise.\n- Push $j$ onto `stack`.\n\nLet `psg_R` be the array of PSG indices for $A^R$. The NSG index $q_i$ for an element $A[i]$ can be found by mapping indices. The element $A[i]$ corresponds to $A^R[n-1-i]$. Its PSG is at some index $j' = \\text{psg\\_R}[n-1-i]$ in $A^R$. The corresponding index in the original array $A$ is $n-1-j'$. If no PSG exists (i.e., $j' = -1$), then no NSG exists for $A[i]$, so $q_i = n$. Thus, $q_i = n-1-\\text{psg\\_R}[n-1-i]$ if $\\text{psg\\_R}[n-1-i] \\ne -1$, and $q_i = n$ otherwise.\n\nBoth passes take $\\mathcal{O}(n)$ time as each index is pushed and popped at most once. The final summation is also $\\mathcal{O}(n)$. The total time complexity is $\\mathcal{O}(n)$, and space complexity is $\\mathcal{O}(n)$ for the helper arrays and the stack.\n\nFor an empty array $A$, $n=0$, the sum is defined to be $0$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the sum of maximums over all contiguous subarrays for multiple test cases.\n    \"\"\"\n\n    def calculate_sum_of_subarray_maxes(A: list[int]) -> int:\n        \"\"\"\n        Computes the sum of max(B) for all contiguous subarrays B of A in O(n) time.\n        \"\"\"\n        n = len(A)\n        if n == 0:\n            return 0\n\n        # 1. Compute `left`: Previous Greater or Equal (PGE)\n        # `left[i]` stores the index of the nearest element to the left of `i`\n        # which is greater than or equal to A[i].\n        left = np.full(n, -1, dtype=np.int64)\n        stack = []  # A list used as a stack, stores indices\n        for i in range(n):\n            while stack and A[stack[-1]]  A[i]:\n                stack.pop()\n            if stack:\n                left[i] = stack[-1]\n            stack.append(i)\n        \n        # 2. Compute `right`: Next Strictly Greater (NSG)\n        # This is equivalent to finding Previous Strictly Greater (PSG) on the reversed array.\n        # `right[i]` stores the index of the nearest element to the right of `i`\n        # which is strictly greater than A[i].\n        right = np.full(n, n, dtype=np.int64)\n        stack = []\n        for i in range(n - 1, -1, -1):\n            while stack and A[stack[-1]] = A[i]:\n                stack.pop()\n            if stack:\n                right[i] = stack[-1]\n            stack.append(i)\n            \n        # 3. Calculate the total sum based on contributions\n        # The contribution of A[i] is A[i] * (number of subarrays where A[i] is the first max).\n        # Number of such subarrays is (i - left[i]) * (right[i] - i).\n        total_sum = 0\n        for i in range(n):\n            count = (i - left[i]) * (right[i] - i)\n            total_sum += A[i] * count\n            \n        return total_sum\n\n    test_cases = [\n        [3, 1, 2, 4],      # Test 1\n        [2, 2, 2],         # Test 2\n        [5, 4, 3, 2, 1],   # Test 3\n        [-1, 0, -3, 2],    # Test 4\n        [],                # Test 5\n        [7]                # Test 6\n    ]\n\n    results = []\n    for A in test_cases:\n        result = calculate_sum_of_subarray_maxes(A)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}