{
    "hands_on_practices": [
        {
            "introduction": "The first step in mastering any algorithm is translating its abstract mathematical form into functional code. This exercise guides you through a direct implementation of the Karatsuba algorithm's recursive logic . By applying the core formula $$xy = z_2 B^{2m} + (z_1 - z_2 - z_0) B^m + z_0$$, you will build a concrete understanding of how the divide-and-conquer strategy works in practice and appreciate the algebraic insight that reduces the number of required multiplications.",
            "id": "3213594",
            "problem": "You are asked to design and implement a recursive integer multiplication procedure that explicitly demonstrates both the base cases and the recursive step of a divide-and-conquer algorithm. The method must operate on nonnegative integers represented in an arbitrary positional base and must reduce the number of recursive multiplications below the naive approach by using algebraic recombination.\n\nFundamental base. Use only these foundational facts as the starting point:\n- Any nonnegative integer $n$ can be represented in base $B$ (with $B \\in \\mathbb{Z}$, $B \\ge 2$) as $n = \\sum_{i=0}^{k-1} d_i B^i$ where each digit $d_i$ is an integer with $0 \\le d_i \\le B-1$.\n- For two integers $x$ and $y$ and any base $B$, if $m \\in \\mathbb{Z}$ with $m \\ge 1$, then the numbers can be split as $x = x_1 B^m + x_0$ and $y = y_1 B^m + y_0$ with $0 \\le x_0  B^m$ and $0 \\le y_0  B^m$.\n- Algebraic identities on integers hold under the usual ring operations.\n\nDefine the recursive algorithm `Multiply(x,y,B,t)` with the following requirements:\n1. Inputs: integers $x \\ge 0$, $y \\ge 0$, base $B \\ge 2$, and a cutoff threshold $t \\ge 1$ representing a number of base-$B$ digits.\n2. Base case: if $\\min(\\text{digits}_B(x), \\text{digits}_B(y)) \\le t$ or if $x = 0$ or $y = 0$, return the exact product $xy$ using a direct method. Here, $\\text{digits}_B(n)$ denotes the number of base-$B$ digits of $n$ (by definition, $\\text{digits}_B(0) = 1$).\n3. Recursive step: otherwise, choose $m = \\lceil \\max(\\text{digits}_B(x), \\text{digits}_B(y)) / 2 \\rceil$, split $x = x_1 B^m + x_0$ and $y = y_1 B^m + y_0$ with $0 \\le x_0, y_0  B^m$, and compute the result using exactly three recursive multiplications on combinations of $(x_0,x_1)$ and $(y_0,y_1)$ together with a constant number of additions, subtractions, and multiplications by powers of $B$. The recombination must produce the exact product $xy$.\n\nYour task:\n- Implement `Multiply(x,y,B,t)` recursively, obeying the base-case and recursive-step constraints above.\n- Use this routine to compute the products for the following test suite of parameter values:\n  - Case A: $x = 123456789012345, y = 987654321098765, B = 10, t = 3$.\n  - Case B: $x = 99, y = 99, B = 10, t = 2$.\n  - Case C: $x = 0, y = 987654321, B = 10, t = 3$.\n  - Case D: $x = 123456, y = 789012, B = 2, t = 16$.\n  - Case E: $x = 10^{20} + 12345, y = 10^{10} + 678, B = 10, t = 3$.\n- The answers are unitless exact integers. No physical units are involved.\n\nFinal output format:\n- Your program must produce a single line of output containing the results for Cases A through E, in order, as a comma-separated list enclosed in square brackets. For example, the format must be [$r_A,r_B,r_C,r_D,r_E$], where each $r_\\cdot$ is the integer product for the corresponding case, written in base $10$ without any additional whitespace or text.",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded, well-posed, objective, and contains all necessary information to derive a unique, verifiable solution. The problem describes the Karatsuba algorithm for fast multiplication, a standard topic in computer science algorithms.\n\nThe task is to design and implement a recursive integer multiplication algorithm, designated as `Multiply(x, y, B, t)`, which reduces the number of recursive calls compared to a naive approach. This is a classic application of the divide-and-conquer paradigm. The core principle lies in an algebraic manipulation that allows the product of two large integers to be computed using three multiplications of smaller integers, rather than the four required by direct expansion.\n\nLet the two non-negative integers to be multiplied be $x$ and $y$. Their product is $x \\cdot y$.\nThe integers are represented in a positional base $B \\ge 2$. Following the problem, we can split them into higher-order and lower-order parts. Let $n_x = \\text{digits}_B(x)$ and $n_y = \\text{digits}_B(y)$ be the number of base-$B$ digits of $x$ and $y$ respectively. Let $n = \\max(n_x, n_y)$. We choose a splitting point $m = \\lceil n / 2 \\rceil$.\n\nUsing this $m$, we can write $x$ and $y$ as:\n$$x = x_1 B^m + x_0$$\n$$y = y_1 B^m + y_0$$\nwhere $x_1 = \\lfloor x / B^m \\rfloor$, $x_0 = x \\pmod{B^m}$, and similarly for $y_1$ and $y_0$. By construction, $x_0$ and $y_0$ are integers with at most $m$ digits in base $B$.\n\nThe product $x \\cdot y$ can be expanded as:\n$$x \\cdot y = (x_1 B^m + x_0) (y_1 B^m + y_0)$$\n$$x \\cdot y = x_1 y_1 B^{2m} + x_1 y_0 B^m + x_0 y_1 B^m + x_0 y_0$$\n$$x \\cdot y = (x_1 y_1) B^{2m} + (x_1 y_0 + x_0 y_1) B^m + (x_0 y_0)$$\n\nA naive recursive implementation would compute the four products $x_1 y_1$, $x_1 y_0$, $x_0 y_1$, and $x_0 y_0$ recursively. The problem requires a method using only three recursive multiplications. This is achieved by the algebraic identity discovered by Anatoly Karatsuba.\n\nLet us define three intermediate products:\n$z_2 = x_1 y_1$\n$z_0 = x_0 y_0$\n$z_1 = (x_1 + x_0)(y_1 + y_0)$\n\nThe key insight is to express the middle term, $(x_1 y_0 + x_0 y_1)$, using these three products. Expanding $z_1$:\n$z_1 = x_1 y_1 + x_1 y_0 + x_0 y_1 + x_0 y_0$\n$z_1 = z_2 + (x_1 y_0 + x_0 y_1) + z_0$\n\nFrom this, we can isolate the middle term:\n$x_1 y_0 + x_0 y_1 = z_1 - z_2 - z_0$\n\nSubstituting this back into the expression for $x \\cdot y$:\n$$x \\cdot y = z_2 B^{2m} + (z_1 - z_2 - z_0) B^m + z_0$$\n\nThis final expression for the product requires only three multiplications to find $z_0$, $z_1$, and $z_2$, along with several additions, subtractions, and multiplications by powers of the base $B$ (which are computationally inexpensive shifts). These three products are computed via recursive calls to the multiplication algorithm itself.\n\nThe implementation of `Multiply(x, y, B, t)` will follow this structure:\n\n1.  **Helper Function `digits_B(n, B)`**: A function is required to compute the number of digits of an integer $n$ in base $B$. As specified, $\\text{digits}_B(0) = 1$. For $n > 0$, this can be computed robustly using integer division in a loop to avoid potential floating-point precision issues with large numbers, where $\\text{digits}_B(n) = \\lfloor \\log_B n \\rfloor + 1$.\n\n2.  **Base Case**: The recursion must terminate. The problem specifies two conditions for the base case:\n    -   If $x=0$ or $y=0$, the product is $0$.\n    -   If the number of digits of either operand is small enough, i.e., $\\min(\\text{digits}_B(x), \\text{digits}_B(y)) \\le t$, we stop recursing and compute the product $x \\cdot y$ directly. This avoids excessive recursion on small numbers where the overhead of the recursive calls outweighs the benefits.\n\n3.  **Recursive Step**: If the base case is not met:\n    -   Calculate $n = \\max(\\text{digits}_B(x), \\text{digits}_B(y))$.\n    -   Calculate the split point $m = \\lceil n / 2 \\rceil$. In integer arithmetic, this is `(n + 1) // 2`.\n    -   Compute $B_m = B^m$.\n    -   Split $x$ into $x_1 = x // B_m$ and $x_0 = x \\% B_m$.\n    -   Split $y$ into $y_1 = y // B_m$ and $y_0 = y \\% B_m$.\n    -   Make three recursive calls:\n        -   $z_2 = \\text{Multiply}(x_1, y_1, B, t)$\n        -   $z_0 = \\text{Multiply}(x_0, y_0, B, t)$\n        -   $z_1 = \\text{Multiply}(x_1 + x_0, y_1 + y_0, B, t)$\n    -   Recombine the results using the derived formula:\n        $xy = z_2 \\cdot B^{2m} + (z_1 - z_2 - z_0) \\cdot B^m + z_0$. The term $B^{2m}$ can be efficiently computed as $B_m \\cdot B_m$.\n\nThis design fulfills all requirements of the problem statement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef digits_B(n, B):\n    \"\"\"\n    Calculates the number of digits of a non-negative integer n in a given base B.\n    As per the problem, digits_B(0) is defined as 1.\n    For n  0, this is equivalent to floor(log_B(n)) + 1.\n    This implementation uses integer arithmetic to avoid floating point precision issues.\n    \"\"\"\n    if n == 0:\n        return 1\n    \n    count = 0\n    temp_n = n\n    while temp_n  0:\n        temp_n //= B\n        count += 1\n    return count\n\ndef Multiply(x, y, B, t):\n    \"\"\"\n    Recursively computes the product of two non-negative integers x and y using\n    the Karatsuba algorithm, as specified in the problem statement.\n\n    Args:\n        x (int): A non-negative integer.\n        y (int): A non-negative integer.\n        B (int): The base for number representation (B = 2).\n        t (int): The digit count threshold for the base case (t = 1).\n\n    Returns:\n        int: The exact product x * y.\n    \"\"\"\n    # Base case: if one of the numbers is zero.\n    if x == 0 or y == 0:\n        return 0\n\n    # Determine the number of digits for x and y in base B.\n    num_digits_x = digits_B(x, B)\n    num_digits_y = digits_B(y, B)\n    \n    # Base case: if the number of digits in the smaller number is below the threshold.\n    if min(num_digits_x, num_digits_y) = t:\n        return x * y\n\n    # Recursive step:\n    # 1. Determine the split point m.\n    n_digits = max(num_digits_x, num_digits_y)\n    m = (n_digits + 1) // 2  # This is equivalent to ceil(n_digits / 2)\n\n    # 2. Split the numbers x and y into higher and lower parts.\n    Bm = B**m\n    x1 = x // Bm\n    x0 = x % Bm\n    y1 = y // Bm\n    y0 = y % Bm\n\n    # 3. Make three recursive calls as per the Karatsuba algorithm.\n    z2 = Multiply(x1, y1, B, t)\n    z0 = Multiply(x0, y0, B, t)\n    z1 = Multiply(x1 + x0, y1 + y0, B, t)\n\n    # 4. Recombine the results to get the final product.\n    # The formula is: z2 * B^(2m) + (z1 - z2 - z0) * B^m + z0\n    # To avoid re-calculating powers of B, we can reuse Bm.\n    B2m = Bm * Bm\n    result = z2 * B2m + (z1 - z2 - z0) * Bm + z0\n    \n    return result\n\ndef solve():\n    \"\"\"\n    Solves the problem by running the specified test cases through the\n    recursive multiplication algorithm and printing the results in the\n    required format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: x = 123456789012345, y = 987654321098765, B = 10, t = 3\n        (123456789012345, 987654321098765, 10, 3),\n        # Case B: x = 99, y = 99, B = 10, t = 2\n        (99, 99, 10, 2),\n        # Case C: x = 0, y = 987654321, B = 10, t = 3\n        (0, 987654321, 10, 3),\n        # Case D: x = 123456, y = 789012, B = 2, t = 16\n        (123456, 789012, 2, 16),\n        # Case E: x = 10**20 + 12345, y = 10**10 + 678, B = 10, t = 3\n        (10**20 + 12345, 10**10 + 678, 10, 3)\n    ]\n\n    results = []\n    for case in test_cases:\n        x, y, B, t = case\n        result = Multiply(x, y, B, t)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Theoretical analysis tells us that Karatsuba's algorithm scales with a time complexity of $O(n^{\\log_2 3})$, making it asymptotically faster than the $O(n^2)$ grade-school method. This exercise challenges you to verify this claim experimentally . You will model the operational cost of the algorithm and use log-log data analysis to empirically estimate the scaling exponent, providing a powerful bridge between abstract complexity theory and observable performance.",
            "id": "3243158",
            "problem": "You are tasked with designing and executing a self-contained computational experiment that empirically recovers the exponent in the asymptotic time complexity of the Karatsuba multiplication algorithm using only first principles from divide-and-conquer analysis and elementary statistical fitting. The experiment must be implemented as a complete, runnable program that performs no input or output beyond printing a single aggregated line described below.\n\nBegin from the following base elements:\n- The asymptotic time of an algorithm on inputs of “size” $n$ is modeled as a function $t(n)$ counting a fixed proxy for the work performed. In a unit-cost Random Access Machine (RAM) model, one may proxy “runtime” by counting elementary operations such as single-digit multiplications. The Karatsuba algorithm reduces a multiplication of two $n$-digit numbers into a fixed number of multiplications on roughly half-sized inputs, in addition to linear-time overhead for additions and shifts. The grade-school algorithm performs a multiplication for two $n$-digit numbers using a quadratic number of single-digit multiplications.\n- To empirically estimate an exponent $\\alpha$ in a hypothesized law $t(n) = c \\cdot n^{\\alpha}$ with constant $c0$, it suffices to apply a logarithm and fit a line $y = \\alpha x + b$ where $x = \\ln n$, $y = \\ln t(n)$, and $b = \\ln c$. The slope $\\alpha$ can be estimated by Ordinary Least Squares (OLS).\n\nYour program must:\n1) Implement a counting model for two multiplication strategies over length-$n$ digit strings (in any fixed base) that returns a proxy “time” $t(n)$ equal to the number of single-digit multiplications performed by the algorithm on worst-case inputs of length $n$.\n   - For the grade-school algorithm, use the fundamental fact that it performs $n^2$ single-digit multiplications; set $t_{\\text{grade}}(n) = n^2$.\n   - For Karatsuba, implement a recurrence that counts single-digit multiplications under divide-and-conquer with a tunable base-case threshold $b$. Specifically, for $n \\le b$, use the grade-school cost $n^2$ as the base case; for $n  b$, split $n$ into two parts $n_{\\text{high}} = \\lceil n/2 \\rceil$ and $n_{\\text{low}} = \\lfloor n/2 \\rfloor$, and count three recursive multiplications on subproblem sizes $n_{\\text{high}}$, $n_{\\text{low}}$, and $\\max(n_{\\text{high}}, n_{\\text{low}})$. This models the three submultiplications performed after the divide-and-conquer rearrangement, while additions and shifts are not counted in $t(n)$ (they do not change the fitted exponent when using sufficiently large $n$). The recurrence is\n   $$\n   t_{\\text{kara}}(n) = \n   \\begin{cases}\n   n^2,  n \\le b,\\\\\n   t_{\\text{kara}}(n_{\\text{high}}) + t_{\\text{kara}}(n_{\\text{low}}) + t_{\\text{kara}}(\\max\\{n_{\\text{high}}, n_{\\text{low}}\\}),  n  b,\n   \\end{cases}\n   $$\n   with $n_{\\text{high}} = \\lceil n/2 \\rceil$ and $n_{\\text{low}} = \\lfloor n/2 \\rfloor$.\n\n2) For each provided test case, generate a sequence of input sizes $\\{n_i\\}$, compute the corresponding counts $\\{t(n_i)\\}$ for the specified algorithm, then estimate $\\alpha$ by OLS on the pairs $(\\ln n_i, \\ln t(n_i))$. Use the natural logarithm. The fitted slope is the estimate $\\widehat{\\alpha}$.\n\n3) For comparison with theory, compute the absolute error of the estimate relative to the theoretical exponent obtained by solving the standard divide-and-conquer recurrence using the Master Theorem framework. For the Karatsuba method, the theoretical exponent is the unique $\\alpha$ satisfying the homogeneous recurrence solution for the case of three subproblems of half size and lower-order work; for the grade-school method, the theoretical exponent is that of the quadratic work law.\n\nThe test suite to be executed by your program is as follows. Each test case specifies the algorithm, the base-case threshold $b$ (only for Karatsuba), and the list of sizes $\\{n_i\\}$ on which to fit the model:\n- Test $1$ (happy path, powers of two with moderate threshold): Karatsuba with $b = 16$ on sizes $[16, 32, 64, 128, 256]$.\n- Test $2$ (happy path, larger threshold): Karatsuba with $b = 32$ on sizes $[32, 64, 128, 256, 512]$.\n- Test $3$ (edge case, aggressive recursion): Karatsuba with $b = 1$ on sizes $[8, 16, 32, 64, 128]$.\n- Test $4$ (control, quadratic baseline): grade-school on sizes $[16, 32, 64, 128, 256]$.\n- Test $5$ (non-power-of-two sizes to test uneven splits): Karatsuba with $b = 8$ on sizes $[30, 60, 120, 240, 480]$.\n\nFor each test case, your program must output two floating-point numbers:\n- The fitted exponent $\\widehat{\\alpha}$.\n- The absolute error $|\\widehat{\\alpha} - \\alpha_{\\text{theory}}|$, where for Karatsuba, $\\alpha_{\\text{theory}}$ is the theoretical exponent that solves the three-way half-size recurrence, and for grade-school, $\\alpha_{\\text{theory}}$ is the quadratic exponent.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in order, the pair for Test $1$, then Test $2$, then Test $3$, then Test $4$, then Test $5$. For example, the output should have the form\n$[\\widehat{\\alpha}_1,\\text{err}_1,\\widehat{\\alpha}_2,\\text{err}_2,\\widehat{\\alpha}_3,\\text{err}_3,\\widehat{\\alpha}_4,\\text{err}_4,\\widehat{\\alpha}_5,\\text{err}_5]$.\nAll numbers must be printed as decimal floating-point values. No physical units are involved in this problem.",
            "solution": "The objective of this problem is to conduct a computational experiment to empirically validate the theoretical time complexity of the Karatsuba multiplication algorithm. This involves implementing a counting model for the number of elementary multiplications, performing a statistical analysis on the generated data, and comparing the empirical results with the established theoretical exponents derived from divide-and-conquer analysis.\n\n### 1. Theoretical Framework and Estimation Method\n\nThe time complexity of many algorithms, particularly those based on divide-and-conquer, can be modeled for an input of size $n$ by a power law of the form:\n$$\nt(n) \\approx c \\cdot n^{\\alpha}\n$$\nwhere $t(n)$ represents the number of fundamental operations (a proxy for runtime), $c$ is a constant related to implementation details and overhead, and $\\alpha$ is the asymptotic scaling exponent that characterizes the algorithm's efficiency.\n\nTo empirically estimate the exponent $\\alpha$, we can transform this power-law relationship into a linear one by taking the natural logarithm of both sides:\n$$\n\\ln(t(n)) = \\ln(c \\cdot n^{\\alpha}) = \\ln(c) + \\alpha \\ln(n)\n$$\nThis equation is in the form of a straight line, $y = b + \\alpha x$, where $y = \\ln(t(n))$, $x = \\ln(n)$, and the y-intercept is $b = \\ln(c)$. Given a set of data points $(n_i, t(n_i))$ from the computational experiment, we can generate a set of transformed points $(x_i, y_i) = (\\ln(n_i), \\ln(t(n_i)))$. The exponent $\\alpha$ can then be estimated as the slope of the best-fit line through these points using Ordinary Least Squares (OLS).\n\nFor a set of $N$ data points $\\{(x_i, y_i)\\}_{i=1}^N$, the OLS estimate for the slope, denoted $\\widehat{\\alpha}$, is given by the formula:\n$$\n\\widehat{\\alpha} = \\frac{\\sum_{i=1}^{N} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{N} (x_i - \\bar{x})^2}\n$$\nwhere $\\bar{x}$ and $\\bar{y}$ are the sample means of the $x_i$ and $y_i$ values, respectively.\n\n### 2. Algorithmic Models and Theoretical Exponents\n\nThe experiment considers two multiplication algorithms:\n\n**Grade-School Multiplication:**\nThe standard grade-school method for multiplying two $n$-digit numbers performs $n \\times n = n^2$ single-digit multiplications. The counting function is therefore:\n$$\nt_{\\text{grade}}(n) = n^2\n$$\nFrom this quadratic relationship, the theoretical exponent is precisely $\\alpha_{\\text{grade}} = 2$.\n\n**Karatsuba Multiplication:**\nThe Karatsuba algorithm is a divide-and-conquer strategy. The problem specifies a precise recurrence relation for counting the number of single-digit multiplications, which includes a base-case threshold $b$. For an input of size $n$:\n$$\nt_{\\text{kara}}(n, b) = \n\\begin{cases}\nn^2,  \\text{if } n \\le b \\\\\nt_{\\text{kara}}(n_{\\text{high}}, b) + t_{\\text{kara}}(n_{\\text{low}}, b) + t_{\\text{kara}}(\\max\\{n_{\\text{high}}, n_{\\text{low}}\\}, b),  \\text{if } n  b\n\\end{cases}\n$$\nwhere $n_{\\text{high}} = \\lceil n/2 \\rceil$ and $n_{\\text{low}} = \\lfloor n/2 \\rfloor$. Since $n_{\\text{high}} \\ge n_{\\text{low}}$ by definition, the term $\\max\\{n_{\\text{high}}, n_{\\text{low}}\\}$ simplifies to $n_{\\text{high}}$. The recurrence becomes:\n$$\nt_{\\text{kara}}(n, b) = 2 \\cdot t_{\\text{kara}}(\\lceil n/2 \\rceil, b) + t_{\\text{kara}}(\\lfloor n/2 \\rfloor, b)\n$$\nThe standard asymptotic analysis of Karatsuba's algorithm considers the simplified recurrence $T(n) = 3T(n/2) + O(n)$, which neglects the ceiling/floor functions and additive lower-order terms. Applying the Master Theorem to this recurrence (with $a=3, b=2$), the complexity is dominated by the recursive calls, yielding $T(n) = \\Theta(n^{\\log_b a}) = \\Theta(n^{\\log_2 3})$. Thus, the theoretical exponent is:\n$$\n\\alpha_{\\text{kara}} = \\log_2 3 \\approx 1.58496\n$$\nThis theoretical value serves as the benchmark against which our empirical estimate $\\widehat{\\alpha}$ will be compared.\n\n### 3. Experimental Design and Procedure\n\nThe program will execute a series of tests as defined in the problem statement. For each test, the following steps are performed:\n$1$. The appropriate counting function ($t_{\\text{grade}}$ or $t_{\\text{kara}}$) is used to generate the operation counts $\\{t(n_i)\\}$ for the given list of input sizes $\\{n_i\\}$. For the recursive $t_{\\text{kara}}$ function, memoization (caching) is employed to avoid redundant computations and ensure efficiency.\n$2$. The data is transformed into a log-log scale, producing points $(x_i, y_i) = (\\ln(n_i), \\ln(t(n_i)))$.\n$3$. The OLS formula is applied to the transformed points to calculate the estimated exponent $\\widehat{\\alpha}$.\n$4$. The absolute error is computed as $|\\widehat{\\alpha} - \\alpha_{\\text{theory}}|$, where $\\alpha_{\\text{theory}}$ is $2$ for the grade-school algorithm and $\\log_2 3$ for the Karatsuba algorithm.\n$5$. The resulting pair $(\\widehat{\\alpha}, |\\widehat{\\alpha} - \\alpha_{\\text{theory}}|)$ is stored.\n\nThe final output aggregates these pairs from all test cases into a single, formatted list. The test cases are designed to explore the behavior of the algorithms under different conditions, such as varying base-case thresholds, input sizes that are powers of two, and input sizes that are not powers of two, which test the handling of uneven splits in the recurrence.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the computational experiment and print the results.\n    \"\"\"\n\n    def get_kara_counter(b):\n        \"\"\"\n        Creates a memoized recursive function to count multiplications for Karatsuba.\n        A closure is used to maintain a private cache for a given base-case threshold b.\n        \"\"\"\n        memo = {}\n\n        def t_kara(n):\n            if n in memo:\n                return memo[n]\n            \n            if n = b:\n                result = n * n\n                memo[n] = result\n                return result\n\n            n_high = (n + 1) // 2  # Integer equivalent of math.ceil(n / 2)\n            n_low = n // 2         # Integer equivalent of math.floor(n / 2)\n            \n            # The recurrence given is t(n) = t(n_high) + t(n_low) + t(max(n_high, n_low)).\n            # Since n_high = n_low, this simplifies to 2 * t(n_high) + t(n_low).\n            result = 2 * t_kara(n_high) + t_kara(n_low)\n            memo[n] = result\n            return result\n\n        return t_kara\n\n    def t_grade(n):\n        \"\"\"\n        Counts multiplications for the grade-school algorithm.\n        \"\"\"\n        return n * n\n\n    def estimate_exponent_ols(n_values, t_values):\n        \"\"\"\n        Estimates the exponent alpha from (n, t) data using OLS on log-log data.\n        \"\"\"\n        if len(n_values)  2:\n            return np.nan # Cannot fit a line to fewer than 2 points\n\n        x = np.log(n_values)\n        y = np.log(t_values)\n        \n        x_mean = np.mean(x)\n        y_mean = np.mean(y)\n        \n        numerator = np.sum((x - x_mean) * (y - y_mean))\n        denominator = np.sum((x - x_mean)**2)\n        \n        if denominator == 0:\n            return np.nan # all n_values were the same\n            \n        alpha_hat = numerator / denominator\n        return alpha_hat\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'id': 1, 'algo': 'karatsuba', 'b': 16, 'n': [16, 32, 64, 128, 256]},\n        {'id': 2, 'algo': 'karatsuba', 'b': 32, 'n': [32, 64, 128, 256, 512]},\n        {'id': 3, 'algo': 'karatsuba', 'b': 1,  'n': [8, 16, 32, 64, 128]},\n        {'id': 4, 'algo': 'grade-school', 'n': [16, 32, 64, 128, 256]},\n        {'id': 5, 'algo': 'karatsuba', 'b': 8,  'n': [30, 60, 120, 240, 480]},\n    ]\n    \n    # Theoretical exponents\n    alpha_theory_kara = np.log(3) / np.log(2)\n    alpha_theory_grade = 2.0\n    \n    all_results = []\n\n    for case in test_cases:\n        n_values = np.array(case['n'])\n        \n        if case['algo'] == 'karatsuba':\n            b = case['b']\n            counter_func = get_kara_counter(b)\n            t_values = np.array([counter_func(n) for n in n_values])\n            alpha_theory = alpha_theory_kara\n        else: # grade-school\n            t_values = np.array([t_grade(n) for n in n_values])\n            alpha_theory = alpha_theory_grade\n\n        # Estimate exponent and calculate error\n        alpha_hat = estimate_exponent_ols(n_values, t_values)\n        error = np.abs(alpha_hat - alpha_theory)\n        \n        all_results.extend([alpha_hat, error])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "An asymptotically superior algorithm is not always the fastest for every input size, as its more complex logic often carries higher overhead. This advanced practice delves into the practical side of algorithm engineering by asking you to find the \"crossover threshold\"—the input size at which Karatsuba's algorithm actually becomes faster than the simpler grade-school method on a given machine . By building empirical timing models from microbenchmarks, you will learn how to create data-driven hybrid algorithms, a technique essential for developing high-performance scientific computing libraries.",
            "id": "3243290",
            "problem": "You are to implement and empirically calibrate the algorithm selection threshold for long integer multiplication between a baseline grade-school method and a divide-and-conquer method. The target platform is a smartphone Advanced RISC Machines (ARM) central processing unit (CPU), but you must perform the calibration on your current environment using a principled microbenchmark that has well-defined units and a testable output. The threshold is the smallest limb count at which the divide-and-conquer approach is predicted to be faster than the grade-school approach. Your implementation must be a complete, runnable program as specified in the final answer, and must produce the final output line described below.\n\nFundamental base and definitions to use:\n- A nonnegative integer is represented as a list of limbs in base $B$, where each limb is an integer in $\\{0, 1, \\dots, B-1\\}$. For this task, fix $B = 10^4$.\n- The grade-school multiplication computes the product of two $n$-limb integers by accumulating all pairwise limb products and then performing carry propagation. This algorithm runs on the limb representation and uses only limb addition and limb multiplication as primitive operations.\n- The Karatsuba divide-and-conquer multiplication recursively splits inputs in half, performs three multiplications on the halves, and combines the results with additions and subtractions and positional shifts. The algorithm’s asymptotic behavior stems from its recursive structure, but you must not assume any constant-factor model a priori; you should determine constants empirically.\n\nYou must follow these steps:\n1. Implement limb-based addition, subtraction (assuming the minuend is not smaller than the subtrahend), and multiplication for the grade-school algorithm over base $B = 10^4$, operating on lists of limbs in little-endian order (least significant limb first).\n2. Implement Karatsuba multiplication over limbs in the same base, using a base-case that falls back to the grade-school multiplication when the smaller operand’s limb-length is at or below a given integer threshold. Your implementation must correctly handle carries and trimming of leading zeros in the limb representation.\n3. Microbenchmark primitive limb operations to obtain empirical timing in seconds:\n   - Measure the average time per limb-array addition on arrays of fixed length $L$ across $R$ repetitions.\n   - Measure the average time per single-limb multiplication across $S$ repetitions.\n   Report no timing values in the program’s printed output; use seconds as the timing unit internally for all regressions and decisions.\n4. Build an empirical model by timing complete algorithm executions on random $n$-limb inputs for a training set of sizes. For each $n$ in the training set, time:\n   - The grade-school multiplication, yielding a measurement $t_g(n)$ in seconds.\n   - The Karatsuba multiplication configured to force divide-and-conquer recursion at the top level (i.e., with a minimal base-case threshold), yielding $t_k(n)$ in seconds.\n   Use at least $3$ repetitions per $n$ and average the timings. Generate random inputs with a fixed seed for reproducibility and ensure each operand has exactly $n$ limbs with the most significant limb nonzero.\n5. Fit the following regression models in seconds (use ordinary least squares):\n   - Grade-school: $t_g(n) \\approx \\alpha \\cdot n^2 + \\beta$ where $\\alpha$ and $\\beta$ are real parameters to estimate.\n   - Karatsuba: $t_k(n) \\approx \\gamma \\cdot n^{\\log_2 3} + \\delta \\cdot n + \\epsilon$ where $\\gamma$, $\\delta$, and $\\epsilon$ are real parameters to estimate, and $n^{\\log_2 3}$ denotes $n$ raised to the power $\\log_2 3$.\n6. Define the predicted threshold $n_0$ as the smallest positive integer $n$ such that the Karatsuba model’s predicted time is strictly less than the grade-school model’s predicted time, i.e., $t_k(n)  t_g(n)$ based on the fitted models. If no such $n$ exists within a reasonable search bound, set $n_0$ to be the bound itself.\n7. Validation on random $n$-digit inputs:\n   - Using a fixed seed, generate random pairs of operands for the following validation sizes (in limbs): $n_1 = 1$, $n_2 = \\max(1, n_0 - 4)$, $n_3 = n_0$, $n_4 = n_0 + 4$, and $n_5 = \\max(2n_0, n_0 + 16)$.\n   - For each $n_i$, measure the actual execution times in seconds of both algorithms (grade-school and Karatsuba forced recursive) on the same operands. Then simulate the selection rule “use Karatsuba if $n \\ge n_0$, otherwise use grade-school,” and record a boolean indicating whether the selected algorithm is strictly faster than the alternative on that case.\n   - Additionally, verify correctness for all validation cases by comparing each algorithm’s product against the product computed by native integer multiplication on the same inputs and record a final boolean indicating whether all algorithm outputs agree with native multiplication across all validation cases.\n8. Final output format:\n   Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the predicted threshold $n_0$ as an integer followed by six booleans:\n   - The first five booleans correspond in order to the five validation sizes $[n_1, n_2, n_3, n_4, n_5]$, each indicating whether the selection rule chose the faster algorithm on that case.\n   - The sixth boolean indicates whether both algorithms produced correct results (matching native integer multiplication) for all five validation cases.\n   For example, a valid output form is $[42,True,True,False,True,True,True]$ with no spaces.\n\nTest suite specification:\n- Use base $B = 10^4$ for all limb operations.\n- Use training sizes $n \\in \\{8,16,32,64,96,128\\}$ for building the regression models.\n- Use exactly $3$ timing repetitions per training size in seconds.\n- Use fixed seeds for random generation: a seed of $12345$ for training data and a seed of $67890$ for validation data.\n- Use a search bound of $512$ limbs when determining $n_0$.\n\nYour program must be self-contained, require no input, and adhere to the exact output format described above. All times must be measured and used internally in seconds, and all random generation must be reproducible with the specified seeds.",
            "solution": "The problem is well-defined, scientifically grounded, and internally consistent. It presents a standard task in empirical algorithm analysis: implementing two algorithms for the same problem (long integer multiplication), modeling their performance, and determining the practical crossover point where the asymptotically superior algorithm becomes faster. All required parameters, constants, random seeds, and procedures are specified, making the problem objective and reproducible. Therefore, the problem is valid.\n\nThe solution will be implemented by following the methodical steps laid out in the problem statement.\n\n**1. Integer Representation and Primitive Operations**\nA non-negative integer is represented as a list of \"limbs\" in base $B = 10^4$. The limbs are stored in little-endian order (least significant limb first). For example, the integer $123456789$ would be represented with $B=10^4$ as `[6789, 2345, 1]`. All arithmetic operations are defined to work on this limb representation.\n\nKey helper functions are implemented:\n- `normalize(limbs)`: This function handles carry propagation. After an operation like addition or multiplication, a limb might exceed the base $B-1$. This function iterates through the limbs, propagating the carry `c = limb // B` to the next higher-order limb.\n- `trim(limbs)`: This removes any leading zero limbs from the most significant end of the list to maintain a canonical representation. A special case ensures that the number zero is represented as `[0]`, not an empty list.\n\nThe primary arithmetic operations are:\n- **Addition (`add`)**: Given two limb lists, it performs element-wise addition and then normalizes the result to handle carries.\n- **Subtraction (`subtract`)**: Given two limb lists representing integers $x$ and $y$ where $x \\ge y$, it performs element-wise subtraction. If a subtraction `x_i - y_i` results in a negative value, a 'borrow' is taken from the next limb, equivalent to adding $B$ to the current limb and subtracting $1$ from the next.\n- **Grade-School Multiplication (`grade_school_multiply`)**: This implements the standard $O(n^2)$ algorithm. For two integers with $n_x$ and $n_y$ limbs respectively, a result list of size $n_x + n_y$ is created. The product is computed by summing all pairwise limb products: `res[i+j] += x[i] * y[j]`. After all products are accumulated, a single `normalize` call resolves all carries.\n\n**2. Karatsuba Multiplication**\nThe Karatsuba algorithm is a recursive, divide-and-conquer method for multiplication with an asymptotic complexity of $O(n^{\\log_2 3})$. Given two $n$-limb numbers $x$ and $y$, we split them into high and low halves:\n$$ x = x_1 \\cdot B^k + x_0 $$\n$$ y = y_1 \\cdot B^k + y_0 $$\nwhere $k = \\lceil n/2 \\rceil$ is the split point. The product $x \\cdot y$ is then:\n$$ x \\cdot y = (x_1 y_1) \\cdot B^{2k} + ((x_1+x_0)(y_1+y_0) - x_1y_1 - x_0y_0) \\cdot B^k + (x_0y_0) $$\nThis formulation requires three recursive multiplications of numbers approximately half the original size: $p_1 = x_1y_1$, $p_2 = x_0y_0$, and $p_3 = (x_1+x_0)(y_1+y_0)$. The final result is assembled using additions, subtractions, and positional shifts (achieved by padding with zero limbs). The recursion terminates when the number of limbs in an operand is smaller than or equal to a specified `threshold`, at which point the algorithm falls back to the more efficient `grade_school_multiply` for small inputs.\n\n**3. Empirical Modeling and Threshold Calibration**\nThe core of the problem is to find the optimal threshold $n_0$ for switching from grade-school to Karatsuba multiplication. This is achieved through empirical analysis.\n\n- **Data Collection**: The execution times of both `grade_school_multiply` and `karatsuba_multiply` are measured. For Karatsuba, the base-case `threshold` is set to a minimal value (e.g., $1$) to ensure the recursive structure is fully exercised. Timings are collected for a set of operand sizes $n \\in \\{8, 16, 32, 64, 96, 128\\}$. For reproducibility, random operands are generated using a fixed seed ($12345$), and each timing is the average of $3$ repetitions.\n\n- **Regression Analysis**: The collected timing data, $(n, t(n))$, is used to fit performance models via ordinary least squares (OLS). The models are specified as:\n  - Grade-school: $t_g(n) \\approx \\alpha \\cdot n^2 + \\beta$\n  - Karatsuba: $t_k(n) \\approx \\gamma \\cdot n^{\\log_2 3} + \\delta \\cdot n + \\epsilon$\n  The coefficients $(\\alpha, \\beta)$ and $(\\gamma, \\delta, \\epsilon)$ are determined by solving a linear system. For example, for the grade-school model, we solve $A \\cdot [\\alpha, \\beta]^T = \\mathbf{t_g}$ where $\\mathbf{t_g}$ is the vector of measured times and $A$ is the design matrix with columns corresponding to $n^2$ and $1$.\n\n- **Threshold Determination**: With the fitted models, we can predict the execution time for any $n$. The threshold $n_0$ is defined as the smallest positive integer $n$ for which the predicted Karatsuba time is strictly less than the predicted grade-school time: $t_k(n)  t_g(n)$. This is found by iterating $n$ from $1$ up to a search bound of $512$.\n\n**4. Validation**\nThe determined threshold $n_0$ and the correctness of the algorithms are validated on a separate set of test cases generated with a different random seed ($67890$).\n- **Test Cases**: Five validation cases are constructed with operand sizes $n_1 = 1$, $n_2 = \\max(1, n_0 - 4)$, $n_3 = n_0$, $n_4 = n_0 + 4$, and $n_5 = \\max(2n_0, n_0 + 16)$.\n- **Correctness Check**: For each case, the results from both `grade_school_multiply` and `karatsuba_multiply` are compared against the product computed by Python's native arbitrary-precision integers. A final boolean flag tracks whether all implemented results were correct across all validation cases.\n- **Selection Rule Efficacy**: The selection rule \"Use Karatsuba if operand size $n \\ge n_0$, else use grade-school\" is simulated. For each validation case, we record a boolean indicating whether this rule actually chose the algorithm that was strictly faster in that specific trial.\n\nThe final output is a list containing the integer threshold $n_0$, the five booleans from the selection rule check, and the final boolean for the correctness check, formatted as specified.",
            "answer": "```python\nimport time\nimport math\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and calibrates the algorithm selection threshold for long integer multiplication.\n    \"\"\"\n    \n    # --- Constants and Configuration ---\n    BASE = 10000\n    TRAINING_SEED = 12345\n    VALIDATION_SEED = 67890\n    TRAINING_SIZES = [8, 16, 32, 64, 96, 128]\n    REPETITIONS = 3\n    THRESHOLD_SEARCH_BOUND = 512\n    LOG2_3 = math.log2(3)\n\n    # --- Utility Functions for Limb Representation ---\n    \n    def trim(limbs):\n        \"\"\"Removes leading zeros from a limb list.\"\"\"\n        while len(limbs)  1 and limbs[-1] == 0:\n            limbs.pop()\n        return limbs\n\n    def normalize(limbs):\n        \"\"\"Propagates carries in a limb list.\"\"\"\n        carry = 0\n        for i in range(len(limbs)):\n            limbs[i] += carry\n            carry = limbs[i] // BASE\n            limbs[i] %= BASE\n        while carry  0:\n            limbs.append(carry % BASE)\n            carry //= BASE\n        return trim(limbs)\n\n    def from_limbs(limbs):\n        \"\"\"Converts a limb list back to a native Python integer.\"\"\"\n        n = 0\n        for i in range(len(limbs) - 1, -1, -1):\n            n = n * BASE + limbs[i]\n        return n\n\n    def random_limbs(n, rng):\n        \"\"\"Generates a random n-limb number with a non-zero most significant limb.\"\"\"\n        if n == 0: return [0]\n        if n == 1: return [rng.integers(0, BASE)]\n        \n        limbs = rng.integers(0, BASE, size=n-1).tolist()\n        msl = rng.integers(1, BASE) # Most significant limb\n        limbs.append(msl)\n        return limbs\n\n    # --- Core Arithmetic Algorithms on Limbs ---\n\n    def add(x_limbs, y_limbs):\n        \"\"\"Adds two numbers in limb representation.\"\"\"\n        nx, ny = len(x_limbs), len(y_limbs)\n        n = max(nx, ny)\n        res = [0] * n\n        \n        for i in range(n):\n            v_x = x_limbs[i] if i  nx else 0\n            v_y = y_limbs[i] if i  ny else 0\n            res[i] = v_x + v_y\n            \n        return normalize(res)\n\n    def subtract(x_limbs, y_limbs):\n        \"\"\"Subtracts y from x (x = y) in limb representation.\"\"\"\n        nx, ny = len(x_limbs), len(y_limbs)\n        res = list(x_limbs)\n        borrow = 0\n        \n        for i in range(nx):\n            v_y = y_limbs[i] if i  ny else 0\n            sub = res[i] - v_y - borrow\n            if sub  0:\n                sub += BASE\n                borrow = 1\n            else:\n                borrow = 0\n            res[i] = sub\n        \n        return trim(res)\n\n    def grade_school_multiply(x_limbs, y_limbs):\n        \"\"\"Multiplies two numbers using the grade-school algorithm.\"\"\"\n        if (len(x_limbs) == 1 and x_limbs[0] == 0) or \\\n           (len(y_limbs) == 1 and y_limbs[0] == 0):\n            return [0]\n\n        nx, ny = len(x_limbs), len(y_limbs)\n        res = [0] * (nx + ny)\n        \n        for i in range(nx):\n            for j in range(ny):\n                res[i+j] += x_limbs[i] * y_limbs[j]\n        \n        return normalize(res)\n\n    def karatsuba_multiply(x_limbs, y_limbs, threshold):\n        \"\"\"Multiplies two numbers using Karatsuba's algorithm.\"\"\"\n        nx, ny = len(x_limbs), len(y_limbs)\n\n        if min(nx, ny) = threshold:\n            return grade_school_multiply(x_limbs, y_limbs)\n\n        n = max(nx, ny)\n        k = (n + 1) // 2\n\n        low_x = x_limbs[:k] if k = nx else x_limbs\n        high_x = x_limbs[k:] if k  nx else [0]\n        \n        low_y = y_limbs[:k] if k = ny else y_limbs\n        high_y = y_limbs[k:] if k  ny else [0]\n\n        p1 = karatsuba_multiply(high_x, high_y, threshold)\n        p2 = karatsuba_multiply(low_x, low_y, threshold)\n        \n        sum_x = add(low_x, high_x)\n        sum_y = add(low_y, high_y)\n        p3 = karatsuba_multiply(sum_x, sum_y, threshold)\n        \n        sum_p1_p2 = add(p1, p2)\n        term2 = subtract(p3, sum_p1_p2)\n        \n        shifted_p1 = [0] * (2 * k) + p1\n        shifted_term2 = [0] * k + term2\n\n        res = add(shifted_p1, shifted_term2)\n        res = add(res, p2)\n        \n        return trim(res)\n\n    \n    # --- Step 3: Microbenchmark (executed as required, but results not used in model) ---\n    # This section fulfills the requirement but the primary model relies on full algorithm timing.\n    def microbenchmark_primitives():\n        L, R, S = 100, 1000, 10000\n        rng = np.random.default_rng(0)\n        \n        add_ops_limbs = [rng.integers(0, BASE, size=L).tolist() for _ in range(R * 2)]\n        start = time.perf_counter()\n        for i in range(R):\n            add(add_ops_limbs[2*i], add_ops_limbs[2*i+1])\n        _ = (time.perf_counter() - start) / R # avg_add_time\n\n        mult_ops = rng.integers(0, BASE, size=S * 2)\n        start = time.perf_counter()\n        for i in range(S):\n            _ = mult_ops[2*i] * mult_ops[2*i+1]\n        _ = (time.perf_counter() - start) / S # avg_mult_time\n    microbenchmark_primitives()\n\n    # --- Step 4: Time Complete Algorithms for Model Training ---\n    training_rng = np.random.default_rng(TRAINING_SEED)\n    tg_data = []\n    tk_data = []\n\n    for n in TRAINING_SIZES:\n        times_g = []\n        times_k = []\n        for _ in range(REPETITIONS):\n            x = random_limbs(n, training_rng)\n            y = random_limbs(n, training_rng)\n            \n            start_g = time.perf_counter()\n            grade_school_multiply(x, y)\n            times_g.append(time.perf_counter() - start_g)\n\n            start_k = time.perf_counter()\n            karatsuba_multiply(x, y, threshold=1)\n            times_k.append(time.perf_counter() - start_k)\n        \n        tg_data.append((n, np.mean(times_g)))\n        tk_data.append((n, np.mean(times_k)))\n\n    # --- Step 5: Fit Regression Models ---\n    n_train = np.array([d[0] for d in tg_data], dtype=np.float64)\n    t_g_train = np.array([d[1] for d in tg_data])\n    t_k_train = np.array([d[1] for d in tk_data])\n\n    A_g = np.vstack([n_train**2, np.ones_like(n_train)]).T\n    alpha, beta = np.linalg.lstsq(A_g, t_g_train, rcond=None)[0]\n\n    A_k = np.vstack([n_train**LOG2_3, n_train, np.ones_like(n_train)]).T\n    gamma, delta, epsilon = np.linalg.lstsq(A_k, t_k_train, rcond=None)[0]\n\n    # --- Step 6: Find Threshold n0 ---\n    n0 = THRESHOLD_SEARCH_BOUND\n    for n_test in range(1, THRESHOLD_SEARCH_BOUND + 1):\n        t_g_pred = alpha * (n_test**2) + beta\n        t_k_pred = gamma * (n_test**LOG2_3) + delta * n_test + epsilon\n        if t_k_pred  t_g_pred:\n            n0 = n_test\n            break\n\n    # --- Step 7: Validation ---\n    validation_rng = np.random.default_rng(VALIDATION_SEED)\n    validation_sizes = [\n        1,\n        max(1, n0 - 4),\n        n0,\n        n0 + 4,\n        max(2 * n0, n0 + 16)\n    ]\n    \n    selection_faster_bools = []\n    all_correct = True\n\n    for n_val in validation_sizes:\n        x_limbs = random_limbs(n_val, validation_rng)\n        y_limbs = random_limbs(n_val, validation_rng)\n        \n        expected_product = from_limbs(x_limbs) * from_limbs(y_limbs)\n\n        start = time.perf_counter()\n        res_g_limbs = grade_school_multiply(x_limbs, y_limbs)\n        time_g = time.perf_counter() - start\n        \n        start = time.perf_counter()\n        res_k_limbs = karatsuba_multiply(x_limbs, y_limbs, threshold=1)\n        time_k = time.perf_counter() - start\n\n        # Correctness check\n        if from_limbs(res_g_limbs) != expected_product or \\\n           from_limbs(res_k_limbs) != expected_product:\n            all_correct = False\n        \n        # Selection rule performance check\n        use_karatsuba = n_val = n0\n        if use_karatsuba:\n            selection_faster_bools.append(time_k  time_g)\n        else:\n            selection_faster_bools.append(time_g  time_k)\n\n    # --- Step 8: Final Output ---\n    final_list = [n0] + selection_faster_bools + [all_correct]\n    print(f\"[{','.join(map(str, final_list))}]\")\n\nsolve()\n```"
        }
    ]
}