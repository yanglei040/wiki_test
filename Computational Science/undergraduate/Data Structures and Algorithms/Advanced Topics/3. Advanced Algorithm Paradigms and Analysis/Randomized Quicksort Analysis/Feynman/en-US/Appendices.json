{
    "hands_on_practices": [
        {
            "introduction": "To analyze a randomized algorithm, we must first be crystal clear about the source of randomness and its direct implications. This initial practice problem zeroes in on the single most important component of randomized quicksort: the pivot selection. By calculating the probability of a \"perfectly balanced\" split, you will solidify your understanding of what \"choosing a pivot uniformly at random\" truly means and how it translates into concrete probabilities for different partitioning outcomes. ",
            "id": "3264015",
            "problem": "Consider the standard randomized quicksort on an input array of $n$ distinct keys drawn from a totally ordered set. At the root of the recursion, the algorithm selects a pivot uniformly at random from the $n$ keys, partitions the remaining $n-1$ keys into those less than the pivot and those greater than the pivot, and then recursively sorts the two resulting subarrays. Let $k$ denote the number of keys strictly less than the pivot (so the left subproblem has size $k$ and the right subproblem has size $n-1-k$). Define a perfectly balanced split to mean $k=\\lfloor n/2 \\rfloor$.\n\nStarting from the core definition that the pivot is chosen uniformly at random from the $n$ distinct keys and that its rank among the $n$ keys is equally likely to be any of the integers from $1$ through $n$, derive from first principles the exact probability, as a function of $n$, that the root split is perfectly balanced in the sense $k=\\lfloor n/2 \\rfloor$.\n\nExpress your final answer as a single simplified closed-form expression in terms of $n$. No rounding is required.",
            "solution": "Let the $n$ distinct keys be sorted as $z_1  z_2  \\dots  z_n$. The rank of a key is its position in this sorted sequence.\n\nThe randomized quicksort algorithm selects a pivot uniformly at random from the $n$ keys. This means that each key $z_i$ has an equal probability of being chosen as the pivot. Let $R$ be the random variable representing the rank of the chosen pivot. The uniformity of the pivot selection implies that the probability of the pivot having rank $i$ is $\\Pr(R=i) = \\frac{1}{n}$ for any $i \\in \\{1, 2, \\dots, n\\}$.\n\nThe problem defines $k$ as the number of keys strictly less than the pivot. If the chosen pivot has rank $R=i$, then there are exactly $i-1$ keys smaller than it. Thus, the size of the left partition is $k = R-1$.\n\nWe are asked to find the probability that the split is \"perfectly balanced,\" which is defined as the event $k = \\lfloor n/2 \\rfloor$. We can express this in terms of the pivot's rank $R$:\n$$ \\Pr(k = \\lfloor n/2 \\rfloor) = \\Pr(R-1 = \\lfloor n/2 \\rfloor) = \\Pr(R = \\lfloor n/2 \\rfloor + 1) $$\nLet $i_0 = \\lfloor n/2 \\rfloor + 1$. This is a single, specific integer. To find the probability that the random variable $R$ takes this specific value $i_0$, we need to check if $i_0$ is a possible rank, i.e., if $1 \\le i_0 \\le n$.\nFor any $n \\ge 1$:\nThe lower bound is $\\lfloor n/2 \\rfloor \\ge 0$, so $i_0 = \\lfloor n/2 \\rfloor + 1 \\ge 1$.\nThe upper bound is $\\lfloor n/2 \\rfloor \\le n/2$, so $i_0 = \\lfloor n/2 \\rfloor + 1 \\le n/2 + 1$. For $n \\ge 2$, $n/2+1 \\le n$. For $n=1$, $i_0=\\lfloor 1/2 \\rfloor + 1 = 1$, which is also $\\le n$.\nSo, for any $n \\ge 1$, the rank $i_0 = \\lfloor n/2 \\rfloor + 1$ is always a valid rank in the set $\\{1, 2, \\dots, n\\}$.\n\nSince the pivot's rank $R$ is uniformly distributed over the $n$ possible ranks, the probability of it being any single specific rank is $\\frac{1}{n}$.\nTherefore,\n$$ \\Pr(R = i_0) = \\Pr(R = \\lfloor n/2 \\rfloor + 1) = \\frac{1}{n} $$",
            "answer": "$$\\boxed{\\frac{1}{n}}$$"
        },
        {
            "introduction": "With the fundamentals of random pivot selection in place, we can now tackle the central question: what is the average-case performance of randomized quicksort? This exercise guides you through the classic and elegant derivation of the expected total number of comparisons, a cornerstone result in algorithm analysis. The method introduces two of the most powerful tools in the computer scientist's probabilistic toolkit—linearity of expectation and indicator random variables—to arrive at a precise and famous result. ",
            "id": "3263936",
            "problem": "Consider a version of the QuickSort algorithm on an input array $A$ that is a permutation of the set $\\{1, 2, \\ldots, n\\}$, where $n \\geq 2$. At every recursive call that operates on a contiguous subarray $A[L..R]$, let $m = R - L + 1$ denote the subarray length. The algorithm chooses the pivot index uniformly at random from the subarray by calling a Random Number Generator (RNG) that returns an Independent and Identically Distributed (i.i.d.) real value $\\operatorname{rand}()$ drawn uniformly from the interval $[0, 1)$, and then sets the pivot index to $L - 1 + \\lceil \\operatorname{rand}() \\cdot m \\rceil$. The subarray is then partitioned using only key comparisons that compare the pivot key to each other key in the subarray exactly once, and the algorithm recurses on the two partitions. Assume that the RNG calls at different recursive levels are mutually independent.\n\nUsing only foundational definitions of expectation in probability theory, the uniformity of the pivot selection described above, and the structural behavior of QuickSort, derive the exact expected total number of key comparisons performed by the algorithm over the entire execution, expressed as a closed-form analytic expression in terms of $n$ and the $n$-th harmonic number $H_n = \\sum_{k=1}^{n} \\frac{1}{k}$.\n\nYour final answer must be a single analytic expression in terms of $n$ and $H_n$. No numerical rounding is required.",
            "solution": "Let $C$ be the random variable for the total number of comparisons. We want to find its expectation, $\\mathbb{E}[C]$. We use the method of indicator variables combined with linearity of expectation.\n\nLet the sorted elements of the input be $z_1  z_2  \\dots  z_n$. For any pair of elements $(z_i, z_j)$ with $i  j$, let $X_{ij}$ be an indicator random variable such that $X_{ij}=1$ if $z_i$ and $z_j$ are compared, and $X_{ij}=0$ otherwise.\n\nThe total number of comparisons is the sum over all pairs: $C = \\sum_{i=1}^{n-1} \\sum_{j=i+1}^{n} X_{ij}$.\n\nBy linearity of expectation, which holds even for dependent variables:\n$$ \\mathbb{E}[C] = \\mathbb{E}\\left[\\sum_{i=1}^{n-1} \\sum_{j=i+1}^{n} X_{ij}\\right] = \\sum_{i=1}^{n-1} \\sum_{j=i+1}^{n} \\mathbb{E}[X_{ij}] $$\nThe expectation of an indicator variable is the probability of the event it indicates: $\\mathbb{E}[X_{ij}] = \\Pr(X_{ij} = 1)$.\n\nNow, we determine the probability that $z_i$ and $z_j$ are compared. Consider the set of elements $S_{ij} = \\{z_i, z_{i+1}, \\dots, z_j\\}$. All elements in $S_{ij}$ are together in the same subarray at the beginning. They will continue to be in the same subarray as long as no pivot is chosen from within $S_{ij}$. The first time a pivot is selected from $S_{ij}$, the fate of $z_i$ and $z_j$ is sealed.\n- If this first pivot is some $z_k$ with $i  k  j$, then $z_i$ is placed in the partition of elements smaller than $z_k$, and $z_j$ is placed in the partition of elements larger than $z_k$. They are separated and will never be compared.\n- If this first pivot is $z_i$ or $z_j$, then they are compared (since the pivot is compared to all other elements in its subarray).\n\nTherefore, $z_i$ and $z_j$ are compared if and only if the first pivot chosen from the set $S_{ij}$ is either $z_i$ or $z_j$.\nSince the pivot is chosen uniformly at random from its subarray, every element in $S_{ij}$ has an equal chance of being the first pivot selected from that set. The size of $S_{ij}$ is $j-i+1$. There are two favorable outcomes ($z_i$ or $z_j$ is chosen) out of $j-i+1$ total possibilities.\nSo, $\\Pr(X_{ij} = 1) = \\frac{2}{j-i+1}$.\n\nNow we can write the total expected number of comparisons as:\n$$ \\mathbb{E}[C] = \\sum_{i=1}^{n-1} \\sum_{j=i+1}^{n} \\frac{2}{j-i+1} $$\nTo evaluate this sum, we can re-index. Let $k = j-i$. The inner sum over $j$ becomes a sum over $k$ from $1$ to $n-i$.\n$$ \\mathbb{E}[C] = \\sum_{i=1}^{n-1} \\sum_{k=1}^{n-i} \\frac{2}{k+1} $$\nNow we change the order of summation. The variable $k$ ranges from $1$ to $n-1$. For a fixed $k$, $i$ can range from $1$ to $n-k$.\n$$ \\mathbb{E}[C] = \\sum_{k=1}^{n-1} \\sum_{i=1}^{n-k} \\frac{2}{k+1} $$\nThe inner sum is over $i$, but the term $\\frac{2}{k+1}$ does not depend on $i$. The number of terms in the inner sum is $n-k$.\n$$ \\mathbb{E}[C] = \\sum_{k=1}^{n-1} (n-k) \\frac{2}{k+1} = 2 \\sum_{k=1}^{n-1} \\frac{n-k}{k+1} $$\nWe can rewrite the numerator: $n-k = (n+1) - (k+1)$.\n$$ \\mathbb{E}[C] = 2 \\sum_{k=1}^{n-1} \\left( \\frac{n+1}{k+1} - \\frac{k+1}{k+1} \\right) = 2 \\sum_{k=1}^{n-1} \\left( \\frac{n+1}{k+1} - 1 \\right) $$\nLet's split the sum:\n$$ \\mathbb{E}[C] = 2 \\left( (n+1) \\sum_{k=1}^{n-1} \\frac{1}{k+1} - \\sum_{k=1}^{n-1} 1 \\right) $$\nThe second sum is simply $n-1$. For the first sum, let $m=k+1$. As $k$ goes from $1$ to $n-1$, $m$ goes from $2$ to $n$.\n$$ \\sum_{k=1}^{n-1} \\frac{1}{k+1} = \\sum_{m=2}^{n} \\frac{1}{m} = \\left(\\sum_{m=1}^{n} \\frac{1}{m}\\right) - 1 = H_n - 1 $$\nSubstituting these back:\n$$ \\mathbb{E}[C] = 2 \\left( (n+1)(H_n - 1) - (n-1) \\right) $$\n$$ \\mathbb{E}[C] = 2 ( (n+1)H_n - (n+1) - n + 1 ) $$\n$$ \\mathbb{E}[C] = 2 ( (n+1)H_n - 2n ) $$\n$$ \\mathbb{E}[C] = 2(n+1)H_n - 4n $$\nThis is the final expression for the expected total number of comparisons.",
            "answer": "$$\\boxed{2(n+1)H_n - 4n}$$"
        },
        {
            "introduction": "While the previous analysis showed that the average performance is excellent, it is also insightful to analyze how often \"unlucky\" events occur. This practice explores the expected number of times quicksort produces a highly unbalanced partition where the pivot is the smallest or largest element in a subarray. To solve this, you will employ a different but equally fundamental technique: setting up and solving a recurrence relation for an expected value, showcasing the versatility of probabilistic analysis. ",
            "id": "3263955",
            "problem": "Consider the standard randomized quicksort on an array of $n$ distinct keys, where at each recursive call the pivot is selected uniformly at random from the current subarray, and a partition operation splits the subarray into elements less than the pivot and elements greater than the pivot. Assume that the partition procedure is invoked only on subarrays of size at least $2$, and that subarrays of size $0$ or $1$ constitute base cases for which no partition is performed.\n\nDefine a partition to be one in which one of the two resulting sides has size $0$; equivalently, the pivot chosen for that partition is either the minimum or the maximum element of the subarray being partitioned. Let $X_n$ denote the total number of such partitions during the complete execution of randomized quicksort on an input of size $n$.\n\nStarting only from the algorithmic definition above and fundamental rules of probability (such as conditioning and linearity of expectation), derive a closed-form expression for the expected value $\\mathbb{E}[X_n]$ as a function of $n$, for $n \\ge 2$. Your final answer must be a single analytic expression in $n$ with no unevaluated sums or recurrences.",
            "solution": "Let $X_n$ be the random variable representing the total number of partitions where the pivot is the minimum or maximum element in its subarray, during the execution of randomized quicksort on an array of $n$ distinct keys. We are asked to find the expected value of $X_n$, denoted by $E_n = \\mathbb{E}[X_n]$, for $n \\ge 2$.\n\nThe problem states that a partition operation is invoked only on subarrays of size at least $2$. This implies that for subarrays of size $0$ or $1$, the recursion terminates and no partitions are performed. Therefore, the number of such partitions for an input of size $n=0$ or $n=1$ is $0$. The corresponding expected values are:\n$E_0 = \\mathbb{E}[X_0] = 0$\n$E_1 = \\mathbb{E}[X_1] = 0$\n\nFor $n \\ge 2$, the algorithm begins by selecting a pivot uniformly at random from the $n$ elements. Let the rank of the chosen pivot be $k$, where $k \\in \\{1, 2, \\dots, n\\}$. The probability of any specific rank $k$ being chosen is $\\frac{1}{n}$.\n\nAfter partitioning the array of size $n$ around the pivot of rank $k$, the array is split into two subarrays of sizes $k-1$ and $n-k$. The algorithm then recursively sorts these two subarrays. The total number of specified partitions, $X_n$, is the sum of contributions from the first partition and the subsequent recursive calls.\n\nLet $I$ be an indicator random variable for the event that the first partition (on the array of size $n$) is one where the pivot is the minimum or maximum element. This event occurs if and only if the chosen pivot has rank $k=1$ (minimum) or $k=n$ (maximum). The probability of this event is $\\Pr(k=1) + \\Pr(k=n) = \\frac{1}{n} + \\frac{1}{n} = \\frac{2}{n}$ for $n \\ge 2$. Therefore, the expected value of $I$ is $\\mathbb{E}[I] = \\frac{2}{n}$.\n\nWe can set up a recurrence for $E_n$ using the law of total expectation, by conditioning on the rank $k$ of the first pivot chosen.\n$$E_n = \\mathbb{E}[X_n] = \\sum_{k=1}^{n} \\mathbb{E}[X_n | \\text{pivot rank is } k] \\cdot \\Pr(\\text{pivot rank is } k)$$\nGiven that the pivot rank is $k$, the total number of specified partitions is the sum of:\n$1$. Whether the first partition is of the specified type (i.e., if $k=1$ or $k=n$).\n$2$. The number of specified partitions in the recursive call on the subarray of size $k-1$.\n$3$. The number of specified partitions in the recursive call on the subarray of size $n-k$.\n\nBy linearity of expectation, the conditional expectation is:\n$$\\mathbb{E}[X_n | \\text{pivot rank is } k] = \\mathbb{E}[I | \\text{pivot rank is } k] + \\mathbb{E}[X_{k-1}] + \\mathbb{E}[X_{n-k}]$$\nThe term $\\mathbb{E}[I | \\text{pivot rank is } k]$ is $1$ if $k=1$ or $k=n$, and $0$ otherwise. The expectations for the recursive calls are $E_{k-1}$ and $E_{n-k}$ respectively, as the randomization for the subproblems is independent of the first pivot choice.\nThus, $\\mathbb{E}[X_n | \\text{pivot rank is } k] = (\\delta_{k,1} + \\delta_{k,n}) + E_{k-1} + E_{n-k}$, where $\\delta_{i,j}$ is the Kronecker delta.\n\nSubstituting this into the sum for $E_n$:\n$$E_n = \\sum_{k=1}^{n} \\left[ (\\delta_{k,1} + \\delta_{k,n}) + E_{k-1} + E_{n-k} \\right] \\frac{1}{n}$$\n$$E_n = \\frac{1}{n} \\left[ \\sum_{k=1}^{n}(\\delta_{k,1} + \\delta_{k,n}) + \\sum_{k=1}^{n}E_{k-1} + \\sum_{k=1}^{n}E_{n-k} \\right]$$\nThe first sum evaluates to $2$, since it is $1$ for $k=1$ and $k=n$, and $0$ otherwise. The next two sums are identical, as an index change $j=n-k$ shows: $\\sum_{k=1}^{n}E_{n-k} = \\sum_{j=0}^{n-1}E_j$.\n$$E_n = \\frac{1}{n} \\left[ 2 + 2\\sum_{j=0}^{n-1}E_j \\right]$$\nThis recurrence relation holds for $n \\ge 2$.\n\nTo solve this recurrence, we first multiply by $n$:\n$$n E_n = 2 + 2\\sum_{j=0}^{n-1}E_j \\quad (*)$$\nThis equation is valid for $n \\ge 2$. We can write the same relation for $n-1$, which is valid for $n-1 \\ge 2$, i.e., $n \\ge 3$:\n$$(n-1)E_{n-1} = 2 + 2\\sum_{j=0}^{n-2}E_j \\quad (**)$$\nSubtracting $(**)$ from $(*)$ for $n \\ge 3$:\n$$n E_n - (n-1)E_{n-1} = \\left(2 + 2\\sum_{j=0}^{n-1}E_j\\right) - \\left(2 + 2\\sum_{j=0}^{n-2}E_j\\right)$$\n$$n E_n - (n-1)E_{n-1} = 2E_{n-1}$$\n$$n E_n = (n-1)E_{n-1} + 2E_{n-1} = (n+1)E_{n-1}$$\nThis gives a simpler recurrence relation for $n \\ge 3$:\n$$E_n = \\frac{n+1}{n} E_{n-1}$$\nWe can solve this by unrolling the recurrence down to $E_2$:\n$$E_n = \\frac{n+1}{n}E_{n-1} = \\frac{n+1}{n} \\cdot \\frac{n}{n-1}E_{n-2} = \\dots = \\left(\\frac{n+1}{n} \\cdot \\frac{n}{n-1} \\cdot \\frac{n-1}{n-2} \\cdots \\frac{4}{3}\\right)E_2$$\nThis is a telescoping product:\n$$E_n = \\frac{n+1}{3}E_2$$\nThis solution is valid for $n \\ge 3$. To find the value of $E_2$, we use the original recurrence relation $(*)$ for $n=2$:\n$$2 E_2 = 2 + 2\\sum_{j=0}^{1}E_j = 2 + 2(E_0 + E_1)$$\nUsing the base cases $E_0=0$ and $E_1=0$:\n$$2 E_2 = 2 + 2(0+0) = 2 \\implies E_2 = 1$$\nThis is also verifiable by inspection: for an array of size $2$, any pivot chosen must be either the minimum or the maximum, so exactly one partition occurs, and it is always of the specified type.\n\nSubstituting $E_2=1$ into the solution for $E_n$:\n$$E_n = \\frac{n+1}{3} \\quad \\text{for } n \\ge 3$$\nFinally, we check if this formula also holds for the boundary case $n=2$:\n$$E_2 = \\frac{2+1}{3} = \\frac{3}{3} = 1$$\nThis matches the value of $E_2$ we calculated. Therefore, the closed-form expression for the expected number of such partitions for any $n \\ge 2$ is $\\frac{n+1}{3}$.",
            "answer": "$$\n\\boxed{\\frac{n+1}{3}}\n$$"
        }
    ]
}