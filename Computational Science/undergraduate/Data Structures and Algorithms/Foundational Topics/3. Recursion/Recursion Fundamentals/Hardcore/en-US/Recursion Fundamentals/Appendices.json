{
    "hands_on_practices": [
        {
            "introduction": "How do we quantify the efficiency of a recursive algorithm? This question is answered by solving recurrence relations, and this practice will sharpen your analytical skills. You will tackle the recurrence $T(n) = T(\\sqrt{n}) + \\ln(n)$, a non-standard form that requires the \"unrolling\" method to find an exact solution. This exercise provides a deeper understanding of how costs accumulate in a recursive process, a crucial skill for any algorithm designer. ",
            "id": "3264680",
            "problem": "Consider a recursive procedure on an input of size $n$ that performs exactly $\\ln n$ primitive operations before making a single recursive call on input size $\\sqrt{n}$, and terminates when the input size reaches $2$. Let $T(n)$ denote the exact number of primitive operations performed by this procedure on input size $n$, including all recursive calls. Assume the cost of the base case is $T(2)$, a fixed constant, and that $\\ln$ denotes the natural logarithm. To avoid rounding issues from the square-root recursion, assume the input size is restricted to the set $\\{2^{2^{k}} : k \\in \\mathbb{N}, k \\geq 0\\}$ so that every recursive call exactly lands on an integer until the base case $2$ is reached.\n\nStarting from the fundamental definition of recursion as repeated self-reduction and the exact counting of operations per invocation, derive a closed-form expression for $T(n)$ as a function of $n$ and $T(2)$ under the stated assumptions. Your answer must be an exact analytic expression, not an asymptotic form, and should be expressed using the natural logarithm.",
            "solution": "The problem statement has been analyzed and is determined to be valid. It is a well-posed problem in the analysis of algorithms, free of scientific or logical inconsistencies. The provided assumptions, particularly the domain restriction for the input size $n$, ensure that the recurrence relation can be solved exactly without ambiguity.\n\nThe problem describes a recursive procedure. Let $T(n)$ be the total number of primitive operations for an input of size $n$. The procedure performs $\\ln n$ operations and then makes a recursive call on an input of size $\\sqrt{n}$. The total cost $T(n)$ is therefore the sum of the cost at the current step and the cost of the recursive subproblem. This can be expressed as the following recurrence relation:\n$$T(n) = \\ln(n) + T(\\sqrt{n})$$\nThe recursion terminates when the input size reaches $2$, at which point the cost is a constant, denoted as $T(2)$. This provides the base case for the recurrence relation.\n\nTo find a closed-form expression for $T(n)$, we can use the method of repeated substitution, also known as unrolling or iteration.\n\nStarting with the recurrence for $T(n)$:\n$$T(n) = \\ln(n) + T(n^{1/2})$$\nWe substitute the expression for the recursive term, $T(n^{1/2})$:\n$$T(n^{1/2}) = \\ln(n^{1/2}) + T((n^{1/2})^{1/2}) = \\ln(n^{1/2}) + T(n^{1/4})$$\nSubstituting this back into the equation for $T(n)$:\n$$T(n) = \\ln(n) + \\ln(n^{1/2}) + T(n^{1/4})$$\nUsing the logarithm property $\\ln(x^y) = y \\ln(x)$, this becomes:\n$$T(n) = \\ln(n) + \\frac{1}{2}\\ln(n) + T(n^{1/4})$$\nWe can repeat this substitution process. The next step yields:\n$$T(n) = \\ln(n) + \\frac{1}{2}\\ln(n) + \\ln(n^{1/4}) + T(n^{1/8})$$\n$$T(n) = \\ln(n) + \\frac{1}{2}\\ln(n) + \\frac{1}{4}\\ln(n) + T(n^{1/8})$$\nA clear pattern emerges. After $m$ steps of unrolling, the expression for $T(n)$ is:\n$$T(n) = \\ln(n) \\left(1 + \\frac{1}{2} + \\frac{1}{4} + \\dots + \\frac{1}{2^{m-1}}\\right) + T(n^{1/2^m})$$\n$$T(n) = \\ln(n) \\sum_{i=0}^{m-1} \\left(\\frac{1}{2}\\right)^i + T(n^{1/2^m})$$\nThe recursion terminates when the input size reaches the base case, $2$. We need to find the number of steps, $m$, for this to occur.\n$$n^{1/2^m} = 2$$\nTo solve for $m$, we take the natural logarithm of both sides:\n$$\\ln(n^{1/2^m}) = \\ln(2)$$\n$$\\frac{1}{2^m} \\ln(n) = \\ln(2)$$\nRearranging for $\\frac{1}{2^m}$ gives:\n$$\\frac{1}{2^m} = \\frac{\\ln(2)}{\\ln(n)}$$\nThe term $T(n^{1/2^m})$ in the unrolled expression becomes $T(2)$.\n\nThe sum in the expression for $T(n)$ is a finite geometric series:\n$$S_m = \\sum_{i=0}^{m-1} \\left(\\frac{1}{2}\\right)^i = \\frac{1 - (1/2)^m}{1 - 1/2}$$\n$$S_m = \\frac{1 - (1/2)^m}{1/2} = 2\\left(1 - \\left(\\frac{1}{2}\\right)^m\\right)$$\nNow we substitute this sum back into the equation for $T(n)$:\n$$T(n) = \\ln(n) \\cdot 2\\left(1 - \\left(\\frac{1}{2}\\right)^m\\right) + T(2)$$\nWe can replace the term $(1/2)^m$ using our previously derived relation $\\frac{1}{2^m} = \\frac{\\ln(2)}{\\ln(n)}$:\n$$T(n) = 2\\ln(n) \\left(1 - \\frac{\\ln(2)}{\\ln(n)}\\right) + T(2)$$\nDistributing the $2\\ln(n)$ term through the parenthesis:\n$$T(n) = 2\\ln(n) \\cdot 1 - 2\\ln(n) \\cdot \\frac{\\ln(2)}{\\ln(n)} + T(2)$$\n$$T(n) = 2\\ln(n) - 2\\ln(2) + T(2)$$\nThis can be written more compactly using the logarithm property $\\ln(a) - \\ln(b) = \\ln(a/b)$:\n$$T(n) = 2(\\ln(n) - \\ln(2)) + T(2) = 2\\ln\\left(\\frac{n}{2}\\right) + T(2)$$\nTo ensure correctness, we can verify this closed-form solution by substituting it back into the original recurrence relation $T(n) = \\ln(n) + T(\\sqrt{n})$:\n$$\n\\begin{align*}\n\\text{Right Hand Side} &= \\ln(n) + T(\\sqrt{n}) \\\\\n&= \\ln(n) + \\left(2\\ln(\\sqrt{n}) - 2\\ln(2) + T(2)\\right) \\\\\n&= \\ln(n) + \\left(2\\ln(n^{1/2}) - 2\\ln(2) + T(2)\\right) \\\\\n&= \\ln(n) + \\left(2 \\cdot \\frac{1}{2}\\ln(n) - 2\\ln(2) + T(2)\\right) \\\\\n&= \\ln(n) + \\ln(n) - 2\\ln(2) + T(2) \\\\\n&= 2\\ln(n) - 2\\ln(2) + T(2)\n\\end{align*}\n$$\nThis result matches our derived expression for $T(n)$, confirming the solution is correct. The base case check $T(2) = 2\\ln(2) - 2\\ln(2) + T(2) = T(2)$ also holds. The assumption that $n$ is in the set $\\{2^{2^{k}} : k \\in \\mathbb{N}, k \\geq 0\\}$ guarantees that the argument to $T$ is always an integer power of $2$ when a square root is taken, until it reaches $2$.\nFor example, if $n=2^{2^k}$, then $\\sqrt{n}=2^{2^{k-1}}$, and so on, reaching $2^{2^0}=2$ after $k$ steps. This validates the structure of our derivation.\n\nThe final closed-form expression for $T(n)$ is a function of $n$ and the constant $T(2)$.",
            "answer": "$$\\boxed{2\\ln(n) - 2\\ln(2) + T(2)}$$"
        },
        {
            "introduction": "A recursive algorithm is a defined process for exploring a problem's state space, and subtle changes to its rules can have dramatic effects. This thought experiment challenges you to analyze a maze-solving algorithm constrained to make only left turns at intersections. By predicting its properties like termination and completeness, you will develop a more profound intuition for how the logic of recursion dictates algorithmic behavior. ",
            "id": "3264661",
            "problem": "Consider a finite maze modeled as a planar undirected graph $G = (V, E)$ embedded in the square grid, with a distinguished start vertex $s \\in V$ and a goal vertex $t \\in V$. A standard recursive Depth-First Search (DFS) explores neighbors of a vertex in some order and uses a visited set to prevent revisiting vertices, guaranteeing termination on finite graphs and completeness on connected graphs. Now consider the following modification that constrains the recursion by an orientation rule.\n\nEach corridor in the embedded maze is aligned with one of $4$ compass directions, and each recursive call carries a heading $h \\in H$, where $H = \\{\\text{North}, \\text{East}, \\text{South}, \\text{West}\\}$ denotes the compass directions. For a call at state $(u, h)$, define the set of admissible non-backtracking neighbors $S(u, h)$ as the neighbors of $u$ that are not the vertex from which the recursion just arrived via heading $h$. The algorithm distinguishes between corridor continuation and intersection:\n- If $|S(u, h)| = 1$ (corridor continuation), the unique neighbor in $S(u, h)$ is considered admissible even if it corresponds to going straight with respect to $h$.\n- If $|S(u, h)| \\geq 2$ (intersection), the algorithm is only allowed to recurse into neighbors in $S(u, h)$ that correspond to a left turn relative to $h$; neighbors that require straight or right turns at the intersection are forbidden.\nIf no admissible neighbor exists under the above rule, the recursion backtracks. The visited set is defined over ordered pairs $(u, h)$ to prevent revisiting the same state. The base case is success when $u = t$ and failure when no admissible recursive call is possible from $(u, h)$.\n\nSelect all statements that are correct about this modified recursive algorithm and its logical consequences.\n\nA. On any finite maze, if the visited set is defined over ordered pairs $(u, h)$, the recursion must terminate because the number of distinct states is finite and the recursion never revisits a state.\n\nB. Even on a maze that is a tree (acyclic graph), the algorithm may fail to reach a reachable goal because at an intersection it may be forced to turn left into a dead end when the unique path to the goal requires a right turn.\n\nC. The time complexity of the algorithm, measured in the number of recursive calls, is $\\Theta(|V|)$ on any finite maze because only one recursive call is made per vertex.\n\nD. The algorithm is complete on any simply connected planar maze when the goal lies on the boundary because repeatedly turning left implements the left-hand wall follower and guarantees reaching an exit.\n\nE. The modified recursion behaves like a deterministic walk that prefers turning left at intersections and continues straight in corridors; therefore, it can be modeled as a function from states to at most one successor, and the reachable set is exactly the forward orbit of the start state under this function.",
            "solution": "The user wants a critical validation of the provided problem statement, followed by a rigorous derivation of the solution if the statement is valid.\n\n### Problem Validation\n\nFirst, I will extract the givens from the problem statement and then validate its scientific and logical integrity.\n\n#### Step 1: Extract Givens\n\n-   **Graph Model**: A finite maze is modeled as a planar undirected graph $G = (V, E)$ embedded in a square grid.\n-   **Terminals**: There is a start vertex $s \\in V$ and a goal vertex $t \\in V$.\n-   **Algorithm State**: The algorithm state is an ordered pair $(u, h)$, where $u \\in V$ is the current vertex and $h \\in H$ is the heading of arrival. $H = \\{\\text{North, East, South, West}\\}$.\n-   **Admissible Neighbors ($S(u,h)$)**: For a state $(u, h)$, $S(u, h)$ is the set of neighbors of $u$ excluding the vertex from which the algorithm arrived at $u$.\n-   **Move Rules**:\n    1.  **Corridor Continuation**: If $|S(u, h)| = 1$, the unique neighbor in $S(u, h)$ is admissible.\n    2.  **Intersection**: If $|S(u, h)| \\geq 2$, only neighbors in $S(u, h)$ corresponding to a left turn relative to heading $h$ are admissible. Neighbors requiring straight or right turns are forbidden.\n-   **Backtracking**: If no admissible neighbor exists, the recursion backtracks.\n-   **Termination/Cycle Prevention**: A visited set is maintained for states $(u, h)$ to prevent re-visiting any state.\n-   **Base Cases**: The recursion succeeds if $u=t$ and fails (for a path) if no admissible recursive call can be made from $(u, h)$.\n\n#### Step 2: Validate Using Extracted Givens\n\n-   **Scientific Groundedness**: The problem is grounded in the well-established fields of graph theory and algorithm design. The concepts used (graphs, DFS, state space) are standard in computer science. The rules, while specific, are mathematically and logically precise. The problem is scientifically sound.\n-   **Well-Posedness**: The rules for the algorithm are deterministic. For any given state $(u, h)$, the set of possible next states is uniquely determined. The problem asks for logical consequences of these rules, which is a well-posed task. While the initial heading from $s$ is not specified, the properties in question (termination, completeness, complexity) can be analyzed for any given starting condition.\n-   **Objectivity**: The problem is stated in precise, objective language. Terms like \"left turn\" are unambiguous in the context of a square grid embedding (e.g., a left turn from a 'North' heading is 'West').\n-   **Completeness and Consistency**: The problem provides all necessary rules to define the algorithm's behavior. There are no contradictions in the rules.\n-   **Other Flaws**: The problem is not unrealistic (it's a theoretical construct), ill-posed, trivial, or unverifiable. It presents a non-trivial variant of a standard algorithm, requiring careful analysis.\n\n#### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is self-contained, logically consistent, and grounded in established computer science principles. I will now proceed with the solution by analyzing each option.\n\n### Solution Derivation\n\nThe modified recursive algorithm explores a state graph where the nodes are the pairs $(u, h)$. The crucial feature of this algorithm is its deterministic nature: from any state, there is at most one admissible move.\n\n#### Analysis of Option A\n\n**Statement A:** On any finite maze, if the visited set is defined over ordered pairs $(u, h)$, the recursion must terminate because the number of distinct states is finite and the recursion never revisits a state.\n\n-   The state of the recursion is given by the pair $(u, h)$, where $u$ is a vertex in $V$ and $h$ is a heading from the set $H$.\n-   The graph $G=(V,E)$ is finite, so the number of vertices $|V|$ is a finite integer.\n-   The set of headings $H$ has a fixed, finite size of $|H|=4$.\n-   The total number of possible states is the size of the Cartesian product $V \\times H$, which is $|V| \\times |H| = 4|V|$. This is a finite number.\n-   The problem explicitly states that the algorithm uses a visited set on the states $(u, h)$ to prevent revisiting them.\n-   A search algorithm that explores a finite state space and never visits the same state more than once is guaranteed to terminate. The number of recursive calls is bounded by the size of the state space, $4|V|$.\n-   Therefore, the statement is a correct application of a fundamental termination argument for search algorithms.\n\n**Verdict on A:** **Correct**.\n\n#### Analysis of Option B\n\n**Statement B:** Even on a maze that is a tree (acyclic graph), the algorithm may fail to reach a reachable goal because at an intersection it may be forced to turn left into a dead end when the unique path to the goal requires a right turn.\n\n-   Let's construct a counterexample. A tree is an acyclic graph. Consider a T-junction at vertex $u$. Let the start vertex $s$ be to the south of $u$, the goal vertex $t$ be to the east of $u$, and a dead-end path be to the west of $u$. In a tree, the paths from $u$ to $t$ and to the dead end are distinct branches.\n-   The algorithm starts at $s$ and moves towards $u$. Assuming the path from $s$ is aligned vertically, the state upon reaching $u$ is $(u, \\text{North})$.\n-   The neighbors of $u$ are the preceding vertex (south), the vertex on the dead-end path (west), and the vertex on the path to the goal (east). Let's call them $v_S, v_W, v_E$ respectively.\n-   The set of non-backtracking neighbors is $S(u, \\text{North}) = \\{v_W, v_E\\}$.\n-   Since $|S(u, \\text{North})| = 2$, vertex $u$ is treated as an intersection.\n-   The rule for intersections mandates taking a left turn relative to the heading $h=\\text{North}$. A left turn from North is West. Thus, the only admissible move is to $v_W$. The path towards $t$ via $v_E$ requires a right turn and is forbidden.\n-   The algorithm will recursively explore the branch starting with $v_W$, hit the dead end, and backtrack to $u$. Upon returning to the call for state $(u, \\text{North})$, there are no other admissible moves to try (left was the only option). The recursion will backtrack further, having never explored the path to the east.\n-   Since the unique path to the reachable goal $t$ was to the right, the algorithm fails.\n\n**Verdict on B:** **Correct**.\n\n#### Analysis of Option C\n\n**Statement C:** The time complexity of the algorithm, measured in the number of recursive calls, is $\\Theta(|V|)$ on any finite maze because only one recursive call is made per vertex.\n\n-   Let's first evaluate the justification: \"only one recursive call is made per vertex\". This is false. The visited set is on states $(u, h)$, not on vertices $u$. A vertex $u$ can be entered via different headings, leading to distinct states like $(u, \\text{North})$, $(u, \\text{East})$, etc. For a vertex with degree $4$, it is possible to visit it four times, once for each arrival heading.\n-   Now let's evaluate the complexity claim: $\\Theta(|V|)$. The total number of states is $4|V|$. The algorithm visits each state at most once. Thus, the number of recursive calls is bounded above by $4|V|$, which implies the time complexity is $O(|V|)$.\n-   For a complexity to be $\\Theta(|V|)$, it must also be $\\Omega(|V|)$. This means the number of calls must be bounded below by $c|V|$ for some constant $c>0$. This is not true for *any* finite maze.\n-   Consider a maze where the start vertex $s$ is at an intersection. Suppose the initial move is a left turn that leads into a very small portion of the maze (e.g., a dead-end corridor of length $2$). The algorithm will explore this small section, backtrack, and terminate, as no other moves from the start were admissible. The vast majority of the maze's $|V|$ vertices might remain unvisited. The number of recursive calls would be a small constant, which is not proportional to $|V|$.\n-   Since the complexity is $O(|V|)$ but not $\\Omega(|V|)$ in general, it cannot be $\\Theta(|V|)$.\n\n**Verdict on C:** **Incorrect**.\n\n#### Analysis of Option D\n\n**Statement D:** The algorithm is complete on any simply connected planar maze when the goal lies on the boundary because repeatedly turning left implements the left-hand wall follower and guarantees reaching an exit.\n\n-   A simply connected maze is one without \"islands\" of walls; all walls are connected to the outer boundary. The left-hand wall-following algorithm (or Pledge algorithm) is known to be complete for such mazes. This algorithm follows a preference order: if possible, turn left; otherwise, go straight; otherwise, turn right.\n-   The statement claims that the given algorithm implements this wall-follower. This claim is false. The given algorithm's rule at an intersection ($|S(u,h)| \\geq 2$) is to *only* allow a left turn. If a left turn is not possible, or if the path continues straight or right, the algorithm does not consider these options; it backtracks. The wall-follower, by contrast, would explore these other options.\n-   The counterexample from the analysis of Option B is a tree, which is a simply connected graph. In that example, the algorithm was forced to turn left into a dead end and missed the goal, which was to the right. This demonstrates that the algorithm is incomplete even on this class of mazes. Its rigid \"left-turn-only\" rule at intersections is fundamentally different and less powerful than the \"left-first\" strategy of a true wall-follower.\n\n**Verdict on D:** **Incorrect**.\n\n#### Analysis of Option E\n\n**Statement E:** The modified recursion behaves like a deterministic walk that prefers turning left at intersections and continues straight in corridors; therefore, it can be modeled as a function from states to at most one successor, and the reachable set is exactly the forward orbit of the start state under this function.\n\n-   Let's analyze the algorithm's behavior at any state $(u, h)$.\n    -   If it is a corridor continuation ($|S(u, h)|=1$), there is exactly one choice.\n    -   If it is a dead end ($|S(u, h)|=0$), there are no choices.\n    -   If it is an intersection ($|S(u, h)| \\geq 2$), the rule permits only a left turn. In a square grid, there can be at most one neighbor in the \"left\" direction. So, there is at most one choice.\n-   In every possible case, for a given state $(u, h)$, there is at most one admissible successor state. This means the algorithm's progression from one state to the next is deterministic. This can be perfectly modeled by a transition function $f: V \\times H \\to (V \\times H) \\cup \\{\\text{null}\\}$, which maps a state to its unique successor, or to a null/backtrack symbol if no successor exists.\n-   The \"forward orbit\" of a start state $s_0$ under such a function is the sequence of states $s_0, f(s_0), f(f(s_0)), \\dots$ generated by repeatedly applying the function. This sequence defines a single, deterministic path through the state space.\n-   The recursive algorithm, with its visited set, traces this exact path. It starts at $s_0$ and calls itself on $s_1=f(s_0)$, then on $s_2=f(s_1)$, and so on. When the path ends (either by hitting a null successor or by reaching an already visited state), the recursion unwinds (backtracks). Critically, because there was never more than one option at any state, the backtracking process does not explore any new states.\n-   Thus, the set of all states entered by the recursion (the \"reachable set\" from the starting state) is precisely the set of unique states in this single forward path or orbit. The statement provides a formal and accurate description of the algorithm's dynamics.\n\n**Verdict on E:** **Correct**.\n\n### Summary of Correct Statements\n-   A is correct.\n-   B is correct.\n-   C is incorrect.\n-   D is incorrect.\n-   E is correct.\n\nThe correct options are A, B, and E.",
            "answer": "$$\\boxed{ABE}$$"
        },
        {
            "introduction": "Recursion provides an elegant way to solve complex counting problems by breaking them down based on their structure. This practice challenges you to design a recursive algorithm that counts all valid sequences of nested brackets of multiple types. By deriving the underlying recurrence relation and using memoization, you will apply core recursive principles to a sophisticated combinatorial problem. ",
            "id": "3264821",
            "problem": "You are to design and implement a recursive generator for well-formed bracket sequences with multiple bracket types, from first principles in data structures and algorithms. The alphabet of tokens contains three bracket types: parentheses, square brackets, and a composite type that uses a paired two-character opening token and a paired two-character closing token. Concretely, the three types use the token pairs: `()` (parentheses), `[]` (square brackets), and `{( )}` (a composite type with opening token `{( ` and closing token ` )}`).\n\nA string over these tokens is well-formed if and only if it belongs to the generalization of the Dyck language defined inductively as follows:\n- Base: the empty string $\\epsilon$ is well-formed.\n- Enclosure: if $w$ is well-formed, then `(w)` is well-formed, `[w]` is well-formed, and `{(w)}` is well-formed.\n- Concatenation: if $u$ and $v$ are well-formed, then $uv$ is well-formed.\n\nYou must implement a recursive algorithm that, given nonnegative integers $a$, $b$, and $c$, generates all well-formed strings that use exactly $a$ pairs of `()`, exactly $b$ pairs of `[]`, and exactly $c$ pairs of `{( )}`. The algorithm must ensure correct nesting: closing tokens must match the most recently opened unmatched token of the same type. The design must start from foundational definitions and reason from first principles about recursion and state invariants, with precise justification of correctness.\n\nYour program must compute, for each test case, the integer count of distinct valid strings that satisfy the given $(a,b,c)$ and output the counts aggregated in a single line. There are no physical units, angles, or percentages in this problem.\n\nImplement the solution as a complete, runnable program. The final output format must be a single line containing the results as a comma-separated list enclosed in square brackets, for example, $\\mathtt{[r_1,r_2,\\dots,r_k]}$ where each $r_i$ is an integer count for the corresponding test case.\n\nTest suite:\n- Case 1: $(a,b,c) = (1,1,0)$, one `()` pair and one `[]` pair.\n- Case 2: $(a,b,c) = (0,0,1)$, one composite `{( )}` pair only.\n- Case 3: $(a,b,c) = (1,0,1)$, one `()` pair and one composite pair.\n- Case 4: $(a,b,c) = (0,2,0)$, two `[]` pairs only.\n- Case 5: $(a,b,c) = (0,0,0)$, zero pairs of any type (the empty string).\n- Case 6: $(a,b,c) = (1,1,1)$, one of each type.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\mathtt{[result1,result2,result3,result4,result5,result6]}$).",
            "solution": "This is a combinatorial counting problem that can be solved by deriving a recurrence relation and implementing it using memoized recursion (a form of dynamic programming). The set of well-formed strings is a generalization of the language of Dyck paths.\n\nLet $N(a, b, c)$ be the number of distinct well-formed strings containing exactly $a$ pairs of `()`, $b$ pairs of `[]`, and $c$ pairs of `{( )}`.\n\n**Base Case:**\nThe simplest well-formed string is the empty string, which has zero pairs of any type. Therefore, the base case for our recursion is:\n$$N(0, 0, 0) = 1$$\nIf any of $a, b, c$ are negative, the state is invalid, so $N(a, b, c) = 0$.\n\n**Recursive Step:**\nAny non-empty well-formed string $S$ can be uniquely decomposed into two parts: $S = S_p S_s$, where $S_p$ is a *prime* well-formed prefix and $S_s$ is the remaining (possibly empty) well-formed suffix. A prime well-formed string is one that cannot be decomposed into two non-empty well-formed strings. By the \"Enclosure\" rule, a prime string must have the form `(w)`, `[w]`, or `{(w)}`, where `w` is any well-formed string.\n\nWe can construct the recurrence for $N(a, b, c)$ by considering the first prime component, $S_p$, of any string counted by $N(a,b,c)$:\n\n1.  **Case 1: $S_p = (w)$**. The outermost pair is `()`. This uses one of the $a$ available `()` pairs. The remaining $a-1$ pairs of `()`, $b$ pairs of `[]`, and $c$ pairs of `{( )}` must be distributed between the inner string `w` and the suffix string $S_s$.\n    Let `w` have $(a_1, b_1, c_1)$ pairs and $S_s$ have $(a_2, b_2, c_2)$ pairs. Then we must have:\n    $a_1 + a_2 = a-1$\n    $b_1 + b_2 = b$\n    $c_1 + c_2 = c$\n    The total number of ways to form such strings is the sum over all possible non-negative integer partitions: $\\sum_{a_1+a_2=a-1} \\sum_{b_1+b_2=b} \\sum_{c_1+c_2=c} N(a_1, b_1, c_1) \\cdot N(a_2, b_2, c_2)$.\n\n2.  **Case 2: $S_p = [w]$**. Similarly, the outermost pair is `[]`, which uses one of the $b$ available pairs. The remaining pairs $(a, b-1, c)$ must be distributed between `w` and $S_s$.\n    The contribution from this case is: $\\sum_{a_1+a_2=a} \\sum_{b_1+b_2=b-1} \\sum_{c_1+c_2=c} N(a_1, b_1, c_1) \\cdot N(a_2, b_2, c_2)$.\n\n3.  **Case 3: $S_p = \\{(w)\\}$**. The outermost pair is `{( )}`, which uses one of the $c$ available pairs. The remaining pairs $(a, b, c-1)$ must be distributed between `w` and $S_s$.\n    The contribution from this case is: $\\sum_{a_1+a_2=a} \\sum_{b_1+b_2=b} \\sum_{c_1+c_2=c-1} N(a_1, b_1, c_1) \\cdot N(a_2, b_2, c_2)$.\n\nThe total count $N(a, b, c)$ is the sum of these three mutually exclusive cases. We can define a convolution operator to simplify the notation:\n$$C(A, B, C) = \\sum_{a_1=0}^{A} \\sum_{b_1=0}^{B} \\sum_{c_1=0}^{C} N(a_1, b_1, c_1) \\cdot N(A-a_1, B-b_1, C-c_1)$$\n\nThe complete recurrence relation is:\n$$N(a,b,c) = C(a-1,b,c) + C(a,b-1,c) + C(a,b,c-1)$$\nThis recurrence holds for any $(a, b, c) \\neq (0, 0, 0)$.\n\n**Implementation:**\nThis recurrence has overlapping subproblems (e.g., $N(1,0,0)$ is needed to compute many other states), making it suitable for a top-down recursive solution with memoization. We use a dictionary or hash map to store the results of $N(a, b, c)$ once computed. When the function is called for a state $(a, b, c)$, it first checks the memoization table. If the value is present, it is returned immediately. Otherwise, the value is computed using the recurrence, stored in the table, and then returned. This approach ensures that each subproblem is solved only once, drastically improving efficiency over a naive recursive implementation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of counting well-formed bracket sequences\n    for multiple test cases.\n    \"\"\"\n\n    class BracketCounter:\n        \"\"\"\n        A class to compute the number of well-formed bracket sequences\n        using dynamic programming with memoization.\n        \"\"\"\n        def __init__(self):\n            # The memoization table stores results for N(a, b, c).\n            # The base case N(0,0,0) = 1 is pre-filled.\n            self.memo = {(0, 0, 0): 1}\n\n        def count_sequences(self, a, b, c):\n            \"\"\"\n            Computes N(a, b, c), the number of well-formed strings with:\n            - a pairs of ()\n            - b pairs of []\n            - c pairs of {()}\n            \n            This function uses a top-down recursive approach with memoization.\n            \"\"\"\n            \n            # The state is defined by the tuple of counts (a, b, c).\n            state = (a, b, c)\n\n            # Return 0 if any count is negative, as this is an invalid state.\n            if a  0 or b  0 or c  0:\n                return 0\n\n            # If the result for this state is already computed, return it.\n            if state in self.memo:\n                return self.memo[state]\n\n            # The recurrence relation is derived from the decomposition of a\n            # non-empty sequence S into a prime prefix Sp and a suffix Sr (S = SpSr).\n            # The prime prefix must be of the form (w), [w], or {(w)}.\n            # We sum the contributions from these three cases.\n            \n            # Case 1: Sp = (w), Sr = v. The a-1, b, c pairs are partitioned\n            # between w and v. This is calculated by the convolution C(a-1, b, c).\n            term1 = self._convolution(a - 1, b, c)\n            \n            # Case 2: Sp = [w], Sr = v. The a, b-1, c pairs are partitioned.\n            # This is calculated by the convolution C(a, b-1, c).\n            term2 = self._convolution(a, b - 1, c)\n\n            # Case 3: Sp = {(w)}, Sr = v. The a, b, c-1 pairs are partitioned.\n            # This is calculated by the convolution C(a, b, c-1).\n            term3 = self._convolution(a, b, c - 1)\n            \n            # The total count is the sum of the three cases.\n            total = term1 + term2 + term3\n            \n            # Store the computed result in the memoization table before returning.\n            self.memo[state] = total\n            return total\n\n        def _convolution(self, A, B, C):\n            \"\"\"\n            Computes the convolution C(A, B, C), which represents summing\n            N(a1,b1,c1) * N(a2,b2,c2) over all partitions of (A,B,C).\n            \n            C(A,B,C) = sum_{a1+a2=A, b1+b2=B, c1+c2=C} N(a1,b1,c1) * N(a2,b2,c2)\n            \n            This is used to combine the counts for the inner sequence (w) and\n            the trailing sequence (v).\n            \"\"\"\n            \n            # If any target count is negative, the convolution is 0.\n            if A  0 or B  0 or C  0:\n                return 0\n\n            conv_sum = 0\n            # Iterate over all possible partitions for 'a' pairs.\n            for a1 in range(A + 1):\n                a2 = A - a1\n                # Iterate over all possible partitions for 'b' pairs.\n                for b1 in range(B + 1):\n                    b2 = B - b1\n                    # Iterate over all possible partitions for 'c' pairs.\n                    for c1 in range(C + 1):\n                        c2 = C - c1\n                        \n                        # Recursively call count_sequences for the two subproblems.\n                        # The results will be retrieved from memoization if available.\n                        term_w = self.count_sequences(a1, b1, c1)\n                        term_v = self.count_sequences(a2, b2, c2)\n                        \n                        conv_sum += term_w * term_v\n            \n            return conv_sum\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 1, 0),\n        (0, 0, 1),\n        (1, 0, 1),\n        (0, 2, 0),\n        (0, 0, 0),\n        (1, 1, 1),\n    ]\n\n    results = []\n    for a, b, c in test_cases:\n        # For each test case, instantiate a new counter to ensure\n        # a fresh memoization table.\n        counter = BracketCounter()\n        result = counter.count_sequences(a, b, c)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}