{
    "hands_on_practices": [
        {
            "introduction": "Our exploration of memory allocation begins with the most fundamental question: when a program requests a block of memory, how does the allocator choose which free space to use? This exercise introduces two classic heuristics, first-fit and best-fit, which represent a primary trade-off between allocation speed and memory utilization. By simulating these strategies and quantifying their performance through metrics like allocation success and internal fragmentation, you will gain a hands-on understanding of the core challenges in dynamic memory management .",
            "id": "3251611",
            "problem": "Consider a finite set of shelves represented by a sequence of nonnegative integer capacities $S = (s_1, s_2, \\dots, s_n)$ and a sequence of pallets represented by nonnegative integer sizes $P = (p_1, p_2, \\dots, p_m)$. Each shelf can hold at most one pallet. A pallet of size $p_j$ can be placed into a shelf of capacity $s_i$ if and only if $s_i \\ge p_j$. Once a pallet is placed into a shelf, that shelf becomes unavailable for any other pallet. The internal fragmentation incurred by placing a pallet $p_j$ into shelf $s_i$ is defined as $s_i - p_j$. The allocation fails for pallet $p_j$ if there is no available shelf with capacity at least $p_j$.\n\nTwo allocation strategies are to be compared:\n\n- First-fit: For each pallet $p_j$ in order $j = 1, 2, \\dots, m$, scan shelves in increasing index order $i = 1, 2, \\dots, n$ and place $p_j$ into the first available shelf with $s_i \\ge p_j$.\n- Best-fit: For each pallet $p_j$ in order $j = 1, 2, \\dots, m$, among all available shelves with $s_i \\ge p_j$, choose the shelf whose capacity $s_i$ is minimal; in case of a tie, choose the shelf with the smallest index.\n\nStarting from the core definitions of sequence processing and deterministic selection rules, and without assuming any pre-existing specialized formula, derive a programmatic simulation that, for each given test case, executes both strategies on the same inputs $(S, P)$ and reports the following integer metrics for each strategy:\n- The number of pallets successfully allocated, denoted $A$.\n- The number of allocation failures, denoted $F$.\n- The total internal fragmentation, denoted $W$, computed as $\\sum (s_i - p_j)$ over all allocated pairs under the strategy.\n\nYour program must implement both strategies exactly as defined, with the tie-breaking rule in best-fit selecting the smallest index when minimal capacities are equal. The final output must be a single line containing a comma-separated list enclosed in square brackets. For each test case, append the six integers in the order $[A_{\\text{FF}}, F_{\\text{FF}}, W_{\\text{FF}}, A_{\\text{BF}}, F_{\\text{BF}}, W_{\\text{BF}}]$, where the subscripts $\\text{FF}$ and $\\text{BF}$ denote first-fit and best-fit respectively. Concatenate the results across all test cases into one flat list, preserving test case order.\n\nUse the following test suite, designed to probe different aspects of allocation behavior:\n- Test case $1$: $S = [9,8,10]$, $P = [8,10,9]$ (difference between strategies due to shelf order and tie-breaking).\n- Test case $2$: $S = [5,5,5]$, $P = [5,5,5,5]$ (boundary with exact fits and more pallets than shelves).\n- Test case $3$: $S = [4,4]$, $P = [5,6]$ (all pallets too large).\n- Test case $4$: $S = [12,3]$, $P = []$ (empty pallet sequence).\n- Test case $5$: $S = [5,9,6]$, $P = [6,5,9]$ (difference between strategies due to future exact matches).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with integers in the precise order specified and no additional text.",
            "solution": "The problem statement has been validated and is deemed sound. It presents a well-defined simulation task rooted in fundamental concepts of computer science, specifically deterministic resource allocation algorithms. The problem is self-contained, logically consistent, and free of ambiguity.\n\nThe core of this problem is the simulation of two distinct memory allocation strategies, first-fit and best-fit, applied to a discrete set of resources (shelves) and requests (pallets). We will formally derive the steps for each simulation and then implement them to calculate the required performance metrics.\n\nLet the set of shelf capacities be represented by a sequence $S = (s_1, s_2, \\dots, s_n)$, where $n$ is the number of shelves and $s_i \\in \\mathbb{Z}_{\\ge 0}$ is the capacity of the $i$-th shelf. Let the set of pallet sizes be a sequence $P = (p_1, p_2, \\dots, p_m)$, where $m$ is the number of pallets and $p_j \\in \\mathbb{Z}_{\\ge 0}$ is the size of the $j$-th pallet.\n\nThe state of the system can be tracked by a boolean availability vector $U = (u_1, u_2, \\dots, u_n)$, where $u_i = 1$ if shelf $i$ is available and $u_i = 0$ if it is occupied. Initially, all shelves are available, so $u_i = 1$ for all $i \\in \\{1, 2, \\dots, n\\}$.\n\nFor each strategy, we will process the pallets in their given order, from $j=1$ to $m$. The metrics to be computed for each strategy are:\n- $A$: The total number of successfully allocated pallets.\n- $F$: The total number of allocation failures.\n- $W$: The total internal fragmentation, defined as the sum $W = \\sum (s_{i^*} - p_j)$ over all allocated pairs $(p_j, s_{i^*})$.\n\n**1. First-Fit (FF) Strategy**\n\nThe first-fit algorithm is a sequential search heuristic. For each pallet $p_j$, we scan the shelves from the first to the last and place the pallet in the first shelf that is large enough.\n\nThe algorithm proceeds as follows for each $j \\in \\{1, 2, \\dots, m\\}$:\n- Initialize a flag, `placed_j = false`.\n- Iterate through the shelves with index $i$ from $1$ to $n$.\n- At each shelf $i$, check for two conditions:\n    1. The shelf is available: $u_i = 1$.\n    2. The shelf has sufficient capacity: $s_i \\ge p_j$.\n- If both conditions are met, this is the first fit. We perform the allocation:\n    - Designate this shelf as the chosen one: $i^* = i$.\n    - Update the system state by marking the shelf as occupied: $u_{i^*} \\leftarrow 0$.\n    - Increment the allocated pallet count: $A \\leftarrow A + 1$.\n    - Add the resulting internal fragmentation to the total: $W \\leftarrow W + (s_{i^*} - p_j)$.\n    - Set `placed_j = true` and break the inner loop over $i$, proceeding to the next pallet $p_{j+1}$.\n- If the loop over all shelves $i$ completes and `placed_j` remains `false`, it signifies that no suitable shelf was found. The allocation for pallet $p_j$ fails.\n- Increment the failure count: $F \\leftarrow F + 1$.\n\nThis process is repeated for all pallets. The initial state for the simulation is $A=0$, $F=0$, $W=0$, and $u_i=1$ for all $i$.\n\n**2. Best-Fit (BF) Strategy**\n\nThe best-fit algorithm attempts to be more efficient in its use of space. For each pallet $p_j$, it searches all available shelves to find the one that fits the pallet most snugly, i.e., the one with the smallest capacity that is still large enough. This strategy aims to leave larger-capacity shelves available for potentially larger future pallets.\n\nThe algorithm proceeds as follows for each $j \\in \\{1, 2, \\dots, m\\}$:\n- Identify the set of all candidate shelves, $C_j$, that are both available and have sufficient capacity:\n$$ C_j = \\{ i \\in \\{1, \\dots, n\\} \\mid u_i = 1 \\land s_i \\geq p_j \\} $$\n- If this set $C_j$ is empty, no allocation is possible for pallet $p_j$.\n    - Increment the failure count: $F \\leftarrow F + 1$.\n- If $C_j$ is non-empty, a best-fit shelf must be chosen.\n    - First, find the minimum capacity among all candidate shelves:\n    $$ s_{\\min} = \\min_{i \\in C_j} \\{s_i\\} $$\n    - Next, identify the subset of candidates that have this minimum capacity, $B_j \\subseteq C_j$:\n    $$ B_j = \\{ i \\in C_j \\mid s_i = s_{\\min} \\} $$\n    - The problem provides a tie-breaking rule: if multiple shelves have the same minimal capacity $s_{\\min}$, the one with the smallest index is chosen.\n    $$ i^* = \\min_{i \\in B_j} \\{i\\} $$\n    - The pallet $p_j$ is allocated to shelf $s_{i^*}$.\n    - Update the system state: $u_{i^*} \\leftarrow 0$.\n    - Increment the allocated pallet count: $A \\leftarrow A + 1$.\n    - Add the fragmentation to the total: $W \\leftarrow W + (s_{i^*} - p_j)$.\n\nThis process is repeated for all pallets, starting from the same initial state ($A=0, F=0, W=0, u_i=1$) as the first-fit simulation.\n\n**Implementation Design**\n\nA programmatic solution will consist of two distinct functions, one for each strategy. Each function will take the shelf capacities $S$ and pallet sizes $P$ as input. Inside each function, an availability array corresponding to $U$ will be initialized. The function will then loop through the pallets, applying the respective logic to find a shelf or declare a failure, and update the metrics $A$, $F$, and $W$. Finally, the function will return these three metrics. The main program will execute these two functions for each test case and format the results as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef first_fit_strategy(shelves, pallets):\n    \"\"\"\n    Simulates the first-fit allocation strategy.\n\n    Args:\n        shelves (list): A list of nonnegative integer shelf capacities.\n        pallets (list): A list of nonnegative integer pallet sizes.\n\n    Returns:\n        tuple: A tuple containing (A, F, W) where A is the number of\n               allocations, F is the number of failures, and W is the\n               total internal fragmentation.\n    \"\"\"\n    num_shelves = len(shelves)\n    available_shelves = np.ones(num_shelves, dtype=bool)\n    \n    allocated_count = 0\n    failed_count = 0\n    total_fragmentation = 0\n\n    for pallet_size in pallets:\n        pallet_placed = False\n        for i in range(num_shelves):\n            if available_shelves[i] and shelves[i] >= pallet_size:\n                # Place the pallet in the first available-and-fitting shelf\n                available_shelves[i] = False\n                allocated_count += 1\n                total_fragmentation += shelves[i] - pallet_size\n                pallet_placed = True\n                break  # Move to the next pallet\n        \n        if not pallet_placed:\n            failed_count += 1\n            \n    return allocated_count, failed_count, total_fragmentation\n\ndef best_fit_strategy(shelves, pallets):\n    \"\"\"\n    Simulates the best-fit allocation strategy.\n\n    Args:\n        shelves (list): A list of nonnegative integer shelf capacities.\n        pallets (list): A list of nonnegative integer pallet sizes.\n\n    Returns:\n        tuple: A tuple containing (A, F, W) where A is the number of\n               allocations, F is the number of failures, and W is the\n               total internal fragmentation.\n    \"\"\"\n    num_shelves = len(shelves)\n    available_shelves = np.ones(num_shelves, dtype=bool)\n\n    allocated_count = 0\n    failed_count = 0\n    total_fragmentation = 0\n\n    for pallet_size in pallets:\n        best_shelf_index = -1\n        # Using a large number for initial minimum capacity\n        min_capacity = float('inf')\n\n        for i in range(num_shelves):\n            if available_shelves[i] and shelves[i] >= pallet_size:\n                # Found a potential shelf. Check if it's a better fit.\n                if shelves[i] < min_capacity:\n                    min_capacity = shelves[i]\n                    best_shelf_index = i\n        \n        if best_shelf_index != -1:\n            # A best-fit shelf was found, place the pallet\n            available_shelves[best_shelf_index] = False\n            allocated_count += 1\n            total_fragmentation += shelves[best_shelf_index] - pallet_size\n        else:\n            # No suitable shelf found\n            failed_count += 1\n\n    return allocated_count, failed_count, total_fragmentation\n\ndef solve():\n    \"\"\"\n    Runs the allocation simulations for all test cases and prints the results.\n    \"\"\"\n    test_cases = [\n        # Test case 1: S = [9,8,10], P = [8,10,9]\n        ([9, 8, 10], [8, 10, 9]),\n        # Test case 2: S = [5,5,5], P = [5,5,5,5]\n        ([5, 5, 5], [5, 5, 5, 5]),\n        # Test case 3: S = [4,4], P = [5,6]\n        ([4, 4], [5, 6]),\n        # Test case 4: S = [12,3], P = []\n        ([12, 3], []),\n        # Test case 5: S = [5,9,6], P = [6,5,9]\n        ([5, 9, 6], [6, 5, 9]),\n    ]\n\n    all_results = []\n    for s_capacities, p_sizes in test_cases:\n        # Each strategy must run on a fresh set of shelves\n        shelves_copy = list(s_capacities)\n        pallets_copy = list(p_sizes)\n        \n        # Run first-fit\n        ff_results = first_fit_strategy(shelves_copy, pallets_copy)\n        all_results.extend(ff_results)\n        \n        # Run best-fit\n        bf_results = best_fit_strategy(shelves_copy, pallets_copy)\n        all_results.extend(bf_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Over time, a sequence of allocations and deallocations can shatter free memory into many small, unusable piecesâ€”a problem known as external fragmentation. One powerful solution is compaction, which reorganizes the heap by moving live objects together to form a single, large contiguous free block. This practice challenges you to design an optimal, in-place algorithm that performs this compaction while minimizing the total amount of data moved, a critical consideration for performance .",
            "id": "3251644",
            "problem": "You are given a custom heap modeled as a finite linear address space from address $0$ up to address $L$, partitioned into nonoverlapping contiguous segments. Each segment is either a free region or a live allocated block. Each live block is an indivisible contiguous region with a positive integer size, denoted $s_i$, and blocks appear in a fixed left-to-right order. Free regions have positive integer sizes, denoted $f_j$. The sum of all segment sizes equals $L$. All copying costs are measured in units of bytes, and copying a block of size $s_i$ exactly once costs $s_i$ bytes of movement.\n\nTask: Design and implement an in-place defragmentation algorithm that compacts all live blocks to form a single contiguous region starting at address $0$ with no gaps, preserving the original left-to-right order of live blocks, while minimizing the total number of bytes copied. The algorithm must operate without allocating auxiliary arrays proportional to $L$ or the number of blocks. The algorithm should be derived using only core definitions of linear memory layouts and contiguous compaction, and should justify minimality by reasoning from first principles.\n\nFormally, let the live blocks in left-to-right order be $b_1, b_2, \\dots, b_k$ with sizes $s_1, s_2, \\dots, s_k$. After defragmentation, the intended target start address of block $b_i$ is\n$$\nt_i = \\sum_{j=1}^{i-1} s_j,\n$$\nso that blocks occupy $[t_i, t_i + s_i)$ contiguously for $i = 1, 2, \\dots, k$. The total bytes moved is defined as\n$$\nC = \\sum_{i \\in M} s_i,\n$$\nwhere $M$ is the set of indices of blocks that are copied at least once by the algorithm. Your solution must derive an algorithm that achieves the minimal possible $C$ subject to the constraints above, and must analyze its time and space complexity as functions of $L$ and $k$.\n\nInput modeling for the program: Each heap in the test suite is described as a list of segments. A live allocated block is represented as a tuple $\\texttt{(\"A\", id, size)}$ where $\\texttt{id}$ is a unique integer label for readability and $\\texttt{size}$ is a positive integer giving $s_i$. A free region is represented as a tuple $\\texttt{(\"F\", size)}$ where $\\texttt{size}$ is a positive integer giving $f_j$. Segments appear in their actual left-to-right order, and the initial start address of each segment is the running sum of preceding segment sizes starting from address $0$.\n\nYour program must, for each test heap, compute and output two items:\n- The minimal total bytes moved $C$ under stable compaction that preserves the original order of live blocks.\n- The list of final start addresses $[t_1, t_2, \\dots, t_k]$ of the live blocks after defragmentation, in the same order as they appear in the input.\n\nTest suite:\n- Test $1$: Heap segments $\\texttt{[(\"A\", 1, 4), (\"A\", 2, 2), (\"A\", 3, 3)]}$.\n- Test $2$: Heap segments $\\texttt{[(\"A\", 1, 3), (\"F\", 2), (\"A\", 2, 2), (\"F\", 1), (\"A\", 3, 1)]}$.\n- Test $3$: Heap segments $\\texttt{[(\"F\", 5), (\"A\", 1, 2), (\"A\", 2, 4)]}$.\n- Test $4$: Heap segments $\\texttt{[(\"A\", 1, 1), (\"F\", 1), (\"A\", 2, 1), (\"F\", 2), (\"A\", 3, 2), (\"F\", 3)]}$.\n- Test $5$: Heap segments $\\texttt{[(\"F\", 7), (\"A\", 1, 5)]}$.\n- Test $6$: Heap segments $\\texttt{[(\"F\", 10)]}$.\n\nFinal output format: Your program should produce a single line of output containing a single list where each element corresponds to a test heap, and each element is itself the list $\\texttt{[C, [t_1, t_2, \\dots, t_k]]}$. The list must be printed with comma separators and no spaces, enclosed in square brackets. For example, an output for two tests would look like $\\texttt{[[C_1,[t_{1,1},\\dots]],[C_2,[t_{2,1},\\dots]]]}$, where all $C$ and $t$ values are integers.",
            "solution": "We begin from the core definition of a linear heap memory: a one-dimensional address space indexed from $0$ to $L$, partitioned into a sequence of contiguous segments that exactly cover the interval $[0, L)$. Each segment represents either a live allocated block, of size $s_i \\in \\mathbb{Z}^+$, or a free region, of size $f_j \\in \\mathbb{Z}^+$. The order of segments is given by their left-to-right placement. No live block may overlap another live block or any free region, and live blocks are indivisible and must be preserved as contiguous sequences of bytes.\n\nThe objective of defragmentation is to achieve a contiguous placement of all live blocks starting at address $0$ and preserving their original order, which we call stable compaction. Specifically, given the sizes $s_1, s_2, \\dots, s_k$ of the $k$ live blocks in order, the intended target start address of block $b_i$ is\n$$\nt_i = \\sum_{j=1}^{i-1} s_j,\n$$\nso that the final layout occupies the interval $[0, T)$ where\n$$\nT = \\sum_{i=1}^{k} s_i.\n$$\nWe measure the cost of data movement by counting the total number of bytes that are copied by the algorithm. Copying a block of size $s_i$ exactly once costs $s_i$ bytes. If a block is copied multiple times, the costs add. The total cost is\n$$\nC = \\sum_{i \\in M} s_i,\n$$\nwhere $M$ is the set of indices of blocks copied at least once.\n\nPrinciple-based lower bound on $C$: For stable compaction, the final target position $t_i$ for block $b_i$ is fixed. Consider the initial start address of block $b_i$, denoted $a_i$. By definition of the initial configuration, $a_i$ equals the sum of sizes of all preceding segments, including free segments and live blocks. For any $i$ such that there is at least one free segment before $b_i$, we necessarily have $a_i > t_i$, because the initial prefix sum includes extra free sizes that are not present in the compacted target. Since $a_i \\neq t_i$ and blocks must end up occupying $[t_i, t_i+s_i)$, block $b_i$ cannot remain unmoved at its initial position. To preserve order and prevent overlap, $b_i$ must be copied into its target region. Therefore, every block that has at least one free segment before it must be moved at least once, incurring a cost of at least $s_i$. Let $P$ be the largest prefix of the heap that contains only live blocks and no free segments. Denote the set of blocks contained in $P$ by indices $i=1,2,\\dots,r$. These blocks have $a_i = t_i$ and can remain unmoved. All remaining blocks $i=r+1,\\dots,k$ have at least one free segment before them and thus must be moved at least once. The lower bound on total cost is\n$$\nC_{\\min} \\geq \\sum_{i=r+1}^{k} s_i.\n$$\n\nConstructive algorithm that attains the lower bound: Use two pointers and a single pass over the segment sequence. Maintain a write pointer $w$ that indicates the start address where the next live block should be placed to fill any preceding free space, and a read pointer $r$ that indicates the start address of the current segment being scanned.\n\nAlgorithm steps:\n1. Initialize $w \\leftarrow 0$ and $r \\leftarrow 0$.\n2. For each segment in left-to-right order:\n   - If the segment is a free region of size $f_j$, update $r \\leftarrow r + f_j$ and do nothing else.\n   - If the segment is a live block of size $s_i$:\n     - If $r = w$, there is no preceding free space, so the block is already at its target start address $t_i = w$ and no copy is needed. Record the final start $t_i = w$ and update $w \\leftarrow w + s_i$, $r \\leftarrow r + s_i$.\n     - If $r \\neq w$, there is preceding free space. Copy the block to start at $t_i = w$, incurring cost $s_i$. Record the final start $t_i = w$ and update $w \\leftarrow w + s_i$, $r \\leftarrow r + s_i$.\n3. After the pass, all live blocks have been assigned final start addresses $t_i$ that form $[0, T)$ with no gaps, and the total cost $C$ is the sum of $s_i$ for exactly those blocks for which $r \\neq w$ at the time of processing.\n\nMinimality proof: As derived, any block with at least one preceding free segment must be moved at least once, contributing $s_i$ to the cost. The algorithm moves exactly those blocks, and moves each such block once. Blocks in the maximal initial prefix of live blocks incur no movement. Consequently, the algorithm attains the lower bound\n$$\nC = \\sum_{i=r+1}^{k} s_i,\n$$\nand is therefore optimal under the constraints.\n\nCorrectness and in-place nature: The algorithm preserves the order of live blocks because it processes them left-to-right and assigns contiguous target addresses that increase by $s_i$. Copy operations can be implemented using a memory move that correctly handles overlap (for example, a semantics equivalent to the standard memory move function that safely copies contiguous regions even when source and destination ranges overlap). Because we only maintain a constant number of pointers and do not allocate auxiliary arrays proportional to $L$ or $k$, the algorithm is in-place with $O(1)$ extra space.\n\nComplexity analysis: Let $L$ be the total heap size and $k$ the number of live blocks. The algorithm performs a single pass over the segment sequence, updating $r$ and $w$. Each live block is copied at most once, and the total bytes copied equals $C \\leq \\sum_{i=1}^{k} s_i \\leq L$. The time to scan segments is $O(m)$ where $m$ is the number of segments, and the time to copy data is $O(C) \\leq O(L)$. Therefore, the total time complexity is $O(L)$ when measuring copying cost as proportional to bytes moved, and the extra space complexity is $O(1)$.\n\nProgram outputs: For each test heap, the program computes $C$ and the list $[t_1, t_2, \\dots, t_k]$. The final output is a single line containing a comma-separated list with no spaces, where each element is the list $\\texttt{[C,[t_1,\\dots,t_k]]}$ for the corresponding test.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np  # Imported as permitted; not required for core logic.\n\ndef defragment(heap_segments):\n    \"\"\"\n    Perform stable in-place compaction analysis on a custom heap described by segments.\n\n    heap_segments: list of tuples\n      - (\"A\", id, size) for allocated blocks\n      - (\"F\", size) for free regions\n\n    Returns:\n      moved_bytes: int, minimal total bytes moved under stable compaction\n      final_starts: list of ints, target start addresses of live blocks in input order\n    \"\"\"\n    write = 0  # Next target start address for the next live block\n    read = 0   # Current address while scanning segments\n    moved_bytes = 0\n    final_starts = []\n\n    for seg in heap_segments:\n        tag = seg[0]\n        if tag == \"F\":\n            # Free region: advance read pointer by its size\n            size = seg[1]\n            read += size\n        else:\n            # Allocated block: process its placement\n            _, _id, size = seg\n            if read != write:\n                # There is preceding free space; moving this block once costs its size\n                moved_bytes += size\n            # Record final start for this block (stable order, contiguous packing)\n            final_starts.append(write)\n            # Advance pointers by block size\n            write += size\n            read += size\n\n    return moved_bytes, final_starts\n\ndef serialize(obj):\n    \"\"\"\n    Serialize ints and nested lists to a compact string without spaces.\n    \"\"\"\n    if isinstance(obj, int):\n        return str(obj)\n    elif isinstance(obj, list):\n        return \"[\" + \",\".join(serialize(x) for x in obj) + \"]\"\n    else:\n        # Should not occur given our data model; fallback to str without spaces if possible.\n        return str(obj)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test 1: No free regions; no movement needed.\n        [(\"A\", 1, 4), (\"A\", 2, 2), (\"A\", 3, 3)],\n        # Test 2: Interleaved free and allocated segments; movement after the first free.\n        [(\"A\", 1, 3), (\"F\", 2), (\"A\", 2, 2), (\"F\", 1), (\"A\", 3, 1)],\n        # Test 3: Leading free region; all blocks move.\n        [(\"F\", 5), (\"A\", 1, 2), (\"A\", 2, 4)],\n        # Test 4: Alternating small free and allocated segments.\n        [(\"A\", 1, 1), (\"F\", 1), (\"A\", 2, 1), (\"F\", 2), (\"A\", 3, 2), (\"F\", 3)],\n        # Test 5: Single block after a large free region.\n        [(\"F\", 7), (\"A\", 1, 5)],\n        # Test 6: Entirely free heap; no blocks to move.\n        [(\"F\", 10)],\n    ]\n\n    results = []\n    for heap in test_cases:\n        moved, starts = defragment(heap)\n        results.append([moved, starts])\n\n    # Final print statement in the exact required format: comma-separated, no spaces.\n    print(serialize(results))\n\nsolve()\n```"
        },
        {
            "introduction": "While compaction addresses the consequences of manual memory deallocation, an alternative paradigm seeks to eliminate the source of the problem: manual memory management itself. This leads to automatic garbage collection (GC), where the system, not the programmer, is responsible for reclaiming unused memory. In this exercise, you will implement a foundational mark-and-sweep garbage collector, modeling the heap as a graph and using reachability analysis to identify live objects, providing insight into how modern programming languages manage memory safely and effectively, even with complex cyclical data structures .",
            "id": "3251599",
            "problem": "Design and implement a precise, runnable program that simulates automatic memory reclamation using a Garbage Collector (GC) for a minimal Lisp-like heap model. The heap is modeled as a directed graph $G = (V, E)$ where each object is a node $v \\in V$ with a nonnegative integer size $s(v) \\in \\mathbb{N}$ and zero or more pointer fields that form directed edges $(v, w) \\in E$. A root set $R \\subseteq V$ denotes object identifiers directly referenced by the execution environment. An object $u \\in V$ is defined to be reachable if and only if there exists a path in $G$ from some $r \\in R$ to $u$. The set of reachable nodes is the smallest fixed point $Reach(R)$ that satisfies $R \\subseteq Reach(R)$ and, whenever $(x,y) \\in E$ with $x \\in Reach(R)$, then $y \\in Reach(R)$. The set of unreachable nodes is $U = V \\setminus Reach(R)$. The total reclaimed memory from a GC cycle is the sum of sizes of unreachable nodes, i.e., $B = \\sum_{u \\in U} s(u)$.\n\nYour task is to implement a stop-the-world mark-and-sweep Garbage Collector (GC) that, given a heap and a root set, computes:\n- the integer $B$ of reclaimed memory units,\n- the sorted list of surviving object identifiers $S = \\mathrm{sorted}(Reach(R))$,\n- the sorted list of unreachable object identifiers $U = \\mathrm{sorted}(V \\setminus Reach(R))$.\n\nThe GC must correctly handle cyclical data structures: cycles that are reachable from $R$ must remain, and cycles that are not reachable from $R$ must be reclaimed entirely.\n\nFundamental base you must use to derive your algorithmic design:\n- Graph reachability from a set of source nodes using well-defined traversal,\n- Fixed-point characterization of reachability as described above,\n- Set-theoretic partitioning $V = Reach(R) \\cup U$ with $Reach(R) \\cap U = \\varnothing$,\n- Summation over disjoint sets for memory accounting.\n\nAvoid using any higher-level or shortcut formulas beyond these fundamentals. Derive the correctness of your approach from these principles.\n\nThe input to your program is fixed within the program itself (no external input). Each heap is specified as:\n- a finite set of object identifiers $V = \\{id_1, id_2, \\dots, id_n\\}$,\n- for each $v \\in V$, a nonnegative integer size $s(v)$ and a finite list of outgoing pointers to other identifiers in $V$,\n- a root set $R \\subseteq V$.\n\nYour program must process the following test suite, where each case specifies $V$, $s(\\cdot)$, edges $E$, and $R$. In each case, all identifiers and sizes are integers, and all pointers target valid identifiers in $V$.\n\nTest case $1$ (happy path with a reachable cycle and an unreachable cycle):\n- $V = \\{0,1,2,3,4,5,6,7\\}$,\n- sizes: $s(0)=3$, $s(1)=2$, $s(2)=1$, $s(3)=2$, $s(4)=5$, $s(5)=4$, $s(6)=4$, $s(7)=4$,\n- edges: $0 \\to \\{1,2\\}$, $1 \\to \\{3\\}$, $2 \\to \\{\\}$, $3 \\to \\{1\\}$, $4 \\to \\{\\}$, $5 \\to \\{6\\}$, $6 \\to \\{7\\}$, $7 \\to \\{5\\}$,\n- roots: $R = \\{0\\}$.\n\nTest case $2$ (boundary with empty roots; everything is unreachable):\n- $V = \\{10,11,12\\}$,\n- sizes: $s(10)=2$, $s(11)=2$, $s(12)=2$,\n- edges: $10 \\to \\{\\}$, $11 \\to \\{12\\}$, $12 \\to \\{11\\}$,\n- roots: $R = \\varnothing$.\n\nTest case $3$ (all objects reachable; includes a reachable cycle):\n- $V = \\{20,21,22,23\\}$,\n- sizes: $s(20)=1$, $s(21)=1$, $s(22)=1$, $s(23)=2$,\n- edges: $20 \\to \\{21,23\\}$, $21 \\to \\{22\\}$, $22 \\to \\{21\\}$, $23 \\to \\{\\}$,\n- roots: $R = \\{20\\}$.\n\nTest case $4$ (shared substructure; only one unreachable leaf):\n- $V = \\{30,31,32,33,34\\}$,\n- sizes: $s(30)=3$, $s(31)=4$, $s(32)=5$, $s(33)=6$, $s(34)=7$,\n- edges: $30 \\to \\{31,32\\}$, $31 \\to \\{33\\}$, $32 \\to \\{33\\}$, $33 \\to \\{\\}$, $34 \\to \\{\\}$,\n- roots: $R = \\{30\\}$.\n\nTest case $5$ (self-cycle unreachable):\n- $V = \\{40\\}$,\n- sizes: $s(40)=9$,\n- edges: $40 \\to \\{40\\}$,\n- roots: $R = \\varnothing$.\n\nTest case $6$ (self-cycle reachable):\n- $V = \\{50\\}$,\n- sizes: $s(50)=9$,\n- edges: $50 \\to \\{50\\}$,\n- roots: $R = \\{50\\}$.\n\nYour program must compute, for each test case, the triple $[B, S, U]$ where $B$ is an integer, $S$ is the sorted list of surviving identifiers, and $U$ is the sorted list of unreachable identifiers. The final output format must be a single line containing the list of all test results in order, as a comma-separated list enclosed in square brackets and with each test result itself in bracket notation. For example, a line such as $[[b_1, s_1, u_1],[b_2, s_2, u_2],\\dots]$, where $b_i$ is an integer and $s_i$ and $u_i$ are lists of integers. No additional text or whitespace constraints are imposed beyond producing a valid Python list literal on one line.",
            "solution": "The problem requires the design and implementation of a mark-and-sweep garbage collector (GC). The heap is abstractly modeled as a directed graph $G = (V, E)$, where $V$ is the set of memory objects (nodes) and $E$ represents pointers between them (edges). Each object $v \\in V$ has an associated size $s(v)$. The GC's task is to identify and compute the total size of all unreachable objects, starting from a given root set $R \\subseteq V$.\n\nThe algorithmic design is directly derived from the fundamental principles stipulated in the problem statement: graph reachability, its fixed-point characterization, set-theoretic partitioning of the heap, and summation over identified sets. The process is bifurcated into two distinct phases: a **Mark Phase** to identify all reachable objects, and a **Sweep Phase** to reclaim unreachable objects and summarize the results.\n\n### Algorithmic Derivation\n\n1.  **Mark Phase: Computing the Reachable Set**\n\n    The core of the problem is to compute the set of reachable nodes, $Reach(R)$. The problem defines this set as the smallest fixed point satisfying two conditions:\n    1.  $R \\subseteq Reach(R)$ (the Base Case)\n    2.  If $x \\in Reach(R)$ and $(x, y) \\in E$, then $y \\in Reach(R)$ (the Inductive Step)\n\n    This fixed-point definition naturally leads to an iterative graph traversal algorithm. We can compute $Reach(R)$ by starting with the root set and transitively exploring all objects accessible via pointer chains.\n\n    Let us define a set $M$ of \"marked\" (i.e., known to be reachable) objects. The algorithm proceeds as follows:\n    -   Initialize a worklist, $W$, with the contents of the root set $R$.\n    -   Initialize the set of marked nodes $M$ as an empty set, $\\varnothing$.\n    -   The algorithm iterates until the worklist $W$ is empty. In each step:\n        a.  An object identifier $u$ is removed from $W$.\n        b.  If $u$ is not already in $M$ (i.e., $u \\notin M$), it means we are visiting this reachable object for the first time.\n        c.  We mark $u$ by adding it to $M$, so $M \\leftarrow M \\cup \\{u\\}$.\n        d.  We then find all objects $v$ directly pointed to by $u$ (i.e., for all $v$ such that $(u, v) \\in E$) and add them to the worklist $W$. This step directly implements the inductive part of the fixed-point definition.\n        e.  If $u$ is already in $M$, we do nothing, as its descendants must have already been added to the worklist or processed. This step is crucial for correctness and termination, especially in the presence of cyclical data structures.\n\n    Upon termination of this iterative process (when $W$ becomes empty), the set $M$ is precisely the smallest set satisfying the conditions, thus $M = Reach(R)$. This traversal can be implemented using either a stack (Depth-First Search) or a queue (Breadth-First Search) for the worklist $W$.\n\n2.  **Sweep Phase: Partitioning and Accounting**\n\n    Once the Mark Phase is complete and the set $Reach(R)$ has been determined, the Sweep Phase commences. This phase uses the computed set to partition the entire set of objects $V$ and calculate the required outputs.\n\n    -   **Partitioning**: As per the principle of set-theoretic partitioning, the set of all objects $V$ is divided into two disjoint subsets:\n        -   The set of surviving objects, which is exactly the reachable set $S_{set} = Reach(R)$.\n        -   The set of unreachable (garbage) objects, $U$, which is the set-complement of $Reach(R)$ with respect to $V$, i.e., $U = V \\setminus Reach(R)$.\n\n    -   **Memory Reclamation Accounting**: The total amount of reclaimed memory, $B$, is the sum of the sizes of all objects in the unreachable set $U$. This is a direct application of the summation principle over the disjoint set $U$:\n        $$B = \\sum_{u \\in U} s(u)$$\n\n    -   **Final Output Formulation**: The problem requires three specific outputs:\n        1.  The integer total of reclaimed memory, $B$.\n        2.  A sorted list of surviving object identifiers, $S = \\text{sorted}(S_{set})$.\n        3.  A sorted list of unreachable object identifiers, $U_{list} = \\text{sorted}(U)$.\n\n    This complete procedure correctly implements a mark-and-sweep garbage collector based on the specified first principles, robustly handling complex heap structures including cycles and shared subgraphs.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_gc(sizes, edges, roots):\n    \"\"\"\n    Simulates a mark-and-sweep garbage collector for a given heap model.\n\n    Args:\n        sizes (dict): A dictionary mapping object identifiers (int) to their sizes (int).\n        edges (dict): A dictionary representing the graph's adjacency list, mapping\n                      object identifiers (int) to a list of identifiers they point to.\n        roots (set): A set of root object identifiers (int).\n\n    Returns:\n        list: A list containing three elements:\n              - B (int): The total size of reclaimed memory.\n              - S (list): A sorted list of surviving (reachable) object identifiers.\n              - U (list): A sorted list of unreachable object identifiers.\n    \"\"\"\n    all_nodes = set(sizes.keys())\n    \n    # Mark Phase: Find all reachable objects using graph traversal (DFS-style).\n    # The set of reachable_nodes is the smallest fixed point that contains the\n    # roots and is closed under the edge relation.\n    reachable_nodes = set()\n    worklist = list(roots) # The worklist is initialized with the root set.\n    \n    while worklist:\n        node_id = worklist.pop()\n        if node_id not in reachable_nodes:\n            # Mark the node as reachable.\n            reachable_nodes.add(node_id)\n            # Add its children to the worklist to continue the traversal.\n            # This implements the inductive step of the fixed-point definition.\n            # A node must have an entry in `edges` to have children.\n            if node_id in edges:\n                for child_id in edges[node_id]:\n                    worklist.append(child_id)\n\n    # Sweep Phase: Partition objects and calculate results.\n    # The set of all nodes V is partitioned into Reach(R) and U = V \\ Reach(R).\n    unreachable_nodes = all_nodes - reachable_nodes\n    \n    # Calculate total reclaimed memory by summing sizes of unreachable objects.\n    reclaimed_memory = sum(sizes[node_id] for node_id in unreachable_nodes)\n    \n    # Sort the lists of surviving and unreachable identifiers as required.\n    surviving_list = sorted(list(reachable_nodes))\n    unreachable_list = sorted(list(unreachable_nodes))\n    \n    return [reclaimed_memory, surviving_list, unreachable_list]\n\ndef solve():\n    # Define the test suite as specified in the problem statement.\n    # Each case is a tuple: (sizes, edges, roots).\n    # The set V of all nodes is inferred from the keys of the `sizes` dictionary.\n    test_cases = [\n        # Test case 1 (happy path with a reachable cycle and an unreachable cycle)\n        (\n            {0: 3, 1: 2, 2: 1, 3: 2, 4: 5, 5: 4, 6: 4, 7: 4},\n            {0: [1, 2], 1: [3], 2: [], 3: [1], 4: [], 5: [6], 6: [7], 7: [5]},\n            {0}\n        ),\n        # Test case 2 (boundary with empty roots; everything is unreachable)\n        (\n            {10: 2, 11: 2, 12: 2},\n            {10: [], 11: [12], 12: [11]},\n            set()\n        ),\n        # Test case 3 (all objects reachable; includes a reachable cycle)\n        (\n            {20: 1, 21: 1, 22: 1, 23: 2},\n            {20: [21, 23], 21: [22], 22: [21], 23: []},\n            {20}\n        ),\n        # Test case 4 (shared substructure; only one unreachable leaf)\n        (\n            {30: 3, 31: 4, 32: 5, 33: 6, 34: 7},\n            {30: [31, 32], 31: [33], 32: [33], 33: [], 34: []},\n            {30}\n        ),\n        # Test case 5 (self-cycle unreachable)\n        (\n            {40: 9},\n            {40: [40]},\n            set()\n        ),\n        # Test case 6 (self-cycle reachable)\n        (\n            {50: 9},\n            {50: [50]},\n            {50}\n        ),\n    ]\n\n    results = []\n    for sizes, edges, roots in test_cases:\n        result = run_gc(sizes, edges, roots)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The output is a string representation of a Python list of lists.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}