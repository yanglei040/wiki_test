{
    "hands_on_practices": [
        {
            "introduction": "Many algorithms on grids, such as image filters or physics simulations, involve \"stencil\" operations where each cell's new value depends on its neighbors. A common challenge is handling boundary cells, which lack some neighbors. This exercise  contrasts a naive implementation using conditional branches with a more sophisticated method using \"ghost cell\" padding, allowing you to quantify the significant performance gains from eliminating branches and improving data locality.",
            "id": "3254557",
            "problem": "Consider a two-dimensional array $A$ of double-precision floating-point values (each element is $8$ bytes) stored in row-major order, representing a uniform $n \\times n$ grid. A five-point stencil update computes an output array $B$ of the same shape by, for each cell $(i,j)$, combining its four cardinal neighbors (left, right, up, down) and the center. Two implementation strategies are considered for a single full-grid sweep.\n\nVersion $\\mathrm{U}$ (unpadded) stores only the $n \\times n$ interior and handles boundaries inside the inner loop by a conditional branch: if $(i,j)$ is on the boundary, then substitute boundary values (from fixed boundary arrays) in place of missing neighbors; otherwise, use the usual interior formula. Version $\\mathrm{G}$ (ghost-padded) stores a ghost halo of width $1$ around $A$, forming $A'$ of size $(n+2)\\times(n+2)$ such that every neighbor access for $1 \\le i \\le n$ and $1 \\le j \\le n$ is valid and uniform, eliminating the per-cell boundary branch. Both versions write to $B$ without branching.\n\nAssume the following hardware and access model:\n- The Central Processing Unit (CPU) has a static branch predictor that predicts conditional branches as “not taken.” A misprediction costs $p$ cycles, and a correctly predicted branch still costs $c_b$ cycles to decode and evaluate.\n- The Level-1 (L1) data cache has line size $L = 64$ bytes, and a miss penalty of $m$ cycles. Arrays are aligned to $64$ bytes. The inner loop scans $j$ in increasing order, then increments $i$.\n- In Version $\\mathrm{U}$, at the start and end of each row, the substitution of left or right boundary values accesses separate boundary arrays that are not on the same cache line as the first or last interior element of that row, incurring one additional L1 miss for the left boundary and one additional L1 miss for the right boundary per row. The top and bottom boundary substitutions are assumed to remain resident and do not add misses across the sweep.\n- In Version $\\mathrm{G}$, the ghost cells for left and right neighbors are contiguous with the interior row in $A'$, so those two additional per-row misses do not occur.\n\nUsing only these assumptions and the definitions of row-major layout, boundary cells, and cache lines, determine the quantitative savings when switching from Version $\\mathrm{U}$ to Version $\\mathrm{G}$ for $n = 1024$, $p = 15$, $c_b = 1$, and $m = 40$.\n\nWhich option correctly states all of the following for a single sweep: the number of dynamic per-cell branches eliminated, the number of branch mispredictions eliminated, the number of L1 data cache misses eliminated, and the total cycles saved due to these eliminations?\n\nA. Eliminated branches: $n^2$. Eliminated mispredictions: $(4n - 4)$. Eliminated L1 misses: $2n$. Total cycles saved: $n^2 c_b + (4n - 4) p + 2n m = 1{,}048{,}576 + 61{,}380 + 81{,}920 = 1{,}191{,}876$.\n\nB. Eliminated branches: $(n - 2)^2$. Eliminated mispredictions: $4n$. Eliminated L1 misses: $n$. Total cycles saved: $(n - 2)^2 c_b + 4n p + n m = 1{,}044{,}484 + 61{,}440 + 40{,}960 = 1{,}146{,}884$.\n\nC. Eliminated branches: $n^2$. Eliminated mispredictions: $2n$. Eliminated L1 misses: $0$. Total cycles saved: $n^2 c_b + 2n p + 0 \\cdot m = 1{,}048{,}576 + 30{,}720 + 0 = 1{,}079{,}296$.\n\nD. Eliminated branches: $n^2$. Eliminated mispredictions: $(4n - 4)$. Eliminated L1 misses: $n/8$. Total cycles saved: $n^2 c_b + (4n - 4) p + \\frac{n}{8} m = 1{,}048{,}576 + 61{,}380 + 5{,}120 = 1{,}115{,}076$.",
            "solution": "The user wants me to analyze a computational problem, first validating the problem statement and then deriving a solution.\n\n### Step 1: Extract Givens\n- **Array A**: A two-dimensional array of size $n \\times n$.\n- **Data Type**: Double-precision floating-point values, each occupying $8$ bytes.\n- **Storage**: Row-major order.\n- **Stencil Update**: A five-point stencil computes an output array $B$ from an input array $A$. For each cell $(i,j)$, the new value depends on the values at $(i,j)$, $(i-1,j)$, $(i+1,j)$, $(i,j-1)$, and $(i,j+1)$.\n- **Version U (unpadded)**:\n    - Stores only the $n \\times n$ grid.\n    - Uses a conditional branch in the inner loop to handle boundary cells.\n    - Boundary values are substituted from separate, fixed boundary arrays.\n- **Version G (ghost-padded)**:\n    - Stores an $(n+2) \\times (n+2)$ array $A'$ with a ghost halo of width $1$.\n    - Eliminates the per-cell branch for boundary checks for the interior $n \\times n$ grid computation.\n- **Hardware and Access Model**:\n    - **Branch Prediction**: Static, predicts conditional branches as “not taken.”\n    - **Branch Costs**: Misprediction costs $p$ cycles. Correctly predicted branch costs $c_b$ cycles.\n    - **L1 Cache**: Line size $L = 64$ bytes. Miss penalty is $m$ cycles.\n    - **Array Alignment**: Arrays are aligned to $64$ bytes.\n    - **Loop Order**: The inner loop iterates over $j$ (columns), the outer loop over $i$ (rows).\n- **Cache Miss Assumptions (Version U)**:\n    - Accessing left/right boundary values from separate arrays causes one additional L1 miss for the left boundary and one for the right, per row. Total: $2$ additional misses per row.\n    - Top/bottom boundary value accesses are assumed not to cause additional misses.\n- **Cache Miss Assumptions (Version G)**:\n    - The $2$ additional per-row misses for left/right boundaries are eliminated due to contiguous storage in the padded array $A'$.\n- **Constants**:\n    - $n = 1024$\n    - $p = 15$ cycles\n    - $c_b = 1$ cycle\n    - $m = 40$ cycles\n- **Question**: Determine the quantitative savings (eliminated branches, eliminated mispredictions, eliminated L1 misses, and total cycles saved) when switching from Version U to Version G for a single sweep.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically grounded in the principles of computer architecture and high-performance computing. The concepts of stencil computations, cache behavior, branch prediction, and performance modeling with ghost cells are standard and well-established. The problem is well-posed, providing all necessary parameters and a clear, objective model to work within. The assumptions, such as the static branch predictor and specific costs, are explicitly stated, which removes ambiguity and allows for a unique solution within the defined model. The problem is not trivial, as it requires careful accounting of events on the grid boundaries versus the interior, and a correct interpretation of the cost model.\n\n1.  **Scientific or Factual Unsoundness**: None. The model is a simplification, but it is a valid and common approach for performance estimation. It does not violate any fundamental principles.\n2.  **Non-Formalizable or Irrelevant**: None. The problem is formalizable and directly relevant.\n3.  **Incomplete or Contradictory Setup**: None. All required data and assumptions are provided.\n4.  **Unrealistic or Infeasible**: None. The parameters are plausible for a modern CPU and a reasonably sized problem.\n5.  **Ill-Posed or Poorly Structured**: None. The question is precise and the terms are defined.\n6.  **Pseudo-Profound, Trivial, or Tautological**: None. The problem requires substantive reasoning.\n7.  **Outside Scientific Verifiability**: None. The result is verifiable within the given model.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. We may proceed to the solution.\n\n### Derivation of the Solution\nThe goal is to calculate the total savings by switching from Version U to Version G. The savings come from three sources: the elimination of per-cell branches, the elimination of branch mispredictions, and the elimination of L1 data cache misses. We will calculate the savings from each source and sum them up.\n\n**1. Number of Dynamic Per-Cell Branches Eliminated**\nIn Version U, a conditional branch is executed for every cell in the $n \\times n$ grid to check if it is a boundary cell. The total number of cells is $n \\times n = n^2$.\n$$ \\text{Branches in Version U} = n^2 $$\nVersion G uses a padded array and has no such conditional branch within the main computational loop.\n$$ \\text{Branches in Version G} = 0 $$\nTherefore, the number of eliminated branches is:\n$$ \\text{Eliminated Branches} = n^2 = 1024^2 = 1,048,576 $$\n\n**2. Number of Branch Mispredictions Eliminated**\nThe static branch predictor always predicts \"not taken.\" The branch instruction is effectively `if (is_boundary_cell)`. The \"taken\" path is for boundary cells, and the \"not taken\" path is for interior cells. The predictor will be wrong (mispredict) every time the condition is true, i.e., for every boundary cell.\n\nThe number of boundary cells in an $n \\times n$ grid is the total number of cells minus the number of interior cells. The interior forms an $(n-2) \\times (n-2)$ grid.\n$$ \\text{Number of boundary cells} = n^2 - (n-2)^2 = n^2 - (n^2 - 4n + 4) = 4n - 4 $$\nEach of these boundary cells results in a misprediction in Version U.\n$$ \\text{Mispredictions in Version U} = 4n - 4 $$\nVersion G has no branches, thus no mispredictions.\n$$ \\text{Mispredictions in Version G} = 0 $$\nThe number of eliminated mispredictions is:\n$$ \\text{Eliminated Mispredictions} = 4n - 4 = 4(1024) - 4 = 4096 - 4 = 4092 $$\n\n**3. Number of L1 Data Cache Misses Eliminated**\nThe problem statement explicitly defines the difference in cache misses. In Version U, for each of the $n$ rows, accessing the separate boundary arrays for the left and right neighbors incurs $2$ additional L1 cache misses.\n$$ \\text{Additional Misses in Version U} = 2 \\times n = 2n $$\nIn Version G, these specific misses are eliminated due to the contiguous memory layout of the ghost-padded array.\nThe number of eliminated L1 misses is:\n$$ \\text{Eliminated L1 Misses} = 2n = 2 \\times 1024 = 2048 $$\n\n**4. Total Cycles Saved**\nThe total cycle savings are the sum of costs eliminated from branches, mispredictions, and cache misses. The structure of the options suggests a cost model where the total cost of branching is the sum of a base cost for all branches and an additional penalty for mispredictions.\n- **Cost of a correctly predicted branch**: $c_b$\n- **Cost of a mispredicted branch**: The problem states a misprediction \"costs $p$ cycles\" and a correct one \"costs $c_b$ cycles\". A standard interpretation, confirmed by the structure of the options' formulas, is that the total cost is a base cost plus a penalty, i.e., Cost(mispredict) = $c_b + p$. However, the savings can be calculated by summing the cost of executing all branches and the *additional* penalty from mispredictions.\n\n- **Savings from eliminating the base cost of all branches**: There are $n^2$ branches, each having a base cost of $c_b$.\n  $$ \\text{Cycles Saved (Base Branch Cost)} = n^2 \\times c_b = 1024^2 \\times 1 = 1,048,576 \\text{ cycles} $$\n- **Savings from eliminating misprediction penalties**: There are $4n-4$ mispredictions, each costing an additional $p$ cycles.\n  $$ \\text{Cycles Saved (Misprediction Penalty)} = (4n-4) \\times p = (4092) \\times 15 = 61,380 \\text{ cycles} $$\n- **Savings from eliminating L1 cache misses**: There are $2n$ eliminated misses, each costing $m$ cycles.\n  $$ \\text{Cycles Saved (Cache Misses)} = 2n \\times m = (2 \\times 1024) \\times 40 = 2048 \\times 40 = 81,920 \\text{ cycles} $$\n\nThe total cycles saved is the sum of these three components:\n$$ \\text{Total Cycles Saved} = (n^2 c_b) + ((4n-4) p) + (2n m) $$\n$$ \\text{Total Cycles Saved} = 1,048,576 + 61,380 + 81,920 = 1,191,876 \\text{ cycles} $$\n\n### Option-by-Option Analysis\n\n**A. Eliminated branches: $n^2$. Eliminated mispredictions: $(4n - 4)$. Eliminated L1 misses: $2n$. Total cycles saved: $n^2 c_b + (4n - 4) p + 2n m = 1{,}048{,}576 + 61{,}380 + 81{,}920 = 1{,}191{,}876$.**\n- Eliminated branches: $n^2$. This matches our derivation.\n- Eliminated mispredictions: $(4n - 4)$. This matches our derivation.\n- Eliminated L1 misses: $2n$. This matches our derivation.\n- Total cycles saved: The formula $n^2 c_b + (4n - 4) p + 2n m$ and all numerical calculations match our derivation.\n- **Verdict: Correct.**\n\n**B. Eliminated branches: $(n - 2)^2$. Eliminated mispredictions: $4n$. Eliminated L1 misses: $n$. Total cycles saved: $(n - 2)^2 c_b + 4n p + n m = 1{,}044{,}484 + 61{,}440 + 40{,}960 = 1{,}146{,}884$.**\n- Eliminated branches: $(n - 2)^2$. Incorrect. The branch is executed for all $n^2$ cells, not just the interior cells.\n- Eliminated mispredictions: $4n$. Incorrect. The correct count of boundary cells is $4n - 4$ due to double-counting the corners.\n- Eliminated L1 misses: $n$. Incorrect. The problem specifies $2$ misses per row for $n$ rows, totaling $2n$.\n- **Verdict: Incorrect.**\n\n**C. Eliminated branches: $n^2$. Eliminated mispredictions: $2n$. Eliminated L1 misses: $0$. Total cycles saved: $n^2 c_b + 2n p + 0 \\cdot m = 1{,}048{,}576 + 30{,}720 + 0 = 1{,}079{,}296$.**\n- Eliminated branches: $n^2$. Correct.\n- Eliminated mispredictions: $2n$. Incorrect. This undercounts the boundary cells; the correct count is $4n-4$.\n- Eliminated L1 misses: $0$. Incorrect. The problem explicitly states that $2n$ misses are eliminated.\n- **Verdict: Incorrect.**\n\n**D. Eliminated branches: $n^2$. Eliminated mispredictions: $(4n - 4)$. Eliminated L1 misses: $n/8$. Total cycles saved: $n^2 c_b + (4n - 4) p + \\frac{n}{8} m = 1{,}048{,}576 + 61{,}380 + 5{,}120 = 1{,}115٬076$.**\n- Eliminated branches: $n^2$. Correct.\n- Eliminated mispredictions: $(4n - 4)$. Correct.\n- Eliminated L1 misses: $n/8$. Incorrect. This value seems to be based on the number of cache lines per row ($n$ doubles / $8$ doubles per line), but it contradicts the problem's explicit statement that $2$ misses are incurred per row, for a total of $2n$ misses.\n- **Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Beyond local operations, we often need to compute aggregates over large rectangular regions of an array. Calculating such a sum from scratch for every query can be slow. This practice  guides you through the development of the integral image, a powerful precomputation technique that allows you to answer any rectangular sum query in constant time, $O(1)$, by cleverly applying the inclusion-exclusion principle.",
            "id": "3254618",
            "problem": "Consider a rectangular two-dimensional array $A$ with $d=2$, where $A \\in \\mathbb{Z}^{n \\times m}$ is indexed with $0$-based inclusive coordinates. The task is to design, derive, and implement a method to answer arbitrary axis-aligned rectangle sum queries over $A$ in constant time after a one-time preprocessing step. Begin from fundamental definitions and the inclusion-exclusion principle, and do not assume any pre-derived formulas.\n\nFundamental base:\n- Define the rectangle sum over a subset of entries of $A$ as follows. For indices $r_1, r_2, c_1, c_2$ with $0 \\le r_1 \\le r_2 < n$ and $0 \\le c_1 \\le c_2 < m$, the rectangle sum is\n$$\nS(r_1, c_1, r_2, c_2) = \\sum_{i=r_1}^{r_2} \\sum_{j=c_1}^{c_2} A[i,j].\n$$\n- Define a two-dimensional prefix-sum array (also called an integral image) $P \\in \\mathbb{Z}^{(n+1) \\times (m+1)}$ constructed from $A$ such that each entry of $P$ encodes the sum of a contiguous subarray of $A$ whose top-left corner is at the origin. Use $1$-based padding for $P$ to avoid boundary special cases, so that indices of $P$ run from $0$ to $n$ in rows and from $0$ to $m$ in columns, with $P[0,\\cdot] = 0$ and $P[\\cdot,0] = 0$.\n\nYour tasks:\n1. Using only the above definitions and the inclusion-exclusion principle, derive a formula that expresses $S(r_1, c_1, r_2, c_2)$ in terms of $P$ that achieves $O(1)$ time per query. Your derivation must be logically sound and based on summation properties and inclusion-exclusion; do not introduce or assume any shortcut formulas.\n2. From first principles, derive the recurrence to build $P$ using $A$ so that all entries of $P$ are correct. Clearly explain why this build takes $O(nm)$ time.\n3. Implement a program that:\n   - Builds $P$ from each test case’s $A$.\n   - Computes the specified rectangle sum query $S(r_1, c_1, r_2, c_2)$ in $O(1)$ time using your derived inclusion-exclusion formula over $P$.\n   - Produces a single line of output containing the results as a comma-separated list enclosed in square brackets, for all provided test cases, in the order they appear.\n\nIndexing and correctness requirements:\n- Use $0$-based inclusive indices $(r_1, c_1, r_2, c_2)$ for rectangle queries over $A$.\n- Use $1$-based padding for $P$ as specified to avoid ambiguous boundary cases.\n- All arrays and indices must be treated consistently with the stated conventions.\n\nTest suite:\n- Test case $1$: $n = 3$, $m = 4$, matrix $A^{(1)}$ has rows [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], query $(r_1, c_1, r_2, c_2) = (1, 1, 2, 3)$.\n- Test case $2$: same $A^{(1)}$, query $(r_1, c_1, r_2, c_2) = (0, 0, 2, 3)$.\n- Test case $3$: same $A^{(1)}$, query $(r_1, c_1, r_2, c_2) = (0, 0, 0, 0)$.\n- Test case $4$: $n = 2$, $m = 2$, matrix $A^{(4)}$ has rows [-1, 2], [3, -4], query $(r_1, c_1, r_2, c_2) = (0, 0, 1, 1)$.\n- Test case $5$: $n = 3$, $m = 3$, matrix $A^{(5)}$ has rows [0, 0, 0], [0, 1, 0], [0, 0, 0], query $(r_1, c_1, r_2, c_2) = (0, 0, 1, 2)$.\n\nExpected output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[\\text{result}_1,\\text{result}_2,\\text{result}_3]$). Each $\\text{result}_k$ must be the integer value of the corresponding rectangle sum $S(r_1, c_1, r_2, c_2)$ for the $k$-th test case, in the order given above.",
            "solution": "The problem statement is evaluated to be **valid**. It is scientifically grounded in established principles of computer science and mathematics, specifically regarding data structures (multidimensional arrays) and algorithms (prefix sums). The problem is well-posed, with clear, unambiguous definitions, consistent constraints, and a verifiable set of test cases. It is self-contained and requires no external information or subjective interpretation. Therefore, a formal solution can be derived and implemented.\n\nThe derivation and implementation proceed in two stages as requested: deriving the constant-time query formula and the linear-time build recurrence, followed by the implementation.\n\n### 1. Derivation of the Constant-Time Query Formula\n\nThe objective is to compute the sum of an arbitrary rectangular sub-array, $S(r_1, c_1, r_2, c_2)$, in $O(1)$ time using a precomputed prefix-sum array, $P$.\n\n**Definition of the Prefix-Sum Array ($P$)**\n\nThe problem defines a prefix-sum array $P \\in \\mathbb{Z}^{(n+1) \\times (m+1)}$ with $1$-based padding. The value at $P[i,j]$ represents the sum of all elements in the rectangle of the original array $A$ from the origin $(0,0)$ to the point $(i-1, j-1)$, inclusive. Formally, for $i > 0$ and $j > 0$:\n$$\nP[i, j] = \\sum_{k=0}^{i-1} \\sum_{l=0}^{j-1} A[k,l]\n$$\nThe padding ensures that $P[i,j] = 0$ if $i=0$ or $j=0$. This convention simplifies the query formula by eliminating the need for boundary checks.\n\n**Derivation using the Inclusion-Exclusion Principle**\n\nThe query asks for the sum $S(r_1, c_1, r_2, c_2) = \\sum_{i=r_1}^{r_2} \\sum_{j=c_1}^{c_2} A[i,j]$. This sum corresponds to the area of a rectangle defined by the corners $(r_1, c_1)$ and $(r_2, c_2)$. We can compute this sum by starting with a larger rectangle originating at $(0,0)$ and systematically subtracting the parts that are not in the query rectangle. This is a direct application of the inclusion-exclusion principle.\n\nLet's define a helper function, $Sum(r, c) = \\sum_{k=0}^{r} \\sum_{l=0}^{c} A[k,l]$, which represents the sum of the rectangle from $(0,0)$ to $(r,c)$. In terms of our prefix-sum array $P$, this is $Sum(r, c) = P[r+1, c+1]$.\n\nThe desired sum, $S(r_1, c_1, r_2, c_2)$, can be visualized as the area of a large rectangle with its two smaller adjacent rectangles removed, plus a small corner rectangle that was removed twice.\n\n1.  **Include the large rectangle:** Start with the sum of all elements from the origin $(0,0)$ up to the bottom-right corner of the query rectangle, $(r_2, c_2)$. This sum is $Sum(r_2, c_2) = P[r_2+1, c_2+1]$. This area, let's call it $D$, contains the desired rectangle plus three other regions.\n\n2.  **Exclude the top rectangle:** The region above the query rectangle spans from $(0,0)$ to $(r_1-1, c_2)$. Its sum is $Sum(r_1-1, c_2) = P[(r_1-1)+1, c_2+1] = P[r_1, c_2+1]$. Let's call this area $C$. Subtracting this removes the elements above our target rectangle.\n\n3.  **Exclude the left rectangle:** The region to the left of the query rectangle spans from $(0,0)$ to $(r_2, c_1-1)$. Its sum is $Sum(r_2, c_1-1) = P[r_2+1, (c_1-1)+1] = P[r_2+1, c_1]$. Let's call this area $B$. Subtracting this removes the elements to the left of our target rectangle.\n\n4.  **Re-include the doubly-excluded corner:** When we subtracted the top rectangle ($C$) and the left rectangle ($B$), we subtracted their intersection twice. This intersection is the small rectangle from $(0,0)$ to $(r_1-1, c_1-1)$. Its sum is $Sum(r_1-1, c_1-1) = P[(r_1-1)+1, (c_1-1)+1] = P[r_1, c_1]$. Let's call this area $A$. To correct for the double subtraction, we must add this sum back once.\n\nCombining these steps gives the final formula:\n$$\nS(r_1, c_1, r_2, c_2) = D - B - C + A\n$$\n$$\nS(r_1, c_1, r_2, c_2) = P[r_2+1, c_2+1] - P[r_2+1, c_1] - P[r_1, c_2+1] + P[r_1, c_1]\n$$\nThis formula requires exactly $4$ lookups in the precomputed array $P$ and $3$ arithmetic operations (two subtractions, one addition). Since these operations take constant time, any query can be answered in $O(1)$ time. The use of a padded array $P$ elegantly handles cases where $r_1=0$ or $c_1=0$, as the corresponding terms like $P[r_2+1, 0]$ or $P[0, c_2+1]$ correctly evaluate to $0$.\n\n### 2. Derivation of the Build Recurrence for the Prefix-Sum Array\n\nThe second task is to derive a recurrence relation to build the prefix-sum array $P$ from the input array $A$ in $O(nm)$ time.\n\nFrom the definition of $P$, the value of a single element $A[i-1, j-1]$ can be expressed using values from $P$. This is equivalent to applying our query formula to a $1 \\times 1$ rectangle:\n$$\nA[i-1, j-1] = S(i-1, j-1, i-1, j-1)\n$$\nUsing the derived formula with $r_1=r_2=i-1$ and $c_1=c_2=j-1$:\n$$\nA[i-1, j-1] = P[(i-1)+1, (j-1)+1] - P[(i-1)+1, (j-1)] - P[(i-1), (j-1)+1] + P[(i-1), (j-1)]\n$$\n$$\nA[i-1, j-1] = P[i, j] - P[i, j-1] - P[i-1, j] + P[i-1, j-1]\n$$\nOur goal is to find a recurrence for $P[i,j]$. We can rearrange the above equation to solve for $P[i,j]$:\n$$\nP[i,j] = A[i-1, j-1] + P[i-1, j] + P[i, j-1] - P[i-1, j-1]\n$$\nThis is the desired recurrence relation. It states that the prefix sum up to cell $(i-1, j-1)$ of $A$ can be calculated from the current element $A[i-1, j-1]$ and the three adjacent, previously computed prefix sums in $P$: the one above ($P[i-1,j]$), the one to the left ($P[i,j-1]$), and the one diagonally top-left ($P[i-1, j-1]$).\n\nTo build the entire array $P$, we can iterate through its indices, for $i$ from $1$ to $n$ and for $j$ from $1$ to $m$, applying this recurrence at each step. The base cases are the padded rows and columns, which are initialized to $0$.\nA nested loop structure computes each of the $n \\times m$ non-padding entries of $P$:\n```\nfor i from 1 to n:\n  for j from 1 to m:\n    P[i,j] = A[i-1, j-1] + P[i-1,j] + P[i,j-1] - P[i-1,j-1]\n```\nSince the calculation for each $P[i,j]$ involves a constant number of arithmetic operations and array lookups ($O(1)$), and this is performed for all $n \\times m$ cells, the total time complexity for building the prefix-sum array $P$ is $O(nm)$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the rectangle sum query problem for a suite of test cases.\n    It follows a two-phase process:\n    1. Preprocessing: Builds a 2D prefix-sum array (integral image).\n    2. Querying: Uses the prefix-sum array to answer queries in O(1) time.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        {\n            \"A\": np.array([\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12]\n            ], dtype=np.int64),\n            \"query\": (1, 1, 2, 3)\n        },\n        # Test case 2\n        {\n            \"A\": np.array([\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12]\n            ], dtype=np.int64),\n            \"query\": (0, 0, 2, 3)\n        },\n        # Test case 3\n        {\n            \"A\": np.array([\n                [1, 2, 3, 4],\n                [5, 6, 7, 8],\n                [9, 10, 11, 12]\n            ], dtype=np.int64),\n            \"query\": (0, 0, 0, 0)\n        },\n        # Test case 4\n        {\n            \"A\": np.array([\n                [-1, 2],\n                [3, -4]\n            ], dtype=np.int64),\n            \"query\": (0, 0, 1, 1)\n        },\n        # Test case 5\n        {\n            \"A\": np.array([\n                [0, 0, 0],\n                [0, 1, 0],\n                [0, 0, 0]\n            ], dtype=np.int64),\n            \"query\": (0, 0, 1, 2)\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        A = case[\"A\"]\n        query_coords = case[\"query\"]\n        \n        # Get dimensions of the original matrix A.\n        # A is 0-indexed, with dimensions n x m.\n        n, m = A.shape\n        \n        # 1. Preprocessing Step: Build the prefix-sum array P.\n        # P is (n+1) x (m+1) with 1-based padding for simplified calculations.\n        # P[0,:] and P[:,0] are all 0s by initialization.\n        P = np.zeros((n + 1, m + 1), dtype=np.int64)\n        \n        # Build P using the derived recurrence relation:\n        # P[i,j] = A[i-1,j-1] + P[i-1,j] + P[i,j-1] - P[i-1,j-1]\n        for i in range(1, n + 1):\n            for j in range(1, m + 1):\n                P[i, j] = A[i - 1, j - 1] + P[i - 1, j] + P[i, j - 1] - P[i - 1, j - 1]\n                \n        # 2. Query Step: Compute the sum in O(1) time.\n        # The query is for the rectangle with inclusive 0-based coordinates\n        # (r1, c1) to (r2, c2).\n        r1, c1, r2, c2 = query_coords\n        \n        # Use the derived inclusion-exclusion formula:\n        # S(r1, c1, r2, c2) = P[r2+1, c2+1] - P[r1, c2+1] - P[r2+1, c1] + P[r1, c1]\n        # The indices of P are offset by +1 relative to A's indices.\n        sum_val = P[r2 + 1, c2 + 1] - P[r1, c2 + 1] - P[r2 + 1, c1] + P[r1, c1]\n        \n        results.append(sum_val)\n\n    # Final print statement in the exact required format.\n    # np.int64 objects must be converted to standard Python ints for str()\n    # to format them without any type-specific annotations.\n    print(f\"[{','.join(map(str, [int(r) for r in results]))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Some problems on multidimensional arrays are best solved not by direct iteration, but by cleverly reducing the problem's dimensionality. The challenge of finding the contiguous submatrix with the maximum sum is a prime example of this algorithmic strategy. This exercise  will have you adapt the well-known one-dimensional Kadane's algorithm to solve the two-dimensional version, providing deep insight into this elegant and widely applicable problem-solving technique.",
            "id": "3254593",
            "problem": "A developer is given integer-valued multidimensional arrays and must compute maximum-sum contiguous regions within them by reasoning from first principles about sums and contiguity in arrays. Begin from the following base definitions: a two-dimensional array has shape $n \\times m$ and a three-dimensional array has shape $n \\times m \\times k$; a contiguous subarray in one dimension is specified by an index interval $[i,j]$ with $0 \\le i \\le j$; a contiguous submatrix in two dimensions is specified by intervals $[r_1,r_2]$ and $[c_1,c_2]$; a contiguous sub-cuboid in three dimensions is specified by intervals $[r_1,r_2]$, $[c_1,c_2]$, and $[z_1,z_2]$. The sum of any such region is defined by adding all entries with indices in the specified ranges. The one-dimensional maximum contiguous subarray problem asks for a contiguous interval with maximal sum; it is known to admit a linear-time solution by dynamic programming (Dynamic Programming (DP)) that uses only constant extra space. Using these foundations, the task is to derive and implement two algorithms: first, for a two-dimensional matrix, derive an approach that iteratively selects pairs of row boundaries and reduces the problem to a one-dimensional maximum contiguous subarray across columns for an appropriately constructed compressed array; second, for a three-dimensional tensor, generalize the idea by fixing two dimensions (rows and columns) to form a one-dimensional array across the remaining depth dimension and compute the maximal contiguous depth interval. The developer must present the algorithms as programs that compute the required maximum sums for the provided test suite and then, in accompanying analysis, quantify the time complexity in terms of $n$, $m$, and $k$ for both algorithms, making clear the effect of any precomputation used.\n\nThe program must be completely self-contained (no input from the user) and produce a single line of output that aggregates the integer results for all provided test cases into a comma-separated list enclosed in square brackets, in the exact order listed below. No physical units or angles are involved in this problem, and there is no rounding.\n\nImplement the two algorithms described above and apply them to the following test suite.\n\nTwo-Dimensional (2D) matrices:\n- Matrix $A_1$ of shape $4 \\times 5$:\n  $[ [\\,1,\\,-2,\\,-1,\\,4,\\,-1\\,],\\; [\\,-8,\\,3,\\,4,\\,-2,\\,2\\,],\\; [\\,3,\\,-1,\\,2,\\,1,\\,-5\\,],\\; [\\,-4,\\,2,\\,-1,\\,3,\\,1\\,] ]$\n- Matrix $A_2$ of shape $2 \\times 2$ (all negative, to test the boundary case):\n  $[ [\\,-5,\\,-1\\,],\\; [\\,-2,\\,-3\\,] ]$\n\nThree-Dimensional (3D) tensors:\n- Tensor $B_1$ of shape $3 \\times 3 \\times 4$, given as four layers along the depth dimension (each layer is a $3 \\times 3$ matrix):\n  Layer $z=0$: $[ [\\,1,\\,-2,\\,0\\,],\\; [\\,-1,\\,3,\\,-1\\,],\\; [\\,2,\\,-1,\\,1\\,] ]$\n  Layer $z=1$: $[ [\\,-2,\\,1,\\,4\\,],\\; [\\,3,\\,-1,\\,2\\,],\\; [\\,-1,\\,2,\\,-3\\,] ]$\n  Layer $z=2$: $[ [\\,0,\\,2,\\,-1\\,],\\; [\\,-3,\\,4,\\,1\\,],\\; [\\,2,\\,-2,\\,0\\,] ]$\n  Layer $z=3$: $[ [\\,-1,\\,-2,\\,3\\,],\\; [\\,1,\\,0,\\,-1\\,],\\; [\\,2,\\,1,\\,-2\\,] ]$\n- Tensor $B_2$ of shape $3 \\times 3 \\times 1$ (depth of $1$, serving as a reduction to a single 2D layer):\n  Single layer $z=0$: $[ [\\,-1,\\,2,\\,-3\\,],\\; [\\,4,\\,-5,\\,6\\,],\\; [\\,-7,\\,8,\\,-9\\,] ]$\n\nFor each $2$D test case, compute the maximum sum over all contiguous submatrices. For each $3$D test case, compute the maximum sum over all contiguous sub-cuboids. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $[A_1, A_2, B_1, B_2]$, for example $[r_1,r_2,r_3,r_4]$, where $r_i$ are integers representing the corresponding maximum sums.\n\nDesign for coverage:\n- The case $A_1$ is a general mixed-sign $2$D instance that exercises the reduction to one dimension across column accumulations.\n- The case $A_2$ is a $2$D boundary instance with all negative entries to ensure the algorithm correctly returns the largest single entry when all sums are negative.\n- The case $B_1$ is a mixed-sign $3$D instance that requires fixing two dimensions and using an efficient per-layer rectangle summation to build a one-dimensional depth series for the one-dimensional maximum contiguous subarray algorithm.\n- The case $B_2$ is a $3$D boundary instance with $k=1$, which reduces to the $2$D maximum sum submatrix problem.",
            "solution": "The problem is assessed to be valid. It is a well-posed algorithmic challenge grounded in the established principles of dynamic programming and computational complexity within the field of data structures and algorithms. The definitions are clear, the objectives are formalizable, and the test cases are concrete and serve to validate the correctness of the derived algorithms under various conditions.\n\nThe core of the problem is to find the maximum-sum contiguous region in two-dimensional ($2$D) and three-dimensional ($3$D) integer-valued arrays by generalizing a known one-dimensional ($1$D) solution.\n\n### 1. The One-Dimensional Base Case: Maximum Contiguous Subarray Sum\n\nThe foundation for this problem is the one-dimensional maximum contiguous subarray sum problem. Given a $1$D array $A$ of length $N$, the goal is to find indices $i$ and $j$ ($0 \\le i \\le j < N$) such that the sum $\\sum_{k=i}^{j} A[k]$ is maximized.\n\nThis problem can be solved in $O(N)$ time with $O(1)$ extra space using Kadane's algorithm, a classic dynamic programming approach. The core idea is to iterate through the array, maintaining the maximum sum of a subarray ending at the current position. Let $c_i$ be the maximum sum of a contiguous subarray ending at index $i$, and $g$ be the global maximum sum found so far. The recurrence relation is:\n$c_i = \\max(A[i], c_{i-1} + A[i])$\n$g_i = \\max(g_{i-1}, c_i)$\n\nThis logic correctly handles arrays with all negative numbers, in which case the result is the largest (least negative) single element in the array.\n\n### 2. Derivation of the Two-Dimensional Algorithm\n\nFor a two-dimensional matrix $A$ of shape $n \\times m$, we are asked to find the contiguous submatrix with the maximum sum. The problem requires an approach that reduces this $2$D problem to a series of $1$D problems.\n\nThe algorithm proceeds as follows:\n1.  Initialize a global maximum sum, $S_{max}$, to a very small number (e.g., $-\\infty$).\n2.  Iterate through all possible pairs of top and bottom row boundaries, denoted by indices $r_1$ and $r_2$ where $0 \\le r_1 \\le r_2 < n$.\n3.  For each fixed pair $(r_1, r_2)$, we create a temporary $1$D array, let's call it `col_sums`, of size $m$. Each element `col_sums[c]` will store the sum of the elements in column $c$ from row $r_1$ to $r_2$. That is, $\\text{col\\_sums}[c] = \\sum_{r=r_1}^{r_2} A[r][c]$.\n4.  This `col_sums` array represents a \"compressed\" view of the submatrix defined by rows $r_1$ to $r_2$. Any contiguous subarray in `col_sums` with sum $S$ corresponds to a contiguous submatrix in the original matrix $A$ (spanning rows $r_1$ to $r_2$ and the corresponding column interval) with the same sum $S$.\n5.  Apply the $1$D maximum contiguous subarray algorithm (Kadane's) to the `col_sums` array to find the maximum sum for the fixed rows $r_1$ and $r_2$.\n6.  Update the global maximum sum $S_{max}$ with the result from step 5 if it is greater.\n\nAfter iterating through all possible pairs of $(r_1, r_2)$, $S_{max}$ will hold the maximum submatrix sum.\n\n**Complexity Analysis (2D):**\n- The outer loop for $r_1$ runs $n$ times.\n- The inner loop for $r_2$ runs on average $n/2$ times, so $O(n)$.\n- Inside the loops, we construct the `col_sums` array. This can be done efficiently. For a fixed $r_1$, as $r_2$ increments, we can update `col_sums` by adding the values from the new row $r_2$. This update takes $O(m)$ time.\n- Applying Kadane's algorithm to `col_sums` takes $O(m)$ time.\n- The total time complexity is the product of these nested operations: $O(n \\cdot n \\cdot (m + m)) = O(n^2 m)$.\n- The space complexity is $O(m)$ to store the `col_sums` array. No precomputation is specified or necessary for this method.\n\n### 3. Derivation of the Three-Dimensional Algorithm\n\nFor a three-dimensional tensor $B$ of shape $n \\times m \\times k$, we generalize the strategy above. The problem asks us to fix boundaries in two dimensions (rows and columns) and reduce the problem to a $1$D search along the third dimension (depth).\n\nThe algorithm is as follows:\n1.  Initialize a global maximum sum, $S_{max}$, to $-\\infty$.\n2.  Iterate through all possible rectangular cross-sections in the $n \\times m$ plane. This is defined by four boundary indices: $r_1, r_2, c_1, c_2$ where $0 \\le r_1 \\le r_2 < n$ and $0 \\le c_1 \\le c_2 < m$.\n3.  For each fixed rectangular region $(r_1, c_1)$ to $(r_2, c_2)$, create a temporary $1$D array, `depth_sums`, of size $k$.\n4.  Each element `depth_sums[z]` is the sum of all elements within the fixed rectangle at depth slice $z$. That is, $\\text{depth\\_sums}[z] = \\sum_{r=r_1}^{r_2} \\sum_{c=c_1}^{c_2} B[r][c][z]$.\n5.  Apply the $1$D maximum contiguous subarray algorithm (Kadane's) to `depth_sums`. The result gives the maximum sum for a contiguous sub-cuboid whose cross-section is the fixed rectangle.\n6.  Update the global maximum sum $S_{max}$ with the result from step 5.\n\n**Complexity Analysis (3D):**\nA naive calculation of the sum in step 4 for each rectangle and each depth slice would be inefficient. A direct implementation would have a complexity of roughly $O(n^2 \\cdot m^2 \\cdot k \\cdot n \\cdot m) = O(n^3 m^3 k)$. This is computationally prohibitive.\n\nTo make this feasible, we introduce a precomputation step.\n- **Precomputation:** For each of the $k$ depth slices, we compute a $2$D summed-area table (SAT). A SAT, $S$, for a matrix $M$ is defined as $S[i][j] = \\sum_{x=0}^{i} \\sum_{y=0}^{j} M[x][y]$. Building a SAT for an $n \\times m$ matrix takes $O(nm)$ time. Since there are $k$ slices, the total time for this precomputation is $O(nmk)$.\n- **Main Computation:** With the SATs, the sum of any rectangular region (step 4) can be calculated in $O(1)$ time.\nThe main algorithm consists of four nested loops for $r_1, r_2, c_1, c_2$, giving $O(n^2 m^2)$ choices for the rectangular cross-section. For each choice:\n  - Building the `depth_sums` array of size $k$ takes $O(k)$ time, since each sum is an $O(1)$ lookup.\n  - Applying Kadane's algorithm to `depth_sums` takes $O(k)$ time.\nThe total time for the main computation is $O(n^2 m^2 \\cdot k)$.\n- **Overall Complexity:** The total complexity is the sum of precomputation and main computation: $O(nmk + n^2 m^2 k)$. Since the second term dominates, the overall time complexity is $O(n^2 m^2 k)$. The space complexity is $O(nmk)$ to store the SATs. The prompt's requirement to discuss precomputation is addressed by this choice of an optimized algorithm.\n\nThe algorithms are now fully specified and their complexities are analyzed. These will be implemented to solve for the given test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and applies algorithms for finding the maximum-sum contiguous sub-region\n    in 2D and 3D arrays, as per the problem specification.\n    \"\"\"\n\n    def kadane(arr: np.ndarray) -> int:\n        \"\"\"\n        Computes the maximum contiguous subarray sum in O(N) time using Kadane's algorithm.\n        Handles the all-negative case correctly.\n        \"\"\"\n        if arr.size == 0:\n            return 0\n        \n        max_so_far = arr[0]\n        current_max = arr[0]\n        for i in range(1, arr.size):\n            x = arr[i]\n            current_max = max(x, current_max + x)\n            max_so_far = max(max_so_far, current_max)\n        return max_so_far\n\n    def max_sum_2d(matrix: np.ndarray) -> int:\n        \"\"\"\n        Computes the maximum sum of a contiguous submatrix.\n        Complexity: O(n*n*m) where shape is (n, m).\n        \"\"\"\n        n, m = matrix.shape\n        if n == 0 or m == 0:\n            return 0\n\n        max_overall_sum = -float('inf')\n\n        for r1 in range(n):\n            col_sums = np.zeros(m, dtype=int)\n            for r2 in range(r1, n):\n                # Update column sums by adding the new row r2\n                col_sums += matrix[r2, :]\n                \n                # Apply Kadane's algorithm to find the max sum for the submatrix from r1 to r2\n                current_max = kadane(col_sums)\n                max_overall_sum = max(max_overall_sum, current_max)\n                \n        return int(max_overall_sum)\n\n    def get_sum_from_2d_sat(sat_2d: np.ndarray, r1: int, c1: int, r2: int, c2: int) -> int:\n        \"\"\"\n        Calculates the sum of a rectangle from a 2D summed-area table in O(1).\n        \"\"\"\n        res = sat_2d[r2, c2]\n        if r1 > 0:\n            res -= sat_2d[r1 - 1, c2]\n        if c1 > 0:\n            res -= sat_2d[r2, c1 - 1]\n        if r1 > 0 and c1 > 0:\n            res += sat_2d[r1 - 1, c1 - 1]\n        return res\n\n    def max_sum_3d(tensor: np.ndarray) -> int:\n        \"\"\"\n        Computes the maximum sum of a contiguous sub-cuboid.\n        Complexity: O(n*n*m*m*k) where shape is (n, m, k), using precomputation.\n        \"\"\"\n        n, m, k = tensor.shape\n        if n == 0 or m == 0 or k == 0:\n            return 0\n        \n        # Precomputation: Build a 2D summed-area table for each depth slice.\n        # Complexity: O(n*m*k)\n        sats = np.zeros_like(tensor, dtype=int)\n        for z in range(k):\n            sats[:, :, z] = np.cumsum(np.cumsum(tensor[:, :, z], axis=0), axis=1)\n\n        max_overall_sum = -float('inf')\n\n        # Main computation: Iterate over all possible (r,c) rectangles, then find max\n        # contiguous sum along depth.\n        # Complexity: O(n^2 * m^2 * k)\n        for r1 in range(n):\n            for r2 in range(r1, n):\n                for c1 in range(m):\n                    for c2 in range(c1, m):\n                        # Construct a 1D array of sums along the depth dimension\n                        # for the fixed rectangle (r1,c1)-(r2,c2).\n                        depth_sums = np.zeros(k, dtype=int)\n                        for z in range(k):\n                            depth_sums[z] = get_sum_from_2d_sat(sats[:, :, z], r1, c1, r2, c2)\n                        \n                        current_max = kadane(depth_sums)\n                        max_overall_sum = max(max_overall_sum, current_max)\n        \n        return int(max_overall_sum)\n\n    # Define the test cases from the problem statement.\n    A1 = np.array([\n        [1, -2, -1, 4, -1],\n        [-8, 3, 4, -2, 2],\n        [3, -1, 2, 1, -5],\n        [-4, 2, -1, 3, 1]\n    ], dtype=int)\n\n    A2 = np.array([\n        [-5, -1],\n        [-2, -3]\n    ], dtype=int)\n\n    B1_layers = [\n        np.array([[1, -2, 0], [-1, 3, -1], [2, -1, 1]], dtype=int),\n        np.array([[-2, 1, 4], [3, -1, 2], [-1, 2, -3]], dtype=int),\n        np.array([[0, 2, -1], [-3, 4, 1], [2, -2, 0]], dtype=int),\n        np.array([[-1, -2, 3], [1, 0, -1], [2, 1, -2]], dtype=int)\n    ]\n    B1 = np.stack(B1_layers, axis=2)\n\n    B2_layers = [\n        np.array([[-1, 2, -3], [4, -5, 6], [-7, 8, -9]], dtype=int)\n    ]\n    B2 = np.stack(B2_layers, axis=2)\n\n    # Calculate results for all test cases\n    results = [\n        max_sum_2d(A1),\n        max_sum_2d(A2),\n        max_sum_3d(B1),\n        max_sum_3d(B2)\n    ]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}