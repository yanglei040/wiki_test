{
    "hands_on_practices": [
        {
            "introduction": "Parameter estimation is a cornerstone of statistical learning, and the Maximum Likelihood Estimator (MLE) is one of its most important tools. This first exercise moves beyond simply deriving an estimator; it challenges you to rigorously evaluate its quality. By focusing on the seemingly simple case of a Uniform distribution, you will uncover subtleties in estimation, compute the estimator's risk, and even discover how to construct a provably better one . This practice builds a solid foundation in the principles of evaluating and improving statistical estimators.",
            "id": "3111021",
            "problem": "A dataset consists of independent and identically distributed observations $X_{1}, X_{2}, \\ldots, X_{n}$ drawn from a continuous Uniform distribution on the interval $[0,\\theta]$ with unknown upper endpoint $\\theta$ and known lower endpoint $0$. Using the core definitions of independence, probability density function, and likelihood, and the order statistic $X_{(n)}=\\max\\{X_{1},\\ldots,X_{n}\\}$, proceed as follows:\n\n1. Derive the Maximum Likelihood Estimator (MLE) $\\hat{\\theta}_{\\mathrm{MLE}}$ for $\\theta$ by maximizing the likelihood $L(\\theta; x_{1},\\ldots,x_{n})$ over $\\theta0$ subject to the support constraints implied by the Uniform distribution.\n\n2. In the squared error loss $L(\\hat{\\theta},\\theta)=(\\hat{\\theta}-\\theta)^{2}$, compute the risk (the expectation of the loss) of the MLE, $R(\\hat{\\theta}_{\\mathrm{MLE}})=\\mathbb{E}\\big[(\\hat{\\theta}_{\\mathrm{MLE}}-\\theta)^{2}\\big]$, in closed form as a function of $n$ and $\\theta$.\n\n3. Consider the one-parameter class of bias-corrected estimators of the form $\\hat{\\theta}_{c}=c\\,X_{(n)}$ with a multiplicative constant $c0$. Determine the value $c^{\\ast}$ that minimizes the mean squared error $\\mathbb{E}\\big[(\\hat{\\theta}_{c}-\\theta)^{2}\\big]$ over $c0$. Provide the resulting minimized mean squared error in closed form and justify that it is strictly smaller than the risk of the MLE for all integer $n\\geq 1$ and all $\\theta0$.\n\nReport the four closed-form expressions, in order: $\\hat{\\theta}_{\\mathrm{MLE}}$, $R(\\hat{\\theta}_{\\mathrm{MLE}})$, the optimal constant $c^{\\ast}$, and the minimized mean squared error at $c^{\\ast}$. No numerical approximation is required.",
            "solution": "The problem is valid as it is a standard, well-posed question in parameter estimation within the field of statistical learning. It is scientifically grounded, objective, and contains all necessary information for a unique solution.\n\nLet the independent and identically distributed (i.i.d.) observations be $X_{1}, X_{2}, \\ldots, X_{n}$, drawn from a continuous Uniform distribution $U(0, \\theta)$. The probability density function (PDF) for a single observation $X_{i}$ is given by:\n$$f(x_i; \\theta) = \\frac{1}{\\theta} \\mathbb{I}(0 \\le x_i \\le \\theta)$$\nwhere $\\mathbb{I}(\\cdot)$ is the indicator function.\n\n### 1. Derivation of the Maximum Likelihood Estimator (MLE)\n\nThe likelihood function $L(\\theta; x_{1}, \\ldots, x_{n})$ is the joint probability density of the observed sample. Due to the i.i.d. assumption, it is the product of the individual PDFs:\n$$L(\\theta; \\mathbf{x}) = \\prod_{i=1}^{n} f(x_i; \\theta) = \\prod_{i=1}^{n} \\left[ \\frac{1}{\\theta} \\mathbb{I}(0 \\le x_i \\le \\theta) \\right]$$\nThis expression can be separated into two parts:\n$$L(\\theta; \\mathbf{x}) = \\left( \\frac{1}{\\theta} \\right)^{n} \\prod_{i=1}^{n} \\mathbb{I}(0 \\le x_i \\le \\theta)$$\nThe product of the indicator functions is $1$ if and only if all conditions $0 \\le x_i \\le \\theta$ are met for $i=1, \\ldots, n$. This is equivalent to the joint condition that $0 \\le \\min\\{x_1, \\ldots, x_n\\}$ and $\\max\\{x_1, \\ldots, x_n\\} \\le \\theta$. Let $x_{(n)} = \\max\\{x_1, \\ldots, x_n\\}$. The condition $x_{(n)} \\le \\theta$ implies $x_i \\le \\theta$ for all $i$. The condition $0 \\le \\min\\{x_i\\}$ is guaranteed by the problem setup. Thus, the likelihood function can be written as:\n$$L(\\theta; \\mathbf{x}) = \\frac{1}{\\theta^n} \\mathbb{I}(x_{(n)} \\le \\theta)$$\nTo find the MLE, $\\hat{\\theta}_{\\mathrm{MLE}}$, we must maximize $L(\\theta; \\mathbf{x})$ with respect to $\\theta$. The indicator function $\\mathbb{I}(x_{(n)} \\le \\theta)$ constrains the domain of $\\theta$ to the interval $[x_{(n)}, \\infty)$. On this interval, the term $\\frac{1}{\\theta^n}$ is a strictly decreasing function of $\\theta$ for $\\theta  0$. To maximize a decreasing function, we must choose the smallest possible value for its argument. The smallest value $\\theta$ can take, subject to the constraint $\\theta \\ge x_{(n)}$, is $x_{(n)}$. Therefore, the MLE for $\\theta$ is:\n$$\\hat{\\theta}_{\\mathrm{MLE}} = x_{(n)} = \\max\\{X_1, \\ldots, X_n\\}$$\n\n### 2. Risk of the MLE\n\nThe risk $R(\\hat{\\theta}_{\\mathrm{MLE}})$ is the mean squared error (MSE) of the estimator, defined as $R(\\hat{\\theta}_{\\mathrm{MLE}}) = \\mathbb{E}\\big[(\\hat{\\theta}_{\\mathrm{MLE}} - \\theta)^{2}\\big]$. To compute this, we first need the probability distribution of the estimator $\\hat{\\theta}_{\\mathrm{MLE}} = X_{(n)}$.\n\nLet $Y = X_{(n)}$. The cumulative distribution function (CDF) of $Y$ is:\n$$F_Y(y) = P(Y \\le y) = P(X_{(n)} \\le y) = P(X_1 \\le y, \\ldots, X_n \\le y)$$\nSince the $X_i$ are i.i.d., $F_Y(y) = \\prod_{i=1}^{n} P(X_i \\le y) = (P(X_1 \\le y))^n$. The CDF for a single $X_i \\sim U(0, \\theta)$ is $F_{X_i}(x) = x/\\theta$ for $0 \\le x \\le \\theta$. Thus, for $0 \\le y \\le \\theta$:\n$$F_Y(y) = \\left(\\frac{y}{\\theta}\\right)^n$$\nThe PDF of $Y$ is the derivative of its CDF:\n$$f_Y(y) = \\frac{d}{dy}F_Y(y) = \\frac{d}{dy}\\left(\\frac{y^n}{\\theta^n}\\right) = \\frac{ny^{n-1}}{\\theta^n}, \\quad \\text{for } 0 \\le y \\le \\theta$$\nThe MSE can be expanded as $\\mathbb{E}[(\\hat{\\theta}_{\\mathrm{MLE}} - \\theta)^2] = \\mathbb{E}[X_{(n)}^2] - 2\\theta\\mathbb{E}[X_{(n)}] + \\theta^2$. We compute the first two moments of $X_{(n)}$:\n$$\\mathbb{E}[X_{(n)}] = \\int_{0}^{\\theta} y f_Y(y) dy = \\int_{0}^{\\theta} y \\frac{ny^{n-1}}{\\theta^n} dy = \\frac{n}{\\theta^n} \\int_{0}^{\\theta} y^n dy = \\frac{n}{\\theta^n} \\left[\\frac{y^{n+1}}{n+1}\\right]_0^{\\theta} = \\frac{n\\theta}{n+1}$$\n$$\\mathbb{E}[X_{(n)}^2] = \\int_{0}^{\\theta} y^2 f_Y(y) dy = \\int_{0}^{\\theta} y^2 \\frac{ny^{n-1}}{\\theta^n} dy = \\frac{n}{\\theta^n} \\int_{0}^{\\theta} y^{n+1} dy = \\frac{n}{\\theta^n} \\left[\\frac{y^{n+2}}{n+2}\\right]_0^{\\theta} = \\frac{n\\theta^2}{n+2}$$\nSubstituting these into the MSE expression:\n$$R(\\hat{\\theta}_{\\mathrm{MLE}}) = \\frac{n\\theta^2}{n+2} - 2\\theta\\left(\\frac{n\\theta}{n+1}\\right) + \\theta^2 = \\theta^2 \\left(\\frac{n}{n+2} - \\frac{2n}{n+1} + 1\\right)$$\nBringing to a common denominator $(n+1)(n+2)$:\n$$R(\\hat{\\theta}_{\\mathrm{MLE}}) = \\theta^2 \\left(\\frac{n(n+1) - 2n(n+2) + (n+1)(n+2)}{(n+1)(n+2)}\\right)$$\n$$R(\\hat{\\theta}_{\\mathrm{MLE}}) = \\theta^2 \\left(\\frac{n^2+n - 2n^2-4n + n^2+3n+2}{(n+1)(n+2)}\\right) = \\theta^2 \\left(\\frac{2}{(n+1)(n+2)}\\right) = \\frac{2\\theta^2}{(n+1)(n+2)}$$\n\n### 3. Optimal Bias-Corrected Estimator\n\nWe consider estimators of the form $\\hat{\\theta}_c = cX_{(n)}$ and seek to find the constant $c^*$ that minimizes the MSE, $\\mathbb{E}[(\\hat{\\theta}_c - \\theta)^2]$.\n$$\\text{MSE}(\\hat{\\theta}_c) = \\mathbb{E}[(cX_{(n)} - \\theta)^2] = \\mathbb{E}[c^2X_{(n)}^2 - 2c\\theta X_{(n)} + \\theta^2]$$\nUsing linearity of expectation and the moments calculated above:\n$$\\text{MSE}(\\hat{\\theta}_c) = c^2\\mathbb{E}[X_{(n)}^2] - 2c\\theta\\mathbb{E}[X_{(n)}] + \\theta^2 = c^2\\left(\\frac{n\\theta^2}{n+2}\\right) - 2c\\theta\\left(\\frac{n\\theta}{n+1}\\right) + \\theta^2$$\n$$\\text{MSE}(\\hat{\\theta}_c) = \\theta^2 \\left[c^2 \\frac{n}{n+2} - c \\frac{2n}{n+1} + 1\\right]$$\nThis is a quadratic function of $c$, say $g(c)$. To find the minimum, we differentiate with respect to $c$ and set the result to zero:\n$$\\frac{d}{dc}g(c) = \\theta^2 \\left[2c \\frac{n}{n+2} - \\frac{2n}{n+1}\\right] = 0$$\nAssuming $n \\ge 1$, we can solve for $c$:\n$$2c \\frac{n}{n+2} = \\frac{2n}{n+1} \\implies c = \\frac{n+2}{n+1}$$\nThe second derivative, $\\frac{d^2}{dc^2}g(c) = \\theta^2 \\frac{2n}{n+2}$, is positive for $n \\ge 1$, confirming this value $c^*$ gives a minimum.\n$$c^* = \\frac{n+2}{n+1}$$\nTo find the minimized MSE, we substitute $c^*$ back into the MSE formula:\n$$\\text{MSE}(\\hat{\\theta}_{c^*}) = \\theta^2 \\left[ \\left(\\frac{n+2}{n+1}\\right)^2 \\frac{n}{n+2} - \\left(\\frac{n+2}{n+1}\\right) \\frac{2n}{n+1} + 1 \\right]$$\n$$\\text{MSE}(\\hat{\\theta}_{c^*}) = \\theta^2 \\left[ \\frac{n(n+2)}{(n+1)^2} - \\frac{2n(n+2)}{(n+1)^2} + 1 \\right] = \\theta^2 \\left[ \\frac{-n(n+2) + (n+1)^2}{(n+1)^2} \\right]$$\n$$\\text{MSE}(\\hat{\\theta}_{c^*}) = \\theta^2 \\left[ \\frac{-n^2-2n + n^2+2n+1}{(n+1)^2} \\right] = \\frac{\\theta^2}{(n+1)^2}$$\nFinally, we must show this minimized MSE is strictly smaller than the risk of the MLE for all $n \\ge 1$ and $\\theta  0$:\n$$\\frac{\\theta^2}{(n+1)^2}  \\frac{2\\theta^2}{(n+1)(n+2)}$$\nSince $\\theta^2  0$ and $n+1  0$, we can simplify the inequality:\n$$\\frac{1}{n+1}  \\frac{2}{n+2} \\implies n+2  2(n+1) \\implies n+2  2n+2 \\implies 0  n$$\nThis inequality holds for all integers $n \\ge 1$, so the justification is complete.\n\nThe four required expressions are:\n1. $\\hat{\\theta}_{\\mathrm{MLE}} = X_{(n)}$\n2. $R(\\hat{\\theta}_{\\mathrm{MLE}}) = \\frac{2\\theta^2}{(n+1)(n+2)}$\n3. $c^* = \\frac{n+2}{n+1}$\n4. Minimized MSE = $\\frac{\\theta^2}{(n+1)^2}$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nX_{(n)}  \\frac{2\\theta^2}{(n+1)(n+2)}  \\frac{n+2}{n+1}  \\frac{\\theta^2}{(n+1)^2}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "In practice, data scientists frequently standardize features to have zero mean and unit variance, a process often called z-scoring. This is a standard step before feeding data into many algorithms like PCA or regularized regression. But what does this transformation actually do to the shape of your data's distribution? This exercise explores that question by comparing a standardized Uniform variable to a standardized Normal variable. By calculating and interpreting the kurtosis—a measure of \"tailedness\"—you will gain a deeper, more critical understanding of what standardization can and cannot achieve, a crucial insight for any practitioner .",
            "id": "3110941",
            "problem": "A data engineer prepares features for a statistical learning pipeline by standardizing (z-scoring) each feature to have zero mean and unit variance. Let $X$ be a continuous feature with a uniform distribution on the interval $[a,b]$ where $ab$, and let $Y$ be a continuous feature with a normal distribution having mean $\\mu$ and variance $\\sigma^{2}$. Define the standardized variables $Z_{X} = (X - \\mathbb{E}[X]) / \\sqrt{\\operatorname{Var}(X)}$ and $Z_{Y} = (Y - \\mathbb{E}[Y]) / \\sqrt{\\operatorname{Var}(Y)}$. Use the fundamental definitions for continuous random variables: probability density function, expectation $\\mathbb{E}[\\cdot]$, variance $\\operatorname{Var}(\\cdot)$, and kurtosis $\\beta_{2}(W) = \\frac{\\mathbb{E}\\!\\left[(W - \\mathbb{E}[W])^{4}\\right]}{\\left(\\operatorname{Var}(W)\\right)^{2}}$ with excess kurtosis $\\gamma_{2}(W) = \\beta_{2}(W) - 3$. \n\nStarting only from these definitions, derive the population excess kurtosis $\\gamma_{2}(Z_{X})$ and $\\gamma_{2}(Z_{Y})$. Then, considering the common practice in Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) to assume approximately normal standardized features, interpret what the sign of the difference $\\Delta = \\gamma_{2}(Z_{X}) - \\gamma_{2}(Z_{Y})$ implies about tail heaviness after z-scoring. \n\nReport the single numerical value of $\\Delta$. No rounding is required.",
            "solution": "The problem is assessed as valid. It is scientifically grounded in standard probability theory and statistics, well-posed with all necessary definitions provided, and objective in its formulation. It requests a derivation and interpretation of standard statistical quantities.\n\nThe problem requires the derivation of the population excess kurtosis for a standardized uniform random variable, $\\gamma_{2}(Z_{X})$, and a standardized normal random variable, $\\gamma_{2}(Z_{Y})$. The final goal is to compute and interpret their difference, $\\Delta = \\gamma_{2}(Z_{X}) - \\gamma_{2}(Z_{Y})$.\n\nLet $W$ be a continuous random variable. The standardized variable $Z_W$ is defined as $Z_{W} = (W - \\mathbb{E}[W]) / \\sqrt{\\operatorname{Var}(W)}$. By construction, a standardized variable has a mean of $0$ and a variance of $1$.\n$\\mathbb{E}[Z_W] = \\mathbb{E}\\left[\\frac{W - \\mathbb{E}[W]}{\\sqrt{\\operatorname{Var}(W)}}\\right] = \\frac{1}{\\sqrt{\\operatorname{Var}(W)}} (\\mathbb{E}[W] - \\mathbb{E}[\\mathbb{E}[W]]) = \\frac{1}{\\sqrt{\\operatorname{Var}(W)}} (\\mathbb{E}[W] - \\mathbb{E}[W]) = 0$.\n$\\operatorname{Var}(Z_W) = \\operatorname{Var}\\left(\\frac{W - \\mathbb{E}[W]}{\\sqrt{\\operatorname{Var}(W)}}\\right) = \\frac{1}{\\operatorname{Var}(W)} \\operatorname{Var}(W - \\mathbb{E}[W]) = \\frac{1}{\\operatorname{Var}(W)} \\operatorname{Var}(W) = 1$.\n\nThe kurtosis, $\\beta_{2}(W)$, and excess kurtosis, $\\gamma_{2}(W)$, are defined as:\n$$ \\beta_{2}(W) = \\frac{\\mathbb{E}\\!\\left[(W - \\mathbb{E}[W])^{4}\\right]}{\\left(\\operatorname{Var}(W)\\right)^{2}} $$\n$$ \\gamma_{2}(W) = \\beta_{2}(W) - 3 $$\nFor a standardized variable $Z_W$, these formulas simplify. Since $\\mathbb{E}[Z_W]=0$ and $\\operatorname{Var}(Z_W)=1$, the kurtosis becomes the fourth moment of $Z_W$:\n$$ \\beta_{2}(Z_W) = \\frac{\\mathbb{E}\\!\\left[(Z_W - 0)^{4}\\right]}{1^{2}} = \\mathbb{E}[Z_W^4] $$\nThe excess kurtosis is therefore $\\gamma_{2}(Z_W) = \\mathbb{E}[Z_W^4] - 3$.\n\nFirst, we derive the excess kurtosis for the standardized normal variable, $\\gamma_{2}(Z_{Y})$.\nThe variable $Y$ follows a normal distribution, $Y \\sim N(\\mu, \\sigma^2)$. The standardized variable is $Z_{Y} = (Y - \\mathbb{E}[Y]) / \\sqrt{\\operatorname{Var}(Y)} = (Y - \\mu) / \\sigma$. By the properties of the normal distribution, $Z_Y$ follows a standard normal distribution, $Z_Y \\sim N(0, 1)$, with probability density function (PDF) $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2)$.\nWe need to compute $\\mathbb{E}[Z_Y^4]$:\n$$ \\mathbb{E}[Z_Y^4] = \\int_{-\\infty}^{\\infty} z^{4} \\phi(z) dz = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} z^{4} \\exp(-\\frac{z^{2}}{2}) dz $$\nWe solve this integral using integration by parts, $\\int u dv = uv - \\int v du$. Let $u = z^{3}$ and $dv = z \\exp(-z^{2}/2) dz$. Then $du = 3z^{2} dz$ and $v = -\\exp(-z^{2}/2)$.\n$$ \\int z^{4} \\exp(-\\frac{z^{2}}{2}) dz = -z^{3}\\exp(-\\frac{z^{2}}{2}) - \\int (-\\exp(-\\frac{z^{2}}{2}))(3z^{2}) dz = -z^{3}\\exp(-\\frac{z^{2}}{2}) + 3 \\int z^{2}\\exp(-\\frac{z^{2}}{2}) dz $$\nEvaluating the definite integral from $-\\infty$ to $\\infty$:\n$$ \\int_{-\\infty}^{\\infty} z^{4} \\exp(-\\frac{z^{2}}{2}) dz = \\left[-z^{3}\\exp(-\\frac{z^{2}}{2})\\right]_{-\\infty}^{\\infty} + 3 \\int_{-\\infty}^{\\infty} z^{2}\\exp(-\\frac{z^{2}}{2}) dz $$\nThe boundary term $\\left[-z^{3}\\exp(-z^{2}/2)\\right]_{-\\infty}^{\\infty}$ evaluates to $0$. The remaining integral is related to the variance of $Z_Y$:\n$$ \\operatorname{Var}(Z_Y) = \\mathbb{E}[Z_Y^2] - (\\mathbb{E}[Z_Y])^2 = \\int_{-\\infty}^{\\infty} z^{2} \\phi(z) dz - 0^2 = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} z^{2} \\exp(-\\frac{z^{2}}{2}) dz $$\nSince we know $\\operatorname{Var}(Z_Y)=1$, we have $\\int_{-\\infty}^{\\infty} z^{2} \\exp(-z^{2}/2) dz = \\sqrt{2\\pi}$.\nSubstituting this back:\n$$ \\mathbb{E}[Z_Y^4] = \\frac{1}{\\sqrt{2\\pi}} \\left( 3 \\int_{-\\infty}^{\\infty} z^{2}\\exp(-\\frac{z^{2}}{2}) dz \\right) = \\frac{3}{\\sqrt{2\\pi}} (\\sqrt{2\\pi}) = 3 $$\nSo, the kurtosis of a standard normal distribution is $\\beta_{2}(Z_{Y}) = 3$. The excess kurtosis is:\n$$ \\gamma_{2}(Z_{Y}) = \\beta_{2}(Z_{Y}) - 3 = 3 - 3 = 0 $$\n\nNext, we derive the excess kurtosis for the standardized uniform variable, $\\gamma_{2}(Z_{X})$.\nThe variable $X$ follows a uniform distribution, $X \\sim U(a,b)$. Its PDF is $f_X(x) = \\frac{1}{b-a}$ for $x \\in [a,b]$.\nThe mean is $\\mathbb{E}[X] = \\frac{a+b}{2}$ and the variance is $\\operatorname{Var}(X) = \\frac{(b-a)^2}{12}$.\nThe standardized variable is $Z_X = \\frac{X - \\mathbb{E}[X]}{\\sqrt{\\operatorname{Var}(X)}} = \\frac{X - (a+b)/2}{(b-a)/\\sqrt{12}}$.\nTo simplify the calculation of $\\mathbb{E}[Z_X^4]$, we can consider a simpler linear transformation of $X$ to a variable $U$ on the interval $[-1, 1]$. Let $U = \\frac{X - (a+b)/2}{(b-a)/2}$. This variable $U$ is uniformly distributed on $[-1, 1]$ with PDF $f_U(u) = 1/2$ for $u \\in [-1, 1]$.\nWe can express $Z_X$ in terms of $U$:\n$$ Z_X = \\frac{U \\cdot (b-a)/2}{(b-a)/\\sqrt{12}} = U \\frac{\\sqrt{12}}{2} = U \\frac{2\\sqrt{3}}{2} = U\\sqrt{3} $$\nNow we can compute the fourth moment of $Z_X$:\n$$ \\mathbb{E}[Z_X^4] = \\mathbb{E}[(U\\sqrt{3})^4] = \\mathbb{E}[9U^4] = 9\\mathbb{E}[U^4] $$\nWe compute $\\mathbb{E}[U^4]$ from its definition:\n$$ \\mathbb{E}[U^4] = \\int_{-1}^{1} u^{4} f_U(u) du = \\int_{-1}^{1} u^{4} \\left(\\frac{1}{2}\\right) du = \\frac{1}{2} \\left[ \\frac{u^5}{5} \\right]_{-1}^{1} = \\frac{1}{10} [1^5 - (-1)^5] = \\frac{1}{10} (1 - (-1)) = \\frac{2}{10} = \\frac{1}{5} $$\nThus, the fourth moment of $Z_X$ is $\\mathbb{E}[Z_X^4] = 9 \\times \\frac{1}{5} = \\frac{9}{5}$.\nThe kurtosis of the standardized uniform distribution is $\\beta_{2}(Z_X) = \\frac{9}{5}$. Its excess kurtosis is:\n$$ \\gamma_{2}(Z_{X}) = \\beta_{2}(Z_{X}) - 3 = \\frac{9}{5} - 3 = \\frac{9-15}{5} = -\\frac{6}{5} $$\n\nFinally, we compute the difference $\\Delta$:\n$$ \\Delta = \\gamma_{2}(Z_{X}) - \\gamma_{2}(Z_{Y}) = -\\frac{6}{5} - 0 = -\\frac{6}{5} $$\n\nInterpretation:\nThe excess kurtosis $\\gamma_2$ measures the \"tailedness\" of a distribution relative to the normal distribution, which serves as the benchmark with $\\gamma_2 = 0$.\nA positive excess kurtosis ($\\gamma_2  0$) indicates a leptokurtic distribution, which is more peaked and has heavier tails than a normal distribution.\nA negative excess kurtosis ($\\gamma_2  0$) indicates a platykurtic distribution, which is less peaked and has lighter tails.\nOur result $\\gamma_{2}(Z_{X}) = -6/5 = -1.2$ shows that the standardized uniform distribution is platykurtic. This is because the uniform distribution is bounded, so its probability density drops to zero outside a finite interval, meaning it has \"lighter\" tails (in fact, no tails) compared to the unbounded normal distribution.\nThe difference $\\Delta = -6/5$ is negative. This signifies that after z-scoring, the uniform feature $Z_X$ has substantially lighter tails than the normal feature $Z_Y$. Common methods like PCA and LDA can be sensitive to the distribution of features, and their theoretical properties are often derived under the assumption of normality. Using such methods on a uniformly distributed feature, under the implicit assumption that standardization makes it \"approximately normal,\" would be a poor approximation. Specifically, the model would incorrectly assume a non-zero probability for extreme values that can never occur for the bounded uniform feature. This highlights the fact that standardization centers and scales a distribution but does not change its fundamental shape, including its kurtosis.\n\nThe single numerical value of $\\Delta$ is $-\\frac{6}{5} = -1.2$.",
            "answer": "$$ \\boxed{-1.2} $$"
        },
        {
            "introduction": "Statistical theory contains some remarkably elegant and powerful results, and the probability integral transform (PIT) is a prime example. This transform provides a universal bridge, capable of converting any continuous random variable into a standard uniform variable. In this culminating practice, you will first derive this fundamental theorem from first principles. Then, you will translate this theory into practice by writing code to implement a calibration test for a probabilistic model, a critical task in modern machine learning for ensuring that a model's predicted probabilities are reliable . This exercise beautifully connects the Normal and Uniform distributions and demonstrates how abstract theory empowers practical data analysis.",
            "id": "3110957",
            "problem": "You are given that a random variable $Z$ is standard normal, written $Z \\sim \\mathcal{N}(0,1)$, with cumulative distribution function $ \\Phi(z) = \\int_{-\\infty}^{z} \\frac{1}{\\sqrt{2\\pi}} e^{-t^2/2} \\, dt$. Consider the probability integral transform (PIT): define $U = \\Phi(Z)$. \n\nTask 1 (theoretical verification): Starting from the definition of a cumulative distribution function and the monotonicity of $ \\Phi(\\cdot)$, derive from first principles that $U$ has a standard uniform distribution, written $U \\sim \\mathrm{Unif}(0,1)$. Your derivation must not assume the result; it must use only core definitions such as the definition of a cumulative distribution function and properties of strictly increasing functions.\n\nTask 2 (calibration test design): In probabilistic prediction for a continuous target $Y$, a model outputs a predictive cumulative distribution function $F(y)$. The model is calibrated if, when $Y$ is drawn from the true data-generating process and $U = F(Y)$ is computed for each prediction–observation pair, the $U$ values are distributed as $ \\mathrm{Unif}(0,1)$. Design a practical, deterministic test of calibration based on PIT histograms as follows:\n- Use a histogram with $B$ equal-width bins over the interval $[0,1]$ to summarize the PIT values.\n- Use a chi-square goodness-of-fit test comparing the observed bin counts against the uniform expected counts. Clearly state the decision rule in terms of a significance level $\\alpha$.\n- To eliminate randomness and ensure reproducibility, generate a deterministic synthetic dataset representative of the ideal calibrated setting as follows. Set an integer $N \\ge 1$. Define grid points $u_i = \\frac{i - 1/2}{N}$ for $i = 1,2,\\dots,N$. Map these to “true” observations from a standard normal distribution by $y_i = \\Phi^{-1}(u_i)$, where $\\Phi^{-1}(\\cdot)$ is the quantile function (inverse cumulative distribution function) of $\\mathcal{N}(0,1)$. This construction produces a deterministic sample that is indistinguishable, in distribution, from draws $Y \\sim \\mathcal{N}(0,1)$ when used under the PIT framework.\n- Given a normal predictive family $F_{\\text{pred}}(y) = \\Phi\\!\\left(\\frac{y - \\mu_{\\text{pred}}}{\\sigma_{\\text{pred}}}\\right)$ with parameters $\\mu_{\\text{pred}} \\in \\mathbb{R}$ and $\\sigma_{\\text{pred}}  0$, compute PIT values $u_i^{\\text{pred}} = F_{\\text{pred}}(y_i)$ and perform the histogram-based chi-square test against uniformity.\n\nYour program must implement this procedure and evaluate the following test suite of parameter settings. For each case, report a boolean indicating whether the null hypothesis of uniform PIT (calibration) is rejected at significance level $\\alpha$ using the chi-square goodness-of-fit test with $B$ bins. Use the deterministic construction described above; do not use any pseudorandom number generator.\n\nTest suite (each tuple is $(\\mu_{\\text{pred}}, \\sigma_{\\text{pred}}, N, B, \\alpha)$):\n- Case A (happy path, exact calibration): $(0, 1, 20000, 20, 0.01)$.\n- Case B (systematic mean error): $(0.75, 1, 20000, 20, 0.01)$.\n- Case C (underdispersion): $(0, 0.6, 20000, 20, 0.01)$.\n- Case D (overdispersion): $(0, 1.6, 20000, 20, 0.01)$.\n\nFinal output requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test suite, for example, $[r_A,r_B,r_C,r_D]$ where each $r_{\\cdot}$ is a boolean. No additional text should be printed.",
            "solution": "The problem statement is assessed for validity before a solution is attempted.\n\n### Step 1: Extract Givens\n- A random variable $Z$ is standard normal, $Z \\sim \\mathcal{N}(0,1)$.\n- Its cumulative distribution function (CDF) is $\\Phi(z) = \\int_{-\\infty}^{z} \\frac{1}{\\sqrt{2\\pi}} e^{-t^2/2} \\, dt$.\n- A new random variable $U$ is defined via the probability integral transform (PIT): $U = \\Phi(Z)$.\n- **Task 1**: Derive from first principles that $U$ is distributed as a standard uniform random variable, $U \\sim \\mathrm{Unif}(0,1)$. The derivation must be based on the definition of a CDF and properties of strictly increasing functions.\n- **Task 2**: Design and implement a deterministic, reproducible chi-square goodness-of-fit test for model calibration.\n- The test uses a histogram of PIT values with $B$ equal-width bins on $[0,1]$.\n- The decision rule is based on a significance level $\\alpha$.\n- A deterministic synthetic dataset is generated with $N$ points:\n    - Grid points: $u_i = \\frac{i - 1/2}{N}$ for $i = 1,2,\\dots,N$.\n    - \"True\" observations: $y_i = \\Phi^{-1}(u_i)$, where $\\Phi^{-1}(\\cdot)$ is the quantile function of $\\mathcal{N}(0,1)$.\n- A predictive model family is given by the CDF $F_{\\text{pred}}(y) = \\Phi\\!\\left(\\frac{y - \\mu_{\\text{pred}}}{\\sigma_{\\text{pred}}}\\right)$.\n- Predictive PIT values are computed as $u_i^{\\text{pred}} = F_{\\text{pred}}(y_i)$.\n- The program must evaluate the calibration test for four specific cases and report a boolean for each, indicating if the null hypothesis of uniformity is rejected.\n- **Test Suite**:\n    - Case A: $(\\mu_{\\text{pred}}, \\sigma_{\\text{pred}}, N, B, \\alpha) = (0, 1, 20000, 20, 0.01)$.\n    - Case B: $(\\mu_{\\text{pred}}, \\sigma_{\\text{pred}}, N, B, \\alpha) = (0.75, 1, 20000, 20, 0.01)$.\n    - Case C: $(\\mu_{\\text{pred}}, \\sigma_{\\text{pred}}, N, B, \\alpha) = (0, 0.6, 20000, 20, 0.01)$.\n    - Case D: $(\\mu_{\\text{pred}}, \\sigma_{\\text{pred}}, N, B, \\alpha) = (0, 1.6, 20000, 20, 0.01)$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is founded on the probability integral transform, a cornerstone of statistical theory. The application to model calibration and the use of the chi-square goodness-of-fit test are standard, well-established practices in statistics and machine learning. The deterministic sample generation is a valid technique in quasi-Monte Carlo methods to ensure reproducibility and reduce sampling error in simulations.\n- **Well-Posed**: The problem is clearly stated and provides all necessary information. Task 1 is a standard theoretical proof. Task 2 provides a complete specification for the algorithm to be implemented, including all parameters for each test case.\n- **Objective**: The problem is stated in precise mathematical and statistical language, free of ambiguity or subjective claims.\n\nThe problem does not violate any of the invalidity criteria. It is scientifically sound, formally specified, complete, and feasible.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n### Task 1: Theoretical Verification of the Probability Integral Transform\n\nLet $Z$ be a random variable with a continuous and strictly increasing cumulative distribution function (CDF), $F_Z(z) = P(Z \\le z)$. In this specific problem, $Z \\sim \\mathcal{N}(0,1)$ and its CDF is denoted by $\\Phi(z)$. The function $\\Phi: \\mathbb{R} \\to (0,1)$ is continuous and strictly increasing.\n\nWe define a new random variable $U = \\Phi(Z)$. To determine the distribution of $U$, we derive its CDF, denoted $F_U(u) = P(U \\le u)$.\n\nThe range of the function $\\Phi(\\cdot)$ is the open interval $(0,1)$. Therefore, the random variable $U$ can only take values in $(0,1)$.\n- For any $u \\le 0$, it is impossible for $U \\le u$, so $P(U \\le u) = 0$.\n- For any $u \\ge 1$, it is certain that $U \\le u$, so $P(U \\le u) = 1$.\n\nNow, consider $u \\in (0,1)$. By definition,\n$$ F_U(u) = P(U \\le u) $$\nSubstituting the definition of $U$:\n$$ F_U(u) = P(\\Phi(Z) \\le u) $$\nSince $\\Phi(\\cdot)$ is a strictly increasing function, its inverse, the quantile function $\\Phi^{-1}(\\cdot)$, exists and is also strictly increasing. We can apply $\\Phi^{-1}$ to both sides of the inequality within the probability operator without changing the direction of the inequality:\n$$ F_U(u) = P(\\Phi^{-1}(\\Phi(Z)) \\le \\Phi^{-1}(u)) $$\nBy the property of inverse functions, $\\Phi^{-1}(\\Phi(Z)) = Z$. Thus, we have:\n$$ F_U(u) = P(Z \\le \\Phi^{-1}(u)) $$\nThe expression $P(Z \\le z_0)$ for some value $z_0$ is, by definition, the CDF of $Z$ evaluated at $z_0$. In our case, $z_0 = \\Phi^{-1}(u)$. Therefore,\n$$ F_U(u) = \\Phi(\\Phi^{-1}(u)) $$\nAgain applying the property of inverse functions, $\\Phi(\\Phi^{-1}(u)) = u$. So, for $u \\in (0,1)$,\n$$ F_U(u) = u $$\nCombining these results, the complete CDF of $U$ is:\n$$ F_U(u) = \\begin{cases} 0  \\text{if } u \\le 0 \\\\ u  \\text{if } 0  u  1 \\\\ 1  \\text{if } u \\ge 1 \\end{cases} $$\nThis is the CDF of the standard uniform distribution, $\\mathrm{Unif}(0,1)$. The derivation confirms from first principles that if $Z \\sim \\mathcal{N}(0,1)$, then $U = \\Phi(Z) \\sim \\mathrm{Unif}(0,1)$. This result holds more generally for any continuous random variable.\n\n### Task 2: Calibration Test Design and Implementation\nThe problem requires designing and implementing a deterministic test for the calibration of a probabilistic forecast. A forecast is calibrated if its PIT values are uniformly distributed on $[0,1]$.\n\n**Deterministic Dataset Construction**:\nTo create a synthetic dataset that is perfectly representative of a standard normal distribution, we avoid random sampling. Instead, we generate $N$ quantiles, $y_i$, corresponding to a uniform grid of probabilities $u_i$.\n1.  Define a uniform grid of $N$ probability values: $u_i = \\frac{i - 1/2}{N}$ for $i \\in \\{1, 2, \\dots, N\\}$.\n2.  Compute the corresponding quantiles from the standard normal distribution: $y_i = \\Phi^{-1}(u_i)$. This set $\\{y_i\\}$ serves as our ground-truth observations.\n\n**Calibration Test Procedure**:\nGiven a predictive model with CDF $F_{\\text{pred}}(y)$, we test its calibration against the observations $\\{y_i\\}$.\n1.  For each observation $y_i$, compute the PIT value using the model's predictive CDF: $u_i^{\\text{pred}} = F_{\\text{pred}}(y_i)$.\n2.  If the model represented by $F_{\\text{pred}}$ is perfectly calibrated (i.e., it matches the true data-generating process, $\\Phi$), then the set of values $\\{u_i^{\\text{pred}}\\}$ will be uniformly distributed. Specifically, if $F_{\\text{pred}}(y) = \\Phi(y)$, then $u_i^\\text{pred} = \\Phi(y_i) = \\Phi(\\Phi^{-1}(u_i)) = u_i$, producing a perfect grid. Any deviation of $F_{\\text{pred}}$ from $\\Phi$ will distort this uniformity.\n3.  To quantify this distortion, we use a chi-square goodness-of-fit test. The interval $[0,1]$ is divided into $B$ equal-width bins.\n4.  The observed count, $O_k$, is the number of $u_i^{\\text{pred}}$ values that fall into the $k$-th bin, where $k \\in \\{1, 2, \\dots, B\\}$.\n5.  Under the null hypothesis $H_0$ that the $u_i^{\\text{pred}}$ values are uniformly distributed, the expected count for each bin is $E_k = N/B$.\n6.  The chi-square test statistic is calculated as:\n    $$ \\chi^2 = \\sum_{k=1}^{B} \\frac{(O_k - E_k)^2}{E_k} $$\n7.  This statistic follows a chi-square distribution with $df = B-1$ degrees of freedom.\n8.  **Decision Rule**: We compute the p-value, which is the probability of observing a test statistic at least as extreme as the one calculated, assuming $H_0$ is true: $p = P(\\chi^2_{df} \\ge \\chi^2)$. The null hypothesis of calibration is rejected if the p-value is less than the specified significance level $\\alpha$. That is, reject $H_0$ if $p  \\alpha$.\n\n**Implementation Logic**:\nThe procedure is applied to each of the four cases, and the Python code below implements this logic.\n- **Case A (Exact Calibration)**: $\\mu_{\\text{pred}} = 0, \\sigma_{\\text{pred}} = 1$. The predictive CDF matches the true data-generating process. The PIT values will form a perfect grid, so each bin will contain exactly $N/B$ points. Thus, $O_k = E_k$ for all $k$, leading to $\\chi^2 = 0$, $p=1$. Since $1 \\not 0.01$, $H_0$ is not rejected.\n- **Case B (Systematic Mean Error)**: $\\mu_{\\text{pred}} = 0.75, \\sigma_{\\text{pred}} = 1$. The forecast is systematically biased. The PIT values will be shifted, leading to a non-uniform histogram. The $\\chi^2$ statistic will be large, and the p-value is expected to be less than $\\alpha$, leading to rejection.\n- **Case C (Underdispersion)**: $\\mu_{\\text{pred}} = 0, \\sigma_{\\text{pred}} = 0.6$. The forecast is too confident (narrow). PIT values will be pushed toward the extremes of $0$ and $1$, creating a U-shaped distribution. The test will detect this non-uniformity, leading to rejection.\n- **Case D (Overdispersion)**: $\\mu_{\\text{pred}} = 0, \\sigma_{\\text{pred}} = 1.6$. The forecast is not confident enough (wide). PIT values will be concentrated around the median of $0.5$, creating a bell-shaped distribution. The test will detect this, leading to rejection.\n\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, chi2\n\ndef solve():\n    \"\"\"\n    Implements the deterministic calibration test for a series of parameter settings.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (mu_pred, sigma_pred, N, B, alpha)\n    test_cases = [\n        (0.0, 1.0, 20000, 20, 0.01),  # Case A: happy path, exact calibration\n        (0.75, 1.0, 20000, 20, 0.01), # Case B: systematic mean error\n        (0.0, 0.6, 20000, 20, 0.01),  # Case C: underdispersion\n        (0.0, 1.6, 20000, 20, 0.01),  # Case D: overdispersion\n    ]\n\n    results = []\n    for case in test_cases:\n        mu_pred, sigma_pred, N, B, alpha = case\n\n        # Step 1: Generate the deterministic synthetic dataset.\n        # This creates a set of points that are perfectly representative of quantiles\n        # from a N(0,1) distribution, avoiding random sampling noise.\n        # The grid points u_i are from a Unif(0,1) distribution by construction.\n        u_i = (np.arange(1, N + 1) - 0.5) / N\n        \n        # The \"true\" observations y_i are the corresponding quantiles from N(0,1).\n        # norm.ppf is the inverse CDF (quantile function) of the normal distribution.\n        # With default loc=0 and scale=1, it is Phi^{-1}.\n        y_i = norm.ppf(u_i)\n\n        # Step 2: Compute PIT values from the predictive model.\n        # The predictive CDF is F_pred(y) = Phi((y - mu_pred) / sigma_pred).\n        # norm.cdf is the CDF of the normal distribution. With default loc=0 and\n        # scale=1, it is Phi.\n        u_i_pred = norm.cdf((y_i - mu_pred) / sigma_pred)\n\n        # Step 3: Perform the chi-square goodness-of-fit test.\n        # Create a histogram of the predictive PIT values u_i_pred.\n        # The range is [0, 1] and there are B equal-width bins.\n        observed_counts, _ = np.histogram(u_i_pred, bins=B, range=(0, 1))\n\n        # Under the null hypothesis of uniformity, the expected count in each bin is N/B.\n        expected_counts = N / B\n\n        # Calculate the chi-square statistic.\n        # Note: If expected_counts is 0, this would lead to division by zero.\n        # However, N and B are positive integers, so expected_counts  0.\n        chi2_statistic = np.sum((observed_counts - expected_counts)**2 / expected_counts)\n\n        # The degrees of freedom for the chi-square test is B - 1.\n        df = B - 1\n\n        # Calculate the p-value.\n        # The survival function (sf) is 1 - cdf, which gives P(X  x).\n        # This is the probability of observing a chi2 statistic this large or larger.\n        p_value = chi2.sf(chi2_statistic, df)\n\n        # Step 4: Make a decision based on the significance level alpha.\n        # Reject the null hypothesis (that the PITs are uniform) if the p-value\n        # is less than alpha.\n        is_rejected = p_value  alpha\n        results.append(is_rejected)\n\n    # Final print statement in the exact required format.\n    # The boolean values are automatically converted to strings 'True' or 'False'.\n    return f\"[{','.join(map(str, [b.item() for b in results]))}]\"\n\n# The problem requires the output of the program, not the program itself.\n# We run the function to get the string output for the answer tag.\n# solve()\n```",
            "answer": "[False,True,True,True]"
        }
    ]
}