{
    "hands_on_practices": [
        {
            "introduction": "我们将从一个经典的统计推断问题开始，这个问题在历史上被称为“德国坦克问题”。想象一下，你需要根据观察到的部分序列号来估计敌方生产的总坦克数量。这个问题可以被建模为从一个均匀分布 $U(0, \\theta)$ 中抽样，其中未知的上限 $\\theta$ 就是你需要估计的总量。这个练习将引导你推导参数 $\\theta$ 的最大似然估计（MLE），并进一步探索其统计性质，揭示一个深刻的见解：虽然最大似然法非常强大，但它得到的估计量未必总是最优的。通过这个练习，你将掌握使用均方误差（MSE）等核心标准来推导和评估估计量的技能。",
            "id": "3111021",
            "problem": "一个数据集由从区间 $[0,\\theta]$ 上的连续均匀分布中抽取的独立同分布观测值 $X_{1}, X_{2}, \\ldots, X_{n}$ 组成，其上端点 $\\theta$ 未知，下端点 $0$ 已知。使用独立性、概率密度函数、似然的核心定义以及顺序统计量 $X_{(n)}=\\max\\{X_{1},\\ldots,X_{n}\\}$，按以下步骤进行：\n\n1. 通过在由均匀分布所蕴含的支撑集约束下，对似然函数 $L(\\theta; x_{1},\\ldots,x_{n})$ 在 $\\theta>0$ 上进行最大化，推导出 $\\theta$ 的最大似然估计量 (MLE) $\\hat{\\theta}_{\\mathrm{MLE}}$。\n\n2. 在平方误差损失 $L(\\hat{\\theta},\\theta)=(\\hat{\\theta}-\\theta)^{2}$ 下，计算 MLE 的风险（损失的期望）$R(\\hat{\\theta}_{\\mathrm{MLE}})=\\mathbb{E}\\big[(\\hat{\\theta}_{\\mathrm{MLE}}-\\theta)^{2}\\big]$，以 $n$ 和 $\\theta$ 的函数形式给出其闭式表达式。\n\n3. 考虑形式为 $\\hat{\\theta}_{c}=c\\,X_{(n)}$ 的单参数偏差校正估计量族，其中乘法常数 $c>0$。确定使均方误差 $\\mathbb{E}\\big[(\\hat{\\theta}_{c}-\\theta)^{2}\\big]$ 在 $c>0$ 上最小化的值 $c^{\\ast}$。以闭式形式给出最终的最小化均方误差，并证明对于所有整数 $n\\geq 1$ 和所有 $\\theta>0$，它都严格小于 MLE 的风险。\n\n按顺序报告四个闭式表达式：$\\hat{\\theta}_{\\mathrm{MLE}}$、$R(\\hat{\\theta}_{\\mathrm{MLE}})$、最优常数 $c^{\\ast}$，以及在 $c^{\\ast}$ 处的最小化均方误差。不需要数值近似。",
            "solution": "该问题是有效的，因为它是统计学习领域参数估计中的一个标准的、适定的问题。它具有科学依据、是客观的，并包含了唯一解所需的所有信息。\n\n设独立同分布 (i.i.d.) 的观测值为 $X_{1}, X_{2}, \\ldots, X_{n}$，它们从连续均匀分布 $U(0, \\theta)$ 中抽取。单个观测值 $X_{i}$ 的概率密度函数 (PDF) 为：\n$$f(x_i; \\theta) = \\frac{1}{\\theta} \\mathbb{I}(0 \\le x_i \\le \\theta)$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。\n\n### 1. 最大似然估计量 (MLE) 的推导\n\n似然函数 $L(\\theta; x_{1}, \\ldots, x_{n})$ 是观测样本的联合概率密度。根据独立同分布的假设，它是各个概率密度函数 (PDF) 的乘积：\n$$L(\\theta; \\mathbf{x}) = \\prod_{i=1}^{n} f(x_i; \\theta) = \\prod_{i=1}^{n} \\left[ \\frac{1}{\\theta} \\mathbb{I}(0 \\le x_i \\le \\theta) \\right]$$\n该表达式可以分为两部分：\n$$L(\\theta; \\mathbf{x}) = \\left( \\frac{1}{\\theta} \\right)^{n} \\prod_{i=1}^{n} \\mathbb{I}(0 \\le x_i \\le \\theta)$$\n指示函数的乘积为 $1$ 当且仅当对于 $i=1, \\ldots, n$ 所有条件 $0 \\le x_i \\le \\theta$ 都满足。这等价于联合条件 $0 \\le \\min\\{x_1, \\ldots, x_n\\}$ 且 $\\max\\{x_1, \\ldots, x_n\\} \\le \\theta$。令 $x_{(n)} = \\max\\{x_1, \\ldots, x_n\\}$。条件 $x_{(n)} \\le \\theta$ 意味着对所有 $i$ 都有 $x_i \\le \\theta$。条件 $0 \\le \\min\\{x_i\\}$ 由问题设定保证。因此，似然函数可以写为：\n$$L(\\theta; \\mathbf{x}) = \\frac{1}{\\theta^n} \\mathbb{I}(x_{(n)} \\le \\theta)$$\n为了找到 MLE $\\hat{\\theta}_{\\mathrm{MLE}}$，我们必须关于 $\\theta$ 最大化 $L(\\theta; \\mathbf{x})$。指示函数 $\\mathbb{I}(x_{(n)} \\le \\theta)$ 将 $\\theta$ 的定义域限制在区间 $[x_{(n)}, \\infty)$。在这个区间上，对于 $\\theta > 0$，$\\frac{1}{\\theta^n}$ 是 $\\theta$ 的一个严格递减函数。要最大化一个递减函数，我们必须为其参数选择尽可能小的值。在约束 $\\theta \\ge x_{(n)}$ 下，$\\theta$ 能取的最小值是 $x_{(n)}$。因此，$\\theta$ 的 MLE 是：\n$$\\hat{\\theta}_{\\mathrm{MLE}} = x_{(n)} = \\max\\{X_1, \\ldots, X_n\\}$$\n\n### 2. MLE 的风险\n\n风险 $R(\\hat{\\theta}_{\\mathrm{MLE}})$ 是估计量的均方误差 (MSE)，定义为 $R(\\hat{\\theta}_{\\mathrm{MLE}}) = \\mathbb{E}\\big[(\\hat{\\theta}_{\\mathrm{MLE}} - \\theta)^{2}\\big]$。要计算它，我们首先需要估计量 $\\hat{\\theta}_{\\mathrm{MLE}} = X_{(n)}$ 的概率分布。\n\n令 $Y = X_{(n)}$。$Y$ 的累积分布函数 (CDF) 是：\n$$F_Y(y) = P(Y \\le y) = P(X_{(n)} \\le y) = P(X_1 \\le y, \\ldots, X_n \\le y)$$\n由于 $X_i$ 是独立同分布的，$F_Y(y) = \\prod_{i=1}^{n} P(X_i \\le y) = (P(X_1 \\le y))^n$。单个 $X_i \\sim U(0, \\theta)$ 的 CDF 是 $F_{X_i}(x) = x/\\theta$ (对于 $0 \\le x \\le \\theta$)。因此，对于 $0 \\le y \\le \\theta$：\n$$F_Y(y) = \\left(\\frac{y}{\\theta}\\right)^n$$\n$Y$ 的 PDF 是其 CDF 的导数：\n$$f_Y(y) = \\frac{d}{dy}F_Y(y) = \\frac{d}{dy}\\left(\\frac{y^n}{\\theta^n}\\right) = \\frac{ny^{n-1}}{\\theta^n}, \\quad \\text{for } 0 \\le y \\le \\theta$$\nMSE 可以展开为 $\\mathbb{E}[(\\hat{\\theta}_{\\mathrm{MLE}} - \\theta)^2] = \\mathbb{E}[X_{(n)}^2] - 2\\theta\\mathbb{E}[X_{(n)}] + \\theta^2$。我们计算 $X_{(n)}$ 的前两阶矩：\n$$\\mathbb{E}[X_{(n)}] = \\int_{0}^{\\theta} y f_Y(y) dy = \\int_{0}^{\\theta} y \\frac{ny^{n-1}}{\\theta^n} dy = \\frac{n}{\\theta^n} \\int_{0}^{\\theta} y^n dy = \\frac{n}{\\theta^n} \\left[\\frac{y^{n+1}}{n+1}\\right]_0^{\\theta} = \\frac{n\\theta}{n+1}$$\n$$\\mathbb{E}[X_{(n)}^2] = \\int_{0}^{\\theta} y^2 f_Y(y) dy = \\int_{0}^{\\theta} y^2 \\frac{ny^{n-1}}{\\theta^n} dy = \\frac{n}{\\theta^n} \\int_{0}^{\\theta} y^{n+1} dy = \\frac{n}{\\theta^n} \\left[\\frac{y^{n+2}}{n+2}\\right]_0^{\\theta} = \\frac{n\\theta^2}{n+2}$$\n将这些代入 MSE 表达式：\n$$R(\\hat{\\theta}_{\\mathrm{MLE}}) = \\frac{n\\theta^2}{n+2} - 2\\theta\\left(\\frac{n\\theta}{n+1}\\right) + \\theta^2 = \\theta^2 \\left(\\frac{n}{n+2} - \\frac{2n}{n+1} + 1\\right)$$\n通分到公分母 $(n+1)(n+2)$：\n$$R(\\hat{\\theta}_{\\mathrm{MLE}}) = \\theta^2 \\left(\\frac{n(n+1) - 2n(n+2) + (n+1)(n+2)}{(n+1)(n+2)}\\right)$$\n$$R(\\hat{\\theta}_{\\mathrm{MLE}}) = \\theta^2 \\left(\\frac{n^2+n - 2n^2-4n + n^2+3n+2}{(n+1)(n+2)}\\right) = \\theta^2 \\left(\\frac{2}{(n+1)(n+2)}\\right) = \\frac{2\\theta^2}{(n+1)(n+2)}$$\n\n### 3. 最优偏差校正估计量\n\n我们考虑形式为 $\\hat{\\theta}_c = cX_{(n)}$ 的估计量，并寻求找到使 MSE $\\mathbb{E}[(\\hat{\\theta}_c - \\theta)^2]$ 最小化的常数 $c^*$。\n$$\\text{MSE}(\\hat{\\theta}_c) = \\mathbb{E}[(cX_{(n)} - \\theta)^2] = \\mathbb{E}[c^2X_{(n)}^2 - 2c\\theta X_{(n)} + \\theta^2]$$\n使用期望的线性性质和上面计算出的矩：\n$$\\text{MSE}(\\hat{\\theta}_c) = c^2\\mathbb{E}[X_{(n)}^2] - 2c\\theta\\mathbb{E}[X_{(n)}] + \\theta^2 = c^2\\left(\\frac{n\\theta^2}{n+2}\\right) - 2c\\theta\\left(\\frac{n\\theta}{n+1}\\right) + \\theta^2$$\n$$\\text{MSE}(\\hat{\\theta}_c) = \\theta^2 \\left[c^2 \\frac{n}{n+2} - c \\frac{2n}{n+1} + 1\\right]$$\n这是一个关于 $c$ 的二次函数，记为 $g(c)$。为了找到最小值，我们对 $c$求导并令结果为零：\n$$\\frac{d}{dc}g(c) = \\theta^2 \\left[2c \\frac{n}{n+2} - \\frac{2n}{n+1}\\right] = 0$$\n假设 $n \\ge 1$，我们可以解出 $c$：\n$$2c \\frac{n}{n+2} = \\frac{2n}{n+1} \\implies c = \\frac{n+2}{n+1}$$\n二阶导数 $\\frac{d^2}{dc^2}g(c) = \\theta^2 \\frac{2n}{n+2}$ 对于 $n \\ge 1$ 为正，这确认了该值 $c^*$ 给出了一个最小值。\n$$c^* = \\frac{n+2}{n+1}$$\n为了找到最小化的 MSE，我们将 $c^*$ 代回 MSE 公式中：\n$$\\text{MSE}(\\hat{\\theta}_{c^*}) = \\theta^2 \\left[ \\left(\\frac{n+2}{n+1}\\right)^2 \\frac{n}{n+2} - \\left(\\frac{n+2}{n+1}\\right) \\frac{2n}{n+1} + 1 \\right]$$\n$$\\text{MSE}(\\hat{\\theta}_{c^*}) = \\theta^2 \\left[ \\frac{n(n+2)}{(n+1)^2} - \\frac{2n(n+2)}{(n+1)^2} + 1 \\right] = \\theta^2 \\left[ \\frac{-n(n+2) + (n+1)^2}{(n+1)^2} \\right]$$\n$$\\text{MSE}(\\hat{\\theta}_{c^*}) = \\theta^2 \\left[ \\frac{-n^2-2n + n^2+2n+1}{(n+1)^2} \\right] = \\frac{\\theta^2}{(n+1)^2}$$\n最后，我们必须证明对于所有 $n \\ge 1$ 和 $\\theta > 0$，这个最小化的 MSE 严格小于 MLE 的风险：\n$$\\frac{\\theta^2}{(n+1)^2}  \\frac{2\\theta^2}{(n+1)(n+2)}$$\n由于 $\\theta^2  0$ 且 $n+1  0$，我们可以简化不等式：\n$$\\frac{1}{n+1}  \\frac{2}{n+2} \\implies n+2  2(n+1) \\implies n+2  2n+2 \\implies 0  n$$\n这个不等式对所有整数 $n \\ge 1$ 都成立，因此证明完成。\n\n所需的四个表达式是：\n1. $\\hat{\\theta}_{\\mathrm{MLE}} = X_{(n)}$\n2. $R(\\hat{\\theta}_{\\mathrm{MLE}}) = \\frac{2\\theta^2}{(n+1)(n+2)}$\n3. $c^* = \\frac{n+2}{n+1}$\n4. 最小化 MSE = $\\frac{\\theta^2}{(n+1)^2}$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nX_{(n)}  \\frac{2\\theta^2}{(n+1)(n+2)}  \\frac{n+2}{n+1}  \\frac{\\theta^2}{(n+1)^2}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在掌握了参数估计的基础后，我们转向一个在数据科学实践中至关重要的话题：理解数据的内在“形状”。一个常见的预处理步骤是对特征进行标准化（z-score变换），使其均值为0，方差为1，但这往往被误解为数据变得“正态化”了。本练习将通过计算峰度（kurtosis）这一高阶矩，来定量比较均匀分布和正态分布在标准化之后其分布形状的差异，特别是尾部的“厚重”程度。这个练习将教会你超越均值和方差，去审视和理解数据分布的更深层次特性。",
            "id": "3110941",
            "problem": "一位数据工程师通过对每个特征进行标准化（z-score 化），使其均值为零、方差为一，来为统计学习流程准备特征。设 $X$ 是一个在区间 $[a,b]$ 上服从均匀分布的连续特征（其中 $a  b$），而另一个特征 $Y$ 服从正态分布。你的任务是推导并解释这两个特征在标准化后其分布形状的一个关键差异。\n\n具体来说，推导标准化均匀变量 $Z_X$ 的总体超额峰度 $\\gamma_2(Z_X)$ 和标准化正态变量 $Z_Y$ 的总体超额峰度 $\\gamma_2(Z_Y)$。然后，计算并解释差值 $\\Delta = \\gamma_2(Z_X) - \\gamma_2(Z_Y)$。你的最终答案应该是单个数值 $\\Delta$。超额峰度定义为 $\\gamma_2 = \\frac{\\mathbb{E}[(W - \\mu)^4]}{(\\sigma^2)^2} - 3$。",
            "solution": "该问题被评估为有效。它在科学上基于标准的概率论和统计学，问题阐述清晰，提供了所有必要的定义，并且表述客观。它要求推导和解释标准的统计量。\n\n该问题要求推导标准化均匀随机变量的总体超额峰度 $\\gamma_{2}(Z_{X})$ 和标准化正态随机变量的总体超额峰度 $\\gamma_{2}(Z_{Y})$。最终目标是计算并解释它们的差值 $\\Delta = \\gamma_{2}(Z_{X}) - \\gamma_{2}(Z_{Y})$。\n\n设 $W$ 是一个连续随机变量。标准化变量 $Z_W$ 定义为 $Z_{W} = (W - \\mathbb{E}[W]) / \\sqrt{\\operatorname{Var}(W)}$。根据定义，一个标准化变量的均值为 $0$，方差为 $1$。\n$\\mathbb{E}[Z_W] = \\mathbb{E}\\left[\\frac{W - \\mathbb{E}[W]}{\\sqrt{\\operatorname{Var}(W)}}\\right] = \\frac{1}{\\sqrt{\\operatorname{Var}(W)}} (\\mathbb{E}[W] - \\mathbb{E}[\\mathbb{E}[W]]) = \\frac{1}{\\sqrt{\\operatorname{Var}(W)}} (\\mathbb{E}[W] - \\mathbb{E}[W]) = 0$。\n$\\operatorname{Var}(Z_W) = \\operatorname{Var}\\left(\\frac{W - \\mathbb{E}[W]}{\\sqrt{\\operatorname{Var}(W)}}\\right) = \\frac{1}{\\operatorname{Var}(W)} \\operatorname{Var}(W - \\mathbb{E}[W]) = \\frac{1}{\\operatorname{Var}(W)} \\operatorname{Var}(W) = 1$。\n\n峰度 $\\beta_{2}(W)$ 和超额峰度 $\\gamma_{2}(W)$ 定义如下：\n$$ \\beta_{2}(W) = \\frac{\\mathbb{E}\\!\\left[(W - \\mathbb{E}[W])^{4}\\right]}{\\left(\\operatorname{Var}(W)\\right)^{2}} $$\n$$ \\gamma_{2}(W) = \\beta_{2}(W) - 3 $$\n对于一个标准化变量 $Z_W$，这些公式可以简化。由于 $\\mathbb{E}[Z_W]=0$ 且 $\\operatorname{Var}(Z_W)=1$，峰度成为 $Z_W$ 的四阶矩：\n$$ \\beta_{2}(Z_W) = \\frac{\\mathbb{E}\\!\\left[(Z_W - 0)^{4}\\right]}{1^{2}} = \\mathbb{E}[Z_W^4] $$\n因此，超额峰度为 $\\gamma_{2}(Z_W) = \\mathbb{E}[Z_W^4] - 3$。\n\n首先，我们推导标准化正态变量的超额峰度 $\\gamma_{2}(Z_{Y})$。\n变量 $Y$ 服从正态分布，$Y \\sim N(\\mu, \\sigma^2)$。其标准化变量为 $Z_{Y} = (Y - \\mathbb{E}[Y]) / \\sqrt{\\operatorname{Var}(Y)} = (Y - \\mu) / \\sigma$。根据正态分布的性质，$Z_Y$ 服从标准正态分布，$Z_Y \\sim N(0, 1)$，其概率密度函数 (PDF) 为 $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2)$。\n我们需要计算 $\\mathbb{E}[Z_Y^4]$：\n$$ \\mathbb{E}[Z_Y^4] = \\int_{-\\infty}^{\\infty} z^{4} \\phi(z) dz = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} z^{4} \\exp(-\\frac{z^{2}}{2}) dz $$\n我们使用分部积分法 $\\int u dv = uv - \\int v du$ 来求解此积分。设 $u = z^{3}$ 且 $dv = z \\exp(-z^{2}/2) dz$。则 $du = 3z^{2} dz$ 且 $v = -\\exp(-z^{2}/2)$。\n$$ \\int z^{4} \\exp(-\\frac{z^{2}}{2}) dz = -z^{3}\\exp(-\\frac{z^{2}}{2}) - \\int (-\\exp(-\\frac{z^{2}}{2}))(3z^{2}) dz = -z^{3}\\exp(-\\frac{z^{2}}{2}) + 3 \\int z^{2}\\exp(-\\frac{z^{2}}{2}) dz $$\n计算从 $-\\infty$到 $\\infty$ 的定积分：\n$$ \\int_{-\\infty}^{\\infty} z^{4} \\exp(-\\frac{z^{2}}{2}) dz = \\left[-z^{3}\\exp(-\\frac{z^{2}}{2})\\right]_{-\\infty}^{\\infty} + 3 \\int_{-\\infty}^{\\infty} z^{2}\\exp(-\\frac{z^{2}}{2}) dz $$\n边界项 $\\left[-z^{3}\\exp(-z^{2}/2)\\right]_{-\\infty}^{\\infty}$ 的值为 $0$。剩余的积分与 $Z_Y$ 的方差有关：\n$$ \\operatorname{Var}(Z_Y) = \\mathbb{E}[Z_Y^2] - (\\mathbb{E}[Z_Y])^2 = \\int_{-\\infty}^{\\infty} z^{2} \\phi(z) dz - 0^2 = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} z^{2} \\exp(-\\frac{z^{2}}{2}) dz $$\n由于我们知道 $\\operatorname{Var}(Z_Y)=1$，所以有 $\\int_{-\\infty}^{\\infty} z^{2} \\exp(-z^{2}/2) dz = \\sqrt{2\\pi}$。\n将此代回：\n$$ \\mathbb{E}[Z_Y^4] = \\frac{1}{\\sqrt{2\\pi}} \\left( 3 \\int_{-\\infty}^{\\infty} z^{2}\\exp(-\\frac{z^{2}}{2}) dz \\right) = \\frac{3}{\\sqrt{2\\pi}} (\\sqrt{2\\pi}) = 3 $$\n因此，标准正态分布的峰度是 $\\beta_{2}(Z_{Y}) = 3$。其超额峰度为：\n$$ \\gamma_{2}(Z_{Y}) = \\beta_{2}(Z_{Y}) - 3 = 3 - 3 = 0 $$\n\n接下来，我们推导标准化均匀变量的超额峰度 $\\gamma_{2}(Z_{X})$。\n变量 $X$ 服从均匀分布，$X \\sim U(a,b)$。其概率密度函数为 $f_X(x) = \\frac{1}{b-a}$，其中 $x \\in [a,b]$。\n均值为 $\\mathbb{E}[X] = \\frac{a+b}{2}$，方差为 $\\operatorname{Var}(X) = \\frac{(b-a)^2}{12}$。\n标准化变量为 $Z_X = \\frac{X - \\mathbb{E}[X]}{\\sqrt{\\operatorname{Var}(X)}} = \\frac{X - (a+b)/2}{(b-a)/\\sqrt{12}}$。\n为简化 $\\mathbb{E}[Z_X^4]$ 的计算，我们可以考虑将 $X$ 线性变换为一个在区间 $[-1, 1]$ 上的变量 $U$。令 $U = \\frac{X - (a+b)/2}{(b-a)/2}$。该变量 $U$ 在 $[-1, 1]$ 上均匀分布，其概率密度函数为 $f_U(u) = 1/2$，其中 $u \\in [-1, 1]$。\n我们可以用 $U$ 来表示 $Z_X$：\n$$ Z_X = \\frac{U \\cdot (b-a)/2}{(b-a)/\\sqrt{12}} = U \\frac{\\sqrt{12}}{2} = U \\frac{2\\sqrt{3}}{2} = U\\sqrt{3} $$\n现在我们可以计算 $Z_X$ 的四阶矩：\n$$ \\mathbb{E}[Z_X^4] = \\mathbb{E}[(U\\sqrt{3})^4] = \\mathbb{E}[9U^4] = 9\\mathbb{E}[U^4] $$\n我们根据定义计算 $\\mathbb{E}[U^4]$：\n$$ \\mathbb{E}[U^4] = \\int_{-1}^{1} u^{4} f_U(u) du = \\int_{-1}^{1} u^{4} \\left(\\frac{1}{2}\\right) du = \\frac{1}{2} \\left[ \\frac{u^5}{5} \\right]_{-1}^{1} = \\frac{1}{10} [1^5 - (-1)^5] = \\frac{1}{10} (1 - (-1)) = \\frac{2}{10} = \\frac{1}{5} $$\n因此，$Z_X$ 的四阶矩是 $\\mathbb{E}[Z_X^4] = 9 \\times \\frac{1}{5} = \\frac{9}{5}$。\n标准化均匀分布的峰度是 $\\beta_{2}(Z_X) = \\frac{9}{5}$。其超额峰度为：\n$$ \\gamma_{2}(Z_{X}) = \\beta_{2}(Z_{X}) - 3 = \\frac{9}{5} - 3 = \\frac{9-15}{5} = -\\frac{6}{5} $$\n\n最后，我们计算差值 $\\Delta$：\n$$ \\Delta = \\gamma_{2}(Z_{X}) - \\gamma_{2}(Z_{Y}) = -\\frac{6}{5} - 0 = -\\frac{6}{5} $$\n\n解释：\n超额峰度 $\\gamma_2$ 衡量一个分布相对于正态分布的“尾部厚重程度”，正态分布作为基准，其 $\\gamma_2 = 0$。\n正的超额峰度（$\\gamma_2 > 0$）表示一个尖峰态 (leptokurtic) 分布，这种分布比正态分布更尖峭，尾部更厚重。\n负的超额峰度（$\\gamma_2  0$）表示一个扁平峰态 (platykurtic) 分布，这种分布峰顶更平，尾部更轻薄。\n我们的结果 $\\gamma_{2}(Z_{X}) = -6/5 = -1.2$ 表明标准化均匀分布是扁平峰态的。这是因为均匀分布是有界的，其概率密度在有限区间外降为零，这意味着与无界的正态分布相比，它的尾部“更轻薄”（实际上没有尾部）。\n差值 $\\Delta = -6/5$ 是负数。这表明经过 z-score 化之后，均匀特征 $Z_X$ 的尾部比正态特征 $Z_Y$ 的尾部要轻薄得多。像 PCA 和 LDA 这样的常用方法对特征的分布可能很敏感，它们的理论性质通常是在正态性假设下推导出来的。在一个均匀分布的特征上使用这些方法，并暗中假设标准化使其“近似正态”，这将是一个很差的近似。具体来说，模型会错误地假设有界的均匀特征不可能出现的极端值具有非零概率。这突显了一个事实，即标准化可以中心化和缩放一个分布，但不会改变其基本形状，包括其峰度。\n\n$\\Delta$ 的单一数值是 $-\\frac{6}{5} = -1.2$。",
            "answer": "$$ \\boxed{-1.2} $$"
        },
        {
            "introduction": "最后，我们将理论与现代机器学习实践相结合，探索如何利用不同分布之间的深刻联系来构建实用工具。我们将介绍概率积分变换（Probability Integral Transform, PIT），这是一个强大的理论，它能将任何连续随机变量转换为标准均匀分布。本练习将向你展示如何巧妙地运用这一原理，为评估概率预测模型的“校准度”设计一个有效的测试。通过这个动手编程练习，你将把抽象的概率论知识转化为一个具体、可复现的数据科学工作流程，从而弥合理论与实践之间的鸿沟。",
            "id": "3110957",
            "problem": "给定一个随机变量 $Z$ 服从标准正态分布，记为 $Z \\sim \\mathcal{N}(0,1)$，其累积分布函数为 $ \\Phi(z) = \\int_{-\\infty}^{z} \\frac{1}{\\sqrt{2\\pi}} e^{-t^2/2} \\, dt$。考虑概率积分变换 (PIT)：定义 $U = \\Phi(Z)$。\n\n任务1（理论验证）：从累积分布函数的定义和 $ \\Phi(\\cdot)$ 的单调性出发，根据第一性原理推导 $U$ 服从标准均匀分布，记为 $U \\sim \\mathrm{Unif}(0,1)$。你的推导不能假设结论，必须仅使用累积分布函数的定义和严格递增函数的性质等核心定义。\n\n任务2（校准测试设计）：在对连续目标 $Y$ 进行概率预测时，模型会输出一个预测累积分布函数 $F(y)$。如果从真实数据生成过程中抽取 $Y$，并为每个预测-观测对计算 $U = F(Y)$，得到的 $U$ 值服从 $ \\mathrm{Unif}(0,1)$ 分布，则称该模型是经过校准的。请设计一个基于PIT直方图的确定性实用校准测试，具体如下：\n- 使用一个在区间 $[0,1]$ 上有 $B$ 个等宽箱的直方图来总结PIT值。\n- 使用卡方拟合优度检验，将观测到的箱计数与均匀分布下的期望计数进行比较。明确陈述在显著性水平 $\\alpha$ 下的决策规则。\n- 为消除随机性并确保可复现性，按如下方式生成一个代表理想校准情况的确定性合成数据集。设置一个整数 $N \\ge 1$。定义网格点 $u_i = \\frac{i - 1/2}{N}$，其中 $i = 1,2,\\dots,N$。通过 $y_i = \\Phi^{-1}(u_i)$ 将这些点映射为标准正态分布的“真实”观测值，其中 $\\Phi^{-1}(\\cdot)$ 是 $\\mathcal{N}(0,1)$ 的分位数函数（逆累积分布函数）。当在PIT框架下使用时，这种构造方法产生了一个在分布上与从 $Y \\sim \\mathcal{N}(0,1)$ 中抽取的样本无法区分的确定性样本。\n- 给定一个正态预测族 $F_{\\text{pred}}(y) = \\Phi\\!\\left(\\frac{y - \\mu_{\\text{pred}}}{\\sigma_{\\text{pred}}}\\right)$，其参数为 $\\mu_{\\text{pred}} \\in \\mathbb{R}$ 和 $\\sigma_{\\text{pred}}  0$，计算PIT值 $u_i^{\\text{pred}} = F_{\\text{pred}}(y_i)$，并对均匀性进行基于直方图的卡方检验。\n\n你的程序必须实现此过程，并评估以下参数设置的测试套件。对于每种情况，报告一个布尔值，指示在使用具有 $B$ 个箱的卡方拟合优度检验时，是否在显著性水平 $\\alpha$ 下拒绝了PIT均匀（校准）的原假设。使用上述确定性构造方法；不要使用任何伪随机数生成器。\n\n测试套件（每个元组为 $(\\mu_{\\text{pred}}, \\sigma_{\\text{pred}}, N, B, \\alpha)$）：\n- 情况A（理想情况，精确校准）：$(0, 1, 20000, 20, 0.01)$。\n- 情况B（系统性均值误差）：$(0.75, 1, 20000, 20, 0.01)$。\n- 情况C（弥散不足）：$(0, 0.6, 20000, 20, 0.01)$。\n- 情况D（过度弥散）：$(0, 1.6, 20000, 20, 0.01)$。\n\n最终输出要求：你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果顺序与测试套件相同，例如 $[r_A,r_B,r_C,r_D]$，其中每个 $r_{\\cdot}$ 是一个布尔值。不应打印任何额外文本。",
            "solution": "在尝试提供解决方案之前，先对问题陈述的有效性进行评估。\n\n### 第1步：提取已知信息\n- 一个随机变量 $Z$ 是标准正态的，$Z \\sim \\mathcal{N}(0,1)$。\n- 其累积分布函数 (CDF) 是 $\\Phi(z) = \\int_{-\\infty}^{z} \\frac{1}{\\sqrt{2\\pi}} e^{-t^2/2} \\, dt$。\n- 通过概率积分变换 (PIT) 定义一个新的随机变量 $U$：$U = \\Phi(Z)$。\n- **任务1**：从第一性原理出发，推导 $U$ 服从标准均匀分布，$U \\sim \\mathrm{Unif}(0,1)$。推导必须基于CDF的定义和严格递增函数的性质。\n- **任务2**：设计并实现一个用于模型校准的确定性、可复现的卡方拟合优度检验。\n- 该检验使用一个在 $[0,1]$ 上具有 $B$ 个等宽箱的PIT值直方图。\n- 决策规则基于显著性水平 $\\alpha$。\n- 生成一个包含 $N$ 个点的确定性合成数据集：\n    - 网格点：$u_i = \\frac{i - 1/2}{N}$，其中 $i = 1,2,\\dots,N$。\n    - “真实”观测值：$y_i = \\Phi^{-1}(u_i)$，其中 $\\Phi^{-1}(\\cdot)$ 是 $\\mathcal{N}(0,1)$ 的分位数函数。\n- 给定一个预测模型族，其CDF为 $F_{\\text{pred}}(y) = \\Phi\\!\\left(\\frac{y - \\mu_{\\text{pred}}}{\\sigma_{\\text{pred}}}\\right)$。\n- 预测PIT值计算为 $u_i^{\\text{pred}} = F_{\\text{pred}}(y_i)$。\n- 程序必须对四种特定情况评估校准检验，并为每种情况报告一个布尔值，指示是否拒绝了均匀性的原假设。\n- **测试套件**：\n    - 情况A：$(\\mu_{\\text{pred}}, \\sigma_{\\text{pred}}, N, B, \\alpha) = (0, 1, 20000, 20, 0.01)$。\n    - 情况B：$(\\mu_{\\text{pred}}, \\sigma_{\\text{pred}}, N, B, \\alpha) = (0.75, 1, 20000, 20, 0.01)$。\n    - 情况C：$(\\mu_{\\text{pred}}, \\sigma_{\\text{pred}}, N, B, \\alpha) = (0, 0.6, 20000, 20, 0.01)$。\n    - 情况D：$(\\mu_{\\text{pred}}, \\sigma_{\\text{pred}}, N, B, \\alpha) = (0, 1.6, 20000, 20, 0.01)$。\n\n### 第2步：使用提取的已知信息进行验证\n- **科学基础**：该问题基于概率积分变换，这是统计理论的基石。将其应用于模型校准以及使用卡方拟合优度检验是统计学和机器学习中的标准、成熟的做法。确定性样本生成是准蒙特卡洛方法中的一种有效技术，可确保可复现性并减少模拟中的抽样误差。\n- **定义明确**：问题陈述清晰，提供了所有必要信息。任务1是一个标准的理论证明。任务2为要实现的算法提供了完整的规范，包括每个测试用例的所有参数。\n- **客观性**：问题以精确的数学和统计语言陈述，没有歧义或主观论断。\n\n该问题不违反任何无效性标准。它科学合理、形式规范、完整且可行。\n\n### 第3步：结论与行动\n该问题有效。将提供解决方案。\n\n### 任务1：概率积分变换的理论验证\n\n设 $Z$ 是一个具有连续且严格递增的累积分布函数 (CDF) $F_Z(z) = P(Z \\le z)$ 的随机变量。在这个具体问题中，$Z \\sim \\mathcal{N}(0,1)$，其CDF表示为 $\\Phi(z)$。函数 $\\Phi: \\mathbb{R} \\to (0,1)$ 是连续且严格递增的。\n\n我们定义一个新的随机变量 $U = \\Phi(Z)$。为了确定 $U$ 的分布，我们推导其CDF，记为 $F_U(u) = P(U \\le u)$。\n\n函数 $\\Phi(\\cdot)$ 的值域是开区间 $(0,1)$。因此，随机变量 $U$ 只能取 $(0,1)$ 内的值。\n- 对于任何 $u \\le 0$，$U \\le u$ 是不可能的，所以 $P(U \\le u) = 0$。\n- 对于任何 $u \\ge 1$，$U \\le u$ 是必然的，所以 $P(U \\le u) = 1$。\n\n现在，考虑 $u \\in (0,1)$。根据定义，\n$$ F_U(u) = P(U \\le u) $$\n代入 $U$ 的定义：\n$$ F_U(u) = P(\\Phi(Z) \\le u) $$\n由于 $\\Phi(\\cdot)$ 是一个严格递增的函数，其逆函数，即分位数函数 $\\Phi^{-1}(\\cdot)$，存在且也是严格递增的。我们可以对概率算子内部不等式的两边应用 $\\Phi^{-1}$，而不会改变不等号的方向：\n$$ F_U(u) = P(\\Phi^{-1}(\\Phi(Z)) \\le \\Phi^{-1}(u)) $$\n根据反函数的性质，$\\Phi^{-1}(\\Phi(Z)) = Z$。因此，我们有：\n$$ F_U(u) = P(Z \\le \\Phi^{-1}(u)) $$\n表达式 $P(Z \\le z_0)$，对于某个值 $z_0$，根据定义是 $Z$ 的CDF在 $z_0$ 处的取值。在我们的例子中，$z_0 = \\Phi^{-1}(u)$。因此，\n$$ F_U(u) = \\Phi(\\Phi^{-1}(u)) $$\n再次应用反函数的性质，$\\Phi(\\Phi^{-1}(u)) = u$。所以，对于 $u \\in (0,1)$，\n$$ F_U(u) = u $$\n综合这些结果，$U$ 的完整CDF是：\n$$ F_U(u) = \\begin{cases} 0  \\text{若 } u \\le 0 \\\\ u  \\text{若 } 0  u  1 \\\\ 1  \\text{若 } u \\ge 1 \\end{cases} $$\n这是标准均匀分布 $\\mathrm{Unif}(0,1)$ 的CDF。该推导从第一性原理证实了如果 $Z \\sim \\mathcal{N}(0,1)$，那么 $U = \\Phi(Z) \\sim \\mathrm{Unif}(0,1)$。这个结论对于任何连续随机变量都更普遍地成立。\n\n### 任务2：校准测试的设计与实现\n该问题要求设计并实现一个确定性测试，用于检验概率预测的校准性。如果一个预测的PIT值在 $[0,1]$ 上均匀分布，则该预测是经过校准的。\n\n**确定性数据集的构建**：\n为了创建一个能完美代表标准正态分布的合成数据集，我们避免随机抽样。相反，我们生成 $N$ 个分位数 $y_i$，对应于均匀的概率网格 $u_i$。\n1.  定义一个包含 $N$ 个概率值的均匀网格：$u_i = \\frac{i - 1/2}{N}$，其中 $i \\in \\{1, 2, \\dots, N\\}$。\n2.  计算标准正态分布中对应的分位数：$y_i = \\Phi^{-1}(u_i)$。这个集合 $\\{y_i\\}$ 作为我们的基准真相观测值。\n\n**校准测试流程**：\n给定一个具有CDF $F_{\\text{pred}}(y)$ 的预测模型，我们检验它相对于观测值 $\\{y_i\\}$ 的校准性。\n1.  对于每个观测值 $y_i$，使用模型的预测CDF计算PIT值：$u_i^{\\text{pred}} = F_{\\text{pred}}(y_i)$。\n2.  如果由 $F_{\\text{pred}}$ 代表的模型是完美校准的（即，它与真实数据生成过程 $\\Phi$ 相匹配），那么值集合 $\\{u_i^{\\text{pred}}\\}$ 将是均匀分布的。具体来说，如果 $F_{\\text{pred}}(y) = \\Phi(y)$，则 $u_i^\\text{pred} = \\Phi(y_i) = \\Phi(\\Phi^{-1}(u_i)) = u_i$，从而产生一个完美的均匀网格。任何 $F_{\\text{pred}}$ 对 $\\Phi$ 的偏离都会扭曲这种均匀性。\n3.  为了量化这种扭曲，我们使用卡方拟合优度检验。区间 $[0,1]$ 被划分为 $B$ 个等宽的箱。\n4.  观测计数 $O_k$ 是落入第 $k$ 个箱的 $u_i^{\\text{pred}}$ 值的数量，其中 $k \\in \\{1, 2, \\dots, B\\}$。\n5.  在原假设 $H_0$（即 $u_i^{\\text{pred}}$ 值是均匀分布的）下，每个箱的期望计数是 $E_k = N/B$。\n6.  卡方检验统计量计算如下：\n    $$ \\chi^2 = \\sum_{k=1}^{B} \\frac{(O_k - E_k)^2}{E_k} $$\n7.  该统计量服从自由度为 $df = B-1$ 的卡方分布。\n8.  **决策规则**：我们计算p值，即假设 $H_0$ 为真时，观测到至少与计算出的检验统计量一样极端的检验统计量的概率：$p = P(\\chi^2_{df} \\ge \\chi^2)$。如果p值小于指定的显著性水平 $\\alpha$，则拒绝校准的原假设。也就是说，如果 $p  \\alpha$，则拒绝 $H_0$。\n\n**测试套件的实现逻辑**：\n该流程应用于四种情况中的每一种。\n- **情况A（精确校准）**：$\\mu_{\\text{pred}} = 0, \\sigma_{\\text{pred}} = 1$。预测CDF为 $F_{\\text{pred}}(y) = \\Phi(\\frac{y-0}{1}) = \\Phi(y)$。PIT值为 $u_i^{\\text{pred}} = \\Phi(y_i) = \\Phi(\\Phi^{-1}(u_i)) = u_i$。值 $\\{u_i\\}$ 形成一个完美的网格，因此每个箱将精确包含 $N/B$ 个点。因此，$O_k = E_k$ 对所有 $k$ 成立，导致 $\\chi^2 = 0$，$p=1$。由于 $1 \\not 0.01$，$H_0$ 不被拒绝。\n- **情况B（系统性均值误差）**：$\\mu_{\\text{pred}} = 0.75, \\sigma_{\\text{pred}} = 1$。预测存在系统性偏差。PIT值 $u_i^{\\text{pred}} = \\Phi(y_i - 0.75)$ 将会偏移，集中在较低的值，导致直方图不均匀。$\\chi^2$ 统计量将会很大，p值预计会小于 $\\alpha$，导致拒绝。\n- **情况C（弥散不足）**：$\\mu_{\\text{pred}} = 0, \\sigma_{\\text{pred}} = 0.6$。预测过于自信（分布过窄）。PIT值 $u_i^{\\text{pred}} = \\Phi(y_i / 0.6)$ 将被推向 $0$ 和 $1$ 的极端，形成一个U形分布。检验将检测到这种非均匀性，导致拒绝。\n- **情况D（过度弥散）**：$\\mu_{\\text{pred}} = 0, \\sigma_{\\text{pred}} = 1.6$。预测不够自信（分布过宽）。PIT值 $u_i^{\\text{pred}} = \\Phi(y_i / 1.6)$ 将集中在中位数 $0.5$ 附近，形成一个钟形分布。检验将检测到这一点，导致拒绝。\n下面的程序实现了这一逻辑。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, chi2\n\ndef solve():\n    \"\"\"\n    Implements the deterministic calibration test for a series of parameter settings.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (mu_pred, sigma_pred, N, B, alpha)\n    test_cases = [\n        (0.0, 1.0, 20000, 20, 0.01),  # Case A: happy path, exact calibration\n        (0.75, 1.0, 20000, 20, 0.01), # Case B: systematic mean error\n        (0.0, 0.6, 20000, 20, 0.01),  # Case C: underdispersion\n        (0.0, 1.6, 20000, 20, 0.01),  # Case D: overdispersion\n    ]\n\n    results = []\n    for case in test_cases:\n        mu_pred, sigma_pred, N, B, alpha = case\n\n        # Step 1: Generate the deterministic synthetic dataset.\n        # This creates a set of points that are perfectly representative of quantiles\n        # from a N(0,1) distribution, avoiding random sampling noise.\n        # The grid points u_i are from a Unif(0,1) distribution by construction.\n        u_i = (np.arange(1, N + 1) - 0.5) / N\n        \n        # The \"true\" observations y_i are the corresponding quantiles from N(0,1).\n        # norm.ppf is the inverse CDF (quantile function) of the normal distribution.\n        # With default loc=0 and scale=1, it is Phi^{-1}.\n        y_i = norm.ppf(u_i)\n\n        # Step 2: Compute PIT values from the predictive model.\n        # The predictive CDF is F_pred(y) = Phi((y - mu_pred) / sigma_pred).\n        # norm.cdf is the CDF of the normal distribution. With default loc=0 and\n        # scale=1, it is Phi.\n        u_i_pred = norm.cdf((y_i - mu_pred) / sigma_pred)\n\n        # Step 3: Perform the chi-square goodness-of-fit test.\n        # Create a histogram of the predictive PIT values u_i_pred.\n        # The range is [0, 1] and there are B equal-width bins.\n        observed_counts, _ = np.histogram(u_i_pred, bins=B, range=(0, 1))\n\n        # Under the null hypothesis of uniformity, the expected count in each bin is N/B.\n        expected_counts = N / B\n\n        # Calculate the chi-square statistic.\n        # Note: If expected_counts is 0, this would lead to division by zero.\n        # However, N and B are positive integers, so expected_counts > 0.\n        chi2_statistic = np.sum((observed_counts - expected_counts)**2 / expected_counts)\n\n        # The degrees of freedom for the chi-square test is B - 1.\n        df = B - 1\n\n        # Calculate the p-value.\n        # The survival function (sf) is 1 - cdf, which gives P(X > x).\n        # This is the probability of observing a chi2 statistic this large or larger.\n        p_value = chi2.sf(chi2_statistic, df)\n\n        # Step 4: Make a decision based on the significance level alpha.\n        # Reject the null hypothesis (that the PITs are uniform) if the p-value\n        # is less than alpha.\n        is_rejected = p_value  alpha\n        results.append(is_rejected)\n\n    # Final print statement in the exact required format.\n    # The boolean values are automatically converted to strings 'True' or 'False'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}