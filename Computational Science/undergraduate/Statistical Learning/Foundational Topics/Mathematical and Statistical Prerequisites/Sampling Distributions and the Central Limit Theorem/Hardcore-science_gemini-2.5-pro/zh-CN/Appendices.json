{
    "hands_on_practices": [
        {
            "introduction": "本练习将指导你完成一个动手编程实践。我们将使用蒙特卡洛模拟来估计机器学习模型在对抗性扰动下的期望损失。这个练习将中心极限定理具体化，展示了它如何让我们通过构建置信区间来量化估计的不确定性，这是模型评估中的一项基本技能。",
            "id": "3171846",
            "problem": "考虑一个固定向量 $w \\in \\mathbb{R}^d$、一个标量边距 $m \\in \\mathbb{R}$ 以及随机扰动 $\\delta \\sim \\mathcal{N}(0, \\sigma^2 I_d)$，其中 $I_d$ 是 $d \\times d$ 的单位矩阵。将随机扰动下的对抗性合页损失定义为\n$$\nL_{\\text{adv}}(\\delta) = \\max\\left(0,\\, m - w^\\top \\delta\\right).\n$$\n令 $\\{ \\delta_i \\}_{i=1}^n$ 为从 $\\mathcal{N}(0, \\sigma^2 I_d)$ 中抽取的独立同分布 (i.i.d.) 样本，并将平均对抗损失定义为样本均值\n$$\n\\overline{L}_{\\text{adv}} = \\frac{1}{n} \\sum_{i=1}^{n} L_{\\text{adv}}(\\delta_i).\n$$\n将随机扰动下的鲁棒准确率定义为：在随机抽取一个 $\\delta$ 的情况下，合页损失恰好为零的概率。这等价于在扰动下边距未被违反的概率：\n$$\np = \\mathbb{P}\\left( L_{\\text{adv}}(\\delta) = 0 \\right) = \\mathbb{P}\\left( w^\\top \\delta \\ge m \\right).\n$$\n令 $Y_i = \\mathbb{I}\\{ L_{\\text{adv}}(\\delta_i) = 0 \\}$ 为第 $i$ 个扰动未违反边距的指示函数，并令 $\\widehat{p} = \\frac{1}{n} \\sum_{i=1}^{n} Y_i$ 为未违反边距的样本比例。\n\n你的任务是使用样本均值、方差和独立性的基本定义，以及针对独立同分布随机变量的中心极限定理 (CLT)，来构建一个程序，该程序能够：\n- 生成指定的扰动测试套件，\n- 使用 CLT 计算 $\\overline{L}_{\\text{adv}}$ 以及 $\\overline{L}_{\\text{adv}}$ 的双侧 $95\\%$ 置信区间，\n- 使用应用于伯努利随机变量的 CLT 计算 $\\widehat{p}$ 以及 $p$ 的双侧 $95\\%$ 置信区间，\n- 将每个测试用例的结果汇总为一个包含六个浮点数的列表：\n$$\n\\left[\\overline{L}_{\\text{adv}},\\ \\text{CI}_{\\text{low}}(\\overline{L}_{\\text{adv}}),\\ \\text{CI}_{\\text{high}}(\\overline{L}_{\\text{adv}}),\\ \\widehat{p},\\ \\text{CI}_{\\text{low}}(p),\\ \\text{CI}_{\\text{high}}(p)\\right],\n$$\n其中 $\\text{CI}_{\\text{low}}$ 和 $\\text{CI}_{\\text{high}}$ 分别是置信区间的下界和上界。\n\n仅使用以下基础理论：\n- 样本均值和样本方差的定义，\n- 独立性和同分布的定义，\n- 针对具有有限方差的独立同分布随机变量的中心极限定理 (CLT) 的陈述。\n\n你不得使用任何正态分布的闭式概率表达式，也不得使用超出 CLT 和基本样本统计量所蕴含范围的任何预先推导的公式。\n\n为确保数值可复现性，请对每个测试用例使用指定种子的伪随机数生成器。\n\n测试套件：\n- 案例 1 (常规成功路径)：$d = 5$, $w = [1.0,\\ -0.5,\\ 0.3,\\ 0.8,\\ -0.2]$, $m = 0.4$, $\\sigma = 0.5$, $n = 5000$, 种子 $= 12345$。\n- 案例 2 (边界情况，小样本下鲁棒准确率低)：$d = 10$, $w = [0.3,\\ -0.1,\\ 0.2,\\ -0.4,\\ 0.5,\\ -0.7,\\ 0.9,\\ -0.2,\\ 0.1,\\ -0.3]$, $m = 0.6$, $\\sigma = 0.1$, $n = 30$, 种子 $= 2025$。\n- 案例 3 (边界情况，小样本下鲁棒准确率高)：$d = 10$, $w = [0.3,\\ -0.1,\\ 0.2,\\ -0.4,\\ 0.5,\\ -0.7,\\ 0.9,\\ -0.2,\\ 0.1,\\ -0.3]$, $m = -0.6$, $\\sigma = 0.1$, $n = 30$, 种子 $= 2026$。\n- 案例 4 (高维度，大样本)：$d = 50$, $w_j = (-1)^j \\left(0.1 + 0.02 j\\right)$ for $j = 1,2,\\dots,50$, $m = 0.5$, $\\sigma = 0.05$, $n = 10000$, 种子 $= 9876$。\n\n计算要求和输出规范：\n- 对每个案例，计算样本均值 $\\overline{L}_{\\text{adv}}$、$\\{L_{\\text{adv}}(\\delta_i)\\}$ 的无偏样本方差 $S^2$，并使用 CLT 构建一个双侧 $95\\%$ 置信区间：\n$$\n\\overline{L}_{\\text{adv}} \\pm z_{0.975}\\ \\sqrt{\\frac{S^2}{n}},\n$$\n其中 $z_{0.975}$ 是标准正态分布的 $0.975$ 分位数。使用 $z_{0.975} \\approx 1.959964$。\n- 对于鲁棒准确率，计算样本比例 $\\widehat{p}$ 及其双侧 $95\\%$ CLT 区间：\n$$\n\\widehat{p} \\pm z_{0.975}\\ \\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{n}},\n$$\n然后将边界截断，使其位于 $[0,1]$ 区间内。\n- 你的程序应生成单行输出，其中包含所有四个测试用例的结果，格式为一个由方括号括起来的、逗号分隔的列表的列表。每个浮点数必须四舍五入到六位小数。例如，总体格式应为\n$$\n\\left[\\left[r_{1,1}, r_{1,2}, \\dots, r_{1,6}\\right], \\left[r_{2,1}, \\dots, r_{2,6}\\right], \\left[r_{3,1}, \\dots, r_{3,6}\\right], \\left[r_{4,1}, \\dots, r_{4,6}\\right]\\right],\n$$\n其中每个 $r_{i,j}$ 是一个四舍五入到六位小数的浮点数。\n\n不涉及物理单位或角度。所有数值量必须以小数形式表示。程序必须是完整的，并且无需任何用户输入、外部文件或网络访问即可运行。",
            "solution": "该问题要求构建一个基于蒙特卡洛模拟的计算程序，以估计两个量及其置信区间。该程序的基础在于抽样分布和中心极限定理 (CLT) 的原理。\n\n首先，我们将感兴趣的随机变量形式化。扰动向量 $\\delta$ 是一个从多元正态分布 $\\delta \\sim \\mathcal{N}(0, \\sigma^2 I_d)$ 中抽取的 $d$ 维随机变量，其中 $I_d$ 是 $d \\times d$ 的单位矩阵。将此扰动投影到固定向量 $w \\in \\mathbb{R}^d$ 上，定义了一个新的一维随机变量 $Z = w^\\top \\delta$。由于 $Z$ 是独立高斯随机变量的线性组合，它本身也是一个高斯随机变量。其均值为 $\\mathbb{E}[Z] = \\mathbb{E}[w^\\top \\delta] = w^\\top \\mathbb{E}[\\delta] = w^\\top 0 = 0$。其方差为 $\\text{Var}(Z) = \\text{Var}(w^\\top \\delta) = w^\\top \\text{Cov}(\\delta) w = w^\\top (\\sigma^2 I_d) w = \\sigma^2 w^\\top w = \\sigma^2 \\|w\\|_2^2$。因此，$Z \\sim \\mathcal{N}(0, \\sigma^2 \\|w\\|_2^2)$。\n\n问题定义了两个源自 $Z$ 的关键量。首先是对抗性合页损失，$L_{\\text{adv}}(\\delta) = \\max(0, m - w^\\top \\delta) = \\max(0, m - Z)$。这是随机变量 $Z$ 的一个变换。其次是鲁棒准确率，$p = \\mathbb{P}( L_{\\text{adv}}(\\delta) = 0 ) = \\mathbb{P}(m - w^\\top \\delta \\le 0) = \\mathbb{P}(Z \\ge m)$。\n\n对期望损失 $\\mathbb{E}[L_{\\text{adv}}]$ 或概率 $p$ 进行解析计算需要对 $Z$ 的概率密度函数进行积分，而这正是问题陈述所禁止的方法。相反，我们必须依赖蒙特卡洛模拟和中心极限定理。模拟过程涉及从分布 $\\mathcal{N}(0, \\sigma^2 I_d)$ 中生成 $n$ 个独立同分布 (i.i.d.) 样本 $\\{\\delta_i\\}_{i=1}^n$。对于每个样本 $\\delta_i$，我们计算相应的标量投影 $z_i = w^\\top \\delta_i$。这给了我们一组来自 $Z$ 分布的独立同分布样本 $\\{z_i\\}_{i=1}^n$。从这些样本中，我们生成两组独立同分布的随机变量：一组合页损失 $\\{L_i\\}_{i=1}^n$，其中 $L_i = \\max(0, m - z_i)$；以及一组指示变量 $\\{Y_i\\}_{i=1}^n$，其中 $Y_i = \\mathbb{I}\\{z_i \\ge m\\}$。每个 $Y_i$ 是一个成功概率为 $p$ 的伯努利随机变量。任务的核心是估计 $L_{\\text{adv}}$ 和 $Y$ 的总体均值，并使用 CLT 为这些均值构建置信区间。\n\n为了估计平均对抗损失及其置信区间，令 $\\mu_L = \\mathbb{E}[L_{\\text{adv}}]$ 为真实平均对抗损失。样本均值 $\\overline{L}_{\\text{adv}} = \\frac{1}{n} \\sum_{i=1}^{n} L_i$ 是 $\\mu_L$ 的一个无偏估计量。中心极限定理指出，对于足够大的样本量 $n$，样本均值的分布近似为正态分布：\n$$\n\\overline{L}_{\\text{adv}} \\approx \\mathcal{N}\\left(\\mu_L, \\frac{\\sigma_L^2}{n}\\right)\n$$\n其中 $\\sigma_L^2 = \\text{Var}(L_{\\text{adv}})$ 是损失的真实方差。由于 $\\sigma_L^2$ 未知，我们使用无偏样本方差 $S^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (L_i - \\overline{L}_{\\text{adv}})^2$ 来估计它。量 $\\frac{\\overline{L}_{\\text{adv}} - \\mu_L}{S/\\sqrt{n}}$ 近似服从标准正态分布 $\\mathcal{N}(0,1)$。为了构建 $\\mu_L$ 的 $95\\%$ 置信区间，我们找到值 $z_{0.975}$ 使得 $\\mathbb{P}(-z_{0.975} \\le \\mathcal{N}(0,1) \\le z_{0.975}) = 0.95$。这就得出了区间 $\\overline{L}_{\\text{adv}} \\pm z_{0.975} \\frac{S}{\\sqrt{n}}$。使用给定的值 $z_{0.975} \\approx 1.959964$，置信区间的边界为 $\\text{CI}_{\\text{low}}(\\overline{L}_{\\text{adv}}) = \\overline{L}_{\\text{adv}} - 1.959964 \\cdot \\sqrt{\\frac{S^2}{n}}$ 和 $\\text{CI}_{\\text{high}}(\\overline{L}_{\\text{adv}}) = \\overline{L}_{\\text{adv}} + 1.959964 \\cdot \\sqrt{\\frac{S^2}{n}}$。\n\n为了估计鲁棒准确率及其置信区间，我们注意到 $p = \\mathbb{P}(Z \\ge m)$。变量 $Y_i = \\mathbb{I}\\{z_i \\ge m\\}$ 是一个成功概率为 $p$ 的伯努利试验。样本比例 $\\widehat{p} = \\frac{1}{n} \\sum_{i=1}^{n} Y_i$ 是这些伯努利变量的样本均值，并作为 $p$ 的一个无偏估计量。以 De Moivre-Laplace 定理形式出现的 CLT 指出，对于大的 $n$，$\\widehat{p} \\approx \\mathcal{N}\\left(p, \\frac{p(1-p)}{n}\\right)$。$\\widehat{p}$ 的标准误是 $\\sqrt{\\frac{p(1-p)}{n}}$。由于 $p$ 未知，我们代入其估计值 $\\widehat{p}$ 来得到估计的标准误 $\\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{n}}$。标准化量 $\\frac{\\widehat{p} - p}{\\sqrt{\\widehat{p}(1-\\widehat{p})/n}}$ 近似服从 $\\mathcal{N}(0,1)$。这导出了 $p$ 的 Wald 型 $95\\%$ 置信区间，由 $\\widehat{p} \\pm z_{0.975} \\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{n}}$ 给出。初始边界为 $\\text{CI}_{\\text{low}}'(p) = \\widehat{p} - 1.959964 \\cdot \\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{n}}$ 和 $\\text{CI}_{\\text{high}}'(p) = \\widehat{p} + 1.959964 \\cdot \\sqrt{\\frac{\\widehat{p}(1-\\widehat{p})}{n}}$。由于 $p$ 是一个概率，它必须在 $[0, 1]$ 范围内。我们将边界截断以确保它们位于此范围内：$\\text{CI}_{\\text{low}}(p) = \\max(0, \\text{CI}_{\\text{low}}'(p))$ 和 $\\text{CI}_{\\text{high}}(p) = \\min(1, \\text{CI}_{\\text{high}}'(p))$。这就完成了理论框架。实现将对每个测试用例遵循这些步骤。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not used as per the problem description.\n\ndef solve():\n    \"\"\"\n    Solves the problem by iterating through test cases, performing Monte Carlo\n    simulations to compute adversarial hinge loss and robust accuracy, and\n    calculating their 95% confidence intervals using the Central Limit Theorem.\n    \"\"\"\n    test_cases = [\n        {\n            \"d\": 5,\n            \"w\": np.array([1.0, -0.5, 0.3, 0.8, -0.2]),\n            \"m\": 0.4,\n            \"sigma\": 0.5,\n            \"n\": 5000,\n            \"seed\": 12345,\n        },\n        {\n            \"d\": 10,\n            \"w\": np.array([0.3, -0.1, 0.2, -0.4, 0.5, -0.7, 0.9, -0.2, 0.1, -0.3]),\n            \"m\": 0.6,\n            \"sigma\": 0.1,\n            \"n\": 30,\n            \"seed\": 2025,\n        },\n        {\n            \"d\": 10,\n            \"w\": np.array([0.3, -0.1, 0.2, -0.4, 0.5, -0.7, 0.9, -0.2, 0.1, -0.3]),\n            \"m\": -0.6,\n            \"sigma\": 0.1,\n            \"n\": 30,\n            \"seed\": 2026,\n        },\n        {\n            \"d\": 50,\n            \"w\": np.array([((-1)**(j + 1)) * (0.1 + 0.02 * (j + 1)) for j in range(50)]),\n            \"m\": 0.5,\n            \"sigma\": 0.05,\n            \"n\": 10000,\n            \"seed\": 9876,\n        },\n    ]\n\n    all_results = []\n    z_crit = 1.959964\n\n    for case in test_cases:\n        d, w, m, sigma, n, seed = (\n            case[\"d\"],\n            case[\"w\"],\n            case[\"m\"],\n            case[\"sigma\"],\n            case[\"n\"],\n            case[\"seed\"],\n        )\n\n        # Initialize the random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # Generate n i.i.d. samples of perturbations\n        # delta_i ~ N(0, sigma^2 * I_d)\n        perturbations = rng.standard_normal(size=(n, d)) * sigma\n\n        # Compute the projections w^T * delta_i for all samples\n        projections = perturbations @ w\n\n        # --- Adversarial Loss Calculation ---\n        \n        # Compute the adversarial hinge loss for each sample\n        # L_adv(delta_i) = max(0, m - w^T * delta_i)\n        losses = np.maximum(0, m - projections)\n\n        # Compute the sample mean of the adversarial loss\n        mean_loss = np.mean(losses)\n\n        # Compute the unbiased sample variance of the loss (ddof=1 for n-1 denominator)\n        if n  1:\n            var_loss = np.var(losses, ddof=1)\n        else:\n            var_loss = 0.0 # Variance is zero for a single sample\n\n        # Compute the standard error of the mean loss\n        se_loss = np.sqrt(var_loss / n) if n  0 else 0.0\n\n        # Compute the 95% confidence interval for the mean loss\n        half_width_loss = z_crit * se_loss\n        ci_low_loss = mean_loss - half_width_loss\n        ci_high_loss = mean_loss + half_width_loss\n\n        # --- Robust Accuracy Calculation ---\n\n        # Compute the indicator for robust accuracy for each sample\n        # Y_i = I{w^T * delta_i = m}\n        indicators = (projections = m).astype(float)\n\n        # Compute the sample proportion (estimator for p)\n        p_hat = np.mean(indicators)\n\n        # Compute the standard error for the proportion\n        # The variance of the estimator p_hat is p(1-p)/n, estimated by p_hat(1-p_hat)/n\n        se_p = np.sqrt(p_hat * (1 - p_hat) / n) if n  0 else 0.0\n\n        # Compute the 95% confidence interval for p\n        half_width_p = z_crit * se_p\n        ci_low_p = p_hat - half_width_p\n        ci_high_p = p_hat + half_width_p\n\n        # Clip the confidence interval for p to the valid range [0, 1]\n        ci_low_p_clipped = np.clip(ci_low_p, 0.0, 1.0)\n        ci_high_p_clipped = np.clip(ci_high_p, 0.0, 1.0)\n        \n        # Aggregate and round results to six decimal places\n        case_results = [\n            round(mean_loss, 6),\n            round(ci_low_loss, 6),\n            round(ci_high_loss, 6),\n            round(p_hat, 6),\n            round(ci_low_p_clipped, 6),\n            round(ci_high_p_clipped, 6),\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string as a list of lists without spaces\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "在直接分析数据的基础上，我们现在将应用中心极限定理来分析*估计量*本身的行为。本问题将探讨深度学习中的关键技术——批量归一化（Batch Normalization），将其运行平均值建模为随机变量的均值。你将推导这些统计量的渐近分布，为理解这些算法的工作原理及其稳定性提供理论基础。",
            "id": "3171886",
            "problem": "深度网络中的单个隐藏层使用批量归一化 (BN)。令 $X$ 表示某个固定通道上的标量预激活值，其模型为来自正态分布 $\\mathcal{N}(\\mu, \\sigma^{2})$ 的独立同分布样本。BN 观察 $B$ 个独立的 mini-batch，每个 batch 的大小为 $n$，并为每个 batch $b \\in \\{1, \\dots, B\\}$ 计算批次统计量：样本均值 $\\hat{\\mu}_{b}$ 和无偏样本方差 $\\hat{\\sigma}_{b}^{2}$。跨批次的平均 BN 统计量定义为\n$$\\bar{\\mu}_{B} = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{\\mu}_{b}, \\qquad \\bar{\\sigma}_{B}^{2} = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{\\sigma}_{b}^{2}.$$\n从样本均值和样本方差的基本定义出发，并仅使用中心极限定理 (CLT)，推导当 $B$ 增大时 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的渐近抽样分布，并使用这些分布来证明运行平均值的基于正态性的不确定性界限的合理性。然后，对于一个 BN 层，其中 $n = 128$，$B = 50$，$\\mu = 0.2$，$\\sigma = 0.9$，假设我们将稳健的运行平均值设置在 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的期望值处，同时为每个平均值附加置信水平为 $0.95$ 的对称不确定性界限。定义界限半径 $R$ 为 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的两个覆盖率为 $0.95$ 的基于正态分布的区间中较大的半宽。计算 $R$ 并将您的答案四舍五入到四位有效数字。将最终值表示为不带单位的纯数。",
            "solution": "该问题要求推导平均批量归一化 (BN) 统计量 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的渐近抽样分布，然后计算一个特定的不确定性界限半径 $R$。验证问题陈述是强制性的第一步。\n\n### 问题验证\n\n**第 1 步：提取已知条件**\n- 预激活值 $X$ 被建模为来自正态分布 $X \\sim \\mathcal{N}(\\mu, \\sigma^{2})$ 的独立同分布 (i.i.d.) 样本。\n- 有 $B$ 个独立的 mini-batch，每个的大小为 $n$。\n- 对于每个批次 $b \\in \\{1, \\dots, B\\}$，批次内统计量是样本均值 $\\hat{\\mu}_{b}$ 和无偏样本方差 $\\hat{\\sigma}_{b}^{2}$。\n- 平均 BN 统计量定义为 $\\bar{\\mu}_{B} = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{\\mu}_{b}$ 和 $\\bar{\\sigma}_{B}^{2} = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{\\sigma}_{b}^{2}$。\n- 渐近抽样分布的推导必须通过调用中心极限定理 (CLT) 来完成。\n- 用于计算的数值：$n = 128$, $B = 50$, $\\mu = 0.2$, $\\sigma = 0.9$。\n- 不确定性界限的置信水平为 $0.95$。\n- 界限半径 $R$ 是 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的两个覆盖率为 $0.95$ 的基于正态分布的区间中较大的半宽。\n- 最终答案必须四舍五入到四位有效数字。\n\n**第 2 步：使用提取的已知条件进行验证**\n该问题具有科学依据，提法明确且客观。它探讨了批量归一化（深度学习中的一种标准技术）中使用的估计量的统计特性。该问题基于数理统计的基本原理，即抽样分布和中心极限定理。所有定义和参数均已提供，从而得出一个唯一且可验证的解。使用 CLT 的约束是统计问题中的一个标准指令，用于证明对样本均值使用正态近似的合理性，这在这里是合适的。该问题在数学上和科学上都是合理的。\n\n**第 3 步：结论与行动**\n问题被判定为有效。将提供完整的解答。\n\n### 解答\n\n解答分为三个部分：推导渐近抽样分布，证明基于正态性的界限的合理性，以及计算界限半径 $R$ 的数值。\n\n**1. $\\bar{\\mu}_{B}$ 的渐近抽样分布**\n\n设 $X_{i,b}$ 是第 $b$ 个 mini-batch 中的第 $i$ 个预激活值，其中 $i \\in \\{1, \\dots, n\\}$ 且 $b \\in \\{1, \\dots, B\\}$。根据假设，$X_{i,b} \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 是独立同分布的。\n\n对于单个 mini-batch $b$，样本均值为 $\\hat{\\mu}_{b} = \\frac{1}{n} \\sum_{i=1}^{n} X_{i,b}$。由于独立正态随机变量的和也服从正态分布，$\\hat{\\mu}_{b}$ 精确地服从正态分布。其期望和方差为：\n$$E[\\hat{\\mu}_{b}] = E\\left[\\frac{1}{n} \\sum_{i=1}^{n} X_{i,b}\\right] = \\frac{1}{n} \\sum_{i=1}^{n} E[X_{i,b}] = \\frac{1}{n} (n\\mu) = \\mu$$\n$$Var(\\hat{\\mu}_{b}) = Var\\left(\\frac{1}{n} \\sum_{i=1}^{n} X_{i,b}\\right) = \\frac{1}{n^2} \\sum_{i=1}^{n} Var(X_{i,b}) = \\frac{1}{n^2} (n\\sigma^2) = \\frac{\\sigma^2}{n}$$\n所以，对于每个批次 $b$，样本均值是一个随机变量 $\\hat{\\mu}_{b} \\sim \\mathcal{N}(\\mu, \\sigma^2/n)$。\n\n平均统计量 $\\bar{\\mu}_{B}$ 是 $B$ 个独立同分布的随机变量 $\\hat{\\mu}_{1}, \\dots, \\hat{\\mu}_{B}$ 的样本均值。中心极限定理 (CLT) 指出，对于大量独立同分布的随机变量，它们的样本均值近似服从正态分布。将 CLT 应用于序列 $\\{\\hat{\\mu}_b\\}_{b=1}^B$，当 $B \\to \\infty$ 时 $\\bar{\\mu}_{B}$ 的渐近分布为：\n$$\\bar{\\mu}_{B} \\approx \\mathcal{N}\\left(E[\\hat{\\mu}_{b}], \\frac{Var(\\hat{\\mu}_{b})}{B}\\right)$$\n代入 $\\hat{\\mu}_{b}$ 的矩：\n$$\\bar{\\mu}_{B} \\approx \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2/n}{B}\\right) = \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{nB}\\right)$$\n（注意：由于每个 $\\hat{\\mu}_b$ 本身就服从正态分布，它们的均值 $\\bar{\\mu}_B$ 精确地服从正态分布，但问题要求通过 CLT 进行证明，我们已经提供了该证明。）\n\n**2. $\\bar{\\sigma}_{B}^{2}$ 的渐近抽样分布**\n\n对于单个 mini-batch $b$，无偏样本方差为 $\\hat{\\sigma}_{b}^{2} = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_{i,b} - \\hat{\\mu}_{b})^2$。\n对于来自正态分布的数据，量 $\\frac{(n-1)\\hat{\\sigma}_{b}^{2}}{\\sigma^2}$ 服从自由度为 $n-1$ 的卡方分布，即 $\\frac{(n-1)\\hat{\\sigma}_{b}^{2}}{\\sigma^2} \\sim \\chi_{n-1}^2$。\n\n由此，我们可以求出 $\\hat{\\sigma}_{b}^{2}$ 的期望和方差。一个 $\\chi_k^2$ 随机变量的均值和方差分别为 $k$ 和 $2k$。\n$$E[\\hat{\\sigma}_{b}^{2}] = E\\left[\\frac{\\sigma^2}{n-1} \\chi_{n-1}^2\\right] = \\frac{\\sigma^2}{n-1} E[\\chi_{n-1}^2] = \\frac{\\sigma^2}{n-1} (n-1) = \\sigma^2$$\n这证实了 $\\hat{\\sigma}_{b}^{2}$ 是 $\\sigma^2$ 的一个无偏估计量。\n$$Var(\\hat{\\sigma}_{b}^{2}) = Var\\left(\\frac{\\sigma^2}{n-1} \\chi_{n-1}^2\\right) = \\left(\\frac{\\sigma^2}{n-1}\\right)^2 Var(\\chi_{n-1}^2) = \\frac{\\sigma^4}{(n-1)^2} [2(n-1)] = \\frac{2\\sigma^4}{n-1}$$\n平均统计量 $\\bar{\\sigma}_{B}^{2}$ 是 $B$ 个独立同分布的随机变量 $\\hat{\\sigma}_{1}^{2}, \\dots, \\hat{\\sigma}_{B}^{2}$ 的样本均值。这些变量不服从正态分布；它们服从一个缩放的卡方分布。因此，我们必须调用 CLT 来求出它们的均值 $\\bar{\\sigma}_{B}^{2}$ 的渐近分布。当 $B \\to \\infty$ 时，CLT 给出：\n$$\\bar{\\sigma}_{B}^{2} \\approx \\mathcal{N}\\left(E[\\hat{\\sigma}_{b}^{2}], \\frac{Var(\\hat{\\sigma}_{b}^{2})}{B}\\right)$$\n代入 $\\hat{\\sigma}_{b}^{2}$ 的矩：\n$$\\bar{\\sigma}_{B}^{2} \\approx \\mathcal{N}\\left(\\sigma^2, \\frac{2\\sigma^4/(n-1)}{B}\\right) = \\mathcal{N}\\left(\\sigma^2, \\frac{2\\sigma^4}{B(n-1)}\\right)$$\n\n**3. 基于正态性的不确定性界限的合理性证明**\n\n由 CLT 确立的 $\\bar{\\mu}_{B}$ 和 $\\bar{\\sigma}_{B}^{2}$ 的渐近正态性，是使用基于正态性的不确定性界限的理由。对于大量的批次 $B$，这些运行平均值的抽样分布可以很好地用正态分布来近似。对于均值为 $\\theta$、方差为 $V$ 的正态分布估计量 $\\hat{\\theta}$，一个对称的 $(1-\\alpha)$ 置信区间由 $\\hat{\\theta} \\pm z_{1-\\alpha/2} \\sqrt{V}$ 给出。问题要求不确定性界限以估计量的期望值为中心。这样一个界限的半宽为 $z_{1-\\alpha/2} \\sqrt{\\text{Var}(\\text{estimator})}$。\n\n**4. 界限半径 $R$ 的计算**\n\n我们已知 $n = 128$，$B = 50$，$\\mu = 0.2$，$\\sigma = 0.9$。置信水平为 $0.95$，因此 $\\alpha = 0.05$。来自标准正态分布的临界值为 $z_{1-\\alpha/2} = z_{0.975} \\approx 1.95996$。我们将使用标准近似值 $z_{0.975} = 1.96$。\n\n首先，我们计算 $\\bar{\\mu}_{B}$ 的不确定性界限的半宽，记为 $R_{\\mu}$。\n$$R_{\\mu} = z_{0.975} \\sqrt{Var(\\bar{\\mu}_{B})} = z_{0.975} \\sqrt{\\frac{\\sigma^2}{nB}}$$\n代入数值：$\\sigma^2 = (0.9)^2 = 0.81$。\n$$R_{\\mu} = 1.96 \\sqrt{\\frac{0.81}{128 \\times 50}} = 1.96 \\sqrt{\\frac{0.81}{6400}} = 1.96 \\times \\frac{0.9}{80} = 1.96 \\times 0.01125 = 0.02205$$\n\n接下来，我们计算 $\\bar{\\sigma}_{B}^{2}$ 的不确定性界限的半宽，记为 $R_{\\sigma^2}$。\n$$R_{\\sigma^2} = z_{0.975} \\sqrt{Var(\\bar{\\sigma}_{B}^{2})} = z_{0.975} \\sqrt{\\frac{2\\sigma^4}{B(n-1)}}$$\n代入数值：$\\sigma^4 = (0.81)^2 = 0.6561$ 且 $n-1 = 127$。\n$$R_{\\sigma^2} = 1.96 \\sqrt{\\frac{2 \\times 0.6561}{50 \\times 127}} = 1.96 \\sqrt{\\frac{1.3122}{6350}} \\approx 1.96 \\sqrt{0.00020664567}$$\n$$R_{\\sigma^2} \\approx 1.96 \\times 0.0143751754 \\approx 0.0281753439$$\n\n界限半径 $R$ 定义为这两个半宽中较大的一个。\n$$R = \\max(R_{\\mu}, R_{\\sigma^2}) = \\max(0.02205, 0.0281753439) = 0.0281753439$$\n将结果四舍五入到四位有效数字，得到：\n$$R \\approx 0.02818$$",
            "answer": "$$\\boxed{0.02818}$$"
        },
        {
            "introduction": "对中心极限定理的简单应用有时可能会产生误导。这个问题挑战你批判性地思考不同统计方法捕捉了哪些不确定性的来源。通过比较一个简单的基于CLT的方差近似和一个更全面的自助法（bootstrap）方法，你将学会区分来自有限测试数据的不确定性与源于模型不稳定性和选择的不确定性。",
            "id": "3171798",
            "problem": "一位分析师研究监督学习流程中预测误差估计量的抽样分布。设 $(X,Y)$ 服从一个未知的联合分布，预测损失为平方误差 $L(Y,f(X)) = (Y - f(X))^2$。定义总体预测误差为 $\\mathcal{E} = \\mathbb{E}[L(Y,f(X))]$。分析师使用一个大小为 $n$ 的训练样本，通过一个数据驱动的流程（包括模型选择，例如通过最小化交叉验证标准来进行超参数调整）来训练模型 $\\hat f$，然后在一个大小为 $m$ 的独立测试集上评估其预测误差：\n$$\n\\hat E = \\frac{1}{m}\\sum_{i=1}^{m} \\ell_i, \\quad \\text{其中 } \\ell_i = \\left(Y_i^{\\text{test}} - \\hat f(X_i^{\\text{test}})\\right)^2.\n$$\n假设测试对 $\\{(X_i^{\\text{test}},Y_i^{\\text{test}})\\}_{i=1}^m$ 是独立同分布的，并且独立于训练数据。考虑 $\\hat E$ 的两种方差近似：\n\n1. 一种通过中心极限定理（CLT）的解析近似，其理想化假设是 $\\hat f$ 是固定的（即不依赖于数据），因此 $\\{\\ell_i\\}_{i=1}^m$ 是独立同分布的，具有有限的均值 $\\mu$ 和方差 $\\nu$。\n\n2. 一种非参数自助法（bootstrap）近似，它对训练数据进行 $B$ 次有放回的重抽样，在每次重抽样中重新拟合整个流程（包括模型选择），并对每个自助法拟合 $\\hat f^{*b}$ 在同一个独立测试集上重新计算预测误差，得到\n$$\n\\hat E^{*b} = \\frac{1}{m}\\sum_{i=1}^{m} \\left(Y_i^{\\text{test}} - \\hat f^{*b}(X_i^{\\text{test}})\\right)^2, \\quad b=1,\\dots,B,\n$$\n然后使用 $\\{\\hat E^{*b}\\}_{b=1}^B$ 间的样本方差，\n$$\n\\widehat{\\operatorname{Var}}_{\\text{boot}}(\\hat E) = \\frac{1}{B-1}\\sum_{b=1}^{B}\\left(\\hat E^{*b} - \\bar E^{*}\\right)^2, \\quad \\bar E^{*} = \\frac{1}{B}\\sum_{b=1}^{B}\\hat E^{*b},\n$$\n作为 $\\hat E$ 的方差估计。\n\n为了使解析CLT比较更具体，进一步假设数据生成机制满足 $Y = f^*(X) + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 且独立于 $X$，并且固定模型理想化设定 $\\hat f(X) = f^*(X)$，因此 $\\ell_i = \\varepsilon_i^2$。取 $\\sigma^2 = 4$ 和 $m = 100$。\n\n选择所有正确的陈述：\n\nA. 在固定模型理想化、平方误差损失和 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 的条件下，$\\hat E$ 的 CLT 方差近似为 $2\\sigma^4/m$。对于在每次重抽样中都重新拟合模型并重新运行模型选择的自助法，其自助法方差通常超过解析 CLT 方差，因为它捕捉了由模型选择引起的额外变异性。\n\nB. 在小样本中，自助法方差必须小于解析 CLT 方差，因为重抽样通过平均来稳定估计量。\n\nC. 当 $\\sigma^2 = 4$ 和 $m = 100$ 时，$\\hat E$ 的 CLT 方差为 $\\sigma^2/m = 4/100 = 0.04$。\n\nD. 当存在模型选择时，自助法方差估计是无效的，因为模型选择违反了独立性，所以自助法不能用于量化 $\\hat E$ 的不确定性。\n\nE. 无论是否存在模型选择，随着 $m$ 变大，自助法方差必然等于解析 CLT 方差。",
            "solution": "用户提供了一个有效的问题陈述。该设定在科学上是合理的、适定的和客观的，为评估给定选项提供了清晰的基础。我将继续进行分析。\n\n问题要求比较预测误差估计量 $\\hat E$ 的方差的两种近似方法。估计量 $\\hat E$ 本身是一个随机变量，因为它依赖于两个随机性来源：大小为 $n$ 的训练数据（它决定了模型 $\\hat f$）和大小为 $m$ 的独立测试数据（$\\hat f$ 在其上被评估）。$\\hat E$ 的真实方差可以使用全方差公式分解：\n$$\n\\operatorname{Var}(\\hat E) = \\mathbb{E}_{\\mathcal{D}_{\\text{train}}}[\\operatorname{Var}_{\\mathcal{D}_{\\text{test}}}(\\hat E | \\mathcal{D}_{\\text{train}})] + \\operatorname{Var}_{\\mathcal{D}_{\\text{train}}}[\\mathbb{E}_{\\mathcal{D}_{\\text{test}}}(\\hat E | \\mathcal{D}_{\\text{train}})]\n$$\n此处，$\\mathcal{D}_{\\text{train}}$ 表示训练集，$\\mathcal{D}_{\\text{test}}$ 表示测试集。\n第一项，$\\mathbb{E}_{\\mathcal{D}_{\\text{train}}}[\\operatorname{Var}_{\\mathcal{D}_{\\text{test}}}(\\hat E | \\mathcal{D}_{\\text{train}})]$，表示由测试集的随机性引起的 $\\hat E$ 的方差，该方差是在所有可能的训练集上取平均得到的。在给定训练集的情况下，模型 $\\hat f$ 是固定的。由于测试数据是独立同分布的，这个条件方差是 $\\operatorname{Var}_{\\mathcal{D}_{\\text{test}}}(\\hat E | \\mathcal{D}_{\\text{train}}) = \\frac{1}{m}\\operatorname{Var}(\\ell_1 | \\hat f)$，其中 $\\ell_1 = (Y_1^{\\text{test}} - \\hat f(X_1^{\\text{test}}))^2$。\n第二项，$\\operatorname{Var}_{\\mathcal{D}_{\\text{train}}}[\\mathbb{E}_{\\mathcal{D}_{\\text{test}}}(\\hat E | \\mathcal{D}_{\\text{train}})]$，表示由训练集中的随机性引起的方差，这种随机性导致模型 $\\hat f$ 发生变化。这是 $\\hat f$ 的真实条件误差在训练集分布上的方差。该项通常被称为模型不稳定性或模型选择方差。\n\n问题中提出的两种近似方法与这两个分量有关：\n1.  解析CLT近似将 $\\hat f$ 理想化为固定的。这意味着它只考虑了第一个方差来源（来自测试集），而忽略了第二个来源（来自模型不稳定性）。它估计的是固定 $\\hat f$ 下的 $\\frac{1}{m}\\operatorname{Var}(\\ell_1)$。\n2.  如前所述的非参数自助法近似，它在保持测试数据固定的同时，对训练数据进行重抽样。方差是根据得到的测试误差 $\\{\\hat E^{*b}\\}$ 计算的。这个过程分离并估计了第二个方差来源，即由拟合过程（包括模型选择）相对于训练数据的不稳定性所引起的方差。\n\n在这个框架下，我们可以评估每个陈述。\n\n**A. 在固定模型理想化、平方误差损失和 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 的条件下，$\\hat E$ 的 CLT 方差近似为 $2\\sigma^4/m$。对于在每次重抽样中都重新拟合模型并重新运行模型选择的自助法，其自助法方差通常超过解析 CLT 方差，因为它捕捉了由模型选择引起的额外变异性。**\n\n第一部分：我们来计算指定理想化下的解析CLT方差。模型被固定为真实模型, $\\hat f(X) = f^*(X)$。各个损失项为 $\\ell_i = (Y_i^{\\text{test}} - f^*(X_i^{\\text{test}}))^2 = \\varepsilon_i^2$，其中 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$ 是独立同分布的。估计量是 $\\hat E = \\frac{1}{m}\\sum_{i=1}^m \\varepsilon_i^2$。方差为 $\\operatorname{Var}(\\hat E) = \\frac{1}{m^2} \\sum_{i=1}^m \\operatorname{Var}(\\varepsilon_i^2) = \\frac{m \\operatorname{Var}(\\varepsilon^2)}{m^2} = \\frac{\\operatorname{Var}(\\varepsilon^2)}{m}$。\n为了求 $\\operatorname{Var}(\\varepsilon^2)$，我们注意到如果 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$，那么 $\\varepsilon/\\sigma \\sim \\mathcal{N}(0,1)$。一个标准正态变量的平方，$(\\varepsilon/\\sigma)^2$，服从自由度为1的卡方分布，即 $\\chi^2_1$。一个 $\\chi^2_k$ 分布的方差是 $2k$。对于 $k=1$，方差是 $2$。\n所以，$\\operatorname{Var}((\\varepsilon/\\sigma)^2) = 2$。\n$\\varepsilon^2$ 的方差是 $\\operatorname{Var}(\\varepsilon^2) = \\operatorname{Var}(\\sigma^2 (\\varepsilon/\\sigma)^2) = (\\sigma^2)^2 \\operatorname{Var}((\\varepsilon/\\sigma)^2) = \\sigma^4 \\cdot 2 = 2\\sigma^4$。\n因此，CLT方差近似为 $\\operatorname{Var}(\\hat E) = \\frac{2\\sigma^4}{m}$。陈述的第一部分是正确的。\n\n第二部分：所描述的自助法过程估计了由模型不稳定性引起的方差分量。解析CLT方法通过假设一个固定模型来明确地忽略这个分量。特别是模型选择，可能是模型不稳定性的一个主要来源，因为训练数据中的小扰动可能导致选择不同的模型（例如，不同的超参数），这反过来又可能导致显著不同的预测。自助法捕捉到了这个真实的变异来源。解析CLT方差只捕捉了由于有限测试集引起的变异。在统计学习中，一个普遍的现象是，由模型不稳定性引起的方差是显著的，通常与来自测试集的方差相当甚至更大，特别是对于复杂的建模流程和有限的训练数据 $n$。自助法方差“通常超过”解析CLT方差的陈述反映了这一事实，并且所给出的理由——它“捕捉了由模型选择引起的额外变异性”——是完全正确的。解析方法假设这个变异性为零。\n\n结论：**正确**。\n\n**B. 在小样本中，自助法方差必须小于解析 CLT 方差，因为重抽样通过平均来稳定估计量。**\n\n这个陈述不正确，主要有两个原因。首先，其推理是有缺陷的。“重抽样通过平均来稳定估计量”这个想法指的是像 bagging（自助聚合）这样的集成方法，其中来自多个自助法模型的预测被平均以形成一个具有较低方差的最终预测。这里描述的过程是用于*方差估计*，而不是创建一个稳定的预测器。其次，这个结论通常是错误的。如选项A中所解释的，自助法捕捉了模型不稳定性方差，这个方差通常很大，特别是在模型不太稳定的小样本量 $n$ 的情况下。解析CLT方差依赖于 $1/m$。没有任何原则规定自助法估计的方差必须小于CLT方差。\n\n结论：**不正确**。\n\n**C. 当 $\\sigma^2 = 4$ 和 $m = 100$ 时，$\\hat E$ 的 CLT 方差为 $\\sigma^2/m = 4/100 = 0.04$。**\n\n这个陈述为方差提供了一个不正确的公式。正如选项A中所推导的，在固定模型理想化下，$\\hat E$ 的正确方差是 $\\frac{2\\sigma^4}{m}$。量 $\\sigma^2$ 是噪声项 $\\varepsilon$ 的方差，而不是平方噪声项 $\\ell_i = \\varepsilon^2$ 的方差。该陈述错误地使用了 $\\operatorname{Var}(\\ell_i) = \\sigma^2$。\n使用正确的公式和给定的值 $\\sigma^2 = 4$ 和 $m=100$:\n$$\n\\operatorname{Var}(\\hat E) = \\frac{2\\sigma^4}{m} = \\frac{2 \\cdot (4)^2}{100} = \\frac{2 \\cdot 16}{100} = \\frac{32}{100} = 0.32.\n$$\n选项中声称的值 $0.04$ 是不正确的，用于推导它的公式 $\\sigma^2/m$ 也是不正确的。\n\n结论：**不正确**。\n\n**D. 当存在模型选择时，自助法方差估计是无效的，因为模型选择违反了独立性，所以自助法不能用于量化 $\\hat E$ 的不确定性。**\n\n这个陈述根本上是错误的。自助法是一种强大且广泛使用的工具，正是在解析公式难以处理的情况下，例如涉及像模型选择这样复杂的、数据驱动过程的情况下，用于评估统计不确定性。虽然模型选择使得数据与最终估计 $\\hat E$ 之间的关系变得非常复杂，但自助法“模仿抽样过程”的原则使其能够经验地近似 $\\hat E$ 的抽样分布。关于模型选择“违反独立性”的说法是含糊的，但它并不会使自助法原则失效。自助法远非无效，它通常被认为是在包含模型选择的流程中量化不确定性的最先进方法。\n\n结论：**不正确**。\n\n**E. 无论是否存在模型选择，随着 $m$ 变大，自助法方差必然等于解析 CLT 方差。**\n\n这个陈述是错误的。这两种方差估计捕捉了不同的变异来源，并且相对于测试集大小 $m$ 具有不同的渐近行为。\n解析CLT方差 $\\frac{\\operatorname{Var}(\\ell_1|\\hat{f})}{m}$ 是 $m$ 的函数，并且当 $m \\to \\infty$ 时收敛到 $0$。这反映了一个事实，即对于一个无限大的测试集，一个*固定*模型的误差可以以零方差被测量。\n如问题中定义的，自助法方差是由重抽样大小为 $n$ 的训练集并重新拟合模型产生的。$\\hat E^{*b}$ 的方差是由模型 $\\hat f^{*b}$ 的变异性驱动的。当 $m \\to \\infty$ 时，根据大数定律，每个 $\\hat E^{*b} = \\frac{1}{m}\\sum_i (Y_i^{\\text{test}} - \\hat f^{*b}(X_i^{\\text{test}}))^2$ 收敛到模型 $\\hat f^{*b}$ 的真实条件误差，即 $\\mathbb{E}[(Y - \\hat f^{*b}(X))^2]$。因此，自助法方差收敛到这些真实条件误差的方差，这是一个依赖于训练集大小 $n$ 和建模过程稳定性的量，但*不*依赖于 $m$。这个极限通常是非零的。\n由于一个量趋于 $0$，而另一个量（对于固定的 $n$）趋于一个非零常数，所以它们不会变得相等。\n\n结论：**不正确**。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}