{
    "hands_on_practices": [
        {
            "introduction": "我们将从一个基本但至关重要的问题开始：为什么在处理不平衡数据集时，分层是必要的？虽然标准的k折交叉验证是一个强大的工具，但其非分层版本可能会在类别分布不均时给出具有误导性的性能评估。这个练习将通过一个量化的思想实验，让您亲手计算和观察不进行分层所引入的额外风险，从而深刻理解分层策略的核心价值。",
            "id": "3134712",
            "problem": "考虑一个存在严重类别不平衡的二分类问题。设类别标签为 $Y \\in \\{0,1\\}$，其总体先验概率为 $\\mathbb{P}(Y=1)=\\pi$ 和 $\\mathbb{P}(Y=0)=1-\\pi$，其中 $\\pi \\ll 0.5$。给定一个实值特征 $X$，假设类别条件分布是方差相等的正态分布：$X \\mid Y=0 \\sim \\mathcal{N}(0,1)$ 和 $X \\mid Y=1 \\sim \\mathcal{N}(\\mu,1)$，其中 $\\mu0$ 为已知。考虑在一个大小为 $N$ 的数据集上执行 $k$ 折交叉验证（Cross-Validation, CV），其中包含 $k$ 个大小相等的折。\n\n使用以下基本依据：\n- 在已知类别条件密度和先验概率的情况下，Bayes 分类器使用似然比检验，当方差相等时，该检验可简化为对 $X$ 的阈值规则。\n- 错分风险定义为总体误差 $\\mathbb{P}(\\hat{Y}\\neq Y)$，该误差在真实数据分布下计算。\n- 非分层 $k$ 折划分是指将 $N$ 个样本随机划分为 $k$ 个折，而不考虑类别标签。\n- 分层 $k$ 折划分确保每个折尽可能地反映总体的类别比例。在本问题中，假设为精确分层：$N\\pi$ 是一个整数，并且每个折恰好包含来自少数类的 $N\\pi/k$ 个样本和来自多数类的 $N(1-\\pi)/k$ 个样本。\n\n将在一个折内训练的分类器定义为使用从该折的训练部分估计出的经验类别先验 $\\hat{\\pi}$ 的似然比阈值规则，同时使用已知的真实类别条件密度。具体而言，决策规则是“如果 $X \\ge t(\\hat{\\pi})$ 则预测 $Y=1$，否则预测 $Y=0$”，其中 $t(\\hat{\\pi})$ 是由带有先验 $\\hat{\\pi}$ 的似然比检验所隐含的阈值。该折的测试误差是在从相同总体中抽出的数据上测量的。\n\n您必须：\n1. 从第一性原理出发，从似然比检验开始，推导在方差相等的正态分布情况下决策阈值 $t(\\hat{\\pi})$，以及相应的错分风险 $R(t)$ 作为 $t$、$\\pi$ 和 $\\mu$ 的函数。\n2. 在非分层 $k$ 折交叉验证下，将训练先验 $\\hat{\\pi}$ 建模为一个由随机分折引起的随机变量。设 $M=N\\pi$ 为少数类样本的总数（根据假设为整数），$n_{\\text{train}}=N(k-1)/k$ 为每折的训练集大小。对于给定的折，训练集中的少数类样本数量 $m$ 服从参数为 $(N, M, n_{\\text{train}})$ 的超几何分布。因此，$\\hat{\\pi}=m/n_{\\text{train}}$。利用这一点，计算非分层交叉验证的期望风险，即 $R\\big(t(\\hat{\\pi})\\big)$ 关于 $m$ 的超几何分布的期望值。\n3. 在具有精确每折类别比例的分层 $k$ 折交叉验证下，训练先验完全等于总体先验 $\\pi$，因此分层交叉验证风险等于 $R\\big(t(\\pi)\\big)$。\n4. 将由非分层引起的误差膨胀 $\\Delta$ 量化为\n$$\n\\Delta = \\mathbb{E}\\left[R\\big(t(\\hat{\\pi})\\big)\\right] - R\\big(t(\\pi)\\big).\n$$\n对下面指定的每个测试用例计算 $\\Delta$。\n\n您必须实现一个完整、可运行的程序，对于每个参数元组 $(N,k,\\pi,\\mu)$，通过精确的超几何分布计算单折的期望非分层交叉验证风险、分层交叉验证风险，并以浮点数形式输出误差膨胀 $\\Delta$。通过解释阈值规则的极限情况，正确处理 $\\hat{\\pi}=0$ 和 $\\hat{\\pi}=1$ 的退化情况：如果 $\\hat{\\pi}=0$，分类器总是预测 $Y=0$，产生的风险为 $R=\\pi$；如果 $\\hat{\\pi}=1$，分类器总是预测 $Y=1$，产生的风险为 $R=1-\\pi$。\n\n测试套件：\n- 用例 $1$（正常路径）：$(N,k,\\pi,\\mu) = (500,5,0.05,2.0)$。\n- 用例 $2$（小数据，但仍严重不平衡）：$(N,k,\\pi,\\mu) = (100,10,0.10,1.5)$。\n- 用例 $3$（大数据，极端不平衡）：$(N,k,\\pi,\\mu) = (5000,10,0.01,1.0)$。\n- 用例 $4$（中等数据，强可分性）：$(N,k,\\pi,\\mu) = (1200,4,0.03,3.0)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result_1,result_2,result_3,result_4]$），其中每个 $result_i$ 是为用例 $i$ 计算的 $\\Delta$，四舍五入到 $6$ 位小数。不应打印任何其他文本。",
            "solution": "该问题要求我们量化在使用非分层 $k$ 折交叉验证与分层 $k$ 折交叉验证时，对于一个存在严重类别不平衡的二分类器所产生的误差膨胀，记为 $\\Delta$。该分析基于一个涉及高斯类别条件分布的特定理论设置。我们将首先推导必要的理论部分，然后将它们应用于指定的交叉验证方案。\n\n### 1. 决策阈值与错分风险\n\n分类器的决策基于似然比检验，该检验比较了两个类别的后验概率。对于给定的特征值 $X$，如果 $\\mathbb{P}(Y=1|X)  \\mathbb{P}(Y=0|X)$，分类器预测类别为 $Y=1$。使用 Bayes 定理，这等价于 $\\frac{p(X|Y=1)\\mathbb{P}(Y=1)}{p(X)}  \\frac{p(X|Y=0)\\mathbb{P}(Y=0)}{p(X)}$，可简化为似然比检验：\n$$\n\\frac{p(X|Y=1)}{p(X|Y=0)}  \\frac{\\mathbb{P}(Y=0)}{\\mathbb{P}(Y=1)}\n$$\n问题指定分类器使用真实的类别条件密度，但用从训练数据中得到的经验估计值 $\\hat{\\pi}$ 来估计先验概率 $\\mathbb{P}(Y=1)$。因此，决策规则变为：\n$$\n\\frac{p(X|Y=1)}{p(X|Y=0)}  \\frac{1-\\hat{\\pi}}{\\hat{\\pi}}\n$$\n类别条件密度给定为 $X \\mid Y=0 \\sim \\mathcal{N}(0,1)$ 和 $X \\mid Y=1 \\sim \\mathcal{N}(\\mu,1)$。它们的概率密度函数（PDF）是：\n$$\np(X|Y=0) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{X^2}{2}\\right)\n$$\n$$\np(X|Y=1) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(X-\\mu)^2}{2}\\right)\n$$\n似然比为：\n$$\n\\frac{p(X|Y=1)}{p(X|Y=0)} = \\frac{\\exp\\left(-\\frac{(X-\\mu)^2}{2}\\right)}{\\exp\\left(-\\frac{X^2}{2}\\right)} = \\exp\\left(\\frac{X^2 - (X-\\mu)^2}{2}\\right) = \\exp\\left(\\frac{X^2 - (X^2 - 2\\mu X + \\mu^2)}{2}\\right) = \\exp\\left(\\mu X - \\frac{\\mu^2}{2}\\right)\n$$\n将此代入决策规则不等式：\n$$\n\\exp\\left(\\mu X - \\frac{\\mu^2}{2}\\right)  \\frac{1-\\hat{\\pi}}{\\hat{\\pi}}\n$$\n对两边取自然对数（这是一个保持不等式的单调变换）：\n$$\n\\mu X - \\frac{\\mu^2}{2}  \\ln\\left(\\frac{1-\\hat{\\pi}}{\\hat{\\pi}}\\right)\n$$\n由于给定 $\\mu  0$，我们可以求解 $X$ 以找到决策阈值 $t(\\hat{\\pi})$：\n$$\nX  \\frac{1}{\\mu}\\left(\\frac{\\mu^2}{2} + \\ln\\left(\\frac{1-\\hat{\\pi}}{\\hat{\\pi}}\\right)\\right)\n$$\n因此，作为经验先验 $\\hat{\\pi}$ 函数的决策阈值为：\n$$\nt(\\hat{\\pi}) = \\frac{\\mu}{2} + \\frac{1}{\\mu}\\ln\\left(\\frac{1-\\hat{\\pi}}{\\hat{\\pi}}\\right)\n$$\n分类器的规则是，如果 $X \\geq t(\\hat{\\pi})$ 则预测 $Y=1$，否则预测 $Y=0$。\n\n接下来，我们推导给定阈值 $t$ 的错分风险 $R(t)$。该风险是总体错误率，使用真实总体先验 $\\pi$ 进行评估。它是由真实类别先验加权的第一类和第二类错误概率之和：\n$$\nR(t) = \\mathbb{P}(\\text{predict } 1 \\mid Y=0)\\mathbb{P}(Y=0) + \\mathbb{P}(\\text{predict } 0 \\mid Y=1)\\mathbb{P}(Y=1)\n$$\n$$\nR(t) = \\mathbb{P}(X \\ge t \\mid Y=0)(1-\\pi) + \\mathbb{P}(X  t \\mid Y=1)\\pi\n$$\n令 $\\Phi(\\cdot)$ 为标准正态分布 $\\mathcal{N}(0,1)$ 的累积分布函数（CDF）。\n对于第一项，由于 $X \\mid Y=0 \\sim \\mathcal{N}(0,1)$，我们有 $\\mathbb{P}(X \\ge t \\mid Y=0) = 1 - \\Phi(t)$。\n对于第二项，由于 $X \\mid Y=1 \\sim \\mathcal{N}(\\mu,1)$，变量 $X-\\mu$ 服从 $\\mathcal{N}(0,1)$。因此，$\\mathbb{P}(X  t \\mid Y=1) = \\mathbb{P}(X-\\mu  t-\\mu \\mid Y=1) = \\Phi(t-\\mu)$。\n因此，错分风险为：\n$$\nR(t) = (1-\\pi)(1 - \\Phi(t)) + \\pi \\Phi(t-\\mu)\n$$\n\n### 2. 分层与非分层交叉验证风险\n\n**分层交叉验证风险：**\n在分层 $k$ 折划分中，构建的每个折都具有与整个数据集相同的类别比例。因此，任何一个折的训练集（由 $k-1$ 个折组成）也将具有这个精确的比例。因此，从训练集估计的经验先验 $\\hat{\\pi}$ 总是等于总体先验 $\\pi$。\n$$\n\\hat{\\pi}_{\\text{strat}} = \\pi\n$$\n所有折的决策阈值是恒定的：$t_{\\text{strat}} = t(\\pi) = \\frac{\\mu}{2} + \\frac{1}{\\mu}\\ln\\left(\\frac{1-\\pi}{\\pi}\\right)$。这是最优 Bayes 阈值。我们记为 $R_{\\text{strat}}$ 的最终风险，即 Bayes 错误率：\n$$\nR_{\\text{strat}} = R(t(\\pi)) = (1-\\pi)(1 - \\Phi(t(\\pi))) + \\pi \\Phi(t(\\pi)-\\mu)\n$$\n\n**非分层交叉验证风险：**\n在非分层划分中，数据被随机划分为 $k$ 个折。一个折的训练数据中少数类样本的数量是一个随机变量。设 $N$ 为总样本量，$M=N\\pi$ 为少数类样本总数，$n_{\\text{train}} = N(k-1)/k$ 为训练集大小。训练集中的少数类样本数量 $m$ 服从超几何分布，其参数为总体大小（$N$）、总体中成功次数（$M$）和抽样次数（$n_{\\text{train}}$）。我们将其记为 $m \\sim \\text{Hypergeometric}(N, M, n_{\\text{train}})$。\n其概率质量函数（PMF）为 $\\mathbb{P}(m) = \\frac{\\binom{M}{m}\\binom{N-M}{n_{\\text{train}}-m}}{\\binom{N}{n_{\\text{train}}}}$。\n给定折的经验先验是 $\\hat{\\pi} = m/n_{\\text{train}}$，它是一个随机变量。决策阈值 $t(\\hat{\\pi})$ 和相应的风险 $R(t(\\hat{\\pi}))$ 也是随机变量。期望的非分层交叉验证风险是此风险在 $m$ 分布上的期望：\n$$\n\\mathbb{E}\\left[R\\big(t(\\hat{\\pi})\\big)\\right] = \\sum_{m} \\mathbb{P}(m) \\cdot R\\left(t\\left(\\frac{m}{n_{\\text{train}}}\\right)\\right)\n$$\n求和遍及超几何分布的支撑集，$m \\in [\\max(0, n_{\\text{train}} - (N-M)), \\min(n_{\\text{train}}, M)]$。\n\n问题指定了如何处理 $\\hat{\\pi}=0$ 或 $\\hat{\\pi}=1$ 的边缘情况：\n-   如果 $\\hat{\\pi}=0$（即 $m=0$），$\\ln((1-\\hat{\\pi})/\\hat{\\pi}) \\to \\infty$，所以 $t(0) \\to \\infty$。分类器总是预测 $Y=0$。风险为 $R(\\infty) = (1-\\pi)(1-\\Phi(\\infty)) + \\pi \\Phi(\\infty-\\mu) = (1-\\pi) \\cdot 0 + \\pi \\cdot 1 = \\pi$。\n-   如果 $\\hat{\\pi}=1$（即 $m=n_{\\text{train}}$），$\\ln((1-\\hat{\\pi})/\\hat{\\pi}) \\to -\\infty$，所以 $t(1) \\to -\\infty$。分类器总是预测 $Y=1$。风险为 $R(-\\infty) = (1-\\pi)(1-\\Phi(-\\infty)) + \\pi \\Phi(-\\infty-\\mu) = (1-\\pi) \\cdot 1 + \\pi \\cdot 0 = 1-\\pi$。\n\n### 3. 误差膨胀 $\\Delta$\n\n误差膨胀 $\\Delta$ 定义为非分层交叉验证下的期望风险与分层交叉验证下的风险之差：\n$$\n\\Delta = \\mathbb{E}\\left[R\\big(t(\\hat{\\pi})\\big)\\right] - R_{\\text{strat}}\n$$\n这个量捕捉了由于非分层折中经验先验估计的可变性而导致的平均错分误差的增加。这种可变性将决策阈值推离最优 Bayes 阈值，并且由于风险函数在其最小值（Bayes 误差）附近的凸性，期望风险高于在期望先验下的风险。根据 Jensen 不等式，由于风险函数是凸的，$\\mathbb{E}[R(t(\\hat{\\pi}))] \\ge R(t(\\mathbb{E}[\\hat{\\pi}]))$。因为 $\\mathbb{E}[\\hat{\\pi}] = \\pi$，我们预期 $\\Delta \\ge 0$。我们的任务是为给定的测试用例计算此值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import hypergeom, norm\n\ndef solve():\n    \"\"\"\n    Computes the error inflation delta for a series of test cases.\n    \"\"\"\n    \n    # Test cases: tuples of (N, k, pi, mu)\n    test_cases = [\n        (500, 5, 0.05, 2.0),\n        (100, 10, 0.10, 1.5),\n        (5000, 10, 0.01, 1.0),\n        (1200, 4, 0.03, 3.0),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N, k, pi, mu = case\n        \n        # Ensure N*pi is an integer as per problem statement\n        M = int(round(N * pi))\n        n_train = int(N * (k - 1) / k)\n        \n        # --- 1. Calculate Stratified CV Risk (R_strat) ---\n        # The empirical prior is the true prior\n        pi_strat = pi\n        \n        # Calculate the Bayes optimal threshold t(pi)\n        # logit(pi) = log(pi / (1-pi)), so -log((1-pi)/pi)\n        t_strat = mu / 2.0 - (1.0 / mu) * np.log(pi_strat / (1.0 - pi_strat))\n        \n        # Calculate the risk R(t(pi)), which is the Bayes error rate\n        risk_type1_strat = 1.0 - norm.cdf(t_strat)\n        risk_type2_strat = norm.cdf(t_strat - mu)\n        R_strat = (1.0 - pi) * risk_type1_strat + pi * risk_type2_strat\n        \n        # --- 2. Calculate Expected Non-Stratified CV Risk (E_non_strat) ---\n        \n        # The number of minority samples 'm' in the training set follows a\n        # Hypergeometric distribution.\n        # Scipy's hypergeom(M, n, N) takes:\n        # M: total number of objects (our N)\n        # n: total number of type I objects (our M)\n        # N: number of draws (our n_train)\n        dist = hypergeom(M=N, n=M, N=n_train)\n        \n        # Support of the hypergeometric distribution for m\n        m_min = max(0, n_train - (N - M))\n        m_max = min(n_train, M)\n        \n        E_non_strat = 0.0\n        \n        for m in range(m_min, m_max + 1):\n            prob_m = dist.pmf(m)\n            \n            # If there's no probability mass, skip to avoid unnecessary calculation\n            if prob_m == 0:\n                continue\n\n            pi_hat = m / n_train\n            \n            # Handle edge cases as per problem statement\n            if m == 0:  # pi_hat = 0\n                risk_m = pi\n            elif m == n_train:  # pi_hat = 1\n                risk_m = 1.0 - pi\n            else:\n                # Calculate threshold t(pi_hat) for this m\n                t_m = mu / 2.0 - (1.0 / mu) * np.log(pi_hat / (1.0 - pi_hat))\n                \n                # Calculate risk R(t(pi_hat))\n                risk_type1_m = 1.0 - norm.cdf(t_m)\n                risk_type2_m = norm.cdf(t_m - mu)\n                risk_m = (1.0 - pi) * risk_type1_m + pi * risk_type2_m\n            \n            E_non_strat += prob_m * risk_m\n            \n        # --- 3. Compute Error Inflation Delta ---\n        delta = E_non_strat - R_strat\n        results.append(round(delta, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "确定了需要使用分层k折交叉验证后，下一个实际问题就是如何选择折数$k$。这个选择并非总是遵循$k=5$或$k=10$的简单法则。本练习将引导您将$k$的选择视为一个优化问题，在统计目标（最小化估计器方差）和现实约束（计算时间成本）之间进行权衡，从而找到最佳的$k$值。",
            "id": "3177490",
            "problem": "考虑一个总样本量为 $n=1200$ 的二元分类数据集，其中包含一个多数类（$n_{+}=900$ 个样本）和一个少数类（$n_{-}=300$ 个样本）。您计划使用分层 $k$ 折交叉验证 (CV) 来评估一个固定的分类器，其中各折保持整体的类别比例。设分层 $k$ 折交叉验证的风险估计量记为 $\\hat{R}_{\\mathrm{CV}}(k)$，定义为 $k$ 个留存折风险的算术平均值。\n\n假设通过先前的测量和标准缩放，已确定以下建模和计算方面的事实：\n- 风险估计量的方差服从参数模型 $V(k)\\approx \\frac{a}{k}+b$，其中常数 $a0$ 和 $b\\ge 0$ 概括了与数据和模型相关的可变性。一项初步研究得出 $a=0.6$ 和 $b=0.01$。\n- 分类器的训练运行时间与训练样本数 $m$ 成线性关系，即每折的训练时间为 $t(m)=c\\,m$，其中 $c0$ 为常数。在大小为 $n=1200$ 的完整训练集上进行的初步拟合耗时 $60$ 秒，这意味着 $c=\\frac{60}{1200}$ 秒/样本。\n- 分层 $k$ 折交叉验证的总运行时间主要由模型拟合决定，并由 $T(k)=k\\,t((1-\\frac{1}{k})\\,n)=c\\,n\\,(k-1)$ 给出。\n- 运行时间预算为 $T_{\\max}=220$ 秒。\n\n在分层 $k$ 折交叉验证中，为确保每折的测试分割至少包含来自每个类别的一个样本，并且在没有空层的情况下保持类别比例，您必须满足分层可行性界限 $k\\le \\min\\{n_{+},n_{-}\\}$。\n\n仅使用 $\\hat{R}_{\\mathrm{CV}}(k)$ 作为 $k$ 个留存风险平均值的定义、给定的方差模型 $V(k)$ 以及线性时间训练规模关系，推导出在约束条件 $T(k)\\le T_{\\max}$ 和分层可行性下，使 $V(k)$ 最小化的整数 $k^{*}$。将 $k^{*}$ 报告为单个整数。除了整数性所隐含的要求外，不需要进行额外的四舍五入。此外，通过说明多数类和少数类每折的测试分割大小，来验证您选择的 $k^{*}$ 允许进行分层划分（最终答案中不要包含这些验证值）。",
            "solution": "我们从分层 $k$ 折交叉验证 (CV) 的定义开始：CV 风险估计量 $\\hat{R}_{\\mathrm{CV}}(k)$ 是 $k$ 个留存折风险的平均值，每个风险都是在大小为 $\\frac{n}{k}$ 且类别比例得以保持的测试分割上计算的。对 $k$ 个逐折估计值求平均会因平均值的大数定律而降低可变性；与这一基本行为一致，给定的模型 $V(k)\\approx \\frac{a}{k}+b$ 捕捉了随着 $k$ 增加方差减小的趋势，以及由于模型不稳定性或数据异质性等不可约减来源而存在的非零下限 $b$。\n\n接下来，我们使用线性运行时间规模关系来刻画计算可行性。在 $m$ 个样本上每折的训练时间是 $t(m)=c\\,m$。初步测量提供了在 $n=1200$ 时的校准值 $t(n)=60$ 秒，因此\n$$\nc=\\frac{t(n)}{n}=\\frac{60}{1200}=0.05.\n$$\n在 $k$ 折交叉验证中，$k$ 次拟合中的每一次都使用 $(1-\\frac{1}{k})\\,n$ 个训练样本。因此总运行时间为\n$$\nT(k)=k\\,t\\!\\left(\\left(1-\\frac{1}{k}\\right)n\\right)=k\\,c\\,\\left(1-\\frac{1}{k}\\right)n=c\\,n\\,(k-1).\n$$\n代入 $c=0.05$ 和 $n=1200$，我们得到\n$$\nT(k)=0.05\\times 1200 \\times (k-1)=60\\,(k-1).\n$$\n运行时间预算为 $T_{\\max}=220$，因此可行性条件 $T(k)\\le T_{\\max}$ 变为\n$$\n60\\,(k-1)\\le 220 \\quad \\Longrightarrow \\quad k-1\\le \\frac{220}{60}=\\frac{11}{3} \\quad \\Longrightarrow \\quad k\\le 1+\\frac{11}{3}=\\frac{14}{3}.\n$$\n由于 $k$ 必须是整数，运行时间所允许的最大 $k$ 为\n$$\nk\\le \\left\\lfloor \\frac{14}{3}\\right\\rfloor = 4.\n$$\n\n分层可行性进一步要求每个测试分割至少包含来自每个类别的一个样本。一个充分条件是 $k\\le \\min\\{n_{+},n_{-}\\}$，在这里即为\n$$\nk\\le \\min\\{900,300\\}=300.\n$$\n这个界限比运行时间界限 $k\\le 4$ 宽松得多，因此起作用的约束是计算约束。\n\n为了在约束条件下最小化 $V(k)=\\frac{a}{k}+b$，我们利用单调性：对于 $a0$，$V(k)$ 关于 $k$ 是严格递减的，而 $b$ 不依赖于 $k$。因此，在约束条件下，最小值在最大的可行 $k$ 处取得。结合这些界限，最大的可行 $k$ 是\n$$\nk^{*}=4.\n$$\n\n最后，我们用 $k^{*}=4$ 来验证分层。每个测试分割的大小为 $\\frac{n}{k^{*}}=\\frac{1200}{4}=300$。保持比例可得出每折的测试计数为\n$$\n\\text{多数类}:\\ \\frac{n_{+}}{k^{*}}=\\frac{900}{4}=225, \\qquad \\text{少数类}:\\ \\frac{n_{-}}{k^{*}}=\\frac{300}{4}=75,\n$$\n这些都是整数且严格为正，因此分层折是可行的。由于 $V(k)$ 关于 $k$ 是递减的，并且 $k^{*}=4$ 是运行时间预算所允许的最大 $k$ 值，因此 $k^{*}=4$ 是在所述约束条件下 $V(k)$ 的最小化子。",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "在选择$k$时，我们通常倾向于选择较大的$k$以减小方差，但这可能带来一个陷阱：当某个类别的样本数量过少时会发生什么？如果一个类别的总样本数$n_c$甚至小于$k$，那么在某些折中，训练集或验证集可能不包含该类的任何样本，导致精确率或召回率等指标无法计算。这个练习将探讨这个问题，推导出一个确保交叉验证有效性的最小样本支持条件，并介绍一种在不满足该条件时仍能稳健评估模型性能的标准技术——拉普拉斯平滑。",
            "id": "3177513",
            "problem": "一个用于多类别分类任务的数据集包含一个特定的类别 $c$，其总数为 $n_c$。您计划使用分层 $k$ 折交叉验证来评估一个分类器，其中每一折都使用一个分层分割作为验证集，剩下的 $k-1$ 个分割作为训练集。分层意味着每一折的验证集会收到 $\\lfloor n_c/k \\rfloor$ 或 $\\lceil n_c/k \\rceil$ 个类别 $c$ 的实例，而相应的训练集则会收到类别 $c$ 的互补数量。\n\n在验证折上计算的类别 $c$ 的逐类召回率由混淆矩阵条目定义为 $\\mathrm{Recall}_c = \\frac{\\mathrm{TP}_c}{\\mathrm{TP}_c + \\mathrm{FN}_c}$，其中 $\\mathrm{TP}_c$ 和 $\\mathrm{FN}_c$ 分别表示该折验证集中类别 $c$ 的真正例和假负例的数量。逐类精确率定义为 $\\mathrm{Precision}_c = \\frac{\\mathrm{TP}_c}{\\mathrm{TP}_c + \\mathrm{FP}_c}$，其中 $\\mathrm{FP}_c$ 表示验证集中类别 $c$ 的假正例的数量。如果某个指标的分母为 0，则该指标在该折中未定义。\n\n仅从上述定义和分层 $k$ 折分配规则出发，推导出一个关于 $n_c$（作为 $k$ 的函数）的保守的最小逐类支持度要求，该要求需保证在每个折的验证集中，类别 $c$ 的实际支持度严格为正（从而使召回率的分母严格为正），同时确保该折对应的训练集至少包含一个类别 $c$ 的实例。为消除舍入的边界情况，施加一个更强的要求，即每个验证折必须至少包含 2 个类别 $c$ 的实例。\n\n然后，对于 $n_c  2k$ 的情况，提出一个加性拉普拉斯平滑方案，该方案使得逐类精确率和召回率在每个折中都有定义，无论是否存在零计数。具体来说，将一个对称的加性常数 $\\alpha  0$ 应用于验证集中类别 $c$ 的“一对多”(one-versus-rest)分解的每个混淆矩阵单元，并推导出平滑后的逐类精确率和平滑后的逐类召回率的闭式表达式，用 $\\mathrm{TP}_c$、$\\mathrm{FP}_c$、$\\mathrm{FN}_c$ 和 $\\alpha$ 表示。\n\n你的最终答案必须列出：\n- 在所述保守要求下，以 $k$ 表示的最小 $n_c$，以及\n- 拉普拉斯平滑的逐类精确率和召回率的解析表达式。\n\n所有量均需以符号表示。无需进行数值舍入。",
            "solution": "这个问题包含两个部分。第一部分是确定在分层 $k$ 折交叉验证设置中，类别 $c$ 的最小总数 $n_c$ 需要满足的特定条件。第二部分是推导拉普拉斯平滑的逐类精确率和召回率的表达式。\n\n第 1 部分：最小逐类支持度要求\n\n设 $n_c$ 是数据集中类别 $c$ 的实例总数，设 $k$ 是交叉验证的折数，其中 $k$ 是一个大于或等于 2 的整数。\n\n在分层 $k$ 折交叉验证中，$n_c$ 个实例被划分为 $k$ 个不相交的子集（折）。对于任何给定的折 $i$（其中 $i \\in \\{1, 2, \\dots, k\\}$），该折的子集作为验证集，其他 $k-1$ 个子集的并集作为训练集。\n\n设 $n_{c, \\text{val}}^{(i)}$ 是第 $i$ 折验证集中类别 $c$ 的实例数。根据问题的分层规则，这个数量由下式给出：\n$$n_{c, \\text{val}}^{(i)} \\in \\{\\lfloor n_c/k \\rfloor, \\lceil n_c/k \\rceil\\}$$\n设 $n_{c, \\text{train}}^{(i)}$ 是第 $i$ 折对应训练集中类别 $c$ 的实例数。由于训练集和验证集相对于类别 $c$ 的所有实例是互补的：\n$$n_{c, \\text{train}}^{(i)} = n_c - n_{c, \\text{val}}^{(i)}$$\n问题提出了两个必须对*每个*折 $i$ 都满足的要求：\n1. 每个折的验证集必须至少包含 2 个类别 $c$ 的实例。\n2. 每个折的训练集必须至少包含 1 个类别 $c$ 的实例。\n\n让我们将这些要求形式化为不等式。\n要求 1：对于所有 $i \\in \\{1, 2, \\dots, k\\}$,\n$$n_{c, \\text{val}}^{(i)} \\geq 2$$\n为了保证每个折都满足此条件，该条件即使在接收到最少实例数的折中也必须成立。分配给任何折的验证集的最小实例数是 $\\lfloor n_c/k \\rfloor$。因此，我们必须强制要求：\n$$\\lfloor n_c/k \\rfloor \\geq 2$$\n根据向下取整函数的定义，如果对于整数 $m$ 有 $\\lfloor x \\rfloor \\geq m$，则 $x \\geq m$。应用此定义，我们得到：\n$$\\frac{n_c}{k} \\geq 2 \\implies n_c \\geq 2k$$\n\n要求 2：对于所有 $i \\in \\{1, 2, \\dots, k\\}$,\n$$n_{c, \\text{train}}^{(i)} \\geq 1$$\n代入训练集计数的表达式，我们有：\n$$n_c - n_{c, \\text{val}}^{(i)} \\geq 1$$\n为了保证每个折都满足此条件，该条件即使在训练集最小时也必须成立。当对应的验证集大小 $n_{c, \\text{val}}^{(i)}$ 最大化时，训练集大小 $n_{c, \\text{train}}^{(i)}$ 被最小化。分配给任何折的验证集的最大实例数是 $\\lceil n_c/k \\rceil$。因此，我们必须强制要求：\n$$n_c - \\lceil n_c/k \\rceil \\geq 1$$\n\n我们现在对 $n_c$ 有两个条件：$n_c \\geq 2k$ 和 $n_c - \\lceil n_c/k \\rceil \\geq 1$。最终的 $n_c$ 最小值必须同时满足两者。让我们检查第一个看似更严格的条件 ($n_c \\geq 2k$) 是否足以满足第二个条件。\n\n假设 $n_c \\geq 2k$。我们知道对于任何实数 $x$，$\\lceil x \\rceil  x+1$。设 $x = n_c/k$。\n$$n_c - \\lceil n_c/k \\rceil > n_c - \\left(\\frac{n_c}{k} + 1\\right) = n_c \\left(1 - \\frac{1}{k}\\right) - 1 = \\frac{n_c(k-1)}{k} - 1$$\n由于我们假设 $n_c \\geq 2k$，我们可以将其代入不等式：\n$$\\frac{n_c(k-1)}{k} - 1 \\geq \\frac{2k(k-1)}{k} - 1 = 2(k-1) - 1 = 2k - 2 - 1 = 2k - 3$$\n因此，我们已证明 $n_c - \\lceil n_c/k \\rceil > 2k-3$。为使条件 $n_c - \\lceil n_c/k \\rceil \\geq 1$ 成立，我们需要 $2k-3 \\geq 0$（因为左侧是整数）。对于 $k \\geq 1.5$，这是成立的。由于 $k$ 代表折数，通常假设 $k \\geq 2$，所以这个条件是满足的。\n因此，条件 $n_c \\geq 2k$ 是两者中更严格的，并且足以保证两个要求都得到满足。\n\n问题要求最小的逐类支持度 $n_c$。由于 $n_c$ 必须是整数，满足 $n_c \\geq 2k$ 的最小值是 $n_c = 2k$。\n\n第 2 部分：拉普拉斯平滑指标\n\n问题要求平滑后的逐类精确率和召回率的表达式。平滑是通过向类别 $c$ 的“一对多”混淆矩阵的每个单元格添加一个常数 $\\alpha  0$ 来执行的。\n\n类别 $c$ 的“一对多”混淆矩阵基于在验证集上做出的预测，有四个单元格：\n- $\\mathrm{TP}_c$：真正例（正确预测为类别 $c$）\n- $\\mathrm{FN}_c$：假负例（错误预测为非类别 $c$）\n- $\\mathrm{FP}_c$：假正例（错误预测为类别 $c$）\n- $\\mathrm{TN}_c$：真负例（正确预测为非类别 $c$）\n\n应用对称加性平滑后，平滑后的计数变为：\n- $\\mathrm{TP}'_c = \\mathrm{TP}_c + \\alpha$\n- $\\mathrm{FN}'_c = \\mathrm{FN}_c + \\alpha$\n- $\\mathrm{FP}'_c = \\mathrm{FP}_c + \\alpha$\n- $\\mathrm{TN}'_c = \\mathrm{TN}_c + \\alpha$\n\n类别 $c$ 的逐类召回率的标准定义是：\n$$\\mathrm{Recall}_c = \\frac{\\mathrm{TP}_c}{\\mathrm{TP}_c + \\mathrm{FN}_c}$$\n分母 $\\mathrm{TP}_c + \\mathrm{FN}_c$ 代表验证集中类别 $c$ 的实际实例总数。\n\n平滑后的召回率 $\\mathrm{Recall}'_c$ 是通过将平滑后的计数代入此公式得出的：\n$$\\mathrm{Recall}'_c = \\frac{\\mathrm{TP}'_c}{\\mathrm{TP}'_c + \\mathrm{FN}'_c} = \\frac{\\mathrm{TP}_c + \\alpha}{(\\mathrm{TP}_c + \\alpha) + (\\mathrm{FN}_c + \\alpha)} = \\frac{\\mathrm{TP}_c + \\alpha}{\\mathrm{TP}_c + \\mathrm{FN}_c + 2\\alpha}$$\n\n类别 $c$ 的逐类精确率的标准定义是：\n$$\\mathrm{Precision}_c = \\frac{\\mathrm{TP}_c}{\\mathrm{TP}_c + \\mathrm{FP}_c}$$\n分母 $\\mathrm{TP}_c + \\mathrm{FP}_c$ 代表被预测为类别 $c$ 的实例总数。\n\n平滑后的精确率 $\\mathrm{Precision}'_c$ 是通过将平滑后的计数代入此公式得出的：\n$$\\mathrm{Precision}'_c = \\frac{\\mathrm{TP}'_c}{\\mathrm{TP}'_c + \\mathrm{FP}'_c} = \\frac{\\mathrm{TP}_c + \\alpha}{(\\mathrm{TP}_c + \\alpha) + (\\mathrm{FP}_c + \\alpha)} = \\frac{\\mathrm{TP}_c + \\alpha}{\\mathrm{TP}_c + \\mathrm{FP}_c + 2\\alpha}$$\n由于 $\\alpha  0$ 且计数（$\\mathrm{TP}_c$、$\\mathrm{FP}_c$、$\\mathrm{FN}_c$）是非负整数，这些平滑指标的分母保证严格为正，从而确保这些指标总是有定义的。\n\n最终答案需要三个组成部分：以 $k$ 表示的最小 $n_c$，平滑精确率的表达式，以及平滑召回率的表达式。\n1. 最小 $n_c$：$2k$\n2. 平滑精确率：$\\frac{\\mathrm{TP}_c + \\alpha}{\\mathrm{TP}_c + \\mathrm{FP}_c + 2\\alpha}$\n3. 平滑召回率：$\\frac{\\mathrm{TP}_c + \\alpha}{\\mathrm{TP}_c + \\mathrm{FN}_c + 2\\alpha}$",
            "answer": "$$\\boxed{\\begin{pmatrix} 2k  \\frac{\\mathrm{TP}_c + \\alpha}{\\mathrm{TP}_c + \\mathrm{FP}_c + 2\\alpha}  \\frac{\\mathrm{TP}_c + \\alpha}{\\mathrm{TP}_c + \\mathrm{FN}_c + 2\\alpha} \\end{pmatrix}}$$"
        }
    ]
}