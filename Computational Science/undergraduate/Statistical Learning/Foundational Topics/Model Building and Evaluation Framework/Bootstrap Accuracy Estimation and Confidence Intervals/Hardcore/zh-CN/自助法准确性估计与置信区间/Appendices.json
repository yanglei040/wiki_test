{
    "hands_on_practices": [
        {
            "introduction": "我们从一个基础但至关重要的练习开始。在评估分类器性能时，准确率是一个核心指标，但仅仅一个点估计值无法告诉我们其不确定性。本实践将指导你使用非参数自助法（bootstrap），通过对混淆矩阵进行重抽样，来量化分类器准确率的置信区间，从而让你更深入地理解模型性能估计的稳定性。",
            "id": "3106305",
            "problem": "给定一个二元分类场景，以及一个数据集的观测混淆矩阵条目。混淆矩阵的条目定义如下：$TP$ 是真阳性 (true positives) 的数量，$FP$ 是假阳性 (false positives) 的数量，$TN$ 是真阴性 (true negatives) 的数量，$FN$ 是假阴性 (false negatives) 的数量。准确率定义为 $A = (TP + TN)/n$，其中 $n = TP + FP + TN + FN$ 是观测总数。你将使用非参数自助法 (nonparametric bootstrap) 来量化混淆矩阵条目向量 $(TP, FP, TN, FN)$ 的不确定性，并将此不确定性传播到准确率的置信区间。你还将评估混淆矩阵条目之间的协方差效应。\n\n基本原理：\n- 非参数自助法通过从经验分布中有放回地重抽样来近似抽样分布。\n- 四个分类结果 $(TP, FP, TN, FN)$ 的经验分布将质量 $\\hat{p}_k = c_k / n$ 赋予每个类别 $k \\in \\{TP, FP, TN, FN\\}$，其中 $c_k$ 是观测到的计数。从经验分布中抽取的规模为 $n$ 的自助样本，其计数向量服从一个多项分布，参数为 $n$ 和概率 $(\\hat{p}_{TP}, \\hat{p}_{FP}, \\hat{p}_{TN}, \\hat{p}_{FN})$。\n- 置信区间 (CI) 可以通过百分位法形成：对于一个统计量 $T$，在选定的置信水平 $1-\\alpha$ 下，其下限和上限分别是 $T$ 的自助法复制样本的 $\\alpha/2$ 和 $1-\\alpha/2$ 经验分位数。\n- 对于随机向量 $X$ 的一个平滑函数 $g$，delta 方法给出了一个近似 $\\mathrm{Var}(g(X)) \\approx \\nabla g(\\mu)^\\top \\Sigma \\nabla g(\\mu)$，其中 $\\mu = \\mathbb{E}[X]$，$\\Sigma = \\mathrm{Cov}(X)$，$\\nabla g$ 是梯度。当 $\\Sigma$ 通过向量 $(TP, FP, TN, FN)$ 的自助法协方差来估计时，这将为 $A$ 产生一个正态近似置信区间。\n\n你的程序必须为每个测试用例实现以下步骤：\n1. 使用观测到的混淆矩阵计数 $(TP, FP, TN, FN)$ 和总数 $n$ 来定义经验概率 $\\hat{p}_{TP} = TP/n$，$\\hat{p}_{FP} = FP/n$，$\\hat{p}_{TN} = TN/n$，$\\hat{p}_{FN} = FN/n$。\n2. 通过从一个规模为 $n$、类别概率为 $(\\hat{p}_{TP}, \\hat{p}_{FP}, \\hat{p}_{TN}, \\hat{p}_{FN})$ 的多项分布中抽样，生成 $B$ 个自助法复制的计数向量。使用固定的随机种子以确保可复现性。\n3. 对于每个自助法复制 $b$，计算准确率 $A^{(b)} = (TP^{(b)} + TN^{(b)})/n$。\n4. 通过取 $\\{A^{(b)}\\}$ 在 $q_{\\mathrm{low}} = \\alpha/2$ 和 $q_{\\mathrm{high}} = 1-\\alpha/2$ 处的经验分位数，构建准确率在置信水平 $1-\\alpha$ 下的百分位置信区间。\n5. 估计向量 $(TP, FP, TN, FN)$ 的自助法复制的协方差矩阵 $\\hat{\\Sigma}$，并使用 delta 方法构建准确率在置信水平 $1-\\alpha$ 下的正态近似置信区间。具体来说，使用准确率作为 $(TP, FP, TN, FN)$ 的函数在观测计数值处的线性化来获得标准误，然后构建对称的正态置信区间。不要将区间裁剪到 $[0,1]$；以小数形式报告原始端点。\n6. 通过计算自助法复制中 $(TP, TN)$ 之间以及 $(TP, FP)$ 之间的自助法相关性，评估协方差效应。如果一对中的任何一个分量的自助法方差为零，则将相关性定义为 $0$。\n\n测试套件：\n- 案例 $1$（均衡，中等准确率）：$n = 200$，$(TP, FP, TN, FN) = (70, 20, 90, 20)$。\n- 案例 $2$（不均衡，罕见阳性）：$n = 300$，$(TP, FP, TN, FN) = (5, 25, 260, 10)$。\n- 案例 $3$（小样本，退化预测器）：$n = 40$，$(TP, FP, TN, FN) = (0, 0, 28, 12)$。\n\n所有案例的通用设置：\n- 置信水平：$1-\\alpha = 0.95$（所以 $\\alpha = 0.05$）。\n- 自助法复制数量：$B = 40000$。\n- 随机种子：$R = 1729$。\n- 所有与准确率相关的量必须以小数形式报告，而不是百分比。\n\n每个测试用例所需的输出：\n- 一个包含 $7$ 个浮点数的列表，按以下顺序排列：\n  - 准确率点估计值 $A$。\n  - $A$ 的百分位置信区间下限。\n  - $A$ 的百分位置信区间上限。\n  - $A$ 的 Delta 方法置信区间下限。\n  - $A$ 的 Delta 方法置信区间上限。\n  - 从自助法复制中估计的 $(TP, TN)$ 之间的相关性。\n  - 从自助法复制中估计的 $(TP, FP)$ 之间的相关性。\n- 如果由于任一分量的方差为零而导致相关性未定义，则该相关性返回 $0$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个逗号分隔的各案例结果列表，并用方括号括起来，每个案例的结果本身也是一个方括号括起来的、按上述顺序排列的逗号分隔列表。所有浮点数必须四舍五入到 $6$ 位小数。例如，包含两个案例的输出将如下所示：$[[0.800000,0.750000,0.840000,0.760000,0.840000,-0.300000,-0.200000],[\\dots]]$。",
            "solution": "用户先验地声明问题陈述是有效的。我的分析证实了这一点：该问题具有科学依据，提法明确，客观，并且没有其他使其无效的缺陷。它完全属于计算统计学和统计学习的范畴，所有必要的参数和定义都已提供，以确保一个独特且可验证的解决方案。\n\n目标是基于混淆矩阵计数 $(TP, FP, TN, FN)$，使用非参数自助法来分析二元分类器准确率的不确定性。我们将计算准确率的点估计，构建两种类型的置信区间（百分位法和 Delta 方法），并评估某些计数分量之间的相关性。观测总数为 $n = TP + FP + TN + FN$。\n\n准确率 $A$ 定义为正确预测的比例：\n$$A = \\frac{TP + TN}{n}$$\n这作为我们真实准确率的点估计，由观测计数计算得出。\n\n分析的核心是非参数自助法。该方法通过从观测数据中有放回地抽样来模拟抽样过程。对于由计数 $(c_{TP}, c_{FP}, c_{TN}, c_{FN})$ 概括的分类数据，这等同于从经验概率分布中抽样。经验概率为 $\\hat{p}_k = c_k / n$，适用于每个类别 $k \\in \\{TP, FP, TN, FN\\}$。一个计数的自助样本是一个向量 $\\mathbf{c}^{(b)} = (TP^{(b)}, FP^{(b)}, TN^{(b)}, FN^{(b)})$，它从一个具有 $n$ 次试验和概率向量 $\\hat{\\mathbf{p}} = (\\hat{p}_{TP}, \\hat{p}_{FP}, \\hat{p}_{TN}, \\hat{p}_{FN})$ 的多项分布中抽取。\n$$\\mathbf{c}^{(b)} \\sim \\mathrm{Multinomial}(n, \\hat{\\mathbf{p}})$$\n我们生成 $B = 40000$ 个这样的自助法复制向量。\n\n对于每个计数的自助法复制 $\\mathbf{c}^{(b)}$，我们计算相应的准确率：\n$$A^{(b)} = \\frac{TP^{(b)} + TN^{(b)}}{n}$$\n这个过程产生了一个包含 $B$ 个自助法准确率的分布 $\\{A^{(b)}\\}_{b=1}^B$，它近似了准确率估计值 $A$ 的抽样分布。\n\n我们从这个自助法分布中，使用百分位法为准确率构建一个 $(1-\\alpha)$ 置信区间。对于置信水平 $1-\\alpha = 0.95$（即 $\\alpha=0.05$），区间的下限和上限分别是自助法准确率 $\\{A^{(b)}\\}$ 的 $q_{\\mathrm{low}} = \\alpha/2 = 0.025$ 和 $q_{\\mathrm{high}} = 1 - \\alpha/2 = 0.975$ 经验分位数。\n$$\\text{CI}_{\\text{percentile}} = [Q_{0.025}, Q_{0.975}]$$\n\n接下来，我们使用 Delta 方法构建一个置信区间。该方法使用一阶泰勒展开来近似一个随机变量函数的方差。在这里，准确率是计数向量 $\\mathbf{c} = (TP, FP, TN, FN)$ 的函数：$A = g(\\mathbf{c}) = (TP + TN)/n$。该函数相对于计数的梯度是一个常数向量：\n$$\\nabla g = \\left( \\frac{\\partial g}{\\partial TP}, \\frac{\\partial g}{\\partial FP}, \\frac{\\partial g}{\\partial TN}, \\frac{\\partial g}{\\partial FN} \\right)^\\top = \\left( \\frac{1}{n}, 0, \\frac{1}{n}, 0 \\right)^\\top$$\nDelta 方法将 $A$ 的方差近似为：\n$$\\widehat{\\mathrm{Var}}(A) \\approx (\\nabla g)^\\top \\hat{\\Sigma} (\\nabla g)$$\n其中 $\\hat{\\Sigma}$ 是自助法计数向量 $\\{\\mathbf{c}^{(b)}\\}_{b=1}^B$ 的样本协方差矩阵。$A$ 的标准误是 $SE(A) = \\sqrt{\\widehat{\\mathrm{Var}}(A)}$。然后，围绕点估计 $A$ 对称地构建 $(1-\\alpha)$ 正态近似置信区间：\n$$\\text{CI}_{\\text{delta}} = [A - z_{1-\\alpha/2} \\cdot SE(A), A + z_{1-\\alpha/2} \\cdot SE(A)]$$\n其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$-分位数。对于 $\\alpha=0.05$，$z_{0.975} \\approx 1.96$。\n\n最后，我们通过计算自助法复制中计数分量之间的相关性来评估它们之间的关系。两个分量（例如 $X_i$ 和 $X_j$，如 $TP$ 和 $TN$）之间的相关性，可以从自助法协方差矩阵 $\\hat{\\Sigma}$ 中估计：\n$$\\hat{\\rho}_{ij} = \\frac{\\hat{\\Sigma}_{ij}}{\\sqrt{\\hat{\\Sigma}_{ii} \\hat{\\Sigma}_{jj}}}$$\n其中 $\\hat{\\Sigma}_{ii}$ 和 $\\hat{\\Sigma}_{jj}$ 是方差。如果任一分量的自助法方差为 $0$（当经验概率为 $0$ 时发生），则相关性定义为 $0$。\n\n实现将通过遍历每个测试用例，并使用固定的随机种子 $R=1729$ 应用这些步骤以保证可复现性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes bootstrap confidence intervals and correlations for classifier accuracy.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # ((TP, FP, TN, FN), n)\n        ((70, 20, 90, 20), 200),\n        ((5, 25, 260, 10), 300),\n        ((0, 0, 28, 12), 40),\n    ]\n\n    # Common settings for all cases\n    B = 40000\n    alpha = 0.05\n    R = 1729\n    rng = np.random.default_rng(R)\n\n    all_results_str = []\n    for case in test_cases:\n        counts, n = case\n        \n        # 1. Point estimate and empirical probabilities\n        tp, fp, tn, fn = counts\n        A = (tp + tn) / n\n        p_hat = np.array(counts) / n\n\n        # 2. Generate B bootstrap replicates of the count vector\n        # Each row is a draw from Multinomial(n, p_hat)\n        bootstrap_counts = rng.multinomial(n, p_hat, size=B)\n\n        # 3. Compute accuracy for each bootstrap replicate\n        bootstrap_accuracies = (bootstrap_counts[:, 0] + bootstrap_counts[:, 2]) / n\n\n        # 4. Construct percentile confidence interval\n        q_low = alpha / 2\n        q_high = 1 - alpha / 2\n        ci_percentile_low = np.quantile(bootstrap_accuracies, q_low)\n        ci_percentile_high = np.quantile(bootstrap_accuracies, q_high)\n\n        # 5. Construct delta-method confidence interval\n        # Estimate covariance matrix from bootstrap replicates\n        cov_mat = np.cov(bootstrap_counts, rowvar=False)\n        \n        # Gradient of accuracy function g(TP, FP, TN, FN) = (TP + TN)/n\n        grad_g = np.array([1/n, 0, 1/n, 0])\n        \n        # Delta method variance approximation\n        var_A_delta = grad_g.T @ cov_mat @ grad_g\n        # Use max(0, ...) for numerical stability, though var should be non-negative\n        se_A_delta = np.sqrt(max(0, var_A_delta))\n        \n        z_val = norm.ppf(q_high)\n        ci_delta_low = A - z_val * se_A_delta\n        ci_delta_high = A + z_val * se_A_delta\n\n        # 6. Assess covariance effects by computing correlations\n        var_tp = cov_mat[0, 0]\n        var_fp = cov_mat[1, 1]\n        var_tn = cov_mat[2, 2]\n\n        # Correlation between TP and TN\n        if var_tp == 0 or var_tn == 0:\n            corr_tp_tn = 0.0\n        else:\n            cov_tp_tn = cov_mat[0, 2]\n            corr_tp_tn = cov_tp_tn / np.sqrt(var_tp * var_tn)\n\n        # Correlation between TP and FP\n        if var_tp == 0 or var_fp == 0:\n            corr_tp_fp = 0.0\n        else:\n            cov_tp_fp = cov_mat[0, 1]\n            corr_tp_fp = cov_tp_fp / np.sqrt(var_tp * var_fp)\n\n        # Collate and format results for the current case\n        case_results = [A, ci_percentile_low, ci_percentile_high, ci_delta_low, ci_delta_high, corr_tp_tn, corr_tp_fp]\n        formatted_case_results = [f\"{x:.6f}\" for x in case_results]\n        all_results_str.append(f\"[{','.join(formatted_case_results)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "标准的自助法假设数据点是独立同分布的（i.i.d.），但在许多现实场景中，例如处理图像或时间序列数据时，这个假设并不成立。本练习通过一个模拟研究，让你直观地看到忽略空间相关性所带来的问题，并引入块状自助法（block bootstrap）作为解决方案。你将亲手实现并比较朴素自助法与块状自助法在覆盖率上的表现，从而理解在处理相关数据时保留其依赖结构的重要性。",
            "id": "3106269",
            "problem": "考虑一个在大小为 $N \\times N$ 像素的单张合成图像上的像素二元分类任务，其中相邻像素的分类正确性表现出空间相关性。令 $X_{ij} \\in \\{0,1\\}$ 表示在像素 $(i,j)$ 处分类正确的指示变量，并将整个图像的经验准确率定义为\n$$\n\\hat{A} \\;=\\; \\frac{1}{N^2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} X_{ij}.\n$$\n假设空间相关的正确性具有以下生成机制：\n- 为所有像素独立地抽取一个白噪声场 $W_{ij} \\sim \\mathcal{N}(0,1)$。\n- 通过与标准差为 $s$ 的归一化各向同性高斯核进行卷积来平滑 $W$，从而获得一个相关的场 $Z_{ij}$。\n- 设定一个基准logit水平 $\\alpha = \\log\\left(\\frac{p}{1-p}\\right)$，其中 $p$ 是一个不相关模型的目标基准正确率概率。\n- 通过logistic映射定义逐像素的正确率概率 $\\pi_{ij} = \\frac{1}{1 + e^{-(\\alpha + Z_{ij})}}$，然后在给定场的条件下，跨像素独立地抽取 $X_{ij} \\sim \\mathrm{Bernoulli}(\\pi_{ij})$。\n\n为了使用自助法对 $\\hat{A}$ 进行推断，考虑应用于单个观测图像的两种重抽样方案：\n- 在像素级别进行的独立同分布 (iid) 自助法重抽样，其中通过从 $N^2$ 个观测像素中有放回地抽取 $N^2$ 个像素来形成重抽样样本，并计算重抽样指示变量的均值。\n- 一种基于图像块的块状自助法重抽样，该方法通过从图像中所有可能的重叠 $b \\times b$ 图像块中有放回地抽取方形图像块（块）来保持空间依赖性；拼接足够数量的图像块以达到至少 $N^2$ 个像素，并计算拼接图像块的前 $N^2$ 个像素的均值。\n\n对于每种重抽样方案，通过取重抽样均值的自助法分布的 $0.025$ 和 $0.975$ 水平上的经验下分位数和上分位数，为 $\\hat{A}$ 构建一个双侧自助法置信区间 (CI)。对于给定的方案和单次图像实现，将覆盖定义为置信区间包含在完整图像像素上计算的真实经验准确率 $\\hat{A}$ 这一事件。在图像的重复独立实现（新的 $W$ 和 $X$ 抽取）中，将覆盖率定义为其置信区间包含相应 $\\hat{A}$ 的实现所占的比例。此覆盖率必须表示为 $[0,1]$ 区间内的一个小数。\n\n从自助法重抽样、置信区间和经验准确率的核心定义出发，实现一个程序，该程序：\n1. 根据上述机制生成 $R$ 个独立的图像实现。\n2. 对于每次实现，计算 $\\hat{A}$ 和两个自助法置信区间（iid像素级和基于块的块状自助法），每种方案使用 $B$ 个自助法重抽样样本。\n3. 记录每个置信区间是否覆盖 $\\hat{A}$，并对两种方案在 $R$ 次实现中汇总覆盖率。\n\n为了可复现性，使用一个固定的伪随机种子 $2025$。使用一个标准差为 $s$ 且方形支持域边长为 $L = 2\\lceil 3s \\rceil + 1$ 像素的高斯卷积核，并将其归一化以使总和为 $1$。基准正确率参数 $p$ 仅通过 $\\alpha$ 出现；所有其他符号均如上文所定义。\n\n测试套件。为以下四组参数运行程序，其中 $N$ 是图像边长，$p$ 是基准正确率概率，$s$ 控制空间相关性（作为高斯核标准差），$b$ 是块状自助法的图像块边长，$R$ 是实现次数，$B$ 是每种方案的自助法重抽样次数：\n- 情况 1：$(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,1.0,\\,1,\\,200,\\,400\\,)$。\n- 情况 2：$(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,2.0,\\,4,\\,200,\\,400\\,)$。\n- 情况 3：$(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,2.0,\\,8,\\,200,\\,400\\,)$。\n- 情况 4：$(N,p,s,b,R,B) = (\\,32,\\,0.80,\\,4.0,\\,4,\\,200,\\,400\\,)$。\n\n您的程序必须生成单行输出，其中包含所有四种情况下iid和块状自助法方案的覆盖率。所需格式为一个逗号分隔的列表，该列表包含四个由两个浮点数组成的列表，并用方括号括起来。具体而言，输出必须是以下形式：\n$$\n[\\,[c^{\\mathrm{iid}}_1, c^{\\mathrm{block}}_1], [c^{\\mathrm{iid}}_2, c^{\\mathrm{block}}_2], [c^{\\mathrm{iid}}_3, c^{\\mathrm{block}}_3], [c^{\\mathrm{iid}}_4, c^{\\mathrm{block}}_4]\\,]\n$$\n其中 $c^{\\mathrm{iid}}_k$ 和 $c^{\\mathrm{block}}_k$ 是情况 $k$ 的覆盖率，每个都报告为 $[0,1]$ 区间内的小数。",
            "solution": "用户希望在空间相关的合成图像上，评估两种基于自助法（bootstrap）的置信区间方案对像素分类器平均准确率的覆盖率。该问题定义明确，并基于标准的统计模拟方法论。我们将通过实现指定的数据生成过程和两种重抽样方案（IID和块状自助法），并将它们包装在蒙特卡洛模拟中来估计覆盖概率。\n\n### 算法分解\n\n问题的核心是进行一项模拟研究。对于指定的四个参数集中的每一个，我们必须执行以下步骤：\n\n1.  **初始化**：为了可复现性，使用指定的种子 $2025$ 设置一个主伪随机数生成器 (RNG)。将 IID 和块状自助法两种方案的覆盖计数器初始化为零。\n\n2.  **蒙特卡洛循环**：重复 $R$ 次（对于 $R$ 个独立实现）：\n    a. **数据生成**：根据指定的空间相关模型，生成一个表示分类正确性的 $N \\times N$ 二进制图像 $X$。\n        i.  生成一个 $N \\times N$ 的标准正态白噪声场 $W_{ij}$。\n        ii. 创建一个标准差为 $s$、支持域边长为 $L = 2\\lceil 3s \\rceil + 1$ 的二维高斯卷积核。该核必须归一化，使其元素总和为 $1$。\n        iii. 将噪声场 $W$ 与高斯核进行卷积，以生成一个空间相关的 高斯场 $Z$。我们将使用周期性边界条件 (`wrap`) 来避免边缘效应。\n        iv. 将基准正确率概率 $p$ 转换为 logit 尺度参数 $\\alpha = \\log(p/(1-p))$。\n        v.  使用 logistic 函数将相关场 $Z$ 转换为逐像素的正确率概率 $\\pi_{ij}$：$\\pi_{ij} = (1 + e^{-(\\alpha + Z_{ij})})^{-1}$。\n        vi. 生成最终的二进制图像 $X$，其中每个像素 $X_{ij}$ 是一个成功概率为 $\\pi_{ij}$ 的独立伯努利试验。\n\n    b. **真实准确率**：计算生成的图像 $X$ 的经验准确率 $\\hat{A}$，它就是所有像素值的均值：$\\hat{A} = \\frac{1}{N^2} \\sum_{i,j} X_{ij}$。该值作为置信区间旨在捕获的“真实”参数。\n\n    c. **IID 自助法置信区间**：\n        i.  通过从图像 $X$ 的 $N^2$ 个像素中有放回地抽取 $N^2$ 个像素，生成 $B$ 个自助法样本。\n        ii. 对于每个自助法样本，计算其均值。这将产生一个包含 $B$ 个自助法均值的分布。\n        iii. 通过找到该分布的第 $2.5$ 和第 $97.5$ 百分位数来构建一个 $95\\%$ 的置信区间。\n\n    d. **块状自助法置信区间**：\n        i.  生成 $B$ 个块状自助法样本。每个样本的构建方法如下：\n            - 识别图像 $X$ 中所有重叠的 $b \\times b$ 块。\n            - 计算需要抽取的块数，$M = \\lceil N^2 / b^2 \\rceil$。\n            - 有放回地抽取 $M$ 个块。\n            - 拼接抽取的块，并取前 $N^2$ 个像素。\n        ii. 对于 $B$ 个得到的长度为 $N^2$ 的像素序列，分别计算其均值。这将产生一个包含 $B$ 个块状自助法均值的分布。\n        iii. 使用该分布的第 $2.5$ 和第 $97.5$ 百分位数构建一个 $95\\%$ 的置信区间。\n\n    e. **覆盖性检查**：\n        i.  检查 IID 自助法置信区间是否包含 $\\hat{A}$。如果包含，则增加 IID 覆盖计数器。\n        ii. 检查块状自助法置信区间是否包含 $\\hat{A}$。如果包含，则增加块状自助法覆盖计数器。\n\n3.  **计算覆盖率**：在 $R$ 次重复之后，通过将每种方案的覆盖计数器除以 $R$ 来计算其覆盖率。\n\n4.  **对所有情况重复**：为提供的四个参数集中的每一个执行整个过程。\n\n### 实现细节\n\n-   **RNG**：将使用种子创建一个 `numpy.random.default_rng` 实例，并将其传递给所有需要随机数生成的函数，以确保完全的可复现性。\n-   **向量化**：为确保计算效率，自助法过程将被向量化。我们将一次性生成所有 $B$ 个自助法样本的随机索引，而不是循环 $B$ 次，并利用 NumPy 的高级索引和广播功能同时计算所有 $B$ 个自助法均值。\n-   **步幅技巧 (Stride Tricks)**：提取用于块状自助法的重叠块可能成为瓶颈，将使用 `numpy.lib.stride_tricks.as_strided` 高效实现。这将创建原始图像数据的内存高效视图，避免在内存中显式存储所有块。\n-   **特殊情况**：对于块状自助法，如果块边长 $b=1$，则该过程在数学上等同于 IID 自助法。我们的实现将通过委托给 IID 自助法函数来处理此情况。\n\n这种结构化的方法确保了以科学严谨和计算高效的方式满足问题的所有要求。最终输出将严格按照指定格式进行格式化。",
            "answer": "```python\nimport numpy as np\nfrom scipy.signal import convolve2d\nfrom scipy.special import logit, expit\n\ndef solve():\n    \"\"\"\n    Solves the bootstrap coverage rate problem for all test cases.\n    \"\"\"\n\n    def generate_gaussian_kernel(s: float) -> np.ndarray:\n        \"\"\"\n        Generates a 2D Gaussian kernel normalized to sum to 1.\n        \n        Args:\n            s (float): Standard deviation of the Gaussian.\n        \n        Returns:\n            np.ndarray: The normalized 2D kernel.\n        \"\"\"\n        L = 2 * int(np.ceil(3 * s)) + 1\n        center = L // 2\n        coords = np.arange(L) - center\n        x, y = np.meshgrid(coords, coords)\n        kernel = np.exp(-(x**2 + y**2) / (2 * s**2))\n        return kernel / np.sum(kernel)\n\n    def generate_spatially_correlated_data(N: int, p: float, s: float, rng: np.random.Generator) -> np.ndarray:\n        \"\"\"\n        Generates a single realization of the spatially correlated binary image.\n        \n        Args:\n            N (int): Side length of the square image.\n            p (float): Baseline correctness probability.\n            s (float): Standard deviation for the Gaussian correlation kernel.\n            rng (np.random.Generator): The random number generator instance.\n        \n        Returns:\n            np.ndarray: The N x N binary image X.\n        \"\"\"\n        # Generate white noise field\n        W = rng.normal(size=(N, N))\n        \n        # Create and apply Gaussian kernel for spatial correlation\n        kernel = generate_gaussian_kernel(s)\n        Z = convolve2d(W, kernel, mode='same', boundary='wrap')\n        \n        # Define pixel-wise correctness probabilities\n        alpha = logit(p)\n        pi = expit(alpha + Z)\n        \n        # Draw binary outcomes\n        X = rng.binomial(1, pi)\n        return X\n\n    def iid_bootstrap(X: np.ndarray, B: int, rng: np.random.Generator) -> np.ndarray:\n        \"\"\"\n        Computes the IID bootstrap confidence interval for the mean of X.\n        \n        Args:\n            X (np.ndarray): The N x N data image.\n            B (int): The number of bootstrap resamples.\n            rng (np.random.Generator): The random number generator instance.\n        \n        Returns:\n            np.ndarray: A 2-element array [lower_bound, upper_bound].\n        \"\"\"\n        N = X.shape[0]\n        N_sq = N * N\n        X_flat = X.flatten()\n        \n        # Vectorized generation of B bootstrap samples\n        resample_indices = rng.choice(N_sq, size=(B, N_sq), replace=True)\n        bootstrap_samples = X_flat[resample_indices]\n        \n        # Compute means for all B samples\n        bootstrap_means = np.mean(bootstrap_samples, axis=1)\n        \n        # Calculate quantiles for the confidence interval\n        return np.quantile(bootstrap_means, [0.025, 0.975])\n\n    def block_bootstrap(X: np.ndarray, b: int, B: int, rng: np.random.Generator) -> np.ndarray:\n        \"\"\"\n        Computes the block bootstrap confidence interval for the mean of X.\n        \n        Args:\n            X (np.ndarray): The N x N data image.\n            b (int): The side length of the square blocks.\n            B (int): The number of bootstrap resamples.\n            rng (np.random.Generator): The random number generator instance.\n        \n        Returns:\n            np.ndarray: A 2-element array [lower_bound, upper_bound].\n        \"\"\"\n        N = X.shape[0]\n\n        if b == 1:\n            return iid_bootstrap(X, B, rng)\n            \n        N_sq = N * N\n\n        # Use stride tricks to get an efficient view of all overlapping blocks\n        n_blocks_dim = N - b + 1\n        block_view = np.lib.stride_tricks.as_strided(\n            X,\n            shape=(n_blocks_dim, n_blocks_dim, b, b),\n            strides=(X.strides[0], X.strides[1], X.strides[0], X.strides[1])\n        )\n        all_blocks = block_view.reshape(-1, b * b)\n        num_total_blocks = all_blocks.shape[0]\n\n        # Number of blocks to sample to get at least N^2 pixels\n        num_blocks_to_sample = int(np.ceil(N_sq / (b * b)))\n        \n        # Vectorized sampling of block indices for all B resamples\n        block_indices = rng.choice(num_total_blocks, size=(B, num_blocks_to_sample), replace=True)\n        \n        # Form B bootstrap samples by concatenating blocks\n        resampled_blocks = all_blocks[block_indices]\n        resampled_pixels = resampled_blocks.reshape(B, -1)[:, :N_sq]\n        \n        # Compute means for all B samples\n        bootstrap_means = np.mean(resampled_pixels, axis=1)\n        \n        # Calculate quantiles for the confidence interval\n        return np.quantile(bootstrap_means, [0.025, 0.975])\n\n    # --- Main Execution ---\n    \n    # Fixed seed for reproducibility\n    rng = np.random.default_rng(2025)\n    \n    test_cases = [\n        (32, 0.80, 1.0, 1, 200, 400),\n        (32, 0.80, 2.0, 4, 200, 400),\n        (32, 0.80, 2.0, 8, 200, 400),\n        (32, 0.80, 4.0, 4, 200, 400),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        N, p, s, b, R, B = case\n        \n        iid_cover_count = 0\n        block_cover_count = 0\n        \n        for _ in range(R):\n            # 1. Generate one realization of the data\n            X = generate_spatially_correlated_data(N, p, s, rng)\n            A_hat = np.mean(X)\n            \n            # 2. Compute IID bootstrap CI and check coverage\n            iid_ci = iid_bootstrap(X, B, rng)\n            if iid_ci[0] = A_hat = iid_ci[1]:\n                iid_cover_count += 1\n            \n            # 3. Compute Block bootstrap CI and check coverage\n            block_ci = block_bootstrap(X, b, B, rng)\n            if block_ci[0] = A_hat = block_ci[1]:\n                block_cover_count += 1\n                \n        # 4. Calculate coverage rates for the current case\n        iid_rate = iid_cover_count / R\n        block_rate = block_cover_count / R\n        all_results.append([iid_rate, block_rate])\n\n    # Final print statement in the exact required format\n    # Example format: [[c_iid_1,c_block_1],[c_iid_2,c_block_2],...]\n    formatted_results = \",\".join(f\"[{res[0]},{res[1]}]\" for res in all_results)\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在许多实际应用中，不同类型的分类错误会带来不同的代价，因此简单的准确率指标可能不足以全面评估模型。这个高级实践将引导你处理一个更复杂的场景：为成本敏感准确率（cost-sensitive accuracy）的期望值构建置信区间，其中数据的不确定性和误分类成本的不确定性都需要被考虑。你将实现一个联合自助法程序，对数据和成本分布同时进行重抽样，从而为这个更贴近真实世界需求的性能指标提供稳健的置信度评估。",
            "id": "3106316",
            "problem": "给定二元分类结果和误分类成本的分布。目标是使用 Bootstrap 方法估计预期成本敏感准确率的置信区间 (CI)。预期成本敏感准确率定义为成本归一化准确率在误分类成本分布上的期望值。您必须联合重抽样数据和成本对，这意味着对于每个 Bootstrap 复制，数据点和成本对都从它们的经验支持中进行有放回抽样。\n\n定义和基本原理：\n- 令 $N$ 表示观测值的数量。每个观测值都有一个真实标签 $y_i \\in \\{0,1\\}$ 和一个预测标签 $\\hat{y}_i \\in \\{0,1\\}$，其中 $i \\in \\{1,\\dots,N\\}$。\n- 定义计数 $N_0 = \\sum_{i=1}^N \\mathbf{1}\\{y_i = 0\\}$ 和 $N_1 = \\sum_{i=1}^N \\mathbf{1}\\{y_i = 1\\}$。\n- 定义假阳性计数 $\\mathrm{FP} = \\sum_{i=1}^N \\mathbf{1}\\{y_i = 0, \\hat{y}_i = 1\\}$ 和假阴性计数 $\\mathrm{FN} = \\sum_{i=1}^N \\mathbf{1}\\{y_i = 1, \\hat{y}_i = 0\\}$。\n- 对于一个误分类成本对 $(c_{\\mathrm{FP}}, c_{\\mathrm{FN}})$，其中 $c_{\\mathrm{FP}}  0$ 且 $c_{\\mathrm{FN}}  0$，定义归一化成本敏感准确率\n$$\n\\mathrm{CSA}(c_{\\mathrm{FP}}, c_{\\mathrm{FN}}) \\;=\\; 1 \\;-\\; \\frac{c_{\\mathrm{FP}} \\cdot \\mathrm{FP} \\;+\\; c_{\\mathrm{FN}} \\cdot \\mathrm{FN}}{c_{\\mathrm{FP}} \\cdot N_0 \\;+\\; c_{\\mathrm{FN}} \\cdot N_1}.\n$$\n这种归一化使得 $\\mathrm{CSA} \\in [0,1]$，其中 $1$ 对应零误分类成本，$0$ 对应所有观测值都被误分类。\n- 假设存在一个关于 $(c_{\\mathrm{FP}}, c_{\\mathrm{FN}})$ 的成本分布，表示为 $\\mathbb{R}_{0}^2$ 上的一个定律。预期的成本敏感准确率是\n$$\n\\mathbb{E}_{(c_{\\mathrm{FP}},c_{\\mathrm{FN}})}\\left[ \\mathrm{CSA}(c_{\\mathrm{FP}}, c_{\\mathrm{FN}}) \\right],\n$$\n其中期望是关于给定的成本分布计算的。\n\nBootstrap 设计原则：\n- Bootstrap 是一种重抽样方法，它通过从数据和任何随机分量的经验分布中进行重抽样来近似统计量的抽样分布。在这里，将数据 $(y_i, \\hat{y}_i)$ 和成本抽取 $(c_{\\mathrm{FP},j}, c_{\\mathrm{FN},j})$ 视为来自未知乘积分布的样本。对于每个 Bootstrap 复制：\n    1. 从经验数据集中有放回地重抽样 $N$ 个数据点 $(y_i, \\hat{y}_i)$。\n    2. 从经验成本抽取中有放回地重抽样 $K$ 个成本对 $(c_{\\mathrm{FP},j}, c_{\\mathrm{FN},j})$。\n    3. 通过对重抽样的成本对上的 $\\mathrm{CSA}$ 进行平均，计算重抽样数据上的预期成本敏感准确率。\n- 使用百分位数法汇总 Bootstrap 复制，以构建置信区间 (CI)。对于双侧置信水平 $1-\\alpha$，下界和上界分别是 Bootstrap 分布的 $(\\alpha/2)$ 和 $(1-\\alpha/2)$ 经验分位数。\n\n程序要求：\n- 实现上述联合 Bootstrap 程序。\n- 对于每个测试用例，使用提供的随机种子，通过从指定的 Uniform 分布中独立抽样 $K$ 对 $(c_{\\mathrm{FP}}, c_{\\mathrm{FN}})$ 来生成经验成本抽取。然后使用提供的 Bootstrap 种子执行 $B$ 次 Bootstrap 复制。\n- 通过百分位数法计算双侧 $(1-\\alpha)$ 置信区间。\n- 将每个置信区间边界四舍五入到 $6$ 位小数。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果。每个结果必须是一个包含两个浮点数 $[\\text{lower}, \\text{upper}]$ 的列表，四舍五入到 $6$ 位小数，整体输出格式应为\n$[\\,[\\ell_1,u_1],\\,[\\ell_2,u_2],\\,\\dots\\,]$\n且无额外文本。\n\n测试套件：\n对于每个用例，参数为 $(y, \\hat{y}, K, \\text{cost ranges}, \\text{cost seed}, B, \\text{bootstrap seed}, \\alpha)$。\n\n- 用例 1（一般性能，非对称成本）：\n    - $y = [1,0,1,1,0,1,0,0,1,1,0,1,0,1,1,0,0,1,0,1,0,0,1,1,0,1,0,1,1,0]$\n    - $\\hat{y} = [1,0,0,1,0,1,1,0,1,0,0,1,0,1,0,0,1,1,0,1,0,0,1,0,0,1,0,1,1,0]$\n    - $K = 40$\n    - $c_{\\mathrm{FP}} \\sim \\mathrm{Uniform}(0.5, 2.0)$, $c_{\\mathrm{FN}} \\sim \\mathrm{Uniform}(1.0, 3.0)$, cost seed $= 12345$\n    - $B = 1000$, bootstrap seed $= 54321$, $\\alpha = 0.05$\n\n- 用例 2（完美分类器）：\n    - $y = [0,1,0,1,1,0,0,1,1,0,1,0,1,0,1,0,0,1,0,1]$\n    - $\\hat{y} = [0,1,0,1,1,0,0,1,1,0,1,0,1,0,1,0,0,1,0,1]$\n    - $K = 30$\n    - $c_{\\mathrm{FP}} \\sim \\mathrm{Uniform}(0.2, 2.0)$, $c_{\\mathrm{FN}} \\sim \\mathrm{Uniform}(0.2, 2.0)$, cost seed $= 2021$\n    - $B = 600$, bootstrap seed $= 2022$, $\\alpha = 0.05$\n\n- 用例 3（总是错误的分类器）：\n    - $y = [0,1,0,1,1,0,0,1,1,0,1,0,1,0,1,0,0,1,0,1]$\n    - $\\hat{y} = [1,0,1,0,0,1,1,0,0,1,0,1,0,1,0,1,1,0,1,0]$\n    - $K = 30$\n    - $c_{\\mathrm{FP}} \\sim \\mathrm{Uniform}(0.2, 2.0)$, $c_{\\mathrm{FN}} \\sim \\mathrm{Uniform}(0.2, 2.0)$, cost seed $= 2021$\n    - $B = 600$, bootstrap seed $= 3033$, $\\alpha = 0.05$\n\n- 用例 4（类别不平衡，高假阴性成本，预测全为零的平凡分类器）：\n    - y 有 36 个零，后跟 4 个一：\n      $y = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1]$\n    - y_hat 预测全为零：\n      $\\hat{y} = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]$\n    - $K = 50$\n    - $c_{\\mathrm{FP}} \\sim \\mathrm{Uniform}(0.2, 0.4)$, $c_{\\mathrm{FN}} \\sim \\mathrm{Uniform}(4.5, 5.5)$, cost seed $= 777$\n    - $B = 800$, bootstrap seed $= 778$, $\\alpha = 0.05$\n\n输出规范：\n- 您的程序应生成单行输出，其中包含四个测试用例的 CI 结果，形式为一个用方括号括起来的逗号分隔列表，其中每个用例贡献一个包含两个浮点数 $[\\text{lower}, \\text{upper}]$ 的列表，四舍五入到 $6$ 位小数。例如，输出必须如下所示\n$[[\\ell_1,u_1],[\\ell_2,u_2],[\\ell_3,u_3],[\\ell_4,u_4]]$，\n前后无任何附加字符或文本。",
            "solution": "该问题是有效的。这是一个定义明确的计算统计学问题，其基础是为置信区间估计而建立的 Bootstrap 重抽样原则。所有必要的数据、定义和算法规范都已提供，并且它们在内部是一致的，在科学上是合理的。\n\n目标是计算二元分类器的预期成本敏感准确率的双侧 $(1-\\alpha)$ 置信区间，记为 $\\theta = \\mathbb{E}[\\mathrm{CSA}]$。期望是在给定的误分类成本分布上计算的。估计将使用联合 Bootstrap 程序执行。\n\n首先，我们形式化感兴趣的统计量。给定一个包含 $N$ 个观测值的数据集 $\\mathcal{D} = \\{(y_i, \\hat{y}_i)\\}_{i=1}^N$，其中 $y_i \\in \\{0,1\\}$ 是真实标签，$\\hat{y}_i \\in \\{0,1\\}$ 是预测标签。从这个数据集中，我们可以计算负类实例的总数 $N_0 = \\sum_{i=1}^N \\mathbf{1}\\{y_i = 0\\}$，和正类实例的总数 $N_1 = \\sum_{i=1}^N \\mathbf{1}\\{y_i = 1\\}$。同样，我们计算假阳性的数量 $\\mathrm{FP} = \\sum_{i=1}^N \\mathbf{1}\\{y_i = 0, \\hat{y}_i = 1\\}$，和假阴性的数量 $\\mathrm{FN} = \\sum_{i=1}^N \\mathbf{1}\\{y_i = 1, \\hat{y}_i = 0\\}$。\n\n对于特定的误分类成本对 $(c_{\\mathrm{FP}}, c_{\\mathrm{FN}})$，其中 $c_{\\mathrm{FP}}  0$ 且 $c_{\\mathrm{FN}}  0$，归一化成本敏感准确率定义为：\n$$\n\\mathrm{CSA}(c_{\\mathrm{FP}}, c_{\\mathrm{FN}}) = 1 - \\frac{c_{\\mathrm{FP}} \\cdot \\mathrm{FP} + c_{\\mathrm{FN}} \\cdot \\mathrm{FN}}{c_{\\mathrm{FP}} \\cdot N_0 + c_{\\mathrm{FN}} \\cdot N_1}\n$$\n分母代表了可能的最大成本，即如果每个负类实例都被误分类为正类，并且每个正类实例都被误分类为负类时产生的成本。这种归一化确保了 $\\mathrm{CSA} \\in [0,1]$。\n\n我们希望为其估计置信区间的参数是该量在成本分布上的期望值：\n$$\n\\theta = \\mathbb{E}_{(c_{\\mathrm{FP}},c_{\\mathrm{FN}})}\\left[ \\mathrm{CSA}(c_{\\mathrm{FP}}, c_{\\mathrm{FN}}) \\right]\n$$\n在实践中，成本分布由从指定分布中抽取的 $K$ 个成本对的有限样本 $\\mathcal{C} = \\{(c_{\\mathrm{FP},j}, c_{\\mathrm{FN},j})\\}_{j=1}^K$ 表示。$\\theta$ 的经验估计则是样本均值：\n$$\n\\hat{\\theta} = \\frac{1}{K} \\sum_{j=1}^K \\mathrm{CSA}(c_{\\mathrm{FP},j}, c_{\\mathrm{FN},j})\n$$\n\n为了估计 $\\theta$ 的置信区间，我们采用指定的联合 Bootstrap 程序。这包括创建统计量 $\\hat{\\theta}$ 的 $B$ 个 Bootstrap 复制。每个复制模拟了由数据抽样和成本抽样共同引起的可变性。\n\n对于每个测试用例，算法按以下步骤进行：\n1.  **生成经验成本**：首先，我们使用提供的 `cost seed` 从各自的均匀分布中抽样，生成 $K$ 个经验成本对的集合 $\\mathcal{C} = \\{(c_{\\mathrm{FP},j}, c_{\\mathrm{FN},j})\\}_{j=1}^K$。\n\n2.  **Bootstrap 重抽样**：我们执行 $B$ 次 Bootstrap 迭代，索引为 $b = 1, \\dots, B$。对于每次迭代：\n    a.  **重抽样数据**：通过从原始数据集 $\\mathcal{D}$ 中有放回地抽取 $N$ 对来创建 Bootstrap 数据样本 $\\mathcal{D}_b^*$。令结果的真实标签和预测标签为 $y_b^*$ 和 $\\hat{y}_b^*$。\n    b.  **重抽样成本**：通过从经验成本集 $\\mathcal{C}$ 中有放回地抽取 $K$ 对来创建 Bootstrap 成本样本 $\\mathcal{C}_b^*$。\n    c.  **计算 Bootstrap 统计量**：对于重抽样的数据 $\\mathcal{D}_b^*$，我们计算相应的计数：$N_{0,b}^*$, $N_{1,b}^*$, $\\mathrm{FP}_b^*$, 和 $\\mathrm{FN}_b^*$。然后通过对 $\\mathcal{C}_b^*$ 中重抽样成本上的 $\\mathrm{CSA}$ 进行平均来计算我们统计量的 Bootstrap 复制 $\\hat{\\theta}_b^*$：\n        $$\n        \\hat{\\theta}_b^* = \\frac{1}{K} \\sum_{(c_{\\mathrm{FP}}^*, c_{\\mathrm{FN}}^*) \\in \\mathcal{C}_b^*} \\left( 1 - \\frac{c_{\\mathrm{FP}}^* \\cdot \\mathrm{FP}_b^* + c_{\\mathrm{FN}}^* \\cdot \\mathrm{FN}_b^*}{c_{\\mathrm{FP}}^* \\cdot N_{0,b}^* + c_{\\mathrm{FN}}^* \\cdot N_{1,b}^*} \\right)\n        $$\n        分母 $c_{\\mathrm{FP}}^* \\cdot N_{0,b}^* + c_{\\mathrm{FN}}^* \\cdot N_{1,b}^*$ 保证为正，因为成本 $c_{\\mathrm{FP}}^*$ 和 $c_{\\mathrm{FN}}^*$ 是从 $\\mathbb{R}_{0}$ 上的分布中抽取的，并且由于 $N_{0,b}^*$ 和 $N_{1,b}^*$ 的和是总样本量 $N  0$，所以它们中至少有一个必须为正。\n\n3.  **置信区间构建**：生成 $B$ 个 Bootstrap 统计量的集合 $\\{\\hat{\\theta}_1^*, \\dots, \\hat{\\theta}_B^*\\}$ 后，我们使用百分位数法构建双侧 $(1-\\alpha)$ 置信区间。这包括对 Bootstrap 统计量进行排序，并找到对应于 $\\alpha/2$ 和 $1-\\alpha/2$ 水平的经验分位数。CI 的下界是 Bootstrap 分布的第 $(100 \\cdot \\alpha/2)$ 个百分位数，上界是第 $(100 \\cdot (1-\\alpha/2))$ 个百分位数。例如，当 $\\alpha=0.05$ 时，我们找到第 $2.5$ 和第 $97.5$ 个百分位数。\n\n对提供的四个测试用例中的每一个都实施此程序，使用它们各自的 $(y, \\hat{y}, K, \\text{cost ranges}, \\text{cost seed}, B, \\text{bootstrap seed}, \\alpha)$ 参数。最终结果按要求四舍五入到 $6$ 位小数。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes bootstrap confidence intervals for expected cost-sensitive accuracy.\n    \"\"\"\n\n    def calculate_expected_csa(y_true, y_pred, costs):\n        \"\"\"\n        Calculates the expected cost-sensitive accuracy for a given dataset and cost sample.\n        \n        Args:\n            y_true (np.array): Array of true labels.\n            y_pred (np.array): Array of predicted labels.\n            costs (np.array): A Kx2 array of [c_FP, c_FN] cost pairs.\n        \n        Returns:\n            float: The mean cost-sensitive accuracy over the provided costs.\n        \"\"\"\n        N0 = np.sum(y_true == 0)\n        N1 = np.sum(y_true == 1)\n        \n        FP = np.sum((y_true == 0)  (y_pred == 1))\n        FN = np.sum((y_true == 1)  (y_pred == 0))\n        \n        c_fp = costs[:, 0]\n        c_fn = costs[:, 1]\n        \n        numerator = c_fp * FP + c_fn * FN\n        denominator = c_fp * N0 + c_fn * N1\n        \n        # Denominator is positive if N0 and costs0, as established.\n        # Handle the edge case of a perfect classifier (numerator=0) or an all-wrong\n        # classifier (num=den) gracefully through vectorization.\n        # If a bootstrap sample has N0=0 or N1=0, the corresponding term in the\n        # denominator will be zero, which is correct.\n        # Use np.divide to handle division by zero, returning np.nan which will be ignored by np.mean.\n        with np.errstate(divide='ignore', invalid='ignore'):\n            csa_values = 1.0 - np.divide(numerator, denominator)\n        \n        # A nan value would arise if a bootstrap sample contained only instances\n        # of one class AND that class had zero cost associated. This is unlikely\n        # but to be safe we use nanmean.\n        return np.nanmean(csa_values)\n\n    y_case4 = np.array([0]*36 + [1]*4)\n    y_hat_case4 = np.array([0]*40)\n\n    test_cases = [\n        (\n            np.array([1,0,1,1,0,1,0,0,1,1,0,1,0,1,1,0,0,1,0,1,0,0,1,1,0,1,0,1,1,0]),\n            np.array([1,0,0,1,0,1,1,0,1,0,0,1,0,1,0,0,1,1,0,1,0,0,1,0,0,1,0,1,1,0]),\n            40, ((0.5, 2.0), (1.0, 3.0)), 12345, 1000, 54321, 0.05\n        ),\n        (\n            np.array([0,1,0,1,1,0,0,1,1,0,1,0,1,0,1,0,0,1,0,1]),\n            np.array([0,1,0,1,1,0,0,1,1,0,1,0,1,0,1,0,0,1,0,1]),\n            30, ((0.2, 2.0), (0.2, 2.0)), 2021, 600, 2022, 0.05\n        ),\n        (\n            np.array([0,1,0,1,1,0,0,1,1,0,1,0,1,0,1,0,0,1,0,1]),\n            np.array([1,0,1,0,0,1,1,0,0,1,0,1,0,1,0,1,1,0,1,0]),\n            30, ((0.2, 2.0), (0.2, 2.0)), 2021, 600, 3033, 0.05\n        ),\n        (\n            y_case4,\n            y_hat_case4,\n            50, ((0.2, 0.4), (4.5, 5.5)), 777, 800, 778, 0.05\n        )\n    ]\n\n    all_results = []\n    \n    for y, y_hat, K, cost_ranges, cost_seed, B, bootstrap_seed, alpha in test_cases:\n        N = len(y)\n        \n        # 1. Generate empirical cost draws\n        rng_cost = np.random.default_rng(cost_seed)\n        c_fp_draws = rng_cost.uniform(cost_ranges[0][0], cost_ranges[0][1], size=K)\n        c_fn_draws = rng_cost.uniform(cost_ranges[1][0], cost_ranges[1][1], size=K)\n        costs = np.stack([c_fp_draws, c_fn_draws], axis=1)\n        \n        # 2. Bootstrap procedure\n        bootstrap_stats = np.empty(B)\n        rng_boot = np.random.default_rng(bootstrap_seed)\n        \n        data_indices = np.arange(N)\n        cost_indices = np.arange(K)\n        \n        for i in range(B):\n            # Resample data\n            boot_data_indices = rng_boot.choice(data_indices, size=N, replace=True)\n            y_boot = y[boot_data_indices]\n            y_hat_boot = y_hat[boot_data_indices]\n            \n            # Resample costs\n            boot_cost_indices = rng_boot.choice(cost_indices, size=K, replace=True)\n            costs_boot = costs[boot_cost_indices]\n            \n            # Calculate and store statistic\n            stat = calculate_expected_csa(y_boot, y_hat_boot, costs_boot)\n            bootstrap_stats[i] = stat\n            \n        # 3. Compute CI using percentile method\n        lower_quantile = alpha / 2.0 * 100\n        upper_quantile = (1 - alpha / 2.0) * 100\n        \n        ci_lower, ci_upper = np.nanpercentile(bootstrap_stats, [lower_quantile, upper_quantile])\n        \n        # 4. Round and store\n        all_results.append([round(ci_lower, 6), round(ci_upper, 6)])\n        \n    # Format and print the final output\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}