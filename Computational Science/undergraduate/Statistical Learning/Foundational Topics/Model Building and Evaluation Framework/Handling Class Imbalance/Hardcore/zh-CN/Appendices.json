{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握类别不平衡问题，我们必须首先理解其数学根源。本练习将通过经典的线性判别分析（LDA）模型，展示不均衡的类别先验如何直接影响决策边界。通过从第一性原理出发推导决策边界，您将能定量地计算这种边界偏移，从而为理解不平衡问题对生成模型的影响建立起坚实的直觉。",
            "id": "3127149",
            "problem": "考虑一个使用线性判别分析 (LDA) 建模的两类分类任务，其中类条件特征分布是一维高斯分布，并且共享一个共同的方差。具体来说，假设对于类别标签 $y \\in \\{0,1\\}$，特征 $x \\in \\mathbb{R}$ 的分布为\n$$\nx \\mid y=k \\sim \\mathcal{N}(\\mu_k,\\sigma^2), \\quad k \\in \\{0,1\\},\n$$\n参数为 $\\mu_0 = 0.5$、$\\mu_1 = 2.3$ 和 $\\sigma^2 = 1.44$。先验概率是不平衡的：$\\pi_0 = 0.7$ 和 $\\pi_1 = 0.3$。\n\n仅从 (i) 贝叶斯决策规则“将样本分配给后验概率较大的类别”，(ii) 关联后验概率、先验概率和似然的贝叶斯定理，以及 (iii) 高斯概率密度函数出发，通过求解后验概率相等的点，推导出在这些不相等先验概率下 LDA 决策边界的位置 $x^{\\star}_{\\text{unequal}}$。然后，使用相同的原理，在先验概率相等（即 $\\pi_0=\\pi_1=\\tfrac{1}{2}$）的情况下，推导出决策边界的位置 $x^{\\star}_{\\text{equal}}$。\n\n计算由类别不平衡引起的决策边界偏移量，\n$$\n\\Delta x \\equiv x^{\\star}_{\\text{unequal}} - x^{\\star}_{\\text{equal}}.\n$$\n将 $\\Delta x$ 的数值答案四舍五入到四位有效数字。",
            "solution": "我们从贝叶斯决策规则开始：将观测值 $x$ 分配给后验概率较大的类别。决策边界是后验概率相等的 $x$ 的集合：\n$$\np(y=1 \\mid x) = p(y=0 \\mid x).\n$$\n使用贝叶斯定理，并且注意到类条件密度函数共享相同的支撑集，该边界满足\n$$\np(x \\mid y=1)\\,\\pi_1 = p(x \\mid y=0)\\,\\pi_0.\n$$\n类别 $k \\in \\{0,1\\}$ 的高斯概率密度函数为\n$$\np(x \\mid y=k) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\exp\\!\\left(-\\frac{(x-\\mu_k)^2}{2\\sigma^2}\\right).\n$$\n将这些代入等式中，并消去公因子 $\\frac{1}{\\sqrt{2\\pi}\\,\\sigma}$，得到\n$$\n\\exp\\!\\left(-\\frac{(x-\\mu_1)^2}{2\\sigma^2}\\right)\\pi_1\n=\n\\exp\\!\\left(-\\frac{(x-\\mu_0)^2}{2\\sigma^2}\\right)\\pi_0.\n$$\n对两边取自然对数，得到\n$$\n-\\frac{(x-\\mu_1)^2}{2\\sigma^2} + \\ln \\pi_1\n=\n-\\frac{(x-\\mu_0)^2}{2\\sigma^2} + \\ln \\pi_0.\n$$\n整理得\n$$\n\\frac{(x-\\mu_0)^2 - (x-\\mu_1)^2}{2\\sigma^2}\n=\n\\ln\\!\\left(\\frac{\\pi_0}{\\pi_1}\\right).\n$$\n展开平方项，\n$$\n(x^2 - 2x\\mu_0 + \\mu_0^2) - (x^2 - 2x\\mu_1 + \\mu_1^2)\n=\n2x(\\mu_1 - \\mu_0) + (\\mu_0^2 - \\mu_1^2).\n$$\n因此，\n$$\n\\frac{2x(\\mu_1 - \\mu_0) + (\\mu_0^2 - \\mu_1^2)}{2\\sigma^2}\n=\n\\ln\\!\\left(\\frac{\\pi_0}{\\pi_1}\\right),\n$$\n所以\n$$\n2x(\\mu_1 - \\mu_0) + (\\mu_0^2 - \\mu_1^2) = 2\\sigma^2 \\ln\\!\\left(\\frac{\\pi_0}{\\pi_1}\\right).\n$$\n解出 $x$，\n$$\nx\n=\n\\frac{2\\sigma^2 \\ln\\!\\left(\\frac{\\pi_0}{\\pi_1}\\right) - (\\mu_0^2 - \\mu_1^2)}{2(\\mu_1 - \\mu_0)}\n=\n\\frac{\\mu_0 + \\mu_1}{2} + \\frac{\\sigma^2}{\\mu_1 - \\mu_0}\\,\\ln\\!\\left(\\frac{\\pi_0}{\\pi_1}\\right).\n$$\n这就是先验概率不相等时的 LDA 决策边界：\n$$\nx^{\\star}_{\\text{unequal}} = \\frac{\\mu_0 + \\mu_1}{2} + \\frac{\\sigma^2}{\\mu_1 - \\mu_0}\\,\\ln\\!\\left(\\frac{\\pi_0}{\\pi_1}\\right).\n$$\n对于相等的先验概率 $\\pi_0=\\pi_1=\\tfrac{1}{2}$，我们有 $\\ln(\\pi_0/\\pi_1)=\\ln 1 = 0$，所以决策边界简化为中点：\n$$\nx^{\\star}_{\\text{equal}} = \\frac{\\mu_0 + \\mu_1}{2}.\n$$\n因此，由不相等的先验概率引起的偏移量为\n$$\n\\Delta x \\equiv x^{\\star}_{\\text{unequal}} - x^{\\star}_{\\text{equal}}\n=\n\\frac{\\sigma^2}{\\mu_1 - \\mu_0}\\,\\ln\\!\\left(\\frac{\\pi_0}{\\pi_1}\\right).\n$$\n现在代入给定的数值 $\\mu_0 = 0.5$、$\\mu_1 = 2.3$、$\\sigma^2 = 1.44$、$\\pi_0 = 0.7$ 和 $\\pi_1 = 0.3$：\n$$\n\\mu_1 - \\mu_0 = 2.3 - 0.5 = 1.8,\n\\quad\n\\frac{\\sigma^2}{\\mu_1 - \\mu_0} = \\frac{1.44}{1.8} = 0.8,\n\\quad\n\\ln\\!\\left(\\frac{\\pi_0}{\\pi_1}\\right) = \\ln\\!\\left(\\frac{0.7}{0.3}\\right) = \\ln\\!\\left(\\frac{7}{3}\\right).\n$$\n计算对数：\n$$\n\\ln\\!\\left(\\frac{7}{3}\\right) \\approx 0.847297860.\n$$\n因此，\n$$\n\\Delta x \\approx 0.8 \\times 0.847297860 \\approx 0.677838288.\n$$\n四舍五入到四位有效数字，得到\n$$\n\\Delta x \\approx 0.6778.\n$$\n这个正向偏移表明，由于 $\\pi_0  \\pi_1$，决策边界相对于先验相等时的中点向右移动，从而扩大了预测为类别 0 的区域。这正是线性判别分析 (LDA) 通过其对数先验项处理类别不平衡的表现，即通过将决策边界向少数类一侧偏移。",
            "answer": "$$\\boxed{0.6778}$$"
        },
        {
            "introduction": "在许多现实世界的应用中，不同类型的分类错误会带来迥然不同的代价。本练习将引导您超越仅仅观察不平衡效应的层面，运用决策理论来主动修正它。您将推导出一个能最大化给定效用函数的最优分类阈值，学会如何权衡类别先验和非对称的错分成本，以做出风险最优的决策。",
            "id": "3127116",
            "problem": "一个二元分类器产生一个实值分数 $s \\in \\mathbb{R}$，该分数用于在少数正类 $Y=1$ 和多数负类 $Y=0$ 之间做出决策。正类的类别先验为 $P(Y=1)=\\pi$，其中 $\\pi = 0.10$，且 $P(Y=0)=1-\\pi$。以类别为条件的得分分布经科学测量为高斯分布且方差相等：$s \\mid Y=1 \\sim \\mathcal{N}(\\mu_{1},\\sigma^{2})$ 和 $s \\mid Y=0 \\sim \\mathcal{N}(\\mu_{0},\\sigma^{2})$，其中 $\\mu_{1} = 2$，$\\mu_{0} = 0$，$\\sigma = 1$。您将选择一个单一的确定性阈值 $t$，如果 $s \\geq t$ 则预测 $Y=1$，否则预测 $Y=0$。\n\n根据单次决策效用，将总体效用 $U(\\text{TP},\\text{FP},\\text{FN},\\text{TN})$ 线性定义为\n$$\nU(\\text{TP},\\text{FP},\\text{FN},\\text{TN}) \\;=\\; u_{\\text{TP}} \\cdot \\text{TP} \\;+\\; u_{\\text{FP}} \\cdot \\text{FP} \\;+\\; u_{\\text{FN}} \\cdot \\text{FN} \\;+\\; u_{\\text{TN}} \\cdot \\text{TN},\n$$\n其中 $\\text{TP}$、$\\text{FP}$、$\\text{FN}$ 和 $\\text{TN}$ 是在该阈值规则下真正例 (TP)、假正例 (FP)、假负例 (FN) 和真负例 (TN) 决策的计数。在一个高风险的罕见事件筛选情境中，错误分类一个正例的后果远比将一个负例标记出来要严重；假设单次决策效用为 $u_{\\text{TP}} = 3$、 $u_{\\text{FP}} = -1$、 $u_{\\text{FN}} = -8$ 和 $u_{\\text{TN}} = 1$。\n\n仅从期望效用、条件概率和贝叶斯定理的基本定义出发，推导出在阈值族 $s \\geq t$ 下使总体期望效用最大化的决策规则，并为给定的 $\\pi$、$\\mu_{1}$、$\\mu_{0}$ 和 $\\sigma$ 求解最优阈值 $t^{\\star}$。提供您最终的 $t^{\\star}$ 数值，四舍五入到四位有效数字。无需单位。",
            "solution": "目标是找到使分类规则的期望效用最大化的阈值 $t$。我们可以通过考虑在给定分数 $s$ 的情况下单个决策的期望效用，然后选择能产生更高条件期望效用的行动（预测 $Y=1$ 或 $Y=0$）来实现这一目标。最优阈值 $t^{\\star}$ 将是两种行动的期望效用相等时的分数 $s$ 的值，该值定义了决策边界。\n\n令 $\\hat{Y}$ 表示预测的类别。对于一个给定的分数 $s$，我们可以预测 $\\hat{Y}=1$ 或 $\\hat{Y}=0$。\n\n在给定分数 $s$ 的情况下，预测 $\\hat{Y}=1$ 的条件期望效用是：\n$$\nE[U \\mid s, \\hat{Y}=1] = u_{\\text{TP}} P(Y=1 \\mid s) + u_{\\text{FP}} P(Y=0 \\mid s)\n$$\n这是因为如果我们预测 $\\hat{Y}=1$，结果要么是真正例（如果真实类别是 $Y=1$），效用为 $u_{\\text{TP}}$；要么是假正例（如果真实类别是 $Y=0$），效用为 $u_{\\text{FP}}$。这些结果的概率分别是后验概率 $P(Y=1 \\mid s)$ 和 $P(Y=0 \\mid s)$。\n\n同样地，在给定分数 $s$ 的情况下，预测 $\\hat{Y}=0$ 的条件期望效用是：\n$$\nE[U \\mid s, \\hat{Y}=0] = u_{\\text{FN}} P(Y=1 \\mid s) + u_{\\text{TN}} P(Y=0 \\mid s)\n$$\n这是通过考虑结果要么是假负例（效用为 $u_{\\text{FN}}$）要么是真负例（效用为 $u_{\\text{TN}}$）得出的。\n\n最优决策规则是在 $E[U \\mid s, \\hat{Y}=1]  E[U \\mid s, \\hat{Y}=0]$ 时预测 $\\hat{Y}=1$，否则预测 $\\hat{Y}=0$。阈值 $t^{\\star}$ 是使这两个期望效用相等的 $s$ 值，定义了决策边界：\n$$\nu_{\\text{TP}} P(Y=1 \\mid s) + u_{\\text{FP}} P(Y=0 \\mid s) = u_{\\text{FN}} P(Y=1 \\mid s) + u_{\\text{TN}} P(Y=0 \\mid s)\n$$\n重新整理各项，将后验概率分组：\n$$\n(u_{\\text{TP}} - u_{\\text{FN}}) P(Y=1 \\mid s) = (u_{\\text{TN}} - u_{\\text{FP}}) P(Y=0 \\mid s)\n$$\n现在，我们应用贝叶斯定理，用似然 $p(s|Y)$ 和先验 $P(Y)$ 来表示后验概率。\n$$\nP(Y=c \\mid s) = \\frac{p(s \\mid Y=c) P(Y=c)}{p(s)} \\quad \\text{for } c \\in \\{0, 1\\}\n$$\n其中 $p(s) = p(s \\mid Y=1)P(Y=1) + p(s \\mid Y=0)P(Y=0)$ 是分数 $s$ 的边缘概率密度。\n将这些代入等式中得到：\n$$\n(u_{\\text{TP}} - u_{\\text{FN}}) \\frac{p(s \\mid Y=1) P(Y=1)}{p(s)} = (u_{\\text{TN}} - u_{\\text{FP}}) \\frac{p(s \\mid Y=0) P(Y=0)}{p(s)}\n$$\n边缘密度 $p(s)$ 从两边消掉。我们可以重新整理方程，用似然比来表示：\n$$\n\\frac{p(s \\mid Y=1)}{p(s \\mid Y=0)} = \\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{P(Y=0)}{P(Y=1)}\n$$\n最优阈值 $t^{\\star}$ 是满足此方程的 $s$ 值。\n\n给定的条件分布是高斯分布：\n$p(s \\mid Y=1) = \\mathcal{N}(s; \\mu_1, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(s-\\mu_1)^2}{2\\sigma^2}\\right)$\n$p(s \\mid Y=0) = \\mathcal{N}(s; \\mu_0, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(s-\\mu_0)^2}{2\\sigma^2}\\right)$\n\n似然比是：\n$$\n\\frac{p(s \\mid Y=1)}{p(s \\mid Y=0)} = \\frac{\\exp\\left(-\\frac{(s-\\mu_1)^2}{2\\sigma^2}\\right)}{\\exp\\left(-\\frac{(s-\\mu_0)^2}{2\\sigma^2}\\right)} = \\exp\\left(\\frac{(s-\\mu_0)^2 - (s-\\mu_1)^2}{2\\sigma^2}\\right)\n$$\n简化指数部分：\n$(s-\\mu_0)^2 - (s-\\mu_1)^2 = (s^2 - 2s\\mu_0 + \\mu_0^2) - (s^2 - 2s\\mu_1 + \\mu_1^2) = 2s(\\mu_1 - \\mu_0) - (\\mu_1^2 - \\mu_0^2)$\n$= 2s(\\mu_1 - \\mu_0) - (\\mu_1 - \\mu_0)(\\mu_1 + \\mu_0) = (\\mu_1 - \\mu_0) [2s - (\\mu_1 + \\mu_0)]$\n\n在 $s=t^{\\star}$ 时，将其代回主方程：\n$$\n\\exp\\left(\\frac{(\\mu_1 - \\mu_0) [2t^{\\star} - (\\mu_1 + \\mu_0)]}{2\\sigma^2}\\right) = \\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\n$$\n为了求解 $t^{\\star}$，我们对两边取自然对数：\n$$\n\\frac{(\\mu_1 - \\mu_0) [2t^{\\star} - (\\mu_1 + \\mu_0)]}{2\\sigma^2} = \\ln\\left(\\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\\right)\n$$\n现在，我们求解 $t^{\\star}$：\n$$\n2t^{\\star} - (\\mu_1 + \\mu_0) = \\frac{2\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\\right)\n$$\n$$\n2t^{\\star} = (\\mu_1 + \\mu_0) + \\frac{2\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\\right)\n$$\n$$\nt^{\\star} = \\frac{\\mu_1 + \\mu_0}{2} + \\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{u_{\\text{TN}} - u_{\\text{FP}}}{u_{\\text{TP}} - u_{\\text{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\\right)\n$$\n这是最优阈值的一般符号表达式。\n\n我们现在代入给定的数值：\n$\\mu_1 = 2$, $\\mu_0 = 0$, $\\sigma^2 = 1^2 = 1$, $\\pi=0.10$。\n$u_{\\text{TP}} = 3$, $u_{\\text{FP}} = -1$, $u_{\\text{FN}} = -8$, $u_{\\text{TN}} = 1$。\n\n计算表达式的各个部分：\n*   $\\frac{\\mu_1 + \\mu_0}{2} = \\frac{2 + 0}{2} = 1$\n*   $\\frac{\\sigma^2}{\\mu_1 - \\mu_0} = \\frac{1}{2 - 0} = \\frac{1}{2}$\n*   $u_{\\text{TN}} - u_{\\text{FP}} = 1 - (-1) = 2$\n*   $u_{\\text{TP}} - u_{\\text{FN}} = 3 - (-8) = 11$\n*   $\\frac{1-\\pi}{\\pi} = \\frac{1 - 0.10}{0.10} = \\frac{0.90}{0.10} = 9$\n\n将这些值代入 $t^{\\star}$ 的表达式中：\n$$\nt^{\\star} = 1 + \\frac{1}{2} \\ln\\left(\\frac{2}{11} \\cdot 9\\right)\n$$\n$$\nt^{\\star} = 1 + \\frac{1}{2} \\ln\\left(\\frac{18}{11}\\right)\n$$\n现在我们计算数值：\n$$\n\\frac{18}{11} \\approx 1.6363636...\n$$\n$$\n\\ln\\left(\\frac{18}{11}\\right) \\approx \\ln(1.6363636...) \\approx 0.492476...\n$$\n$$\nt^{\\star} \\approx 1 + \\frac{1}{2}(0.492476...) = 1 + 0.246238...\n$$\n$$\nt^{\\star} \\approx 1.246238...\n$$\n四舍五入到四位有效数字，得到 $t^{\\star} = 1.246$。\n推导出的决策规则是，如果分数 $s$ 大于或等于约 $1.246$，则预测 $Y=1$，否则预测 $Y=0$。",
            "answer": "$$\\boxed{1.246}$$"
        },
        {
            "introduction": "处理类别不平衡的原理同样适用于像神经网络这样复杂的多类别模型，在这些模型中，“长尾分布”现象十分普遍。这项基于编程的练习将挑战您实现“对数几率调整”（logit adjustment），这是一种直接源于贝叶斯定理、用于整合类别先验信息的技术。通过亲手实现，您将探索在提升排名准确率与确保模型预测概率的良好校准性之间，那个在实践中至关重要且通常微妙的权衡。",
            "id": "3127123",
            "problem": "给定一个带有类别不平衡的多类别分类场景，其中模型为每个类别生成实值分数，通常称为 logits。softmax 函数将 logits 转换为类别上的概率分布。您将实现一个有原则的 logit 调整，该调整融合了类别先验信息，然后量化此调整如何影响两个不同方面：排序（通过 top-1 准确率衡量）和校准（通过平均负对数似然衡量）。\n\n从 Bayes 法则的条件概率基本定义出发，对于任何输入特征向量 $x$ 和类别 $k$，后验概率满足\n$$\np(y=k \\mid x) \\propto p(x \\mid y=k)\\,p(y=k),\n$$\n其中比例常数由证据 $p(x)$ 给出。当一个判别模型的各类别 logit $z_k(x)$ 在一个与类别相关的加性常数范围内与类别条件对数似然成正比时，通过在归一化之前将 logits 转换为与后验概率成比例的分数，可以得到正确考虑了类别先验 $p(y=k)$ 的概率预测。这启发了一种编码先验信息的 logit 变换，之后通过 softmax 归一化获得概率。您的任务是从 Bayes 法则推导出此变换，并实现未经调整和经过调整的 softmax 预测。\n\n您的程序必须：\n1. 实现从 logits $z_{i,k}$ 到概率 $p_{i,k}$ 的未经调整的 softmax 映射。\n2. 基于 Bayes 法则，推导并实现一个基于先验信息的 logit 变换，该变换在 softmax 归一化后产生调整后的概率 $q_{i,k}$。\n3. 对每个测试用例，计算：\n   - 在未经调整和经过调整的概率下的 Top-1 准确率，定义为预测类别 $\\arg\\max_k p_{i,k}$ 或 $\\arg\\max_k q_{i,k}$ 等于真实标签的样本比例（以小数表示）。\n   - 在未经调整和经过调整的概率下的平均负对数似然（NLL），定义为在所有样本 $i$ 上 $-\\log p_{i,y_i}$ 或 $-\\log q_{i,y_i}$ 的平均值，其中 $y_i$ 是样本 $i$ 的真实类别标签。\n4. 对每个测试用例，输出两个值：\n   - 准确率差异 $a = \\text{accuracy}_{\\text{adjusted}} - \\text{accuracy}_{\\text{unadjusted}}$。\n   - NLL 差异 $\\ell = \\text{NLL}_{\\text{adjusted}} - \\text{NLL}_{\\text{unadjusted}}$。\n   将 $a$ 和 $\\ell$ 作为小数报告（无百分号），四舍五入到六位小数。\n\n使用的定义：\n- 对于每个具有 logits $\\{z_{i,1},\\dots,z_{i,K}\\}$ 的样本 $i$，未经调整的 softmax 概率为\n$$\np_{i,k} = \\frac{\\exp(z_{i,k})}{\\sum_{j=1}^{K} \\exp(z_{i,j})}.\n$$\n- 调整后的概率必须通过首先使用类别先验信息以 Bayes 法则所蕴含的方式变换 logits，然后应用 softmax 归一化以在类别上产生有效分布来获得。\n\n测试套件规范。对于每个测试用例，您将得到一个 logit 矩阵 $Z \\in \\mathbb{R}^{n \\times K}$，整数标签 $\\boldsymbol{y} \\in \\{0,\\dots,K-1\\}^n$，以及一个类别先验向量 $\\boldsymbol{\\pi} \\in \\mathbb{R}^K$，其条目在 $(0,1)$ 范围内且总和为 $1$。使用以下四个测试用例：\n\n测试用例 1（一般长尾分布）：\n$$\nZ^{(1)} = \\begin{bmatrix}\n2.5  1.0  0.0\\\\\n0.0  1.2  1.0\\\\\n1.2  0.2  0.1\\\\\n-1.0  0.0  3.0\\\\\n0.5  0.4  0.3\n\\end{bmatrix},\\quad\n\\boldsymbol{y}^{(1)} = \\begin{bmatrix}0\\\\1\\\\0\\\\2\\\\0\\end{bmatrix},\\quad\n\\boldsymbol{\\pi}^{(1)} = \\begin{bmatrix}0.7\\\\0.2\\\\0.1\\end{bmatrix}.\n$$\n\n测试用例 2（均匀先验边界；不变性检查）：\n$$\nZ^{(2)} = \\begin{bmatrix}\n2.5  1.0  0.0\\\\\n0.0  1.2  1.0\\\\\n1.2  0.2  0.1\\\\\n-1.0  0.0  3.0\\\\\n0.5  0.4  0.3\n\\end{bmatrix},\\quad\n\\boldsymbol{y}^{(2)} = \\begin{bmatrix}2\\\\2\\\\1\\\\2\\\\0\\end{bmatrix},\\quad\n\\boldsymbol{\\pi}^{(2)} = \\begin{bmatrix}\\tfrac{1}{3}\\\\\\tfrac{1}{3}\\\\\\tfrac{1}{3}\\end{bmatrix}.\n$$\n\n测试用例 3（极端不平衡；长尾压力测试）：\n$$\nZ^{(3)} = \\begin{bmatrix}\n4.0  3.9  5.5\\\\\n1.0  2.0  3.0\\\\\n3.0  0.0  0.5\\\\\n0.5  0.6  0.7\n\\end{bmatrix},\\quad\n\\boldsymbol{y}^{(3)} = \\begin{bmatrix}2\\\\2\\\\0\\\\1\\end{bmatrix},\\quad\n\\boldsymbol{\\pi}^{(3)} = \\begin{bmatrix}0.95\\\\0.04\\\\0.01\\end{bmatrix}.\n$$\n\n测试用例 4（二元边界；阈值敏感度）：\n$$\nZ^{(4)} = \\begin{bmatrix}\n2.0  1.8\\\\\n0.1  0.2\\\\\n-0.5  -0.6\\\\\n1.0  2.0\\\\\n0.0  0.0\n\\end{bmatrix},\\quad\n\\boldsymbol{y}^{(4)} = \\begin{bmatrix}0\\\\1\\\\0\\\\1\\\\0\\end{bmatrix},\\quad\n\\boldsymbol{\\pi}^{(4)} = \\begin{bmatrix}0.9\\\\0.1\\end{bmatrix}.\n$$\n\n最终输出格式：\n您的程序应生成单行输出，其中包含所有按顺序连接的结果，形式为用方括号括起来的逗号分隔列表。对于测试用例 1 到 4，按顺序为每个测试用例附加一对值：首先是准确率差异 $a$，然后是 NLL 差异 $\\ell$，两者都四舍五入到六位小数。例如，输出必须具有以下形式\n$$\n[\\;a_1,\\ell_1,a_2,\\ell_2,a_3,\\ell_3,a_4,\\ell_4\\;].\n$$",
            "solution": "我们从贝叶斯法则开始，该法则指出，对于任何输入 $x$ 和类别 $k$，\n$$\np(y=k \\mid x) = \\frac{p(x \\mid y=k)\\,p(y=k)}{p(x)} \\propto p(x \\mid y=k)\\,p(y=k).\n$$\n在用于多类别分类的许多判别模型中，模型会生成一个 logit 向量 $z(x) \\in \\mathbb{R}^K$。 logits 的一个经典概率解释是它们通过 softmax 函数参数化一个分类分布，\n$$\np_{k}(x) = \\frac{\\exp\\big(z_k(x)\\big)}{\\sum_{j=1}^{K} \\exp\\big(z_j(x)\\big)}.\n$$\n对于未经显式先验校正训练的模型，logits $z_k(x)$ 通常充当类别条件分数的比例代理（例如，作为 $\\log p(x \\mid y=k)$ 的仿射代理），而忽略了先验 $p(y=k)$。为了融合类别先验，我们必须构建一个变换后的分数 $\\tilde{z}_k(x)$，其指数运算结果与后验概率成正比。根据贝叶斯法则，\n$$\np(y=k \\mid x) \\propto p(x \\mid y=k)\\,p(y=k).\n$$\n如果 $z_k(x)$ 在一个不依赖于 $x$ 的加性常数范围内与 $\\log p(x \\mid y=k)$ 成正比，那么在指数内部加上 $\\log p(y=k)$ 会使分数与后验概率对齐，即\n$$\n\\exp\\big(\\tilde{z}_k(x)\\big) \\propto \\exp\\big(z_k(x)\\big)\\,p(y=k),\n$$\n这意味着 logit 变换为\n$$\n\\tilde{z}_k(x) = z_k(x) + \\log p(y=k) + c,\n$$\n其中 $c$ 是任何不依赖于 $k$ 的常数；softmax 归一化使得 $c$ 无关紧要。因此，通过对 $\\tilde{z}(x)$ 应用 softmax 可以获得满足贝叶斯法则的调整后概率：\n$$\nq_{k}(x) = \\frac{\\exp\\big(z_k(x) + \\log \\pi_k\\big)}{\\sum_{j=1}^{K} \\exp\\big(z_j(x) + \\log \\pi_j\\big)},\n$$\n其中 $\\pi_k = p(y=k)$ 表示类别先验。\n\n我们现在评估这种 logit 调整对两个属性的影响。\n\n排序：top-1 决策规则预测 $\\arg\\max_k p_k(x)$（未经调整）或 $\\arg\\max_k q_k(x)$（经过调整）。给所有 logits 加上相同的常数不会改变 argmax，但加上与类别相关的常数 $\\log \\pi_k$ 可以改变类别间的排序。当先验是均匀的，即对所有 $k$ 都有 $\\pi_k = \\tfrac{1}{K}$ 时，会出现一个边界情况，此时所有 $\\log \\pi_k$ 都相等，因此 argmax 与未经调整的情况相同。更一般地，在不平衡的情况下，当未经调整的分数尚未编码先验信息时，调整后的 argmax 可能会向频繁类别偏移；这可能会根据数据分布和原始 logits 的充分性而改变 top-1 准确率。\n\n校准：一个常见的校准度量是平均负对数似然（NLL），\n$$\n\\text{NLL} = -\\frac{1}{n} \\sum_{i=1}^{n} \\log r_{i,y_i},\n$$\n其中 $r_{i,k}$ 表示样本 $i$ 上类别 $k$ 的预测概率，$y_i$ 是真实标签。如果未经调整的 logits 近似地反映了没有先验的类别条件证据，那么注入 $\\log \\pi_k$ 会使模型更接近贝叶斯法则所蕴含的后验分布，这通常会改善不平衡数据上的校准。然而，对 NLL 的影响取决于 logits 的质量和指定先验的正确性。\n\n每个测试用例的算法流程：\n1. 通过对 $Z$ 的每一行应用数值稳定的 softmax 来计算未经调整的概率 $p_{i,k}$。\n2. 计算调整后的 logits $\\tilde{z}_{i,k} = z_{i,k} + \\log \\pi_k$，然后通过 softmax 计算调整后的概率 $q_{i,k}$。\n3. 计算 top-1 准确率：\n   $$\n   \\text{acc}_{\\text{unadj}} = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbf{1}\\!\\left(\\arg\\max_k p_{i,k} = y_i\\right),\\quad\n   \\text{acc}_{\\text{adj}} = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbf{1}\\!\\left(\\arg\\max_k q_{i,k} = y_i\\right).\n   $$\n4. 计算平均 NLL：\n   $$\n   \\text{NLL}_{\\text{unadj}} = -\\frac{1}{n}\\sum_{i=1}^{n} \\log p_{i,y_i},\\quad\n   \\text{NLL}_{\\text{adj}} = -\\frac{1}{n}\\sum_{i=1}^{n} \\log q_{i,y_i}.\n   $$\n5. 报告差异 $a = \\text{acc}_{\\text{adj}} - \\text{acc}_{\\text{unadj}}$ 和 $\\ell = \\text{NLL}_{\\text{adj}} - \\text{NLL}_{\\text{unadj}}$，四舍五入到六位小数。\n\n所提供测试套件的覆盖范围：\n- 测试用例 1 是一个普遍的不平衡场景，其中先验偏向某一类别；这测试了典型的长尾行为。\n- 测试用例 2 使用均匀先验，这是一个边界条件，在此条件下排序应该是不变的，并且在数值容差范围内校准不变；这验证了对添加与类别无关的常数的不变性。\n- 测试用例 3 表现出极端不平衡；当一个稀有类别获得较大的未经调整的 logits 时，这对调整及其对排序和校准的影响进行了压力测试。\n- 测试用例 4 是二元的，并突显了先验如何在对数几率中导致有效的阈值偏移，这可以改变 top-1 决策，同时也会影响 NLL。\n\n程序将计算所有测试用例的所求差异，并将其打印为单个列表 $[a_1,\\ell_1,a_2,\\ell_2,a_3,\\ell_3,a_4,\\ell_4]$，每个值都四舍五入到六位小数，并表示为不带百分号的小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Execution environment: Python 3.12, numpy 1.23.5, scipy 1.11.4 (not used).\nimport numpy as np\n\ndef softmax_rows(logits: np.ndarray) - np.ndarray:\n    \"\"\"\n    Numerically stable softmax applied row-wise.\n    logits: shape (n, K)\n    returns: probabilities, shape (n, K)\n    \"\"\"\n    # Subtract row-wise max for numerical stability.\n    z = logits - np.max(logits, axis=1, keepdims=True)\n    np.exp(z, out=z)\n    z_sum = np.sum(z, axis=1, keepdims=True)\n    # Avoid division by zero in degenerate cases.\n    z_sum = np.where(z_sum == 0.0, 1.0, z_sum)\n    return z / z_sum\n\ndef top1_accuracy(probs: np.ndarray, y: np.ndarray) - float:\n    preds = np.argmax(probs, axis=1)\n    return float(np.mean(preds == y))\n\ndef mean_nll(probs: np.ndarray, y: np.ndarray) - float:\n    # Clip to avoid log(0).\n    eps = 1e-15\n    p_true = probs[np.arange(probs.shape[0]), y]\n    p_true = np.clip(p_true, eps, 1.0)\n    return float(-np.mean(np.log(p_true)))\n\ndef logit_adjusted_probs(logits: np.ndarray, pi: np.ndarray) - np.ndarray:\n    \"\"\"\n    Apply Bayes-inspired logit adjustment: add log(pi_k) to class k logits.\n    \"\"\"\n    # Ensure pi is a proper distribution and strictly positive.\n    pi = np.asarray(pi, dtype=float)\n    pi_sum = np.sum(pi)\n    if pi_sum == 0.0:\n        raise ValueError(\"Class prior vector must have positive sum.\")\n    pi = pi / pi_sum\n    if np.any(pi == 0.0):\n        raise ValueError(\"Class priors must be strictly positive.\")\n    adjusted = logits + np.log(pi)[None, :]\n    return softmax_rows(adjusted)\n\ndef evaluate_case(Z: np.ndarray, y: np.ndarray, pi: np.ndarray):\n    # Unadjusted probabilities\n    p = softmax_rows(Z)\n    # Adjusted probabilities\n    q = logit_adjusted_probs(Z, pi)\n    # Metrics\n    acc_unadj = top1_accuracy(p, y)\n    acc_adj = top1_accuracy(q, y)\n    nll_unadj = mean_nll(p, y)\n    nll_adj = mean_nll(q, y)\n    # Differences\n    a = acc_adj - acc_unadj\n    l = nll_adj - nll_unadj\n    return a, l\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    # Test case 1\n    Z1 = np.array([\n        [2.5, 1.0, 0.0],\n        [0.0, 1.2, 1.0],\n        [1.2, 0.2, 0.1],\n        [-1.0, 0.0, 3.0],\n        [0.5, 0.4, 0.3]\n    ], dtype=float)\n    y1 = np.array([0, 1, 0, 2, 0], dtype=int)\n    pi1 = np.array([0.7, 0.2, 0.1], dtype=float)\n\n    # Test case 2 (uniform prior)\n    Z2 = np.array([\n        [2.5, 1.0, 0.0],\n        [0.0, 1.2, 1.0],\n        [1.2, 0.2, 0.1],\n        [-1.0, 0.0, 3.0],\n        [0.5, 0.4, 0.3]\n    ], dtype=float)\n    y2 = np.array([2, 2, 1, 2, 0], dtype=int)\n    pi2 = np.array([1/3, 1/3, 1/3], dtype=float)\n\n    # Test case 3 (extreme imbalance)\n    Z3 = np.array([\n        [4.0, 3.9, 5.5],\n        [1.0, 2.0, 3.0],\n        [3.0, 0.0, 0.5],\n        [0.5, 0.6, 0.7]\n    ], dtype=float)\n    y3 = np.array([2, 2, 0, 1], dtype=int)\n    pi3 = np.array([0.95, 0.04, 0.01], dtype=float)\n\n    # Test case 4 (binary)\n    Z4 = np.array([\n        [2.0, 1.8],\n        [0.1, 0.2],\n        [-0.5, -0.6],\n        [1.0, 2.0],\n        [0.0, 0.0]\n    ], dtype=float)\n    y4 = np.array([0, 1, 0, 1, 0], dtype=int)\n    pi4 = np.array([0.9, 0.1], dtype=float)\n\n    test_cases = [\n        (Z1, y1, pi1),\n        (Z2, y2, pi2),\n        (Z3, y3, pi3),\n        (Z4, y4, pi4),\n    ]\n\n    results = []\n    for Z, y, pi in test_cases:\n        a, l = evaluate_case(Z, y, pi)\n        # Round to six decimals as required\n        results.append(round(a + 0.0, 6))\n        results.append(round(l + 0.0, 6))\n\n    # Final print statement in the exact required format.\n    # Ensure each number has up to six decimal places formatting.\n    formatted = []\n    for val in results:\n        # Format with exactly six decimal places\n        formatted.append(f\"{val:.6f}\")\n    print(f\"[{','.join(formatted)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}