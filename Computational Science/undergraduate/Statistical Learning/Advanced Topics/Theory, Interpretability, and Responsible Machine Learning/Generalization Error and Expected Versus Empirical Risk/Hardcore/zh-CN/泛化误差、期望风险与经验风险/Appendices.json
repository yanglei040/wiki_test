{
    "hands_on_practices": [
        {
            "introduction": "在机器学习中，选择损失函数是一项关键的设计决策，它直接指导了模型的训练过程。这个练习探讨了一个重要且常见的情景：我们训练模型时优化的损失函数（例如，绝对损失$ \\ell_1 $）与我们最终评估模型性能的损失函数（例如，平方损失$ \\ell_2 $）不一致。通过这个练习，我们将量化这种不匹配所导致的“超额风险”，从而揭示训练目标和评估目标之间的差异如何影响模型的最终表现。",
            "id": "3123205",
            "problem": "考虑从分布 $Y=\\mu+X$ 中抽取的独立同分布（i.i.d.）观测值 $\\{Y_i\\}_{i=1}^{n}$，其中 $X$ 服从率参数为 $\\lambda>0$ 的指数分布。您考虑常数预测器的假设类别 $\\{f_{\\theta}:\\theta\\in\\mathbb{R}\\}$，其中对于所有输入，$f_{\\theta}(x)=\\theta$。训练是通过最小化绝对损失 $\\ell_{1}(y,\\theta)=|y-\\theta|$ 下的经验风险来进行的，也就是说，您选择一个经验风险最小化器 $\\hat{\\theta}_{n}\\in\\arg\\min_{\\theta}\\hat{R}_{\\ell_{1}}(\\theta)$，其中 $\\hat{R}_{\\ell_{1}}(\\theta)=\\frac{1}{n}\\sum_{i=1}^{n}|Y_{i}-\\theta|$。然而，评估是在平方损失 $\\ell_{2}(y,\\theta)=(y-\\theta)^{2}$ 下进行的，其期望风险为 $R_{\\ell_{2}}(\\theta)=\\mathbb{E}[(Y-\\theta)^{2}]$。\n\n仅从 $\\ell_{1}$ 和 $\\ell_{2}$ 的经验风险和期望风险的定义，以及期望和分位点的基本性质出发，在大样本极限 $n\\to\\infty$ 的情况下完成以下任务：\n1. 在所选的假设类别中，论证经验 $\\ell_{1}$ 最小化器收敛到哪个总体参数，以及哪个总体参数最小化期望 $\\ell_{2}$ 风险。\n2. 将经过 $\\ell_{1}$ 训练的预测器的渐近超额 $\\ell_{2}$ 风险定义为 $\\mathcal{E}=R_{\\ell_{2}}(\\theta_{\\ell_{1}}^{\\star})-\\inf_{\\theta\\in\\mathbb{R}}R_{\\ell_{2}}(\\theta)$，其中 $\\theta_{\\ell_{1}}^{\\star}$ 是当 $n\\to\\infty$ 时 $\\hat{\\theta}_{n}$ 的几乎必然极限。推导一个仅用 $\\lambda$ 表示的 $\\mathcal{E}$ 的闭式表达式。\n3. 以总体统计量的形式，陈述使 $\\mathcal{E}=0$ 的对齐条件，并讨论该条件对于给定的指数移位模型是否成立。\n\n请提供 $\\mathcal{E}$ 的精确闭式表达式作为最终答案。不要对您的结果进行近似或四舍五入。",
            "solution": "该问题要求分析当一个模型使用一种损失函数进行训练，但使用另一种损失函数进行评估时出现的性能不匹配问题。具体来说，我们考虑一个常数预测器 $f_{\\theta}(x) = \\theta$，它通过最小化经验 $\\ell_{1}$ 风险（绝对损失）进行训练，并根据其渐近期望 $\\ell_{2}$ 风险（平方损失）进行评估。数据 $\\{Y_i\\}_{i=1}^{n}$ 是来自 $Y = \\mu + X$ 的独立同分布样本，其中 $X$ 服从率参数为 $\\lambda > 0$ 的指数分布。\n\n首先，我们解决问题的三个部分：确定相关的总体参数，推导渐近超额风险，以及讨论对齐条件。\n\n1. 用于 $\\ell_{1}$ 和 $\\ell_{2}$ 风险最小化的总体参数\n\n训练过程涉及找到 $\\hat{\\theta}_{n} \\in \\arg\\min_{\\theta} \\hat{R}_{\\ell_{1}}(\\theta)$，其中经验风险为 $\\hat{R}_{\\ell_{1}}(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n}|Y_{i}-\\theta|$。统计学中的一个基本结论是，使与一组点 $\\{Y_i\\}_{i=1}^n$ 的绝对差之和最小化的 $\\theta$ 值是这些点的样本中位数。因此，$\\hat{\\theta}_{n} = \\text{median}(\\{Y_i\\}_{i=1}^n)$。\n当样本量 $n$ 趋于无穷大时，样本中位数几乎必然收敛到总体中位数。问题将 $\\theta_{\\ell_{1}}^{\\star}$ 定义为此极限。因此，\n$$ \\theta_{\\ell_{1}}^{\\star} = \\lim_{n\\to\\infty} \\hat{\\theta}_{n} = \\text{median}(Y) $$\n评估是使用期望 $\\ell_{2}$ 风险 $R_{\\ell_{2}}(\\theta) = \\mathbb{E}[(Y-\\theta)^{2}]$ 进行的。为了找到最小化此风险的参数 $\\theta$，我们可以对 $R_{\\ell_{2}}(\\theta)$ 关于 $\\theta$ 求导，并令导数为零。\n$$ \\frac{d}{d\\theta}R_{\\ell_{2}}(\\theta) = \\frac{d}{d\\theta}\\mathbb{E}[(Y-\\theta)^{2}] = \\mathbb{E}\\left[\\frac{\\partial}{\\partial\\theta}(Y-\\theta)^{2}\\right] = \\mathbb{E}[-2(Y-\\theta)] = -2(\\mathbb{E}[Y] - \\theta) $$\n将此导数设为零得到 $\\theta = \\mathbb{E}[Y]$。二阶导数为 $\\frac{d^2}{d\\theta^2}R_{\\ell_{2}}(\\theta) = 2 > 0$，这证实了该 $\\theta$ 值确实是一个最小化器。在期望平方损失下的最优参数是总体均值。我们将此最小化器表示为 $\\theta_{\\ell_2}^\\star$：\n$$ \\theta_{\\ell_2}^\\star = \\arg\\inf_{\\theta \\in \\mathbb{R}} R_{\\ell_2}(\\theta) = \\mathbb{E}[Y] $$\n总而言之，经验 $\\ell_{1}$ 最小化器收敛到总体中位数，而期望 $\\ell_{2}$ 风险由总体均值最小化。\n\n2. 渐近超额 $\\ell_{2}$ 风险的推导\n\n渐近超额 $\\ell_{2}$ 风险 $\\mathcal{E}$ 衡量了在 $\\ell_2$ 评估的背景下使用 $\\ell_{1}$ 最优参数 $\\theta_{\\ell_1}^\\star$ 所带来的惩罚。它定义为：\n$$ \\mathcal{E} = R_{\\ell_{2}}(\\theta_{\\ell_{1}}^{\\star}) - \\inf_{\\theta\\in\\mathbb{R}}R_{\\ell_{2}}(\\theta) = R_{\\ell_{2}}(\\theta_{\\ell_{1}}^{\\star}) - R_{\\ell_2}(\\theta_{\\ell_2}^\\star) $$\n使用恒等式 $R_{\\ell_2}(\\theta) = \\mathbb{E}[(Y-\\theta)^2] = \\text{Var}(Y) + (\\mathbb{E}[Y]-\\theta)^2$，我们可以将超额风险表示为：\n$$ \\mathcal{E} = \\left(\\text{Var}(Y) + (\\mathbb{E}[Y]-\\theta_{\\ell_{1}}^{\\star})^2\\right) - \\left(\\text{Var}(Y) + (\\mathbb{E}[Y]-\\theta_{\\ell_{2}}^{\\star})^2\\right) $$\n由于 $\\theta_{\\ell_2}^\\star = \\mathbb{E}[Y]$，第二项得以简化，我们得到：\n$$ \\mathcal{E} = (\\mathbb{E}[Y] - \\theta_{\\ell_{1}}^{\\star})^2 = (\\mathbb{E}[Y] - \\text{median}(Y))^2 $$\n为了找到一个闭式表达式，我们必须计算指定分布 $Y = \\mu + X$ 的均值和中位数，其中 $X \\sim \\text{Exp}(\\lambda)$。$X$ 的概率密度函数是 $f_X(x) = \\lambda \\exp(-\\lambda x)$ for $x \\ge 0$。\n\n$Y$ 的均值是：\n$$ \\mathbb{E}[Y] = \\mathbb{E}[\\mu + X] = \\mu + \\mathbb{E}[X] $$\n率参数为 $\\lambda$ 的指数分布的均值是 $\\mathbb{E}[X] = \\frac{1}{\\lambda}$。因此，\n$$ \\mathbb{E}[Y] = \\mu + \\frac{1}{\\lambda} $$\n$Y$ 的中位数，我们记为 $m_Y$，是满足 $P(Y \\le m_Y) = 1/2$ 的值。\n$$ P(Y \\le m_Y) = P(\\mu + X \\le m_Y) = P(X \\le m_Y - \\mu) = \\int_{0}^{m_Y - \\mu} \\lambda \\exp(-\\lambda x) dx = 1 - \\exp(-\\lambda(m_Y - \\mu)) $$\n将此概率设为 $1/2$：\n$$ 1 - \\exp(-\\lambda(m_Y - \\mu)) = \\frac{1}{2} \\implies \\exp(-\\lambda(m_Y - \\mu)) = \\frac{1}{2} $$\n对两边取自然对数：\n$$ -\\lambda(m_Y - \\mu) = \\ln\\left(\\frac{1}{2}\\right) = -\\ln(2) \\implies m_Y - \\mu = \\frac{\\ln(2)}{\\lambda} $$\n因此，$Y$ 的中位数是：\n$$ \\text{median}(Y) = m_Y = \\mu + \\frac{\\ln(2)}{\\lambda} $$\n现在我们可以通过将均值和中位数代入我们的表达式来计算超额风险 $\\mathcal{E}$：\n$$ \\mathcal{E} = \\left( \\left(\\mu + \\frac{1}{\\lambda}\\right) - \\left(\\mu + \\frac{\\ln(2)}{\\lambda}\\right) \\right)^2 = \\left( \\frac{1}{\\lambda} - \\frac{\\ln(2)}{\\lambda} \\right)^2 $$\n这可以简化为仅用 $\\lambda$ 表示的最终闭式表达式：\n$$ \\mathcal{E} = \\frac{(1 - \\ln(2))^2}{\\lambda^2} $$\n\n3. 对齐条件\n\n对齐条件是使超额风险 $\\mathcal{E}$ 为零的条件。根据我们的推导，$\\mathcal{E} = (\\mathbb{E}[Y] - \\text{median}(Y))^2$。该量为零当且仅当：\n$$ \\mathbb{E}[Y] = \\text{median}(Y) $$\n就总体统计量而言，当总体均值等于总体中位数时，就会发生对齐。在这种情况下，用于训练损失函数（$\\ell_1$）的最优参数与用于评估损失函数（$\\ell_2$）的最优参数相同，因此不会因不匹配而导致性能下降。\n\n对于给定的指数移位模型，此条件要求：\n$$ \\mu + \\frac{1}{\\lambda} = \\mu + \\frac{\\ln(2)}{\\lambda} $$\n由于 $\\lambda > 0$，这简化为 $1 = \\ln(2)$。然而，这是一个错误的陈述，因为 $\\ln(2) \\approx 0.6931$。指数分布是一种偏态分布，其均值和中位数不重合。具体来说，由于 $1 > \\ln(2)$，对于任何 $\\lambda > 0$，均值总是大于中位数。因此，对于此模型，对齐条件永远不能成立，并且渐近超额风险 $\\mathcal{E}$ 总是严格为正。",
            "answer": "$$\n\\boxed{\\frac{\\left(1 - \\ln(2)\\right)^2}{\\lambda^2}}\n$$"
        },
        {
            "introduction": "理论与实践之间的一个常见差距是，我们用于训练模型的数据分布可能与模型在现实世界中遇到的数据分布不完全相同，这种现象被称为“数据集偏移”。这个练习模拟了一个分类任务，其中训练样本的类别比例与目标总体的类别比例不一致。它将引导我们计算在这种情况下天真的经验风险会如何产生误导性的结果，并介绍一种强大的修正技术——重要性加权（importance weighting），以获得对真实泛化误差的无偏估计。",
            "id": "3123242",
            "problem": "考虑一个标签为 $Y \\in \\{0,1\\}$ 且分类器 $h$ 固定的二元分类任务。损失函数为 0-1 损失 $\\ell(h(X),Y) = \\mathbf{1}\\{h(X) \\neq Y\\}$。目标总体是平衡的，即目标标签分布满足 $\\mathbb{P}(Y=1)=\\mathbb{P}(Y=0)=\\frac{1}{2}$。然而，训练样本来自一个不平衡的病例-对照设计，其中标签的抽样分布为 $\\mathbb{P}_{\\text{sample}}(Y=1)=0.8$ 和 $\\mathbb{P}_{\\text{sample}}(Y=0)=0.2$。假设分类器的类条件错误率在总体和样本中是不变的：当 $Y=1$ 时，错分概率为 $\\alpha=0.1$；当 $Y=0$ 时，错分概率为 $\\beta=0.3$。假设在抽样分布下，观测值是独立同分布的（i.i.d.），并且在给定 $Y$ 的条件下，不同样本的损失是独立的 Bernoulli 随机变量，当 $Y=1$ 时参数为 $\\alpha$，当 $Y=0$ 时参数为 $\\beta$。样本大小为 $n=1000$。\n\n仅使用期望风险和经验风险的基本定义，以及重要性加权的原理，完成以下任务：\n\n(a) 定义平衡目标总体下的期望风险，并用 $\\alpha$ 和 $\\beta$ 计算其值。\n\n(b) 定义朴素经验风险的期望值，该风险是通过对不平衡样本上的 $\\ell(h(X),Y)$ 进行平均计算而得到的（无任何重加权），并用给定参数计算其值。\n\n(c) 设计一个基于类的重加权方案，当应用于不平衡样本时，能够产生对平衡总体风险的无偏估计量。从第一性原理出发，证明其无偏性。\n\n(d) 推导在不平衡抽样分布下，重加权经验风险估计量的方差，然后根据给定的参数和 $n=1000$ 计算其数值。\n\n将最终数值答案四舍五入到四位有效数字。以科学记数法表示最终答案。答案中不要使用百分号。",
            "solution": "这个问题探讨了总体风险（泛化误差）和经验风险之间的关系，特别是在数据集漂移的情况下，即训练样本分布与目标总体分布不同。我们将使用重要性加权原理来纠正这种不匹配。\n\n设 $P$ 表示目标（平衡的）数据生成分布， $P_{\\text{sample}}$ 表示抽样（不平衡的）分布。损失函数是 0-1 损失，$\\ell(h(X), Y) = \\mathbf{1}\\{h(X) \\neq Y\\}$。给定的类条件错误率是 $\\alpha = \\mathbb{P}(h(X) \\neq 1 | Y=1) = 0.1$ 和 $\\beta = \\mathbb{P}(h(X) \\neq 0 | Y=0) = 0.3$。假设这些错误率相对于分布是不变的，即对于 $y \\in \\{0,1\\}$，有 $\\mathbb{P}_{\\text{sample}}(h(X) \\neq y | Y=y) = \\mathbb{P}(h(X) \\neq y | Y=y)$。\n\n(a) 平衡目标总体下的期望风险。\n\n期望风险，或称泛化误差，$R(h)$，是关于目标总体分布 $P(X,Y)$ 的期望损失。\n$$R(h) = \\mathbb{E}_{P(X,Y)}[\\ell(h(X), Y)]$$\n使用全期望定律，我们可以对标签 $Y$ 取条件：\n$$R(h) = \\sum_{y \\in \\{0,1\\}} \\mathbb{P}(Y=y) \\mathbb{E}_{P(X|Y=y)}[\\ell(h(X), y) | Y=y]$$\n这可以简化为：\n$$R(h) = \\mathbb{P}(Y=1) \\mathbb{P}(h(X) \\neq 1 | Y=1) + \\mathbb{P}(Y=0) \\mathbb{P}(h(X) \\neq 0 | Y=0)$$\n在平衡的目标总体中，$\\mathbb{P}(Y=1) = \\mathbb{P}(Y=0) = \\frac{1}{2}$。代入给定值：\n$$R(h) = \\left(\\frac{1}{2}\\right) \\alpha + \\left(\\frac{1}{2}\\right) \\beta = \\frac{1}{2}(\\alpha + \\beta)$$\n$$R(h) = \\frac{1}{2}(0.1 + 0.3) = \\frac{1}{2}(0.4) = 0.2$$\n\n(b) 朴素经验风险的期望值。\n\n朴素经验风险是在从 $P_{\\text{sample}}$ 中抽取的、大小为 $n$ 的不平衡样本上计算的平均损失。\n$$\\hat{R}_{\\text{naive}}(h) = \\frac{1}{n} \\sum_{i=1}^n \\ell(h(X_i), Y_i), \\quad \\text{where } (X_i, Y_i) \\sim P_{\\text{sample}}$$\n该估计量的期望值是关于抽样分布 $P_{\\text{sample}}$ 计算的。根据期望的线性和样本的独立同分布特性：\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{naive}}(h)] = \\mathbb{E}_{P_{\\text{sample}}} \\left[ \\frac{1}{n} \\sum_{i=1}^n \\ell(h(X_i), Y_i) \\right] = \\mathbb{E}_{P_{\\text{sample}}}[\\ell(h(X), Y)]$$\n这就是抽样分布下的期望风险。再次应用全期望定律，但使用 $Y$ 的抽样概率：\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\ell(h(X), Y)] = \\mathbb{P}_{\\text{sample}}(Y=1) \\mathbb{P}(h(X) \\neq 1 | Y=1) + \\mathbb{P}_{\\text{sample}}(Y=0) \\mathbb{P}(h(X) \\neq 0 | Y=0)$$\n我们已知 $\\mathbb{P}_{\\text{sample}}(Y=1) = 0.8$ 和 $\\mathbb{P}_{\\text{sample}}(Y=0) = 0.2$。\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{naive}}(h)] = (0.8)\\alpha + (0.2)\\beta = (0.8)(0.1) + (0.2)(0.3) = 0.08 + 0.06 = 0.14$$\n\n(c) 无偏估计量的重加权方案。\n\n为了从 $P_{\\text{sample}}$ 抽取的样本中获得目标风险 $R(h)$ 的无偏估计量，我们使用重要性加权。一个观测值 $(x,y)$ 的权重是其在目标分布下的概率与在抽样分布下的概率之比：$w(x,y) = \\frac{P(x,y)}{P_{\\text{sample}}(x,y)}$。\n由于条件分布 $P(X|Y)$ 是不变的，我们有 $P(x,y) = P(y) P(x|y)$ 和 $P_{\\text{sample}}(x,y) = P_{\\text{sample}}(y) P(x|y)$。权重简化为仅依赖于类别标签 $y$：\n$$w(y) = \\frac{P(y) P(x|y)}{P_{\\text{sample}}(y) P(x|y)} = \\frac{P(y)}{P_{\\text{sample}}(y)}$$\n我们定义两个权重，每个类别一个：\n$Y=1$ 的权重：$w_1 = w(1) = \\frac{\\mathbb{P}(Y=1)}{\\mathbb{P}_{\\text{sample}}(Y=1)} = \\frac{0.5}{0.8} = \\frac{5}{8} = 0.625$。\n$Y=0$ 的权重：$w_0 = w(0) = \\frac{\\mathbb{P}(Y=0)}{\\mathbb{P}_{\\text{sample}}(Y=0)} = \\frac{0.5}{0.2} = \\frac{5}{2} = 2.5$。\n重加权经验风险估计量 $\\hat{R}_{\\text{rw}}(h)$ 为：\n$$\\hat{R}_{\\text{rw}}(h) = \\frac{1}{n} \\sum_{i=1}^n w(Y_i) \\ell(h(X_i), Y_i)$$\n为了证明其无偏性，我们计算其关于抽样分布 $P_{\\text{sample}}$ 的期望：\n$$\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{rw}}(h)] = \\mathbb{E}_{P_{\\text{sample}}} \\left[ \\frac{1}{n} \\sum_{i=1}^n w(Y_i) \\ell(h(X_i), Y_i) \\right]$$\n$$= \\mathbb{E}_{P_{\\text{sample}}}[w(Y) \\ell(h(X), Y)]$$\n使用全期望定律：\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}_{\\text{sample}}(Y=y) \\mathbb{E}_{P_{\\text{sample}}(X|Y=y)}[w(y) \\ell(h(X), y) | Y=y]$$\n由于给定 $y$ 时 $w(y)$ 是常数：\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}_{\\text{sample}}(Y=y) w(y) \\mathbb{E}_{P(X|Y=y)}[\\ell(h(X), y) | Y=y]$$\n代入 $w(y) = \\frac{\\mathbb{P}(Y=y)}{\\mathbb{P}_{\\text{sample}}(Y=y)}$：\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}_{\\text{sample}}(Y=y) \\frac{\\mathbb{P}(Y=y)}{\\mathbb{P}_{\\text{sample}}(Y=y)} \\mathbb{P}(h(X) \\neq y | Y=y)$$\n$$= \\sum_{y \\in \\{0,1\\}} \\mathbb{P}(Y=y) \\mathbb{P}(h(X) \\neq y | Y=y)$$\n这正是 (a) 部分中目标总体风险 $R(h)$ 的定义。因此，该估计量是无偏的：$\\mathbb{E}_{P_{\\text{sample}}}[\\hat{R}_{\\text{rw}}(h)] = R(h)$。\n\n(d) 重加权经验风险估计量的方差。\n\n令 $Z_i = w(Y_i) \\ell(h(X_i), Y_i)$。估计量为 $\\hat{R}_{\\text{rw}}(h) = \\frac{1}{n} \\sum_{i=1}^n Z_i$。由于样本 $(X_i, Y_i)$ 是从 $P_{\\text{sample}}$ 中抽取的独立同分布样本，随机变量 $Z_i$ 也是独立同分布的。\n估计量的方差为：\n$$\\text{Var}(\\hat{R}_{\\text{rw}}(h)) = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n Z_i\\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(Z_i) = \\frac{1}{n} \\text{Var}(Z_1)$$\n单个项 $Z_1$ 的方差由 $\\text{Var}(Z_1) = \\mathbb{E}[Z_1^2] - (\\mathbb{E}[Z_1])^2$ 给出。\n从 (c) 部分可知，$\\mathbb{E}[Z_1] = \\mathbb{E}_{P_{\\text{sample}}}[w(Y) \\ell(h(X), Y)] = R(h) = 0.2$。\n现在我们计算在抽样分布 $P_{\\text{sample}}$ 下的二阶矩 $\\mathbb{E}[Z_1^2]$：\n$$\\mathbb{E}[Z_1^2] = \\mathbb{E}_{P_{\\text{sample}}}[(w(Y) \\ell(h(X), Y))^2] = \\mathbb{E}_{P_{\\text{sample}}}[w(Y)^2 \\ell(h(X), Y)^2]$$\n由于损失 $\\ell$ 是一个指示函数（$\\mathbf{1}\\{\\cdot\\}$），其值要么为 $0$，要么为 $1$。因此，$\\ell^2 = \\ell$。\n$$\\mathbb{E}[Z_1^2] = \\mathbb{E}_{P_{\\text{sample}}}[w(Y)^2 \\ell(h(X), Y)]$$\n应用全期望定律：\n$$\\mathbb{E}[Z_1^2] = \\mathbb{P}_{\\text{sample}}(Y=1) w_1^2 \\mathbb{P}(h(X) \\neq 1|Y=1) + \\mathbb{P}_{\\text{sample}}(Y=0) w_0^2 \\mathbb{P}(h(X) \\neq 0|Y=0)$$\n$$= \\mathbb{P}_{\\text{sample}}(Y=1) w_1^2 \\alpha + \\mathbb{P}_{\\text{sample}}(Y=0) w_0^2 \\beta$$\n代入已知值：\n$$\\mathbb{E}[Z_1^2] = (0.8)(0.625)^2(0.1) + (0.2)(2.5)^2(0.3)$$\n$$= (0.8)(0.390625)(0.1) + (0.2)(6.25)(0.3)$$\n$$= 0.03125 + 0.375 = 0.40625$$\n现在我们计算 $\\text{Var}(Z_1)$：\n$$\\text{Var}(Z_1) = \\mathbb{E}[Z_1^2] - (\\mathbb{E}[Z_1])^2 = 0.40625 - (0.2)^2 = 0.40625 - 0.04 = 0.36625$$\n最后，对于 $n=1000$，重加权估计量的方差为：\n$$\\text{Var}(\\hat{R}_{\\text{rw}}(h)) = \\frac{\\text{Var}(Z_1)}{n} = \\frac{0.36625}{1000} = 0.00036625$$\n四舍五入到四位有效数字并以科学记数法表示：\n$$0.00036625 = 3.6625 \\times 10^{-4} \\approx 3.663 \\times 10^{-4}$$",
            "answer": "$$\\boxed{3.663 \\times 10^{-4}}$$"
        },
        {
            "introduction": "在实践中，我们通常使用重采样技术（如交叉验证）来估计模型的泛化能力。然而，这个估计本身也存在不确定性，其来源是多方面的。这个练习深入探讨了这些不确定性的来源，特别是由于验证集样本有限而产生的“组内变异”和由于训练/验证集随机划分而产生的“组间变异”。通过运用全方差定律，我们将学习如何构建一个更稳健的置信区间来估计模型的真实预期风险。",
            "id": "3123300",
            "problem": "一个二元分类模型在同一个独立同分布的数据集上通过重复随机的训练/验证集划分进行训练。对于每个随机种子 $s \\in \\{1,\\dots,k\\}$，都会形成一个训练集，并在一个大小为 $n_{\\mathrm{val}}$ 的验证集上评估该模型，从而产生一个表示为 $\\hat{R}_{s}$ 的验证集经验风险（平均 $0\\text{-}1$ 损失）。假设在不同种子之间，$\\hat{R}_{s}$ 是相同数据生成机制的独立实现，并且每个 $\\hat{R}_{s}$ 都是期望（总体）风险 $R$ 的无偏估计量。目标是估计 $R$ 并量化不确定性，该不确定性要同时考虑到不同划分间的变异性（划分间变异性）和有限的验证样本量（划分内变异性）。\n\n您可以假设：(i) 不同样本的验证损失是独立的伯努利随机变量，其成功概率等于该训练模型的真实错分概率；以及 (ii) 中心极限定理 (CLT) 适用于跨种子的平均值。\n\n在一个实验中，使用了 $k=8$ 个种子，每个种子的验证集大小为 $n_{\\mathrm{val}}=5000$，观察到的验证集经验风险为：\n$0.158,\\; 0.171,\\; 0.165,\\; 0.162,\\; 0.169,\\; 0.155,\\; 0.166,\\; 0.160$。\n\n从期望风险 $R$ 和经验风险 $\\hat{R}_{s}$ 的核心定义出发，使用全方差定律推导跨种子平均值 $\\bar{R} = \\frac{1}{k}\\sum_{s=1}^{k}\\hat{R}_{s}$ 的方差估计量，该估计量需明确考虑划分间变异性和划分内验证抽样噪声。然后，在自由度为 $\\nu=k-1$ 的学生t分布近似下，计算 $\\bar{R}$ 的抽样分布，并求出 $R$ 的双侧 $95\\%$ 置信区间的半宽度。\n\n将您的最终答案表示为单个十进制数值（仅半宽度），并将答案四舍五入到四位有效数字。不需要单位。",
            "solution": "目标是使用平均经验风险 $\\bar{R} = \\frac{1}{k}\\sum_{s=1}^{k}\\hat{R}_{s}$ 来估计期望风险 $R$，并量化此估计的不确定性。总不确定性来源于两个方面：\n1.  **划分内变异性**：由于每次划分使用有限大小为 $n_{\\mathrm{val}}$ 的验证集而产生的方差。这是一种抽样误差。\n2.  **划分间变异性**：由于每次划分为特定训练集的选择而产生的方差，这导致每个种子 $s$ 都有一个不同的训练模型。\n\n我们的任务是推导 $\\bar{R}$ 的一个方差估计量，该估计量明确地考虑了这两个来源。令 $\\theta_s$ 表示在种子 $s$ 的训练数据上学习到的模型参数的随机变量。经验风险 $\\hat{R}_s$ 也是一个随机变量，它既依赖于 $\\theta_s$，也依赖于验证集的随机抽样。\n\n总期望风险为 $R = E[\\hat{R}_s]$。由于 $s=1, \\dots, k$ 的 $\\hat{R}_s$ 是独立同分布的，它们的平均值 $\\bar{R}$ 的方差为：\n$$ \\mathrm{Var}(\\bar{R}) = \\mathrm{Var}\\left(\\frac{1}{k}\\sum_{s=1}^{k}\\hat{R}_{s}\\right) = \\frac{1}{k^2}\\sum_{s=1}^{k}\\mathrm{Var}(\\hat{R}_{s}) = \\frac{1}{k}\\mathrm{Var}(\\hat{R}_{s}) $$\n为了理解 $\\mathrm{Var}(\\hat{R}_{s})$ 的组成部分，我们应用全方差定律，以训练好的模型 $\\theta_s$ 为条件：\n$$ \\mathrm{Var}(\\hat{R}_{s}) = E_{\\theta_s}[\\mathrm{Var}(\\hat{R}_{s} | \\theta_s)] + \\mathrm{Var}_{\\theta_s}(E[\\hat{R}_{s} | \\theta_s]) $$\n让我们分析每一项：\n- 内层期望 $E[\\hat{R}_{s} | \\theta_s]$ 是对于一个*固定*模型 $\\theta_s$ 的期望经验风险。这是该特定模型的真实风险，我们称之为 $R(\\theta_s)$。所以，$E[\\hat{R}_{s} | \\theta_s] = R(\\theta_s)$。\n- 这个期望的方差 $\\mathrm{Var}_{\\theta_s}(R(\\theta_s))$ 是在不同训练划分下真实模型性能的方差。这就是**划分间方差**，我们表示为 $\\sigma^2_{\\text{between}}$。\n- 内层方差 $\\mathrm{Var}(\\hat{R}_{s} | \\theta_s)$ 是对于固定模型 $\\theta_s$ 的经验风险的方差，它源于有限的验证集。由于 $\\hat{R}_s$ 是 $n_{\\mathrm{val}}$ 个独立的伯努利试验（0-1损失）的平均值，其成功概率为 $R(\\theta_s)$，因此其方差为 $\\frac{R(\\theta_s)(1-R(\\theta_s))}{n_{\\mathrm{val}}}$。\n- 这个内层方差的期望 $E_{\\theta_s}\\left[\\frac{R(\\theta_s)(1-R(\\theta_s))}{n_{\\mathrm{val}}}\\right]$ 是由于验证集抽样而产生的平均方差，在所有可能的训练划分上取平均。这就是**划分内方差**，我们表示为 $\\sigma^2_{\\text{within}}$。\n\n综合这些，单个经验风险测量 $\\hat{R}_s$ 的总方差是：\n$$ \\mathrm{Var}(\\hat{R}_{s}) = \\sigma^2_{\\text{within}} + \\sigma^2_{\\text{between}} $$\n此推导明确地显示了总方差是两个不同变异性来源之和。\n\n为了估计 $\\mathrm{Var}(\\bar{R})$，我们首先需要估计 $\\mathrm{Var}(\\hat{R}_{s})$。我们有一个包含 $k$ 个观测值的样本 $\\{\\hat{R}_1, \\dots, \\hat{R}_k\\}$。这些观测值的样本方差，\n$$ S^2_{\\hat{R}} = \\frac{1}{k-1} \\sum_{s=1}^{k} (\\hat{R}_s - \\bar{R})^2 $$\n是总方差 $\\mathrm{Var}(\\hat{R}_{s})$ 的一个无偏估计量。也就是说，$E[S^2_{\\hat{R}}] = \\mathrm{Var}(\\hat{R}_{s}) = \\sigma^2_{\\text{within}} + \\sigma^2_{\\text{between}}$。这个单一的统计量经验性地捕捉了两种方差来源的综合效应。\n\n因此，均值 $\\bar{R}$ 的方差的一个无偏估计量是：\n$$ \\widehat{\\mathrm{Var}}(\\bar{R}) = \\frac{S^2_{\\hat{R}}}{k} $$\n$\\bar{R}$ 的标准误差是这个估计方差的平方根：\n$$ \\mathrm{SE}(\\bar{R}) = \\sqrt{\\frac{S^2_{\\hat{R}}}{k}} = \\frac{S_{\\hat{R}}}{\\sqrt{k}} $$\n现在，我们进行数值计算。给定的 $\\hat{R}_s$ 数据是：\n$\\{0.158, 0.171, 0.165, 0.162, 0.169, 0.155, 0.166, 0.160\\}$。我们有 $k=8$。\n\n首先，计算样本均值 $\\bar{R}$：\n$$ \\bar{R} = \\frac{1}{8} (0.158 + 0.171 + 0.165 + 0.162 + 0.169 + 0.155 + 0.166 + 0.160) = \\frac{1.306}{8} = 0.16325 $$\n接下来，计算平方偏差和 $\\sum_{s=1}^{k} (\\hat{R}_s - \\bar{R})^2$：\n\\begin{align*}\n\\sum_{s=1}^{8} (\\hat{R}_s - \\bar{R})^2 =  (0.158-0.16325)^2 + (0.171-0.16325)^2 + (0.165-0.16325)^2 \\\\\n+ (0.162-0.16325)^2 + (0.169-0.16325)^2 + (0.155-0.16325)^2 \\\\\n+ (0.166-0.16325)^2 + (0.160-0.16325)^2 \\\\\n=  (-0.00525)^2 + (0.00775)^2 + (0.00175)^2 + (-0.00125)^2 \\\\\n+ (0.00575)^2 + (-0.00825)^2 + (0.00275)^2 + (-0.00325)^2 \\\\\n=  (2.75625 + 6.00625 + 0.30625 + 0.15625 + 3.30625 + 6.80625 + 0.75625 + 1.05625) \\times 10^{-5} \\\\\n=  2.115 \\times 10^{-4}\n\\end{align*}\n现在，计算样本方差 $S^2_{\\hat{R}}$：\n$$ S^2_{\\hat{R}} = \\frac{1}{k-1} \\sum_{s=1}^{k} (\\hat{R}_s - \\bar{R})^2 = \\frac{2.115 \\times 10^{-4}}{8-1} = \\frac{2.115 \\times 10^{-4}}{7} \\approx 3.0214286 \\times 10^{-5} $$\n均值的估计方差是：\n$$ \\widehat{\\mathrm{Var}}(\\bar{R}) = \\frac{S^2_{\\hat{R}}}{k} = \\frac{3.0214286 \\times 10^{-5}}{8} \\approx 3.7767857 \\times 10^{-6} $$\n均值的标准误差是：\n$$ \\mathrm{SE}(\\bar{R}) = \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{R})} = \\sqrt{3.7767857 \\times 10^{-6}} \\approx 0.001943395 $$\n问题要求使用自由度为 $\\nu = k-1 = 7$ 的学生t分布近似来计算 $R$ 的双侧 $95\\%$ 置信区间的半宽度。半宽度 $H$ 由下式给出：\n$$ H = t_{\\alpha/2, \\nu} \\times \\mathrm{SE}(\\bar{R}) $$\n对于 $95\\%$ 的置信区间，$\\alpha=0.05$，所以 $\\alpha/2 = 0.025$。来自自由度为 $\\nu=7$ 的t分布的临界值是：\n$$ t_{0.025, 7} \\approx 2.3646 $$\n现在，我们计算半宽度：\n$$ H = 2.3646 \\times 0.001943395 \\approx 0.00459523 $$\n将结果四舍五入到四位有效数字得到：\n$$ H \\approx 0.004595 $$",
            "answer": "$$\\boxed{0.004595}$$"
        }
    ]
}