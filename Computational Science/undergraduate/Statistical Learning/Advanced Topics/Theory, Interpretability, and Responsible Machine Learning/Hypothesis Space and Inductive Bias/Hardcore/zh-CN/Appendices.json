{
    "hands_on_practices": [
        {
            "introduction": "这项练习旨在探讨数据预处理步骤（通常被视为简单的准备工作）如何成为一种强有力的归纳偏置。你将使用k最近邻（k-NN）分类器，实现并比较两种常见的特征归一化技术——Z-score归一化和最小-最大值归一化。通过这个练习，你将具体地看到这些选择如何改变底层的距离度量，从而有效地改变假设空间并影响模型的最终预测。",
            "id": "3129970",
            "problem": "你必须编写一个完整的程序，比较不同的特征归一化如何为基于距离的学习器导出不同的假设空间，并在此过程中量化归一化如何充当归纳偏置。该学习器是1-最近邻分类器，其形式化定义如下。给定一个训练集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^n$，其中 $\\mathbf{x}_i \\in \\mathbb{R}^d$，标签 $y_i \\in \\{0,1,\\dotsc,C-1\\}$，以及一个度量 $d(\\cdot,\\cdot)$，假设空间 $\\mathcal{H}$ 中的假设 $h$ 对于任何查询点 $\\mathbf{q} \\in \\mathbb{R}^d$ 返回使得 $d(\\mathbf{q}, \\mathbf{x}_j)$ 最小的训练点 $\\mathbf{x}_j$ 的标签 $y_j$（如果出现平局，则选择最小的索引 $j$）。因此，假设空间由度量的选择参数化，这里的度量是由归一化导出的。\n\n你必须实现两种仅从训练数据计算的归一化方法：\n- Z-分数归一化：对于特征索引 $j \\in \\{1,\\dotsc,d\\}$，计算总体均值 $\\mu_j$ 和总体标准差 $\\sigma_j$，并通过下式定义导出距离\n$$\nd_{\\text{z}}(\\mathbf{q}, \\mathbf{x}) \\triangleq \\sqrt{\\sum_{j=1}^d \\left(\\frac{q_j - x_j}{\\sigma_j}\\right)^2},\n$$\n约定如果 $\\sigma_j = 0$，则该特征对总和的贡献为 $0$（也就是说，该特征在距离计算中被忽略，因为它在训练数据中的方差为零）。\n- 最小-最大归一化：对于特征索引 $j$，计算最小值 $m_j$ 和最大值 $M_j$，定义极差 $r_j \\triangleq M_j - m_j$，并通过下式定义导出距离\n$$\nd_{\\text{mm}}(\\mathbf{q}, \\mathbf{x}) \\triangleq \\sqrt{\\sum_{j=1}^d \\left(\\frac{q_j - x_j}{r_j}\\right)^2},\n$$\n约定如果 $r_j = 0$，则该特征对总和的贡献为 $0$。\n\n这些定义通过度量中的逐特征权重来编码归纳偏置：具有较大训练数据变异性的特征被降权，而选择 $\\sigma_j$ 或 $r_j$ 会产生不同的权重，从而导致不同的假设空间，并可能产生不同的预测。\n\n你必须为每个导出距离实现1-最近邻分类器，为每个查询点返回单个最近训练点的标签，并采用确定性的平局决胜规则，即在距离相等的训练点中选择最小的索引。\n\n从上述基本定义出发，构建一个程序，对于下面描述的每个测试用例，执行以下操作：\n- 为每种归一化计算训练统计数据。\n- 对于每个查询，计算在 $d_{\\text{z}}$ 和 $d_{\\text{mm}}$ 下的预测标签。\n- 计算在两种归一化下预测标签一致的查询所占的比例，表示为四舍五入到3位小数的十进制数。\n- 根据指定的输出格式，将所有测试用例的结果汇总到一行中。\n\n本问题不涉及物理单位。也不涉及角度。所有输出必须是整数、布尔值、浮点数或这些类型的列表。\n\n测试套件：\n- 测试用例1（一般情况，存在不同的归纳偏置和零方差特征）：\n    - 训练输入 $\\mathbf{X}$，$n=6$，$d=3$：\n      $\\mathbf{x}_1 = (1000, 0, 0)$, $\\mathbf{x}_2 = (1000, 1, 0)$, $\\mathbf{x}_3 = (0, 5, 0)$, $\\mathbf{x}_4 = (0, 6, 0)$, $\\mathbf{x}_5 = (0, 7, 0)$, $\\mathbf{x}_6 = (0, 8, 0)$。\n    - 标签：$y = [0, 0, 1, 1, 1, 1]$。\n    - 查询：$\\mathbf{q}_1 = (700, 6, 0)$, $\\mathbf{q}_2 = (650, 5.5, 0)$, $\\mathbf{q}_3 = (600, 7.5, 0)$。\n- 测试用例2（边界条件，两种归一化的逐特征尺度成比例，这意味着度量成比例，因此对任何查询的最近邻排名相同）：\n    - 训练输入，$n=4$，$d=2$：\n      $\\mathbf{x}_1 = (0, 0)$, $\\mathbf{x}_2 = (1, 0)$, $\\mathbf{x}_3 = (0, 100)$, $\\mathbf{x}_4 = (1, 100)$。\n    - 标签：$y = [0, 0, 1, 1]$。\n    - 查询：$\\mathbf{q}_1 = (0.9, 10)$, $\\mathbf{q}_2 = (0.5, 90)$, $\\mathbf{q}_3 = (0.2, 30)$。\n- 测试用例3（边缘情况，存在一个零方差特征，而查询在该特征上的差异很大；两种归一化都必须忽略该零方差特征）：\n    - 训练输入，$n=3$，$d=2$：\n      $\\mathbf{x}_1 = (1, 5)$, $\\mathbf{x}_2 = (1, 5)$, $\\mathbf{x}_3 = (1, 10)$。\n    - 标签：$y = [0, 1, 1]$。\n    - 查询：$\\mathbf{q}_1 = (100, 7)$, $\\mathbf{q}_2 = (100, 5)$, $\\mathbf{q}_3 = (100, 9)$。\n\n最终输出格式：\n- 你的程序应产生一行输出，其中包含一个逗号分隔的列表，并用方括号括起来。每个测试用例贡献一个包含三个元素的列表：\n    1. 在 $d_{\\text{z}}$ 和 $d_{\\text{mm}}$ 下预测标签相同的查询所占的比例（四舍五入到3位小数），以浮点数表示。\n    2. 在 $d_{\\text{z}}$ 下对查询的预测标签列表，以整数表示。\n    3. 在 $d_{\\text{mm}}$ 下对查询的预测标签列表，以整数表示。\n- 具体来说，输出必须看起来像\n$[\\,[f_1,[\\ell^{\\text{z}}_{1},\\dotsc],[\\ell^{\\text{mm}}_{1},\\dotsc]],\\,[f_2,[\\dotsc],[\\dotsc]],\\,[f_3,[\\dotsc],[\\dotsc]]\\,]$\n其中 $f_k$ 是测试用例 $k$ 的比例，$\\ell^{\\text{z}}$ 是 $d_{\\text{z}}$ 下的标签，$\\ell^{\\text{mm}}$ 是 $d_{\\text{mm}}$ 下的标签。\n\n你的程序必须是自包含的，且不得读取任何输入。它必须完全按照规定执行计算，并在距离相等时通过最小索引进行确定性平局决胜。",
            "solution": "用户在统计学习理论领域提供了一个定义明确的计算问题。任务是实现一个1-最近邻（1-NN）分类器，该分类器在两种不同的特征归一化方案下运行，并在一个查询点集上比较它们的预测。这种比较量化了归一化选择（作为一种归纳偏置形式）如何影响假设空间。\n\n该问题是有效的。它在科学上是合理的、适定的和客观的。所有必需的定义、数据和过程都得到了明确的规定。平局决胜规则（最小索引）确保了唯一的解。处理零方差特征的约定也清晰说明，防止了不确定的计算。\n\n问题的核心在于理解不同的归一化统计数据——用于Z-分数归一化的总体标准差和用于最小-最大归一化的极差——如何导出不同的距离度量。查询点 $\\mathbf{q}$ 和训练点 $\\mathbf{x}$ 之间的距离被定义为缩放后的欧几里得距离：\n$$d(\\mathbf{q}, \\mathbf{x}) = \\sqrt{\\sum_{j=1}^d \\left(w_j (q_j - x_j)\\right)^2}$$\n其中 $d$ 是特征数量，$w_j$ 是第 $j$ 个特征的权重。对于Z-分数归一化，权重是总体标准差的倒数，$w_j = 1/\\sigma_j$。对于最小-最大归一化，权重是特征极差的倒数，$w_j = 1/r_j$。在训练集中变异性为零的特征（$\\sigma_j=0$ 或 $r_j=0$）对总距离的贡献为 $0$，实际上被忽略了。\n\n1-NN假设 $h(\\mathbf{q})$ 将查询点 $\\mathbf{q}$ 映射到训练点 $\\mathbf{x}_i$ 的标签 $y_i$，该训练点根据所选度量最接近 $\\mathbf{q}$。\n$$\nh(\\mathbf{q}) = y_k \\quad \\text{where} \\quad k = \\underset{i \\in \\{1,\\dots,n\\}}{\\arg\\min} \\, d(\\mathbf{q}, \\mathbf{x}_i)\n$$\n由于平方根函数是单调的，最小化 $d(\\mathbf{q}, \\mathbf{x}_i)$ 等价于最小化平方距离 $d^2(\\mathbf{q}, \\mathbf{x}_i)$，这在计算上更高效。选择最小索引的平局决胜规则解决了任何歧义。\n\n每个测试用例的步骤如下：\n1.  **计算归一化统计数据**：对于训练数据 $\\mathbf{X}$ 的每个特征 $j$，计算总体标准差 $\\sigma_j$ 和极差 $r_j$。\n2.  **定义度量权重**：Z-分数导出度量的权重是 $\\{1/\\sigma_j\\}_{j=1}^d$，最小-最大导出度量的权重是 $\\{1/r_j\\}_{j=1}^d$。如果 $\\sigma_j=0$ 或 $r_j=0$，相应的权重实际上为 $0$，因为该特征对距离总和的贡献被定义为 $0$。\n3.  **分类查询**：对于每个查询点 $\\mathbf{q}_k$，计算它到每个训练点 $\\mathbf{x}_i$ 在 $d_{\\text{z}}^2$ 和 $d_{\\text{mm}}^2$ 下的平方距离。为每个度量确定最近邻的索引，应用平局决胜规则。预测的标签是这些最近邻的标签。\n4.  **计算一致性**：比较两种方法的预测列表。一致性比例是两种方法预测相同标签的查询数量除以查询总数。\n\n我们将此过程应用于每个测试用例。\n\n**测试用例1**：\n- 训练数据 $\\mathbf{X}$：$n=6, d=3$。\n- 特征 $j=1$ 的统计数据：$\\sigma_1 = 1000\\sqrt{2}/3 \\approx 471.4$，$r_1 = 1000$。\n- 特征 $j=2$ 的统计数据：$\\sigma_2 = \\sqrt{107/12} \\approx 2.986$，$r_2 = 8$。\n- 特征 $j=3$ 的统计数据：$\\sigma_3 = 0, r_3 = 0$。此特征被忽略。\n两种度量的权重不同，导致不同的假设空间几何形状。然而，对于提供的三个特定查询点，两种度量下确定的最近邻是相同的。\n- 对于 $\\mathbf{q}_1=(700, 6, 0)$，两种度量的最近邻都是 $\\mathbf{x}_4=(0, 6, 0)$。标签：$1$。\n- 对于 $\\mathbf{q}_2=(650, 5.5, 0)$，最近邻在 $\\mathbf{x}_3=(0, 5, 0)$ 和 $\\mathbf{x}_4=(0, 6, 0)$ 之间出现平局。根据平局决胜规则（最小索引），两者都选择 $\\mathbf{x}_3$。标签：$1$。\n- 对于 $\\mathbf{q}_3=(600, 7.5, 0)$，最近邻在 $\\mathbf{x}_5=(0, 7, 0)$ 和 $\\mathbf{x}_6=(0, 8, 0)$ 之间出现平局。两者都选择 $\\mathbf{x}_5$。标签：$1$。\n两种方法的预测标签都是 $[1, 1, 1]$。一致性比例为 $3/3 = 1.0$。\n\n**测试用例2**：\n- 训练数据 $\\mathbf{X}$：$n=4, d=2$。\n- 特征 $j=1$ 的统计数据：$\\sigma_1=0.5, r_1=1$。\n- 特征 $j=2$ 的统计数据：$\\sigma_2=50, r_2=100$。\nZ-分数度量的尺度（权重）是 $(1/\\sigma_1, 1/\\sigma_2)=(2, 0.02)$。最小-最大度量的尺度是 $(1/r_1, 1/r_2)=(1, 0.01)$。Z-分数尺度恰好是最小-最大尺度的两倍。因此，$d_{\\text{z}}(\\mathbf{q}, \\mathbf{x}) = 2 \\cdot d_{\\text{mm}}(\\mathbf{q}, \\mathbf{x})$。由于一个度量是另一个度量的常数倍，它们将始终以相同的顺序对邻居进行排序。预测必须相同。\n- 对查询点 $\\mathbf{q}_1=(0.9, 10), \\mathbf{q}_2=(0.5, 90), \\mathbf{q}_3=(0.2, 30)$ 的预测，两种方法都是 $[0, 1, 0]$。一致性比例为 $3/3 = 1.0$。\n\n**测试用例3**：\n- 训练数据 $\\mathbf{X}$：$n=3, d=2$。\n- 特征 $j=1$ 的统计数据：$\\sigma_1=0, r_1=0$。此特征被两种度量忽略。\n- 特征 $j=2$ 的统计数据：$\\sigma_2 = 5\\sqrt{2}/3, r_2 = 5$。\n由于两种度量的距离计算仅依赖于第二个特征，对于任何给定的查询，两者都将试图最小化 $(q_2 - x_{i2})^2$。缩放因子 $1/\\sigma_2^2$ 和 $1/r_2^2$ 对于固定的查询在所有训练点上都是常数，不影响邻居的排序。因此，预测必须相同。\n- 训练点特征2的值为 $[5, 5, 10]$，对应标签为 $[0, 1, 1]$。\n- 对于 $\\mathbf{q}_1=(100, 7)$，$q_2=7$。最近的 $x_{i2}$ 是 $5$，对应于索引 $1$ 和 $2$。最小的索引是 $1$，所以标签是 $0$。\n- 对于 $\\mathbf{q}_2=(100, 5)$，$q_2=5$。最近的 $x_{i2}$ 是 $5$，对应于索引 $1$ 和 $2$。最小的索引是 $1$，所以标签是 $0$。\n- 对于 $\\mathbf{q}_3=(100, 9)$，$q_2=9$。最近的 $x_{i2}$ 是 $10$，对应于索引 $3$。标签是 $1$。\n两种方法的预测标签都是 $[0, 0, 1]$。一致性比例为 $3/3 = 1.0$。",
            "answer": "```python\nimport numpy as np\n\ndef one_nn_predict(queries, train_X, train_y, scales):\n    \"\"\"\n    Predicts labels for queries using the 1-NN rule with a scaled Euclidean distance.\n    The 'scales' vector contains the per-feature weights (e.g., 1/sigma or 1/range).\n    \"\"\"\n    n_train = train_X.shape[0]\n    predictions = []\n\n    for q in queries:\n        # We use the squared Euclidean distance to find the nearest neighbor.\n        # This avoids the computationally expensive sqrt operation and does not\n        # change the result of argmin, as sqrt is a monotonic function.\n        \n        # Broadcasted, vectorized calculation of all squared distances from q\n        # to each point in train_X.\n        # diff shape: (n_train, n_features)\n        diff = q - train_X\n        # scales shape: (n_features,). Broadcasting applies it to each row of diff.\n        scaled_diff = diff * scales\n        # Sum of squares along the feature axis (axis=1)\n        sq_distances = np.sum(scaled_diff**2, axis=1)\n\n        # np.argmin finds the index of the minimum value. In case of ties,\n        # it returns the index of the first occurrence, which matches the\n        # problem's tie-breaking rule (pick the smallest index).\n        nearest_neighbor_idx = np.argmin(sq_distances)\n        predictions.append(train_y[nearest_neighbor_idx])\n        \n    return predictions\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        {\n            \"X\": np.array([\n                [1000., 0., 0.], [1000., 1., 0.], [0., 5., 0.], \n                [0., 6., 0.], [0., 7., 0.], [0., 8., 0.]\n            ]),\n            \"y\": np.array([0, 0, 1, 1, 1, 1]),\n            \"Q\": np.array([\n                [700., 6., 0.], [650., 5.5, 0.], [600., 7.5, 0.]\n            ])\n        },\n        {\n            \"X\": np.array([\n                [0., 0.], [1., 0.], [0., 100.], [1., 100.]\n            ]),\n            \"y\": np.array([0, 0, 1, 1]),\n            \"Q\": np.array([\n                [0.9, 10.], [0.5, 90.], [0.2, 30.]\n            ])\n        },\n        {\n            \"X\": np.array([\n                [1., 5.], [1., 5.], [1., 10.]\n            ]),\n            \"y\": np.array([0, 1, 1]),\n            \"Q\": np.array([\n                [100., 7.], [100., 5.], [100., 9.]\n            ])\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        X, y, Q = case[\"X\"], case[\"y\"], case[\"Q\"]\n        \n        # Compute stats for Z-score normalization.\n        # np.std with default ddof=0 computes the population standard deviation.\n        sigma = np.std(X, axis=0)\n        \n        # Compute stats for Min-Max normalization.\n        m = np.min(X, axis=0)\n        M = np.max(X, axis=0)\n        r = M - m\n        \n        # Create scales (weights) for distances, handling zero variance/range.\n        # The scale is 1/sigma or 1/r. If the divisor is 0, the scale is 0.\n        # A small epsilon is used for robust floating point comparison.\n        scales_z = np.zeros_like(sigma)\n        valid_sigma_mask = sigma > 1e-12\n        scales_z[valid_sigma_mask] = 1.0 / sigma[valid_sigma_mask]\n        \n        scales_mm = np.zeros_like(r)\n        valid_r_mask = r > 1e-12\n        scales_mm[valid_r_mask] = 1.0 / r[valid_r_mask]\n        \n        # Get predictions for both normalizations.\n        preds_z = one_nn_predict(Q, X, y, scales_z)\n        preds_mm = one_nn_predict(Q, X, y, scales_mm)\n        \n        # Calculate the fraction of queries with agreeing predictions.\n        agreement_count = np.sum(np.array(preds_z) == np.array(preds_mm))\n        agreement_fraction = agreement_count / len(Q)\n        \n        # Format the result for this test case as specified.\n        case_result = [\n            round(agreement_fraction, 3),\n            preds_z,\n            preds_mm\n        ]\n        results.append(case_result)\n\n    # The problem provides a skeleton print statement, which implies that\n    # Python's default string representation of lists is the desired format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在选择假设空间时，我们面临着一个关于偏置与方差之间根本性的权衡。一个简单的模型（对应较小的假设空间）可能具有高偏置但低方差，而一个复杂的模型（对应较大的假设空间）则可能偏置较低但方差较高。这项动手模拟任务将要求你为两个嵌套模型（一个简单，一个复杂）生成学习曲线，从而直观地展示这一权衡，并理解最优模型的选择为何严重依赖于可用训练数据的数量。",
            "id": "3129988",
            "problem": "您的任务是设计并实现一个规范的模拟，用于在有限样本量的情况下，比较监督学习中的两个假设空间，并通过学习曲线分析偏差-方差权衡。具体设定如下。设输入为 $\\mathbf{x} = (x_1, x_2)$，其中 $x_1$ 和 $x_2$ 是从区间 $[-1,1]$ 上的均匀分布中独立同分布（i.i.d.）地抽取的。真实回归函数为\n$$\nf^\\star(\\mathbf{x}) \\;=\\; \\beta_0 \\;+\\; \\beta_1 x_1 \\;+\\; \\beta_2 x_2 \\;+\\; \\beta_{12} x_1 x_2,\n$$\n观测到的输出为\n$$\ny \\;=\\; f^\\star(\\mathbf{x}) \\;+\\; \\varepsilon,\n$$\n其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 是方差为 $\\sigma^2$ 的独立高斯噪声。考虑以下两个用于线性最小二乘法的假设空间（函数集合）：\n- 不含交互项的加性假设空间，\n$$\n\\mathcal{H}_{\\text{add}} \\;=\\; \\left\\{ f(\\mathbf{x}) \\;=\\; \\theta_0 \\;+\\; \\theta_1 x_1 \\;+\\; \\theta_2 x_2 \\right\\},\n$$\n- 包含交互项的交互假设空间，\n$$\n\\mathcal{H}_{\\text{int}} \\;=\\; \\left\\{ f(\\mathbf{x}) \\;=\\; \\theta_0 \\;+\\; \\theta_1 x_1 \\;+\\; \\theta_2 x_2 \\;+\\; \\theta_{12} x_1 x_2 \\right\\}。\n$$\n您的程序必须模拟学习曲线，并将误差分解为偏差和方差，作为训练样本量 $n \\in \\{8,32,128\\}$ 的函数。对于每个固定的 $n$，在 $R$ 次独立重复实验中进行训练，其中 $R=200$，每次重复实验使用从上述数据生成过程中抽取的 $n$ 个 i.i.d. 样本 $\\mathbf{x}$ 和 $y$。评估时，使用一个大小为 $M=512$ 的固定测试集，该测试集由来自相同分布的 i.i.d. $\\mathbf{x}$ 组成，并通过偏差-方差分解来评估期望泛化误差。\n\n从核心定义开始：对于一个学习到的预测器 $\\hat{f}$，在平方损失下，给定 $\\mathbf{x}$ 时的期望平方预测误差为\n$$\n\\mathbb{E}\\!\\left[(\\hat{f}(\\mathbf{x}) - y)^2 \\mid \\mathbf{x}\\right] \\;=\\; \\left(\\mathbb{E}[\\hat{f}(\\mathbf{x})] - f^\\star(\\mathbf{x})\\right)^2 \\;+\\; \\mathrm{Var}(\\hat{f}(\\mathbf{x})) \\;+\\; \\sigma^2,\n$$\n这里的期望和方差是针对随机训练样本（以及任何算法随机性）计算的。样本量为 $n$ 时的学习曲线是该量值在 $\\mathbf{x}$ 的测试分布上的平均值。在您的模拟中，通过在 $R$ 次重复实验和 $M$ 个测试输入上进行蒙特卡洛平均来近似这些期望。\n\n对于每个测试用例，计算 $\\mathcal{H}_{\\text{add}}$ 和 $\\mathcal{H}_{\\text{int}}$ 的学习曲线，然后报告使得交互假设空间的泛化误差小于或等于加性假设空间的泛化误差的最小训练样本量 $n$（从给定的集合中选取）。如果对于给定的 $n$ 值没有出现这种交叉，则该测试用例报告 $0$。\n\n使用以下参数值的测试套件，其中所有未明确列出的参数均固定为 $\\beta_0 = 0$、$\\beta_1 = 1$ 和 $\\beta_2 = 1$：\n- 测试用例 1：$\\beta_{12} = 0.8$, $\\sigma^2 = 0.05$\n- 测试用例 2：$\\beta_{12} = 0.8$, $\\sigma^2 = 1.0$\n- 测试用例 3：$\\beta_{12} = 0.0$, $\\sigma^2 = 0.05$\n\n您的程序必须：\n- 对于每个测试用例，模拟并估计在 $n \\in \\{8,32,128\\}$ 时两个假设空间的学习曲线，\n- 使用 $R=200$ 次训练重复实验和一个大小为 $M=512$ 的固定测试集进行蒙特卡洛近似，\n- 对于每个测试用例，返回一个整数：使得交互假设空间的估计泛化误差小于或等于加性假设空间的估计泛化误差的最小 $n$ 值，如果没有发生交叉则返回 $0$。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须为每个测试用例包含一个整数，并按上述顺序列出。",
            "solution": "该问题要求进行数值模拟，以比较两个嵌套线性模型（一个加性模型 $\\mathcal{H}_{\\text{add}}$ 和一个包含交互项的模型 $\\mathcal{H}_{\\text{int}}$）的泛化性能。比较是在偏差-方差权衡的背景下进行的，性能是作为训练样本量 $n$ 的函数来评估的。目标是针对不同的数据生成参数，确定更复杂的模型 $\\mathcal{H}_{\\text{int}}$ 达到小于或等于更简单模型 $\\mathcal{H}_{\\text{add}}$ 的泛化误差所需的最小样本量。\n\n解决方案的核心是一个旨在估计期望泛化误差的蒙特卡洛模拟。对于一个学习到的模型 $\\hat{f}$，在特定输入 $\\mathbf{x}$ 处的期望平方预测误差可以分解为三个部分：\n$$\n\\mathbb{E}_{\\mathcal{D}, \\varepsilon}\\left[(\\hat{f}(\\mathbf{x}) - y)^2 \\mid \\mathbf{x}\\right] \\;=\\; \\underbrace{\\left(\\mathbb{E}_{\\mathcal{D}}[\\hat{f}(\\mathbf{x})] - f^\\star(\\mathbf{x})\\right)^2}_{\\text{偏差平方}} \\;+\\; \\underbrace{\\mathbb{E}_{\\mathcal{D}}\\left[\\left(\\hat{f}(\\mathbf{x}) - \\mathbb{E}_{\\mathcal{D}}[\\hat{f}(\\mathbf{x})]\\right)^2\\right]}_{\\text{方差}} \\;+\\; \\underbrace{\\sigma^2}_{\\text{不可约误差}}\n$$\n这里的期望 $\\mathbb{E}_{\\mathcal{D}}$ 是对固定大小为 $n$ 的训练数据集 $\\mathcal{D}$ 的分布进行计算的。总泛化误差是该量值在测试输入 $\\mathbf{x}$ 的分布上的期望。我们的模拟通过对大量抽样取平均来近似这些期望。\n\n模拟过程如下：\n\n首先，我们建立一个固定的测试集，以确保一致的评估基准。生成一组 $M=512$ 个输入向量 $\\{\\mathbf{x}^{(i)}\\}_{i=1}^M$，其中每个 $\\mathbf{x}^{(i)} = (x_1^{(i)}, x_2^{(i)})$ 的分量都是从 $\\mathcal{U}[-1, 1]$ 中独立抽取的。对于这些测试点，我们使用真实函数 $f^\\star(\\mathbf{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_1 x_2$ 以及每个测试用例指定的参数来计算真实的、无噪声的函数值 $f^\\star(\\mathbf{x}^{(i)})$。\n\n接下来，对于每个训练样本量 $n \\in \\{8, 32, 128\\}$，我们进行 $R=200$ 次独立的训练重复实验。在每次重复实验 $r \\in \\{1, \\dots, R\\}$ 中：\n1.  生成一个新的大小为 $n$ 的训练数据集 $\\mathcal{D}_r$。输入 $\\{\\mathbf{x}_j\\}_{j=1}^n$ 从 $\\mathcal{U}[-1, 1] \\times \\mathcal{U}[-1, 1]$ 中独立同分布地抽取。相应的输出 $\\{y_j\\}_{j=1}^n$ 计算为 $y_j = f^\\star(\\mathbf{x}_j) + \\varepsilon_j$，其中 $\\varepsilon_j \\sim \\mathcal{N}(0, \\sigma^2)$。\n2.  将两个模型拟合到训练数据 $\\mathcal{D}_r$：一个来自 $\\mathcal{H}_{\\text{add}}$，另一个来自 $\\mathcal{H}_{\\text{int}}$。这通过普通最小二乘法完成，该方法寻找使残差平方和最小化的参数向量 $\\hat{\\theta}$。对于设计矩阵为 $X$、目标向量为 $y$ 的模型，解为 $\\hat{\\theta} = (X^T X)^{-1} X^T y$。在数值上，最好使用稳定的方法来计算，例如 `numpy.linalg.lstsq` 中实现的奇异值分解（SVD）。\n    -   对于 $\\mathcal{H}_{\\text{add}}$，设计矩阵的列对应于截距项、$x_1$ 和 $x_2$。\n    -   对于 $\\mathcal{H}_{\\text{int}}$，设计矩阵额外增加一列用于交互项 $x_1 x_2$。\n3.  然后，将这两个拟合后的模型（我们称之为 $\\hat{f}_{\\text{add}, r}$ 和 $\\hat{f}_{\\text{int}, r}$）用于对 $M$ 个固定测试点进行预测。这将产生两个预测向量 $\\hat{y}_{\\text{add}, r}$ 和 $\\hat{y}_{\\text{int}, r}$，并将其存储起来。\n\n在完成给定 $n$ 的所有 $R=200$ 次重复实验后，对于两个假设空间中的每一个，我们都为 $M$ 个测试点中的每一个点获得了 $R$ 个预测值。现在我们可以近似偏差和方差项。对于每个测试点 $\\mathbf{x}^{(i)}$ 和每个模型类别（例如 'add'），我们执行以下计算：\n-   所有重复实验中的平均预测值，$\\bar{f}_{\\text{add}}(\\mathbf{x}^{(i)}) = \\frac{1}{R} \\sum_{r=1}^R \\hat{f}_{\\text{add}, r}(\\mathbf{x}^{(i)})$，近似于 $\\mathbb{E}_{\\mathcal{D}}[\\hat{f}_{\\text{add}}(\\mathbf{x}^{(i)})]$。\n-   在 $\\mathbf{x}^{(i)}$ 处的偏差平方估计为 $(\\bar{f}_{\\text{add}}(\\mathbf{x}^{(i)}) - f^\\star(\\mathbf{x}^{(i)}))^2$。\n-   在 $\\mathbf{x}^{(i)}$ 处的方差估计为 $\\frac{1}{R} \\sum_{r=1}^R (\\hat{f}_{\\text{add}, r}(\\mathbf{x}^{(i)}) - \\bar{f}_{\\text{add}}(\\mathbf{x}^{(i)}))^2$。\n\n因此，模型的总泛化误差是三个部分的和：在 $M$ 个测试点上估计的偏差平方的平均值，在 $M$ 个测试点上估计的方差的平均值，以及不可约误差 $\\sigma^2$。\n\n对每个训练样本量 $n$ 重复此整个过程。最后，通过比较在每个 $n$ 处计算出的 $\\mathcal{H}_{\\text{add}}$ 和 $\\mathcal{H}_{\\text{int}}$ 的泛化误差，我们找出满足 $\\text{Error}(\\mathcal{H}_{\\text{int}}) \\le \\text{Error}(\\mathcal{H}_{\\text{add}})$ 的最小 $n$ 值。如果对于任何指定的 $n$ 值都不满足此条件，则该测试用例的结果为 $0$。此过程应用于三个测试用例中的每一个，这些测试用例通过改变真实参数 $\\beta_{12}$ 和噪声方差 $\\sigma^2$ 来展示偏差-方差权衡的不同情景。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # (beta_12, sigma_sq)\n        (0.8, 0.05),\n        (0.8, 1.0),\n        (0.0, 0.05),\n    ]\n\n    # Fixed parameters from problem statement\n    base_params = {'beta0': 0.0, 'beta1': 1.0, 'beta2': 1.0}\n    n_values = [8, 32, 128]\n    R = 200\n    M = 512\n\n    results = []\n    for beta_12, sigma_sq in test_cases:\n        params = base_params.copy()\n        params['beta_12'] = beta_12\n        params['sigma_sq'] = sigma_sq\n        \n        crossover_n = simulate_learning_curves(params, n_values, R, M)\n        results.append(crossover_n)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef simulate_learning_curves(params, n_values, R, M):\n    \"\"\"\n    Simulates learning curves for one set of parameters.\n\n    Args:\n        params (dict): Dictionary of parameters (beta0, beta1, beta2, beta_12, sigma_sq).\n        n_values (list): List of training sample sizes to test.\n        R (int): Number of training replicates.\n        M (int): Size of the fixed test set.\n\n    Returns:\n        int: The smallest n at which the interaction model's error is less than\n             or equal to the additive model's error, or 0 if no crossover occurs.\n    \"\"\"\n    # Use a fixed seed for reproducibility of the simulation.\n    np.random.seed(42)\n\n    beta_star = np.array([params['beta0'], params['beta1'], params['beta2'], params['beta_12']])\n    sigma_sq = params['sigma_sq']\n    sigma = np.sqrt(sigma_sq)\n\n    # 1. Generate a fixed test set\n    x_test_raw = np.random.uniform(-1, 1, size=(M, 2))\n    x1_test, x2_test = x_test_raw[:, 0], x_test_raw[:, 1]\n    \n    # Design matrices for the test set\n    X_test_add = np.c_[np.ones(M), x1_test, x2_test]\n    X_test_int = np.c_[X_test_add, x1_test * x2_test]\n    \n    # True function values on the test set\n    f_star_test = X_test_int @ beta_star\n\n    errors = {n: {} for n in n_values}\n\n    # 2. Iterate through training sizes\n    for n in n_values:\n        # Storage for predictions from all R replicates for the current n\n        preds_add = np.zeros((M, R))\n        preds_int = np.zeros((M, R))\n\n        # 3. Loop over R replicates\n        for r in range(R):\n            # a. Generate training data\n            x_train_raw = np.random.uniform(-1, 1, size=(n, 2))\n            x1_train, x2_train = x_train_raw[:, 0], x_train_raw[:, 1]\n            \n            X_train_add = np.c_[np.ones(n), x1_train, x2_train]\n            X_train_int = np.c_[X_train_add, x1_train * x2_train]\n\n            f_star_train = X_train_int @ beta_star\n            noise = np.random.normal(0, sigma, size=n)\n            y_train = f_star_train + noise\n            \n            # b. Fit models using linear least squares\n            theta_add, _, _, _ = np.linalg.lstsq(X_train_add, y_train, rcond=None)\n            theta_int, _, _, _ = np.linalg.lstsq(X_train_int, y_train, rcond=None)\n\n            # c. Make and store predictions on the test set\n            preds_add[:, r] = X_test_add @ theta_add\n            preds_int[:, r] = X_test_int @ theta_int\n\n        # 4. Calculate bias-squared, variance, and total generalization error\n        # For the additive model\n        E_f_hat_add = np.mean(preds_add, axis=1)\n        bias_sq_add = (E_f_hat_add - f_star_test)**2\n        var_add = np.var(preds_add, axis=1) # ddof=0 is default, correct for population var over replicates\n        total_err_add = np.mean(bias_sq_add) + np.mean(var_add) + sigma_sq\n        errors[n]['add'] = total_err_add\n        \n        # For the interaction model\n        E_f_hat_int = np.mean(preds_int, axis=1)\n        bias_sq_int = (E_f_hat_int - f_star_test)**2\n        var_int = np.var(preds_int, axis=1)\n        total_err_int = np.mean(bias_sq_int) + np.mean(var_int) + sigma_sq\n        errors[n]['int'] = total_err_int\n\n    # 5. Find the crossover point\n    for n in sorted(n_values):\n        if errors[n]['int'] = errors[n]['add']:\n            return n\n    \n    return 0\n\nsolve()\n```"
        },
        {
            "introduction": "在实践中，我们常常需要从多个候选模型或假设空间中挑选出最佳的一个。然而，如果选择过程不严谨，其本身就会引入一种偏置，导致对模型性能的评估过于乐观。这最后一个练习通过一个思想实验来分析因“偷看”验证集来选择模型而产生的选择偏置，为我们揭示了遵循正确验证流程（如嵌套交叉验证）的至关重要性。",
            "id": "3130063",
            "problem": "一个输入-输出对的数据集从一个未知分布 $\\mathcal{D}$ 中独立同分布 (i.i.d.) 地抽取。对于一个假设 $h$ 和一个损失函数 $L$，定义泛化风险为 $R(h) = \\mathbb{E}_{(X,Y) \\sim \\mathcal{D}}[L(h(X),Y)]$。通过从 $\\mathcal{D}$ 中进行独立同分布采样，形成一个大小为 $n$ 的验证集 $V$，并且 $h$ 的经验验证风险为 $\\hat{R}_V(h) = \\frac{1}{n}\\sum_{(x_i,y_i)\\in V} L(h(x_i),y_i)$。考虑 $K$ 个候选假设空间 $\\{\\mathcal{H}_k\\}_{k=1}^K$。对于每个 $k \\in \\{1,\\dots,K\\}$，一个在独立训练集上训练的学习算法会产生一个假设 $h_k \\in \\mathcal{H}_k$。\n\n假设对于每个固定的 $k$，验证估计量 $\\hat{R}_V(h_k)$ 是 $R(h_k)$ 的一个近似无偏估计量，其抽样波动根据中心极限定理可以建模为 $\\hat{R}_V(h_k) = R(h_k) + \\varepsilon_k$，其中 $\\varepsilon_k \\overset{\\text{approx}}{\\sim} \\mathcal{N}(0, \\sigma^2/n)$ 并且 $\\{\\varepsilon_k\\}_{k=1}^K$ 在 $k$ 之间近似独立。\n\n我们比较两种选择协议：\n- 协议 I（预先指定）：在查看 $V$ 之前选择单个假设空间 $\\mathcal{H}$，训练一个假设 $h \\in \\mathcal{H}$，并报告 $\\hat{R}_V(h)$。\n- 协议 II（基于“偷窥”的选择）：对于 $K$ 个已训练的假设 $\\{h_k\\}$，在观察 $V$ 之后选择 $k^\\star \\in \\arg\\min_{k} \\hat{R}_V(h_k)$，并报告 $\\hat{R}_V(h_{k^\\star})$。\n\n分析协议 II 中基于“偷窥”的选择如何对验证性能产生隐式的归纳偏置，并如何影响所报告的验证风险中的乐观度。选择所有正确的陈述。\n\nA. 在协议 II 中，根据上述高斯噪声模型且所有 $k$ 的方差相等的情况下，期望乐观度 $\\mathbb{E}[\\hat{R}_V(h_{k^\\star}) - R(h_{k^\\star})]$ 为负，并且随着 $K$ 的增加，其量级以 $\\sigma \\sqrt{2\\ln K}/\\sqrt{n}$ 的阶数增长。\n\nB. 在协议 I 中，如果 $h$ 是独立于 $V$ 固定的，那么验证风险是 $h$ 的泛化风险的无偏估计量：$\\mathbb{E}[\\hat{R}_V(h)] = R(h)$。\n\nC. “偷窥” $V$ 来选择假设空间 $\\mathcal{H}_k$ 会增加每个 $\\mathcal{H}_k$ 的 Vapnik–Chervonenkis (VC) 维 $d$，从而无论 $K$ 和 $n$ 为何值，都保证了更大的泛化风险 $R(h_{k^\\star})$。\n\nD. 嵌套 k 折交叉验证 (CV) 使用内循环选择 $k^\\star$，并使用外循环在未用于选择的留出折上估计性能，在独立同分布采样假设下，它能得出对 $R(h)$ 的近似无偏估计。\n\nE. 在协议 II 中，增加验证集大小 $n$ 会增加 $\\hat{R}_V(h_{k^\\star})$ 相对于 $R(h_{k^\\star})$ 的期望乐观度（向下偏差）。",
            "solution": "首先对问题陈述进行验证。\n\n### 步骤 1：提取已知信息\n- 一个数据集从一个未知分布 $\\mathcal{D}$ 中独立同分布 (i.i.d.) 地抽取。\n- $h$ 是一个假设。\n- $L$ 是一个损失函数。\n- 泛化风险：$R(h) = \\mathbb{E}_{(X,Y) \\sim \\mathcal{D}}[L(h(X),Y)]$。\n- 验证集 $V$ 的大小为 $n$，通过从 $\\mathcal{D}$ 中独立同分布采样形成。\n- 经验验证风险：$\\hat{R}_V(h) = \\frac{1}{n}\\sum_{(x_i,y_i)\\in V} L(h(x_i),y_i)$。\n- 有 $K$ 个候选假设空间：$\\{\\mathcal{H}_k\\}_{k=1}^K$。\n- 对于每个 $k \\in \\{1,\\dots,K\\}$，一个在独立训练集上训练的学习算法产生一个假设 $h_k \\in \\mathcal{H}_k$。\n- 假设：对于每个固定的 $k$，$\\hat{R}_V(h_k)$ 是 $R(h_k)$ 的一个近似无偏估计量。\n- 假设：抽样波动被建模为 $\\hat{R}_V(h_k) = R(h_k) + \\varepsilon_k$。\n- 假设：$\\varepsilon_k \\overset{\\text{approx}}{\\sim} \\mathcal{N}(0, \\sigma^2/n)$。\n- 假设：随机变量 $\\{\\varepsilon_k\\}_{k=1}^K$ 在 $k$ 之间近似独立。\n- 协议 I：在查看 $V$ 之前选择单个假设空间 $\\mathcal{H}$，训练一个假设 $h \\in \\mathcal{H}$，并报告 $\\hat{R}_V(h)$。\n- 协议 II：对于 $K$ 个已训练的假设 $\\{h_k\\}$，在观察 $V$ 之后选择 $k^\\star \\in \\arg\\min_{k} \\hat{R}_V(h_k)$，并报告 $\\hat{R}_V(h_{k^\\star})$。\n\n### 步骤 2：使用提取的已知信息进行验证\n问题陈述具有科学依据、定义明确且客观。\n- **科学依据**：该问题是统计学习理论中的一个标准练习，涉及泛化风险、经验风险、模型选择和选择偏差等基本概念。对经验风险分布使用高斯近似，是中心极限定理应用于验证集上损失总和的直接结果，这是一种常见且有效的建模方法。\n- **定义明确**：该问题为场景提供了清晰和形式化的模型。所有术语都有明确定义，并且假设（独立同分布数据、高斯噪声、噪声项的独立性）都已明确说明，从而可以进行严格的数学分析。问题是具体的，并且可以在给定框架内回答。\n- **客观性**：语言精确且无偏见。协议的描述清晰明确。没有主观因素。\n- **缺陷清单**：该问题没有违反任何指定的无效标准。关于噪声项独立性和等方差的假设是简化的，但它们是此类理论分析中的标准做法，并不会使问题无效；它们定义了进行分析的上下文。\n\n### 步骤 3：结论与行动\n问题是**有效的**。开始解答。\n\n---\n\n该问题要求评估关于两种模型评估协议的统计特性的几个陈述。核心问题是使用同一个验证集来选择模型并估计其性能所引入的偏差。\n\n### 协议 II 分析\n在协议 II 中，选择的假设是 $h_{k^\\star}$，其中 $k^\\star = \\arg\\min_{k \\in \\{1, \\dots, K\\}} \\hat{R}_V(h_k)$。我们关心的是乐观度，其定义为报告的风险与所选模型的真实风险之间的期望差异。这个量是 $\\mathbb{E}[\\hat{R}_V(h_{k^\\star}) - R(h_{k^\\star})]$。期望是针对验证集 $V$ 的随机性计算的。\n\n使用给定的模型 $\\hat{R}_V(h_k) = R(h_k) + \\varepsilon_k$，其中 $\\varepsilon_k \\sim \\mathcal{N}(0, \\sigma^2/n)$。乐观度可以重写为：\n$$\n\\mathbb{E}[\\hat{R}_V(h_{k^\\star}) - R(h_{k^\\star})] = \\mathbb{E}[(R(h_{k^\\star}) + \\varepsilon_{k^\\star}) - R(h_{k^\\star})] = \\mathbb{E}[\\varepsilon_{k^\\star}]\n$$\n索引 $k^\\star$ 是一个依赖于所有 $\\varepsilon_k$ 值的随机变量：\n$$\nk^\\star = \\arg\\min_{k} (R(h_k) + \\varepsilon_k)\n$$\n因此，乐观度是与获胜假设相对应的噪声项的期望。由于我们选择的是观测风险 $\\hat{R}_V(h_k)$ 的最小值，我们隐含地偏向于那些噪声项 $\\varepsilon_k$ 恰好很小（即为负）的假设。这导致了乐观偏差，意味着期望乐观度为负。\n\n### 逐项分析\n\n**A. 在协议 II 中，根据上述高斯噪声模型且所有 $k$ 的方差相等的情况下，期望乐观度 $\\mathbb{E}[\\hat{R}_V(h_{k^\\star}) - R(h_{k^\\star})]$ 为负，并且随着 $K$ 的增加，其量级以 $\\sigma \\sqrt{2\\ln K}/\\sqrt{n}$ 的阶数增长。**\n\n为了分析其缩放规律，我们考虑一个简化但有说明性的案例，即所有真实风险都相等：$R(h_k) = R_0$ 对于所有 $k \\in \\{1, \\dots, K\\}$。在这种情况下，选择完全由噪声驱动：\n$$\nk^\\star = \\arg\\min_{k} (R_0 + \\varepsilon_k) = \\arg\\min_{k} \\varepsilon_k\n$$\n乐观度为 $\\mathbb{E}[\\min_{k=1,\\dots,K} \\varepsilon_k]$。变量 $\\varepsilon_k$ 是从 $\\mathcal{N}(0, \\sigma^2/n)$ 中抽取的独立同分布样本。令 $\\sigma_{\\text{eff}} = \\sigma/\\sqrt{n}$。问题简化为求 $K$ 个均值为 $0$、标准差为 $\\sigma_{\\text{eff}}$ 的独立同分布高斯随机变量的最小值的期望。\n对于 $Z_k \\sim \\mathcal{N}(0, 1)$，根据极值理论的一个已知结果，对于大的 $K$，期望的最小值近似为 $\\mathbb{E}[\\min_{k=1,\\dots,K} Z_k] \\approx -\\sqrt{2 \\ln K}$。\n由于 $\\varepsilon_k = \\sigma_{\\text{eff}} Z_k$，根据期望的线性性质：\n$$\n\\mathbb{E}[\\min_k \\varepsilon_k] = \\sigma_{\\text{eff}} \\mathbb{E}[\\min_k Z_k] \\approx -\\frac{\\sigma}{\\sqrt{n}} \\sqrt{2 \\ln K}\n$$\n如预测的那样，期望乐观度为负。其量级约为 $\\frac{\\sigma \\sqrt{2\\ln K}}{\\sqrt{n}}$。这个量级随着 $K$ 以 $\\sqrt{\\ln K}$ 的形式增长，并如陈述所述，随着 $\\sigma$ 和 $1/\\sqrt{n}$ 增长。该陈述准确地描述了偏差的符号及其随 $K$ 和 $n$ 的渐近缩放规律。即使当 $R(h_k)$ 不全相等时，这种效应仍然存在，并且这种缩放规律很好地刻画了选择偏差。\n\n结论：**正确**。\n\n**B. 在协议 I 中，如果 $h$ 是独立于 $V$ 固定的，那么验证风险是 $h$ 的泛化风险的无偏估计量：$\\mathbb{E}[\\hat{R}_V(h)] = R(h)$。**\n\n在协议 I 中，假设 $h$ 的选择与验证集 $V$ 无关。因此，相对于验证集上的概率测度，$h$ 是固定的。经验验证风险的期望是针对 $V$ 的分布来计算的。\n$$\n\\mathbb{E}_V[\\hat{R}_V(h)] = \\mathbb{E}_V\\left[\\frac{1}{n} \\sum_{i=1}^n L(h(x_i), y_i)\\right]\n$$\n根据期望的线性性质：\n$$\n\\mathbb{E}_V[\\hat{R}_V(h)] = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}_V[L(h(x_i), y_i)]\n$$\n由于每个样本 $(x_i, y_i) \\in V$ 都是从分布 $\\mathcal{D}$ 中抽取的独立同分布样本，根据定义，任何单个样本损失的期望就是泛化风险 $R(h)$：\n$$\n\\mathbb{E}_V[L(h(x_i), y_i)] = \\mathbb{E}_{(X,Y) \\sim \\mathcal{D}}[L(h(X), Y)] = R(h)\n$$\n将此代入总和中：\n$$\n\\mathbb{E}_V[\\hat{R}_V(h)] = \\frac{1}{n} \\sum_{i=1}^n R(h) = \\frac{1}{n} \\cdot n \\cdot R(h) = R(h)\n$$\n该陈述是使用留出集进行评估的一个基本原则：如果该集合未用于影响模型的选择，则该集合上的经验风险是真实泛化风险的无偏估计量。\n\n结论：**正确**。\n\n**C. “偷窥” $V$ 来选择假设空间 $\\mathcal{H}_k$ 会增加每个 $\\mathcal{H}_k$ 的 Vapnik–Chervonenkis (VC) 维 $d$，从而无论 $K$ 和 $n$ 为何值，都保证了更大的泛化风险 $R(h_{k^\\star})$。**\n\n这个陈述包含两个主要的谬误。\n1. 假设空间 $\\mathcal{H}_k$ 的 VC 维 $d_k$ 是函数集 $\\mathcal{H}_k$ 的一个内在属性。它通过函数类打散点集的能力来衡量其复杂性。这个属性独立于任何数据集 $V$ 或任何用于从该类中选择假设的程序。协议 II 中的“偷窥”过程使用 $V$ 从假设 $\\{h_1, \\dots, h_K\\}$ 中进行选择，其中每个 $h_k$ 都已经是 $\\mathcal{H}_k$ 的一个元素。假设空间 $\\mathcal{H}_k$ 本身没有被修改，所以它们的 VC 维不会改变。\n2. “保证了更大的泛化风险 $R(h_{k^\\star})$” 这句话是错误的。协议 II 导致了对风险的乐观估计，即 $\\mathbb{E}[\\hat{R}_V(h_{k^\\star})]  R(h_{k^\\star})$（更严谨的陈述也应包括对训练集的平均，但乐观偏差是关键点）。它并不“保证”所选模型 $h_{k^\\star}$ 比其他某个模型更差。例如，完全有可能某个假设空间 $\\mathcal{H}_1$ 包含一个真正优秀模型 $h_1$，其 $R(h_1) \\ll R(h_k)$ 对所有 $k > 1$ 成立。在这种情况下，$\\hat{R}_V(h_1)$ 很有可能是最小值，从而导致 $k^\\star=1$。选择程序将正确地识别出最佳模型。问题在于报告的风险 $\\hat{R}_V(h_1)$ 可能是一个比典型估计值更幸运（更低）的值，而不是 $R(h_1)$ 被神奇地变大了。选择过程不会改变假设的真实风险。\n\n结论：**错误**。\n\n**D. 嵌套 k 折交叉验证 (CV) 使用内循环选择 $k^\\star$，并使用外循环在未用于选择的留出折上估计性能，在独立同分布采样假设下，它能得出对 $R(h)$ 的近似无偏估计。**\n\n嵌套交叉验证 (Nested CV) 是专门为减轻本问题中讨论的选择偏差而设计的程序。\n- 数据被划分为外层折。其中一折作为最终测试集（我们称之为 $T_{\\text{outer}}$）被留出，其余部分用于训练和选择 ($D_{\\text{outer-train}}$)。\n- 完全在 $D_{\\text{outer-train}}$ 上执行一个交叉验证的“内循环”，以选择最佳超参数（在本问题中是索引 $k$）。这是“偷窥”步骤，但它被限制在 $D_{\\text{outer-train}}$ 内。\n- 一旦找到最佳超参数 $k^\\star$，就在整个 $D_{\\text{outer-train}}$ 数据集上训练一个新模型 $h_{k^\\star}$。\n- 然后在留出的测试集 $T_{\\text{outer}}$ 上估计这个最终模型的性能。\n关键在于，$T_{\\text{outer}}$ 没有以任何方式用于选择 $k^\\star$。它作为整个模型构建流程（包括超参数选择）的真正独立的验证集。通过对所有外层折重复此过程并对结果进行平均，我们得到了该流程预期性能的估计。对于使用此程序训练的模型的泛化风险，该估计是近似无偏的。当涉及超参数调整时，这是性能估计的标准最佳实践。\n\n结论：**正确**。\n\n**E. 在协议 II 中，增加验证集大小 $n$ 会增加 $\\hat{R}_V(h_{k^\\star})$ 相对于 $R(h_{k^\\star})$ 的期望乐观度（向下偏差）。**\n\n术语“期望乐观度”指的是偏差 $\\mathbb{E}[\\hat{R}_V(h_{k^\\star}) - R(h_{k^\\star})]$，它是一个负值。“向下偏差”是其量级。如在选项 A 的分析中推导出的，该偏差的量级在 $\\frac{\\sigma \\sqrt{2 \\ln K}}{\\sqrt{n}}$ 的阶数上。\n这个表达式显示了偏差的量级如何依赖于验证集大小 $n$。项 $\\sqrt{n}$ 位于分母中。因此，随着 $n$ 的增加，分母增加，整个分数值*减小*。\n这意味着增加验证集的大小会*减小*选择偏差。这是符合直觉的：一个更大的验证集提供了更准确的经验风险估计 $\\hat{R}_V(h_k)$，因为估计量的方差 $\\sigma^2/n$ 减小了。估计中的噪声越小，最小值的选择就越不容易受到大的负向随机波动的影响，最终报告的风险也就越接近所选模型真实风险的无偏估计。该陈述的说法正好相反。\n\n结论：**错误**。",
            "answer": "$$\\boxed{ABD}$$"
        }
    ]
}