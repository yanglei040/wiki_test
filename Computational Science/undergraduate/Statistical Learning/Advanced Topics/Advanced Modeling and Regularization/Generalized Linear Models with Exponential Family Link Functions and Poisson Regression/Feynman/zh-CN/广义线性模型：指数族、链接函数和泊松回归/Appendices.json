{
    "hands_on_practices": [
        {
            "introduction": "理论模型的优雅简洁常常需要在现实数据的检验中得到确认。泊松回归的一个核心假设是方差等于均值，但在实际应用中，数据常表现出比理论预测更大的变异性，即“过度离势”。本练习将指导您推导并使用皮尔逊残差（Pearson residuals），这是一种标准化的度量，用于诊断模型的方差设定是否恰当，是模型验证流程中的基本功。",
            "id": "3124037",
            "problem": "一个实验室研究在固定时间窗口内自发细胞事件的计数。这些计数使用广义线性模型（GLM）进行建模，该模型适用于泊松分布，并采用规范对数连接函数。假设响应变量 $Y_{i}$ 条件独立，且每个变量都服从均值为 $\\mu_{i}$ 的泊松分布。\n\n1) 从指数族形式和 GLM 方差函数出发，推导泊松 GLM 的 Pearson 残差，用 $y_{i}$ 和 $\\mu_{i}$ 表示。您的推导必须从指数族的表示开始，然后通过确定方差函数来进行。\n\n2) 解释在此设置下 Pearson 残差的含义，并描述在残差对拟合值图中，什么样的定性模式可以诊断出相对于泊松方差假设的方差失配。请明确说明过度离散或离散不足会如何表现。\n\n3) 进行了一项简单的研究，包含 $n=6$ 个独立观测值和一个协变量 $x_{i}\\in\\{0,1,2,3,4,5\\}$。拟合了一个带对数连接的泊松 GLM，得到的估计系数为 $\\hat{\\beta}_{0}=1$ 和 $\\hat{\\beta}_{1}=0.25$，因此拟合均值为 $\\hat{\\mu}_{i}=\\exp\\big(\\hat{\\beta}_{0}+\\hat{\\beta}_{1}x_{i}\\big)$。观测到的计数为\n- 对于 $x_{1}=0$，$y_{1}=1$，\n- 对于 $x_{2}=1$，$y_{2}=6$，\n- 对于 $x_{3}=2$，$y_{3}=2$，\n- 对于 $x_{4}=3$，$y_{4}=10$，\n- 对于 $x_{5}=4$，$y_{5}=9$，\n- 对于 $x_{6}=5$，$y_{6}=13$。\n\n计算 Pearson 离散估计量\n$$\n\\hat{\\phi}_{P}\\;=\\;\\frac{1}{n-p}\\sum_{i=1}^{n} r_{i}^{2},\n$$\n其中 $r_{i}$ 是您在第 (1) 部分中推导出的 Pearson 残差，$p=2$ 是拟合系数的数量（截距和斜率）。报告 $\\hat{\\phi}_{P}$ 的数值。将您的答案四舍五入到四位有效数字。不要包含单位。",
            "solution": "我们从指数族的基本性质和广义线性模型（GLM）的结构入手。\n\n1) 泊松 GLM 的 Pearson 残差推导。\n\n单参数指数族的密度函数形式为\n$$\nf(y\\mid \\theta,\\phi)\\;=\\;\\exp\\left(\\frac{y\\theta-b(\\theta)}{a(\\phi)}+c(y,\\phi)\\right),\n$$\n其中 $\\theta$ 是规范参数，$\\phi$ 是尺度（离散）参数，而 $a(\\cdot)$、$b(\\cdot)$、$c(\\cdot)$ 是已知函数。指数族的基本性质得出\n$$\n\\mathbb{E}[Y]\\;=\\;b'(\\theta),\\qquad \\operatorname{Var}(Y)\\;=\\;a(\\phi)\\,b''(\\theta).\n$$\n在 GLM 中，我们通过一个连接函数 $g(\\mu)=\\eta=x^{\\top}\\beta$ 将均值 $\\mu=\\mathbb{E}[Y]$ 与预测变量联系起来，并将方差写成\n$$\n\\operatorname{Var}(Y)\\;=\\;\\phi\\,V(\\mu),\n$$\n的形式，其中 $V(\\mu)$ 是方差函数。\n\n对于泊松分布，其概率质量函数为\n$$\n\\mathbb{P}(Y=y)\\;=\\;\\exp\\big(y\\ln\\mu - \\mu - \\ln(y!)\\big),\n$$\n因此，在规范形式下，我们可以取 $\\theta=\\ln\\mu$，$a(\\phi)=1$，$b(\\theta)=\\exp(\\theta)$，以及 $c(y,\\phi)=-\\ln(y!)$。那么\n$$\nb'(\\theta)\\;=\\;\\exp(\\theta)\\;=\\;\\mu,\\qquad b''(\\theta)\\;=\\;\\exp(\\theta)\\;=\\;\\mu,\n$$\n因此\n$$\n\\operatorname{Var}(Y)\\;=\\;a(\\phi)\\,b''(\\theta)\\;=\\;1\\cdot \\mu\\;=\\;\\mu.\n$$\n因此，泊松族的方差函数是 $V(\\mu)=\\mu$，并且根据泊松 GLM 的构造，离散度为 $\\phi=1$。\n\nPearson 残差定义为通过模型隐含的标准差标准化的原始残差，\n$$\nr_{i}\\;=\\;\\frac{y_{i}-\\mu_{i}}{\\sqrt{\\operatorname{Var}(Y_{i})}}\\;=\\;\\frac{y_{i}-\\mu_{i}}{\\sqrt{\\phi\\,V(\\mu_{i})}}.\n$$\n对于泊松情况，$\\phi=1$ 且 $V(\\mu_{i})=\\mu_{i}$，这具体化为\n$$\nr_{i}\\;=\\;\\frac{y_{i}-\\mu_{i}}{\\sqrt{\\mu_{i}}}.\n$$\n\n2) 方差失配的解释和残差对拟合值诊断。\n\n因为 $r_{i}$ 是通过模型隐含的标准差 $\\sqrt{\\mu_{i}}$ 来标准化偏差 $y_{i}-\\mu_{i}$ 的，所以在一个正确指定的泊松 GLM 中，如果样本量足够大且均值结构拟合良好，我们期望 $r_{i}$ 近似以 0 为中心，方差为 1，即\n$$\n\\mathbb{E}[r_{i}]\\approx 0,\\qquad \\operatorname{Var}(r_{i})\\approx 1,\n$$\n并且当其与拟合均值 $\\hat{\\mu}_{i}$（或线性预测值 $\\hat{\\eta}_{i}$）作图时，没有系统性模式。一个残差对拟合值图，如果显示 $r_{i}$ 的散布随着 $\\hat{\\mu}_{i}$ 的增加而增加（一个向上开口的漏斗形），则表明相对于泊松方差假设 $V(\\mu)=\\mu$ 存在过度离散；经验方差超过了均值，导致在较大的拟合值处残差的散布增大。相反，散布减小（一个收窄的漏斗形）表明存在离散不足，经验方差小于泊松均值。残差均值趋势中的系统性曲率表明均值结构指定错误，而纵向散布随 $\\hat{\\mu}_{i}$ 变化的系统性变化则表明方差失配。\n\n3) Pearson 离散估计量 $\\hat{\\phi}_{P}$ 的计算。\n\n给定 $n=6$，$p=2$，$\\hat{\\beta}_{0}=1$，$\\hat{\\beta}_{1}=0.25$，$x_{i}\\in\\{0,1,2,3,4,5\\}$，以及观测到的计数 $(y_{1},\\dots,y_{6})=(1,6,2,10,9,13)$。拟合均值为\n$$\n\\hat{\\mu}_{i}\\;=\\;\\exp\\big(\\hat{\\beta}_{0}+\\hat{\\beta}_{1}x_{i}\\big)\\;=\\;\\exp\\big(1+0.25\\,x_{i}\\big).\n$$\n记 $\\exp(1)=e$，拟合均值及其平方根为\n$$\n\\begin{aligned}\n\\hat{\\mu}_{1}=\\exp(1+0.25\\cdot 0)=\\exp(1)=e,\\quad \\sqrt{\\hat{\\mu}_{1}}=\\exp(0.5)=e^{1/2},\\\\\n\\hat{\\mu}_{2}=\\exp(1+0.25\\cdot 1)=\\exp(1.25),\\quad \\sqrt{\\hat{\\mu}_{2}}=\\exp(0.625),\\\\\n\\hat{\\mu}_{3}=\\exp(1+0.25\\cdot 2)=\\exp(1.5),\\quad \\sqrt{\\hat{\\mu}_{3}}=\\exp(0.75),\\\\\n\\hat{\\mu}_{4}=\\exp(1+0.25\\cdot 3)=\\exp(1.75),\\quad \\sqrt{\\hat{\\mu}_{4}}=\\exp(0.875),\\\\\n\\hat{\\mu}_{5}=\\exp(1+0.25\\cdot 4)=\\exp(2),\\quad \\sqrt{\\hat{\\mu}_{5}}=\\exp(1),\\\\\n\\hat{\\mu}_{6}=\\exp(1+0.25\\cdot 5)=\\exp(2.25),\\quad \\sqrt{\\hat{\\mu}_{6}}=\\exp(1.125).\n\\end{aligned}\n$$\nPearson 残差为 $r_{i}=(y_{i}-\\hat{\\mu}_{i})/\\sqrt{\\hat{\\mu}_{i}}$。在方便时使用精确的指数形式，并为最终计算进行数值评估：\n- 对于 $i=1$：$r_{1}=(1-e)/e^{1/2}=e^{-1/2}-e^{1/2}\\approx -1.042190611$。\n- 对于 $i=2$：$r_{2}=\\big(6-\\exp(1.25)\\big)/\\exp(0.625)\\approx 1.343391721$。\n- 对于 $i=3$：$r_{3}=\\big(2-\\exp(1.5)\\big)/\\exp(0.75)\\approx -1.172450069$。\n- 对于 $i=4$：$r_{4}=\\big(10-\\exp(1.75)\\big)/\\exp(0.875)\\approx 1.769745$。\n- 对于 $i=5$：$r_{5}=\\big(9-\\exp(2)\\big)/\\exp(1)=9/e-e\\approx 0.5926331421$。\n- 对于 $i=6$：$r_{6}=\\big(13-\\exp(2.25)\\big)/\\exp(1.125)\\approx 1.1402652$。\n\n现在用 $n-p=6-2=4$ 计算 Pearson 离散估计量：\n$$\n\\hat{\\phi}_{P}\\;=\\;\\frac{1}{4}\\sum_{i=1}^{6} r_{i}^{2}\\;\\approx\\;\\frac{1}{4}\\Big(1.042190611^{2}+1.343391721^{2}+1.172450069^{2}+1.769745^{2}+0.5926331421^{2}+1.1402652^{2}\\Big).\n$$\n计算平方和，\n$$\n\\sum_{i=1}^{6} r_{i}^{2}\\;\\approx\\;9.04892,\n$$\n所以\n$$\n\\hat{\\phi}_{P}\\;\\approx\\;\\frac{9.04892}{4}\\;=\\;2.26223.\n$$\n四舍五入到四位有效数字，该值为 $2.262$。该值显著超过 $1$，这与相对于泊松方差假设的过度离散是一致的，并且与残差对拟合值图中预期的向上开口的漏斗形相符。",
            "answer": "$$\\boxed{2.262}$$"
        },
        {
            "introduction": "除了方差假设，广义线性模型（GLM）的另一个基石是连接函数所定义的线性关系假设。如何验证预测变量和响应变量之间的函数形式是否被模型正确捕捉？本编程练习将引导您从第一性原理出发，实现并应用成分-残差图（component-plus-residual plot），这是一种强大的可视化诊断工具，专门用于检验模型中特定预测变量的线性假设。",
            "id": "3124117",
            "problem": "要求您从基本原理出发，为一个泊松广义线性模型 (GLM) 实现一个使用成分加残差图检验对数均值与预测变量之间线性关系的过程。您必须将您的方法建立在泊松分布的指数族表示以及使用对数连接函数的广义线性模型定义之上。您的实现必须是一个完整的程序，无需任何用户输入即可执行以下任务。\n\n设响应变量为一个计数变量 $Y \\in \\{0,1,2,\\dots\\}$，使得 $Y \\mid \\boldsymbol{x} \\sim \\text{Poisson}(\\mu)$，其中均值 $\\mu$ 满足 GLM 关系 $\\eta = g(\\mu) = \\log(\\mu)$ 且 $\\eta = \\boldsymbol{x}^{\\top}\\boldsymbol{\\beta}$，$\\boldsymbol{\\beta}$ 为系数向量。泊松分布属于指数族，其典则连接函数为对数函数，模型将通过迭代重加权最小二乘法进行估计，该方法源于指数族的得分方程和连接函数。在您的代码设计中，除了这些基本定义之外，您不得假定任何快捷公式。\n\n您的程序必须：\n\n- 从基本原理出发，仅使用线性代数以及指数族和 GLM 框架所隐含的定义，实现一个通过迭代重加权最小二乘法拟合的泊松 GLM（使用对数连接函数）。\n- 拟合模型后，通过为每个观测值 $i$ 计算一个适用于泊松对数连接模型的成分加残差纵坐标，为指定的预测变量 $x_j$ 构建成分加残差诊断。利用此诊断评估线性预测器与 $x_j$ 之间的关系是否为线性。\n- 通过拟合一个成分加残差纵坐标对 $1$、$x_j$ 和 $x_j^2$ 的普通最小二乘模型，来操作化线性度检验，并提取 $x_j^2$ 的系数。接近 $0$ 的值表示在 $x_j$ 上近似线性，而具有不可忽略量级的值表示存在曲率。\n- 对于下述每个测试用例，以浮点数形式输出估计的二次项系数。\n\n您必须使用以下测试套件，在每个案例中以指定的种子生成合成数据，以确保可复现性。在所有情况下，拟合的模型中都应包含一个截距项、目标预测变量 $x$ 和一个干扰预测变量 $w$（但不要在拟合的 GLM 中包含任何非线性项；非线性仅用于特定情况下的数据生成）。令 $\\boldsymbol{x}_i = (1, x_i, w_i)^{\\top}$，并令 $n$ 表示样本量。\n\n测试用例 A（理想情况，真实关系为线性）：\n- 样本量 $n = 1000$。\n- 设置系数 $\\beta_0 = 1.0$，$\\beta_1 = 0.5$，$\\beta_2 = -0.25$。\n- 使用随机种子 $12345$，独立地生成 $x_i \\sim \\text{Uniform}([-2,2])$ 和 $w_i \\sim \\mathcal{N}(0,1)$。\n- 使用 $\\eta_i = \\beta_0 + \\beta_1 x_i + \\beta_2 w_i$ 和 $\\mu_i = \\exp(\\eta_i)$ 生成响应，然后使用种子 $12345$ 生成 $Y_i \\sim \\text{Poisson}(\\mu_i)$。\n\n测试用例 B（在 $x$ 中存在可检测的曲率）：\n- 样本量 $n = 1000$。\n- 设置系数 $\\beta_0 = 1.0$，$\\beta_1 = 0.0$，$\\gamma = 0.6$，$\\beta_2 = -0.25$。\n- 使用随机种子 $23456$，独立地生成 $x_i \\sim \\text{Uniform}([-2,2])$ 和 $w_i \\sim \\mathcal{N}(0,1)$。\n- 使用 $\\eta_i = \\beta_0 + \\beta_1 x_i + \\gamma x_i^2 + \\beta_2 w_i$ 和 $\\mu_i = \\exp(\\eta_i)$ 生成响应，然后使用种子 $23456$ 生成 $Y_i \\sim \\text{Poisson}(\\mu_i)$。\n\n测试用例 C（边界情况：$x$ 无效应，仅与 $w$ 线性相关）：\n- 样本量 $n = 1000$。\n- 设置系数 $\\beta_0 = 1.0$，$\\beta_1 = 0.0$，$\\beta_2 = 0.2$。\n- 使用随机种子 $34567$，独立地生成 $x_i \\sim \\text{Uniform}([-2,2])$ 和 $w_i \\sim \\mathcal{N}(0,1)$。\n- 使用 $\\eta_i = \\beta_0 + \\beta_1 x_i + \\beta_2 w_i$ 和 $\\mu_i = \\exp(\\eta_i)$ 生成响应，然后使用种子 $34567$ 生成 $Y_i \\sim \\text{Poisson}(\\mu_i)$。\n\n对于每个测试用例，通过迭代重加权最小二乘法拟合仅含预测变量 $(1, x, w)$（无二次项）的泊松 GLM。然后，对于预测变量 $x$，计算一个适用于泊松对数连接模型的成分加残差纵坐标，并拟合该纵坐标对 $1$、$x$ 和 $x^2$ 的普通最小二乘回归。提取 $x^2$ 的估计系数。\n\n您的程序应生成单行输出，其中包含一个逗号分隔的列表，按顺序对应测试用例 A、B 和 C 的三个估计二次项系数，四舍五入至最多六位小数，并用方括号括起来。例如，输出必须形如 $[a,b,c]$，其中 $a$、$b$ 和 $c$ 是所要求的浮点数。\n\n不涉及任何物理单位或角度。所有输出均为无单位标注的纯数字。所有随机数生成必须严格遵循所述的种子。不允许任何外部输入，程序必须能按原样执行。",
            "solution": "用户要求实现一个统计诊断程序，以验证泊松广义线性模型 (GLM) 中的线性假设。这需要从基本原理出发构建模型拟合算法——迭代重加权最小二乘法 (IRLS)，然后构建并分析成分加残差 (CPR) 诊断。\n\n### 1. 泊松 GLM 及其指数族表示\n\n广义线性模型包含三个组成部分：随机部分（响应的分布）、系统部分（线性预测器）和连接函数。对于指定的泊松 GLM：\n\n*   **随机部分**：对于观测值 $i$，响应变量 $Y_i$ 假定遵循泊松分布，$Y_i \\sim \\text{Poisson}(\\mu_i)$，其中 $\\mu_i = E[Y_i]$。其概率质量函数 (PMF) 为 $P(Y_i=y_i) = \\frac{e^{-\\mu_i}\\mu_i^{y_i}}{y_i!}$。\n*   **系统部分**：线性预测器 $\\eta_i$ 是预测变量 $\\boldsymbol{x}_i$ 的线性函数，即 $\\eta_i = \\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta}$，其中 $\\boldsymbol{\\beta}$ 是系数向量。\n*   **连接函数**：连接函数 $g$ 将均值 $\\mu_i$ 与线性预测器 $\\eta_i$ 联系起来。问题指定对数作为连接函数，因此 $\\eta_i = g(\\mu_i) = \\log(\\mu_i)$。这意味着 $\\mu_i = \\exp(\\eta_i)$。\n\n泊松分布是指数族的一员。其概率质量函数可以表示为典则形式 $f(y|\\theta, \\phi) = \\exp\\left(\\frac{y\\theta - b(\\theta)}{a(\\phi)} + c(y, \\phi)\\right)$：\n$$P(Y=y;\\mu) = \\frac{\\mu^y e^{-\\mu}}{y!} = \\exp(y\\log(\\mu) - \\mu - \\log(y!))$$\n通过比较，我们确定以下部分：\n*   典则参数为 $\\theta = \\log(\\mu)$。\n*   $b(\\theta)$ 函数为 $\\mu = e^{\\theta}$。\n*   离散参数 $a(\\phi)$ 为 $1$。\n*   $c(y, \\phi) = -\\log(y!)$。\n\n典则连接函数是将典则参数与线性预测器等同的函数，即 $\\theta = \\eta$。对于泊松分布，这意味着 $\\log(\\mu) = \\eta$，这与指定的对数连接函数相匹配。\n\n### 2. 模型拟合：迭代重加权最小二乘法 (IRLS)\n\n系数 $\\boldsymbol{\\beta}$ 通过最大化对数似然函数来估计。$n$ 个独立观测值的对数似然函数为：\n$$l(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\log P(Y_i=y_i) = \\sum_{i=1}^n (y_i \\log(\\mu_i) - \\mu_i - \\log(y_i!))$$\n由于 $\\mu_i = \\exp(\\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta})$，估计方程（通过将 $l(\\boldsymbol{\\beta})$ 的梯度设为零得到）对于 $\\boldsymbol{\\beta}$ 是非线性的。我们使用一种基于牛顿-拉夫逊的算法来求解它们，该算法被称为费雪评分法或 IRLS。\n\n得分向量 $\\boldsymbol{U}(\\boldsymbol{\\beta})$（对数似然的梯度）为：\n$$\\boldsymbol{U}(\\boldsymbol{\\beta}) = \\frac{\\partial l}{\\partial \\boldsymbol{\\beta}} = \\sum_{i=1}^n \\frac{\\partial l_i}{\\partial \\mu_i} \\frac{\\partial \\mu_i}{\\partial \\eta_i} \\frac{\\partial \\eta_i}{\\partial \\boldsymbol{\\beta}} = \\sum_{i=1}^n \\left(\\frac{y_i - \\mu_i}{\\mu_i}\\right) (\\mu_i) (\\boldsymbol{x}_i) = \\sum_{i=1}^n (y_i-\\mu_i)\\boldsymbol{x}_i = \\boldsymbol{X}^{\\top}(\\boldsymbol{y}-\\boldsymbol{\\mu})$$\n海森矩阵 $\\boldsymbol{H}(\\boldsymbol{\\beta})$（二阶导数）为：\n$$\\boldsymbol{H}(\\boldsymbol{\\beta}) = \\frac{\\partial^2 l}{\\partial \\boldsymbol{\\beta} \\partial \\boldsymbol{\\beta}^{\\top}} = -\\sum_{i=1}^n \\mu_i \\boldsymbol{x}_i \\boldsymbol{x}_i^{\\top} = -\\boldsymbol{X}^{\\top}\\boldsymbol{W}\\boldsymbol{X}$$\n其中 $\\boldsymbol{W}$ 是一个对角矩阵，其对角元素为 $W_{ii} = \\mu_i$。费雪信息矩阵是 $\\boldsymbol{I}(\\boldsymbol{\\beta}) = -E[\\boldsymbol{H}(\\boldsymbol{\\beta})] = \\boldsymbol{X}^{\\top}\\boldsymbol{W}\\boldsymbol{X}$。\n\n在第 $t$ 次迭代时的牛顿-拉夫逊更新为：\n$$\\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} + \\boldsymbol{I}(\\boldsymbol{\\beta}^{(t)})^{-1} \\boldsymbol{U}(\\boldsymbol{\\beta}^{(t)}) = \\boldsymbol{\\beta}^{(t)} + (\\boldsymbol{X}^{\\top}\\boldsymbol{W}^{(t)}\\boldsymbol{X})^{-1} \\boldsymbol{X}^{\\top}(\\boldsymbol{y}-\\boldsymbol{\\mu}^{(t)})$$\n这可以重新排列成 IRLS 形式。我们定义一个“调整后”或“工作”响应向量 $\\boldsymbol{z}^{(t)}$：\n$$z_i^{(t)} = \\eta_i^{(t)} + (y_i - \\mu_i^{(t)})g'(\\mu_i^{(t)}) = \\eta_i^{(t)} + \\frac{y_i - \\mu_i^{(t)}}{\\mu_i^{(t)}}$$\n通过这个定义，$\\boldsymbol{\\beta}$ 的更新就变成了一个加权最小二乘问题的解：\n$$\\boldsymbol{\\beta}^{(t+1)} = (\\boldsymbol{X}^{\\top}\\boldsymbol{W}^{(t)}\\boldsymbol{X})^{-1}\\boldsymbol{X}^{\\top}\\boldsymbol{W}^{(t)}\\boldsymbol{z}^{(t)}$$\n算法流程如下：\n1.  初始化 $\\boldsymbol{\\beta}^{(0)}$，例如，设为 $\\boldsymbol{0}$。\n2.  对 $t=0, 1, 2, \\dots$ 进行迭代，直到收敛：\n    a. 计算 $\\boldsymbol{\\eta}^{(t)} = \\boldsymbol{X}\\boldsymbol{\\beta}^{(t)}$ 和 $\\boldsymbol{\\mu}^{(t)} = \\exp(\\boldsymbol{\\eta}^{(t)})$。\n    b. 计算权重 $W_{ii}^{(t)} = \\mu_i^{(t)}$ 和工作响应 $z_i^{(t)} = \\eta_i^{(t)} + (y_i - \\mu_i^{(t)})/\\mu_i^{(t)}$。\n    c. 求解加权最小二乘方程以得到 $\\boldsymbol{\\beta}^{(t+1)}$。\n3.  最终收敛的向量 $\\hat{\\boldsymbol{\\beta}}$ 就是最大似然估计。\n\n### 3. 成分加残差 (CPR) 诊断\n\nCPR 图是一种诊断工具，用于评估回归模型中预测变量的函数形式。对于预测变量 $x_j$，该图绘制了“成分加残差”纵坐标与 $x_j$ 的关系。如果假定的线性关系是正确的，该图应呈现线性趋势。\n\n对于 GLM，关系在线性预测器尺度上是线性的。预测变量 $x_j$ 在观测值 $i$ 处的成分加残差纵坐标定义为拟合的线性成分与残差项之和：\n$$C_i^{(j)} = \\hat{\\beta}_j x_{ij} + \\text{residual}_i$$\n合适的残差是最后一次 IRLS 迭代的*工作残差*，它代表了在线性预测器尺度上的剩余误差：\n$$r_{W,i} = z_i - \\hat{\\eta}_i = \\frac{y_i - \\hat{\\mu}_i}{\\hat{\\mu}_i}$$\n因此，CPR 纵坐标为：\n$$C_i^{(j)} = \\hat{\\beta}_j x_{ij} + \\frac{y_i - \\hat{\\mu}_i}{\\hat{\\mu}_i}$$\n这个量分离出了响应（在调整了其他预测变量后）与 $x_j$ 之间的关系。\n\n### 4. 线性关系的量化评估\n\n为了自动化 CPR 图的视觉检查，我们可以对其拟合一个回归模型。问题指定使用普通最小二乘法 (OLS) 拟合一个二次模型：\n$$C_i^{(j)} = \\gamma_0 + \\gamma_1 x_{ij} + \\gamma_2 x_{ij}^2 + \\epsilon_i$$\n估计系数 $\\hat{\\gamma}_2$ 的大小可作为非线性的量化度量。$\\hat{\\gamma}_2$ 的值接近于零支持了预测变量 $x_j$ 的线性假设。一个不可忽略的值表明模型中可能需要一个二次项（或其他非线性项）。$\\boldsymbol{\\gamma} = (\\gamma_0, \\gamma_1, \\gamma_2)^\\top$ 的 OLS 估计可以通过求解正规方程组得到：\n$$\\hat{\\boldsymbol{\\gamma}} = (\\boldsymbol{Z}_j^\\top \\boldsymbol{Z}_j)^{-1}\\boldsymbol{Z}_j^\\top \\boldsymbol{C}^{(j)}$$\n其中 $\\boldsymbol{Z}_j$ 是以 $[1, x_j, x_j^2]$ 为列的设计矩阵，而 $\\boldsymbol{C}^{(j)}$ 是 CPR 纵坐标的向量。\n\n以下 Python 程序为三个指定的测试用例实现了这整个过程。它生成合成数据，使用推导出的 IRLS 算法拟合泊松 GLM，计算预测变量 $x$ 的 CPR 纵坐标，并最终为每个案例估计二次项系数 $\\gamma_2$。",
            "answer": "```python\nimport numpy as np\n\ndef fit_poisson_glm(X, y, max_iter=50, tol=1e-8):\n    \"\"\"\n    Fits a Poisson GLM with a log link using Iteratively Reweighted Least Squares (IRLS).\n    \n    The derivation is from first principles based on the exponential family form\n    of the Poisson distribution and Newton-Raphson (Fisher scoring) updates.\n\n    Args:\n        X (np.ndarray): Design matrix (n_samples, n_features).\n        y (np.ndarray): Response vector (n_samples,).\n        max_iter (int): Maximum number of iterations for the IRLS algorithm.\n        tol (float): Convergence tolerance for the norm of the change in the coefficient vector.\n        \n    Returns:\n        np.ndarray: Estimated coefficient vector beta.\n    \"\"\"\n    # Initialize coefficients to zeros\n    beta = np.zeros(X.shape[1])\n    \n    for _ in range(max_iter):\n        # Step a: Calculate current linear predictor, mean, and weights\n        eta = X @ beta\n        mu = np.exp(eta)\n        \n        # The weight for observation i is mu_i, derived from the Fisher Information matrix\n        w = mu\n        \n        # Step b: Calculate the working response z\n        # z = eta + (y - mu) * g'(mu), where g'(mu) = 1/mu for the log link\n        z = eta + (y - mu) / mu\n        \n        # Store old beta for convergence check\n        beta_old = beta.copy()\n        \n        # Step c: Solve the weighted least squares problem for the new beta\n        # beta_new = inv(X.T @ W @ X) @ X.T @ W @ z\n        # This is best implemented using np.linalg.solve for numerical stability,\n        # and by using broadcasting for efficient computation of matrix products involving W.\n        XtW = X.T * w  # Broadcasting w to the rows of X.T\n        XtWX = XtW @ X\n        XtWz = XtW @ z\n        \n        try:\n            beta = np.linalg.solve(XtWX, XtWz)\n        except np.linalg.LinAlgError:\n            # This is unlikely with the problem's data but is good practice.\n            # If the matrix is singular, return the last stable coefficients.\n            return beta_old\n            \n        # Check for convergence\n        if np.linalg.norm(beta - beta_old)  tol:\n            break\n            \n    return beta\n\ndef run_case(n, true_params, seed, target_predictor_idx=1):\n    \"\"\"\n    Runs a single test case: generates data, fits the GLM, and computes the diagnostic.\n    \n    Args:\n        n (int): Sample size.\n        true_params (dict): Dictionary of parameters for data generation.\n        seed (int): Random seed for reproducibility of both predictors and response.\n        target_predictor_idx (int): Column index in X of the predictor to test.\n        \n    Returns:\n        float: The estimated quadratic coefficient from the CPR diagnostic regression.\n    \"\"\"\n    # 1. Generate data using the specified seed to ensure reproducibility.\n    rng = np.random.default_rng(seed)\n    \n    x = rng.uniform(-2, 2, size=n)\n    w = rng.normal(0, 1, size=n)\n    \n    # Construct design matrix for the GLM to be fitted (linear terms only)\n    X = np.c_[np.ones(n), x, w]\n    \n    # Generate true linear predictor (eta_true) based on the case's data generating process\n    b0 = true_params.get('b0', 0.0)\n    b1 = true_params.get('b1', 0.0)\n    b2 = true_params.get('b2', 0.0)\n    gamma_true = true_params.get('gamma', 0.0) # For non-linear case\n    \n    eta_true = b0 + b1 * x + gamma_true * x**2 + b2 * w\n    mu_true = np.exp(eta_true)\n    y = rng.poisson(mu_true)\n    \n    # 2. Fit the specified Poisson GLM\n    beta_hat = fit_poisson_glm(X, y)\n    \n    # 3. Compute the Component-Plus-Residual (CPR) ordinate\n    # Calculate final fitted values from the model\n    mu_hat = np.exp(X @ beta_hat)\n    \n    # Isolate the target predictor variable and its estimated coefficient\n    x_j = X[:, target_predictor_idx]\n    beta_j_hat = beta_hat[target_predictor_idx]\n    \n    # CPR ordinate = (linear component for x_j) + (working residual)\n    cpr_ordinate = beta_j_hat * x_j + (y - mu_hat) / mu_hat\n    \n    # 4. Perform the diagnostic OLS regression: CPR ordinate ~ 1 + x_j + x_j^2\n    # Construct the design matrix for this diagnostic regression\n    Z = np.c_[np.ones(n), x_j, x_j**2]\n    \n    # Solve for the coefficients of the diagnostic regression\n    gamma_hat = np.linalg.solve(Z.T @ Z, Z.T @ cpr_ordinate)\n    \n    # 5. Extract and return the quadratic coefficient (gamma_2)\n    quad_coeff = gamma_hat[2]\n    \n    return quad_coeff\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite, then prints the results in the required format.\n    \"\"\"\n    # Define the three test cases as specified in the problem statement.\n    test_cases = [\n        # Case A: Linear relationship (happy path)\n        {'n': 1000, 'params': {'b0': 1.0, 'b1': 0.5, 'b2': -0.25}, 'seed': 12345},\n        # Case B: Quadratic relationship (detectable curvature)\n        {'n': 1000, 'params': {'b0': 1.0, 'b1': 0.0, 'gamma': 0.6, 'b2': -0.25}, 'seed': 23456},\n        # Case C: No relationship with x (boundary case)\n        {'n': 1000, 'params': {'b0': 1.0, 'b1': 0.0, 'b2': 0.2}, 'seed': 34567},\n    ]\n\n    results = []\n    for case in test_cases:\n        # For all cases, the target predictor 'x' is at index 1 of the design matrix X.\n        quad_coeff = run_case(\n            n=case['n'],\n            true_params=case['params'],\n            seed=case['seed'],\n            target_predictor_idx=1\n        )\n        # Round the result to at most six decimal places as requested.\n        results.append(round(quad_coeff, 6))\n\n    # Format the final output as a single-line, comma-separated list in brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "当模型假设被违背时，我们该如何应对？一个常见且微妙的情况是，即使我们对均值函数的设定是正确的，方差函数的错误设定仍会导致错误的统计推断（例如，不正确的标准误和置信区间）。本练习将引导您处理这种模型设定不当的情形，通过推导和计算“三明治”协方差估计量（sandwich estimator），学习如何获得即使在异方差存在时也依然稳健的标准误。",
            "id": "3124048",
            "problem": "给定一个统计学习场景，其中涉及一个广义线性模型 (GLM)。在此场景中，真实的数据生成过程是具有恒等链接函数的 Poisson 分布，但推断过程却使用具有恒等链接的高斯线性模型。此设定阐明了链接函数设定错误如何在使用了错误方差的情况下仍能得到正确的均值，以及必须如何通过三明治估计量来校正推断。\n\n假设有独立观测值 $\\{(x_i, y_i)\\}_{i=1}^n$，其中 $y_i$ 服从条件均值为 $E[y_i \\mid x_i] = \\mu_i$ 的 Poisson 分布，并假设真实均值是线性的，即 $\\mu_i = \\beta_0 + \\beta_1 x_i$，且对所有 $i$ 都有 $\\mu_i > 0$。考虑对 $\\{(x_i, y_i)\\}$ 拟合一个具有恒等链接的 Gaussian 线性模型，这样做可以得到正确的均值设定，但假设了恒定方差。相比之下，Poisson 分布意味着在每个 $i$ 处的方差等于其均值。你需要使用三明治估计量来设计、推导和计算最小二乘估计量的正确渐近协方差。\n\n使用以下核心定义和事实作为基本依据：\n- Poisson 分布属于指数族，并满足 $E[y_i \\mid x_i] = \\mu_i$ 和 $\\operatorname{Var}(y_i \\mid x_i) = \\mu_i$。\n- 广义线性模型 (GLM) 通过一个链接函数将均值 $\\mu_i$ 与线性预测值联系起来，其方差由方差函数乘以一个离散参数给出。对于 Poisson 分布，方差函数为 $V(\\mu_i) = \\mu_i$，离散参数为 $1$。\n- 具有恒等链接的 Gaussian 线性模型假设 $\\operatorname{Var}(y_i \\mid x_i) = \\sigma^2$ 是一个常数，如果真实方差不是恒定的，则该假设可能设定错误。\n\n对于每个测试用例，你的程序必须从第一性原理出发，推导在由 Poisson 方差引起的异方差性下，最小二乘估计量的渐近协方差，并将其与设定错误的同方差协方差进行比较。异方差稳健的协方差必须使用基于得分的 M 估计框架构建为三明治估计量。设定错误的同方差协方差必须根据具有恒等链接的 Gaussian 模型，并使用一个恒定方差水平来构建。为使比较在数值上确定且完全可复现，将设定错误的恒定方差水平定义为真实方差的平均值，即 $\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^n \\mu_i$。\n\n对于每个测试用例：\n1. 将设计矩阵视为 $X \\in \\mathbb{R}^{n \\times 2}$，其第一列为 $1$，第二列为 $x_i$。\n2. 使用 Poisson 方差结构计算 $(\\beta_0,\\beta_1)$ 的异方差稳健三明治协方差矩阵。\n3. 使用 $\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^n \\mu_i$ 计算 $(\\beta_0,\\beta_1)$ 的设定错误的同方差协方差矩阵。\n4. 从两个协方差矩阵中提取截距和斜率的标准误。\n5. 对于每个测试用例，按截距和斜率的顺序，以两个浮点数的形式报告稳健标准误与同方差标准误的比率。\n\n测试套件：\n- 情况 A (理想路径，中等均值)：$n = 6$, $x = [0, 1, 2, 3, 4, 5]$, $\\beta_0 = 2.0$, $\\beta_1 = 0.5$。\n- 情况 B (边界情况，均值较小但严格为正)：$n = 5$, $x = [-3, -2, -1, 0, 1]$, $\\beta_0 = 0.7$, $\\beta_1 = 0.2$。\n- 情况 C (强异方差性，均值离散度大)：$n = 6$, $x = [0, 5, 10, 15, 20, 25]$, $\\beta_0 = 1.0$, $\\beta_1 = 0.8$。\n\n你的程序必须计算所有三种情况的比率，并生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果是一个按 [截距比率, 斜率比率] 顺序排列的双元素列表。例如，输出格式必须与以下完全一样：\n[[rA0,rA1],[rB0,rB1],[rC0,rC1]]\n其中每个 $r$ 都是一个浮点数。不应打印任何额外文本。此任务不涉及角度，也不涉及任何物理单位。将所有数值输出表示为十进制浮点数。",
            "solution": "该问题要求在特定的模型设定错误场景下，推导和计算普通最小二乘 (OLS) 估计量的两种协方差矩阵。真实的数据生成过程是一个具有恒等链接函数的 Poisson 回归模型，而拟合的模型是一个同样具有恒等链接的 Gaussian 线性模型。这种设定意味着均值函数被正确指定，但方差结构没有。\n\n首先，我们将问题形式化。我们有独立观测值 $\\{(x_i, y_i)\\}_{i=1}^n$。给定预测变量 $x_i$ 的条件下，$y_i$ 的真实模型由以下给出：\n1.  **真实均值**：$E[y_i \\mid x_i] = \\mu_i$。链接函数是恒等链接，因此均值是参数的线性函数：$\\mu_i = \\beta_0 + \\beta_1 x_i$。在使用行向量为 $x_i^T = [1, x_i]$ 的设计矩阵 $X$ 的矩阵表示法中，我们有 $E[y \\mid X] = X\\beta$。\n2.  **真实分布**：$y_i \\sim \\text{Poisson}(\\mu_i)$。Poisson 分布的一个关键特性是方差等于均值，因此 $\\operatorname{Var}(y_i \\mid x_i) = \\mu_i$。\n\n被拟合的模型是一个 Gaussian 线性模型，它对应于 OLS。系数向量 $\\beta = [\\beta_0, \\beta_1]^T$ 的估计量为：\n$$ \\hat{\\beta} = (X^T X)^{-1} X^T y $$\n由于均值函数被正确指定 ($E[y \\mid X] = X\\beta$)，OLS 估计量 $\\hat{\\beta}$ 是无偏的：\n$$ E[\\hat{\\beta}] = E[(X^T X)^{-1} X^T y] = (X^T X)^{-1} X^T E[y] = (X^T X)^{-1} X^T (X\\beta) = \\beta $$\n\n问题的核心在于 $\\hat{\\beta}$ 的协方差。随机向量 $y$ 的线性变换的协方差通用公式是 $\\operatorname{Cov}(Ay) = A \\operatorname{Cov}(y) A^T$。将此应用于 $\\hat{\\beta}$：\n$$ \\operatorname{Cov}(\\hat{\\beta}) = \\operatorname{Cov}((X^T X)^{-1} X^T y) = (X^T X)^{-1} X^T \\operatorname{Cov}(y) X (X^T X)^{-1} $$\n此处，$\\operatorname{Cov}(y)$ 是响应向量 $y$ 的协方差矩阵。由于观测值是独立的，这是一个对角矩阵，其对角线元素是各自的方差 $\\operatorname{Var}(y_i)$。我们用 $\\Omega = \\text{diag}(\\operatorname{Var}(y_1), \\dots, \\operatorname{Var}(y_n))$ 来表示这个矩阵。\n\n**1. 异方差稳健（三明治）协方差**\n\n在真实的 Poisson 数据生成过程中，方差是异方差的：$\\operatorname{Var}(y_i \\mid x_i) = \\mu_i$。因此，$y$ 的真实协方差矩阵为 $\\Omega = \\text{diag}(\\mu_1, \\mu_2, \\dots, \\mu_n)$。将此代入通用公式，得到 $\\hat{\\beta}$ 的正确、稳健的协方差矩阵：\n$$ \\Sigma_{\\text{robust}} = (X^T X)^{-1} (X^T \\Omega X) (X^T X)^{-1} $$\n这就是协方差的“三明治”估计量。矩阵 $(X^T X)^{-1}$ 构成“面包”，中间项 $X^T \\Omega X$ 是“肉”。这种形式源于 M 估计理论，其中 OLS 估计量是从估计方程 $\\sum_{i=1}^n x_i(y_i - x_i^T\\beta) = 0$ 推导出来的。稳健协方差公式正确地考虑了残差 $(y_i - \\mu_i)$ 的方差依赖于 $i$ 这一事实。\n\n**2. 设定错误的同方差协方差**\n\n标准的 Gaussian 线性模型错误地假设了同方差性，即对所有 $i$ 都有恒定方差 $\\operatorname{Var}(y_i \\mid x_i) = \\sigma^2$。在此假设下，$\\operatorname{Cov}(y) = \\sigma^2 I_n$，其中 $I_n$ 是 $n \\times n$ 的单位矩阵。协方差公式简化为：\n$$ \\Sigma_{\\text{misspecified}} = (X^T X)^{-1} X^T (\\sigma^2 I_n) X (X^T X)^{-1} = \\sigma^2 (X^T X)^{-1} (X^T X) (X^T X)^{-1} = \\sigma^2 (X^T X)^{-1} $$\n为了使比较具体化，问题指定恒定方差水平 $\\sigma^2$ 应取为真实方差的平均值：\n$$ \\sigma^2 = \\frac{1}{n} \\sum_{i=1}^n \\operatorname{Var}(y_i) = \\frac{1}{n} \\sum_{i=1}^n \\mu_i $$\n\n**3. 计算与比较**\n\n对于每个测试用例，步骤如下：\n- 给定真实参数 $\\beta_0$ 和 $\\beta_1$ 以及预测变量向量 $x$，我们首先构建设计矩阵 $X$。\n- 然后我们计算真实条件均值 $\\mu = X\\beta$。\n- 稳健协方差矩阵 $\\Sigma_{\\text{robust}}$ 是使用 $\\Omega = \\text{diag}(\\mu_i)$ 计算的。“肉”矩阵可以计算为 $X^T \\Omega X = \\sum_{i=1}^n \\mu_i x_i x_i^T$，其中 $x_i$ 是 $X$ 的第 $i$ 行。\n- 设定错误的同方差协方差矩阵 $\\Sigma_{\\text{homo}} = \\sigma^2 (X^T X)^{-1}$ 是使用 $\\sigma^2 = \\text{mean}(\\mu)$ 计算的。\n- 截距和斜率的标准误 (SE) 分别是这些协方差矩阵对角元素的平方根。例如，$\\text{SE}_{\\text{robust}}(\\hat{\\beta}_0) = \\sqrt{(\\Sigma_{\\text{robust}})_{11}}$。\n- 最后，我们计算截距 ($\\beta_0$) 和斜率 ($\\beta_1$) 的稳健 SE 与同方差 SE 的比率。该比率表明了朴素 OLS 标准误不正确的程度。比率大于 $1$ 意味着朴素 SE 低估了真实的不确定性，而比率小于 $1$ 则意味着它高估了不确定性。\n\n实现将对所提供的三个测试用例中的每一个执行这些矩阵计算。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the formatted result.\n    \"\"\"\n    test_cases = [\n        # Case A (happy path, moderate means)\n        {'n': 6, 'x': np.array([0., 1., 2., 3., 4., 5.]), 'beta0': 2.0, 'beta1': 0.5},\n        # Case B (boundary, small means but strictly positive)\n        {'n': 5, 'x': np.array([-3., -2., -1., 0., 1.]), 'beta0': 0.7, 'beta1': 0.2},\n        # Case C (strong heteroskedasticity, large spread in means)\n        {'n': 6, 'x': np.array([0., 5., 10., 15., 20., 25.]), 'beta0': 1.0, 'beta1': 0.8},\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        n, x_data, beta0, beta1 = case['n'], case['x'], case['beta0'], case['beta1']\n        \n        # 1. Construct the design matrix X and coefficient vector beta.\n        X = np.vstack([np.ones(n), x_data]).T\n        beta = np.array([beta0, beta1])\n\n        # 2. Compute the true conditional means mu_i.\n        mu = X @ beta\n\n        # 3. Compute the inverse of X^T X, a common term.\n        XTX_inv = np.linalg.inv(X.T @ X)\n\n        # 4. Compute the heteroskedastic-robust sandwich covariance matrix.\n        # Omega is the diagonal matrix of true variances (mu_i).\n        # The 'meat' of the sandwich is X^T * Omega * X.\n        # This can be computed efficiently without forming the large Omega matrix.\n        # (X.T * mu) @ X is an efficient way to write X.T @ diag(mu) @ X\n        meat = (X.T * mu) @ X\n        Sigma_robust = XTX_inv @ meat @ XTX_inv\n\n        # 5. Compute the misspecified homoskedastic covariance matrix.\n        # sigma^2 is defined as the average of the true variances.\n        sigma2 = np.mean(mu)\n        Sigma_homo = sigma2 * XTX_inv\n\n        # 6. Extract the standard errors (sqrt of diagonal elements).\n        se_robust = np.sqrt(np.diag(Sigma_robust))\n        se_homo = np.sqrt(np.diag(Sigma_homo))\n\n        # 7. Compute the ratios of robust to homoskedastic standard errors.\n        ratios = se_robust / se_homo\n        \n        # Format the result for this case as a list of floats\n        all_results.append(list(ratios))\n\n    # Final print statement in the exact required format.\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}