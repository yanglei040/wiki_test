{
    "hands_on_practices": [
        {
            "introduction": "为了准确估计一项处理措施的因果效应，关键在于有效控制所有混淆变量。回归调整法是一种常用的策略，但它的成功与否，完全取决于我们观测到的协变量是否足以关闭所有从处理到结果的“后门路径”。本练习将通过一系列精心设计的思想实验，帮助你深入理解因果识别的核心条件，即后门准则，并辨析在何种情况下回归调整能够成功识别平均处理效应（$ATE$），又在何种情况下会因存在未观测混淆而失效。",
            "id": "3106696",
            "problem": "考虑一个二元处理变量 $T \\in \\{0,1\\}$，一个可观测的协变量 $X$，一个可能不可观测的变量 $U$，以及一个结果 $Y$。假设稳定单位处理价值假设（SUTVA）和一致性成立，因此对于每个单位，观测到的结果满足 $Y = Y(T)$。定义平均处理效应（ATE）为 $E\\big[Y(1) - Y(0)\\big]$。您将从条件独立性和全期望定律的定义出发，研究使用条件均值 $E[Y \\mid T, X]$ 进行回归调整是否足以识别 ATE。在以下所有情景中，假设误差项 $\\varepsilon$ 独立于 $(T,X,U)$，且 $E[\\varepsilon] = 0$ 并具有有限方差。\n\n对于每个情景，判断使用回归函数 $E[Y \\mid T, X]$ 是否足以识别 ATE，即判断使用 $E[Y \\mid T, X]$ 来恢复 $E\\big[Y(1) - Y(0)\\big]$ 的条件是否成立。选择所有成立的情景。\n\n选项 A:\n- $X \\sim \\text{Bernoulli}(0.5)$，$T \\sim \\text{Bernoulli}(0.5)$，且 $T$ 独立于 $X$。\n- 结果由 $Y = 2T + X + \\varepsilon$ 生成。\n- 此情景中没有 $U$。\n\n选项 B:\n- $U \\sim \\text{Bernoulli}(0.5)$，$X \\sim \\text{Bernoulli}(0.5)$，且 $X$ 独立于 $U$。\n- 处理是确定性的 $T = U$。\n- 结果由 $Y = 2T + U + \\varepsilon$ 生成。\n\n选项 C:\n- $U \\sim \\text{Bernoulli}(0.5)$。\n- 可观测协变量 $X$ 是 $U$ 的一个含噪声的代理变量：$P(X = U) = 0.8$ 且 $P(X \\neq U) = 0.2$。\n- 处理是确定性的 $T = U$。\n- 结果由 $Y = 2T + U + \\varepsilon$ 生成。\n\n选项 D:\n- $U \\sim \\text{Bernoulli}(0.5)$，且 $X = U$（即，$X$ 等于 $U$ 且没有误差）。\n- 处理在以 $U$ 为条件的基本上是随机化的，因此 $P(T = 1 \\mid U = 1) = 0.8$ 且 $P(T = 1 \\mid U = 0) = 0.2$。\n- 结果由 $Y = 2T + U + \\varepsilon$ 生成。\n\n在每个选项中，从基本定义（一致性/SUTVA、条件独立性和全期望定律）出发，论证 $E[Y \\mid T, X]$ 是否能识别 $E\\big[Y(1) - Y(0)\\big]$，以及在何种情况下由于 $X$ 未能阻断所有后门路径而失败。选择所有正确的选项。\nA. 选项A\nB. 选项B\nC. 选项C\nD. 选项D",
            "solution": "该问题要求确定在哪四种情景中，基于条件期望 $E[Y \\mid T, X]$ 的回归调整公式足以识别定义为 $E\\big[Y(1) - Y(0)\\big]$ 的平均处理效应（ATE）。\n\n首先，我们建立理论基础。问题陈述我们可以假设SUTVA和一致性，这意味着 $Y = Y(T)$。ATE是 $E[Y(1) - Y(0)]$。根据全期望定律，我们可以将ATE写成：\n$$ E\\big[Y(1) - Y(0)\\big] = E_X\\Big[E\\big[Y(1) \\mid X\\big] - E\\big[Y(0) \\mid X\\big]\\Big] $$\n回归调整估计量定义为：\n$$ \\tau_{adj} = E_X\\Big[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]\\Big] $$\n根据一致性，$E[Y \\mid T=1, X] = E[Y(1) \\mid T=1, X]$ 且 $E[Y \\mid T=0, X] = E[Y(0) \\mid T=0, X]$。\n为了使 $\\tau_{adj}$ 等于 ATE，我们需要条件可忽略性假设（也称为无混杂性或可观测选择）成立：\n$$ \\big(Y(1), Y(0)\\big) \\perp T \\mid X $$\n这意味着，在给定协变量 $X$ 的条件下，处理分配 $T$ 独立于潜在结果。用因果图的语言来说，这等同于陈述协变量集 $X$ 阻断了所有从处理 $T$ 到结果 $Y$ 的后门路径。后门路径是 $T$ 和 $Y$ 之间的一条非因果路径，其上有一指向 $T$ 的箭头。\n\n后门路径的一个常见来源是变量 $U$，它是 $T$ 和 $Y$ 的共同原因（一个混杂因素）。路径 $T \\leftarrow U \\rightarrow Y$ 必须被阻断。如果 $U$ 是可观测协变量 $X$ 的一部分，那么以 $X$ 为条件可以阻断此路径。如果 $U$ 是不可观测的，则识别可能会失败。\n\n在所有情景中，结果的结构方程形式为 $Y = 2T + \\text{不含 } T \\text{ 的项} + \\varepsilon$。\n通过将 $T$ 设置为 $1$ 或 $0$ 来推导潜在结果：\n- $Y(1) = 2(1) + \\dots + \\varepsilon$\n- $Y(0) = 2(0) + \\dots + \\varepsilon$\n对任何单位的因果效应是 $Y(1) - Y(0) = 2$。\n因此，在所有四种情景中，真实的平均处理效应（ATE）是：\n$$ E\\big[Y(1) - Y(0)\\big] = E[2] = 2 $$\n因此，问题简化为检查在哪种情景下，回归调整估计量 $\\tau_{adj}$ 等于 $2$。\n\n给定在所有情景中，$E[\\varepsilon]=0$ 且 $\\varepsilon$ 独立于 $(T, X, U)$。\n\n### 选项 A\n\n- **设置**：$X \\sim \\text{Bernoulli}(0.5)$，$T \\sim \\text{Bernoulli}(0.5)$，$T \\perp X$。$Y = 2T + X + \\varepsilon$。此情景中没有不可观测的混杂因素 $U$。\n- **分析**：\n潜在结果为 $Y(1) = 2 + X + \\varepsilon$ 和 $Y(0) = X + \\varepsilon$。\n条件可忽略性假设是 $(Y(1), Y(0)) \\perp T \\mid X$。潜在结果是 $X$ 和 $\\varepsilon$ 的函数。我们已知 $T$ 独立于 $X$。我们还已知 $\\varepsilon$ 独立于 $(T, X, U)$，这意味着 $\\varepsilon \\perp T$。由于 $T$ 同时独立于 $X$ 和 $\\varepsilon$，它也独立于 $(X, \\varepsilon)$ 的任何函数。因此，$T \\perp (Y(1), Y(0))$。无条件独立性意味着给定 $X$ 的条件独立性。所以，该条件成立。从 $T$ 到 $Y$ 没有后门路径。这是一个随机对照试验。\n让我们计算估计量：\n$E[Y \\mid T, X] = E[2T + X + \\varepsilon \\mid T, X] = 2T + X + E[\\varepsilon \\mid T, X]$\n由于 $\\varepsilon$ 独立于 $(T,X)$，$E[\\varepsilon \\mid T, X] = E[\\varepsilon]=0$。所以，$E[Y \\mid T, X] = 2T + X$。\n回归调整估计量是：\n$\\tau_{adj} = E_X\\Big[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]\\Big] = E_X\\Big[ (2(1) + X) - (2(0) + X) \\Big] = E_X[2] = 2$\n- **结论**：由于 $\\tau_{adj} = 2$，即真实的ATE，回归调整足以识别ATE。**正确**。\n\n### 选项 B\n\n- **设置**：$U \\sim \\text{Bernoulli}(0.5)$，$X \\sim \\text{Bernoulli}(0.5)$，$X \\perp U$。处理是 $T = U$。结果是 $Y = 2T + U + \\varepsilon$。\n- **分析**：\n在这里，$U$ 是 $T$（因为 $T=U$）和 $Y$（因为 $U$ 在 $Y$ 的结构方程中）的共同原因。这创建了一条后门路径 $T \\leftarrow U \\rightarrow Y$。由于 $U$ 不可观测，这条路径可能是开放的。可观测的协变量 $X$ 独立于 $U$，因此以 $X$ 为条件不能阻断该路径。\n潜在结果为 $Y(t) = 2t + U + \\varepsilon$。我们需要检查是否 $(Y(1), Y(0)) \\perp T \\mid X$。这等价于检查是否 $U \\perp T \\mid X$。但 $T=U$，所以我们是在检查是否 $U \\perp U \\mid X$。这显然是错误的。条件可忽略性不成立。\n让我们计算估计量。首先，将 $T=U$ 代入观测数据的结果方程：$Y = 2T + T + \\varepsilon = 3T + \\varepsilon$。\n$E[Y \\mid T, X] = E[3T + \\varepsilon \\mid T, X] = 3T + E[\\varepsilon \\mid T, X] = 3T$\n回归调整估计量是：\n$\\tau_{adj} = E_X\\Big[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]\\Big] = E_X\\big[3(1) - 3(0)\\big] = E_X[3] = 3$\n- **结论**：估计量 $\\tau_{adj} = 3$ 不等于真实的ATE $2$。差异是由于不可观测变量 $U$ 造成的混杂。**错误**。\n\n### 选项 C\n\n- **设置**：$U \\sim \\text{Bernoulli}(0.5)$，$X$ 是 $U$ 的一个含噪声的代理变量，满足 $P(X=U)=0.8$。处理是 $T = U$。结果是 $Y = 2T + U + \\varepsilon$。\n- **分析**：\n与选项B类似，$U$ 是一个混杂因素，创建了后门路径 $T \\leftarrow U \\rightarrow Y$。在这里，我们观测到 $U$ 的一个代理变量 $X$。因果结构是 $U \\rightarrow X$ 和 $T \\leftarrow U \\rightarrow Y$。以混杂因素的子节点 $X$ 为条件，并不能阻断后门路径。条件 $U \\perp T \\mid X$ 不成立，因为知道 $X$ 提供了关于 $U$ 的信息，但并不能使 $U$ 独立于 $T=U$。\n让我们计算估计量。与选项B一样，观测到的结果是 $Y = 3T+\\varepsilon$。\n$E[Y \\mid T, X] = E[3T + \\varepsilon \\mid T, X] = 3T + E[\\varepsilon \\mid T, X] = 3T$\n计算与选项B相同，因为一旦给定 $T$，$U$ 也已知（$U=T$），所以在求 $Y$ 的条件期望时，从 $X$ 获得的关于 $U$ 的任何额外信息都变得多余。\n回归调整估计量是：\n$\\tau_{adj} = E_X\\Big[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]\\Big] = E_X\\big[3 - 0\\big] = 3$\n- **结论**：估计量 $\\tau_{adj} = 3$ 不等于真实的ATE $2$。这是由不完美代理变量导致的残余混杂的典型案例。**错误**。\n\n### 选项 D\n\n- **设置**：$U \\sim \\text{Bernoulli}(0.5)$，$X = U$。处理 $T$ 在以 $U$ 为条件的基本上是随机化的：$P(T=1|U=1)=0.8, P(T=1|U=0)=0.2$。结果是 $Y = 2T + U + \\varepsilon$。\n- **分析**：\n这里，$U$ 再次成为 $T$ 和 $Y$ 的共同原因，因此存在后门路径 $T \\leftarrow U \\rightarrow Y$。然而，在这种情景下，混杂因素 $U$ 通过 $X=U$ 被完美观测到。通过以 $X$ 为条件，我们就是以混杂因素本身为条件，从而阻断了后门路径。\n让我们正式检查条件可忽略性假设：$(Y(1), Y(0)) \\perp T \\mid X$。潜在结果是 $Y(t) = 2t + U + \\varepsilon$。由于它们是 $U$ 和 $\\varepsilon$ 的函数，我们必须检查是否 $(U, \\varepsilon) \\perp T \\mid X$。给定 $X=U$，这变为 $(U, \\varepsilon) \\perp T \\mid U$。一个变量总是依赖于自身，但当我们以它为条件时，它的值是固定的。所以我们只需要检查是否 $\\varepsilon \\perp T \\mid U$。我们已知 $\\varepsilon$ 独立于 $(T,X,U)$ 的联合分布，这意味着 $\\varepsilon \\perp T \\mid U$。因此，条件可忽略性成立。\n让我们计算估计量：\n$E[Y \\mid T, X] = E[2T + U + \\varepsilon \\mid T, X]$\n由于 $X=U$，这等价于：\n$E[Y \\mid T, X] = E[2T + X + \\varepsilon \\mid T, X] = 2T + X + E[\\varepsilon \\mid T,X] = 2T + X$\n回归调整估计量是：\n$\\tau_{adj} = E_X\\Big[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]\\Big] = E_X\\Big[ (2(1) + X) - (2(0) + X) \\Big] = E_X[2] = 2$\n- **结论**：由于 $\\tau_{adj} = 2$，即真实的ATE，回归调整足以识别ATE。此情景代表了通过在回归模型中包含混杂因素来成功控制混杂的情况。**正确**。\n\n使用回归函数 $E[Y \\mid T, X]$ 足以识别 ATE 的情景是 A 和 D。",
            "answer": "$$\\boxed{AD}$$"
        },
        {
            "introduction": "在确立了控制混淆的必要性后，我们便需要更强大的估计工具。许多标准方法，如逆概率加权（IPW）或结果回归，其无偏性均依赖于相应模型的正确设定。本练习将引导你探索增广逆概率加权（AIPW）估计量，并通过模拟实验来验证其最为重要的“双重稳健性”：只要倾向性得分模型或结果模型中有一个被正确设定，AIPW 就能对因果效应给出一致的估计，这使其成为现代因果推断的基石之一。",
            "id": "3106777",
            "problem": "考虑一个二元处理设定，其中包含潜在结果 $Y(1)$ 和 $Y(0)$，一个观测协变量 $X \\in \\mathbb{R}$，一个处理指示符 $T \\in \\{0,1\\}$，以及一个观测结果 $Y \\in \\mathbb{R}$。假设遵循以下基本原则：一致性 $Y = T Y(1) + (1 - T) Y(0)$，条件可忽略性 $(Y(1), Y(0)) \\perp T \\mid X$，以及正值性 $0 < \\mathbb{P}(T = 1 \\mid X = x) < 1$ 对于所有实现的 $x$。目标参数是平均处理效应 (ATE)，定义为 $\\Delta = \\mathbb{E}[Y(1) - Y(0)]$。\n\n您将研究在两个统计学习模型下的增广逆概率加权 (AIPW) 估计量：\n- 一个结果回归模型 $m_t(x) \\approx \\mathbb{E}[Y \\mid T = t, X = x]$，其中 $t \\in \\{0,1\\}$。\n- 一个倾向性得分模型 $e(x) \\approx \\mathbb{P}(T = 1 \\mid X = x)$。\n\n开发一个结果回归模型被正确设定而倾向性得分模型被错误设定的例子，并根据经验证明增广逆概率加权 (AIPW) 估计量的双重稳健性属性。该属性指出，如果结果回归模型被正确设定或倾向性得分模型被正确设定（不一定两者都正确），则该估计量是一致的。\n\n用于模拟的数据生成过程：\n- 协变量：$X \\sim \\mathcal{N}(0,1)$。\n- 处理分配：$T \\mid X \\sim \\text{Bernoulli}(e^\\star(X))$，其中 $e^\\star(x) = \\frac{1}{1 + \\exp(-(\\alpha x + c))}$ 是参数为 $\\alpha$ 和 $c$ 的 logistic 函数。\n- 结果：$Y = \\beta_0 + \\beta_1 X + \\tau T + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$，在给定 $X$ 和 $T$ 的条件下独立于 $X$ 和 $T$。真实的平均处理效应是恒定的，等于 $\\tau$。\n\n用于估计的模型设定：\n- 正确的结果回归模型：将 $Y$ 对截距项、$T$ 和 $X$ 进行回归；然后使用此线性模型，将 $m_1(x)$ 和 $m_0(x)$ 分别设为 $T=1$ 和 $T=0$ 下的拟合条件均值。\n- 错误设定的结果回归模型：仅将 $Y$ 对截距项和 $T$ 进行回归（省略 $X$）。\n- 正确的倾向性得分模型：使用真实的函数 $e^\\star(x) = \\frac{1}{1 + \\exp(-(\\alpha x + c))}$ 以及来自数据生成过程的已知参数 $\\alpha$ 和 $c$。\n- 错误设定的倾向性得分模型：使用常数函数 $e(x) = 0.5$。\n\n根据上述基本原则和定义，推导 $\\Delta$ 的 AIPW 估计量并加以实现。对于一个样本 $\\{(X_i,T_i,Y_i)\\}_{i=1}^n$，使用估计的 $m_1(X_i)$、$m_0(X_i)$ 和 $e(X_i)$，计算 $\\Delta$ 的 AIPW 估计值，并报告其相对于真实 $\\tau$ 的偏差。\n\n测试套件：\n对于每个测试，根据指定参数的数据生成过程模拟数据，按规定拟合模型，计算 AIPW 估计值 $\\widehat{\\Delta}_{\\text{AIPW}}$，并报告偏差 $\\widehat{\\Delta}_{\\text{AIPW}} - \\tau$，结果为浮点数，保留 $6$ 位小数。\n\n- 测试 $1$（双重稳健性，结果模型正确，倾向性得分模型错误，理想路径）：$n = 50000$, $\\beta_0 = 2.0$, $\\beta_1 = 1.0$, $\\tau = 3.0$, $\\sigma = 1.0$, $\\alpha = 1.2$, $c = -0.2$，结果回归正确，倾向性得分错误，随机种子 $123$。\n- 测试 $2$（双重稳健性，倾向性得分模型正确，结果模型错误）：$n = 50000$, $\\beta_0 = 2.0$, $\\beta_1 = 1.0$, $\\tau = 3.0$, $\\sigma = 1.0$, $\\alpha = 1.2$, $c = -0.2$，结果回归错误，倾向性得分正确，随机种子 $456$。\n- 测试 $3$（两个模型均错误设定）：$n = 50000$, $\\beta_0 = 2.0$, $\\beta_1 = 1.0$, $\\tau = 3.0$, $\\sigma = 1.0$, $\\alpha = 1.2$, $c = -0.2$，结果回归错误，倾向性得分错误，随机种子 $789$。\n- 测试 $4$（两个模型均正确设定）：$n = 50000$, $\\beta_0 = 2.0$, $\\beta_1 = 1.0$, $\\tau = 3.0$, $\\sigma = 1.0$, $\\alpha = 1.2$, $c = -0.2$，结果回归正确，倾向性得分正确，随机种子 $321$。\n- 测试 $5$（接近正值性边界但有效的边缘案例，双重稳健性，结果模型正确，倾向性得分模型错误）：$n = 50000$, $\\beta_0 = 2.0$, $\\beta_1 = 1.0$, $\\tau = 3.0$, $\\sigma = 1.0$, $\\alpha = 4.0$, $c = 0.0$，结果回归正确，倾向性得分错误，随机种子 $654$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含五个偏差值，以逗号分隔并用方括号括起（例如 $[b_1,b_2,b_3,b_4,b_5]$），其中每个 $b_j$ 是测试 $j$ 的偏差，保留 $6$ 位小数。不应打印任何其他文本。",
            "solution": "目标是推导增广逆概率加权 (AIPW) 估计量，并在一项模拟研究中使用它来证明其双重稳健性。目标参数是 ATE，$\\Delta$，定义为 $\\Delta = \\mathbb{E}[Y(1) - Y(0)]$。根据期望的线性性质，这等于 $\\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)]$。我们将分别推导每一项的估计量。\n\n#### AIPW 估计量的推导\n\n我们先关注估计 $\\mu_1 = \\mathbb{E}[Y(1)]$。对于 $\\mu_0 = \\mathbb{E}[Y(0)]$，可以进行类似的推导。AIPW 估计量的构造使其在以下两种情况之一成立时对 $\\mu_1$ 是一致的：结果回归模型 $m_1(x) = \\mathbb{E}[Y \\mid T=1, X=x]$ 被正确设定，或者倾向性得分模型 $e(x) = \\mathbb{P}(T=1 \\mid X=x)$ 被正确设定。\n\n考虑以下变量，它是数据 $(X, T, Y)$ 和滋扰模型 $(m_1, e)$ 的函数：\n$$\n\\psi_1(X, T, Y; m_1, e) = \\frac{T(Y - m_1(X))}{e(X)} + m_1(X)\n$$\n我们将证明在两种正确性条件中的任意一种下，$\\psi_1$ 的期望都是 $\\mu_1$。\n\n**情况 1：倾向性得分模型 $e(x)$ 正确。**\n令 $e(x) = e^\\star(x) = \\mathbb{P}(T=1 \\mid X=x)$。我们对 $\\psi_1$ 求期望：\n$$ \\mathbb{E}[\\psi_1] = \\mathbb{E}\\left[ \\frac{T(Y - m_1(X))}{e^\\star(X)} + m_1(X) \\right] = \\mathbb{E}\\left[ \\frac{T(Y - m_1(X))}{e^\\star(X)} \\right] + \\mathbb{E}[m_1(X)] $$\n使用全期望定律，$\\mathbb{E}[A] = \\mathbb{E}[\\mathbb{E}[A \\mid X]]$：\n$$ \\mathbb{E}\\left[ \\frac{T(Y - m_1(X))}{e^\\star(X)} \\right] = \\mathbb{E}\\left[ \\mathbb{E}\\left[ \\frac{T(Y - m_1(X))}{e^\\star(X)} \\mid X \\right] \\right] $$\n内部期望为：\n$$ \\mathbb{E}\\left[ \\frac{T(Y - m_1(X))}{e^\\star(X)} \\mid X=x \\right] = \\frac{1}{e^\\star(x)} \\mathbb{E}[T(Y - m_1(x)) \\mid X=x] $$\n再次使用全期望定律，以 $T$ 为条件：\n$$ \\mathbb{E}[T(Y - m_1(x)) \\mid X=x] = \\mathbb{E}[Y-m_1(x) \\mid X=x, T=1]\\mathbb{P}(T=1 \\mid X=x) + 0 $$\n$$ = \\mathbb{E}[Y-m_1(x) \\mid X=x, T=1] e^\\star(x) $$\n结合这些，内部期望变为 $\\mathbb{E}[Y-m_1(x) \\mid X=x, T=1]$。根据一致性，当 $T=1$ 时 $Y=Y(1)$，因此这等于 $\\mathbb{E}[Y(1)-m_1(x) \\mid X=x, T=1]$。根据可忽略性，这等于 $\\mathbb{E}[Y(1)-m_1(x) \\mid X=x]$。\n因此，\n$$ \\mathbb{E}[\\psi_1] = \\mathbb{E}[\\mathbb{E}[Y(1)-m_1(X) \\mid X]] + \\mathbb{E}[m_1(X)] = \\mathbb{E}[Y(1)-m_1(X)] + \\mathbb{E}[m_1(X)] = \\mathbb{E}[Y(1)] = \\mu_1 $$\n如果倾向性得分模型正确，则该估计量对 $\\mu_1$ 是一致的，无论 $m_1(x)$ 的设定如何。\n\n**情况 2：结果回归模型 $m_1(x)$ 正确。**\n令 $m_1(x) = m_1^\\star(x) = \\mathbb{E}[Y \\mid T=1, X=x]$。我们同样从 $\\mathbb{E}[\\psi_1] = \\mathbb{E}\\left[ \\frac{T(Y - m_1^\\star(X))}{e(X)} \\right] + \\mathbb{E}[m_1^\\star(X)]$ 开始。\n根据可忽略性和一致性，$\\mathbb{E}[m_1^\\star(X)] = \\mathbb{E}[\\mathbb{E}[Y \\mid T=1, X]] = \\mathbb{E}[\\mathbb{E}[Y(1) \\mid X]] = \\mathbb{E}[Y(1)] = \\mu_1$。\n我们需要证明第一项为零。使用全期望定律：\n$$ \\mathbb{E}\\left[ \\mathbb{E}\\left[ \\frac{T(Y - m_1^\\star(X))}{e(X)} \\mid X \\right] \\right] $$\n内部期望是 $\\frac{1}{e(x)} \\mathbb{E}[T(Y - m_1^\\star(x)) \\mid X=x]$。这可以计算为：\n$$ \\frac{1}{e(x)} \\mathbb{E}[Y-m_1^\\star(x) \\mid X=x, T=1] \\mathbb{P}(T=1 \\mid X=x) $$\n由于 $m_1^\\star(x)$ 是真实的条件均值，$\\mathbb{E}[Y \\mid X=x, T=1] - m_1^\\star(x) = 0$。\n因此，第一项为零，且 $\\mathbb{E}[\\psi_1] = \\mathbb{E}[m_1^\\star(X)] = \\mu_1$。如果结果模型正确，则该估计量对 $\\mu_1$ 是一致的，无论 $e(x)$ 的设定如何。\n\n**完整估计量**\n类似地，$\\mu_0 = \\mathbb{E}[Y(0)]$ 的分量为：\n$$\n\\psi_0(X, T, Y; m_0, e) = \\frac{(1-T)(Y - m_0(X))}{1-e(X)} + m_0(X)\n$$\n基于大小为 $n$ 的样本和估计的滋扰模型 $\\hat{m}_0, \\hat{m}_1, \\hat{e}$，ATE ($\\Delta = \\mu_1 - \\mu_0$) 的 AIPW 估计量是这些分量之差的样本均值：\n$$\n\\widehat{\\Delta}_{\\text{AIPW}} = \\frac{1}{n} \\sum_{i=1}^n (\\psi_{1,i} - \\psi_{0,i})\n$$\n$$\n\\widehat{\\Delta}_{\\text{AIPW}} = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\left(\\frac{T_i(Y_i - \\hat{m}_1(X_i))}{\\hat{e}(X_i)} + \\hat{m}_1(X_i)\\right) - \\left(\\frac{(1-T_i)(Y_i - \\hat{m}_0(X_i))}{1-\\hat{e}(X_i)} + \\hat{m}_0(X_i)\\right) \\right]\n$$\n\n#### 模拟与实现\n\n我们实现一个模拟来验证这些属性。该问题提供了一个数据生成过程，其中真实的结果模型是 $X$ 和 $T$ 的线性函数，而真实的倾向性得分遵循 logistic 模型。\n$Y = \\beta_0 + \\beta_1 X + \\tau T + \\varepsilon$。由此，真实的条件结果模型为：\n$m_1^\\star(x) = \\mathbb{E}[Y \\mid X=x, T=1] = \\beta_0 + \\beta_1 x + \\tau$\n$m_0^\\star(x) = \\mathbb{E}[Y \\mid X=x, T=0] = \\beta_0 + \\beta_1 x$\n\n-   **正确的结果模型**：我们将 $Y$ 对截距项、$T$ 和 $X$ 进行线性回归。该模型形式与真实的数据生成过程（DGP）相匹配，因此设定是正确的。系数将从数据中估计。根据带有系数 $(\\hat{\\beta}_0, \\hat{\\beta}_T, \\hat{\\beta}_X)$ 的拟合模型，估计的函数为 $\\hat{m}_1(x) = \\hat{\\beta}_0 + \\hat{\\beta}_T + \\hat{\\beta}_X x$ 和 $\\hat{m}_0(x) = \\hat{\\beta}_0 + \\hat{\\beta}_X x$。\n-   **错误设定的结果模型**：我们将 $Y$ 对截距项和 $T$ 进行线性回归，忽略了混杂因素 $X$。这是一个错误设定，因为真实结果依赖于 $X$（$\\beta_1 \\neq 0$），且 $X$ 与 $T$ 相关。估计的函数 $\\hat{m}_1(x)$ 和 $\\hat{m}_0(x)$ 将相对于 $x$ 是常数。\n-   **正确的倾向性得分模型**：我们使用真实的 logistic 函数形式及真实参数 $\\alpha$ 和 $c$，因此 $\\hat{e}(x) = e^\\star(x)$。在真实世界的场景中，这些参数将会被估计（例如，通过 logistic 回归），但在这里我们使用真实值来隔离模型设定的影响。\n-   **错误设定的倾向性得分模型**：我们使用一个常数模型，$\\hat{e}(x) = 0.5$，这是不正确的，因为真实的倾向性得分依赖于 $X$（$\\alpha \\neq 0$）。\n\n五个测试用例探讨了模型正确性的四种组合，外加一个边缘案例。\n-   测试 1、2 和 4 至少有一个正确设定的模型。由于双重稳健性属性，AIPW 估计量对于真实的 ATE ($\\tau$) 应该是近似无偏的。\n-   测试 3 中两个模型都被错误设定。一致性的条件未被满足，我们预计会出现显著的偏差。\n-   测试 5 使用一个更大的 $\\alpha$，这将真实的倾向性得分推向更接近 0 和 1 的位置，这可能对估计量构成挑战。然而，由于结果模型是正确的，双重稳健性仍然成立，偏差应该会保持很小。\n-   以下 Python 代码实现了这个模拟研究。对于每个测试用例，它模拟数据，按规定估计滋扰函数，计算 $\\Delta$ 的 AIPW 估计值，并计算相对于已知的真实 ATE ($\\tau$) 的偏差。",
            "answer": "```python\nimport numpy as np\n\ndef simulate_data(n, beta0, beta1, tau, sigma, alpha, c, seed):\n    \"\"\"\n    Simulates data according to the specified data generating process.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # Generate covariate X from a standard normal distribution\n    X = rng.normal(0, 1, n)\n    \n    # Calculate true propensity scores e*(X)\n    logit_e_star = alpha * X + c\n    e_star = 1 / (1 + np.exp(-logit_e_star))\n    \n    # Generate treatment assignment T from a Bernoulli distribution\n    T = rng.binomial(1, e_star, n)\n    \n    # Generate outcome Y\n    epsilon = rng.normal(0, sigma, n)\n    Y = beta0 + beta1 * X + tau * T + epsilon\n    \n    return X, T, Y\n\ndef fit_outcome_regression(X, T, Y, is_correct):\n    \"\"\"\n    Fits the outcome regression model (correctly or misspecified) and returns\n    predicted outcomes for T=0 and T=1.\n    \"\"\"\n    n = len(Y)\n    if is_correct:\n        # Correct specification: Y ~ intercept + T + X\n        A = np.vstack([np.ones(n), T, X]).T\n        # Solve Normal Equations (A'A)beta = A'Y for OLS coefficients\n        try:\n            coeffs = np.linalg.solve(A.T @ A, A.T @ Y)\n        except np.linalg.LinAlgError:\n            coeffs = np.linalg.pinv(A.T @ A) @ A.T @ Y\n            \n        b0_hat, bT_hat, bX_hat = coeffs\n        \n        # Predicted outcomes under T=1 and T=0\n        m1_hat = b0_hat + bT_hat * 1 + bX_hat * X\n        m0_hat = b0_hat + bT_hat * 0 + bX_hat * X\n    else:\n        # Misspecified: Y ~ intercept + T (omits confounder X)\n        A = np.vstack([np.ones(n), T]).T\n        try:\n            coeffs = np.linalg.solve(A.T @ A, A.T @ Y)\n        except np.linalg.LinAlgError:\n            coeffs = np.linalg.pinv(A.T @ A) @ A.T @ Y\n\n        b0_hat, bT_hat = coeffs\n        \n        # Predicted outcomes are constant with respect to X\n        m1_hat = np.full(n, b0_hat + bT_hat * 1)\n        m0_hat = np.full(n, b0_hat + bT_hat * 0)\n        \n    return m0_hat, m1_hat\n\ndef get_propensity_scores(X, is_correct, alpha, c):\n    \"\"\"\n    Returns the propensity scores (correctly or misspecified).\n    \"\"\"\n    if is_correct:\n        # Use the true propensity score function with true parameters\n        logit_e = alpha * X + c\n        e_hat = 1 / (1 + np.exp(-logit_e))\n    else:\n        # Misspecified as a constant\n        e_hat = np.full(len(X), 0.5)\n        \n    return e_hat\n\ndef calculate_aipw_estimate(T, Y, m0_hat, m1_hat, e_hat):\n    \"\"\"\n    Calculates the AIPW estimate of the Average Treatment Effect (ATE).\n    \"\"\"\n    # Component for E[Y(1)]\n    psi1 = (T * (Y - m1_hat)) / e_hat + m1_hat\n    \n    # Component for E[Y(0)]\n    psi0 = ((1 - T) * (Y - m0_hat)) / (1 - e_hat) + m0_hat\n    \n    # AIPW estimate is the sample average of the difference\n    aipw_est = np.mean(psi1 - psi0)\n    \n    return aipw_est\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (n, beta0, beta1, tau, sigma, alpha, c, outcome_correct, propensity_correct, seed)\n        (50000, 2.0, 1.0, 3.0, 1.0, 1.2, -0.2, True, False, 123), # Test 1\n        (50000, 2.0, 1.0, 3.0, 1.0, 1.2, -0.2, False, True, 456), # Test 2\n        (50000, 2.0, 1.0, 3.0, 1.0, 1.2, -0.2, False, False, 789), # Test 3\n        (50000, 2.0, 1.0, 3.0, 1.0, 1.2, -0.2, True, True, 321), # Test 4\n        (50000, 2.0, 1.0, 3.0, 1.0, 4.0, 0.0, True, False, 654), # Test 5\n    ]\n    \n    results = []\n    \n    for case in test_cases:\n        n, beta0, beta1, tau, sigma, alpha, c, outcome_correct, propensity_correct, seed = case\n        \n        # 1. Simulate data from the DGP\n        X, T, Y = simulate_data(n, beta0, beta1, tau, sigma, alpha, c, seed)\n        \n        # 2. Estimate nuisance functions based on test case specification\n        m0_hat, m1_hat = fit_outcome_regression(X, T, Y, outcome_correct)\n        e_hat = get_propensity_scores(X, propensity_correct, alpha, c)\n        \n        # 3. Calculate the AIPW estimate of the ATE\n        aipw_estimate = calculate_aipw_estimate(T, Y, m0_hat, m1_hat, e_hat)\n        \n        # 4. Calculate and store the bias\n        bias = aipw_estimate - tau\n        results.append(f\"{bias:.6f}\")\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在许多科学探索中，我们不仅关心处理措施的总因果效应，更渴望揭示其背后的作用机制。本练习将带你进入中介分析的世界，学习如何将总效应分解为处理直接产生的“直接效应”，以及通过一个或多个中介变量传递的“间接效应”。你将运用强大的 g-计算（g-computation）公式，在一个包含时序混淆的复杂因果系统中推导并计算这些效应，从而对因果路径获得更深刻的洞察。",
            "id": "3106705",
            "problem": "考虑一个结构因果模型（SCM），其特征是随机变量 $X$（一个基线协变量）、$T$（在时间 $t_0$ 的一个二元处理）、$L$（在时间 $t_1$ 测量的一个处理后的中间混杂因子）、$M$（在时间 $t_2$ 测量的一个中介变量）和 $Y$（在时间 $t_3$ 的一个结果）。处理 $T$ 是通过观察分配的，并受到 $X$ 的混杂。中介变量 $M$ 和结果 $Y$ 都受到 $X$ 的影响，并且存在通过 $L$ 的中间混杂，其中 $L$ 受到 $T$ 和 $X$ 的影响，并反过来影响 $M$ 和 $Y$。假设以下具有线性高斯结构方程和逻辑斯蒂处理分配的数据生成过程：\n$$\nX \\sim \\mathcal{N}(\\mu_X, \\sigma_X^2),\n$$\n$$\n\\Pr(T = 1 \\mid X) = \\operatorname{logit}^{-1}(\\eta_0 + \\eta_1 X),\n$$\n$$\nL \\mid T, X \\sim \\mathcal{N}(\\alpha_0 + \\alpha_1 T + \\alpha_2 X, \\sigma_L^2),\n$$\n$$\nM \\mid T, X, L \\sim \\mathcal{N}(\\beta_0 + \\beta_1 T + \\beta_2 X + \\beta_3 L, \\sigma_M^2),\n$$\n$$\nY \\mid T, M, X, L \\sim \\mathcal{N}(\\gamma_0 + \\gamma_1 T + \\gamma_2 M + \\gamma_3 X + \\gamma_4 L, \\sigma_Y^2).\n$$\n目标是使用 g-计算公式（G-formula）来识别干预下的因果估计量。定义 do-算子干预如下：\n- 静态处理干预 $\\operatorname{do}(T = t)$，将 $T$ 设置为 $t \\in \\{0, 1\\}$。\n- 一个随机中介干预，在以 $X$ 和 $L$ 为条件时，从 $M$ 在 $\\operatorname{do}(T = t')$（其中 $t' \\in \\{0, 1\\}$）下应有的分布中抽取 $M$，同时保持 $L$ 是在 $\\operatorname{do}(T = t)$ 下生成的。\n\n在这些干预下，定义干预均值\n$$\n\\mathbb{E}[Y(t, t')] = \\mathbb{E}_X \\left[ \\mathbb{E}_{L \\mid \\operatorname{do}(T=t), X} \\left[ \\mathbb{E}_{M \\mid \\operatorname{do}(T=t'), X, L} \\left[ \\mathbb{E}[Y \\mid \\operatorname{do}(T=t), M, X, L] \\right] \\right] \\right],\n$$\n其中 $\\mathbb{E}[\\cdot]$ 表示期望，嵌套的期望是相对于 SCM 所蕴含的相应干预分布来计算的。\n\n任务：\n1.  仅从 SCM、do-算子的定义和 g-计算公式（G-formula）出发，推导在 $\\operatorname{do}(T = t)$ 干预下的 $\\mathbb{E}[Y(t)]$ 和在组合干预（其中 $T$ 被设置为 $t$，$M$ 从其在 $\\operatorname{do}(T = t')$ 下应有的分布中抽取，而 $L$ 在 $\\operatorname{do}(T = t)$ 下生成）下的 $\\mathbb{E}[Y(t, t')]$ 的闭式表达式。\n2.  使用这些闭式表达式，考虑以下干预效应：\n    -   平均处理效应（ATE）：$\\mathbb{E}[Y(1, 1)] - \\mathbb{E}[Y(0, 0)]$。\n    -   干预直接效应（IDE）：$\\mathbb{E}[Y(1, 0)] - \\mathbb{E}[Y(0, 0)]$。\n    -   干预间接效应（IIE）：$\\mathbb{E}[Y(1, 1)] - \\mathbb{E}[Y(1, 0)]$。\n    证明对于此 SCM，有 $\\text{ATE} = \\text{IDE} + \\text{IIE}$。\n3.  实现一个程序，对每个指定的参数集，使用推导出的闭式表达式计算包含五个浮点数的列表\n    $$\n    \\left[\\mathbb{E}[Y(1, 1)],\\ \\mathbb{E}[Y(0, 0)],\\ \\text{IDE},\\ \\text{IIE},\\ \\text{ATE}\\right]\n    $$\n\n使用以下参数值的测试套件（注意：方差 $\\sigma_X^2$、$\\sigma_L^2$、$\\sigma_M^2$、$\\sigma_Y^2$ 和处理分配参数 $\\eta_0$、$\\eta_1$ 在此线性高斯设置中不影响干预均值，仅为科学完整性而包含）：\n- 测试用例1（一般情况，存在基线混杂）：\n  $$\n  \\mu_X = 0.5,\\ \n  \\alpha_0 = 0.1,\\ \\alpha_1 = 0.8,\\ \\alpha_2 = 0.3,\\\n  \\beta_0 = 0.2,\\ \\beta_1 = 0.9,\\ \\beta_2 = 0.4,\\ \\beta_3 = 0.5,\\\n  \\gamma_0 = 0.0,\\ \\gamma_1 = 0.3,\\ \\gamma_2 = 1.2,\\ \\gamma_3 = 0.6,\\ \\gamma_4 = 0.7.\n  $$\n- 测试用例2（中介变量对结果没有影响）：\n  $$\n  \\mu_X = -0.2,\\ \n  \\alpha_0 = 0.0,\\ \\alpha_1 = 0.5,\\ \\alpha_2 = 0.2,\\\n  \\beta_0 = 0.1,\\ \\beta_1 = 0.7,\\ \\beta_2 = 0.3,\\ \\beta_3 = 0.6,\\\n  \\gamma_0 = 0.0,\\ \\gamma_1 = 0.4,\\ \\gamma_2 = 0.0,\\ \\gamma_3 = 0.5,\\ \\gamma_4 = 0.6.\n  $$\n- 测试用例3（处理对结果没有直接影响，但存在强的中间混杂和中介效应）：\n  $$\n  \\mu_X = 1.0,\\ \n  \\alpha_0 = 0.2,\\ \\alpha_1 = 1.0,\\ \\alpha_2 = 0.1,\\\n  \\beta_0 = 0.0,\\ \\beta_1 = 1.0,\\ \\beta_2 = 0.5,\\ \\beta_3 = 0.8,\\\n  \\gamma_0 = 0.0,\\ \\gamma_1 = 0.0,\\ \\gamma_2 = 1.0,\\ \\gamma_3 = 0.3,\\ \\gamma_4 = 0.9.\n  $$\n- 测试用例4（边界情况，$M$ 和 $Y$ 中没有基线混杂）：\n  $$\n  \\mu_X = 0.0,\\ \n  \\alpha_0 = 0.3,\\ \\alpha_1 = 0.2,\\ \\alpha_2 = 0.0,\\\n  \\beta_0 = 0.5,\\ \\beta_1 = 0.5,\\ \\beta_2 = 0.0,\\ \\beta_3 = 0.4,\\\n  \\gamma_0 = 0.0,\\ \\gamma_1 = 0.2,\\ \\gamma_2 = 0.8,\\ \\gamma_3 = 0.0,\\ \\gamma_4 = 0.3.\n  $$\n\n你的程序应生成单行输出，按顺序包含每个测试用例的五个浮点数列表\n$\n\\left[\\mathbb{E}[Y(1, 1)],\\ \\mathbb{E}[Y(0, 0)],\\ \\text{IDE},\\ \\text{IIE},\\ \\text{ATE}\\right]\n$\n并将这些每个测试用例的列表聚合成一个用方括号括起来的、以逗号分隔的列表。例如，输出应如下所示\n$\n\\big[\\,[\\cdots],\\,[\\cdots],\\,[\\cdots],\\,[\\cdots]\\,\\big]\n$\n不带任何附加文本。",
            "solution": "该问题是有效的，因为它科学地基于已建立的结构因果模型（SCM）框架，通过一套完整的线性高斯结构方程使其成为一个适定的问题，并以客观、数学的精度进行表达。它提出了一个因果推断中可解的问题，没有任何内部矛盾、歧义或对非科学前提的依赖。因此，我们可以进行推导和求解。\n\n主要目标是使用 g-计算公式推导干预均值 $\\mathbb{E}[Y(t, t')]$ 及相关因果效应的闭式表达式。SCM 由以下结构方程定义，其中所有误差项都是独立的，并且服从零均值的正态分布：\n$$\nX = \\mu_X + \\epsilon_X\n$$\n$$\nL = \\alpha_0 + \\alpha_1 T + \\alpha_2 X + \\epsilon_L\n$$\n$$\nM = \\beta_0 + \\beta_1 T + \\beta_2 X + \\beta_3 L + \\epsilon_M\n$$\n$$\nY = \\gamma_0 + \\gamma_1 T + \\gamma_2 M + \\gamma_3 X + \\gamma_4 L + \\epsilon_Y\n$$\n处理分配机制 $\\Pr(T = 1 \\mid X) = \\operatorname{logit}^{-1}(\\eta_0 + \\eta_1 X)$ 是观察性的，但 g-计算公式通过 do-算子模拟干预，替代了这一机制，使其参数与干预均值的计算无关。同样，方差 $\\sigma_X^2$、$\\sigma_L^2$、$\\sigma_M^2$ 和 $\\sigma_Y^2$ 在这个线性系统中不影响期望值。\n\n### 任务1：闭式表达式的推导\n\n我们被要求计算定义如下的干预均值：\n$$\n\\mathbb{E}[Y(t, t')] = \\mathbb{E}_X \\left[ \\mathbb{E}_{L \\mid \\operatorname{do}(T=t), X} \\left[ \\mathbb{E}_{M \\mid \\operatorname{do}(T=t'), X, L} \\left[ \\mathbb{E}[Y \\mid \\operatorname{do}(T=t), M, X, L] \\right] \\right] \\right]\n$$\n我们通过从内到外评估嵌套期望来进行，应用 do-演算的规则，这在 SCM 中对应于替换被干预变量的结构方程。\n\n**步骤1：最内层期望**\n最内层的期望是关于 $Y$ 的分布。$Y$ 的结构方程是 $Y = \\gamma_0 + \\gamma_1 T + \\gamma_2 M + \\gamma_3 X + \\gamma_4 L + \\epsilon_Y$。在干预 $\\operatorname{do}(T=t)$ 下，变量 $T$ 被固定为值 $t$。因此，条件期望是：\n$$\n\\mathbb{E}[Y \\mid \\operatorname{do}(T=t), M, X, L] = \\gamma_0 + \\gamma_1 t + \\gamma_2 M + \\gamma_3 X + \\gamma_4 L\n$$\n\n**步骤2：对中介变量 $M$ 的期望**\n下一步是对步骤1的结果，关于在干预 $\\operatorname{do}(T=t')$ 下 $M$ 的分布（以 $X$ 和 $L$ 为条件）取期望。$M$ 的结构方程变为 $M = \\beta_0 + \\beta_1 t' + \\beta_2 X + \\beta_3 L + \\epsilon_M$。$M$ 的条件期望是：\n$$\n\\mathbb{E}[M \\mid \\operatorname{do}(T=t'), X, L] = \\beta_0 + \\beta_1 t' + \\beta_2 X + \\beta_3 L\n$$\n利用期望的线性性质，我们将其代入步骤1的表达式中：\n$$\n\\mathbb{E}_{M \\mid \\operatorname{do}(T=t'), X, L} \\left[ \\gamma_0 + \\gamma_1 t + \\gamma_2 M + \\gamma_3 X + \\gamma_4 L \\right] \\\\\n= \\gamma_0 + \\gamma_1 t + \\gamma_2 \\mathbb{E}[M \\mid \\operatorname{do}(T=t'), X, L] + \\gamma_3 X + \\gamma_4 L \\\\\n= \\gamma_0 + \\gamma_1 t + \\gamma_2 (\\beta_0 + \\beta_1 t' + \\beta_2 X + \\beta_3 L) + \\gamma_3 X + \\gamma_4 L\n$$\n展开并合并各项：\n$$\n= (\\gamma_0 + \\gamma_2 \\beta_0) + \\gamma_1 t + \\gamma_2 \\beta_1 t' + (\\gamma_3 + \\gamma_2 \\beta_2) X + (\\gamma_4 + \\gamma_2 \\beta_3) L\n$$\n\n**步骤3：对中间混杂因子 $L$ 的期望**\n我们现在对前一个结果，关于在干预 $\\operatorname{do}(T=t)$ 下 $L$ 的分布（以 $X$ 为条件）取期望。$L$ 的结构方程变为 $L = \\alpha_0 + \\alpha_1 t + \\alpha_2 X + \\epsilon_L$。$L$ 的条件期望是：\n$$\n\\mathbb{E}[L \\mid \\operatorname{do}(T=t), X] = \\alpha_0 + \\alpha_1 t + \\alpha_2 X\n$$\n将其代入步骤2的表达式中：\n$$\n\\mathbb{E}_{L \\mid \\operatorname{do}(T=t), X} \\left[ (\\gamma_0 + \\gamma_2 \\beta_0) + \\gamma_1 t + \\gamma_2 \\beta_1 t' + (\\gamma_3 + \\gamma_2 \\beta_2) X + (\\gamma_4 + \\gamma_2 \\beta_3) L \\right] \\\\\n= (\\gamma_0 + \\gamma_2 \\beta_0) + \\gamma_1 t + \\gamma_2 \\beta_1 t' + (\\gamma_3 + \\gamma_2 \\beta_2) X + (\\gamma_4 + \\gamma_2 \\beta_3) \\mathbb{E}[L \\mid \\operatorname{do}(T=t), X] \\\\\n= (\\gamma_0 + \\gamma_2 \\beta_0) + \\gamma_1 t + \\gamma_2 \\beta_1 t' + (\\gamma_3 + \\gamma_2 \\beta_2) X + (\\gamma_4 + \\gamma_2 \\beta_3) (\\alpha_0 + \\alpha_1 t + \\alpha_2 X)\n$$\n\n**步骤4：对基线协变量 $X$ 的期望**\n最后一步是关于 $X$ 的边际分布取期望。我们已知 $X \\sim \\mathcal{N}(\\mu_X, \\sigma_X^2)$，所以 $\\mathbb{E}[X] = \\mu_X$。我们对步骤3的整个表达式取期望：\n$$\n\\mathbb{E}[Y(t, t')] = \\mathbb{E}_X \\left[ (\\gamma_0 + \\gamma_2 \\beta_0) + \\gamma_1 t + \\gamma_2 \\beta_1 t' + (\\gamma_3 + \\gamma_2 \\beta_2) X + (\\gamma_4 + \\gamma_2 \\beta_3) (\\alpha_0 + \\alpha_1 t + \\alpha_2 X) \\right]\n$$\n展开并应用期望的线性性质：\n$$\n\\mathbb{E}[Y(t, t')] = (\\gamma_0 + \\gamma_2 \\beta_0) + \\gamma_1 t + \\gamma_2 \\beta_1 t' + (\\gamma_3 + \\gamma_2 \\beta_2) \\mathbb{E}[X] + (\\gamma_4 + \\gamma_2 \\beta_3) (\\alpha_0 + \\alpha_1 t + \\alpha_2 \\mathbb{E}[X])\n$$\n代入 $\\mathbb{E}[X] = \\mu_X$ 并根据常数、$t$、$t'$ 和 $\\mu_X$ 重新组合项：\n$$\n\\mathbb{E}[Y(t, t')] = (\\gamma_0 + \\gamma_2 \\beta_0 + \\alpha_0(\\gamma_4 + \\gamma_2 \\beta_3)) + \\mu_X(\\gamma_3 + \\gamma_2 \\beta_2 + \\alpha_2(\\gamma_4 + \\gamma_2 \\beta_3)) + t(\\gamma_1 + \\alpha_1(\\gamma_4 + \\gamma_2 \\beta_3)) + t'(\\gamma_2 \\beta_1)\n$$\n这是 $\\mathbb{E}[Y(t, t')]$ 的闭式表达式。\n\n在简单静态干预下的潜在结果均值 $\\mathbb{E}[Y(t)]$ 是 $t' = t$ 的特例：\n$$\n\\mathbb{E}[Y(t)] = \\mathbb{E}[Y(t, t)] = (\\gamma_0 + \\gamma_2 \\beta_0 + \\alpha_0(\\gamma_4 + \\gamma_2 \\beta_3)) + \\mu_X(\\gamma_3 + \\gamma_2 \\beta_2 + \\alpha_2(\\gamma_4 + \\gamma_2 \\beta_3)) + t(\\gamma_1 + \\alpha_1(\\gamma_4 + \\gamma_2 \\beta_3) + \\gamma_2 \\beta_1)\n$$\n\n### 任务2：因果效应及其分解的推导\n\n我们使用推导出的 $\\mathbb{E}[Y(t, t')]$ 表达式来找到平均处理效应（ATE）、干预直接效应（IDE）和干预间接效应（IIE）。\n\n为简单起见，我们将一般表达式表示为：\n$$\n\\mathbb{E}[Y(t, t')] = C_0 + C_1 t + C_2 t'\n$$\n其中\n$C_0 = (\\gamma_0 + \\gamma_2 \\beta_0 + \\alpha_0(\\gamma_4 + \\gamma_2 \\beta_3)) + \\mu_X(\\gamma_3 + \\gamma_2 \\beta_2 + \\alpha_2(\\gamma_4 + \\gamma_2 \\beta_3))$ 是一个与 $t$ 和 $t'$ 无关的常数项。\n$C_1 = \\gamma_1 + \\alpha_1(\\gamma_4 + \\gamma_2 \\beta_3)$ 是 $t$ 的系数。\n$C_2 = \\gamma_2 \\beta_1$ 是 $t'$ 的系数。\n\n**平均处理效应 (ATE):**\nATE 定义为 $\\mathbb{E}[Y(1, 1)] - \\mathbb{E}[Y(0, 0)]$。\n$$\n\\mathbb{E}[Y(1, 1)] = C_0 + C_1(1) + C_2(1) = C_0 + C_1 + C_2\n$$\n$$\n\\mathbb{E}[Y(0, 0)] = C_0 + C_1(0) + C_2(0) = C_0\n$$\n$$\n\\text{ATE} = (C_0 + C_1 + C_2) - C_0 = C_1 + C_2 = (\\gamma_1 + \\alpha_1(\\gamma_4 + \\gamma_2 \\beta_3)) + (\\gamma_2 \\beta_1)\n$$\n\n**干预直接效应 (IDE):**\nIDE 定义为 $\\mathbb{E}[Y(1, 0)] - \\mathbb{E}[Y(0, 0)]$。这衡量了在将中介变量 $M$ 设置为如果 $T$ 为 $0$ 时它本应有的值的情况下，将 $T$ 从 $0$ 变为 $1$ 的效应。\n$$\n\\mathbb{E}[Y(1, 0)] = C_0 + C_1(1) + C_2(0) = C_0 + C_1\n$$\n$$\n\\text{IDE} = (C_0 + C_1) - C_0 = C_1 = \\gamma_1 + \\alpha_1(\\gamma_4 + \\gamma_2 \\beta_3)\n$$\n\n**干预间接效应 (IIE):**\nIIE 定义为 $\\mathbb{E}[Y(1, 1)] - \\mathbb{E}[Y(1, 0)]$。这衡量了在保持实际处理恒定为 $T=1$ 的情况下，将中介变量的控制从 $T=0$ 下的状态改变为 $T=1$ 下的状态的效应。\n$$\n\\mathbb{E}[Y(1, 1)] = C_0 + C_1 + C_2\n$$\n$$\n\\mathbb{E}[Y(1, 0)] = C_0 + C_1\n$$\n$$\n\\text{IIE} = (C_0 + C_1 + C_2) - (C_0 + C_1) = C_2 = \\gamma_2 \\beta_1\n$$\n\n**分解证明:**\n我们必须证明 $\\text{ATE} = \\text{IDE} + \\text{IIE}$。\n$$\n\\text{IDE} + \\text{IIE} = C_1 + C_2\n$$\n如前所示，$\\text{ATE} = C_1 + C_2$。因此，对于此 SCM 和这些效应定义，分解 $\\text{ATE} = \\text{IDE} + \\text{IIE}$ 成立。\n\n### 任务3：实现\n现在将实施推导出的闭式表达式，以计算给定参数集的所需估计量。用于实现的关键公式是：\n- $\\mathbb{E}[Y(0, 0)] = C_0$\n- $\\mathbb{E}[Y(1, 1)] = C_0 + C_1 + C_2$\n- $\\text{IDE} = C_1$\n- $\\text{IIE} = C_2$\n- $\\text{ATE} = C_1 + C_2$\n其中 $C_0$、$C_1$ 和 $C_2$ 是如上推导的结构参数的函数。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes causal effects for an SCM with intermediate confounding using derived closed-form expressions.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (general case, baseline confounding present)\n        {\n            \"mu_X\": 0.5, \"alpha_0\": 0.1, \"alpha_1\": 0.8, \"alpha_2\": 0.3,\n            \"beta_0\": 0.2, \"beta_1\": 0.9, \"beta_2\": 0.4, \"beta_3\": 0.5,\n            \"gamma_0\": 0.0, \"gamma_1\": 0.3, \"gamma_2\": 1.2, \"gamma_3\": 0.6, \"gamma_4\": 0.7\n        },\n        # Test case 2 (mediator has no effect on outcome)\n        {\n            \"mu_X\": -0.2, \"alpha_0\": 0.0, \"alpha_1\": 0.5, \"alpha_2\": 0.2,\n            \"beta_0\": 0.1, \"beta_1\": 0.7, \"beta_2\": 0.3, \"beta_3\": 0.6,\n            \"gamma_0\": 0.0, \"gamma_1\": 0.4, \"gamma_2\": 0.0, \"gamma_3\": 0.5, \"gamma_4\": 0.6\n        },\n        # Test case 3 (no direct effect of treatment on outcome)\n        {\n            \"mu_X\": 1.0, \"alpha_0\": 0.2, \"alpha_1\": 1.0, \"alpha_2\": 0.1,\n            \"beta_0\": 0.0, \"beta_1\": 1.0, \"beta_2\": 0.5, \"beta_3\": 0.8,\n            \"gamma_0\": 0.0, \"gamma_1\": 0.0, \"gamma_2\": 1.0, \"gamma_3\": 0.3, \"gamma_4\": 0.9\n        },\n        # Test case 4 (edge case with no baseline confounding in M and Y)\n        {\n            \"mu_X\": 0.0, \"alpha_0\": 0.3, \"alpha_1\": 0.2, \"alpha_2\": 0.0,\n            \"beta_0\": 0.5, \"beta_1\": 0.5, \"beta_2\": 0.0, \"beta_3\": 0.4,\n            \"gamma_0\": 0.0, \"gamma_1\": 0.2, \"gamma_2\": 0.8, \"gamma_3\": 0.0, \"gamma_4\": 0.3\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        # Unpack parameters for readability\n        mu_X = params[\"mu_X\"]\n        alpha_0, alpha_1, alpha_2 = params[\"alpha_0\"], params[\"alpha_1\"], params[\"alpha_2\"]\n        beta_0, beta_1, beta_2, beta_3 = params[\"beta_0\"], params[\"beta_1\"], params[\"beta_2\"], params[\"beta_3\"]\n        gamma_0, gamma_1, gamma_2, gamma_3, gamma_4 = params[\"gamma_0\"], params[\"gamma_1\"], params[\"gamma_2\"], params[\"gamma_3\"], params[\"gamma_4\"]\n\n        # The derived formula for E[Y(t, t')] is of the form: C0 + C1*t + C2*t'\n        # C1 corresponds to the IDE, C2 corresponds to the IIE.\n\n        # Calculate IIE (C2)\n        # This is the effect path T -> M -> Y, coefficient gamma_2 * beta_1\n        iie = gamma_2 * beta_1\n\n        # Calculate an intermediate term for IDE (C1) and the constant part (C0)\n        # This term represents the total effect of L on Y, both directly and through M.\n        l_effect_on_y = gamma_4 + gamma_2 * beta_3\n\n        # Calculate IDE (C1)\n        # This is the effect of T on Y not mediated by the direct T->M path.\n        # It includes the direct T->Y path and the path T->L->Y (and T->L->M->Y).\n        ide = gamma_1 + alpha_1 * l_effect_on_y\n\n        # Calculate ATE\n        ate = ide + iie\n\n        # Calculate the constant part of the expectation (C0)\n        # This corresponds to E[Y(0, 0)]\n        constant_intercepts = gamma_0 + gamma_2 * beta_0 + alpha_0 * l_effect_on_y\n        constant_from_x = mu_X * (gamma_3 + gamma_2 * beta_2 + alpha_2 * l_effect_on_y)\n        e_y_00 = constant_intercepts + constant_from_x\n\n        # Calculate E[Y(1, 1)]\n        e_y_11 = e_y_00 + ate\n        \n        # Assemble the list of results for the current test case\n        case_result = [e_y_11, e_y_00, ide, iie, ate]\n        results.append(case_result)\n\n    # Format the final output as a comma-separated list of lists\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}