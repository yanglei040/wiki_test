{
    "hands_on_practices": [
        {
            "introduction": "主动学习的有效性通常取决于我们如何定义和衡量“不确定性”。本练习通过比较两种基本策略——最小置信度采样和边际采样——来深入探讨这个问题。通过分析它们在二分类和多分类场景下的行为，您将对这些度量方法的差异以及为何针对特定问题选择合适的度量至关重要建立更深刻的直觉。",
            "id": "3095044",
            "problem": "一个概率多类分类器为每个输入 $x$ 生成一个在有限标签集 $\\mathcal{Y}$ 上的类后验概率 $p(y \\mid x)$，满足 $\\sum_{y \\in \\mathcal{Y}} p(y \\mid x) = 1$ 和 $p(y \\mid x) \\in [0,1]$。在主动学习 (AL) 中，不确定性采样根据一个不确定性得分来选择 $x$。两种常见的不确定性得分是最小置信度得分和边际得分，它们使用后验概率的顺序统计量来定义。令 $p_{(1)}(x) = \\max_{y \\in \\mathcal{Y}} p(y \\mid x)$ 表示最大的后验概率，$p_{(2)}(x)$ 表示第二大的后验概率。最小置信度 (LC) 采样选择使 $u_{\\mathrm{LC}}(x) = 1 - p_{(1)}(x)$ 最大化的 $x$，而边际采样 (MS) 选择使 $u_{\\mathrm{margin}}(x) = p_{(1)}(x) - p_{(2)}(x)$ 最小化的 $x$。\n\n仅从这些定义以及后验概率非负且总和为 $1$ 的事实出发，推断这两种选择规则在何种情况下会产生相同的选择。具体来说，确定它们在二元分类（$K=2$ 个类别）中是否等价，以及在多类设置（$K2$）中是否可能产生分歧。然后，对于一个 $K=3$ 且 $\\mathcal{Y} = \\{1,2,3\\}$ 的设置，考虑两个具有以下后验向量的未标记点\n- $x_A$: $(p(1 \\mid x_A), p(2 \\mid x_A), p(3 \\mid x_A)) = (\\,0.60,\\,0.39,\\,0.01\\,)$,\n- $x_B$: $(p(1 \\mid x_B), p(2 \\mid x_B), p(3 \\mid x_B)) = (\\,0.51,\\,0.26,\\,0.23\\,)$.\n\n使用不确定性的定义计算 $x_A$ 和 $x_B$ 的 $u_{\\mathrm{LC}}(x)$ 和 $u_{\\mathrm{margin}}(x)$，并确定每种策略会选择哪个点。\n\n哪个选项是正确的？\n\nA. 在二元分类（$K=2$）中，最小置信度和边际采样总是选择相同的点；在 $K=3$ 的例子中，最小置信度选择 $x_B$，边际采样选择 $x_A$。\n\nB. 在二元分类（$K=2$）中，最小置信度和边际采样可能不一致；在 $K=3$ 的例子中，两种策略都选择 $x_B$。\n\nC. 在二元分类（$K=2$）中，两种策略仅在 $p_{(1)}(x) = \\tfrac{1}{2}$ 时一致；在 $K=3$ 的例子中，最小置信度选择 $x_A$，边际采样选择 $x_B$。\n\nD. 对于任意数量的类别（$K \\ge 2$），最小置信度和边际采样总是达成一致；在 $K=3$ 的例子中，两种策略都选择 $x_A$。",
            "solution": "首先验证问题陈述的合理性和完整性。\n\n### 步骤 1：提取已知条件\n- 一个概率多类分类器为输入 $x$ 在大小为 $K = |\\mathcal{Y}|$ 的标签集 $\\mathcal{Y}$ 上生成类后验概率 $p(y \\mid x)$。\n- 后验概率满足 $\\sum_{y \\in \\mathcal{Y}} p(y \\mid x) = 1$ 和 $p(y \\mid x) \\in [0,1]$。\n- 定义了后验概率的顺序统计量：$p_{(1)}(x) = \\max_{y \\in \\mathcal{Y}} p(y \\mid x)$ (最大值) 和 $p_{(2)}(x)$ (第二大值)。\n- 最小置信度 (LC) 采样选择最大化得分 $u_{\\mathrm{LC}}(x) = 1 - p_{(1)}(x)$ 的未标记点 $x$。\n- 边际采样 (MS) 选择最小化得分 $u_{\\mathrm{margin}}(x) = p_{(1)}(x) - p_{(2)}(x)$ 的未标记点 $x$。\n- 问题要求分析这两种规则在二元分类（$K=2$）和多类分类（$K2$）中的等价性。\n- 对于一个 $K=3$ 的场景，其中 $\\mathcal{Y} = \\{1,2,3\\}$，给出了两个特定的未标记点：\n  - $x_A$ 的后验向量为 $(p(1 \\mid x_A), p(2 \\mid x_A), p(3 \\mid x_A)) = (0.60, 0.39, 0.01)$。\n  - $x_B$ 的后验向量为 $(p(1 \\mid x_B), p(2 \\mid x_B), p(3 \\mid x_B)) = (0.51, 0.26, 0.23)$。\n- 任务是确定每种策略会从这对点 $\\{x_A, x_B\\}$ 中选择哪一个。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准对问题进行评估。\n- **科学依据：** 该问题基于机器学习中已确立的标准概念，特别是在主动学习的子领域。最小置信度和边际采样的定义是规范的。\n- **问题定义良好：** 问题定义清晰。目标是基于两种选择规则的正式定义来比较它们，并将这些规则应用于一个具体的数值例子。唯一且有意义的解的存在性是有保证的。\n- **客观性：** 问题以精确的数学语言陈述，没有主观性或歧义。\n- **完整性和一致性：** 提供了所有必要的定义和数据。给定示例的后验概率总和正确地为 $1$。没有矛盾之处。\n\n### 步骤 3：结论与行动\n问题陈述有效。这是一个在统计学习领域内定义良好、科学合理的问题。下面将进行求解。\n\n### 求解过程\n\n求解过程按要求分为三部分：二元分类分析、一般多类情况分析，以及对特定 $K=3$ 示例的应用。\n\n**第 1 部分：二元分类（$K=2$）分析**\n\n设类别集为 $\\mathcal{Y} = \\{y_1, y_2\\}$。对于任何输入 $x$，后验概率为 $p(y_1 \\mid x)$ 和 $p(y_2 \\mid x)$。\n根据总和为一的性质，我们有 $p(y_1 \\mid x) + p(y_2 \\mid x) = 1$。\n不失一般性，我们假设 $p(y_1 \\mid x) \\ge p(y_2 \\mid x)$。这意味着 $p(y_1 \\mid x) \\ge 0.5$。\n根据定义，第一大和第二大的后验概率为：\n$p_{(1)}(x) = p(y_1 \\mid x)$\n$p_{(2)}(x) = p(y_2 \\mid x) = 1 - p(y_1 \\mid x)$\n\n现在，我们分析选择规则。\n1.  **最小置信度 (LC) 采样：** LC 选择最大化 $u_{\\mathrm{LC}}(x) = 1 - p_{(1)}(x)$ 的点 $x$。最大化 $1 - p_{(1)}(x)$ 等价于最小化 $p_{(1)}(x)$。所以，LC 选择 $\\arg\\min_x p_{(1)}(x)$。该策略寻找分类器对其最可能预测最不确定的点。\n\n2.  **边际采样 (MS)：** MS 选择最小化 $u_{\\mathrm{margin}}(x) = p_{(1)}(x) - p_{(2)}(x)$ 的点 $x$。在二元情况下代入 $p_{(2)}(x)$ 的表达式：\n    $$u_{\\mathrm{margin}}(x) = p_{(1)}(x) - (1 - p_{(1)}(x)) = 2p_{(1)}(x) - 1$$\n    所以，MS 选择 $\\arg\\min_x (2p_{(1)}(x) - 1)$。\n\n为了比较这两种策略，我们比较它们优化的目标函数。LC 最小化 $p_{(1)}(x)$，而 MS 最小化 $2p_{(1)}(x) - 1$。\n函数 $f(z) = 2z - 1$ 是 $z$ 的一个严格递增的线性变换。因此，对于任何点集，最小化 $p_{(1)}(x)$ 的点也正是最小化 $2p_{(1)}(x) - 1$ 的点。\n例如，如果我们在 $x_i$ 和 $x_j$ 之间选择，且 $p_{(1)}(x_i)  p_{(1)}(x_j)$，那么 $2p_{(1)}(x_i) - 1  2p_{(1)}(x_j) - 1$ 也成立。两种策略都会偏好 $x_i$。\n因此，在这两种标准下，所有候选点的排序是相同的，它们将始终选择相同的点。问题陈述的第一部分得以确立：在二元分类中，LC 和 MS 是等价的选择策略。\n\n**第 2 部分：多类设置（$K2$）中的分歧**\n\n对于 $K  2$，$p_{(2)}(x)$ 不再是 $p_{(1)}(x)$ 的一个简单函数。总和为一的约束是 $\\sum_{i=1}^K p_{(i)}(x) = 1$，其中 $p_{(i)}(x)$ 是有序的后验概率。这意味着 $p_{(2)}(x)$ 可以独立于 $p_{(1)}(x)$ 变化（在某些约束内）。\n- LC 采样仍然选择 $\\arg\\min_x p_{(1)}(x)$。这种策略是短视的，因为它只考虑对首选的置信度，而忽略了概率在其他类别中的分布。\n- MS 采样选择 $\\arg\\min_x (p_{(1)}(x) - p_{(2)}(x))$。这种策略明确地考虑了两个最可能类别之间的模糊性。\n\n如果一个点具有较低的 $p_{(1)}$（受 LC 青睐），而另一个点具有较小的边际 $p_{(1)}-p_{(2)}$（受 MS 青睐），则可能出现分歧。所提供的 $K=3$ 示例将用于证明这种分歧。\n\n**第 3 部分：$K=3$ 示例分析**\n\n我们为给定的两个点 $x_A$ 和 $x_B$ 计算不确定性得分。\n\n对于点 $x_A$：\n- 后验概率：$(0.60, 0.39, 0.01)$。\n- 有序后验概率：$p_{(1)}(x_A) = 0.60$, $p_{(2)}(x_A) = 0.39$, $p_{(3)}(x_A) = 0.01$。\n- LC 得分：$u_{\\mathrm{LC}}(x_A) = 1 - p_{(1)}(x_A) = 1 - 0.60 = 0.40$。\n- 边际得分：$u_{\\mathrm{margin}}(x_A) = p_{(1)}(x_A) - p_{(2)}(x_A) = 0.60 - 0.39 = 0.21$。\n\n对于点 $x_B$：\n- 后验概率：$(0.51, 0.26, 0.23)$。\n- 有序后验概率：$p_{(1)}(x_B) = 0.51$, $p_{(2)}(x_B) = 0.26$, $p_{(3)}(x_B) = 0.23$。\n- LC 得分：$u_{\\mathrm{LC}}(x_B) = 1 - p_{(1)}(x_B) = 1 - 0.51 = 0.49$。\n- 边际得分：$u_{\\mathrm{margin}}(x_B) = p_{(1)}(x_B) - p_{(2)}(x_B) = 0.51 - 0.26 = 0.25$。\n\n现在，我们确定每种策略的选择：\n- **LC 选择：** 目标是**最大化** $u_{\\mathrm{LC}}(x)$。比较得分，$u_{\\mathrm{LC}}(x_B) = 0.49  u_{\\mathrm{LC}}(x_A) = 0.40$。因此，最小置信度采样选择点 **$x_B$**。\n- **MS 选择：** 目标是**最小化** $u_{\\mathrm{margin}}(x)$。比较得分，$u_{\\mathrm{margin}}(x_A) = 0.21  u_{\\mathrm{margin}}(x_B) = 0.25$。因此，边际采样选择点 **$x_A$**。\n\n这个例子证实了对于 $K2$，这两种策略确实可以选择不同的点。LC 偏好 $x_B$ 是因为它最可能的类别（$0.51$）比 $x_A$ 最可能的类别（$0.60$）更不确定。MS 偏好 $x_A$ 是因为其两个最可能的类别（$0.60$ 和 $0.39$）比 $x_B$ 的（$0.51$ 和 $0.26$）更接近，这表明前两个竞争者之间有更大的模糊性。\n\n### 逐项分析\n\n基于以上推导，对每个选项进行评估。\n\n**A. 在二元分类（$K=2$）中，最小置信度和边际采样总是选择相同的点；在 $K=3$ 的例子中，最小置信度选择 $x_B$，边际采样选择 $x_A$。**\n- 第一部分，关于二元分类中的等价性，已被证明是正确的。\n- 第二部分，关于 $K=3$ 示例的选择，与我们的计算完全匹配。\n- **结论：正确。**\n\n**B. 在二元分类（$K=2$）中，最小置信度和边际采样可能不一致；在 $K=3$ 的例子中，两种策略都选择 $x_B$。**\n- 第一部分不正确。我们的证明表明它们在 $K=2$ 时是等价的。\n- 第二部分不正确。我们的计算表明边际采样选择 $x_A$，而不是 $x_B$。\n- **结论：不正确。**\n\n**C. 在二元分类（$K=2$）中，两种策略仅在 $p_{(1)}(x) = \\tfrac{1}{2}$ 时一致；在 $K=3$ 的例子中，最小置信度选择 $x_A$，边际采样选择 $x_B$。**\n- 第一部分不正确。我们的证明表明它们在 $K=2$ 时总是达成一致，而不仅仅是在最大不确定性的特殊情况 $p_{(1)}(x) = 1/2$ 时。\n- 第二部分不正确。选择结果与我们的发现相反。\n- **结论：不正确。**\n\n**D. 对于任意数量的类别（$K \\ge 2$），最小置信度和边际采样总是达成一致；在 $K=3$ 的例子中，两种策略都选择 $x_A$。**\n- 第一部分不正确。$K=3$ 的例子明确表明它们可能不一致。\n- 第二部分不正确。我们的计算表明最小置信度采样选择 $x_B$，而不是 $x_A$。\n- **结论：不正确。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "将理论付诸代码是掌握任何机器学习技术的关键一步。这个动手练习要求您实现三种最常见的不确定性采样算法：最小置信度、边际和熵采样。通过将您的代码应用于一组精心设计的例子，您将亲眼看到这些对不确定性的不同定义如何导致不同的数据选择。",
            "id": "3095122",
            "problem": "给定一个用于多类别分类的基于池的主动学习场景，其中具有固定参数 $\\hat{\\theta}$ 的概率分类器为每个未标记的输入 $x$ 提供一个在有限标签集 $\\mathcal{Y}$ 上的类别预测分布 $p_{\\hat{\\theta}}(y \\mid x)$。您的任务是实现三种不确定性采样策略——最小置信度（least-confidence）、边际（margin）和熵采样（entropy sampling）——并确保它们在一个适当构建的池上产生不同的选择。解决方案必须是一个完整的、可运行的程序，该程序能够评估指定的测试套件并以确切的格式打印所要求的输出。\n\n基本依据和定义：\n- 对于每个未标记的输入 $x$，分类器输出一个类别概率向量 $p_{\\hat{\\theta}}(y \\mid x)$，其中 $y \\in \\mathcal{Y}$，该向量满足对于所有 $y$，有 $p_{\\hat{\\theta}}(y \\mid x) \\ge 0$，且 $\\sum_{y \\in \\mathcal{Y}} p_{\\hat{\\theta}}(y \\mid x) = 1$。\n- 令 $p_{(1)}(x) \\ge p_{(2)}(x) \\ge \\cdots$ 表示 $p_{\\hat{\\theta}}(y \\mid x)$ 按降序排列的概率。\n- 对于 $x$ 的最小置信度不确定性由 $\\max_{y \\in \\mathcal{Y}} p_{\\hat{\\theta}}(y \\mid x) = p_{(1)}(x)$ 衡量。最小置信度采样选择池中具有最小 $p_{(1)}(x)$ 的 $x$。\n- 对于 $x$ 的边际不确定性由前两个最高概率之差 $p_{(1)}(x) - p_{(2)}(x)$ 衡量。边际采样选择池中具有最小 $p_{(1)}(x) - p_{(2)}(x)$ 的 $x$。\n- 对于 $x$ 的熵不确定性由 Shannon 熵 $H\\!\\left[Y \\mid x, \\hat{\\theta}\\right] = - \\sum_{y \\in \\mathcal{Y}} p_{\\hat{\\theta}}(y \\mid x) \\log p_{\\hat{\\theta}}(y \\mid x)$ 给出，其中 $\\log$ 表示自然对数。熵采样选择池中具有最大 $H\\!\\left[Y \\mid x, \\hat{\\theta}\\right]$ 的 $x$。\n- 平局必须通过选择 0-基索引下的最小索引来确定性地打破。\n\n编程要求：\n- 对于每个测试用例，您将得到一个有限池 $\\mathcal{U} = \\{x_i\\}_{i=0}^{n-1}$，由预测的类别概率向量矩阵 $\\left( p_{\\hat{\\theta}}(y \\mid x_i) \\right)$ 表示。每行对应一个 $x_i$，且每行之和在浮点精度范围内为 $1$。\n- 对于每个测试用例，计算：\n  $1.$ 由最小置信度采样选择的索引（基于 0-基索引）以及在该索引处的对应值 $p_{(1)}(x)$。\n  $2.$ 由边际采样选择的索引以及在该索引处的对应值 $\\left(p_{(1)}(x) - p_{(2)}(x)\\right)$。\n  $3.$ 由熵采样选择的索引以及在该索引处的对应值 $H\\!\\left[Y \\mid x, \\hat{\\theta}\\right]$。\n  $4.$ 这三种选择中不同索引的数量（即包含这三个选定索引的集合的基数）。\n- 计算熵时使用约定 $0 \\cdot \\log 0 = 0$。$\\log$ 使用自然对数。\n- 所有浮点输出必须四舍五入到恰好 $6$ 位小数。\n- 任何选择标准的平局都必须通过选择 0-基索引下的最小索引来解决。\n\n测试套件：\n- 测试用例 $\\mathbf{1}$ (理想情况：三个标准选择了不同的输入):\n  - 包含四个未标记输入（行）和三个类别（列）的池：\n    - $x_0$: $\\left[0.39,\\; 0.38,\\; 0.23\\right]$\n    - $x_1$: $\\left[0.41,\\; 0.295,\\; 0.295\\right]$\n    - $x_2$: $\\left[0.500,\\; 0.495,\\; 0.005\\right]$\n    - $x_3$: $\\left[0.70,\\; 0.20,\\; 0.10\\right]$\n- 测试用例 $\\mathbf{2}$ (边界情况：池内所有标准完全平局；通过最小索引打破平局):\n  - 包含三个未标记输入和三个类别的池：\n    - $x_0$: $\\left[\\frac{1}{3},\\; \\frac{1}{3},\\; \\frac{1}{3}\\right]$\n    - $x_1$: $\\left[\\frac{1}{3},\\; \\frac{1}{3},\\; \\frac{1}{3}\\right]$\n    - $x_2$: $\\left[\\frac{1}{3},\\; \\frac{1}{3},\\; \\frac{1}{3}\\right]$\n- 测试用例 $\\mathbf{3}$ (边缘情况：存在零概率；近似确定性的预测):\n  - 包含四个未标记输入和三个类别的池：\n    - $x_0$: $\\left[0.99,\\; 0.01,\\; 0.00\\right]$\n    - $x_1$: $\\left[0.60,\\; 0.40,\\; 0.00\\right]$\n    - $x_2$: $\\left[0.49,\\; 0.49,\\; 0.02\\right]$\n    - $x_3$: $\\left[0.55,\\; 0.45,\\; 0.00\\right]$\n\n最终输出规范：\n- 对于每个测试用例，按顺序生成以下七个值作为一维序列：\n  - $\\text{LC\\_idx}$，在 $\\text{LC\\_idx}$ 处的 $p_{(1)}$，\n  - $\\text{M\\_idx}$，在 $\\text{M\\_idx}$ 处的 $\\left(p_{(1)} - p_{(2)}\\right)$，\n  - $\\text{ENT\\_idx}$，在 $\\text{ENT\\_idx}$ 处的 $H$，\n  - $\\text{distinct\\_count}$。\n- 将所有测试用例的结果按测试用例的顺序聚合到一个列表中。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，所有浮点数都四舍五入到恰好 $6$ 位小数。例如，输出必须具有 $\\left[\\text{v}_0,\\text{v}_1,\\ldots,\\text{v}_{m-1}\\right]$ 的形式，其中每个 $\\text{v}_j$ 是一个整数或一个恰好有 $6$ 位小数的浮点数。",
            "solution": "问题陈述经过了严格审查，并被确定为有效。它在科学上基于统计学习的原理，特别是在主动学习方面。最小置信度、边际和熵采样的定义是标准且正确的。该问题是适定的，提供了所有必要的数据、约束和确定性的平局打破规则，这确保了每个测试用例都存在唯一且可计算的解。输入是自洽的，目标是可形式化和客观的。\n\n任务是在一个基于池的主动学习设置中，为多类别分类器实现并比较三种不同的不确定性采样策略。给定一个未标记数据点池 $\\mathcal{U}$，每个数据点由一个在类别集合 $\\mathcal{Y}$ 上的预测概率向量 $p_{\\hat{\\theta}}(y \\mid x)$ 表示，我们必须选择信息量最大的单个点来查询其真实标签。“信息量”或“不确定性”由三种不同的度量标准量化。\n\n设 $P$ 是一个维度为 $n \\times k$ 的矩阵，其中 $n$ 是池中数据点的数量，$k = |\\mathcal{Y}|$ 是类别的数量。每一行 $P_i$ 对应于概率向量 $p_{\\hat{\\theta}}(y \\mid x_i)$。目标是根据以下每个标准，找到对应于最不确定数据点的索引 $i^*$。\n\n**1. 最小置信度采样**\n\n该策略基于分类器对其最可能预测的置信度。当最可能类别的概率最小时，不确定性被认为是最大的。对于一个输入 $x$ 的最置信预测由 $p_{(1)}(x) = \\max_{y \\in \\mathcal{Y}} p_{\\hat{\\theta}}(y \\mid x)$ 给出。最小置信度采样策略从池 $\\mathcal{U}$ 中选择使该值最小化的数据点 $x^*$。\n\n因此，选择索引 $i^*_{LC}$ 是：\n$$\ni^*_{LC} = \\arg\\min_{i \\in \\{0, \\dots, n-1\\}} p_{(1)}(x_i)\n$$\n如果出现平局，则选择最小的索引 $i$。相关的不确定性值为 $p_{(1)}(x_{i^*_{LC}})$。\n\n**2. 边际采样**\n\n该策略通过考虑两个最可能类别之间的模糊性来改进最小置信度采样。第一和第二最可能类别 $p_{(1)}(x)$ 和 $p_{(2)}(x)$ 之间的微小边际表明分类器难以区分它们，从而标志着高度不确定性。边际定义为 $p_{(1)}(x) - p_{(2)}(x)$。边际采样选择具有最小边际的数据点 $x^*$。\n\n选择索引 $i^*_{M}$ 是：\n$$\ni^*_{M} = \\arg\\min_{i \\in \\{0, \\dots, n-1\\}} \\left( p_{(1)}(x_i) - p_{(2)}(x_i) \\right)\n$$\n同样，平局通过选择最小索引来打破。相关的不确定性值是边际本身，即 $p_{(1)}(x_{i^*_{M}}) - p_{(2)}(x_{i^*_{M}})$。\n\n**3. 熵采样**\n\n这是三种度量标准中最全面的，因为它考虑了整个概率分布。它使用 Shannon 熵作为不确定性的度量。一个急剧峰值（一个高概率，其他低概率）的概率分布具有低熵，表示低不确定性。相反，一个接近均匀的分布具有高熵，表示高不确定性。给定输入 $x$ 的熵是：\n$$\nH[Y \\mid x, \\hat{\\theta}] = - \\sum_{y \\in \\mathcal{Y}} p_{\\hat{\\theta}}(y \\mid x) \\log p_{\\hat{\\theta}}(y \\mid x)\n$$\n其中 $\\log$ 是自然对数，并使用约定 $0 \\cdot \\log 0 = 0$。熵采样选择具有最大熵的数据点 $x^*$。\n\n选择索引 $i^*_{ENT}$ 是：\n$$\ni^*_{ENT} = \\arg\\max_{i \\in \\{0, \\dots, n-1\\}} H[Y \\mid x_i, \\hat{\\theta}]\n$$\n平局通过选择最小索引来打破。相关的不确定性值是熵 $H[Y \\mid x_{i^*_{ENT}}, \\hat{\\theta}]$。\n\n**计算步骤**\n\n对于由一个 $n \\times k$ 概率矩阵 $P$ 表示的每个测试用例：\n1.  **最小置信度：** 对每一行，找到最大概率。然后，找到这些最大值中最小者所在行的索引。\n2.  **边际：** 对每一行，按降序对概率进行排序以找到 $p_{(1)}$ 和 $p_{(2)}$。计算它们的差值。然后，找到具有最小差值所在行的索引。\n3.  **熵：** 对每一行，计算 Shannon 熵，通过确保形如 $0 \\cdot \\log 0$ 的项对总和的贡献为 0 来正确处理 $p=0$ 的情况。然后，找到具有最大熵所在行的索引。\n4.  **不同索引计数：** 收集三个结果索引（$i^*_{LC}$，$i^*_{M}$，$i^*_{ENT}$），并计算此集合中唯一值的数量。\n5.  **格式化：** 所有浮点结果都四舍五入到 6 位小数，并与整数索引和计数一起整理成一个单一的一维列表，以符合问题规范。\n\n实现将利用 `numpy` 库，其 `argmin` 和 `argmax` 函数通过返回极值的第一个出现位置的索引，固有地满足了指定的平局打破规则。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements least-confidence, margin, and entropy uncertainty sampling\n    for a series of test cases and formats the output as specified.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        [\n            [0.39, 0.38, 0.23],\n            [0.41, 0.295, 0.295],\n            [0.500, 0.495, 0.005],\n            [0.70, 0.20, 0.10],\n        ],\n        # Test case 2\n        [\n            [1/3, 1/3, 1/3],\n            [1/3, 1/3, 1/3],\n            [1/3, 1/3, 1/3],\n        ],\n        # Test case 3\n        [\n            [0.99, 0.01, 0.00],\n            [0.60, 0.40, 0.00],\n            [0.49, 0.49, 0.02],\n            [0.55, 0.45, 0.00],\n        ]\n    ]\n\n    results = []\n    for case in test_cases:\n        p_matrix = np.array(case, dtype=np.float64)\n\n        # 1. Least-Confidence Sampling\n        # The goal is to find the point with the smallest most-confident prediction.\n        p1_values = np.max(p_matrix, axis=1)\n        lc_idx = np.argmin(p1_values)\n        lc_val = p1_values[lc_idx]\n\n        # 2. Margin Sampling\n        # The goal is to find the point with the smallest difference between the\n        # top two predictions.\n        # Sort probabilities in descending order for each row.\n        sorted_p = -np.sort(-p_matrix, axis=1)\n        p1 = sorted_p[:, 0]\n        p2 = sorted_p[:, 1]\n        margin_values = p1 - p2\n        m_idx = np.argmin(margin_values)\n        m_val = margin_values[m_idx]\n\n        # 3. Entropy Sampling\n        # The goal is to find the point with the highest Shannon entropy.\n        # We must handle the 0 * log(0) = 0 case.\n        # Create a temporary array where p=0 is replaced by p=1.\n        # This makes log(p)=0, so p*log(p) becomes 0, satisfying the convention.\n        p_for_log = p_matrix.copy()\n        p_for_log[p_for_log == 0] = 1.0\n        entropy_values = -np.sum(p_matrix * np.log(p_for_log), axis=1)\n        ent_idx = np.argmax(entropy_values)\n        ent_val = entropy_values[ent_idx]\n\n        # 4. Count of distinct indices\n        distinct_count = len({lc_idx, m_idx, ent_idx})\n\n        # Append results for the current test case.\n        results.extend([\n            lc_idx, lc_val,\n            m_idx, m_val,\n            ent_idx, ent_val,\n            distinct_count\n        ])\n\n    def format_val(v):\n        \"\"\"Formats an integer or float according to problem specs.\"\"\"\n        if isinstance(v, (int, np.integer)):\n            return str(v)\n        else:  # float or np.floating\n            return f\"{v:.6f}\"\n\n    # Format the final list of results for printing.\n    formatted_results = [format_val(r) for r in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "归根结底，主动学习的目标是以更少的标记样本实现更高的准确率。最后一个练习提供了一个通过分析学习曲线来量化这一优势的框架。您将对主动和被动学习策略的模拟性能数据拟合一个数学模型，从而估算出具体的“标签节省量”，并以此衡量主动学习方法的实际价值。",
            "id": "3095092",
            "problem": "在监督式统计学习中，预期泛化风险的学习曲线通常可以由一个经验性幂律加平台模型 $R(n)=\\alpha n^{-\\beta}+\\gamma$ 很好地近似，其中 $R(n)$ 表示在 $n$ 个标记样本下的预期风险，$\\alpha \\ge 0$ 是一个尺度参数，$\\beta  0$ 是衰减率，$\\gamma \\ge 0$ 是不可约减的平台项。考虑比较被动采样（从数据分布中抽取的独立同分布标签）与使用不确定性采样的**主动学习**（一种优先标记当前模型最不确定输入的策略）。我们假设两种策略都会对不同标签数量产生带噪声的风险测量值，并且我们通过非线性最小二乘法来拟合学习曲线模型的参数。\n\n从以下基本前提出发：对于适定学习问题，预期风险 $R(n)$ 关于 $n$ 是非递增的，并且随着 $n$ 的增加，$R(n)$ 的降低通常由经验模型 $R(n)=\\alpha n^{-\\beta}+\\gamma$ 捕捉。请推导一个表达式，用于计算在给定目标误差阈值 $\\epsilon$ 的情况下，满足 $R(n)\\le \\epsilon$ 的最小标签数 $n_{\\text{req}}$。使用此表达式来估算被动采样和主动采样在达到相同目标 $\\epsilon$ 时所需的整数标签节省量。\n\n您的任务是编写一个完整、可运行的程序，该程序：\n- 通过有界非线性最小二乘法，将模型参数 $(\\alpha,\\beta,\\gamma)$ 拟合到每种策略测得的 $(n,R)$ 数据对。\n- 为每种策略计算满足 $R(n)\\le \\epsilon$ 的最小整数标签数 $n_{\\text{req}}$。\n- 根据以下约定计算标签节省量 $S = n_{\\text{req}}^{\\text{passive}} - n_{\\text{req}}^{\\text{active}}$：\n    - 如果某个策略的 $\\epsilon \\le \\gamma$，则该策略无法达到目标，此时 $n_{\\text{req}}=+\\infty$。\n    - 如果两种策略都得到 $n_{\\text{req}}=+\\infty$，则 $S$ 返回 $\\mathrm{NaN}$。\n    - 如果只有一种策略得到 $n_{\\text{req}}=+\\infty$，当被动采样无法达到目标时返回 $+\\infty$，当主动采样无法达到目标时返回 $-\\infty$。\n    - 否则，返回 $S$ 作为有限整数差。\n- 当 $n_{\\text{req}}$ 为有限值时，使用上取整函数确保其为整数标签数。\n\n使用以下测得的 $(n,R)$ 数据对和目标 $\\epsilon$ 值的测试套件。每对数据以 $(n,R)$ 的形式给出，其中 $n$ 的单位是标签数，$R$ 和 $\\epsilon$ 是无量纲的。对于每种情况，为主动和被动测量数据分别拟合模型，然后按规定计算标签节省量。\n\n测试用例1（正常路径，主动采样更具样本效率）：\n- 主动采样测量值：$(20,0.154)$, $(50,0.119)$, $(100,0.104)$, $(200,0.095)$, $(500,0.088)$, $(1000,0.085)$。\n- 被动采样测量值：$(20,0.322)$, $(50,0.242)$, $(100,0.199)$, $(200,0.171)$, $(500,0.145)$, $(1000,0.132)$。\n- 目标：$\\epsilon=0.12$。\n\n测试用例2（边界情况，$\\epsilon$ 接近主动采样平台但低于被动采样平台）：\n- 主动采样测量值：$(50,0.117)$, $(100,0.094)$, $(200,0.0795)$, $(500,0.067)$, $(1000,0.061)$, $(2000,0.057)$。\n- 被动采样测量值：$(50,0.236)$, $(100,0.190)$, $(200,0.158)$, $(500,0.129)$, $(1000,0.115)$, $(2000,0.105)$。\n- 目标：$\\epsilon=0.055$。\n\n测试用例3（边缘情况，目标低于两个平台）：\n- 主动采样测量值：$(50,0.151)$, $(100,0.129)$, $(200,0.115)$, $(500,0.102)$, $(1000,0.096)$。\n- 被动采样测量值：$(50,0.190)$, $(100,0.160)$, $(160,0.148)$, $(200,0.139)$, $(500,0.121)$, $(1000,0.112)$。\n- 目标：$\\epsilon=0.07$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，“[result1,result2,result3]”）。每个结果必须是相应测试用例的标签节省量 $S$，如果是有限的，则表示为整数；否则按上述规定表示为 $inf$、$ -inf$ 或 $nan$。不应打印任何额外文本。",
            "solution": "问题陈述经评估具有科学依据、适定且客观。它没有矛盾、歧义或不合理的假设。该任务是统计学习领域内非线性回归和基于模型的**外推**的标准应用。\n\n预期泛化风险 $R(n)$ 作为标记样本数量 $n$ 的函数的学习曲线，由以下经验模型给出：\n$$R(n) = \\alpha n^{-\\beta} + \\gamma$$\n参数约束为 $\\alpha \\ge 0$, $\\beta  0$ 和 $\\gamma \\ge 0$。参数 $\\alpha$ 是尺度因子，$\\beta$ 是学习率，$\\gamma$ 是不可约减误差，即当 $n \\to \\infty$ 时的渐近风险。\n\n主要目标是推导出达到目标风险水平 $\\epsilon$ 所需的最小整数样本数 $n_{\\text{req}}$ 的表达式。这需要找到满足 $R(n) \\le \\epsilon$ 的最小整数 $n$。\n\n由于 $R(n)$ 是 $n$ 的非增函数（对于 $\\alpha, \\beta  0$），我们可以通过设置 $R(n) = \\epsilon$ 来找到边界情况：\n$$\\alpha n^{-\\beta} + \\gamma = \\epsilon$$\n我们接着求解此方程以得到 $n$：\n$$\\alpha n^{-\\beta} = \\epsilon - \\gamma$$\n为了使解存在，方程两边的符号必须一致。左侧 $\\alpha n^{-\\beta}$ 是非负的，因为 $\\alpha \\ge 0$ 且 $n  0$。因此，我们必须有 $\\epsilon - \\gamma \\ge 0$，这意味着 $\\epsilon \\ge \\gamma$。\n\n情况1：目标误差无法达到。\n如果 $\\epsilon \\le \\gamma$，目标误差 $\\epsilon$ 小于或等于不可约减误差 $\\gamma$。对于任何非平凡的学习过程（$\\alpha0$），风险 $R(n) = \\alpha n^{-\\beta} + \\gamma$ 将始终严格大于 $\\gamma$，因此也大于 $\\epsilon$。在这种情况下，目标误差是无法实现的。根据问题的规定，所需的样本数量是无限的：\n$$n_{\\text{req}} = +\\infty \\quad \\text{if} \\quad \\epsilon \\le \\gamma$$\n\n情况2：目标误差可以达到。\n如果 $\\epsilon  \\gamma$，有限的样本量可以达到目标。我们可以继续求解 $n$。假设 $\\alpha  0$：\n$$n^{-\\beta} = \\frac{\\epsilon - \\gamma}{\\alpha}$$\n对两边取倒数：\n$$n^{\\beta} = \\frac{\\alpha}{\\epsilon - \\gamma}$$\n将两边同时取 $1/\\beta$ 次幂：\n$$n = \\left( \\frac{\\alpha}{\\epsilon - \\gamma} \\right)^{1/\\beta}$$\n这个 $n$ 值是达到 $R(n) = \\epsilon$ 所需的精确实数样本数量。由于 $R(n)$ 是非递增的，任何大于或等于此值的样本量也将满足 $R(n) \\le \\epsilon$ 的标准。问题要求的是*最小整数*标签数，这可以通过应用上取整函数得到。为了确保样本数至少为1，我们取结果与1的最大值。\n$$n_{\\text{req}} = \\max\\left(1, \\left\\lceil \\left( \\frac{\\alpha}{\\epsilon - \\gamma} \\right)^{1/\\beta} \\right\\rceil\\right) \\quad \\text{if} \\quad \\epsilon  \\gamma$$\n\n解决该问题的计算步骤如下：\n1.  对于每个测试用例中的每种采样策略（主动和被动），通过将函数 $R(n)$ 拟合到所提供的 $(n, R)$ 数据点来确定模型参数 $(\\alpha, \\beta, \\gamma)$。这是通过有界非线性最小二乘法完成的，具体使用了 `scipy.optimize.curve_fit` 函数。参数的边界被设置为遵守约束条件 $\\alpha \\ge 0$, $\\beta  0$ 和 $\\gamma \\ge 0$。为 $\\beta$ 使用一个小的正数下界（例如 $10^{-9}$）以确保数值稳定性并遵守严格不等式。\n2.  一旦为某个策略找到了最优参数 $(\\hat{\\alpha}, \\hat{\\beta}, \\hat{\\gamma})$，就使用推导出的表达式为给定的目标风险 $\\epsilon$ 计算所需的样本量 $n_{\\text{req}}$。\n3.  然后，根据为处理有限、无限 ($+\\infty, -\\infty$) 和未定义 ($\\mathrm{NaN}$) 结果所提供的特定规则，计算标签节省量 $S = n_{\\text{req}}^{\\text{passive}} - n_{\\text{req}}^{\\text{active}}$。\n\n这种完整、有原则的方法被应用于每个提供的测试用例。\n\n提供的数据如下：\n测试用例1：\n- 主动采样测量值：$(20, 0.154)$, $(50, 0.119)$, $(100, 0.104)$, $(200, 0.095)$, $(500, 0.088)$, $(1000, 0.085)$。\n- 被动采样测量值：$(20, 0.322)$, $(50, 0.242)$, $(100, 0.199)$, $(200, 0.171)$, $(500, 0.145)$, $(1000, 0.132)$。\n- 目标：$\\epsilon=0.12$。\n\n测试用例2：\n- 主动采样测量值：$(50, 0.117)$, $(100, 0.094)$, $(200, 0.0795)$, $(500, 0.067)$, $(1000, 0.061)$, $(2000, 0.057)$。\n- 被动采样测量值：$(50, 0.236)$, $(100, 0.190)$, $(200, 0.158)$, $(500, 0.129)$, $(1000, 0.115)$, $(2000, 0.105)$。\n- 目标：$\\epsilon=0.055$。\n\n测试用例3：\n- 主动采样测量值：$(50, 0.151)$, $(100, 0.129)$, $(200, 0.115)$, $(500, 0.102)$, $(1000, 0.096)$。\n- 被动采样测量值：$(50, 0.190)$, $(100, 0.160)$, $(160, 0.148), (200, 0.139)$, $(500, 0.121)$, $(1000, 0.112)$。\n- 目标：$\\epsilon=0.07$。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\ndef solve():\n    \"\"\"\n    Solves the learning curve analysis problem for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"active\": {\n                \"n\": np.array([20, 50, 100, 200, 500, 1000]),\n                \"R\": np.array([0.154, 0.119, 0.104, 0.095, 0.088, 0.085]),\n            },\n            \"passive\": {\n                \"n\": np.array([20, 50, 100, 200, 500, 1000]),\n                \"R\": np.array([0.322, 0.242, 0.199, 0.171, 0.145, 0.132]),\n            },\n            \"epsilon\": 0.12,\n        },\n        {\n            \"active\": {\n                \"n\": np.array([50, 100, 200, 500, 1000, 2000]),\n                \"R\": np.array([0.117, 0.094, 0.0795, 0.067, 0.061, 0.057]),\n            },\n            \"passive\": {\n                \"n\": np.array([50, 100, 200, 500, 1000, 2000]),\n                \"R\": np.array([0.236, 0.190, 0.158, 0.129, 0.115, 0.105]),\n            },\n            \"epsilon\": 0.055,\n        },\n        {\n            \"active\": {\n                \"n\": np.array([50, 100, 200, 500, 1000]),\n                \"R\": np.array([0.151, 0.129, 0.115, 0.102, 0.096]),\n            },\n            \"passive\": {\n                \"n\": np.array([50, 100, 160, 200, 500, 1000]),\n                \"R\": np.array([0.190, 0.160, 0.148, 0.139, 0.121, 0.112]),\n            },\n            \"epsilon\": 0.07,\n        },\n    ]\n\n    def learning_curve_model(n, alpha, beta, gamma):\n        \"\"\"Power-law-plus-plateau model for learning curves.\"\"\"\n        return alpha * n**(-beta) + gamma\n\n    def get_n_req(n_data, r_data, epsilon):\n        \"\"\"\n        Fits the learning curve model and calculates the required number of samples.\n        \"\"\"\n        # Heuristic initial guesses for parameters\n        gamma_guess = r_data[-1]\n        beta_guess = 0.5\n        alpha_guess = (r_data[0] - gamma_guess) * (n_data[0]**beta_guess)\n        p0 = [alpha_guess, beta_guess, gamma_guess]\n\n        # Parameter bounds: alpha >= 0, beta > 0, gamma >= 0\n        bounds = ([0, 1e-9, 0], [np.inf, np.inf, np.inf])\n\n        try:\n            params, _ = curve_fit(\n                learning_curve_model,\n                n_data,\n                r_data,\n                p0=p0,\n                bounds=bounds,\n                maxfev=5000\n            )\n        except RuntimeError:\n            # If fit fails, assume it's impossible to determine n_req\n            return np.inf\n\n        alpha, beta, gamma = params\n\n        # If target epsilon is below or at the irreducible error plateau, it's unreachable.\n        if epsilon = gamma:\n            return np.inf\n\n        # Handle the case where the numerator or the entire base might be problematic\n        base = alpha / (epsilon - gamma)\n        if base  0:\n             # This can happen due to numerical precision issues if alpha is near zero\n             # or epsilon is extremely close to gamma. Treat as unreachable.\n            return np.inf\n\n        # Calculate required sample size n, ensuring it's at least 1.\n        n_calc = base**(1 / beta)\n        n_required = np.ceil(n_calc)\n        \n        return max(1, n_required)\n\n    results = []\n    for case in test_cases:\n        n_req_active = get_n_req(case[\"active\"][\"n\"], case[\"active\"][\"R\"], case[\"epsilon\"])\n        n_req_passive = get_n_req(case[\"passive\"][\"n\"], case[\"passive\"][\"R\"], case[\"epsilon\"])\n\n        is_active_inf = np.isinf(n_req_active)\n        is_passive_inf = np.isinf(n_req_passive)\n\n        if is_active_inf and is_passive_inf:\n            savings = np.nan\n        elif is_passive_inf:\n            savings = np.inf\n        elif is_active_inf:\n            savings = -np.inf\n        else:\n            savings = int(n_req_passive - n_req_active)\n        \n        results.append(savings)\n\n    def format_result(val):\n        if np.isnan(val):\n            return \"nan\"\n        elif np.isposinf(val):\n            return \"inf\"\n        elif np.isneginf(val):\n            return \"-inf\"\n        else:\n            return str(int(val))\n\n    formatted_results = [format_result(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}