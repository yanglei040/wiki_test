## 引言
在众多科学与工程领域，从医学研究到[可靠性工程](@entry_id:271311)，我们常常关心某个特定事件发生的时间。然而，由于研究时间限制、个体失访或检测技术的局限，我们往往无法精确地观测到所有个体的事件时间，从而产生了不完整的数据。这种被称为“审查数据”（censored data）的现象，是[生存分析](@entry_id:163785)领域的核心议题，若处理不当，极易导致结论产生严重偏差。

本文旨在为读者提供一个关于审查数据分析的全面指南，系统地阐明如何理解和处理这种不完整的时间事件数据。通过接下来的内容，您将：
-   在**“原理与机制”**部分，深入学习审查数据的[基本类](@entry_id:158335)型（右审查、左审查与区间审查），并掌握构建似然函数、使用[Kaplan-Meier](@entry_id:169317)估计和[Cox比例风险模型](@entry_id:174252)等核心统计方法。
-   在**“应用与跨学科联系”**部分，探索这些理论和方法如何在医学、工程、商业和数据科学等多元化领域中解决实际问题，见证其强大的跨学科能力。
-   在**“动手实践”**部分，通过解决具体的分析任务，将理论知识转化为可操作的技能，从而巩固并深化对核心概念的理解。

本指南将带领您从理论基础出发，逐步深入到应用层面，最终通过实践掌握分析审查数据的关键技能。

## 原理与机制

在上一章引言中，我们了解了[生存分析](@entry_id:163785)及其在多个领域中的重要性。我们认识到，在许多研究中，我们感兴趣的事件时间（如设备故障、疾病复发或用户流失）往往无法被精确观测。这种不完全观测的数据被称为 **审查数据 (censored data)**。本章将深入探讨审查数据的基本原理和处理这些数据的核心统计机制。我们将从审查的不同类型出发，建立一个统一的分析框架——[似然](@entry_id:167119)原理，然后介绍用于估计生存函数的关键[非参数方法](@entry_id:138925)，并进一步扩展到包含协变量的[回归模型](@entry_id:163386)。最后，我们将讨论一些[生存分析](@entry_id:163785)中的高级主题，以加深对这些方法的理解和正确应用的认识。

### 审查数据的[基本类](@entry_id:158335)型

当一个观测对象的主要事件时间点未知，但我们掌握了关于该时间点的部分信息时，就产生了审查数据。这些信息通常将未知的时间点限制在一个特定的时间范围或区间内。根据这个区间的性质，审查数据主要分为三种类型：右审查、左审查和区间审查。

#### 右审查 (Right Censoring)

**右审查** 是[生存分析](@entry_id:163785)中最常见的审查类型。它发生在我们知道事件时间 $T$ 大于某个观测时间 $T_R$ 时，即 $T > T_R$。这种情况通常出现在研究结束时，一些观测对象仍然“存活”（即未经历事件），或者观测对象因与研究无关的原因失访（例如搬家或自愿退出）。

在临床试验中，右审查是司空见惯的。例如，一项评估新药“CardioGuard”在预防心血管事件复发方面疗效的研究，可能会跟踪患者五年。研究结束时，有些患者可能从未经历事件复发，他们的事件时间被右审查在五年这个时间点。另一些患者可能在五年期满前因个人原因退出研究，他们在最后一次随访时仍未经历事件。对于一个在两年后失访的患者，我们只知道他的事件复发时间（如果会发生的话）大于两年。这两种情况——研究期满和中途失访——都是右审查的典型例子 。

#### 左审查 (Left Censoring)

与右审查相对的是 **左审查**。当事件在观测开始之前就已经发生，但我们不知道确切的发生时间时，就会出现左审查。我们唯一知道的是事件时间 $T$ 小于某个观测时间 $T_L$，即 $T \le T_L$。

左审查在某些工程和[环境科学](@entry_id:187998)领域很常见。例如，一个实验室使用传感器记录设备的故障时间，但该传感器有一个检测下限 $L$。如果设备在时间 $L$ 之前就已发生故障，传感器无法记录确切的故障时间，只能记录一个标记，表明故障发生在 $L$ 之前。在这种情况下，真实的故障时间 $T$ 是左审查的，我们只知道 $T \le L$ 。另一个例子是研究某种[传染病](@entry_id:182324)的潜伏期，如果对患者进行首次检查时，他们已经表现出症状，那么他们的感染时间就被左审查了，我们只知道感染发生在首次检查之前。

#### 区间审查 (Interval Censoring)

**区间审查** 是一种更普遍的审查形式，它发生在我们只知道事件发生在某个时间区间 $(T_1, T_2]$ 内，即 $T_1  T \le T_2$。右审查和左审查可以被看作是区间审查的特例（分别为 $(T_R, \infty)$ 和 $(0, T_L]$）。

区间审查通常源于间歇性的观测或随访计划。在可靠性工程中，一个电子元件可能在时间 $T_1$ 的检查中被发现功能完好，但在下一次时间 $T_2$ 的检查中被发现已经失效。我们无法得知其确切的失效时间，只知道它发生在 $T_1$ 和 $T_2$ 之间 。在医学研究中，如果疾病（如艾滋病病毒感染）只能通过定期的血液检测来发现，那么一个人的感染时间就被区间审查在他最后一次阴性检测和第一次阳性检测之间。

一个特殊的区间审查类型是 **当前状态数据 (current status data)**，其中每个观测对象只被检查一次。在检查时，我们要么发现事件已经发生，要么发现事件尚未发生。这对应于两种观测区间：$(0, C_i]$ 或 $(C_i, \infty)$，其中 $C_i$ 是第 $i$ 个个体的检查时间 。

### 审查数据分析的基石：似然原理

尽管审查数据的形式各异，但处理它们的统计方法都建立在一个统一的强大原理之上：**似然原理 (likelihood principle)**。该原理指出，模型参数的全部信息都包含在似然函数中，而[似然函数](@entry_id:141927)是观测到当前数据集的概率，被看作是模型参数的函数。对于包含审查数据的[生存分析](@entry_id:163785)，每个观测（无论是精确的、右审查的、左审查的还是区间审查的）对总[似然](@entry_id:167119)的贡献就是观测到该结果的概率。

假设事件时间 $T$ 服从一个由参数 $\theta$ 决定的[概率分布](@entry_id:146404)，其[概率密度函数](@entry_id:140610) (PDF) 为 $f(t; \theta)$，[累积分布函数 (CDF)](@entry_id:264700) 为 $F(t; \theta) = P(T \le t)$，生存函数为 $S(t; \theta) = P(T > t) = 1 - F(t; \theta)$。

-   对于一个 **精确观测** 的事件时间 $t_i$，其[似然](@entry_id:167119)贡献是事件恰好发生在时间 $t_i$ 的概率密度，即 $L_i = f(t_i; \theta)$。

-   对于一个 **右审查** 观测，我们知道 $T_i > T_R$，其[似然](@entry_id:167119)贡献是事件时间大于 $T_R$ 的概率，即 $L_i = P(T_i > T_R) = S(T_R; \theta)$。

-   对于一个 **左审查** 观测，我们知道 $T_i \le T_L$，其[似然](@entry_id:167119)贡献是事件时间不大于 $T_L$ 的概率，即 $L_i = P(T_i \le T_L) = F(T_L; \theta)$。

-   对于一个 **区间审查** 观测，我们知道 $T_1  T_i \le T_2$，其[似然](@entry_id:167119)贡献是事件时间落在这个区间内的概率，即 $L_i = P(T_1  T_i \le T_2) = F(T_2; \theta) - F(T_1; \theta)$。

总[似然函数](@entry_id:141927)是所有独立观测的似然贡献的乘积。这个框架的优美之处在于它的普适性。无论审查机制如何，只要我们能写出观测结果的概率，我们就能构建[似然函数](@entry_id:141927)，并进而通过最大化该函数来估计模型参数。

让我们通过一个具体的例子来阐明这一点。假设电子元件的寿命 $T$ 服从双参数的 **[Weibull分布](@entry_id:270143)**，其CDF为 $F(t; k, \lambda) = 1 - \exp(-(\frac{t}{\lambda})^k)$，生存函数为 $S(t; k, \lambda) = \exp(-(\frac{t}{\lambda})^k)$。根据上述原理，我们可以直接写出不同审查类型下的似然贡献 ：

-   **场景A (右审查):** 在时间 $T_R$ 发现元件仍正常工作，观测为 $T > T_R$。似然贡献为 $L_A = S(T_R; k, \lambda) = \exp(-(\frac{T_R}{\lambda})^k)$。

-   **场景B (左审查):** 在时间 $T_L$ 发现元件已失效，观测为 $T \le T_L$。似然贡献为 $L_B = F(T_L; k, \lambda) = 1 - \exp(-(\frac{T_L}{\lambda})^k)$。

-   **场景C (区间审查):** 在 $T_1$ 检查时正常，在 $T_2$ 检查时已失效，观测为 $T_1  T \le T_2$。[似然](@entry_id:167119)贡献为 $L_C = S(T_1; k, \lambda) - S(T_2; k, \lambda) = \exp(-(\frac{T_1}{\lambda})^k) - \exp(-(\frac{T_2}{\lambda})^k)$。

这个原理同样适用于其他[概率模型](@entry_id:265150)。例如，在处理因传感器检测下限 $L$ 导致的左审查数据时，如果我们将潜在的故障时间 $T_i$ 建模为服从[正态分布](@entry_id:154414) $\mathcal{N}(x_i^\top\beta, \sigma^2)$（一种称为Tobit模型的 censored regression model），那么一个左审查观测（即 $T_i \le L$）的似然贡献就是 $P(T_i \le L)$。通过标准化，这可以表示为标准正态CDF $\Phi(\frac{L - x_i^\top\beta}{\sigma})$。这与我们上面得出的 $F(L; \theta)$ 的一般形式完全一致 。

### 生存函数的非[参数估计](@entry_id:139349)

在许多应用中，我们可能不愿意或没有足够的先验知识来假设事件时间服从某个特定的参数[分布](@entry_id:182848)（如Weibull或指数分布）。在这种情况下，**[非参数方法](@entry_id:138925)** 成为了首选，因为它不预设生存函数的形式。

#### 右审查数据：[Kaplan-Meier](@entry_id:169317)估计

对于右审查数据，最著名和最广泛使用的[非参数方法](@entry_id:138925)是 **[Kaplan-Meier](@entry_id:169317) (KM) 估计器**，也称为乘积限估计器 (product-limit estimator)。KM方法的核心思想是，在每个事件发生的时间点，重新估计条件生存概率，然后将这些概率连乘起来得到最终的生存函数估计。

KM估计器的计算步骤如下：
1.  将所有观测到的事件时间点按从小到大排序，得到 $t_{(1)} \le t_{(2)} \le \dots \le t_{(k)}$。
2.  在每个事件时间点 $t_{(j)}$，确定两件事：
    -   **风险集 (risk set)** $n_j$：在时间点 $t_{(j)}$ 之前（即 $t_{(j)}^{-}$ 时刻）仍然在研究中且尚未经历事件的个体数量。
    -   **事件数** $d_j$：在时间点 $t_{(j)}$ 恰好经历事件的个体数量。
3.  在时间点 $t_{(j)}$，存活过该时间点的条件概率可以估计为 $(1 - d_j/n_j)$。
4.  生存函数 $S(t)$ 的估计值 $\widehat{S}(t)$ 是所有不晚于 $t$ 的事件时间点上的条件生存概率的乘积：
    $$ \widehat{S}(t) = \prod_{t_{(j)} \le t} \left(1 - \frac{d_j}{n_j}\right) $$
审查观测本身不直接参与分子或分母的计算，但它们会在其审查时间点之后，从风险集中“退出”，从而影响后续事件时间点的风险集大小 $n_j$。

我们来看一个[临床试验](@entry_id:174912)的例子 。一项研究跟踪10名癌症患者，记录肿瘤缩小50%（“肿瘤反应”）的时间。数据点为 (时间, 状态)，其中“审查”表示患者因其他原因死亡或研究结束。我们想估计在第25周结束时，患者还未实现肿瘤反应的概率，即 $\widehat{S}(25)$。
数据中的事件时间点为6, 12, 15, 24, 30, 40周。
-   在 $t=6$ 时，10人处于风险中，1人发生事件。风险集 $n_1=10, d_1=1$。生存概率因子为 $1 - 1/10 = 9/10$。
-   在 $t=10$ 时，1人被审查。剩余8人进入下一个风险期。
-   在 $t=12$ 时，8人处于风险中，1人发生事件。风险集 $n_2=8, d_2=1$。生存概率因子为 $1 - 1/8 = 7/8$。
-   在 $t=15$ 时，7人处于风险中，1人发生事件。风险集 $n_3=7, d_3=1$。生存概率因子为 $1 - 1/7 = 6/7$。
-   在 $t=19$ 时，1人被审查。剩余5人进入下一个风险期。
-   在 $t=24$ 时，5人处于风险中，1人发生事件。风险集 $n_4=5, d_4=1$。生存概率因子为 $1 - 1/5 = 4/5$。
-   在 $t=25$ 时，1人被审查，但这不改变 $\widehat{S}(25)$ 的值，因为KM估计只在事件时间点更新。

因此，$\widehat{S}(25)$ 是所有在25周或之前的事件时间点上的生存概率因子的乘积：
$$ \widehat{S}(25) = \left(1-\frac{1}{10}\right) \times \left(1-\frac{1}{8}\right) \times \left(1-\frac{1}{7}\right) \times \left(1-\frac{1}{5}\right) = \frac{9}{10} \times \frac{7}{8} \times \frac{6}{7} \times \frac{4}{5} = 0.54 $$
这表明，根据这些数据，一个患者在25周后仍未出现肿瘤反应的估计概率是 $0.54$。

#### 区间审查数据：[非参数最大似然估计](@entry_id:164132)

[Kaplan-Meier](@entry_id:169317)方法不适用于左审查或区间审查数据。对于这些更复杂的数据结构，我们需要一种更通用的[非参数方法](@entry_id:138925)，即 **[非参数最大似然估计](@entry_id:164132) (Nonparametric Maximum Likelihood Estimation, [NPMLE](@entry_id:164132))**。[NPMLE](@entry_id:164132)的目标是找到一个在所有（非递减的）[分布函数](@entry_id:145626)中，能够最大化观测数据[似然函数](@entry_id:141927)的那一个。

对于 **当前状态数据**，[NPMLE](@entry_id:164132)的求解可以通过一个称为 **池邻近违规算法 (Pool-Adjacent-Violators Algorithm, PAVA)** 的方法来实现 。这个算法首先在每个检查时间点计算一个初始的、可能不满足单调性的事件发生率估计。然后，它通过迭代地“合并”（或“池化”）那些违反单调性约束的邻近点，并用加权平均值替换它们，直到整个估计序列满足[单调性](@entry_id:143760)为止。这种方法在数学上保证了能找到唯一的、满足[单调性](@entry_id:143760)约束的最大似然解。

对于更一般的 **区间审查数据**，[NPMLE](@entry_id:164132)可以通过一个称为 **Turnbull估计器** 的[迭代算法](@entry_id:160288)来计算。这个算法是[期望最大化](@entry_id:273892)(EM)算法的一个应用 。其基本思想如下：
1.  **划分区间**: 将所有观测区间的端点集合起来，排序并去重，从而将时间轴划分为一系列互不相交的“Turnbull细胞”。[NPMLE](@entry_id:164132)的结果是一个[离散分布](@entry_id:193344)，其概率质量只分配给这些细胞。
2.  **迭代估计**: 算法从一个初始的概率[质量分配](@entry_id:751704)开始，然后通过一个**[自洽方程](@entry_id:155949) (self-consistency equation)** 迭代更新。在每一步：
    -   **E-步 (期望)**: 对于每个观测区间 $(L_i, R_i]$，根据当前的概率[质量分配](@entry_id:751704)，计算真实事件时间落在该区间内每个细胞的[条件概率](@entry_id:151013)。
    -   **M-步 (最大化)**: 将所有观测的这些条件概率在每个细胞上加总，得到每个细胞的“期望事件数”。然后，将这些期望事件数归一化，得到新的概率[质量分配](@entry_id:751704)。
这个过程持续进行，直到概率[质量分配](@entry_id:751704)收敛到一个[不动点](@entry_id:156394)。这个[不动点](@entry_id:156394)就是最大化区间审查数据[似然函数](@entry_id:141927)的非参数解。

### 审查数据的[回归模型](@entry_id:163386)

[生存分析](@entry_id:163785)的一个核心目标是理解协变量（如年龄、治疗方案、基因标记等）如何影响事件时间。为此，我们需要回归模型。

#### [Cox比例风险模型](@entry_id:174252)与部分[似然](@entry_id:167119)

在[生存分析](@entry_id:163785)领域，**[Cox比例风险模型](@entry_id:174252) (Cox proportional hazards model)** 是迄今为止最重要和最流行的回归模型。它是一个 **[半参数模型](@entry_id:200031)**，其优美之处在于它允许我们在不指定基准[风险函数](@entry_id:166593) $h_0(t)$ 的具体形式的情况下，估计[协变](@entry_id:634097)量对风险的影响。

[Cox模型](@entry_id:164053)假设第 $i$ 个个体的[风险函数](@entry_id:166593) $h_i(t)$ 与一个未知的基准[风险函数](@entry_id:166593) $h_0(t)$ 和一个依赖于协变量 $\mathbf{X}_i$ 的因子成比例关系：
$$ h_i(t) = h_0(t) \exp(\boldsymbol{\beta}^\top \mathbf{X}_i) $$
其中 $\boldsymbol{\beta}$ 是需要估计的[回归系数](@entry_id:634860)向量。$\exp(\boldsymbol{\beta}^\top \mathbf{X}_i)$ 被称为 **[风险比](@entry_id:173429) (hazard ratio)**。

为了估计 $\boldsymbol{\beta}$ 而不估计无限维的 $h_0(t)$，Cox提出了一种巧妙的方法，称为 **部分[似然](@entry_id:167119) (partial likelihood)**。其思想是，在每个事件发生的时间点，我们只考虑“是这个特定个体而不是风险集中的其他任何一个[个体发生](@entry_id:164036)事件”的[条件概率](@entry_id:151013)。这个[条件概率](@entry_id:151013)恰好可以消去未知的 $h_0(t)$ 项。

在现代[生存分析](@entry_id:163785)理论中，这一思想可以用 **[计数过程](@entry_id:260664) (counting process)** 的语言来更严谨和普适地表述 。我们可以定义：
-   $N_i(t) = \mathbf{1}\{T_i \le t, \Delta_i=1\}$：表示个体 $i$ 到时间 $t$ 为止观测到的事件数（0或1）。
-   $Y_i(t) = \mathbf{1}\{T_i \ge t\}$：表示个体 $i$ 在时间 $t$ 是否处于风险中。

[Cox模型](@entry_id:164053)可以被看作一个强度过程模型 $\lambda_i(t) = Y_i(t) h_0(t) \exp(\boldsymbol{\beta}^\top \mathbf{X}_i(t))$。通过最大化部分[似然函数](@entry_id:141927)，我们可以得到 $\boldsymbol{\beta}$ 的估计。其对数部分[似然](@entry_id:167119)的导数，即 **[得分函数](@entry_id:164520) (score function)**，具有非常直观的解释：
$$ \mathbf{U}(\boldsymbol{\beta}) = \sum_{i=1}^n \int_0^\tau \left( \mathbf{X}_i(t) - \frac{\sum_{j=1}^n Y_j(t)\mathbf{X}_j(t)\exp(\boldsymbol{\beta}^{\top}\mathbf{X}_j(t))}{\sum_{k=1}^n Y_k(t)\exp(\boldsymbol{\beta}^{\top}\mathbf{X}_k(t))} \right) \mathrm{d}N_i(t) $$
这个公式的含义是，在每个事件发生的时间点（由 $\mathrm{d}N_i(t)$ 挑选出来），我们将发生事件的那个个体的[协变](@entry_id:634097)量 $\mathbf{X}_i(t)$ 与当时风险集中所有个体的[协变](@entry_id:634097)量的加权平均值进行比较（权重为它们的相对风险）。[得分函数](@entry_id:164520)就是将这些“残差”在所有事件上累加起来。当这个总和为零时，我们就找到了 $\boldsymbol{\beta}$ 的最大部分[似然](@entry_id:167119)估计。

#### 核心假设：独立审查

所有这些[生存分析](@entry_id:163785)方法，无论是[Kaplan-Meier](@entry_id:169317)还是[Cox模型](@entry_id:164053)，都依赖于一个至关重要的假设：审查机制是 **非信息性的 (non-informative)**。更准确地说，我们假设 **条件独立审查 (conditionally independent censoring)**。这意味着，在给定协变量 $\mathbf{X}$ 的条件下，个体的真实事件时间 $T$ 与其审查时间 $C$ 是相互独立的。用数学符号表示为：
$$ T \perp\!\!\!\perp C \mid \mathbf{X} $$
这个假设保证了在具有相同协变量的个体中，一个被审查的个体与一个未被审查的个体在事件风险上是没有系统性差异的。

我们可以使用 **有向无环图 (Directed Acyclic Graph, DAG)** 来更清晰地理解这个假设 。在一个典型的[生存分析](@entry_id:163785)场景中，协变量 $\mathbf{X}$ 既影响事件时间 $T$（例如，年龄大的患者风险更高），也可能影响审查时间 $C$（例如，年龄大的患者更可能因其他原因失访）。这对应于一个路径 $T \leftarrow \mathbf{X} \rightarrow C$。这个路径在 $T$ 和 $C$ 之间引入了关联。然而，一旦我们以 $\mathbf{X}$ 为条件，根据[d-分离](@entry_id:748152)准则，这个路径就被阻断了。因此，[条件独立性](@entry_id:262650) $T \perp\!\!\!\perp C \mid \mathbf{X}$ 成立。

这个图模型还警示我们一个潜在的陷阱：**[对撞偏倚](@entry_id:163186) (collider bias)**。在图中，$Y = \min(T, C)$ 和 $\Delta = \mathbb{I}(T \le C)$ 都是 **对撞节点**，因为它们都有来自 $T$ 和 $C$ 的箭头指向它们。如果我们以这些结果变量为条件进行分析（例如，只分析未被审查的个体），就会打开 $T \rightarrow Y \leftarrow C$ 或 $T \rightarrow \Delta \leftarrow C$ 的路径，从而在 $T$ 和 $C$ 之间人为地引入虚假的[统计关联](@entry_id:172897)，即使在以 $\mathbf{X}$ 为条件的情况下也是如此。这会破坏独立审查假设，导致有偏的估计。因此，在构建模型（尤其是像[逆概率](@entry_id:196307)审查加权(IPCW)这样的方法）时，对审查机制的建模只能以基线[协变](@entry_id:634097)量 $\mathbf{X}$ 为条件，而不能以任何事后发生的结果为条件。

### 高级主题与重要区分

最后，我们讨论两个在实践中经常遇到且至关重要的概念：截断和[竞争风险](@entry_id:173277)。

#### 审查与截断

**截断 (truncation)** 与审查密切相关，但有本质区别。审查数据是指那些被纳入研究但事件时间未被完全观测的个体。而[截断数据](@entry_id:163004)是指，只有当个体的事件时间落在某个特定区间内时，他们才有可能被纳入研究。

最常见的截断类型是 **左截断 (left-truncation)**，也称为 **延迟进入 (delayed entry)**。这发生于个体必须存活到某个时间点 $E_i$ 之后才能进入研究。例如，一项关于养老院居民[死亡率](@entry_id:197156)的研究，只有在人们进入养老院后才开始跟踪他们。如果一个人在进入养老院之前就去世了，他根本不会出现在数据集中。因此，所有被观测到的个体都满足条件 $T_i \ge E_i$。

左截断对[生存分析](@entry_id:163785)的主要影响是风险集的构建。在处理左截断和右审查数据时，在任何时间点 $t$，风险集 $R(t)$ 不仅包括那些尚未经历事件或被审查的个体，还必须是那些已经进入研究的个体。因此，风险集的正确定义是 $R(t) = \{i : E_i \le t \le Y_i\}$，其中 $Y_i = \min(T_i, C_i)$ 。在计算[Kaplan-Meier](@entry_id:169317)估计或[Cox模型](@entry_id:164053)的部分[似然](@entry_id:167119)时，必须使用这个修正后的风险集，否则会导致对生存概率的严重低估。

#### [竞争风险](@entry_id:173277)：一种常见的复杂情况

在许多研究中，个体可能经历多种不同类型的事件，而任何一种事件的发生都会阻止其他事件的发生。这种情况被称为 **[竞争风险](@entry_id:173277) (competing risks)**。例如，在心脏病研究中，患者可能死于[心肌](@entry_id:150153)梗死（事件类型1），也可能死于中风（事件类型2），或者接受心脏移植（事件类型3）。

处理[竞争风险](@entry_id:173277)时一个常见的、但**严重错误**的做法是，在分析某一特定原因（如[心肌](@entry_id:150153)梗死）的发生率时，将所有其他原因的事件（如中风）当作右审查处理，然后直接使用标准的[Kaplan-Meier](@entry_id:169317)方法。这种方法是错误的，因为它违反了独立审查的核心假设。一个死于中风的患者，其[心肌](@entry_id:150153)梗死的风险可能系统性地高于一个被审查的健康个体。

正确的分析方法是估计两个关键量：
1.  **原因别[风险函数](@entry_id:166593) (Cause-Specific Hazard Function)** $h_k(t)$：在时间 $t$ 发生原因 $k$ 事件的[瞬时速率](@entry_id:182981)。
2.  **累积发生率函数 (Cumulative Incidence Function, CIF)** $F_k(t)$：到时间 $t$ 为止，发生原因 $k$ 事件的累积概率。CIF是 $P(T \le t, J=k)$，其中 $J$ 是事件类型。

CIF的计算需要同时考虑所有原因的风险。可以证明，天真地使用KM方法（将其他事件视为审查）估计的“1-生存函数”实际上估计的是在一个假设性的、只有原因 $k$ 存在的世界里的事件发生概率。这个量会系统性地高估在存在[竞争风险](@entry_id:173277)的真实世界中发生原因 $k$ 事件的概率 。在存在[竞争风险](@entry_id:173277)（即原因2的风险 $\lambda_2 > 0$）的情况下，天真KM估计与真实CIF之间的偏差 $\Delta(t) = [1 - \widehat{S}^{\mathrm{KM}}_1(t)] - F_1(t)$ 总是正的，并且随着时间的推移而增加。因此，在[竞争风险](@entry_id:173277)存在时，必须使用专门为[竞争风险](@entry_id:173277)设计的统计方法来估计累积发生率。

本章系统地介绍了审查数据的原理与机制，从基本定义到核心的[似然](@entry_id:167119)原理，再到非参数和半参数的建模方法。理解这些原理和它们背后的假设，是正确应用[生存分析](@entry_id:163785)解决现实世界问题的关键。