## 引言
在非实验性的观测研究中，探寻因果关系如同在迷雾中航行。处理组与控制组之间往往存在系统性差异，即“[选择偏差](@entry_id:172119)”，这使得我们难以判断观测到的结果差异究竟是干预措施的真实效果，还是源于这些先前存在的不同。本文旨在系统介绍倾向性[得分匹配](@entry_id:635640)（Propensity Score Matching, PSM）——一种旨在拨开这层迷雾的强大统计方法。

本文将通过三个章节，引领读者全面掌握PSM。首先，在“原理与机制”中，我们将深入其统计学基础，理解它如何通过平衡[协变](@entry_id:634097)量来模拟随机试验。接着，在“应用与跨学科联系”中，我们将探索PSM在社会科学、[公共卫生](@entry_id:273864)和生态学等领域的实际应用，展示其解决真实世界问题的能力。最后，通过“动手实践”部分，您将有机会亲手实现PSM的关键步骤，将理论知识转化为实践技能。让我们首先从其核心原理出发，揭示倾[向性](@entry_id:144651)得分是如何作为一把钥匙，解锁观测数据中隐藏的因果秘密的。

## 原理与机制

在上一章引言中，我们探讨了从观测数据中推断因果关系的挑战。与随机对照试验（RCT）不同，观测研究中的处理分配（例如，患者选择何种药物、地块是否被划为保护区）并非由研究者随机决定，而是受到一系列个体特征的影响。这些特征既可能影响个体接受处理的可能性，也可能影响研究的最终结果。这种现象——即所谓的**[选择偏差](@entry_id:172119)（selection bias）**——是因果推断的核心障碍。它使得处理组和[控制组](@entry_id:747837)在接受处理前就已存在系统性差异，导致我们无法确定观测到的结果差异究竟是处理本身的效果，还是这些先前存在的差异所致。

本章将深入探讨一种旨在解决此问题的强大统计方法：**倾向性[得分匹配](@entry_id:635640)（Propensity Score Matching, PSM）**。我们将从其核心理论基础出发，系统性地阐述其工作原理、实施流程、诊断方法，以及在实践中可能遇到的挑战。我们的目标是揭示倾向性得分如何作为一个“平衡得分”，使我们能够在观测数据中模拟出随机试验的关键特性，从而获得更可靠的因果效应估计。

### 因果推断的基本挑战与[潜在结果框架](@entry_id:636884)

为了精确地定义因果效应，我们首先引入**[潜在结果](@entry_id:753644)（potential outcomes）**框架。对于每个研究单元（例如，一个病人或一块土地），我们设想存在两种[潜在结果](@entry_id:753644)：$Y(1)$表示该单元接受处理（Treatment, $T=1$）时的结果，而$Y(0)$表示该单元未接受处理（$T=0$）时的结果。对于任何一个单元，我们只能观测到这两种[潜在结果](@entry_id:753644)中的一种。例如，一个病人要么服用了新药，要么没有，我们无法同时观测到他服用和不服用新药的两种情况。这就是所谓的“因果推断的根本问题”。

我们通常感兴趣的因果量是**平均[处理效应](@entry_id:636010)（Average Treatment Effect, ATE）**，定义为 $ATE = \mathbb{E}[Y(1) - Y(0)]$。然而，在观测数据中，我们只能计算一个朴素的均值差异：$\mathbb{E}[Y | T=1] - \mathbb{E}[Y | T=0]$。这个差异通常不等于 ATE，因为处理组和[控制组](@entry_id:747837)的选择不是随机的。用数学语言表达，$\mathbb{E}[Y | T=1] = \mathbb{E}[Y(1) | T=1]$，而 $\mathbb{E}[Y | T=0] = \mathbb{E}[Y(0) | T=0]$。因此，朴素差异为 $\mathbb{E}[Y(1) | T=1] - \mathbb{E}[Y(0) | T=0]$。

这个表达式与 ATE 的差异在于：
$ATE = (\mathbb{E}[Y(1)|T=1] - \mathbb{E}[Y(0)|T=1]) + (\mathbb{E}[Y(0)|T=1] - \mathbb{E}[Y(0)|T=0])$
第一部分是处理组的平均[处理效应](@entry_id:636010)（ATT），第二部分 $(\mathbb{E}[Y(0)|T=1] - \mathbb{E}[Y(0)|T=0])$ 则代表了**[选择偏差](@entry_id:172119)**。它比较了处理组假如未接受处理时的[潜在结果](@entry_id:753644)与[控制组](@entry_id:747837)本来的结果。如果这个差值不为零，就说明两组在研究开始前就存在系统性差异，这些差异本身就会导致结果的不同，与[处理效应](@entry_id:636010)无关。

**混杂（Confounding）**是产生[选择偏差](@entry_id:172119)的主要原因。一个**[混杂变量](@entry_id:199777)（confounder）**是一个既与处理分配相关，又与结果相关的处理前变量。例如，在评估保护区对防止森林砍伐的效果时，地块的坡度、距道路的远近等因素都可能是[混杂变量](@entry_id:199777) ()。更陡峭、更偏远的地块本身就不容易被砍伐（影响结果），同时它们也更有可能被指定为保护区（影响处理分配）。直接比较保护区内外的森林砍伐率，会将保护区的真实效果与这些地理因素的“保护”效果混为一谈。

### 倾向性得分：一个神奇的“平衡得分”

为了解决混杂问题，理想的办法是比较“在所有其他方面都相同”的处理单元和控制单元。如果我们可以找到一个处理单元和一个控制单元，它们具有完全相同的[协变](@entry_id:634097)量（covariates）向量 $X$（例如，相同的坡度、道路距离、[人口密度](@entry_id:138897)等），那么它们之间的结果差异就可以更可信地归因于处理本身。然而，当[协变](@entry_id:634097)量维度很高或包含连续变量时，进行精确匹配几乎是不可能的。

1983年，Paul Rosenbaum 和 Donald Rubin 提出了一个突破性的解决方案。他们证明，我们无需在所有[协变](@entry_id:634097)量 $X$ 上进行匹配，只需在一个单一的标量——**倾向性得分（propensity score）**上进行匹配即可。

**倾向性得分**被定义为在给定一系列观测到的基线[协变](@entry_id:634097)量 $X$ 的条件下，一个单元接受处理的条件概率：
$$e(X) = \mathbb{P}(T=1 | X)$$

这个定义看似简单，但其背后蕴含着深刻的意义。倾[向性](@entry_id:144651)得分概括了所有[观测信息](@entry_id:165764)中与处理分配相关的那部分。它的核心作用体现在一个关键定理上：在满足特定假设的前提下，倾[向性](@entry_id:144651)得分是一个**平衡得分（balancing score）**。这意味着，在倾[向性](@entry_id:144651)得分的任何一个给定值上，处理分配 $T$ 与[协变](@entry_id:634097)量向量 $X$ 是条件独立的，即 $X \perp T | e(X)$。

这个性质的威力在于**降维**。它告诉我们，如果我们能找到一个处理单元和一个控制单元，它们拥有相同的倾[向性](@entry_id:144651)得分，那么我们可以期望它们在所有用于计算得分的协变量 $X$ 的[分布](@entry_id:182848)上也是相似的（即“平衡的”）。这样一来，我们就将一个高维度的[匹配问题](@entry_id:275163)简化为了一个一维度的[匹配问题](@entry_id:275163)。

为了使倾[向性](@entry_id:144651)得分方法有效，必须依赖两个核心假设：

1.  **条件无混杂性（Conditional Ignorability / Unconfoundedness）**：给定协变量 $X$，[潜在结果](@entry_id:753644) $(Y(1), Y(0))$ 与处理分配 $T$ 相互独立，即 $(Y(1), Y(0)) \perp T | X$。这个假设的实质是，我们已经观测并包含了所有同时影响处理分配和结果的[混杂变量](@entry_id:199777)。这是一个强假设，且无法被数据直接检验，它依赖于领域知识的支撑。

2.  **正值性（Positivity / Common Support）**：对于协变量 $X$ 的任何可能取值，单元接受处理和不接受处理的概率都严格介于0和1之间，即 $0  e(X)  1$。这个假设保证了对于任何特征的单元，我们总能找到与之相似的来自另一组的单元进行比较。

在这两个假设下，我们就可以通过在倾向性得分上进行匹配或调整，来估计无偏的因果效应。

### 倾向性[得分匹配](@entry_id:635640)的实践工作流

倾向性[得分匹配](@entry_id:635640)的完[整流](@entry_id:197363)程可以分解为一系列逻辑步骤。我们将以一个统一的框架来阐述，并结合具体问题中的实例进行说明。

#### 步骤一：估计倾[向性](@entry_id:144651)得分

在实际应用中，真实的倾向性得分 $e(X)$ 是未知的，必须从数据中进行估计。最常用的方法是使用**逻辑回归（logistic regression）**模型。该模型假设处理概率的[对数几率](@entry_id:141427)（log-odds）是协变量的线性函数：
$$ \ln\left(\frac{e(X)}{1-e(X)}\right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p $$
其中，$X_1, \dots, X_p$ 是协变量，$\beta_0, \dots, \beta_p$ 是需要估计的系数。

一旦模型拟合完成，我们就可以为每个单元计算其[线性预测](@entry_id:180569)值 $\eta = \hat{\beta}_0 + \hat{\beta}_1 X_1 + \dots + \hat{\beta}_p X_p$。然后，通过逻辑函数（logistic function）将其转换为倾[向性](@entry_id:144651)得分的估计值 $\hat{e}(X)$：
$$ \hat{e}(X) = \frac{\exp(\eta)}{1 + \exp(\eta)} $$

**示例：计算地块被指定为保护区的倾[向性](@entry_id:144651)** ()
假设一项[环境科学](@entry_id:187998)研究估计了一个用于预测地块被指定为保护区概率的逻辑回归模型。协变量包括坡度（slope）、距道路距离（dist）和一个表示是否邻近政治边界的二元[指示变量](@entry_id:266428)（bound）。模型系数如下：
- 截距 $\beta_0 = -3.8$
- 坡度系数 $\beta_{\text{slope}} = 0.07$
- 距离系数 $\beta_{\text{dist}} = 0.05$
- 边界系数 $\beta_{\text{bound}} = 0.60$

对于一个坡度为18度、距最近道路25公里且邻近政治边界的地块（$X_{\text{slope}}=18, X_{\text{dist}}=25, X_{\text{bound}}=1$），其[线性预测](@entry_id:180569)值为：
$$ \eta = -3.8 + (0.07 \times 18) + (0.05 \times 25) + (0.60 \times 1) = -0.69 $$
该地块的倾[向性](@entry_id:144651)得分估计值为：
$$ \hat{e}(X) = \frac{\exp(-0.69)}{1 + \exp(-0.69)} \approx \frac{0.5016}{1 + 0.5016} \approx 0.3340 $$
这意味着，基于其可观测特征，该地块被指定为保护区的估计概率约为 $0.334$。

#### 步骤二：为倾[向性](@entry_id:144651)得分[模型选择](@entry_id:155601)变量

这是整个分析中最具挑战性和最需要深思熟虑的一步。选择哪些变量进入倾[向性](@entry_id:144651)得分模型，直接决定了分析的成败。基本原则是：**倾向性得分模型的目的是为了实现协变量平衡，而不是为了最好地预测处理分配**。

**变量选择的核心准则：**

1.  **包含所有潜在的[混杂变量](@entry_id:199777)**：模型的首要任务是包含所有我们能想到的、基于领域知识判断的、同时与处理分配和研究结果相关的基线变量。在评估一项皮肤病疗法的研究中，这意味着需要包括基线疾病严重程度、年龄、性别、共病情况等一系列临床和[人口统计学](@entry_id:143605)变量 ()。忽略重要的[混杂变量](@entry_id:199777)（如疾病严重程度）会导致**残余混杂（residual confounding）**，使得匹配后的估计仍然有偏。

2.  **绝对不能包含处理后变量**：将处理开始后才出现的变量纳入倾向性得分模型是一个致命的错误。
    *   **中介变量（Mediators）**：如果一个变量是处理通往结果的因果路径上的一环，那么它就是中介变量。例如，在上述皮肤病研究中，“治疗第二周的早期反应”就是初始治疗选择（处理）影响最终90天结果（结果）的中间环节。在倾[向性](@entry_id:144651)得分模型中控制中介变量，会错误地阻断我们想要研究的因果路径，导致对总效应的估计产生偏差 ()。
    *   **对撞机（Colliders）**：这是一个更微妙但同样严重的陷阱。当一个变量同时被两个独立的变量所影响时，它就是一个[对撞机](@entry_id:192770)。在因果图中，这表现为 $A \rightarrow C \leftarrow B$ 的结构。在控制对撞机 $C$ 之前，$A$ 和 $B$ 之间没有关联。但一旦我们控制了 $C$，就会在 $A$ 和 $B$ 之间打开一条虚假的[统计关联](@entry_id:172897)。如果 $A$ 是处理的一个原因（或处理本身），而 $B$ 是结果的一个原因，那么控制对撞机就会人为地制造出处理和结果之间的非因果关联，这种偏误被称为 **M-偏误（M-bias）**。例如，在一个模拟研究中 ()，一个未观测变量 $U$ 影响处理 $T$，另一个未观测变量 $V$ 影响结果 $Y$，而一个可观测变量 $C$ 同时受 $U$ 和 $V$ 的影响（$U \rightarrow C \leftarrow V$）。如果在倾向性得分模型中包含了 $C$，即使 $T$ 和 $Y$ 之间原本没有通过 $U,V$ 的混杂路径，控制 $C$ 也会打开一条 $T \leftarrow U \rightarrow C \leftarrow V \rightarrow Y$ 的虚[假路径](@entry_id:168255)，从而引入偏误。反之，不包含 $C$ 的模型则能得到[无偏估计](@entry_id:756289)。

3.  **灵活地指定模型形式**：逻辑回归模型默认假设协变量对[对数几率](@entry_id:141427)的影响是线性的。如果真实的函数关系是[非线性](@entry_id:637147)的，那么一个简单的[线性模型](@entry_id:178302)可能无法准确估计倾向性得分，从而导致匹配后[协变](@entry_id:634097)量不平衡。一项模拟研究表明 ()，当真实关系是单调[非线性](@entry_id:637147)时（例如，二次或平方根），使用能够捕捉这种单调性的半参数**保序回归（isotonic regression）**模型，相比于错误指定的线性逻辑[回归模型](@entry_id:163386)，能实现更好的协变量平衡。在实践中，这意味着研究者应考虑在模型中加入协变量的[非线性](@entry_id:637147)项（如平方项、三次项）或使用更灵活的机器学习方法（如[梯度提升](@entry_id:636838)机、[随机森林](@entry_id:146665)）来估计倾向性得分。

#### 步骤三：进行匹配

在估计了每个单元的倾[向性](@entry_id:144651)得分之后，下一步就是利用这些得分来创建一个新的、平衡的样本。有多种匹配策略可供选择：

*   **最近邻匹配（Nearest-Neighbor Matching）**：这是最直观的方法。对于处理组中的每个单元，从控制组中找到一个倾向性得分与之最接近的单元作为匹配对。
    *   **有放回 vs. 无放回**：无放回匹配（without replacement）意味着一个[控制组](@entry_id:747837)单元一旦被匹配，就不能再用于匹配其他处理组单元。这可以保证匹配对之间的独立性，但可能会因为“用尽”了好的控制单元而导致后续匹配质量下降。有放回匹配（with replacement）则允许一个控制单元被多次使用，这通常能提高匹配的整体质量（因为优质的控制单元可以服务于多个处理单元），但需要对后续的[方差估计](@entry_id:268607)进行调整。
    *   **卡尺（Caliper）**：为了防止“差的匹配”，可以设置一个**卡尺**，即一个预先定义的最大可接受的倾[向性](@entry_id:144651)得分差异阈值。如果对于一个处理单元，找不到任何一个控制单元的得分差异在卡尺范围内，那么该处理单元将被丢弃，不进入最终分析。这有助于保证匹配质量，但代价是可能损失样本量。

#### 步骤四：评估协变量平衡性

这是倾向性[得分匹配](@entry_id:635640)流程中一个**不可或缺的诊断步骤**。我们必须用经验证据来检验匹配是否成功地平衡了协变量。

**评估平衡性的关键指标是绝对标准化均值差（Absolute Standardized Mean Difference, ASMD）**。对于一个协变量 $X_k$，其定义为：
$$ \text{ASMD} = \frac{|\bar{X}_{k, \text{treated}} - \bar{X}_{k, \text{control}}|}{s_{\text{pool}}} $$
其中，$\bar{X}_{k, \text{treated}}$ 和 $\bar{X}_{k, \text{control}}$ 分别是匹配后处理组和控制组中该协变量的样本均值。[标准化](@entry_id:637219)因子 $s_{\text{pool}}$ 通常使用原始（匹配前）处理组的[标准差](@entry_id:153618)，或者两组的[合并标准差](@entry_id:198759)。ASMD 不受样本量影响，直接衡量了均值差异相对于变量自身波动的大小。通常，**ASMD 小于 0.1 被认为是达到了良好平衡的经验法则**。

**示例：诊断[栖息地破碎化](@entry_id:143498)研究中的平衡性** ()
一项生态学研究比较了高破碎度景观和低破碎度景观对鸟类[物种丰富度](@entry_id:165263)的影响。匹配前，两组在人类人口密度（$X_1$）和道路密度（$X_2$）上存在巨大差异。
- **匹配前**，人口密度的 ASMD 计算为 $\frac{|120 - 90|}{40} = 0.75$，道路密度的 ASMD 为 $\frac{|6.0 - 4.5|}{2.0} = 0.75$。这两个值都远大于 0.1，表明存在严重的初始不平衡。
- **匹配后**，[人口密度](@entry_id:138897)的 ASMD 降至 $\frac{|118 - 116|}{40} = 0.05$，道路密度的 ASMD 降至 $\frac{|5.8 - 5.7|}{2.0} = 0.05$。这两个值均小于 0.1，表明匹配成功地消除了这两个关键协变量的均值差异。

除了 ASMD，研究者还应该检查[方差比](@entry_id:162608)（应接近1）以及倾向性得分本身的[分布](@entry_id:182848)图（如[直方图](@entry_id:178776)或QQ图），以确保两组在得分的整个[分布](@entry_id:182848)上都相似。如果检查发现不平衡，研究者需要回到步骤一或步骤二，调整倾[向性](@entry_id:144651)得分模型（例如，加入交互项或[非线性](@entry_id:637147)项），然后重新进行匹配和诊断，这是一个**迭代优化**的过程 ()。

一个更高级的诊断方法是**对抗性平衡检验** ()。其核心思想是：如果协变量真正达到了平衡，那么任何分类算法应该都无法仅凭[协变](@entry_id:634097)量 $X$ 来区分匹配样本中的处理单元和控制单元。我们可以训练一个强大的分类器（如带有多项式特征的逻辑回归），如果其在留出样本上的预测准确率接近于随机猜测的 50%，则可以认为平衡性良好。

#### 步骤五：估计[处理效应](@entry_id:636010)与不确定性

一旦确认协变量达到了满意的平衡，最后一步就是在匹配后的样本上估计[处理效应](@entry_id:636010)。对于连续性结果，这通常就是计算两组结果的均值差异。对于[二元结果](@entry_id:173636)，则是计算比例差异。

例如，在一项药物研究中，通过倾[向性](@entry_id:144651)[得分匹配](@entry_id:635640)得到了两组各625名患者。A组（新药）有515人康复，B组（标准药）有460人康复 ()。
- A组康复比例 $\hat{p}_A = 515 / 625 = 0.824$
- B组康复比例 $\hat{p}_B = 460 / 625 = 0.736$
- [处理效应](@entry_id:636010)的[点估计](@entry_id:174544)为 $\hat{p}_A - \hat{p}_B = 0.088$。

接下来，可以构建这个差异的[置信区间](@entry_id:142297)来量化其不确定性。使用标准公式，可以计算出95%[置信区间](@entry_id:142297)为 $(0.0423, 0.134)$。这个区间完全在0以上，表明有统计学证据支持新药比标准药更有效。需要注意的是，对匹配样本的标准误进行估计存在一些技术上的复杂性，因为匹配对并不完全独立，但对于大样本，将其近似为两个[独立样本](@entry_id:177139)进行分析是一种常见的做法。

### 高级主题与实践挑战

尽管倾[向性](@entry_id:144651)[得分匹配](@entry_id:635640)是一个强大的工具，但它并非万能药。它的有效性取决于无混杂假设，并且在实际操作中会遇到各种[数据质量](@entry_id:185007)问题。

#### 测量误差的影响

1.  **协变量中的测量误差**：无混杂假设要求我们控制所有真实的[混杂变量](@entry_id:199777)。但如果一个关键的混杂变量 $X$ 本身存在测量误差，我们实际观测到的是一个带噪音的版本 $W = X + U$，那么会发生什么？一项模拟研究 () 表明，即使我们使用观测到的 $W$ 来估计倾[向性](@entry_id:144651)得分并进行匹配，也无法完全消除由真实混杂变量 $X$ 引起的混杂。匹配后仍然会存在**残余混杂**，导致因果效应的估计有偏。误差越大，偏误通常也越大。这凸显了高质量、精确测量协变量的重要性。

2.  **处理变量中的[测量误差](@entry_id:270998)**：同样，如果处理分配本身被错误分类（例如，患者声称服用了药物但实际没有），也会导致偏误。假设我们观测到的是一个有误的标签 $L$，而不是真实的治疗状态 $T$。即使我们能够通过匹配完美地平衡[协变](@entry_id:634097)量，最终基于标签 $L$ 计算出的均值差异，其[期望值](@entry_id:153208)也将不再是真实的 ATE $\tau$。理论推导和模拟 () 表明，这种效应估计值通常是真实效应的**衰减（attenuated）**版本。其偏误大小是真实效应、处理 prevalence 以及标签分类的灵敏度和特异度的复杂函数。

### 总结

倾[向性](@entry_id:144651)[得分匹配](@entry_id:635640)为从观测数据中进行因果推断提供了一个严谨而灵活的框架。通过将众多协变量的信息压缩到一个单一的倾[向性](@entry_id:144651)得分中，它将一个棘手的高维[匹配问题](@entry_id:275163)转化为一个可操作的一维问题，旨在创建一个处理组和控制组在所有观测特征上都平衡的“伪随机”比较。

一个成功的倾[向性](@entry_id:144651)得分分析依赖于一个清晰的、原则性的工作流程：
1.  **模型设定**：基于领域知识，谨慎选择变量以构建一个能够充分捕捉处理分配机制的倾[向性](@entry_id:144651)得分模型，特别要注意避免纳入处理后变量和对撞机。
2.  **匹配**：选择合适的[匹配算法](@entry_id:269190)，在倾[向性](@entry_id:144651)得分上为处理单元寻找可比的控制单元。
3.  **平衡性诊断**：使用[标准化](@entry_id:637219)均值差等客观指标，严格检验匹配是否成功地消除了[协变](@entry_id:634097)量的不平衡。这是一个必须执行的、关键的诊断步骤。
4.  **效应估计**：在确认平衡的样本上，计算[处理效应](@entry_id:636010)的[点估计](@entry_id:174544)和[置信区间](@entry_id:142297)。

最后，我们必须铭记，倾向性[得分匹配](@entry_id:635640)的有效性最终建立在“无未观测混杂”这一无法检验的假设之上。任何统计调整方法都无法替代对研究设计、数据收集过程以及潜在未测量因素的深入思考。倾向性[得分匹配](@entry_id:635640)是一个强大的工具，但它要求使用者不仅是熟练的技术员，更应是批判性的科学家。