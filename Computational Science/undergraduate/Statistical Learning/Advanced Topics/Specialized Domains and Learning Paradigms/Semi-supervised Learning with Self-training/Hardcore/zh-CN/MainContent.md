## 引言
在机器学习的许多实际应用中，获取大量高质量的标记数据是一项成本高昂甚至难以完成的任务。然而，未标记数据却往往随处可见、唾手可得。如何有效利用这些海量的未标记数据来提升模型性能，是[半监督学习](@entry_id:636420)（Semi-supervised Learning）研究的核心问题。自训练（Self-training）作为其中最直观、最灵活的方法之一，为解决数据稀缺问题提供了一条强有力的途径。它通过一个巧妙的迭代过程，让模型“自我教学”，从无标签数据中挖掘宝贵信息。

本文旨在为读者提供一个关于自训练的全面而深入的理解，从其理论基础到实践应用。我们将不仅揭示其工作原理，更要剖析其潜在的风险，并探讨如何驾驭这些风险以发挥其最大效用。

为实现这一目标，本文将分为三个核心章节。在“原理与机制”一章中，我们将深入探讨自训练的迭代框架、其固有的确认偏差风险，以及如何通过置信度阈值、[标签平滑](@entry_id:635060)等技术进行[风险管理](@entry_id:141282)。随后的“应用与[交叉](@entry_id:147634)学科联系”一章，将展示自训练如何在自然语言处理、计算机视觉、[机器人学](@entry_id:150623)乃至[生物信息学](@entry_id:146759)等不同领域中大放异彩，并应对[类别不平衡](@entry_id:636658)、领[域漂移](@entry_id:637840)等真实世界的挑战。最后，在“动手实践”部分，我们将通过一系列精心设计的问题，将理论知识转化为解决实际问题的能力。通过这一结构化的学习路径，读者将能够系统地掌握自训练的精髓，并将其应用于自己的研究和项目中。

## 原理与机制

在上一章引言的基础上，本章将深入探讨自训练（Self-training）这一[半监督学习](@entry_id:636420)方法的内部工作原理和关键机制。我们将从其核心迭代流程入手，逐步揭示其潜在的风险，如确认偏差和错误传播。随后，我们将系统地分析用于控制这些风险的关键策略，特别是[置信度](@entry_id:267904)阈值在平衡偏差与[方差](@entry_id:200758)中的核心作用。最后，本章将探讨一系列高级机制，包括[标签平滑](@entry_id:635060)、一致性正则化，并将自训练与[期望最大化](@entry_id:273892)（EM）算法等其他[统计学习](@entry_id:269475)方法进行比较，以期为读者构建一个关于自训练既全面又深刻的理论框架。

### 自训练的核心机制

自训练遵循一个直观且易于实现的迭代式框架。该过程始于一个在少量可用标记数据上训练的“教师”模型。随后，这个教师模型被用来为大量未标记数据生成预测。其中，一部分被模型认为“高置信度”的预测被挑选出来，并被赋予“[伪标签](@entry_id:635860)”（pseudo-labels）。这些带有[伪标签](@entry_id:635860)的样本随后被加入到原始的标记数据集中，形成一个增广的训练集。最后，一个新的“学生”模型（通常与教师模型同构）在这个增广的数据集上被重新训练。这个学生模型随后成为下一轮迭代的教师模型，整个“教学”过程循环往复，直到满足某个停止条件（例如，[伪标签](@entry_id:635860)不再变化或达到最大迭代次数）。

这个过程的根本假设是：模型在其高置信度的预测上大概率是正确的。通过这种方式，模型能够利用未标记数据中的潜在结构信息，逐步扩大其知识边界，从而提升泛化性能。

为了精确理解[伪标签](@entry_id:635860)如何影响模型参数，我们考虑一个理想化的分析场景 。假设我们处理一个一维[二元分类](@entry_id:142257)问题，其中类别 $y=0$ 和 $y=1$ 的特征 $x$ 分别服从均值为 $\mu_0=0$、$\mu_1=2$ 且[方差](@entry_id:200758)均为 $\sigma^2=1$ 的高斯分布。类别先验是均衡的，即 $\Pr(y=1) = \Pr(y=0) = 0.5$。对于这种[数据结构](@entry_id:262134)，最优的逻辑回归分类器 $\ln(\frac{\Pr(y=1 \mid x)}{\Pr(y=0 \mid x)}) = w x + b$ 的参数 $(w^\star, b^\star)$ 可以通过贝叶斯决策理论直接导出，其形式等价于[线性判别分析](@entry_id:178689)（LDA）。最优参数为 $w^\star = (\mu_1 - \mu_0)/\sigma^2 = 2$ 和 $b^\star = -(\mu_1^2 - \mu_0^2)/(2\sigma^2) = -2$。由此得到的最优[决策边界](@entry_id:146073)为 $2x - 2 = 0$，即 $x=1$。

现在，我们进行一轮自训练。我们使用这个最优的“教师”模型为一个无限大的未标记样本池生成[伪标签](@entry_id:635860)：当 $x \ge 1$ 时，我们赋予[伪标签](@entry_id:635860) $\hat{y}=1$；当 $x  1$ 时，赋予[伪标签](@entry_id:635860) $\hat{y}=0$。接下来，我们在这个完全由[伪标签](@entry_id:635860)构成的“新”数据集上重新训练一个逻辑回归模型。由于数据生成过程的对称性，我们可以证明，被赋予[伪标签](@entry_id:635860) $\hat{y}=1$ 和 $\hat{y}=0$ 的数据比例恰好都是 $0.5$。利用截断高斯分布的期望公式，我们可以精确计算出这两个[伪标签](@entry_id:635860)类别下的样本均值，记为 $\tilde{\mu}_1$ 和 $\tilde{\mu}_0$。通过计算，我们发现一个有趣的现象：$\tilde{\mu}_1 + \tilde{\mu}_0 = 2$。

根据LDA与逻辑回归的等价性，新的模型参数 $\tilde{w}$ 和 $\tilde{b}$ 可以由新的类别均值 $\tilde{\mu}_1, \tilde{\mu}_0$ 和[伪标签](@entry_id:635860)比例计算得出。新的权重为 $\tilde{w} = (\tilde{\mu}_1 - \tilde{\mu}_0)/\sigma^2$，新的偏置为 $\tilde{b} = \ln(0.5/0.5) - (\tilde{\mu}_1^2 - \tilde{\mu}_0^2)/(2\sigma^2) = -(\tilde{\mu}_1 - \tilde{\mu}_0)(\tilde{\mu}_1 + \tilde{\mu}_0)/2$。代入 $\tilde{\mu}_1 + \tilde{\mu}_0 = 2$，我们得到 $\tilde{b} = -(\tilde{\mu}_1 - \tilde{\mu}_0) = -\tilde{w}$。因此，新的[决策边界](@entry_id:146073)由 $\tilde{w}x + \tilde{b} = 0$ 给出，即 $\tilde{w}x - \tilde{w} = 0$。只要 $\tilde{w} \neq 0$（可以验证确实如此），新的[决策边界](@entry_id:146073)仍然是 $x=1$。

这个理想化的例子表明，在某些对称且模型设定正确的条件下，自训练可以是一个[稳定过程](@entry_id:269810)，能够保持最优的[决策边界](@entry_id:146073)。然而，现实世界远比此复杂。这个例子也引发了一个关键问题：自训练过程总是这么稳定吗？如果初始模型并非最优，或者数据[分布](@entry_id:182848)不那么理想，会发生什么？

### 自训练的风险：确认偏差与错误传播

自训练最主要的风险在于其固有的反馈循环机制可能导致**确认偏差**（confirmation bias）。即，模型可能会不断强化其自身的初始预测，无论这些预测是否正确。一旦一个错误的[伪标签](@entry_id:635860)被纳入[训练集](@entry_id:636396)，它就会“教导”下一代模型去重复这个错误，甚至可能以更高的[置信度](@entry_id:267904)。如果这种现象持续发生，微小的初始错误就可能被放大，最终导致模型性能的严重退化。

#### [高杠杆点](@entry_id:167038)的危害

确认偏差的危害在存在**[高杠杆点](@entry_id:167038)**（high-leverage points）时尤为显著。在统计学中，[杠杆值](@entry_id:172567)衡量了一个数据点的[特征向量](@entry_id:151813)对[模型拟合](@entry_id:265652)的潜在影响力。[特征值](@entry_id:154894)远离数据中心（即特征均值）的点具有高[杠杆值](@entry_id:172567)。一个被错误赋予[伪标签](@entry_id:635860)的[高杠杆点](@entry_id:167038)，会对模型参数产生不成比例的巨大影响。

我们可以通过一个简单的回归例子来揭示这一机制 。假设我们的初始标记数据集为 $\mathcal{L} = \{(-1,-1),(0,0),(1,1)\}$。通过[普通最小二乘法](@entry_id:137121)（OLS）拟合的教师模型显然是 $y=x$，其斜率为 $1$。现在，我们有一个未标记数据点，其特征为 $x_U=10$。这个点距离原始数据均值 $\bar{x}_{\mathcal{L}}=0$ 非常遥远，因此是一个[高杠杆点](@entry_id:167038)。教师模型预测其标签为 $y_U = 10$。但假设由于某种[分布偏移](@entry_id:638064)，该点被错误地赋予了[伪标签](@entry_id:635860) $\tilde{y}_U = -10$。

我们将这个错误的[伪标签](@entry_id:635860)点 $(10, -10)$ 加入训练集，并在增广后的数据集 $\mathcal{L}' = \{(-1,-1), (0,0), (1,1), (10,-10)\}$ 上重新训练线性模型。根据OLS斜率的计算公式 $b_1 = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2}$，我们可以计算出新的斜率。对于 $\mathcal{L}'$，我们有 $n=4$, $\bar{x}=2.5$, $\bar{y}=-2.5$。代入计算可得，新的斜率 $b_1 = \frac{-73}{77} \approx -0.9481$。仅仅因为一个错误的高杠杆[伪标签](@entry_id:635860)点，回归线就从斜率 $1$ 急剧地“倾斜”到了接近 $-1$。OLS为了最小化点 $(10,-10)$ 带来的巨大平方误差，被迫向该点严重倾斜，从而完全破坏了从原始数据中学到的规律。

这个现象在[分类问题](@entry_id:637153)中有着直接的类比。一个远离当前[决策边界](@entry_id:146073)（高杠杆）的未标记点，如果被赋予了错误的[伪标签](@entry_id:635860)，在再训练过程中，它会对[决策边界](@entry_id:146073)产生强大的“拉力”，可能导致边界发生显著旋转，以牺牲整体分类性能为代价去迎合这个错误的[伪标签](@entry_id:635860)。

#### 错误传播的动力学

当错误开始累积，就可能引发“错误爆炸”的链式反应，这一过程被称为**错误传播**（error propagation）。我们可以将此过程类比为生物学中的种群繁衍模型，例如高尔顿-沃森（Galton-Watson）分支过程，来对其进行[数学建模](@entry_id:262517) 。

假设在第 $t$ 轮迭代中，我们有 $Z_t$ 个错误的[伪标签](@entry_id:635860)。每个错误的[伪标签](@entry_id:635860)，在下一轮迭代中，平均会“诱导”产生 $R$ 个新的错误[伪标签](@entry_id:635860)。这个 $R$ 被称为**繁殖均值**（reproduction mean）。那么，在下一轮中，我们期望的错误[伪标签](@entry_id:635860)数量为 $\mathbb{E}[Z_{t+1} | Z_t] = R \cdot Z_t$。经过多轮迭代，期望的错误数量将呈几何级数增长或衰减：$\mathbb{E}[Z_t] = \mathbb{E}[Z_0] R^t$。

这个模型的动态行为完全由 $R$ 的值决定：
-   如果 $R  1$，错误数量将呈指数级增长，导致错误爆炸，自训练过程发散。
-   如果 $R = 1$，错误数量将保持稳定，过程处于临界状态。
-   如果 $R  1$，错误数量将指数级衰减至零，表明自训练过程是稳定的，能够自我修正。

因此，为了确保自训练的成功，一个核心任务就是设法让繁殖均值 $R  1$。繁殖均值 $R$ 本身受算法设计的影响。例如，我们可以将其分解为 $R = \eta \cdot g(\tau)$，其中 $\eta$ 代表每个错误所能影响到的下游未标记样本的数量，而 $g(\tau)$ 是在置信度阈值为 $\tau$ 的情况下，一个被影响的样本最终被错误地赋予[伪标签](@entry_id:635860)的概率。通常，$g(\tau)$ 是 $\tau$ 的减函数，例如 $g(\tau) = \exp(-\beta \tau)$。这意味着提高[置信度](@entry_id:267904)阈值 $\tau$ 可以有效降低 $g(\tau)$，从而减小 $R$，抑制错误传播。

#### 稳定性分析

错误传播的动力学也与自训练过程的**稳定性**（stability）密切相关。我们可以将自训练过程视为一个寻找分类器[不动点](@entry_id:156394)（fixed point）的迭代过程。一个理想的[不动点](@entry_id:156394)是[贝叶斯最优分类器](@entry_id:164732)。如果自训练过程能够从一个接近最优的分类器出发，并最终收敛回这个最优分类器，我们就称该[不动点](@entry_id:156394)是稳定的。

考虑一个一维[线性分类器](@entry_id:637554)，其决策边界为 $x=t$。自训练的每一轮都根据当前的[伪标签](@entry_id:635860)数据重新计算一个新的[决策边界](@entry_id:146073)。这定义了一个更新算子 $t_{new} = T(t_{old})$。在一个对称的[分类问题](@entry_id:637153)中，最优[决策边界](@entry_id:146073)通常是 $t^\star=0$。为了判断这个理想[不动点](@entry_id:156394)的[局部稳定性](@entry_id:751408)，我们可以考察更新算子在[不动点](@entry_id:156394)处的导数 $T'(0)$ 。如果 $|T'(0)|  1$，任何靠近 $t^\star=0$ 的微小扰动（即初始分类器的微小误差）都会在迭代中被逐渐修正，最终收敛回 $t^\star$。反之，如果 $|T'(0)| > 1$，微小的误差则会被放大，导致迭代过程偏离理想解，这正是自训练失败的根源。通过严谨的数学推导可以发现，$T'(0)$ 的值取决于类别[分布](@entry_id:182848)的间隔 $\Delta$、[方差](@entry_id:200758) $\sigma^2$ 以及筛选[伪标签](@entry_id:635860)时采用的置信度裕量 $\tau$。这再次说明，通过审慎地[选择算法](@entry_id:637237)参数（如 $\tau$），可以主动控制自训练过程的稳定性。

### 风险管理：[伪标签](@entry_id:635860)中的偏差-方差权衡

上述分析表明，简单地将所有[伪标签](@entry_id:635860)纳入训练过程是极其危险的。现代自训练方法的核心在于如何明智地筛选和使用[伪标签](@entry_id:635860)。这通常通过设定一个**[置信度](@entry_id:267904)阈值** $\tau$ 来实现：只有当模型对一个未标记样本的预测[置信度](@entry_id:267904)（例如，最大softmax概率）大于 $\tau$ 时，该样本才会被赋予[伪标签](@entry_id:635860)并用于训练。

选择 $\tau$ 的过程本质上是一个**偏差-方差权衡**（bias-variance trade-off） 。
-   **偏差（Bias）**: [伪标签](@entry_id:635860)的质量直接影响模型的偏差。一个较高的阈值 $\tau$ 意味着我们只接纳那些模型“非常确定”的预测。这些预测正确的概率更高，因此引入的伪[标签噪声](@entry_id:636605)（即错误标签）更少。这有助于降低因错误标签而引入的[模型偏差](@entry_id:184783)。
-   **[方差](@entry_id:200758)（Variance）**: 训练数据量的大小影响模型的[方差](@entry_id:200758)。一个较低的阈值 $\tau$ 允许更多的未标记样本被纳入训练，从而增大了总[训练集](@entry_id:636396)的大小。根据[统计学习理论](@entry_id:274291)（例如VC理论），更大的[训练集](@entry_id:636396)有助于降低模型的[方差](@entry_id:200758)，提高其泛化能力。

因此，$\tau$ 的选择面临一个两难的境地：
-   **过高的 $\tau$**：我们得到了一批高质量的[伪标签](@entry_id:635860)（低偏差），但数量很少。新增的数据不足以显著降低模型[方差](@entry_id:200758)，导致模型**[欠拟合](@entry_id:634904)**（underfitting）。我们未能充分利用未标记数据带来的好处。
-   **过低的 $\tau$**：我们获得了大量的[伪标签](@entry_id:635860)，有助于降低模型[方差](@entry_id:200758)，但其中混杂了大量错误标签（高偏差）。这些错误标签会误导模型的学习，导致模型性能下降，甚至比仅用标记数据训练的模型更差。

存在一个最优的阈值 $\tau^\star$，它在引入可接受偏差的同时，最大化地利用未标记数据来降低[方差](@entry_id:200758)，从而使模型的总风险最小化。在一个简化的理论模型中，假设模型的风险可以表示为 $R(\tau) = \eta(\tau) + k \sqrt{h / (n_L + n_U(\tau))}$，其中 $\eta(\tau)$ 是[伪标签](@entry_id:635860)的期望错误率（偏差项），而第二项是与[VC维](@entry_id:636849) $h$ 和总训练样本数 $n_L+n_U(\tau)$ 相关的[模型容量](@entry_id:634375)惩罚（[方差](@entry_id:200758)项）。通过对这个[风险函数](@entry_id:166593)进行最小化，可以解析地求解出最优阈值 $\tau^\star$。例如，在一个假设场景中，$\tau^\star$ 可能表达为 $1 + \frac{n_{L}}{|U|} - \frac{k^{2/3}h^{1/3}}{|U|^{1/3}}$ 的形式。这个公式清晰地揭示了最优阈值如何依赖于[模型复杂度](@entry_id:145563) $h$、标记数据量 $n_L$ 和未标记数据量 $|U|$ 等因素。

### 高级机制与方法论比较

为了进一步提升自训练的性能和稳定性，研究者们发展出了一系列高级技术，并深入探讨了它与其他学习[范式](@entry_id:161181)的关系。

#### [标签平滑](@entry_id:635060)（Label Smoothing）

对抗确认偏差和模型过分自信的一个有效技术是**[标签平滑](@entry_id:635060)**（label smoothing）。在标准的[分类任务](@entry_id:635433)中，我们使用“硬”的one-hot向量（例如 $[0, 1, 0]$）作为标签。这会激励模型输出极端化的概率（例如 $[0.01, 0.98, 0.01]$），使其变得过分自信。在自训练中，这种过分自信尤其有害，因为它会使模型过早地停止对高[置信度](@entry_id:267904)样本的学习，并固化可能存在的错误。

[标签平滑](@entry_id:635060)通过使用“软”标签来解决这个问题。一个one-hot标签 $y$ 被替换为一个平滑后的[分布](@entry_id:182848) $q_k = (1 - \alpha) \mathbf{1}\{k = c\} + \alpha/K$，其中 $c$ 是真实类别，$\alpha$ 是一个小的平滑参数，$K$ 是类别总数。

我们来分析[标签平滑](@entry_id:635060)在自训练中对梯度的影响 。对于一个[伪标签](@entry_id:635860)为 $c$ 的样本，分类器对其预测的概率为 $p_c$。[损失函数](@entry_id:634569)关于对应logit $z_c$ 的梯度为 $g_c = p_c - q_c$。
-   **无[标签平滑](@entry_id:635060)**（$\alpha=0$）：$q_c=1$，梯度为 $g_c(0) = p_c - 1$。当模型变得非常自信时（$p_c \to 1$），梯度趋近于零，学习过程停滞。
-   **有[标签平滑](@entry_id:635060)**（$\alpha > 0$）：$q_c = 1 - \alpha + \alpha/K$，梯度为 $g_c(\alpha) = p_c - (1 - \alpha + \alpha/K)$。即使当 $p_c \to 1$，梯度也趋向一个非零常数，即 $\alpha - \alpha/K$。这保证了学习信号的持续存在，防止模型变得绝对自信。

我们可以定义一个比率 $R(\alpha, p_c, K) = |g_c(\alpha)| / |g_c(0)|$ 来量化[标签平滑](@entry_id:635060)对梯度的相对影响。通过推导，可以得到 $R = |\frac{\alpha(1 - 1/K)}{1 - p_c} - 1|$。这个表达式表明，[标签平滑](@entry_id:635060)的作用是自适应的：对于置信度较低（$p_c$ 较小）的[伪标签](@entry_id:635860)，它会减小梯度的大小，从而减弱对不确定标签的追逐；而对于[置信度](@entry_id:267904)极高（$p_c \to 1$）的[伪标签](@entry_id:635860)，它能有效防止梯度消失，从而缓解过分自信和确认偏差。

#### 监控与一致性

在实践中，监控自训练过程的稳定性至关重要。一个简单而有效的度量是**[伪标签](@entry_id:635860)漂移**（label drift），即在连续的迭代中，未标记样本被赋予的[伪标签](@entry_id:635860)发生变化的比例 。一个较高的漂移率，例如 $23\%$，表明模型的预测非常不稳定，训练目标在剧烈变化，这可能阻碍收敛或导致性能[振荡](@entry_id:267781)。

为了缓解高度的标签漂移，除了我们已经讨论过的置信度阈值策略外，另一个强大的技术是引入**一致性正则化**（consistency regularization）。其核心思想是，模型对于同一个输入样本，即使在不同的迭代步骤或受到微小扰动时，也应产生相似的预测。具体来说，我们可以在训练目标中加入一个正则项，惩罚当前模型 $p_t(y|x)$ 与上一轮模型 $p_{t-1}(y|x)$ 的[预测分布](@entry_id:165741)之间的差异。常用的度量是[KL散度](@entry_id:140001)，例如，在损失函数中增加一项 $\lambda \cdot \mathbb{E}_{x \sim \mathcal{U}}[D_{\mathrm{KL}}(p_t(\cdot|x) || p_{t-1}(\cdot|x))]$。这一项鼓励模型在学习新知识的同时，保持与过去认知的一致性，从而使学习轨迹更加平滑，抑制了预测的剧烈[振荡](@entry_id:267781)。

#### 与其他学习[范式](@entry_id:161181)的关系

**与[期望最大化](@entry_id:273892)（EM）算法的比较**

自训练与另一类经典的[半监督学习](@entry_id:636420)方法——基于生成模型的[期望最大化](@entry_id:273892)（EM）算法——有着深刻的联系 。[EM算法](@entry_id:274778)将未标记数据的标签视为“[缺失数据](@entry_id:271026)”，并通过迭代的E步和[M步](@entry_id:178892)来最大化观测数据（包括标记和未标记数据）的[边际似然](@entry_id:636856)。
-   **E步（Expectation）**：使用当前模型参数，计算每个未标记样本属于各个类别的后验概率（称为“责任”，responsibilities）。
-   **[M步](@entry_id:178892)（Maximization）**：使用标记数据的硬标签和未标记数据的软标签（即责任），更新模型参数以最大化期望的完全数据[对数似然](@entry_id:273783)。

当自训练采用“软[伪标签](@entry_id:635860)”（即使用[后验概率](@entry_id:153467)作为加权标签而非硬标签）并且模型是一个正确指定的生成模型（如[朴素贝叶斯](@entry_id:637265)）时，**软自训练的过程在数学上等价于[EM算法](@entry_id:274778)**。两者的参数更新公式完全相同，因此会收敛到相同的局部最优解。

然而，常见的“硬自训练”（使用$\operatorname{argmax}$选择标签）是[EM算法](@entry_id:274778)的一个贪婪近似。当类别[分布](@entry_id:182848)有重叠，即后验概率不总是0或1时，硬自训练会强制将概率（如0.7）转换为确定性标签（1.0），而EM则会保留这种不确定性。这种差异导致它们在实践中通常会收敛到不同的解。特别是在模型被**错误指定**（misspecified）时（例如，[朴素贝叶斯](@entry_id:637265)的特征独立性假设不成立），硬自训练会因为模型输出的过分自信的[后验概率](@entry_id:153467)而放大错误，而EM虽然也在优化一个“错误”的目标函数，但其过程更为稳健，保证了[边际似然](@entry_id:636856)的单调增长。

**与[自助法](@entry_id:139281)（Bootstrap）的比较**

自训练也可以被视为一种**[方差缩减](@entry_id:145496)**（variance reduction）技术，这使它能够与[自助聚合](@entry_id:636828)（[Bagging](@entry_id:145854)）等[集成方法](@entry_id:635588)进行比较 。[Bagging](@entry_id:145854)通过从原始标记数据集中有放回地抽样，创建多个自助（bootstrap）样本，训练多个模型并对其预测进行平均，从而降低估计器的[方差](@entry_id:200758)。

自训练与[Bagging](@entry_id:145854)的共同目标都是降低[方差](@entry_id:200758)，但途径不同：
-   **[Bagging](@entry_id:145854)**：通过在**同一个数据集**上进行[重采样](@entry_id:142583)和平均，来平滑估计。它不引入新的数据源，因此通常不会引入额外的偏差。
-   **自训练**：通过引入**新的数据**（即[伪标签](@entry_id:635860)样本）来增大训练集，从而降低[方差](@entry_id:200758)。

在一个理想化的加权[最小二乘回归](@entry_id:262382)设定中，我们可以定量地比较这两种方法。结果显示，当[伪标签](@entry_id:635860)是无偏的，自训练可能比[Bagging](@entry_id:145854)实现更大幅度的[方差缩减](@entry_id:145496)，因为它利用了标记集之外的额外信息。然而，自训练的致命弱点是，如果教师模型存在偏差（例如，它对[伪标签](@entry_id:635860)的预测存在系统性误差），这个偏差将被引入到再训练的过程中。当偏差足够大时，自训练估计器的[均方误差](@entry_id:175403)（MSE = Variance + Bias²）可能会超过[Bagging](@entry_id:145854)估计器。这再次凸显了自训练的核心权衡：**用引入偏差的风险，换取更大程度的[方差缩减](@entry_id:145496)**。

#### 在[协变量偏移](@entry_id:636196)下的自训练

最后，一个在实际应用中至关重要的高级问题是**[协变量偏移](@entry_id:636196)**（covariate shift），即标记数据与未标记数据的特征[分布](@entry_id:182848)不一致 ($p_{\mathcal{L}}(x) \neq p_{\mathcal{U}}(x)$)，但类别[条件分布](@entry_id:138367)保持不变 ($p(y|x)$ 相同)。在这种情况下，直接应用自训练是危险的，因为在标记数据上训练的教师模型在未标记数据[分布](@entry_id:182848)的某些区域可能并不可靠。

一个稳健的策略是首先识别出两个[分布](@entry_id:182848)的重叠区域，并只在该区域内进行自训练 。这可以通过估计**密度比** $r(x) = p_{\mathcal{U}}(x) / p_{\mathcal{L}}(x)$ 来实现。一个巧妙的方法是，将标记样本和未标记样本混合，训练一个“域分类器”来区分一个样本是来自 $\mathcal{L}$ 还是 $\mathcal{U}$。该分类器的[后验概率](@entry_id:153467) $\hat{q}(x) = \mathbb{P}(s=\mathcal{U} | x)$ 可以通过[贝叶斯法则](@entry_id:275170)直接转换为对密度比的估计：$\hat{r}(x) \propto \hat{q}(x) / (1 - \hat{q}(x))$。

通过这个估计出的密度比，我们可以筛选出那些 $p_{\mathcal{L}}(x)$ 和 $p_{\mathcal{U}}(x)$ 都具有显著密度的区域（即 $\hat{r}(x)$ 既不太大也不太小的区域）。将[伪标签](@entry_id:635860)的生成和使用限制在这些高重叠区域，可以有效避免模型在[分布](@entry_id:182848)外区域进行不可靠的推断，从而降低[负迁移](@entry_id:634593)的风险，使自训练在面对[协变量偏移](@entry_id:636196)时更加安全和有效。