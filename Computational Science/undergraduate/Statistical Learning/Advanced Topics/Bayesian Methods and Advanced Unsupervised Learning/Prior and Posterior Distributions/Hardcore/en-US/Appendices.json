{
    "hands_on_practices": [
        {
            "introduction": "One of the most powerful applications of Bayesian inference is quantifying how evidence changes our beliefs about an unknown proportion. This first exercise  explores a practical question: how many observations are needed to shift our belief to a specific level of certainty? We will use the fundamental Beta-Binomial conjugate model, where our prior belief about a probability $p$, represented by a Beta distribution, is updated with new success/failure data.",
            "id": "1946628",
            "problem": "A materials science company has developed a new, experimental process for manufacturing optical fibers. The key quality metric is the proportion, $p$, of manufactured fibers that meet a stringent signal transmission standard. As the process is entirely new, the engineering team has no prior knowledge about its effectiveness. They decide to model their initial belief about $p$ using a continuous uniform distribution over the interval $[0, 1]$, which is equivalent to a Beta distribution with parameters $\\alpha=1$ and $\\beta=1$.\n\nTo update their belief, they test a sequence of newly manufactured fibers. They find that the first $n$ fibers they test all meet the transmission standard. What is the smallest integer number of consecutive successful tests, $n$, required for the posterior mean of the proportion $p$ to exceed $0.98$?",
            "solution": "The prior for the success proportion is $p \\sim \\mathrm{Beta}(\\alpha,\\beta)$ with $\\alpha=1$ and $\\beta=1$. Under the Beta-Binomial conjugate model, after observing $S$ successes and $F$ failures, the posterior is $\\mathrm{Beta}(\\alpha+S,\\beta+F)$. Here, the first $n$ tests are all successes, so $S=n$ and $F=0$, giving the posterior\n$$\np \\mid \\text{data} \\sim \\mathrm{Beta}(1+n,1).\n$$\nThe mean of a $\\mathrm{Beta}(a,b)$ distribution is $\\frac{a}{a+b}$, hence the posterior mean is\n$$\n\\mathbb{E}[p \\mid \\text{data}] = \\frac{n+1}{n+2}.\n$$\nWe require the smallest integer $n$ such that\n$$\n\\frac{n+1}{n+2} > 0.98.\n$$\nSince $n+2>0$ for all integer $n \\geq 0$, we can multiply both sides by $n+2$ without changing the inequality direction:\n$$\nn+1 > 0.98(n+2).\n$$\nExpanding and rearranging,\n$$\nn+1 > 0.98n + 1.96 \\quad \\Rightarrow \\quad n - 0.98n > 1.96 - 1 \\quad \\Rightarrow \\quad 0.02\\,n > 0.96.\n$$\nDividing by $0.02$ (positive) yields\n$$\nn > 48.\n$$\nTherefore, the smallest integer $n$ satisfying the strict inequality is $n=49$. Note that for $n=48$, the mean is $\\frac{49}{50}=0.98$, which does not exceed $0.98$, confirming the need for $n=49$.",
            "answer": "$$\\boxed{49}$$"
        },
        {
            "introduction": "Beyond simple proportions, we often need to estimate the rate at which events occur, such as the frequency of defects in a product or arrivals at a service center. This practice  introduces the Poisson-Gamma conjugate family, a cornerstone for modeling count data. You will see how a prior belief about a rate parameter $\\lambda$, described by a Gamma distribution, is systematically refined by observed counts to yield an updated posterior distribution.",
            "id": "1946607",
            "problem": "An industrial process manufactures large sheets of a specialized polymer. A quality control specialist models the number of microscopic imperfections found in a randomly chosen 1 cm by 1 cm square sample of the polymer as a random variable following a Poisson distribution with an unknown mean rate $\\lambda$ imperfections per cm$^2$.\n\nBased on extensive experience with similar manufacturing processes, the specialist's prior belief about the parameter $\\lambda$ is modeled by a Gamma distribution with a shape parameter $\\alpha = 3$ and a rate parameter $\\beta = 2$. The probability density function of a Gamma($\\alpha, \\beta$) distribution is given by $f(x; \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} \\exp(-\\beta x)$ for $x > 0$.\n\nThe specialist then takes five independent 1 cm by 1 cm square samples and observes the following number of imperfections: 4, 2, 0, 3, 1.\n\nGiven this new data, what is the updated expected value (mean) of the rate parameter $\\lambda$? Express your answer as an exact fraction.",
            "solution": "Let the observed counts be denoted by $y_{1},\\dots,y_{n}$, where $n=5$ and $y_{1},\\dots,y_{5}\\in \\{4,2,0,3,1\\}$. The sampling model assumes $y_{i}\\mid \\lambda \\sim \\text{Poisson}(\\lambda)$ independently, so the likelihood is\n$$\nL(\\lambda; y_{1:n})=\\prod_{i=1}^{n}\\frac{\\exp(-\\lambda)\\lambda^{y_{i}}}{y_{i}!} \\propto \\lambda^{\\sum_{i=1}^{n} y_{i}} \\exp(-n\\lambda).\n$$\nThe prior is $\\lambda \\sim \\text{Gamma}(\\alpha,\\beta)$ with density\n$$\np(\\lambda)=\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\lambda^{\\alpha-1}\\exp(-\\beta \\lambda), \\quad \\lambda>0.\n$$\nBy conjugacy, the posterior is proportional to the product of prior and likelihood:\n$$\np(\\lambda\\mid y_{1:n}) \\propto \\lambda^{\\alpha-1}\\exp(-\\beta \\lambda)\\cdot \\lambda^{\\sum_{i=1}^{n} y_{i}}\\exp(-n\\lambda)\n= \\lambda^{\\alpha+\\sum_{i=1}^{n} y_{i}-1}\\exp\\!\\big(-( \\beta+n)\\lambda\\big),\n$$\nwhich is the kernel of a $\\text{Gamma}(\\alpha+\\sum_{i=1}^{n} y_{i},\\, \\beta+n)$ distribution (shape-rate parameterization).\n\nFor the given values, $\\alpha=3$, $\\beta=2$, $n=5$, and $\\sum_{i=1}^{5} y_{i}=4+2+0+3+1=10$, the posterior is\n$$\n\\lambda \\mid y_{1:5} \\sim \\text{Gamma}(3+10,\\, 2+5)=\\text{Gamma}(13,7).\n$$\nThe mean of a $\\text{Gamma}(\\alpha',\\beta')$ distribution (rate parameterization) is $\\alpha'/\\beta'$, hence the updated expected value is\n$$\n\\mathbb{E}[\\lambda \\mid y_{1:5}] = \\frac{13}{7}.\n$$",
            "answer": "$$\\boxed{\\frac{13}{7}}$$"
        },
        {
            "introduction": "A key feature of Bayesian updating is its logical consistency. Does it matter if you analyze your data all at once (batch update) or revise your beliefs one observation at a time (sequential update)? This exercise  tackles this fundamental question, demonstrating that the final posterior belief is the same regardless of the path taken. This powerful property highlights the robustness and elegance of the Bayesian framework.",
            "id": "1946578",
            "problem": "A quality control engineer is assessing a new manufacturing process designed to produce highly reliable electronic components. The success rate of the process, defined as the probability $p$ that a component is non-defective, is unknown. The engineer's initial belief about this probability $p$ is modeled as a random variable following a Beta distribution with known parameters $\\alpha > 0$ and $\\beta > 0$. The probability density function for this belief is proportional to $p^{\\alpha-1}(1-p)^{\\beta-1}$.\n\nThe engineer observes a test batch of $n$ newly produced components. In this batch, a total of $k$ components are found to be non-defective (successes), and consequently, $n-k$ components are defective (failures). The engineer wishes to update their belief about $p$ based on these observations. Two different methods of updating are considered.\n\nMethod 1 (Batch Update): The engineer waits until all $n$ components have been tested. They then update their initial belief (the prior) using the total counts of $k$ successes and $n-k$ failures all at once. The updated belief (the posterior) is another Beta distribution with new parameters, which we will denote as $(\\alpha_{batch}, \\beta_{batch})$.\n\nMethod 2 (Sequential Update): The engineer updates their belief after each component is tested, one by one. Starting with the same initial belief $(\\alpha, \\beta)$, they update it after the first observation. The resulting posterior distribution then serves as the prior for the second observation. This procedure is repeated for all $n$ observations in the sequence. Let the parameters of the final Beta distribution after all $n$ updates be denoted by $(\\alpha_{seq}, \\beta_{seq})$.\n\nDetermine the expression for the parameter $\\alpha_{batch}$ resulting from the batch update and the expression for the parameter $\\beta_{seq}$ resulting from the sequential update. Present your answer as a pair of expressions $(\\alpha_{batch}, \\beta_{seq})$.",
            "solution": "We model the unknown success probability $p$ with a Beta prior having parameters $(\\alpha,\\beta)$, whose density is proportional to $p^{\\alpha-1}(1-p)^{\\beta-1}$. For $n$ independent Bernoulli trials with $k$ successes and $n-k$ failures, the likelihood is proportional to $p^{k}(1-p)^{n-k}$.\n\nBatch update: By Bayesâ€™ rule and Beta-Binomial conjugacy, the posterior density is proportional to the product of prior and likelihood,\n$$\np^{\\alpha-1}(1-p)^{\\beta-1}\\cdot p^{k}(1-p)^{n-k}\n= p^{\\alpha-1+k}(1-p)^{\\beta-1+(n-k)}.\n$$\nThis is the kernel of a Beta distribution with parameters $(\\alpha+k,\\beta+n-k)$. Therefore, the batch-updated parameter for $p$ corresponding to the exponent of $p$ is\n$$\n\\alpha_{batch}=\\alpha+k.\n$$\n\nSequential update: Consider a single Bernoulli observation $x\\in\\{0,1\\}$ with prior $\\operatorname{Beta}(a,b)$. The likelihood is proportional to $p^{x}(1-p)^{1-x}$. The posterior is then proportional to\n$$\np^{a-1}(1-p)^{b-1}\\cdot p^{x}(1-p)^{1-x}\n= p^{(a-1)+x}(1-p)^{(b-1)+(1-x)},\n$$\nwhich is the kernel of $\\operatorname{Beta}(a+x,\\,b+1-x)$. Hence, each success ($x=1$) increments the first parameter by $1$, and each failure ($x=0$) increments the second parameter by $1$. After $k$ successes and $n-k$ failures, starting from $(\\alpha,\\beta)$, the final parameters are $(\\alpha+k,\\beta+n-k)$. Therefore, the sequentially updated second parameter is\n$$\n\\beta_{seq}=\\beta+(n-k).\n$$\n\nThus, the requested pair is $(\\alpha_{batch},\\beta_{seq})=(\\alpha+k,\\beta+n-k)$.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\alpha+k & \\beta+n-k\\end{pmatrix}}$$"
        }
    ]
}