{
    "hands_on_practices": [
        {
            "introduction": "t-SNE最常见的应用之一是可视化带标签的数据，并以不同的颜色展示类别。虽然生成的图在视觉上引人注目，但解读它们却充满挑战。这项概念性练习  挑战了一个常见但错误的假设：t-SNE图上聚类之间的距离直接对应于原始高维空间中类别间的相似性。掌握这一点是负责任地使用t-SNE的第一步。",
            "id": "3179569",
            "problem": "一个在 $\\mathbb{R}^{D}$ 中包含 $n=5{,}000$ 个观测值的数据集被划分为 $C=10$ 个带标签的类别。你使用 t-分布随机邻域嵌入 (t-SNE) 计算了一个到 $\\mathbb{R}^{2}$ 的嵌入，其中困惑度 $\\mathcal{P}=40$，在初始优化阶段使用了早期夸大，并进行了随机初始化。然后，你通过根据每个点的类别为其着色，并用类别名称标注视觉上可识别的簇，来叠加类别标签。多位观察者得出结论，嵌入中看起来彼此靠近的带标签的簇，对应于在原始高维空间中相似的类别。\n\n从 t-SNE 构建和优化邻域结构的基本原理出发，选择所有关于如何解释此类标签叠加和带标签簇的邻近性的最合理陈述：\n\nA. 在一个二维 t-SNE 图中，簇中心之间的欧几里得距离是类别间高维相异性的可靠代理；因此，邻近的带标签簇表示相似的类别。\n\nB. t-SNE 优化的目标函数强调在高概率邻域关系上的一致性，因此多种全局不同的布局都可以满足局部约束；因此，不应将带标签簇的邻近性视为类别相似性的证据。\n\nC. 增加困惑度 $\\mathcal{P}$ 总是会增加嵌入中簇之间的距离，使得标签叠加可以全局地解释为类别相似性。\n\nD. 不同的随机初始化和早期夸大策略可以产生保留相似局部邻域但将簇放置在不同相对位置的嵌入；因此，推断邻近的带标签簇表示相似的类别可能会产生误导。\n\nE. 因为 t-SNE 在嵌入空间中使用重尾分布，远处的点会产生不可忽略的影响，这使得全局几何结构有意义；因此，带标签簇的邻近性忠实地反映了全局相似性。\n\nF. 如果两个类别在高维空间中重叠，t-SNE 必然会将其带标签的点合并成一个单一的簇；任何分裂的簇都意味着是不同的类别。",
            "solution": "我们从 t-分布随机邻域嵌入 (t-SNE) 的核心定义开始。设高维数据为 $\\{\\mathbf{x}_i\\}_{i=1}^{n}$，其中 $\\mathbf{x}_i \\in \\mathbb{R}^{D}$。t-SNE 通过为每个点 $i$ 定义一个高斯核来构建高维空间中的条件邻域亲和度，该高斯核的带宽 $\\sigma_i$ 是为了匹配目标困惑度而选择的。条件概率为\n$$\np_{j \\mid i} = \\frac{\\exp\\!\\left(-\\frac{\\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert^2}{2\\sigma_i^2}\\right)}{\\sum_{k \\neq i} \\exp\\!\\left(-\\frac{\\lVert \\mathbf{x}_i - \\mathbf{x}_k \\rVert^2}{2\\sigma_i^2}\\right)}, \\quad j \\neq i,\n$$\n而点 $i$ 处的困惑度是根据 $\\{p_{j \\mid i}\\}_{j \\neq i}$ 的香农熵 $H(P_i)$ 定义的\n$$\n\\mathrm{Perplexity}(P_i) = 2^{H(P_i)}, \\quad H(P_i) = - \\sum_{j \\neq i} p_{j \\mid i} \\log_2 p_{j \\mid i}.\n$$\n这些条件概率被对称化为联合概率\n$$\np_{ij} = \\frac{p_{j \\mid i} + p_{i \\mid j}}{2n}, \\quad i \\neq j,\n$$\n其中 $p_{ii} = 0$。在低维嵌入中，对于点集 $\\{\\mathbf{y}_i\\}_{i=1}^{n}$（位于 $\\mathbb{R}^{2}$ 中），t-SNE 定义了\n$$\nq_{ij} = \\frac{\\left(1 + \\lVert \\mathbf{y}_i - \\mathbf{y}_j \\rVert^2\\right)^{-1}}{\\sum_{k \\neq \\ell} \\left(1 + \\lVert \\mathbf{y}_k - \\mathbf{y}_\\ell \\rVert^2\\right)^{-1}}, \\quad i \\neq j, \\quad q_{ii} = 0,\n$$\n这对应于嵌入空间中自由度为 1 的学生 t-分布（柯西分布）。优化过程最小化 Kullback–Leibler 散度 (KL 散度)\n$$\n\\mathrm{KL}(P \\,\\|\\, Q) = \\sum_{i \\neq j} p_{ij} \\log \\frac{p_{ij}}{q_{ij}},\n$$\n该散度会强烈惩罚原始空间中的高概率点对（大的 $p_{ij}$）在嵌入中被赋予小概率（小的 $q_{ij}$）的情况。这种结构使得 t-SNE 强调局部邻域的保持：匹配高 $p_{ij}$ 的点对优先于安排低概率、相距较远的点对。在 $q_{ij}$ 中使用重尾核减轻了拥挤问题，它允许用中等距离来表示更大的高维分离，但这并不强制保持全局度量。该算法还表现出不变性（例如平移和旋转）以及对初始化和早期夸大的敏感性，这些因素可以在不显著改变驱动目标函数的邻域的情况下，改变分离良好的组的相对位置。\n\n基于这些原理，我们评估每个选项：\n\nA. 它声称 $\\mathbb{R}^{2}$ 中簇中心之间的欧几里得距离可靠地代表了类别间的高维相异性。t-SNE 的目标不是保持全局距离或类别均值；它的目标是保持局部邻域概率。两个簇可以被放置得彼此靠近或远离，这取决于优化路径、初始化以及由重尾核产生的排斥力。此外，嵌入中的簇中心不一定对应于 $\\mathbb{R}^{D}$ 中的类别均值。因此，将簇间中心距离解释为类别相似性的可靠度量是不合理的。结论：错误。\n\nB. 它指出，目标函数强调在高概率邻域关系上的一致性，允许多种全局不同的布局来满足局部约束，并警告不要将簇的邻近性解释为类别相似性。这直接源于最小化 $\\mathrm{KL}(P \\,\\|\\, Q)$，该目标函数用 $p_{ij}$ 对误差进行加权，使得局部邻域占主导地位。许多嵌入对于高 $p_{ij}$ 的点对可以有相似的 $q_{ij}$，但簇的质心排列却不同。因此，不应将带标签簇的邻近性视为类别相似性的证据。结论：正确。\n\nC. 它断言增加困惑度 $\\mathcal{P}$ 总是会增加簇间距离，从而使全局解释有效。困惑度 $\\mathcal{P}$ 通过熵 $H(P_i)$ 控制有效邻域的大小，但其对全局几何结构的影响既不是单调的，也不是普遍增加的。根据数据结构，增加 $\\mathcal{P}$ 可能会合并或分离结构，也可能会缩小或扩大簇间距离。无法保证“总是增加”，也不能使全局距离可解释为相似性。结论：错误。\n\nD. 它声称不同的随机初始化和早期夸大策略可以产生保留相似局部邻域但簇相对位置不同的嵌入，这使得基于邻近性的类别相似性推断具有误导性。$\\mathrm{KL}(P \\,\\|\\, Q)$ 的优化，加上非凸性、初始化和早期夸大（临时放大 $p_{ij}$ 以突出局部结构），可以在保持邻域的同时改变全局布局。这是一个与上述基本原理一致且被广泛理解的特性。结论：正确。\n\nE. 它认为重尾分布使得全局几何结构有意义，因此带标签簇的邻近性忠实地反映了全局相似性。$q_{ij}$ 中的重尾主要解决的是拥挤问题，它允许用中等距离来表示更大的高维分离；它并不强制要求大规模的几何结构反映原始空间。全局距离除了通过 $q_{ij}$ 的归一化和排斥相互作用产生的间接影响外，不受目标函数的约束，因此不是类别相似性的忠实指标。结论：错误。\n\nF. 它指出，$\\mathbb{R}^{D}$ 中重叠的类别必然被 t-SNE 合并成一个单一的簇，而分裂的簇则意味着是不同的类别。t-SNE 是无监督的，不使用标签；它保持局部邻域，而不是类别边界。由于局部流形结构或参数选择，重叠的类别可能会看起来是分开的，而如果它们的局部邻域交错，不同的类别也可能看起来是合并的。“必然”这个词太强了，是不正确的。结论：错误。\n\n因此，合理的陈述是 B 和 D。",
            "answer": "$$\\boxed{BD}$$"
        },
        {
            "introduction": "在完成了前一个练习后，一个自然的问题是：如果全局距离不被保留，那么是什么力量塑造了t-SNE图的布局呢？本实践  深入t-SNE的数学核心，探究核函数所扮演的角色。通过推导梯度，并将标准的学生t分布核与一个假设的拉普拉斯核进行比较，你将揭示t-SNE的设计对于在聚类之间创造清晰分离和缓解“拥挤问题”为何至关重要。",
            "id": "3179628",
            "problem": "考虑 t-分布随机邻域嵌入 (t-SNE) 方法，其目标函数可以写成高维邻域概率与低维核诱导概率之间的 Kullback–Leibler 散度 (KL)。令 $y_i \\in \\mathbb{R}^d$ 表示低维嵌入，$r_{ij} = \\lVert y_i - y_j \\rVert$ 表示两两之间的距离。假设低维空间中的相似度由一个可微的径向核函数 $g(r)$ 定义，使得\n$$\nq_{ij} = \\frac{g(r_{ij})}{\\sum_{k \\ne \\ell} g(r_{k\\ell})},\n$$\n且目标函数为\n$$\nC(y) = \\sum_{i \\ne j} p_{ij} \\log\\left(\\frac{p_{ij}}{q_{ij}}\\right),\n$$\n其中 $p_{ij}$ 是固定的、对称的高维相似度，满足 $\\sum_{i \\ne j} p_{ij} = 1$。从这些核心定义出发，对于一个通用的可微核函数 $g(r)$，推导其负梯度（“力”）$F_i = -\\frac{\\partial C}{\\partial y_i}$，并用 $p_{ij}$、$q_{ij}$、$g'(r)$ 以及单位方向 $u_{ij} = \\frac{y_i - y_j}{r_{ij}}$ 来表示。然后，将您的表达式特化到远邻域情况，即 $p_{ij} + p_{ji} \\approx 0$ 的情况，并提取径向排斥力大小 $M(r)$ 作为 $r$ 的函数。\n\n接下来，考虑两种特定的核函数：\n- 自由度为1的 Student-t 核函数，定义为 $g_{\\mathrm{t}}(r) = (1 + r^2)^{-1}$。\n- 一种提出的 Laplace 核函数变体，定义为 $g_{\\mathrm{L}}(r) = \\exp(-r)$。\n\n从第一性原理出发，确定当 $r \\to \\infty$ 时，排斥力大小 $M_{\\mathrm{t}}(r)$ 和 $M_{\\mathrm{L}}(r)$ 的远距离渐近行为，并评估与 Student-t 核函数相比，Laplace 核函数的尾部形状是否能缓解拥挤问题。您的分析必须从上述 KL 目标函数和 $q_{ij}$ 的定义出发；不要假设或使用预先给出的 t-SNE 梯度公式。\n\n您的程序必须实现以下测试套件，每个测试产生一个基本类型的结果（布尔值或浮点数）：\n\n- 定义“力-分布比”$R(r)$ 为\n$$\nR(r) = \\frac{\\left|g'_{\\mathrm{L}}(r)\\right|}{\\left|g'_{\\mathrm{t}}(r)\\right|},\n$$\n如果将归一化项 $\\sum_{k \\ne \\ell} g(r_{k\\ell})$ 视为一个与单个远距离点对无关的常数因子，那么该比值与远邻排斥力大小之比成正比。计算集合 $\\{10^{-8}, 1, 5, 50\\}$ 中每个 $r$ 值的 $R(r)$，并将每个结果作为浮点数返回。\n\n- 返回一个布尔值，表示 $R(50)  10^{-6}$ 是否成立。\n\n- 使用数值积分计算浮点数\n$$\n\\Delta = \\int_{10}^{20} \\left|g'_{\\mathrm{L}}(r)\\right| \\, dr \\;-\\; \\int_{10}^{20} \\left|g'_{\\mathrm{t}}(r)\\right| \\, dr,\n$$\n并返回 $\\Delta$。\n\n- 返回一个布尔值，表示 $\\Delta  0$ 是否成立。\n\n- 对于阈值 $\\tau = 10^{-3}$，分别计算使得 $\\left|g'_{\\mathrm{L}}(r)\\right| = \\tau$ 和 $\\left|g'_{\\mathrm{t}}(r)\\right| = \\tau$ 成立的半径 $r^\\ast_{\\mathrm{L}}$ 和 $r^\\ast_{\\mathrm{t}}$，并返回浮点数比值 $r^\\ast_{\\mathrm{L}} / r^\\ast_{\\mathrm{t}}$。\n\n- 返回一个布尔值，表示 $r^\\ast_{\\mathrm{L}}  r^\\ast_{\\mathrm{t}}$ 是否成立。\n\n您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔的结果列表（例如，“[result1,result2,result3,result4,result5,result6,result7,result8,result9]”）。不需要用户输入，本问题不涉及物理单位。",
            "solution": "问题的分析主要分两个阶段进行。首先，我们对通用核函数下的 t-SNE 目标函数进行梯度形式化推导。其次，我们分析两种特定核函数的梯度，并按要求评估其性质。\n\n### 第 1 步：通用梯度推导\n\n需要最小化的目标函数是高维相似度 $p_{ij}$ 和低维相似度 $q_{ij}$ 之间的 Kullback-Leibler (KL) 散度：\n$$\nC(y) = \\sum_{i \\ne j} p_{ij} \\log\\left(\\frac{p_{ij}}{q_{ij}}\\right)\n$$\n其中 $y_i \\in \\mathbb{R}^d$ 是低维嵌入。高维相似度 $p_{ij}$ 是给定的、固定的、对称的（$p_{ij}=p_{ji}$），并且归一化以满足 $\\sum_{i \\ne j} p_{ij} = 1$。低维相似度 $q_{ij}$ 使用可微的径向核函数 $g(r)$ 定义：\n$$\nq_{ij} = \\frac{g(r_{ij})}{\\sum_{k \\ne \\ell} g(r_{k\\ell})} = \\frac{g(r_{ij})}{Z}\n$$\n其中 $r_{ij} = \\lVert y_i - y_j \\rVert$ 且 $Z = \\sum_{k \\ne \\ell} g(r_{k\\ell})$ 是归一化常数。\n\n我们可以通过分离包含 $y$ 的项来重写代价函数 $C(y)$：\n$$\nC(y) = \\sum_{i \\ne j} p_{ij} \\log p_{ij} - \\sum_{i \\ne j} p_{ij} \\log q_{ij}\n$$\n第一项相对于 $y_i$ 是一个常数。代入 $q_{ij}$ 的定义：\n$$\nC(y) = \\text{const} - \\sum_{i \\ne j} p_{ij} \\log \\left( \\frac{g(r_{ij})}{Z} \\right) = \\text{const} - \\sum_{i \\ne j} p_{ij} \\log g(r_{ij}) + \\left(\\sum_{i \\ne j} p_{ij}\\right) \\log Z\n$$\n由于 $\\sum_{i \\ne j} p_{ij} = 1$，我们有：\n$$\nC(y) = \\text{const} - \\sum_{i \\ne j} p_{ij} \\log g(r_{ij}) + \\log \\left( \\sum_{k \\ne \\ell} g(r_{k\\ell}) \\right)\n$$\n我们要求解负梯度，即“力”$F_i = -\\frac{\\partial C}{\\partial y_i}$。我们计算梯度 $\\frac{\\partial C}{\\partial y_i}$：\n$$\n\\frac{\\partial C}{\\partial y_i} = -\\sum_{k \\ne \\ell} p_{k\\ell} \\frac{1}{g(r_{k\\ell})} \\frac{\\partial g(r_{k\\ell})}{\\partial y_i} + \\frac{1}{Z} \\frac{\\partial Z}{\\partial y_i}\n$$\n一个关于两点间距离的函数 $f(r_{k\\ell})$ 对 $y_i$ 的导数是：\n$$\n\\frac{\\partial f(r_{k\\ell})}{\\partial y_i} = f'(r_{k\\ell}) \\frac{\\partial r_{k\\ell}}{\\partial y_i} = f'(r_{k\\ell}) \\frac{y_k - y_\\ell}{r_{k\\ell}} (\\delta_{ik} - \\delta_{i\\ell}) = f'(r_{k\\ell}) u_{k\\ell} (\\delta_{ik} - \\delta_{i\\ell})\n$$\n其中 $u_{k\\ell} = (y_k - y_\\ell) / r_{k\\ell}$ 是单位方向向量。\n\n应用此规则，$\\frac{\\partial C}{\\partial y_i}$ 第一项中的求和仅在 $k=i$ 或 $\\ell=i$ 时非零：\n$$\n-\\sum_{k \\ne \\ell} p_{k\\ell} \\frac{g'(r_{k\\ell})}{g(r_{k\\ell})} u_{k\\ell} (\\delta_{ik} - \\delta_{i\\ell}) = -\\sum_{j \\ne i} p_{ij} \\frac{g'(r_{ij})}{g(r_{ij})} u_{ij} - \\sum_{j \\ne i} p_{ji} \\frac{g'(r_{ji})}{g(r_{ji})} (-u_{ji})\n$$\n使用 $r_{ij}=r_{ji}$ 和 $u_{ij}=-u_{ji}$，第二部分变为 $-\\sum_{j \\ne i} p_{ji} \\frac{g'(r_{ij})}{g(r_{ij})} u_{ij}$。将它们合并得到：\n$$\n-\\sum_{j \\ne i} (p_{ij} + p_{ji}) \\frac{g'(r_{ij})}{g(r_{ij})} u_{ij}\n$$\n类似地，归一化常数 $Z$ 的导数是：\n$$\n\\frac{\\partial Z}{\\partial y_i} = \\sum_{k \\ne \\ell} g'(r_{k\\ell}) u_{k\\ell} (\\delta_{ik} - \\delta_{i\\ell}) = \\sum_{j \\ne i} g'(r_{ij})u_{ij} - \\sum_{j \\ne i} g'(r_{ji})u_{ji} = \\sum_{j \\ne i} (g'(r_{ij})u_{ij} - g'(r_{ij})(-u_{ij})) = 2\\sum_{j \\ne i} g'(r_{ij}) u_{ij}\n$$\n将所有部分合并，梯度为：\n$$\n\\frac{\\partial C}{\\partial y_i} = -\\sum_{j \\ne i} (p_{ij} + p_{ji}) \\frac{g'(r_{ij})}{g(r_{ij})} u_{ij} + \\frac{2}{Z} \\sum_{j \\ne i} g'(r_{ij}) u_{ij}\n$$\n重排求和项：\n$$\n\\frac{\\partial C}{\\partial y_i} = \\sum_{j \\ne i} \\left( \\frac{2 g'(r_{ij})}{Z} - (p_{ij} + p_{ji}) \\frac{g'(r_{ij})}{g(r_{ij})} \\right) u_{ij}\n$$\n因此，力 $F_i = -\\frac{\\partial C}{\\partial y_i}$ 为：\n$$\nF_i = \\sum_{j \\ne i} \\left( (p_{ij} + p_{ji}) \\frac{g'(r_{ij})}{g(r_{ij})} - \\frac{2 g'(r_{ij})}{Z} \\right) u_{ij}\n$$\n这个表达式将作用在点 $y_i$ 上的力分解为来自其他点 $y_j$ 的成对贡献之和。与 $(p_{ij}+p_{ji})$ 成正比的项代表吸引力，而涉及 $Z$ 的项代表排斥力。注意 $g(r)$ 通常是一个递减函数，因此 $g'(r)  0$。吸引项将 $y_i$ 拉向 $y_j$（与 $u_{ij}$ 方向相反），而排斥项将 $y_i$ 推离 $y_j$（沿着 $u_{ij}$ 方向）。\n\n### 第 2 步：远邻排斥力大小\n\n在点对 $(i, j)$ 的远邻域情况下，高维相似度可忽略不计，即 $p_{ij} + p_{ji} \\approx 0$。在这种情况下，来自 $y_j$ 的力的吸引部分消失了。力简化为一个纯粹的排斥分量：\n$$\nF_{i \\leftarrow j}^{\\text{far}} \\approx \\left( - \\frac{2 g'(r_{ij})}{Z} \\right) u_{ij}\n$$\n径向排斥力大小是这个力贡献的大小：\n$$\nM(r) = \\left| - \\frac{2 g'(r)}{Z} \\right| = \\frac{2 |g'(r)|}{\\sum_{k \\ne \\ell} g(r_{k\\ell})}\n$$\n在分析排斥力的函数形式时，对于给定的嵌入配置，$Z$ 被视为一个常数因子。因此，排斥力分布的形状由 $|g'(r)|$ 决定。\n\n### 第 3 步：特定核函数的分析\n\n我们现在分析两种指定的核函数。\n\n1.  **Student-t 核函数**: $g_{\\mathrm{t}}(r) = (1 + r^2)^{-1}$\n    其导数为 $g'_{\\mathrm{t}}(r) = -2r(1 + r^2)^{-2}$。\n    排斥力大小的函数形式为 $M_{\\mathrm{t}}(r) \\propto |g'_{\\mathrm{t}}(r)| = 2r(1 + r^2)^{-2}$。\n    当 $r \\to \\infty$ 时，其渐近行为为 $M_{\\mathrm{t}}(r) \\propto r(r^2)^{-2} = r \\cdot r^{-4} = r^{-3}$。这是一种代数（幂律）衰减。\n\n2.  **Laplace 核函数**: $g_{\\mathrm{L}}(r) = \\exp(-r)$\n    其导数为 $g'_{\\mathrm{L}}(r) = -\\exp(-r)$。\n    排斥力大小的函数形式为 $M_{\\mathrm{L}}(r) \\propto |g'_{\\mathrm{L}}(r)| = \\exp(-r)$。\n    当 $r \\to \\infty$ 时，这表现为指数衰减。\n\n**拥挤问题的评估**：\nSNE 中的拥挤问题源于当高维空间中相距很远的点，没有足够的排斥力将它们在低维空间中分离开。t-SNE 通过使用 Student-t 核函数缓解了这个问题，其代数衰减（$r^{-3}$）提供了“重尾”特性，因此与原始 SNE 中使用的高斯核函数的指数衰减相比，它能提供更长程的排斥力。\n\n将 Laplace 核函数与 Student-t 核函数进行比较，我们发现排斥力大小 $M_{\\mathrm{L}}(r) \\propto e^{-r}$ 呈指数衰减，这比 $M_{\\mathrm{t}}(r) \\propto r^{-3}$ 的代数衰减要快得多。指数衰减构成了作用范围更短的力。因此，与 Student-t 核函数相比，Laplace 核函数在远距离点之间提供的排斥力要弱得多。这将加剧而不是缓解拥挤问题。由于其重尾的排斥力，Student-t 核函数在这方面更为优越。\n\n### 第 4 步：数值计算\n\n该问题要求基于这些核函数进行一系列数值计算。\n\n- **核函数及其导数**：\n  $|g'_{\\mathrm{t}}(r)| = 2r(1 + r^2)^{-2}$\n  $|g'_{\\mathrm{L}}(r)| = \\exp(-r)$\n\n- **力-分布比**：$R(r) = |g'_{\\mathrm{L}}(r)| / |g'_{\\mathrm{t}}(r)| = \\frac{\\exp(-r)}{2r(1+r^2)^{-2}} = \\frac{\\exp(-r)(1+r^2)^2}{2r}$。\n\n- **积分差**：$\\Delta = \\int_{10}^{20} \\exp(-r) \\, dr - \\int_{10}^{20} 2r(1+r^2)^{-2} \\, dr$。这些积分可以进行数值计算或解析计算。\n  $\\int \\exp(-r) dr = -\\exp(-r)$\n  $\\int 2r(1+r^2)^{-2} dr = -(1+r^2)^{-1}$ (使用换元法 $u=1+r^2$)\n  $\\Delta = [-\\exp(-r)]_{10}^{20} - [-(1+r^2)^{-1}]_{10}^{20} = (e^{-10} - e^{-20}) - (\\frac{1}{101} - \\frac{1}{401})$。\n\n- **阈值为 $\\tau = 10^{-3}$ 时的半径**：\n  $r^\\ast_{\\mathrm{L}}$：求解 $|g'_{\\mathrm{L}}(r)| = e^{-r} = 10^{-3} \\implies r = -\\ln(10^{-3}) = 3\\ln(10)$。\n  $r^\\ast_{\\mathrm{t}}$：求解 $|g'_{\\mathrm{t}}(r)| = \\frac{2r}{(1+r^2)^2} = 10^{-3}$。这需要使用数值求根方法。\n\n这些计算在下面的 Python 代码中实现。",
            "answer": "```python\nimport numpy as np\nfrom scipy.integrate import quad\nfrom scipy.optimize import root_scalar\n\ndef solve():\n    \"\"\"\n    Performs the calculations specified in the problem statement.\n    \"\"\"\n\n    # Define the absolute values of the kernel derivatives\n    def abs_g_prime_t(r):\n        \"\"\"Absolute derivative of the Student-t kernel.\"\"\"\n        return 2 * r / ((1 + r**2)**2)\n\n    def abs_g_prime_l(r):\n        \"\"\"Absolute derivative of the Laplace kernel.\"\"\"\n        return np.exp(-r)\n\n    # Task 1: Compute the force-profile ratio R(r) for specific r values\n    def force_profile_ratio(r):\n        \"\"\"Computes R(r) = |g'_L(r)| / |g'_t(r)|.\"\"\"\n        if r == 0:\n            return np.inf  # The formula has 1/r dependency\n        # handle r very close to 0\n        if np.isclose(r, 0):\n             return 0.5 * np.exp(-r) * (1 + r**2)**2 / r # Avoid division by zero, though problem inputs are fine\n        return abs_g_prime_l(r) / abs_g_prime_t(r)\n\n    r_values = [1e-8, 1, 5, 50]\n    r_results = [force_profile_ratio(r) for r in r_values]\n\n    # Task 2: Check if R(50)  1e-6\n    r50_check = bool(r_results[-1]  1e-6)\n\n    # Task 3: Compute the integral difference Delta\n    integral_l, _ = quad(abs_g_prime_l, 10, 20)\n    integral_t, _ = quad(abs_g_prime_t, 10, 20)\n    delta = integral_l - integral_t\n\n    # Task 4: Check if Delta  0\n    delta_check = bool(delta  0)\n\n    # Task 5: Compute the radii ratio r_star_L / r_star_t\n    tau = 1e-3\n\n    # For Laplace kernel: exp(-r) = tau => r = -log(tau)\n    r_star_l = -np.log(tau)\n\n    # For Student-t kernel: 2r / (1+r^2)^2 = tau. Find root of f(r) = 0.\n    def f_t(r):\n        return abs_g_prime_t(r) - tau\n    \n    # Bracket the root. f(10) > 0, f(15)  0 based on preliminary analysis.\n    sol_t = root_scalar(f_t, bracket=[1, 20], method='brentq')\n    r_star_t = sol_t.root\n\n    radii_ratio = r_star_l / r_star_t\n\n    # Task 6: Check if r_star_L  r_star_t\n    radii_ratio_check = bool(r_star_l  r_star_t)\n    \n    # Consolidate all results\n    all_results = r_results + [r50_check, delta, delta_check, radii_ratio, radii_ratio_check]\n    \n    # Format and print the final output\n    # Using a mix of float formatting for readability where appropriate\n    formatted_results = []\n    for item in all_results:\n        if isinstance(item, bool):\n            formatted_results.append(str(item).lower())\n        else:\n            # Use general format for large/small numbers, and float for others\n            if abs(item) > 1e6 or (abs(item)  1e-4 and item != 0):\n                 formatted_results.append(f\"{item:.10e}\")\n            else:\n                 formatted_results.append(f\"{item:.10f}\")\n\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在理解了解读时的注意事项和其内部机制后，我们如何客观地衡量一个t-SNE嵌入的质量？这最后一个实践  引入了一种量化方法来实现这一点，即计算“可信度”或邻域保持度。通过编写一个函数来检查一个点的原始最近邻中有多少比例在其嵌入表示中得以保留，你将获得一个超越简单目视检查的强大工具，用于诊断和验证你的t-SNE可视化结果。",
            "id": "3179626",
            "problem": "给定您两个欧几里得空间：一个高维数据空间和一个由 t-分布随机邻域嵌入 (t-SNE) 产生的低维嵌入空间。对于一个由 $i \\in \\{0,1,\\dots,N-1\\}$ 索引的有限点集，令 $X = \\{x_i \\in \\mathbb{R}^D\\}$ 表示数据空间坐标，$Y = \\{y_i \\in \\mathbb{R}^d\\}$ 表示嵌入空间坐标。对于选定的邻域大小 $k \\in \\{1,2,\\dots,N-1\\}$，使用欧几里得范数定义点 $i$ 在数据空间中的 $k$-最近邻集合为 $N_k^X(i)$，在嵌入空间中的为 $N_k^Y(i)$。两点 $a,b \\in \\mathbb{R}^m$ 之间的欧几里得距离为 $\\|a-b\\|_2 = \\sqrt{\\sum_{j=1}^m (a_j-b_j)^2}$。点 $i$ 的 $k$-最近邻集合是通过将所有索引 $j \\neq i$ 按距离 $\\|x_i - x_j\\|_2$ (或 $\\|y_i - y_j\\|_2$) 递增排序，并以较小的索引 $j$ 来打破任何精确的距离平局，然后取前 $k$ 个索引得到的。对于每个点 $i$，定义逐点邻域保持分数\n$$\np_i(k) \\;=\\; \\frac{\\left|\\,N_k^X(i) \\,\\cap\\, N_k^Y(i)\\,\\right|}{k}.\n$$\n这个量 $p_i(k)$ 位于 $[0,1]$ 区间内，对于给定的 $k$，可作为单个点层面上的可信度指标。\n\n您的任务是编写一个完整的程序，为每个指定的测试用例计算逐点邻域保持分数向量 $[p_0(k),p_1(k),\\dots,p_{N-1}(k)]$，并识别出那些局部邻域保持度低于诊断容差的索引。给定一个阈值 $\\tau \\in [0,1]$，定义受损点集为那些满足 $p_i(k)  \\tau$ 的索引 $i$。这可以用于诊断因 t-分布随机邻域嵌入 (t-SNE) 中的早期夸大 (early exaggeration) 或近似等机制而受损的区域，已知这些机制即使在全局结构看起来合理的情况下，也可能破坏某些点的局部邻域。\n\n仅使用上述基础定义；不要依赖于预打包的邻域保持或可信度函数。按照规定实现欧几里得距离、按较小索引的确定性平局打破规则以及严格的集合交集。对于每个测试用例，输出两项内容：列表 $[p_0(k),\\dots,p_{N-1}(k)]$（每个值四舍五入到三位小数）和已排序的受损索引列表 $\\{i : p_i(k)  \\tau\\}$。\n\n测试套件。使用以下四个测试用例。在每个用例中，$X$ 和 $Y$ 都是明确给出的。\n\n- 测试用例 1 (顺利路径：$Y$ 中的单调缩放保持了邻居)：\n  - $N = 6$，$D = 1$，$d = 1$，$k = 2$，$\\tau = 1.0$。\n  - $X^{(1)} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 3 \\\\ 7 \\\\ 12 \\\\ 18 \\end{bmatrix}$。\n  - $Y^{(1)} = \\begin{bmatrix} 0 \\\\ 2 \\\\ 6 \\\\ 14 \\\\ 24 \\\\ 36 \\end{bmatrix}$。\n- 测试用例 2 (诊断因 $Y$ 中类似夸大的失真而导致的局部受损区域)：\n  - $N = 6$，$D = 1$，$d = 1$，$k = 2$，$\\tau = 0.75$。\n  - $X^{(2)} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 3 \\\\ 7 \\\\ 12 \\\\ 18 \\end{bmatrix}$。\n  - $Y^{(2)} = \\begin{bmatrix} 0 \\\\ 2 \\\\ 20 \\\\ 14 \\\\ 24 \\\\ 36 \\end{bmatrix}$。\n- 测试用例 3 (导致 $k=1$ 时最近邻翻转的类似近似的扰动)：\n  - $N = 5$，$D = 2$，$d = 2$，$k = 1$，$\\tau = 1.0$。\n  - $X^{(3)} = \\begin{bmatrix} 0.0  0.0 \\\\ 0.9  0.05 \\\\ 1.8  0.2 \\\\ 3.0  5.0 \\\\ 3.1  5.05 \\end{bmatrix}$。\n  - $Y^{(3)} = \\begin{bmatrix} 0.0  0.0 \\\\ 0.9  0.05 \\\\ 0.3  0.02 \\\\ 3.0  5.0 \\\\ 3.1  5.05 \\end{bmatrix}$。\n- 测试用例 4 (边界情况：$k = N-1$ 使得每个点的邻居集合都是所有其他点)：\n  - $N = 4$，$D = 2$，$d = 2$，$k = 3$，$\\tau = 1.0$。\n  - $X^{(4)} = \\begin{bmatrix} 0  0 \\\\ 1  0 \\\\ 0  1 \\\\ 1  1 \\end{bmatrix}$。\n  - $Y^{(4)} = \\begin{bmatrix} 1  1 \\\\ 0  1 \\\\ 1  0 \\\\ 0  0 \\end{bmatrix}$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素对应一个测试用例，并且本身是一个双元素列表：第一个元素是按点索引顺序排列的列表 $[p_0(k),\\dots,p_{N-1}(k)]$，四舍五入到三位小数；第二个元素是满足 $p_i(k)  \\tau$ 的已排序的受损索引列表。例如，整体结构必须是\n$[[[p^{(1)}_0,\\dots,p^{(1)}_{N-1}],[\\text{harmed}^{(1)}]], [[p^{(2)}_0,\\dots],[\\text{harmed}^{(2)}]], [[p^{(3)}_0,\\dots],[\\text{harmed}^{(3)}]], [[p^{(4)}_0,\\dots],[\\text{harmed}^{(4)}]]]$ 的形式。",
            "solution": "该问题要求计算一个 t-SNE 风格嵌入的逐点局部邻域保持度量。这个度量，记为 $p_i(k)$，量化了高维数据空间 $X$ 中一个点 $x_i$ 的 $k$-最近邻中，有多少比例同时也是其在低维嵌入空间 $Y$ 中对应点 $y_i$ 的 $k$-最近邻。目标是实现一个程序来计算这些保持分数的向量 $[p_0(k), p_1(k), \\ldots, p_{N-1}(k)]$，并识别出一组“受损”点，这些点的保持分数低于指定的容差阈值 $\\tau$。\n\n该问题定义明确且有科学依据。所有术语都经过数学上的精确定义。数据空间坐标由集合 $X = \\{x_i \\in \\mathbb{R}^D\\}_{i=0}^{N-1}$ 给出，嵌入空间坐标由 $Y = \\{y_i \\in \\mathbb{R}^d\\}_{i=0}^{N-1}$ 给出。距离度量是标准的欧几里得范数，$\\|a-b\\|_2 = \\sqrt{\\sum_{j=1}^m (a_j-b_j)^2}$。一个关键细节是确定性的平局打破规则：当两个点与一个参考点的距离相等时，索引较小的点被认为更近。这确保了 $k$-最近邻集合 $N_k^X(i)$ 和 $N_k^Y(i)$ 对于任何点 $i$ 和任何邻域大小 $k \\in \\{1, 2, \\ldots, N-1\\}$ 都是唯一定义的。\n\n逐点邻域保持分数的定义为：\n$$\np_i(k) \\;=\\; \\frac{\\left|\\,N_k^X(i) \\,\\cap\\, N_k^Y(i)\\,\\right|}{k}\n$$\n该值的范围从 $0$ (没有邻居被保持) 到 $1$ (所有 $k$ 个邻居都被保持)。受损点集则被定义为所有满足 $p_i(k)  \\tau$ 的索引 $i$。\n\n为每个测试用例计算所需输出的算法过程如下。对于每个从 $0$ 到 $N-1$ 的点 $i$：\n\n1.  **构建邻居列表**：\n    -   对于数据空间 $X$，为所有 $j \\neq i$ 创建一个元组列表 $(d_{ij}^X, j)$，其中 $d_{ij}^X = \\|x_i - x_j\\|_2$。\n    -   对于嵌入空间 $Y$，为所有 $j \\neq i$ 创建一个元组列表 $(d_{ij}^Y, j)$，其中 $d_{ij}^Y = \\|y_i - y_j\\|_2$。\n\n2.  **排序并确定 k-NN 集合**：\n    -   根据距离 $d_{ij}^X$ (升序) 的主键和索引 $j$ (升序) 的次键对 $X$ 空间的列表进行排序，以强制执行平局打破规则。此排序列表中的前 $k$ 个索引构成了 $k$-最近邻集合 $N_k^X(i)$。\n    -   对来自 $Y$ 空间的列表执行相同的排序过程，以确定集合 $N_k^Y(i)$。\n\n3.  **计算保持分数**：\n    -   计算两个集合的交集：$I_i = N_k^X(i) \\cap N_k^Y(i)$。\n    -   计算保持分数 $p_i(k) = |I_i| / k$。\n\n4.  **识别受损点**：\n    -   为所有 $i \\in \\{0, \\ldots, N-1\\}$ 计算出 $p_i(k)$ 后，将每个 $p_i(k)$ 与阈值 $\\tau$ 进行比较。受损索引的集合为 $\\{i \\mid p_i(k)  \\tau\\}$。\n\n此算法将应用于所提供的四个测试用例。\n\n-   **测试用例 1** ($N=6, k=2, \\tau=1.0$)：嵌入 $Y^{(1)}$ 是数据 $X^{(1)}$ 的线性缩放，即 $y_i = 2x_i$。此变换保持了所有点间距离的顺序。因此，对于每个点 $i$，两个空间中的 $k$-最近邻是相同的：$N_k^X(i) = N_k^Y(i)$。这导致所有 $i$ 的保持分数都为完美的 $p_i(k) = 1.0$。由于没有 $p_i(k)$ 小于 $\\tau=1.0$，因此没有点受损。\n\n-   **测试用例 2** ($N=6, k=2, \\tau=0.75$)：坐标 $y_2=20$ 是对原始数据结构的显著扭曲，在原始数据中 $x_2=3$ 靠近 $x_1=1$ 和 $x_0=0$。这种位移使得点 2 在嵌入空间 $Y$ 中远离点 0 和 1，从而破坏了它们的局部邻域。具体来说，对于点 $i=2$，其在 $X$ 中的邻居是 $\\{0,1\\}$，但在 $Y$ 中变为 $\\{3,4\\}$，得出 $p_2(2)=0.0$。类似的破坏影响了点 0 和 1 的邻域，导致 $p_0(2)=0.5$ 和 $p_1(2)=0.5$。其余的点 $3, 4, 5$ 远离这个扰动并保留了它们的邻域，因此对于 $i \\in \\{3,4,5\\}$，$p_i(2)=1.0$。索引 $0, 1, 2$ 受损，因为它们的 $p_i(k)$ 值低于 $\\tau=0.75$。\n\n-   **测试用例 3** ($N=5, k=1, \\tau=1.0$)：这个案例说明了一种局部混淆。在空间 $X$ 中，索引为 $0, 1, 2$ 的点形成一个链，其中 $1$ 是 $0$ 和 $2$ 的最近邻，$0$ 是 $1$ 的最近邻。在空间 $Y$ 中，点 $y_2$ 被移动到非常靠近 $y_0$ 的位置。这打破了原始的邻域结构。$y_0$ 的最近邻变成了 $y_2$ (而不是 $y_1$)，$y_1$ 的最近邻变成了 $y_2$ (而不是 $y_0$)，$y_2$ 的最近邻变成了 $y_0$ (而不是 $y_1$)。在这三种情况下，单个最近邻都没有被保持，所以 $p_0(1)=p_1(1)=p_2(1)=0.0$。点对 $(3,4)$ 远离此混淆，它们相互的最近邻关系得以保持，所以 $p_3(1)=p_4(1)=1.0$。受损的索引是 $\\{0, 1, 2\\}$，因为它们的保持度小于 $\\tau=1.0$。\n\n-   **测试用例 4** ($N=4, k=3, \\tau=1.0$)：这是一个边界情况，其中 $k=N-1=3$。对于任何点 $i$，其邻居集合自然是数据集中所有其他点的集合。也就是说，$N_3^X(i) = N_3^Y(i) = \\{0, 1, 2, 3\\} \\setminus \\{i\\}$。根据定义，交集是完美的。因此，对于所有 $i \\in \\{0,1,2,3\\}$，$p_i(3) = 3/3 = 1.0$。没有点受损。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_k_nearest_neighbors(points, i, k):\n    \"\"\"\n    Finds the k-nearest neighbors for point i in the given set of points.\n\n    Args:\n        points (np.ndarray): An NxD or Nxd array of points.\n        i (int): The index of the reference point.\n        k (int): The number of neighbors to find.\n\n    Returns:\n        set: A set of indices of the k nearest neighbors.\n    \"\"\"\n    N = points.shape[0]\n    distances = []\n    current_point = points[i]\n\n    for j in range(N):\n        if i == j:\n            continue\n        other_point = points[j]\n        # Euclidean distance calculation as per the problem definition\n        dist = np.linalg.norm(current_point - other_point)\n        # Store as a tuple of (distance, index) for sorting\n        distances.append((dist, j))\n\n    # Sort by distance (primary key) and then by index (secondary key for tie-breaking)\n    distances.sort(key=lambda x: (x[0], x[1]))\n\n    # Extract the indices of the first k neighbors\n    neighbors = {d[1] for d in distances[:k]}\n    return neighbors\n\ndef solve():\n    \"\"\"\n    Solves the neighbor preservation problem for the four given test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"N\": 6, \"k\": 2, \"tau\": 1.0,\n            \"X\": np.array([[0.0], [1.0], [3.0], [7.0], [12.0], [18.0]]),\n            \"Y\": np.array([[0.0], [2.0], [6.0], [14.0], [24.0], [36.0]])\n        },\n        {\n            \"N\": 6, \"k\": 2, \"tau\": 0.75,\n            \"X\": np.array([[0.0], [1.0], [3.0], [7.0], [12.0], [18.0]]),\n            \"Y\": np.array([[0.0], [2.0], [20.0], [14.0], [24.0], [36.0]])\n        },\n        {\n            \"N\": 5, \"k\": 1, \"tau\": 1.0,\n            \"X\": np.array([[0.0, 0.0], [0.9, 0.05], [1.8, 0.2], [3.0, 5.0], [3.1, 5.05]]),\n            \"Y\": np.array([[0.0, 0.0], [0.9, 0.05], [0.3, 0.02], [3.0, 5.0], [3.1, 5.05]])\n        },\n        {\n            \"N\": 4, \"k\": 3, \"tau\": 1.0,\n            \"X\": np.array([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 1.0]]),\n            \"Y\": np.array([[1.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 0.0]])\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        N = case[\"N\"]\n        k = case[\"k\"]\n        tau = case[\"tau\"]\n        X = case[\"X\"]\n        Y = case[\"Y\"]\n\n        p_values = []\n        harmed_indices = []\n\n        for i in range(N):\n            # Find k-nearest neighbors in both spaces\n            neighbors_X = get_k_nearest_neighbors(X, i, k)\n            neighbors_Y = get_k_nearest_neighbors(Y, i, k)\n\n            # Calculate the size of the intersection\n            intersection_size = len(neighbors_X.intersection(neighbors_Y))\n            \n            # Calculate preservation fraction p_i(k)\n            if k > 0:\n                p_i_k = intersection_size / k\n            else:\n                p_i_k = 1.0 # By convention for k=0, though k >= 1 in this problem\n            \n            p_values.append(p_i_k)\n\n            # Check if the point is harmed\n            if p_i_k  tau:\n                harmed_indices.append(i)\n        \n        # Round p_values to three decimal places\n        rounded_p_values = [round(p, 3) for p in p_values]\n        \n        # Assemble the result for this test case\n        # harmed_indices is naturally sorted as the loop iterates from i=0 to N-1\n        case_result = [rounded_p_values, harmed_indices]\n        all_results.append(case_result)\n\n    # Format the final output string to match the exact requirement (no spaces)\n    # The default str() representation of lists is used, and then spaces are removed.\n    final_output_str = str(all_results).replace(\" \", \"\")\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}