{
    "hands_on_practices": [
        {
            "introduction": "选择“最优”模型的第一步是定义“最优”的标准。在实践中，不存在一个在所有方面都表现最佳的通用模型。这个练习将引导你比较几个常见的分类评估指标——例如 Top-$k$ 准确率、F1 分数和受试者工作特征曲线下面积（Area Under the Receiver Operating Characteristic, AUROC）——并让你亲身体验，对于同一组候选模型，不同的评估指标会如何导致不同的模型选择结果 。通过这个练习，你将深刻理解根据具体应用场景和业务目标选择合适评估指标的重要性。",
            "id": "3107729",
            "problem": "考虑一个多类分类问题，其中有 $3$ 个类别，标记为 $0$、$1$ 和 $2$。现有 $N=8$ 个样本，其真实类别标签由向量 $y=(0,1,2,1,0,2,1,0)$ 给出。我们评估三个候选模型 $\\mathcal{M}_0$、$\\mathcal{M}_1$ 和 $\\mathcal{M}_2$。对于每个样本，这些模型会输出一个跨类别的非负分数向量，用于排序。对于每个模型 $\\mathcal{M}_m$，令 $S^{(m)} \\in \\mathbb{R}^{8 \\times 3}$ 表示其分数矩阵，其中 $S^{(m)}_{i,c}$ 是模型 $m$ 为样本 $i \\in \\{0,1,\\dots,7\\}$ 的类别 $c \\in \\{0,1,2\\}$ 分配的分数。分数矩阵如下：\n\n- 对于 $\\mathcal{M}_0$：各行为 $(0.45,0.40,0.15)$、$(0.10,0.80,0.10)$、$(0.30,0.20,0.50)$、$(0.25,0.60,0.15)$、$(0.30,0.65,0.05)$、$(0.25,0.25,0.50)$、$(0.20,0.75,0.05)$、$(0.55,0.25,0.20)$。\n- 对于 $\\mathcal{M}_1$：各行为 $(0.35,0.55,0.10)$、$(0.30,0.50,0.20)$、$(0.20,0.15,0.65)$、$(0.15,0.70,0.15)$、$(0.60,0.25,0.15)$、$(0.10,0.20,0.70)$、$(0.05,0.85,0.10)$、$(0.65,0.20,0.15)$。\n- 对于 $\\mathcal{M}_2$：各行为 $(0.30,0.35,0.35)$、$(0.05,0.92,0.03)$、$(0.25,0.40,0.35)$、$(0.10,0.85,0.05)$、$(0.20,0.55,0.25)$、$(0.15,0.35,0.50)$、$(0.02,0.95,0.03)$、$(0.40,0.45,0.15)$。\n\n我们定义以下基于核心定义的评估指标：\n\n1. Top-$k$ 准确率 (Top-$k$ accuracy): 对于给定的 $k \\in \\{1,2,3\\}$，将样本 $i$ 的 top-$k$ 集合定义为根据下述平局打破规则得分最高的 $k$ 个类别。模型的 top-$k$ 准确率是真实类别 $y_i$ 位于此 top-$k$ 集合内的样本比例。类别排序的平局打破规则是：首先按分数降序排序，如果分数出现平局，则按类别索引升序排序。\n\n2. F1 分数 (F1-score): 对于类别 1 与其余类别的二元评估，将预测正例集定义为类别 1 分数高于某个阈值的样本。对于任何阈值，在类别 1 的“一对多”(one-versus-rest) 意义上定义真正例 (True Positives, $\\mathrm{TP}$)、假正例 (False Positives, $\\mathrm{FP}$) 和假负例 (False Negatives, $\\mathrm{FN}$)。精确率为 $\\mathrm{Precision} = \\mathrm{TP}/(\\mathrm{TP}+\\mathrm{FP})$，召回率为 $\\mathrm{Recall} = \\mathrm{TP}/(\\mathrm{TP}+\\mathrm{FN})$，F1 分数为 $F1 = 2 \\cdot \\mathrm{Precision} \\cdot \\mathrm{Recall} / (\\mathrm{Precision}+\\mathrm{Recall})$，等价于 $F1 = \\dfrac{2 \\mathrm{TP}}{2 \\mathrm{TP} + \\mathrm{FP} + \\mathrm{FN}}$。一个用例约束对预测正例施加了资源预算：令 $b \\in (0,1]$ 为允许标记为正例的样本比例，因此预测正例数最多为 $\\lfloor b \\cdot N \\rfloor$。在此约束下，为在所有允许的阈值中最大化 F1 分数，最优阈值将根据类别 1 的分数选择前 $m$ 个样本，其中 $m \\in \\{0,1,\\dots,\\lfloor bN \\rfloor\\}$，当分数相等时，遵循相同的索引平局打破规则。\n\n3. 受试者工作特征曲线下面积 (Area Under the Receiver Operating Characteristic, AUROC): 对于类别 1 与其余类别的二元评估，受试者工作特征 (ROC) 曲线绘制了在类别 1 分数的所有阈值下，真正例率 (True Positive Rate, $\\mathrm{TPR} = \\mathrm{TP}/(\\mathrm{TP}+\\mathrm{FN})$) 与假正例率 (False Positive Rate, $\\mathrm{FPR} = \\mathrm{FP}/(\\mathrm{FP}+\\mathrm{TN})$) 的关系图。受试者工作特征曲线下面积 (AUROC) 是该曲线下的面积，它可以通过 Mann–Whitney 统计量等价地计算，即一个随机选择的正例样本的类别 1 分数高于一个随机选择的负例样本分数的概率，其中平局计为二分之一。\n\n模型选择规则：对于给定的指标，所选模型的索引是在 $\\{\\mathcal{M}_0,\\mathcal{M}_1,\\mathcal{M}_2\\}$ 中实现该指标最大值的最小索引 $m \\in \\{0,1,2\\}$，平局时选择最小的索引。\n\n您的程序必须为下面的测试套件中的每个测试用例计算：\n- 最大化 top-$k$ 准确率的模型的索引。\n- 在预算约束 $b$ 下最大化类别 1 的 F1 分数的模型的索引。\n- 最大化类别 1 的 AUROC 的模型的索引。\n\n测试套件：\n- 测试用例 1：$k=1$，$b=0.5$。\n- 测试用例 2：$k=2$，$b=0.25$。\n- 测试用例 3：$k=2$，$b=0.125$。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果本身是一个用方括号括起来的三个整数的逗号分隔列表，表示 $[$top-$k$ 模型索引, F1-under-$b$ 模型索引, AUROC 模型索引$]$。例如，输出应类似于 $[[a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3]]$，行中不含任何空格。",
            "solution": "该问题是有效的，因为它在科学上基于统计学习的原理，问题陈述清晰，提供了所有必要的数据和明确的定义，并且其表述是客观的。我们将进行完整的解答。\n\n该问题要求我们评估三个模型 $\\mathcal{M}_0$、$\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 在一个有 $N=8$ 个样本和 $3$ 个类别的多类分类任务上的表现。真实标签由向量 $y=(0,1,2,1,0,2,1,0)$ 给出。对于每个模型，我们都提供了一个 $8 \\times 3$ 的分数矩阵 $S^{(m)}$。我们将为每个模型计算三个指标：top-$k$ 准确率、类别 1 的预算内 F1 分数，以及类别 1 的受试者工作特征曲线下面积 (AUROC)。对于每个指标，我们选择得分最高的模型，并通过选择最小的模型索引 $m \\in \\{0,1,2\\}$ 来打破平局。\n\n让我们将模型集合表示为 $\\{\\mathcal{M}_0, \\mathcal{M}_1, \\mathcal{M}_2\\}$。分数矩阵 $S^{(0)}$、$S^{(1)}$、$S^{(2)}$ 和标签向量 $y$ 是主要输入。\n\n**1. Top-$k$ 准确率计算**\n\nTop-$k$ 准确率是真实类别标签 $y_i$ 位于得分最高的 $k$ 个类别中的样本比例。样本 $i$ 的类别排序是通过将分数按降序排序来确定的，平局则按类别索引的升序来打破。\n\n令 $S^{(m)}_{i, \\cdot}$ 为模型 $\\mathcal{M}_m$ 对样本 $i$ 的分数向量。我们为 $c \\in \\{0,1,2\\}$ 形成配对 $(S^{(m)}_{i,c}, c)$。这些配对首先按分数（降序）排序，然后按类别索引 $c$（升序）排序。预测的 top-$k$ 类别集合 $\\hat{Y}_{i,k}^{(m)}$ 是此排序列表中的前 $k$ 个类别索引的集合。\n\n模型 $\\mathcal{M}_m$ 的 top-$k$ 准确率由下式给出：\n$$ \\text{Accuracy}_k(\\mathcal{M}_m) = \\frac{1}{N} \\sum_{i=0}^{N-1} I(y_i \\in \\hat{Y}_{i,k}^{(m)}) $$\n其中 $I(\\cdot)$ 是指示函数。\n\n**2. 类别 1 的预算内 F1 分数**\n\n该指标评估模型识别类别 1 样本（正例）与类别 0 和 2 样本（负例）的能力。真正例样本集为 $P = \\{i | y_i = 1\\} = \\{1, 3, 6\\}$，因此正例总数为 $N_P = 3$。真负例样本集为 $N_{set} = \\{i | y_i \\neq 1\\} = \\{0, 2, 4, 5, 7\\}$，负例总数为 $N_N = 5$。\n\n预算约束将可预测为正例的样本数量限制为最多 $m_{max} = \\lfloor b \\cdot N \\rfloor$。为了最大化 F1 分数，我们必须找到预测正例的最优数量 $m^*$，其中 $0 \\le m^* \\le m_{max}$。对于每个可能的预测数量 $m_{pred} \\in \\{0, 1, \\dots, m_{max}\\}$，我们根据其类别 1 分数 $S^{(m)}_{\\cdot, 1}$ 选择前 $m_{pred}$ 个样本。样本的排序是通过将其类别 1 分数按降序排序来确定的，平局则按样本索引 $i$ 的升序来打破。\n\n对于每个 $m_{pred}$，我们计算：\n- $\\mathrm{TP}(m_{pred})$：前 $m_{pred}$ 个样本中真正例的数量。\n- $\\mathrm{FP}(m_{pred})$：前 $m_{pred}$ 个样本中真负例的数量。\n- $\\mathrm{FN}(m_{pred}) = N_P - \\mathrm{TP}(m_{pred})$。\n\n给定 $m_{pred}$ 的 F1 分数为：\n$$ F1(m_{pred}) = \\frac{2 \\cdot \\mathrm{TP}(m_{pred})}{2 \\cdot \\mathrm{TP}(m_{pred}) + \\mathrm{FP}(m_{pred}) + \\mathrm{FN}(m_{pred})} $$\n模型 $\\mathcal{M}_m$ 在预算 $b$ 下的 F1 分数是这些值的最大值：\n$$ F1_b(\\mathcal{M}_m) = \\max_{m_{pred}=0, \\dots, m_{max}} F1(m_{pred}) $$\n\n**3. 类别 1 的 AUROC**\n\n类别 1 与其余类别的二元任务的 AUROC 可以使用 Mann-Whitney U 统计量计算。它衡量的是一个随机选择的正例样本的类别 1 分数高于一个随机选择的负例样本分数的概率。\n\n令 $S_P^{(m)} = \\{S_{i,1}^{(m)} | i \\in P\\}$ 为正例样本的类别 1 分数集合， $S_N^{(m)} = \\{S_{j,1}^{(m)} | j \\in N_{set}\\}$ 为负例样本的分数集合。模型 $\\mathcal{M}_m$ 的 AUROC 为：\n$$ \\text{AUROC}(\\mathcal{M}_m) = \\frac{1}{N_P \\cdot N_N} \\sum_{s_p \\in S_P^{(m)}} \\sum_{s_n \\in S_N^{(m)}} \\left( I(s_p > s_n) + 0.5 \\cdot I(s_p = s_n) \\right) $$\n\n**模型选择**\n对于每个测试用例和每个指标，我们计算所有三个模型 $\\{\\mathcal{M}_0, \\mathcal{M}_1, \\mathcal{M}_2\\}$ 的指标值。设计算出的值为 $\\{v_0, v_1, v_2\\}$。最大值为 $v_{max} = \\max(v_0, v_1, v_2)$。所选模型的索引是 $\\arg \\min \\{m | v_m = v_{max}\\}$。\n\n**测试用例计算**\n\n让我们计算每个测试用例的结果。\n\n**测试用例 1: $k=1, b=0.5$**\n- $N=8$，因此对于 F1 分数， $m_{max} = \\lfloor 0.5 \\times 8 \\rfloor = 4$。\n- **Top-1 准确率:**\n  - $\\text{Acc}_1(\\mathcal{M}_0) = 7/8 = 0.875$\n  - $\\text{Acc}_1(\\mathcal{M}_1) = 7/8 = 0.875$\n  - $\\text{Acc}_1(\\mathcal{M}_2) = 4/8 = 0.5$\n  - 最大值为 $0.875$，在 $\\mathcal{M}_0$ 和 $\\mathcal{M}_1$ 之间持平。我们选择索引 $0$。\n- **F1 分数 ($b=0.5$):**\n  - 对于 $\\mathcal{M}_0$，最大 F1 为 $6/7 \\approx 0.857$ (在 $m_{pred}=4$ 时)。\n  - 对于 $\\mathcal{M}_1$，最大 F1 为 $6/7 \\approx 0.857$ (在 $m_{pred}=4$ 时)。\n  - 对于 $\\mathcal{M}_2$，最大 F1 为 $1.0$ (在 $m_{pred}=3$ 时，其中 $\\mathrm{TP}=3, \\mathrm{FP}=0$)。\n  - 最大值为 $1.0$，由 $\\mathcal{M}_2$ 实现。我们选择索引 $2$。\n- **AUROC:**\n  - $\\text{AUROC}(\\mathcal{M}_0) = 14/15 \\approx 0.9333$\n  - $\\text{AUROC}(\\mathcal{M}_1) = 14/15 \\approx 0.9333$\n  - $\\text{AUROC}(\\mathcal{M}_2) = 15/15 = 1.0$\n  - 最大值为 $1.0$，由 $\\mathcal{M}_2$ 实现。我们选择索引 $2$。\n- **测试用例 1 的结果：** $[0, 2, 2]$\n\n**测试用例 2: $k=2, b=0.25$**\n- 对于 F1 分数， $m_{max} = \\lfloor 0.25 \\times 8 \\rfloor = 2$。\n- **Top-2 准确率:**\n  - $\\text{Acc}_2(\\mathcal{M}_0) = 8/8 = 1.0$\n  - $\\text{Acc}_2(\\mathcal{M}_1) = 8/8 = 1.0$\n  - $\\text{Acc}_2(\\mathcal{M}_2) = 6/8 = 0.75$\n  - 最大值为 $1.0$，在 $\\mathcal{M}_0$ 和 $\\mathcal{M}_1$ 之间持平。我们选择索引 $0$。\n- **F1 分数 ($b=0.25$):**\n  - 对于 $\\mathcal{M}_0$，最大 F1 为 $0.8$ (在 $m_{pred}=2$ 时，$\\mathrm{TP}=2, \\mathrm{FP}=0$)。\n  - 对于 $\\mathcal{M}_1$，最大 F1 为 $0.8$ (在 $m_{pred}=2$ 时，$\\mathrm{TP}=2, \\mathrm{FP}=0$)。\n  - 对于 $\\mathcal{M}_2$，最大 F1 为 $0.8$ (在 $m_{pred}=2$ 时，$\\mathrm{TP}=2, \\mathrm{FP}=0$)。\n  - 所有模型得分均为 $0.8$。我们选择最小的索引 $0$。\n- **AUROC:** (此值与 $k$ 和 $b$ 无关)\n  - 值与测试用例 1 相同。\n  - 最大值为 $1.0$，由 $\\mathcal{M}_2$ 实现。我们选择索引 $2$。\n- **测试用例 2 的结果：** $[0, 0, 2]$\n\n**测试用例 3: $k=2, b=0.125$**\n- 对于 F1 分数， $m_{max} = \\lfloor 0.125 \\times 8 \\rfloor = 1$。\n- **Top-2 准确率:** (此值与 $b$ 无关)\n  - 值与测试用例 2 相同。\n  - 最大值为 $1.0$，在 $\\mathcal{M}_0$ 和 $\\mathcal{M}_1$ 之间持平。我们选择索引 $0$。\n- **F1 分数 ($b=0.125$):**\n  - 对于 $\\mathcal{M}_0$，最大 F1 为 $0.5$ (在 $m_{pred}=1$ 时，$\\mathrm{TP}=1, \\mathrm{FP}=0$)。\n  - 对于 $\\mathcal{M}_1$，最大 F1 为 $0.5$ (在 $m_{pred}=1$ 时，$\\mathrm{TP}=1, \\mathrm{FP}=0$)。\n  - 对于 $\\mathcal{M}_2$，最大 F1 为 $0.5$ (在 $m_{pred}=1$ 时，$\\mathrm{TP}=1, \\mathrm{FP}=0$)。\n  - 所有模型得分均为 $0.5$。我们选择最小的索引 $0$。\n- **AUROC:** (此值与 $k$ 和 $b$ 无关)\n  - 值与测试用例 1 相同。\n  - 最大值为 $1.0$，由 $\\mathcal{M}_2$ 实现。我们选择索引 $2$。\n- **测试用例 3 的结果：** $[0, 0, 2]$\n\n程序将系统地实现这些计算。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the model evaluation problem by calculating three metrics for three models\n    across three test cases and selecting the best model for each.\n    \"\"\"\n    # Define problem givens\n    y_true = np.array([0, 1, 2, 1, 0, 2, 1, 0])\n    num_samples = len(y_true)\n    num_classes = 3\n\n    scores = [\n        np.array([\n            [0.45, 0.40, 0.15], [0.10, 0.80, 0.10], [0.30, 0.20, 0.50],\n            [0.25, 0.60, 0.15], [0.30, 0.65, 0.05], [0.25, 0.25, 0.50],\n            [0.20, 0.75, 0.05], [0.55, 0.25, 0.20]\n        ]),\n        np.array([\n            [0.35, 0.55, 0.10], [0.30, 0.50, 0.20], [0.20, 0.15, 0.65],\n            [0.15, 0.70, 0.15], [0.60, 0.25, 0.15], [0.10, 0.20, 0.70],\n            [0.05, 0.85, 0.10], [0.65, 0.20, 0.15]\n        ]),\n        np.array([\n            [0.30, 0.35, 0.35], [0.05, 0.92, 0.03], [0.25, 0.40, 0.35],\n            [0.10, 0.85, 0.05], [0.20, 0.55, 0.25], [0.15, 0.35, 0.50],\n            [0.02, 0.95, 0.03], [0.40, 0.45, 0.15]\n        ])\n    ]\n\n    test_cases = [\n        {'k': 1, 'b': 0.5},\n        {'k': 2, 'b': 0.25},\n        {'k': 2, 'b': 0.125}\n    ]\n\n    def select_best_model(metric_scores):\n        \"\"\"Selects model index with max score, breaking ties by smallest index.\"\"\"\n        max_score = np.max(metric_scores)\n        best_model_idx = np.where(metric_scores == max_score)[0][0]\n        return best_model_idx\n\n    # --- Metric Calculation Functions ---\n\n    def calculate_top_k_accuracy(model_scores, y_true, k, num_classes):\n        correct_predictions = 0\n        class_indices = np.arange(num_classes)\n        for i in range(len(y_true)):\n            sample_scores = model_scores[i]\n            # Tie-breaking: sort by score desc, then class index asc\n            sorted_indices = np.lexsort((class_indices, -sample_scores))\n            top_k_classes = sorted_indices[:k]\n            if y_true[i] in top_k_classes:\n                correct_predictions += 1\n        return correct_predictions / len(y_true)\n\n    def calculate_budgeted_f1(model_scores, y_true, b, num_samples):\n        class1_scores = model_scores[:, 1]\n        is_positive = (y_true == 1)\n        \n        sample_indices = np.arange(num_samples)\n        # Tie-breaking: sort samples by class 1 score desc, then sample index asc\n        ranked_sample_indices = np.lexsort((sample_indices, -class1_scores))\n        \n        num_positives_total = np.sum(is_positive)\n        max_predictions = int(np.floor(b * num_samples))\n        \n        max_f1 = 0.0\n        \n        for m_pred in range(max_predictions + 1):\n            if m_pred == 0:\n                tp = 0\n                fp = 0\n            else:\n                predicted_pos_indices = ranked_sample_indices[:m_pred]\n                tp = np.sum(is_positive[predicted_pos_indices])\n                fp = m_pred - tp\n            \n            fn = num_positives_total - tp\n            \n            denominator = 2 * tp + fp + fn\n            if denominator > 0:\n                f1 = (2 * tp) / denominator\n                if f1 > max_f1:\n                    max_f1 = f1\n        return max_f1\n\n    def calculate_auroc(model_scores, y_true):\n        class1_scores = model_scores[:, 1]\n        is_positive = (y_true == 1)\n        \n        pos_scores = class1_scores[is_positive]\n        neg_scores = class1_scores[~is_positive]\n        \n        if len(pos_scores) == 0 or len(neg_scores) == 0:\n            return 0.5 \n\n        numerator = 0.0\n        for p_score in pos_scores:\n            for n_score in neg_scores:\n                if p_score > n_score:\n                    numerator += 1.0\n                elif p_score == n_score:\n                    numerator += 0.5\n        \n        denominator = len(pos_scores) * len(neg_scores)\n        return numerator / denominator\n\n    # --- Main Loop ---\n    \n    all_results = []\n    \n    # Pre-calculate AUROC as it's independent of test cases\n    auroc_scores = np.array([calculate_auroc(s, y_true) for s in scores])\n    best_auroc_model = select_best_model(auroc_scores)\n\n    for case in test_cases:\n        k = case['k']\n        b = case['b']\n        \n        # Top-k accuracy\n        top_k_scores = np.array([\n            calculate_top_k_accuracy(s, y_true, k, num_classes) for s in scores\n        ])\n        best_top_k_model = select_best_model(top_k_scores)\n        \n        # Budgeted F1\n        f1_scores = np.array([\n            calculate_budgeted_f1(s, y_true, b, num_samples) for s in scores\n        ])\n        best_f1_model = select_best_model(f1_scores)\n        \n        case_results = [best_top_k_model, best_f1_model, best_auroc_model]\n        all_results.append(case_results)\n\n    # Format and print the final output\n    output_str = f\"[{','.join([f'[{r[0]},{r[1]},{r[2]}]' for r in all_results])}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "这个练习将带你深入探索模型评估的一个更微妙的层面：概率校准。它揭示了一个高排名质量（如高 $AUC$ 值）的模型，可能因为其预测的概率值不准确而并非最佳选择。通过比较一个排名能力强但校准不佳的模型和一个校准更优但排名稍逊的模型，你将学习到对数损失（log-loss）等指标在评估概率预测质量时的独特价值 。这个实践对于需要可靠概率估计来做决策的场景（如信用评分或医疗诊断）至关重要。",
            "id": "3107702",
            "problem": "对于每个测试用例，您会获得两个二元分类器，模型 A 和模型 B。每个分类器都会为正类输出一个分数，该分数旨在表示一个估计概率。这两个分类器在两方面有所不同：模型 A 倾向于产生较高的排序质量（以受试者工作特征曲线下面积 (AUC) 衡量），但可能校准不佳；模型 B 产生的排序质量较低，但校准得更好。您的任务是在对数损失（也称为负对数似然或交叉熵）下选择最优模型，并研究在简单错分成本下对这些分数进行阈值化决策所产生的影响。\n\n基本原理和定义：\n- 对于二元标签 $y \\in \\{0,1\\}$ 和预测概率 $p \\in (0,1)$，单样本对数损失为 $-\\left(y \\log p + (1-y)\\log(1-p)\\right)$。在 $n$ 个样本上的平均对数损失是这些项的算术平均值。\n- 为避免 $\\log(0)$ 产生未定义值，必须使用数值稳定的概率 $\\tilde{p} = \\min(\\max(p,\\epsilon),1-\\epsilon)$，其中 $\\epsilon$ 是一个很小的正数，例如 $\\epsilon = 10^{-15}$。\n- 假设假正例产生 $c_{\\text{fp}} > 0$ 的成本，假反例产生 $c_{\\text{fn}} > 0$ 的成本。在校准概率下，最小化期望错分成本的贝叶斯最优确定性决策规则是：当且仅当 $p \\ge \\tau$ 时预测为正类，其中阈值 $\\tau$ 满足 $\\tau = \\dfrac{c_{\\text{fp}}}{c_{\\text{fp}} + c_{\\text{fn}}}$。\n\n程序要求：\n- 对于每个测试用例，您会获得真实标签数组 $y_i \\in \\{0,1\\}$、分别对应于模型 A 和模型 B 的两个分数数组 $p^{(A)}_i$ 和 $p^{(B)}_i$，以及成本 $c_{\\text{fp}}$ 和 $c_{\\text{fn}}$。\n- 对于每个测试用例中的每个模型，使用数值稳定的概率（其中 $\\epsilon = 10^{-15}$）计算平均对数损失。\n- 在对数损失下选择最优模型：如果模型 A 的平均对数损失严格更小，则输出整数 $m$ 等于 $0$；如果模型 B 的平均对数损失严格更小，则输出 $1$。如果在容差 $\\delta = 10^{-12}$ 内出现平局，则通过选择在阈值 $\\tau = \\dfrac{c_{\\text{fp}}}{c_{\\text{fp}} + c_{\\text{fn}}}$ 下具有更小实现决策成本的模型来打破平局。如果仍然平局，则选择模型 B（即输出 $1$）。\n- 关于决策影响，使用阈值 $\\tau$ 计算每个模型的实现总错分成本：如果 $p \\ge \\tau$ 则预测 $\\hat{y}=1$，否则预测 $\\hat{y}=0$。如果 $\\hat{y}=1$ 且 $y=0$，预测产生 $c_{\\text{fp}}$ 的成本；如果 $\\hat{y}=0$ 且 $y=1$，产生 $c_{\\text{fn}}$ 的成本；其他情况成本为 $0$。报告每个模型的总成本（所有样本的总和）。\n\n测试套件：\n提供以下四个测试用例。每个测试用例都是一个元组 $(y, p^{(A)}, p^{(B)}, c_{\\text{fp}}, c_{\\text{fn}})$。\n\n- 案例 1（一般情况，尽管排序能力强，但校准不佳会损害对数损失）：\n  - $y = [1,0,1,0,1,0,0,1,0,1]$\n  - $p^{(A)} = [0.9,0.2,0.85,0.25,0.8,0.15,0.95,0.65,0.1,0.6]$\n  - $p^{(B)} = [0.7,0.35,0.65,0.4,0.6,0.3,0.45,0.55,0.35,0.6]$\n  - $c_{\\text{fp}} = 1.0$, $c_{\\text{fn}} = 1.0$\n- 案例 2（边界情况，具有需要稳定化的极端分数和非对称成本）：\n  - $y = [1,0,1,0]$\n  - $p^{(A)} = [1.0,0.0,1.0,1.0]$\n  - $p^{(B)} = [0.8,0.2,0.8,0.2]$\n  - $c_{\\text{fp}} = 2.0$, $c_{\\text{fn}} = 1.0$\n- 案例 3（平衡成本，更强的可分性与校准性的对比）：\n  - $y = [1,0,0,1,0,1]$\n  - $p^{(A)} = [0.9,0.6,0.3,0.8,0.35,0.7]$\n  - $p^{(B)} = [0.7,0.5,0.45,0.65,0.4,0.55]$\n  - $c_{\\text{fp}} = 1.0$, $c_{\\text{fn}} = 1.0$\n- 案例 4（分数完全相同，用于测试确定性平局打破规则）：\n  - $y = [0,1,0,1,1]$\n  - $p^{(A)} = [0.4,0.6,0.5,0.55,0.65]$\n  - $p^{(B)} = [0.4,0.6,0.5,0.55,0.65]$\n  - $c_{\\text{fp}} = 3.0$, $c_{\\text{fn}} = 2.0$\n\n数值和输出要求：\n- 使用 $\\epsilon = 10^{-15}$ 来稳定对数损失的概率，并使用 $\\delta = 10^{-12}$ 来处理平均对数损失比较中的平局。\n- 对于每个测试用例，输出一个列表 $[m, L_A, L_B, C_A, C_B]$，其中 $m$ 是 $\\{0,1\\}$ 中的一个整数，$L_A$ 和 $L_B$ 分别是模型 A 和模型 B 的平均对数损失值，$C_A$ 和 $C_B$ 是在阈值 $\\tau$ 下的实现总错分成本。将 $L_A$、$L_B$、$C_A$ 和 $C_B$ 表示为四舍五入到小数点后 $6$ 位的小数浮点数。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个由四个按案例排列的列表组成的逗号分隔列表，并用方括号括起来；例如，`[[m_1,L_{A,1},L_{B,1},C_{A,1},C_{B,1}],[m_2,L_{A,2},L_{B,2},C_{A,2},C_{B,2}],\\dots]`。输出行中不得有多余的文本或空格。",
            "solution": "该问题要求根据一个涉及对数损失和错分成本的分层准则，从两个候选模型（模型 A 和模型 B）中选择一个最优的二元分类器。此任务涉及统计学习中的基本概念：模型评估、校准和决策理论。解决方案涉及对所提供的评估协议进行精确、分步的实现。\n\n首先，我们处理主要的评估指标，即平均对数损失，通常也称为交叉熵损失。对于一组具有真实二元标签 $y_i \\in \\{0, 1\\}$ 和相应预测概率 $p_i \\in (0, 1)$ 的 $n$ 个样本，平均对数损失定义为：\n$$\n\\bar{L}(y, p) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right]\n$$\n该指标直接评估预测概率的质量。较低的对数损失表明模型校准得更好，意味着其输出能更准确地表示正类的真实似然。为了处理模型预测概率恰好为 $0$ 或 $1$（这会使对数未定义）的情况，需要对概率 $p_i$ 进行数值稳定化处理。将它们裁剪到一个小区间 $[\\epsilon, 1-\\epsilon]$ 内，其中 $\\epsilon$ 是一个很小的正常数。稳定后的概率 $\\tilde{p}_i$ 由下式给出：\n$$\n\\tilde{p}_i = \\min(\\max(p_i, \\epsilon), 1-\\epsilon)\n$$\n在本问题中，$\\epsilon$ 被指定为 $10^{-15}$。对于每个模型（模型 A 和模型 B），我们计算它们各自的平均对数损失，记为 $L_A$ 和 $L_B$。\n\n其次，我们在决策理论框架下考虑模型预测的影响。给定假正例预测的成本 $c_{\\text{fp}}$ 和假反例预测的成本 $c_{\\text{fn}}$，最小化期望错分成本的决策规则（假设概率 $p_i$ 已完美校准）是：当且仅当 $p_i \\ge \\tau$ 时预测为正类，其中决策阈值 $\\tau$ 为：\n$$\n\\tau = \\frac{c_{\\text{fp}}}{c_{\\text{fp}} + c_{\\text{fn}}}\n$$\n对于每个模型，我们将此阈值应用于其分数输出 $p_i$，以获得一组确定性预测 $\\hat{y}_i$。然后通过对 $n$ 个样本上的所有错误成本求和来计算实现的总错分成本：\n$$\nC(y, \\hat{y}) = c_{\\text{fp}} \\sum_{i=1}^{n} \\mathbb{I}(\\hat{y}_i = 1 \\text{ and } y_i = 0) + c_{\\text{fn}} \\sum_{i=1}^{n} \\mathbb{I}(\\hat{y}_i = 0 \\text{ and } y_i = 1)\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。这样就得出了模型 A 和模型 B 的总成本 $C_A$ 和 $C_B$。\n\n最后，使用一个定义好的分层程序来选择最优模型。设 $m$ 是一个表示所选模型的整数（$0$ 代表 A，$1$ 代表 B）。\n\n1.  主要标准是平均对数损失。选择平均对数损失严格更小的模型。为考虑潜在的浮点不精确性，如果对数损失之间的绝对差值在容差 $\\delta = 10^{-12}$ 之内，则声明为平局。\n    $$\n    \\text{如果 } |L_A - L_B| > \\delta, \\text{ 那么 }\n    m = \\begin{cases} 0  &\\text{如果 } L_A < L_B \\\\ 1  &\\text{如果 } L_B < L_A \\end{cases}\n    $$\n2.  如果对数损失持平（即 $|L_A - L_B| \\le \\delta$），则通过实现的总错分成本来打破平局。选择成本较低的模型。\n    $$\n    \\text{如果 } |L_A - L_B| \\le \\delta \\text{ 且 } C_A \\neq C_B, \\text{ 那么 }\n    m = \\begin{cases} 0  &\\text{如果 } C_A < C_B \\\\ 1  &\\text{如果 } C_B < C_A \\end{cases}\n    $$\n3.  如果对数损失和成本都持平，则应用最终的确定性规则：选择模型 B。\n    $$\n    \\text{如果 } |L_A - L_B| \\le \\delta \\text{ 且 } C_A = C_B, \\text{ 那么 } m = 1\n    $$\n\n将此完整算法应用于每个测试用例。结果包括所选模型的索引 $m$ 以及 $L_A, L_B, C_A, C_B$ 的计算值（四舍五入到六位小数），然后汇总成最终指定的输出格式。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    \n    # Define the constants from the problem statement.\n    EPSILON = 1e-15\n    DELTA = 1e-12\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (y, p_A, p_B, c_fp, c_fn)\n    test_cases = [\n        (\n            np.array([1, 0, 1, 0, 1, 0, 0, 1, 0, 1]),\n            np.array([0.9, 0.2, 0.85, 0.25, 0.8, 0.15, 0.95, 0.65, 0.1, 0.6]),\n            np.array([0.7, 0.35, 0.65, 0.4, 0.6, 0.3, 0.45, 0.55, 0.35, 0.6]),\n            1.0, 1.0\n        ),\n        (\n            np.array([1, 0, 1, 0]),\n            np.array([1.0, 0.0, 1.0, 1.0]),\n            np.array([0.8, 0.2, 0.8, 0.2]),\n            2.0, 1.0\n        ),\n        (\n            np.array([1, 0, 0, 1, 0, 1]),\n            np.array([0.9, 0.6, 0.3, 0.8, 0.35, 0.7]),\n            np.array([0.7, 0.5, 0.45, 0.65, 0.4, 0.55]),\n            1.0, 1.0\n        ),\n        (\n            np.array([0, 1, 0, 1, 1]),\n            np.array([0.4, 0.6, 0.5, 0.55, 0.65]),\n            np.array([0.4, 0.6, 0.5, 0.55, 0.65]),\n            3.0, 2.0\n        )\n    ]\n\n    results_str_list = []\n    \n    for y, p_a, p_b, c_fp, c_fn in test_cases:\n        # 1. Calculate average log-loss\n        def calculate_log_loss(y_true, p_pred):\n            p_clipped = np.clip(p_pred, EPSILON, 1 - EPSILON)\n            loss_per_sample = - (y_true * np.log(p_clipped) + (1 - y_true) * np.log(1 - p_clipped))\n            return np.mean(loss_per_sample)\n\n        l_a = calculate_log_loss(y, p_a)\n        l_b = calculate_log_loss(y, p_b)\n\n        # 2. Calculate realized total misclassification cost\n        tau = c_fp / (c_fp + c_fn)\n        \n        def calculate_cost(y_true, p_pred, threshold, cost_fp, cost_fn):\n            y_hat = (p_pred >= threshold).astype(int)\n            false_positives = np.sum((y_hat == 1)  (y_true == 0))\n            false_negatives = np.sum((y_hat == 0)  (y_true == 1))\n            total_cost = false_positives * cost_fp + false_negatives * cost_fn\n            return float(total_cost)\n\n        c_a = calculate_cost(y, p_a, tau, c_fp, c_fn)\n        c_b = calculate_cost(y, p_b, tau, c_fp, c_fn)\n\n        # 3. Select optimal model based on hierarchical rules\n        m = 0\n        if abs(l_a - l_b) = DELTA:\n            # Tie in log-loss, use cost to break tie\n            if c_a  c_b:\n                m = 0\n            elif c_b  c_a:\n                m = 1\n            else:\n                # Tie in cost, default to Model B\n                m = 1\n        elif l_a  l_b:\n            m = 0\n        else: # l_b  l_a\n            m = 1\n            \n        # 4. Format the output for the current case\n        # Round the float values to 6 decimal places before formatting\n        l_a_rounded = round(l_a, 6)\n        l_b_rounded = round(l_b, 6)\n        c_a_rounded = round(c_a, 6)\n        c_b_rounded = round(c_b, 6)\n        \n        case_result_str = (\n            f\"[{m},\"\n            f\"{l_a_rounded:.6f},\"\n            f\"{l_b_rounded:.6f},\"\n            f\"{c_a_rounded:.6f},\"\n            f\"{c_b_rounded:.6f}]\"\n        )\n        results_str_list.append(case_result_str)\n\n    # Final print statement in the exact required format without spaces.\n    final_output = f\"[{','.join(results_str_list)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "这个练习将模型选择从抽象的统计指标推向了解决实际业务问题的决策过程。在许多现实场景中，不同类型的错误（如假阳性和假阴性）会带来截然不同的成本。此练习将指导你如何基于一个明确的成本矩阵来定义一个效用函数，并通过交叉验证来联合选择能够最大化预期效用的模型参数（如正则化强度 $\\lambda$）和决策阈值 $t$ 。这让你能够将机器学习模型与具体的业务目标（如利润最大化或风险最小化）直接对齐。",
            "id": "3107638",
            "problem": "您会拿到三个独立的二元分类任务。对于每个任务，您的目标是实现一个有原则的流程，通过最大化由指定成本矩阵引出的预期效用的估计值，来联合选择模型和决策阈值。您生成的程序必须是一个完整、可运行的程序，该程序执行此流程，并在一行中输出所有任务的最终测试集效用。\n\n基本基础。使用以下基本定义：\n- 一个二元分类器将特征向量 $x \\in \\mathbb{R}^d$ 映射到一个实值分数 $s(x) \\in \\mathbb{R}$，然后使用逻辑函数（logistic function）将其解释为概率估计 $p(y=1 \\mid x) \\in [0,1]$。假设使用带有 $\\ell_2$ 正则化的概率线性模型（即逻辑回归）来拟合 $p(y=1 \\mid x)$。\n- 一个带有阈值 $t \\in [0,1]$ 的决策规则进行预测 $\\hat{y}(x;t)=\\mathbf{1}\\{p(y=1 \\mid x) \\ge t\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n- 一个成本矩阵 $C \\in \\mathbb{R}^{2 \\times 2}$ 为当真实类别为 $i \\in \\{0,1\\}$ 时预测为类别 $j \\in \\{0,1\\}$ 的情况分配一个非负成本 $C_{ij}$。定义效用矩阵 $U$ 为 $U_{ij}=-C_{ij}$。分类器-阈值对在数据集 $\\{(x_n,y_n)\\}_{n=1}^N$ 上的预期效用是经验平均值 $\\frac{1}{N}\\sum_{n=1}^N U_{y_n,\\hat{y}(x_n;t)}$。\n- $K$ 折交叉验证（Cross-Validation, CV）将训练集划分为 $K$ 个大小近似相等的不相交的折（fold），在 $K-1$ 个折上进行训练，在留出的那个折上进行验证，并通过对各折上的验证标准进行平均来估计泛化性能。\n\n任务。对于以下每种情况：\n1. 使用 $K=3$ 的 $K$ 折交叉验证，通过最大化平均验证预期效用，来联合选择逻辑回归的正则化强度 $\\lambda$ 和决策阈值 $t$。搜索集合为：\n   - 正则化候选项 $\\Lambda=\\{\\lambda_1,\\lambda_2,\\lambda_3\\}=\\{\\,0.0,\\,0.1,\\,1.0\\,\\}$。\n   - 阈值网格 $\\mathcal{T}=\\{\\,0.00,\\,0.05,\\,0.10,\\,\\dots,\\,0.95,\\,1.00\\,\\}$。\n   使用确定性的折：将（从零开始的）样本索引 $n$ 分配到第 $n \\bmod K$ 折。\n   通过在最大化项中选择最小的 $\\lambda$ 来打破平局，然后在余下的最大化项中选择最小的 $t$。\n2. 使用所选的 $\\lambda$ 在完整的训练集上重新训练逻辑回归，然后使用所选的阈值 $t$ 在提供的测试集上评估预期效用。\n3. 报告每种情况下测试集的预期效用，形式为浮点数，保留 $6$ 位小数。不要报告中间值或参数。\n\n数据集和成本矩阵。\n\n情况 A:\n- 训练特征 $X_{\\text{train}} \\in \\mathbb{R}^{6 \\times 2}$ 和标签 $y_{\\text{train}} \\in \\{0,1\\}^6$:\n  $$\n  X_{\\text{train}}=\\begin{bmatrix}\n  0.0  0.0\\\\\n  0.2  0.1\\\\\n  0.4  0.2\\\\\n  0.6  0.8\\\\\n  0.8  0.7\\\\\n  1.0  0.9\n  \\end{bmatrix},\\quad\n  y_{\\text{train}}=\\begin{bmatrix}\n  0\\\\\n  0\\\\\n  0\\\\\n  1\\\\\n  1\\\\\n  1\n  \\end{bmatrix}.\n  $$\n- 测试特征 $X_{\\text{test}} \\in \\mathbb{R}^{2 \\times 2}$ 和标签 $y_{\\text{test}} \\in \\{0,1\\}^2$:\n  $$\n  X_{\\text{test}}=\\begin{bmatrix}\n  0.3  0.2\\\\\n  0.7  0.75\n  \\end{bmatrix},\\quad\n  y_{\\text{test}}=\\begin{bmatrix}\n  0\\\\\n  1\n  \\end{bmatrix}.\n  $$\n- 成本矩阵 $C=\\begin{bmatrix}0  1\\\\ 1  0\\end{bmatrix}$。\n\n情况 B:\n- 训练特征和标签：\n  $$\n  X_{\\text{train}}=\\begin{bmatrix}\n  -1.0  -1.0\\\\\n  -0.8  -0.6\\\\\n  -0.6  -0.8\\\\\n  0.5  0.4\\\\\n  0.6  0.3\\\\\n  0.2  0.1\\\\\n  -0.2  0.0\n  \\end{bmatrix},\\quad\n  y_{\\text{train}}=\\begin{bmatrix}\n  0\\\\\n  0\\\\\n  0\\\\\n  1\\\\\n  1\\\\\n  1\\\\\n  1\n  \\end{bmatrix}.\n  $$\n- 测试特征和标签：\n  $$\n  X_{\\text{test}}=\\begin{bmatrix}\n  -0.7  -0.7\\\\\n  0.55  0.35\\\\\n  0.0  0.1\n  \\end{bmatrix},\\quad\n  y_{\\text{test}}=\\begin{bmatrix}\n  0\\\\\n  1\\\\\n  1\n  \\end{bmatrix}.\n  $$\n- 成本矩阵 $C=\\begin{bmatrix}0  1\\\\ 4  0\\end{bmatrix}$。\n\n情况 C:\n- 训练特征和标签：\n  $$\n  X_{\\text{train}}=\\begin{bmatrix}\n  0.0  1.0\\\\\n  0.1  0.9\\\\\n  0.9  0.1\\\\\n  1.0  0.0\\\\\n  0.45  0.55\\\\\n  0.55  0.45\n  \\end{bmatrix},\\quad\n  y_{\\text{train}}=\\begin{bmatrix}\n  0\\\\\n  0\\\\\n  1\\\\\n  1\\\\\n  0\\\\\n  1\n  \\end{bmatrix}.\n  $$\n- 测试特征和标签：\n  $$\n  X_{\\text{test}}=\\begin{bmatrix}\n  0.52  0.48\\\\\n  0.48  0.52\\\\\n  0.6  0.4\\\\\n  0.4  0.6\n  \\end{bmatrix},\\quad\n  y_{\\text{test}}=\\begin{bmatrix}\n  1\\\\\n  0\\\\\n  1\\\\\n  0\n  \\end{bmatrix}.\n  $$\n- 成本矩阵 $C=\\begin{bmatrix}0  3\\\\ 1  0\\end{bmatrix}$。\n\n实现要求。\n- 使用带有 $\\ell_2$ 正则化和偏置项的逻辑回归，通过在正则化的负对数似然上进行基于梯度的优化来训练。您可以假设标签在 $\\{0,1\\}$ 中，并使用逻辑链接函数。\n- 对于每个阈值 $t \\in \\mathcal{T}$ 和 $\\lambda \\in \\Lambda$，估计在 $K$ 个折上的平均验证预期效用，然后根据上面给出的打破平局规则选择使该量最大化的对 $(\\lambda^\\star,t^\\star)$。\n- 选择后，使用 $\\lambda^\\star$ 在完整的训练集上重新训练，然后使用 $t^\\star$ 评估平均测试集预期效用。\n- 角度单位不适用。没有物理单位。所有报告的预期效用必须是小数，四舍五入到小数点后 $6$ 位。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按情况 A、情况 B、情况 C 的顺序排列，例如 $[u_A,u_B,u_C]$，其中每个 $u_\\cdot$ 是如上所述四舍五入后的测试集预期效用。",
            "solution": "我们必须设计一个基于成本矩阵衍生的预期效用的、有原则的联合模型与阈值选择方案。其基本基础包括：二元分类器的概率解释、通过阈值化构建决策规则、成本到效用的转换，以及使用交叉验证（CV）作为样本外性能的估计器。\n\n首先，考虑一个输入为 $x \\in \\mathbb{R}^d$、标签为 $y \\in \\{0,1\\}$ 的二元分类设置。伯努利模型下的概率线性分类器使用逻辑链接函数生成 $p_\\theta(y=1\\mid x)=\\sigma(w^\\top x + b)$，其中 $\\sigma(z)=\\frac{1}{1+e^{-z}}$，参数为 $\\theta=(w,b)$，其中 $w \\in \\mathbb{R}^d$，$b \\in \\mathbb{R}$，正则化强度 $\\lambda \\ge 0$ 控制对 $w$ 的 $\\ell_2$ 惩罚。训练过程是通过最小化训练数据 $\\{(x_n,y_n)\\}_{n=1}^N$ 上的正则化负对数似然来进行的，这是一个关于 $(w,b)$ 的凸目标函数，对于固定的 $\\lambda$ 有唯一的最小值点。\n\n其次，决策需要一个阈值 $t \\in [0,1]$ 将概率转换为类别预测：$\\hat{y}(x;t)=\\mathbf{1}\\{\\sigma(w^\\top x+b)\\ge t\\}$。决策的后果由成本矩阵 $C \\in \\mathbb{R}^{2\\times 2}$ 捕获，其中 $C_{ij}$ 是真实类别为 $i$ 而预测为 $j$ 时产生的成本。我们定义效用矩阵 $U$ 为 $U=-C$，因此最大化预期效用等价于最小化预期成本。给定一个数据集，$(\\theta,t)$ 的经验预期效用是\n$$\n\\bar{u}(\\theta,t) \\;=\\; \\frac{1}{N}\\sum_{n=1}^N U_{y_n,\\,\\hat{y}(x_n;t)}.\n$$\n这个量根据效用矩阵奖励正确的决策，并根据负成本惩罚错误。\n\n第三，为了选择最优的模型和阈值，我们需要一个对样本外预期效用的无偏估计。$K$ 折交叉验证（CV）通过将训练集索引划分为 $K$ 个折 $\\{\\mathcal{I}_k\\}_{k=0}^{K-1}$、在 $\\bigcup_{j\\ne k}\\mathcal{I}_j$ 上训练并在 $\\mathcal{I}_k$ 上验证来提供这种估计。对于任何候选的 $\\lambda$ 和 $t$，定义\n$$\n\\widehat{u}_{\\text{CV}}(\\lambda,t) \\;=\\; \\frac{1}{K}\\sum_{k=0}^{K-1} \\frac{1}{|\\mathcal{I}_k|}\\sum_{n\\in \\mathcal{I}_k} U_{y_n,\\,\\hat{y}_{\\lambda,k}(x_n;t)},\n$$\n其中 $\\hat{y}_{\\lambda,k}$ 是通过在训练折 $\\bigcup_{j\\ne k}\\mathcal{I}_j$ 上使用正则化参数 $\\lambda$ 训练逻辑回归，并将其概率输出在验证折 $\\mathcal{I}_k$ 上应用阈值 $t$ 所获得的决策规则。然后选择对 $(\\lambda^\\star,t^\\star)$ 以在搜索网格上最大化 $\\widehat{u}_{\\text{CV}}(\\lambda,t)$。通过选择最小的 $\\lambda$ 以及在其中选择最小的 $t$ 来打破平局。在 CV 内部选择 $t$ 至关重要，因为验证概率依赖于训练好的模型，在用于评估效用的相同验证数据上选择 $t$ 可以确保阈值的选择是为泛化而调整的，从而减少了如果在最终测试集上调整 $t$ 可能出现的乐观偏差。\n\n算法步骤：\n1. 对每种情况，通过将索引 $n$ 放入第 $n \\bmod K$ 折来构建确定性的 $K$ 折分区，以确保可复现性并覆盖边缘索引。\n2. 对于每个 $\\lambda \\in \\{0.0,0.1,1.0\\}$：\n   - 对于每个折 $k \\in \\{0,1,2\\}$：\n     - 在其他折的并集上训练带有 $\\ell_2$ 惩罚 $\\lambda$ 的逻辑回归，使用基于梯度的优化最小化正则化负对数似然。$w$ 的梯度结合了平均残差项和正则化项；$b$ 的梯度是平均残差。迭代更新 $w \\leftarrow w - \\eta \\nabla_w, b \\leftarrow b - \\eta \\nabla_b$ 会减小凸目标函数值，其中 $\\eta0$ 是学习率。\n     - 在验证折上计算概率预测。\n   - 对于每个阈值 $t \\in \\{0.00,0.05,\\dots,1.00\\}$，将验证概率转换为预测，并计算每个折的效用，然后在所有折上取平均得到 $\\widehat{u}_{\\text{CV}}(\\lambda,t)$。\n3. 使用指定的打破平局规则，选择使交叉验证估计值最大化的 $(\\lambda^\\star,t^\\star)$。\n4. 使用 $\\lambda^\\star$ 在完整的训练集上重新训练逻辑回归，在测试集上计算概率预测，应用 $t^\\star$ 获得决策，并计算平均测试集预期效用 $\\bar{u}_{\\text{test}}$。\n5. 将每个 $\\bar{u}_{\\text{test}}$ 四舍五入到 $6$ 位小数。\n\n设计覆盖范围的基本原理：\n- 阈值网格包括边界值 $t=0$ 和 $t=1$，捕捉所有样本分别被预测为正类或负类的极端情况，这在成本极度不对称的情况下非常重要。\n- 正则化网格涵盖了无正则化（$\\lambda=0.0$）、弱正则化（$\\lambda=0.1$）和强正则化（$\\lambda=1.0$）的情况，以测试偏差-方差权衡。\n- 数据集涵盖了：平衡成本（情况 A）、更多地惩罚假阴性的不对称成本（情况 B），以及更多地惩罚假阳性的不对称成本（情况 C）。这确保了阈值向相反方向移动的情况都得到了检验。\n\n该程序精确地实现了上述算法，确保了确定性的折、模型复杂度和阈值的联合选择、选择后在完整训练集上的重新训练，并以所需格式计算最终输出 $[u_A,u_B,u_C]$。每个效用都是一个小数（不是百分比），按规定四舍五入到 $6$ 位。",
            "answer": "```python\nimport numpy as np\n\ndef sigmoid(z):\n    return 1.0 / (1.0 + np.exp(-z))\n\ndef train_logistic_regression(X, y, lambda_reg=0.0, lr=0.1, iters=3000):\n    \"\"\"\n    Train logistic regression with L2 regularization on weights (not bias).\n    X: (n_samples, n_features)\n    y: (n_samples,) in {0,1}\n    Returns weights w (n_features,) and bias b.\n    \"\"\"\n    n, d = X.shape\n    w = np.zeros(d, dtype=float)\n    b = 0.0\n    for _ in range(iters):\n        z = X @ w + b\n        p = sigmoid(z)\n        # gradient\n        residual = p - y  # shape (n,)\n        grad_w = (X.T @ residual) / n + lambda_reg * w\n        grad_b = np.sum(residual) / n\n        # update\n        w -= lr * grad_w\n        b -= lr * grad_b\n    return w, b\n\ndef predict_proba(X, w, b):\n    return sigmoid(X @ w + b)\n\ndef expected_utility_from_probs(y_true, y_prob, threshold, cost_matrix):\n    \"\"\"\n    y_true: (n,) in {0,1}\n    y_prob: (n,) in [0,1]\n    threshold: float in [0,1]\n    cost_matrix: 2x2 numpy array\n    Returns mean utility (negative cost).\n    \"\"\"\n    y_pred = (y_prob >= threshold).astype(int)\n    # Utility matrix is negative of cost matrix\n    U = -cost_matrix\n    # Map each pair (y_true[i], y_pred[i]) to utility\n    utilities = U[y_true, y_pred]\n    return float(np.mean(utilities))\n\ndef kfold_indices(n, K):\n    \"\"\"\n    Deterministic K-fold split by index modulo K.\n    Returns list of folds, each is a numpy array of indices.\n    \"\"\"\n    folds = [[] for _ in range(K)]\n    for idx in range(n):\n        folds[idx % K].append(idx)\n    return [np.array(f, dtype=int) for f in folds]\n\ndef joint_cv_select_threshold_and_lambda(X, y, cost_matrix, lambdas, thresholds, K=3, lr=0.1, iters=3000):\n    \"\"\"\n    Perform K-fold CV to jointly select lambda and threshold maximizing expected utility.\n    Returns selected (lambda_star, threshold_star).\n    Tie-breaking: smallest lambda, then smallest threshold.\n    \"\"\"\n    n = X.shape[0]\n    folds = kfold_indices(n, K)\n    # Precompute folds' train/val splits\n    fold_train_val = []\n    all_indices = np.arange(n, dtype=int)\n    for val_idx in folds:\n        train_idx = np.setdiff1d(all_indices, val_idx, assume_unique=True)\n        fold_train_val.append((train_idx, val_idx))\n\n    best_u = -np.inf\n    best_lambda = -1\n    best_t = -1\n\n    # Iterate lambdas and thresholds in ascending order for tie-breaking\n    for lam in sorted(lambdas):\n        val_probs_per_fold = []\n        y_val_per_fold = []\n        for (tr_idx, va_idx) in fold_train_val:\n            w, b = train_logistic_regression(X[tr_idx], y[tr_idx], lambda_reg=lam, lr=lr, iters=iters)\n            probs = predict_proba(X[va_idx], w, b)\n            val_probs_per_fold.append(probs)\n            y_val_per_fold.append(y[va_idx])\n        \n        for t in sorted(thresholds):\n            u_folds = []\n            for probs, yv in zip(val_probs_per_fold, y_val_per_fold):\n                u = expected_utility_from_probs(yv, probs, t, cost_matrix)\n                u_folds.append(u)\n            u_cv = float(np.mean(u_folds))\n            \n            if u_cv > best_u:\n                best_u = u_cv\n                best_lambda = lam\n                best_t = t\n\n    return best_lambda, best_t\n\ndef solve():\n    # Define threshold grid and lambda grid\n    thresholds = np.round(np.linspace(0.0, 1.0, 21), 2)  # 0.00, 0.05, ..., 1.00\n    lambdas = [0.0, 0.1, 1.0]\n    K = 3\n\n    # Case A\n    X_train_A = np.array([\n        [0.0, 0.0],\n        [0.2, 0.1],\n        [0.4, 0.2],\n        [0.6, 0.8],\n        [0.8, 0.7],\n        [1.0, 0.9],\n    ], dtype=float)\n    y_train_A = np.array([0, 0, 0, 1, 1, 1], dtype=int)\n    X_test_A = np.array([\n        [0.3, 0.2],\n        [0.7, 0.75],\n    ], dtype=float)\n    y_test_A = np.array([0, 1], dtype=int)\n    C_A = np.array([[0.0, 1.0],\n                    [1.0, 0.0]], dtype=float)\n\n    # Case B\n    X_train_B = np.array([\n        [-1.0, -1.0],\n        [-0.8, -0.6],\n        [-0.6, -0.8],\n        [0.5, 0.4],\n        [0.6, 0.3],\n        [0.2, 0.1],\n        [-0.2, 0.0],\n    ], dtype=float)\n    y_train_B = np.array([0, 0, 0, 1, 1, 1, 1], dtype=int)\n    X_test_B = np.array([\n        [-0.7, -0.7],\n        [0.55, 0.35],\n        [0.0, 0.1],\n    ], dtype=float)\n    y_test_B = np.array([0, 1, 1], dtype=int)\n    C_B = np.array([[0.0, 1.0],\n                    [4.0, 0.0]], dtype=float)\n\n    # Case C\n    X_train_C = np.array([\n        [0.0, 1.0],\n        [0.1, 0.9],\n        [0.9, 0.1],\n        [1.0, 0.0],\n        [0.45, 0.55],\n        [0.55, 0.45],\n    ], dtype=float)\n    y_train_C = np.array([0, 0, 1, 1, 0, 1], dtype=int)\n    X_test_C = np.array([\n        [0.52, 0.48],\n        [0.48, 0.52],\n        [0.6, 0.4],\n        [0.4, 0.6],\n    ], dtype=float)\n    y_test_C = np.array([1, 0, 1, 0], dtype=int)\n    C_C = np.array([[0.0, 3.0],\n                    [1.0, 0.0]], dtype=float)\n\n    cases = [\n        (X_train_A, y_train_A, X_test_A, y_test_A, C_A),\n        (X_train_B, y_train_B, X_test_B, y_test_B, C_B),\n        (X_train_C, y_train_C, X_test_C, y_test_C, C_C),\n    ]\n\n    results = []\n    # Training parameters (chosen to ensure convergence on small datasets)\n    lr = 0.2\n    iters = 4000\n\n    for X_tr, y_tr, X_te, y_te, C in cases:\n        lam_star, t_star = joint_cv_select_threshold_and_lambda(\n            X_tr, y_tr, C, lambdas, thresholds, K=K, lr=lr, iters=iters\n        )\n        w, b = train_logistic_regression(X_tr, y_tr, lambda_reg=lam_star, lr=lr, iters=iters)\n        probs_test = predict_proba(X_te, w, b)\n        u_test = expected_utility_from_probs(y_te, probs_test, t_star, C)\n        # Round to 6 decimal places\n        results.append(f\"{u_test:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}