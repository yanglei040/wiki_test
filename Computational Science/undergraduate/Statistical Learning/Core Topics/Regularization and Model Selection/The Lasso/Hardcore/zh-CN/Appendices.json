{
    "hands_on_practices": [
        {
            "introduction": "Lasso 回归的核心在于其独特的惩罚项——$L_1$ 范数。在深入探讨 Lasso 如何进行特征选择和模型正则化之前，我们必须首先对这个惩罚项有一个直观的理解。本练习  提供了一个直接的计算任务，旨在帮助你熟悉 $L_1$ 范数的概念，这是理解 Lasso 所有后续行为的基础。",
            "id": "1928640",
            "problem": "在统计学习中，最小绝对收缩和选择算子 (LASSO) 是一种回归分析方法，它同时进行变量选择和正则化，以增强统计模型的预测准确性和可解释性。LASSO 中应用的惩罚项是基于模型系数向量的 $L_1$ 范数。\n\n假设一位数据分析师拟合了一个包含四个预测变量的 LASSO 回归模型。这些预测变量的最终估计系数向量为 $\\boldsymbol{\\beta} = (3, -1, 0, -4)^T$。\n\n计算该系数向量的 $L_1$ 范数，记为 $\\|\\boldsymbol{\\beta}\\|_1$。",
            "solution": "向量的 $L_{1}$ 范数定义为其各分量绝对值之和。对于 $\\boldsymbol{\\beta} = (3, -1, 0, -4)^{T}$，我们有\n$$\n\\|\\boldsymbol{\\beta}\\|_{1}=\\sum_{i=1}^{4}|\\beta_{i}|=|3|+|-1|+|0|+|-4|.\n$$\n计算每个绝对值，\n$$\n|3|=3,\\quad |-1|=1,\\quad |0|=0,\\quad |-4|=4,\n$$\n所以\n$$\n\\|\\boldsymbol{\\beta}\\|_{1}=3+1+0+4=8.\n$$",
            "answer": "$$\\boxed{8}$$"
        },
        {
            "introduction": "理解了 $L_1$ 惩罚的定义后，下一个关键问题是：它究竟如何影响回归系数的求解过程？本练习  将带你深入 Lasso 的数学心脏。通过在一个理想化的正交设计（orthonormal design）场景下推导其解，你将亲手揭示著名的“软阈值”（soft-thresholding）公式，它清晰地展示了系数是如何被压缩乃至直接归零的。",
            "id": "3184336",
            "problem": "考虑没有截距项的最小绝对收缩和选择算子 (LASSO) 问题：最小化目标函数\n$$\n\\frac{1}{2}\\|y - X\\boldsymbol{\\beta}\\|_{2}^{2} + \\lambda \\|\\boldsymbol{\\beta}\\|_{1},\n$$\n其中 $X \\in \\mathbb{R}^{n \\times p}$ 是一个固定的设计矩阵，$y \\in \\mathbb{R}^{n}$ 是一个响应向量，$\\boldsymbol{\\beta} \\in \\mathbb{R}^{p}$ 是系数向量，$\\lambda \\ge 0$ 是一个调节参数。假设 $X$ 的列被标准化为标准正交，即 $X^{\\top}X = I_{p}$，并且模型中没有截距项。\n\n任务：\n1) 仅从凸优化最优性原理（一个点 $\\boldsymbol{\\beta}^{\\star}$ 最小化凸函数 $f$ 当且仅当 $\\mathbf{0} \\in \\partial f(\\boldsymbol{\\beta}^{\\star})$）和 $\\ell_{1}$范数次梯度的定义出发，推导在此设定下刻画 LASSO 问题最优解 $\\boldsymbol{\\beta}^{\\star}$ 的显式卡罗需-库恩-塔克 (KKT) 条件（带有次梯度的平稳性条件）。您的推导必须清楚地说明这些条件在坐标 $j$ 满足 $\\beta^{\\star}_{j} \\ne 0$ 和 $\\beta^{\\star}_{j} = 0$ 时的具体形式。\n\n2) 使用您推导出的条件，手动求解以下 $p = 3$ 的三特征实例。假设 $X^{\\top}X = I_{3}$ 且\n$$\nX^{\\top}y = \\begin{pmatrix} 1.8 \\\\ -0.5 \\\\ 0.4 \\end{pmatrix}, \\qquad \\lambda = 0.6.\n$$\n计算最优系数向量 $\\boldsymbol{\\beta}^{\\star} \\in \\mathbb{R}^{3}$。\n\n将您关于 $\\boldsymbol{\\beta}^{\\star}$ 的最终数值答案以单行向量的形式给出。",
            "solution": "用户提供的问题经评估有效。这是一个来自统计学习领域的适定、有科学依据的问题，其陈述清晰完整。\n\n该问题要求完成与正交设计矩阵假设下的 LASSO 目标函数相关的两个任务。\n\n**任务 1：推导卡罗需-库恩-塔克 (KKT) 条件**\n\n需要最小化的 LASSO 目标函数是：\n$$\nf(\\boldsymbol{\\beta}) = \\frac{1}{2}\\|y - X\\boldsymbol{\\beta}\\|_{2}^{2} + \\lambda \\|\\boldsymbol{\\beta}\\|_{1}\n$$\n其中 $X \\in \\mathbb{R}^{n \\times p}$，$y \\in \\mathbb{R}^{n}$，$\\boldsymbol{\\beta} \\in \\mathbb{R}^{p}$，且 $\\lambda \\ge 0$。我们已知设计矩阵 $X$ 具有标准正交列，即 $X^{\\top}X = I_{p}$。\n\n目标函数 $f(\\boldsymbol{\\beta})$ 是两个凸函数之和：\n1. $g(\\boldsymbol{\\beta}) = \\frac{1}{2}\\|y - X\\boldsymbol{\\beta}\\|_{2}^{2}$，它是可微且凸的。\n2. $h(\\boldsymbol{\\beta}) = \\lambda \\|\\boldsymbol{\\beta}\\|_{1}$，它是凸的，但在 $\\boldsymbol{\\beta}$ 的任何分量为零的点处不可微。\n\n函数 $f(\\boldsymbol{\\beta})$ 是凸的。根据凸优化的基本原理，一个点 $\\boldsymbol{\\beta}^{\\star}$ 是 $f(\\boldsymbol{\\beta})$ 的全局最小值点，当且仅当零向量是 $f$ 在 $\\boldsymbol{\\beta}^{\\star}$ 处的次微分的元素：\n$$\n\\mathbf{0} \\in \\partial f(\\boldsymbol{\\beta}^{\\star})\n$$\n由于 $g(\\boldsymbol{\\beta})$ 是可微的，和函数 $f(\\boldsymbol{\\beta}) = g(\\boldsymbol{\\beta}) + h(\\boldsymbol{\\beta})$ 的次微分是 $g(\\boldsymbol{\\beta})$ 的梯度与 $h(\\boldsymbol{\\beta})$ 的次微分之和：\n$$\n\\partial f(\\boldsymbol{\\beta}^{\\star}) = \\nabla g(\\boldsymbol{\\beta}^{\\star}) + \\partial h(\\boldsymbol{\\beta}^{\\star})\n$$\n首先，我们计算 $g(\\boldsymbol{\\beta})$ 的梯度。我们展开平方范数：\n$$\ng(\\boldsymbol{\\beta}) = \\frac{1}{2}(y - X\\boldsymbol{\\beta})^{\\top}(y - X\\boldsymbol{\\beta}) = \\frac{1}{2}(y^{\\top}y - 2\\boldsymbol{\\beta}^{\\top}X^{\\top}y + \\boldsymbol{\\beta}^{\\top}X^{\\top}X\\boldsymbol{\\beta})\n$$\n对 $\\boldsymbol{\\beta}$ 求梯度：\n$$\n\\nabla g(\\boldsymbol{\\beta}) = \\frac{1}{2}(-2X^{\\top}y + 2X^{\\top}X\\boldsymbol{\\beta}) = X^{\\top}X\\boldsymbol{\\beta} - X^{\\top}y\n$$\n使用给定条件 $X^{\\top}X = I_{p}$，梯度简化为：\n$$\n\\nabla g(\\boldsymbol{\\beta}) = \\boldsymbol{\\beta} - X^{\\top}y\n$$\n在最优点 $\\boldsymbol{\\beta}^{\\star}$ 处，梯度为 $\\nabla g(\\boldsymbol{\\beta}^{\\star}) = \\boldsymbol{\\beta}^{\\star} - X^{\\top}y$。\n\n接下来，我们刻画 $h(\\boldsymbol{\\beta}) = \\lambda \\|\\boldsymbol{\\beta}\\|_{1} = \\lambda \\sum_{j=1}^{p} |\\beta_j|$ 的次微分。次微分 $\\partial h(\\boldsymbol{\\beta})$ 是其各分量 $\\lambda |\\beta_j|$ 次微分的笛卡尔积。对于单个分量 $\\beta_j$，$\\lambda|\\beta_j|$ 的次微分是：\n$$\n\\partial (\\lambda |\\beta_j|) = \\begin{cases} \\{\\lambda \\cdot \\text{sgn}(\\beta_j)\\}  \\text{if } \\beta_j \\ne 0 \\\\ [-\\lambda, \\lambda]  \\text{if } \\beta_j = 0 \\end{cases}\n$$\n其中 $\\text{sgn}(\\cdot)$ 是符号函数。所以，$\\partial h(\\boldsymbol{\\beta})$ 由所有向量 $v \\in \\mathbb{R}^{p}$ 组成，其分量为 $v_j \\in \\partial (\\lambda |\\beta_j|)$。\n\n最优性条件 $\\mathbf{0} \\in \\nabla g(\\boldsymbol{\\beta}^{\\star}) + \\partial h(\\boldsymbol{\\beta}^{\\star})$ 现在可以写为：\n$$\n\\mathbf{0} \\in (\\boldsymbol{\\beta}^{\\star} - X^{\\top}y) + \\partial(\\lambda \\|\\boldsymbol{\\beta}^{\\star}\\|_{1})\n$$\n这等价于存在一个次梯度向量 $s \\in \\partial(\\|\\boldsymbol{\\beta}^{\\star}\\|_1)$，使得：\n$$\n\\mathbf{0} = (\\boldsymbol{\\beta}^{\\star} - X^{\\top}y) + \\lambda s\n$$\n重新整理得到平稳性条件：\n$$\nX^{\\top}y - \\boldsymbol{\\beta}^{\\star} = \\lambda s\n$$\n我们现在对 $j \\in \\{1, 2, \\dots, p\\}$ 逐分量分析这个条件，令 $c_j = (X^{\\top}y)_j$：\n$$\nc_j - \\beta^{\\star}_j = \\lambda s_j, \\quad \\text{where } s_j \\in \\partial|\\beta^{\\star}_j|\n$$\n\n我们按要求将此条件细化为两种情况。\n\n**情况 1：最优系数非零，$\\beta^{\\star}_j \\ne 0$。**\n在这种情况下， $|\\beta^{\\star}_j|$ 的次梯度是单值的：$s_j = \\text{sgn}(\\beta^{\\star}_j)$。该分量的平稳性条件变为：\n$$\nc_j - \\beta^{\\star}_j = \\lambda \\cdot \\text{sgn}(\\beta^{\\star}_j)\n$$\n求解 $\\beta^{\\star}_j$：\n$$\n\\beta^{\\star}_j = c_j - \\lambda \\cdot \\text{sgn}(\\beta^{\\star}_j)\n$$\n如果 $\\beta^{\\star}_j > 0$，则 $\\text{sgn}(\\beta^{\\star}_j) = 1$，这给出 $\\beta^{\\star}_j = c_j - \\lambda$。为保持一致性，需要 $c_j - \\lambda > 0$，所以 $c_j > \\lambda$。\n如果 $\\beta^{\\star}_j  0$，则 $\\text{sgn}(\\beta^{\\star}_j) = -1$，这给出 $\\beta^{\\star}_j = c_j + \\lambda$。为保持一致性，需要 $c_j + \\lambda  0$，所以 $c_j  -\\lambda$。\n在这两种子情况下，我们都有 $|c_j| > \\lambda$，并且 $\\beta^{\\star}_j$ 的符号与 $c_j$ 的符号相匹配。因此，我们可以写成 $\\text{sgn}(\\beta^{\\star}_j) = \\text{sgn}(c_j)$。非零系数的显式 KKT 条件是：\n$$\nc_j - \\beta^{\\star}_j = \\lambda \\cdot \\text{sgn}(c_j) \\quad \\text{or} \\quad \\beta^{\\star}_j = c_j - \\lambda \\cdot \\text{sgn}(c_j)\n$$\n\n**情况 2：最优系数为零，$\\beta^{\\star}_j = 0$。**\n在这种情况下，次梯度 $s_j$ 可以是区间 $[-1, 1]$ 内的任何值。该分量的平稳性条件是：\n$$\nc_j - 0 = \\lambda s_j \\quad \\text{for some } s_j \\in [-1, 1]\n$$\n这意味着 $c_j = \\lambda s_j$。由于 $s_j$ 可以在 $[-1, 1]$ 范围内取值，$c_j$ 必须位于区间 $[-\\lambda, \\lambda]$ 内。零系数的显式 KKT 条件是：\n$$\n|c_j| \\le \\lambda\n$$\n\n总而言之，从次梯度最优性准则推导出的 KKT 条件是：\n- 如果 $|(X^{\\top}y)_j| > \\lambda$，则 $\\beta^{\\star}_j = (X^{\\top}y)_j - \\lambda \\cdot \\text{sgn}((X^{\\top}y)_j)$。\n- 如果 $|(X^{\\top}y)_j| \\le \\lambda$，则 $\\beta^{\\star}_j = 0$。\n\n这个解被称为软阈值法，可以紧凑地写为 $\\beta^{\\star}_j = S_{\\lambda}((X^{\\top}y)_j)$，其中 $S_{\\lambda}(z) = \\text{sgn}(z)\\max(0, |z|-\\lambda)$。\n\n**任务 2：求解一个具体实例**\n\n我们给定一个三特征实例 ($p=3$)，$X^{\\top}X = I_3$ 且：\n$$\nX^{\\top}y = \\begin{pmatrix} 1.8 \\\\ -0.5 \\\\ 0.4 \\end{pmatrix}, \\qquad \\lambda = 0.6\n$$\n我们应用上面推导出的 KKT 条件来计算最优系数向量 $\\boldsymbol{\\beta}^{\\star}$ 的每个分量。令 $c = X^{\\top}y$。\n\n**对于分量 $j=1$：**\n$c_1 = 1.8$。我们将其绝对值与 $\\lambda$ 比较：\n$|c_1| = 1.8$。由于 $1.8 > 0.6$，我们处于 $|c_1| > \\lambda$ 的情况。\n最优系数非零，计算如下：\n$$\n\\beta^{\\star}_1 = c_1 - \\lambda \\cdot \\text{sgn}(c_1) = 1.8 - 0.6 \\cdot \\text{sgn}(1.8) = 1.8 - 0.6(1) = 1.2\n$$\n\n**对于分量 $j=2$：**\n$c_2 = -0.5$。我们将其绝对值与 $\\lambda$ 比较：\n$|c_2| = 0.5$。由于 $0.5 \\le 0.6$，我们处于 $|c_2| \\le \\lambda$ 的情况。\n最优系数为零：\n$$\n\\beta^{\\star}_2 = 0\n$$\n\n**对于分量 $j=3$：**\n$c_3 = 0.4$。我们将其绝对值与 $\\lambda$ 比较：\n$|c_3| = 0.4$。由于 $0.4 \\le 0.6$，我们处于 $|c_3| \\le \\lambda$ 的情况。\n最优系数为零：\n$$\n\\beta^{\\star}_3 = 0\n$$\n\n结合这些结果，最优系数向量是：\n$$\n\\boldsymbol{\\beta}^{\\star} = \\begin{pmatrix} 1.2 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n作为行向量，它是 $\\begin{pmatrix} 1.2  0  0 \\end{pmatrix}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1.2  0  0 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "我们已经知道，Lasso 的惩罚强度由超参数 $\\lambda$ 控制，但如何选择一个最优的 $\\lambda$ 值呢？在实际应用中，这是一个至关重要的步骤。本练习  模拟了一个完整的数据科学工作流程，指导你使用 k-折交叉验证（k-fold cross-validation）来评估不同 $\\lambda$ 值下的模型性能，从而找到在偏差和方差之间取得最佳平衡的模型。",
            "id": "1928609",
            "problem": "一位材料科学家正在开发一个预测模型，用于预测一种新型合金的热导率 $y$。该模型基于两种关键添加剂 $x_1$ 和 $x_2$ 的浓度。提出的模型是一个形式为 $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$ 的线性关系。为了防止过拟合并选择一个简约模型，该科学家决定使用最小绝对值收敛和选择算子 (LASSO) 回归技术。\n\nLASSO 的核心是调整参数 $\\lambda$，它控制着正则化的程度。$\\lambda$ 的最优值将通过 3 折交叉验证从集合 $\\{0.1, 1.0, 10.0\\}$ 中选择。该科学家收集了以下六个数据点：\n\n| 数据点 | $x_1$ | $x_2$ | $y$ |\n| :--- | :--- | :--- | :--- |\n| 1 | 1.0 | 0.0 | 1.5 |\n| 2 | 0.0 | 1.0 | 2.5 |\n| 3 | 2.0 | 1.0 | 4.0 |\n| 4 | 1.0 | 2.0 | 5.0 |\n| 5 | 3.0 | 2.0 | 6.5 |\n| 6 | 2.0 | 3.0 | 7.5 |\n\n3 折交叉验证的设置如下：\n- **第 1 折**：数据点 1, 2\n- **第 2 折**：数据点 3, 4\n- **第 3 折**：数据点 5, 6\n\n对于三次交叉验证迭代中的每一次，都会在其中的两折（训练集）上训练一个 LASSO 模型，然后用该模型对剩下的一折（验证集）进行预测。每次训练运行和每个 $\\lambda$ 值得到的模型系数 $(\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2)$ 如下所示：\n\n**在第 2 折和第 3 折上训练得到的系数（用于在第 1 折上验证）：**\n- 对于 $\\lambda=0.1$: $\\hat{\\beta}_0=1.35, \\hat{\\beta}_1=0.84, \\hat{\\beta}_2=1.26$\n- 对于 $\\lambda=1.0$: $\\hat{\\beta}_0=2.80, \\hat{\\beta}_1=0.00, \\hat{\\beta}_2=0.90$\n- 对于 $\\lambda=10.0$: $\\hat{\\beta}_0=5.75, \\hat{\\beta}_1=0.00, \\hat{\\beta}_2=0.00$\n\n**在第 1 折和第 3 折上训练得到的系数（用于在第 2 折上验证）：**\n- 对于 $\\lambda=0.1$: $\\hat{\\beta}_0=0.40, \\hat{\\beta}_1=1.33, \\hat{\\beta}_2=1.49$\n- 对于 $\\lambda=1.0$: $\\hat{\\beta}_0=1.13, \\hat{\\beta}_1=0.65, \\hat{\\beta}_2=1.55$\n- 对于 $\\lambda=10.0$: $\\hat{\\beta}_0=4.50, \\hat{\\beta}_1=0.00, \\hat{\\beta}_2=0.00$\n\n**在第 1 折和第 2 折上训练得到的系数（用于在第 3 折上验证）：**\n- 对于 $\\lambda=0.1$: $\\hat{\\beta}_0=0.60, \\hat{\\beta}_1=1.14, \\hat{\\beta}_2=1.56$\n- 对于 $\\lambda=1.0$: $\\hat{\\beta}_0=1.55, \\hat{\\beta}_1=0.40, \\hat{\\beta}_2=1.30$\n- 对于 $\\lambda=10.0$: $\\hat{\\beta}_0=3.25, \\hat{\\beta}_1=0.00, \\hat{\\beta}_2=0.00$\n\n你的任务是计算每个候选 $\\lambda$ 值的交叉验证误差。每一折的误差应使用均方误差 (MSE) 来衡量。对于给定的 $\\lambda$，总的交叉验证误差是三折的 MSE 的平均值。根据你的计算，以下哪个是调整参数 $\\lambda$ 的最优值？\n\nA. $0.1$\n\nB. $1.0$\n\nC. $10.0$\n\nD. 所有 $\\lambda$ 值导致的交叉验证误差都相同。",
            "solution": "我们将响应建模为 $\\hat{y}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1}x_{1}+\\hat{\\beta}_{2}x_{2}$。对于每一折和每个 $\\lambda$，我们在验证点上计算残差 $r_{i}=y_{i}-\\hat{y}_{i}$，并将该折的 MSE 计算为 $\\text{MSE}=\\frac{1}{n}\\sum r_{i}^{2}$，其中 $n=2$。对于给定的 $\\lambda$，交叉验证误差是三折 MSE 的平均值。\n\n第 1 折（在点 1 和 2 上验证；使用在第 2 折和第 3 折上训练得到的系数）：\n\n对于 $\\lambda=0.1$: $(\\hat{\\beta}_{0},\\hat{\\beta}_{1},\\hat{\\beta}_{2})=(1.35,0.84,1.26)$。\n- 点 1: $(x_{1},x_{2},y)=(1,0,1.5)$，$\\hat{y}=1.35+0.84\\cdot 1+1.26\\cdot 0=2.19$，$r=1.5-2.19=-0.69$，$r^{2}=0.4761$。\n- 点 2: $(0,1,2.5)$，$\\hat{y}=1.35+0.84\\cdot 0+1.26\\cdot 1=2.61$，$r=2.5-2.61=-0.11$，$r^{2}=0.0121$。\n$$\\text{MSE}_{1}(0.1)=\\frac{0.4761+0.0121}{2}=0.2441.$$\n\n对于 $\\lambda=1.0$: $(2.80,0.00,0.90)$。\n- 点 1: $\\hat{y}=2.80$，$r=-1.30$，$r^{2}=1.69$。\n- 点 2: $\\hat{y}=2.80+0.90=3.70$，$r=-1.20$，$r^{2}=1.44$。\n$$\\text{MSE}_{1}(1.0)=\\frac{1.69+1.44}{2}=1.565.$$\n\n对于 $\\lambda=10.0$: $(5.75,0.00,0.00)$。\n- 点 1: $\\hat{y}=5.75$，$r=-4.25$，$r^{2}=18.0625$。\n- 点 2: $\\hat{y}=5.75$，$r=-3.25$，$r^{2}=10.5625$。\n$$\\text{MSE}_{1}(10.0)=\\frac{18.0625+10.5625}{2}=14.3125.$$\n\n第 2 折（在点 3 和 4 上验证；使用在第 1 折和第 3 折上训练得到的系数）：\n\n对于 $\\lambda=0.1$: $(0.40,1.33,1.49)$。\n- 点 3: $(2,1,4.0)$，$\\hat{y}=0.40+1.33\\cdot 2+1.49\\cdot 1=4.55$，$r=-0.55$，$r^{2}=0.3025$。\n- 点 4: $(1,2,5.0)$，$\\hat{y}=0.40+1.33\\cdot 1+1.49\\cdot 2=4.71$，$r=0.29$，$r^{2}=0.0841$。\n$$\\text{MSE}_{2}(0.1)=\\frac{0.3025+0.0841}{2}=0.1933.$$\n\n对于 $\\lambda=1.0$: $(1.13,0.65,1.55)$。\n- 点 3: $\\hat{y}=1.13+0.65\\cdot 2+1.55\\cdot 1=3.98$，$r=0.02$，$r^{2}=0.0004$。\n- 点 4: $\\hat{y}=1.13+0.65\\cdot 1+1.55\\cdot 2=4.88$，$r=0.12$，$r^{2}=0.0144$。\n$$\\text{MSE}_{2}(1.0)=\\frac{0.0004+0.0144}{2}=0.0074.$$\n\n对于 $\\lambda=10.0$: $(4.50,0.00,0.00)$。\n- 点 3: $\\hat{y}=4.50$，$r=-0.50$，$r^{2}=0.25$。\n- 点 4: $\\hat{y}=4.50$，$r=0.50$，$r^{2}=0.25$。\n$$\\text{MSE}_{2}(10.0)=\\frac{0.25+0.25}{2}=0.25.$$\n\n第 3 折（在点 5 和 6 上验证；使用在第 1 折和第 2 折上训练得到的系数）：\n\n对于 $\\lambda=0.1$: $(0.60,1.14,1.56)$。\n- 点 5: $(3,2,6.5)$，$\\hat{y}=0.60+1.14\\cdot 3+1.56\\cdot 2=7.14$，$r=-0.64$，$r^{2}=0.4096$。\n- 点 6: $(2,3,7.5)$，$\\hat{y}=0.60+1.14\\cdot 2+1.56\\cdot 3=7.56$，$r=-0.06$，$r^{2}=0.0036$。\n$$\\text{MSE}_{3}(0.1)=\\frac{0.4096+0.0036}{2}=0.2066.$$\n\n对于 $\\lambda=1.0$: $(1.55,0.40,1.30)$。\n- 点 5: $\\hat{y}=1.55+0.40\\cdot 3+1.30\\cdot 2=5.35$，$r=1.15$，$r^{2}=1.3225$。\n- 点 6: $\\hat{y}=1.55+0.40\\cdot 2+1.30\\cdot 3=6.25$，$r=1.25$，$r^{2}=1.5625$。\n$$\\text{MSE}_{3}(1.0)=\\frac{1.3225+1.5625}{2}=1.4425.$$\n\n对于 $\\lambda=10.0$: $(3.25,0.00,0.00)$。\n- 点 5: $\\hat{y}=3.25$，$r=3.25$，$r^{2}=10.5625$。\n- 点 6: $\\hat{y}=3.25$，$r=4.25$，$r^{2}=18.0625$。\n$$\\text{MSE}_{3}(10.0)=\\frac{10.5625+18.0625}{2}=14.3125.$$\n\n计算每个 $\\lambda$ 的平均交叉验证误差：\n$$\\text{CV}(0.1)=\\frac{0.2441+0.1933+0.2066}{3}=0.214666\\ldots,$$\n$$\\text{CV}(1.0)=\\frac{1.565+0.0074+1.4425}{3}=1.004966\\ldots,$$\n$$\\text{CV}(10.0)=\\frac{14.3125+0.25+14.3125}{3}=9.625.$$\n\n最小的交叉验证误差出现在 $\\lambda=0.1$ 时，因此最优选择是选项 A。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}