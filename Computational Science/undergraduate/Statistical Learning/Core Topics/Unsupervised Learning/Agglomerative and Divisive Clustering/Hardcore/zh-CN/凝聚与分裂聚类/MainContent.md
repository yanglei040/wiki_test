## 引言
在数据科学中，聚类是将相似对象分组的关键[无监督学习](@entry_id:160566)技术。虽然像K-均值这样的划分方法在预先知道簇数时非常有效，但它们无法揭示数据中固有的、多层次的结构。[层次聚类](@entry_id:268536)填补了这一空白，它不产生单一的簇划分，而是构建一个嵌套的簇层次结构，为数据探索提供了更丰富、更具解释性的视角。这种方法使我们能够在不同的粒度级别上审视数据，从细粒度的个体分组到宏观的全局结构。

本文将系统地引导您了解[层次聚类](@entry_id:268536)的世界。在第一章“**原理与机制**”中，我们将深入探讨两种主要方法——“自下而上”的凝聚式聚类和“自上而下”的分裂式[聚类](@entry_id:266727)，并详细分析决定聚类结果的关键因素：连接标准。在第二章“**应用与跨学科连接**”中，我们将展示这些理论如何在生物信息学、自然语言处理、金融等多个领域中解决实际问题，揭示隐藏的模式。最后，在“**动手实践**”部分，您将通过具体的编码挑战，加深对核心概念的理解，例如[Ward方法](@entry_id:636890)的数学原理和不同连接方法的稳健性。通过这趟旅程，您将掌握有效应用[层次聚类](@entry_id:268536)来发现[数据结构](@entry_id:262134)的能力。

## 原理与机制

在前一章中，我们介绍了聚类的基本概念，即根据数据点之间的相似性将其分组。本章将深入探讨一类重要的[聚类算法](@entry_id:146720)——[层次聚类](@entry_id:268536)（Hierarchical Clustering）。与旨在将数据集划分为单个固定数量簇的[划分聚类](@entry_id:166920)（如K-均值）不同，[层次聚类](@entry_id:268536)构建了一个嵌套的簇层次结构，可以以[树状图](@entry_id:266792)（Dendrogram）的形式进行可视化。这种层次结构为数据探索提供了更丰富、更详细的视角。

[层次聚类](@entry_id:268536)主要分为两大类：凝聚式（Agglomerative）和分裂式（Divisive）。我们将系统地研究这两种方法的基本原理和核心机制。

### 凝聚式[层次聚类](@entry_id:268536) (Agglomerative Hierarchical Clustering)

凝聚式方法采用“自下而上”的策略。其算法过程直观而系统：

1.  **初始化**：将每个数据点视为一个独立的簇，因此初始时有 $N$ 个簇，其中 $N$ 是数据点的总数。
2.  **迭代合并**：在每一步中，找到最“相似”或“距离最近”的两个簇，并将它们合并成一个新的簇。
3.  **终止**：重复步骤2，直到所有数据点都合并到同一个簇中。

这个过程自然地生成了一个簇的层次结构，记录了从 $N$ 个簇到 1 个簇的完整合并序列。算法的核心在于如何定义不同簇之间的“距离”或“不相似性”。这个定义被称为**连接标准 (Linkage Criterion)**。

#### 连接标准：定义簇间距离

假设我们有两个簇 $A$ 和 $B$。如何量化它们之间的距离？不同的连接标准会导致不同的[聚类](@entry_id:266727)结果，每种标准都有其独特的行为和适用场景。

1.  **单一连接 (Single Linkage)**
    **单一连接**将两个簇之间的距离定义为它们之间所有点对距离的最小值。
    $$
    d_{\text{single}}(A, B) = \min_{x \in A, y \in B} d(x, y)
    $$
    其中 $d(x, y)$ 是点 $x$ 和 $y$ 之间的原始距离（例如，[欧几里得距离](@entry_id:143990)）。由于单一连接仅关注两个簇之间最近的一对点，它倾向于产生链状的、伸展的簇。这种行为被称为**链接效应 (Chaining Effect)**。在某些情况下，这可能是有益的，例如发现非凸形状的簇。然而，它也可能导致一种不良现象：仅仅因为少数几个“桥接”点的存在，两个在其他方面非常遥远的簇就被合并了。

    考虑一个场景：两个密集且间隔很远的大型点群，但在它们之间存在一小串间隔很近的“桥梁”点。单一连接算法在早期就会通过这些桥梁点将两个大[点群](@entry_id:142456)连接起来，而不是先形成两个完整的大簇。 这种对局部近邻的敏感性是单一连接最显著的特征。

2.  **完全连接 (Complete Linkage)**
    与单一连接相反，**完全连接**将两个簇之间的距离定义为它们之间所有点对距离的最大值。
    $$
    d_{\text{complete}}(A, B) = \max_{x \in A, y \in B} d(x, y)
    $$
    完全连接倾向于产生直径大致相等的紧凑、球状簇。因为它要求一个簇中的所有点都必须与另一个簇中的所有点相对接近，才会将它们合并。这种方法对异常值较为敏感。

3.  **平均连接 (Average Linkage)**
    **平均连接**试图在单一连接和完全连接之间找到一个[平衡点](@entry_id:272705)。它将簇间距离定义为两个簇之间所有点对距离的平均值。
    $$
    d_{\text{avg}}(A, B) = \frac{1}{|A| |B|} \sum_{x \in A} \sum_{y \in B} d(x, y)
    $$
    其中 $|A|$ 和 $|B|$ 分别是簇 $A$ 和 $B$ 的大小。平均连接不像单一连接那样容易受到单个点对的影响，也不像完全连接那样极端，因此通常表现得更为稳健。

4.  **Ward 方法 (Ward's Method)**
    Ward 方法采用了一种完全不同的、基于[方差](@entry_id:200758)的视角。它合并的是那些能使总簇内平方和（Within-cluster Sum of Squares, SSE）增加最小的两个簇。簇 $C$ 的 SSE 定义为：
    $$
    \mathrm{SSE}(C) = \sum_{x \in C} \|x - \mu_{C}\|^{2}
    $$
    其中 $\mu_{C}$ 是簇 $C$ 的质心（或均值）。当合并两个簇 $A$ 和 $B$ 时，总 SSE 的增加量 $\Delta(A, B)$ 可以被推导出来 。
    $$
    \Delta(A, B) = \mathrm{SSE}(A \cup B) - (\mathrm{SSE}(A) + \mathrm{SSE}(B))
    $$
    通过代数推导，可以证明这个增加量等于：
    $$
    \Delta(A, B) = \frac{|A| |B|}{|A| + |B|} \|\mu_{A} - \mu_{B}\|^{2}
    $$
    这个公式直观地解释了 Ward 方法的原理：它倾向于合并那些大小适中且质心相近的簇。合并后 SSE 的增加量既取决于两个簇质心之间的距离，也取决于它们的相对大小。这使得 Ward 方法倾向于产生大小相似的紧凑簇，并且在实践中表现非常出色。

#### 高效实现：Lance-Williams 更新公式

在凝聚式聚类的每一步，我们都需要更新[距离矩阵](@entry_id:165295)。如果每次合并后都从头计算所有新簇与其他簇的距离，计算成本会非常高。幸运的是，对于许多连接标准，存在一个高效的更新方法，即 **Lance-Williams 公式**。这个公式允许我们根据已有的簇间距离，直接计算新合并簇与其他簇的距离。

以平均连接为例，假设我们刚刚合并了簇 $A$ 和 $B$ 形成新簇 $A \cup B$。我们想要计算新簇与另一个簇 $C$ 之间的距离 $d_{\text{avg}}(A \cup B, C)$。从平均连接的定义出发 ：
$$
d_{\text{avg}}(A \cup B, C) = \frac{1}{|A \cup B| |C|} \sum_{x \in A \cup B} \sum_{y \in C} d(x, y)
$$
由于 $A$ 和 $B$ 不相交，求和可以分解：
$$
\sum_{x \in A \cup B} \sum_{y \in C} d(x, y) = \sum_{x \in A} \sum_{y \in C} d(x, y) + \sum_{x \in B} \sum_{y \in C} d(x, y)
$$
利用平均连接的定义，$\sum_{x \in A} \sum_{y \in C} d(x, y) = |A||C| d_{\text{avg}}(A, C)$，代入上式可得：
$$
d_{\text{avg}}(A \cup B, C) = \frac{1}{(|A|+|B|)|C|} \left( |A||C|d_{\text{avg}}(A, C) + |B||C|d_{\text{avg}}(B, C) \right)
$$
简化后得到更新公式：
$$
d_{\text{avg}}(A \cup B, C) = \frac{|A|}{|A|+|B|} d_{\text{avg}}(A, C) + \frac{|B|}{|A|+|B|} d_{\text{avg}}(B, C)
$$
这个公式表明，新簇与 $C$ 的距离是旧簇 $A, B$ 与 $C$ 距离的加权平均。单一连接、完全连接和 Ward 方法也都有类似的 Lance-Williams 形式，这使得凝聚式[聚类算法](@entry_id:146720)在计算上是可行的。

### 分裂式[层次聚类](@entry_id:268536) (Divisive Hierarchical Clustering)

分裂式方法采用“自上而下”的策略。其过程与凝聚式相反：

1.  **初始化**：所有数据点开始时都属于同一个大簇。
2.  **迭代分裂**：在每一步中，选择一个现有的簇并将其分裂成两个子簇。
3.  **终止**：重复步骤2，直到每个点都成为一个独立的簇，或达到某个终止条件。

分裂式[聚类](@entry_id:266727)的主要挑战在于分裂的两个方面：(1) 在每一步选择哪个簇进行分裂；(2) 如何将选定的簇分裂成两个子簇。这是一个比凝聚式合并更复杂的组合问题，因为将一个包含 $m$ 个点的簇分裂成两部分有 $2^{m-1}-1$ 种可能的方式。

因此，实际的分裂算法通常采用启发式策略。例如，一种常见的分裂方法（如 DIANA 算法中所使用的）如下 ：

1.  在要分裂的簇中，找到与其他所有点平均不相似度最高的点，这个点成为新“碎片”簇的“种子”。
2.  然后，迭代地检查旧簇中剩余的每个点。如果一个点到这个新碎片簇的平均距离小于它到剩余旧簇的平均距离，就将其移动到碎片簇中。
3.  重复此过程，直到没有点可以移动为止，从而完成一次分裂。

#### 凝聚式与分裂式的对比

凝聚式方法关注局部结构，因为它总是寻找最相似的对进行合并。这可能导致它在早期做出无法挽回的“贪婪”决策，而忽略了全局结构。例如，在上面提到的“桥接”数据集上，单一连接会过早地连接两个大簇 。

相比之下，分裂式方法从全局视角开始，首先处理数据中最显著的结构。例如，在面对两个空间上分离良好的大簇时，分裂式方法通常能正确地在第一步就将它们分开。一个有趣的例子是，当数据集包含一个紧凑的内圈和稀疏的外圈时，分裂式方法可能会首先识别出外圈中最“异常”的点并将其分离出来，而凝聚式的单一连接方法则可能因为局部距离近而将内圈点与某个外圈点“链接”起来 。这揭示了两种方法哲学的根本差异：凝聚式构建结构，而分裂式揭示结构。

### [树状图](@entry_id:266792)：可视化与解释

[层次聚类](@entry_id:268536)的结果通常用一种称为**[树状图](@entry_id:266792) (Dendrogram)** 的树形图来表示。

*   [树状图](@entry_id:266792)的叶子节点代表单个数据点。
*   内部节点代表一次合并事件。
*   一个内部节点的高度（通常在 y 轴上表示）代表其两个子簇被合并时的簇间距离（或不相似度）。

[树状图](@entry_id:266792)是一个功能强大的可视化工具。它不仅展示了最终的簇，还展示了簇是如何形成的。通过观察[树状图](@entry_id:266792)，我们可以了解数据点之间的相似性关系。合并高度较低的簇意味着它们的成员非常相似；而合并高度非常高的簇则表明它们非常不同。

#### 从层次到划分：切割[树状图](@entry_id:266792)

尽管[层次聚类](@entry_id:268536)提供了完整的层次结构，但在许多应用中，我们最终需要一个单一的、扁平的簇划分。这可以通过“切割”[树状图](@entry_id:266792)来实现。

有两种主要方法来切割[树状图](@entry_id:266792)：

1.  **按高度切割**：在[树状图](@entry_id:266792)上画一条水平线。这条线所穿过的所有分支都被切断。水平线以下的各个独立的树就是最终的簇。从算法角度看，这等同于忽略所有合并高度大于该切割高度 $h$ 的合并。对于单一连接，这相当于构建一个图，其中仅包含距离小于或等于 $h$ 的边，然后找出其连通分量 。

2.  **按簇数切割**：直接指定所需的簇数 $k$。算法会找到一个切割高度，使得恰好产生 $k$ 个簇。这在概念上等同于停止凝聚过程，使其恰好剩下 $k$ 个簇，或者等效地，撤销最后 $k-1$ 次合并 。

### 实践中的考量与评估

[层次聚类](@entry_id:268536)虽然强大，但在应用时需要仔细考虑几个关键问题。

#### 1. 如何选择最佳簇数 $k$？

[树状图](@entry_id:266792)本身并不能告诉我们“正确”的簇数是多少。我们需要外部标准来评估不同 $k$ 值下划分的质量。**[轮廓系数](@entry_id:754846) (Silhouette Coefficient)** 是一个广泛使用的度量。对于一个数据点 $i$，其[轮廓系数](@entry_id:754846) $s(i)$ 衡量了它与自己簇内其他点的紧密程度（内聚度）与它和最近的其他簇的分离程度（分离度）的对比。

$s(i)$ 的计算方式如下 ：
-   令 $a(i)$ 为点 $i$ 与其所在簇内所有其他点的平均距离。
-   令 $b(i)$ 为点 $i$ 与“下一个最近”簇中所有点的平均距离。
-   则[轮廓系数](@entry_id:754846)为：
    $$
    s(i) = \frac{b(i) - a(i)}{\max\{a(i), b(i)\}}
    $$
$s(i)$ 的取值范围为 $[-1, 1]$。值接近 1 表示点 $i$ 被很好地[聚类](@entry_id:266727)；值接近 0 表示点位于两个簇的边界上；值接近 -1 表示点可能被分到了错误的簇。

我们可以通过对整个数据集的所有点的 $s(i)$ 取平均，得到一个给定划分（例如，通过切割[树状图](@entry_id:266792)得到的 $k$ 个簇）的**平均轮廓分数** $\bar{s}(k)$。一个实用的策略是，为一系列可能的 $k$ 值（例如，从 $k=2$ 到某个上限）计算平均轮廓分数，然后选择使 $\bar{s}(k)$ 最大化的 $k$ 作为最佳簇数。

#### 2. 如何评估层次结构本身的质量？

除了评估特定切割产生的划分外，我们可能还想评估整个[树状图](@entry_id:266792)与原始数据相似性的匹配程度。**共表型[相关系数](@entry_id:147037) (Cophenetic Correlation Coefficient)** 就是为此设计的。

首先，我们定义**[共表型距离](@entry_id:637200) (Cophenetic Distance)** $d_c(i, j)$，即在[树状图](@entry_id:266792)中，点 $i$ 和点 $j$ 首次被合并到同一个簇时的高度。这个距离完全由层次结构决定。然后，我们计算所有点对的原始距离向量 $\vec{d}$ 和[共表型距离](@entry_id:637200)向量 $\vec{d}_c$ 之间的[皮尔逊相关系数](@entry_id:270276)。这个相关系数就是共表型相关系数。

一个接近 1 的值表示[树状图](@entry_id:266792)很好地保留了原始点对之间的相似性。这个系数可以用来比较不同连接标准（如单一、完全、平均连接）在同一数据集上产生的层次结构的保真度 。

#### 3. 算法的敏感性

[层次聚类](@entry_id:268536)对输入和参数的选择非常敏感，理解这些敏感性对于正确使用该方法至关重要。

*   **[特征缩放](@entry_id:271716)**：由于大多数连接标准都基于[距离度量](@entry_id:636073)（如[欧几里得距离](@entry_id:143990)），算法对特征的缩放非常敏感。如果一个特征的[数值范围](@entry_id:752817)远大于其他特征，它将在距离计算中占据主导地位，可能会扭曲[聚类](@entry_id:266727)结果。例如，将一个特征的尺度乘以一个因子 $\alpha$，等同于使用一个加权的欧几里得距离，这会改变点对之间的相对距离，从而可能改变合并的顺序和最终的层次结构 。因此，在进行[层次聚类](@entry_id:268536)之前，对数据进行标准化（例如，缩放到均值为0，[方差](@entry_id:200758)为1）通常是一个至关重要的[预处理](@entry_id:141204)步骤。

*   **簇密度差异**：标准连接方法对簇的密度变化也很敏感。例如，单一连接可能会被一个稀疏的“桥梁”区域所吸引，而忽略了连接两个高密度区域可能更合理。可以设计**密度感知 (Density-aware)** 的连接标准来缓解这个问题。例如，我们可以通过将标准距离除以相关簇的[密度估计](@entry_id:634063)来惩罚与稀疏簇的合并 。

*   **非度量不相似性与平局处理**：虽然我们通常使用度量（满足三角不等式）作为距离，但[层次聚类](@entry_id:268536)算法本身也可以应用于任何对称的不相似性矩阵。即使不满足[三角不等式](@entry_id:143750)，标准的凝聚式方法（如单一、完全、平均连接）仍然保证生成一个单调的[树状图](@entry_id:266792)（即合并高度不会下降）。然而，当出现平局（即多个点对具有相同的最小距离）时，**平局处理策略 (Tie-breaking policy)** 会变得很重要。不同的策略可能导致不同的合并序列，从而产生不同的[树状图](@entry_id:266792)。有趣的是，对于单一连接，虽然不同的平局处理策略可能改变[树状图](@entry_id:266792)的精确拓扑结构，但通过在特定高度 $h$ 切割所产生的划分却是唯一的，因为它仅取决于距离小于等于 $h$ 的所有点对 。然而，如果我们的目标是获得一个固定数量为 $k$ 的簇（即停止在第 $N-k$ 次合并后），那么结果就可能依赖于平局处理策略了。

总之，[层次聚类](@entry_id:268536)提供了一套强大而灵活的工具来探索数据中的结构。通过理解不同连接标准的行为、[树状图](@entry_id:266792)的解释方式、评估层次结构质量的方法以及算法对各种因素的敏感性，我们可以更有效地应用这些技术来揭示数据中隐藏的模式。