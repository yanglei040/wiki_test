{
    "hands_on_practices": [
        {
            "introduction": "在回归分析中，t统计量是检验系数显著性的基石。这个练习提供了一个具体的生态学场景，让你能够实践t统计量的基本计算。通过这个练习，你将学会如何利用估计的效应大小（即回归系数 $\\hat{\\beta}_1$）及其不确定性（即标准误 $SE(\\hat{\\beta}_1)$）来量化自变量与因变量之间线性关系的证据强度。",
            "id": "1955459",
            "problem": "一位环境科学家正在研究湖中某种特定污染物对某种藻类种群密度的影响。从不同位置收集水样，并对每个样本测量污染物的浓度（单位：微克/升）和藻类的密度（单位：细胞/毫升）。\n\n该科学家将数据拟合到一个简单线性回归模型 $Y = \\beta_0 + \\beta_1 X + \\epsilon$ 中，其中 $Y$ 代表藻类密度，$X$ 代表污染物浓度。对收集的数据进行分析，得到估计的斜率系数为 $\\hat{\\beta}_1 = -18.4$。与此斜率估计值相关的标准误差为 $SE(\\hat{\\beta}_1) = 5.25$。\n\n为了评估污染物浓度和藻类密度之间是否存在统计上显著的线性关系，进行了一项假设检验。计算用于检验真实斜率系数 $\\beta_1$ 为零的原假设的 t-统计量的值。答案请四舍五入保留三位有效数字。",
            "solution": "我们检验原假设 $H_{0}:\\beta_{1}=0$ 与备择假设 $\\beta_{1}\\neq 0$。简单线性回归中斜率的检验统计量为\n$$\nt=\\frac{\\hat{\\beta}_{1}-\\beta_{1,0}}{SE(\\hat{\\beta}_{1})},\n$$\n其中 $\\beta_{1,0}$ 是 $H_{0}$ 下的假设值。当 $\\beta_{1,0}=0$，$\\hat{\\beta}_{1}=-18.4$ 且 $SE(\\hat{\\beta}_{1})=5.25$ 时，我们有\n$$\nt=\\frac{-18.4-0}{5.25}=-\\frac{18.4}{5.25}\\approx -3.5047619\\ldots\n$$\n四舍五入保留三位有效数字，得到 $t\\approx -3.50$。",
            "answer": "$$\\boxed{-3.50}$$"
        },
        {
            "introduction": "掌握了基本计算后，我们来探讨一个更深层次的概念：t统计量的不变性。这个思想实验将探究当我们对预测变量进行线性变换（例如，标准化）时，回归系数及其t统计量会发生什么变化。通过证明t统计量在这种变换下保持不变，我们能更深刻地理解它为何是一个标准化的、独立于度量单位的证据度量。",
            "id": "3131042",
            "problem": "考虑含截距的简单线性回归，其中一个大小为 $n \\ge 3$ 的数据集由数据对 $\\{(x_i, y_i)\\}_{i=1}^n$ 组成，模型为 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$。假设误差 $\\varepsilon_i$ 满足通常的 Gauss–Markov 条件（独立，均值为 $0$，共同方差为 $\\sigma^2$），并且，为保证 Student’s $t$ 检验的有效性，$\\varepsilon_i$ 服从正态分布。令 $\\bar x = \\frac{1}{n}\\sum_{i=1}^n x_i$ 并定义样本标准差 $s_x = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar x)^2}$。考虑变换后的预测变量 $z_i = \\frac{x_i - \\bar x}{s_x}$，并使用普通最小二乘法 (OLS) 拟合模型 $y_i = \\tilde\\beta_0 + \\tilde\\beta_1 z_i + \\varepsilon_i$。\n\n令 $\\hat\\beta_1$ 表示使用预测变量 $x$ 的原始模型中 $\\beta_1$ 的 OLS 估计量，并令 $\\hat\\beta_1^{(z)}$ 表示使用预测变量 $z$ 的标准化模型中斜率的 OLS 估计量。令 $t_1$ 为基于原始模型检验 $H_0:\\beta_1=0$ 的 OLS $t$ 统计量，并令 $t_1^{(z)}$ 为标准化模型中相应的 $t$ 统计量。\n\n哪个陈述最能描述 $\\hat\\beta_1$、$\\hat\\beta_1^{(z)}$、$t_1$ 和 $t_1^{(z)}$ 之间的关系？\n\nA. $\\hat\\beta_1^{(z)} = s_x \\hat\\beta_1$ 且 $t_1^{(z)} = t_1$。\n\nB. $\\hat\\beta_1^{(z)} = \\hat\\beta_1/s_x$ 且 $t_1^{(z)} = t_1$。\n\nC. $\\hat\\beta_1^{(z)} = s_x \\hat\\beta_1$ 且 $t_1^{(z)} = s_x \\, t_1$。\n\nD. $\\hat\\beta_1^{(z)} = \\hat\\beta_1$ 且 $t_1^{(z)} = t_1$。",
            "solution": "在进行解答之前，将对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n- **模型 1 (原始)**: $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$, $i=1, \\dots, n$。\n- **数据集**: $\\{(x_i, y_i)\\}_{i=1}^n$, 样本大小为 $n \\ge 3$。\n- **误差假设**: $\\varepsilon_i$ 是独立同分布 (i.i.d.) 的正态随机变量，其均值 $E[\\varepsilon_i]=0$，共同方差 $Var(\\varepsilon_i)=\\sigma^2$。这包含了 Gauss-Markov 条件及正态性假设。\n- **定义**:\n    - $x$ 的样本均值: $\\bar x = \\frac{1}{n}\\sum_{i=1}^n x_i$。\n    - $x$ 的样本标准差: $s_x = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar x)^2}$。这里隐含假设并非所有的 $x_i$ 都相同，因此 $s_x > 0$。\n- **变换**: $z_i = \\frac{x_i - \\bar x}{s_x}$。\n- **模型 2 (标准化)**: $y_i = \\tilde\\beta_0 + \\tilde\\beta_1 z_i + \\varepsilon_i$。\n- **关注的量**:\n    - $\\hat\\beta_1$: 模型 1 中 $\\beta_1$ 的普通最小二乘 (OLS) 估计量。\n    - $\\hat\\beta_1^{(z)}$: 模型 2 中 $\\tilde\\beta_1$ 的 OLS 估计量。\n    - $t_1$: 模型 1 中用于检验原假设 $H_0: \\beta_1 = 0$ 的 OLS $t$ 统计量。\n    - $t_1^{(z)}$: 模型 2 中用于检验原假设 $H_0: \\tilde\\beta_1 = 0$ 的 OLS $t$ 统计量。\n- **问题**: 描述 $\\hat\\beta_1$、$\\hat\\beta_1^{(z)}$、$t_1$ 和 $t_1^{(z)}$ 之间的关系。\n\n### 步骤 2：使用提取的已知条件进行验证\n- **科学依据**: 该问题在线性回归理论中有充分的依据，这是统计学和统计学习中的一个核心课题。所有概念，包括 OLS 估计、变量标准化以及使用 $t$ 统计量进行假设检验，都是标准的且被严格定义的。\n- **适定性**: 该问题是适定的。从 $x$ 到 $z$ 的变换是明确的。估计量和检验统计量之间的关系可以从 OLS 回归的第一性原理唯一地推导出来。条件 $n \\ge 3$ 确保了模型误差方差估计的自由度 $n-2$ 至少为 $1$，这是 $t$ 统计量有良好定义的必要条件。\n- **客观性**: 该问题以客观的数学语言陈述，没有歧义或主观性。\n\n### 步骤 3：结论和行动\n问题陈述是有效的。这是统计理论中一个标准的、适定的问题。将推导求解。\n\n### 推导\n求解过程需要推导两个模型中斜率估计量和 $t$ 统计量之间的关系。\n\n**第一部分：$\\hat\\beta_1$ 和 $\\hat\\beta_1^{(z)}$ 之间的关系**\n\n在响应变量 $Y$ 对预测变量 $X$ 的简单线性回归中，斜率系数的 OLS 估计量由以下公式给出：\n$$ \\hat\\beta_{slope} = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2} $$\n对于原始模型（模型 1），预测变量是 $x$，$\\beta_1$ 的 OLS 估计量为：\n$$ \\hat\\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar x)(y_i - \\bar y)}{\\sum_{i=1}^n (x_i - \\bar x)^2} $$\n对于标准化模型（模型 2），预测变量是 $z$。我们首先求出 $z$ 的样本均值和离差平方和。\n$z$ 的样本均值为：\n$$ \\bar z = \\frac{1}{n}\\sum_{i=1}^n z_i = \\frac{1}{n}\\sum_{i=1}^n \\frac{x_i - \\bar x}{s_x} = \\frac{1}{n s_x} \\left( \\sum_{i=1}^n x_i - n\\bar x \\right) = \\frac{1}{n s_x} (n\\bar x - n\\bar x) = 0 $$\n$z$ 的离差平方和为：\n$$ \\sum_{i=1}^n (z_i - \\bar z)^2 = \\sum_{i=1}^n (z_i - 0)^2 = \\sum_{i=1}^n z_i^2 = \\sum_{i=1}^n \\left( \\frac{x_i - \\bar x}{s_x} \\right)^2 $$\n根据定义 $s_x^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar x)^2$，我们有 $\\sum_{i=1}^n (x_i - \\bar x)^2 = (n-1)s_x^2$。\n代入此式，我们得到：\n$$ \\sum_{i=1}^n (z_i - \\bar z)^2 = \\frac{1}{s_x^2} \\sum_{i=1}^n (x_i - \\bar x)^2 = \\frac{(n-1)s_x^2}{s_x^2} = n-1 $$\n现在我们可以写出模型 2 中斜率 $\\tilde\\beta_1$ 的 OLS 估计量，记为 $\\hat\\beta_1^{(z)}$：\n$$ \\hat\\beta_1^{(z)} = \\frac{\\sum_{i=1}^n (z_i - \\bar z)(y_i - \\bar y)}{\\sum_{i=1}^n (z_i - \\bar z)^2} = \\frac{\\sum_{i=1}^n z_i (y_i - \\bar y)}{n-1} $$\n代入 $z_i = \\frac{x_i - \\bar x}{s_x}$：\n$$ \\hat\\beta_1^{(z)} = \\frac{\\sum_{i=1}^n \\frac{x_i - \\bar x}{s_x} (y_i - \\bar y)}{n-1} = \\frac{1}{(n-1)s_x} \\sum_{i=1}^n (x_i - \\bar x)(y_i - \\bar y) $$\n从 $\\hat\\beta_1$ 的公式中，我们可以将分子中的交叉乘积和表示为 $\\sum_{i=1}^n (x_i - \\bar x)(y_i - \\bar y) = \\hat\\beta_1 \\sum_{i=1}^n (x_i - \\bar x)^2 = \\hat\\beta_1 (n-1)s_x^2$。\n将此代入 $\\hat\\beta_1^{(z)}$ 的表达式中：\n$$ \\hat\\beta_1^{(z)} = \\frac{1}{(n-1)s_x} \\left( \\hat\\beta_1 (n-1)s_x^2 \\right) = s_x \\hat\\beta_1 $$\n这就建立了第一个关系：$\\hat\\beta_1^{(z)} = s_x \\hat\\beta_1$。\n\n**第二部分：$t_1$ 和 $t_1^{(z)}$ 之间的关系**\n\n斜率系数的 $t$ 统计量是估计系数与其标准误的比值。\n$$ t_1 = \\frac{\\hat\\beta_1}{\\text{SE}(\\hat\\beta_1)} \\quad \\text{和} \\quad t_1^{(z)} = \\frac{\\hat\\beta_1^{(z)}}{\\text{SE}(\\hat\\beta_1^{(z)})} $$\n斜率估计的标准误由 $\\text{SE}(\\hat\\beta_{slope}) = \\sqrt{\\frac{\\hat\\sigma^2}{\\sum (X_i - \\bar{X})^2}}$ 给出，其中 $\\hat\\sigma^2$ 是误差方差 $\\sigma^2$ 的无偏估计量。\n\n我们首先证明两个模型的估计误差方差是相同的。估计量 $\\hat\\sigma^2$ 是从残差平方和 (RSS) 计算得出的：$\\hat\\sigma^2 = \\frac{\\text{RSS}}{n-2}$。\n对于模型 1，拟合值为 $\\hat y_i = \\hat\\beta_0 + \\hat\\beta_1 x_i$。OLS 截距为 $\\hat\\beta_0 = \\bar y - \\hat\\beta_1 \\bar x$。因此，\n$$ \\hat y_i = (\\bar y - \\hat\\beta_1 \\bar x) + \\hat\\beta_1 x_i = \\bar y + \\hat\\beta_1(x_i - \\bar x) $$\n对于模型 2，拟合值为 $\\hat y_i^{(z)} = \\hat{\\tilde\\beta}_0 + \\hat\\beta_1^{(z)} z_i$。OLS 截距为 $\\hat{\\tilde\\beta}_0 = \\bar y - \\hat\\beta_1^{(z)} \\bar z$。由于 $\\bar z = 0$，我们有 $\\hat{\\tilde\\beta}_0 = \\bar y$。因此，\n$$ \\hat y_i^{(z)} = \\bar y + \\hat\\beta_1^{(z)} z_i $$\n现在，代入关系式 $\\hat\\beta_1^{(z)} = s_x \\hat\\beta_1$ 和 $z_i = \\frac{x_i - \\bar x}{s_x}$：\n$$ \\hat y_i^{(z)} = \\bar y + (s_x \\hat\\beta_1) \\left( \\frac{x_i - \\bar x}{s_x} \\right) = \\bar y + \\hat\\beta_1(x_i - \\bar x) $$\n我们看到 $\\hat y_i^{(z)} = \\hat y_i$。两个模型的拟合值是相同的。因此，残差 $e_i = y_i - \\hat y_i$ 也相同，RSS 相同，估计的误差方差也相同。我们将其对两个模型都记为 $\\hat\\sigma^2$。\n\n现在，我们可以计算标准误。\n对于模型 1：\n$$ \\text{SE}(\\hat\\beta_1) = \\sqrt{\\frac{\\hat\\sigma^2}{\\sum_{i=1}^n (x_i - \\bar x)^2}} = \\frac{\\hat\\sigma}{\\sqrt{(n-1)s_x^2}} = \\frac{\\hat\\sigma}{s_x \\sqrt{n-1}} $$\n$t$ 统计量为：\n$$ t_1 = \\frac{\\hat\\beta_1}{\\text{SE}(\\hat\\beta_1)} = \\frac{\\hat\\beta_1 s_x \\sqrt{n-1}}{\\hat\\sigma} $$\n对于模型 2：\n$$ \\text{SE}(\\hat\\beta_1^{(z)}) = \\sqrt{\\frac{\\hat\\sigma^2}{\\sum_{i=1}^n (z_i - \\bar z)^2}} = \\sqrt{\\frac{\\hat\\sigma^2}{n-1}} = \\frac{\\hat\\sigma}{\\sqrt{n-1}} $$\n$t$ 统计量为：\n$$ t_1^{(z)} = \\frac{\\hat\\beta_1^{(z)}}{\\text{SE}(\\hat\\beta_1^{(z)})} = \\frac{s_x \\hat\\beta_1}{\\hat\\sigma / \\sqrt{n-1}} = \\frac{\\hat\\beta_1 s_x \\sqrt{n-1}}{\\hat\\sigma} $$\n比较最终的表达式，我们发现 $t_1^{(z)} = t_1$。\n\n*t-统计量的另一种推导方法：*\n在简单线性回归中，检验斜率显著性的 $t$ 统计量也可以用预测变量和响应变量之间的 Pearson 相关系数 $r$ 来表示：\n$$ t = \\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}} $$\nPearson 相关系数对两个变量各自的线性变换是不变的。也就是说，如果 $X' = aX+b$ 且 $Y' = cY+d$，那么 $|\\text{Corr}(X', Y')| = |\\text{Corr}(X, Y)|$。如果 $a$ 和 $c$ 同号，则 $\\text{Corr}(X', Y') = \\text{Corr}(X, Y)$。\n在我们的例子中，响应变量 $y$ 没有改变。预测变量通过 $z_i = \\frac{1}{s_x} x_i - \\frac{\\bar x}{s_x}$ 从 $x$ 变换到 $z$。这是一个线性变换，其缩放因子 $\\frac{1}{s_x}$ 为正（因为 $s_x > 0$）。因此，$z$ 和 $y$ 之间的相关性与 $x$ 和 $y$ 之间的相关性相同：\n$$ r_{zy} = \\text{Corr}(z, y) = \\text{Corr}(x, y) = r_{xy} $$\n由于 $t$ 统计量仅取决于样本大小 $n$ 和相关系数 $r$，且这两者对于两个模型都是相同的，因此 $t$ 统计量本身也必须相同。\n$$ t_1 = \\frac{r_{xy}\\sqrt{n-2}}{\\sqrt{1-r_{xy}^2}} = \\frac{r_{zy}\\sqrt{n-2}}{\\sqrt{1-r_{zy}^2}} = t_1^{(z)} $$\n两种推导方法都证实了 $t_1^{(z)} = t_1$。\n\n总结一下：\n- $\\hat\\beta_1^{(z)} = s_x \\hat\\beta_1$\n- $t_1^{(z)} = t_1$\n\n### 逐项分析\n\n**A. $\\hat\\beta_1^{(z)} = s_x \\hat\\beta_1$ 且 $t_1^{(z)} = t_1$。**\n- 第一部分 $\\hat\\beta_1^{(z)} = s_x \\hat\\beta_1$ 与我们的推导一致。\n- 第二部分 $t_1^{(z)} = t_1$ 也与我们的推导一致。\n- 此陈述**正确**。\n\n**B. $\\hat\\beta_1^{(z)} = \\hat\\beta_1/s_x$ 且 $t_1^{(z)} = t_1$。**\n- 第一部分 $\\hat\\beta_1^{(z)} = \\hat\\beta_1/s_x$ 与我们发现的 $\\hat\\beta_1^{(z)} = s_x \\hat\\beta_1$ 相矛盾。这仅在 $s_x^2=1$ 时成立，而通常情况并非如此。\n- 因此，该陈述**不正确**。\n\n**C. $\\hat\\beta_1^{(z)} = s_x \\hat\\beta_1$ 且 $t_1^{(z)} = s_x \\, t_1$。**\n- 第二部分 $t_1^{(z)} = s_x \\, t_1$ 与我们发现的 $t_1^{(z)} = t_1$ 相矛盾。这仅在 $s_x=1$ 时成立。\n- 因此，该陈述**不正确**。\n\n**D. $\\hat\\beta_1^{(z)} = \\hat\\beta_1$ 且 $t_1^{(z)} = t_1$。**\n- 第一部分 $\\hat\\beta_1^{(z)} = \\hat\\beta_1$ 与我们发现的 $\\hat\\beta_1^{(z)} = s_x \\hat\\beta_1$ 相矛盾。这仅在 $s_x=1$ 时成立。\n- 因此，该陈述**不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在多元回归中，一个常见且棘手的问题是多重共线性，即预测变量之间高度相关。这个练习剖析了多重共线性如何影响t检验的结果，解释了为何我们有时会观察到模型整体拟合度很高（高 $R^2$），但单个系数的t统计量却不显著。理解共线性如何夸大系数估计的标准误，是正确解读回归结果和避免错误结论的关键一步。",
            "id": "3131116",
            "problem": "考虑多元线性回归模型 $Y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\varepsilon$，其中 $\\varepsilon \\sim \\text{independent and identically distributed } \\mathcal{N}(0,\\sigma^2)$，且预测变量经过中心化，因此 $\\sum_{i=1}^{n} x_{1i} = 0$ 和 $\\sum_{i=1}^{n} x_{2i} = 0$。假设设计存在近似共线性，即 $x_2 = x_1 + \\delta$，其中 $\\delta$ 是一个均值为0的扰动，独立于 $x_1$，其方差 $\\operatorname{Var}(\\delta) = \\tau^2$ 相对于 $\\operatorname{Var}(x_1) = v_1  0$ 很小。从普通最小二乘法的基本原理和高斯线性模型下的抽样分布出发（特别是普通最小二乘估计量 $\\hat{\\beta} = (X^\\top X)^{-1} X^\\top Y$ 的定义、其协方差 $\\operatorname{Var}(\\hat{\\beta}) = \\sigma^2 (X^\\top X)^{-1}$ 以及正交投影的作用），分析近似共线性如何影响 $\\hat{\\beta}_2$ 的标准误以及对 $H_0:\\beta_2=0$ 的 $t$ 检验。\n\n在此设置下，以下哪些陈述是正确的？选择所有适用项。\n\nA. 在这种 $x_2 = x_1 + \\delta$ 且预测变量中心化的构造中，$\\hat{\\beta}_2$ 的抽样方差等于 $\\sigma^2 \\big/ \\big(n\\, \\operatorname{Var}(\\delta)\\big)$，因此当 $\\tau^2 \\to 0$ 时，它会发散。\n\nB. 将 $\\operatorname{Var}(\\hat{\\beta}_2)$ 与单变量回归方差联系起来的方差膨胀因子是 $(1 - R_2^2)^{-1}$，其中 $R_2^2$ 来自将 $x_2$ 对 $x_1$ 进行回归。在此设置中，$R_2^2 = v_1/(v_1+\\tau^2)$，所以膨胀因子等于 $(v_1+\\tau^2)/\\tau^2$，并且当 $\\tau^2 \\to 0$ 时无界增长。\n\nC. 由于 $x_1$ 的作用，模型的 $R^2$ 可以任意接近于 $1$，而对 $H_0:\\beta_2=0$ 的检验却得出很小的 $|t_2|$，因为只有 $x_2$ 正交于 $x_1$ 的分量（即 $\\delta$）为 $\\beta_2$ 提供信息，且其方差很小。\n\nD. 因为当添加更多预测变量时，残差标准误 $s$ 会减小，所以当 $x_2$ 被添加到已包含 $x_1$ 的模型中时，$|t_2|$ 必须增加。\n\nE. 近似共线性会导致 $\\hat{\\beta}_2$ 产生朝向 $0$ 的偏差，这是即使 $R^2$ 很大，$|t_2|$ 也很小的主要原因。",
            "solution": "用户想要对近似共线性条件下的多元线性回归模型进行详细分析。\n\n### 问题验证\n\n**第一步：提取已知条件**\n-   **模型：** $Y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\varepsilon$\n-   **误差分布：** $\\varepsilon$ 独立同分布（i.i.d.）于 $\\mathcal{N}(0,\\sigma^2)$。\n-   **预测变量中心化：** $\\sum_{i=1}^{n} x_{1i} = 0$ 和 $\\sum_{i=1}^{n} x_{2i} = 0$。\n-   **共线性结构：** $x_2 = x_1 + \\delta$。\n-   **扰动性质：** $\\delta$ 是一个均值为0的扰动，独立于 $x_1$，其方差 $\\operatorname{Var}(\\delta) = \\tau^2$ 相对于 $\\operatorname{Var}(x_1) = v_1  0$ 很小。\n-   **OLS 估计量：** $\\hat{\\beta} = (X^\\top X)^{-1} X^\\top Y$。\n-   **OLS 估计量的协方差：** $\\operatorname{Var}(\\hat{\\beta}) = \\sigma^2 (X^\\top X)^{-1}$。\n-   **任务：** 分析近似共线性对 $\\hat{\\beta}_2$ 的标准误以及对 $H_0: \\beta_2 = 0$ 的 $t$ 检验的影响。\n\n**第二步：使用提取的已知条件进行验证**\n问题陈述描述了统计学和计量经济学中用于说明多重共线性后果的典型情景。\n-   **科学依据：** 该设置基于标准高斯线性模型和普通最小二乘估计理论。所有概念都是统计学习的基础。\n-   **问题适定性：** 问题定义明确。它要求在指定模型内分析估计量的性质。所提供的条件足以进行此分析。\n-   **客观性：** 语言是形式化和数学化的，没有主观内容。\n-   **一致性检查：** 中心化条件 $\\sum x_{1i} = 0$ 和 $\\sum x_{2i} = 0$ 与 $x_{2i} = x_{1i} + \\delta_i$ 相结合，意味着 $\\sum (x_{1i} + \\delta_i) = 0$，从而得出 $\\sum \\delta_i = 0$。这与 $\\delta$ 是一个均值为0的扰动是一致的。该设置内部是一致的。\n\n**第三步：结论与行动**\n问题是有效的。我将继续推导解决方案。\n\n### 从基本原理推导\n\n问题的核心在于理解 OLS 估计量 $\\hat{\\beta}_2$ 的方差。题目要求我们从基本原理出发，包括正交投影的思想。Frisch-Waugh-Lovell (FWL) 定理是这里的相关原理。该定理指出，多元回归中的系数 $\\hat{\\beta}_2$ 与将 $Y$ 对 $x_1$ 回归所得的残差向量 $Y_{\\perp 1}$ 对将 $x_2$ 对 $x_1$ 回归所得的残差向量 $x_{2, \\perp 1}$ 进行简单回归得到的系数是相同的。\n\n$\\hat{\\beta}_2$ 的方差由下式给出：\n$$ \\operatorname{Var}(\\hat{\\beta}_2) = \\frac{\\sigma^2}{\\|\\mathbf{x}_{2, \\perp 1}\\|^2} $$\n其中 $\\|\\mathbf{x}_{2, \\perp 1}\\|^2 = \\sum_{i=1}^n (x_{2i, \\perp 1})^2$ 是将 $\\mathbf{x}_2$ 对 $\\mathbf{x}_1$ 回归所得的残差平方和。\n\n我们来计算这些残差。模型是 $\\mathbf{x}_2 = \\gamma_1 \\mathbf{x}_1 + \\text{error}$。由于预测变量是中心化的，截距为 $0$。$\\gamma_1$ 的 OLS 估计是 $\\hat{\\gamma}_1 = (\\mathbf{x}_1^\\top \\mathbf{x}_1)^{-1} \\mathbf{x}_1^\\top \\mathbf{x}_2$。残差向量是 $\\mathbf{x}_{2, \\perp 1} = \\mathbf{x}_2 - \\hat{\\gamma}_1 \\mathbf{x}_1$。\n使用问题中的定义 $\\mathbf{x}_2 = \\mathbf{x}_1 + \\mathbf{\\delta}$：\n$$ \\mathbf{x}_{2, \\perp 1} = (\\mathbf{x}_1 + \\mathbf{\\delta}) - \\hat{\\gamma}_1 \\mathbf{x}_1 $$\n等等，使用投影矩阵的公式更简单。设 $P_1$ 是到由 $\\mathbf{x}_1$ 张成的空间的投影矩阵。那么 $\\mathbf{x}_{2, \\perp 1} = (I - P_1)\\mathbf{x}_2$。\n代入 $\\mathbf{x}_2 = \\mathbf{x}_1 + \\mathbf{\\delta}$：\n$$ \\mathbf{x}_{2, \\perp 1} = (I - P_1)(\\mathbf{x}_1 + \\mathbf{\\delta}) = (I - P_1)\\mathbf{x}_1 + (I - P_1)\\mathbf{\\delta} = \\mathbf{0} + (I - P_1)\\mathbf{\\delta} $$\n项 $(I - P_1)\\mathbf{x}_1$ 为零，因为 $\\mathbf{x}_1$ 在其自身的列空间中。因此，将 $\\mathbf{x}_2$ 对 $\\mathbf{x}_1$ 回归的残差恰好是 $\\mathbf{\\delta}$ 对 $\\mathbf{x}_1$ 回归的残差。\n$\\hat{\\beta}_2$ 方差的分母是这个残差向量的平方范数：\n$$ \\|\\mathbf{x}_{2, \\perp 1}\\|^2 = \\|(I - P_1)\\mathbf{\\delta}\\|^2 = \\text{RSS}_{\\delta \\sim x_1} $$\n这是将 $\\mathbf{\\delta}$ 对 $\\mathbf{x}_1$ 回归得到的残差平方和。这就是“$\\mathbf{\\delta}$ 正交于 $\\mathbf{x}_1$ 的分量”。\n\n问题陈述 $x_1$ 和 $\\delta$ 是独立的。在有限样本中，这并不能保证样本相关性为零（即 $\\sum x_{1i}\\delta_i = 0$）。然而，对于这类理论分析，通常会假设样本性质反映总体性质，这意味着样本正交性。我们假设 $\\sum_{i=1}^n x_{1i}\\delta_i = 0$。这意味着在我们的样本中，$\\mathbf{x}_1$ 和 $\\mathbf{\\delta}$ 是正交的。\n在这种标准的理想化情况下，将 $\\mathbf{\\delta}$ 对 $\\mathbf{x}_1$ 回归会得到零系数，残差就是 $\\mathbf{\\delta}$ 本身。\n$$ \\text{如果 } \\mathbf{x}_1^\\top \\mathbf{\\delta} = 0, \\text{ 那么 } \\mathbf{x}_{2, \\perp 1} = (I-P_1)\\mathbf{\\delta} = \\mathbf{\\delta}。 $$\n因此，$\\|\\mathbf{x}_{2, \\perp 1}\\|^2 = \\|\\mathbf{\\delta}\\|^2 = \\sum_{i=1}^n \\delta_i^2$。\n由于 $\\delta$ 是一个均值为0的扰动，其样本方差（为简单起见，通常在分母中使用 $n$）为 $\\frac{1}{n} \\sum \\delta_i^2$。问题将此量给定为 $\\tau^2 = \\operatorname{Var}(\\delta)$。所以，$\\sum \\delta_i^2 = n \\tau^2 = n \\operatorname{Var}(\\delta)$。\n\n因此，在这种标准简化下，我们有：\n$$ \\operatorname{Var}(\\hat{\\beta}_2) = \\frac{\\sigma^2}{\\sum_{i=1}^n \\delta_i^2} = \\frac{\\sigma^2}{n \\tau^2} = \\frac{\\sigma^2}{n \\operatorname{Var}(\\delta)} $$\n当 $\\tau^2 \\to 0$ 时，此方差无界增长。\n\n### 逐项分析\n\n**A. 在这种 $x_2 = x_1 + \\delta$ 且预测变量中心化的构造中，$\\hat{\\beta}_2$ 的抽样方差等于 $\\sigma^2 \\big/ \\big(n\\, \\operatorname{Var}(\\delta)\\big)$，因此当 $\\tau^2 \\to 0$ 时，它会发散。**\n\n如上所述，在样本正交性（$\\sum x_{1i}\\delta_i=0$）这一此类理论问题的典型简化假设下，方差恰好是 $\\operatorname{Var}(\\hat{\\beta}_2) = \\sigma^2 / (n \\operatorname{Var}(\\delta))$。量 $\\operatorname{Var}(\\delta)$ 表示为 $\\tau^2$。当 $\\tau^2 \\to 0$ 时，分母趋近于 $0$，因此方差发散到无穷大。即使没有这个简化假设，分母 $\\text{RSS}_{\\delta \\sim x_1}$ 的数量级也是 $n\\tau^2$，所以方差发散的结论仍然正确。该陈述正确地表述了近似共线性的影响。\n\n**结论：正确**\n\n**B. 将 $\\operatorname{Var}(\\hat{\\beta}_2)$ 与单变量回归方差联系起来的方差膨胀因子是 $(1 - R_2^2)^{-1}$，其中 $R_2^2$ 来自将 $x_2$ 对 $x_1$ 进行回归。在此设置中，$R_2^2 = v_1/(v_1+\\tau^2)$，所以膨胀因子等于 $(v_1+\\tau^2)/\\tau^2$，并且当 $\\tau^2 \\to 0$ 时无界增长。**\n\n$\\hat{\\beta}_2$ 的方差膨胀因子是 $\\text{VIF}_2 = (1 - R_2^2)^{-1}$，其中 $R_2^2$ 是将 $x_2$ 对 $x_1$ 回归的决定系数。$R_2^2$ 定义为 $x_1$ 和 $x_2$ 之间相关系数的平方。对于中心化变量，$R_2^2= (\\sum x_{1i}x_{2i})^2 / ((\\sum x_{1i}^2)(\\sum x_{2i}^2))$。让我们使用我们简化后的量：\n- $\\sum x_{1i}^2 = n \\operatorname{Var}(x_1) = n v_1$。\n- $\\sum x_{2i}^2 = \\sum (x_{1i}+\\delta_i)^2 = \\sum x_{1i}^2 + \\sum \\delta_i^2 + 2\\sum x_{1i}\\delta_i = n v_1 + n \\tau^2 + 0 = n(v_1+\\tau^2)$。\n- $\\sum x_{1i}x_{2i} = \\sum x_{1i}(x_{1i}+\\delta_i) = \\sum x_{1i}^2 + \\sum x_{1i}\\delta_i = n v_1 + 0 = n v_1$。\n\n代入这些值：\n$$ R_2^2 = \\frac{(n v_1)^2}{(n v_1)(n(v_1+\\tau^2))} = \\frac{v_1}{v_1 + \\tau^2} $$\n这与选项中的公式相符。当 $\\tau^2 \\to 0$ 时，$R_2^2 \\to v_1/v_1 = 1$，表示完全共线性。\n膨胀因子是：\n$$ \\text{VIF}_2 = \\frac{1}{1 - R_2^2} = \\frac{1}{1 - \\frac{v_1}{v_1+\\tau^2}} = \\frac{1}{\\frac{(v_1+\\tau^2)-v_1}{v_1+\\tau^2}} = \\frac{v_1+\\tau^2}{\\tau^2} $$\n这也与选项中的公式相符。当 $\\tau^2 \\to 0$ 时，分子趋近于 $v_1  0$，分母趋近于 $0$，所以 VIF 无界增长。这个陈述完全正确。\n\n**结论：正确**\n\n**C. 由于 $x_1$ 的作用，模型的 $R^2$ 可以任意接近于 $1$，而对 $H_0:\\beta_2=0$ 的检验却得出很小的 $|t_2|$，因为只有 $x_2$ 正交于 $x_1$ 的分量（即 $\\delta$）为 $\\beta_2$ 提供信息，且其方差很小。**\n\n这个陈述为多重共线性现象提供了概念性解释。\n1.  **高 $R^2$**：如果 $x_1$ 是 $Y$ 的强预测变量，那么无论 $x_2$ 的贡献如何，模型的整体 $R^2$ 都可以很高。\n2.  **小 $|t_2|$**：$\\beta_2$ 的 $t$ 统计量是 $t_2 = \\hat{\\beta}_2 / \\text{SE}(\\hat{\\beta}_2)$。如 A 和 B 所示，近似共线性导致标准误 $\\text{SE}(\\hat{\\beta}_2)$ 变得非常大。即使真实的 $\\beta_2$ 不为零，一个大的分母也会导致 $|t_2|$ 很小，从而无法拒绝 $H_0: \\beta_2 = 0$。\n3.  **原因**：所提供的推理是完全正确的，并且遵循 FWL 定理。$x_2$ 为估计其系数 $\\beta_2$ 所贡献的独特信息包含在其正交于 $x_1$ 的分量中。我们证明了这个分量是 $(I-P_1)\\mathbf{\\delta}$。该分量的“方差”（其平方和）是 $\\|\\mathbf{x}_{2, \\perp 1}\\|^2 \\approx n\\tau^2$，当 $\\tau^2$ 很小时，这个值很小。少量信息导致估计的高度不确定性，即大的标准误。该陈述正确地指出了多重共线性的典型症状（整体 $R^2$ 高，单个 $|t|$ 统计量低）和原因。\n\n**结论：正确**\n\n**D. 因为当添加更多预测变量时，残差标准误 $s$ 会减小，所以当 $x_2$ 被添加到已包含 $x_1$ 的模型中时，$|t_2|$ 必须增加。**\n\n这个陈述有两点错误。\n1.  前提“当添加更多预测变量时，残差标准误 $s$ 会减小”并不完全正确。残差标准误是 $s = \\sqrt{\\text{RSS}/(n-p-1)}$。添加预测变量永远不会增加 RSS，但它会减少分母中的自由度 $(n-p-1)$。如果 RSS 的减少微不足道，$s$ 实际上可能会增加。\n2.  更重要的是，结论与事实相反。$t$ 统计量是 $t_2 = \\hat{\\beta}_2 / \\text{SE}(\\hat{\\beta}_2)$。标准误是 $\\text{SE}(\\hat{\\beta}_2) = s / \\sqrt{\\|\\mathbf{x}_{2, \\perp 1}\\|^2}$。在近似共线性的背景下，分母项 $\\|\\mathbf{x}_{2, \\perp 1}\\|^2$ 非常小（趋近于 $0$）。这使得 $\\text{SE}(\\hat{\\beta}_2)$ 非常大，进而使得 $|t_2|$ *小*，而不是大。该陈述的说法与多重共线性的主要影响直接矛盾。\n\n**结论：不正确**\n\n**E. 近似共线性会导致 $\\hat{\\beta}_2$ 产生朝向 $0$ 的偏差，这是即使 $R^2$ 很大，$|t_2|$ 也很小的主要原因。**\n\n这个陈述错误地归因了多重共线性的影响。只要高斯-马尔可夫假设成立（在本问题的设置中是成立的，特别是 $E[\\varepsilon|X]=0$），普通最小二乘（OLS）估计量就是无偏的。OLS 估计量的期望值是 $E[\\hat{\\beta}] = \\beta$。无论共线性的程度如何，只要它不是完全共线性（即 $X^\\top X$ 是可逆的），这一点都成立。近似共线性不会引入偏差。相反，它会增大估计量的*方差*。$|t_2|$ 很小的主要原因是标准误很大（$t$ 统计量的分母），而不是估计量 $\\hat{\\beta}_2$（分子）中存在偏差。\n\n**结论：不正确**",
            "answer": "$$\\boxed{ABC}$$"
        }
    ]
}