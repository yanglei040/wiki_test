{
    "hands_on_practices": [
        {
            "introduction": "F 检验不仅仅是评估整个模型是否有任何价值的工具。它更强大的用途在于精确比较“嵌套”模型，例如，一个简单的模型和一个包含额外（更复杂的）项的扩展模型。通过这个练习，我们将学习如何检验一个包含交互项的完整模型的总体显著性，并接着使用部分 F 检验来判断这些交互项的加入是否显著提升了模型性能，这是模型构建和选择中的一项核心技能 。",
            "id": "3182401",
            "problem": "一个制造团队将 $n=50$ 批次的产出率 $y$ 建模为三个测量协变量的线性函数：反应物浓度 $x_{1}$、熔炉温度 $x_{2}$ 和催化剂指标 $x_{3}$（编码为 $0$ 或 $1$）。为了捕捉协同效应，他们在模型中包含了乘积项 $x_{1}x_{2}$ 和 $x_{2}x_{3}$。设完整模型为\n$$\ny_{i} \\;=\\; \\beta_{0} \\;+\\; \\beta_{1} x_{1i} \\;+\\; \\beta_{2} x_{2i} \\;+\\; \\beta_{3} x_{3i} \\;+\\; \\beta_{4} (x_{1i}x_{2i}) \\;+\\; \\beta_{5} (x_{2i}x_{3i}) \\;+\\; \\varepsilon_{i}, \\quad i=1,\\dots,50,\n$$\n其中假设 $\\varepsilon_{i}$ 独立同分布，服从均值为零、方差恒定的高斯分布。只包含主效应的简化模型为\n$$\ny_{i} \\;=\\; \\beta_{0} \\;+\\; \\beta_{1} x_{1i} \\;+\\; \\beta_{2} x_{2i} \\;+\\; \\beta_{3} x_{3i} \\;+\\; \\varepsilon_{i}.\n$$\n通过普通最小二乘法（OLS）拟合，围绕样本均值计算的方差分析（ANOVA）量为：\n- 总平方和 $SST = 1200$，\n- 完整模型的残差平方和 $SSE_{\\text{full}} = 400$，\n- 简化（仅主效应）模型的残差平方和 $SSE_{\\text{main}} = 550$。\n\n从经典线性模型的假设和正态误差下二次型的核心性质出发，推导用于检验以下假设的适当检验统计量：\n1. 完整模型的整体回归显著性（所有五个非截距项系数联合等于零），以及\n2. 使用嵌套模型的逻辑，将在主效应模型中加入两个交互项 $x_{1}x_{2}$ 和 $x_{2}x_{3}$ 所带来的增量收益。\n\n计算这两个检验统计量的数值。将最终答案表示为一个行矩阵，其中第一个条目等于完整模型的整体显著性统计量，第二个条目等于交互作用的偏统计量。将两个数字四舍五入到四位有效数字。不需要单位。",
            "solution": "问题要求推导和计算与多元线性回归分析相关的两个不同的 F 统计量。第一个用于检验完整模型的整体显著性，而第二个用于检验预测变量子集（交互项）的显著性。这两种检验的基础都是嵌套线性模型的比较。\n\n设一个通用线性模型以矩阵形式表示为 $\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$，其中 $\\mathbf{y}$ 是一个 $n \\times 1$ 的观测向量，$\\mathbf{X}$ 是一个秩为 $p$ 的 $n \\times p$ 设计矩阵，$\\boldsymbol{\\beta}$ 是一个 $p \\times 1$ 的系数向量，$\\boldsymbol{\\varepsilon}$ 是一个 $n \\times 1$ 的误差向量，且 $\\boldsymbol{\\varepsilon} \\sim N(0, \\sigma^2 \\mathbf{I})$。残差平方和由 $SSE = ||\\mathbf{y} - \\hat{\\mathbf{y}}||^2 = \\mathbf{y}^T(\\mathbf{I} - \\mathbf{H})\\mathbf{y}$ 给出，其中 $\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T$ 是帽子矩阵。在正态性假设下，$\\frac{SSE}{\\sigma^2} \\sim \\chi^2_{n-p}$。\n\n对于线性假设 $H_0: \\mathbf{L}\\boldsymbol{\\beta} = \\mathbf{0}$（其中 $\\mathbf{L}$ 是一个秩为 $q$ 的 $q \\times p$ 矩阵）的一般 F 检验，是比较一个完整模型（不施加该假设）和一个简化模型（施加该假设）。检验统计量为：\n$$\nF = \\frac{(SSE_R - SSE_F) / q}{SSE_F / (n-p_F)}\n$$\n其中 $SSE_R$ 和 $SSE_F$ 分别是简化模型和完整模型的残差平方和。完整模型中的参数数量为 $p_F$，$q$ 是原假设施加的线性约束的数量，也等于 $p_F - p_R$，其中 $p_R$ 是简化模型中的参数数量。在 $H_0$ 下，该统计量服从自由度为 $q$ 和 $n-p_F$ 的 F 分布，记为 $F(q, n-p_F)$。\n\n提供的数据如下：\n- 观测数量：$n=50$\n- 总平方和：$SST = 1200$\n- 残差平方和（完整模型）：$SSE_{\\text{full}} = 400$\n- 残差平方和（主效应模型）：$SSE_{\\text{main}} = 550$\n\n完整模型有预测变量 $x_1$、$x_2$、$x_3$、$x_1x_2$ 和 $x_2x_3$。非截距项预测变量的数量为 $k_{\\text{full}}=5$。包括截距 $\\beta_0$ 在内的总参数数量为 $p_{\\text{full}} = k_{\\text{full}} + 1 = 6$。\n\n### 1. 完整模型的整体回归显著性\n\n该检验评估所有非截距项系数均为零的原假设：$H_0: \\beta_1 = \\beta_2 = \\beta_3 = \\beta_4 = \\beta_5 = 0$。\n\n- **完整模型**：这是包含所有 $5$ 个预测变量外加一个截距项的模型。其残差平方和为 $SSE_F = SSE_{\\text{full}} = 400$。参数数量为 $p_F = p_{\\text{full}} = 6$。误差自由度为 $df_E = n - p_{\\text{full}} = 50 - 6 = 44$。相应的均方误差为 $MSE_{\\text{full}} = \\frac{SSE_{\\text{full}}}{n - p_{\\text{full}}}$。\n\n- **简化模型**：在 $H_0$ 下，模型变为 $y_i = \\beta_0 + \\varepsilon_i$。这是一个仅含截距项的模型。对于仅含截距项的模型，$\\beta_0$ 的 OLS 估计是样本均值 $\\bar{y}$，根据定义，其残差平方和等于总平方和 $SST$。因此，$SSE_R = SST = 1200$。参数数量为 $p_R = 1$。约束的数量为 $q = p_{\\text{full}} - p_R = 6-1=5$，这对应于被设为零的 $5$ 个系数。\n\n回归解释的平方和为 $SSR_{\\text{full}} = SSE_R - SSE_F = SST - SSE_{\\text{full}}$。这个量表示使用完整模型相对于仅含截距项模型所实现的误差平方和的减少量。\n$SSR_{\\text{full}} = 1200 - 400 = 800$。\n\n整体显著性的 F 统计量是回归均方（$MSR_{\\text{full}}$）与误差均方（$MSE_{\\text{full}}$）之比：\n$$\nF_{\\text{overall}} = \\frac{MSR_{\\text{full}}}{MSE_{\\text{full}}} = \\frac{SSR_{\\text{full}} / (p_{\\text{full}} - 1)}{SSE_{\\text{full}} / (n - p_{\\text{full}})}\n$$\n代入给定值：\n$$\nF_{\\text{overall}} = \\frac{(1200 - 400) / 5}{400 / (50 - 6)} = \\frac{800 / 5}{400 / 44} = \\frac{160}{400/44} = 160 \\times \\frac{44}{400} = 0.4 \\times 44 = 17.6\n$$\n在 $H_0$ 下，该统计量服从 $F(5, 44)$ 分布。\n\n### 2. 交互项的增量收益\n\n该检验评估交互项系数均为零的原假设：$H_0: \\beta_4 = \\beta_5 = 0$。这是一个比较两个嵌套模型的偏 F 检验。\n\n- **完整模型**：这仍然是包含所有 $5$ 个预测变量的模型：$y_{i} = \\beta_{0} + \\beta_{1} x_{1i} + \\beta_{2} x_{2i} + \\beta_{3} x_{3i} + \\beta_{4} (x_{1i}x_{2i}) + \\beta_{5} (x_{2i}x_{3i}) + \\varepsilon_{i}$。它的 SSE 为 $SSE_F = SSE_{\\text{full}} = 400$，有 $p_F = p_{\\text{full}} = 6$ 个参数。F 统计量的分母是这个完整模型的 MSE，$MSE_{\\text{full}} = \\frac{SSE_{\\text{full}}}{n - p_{\\text{full}}} = \\frac{400}{44}$。\n\n- **简化模型**：这是在 $H_0$ 下的模型，排除了交互项。这就是问题陈述中提供的主效应模型：$y_{i} = \\beta_{0} + \\beta_{1} x_{1i} + \\beta_{2} x_{2i} + \\beta_{3} x_{3i} + \\varepsilon_{i}$。它的 SSE 给出为 $SSE_R = SSE_{\\text{main}} = 550$。该模型有 $k_{\\text{main}} = 3$ 个预测变量，因此参数数量为 $p_R = p_{\\text{main}} = 3+1 = 4$。\n\n约束的数量 $q$ 是完整模型相对于简化模型增加的参数数量，即 $q = p_F - p_R = 6 - 4 = 2$。这与原假设中设为零的系数数量相符。\n\n这个偏检验的 F 统计量是：\n$$\nF_{\\text{partial}} = \\frac{(SSE_{\\text{main}} - SSE_{\\text{full}}) / (p_{\\text{full}} - p_{\\text{main}})}{SSE_{\\text{full}} / (n - p_{\\text{full}})}\n$$\n分子表示在主效应模型中加入两个交互项所带来的 SSE 的边际减少量，并按增加的项数进行归一化。\n代入给定值：\n$$\nF_{\\text{partial}} = \\frac{(550 - 400) / 2}{400 / (50 - 6)} = \\frac{150 / 2}{400 / 44} = \\frac{75}{400 / 44} = 75 \\times \\frac{44}{400} = \\frac{3 \\times 25 \\times 44}{16 \\times 25} = \\frac{3 \\times 44}{16} = \\frac{3 \\times 11}{4} = \\frac{33}{4} = 8.25\n$$\n在 $H_0$ 下，该统计量服从 $F(2, 44)$ 分布。\n\n问题要求将两个值四舍五入到四位有效数字。\n$F_{\\text{overall}} = 17.6$ 变为 $17.60$。\n$F_{\\text{partial}} = 8.25$ 变为 $8.250$。\n最终答案以行矩阵形式呈现。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n17.60  8.250\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "上一个练习展示了如何*使用* F 统计量，而本练习将带你深入*理解*其内在机制。我们将通过一个思想实验来探讨：向模型中添加一个与现有预测变量高度相关的“冗余”变量会发生什么？这个过程揭示了 F 统计量并非只追求最大化的解释方差（$R^2$），而是在解释力与模型复杂度（预测变量数量 $p$）之间进行权衡，这种权衡对于构建简约而有效的模型至关重要 。",
            "id": "3182478",
            "problem": "考虑一个统计学习中的标准线性回归设定，其中响应变量为 $y$，预测变量收集在设计矩阵 $X$ 中，通过普通最小二乘法 (OLS) 进行拟合。OLS 模型为 $y = X\\beta + \\varepsilon$，其中 $\\varepsilon$ 的均值为 $0$ 且方差恒定，并包含一个截距项。整体回归的显著性通过使用平方和比较已解释变异和未解释变异来评估。假设存在以下情景。\n\n您有 $n=120$ 个独立观测值。首先，对 $y$ 和单个预测变量 $x$ 拟合一个简单回归。接下来，添加第二个预测变量 $z$，$z$ 是 $x$ 的一个带噪声的副本，这意味着 $z$ 与 $x$ 高度相关，但除了 $x$ 已提供的信息外，不携带实质性的新信号。假设所有变量 $y$、$x$ 和 $z$ 都已中心化（均值为 $0$）并标准化（单位方差），样本相关系数如下：\n- $r_{yx} = 0.60$,\n- $r_{yz} = 0.58$,\n- $r_{xz} = 0.95$.\n\n从总平方和、残差平方和以及回归平方和的定义出发，并使用带截距的 OLS，推导出一个包含 $p$ 个预测变量的模型的整体回归 $F$ 统计量。然后，对标准化变量使用基于相关的推理，来量化当冗余预测变量 $z$ 添加到 $x$ 中时，决定系数 $R^{2}$ 如何变化。\n\n计算两个模型（第一个模型有 $p=1$ 个预测变量 $x$，第二个模型有 $p=2$ 个预测变量 $x$ 和 $z$）的整体回归 $F$ 统计量的比值，\n$$\\frac{F_{\\text{with }x,z}}{F_{\\text{with }x}},$$\n在给定的相关系数和样本量下。将您的最终比值四舍五入到四位有效数字。\n\n除了计算之外，简要定性地解释两个模型之间自由度如何变化，以及 $x$ 和 $z$ 之间的高度相关性如何导致设计矩阵出现病态（ill-conditioning），从而影响系数估计的稳定性和整体显著性评估。最终的数值比是唯一需要在最终答案框中报告的量。",
            "solution": "所述问题具有科学依据，提法得当，且客观。所有必要数据均已提供，其框架是标准的统计线性回归。我们可以开始求解。\n\n首先，我们推导整体回归 $F$ 统计量的一般公式。在一个包含 $n$ 个观测值和 $p$ 个预测变量（外加一个截距项）的线性回归模型中，响应变量 $y$ 的总变异被划分为已解释部分和未解释部分。总平方和 ($SST$) 由 $SST = \\sum_{i=1}^n (y_i - \\bar{y})^2$ 给出。它被划分为回归平方和 ($SSR$)，$SSR = \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2$，和残差平方和 ($SSE$)，$SSE = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$。基本恒等式是 $SST = SSR + SSE$。\n\n决定系数 $R^2$ 是模型解释的总方差的比例：\n$$R^2 = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST}$$\n由此，我们可以用 $R^2$ 和 $SST$ 来表示 $SSR$ 和 $SSE$：\n$$SSR = R^2 \\cdot SST$$\n$$SSE = (1 - R^2) \\cdot SST$$\n整体 $F$ 统计量检验所有预测变量系数均为零的原假设 ($H_0: \\beta_1 = \\beta_2 = \\dots = \\beta_p = 0$)。它是回归均方 ($MSR$) 与误差均方 ($MSE$) 的比值。回归的自由度是 $p$，残差的自由度是 $n - p - 1$。\n$$MSR = \\frac{SSR}{p}$$\n$$MSE = \\frac{SSE}{n-p-1}$$\n因此，$F$ 统计量为：\n$$F = \\frac{MSR}{MSE} = \\frac{SSR/p}{SSE/(n-p-1)}$$\n代入以 $R^2$ 表示的表达式：\n$$F = \\frac{(R^2 \\cdot SST) / p}{((1 - R^2) \\cdot SST) / (n-p-1)} = \\frac{R^2/p}{(1-R^2)/(n-p-1)}$$\n这就是所要求的一般公式。\n\n接下来，我们计算两个模型的决定系数 $R^2$。变量 $y$、$x$ 和 $z$ 是标准化的，这简化了计算。\n对于第一个模型，即 $y$ 对 $x$ 的简单线性回归，我们有 $p=1$。决定系数，我们记为 $R^2_x$，是 $y$ 和 $x$ 之间样本相关系数的平方。\n$$R^2_x = (r_{yx})^2 = (0.60)^2 = 0.36$$\n\n对于第二个模型，即 $y$ 对 $x$ 和 $z$ 的多元线性回归，我们有 $p=2$。对于标准化变量，多元决定系数，记为 $R^2_{xz}$，由以下公式给出：\n$$R^2_{xz} = \\frac{r_{yx}^2 + r_{yz}^2 - 2 r_{yx} r_{yz} r_{xz}}{1 - r_{xz}^2}$$\n代入给定的相关系数值：$r_{yx} = 0.60$，$r_{yz} = 0.58$ 和 $r_{xz} = 0.95$。\n$$R^2_{xz} = \\frac{(0.60)^2 + (0.58)^2 - 2(0.60)(0.58)(0.95)}{1 - (0.95)^2}$$\n$$R^2_{xz} = \\frac{0.36 + 0.3364 - 0.6612}{1 - 0.9025} = \\frac{0.0352}{0.0975}$$\n注意到 $R^2_{xz} \\approx 0.3610256$，与 $R^2_x = 0.36$ 相比仅有非常微小的增加。这是预料之中的，因为 $z$ 与 $x$ 高度相关，对于预测 $y$ 几乎不提供新信息。\n\n现在我们使用 $n=120$ 来计算每个模型的 $F$ 统计量。\n对于仅含 $x$ 的模型 ($p_1=1$)：\n$$F_{\\text{with }x} = \\frac{R^2_x/p_1}{(1-R^2_x)/(n-p_1-1)} = \\frac{0.36/1}{(1-0.36)/(120-1-1)} = \\frac{0.36}{0.64/118} = \\frac{0.36 \\times 118}{0.64} = 66.375$$\n\n对于含 $x$ 和 $z$ 的模型 ($p_2=2$)：\n$$F_{\\text{with }x,z} = \\frac{R^2_{xz}/p_2}{(1-R^2_{xz})/(n-p_2-1)} = \\frac{(0.0352/0.0975)/2}{(1 - 0.0352/0.0975)/(120-2-1)}$$\n$$F_{\\text{with }x,z} = \\frac{0.0352 / (2 \\times 0.0975)}{( (0.0975 - 0.0352)/0.0975 ) / 117} = \\frac{0.0352 / 0.195}{(0.0623/0.0975)/117} = \\frac{0.0352 \\times 117}{2 \\times 0.0623} = \\frac{4.1184}{0.1246} \\approx 33.053...$$\n\n最后，我们计算两个 $F$ 统计量的比值：\n$$\\frac{F_{\\text{with }x,z}}{F_{\\text{with }x}} = \\frac{33.053...}{66.375} \\approx 0.49800...$$\n四舍五入到四位有效数字，该比值为 $0.4980$。\n\n有必要对相关现象进行定性解释。\n当添加预测变量 $z$ 时，回归模型的自由度从 $p_1=1$ 增加到 $p_2=2$。相应地，残差的自由度从 $n-p_1-1=118$ 减少到 $n-p_2-1=117$。总自由度 $n-1=119$ 保持不变。\n\n$x$ 和 $z$ 之间的高度相关性（$r_{xz}=0.95$）被称为多重共线性。这会导致设计矩阵 $X$ 出现病态（ill-conditioning）。用于求 OLS 系数估计值 $\\hat{\\beta}$ 的矩阵 $(X^T X)$ 在求逆时变得近乎奇异。因此，其逆矩阵的对角线元素很大，这会使得系数估计的方差（$\\text{Var}(\\hat{\\beta}_j)$）膨胀。这使得单个系数的估计值不稳定，其标准误增大，从而影响对每个预测变量各自贡献的评估。\n\n关于整体显著性，尽管 $R^2$ 增加了，但 $F$ 统计量却减小了。公式 $F = (R^2/p) / ((1-R^2)/(n-p-1))$ 揭示了原因。$R^2/p$ 这一项代表每个预测变量平均解释的方差。当添加冗余预测变量 $z$ 时，$R^2$ 仅略微增加（从 $0.36$ 到约 $0.361$），但预测变量的数量 $p$ 从 $1$ 翻倍到 $2$。因此，分子项 $R^2/p$ 急剧下降，从 $0.36/1$ 降至约 $0.361/2 \\approx 0.18$。这反映了对模型复杂度的惩罚；添加 $z$ 所带来的解释力的微小增长不足以证明增加一个额外参数的“成本”，从而导致根据 F 统计量判断，模型的整体显著性降低。",
            "answer": "$$\\boxed{0.4980}$$"
        },
        {
            "introduction": "最后一个练习将我们带入一个在现实世界数据分析中至关重要的两难情境。如果一个模型在预测新数据方面表现出色，但其整体 F 检验却未能达到统计显著性水平，我们该如何解读？这个案例突出了统计推断（检验关于系数的假设）与预测（估计未来结果）之间的区别，并揭示了样本量如何在这种差异中扮演关键角色 。理解这一区别对于正确解释你的分析结果至关重要。",
            "id": "3182416",
            "problem": "一位分析师对一个响应变量 $Y$ 拟合了一个带有截距项和 $p$ 个预测变量的多元线性回归模型，该模型遵循标准正态线性模型 $Y = X\\beta + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I)$。其目标是评估这 $p$ 个预测变量的整体回归显著性，同时也要关注模型在新数据上的预测性能。考虑以下一个特殊设计的案例，旨在强调当样本量 $n$ 较小时，统计推断与预测之间存在的矛盾。\n\n已知对于一个拟合模型，有 $n = 9$ 个观测值和 $p = 3$ 个预测变量（不包括截距项），其总离差平方和为 $\\operatorname{SST} = 88$，拟合模型的残差平方和为 $\\operatorname{SSE} = 25$。另外，该分析师还使用留一法交叉验证（LOOCV）评估了预测性能，发现拟合模型的 LOOCV 均方误差为 $5.6$，而仅包含截距项的模型（零模型）的均方误差为 $12.3$。\n\n任务：\n- 从正态线性模型的假设以及总平方和与残差平方和的定义出发，推导用于评估原假设 $H_{0}: \\beta_{1} = \\cdots = \\beta_{p} = 0$ 与备择假设（至少有一个斜率不为零）的整体回归检验统计量，并明确指出相关的自由度。\n- 使用所提供的摘要信息计算该检验统计量的观测值。\n- 用一两句话简要解释，为何当 $n$ 较小时，模型在 LOOCV 中表现出优越的预测性能，而整体回归检验却可能无法达到常规的显著性水平。\n\n最终答案只报告该检验统计量的观测数值。将结果四舍五入至三位有效数字。",
            "solution": "该问题经评估是有效的。它内容完整，科学上基于线性回归分析的原理，并且问题表述清晰。进行所需计算的所有必要数据均已提供。\n\n主要任务是推导用于检验多元线性回归模型整体显著性的 F 统计量，然后计算其值。该模型由 $Y = X\\beta + \\varepsilon$ 给出，其中 $Y$ 是观测值的 $n \\times 1$ 向量，$X$ 是 $n \\times (p+1)$ 的设计矩阵（包含一列全为1的截距项），$\\beta$ 是系数的 $(p+1) \\times 1$ 向量，$\\varepsilon$ 是误差的 $n \\times 1$ 向量，且 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I)$。\n\n整体回归显著性检验评估的是原假设 $H_{0}: \\beta_{1} = \\beta_{2} = \\cdots = \\beta_{p} = 0$ 相对于备择假设 $H_{A}$：对于 $j \\in \\{1, \\dots, p\\}$，至少有一个 $\\beta_{j} \\neq 0$。这是对两个嵌套模型的比较：\n1. 完整模型，包含所有 $p$ 个预测变量和截距项。\n2. 简化（或零）模型，仅包含截距项。该模型由原假设的约束条件指定。\n\n该检验统计量是通过对总平方和 $\\operatorname{SST}$ 的分解来构建的。总平方和衡量响应变量 $Y$ 围绕其样本均值 $\\bar{y}$ 的总变异性。其定义为 $\\operatorname{SST} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2$。与 $\\operatorname{SST}$ 相关的自由度为 $df_{T} = n-1$。\n\n残差平方和 $\\operatorname{SSE}$ 衡量在拟合回归模型后仍未被解释的变异性。其定义为 $\\operatorname{SSE} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$，其中 $\\hat{y}_i$ 是来自完整模型的拟合值。完整模型中误差的自由度为 $df_{E} = n - (\\text{参数数量}) = n - (p+1)$。\n\n回归平方和 $\\operatorname{SSR}$ 衡量由回归模型解释的 $Y$ 的变异性。它是总变异性与未解释变异性之间的差值：$\\operatorname{SSR} = \\operatorname{SST} - \\operatorname{SSE}$。回归的自由度对应于被检验的预测变量系数的数量，即 $p$。这也可以看作是简化模型 ($n-1$) 和完整模型 ($n-p-1$) 误差自由度之差，因此 $df_{R} = (n-1) - (n-p-1) = p$。\n\nF 检验统计量是两个均方的比值。均方是平方和除以其自由度。\n回归均方为 $\\operatorname{MSR} = \\frac{\\operatorname{SSR}}{df_{R}} = \\frac{\\operatorname{SST} - \\operatorname{SSE}}{p}$。\n误差均方为 $\\operatorname{MSE} = \\frac{\\operatorname{SSE}}{df_{E}} = \\frac{\\operatorname{SSE}}{n-p-1}$。\n\nF 统计量定义为比率 $F = \\frac{\\operatorname{MSR}}{\\operatorname{MSE}}$。在原假设 $H_{0}$ 为真的前提下，该统计量服从自由度为 $p$ 和 $n-p-1$ 的 F 分布。\n公式为：\n$$F = \\frac{(\\operatorname{SST} - \\operatorname{SSE}) / p}{\\operatorname{SSE} / (n-p-1)}$$\n相关的自由度是分子的 $p$ 和分母的 $n-p-1$。\n\n我们已知以下数值：\n- 样本量：$n = 9$\n- 预测变量数量：$p = 3$\n- 总平方和：$\\operatorname{SST} = 88$\n- 残差平方和：$\\operatorname{SSE} = 25$\n\n首先，我们计算自由度：\n- 分子自由度：$df_{1} = p = 3$\n- 分母自由度：$df_{2} = n - p - 1 = 9 - 3 - 1 = 5$\n\n接下来，我们计算均方：\n- $\\operatorname{SSR} = \\operatorname{SST} - \\operatorname{SSE} = 88 - 25 = 63$\n- $\\operatorname{MSR} = \\frac{\\operatorname{SSR}}{p} = \\frac{63}{3} = 21$\n- $\\operatorname{MSE} = \\frac{\\operatorname{SSE}}{n-p-1} = \\frac{25}{5} = 5$\n\n最后，我们计算观测到的 F 统计量：\n$$F_{\\text{obs}} = \\frac{\\operatorname{MSR}}{\\operatorname{MSE}} = \\frac{21}{5} = 4.2$$\n四舍五入到三位有效数字，其值为 $4.20$。\n\n最后的任务是解释预测性能与统计显著性之间的明显矛盾。拟合模型的 LOOCV 均方误差 ($5.6$) 不到零模型 ($12.3$) 的一半，这表明预测性能有实质性改善。然而，自由度为 $(3, 5)$ 的 F 统计量值为 $4.20$，其 p 值约为 $0.08$，在常规的 $\\alpha = 0.05$ 水平下不显著（临界值 $F_{0.05, 3, 5}$ 为 $5.41$）。这种情况的发生是因为 F 检验的统计功效较低，这是由于样本量非常小 ($n=9$) 以及由此导致的误差自由度很小 ($df_{E}=5$)。交叉验证评估的是预测效用，即使样本量太小，以至于正式的假设检验无法提供具有统计显著性的证据来拒绝原假设，这种预测效用也可能很明显。",
            "answer": "$$\\boxed{4.20}$$"
        }
    ]
}