{
    "hands_on_practices": [
        {
            "introduction": "为了真正掌握回归诊断，我们必须深入其“引擎盖”之下，理解其内部工作机制。本练习将引导我们从零开始，为一个简单的数据集构建帽子矩阵 $H$。 通过这个过程，我们将具体看到单个观测值的变动如何通过矩阵 $(I-H)$ 影响所有残差，从而深化对最小二乘法几何原理的理解。",
            "id": "3183487",
            "problem": "考虑一个固定设计的线性回归模型，其中有 $n=5$ 个观测值和 $p=3$ 个预测变量。设设计矩阵 $X \\in \\mathbb{R}^{5 \\times 3}$ 的列向量 $c_{0}, c_{1}, c_{2}$ 定义如下\n$$\nc_{0} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad\nc_{1} = \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\\\ -1 \\\\ 0 \\end{pmatrix}, \\quad\nc_{2} = \\begin{pmatrix} 1 \\\\ 1 \\\\ -1 \\\\ -1 \\\\ 0 \\end{pmatrix},\n$$\n因此\n$$\nX = \\begin{pmatrix}\n1  1  1 \\\\\n1  -1  1 \\\\\n1  1  -1 \\\\\n1  -1  -1 \\\\\n1  0  0\n\\end{pmatrix}.\n$$\n您可以假设响应向量 $y \\in \\mathbb{R}^{5}$ 是任意的，并且最小二乘拟合向量是 $y$ 在标准欧几里得内积下到 $X$ 的列空间上的正交投影。残差向量为 $e = y - \\hat{y}$。\n\n任务：\n1. 显式地构建在 $\\mathbb{R}^{5}$ 上的线性算子，该算子将任意 $y$ 映射到其在 $X$ 的列空间中的最小二乘拟合值 $\\hat{y}$。对于给定的 $X$，精确计算该算子。\n2. 使用第1部分的算子，分析对 $y$ 的形式为 $y = y_{0} + \\delta v$ 的扰动，其中 $y_{0}$ 是固定的，$\\delta \\in \\mathbb{R}$ 是一个标量，$v$ 是 $\\mathbb{R}^{5}$ 中的标准基向量 $e_{k}$（即第 $k$ 个坐标方向）。确定残差向量 $e = (I - H) y$ 如何响应每个坐标方向。\n3. 对于 $\\delta = 3$ 和 $v = e_{3}$ 的特定扰动，确定在观测值 $i=5$ 处的残差产生的变化。\n\n请以一个精确的数字作为最终答案。本题无需四舍五入，也没有物理单位。",
            "solution": "该问题被评估为有效，因为它在科学上基于线性回归理论，问题设定良好且有唯一解，并且表述正式，没有歧义或矛盾。我们开始解答。\n\n该问题要求对由设计矩阵 $X$ 定义的线性回归模型进行三部分分析。这三个任务是：\n1.  构建到 $X$ 的列空间上的投影算子，即帽子矩阵 $H$。\n2.  分析残差向量对响应向量 $y$ 中特定类型扰动的响应。\n3.  计算给定扰动下特定残差的变化。\n\n设线性模型为 $y = X\\beta + \\epsilon$，其中 $y \\in \\mathbb{R}^{5}$ 是响应向量，$X \\in \\mathbb{R}^{5 \\times 3}$ 是设计矩阵，$\\beta \\in \\mathbb{R}^{3}$ 是系数向量，$\\epsilon \\in \\mathbb{R}^{5}$ 是误差向量。$\\beta$ 的最小二乘估计为 $\\hat{\\beta} = (X^T X)^{-1}X^T y$。拟合值由 $\\hat{y} = X\\hat{\\beta} = X(X^T X)^{-1}X^T y$ 给出。\n\n**第1部分：构建帽子矩阵**\n\n将 $y$ 映射到 $\\hat{y}$ 的线性算子是帽子矩阵 $H$，定义为：\n$$ H = X(X^T X)^{-1}X^T $$\n我们给定的设计矩阵是：\n$$ X = \\begin{pmatrix}\n1  1  1 \\\\\n1  -1  1 \\\\\n1  1  -1 \\\\\n1  -1  -1 \\\\\n1  0  0\n\\end{pmatrix} $$\n首先，我们计算矩阵 $X^T X$：\n$$ X^T X = \\begin{pmatrix}\n1  1  1  1  1 \\\\\n1  -1  1  -1  0 \\\\\n1  1  -1  -1  0\n\\end{pmatrix}\n\\begin{pmatrix}\n1  1  1 \\\\\n1  -1  1 \\\\\n1  1  -1 \\\\\n1  -1  -1 \\\\\n1  0  0\n\\end{pmatrix} $$\n$X$ 的列向量，记为 $c_0, c_1, c_2$，是正交的。我们可以通过计算 $X^T X$ 的非对角元素来验证这一点：\n$c_0^T c_1 = 1-1+1-1+0 = 0$\n$c_0^T c_2 = 1+1-1-1+0 = 0$\n$c_1^T c_2 = 1-1-1+1+0 = 0$\n对角线元素是列向量的平方范数：\n$c_0^T c_0 = 1^2+1^2+1^2+1^2+1^2 = 5$\n$c_1^T c_1 = 1^2+(-1)^2+1^2+(-1)^2+0^2 = 4$\n$c_2^T c_2 = 1^2+1^2+(-1)^2+(-1)^2+0^2 = 4$\n因此，$X^T X$ 是一个对角矩阵：\n$$ X^T X = \\begin{pmatrix}\n5  0  0 \\\\\n0  4  0 \\\\\n0  0  4\n\\end{pmatrix} $$\n其逆矩阵 $(X^T X)^{-1}$ 也是一个对角矩阵，对角线元素是原对角元素的倒数：\n$$ (X^T X)^{-1} = \\begin{pmatrix}\n\\frac{1}{5}  0  0 \\\\\n0  \\frac{1}{4}  0 \\\\\n0  0  \\frac{1}{4}\n\\end{pmatrix} $$\n现在我们可以计算帽子矩阵 $H$。由于 $X$ 的列向量是正交的， $H$ 可以写成到每个列向量上的投影矩阵之和：\n$$ H = \\sum_{k=0}^{2} \\frac{c_k c_k^T}{c_k^T c_k} $$\n另外，帽子矩阵的元素 $H_{ij}$ 由 $H_{ij} = X_i (X^T X)^{-1} X_j^T$ 给出，其中 $X_i$ 是 $X$ 的第 $i$ 行。使用推导出的 $(X^TX)^{-1}$：\n$$ H_{ij} = \\frac{x_{i1} x_{j1}}{5} + \\frac{x_{i2} x_{j2}}{4} + \\frac{x_{i3} x_{j3}}{4} $$\n我们来计算 $H$ 的元素：\n对角线元素（杠杆值）$h_{ii} = H_{ii}$：\n$h_{11} = h_{22} = h_{33} = h_{44} = \\frac{1^2}{5} + \\frac{(\\pm 1)^2}{4} + \\frac{(\\pm 1)^2}{4} = \\frac{1}{5} + \\frac{1}{4} + \\frac{1}{4} = \\frac{7}{10}$。\n$h_{55} = \\frac{1^2}{5} + \\frac{0^2}{4} + \\frac{0^2}{4} = \\frac{1}{5} = \\frac{2}{10}$。\n非对角线元素 $h_{ij} = H_{ij}$，其中 $i \\ne j$：\n$h_{12} = \\frac{1 \\cdot 1}{5} + \\frac{1 \\cdot (-1)}{4} + \\frac{1 \\cdot 1}{4} = \\frac{1}{5} = \\frac{2}{10}$。\n$h_{13} = \\frac{1 \\cdot 1}{5} + \\frac{1 \\cdot 1}{4} + \\frac{1 \\cdot (-1)}{4} = \\frac{1}{5} = \\frac{2}{10}$。\n$h_{14} = \\frac{1 \\cdot 1}{5} + \\frac{1 \\cdot (-1)}{4} + \\frac{1 \\cdot (-1)}{4} = \\frac{1}{5} - \\frac{1}{2} = -\\frac{3}{10}$。\n$h_{15} = \\frac{1 \\cdot 1}{5} + \\frac{1 \\cdot 0}{4} + \\frac{1 \\cdot 0}{4} = \\frac{1}{5} = \\frac{2}{10}$。\n$h_{23} = \\frac{1 \\cdot 1}{5} + \\frac{(-1) \\cdot 1}{4} + \\frac{1 \\cdot (-1)}{4} = \\frac{1}{5} - \\frac{1}{2} = -\\frac{3}{10}$。\n$h_{24} = \\frac{1 \\cdot 1}{5} + \\frac{(-1) \\cdot (-1)}{4} + \\frac{1 \\cdot (-1)}{4} = \\frac{1}{5} = \\frac{2}{10}$。\n$h_{25} = \\frac{1 \\cdot 1}{5} + \\frac{(-1) \\cdot 0}{4} + \\frac{1 \\cdot 0}{4} = \\frac{1}{5} = \\frac{2}{10}$。\n$h_{34} = \\frac{1 \\cdot 1}{5} + \\frac{1 \\cdot (-1)}{4} + \\frac{(-1) \\cdot (-1)}{4} = \\frac{1}{5} = \\frac{2}{10}$。\n$h_{35} = \\frac{1 \\cdot 1}{5} + \\frac{1 \\cdot 0}{4} + \\frac{(-1) \\cdot 0}{4} = \\frac{1}{5} = \\frac{2}{10}$。\n$h_{45} = \\frac{1 \\cdot 1}{5} + \\frac{(-1) \\cdot 0}{4} + \\frac{(-1) \\cdot 0}{4} = \\frac{1}{5} = \\frac{2}{10}$。\n利用对称性（$h_{ij}=h_{ji}$），完整的帽子矩阵是：\n$$ H = \\frac{1}{10} \\begin{pmatrix}\n7  2  2  -3  2 \\\\\n2  7  -3  2  2 \\\\\n2  -3  7  2  2 \\\\\n-3  2  2  7  2 \\\\\n2  2  2  2  2\n\\end{pmatrix} $$\n\n**第2部分：扰动分析**\n\n残差向量为 $e = y - \\hat{y}$。由于 $\\hat{y} = Hy$，残差向量由 $e = y - Hy = (I - H)y$ 给出，其中 $I$ 是 $5 \\times 5$ 的单位矩阵。\n设原始响应向量为 $y_0$，其对应的残差向量为 $e_0 = (I-H)y_0$。\n响应向量被扰动为 $y' = y_0 + \\delta v$，其中 $v$ 是一个标准基向量 $e_k$。新的残差向量 $e'$ 是：\n$$ e' = (I-H)y' = (I-H)(y_0 + \\delta e_k) $$\n根据算子 $(I-H)$ 的线性性质，我们有：\n$$ e' = (I-H)y_0 + \\delta(I-H)e_k = e_0 + \\delta(I-H)e_k $$\n残差向量的变化为 $\\Delta e = e' - e_0$：\n$$ \\Delta e = \\delta(I-H)e_k $$\n向量 $(I-H)e_k$ 就是矩阵 $(I-H)$ 的第 $k$ 列。因此，对第 $k$ 个观测值 $y_k$ 的大小为 $\\delta$ 的扰动，会导致残差向量改变 $\\delta$ 乘以 $(I-H)$ 的第 $k$ 列。第 $i$ 个残差的变化 $\\Delta e_i$ 由 $\\Delta e_i = \\delta((I-H)e_k)_i = \\delta(I-H)_{ik}$ 给出。\n\n矩阵 $I-H$ 是：\n$$ I-H = \\frac{1}{10} \\begin{pmatrix}\n10  0  0  0  0 \\\\\n0  10  0  0  0 \\\\\n0  0  10  0  0 \\\\\n0  0  0  10  0 \\\\\n0  0  0  0  10\n\\end{pmatrix} - \\frac{1}{10} \\begin{pmatrix}\n7  2  2  -3  2 \\\\\n2  7  -3  2  2 \\\\\n2  -3  7  2  2 \\\\\n-3  2  2  7  2 \\\\\n2  2  2  2  2\n\\end{pmatrix} $$\n$$ I-H = \\frac{1}{10} \\begin{pmatrix}\n3  -2  -2  3  -2 \\\\\n-2  3  3  -2  -2 \\\\\n-2  3  3  -2  -2 \\\\\n3  -2  -2  3  -2 \\\\\n-2  -2  -2  -2  8\n\\end{pmatrix} $$\n\n**第3部分：特定扰动计算**\n\n我们被要求计算在特定扰动下，观测值 $i=5$ 处的残差变化。\n给定的扰动为 $\\delta = 3$ 和 $v = e_3$。这意味着扰动施加于第3个观测值，所以 $k=3$。我们关心的是第5个残差的变化，所以 $i=5$。\n使用第2部分推导的公式：\n$$ \\Delta e_i = \\delta(I-H)_{ik} $$\n代入给定的值：\n$$ \\Delta e_5 = 3 \\cdot (I-H)_{53} $$\n从上面计算出的矩阵 $I-H$ 中，第5行第3列的元素是 $(I-H)_{53} = -\\frac{2}{10}$。\n因此，在观测值 $i=5$ 处的残差变化为：\n$$ \\Delta e_5 = 3 \\cdot \\left(-\\frac{2}{10}\\right) = -\\frac{6}{10} = -\\frac{3}{5} $$",
            "answer": "$$\\boxed{-\\frac{3}{5}}$$"
        },
        {
            "introduction": "在了解了帽子矩阵的基本计算后，让我们来建立关于杠杆值的直观认识。杠杆值并非随机分布，它完全由预测变量 $X$ 的结构决定。 这个练习通过一个巧妙的思想实验——复制一个数据点——来探索数据结构对杠杆值的影响。通过分析这种复制如何改变相关点的杠杆值，我们将揭示杠杆的几何意义，并理解为何在预测变量上相同的点必然会得到相同的拟合值。",
            "id": "3183500",
            "problem": "考虑一个通过普通最小二乘法 (OLS) 估计的带截距的简单线性回归，其中设计矩阵 $X$ 有两列：一列是截距，另一列是单个协变量 $x$。从 $n=3$ 的设计矩阵\n$$\nX_{\\text{before}}=\\begin{pmatrix}\n1  0\\\\\n1  1\\\\\n1  2\n\\end{pmatrix},\n$$\n和响应向量\n$$\ny=\\begin{pmatrix}\n1\\\\\n3\\\\\n2\n\\end{pmatrix}\n$$\n开始。现在，通过添加第四个观测值来构建一个重复设计，该观测值的协变量行与 $X_{\\text{before}}$ 的第二行相同，得到\n$$\nX_{\\text{after}}=\\begin{pmatrix}\n1  0\\\\\n1  1\\\\\n1  2\\\\\n1  1\n\\end{pmatrix},\n\\quad\ny_{\\text{after}}=\\begin{pmatrix}\n1\\\\\n3\\\\\n2\\\\\n5\n\\end{pmatrix},\n$$\n因此 $X_{\\text{after}}$ 的第 2 行和第 4 行是相同的。令 $H=X(X^{\\top}X)^{-1}X^{\\top}$ 为帽子矩阵，$h_{ii}$ 为其对角线元素（杠杆值），$e=(I-H)y$ 为残差向量。\n\n仅使用 OLS 和帽子矩阵的核心定义，并且不使用任何现成的快捷公式，对重复设计 $X_{\\text{after}}$ 进行以下操作：推导重复行的杠杆值，并通过 $e=(I-H)y$ 解释 $X$ 中的相同行如何约束这些索引的拟合值和残差。作为比较的基准，也计算 $X_{\\text{before}}$ 的杠杆值 $h_{22}$。\n\n你的最终任务是报告由重复引起的重复协变量模式的杠杆值的确切变化，定义为\n$$\n\\Delta h \\equiv h_{22}^{(\\text{after})}-h_{22}^{(\\text{before})}.\n$$\n将最终答案表示为精确分数。不需要四舍五入。",
            "solution": "按要求，分析分三部分进行。首先，我们计算初始设计中指定观测值的杠杆值。其次，我们对重复设计进行相同的计算，并解释其对模型的拟合值和残差产生的约束。最后，我们计算杠杆值的变化。\n\n帽子矩阵定义为 $H=X(X^{\\top}X)^{-1}X^{\\top}$，其中 $X$ 是设计矩阵。第 $i$ 个观测值的杠杆值 $h_{ii}$ 是 $H$ 的第 $i$ 个对角线元素。它可以直接计算为 $h_{ii} = x_i^{\\top}(X^{\\top}X)^{-1}x_i$，其中 $x_i^{\\top}$ 是 $X$ 的第 $i$ 行。\n\n**1. 初始设计 ($X_{\\text{before}}$) 的杠杆值计算**\n\n初始设计矩阵由下式给出：\n$$\nX_{\\text{before}} = \\begin{pmatrix}\n1  0 \\\\\n1  1 \\\\\n1  2\n\\end{pmatrix}\n$$\n首先，我们计算矩阵 $X_{\\text{before}}^{\\top}X_{\\text{before}}$：\n$$\nX_{\\text{before}}^{\\top}X_{\\text{before}} = \\begin{pmatrix}\n1  1  1 \\\\\n0  1  2\n\\end{pmatrix}\n\\begin{pmatrix}\n1  0 \\\\\n1  1 \\\\\n1  2\n\\end{pmatrix}\n= \\begin{pmatrix}\n1 \\cdot 1 + 1 \\cdot 1 + 1 \\cdot 1  1 \\cdot 0 + 1 \\cdot 1 + 1 \\cdot 2 \\\\\n0 \\cdot 1 + 1 \\cdot 1 + 2 \\cdot 1  0 \\cdot 0 + 1 \\cdot 1 + 2 \\cdot 2\n\\end{pmatrix}\n= \\begin{pmatrix}\n3  3 \\\\\n3  5\n\\end{pmatrix}\n$$\n接下来，我们求该矩阵的逆。行列式为 $\\det(X_{\\text{before}}^{\\top}X_{\\text{before}}) = (3)(5) - (3)(3) = 15 - 9 = 6$。\n逆矩阵为：\n$$\n(X_{\\text{before}}^{\\top}X_{\\text{before}})^{-1} = \\frac{1}{6}\n\\begin{pmatrix}\n5  -3 \\\\\n-3  3\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\frac{5}{6}  -\\frac{1}{2} \\\\\n-\\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}\n$$\n题目要求我们计算杠杆值 $h_{22}^{(\\text{before})}$。$X_{\\text{before}}$ 的第二行是 $x_2^{\\top} = \\begin{pmatrix} 1  1 \\end{pmatrix}$。\n$$\nh_{22}^{(\\text{before})} = x_2^{\\top}(X_{\\text{before}}^{\\top}X_{\\text{before}})^{-1}x_2 =\n\\begin{pmatrix}\n1  1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\frac{5}{6}  -\\frac{1}{2} \\\\\n-\\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 \\\\\n1\n\\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix}\n1 \\cdot \\frac{5}{6} + 1 \\cdot (-\\frac{1}{2})  1 \\cdot (-\\frac{1}{2}) + 1 \\cdot \\frac{1}{2}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 \\\\\n1\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\frac{5}{6} - \\frac{3}{6}  0\n\\end{pmatrix}\n\\begin{pmatrix}\n1 \\\\\n1\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\frac{2}{6}  0\n\\end{pmatrix}\n\\begin{pmatrix}\n1 \\\\\n1\n\\end{pmatrix}\n= \\frac{1}{3}\n$$\n因此，原始设计中第二个观测值的杠杆值为 $h_{22}^{(\\text{before})} = \\frac{1}{3}$。\n\n**2. 重复设计 ($X_{\\text{after}}$) 的杠杆值和约束**\n\n重复设计矩阵为：\n$$\nX_{\\text{after}} = \\begin{pmatrix}\n1  0 \\\\\n1  1 \\\\\n1  2 \\\\\n1  1\n\\end{pmatrix}\n$$\n相应的响应向量是 $y_{\\text{after}} = \\begin{pmatrix} 1  3  2  5 \\end{pmatrix}^{\\top}$。$X_{\\text{after}}$ 的第 2 行和第 4 行是相同的。\n我们计算 $X_{\\text{after}}^{\\top}X_{\\text{after}}$：\n$$\nX_{\\text{after}}^{\\top}X_{\\text{after}} = \\begin{pmatrix}\n1  1  1  1 \\\\\n0  1  2  1\n\\end{pmatrix}\n\\begin{pmatrix}\n1  0 \\\\\n1  1 \\\\\n1  2 \\\\\n1  1\n\\end{pmatrix}\n= \\begin{pmatrix}\n4  4 \\\\\n4  6\n\\end{pmatrix}\n$$\n行列式为 $\\det(X_{\\text{after}}^{\\top}X_{\\text{after}}) = (4)(6) - (4)(4) = 24 - 16 = 8$。\n逆矩阵为：\n$$\n(X_{\\text{after}}^{\\top}X_{\\text{after}})^{-1} = \\frac{1}{8}\n\\begin{pmatrix}\n6  -4 \\\\\n-4  4\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\frac{3}{4}  -\\frac{1}{2} \\\\\n-\\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}\n$$\n重复的行是 $x_2^{\\top} = x_4^{\\top} = \\begin{pmatrix} 1  1 \\end{pmatrix}$。它们的杠杆值 $h_{22}^{(\\text{after})}$ 和 $h_{44}^{(\\text{after})}$ 必然相等。我们计算这个值：\n$$\nh_{22}^{(\\text{after})} = h_{44}^{(\\text{after})} =\n\\begin{pmatrix}\n1  1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\frac{3}{4}  -\\frac{1}{2} \\\\\n-\\frac{1}{2}  \\frac{1}{2}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 \\\\\n1\n\\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix}\n\\frac{3}{4} - \\frac{1}{2}  -\\frac{1}{2} + \\frac{1}{2}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 \\\\\n1\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\frac{1}{4}  0\n\\end{pmatrix}\n\\begin{pmatrix}\n1 \\\\\n1\n\\end{pmatrix}\n= \\frac{1}{4}\n$$\n重复行的杠杆值为 $h_{22}^{(\\text{after})} = h_{44}^{(\\text{after})} = \\frac{1}{4}$。\n\n现在我们来解释对拟合值和残差的约束。设 $x_i^{\\top}$ 和 $x_j^{\\top}$ 是设计矩阵 $X$ 的两个相同行。第 $k$ 个观测值的拟合值为 $\\hat{y}_k = x_k^{\\top}\\hat{\\beta}$，其中 $\\hat{\\beta} = (X^{\\top}X)^{-1}X^{\\top}y$。由于 $x_i^{\\top}=x_j^{\\top}$，很明显它们的拟合值必然相同：\n$$\n\\hat{y}_i = x_i^{\\top}\\hat{\\beta} = x_j^{\\top}\\hat{\\beta} = \\hat{y}_j\n$$\n这是 $X$ 中重复行施加的主要约束：模型必须对每个重复点产生相同的预测。\n\n这也可以通过帽子矩阵 $H$ 来解释。$H$ 的第 $(k, l)$ 个元素是 $H_{kl} = x_k^{\\top}(X^{\\top}X)^{-1}x_l$。如果 $x_i^{\\top} = x_j^{\\top}$，那么对于任何列索引 $l \\in \\{1, \\dots, n\\}$，我们有 $H_{il} = x_i^{\\top}(X^{\\top}X)^{-1}x_l = x_j^{\\top}(X^{\\top}X)^{-1}x_l = H_{jl}$。这意味着帽子矩阵的第 $i$ 行和第 $j$ 行是相同的。\n拟合值由向量 $\\hat{y} = Hy$ 给出。第 $i$ 个分量是 $\\hat{y}_i = \\sum_{l=1}^n H_{il}y_l$，第 $j$ 个分量是 $\\hat{y}_j = \\sum_{l=1}^n H_{jl}y_l$。由于第 $i$ 行 $H_{i\\cdot}$ 和第 $j$ 行 $H_{j\\cdot}$ 相同，因此必然有 $\\hat{y}_i = \\hat{y}_j$。对于我们的问题，这意味着 $\\hat{y}_2 = \\hat{y}_4$。\n\n残差定义为 $e = (I-H)y$，或者按元素表示为 $e_k = y_k - \\hat{y}_k$。对于重复的索引 $i$ 和 $j$，我们有：\n$$\ne_i = y_i - \\hat{y}_i\n$$\n$$\ne_j = y_j - \\hat{y}_j\n$$\n由于 $\\hat{y}_i = \\hat{y}_j$，观测响应 $y_i$ 和 $y_j$ 之间的任何差异都直接转移到残差上：\n$$\ne_i - e_j = (y_i - \\hat{y}_i) - (y_j - \\hat{y}_j) = y_i - y_j\n$$\n在给定的问题中，$y_2 = 3$ 且 $y_4 = 5$，我们发现 $\\hat{y}_2 = \\hat{y}_4$。我们可以计算出该值为 $\\hat{y} = 11/4$。残差为 $e_2 = 3 - \\frac{11}{4} = \\frac{1}{4}$ 和 $e_4 = 5 - \\frac{11}{4} = \\frac{9}{4}$。它们的差为 $e_2 - e_4 = \\frac{1}{4} - \\frac{9}{4} = -\\frac{8}{4} = -2$，这等于 $y_2 - y_4 = 3 - 5 = -2$。\n\n**3. 杠杆值的变化 ($\\Delta h$)**\n\n最后的任务是计算重复协变量模式的杠杆值变化。\n$$\n\\Delta h = h_{22}^{(\\text{after})} - h_{22}^{(\\text{before})}\n$$\n使用上面推导出的值：\n$$\n\\Delta h = \\frac{1}{4} - \\frac{1}{3} = \\frac{3}{12} - \\frac{4}{12} = -\\frac{1}{12}\n$$\n重复协变量为 $x=1$ 的观测值导致该协变量值上每个单独点的杠杆值都减小。",
            "answer": "$$\n\\boxed{-\\frac{1}{12}}\n$$"
        },
        {
            "introduction": "我们已经探讨了杠杆值和残差，但回归诊断的最终目标之一是识别“强影响点”。一个拥有高杠杆值的点就一定具有强影响力吗？ 这个综合性练习将揭示答案。我们将构建一个包含明确高杠杆点的数据集，并展示该点的影响力（以库克距离衡量）可以微不足道，也可以极其巨大，而这完全取决于其残差的大小。这个实践将帮助我们巩固杠杆值与影响力之间至关重要的区别，这是现代回归诊断的基石。",
            "id": "3183419",
            "problem": "在一个固定的线性回归设置中，考虑一个设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$，该矩阵在普通最小二乘 (OLS) 框架下具有满列秩。在此框架中，拟合值是通过应用一个线性投影将观测到的响应映射到 $X$ 的列空间得到的。相关投影（帽子）矩阵的对角线元素量化了杠杆值。一个高杠杆值的观测点具有较大的对角线元素 $h_{ii}$，而回归诊断则通过关联残差的大小和杠杆值来检测影响点。您的任务是构建一个小的、明确的数据集，其中单个观测点具有约 $h_{ii} \\approx 0.9$ 的杠杆值，然后计算诊断统计量以说明杠杆值如何与残差大小相互作用。\n\n请使用以下具体设置以确保科学真实性和可复现性。设 $n = 6$ 和 $p = 2$（一个截距项和一个预测变量），并定义预测变量值为\n$$x = [-8,\\,-1,\\,0,\\,1,\\,2,\\,3],$$\n并附加一列截距项以形成 $X = [\\mathbf{1},\\,x]$。这一选择使得第一个观测点成为一个高杠杆点。设真实的线性关系为 $y = \\alpha + \\beta x$，其中 $\\alpha = 1.0$ 和 $\\beta = 0.5$。为非高杠杆的观测点（索引 2 到 6）引入小的、固定的扰动以避免退化方差：将索引为 $i = 2,3,4,5,6$ 的噪声向量设置为\n$$\\nu = [0.1,\\,-0.05,\\,0.0,\\,0.03,\\,-0.02],$$\n因此对于 $i \\in \\{2,3,4,5,6\\}$，$y_i = \\alpha + \\beta x_i + \\nu_{i-1}$，而对于 $i=1$，$y_1 = \\alpha + \\beta x_1 + \\epsilon$，其中 $\\epsilon$ 是高杠杆点处的一个受控残差。\n\n请根据第一性原理和核心定义（OLS 的投影解释、杠杆值作为帽子矩阵的对角线元素、残差作为观测值与拟合值之差，以及回归诊断中使用的常规学生化方法），计算观测点 $i=1$ 的以下诊断统计量：\n- 杠杆值 $h_{11}$，\n- 学生化残差（使用内部学生化残差的定义），\n- Cook 距离。\n\n不要使用绕过从所述基础进行推导的快捷公式。所有计算必须与 OLS 框架一致，并使用上述指定的 $n$ 和 $p$。\n\n测试套件：\n在高杠杆点的受控残差取以下五个值时评估诊断统计量：$\\epsilon \\in \\{0.0,\\,1.0,\\,-1.0,\\,8.0,\\,30.0\\}$，同时保持所有其他分量（$X$、$\\alpha$、$\\beta$ 和 $\\nu$）固定不变。对于每个 $\\epsilon$ 的选择，相应地构建 $y$ 并计算 $i=1$ 所需的诊断统计量。\n\n答案规格：\n对于每个测试用例（每个 $\\epsilon$），您的程序必须按顺序输出一个包含三个浮点数的列表：$[h_{11},\\,\\text{i=1 处的学生化残差},\\,\\text{i=1 处的 Cook 距离}]$。将所有五个测试用例的结果汇总到一个列表中，顺序与上述 $\\epsilon$ 值的顺序相同。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。聚合列表必须包含五个按用例划分的列表，每个列表本身都是一个用方括号括起来的逗号分隔列表。例如，输出应具有以下形式：\n$$[\\,[h_{11}^{(1)},\\,r^{(1)},\\,D^{(1)}],\\,[h_{11}^{(2)},\\,r^{(2)},\\,D^{(2)}],\\,[h_{11}^{(3)},\\,r^{(3)},\\,D^{(3)}],\\,[h_{11}^{(4)},\\,r^{(4)},\\,D^{(4)}],\\,[h_{11}^{(5)},\\,r^{(5)},\\,D^{(5)}]\\,],$$\n所有数值均表示为普通十进制浮点数。不适用任何物理单位或角度单位，任何分数都必须以小数形式提供。",
            "solution": "该问题经评估是有效的，因为它科学地基于普通最小二乘 (OLS) 回归的原理，问题设定良好，具有完整且一致的给定条件，并且其表述是客观的。所有提供的数据和定义都是统计学习领域的标准。\n\n解决方案按要求从第一性原理出发。我们将首先构建必要的矩阵和向量，然后推导所需诊断统计量（杠杆值、学生化残差和 Cook 距离）作为受控残差 $\\epsilon$ 的函数表达式。\n\n**1. 设置和给定条件**\n\n该问题是一个线性回归，有 $n=6$ 个观测值和 $p=2$ 个参数（一个截距项和一个预测变量）。预测变量的值由向量 $x$ 给出：\n$$ x = \\begin{pmatrix} -8 \\\\ -1 \\\\ 0 \\\\ 1 \\\\ 2 \\\\ 3 \\end{pmatrix} $$\n设计矩阵 $X \\in \\mathbb{R}^{6 \\times 2}$ 是通过在前面添加一列全为 1 的截距项构成的：\n$$ X = \\begin{pmatrix} 1  -8 \\\\ 1  -1 \\\\ 1  0 \\\\ 1  1 \\\\ 1  2 \\\\ 1  3 \\end{pmatrix} $$\n响应向量 $y \\in \\mathbb{R}^6$ 是由一个真实线性模型 $y = \\alpha + \\beta x$（其中 $\\alpha=1.0$ 和 $\\beta=0.5$）加上一些噪声生成的。对于观测值 $i = 2, \\dots, 6$，噪声由向量 $\\nu = [0.1, -0.05, 0.0, 0.03, -0.02]$ 固定。对于观测值 $i=1$，噪声是一个变量 $\\epsilon$。\n因此，响应向量 $y$ 为：\n$$ y_i = \\begin{cases} (1.0 + 0.5x_1) + \\epsilon = -3.0 + \\epsilon  \\text{若 } i=1 \\\\ (1.0 + 0.5x_i) + \\nu_{i-1}  \\text{若 } i \\in \\{2, \\dots, 6\\} \\end{cases} $$\n这得到了向量 $y$ 作为 $\\epsilon$ 的函数：\n$$ y(\\epsilon) = \\begin{pmatrix} -3.0 + \\epsilon \\\\ 0.6 \\\\ 0.95 \\\\ 1.5 \\\\ 2.03 \\\\ 2.48 \\end{pmatrix} $$\n\n**2. 杠杆值 ($h_{11}$)**\n\n杠杆值由帽子矩阵 $H$ 的对角线元素 $h_{ii}$ 来量化。帽子矩阵是将观测响应向量 $y$ 映射到拟合值 $\\hat{y}$ 的投影矩阵：\n$$ \\hat{y} = H y $$\n其中 $H$ 定义为：\n$$ H = X(X^T X)^{-1} X^T $$\n第 $i$ 个观测值的杠杆值是 $h_{ii} = x_i^T (X^T X)^{-1} x_i$，其中 $x_i^T$ 是 $X$ 的第 $i$ 行。关键在于，$H$ 及其对角线元素仅取决于设计矩阵 $X$，而不取决于响应向量 $y$。因此，$h_{11}$ 在所有测试用例中都将是常数。\n\n首先，我们计算 $X^T X$：\n$$ X^T X = \\begin{pmatrix} 1  1  1  1  1  1 \\\\ -8  -1  0  1  2  3 \\end{pmatrix} \\begin{pmatrix} 1  -8 \\\\ 1  -1 \\\\ 1  0 \\\\ 1  1 \\\\ 1  2 \\\\ 1  3 \\end{pmatrix} = \\begin{pmatrix} 6  -3 \\\\ -3  79 \\end{pmatrix} $$\n接下来，我们求其逆矩阵 $(X^T X)^{-1}$：\n$$ \\det(X^T X) = (6)(79) - (-3)(-3) = 474 - 9 = 465 $$\n$$ (X^T X)^{-1} = \\frac{1}{465} \\begin{pmatrix} 79  3 \\\\ 3  6 \\end{pmatrix} $$\n第一个观测值对应于 $X$ 的第一行，$x_1^T = \\begin{pmatrix} 1  -8 \\end{pmatrix}$。现在我们可以计算杠杆值 $h_{11}$：\n$$ h_{11} = x_1^T (X^T X)^{-1} x_1 = \\begin{pmatrix} 1  -8 \\end{pmatrix} \\frac{1}{465} \\begin{pmatrix} 79  3 \\\\ 3  6 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -8 \\end{pmatrix} $$\n$$ h_{11} = \\frac{1}{465} \\begin{pmatrix} 1  -8 \\end{pmatrix} \\begin{pmatrix} 79(1) + 3(-8) \\\\ 3(1) + 6(-8) \\end{pmatrix} = \\frac{1}{465} \\begin{pmatrix} 1  -8 \\end{pmatrix} \\begin{pmatrix} 55 \\\\ -45 \\end{pmatrix} $$\n$$ h_{11} = \\frac{1(55) - 8(-45)}{465} = \\frac{55 + 360}{465} = \\frac{415}{465} \\approx 0.89247 $$\n这个接近于 1 的高杠杆值证实了第一个观测值是预测变量空间中的一个离群点，将对其自身的拟合值产生强烈影响。\n\n**3. 残差和学生化**\n\nOLS 残差向量为 $e = y - \\hat{y} = y - Hy = (I-H)y$。第 $i$ 个残差是 $e_i$。\n令 $y_0$ 为 $\\epsilon=0$ 时的响应向量。对于一般的 $\\epsilon$，响应向量可以写成 $y(\\epsilon) = y_0 + \\delta$，其中 $\\delta = [\\epsilon, 0, 0, 0, 0, 0]^T$。\n残差向量则为 $e(\\epsilon) = (I-H)(y_0+\\delta) = (I-H)y_0 + (I-H)\\delta = e_0 + (I-H)\\delta$。\n向量 $(I-H)\\delta$ 的第 $i$ 个分量等于 $(1-h_{ii})\\delta_i - \\sum_{j \\neq i} h_{ij}\\delta_j$。由于只有 $\\delta_1 = \\epsilon$ 非零，第一个残差是：\n$$ e_1(\\epsilon) = e_{1,0} + (1-h_{11})\\epsilon $$\n其中 $e_{1,0}$ 是当 $\\epsilon=0$ 时观测值 1 的残差。\n总残差平方和 (RSS) 是 $e^T e$。经过类似的推导，可以证明 RSS 是 $\\epsilon$ 的一个二次函数：\n$$ \\text{RSS}(\\epsilon) = e(\\epsilon)^T e(\\epsilon) = (e_0 + (I-H)\\delta)^T(e_0 + (I-H)\\delta) = e_0^T e_0 + 2e_0^T(I-H)\\delta + \\delta^T(I-H)^T(I-H)\\delta $$\n利用 $e_0^T(I-H) = e_0^T$ 以及 $(I-H)$ 是对称和幂等的性质，这可以简化为：\n$$ \\text{RSS}(\\epsilon) = \\text{RSS}_0 + 2e_{1,0}\\epsilon + (1-h_{11})\\epsilon^2 $$\n其中 $\\text{RSS}_0$ 是 $\\epsilon=0$ 时的残差平方和。\n\n观测值 $i$ 的（内部）学生化残差定义为：\n$$ r_i = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_{ii}}} $$\n其中 $\\hat{\\sigma}^2 = \\text{MSE} = \\text{RSS}/(n-p)$ 是均方误差。在我们的案例中，$n-p = 6-2=4$。\n因此，对于观测值 1：\n$$ r_1(\\epsilon) = \\frac{e_1(\\epsilon)}{\\sqrt{\\text{RSS}(\\epsilon)/(n-p)} \\sqrt{1-h_{11}}} $$\n\n**4. Cook 距离**\n\nCook 距离 $D_i$ 衡量删除观测值 $i$ 的影响。它可以从杠杆值和学生化残差计算得出：\n$$ D_i = \\frac{r_i^2}{p} \\frac{h_{ii}}{1-h_{ii}} $$\n对于观测值 1：\n$$ D_1(\\epsilon) = \\frac{r_1(\\epsilon)^2}{2} \\frac{h_{11}}{1-h_{11}} = \\frac{r_1(\\epsilon)^2}{2} \\frac{415/465}{50/465} = \\frac{r_1(\\epsilon)^2}{2} \\frac{415}{50} = 4.15 \\cdot r_1(\\epsilon)^2 $$\n\n**5. 计算**\n\n为了计算每个 $\\epsilon$ 的诊断统计量，我们首先计算 $\\epsilon=0$ 时的基线量。\n- $y_0 = [-3.0, 0.6, 0.95, 1.5, 2.03, 2.48]^T$。\n- OLS 系数为 $\\hat{\\beta}_{\\text{vec},0} = (X^T X)^{-1} X^T y_0$，得出 $\\hat{\\alpha}_0 \\approx 1.00955$ 和 $\\hat{\\beta}_0 \\approx 0.49910$。\n- 计算残差 $e_0 = y_0 - X\\hat{\\beta}_{\\text{vec},0}$，从中我们发现 $e_{1,0} = -7.8/465 \\approx -0.01677$ 和 $\\text{RSS}_0 = \\sum_{i=1}^6 e_{i,0}^2 \\approx 0.013137$。\n\n对于每个给定的 $\\epsilon \\in \\{0.0, 1.0, -1.0, 8.0, 30.0\\}$，我们计算：\n1. $h_{11} = 415/465$。\n2. $e_1(\\epsilon) = e_{1,0} + (1-h_{11})\\epsilon$。\n3. $\\text{RSS}(\\epsilon) = \\text{RSS}_0 + 2e_{1,0}\\epsilon + (1-h_{11})\\epsilon^2$。\n4. $r_1(\\epsilon) = \\frac{e_1(\\epsilon)}{\\sqrt{\\text{RSS}(\\epsilon)/4} \\sqrt{1-h_{11}}}$。\n5. $D_1(\\epsilon) = 4.15 \\cdot r_1(\\epsilon)^2$。\n\n这些计算在提供的程序中以数值方式执行。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes regression diagnostics for a high-leverage point under different\n    residual magnitudes.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases_epsilon = [0.0, 1.0, -1.0, 8.0, 30.0]\n\n    # --- Step 1: Setup and Givens ---\n    n = 6\n    p = 2\n    x_vec = np.array([-8.0, -1.0, 0.0, 1.0, 2.0, 3.0])\n    \n    # Design Matrix X\n    X = np.ones((n, p))\n    X[:, 1] = x_vec\n\n    # True model parameters\n    alpha_true = 1.0\n    beta_true = 0.5\n\n    # Noise for observations 2 through 6\n    nu = np.array([0.1, -0.05, 0.0, 0.03, -0.02])\n\n    # --- Step 2: Leverage Calculation (independent of y) ---\n    # Compute h_11 from H = X(X^T X)^-1 X^T\n    XTX = X.T @ X\n    XTX_inv = np.linalg.inv(XTX)\n    x1_row = X[0, :].reshape(1, -1)\n    h_11 = (x1_row @ XTX_inv @ x1_row.T)[0, 0]\n\n    # --- Step 3  4: Baseline Calculations for epsilon = 0 ---\n    # Construct response vector y for epsilon = 0\n    y0 = np.zeros(n)\n    y_true = alpha_true + beta_true * x_vec\n    y0[0] = y_true[0]  # Epsilon is 0\n    y0[1:] = y_true[1:] + nu\n    \n    # OLS coefficients for epsilon = 0\n    beta_hat_0 = XTX_inv @ X.T @ y0\n    \n    # Residuals for epsilon = 0\n    e_0 = y0 - X @ beta_hat_0\n    e_1_0 = e_0[0]\n    \n    # RSS for epsilon = 0\n    rss_0 = e_0.T @ e_0\n\n    results = []\n    # --- Main Loop over test cases ---\n    for epsilon in test_cases_epsilon:\n        \n        # Calculate diagnostics based on derived formulas\n        # e_1(eps) = e_1_0 + (1-h_11)*eps\n        # RSS(eps) = RSS_0 + 2*e_1_0*eps + (1-h_11)*eps^2\n        \n        e_1 = e_1_0 + (1.0 - h_11) * epsilon\n        \n        rss = rss_0 + 2.0 * e_1_0 * epsilon + (1.0 - h_11) * epsilon**2\n        \n        # Mean Squared Error (MSE) and Residual Standard Error (sigma_hat)\n        mse = rss / (n - p)\n        if mse  0: # Should not happen in this problem\n             mse = 0\n        sigma_hat = np.sqrt(mse)\n        \n        # Internally Studentized Residual r_1\n        # r_1 = e_1 / (sigma_hat * sqrt(1-h_11))\n        # Account for sigma_hat = 0 in degenerate cases\n        denom = sigma_hat * np.sqrt(1.0 - h_11)\n        if np.isclose(denom, 0.0):\n            r_1 = np.inf if e_1 > 0 else -np.inf if e_1  0 else 0.0\n        else:\n            r_1 = e_1 / denom\n            \n        # Cook's Distance D_1\n        # D_1 = (r_1^2 / p) * (h_11 / (1-h_11))\n        D_1 = (r_1**2 / p) * (h_11 / (1.0 - h_11))\n        \n        case_result = [h_11, r_1, D_1]\n        results.append(case_result)\n\n    # --- Final Output Formatting ---\n    # Format each inner list into a string \"[v1,v2,v3]\"\n    inner_lists_str = [f\"[{','.join(map(str, res))}]\" for res in results]\n    # Join the inner list strings with commas and wrap in brackets\n    final_output_str = f\"[{','.join(inner_lists_str)}]\"\n    \n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}