{
    "hands_on_practices": [
        {
            "introduction": "在实践中，经验AUC（曲线下面积）可以通过多种方式计算。本练习旨在通过第一性原理证明两种最常见的计算方法——基于Mann-Whitney U统计量的概率方法和基于几何梯形法则的方法——在代数上是等价的 ()。通过这个练习，你将加深对AUC本质的理解，并建立起其概率解释与几何解释之间的桥梁。",
            "id": "3167034",
            "problem": "一个二元分类器为每个实例分配一个实值分数。有 $n$ 个正实例和 $m$ 个负实例，其中 $n \\geq 1$ 且 $m \\geq 1$。考虑以下两种受试者工作特征（ROC）曲线下面积的经验估计量。\n\n1. 通过曼-惠特尼（Mann–Whitney）统计量将经验曲线下面积（AUC）定义为\n$$\nA_{\\mathrm{MW}} \\;=\\; \\frac{1}{nm} \\sum_{i=1}^{n} \\sum_{j=1}^{m} \\left[ \\mathbf{1}\\big(s_{i}^{+}  s_{j}^{-}\\big) \\;+\\; \\frac{1}{2}\\,\\mathbf{1}\\big(s_{i}^{+} = s_{j}^{-}\\big) \\right],\n$$\n其中 $s_{i}^{+}$ 表示第 $i$ 个正实例的分数，$s_{j}^{-}$ 表示第 $j$ 个负实例的分数，$\\mathbf{1}(\\cdot)$ 是指示函数。\n\n2. 通过将所有实例按其分数的非递增顺序排序，并将它们分组为分数相同的块来构建经验ROC曲线。假设有 $B$ 个不同的分数级别；在级别 $b \\in \\{1,\\dots,B\\}$，有 $t_{b}$ 个正实例和 $u_{b}$ 个负实例，满足 $\\sum_{b=1}^{B} t_{b} = n$ 和 $\\sum_{b=1}^{B} u_{b} = m$。令块 $b$ 之前的累积假阳性率和真阳性率为\n$$\nx_{b-1} \\;=\\; \\frac{1}{m} \\sum_{a=1}^{b-1} u_{a}, \\qquad\ny_{b-1} \\;=\\; \\frac{1}{n} \\sum_{a=1}^{b-1} t_{a},\n$$\n块 $b$ 之后的累积假阳性率和真阳性率为\n$$\nx_{b} \\;=\\; x_{b-1} + \\frac{u_{b}}{m}, \\qquad\ny_{b} \\;=\\; y_{b-1} + \\frac{t_{b}}{n}.\n$$\n将在这些 $B+1$ 个点 $\\{(x_{b},y_{b})\\}_{b=0}^{B}$ 上的梯形法则AUC定义为\n$$\nA_{\\mathrm{trap}} \\;=\\; \\sum_{b=1}^{B} \\frac{y_{b-1} + y_{b}}{2} \\,\\big(x_{b} - x_{b-1}\\big).\n$$\n\n将分数 $\\{s_{i}^{+}\\}$ 和 $\\{s_{j}^{-}\\}$ 视为任意实数，它们决定了块大小 $\\{t_{b}\\}$ 和 $\\{u_{b}\\}$ 及其顺序。在所有可能的分数分配（等价于，在所有与 $n$ 和 $m$ 一致的可能 $\\{t_{b},u_{b}\\}_{b=1}^{B}$ 以及所有可能的块顺序）上，计算这两个AUC估计量之间绝对差异的上确界，\n$$\n\\sup \\left| A_{\\mathrm{MW}} \\,-\\, A_{\\mathrm{trap}} \\right|.\n$$\n\n你的最终答案必须是一个实数值。不需要四舍五入。",
            "solution": "问题要求计算ROC曲线下面积（AUC）的两个估计量——一个基于曼-惠特尼统计量 $A_{\\mathrm{MW}}$，另一个基于梯形法则 $A_{\\mathrm{trap}}$——之间绝对差的上确界。该上确界是在对 $n$ 个正实例和 $m$ 个负实例所有可能的分数分配上取。\n\n我们的策略是将 $A_{\\mathrm{MW}}$ 和 $A_{\\mathrm{trap}}$ 都表示为一个共同的、依赖于排序后分数结构的代数形式。当所有 $n+m$ 个分数按非递增顺序排序时，任何分数 $\\{s_i^+\\}$ 和 $\\{s_j^-\\}$ 的分配都会产生一个特定的、由分数并列的块组成的序列。假设有 $B$ 个这样的块，索引为 $b=1, \\dots, B$，对应于不同的分数值 $S_1  S_2  \\dots  S_B$。令块 $b$ 包含 $t_b$ 个正实例和 $u_b$ 个负实例。正实例和负实例的总数是守恒的，因此我们有约束条件 $\\sum_{b=1}^{B} t_b = n$ 和 $\\sum_{b=1}^{B} u_b = m$。该问题等价于在所有可能的分区 $\\{t_b, u_b\\}_{b=1}^B$ 及其顺序上，找到 $|A_{\\mathrm{MW}} - A_{\\mathrm{trap}}|$ 的上确界。\n\n首先，我们来分析梯形法则估计量 $A_{\\mathrm{trap}}$。\n它被定义为由经验ROC曲线上的点形成的梯形面积之和：\n$$\nA_{\\mathrm{trap}} \\;=\\; \\sum_{b=1}^{B} \\frac{y_{b-1} + y_{b}}{2} \\,\\big(x_{b} - x_{b-1}\\big).\n$$\nROC曲线的顶点是 $\\{(x_b, y_b)\\}_{b=0}^B$，其中 $(x_0, y_0) = (0,0)$。点 $(x_b, y_b)$ 表示在考虑了所有分数大于或等于 $S_b$ 的实例之后的累积假阳性率（FPR）和真阳性率（TPR）。\n第 $b$ 个梯形的宽度是由于块 $b$ 中的实例引起的FPR变化：\n$$\nx_b - x_{b-1} = \\frac{u_b}{m}.\n$$\n第 $b$ 个梯形的高度从 $y_{b-1}$ 变为 $y_b$。平均高度为 $\\frac{y_{b-1} + y_b}{2}$。我们可以用 $y_{b-1}$ 和块 $b$ 中正实例的数量 $t_b$ 来表示 $y_b$：\n$$\ny_b = y_{b-1} + \\frac{t_b}{n}.\n$$\n将此代入平均高度的表达式中，得到：\n$$\n\\frac{y_{b-1} + y_b}{2} = \\frac{y_{b-1} + (y_{b-1} + t_b/n)}{2} = y_{b-1} + \\frac{t_b}{2n}.\n$$\n点 $b-1$ 处的TPR，$y_{b-1}$，是分数更高的块（即块 $a=1, \\ldots, b-1$）中正实例的累积和：\n$$\ny_{b-1} = \\frac{1}{n} \\sum_{a=1}^{b-1} t_a.\n$$\n现在，我们将这些代回到 $A_{\\mathrm{trap}}$ 的公式中：\n$$\nA_{\\mathrm{trap}} = \\sum_{b=1}^{B} \\left( \\frac{1}{n} \\sum_{a=1}^{b-1} t_a + \\frac{t_b}{2n} \\right) \\left( \\frac{u_b}{m} \\right).\n$$\n提出常数 $n$ 和 $m$，我们得到 $A_{\\mathrm{trap}}$ 的一个简化表达式：\n$$\nA_{\\mathrm{trap}} = \\frac{1}{nm} \\sum_{b=1}^{B} u_b \\left( \\sum_{a=1}^{b-1} t_a + \\frac{t_b}{2} \\right).\n$$\n\n接下来，我们分析曼-惠特尼估计量 $A_{\\mathrm{MW}}$。\n它通过对所有可能的一个正实例和一个负实例对进行平均来定义：\n$$\nA_{\\mathrm{MW}} \\;=\\; \\frac{1}{nm} \\sum_{i=1}^{n} \\sum_{j=1}^{m} \\left[ \\mathbf{1}\\big(s_{i}^{+}  s_{j}^{-}\\big) \\;+\\; \\frac{1}{2}\\,\\mathbf{1}\\big(s_{i}^{+} = s_{j}^{-}\\big) \\right].\n$$\n项 $\\mathbf{1}(s_i^+  s_j^-) + \\frac{1}{2}\\mathbf{1}(s_i^+ = s_j^-)$ 可以解释为正实例 $i$ 和负实例 $j$ 的分数比较结果，其中正实例获胜得1分，平局得 $\\frac{1}{2}$ 分，失败得0分。\n为了简化这个表达式，我们可以改变求和的顺序，并按分数块对各项进行分组。让我们首先对负实例 $j$ 求和：\n$$\nA_{\\mathrm{MW}} = \\frac{1}{m} \\sum_{j=1}^{m} \\left[ \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\mathbf{1}(s_{i}^{+}  s_{j}^{-}) + \\frac{1}{2}\\mathbf{1}(s_{i}^{+} = s_{j}^{-}) \\right) \\right].\n$$\n考虑一个属于块 $b$ 的负实例 $j$。它的分数是 $s_j^- = S_b$。关于 $i$ 的内层求和计算了满足 $s_i^+  S_b$ 的正实例数量，加上满足 $s_i^+ = S_b$ 的正实例数量的一半。\n分数 $s_i^+  S_b$ 的正实例是那些在块 $a=1, \\dots, b-1$ 中的实例。它们的总数是 $\\sum_{a=1}^{b-1} t_a$。\n分数 $s_i^+ = S_b$ 的正实例是那些在块 $b$ 中的实例。它们的数量是 $t_b$。\n因此，对于块 $b$ 中的任何负实例 $j$，关于 $i$ 的内层求和的值是：\n$$\n\\sum_{i=1}^{n} \\left( \\mathbf{1}(s_{i}^{+}  S_b) + \\frac{1}{2}\\mathbf{1}(s_{i}^{+} = S_b) \\right) = \\left(\\sum_{a=1}^{b-1} t_a\\right) \\cdot 1 + t_b \\cdot \\frac{1}{2}.\n$$\n由于块 $b$ 中有 $u_b$ 个负实例，它们的分数都相同，为 $S_b$，我们可以将关于 $j$ 的求和重写为关于块 $b$ 的求和：\n$$\n\\sum_{j=1}^{m} \\left[ \\sum_{i=1}^{n} \\left(\\dots\\right) \\right] = \\sum_{b=1}^{B} u_b \\left( \\sum_{a=1}^{b-1} t_a + \\frac{t_b}{2} \\right).\n$$\n将此代回到 $A_{\\mathrm{MW}}$ 的公式中：\n$$\nA_{\\mathrm{MW}} = \\frac{1}{nm} \\sum_{b=1}^{B} u_b \\left( \\sum_{a=1}^{b-1} t_a + \\frac{t_b}{2} \\right).\n$$\n通过比较推导出的表达式，我们发现\n$$\nA_{\\mathrm{trap}} = A_{\\mathrm{MW}} = \\frac{1}{nm} \\sum_{b=1}^{B} u_b \\left( \\sum_{a=1}^{b-1} t_a + \\frac{t_b}{2} \\right).\n$$\n这两个估计量在代数上是相同的。它们的相等性对任何分数的选择都成立，因为它只取决于块计数 $\\{t_b, u_b\\}$ 及其等级排序，而这些是由分数决定的。\n\n因此，对于任何可能的分数分配，这两个估计量之间的差总是零：\n$$\nA_{\\mathrm{MW}} - A_{\\mathrm{trap}} = 0.\n$$\n因此，绝对差异也总是零：\n$$\n| A_{\\mathrm{MW}} - A_{\\mathrm{trap}} | = 0.\n$$\n问题要求计算这个量在所有可能的分数分配上的上确界。由于该量是常数且等于 $0$，其上确界也为 $0$。\n$$\n\\sup \\left| A_{\\mathrm{MW}} \\,-\\, A_{\\mathrm{trap}} \\right| = \\sup \\{0\\} = 0.\n$$",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "在处理真实世界的数据时，正例和负例的得分常常会出现相同的情况（即“平局”）。我们如何处理这些平局会直接影响最终的AUC值。本练习通过引入一个广义的AUC公式，让你能够系统地探究平局的影响 ()。通过一个具体的计算案例和对该公式性质的分析，你将更深刻地理解标准AUC计算是如何隐式处理平局的，以及这一选择与该度量指标更广泛的特性之间有何关联。",
            "id": "3167068",
            "problem": "考虑一个二元分类情境，其中一个评分函数为每个实例分配一个实值分数 $S$。受试者工作特征（ROC）曲线绘制了当决策阈值 $\\tau$ 从 $+\\infty$ 扫描到 $-\\infty$ 时，真阳性率（TPR）相对于假阳性率（FPR）的变化情况，其中 $\\text{TPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=1)$ 且 $\\text{FPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=0)$。曲线下面积（AUC）是该 ROC 曲线下的面积。\n\n为了研究分数相同（ties）对曲线下面积的贡献，对于 $\\lambda \\in [0,1]$ 定义广义曲线下面积\n$$\nAUC_\\lambda \\;=\\; \\mathbb{P}(S^+  S^-) \\;+\\; \\lambda \\,\\mathbb{P}(S^+ = S^-),\n$$\n其中 $S^+$ 是一个随机选择的正实例的分数，$S^-$ 是一个随机选择的负实例的分数，这种随机性是在经验正、负样本集上均匀抽样，且两者之间相互独立。\n\n给定 $n_+ = 5$ 个正样本和 $n_- = 5$ 个负样本的分数：\n- 正样本：$S^+ \\in \\{0.2,\\,0.4,\\,0.6,\\,0.6,\\,0.8\\}$，\n- 负样本：$S^- \\in \\{0.1,\\,0.4,\\,0.4,\\,0.7,\\,0.9\\}$。\n\n首先，通过对所有 $n_+ n_- = 25$ 个正负样本对进行计数，并将其转换为概率，来为给定的列表计算 $\\mathbb{P}(S^+  S^-)$ 和 $\\mathbb{P}(S^+ = S^-)$。然后，使用这些概率值计算当 $\\lambda \\in \\{0,\\,1/2,\\,1\\}$ 时 $AUC_\\lambda$ 的值。\n\n选择所有正确的选项。\n\nA. 对于给定的分数，$AUC_{1/2} = 0.52$。\n\nB. 对于任何严格递增函数 $g:\\mathbb{R}\\to\\mathbb{R}$，对于所有 $\\lambda \\in [0,1]$，根据 $g(S)$ 计算的 $AUC_\\lambda$ 值与根据 $S$ 计算的值相同。\n\nC. 如果分数分布是连续的，使得 $\\mathbb{P}(S^+ = S^-)=0$，那么 $AUC_\\lambda$ 与 $\\lambda$ 无关，并且等于 $\\mathbb{P}(S^+  S^-)$。\n\nD. 通过扫描阈值并使用梯形法则得到的标准经验ROC曲线下面积对应于 $\\lambda = 1$。\n\nE. 对于固定的分数分布，$AUC_\\lambda$ 是 $\\lambda$ 的线性函数，其斜率为 $\\mathbb{P}(S^+ = S^-)$。",
            "solution": "问题陈述经核实具有科学依据、提法得当且客观。它为广义曲线下面积 $AUC_\\lambda$ 提供了清晰的定义，并给出了一个具体的数据集来执行计算和评估概念性陈述。陈述中没有矛盾、歧义或信息缺失。\n\n问题的核心是计算与分数比较相关的概率，然后分析 $AUC_\\lambda$ 函数的性质。\n\n首先，我们根据给定数据计算所需的概率。\n正样本分数集为 $S^+ \\in \\{0.2, 0.4, 0.6, 0.6, 0.8\\}$，其中 $n_+ = 5$。\n负样本分数集为 $S^- \\in \\{0.1, 0.4, 0.4, 0.7, 0.9\\}$，其中 $n_- = 5$。\n一个正实例和一个负实例组成的样本对总数为 $n_+ n_- = 5 \\times 5 = 25$。\n\n我们需要计算满足 $S^+  S^-$、$S^+ = S^-$ 和 $S^+  S^-$ 的配对 $(S^+, S^-)$ 的数量。我们可以对每个正样本分数系统地进行计算：\n- 对于 $S^+ = 0.2$：\n  - $0.2  0.1$（1 对）\n  - $0.2  0.4$（2 对）\n  - $0.2  0.7$（1 对）\n  - $0.2  0.9$（1 对）\n  - 对于 $S^+=0.2$ 的总计：1 对满足 $S^+  S^-$，0 对满足 $S^+ = S^-$。\n\n- 对于 $S^+ = 0.4$：\n  - $0.4  0.1$（1 对）\n  - $0.4 = 0.4$（2 对）\n  - $0.4  0.7$（1 对）\n  - $0.4  0.9$（1 对）\n  - 对于 $S^+=0.4$ 的总计：1 对满足 $S^+  S^-$，2 对满足 $S^+ = S^-$。\n\n- 对于两个分数为 $S^+ = 0.6$ 的每一个：\n  - $0.6  0.1$（1 对）\n  - $0.6  0.4$（2 对）\n  - $0.6  0.7$（1 对）\n  - $0.6  0.9$（1 对）\n  - 对于每个 $S^+=0.6$ 的总计：3 对满足 $S^+  S^-$，0 对满足 $S^+ = S^-$。\n  - 对于两个分数为 $0.6$ 的样本，共有 $2 \\times 3 = 6$ 对满足 $S^+  S^-$。\n\n- 对于 $S^+ = 0.8$：\n  - $0.8  0.1$（1 对）\n  - $0.8  0.4$（2 对）\n  - $0.8  0.7$（1 对）\n  - $0.8  0.9$（1 对）\n  - 对于 $S^+=0.8$ 的总计：4 对满足 $S^+  S^-$，0 对满足 $S^+ = S^-$。\n\n汇总这些计数：\n- 满足 $S^+  S^-$ 的总配对数：$1 + 1 + 6 + 4 = 12$。\n- 满足 $S^+ = S^-$ 的总配对数：$0 + 2 + 0 + 0 = 2$。\n- 剩余的配对必须满足 $S^+  S^-$，数量为 $25 - 12 - 2 = 11$。\n\n现在，我们将这些计数除以总配对数 25，转换为概率：\n$$\n\\mathbb{P}(S^+  S^-) = \\frac{12}{25} = 0.48\n$$\n$$\n\\mathbb{P}(S^+ = S^-) = \\frac{2}{25} = 0.08\n$$\n\n广义曲线下面积的公式为：\n$$\nAUC_\\lambda = \\mathbb{P}(S^+  S^-) + \\lambda \\mathbb{P}(S^+ = S^-)\n$$\n代入计算出的概率：\n$$\nAUC_\\lambda = 0.48 + \\lambda(0.08)\n$$\n\n现在我们来评估每个选项。\n\n**A. 对于给定的分数，$AUC_{1/2} = 0.52$。**\n我们在推导出的 $AUC_\\lambda$ 表达式中令 $\\lambda = 1/2$：\n$$\nAUC_{1/2} = 0.48 + \\frac{1}{2}(0.08) = 0.48 + 0.04 = 0.52\n$$\n此陈述与我们的计算结果相符。\n结论：**正确**。\n\n**B. 对于任何严格递增函数 $g:\\mathbb{R}\\to\\mathbb{R}$，对于所有 $\\lambda \\in [0,1]$，根据 $g(S)$ 计算的 $AUC_\\lambda$ 值与根据 $S$ 计算的值相同。**\n$AUC_\\lambda$ 的定义取决于概率 $\\mathbb{P}(S^+  S^-)$ 和 $\\mathbb{P}(S^+ = S^-)$。这些概率由分数对的排序和相等关系决定。一个严格递增函数 $g$ 会保持序关系，这意味着对于任意两个数 $a$ 和 $b$：\n- $a  b \\iff g(a)  g(b)$\n- $a = b \\iff g(a) = g(b)$\n- $a  b \\iff g(a)  g(b)$\n因此，事件 $\\{S^+  S^-\\}$ 和 $\\{g(S^+)  g(S^-)\\}$ 是等价的，事件 $\\{S^+ = S^-\\}$ 和 $\\{g(S^+) = g(S^-)\\}$ 也是等价的。这意味着它们的概率是相同的：\n$$\n\\mathbb{P}(g(S^+)  g(S^-)) = \\mathbb{P}(S^+  S^-)\n$$\n$$\n\\mathbb{P}(g(S^+) = g(S^-)) = \\mathbb{P}(S^+ = S^-)\n$$\n由于构成 $AUC_\\lambda$ 的两个概率分量在这样的变换 $g$ 下是不变的，所以对于任何 $\\lambda$，$AUC_\\lambda$ 的值也是不变的。这是 AUC 的一个基本性质。\n结论：**正确**。\n\n**C. 如果分数分布是连续的，使得 $\\mathbb{P}(S^+ = S^-)=0$，那么 $AUC_\\lambda$ 与 $\\lambda$ 无关，并且等于 $\\mathbb{P}(S^+  S^-)$。**\n根据公式 $AUC_\\lambda = \\mathbb{P}(S^+  S^-) + \\lambda \\mathbb{P}(S^+ = S^-)$。\n如果我们假设分布是连续的，那么两个独立样本之间出现分数相同的概率为零，即 $\\mathbb{P}(S^+ = S^-) = 0$。\n将此代入公式可得：\n$$\nAUC_\\lambda = \\mathbb{P}(S^+  S^-) + \\lambda \\cdot 0 = \\mathbb{P}(S^+  S^-)\n$$\n最终的表达式 $\\mathbb{P}(S^+  S^-)$ 不包含 $\\lambda$。因此，在这种条件下，$AUC_\\lambda$ 与 $\\lambda$ 无关。这是对于连续分数 AUC 的标准定义。\n结论：**正确**。\n\n**D. 通过扫描阈值并使用梯形法则得到的标准经验ROC曲线下面积对应于 $\\lambda = 1$。**\n从一组分数计算经验 AUC 的标准方法包括构建 ROC 曲线并计算其曲线下面积。ROC 曲线是一系列的点 $(FPR, TPR)$。当在某个分数阈值处，正负实例之间存在分数相同时，曲线会呈对角线移动。使用梯形法则计算此分段线性曲线下的面积等同于在 ROC 点之间进行线性插值。该方法也等价于 Wilcoxon-Mann-Whitney U 统计量，归一化后，其计算 AUC 的公式为：\n$$\nAUC = \\frac{1}{n_+ n_-} \\left( \\sum_{S^+  S^-} 1 + \\frac{1}{2} \\sum_{S^+ = S^-} 1 \\right) = \\mathbb{P}(S^+  S^-) + \\frac{1}{2}\\mathbb{P}(S^+ = S^-)\n$$\n这对应于 $AUC_{1/2}$，即 $\\lambda = 1/2$。这种选择反映了随机打破平局的思想。$\\lambda = 1$ 的情况对应于 $AUC_1 = \\mathbb{P}(S^+  S^-) + \\mathbb{P}(S^+ = S^-) = \\mathbb{P}(S^+ \\ge S^-)$，这代表了一种对平局的乐观处理方式，即总是将平局计为正确分类。这不是梯形法则所定义的标准。\n结论：**错误**。\n\n**E. 对于固定的分数分布，$AUC_\\lambda$ 是 $\\lambda$ 的线性函数，其斜率为 $\\mathbb{P}(S^+ = S^-)$。**\n公式为 $AUC_\\lambda = \\mathbb{P}(S^+  S^-) + \\lambda \\mathbb{P}(S^+ = S^-)$。\n对于固定的分数分布，$\\mathbb{P}(S^+  S^-)$ 和 $\\mathbb{P}(S^+ = S^-)$ 这两个量是常数。让我们将它们表示为 $C_1 = \\mathbb{P}(S^+  S^-)$ 和 $C_2 = \\mathbb{P}(S^+ = S^-)$。表达式变为：\n$$\nAUC_\\lambda = C_1 + C_2 \\lambda\n$$\n这是一个形式为 $y = c + mx$ 的方程，其中 $y = AUC_\\lambda$，$x = \\lambda$，截距是 $c=C_1$，斜率是 $m=C_2$。因此，$AUC_\\lambda$ 确实是 $\\lambda$ 的一个线性函数，其斜率是 $\\lambda$ 的系数，即 $C_2 = \\mathbb{P}(S^+ = S^-)$。\n结论：**正确**。\n\n最终结论总结：\n- A：正确\n- B：正确\n- C：正确\n- D：错误\n- E：正确\n\n正确的选项是 A、B、C 和 E。",
            "answer": "$$\\boxed{ABCE}$$"
        },
        {
            "introduction": "AUC不仅是一个评估指标，它还可以直接用作目标函数来训练机器学习模型，尤其是在“学习到排序”（learning-to-rank）任务中。这个高级练习将引导你推导AUC函数的梯度，这是在梯度下降等优化算法中使用AUC的关键一步 ()。你将首先处理不可微的标准AUC，然后转向一个光滑、可微的替代函数，从而将AUC的理论概念与模型训练的实际挑战联系起来。",
            "id": "3167109",
            "problem": "考虑一个二元分类和学习排序场景，其中有 $n$ 个实例，索引为 $i \\in \\{1,\\dots,n\\}$，真实标签为 $y_i \\in \\{0,1\\}$，实值分数为 $s_i \\in \\mathbb{R}$。令 $\\mathcal{P} = \\{i: y_i = 1\\}$ 表示正例集合，其数量为 $n_{+} = |\\mathcal{P}|$；令 $\\mathcal{N} = \\{j: y_j = 0\\}$ 表示负例集合，其数量为 $n_{-} = |\\mathcal{N}|$。受试者工作特征 (ROC) 曲线的经验曲线下面积 (AUC) 定义为：对于所有正负例对，正例分数超过负例分数的指示函数的平均值。\n\n从亥维赛指示函数和可微性的基本定义出发，完成以下任务：\n\n1) 从第一性原理出发，推导由下式定义的经验曲线下面积 (AUC) 关于分数向量 $s = (s_1,\\dots,s_n)$ 的梯度（或在适当时使用次梯度）。\n$$\n\\mathrm{AUC}(s) \\equiv \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\mathbf{1}\\{ s_i - s_j  0 \\}.\n$$\n明确说明该函数在何处可微，并给出 $\\nabla_{s} \\mathrm{AUC}(s)$ 的表达式，或在不可微时给出其次梯度。\n\n2) 为了获得一个适用于优化的可微代理函数，用带有温度参数 $\\tau  0$ 的 logistic sigmoid 函数 $\\sigma_{\\tau}(x) \\equiv \\frac{1}{1 + \\exp(-x/\\tau)}$ 替换指示函数 $\\mathbf{1}\\{x  0\\}$，并定义平滑代理函数\n$$\nA_{\\tau}(s) \\equiv \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\sigma_{\\tau}(s_i - s_j).\n$$\n推导梯度 $\\nabla_{s} A_{\\tau}(s)$ 的精确解析表达式。\n\n3) 考虑一个具体案例：$n = 4$，标签 $y = (1, 0, 1, 0)$，因此 $\\mathcal{P} = \\{1, 3\\}$ 且 $\\mathcal{N} = \\{2, 4\\}$，分数向量 $s = (1.2, 0.8, 0.5, 0.3)$，温度 $\\tau = 1$，方向向量 $v = (1, -2, 0.5, 3)$。计算平滑代理函数在点 $s$ 沿方向 $v$ 的方向导数，即\n$$\nD A_{\\tau}(s)[v] \\equiv \\nabla_{s} A_{\\tau}(s)^{\\top} v,\n$$\n作为一个实数。将您的最终数值结果四舍五入到四位有效数字。将您的答案表示为一个无单位的实数。",
            "solution": "该问题经评估具有科学依据、是良定的，并包含得出唯一解所需的所有信息。步骤逻辑一致，且与统计学习中的标准概念相关。因此，该问题是有效的。\n\n解答按要求分为三部分。\n\n### 第 1 部分：经验 AUC 的梯度\n\n经验曲线下面积 (AUC) 由下式给出：\n$$\n\\mathrm{AUC}(s) = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\mathbf{1}\\{ s_i - s_j  0 \\}\n$$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数，它可以用亥维赛阶跃函数 $H(x)$ 定义为 $\\mathbf{1}\\{x  0\\} \\equiv H(x)$。函数 $H(x)$ 在 $x  0$ 时为 $1$，在 $x \\leq 0$ 时为 $0$。函数 $\\mathrm{AUC}(s)$ 是这些阶跃函数的和，因此是分段常数函数。\n\n对于任意满足 $i \\in \\mathcal{P}$ 和 $j \\in \\mathcal{N}$ 的所有对 $(i, j)$ 都有 $s_i \\neq s_j$ 的点 $s$，该函数是可微的。在这些点上，对任何分数 $s_k$ 的微小扰动都不会改变任何指示函数的值，因此函数是局部常数。梯度因此是零向量：\n$$\n\\nabla_{s} \\mathrm{AUC}(s) = \\mathbf{0} \\quad \\text{if } s_i \\neq s_j \\text{ for all } i \\in \\mathcal{P}, j \\in \\mathcal{N}.\n$$\n当一个或多个正例的分数与负例的分数相等时，即对于某些 $i \\in \\mathcal{P}, j \\in \\mathcal{N}$ 存在 $s_i = s_j$ 时，该函数在这些点上是不可微的。在这些点上，需要次梯度或广义梯度的概念。\n\n在分布意义上，亥维赛阶跃函数 $H(x)$ 的导数是狄拉克 δ 函数 $\\delta(x)$。我们用它来定义一个广义梯度。$\\mathrm{AUC}(s)$ 关于分数向量 $s$ 的梯度是一个向量，其第 $k$ 个分量是偏导数 $\\frac{\\partial}{\\partial s_k} \\mathrm{AUC}(s)$。\n\n为了找到梯度的第 $k$ 个分量，我们对和的每一项进行逐项求导：\n$$\n\\frac{\\partial}{\\partial s_k} \\mathrm{AUC}(s) = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\frac{\\partial}{\\partial s_k} H(s_i - s_j)\n$$\n使用链式法则，$\\frac{\\partial}{\\partial s_k} H(s_i - s_j) = \\delta(s_i - s_j) \\frac{\\partial}{\\partial s_k}(s_i - s_j)$。如果 $k=i$，则 $\\frac{\\partial}{\\partial s_k}(s_i - s_j)$ 的值为 $1$；如果 $k=j$，则为 $-1$；否则为 $0$。\n\n我们考虑索引 $k$ 的两种情况：\n\n情况 1：$k \\in \\mathcal{P}$（第 $k$ 个实例是正例）。\n仅当 $i=k$ 时，导数 $\\frac{\\partial}{\\partial s_k}(s_i - s_j)$ 非零。\n$$\n\\frac{\\partial \\mathrm{AUC}(s)}{\\partial s_k} = \\frac{1}{n_{+} n_{-}} \\sum_{j \\in \\mathcal{N}} \\delta(s_k - s_j) \\cdot (1) = \\frac{1}{n_{+} n_{-}} \\sum_{j \\in \\mathcal{N}} \\delta(s_k - s_j)\n$$\n\n情况 2：$k \\in \\mathcal{N}$（第 $k$ 个实例是负例）。\n仅当 $j=k$ 时，导数 $\\frac{\\partial}{\\partial s_k}(s_i - s_j)$ 非零。\n$$\n\\frac{\\partial \\mathrm{AUC}(s)}{\\partial s_k} = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\delta(s_i - s_k) \\cdot (-1) = -\\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\delta(s_i - s_k)\n$$\n这些表达式定义了广义梯度 $\\nabla_{s} \\mathrm{AUC}(s)$ 的分量。在可微处（即没有 $s_i=s_j$ 的情况），δ 函数的自变量均非零，使得梯度为零向量，这与我们之前的观察一致。\n\n### 第 2 部分：平滑代理函数的梯度\n\nAUC 的平滑代理函数定义为：\n$$\nA_{\\tau}(s) = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\sigma_{\\tau}(s_i - s_j)\n$$\n其中 logistic sigmoid 函数为 $\\sigma_{\\tau}(x) = \\frac{1}{1 + \\exp(-x/\\tau)}$。由于当 $\\tau  0$ 时 $\\sigma_{\\tau}(x)$ 是一个平滑函数，因此 $A_{\\tau}(s)$ 也是平滑的，其梯度处处有良好定义。\n\n首先，我们推导 sigmoid 函数关于其自变量 $x$ 的导数：\n\\begin{align*}\n\\frac{d}{dx} \\sigma_{\\tau}(x) = \\frac{d}{dx} \\left(1 + \\exp(-x/\\tau)\\right)^{-1} \\\\\n= -1 \\cdot \\left(1 + \\exp(-x/\\tau)\\right)^{-2} \\cdot \\left(\\exp(-x/\\tau) \\cdot \\left(-\\frac{1}{\\tau}\\right)\\right) \\\\\n= \\frac{1}{\\tau} \\frac{\\exp(-x/\\tau)}{\\left(1 + \\exp(-x/\\tau)\\right)^2} \\\\\n= \\frac{1}{\\tau} \\left(\\frac{1}{1 + \\exp(-x/\\tau)}\\right) \\left(\\frac{\\exp(-x/\\tau)}{1 + \\exp(-x/\\tau)}\\right) \\\\\n= \\frac{1}{\\tau} \\sigma_{\\tau}(x) \\left(\\frac{1 + \\exp(-x/\\tau) - 1}{1 + \\exp(-x/\\tau)}\\right) \\\\\n= \\frac{1}{\\tau} \\sigma_{\\tau}(x) \\left(1 - \\frac{1}{1 + \\exp(-x/\\tau)}\\right) \\\\\n= \\frac{1}{\\tau} \\sigma_{\\tau}(x) \\left(1 - \\sigma_{\\tau}(x)\\right)\n\\end{align*}\n让我们将此导数记为 $\\sigma'_{\\tau}(x)$。为了求梯度 $\\nabla_{s} A_{\\tau}(s)$ 的第 $k$ 个分量，我们进行微分：\n$$\n\\frac{\\partial A_{\\tau}(s)}{\\partial s_k} = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{N}} \\frac{\\partial}{\\partial s_k} \\sigma_{\\tau}(s_i - s_j)\n$$\n应用链式法则：\n$$\n\\frac{\\partial}{\\partial s_k} \\sigma_{\\tau}(s_i - s_j) = \\sigma'_{\\tau}(s_i - s_j) \\cdot \\frac{\\partial}{\\partial s_k}(s_i - s_j)\n$$\n和之前一样，我们考虑索引 $k$ 的两种情况：\n\n情况 1：$k \\in \\mathcal{P}$\n$$\n\\frac{\\partial A_{\\tau}(s)}{\\partial s_k} = \\frac{1}{n_{+} n_{-}} \\sum_{j \\in \\mathcal{N}} \\sigma'_{\\tau}(s_k - s_j) = \\frac{1}{\\tau n_{+} n_{-}} \\sum_{j \\in \\mathcal{N}} \\sigma_{\\tau}(s_k - s_j) (1 - \\sigma_{\\tau}(s_k - s_j))\n$$\n\n情况 2：$k \\in \\mathcal{N}$\n$$\n\\frac{\\partial A_{\\tau}(s)}{\\partial s_k} = \\frac{1}{n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sigma'_{\\tau}(s_i - s_k) \\cdot (-1) = -\\frac{1}{\\tau n_{+} n_{-}} \\sum_{i \\in \\mathcal{P}} \\sigma_{\\tau}(s_i - s_k) (1 - \\sigma_{\\tau}(s_i - s_k))\n$$\n这些表达式给出了梯度向量 $\\nabla_{s} A_{\\tau}(s)$ 每个分量的精确解析公式。\n\n### 第 3 部分：方向导数计算\n\n我们需要计算方向导数 $D A_{\\tau}(s)[v] = \\nabla_{s} A_{\\tau}(s)^{\\top} v$。\n给定的参数如下：\n- 标签 $y = (1, 0, 1, 0)$，因此 $\\mathcal{P} = \\{1, 3\\}$ 且 $\\mathcal{N} = \\{2, 4\\}$。\n- $n_{+} = 2$, $n_{-} = 2$。\n- 分数 $s = (s_1, s_2, s_3, s_4) = (1.2, 0.8, 0.5, 0.3)$。\n- 温度 $\\tau = 1$。sigmoid 函数为 $\\sigma_{1}(x) = (1 + \\exp(-x))^{-1}$。\n- 方向向量 $v = (v_1, v_2, v_3, v_4) = (1, -2, 0.5, 3)$。\n\n梯度分量由第 2 部分的公式给出，前置因子为 $\\frac{1}{\\tau n_{+} n_{-}} = \\frac{1}{1 \\cdot 2 \\cdot 2} = \\frac{1}{4}$。令 $\\sigma'(x) = \\sigma_1(x)(1-\\sigma_1(x))$。\n\n梯度分量为：\n- 对于 $k=1 \\in \\mathcal{P}$：$\\frac{\\partial A_1}{\\partial s_1} = \\frac{1}{4} \\left( \\sigma'(s_1-s_2) + \\sigma'(s_1-s_4) \\right)$\n- 对于 $k=3 \\in \\mathcal{P}$：$\\frac{\\partial A_1}{\\partial s_3} = \\frac{1}{4} \\left( \\sigma'(s_3-s_2) + \\sigma'(s_3-s_4) \\right)$\n- 对于 $k=2 \\in \\mathcal{N}$：$\\frac{\\partial A_1}{\\partial s_2} = -\\frac{1}{4} \\left( \\sigma'(s_1-s_2) + \\sigma'(s_3-s_2) \\right)$\n- 对于 $k=4 \\in \\mathcal{N}$：$\\frac{\\partial A_1}{\\partial s_4} = -\\frac{1}{4} \\left( \\sigma'(s_1-s_4) + \\sigma'(s_3-s_4) \\right)$\n\n分数差为：\n- $s_1 - s_2 = 1.2 - 0.8 = 0.4$\n- $s_1 - s_4 = 1.2 - 0.3 = 0.9$\n- $s_3 - s_2 = 0.5 - 0.8 = -0.3$\n- $s_3 - s_4 = 0.5 - 0.3 = 0.2$\n\n$\\sigma'(x)$ 的值为：\n- $\\sigma'(0.4) = \\sigma_1(0.4)(1-\\sigma_1(0.4)) \\approx 0.598688(1 - 0.598688) \\approx 0.240260$\n- $\\sigma'(0.9) = \\sigma_1(0.9)(1-\\sigma_1(0.9)) \\approx 0.710950(1 - 0.710950) \\approx 0.205504$\n- $\\sigma'(-0.3) = \\sigma_1(-0.3)(1-\\sigma_1(-0.3)) \\approx 0.425557(1 - 0.425557) \\approx 0.244460$\n- $\\sigma'(0.2) = \\sigma_1(0.2)(1-\\sigma_1(0.2)) \\approx 0.549834(1 - 0.549834) \\approx 0.247525$\n\n方向导数是点积：\n$D A_1(s)[v] = \\sum_{k=1}^{4} \\frac{\\partial A_1}{\\partial s_k} v_k$。\n$$\nD A_1(s)[v] = \\frac{\\partial A_1}{\\partial s_1} v_1 + \\frac{\\partial A_1}{\\partial s_2} v_2 + \\frac{\\partial A_1}{\\partial s_3} v_3 + \\frac{\\partial A_1}{\\partial s_4} v_4\n$$\n$$\n= \\frac{1}{4} \\left( \\sigma'(0.4) + \\sigma'(0.9) \\right) \\cdot (1) \\\\\n- \\frac{1}{4} \\left( \\sigma'(0.4) + \\sigma'(-0.3) \\right) \\cdot (-2) \\\\\n+ \\frac{1}{4} \\left( \\sigma'(-0.3) + \\sigma'(0.2) \\right) \\cdot (0.5) \\\\\n- \\frac{1}{4} \\left( \\sigma'(0.9) + \\sigma'(0.2) \\right) \\cdot (3)\n$$\n我们可以提出因子 $\\frac{1}{4}$ 并按 $\\sigma'$ 的值对各项进行分组：\n$$\n= \\frac{1}{4} \\left[ \\sigma'(0.4)(1+2) + \\sigma'(0.9)(1-3) + \\sigma'(-0.3)(2+0.5) + \\sigma'(0.2)(0.5-3) \\right]\n$$\n$$\n= \\frac{1}{4} \\left[ 3 \\sigma'(0.4) - 2 \\sigma'(0.9) + 2.5 \\sigma'(-0.3) - 2.5 \\sigma'(0.2) \\right]\n$$\n代入数值：\n$$\n\\approx \\frac{1}{4} \\left[ 3(0.240260) - 2(0.205504) + 2.5(0.244460) - 2.5(0.247525) \\right]\n$$\n$$\n= \\frac{1}{4} \\left[ 0.72078 - 0.411008 + 0.61115 - 0.6188125 \\right]\n$$\n$$\n= \\frac{1}{4} \\left[ 0.3021095 \\right] \\approx 0.075527375\n$$\n四舍五入到四位有效数字，我们得到 $0.07553$。",
            "answer": "$$\n\\boxed{0.07553}\n$$"
        }
    ]
}