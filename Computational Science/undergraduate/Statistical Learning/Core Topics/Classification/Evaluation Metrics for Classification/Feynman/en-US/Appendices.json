{
    "hands_on_practices": [
        {
            "introduction": "In real-world classification tasks, from fraud detection to medical diagnosis, we often face severe class imbalance where one class is far rarer than the other. In such scenarios, a high accuracy score can be dangerously misleading. This exercise  provides a hands-on exploration of why accuracy fails and introduces more informative metrics like Balanced Accuracy and the F1-score, which are designed to provide a more nuanced and reliable picture of a classifier's performance on imbalanced data.",
            "id": "3118882",
            "problem": "You are given a binary classification setting with severe class imbalance. The true label is denoted by $y \\in \\{0,1\\}$, with a fixed base rate $\\mathbb{P}(y=1)=p=0.01$. A classifier maps each instance into a class label $\\hat{y} \\in \\{0,1\\}$. A probabilistic model maps each instance into a score $s \\in [0,1]$ interpreted as a calibrated probability, meaning for any score value $v$ in the range of $s$, the conditional probability satisfies $\\mathbb{P}(y=1 \\mid s=v) = v$. To convert scores into hard labels, one uses a threshold rule of the form \"predict $\\hat{y}=1$ if and only if $s \\ge \\theta$,\" with a specified tie convention that includes equality in the positive class. Your tasks are to derive and compute evaluation metrics for several cases using only core definitions and the law of total probability.\n\nStart from the fundamental base: the confusion outcomes defined by True Positive (TP), False Positive (FP), True Negative (TN), and False Negative (FN) events. Work with population fractions rather than finite-sample counts. Use the law of total probability to obtain each confusion component from calibrated probability strata and thresholding decisions. Then, using the standard definitions of Accuracy, Balanced Accuracy (mean of True Positive Rate and True Negative Rate), and the F-score of order one (F1), compute the requested quantities below. If a ratio requires division by zero in its denominator, adopt the convention that the ratio is zero. In particular, if no predictions are made for the positive class, define precision to be zero and hence the F1 value to be zero. All values must be expressed as decimals, not as percentages.\n\nSynthetic calibrated two-bin model. Consider a score model that outputs only two values: a \"high\" score $p_h$ on a subset $S_h$ of instances with mass $w \\in (0,1)$, and a \"low\" score $p_\\ell$ on the complement $S_\\ell$ with mass $1-w$. The model is calibrated, so the conditional positive rate on $S_h$ is $p_h$ and on $S_\\ell$ is $p_\\ell$. The overall positive base rate must equal $p$, so $p = w \\, p_h + (1-w)\\, p_\\ell$. You must use this identity to set $p_\\ell$ from the specified parameters when it is not explicitly given. For a threshold $\\theta$, the decision regions are: predict positive on any stratum whose score is at least $\\theta$ and negative otherwise.\n\nTest suite. Compute, for each case below, the Accuracy, Balanced Accuracy, and F1 according to the above definitions. Output each metric rounded to exactly six digits after the decimal point.\n\n- Case A (always-negative classifier): A trivial classifier that predicts $\\hat{y}=0$ for all instances, irrespective of inputs.\n- Case B (calibrated, threshold at high score): Two-bin calibrated model with $w=0.02$, $p_h=0.50$, and $p_\\ell$ determined by the base rate $p=0.01$. Use threshold $\\theta=0.50$.\n- Case C (calibrated, threshold too high): Two-bin calibrated model with $w=0.05$, $p_h=0.20$, and $p_\\ell$ determined by $p=0.01$. Use threshold $\\theta=0.50$.\n- Case D (calibrated, F1-optimal among discrete policies): Same parameters as Case C. Choose the prediction policy that maximizes F1 among the three distinct hard-labeling regimes induced by thresholds: predict none positive (equivalently, $\\thetap_h$), predict only the high-score bin as positive (equivalently, $p_\\ell\\theta\\le p_h$), or predict both bins as positive (equivalently, $\\theta\\le p_\\ell$). In case of ties in F1, select the regime with the fewest predicted positives.\n\nFinal output format. Your program should produce a single line of output containing $12$ values, in this exact order:\n$[\\text{Acc}_A,\\text{BalAcc}_A,\\text{F1}_A,\\text{Acc}_B,\\text{BalAcc}_B,\\text{F1}_B,\\text{Acc}_C,\\text{BalAcc}_C,\\text{F1}_C,\\text{Acc}_D,\\text{BalAcc}_D,\\text{F1}_D]$,\nrounded to six digits after the decimal point, and printed as a comma-separated list enclosed in square brackets (e.g., $[0.000000,0.000000,\\dots]$). No other output is permitted.",
            "solution": "The problem requires the calculation of three evaluation metrics—Accuracy, Balanced Accuracy, and the F1-score—for a binary classifier under several scenarios. The setting is a population-level analysis, not a finite sample, characterized by a base rate of positive instances $\\mathbb{P}(y=1) = p = 0.01$.\n\nFirst, we establish the definitions of the metrics based on the population fractions of the four confusion matrix outcomes: True Positives ($TP$), False Positives ($FP$), True Negatives ($TN$), and False Negatives ($FN$). These fractions sum to $1$: $TP+FP+TN+FN=1$.\n\nThe total positive and negative populations are given by:\n$$TP + FN = \\mathbb{P}(y=1) = p$$\n$$TN + FP = \\mathbb{P}(y=0) = 1-p$$\n\nThe metrics are defined as:\n1.  **Accuracy ($Acc$)**: The fraction of correct predictions.\n    $$Acc = TP + TN$$\n2.  **True Positive Rate ($TPR$)** or **Recall ($Rec$)**: The fraction of actual positives correctly identified.\n    $$TPR = Rec = \\frac{TP}{TP+FN} = \\frac{TP}{p}$$\n3.  **True Negative Rate ($TNR$)**: The fraction of actual negatives correctly identified.\n    $$TNR = \\frac{TN}{TN+FP} = \\frac{TN}{1-p}$$\n4.  **Balanced Accuracy ($BalAcc$)**: The arithmetic mean of $TPR$ and $TNR$.\n    $$BalAcc = \\frac{1}{2}(TPR + TNR)$$\n5.  **Precision ($Prec$)**: The fraction of positive predictions that are correct.\n    $$Prec = \\frac{TP}{TP+FP}$$\n    The denominator $TP+FP = \\mathbb{P}(\\hat{y}=1)$ is the total fraction of instances predicted as positive. If $\\mathbb{P}(\\hat{y}=1)=0$, then $Prec=0$ by convention.\n6.  **F1-Score ($F1$)**: The harmonic mean of Precision and Recall.\n    $$F1 = 2 \\cdot \\frac{Prec \\cdot Rec}{Prec + Rec}$$\n    If $Prec+Rec=0$, which occurs if $TP=0$, then $F1=0$.\n\nThe problem introduces a calibrated two-bin score model. The model outputs a \"high\" score $s=p_h$ on a fraction $w$ of the data, and a \"low\" score $s=p_\\ell$ on the remaining fraction $1-w$. Calibration implies $\\mathbb{P}(y=1|s=p_h)=p_h$ and $\\mathbb{P}(y=1|s=p_\\ell)=p_\\ell$. The overall base rate $p$ is constrained by the law of total probability: $p = w \\cdot p_h + (1-w) \\cdot p_\\ell$. From this, we can determine $p_\\ell$ as $p_\\ell = \\frac{p - w p_h}{1-w}$.\n\nThe confusion matrix components can be derived by considering the classifier's decision rule, \"predict $\\hat{y}=1$ if $s \\ge \\theta$\", and the joint probabilities of score and true label.\n$$TP = \\mathbb{P}(\\hat{y}=1, y=1) \\qquad FP = \\mathbb{P}(\\hat{y}=1, y=0)$$\n$$TN = \\mathbb{P}(\\hat{y}=0, y=0) \\qquad FN = \\mathbb{P}(\\hat{y}=0, y=1)$$\n\nLet's analyze the three distinct prediction policies possible with a two-bin model, assuming $p_h  p_\\ell$.\n\n**Policy 1: Always predict negative ($\\hat{y}=0$)**. This occurs for a threshold $\\theta  p_h$.\n- $\\mathbb{P}(\\hat{y}=1)=0$, so $TP=0, FP=0$.\n- All instances are predicted negative, so $FN = \\mathbb{P}(y=1) = p$ and $TN = \\mathbb{P}(y=0) = 1-p$.\n- Metrics:\n    - $Acc = TP+TN = 1-p$.\n    - $TPR = 0/p = 0$. $TNR = (1-p)/(1-p) = 1$.\n    - $BalAcc = \\frac{1}{2}(0+1) = 0.5$.\n    - $Prec=0$ (by convention), $Rec=0$.\n    - $F1 = 0$.\n\n**Policy 2: Predict high-score bin positive, low-score bin negative**. This occurs for $p_\\ell  \\theta \\le p_h$.\n- $\\hat{y}=1$ only for the $S_h$ stratum (mass $w$).\n- $TP = \\mathbb{P}(s=p_h, y=1) = \\mathbb{P}(y=1|s=p_h)\\mathbb{P}(s=p_h) = p_h w$.\n- $FP = \\mathbb{P}(s=p_h, y=0) = (1-p_h)w$.\n- $TN = \\mathbb{P}(s=p_\\ell, y=0) = (1-p_\\ell)(1-w)$.\n- $FN = \\mathbb{P}(s=p_\\ell, y=1) = p_\\ell(1-w)$.\n- Metrics:\n    - $Acc = p_h w + (1-p_\\ell)(1-w)$.\n    - $TPR = \\frac{p_h w}{p}$. $TNR = \\frac{(1-p_\\ell)(1-w)}{1-p}$.\n    - $BalAcc = \\frac{1}{2} \\left( \\frac{p_h w}{p} + \\frac{(1-p_\\ell)(1-w)}{1-p} \\right)$.\n    - $Prec = \\frac{p_h w}{p_h w + (1-p_h)w} = \\frac{p_h w}{w} = p_h$.\n    - $Rec = TPR = \\frac{p_h w}{p}$.\n    - $F1 = 2 \\frac{p_h \\cdot (p_h w/p)}{p_h + p_h w/p} = \\frac{2 p_h^2 w}{p_h(p+w)} = \\frac{2 p_h w}{p+w}$.\n\n**Policy 3: Always predict positive ($\\hat{y}=1$)**. This occurs for $\\theta \\le p_\\ell$.\n- $\\mathbb{P}(\\hat{y}=0)=0$, so $TN=0, FN=0$.\n- All instances are predicted positive, so $TP = \\mathbb{P(y=1)} = p$ and $FP = \\mathbb{P}(y=0) = 1-p$.\n- Metrics:\n    - $Acc = TP+TN = p$.\n    - $TPR = p/p = 1$. $TNR = 0/(1-p) = 0$.\n    - $BalAcc = \\frac{1}{2}(1+0) = 0.5$.\n    - $Prec = \\frac{p}{p+(1-p)} = p$. $Rec=1$.\n    - $F1 = 2 \\frac{p \\cdot 1}{p+1} = \\frac{2p}{p+1}$.\n\nWith these general formulas, we can compute the values for each case. The base rate is $p=0.01$.\n\n**Case A: Always-negative classifier**\nThis is Policy 1.\n- $Acc_A = 1-p = 1-0.01 = 0.99$.\n- $BalAcc_A = 0.5$.\n- $F1_A = 0$.\nValues: $0.990000, 0.500000, 0.000000$.\n\n**Case B: Calibrated, threshold at high score**\nParameters: $w=0.02$, $p_h=0.50$, threshold $\\theta=0.50$.\nFirst, we find $p_\\ell$: $p_\\ell = \\frac{0.01 - 0.02 \\cdot 0.50}{1-0.02} = \\frac{0.01 - 0.01}{0.98} = 0$.\nThe scores are $p_h=0.50$ and $p_\\ell=0$. Since $0  \\theta=0.50 \\le 0.50$, this is Policy 2.\n- $Acc_B = p_h w + (1-p_\\ell)(1-w) = 0.50 \\cdot 0.02 + (1-0)(1-0.02) = 0.01 + 0.98 = 0.99$.\n- $TPR_B = \\frac{p_h w}{p} = \\frac{0.50 \\cdot 0.02}{0.01} = 1$.\n- $TNR_B = \\frac{(1-p_\\ell)(1-w)}{1-p} = \\frac{(1-0)(1-0.02)}{1-0.01} = \\frac{0.98}{0.99}$.\n- $BalAcc_B = \\frac{1}{2}(1 + \\frac{0.98}{0.99}) = \\frac{1.97}{1.98} \\approx 0.994949$.\n- $F1_B = \\frac{2 p_h w}{p+w} = \\frac{2 \\cdot 0.50 \\cdot 0.02}{0.01+0.02} = \\frac{0.02}{0.03} = \\frac{2}{3} \\approx 0.666667$.\nValues: $0.990000, 0.994949, 0.666667$.\n\n**Case C: Calibrated, threshold too high**\nParameters: $w=0.05$, $p_h=0.20$, threshold $\\theta=0.50$.\nFirst, we find $p_\\ell$: $p_\\ell = \\frac{0.01 - 0.05 \\cdot 0.20}{1-0.05} = \\frac{0.01 - 0.01}{0.95} = 0$.\nThe scores are $p_h=0.20$ and $p_\\ell=0$. Since $\\theta=0.50  p_h=0.20$, this is Policy 1.\nThe results are identical to Case A.\n- $Acc_C = 0.99$.\n- $BalAcc_C = 0.5$.\n- $F1_C = 0$.\nValues: $0.990000, 0.500000, 0.000000$.\n\n**Case D: Calibrated, F1-optimal policy**\nParameters are the same as Case C: $w=0.05, p_h=0.20, p_\\ell=0$. We must choose the policy that maximizes $F1$.\n- **Policy 1 ($F1_1$)**: $F1_1=0$.\n- **Policy 2 ($F1_2$)**: $F1_2 = \\frac{2 p_h w}{p+w} = \\frac{2 \\cdot 0.20 \\cdot 0.05}{0.01+0.05} = \\frac{0.02}{0.06} = \\frac{1}{3} \\approx 0.333333$.\n- **Policy 3 ($F1_3$)**: $F1_3 = \\frac{2p}{p+1} = \\frac{2 \\cdot 0.01}{1.01} = \\frac{0.02}{1.01} \\approx 0.019802$.\nComparing the F1 scores, $F1_2$ is the maximum. Thus, the optimal policy is Policy 2. We now compute its metrics.\n- $Acc_D = p_h w + (1-p_\\ell)(1-w) = 0.20 \\cdot 0.05 + (1-0)(1-0.05) = 0.01 + 0.95 = 0.96$.\n- $TPR_D = \\frac{p_h w}{p} = \\frac{0.20 \\cdot 0.05}{0.01} = 1$.\n- $TNR_D = \\frac{(1-p_\\ell)(1-w)}{1-p} = \\frac{(1-0)(1-0.05)}{1-0.01} = \\frac{0.95}{0.99}$.\n- $BalAcc_D = \\frac{1}{2}(1 + \\frac{0.95}{0.99}) = \\frac{1.94}{1.98} \\approx 0.979798$.\n- $F1_D = 1/3 \\approx 0.333333$.\nValues: $0.960000, 0.979798, 0.333333$.\n\nCombining all results for the final output:\n- Acc_A, BalAcc_A, F1_A: $0.990000, 0.500000, 0.000000$\n- Acc_B, BalAcc_B, F1_B: $0.990000, 0.994949, 0.666667$\n- Acc_C, BalAcc_C, F1_C: $0.990000, 0.500000, 0.000000$\n- Acc_D, BalAcc_D, F1_D: $0.960000, 0.979798, 0.333333$",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes Accuracy, Balanced Accuracy, and F1-score for four\n    binary classification scenarios as defined in the problem.\n    \"\"\"\n\n    def calculate_metrics(p_rate, TP, FP, TN, FN):\n        \"\"\"\n        Calculates evaluation metrics from confusion matrix components.\n        \n        Args:\n            p_rate (float): The base rate P(y=1).\n            TP, FP, TN, FN (float): Population fractions for confusion matrix.\n\n        Returns:\n            tuple: A tuple containing (Accuracy, Balanced Accuracy, F1-score).\n        \"\"\"\n        # Denominators for rates\n        # real_pos = p_rate\n        # real_neg = 1 - p_rate\n        real_pos = TP + FN\n        real_neg = TN + FP\n        pred_pos = TP + FP\n        \n        # Accuracy\n        acc = TP + TN\n\n        # True Positive Rate (Recall) and True Negative Rate\n        tpr = TP / real_pos if real_pos > 0 else 0.0\n        tnr = TN / real_neg if real_neg > 0 else 0.0\n\n        # Balanced Accuracy\n        bal_acc = 0.5 * (tpr + tnr)\n\n        # Precision and Recall\n        prec = TP / pred_pos if pred_pos > 0 else 0.0\n        recall = tpr # Recall is the same as TPR\n\n        # F1 Score\n        f1 = 2 * (prec * recall) / (prec + recall) if (prec + recall) > 0 else 0.0\n\n        return acc, bal_acc, f1\n\n    results = []\n    p = 0.01\n\n    # Case A: Always-negative classifier (Policy 1)\n    TP_A, FP_A, TN_A, FN_A = 0.0, 0.0, 1 - p, p\n    acc_A, bal_acc_A, f1_A = calculate_metrics(p, TP_A, FP_A, TN_A, FN_A)\n    results.extend([acc_A, bal_acc_A, f1_A])\n\n    # Case B: Calibrated, threshold at high score\n    w_B, p_h_B = 0.02, 0.50\n    p_l_B = (p - w_B * p_h_B) / (1 - w_B)\n    # Threshold theta = 0.50, which is = p_h_B. This is Policy 2.\n    TP_B = p_h_B * w_B\n    FP_B = (1 - p_h_B) * w_B\n    TN_B = (1 - p_l_B) * (1 - w_B)\n    FN_B = p_l_B * (1 - w_B)\n    acc_B, bal_acc_B, f1_B = calculate_metrics(p, TP_B, FP_B, TN_B, FN_B)\n    results.extend([acc_B, bal_acc_B, f1_B])\n\n    # Case C: Calibrated, threshold too high\n    w_C, p_h_C = 0.05, 0.20\n    p_l_C = (p - w_C * p_h_C) / (1 - w_C)\n    # Threshold theta = 0.50, which is  p_h_C. This is Policy 1.\n    TP_C, FP_C, TN_C, FN_C = 0.0, 0.0, 1 - p, p\n    acc_C, bal_acc_C, f1_C = calculate_metrics(p, TP_C, FP_C, TN_C, FN_C)\n    results.extend([acc_C, bal_acc_C, f1_C])\n    \n    # Case D: Calibrated, F1-optimal among discrete policies\n    w_D, p_h_D = w_C, p_h_C\n    p_l_D = p_l_C\n\n    # Evaluate F1 for the three possible policies\n    \n    # Policy 1: Predict none positive\n    # F1 is 0, as calculated in Case A.\n    f1_1 = f1_A\n    metrics_1 = (acc_A, bal_acc_A, f1_1)\n    pred_pos_1 = 0.0\n\n    # Policy 2: Predict high-score bin as positive\n    TP_2 = p_h_D * w_D\n    FP_2 = (1 - p_h_D) * w_D\n    TN_2 = (1 - p_l_D) * (1 - w_D)\n    FN_2 = p_l_D * (1 - w_D)\n    metrics_2 = calculate_metrics(p, TP_2, FP_2, TN_2, FN_2)\n    f1_2 = metrics_2[2]\n    pred_pos_2 = w_D\n\n    # Policy 3: Predict all positive\n    TP_3, FP_3, TN_3, FN_3 = p, 1 - p, 0.0, 0.0\n    metrics_3 = calculate_metrics(p, TP_3, FP_3, TN_3, FN_3)\n    f1_3 = metrics_3[2]\n    pred_pos_3 = 1.0\n\n    # Find the optimal policy: maximize F1, with tie-breaking by fewest predicted positives\n    policies = [\n        (f1_1, pred_pos_1, metrics_1),\n        (f1_2, pred_pos_2, metrics_2),\n        (f1_3, pred_pos_3, metrics_3)\n    ]\n    \n    # Sort by F1 descending (-f1), then by predicted positives ascending (pred_pos)\n    # The best policy is the first element after sorting.\n    best_policy = sorted(policies, key=lambda x: (-x[0], x[1]))[0]\n    acc_D, bal_acc_D, f1_D = best_policy[2]\n    results.extend([acc_D, bal_acc_D, f1_D])\n\n    # Format the final output string with rounding to 6 decimal places\n    output_str = f\"[{','.join(f'{x:.6f}' for x in results)}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "A classifier's performance is often described by intrinsic metrics like sensitivity and specificity, which are independent of the population being tested. However, the practical utility of a test, such as its Negative Predictive Value ($NPV$), is deeply connected to the context in which it's deployed. This practice problem  illustrates this critical distinction by showing how the same classifier can have dramatically different predictive values when used in a general screening population versus a specialized clinic, highlighting the essential role of prevalence in interpreting diagnostic results.",
            "id": "3118938",
            "problem": "A binary diagnostic classifier is used to detect a rare disease. The same classifier is deployed in two clinical settings that differ only in the disease prevalence. The classifier has sensitivity (true positive rate) $TPR$ equal to $0.85$ and specificity (true negative rate) $TNR$ equal to $0.98$. Setting $\\mathcal{A}$ is a population screening clinic where the disease prevalence is $\\pi_{\\mathcal{A}} = 0.01$. Setting $\\mathcal{B}$ is a specialty referral clinic where the disease prevalence is $\\pi_{\\mathcal{B}} = 0.30$. Use only the definitions of sensitivity, specificity, and Negative Predictive Value (NPV), together with the laws of probability, to compute the Negative Predictive Value (NPV) in each setting and thereby demonstrate how the same high specificity can yield different $NPV$ due solely to differing prevalence.\n\nLet $\\Delta$ denote the difference between the Negative Predictive Values, defined as\n$$\n\\Delta \\;=\\; \\mathrm{NPV}_{\\mathcal{A}} \\;-\\; \\mathrm{NPV}_{\\mathcal{B}}.\n$$\nCompute $\\Delta$ and report it as a decimal. Round your final answer to four significant figures. Do not use a percent sign.",
            "solution": "### Step 1: Definition of Terms and Probabilities\n\nFirst, let's define the events and translate the given information into the language of probability theory.\nLet $D$ be the event that an individual has the disease, and $D^c$ be the event that the individual does not have the disease.\nLet $T$ be the event of a positive test result from the classifier, and $T^c$ be the event of a negative test result.\n\nThe problem provides the following quantities:\n-   Disease prevalence, $\\pi = P(D)$. This varies between the two settings.\n-   Sensitivity, or True Positive Rate: $TPR = P(T | D) = 0.85$. This is the probability of a positive test given the individual has the disease.\n-   Specificity, or True Negative Rate: $TNR = P(T^c | D^c) = 0.98$. This is the probability of a negative test given the individual does not have the disease.\n\nFrom these, we can derive the False Negative Rate ($FNR$), which is the probability of a negative test given the individual has the disease:\n$$FNR = P(T^c | D) = 1 - TPR = 1 - 0.85 = 0.15$$\n\nThe Negative Predictive Value ($NPV$) is defined as the probability that an individual is truly disease-free given that they received a negative test result:\n$$NPV = P(D^c | T^c)$$\n\n### Step 2: Derivation of the General Formula for NPV\n\nTo compute the $NPV$, we apply Bayes' theorem:\n$$NPV = P(D^c | T^c) = \\frac{P(T^c | D^c) P(D^c)}{P(T^c)}$$\n\nThe components of this formula are:\n-   $P(T^c | D^c) = TNR$, which is given as $0.98$.\n-   $P(D^c) = 1 - P(D) = 1 - \\pi$.\n-   $P(T^c)$, the total probability of a negative test result.\n\nWe can find $P(T^c)$ using the law of total probability, by summing over the two states of disease (present or absent):\n$$P(T^c) = P(T^c | D)P(D) + P(T^c | D^c)P(D^c)$$\nSubstituting the defined terms:\n$$P(T^c) = (FNR \\cdot \\pi) + (TNR \\cdot (1 - \\pi))$$\n$$P(T^c) = ((1 - TPR) \\cdot \\pi) + (TNR \\cdot (1 - \\pi))$$\n\nSubstituting this denominator back into the Bayes' theorem expression for $NPV$, we obtain a general formula for $NPV$ as a function of prevalence $\\pi$:\n$$NPV(\\pi) = \\frac{TNR \\cdot (1 - \\pi)}{(1 - TPR) \\cdot \\pi + TNR \\cdot (1 - \\pi)}$$\n\n### Step 3: Calculation of NPV for Each Setting\n\nNow, we apply this formula to the two clinical settings.\n\n**Setting $\\mathcal{A}$ (Population Screening):**\nThe disease prevalence is $\\pi_{\\mathcal{A}} = 0.01$.\n$$NPV_{\\mathcal{A}} = \\frac{0.98 \\cdot (1 - 0.01)}{(1 - 0.85) \\cdot 0.01 + 0.98 \\cdot (1 - 0.01)}$$\n$$NPV_{\\mathcal{A}} = \\frac{0.98 \\cdot 0.99}{0.15 \\cdot 0.01 + 0.98 \\cdot 0.99}$$\n$$NPV_{\\mathcal{A}} = \\frac{0.9702}{0.0015 + 0.9702}$$\n$$NPV_{\\mathcal{A}} = \\frac{0.9702}{0.9717} \\approx 0.9984563$$\n\n**Setting $\\mathcal{B}$ (Specialty Referral Clinic):**\nThe disease prevalence is $\\pi_{\\mathcal{B}} = 0.30$.\n$$NPV_{\\mathcal{B}} = \\frac{0.98 \\cdot (1 - 0.30)}{(1 - 0.85) \\cdot 0.30 + 0.98 \\cdot (1 - 0.30)}$$\n$$NPV_{\\mathcal{B}} = \\frac{0.98 \\cdot 0.70}{0.15 \\cdot 0.30 + 0.98 \\cdot 0.70}$$\n$$NPV_{\\mathcal{B}} = \\frac{0.686}{0.045 + 0.686}$$\n$$NPV_{\\mathcal{B}} = \\frac{0.686}{0.731} \\approx 0.9384405$$\n\nAs demonstrated, the $NPV$ is substantially higher in the low-prevalence setting ($\\approx 0.998$) than in the high-prevalence setting ($\\approx 0.938$), even though the classifier's intrinsic properties ($TPR$ and $TNR$) are unchanged.\n\n### Step 4: Computation of the Difference $\\Delta$\n\nThe problem asks for the difference $\\Delta = NPV_{\\mathcal{A}} - NPV_{\\mathcal{B}}$.\nUsing the calculated values:\n$$\\Delta = \\frac{0.9702}{0.9717} - \\frac{0.686}{0.731}$$\n$$\\Delta \\approx 0.9984563 - 0.9384405$$\n$$\\Delta \\approx 0.0600158$$\n\nThe problem requires rounding the final answer to four significant figures. The number is $0.0600158...$. The first four significant figures are $6$, $0$, $0$, and $1$. The next digit is $5$, which requires rounding up the last significant digit.\n$$\\Delta \\approx 0.06002$$",
            "answer": "$$\\boxed{0.06002}$$"
        },
        {
            "introduction": "Choosing the right evaluation metric is not just a technical choice; it's about aligning a model with real-world consequences. While the $F_1$ score offers a balanced view of precision and recall, it implicitly assumes that false positives and false negatives carry equal weight. This exercise  demonstrates how to tailor a classifier's decision threshold to specific, asymmetric misclassification costs, a technique central to risk minimization. By calculating the financial \"regret\" of optimizing for the generic $F_1$ score instead of the actual cost function, you will gain a practical understanding of how to build models that are not just statistically sound but also economically optimal.",
            "id": "3118850",
            "problem": "A binary classifier produces, for each input instance, a calibrated score $s \\in [0,1]$ interpreted as the conditional probability $s = \\mathbb{P}(Y=1 \\mid X)$ of the positive class. The decision rule classifies an instance as positive if $s \\geq t$ for some threshold $t$. Consider the following dataset of $12$ instances with pairs $(s_i, y_i)$, where $y_i \\in \\{0,1\\}$ is the true label ($1$ for positive, $0$ for negative):\n$(0.95, 1)$; $(0.85, 1)$; $(0.70, 0)$; $(0.65, 1)$; $(0.60, 0)$; $(0.55, 1)$; $(0.50, 0)$; $(0.40, 1)$; $(0.35, 0)$; $(0.20, 0)$; $(0.10, 0)$; $(0.05, 1)$.\n\nSuppose the misclassification costs are asymmetric with false negative cost $C_{\\mathrm{FN}} = 20$ and false positive cost $C_{\\mathrm{FP}} = 1$. Define the expected cost of a deterministic decision for an instance with calibrated score $s$ as follows: if it is classified positive, the expected cost is $C_{\\mathrm{FP}} \\cdot (1 - s)$; if it is classified negative, the expected cost is $C_{\\mathrm{FN}} \\cdot s$.\n\nYou are to:\n- Use risk minimization from first principles to determine the threshold $t_{\\mathrm{cost}}$ that minimizes expected misclassification cost, and compute the total expected cost on the dataset under this threshold by summing the expected costs over all instances.\n- Using only the foundational definitions of the confusion matrix counts (True Positive, False Positive, True Negative, False Negative), precision, recall, and the harmonic mean, determine the threshold $t_{F1}$ (chosen from the set of unique score values in the dataset) that maximizes the $F_1$ score on this dataset. Then, compute the total expected cost on the dataset under $t_{F1}$ by summing the expected costs over all instances.\n- Quantify the regret of optimizing $F_1$ instead of expected cost as the difference between the total expected cost under $t_{F1}$ and the total expected cost under $t_{\\mathrm{cost}}$.\n\nRound your final numerical answer for the regret to four significant figures. Express your final answer as a single real number with no units.",
            "solution": "### Part 1: Risk Minimization and Optimal Cost Threshold\nWe seek the threshold $t_{\\mathrm{cost}}$ that minimizes the expected misclassification cost. For a single instance with score $s = \\mathbb{P}(Y=1 \\mid X)$, the probability of it being negative is $\\mathbb{P}(Y=0 \\mid X) = 1 - s$.\n\nThe expected cost of classifying the instance as positive (action $a=1$) is:\n$$E[\\text{Cost} \\mid s, a=1] = C_{\\mathrm{FP}} \\cdot \\mathbb{P}(Y=0 \\mid X) = C_{\\mathrm{FP}}(1-s)$$\nThe expected cost of classifying the instance as negative (action $a=0$) is:\n$$E[\\text{Cost} \\mid s, a=0] = C_{\\mathrm{FN}} \\cdot \\mathbb{P}(Y=1 \\mid X) = C_{\\mathrm{FN}} s$$\n\nThe principle of risk minimization dictates that we should choose the action with the lower expected cost. We should classify as positive if:\n$$E[\\text{Cost} \\mid s, a=1] \\leq E[\\text{Cost} \\mid s, a=0]$$\n$$C_{\\mathrm{FP}}(1-s) \\leq C_{\\mathrm{FN}} s$$\nSubstituting the given cost values, $C_{\\mathrm{FP}} = 1$ and $C_{\\mathrm{FN}} = 20$:\n$$1(1-s) \\leq 20 s$$\n$$1 - s \\leq 20 s$$\n$$1 \\leq 21 s$$\n$$s \\geq \\frac{1}{21}$$\nThe decision rule is to classify as positive if the score $s$ is greater than or equal to the threshold $t_{\\mathrm{cost}} = \\frac{1}{21}$.\nNumerically, $t_{\\mathrm{cost}} \\approx 0.0476$.\nThe smallest score in the dataset is $s=0.05$. Since $0.05 = \\frac{1}{20}$ and $\\frac{1}{20}  \\frac{1}{21}$, every instance in the dataset has a score $s_i  t_{\\mathrm{cost}}$.\nTherefore, under this optimal threshold, every instance is classified as positive.\n\nThe total expected cost on the dataset, $C_{\\mathrm{total}}(t_{\\mathrm{cost}})$, is the sum of the expected costs for each instance, given the decision rule. Since all instances are classified as positive, the cost for each is $C_{\\mathrm{FP}}(1-s_i) = 1(1-s_i)$.\n$$C_{\\mathrm{total}}(t_{\\mathrm{cost}}) = \\sum_{i=1}^{12} (1-s_i) = 12 - \\sum_{i=1}^{12} s_i$$\nLet's sum the scores:\n$$\\sum s_i = 0.95+0.85+0.70+0.65+0.60+0.55+0.50+0.40+0.35+0.20+0.10+0.05 = 5.90$$\nThe total expected cost is:\n$$C_{\\mathrm{total}}(t_{\\mathrm{cost}}) = 12 - 5.90 = 6.10$$\n\n### Part 2: $F_1$ Score Maximization and its Associated Cost\nThe $F_1$ score is the harmonic mean of precision ($P$) and recall ($R$):\n$$F_1 = 2 \\cdot \\frac{P \\cdot R}{P+R}$$\nwhere $P = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}$ and $R = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}$. Here, $\\mathrm{TP}$, $\\mathrm{FP}$, and $\\mathrm{FN}$ are the counts of true positives, false positives, and false negatives, respectively. The total number of positive instances in the dataset is $P_{true} = 6$, and the total number of negative instances is $N_{true} = 6$.\n\nWe evaluate the $F_1$ score for each unique score value in the dataset as a potential threshold $t$. The decision rule is: predict positive if $s_i \\geq t$.\n\n- $t = 0.95$: $\\mathrm{TP}=1, \\mathrm{FP}=0$. $P=\\frac{1}{1}=1, R=\\frac{1}{6}$. $F_1 = \\frac{2 \\cdot 1 \\cdot \\frac{1}{6}}{1+\\frac{1}{6}} = \\frac{1/3}{7/6} = \\frac{2}{7}$.\n- $t = 0.85$: $\\mathrm{TP}=2, \\mathrm{FP}=0$. $P=\\frac{2}{2}=1, R=\\frac{2}{6}=\\frac{1}{3}$. $F_1 = \\frac{2 \\cdot 1 \\cdot \\frac{1}{3}}{1+\\frac{1}{3}} = \\frac{2/3}{4/3} = \\frac{1}{2}$.\n- $t = 0.70$: $\\mathrm{TP}=2, \\mathrm{FP}=1$. $P=\\frac{2}{3}, R=\\frac{2}{6}=\\frac{1}{3}$. $F_1 = \\frac{2 \\cdot \\frac{2}{3} \\cdot \\frac{1}{3}}{\\frac{2}{3}+\\frac{1}{3}} = \\frac{4/9}{1} = \\frac{4}{9}$.\n- $t = 0.65$: $\\mathrm{TP}=3, \\mathrm{FP}=1$. $P=\\frac{3}{4}, R=\\frac{3}{6}=\\frac{1}{2}$. $F_1 = \\frac{2 \\cdot \\frac{3}{4} \\cdot \\frac{1}{2}}{\\frac{3}{4}+\\frac{1}{2}} = \\frac{3/4}{5/4} = \\frac{3}{5}$.\n- $t = 0.55$: $\\mathrm{TP}=4, \\mathrm{FP}=2$. $P=\\frac{4}{6}=\\frac{2}{3}, R=\\frac{4}{6}=\\frac{2}{3}$. $F_1 = \\frac{2 \\cdot \\frac{2}{3} \\cdot \\frac{2}{3}}{\\frac{2}{3}+\\frac{2}{3}} = \\frac{8/9}{4/3} = \\frac{2}{3}$.\n- $t = 0.50$: $\\mathrm{TP}=4, \\mathrm{FP}=3$. $P=\\frac{4}{7}, R=\\frac{4}{6}=\\frac{2}{3}$. $F_1 = \\frac{2 \\cdot \\frac{4}{7} \\cdot \\frac{2}{3}}{\\frac{4}{7}+\\frac{2}{3}} = \\frac{16/21}{26/21} = \\frac{8}{13}$.\n- $t = 0.40$: $\\mathrm{TP}=5, \\mathrm{FP}=3$. $P=\\frac{5}{8}, R=\\frac{5}{6}$. $F_1 = \\frac{2 \\cdot \\frac{5}{8} \\cdot \\frac{5}{6}}{\\frac{5}{8}+\\frac{5}{6}} = \\frac{25/24}{35/24} = \\frac{25}{35} = \\frac{5}{7}$.\n- $t = 0.35$: $\\mathrm{TP}=5, \\mathrm{FP}=4$. $P=\\frac{5}{9}, R=\\frac{5}{6}$. $F_1 = \\frac{2 \\cdot \\frac{5}{9} \\cdot \\frac{5}{6}}{\\frac{5}{9}+\\frac{5}{6}} = \\frac{25/27}{25/18} = \\frac{18}{27} = \\frac{2}{3}$.\n- $t = 0.20$: $\\mathrm{TP}=5, \\mathrm{FP}=5$. $P=\\frac{5}{10}=\\frac{1}{2}, R=\\frac{5}{6}$. $F_1 = \\frac{2 \\cdot \\frac{1}{2} \\cdot \\frac{5}{6}}{\\frac{1}{2}+\\frac{5}{6}} = \\frac{5/6}{8/6} = \\frac{5}{8}$.\n- $t = 0.10$: $\\mathrm{TP}=5, \\mathrm{FP}=6$. $P=\\frac{5}{11}, R=\\frac{5}{6}$. $F_1 = \\frac{2 \\cdot \\frac{5}{11} \\cdot \\frac{5}{6}}{\\frac{5}{11}+\\frac{5}{6}} = \\frac{50/66}{85/66} = \\frac{50}{85} = \\frac{10}{17}$.\n- $t = 0.05$: $\\mathrm{TP}=6, \\mathrm{FP}=6$. $P=\\frac{6}{12}=\\frac{1}{2}, R=\\frac{6}{6}=1$. $F_1 = \\frac{2 \\cdot \\frac{1}{2} \\cdot 1}{\\frac{1}{2}+1} = \\frac{1}{3/2} = \\frac{2}{3}$.\n\nComparing the $F_1$ scores: $\\frac{2}{7} \\approx 0.286$, $\\frac{1}{2}=0.5$, $\\frac{4}{9}\\approx 0.444$, $\\frac{3}{5}=0.6$, $\\frac{2}{3}\\approx 0.667$, $\\frac{8}{13}\\approx 0.615$, $\\frac{5}{7}\\approx 0.714$.\nThe maximum $F_1$ score is $\\frac{5}{7}$, which occurs at the threshold $t_{F1} = 0.40$.\n\nNow, we calculate the total expected cost for $t_{F1} = 0.40$.\n- For instances with $s_i \\geq 0.40$, we classify as positive, and the cost is $1(1-s_i)$. These are the scores: $0.95, 0.85, 0.70, 0.65, 0.60, 0.55, 0.50, 0.40$.\n- For instances with $s_i  0.40$, we classify as negative, and the cost is $20 s_i$. These are the scores: $0.35, 0.20, 0.10, 0.05$.\n\nThe total expected cost $C_{\\mathrm{total}}(t_{F1})$ is:\n$$C_{\\mathrm{total}}(t_{F1}) = \\sum_{s_i \\geq 0.40} (1-s_i) + \\sum_{s_i  0.40} 20 s_i$$\nSum for the first group:\n$$ (1-0.95) + (1-0.85) + (1-0.70) + (1-0.65) + (1-0.60) + (1-0.55) + (1-0.50) + (1-0.40) $$\n$$ = 0.05 + 0.15 + 0.30 + 0.35 + 0.40 + 0.45 + 0.50 + 0.60 = 2.80 $$\nSum for the second group:\n$$ 20(0.35) + 20(0.20) + 20(0.10) + 20(0.05) $$\n$$ = 7 + 4 + 2 + 1 = 14.0 $$\nTotal expected cost:\n$$ C_{\\mathrm{total}}(t_{F1}) = 2.80 + 14.0 = 16.80 $$\n\n### Part 3: Regret Calculation\nThe regret of optimizing for $F_1$ score instead of expected cost is the difference between the total cost under $t_{F1}$ and the minimum possible total cost, which is achieved with $t_{\\mathrm{cost}}$.\n$$ \\text{Regret} = C_{\\mathrm{total}}(t_{F1}) - C_{\\mathrm{total}}(t_{\\mathrm{cost}}) $$\n$$ \\text{Regret} = 16.80 - 6.10 = 10.70 $$\nThe problem requires the answer to be rounded to four significant figures. The calculated value $10.70$ is already in this form.",
            "answer": "$$\n\\boxed{10.70}\n$$"
        }
    ]
}