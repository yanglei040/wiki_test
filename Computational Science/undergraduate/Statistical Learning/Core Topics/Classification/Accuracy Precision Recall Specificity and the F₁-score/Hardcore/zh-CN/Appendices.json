{
    "hands_on_practices": [
        {
            "introduction": "理论指标在解决现实世界问题时才真正显示其价值，尤其是在那些准确率可能产生误导的不平衡数据集中。 这个练习将指导你为一个具体的不平衡数据集计算两种不同模型的全套性能指标。它突出了精确率和召回率之间的权衡，并展示了 $F_1$ 分数在做出均衡决策中的关键作用。",
            "id": "3094207",
            "problem": "一个职业体育联盟正在试用两款自动化助手，以帮助裁判在比赛中检测一种罕见的犯规。该联盟有一个包含 $N=10000$ 次比赛回合的已标注评估集，其中 $F=100$ 次是真实犯规（真实标签），这反映了犯规的罕见性。对于每个自动化助手，“标记”表示该助手预测某次比赛回合中发生了犯规。\n\n助手 $\\mathsf{A}$（设计为高召回率、低精确率）标记了 $990$ 次比赛回合；在这些被标记的比赛回合中，$90$ 次是真实犯规。助手 $\\mathsf{B}$（设计为高精确率、低召回率）标记了 $40$ 次比赛回合；在这些被标记的比赛回合中，$38$ 次是真实犯规。未被标记的比赛回合被预测为“无犯规”。\n\n为每个助手构建一个 $2\\times 2$ 的混淆矩阵，其中包含真正例（TP）、假正例（FP）、真反例（TN）和假反例（FN）的计数。然后，使用基于这些计数的标准定义，计算：\n- 准确率 (Accuracy),\n- 精确率 ($P$),\n- 召回率 ($R$),\n- 特异度 (Specificity),\n- $F_1$ 分数。\n\n最后，确定哪个助手在此评估集上产生更高的 $F_1$ 分数。\n\n选择一个选项：\n\nA. 助手 $\\mathsf{A}$（高 $R$/低 $P$）的 $F_1$ 分数更高。\n\nB. 助手 $\\mathsf{B}$（高 $P$/低 $R$）的 $F_1$ 分数更高。\n\nC. 两个助手的 $F_1$ 分数相同。\n\nD. 在没有超出给定计数的类别普遍性额外信息的情况下无法确定。",
            "solution": "对问题陈述进行验证。\n\n**步骤 1：提取给定信息**\n- 评估集中的比赛回合总数：$N = 10000$。\n- 真实犯规总数（正类）：$F = 100$。\n- 真实非犯规数（负类）为 $N - F = 10000 - 100 = 9900$。\n- 对于助手 $\\mathsf{A}$：\n  - 它标记（预测为正例）了 $990$ 次比赛回合。\n  - 在被标记的比赛回合中，$90$ 次是真实犯规。\n- 对于助手 $\\mathsf{B}$：\n  - 它标记（预测为正例）了 $40$ 次比赛回合。\n  - 在被标记的比赛回合中，$38$ 次是真实犯规。\n\n**步骤 2：使用提取的给定信息进行验证**\n- **科学依据**：该问题基于统计学习和机器学习中标准的、明确定义的度量标准（混淆矩阵、准确率、精确率、召回率、$F_1$ 分数）。这些概念在数学上是严谨的，并广泛用于评估分类模型。\n- **适定性**：该问题提供了构建两个助手的混淆矩阵并随后计算所需性能指标的所有必要信息。最终的问题是明确的。\n- **客观性**：该问题以客观术语陈述，使用了统计学领域的标准术语。\n- **一致性和完整性**：所提供的数字在内部是一致且充分的。对于每个助手，都给出了真正例的数量和预测正例的总数。结合整个数据集的真实正例和真实反例的真实标签计数，可以唯一确定混淆矩阵的所有组成部分。例如，对于助手 $\\mathsf{A}$，我们有 $TP_A=90$ 和 $TP_A+FP_A=990$，这意味着 $FP_A=900$。鉴于真实正例为 $100$，则 $FN_A = 100 - TP_A = 10$。鉴于真实反例为 $9900$，则 $TN_A = 9900 - FP_A = 9000$。总和 $TP_A+FP_A+FN_A+TN_A=90+900+10+9000=10000=N$，确认了一致性。类似的检查也确认了助手 $\\mathsf{B}$ 的一致性。\n\n**步骤 3：结论和行动**\n- 该问题是有效的，因为它具有科学依据、适定、客观、完整且一致。可以继续进行求解过程。\n\n---\n\n任务是比较两个自动化助手 $\\mathsf{A}$ 和 $\\mathsf{B}$ 的 $F_1$ 分数。分析需要为每个助手构建一个 $2 \\times 2$ 的混淆矩阵，并计算几个性能指标。\n\n二元分类任务的混淆矩阵结构如下：\n- **真正例 ($TP$)**：被正确分类为正例的正实例数。\n- **假正例 ($FP$)**：被错误分类为正例的负实例数（第一类错误）。\n- **真反例 ($TN$)**：被正确分类为负例的负实例数。\n- **假反例 ($FN$)**：被错误分类为负例的正实例数（第二类错误）。\n\n根据这些计数，我们定义以下度量标准：\n- **精确率 ($P$)**：在预测为正例的实例中，实际为正例的比例。\n  $$P = \\frac{TP}{TP + FP}$$\n- **召回率 ($R$)**：在所有实际为正例的实例中，被正确识别的比例。也称为灵敏度或真正例率。\n  $$R = \\frac{TP}{TP + FN}$$\n- **$F_1$ 分数**：精确率和召回率的调和平均数。\n  $$F_1 = 2 \\cdot \\frac{P \\cdot R}{P + R} = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}$$\n- **准确率**：在所有实例中，被正确分类的比例。\n  $$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n- **特异度**：在所有实际为负例的实例中，被正确识别的比例。也称为真反例率。\n  $$\\text{Specificity} = \\frac{TN}{TN + FP}$$\n\n真实正例（犯规）的总数是 $100$，真实反例（无犯规）的总数是 $10000 - 100 = 9900$。\n\n**对助手 $\\mathsf{A}$ 的分析**\n- 预测为正例（被标记的比赛回合）= $TP_A + FP_A = 990$。\n- 真正例 ($TP_A$)：在被标记的比赛回合中，$90$ 次是真实犯规。所以，$TP_A = 90$。\n- 假正例 ($FP_A$)：$FP_A = 990 - TP_A = 990 - 90 = 900$。\n- 假反例 ($FN_A$)：真实犯规总数为 $100$。$FN_A = (\\text{真实正例}) - TP_A = 100 - 90 = 10$。\n- 真反例 ($TN_A$)：非犯规总数为 $9900$。$TN_A = (\\text{真实反例}) - FP_A = 9900 - 900 = 9000$。\n\n助手 $\\mathsf{A}$ 的混淆矩阵是：\n```\n              | 预测为犯规 | 预测为无犯规 | 总计\n--------------|--------------|----------------|------\n真实犯规      |   TP_A = 90  |   FN_A = 10    |  100\n真实无犯规    |  FP_A = 900  |  TN_A = 9000   | 9900\n--------------|--------------|----------------|------\n总计          |     990      |      9010      | 10000\n```\n助手 $\\mathsf{A}$ 的度量指标：\n- 准确率$_A = \\frac{90 + 9000}{10000} = \\frac{9090}{10000} = 0.909$。\n- 特异度$_A = \\frac{9000}{9000 + 900} = \\frac{9000}{9900} = \\frac{10}{11} \\approx 0.9091$。\n- 精确率 $P_A = \\frac{TP_A}{TP_A + FP_A} = \\frac{90}{990} = \\frac{1}{11}$。\n- 召回率 $R_A = \\frac{TP_A}{TP_A + FN_A} = \\frac{90}{100} = 0.90 = \\frac{9}{10}$。\n- $F_{1,A}$ 分数 $= 2 \\cdot \\frac{P_A \\cdot R_A}{P_A + R_A} = 2 \\cdot \\frac{(\\frac{1}{11}) \\cdot (\\frac{9}{10})}{(\\frac{1}{11}) + (\\frac{9}{10})} = 2 \\cdot \\frac{\\frac{9}{110}}{\\frac{10+99}{110}} = 2 \\cdot \\frac{9}{109} = \\frac{18}{109}$。\n数值上，$F_{1,A} \\approx 0.1651$。\n\n**对助手 $\\mathsf{B}$ 的分析**\n- 预测为正例（被标记的比赛回合）= $TP_B + FP_B = 40$。\n- 真正例 ($TP_B$)：在被标记的比赛回合中，$38$ 次是真实犯规。所以，$TP_B = 38$。\n- 假正例 ($FP_B$)：$FP_B = 40 - TP_B = 40 - 38 = 2$。\n- 假反例 ($FN_B$)：$FN_B = (\\text{真实正例}) - TP_B = 100 - 38 = 62$。\n- 真反例 ($TN_B$)：$TN_B = (\\text{真实反例}) - FP_B = 9900 - 2 = 9898$。\n\n助手 $\\mathsf{B}$ 的混淆矩阵是：\n```\n              | 预测为犯规 | 预测为无犯规 | 总计\n--------------|--------------|----------------|------\n真实犯规      |   TP_B = 38  |   FN_B = 62    |  100\n真实无犯规    |   FP_B = 2   |  TN_B = 9898   | 9900\n--------------|--------------|----------------|------\n总计          |      40      |      9960      | 10000\n```\n助手 $\\mathsf{B}$ 的度量指标：\n- 准确率$_B = \\frac{38 + 9898}{10000} = \\frac{9936}{10000} = 0.9936$。\n- 特异度$_B = \\frac{9898}{9898 + 2} = \\frac{9898}{9900} \\approx 0.9998$。\n- 精确率 $P_B = \\frac{TP_B}{TP_B + FP_B} = \\frac{38}{40} = 0.95 = \\frac{19}{20}$。\n- 召回率 $R_B = \\frac{TP_B}{TP_B + FN_B} = \\frac{38}{100} = 0.38 = \\frac{19}{50}$。\n- $F_{1,B}$ 分数 $= 2 \\cdot \\frac{P_B \\cdot R_B}{P_B + R_B} = 2 \\cdot \\frac{(0.95) \\cdot (0.38)}{0.95 + 0.38} = 2 \\cdot \\frac{0.361}{1.33} = \\frac{0.722}{1.33} = \\frac{722}{1330} = \\frac{361}{665}$。\n数值上，$F_{1,B} \\approx 0.5429$。\n\n**比较与结论**\n我们必须比较 $F_1$ 分数：\n- $F_{1,A} = \\frac{18}{109} \\approx 0.1651$\n- $F_{1,B} = \\frac{361}{665} \\approx 0.5429$\n\n显然，$F_{1,B}  F_{1,A}$。助手 $\\mathsf{B}$ 的 $F_1$ 分数更高。问题指出，助手 $\\mathsf{A}$ 是高召回率/低精确率（$R_A=0.9$，$P_A\\approx 0.09$），而助手 $\\mathsf{B}$ 是高精确率/低召回率（$P_B=0.95$，$R_B=0.38$），我们的计算证实了这一点。我们的结论是，在这种情况下，高精确率/低召回率的助手具有更高的 $F_1$ 分数。\n\n**选项评估**\n- **A. 助手 $\\mathsf{A}$（高 $R$/低 $P$）的 $F_1$ 分数更高。** 这是 **错误的**。我们的计算显示 $F_{1,A}  F_{1,B}$。\n- **B. 助手 $\\mathsf{B}$（高 $P$/低 $R$）的 $F_1$ 分数更高。** 这是 **正确的**。我们的计算显示 $F_{1,B}  F_{1,A}$。\n- **C. 两个助手的 $F_1$ 分数相同。** 这是 **错误的**。$\\frac{18}{109} \\neq \\frac{361}{665}$。\n- **D. 在没有超出给定计数的类别普遍性额外信息的情况下无法确定。** 这是 **错误的**。评估集的类别普遍性（真实犯规和非犯规的数量）已经给出（$10000$ 次比赛回合中有 $100$ 次犯规），并且计算 $F_1$ 分数所需的所有计数都已提供或可以推导出来。计算是确定的。",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "在处理了真实场景之后，探索极端或“基线”模型有助于建立更深刻的直觉。 这个问题研究了一个尽可能简单的分类器，通过分析其性能来揭示评估指标的内在属性。通过为一个总是预测正类的分类器推导指标，你将看到指标在边缘情况下的行为，并更好地理解流行度与朴素模型的精确率和准确率之间的关系。",
            "id": "3094187",
            "problem": "考虑一个二元分类任务，其中有$N$个带标签的实例，每个真实标签$y \\in \\{0,1\\}$，正类别流行度为 $\\pi \\in (0,1)$，定义为 $\\pi = N_{+}/N$，其中$N_{+}$是正例的数量，$N_{-} = N - N_{+}$是负例的数量。一个确定性分类器对每个实例都生成预测$\\hat{y} = 1$。\n\n从标准的混淆矩阵计数——真阳性、假阳性、真阴性和假阴性——以及准确率、精确率、召回率（真阳性率）、特异性（真阴性率）和F1分数（F1）的基本定义出发，推导出当召回率$R$等于$1$且特异性$S$等于$0$时，$N_{+}$和$N_{-}$需要满足的明确条件。在这些条件下，证明精确率$P$等于$\\pi$，准确率$\\text{Acc}$也等于$\\pi$。然后，将F1分数表示为仅关于流行度$\\pi$的闭式函数。无需四舍五入。你的最终答案必须是仅用$\\pi$表示的F1分数的简化解析表达式。",
            "solution": "该问题要求从常用分类指标的基本定义出发，为一种特定类型的二元分类器推导F1分数的表达式。第一步是验证问题陈述的有效性。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n- **任务**：二元分类。\n- **实例**：$N$个带标签的实例。\n- **真实标签**：$y \\in \\{0,1\\}$，其中$y=1$为正类别，$y=0$为负类别。\n- **正类别流行度**：$\\pi \\in (0,1)$，定义为 $\\pi = N_{+}/N$。\n- **正例数量**：$N_{+}$。\n- **负例数量**：$N_{-} = N - N_{+}$。\n- **分类器行为**：一个确定性分类器，对每个实例都生成预测$\\hat{y} = 1$。\n- **使用的指标**：准确率 (Acc)、精确率 ($P$)、召回率 ($R$)、特异性 ($S$)、F1分数 ($F1$)。\n- **要求推导**：\n    1.  找出使$R=1$和$S=0$时$N_{+}$和$N_{-}$需满足的条件。\n    2.  在这些条件下，证明$P = \\pi$且$\\text{Acc} = \\pi$。\n    3.  将F1分数表示为$\\pi$的函数。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题具有科学依据，提法明确且客观。这是统计学习中的一个标准练习，旨在测试在特定、明确定义的基线模型下对分类指标的理解。该模型虽然简单（总是预测正类别），但它是一个有效且常用的参考点。所有术语（$N, N_{+}, N_{-}, \\pi$等）都有明确定义，它们之间的关系也是标准的。该问题不包含科学矛盾、歧义或缺失信息。条件 $\\pi \\in (0,1)$ 确保了数据集中同时存在正类别和负类别（即$N_{+} > 0$和$N_{-} > 0$），这可以防止在指标定义中出现除以零的情况。\n\n**步骤3：结论与行动**\n问题有效。将提供完整解答。\n\n### 解题过程\n\n解答首先根据分类器的指定行为确定混淆矩阵的各项计数。该分类器对所有实例都预测为正类别，即对所有$N$个实例都有$\\hat{y} = 1$。数据集包含$N_{+}$个真实正例（$y=1$）和$N_{-}$个真实负例（$y=0$）。\n\n1.  **混淆矩阵元素**：\n    -   **真阳性 ($TP$)**：真实标签为正（$y=1$）且预测也为正（$\\hat{y}=1$）的实例数量。由于分类器对所有实例都预测$\\hat{y}=1$，它正确分类了所有$N_{+}$个正例。因此，$TP = N_{+}$。\n    -   **假阳性 ($FP$)**：真实标签为负（$y=0$）但预测为正（$\\hat{y}=1$）的实例数量。分类器将所有$N_{-}$个负例错误地分类为正例。因此，$FP = N_{-}$。\n    -   **真阴性 ($TN$)**：真实标签为负（$y=0$）且预测也为负（$\\hat{y}=0$）的实例数量。由于分类器从不预测$\\hat{y}=0$，此计数为零。因此，$TN = 0$。\n    -   **假阴性 ($FN$)**：真实标签为正（$y=1$）但预测为负（$\\hat{y}=0$）的实例数量。由于分类器从不预测$\\hat{y}=0$，此计数也为零。因此，$FN = 0$。\n\n2.  **基本指标定义**：\n    -   召回率 ($R$) 或 真阳性率：$R = \\frac{TP}{TP + FN}$\n    -   特异性 ($S$) 或 真阴性率：$S = \\frac{TN}{TN + FP}$\n    -   精确率 ($P$)：$P = \\frac{TP}{TP + FP}$\n    -   准确率 ($\\text{Acc}$)：$\\text{Acc} = \\frac{TP + TN}{TP + TN + FP + FN} = \\frac{TP+TN}{N}$\n    -   F1分数 ($F1$)：$F1 = \\frac{2 \\cdot P \\cdot R}{P + R}$\n\n3.  **推导$R=1$和$S=0$的条件**：\n    -   将混淆矩阵的计数代入召回率的定义：\n        $$R = \\frac{N_{+}}{N_{+} + 0} = \\frac{N_{+}}{N_{+}}$$\n        要使$R$等于$1$，分母$N_{+}$必须不为零。问题陈述中指出，流行度$\\pi = N_{+}/N$在开区间$(0,1)$内。这意味着$N_{+} > 0$且$N_{-} > 0$。因此，在给定的问题条件下，$R$始终等于$1$。\n    -   将混淆矩阵的计数代入特异性的定义：\n        $$S = \\frac{0}{0 + N_{-}} = \\frac{0}{N_{-}}$$\n        要使$S$等于$0$，分母$N_{-}$必须不为零。由$\\pi \\in (0,1)$可知，$N_{-} = N(1-\\pi) > 0$。因此，在给定的问题条件下，$S$始终等于$0$。\n    -   使$R=1$和$S=0$成立的关于$N_{+}$和$N_{-}$的条件是$N_{+} > 0$和$N_{-} > 0$。这些条件由给定的约束$\\pi \\in (0,1)$自动满足。\n\n4.  **验证$P = \\pi$和$\\text{Acc} = \\pi$**：\n    -   使用精确率的定义：\n        $$P = \\frac{TP}{TP + FP} = \\frac{N_{+}}{N_{+} + N_{-}}$$\n        由于实例总数为$N = N_{+} + N_{-}$，我们可以写出：\n        $$P = \\frac{N_{+}}{N}$$\n        根据问题中对流行度的定义，$\\pi = N_{+}/N$。因此，我们证明了$P=\\pi$。\n    -   使用准确率的定义：\n        $$\\text{Acc} = \\frac{TP + TN}{N} = \\frac{N_{+} + 0}{N} = \\frac{N_{+}}{N}$$\n        同样，使用流行度的定义，我们发现$\\text{Acc}=\\pi$。\n\n5.  **推导用$\\pi$表示的F1分数**：\n    F1分数是精确率和召回率的调和平均数：\n    $$F1 = \\frac{2 \\cdot P \\cdot R}{P + R}$$\n    根据我们之前的步骤，我们已经确定对于此分类器，$P=\\pi$且$R=1$。将这些表达式代入F1分数的公式中得到：\n    $$F1 = \\frac{2 \\cdot \\pi \\cdot 1}{\\pi + 1}$$\n    简化此表达式，得到F1分数作为流行度$\\pi$的函数的最终形式：\n    $$F1 = \\frac{2\\pi}{1+\\pi}$$\n此表达式表示一个总是预测正类别的分类器的F1分数，仅用正类别流行度$\\pi$来表示。",
            "answer": "$$\\boxed{\\frac{2\\pi}{1+\\pi}}$$"
        },
        {
            "introduction": "实践的最后一步是利用这些评估指标来主动指导模型开发，这是机器学习中的一项核心任务。 这个计算练习模拟了超参数调优的过程，它有力地证明了评估指标的选择（$F_1$ 分数与准确率）可能导致选出不同的“最佳”模型。对于任何处理不平衡数据集的实践者来说，这是一个至关重要的教训。",
            "id": "3094204",
            "problem": "给定一个抽象的二元分类场景，旨在以科学上真实且数学上可复现的方式，分离模型、超参数和度量指标的影响。基本对象是二元分类器混淆矩阵中的计数：真正例 ($\\mathrm{TP}$)、假正例 ($\\mathrm{FP}$)、真负例 ($\\mathrm{TN}$) 和假负例 ($\\mathrm{FN}$)。所有度量指标必须仅从这些计数中导出。使用这些定义，推导并实现准确率 (accuracy)、精确率 (precision)、召回率 (recall)、特异度 (specificity) 和 F1分数 (F1-score, F1) 的表达式，然后在相同的不平衡数据上，针对两个不同的目标执行超参数选择。\n\n两种分类器的决策机制都是对一维决策分数应用一个阈值。设正类的分数为一个高斯随机变量 $s_{+} \\sim \\mathcal{N}(\\mu_{+}, \\sigma^{2})$，负类的分数为 $s_{-} \\sim \\mathcal{N}(\\mu_{-}, \\sigma^{2})$，其中 $\\mu_{+}  0$ 且 $\\mu_{-}  0$。正例总数为 $N_{+}$，负例总数为 $N_{-}$，这两者共同控制着数据的不平衡程度。对于应用于分数 $s$ 的决策阈值 $\\tau$，预测为正例的是那些满足 $s \\ge \\tau$ 的样本。\n\n考虑两种分类器：\n- 支持向量机 (SVM)：原始决策分数被直接阈值化，因此决策规则为 $s \\ge \\tau$，其中 $s \\in \\mathbb{R}$ 且 $\\tau \\in \\mathbb{R}$。\n- 逻辑回归 (Logistic Regression)：原始分数 $s$ 通过 logistic sigmoid 函数生成一个概率 $p = \\frac{1}{1 + e^{-s}} \\in (0,1)$，决策规则为 $p \\ge \\tau$，其中 $\\tau \\in (0,1)$。这等价于在 logit 层面对 $s$ 应用阈值，即 $s \\ge \\operatorname{logit}(\\tau)$，其中 $\\operatorname{logit}(\\tau) = \\ln\\!\\left(\\frac{\\tau}{1 - \\tau}\\right)$。\n\n一个单一的标量超参数 $\\theta  0$ 通过缩放两个高斯分数分布的均值来控制它们的分离程度。具体来说，对于给定的基础分离度 $\\mu  0$，使用 $\\mu_{+} = \\theta \\mu$ 和 $\\mu_{-} = -\\theta \\mu$。噪声水平 $\\sigma  0$ 在每个测试用例中是固定的。\n\n对于任何 $(\\theta, \\tau)$ 的选择，期望的混淆矩阵计数由以下公式给出：\n- $\\mathrm{TP} = N_{+} \\cdot \\mathbb{P}(s_{+} \\ge \\tau)$，\n- $\\mathrm{FP} = N_{-} \\cdot \\mathbb{P}(s_{-} \\ge \\tau)$，\n- $\\mathrm{TN} = N_{-} - \\mathrm{FP}$，\n- $\\mathrm{FN} = N_{+} - \\mathrm{TP}$，\n其中 $\\mathbb{P}(s \\ge \\tau)$ 是根据正态分布计算的。对于逻辑回归，请确保通过使用 $s \\ge \\operatorname{logit}(\\tau)$ 在正确的层面上应用阈值。\n\n从混淆矩阵条目的基本定义出发，推导准确率、精确率、召回率、特异度和 F1分数的公式，然后实现它们。对于下面的每个测试用例，对 SVM 和逻辑回归的 $\\theta$ 和 $\\tau$ 进行网格搜索，并记录：\n- 最大化F1分数的 $(\\theta,\\tau)$ 对，\n- 最大化准确率的 $(\\theta,\\tau)$ 对。\n\n您的目标是证明在不平衡数据上，F1最优的超参数与准确率最优的超参数不同，并说明在此设置下支持向量机 (SVM) 和逻辑回归之间的任何对比。\n\n使用以下固定网格进行搜索：\n- $\\Theta = \\{\\,0.8,\\,1.0,\\,1.2\\,\\}$，\n- 对于逻辑回归阈值，$T_{\\mathrm{LR}} = \\{\\,0.2,\\,0.5,\\,0.8\\,\\}$，\n- 对于 SVM 阈值，$T_{\\mathrm{SVM}} = \\{\\, -0.5,\\,0.0,\\,0.5 \\,\\}$。\n\n计算并报告以下四个测试用例的结果，每个用例由 $(N_{+}, N_{-}, \\mu, \\sigma)$ 定义：\n1. $N_{+} = 100$, $N_{-} = 900$, $\\mu = 1.5$, $\\sigma = 1.0$ (中度不平衡，可分性尚可)。\n2. $N_{+} = 50$, $N_{-} = 4950$, $\\mu = 1.0$, $\\sigma = 1.0$ (严重不平衡)。\n3. $N_{+} = 500$, $N_{-} = 500$, $\\mu = 1.5$, $\\sigma = 1.0$ (平衡参考)。\n4. $N_{+} = 100$, $N_{-} = 900$, $\\mu = 0.3$, $\\sigma = 2.5$ (中度不平衡，可分性差)。\n\n您的程序必须：\n- 对于每个测试用例和每个分类器，搜索指定的网格以找到最大化F1分数的 $(\\theta,\\tau)$ 和最大化准确率的 $(\\theta,\\tau)$。如果出现平局，选择在网格顺序中首先遇到的一个。\n- 使用从正态分布计算出的期望计数，而非抽样，以确保确定性。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，其本身是按以下顺序排列的八个浮点数列表：\n$[\\,\\theta_{\\mathrm{F1,LR}},\\,\\tau_{\\mathrm{F1,LR}},\\,\\theta_{\\mathrm{Acc,LR}},\\,\\tau_{\\mathrm{Acc,LR}},\\,\\theta_{\\mathrm{F1,SVM}},\\,\\tau_{\\mathrm{F1,SVM}},\\,\\theta_{\\mathrm{Acc,SVM}},\\,\\tau_{\\mathrm{Acc,SVM}}\\,]$。\n不应打印百分比；所有量必须是纯十进制数。没有物理单位。不涉及角度单位。",
            "solution": "对问题陈述进行验证。\n\n### 第一步：提取已知条件\n- **基础对象**：混淆矩阵计数：真正例 ($\\mathrm{TP}$)、假正例 ($\\mathrm{FP}$)、真负例 ($\\mathrm{TN}$)、假负例 ($\\mathrm{FN}$)。\n- **数据分布**：\n    - 正类分数：$s_{+} \\sim \\mathcal{N}(\\mu_{+}, \\sigma^{2})$。\n    - 负类分数：$s_{-} \\sim \\mathcal{N}(\\mu_{-}, \\sigma^{2})$。\n- **类别大小**：正例总数 $N_{+}$，负例总数 $N_{-}$。\n- **超参数 $\\theta$**：$\\mu_{+} = \\theta \\mu$ 和 $\\mu_{-} = -\\theta \\mu$，其中 $\\mu  0$ 是基础分离度，$\\theta  0$。\n- **决策规则**：如果分数 $s \\ge \\tau'$，则将其分类为正例，其中 $\\tau'$ 是对分数的有效阈值。\n- **分类器模型**：\n    - **支持向量机 (SVM)**：原始分数 $s$ 在 $\\tau \\in \\mathbb{R}$ 处被阈值化。有效阈值为 $\\tau' = \\tau$。\n    - **逻辑回归 (LR)**：分数 $s$ 产生概率 $p = \\frac{1}{1 + e^{-s}}$。决策规则为 $p \\ge \\tau$，其中 $\\tau \\in (0,1)$。这等价于对分数 $s$ 在 $\\tau' = \\operatorname{logit}(\\tau) = \\ln\\!\\left(\\frac{\\tau}{1 - \\tau}\\right)$ 处的有效阈值。\n- **期望计数公式**：\n    - $\\mathrm{TP} = N_{+} \\cdot \\mathbb{P}(s_{+} \\ge \\tau')$。\n    - $\\mathrm{FP} = N_{-} \\cdot \\mathbb{P}(s_{-} \\ge \\tau')$。\n    - $\\mathrm{TN} = N_{-} - \\mathrm{FP}$。\n    - $\\mathrm{FN} = N_{+} - \\mathrm{TP}$。\n- **搜索网格**：\n    - $\\Theta = \\{\\,0.8,\\,1.0,\\,1.2\\,\\}$。\n    - $T_{\\mathrm{LR}} = \\{\\,0.2,\\,0.5,\\,0.8\\,\\}$。\n    - $T_{\\mathrm{SVM}} = \\{\\, -0.5,\\,0.0,\\,0.5 \\,\\}$。\n- **测试用例** $(N_{+}, N_{-}, \\mu, \\sigma)$:\n    1. $(100, 900, 1.5, 1.0)$\n    2. $(50, 4950, 1.0, 1.0)$\n    3. $(500, 500, 1.5, 1.0)$\n    4. $(100, 900, 0.3, 2.5)$\n- **优化目标**：对于每个分类器和测试用例，找到最大化F1分数的 $(\\theta, \\tau)$ 对和最大化准确率的对。\n- **平局打破规则**：如果分数相等，选择在指定网格顺序中首先遇到的配对。\n- **输出格式**：单行表示一个列表，其中每个元素是针对一个测试用例的8个浮点数的列表：$[\\,\\theta_{\\mathrm{F1,LR}},\\,\\tau_{\\mathrm{F1,LR}},\\,\\theta_{\\mathrm{Acc,LR}},\\,\\tau_{\\mathrm{Acc,LR}},\\,\\theta_{\\mathrm{F1,SVM}},\\,\\tau_{\\mathrm{F1,SVM}},\\,\\theta_{\\mathrm{Acc,SVM}},\\,\\tau_{\\mathrm{Acc,SVM}}\\,]$。\n\n### 第二步：使用提取的已知条件进行验证\n- **科学基础**：该问题在统计学习理论中有坚实的基础。它使用标准模型（SVM、LR）、度量指标（准确率、F1分数）和建模假设（高斯分数分布，这是信号检测理论和分类器分析中常见的抽象）。其数学是标准且正确的。\n- **良态问题**：该问题是确定性的，因为它使用从概率分布导出的期望计数，而不是随机抽样。搜索空间是一个有限网格，优化目标定义清晰，并有明确的平局打破规则。这确保了存在唯一且可计算的解。\n- **客观性**：问题以精确、形式化的数学语言陈述，没有主观性或歧义。\n- **完整性**：所有必要的数据，包括模型参数、搜索网格和测试用例，都已提供。问题是自包含的。\n\n### 第三步：结论与行动\n问题是有效的。这是一个关于统计模型评估和超参数选择的、定义明确的计算练习。将提供一个解决方案。\n\n***\n\n该解决方案需要从基本原理出发，系统地推导性能度量指标，然后实现确定性的网格搜索，以在不同目标下识别最优超参数。\n\n### 1. 性能度量指标的推导\n\n所有性能度量指标都是混淆矩阵四个基本量的函数：$\\mathrm{TP}$ (真正例)、$\\mathrm{FP}$ (假正例)、$\\mathrm{TN}$ (真负例) 和 $\\mathrm{FN}$ (假负例)。正例总数为 $N_{+} = \\mathrm{TP} + \\mathrm{FN}$，负例总数为 $N_{-} = \\mathrm{TN} + \\mathrm{FP}$。\n\n- **准确率 (Accuracy)**：所有决策中正确的比例。\n$$ \\text{Accuracy} = \\frac{\\mathrm{TP} + \\mathrm{TN}}{\\mathrm{TP} + \\mathrm{TN} + \\mathrm{FP} + \\mathrm{FN}} = \\frac{\\mathrm{TP} + \\mathrm{TN}}{N_{+} + N_{-}} $$\n- **精确率 (Precision, 正预测值)**：正向预测中正确的比例。\n$$ \\text{Precision} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}} $$\n如果分母为零，此度量指标未定义。按照惯例，如果 $\\mathrm{TP} + \\mathrm{FP} = 0$，则精确率取为 $0$。\n\n- **召回率 (Recall, 灵敏度, 真正例率)**：实际正例中被正确识别的比例。\n$$ \\text{Recall} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} = \\frac{\\mathrm{TP}}{N_{+}} $$\n- **特异度 (Specificity, 真负例率)**：实际负例中被正确识别的比例。\n$$ \\text{Specificity} = \\frac{\\mathrm{TN}}{\\mathrm{TN} + \\mathrm{FP}} = \\frac{\\mathrm{TN}}{N_{-}} $$\n- **F1分数 (F1-Score)**：精确率和召回率的调和平均数。它提供了一个平衡这两个度量指标的单一分数。\n$$ F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n代入精确率和召回率的定义并简化，我们得到一个在数值上更稳定的形式，可以避免当精确率或召回率为零时可能出现的除以零的情况：\n$$ F_1 = \\frac{2 \\mathrm{TP}}{2 \\mathrm{TP} + \\mathrm{FP} + \\mathrm{FN}} $$\n如果 $\\mathrm{TP} = 0$，则 $F_1 = 0$。只要 $N_{+}  0$ 和 $N_{-}  0$，这个形式就是稳健的，因为 $2\\mathrm{TP} + \\mathrm{FP} + \\mathrm{FN}  0$。\n\n### 2. 期望混淆矩阵计数的计算\n\n问题的核心是基于高斯分数分布计算 $\\mathrm{TP}$ 和 $\\mathrm{FP}$ 的期望值。设 $s$ 是一个代表分类器原始分数的随机变量，其中 $s \\sim \\mathcal{N}(\\mu_s, \\sigma^2)$。该分数超过阈值 $\\tau'$ 的概率由生存函数 (SF)，即 1 - 累积分布函数 (CDF) 给出。\n\n设 $Z$ 是一个标准正态随机变量，$Z \\sim \\mathcal{N}(0, 1)$，并设 $\\Phi(z)$ 是其 CDF。\n$$ \\mathbb{P}(s \\ge \\tau') = \\mathbb{P}\\left(\\frac{s - \\mu_s}{\\sigma} \\ge \\frac{\\tau' - \\mu_s}{\\sigma}\\right) = \\mathbb{P}\\left(Z \\ge \\frac{\\tau' - \\mu_s}{\\sigma}\\right) = 1 - \\Phi\\left(\\frac{\\tau' - \\mu_s}{\\sigma}\\right) $$\n这是在 $z = (\\tau' - \\mu_s) / \\sigma$ 处评估的标准正态分布的生存函数。\n\n对于我们的具体问题，给定一个超参数 $\\theta$：\n- 正类分数分布为 $s_{+} \\sim \\mathcal{N}(\\mu_{+}, \\sigma^2)$，其中 $\\mu_{+} = \\theta \\mu$。\n- 负类分数分布为 $s_{-} \\sim \\mathcal{N}(\\mu_{-}, \\sigma^2)$，其中 $\\mu_{-} = -\\theta \\mu$。\n\n真正例率 (TPR) 和假正例率 (FPR) 分别是正例和负例被分类为正例的概率。\n$$ \\mathrm{TPR}(\\tau', \\theta) = \\mathbb{P}(s_{+} \\ge \\tau') = 1 - \\Phi\\left(\\frac{\\tau' - \\theta\\mu}{\\sigma}\\right) $$\n$$ \\mathrm{FPR}(\\tau', \\theta) = \\mathbb{P}(s_{-} \\ge \\tau') = 1 - \\Phi\\left(\\frac{\\tau' + \\theta\\mu}{\\sigma}\\right) $$\n\n有效阈值 $\\tau'$ 取决于分类器模型：\n- 对于 **SVM**，阈值 $\\tau$ 直接应用于原始分数 $s$。因此，$\\tau' = \\tau$。\n- 对于 **逻辑回归**，阈值 $\\tau \\in (0,1)$ 应用于概率输出 $p = (1+e^{-s})^{-1}$。条件 $p \\ge \\tau$ 等价于 $s \\ge \\ln(\\tau/(1-\\tau))$。因此，有效阈值为 $\\tau' = \\operatorname{logit}(\\tau)$。\n\n利用这些率，期望计数为：\n$$ \\mathrm{TP} = N_{+} \\cdot \\mathrm{TPR}(\\tau', \\theta) $$\n$$ \\mathrm{FP} = N_{-} \\cdot \\mathrm{FPR}(\\tau', \\theta) $$\n$$ \\mathrm{FN} = N_{+} \\cdot (1 - \\mathrm{TPR}(\\tau', \\theta)) = N_{+} - \\mathrm{TP} $$\n$$ \\mathrm{TN} = N_{-} \\cdot (1 - \\mathrm{FPR}(\\tau', \\theta)) = N_{-} - \\mathrm{FP} $$\n\n### 3. 超参数优化过程\n\n对于每个测试用例和分类器，在离散的超参数集 $\\theta \\in \\Theta$ 和 $\\tau \\in T$ 上执行网格搜索。过程如下：\n\n1. 初始化四对变量，用于存储四个目标的最优 $(\\theta, \\tau)$：$(\\theta_{\\mathrm{F1,LR}}, \\tau_{\\mathrm{F1,LR}})$、$(\\theta_{\\mathrm{Acc,LR}}, \\tau_{\\mathrm{Acc,LR}})$、$(\\theta_{\\mathrm{F1,SVM}}, \\tau_{\\mathrm{F1,SVM}})$ 和 $(\\theta_{\\mathrm{Acc,SVM}}, \\tau_{\\mathrm{Acc,SVM}})$。同时，将迄今为止找到的相应最大分数初始化为 $-1.0$。\n\n2. 遍历每个分类器 (LR, SVM)。\n\n3. 对于所选的分类器，遍历有序网格 $\\Theta = [0.8, 1.0, 1.2]$ 中的每个 $\\theta$。\n\n4. 对于每个 $\\theta$，遍历相应的有序阈值网格（$T_{\\mathrm{LR}} = [0.2, 0.5, 0.8]$ 或 $T_{\\mathrm{SVM}} = [-0.5, 0.0, 0.5]$）中的每个 $\\tau$。\n\n5. 对于每个 $(\\theta, \\tau)$ 对：\n    a. 确定有效分数阈值 $\\tau'$。\n    b. 使用第2节中推导的公式计算 $\\mathrm{TPR}$ 和 $\\mathrm{FPR}$。\n    c. 计算期望计数 $\\mathrm{TP}, \\mathrm{FP}, \\mathrm{TN}, \\mathrm{FN}$。\n    d. 使用第1节中的公式计算准确率和F1分数。\n    e. 将计算出的F1分数与当前分类器迄今为止找到的最佳F1分数进行比较。如果新分数严格更大，则更新最佳分数并存储当前的 $(\\theta, \\tau)$ 对。\n    f. 对准确率分数执行类似的比较和更新。严格不等号 `` 实现了在网格顺序中选择第一个遇到的配对的平局打破规则。\n\n6. 遍历所有网格点后，存储的 $(\\theta, \\tau)$ 对代表每个目标的最优超参数。\n\n7. 按照指定顺序收集当前测试用例的八个结果参数值。对所有四个测试用例重复此过程。然后将结果格式化为所需的输出字符串。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the hyperparameter optimization problem for binary classification.\n    \"\"\"\n    \n    # Define the parameter grids. These are treated as ordered lists\n    # to respect the tie-breaking rule.\n    THETA_GRID = [0.8, 1.0, 1.2]\n    T_LR_GRID = [0.2, 0.5, 0.8]   # For Logistic Regression\n    T_SVM_GRID = [-0.5, 0.0, 0.5] # For Support Vector Machine\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N_plus, N_minus, mu_base, sigma)\n        (100, 900, 1.5, 1.0),\n        (50, 4950, 1.0, 1.0),\n        (500, 500, 1.5, 1.0),\n        (100, 900, 0.3, 2.5),\n    ]\n\n    all_results = []\n\n    for n_plus, n_minus, mu_base, sigma in test_cases:\n        \n        # --- Logistic Regression Optimization ---\n        best_f1_lr = -1.0\n        params_f1_lr = (None, None)\n        best_acc_lr = -1.0\n        params_acc_lr = (None, None)\n\n        for theta in THETA_GRID:\n            for tau in T_LR_GRID:\n                # Calculate effective threshold for LR: logit(tau)\n                # Handle tau=0 or tau=1 for numerical stability, though not in grid.\n                if tau == 0 or tau >= 1: continue \n                tau_eff = np.log(tau / (1 - tau))\n\n                # Calculate means based on theta\n                mu_plus = theta * mu_base\n                mu_minus = -theta * mu_base\n\n                # Calculate True Positive Rate and False Positive Rate\n                # Use survival function (1 - CDF) for P(X >= x)\n                tpr = norm.sf((tau_eff - mu_plus) / sigma)\n                fpr = norm.sf((tau_eff - mu_minus) / sigma)\n\n                # Calculate expected confusion matrix counts\n                tp = n_plus * tpr\n                fp = n_minus * fpr\n                fn = n_plus * (1 - tpr)\n                tn = n_minus * (1 - fpr)\n\n                # Calculate metrics\n                # Accuracy\n                accuracy = (tp + tn) / (n_plus + n_minus)\n                \n                # F1-score using robust formula: 2*TP / (2*TP + FP + FN)\n                f1_denom = 2 * tp + fp + fn\n                f1_score = (2 * tp / f1_denom) if f1_denom > 0 else 0.0\n\n                # Update best parameters for LR\n                # Tie-breaking: strict '>' ensures first-in-grid wins\n                if f1_score > best_f1_lr:\n                    best_f1_lr = f1_score\n                    params_f1_lr = (theta, tau)\n                \n                if accuracy > best_acc_lr:\n                    best_acc_lr = accuracy\n                    params_acc_lr = (theta, tau)\n\n        # --- SVM Optimization ---\n        best_f1_svm = -1.0\n        params_f1_svm = (None, None)\n        best_acc_svm = -1.0\n        params_acc_svm = (None, None)\n\n        for theta in THETA_GRID:\n            for tau in T_SVM_GRID:\n                # Effective threshold for SVM is just tau\n                tau_eff = tau\n\n                # Calculate means based on theta\n                mu_plus = theta * mu_base\n                mu_minus = -theta * mu_base\n\n                # Calculate True Positive Rate and False Positive Rate\n                tpr = norm.sf((tau_eff - mu_plus) / sigma)\n                fpr = norm.sf((tau_eff - mu_minus) / sigma)\n\n                # Calculate expected confusion matrix counts\n                tp = n_plus * tpr\n                fp = n_minus * fpr\n                fn = n_plus * (1 - tpr)\n                tn = n_minus * (1 - fpr)\n                \n                # Calculate metrics\n                accuracy = (tp + tn) / (n_plus + n_minus)\n                f1_denom = 2 * tp + fp + fn\n                f1_score = (2 * tp / f1_denom) if f1_denom > 0 else 0.0\n\n                # Update best parameters for SVM\n                if f1_score > best_f1_svm:\n                    best_f1_svm = f1_score\n                    params_f1_svm = (theta, tau)\n                \n                if accuracy > best_acc_svm:\n                    best_acc_svm = accuracy\n                    params_acc_svm = (theta, tau)\n\n        # Collate results for the current test case\n        case_results = [\n            params_f1_lr[0], params_f1_lr[1],\n            params_acc_lr[0], params_acc_lr[1],\n            params_f1_svm[0], params_f1_svm[1],\n            params_acc_svm[0], params_acc_svm[1],\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string as a list of lists.\n    # The `str` of a list already provides the correct '[...]' format for each sublist.\n    # We join these string representations with commas.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}