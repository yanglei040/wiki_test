{
    "hands_on_practices": [
        {
            "introduction": "我们将从一个非常基础但关键的问题入手：线性回归如何处理分类任务中的二元标签？本练习将引导你通过一个实践案例，比较两种常见的标签编码方式——$\\{0, 1\\}$ 和 $\\{-1, 1\\}$——并揭示这种看似随意的选择如何影响模型的预测和决策边界。你会发现，虽然包含截距项的模型能提供一定程度的一致性，但其预测值并不会自然地落在有意义的区间内，这也是线性回归不适用于分类任务的一个根本原因 ()。",
            "id": "3117107",
            "problem": "要求您研究普通最小二乘线性回归在用于二元分类时，不同标签编码下的行为，以及这如何影响决策边界和可解释性。请完全使用以下数学基础进行分析：\n\n- 普通最小二乘 (OLS) 最小化均方误差 (MSE) 目标函数，该函数由下式给出：$$\\min_{\\beta} \\sum_{i=1}^{n} (y_i - z_i^\\top \\beta)^2,$$ 其中，如果包含截距，每个训练输入的增广特征向量为 $$z_i = [1, x_i^\\top]^\\top \\in \\mathbb{R}^{d+1}$$；如果不使用截距，则为 $$z_i = x_i \\in \\mathbb{R}^{d}$$。\n- OLS 解满足正规方程 $$Z^\\top Z \\, \\beta = Z^\\top y,$$ 其中 $$Z \\in \\mathbb{R}^{n \\times p}$$ 是通过将 $$z_i^\\top$$ 逐行堆叠形成的设计矩阵，如果使用截距，则 $$p = d+1$$，否则 $$p = d$$；$$y \\in \\mathbb{R}^{n}$$ 是标签向量。\n\n您的程序必须实现两种常见的二元分类标签编码下的 OLS 拟合：\n- 编码 A: $$y \\in \\{0, 1\\}.$$\n- 编码 B: $$y' \\in \\{-1, 1\\}.$$\n\n在编码 A 下，分类通常通过对拟合值 $$\\hat{y} = z^\\top \\beta$$ 在 $$0.5$$ 处设置阈值来执行；即，如果 $$\\hat{y} \\ge 0.5$$，则预测为类别 $$1$$，否则为类别 $$0$$。在编码 B 下，分类通常通过对 $$\\hat{y}' = z^\\top \\beta'$$ 在 $$0$$ 处设置阈值来执行；即，如果 $$\\hat{y}' \\ge 0$$，则预测为类别 $$1$$，否则为类别 $$-1$$。这些阈值的确切处理方式以及编码选择的影响是本练习的重点。\n\n数据说明：\n- 训练集包含 $$n = 10$$ 个在 $$\\mathbb{R}^2$$ 中的点：\n  - 类别 $$0$$ 的点（编码 A 标签为 $$0$$，编码 B 标签为 $$-1$$）：$$x = [-5, 3], [-4, 2], [-3, 1], [-2, 0.5], [-1, -0.5].$$\n  - 类别 $$1$$ 的点（编码 A 标签为 $$1$$，编码 B 标签为 $$1$$）：$$x = [2, 1], [3, 2], [4, 2.5], [5, 3], [6, 4].$$\n- 对于“有截距”的模型，使用增广特征 $$z = [1, x_1, x_2]^\\top$$。对于“无截距”的模型，使用特征 $$z = [x_1, x_2]^\\top$$。\n\n评估网格：\n- 定义一个测试点网格 $$x = (x_1, x_2)$$，其中 $$x_1 \\in \\{-6, -5, \\dots, 6\\}$$ 且 $$x_2 \\in \\{-3, -2, \\dots, 6\\}$$，形成一个 $$13 \\times 10$$ 的网格点。使用这些点来评估决策区域和可解释性属性。\n\n您必须实现以下四个测试用例，以探究线性回归用于分类的缺点的不同方面。每个测试用例必须产生一个单一的基本类型：布尔值、整数或浮点数。\n\n- 测试用例 $$1$$（在有截距和正确阈值的情况下，决策边界在不同编码间的恒定性）：\n  - 在编码 A 下拟合带截距的 OLS，得到 $$\\hat{y}(x)$$，并使用阈值 $$0.5$$ 将网格点分类为 $$\\{0,1\\}$$ 标签。\n  - 在编码 B 下拟合带截距的 OLS，得到 $$\\hat{y}'(x)$$，并使用阈值 $$0$$ 将网格点分类为 $$\\{-1,1\\}$$ 标签。通过 $$-1 \\mapsto 0, 1 \\mapsto 1$$ 将这些标签映射到 $$\\{0,1\\}$$。\n  - 返回一个布尔值，指示对于所有网格点，两种分类标签是否完全相同。\n\n- 测试用例 $$2$$（在有截距情况下，编码 A 产生的超出范围的拟合值）：\n  - 使用带截距的 OLS 在编码 A 下的拟合结果，计算其拟合值 $$\\hat{y}(x)$$ 落在 $$[0, 1]$$ 区间之外的网格点的比例。以 $$[0,1]$$ 范围内的浮点数形式返回此比例。这量化了一个缺点：线性回归的拟合值不是概率，并且可能超出可解释的范围。\n\n- 测试用例 $$3$$（在无截距情况下，仿射一致性的失效）：\n  - 在两种编码下拟合不带截距的 OLS，以获得训练输入上的拟合值 $$\\hat{y}(x_i)$$ 和 $$\\hat{y}'(x_i)$$。\n  - 设 $$a$$ 和 $$c$$ 是满足 $$a \\cdot 0 + c = -1$$ 和 $$a \\cdot 1 + c = 1$$ 的唯一标量（即从 $$[0,1]$$到$$[-1,1]$$的唯一仿射映射）。计算在所有训练点上，$$\\hat{y}'(x_i)$$ 与 $$a \\, \\hat{y}(x_i) + c$$ 之间的最大绝对偏差。以浮点数形式返回此最大偏差。一个非零的偏差表明，当省略截距时，编码的改变会改变拟合的决策函数。\n\n- 测试用例 $$4$$（在有截距情况下，编码 B 中与编码相关的阈值设定）：\n  - 使用带截距的 OLS 在编码 B 下的拟合结果，对网格点进行两次分类：一次使用阈值 $$0$$，另一次对 $$\\hat{y}'(x)$$ 使用阈值 $$0.5$$。\n  - 返回一个整数，等于在这两种阈值下分类结果不同的网格点的数量。这量化了编码和阈值的改变如何移动决策边界并影响可解释性。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含测试用例 $$1$$ 到 $$4$$ 的结果，形式为逗号分隔的列表，并用方括号括起来，顺序为 $$[\\text{TC1}, \\text{TC2}, \\text{TC3}, \\text{TC4}]$$。例如，$$[ \\text{boolean}, \\text{float}, \\text{float}, \\text{integer} ]$$。\n- 不允许任何外部输入；所有数据均如上所述。",
            "solution": "用户提供了一个问题，要求分析普通最小二乘 (OLS) 线性回归用于二元分类时的行为。分析的重点是不同标签编码以及包含或排除截距项的影响。该问题定义明确，科学上合理，并提供了所有必要的数据和评估标准。这是一个统计学习中的有效问题。\n\nOLS 的核心是最小化均方误差 (MSE)，定义为观测标签 $$y_i$$ 和预测值 $$\\hat{y}_i = z_i^\\top \\beta$$ 之间平方差的总和。目标函数是 $$J(\\beta) = \\sum_{i=1}^{n} (y_i - z_i^\\top \\beta)^2$$。最小化该目标函数的最优参数向量 $$\\beta$$ 可通过求解正规方程 $$Z^\\top Z \\beta = Z^\\top y$$ 找到，其中 $$Z$$ 是设计矩阵，$$y$$ 是标签向量。其解为 $$\\beta = (Z^\\top Z)^{-1} Z^\\top y$$，前提是矩阵 $$Z^\\top Z$$ 是可逆的，对于给定的非共线数据，此条件成立。\n\n我们将继续解决四个指定的测试用例。\n\n### 测试用例 1：决策边界在不同编码间的恒定性\n该测试用例检验当模型包含截距时，决策边界是否对标签的仿射变换保持不变。\n设编码 A 使用标签 $$y_A \\in \\{0, 1\\}$$，编码 B 使用标签 $$y_B \\in \\{-1, 1\\}$$。这两种编码通过仿射变换 $$y_B = 2y_A - 1$$ 相关联。设 $$\\beta_A$$ 和 $$\\beta_B$$ 分别是对应于 $$y_A$$ 和 $$y_B$$ 的 OLS 系数向量，用于带截距的模型。设计矩阵 $$Z$$ 对两种拟合是相同的，并且包含一列全为 1 的向量，即 $$z_i = [1, x_i^\\top]^\\top$$。\n\n系数向量之间的关系是：\n$$\\beta_B = (Z^\\top Z)^{-1} Z^\\top y_B = (Z^\\top Z)^{-1} Z^\\top (2y_A - \\mathbf{1})$$\n$$= 2(Z^\\top Z)^{-1} Z^\\top y_A - (Z^\\top Z)^{-1} Z^\\top \\mathbf{1} = 2\\beta_A - (Z^\\top Z)^{-1} Z^\\top \\mathbf{1}$$\n其中 $$\\mathbf{1}$$ 是一个元素全为 1 的列向量。由于模型包含截距，$$Z$$ 的第一列是 $$\\mathbf{1}$$。设 $$e_1 = [1, 0, \\dots, 0]^\\top$$。则 $$Z e_1 = \\mathbf{1}$$，这意味着 $$Z^\\top \\mathbf{1} = Z^\\top Z e_1$$。将此代入 $$\\beta_B$$ 的表达式中，得到：\n$$\\beta_B = 2\\beta_A - (Z^\\top Z)^{-1} (Z^\\top Z e_1) = 2\\beta_A - e_1$$\n这意味着如果 $$\\beta_A = [\\beta_{A,0}, \\beta_{A,1}, \\dots]^\\top$$，则 $$\\beta_B = [2\\beta_{A,0} - 1, 2\\beta_{A,1}, \\dots]^\\top$$。\n\n对于任何输入点 $$z = [1, x^\\top]^\\top$$，拟合值的关系如下：\n$$\\hat{y}_B(z) = z^\\top \\beta_B = z^\\top(2\\beta_A - e_1) = 2z^\\top\\beta_A - z^\\top e_1 = 2\\hat{y}_A(z) - 1$$\n因此，预测值也通过相同的仿射变换相关联。\n\n分类规则是：\n- 编码 A：如果 $$\\hat{y}_A(z) \\ge 0.5$$，则预测为类别 1。\n- 编码 B：如果 $$\\hat{y}_B(z) \\ge 0$$，则预测为类别 1。\n\n将拟合值之间的关系代入编码 B 的规则中，得到：\n$$2\\hat{y}_A(z) - 1 \\ge 0 \\implies 2\\hat{y}_A(z) \\ge 1 \\implies \\hat{y}_A(z) \\ge 0.5$$\n这与编码 A 的分类规则完全相同。因此，所有网格点上的分类结果将完全相同。结果是一个布尔值 `True`。\n\n### 测试用例 2：超出范围的拟合值\n此测试用例突出了 OLS 用于分类的一个关键缺点：拟合值 $$\\hat{y}(z) = z^\\top\\beta$$ 并未被限制在标签的范围内（例如 $$[0, 1]$$）。预测是输入特征的线性函数，因此是无界的。对于远离决策超平面 $$z^\\top\\beta_A = 0.5$$ 的点，$$z^\\top\\beta_A$$ 的值可能远大于 $$1$$ 或远小于 $$0$$。这种行为与逻辑回归等模型形成对比，后者使用 sigmoid 函数将线性预测器映射到 $$[0, 1]$$ 区间，从而允许概率解释。我们将计算编码 A 模型在所有网格点上的拟合值，并计算落在 $$[0, 1]$$ 范围之外的点的比例。\n\n### 测试用例 3：无截距时仿射一致性的失效\n此测试用例研究了当省略截距项时，仿射等变性会发生什么变化。模型现在是 $$ \\hat{y}(x) = x^\\top \\beta $$。设计矩阵 $$Z$$ 现在仅由特征列 $$x_i^\\top$$ 组成。\n正如在测试用例 1 中推导的，$$\\beta_B = 2\\beta_A - (Z^\\top Z)^{-1} Z^\\top \\mathbf{1}$$。当不包含截距时，$$Z$$ 的列空间通常不包含向量 $$\\mathbf{1}$$。因此，项 $$(Z^\\top Z)^{-1} Z^\\top \\mathbf{1}$$ 不会简化为 $$e_1$$。\n训练集上拟合值之间的关系变为：\n$$\\hat{y}_B = Z \\beta_B = 2Z\\beta_A - Z(Z^\\top Z)^{-1} Z^\\top \\mathbf{1} = 2\\hat{y}_A - H\\mathbf{1}$$\n其中 $$H = Z(Z^\\top Z)^{-1} Z^\\top$$ 是帽子矩阵。\n仿射关系 $$\\hat{y}_B = 2\\hat{y}_A - \\mathbf{1}$$ 仅在 $$H\\mathbf{1} = \\mathbf{1}$$ 时成立，这要求 $$\\mathbf{1}$$ 位于 $$Z$$ 的列空间中。在没有截距的情况下，这一点无法保证，并且对于给定的数据也不成立。此测试计算在训练点上 $$|\\hat{y}'(x_i) - (2 \\hat{y}(x_i) - 1)|$$ 的最大绝对偏差，这等价于计算向量 $$| (2\\hat{y}_A - H\\mathbf{1}) - (2\\hat{y}_A - \\mathbf{1}) | = | \\mathbf{1} - H\\mathbf{1} |$$ 的元素级最大绝对值。非零结果证明了仿射一致性的失效。\n\n### 测试用例 4：与编码相关的阈值设定\n分类阈值的选择与标签编码内在地联系在一起。对于 $$\\{0, 1\\}$$ 编码，自然阈值是 $$0.5$$，即标签的中点。对于 $$\\{-1, 1\\}$$ 编码，自然阈值是 $$0$$。此测试用例量化了使用“不正确”阈值的影响。它使用在编码 B（标签为 $$\\{-1, 1\\}$$）下拟合的模型，并使用两个不同的阈值对网格点进行分类：正确的阈值（$$0$$）和适用于不同编码的自然阈值（$$0.5$$）。分类发生变化的网格点数量揭示了决策边界移动的程度。如果一个点的拟合值 $$\\hat{y}_B(z)$$ 落在两个阈值之间，即 $$0 \\le \\hat{y}_B(z) < 0.5$$，其分类将会改变。得到的整数计数表明了这种可解释性错误的不可忽略的影响。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the four test cases related to the use of ordinary least squares\n    for binary classification.\n    \"\"\"\n    \n    # --- Data Specification ---\n    X_train = np.array([\n        [-5, 3], [-4, 2], [-3, 1], [-2, 0.5], [-1, -0.5], # Class 0\n        [2, 1], [3, 2], [4, 2.5], [5, 3], [6, 4]         # Class 1\n    ])\n    \n    # Encoding A: y in {0, 1}\n    y_A = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n    \n    # Encoding B: y' in {-1, 1}\n    y_B = np.array([-1, -1, -1, -1, -1, 1, 1, 1, 1, 1])\n\n    # Evaluation grid\n    x1_grid = np.arange(-6, 7)  # 13 points from -6 to 6\n    x2_grid = np.arange(-3, 7)  # 10 points from -3 to 6\n    xx1, xx2 = np.meshgrid(x1_grid, x2_grid, indexing='ij')\n    grid_points = np.vstack([xx1.ravel(), xx2.ravel()]).T\n\n    # --- Helper Functions ---\n    def fit_ols(X, y, intercept=True):\n        \"\"\"Fits an OLS model and returns the parameters beta.\"\"\"\n        if intercept:\n            Z = np.hstack([np.ones((X.shape[0], 1)), X])\n        else:\n            Z = X\n        \n        # Solve the normal equations: Z.T Z beta = Z.T y\n        try:\n            beta = np.linalg.solve(Z.T @ Z, Z.T @ y)\n        except np.linalg.LinAlgError:\n            # Fallback for singular matrices, though not expected here\n            # as the problem is well-posed.\n            Z_pinv = np.linalg.pinv(Z)\n            beta = Z_pinv @ y\n            \n        return beta\n\n    def predict_ols(X_new, beta, intercept=True):\n        \"\"\"Computes predictions y_hat = Z beta.\"\"\"\n        if intercept:\n            Z_new = np.hstack([np.ones((X_new.shape[0], 1)), X_new])\n        else:\n            Z_new = X_new\n        return Z_new @ beta\n\n    # --- Test Case 1: Decision boundary invariance ---\n    beta_A_int = fit_ols(X_train, y_A, intercept=True)\n    beta_B_int = fit_ols(X_train, y_B, intercept=True)\n    \n    y_hat_A_grid = predict_ols(grid_points, beta_A_int, intercept=True)\n    y_hat_B_grid = predict_ols(grid_points, beta_B_int, intercept=True)\n    \n    # Classification with Encoding A model and threshold 0.5\n    classif_A = (y_hat_A_grid >= 0.5)\n    \n    # Classification with Encoding B model, threshold 0, then map to {0, 1}\n    pred_B = np.where(y_hat_B_grid >= 0, 1, -1)\n    classif_B = (pred_B == 1)\n    \n    tc1_result = bool(np.array_equal(classif_A, classif_B))\n\n    # --- Test Case 2: Out-of-range fitted values ---\n    out_of_range = (y_hat_A_grid < 0) | (y_hat_A_grid > 1)\n    tc2_result = float(np.sum(out_of_range) / len(grid_points))\n\n    # --- Test Case 3: Failure of affine consistency ---\n    beta_A_noint = fit_ols(X_train, y_A, intercept=False)\n    beta_B_noint = fit_ols(X_train, y_B, intercept=False)\n    \n    y_hat_A_train = predict_ols(X_train, beta_A_noint, intercept=False)\n    y_hat_B_train = predict_ols(X_train, beta_B_noint, intercept=False)\n    \n    # Affine map from [0,1] to [-1,1] is f(t) = 2*t - 1\n    y_hat_A_transformed = 2 * y_hat_A_train - 1\n    \n    deviations = np.abs(y_hat_B_train - y_hat_A_transformed)\n    tc3_result = float(np.max(deviations))\n    \n    # --- Test Case 4: Encoding-dependent thresholding ---\n    # Use y_hat_B_grid from Test Case 1\n    classif_B_thresh0 = (y_hat_B_grid >= 0)\n    classif_B_thresh05 = (y_hat_B_grid >= 0.5)\n    \n    differences = np.sum(classif_B_thresh0 != classif_B_thresh05)\n    tc4_result = int(differences)\n\n    # --- Final Output ---\n    results = [tc1_result, tc2_result, tc3_result, tc4_result]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "即使线性回归在某个数据集上达到了完美的分类准确率，我们能相信它的预测值可以作为置信度的度量吗？本练习将探讨特征空间中异常值（即高杠杆点）的影响。你将构建一个类别完全可分的数据集，并通过实验看到，异常值的存在会如何“扭曲”普通最小二乘（OLS）模型，使其对大部分数据点的预测值都收缩到决策边界附近，从而丧失了反映分类不确定性的能力 ()。",
            "id": "3117088",
            "problem": "你需要编写一个完整的、可运行的程序，该程序构建三个合成的二元分类数据集，并使用普通最小二乘法 (OLS) 拟合一个线性回归模型。目标是通过精确计算来证明，在线性可分的情况下，OLS 可以实现零训练集误分类，但其产生的实值预测不适合作为概率，因此无法反映不确定性，使得弃权和风险控制变得困难。\n\n从以下统计学习的基本基础开始：\n- 二元标签被编码为 $y_i \\in \\{0,1\\}$。\n- 普通最小二乘法 (OLS) 旨在为线性预测器 $f(\\mathbf{x}) = \\mathbf{w}^{\\top}\\mathbf{x} + b$ 寻找参数 $(\\mathbf{w}, b)$，以最小化经验平方损失 $\\sum_{i=1}^{n} (y_i - f(\\mathbf{x}_i))^2$。\n- 从回归输出中导出的分类规则以 $0.5$ 为阈值：如果 $f(\\mathbf{x}_i) \\geq 0.5$，则预测类别为 $\\hat{y}_i = 1$，否则为 $\\hat{y}_i = 0$。\n- 线性可分性意味着存在 $(\\mathbf{w}^\\ast, b^\\ast)$，使得对于所有 $y_i = 1$ 的点，$f^\\ast(\\mathbf{x}_i) \\geq 0.5$；对于所有 $y_i = 0$ 的点，$f^\\ast(\\mathbf{x}_i) < 0.5$。\n\n你的程序必须使用正规方程或数值稳定的等效方法来实现 OLS 拟合。使用一个设计矩阵 $X \\in \\mathbb{R}^{n \\times d}$，并添加一列全为 1 的截距项，因此线性模型为 $f(\\mathbf{x}) = \\mathbf{w}^{\\top}\\mathbf{x} + b$。通过求解 $X_{\\text{aug}}\\boldsymbol{\\theta} \\approx \\mathbf{y}$ 的最小二乘解来计算 OLS 解，其中 $X_{\\text{aug}} = [X \\,\\, \\mathbf{1}] \\in \\mathbb{R}^{n \\times (d+1)}$ 且 $\\boldsymbol{\\theta} \\in \\mathbb{R}^{d+1}$ 连接了 $\\mathbf{w}$ 和 $b$。\n\n对于每个数据集，在拟合 OLS 后，计算以下三个量：\n1. 零训练集误分类的布尔指标，定义为 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}[\\hat{y}_i \\neq y_i] = 0$ 是否成立，其中 $\\hat{y}_i = \\mathbb{I}[f(\\mathbf{x}_i) \\geq 0.5]$。\n2. 回归预测值在单位区间外的比例，定义为 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}[f(\\mathbf{x}_i) < 0 \\,\\lor\\, f(\\mathbf{x}_i) > 1]$。\n3. 在边距水平 $\\epsilon$ 下的弃权覆盖率，定义为回归输出与极值（0 或 1）之差在 $\\epsilon$ 以内的点的比例，即 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}\\big(\\min\\{|f(\\mathbf{x}_i) - 0|, |f(\\mathbf{x}_i) - 1|\\} \\leq \\epsilon\\big)$。该指标量化了如果我们将回归输出视为概率，并只接受被认为是“高置信度”的决策时，会有多少预测被保留下来；它揭示了 OLS 输出并非概率这一不匹配之处。\n\n你的程序必须精确构建以下测试数据集（所有特征都是一维的，$d=1$，并且需要包含截距项）：\n\n- 测试用例 A（均衡，中等分离度）：\n  - 负类 ($y=0$)：$x \\in \\{-3,-2,-1\\}$，每个值重复 $10$ 次。\n  - 正类 ($y=1$)：$x \\in \\{1,2,3\\}$，每个值重复 $10$ 次。\n  - 边距参数 $\\epsilon = 0.1$。\n\n- 测试用例 B（均衡，但包含会增大方差并将大多数预测压缩到 $0.5$ 附近的大幅值离群点）：\n  - 负类 ($y=0$)：$x = -1$ 重复 $20$ 次， $x = -100$ 重复 $5$ 次。\n  - 正类 ($y=1$)：$x = 1$ 重复 $20$ 次， $x = 100$ 重复 $5$ 次。\n  - 边距参数 $\\epsilon = 0.05$。\n\n- 测试用例 C（数据集与测试用例 B 相同，但通过更严格的边距进行更严格的风险控制）：\n  - 负类 ($y=0$)：$x = -1$ 重复 $20$ 次， $x = -100$ 重复 $5$ 次。\n  - 正类 ($y=1$)：$x = 1$ 重复 $20$ 次， $x = 100$ 重复 $5$ 次。\n  - 边距参数 $\\epsilon = 0.01$。\n\n对于每个测试用例，拟合 OLS 模型，生成上述三个指标，并将所有结果按以下顺序汇总到一个列表中：\n$[\\text{A\\_zero\\_error}, \\text{A\\_frac\\_outside}, \\text{A\\_coverage}, \\text{B\\_zero\\_error}, \\text{B\\_frac\\_outside}, \\text{B\\_coverage}, \\text{C\\_zero\\_error}, \\text{C\\_frac\\_outside}, \\text{C\\_coverage}]$。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[r_1,r_2,\\dots,r_9]$）。本问题不涉及物理单位或角度单位。所有输出必须是基本类型：布尔值和浮点数。计算必须是确定性的和自包含的，不需要用户输入或外部文件。",
            "solution": "本问题的目标是通过编程方式展示使用普通最小二乘法 (OLS) 线性回归处理二元分类任务的一个根本缺陷。具体来说，我们将展示即使当数据线性可分且 OLS 实现了零训练集误分类误差时，其产生的实值预测也不适合作为概率分数。这是因为 OLS 对特征空间中数据点的位置敏感，这一特性被称为杠杆效应 (leverage)。高杠杆点会扭曲回归拟合，产生的预测值会远远超出 $[0,1]$ 区间，并将其他点的预测值压缩到决策边界附近，因此无法提供有意义的分类置信度度量。\n\n我们首先将问题形式化。对于一个包含 $n$ 个点 $(\\mathbf{x}_i, y_i)$ 的数据集，其中 $\\mathbf{x}_i \\in \\mathbb{R}^d$ 是特征向量， $y_i \\in \\{0, 1\\}$ 是二元标签，OLS 会寻找一个线性函数 $f(\\mathbf{x}) = \\mathbf{w}^{\\top}\\mathbf{x} + b$ 来最小化预测值与真实标签之间的平方误差和：\n$$\n\\mathcal{L}(\\mathbf{w}, b) = \\sum_{i=1}^{n} (y_i - f(\\mathbf{x}_i))^2 = \\sum_{i=1}^{n} (y_i - (\\mathbf{w}^{\\top}\\mathbf{x}_i + b))^2\n$$\n为了方便地处理截距项 $b$，我们通过在特征向量 $\\mathbf{x}_i$ 前面（或按题目要求，在后面）添加一个 1 来增强它。设特征矩阵为 $X \\in \\mathbb{R}^{n \\times d}$。我们构建一个增广设计矩阵 $X_{\\text{aug}} = [X \\,\\, \\mathbf{1}] \\in \\mathbb{R}^{n \\times (d+1)}$，其中 $\\mathbf{1}$ 是一个全为 1 的列向量。设 $\\boldsymbol{\\theta} = [\\mathbf{w}^{\\top} \\,\\, b]^{\\top} \\in \\mathbb{R}^{d+1}$ 为参数向量。OLS 的目标是找到使残差向量的平方 $L_2$ 范数 $\\|\\mathbf{y} - X_{\\text{aug}}\\boldsymbol{\\theta}\\|_2^2$ 最小化的 $\\boldsymbol{\\theta}$。该解可以通过求解正规方程 $(X_{\\text{aug}}^{\\top}X_{\\text{aug}})\\boldsymbol{\\theta} = X_{\\text{aug}}^{\\top}\\mathbf{y}$ 来找到，或者更可靠地使用像奇异值分解 (SVD) 这样的数值方法，这些方法已在标准科学计算库中实现。\n\n一旦找到最优的 $\\boldsymbol{\\theta}$，我们就可以为每个数据点获得回归预测值 $f(\\mathbf{x}_i)$。为了将这些值转换为类别标签，我们应用 $0.5$ 的阈值：\n$$\n\\hat{y}_i = \\mathbb{I}[f(\\mathbf{x}_i) \\geq 0.5]\n$$\n其中 $\\mathbb{I}[\\cdot]$ 是指示函数。\n\n我们将使用以下三个指标在三个合成的一维 ($d=1$) 数据集上评估 OLS 分类器：\n$1$. **零训练集误分类**：一个布尔值，指示误分类率 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}[\\hat{y}_i \\neq y_i]$ 是否恰好为 $0$。这验证了 OLS 模型是否为训练数据找到了一个完美的分割超平面。\n$2$. **预测值在单位区间外的比例**：回归输出不在 $[0, 1]$ 范围内的点的比例，计算公式为 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}[f(\\mathbf{x}_i) < 0 \\lor f(\\mathbf{x}_i) > 1]$。该指标直接量化了 OLS 未能产生类似概率的输出的失败程度。\n$3$. **弃权覆盖率**：预测值被认为是“高置信度”（即接近理想概率值 0 或 1）的数据点的比例。对于给定的边距 $\\epsilon$，其计算公式为 $\\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}\\big(\\min\\{|f(\\mathbf{x}_i) - 0|, |f(\\mathbf{x}_i) - 1|\\} \\leq \\epsilon\\big)$。该指标值较低表明大多数预测值远离极值，意味着置信度低，使得进行风险控制决策（即对低置信度预测弃权）变得困难。\n\n每个测试用例的算法流程如下：\n$1$. 根据测试用例的规范构建特征向量 $\\mathbf{x}$ 和标签向量 $\\mathbf{y}$。\n$2$. 通过取列向量 $\\mathbf{x}$ 并附加一列全为 1 的向量来创建设计矩阵 $X_{\\text{aug}}$。\n$3$. 使用最小二乘法求解器求解线性系统 $X_{\\text{aug}}\\boldsymbol{\\theta} \\approx \\mathbf{y}$，以计算 OLS 参数向量 $\\boldsymbol{\\theta} = [w, b]^{\\top}$。\n$4$. 计算所有数据点的回归预测值：$\\mathbf{f} = X_{\\text{aug}}\\boldsymbol{\\theta}$。\n$5$. 使用预测向量 $\\mathbf{f}$、真实标签 $\\mathbf{y}$ 和指定的边距 $\\epsilon$ 来计算所需的三个指标。\n\n这些测试用例旨在说明高杠杆点的影响。测试用例 A 提供了一个基线，其数据行为良好且分离度适中。测试用例 B 和 C 在特征空间中引入了离群点（$x=-100$ 和 $x=100$）。由于 OLS 最小化平方误差，这些离群点对回归线施加了强大的影响（高杠杆效应）。为了最小化与这些点相关的大误差，OLS 会拟合一条斜率远小于仅针对内点数据所选斜率的直线。回归线的这种“扁平化”导致了两种效应：(i) 为了满足损失函数，离群点的预测值被推向极值（通常在 $[0,1]$ 区间之外），以及 (ii) 数量更多的内点的预测值被压缩到决策边界 ($0.5$) 附近，导致大部分数据的置信度分数较低。这种行为与逻辑回归等模型形成鲜明对比，后者专为分类设计，并且对此类离群点更具鲁棒性。程序将精确地计算这些效应。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef process_case(x_data, y_data, epsilon):\n    \"\"\"\n    Fits an OLS model and computes the three specified metrics for a given dataset.\n\n    Args:\n        x_data (np.ndarray): 1D feature data.\n        y_data (np.ndarray): Binary labels (0 or 1).\n        epsilon (float): Margin for the abstention coverage metric.\n    \n    Returns:\n        tuple: A tuple containing the three metrics:\n               (zero_error, frac_outside, coverage).\n    \"\"\"\n    # Reshape x_data to be a column vector for the design matrix\n    X_mat = x_data.reshape(-1, 1)\n    \n    # Construct the augmented design matrix with an intercept column of ones.\n    # X_aug = [X, 1], so the model is f(x) = w*x + b\n    X_aug = np.hstack([X_mat, np.ones((x_data.shape[0], 1))])\n    \n    # Solve for the OLS parameters theta = [w, b]^T using np.linalg.lstsq.\n    # This provides a numerically stable solution to the normal equations.\n    theta, _, _, _ = np.linalg.lstsq(X_aug, y_data, rcond=None)\n    \n    # Calculate the continuous regression predictions f(x_i)\n    y_pred_reg = X_aug @ theta\n    \n    # --- Metric 1: Zero training misclassification ---\n    # Classify by thresholding regression outputs at 0.5\n    y_pred_class = (y_pred_reg >= 0.5).astype(int)\n    # The rate is the mean of the indicator I[y_pred != y_true]\n    misclassification_rate = np.mean(y_pred_class != y_data)\n    zero_error = (misclassification_rate == 0.0)\n    \n    # --- Metric 2: Fraction of predictions outside the unit interval [0, 1] ---\n    frac_outside = np.mean((y_pred_reg < 0) | (y_pred_reg > 1))\n    \n    # --- Metric 3: Abstention coverage at margin epsilon ---\n    # This is the fraction of points where the prediction is within epsilon of 0 or 1.\n    # The metric is min(|f(x)-0|, |f(x)-1|) <= epsilon\n    dist_to_extremes = np.minimum(np.abs(y_pred_reg - 0.0), np.abs(y_pred_reg - 1.0))\n    coverage = np.mean(dist_to_extremes <= epsilon)\n    \n    return zero_error, frac_outside, coverage\n\n\ndef solve():\n    \"\"\"\n    Constructs datasets, runs OLS, computes metrics, and prints the final result.\n    \"\"\"\n    # The final list to be populated with 9 results.\n    all_results = []\n    \n    # --- Test Case A (balanced, moderate separation) ---\n    x_neg_A = np.repeat([-3.0, -2.0, -1.0], 10)\n    x_pos_A = np.repeat([1.0, 2.0, 3.0], 10)\n    x_A = np.concatenate([x_neg_A, x_pos_A])\n    y_A = np.concatenate([np.zeros(len(x_neg_A)), np.ones(len(x_pos_A))])\n    epsilon_A = 0.1\n    results_A = process_case(x_A, y_A, epsilon_A)\n    all_results.extend(results_A)\n\n    # --- Test Case B (balanced with large-magnitude outliers) ---\n    x_neg_B = np.concatenate([np.full(20, -1.0), np.full(5, -100.0)])\n    x_pos_B = np.concatenate([np.full(20, 1.0), np.full(5, 100.0)])\n    x_B = np.concatenate([x_neg_B, x_pos_B])\n    y_B = np.concatenate([np.zeros(len(x_neg_B)), npones(len(x_pos_B))])\n    epsilon_B = 0.05\n    results_B = process_case(x_B, y_B, epsilon_B)\n    all_results.extend(results_B)\n\n    # --- Test Case C (same as B, stricter margin) ---\n    # Data is identical to Test Case B\n    x_C, y_C = x_B, y_B\n    epsilon_C = 0.01\n    results_C = process_case(x_C, y_C, epsilon_C)\n    all_results.extend(results_C)\n    \n    # Final print statement in the exact required format.\n    # `map(str, ...)` converts boolean `True`/`False` and floats to strings.\n    print(f\"[{','.join(map(lambda x: str(x).lower() if isinstance(x, bool) else str(x), all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "前面的练习表明，普通最小二乘法（OLS）的输出分数并不是概率。最后一个练习将聚焦于决策阈值本身，从而将这一问题具体化。我们将探讨一个思想实验：假设一个 OLS 模型的分数与一个更合适的分类器（如逻辑回归）的分数之间存在完美的单调关系。你会发现，即便如此，使用一个固定的、看似合理的决策阈值仍然可能导致不同的分类结果，这凸显了 OLS 分数未经“校准”的根本缺陷——其数值大小缺乏稳定且有意义的解释 ()。",
            "id": "3117167",
            "problem": "您的任务是通过展示阈值依赖性来论证使用普通最小二乘 (OLS) 回归进行二元分类的一个缺点：即使两个模型生成的预测在单调重缩放的意义上是相同的，但如果它们使用不同的固定阈值，其导出的分类结果也可能不同。请使用以下基本依据。普通最小二乘 (OLS) 回归通过最小化编码响应 $\\tilde{y} \\in \\{-1,+1\\}$ 上的平方误差，从特征 $x$ 预测一个连续分数 $s$，从而产生拟合分数 $s_i = x_i^\\top w$。这些分数通常通过符号法则转换为类别标签，即 $\\hat{y}^{\\mathrm{OLS}}_i = \\mathrm{sign}(s_i)$，或者等效地，通过阈值法则 $\\hat{y}^{\\mathrm{OLS}}_i = +1$（如果 $s_i \\ge 0$）和 $\\hat{y}^{\\mathrm{OLS}}_i = -1$（如果 $s_i < 0$）。逻辑回归通过逻辑函数 $p_i = \\sigma(z_i)$（其中 $\\sigma(t) = 1/(1+e^{-t})$）和线性预测器 $z_i = \\beta_0 + x_i^\\top \\beta$ 来建模条件概率 $p_i = \\mathbb{P}(Y=1 \\mid x_i)$。其标准决策法则是：如果 $p_i \\ge 0.5$，则 $\\hat{y}^{\\mathrm{LR}}_i = 1$，否则 $\\hat{y}^{\\mathrm{LR}}_i = 0$；这等价于：如果 $z_i \\ge 0$，则 $\\hat{y}^{\\mathrm{LR}}_i = 1$，否则 $\\hat{y}^{\\mathrm{LR}}_i = 0$。为了与 OLS 使用的 $\\{-1,+1\\}$ 编码进行比较，将逻辑决策映射到 $\\{-1,+1\\}$，定义为：如果 $z_i \\ge 0$，则 $\\tilde{y}^{\\mathrm{LR}}_i = +1$，否则 $\\tilde{y}^{\\mathrm{LR}}_i = -1$。考虑这样一种情况：逻辑模型的线性预测器 $\\{z_i\\}_{i=1}^n$ 与 OLS 拟合分数 $\\{s_i\\}_{i=1}^n$ 通过仿射变换 $z_i = a s_i + b$ 相关联，其中常数 $a \\in \\mathbb{R} \\setminus \\{0\\}$ 且 $b \\in \\mathbb{R}$。由于逻辑链接函数 $\\sigma(\\cdot)$ 是严格单调的，因此概率 $\\{p_i\\}$ 是通过 $p_i = \\sigma(a s_i + b)$ 对 $\\{s_i\\}$ 进行的单调重缩放。\n\n您的程序必须仅基于向量 $\\{s_i\\}$ 和参数 $(a,b)$ 实现上述两种决策法则，而无需执行任何模型拟合。具体来说：\n- OLS 决策：对于每个 $s_i$，如果 $s_i \\ge 0$，则预测为 $+1$，否则预测为 $-1$。\n- 逻辑决策：对于每个 $s_i$，计算 $z_i = a s_i + b$，如果 $z_i \\ge 0$，则预测为 $+1$，否则预测为 $-1$。\n\n对于下面列出的每个测试用例，计算一个整数 $D$，其值等于 OLS 决策和逻辑决策不一致的索引 $i$ 的数量，即满足 $\\mathrm{sign}(s_i) \\ne \\mathrm{sign}(a s_i + b)$ 的 $i$ 的计数。请使用约定 $\\mathrm{sign}(0) = +1$（即阈值处的平局情况归为正类）。注意，所有量都是无量纲的，没有物理单位。测试套件如下：\n\n1. 情况 A (阈值不同的理想路径)：$s = [-1.0,-0.25,0.0,0.25,1.0]$，$a = 1.0$，$b = 0.5$。\n2. 情况 B (边界对齐，无不一致)：$s = [-2.0,-1.0,0.0,1.0,2.0]$，$a = 3.0$，$b = 0.0$。\n3. 情况 C (阈值移动到 $s^\\star = -b/a > 0$)：$s = [-0.2,0.0,0.2,0.25,0.5,1.0]$，$a = 2.0$，$b = -0.5$。\n4. 情况 D (单调递减重缩放，方向翻转)：$s = [-1.0,-0.5,0.0,0.5,1.0]$，$a = -1.5$，$b = 0.0$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 $[d_A,d_B,d_C,d_D]$），其中 $d_A$、$d_B$、$d_C$ 和 $d_D$ 分别是情况 A、B、C 和 D 的整数不一致计数 $D$。",
            "solution": "该问题要求对两种二元分类决策法则进行定量比较。第一种法则是从一组分数 $\\{s_i\\}_{i=1}^n$ 派生而来，使用固定的阈值 $0$。第二种法则是从另一组分数 $\\{z_i\\}_{i=1}^n$ 派生而来，这组分数是第一组分数的仿射变换 $z_i = a s_i + b$，同样使用固定的阈值 $0$。目标是计算两种法则产生不同类别标签的实例数量。这个练习展示了，即使分数之间通过严格单调函数相关联，选择一个固定的、非数据自适应的阈值（如在基于 OLS 的分类器中）与选择一个模型内在的阈值（如在逻辑回归中）也可能导致不同的结果。\n\n首先，让我们将指定的两种决策法则形式化。对于给定向量 $\\mathbf{s}$ 中的每个分数 $s_i$，基于 OLS 的预测 $\\hat{y}^{\\mathrm{OLS}}_i$ 由 $s_i$ 的符号决定。根据处理阈值平局的指定约定，该法则是：\n$$\n\\hat{y}^{\\mathrm{OLS}}_i = \\begin{cases} +1 & \\text{if } s_i \\ge 0 \\\\ -1 & \\text{if } s_i < 0 \\end{cases}\n$$\n这等效于应用符号函数 $\\mathrm{sign}(\\cdot)$，并约定 $\\mathrm{sign}(0) = +1$。\n\n基于逻辑回归的预测 $\\tilde{y}^{\\mathrm{LR}}_i$ 首先计算一个变换后的分数 $z_i = a s_i + b$，然后应用相同的基于符号的法则：\n$$\n\\tilde{y}^{\\mathrm{LR}}_i = \\begin{cases} +1 & \\text{if } z_i \\ge 0 \\\\ -1 & \\text{if } z_i < 0 \\end{cases}\n$$\n代入 $z_i$ 的表达式，预测为正类的条件变为 $a s_i + b \\ge 0$。\n\n当且仅当 $\\hat{y}^{\\mathrm{OLS}}_i \\ne \\tilde{y}^{\\mathrm{LR}}_i$ 时，两种法则在索引 $i$ 处出现不一致。使用指定的符号约定，这等效于条件 $\\mathrm{sign}(s_i) \\ne \\mathrm{sign}(a s_i + b)$。我们必须为每个测试用例计算满足此条件的索引 $i$ 的数量。\n\n让我们根据参数 $a$ 和 $b$ 来分析不一致的条件。\n\n情况 I：$a > 0$。\n变换 $z_i = a s_i + b$ 是严格单调递增的。\nOLS 法则在阈值 $s_i = 0$ 处划分实数轴。\n逻辑法则的条件 $a s_i + b \\ge 0$ 等价于 $a s_i \\ge -b$，可简化为 $s_i \\ge -b/a$。因此，逻辑法则在阈值 $s_i = -b/a$ 处划分实数轴。\n如果不一致发生，则分数 $s_i$ 落在两个阈值 $0$ 和 $-b/a$ 之间。\n- 如果 $-b/a > 0$，对于任何满足 $0 \\le s_i < -b/a$ 的 $s_i$，都会出现不一致。\n- 如果 $-b/a < 0$，对于任何满足 $-b/a \\le s_i < 0$ 的 $s_i$，都会出现不一致。\n如果 $-b/a = 0$（即 $b=0$），则阈值相同，没有不一致。\n\n情况 II：$a < 0$。\n变换 $z_i = a s_i + b$ 是严格单调递减的。\n逻辑法则的条件 $a s_i + b \\ge 0$ 等价于 $a s_i \\ge -b$，由于除以一个负数会使不等式反向，因此简化为 $s_i \\le -b/a$。\nOLS 法则仍然对 $s_i \\ge 0$ 预测为 $+1$，对 $s_i < 0$ 预测为 $-1$。\n而逻辑法则现在对 $s_i \\le -b/a$ 预测为 $+1$，对 $s_i > -b/a$ 预测为 $-1$。\n如果 $b=0$，两个法则的阈值都是 $s_i=0$，但逻辑法则的方向是相反的。\n- OLS: $\\hat{y}^{\\mathrm{OLS}}_i = +1$ if $s_i \\ge 0$, $-1$ if $s_i < 0$.\n- LR: $\\tilde{y}^{\\mathrm{LR}}_i = +1$ if $s_i \\le 0$, $-1$ if $s_i > 0$.\n对于所有 $s_i \\ne 0$ 都会出现不一致。对于 $s_i > 0$，$\\hat{y}^{\\mathrm{OLS}}_i = +1$ 而 $\\tilde{y}^{\\mathrm{LR}}_i = -1$。对于 $s_i < 0$，$\\hat{y}^{\\mathrm{OLS}}_i = -1$ 而 $\\tilde{y}^{\\mathrm{LR}}_i = +1$。对于 $s_i=0$，两个法则都得出 $+1$，因此没有不一致。\n\n我们现在将此分析应用于每个测试用例。不一致的数量用 $D$ 表示。\n\n情况 A：$s = [-1.0, -0.25, 0.0, 0.25, 1.0]$，$a = 1.0$，$b = 0.5$。\n此时，$a = 1.0 > 0$。OLS 阈值为 $s=0$。逻辑阈值为 $s = -b/a = -0.5/1.0 = -0.5$。\n当 $s_i$ 位于区间 $[-0.5, 0)$ 时，会发生不一致。\n$s$ 中唯一落入此区间的分数是 $s_2 = -0.25$。\n对于 $s_2 = -0.25$：$\\hat{y}^{\\mathrm{OLS}}_2 = \\mathrm{sign}(-0.25) = -1$。变换后的分数为 $z_2 = 1.0(-0.25) + 0.5 = 0.25$，因此 $\\tilde{y}^{\\mathrm{LR}}_2 = \\mathrm{sign}(0.25) = +1$。两者不一致。\n对于所有其他分数，预测结果一致。\n不一致的数量为 $D_A = 1$。\n\n情况 B：$s = [-2.0, -1.0, 0.0, 1.0, 2.0]$，$a = 3.0$，$b = 0.0$。\n此时，$a = 3.0 > 0$ 且 $b=0$。OLS 阈值为 $s=0$。逻辑阈值为 $s = -b/a = 0.0$。\n两个阈值相同。对于任何 $s_i$，$\\mathrm{sign}(s_i) = \\mathrm{sign}(3.0 \\cdot s_i)$。\n因此，不可能有不一致。\n不一致的数量为 $D_B = 0$。\n\n情况 C：$s = [-0.2, 0.0, 0.2, 0.25, 0.5, 1.0]$，$a = 2.0$，$b = -0.5$。\n此时，$a = 2.0 > 0$。OLS 阈值为 $s=0$。逻辑阈值为 $s = -b/a = -(-0.5)/2.0 = 0.25$。\n当 $s_i$ 位于区间 $[0, 0.25)$ 时，会发生不一致。\n$s$ 中落入此区间的两个分数是 $s_2=0.0$ 和 $s_3=0.2$。\n- 对于 $s_2=0.0$：$\\hat{y}^{\\mathrm{OLS}}_2 = \\mathrm{sign}(0.0)=+1$。变换后的分数为 $z_2 = 2.0(0.0) - 0.5 = -0.5$，因此 $\\tilde{y}^{\\mathrm{LR}}_2 = \\mathrm{sign}(-0.5)=-1$。不一致。\n- 对于 $s_3=0.2$：$\\hat{y}^{\\mathrm{OLS}}_3 = \\mathrm{sign}(0.2)=+1$。变换后的分数为 $z_3 = 2.0(0.2) - 0.5 = -0.1$，因此 $\\tilde{y}^{\\mathrm{LR}}_3 = \\mathrm{sign}(-0.1)=-1$。不一致。\n不一致的数量为 $D_C = 2$。\n\n情况 D：$s = [-1.0, -0.5, 0.0, 0.5, 1.0]$，$a = -1.5$，$b = 0.0$。\n此时，$a = -1.5 < 0$ 且 $b=0.0$。根据对此种情况的一般性分析，对于每个 $s_i \\ne 0$ 都会出现不一致。\n$s$ 中的分数为 $\\{ -1.0, -0.5, 0.0, 0.5, 1.0 \\}$。有 $4$ 个非零分数。\n- 对于 $s_1 = -1.0$ (负数)：$\\hat{y}^{\\mathrm{OLS}}_1 = -1$，$\\tilde{y}^{\\mathrm{LR}}_1 = \\mathrm{sign}((-1.5)(-1.0)) = \\mathrm{sign}(1.5) = +1$。不一致。\n- 对于 $s_2 = -0.5$ (负数)：$\\hat{y}^{\\mathrm{OLS}}_2 = -1$，$\\tilde{y}^{\\mathrm{LR}}_2 = \\mathrm{sign}((-1.5)(-0.5)) = \\mathrm{sign}(0.75) = +1$。不一致。\n- 对于 $s_3 = 0.0$：$\\hat{y}^{\\mathrm{OLS}}_3 = +1$，$\\tilde{y}^{\\mathrm{LR}}_3 = \\mathrm{sign}(0.0) = +1$。一致。\n- 对于 $s_4 = 0.5$ (正数)：$\\hat{y}^{\\mathrm{OLS}}_4 = +1$，$\\tilde{y}^{\\mathrm{LR}}_4 = \\mathrm{sign}((-1.5)(0.5)) = \\mathrm{sign}(-0.75) = -1$。不一致。\n- 对于 $s_5 = 1.0$ (正数)：$\\hat{y}^{\\mathrm{OLS}}_5 = +1$，$\\tilde{y}^{\\mathrm{LR}}_5 = \\mathrm{sign}((-1.5)(1.0)) = \\mathrm{sign}(-1.5) = -1$。不一致。\n不一致的数量为 $D_D = 4$。\n\n最终结果是不一致计数的列表：$[D_A, D_B, D_C, D_D] = [1, 0, 2, 4]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the number of disagreements between two classification rules\n    for several test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (s_vector, a, b)\n    test_cases = [\n        # Case A\n        (np.array([-1.0, -0.25, 0.0, 0.25, 1.0]), 1.0, 0.5),\n        # Case B\n        (np.array([-2.0, -1.0, 0.0, 1.0, 2.0]), 3.0, 0.0),\n        # Case C\n        (np.array([-0.2, 0.0, 0.2, 0.25, 0.5, 1.0]), 2.0, -0.5),\n        # Case D\n        (np.array([-1.0, -0.5, 0.0, 0.5, 1.0]), -1.5, 0.0),\n    ]\n\n    results = []\n    # Process each test case by unpacking the parameters\n    for s, a, b in test_cases:\n        # The decision rule is to predict +1 for a score >= 0, and -1 otherwise.\n        # This can be implemented efficiently for the entire vector using np.where.\n        \n        # 1. OLS decision based on scores s\n        # y_ols is a vector of +1s and -1s representing the class predictions.\n        y_ols = np.where(s >= 0, 1, -1)\n\n        # 2. Logistic decision based on transformed scores z = a*s + b\n        # First, compute the vector of z scores.\n        z = a * s + b\n        # Then, apply the same decision rule to the z scores.\n        y_lr = np.where(z >= 0, 1, -1)\n\n        # 3. Count the number of disagreements\n        # The boolean array (y_ols != y_lr) contains True where predictions differ.\n        # Summing a boolean array in numpy counts the number of True values.\n        disagreement_count = np.sum(y_ols != y_lr)\n        \n        results.append(int(disagreement_count))\n\n    # Final print statement in the exact required format \"[d_A,d_B,d_C,d_D]\".\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}