{
    "hands_on_practices": [
        {
            "introduction": "递归二元分裂算法的核心在于其评估和选择最佳分裂点的方法。这个练习将引导你亲手计算杂度指标——在这里是平方误差和 (SSE)——来量化和比较不同分裂方案的优劣 。通过处理一个多输出回归的假想场景，你将学会如何在构建决策树时权衡对不同预测目标的增益，这是解决复杂预测任务时的一项关键技能。",
            "id": "3168007",
            "problem": "考虑一个单预测变量、多输出的回归树，其响应向量为 $Y=(Y_{1},Y_{2})$。给定 $8$ 个观测值 $(x_{i},y_{1i},y_{2i})$：\n- $(1,1,5)$\n- $(2,1,5)$\n- $(3,1,5)$\n- $(4,1,5)$\n- $(5,3,5)$\n- $(6,3,5)$\n- $(7,3,7)$\n- $(8,3,7)$\n\n在任何节点，对每个输出坐标的预测是该坐标在节点内的样本均值。回归树的杂质度定义为平方误差和 (SSE)：对于均值为 $\\bar{z}$ 的集合 $\\{z_{j}\\}_{j=1}^{m}$，$\\mathrm{SSE}=\\sum_{j=1}^{m}(z_{j}-\\bar{z})^{2}$。对于多输出，考虑两个准则：\n- 求和准则：在子节点上最小化 $\\mathrm{SSE}(Y_{1})+\\mathrm{SSE}(Y_{2})$（递归二元分裂选择使子节点杂质度之和最小化的分裂）。\n- 加权准则：在子节点上最小化 $w\\,\\mathrm{SSE}(Y_{1})+(1-w)\\,\\mathrm{SSE}(Y_{2})$，其中 $w\\in(0,1)$ 是用户选择的权重。\n\n评估在根节点的两个候选分裂：\n- 分裂 $\\mathcal{S}_{A}$：阈值为 $x=4.5$（左子节点包含 $x\\in\\{1,2,3,4\\}$；右子节点包含 $x\\in\\{5,6,7,8\\}$）。\n- 分裂 $\\mathcal{S}_{B}$：阈值为 $x=6.5$（左子节点包含 $x\\in\\{1,2,3,4,5,6\\}$；右子节点包含 $x\\in\\{7,8\\}$）。\n\n仅以上述定义为出发点，计算在 $\\mathcal{S}_{A}$ 和 $\\mathcal{S}_{B}$ 下每个输出的子节点内杂质度。证明在求和准则下，$\\mathcal{S}_{A}$ 更优。然后，推导出唯一的 $w^{\\star}\\in(0,1)$，使得加权准则在 $\\mathcal{S}_{A}$ 和 $\\mathcal{S}_{B}$ 之间无差异，即 $w^{\\star}$ 满足 $w^{\\star}\\,\\mathrm{SSE}_{\\mathcal{S}_{A}}(Y_{1})+(1-w^{\\star})\\,\\mathrm{SSE}_{\\mathcal{S}_{A}}(Y_{2})=w^{\\star}\\,\\mathrm{SSE}_{\\mathcal{S}_{B}}(Y_{1})+(1-w^{\\star})\\,\\mathrm{SSE}_{\\mathcal{S}_{B}}(Y_{2})$。以精确值的形式报告 $w^{\\star}$。最终答案必须是单个数字。不要四舍五入；如果适用，请提供精确分数。",
            "solution": "用户希望验证问题陈述。\n\n### 步骤 1：提取已知条件\n- **数据集**：$8$ 个观测值 $(x_{i},y_{1i},y_{2i})$，其中 $i \\in \\{1, \\dots, 8\\}$。\n  - $(1,1,5), (2,1,5), (3,1,5), (4,1,5), (5,3,5), (6,3,5), (7,3,7), (8,3,7)$\n- **模型**：单预测变量、多输出的回归树，响应向量为 $Y=(Y_{1},Y_{2})$。\n- **预测规则**：在任何节点，对每个输出坐标的预测是该坐标在节点内的样本均值。\n- **杂质度定义**：平方误差和 (SSE)，对于均值为 $\\bar{z}$ 的集合 $\\{z_{j}\\}_{j=1}^{m}$，其 SSE 为 $\\mathrm{SSE}=\\sum_{j=1}^{m}(z_{j}-\\bar{z})^{2}$。\n- **分裂准则**：递归二元分裂选择使子节点杂质度之和最小化的分裂。\n  - **求和准则**：最小化 $\\mathrm{SSE}(Y_{1})+\\mathrm{SSE}(Y_{2})$。\n  - **加权准则**：最小化 $w\\,\\mathrm{SSE}(Y_{1})+(1-w)\\,\\mathrm{SSE}(Y_{2})$，其中 $w\\in(0,1)$。\n- **候选分裂**：\n  - $\\mathcal{S}_{A}$：阈值为 $x=4.5$。左子节点：$x\\in\\{1,2,3,4\\}$，右子节点：$x\\in\\{5,6,7,8\\}$。\n  - $\\mathcal{S}_{B}$：阈值为 $x=6.5$。左子节点：$x\\in\\{1,2,3,4,5,6\\}$，右子节点：$x\\in\\{7,8\\}$。\n- **任务**：\n  1. 计算在 $\\mathcal{S}_{A}$ 和 $\\mathcal{S}_{B}$ 下 $Y_{1}$ 和 $Y_{2}$ 的子节点内杂质度。\n  2. 证明在求和准则下，$\\mathcal{S}_{A}$ 更优。\n  3. 推导出唯一的 $w^{\\star}\\in(0,1)$，使得加权准则在 $\\mathcal{S}_{A}$ 和 $\\mathcal{S}_{B}$ 之间无差异。\n\n### 步骤 2：使用提取的已知条件进行验证\n- **科学依据**：该问题是统计学习中的一个标准练习，具体涉及回归树和递归二元分裂主题。使用 SSE 作为杂质度度量和基于最小化杂质度的分裂是 CART 算法的基础。将其扩展到多输出场景是一种有效且成熟的变体。该问题在科学上是合理的。\n- **良构性**：该问题提供了所有必要的数据、清晰的杂质度和分裂准则定义，以及具体的任务。目标是计算特定的数值并证明一个给定的关系，从而得出 $w^{\\star}$ 的唯一且有意义的解。\n- **客观性**：该问题以精确、正式的语言陈述，没有任何主观性或偏见。\n\n该问题不违反任何无效性标准。它是自包含、一致且可形式化的。\n\n### 步骤 3：结论与行动\n该问题有效。将提供完整的解决方案。\n\n**解题过程**\n\n问题的核心是为数据的两种不同潜在分裂方式，计算每个响应变量（$Y_1$ 和 $Y_2$）的总平方误差和 (SSE)。给定分裂的总 SSE 是在每个产生的子节点内计算的 SSE 之和。\n\n我们首先计算分裂 $\\mathcal{S}_{A}$（使用阈值 $x=4.5$）所需的值。\n\n**分裂 $\\mathcal{S}_{A}$ 的分析 ($x=4.5$)**\n\n左子节点 $L_A$ 包含 $x \\in \\{1,2,3,4\\}$ 的观测值。\n$L_A$ 中的数据是：$(1,1,5), (2,1,5), (3,1,5), (4,1,5)$。\n- 对于 $Y_1$，值为 $\\{1,1,1,1\\}$。均值为 $\\bar{y}_{1,L_A} = \\frac{1+1+1+1}{4} = 1$。\n$L_A$ 中 $Y_1$ 的 SSE 为 $\\mathrm{SSE}_{L_A}(Y_1) = \\sum_{i \\in L_A} (y_{1i} - \\bar{y}_{1,L_A})^2 = (1-1)^2 + (1-1)^2 + (1-1)^2 + (1-1)^2 = 0$。\n- 对于 $Y_2$，值为 $\\{5,5,5,5\\}$。均值为 $\\bar{y}_{2,L_A} = \\frac{5+5+5+5}{4} = 5$。\n$L_A$ 中 $Y_2$ 的 SSE 为 $\\mathrm{SSE}_{L_A}(Y_2) = \\sum_{i \\in L_A} (y_{2i} - \\bar{y}_{2,L_A})^2 = (5-5)^2 + (5-5)^2 + (5-5)^2 + (5-5)^2 = 0$。\n\n右子节点 $R_A$ 包含 $x \\in \\{5,6,7,8\\}$ 的观测值。\n$R_A$ 中的数据是：$(5,3,5), (6,3,5), (7,3,7), (8,3,7)$。\n- 对于 $Y_1$，值为 $\\{3,3,3,3\\}$。均值为 $\\bar{y}_{1,R_A} = \\frac{3+3+3+3}{4} = 3$。\n$R_A$ 中 $Y_1$ 的 SSE 为 $\\mathrm{SSE}_{R_A}(Y_1) = \\sum_{i \\in R_A} (y_{1i} - \\bar{y}_{1,R_A})^2 = (3-3)^2 + (3-3)^2 + (3-3)^2 + (3-3)^2 = 0$。\n- 对于 $Y_2$，值为 $\\{5,5,7,7\\}$。均值为 $\\bar{y}_{2,R_A} = \\frac{5+5+7+7}{4} = \\frac{24}{4} = 6$。\n$R_A$ 中 $Y_2$ 的 SSE 为 $\\mathrm{SSE}_{R_A}(Y_2) = \\sum_{i \\in R_A} (y_{2i} - \\bar{y}_{2,R_A})^2 = (5-6)^2 + (5-6)^2 + (7-6)^2 + (7-6)^2 = (-1)^2 + (-1)^2 + 1^2 + 1^2 = 1+1+1+1 = 4$。\n\n分裂 $\\mathcal{S}_A$ 对每个响应变量的总杂质度是其子节点杂质度之和：\n$\\mathrm{SSE}_{\\mathcal{S}_A}(Y_1) = \\mathrm{SSE}_{L_A}(Y_1) + \\mathrm{SSE}_{R_A}(Y_1) = 0 + 0 = 0$。\n$\\mathrm{SSE}_{\\mathcal{S}_A}(Y_2) = \\mathrm{SSE}_{L_A}(Y_2) + \\mathrm{SSE}_{R_A}(Y_2) = 0 + 4 = 4$。\n\n**分裂 $\\mathcal{S}_{B}$ 的分析 ($x=6.5$)**\n\n左子节点 $L_B$ 包含 $x \\in \\{1,2,3,4,5,6\\}$ 的观测值。\n$L_B$ 中的数据是：$(1,1,5), (2,1,5), (3,1,5), (4,1,5), (5,3,5), (6,3,5)$。\n- 对于 $Y_1$，值为 $\\{1,1,1,1,3,3\\}$。均值为 $\\bar{y}_{1,L_B} = \\frac{4 \\cdot 1 + 2 \\cdot 3}{6} = \\frac{10}{6} = \\frac{5}{3}$。\n$L_B$ 中 $Y_1$ 的 SSE 为 $\\mathrm{SSE}_{L_B}(Y_1) = 4 \\cdot (1 - \\frac{5}{3})^2 + 2 \\cdot (3 - \\frac{5}{3})^2 = 4 \\cdot (-\\frac{2}{3})^2 + 2 \\cdot (\\frac{4}{3})^2 = 4 \\cdot \\frac{4}{9} + 2 \\cdot \\frac{16}{9} = \\frac{16}{9} + \\frac{32}{9} = \\frac{48}{9} = \\frac{16}{3}$。\n- 对于 $Y_2$，值为 $\\{5,5,5,5,5,5\\}$。均值为 $\\bar{y}_{2,L_B} = 5$。\n$L_B$ 中 $Y_2$ 的 SSE 为 $\\mathrm{SSE}_{L_B}(Y_2) = \\sum_{i \\in L_B} (y_{2i} - 5)^2 = 6 \\cdot (5-5)^2 = 0$。\n\n右子节点 $R_B$ 包含 $x \\in \\{7,8\\}$ 的观测值。\n$R_B$ 中的数据是：$(7,3,7), (8,3,7)$。\n- 对于 $Y_1$，值为 $\\{3,3\\}$。均值为 $\\bar{y}_{1,R_B} = \\frac{3+3}{2} = 3$。\n$R_B$ 中 $Y_1$ 的 SSE 为 $\\mathrm{SSE}_{R_B}(Y_1) = (3-3)^2 + (3-3)^2 = 0$。\n- 对于 $Y_2$，值为 $\\{7,7\\}$。均值为 $\\bar{y}_{2,R_B} = 7$。\n$R_B$ 中 $Y_2$ 的 SSE 为 $\\mathrm{SSE}_{R_B}(Y_2) = (7-7)^2 + (7-7)^2 = 0$。\n\n分裂 $\\mathcal{S}_B$ 对每个响应变量的总杂质度为：\n$\\mathrm{SSE}_{\\mathcal{S}_B}(Y_1) = \\mathrm{SSE}_{L_B}(Y_1) + \\mathrm{SSE}_{R_B}(Y_1) = \\frac{16}{3} + 0 = \\frac{16}{3}$。\n$\\mathrm{SSE}_{\\mathcal{S}_B}(Y_2) = \\mathrm{SSE}_{L_B}(Y_2) + \\mathrm{SSE}_{R_B}(Y_2) = 0 + 0 = 0$。\n\n**使用求和准则进行比较**\n\n目标是选择使总杂质度 $\\mathrm{SSE}(Y_1) + \\mathrm{SSE}(Y_2)$ 最小化的分裂。\n- 对于 $\\mathcal{S}_A$：总杂质度 $I_A = \\mathrm{SSE}_{\\mathcal{S}_A}(Y_1) + \\mathrm{SSE}_{\\mathcal{S}_A}(Y_2) = 0 + 4 = 4$。\n- 对于 $\\mathcal{S}_B$：总杂质度 $I_B = \\mathrm{SSE}_{\\mathcal{S}_B}(Y_1) + \\mathrm{SSE}_{\\mathcal{S}_B}(Y_2) = \\frac{16}{3} + 0 = \\frac{16}{3}$。\n比较这两个值：$I_A = 4 = \\frac{12}{3}$。由于 $\\frac{12}{3}  \\frac{16}{3}$，我们有 $I_A  I_B$。因此，在求和准则下，分裂 $\\mathcal{S}_A$ 更优。\n\n**无差异权重 $w^{\\star}$ 的推导**\n\n当两种分裂的加权杂质度相等时，加权准则对它们无差异。设 $W_{\\mathcal{S}}(w)$ 为分裂 $\\mathcal{S}$ 的加权杂质度。我们需要找到 $w^{\\star}$，使得 $W_{\\mathcal{S}_A}(w^{\\star}) = W_{\\mathcal{S}_B}(w^{\\star})$。\n加权杂质度定义为 $W_{\\mathcal{S}}(w) = w\\,\\mathrm{SSE}_{\\mathcal{S}}(Y_1) + (1-w)\\,\\mathrm{SSE}_{\\mathcal{S}}(Y_2)$。\n\n令加权杂质度相等：\n$$w^{\\star}\\,\\mathrm{SSE}_{\\mathcal{S}_{A}}(Y_{1}) + (1-w^{\\star})\\,\\mathrm{SSE}_{\\mathcal{S}_{A}}(Y_{2}) = w^{\\star}\\,\\mathrm{SSE}_{\\mathcal{S}_{B}}(Y_{1}) + (1-w^{\\star})\\,\\mathrm{SSE}_{\\mathcal{S}_{B}}(Y_{2})$$\n代入计算出的 SSE 值：\n$$w^{\\star}(0) + (1-w^{\\star})(4) = w^{\\star}\\left(\\frac{16}{3}\\right) + (1-w^{\\star})(0)$$\n简化为：\n$$4(1-w^{\\star}) = \\frac{16}{3}w^{\\star}$$\n现在我们求解 $w^{\\star}$：\n$$4 - 4w^{\\star} = \\frac{16}{3}w^{\\star}$$\n$$4 = \\frac{16}{3}w^{\\star} + 4w^{\\star}$$\n$$4 = \\left(\\frac{16}{3} + \\frac{12}{3}\\right)w^{\\star}$$\n$$4 = \\frac{28}{3}w^{\\star}$$\n$$w^{\\star} = 4 \\cdot \\frac{3}{28} = \\frac{12}{28} = \\frac{3}{7}$$\n值 $w^{\\star}=\\frac{3}{7}$ 确实在指定的区间 $(0,1)$ 内。这是加权准则判断两个分裂同样好的唯一权重。",
            "answer": "$$\\boxed{\\frac{3}{7}}$$"
        },
        {
            "introduction": "在通过递归分裂生成一棵完整的决策树后，下一个关键步骤是剪枝，这是防止模型过拟合并提升其泛化能力的必要手段。本练习将带你一步步地应用成本复杂性剪枝，也称为“最弱环节剪枝” (weakest link pruning)，让你清晰地理解剪枝过程中的每一步计算 。掌握这项技术，是构建稳健且实用的决策树模型的关键。",
            "id": "3168071",
            "problem": "一个回归树通过对数据集使用平方误差损失进行递归二元分裂来生长，直到获得一棵最大树 $T_{\\max}$。为解决此问题，我们给出了最终的树结构，以及将每个内部节点视为单个叶节点时的经验平方误差和（风险），还有所有当前叶节点的风险。根节点是 $r$，它有两个子节点：一个左内部节点 $L$ 和一个右内部节点 $R$。节点 $L$ 分裂成两个叶节点 $L_{\\ell}$ 和 $L_{r}$。节点 $R$ 分裂成一个左叶节点 $R_{\\ell}$ 和一个内部节点 $RR$，而 $RR$ 又分裂成两个叶节点 $RR_{\\ell}$ 和 $RR_{r}$。经验风险如下：\n- 在内部节点被视为单个叶节点时：$R(r)=20.0$, $R(L)=9.0$, $R(R)=8.5$, $R(RR)=4.0$。\n- 在当前叶节点处：$R(L_{\\ell})=3.0$, $R(L_{r})=2.0$, $R(R_{\\ell})=4.0$, $R(RR_{\\ell})=1.0$, $R(RR_{r})=1.5$。\n\n假设对于一棵使用平方误差损失的树 $T$，其成本复杂度函数是经验风险加上一个与终端节点数量成正比的惩罚项，也就是说，惩罚项取决于叶节点的数量 $|T|$。仅使用平方误差回归树的经验风险的基本定义和带有调整参数 $\\alpha \\ge 0$ 的成本复杂度准则，完成以下任务：\n- 计算总经验风险 $R(T_{\\max})$，并确定通过最弱连接剪枝获得的成本复杂度剪枝序列 $\\{T_{\\alpha}\\}$。识别出最优子树发生变化的 $\\alpha$ 的断点。\n- 通过在每个剪枝步骤中识别被折叠的内部节点和由此产生的树风险，明确地展示此示例上的最弱连接剪枝过程。\n\n作为你的最终答案，报告最优子树发生进一步剪枝的第二个断点 $\\alpha_{2}$ 的值。请以精确有理数形式给出答案（不要四舍五入）。",
            "solution": "该问题要求我们对给定的回归树执行成本复杂度剪枝，也称为最弱连接剪枝。目标是找到最优剪枝子树的序列以及复杂度参数 $\\alpha$ 的相应断点。题目特别要求我们给出第二个断点 $\\alpha_2$ 的值。\n\n子树 $T$ 的成本复杂度准则由 $C_{\\alpha}(T) = R(T) + \\alpha |T|$ 给出，其中 $R(T)$ 是树的经验风险（平方误差和），$|T|$ 是其终端节点（叶节点）的数量。参数 $\\alpha \\ge 0$ 对树的复杂度进行惩罚。\n\n最弱连接剪枝是一种迭代算法。在每一步中，我们识别出那个每移除一个叶节点所带来的误差增加量最小的内部节点 $t$。这由内部节点 $t$ 及其对应分支（子树）$T_t$ 的函数 $g(t)$ 来量化：\n$$g(t) = \\frac{R(t) - R(T_t)}{|T_t| - 1}$$\n这里，$R(t)$ 是将节点 $t$ 视为叶节点时的经验风险，$R(T_t)$ 是分支 $T_t$ 内所有终端节点风险的总和。分母 $|T_t| - 1$ 表示通过剪枝分支 $T_t$ 所“节省”的叶节点数量。值 $\\alpha_k = g(t)$ 表示一个断点，在此点上，我们对于保留分支 $T_t$ 和将其剪枝到节点 $t$ 两者之间没有偏好。最弱连接是具有最小 $g(t)$ 值的内部节点。\n\n为了精确起见，我们将给定的风险值转换为精确的有理数：\n$R(r)=20.0 = 20$\n$R(L)=9.0 = 9$\n$R(R)=8.5 = \\frac{17}{2}$\n$R(RR)=4.0 = 4$\n$R(L_{\\ell})=3.0 = 3$\n$R(L_{r})=2.0 = 2$\n$R(R_{\\ell})=4.0 = 4$\n$R(RR_{\\ell})=1.0 = 1$\n$R(RR_{r})=1.5 = \\frac{3}{2}$\n\n设 $T_0$ 表示最大树 $T_{\\max}$。$T_0$ 的结构如下：\n- 根节点是 $r$。\n- 节点 $r$ 分裂成节点 $L$ 和 $R$。\n- 节点 $L$ 是内部节点，分裂成叶节点 $L_{\\ell}$ 和 $L_{r}$。\n- 节点 $R$ 是内部节点，分裂成叶节点 $R_{\\ell}$ 和内部节点 $RR$。\n- 节点 $RR$ 是内部节点，分裂成叶节点 $RR_{\\ell}$ 和 $RR_{r}$。\n\n$T_0$ 的内部节点是 $\\{r, L, R, RR\\}$。\n$T_0$ 的叶节点是 $\\{L_{\\ell}, L_{r}, R_{\\ell}, RR_{\\ell}, RR_{r}\\}$。\n$T_0$ 的叶节点数量是 $|T_0|=5$。\n\n首先，我们通过对其叶节点的风险求和来计算最大树 $T_0$ 的总经验风险：\n$$R(T_0) = R(L_{\\ell}) + R(L_{r}) + R(R_{\\ell}) + R(RR_{\\ell}) + R(RR_{r}) = 3 + 2 + 4 + 1 + \\frac{3}{2} = 10 + \\frac{3}{2} = \\frac{23}{2}$$\n\n现在，我们通过计算 $T_0$ 中所有内部节点的 $g(t)$ 来执行第一个剪枝步骤。\n\n- 对于内部节点 $L$：分支 $T_L$ 有叶节点 $\\{L_{\\ell}, L_{r}\\}$。\n  $R(T_L) = R(L_{\\ell}) + R(L_{r}) = 3 + 2 = 5$。\n  $|T_L| = 2$。\n  $g(L) = \\frac{R(L) - R(T_L)}{|T_L| - 1} = \\frac{9 - 5}{2 - 1} = 4$。\n\n- 对于内部节点 $RR$：分支 $T_{RR}$ 有叶节点 $\\{RR_{\\ell}, RR_{r}\\}$。\n  $R(T_{RR}) = R(RR_{\\ell}) + R(RR_{r}) = 1 + \\frac{3}{2} = \\frac{5}{2}$。\n  $|T_{RR}| = 2$。\n  $g(RR) = \\frac{R(RR) - R(T_{RR})}{|T_{RR}| - 1} = \\frac{4 - \\frac{5}{2}}{2 - 1} = \\frac{\\frac{3}{2}}{1} = \\frac{3}{2}$。\n\n- 对于内部节点 $R$：分支 $T_R$ 有叶节点 $\\{R_{\\ell}, RR_{\\ell}, RR_{r}\\}$。\n  $R(T_R) = R(R_{\\ell}) + R(T_{RR}) = 4 + \\frac{5}{2} = \\frac{13}{2}$。\n  $|T_R| = 3$。\n  $g(R) = \\frac{R(R) - R(T_R)}{|T_R| - 1} = \\frac{\\frac{17}{2} - \\frac{13}{2}}{3 - 1} = \\frac{\\frac{4}{2}}{2} = \\frac{2}{2} = 1$。\n\n- 对于根节点 $r$：分支是整棵树 $T_0$。\n  $R(T_r) = R(T_0) = \\frac{23}{2}$。\n  $|T_r| = |T_0| = 5$。\n  $g(r) = \\frac{R(r) - R(T_0)}{|T_0| - 1} = \\frac{20 - \\frac{23}{2}}{5 - 1} = \\frac{\\frac{17}{2}}{4} = \\frac{17}{8}$。\n\n$T_0$ 内部节点的 $g(t)$ 值是：\n$$ g(L) = 4, \\quad g(RR) = \\frac{3}{2} = 1.5, \\quad g(R) = 1, \\quad g(r) = \\frac{17}{8} = 2.125 $$\n最弱连接是具有最小 $g(t)$ 值的节点。\n$$\\min\\{g(L), g(RR), g(R), g(r)\\} = \\min\\left\\{4, \\frac{3}{2}, 1, \\frac{17}{8}\\right\\} = g(R) = 1$$\n因此，第一个断点是 $\\alpha_1 = 1$，要被剪枝的内部节点是 $R$。\n\n这个剪枝步骤折叠了整个分支 $T_R$，使节点 $R$ 成为一个叶节点。得到的树是 $T_1$。对于范围 $[\\alpha_1, \\alpha_2)$ 内的 $\\alpha$，最优子树是 $T_1$。\n- $T_1$ 的结构：根节点 $r$ 分裂成内部节点 $L$ 和叶节点 $R$。节点 $L$ 分裂成叶节点 $L_{\\ell}$ 和 $L_{r}$。\n- $T_1$ 的叶节点：$\\{L_{\\ell}, L_{r}, R\\}$。\n- $|T_1| = 3$。\n- 得到的风险是 $R(T_1) = R(L_{\\ell}) + R(L_{r}) + R(R) = 3 + 2 + \\frac{17}{2} = 5 + \\frac{17}{2} = \\frac{27}{2}$。\n\n为了找到第二个断点 $\\alpha_2$，我们在新树 $T_1$ 上重复这个过程。我们必须找到 $T_1$ 内部的最弱连接。\n$T_1$ 的内部节点是 $\\{r, L\\}$。我们计算它们的 $g(t)$ 值。\n\n- 对于内部节点 $L$：在 $T_1$ 内的分支 $T_L$ 与在 $T_0$ 中的相同。\n  $g(L) = 4$。\n\n- 对于根节点 $r$：分支现在是整棵树 $T_1$。\n  $R(T_r) = R(T_1) = \\frac{27}{2}$。\n  $|T_r| = |T_1| = 3$。\n  $g(r) = \\frac{R(r) - R(T_1)}{|T_1| - 1} = \\frac{20 - \\frac{27}{2}}{3 - 1} = \\frac{\\frac{13}{2}}{2} = \\frac{13}{4}$。\n\n$T_1$ 内部节点的 $g(t)$ 值是：\n$$ g(L) = 4 = \\frac{16}{4}, \\quad g(r) = \\frac{13}{4} $$\n新的最弱连接是 $T_1$ 中具有最小 $g(t)$ 值的节点。\n$$\\min\\{g(L), g(r)\\} = \\min\\left\\{4, \\frac{13}{4}\\right\\} = g(r) = \\frac{13}{4}$$\n因此，最优子树从 $T_1$ 变为更小的树的第二个断点是 $\\alpha_2 = \\frac{13}{4}$。\n\n剪枝序列如下：\n1. 对于 $0 \\le \\alpha  1$，最优树是 $T_0 = T_{\\max}$，它有 5 个叶节点，风险为 $R(T_0) = \\frac{23}{2}$。\n2. 在 $\\alpha_1=1$ 时，节点 $R$ 被剪枝。对于 $1 \\le \\alpha  \\frac{13}{4}$，最优树是 $T_1$，它有 3 个叶节点，风险为 $R(T_1) = \\frac{27}{2}$。\n3. 在 $\\alpha_2=\\frac{13}{4}$ 时，节点 $r$ 被剪枝（即，整棵树 $T_1$ 被折叠到其根节点）。对于 $\\alpha \\ge \\frac{13}{4}$，最优树是 $T_2=\\{r\\}$，它有 1 个叶节点，风险为 $R(T_2)=20$。\n\n题目要求的是第二个断点 $\\alpha_2$ 的值。这个值是 $\\frac{13}{4}$。",
            "answer": "$$\\boxed{\\frac{13}{4}}$$"
        },
        {
            "introduction": "在掌握了分裂和剪枝的基本机理后，是时候深入探究递归二元分裂的算法策略了。该算法采用的“贪婪”策略——即在每一步都做出局部最优的选择——虽然高效，但并不总能保证得到全局最优的决策树。这个练习是一个思想实验，它要求你构建一个具体的反例，以证明这种局部最优选择可能导致的次优结果 。通过这个过程，你将对该算法在性能与计算成本之间的内在权衡形成更深刻的批判性理解。",
            "id": "3168039",
            "problem": "您正在研究在平方损失下通过递归二元分裂构建的一维决策树。对于一组给定的训练样本对 $\\{(x_i,y_i)\\}_{i=1}^{n}$，其中 $x_i \\in \\mathbb{R}$ 且 $y_i \\in \\mathbb{R}$，在阈值 $t \\in \\mathbb{R}$ 处的一次分裂将数据划分为两个叶节点：左叶节点 $\\{i: x_i \\le t\\}$ 和右叶节点 $\\{i: x_i > t\\}$。每个叶节点的不纯度由平方误差和 (SSE) 度量，即对于任意叶节点 $L$ 及其响应值 $\\{y_i\\}_{i \\in L}$ 和叶节点均值 $\\bar{y}_L$，其不纯度为 $\\sum_{i \\in L} (y_i - \\bar{y}_L)^2$。贪心根分裂选择的阈值 $t$ 能使该单次分裂后的总SSE最小化。\n\n定义一个“深度为2的前瞻计划”为联合选择两个阈值，其中一个阈值作用于根节点，另一个阈值作用于左子节点或右子节点，最终产生至多三个叶节点。在此设定下，您将构建一个最小反例，说明在使用两个阈值后，相对于最终的总SSE，贪心根分裂是次优的。\n\n考虑沿 $x$ 轴的三个连续簇，按顺序分别称为“左”、“中”、“右”，其结构如下：\n- “左”簇有 $p$ 个点，其 $x$ 坐标接近于区间 $[0,1)$。\n- “中”簇有 $q$ 个点，其 $x$ 坐标接近于区间 $[1,2)$。\n- “右”簇有 $r$ 个点，其 $x$ 坐标接近于区间 $[2,3)$，但其内部包含两个沿 $x$ 轴分离的子簇（因此右簇内部的一个阈值可以将其分裂为两部分）。\n\n假设目标值如下：\n- 所有 $p$ 个“左”簇的响应值均为 $y=0$。\n- 所有 $q$ 个“中”簇的响应值均为 $y=\\delta$，其中 $\\delta \\neq 0$ 是一个常数。\n- $r$ 个“右”簇的响应值由 $r/2$ 个 $y=+B$ 的点和 $r/2$ 个 $y=-B$ 的点组成，其中 $B>0$，且这两个右子簇可以通过 $[2,3)$ 内的一个阈值进行分离。\n\n在总共只允许使用两个阈值（一个在根节点，一个应用于其某个子节点）的约束下，构建这样一个配置，并确定最小总样本量 $N_{\\min} = p + q + r$，使得存在一组 $(p,q,r,\\delta,B)$ 的选择以及点沿 $x$ 轴的实际位置，同时满足以下两个条件：\n1. 贪心根分裂选择位于“左”簇和“中”簇之间的一个阈值。\n2. 首先在“中”簇和“右”簇之间进行分裂，然后使用第二个阈值在“右”簇内进行分裂的深度为2的前瞻计划，其最终总SSE严格小于贪心计划的最终总SSE。\n\n您的最终答案必须是单个实数值 $N_{\\min}$。不需要单位。请给出精确的最终答案，无需四舍五入。",
            "solution": "用户希望在一个一维回归树问题中，找到一个最小总样本量 $N_{\\min}$，用于构建一个反例，证明贪心根分裂相对于深度为2的前瞻计划是次优的。\n\n### 1. 问题建模与已知条件\n\n设所有训练点的集合为 $S$。它根据预测变量 $x$ 被划分为三个簇：\n- “左”簇 $C_L$ 有 $p$ 个点，其 $x$ 坐标接近于区间 $[0,1)$，且所有目标值 $y_i=0$。\n- “中”簇 $C_M$ 有 $q$ 个点，其 $x$ 坐标接近于区间 $[1,2)$，且所有目标值 $y_i=\\delta$。\n- “右”簇 $C_R$ 有 $r$ 个点，其 $x$ 坐标接近于区间 $[2,3)$。该簇由两个子簇组成：$r/2$ 个点的 $y_i=+B$，$r/2$ 个点的 $y_i=-B$。已知 $r$ 是偶数，$\\delta \\neq 0$，且 $B > 0$。\n\n任意叶节点 $L$（包含 $n_L$ 个点）的不纯度是其平方误差和 (SSE)：$SSE(L) = \\sum_{i \\in L} (y_i - \\bar{y}_L)^2$，其中 $\\bar{y}_L = \\frac{1}{n_L}\\sum_{i \\in L} y_i$。\n\n一个包含两组点的叶节点的SSE的有用公式是：\n如果一个叶节点 $L$ 包含 $n_1$ 个均值为 $\\mu_1$ 的点和 $n_2$ 个均值为 $\\mu_2$ 的点，其SSE由公式 $SSE(L) = \\frac{n_1 n_2}{n_1+n_2}(\\mu_1-\\mu_2)^2$ 给出。\n\n让我们计算初始簇作为叶节点时的SSE：\n- $SSE(C_L)$: 所有点的 $y=0$。这是一个纯叶节点，所以 $SSE(C_L) = 0$。\n- $SSE(C_M)$: 所有点的 $y=\\delta$。这是一个纯叶节点，所以 $SSE(C_M) = 0$。\n- $SSE(C_R)$: 包含 $r/2$ 个 $y=+B$ 的点和 $r/2$ 个 $y=-B$ 的点。均值为 $\\bar{y}_{C_R} = \\frac{(r/2)B + (r/2)(-B)}{r} = 0$。\n  $SSE(C_R) = \\sum (y_i - 0)^2 = \\frac{r}{2}B^2 + \\frac{r}{2}(-B)^2 = rB^2$。\n\n### 2. 贪心根分裂分析\n\n贪心算法会考虑所有可能的根分裂。由于簇的结构，唯一有意义的分裂是发生在簇之间。我们考虑两个候选阈值：\n- $T_1$: 位于左簇和中簇之间的一个阈值（例如，$t_1 \\in [1,2)$）。这将数据 $S$ 划分为 $C_L$ 和 $C_M \\cup C_R$。\n- $T_2$: 位于中簇和右簇之间的一个阈值（例如，$t_2 \\in [2,3)$）。这将数据 $S$ 划分为 $C_L \\cup C_M$ 和 $C_R$。\n\n让我们计算每次分裂的总SSE。\n- **对于分裂 $T_1$**：\n  - 左叶节点是 $C_L$。$SSE(C_L) = 0$。\n  - 右叶节点是 $C_M \\cup C_R$。它包含 $q$ 个 $y=\\delta$ 的点和来自 $C_R$ 的 $r$ 个点（均值为0，平方和为 $rB^2$）。该叶节点的均值为 $\\bar{y}_{M \\cup R} = \\frac{q\\delta + r \\cdot 0}{q+r} = \\frac{q\\delta}{q+r}$。\n  - $SSE(C_M \\cup C_R) = \\sum_{i \\in C_M \\cup C_R} y_i^2 - (q+r)\\bar{y}_{M \\cup R}^2 = (q\\delta^2 + rB^2) - (q+r)\\left(\\frac{q\\delta}{q+r}\\right)^2 = q\\delta^2 + rB^2 - \\frac{q^2\\delta^2}{q+r} = \\frac{q(q+r)\\delta^2 - q^2\\delta^2}{q+r} + rB^2 = \\frac{qr\\delta^2}{q+r} + rB^2$。\n  - 这次分裂的总SSE为 $SSE(T_1) = 0 + \\frac{qr\\delta^2}{q+r} + rB^2$。\n\n- **对于分裂 $T_2$**：\n  - 左叶节点是 $C_L \\cup C_M$。它包含 $p$ 个 $y=0$ 的点和 $q$ 个 $y=\\delta$ 的点。使用两组点公式，$SSE(C_L \\cup C_M) = \\frac{pq}{p+q}(0-\\delta)^2 = \\frac{pq\\delta^2}{p+q}$。\n  - 右叶节点是 $C_R$。我们已经计算出 $SSE(C_R) = rB^2$。\n  - 这次分裂的总SSE为 $SSE(T_2) = \\frac{pq\\delta^2}{p+q} + rB^2$。\n\n**条件1**：问题陈述贪心根分裂是 $T_1$。这意味着 $SSE(T_1)  SSE(T_2)$。\n$$ \\frac{qr\\delta^2}{q+r} + rB^2  \\frac{pq\\delta^2}{p+q} + rB^2 $$\n$$ \\frac{qr\\delta^2}{q+r}  \\frac{pq\\delta^2}{p+q} $$\n因为 $q>0$ 且 $\\delta \\neq 0$，我们可以除以 $q\\delta^2$：\n$$ \\frac{r}{q+r}  \\frac{p}{p+q} \\implies r(p+q)  p(q+r) \\implies pr + qr  pq + pr \\implies qr  pq $$\n因为 $q>0$，这可以简化为关于簇大小的一个关键约束：\n$$ r  p $$\n\n### 3. 深度为2的计划分析\n\n我们需要比较两种不同两步计划的最终SSE。\n\n**计划A（贪心计划）**：\n1.  根分裂是 $T_1$，产生一个纯叶节点 $C_L$（SSE=$0$）和一个不纯的叶节点 $C_M \\cup C_R$。\n2.  第二次分裂应用于不纯的叶节点 $C_M \\cup C_R$ 以实现SSE的最大额外减少。该节点的可能分裂有：\n    a) 将 $C_M$ 从 $C_R$ 中分离。这将产生两个新叶节点，$C_M$（SSE=$0$）和 $C_R$（SSE=$rB^2$）。这个分支的SSE变为 $rB^2$。\n    b) 在 $C_R$ 内部进行分裂。这将分离 $y=+B$ 和 $y=-B$ 的子簇。结果是一个包含 $C_M \\cup \\{y=+B \\text{ 的点}\\}$ 的叶节点和一个包含 $\\{y=-B \\text{ 的点}\\}$ 的叶节点。不失一般性，我们假设分离出 $y=-B$ 的点。叶节点 $\\{y=-B\\}$ 是纯的（SSE=$0$）。另一个叶节点包含 $q$ 个 $y=\\delta$ 的点和 $r/2$ 个 $y=B$ 的点。其SSE为 $\\frac{q(r/2)}{q+r/2}(\\delta-B)^2 = \\frac{qr(\\delta-B)^2}{2q+r}$。\n3.  贪心计划的最终总SSE为：\n    $$ SSE_A = \\min \\left( rB^2, \\frac{qr(\\delta-B)^2}{2q+r}, \\frac{qr(\\delta+B)^2}{2q+r} \\right) $$\n    不失一般性，我们可以探究参数使得 $(\\delta-B)^2$ 小于 $(\\delta+B)^2$（例如 $\\delta, B > 0$），所以我们分析：\n    $$ SSE_A = \\min \\left( rB^2, \\frac{qr(\\delta-B)^2}{2q+r} \\right) $$\n\n**计划B（前瞻计划）**：\n1.  根分裂是 $T_2$，产生叶节点 $C_L \\cup C_M$ 和 $C_R$。\n2.  第二次分裂应用于右叶节点 $C_R$ 内部。由于 $C_R$ 由两个可分离的纯子簇（$y=+B$ 和 $y=-B$）组成，这次分裂会产生两个新的叶节点，每个的SSE都为0。\n3.  最终的叶节点是 $C_L \\cup C_M$、$\\{y=+B \\text{ 的点}\\}$ 和 $\\{y=-B \\text{ 的点}\\}$。这个计划的最终总SSE是它们各自SSE的和：\n    $$ SSE_B = SSE(C_L \\cup C_M) + 0 + 0 = \\frac{pq\\delta^2}{p+q} $$\n\n**条件2**：前瞻计划（计划B）严格优于贪心计划（计划A）。\n$$ SSE_B  SSE_A $$\n$$ \\frac{pq\\delta^2}{p+q}  \\min \\left( rB^2, \\frac{qr(\\delta-B)^2}{2q+r} \\right) $$\n这要求对于某个参数选择，以下两个不等式同时成立：\n(i) $\\frac{pq\\delta^2}{p+q}  rB^2$\n(ii) $\\frac{pq\\delta^2}{p+q}  \\frac{qr(\\delta-B)^2}{2q+r}$\n\n### 4. 寻找最小样本量\n\n我们需要找到 $N = p+q+r$ 的最小整数值，使得存在整数 $p,q \\ge 1$、偶数 $r \\ge 2$ 和实数 $\\delta \\neq 0, B>0$ 满足 $r  p$ 和上述两个不等式条件。\n\n为了最小化 $N=p+q+r$，我们应该选择最小的可能整数 $p, q, r$。\n-   $q \\ge 1$。最小值为 $q=1$。\n-   $r \\ge 2$ 且为偶数。最小值为 $r=2$。\n-   $r  p$。由于 $r=2$，最小的整数 $p$ 是 $p=3$。\n\n让我们测试这个最小配置：$p=3, q=1, r=2$。\n这给出了总样本量 $N = 3+1+2=6$。\n现在我们必须检查是否存在 $\\delta, B$ 使得不等式 (i) 和 (ii) 成立。\n-   LHS（计划B的SSE，除以 $\\delta^2$）：$\\frac{pq}{p+q} = \\frac{3 \\cdot 1}{3+1} = \\frac{3}{4}$。\n-   不等式 (i) 变为：$\\frac{3}{4}\\delta^2  2B^2 \\implies 3\\delta^2  8B^2$。\n-   不等式 (ii) 变为：$\\frac{3}{4}\\delta^2  \\frac{1 \\cdot 2 (\\delta-B)^2}{2 \\cdot 1 + 2} = \\frac{2(\\delta-B)^2}{4} = \\frac{(\\delta-B)^2}{2} \\implies 3\\delta^2  2(\\delta-B)^2$。\n\n我们只需要证明存在一对 $(\\delta, B)$ 满足这两个条件。\n让我们关注更严格的条件：$3\\delta^2  2(\\delta-B)^2$。\n$3\\delta^2  2(\\delta^2 - 2\\delta B + B^2)$\n$3\\delta^2  2\\delta^2 - 4\\delta B + 2B^2$\n$\\delta^2 + 4\\delta B - 2B^2  0$\n\n将此视为关于 $\\delta$ 的二次函数 $f(\\delta) = \\delta^2 + (4B)\\delta - 2B^2$。这是一个开口向上的抛物线，它在两个根之间取负值。根由 $\\delta = \\frac{-4B \\pm \\sqrt{(4B)^2 - 4(1)(-2B^2)}}{2} = \\frac{-4B \\pm \\sqrt{16B^2 + 8B^2}}{2} = \\frac{-4B \\pm \\sqrt{24B^2}}{2} = \\frac{-4B \\pm 2B\\sqrt{6}}{2} = B(-2 \\pm \\sqrt{6})$。\n只要我们选择 $\\delta$ 在区间 $(B(-2 - \\sqrt{6}), B(-2 + \\sqrt{6}))$ 内，不等式 (ii) 就成立。由于 $B>0$ 且 $\\sqrt{6} \\approx 2.45$，这个区间大约是 $(-4.45B, 0.45B)$。我们可以选择一个非零的 $\\delta$，例如 $\\delta = 0.1B$。\n\n现在检查不等式 (i)：$3\\delta^2  8B^2$。\n将 $\\delta = 0.1B$ 代入，我们得到 $3(0.1B)^2  8B^2 \\implies 3(0.01)B^2  8B^2 \\implies 0.03B^2  8B^2$，这是成立的。\n\n因此，使用 $p=3, q=1, r=2$ 的配置，我们可以找到满足所有条件的 $\\delta$ 和 $B$。这个配置的总样本量是 $N=6$。\n\n我们能找到更小的 $N$ 吗？\n-   $N=p+q+r$。\n-   我们有约束 $p,q \\ge 1$，$r \\ge 2$（偶数），和 $r  p$。\n-   $N = p+q+r > r+1+r = 2r+1 \\ge 2(2)+1 = 5$。所以 $N$ 必须至少为 6。\n-   $N=4$：$p=1, q=1, r=2$。违反 $r  p$ ($2  1$ 不成立)。\n-   $N=5$：\n    -   $p=2, q=1, r=2$。违反 $r  p$ ($2  2$ 不成立)。\n    -   $p=1, q=2, r=2$。违反 $r  p$ ($2  1$ 不成立)。\n因此，最小总样本量 $N_{\\min}$ 是 6。",
            "answer": "$$\\boxed{6}$$"
        }
    ]
}