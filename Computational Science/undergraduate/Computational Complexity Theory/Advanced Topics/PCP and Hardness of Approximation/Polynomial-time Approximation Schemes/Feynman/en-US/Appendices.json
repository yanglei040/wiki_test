{
    "hands_on_practices": [
        {
            "introduction": "The distinction between a Polynomial-Time Approximation Scheme (PTAS) and a Fully Polynomial-Time Approximation Scheme (FPTAS) is fundamental to understanding practical algorithm design for NP-hard problems. This first practice problem challenges you to apply these definitions directly, analyzing how the runtime's dependence on the input size $n$ and the error tolerance $\\epsilon$ determines its classification . Mastering this is the essential first step toward evaluating the feasibility of an approximation algorithm.",
            "id": "1435966",
            "problem": "A technology company, `ConnectSphere`, is working on a notoriously difficult optimization problem related to resource allocation on its distributed computing platform. The problem is known to be NP-hard. To find practical solutions, their algorithms division has developed four different approximation algorithms. Each algorithm takes the problem instance, of size $n$, and an error-tolerance parameter $\\epsilon > 0$, and produces a solution that is guaranteed to be within a factor of $(1+\\epsilon)$ of the optimal solution.\n\nThe company needs to evaluate which of these algorithms can be classified as a Polynomial-Time Approximation Scheme (PTAS) or a Fully Polynomial-Time Approximation Scheme (FPTAS). The definitions are as follows:\n\n- A **Polynomial-Time Approximation Scheme (PTAS)** is an approximation algorithm whose running time is polynomial in the input size $n$ for every fixed value of $\\epsilon > 0$. The exponent of the polynomial can depend on $\\epsilon$. For example, a running time of $O(n^{1/\\epsilon})$ is a PTAS.\n- A **Fully Polynomial-Time Approximation Scheme (FPTAS)** is a PTAS whose running time is also polynomial in $1/\\epsilon$. For example, a running time of $O((1/\\epsilon)^{2} \\cdot n^{3})$ is an FPTAS.\n\nThe time complexities for the four proposed algorithms are:\n- **Algorithm 1:** $T_1(n, \\epsilon) = O(n^4 + (1/\\epsilon)^3)$\n- **Algorithm 2:** $T_2(n, \\epsilon) = O(n \\cdot 3^{1/\\epsilon})$\n- **Algorithm 3:** $T_3(n, \\epsilon) = O(n^{2 + 1/\\epsilon})$\n- **Algorithm 4:** $T_4(n, \\epsilon) = O(\\frac{1}{\\epsilon^2} \\cdot n^2 \\log n)$\n\nWhich of the following algorithms qualify as a Fully Polynomial-Time Approximation Scheme (FPTAS)?\n\nA. Algorithm 2 only\n\nB. Algorithm 1 and Algorithm 4 only\n\nC. Algorithm 2 and Algorithm 3 only\n\nD. Algorithm 3 only\n\nE. All four algorithms are FPTAS.",
            "solution": "We use the definitions:\n- An algorithm is a PTAS if, for every fixed $\\epsilon>0$, its running time is polynomial in $n$.\n- An algorithm is an FPTAS if it is a PTAS and, in addition, its running time is polynomial in both $n$ and $1/\\epsilon$. Formally, there should exist constants $a,b \\geq 0$ and a constant $C>0$ such that $T(n,\\epsilon) \\leq C \\cdot n^{a} \\cdot (1/\\epsilon)^{b}$ up to polylogarithmic factors in $n$.\n\nWe examine each algorithm:\n\nAlgorithm 1: $T_{1}(n,\\epsilon) = O\\!\\left(n^{4} + (1/\\epsilon)^{3}\\right)$. This is the sum of a polynomial in $n$ and a polynomial in $1/\\epsilon$. Therefore $T_{1}(n,\\epsilon)$ is polynomial in both $n$ and $1/\\epsilon$, so Algorithm 1 is an FPTAS.\n\nAlgorithm 2: $T_{2}(n,\\epsilon) = O\\!\\left(n \\cdot 3^{1/\\epsilon}\\right) = O\\!\\left(n \\cdot \\exp\\!\\left((\\ln 3)/\\epsilon\\right)\\right)$. The factor $3^{1/\\epsilon}$ is exponential in $1/\\epsilon$ and is not bounded by any polynomial in $1/\\epsilon$. Hence this is not polynomial in $1/\\epsilon$, so Algorithm 2 is not an FPTAS (although it is a PTAS, since for fixed $\\epsilon$ the factor $3^{1/\\epsilon}$ is a constant).\n\nAlgorithm 3: $T_{3}(n,\\epsilon) = O\\!\\left(n^{2+1/\\epsilon}\\right) = O\\!\\left(n^{2} \\cdot n^{1/\\epsilon}\\right) = O\\!\\left(n^{2} \\cdot \\exp\\!\\left((\\ln n)/\\epsilon\\right)\\right)$. Here the exponent of $n$ depends on $1/\\epsilon$. If an FPTAS bound $T(n,\\epsilon) \\leq C \\cdot n^{a} \\cdot (1/\\epsilon)^{b}$ held for some fixed $a,b$, then for sufficiently small $\\epsilon$ we would have $1/\\epsilon > a$, and as $n \\to \\infty$ the term $n^{1/\\epsilon}$ would dominate any fixed power $n^{a}$, contradicting the bound. Thus Algorithm 3 is not an FPTAS (though it is a PTAS since for fixed $\\epsilon$ the running time is polynomial in $n$).\n\nAlgorithm 4: $T_{4}(n,\\epsilon) = O\\!\\left((1/\\epsilon)^{2} \\cdot n^{2} \\ln n\\right)$. This is polynomial in $1/\\epsilon$ and polynomial in $n$ (since $n^{2} \\ln n \\leq n^{3}$ for sufficiently large $n$, it is upper bounded by a polynomial). Therefore Algorithm 4 is an FPTAS.\n\nCombining these, exactly Algorithms 1 and 4 are FPTAS.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Theoretical guarantees are one thing, but practical performance is another. A PTAS might sound great in theory, but its runtime can be prohibitively expensive even for modest accuracy goals. This exercise provides a sobering, concrete example of this 'tyranny of the exponent,' calculating the astronomical number of operations required by a PTAS to achieve a common precision target . Through this calculation, you will gain a visceral understanding of why the stricter FPTAS definition is so crucial for real-world applications.",
            "id": "1435944",
            "problem": "A tech startup specializing in logistics is developing an algorithm to optimize the delivery routes for its fleet of autonomous drones. The problem is a minimization problem, aiming to find the shortest possible path that visits a set of $n$ locations. They are using an algorithm from a class known as a Polynomial-Time Approximation Scheme (PTAS). A PTAS, for any given error tolerance $\\epsilon > 0$, guarantees a solution with a total length no more than $(1+\\epsilon)$ times the absolute optimal solution's length.\n\nThe specific PTAS implementation the company is using has a known time complexity, measured in the number of elementary computational operations, given by the function $T(n, \\epsilon) = c \\cdot n^{1/\\epsilon}$, where $n$ is the number of delivery locations and the constant $c = 10^5$.\n\nManagement has mandated that for a new service in a mid-sized city with $n=60$ delivery locations, the calculated drone routes must be guaranteed to be no more than $2\\%$ longer than the mathematically optimal route. Calculate the total number of elementary operations required by the algorithm to meet this guarantee for a single route calculation. Express your answer in scientific notation, rounded to three significant figures.",
            "solution": "The problem asks for the number of elementary operations required by a specific approximation algorithm to find a drone route. The algorithm's performance is described by its time complexity function and the quality of its approximation.\n\nFirst, let's identify the parameters given in the problem statement.\nThe number of delivery locations is $n=60$.\nThe constant in the time complexity function is $c=10^5$.\nThe time complexity function is $T(n, \\epsilon) = c \\cdot n^{1/\\epsilon}$.\n\nThe requirement from management is that the route generated by the algorithm must be no more than $2\\%$ longer than the optimal route. For a minimization problem, a Polynomial-Time Approximation Scheme (PTAS) produces a solution of value $S$ such that $S \\le (1+\\epsilon) \\cdot OPT$, where $OPT$ is the value of the optimal solution.\n\nA solution that is $2\\%$ longer than the optimal one can be expressed as $OPT + 0.02 \\cdot OPT = 1.02 \\cdot OPT$.\nTherefore, we can set the approximation guarantee factor $(1+\\epsilon)$ equal to $1.02$.\n$$1 + \\epsilon = 1.02$$\nSolving for the error tolerance $\\epsilon$, we find:\n$$\\epsilon = 1.02 - 1 = 0.02$$\n\nNow we have all the necessary values to calculate the number of elementary operations using the given time complexity function $T(n, \\epsilon)$.\nWe substitute $n=60$, $c=10^5$, and $\\epsilon=0.02$ into the formula $T(n, \\epsilon) = c \\cdot n^{1/\\epsilon}$.\n\nFirst, let's calculate the exponent $1/\\epsilon$:\n$$\\frac{1}{\\epsilon} = \\frac{1}{0.02} = 50$$\n\nNow, substitute this exponent and the other values into the function $T$:\n$$T(60, 0.02) = 10^5 \\cdot 60^{50}$$\n\nThis is a very large number, so we must use logarithms to handle it and express it in scientific notation. We want to find a value $T$ such that $T = A \\times 10^k$, where $1 \\le A  10$.\nLet's take the base-10 logarithm of the expression:\n$$\\log_{10}(T) = \\log_{10}(10^5 \\cdot 60^{50})$$\nUsing the logarithm property $\\log(ab) = \\log(a) + \\log(b)$:\n$$\\log_{10}(T) = \\log_{10}(10^5) + \\log_{10}(60^{50})$$\nUsing the logarithm properties $\\log(x^y) = y\\log(x)$ and $\\log_{10}(10^z) = z$:\n$$\\log_{10}(T) = 5 + 50 \\cdot \\log_{10}(60)$$\nWe can approximate $\\log_{10}(60)$:\n$$\\log_{10}(60) = \\log_{10}(6 \\times 10) = \\log_{10}(6) + \\log_{10}(10) = \\log_{10}(2 \\times 3) + 1 = \\log_{10}(2) + \\log_{10}(3) + 1$$\nUsing standard approximations for $\\log_{10}(2) \\approx 0.30103$ and $\\log_{10}(3) \\approx 0.47712$:\n$$\\log_{10}(60) \\approx 0.30103 + 0.47712 + 1 = 1.77815$$\nNow we substitute this back into the expression for $\\log_{10}(T)$:\n$$\\log_{10}(T) = 5 + 50 \\cdot (1.77815)$$\n$$\\log_{10}(T) = 5 + 88.9075$$\n$$\\log_{10}(T) = 93.9075$$\nThis means that $T = 10^{93.9075}$. To write this in scientific notation, we separate the integer and fractional parts of the exponent:\n$$T = 10^{0.9075} \\times 10^{93}$$\nNow we calculate the value of the mantissa, $10^{0.9075}$:\n$$10^{0.9075} \\approx 8.0814$$\nSo, the total number of operations is approximately:\n$$T \\approx 8.0814 \\times 10^{93}$$\nThe problem requires the answer to be rounded to three significant figures.\n$$T \\approx 8.08 \\times 10^{93}$$\nThis astronomically large number illustrates the practical challenge of using such a PTAS, even for moderately sized inputs and seemingly lenient accuracy requirements. Although the algorithm is \"polynomial time\" for a fixed $\\epsilon$, the degree of the polynomial, $1/\\epsilon$, makes it computationally infeasible.",
            "answer": "$$\\boxed{8.08 \\times 10^{93}}$$"
        },
        {
            "introduction": "Having seen how to classify and evaluate approximation schemes, it's time to build one. This problem guides you through the process of constructing an FPTAS for the Maximum Weight Independent Set problem on a path graph . You will apply the powerful technique of scaling and rounding, which transforms a problem with large numerical weights into one that can be solved efficiently with dynamic programming, all while maintaining a provable approximation guarantee. This practice encapsulates the creative core of designing efficient approximation algorithms.",
            "id": "1425213",
            "problem": "A path graph $P_n$ is defined on a set of $n$ vertices $V = \\{v_1, v_2, \\ldots, v_n\\}$, with edges $E = \\{(v_i, v_{i+1}) \\mid 1 \\le i  n\\}$. Each vertex $v_i$ is assigned a positive integer weight $w_i > 0$.\n\nAn *independent set* is a subset of vertices $I \\subseteq V$ where no two vertices in $I$ are adjacent. The weight of an independent set $I$ is the sum of the weights of its vertices, $W(I) = \\sum_{v_i \\in I} w_i$. The *Maximum Weight Independent Set (MWIS)* problem seeks to find an independent set with the maximum possible weight, denoted as $W^*$.\n\nAn algorithm is a *Fully Polynomial-Time Approximation Scheme (FPTAS)* for a maximization problem if, for any given error parameter $\\epsilon > 0$, it produces a solution with weight $W_{sol}$ satisfying $W_{sol} \\ge (1-\\epsilon)W^*$, and its running time is polynomial in both the input size and $1/\\epsilon$.\n\nConsider an algorithmic strategy for the MWIS problem on a path graph that proceeds as follows:\n1. All original vertex weights $w_i$ are transformed into new integer weights $w'_i$ through a process of scaling and rounding.\n2. An exact algorithm is then used to find the maximum weight independent set for the problem instance with the new weights $w'_i$.\n3. The independent set found in step 2 is returned as the approximate solution to the original problem.\n\nYour task is to fully specify this strategy to create a valid FPTAS. This involves defining the scaling transformation and selecting an appropriate exact algorithm for the scaled problem. Based on your design, determine the function $f(n, \\epsilon)$ such that the overall running time of your FPTAS is $O(f(n, \\epsilon))$. Assume that $n \\ge 2$ and $0  \\epsilon \\le 1$.",
            "solution": "Let $P_{n}$ be the path on vertices $v_{1},\\ldots,v_{n}$ with positive integer weights $w_{1},\\ldots,w_{n}$. Let $W^{*}$ be the optimal MWIS weight. To construct an FPTAS following the stated strategy, proceed as follows.\n\nScaling and rounding. Let $W_{\\max}=\\max_{1\\le i\\le n}w_{i}$. For a given $\\epsilon\\in(0,1]$, define the scaling factor\n$$\nK=\\frac{\\epsilon W_{\\max}}{n}.\n$$\nDefine scaled integer weights by\n$$\nw'_{i}=\\left\\lfloor \\frac{w_{i}}{K}\\right\\rfloor \\quad \\text{for } i=1,\\ldots,n.\n$$\nBy construction, for each $i$,\n$$\nK\\,w'_{i}\\le w_{i}K\\,(w'_{i}+1).\n$$\n\nExact algorithm on the scaled instance. Use a dynamic program over the scaled weight sum. Let $S=\\sum_{i=1}^{n}w'_{i}$. Define a boolean table $C[i,s]$ for $i\\in\\{0,1,\\ldots,n\\}$ and $s\\in\\{0,1,\\ldots,S\\}$ with the meaning: $C[i,s]$ is true if and only if there exists an independent set contained in $\\{v_{1},\\ldots,v_{i}\\}$ whose total scaled weight equals $s$. Initialize\n$$\nC[0,0]=\\text{true},\\quad C[0,s]=\\text{false}\\ \\text{for }s>0.\n$$\nFor $i=1$,\n$$\nC[1,s]=\\big(C[0,s]\\big)\\ \\lor\\ \\big(s=w'_{1}\\big).\n$$\nFor $i\\ge 2$, use the recurrence\n$$\nC[i,s]=C[i-1,s]\\ \\lor\\ \\big(s\\ge w'_{i}\\ \\land\\ C[i-2,\\,s-w'_{i}]\\big).\n$$\nAfter filling the table, let\n$$\ns^{*}=\\max\\{\\,s\\in\\{0,\\ldots,S\\}\\mid C[n,s]=\\text{true}\\,\\}.\n$$\nRecover an independent set $I'$ attaining $s^{*}$ by standard backtracking using the recurrence decisions. This $I'$ is an exact optimal MWIS for the scaled instance with weights $w'_{i}$.\n\nApproximation guarantee. Let $I^{*}$ be an optimal MWIS for the original instance with weight $W^{*}=\\sum_{i\\in I^{*}}w_{i}$. From $w'_{i}\\ge \\frac{w_{i}}{K}-1$, summing over $i\\in I^{*}$ gives\n$$\n\\sum_{i\\in I^{*}}w'_{i}\\ge \\frac{1}{K}\\sum_{i\\in I^{*}}w_{i}-|I^{*}|=\\frac{W^{*}}{K}-|I^{*}|.\n$$\nSince $I'$ maximizes the scaled sum, we have $\\sum_{i\\in I'}w'_{i}\\ge \\sum_{i\\in I^{*}}w'_{i}\\ge \\frac{W^{*}}{K}-|I^{*}|$. Using $w_{i}\\ge K\\,w'_{i}$ for each $i$,\n$$\nW(I')=\\sum_{i\\in I'}w_{i}\\ge K\\sum_{i\\in I'}w'_{i}\\ge K\\left(\\frac{W^{*}}{K}-|I^{*}|\\right)=W^{*}-K\\,|I^{*}|.\n$$\nBecause $|I^{*}|\\le n$ and $K=\\frac{\\epsilon W_{\\max}}{n}$ with $W^{*}\\ge W_{\\max}$, it follows that\n$$\nK\\,|I^{*}|\\le n\\cdot\\frac{\\epsilon W_{\\max}}{n}=\\epsilon W_{\\max}\\le \\epsilon W^{*},\n$$\nhence\n$$\nW(I')\\ge W^{*}-\\epsilon W^{*}=(1-\\epsilon)W^{*}.\n$$\nThus the algorithm achieves the required approximation ratio.\n\nRunning time. Computing $W_{\\max}$ and all $w'_{i}$ takes $O(n)$ time. The DP table has size $O(nS)$ and is filled in $O(nS)$ time. Bound $S$ by\n$$\nS=\\sum_{i=1}^{n}w'_{i}\\le \\sum_{i=1}^{n}\\frac{w_{i}}{K}=\\frac{1}{K}\\sum_{i=1}^{n}w_{i}\\le \\frac{nW_{\\max}}{K}=\\frac{nW_{\\max}}{\\epsilon W_{\\max}/n}=\\frac{n^{2}}{\\epsilon}.\n$$\nTherefore the total running time is $O\\!\\left(nS\\right)=O\\!\\left(\\frac{n^{3}}{\\epsilon}\\right)$, which is polynomial in both $n$ and $\\frac{1}{\\epsilon}$. Hence an admissible choice is $f(n,\\epsilon)=\\frac{n^{3}}{\\epsilon}$.",
            "answer": "$$\\boxed{\\frac{n^{3}}{\\epsilon}}$$"
        }
    ]
}