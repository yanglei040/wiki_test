{
    "hands_on_practices": [
        {
            "introduction": "在理论和实践中，我们很少能接触到完美的随机源。更常见的是“弱随机源”，其输出虽然具有不确定性，但并非均匀分布。为了在密码学和算法设计中安全地使用这些源，我们首先需要一种量化其“随机性”的方法。最小熵（min-entropy）正是为此而生的度量标准，它衡量了最坏情况下源的可预测性。通过解决一个关于“比特固定源”的具体问题 ，我们将亲手计算最小熵，从而直观地理解它如何捕捉一个源所含的真正随机性。",
            "id": "1441918",
            "problem": "在计算复杂性和密码学的研究中，我们经常分析不完美的随机源。其中一种模型是“位固定源”。\n\n考虑一个生成$n$位二进制字符串的源。已知该源部分受损：一个特定的包含$t$个比特的位置集总是固定为值0，而其余的$n-t$个比特位置是独立且均匀随机选择的（即，这$n-t$个比特中的每一个以$1/2$的概率为0，以$1/2$的概率为1）。\n\n随机源的质量可以通过其最小熵来衡量。对于一个从可能结果集$\\Omega$中取值的随机变量$X$，其最小熵（记为$H_{\\infty}(X)$）定义为：\n$$H_{\\infty}(X) = -\\log_{2}\\left(\\max_{x \\in \\Omega} P(X=x)\\right)$$\n其中$P(X=x)$是特定结果$x$的概率。\n\n假设一个特定的位固定源生成$n=128$位的字符串，其中$t=20$个比特位置是固定的。请计算该源的最小熵。",
            "solution": "设$X$为代表该源生成的$n$位字符串的随机变量。所有可能结果的集合记为$\\Omega$。\n\n该源生成$n$位字符串，其中$t$位是固定的，而$n-t$位是随机的。随机位是独立且均匀选择的。这意味着对于$n-t$个非固定位置中的每一个，都有两种等可能性的情况（0或1）。\n\n该源可以产生的不同字符串的总数由随机部分的组合数决定，即$2^{n-t}$。因此，样本空间的大小为$|\\Omega| = 2^{n-t}$。\n\n由于这$n-t$个比特是均匀随机选择的，因此该源可以生成的每个可能字符串都是等可能的。任何特定结果$x \\in \\Omega$的概率由下式给出：\n$$P(X=x) = \\frac{1}{\\text{Total number of possible outcomes}} = \\frac{1}{|\\Omega|} = \\frac{1}{2^{n-t}}$$\n\n最小熵的定义要求我们找到所有可能结果中的最大概率。由于所有结果都是等可能的，因此最大概率与任何单个结果的概率相同：\n$$\\max_{x \\in \\Omega} P(X=x) = \\frac{1}{2^{n-t}}$$\n\n现在我们将这个最大概率代入最小熵的公式中：\n$$H_{\\infty}(X) = -\\log_{2}\\left(\\max_{x \\in \\Omega} P(X=x)\\right)$$\n$$H_{\\infty}(X) = -\\log_{2}\\left(\\frac{1}{2^{n-t}}\\right)$$\n\n使用对数性质$\\log(1/a) = -\\log(a)$，我们得到：\n$$H_{\\infty}(X) = - \\left(-\\log_{2}\\left(2^{n-t}\\right)\\right)$$\n$$H_{\\infty}(X) = \\log_{2}\\left(2^{n-t}\\right)$$\n\n使用性质$\\log_b(b^y) = y$，我们可以将其简化为：\n$$H_{\\infty}(X) = n-t$$\n\n题目给出了数值$n=128$和$t=20$。我们可以将这些值代入我们推导出的表达式中：\n$$H_{\\infty}(X) = 128 - 20 = 108$$\n\n因此，该源的最小熵为108。",
            "answer": "$$\\boxed{108}$$"
        },
        {
            "introduction": "随机性提取器的目标是将弱随机源转换为接近理想均匀分布的输出。但我们如何精确地衡量“接近”程度呢？统计距离（statistical distance）为我们提供了答案，它量化了两个概率分布之间的差异。这个练习  将通过一个简单的场景，让你计算一个有缺陷的随机数生成器与其理想版本之间的统计距离，从而让你对提取器安全定义中的误差参数 $\\epsilon$ 建立起坚实的直觉。",
            "id": "1441905",
            "problem": "在密码学和计算复杂性领域，随机源的质量至关重要。量化一个现实世界中不完美的随机源与一个真正均匀的随机源之间差异的常用方法是计算它们的统计距离。\n\n考虑一个设计用于生成2位整数的简单随机数生成器。该生成器的一个理想版本会以等概率产生集合 $\\{0, 1, 2, 3\\}$ 中的四个可能结果。设这个理想的概率分布记为 $U$。\n\n该生成器的一个特定物理实现被发现是有缺陷的。分析表明，在所有试验中，结果 $0$ 恰好出现了一半。观察到另外三个结果 $\\{1, 2, 3\\}$ 在剩余的试验中以相等的频率出现。设这个有缺陷的概率分布记为 $X$。\n\n在同一有限样本空间 $\\Omega$ 上的两个离散概率分布 $P$ 和 $Q$ 之间的统计距离 $\\Delta(P, Q)$ 定义为：\n$$ \\Delta(P, Q) = \\frac{1}{2} \\sum_{\\omega \\in \\Omega} |P(\\omega) - Q(\\omega)| $$\n\n计算理想分布 $U$ 和有缺陷的分布 $X$ 之间的统计距离 $\\Delta(U, X)$。将答案表示为精确分数。",
            "solution": "我们考虑有限样本空间 $\\Omega=\\{0,1,2,3\\}$。理想分布 $U$ 对每个 $\\omega\\in\\Omega$ 都设定 $U(\\omega)=\\frac{1}{4}$。有缺陷的分布 $X$ 具有 $X(0)=\\frac{1}{2}$，并且由于剩余的概率质量 $\\frac{1}{2}$ 在 $\\{1,2,3\\}$ 中平均分配，我们有 $X(1)=X(2)=X(3)=\\frac{1}{6}$。\n\n根据定义，统计距离为\n$$\n\\Delta(U,X)=\\frac{1}{2}\\sum_{\\omega\\in\\Omega}\\left|U(\\omega)-X(\\omega)\\right|.\n$$\n我们逐项计算绝对差：\n$$\n|U(0)-X(0)|=\\left|\\frac{1}{4}-\\frac{1}{2}\\right|=\\frac{1}{4},\n$$\n并且对于每个 $i\\in\\{1,2,3\\}$，\n$$\n|U(i)-X(i)|=\\left|\\frac{1}{4}-\\frac{1}{6}\\right|=\\left|\\frac{3-2}{12}\\right|=\\frac{1}{12}.\n$$\n将这四项相加得到\n$$\n\\sum_{\\omega\\in\\Omega}\\left|U(\\omega)-X(\\omega)\\right|=\\frac{1}{4}+3\\cdot\\frac{1}{12}=\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}.\n$$\n因此，\n$$\n\\Delta(U,X)=\\frac{1}{2}\\cdot\\frac{1}{2}=\\frac{1}{4}.\n$$",
            "answer": "$$\\boxed{\\frac{1}{4}}$$"
        },
        {
            "introduction": "一个随机性提取器的安全性由其能够处理的最小熵 $k$ 和其输出与均匀分布的统计距离误差 $\\epsilon$ 共同定义。虽然一个极小的 $\\epsilon$ 值意味着高度的安全性，但一个“较大”的 $\\epsilon$ 值意味着什么呢？这个思想实验  探讨了一个临界情况：当 $\\epsilon = 1/2$ 时。通过分析这种情况，你将发现为什么这样的提取器在密码学上是完全无用的，并深刻理解统计距离作为安全度量的实际意义。",
            "id": "1441851",
            "problem": "在密码学领域，一次性密码本需要一个真正随机且与消息本身等长的密钥。在实践中，完美的随机性是稀缺的，因此密码学家依赖随机性提取器从较弱的、有偏的源中提纯出高质量的随机比特。\n\n随机性提取器是一个函数 `Ext`，它接收一个弱随机源 `X` 和一个简短的、真正随机的种子 `S` 作为输入，生成一个在统计上接近均匀分布的输出。形式上，一个函数 $Ext: \\{0,1\\}^n \\times \\{0,1\\}^d \\to \\{0,1\\}^m$ 是一个 **强 $(k, \\epsilon)$-最小熵提取器**，如果对于任意定义在 $\\{0,1\\}^n$ 上且最小熵 $H_\\infty(X) \\ge k$ 的随机变量 $X$，其联合分布 $(S, Ext(X,S))$ 与均匀分布 $(U_d, U_m)$ 的统计距离是 $\\epsilon$-接近的。其中 $S$ 是来自 $U_d$ 的均匀种子，$U_m$ 是 $m$ 比特串上的均匀分布。最小熵 $H_\\infty(X) = - \\log_2(\\max_x \\Pr[X=x])$ 衡量了源 $X$ 的不可预测性。两个在集合 $\\mathcal{Z}$ 上的分布 $P_1$ 和 $P_2$ 之间的统计距离定义为 $\\Delta(P_1, P_2) = \\frac{1}{2}\\sum_{z \\in \\mathcal{Z}} |P_1(z) - P_2(z)|$。\n\n一家初创公司声称他们开发了一种新型硬件设备，可作为一个强 $(k, \\epsilon)$-最小熵提取器，适用于某个较大的最小熵 $k$。然而，在他们的技术规格中，他们声明其提取器的统计距离误差为 $\\epsilon = 1/2$。一位安全分析师立即否定了该设备，认为它对于生成一次性密码本等应用在密码学上是无用的。\n\n下列哪个陈述提供了最准确和最根本的原因，来解释为什么一个误差为 $\\epsilon = 1/2$ 的提取器被认为对于密码学目的是完全无用的？\n\nA. 误差 $\\epsilon = 1/2$ 意味着提取器在恰好一半的时间里无法产生有效的输出字符串，使其不可靠。\n\nB. 它允许输出分布以一种易于与均匀分布区分的方式构成，例如至少有一个比特被固定为常数值，从而让攻击者获得重要信息。\n\nC. 任何具有非零误差 $\\epsilon > 0$ 的提取器在理论上都是不安全的；只有误差为 $\\epsilon=0$ 的完美提取器才能用于密码学。\n\nD. 误差 $\\epsilon = 1/2$ 意味着源的最小熵 $k$ 必须至少是输入长度 $n$ 的两倍，这在物理上是不可能的。\n\nE. 一个简单地输出随机种子 $S$ 的前 $m$ 个比特的平凡函数可以达到 $\\epsilon=1/2$ 的误差，这意味着该提取器没有提供任何实际的“提取”效益。",
            "solution": "我们回顾在同一有限空间 $\\mathcal{Z}$ 上，分布 $P$ 和 $Q$ 之间的统计距离的定义：\n$$\n\\Delta(P,Q)=\\frac{1}{2}\\sum_{z\\in\\mathcal{Z}}|P(z)-Q(z)|.\n$$\n一个强 $(k,\\epsilon)$-提取器要求，对于每个满足 $H_{\\infty}(X)\\ge k$ 的源 $X$，其联合分布 $(S,\\mathrm{Ext}(X,S))$ 与 $(U_{d},U_{m})$ 的统计距离最多为 $\\epsilon$。\n\n为了理解为什么 $\\epsilon=\\frac{1}{2}$ 在密码学上是无用的，考虑一个 $m$ 比特输出上的分布，其中一个比特是固定的，例如，第一个输出比特总是 $0$，而剩下的 $m-1$ 个比特是均匀的，并且独立于种子 $S$。令 $P$ 表示 $(S,Y)$ 的联合分布，其中 $S\\sim U_{d}$ 且 $Y$ 满足 $Y_{1}=0$ 和 $(Y_{2},\\dots,Y_{m})\\sim U_{m-1}$，并独立于 $S$。令 $Q$ 表示 $(U_{d},U_{m})$，即 $S\\sim U_{d}$ 且 $Y\\sim U_{m}$ 相互独立。\n\n直接计算 $\\Delta(P,Q)$。样本空间是序对 $(s,y)$，其中 $s\\in\\{0,1\\}^{d}$ 且 $y\\in\\{0,1\\}^{m}$。根据 $y_{1}=0$ 还是 $y_{1}=1$ 进行划分。\n- 如果 $y_{1}=0$，那么\n$$\nP(s,y)=2^{-d}2^{-(m-1)}=2^{-d-m+1},\\quad Q(s,y)=2^{-(d+m)}.\n$$\n每个这样的序对的绝对差是\n$$\n|P(s,y)-Q(s,y)|=2^{-d-m+1}-2^{-d-m}=2^{-d-m}.\n$$\n这样的序对有 $2^{d}\\cdot 2^{m-1}$ 个。\n- 如果 $y_{1}=1$，那么 $P(s,y)=0$ 而 $Q(s,y)=2^{-(d+m)}$，所以\n$$\n|P(s,y)-Q(s,y)|=2^{-(d+m)}.\n$$\n同样有 $2^{d}\\cdot 2^{m-1}$ 个这样的序对。\n\n将绝对差求和再除以二，我们得到\n$$\n\\Delta(P,Q)=\\frac{1}{2}\\left(2^{d}2^{m-1}\\cdot 2^{-(d+m)}+2^{d}2^{m-1}\\cdot 2^{-(d+m)}\\right)\n=\\frac{1}{2}\\left(2^{-1}+2^{-1}\\right)=\\frac{1}{2}.\n$$\n因此，一个输出中至少有一个固定比特的联合分布，与理想的 $(U_{d},U_{m})$ 分布的统计距离恰好为 $\\frac{1}{2}$。因此，$\\epsilon=\\frac{1}{2}$ 的误差容限并不能排除这样一种提取器：其输出确定性地泄露整整一个比特，并且能以 $\\frac{1}{2}$ 的优势轻易地与均匀分布区分开。这种泄露使得输出对于像一次性密码本这样的密码学任务变得无用，因为在这些任务中，即使是确定性地获知密钥的一个比特也是不可接受的。\n\n现在来评估各个选项：\n- A 是不正确的，因为 $\\epsilon$ 是一个统计距离上界，而不是失败概率。\n- B 是正确的：$\\epsilon=\\frac{1}{2}$ 允许输出分布具有明显的结构，例如一个固定的比特，这使其极易与均匀分布区分，并泄露了重要信息，如上文所示。\n- C 是不正确的：密码学可以容忍小的非零 $\\epsilon$，在信息论安全的环境中，安全性最多降低 $\\epsilon$。\n- D 是不正确的：$\\epsilon$ 并没有施加像 $k\\ge 2n$ 这样的约束。\n- E 不是根本原因，并且对于 $m>1$ 的情况通常是错误的；输出 $S$ 的前 $m$ 个比特的函数与独立分布的统计距离至少为 $1-2^{-m}$，对于 $m\\ge 2$ 的情况，该值超过 $\\frac{1}{2}$。\n\n因此，最准确和最根本的原因是，$\\epsilon=\\frac{1}{2}$ 允许输出具有易于检测的确定性结构（例如，一个固定的比特），从而使该提取器在密码学上变得无用。",
            "answer": "$$\\boxed{B}$$"
        }
    ]
}