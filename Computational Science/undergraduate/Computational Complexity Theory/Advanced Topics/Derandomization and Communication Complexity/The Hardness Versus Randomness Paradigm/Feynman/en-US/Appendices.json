{
    "hands_on_practices": [
        {
            "introduction": "Understanding the concept of a pseudorandom generator (PRG) begins with knowing how to \"break\" one. This exercise introduces the fundamental tools for this task: a statistical test designed to find a non-random pattern, and the \"distinguishing advantage,\" which quantifies its success. By analyzing a very simple, and intuitively flawed, generator, you'll gain a hands-on feel for how computational indistinguishability is formally defined and tested .",
            "id": "1457800",
            "problem": "In computational complexity theory, a Pseudorandom Generator (PRG) is an algorithm that stretches a short, truly random seed into a longer, pseudorandom string. Formally, a function $G: \\{0,1\\}^k \\to \\{0,1\\}^n$ with $n>k$ is a PRG if its output is \"computationally indistinguishable\" from a truly random string of length $n$. The variable $k$ is known as the security parameter.\n\nIndistinguishability is measured by a statistical test, which is any probabilistic polynomial-time algorithm $T$ that takes an $n$-bit string as input and outputs a single bit, 0 or 1. A test $T$ is said to \"break\" or \"distinguish\" the generator $G$ if it can tell the difference between the generator's output and a truly random string with a non-negligible advantage.\n\nThe advantage of a test $T$ against a generator $G$ is defined as:\n$$\n\\text{Adv}_G(T) = \\left| \\Pr_{s \\sim U_k}[T(G(s))=1] - \\Pr_{r \\sim U_n}[T(r)=1] \\right|\n$$\nwhere $s \\sim U_k$ means $s$ is a seed chosen uniformly at random from $\\{0,1\\}^k$, and $r \\sim U_n$ means $r$ is a string chosen uniformly at random from $\\{0,1\\}^n$.\n\nThe advantage is considered non-negligible if there exists a positive constant $c$ such that $\\text{Adv}_G(T) \\ge \\frac{1}{k^c}$ for all sufficiently large $k$. If the advantage shrinks faster than any inverse polynomial in $k$ (i.e., it is negligible), the test fails to break the generator.\n\nConsider a simple candidate generator, which we will call the \"Pad-with-Zero\" generator, $G_{PZ}: \\{0,1\\}^k \\to \\{0,1\\}^{k+1}$. For any $k$-bit seed $s \\in \\{0,1\\}^k$, the generator is defined as:\n$$\nG_{PZ}(s) = s \\circ 0\n$$\nwhere $\\circ$ denotes string concatenation. This generator simply appends a fixed bit '0' to the seed.\n\nWhich of the following statistical tests $T: \\{0,1\\}^{k+1} \\to \\{0,1\\}$ successfully breaks the $G_{PZ}$ generator by achieving a non-negligible advantage?\n\nA. On input $x \\in \\{0,1\\}^{k+1}$, $T(x)$ outputs 1 if the last bit of $x$ is 0, and outputs 0 otherwise.\n\nB. On input $x \\in \\{0,1\\}^{k+1}$, $T(x)$ outputs 1 if the Hamming weight of $x$ (the number of `1`s) is odd, and outputs 0 otherwise.\n\nC. On input $x \\in \\{0,1\\}^{k+1}$, $T(x)$ outputs 1 if the first bit of $x$ is 0, and outputs 0 otherwise.\n\nD. On input $x \\in \\{0,1\\}^{k+1}$, $T(x)$ outputs 1 if the Hamming weight of $x$ is less than or equal to $k/4$, and outputs 0 otherwise. Assume $k$ is a multiple of 4.",
            "solution": "We use the definition of distinguishing advantage\n$$\n\\text{Adv}_{G}(T)=\\left|\\Pr_{s \\sim U_{k}}[T(G(s))=1]-\\Pr_{r \\sim U_{k+1}}[T(r)=1]\\right|.\n$$\nFor the pad-with-zero generator $G_{PZ}(s)=s \\circ 0$, the output always has last bit equal to $0$, while the first $k$ bits are uniformly distributed as $s$.\n\nTest A: $T(x)$ outputs $1$ iff the last bit of $x$ is $0$.\nUnder $G_{PZ}$, the last bit is always $0$, hence\n$$\n\\Pr_{s \\sim U_{k}}[T(G_{PZ}(s))=1]=1.\n$$\nUnder uniform $r \\sim U_{k+1}$, the last bit is $0$ with probability $\\frac{1}{2}$, hence\n$$\n\\Pr_{r \\sim U_{k+1}}[T(r)=1]=\\frac{1}{2}.\n$$\nTherefore\n$$\n\\text{Adv}_{G_{PZ}}(T)=\\left|1-\\frac{1}{2}\\right|=\\frac{1}{2},\n$$\nwhich is a constant, hence non-negligible. Thus A breaks $G_{PZ}$.\n\nTest B: $T(x)$ outputs $1$ iff the Hamming weight of $x$ is odd.\nFor $G_{PZ}(s)=s \\circ 0$, the parity of the Hamming weight is the same as that of $s$, which is uniform; thus\n$$\n\\Pr_{s \\sim U_{k}}[T(G_{PZ}(s))=1]=\\frac{1}{2}.\n$$\nFor $r \\sim U_{k+1}$, parity is also balanced, so\n$$\n\\Pr_{r \\sim U_{k+1}}[T(r)=1]=\\frac{1}{2}.\n$$\nHence\n$$\n\\text{Adv}_{G_{PZ}}(T)=0,\n$$\nwhich is negligible. Thus B does not break $G_{PZ}$.\n\nTest C: $T(x)$ outputs $1$ iff the first bit of $x$ is $0$.\nFor $G_{PZ}(s)$, the first bit is the first bit of $s$, which is uniform, so\n$$\n\\Pr_{s \\sim U_{k}}[T(G_{PZ}(s))=1]=\\frac{1}{2}.\n$$\nFor $r \\sim U_{k+1}$, the first bit is also uniform, so\n$$\n\\Pr_{r \\sim U_{k+1}}[T(r)=1]=\\frac{1}{2}.\n$$\nThus\n$$\n\\text{Adv}_{G_{PZ}}(T)=0,\n$$\nwhich is negligible. Hence C does not break $G_{PZ}$.\n\nTest D: $T(x)$ outputs $1$ iff the Hamming weight of $x$ is less than or equal to $k/4$ (with $k$ a multiple of $4$).\nLet $Y \\sim \\text{Bin}(k,\\frac{1}{2})$ be the Hamming weight of $s$, and let $X \\sim \\text{Bin}(k+1,\\frac{1}{2})$ be the Hamming weight of $r$. Then\n$$\n\\Pr_{s \\sim U_{k}}[T(G_{PZ}(s))=1]=\\Pr[Y \\leq k/4].\n$$\nWrite $X=Y+B$ where $B \\sim \\text{Bernoulli}(\\frac{1}{2})$ is independent of $Y$ (the extra appended bit in uniform $r$). Then\n$$\n\\Pr_{r \\sim U_{k+1}}[T(r)=1]=\\Pr[X \\leq k/4]=\\frac{1}{2}\\Pr[Y \\leq k/4]+\\frac{1}{2}\\Pr[Y \\leq k/4 - 1].\n$$\nTherefore\n$$\n\\text{Adv}_{G_{PZ}}(T)=\\left|\\Pr[Y \\leq k/4]-\\left(\\frac{1}{2}\\Pr[Y \\leq k/4]+\\frac{1}{2}\\Pr[Y \\leq k/4 - 1]\\right)\\right|=\\frac{1}{2}\\Pr[Y=k/4].\n$$\nSince $Y \\sim \\text{Bin}(k,\\frac{1}{2})$ and $k/4$ is a constant fraction away from the mean $k/2$, the point probability satisfies\n$$\n\\Pr[Y=k/4] \\leq \\Pr[Y \\leq k/4] \\leq \\exp\\!\\left(-\\frac{k}{16}\\right)\n$$\nby the Chernoff bound with mean $\\mu=k/2$ and $\\delta=\\frac{1}{2}$. Hence\n$$\n\\text{Adv}_{G_{PZ}}(T) \\leq \\frac{1}{2}\\exp\\!\\left(-\\frac{k}{16}\\right),\n$$\nwhich is negligible. Thus D does not break $G_{PZ}$.\n\nConclusion: Only test A achieves a non-negligible advantage.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "While the distinguishing advantage is formally defined using probabilities, in a real-world setting it is often estimated from experimental data. This practice puts you in the role of an analyst evaluating a new PRG based on a large-scale statistical experiment . You will learn to translate raw experimental counts into a meaningful measure of a generator's security, bridging the gap between theoretical concepts and practical cryptanalysis.",
            "id": "1457819",
            "problem": "In the field of cryptography, a Pseudorandom Generator (PRG) is an algorithm that takes a short, truly random binary string, called a seed, and deterministically expands it into a much longer binary string that appears to be random. Let's denote a PRG as a function $G: \\{0,1\\}^n \\to \\{0,1\\}^m$, where $n$ is the seed length and $m$ is the output length, with $m > n$.\n\nA crucial security property of a PRG is its indistinguishability from a truly random source. To test this, one uses a 'distinguisher', which is an algorithm, often modeled as a boolean circuit, $C: \\{0,1\\}^m \\to \\{0,1\\}$. The circuit $C$ attempts to guess whether its input is from the PRG or from a truly random source. The 'distinguishing advantage' of the circuit $C$ against the generator $G$ is formally defined as the absolute difference between the probability that $C$ outputs '1' when given a truly random input, and the probability that $C$ outputs '1' when given an output from $G$ that was generated from a random seed.\n\nA cybersecurity analyst is tasked with evaluating a newly proposed PRG, let's call it $G_{new}$. To do this, they employ a specially designed distinguisher circuit, $C_{test}$. They perform a large-scale statistical experiment consisting of two parts:\n\n1.  In the first part of the experiment, they generate $1,500,000$ truly random strings of length $m$ and feed each one as input to the circuit $C_{test}$. They record that the circuit outputs '1' a total of $750,900$ times.\n2.  In the second part of the experiment, they generate $1,500,000$ truly random seeds of length $n$, apply the generator $G_{new}$ to each seed to produce $1,500,000$ pseudorandom strings, and feed each of these to the circuit $C_{test}$. In this case, they record that the circuit outputs '1' a total of $752,475$ times.\n\nBased on the results of this experiment, calculate the estimated distinguishing advantage of the circuit $C_{test}$ against the generator $G_{new}$. Express your answer as a decimal, rounded to three significant figures.",
            "solution": "The distinguishing advantage of a circuit $C$ against a generator $G$ is defined as\n$$\n\\Delta(C,G) = \\left|\\Pr_{X \\leftarrow U_{m}}[C(X)=1] - \\Pr_{s \\leftarrow U_{n}}[C(G(s))=1]\\right|.\n$$\nAn unbiased empirical estimate of this advantage from $N$ samples in each condition is obtained by replacing the probabilities with the corresponding sample proportions. With $N=1500000$ trials per condition, the empirical proportions are\n$$\n\\hat{p}_{U} = \\frac{750900}{1500000}, \\quad \\hat{p}_{G} = \\frac{752475}{1500000}.\n$$\nTherefore, the estimated distinguishing advantage is\n$$\n\\hat{\\Delta} = \\left|\\hat{p}_{U} - \\hat{p}_{G}\\right| = \\left|\\frac{750900 - 752475}{1500000}\\right| = \\frac{1575}{1500000} = 0.00105.\n$$\nRounded to three significant figures, this remains $0.00105$.",
            "answer": "$$\\boxed{0.00105}$$"
        },
        {
            "introduction": "A distribution of bits can possess some properties of true randomness without being truly random. This problem explores a common \"random-like\" property known as pairwise independence, where any two bits in the sequence are uniformly random and independent . By designing a statistical test involving three bits, you will discover the limitations of this property and understand why fooling more sophisticated adversaries requires generators with much stronger guarantees.",
            "id": "1457782",
            "problem": "In the field of computational complexity, a key challenge is to generate sequences of bits that appear random, even if they are produced by a deterministic process. These are known as pseudorandom bits.\n\nConsider a simple statistical analyzer designed to test the quality of 3-bit pseudorandom strings. For any given 3-bit string $x_1x_2x_3$, the analyzer computes the statistical covariance between two binary random variables, $A$ and $B$, defined as follows:\n-   The variable $A$ is 1 if the string is a palindrome (i.e., its first bit equals its third bit, $x_1 = x_3$), and 0 otherwise.\n-   The variable $B$ is the value of the middle bit, $x_2$.\n\nA particular pseudorandom generator is constructed to be \"pairwise independent\". It first generates two truly independent and uniformly random bits, $z_1$ and $z_2$. From these, it constructs a 3-bit string $y_1y_2y_3$ by setting $y_1 = z_1$, $y_2 = z_2$, and $y_3 = z_1 \\oplus z_2$, where $\\oplus$ denotes the exclusive OR (XOR) operation.\n\nYour task is to calculate the covariance, $Cov(A, B)$, for the 3-bit strings produced by this specific pseudorandom generator. Express your final answer as an exact fraction.",
            "solution": "Let $z_{1}$ and $z_{2}$ be independent and uniformly random bits. The generator outputs $y_{1}=z_{1}$, $y_{2}=z_{2}$, and $y_{3}=z_{1}\\oplus z_{2}$. Define $A$ as the indicator that the string is a palindrome, i.e., $A=1$ if and only if $y_{1}=y_{3}$, and define $B=y_{2}$.\n\nBy definition of $A$,\n$$\nA=1 \\iff y_{1}=y_{3} \\iff z_{1}=z_{1}\\oplus z_{2}.\n$$\nUsing the XOR identities $u\\oplus u=0$ and $u\\oplus 0=u$, we XOR both sides with $z_{1}$ to get\n$$\nz_{1}\\oplus z_{1}=z_{2} \\iff 0=z_{2}.\n$$\nHence $A=1$ if and only if $z_{2}=0$, and $A=0$ otherwise. Because $B=y_{2}=z_{2}$, it follows deterministically that\n$$\nA=1-B.\n$$\n\nWe compute the covariance using $\\operatorname{Cov}(A,B)=\\mathbb{E}[AB]-\\mathbb{E}[A]\\mathbb{E}[B]$. Since $A=1-B$,\n$$\nAB=B(1-B)=B-B^{2}.\n$$\nFor a binary variable $B\\in\\{0,1\\}$, we have $B^{2}=B$ pointwise, hence $AB=0$ almost surely and\n$$\n\\mathbb{E}[AB]=0.\n$$\nBecause $z_{2}$ is uniform, $\\mathbb{E}[B]=\\mathbb{P}(z_{2}=1)=\\frac{1}{2}$ and $\\mathbb{E}[A]=\\mathbb{P}(z_{2}=0)=\\frac{1}{2}$. Therefore,\n$$\n\\operatorname{Cov}(A,B)=0-\\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right)=-\\frac{1}{4}.\n$$",
            "answer": "$$\\boxed{-\\frac{1}{4}}$$"
        }
    ]
}