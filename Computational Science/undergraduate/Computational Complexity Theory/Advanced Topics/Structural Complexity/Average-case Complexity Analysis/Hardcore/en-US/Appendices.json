{
    "hands_on_practices": [
        {
            "introduction": "Average-case analysis often begins by applying the fundamental definition of expected value. This first exercise provides a clear, intuitive scenario—searching for an item in a grid—to practice this core skill. By assuming a uniform probability distribution for the item's location, we can directly calculate the average search cost, offering a foundational understanding of how to average performance over all possible inputs .",
            "id": "1413197",
            "problem": "A simple image processing algorithm is designed to locate a specific 'marker' pixel within a square digital image. The image is represented as an $n \\times n$ grid of pixels. The algorithm searches for the marker by scanning the pixels one by one, starting from the top-left corner (row 1, column 1), proceeding left-to-right across each row, and then moving to the next row. The search terminates immediately once the marker pixel is found.\n\nAssume that for any given search operation, the marker pixel is guaranteed to be present in the image. Furthermore, the position of this marker pixel is uniformly distributed over all $n^2$ possible pixel locations.\n\nThe cost of the search is defined as the total number of pixels examined by the algorithm. For instance, if the marker is at row $i$ and column $j$ (where indices start from 1), the algorithm examines all pixels in the first $i-1$ rows, and then the first $j$ pixels in row $i$.\n\nDetermine the average-case cost (the expected number of pixels examined) of this search algorithm as a function of the image dimension $n$.",
            "solution": "Let the image be an $n \\times n$ grid and let the marker be uniformly distributed over all $n^{2}$ pixel locations. Index rows and columns from $1$ to $n$. If the marker is at row $i$ and column $j$, the algorithm examines all pixels in the first $i-1$ rows and then the first $j$ pixels of row $i$. Therefore, the cost in this case is\n$$\nC(i,j)=n(i-1)+j.\n$$\nSince each $(i,j)$ is equally likely with probability $\\frac{1}{n^{2}}$, the expected cost is\n$$\n\\mathbb{E}[C]=\\sum_{i=1}^{n}\\sum_{j=1}^{n}\\frac{1}{n^{2}}\\left(n(i-1)+j\\right).\n$$\nCompute the inner sum over $j$:\n$$\n\\sum_{j=1}^{n}\\left(n(i-1)+j\\right)=n\\cdot n(i-1)+\\sum_{j=1}^{n}j=n^{2}(i-1)+\\frac{n(n+1)}{2}.\n$$\nNow sum over $i$:\n$$\n\\sum_{i=1}^{n}\\left[n^{2}(i-1)+\\frac{n(n+1)}{2}\\right]\n= n^{2}\\sum_{i=1}^{n}(i-1)+n\\cdot\\frac{n(n+1)}{2}\n= n^{2}\\cdot\\frac{n(n-1)}{2}+\\frac{n^{2}(n+1)}{2}.\n$$\nThus,\n$$\n\\mathbb{E}[C]=\\frac{1}{n^{2}}\\left[\\frac{n^{3}(n-1)}{2}+\\frac{n^{2}(n+1)}{2}\\right]\n=\\frac{1}{2n^{2}}\\left(n^{4}+n^{2}\\right)=\\frac{n^{2}+1}{2}.\n$$\nThis equals the average of the integers from $1$ to $n^{2}$, consistent with viewing the scan as a linear search over $n^{2}$ uniformly likely positions.",
            "answer": "$$\\boxed{\\frac{n^{2}+1}{2}}$$"
        },
        {
            "introduction": "For many algorithms, calculating the probability of every possible outcome can be cumbersome. A more powerful tool is the linearity of expectation, which allows us to find the expected value of a sum of random variables by summing their individual expected values. This problem, involving the comparison of two random strings, demonstrates how to use indicator variables to elegantly determine the average number of steps before a process terminates .",
            "id": "1413198",
            "problem": "A simplified data integrity verification algorithm is used to compare a received binary string, $A$, with a locally-stored master string, $B$. Both strings are of length $n$. The algorithm operates by comparing the bits of the strings sequentially, starting from the first position ($i=1$) and proceeding towards the last ($i=n$). The process terminates immediately if a mismatch is found (i.e., at the first index $i$ where $A_i \\neq B_i$). If the entire comparison completes without any mismatches, meaning the strings are identical, the process also terminates after the $n$-th comparison.\n\nAssume that both strings are generated randomly, where each bit in each string is independently chosen to be a '0' or a '1' with equal probability of $\\frac{1}{2}$.\n\nDetermine the average number of bit comparisons the algorithm performs. Express your answer as a closed-form analytic expression in terms of $n$.",
            "solution": "Let $C$ be the number of comparisons performed. Define indicator variables $I_{i}$ for $i \\in \\{1,\\dots,n\\}$ by $I_{i}=1$ if the $i$-th comparison is performed and $I_{i}=0$ otherwise. Then\n$$\nC=\\sum_{i=1}^{n} I_{i}.\n$$\nBy linearity of expectation,\n$$\n\\mathbb{E}[C]=\\sum_{i=1}^{n} \\mathbb{E}[I_{i}]=\\sum_{i=1}^{n} \\mathbb{P}(I_{i}=1).\n$$\nThe $i$-th comparison is performed if and only if there is no mismatch among the first $i-1$ positions. For each position, the pair of bits matches with probability $\\frac{1}{2}$, independently across positions. Hence\n$$\n\\mathbb{P}(I_{i}=1)=\\left(\\frac{1}{2}\\right)^{i-1}.\n$$\nTherefore,\n$$\n\\mathbb{E}[C]=\\sum_{i=1}^{n}\\left(\\frac{1}{2}\\right)^{i-1}=\\frac{1-\\left(\\frac{1}{2}\\right)^{n}}{1-\\frac{1}{2}}=2\\left(1-2^{-n}\\right)=2-2^{1-n}.\n$$\nThis is the desired closed-form expression in terms of $n$.",
            "answer": "$$\\boxed{2-2^{1-n}}$$"
        },
        {
            "introduction": "This practice explores a classic problem in computer science with direct applications in hashing, data integrity, and cryptography: the \"Birthday Problem.\" It asks for the expected number of random selections before a value is repeated. The solution introduces another essential technique for calculating expectation, the tail-sum formula, which is particularly useful for analyzing the \"waiting time\" for an event to occur .",
            "id": "1413201",
            "problem": "A simplified system for generating a batch of unique cryptographic nonces works as follows. The system has a pool of $n$ possible nonce values, represented by the set of integers $\\{1, 2, \\dots, n\\}$. It generates a sequence of nonces by drawing values one at a time from this set, with each draw being independent and uniformly random (i.e., sampling with replacement).\n\nThe system is designed to halt as soon as it generates a nonce that has already appeared in the current sequence. This event is called a \"collision.\"\n\nLet $E_n$ be the expected number of nonces generated in a sequence, *including* the final nonce that causes the collision. Determine an analytic expression for $E_n$ as a function of $n$.",
            "solution": "Let $T$ denote the number of generated nonces up to and including the first collision. Since the draws are i.i.d. uniform on $\\{1,2,\\dots,n\\}$ with replacement, the process stops at the first time a drawn value repeats a previous one.\n\nFor $k \\in \\{0,1,\\dots,n\\}$, the event $\\{T>k\\}$ means that the first $k$ draws are all distinct. The probability that the first $k$ draws are distinct is obtained by multiplying conditional probabilities:\n$$\n\\mathbb{P}(T>k)=\\prod_{j=0}^{k-1}\\frac{n-j}{n}=\\frac{n(n-1)\\cdots(n-k+1)}{n^{k}}=\\frac{n^{\\underline{k}}}{n^{k}}=\\frac{n!}{(n-k)!\\,n^{k}}.\n$$\nFor $k=n+1$, $\\mathbb{P}(T>k)=0$ because one cannot have $n+1$ distinct draws from a set of size $n$.\n\nUsing the tail-sum formula for a positive integer-valued random variable,\n$$\nE_{n}=\\mathbb{E}[T]=\\sum_{k=0}^{\\infty}\\mathbb{P}(T>k)=\\sum_{k=0}^{n}\\mathbb{P}(T>k)=\\sum_{k=0}^{n}\\frac{n!}{(n-k)!\\,n^{k}}.\n$$\nThis equals the desired expected number of nonces generated, including the final colliding nonce.",
            "answer": "$$\\boxed{\\sum_{k=0}^{n}\\frac{n!}{(n-k)!\\,n^{k}}}$$"
        }
    ]
}