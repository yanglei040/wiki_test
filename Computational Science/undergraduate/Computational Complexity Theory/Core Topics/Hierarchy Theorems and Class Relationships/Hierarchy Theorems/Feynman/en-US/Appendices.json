{
    "hands_on_practices": [
        {
            "introduction": "The Time Hierarchy Theorem tells us that with more time, we can solve more problems. A direct corollary is that $\\mathrm{DTIME}(n^a) \\subsetneq \\mathrm{DTIME}(n^b)$ for $1 \\le a < b$. This exercise challenges a common misinterpretation of this statement, forcing you to think carefully about what the \"proper subset\" symbol ($\\subsetneq$) truly means in the context of complexity classes ``. It is crucial for understanding that a hierarchy is a series of increasingly larger sets, not a collection of disjoint ones.",
            "id": "1426881",
            "problem": "In computational complexity theory, $\\mathrm{DTIME}(t(n))$ denotes the class of all decision problems that can be solved by a deterministic Turing machine in worst-case time $O(t(n))$, where $n$ is the length of the input. The Time Hierarchy Theorem for deterministic computation states that for any two time-constructible functions $t_1(n)$ and $t_2(n)$ such that $t_1(n) \\log t_1(n) = o(t_2(n))$, the class $\\mathrm{DTIME}(t_1(n))$ is a proper subset of $\\mathrm{DTIME}(t_2(n))$, written as $\\mathrm{DTIME}(t_1(n)) \\subsetneq \\mathrm{DTIME}(t_2(n))$. A common corollary is that for any real numbers $1 \\le a < b$, we have $\\mathrm{DTIME}(n^a) \\subsetneq \\mathrm{DTIME}(n^b)$.\n\nNow, consider a hypothetical decision problem, let's call it $L$. It is known that for any integer $k \\ge 2$, the problem $L$ is in the class $\\mathrm{DTIME}(n^k)$. A student argues that this situation creates a paradox. For instance, by choosing $a=2$ and $b=3$, the theorem says $\\mathrm{DTIME}(n^2) \\subsetneq \\mathrm{DTIME}(n^3)$, implying there should be a separation between problems solvable in quadratic time and those solvable in cubic time. However, problem $L$ is in both $\\mathrm{DTIME}(n^2)$ and $\\mathrm{DTIME}(n^3)$, which seems to contradict the theorem.\n\nWhich of the following statements correctly explains why the existence of such a problem $L$ does not contradict the Time Hierarchy Theorem?\n\nA. The statement $\\mathrm{DTIME}(n^a) \\subsetneq \\mathrm{DTIME}(n^b)$ means that $\\mathrm{DTIME}(n^a)$ is a subset of $\\mathrm{DTIME}(n^b)$, and there exists at least one problem in $\\mathrm{DTIME}(n^b)$ that is not in $\\mathrm{DTIME}(n^a)$. The existence of problem $L$, which belongs to $\\mathrm{DTIME}(n^2)$ and therefore to all $\\mathrm{DTIME}(n^k)$ for $k > 2$, does not contradict this.\n\nB. The Time Hierarchy Theorem is not applicable here because the functions $t(n)=n^k$ are not time-constructible.\n\nC. The Time Hierarchy Theorem only establishes hierarchies for complexity classes containing problems that are proven to be intractable, such as EXPTIME-complete problems. It does not apply to polynomial-time classes.\n\nD. The student is correct; the existence of such a problem $L$ would indeed violate the Time Hierarchy Theorem, indicating that the premise must be impossible. No such problem $L$ can exist.\n\nE. The theorem is a statement about non-deterministic time classes ($\\mathrm{NTIME}$), not deterministic time classes ($\\mathrm{DTIME}$), so it cannot be applied to a problem solved by a deterministic algorithm.\n\nF. The property of problem $L$ implies it belongs to the complexity class $\\mathrm{P}$. The Time Hierarchy Theorem's main result is that $\\mathrm{P} \\subsetneq \\mathrm{EXP}$, which is a different, unrelated hierarchy.",
            "solution": "We restate the deterministic Time Hierarchy Theorem: if $t_{1}$ and $t_{2}$ are time-constructible and satisfy $t_{1}(n)\\log t_{1}(n)=o\\!\\left(t_{2}(n)\\right)$, then $\\mathrm{DTIME}(t_{1}(n))\\subsetneq \\mathrm{DTIME}(t_{2}(n))$. For $1\\le a<b$ and $t_{1}(n)=n^{a}$, $t_{2}(n)=n^{b}$, we have\n$$\nt_{1}(n)\\log t_{1}(n)=n^{a}\\log(n^{a})=a\\,n^{a}\\log n.\n$$\nSince $b>a$, we have $\\log n=o(n^{b-a})$, hence $a\\,n^{a}\\log n=o(n^{b})$. Polynomials are time-constructible, so the theorem applies and yields\n$$\n\\mathrm{DTIME}(n^{a})\\subsetneq \\mathrm{DTIME}(n^{b}).\n$$\n\nThe meaning of the proper subset $\\subsetneq$ is that there exists at least one language $L^{\\ast}$ in $\\mathrm{DTIME}(n^{b})$ that is not in $\\mathrm{DTIME}(n^{a})$. It does not mean the classes are disjoint. In fact, since $n^{a}=O(n^{b})$ for $b>a$, any language decidable in time $O(n^{a})$ is also decidable in time $O(n^{b})$, so\n$$\n\\mathrm{DTIME}(n^{a})\\subseteq \\mathrm{DTIME}(n^{b}),\n$$\nand the intersection equals $\\mathrm{DTIME}(n^{a})$.\n\nNow consider the given problem $L$ with the property that for every integer $k\\ge 2$, $L\\in \\mathrm{DTIME}(n^{k})$. In particular, $L\\in \\mathrm{DTIME}(n^{2})$ and $L\\in \\mathrm{DTIME}(n^{3})$. This is entirely consistent with the theorem: the theorem guarantees the existence of some language $L^{\\ast}\\in \\mathrm{DTIME}(n^{3})\\setminus \\mathrm{DTIME}(n^{2})$, but does not prohibit that many (indeed, infinitely many) languages lie in both classes. Thus, $L$ is simply not the separating witness.\n\nEvaluating the options:\n- A correctly explains that $\\subsetneq$ asserts existence of at least one separating language while allowing overlap; $L$ being in both classes is not a contradiction.\n- B is false: $n^{k}$ is time-constructible for integer $k\\ge 1$.\n- C is false: the theorem applies to deterministic time classes broadly, including polynomial bounds.\n- D is false: the existence of $L$ does not violate the theorem; classes are not disjoint.\n- E is false: the theorem stated is about deterministic time classes as well.\n- F is irrelevant and misleading: while $L\\in \\mathrm{P}$, this does not address the studentâ€™s misinterpretation; the polynomial-time hierarchy separation result is exactly an instance of the deterministic Time Hierarchy Theorem.\n\nTherefore, the correct explanation is A.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "After understanding what the Hierarchy Theorem states, the next step is applying it correctly. It can be tempting to think that any increase in a time bound is enough to create a new class of solvable problems. This practice `` presents a seemingly plausible but ultimately flawed attempt to separate $\\mathrm{DTIME}(n)$ from $\\mathrm{DTIME}(2n)$, highlighting the critical importance of the theorem's precise mathematical constraints, particularly the logarithmic factor in the separation condition.",
            "id": "1426909",
            "problem": "In computational complexity theory, the Time Hierarchy Theorems are a set of fundamental results that establish the existence of a rich structure of complexity classes. They demonstrate that with more time, a Turing machine can solve more problems. A standard version of the Deterministic Time Hierarchy Theorem is stated as follows:\n\n**Theorem (Deterministic Time Hierarchy):**\nLet $f(n)$ and $g(n)$ be functions from non-negative integers to non-negative integers. If $f(n)$ is a time-constructible function and $g(n)$ is a function such that $g(n) \\log g(n) = o(f(n))$, then $\\mathrm{DTIME}(g(n)) \\subsetneq \\mathrm{DTIME}(f(n))$.\n\nHere, a function $T(n)$ is called *time-constructible* if there exists a Turing machine that, given an input of size $n$, halts after exactly $T(n)$ computational steps. The notation $h(n) = o(k(n))$ (read as \"h(n) is little-o of k(n)\") means that for any positive constant $c$, there exists an integer $N$ such that $h(n) < c \\cdot k(n)$ for all $n > N$. This is formally equivalent to $\\lim_{n \\to \\infty} \\frac{h(n)}{k(n)} = 0$. The class $\\mathrm{DTIME}(T(n))$ represents all decision problems that can be solved by a deterministic Turing machine within $O(T(n))$ time. We can assume that simple functions like $n$ and $2n$ are time-constructible.\n\nAn undergraduate student, having just learned this theorem, attempts to use it to prove that $\\mathrm{DTIME}(n) \\neq \\mathrm{DTIME}(2n)$. The student's reasoning is to set $g(n)=n$ and $f(n)=2n$ and apply the theorem.\n\nWhich of the following options identifies the fundamental flaw in the student's attempt to apply the Time Hierarchy Theorem to this specific problem?\n\nA. The function $f(n) = 2n$ is not a time-constructible function.\n\nB. The Time Hierarchy Theorem is only valid for functions that are at least polynomial, and does not apply to linear functions like $n$ and $2n$.\n\nC. The condition that $g(n) \\log g(n) = o(f(n))$ is not satisfied for the chosen functions $g(n)=n$ and $f(n)=2n$.\n\nD. The Linear Speedup Theorem, which states $\\mathrm{DTIME}(T(n)) = \\mathrm{DTIME}(c \\cdot T(n))$ for constants $c>0$ and sufficiently large time bounds $T(n)$, makes the premise $\\mathrm{DTIME}(n) \\neq \\mathrm{DTIME}(2n)$ false, so any proof attempt is flawed.\n\nE. The theorem requires that both $f(n)$ and $g(n)$ are time-constructible, but the function $g(n)=n$ is not.",
            "solution": "We analyze the student's attempt to apply the Deterministic Time Hierarchy Theorem with the choices $g(n)=n$ and $f(n)=2n$. The theorem requires:\n1) $f(n)$ is time-constructible.\n2) $g(n)$ is time-constructible.\n3) The growth condition $g(n)\\log g(n)=o(f(n))$ holds.\n\nFirst, by standard facts in complexity theory, linear functions such as $n$ and $2n$ are time-constructible, so both $f(n)=2n$ and $g(n)=n$ satisfy time-constructibility. Thus options A and E are incorrect.\n\nSecond, the theorem does not exclude linear functions; it applies to any time-constructible functions meeting the little-o condition. Therefore option B is incorrect.\n\nThird, we check the crucial growth condition. Using the definition of little-o, $h(n)=o(k(n))$ if and only if $\\lim_{n\\to\\infty}\\frac{h(n)}{k(n)}=0$. Set $h(n)=g(n)\\log g(n)$ and $k(n)=f(n)$ with $g(n)=n$ and $f(n)=2n$. Then\n$$\n\\lim_{n\\to\\infty}\\frac{g(n)\\log g(n)}{f(n)}=\\lim_{n\\to\\infty}\\frac{n\\log n}{2n}=\\lim_{n\\to\\infty}\\frac{\\log n}{2}=+\\infty\\neq 0.\n$$\nHence $g(n)\\log g(n)\\neq o(f(n))$ for $g(n)=n$ and $f(n)=2n$, so the hypothesis of the theorem fails. This is the fundamental flaw in the student's application. Therefore option C is correct.\n\nFinally, while the Linear Speedup Theorem indeed implies that, for reasonable machine models and sufficiently large bounds, $\\mathrm{DTIME}(n)$ and $\\mathrm{DTIME}(2n)$ coincide, which makes the target conclusion $\\mathrm{DTIME}(n)\\neq \\mathrm{DTIME}(2n)$ untenable, the question asks for the fundamental flaw in applying the Time Hierarchy Theorem. That flaw is precisely the failure of the $g(n)\\log g(n)=o(f(n))$ condition, i.e., option C, not the broader observation in option D.",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "The conditions in the Hierarchy Theorems, such as the logarithmic factor, are not arbitrary; they arise directly from the proof technique itself. This final practice provides a glimpse into the elegant machinery of a diagonalization proof ``. By calculating the time required for a specially constructed machine to simulate and then \"disagree with\" any other machine from a given class, you will see firsthand how the overhead from simulation dictates the necessary gap between complexity classes.",
            "id": "1426854",
            "problem": "In the study of computational complexity, diagonalization is a powerful technique used to establish hierarchy theorems, which show that more computational resources allow for solving more problems. This problem explores the time complexity of a specific diagonalization construction for Alternating Turing Machines (ATMs). An ATM is a variant of a non-deterministic Turing machine with its states partitioned into existential and universal states.\n\nAssume a standard binary encoding scheme where any ATM $M$ can be uniquely represented by a string $\\langle M \\rangle$. We are provided with a special universal ATM, denoted as $U$. For any given ATM $M$ and an input string $w$, the machine $U$ can simulate the computation of $M$ on $w$. This simulation incurs a specific time overhead: if $M$ halts on an input of length $n$ in $T(n)$ steps, the simulation on $U$ requires $T_{sim}(n) = c \\cdot T(n) \\log_2(T(n))$ steps, where $c$ is a positive constant and all logarithms are base 2.\n\nNow, consider a carefully constructed ATM, which we will call $D$. The behavior of $D$ on an input string $x$ of length $n=|x|$ is as follows:\n1.  First, $D$ performs a check to determine if $x$ is a valid encoding of an ATM. This verification process takes exactly $n^2$ steps. If $x$ is not a valid encoding, $D$ halts and rejects.\n2.  If $x$ is a valid encoding of an ATM, which we denote as $M_x$, then $D$ uses the universal machine $U$ to simulate the execution of $M_x$ on the input string $x$ itself.\n3.  After the simulation of $M_x(x)$ is complete, $D$ inverts the result: if the simulation accepts, $D$ rejects; if the simulation rejects, $D$ accepts. This final inversion step takes a negligible constant number of steps.\n\nWe are applying this diagonalization argument to a specific class of polynomial-time ATMs. Every machine $M_x$ from this class (i.e., any machine for which $x = \\langle M_x \\rangle$ is a valid encoding) has a worst-case running time on an input of length $m$ that is bounded by the function $T_x(m) = m^{\\log_2(|\\langle M_x \\rangle|)}$.\n\nYour task is to determine the function $g(n)$ that represents the dominant term in the worst-case running time $T_D(n)$ of the machine $D$ on an input of length $n$, for large $n$. Express your answer as an analytic expression in terms of $n$ and the constant $c$.",
            "solution": "Let the input length be $n=|x|$.\n\n1) The encoding check costs exactly $n^{2}$ steps. If $x$ is not a valid encoding, $D$ halts and rejects at this point.\n\n2) For worst-case running time, consider the case where $x=\\langle M_{x}\\rangle$ is a valid encoding. By the given bound on the machines in the class, for any input length $m$, the running time of $M_{x}$ is\n$$\nT_{x}(m)=m^{\\log_{2}(|\\langle M_{x}\\rangle|)}.\n$$\nFor the self-input $m=n$ and $|\\langle M_{x}\\rangle|=n$, we obtain\n$$\nT_{x}(n)=n^{\\log_{2} n}.\n$$\n\n3) The universal ATM $U$ simulates $M_{x}$ with time overhead\n$$\nT_{\\text{sim}}(n)=c\\cdot T_{x}(n)\\cdot \\log_{2}\\!\\left(T_{x}(n)\\right).\n$$\nUsing the logarithm rule $\\log_{2}(a^{k})=k\\log_{2}(a)$, compute\n$$\n\\log_{2}\\!\\left(T_{x}(n)\\right)=\\log_{2}\\!\\left(n^{\\log_{2} n}\\right)=(\\log_{2} n)\\cdot \\log_{2} n=(\\log_{2} n)^{2}.\n$$\nThus,\n$$\nT_{\\text{sim}}(n)=c\\cdot n^{\\log_{2} n}\\cdot (\\log_{2} n)^{2}.\n$$\n\n4) The final inversion step is $O(1)$.\n\nTherefore, the total worst-case running time satisfies\n$$\nT_{D}(n)=n^{2}+c\\,n^{\\log_{2} n}(\\log_{2} n)^{2}+O(1).\n$$\nFor large $n$, note that $n^{\\log_{2} n}=2^{(\\log_{2} n)^{2}}$ grows faster than any polynomial $n^{k}$, so $c\\,n^{\\log_{2} n}(\\log_{2} n)^{2}$ dominates $n^{2}$. Hence, the dominant term is\n$$\ng(n)=c\\,n^{\\log_{2} n}(\\log_{2} n)^{2}.\n$$",
            "answer": "$$\\boxed{c\\,n^{\\log_{2} n}\\,(\\log_{2} n)^{2}}$$"
        }
    ]
}