{
    "hands_on_practices": [
        {
            "introduction": "Many important functions in science, like the error function $erf(z)$ that appears in diffusion problems and Gaussian orbital calculations, are defined by integrals that cannot be solved with a simple closed-form expression. Numerical quadrature, such as the trapezoidal rule, provides a powerful way to approximate these definite integrals. This practice () is fundamental for building an intuition for the accuracy and limitations of numerical integration by having you implement the trapezoidal rule and critically compare its results to both the true value and the theoretical error bound.",
            "id": "2459587",
            "problem": "Consider the error function $\\text{erf}(z)$ defined for real $z$ by\n$$\n\\text{erf}(z) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{z} e^{-t^{2}} \\, dt.\n$$\nThis special function appears widely in computational chemistry, for example in Gaussian orbital integrals and diffusion models involving normal distributions. Let $N$ denote a positive integer specifying the number of equal subintervals used to partition the integration interval.\n\nTask: Write a complete program that, for each test case $(z,N)$ listed below, computes an approximation $\\widehat{\\text{erf}}(z;N)$ using the composite trapezoidal rule applied to the integral definition above, and then:\n1. Computes the absolute error\n$$\nE_{\\text{abs}}(z,N) = \\left| \\text{erf}(z) - \\widehat{\\text{erf}}(z;N) \\right|.\n$$\n2. Computes the rigorous composite-trapezoidal error bound for this problem derived from the second derivative of the integrand, namely\n$$\nB(z,N) = \\frac{2}{\\sqrt{\\pi}} \\cdot \\frac{|z|}{12} \\left(\\frac{|z|}{N}\\right)^{2} \\cdot \\max_{t \\in [\\min(0,z), \\max(0,z)]} \\left| \\frac{d^{2}}{dt^{2}} e^{-t^{2}} \\right|.\n$$\nYour program must use the exact analytic value of the maximum. The test suite is:\n- $(z,N) = (0, 1)$,\n- $(z,N) = (0.5, 10)$,\n- $(z,N) = (1.0, 2)$,\n- $(z,N) = (1.0, 50)$,\n- $(z,N) = (2.0, 200)$,\n- $(z,N) = (-1.0, 50)$,\n- $(z,N) = (3.0, 400)$.\n\nAngle units do not apply. No physical units are involved. All real numbers used in the output must be written in scientific notation with $12$ significant digits.\n\nFinal output format: Your program should produce a single line of output consisting of a single list where each element corresponds to one test case in the same order as listed above, and each element is a two-element list $[E_{\\text{abs}}(z,N), B(z,N)]$. The outer list and each inner list must be written without any whitespace and using commas as separators. For example, the required structure is of the form $[[x_{1},y_{1}],[x_{2},y_{2}],\\ldots]$ where each $x_{k}$ and $y_{k}$ is a float in scientific notation with $12$ significant digits.",
            "solution": "The problem is valid. It presents a clear, well-posed task in numerical analysis that is scientifically grounded and relevant to computational chemistry. The necessary formulas are either provided or are standard, and the required calculations are feasible. I will now provide the solution.\n\nThe task requires the computation of two quantities for several test cases $(z,N)$: the absolute error $E_{\\text{abs}}(z,N)$ of a numerical approximation to the error function $\\text{erf}(z)$, and the corresponding theoretical error bound $B(z,N)$.\n\nThe error function is defined as:\n$$\n\\text{erf}(z) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{z} e^{-t^{2}} \\, dt\n$$\nThis is an odd function, meaning $\\text{erf}(-z) = -\\text{erf}(z)$. This property will be useful.\n\nFirst, we design the numerical approximation $\\widehat{\\text{erf}}(z;N)$ using the composite trapezoidal rule. The rule approximates an integral $\\int_{a}^{b} f(t) \\, dt$ using $N$ equal subintervals of width $h=(b-a)/N$ as:\n$$\n\\int_{a}^{b} f(t) \\, dt \\approx \\frac{h}{2} \\left( f(t_0) + 2\\sum_{k=1}^{N-1} f(t_k) + f(t_N) \\right)\n$$\nwhere $t_k = a+kh$. For our problem, the integrand is $f(t) = e^{-t^2}$.\n\nFor a given test case $(z,N)$:\nIf $z=0$, the integral is $0$, so $\\text{erf}(0) = 0$. The approximation is also trivially $0$, making the error $E_{\\text{abs}}(0,N)=0$.\nIf $z>0$, we set $a=0$ and $b=z$. The step size is $h=z/N$. The approximation of the integral $I(z) = \\int_{0}^{z} e^{-t^2} dt$ is:\n$$\n\\widehat{I}(z;N) = \\frac{z}{N} \\left( \\frac{e^{-0^2} + e^{-z^2}}{2} + \\sum_{k=1}^{N-1} e^{-(kz/N)^2} \\right)\n$$\nThe approximation for the error function is then $\\widehat{\\text{erf}}(z;N) = \\frac{2}{\\sqrt{\\pi}} \\widehat{I}(z;N)$.\nIf $z<0$, we use the odd symmetry. We calculate the approximation for the positive value $|z|$, and then negate the result:\n$$\n\\widehat{\\text{erf}}(z;N) = -\\widehat{\\text{erf}}(|z|;N)\n$$\nThis simplifies the implementation, as the trapezoidal rule is always applied over a non-negative interval $[0, |z|]$.\n\nSecond, we calculate the absolute error $E_{\\text{abs}}(z,N)$. This is defined as:\n$$\nE_{\\text{abs}}(z,N) = \\left| \\text{erf}(z) - \\widehat{\\text{erf}}(z;N) \\right|\n$$\nThe \"true\" value $\\text{erf}(z)$ is obtained using a high-precision implementation from the `scipy.special` library.\n\nThird, we evaluate the rigorous error bound $B(z,N)$. The problem provides the formula:\n$$\nB(z,N) = \\frac{2}{\\sqrt{\\pi}} \\cdot \\frac{|z|}{12} \\left(\\frac{|z|}{N}\\right)^{2} \\cdot \\max_{t \\in [\\min(0,z), \\max(0,z)]} \\left| \\frac{d^{2}}{dt^{2}} e^{-t^{2}} \\right|\n$$\nThis can be rewritten as $B(z,N) = \\frac{2|z|^3}{12\\sqrt{\\pi}N^2} M_2$, where $M_2$ is the maximum of the absolute value of the second derivative of the integrand, $f(t) = e^{-t^2}$, over the integration interval. The problem requires using the exact analytic value of this maximum. Let's find it.\nThe first derivative is $f'(t) = -2t e^{-t^2}$.\nThe second derivative is:\n$$\nf''(t) = \\frac{d}{dt}\\left(-2t e^{-t^2}\\right) = -2e^{-t^2} + (-2t)(-2t e^{-t^2}) = (4t^2 - 2)e^{-t^2}\n$$\nWe must find the maximum of $|f''(t)| = |(4t^2 - 2)e^{-t^2}|$ on the interval $[\\min(0,z), \\max(0,z)]$. Since $|f''(t)|$ is an even function, this is equivalent to finding its maximum on $[0, |z|]$.\nThe maximum of a function on a closed interval occurs at the interval's endpoints or at its internal critical points. Let us analyze $|f''(t)|$ for $t \\ge 0$.\nThe endpoints are $t=0$ and $t=|z|$.\nAt $t=0$, we have $|f''(0)| = |(0-2)e^0| = 2$.\nTo find critical points, we examine the third derivative, $f'''(t)$.\n$$\nf'''(t) = \\frac{d}{dt}\\left((4t^2 - 2)e^{-t^2}\\right) = (8t)e^{-t^2} + (4t^2 - 2)(-2t e^{-t^2}) = (8t - 8t^3 + 4t)e^{-t^2} = (12t - 8t^3)e^{-t^2} = 4t(3-2t^2)e^{-t^2}\n$$\nThe critical points where $f'''(t)=0$ are $t=0$ and $t=\\pm\\sqrt{3/2}$.\nThe function $|f''(t)|$ has a local maximum at $t=\\sqrt{3/2}\\approx 1.225$, with value $|f''(\\sqrt{3/2})| = |(4(3/2)-2)e^{-3/2}| = 4e^{-3/2} \\approx 0.892$. It has a local minimum (value $0$) where $f''(t)=0$, which is at $t=\\sqrt{1/2} \\approx 0.707$.\nThe function $|f''(t)|$ starts at a value of $2$ at $t=0$, decreases to $0$ at $t=\\sqrt{1/2}$, increases to a local maximum of $\\approx 0.892$ at $t=\\sqrt{3/2}$, and then monotonically decreases towards $0$ as $t \\to \\infty$.\nThe global maximum of $|f''(t)|$ for all $t \\ge 0$ occurs at $t=0$, and its value is $2$.\nSince the integration interval $[\\min(0,z), \\max(0,z)]$ for any $z$ always includes the point $t=0$, the maximum value of $|f''(t)|$ over this interval is always $M_2 = 2$.\nSubstituting this exact analytic value into the bound formula:\n$$\nB(z,N) = \\frac{2|z|^3}{12\\sqrt{\\pi}N^2} \\cdot 2 = \\frac{4|z|^3}{12\\sqrt{\\pi}N^2} = \\frac{|z|^3}{3\\sqrt{\\pi}N^2}\n$$\nFor $z=0$, this correctly gives $B=0$.\n\nThe implementation will loop through the test cases, apply these formulas, and format the results as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy.special\n\ndef solve():\n    \"\"\"\n    Computes the absolute error and theoretical error bound for a composite\n    trapezoidal approximation of the error function erf(z).\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 1),\n        (0.5, 10),\n        (1.0, 2),\n        (1.0, 50),\n        (2.0, 200),\n        (-1.0, 50),\n        (3.0, 400),\n    ]\n\n    # This will hold lists of [E_abs, B] for each test case\n    results_data = []\n\n    for z, N in test_cases:\n        # Trivial case z=0. The integral, approximation, error, and bound are all 0.\n        if z == 0.0:\n            e_abs = 0.0\n            bound = 0.0\n            results_data.append([e_abs, bound])\n            continue\n\n        # Use the property erf(-z) = -erf(z).\n        # The trapezoidal rule is always applied on the positive interval [0, |z|].\n        z_abs = abs(z)\n        \n        # 1. Compute the approximation using the composite trapezoidal rule.\n        #    numpy.trapz provides a concise and efficient implementation.\n        #    The integration nodes are from 0 to |z| with N subintervals.\n        t_nodes = np.linspace(0, z_abs, N + 1)\n        integrand_values = np.exp(-t_nodes**2)\n        integral_approx = np.trapz(integrand_values, t_nodes)\n        \n        # Apply the pre-factor and sign for the final erf approximation.\n        erf_approx = np.sign(z) * (2.0 / np.sqrt(np.pi)) * integral_approx\n\n        # 2. Compute the absolute error against the high-precision library function.\n        erf_true = scipy.special.erf(z)\n        e_abs = abs(erf_true - erf_approx)\n\n        # 3. Compute the rigorous error bound.\n        #    The generic formula is B = (2/sqrt(pi)) * (|z|/12) * (|z|/N)^2 * M2,\n        #    where M2 = max|f''(t)|.\n        #    The analytic maximum M2 for f(t)=exp(-t^2) is 2.\n        #    This simplifies the formula to B = |z|^3 / (3 * N^2 * sqrt(pi)).\n        bound = (z_abs**3) / (3.0 * np.sqrt(np.pi) * N**2)\n        \n        results_data.append([e_abs, bound])\n\n    # Format the final output string exactly as required by the problem statement:\n    # A list of lists, with no whitespace, and numbers in scientific notation\n    # with 12 significant digits.\n    formatted_pairs = []\n    for e, b in results_data:\n        e_str = f\"{e:.12e}\"\n        b_str = f\"{b:.12e}\"\n        formatted_pairs.append(f\"[{e_str},{b_str}]\")\n    \n    final_output_string = f\"[{','.join(formatted_pairs)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond evaluating formal integrals, numerical methods are essential for analyzing discrete data sets obtained from experiments or other simulations. The rate of change, or derivative, of a property can reveal key physical information, such as the $pK_a$ of a titratable group which corresponds to the maximal change in binding energy with respect to pH. This hands-on practice () challenges you to apply numerical differentiation to a realistic chemical problem, estimating a protein's $pK_a$ from binding data and gaining experience with finite-difference methods on non-uniform grids.",
            "id": "2459600",
            "problem": "In computational chemistry, pH-dependent binding arises from protonation equilibria of titratable sites in a protein. Consider a ligand whose binding free energy to a protein, denoted by $E(pH)$ and measured in kilojoules per mole, varies smoothly with $pH$ due to a single acid-base transition characterized by an acid dissociation constant with $pK_a$ in pH units. By thermodynamic and acid-base principles, $E(pH)$ is a smooth, monotonic sigmoid-like function when a single site dominates the transition. The inflection point of such a monotonic sigmoid occurs near the underlying $pK_a$, so the magnitude of the slope $\\left|\\dfrac{dE}{dpH}\\right|$ typically reaches a maximum near $pH \\approx pK_a$. The derivative and integral are defined from first principles as limits of difference quotients and Riemann sums, respectively. The composite trapezoidal rule is a standard, well-tested numerical quadrature that approximates the definite integral by summing areas of trapezoids under the curve. These ideas enable a fully numerical strategy to estimate $pK_a$ from discrete $E(pH)$ data, even on a nonuniform $pH$ grid.\n\nTask. Write a complete program that, given several discrete data sets $\\{(pH_i, E_i)\\}_{i=0}^{N-1}$, performs the following for each data set without using any closed-form model fitting:\n- Numerically approximate the derivative $\\dfrac{dE}{dpH}$ at the given grid points using a second-order-accurate finite-difference scheme based on local quadratic interpolation that works on nonuniform grids. Use one-sided, second-order-accurate, three-point formulas at the endpoints and a three-point formula at interior points.\n- Estimate the protein’s $pK_a$ as the $pH$ value at which $\\left|\\dfrac{dE}{dpH}\\right|$ attains its maximum over the provided grid.\n- Numerically integrate $\\dfrac{dE}{dpH}$ over the provided $pH$ range using the composite trapezoidal rule on the given grid to estimate the net change in binding free energy across the range. Report this estimated change in kilojoules per mole.\n\nUnits and rounding. Binding free energies $E$ are in kilojoules per mole. Report the $pK_a$ in pH units, rounded to two decimal places. Report the integrated energy change in kilojoules per mole, rounded to two decimal places.\n\nAngle unit. If any trigonometric functions are used internally (for deterministic noise generation in the test data below), interpret angles in radians.\n\nInput format for this problem. There is no external input. Your program must internally construct and use the test-suite data sets specified below.\n\nTest suite. To make the task self-contained and testable, use the following three synthetic but physically plausible data sets. In each case, the “measured” binding energy is constructed as\n$$\nE(pH) \\;=\\; E_{\\mathrm{acid}} \\;+\\; \\left(E_{\\mathrm{base}} - E_{\\mathrm{acid}}\\right)\\,\\alpha(pH)\\;+\\; \\eta(pH),\n$$\nwhere\n$$\n\\alpha(pH) \\;=\\; \\dfrac{1}{1 + 10^{\\,pK_a - pH}}\n$$\nis the deprotonated fraction of a monoprotic site, and $\\eta(pH)$ is a small, deterministic baseline-correlated term that mimics experimental noise. There is no randomness; $\\eta(pH)$ is specified explicitly. Use the following three cases:\n\n- Case A (uniform grid, fine spacing, low noise): $E_{\\mathrm{acid}} = -30.00$ kilojoules per mole, $E_{\\mathrm{base}} = -10.00$ kilojoules per mole, $pK_a = 6.50$, $pH$ grid from $2.00$ to $12.00$ inclusive with step $0.25$ (uniform), and $\\eta(pH) = 0.05 \\,\\sin(0.90\\, pH)$.\n- Case B (nonuniform grid, moderate noise): $E_{\\mathrm{acid}} = -25.00$ kilojoules per mole, $E_{\\mathrm{base}} = -15.00$ kilojoules per mole, $pK_a = 4.20$, $pH$ grid given explicitly by the list $[2.00,\\; 2.50,\\; 3.00,\\; 3.50,\\; 4.00,\\; 4.30,\\; 4.60,\\; 5.30,\\; 6.20,\\; 7.50,\\; 9.00,\\; 12.00]$, and $\\eta(pH) = 0.08 \\,\\cos(1.30\\, pH)$.\n- Case C (uniform grid, coarse spacing, very low noise): $E_{\\mathrm{acid}} = -32.00$ kilojoules per mole, $E_{\\mathrm{base}} = -8.00$ kilojoules per mole, $pK_a = 9.00$, $pH$ grid from $6.00$ to $12.00$ inclusive with step $1.00$ (uniform), and $\\eta(pH) = 0.03 \\,\\sin(1.10\\, pH + 0.30)$.\n\nWhat to compute for each case:\n- The estimated $pK_a$ value in pH units, rounded to two decimal places, obtained by the $pH$ location of the maximum of $\\left|\\dfrac{dE}{dpH}\\right|$ on the provided grid.\n- The integrated binding-energy change over the provided $pH$ range, computed as $\\displaystyle \\int_{pH_{\\min}}^{pH_{\\max}} \\dfrac{dE}{dpH}\\, dpH$ by the composite trapezoidal rule on the given grid, expressed in kilojoules per mole and rounded to two decimal places.\n\nFinal output format. Your program should produce a single line of output containing the results for the three cases as a list of lists. Each inner list contains two floats in the order $[pK_a^{\\mathrm{est}}, \\Delta E^{\\mathrm{int}}]$, where $pK_a^{\\mathrm{est}}$ is the estimated $pK_a$ and $\\Delta E^{\\mathrm{int}}$ is the integrated energy change. The entire output must be printed as a single line of the form\n$[[a_1,b_1],[a_2,b_2],[a_3,b_3]]$\nwith no spaces, where each $a_i$ and $b_i$ are decimal numbers rounded as specified above. For example, an output string like $[[6.50,19.95],[4.30,10.02],[9.00,24.01]]$ follows the required format.",
            "solution": "The problem has been subjected to rigorous validation and is determined to be valid. It is scientifically grounded, well-posed, and objective. The problem statement describes a standard scenario in biophysical chemistry, where ligand binding affinity is modulated by $pH$. The underlying model, based on a single-site acid-base equilibrium, is a correct application of thermodynamic principles. The task of estimating the $pK_a$ from the maximum of the derivative's magnitude, $\\left|\\frac{dE}{dpH}\\right|$, is a well-established method for analyzing sigmoidal titration curves. The specified numerical techniques—second-order finite differences for non-uniform grids and the composite trapezoidal rule—are standard and appropriate for the task. All required parameters and data are provided, rendering the problem self-contained and tractable. We may therefore proceed with the derivation and construction of a solution.\n\nThe solution is constructed based on a sequence of established principles, beginning with the physical model and proceeding to the required numerical algorithms.\n\n1.  **Physical Model and Data Generation**\n    The binding free energy, $E(pH)$, is given as a function of $pH$. For a single titratable site, this dependency is modeled by the equation:\n    $$\n    E(pH) = E_{\\mathrm{acid}} + \\left(E_{\\mathrm{base}} - E_{\\mathrm{acid}}\\right)\\,\\alpha(pH) + \\eta(pH)\n    $$\n    Here, $E_{\\mathrm{acid}}$ and $E_{\\mathrm{base}}$ are the binding free energies when the titratable site is fully protonated and deprotonated, respectively. The term $\\eta(pH)$ represents a small experimental noise or baseline artifact. The function $\\alpha(pH)$ is the fraction of the site in the deprotonated (base) form, given by the standard Henderson-Hasselbalch-derived sigmoid:\n    $$\n    \\alpha(pH) = \\dfrac{1}{1 + 10^{\\,pK_a - pH}}\n    $$\n    For each test case, this model is used to generate a discrete data set $\\{ (pH_i, E_i) \\}_{i=0}^{N-1}$, which serves as the input for the subsequent numerical analysis.\n\n2.  **Numerical Differentiation**\n    The core of the $pK_a$ estimation lies in computing the derivative, $\\frac{dE}{dpH}$, from the discrete data. The problem specifies a second-order accurate finite-difference scheme that is valid for non-uniform grids, as is common with experimental data. Such schemes are derived by locally fitting a quadratic polynomial, $P(x)$, to three adjacent data points and then analytically differentiating the polynomial. Let the data points be $(x_i, f_i)$, representing $(pH_i, E_i)$, and let $h_i = x_{i+1} - x_i$ be the step size, which may vary with $i$. The formulas for the derivative $f'(x_i)$ are as follows:\n\n    -   **Interior Points ($i = 1, \\dots, N-2$):** A central-difference formula is used, based on the points $(x_{i-1}, f_{i-1})$, $(x_i, f_i)$, and $(x_{i+1}, f_{i+1})$. With $h_{i-1} = x_i - x_{i-1}$ and $h_i = x_{i+1} - x_i$, the derivative is:\n        $$\n        f'(x_i) \\approx f_{i-1} \\frac{-h_i}{h_{i-1}(h_{i-1}+h_i)} + f_i \\frac{h_i-h_{i-1}}{h_{i-1}h_i} + f_{i+1} \\frac{h_{i-1}}{h_i(h_{i-1}+h_i)}\n        $$\n\n    -   **Left Endpoint ($i=0$):** A one-sided, forward-difference formula is used, based on the points $(x_0, f_0)$, $(x_1, f_1)$, and $(x_2, f_2)$. With $h_0 = x_1 - x_0$ and $h_1 = x_2 - x_1$, the derivative is:\n        $$\n        f'(x_0) \\approx f_0 \\frac{-(2h_0+h_1)}{h_0(h_0+h_1)} + f_1 \\frac{h_0+h_1}{h_0 h_1} - f_2 \\frac{h_0}{h_1(h_0+h_1)}\n        $$\n\n    -   **Right Endpoint ($i=N-1$):** A one-sided, backward-difference formula is used, based on the points $(x_{N-3}, f_{N-3})$, $(x_{N-2}, f_{N-2})$, and $(x_{N-1}, f_{N-1})$. With $h_{N-3} = x_{N-2} - x_{N-3}$ and $h_{N-2} = x_{N-1} - x_{N-2}$, the derivative is:\n        $$\n        f'(x_{N-1}) \\approx f_{N-3}\\frac{h_{N-2}}{h_{N-3}(h_{N-3}+h_{N-2})} - f_{N-2}\\frac{h_{N-3}+h_{N-2}}{h_{N-3}h_{N-2}} + f_{N-1}\\frac{h_{N-3}+2h_{N-2}}{h_{N-2}(h_{N-3}+h_{N-2})}\n        $$\n    These formulas provide a complete vector of derivative values, $(\\frac{dE}{dpH})_i$, for the entire grid.\n\n3.  **Estimation of $pK_a$**\n    The $pK_a$ of the titratable group corresponds to the inflection point of the sigmoid $E(pH)$ curve. At this point, the steepness of the curve is maximal. Therefore, the estimated $pK_a$ is identified as the $pH$ value on the grid where the magnitude of the numerically computed derivative, $\\left|\\frac{dE}{dpH}\\right|$, reaches its maximum.\n    $$\n    pK_a^{\\mathrm{est}} = pH_k \\quad \\text{where} \\quad k = \\underset{i \\in \\{0, \\dots, N-1\\}}{\\arg\\max} \\left| \\left( \\frac{dE}{dpH} \\right)_i \\right|\n    $$\n\n4.  **Numerical Integration**\n    The net change in binding free energy across the measured $pH$ range, $\\Delta E^{\\mathrm{int}}$, is computed by integrating the numerical derivative $\\frac{dE}{dpH}$. The problem mandates the use of the composite trapezoidal rule. For a function $g(x)$ sampled at points $(x_i, g_i)$, this rule approximates the definite integral by summing the areas of the trapezoids formed by adjacent points:\n    $$\n    \\int_{x_0}^{x_{N-1}} g(x) \\, dx \\approx \\sum_{i=0}^{N-2} \\frac{g_i + g_{i+1}}{2} (x_{i+1} - x_i)\n    $$\n    Applying this to our computed derivative values $(pH_i, (\\frac{dE}{dpH})_i)$ gives the desired integrated energy change. By the Fundamental Theorem of Calculus, this integrated value should approximate the total change in the function, $E(pH_{N-1}) - E(pH_0)$, with discrepancies arising from the numerical errors in both the differentiation and integration steps.\n\nThe final program implements this sequence of operations for each of the three specified test cases, adhering to the required rounding and output formatting.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef numerical_derivative(x, y):\n    \"\"\"\n    Computes the derivative of y with respect to x on a potentially\n    non-uniform grid using second-order accurate finite differences.\n    \"\"\"\n    n = len(x)\n    if n < 3:\n        raise ValueError(\"At least 3 points are required for second-order differences.\")\n    \n    dydx = np.zeros(n)\n\n    # First point: second-order forward difference\n    h0 = x[1] - x[0]\n    h1 = x[2] - x[1]\n    if h0 <= 0 or h1 <= 0:\n        raise ValueError(\"Grid points must be strictly increasing.\")\n    \n    c0 = -(2 * h0 + h1) / (h0 * (h0 + h1))\n    c1 = (h0 + h1) / (h0 * h1)\n    c2 = -h0 / (h1 * (h0 + h1))\n    dydx[0] = c0 * y[0] + c1 * y[1] + c2 * y[2]\n\n    # Interior points: second-order central difference\n    for i in range(1, n - 1):\n        h_prev = x[i] - x[i-1]\n        h_next = x[i+1] - x[i]\n        if h_prev <= 0 or h_next <= 0:\n            raise ValueError(\"Grid points must be strictly increasing.\")\n        \n        c_prev = -h_next / (h_prev * (h_prev + h_next))\n        c_curr = (h_next - h_prev) / (h_prev * h_next)\n        c_next = h_prev / (h_next * (h_prev + h_next))\n        dydx[i] = c_prev * y[i-1] + c_curr * y[i] + c_next * y[i+1]\n\n    # Last point: second-order backward difference\n    h_n_minus_3 = x[n-2] - x[n-3]\n    h_n_minus_2 = x[n-1] - x[n-2]\n    if h_n_minus_3 <= 0 or h_n_minus_2 <= 0:\n        raise ValueError(\"Grid points must be strictly increasing.\")\n    \n    c_n_minus_3 = h_n_minus_2 / (h_n_minus_3 * (h_n_minus_3 + h_n_minus_2))\n    c_n_minus_2 = -(h_n_minus_3 + h_n_minus_2) / (h_n_minus_3 * h_n_minus_2)\n    c_n_minus_1 = (h_n_minus_3 + 2 * h_n_minus_2) / (h_n_minus_2 * (h_n_minus_3 + h_n_minus_2))\n    dydx[n-1] = c_n_minus_3 * y[n-3] + c_n_minus_2 * y[n-2] + c_n_minus_1 * y[n-1]\n\n    return dydx\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        {\n            'E_acid': -30.00, 'E_base': -10.00, 'pKa': 6.50,\n            'pH_grid': np.arange(2.00, 12.00 + 1e-9, 0.25),\n            'eta': lambda ph: 0.05 * np.sin(0.90 * ph)\n        },\n        # Case B\n        {\n            'E_acid': -25.00, 'E_base': -15.00, 'pKa': 4.20,\n            'pH_grid': np.array([2.00, 2.50, 3.00, 3.50, 4.00, 4.30, 4.60, 5.30, 6.20, 7.50, 9.00, 12.00]),\n            'eta': lambda ph: 0.08 * np.cos(1.30 * ph)\n        },\n        # Case C\n        {\n            'E_acid': -32.00, 'E_base': -8.00, 'pKa': 9.00,\n            'pH_grid': np.arange(6.00, 12.00 + 1e-9, 1.00),\n            'eta': lambda ph: 0.03 * np.sin(1.10 * ph + 0.30)\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Step 1: Generate the discrete E(pH) data set\n        E_acid, E_base, pKa_true = case['E_acid'], case['E_base'], case['pKa']\n        pH_grid = case['pH_grid']\n        eta_func = case['eta']\n\n        alpha = 1.0 / (1.0 + 10**(pKa_true - pH_grid))\n        E_values = E_acid + (E_base - E_acid) * alpha + eta_func(pH_grid)\n\n        # Step 2: Numerically approximate the derivative dE/dpH\n        dEdpH = numerical_derivative(pH_grid, E_values)\n\n        # Step 3: Estimate pKa from the maximum of |dE/dpH|\n        abs_dEdpH = np.abs(dEdpH)\n        max_idx = np.argmax(abs_dEdpH)\n        pKa_est = pH_grid[max_idx]\n\n        # Step 4: Numerically integrate dE/dpH using trapezoidal rule\n        delta_E_int = np.trapz(dEdpH, pH_grid)\n        \n        # Step 5: Store the rounded results\n        results.append([pKa_est, delta_E_int])\n\n    # Final print statement in the exact required format.\n    # Format each result [pKa, dE] with 2 decimal places.\n    inner_parts = [f\"[{res[0]:.2f},{res[1]:.2f}]\" for res in results]\n    final_output_string = f\"[{','.join(inner_parts)}]\"\n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "A primary application of numerical integration in computational chemistry is molecular dynamics (MD), which simulates the motion of atoms and molecules by integrating Newton's equations of motion. The Verlet algorithm is a specialized integrator prized for its time-reversibility and excellent long-term energy stability, making it a cornerstone of MD. In this capstone exercise (), you will derive the Verlet algorithm from first principles and use it to simulate a diatomic molecule, allowing you to explore the crucial relationship between the integration time step, $\\Delta t$, and the stability of a molecular simulation.",
            "id": "2459645",
            "problem": "You are to derive, implement, and test a numerical integrator based on the Verlet algorithm to propagate the relative coordinate of a diatomic molecule modeled as a one-dimensional harmonic oscillator. The context is the motion of the internal (bond) coordinate near equilibrium. Work entirely in reduced, dimensionless units so that the reduced mass is $m=1$ and the harmonic force constant is $k=1$. The motion is governed by Newton’s second law and the harmonic potential.\n\nTasks:\n- Starting only from Newton’s second law and the definition of force as the negative gradient of potential energy, derive a time-reversible, second-order accurate position-update scheme that uses positions at times $t$ and $t-\\Delta t$ to compute the position at time $t+\\Delta t$ for a one-dimensional trajectory $x(t)$. Your derivation must not assume any preexisting numerical integration formula. You may use Taylor expansions about $t$ as a fundamental tool from calculus.\n- Specify how to initialize the scheme given $x(0)$ and $v(0)$ without requiring knowledge of $x(-\\Delta t)$. Your initialization should be consistent with the same order of accuracy as the scheme and must be derived from fundamental principles.\n- Provide a consistent definition for the kinetic energy $K$, potential energy $V$, and total energy $E=K+V$ at discrete times, given that the position-only update does not explicitly evolve the velocity. Your definition of the discrete velocity should be consistent with the order of accuracy of the position-update scheme.\n- Implement the derived algorithm in code and evaluate the conservation of total energy over time for several time steps $\\Delta t$. For each time step, compute the maximum absolute relative deviation of energy from its initial value over the trajectory,\n$$\n\\delta = \\max_{0 \\le n \\le N} \\frac{\\lvert E_n - E_0 \\rvert}{E_0}.\n$$\n\nModel and parameters (use these exact values):\n- One-dimensional relative coordinate $x(t)$ for a diatomic molecule near equilibrium, with harmonic potential $V(x) = \\tfrac{1}{2} k x^2$ and force $F(x) = -\\tfrac{\\mathrm{d}V}{\\mathrm{d}x} = -kx$.\n- Reduced, dimensionless units with $m=1$ and $k=1$.\n- Initial conditions: $x(0)=0.1$ and $v(0)=0$.\n- Number of steps: $N=2000$.\n- Time steps for the test suite: $\\Delta t \\in \\{0.05,\\;0.5,\\;1.95\\}$.\n\nAngle units are not applicable in this one-dimensional problem. There are no physical units since the problem uses reduced, dimensionless units.\n\nTest suite and coverage rationale:\n- $\\Delta t=0.05$: a small time step to test the expected near-conservation of energy for a high-accuracy regime.\n- $\\Delta t=0.5$: an intermediate time step to test typical behavior away from the asymptotic regime.\n- $\\Delta t=1.95$: a time step close to the linear stability boundary for the harmonic oscillator with $m=1$ and $k=1$, which has angular frequency $\\omega=\\sqrt{k/m}=1$ and a stability limit that depends on $\\Delta t \\,\\omega$. This tests the edge-case behavior of the integrator near its stability limit.\n\nRequired final output:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the values of $\\delta$ for the test suite in the same order as the time steps given above. Express each $\\delta$ as a decimal rounded to eight decimal places. For example, the required format is [$r_1$,$r_2$,$r_3$], where $r_1$, $r_2$, and $r_3$ are the rounded decimals corresponding to $\\Delta t=0.05$, $\\Delta t=0.5$, and $\\Delta t=1.95$, respectively.",
            "solution": "The problem as stated is scientifically sound, well-posed, and complete. It describes a fundamental exercise in computational physics and chemistry: the numerical integration of a simple, yet highly relevant, dynamical system. The parameters are clearly defined, the objectives are unambiguous, and the test cases are chosen to probe the performance of the algorithm in different regimes, including near the stability limit. Therefore, proceeding with the solution is warranted.\n\nThe solution is presented in three parts, as requested: the derivation of the numerical integration scheme, the initialization procedure, and the definitions for the system's energy.\n\n1. Derivation of the Position-Update Scheme (Position Verlet Algorithm)\n\nThe starting point is Newton's second law of motion in one dimension, which relates the acceleration $a(t) = \\ddot{x}(t)$ of a particle of mass $m$ to the force $F(x(t))$ acting upon it:\n$$\nm \\ddot{x}(t) = F(x(t))\n$$\nThe position of the particle at a future time $t + \\Delta t$ and a past time $t - \\Delta t$ can be expressed via Taylor series expansions around the current time $t$:\n$$\nx(t + \\Delta t) = x(t) + \\dot{x}(t)\\Delta t + \\frac{1}{2}\\ddot{x}(t)\\Delta t^2 + \\frac{1}{6}\\dddot{x}(t)\\Delta t^3 + O(\\Delta t^4)\n$$\n$$\nx(t - \\Delta t) = x(t) - \\dot{x}(t)\\Delta t + \\frac{1}{2}\\ddot{x}(t)\\Delta t^2 - \\frac{1}{6}\\dddot{x}(t)\\Delta t^3 + O(\\Delta t^4)\n$$\nAdding these two equations together results in the cancellation of the terms with odd powers of $\\Delta t$:\n$$\nx(t + \\Delta t) + x(t - \\Delta t) = 2x(t) + \\ddot{x}(t)\\Delta t^2 + O(\\Delta t^4)\n$$\nRearranging this equation to solve for the future position $x(t + \\Delta t)$ gives:\n$$\nx(t + \\Delta t) = 2x(t) - x(t - \\Delta t) + \\ddot{x}(t)\\Delta t^2 + O(\\Delta t^4)\n$$\nSubstituting the acceleration from Newton's second law, $\\ddot{x}(t) = F(x(t))/m$, we obtain the general form of the position-update scheme:\n$$\nx(t + \\Delta t) = 2x(t) - x(t - \\Delta t) + \\frac{F(x(t))}{m}\\Delta t^2 + O(\\Delta t^4)\n$$\nThis is the Position Verlet algorithm. The local truncation error is of order $O(\\Delta t^4)$, which leads to a global error of order $O(\\Delta t^2)$ over a fixed time interval, making it a second-order accurate method. The scheme is explicitly time-reversible because swapping $\\Delta t$ with $-\\Delta t$ and rearranging the equation to solve for $x(t-\\Delta t)$ yields the same form. For the specific case of the harmonic oscillator with $F(x) = -kx$, and in reduced units where $m=1$ and $k=1$, the discrete update rule simplifies to:\n$$\nx_{n+1} = 2x_n - x_{n-1} - x_n \\Delta t^2\n$$\nwhere $x_n$ denotes the position at time $t_n = n \\Delta t$.\n\n2. Initialization of the Scheme\n\nThe update scheme requires positions at two previous time steps, $x_n$ and $x_{n-1}$, to compute the next position $x_{n+1}$. At the beginning of the simulation, $t=0$, we are only given the initial position $x(0)$ and initial velocity $v(0) = \\dot{x}(0)$. The position at the fictitious previous time step, $x(-\\Delta t)$, is not known. We must derive an expression for $x(-\\Delta t)$ that is consistent with the integrator's order of accuracy.\n\nWe use the Taylor expansion for $x(-\\Delta t)$ around $t=0$:\n$$\nx(-\\Delta t) = x(0) - v(0)\\Delta t + \\frac{1}{2}a(0)\\Delta t^2 - \\frac{1}{6}\\dddot{x}(0)\\Delta t^3 + O(\\Delta t^4)\n$$\nTo maintain the second-order accuracy of the overall algorithm, we can truncate this series. A common approach is to use the velocity information to construct a \"half-step\" position, but a direct approximation of $x(-\\Delta t)$ is more fundamental. By truncating the series and retaining terms up to $\\Delta t^2$, we obtain an approximation for $x(-\\Delta t)$ with an error of $O(\\Delta t^3)$:\n$$\nx(-\\Delta t) \\approx x(0) - v(0)\\Delta t + \\frac{1}{2}a(0)\\Delta t^2\n$$\nThe acceleration at time $t=0$ is given by $a(0) = F(x(0))/m$. In our specific problem, this becomes $a(0) = -kx(0)/m = -x(0)$. Substituting this into the approximation for $x(-\\Delta t)$ yields the required initialization formula:\n$$\nx_{-1} \\approx x_0 - v_0 \\Delta t - \\frac{1}{2} x_0 \\Delta t^2\n$$\nUsing this value for $x_{-1}$ (the position at $t=-\\Delta t$) allows the first integration step to be taken to find $x_1$ (the position at $t=\\Delta t$), thereby bootstrapping the trajectory propagation while preserving the overall $O(\\Delta t^2)$ accuracy.\n\n3. Expressions for Kinetic and Total Energy\n\nThe potential energy $V$ is a function of position only. For the harmonic oscillator, $V(x) = \\frac{1}{2}kx^2$. At a discrete time step $t_n$, the potential energy is simply:\n$$\nV_n = V(x_n) = \\frac{1}{2} k x_n^2\n$$\nThe kinetic energy is $K = \\frac{1}{2}mv^2$. The Position Verlet algorithm does not explicitly propagate the velocity. To compute the kinetic energy, we must define a discrete velocity $v_n$ at time $t_n$ that is consistent with the integrator's accuracy. We can derive such an expression by subtracting the Taylor series for $x(t-\\Delta t)$ from that of $x(t+\\Delta t)$:\n$$\nx(t + \\Delta t) - x(t - \\Delta t) = 2\\dot{x}(t)\\Delta t + \\frac{1}{3}\\dddot{x}(t)\\Delta t^3 + O(\\Delta t^5)\n$$\nSolving for the velocity $\\dot{x}(t)$ gives:\n$$\n\\dot{x}(t) = \\frac{x(t + \\Delta t) - x(t - \\Delta t)}{2\\Delta t} - \\frac{1}{6}\\dddot{x}(t)\\Delta t^2 + O(\\Delta t^4)\n$$\nThis suggests the central difference formula as a suitable approximation for the velocity, with a truncation error of $O(\\Delta t^2)$:\n$$\nv_n \\approx \\frac{x_{n+1} - x_{n-1}}{2\\Delta t}\n$$\nThis definition is consistent with the second-order accuracy of the position integration. The kinetic energy at step $n$ is thus defined as:\n$$\nK_n = \\frac{1}{2}m v_n^2 = \\frac{1}{2}m \\left( \\frac{x_{n+1} - x_{n-1}}{2\\Delta t} \\right)^2 = \\frac{m}{8\\Delta t^2} (x_{n+1} - x_{n-1})^2\n$$\nThe total energy at step $n$ is the sum of the kinetic and potential energies:\n$$\nE_n = K_n + V_n = \\frac{m}{8\\Delta t^2} (x_{n+1} - x_{n-1})^2 + \\frac{1}{2} k x_n^2\n$$\nThis expression for energy is defined for time steps $1 \\le n \\le N-1$. To compute the energy for the full range $0 \\le n \\le N$ as required by the problem, we need to handle the endpoints.\n- For $n=0$, we have $x_1$ and $x_0$. The value $x_{-1}$ is the fictitious point calculated during initialization. This allows us to compute $v_0$ and thus $K_0$ and $E_0$ using the discrete formula, which correctly reproduces the analytical initial energy.\n- For $n=N$, we need the position $x_{N+1}$. This requires extending the simulation by one extra step to compute the trajectory up to $t_{N+1} = (N+1)\\Delta t$.\n\nThe initial energy $E_0$ for the deviation calculation is the exact analytical value determined by the initial conditions: $E_0 = \\frac{1}{2}mv(0)^2 + \\frac{1}{2}kx(0)^2$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives, implements, and tests a Verlet integrator for a 1D harmonic oscillator.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        0.05,\n        0.5,\n        1.95,\n    ]\n\n    results = []\n    for dt in test_cases:\n        # Model parameters (dimensionless units)\n        m = 1.0\n        k = 1.0\n        \n        # Initial conditions\n        x0 = 0.1\n        v0 = 0.0\n        \n        # Simulation parameters\n        N = 2000\n        \n        # Pre-calculate constants\n        w2 = k / m  # Squared angular frequency\n        \n        # Analytical initial energy E_0 to be used as the reference\n        E_initial = 0.5 * m * v0**2 + 0.5 * k * x0**2\n        \n        # Because the discrete energy E_n depends on x_{n+1}, we need to simulate\n        # N+2 steps (from t=0 to t=(N+1)*dt) to get positions x_0, ..., x_{N+1}.\n        # This allows calculation of energies E_0, ..., E_N.\n        num_points = N + 2\n        x_traj = np.zeros(num_points)\n        \n        # --- Integration ---\n        # Initialize the trajectory\n        x_traj[0] = x0\n        \n        # Calculate the fictitious previous point x_{-1} for the first step\n        # using the derived initialization formula.\n        accel_0 = -w2 * x0\n        x_prev = x0 - v0 * dt + 0.5 * accel_0 * dt**2\n        \n        # Perform the first integration step\n        x_traj[1] = 2.0 * x_traj[0] - x_prev + (-w2 * x_traj[0]) * dt**2\n        \n        # Propagate the trajectory for the remaining steps using the Verlet algorithm\n        for n in range(2, num_points):\n            # n corresponds to x_n, so we use x_{n-1} and x_{n-2}\n            accel = -w2 * x_traj[n - 1]\n            x_traj[n] = 2.0 * x_traj[n - 1] - x_traj[n - 2] + accel * dt**2\n            \n        # --- Energy Analysis ---\n        max_relative_deviation = 0.0\n        \n        # Calculate energy for each step from n=0 to n=N\n        for n in range(N + 1):\n            # Positions needed for velocity calculation at step n: x_{n+1} and x_{n-1}\n            xn = x_traj[n]\n            xn_plus_1 = x_traj[n + 1]\n            \n            if n == 0:\n                # For n=0, x_{n-1} is the fictitious point x_prev\n                xn_minus_1 = x_prev\n            else:\n                xn_minus_1 = x_traj[n - 1]\n                \n            # Calculate velocity at step n using the central difference formula\n            vn = (xn_plus_1 - xn_minus_1) / (2.0 * dt)\n            \n            # Calculate kinetic and potential energies at step n\n            Kn = 0.5 * m * vn**2\n            Vn = 0.5 * k * xn**2\n            En = Kn + Vn\n            \n            # Calculate the absolute relative deviation from the initial energy\n            # Handle E_initial=0 case to avoid division by zero, although not relevant here.\n            if E_initial == 0:\n                relative_deviation = abs(En)\n            else:\n                relative_deviation = abs(En - E_initial) / abs(E_initial)\n            \n            # Update the maximum deviation found so far\n            if relative_deviation > max_relative_deviation:\n                max_relative_deviation = relative_deviation\n                \n        # Append the result for the current time step, rounded to 8 decimal places\n        results.append(f\"{max_relative_deviation:.8f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}