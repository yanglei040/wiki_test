{
    "hands_on_practices": [
        {
            "introduction": "To build a solid understanding of Free Energy Perturbation, we begin with a foundational exercise that connects the FEP formula to first principles. This problem  considers a highly simplified, hypothetical system—a charged sphere in a vacuum—where the free energy change can be calculated directly from classical electromagnetism. By then applying the formal FEP equation and showing that it yields the exact same result, you will gain a deeper intuition for why the FEP method works and see how it behaves in a scenario with no statistical complexity.",
            "id": "2455869",
            "problem": "A single rigid, infinitesimally thin spherical shell of fixed radius $a$ is placed in vacuum (relative permittivity $1$) at absolute temperature $T$. The shell carries a total charge $q$, which is quasi-statically changed to $q + \\delta q$ while the shell remains isolated in vacuum and no other degrees of freedom are present. Assume classical electromagnetism and the canonical ensemble of statistical mechanics apply, and that the only energetic contribution is from the electromagnetic field generated by the shell.\n\nUsing only first principles, determine the exact Helmholtz free energy change $\\Delta F$ associated with changing the charge from $q$ to $q + \\delta q$. Then, within the canonical ensemble, evaluate the exact Free Energy Perturbation (FEP) expression for $\\Delta F$ for this system and simplify it fully. Express your final result as a single closed-form analytic expression in terms of $q$, $\\delta q$, $a$, and $\\varepsilon_{0}$. Express the energy in Joules (J). Do not evaluate numerically.",
            "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n-   System: A single rigid, infinitesimally thin spherical shell of fixed radius $a$.\n-   Initial state charge: $q$.\n-   Final state charge: $q + \\delta q$.\n-   Process: Quasi-static change in charge.\n-   Environment: Vacuum, relative permittivity $1$. Permittivity of free space is $\\varepsilon_{0}$.\n-   Thermodynamic conditions: Constant absolute temperature $T$, canonical ensemble.\n-   Constraint: The shell is isolated, and no other degrees of freedom are present.\n-   Energy model: The only energetic contribution is from the electromagnetic field.\n-   Objective: To find the Helmholtz free energy change, denoted as $\\Delta F$ in the problem, using two methods: (1) first principles and (2) the Free Energy Perturbation (FEP) formula. The final result should be in terms of $q$, $\\delta q$, $a$, and $\\varepsilon_{0}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and internally consistent. It combines principles from classical electromagnetism and statistical mechanics in a non-trivial but solvable manner. The constraint that \"no other degrees of freedom are present\" is a critical piece of information that simplifies the statistical mechanical treatment, making the problem tractable. This implies the system's energy is solely a function of its charge, and for a given charge, the system possesses only a single microstate. The problem's use of $\\Delta F$ to denote Helmholtz free energy change is consistent with the main article.\n\n**Verdict and Action**\nThe problem is deemed **valid**. A full solution will be provided.\n\nThe objective is to compute the change in Helmholtz free energy, $\\Delta F$, when the charge on a spherical shell is changed from $q$ to $q + \\delta q$. This will be done via two independent derivations as requested.\n\n**Part 1: Helmholtz Free Energy from First Principles**\n\nThe Helmholtz free energy $F$ is related to the internal energy $U$ and entropy $S$ by the thermodynamic relation $F = U - TS$. In the context of statistical mechanics, for a system in the canonical ensemble, the entropy is given by the Boltzmann formula, $S = k_B \\ln(W)$, where $W$ is the number of microstates corresponding to the given macrostate.\n\nThe problem states that \"no other degrees of freedom are present\". This means that for a given total charge $Q$ on the shell, the system has exactly one microstate. Therefore, the number of microstates is $W=1$. The entropy of the system is $S = k_B \\ln(1) = 0$.\n\nConsequently, the Helmholtz free energy $F$ is exactly equal to the internal energy $U$ of the system.\n$$F = U - T(0) = U$$\nThe internal energy $U$ is specified to be solely the electrostatic potential energy stored in the electric field of the charged spherical shell. From classical electromagnetism, the electrostatic energy $U(Q)$ of a spherical shell of radius $a$ carrying a total charge $Q$ is given by:\n$$U(Q) = \\frac{Q^2}{8\\pi\\varepsilon_{0}a}$$\nThis energy is equivalent to the work done to quasi-statically assemble the charge $Q$ on the shell.\n\nThe initial state of the system has charge $q$. Its Helmholtz free energy is $F_{\\text{initial}}$.\n$$F_{\\text{initial}} = U(q) = \\frac{q^2}{8\\pi\\varepsilon_{0}a}$$\nThe final state has charge $q + \\delta q$. Its Helmholtz free energy is $F_{\\text{final}}$.\n$$F_{\\text{final}} = U(q + \\delta q) = \\frac{(q + \\delta q)^2}{8\\pi\\varepsilon_{0}a}$$\nThe change in Helmholtz free energy, $\\Delta F$, is the difference between the final and initial free energies.\n$$\\Delta F = F_{\\text{final}} - F_{\\text{initial}}$$\n$$\\Delta F = \\frac{(q + \\delta q)^2}{8\\pi\\varepsilon_{0}a} - \\frac{q^2}{8\\pi\\varepsilon_{0}a}$$\nFactoring out the common term, we get:\n$$\\Delta F = \\frac{1}{8\\pi\\varepsilon_{0}a} \\left[ (q + \\delta q)^2 - q^2 \\right]$$\nExpanding the squared term:\n$$\\Delta F = \\frac{1}{8\\pi\\varepsilon_{0}a} \\left[ (q^2 + 2q\\delta q + (\\delta q)^2) - q^2 \\right]$$\nSimplifying the expression inside the brackets gives the final result from this method:\n$$\\Delta F = \\frac{2q\\delta q + (\\delta q)^2}{8\\pi\\varepsilon_{0}a}$$\n\n**Part 2: Helmholtz Free Energy from the Free Energy Perturbation (FEP) Formula**\n\nThe Free Energy Perturbation (FEP) theorem provides a formal way to calculate the free energy difference between two states, a reference state (denoted by subscript $0$) and a target state (denoted by subscript $1$). The formula is:\n$$\\Delta F = F_1 - F_0 = -k_B T \\ln \\left\\langle \\exp\\left(-\\frac{U_1 - U_0}{k_B T}\\right) \\right\\rangle_0$$\nHere, $\\beta = \\frac{1}{k_B T}$ is the inverse temperature, $U_0$ and $U_1$ are the potential energies of the reference and target states, respectively, and the notation $\\langle \\cdot \\rangle_0$ indicates a canonical ensemble average taken over the microstates of the reference state $0$.\n\nLet us define our states:\n-   Reference state $0$: Charge on the shell is $q$. The system energy is $U_0 = U(q) = \\frac{q^2}{8\\pi\\varepsilon_{0}a}$.\n-   Target state $1$: Charge on the shell is $q + \\delta q$. The system energy is $U_1 = U(q + \\delta q) = \\frac{(q + \\delta q)^2}{8\\pi\\varepsilon_{0}a}$.\n\nThe energy difference is $\\Delta U = U_1 - U_0$.\n$$\\Delta U = \\frac{(q + \\delta q)^2 - q^2}{8\\pi\\varepsilon_{0}a} = \\frac{2q\\delta q + (\\delta q)^2}{8\\pi\\varepsilon_{0}a}$$\nThe ensemble average in the FEP formula is defined as:\n$$\\left\\langle \\exp(-\\beta \\Delta U) \\right\\rangle_0 = \\sum_{i} P_i \\exp(-\\beta \\Delta U_i)$$\nwhere the sum is over all microstates $i$ of the reference system $0$, and $P_i$ is the probability of being in microstate $i$.\n\nAs established in Part 1, the crucial simplification for this problem is that the reference system (with charge $q$) has only one possible microstate. Let this single state be indexed by $i=1$. Its probability is therefore $P_1 = 1$. The energy difference $\\Delta U$ does not depend on any internal coordinates (as there are none), so it is a constant value for the entire \"ensemble\".\n\nThe ensemble average thus collapses to a single term:\n$$\\left\\langle \\exp(-\\beta \\Delta U) \\right\\rangle_0 = (1) \\cdot \\exp(-\\beta \\Delta U) = \\exp(-\\beta \\Delta U)$$\nNow we substitute this simplified average back into the FEP formula:\n$$\\Delta F = -k_B T \\ln \\left[ \\exp(-\\beta \\Delta U) \\right]$$\nUsing the property that $\\ln(\\exp(x)) = x$:\n$$\\Delta F = -k_B T (-\\beta \\Delta U) = k_B T \\beta \\Delta U$$\nSubstituting $\\beta = \\frac{1}{k_B T}$:\n$$\\Delta F = k_B T \\left(\\frac{1}{k_B T}\\right) \\Delta U = \\Delta U$$\nThis demonstrates that for a system with only one microstate (and thus zero entropy), the FEP formula correctly reduces to the statement that the Helmholtz free energy change is equal to the change in the system's potential energy.\n\n$$\\Delta F = U_1 - U_0 = \\frac{2q\\delta q + (\\delta q)^2}{8\\pi\\varepsilon_{0}a}$$\nThis result is identical to the one obtained from first principles, confirming the consistency of the physical model. The final expression for the Helmholtz free energy change is:\n$$\\Delta F = \\frac{2q\\delta q + (\\delta q)^2}{8\\pi\\varepsilon_{0}a}$$\nThe units of this expression are Joules (J) in the SI system, as is required for energy. This is dimensionally consistent, since $\\frac{\\text{charge}^2}{\\text{permittivity} \\times \\text{length}}$ has units of energy.",
            "answer": "$$\\boxed{\\frac{2q\\delta q + (\\delta q)^{2}}{8\\pi \\varepsilon_{0} a}}$$"
        },
        {
            "introduction": "While FEP is a powerful tool, its accuracy depends critically on sufficient overlap between the initial and final state's phase spaces. This computational exercise  allows you to explore this limitation directly using a simple one-dimensional harmonic oscillator model. By systematically increasing the magnitude of the perturbation, you will pinpoint the threshold where the FEP estimate breaks down, providing a tangible understanding of why large, single-step transformations are often unreliable in practice.",
            "id": "2455879",
            "problem": "You are to examine the single-step Free Energy Perturbation (FEP) estimator for a simple, analytically tractable system and determine when it becomes practically unusable, defined here as producing a relative absolute error strictly greater than $1$ (that is, greater than $100$ percent). Consider a classical, one-dimensional harmonic oscillator with initial state $0$ having potential energy $U_0(x) = \\tfrac{1}{2} k_0 x^2$ and perturbed state $1$ having potential energy $U_1(x) = \\tfrac{1}{2} k_1 x^2$. Work in nondimensional units such that the inverse thermal energy is $\\beta = 1$ and choose $k_0 = 1$, so $r = k_1/k_0 = k_1$ is the dimensionless perturbation ratio. The exact Helmholtz free energy difference is\n$$\n\\Delta F_{\\text{true}} = \\tfrac{1}{2} \\ln r,\n$$\nderived from the exact partition function of the harmonic oscillator. The single-step FEP estimator based on $N$ independent and identically distributed samples $x_i$ drawn from the equilibrium distribution of state $0$ with density $p_0(x) \\propto \\exp\\{-U_0(x)\\}$ is\n$$\n\\widehat{\\Delta F}_N = - \\ln\\left( \\frac{1}{N} \\sum_{i=1}^{N} \\exp\\left[-\\left(U_1(x_i) - U_0(x_i)\\right)\\right] \\right).\n$$\nDefine the relative absolute error as\n$$\n\\varepsilon = \n\\begin{cases}\n\\frac{\\left|\\widehat{\\Delta F}_N - \\Delta F_{\\text{true}}\\right|}{\\left|\\Delta F_{\\text{true}}\\right|}, & \\text{if } \\Delta F_{\\text{true}} \\neq 0, \\\\\n0, & \\text{if } \\Delta F_{\\text{true}} = 0 \\text{ and } \\widehat{\\Delta F}_N = 0, \\\\\n+\\infty, & \\text{if } \\Delta F_{\\text{true}} = 0 \\text{ and } \\widehat{\\Delta F}_N \\neq 0.\n\\end{cases}\n$$\nFor a given finite set of candidate ratios $r \\in \\mathcal{R}$, define the perturbation magnitude as\n$$\nm(r) = \\max\\{r, 1/r\\},\n$$\nand define the threshold magnitude for a given test case as the smallest $m(r)$ among all $r \\in \\mathcal{R}$ for which $\\varepsilon > 1$. If no $r \\in \\mathcal{R}$ yields $\\varepsilon > 1$, output $-1.0$.\n\nYour task is to implement a complete program that, for each of the following test cases, computes the threshold magnitude as defined above. All computations are to be performed in the nondimensionalized setting described, and the final outputs must be floats.\n\nTest suite:\n- Case A: $N = 8$, $\\mathcal{R} = \\{1.0, 2.0, 4.0, 8.0, 16.0\\}$.\n- Case B: $N = 64$, $\\mathcal{R} = \\{0.9, 0.7, 0.5, 0.3, 0.2, 2.0, 4.0, 8.0\\}$.\n- Case C: $N = 1024$, $\\mathcal{R} = \\{0.2, 0.1, 8.0, 16.0\\}$.\n\nFinal output format:\nYour program should produce a single line of output containing the three threshold magnitudes for the cases A, B, C, respectively, as a comma-separated list enclosed in square brackets (for example, \"[2.0,-1.0,8.0]\"). All outputs are dimensionless floats.",
            "solution": "The problem requires an analysis of the single-step Free Energy Perturbation (FEP) estimator's practical usability limit, which is defined as the point where the relative absolute error $\\varepsilon$ exceeds $1$. The system under consideration is a one-dimensional classical harmonic oscillator transitioning from an initial state $0$ to a perturbed state $1$.\n\nThe potential energies for the states are given by $U_0(x) = \\frac{1}{2} k_0 x^2$ and $U_1(x) = \\frac{1}{2} k_1 x^2$. The problem operates in nondimensional units where the inverse thermal energy is $\\beta = (k_B T)^{-1} = 1$ and the initial spring constant is $k_0 = 1$. The perturbation is characterized by the dimensionless ratio $r = k_1/k_0 = k_1$.\n\nThe equilibrium probability distribution of the initial state $0$ is given by the Boltzmann distribution, $p_0(x) \\propto \\exp(-\\beta U_0(x))$. With the specified parameters, this becomes $p_0(x) \\propto \\exp(-\\frac{1}{2}x^2)$. This is the probability density function of a standard normal distribution, $\\mathcal{N}(0, 1)$. Therefore, generating the $N$ independent and identically distributed samples $\\{x_i\\}_{i=1}^N$ from the equilibrium distribution of state $0$ is correctly implemented by drawing $N$ random variates from $\\mathcal{N}(0, 1)$.\n\nThe single-step FEP estimator (also known as the Zwanzig equation) for the Helmholtz free energy difference, $\\Delta F = F_1 - F_0$, is given by:\n$$\n\\widehat{\\Delta F}_N = - \\frac{1}{\\beta} \\ln\\left\\langle \\exp\\left[-\\beta\\left(U_1(x) - U_0(x)\\right)\\right] \\right\\rangle_0\n$$\nThe angle brackets $\\langle \\cdot \\rangle_0$ denote an ensemble average over configurations $x$ drawn from the distribution of state $0$. For a finite sample of size $N$, this is approximated by a simple arithmetic mean:\n$$\n\\widehat{\\Delta F}_N = - \\frac{1}{\\beta} \\ln\\left( \\frac{1}{N} \\sum_{i=1}^{N} \\exp\\left[-\\beta\\left(U_1(x_i) - U_0(x_i)\\right)\\right] \\right)\n$$\nGiven $\\beta=1$, the potential energy difference is $\\Delta U(x_i) = U_1(x_i) - U_0(x_i) = \\frac{1}{2}k_1 x_i^2 - \\frac{1}{2}k_0 x_i^2 = \\frac{1}{2}(r-1)x_i^2$. The working formula for the estimator is therefore:\n$$\n\\widehat{\\Delta F}_N = - \\ln\\left( \\frac{1}{N} \\sum_{i=1}^{N} \\exp\\left[-\\frac{1}{2}(r-1)x_i^2\\right] \\right)\n$$\nThe exact analytical solution for the free energy difference for this system is $\\Delta F_{\\text{true}} = \\frac{1}{2\\beta} \\ln(k_1/k_0)$, which simplifies to $\\Delta F_{\\text{true}} = \\frac{1}{2}\\ln r$. The error is evaluated using the relative absolute error $\\varepsilon$, as defined in the problem statement.\n\nA critical consideration for the reliability of the FEP estimator is the variance of the exponential term, $W = \\exp(-\\beta \\Delta U)$. The variance of the estimator $\\widehat{\\Delta F}_N$ is related to $\\text{Var}(W) = \\langle W^2 \\rangle_0 - \\langle W \\rangle_0^2$. The second moment, $\\langle W^2 \\rangle_0$, is given by the integral:\n$$\n\\langle W^2 \\rangle_0 = \\int_{-\\infty}^{\\infty} \\exp\\left[-2\\beta \\Delta U(x)\\right] p_0(x) dx = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}}\\exp\\left[-(r-1)x^2\\right] \\exp\\left[-\\frac{1}{2}x^2\\right] dx\n$$\n$$\n\\langle W^2 \\rangle_0 = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} \\exp\\left[-\\left( (r-1) + \\frac{1}{2} \\right)x^2\\right] dx\n$$\nFor this Gaussian integral to converge, the quadratic term in the exponent must be positive: $(r-1) + \\frac{1}{2} > 0$, which simplifies to $r > \\frac{1}{2}$. If $r \\le \\frac{1}{2}$, the variance of $W$ is infinite. This indicates that the FEP estimator is statistically ill-behaved; a finite sample average will be dominated by rare, extreme events and will not reliably converge. Consequently, large errors are expected for any $r \\le \\frac{1}{2}$.\n\nFurthermore, for $r \\gg 1$, the target potential $U_1$ is much narrower (steeper) than the sampling potential $U_0$. The sampling distribution $p_0(x)$ is broad, while the term being averaged, $ W(x) = \\exp[-\\frac{1}{2}(r-1)x^2] $, is very sharply peaked at $x=0$. This signifies poor phase space overlap. Most samples $x_i$ will be drawn from regions where $W(x_i)$ is practically zero, leading to a systematic underestimation of the true average. This undersampling also results in high variance and large errors.\n\nThus, the FEP estimator is expected to fail (i.e., yield $\\varepsilon > 1$) for both large perturbation ratios ($r \\gg 1$) and for ratios $r \\le \\frac{1}{2}$. The task is to find the smallest perturbation magnitude, $m(r) = \\max\\{r, 1/r\\}$, for which this failure occurs for a given set of ratios $\\mathcal{R}$.\n\nThe computational algorithm proceeds as follows for each test case $(N, \\mathcal{R})$:\n$1$. A fixed random seed is used to ensure the stochastic results are reproducible.\n$2$. For each test case, initialize an empty list to store the magnitudes $m(r)$ for which the error criterion $\\varepsilon > 1$ is met.\n$3$. Iterate through each ratio $r \\in \\mathcal{R}$:\n    a. If $r=1$, then $\\Delta F_{\\text{true}} = 0$ and $\\widehat{\\Delta F}_N = 0$, so $\\varepsilon=0$. The criterion is not met.\n    b. If $r \\ne 1$, generate $N$ samples $\\{x_i\\}$ from $\\mathcal{N}(0, 1)$.\n    c. Calculate $\\Delta F_{\\text{true}} = \\frac{1}{2}\\ln r$.\n    d. Calculate the estimate $\\widehat{\\Delta F}_N$ using the FEP formula.\n    e. Compute the relative absolute error $\\varepsilon = |\\widehat{\\Delta F}_N - \\Delta F_{\\text{true}}| / |\\Delta F_{\\text{true}}|$.\n    f. If $\\varepsilon > 1$, calculate the perturbation magnitude $m(r) = \\max\\{r, 1/r\\}$ and add it to the list of failing magnitudes.\n$4$. After evaluating all $r \\in \\mathcal{R}$, the threshold magnitude is determined. If the list of failing magnitudes is empty, the result for the test case is $-1.0$. Otherwise, the result is the minimum value in this list. This procedure is repeated for all test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the threshold perturbation magnitude for FEP estimator failure.\n    \"\"\"\n    \n    # Set a fixed random seed for reproducibility of the stochastic simulation.\n    np.random.seed(0)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: (N, R_set)\n        (8, [1.0, 2.0, 4.0, 8.0, 16.0]),\n        # Case B: (N, R_set)\n        (64, [0.9, 0.7, 0.5, 0.3, 0.2, 2.0, 4.0, 8.0]),\n        # Case C: (N, R_set)\n        (1024, [0.2, 0.1, 8.0, 16.0]),\n    ]\n\n    results = []\n    \n    for N, R_set in test_cases:\n        failing_magnitudes = []\n        \n        for r in R_set:\n            # Case r=1 is a special case.\n            # Delta_F_true is 0. Delta_U is 0, so exp(-Delta_U) is 1.\n            # The average is 1, and log(1) is 0. So F_est is 0.\n            # Per problem definition, error is 0.\n            if r == 1.0:\n                error = 0.0\n            else:\n                # 1. Generate N samples from the equilibrium distribution of state 0,\n                # which is a standard normal distribution N(0, 1).\n                # The parameters k0=1 and beta=1 lead to variance = (k0*beta)^-1 = 1.\n                x_samples = np.random.randn(N)\n                \n                # 2. Calculate the true free energy difference.\n                delta_F_true = 0.5 * np.log(r)\n                \n                # 3. Calculate the FEP estimate.\n                # Delta_U = 0.5 * (k1 - k0) * x^2, with k1=r, k0=1.\n                delta_U = 0.5 * (r - 1.0) * x_samples**2\n                \n                # The argument of the logarithm in the FEP formula\n                fep_average = np.mean(np.exp(-delta_U))\n                \n                # The FEP estimate\n                # The average is always > 0, so no domain error for log.\n                delta_F_est = -np.log(fep_average)\n                \n                # 4. Calculate the relative absolute error.\n                # The case delta_F_true == 0 is handled by r == 1.0 check.\n                error = np.abs(delta_F_est - delta_F_true) / np.abs(delta_F_true)\n\n            # 5. Check if the error exceeds the threshold.\n            if error > 1.0:\n                perturbation_magnitude = max(r, 1.0 / r)\n                failing_magnitudes.append(perturbation_magnitude)\n                \n        # 6. Determine the threshold magnitude for the test case.\n        if not failing_magnitudes:\n            threshold_magnitude = -1.0\n        else:\n            threshold_magnitude = min(failing_magnitudes)\n        \n        results.append(threshold_magnitude)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "In real-world applications, such as comparing the potency of several drug candidates, we often compute multiple related free energy differences. Since Gibbs free energy is a state function, these calculations must be thermodynamically consistent around a closed loop. This practice problem  guides you through a vital quality control procedure: the cycle-closure test, which combines thermodynamic principles with statistical error analysis to validate the consistency and reliability of your FEP results.",
            "id": "2455881",
            "problem": "In free energy perturbation (FEP), relative Gibbs free energy changes between states are estimated from molecular simulations. For three alchemical mutations $A \\to B$, $B \\to C$, and $A \\to C$, suppose you have independently obtained the following estimates (means and standard errors), in $\\mathrm{kcal\\,mol^{-1}}$:\n- $\\Delta G_{A \\to B} = 1.20 \\pm 0.30$\n- $\\Delta G_{B \\to C} = -0.80 \\pm 0.40$\n- $\\Delta G_{A \\to C} = 0.50 \\pm 0.35$\n\nSelect the option that correctly defines a statistically sound cycle-closure consistency test at $95\\%$ confidence for this three-state set and correctly evaluates whether these data pass that test.\n\nA. Define the cycle-closure residual as $\\varepsilon = \\Delta G_{A \\to B} + \\Delta G_{B \\to C} - \\Delta G_{A \\to C}$, and, assuming independent estimates, the uncertainty as $\\sigma_{\\varepsilon} = \\sqrt{\\sigma_{A \\to B}^{2} + \\sigma_{B \\to C}^{2} + \\sigma_{A \\to C}^{2}}$. Declare the cycle consistent if $\\lvert \\varepsilon \\rvert \\le 1.96\\, \\sigma_{\\varepsilon}$; with the given data, the cycle passes.\n\nB. Enforce thermodynamic consistency by requiring $\\Delta G_{A \\to B} + \\Delta G_{B \\to C} + \\Delta G_{A \\to C} = 0$ exactly; with the given data, the cycle fails.\n\nC. Define the closure residual as $\\varepsilon = \\Delta G_{A \\to B} + \\Delta G_{B \\to C} - \\Delta G_{A \\to C}$, and the uncertainty as $\\sigma_{\\varepsilon} = \\sigma_{A \\to B} + \\sigma_{B \\to C} + \\sigma_{A \\to C}$. Declare the cycle consistent if $\\lvert \\varepsilon \\rvert \\le 1.96\\, \\sigma_{\\varepsilon}$; with the given data, the cycle passes.\n\nD. Define the closure residual as $\\varepsilon = \\Delta G_{A \\to B} + \\Delta G_{B \\to C} + \\Delta G_{C \\to A}$, taking $\\Delta G_{C \\to A} = \\Delta G_{A \\to C}$, and combine uncertainties as $\\sigma_{\\varepsilon} = \\sqrt{\\sigma_{A \\to B}^{2} + \\sigma_{B \\to C}^{2} + \\sigma_{A \\to C}^{2}}$. Declare the cycle consistent if $\\lvert \\varepsilon \\rvert \\le \\sigma_{\\varepsilon}$; with the given data, the cycle passes.\n\nE. Define the closure residual as $\\varepsilon = \\Delta G_{A \\to C} - \\left(\\Delta G_{A \\to B} + \\Delta G_{B \\to C}\\right)$ and its uncertainty as the average $\\sigma_{\\varepsilon} = \\left(\\sigma_{A \\to B} + \\sigma_{B \\to C} + \\sigma_{A \\to C}\\right)/3$. Declare consistency if $\\lvert \\varepsilon \\rvert \\le 1.96\\, \\sigma_{\\varepsilon}$; with the given data, the cycle fails.",
            "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\nThe provided information is as follows:\n- A thermodynamic cycle involving three states, $A$, $B$, and $C$, is considered.\n- The relative Gibbs free energy changes are estimated from independent molecular simulations.\n- $\\Delta G_{A \\to B} = 1.20 \\pm 0.30 \\, \\mathrm{kcal\\,mol^{-1}}$ (mean $\\pm$ standard error).\n- $\\Delta G_{B \\to C} = -0.80 \\pm 0.40 \\, \\mathrm{kcal\\,mol^{-1}}$ (mean $\\pm$ standard error).\n- $\\Delta G_{A \\to C} = 0.50 \\pm 0.35 \\, \\mathrm{kcal\\,mol^{-1}}$ (mean $\\pm$ standard error).\n- The task is to identify a statistically sound cycle-closure consistency test at $95\\%$ confidence and evaluate it with the given data.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is based on the fundamental principle that Gibbs free energy is a state function, a cornerstone of thermodynamics. The application of statistical error analysis (propagation of uncertainty, confidence intervals) to computational chemistry results (FEP simulations) is a standard and rigorous practice in the field. The provided numerical values are physically plausible. The problem is scientifically sound.\n- **Well-Posedness**: The problem is well-posed. It provides all necessary data (means and standard errors of independent measurements) to construct a statistical test for cycle closure. The question is precise and allows for a unique, determinable answer based on established statistical methods.\n- **Objectivity**: The problem is stated objectively using quantitative data and established scientific terminology. It is free of ambiguity or subjective claims.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. It is a standard exercise in the statistical analysis of simulation data. I shall proceed with the derivation and evaluation.\n\n### Derivation\n\nThe analysis rests on two principles: one from thermodynamics and one from statistics.\n\n**1. Thermodynamic Principle:**\nGibbs free energy, $G$, is a state function. This implies that for any cyclic path, the net change in free energy is zero. For the cycle $A \\to B \\to C \\to A$, we have:\n$$ \\Delta G_{\\text{cycle}} = \\Delta G_{A \\to B} + \\Delta G_{B \\to C} + \\Delta G_{C \\to A} = 0 $$\nFurthermore, the free energy change for a reverse process is the negative of the forward process: $\\Delta G_{C \\to A} = - \\Delta G_{A \\to C}$. Substituting this into the cycle equation gives the condition for ideal cycle closure:\n$$ \\Delta G_{A \\to B} + \\Delta G_{B \\to C} - \\Delta G_{A \\to C} = 0 $$\nThis equation defines the ideal relationship that the true mean values should satisfy.\n\n**2. Statistical Principle:**\nThe values provided are not the true, exact free energies, but are *estimates* from finite simulations, each with an associated statistical error (standard error of the mean). We must therefore test whether the observed deviation from ideal closure is statistically significant.\n\nWe define a cycle-closure residual, $\\varepsilon$, as the deviation from the expected value of zero:\n$$ \\varepsilon = \\Delta G_{A \\to B} + \\Delta G_{B \\to C} - \\Delta G_{A \\to C} $$\nUsing the given mean values, we calculate the observed residual:\n$$ \\varepsilon = 1.20 \\, \\mathrm{kcal\\,mol^{-1}} + (-0.80 \\, \\mathrm{kcal\\,mol^{-1}}) - 0.50 \\, \\mathrm{kcal\\,mol^{-1}} = -0.10 \\, \\mathrm{kcal\\,mol^{-1}} $$\nThe problem states the estimates are \"independently obtained\". For a quantity $Y = c_1 X_1 + c_2 X_2 + c_3 X_3$ where $X_i$ are independent random variables with variances $\\sigma_{X_i}^2$, the variance of $Y$ is $\\sigma_Y^2 = c_1^2 \\sigma_{X_1}^2 + c_2^2 \\sigma_{X_2}^2 + c_3^2 \\sigma_{X_3}^2$. In our case, $\\Delta G_{A \\to B}$, $\\Delta G_{B \\to C}$, and $\\Delta G_{A \\to C}$ are the independent variables, and the coefficients are $c_1=1$, $c_2=1$, and $c_3=-1$. The variance of the residual, $\\sigma_{\\varepsilon}^2$, is therefore:\n$$ \\sigma_{\\varepsilon}^2 = (1)^2 \\sigma_{A \\to B}^2 + (1)^2 \\sigma_{B \\to C}^2 + (-1)^2 \\sigma_{A \\to C}^2 = \\sigma_{A \\to B}^2 + \\sigma_{B \\to C}^2 + \\sigma_{A \\to C}^2 $$\nThe standard error of the residual, $\\sigma_{\\varepsilon}$, is the square root of the variance:\n$$ \\sigma_{\\varepsilon} = \\sqrt{\\sigma_{A \\to B}^2 + \\sigma_{B \\to C}^2 + \\sigma_{A \\to C}^2} $$\nSubstituting the given standard errors:\n$$ \\sigma_{\\varepsilon} = \\sqrt{(0.30)^2 + (0.40)^2 + (0.35)^2} = \\sqrt{0.09 + 0.16 + 0.1225} = \\sqrt{0.3725} \\approx 0.6103 \\, \\mathrm{kcal\\,mol^{-1}} $$\nA test at $95\\%$ confidence checks if the ideal value of $0$ is within the $95\\%$ confidence interval of our estimated residual. Assuming the Central Limit Theorem holds and the errors are approximately normally distributed, this interval is $\\varepsilon \\pm 1.96 \\, \\sigma_{\\varepsilon}$. The cycle is considered consistent if $0$ lies within this interval, which simplifies to the condition:\n$$ \\lvert \\varepsilon \\rvert \\le 1.96 \\, \\sigma_{\\varepsilon} $$\nLet us evaluate this condition with our calculated values:\n- Left side: $\\lvert \\varepsilon \\rvert = \\lvert -0.10 \\rvert = 0.10$.\n- Right side: $1.96 \\, \\sigma_{\\varepsilon} \\approx 1.96 \\times 0.6103 \\approx 1.196$.\n\nThe condition is $0.10 \\le 1.196$, which is true. The cycle is consistent at the $95\\%$ confidence level; the data pass the test.\n\n### Option-by-Option Analysis\n\n**A. Define the cycle-closure residual as $\\varepsilon = \\Delta G_{A \\to B} + \\Delta G_{B \\to C} - \\Delta G_{A \\to C}$, and, assuming independent estimates, the uncertainty as $\\sigma_{\\varepsilon} = \\sqrt{\\sigma_{A \\to B}^{2} + \\sigma_{B \\to C}^{2} + \\sigma_{A \\to C}^{2}}$. Declare the cycle consistent if $\\lvert \\varepsilon \\rvert \\le 1.96\\, \\sigma_{\\varepsilon}$; with the given data, the cycle passes.**\n- The definition of the residual $\\varepsilon$ is correct based on thermodynamic principles.\n- The formula for propagating uncertainty (standard error $\\sigma_{\\varepsilon}$) is correct for a sum of independent variables.\n- The statistical test $\\lvert \\varepsilon \\rvert \\le 1.96\\, \\sigma_{\\varepsilon}$ is the correct criterion for $95\\%$ confidence.\n- The evaluation \"the cycle passes\" matches our derivation.\n- **Verdict: Correct.**\n\n**B. Enforce thermodynamic consistency by requiring $\\Delta G_{A \\to B} + \\Delta G_{B \\to C} + \\Delta G_{A \\to C} = 0$ exactly; with the given data, the cycle fails.**\n- The formula $\\Delta G_{A \\to B} + \\Delta G_{B \\to C} + \\Delta G_{A \\to C} = 0$ is thermodynamically incorrect; it should be $\\Delta G_{A \\to B} + \\Delta G_{B \\to C} - \\Delta G_{A \\to C} = 0$.\n- More importantly, requiring an exact equality for statistical estimates is fundamentally flawed logic. It completely ignores the nature of statistical uncertainty inherent in the measurements. This is a deterministic, not a statistical, test.\n- **Verdict: Incorrect.**\n\n**C. Define the closure residual as $\\varepsilon = \\Delta G_{A \\to B} + \\Delta G_{B \\to C} - \\Delta G_{A \\to C}$, and the uncertainty as $\\sigma_{\\varepsilon} = \\sigma_{A \\to B} + \\sigma_{B \\to C} + \\sigma_{A \\to C}$. Declare the cycle consistent if $\\lvert \\varepsilon \\rvert \\le 1.96\\, \\sigma_{\\varepsilon}$; with the given data, the cycle passes.**\n- The definition of the residual $\\varepsilon$ is correct.\n- The formula for the uncertainty, $\\sigma_{\\varepsilon} = \\sigma_{A \\to B} + \\sigma_{B \\to C} + \\sigma_{A \\to C}$, is incorrect. Standard errors add in quadrature (sum of squares), not linearly. This is a gross violation of error propagation rules for independent variables.\n- **Verdict: Incorrect.**\n\n**D. Define the closure residual as $\\varepsilon = \\Delta G_{A \\to B} + \\Delta G_{B \\to C} + \\Delta G_{C \\to A}$, taking $\\Delta G_{C \\to A} = \\Delta G_{A \\to C}$, and combine uncertainties as $\\sigma_{\\varepsilon} = \\sqrt{\\sigma_{A \\to B}^{2} + \\sigma_{B \\to C}^{2} + \\sigma_{A \\to C}^{2}}$. Declare the cycle consistent if $\\lvert \\varepsilon \\rvert \\le \\sigma_{\\varepsilon}$; with the given data, the cycle passes.**\n- The definition of the residual uses the assumption $\\Delta G_{C \\to A} = \\Delta G_{A \\to C}$, which is thermodynamically incorrect. The correct relation is $\\Delta G_{C \\to A} = - \\Delta G_{A \\to C}$.\n- The consistency test $\\lvert \\varepsilon \\rvert \\le \\sigma_{\\varepsilon}$ corresponds to a confidence level of approximately $68\\%$ (one standard deviation), not the required $95\\%$.\n- The option contains at least two fundamental errors.\n- **Verdict: Incorrect.**\n\n**E. Define the closure residual as $\\varepsilon = \\Delta G_{A \\to C} - \\left(\\Delta G_{A \\to B} + \\Delta G_{B \\to C}\\right)$ and its uncertainty as the average $\\sigma_{\\varepsilon} = \\left(\\sigma_{A \\to B} + \\sigma_{B \\to C} + \\sigma_{A \\to C}\\right)/3$. Declare consistency if $\\lvert \\varepsilon \\rvert \\le 1.96\\, \\sigma_{\\varepsilon}$; with the given data, the cycle fails.**\n- The definition of the uncertainty as the arithmetic average of the standard errors is baseless in statistics. There is no principle that justifies this combination rule for error propagation.\n- Furthermore, the evaluation \"the cycle fails\" is a miscalculation even with the flawed formula. As calculated in the derivation, $\\lvert \\varepsilon \\rvert = 0.10$. Using the flawed uncertainty formula, $\\sigma_{\\varepsilon} = (0.30 + 0.40 + 0.35)/3 = 0.35$. Then $1.96\\,\\sigma_{\\varepsilon} = 1.96 \\times 0.35 = 0.686$. Since $0.10 \\le 0.686$, the cycle would pass this test. The option contradicts itself.\n- **Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}