{
    "hands_on_practices": [
        {
            "introduction": "The efficiency of a Replica Exchange Molecular Dynamics (REMD) simulation is gauged by the swap acceptance rate between adjacent temperatures. This exercise bridges statistical theory and simulation analysis, asking you to predict this rate from first principles . By applying the powerful Gaussian approximation for energy fluctuations to simulated energy data, you will derive and compute the expected probability of a successful temperature swap, a fundamental skill for interpreting REMD performance.",
            "id": "2666608",
            "problem": "In Replica Exchange Molecular Dynamics (REMD), two replicas at inverse temperatures $\\beta_1$ and $\\beta_2$ attempt a swap of temperatures with Metropolis acceptance probability given by $\\min\\!\\left(1,\\exp\\!\\left((\\beta_1-\\beta_2)\\,(E_1-E_2)\\right)\\right)$, where $E_1$ and $E_2$ are the instantaneous potential energies sampled independently from the canonical ensembles at temperatures $T_1$ and $T_2$. Consider two adjacent temperatures $T_1=300\\ \\mathrm{K}$ and $T_2=330\\ \\mathrm{K}$. Suppose the measured energy statistics at these temperatures (energies expressed per mole) are approximately Gaussian with means $\\mu_1=-500.0\\ \\mathrm{kJ\\,mol^{-1}}$ and $\\mu_2=-440.0\\ \\mathrm{kJ\\,mol^{-1}}$, and variances $\\sigma_1^2=1496.6033\\ \\mathrm{kJ^2\\,mol^{-2}}$ and $\\sigma_2^2=1810.8900\\ \\mathrm{kJ^2\\,mol^{-2}}$. Assume the two energy samples are independent and that the Gaussian approximation for the canonical energy distribution is valid.\n\nStarting only from the canonical ensemble definition, the Metropolis acceptance criterion for exchanges, and the independence and Gaussian assumptions stated above, derive an analytic expression for the expected swap acceptance probability under these conditions and evaluate it numerically. Use the gas constant $R=0.008314462618\\ \\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$ so that $\\beta_i = 1/(R T_i)$ is consistent with the per-mole energy units. Round your final expected acceptance probability to four significant figures. Express the final answer as a pure number (no units).",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. All necessary data and well-defined assumptions are provided. It represents a standard calculation in the analysis of Replica Exchange Molecular Dynamics simulations. Therefore, the problem is valid, and a solution will be provided.\n\nThe objective is to compute the expected value of the Metropolis acceptance probability, $\\langle P_{\\text{acc}} \\rangle$, for a swap between two replicas at inverse temperatures $\\beta_1$ and $\\beta_2$. The acceptance probability is given by\n$$\nP_{\\text{acc}}(E_1, E_2) = \\min\\!\\left(1, \\exp\\!\\left((\\beta_1-\\beta_2)(E_1-E_2)\\right)\\right)\n$$\nwhere $E_1$ and $E_2$ are the potential energies of the replicas. These are random variables drawn independently from their respective canonical ensembles. The problem states that these energy distributions are approximated as Gaussian: $E_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2)$ and $E_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2^2)$.\n\nLet us define the difference in inverse temperature $\\Delta\\beta = \\beta_1 - \\beta_2$ and the difference in energy $\\Delta E = E_1 - E_2$. The acceptance probability simplifies to $P_{\\text{acc}}(\\Delta E) = \\min(1, \\exp(\\Delta\\beta \\Delta E))$. Since $E_1$ and $E_2$ are independent Gaussian random variables, their difference, $\\Delta E$, is also a Gaussian random variable. Its distribution is $\\Delta E \\sim \\mathcal{N}(\\mu_{\\Delta}, \\sigma_{\\Delta}^2)$, with parameters:\nMean: $\\mu_{\\Delta} = \\mathbb{E}[E_1 - E_2] = \\mathbb{E}[E_1] - \\mathbb{E}[E_2] = \\mu_1 - \\mu_2$.\nVariance: $\\sigma_{\\Delta}^2 = \\text{Var}(E_1 - E_2) = \\text{Var}(E_1) + \\text{Var}(-E_2) = \\text{Var}(E_1) + (-1)^2\\text{Var}(E_2) = \\sigma_1^2 + \\sigma_2^2$.\n\nThe expected acceptance probability is found by integrating over the probability distribution of $\\Delta E$, which we denote by $p_{\\Delta}(x)$:\n$$\n\\langle P_{\\text{acc}} \\rangle = \\mathbb{E}[P_{\\text{acc}}(\\Delta E)] = \\int_{-\\infty}^{\\infty} \\min(1, \\exp(\\Delta\\beta x)) p_{\\Delta}(x) dx\n$$\nwhere $p_{\\Delta}(x) = \\frac{1}{\\sqrt{2\\pi\\sigma_{\\Delta}^2}} \\exp\\left(-\\frac{(x - \\mu_{\\Delta})^2}{2\\sigma_{\\Delta}^2}\\right)$.\n\nGiven $T_1 = 300\\ \\mathrm{K}$ and $T_2 = 330\\ \\mathrm{K}$, we have $T_1 < T_2$, which implies $\\beta_1 = 1/(RT_1) > 1/(RT_2) = \\beta_2$. Thus, $\\Delta\\beta > 0$. This allows us to split the integral based on the sign of the argument of the exponential, $\\Delta\\beta x$. Since $\\Delta\\beta > 0$, the sign is determined by $x = \\Delta E$:\n- If $x > 0$, then $\\Delta\\beta x > 0$, so $\\exp(\\Delta\\beta x) > 1$, and $\\min(1, \\exp(\\Delta\\beta x)) = 1$.\n- If $x \\le 0$, then $\\Delta\\beta x \\le 0$, so $\\exp(\\Delta\\beta x) \\le 1$, and $\\min(1, \\exp(\\Delta\\beta x)) = \\exp(\\Delta\\beta x)$.\n\nThe expectation integral is therefore split into two parts:\n$$\n\\langle P_{\\text{acc}} \\rangle = \\int_{0}^{\\infty} 1 \\cdot p_{\\Delta}(x) dx + \\int_{-\\infty}^{0} \\exp(\\Delta\\beta x) p_{\\Delta}(x) dx\n$$\nThe first integral is the probability that $\\Delta E > 0$, which can be expressed using the cumulative distribution function (CDF) of the standard normal distribution, $\\Phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^z \\exp(-t^2/2) dt$.\n$$\n\\int_{0}^{\\infty} p_{\\Delta}(x) dx = P(\\Delta E > 0) = 1 - P(\\Delta E \\le 0) = 1 - \\Phi\\left(\\frac{0 - \\mu_{\\Delta}}{\\sigma_{\\Delta}}\\right) = 1 - \\Phi\\left(-\\frac{\\mu_{\\Delta}}{\\sigma_{\\Delta}}\\right) = \\Phi\\left(\\frac{\\mu_{\\Delta}}{\\sigma_{\\Delta}}\\right)\n$$\nThe second integral requires us to combine the exponential terms in the integrand:\n$$\n\\int_{-\\infty}^{0} \\exp(\\Delta\\beta x) \\frac{1}{\\sqrt{2\\pi\\sigma_{\\Delta}^2}} \\exp\\left(-\\frac{(x - \\mu_{\\Delta})^2}{2\\sigma_{\\Delta}^2}\\right) dx\n$$\nThe argument of the total exponential is $\\Delta\\beta x - \\frac{(x - \\mu_{\\Delta})^2}{2\\sigma_{\\Delta}^2}$. We complete the square with respect to $x$:\n$$\n-\\frac{1}{2\\sigma_{\\Delta}^2} [x^2 - 2x\\mu_{\\Delta} + \\mu_{\\Delta}^2 - 2\\sigma_{\\Delta}^2\\Delta\\beta x] = -\\frac{1}{2\\sigma_{\\Delta}^2} [x^2 - 2x(\\mu_{\\Delta} + \\sigma_{\\Delta}^2\\Delta\\beta) + \\mu_{\\Delta}^2]\n$$\nLet $\\mu' = \\mu_{\\Delta} + \\sigma_{\\Delta}^2\\Delta\\beta$. The term in the brackets is rewritten as:\n$$\n[x - \\mu']^2 - (\\mu')^2 + \\mu_{\\Delta}^2 = [x - \\mu']^2 - (\\mu_{\\Delta}^2 + 2\\mu_{\\Delta}\\sigma_{\\Delta}^2\\Delta\\beta + (\\sigma_{\\Delta}^2\\Delta\\beta)^2) + \\mu_{\\Delta}^2 = [x - \\mu']^2 - 2\\mu_{\\Delta}\\sigma_{\\Delta}^2\\Delta\\beta - \\sigma_{\\Delta}^4(\\Delta\\beta)^2\n$$\nThe exponent becomes:\n$$\n-\\frac{(x - \\mu')^2}{2\\sigma_{\\Delta}^2} + \\frac{2\\mu_{\\Delta}\\sigma_{\\Delta}^2\\Delta\\beta + \\sigma_{\\Delta}^4(\\Delta\\beta)^2}{2\\sigma_{\\Delta}^2} = -\\frac{(x - \\mu')^2}{2\\sigma_{\\Delta}^2} + \\mu_{\\Delta}\\Delta\\beta + \\frac{\\sigma_{\\Delta}^2(\\Delta\\beta)^2}{2}\n$$\nThe second integral is now:\n$$\n\\int_{-\\infty}^{0} \\exp\\left(\\mu_{\\Delta}\\Delta\\beta + \\frac{\\sigma_{\\Delta}^2(\\Delta\\beta)^2}{2}\\right) \\frac{1}{\\sqrt{2\\pi\\sigma_{\\Delta}^2}} \\exp\\left(-\\frac{(x - \\mu')^2}{2\\sigma_{\\Delta}^2}\\right) dx\n$$\nThe constant exponential factor can be moved outside the integral. The remaining integral is the probability $P(X' \\le 0)$ for a Gaussian variable $X' \\sim \\mathcal{N}(\\mu', \\sigma_{\\Delta}^2)$.\n$$\nP(X' \\le 0) = \\Phi\\left(\\frac{0 - \\mu'}{\\sigma_{\\Delta}}\\right) = \\Phi\\left(-\\frac{\\mu_{\\Delta} + \\sigma_{\\Delta}^2\\Delta\\beta}{\\sigma_{\\Delta}}\\right)\n$$\nCombining all parts, the final analytic expression is:\n$$\n\\langle P_{\\text{acc}} \\rangle = \\Phi\\left(\\frac{\\mu_{\\Delta}}{\\sigma_{\\Delta}}\\right) + \\exp\\left(\\mu_{\\Delta}\\Delta\\beta + \\frac{\\sigma_{\\Delta}^2(\\Delta\\beta)^2}{2}\\right) \\Phi\\left(-\\frac{\\mu_{\\Delta} + \\sigma_{\\Delta}^2\\Delta\\beta}{\\sigma_{\\Delta}}\\right)\n$$\nNow, we substitute the given numerical values.\n$R = 0.008314462618\\ \\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$.\nTemperatures: $T_1 = 300\\ \\mathrm{K}$, $T_2 = 330\\ \\mathrm{K}$.\n$\\Delta\\beta = \\frac{1}{R}\\left(\\frac{1}{T_1} - \\frac{1}{T_2}\\right) = \\frac{1}{0.008314462618}\\left(\\frac{1}{300} - \\frac{1}{330}\\right) = \\frac{1}{0.008314462618}\\left(\\frac{30}{99000}\\right) \\approx 0.036446164\\ (\\mathrm{kJ\\,mol^{-1}})^{-1}$.\n\nEnergy statistics:\n$\\mu_1 = -500.0\\ \\mathrm{kJ\\,mol^{-1}}$, $\\mu_2 = -440.0\\ \\mathrm{kJ\\,mol^{-1}}$.\n$\\sigma_1^2 = 1496.6033\\ \\mathrm{kJ^2\\,mol^{-2}}$, $\\sigma_2^2 = 1810.8900\\ \\mathrm{kJ^2\\,mol^{-2}}$.\n\nParameters for the $\\Delta E$ distribution:\n$\\mu_{\\Delta} = \\mu_1 - \\mu_2 = -500.0 - (-440.0) = -60.0\\ \\mathrm{kJ\\,mol^{-1}}$.\n$\\sigma_{\\Delta}^2 = \\sigma_1^2 + \\sigma_2^2 = 1496.6033 + 1810.8900 = 3307.4933\\ \\mathrm{kJ^2\\,mol^{-2}}$.\n$\\sigma_{\\Delta} = \\sqrt{3307.4933} \\approx 57.5108085\\ \\mathrm{kJ\\,mol^{-1}}$.\n\nWe calculate the arguments for the functions in the analytic expression:\nArgument of the first $\\Phi$: $\\frac{\\mu_{\\Delta}}{\\sigma_{\\Delta}} = \\frac{-60.0}{57.5108085} \\approx -1.043282$.\n$\\Phi(-1.043282) \\approx 0.14841$.\n\nExponent of the exponential term: $\\mu_{\\Delta}\\Delta\\beta + \\frac{\\sigma_{\\Delta}^2(\\Delta\\beta)^2}{2}$\nTerm 1: $\\mu_{\\Delta}\\Delta\\beta = -60.0 \\times 0.036446164 \\approx -2.186770$.\nTerm 2: $\\frac{\\sigma_{\\Delta}^2(\\Delta\\beta)^2}{2} = \\frac{3307.4933 \\times (0.036446164)^2}{2} \\approx \\frac{4.393433}{2} = 2.196717$.\nExponent = $-2.186770 + 2.196717 = 0.009947$.\n$\\exp(0.009947) \\approx 1.009996$.\n\nArgument of the second $\\Phi$: $-\\frac{\\mu_{\\Delta} + \\sigma_{\\Delta}^2\\Delta\\beta}{\\sigma_{\\Delta}}$\n$\\sigma_{\\Delta}^2\\Delta\\beta = 3307.4933 \\times 0.036446164 \\approx 120.5483$.\nArgument $= -\\frac{-60.0 + 120.5483}{57.5108085} = -\\frac{60.5483}{57.5108085} \\approx -1.052816$.\n$\\Phi(-1.052816) \\approx 0.14620$.\n\nFinally, we compute $\\langle P_{\\text{acc}} \\rangle$:\n$\\langle P_{\\text{acc}} \\rangle \\approx 0.14841 + (1.009996) \\times (0.14620) \\approx 0.14841 + 0.147661 \\approx 0.296071$.\n\nRounding to four significant figures, the result is $0.2961$.",
            "answer": "$$\n\\boxed{0.2961}\n$$"
        },
        {
            "introduction": "An efficient REMD simulation depends on a well-designed temperature ladder, particularly for systems with complex thermal behavior. This hands-on coding challenge puts you in the driver's seat, tasking you with generating an optimal, non-uniform temperature ladder based on a model system's heat capacity . You will implement a greedy algorithm to concentrate replicas where they are most needed—near thermal transitions—mastering the art of tailoring simulation parameters to physical properties for maximum efficiency.",
            "id": "2461552",
            "problem": "A canonical-ensemble model of a molecular system exhibits two pronounced activation regions at $310\\,\\mathrm{K}$ and $450\\,\\mathrm{K}$. The goal is to design an optimal, non-uniform temperature ladder for Replica Exchange Molecular Dynamics (REMD) that spans a specified temperature interval and ensures that nearest-neighbor replica exchange meets a prescribed expected acceptance criterion.\n\nModeling assumptions and definitions to be used for this problem:\n- Work in reduced units where the Boltzmann constant satisfies $k_{\\mathrm{B}} = 1$. Report all temperatures in $\\mathrm{K}$.\n- The constant-volume heat capacity as a function of temperature is prescribed by\n$$\nC_{v}(T) = c_{0} + A_{1}\\exp\\!\\left(-\\tfrac{1}{2}\\left(\\tfrac{T - 310}{w_{1}}\\right)^{2}\\right) + A_{2}\\exp\\!\\left(-\\tfrac{1}{2}\\left(\\tfrac{T - 450}{w_{2}}\\right)^{2}\\right),\n$$\nwith constants $c_{0} = 100$, $A_{1} = 200$, $w_{1} = 8$, $A_{2} = 150$, $w_{2} = 10$. In these reduced units, $C_{v}(T)$ is dimensionless.\n- For a replica at temperature $T$, the canonical energy fluctuations are modeled as Gaussian with variance\n$$\n\\sigma^{2}(T) = k_{\\mathrm{B}}\\,C_{v}(T)\\,T^{2} = C_{v}(T)\\,T^{2}.\n$$\n- For two neighboring replicas at temperatures $T_{i}$ and $T_{i+1}$, define the inverse temperatures $\\beta_{i} = 1/T_{i}$ and $\\beta_{i+1} = 1/T_{i+1}$. Under a local equal-variance Gaussian approximation evaluated at the midpoint temperature $T_{m} = \\tfrac{T_{i} + T_{i+1}}{2}$, the expected Metropolis swap acceptance between these two replicas is modeled as\n$$\nA(T_{i}, T_{i+1}) = \\operatorname{erfc}\\!\\left(\\frac{|\\beta_{i+1} - \\beta_{i}|\\,\\sigma(T_{m})}{\\sqrt{2}}\\right),\n$$\nwhere $\\operatorname{erfc}(\\cdot)$ is the complementary error function.\n\nDefine an increasing sequence of temperatures $\\{T_{0}, T_{1}, \\dots, T_{N}\\}$ with $T_{0} = T_{\\min}$ and $T_{N} = T_{\\max}$ to be feasible if it satisfies the nearest-neighbor acceptance constraint\n$$\nA(T_{i}, T_{i+1}) \\ge a_{\\mathrm{target}} \\quad \\text{for all } i \\in \\{0,1,\\dots,N-1\\}.\n$$\nAmong all feasible sequences for the same $(T_{\\min}, T_{\\max}, a_{\\mathrm{target}})$, call a sequence optimal if it has the minimal possible length $N+1$.\n\nYour task is to compute an optimal temperature ladder for each case in the following test suite. For each case, output the full sequence $\\{T_{0}, T_{1}, \\dots, T_{N}\\}$ in $\\mathrm{K}$, rounded to one decimal place.\n\nTest suite:\n1. $T_{\\min} = 280\\,\\mathrm{K}$, $T_{\\max} = 500\\,\\mathrm{K}$, $a_{\\mathrm{target}} = 0.3$.\n2. $T_{\\min} = 295\\,\\mathrm{K}$, $T_{\\max} = 330\\,\\mathrm{K}$, $a_{\\mathrm{target}} = 0.3$.\n3. $T_{\\min} = 280\\,\\mathrm{K}$, $T_{\\max} = 500\\,\\mathrm{K}$, $a_{\\mathrm{target}} = 0.4$.\n4. $T_{\\min} = 430\\,\\mathrm{K}$, $T_{\\max} = 470\\,\\mathrm{K}$, $a_{\\mathrm{target}} = 0.3$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a bracketed, comma-separated list of temperatures (in $\\mathrm{K}$) for the corresponding test case. For example: \"[[T0_case1,T1_case1,...],[T0_case2,T1_case2,...],...]\".",
            "solution": "The problem requires the construction of an optimal temperature ladder, $\\{T_{0}, T_{1}, \\dots, T_{N}\\}$, for Replica Exchange Molecular Dynamics (REMD). The ladder must span a given temperature range $[T_{\\min}, T_{\\max}]$ and satisfy a minimum expected acceptance probability, $a_{\\mathrm{target}}$, for exchanges between adjacent replicas. An optimal ladder is defined as one having the minimum possible number of temperatures, $N+1$.\n\nThe principle of optimality dictates a greedy approach. To minimize the total number of replicas, we must maximize the temperature difference, $T_{i+1} - T_{i}$, at each step $i$ of constructing the ladder, starting from $T_0 = T_{\\min}$. The largest permissible step is one that pushes the expected acceptance probability down to its minimum allowed value, $a_{\\mathrm{target}}$. Therefore, at each step, we must determine the next temperature $T_{i+1}$ by solving the equation:\n$$\nA(T_{i}, T_{i+1}) = a_{\\mathrm{target}}\n$$\nwhere $A(T_i, T_{i+1})$ is the expected acceptance probability between replicas at temperatures $T_i$ and $T_{i+1}$.\n\nThe problem provides a model for this acceptance probability:\n$$\nA(T_{i}, T_{i+1}) = \\operatorname{erfc}\\!\\left(\\frac{|\\beta_{i+1} - \\beta_{i}|\\,\\sigma(T_{m})}{\\sqrt{2}}\\right)\n$$\nHere, $\\beta_{i} = 1/T_{i}$ is the inverse temperature, $T_{m} = (T_{i} + T_{i+1})/2$ is the midpoint temperature, and $\\sigma(T_{m})$ represents the energy fluctuations at $T_m$. Since the temperature sequence is strictly increasing ($T_{i+1} > T_i$), we have $\\beta_{i+1} < \\beta_{i}$, so $|\\beta_{i+1} - \\beta_{i}| = \\beta_{i} - \\beta_{i+1}$.\n\nSubstituting this into our equality and rearranging gives the core equation for our algorithm. Let $k = \\operatorname{erfcinv}(a_{\\mathrm{target}})$, where $\\operatorname{erfcinv}$ is the inverse complementary error function. The equation to be solved for $T_{i+1}$ given $T_i$ is:\n$$\n(\\beta_{i} - \\beta_{i+1})\\,\\sigma(T_{m}) = k\\sqrt{2}\n$$\nSubstituting the definitions for $\\beta$ and $T_m$, we obtain the implicit equation for the next temperature, which we shall denote $T_{\\text{next}}$:\n$$\n\\left(\\frac{1}{T_{i}} - \\frac{1}{T_{\\text{next}}}\\right) \\sigma\\left(\\frac{T_{i} + T_{\\text{next}}}{2}\\right) - k\\sqrt{2} = 0\n$$\nThe energy fluctuation term, $\\sigma(T)$, is given by $\\sigma(T) = T\\sqrt{C_v(T)}$, with the heat capacity $C_v(T)$ defined as:\n$$\nC_{v}(T) = c_{0} + A_{1}\\exp\\!\\left(-\\tfrac{1}{2}\\left(\\tfrac{T - 310}{w_{1}}\\right)^{2}\\right) + A_{2}\\exp\\!\\left(-\\tfrac{1}{2}\\left(\\tfrac{T - 450}{w_{2}}\\right)^{2}\\right)\n$$\nThe parameters are $c_{0} = 100$, $A_{1} = 200$, $w_{1} = 8$, $A_{2} = 150$, and $w_{2} = 10$. The resulting function $\\sigma(T)$ is non-trivial, and as a consequence, the equation for $T_{\\text{next}}$ may not have a unique solution or be monotonic. To satisfy the optimality condition, we must select the largest possible value of $T_{\\text{next}} > T_i$ that solves the equation.\n\nThe algorithmic procedure is as follows:\n1. Initialize the temperature list with the starting temperature: $\\mathcal{T} = \\{T_{\\min}\\}$. Let the current temperature be $T_{\\text{current}} = T_{\\min}$.\n2. While $T_{\\text{current}} < T_{\\max}$:\n    a. Define the function $g(x)$ for the root-finding procedure:\n       $$\n       g(x) = \\left(\\frac{1}{T_{\\text{current}}} - \\frac{1}{x}\\right) \\sigma\\left(\\frac{T_{\\text{current}} + x}{2}\\right) - k\\sqrt{2}\n       $$\n    b. Find the largest root, $T_{\\text{next}}$, of the equation $g(x)=0$ in the interval $(T_{\\text{current}}, T_{\\max}]$.\n    c. If such a root exists and $T_{\\text{next}} < T_{\\max}$, append $T_{\\text{next}}$ to the list $\\mathcal{T}$ and update $T_{\\text{current}} = T_{\\text{next}}$.\n    d. If no root exists in $(T_{\\text{current}}, T_{\\max}]$ (which occurs if $g(T_{\\max}) \\le 0$), or if the found root $T_{\\text{next}} \\ge T_{\\max}$, the process terminates. We append $T_{\\max}$ to $\\mathcal{T}$ to complete the ladder.\n3. The final list $\\mathcal{T}$ represents the optimal temperature ladder.\n\nTo ensure the largest root is found, a simple numerical solver on a fixed interval is insufficient. A robust strategy is required. We implement a backward search for the root's enclosing bracket. Starting from $b=T_{\\max}$, we step backward with a small increment to find an interval $[a, b]$ where $g(a) \\le 0$ and $g(b) > 0$. This ensures that the bracket contains the largest root in $(T_{\\text{current}}, T_{\\max}]$. A stable root-finding algorithm, such as the Brent-Dekker method, is then applied on this bracket. This guarantees that at each step we take the largest possible temperature jump, thus producing a ladder with the minimum number of replicas. The final temperatures are rounded to one decimal place as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erfcinv\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Computes optimal temperature ladders for REMD based on a given bi-modal heat capacity model.\n    \"\"\"\n    # Define the constants for the heat capacity model from the problem statement.\n    c0 = 100.0\n    A1 = 200.0\n    w1 = 8.0\n    T1_peak = 310.0\n    A2 = 150.0\n    w2 = 10.0\n    T2_peak = 450.0\n\n    def Cv(T):\n        \"\"\"\n        Calculates the constant-volume heat capacity Cv(T) as per the given model.\n        \"\"\"\n        term1 = A1 * np.exp(-0.5 * ((T - T1_peak) / w1)**2)\n        term2 = A2 * np.exp(-0.5 * ((T - T2_peak) / w2)**2)\n        return c0 + term1 + term2\n\n    def sigma(T):\n        \"\"\"\n        Calculates the energy fluctuation sigma(T), where sigma^2 = Cv(T) * T^2.\n        \"\"\"\n        return T * np.sqrt(Cv(T))\n\n    def find_next_temp(T_i, T_max, C):\n        \"\"\"\n        Finds the next temperature T_next in the ladder that satisfies the acceptance criterion.\n        This function identifies the largest possible root to ensure an optimal (shortest) ladder.\n\n        Args:\n            T_i (float): The current temperature.\n            T_max (float): The maximum temperature of the ladder.\n            C (float): The constant part of the equation, derived from a_target. \n                       C = erfcinv(a_target) * sqrt(2).\n        Returns:\n            float: The next optimal temperature.\n        \"\"\"\n        def g(T_next):\n            \"\"\"The function whose root is sought: g(T_next) = 0.\"\"\"\n            if T_next <= T_i:\n                # This region is not of interest. Return a large positive value to guide the solver.\n                return np.inf\n            Tm = (T_i + T_next) / 2.0\n            beta_diff = (1.0 / T_i) - (1.0 / T_next)\n            return beta_diff * sigma(Tm) - C\n\n        # If the step to T_max has an acceptance rate >= a_target, the ladder is complete.\n        if g(T_max) <= 0:\n            return T_max\n\n        # To find the largest root, we search backwards from T_max to find a bracket [a, b]\n        # such that g(a) <= 0 and g(b) > 0.\n        step = 1.0  # Search step in Kelvin.\n        b = T_max\n        a = b - step\n        while a > T_i:\n            if g(a) <= 0:\n                # Bracket [a, b] contains the largest root. We can now solve for it.\n                return brentq(g, a, b)\n            b = a\n            a -= step\n        \n        # If the loop finishes, the root must be in the first interval from T_i.\n        return brentq(g, T_i + 1e-9, b)\n\n    def generate_ladder(T_min, T_max, a_target):\n        \"\"\"\n        Generates the optimal temperature ladder for a given set of parameters.\n        \"\"\"\n        # Pre-calculate the constant C from the target acceptance rate.\n        C = erfcinv(a_target) * np.sqrt(2)\n        \n        temps = [T_min]\n        T_current = T_min\n        \n        # Set a practical limit on the number of replicas to prevent infinite loops.\n        max_replicas = 2000\n        while T_current < T_max and len(temps) < max_replicas:\n            T_next = find_next_temp(T_current, T_max, C)\n            temps.append(T_next)\n            T_current = T_next\n            \n        if len(temps) >= max_replicas:\n            raise RuntimeError(\"Exceeded maximum number of replicas, check parameters.\")\n\n        # Round all temperatures in the final list to one decimal place.\n        return [round(t, 1) for t in temps]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (280.0, 500.0, 0.3),\n        (295.0, 330.0, 0.3),\n        (280.0, 500.0, 0.4),\n        (430.0, 470.0, 0.3),\n    ]\n\n    results = []\n    for T_min, T_max, a_target in test_cases:\n        ladder = generate_ladder(T_min, T_max, a_target)\n        results.append(ladder)\n\n    # Format the final output string as specified in the problem statement.\n    # The format is a list of lists, e.g., [[...],[...]].\n    # str(list) automatically creates the required format for each inner list.\n    formatted_results = ','.join(map(str, results))\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "In computational science, a correct implementation is as important as a correct theory. This problem hones your debugging instincts by presenting a plausible coding error: omitting the Boltzmann constant, $k_B$, in the acceptance criterion of an REMD simulation . By analyzing how this single mistake alters the dimensionless exponent in the Metropolis rule, you will learn to predict its unique and dramatic signature in the resulting data, a critical skill for validating and troubleshooting complex simulation code.",
            "id": "2461558",
            "problem": "In Replica Exchange Molecular Dynamics (REMD), neighboring replicas at temperatures $T_i$ and $T_j$ attempt configuration exchanges using a Metropolis criterion that depends on the inverse-temperature difference $\\Delta \\beta = \\left(\\dfrac{1}{k_B T_i} - \\dfrac{1}{k_B T_j}\\right)$, where $k_B$ is the Boltzmann constant. You are running REMD with energies reported in $\\mathrm{kJ\\,mol^{-1}}$, temperatures in $\\mathrm{K}$, and the Boltzmann constant $k_B \\approx 8.3145 \\times 10^{-3}\\ \\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$. You suspect that a coding bug is computing $\\Delta \\beta$ as $\\Delta \\beta_{\\text{bug}} = \\left(\\dfrac{1}{T_i} - \\dfrac{1}{T_j}\\right)$ (i.e., omitting $k_B$ in the denominator).\n\nAssuming all other parts of the REMD algorithm and thermostatting are implemented correctly, which observable signature would most convincingly indicate this specific bug in the simulation data?\n\nA. Uniformly near-unity exchange acceptance probabilities (e.g., $\\ge 0.9$) across almost all neighboring temperature pairs despite spacings chosen to target about $0.2$–$0.4$, accompanied by systematic deviations of energy histograms at fixed $T$ from the expected Boltzmann form (e.g., reweighting checks fail).\n\nB. Uniformly near-zero exchange acceptance probabilities (e.g., $\\le 0.01$) across the ladder, with replicas effectively trapped at their initial temperatures and showing negligible temperature random walks.\n\nC. Exchange acceptance probabilities that oscillate periodically with the swap interval and correlate strongly with the thermostat coupling parameter, while average energies at each $T$ match single-temperature runs.\n\nD. Markedly different acceptance rates for the two directions of the same temperature pair (i.e., $i \\to j$ versus $j \\to i$) when binned by the sign of $\\Delta E$, indicating a systematic violation of detailed balance specific to the swap direction.",
            "solution": "We analyze the effect of omitting $k_B$ from $\\Delta \\beta$ on the Metropolis acceptance used in Replica Exchange Molecular Dynamics (REMD).\n\nFirst principles: In REMD, for a proposed swap between replicas at temperatures $T_i$ and $T_j$ with potential energies $E_i$ and $E_j$, the Metropolis acceptance probability is\n$$\np_{\\text{acc}} = \\min\\left(1,\\ \\exp\\left[(\\beta_i - \\beta_j)(E_j - E_i)\\right]\\right),\n$$\nwhere $\\beta_\\ell = 1/(k_B T_\\ell)$ for $\\ell \\in \\{i,j\\}$. Defining $\\Delta \\beta = \\beta_i - \\beta_j$ and $\\Delta E = E_j - E_i$, the exponent is $\\Delta \\beta \\,\\Delta E$.\n\nWith energies in $\\mathrm{kJ\\,mol^{-1}}$ and temperatures in $\\mathrm{K}$, the correct inverse temperature is $\\beta = 1/(k_B T)$ with $k_B \\approx 8.3145 \\times 10^{-3}\\ \\mathrm{kJ\\,mol^{-1}\\,K^{-1}}$. If a bug computes\n$$\n\\Delta \\beta_{\\text{bug}} = \\frac{1}{T_i} - \\frac{1}{T_j},\n$$\nthen\n$$\n\\Delta \\beta_{\\text{bug}} = k_B\\left(\\frac{1}{k_B T_i} - \\frac{1}{k_B T_j}\\right) = k_B \\,\\Delta \\beta_{\\text{true}}.\n$$\nTherefore the acceptance exponent becomes\n$$\n(\\Delta \\beta_{\\text{bug}})\\,\\Delta E = k_B\\,(\\Delta \\beta_{\\text{true}}\\,\\Delta E).\n$$\nBecause $k_B \\approx 8.3 \\times 10^{-3}$ in these units, the magnitude of the exponent is reduced by a factor of about $10^{-2}$. For typical $\\Delta \\beta_{\\text{true}}\\,\\Delta E$ values of order unity (a common situation when temperature spacings are tuned to achieve target acceptance around $0.2$–$0.4$), multiplying by $k_B \\ll 1$ yields a very small exponent, i.e., $(\\Delta \\beta_{\\text{bug}})\\,\\Delta E \\approx 0$. Then\n$$\n\\exp\\left[(\\Delta \\beta_{\\text{bug}})\\,\\Delta E\\right] \\approx 1,\n$$\nand thus $p_{\\text{acc}} \\approx 1$ for almost all proposed exchanges, independent of the sign of $\\Delta E$.\n\nConsequences in the data:\n- Exchange acceptance fractions across neighboring temperature pairs will be anomalously high (near unity), even when the intended temperature ladder was chosen to yield moderate acceptance (e.g., around $0.2$–$0.4$).\n- Because the acceptance rule is no longer using the correct Boltzmann factor, the stationary distribution at each $T$ will not be the canonical (Boltzmann) distribution. Practical diagnostics such as histogram reweighting across temperatures or checking that $\\ln P_T(E)$ has the correct slope proportional to $-\\beta$ will fail or show systematic deviations.\n- Temperature random walks will be unusually rapid due to the high acceptance, but this alone is not definitive without the acceptance anomaly and non-Boltzmann signatures.\n\nNow evaluate each option:\n\nA. Uniformly near-unity acceptance across neighboring pairs, despite temperature spacings tuned for about $0.2$–$0.4$, together with systematic deviations from Boltzmann energy distributions at fixed $T$, is exactly the expected outcome of scaling the exponent by a small factor $k_B \\ll 1$. The exponent becomes very small, leading to $\\exp(\\cdot) \\approx 1$ and hence $p_{\\text{acc}} \\approx 1$. The incorrect exponent also destroys detailed balance with respect to the canonical distribution at each $T$, so histogram reweighting checks will fail. Correct.\n\nB. Uniformly near-zero acceptance would arise if the exponent magnitude were made too large in absolute value (for example, using something like $\\Delta \\beta \\propto (T_i - T_j)/k_B$ rather than $(1/(k_B T_i) - 1/(k_B T_j))$), which is the opposite of the present bug. With the omission of $k_B$ as stated, the exponent magnitude shrinks, not grows, so acceptance should increase, not decrease. Incorrect.\n\nC. Periodic oscillations tied to the thermostat coupling are not a consequence of rescaling $\\Delta \\beta$ by $k_B$. The acceptance anomaly stems from the exponent scaling and does not inherently couple to the thermostat relaxation time in a periodic fashion. Moreover, this option claims average energies at each $T$ match single-temperature runs, which would be unlikely if the acceptance rule is incorrect. Incorrect.\n\nD. Direction-dependent acceptance rates for the same temperature pair indicate a sign error (e.g., using $\\Delta \\beta$ with reversed indices in a way that breaks detailed balance) or an asymmetric proposal mechanism. Simply scaling the exponent by $k_B$ preserves the symmetry of the acceptance function with respect to $\\Delta E$ and the two directions; it does not create a forward/reverse asymmetry. Incorrect.\n\nTherefore, the signature most consistent with omitting $k_B$ in $\\Delta \\beta$ is described in option A.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}