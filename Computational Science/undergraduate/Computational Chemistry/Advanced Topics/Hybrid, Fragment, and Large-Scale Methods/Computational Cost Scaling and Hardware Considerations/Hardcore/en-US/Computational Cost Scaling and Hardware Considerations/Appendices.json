{
    "hands_on_practices": [
        {
            "introduction": "Before we can analyze a scaling law, we must first understand where it originates. This exercise challenges you to derive the computational cost for a hypothetical quantum system, starting from its fundamental mathematical structure. By working through this thought experiment, you will see how the number of nested loops required for a tensor contraction directly determines the leading-order scaling of an algorithm, a foundational skill for predicting computational feasibility. ",
            "id": "2452811",
            "problem": "Consider a hypothetical quantum system in which the fundamental electron–electron interaction is purely three-body. Let there be an orthonormal set of $N$ spatial one-electron basis functions $\\{\\phi_{p}(\\mathbf{r})\\}_{p=1}^{N}$. The three-electron interaction operator is defined by a symmetric potential $W(\\mathbf{r}_{1},\\mathbf{r}_{2},\\mathbf{r}_{3})$, giving rise to three-electron integrals\n$$\nw_{pqr}^{stu} \\equiv \\iiint \\phi_{p}(\\mathbf{r}_{1})\\,\\phi_{q}(\\mathbf{r}_{2})\\,\\phi_{r}(\\mathbf{r}_{3})\\,W(\\mathbf{r}_{1},\\mathbf{r}_{2},\\mathbf{r}_{3})\\,\\phi_{s}(\\mathbf{r}_{1})\\,\\phi_{t}(\\mathbf{r}_{2})\\,\\phi_{u}(\\mathbf{r}_{3})\\,\\mathrm{d}\\mathbf{r}_{1}\\,\\mathrm{d}\\mathbf{r}_{2}\\,\\mathrm{d}\\mathbf{r}_{3},\n$$\nwith all orbital indices $p,q,r,s,t,u \\in \\{1,\\dots,N\\}$. Consider a single-determinant variational mean-field method analogous to Hartree–Fock (HF), solved by a Self-Consistent Field (SCF) procedure. Let the one-particle density matrix be $D_{pq}$. On a single Slater determinant, the expectation value of a three-body operator factorizes into sums of products of three one-particle density matrices; the corresponding effective one-electron (Fock-like) operator $F$ is obtained as the functional derivative of the total energy with respect to $D$, which requires contraction of the six-index interaction tensor $w$ with two copies of $D$ to produce all $N^{2}$ matrix elements $F_{ij}$.\n\nAssume a direct, naive implementation with no screening, no symmetry exploitation, and no factorization or tensor decomposition: all required three-electron integrals are evaluated or accessed as needed, and all contractions are performed explicitly over the full index ranges. Assume that the one-electron part, if present, does not affect the leading asymptotic cost, that the cost to diagonalize $F$ is subleading, and that memory bandwidth and input/output do not change the leading operation count so that the total floating-point operation count is proportional to the algebraic contraction count.\n\nWhat is the leading-order asymptotic scaling, as a closed-form expression in $N$, of the total floating-point operation count for building the mean-field operator $F$ in one SCF iteration in this three-body-interaction theory? Provide your answer as a single analytic expression in $N$. Do not include units and do not use inequality notation.",
            "solution": "The problem requires the determination of the leading-order asymptotic scaling for the computational cost of constructing a mean-field operator, denoted as $F$, in a hypothetical quantum theory where interactions are governed by a three-body potential. The cost is to be expressed as a function of $N$, the number of basis functions.\n\nFirst, let us establish the nature of the objects involved. We are given a set of $N$ basis functions, which implies that all matrices representing one-particle properties are of size $N \\times N$, and tensors representing interactions will have indices that run from $1$ to $N$.\nThe one-particle density matrix, $D$, is an $N \\times N$ matrix with elements $D_{pq}$.\nThe three-electron integrals form a rank-$6$ tensor, $w$, with elements $w_{pqr}^{stu}$. There are $N^6$ such integrals in total.\nThe mean-field operator, $F$, is a two-index object, an $N \\times N$ matrix with elements $F_{ij}$.\n\nThe core of the problem lies in the construction of the matrix $F$. The problem states that \"the corresponding effective one-electron (Fock-like) operator $F$ is obtained as the functional derivative of the total energy with respect to $D$, which requires contraction of the six-index interaction tensor $w$ with two copies of $D$ to produce all $N^2$ matrix elements $F_{ij}$.\"\n\nThis statement dictates the algebraic structure of the calculation. To form a two-index object, $F_{ij}$, from a six-index object, $w_{pqrstu}$, and two two-index objects, $D_{ab}$ and $D_{cd}$, four of the indices of $w$ must be contracted (summed over) with the four indices from the two density matrices. The remaining two indices of $w$ become the indices of $F$.\n\nLet us consider a specific element $F_{ij}$ of the Fock-like matrix. A general contraction form, consistent with the structure of many-body theory and the functional derivative procedure mentioned, connects the indices of the interaction tensor with those of the density matrices. A representative form for such a contraction, which arises from taking the functional derivative of the three-body energy term with respect to the density matrix, is:\n$$ F_{ij} \\propto \\sum_{q=1}^{N} \\sum_{r=1}^{N} \\sum_{t=1}^{N} \\sum_{u=1}^{N} w_{iqr}^{jtu} D_{tq} D_{ur} $$\nThe exact expression may involve multiple such terms with different index permutations and prefactors due to antisymmetry, but for the purpose of asymptotic scaling analysis in a \"naive implementation\" that does not exploit symmetry, all such terms will have the same computational cost structure. The scaling will be dominated by the term with the highest cost. The expression above involves a summation over four indices.\n\nThe problem specifies a \"direct, naive implementation with no screening, no symmetry exploitation... and all contractions are performed explicitly over the full index ranges.\" This instructs us to analyze the cost of the most straightforward evaluation of the expression for $F_{ij}$.\n\nTo calculate a single element $F_{ij}$, one must perform the summation over the four indices $q$, $r$, $t$, and $u$. This corresponds to four nested loops, each running from $1$ to $N$.\nThe number of terms in this summation is therefore $N \\times N \\times N \\times N = N^4$.\n\nInside the innermost loop, for each specific set of indices $(i, j, q, r, t, u)$, the operation consists of fetching the values of one element of $w$ and two elements of $D$, performing two multiplications ($w_{iqr}^{jtu} \\times D_{tq} \\times D_{ur}$), and one addition to accumulate the sum. This constitutes a constant number of floating-point operations, which we can denote as $O(1)$. Therefore, the computational cost to calculate a single element $F_{ij}$ scales as $O(N^4)$.\n\nThe final step is to construct the entire $N \\times N$ matrix $F$. This requires computing all $N^2$ of its elements, from $F_{11}$ to $F_{NN}$. Since the naive implementation computes each element independently, the total computational cost is the product of the number of elements and the cost per element.\n\nTotal Cost $\\propto$ (Number of elements in $F$) $\\times$ (Cost per element)\nThe number of elements in $F$ is $N^2$.\nThe cost per element is proportional to $N^4$.\nThus, the total cost for building the matrix $F$ in one Self-Consistent Field (SCF) iteration scales as:\n$$ \\text{Total Cost} \\propto N^2 \\times N^4 = N^6 $$\nThis $O(N^6)$ scaling is the leading-order asymptotic behavior. Any attempts to reduce this cost by reordering summations and creating intermediates, for instance, $A_{iqt}^j = \\sum_{r,u} w_{iqr}^{jtu} D_{ur}$, still lead to an overall $O(N^6)$ cost for forming the intermediate tensor $A$. Therefore, even with optimal summation ordering, the scaling remains $O(N^6)$ because of the connectivity of indices in the summand. The \"naive\" loop structure directly yields this result, which happens to be the best possible for this contraction structure.\n\nThe final answer for the leading-order asymptotic scaling, as a closed-form expression in $N$, is $N^6$.",
            "answer": "$$\n\\boxed{N^6}\n$$"
        },
        {
            "introduction": "Once a scaling law like $O(N^k)$ is established, the exponent $k$ becomes the most critical predictor of performance for large systems. This practice problem provides a concrete example of how even a small change in this exponent can lead to a dramatic difference in computational time. Solving this will build your intuition for the powerful, nonlinear effect of polynomial scaling and why algorithmic improvements are so crucial. ",
            "id": "2452785",
            "problem": "On a fixed hardware platform, the wall-clock runtime $T(N)$ of a Density Functional Theory (DFT) code for a system of size $N$ (e.g., number of basis functions) is observed to scale proportionally to a power of $N$ for sufficiently large $N$. Suppose the correct implementation has scaling $T_{\\text{corr}}(N) \\propto N^{3}$, but a bug causes the code to instead scale as $T_{\\text{bug}}(N) \\propto N^{3.5}$. Assume both versions share the same proportionality prefactor (i.e., they differ only in the exponent of $N$), are run on identical hardware, and any lower-order terms are negligible.\n\nFor what value of $N$ does the bug lead to a $100\\%$ increase in runtime relative to the correct implementation for the same system, that is, $T_{\\text{bug}}(N)$ is exactly twice $T_{\\text{corr}}(N)$? Provide $N$ as a pure number with no units. No rounding is required.",
            "solution": "The scaling relations are explicitly defined as:\n$$T_{\\text{corr}}(N) = c N^{3}$$\n$$T_{\\text{bug}}(N) = c N^{3.5}$$\nwhere $c$ is a positive constant representing the shared proportionality prefactor. The assumption of negligible lower-order terms allows us to use these simple power laws as exact equalities for the purpose of this analysis.\n\nThe condition given is that the buggy runtime shows a $100\\%$ increase relative to the correct one. A $100\\%$ increase corresponds to doubling the original value. Therefore, the mathematical condition is:\n$$T_{\\text{bug}}(N) = T_{\\text{corr}}(N) + (1.00) \\times T_{\\text{corr}}(N) = 2 T_{\\text{corr}}(N)$$\n\nSubstitute the scaling expressions into this equation:\n$$c N^{3.5} = 2 (c N^{3})$$\n\nWe are seeking a non-trivial solution for $N$, which implies $N > 0$. The prefactor $c$ must be non-zero for any computation to occur, so $c > 0$. We can therefore divide both sides of the equation by $c$:\n$$N^{3.5} = 2 N^{3}$$\n\nAssuming $N > 0$, we can divide both sides by $N^{3}$:\n$$\\frac{N^{3.5}}{N^{3}} = 2$$\n\nUsing the property of exponents, $x^{a}/x^{b} = x^{a-b}$:\n$$N^{3.5 - 3} = 2$$\n$$N^{0.5} = 2$$\n\nThe exponent $0.5$ is equivalent to the square root:\n$$N^{1/2} = \\sqrt{N} = 2$$\n\nTo solve for $N$, we square both sides of the equation:\n$$\\left(\\sqrt{N}\\right)^{2} = 2^{2}$$\n$$N = 4$$\n\nThus, for a system size of $N=4$, the buggy implementation will take exactly twice as long as the correct implementation. This result is independent of the prefactor $c$, as expected for a relative comparison based on scaling laws.",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "Computational cost is not just about time; it is also about memory. For many electronic structure methods, the memory required to store key quantities like the two-electron repulsion integrals can be the primary factor limiting the size of systems you can study. This exercise asks you to perform a practical, real-world calculation connecting a method's memory scaling to the physical RAM available on a computer, translating an abstract scaling law into a hard limit on system size. ",
            "id": "2452800",
            "problem": "In a Hartree–Fock calculation over a set of spatial basis functions, the four-index electron repulsion integral tensor can be represented as a dense fourth-order array with entries indexed by $(\\mu,\\nu,\\lambda,\\sigma)$, each index running from $1$ to $N$. Assume no symmetry reduction or sparsity is exploited, so the total number of stored real numbers is $N^{4}$. Suppose you have a compute node with exactly $128$ gibibytes allocated exclusively for holding this tensor in memory, and each tensor element is stored as a $64$-bit floating-point number. Use the following definitions for unit conversions: $1\\ \\mathrm{byte} = 8\\ \\mathrm{bits}$ and $1\\ \\mathrm{GiB} = 2^{30}\\ \\mathrm{bytes}$. Ignore any additional memory overhead. What is the largest integer $N$ such that the full $N \\times N \\times N \\times N$ tensor can be held entirely in-core? Provide the exact integer value of $N$.",
            "solution": "The fundamental principle is that the total memory required to store the tensor must be less than or equal to the available memory. We shall formalize this condition and solve for the maximum integer value of $N$.\n\nFirst, we determine the memory required to store a single element of the tensor. The problem states that each element is a $64$-bit floating-point number. Using the provided conversion, we find the size in bytes:\n$$\n\\text{Size per element} = 64\\ \\mathrm{bits} \\times \\frac{1\\ \\mathrm{byte}}{8\\ \\mathrm{bits}} = 8\\ \\mathrm{bytes}\n$$\n\nNext, we express the total memory required to store the entire dense tensor. The tensor is of rank $4$ with each dimension of size $N$. Therefore, the total number of elements is $N^4$. The total memory requirement, which we will denote as $M_{\\text{req}}$, is the product of the number of elements and the size per element:\n$$\nM_{\\text{req}} = N^4 \\times (8\\ \\mathrm{bytes})\n$$\n\nNow, we calculate the total available memory, $M_{\\text{avail}}$, in bytes. The available memory is given as $128$ GiB. Using the specified conversion $1\\ \\mathrm{GiB} = 2^{30}\\ \\mathrm{bytes}$, we have:\n$$\nM_{\\text{avail}} = 128\\ \\mathrm{GiB} \\times \\frac{2^{30}\\ \\mathrm{bytes}}{1\\ \\mathrm{GiB}} = 128 \\times 2^{30}\\ \\mathrm{bytes}\n$$\nIt is advantageous to express the coefficient $128$ as a power of $2$: $128 = 2^7$. Thus,\n$$\nM_{\\text{avail}} = 2^7 \\times 2^{30}\\ \\mathrm{bytes} = 2^{37}\\ \\mathrm{bytes}\n$$\n\nThe condition for the tensor to be held in-core is $M_{\\text{req}} \\le M_{\\text{avail}}$. We substitute our expressions for these quantities:\n$$\n8 \\times N^4 \\le 2^{37}\n$$\nWe express the coefficient $8$ as a power of $2$: $8 = 2^3$.\n$$\n2^3 \\times N^4 \\le 2^{37}\n$$\nTo solve for $N$, we first isolate the $N^4$ term by dividing both sides by $2^3$:\n$$\nN^4 \\le \\frac{2^{37}}{2^3} = 2^{37-3} = 2^{34}\n$$\nNow, we take the fourth root of both sides of the inequality. Since $N$ must be a positive integer, this operation is straightforward:\n$$\nN \\le (2^{34})^{\\frac{1}{4}} = 2^{\\frac{34}{4}} = 2^{8.5}\n$$\nTo find the numerical value, we can write $2^{8.5}$ as $2^8 \\times 2^{0.5}$:\n$$\nN \\le 2^8 \\times \\sqrt{2}\n$$\nWe know that $2^8 = 256$. The value of $\\sqrt{2}$ is approximately $1.41421356...$.\n$$\nN \\le 256 \\times 1.41421356... \\approx 362.03867...\n$$\nThe problem demands the largest integer value of $N$ that satisfies this condition. The set of integers satisfying $N \\le 362.03867...$ is $\\{..., 360, 361, 362\\}$. The largest integer in this set is $362$.\n\nTherefore, the largest number of basis functions $N$ for which the full ERI tensor can be stored in the given memory is $362$.",
            "answer": "$$\n\\boxed{362}\n$$"
        }
    ]
}