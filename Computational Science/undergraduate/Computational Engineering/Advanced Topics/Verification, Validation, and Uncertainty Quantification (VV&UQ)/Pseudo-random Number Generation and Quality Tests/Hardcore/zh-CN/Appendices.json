{
    "hands_on_practices": [
        {
            "introduction": "伪随机数生成器（PRNG）的首要质量标准是其输出的均匀性。一个好的生成器应该以相等的概率产生其范围内的每个数值。本练习将引导您实现卡方拟合优度检验（chi-squared goodness-of-fit test），这是一个用于检验观测频率与期望频率是否一致的基本统计工具。通过将此测试应用于一个旨在生成离散符号（如DNA碱基'A', 'T', 'C', 'G'）的生成器，您将学习如何量化并判断一个PRNG是否存在边际偏差。",
            "id": "2429686",
            "problem": "您的任务是评估一个伪随机数生成器（PRNG）是否从字母表 $\\{ \\texttt{A}, \\texttt{T}, \\texttt{C}, \\texttt{G} \\}$ 中产生一个无偏的离散符号序列。一个无偏的生成器会在每次抽取时以相等的概率 $1/4$ 发出每个符号，且每次抽取独立于之前的抽取。仅使用离散均匀模型下的假设检验第一性原理，构建一个决策规则。对于给定的长度为 $n$ 的有限序列 $s$（其元素来自 $\\{ \\texttt{A}, \\texttt{T}, \\texttt{C}, \\texttt{G} \\}$），该规则输出一个实值 $p$-value 和一个布尔决策，以指示在显著性水平 $\\alpha = 0.01$ 下是否存在足够的边际偏差证据。您的决策规则必须基于在原假设（即每个符号在每次抽取中出现的概率为 $1/4$）下，根据观测计数计算出的标量统计量的分布。$p$-value 必须是该统计量在原假设模型下的精确上尾概率，并且当且仅当 $p$-value 严格小于 $\\alpha$ 时，布尔决策必须为 $\\texttt{True}$。\n\n对于给定序列 $s$，令 $O_i$ 为序列 $s$ 中符号 $i \\in \\{ \\texttt{A}, \\texttt{T}, \\texttt{C}, \\texttt{G} \\}$ 的观测计数，令 $E_i = n/4$ 为原假设下的期望计数。从 $\\{O_i\\}$ 和 $\\{E_i\\}$ 定义一个单一的标量检验统计量，其在原假设下的参考分布具有已知的封闭形式，并且仅依赖于类别数 $k = 4$。使用此参考分布计算已实现统计量的上尾概率，即所需的 $p$-value。然后将 $p$-value 与 $\\alpha = 0.01$ 进行比较，以得出布尔决策。\n\n测试套件。将您的方法应用于以下五个序列，每个序列均由 $\\{ \\texttt{A}, \\texttt{T}, \\texttt{C}, \\texttt{G} \\}$ 中的符号组成：\n- 情况1：$s_1$ 是字符串 $\\texttt{\"ATCG\"}$ 自身连接 $25$ 次的结果，因此 $n = 100$。\n- 情况2：$s_2$ 是字符串 $\\texttt{\"A\"}$ 自身连接 $100$ 次的结果，因此 $n = 100$。\n- 情况3：$s_3$ 的计数为 $O_{\\texttt{A}} = 16$, $O_{\\texttt{T}} = 8$, $O_{\\texttt{C}} = 8$, $O_{\\texttt{G}} = 8$（顺序任意），因此 $n = 40$。\n- 情况4：$s_4 = \\texttt{\"ATCG\"}$，因此 $n = 4$。\n- 情况5：$s_5$ 的计数为 $O_{\\texttt{A}} = 20$, $O_{\\texttt{T}} = 7$, $O_{\\texttt{C}} = 7$, $O_{\\texttt{G}} = 6$（顺序任意），因此 $n = 40$。\n\n答案规范。对于每种情况 $j \\in \\{1,2,3,4,5\\}$，您的程序必须计算：\n- 一个布尔值 $\\texttt{reject}_j$，当且仅当 $p$-value 小于 $\\alpha = 0.01$ 时为 $\\texttt{True}$，否则为 $\\texttt{False}$；\n- 一个浮点数 $p_j$，等于 $p$-value。\n\n最终输出格式。您的程序应生成单行输出，包含一个长度为 $5$ 的列表，其中第 $j$ 个元素是一个双元素列表 $[\\texttt{reject}_j, p_j]$，顺序与上述情况相同。例如，输出形式必须为 $[[\\texttt{bool}, \\texttt{float}],[\\texttt{bool}, \\texttt{float}],\\dots]$，包含恰好五个条目，打印在单行上。此问题不涉及任何物理单位或角度单位。",
            "solution": "问题陈述已经过严格审查，并被认为是有效的。它构成了一个在计算统计学领域中定义明确且具有科学依据的问题，具体来说是针对离散均匀分布的拟合优度检验。所给条件是完整、一致且客观的，允许使用标准的假设检验原理得出一个唯一且可验证的解。\n\n任务是确定来自字母表 $\\{ \\texttt{A}, \\texttt{T}, \\texttt{C}, \\texttt{G} \\}$ 的符号序列是否显示出边际偏差的证据。这个问题被表述为一个假设检验。原假设 $H_0$ 假定生成器是无偏的，即 $k=4$ 个符号中的每一个都以相等的概率 $p_i = 1/4$ 产生。备择假设 $H_A$ 是至少有一个符号的概率不等于 $1/4$。\n\n为了检验这个假设，我们使用 Pearson 卡方（$\\chi^2$）拟合优度检验。该检验基于一个标量统计量，该统计量衡量观测到的符号计数 $O_i$ 与原假设下的期望计数 $E_i$ 之间的差异。对于一个长度为 $n$ 的序列，每个符号的期望计数是 $E_i = n \\cdot p_i = n/4$。检验统计量定义为：\n$$ \\chi^2 = \\sum_{i=1}^{k} \\frac{(O_i - E_i)^2}{E_i} $$\n在原假设下，该统计量近似服从自由度为 $k-1$ 的卡方分布。因为我们有 $k=4$ 个类别，所以参考分布是自由度为 $df = 4 - 1 = 3$ 的卡方分布。该分布具有已知的封闭形式，并且仅依赖于类别数量，正如问题陈述所要求的那样。当所有期望计数 $E_i$ 至少为 $5$ 时，该近似的有效性通常被认为是可接受的。\n\n决策规则构建如下：\n1. 对于给定的序列，计算 $4$ 个符号中每个符号的观测计数 $O_i$。\n2. 使用上述公式计算卡方统计量 $\\chi^2_{\\text{calc}}$。\n3. 计算 $p$-value，它是在假设 $H_0$ 为真的情况下，观测到等于或比 $\\chi^2_{\\text{calc}}$ 更极端的检验统计量的概率。这对应于 $\\chi^2_3$ 分布的上尾概率：$p = P(\\chi^2_3 \\ge \\chi^2_{\\text{calc}})$。\n4. 将 $p$-value 与指定的显著性水平 $\\alpha = 0.01$ 进行比较。如果 $p  \\alpha$，我们拒绝原假设，并得出结论认为存在足够的边际偏差证据。布尔决策 `reject` 为 $\\texttt{True}$。否则，我们不拒绝 $H_0$，`reject` 为 $\\texttt{False}$。\n\n我们现在将此程序应用于五个测试案例。\n\n情况1：$s_1$ 是 $\\texttt{\"ATCG\"}$ 重复 $25$ 次。\n序列长度为 $n = 100$。\n观测计数为 $O_{\\texttt{A}} = 25$, $O_{\\texttt{T}} = 25$, $O_{\\texttt{C}} = 25$, $O_{\\texttt{G}} = 25$。\n期望计数对所有 $i$ 均为 $E_i = 100/4 = 25$。\n检验统计量为：\n$$ \\chi^2_{\\text{calc}} = \\frac{(25-25)^2}{25} + \\frac{(25-25)^2}{25} + \\frac{(25-25)^2}{25} + \\frac{(25-25)^2}{25} = 0 $$\n$p$-value 为 $P(\\chi^2_3 \\ge 0) = 1$。由于 $1 \\not 0.01$，我们不拒绝 $H_0$。决策：$\\texttt{False}$。\n\n情况2：$s_2$ 是 $\\texttt{\"A\"}$ 重复 $100$ 次。\n序列长度为 $n = 100$。\n观测计数为 $O_{\\texttt{A}} = 100$, $O_{\\texttt{T}} = 0$, $O_{\\texttt{C}} = 0$, $O_{\\texttt{G}} = 0$。\n期望计数为 $E_i = 100/4 = 25$。\n检验统计量为：\n$$ \\chi^2_{\\text{calc}} = \\frac{(100-25)^2}{25} + \\frac{(0-25)^2}{25} + \\frac{(0-25)^2}{25} + \\frac{(0-25)^2}{25} = \\frac{75^2}{25} + 3 \\cdot \\frac{(-25)^2}{25} = 225 + 75 = 300 $$\n在 $\\alpha=0.01$ 时，$\\chi^2_3$ 的临界值约为 $11.345$。由于 $300 \\gg 11.345$，因此 $p$-value 极小，必然小于 $0.01$。我们拒绝 $H_0$。决策：$\\texttt{True}$。\n\n情况3：$s_3$ 的计数为 $O_{\\texttt{A}} = 16$, $O_{\\texttt{T}} = 8$, $O_{\\texttt{C}} = 8$, $O_{\\texttt{G}} = 8$。\n序列长度为 $n = 16+8+8+8=40$。\n期望计数为 $E_i = 40/4 = 10$。\n检验统计量为：\n$$ \\chi^2_{\\text{calc}} = \\frac{(16-10)^2}{10} + \\frac{(8-10)^2}{10} + \\frac{(8-10)^2}{10} + \\frac{(8-10)^2}{10} = \\frac{36}{10} + \\frac{4}{10} + \\frac{4}{10} + \\frac{4}{10} = 3.6 + 1.2 = 4.8 $$\n由于 $4.8  11.345$，因此 $p$-value 大于 $0.01$。我们不拒绝 $H_0$。决策：$\\texttt{False}$。\n\n情况4：$s_4 = \\texttt{\"ATCG\"}$。\n序列长度为 $n = 4$。\n观测计数为 $O_{\\texttt{A}} = 1$, $O_{\\texttt{T}} = 1$, $O_{\\texttt{C}} = 1$, $O_{\\texttt{G}} = 1$。\n期望计数为 $E_i = 4/4 = 1$。在此，条件 $E_i \\ge 5$ 被违反，因此卡方近似效果不佳。尽管如此，我们仍遵循所述程序。\n检验统计量为：\n$$ \\chi^2_{\\text{calc}} = \\frac{(1-1)^2}{1} + \\frac{(1-1)^2}{1} + \\frac{(1-1)^2}{1} + \\frac{(1-1)^2}{1} = 0 $$\n$p$-value 为 $P(\\chi^2_3 \\ge 0) = 1$。由于 $1 \\not 0.01$，我们不拒绝 $H_0$。决策：$\\texttt{False}$。\n\n情况5：$s_5$ 的计数为 $O_{\\texttt{A}} = 20$, $O_{\\texttt{T}} = 7$, $O_{\\texttt{C}} = 7$, $O_{\\texttt{G}} = 6$。\n序列长度为 $n = 20+7+7+6=40$。\n期望计数为 $E_i = 40/4 = 10$。\n检验统计量为：\n$$ \\chi^2_{\\text{calc}} = \\frac{(20-10)^2}{10} + \\frac{(7-10)^2}{10} + \\frac{(7-10)^2}{10} + \\frac{(6-10)^2}{10} = \\frac{100}{10} + \\frac{9}{10} + \\frac{9}{10} + \\frac{16}{10} = 10 + 0.9 + 0.9 + 1.6 = 13.4 $$\n由于 $13.4 > 11.345$，因此 $p$-value 小于 $0.01$。我们拒绝 $H_0$。决策：$\\texttt{True}$。\n\n以下程序实现了这一逻辑，以计算每种情况的精确 $p$-value 和决策。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Applies the chi-squared goodness-of-fit test to evaluate marginal bias\n    in sequences of discrete symbols.\n    \"\"\"\n    # Define the significance level from the problem statement.\n    alpha = 0.01\n    \n    # Define the number of categories (symbols in the alphabet).\n    k = 4\n    \n    # Degrees of freedom for the chi-squared distribution.\n    df = k - 1\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (sequence_length_n, observed_counts_O)\n    test_cases = [\n        # Case 1: \"ATCG\" repeated 25 times. n = 100. Counts are 25 for each.\n        (100, [25, 25, 25, 25]),\n        \n        # Case 2: \"A\" repeated 100 times. n = 100. Counts are 100 for 'A', 0 for others.\n        (100, [100, 0, 0, 0]),\n        \n        # Case 3: n = 40. Counts are O_A=16, O_T=8, O_C=8, O_G=8.\n        (40, [16, 8, 8, 8]),\n        \n        # Case 4: s = \"ATCG\". n = 4. Counts are 1 for each.\n        (4, [1, 1, 1, 1]),\n        \n        # Case 5: n = 40. Counts are O_A=20, O_T=7, O_C=7, O_G=6.\n        (40, [20, 7, 7, 6]),\n    ]\n\n    results = []\n    for n, O in test_cases:\n        # Expected counts under the null hypothesis of a uniform distribution.\n        # E_i = n * (1/k) for all i.\n        E = n / k\n        \n        # Convert observed counts to a NumPy array for vectorized operations.\n        observed_counts = np.array(O)\n        \n        # Calculate Pearson's chi-squared test statistic.\n        # chi2_stat = sum((O_i - E_i)^2 / E_i)\n        # Using a small epsilon to avoid division by zero if E is zero,\n        # although in this problem E is always positive.\n        chi2_stat = np.sum((observed_counts - E)**2 / (E + 1e-9))\n        \n        # Calculate the p-value.\n        # This is the upper-tail probability of the chi-squared distribution\n        # with 'df' degrees of freedom. The survival function (sf) gives P(X > x).\n        p_value = chi2.sf(chi2_stat, df)\n        \n        # Make the decision: reject the null hypothesis if p-value  alpha.\n        # The result must be a native Python boolean (True/False).\n        reject = bool(p_value  alpha)\n        \n        # Store the boolean decision and the p-value.\n        results.append([reject, p_value])\n\n    # Final print statement in the exact required format.\n    # The format is a list of lists: [[reject_1, p_1], [reject_2, p_2], ...]\n    # Using str() on each sublist automatically formats it correctly.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "仅仅通过频率检验不足以保证随机性；序列的内部结构同样重要。例如，一个序列可能具有完美的均匀分布，但其数值却以非随机的模式出现（如数值交替出现高低值）。本练习将介绍游程检验（runs test），这是一种经典的非参数方法，用于检测序列中是否存在这种趋势或聚类。您将通过计算中位数之上或之下的连续“游程”数量，来判断序列是否表现出独立随机变量应有的行为。",
            "id": "2429680",
            "problem": "你需要编写一个完整、可运行的程序，用于评估由特定伪随机数生成器（PRNGs, Pseudo-Random Number Generator）生成的若干有限序列中，高于和低于中心阈值的游程数量。其目的是对每个序列进行判断，在其服从来自连续分布的独立同分布（i.i.d., independent and identically distributed）抽样的原假设下，所观察到的游程数量是否异常。该检验应使用二元分类法，将每个值分类为严格高于或严格低于整个序列的样本中位数；在计算游程之前，必须丢弃与中位数完全相等的值。\n\n需使用的定义：\n- 对于一个有限实值序列 $\\{x_k\\}_{k=1}^{N}$，令 $m$ 表示其样本中位数。通过设置 $b_k = 1$（如果 $x_k > m$）和 $b_k = 0$（如果 $x_k  m$）来构建一个二元序列 $\\{b_k\\}$。任何满足 $x_k = m$ 的 $x_k$ 及其位置必须在计算游程前被移除。\n- 游程是二元序列中相同值的最大连续块。令 $R$ 为最终得到的长度为 $n$ 的二元序列中的总游程数（请注意，在丢弃与中位数相等的值后，$n \\le N$）。\n\n原假设与决策：\n- 在原序列服从来自连续分布的独立同分布的原假设下，相对于中位数的符号序列表现得如同连续的 $b_k$ 在类别计数固定的情况下是独立的。决策规则必须是在显著性水平 $\\alpha = 10^{-8}$ 下的双侧检验。\n- 如果在丢弃与中位数相等的值后，所有剩余值都属于同一类别（即 $n = 0$ 或所有 $b_k$ 都相同），则该情况的决策必须报告为布尔值 $0$（解释为“不拒绝”），因为在这种退化情况下，游程数不提供信息。\n\n测试套件（所有参数均已完全指定；无用户输入）：\n- 案例 A（长度 $N = 1000$）：交替高/低序列，定义为当 $k$ 为奇数时 $x_k = 0.25$，当 $k$ 为偶数时 $x_k = 0.75$。\n- 案例 B（长度 $N = 1000$）：线性同余生成器（LCG, Linear Congruential Generator），模数 $m = 2^{31} - 1$，乘数 $a = 16807$，增量 $c = 0$，种子 $x_0 = 1$，输出为 $u_k = x_k / m$，其中 $k = 1,\\dots,N$。\n- 案例 C（长度 $N = 1000$）：具有长持续性的两状态“粘性”生成器。令 $s_1 = 1$。对于 $k \\ge 2$，令 $s_k = s_{k-1}$ 的概率为 $p = 0.95$，令 $s_k = 1 - s_{k-1}$ 的概率为 $1 - p$。通过 $x_k = 0.75 + \\delta_k$（如果 $s_k = 1$）和 $x_k = 0.25 + \\delta_k$（如果 $s_k = 0$）将 $s_k$ 映射到实数值，其中 $\\delta_k$ 是在 $[-10^{-12}, 10^{-12}]$ 上独立均匀分布的。此案例所需的所有随机性必须通过使用与案例 B 中相同的 LCG 来确定性地生成所需的均匀分布变量。\n- 案例 D（长度 $N = 100$）：中位数相等情景。前 $60$ 个值均为 $x_k = 0.5$。其余 $40$ 个值取自案例 B 中 LCG 的后 $40$ 个输出 $u_k$（按案例 B 中的方式缩放到 $[0,1)$）。\n- 案例 E（长度 $N = 30$）：单类别退化。所有值均为 $x_k = 0.7$。\n\n程序要求：\n- 对于每个案例，完全按照规定构建序列。对于每个序列，使用相对于上述定义的样本中位数的游程数，在双侧显著性水平 $\\alpha = 10^{-8}$ 下，计算拒绝或不拒绝原假设的决策。将决策报告为布尔值：$1$ 表示“拒绝”，$0$ 表示“不拒绝”。如果丢弃后的序列少于两个类别，则该案例报告为 $0$。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的布尔值列表（例如，“[True,False,True,False,False]”），并按 A、B、C、D、E 的固定顺序排列。\n\n每个测试案例的答案都是布尔值。此任务中没有物理单位或角度；除了指定格式的单行输出外，不要打印任何其他内容。",
            "solution": "该问题要求使用游程检验来验证几个序列是否符合随机性的原假设。检验统计量是高于和低于样本中位数的游程数量。必须对每个序列在显著性水平 $\\alpha = 10^{-8}$ 下做出拒绝或不拒绝原假设的决策。\n\n首先，我们必须将统计过程形式化。\n\n**问题验证**\n\n步骤 1：提取给定信息\n- **序列生成方法**：\n  - 案例 A：交替序列，$k$ 为奇数时 $x_k = 0.25$，$k$ 为偶数时 $x_k = 0.75$，$N=1000$。\n  - 案例 B：线性同余生成器 (LCG)，模数 $m = 2^{31} - 1$，乘数 $a = 16807$，增量 $c = 0$，种子 $x_0 = 1$。序列为 $u_k = x_k/m$，其中 $k=1, \\dots, N$，$N=1000$。\n  - 案例 C：两状态“粘性”生成器。状态 $s_k \\in \\{0, 1\\}$。$s_1=1$。$s_k = s_{k-1}$ 的概率为 $p=0.95$，$s_k=1-s_{k-1}$ 的概率为 $1-p$。输出 $s_k=1$ 时为 $x_k = 0.75 + \\delta_k$，$s_k=0$ 时为 $x_k = 0.25 + \\delta_k$。$\\delta_k$ 是独立同分布的 $U[-10^{-12}, 10^{-12}]$。随机性源自案例 B 的 LCG。$N=1000$。\n  - 案例 D：中位数相等序列。前 $60$ 个值为 $x_k = 0.5$。后 $40$ 个值来自案例 B 的 LCG。$N=100$。\n  - 案例 E：单类别退化。所有 $x_k = 0.7$，$N=30$。\n- **游程检验定义**：\n  - 阈值为样本中位数 $m$。\n  - 丢弃值 $x_k = m$。剩余序列长度为 $n$。\n  - 形成二元序列：$x_k > m$ 为 $1$，$x_k  m$ 为 $0$。\n  - $R$ 是此二元序列中的游程数。\n- **假设和决策规则**：\n  - 原假设 ($H_0$)：原始序列是来自连续分布的独立同分布。\n  - 双侧检验的显著性水平为 $\\alpha = 10^{-8}$。\n  - 退化情况规则：如果在丢弃相等值后，所有值都属于一个类别（即 $n_0=0$ 或 $n_1=0$）或没有值剩下（$n=0$），则决策为不拒绝 $H_0$（输出 $0$）。\n  - 最终输出是针对案例 A-E 的布尔值列表（$1$ 表示拒绝，$0$ 表示不拒绝）。\n\n步骤 2：使用提取的给定信息进行验证\n- **科学依据**：该问题基于游程检验，这是一种标准的用于检验随机性的非参数统计检验方法。指定的 LCG 是著名的 Park-Miller 生成器。所有概念均来自成熟的统计学和计算科学领域。\n- **适定性**：每个案例都得到了完全的指定。统计检验，包括对相等值和退化情况的处理，都有明确的定义。决策规则是明确的。每个案例都存在唯一且有意义的解。\n- **客观性**：问题陈述不含主观性语言。所有参数和过程都进行了定量定义。\n\n步骤 3：结论与行动\n该问题是有效的。它是一个定义明确的计算统计问题，具有清晰的指令和科学上合理的原则。我将继续进行求解。\n\n**方法论与分步解答**\n\n解决方案的核心是游程检验的实现。对于一个长度为 $N$ 的序列 $\\{x_k\\}$：\n1.  计算样本中位数 $m$。\n2.  过滤序列，只保留不等于 $m$ 的值。设新序列长度为 $n$。\n3.  令 $n_1$ 为大于 $m$ 的值的计数，$n_0$ 为小于 $m$ 的值的计数。因此，$n = n_0 + n_1$。\n4.  根据问题的明确规则，如果 $n_0=0$ 或 $n_1=0$，则检验无定论，我们不拒绝 $H_0$。结果为 $0$。\n5.  否则，我们继续。计算分类为高于或低于中位数的值的序列中的游程数 $R$。\n6.  在原假设 $H_0$ 下，对于大的 $n_0$ 和 $n_1$，$R$ 的分布近似为正态分布，其均值 $\\mu_R$ 和方差 $\\sigma_R^2$ 由下式给出：\n    $$ \\mu_R = \\frac{2 n_0 n_1}{n} + 1 $$\n    $$ \\sigma_R^2 = \\frac{2 n_0 n_1 (2 n_0 n_1 - n)}{(n)^2 (n - 1)} $$\n7.  标准化检验统计量 $Z$ 计算如下：\n    $$ Z = \\frac{R - \\mu_R}{\\sigma_R} $$\n8.  对于显著性水平为 $\\alpha = 10^{-8}$ 的双侧检验，我们从标准正态分布中找到临界值 $Z_{\\alpha/2}$。$P(|Z| > Z_{\\alpha/2}) = \\alpha$。临界值对应于 $(1 - \\alpha/2)$ 分位数。对于 $\\alpha = 10^{-8}$，这是 $(1 - 5 \\times 10^{-9})$ 分位数，即 $Z_{crit} \\approx 5.7309$。\n9.  决策规则是如果 $|Z| > Z_{crit}$，则拒绝 $H_0$。这对应于输出 $1$ (True)。否则，我们不拒绝 $H_0$，得到输出 $0$ (False)。\n\n**测试案例分析：**\n\n- **案例 A（交替序列）**：长度为 $N=1000$ 的序列 $\\{0.25, 0.75, 0.25, \\dots\\}$ 的中位数为 $m=0.5$。没有相等的值。我们有 $n=1000$，其中有 $n_0=500$ 个值低于中位数， $n_1=500$ 个值高于中位数。二元序列是 $\\{0, 1, 0, 1, \\dots\\}$。游程数为 $R=1000$。\n  期望游程数为 $\\mu_R = \\frac{2(500)(500)}{1000} + 1 = 501$。方差为 $\\sigma_R^2 = \\frac{2(500)(500)(2(500)(500)-1000)}{1000^2(999)} \\approx 249.75$。标准差为 $\\sigma_R \\approx 15.80$。\n  $Z$分数为 $Z = (1000 - 501) / 15.80 \\approx 31.58$。因为 $|31.58| > 5.7309$，我们拒绝 $H_0$。结果：$1$。\n\n- **案例 B (LCG)**：来自一个良好伪随机数生成器的 $N=1000$ 个值的序列应表现为随机。找到中位数后，我们将得到 $n=1000$，$n_0=500$，$n_1=500$。游程数 $R$ 预计会接近 $\\mu_R = 501$。由此产生的 $Z$ 分数会很小，所以我们不拒绝 $H_0$。结果：$0$。\n\n- **案例 C（粘性生成器）**：该生成器被设计为具有强正序列相关性。对于 $N=1000$，状态预计仅翻转约 $(1-0.95) \\times (N-1) \\approx 50$ 次。这将导致极少的游程数，约为 $R \\approx 50$。假设状态大致被均等地占据，期望游程数仍为 $\\mu_R \\approx 501$。观察到的 $R$ 远小于期望值，导致一个大的负 $Z$ 分数，例如 $Z \\approx (50 - 501)/15.80 \\approx -28.5$。我们拒绝 $H_0$。结果：$1$。\n\n- **案例 D（中位数相等）**：长度为 $N=100$ 的序列有 $60$ 个值为 $0.5$，以及 $40$ 个来自 LCG 的值。中位数为 $m=0.5$。这 $60$ 个相等的值被丢弃，剩下 $n=40$ 个随机值。检验是针对这些值相对于原始中位数 $0.5$ 进行的。由于 LCG 值在 $[0,1)$ 上是均匀分布的，我们预计 $n_0 \\approx 20$ 且 $n_1 \\approx 20$。这个较短的随机序列中的游程数 $R$ 应接近其期望值，例如 $\\mu_R = \\frac{2(20)(20)}{40} + 1 = 21$。$Z$ 分数会很小。我们不拒绝 $H_0$。结果：$0$。\n\n- **案例 E（退化案例）**：所有 $N=30$ 个值均为 $0.7$。中位数为 $m=0.7$。所有值都被丢弃。剩余序列的长度为 $n=0$。这是问题中定义的退化情况（$n_0=0, n_1=0$）。我们不拒绝 $H_0$。结果：$0$。\n\n实现将为每个案例精确地遵循此逻辑。案例 B、C 和 D 所需的 LCG 将为每个案例重新初始化，以确保确定性的、独立的测试条件。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    \n    # --- Helper functions ---\n\n    def lcg_generator(n_values, seed=1):\n        \"\"\"Generates a sequence of n_values from a LCG.\"\"\"\n        m = 2**31 - 1\n        a = 16807\n        \n        # Use Python's arbitrary-precision integers for calculations\n        x = seed\n        results = np.zeros(n_values)\n        for i in range(n_values):\n            x = (a * x) % m\n            results[i] = x / m\n        return results\n\n    def runs_test(x, alpha=1e-8):\n        \"\"\"\n        Performs the runs test for randomness on a sequence x.\n        Returns True (1) to reject H0, False (0) to not reject.\n        \"\"\"\n        if len(x) == 0:\n            return False\n\n        median = np.median(x)\n        \n        # Filter out elements equal to the median\n        filtered_x = x[x != median]\n        \n        n = len(filtered_x)\n        if n == 0:\n            return False\n            \n        # Create binary sequence\n        binary_seq = (filtered_x > median).astype(int)\n        \n        n1 = np.sum(binary_seq)\n        n0 = n - n1\n        \n        # Degenerate case rule from problem statement\n        if n0 == 0 or n1 == 0:\n            return False\n\n        # Count runs\n        # A run starts at the beginning, and every time the value changes.\n        runs = 1 + np.sum(np.diff(binary_seq) != 0)\n        \n        # Large sample approximation for runs test\n        mu_r = (2 * n0 * n1) / n + 1\n        \n        # Denominator term to check for n=1 case (already covered by n0/n1 check)\n        denom_var = (n**2) * (n - 1)\n        if denom_var == 0:\n            # This case is avoided by the n0=0 or n1=0 check, but as a safeguard:\n            return False\n            \n        sigma_sq_r = (2 * n0 * n1 * (2 * n0 * n1 - n)) / denom_var\n        \n        if sigma_sq_r = 0:\n            # If R is deterministic, variance is 0. Cannot form Z-stat. Do not reject.\n            return False\n            \n        sigma_r = np.sqrt(sigma_sq_r)\n        \n        # Z-statistic\n        z_score = (runs - mu_r) / sigma_r\n        \n        # Two-sided critical value\n        z_crit = norm.ppf(1 - alpha / 2)\n        \n        # Decision: reject if |Z| > Z_crit\n        return abs(z_score) > z_crit\n\n    # --- Test Case Generators ---\n\n    def generate_case_a():\n        n = 1000\n        x = np.zeros(n)\n        x[::2] = 0.25  # Odd k (indices 0, 2, ...)\n        x[1::2] = 0.75 # Even k (indices 1, 3, ...)\n        return x\n\n    def generate_case_b():\n        n = 1000\n        return lcg_generator(n_values=n, seed=1)\n\n    def generate_case_c():\n        n = 1000\n        p_stay = 0.95\n        \n        # Use a fresh LCG instance for deterministic randomness\n        # We need N-1 values for transitions and N values for noise\n        rand_stream = lcg_generator(n_values=2 * n - 1, seed=1)\n        \n        transition_rands = rand_stream[:n - 1]\n        noise_rands = rand_stream[n - 1:]\n\n        states = np.zeros(n, dtype=int)\n        states[0] = 1\n        for i in range(1, n):\n            if transition_rands[i-1]  (1 - p_stay):\n                states[i] = 1 - states[i-1]\n            else:\n                states[i] = states[i-1]\n        \n        # Generate noise term delta in [-1e-12, 1e-12]\n        deltas = (2 * noise_rands - 1) * 1e-12\n        \n        x = np.zeros(n)\n        x[states == 1] = 0.75 + deltas[states == 1]\n        x[states == 0] = 0.25 + deltas[states == 0]\n        \n        return x\n\n    def generate_case_d():\n        n_ties = 60\n        n_lcg = 40\n        \n        ties = np.full(n_ties, 0.5)\n        lcg_vals = lcg_generator(n_values=n_lcg, seed=1)\n        \n        return np.concatenate((ties, lcg_vals))\n\n    def generate_case_e():\n        n = 30\n        return np.full(n, 0.7)\n\n    # --- Main Logic ---\n\n    test_cases = {\n        'A': generate_case_a,\n        'B': generate_case_b,\n        'C': generate_case_c,\n        'D': generate_case_d,\n        'E': generate_case_e,\n    }\n    \n    results = []\n    # Process cases in the required order A, B, C, D, E\n    for case_id in sorted(test_cases.keys()):\n        generator_func = test_cases[case_id]\n        sequence = generator_func()\n        decision = runs_test(sequence)\n        results.append(decision)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "随机性可以从意想不到的来源产生，包括简单的确定性非线性系统。本练习将探索混沌动力学与伪随机数生成之间的迷人联系，您将使用著名的逻辑斯蒂映射（logistic map）来构建一个PRNG。为了评估其质量，您将实现自相关分析（autocorrelation analysis），这是一种比游程检验更精细的工具，用于量化序列中不同位置元素之间的线性依赖关系。",
            "id": "2403579",
            "problem": "实现一个基于混沌逻辑斯蒂映射的伪随机数生成器，并评估其输出的短滞后自相关性。逻辑斯蒂映射由递推关系 $x_{n+1} = r \\, x_n \\, (1 - x_n)$ 定义，其中参数 $r$ 和状态 $x_n$ 位于区间 $(0,1)$ 内。在本任务中，使用 $r = 4$，这将使系统处于强混沌状态。您必须从指定的初始种子生成序列，然后通过计算指定滞后下的样本自相关来量化所生成的伪随机数的质量。\n\n您的程序必须从基本原理出发实现以下步骤：\n\n1. 使用递推关系 $x_{n+1} = 4 \\, x_n \\, (1 - x_n)$ 生成序列。对于给定的初始种子 $x_0 \\in (0,1)$：\n   - 舍弃最初的 $B$ 步暂态（预烧期），以降低对初始条件的敏感性。\n   - 记录接下来的 $N$ 个值作为伪随机序列 $\\{x_n\\}_{n=1}^{N}$。\n2. 对于记录的序列 $\\{x_n\\}$，构建均值中心化序列 $y_n = x_n - \\bar{x}$，其中 $\\bar{x}$ 是 $\\{x_n\\}$ 的样本均值。使用有限样本估计量计算滞后 $k$ 的样本自相关：\n   $$\\rho(k) = \\frac{\\sum_{n=1}^{N-k} y_n \\, y_{n+k}}{\\sum_{n=1}^{N} y_n^2}.$$\n   如果方差 $\\sum_{n=1}^{N} y_n^2$ 在数值容差范围内为零，则判定该种子的相关性测试失败。\n3. 当且仅当在指定滞后集合上的最大绝对自相关低于一个阈值时，序列才通过相关性测试，\n   $$\\max_{k \\in \\mathcal{K}} |\\rho(k)| \\le \\tau,$$\n   其中阈值由下式给出：\n   $$\\tau = \\frac{c}{\\sqrt{N}}.$$\n   这一选择的动机是弱相关或混合过程的样本自相关行为，其中典型波动的大小与 $N^{-1/2}$ 成比例。\n\n使用以下固定参数作为内置测试套件：\n- 逻辑斯蒂映射参数: $r = 4$。\n- 预烧期长度: $B = 1000$。\n- 记录长度: $N = 100000$。\n- 滞后: $\\mathcal{K} = \\{1, 2, 3, 5, 10, 50, 100\\}$。\n- 阈值缩放常数: $c = 3$。\n- 待测试的种子（按给定顺序）: $[0.123456789, \\, 0.2, \\, 0.50123456789, \\, 10^{-12}, \\, 0.75]$。\n\n对于每个种子，生成序列并评估其是否通过上述定义的相关性测试。整个程序的最终输出必须是单行，包含一个与种子顺序相同的布尔值列表，其中每个布尔值表示该种子通过（True）或失败（False）。您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔的结果列表（例如，$[ \\text{True}, \\text{False}, \\text{True} ]$）。不涉及物理单位。当在数学函数中使用角度时，必须以弧度为单位，但此处不需要角度输入。输出必须是布尔值，并且必须完全按照指定格式呈现在单行的单个列表中。",
            "solution": "问题陈述经过严格验证，被认为是有效的。它在科学上基于混沌动力学和统计时间序列分析的原理，所有必要的参数和定义都已提供，问题是适定的，并且表述客观。该任务是实现一个明确定义的计算算法，并且是可行的。\n\n该问题要求实现一个基于逻辑斯蒂映射的伪随机数生成器 (PRNG)，然后使用自相关测试对生成的序列进行统计验证。\n\n其基本原理是，表现出混沌的确定性动力学系统可以产生看起来随机并通过某些随机性统计检验的序列。逻辑斯蒂映射由递推关系定义：\n$$\nx_{n+1} = r \\cdot x_n \\cdot (1 - x_n)\n$$\n对于指定的参数 $r=4$，该映射对于几乎所有初始条件 $x_0 \\in (0, 1)$ 都是完全混沌的。序列的长期行为由一个统计分布（不变测度）所支配，并且对初始条件高度敏感，这些都是 PRNG 所需的理想特性。\n\n根据问题描述，解决方案分三个阶段构建。\n\n步骤1：序列生成\n对于每个给定的初始种子 $x_0$，生成一个数值序列。\n首先，舍弃最初 $B=1000$ 次迭代的暂态。这个“预烧”阶段让轨迹稳定到系统的吸引子上，从而有效地消除了后续序列对特定 $x_0$ 选择的依赖性。设初始状态为 $z_0 = x_0$。预烧期包括迭代：\n$$\nz_{i+1} = 4 \\cdot z_i \\cdot (1 - z_i) \\quad \\text{for } i = 0, 1, \\dots, B-1\n$$\n预烧期过后，生成并存储接下来的 $N=100000$ 个值。这就构成了伪随机序列 $\\{x_n\\}_{n=1}^N$，其中 $x_n = z_{B+n-1}$。\n\n步骤2：自相关计算\n为评估所生成序列的质量，我们检验其序列相关性。一个高质量的随机序列其值应与前面的值无关。样本自相关函数测量序列元素在给定滞后 $k$ 下的线性相关性。\n首先，通过计算样本均值 $\\bar{x}$ 并创建一个新序列 $\\{y_n\\}_{n=1}^N$ 来对序列进行均值中心化：\n$$\n\\bar{x} = \\frac{1}{N} \\sum_{n=1}^{N} x_n\n$$\n$$\ny_n = x_n - \\bar{x}\n$$\n然后使用提供的估计量计算滞后 $k$ 的样本自相关：\n$$\n\\rho(k) = \\frac{\\sum_{n=1}^{N-k} y_n \\cdot y_{n+k}}{\\sum_{n=1}^{N} y_n^2}\n$$\n分母 $\\sum_{n=1}^{N} y_n^2$ 是离均差平方和。如果该项在数值精度内为零，则表示序列 $\\{x_n\\}$ 是恒定的。如果种子 $x_0$ 是映射的不动点或短周期循环的一部分，就可能发生这种情况。对于种子 $x_0=0.75$，$x_{n+1} = 4 \\cdot 0.75 \\cdot (1-0.75) = 0.75$，所以序列是恒定的。在这种情况下，均值等于该恒定值，所有的 $y_n$ 都为零，分母也为零。问题明确指出，方差为零的测试失败。\n\n步骤3：通过/失败评估\n如果序列在指定的滞后集合 $\\mathcal{K} = \\{1, 2, 3, 5, 10, 50, 100\\}$ 上的自相关都很小，则该序列通过测试。其标准为：\n$$\n\\max_{k \\in \\mathcal{K}} |\\rho(k)| \\le \\tau\n$$\n阈值 $\\tau$ 定义为：\n$$\n\\tau = \\frac{c}{\\sqrt{N}}\n$$\n使用给定的参数 $c=3$ 和 $N=100000$，阈值为 $\\tau = 3 / \\sqrt{100000} \\approx 0.009487$。这个阈值是有统计学动机的。对于一个真正随机的序列，当 $N$ 很大时，样本自相关近似服从均值为 $0$、标准差为 $1/\\sqrt{N}$ 的正态分布。因此，阈值 $\\tau$ 定义了一个置信区间（大约是一个“3-sigma”极限），超出该区间的观测相关性被认为在统计上是显著的，意味着随机性测试失败。\n\n该算法将对所提供列表中的每个种子执行。最终结果是一个布尔值列表，表示由每个种子生成的序列是通过（`True`）还是未通过（`False`）测试。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a pseudo-random number generator based on the chaotic logistic map\n    and assesses the short-lag autocorrelation of its outputs.\n    \"\"\"\n\n    # --- Fixed Parameters ---\n    r = 4.0\n    B = 1000\n    N = 100000\n    lags = [1, 2, 3, 5, 10, 50, 100]\n    c = 3.0\n    \n    # Seeds to be tested as per the problem statement.\n    test_cases = [\n        0.123456789,\n        0.2,\n        0.50123456789,\n        1e-12, # Representing 10^{-12}\n        0.75\n    ]\n\n    results = []\n    for seed in test_cases:\n        results.append(run_correlation_test(seed, r, B, N, lags, c))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_correlation_test(x0, r, B, N, lags, c):\n    \"\"\"\n    Generates a sequence from the logistic map and evaluates its autocorrelation properties.\n\n    Args:\n        x0 (float): The initial seed for the logistic map, in (0, 1).\n        r (float): The parameter of the logistic map.\n        B (int): The number of burn-in iterations.\n        N (int): The length of the sequence to record.\n        lags (list[int]): The set of lags k to compute autocorrelation for.\n        c (float): The scaling constant for the significance threshold.\n\n    Returns:\n        bool: True if the sequence passes the correlation test, False otherwise.\n    \"\"\"\n    \n    # --- Step 1: Sequence Generation ---\n    x = float(x0) # Ensure float64 for precision.\n    \n    # Burn-in period to discard initial transient\n    for _ in range(B):\n        x = r * x * (1.0 - x)\n        \n    # Record the sequence after burn-in\n    sequence = np.zeros(N, dtype=np.float64)\n    for i in range(N):\n        x = r * x * (1.0 - x)\n        sequence[i] = x\n\n    # --- Step 2: Autocorrelation Computation ---\n    # Create the mean-centered sequence y_n = x_n - mean(x)\n    mean_x = np.mean(sequence)\n    y = sequence - mean_x\n    \n    # Compute the denominator of the autocorrelation formula\n    # This is equivalent to sum(y_n^2) from n=1 to N\n    sum_y_sq = np.dot(y, y)\n    \n    # If variance is zero to numerical tolerance, the test fails\n    if sum_y_sq  1e-20:\n        return False\n\n    max_abs_rho = 0.0\n    \n    for k in lags:\n        # Numerator: sum_{n=1 to N-k} y_n * y_{n+k}\n        # Implemented with numpy slicing and dot product for efficiency\n        numerator = np.dot(y[:-k], y[k:])\n        \n        # Sample autocorrelation at lag k\n        rho_k = numerator / sum_y_sq\n        \n        # Track the maximum absolute autocorrelation\n        if abs(rho_k) > max_abs_rho:\n            max_abs_rho = abs(rho_k)\n            \n    # --- Step 3: Pass/Fail Evaluation ---\n    # Compute the threshold for statistical significance\n    threshold = c / np.sqrt(N)\n    \n    # The test passes if the max absolute autocorrelation is below the threshold\n    return max_abs_rho = threshold\n\n# Execute the main function\nsolve()\n```"
        }
    ]
}