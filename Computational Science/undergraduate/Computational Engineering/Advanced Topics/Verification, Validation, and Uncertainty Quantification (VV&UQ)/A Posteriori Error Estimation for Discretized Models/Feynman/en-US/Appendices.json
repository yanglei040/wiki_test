{
    "hands_on_practices": [
        {
            "introduction": "A posteriori error estimators are constructed from terms that measure how poorly the approximate solution satisfies the underlying physics. This practice focuses on mastering these core components: the element residual, which measures the error within each element, and the flux jump, which measures the discontinuity across element boundaries. By deriving and computing a residual-based estimator for a simple Finite Element Method (FEM) setup from first principles, you will gain a concrete understanding of the mechanics behind error estimation. ",
            "id": "2370198",
            "problem": "Consider the scalar diffusion model problem (a Poisson-type partial differential equation (PDE)) on the unit square domain $\\Omega = [0,1]^{2}$ with homogeneous Dirichlet boundary conditions:\nfind $u \\in H_{0}^{1}(\\Omega)$ such that\n$-\\Delta u = f$ in $\\Omega$, and $u = 0$ on $\\partial \\Omega$,\nwhere $f(x,y) = 1$ for all $(x,y) \\in \\Omega$. Let $u_{h} \\in V_{h} \\subset H_{0}^{1}(\\Omega)$ be the conforming finite element method (FEM) approximation on the triangulation $\\mathcal{T}_{h}$ obtained by splitting the unit square into $2$ congruent right triangles using the diagonal from $(0,0)$ to $(1,1)$, with $V_{h}$ consisting of continuous, piecewise-linear ($P_{1}$) functions subordinate to $\\mathcal{T}_{h}$.\n\nStarting from the weak formulation and the definitions of the elementwise strong residual and interior-edge flux jumps, construct an explicit residual-based a posteriori error estimator $\\eta$ that targets the gradient error norm $\\|\\nabla(u - u_{h})\\|_{L^{2}(\\Omega)}$, expressed in terms of element residuals and interior-edge flux jumps. Then evaluate your constructed estimator $\\eta$ on this mesh and data. Express the final estimator value $\\eta$ as a single exact real number. Do not round.",
            "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- **PDE**: $-\\Delta u = f$ in $\\Omega$.\n- **Domain**: $\\Omega = [0,1]^{2}$.\n- **Boundary Condition**: $u = 0$ on $\\partial \\Omega$ (homogeneous Dirichlet).\n- **Source Term**: $f(x,y) = 1$ for all $(x,y) \\in \\Omega$.\n- **Exact Solution Space**: $u \\in H_{0}^{1}(\\Omega)$.\n- **Finite Element Approximation**: $u_{h} \\in V_{h} \\subset H_{0}^{1}(\\Omega)$, where $V_h$ consists of continuous, piecewise-linear ($P_1$) functions.\n- **Mesh**: The triangulation $\\mathcal{T}_{h}$ is formed by splitting the unit square into $2$ congruent right triangles using the diagonal from $(0,0)$ to $(1,1)$.\n- **Task**: To construct and evaluate an explicit residual-based a posteriori error estimator $\\eta$ for the gradient error norm $\\|\\nabla(u - u_{h})\\|_{L^{2}(\\Omega)}$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is a standard application of a posteriori error estimation for the finite element method, a well-established topic in computational engineering and numerical analysis for PDEs. It is fundamentally sound.\n- **Well-Posed**: The Poisson problem with homogeneous Dirichlet conditions on a convex domain is well-posed. The task of constructing and evaluating a specific error estimator for a given simple mesh and data is clearly defined and leads to a unique solution.\n- **Objective**: The problem is stated using precise mathematical terminology, free of ambiguity or subjective claims.\n- **Completeness and Consistency**: All necessary components—PDE, domain, boundary conditions, source term, mesh, and finite element space—are fully specified and are mutually consistent.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A solution will be constructed.\n\nThe objective is to construct and evaluate a residual-based a posteriori error estimator for the error $e = u - u_h$ in the energy norm, which for this problem is $\\|\\nabla e\\|_{L^2(\\Omega)}$.\n\nThe weak formulation for the problem is to find $u \\in H_0^1(\\Omega)$ such that\n$$a(u, v) = L(v) \\quad \\forall v \\in H_0^1(\\Omega)$$\nwhere the bilinear form is $a(w,v) = \\int_\\Omega \\nabla w \\cdot \\nabla v \\, d\\mathbf{x}$ and the linear form is $L(v) = \\int_\\Omega f v \\, d\\mathbf{x}$. The corresponding finite element problem is to find $u_h \\in V_h$ such that\n$$a(u_h, v_h) = L(v_h) \\quad \\forall v_h \\in V_h$$\nSubtracting these two equations yields the Galerkin orthogonality property for the error $e = u - u_h$:\n$$a(e, v_h) = 0 \\quad \\forall v_h \\in V_h$$\nThe squared energy norm of the error is $a(e,e)$. We have $a(e,e) = a(u,e) - a(u_h,e) = L(e) - a(u_h,e)$.\nIntegrating by parts over each element $K \\in \\mathcal{T}_h$:\n$$a(u_h, e) = \\sum_{K \\in \\mathcal{T}_h} \\int_K \\nabla u_h \\cdot \\nabla e \\, d\\mathbf{x} = \\sum_{K \\in \\mathcal{T}_h} \\left( -\\int_K (\\Delta u_h) e \\, d\\mathbf{x} + \\int_{\\partial K} (\\nabla u_h \\cdot n_K) e \\, ds \\right)$$\nwhere $n_K$ is the outward unit normal to the boundary $\\partial K$ of element $K$.\nThus, the error equation becomes:\n$$\\|\\nabla e\\|_{L^2(\\Omega)}^2 = a(e,e) = \\sum_{K \\in \\mathcal{T}_h} \\int_K (f + \\Delta u_h) e \\, d\\mathbf{x} - \\sum_{K \\in \\mathcal{T}_h} \\int_{\\partial K} (\\nabla u_h \\cdot n_K) e \\, ds$$\nThe sum of boundary integrals can be split into contributions from interior edges $\\mathcal{E}_I$ and boundary edges $\\mathcal{E}_\\partial$. Since $e \\in H_0^1(\\Omega)$, $e=0$ on $\\partial\\Omega$, so integrals over $\\mathcal{E}_\\partial$ vanish. For an interior edge $E$ shared by elements $K_1$ and $K_2$, the contribution is $\\int_E ((\\nabla u_h|_{K_1} \\cdot n_1) + (\\nabla u_h|_{K_2} \\cdot n_2)) e \\, ds$. We define the flux jump across $E$ as $J_E = [\\nabla u_h \\cdot n] = \\nabla u_h|_{K_1} \\cdot n_1 + \\nabla u_h|_{K_2} \\cdot n_2$. The element residual is $R_K = f + \\Delta u_h$.\nThe error equation is then\n$$\\|\\nabla e\\|_{L^2(\\Omega)}^2 = \\sum_{K \\in \\mathcal{T}_h} \\int_K R_K e \\, d\\mathbf{x} + \\sum_{E \\in \\mathcal{E}_I} \\int_E J_E e \\, ds$$\nwhere we have relabeled the jump direction for convenience in the final sum.\nBy applying Cauchy-Schwarz inequality and interpolation estimates, one can prove the reliability estimate $\\|\\nabla e\\|_{L^2(\\Omega)} \\leq C \\eta$, where $\\eta$ is the error estimator. A standard explicit residual-based a posteriori error estimator is constructed from these residual terms. We define the total estimator $\\eta$ by its square:\n$$\\eta^2 = \\sum_{K \\in \\mathcal{T}_h} \\eta_K^2 = \\sum_{K \\in \\mathcal{T}_h} \\left( h_K^2 \\|R_K\\|_{L^2(K)}^2 + \\frac{1}{2} \\sum_{E \\in \\partial K \\cap \\mathcal{E}_I} h_E \\|J_E\\|_{L^2(E)}^2 \\right)$$\nHere $h_K$ is the diameter of element $K$ and $h_E$ is the length of edge $E$. Since $u_h$ is piecewise linear, the element-wise Laplacian $\\Delta u_h = 0$ for all $K \\in \\mathcal{T}_h$. The source is $f=1$. Thus, the element residual is $R_K = 1$. The estimator simplifies to:\n$$\\eta^2 = \\sum_{K \\in \\mathcal{T}_h} \\left( h_K^2 \\|1\\|_{L^2(K)}^2 + \\frac{1}{2} \\sum_{E \\in \\partial K \\cap \\mathcal{E}_I} h_E \\|J_E\\|_{L^2(E)}^2 \\right)$$\n\nNow, we evaluate this estimator for the given problem.\nThe domain $\\Omega = [0,1]^2$ is partitioned into two triangles:\n- $K_1$: vertices at $(0,0), (1,0), (1,1)$.\n- $K_2$: vertices at $(0,0), (0,1), (1,1)$.\nThe set of interior edges $\\mathcal{E}_I$ contains a single edge $E_{12}$ along the diagonal from $(0,0)$ to $(1,1)$.\n\nThe finite element space $V_h$ consists of continuous piecewise linear functions. The nodes of the mesh are the four corners of the square: $(0,0)$, $(1,0)$, $(0,1)$, and $(1,1)$. All these nodes lie on the boundary $\\partial \\Omega$. Due to the homogeneous Dirichlet condition $u=0$ on $\\partial\\Omega$, the discrete solution $u_h$ must be zero at all these nodes. A linear function on a triangle is uniquely determined by its values at the three vertices. Since $u_h$ is zero at all vertices of both $K_1$ and $K_2$, it follows that $u_h(\\mathbf{x}) = 0$ for all $\\mathbf{x} \\in \\Omega$.\nConsequently, the gradient is also zero: $\\nabla u_h(\\mathbf{x}) = \\mathbf{0}$ for all $\\mathbf{x} \\in \\Omega$.\n\nWith $u_h \\equiv 0$, the flux jump across any interior edge is zero:\n$$J_E = [\\nabla u_h \\cdot n] = [\\mathbf{0} \\cdot n] = 0$$\nTherefore, the second term in the estimator vanishes. The estimator simplifies to the sum of element residual terms:\n$$\\eta^2 = \\sum_{K \\in \\mathcal{T}_h} h_K^2 \\|1\\|_{L^2(K)}^2$$\n\nWe compute the components for each element.\nFor element $K_1$:\n- The vertices are $(0,0)$, $(1,0)$, $(1,1)$. The side lengths are $1$, $1$, and $\\sqrt{(1-0)^2 + (1-0)^2} = \\sqrt{2}$.\n- The element diameter is the length of the longest side, so $h_{K_1} = \\sqrt{2}$.\n- The area of $K_1$ is $\\frac{1}{2} \\times 1 \\times 1 = \\frac{1}{2}$.\n- The squared $L^2$-norm of the residual is $\\|1\\|_{L^2(K_1)}^2 = \\int_{K_1} 1^2 \\, d\\mathbf{x} = \\text{Area}(K_1) = \\frac{1}{2}$.\n- The contribution from $K_1$ is $\\eta_{K_1}^2 = h_{K_1}^2 \\|1\\|_{L^2(K_1)}^2 = (\\sqrt{2})^2 \\times \\frac{1}{2} = 2 \\times \\frac{1}{2} = 1$.\n\nFor element $K_2$:\n- The vertices are $(0,0)$, $(0,1)$, $(1,1)$. The side lengths are also $1$, $1$, and $\\sqrt{2}$.\n- The element diameter is $h_{K_2} = \\sqrt{2}$.\n- The area of $K_2$ is $\\frac{1}{2} \\times 1 \\times 1 = \\frac{1}{2}$.\n- The squared $L^2$-norm of the residual is $\\|1\\|_{L^2(K_2)}^2 = \\int_{K_2} 1^2 \\, d\\mathbf{x} = \\text{Area}(K_2) = \\frac{1}{2}$.\n- The contribution from $K_2$ is $\\eta_{K_2}^2 = h_{K_2}^2 \\|1\\|_{L^2(K_2)}^2 = (\\sqrt{2})^2 \\times \\frac{1}{2} = 2 \\times \\frac{1}{2} = 1$.\n\nThe total estimator value squared is the sum of the contributions from each element:\n$$\\eta^2 = \\eta_{K_1}^2 + \\eta_{K_2}^2 = 1 + 1 = 2$$\nThe value of the estimator is therefore:\n$$\\eta = \\sqrt{2}$$",
            "answer": "$$\\boxed{\\sqrt{2}}$$"
        },
        {
            "introduction": "The primary purpose of a posteriori error estimation is to guide the simulation process, telling us where to focus computational effort to improve accuracy. This hands-on coding exercise demonstrates how local error indicators are used to drive adaptive mesh refinement (AMR). You will investigate how the choice of error measure—specifically, the $L^2$ norm versus the $H^1$ seminorm—dramatically influences where the mesh is refined, teaching a crucial lesson about resolving different types of solution features like sharp internal layers. ",
            "id": "2370210",
            "problem": "You are asked to implement an adaptive mesh refinement study that compares how the choice of error norm influences where the mesh refines for a one-dimensional function with a sharp internal layer. The study must start from first principles: definitions of norms, an interpolation operator, and an elementwise a posteriori error indicator that is computable from the data on the current mesh. The implementation must be mathematically universal and not tied to any specific computing platform beyond standard numerical integration.\n\nConsider the open interval $\\left(0,1\\right)$ and the scalar function\n$$\nu(x) \\;=\\; \\tfrac{1}{2}\\left(1 + \\tanh\\!\\left(\\dfrac{x-x_{0}}{\\varepsilon}\\right)\\right),\n$$\nwhere $x \\in \\left[0,1\\right]$, $x_{0} \\in \\left(0,1\\right)$ locates the internal layer, and $\\varepsilon \\in \\left(0,1\\right)$ controls the layer thickness. This model creates a sharp internal layer near $x=x_{0}$ when $\\varepsilon$ is small.\n\nYou will discretize the interval $\\left[0,1\\right]$ with a partition into line segments (elements) and approximate $u$ by the continuous, piecewise linear interpolant $I_{h}u$ defined by sampling $u$ at the mesh nodes. For an element $K = [a,b]$, define two local a posteriori error indicators based on the exact definitions of the $L^{2}$ norm and the $H^{1}$ semi-norm:\n\n- The $L^{2}$-based indicator:\n$$\n\\eta_{K}^{L^{2}} \\;=\\; \\left(\\int_{a}^{b} \\left(u(x) - I_{h}u(x)\\right)^{2} \\, dx \\right)^{1/2}.\n$$\n\n- The $H^{1}$-based indicator (using the $H^{1}$ semi-norm on the element):\n$$\n\\eta_{K}^{H^{1}} \\;=\\; \\left(\\int_{a}^{b} \\left(u'(x) - \\left(I_{h}u\\right)'(x)\\right)^{2} \\, dx \\right)^{1/2}.\n$$\n\nHere $u'(x)$ is the classical derivative of $u(x)$ and $\\left(I_{h}u\\right)'(x)$ equals the constant slope $\\dfrac{u(b)-u(a)}{b-a}$ on the element $K$. The integral must be evaluated numerically using Gaussian quadrature of sufficiently high order to ensure stable and accurate results for small $\\varepsilon$.\n\nStarting from a uniform mesh of $N_{0}$ equal elements on $\\left[0,1\\right]$, perform iterative adaptive refinement for a prescribed number of steps $S$ by the following generic procedure, once using $\\eta_{K}^{L^{2}}$ and once using $\\eta_{K}^{H^{1}}$:\n\n1. On the current mesh, compute the chosen indicator $\\eta_{K}$ for every element $K$.\n2. Mark the top fraction $\\theta$ (with $0<\\theta<1$) of elements with the largest indicator values.\n3. Refine each marked element by bisecting it at its midpoint, thus creating a nested mesh.\n\nAfter completing $S$ refinement steps, quantify how strongly the mesh is concentrated around the internal layer by computing the concentration ratio $C$ defined as\n$$\nC \\;=\\; \\frac{\\#\\left\\{K : \\text{the midpoint of }K\\text{ satisfies } |x_{\\text{mid}} - x_{0}| \\le \\delta \\right\\}}{\\#\\{\\text{all elements}\\}},\n$$\nwhere $\\delta = m_{\\delta}\\,\\varepsilon$ and $m_{\\delta}>0$ is a chosen multiplier. Compute $C^{L^{2}}$ and $C^{H^{1}}$ for the two adaptation runs and report both. All ratios must be reported as decimals, not as percentages.\n\nImplement a program that performs the above procedure and outputs, for each test case, the pair $\\left[C^{L^{2}},\\,C^{H^{1}}\\right]$.\n\nUse the following test suite. Each test case specifies the parameters $\\left(\\varepsilon, x_{0}, N_{0}, S, \\theta, m_{\\delta}\\right)$:\n\n- Test case $1$ (internal layer centered, sharp): $\\left(\\varepsilon, x_{0}, N_{0}, S, \\theta, m_{\\delta}\\right) = \\left(0.02,\\, 0.5,\\, 8,\\, 6,\\, 0.3,\\, 3\\right)$.\n- Test case $2$ (internal layer near boundary, very sharp): $\\left(\\varepsilon, x_{0}, N_{0}, S, \\theta, m_{\\delta}\\right) = \\left(0.01,\\, 0.05,\\, 8,\\, 6,\\, 0.3,\\, 3\\right)$.\n- Test case $3$ (milder layer): $\\left(\\varepsilon, x_{0}, N_{0}, S, \\theta, m_{\\delta}\\right) = \\left(0.10,\\, 0.5,\\, 8,\\, 4,\\, 0.3,\\, 3\\right)$.\n\nFinal output format: Your program should produce a single line of output containing a list of length $3$, where each entry is a two-entry list $\\left[C^{L^{2}}, C^{H^{1}}\\right]$ for the corresponding test case. Format each decimal with exactly six digits after the decimal point, and print the entire result as a comma-separated list enclosed in square brackets, for example:\n$$\n\\left[\\left[c_{1}^{L^{2}},c_{1}^{H^{1}}\\right],\\left[c_{2}^{L^{2}},c_{2}^{H^{1}}\\right],\\left[c_{3}^{L^{2}},c_{3}^{H^{1}}\\right]\\right].\n$$\nNo units are involved in this problem, and all angles (if any) are in radians by mathematical convention. The outputs must be decimals as specified above.",
            "solution": "The problem as stated is subjected to validation.\n\nGivens extracted verbatim are as follows:\n- Domain of interest: Open interval $\\left(0,1\\right)$, with discretization on the closed interval $\\left[0,1\\right]$.\n- Scalar function: $u(x) \\;=\\; \\tfrac{1}{2}\\left(1 + \\tanh\\!\\left(\\dfrac{x-x_{0}}{\\varepsilon}\\right)\\right)$, with $x \\in \\left[0,1\\right]$, $x_{0} \\in \\left(0,1\\right)$, and $\\varepsilon \\in \\left(0,1\\right)$.\n- Discretization: A partition of $\\left[0,1\\right]$ into line segment elements.\n- Approximation: Continuous, piecewise linear interpolant $I_{h}u$ sampling $u$ at mesh nodes.\n- Error indicators for an element $K = [a,b]$:\n  - $L^{2}$-based: $\\eta_{K}^{L^{2}} \\;=\\; \\left(\\int_{a}^{b} \\left(u(x) - I_{h}u(x)\\right)^{2} \\, dx \\right)^{1/2}$.\n  - $H^{1}$-based: $\\eta_{K}^{H^{1}} \\;=\\; \\left(\\int_{a}^{b} \\left(u'(x) - \\left(I_{h}u\\right)'(x)\\right)^{2} \\, dx \\right)^{1/2}$, where $\\left(I_{h}u\\right)'(x) = \\dfrac{u(b)-u(a)}{b-a}$.\n- Adaptive refinement procedure:\n  - Initial state: Uniform mesh of $N_{0}$ elements.\n  - Number of steps: $S$.\n  - Marking strategy: Mark the top fraction $\\theta$ of elements with the largest indicator values.\n  - Refinement method: Bisect each marked element at its midpoint.\n- Analysis metric: Concentration ratio $C \\;=\\; \\frac{\\#\\left\\{K : |x_{\\text{mid}} - x_{0}| \\le \\delta \\right\\}}{\\#\\{\\text{all elements}\\}}$, where $\\delta = m_{\\delta}\\,\\varepsilon$.\n- Test cases:\n  1. $\\left(\\varepsilon, x_{0}, N_{0}, S, \\theta, m_{\\delta}\\right) = \\left(0.02,\\, 0.5,\\, 8,\\, 6,\\, 0.3,\\, 3\\right)$.\n  2. $\\left(\\varepsilon, x_{0}, N_{0}, S, \\theta, m_{\\delta}\\right) = \\left(0.01,\\, 0.05,\\, 8,\\, 6,\\, 0.3,\\, 3\\right)$.\n  3. $\\left(\\varepsilon, x_{0}, N_{0}, S, \\theta, m_{\\delta}\\right) = \\left(0.10,\\, 0.5,\\, 8,\\, 4,\\, 0.3,\\, 3\\right)$.\n\nThe problem is a standard exercise in computational engineering and numerical analysis, specifically concerning a posteriori error estimation for discretized models. It is scientifically grounded in the theory of finite element methods and functional analysis. The procedure is well-posed, objective, and all parameters are specified. Therefore, the problem is valid and a solution will be provided.\n\nThe solution is constructed from first principles as requested.\n\nFirst, we analyze the model function $u(x)$ and its derivatives. The function $u(x) = \\frac{1}{2}\\left(1 + \\tanh\\left(\\frac{x-x_0}{\\varepsilon}\\right)\\right)$ represents a smooth transition from approximately $0$ to $1$ over a region of width proportional to $\\varepsilon$ centered at $x_0$. Its first derivative is $u'(x) = \\frac{1}{2\\varepsilon} \\text{sech}^2\\left(\\frac{x-x_0}{\\varepsilon}\\right)$. This function is a positive, symmetric bell-shaped curve, sharply peaked at $x=x_0$, which represents the high-gradient internal layer. The second derivative is $u''(x) = -\\frac{1}{\\varepsilon^2} \\text{sech}^2\\left(\\frac{x-x_0}{\\varepsilon}\\right) \\tanh\\left(\\frac{x-x_0}{\\varepsilon}\\right)$. This function is antisymmetric about $x=x_0$, is zero at $x=x_0$, and has two extrema of opposite sign located at $x \\approx x_0 \\pm 0.88\\varepsilon$. The second derivative quantifies the curvature of the function.\n\nSecond, we consider the discretization and interpolation. The interval $\\left[0,1\\right]$ is partitioned by nodes $0=z_0 < z_1 < \\dots < z_M=1$. An element is an interval $K_i = [z_{i-1}, z_i]$. On each element $K_i$, the exact solution $u(x)$ is approximated by the linear polynomial $I_h u(x)$ that connects the points $(z_{i-1}, u(z_{i-1}))$ and $(z_i, u(z_i))$. The explicit form is $I_h u(x) = u(z_{i-1}) + \\frac{u(z_i)-u(z_{i-1})}{z_i-z_{i-1}}(x - z_{i-1})$ for $x \\in K_i$. The derivative $(I_h u)'(x)$ is therefore piecewise constant, equal to the slope $\\frac{u(z_i)-u(z_{i-1})}{z_i-z_{i-1}}$ on each element $K_i$.\n\nThird, we analyze the two a posteriori error indicators. These indicators are defined as the exact local interpolation error measured in two different norms.\nThe $L^2$-based indicator, $\\eta_K^{L^2}$, measures the root-mean-square error in the function value itself. Standard interpolation theory for linear elements states that the error $u - I_h u$ scales with the element size $h_K$ and the second derivative of the function, i.e., $\\|u - I_h u\\|_{L^2(K)} \\sim h_K^2 \\|u''\\|_{L^2(K)}$. Since $|u''(x)|$ is maximal on the \"shoulders\" of the layer (i.e., offset from $x_0$), the $L^2$-based indicator will be largest in elements located in these regions. Consequently, adaptive refinement driven by $\\eta_K^{L^2}$ will preferentially insert new nodes on either side of the layer's center, not directly at its steepest point.\nThe $H^1$-based indicator, $\\eta_K^{H^1}$, measures the root-mean-square error in the derivative. The integrand is $(u'(x) - (I_h u)'(x))^2$. The true derivative $u'(x)$ is a sharply peaked function, while the approximate derivative $(I_h u)'(x)$ is merely a constant secant slope over the element. The primary contribution to this integral comes from regions where $u'(x)$ itself is large. As $u'(x)$ is maximally concentrated at $x=x_0$, the $\\eta_K^{H^1}$ indicator will be largest for a small number of elements that contain or are immediately adjacent to $x_0$. Therefore, refinement driven by $\\eta_K^{H^1}$ will focus mesh points very tightly around the center of the internal layer.\n\nFourth, the numerical implementation requires an algorithm for the adaptive mesh refinement (AMR) loop. Starting with a uniform mesh of $N_0$ elements, the following steps are repeated $S$ times:\n1.  For each element $K$ in the current mesh, compute the chosen error indicator, $\\eta_K^{L^2}$ or $\\eta_K^{H^1}$. This requires numerical quadrature, as the integrals are not analytically trivial. A robust adaptive quadrature method, such as that provided by `scipy.integrate.quad`, is necessary to accurately evaluate the integrals, especially for small $\\varepsilon$ where the integrands become highly localized.\n2.  Identify the elements to be refined. This is done via a Dörfler marking strategy: sort the elements by their indicator values and mark the top $\\lceil \\theta \\cdot M \\rceil$ elements, where $M$ is the current number of elements.\n3.  Generate the new mesh by adding the midpoints of all marked elements to the existing set of nodes. The resulting set of nodes must be sorted and duplicates removed to define the next-level mesh.\n\nFinally, after $S$ refinement steps, the concentration ratio $C$ is computed. This metric quantifies the effectiveness of the refinement strategy in concentrating the mesh around the feature of interest. The calculation involves counting the number of final elements whose midpoint $x_{\\text{mid}}$ falls within the interval $[x_0 - \\delta, x_0 + \\delta]$ and dividing by the total number of elements. We anticipate that $C^{H^1}$ will be consistently larger than $C^{L^2}$ across all test cases, demonstrating the superior localization property of the $H^1$-based indicator for resolving sharp gradients.\nThe implementation will follow this logic precisely for each of the three supplied test cases.",
            "answer": "```python\nimport numpy as np\nfrom scipy import integrate\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to run the adaptive mesh refinement study for all test cases.\n    \"\"\"\n\n    test_cases = [\n        # (epsilon, x0, N0, S, theta, m_delta)\n        (0.02, 0.5, 8, 6, 0.3, 3),\n        (0.01, 0.05, 8, 6, 0.3, 3),\n        (0.10, 0.5, 8, 4, 0.3, 3),\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        eps, x0, N0, S, theta, m_delta = case\n        \n        # Run refinement for L2 indicator\n        C_L2 = run_refinement(eps, x0, N0, S, theta, m_delta, indicator_type='L2')\n        \n        # Run refinement for H1 indicator\n        C_H1 = run_refinement(eps, x0, N0, S, theta, m_delta, indicator_type='H1')\n\n        all_results.append([C_L2, C_H1])\n\n    # Format the final output string as per problem specification.\n    formatted_results = []\n    for c_l2, c_h1 in all_results:\n        formatted_results.append(f\"[{c_l2:.6f},{c_h1:.6f}]\")\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\ndef u(x, x0, eps):\n    \"\"\"The exact function u(x).\"\"\"\n    return 0.5 * (1.0 + np.tanh((x - x0) / eps))\n\ndef du_dx(x, x0, eps):\n    \"\"\"The exact derivative u'(x).\"\"\"\n    val = (x - x0) / eps\n    return 0.5 / eps * (1.0 / np.cosh(val))**2\n\ndef run_refinement(eps, x0, N0, S, theta, m_delta, indicator_type):\n    \"\"\"\n    Performs the adaptive mesh refinement procedure for a given indicator type.\n    \"\"\"\n    # Initial uniform mesh\n    nodes = np.linspace(0.0, 1.0, N0 + 1)\n\n    for _ in range(S):\n        num_elements = len(nodes) - 1\n        indicators = np.zeros(num_elements)\n        elements = []\n\n        # Compute indicators for all elements\n        for i in range(num_elements):\n            a, b = nodes[i], nodes[i+1]\n            elements.append((a, b))\n            ua, ub = u(a, x0, eps), u(b, x0, eps)\n            \n            if b == a:  # Should not happen with proper refinement\n                indicators[i] = 0.0\n                continue\n            \n            slope = (ub - ua) / (b - a)\n\n            if indicator_type == 'L2':\n                integrand = lambda x: (u(x, x0, eps) - (ua + slope * (x - a)))**2\n            elif indicator_type == 'H1':\n                integrand = lambda x: (du_dx(x, x0, eps) - slope)**2\n            else:\n                raise ValueError(\"Invalid indicator type.\")\n\n            # Numerical integration\n            integral_val, _ = integrate.quad(integrand, a, b, limit=100)\n            indicators[i] = math.sqrt(integral_val)\n\n        # Mark elements for refinement\n        num_to_refine = math.ceil(theta * num_elements)\n        if num_to_refine > 0:\n            # Get indices of elements with largest indicators\n            refine_indices = np.argsort(indicators)[-num_to_refine:]\n        else:\n            refine_indices = []\n\n        # Refine marked elements by bisection\n        new_nodes_to_add = []\n        for index in refine_indices:\n            a, b = elements[index]\n            midpoint = (a + b) / 2.0\n            new_nodes_to_add.append(midpoint)\n        \n        # Create new sorted mesh\n        nodes = np.union1d(nodes, new_nodes_to_add)\n\n    # Compute concentration ratio C\n    delta = m_delta * eps\n    num_final_elements = len(nodes) - 1\n    concentrated_count = 0\n\n    for i in range(num_final_elements):\n        midpoint = (nodes[i] + nodes[i+1]) / 2.0\n        if abs(midpoint - x0) = delta:\n            concentrated_count += 1\n    \n    concentration_ratio = concentrated_count / num_final_elements if num_final_elements > 0 else 0.0\n    \n    return concentration_ratio\n\nsolve()\n\n```"
        },
        {
            "introduction": "An error estimator quantifies the total predicted error with a single number, $\\eta$. To truly grasp what this represents, this practice challenges you to think in reverse. Instead of calculating $\\eta$ from a given solution, you will construct a plausible \"fake\" error vector whose discrete norm is precisely equal to a target $\\eta$, reinforcing the fundamental connection between the error value, the direction of the error, and the discrete norms induced by the system's mass and stiffness matrices. ",
            "id": "2370222",
            "problem": "You are given the task of constructing, for a discretized one-dimensional model, a plausible surrogate exact solution $u_{\\text{fake}}$ such that the error norm $\\lVert u_{\\text{fake}} - u_h \\rVert$ matches a specified error magnitude $\\eta$, where $u_h$ is a given computed solution. Work entirely within a finite-dimensional setting induced by standard one-dimensional linear finite elements on the interval $[0,1]$ with a uniform mesh of $n$ nodes. Your construction must be principled: it must follow from the fundamental definition of a norm induced by a symmetric positive definite matrix and must respect the discrete structure of the chosen norm.\n\nFundamental base:\n- A norm on $\\mathbb{R}^m$ induced by a symmetric positive definite matrix $N \\in \\mathbb{R}^{m \\times m}$ is defined by\n$$\n\\lVert v \\rVert_N \\equiv \\sqrt{v^{\\mathsf{T}} N v}.\n$$\n- For continuous, piecewise-linear finite elements on a uniform mesh with mesh size $h = \\frac{1}{n-1}$ and nodes $x_i = i h$ for $i=0,\\dots,n-1$:\n  - The discrete $L^2$ norm is induced by the global mass matrix $M \\in \\mathbb{R}^{n \\times n}$ assembled from the element mass matrix\n$$\nM^{(e)} = \\frac{h}{6} \\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix}.\n$$\n  - The discrete energy norm associated with the Poisson bilinear form $a(u,v) = \\int_0^1 u'(x) v'(x)\\,dx$ and homogeneous Dirichlet boundary conditions at $x=0$ and $x=1$ is induced on the interior degrees of freedom by the reduced stiffness matrix $K_{\\text{int}} \\in \\mathbb{R}^{(n-2) \\times (n-2)}$ assembled from the element stiffness matrix\n$$\nK^{(e)} = \\frac{1}{h} \\begin{bmatrix} 1  -1 \\\\ -1  1 \\end{bmatrix}.\n$$\n  The energy seminorm for a vector $w \\in \\mathbb{R}^{n}$ with zero boundary entries is\n  $$\n  \\lVert w \\rVert_{K} \\equiv \\sqrt{w_{\\text{int}}^{\\mathsf{T}} K_{\\text{int}} w_{\\text{int}}},\n  $$\n  where $w_{\\text{int}} \\in \\mathbb{R}^{n-2}$ collects the interior components of $w$.\n\nTask:\n- For each test case below, construct a method that, given $u_h$ and $\\eta$, returns a vector $u_{\\text{fake}}$ such that the chosen discrete norm of the error $e = u_{\\text{fake}} - u_h$ equals $\\eta$ within a numerically reasonable tolerance. Your construction must be derived from first principles: start from the definition of the induced norm, choose a nonzero direction compatible with the chosen norm, and scale that direction so that the resulting norm equals $\\eta$. Do not assume or use any pre-derived shortcut formulas beyond the definition of the induced norm and the finite element assembly rules stated above.\n\n- Scientific realism requirement: When using the energy norm, enforce homogeneous Dirichlet boundary conditions by working on interior degrees of freedom only, and extend by zero at the boundary nodes. When using the $L^2$ norm, use the full set of $n$ nodes.\n\nNumerical details the program must implement:\n- Construct the uniform mesh with $n$ nodes on $[0,1]$.\n- Assemble the global mass matrix $M$ and the reduced stiffness matrix $K_{\\text{int}}$ according to the element matrices above.\n- For the $L^2$ norm, compute $\\lVert e \\rVert_{M} = \\sqrt{e^{\\mathsf{T}} M e}$.\n- For the energy norm, compute $\\lVert e \\rVert_{K} = \\sqrt{e_{\\text{int}}^{\\mathsf{T}} K_{\\text{int}} e_{\\text{int}}}$ where $e_{\\text{int}}$ are the interior entries of $e$.\n- Choose a nonzero direction compatible with each norm and scale it so that the induced norm of the error equals exactly $\\eta$ in exact arithmetic. Handle the case $\\eta = 0$ by returning $u_{\\text{fake}} = u_h$.\n\nTest suite:\nFor each case below, construct $u_h$ by sampling the indicated function at the mesh nodes $x_i$.\n\n- Case $1$ (happy path, $L^2$ norm):\n  - Norm type: $L^2$\n  - $n = 6$\n  - $u_h(x) = \\sin(\\pi x)$\n  - $\\eta = 0.4$\n- Case $2$ (happy path, energy norm with homogeneous Dirichlet boundary conditions):\n  - Norm type: energy\n  - $n = 8$\n  - $u_h(x) = x(1-x)$\n  - $\\eta = 0.2$\n- Case $3$ (edge case, zero error target, $L^2$ norm):\n  - Norm type: $L^2$\n  - $n = 5$\n  - $u_h(x) = 0$\n  - $\\eta = 0.0$\n- Case $4$ (edge case, very small error target, energy norm):\n  - Norm type: energy\n  - $n = 10$\n  - $u_h(x) = \\sin(2\\pi x)$\n  - $\\eta = 10^{-12}$\n- Case $5$ (small mesh, arbitrary error target, $L^2$ norm):\n  - Norm type: $L^2$\n  - $n = 3$\n  - $u_h(x) = x$\n  - $\\eta = 1.2345$\n\nOutput specification:\n- For each test case, return a boolean indicating whether the constructed $u_{\\text{fake}}$ achieves the target error magnitude within the tolerance\n$$\n\\text{tol} = 10^{-12} + 10^{-10} \\max(1, \\eta).\n$$\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[{\\rm True},{\\rm False},{\\rm True}]$). No additional text should be printed.",
            "solution": "The problem as stated is valid. It is a well-posed, scientifically grounded exercise in computational engineering, specifically in the area of finite element methods and a posteriori error analysis. All definitions and parameters are standard and self-consistent. We therefore proceed with the solution.\n\nThe task is to construct a surrogate exact solution $u_{\\text{fake}}$ such that the error $e = u_{\\text{fake}} - u_h$ has a specified norm, $\\lVert e \\rVert = \\eta$, where $u_h$ is a given discrete solution. This will be performed for two types of norms: the discrete $L^2$ norm, induced by the mass matrix $M$, and the discrete energy norm, induced by the stiffness matrix $K$.\n\nThe guiding principle is the definition of a norm on $\\mathbb{R}^m$ induced by a symmetric positive definite (SPD) matrix $N \\in \\mathbb{R}^{m \\times m}$:\n$$\n\\lVert v \\rVert_N \\equiv \\sqrt{v^{\\mathsf{T}} N v}.\n$$\nOur goal is to construct an error vector $e$ such that $\\lVert e \\rVert_N = \\eta$. Once such an error vector is determined, the surrogate solution is found by the simple vector addition $u_{\\text{fake}} = u_h + e$.\n\nThe methodology mandated is to select a non-zero direction vector $d$ and scale it to obtain the desired error vector $e$. Let us set $e = \\alpha d$ for some scalar $\\alpha \\in \\mathbb{R}$. We must find $\\alpha$ such that the norm condition is satisfied. By substituting $e = \\alpha d$ into the norm definition, we have:\n$$\n\\lVert e \\rVert_N = \\lVert \\alpha d \\rVert_N = \\sqrt{(\\alpha d)^{\\mathsf{T}} N (\\alpha d)} = \\sqrt{\\alpha^2 d^{\\mathsf{T}} N d} = |\\alpha| \\sqrt{d^{\\mathsf{T}} N d} = |\\alpha| \\lVert d \\rVert_N.\n$$\nWe require this to be equal to the target error magnitude $\\eta$, which leads to the equation:\n$$\n|\\alpha| \\lVert d \\rVert_N = \\eta.\n$$\nFor the case where $\\eta  0$, we must choose a direction vector $d$ such that its norm $\\lVert d \\rVert_N$ is non-zero. As both the mass matrix $M$ and the reduced stiffness matrix $K_{\\text{int}}$ are SPD, the condition $\\lVert d \\rVert_N  0$ holds for any non-zero vector $d$. We can therefore solve for $|\\alpha|$ without ambiguity:\n$$\n|\\alpha| = \\frac{\\eta}{\\lVert d \\rVert_N}.\n$$\nWe may choose the positive scalar, $\\alpha = \\frac{\\eta}{\\lVert d \\rVert_N}$. The error vector is then $e = \\frac{\\eta}{\\lVert d \\rVert_N} d$.\n\nIn the trivial case where $\\eta = 0$, the properties of a norm dictate that $e$ must be the zero vector. Consequently, $u_{\\text{fake}} = u_h$.\n\nThis outlines a complete and principled procedure. We will now specify the details for each norm type.\n\n**Construction for the Discrete $L^2$ Norm**\nThe norm operates on vectors in $\\mathbb{R}^n$ and is defined by $\\lVert v \\rVert_M = \\sqrt{v^{\\mathsf{T}} M v}$, where $M \\in \\mathbb{R}^{n \\times n}$ is the global mass matrix.\n1.  **Matrix Assembly**: The global mass matrix $M$ is assembled from the element mass matrices $M^{(e)} = \\frac{h}{6} \\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix}$ over the $n-1$ elements of the uniform mesh, where $h = 1/(n-1)$. This results in an $n \\times n$ tridiagonal SPD matrix.\n2.  **Direction Vector**: Any non-zero vector $d \\in \\mathbb{R}^n$ is permissible. For definiteness, we select a vector with a single non-zero entry at the central node: $d_k = 1$ for $k = \\lfloor n/2 \\rfloor$, and $d_i=0$ for $i \\neq k$.\n3.  **Construction**: If $\\eta=0$, $u_{\\text{fake}} = u_h$. If $\\eta  0$, we compute the scaling factor $\\alpha = \\eta / \\sqrt{d^{\\mathsf{T}} M d}$ and set $u_{\\text{fake}} = u_h + \\alpha d$.\n\n**Construction for the Discrete Energy Norm**\nThis norm is defined for functions satisfying homogeneous Dirichlet boundary conditions, which translates to vectors $e$ where $e_0 = 0$ and $e_{n-1} = 0$. The norm is computed using only the $n-2$ interior degrees of freedom: $\\lVert e \\rVert_K = \\sqrt{e_{\\text{int}}^{\\mathsf{T}} K_{\\text{int}} e_{\\text{int}}}$, where $K_{\\text{int}} \\in \\mathbb{R}^{(n-2) \\times (n-2)}$ is the reduced stiffness matrix.\n1.  **Matrix Assembly**: A global stiffness matrix $K \\in \\mathbb{R}^{n \\times n}$ is first assembled from element matrices $K^{(e)} = \\frac{1}{h} \\begin{bmatrix} 1  -1 \\\\ -1  1 \\end{bmatrix}$. The reduced matrix $K_{\\text{int}}$ is the sub-matrix of $K$ corresponding to the interior nodes (indices $1$ to $n-2$). This process yields a $(n-2) \\times (n-2)$ tridiagonal SPD matrix.\n2.  **Direction Vector**: The direction vector $d \\in \\mathbb{R}^n$ must respect the boundary conditions. We choose a simple vector with a single non-zero component at the first interior node: $d_1=1$, and all other components zero. The corresponding interior vector $d_{\\text{int}} \\in \\mathbb{R}^{n-2}$ is thus the first canonical basis vector.\n3.  **Construction**: If $\\eta=0$, $u_{\\text{fake}} = u_h$. If $\\eta  0$, we compute the scaling factor using the interior vectors: $\\alpha = \\eta / \\sqrt{d_{\\text{int}}^{\\mathsf{T}} K_{\\text{int}} d_{\\text{int}}}$. The full error vector is $e = \\alpha d$, and the surrogate solution is $u_{\\text{fake}} = u_h + e$. The problem specifies that the given $u_h$ for energy norm cases already satisfy the boundary conditions, so $u_{\\text{fake}}$ will do so as well.\n\nThe following program implements this logic to solve the provided test cases and verify that the constructed error matches the target magnitude $\\eta$ within the specified tolerance.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef assemble_mass_matrix(n, h):\n    \"\"\"Assembles the global mass matrix M for n nodes.\"\"\"\n    M = np.zeros((n, n), dtype=float)\n    M_elem = (h / 6.0) * np.array([[2, 1], [1, 2]])\n    for i in range(n - 1):\n        M[i:i+2, i:i+2] += M_elem\n    return M\n\ndef assemble_stiffness_matrix_interior(n, h):\n    \"\"\"Assembles the reduced stiffness matrix K_int for n-2 interior nodes.\"\"\"\n    K = np.zeros((n, n), dtype=float)\n    K_elem = (1.0 / h) * np.array([[1, -1], [-1, 1]])\n    for i in range(n - 1):\n        K[i:i+2, i:i+2] += K_elem\n    K_int = K[1:-1, 1:-1]\n    return K_int\n\ndef construct_and_validate(params):\n    \"\"\"\n    Constructs the surrogate solution u_fake and validates the error norm.\n    \"\"\"\n    norm_type, n, u_h_func, eta = params\n\n    # 1. Define mesh and compute u_h\n    h = 1.0 / (n - 1)\n    x = np.linspace(0.0, 1.0, n)\n    u_h = u_h_func(x)\n\n    # 2. Handle trivial case eta = 0\n    if eta == 0.0:\n        u_fake = u_h.copy()\n        e_norm_computed = 0.0\n    else:\n        # 3. Construct error vector e for eta > 0\n        if norm_type == 'L2':\n            M = assemble_mass_matrix(n, h)\n            \n            # Choose a non-zero direction vector d\n            d = np.zeros(n)\n            d[n // 2] = 1.0\n            \n            # Compute norm of d\n            norm_d_sq = d.T @ M @ d\n            norm_d = np.sqrt(norm_d_sq)\n            \n            # Scale d to create the error vector e\n            alpha = eta / norm_d\n            e = alpha * d\n            \n            # Construct u_fake\n            u_fake = u_h + e\n            \n            # Verification\n            e_check = u_fake - u_h\n            e_norm_computed = np.sqrt(e_check.T @ M @ e_check)\n            \n        elif norm_type == 'energy':\n            K_int = assemble_stiffness_matrix_interior(n, h)\n            \n            # Choose a non-zero direction vector d respecting BCs\n            d = np.zeros(n)\n            d[1] = 1.0  # Non-zero at first interior node\n            d_int = d[1:-1]\n            \n            # Compute norm of d\n            norm_d_sq = d_int.T @ K_int @ d_int\n            norm_d = np.sqrt(norm_d_sq)\n            \n            # Scale d to create the error vector e\n            alpha = eta / norm_d\n            e = alpha * d\n            \n            # Construct u_fake\n            u_fake = u_h + e\n            \n            # Verification\n            e_check = u_fake - u_h\n            e_check_int = e_check[1:-1]\n            e_norm_computed = np.sqrt(e_check_int.T @ K_int @ e_check_int)\n        else:\n            raise ValueError(\"Unknown norm type\")\n\n    # 4. Validate the result against tolerance\n    tolerance = 1e-12 + 1e-10 * max(1.0, eta)\n    return np.abs(e_norm_computed - eta) = tolerance\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: L2 norm, happy path\n        ('L2', 6, lambda x: np.sin(np.pi * x), 0.4),\n        # Case 2: Energy norm, happy path\n        ('energy', 8, lambda x: x * (1 - x), 0.2),\n        # Case 3: L2 norm, zero error\n        ('L2', 5, lambda x: np.zeros_like(x), 0.0),\n        # Case 4: Energy norm, small error\n        ('energy', 10, lambda x: np.sin(2 * np.pi * x), 1e-12),\n        # Case 5: L2 norm, small mesh\n        ('L2', 3, lambda x: x, 1.2345),\n    ]\n\n    results = []\n    for case in test_cases:\n        is_valid = construct_and_validate(case)\n        results.append(str(is_valid))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```"
        }
    ]
}