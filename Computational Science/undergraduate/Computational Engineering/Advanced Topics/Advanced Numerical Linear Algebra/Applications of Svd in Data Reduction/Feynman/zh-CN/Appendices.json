{
    "hands_on_practices": [
        {
            "introduction": "奇异值分解（SVD）在数据降维中的一个最直接的应用是数据压缩。通过保留与最大奇异值相关的分量，SVD能够以最优的方式捕获数据集中的主要结构和能量。这项实践将指导您在一个计算流体动力学（CFD）的速度场数据上，将基于SVD的截断方法与简单的空间粗化（降采样）方法进行定量比较，从而直观地理解为何SVD在保留数据关键特征方面通常优于朴素的降维方法。",
            "id": "2371486",
            "problem": "考虑一个来自计算流体力学 (CFD) 的双分量速度场，其定义在一个具有 $m$ 行和 $n$ 列的矩形网格上。设空间域为 $[0,1] \\times [0,1]$，网格点坐标为 $x_j = \\frac{j}{n-1}$ (其中 $j \\in \\{0,1,\\dots,n-1\\}$) 和 $y_i = \\frac{i}{m-1}$ (其中 $i \\in \\{0,1,\\dots,m-1\\}$)，并约定当 $n=1$ 时 $x_0 = 0$，当 $m=1$ 时 $y_0 = 0$。每个网格点的速度的水平和垂直分量由以下公式定义：\n$$\nu(i,j) = \\sin\\!\\big(2\\pi x_j\\big)\\cos\\!\\big(2\\pi y_i\\big) + 0.3 \\cos\\!\\big(4\\pi x_j + 0.1\\big)\\sin\\!\\big(2\\pi y_i\\big) + 0.1\\, y_i,\n$$\n$$\nv(i,j) = -\\cos\\!\\big(2\\pi x_j\\big)\\sin\\!\\big(2\\pi y_i\\big) + 0.25 \\sin\\!\\big(2\\pi x_j\\big)\\sin\\!\\big(4\\pi y_i + 0.3\\big) + 0.1\\, x_j,\n$$\n适用于所有有效索引 $(i,j)$。三角函数中的角度以弧度为单位。\n\n通过垂直堆叠各分量，将该场聚合为一个实矩阵 $M \\in \\mathbb{R}^{(2m)\\times n}$：\n$$\nM = \\begin{bmatrix} U \\\\ V \\end{bmatrix}, \\quad U_{i,j} = u(i,j), \\quad V_{i,j} = v(i,j).\n$$\n\n我们将比较两种数据降维策略及其重构：\n\n1. 秩为 $r$ 的奇异值分解 (SVD) 截断：设 $M$ 的奇异值分解 (SVD) 为 $M = Q \\Sigma W^\\top$，其中 $Q \\in \\mathbb{R}^{(2m)\\times(2m)}$，$\\Sigma \\in \\mathbb{R}^{(2m)\\times n}$，且 $W \\in \\mathbb{R}^{n\\times n}$。秩为 $r$ 的截断重构 $M_r$ 为\n$$\nM_r = Q_{[:,1:r]} \\,\\Sigma_{[1:r,1:r]} \\, W_{[:,1:r]}^\\top,\n$$\n其中 $r \\in \\mathbb{N}$ 满足 $1 \\le r \\le \\min(2m,n)$，且符号 $A_{[:,1:r]}$ 表示选取前 $r$ 列，$A_{[1:r,1:r]}$ 表示选取前导的 $r\\times r$ 主子矩阵。\n\n2. 空间粗化与块平均重构：给定正整数 $s_y$ 和 $s_x$，将 $U$ 和 $V$ 的 $m\\times n$ 网格划分为大小为 $s_y \\times s_x$ 的非重叠块，但在边界处的块可能较小。对于每个块，用该块内原始所有项的算术平均值替换该块中的所有项。对 $U$ 和 $V$ 独立执行此操作以获得 $\\widehat{U}$ 和 $\\widehat{V}$，并定义粗化重构 $\\widehat{M} = \\begin{bmatrix} \\widehat{U} \\\\ \\widehat{V} \\end{bmatrix}$。\n\n对于每种重构 $\\widetilde{M} \\in \\{M_r, \\widehat{M}\\}$，使用弗罗贝尼乌斯范数定义其相对重构误差为\n$$\n\\varepsilon(\\widetilde{M}) = \\frac{\\lVert M - \\widetilde{M} \\rVert_F}{\\lVert M \\rVert_F}.\n$$\n\n您的任务是实现一个程序，该程序针对下面指定的每个测试用例，根据给定的 $(m,n)$ 构建 $M$，计算秩为 $r$ 的 SVD 截断重构 $M_r$，使用块大小 $(s_y,s_x)$ 计算空间粗化重构 $\\widehat{M}$，评估误差 $\\varepsilon(M_r)$ 和 $\\varepsilon(\\widehat{M})$，并为每个测试用例返回单个浮点数值\n$$\n\\Delta = \\varepsilon(\\widehat{M}) - \\varepsilon(M_r).\n$$\n$\\Delta$ 的正值表示在该测试用例中，秩为 $r$ 的 SVD 重构的相对误差小于粗化重构的相对误差。\n\n测试套件（角度以弧度为单位）：\n- 用例 1： $(m,n,r,s_y,s_x) = (48,64,8,4,4)$。\n- 用例 2： $(m,n,r,s_y,s_x) = (32,30,1,64,64)$。\n- 用例 3： $(m,n,r,s_y,s_x) = (64,24,6,8,6)$。\n- 用例 4： $(m,n,r,s_y,s_x) = (24,96,5,6,8)$。\n- 用例 5： $(m,n,r,s_y,s_x) = (40,50,3,1,1)$。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个由方括号括起来的浮点数逗号分隔列表，按上述用例的顺序排列，即\n$$\n[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4,\\Delta_5].\n$$\n任何行都不应打印额外文本。本问题不涉及物理单位，所有角度均以弧度为单位。每个 $\\Delta_k$ 必须作为浮点数输出。必须完全按照上述定义计算答案，不得引入任何替代的归一化或加权方法。",
            "solution": "我们从第一性原理出发，对两种重构方法和误差度量进行形式化描述。一个实矩阵 $M \\in \\mathbb{R}^{(2m)\\times n}$ 的奇异值分解 (SVD) 是一个形如 $M = Q \\Sigma W^\\top$ 的因式分解，其中 $Q \\in \\mathbb{R}^{(2m)\\times(2m)}$ 和 $W \\in \\mathbb{R}^{n\\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{(2m)\\times n}$ 是对角矩阵，其主对角线上有非负奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge 0$（在其方形核心之外可能用零填充）。对于满足 $1 \\le r \\le \\min(2m,n)$ 的任何秩参数 $r$，秩为 $r$ 的截断重构为\n$$\nM_r = \\sum_{k=1}^{r} \\sigma_k \\, q_k \\, w_k^\\top = Q_{[:,1:r]}\\,\\Sigma_{[1:r,1:r]}\\,W_{[:,1:r]}^\\top,\n$$\n其中 $q_k$ 和 $w_k$ 分别是 $Q$ 和 $W$ 的第 $k$ 列。根据 Eckart–Young–Mirsky 定理，对于弗罗贝尼乌斯范数而言，$M_r$ 是在所有秩至多为 $r$ 的矩阵中对 $M$ 的最佳逼近。因此，其相对弗罗贝尼乌斯误差为\n$$\n\\varepsilon(M_r) = \\frac{\\left\\|M - M_r\\right\\|_F}{\\left\\|M\\right\\|_F} = \\frac{\\sqrt{\\sum_{k=r+1}^{\\rho} \\sigma_k^2}}{\\sqrt{\\sum_{k=1}^{\\rho} \\sigma_k^2}},\n$$\n其中 $\\rho = \\operatorname{rank}(M)$。\n\n空间粗化重构是通过一个块平均算子定义的。对于给定的块大小 $(s_y,s_x)$（其中 $s_y \\in \\mathbb{N}$ 且 $s_x \\in \\mathbb{N}$），我们将索引集 $\\{0,1,\\dots,m-1\\} \\times \\{0,1,\\dots,n-1\\}$ 划分为笛卡尔块\n$$\nB_{\\alpha,\\beta} = \\{(i,j) \\,\\mid\\, \\alpha s_y \\le i \\le \\min((\\alpha+1)s_y-1,m-1),\\ \\beta s_x \\le j \\le \\min((\\beta+1)s_x-1,n-1) \\},\n$$\n其中 $\\alpha \\in \\{0,1,\\dots,\\lceil m/s_y \\rceil - 1\\}$ 且 $\\beta \\in \\{0,1,\\dots,\\lceil n/s_x \\rceil - 1\\}$。对于任意矩阵 $A \\in \\mathbb{R}^{m\\times n}$，定义分段常数投影 $\\mathcal{P}_{s_y,s_x}(A)$，即对每个块 $B_{\\alpha,\\beta}$ 赋值\n$$\n\\left(\\mathcal{P}_{s_y,s_x}(A)\\right)_{i,j} = \\frac{1}{|B_{\\alpha,\\beta}|}\\sum_{(p,q)\\in B_{\\alpha,\\beta}} A_{p,q} \\quad \\text{for all } (i,j)\\in B_{\\alpha,\\beta}.\n$$\n该算子是（关于弗罗贝尼乌斯内积的）一个正交投影算子，它投影到在每个块 $B_{\\alpha,\\beta}$ 上为常数的矩阵子空间上。将此算子应用于每个分量可得 $\\widehat{U}=\\mathcal{P}_{s_y,s_x}(U)$ 和 $\\widehat{V}=\\mathcal{P}_{s_y,s_x}(V)$，从而得到重构的堆叠矩阵 $\\widehat{M} = \\begin{bmatrix}\\widehat{U} \\\\ \\widehat{V}\\end{bmatrix}$。相关的相对误差为\n$$\n\\varepsilon(\\widehat{M}) = \\frac{\\left\\|M - \\widehat{M}\\right\\|_F}{\\left\\|M\\right\\|_F}.\n$$\n\n速度场由以下公式确定性地规定：\n$$\nu(i,j) = \\sin(2\\pi x_j)\\cos(2\\pi y_i) + 0.3 \\cos(4\\pi x_j + 0.1)\\sin(2\\pi y_i) + 0.1\\, y_i,\n$$\n$$\nv(i,j) = -\\cos(2\\pi x_j)\\sin(2\\pi y_i) + 0.25 \\sin(2\\pi x_j)\\sin(4\\pi y_i + 0.3) + 0.1\\, x_j,\n$$\n其中 $x_j = \\frac{j}{n-1}$ (若 $n>1$) 且 $x_0=0$ (若 $n=1$)，以及 $y_i = \\frac{i}{m-1}$ (若 $m>1$) 且 $y_0=0$ (若 $m=1$)。将 $U$ 和 $V$ 构建为 $m\\times n$ 数组并堆叠，得到 $M \\in \\mathbb{R}^{(2m)\\times n}$。\n\n对于每个测试元组 $(m,n,r,s_y,s_x)$，计算步骤直接遵循这些定义：\n- 根据指定的 $m$ 和 $n$，通过在网格点上计算 $u(i,j)$ 和 $v(i,j)$ 并堆叠来形成 $M$。\n- 计算秩为 $r$ 的SVD截断 $M_r$ 及其相对弗罗贝尼乌斯误差 $\\varepsilon(M_r)$。\n- 使用给定的 $(s_y,s_x)$ 计算块平均重构 $\\widehat{U}$ 和 $\\widehat{V}$，堆叠成 $\\widehat{M}$，并计算 $\\varepsilon(\\widehat{M})$。\n- 报告标量差值 $\\Delta = \\varepsilon(\\widehat{M}) - \\varepsilon(M_r)$。\n\n测试套件涵盖了一个具有中等块大小和秩的典型用例，一个块大小超过域（导致单块平均）的边界用例，一个 $2m \\gg n$ 的高矩阵用例，一个 $n \\gg 2m$ 的宽矩阵用例，以及一个粗化误差恰好为零的 $(s_y,s_x)=(1,1)$ 单位粗化用例。最终输出是与上述用例按顺序对应的单个列表 $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4,\\Delta_5]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_velocity_field(m: int, n: int):\n    # Coordinates in [0,1], handle degenerate sizes\n    if n > 1:\n        x = np.linspace(0.0, 1.0, n)\n    else:\n        x = np.array([0.0])\n    if m > 1:\n        y = np.linspace(0.0, 1.0, m)\n    else:\n        y = np.array([0.0])\n\n    X, Y = np.meshgrid(x, y, indexing='xy')\n\n    # Define u and v components as specified\n    u = np.sin(2.0 * np.pi * X) * np.cos(2.0 * np.pi * Y) \\\n        + 0.3 * np.cos(4.0 * np.pi * X + 0.1) * np.sin(2.0 * np.pi * Y) \\\n        + 0.1 * Y\n\n    v = -np.cos(2.0 * np.pi * X) * np.sin(2.0 * np.pi * Y) \\\n        + 0.25 * np.sin(2.0 * np.pi * X) * np.sin(4.0 * np.pi * Y + 0.3) \\\n        + 0.1 * X\n\n    return u, v\n\ndef stack_components(u: np.ndarray, v: np.ndarray) -> np.ndarray:\n    # Stack u and v vertically: shape (2m, n)\n    return np.vstack([u, v])\n\ndef truncated_svd_reconstruction(M: np.ndarray, r: int) -> np.ndarray:\n    # Compute rank-r truncated SVD reconstruction\n    U, s, Vh = np.linalg.svd(M, full_matrices=False)\n    r = int(r)\n    Ur = U[:, :r]\n    sr = s[:r]\n    Vhr = Vh[:r, :]\n    # Equivalent to Ur @ np.diag(sr) @ Vhr but more efficient:\n    return (Ur * sr) @ Vhr\n\ndef block_mean_reconstruction(A: np.ndarray, sy: int, sx: int) -> np.ndarray:\n    m, n = A.shape\n    R = np.empty_like(A)\n    # Iterate over blocks\n    for r0 in range(0, m, sy):\n        r1 = min(r0 + sy, m)\n        for c0 in range(0, n, sx):\n            c1 = min(c0 + sx, n)\n            block = A[r0:r1, c0:c1]\n            mean_val = block.mean() if block.size > 0 else 0.0\n            R[r0:r1, c0:c1] = mean_val\n    return R\n\ndef relative_frobenius_error(A: np.ndarray, B: np.ndarray) -> float:\n    diff = A - B\n    num = np.linalg.norm(diff, ord='fro')\n    den = np.linalg.norm(A, ord='fro')\n    # In our construction, den should be > 0, but guard just in case\n    if den == 0.0:\n        return 0.0 if num == 0.0 else float('inf')\n    return float(num / den)\n\ndef solve():\n    # Define the test cases from the problem statement as (m, n, r, s_y, s_x)\n    test_cases = [\n        (48, 64, 8, 4, 4),\n        (32, 30, 1, 64, 64),\n        (64, 24, 6, 8, 6),\n        (24, 96, 5, 6, 8),\n        (40, 50, 3, 1, 1),\n    ]\n\n    results = []\n    for m, n, r, sy, sx in test_cases:\n        # Generate field and stack\n        u, v = generate_velocity_field(m, n)\n        M = stack_components(u, v)\n\n        # Truncated SVD reconstruction and error\n        Mr = truncated_svd_reconstruction(M, r)\n        err_svd = relative_frobenius_error(M, Mr)\n\n        # Block coarsening reconstruction and error (apply per component)\n        u_hat = block_mean_reconstruction(u, sy, sx)\n        v_hat = block_mean_reconstruction(v, sy, sx)\n        M_hat = stack_components(u_hat, v_hat)\n        err_coarse = relative_frobenius_error(M, M_hat)\n\n        # Delta = coarsening error - SVD error\n        delta = err_coarse - err_svd\n        results.append(delta)\n\n    # Final print statement in the exact required format.\n    # Format with a reasonable precision for readability.\n    print(\"[\" + \",\".join(f\"{val:.10f}\" for val in results) + \"]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "在计算工程领域，许多逆问题（如图像去模糊或参数识别）本质上是“不适定的”，这意味着测量数据中微小的噪声都可能导致解出现剧烈振荡甚至完全错误。截断奇异值分解（TSVD）是一种强大的正则化技术，通过舍弃与小奇异值相关的部分来稳定解。本练习将引导您探索正则化中的一个核心权衡：您的解在多大程度上拟合了含噪数据（残差范数），以及您的解与真实解的接近程度（解误差范数），揭示了在不适定问题中，更小的残差并不总意味着更好的解。",
            "id": "2371492",
            "problem": "考虑一个计算工程中的线性反问题，其模型为 $A x = b$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个病态矩阵，$x \\in \\mathbb{R}^{n}$ 是一个未知的参数向量，$b \\in \\mathbb{R}^{m}$ 是给定的数据。病态性会导致 $b$ 中的小扰动在解中引起大的变化，使得该问题在有限精度计算中实际上是不适定的。您将研究一种使用奇异值分解（SVD）的数据降维方法，以构建一个截断SVD解，并比较解的残差和解的误差。\n\n基本原理：\n- 使用奇异值分解（SVD）的定义：任何实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 都允许分解为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个对角矩阵，其非负对角元按非增序排列。\n- 使用最小二乘原理：对于超定系统，解使残差的欧几里得范数 $\\|A \\tilde{x} - b\\|_{2}$ 最小化。\n- 使用欧几里得范数的性质及其正交不变性。\n\n您的任务：\n- 对于每个测试用例，构建一个矩阵 $A$、一个真实解向量 $x$ 和一个数据向量 $b = A x + e$，其中 $e$ 是一个确定性扰动向量，扮演测量噪声的角色。\n- 通过仅保留 $A$ 的 $k$ 个最大奇异分量来计算截断SVD（TSVD）解 $\\tilde{x}_{k}$。\n- 对于每个用例，计算：\n  1. 残差范数 $r = \\|A \\tilde{x}_{k} - b\\|_{2}$。\n  2. 解误差范数 $e_{x} = \\|\\tilde{x}_{k} - x\\|_{2}$。\n- 对所有范数均使用欧几里得范数，并将所有结果表示为精确到 $6$ 位小数的实数。\n\n所有测试用例的构造规则：\n- 逐项定义希尔伯特型矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其元素为 $A_{ij} = \\frac{1}{i + j - 1}$，其中 $1 \\le i \\le m$，$1 \\le j \\le n$。\n- 定义真实解向量 $x \\in \\mathbb{R}^{n}$，其元素为 $x_{i} = \\frac{(-1)^{i}}{i}$，其中 $1 \\le i \\le n$。\n- 定义确定性扰动向量 $e \\in \\mathbb{R}^{m}$，其元素为 $e_{i} = \\sigma \\cdot (-1)^{i}$，其中 $1 \\le i \\le m$，标量 $\\sigma \\ge 0$ 按测试用例给出。\n- 构造 $b = A x + e$。\n- 按如下方式构造截断SVD解：计算 $A$ 的SVD，并仅保留 $k$ 个最大奇异分量来构建 $\\tilde{x}_{k}$。若 $k = 0$，则定义 $\\tilde{x}_{0}$ 为 $\\mathbb{R}^{n}$ 中的零向量。\n- 计算 $r = \\|A \\tilde{x}_{k} - b\\|_{2}$ 和 $e_{x} = \\|\\tilde{x}_{k} - x\\|_{2}$。\n- 将 $r$ 和 $e_{x}$ 四舍五入到精确的 $6$ 位小数。\n\n测试套件：\n- 用例 1：$m = 8$, $n = 8$, $k = 0$, $\\sigma = 10^{-6}$。\n- 用例 2：$m = 8$, $n = 8$, $k = 2$, $\\sigma = 10^{-3}$。\n- 用例 3：$m = 8$, $n = 8$, $k = 4$, $\\sigma = 10^{-3}$。\n- 用例 4：$m = 8$, $n = 8$, $k = 4$, $\\sigma = 0$。\n- 用例 5：$m = 8$, $n = 8$, $k = 8$, $\\sigma = 10^{-3}$。\n- 用例 6：$m = 10$, $n = 6$, $k = 3$, $\\sigma = 10^{-4}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个方括号内的逗号分隔的数对列表。每个数对对应一个测试用例，顺序与列表相同，格式为 $[r,e_{x}]$，两个数字都四舍五入到 $6$ 位小数。该行中任何地方都不允许有空格。\n- 例如，总输出应类似于 $[[r_{1},e_{x,1}],[r_{2},e_{x,2}],\\dots,[r_{6},e_{x,6}]]$，其中每个 $r_{i}$ 和 $e_{x,i}$ 都是小数点后恰好有 $6$ 位数字的十进制数。",
            "solution": "所提出的问题是有效的。它在科学上基于数值线性代数和反问题这一成熟领域，特别是奇异值分解（SVD）在正则化中的应用。该问题定义良好，所有必要的参数和构造规则都已明确定义，确保每个测试用例都有唯一且可计算的解。其中没有逻辑矛盾、歧义或事实不正确的假设。\n\n所考虑的问题是求解一个线性方程组 $A x = b$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个病态矩阵，$x \\in \\mathbb{R}^{n}$ 是未知参数向量，$b \\in \\mathbb{R}^{m}$ 是受噪声污染的数据向量。数据向量被建模为 $b = A x_{\\text{true}} + e$，其中 $x_{\\text{true}}$ 是真实解，而 $e$ 是代表测量噪声的扰动向量。$A$ 的病态性意味着 $b$ 中的小扰动会导致通过直接求逆系统获得的解出现大的、不符合物理意义的振荡。\n\n解决这种不适定性的一种标准方法是正则化，而截断奇异值分解（TSVD）是一种强大的正则化技术。矩阵 $A$ 的SVD分解为：\n$$ A = U \\Sigma V^{\\top} $$\n其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵（$U^{\\top}U = I_m$，$V^{\\top}V = I_n$），$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个矩形对角矩阵，包含奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_r > 0$，其中 $r = \\text{rank}(A)$。设 $U$ 的列为 $\\{u_i\\}_{i=1}^m$，$V$ 的列为 $\\{v_i\\}_{i=1}^n$。\n\n最小化 $\\|Ax - b\\|_2$ 的标准最小二乘解可以通过 Moore-Penrose 伪逆 $A^{\\dagger} = V \\Sigma^{\\dagger} U^{\\top}$ 来表示：\n$$ \\hat{x} = A^{\\dagger}b = \\sum_{i=1}^{r} \\frac{u_i^{\\top}b}{\\sigma_i} v_i $$\n对于病态矩阵，许多奇异值 $\\sigma_i$ 非常小。如果分子 $u_i^{\\top}b$ 没有相应地小，那么除以小的 $\\sigma_i$ 会放大来自数据向量 $b$ 的噪声，从而破坏解。\n\nTSVD 方法通过截断求和来正则化解，仅包含与 $k$ 个最大奇异值相关的分量，其中 $k \\le r$ 是截断参数。TSVD 解，记为 $\\tilde{x}_k$，定义为：\n$$ \\tilde{x}_k = \\sum_{i=1}^{k} \\frac{u_i^{\\top}b}{\\sigma_i} v_i $$\n当截断参数 $k=0$ 时，求和为空，解定义为零向量，$\\tilde{x}_0 = \\mathbf{0} \\in \\mathbb{R}^n$。\n\n我们的任务是计算两个关键指标：残差范数 $r = \\|A\\tilde{x}_k - b\\|_2$ 和解误差范数 $e_x = \\|\\tilde{x}_k - x_{\\text{true}}\\|_2$。\n\n残差向量是 $A\\tilde{x}_k - b$。利用 $Av_i = \\sigma_i u_i$，我们有：\n$$ A\\tilde{x}_k = A \\left(\\sum_{i=1}^{k} \\frac{u_i^{\\top}b}{\\sigma_i} v_i\\right) = \\sum_{i=1}^{k} \\frac{u_i^{\\top}b}{\\sigma_i} (Av_i) = \\sum_{i=1}^{k} (u_i^{\\top}b) u_i $$\n数据向量 $b$ 可以在 $U$ 的标准正交基中展开为 $b = \\sum_{j=1}^{m} (u_j^{\\top}b) u_j$。因此，残差为：\n$$ A\\tilde{x}_k - b = \\sum_{i=1}^{k} (u_i^{\\top}b) u_i - \\sum_{j=1}^{m} (u_j^{\\top}b) u_j = - \\sum_{j=k+1}^{m} (u_j^{\\top}b) u_j $$\n根据正交向量的毕达哥拉斯定理，残差的范数平方为：\n$$ r^2 = \\|A\\tilde{x}_k - b\\|_2^2 = \\sum_{j=k+1}^{m} (u_j^{\\top}b)^2 $$\n\n解误差向量是 $\\tilde{x}_k - x_{\\text{true}}$。我们使用 $b = Ax_{\\text{true}} + e$ 展开 $\\tilde{x}_k$：\n$$ \\tilde{x}_k = \\sum_{i=1}^{k} \\frac{u_i^{\\top}(Ax_{\\text{true}} + e)}{\\sigma_i} v_i = \\sum_{i=1}^{k} \\frac{u_i^{\\top}Ax_{\\text{true}}}{\\sigma_i} v_i + \\sum_{i=1}^{k} \\frac{u_i^{\\top}e}{\\sigma_i} v_i $$\n利用关系式 $u_i^{\\top}A = (A^{\\top}u_i)^{\\top} = (V\\Sigma^{\\top}U^{\\top}u_i)^{\\top} = (\\sigma_i v_i)^{\\top} = \\sigma_i v_i^{\\top}$，第一项变为：\n$$ \\sum_{i=1}^{k} \\frac{\\sigma_i v_i^{\\top}x_{\\text{true}}}{\\sigma_i} v_i = \\sum_{i=1}^{k} (v_i^{\\top}x_{\\text{true}}) v_i $$\n真实解 $x_{\\text{true}}$ 可以在 $V$ 的标准正交基中展开为 $x_{\\text{true}} = \\sum_{j=1}^{n} (v_j^{\\top}x_{\\text{true}}) v_j$。因此误差向量为：\n$$ \\tilde{x}_k - x_{\\text{true}} = \\left( \\sum_{i=1}^{k} (v_i^{\\top}x_{\\text{true}}) v_i - \\sum_{j=1}^{n} (v_j^{\\top}x_{\\text{true}}) v_j \\right) + \\sum_{i=1}^{k} \\frac{u_i^{\\top}e}{\\sigma_i} v_i $$\n$$ \\tilde{x}_k - x_{\\text{true}} = \\underbrace{- \\sum_{j=k+1}^{n} (v_j^{\\top}x_{\\text{true}}) v_j}_{\\text{truncation error (截断误差)}} + \\underbrace{\\sum_{i=1}^{k} \\frac{u_i^{\\top}e}{\\sigma_i} v_i}_{\\text{perturbation error (扰动误差)}} $$\n这两个误差分量是正交的，因为它们是标准正交基 $\\{v_i\\}$ 的不相交子集的线性组合。解误差的范数平方是这些分量范数平方的和：\n$$ e_x^2 = \\|\\tilde{x}_k - x_{\\text{true}}\\|_2^2 = \\sum_{j=k+1}^{n} (v_j^{\\top}x_{\\text{true}})^2 + \\sum_{i=1}^{k} \\left(\\frac{u_i^{\\top}e}{\\sigma_i}\\right)^2 $$\n截断参数 $k$ 的最优选择涉及一个权衡：增加 $k$ 会减少截断误差，但会增加扰动误差，特别是当噪声 $e$ 很大且奇异值 $\\sigma_i$ 很小时。\n\n对于每个测试用例，我们应用以下步骤：\n1.  构造希尔伯特矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其元素为 $A_{ij} = \\frac{1}{(i+1) + (j+1) - 1} = \\frac{1}{i+j+1}$（对于0-索引的i,j）。\n2.  构造真实解向量 $x \\in \\mathbb{R}^{n}$，其元素为 $x_i = \\frac{(-1)^{i+1}}{i+1}$（对于0-索引的i）。\n3.  构造扰动向量 $e \\in \\mathbb{R}^{m}$，其元素为 $e_i = \\sigma \\cdot (-1)^{i+1}$（对于0-索引的i）。\n4.  构造数据向量 $b = Ax + e$。\n5.  计算 $A$ 的SVD：$A = U \\Sigma V^{\\top}$。\n6.  若 $k=0$，则设 $\\tilde{x}_0 = \\mathbf{0}$。否则，计算 $\\tilde{x}_k = \\sum_{i=1}^{k} \\frac{u_i^{\\top}b}{\\sigma_i} v_i$。\n7.  计算残差范数 $r = \\|A\\tilde{x}_k - b\\|_2$ 和解误差范数 $e_x = \\|\\tilde{x}_k - x\\|_2$。\n8.  将两个结果四舍五入到 $6$ 位小数。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of linear inverse problems using Truncated SVD (TSVD).\n\n    For each test case, it constructs a Hilbert matrix A, a ground-truth\n    solution x, and a perturbed data vector b. It then computes the TSVD\n    solution x_tilde_k for a given truncation level k. Finally, it calculates\n    the residue norm ||A*x_tilde_k - b||_2 and the solution error norm\n    ||x_tilde_k - x||_2.\n    \"\"\"\n\n    test_cases = [\n        # (m, n, k, sigma)\n        (8, 8, 0, 1e-6),\n        (8, 8, 2, 1e-3),\n        (8, 8, 4, 1e-3),\n        (8, 8, 4, 0.0),\n        (8, 8, 8, 1e-3),\n        (10, 6, 3, 1e-4),\n    ]\n\n    results_list = []\n\n    for m, n, k, sigma in test_cases:\n        # Step 1: Construct the Hilbert matrix A\n        # Using 1-based indexing in formula, A_ij = 1/(i+j-1)\n        # In 0-based numpy, this is 1/((i+1)+(j+1)-1) = 1/(i+j+1)\n        i_indices, j_indices = np.meshgrid(np.arange(m), np.arange(n), indexing='ij')\n        A = 1.0 / (i_indices + j_indices + 1)\n\n        # Step 2: Construct the ground-truth vector x\n        # Using 1-based indexing in formula, x_i = (-1)^i/i for i=1..n\n        idx_n = np.arange(1, n + 1)\n        x_true = ((-1)**idx_n) / idx_n\n\n        # Step 3: Construct the perturbation vector e\n        # Using 1-based indexing in formula, e_i = sigma * (-1)^i for i=1..m\n        idx_m = np.arange(1, m + 1)\n        e = sigma * ((-1)**idx_m)\n\n        # Step 4: Form the data vector b\n        b = A @ x_true + e\n\n        # Step 5: Compute the SVD of A\n        # full_matrices=True to match the problem statement's definition\n        U, s, Vh = np.linalg.svd(A, full_matrices=True)\n        # Vh is V.T\n\n        # Step 6: Compute the TSVD solution x_tilde_k\n        if k == 0:\n            x_tilde_k = np.zeros(n)\n        else:\n            # Slices for the truncated components\n            s_k = s[:k]\n            U_k = U[:, :k]\n            Vh_k = Vh[:k, :]\n\n            # Compute x_tilde_k = V_k * (S_k^-1 * (U_k^T * b))\n            # This is numerically more stable than forming the pseudoinverse matrix.\n            c = U_k.T @ b\n            w = c / s_k\n            x_tilde_k = Vh_k.T @ w\n\n        # Step 7: Calculate residue and solution error norms\n        residue_norm = np.linalg.norm(A @ x_tilde_k - b)\n        solution_error_norm = np.linalg.norm(x_tilde_k - x_true)\n        \n        # Step 8: Format results to 6 decimal places\n        r_str = f\"{residue_norm:.6f}\"\n        e_x_str = f\"{solution_error_norm:.6f}\"\n        \n        results_list.append(f\"[{r_str},{e_x_str}]\")\n\n    # Final print statement in the exact required format\n    final_output = f\"[{','.join(results_list)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "处理缺失数据是现代数据科学中的一个普遍挑战，从传感器网络的数据丢失到推荐系统中的未评分项。当数据可以假定为低秩时（例如，传感器读数高度相关），我们可以利用这一结构来“修复”或“填充”缺失的条目，这个过程被称为矩阵补全。本实践将介绍一种基于SVD的迭代算法，通过在每一步将数据投影到低秩空间来恢复缺失值，这展示了如何将SVD作为一个核心构件，嵌入到更复杂的现代优化算法中以解决实际的数据恢复问题。",
            "id": "2371448",
            "problem": "您面临一个源于相关通道传感器阵列的数据降维任务。来自 $m$ 个传感器在 $n$ 个时间步长记录的数据表示为一个实数矩阵 $X_{\\text{true}} \\in \\mathbb{R}^{m \\times n}$。由于通信丢失和损坏，只有一部分条目被观测到。令 $\\Omega \\subset \\{1,\\dots,m\\} \\times \\{1,\\dots,n\\}$ 表示观测条目的索引集，并令 $P_{\\Omega}$ 为采样算子，其定义为：如果 $(i,j) \\in \\Omega$，则 $(P_{\\Omega}(Z))_{ij} = Z_{ij}$，否则 $(P_{\\Omega}(Z))_{ij} = 0$。目标是通过利用 $X_{\\text{true}}$ 具有低秩（反映了相关的传感器行为）这一假设，以及弗罗贝尼乌斯范数下的最佳秩-k近似是通过截断奇异值分解（SVD）得到的这一事实，来重构一个低秩矩阵 $X \\in \\mathbb{R}^{m \\times n}$ 以逼近 $X_{\\text{true}}$。\n\n需要使用的基本定义和事实：\n- 奇异值分解（SVD）指出，任何矩阵 $Z \\in \\mathbb{R}^{m \\times n}$ 都可以写成 $Z = U \\Sigma V^{\\top}$ 的形式，其中 $U \\in \\mathbb{R}^{m \\times m}$ 是正交矩阵，$V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是对角非负矩阵。\n- 弗罗贝尼乌斯范数 $\\|Z\\|_{F} = \\sqrt{\\sum_{i,j} Z_{ij}^{2}}$。\n- Eckart–Young 定理：对于给定的 $k \\in \\mathbb{N}$，矩阵 $Z$ 在弗罗贝尼乌斯范数下的最佳秩-k近似，是通过将 $Z$ 的SVD截断至其前k个最大的奇异值和对应的奇异向量得到的。\n\n考虑以下用于通过低秩近似进行补全的不动点迭代方案：\n- 初始化 $X^{(0)} = 0$。\n- 对于迭代 $t = 0,1,2,\\dots$：\n  1. 构造填充矩阵 $Y^{(t)} = P_{\\Omega}(Y) + P_{\\Omega^{c}}(X^{(t)})$，其中 $Y = P_{\\Omega}(X_{\\text{true}} + N)$ 是观测到的数据（可能带噪），$N$ 是一个噪声矩阵（可能为零），$P_{\\Omega^{c}}$ 是互补采样算子，它保留不在 $\\Omega$ 中的条目，并将 $\\Omega$ 中的条目置零。\n  2. 计算 $Y^{(t)}$ 的秩-k截断SVD近似 $X^{(t+1)}$，方法是保留前k个最大的奇异值和对应的奇异向量。\n- 当 $\\|X^{(t+1)} - X^{(t)}\\|_{F} / \\max(1, \\|X^{(t)}\\|_{F}) \\le \\varepsilon$ 或当 $t$ 达到预设的最大迭代次数时停止，并返回 $X^{(t+1)}$。\n\n实现此算法，并在以下测试集上进行评估。对于每个测试，计算相对弗罗贝尼乌斯误差 $\\|X_{\\text{est}} - X_{\\text{true}}\\|_{F} / \\|X_{\\text{true}}\\|_{F}$，结果为一个浮点数。\n\n测试集（所有数字都是实标量，每个矩阵都已明确给出）：\n\n- 案例A（正常路径，中等采样率，精确低秩）:\n  - 维度: $m = 6$, $n = 5$。\n  - 构造 $X_{\\text{true}} = A_{A} B_{A}^{\\top}$，其中 $A_{A} \\in \\mathbb{R}^{6 \\times 2}$ 且 $B_{A} \\in \\mathbb{R}^{5 \\times 2}$：\n    - $A_{A} = \\begin{bmatrix}\n      1 & 0 \\\\\n      0 & 1 \\\\\n      1 & 1 \\\\\n      2 & -1 \\\\\n      -1 & 2 \\\\\n      0.5 & 1.5\n      \\end{bmatrix}$，\n      $B_{A} = \\begin{bmatrix}\n      2 & 1 \\\\\n      1 & -1 \\\\\n      0 & 2 \\\\\n      -1 & 0.5 \\\\\n      1.5 & -0.5\n      \\end{bmatrix}$。\n  - 掩码 $M_{A} \\in \\{0,1\\}^{6 \\times 5}$，其中1表示观测条目：\n    - $M_{A} = \\begin{bmatrix}\n      1 & 1 & 0 & 1 & 0 \\\\\n      0 & 1 & 1 & 0 & 1 \\\\\n      1 & 0 & 1 & 1 & 0 \\\\\n      1 & 1 & 0 & 0 & 1 \\\\\n      0 & 1 & 1 & 1 & 0 \\\\\n      1 & 0 & 0 & 1 & 1\n      \\end{bmatrix}$。\n  - 噪声 $N_{A} = 0$（所有条目为零）。\n  - 目标秩 $k = 2$。\n  - 停止参数：最大迭代次数 $t_{\\max} = 1000$，容差 $\\varepsilon = 10^{-10}$。\n\n- 案例B（边界情况，完全观测，在真实秩下精确恢复）:\n  - 维度: $m = 4$, $n = 4$。\n  - 构造 $X_{\\text{true}} = A_{B} B_{B}^{\\top}$，其中 $A_{B} \\in \\mathbb{R}^{4 \\times 2}$ 且 $B_{B} \\in \\mathbb{R}^{4 \\times 2}$：\n    - $A_{B} = \\begin{bmatrix}\n      2 & 0 \\\\\n      0 & 1 \\\\\n      1 & -1 \\\\\n      3 & 2\n      \\end{bmatrix}$，\n      $B_{B} = \\begin{bmatrix}\n      1 & 2 \\\\\n      0.5 & -1 \\\\\n      2 & 0 \\\\\n      1 & 1\n      \\end{bmatrix}$。\n  - 掩码 $M_{B}$ 在 $\\mathbb{R}^{4 \\times 4}$ 中全是1。\n  - 噪声 $N_{B} = 0$。\n  - 目标秩 $k = 2$。\n  - 停止参数：最大迭代次数 $t_{\\max} = 1000$，容差 $\\varepsilon = 10^{-12}$。\n\n- 案例C（边缘情况，整行缺失）:\n  - 维度: $m = 5$, $n = 5$。\n  - 构造 $X_{\\text{true}} = A_{C} B_{C}^{\\top}$，其中 $A_{C} \\in \\mathbb{R}^{5 \\times 2}$ 且 $B_{C} \\in \\mathbb{R}^{5 \\times 2}$：\n    - $A_{C} = \\begin{bmatrix}\n      1 & 0 \\\\\n      0 & 1 \\\\\n      1 & 1 \\\\\n      2 & 1 \\\\\n      -1 & 2\n      \\end{bmatrix}$，\n      $B_{C} = \\begin{bmatrix}\n      1 & 1 \\\\\n      2 & -1 \\\\\n      -1 & 0.5 \\\\\n      0 & 2 \\\\\n      1 & -2\n      \\end{bmatrix}$。\n  - 掩码 $M_{C} \\in \\{0,1\\}^{5 \\times 5}$：\n    - $M_{C} = \\begin{bmatrix}\n      1 & 0 & 1 & 1 & 0 \\\\\n      1 & 1 & 0 & 0 & 1 \\\\\n      0 & 0 & 0 & 0 & 0 \\\\\n      1 & 1 & 1 & 0 & 1 \\\\\n      0 & 1 & 0 & 1 & 1\n      \\end{bmatrix}$。\n  - 噪声 $N_{C} = 0$。\n  - 目标秩 $k = 2$。\n  - 停止参数: 最大迭代次数 $t_{\\max} = 2000$，容差 $\\varepsilon = 10^{-12}$。\n\n- 案例D（带噪观测，中等采样率）:\n  - 维度: $m = 5$, $n = 4$。\n  - 构造 $X_{\\text{true}} = A_{D} B_{D}^{\\top}$，其中 $A_{D} \\in \\mathbb{R}^{5 \\times 2}$ 且 $B_{D} \\in \\mathbb{R}^{4 \\times 2}$：\n    - $A_{D} = \\begin{bmatrix}\n      1 & 0 \\\\\n      0 & 1 \\\\\n      1 & -1 \\\\\n      2 & 1 \\\\\n      -1 & 2\n      \\end{bmatrix}$，\n      $B_{D} = \\begin{bmatrix}\n      1 & 2 \\\\\n      2 & 1 \\\\\n      -1 & 1 \\\\\n      0.5 & -0.5\n      \\end{bmatrix}$。\n  - 掩码 $M_{D} \\in \\{0,1\\}^{5 \\times 4}$：\n    - $M_{D} = \\begin{bmatrix}\n      1 & 1 & 0 & 1 \\\\\n      1 & 0 & 1 & 1 \\\\\n      1 & 1 & 0 & 0 \\\\\n      0 & 1 & 1 & 1 \\\\\n      1 & 0 & 1 & 0\n      \\end{bmatrix}$。\n  - 加性噪声 $N_{D} \\in \\mathbb{R}^{5 \\times 4}$：\n    - $N_{D} = \\begin{bmatrix}\n      0.01 & -0.02 & 0 & 0 \\\\\n      -0.03 & 0 & 0.02 & -0.01 \\\\\n      0.02 & 0.01 & 0 & 0 \\\\\n      0 & -0.02 & 0.03 & -0.01 \\\\\n      0.01 & 0 & -0.02 & 0\n      \\end{bmatrix}$。\n  - 目标秩 $k = 2$。\n  - 停止参数：最大迭代次数 $t_{\\max} = 1500$，容差 $\\varepsilon = 10^{-10}$。\n\n实现要求：\n- 严格按照所述实现迭代方案，在每次迭代中对填充矩阵 $Y^{(t)}$ 使用秩-k截断SVD。使用弗罗贝尼乌斯范数来衡量收敛性。\n- 对于每种情况，计算相对弗罗贝尼乌斯误差 $\\|X_{\\text{est}} - X_{\\text{true}}\\|_{F} / \\|X_{\\text{true}}\\|_{F}$，结果为四舍五入到六位小数的浮点数。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 `[r_{A},r_{B},r_{C},r_{D}]`），其中 $r_{A}$、$r_{B}$、$r_{C}$ 和 $r_{D}$ 分别是案例A、B、C和D的四舍五入后的相对误差。不应打印任何其他文本。",
            "solution": "所提出的问题是计算工程领域中一个定义明确的任务，特别是在传感器阵列的数据分析和信号处理领域。它涉及在底层真实数据为低秩的假设下，根据不完整且可能带噪声的观测数据来重构数据矩阵。这是一个经典的矩阵补全问题。所提出的方法是一种基于奇异值分解（SVD）的迭代算法，这是一种用于低秩近似的标准且强大的技术。\n\n在继续之前，需要对问题陈述进行验证。\n\n**第1步：提取的已知条件**\n- **数据模型：** 一个底层的真实数据矩阵 $X_{\\text{true}} \\in \\mathbb{R}^{m \\times n}$，具有低秩。\n- **观测模型：** 一组观测条目由一个索引集 $\\Omega \\subset \\{1,\\dots,m\\} \\times \\{1,\\dots,n\\}$ 给出。观测值为 $Y = P_{\\Omega}(X_{\\text{true}} + N)$，其中 $N$ 是一个噪声矩阵，$P_{\\Omega}$ 是一个采样算子，它保留 $\\Omega$ 中的条目，并将其他条目置零。\n- **迭代算法：**\n  - 初始化：$X^{(0)} = 0$。\n  - 迭代 $t=0, 1, 2, \\dots$：\n    1. $Y^{(t)} = P_{\\Omega}(Y) + P_{\\Omega^{c}}(X^{(t)})$，其中 $P_{\\Omega^{c}}$ 是互补采样算子。\n    2. $X^{(t+1)}$ 是 $Y^{(t)}$ 在弗罗贝尼乌斯范数下的最佳秩-k近似，通过截断SVD获得。\n- **停止准则：** 当 $\\|X^{(t+1)} - X^{(t)}\\|_{F} / \\max(1, \\|X^{(t)}\\|_{F}) \\le \\varepsilon$ 或达到最大迭代次数 $t_{\\max}$ 时，迭代终止。\n- **评估指标：** 相对弗罗贝尼乌斯误差 $\\|X_{\\text{est}} - X_{\\text{true}}\\|_{F} / \\|X_{\\text{true}}\\|_{F}$，其中 $X_{\\text{est}}$ 是最终估计的矩阵。\n- **测试案例：** 提供了四个不同的案例（A、B、C、D），并明确定义了矩阵 $A, B$（用于构造 $X_{\\text{true}} = AB^{\\top}$）、观测掩码 $M$、噪声矩阵 $N$、维度 $m, n$、目标秩 $k$ 以及停止参数 $\\varepsilon, t_{\\max}$。\n\n**第2步：验证**\n根据所需标准对问题进行评估：\n- **有科学依据：** 该问题牢固地植根于线性代数和数值优化。使用SVD进行低秩近似由 Eckart–Young 定理证明其合理性。该迭代过程是解决矩阵补全问题的著名方法，与奇异值阈值算法相关。该设置具有科学严谨性。\n- **适定性：** 每个测试案例的所有必要参数、矩阵和条件都已明确定义。该算法是确定性的，目标函数（在数据约束下最小化秩）与给定的迭代求解器意味着唯一的计算结果。\n- **客观性：** 该问题以精确的数学语言陈述，没有歧义或主观陈述。\n\n**第3步：结论**\n该问题被判定为**有效**。这是一个数值线性代数领域的标准、形式良好的问题，具有明确的指令和可验证的测试案例。现在可以构建一个解决方案。\n\n**求解过程**\n\n目标是实现并评估指定的用于低秩矩阵补全的迭代算法。该算法通过重复强制执行两个属性来运作：与观测数据的一致性以及对低秩模型的遵守。\n\n核心迭代步骤定义为：\n$X^{(t+1)} = \\mathcal{S}_k(P_{\\Omega}(Y) + P_{\\Omega^{c}}(X^{(t)}))$\n其中 $\\mathcal{S}_k(Z)$ 表示计算矩阵 $Z$ 的最佳秩-k近似的操作。根据 Eckart-Young 定理，如果 $Z$ 的SVD为 $Z = U \\Sigma V^{\\top}$，则 $\\mathcal{S}_k(Z) = U_k \\Sigma_k V_k^{\\top}$，其中 $U_k$ 和 $V_k$ 分别是由 $U$ 和 $V$ 的前 $k$ 列组成的矩阵，$\\Sigma_k$ 是前 $k$ 个奇异值的对角矩阵。\n\n让我们使用所提供的掩码矩阵 $M \\in \\{0,1\\}^{m \\times n}$（其中如果 $(i,j) \\in \\Omega$ 则 $M_{ij}=1$，否则 $M_{ij}=0$）来重新表述更新规则。采样算子可以用逐元素（哈达玛）积 $\\circ$ 来表示。\n- $P_{\\Omega}(Z) = M \\circ Z$\n- $P_{\\Omega^{c}}(Z) = (J - M) \\circ Z$，其中 $J$ 是全一矩阵。\n\n观测数据矩阵为 $Y_{\\text{obs}} = P_{\\Omega}(X_{\\text{true}} + N) = M \\circ (X_{\\text{true}} + N)$。\n迭代更新过程如下：\n1.  **初始化：** 估计值初始化为零矩阵：$X^{(0)} = 0 \\in \\mathbb{R}^{m \\times n}$。\n2.  **迭代** $t = 0, 1, ..., t_{\\max}-1$：\n    a. **存储前一个估计值：** $X_{\\text{prev}} = X^{(t)}$。\n    b. **填充矩阵：** 通过将已知的观测条目与当前对未知条目的估计值相结合，形成一个临时矩阵 $Y^{(t)}$：\n       $$Y^{(t)} = Y_{\\text{obs}} + (J-M) \\circ X^{(t)}$$\n    c. **投影到低秩空间：** 新的估计值 $X^{(t+1)}$ 通过计算 $Y^{(t)}$ 的秩-k截断SVD获得：\n       $$X^{(t+1)} = \\mathcal{S}_k(Y^{(t)})$$\n    d. **检查收敛性：** 如果连续估计值之间的相对变化低于容差 $\\varepsilon$，则停止该过程：\n       $$\\frac{\\|X^{(t+1)} - X_{\\text{prev}}\\|_F}{\\max(1, \\|X_{\\text{prev}}\\|_F)} \\le \\varepsilon$$\n3.  **输出：** 返回最终计算出的矩阵 $X_{\\text{est}} = X^{(t+1)}$。\n\n每个测试案例的最终评估是估计矩阵 $X_{\\text{est}}$ 与真实值 $X_{\\text{true}}$ 之间的相对弗罗贝尼乌斯误差：\n$$ \\text{误差} = \\frac{\\|X_{\\text{est}} - X_{\\text{true}}\\|_F}{\\|X_{\\text{true}}\\|_F} $$\n\n- **案例A** 代表一个标准应用，其中有很大一部分条目缺失，但底层矩阵恰好是秩-2的。预计该算法将收敛到一个低误差的解。\n- **案例B** 是一个平凡的情况，其中所有条目都已观测到 ($M=J$)。算法应该在第一次迭代中就完美地恢复 $X_{\\text{true}}$。$Y^{(0)} = M \\circ X_{\\text{true}} + (J-M) \\circ X^{(0)} = X_{\\text{true}} + 0 = X_{\\text{true}}$。由于 $X_{\\text{true}}$ 是秩-2的，$\\mathcal{S}_2(X_{\\text{true}}) = X_{\\text{true}}$。因此，$X^{(1)} = X_{\\text{true}}$，误差应该接近机器精度。\n- **案例C** 是一个边缘情况，其中一整行都未被观测到。矩阵补全理论中一个已知的结论是，在这种情况下恢复是不可能的，因为没有信息来约束该行中的值。算法会收敛，但从真实值的角度来看，缺失行的误差将是任意的，导致整体重构误差很高。\n- **案例D** 在观测值上包含加性噪声。该算法将尝试找到一个最适合噪声数据的秩-2矩阵。重构将不会是精确的，因为算法会通过将数据投影到一个低秩子空间来进行去噪。最终误差预计不为零但会很小，反映了算法剔除部分噪声的能力。\n\n实现将针对每个提供的测试案例遵循此逻辑。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define, run, and evaluate the test cases for matrix completion.\n    \"\"\"\n\n    def run_completion_algorithm(X_true, mask, noise, k, t_max, epsilon):\n        \"\"\"\n        Implements the iterative SVD-based matrix completion algorithm.\n        \n        Args:\n            X_true (np.ndarray): The ground truth matrix.\n            mask (np.ndarray): The observation mask (1s for observed, 0s for missing).\n            noise (np.ndarray): The additive noise matrix.\n            k (int): The target rank.\n            t_max (int): The maximum number of iterations.\n            epsilon (float): The convergence tolerance.\n\n        Returns:\n            np.ndarray: The estimated matrix X_est.\n        \"\"\"\n        m, n = X_true.shape\n        X_est = np.zeros((m, n))\n        Y_obs = mask * (X_true + noise)\n        \n        for _ in range(t_max):\n            X_prev = X_est.copy()\n            \n            # 1. Form the filled matrix\n            Y_filled = Y_obs + (1 - mask) * X_est\n            \n            # 2. Compute the rank-k truncated SVD approximation\n            try:\n                U, s, Vt = np.linalg.svd(Y_filled, full_matrices=False)\n                # Reconstruct from top k singular values/vectors\n                X_est = U[:, :k] @ np.diag(s[:k]) @ Vt[:k, :]\n            except np.linalg.LinAlgError:\n                # In case of non-convergence of SVD, though unlikely for these test cases.\n                break\n\n            # 3. Check for convergence\n            norm_prev = np.linalg.norm(X_prev, 'fro')\n            diff_norm = np.linalg.norm(X_est - X_prev, 'fro')\n            \n            if diff_norm / max(1.0, norm_prev)  epsilon:\n                break\n                \n        return X_est\n\n    # Define Test Cases\n    \n    # Case A\n    A_A = np.array([\n        [1, 0], [0, 1], [1, 1],\n        [2, -1], [-1, 2], [0.5, 1.5]\n    ])\n    B_A = np.array([\n        [2, 1], [1, -1], [0, 2],\n        [-1, 0.5], [1.5, -0.5]\n    ])\n    X_true_A = A_A @ B_A.T\n    M_A = np.array([\n        [1, 1, 0, 1, 0], [0, 1, 1, 0, 1], [1, 0, 1, 1, 0],\n        [1, 1, 0, 0, 1], [0, 1, 1, 1, 0], [1, 0, 0, 1, 1]\n    ])\n    N_A = np.zeros_like(X_true_A)\n    params_A = {'X_true': X_true_A, 'mask': M_A, 'noise': N_A, 'k': 2, 't_max': 1000, 'epsilon': 1e-10}\n\n    # Case B\n    A_B = np.array([[2, 0], [0, 1], [1, -1], [3, 2]])\n    B_B = np.array([[1, 2], [0.5, -1], [2, 0], [1, 1]])\n    X_true_B = A_B @ B_B.T\n    M_B = np.ones((4, 4))\n    N_B = np.zeros_like(X_true_B)\n    params_B = {'X_true': X_true_B, 'mask': M_B, 'noise': N_B, 'k': 2, 't_max': 1000, 'epsilon': 1e-12}\n\n    # Case C\n    A_C = np.array([[1, 0], [0, 1], [1, 1], [2, 1], [-1, 2]])\n    B_C = np.array([[1, 1], [2, -1], [-1, 0.5], [0, 2], [1, -2]])\n    X_true_C = A_C @ B_C.T\n    M_C = np.array([\n        [1, 0, 1, 1, 0], [1, 1, 0, 0, 1], [0, 0, 0, 0, 0],\n        [1, 1, 1, 0, 1], [0, 1, 0, 1, 1]\n    ])\n    N_C = np.zeros_like(X_true_C)\n    params_C = {'X_true': X_true_C, 'mask': M_C, 'noise': N_C, 'k': 2, 't_max': 2000, 'epsilon': 1e-12}\n\n    # Case D\n    A_D = np.array([[1, 0], [0, 1], [1, -1], [2, 1], [-1, 2]])\n    B_D = np.array([[1, 2], [2, 1], [-1, 1], [0.5, -0.5]])\n    X_true_D = A_D @ B_D.T\n    M_D = np.array([\n        [1, 1, 0, 1], [1, 0, 1, 1], [1, 1, 0, 0],\n        [0, 1, 1, 1], [1, 0, 1, 0]\n    ])\n    N_D = np.array([\n        [0.01, -0.02, 0, 0], [-0.03, 0, 0.02, -0.01],\n        [0.02, 0.01, 0, 0], [0, -0.02, 0.03, -0.01],\n        [0.01, 0, -0.02, 0]\n    ])\n    params_D = {'X_true': X_true_D, 'mask': M_D, 'noise': N_D, 'k': 2, 't_max': 1500, 'epsilon': 1e-10}\n\n    test_cases = [params_A, params_B, params_C, params_D]\n    results = []\n\n    for case_params in test_cases:\n        X_est = run_completion_algorithm(**case_params)\n        X_true = case_params['X_true']\n        \n        # Calculate relative Frobenius error\n        error = np.linalg.norm(X_est - X_true, 'fro') / np.linalg.norm(X_true, 'fro')\n        \n        # Round to six decimal places\n        rounded_error = round(error, 6)\n        results.append(rounded_error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}