{
    "hands_on_practices": [
        {
            "introduction": "为了建立我们对幂迭代法的直观理解，我们从一个特殊的例子入手。这个练习  将探讨当幂迭代应用于一个简单的投影矩阵时会发生什么。你会发现，该方法仅需一步迭代即可收敛到主特征向量，清晰地揭示了迭代过程与矩阵特征系统之间的根本联系。",
            "id": "2427094",
            "problem": "设 $v \\in \\mathbb{R}^{n}$ 是一个非零向量，定义到由 $v$ 张成的一维子空间上的正交投影算子为 $P = \\dfrac{v v^{T}}{v^{T} v} \\in \\mathbb{R}^{n \\times n}$。考虑对 $P$ 应用带归一化的幂迭代法，给定一个初始向量 $x_{0} \\in \\mathbb{R}^{n}$ 满足 $v^{T} x_{0} \\neq 0$。一次迭代产生 $y_{1} = P x_{0}$ 和归一化迭代向量 $x_{1} = \\dfrac{y_{1}}{\\|y_{1}\\|_{2}}$。定义 $x_{1}$ 关于 $P$ 的瑞利商为 $r_{1} = \\dfrac{x_{1}^{T} P x_{1}}{x_{1}^{T} x_{1}}$。确定 $r_{1}$ 的精确值。最终答案必须是一个实数。无需四舍五入。",
            "solution": "该问题要求计算应用于正交投影矩阵 $P$ 的幂迭代法第一次迭代的瑞利商 $r_{1}$。\n\n首先，我们必须验证问题陈述。\n给定条件如下：\n- 一个非零向量 $v \\in \\mathbb{R}^{n}$。\n- 正交投影矩阵 $P = \\dfrac{v v^{T}}{v^{T} v} \\in \\mathbb{R}^{n \\times n}$。\n- 一个初始向量 $x_{0} \\in \\mathbb{R}^{n}$，其性质为 $v^{T} x_{0} \\neq 0$。\n- 第一个未归一化的迭代向量是 $y_{1} = P x_{0}$。\n- 第一个归一化的迭代向量是 $x_{1} = \\dfrac{y_{1}}{\\|y_{1}\\|_{2}}$。\n- 瑞利商为 $r_{1} = \\dfrac{x_{1}^{T} P x_{1}}{x_{1}^{T} x_{1}}$。\n\n该问题在科学上基于线性代数和数值分析的原理。正交投影算子、幂迭代和瑞利商的定义都是标准的。该问题是适定的；条件 $v^{T} x_{0} \\neq 0$ 确保了第一次迭代的向量 $y_{1}$ 不是零向量，因此其归一化 $x_{1}$ 是有定义的。该问题是客观的，并包含了唯一解所需的所有信息。因此，该问题被认为是有效的，我们将构建一个解。\n\n目标是计算 $r_{1}$。我们从分析第一次迭代向量 $x_{1}$ 的结构开始。\n未归一化的迭代向量 $y_{1}$ 由下式给出：\n$$y_{1} = P x_{0} = \\left(\\dfrac{v v^{T}}{v^{T} v}\\right) x_{0} = \\dfrac{v (v^{T} x_{0})}{v^{T} v}$$\n我们定义标量 $\\alpha = v^{T} x_{0}$。根据问题陈述，$\\alpha \\neq 0$。同时，我们记标量 $v^{T} v = \\|v\\|_{2}^{2}$。因为 $v$ 是一个非零向量，所以 $v^{T} v  0$。\n根据这些定义，$y_{1}$ 的表达式简化为：\n$$y_{1} = \\dfrac{\\alpha}{v^{T} v} v$$\n该表达式表明，$y_{1}$ 是向量 $v$ 的一个非零标量倍。\n\n接下来，我们将 $y_{1}$ 归一化以获得 $x_{1}$。归一化是关于欧几里得范数 $\\| \\cdot \\|_{2}$ 的。\n$y_{1}$ 的范数是：\n$$\\|y_{1}\\|_{2} = \\left\\| \\dfrac{\\alpha}{v^{T} v} v \\right\\|_{2} = \\left| \\dfrac{\\alpha}{v^{T} v} \\right| \\|v\\|_{2} = \\dfrac{|\\alpha|}{v^{T} v} \\sqrt{v^{T} v} = \\dfrac{|\\alpha|}{\\sqrt{v^{T} v}}$$\n现在，我们计算 $x_{1}$：\n$$x_{1} = \\dfrac{y_{1}}{\\|y_{1}\\|_{2}} = \\dfrac{\\frac{\\alpha}{v^{T} v} v}{\\frac{|\\alpha|}{\\sqrt{v^{T} v}}} = \\dfrac{\\alpha}{|\\alpha|} \\dfrac{\\sqrt{v^{T} v}}{v^{T} v} v = \\dfrac{\\alpha}{|\\alpha|} \\dfrac{1}{\\sqrt{v^{T} v}} v$$\n注意到 $\\sqrt{v^{T} v} = \\|v\\|_{2}$，我们可以将 $x_{1}$ 写为：\n$$x_{1} = \\text{sgn}(\\alpha) \\dfrac{v}{\\|v\\|_{2}}$$\n其中 $\\text{sgn}(\\alpha) = \\frac{\\alpha}{|\\alpha|}$ 是 $\\alpha$ 的符号。这表明 $x_{1}$ 是一个与 $v$ 同向或反向的单位向量。换句话说，$x_{1}$ 位于由 $v$ 张成的一维子空间中。\n\n现在我们必须计算瑞利商 $r_{1} = \\dfrac{x_{1}^{T} P x_{1}}{x_{1}^{T} x_{1}}$。\n根据归一化向量的定义，分母为 $x_{1}^{T} x_{1} = \\|x_{1}\\|_{2}^{2} = 1$。\n所以，瑞利商简化为 $r_{1} = x_{1}^{T} P x_{1}$。\n\n为了计算它，我们首先计算 $P$ 作用于 $x_{1}$ 的结果。\n$$P x_{1} = P \\left( \\text{sgn}(\\alpha) \\dfrac{v}{\\|v\\|_{2}} \\right) = \\text{sgn}(\\alpha) \\dfrac{1}{\\|v\\|_{2}} (P v)$$\n我们来计算 $P v$：\n$$P v = \\left(\\dfrac{v v^{T}}{v^{T} v}\\right) v = \\dfrac{v (v^{T} v)}{v^{T} v} = v$$\n这证实了 $v$ 是投影矩阵 $P$ 的一个特征向量，其对应的特征值为 $\\lambda = 1$。\n将这个结果代回到 $P x_{1}$ 的表达式中：\n$$P x_{1} = \\text{sgn}(\\alpha) \\dfrac{1}{\\|v\\|_{2}} (v) = x_{1}$$\n这表明 $x_{1}$ 也是 $P$ 的一个特征向量，对应于特征值 $\\lambda = 1$。这是预期的，因为幂迭代在单步内收敛到了与 $P$ 的主导特征值（即 1）相关的特征向量。$P$ 的特征值为 1（特征向量为 $v$）和 0（特征空间为 $v$ 的张量的正交补）。\n\n最后，我们计算 $r_{1}$：\n$$r_{1} = x_{1}^{T} (P x_{1}) = x_{1}^{T} x_{1}$$\n因为 $x_{1}$ 是一个单位向量，所以 $x_{1}^{T} x_{1} = 1$。\n因此，瑞利商的值是：\n$$r_{1} = 1$$\n这个结果与初始向量 $x_{0}$ 的选择无关，只要 $x_{0}$ 在 $v$ 的方向上具有非零分量即可。",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "幂迭代法擅长寻找模最大的特征值，但我们如何找到其他特定的特征值呢？这正是位移逆迭代法的用武之地。这个概念性练习  要求你确定理论上的最优“位移量” $\\sigma$，以分离出我们想要的目标特征值，这将促使你深入思考该技术之所以有效的核心原理。",
            "id": "2427117",
            "problem": "一个实对称矩阵 $A \\in \\mathbb{R}^{4 \\times 4}$ 具有不同的特征值 $\\{10,\\, 9.9,\\, 5,\\, 0.1\\}$。您将应用带有恒定偏移量 $\\sigma \\in \\mathbb{R}$ 的偏移反迭代法来计算与特征值 $9.9$ 相关联的特征向量。确定在偏移反迭代法下，原则上能最有效地分离出特征值 $9.9$ 的 $\\sigma$ 值。请以单个实数的形式提供您的答案。无需四舍五入。",
            "solution": "对问题陈述进行验证。\n\n**第一步：提取已知条件**\n- 矩阵 $A$ 是一个实对称矩阵，$A \\in \\mathbb{R}^{4 \\times 4}$。\n- 矩阵 $A$ 的不同特征值集合为 $\\{\\lambda_1, \\lambda_2, \\lambda_3, \\lambda_4\\} = \\{10,\\, 9.9,\\, 5,\\, 0.1\\}$。\n- 所使用的方法是带有恒定偏移量 $\\sigma \\in \\mathbb{R}$ 的偏移反迭代法。\n- 目标是计算与特征值 $9.9$ 相关联的特征向量。\n- 目标是找到“最有效地分离出”特征值 $9.9$ 的 $\\sigma$ 值。\n\n**第二步：使用提取的已知条件进行验证**\n该问题具有科学依据，因为它基于计算工程和线性代数中公认的数值方法——偏移反迭代法。该问题是适定的；术语“最有效地分离出”在此背景下有标准解释，指的是收敛速度的最大化。该问题是客观的，不包含主观或模糊的语言。所有必要的数据（矩阵的完整谱）都已提供，并且没有矛盾之处。因此，该问题被认为是有效的。\n\n**第三步：结论与行动**\n该问题有效。将提供完整的解答。\n\n**求解推导**\n我们首先陈述偏移反迭代法的原理。该方法是幂迭代算法的一个变体，应用于矩阵 $B = (A - \\sigma I)^{-1}$，其中 $A$ 是原始矩阵，$\\sigma$ 是一个标量偏移量，$I$ 是单位矩阵。\n\n设矩阵 $A$ 的特征值为 $\\lambda_k$。则矩阵 $(A - \\sigma I)$ 的特征值为 $(\\lambda_k - \\sigma)$。因此，迭代矩阵 $B = (A - \\sigma I)^{-1}$ 的特征值为 $\\mu_k = \\frac{1}{\\lambda_k - \\sigma}$。\n\n当幂迭代法应用于矩阵 $B$ 时，它会收敛到与 $B$ 的模最大特征值相对应的特征向量。设 $B$ 的这个主特征值为 $\\mu_{dom}$。为了使偏移反迭代法收敛到与 $A$ 的特定特征值 $\\lambda_{target}$ 相关联的特征向量，对应的特征值 $\\mu_{target} = \\frac{1}{\\lambda_{target} - \\sigma}$ 必须是 $B$ 的主特征值。这个条件表示为：\n$$|\\mu_{target}|  |\\mu_k| \\quad \\forall k \\text{ such that } \\lambda_k \\neq \\lambda_{target}$$\n这个不等式等价于：\n$$\\frac{1}{|\\lambda_{target} - \\sigma|}  \\frac{1}{|\\lambda_k - \\sigma|} \\quad \\forall k \\text{ such that } \\lambda_k \\neq \\lambda_{target}$$\n这可以简化为条件：$\\sigma$ 必须比任何其他特征值 $\\lambda_k$ 更接近 $\\lambda_{target}$：\n$$|\\lambda_{target} - \\sigma|  |\\lambda_k - \\sigma| \\quad \\forall k \\text{ such that } \\lambda_k \\neq \\lambda_{target}$$\n\n问题要求找到能“最有效地分离出”特征值 $\\lambda_{target} = 9.9$ 的偏移量 $\\sigma$。在迭代方法的背景下，“最有效”被解释为实现最快的收敛速度。幂法的收敛速度由迭代矩阵的第二大模特征值（次主特征值，$\\mu_{sub}$）与主特征值（$\\mu_{dom}$）的模之比决定。收敛因子为 $R = \\frac{|\\mu_{sub}|}{|\\mu_{dom}|}$。为了最大化收敛速度，必须最小化这个比率 $R$。\n\n在我们的情况中，$\\mu_{dom} = \\mu_{target} = \\frac{1}{9.9 - \\sigma}$。次主特征值 $\\mu_{sub}$ 对应于 $A$ 的某个特征值，我们称之为 $\\lambda_{other}$，它是距离偏移量 $\\sigma$ 第二近的特征值。因此，$\\mu_{sub} = \\frac{1}{\\lambda_{other} - \\sigma}$。\n\n因此，需要最小化的收敛比率为：\n$$R(\\sigma) = \\frac{|\\mu_{sub}|}{|\\mu_{dom}|} = \\frac{\\left| \\frac{1}{\\lambda_{other} - \\sigma} \\right|}{\\left| \\frac{1}{9.9 - \\sigma} \\right|} = \\frac{|9.9 - \\sigma|}{|\\lambda_{other} - \\sigma|}$$\n总体的收敛因子由“最坏情况”的邻近特征值决定，所以我们必须寻求最小化可能的最大比率：\n$$\\min_{\\sigma} \\left( \\max_{k \\neq target} \\frac{|9.9 - \\sigma|}{|\\lambda_k - \\sigma|} \\right)$$\n其他特征值的集合是 $\\{10, 5, 0.1\\}$。\n通过简单的观察可以看出，当其分子 $|9.9 - \\sigma|$ 被最小时，比率 $R(\\sigma)$ 的表达式也达到最小值。非负量 $|x|$ 的最小值为 $0$，这在 $x=0$ 时发生。\n因此，当以下条件满足时，比率 $R(\\sigma)$ 达到其绝对最小值 $0$：\n$$|9.9 - \\sigma| = 0$$\n这意味着最优的偏移量是 $\\sigma = 9.9$。\n\n选择 $\\sigma = 9.9$ 时，收敛比率 $R$ 变为 $0$，这对应于无限快的收敛速度。这代表了对所需特征向量的最有效的分离。问题要求的是“原则上”能实现这一点的 $\\sigma$ 值。这种措辞表明我们关心的是理论上的最优解，而不是数值实现中的实际限制。在实践中，选择 $\\sigma$ 精确等于一个特征值会使矩阵 $(A - \\sigma I)$ 成为奇异矩阵，其逆矩阵未定义。实际的实现会使用一个极其接近但并不等于 $9.9$ 的 $\\sigma$ 值。然而，所提出的问题是一个原则性问题，理论上的最优解明确无误地是 $\\sigma = 9.9$。",
            "answer": "$$\\boxed{9.9}$$"
        },
        {
            "introduction": "理论知识至关重要，但观察算法在实践中的表现能带来更深刻的见解。这个编程练习  要求你实现并比较三种基本方法的收敛速度：幂迭代、固定位移的逆迭代，以及高效的瑞利商迭代（RQI）。通过在不同矩阵上测试这些算法，你将对它们的优缺点以及先进技术所带来的显著性能提升获得切身的体会。",
            "id": "2427128",
            "problem": "实现一个算法，使用以瑞利商为可变位移的反向迭代法来近似求解实对称矩阵的特征对。对于非零向量 $x \\in \\mathbb{R}^n$，瑞利商定义为 $R(x) = \\dfrac{x^\\mathsf{T} A x}{x^\\mathsf{T} x}$。考虑以下三种迭代方案，应用于实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$，给定非零初始向量 $x_0 \\in \\mathbb{R}^n$ 和容差 $\\varepsilon  0$：\n\n- 幂迭代法：$x_{k+1} \\leftarrow \\dfrac{A x_k}{\\lVert A x_k \\rVert_2}$，其中残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n- 固定位移的反向迭代法：固定 $\\sigma_0 = R(x_0)$，通过求解 $(A - \\sigma_0 I) y = x_k$ 计算 $x_{k+1}$，并设置 $x_{k+1} \\leftarrow \\dfrac{y}{\\lVert y \\rVert_2}$，其中残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n- 以瑞利商为可变位移的反向迭代法（瑞利商迭代法）：在每次迭代中，计算 $\\sigma_k = R(x_k)$，求解 $(A - \\sigma_k I) y = x_k$，并设置 $x_{k+1} \\leftarrow \\dfrac{y}{\\lVert y \\rVert_2}$，其中残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n\n对于每种方案，当残差范数首次满足 $\\lVert A x_k - \\lambda_k x_k \\rVert_2 \\le \\varepsilon$ 或达到预设的最大迭代次数时停止。所有向量范数均为欧几里得范数，$I$ 表示大小为 $n$ 的单位矩阵。\n\n使用以下测试套件。在所有情况下，设置 $n = 5$，容差 $\\varepsilon = 10^{-10}$，最大迭代次数为 $1000$。\n\n- 测试用例 #1（三对角对称正定矩阵）：\n  - 矩阵 $A_1 \\in \\mathbb{R}^{5 \\times 5}$：\n    $$\n    A_1 =\n    \\begin{bmatrix}\n    6  2  0  0  0 \\\\\n    2  5  2  0  0 \\\\\n    0  2  4  2  0 \\\\\n    0  0  2  3  2 \\\\\n    0  0  0  2  2\n    \\end{bmatrix}.\n    $$\n  - 初始向量 $x_0^{(1)} = \\dfrac{1}{\\sqrt{5}} [1, 1, 1, 1, 1]^\\mathsf{T}$。\n\n- 测试用例 #2（具有两个非常接近的特征值的对称矩阵）：\n  - 定义对角矩阵 $D = \\mathrm{diag}(1, 1 + 10^{-6}, 2, 3, 4)$。\n  - 定义角度为 $\\theta$ 的平面旋转，使得 $\\cos \\theta = \\dfrac{4}{5}$ 和 $\\sin \\theta = \\dfrac{3}{5}$，并设置\n    $$\n    Q = \\begin{bmatrix}\n    \\cos \\theta  -\\sin \\theta  0  0  0 \\\\\n    \\sin \\theta  \\phantom{-}\\cos \\theta  0  0  0 \\\\\n    0  0  1  0  0 \\\\\n    0  0  0  1  0 \\\\\n    0  0  0  0  1\n    \\end{bmatrix}.\n    $$\n  - 矩阵 $A_2 = Q^\\mathsf{T} D Q$。\n  - 初始向量 $x_0^{(2)} = [1, 0, 0, 0, 0]^\\mathsf{T}$。\n\n- 测试用例 #3（希尔伯特矩阵）：\n  - 矩阵 $A_3 \\in \\mathbb{R}^{5 \\times 5}$，其元素为 $(A_3)_{ij} = \\dfrac{1}{i + j - 1}$，其中 $i,j \\in \\{1, 2, 3, 4, 5\\}$。\n  - 初始向量 $x_0^{(3)} = \\dfrac{1}{\\sqrt{5}} [1, -1, 1, -1, 1]^\\mathsf{T}$。\n\n对于每个测试用例，使用相同的 $A$ 和 $x_0$ 独立运行这三种方案，并记录残差范数首次满足 $\\lVert A x_k - \\lambda_k x_k \\rVert_2 \\le \\varepsilon$ 时的最小迭代次数 $k$。如果在最大迭代次数内未收敛，则记录最大迭代次数。\n\n您的程序必须输出一行，包含一个由方括号括起来的、逗号分隔的9个整数列表，顺序如下：\n$[k_{\\mathrm{RQI}}^{(1)}, k_{\\mathrm{fixed}}^{(1)}, k_{\\mathrm{power}}^{(1)}, k_{\\mathrm{RQI}}^{(2)}, k_{\\mathrm{fixed}}^{(2)}, k_{\\mathrm{power}}^{(2)}, k_{\\mathrm{RQI}}^{(3)}, k_{\\mathrm{fixed}}^{(3)}, k_{\\mathrm{power}}^{(3)}]$，其中 $k_{\\mathrm{RQI}}^{(i)}$ 是瑞利商迭代法在测试用例 $i$ 上的迭代次数，$k_{\\mathrm{fixed}}^{(i)}$ 是固定位移 $\\sigma_0 = R(x_0^{(i)})$ 的反向迭代法上的迭代次数，$k_{\\mathrm{power}}^{(i)}$ 是幂迭代法上的迭代次数。输出必须严格遵循此格式，只有一行，除了列表表示结构上所需的字符外，不含任何额外的字符或空白。",
            "solution": "问题陈述经评估有效。其科学基础植根于数值线性代数的既定原理，特别是特征值问题的迭代方法。该问题是适定的（well-posed），所有必需的参数、矩阵、初始条件和停止准则都得到了明确无误的定义。语言客观、正式。因此，将提供一个解决方案。\n\n该问题要求实现并比较三种迭代算法，用以近似求解实对称矩阵 $A$ 的一个特征对 $(\\lambda, v)$，其中 $A v = \\lambda v$。一个特征对由一个特征值 $\\lambda$ 及其对应的特征向量 $v$ 组成。所考虑的方法是幂迭代法、固定位移的反向迭代法，以及可变位移的反向迭代法（也称为瑞利商迭代法，RQI）。对于一个实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其所有特征值都是实数，并且存在一个由特征向量构成的标准正交基。对于非零向量 $x \\in \\mathbb{R}^n$，瑞利商定义为 $R(x) = \\frac{x^\\mathsf{T} A x}{x^\\mathsf{T} x}$，它提供了对特征值的估计。如果 $x$ 是一个特征向量，那么 $R(x)$ 就是对应的精确特征值。对于所有算法，我们从一个初始向量 $x_0$ 开始，生成一个收敛到某个特征向量的向量序列 $\\{x_k\\}$，以及一个收敛到相应特征值的瑞利商序列 $\\{\\lambda_k = R(x_k)\\}$。\n\n1.  **幂迭代法**\n\n    幂迭代法是寻找矩阵主特征对的最简单算法，即特征值 $|\\lambda_1|$ 在所有特征值中模最大的特征对 $(\\lambda_1, v_1)$。其迭代步骤定义为：\n    $$\n    x_{k+1} = \\frac{A x_k}{\\lVert A x_k \\rVert_2}\n    $$\n    从一个在主特征向量 $v_1$ 方向上具有非零分量的初始向量 $x_0$ 开始，序列 $x_k$ 将收敛到 $v_1$。收敛是线性的，收敛速度由比率 $|\\lambda_2 / \\lambda_1|$ 决定，其中 $\\lambda_2$ 是模第二大的特征值。如果这个比率接近1，收敛可能非常缓慢。在每一步中，特征值通过瑞利商 $\\lambda_k = R(x_k)$ 来近似。\n\n2.  **固定位移的反向迭代法**\n\n    反向迭代法是一种寻找与给定偏移量 $\\sigma$ 最接近的特征值所对应的特征对的方法。它将幂迭代法应用于矩阵 $(A - \\sigma I)^{-1}$。矩阵 $(A - \\sigma I)^{-1}$ 的特征值为 $(\\lambda_i - \\sigma)^{-1}$，其中 $\\lambda_i$ 是 $A$ 的特征值。$(A - \\sigma I)^{-1}$ 的主特征值对应于 $|\\lambda_i - \\sigma|$ 的最小值，这意味着 $\\lambda_i$ 是 $A$ 的最接近 $\\sigma$ 的特征值。迭代步骤为：\n    $$\n    x_{k+1} = \\frac{(A - \\sigma I)^{-1} x_k}{\\lVert (A - \\sigma I)^{-1} x_k \\rVert_2}\n    $$\n    在实践中，我们避免计算矩阵的逆。而是求解线性方程组 $(A - \\sigma I) y_k = x_k$ 得到 $y_k$，然后进行归一化：\n    $$\n    x_{k+1} = \\frac{y_k}{\\lVert y_k \\rVert_2}\n    $$\n    在这个问题中，整个过程使用一个固定的位移 $\\sigma_0 = R(x_0)$。收敛是线性的，但收敛速度由 $(A-\\sigma_0 I)^{-1}$ 的两个模最大特征值的比率决定。如果 $\\sigma_0$ 比其他任何特征值都更接近某个特征值 $\\lambda_j$，那么向特征向量 $v_j$ 的收敛会非常快。\n\n3.  **瑞利商迭代法 (RQI)**\n\n    瑞利商迭代法是反向迭代法的一种强大改进，其中位移在每一步都使用对特征值的当前最佳估计——瑞利商——进行更新。迭代过程定义如下：\n    1.  计算位移：$\\sigma_k = R(x_k) = \\frac{x_k^\\mathsf{T} A x_k}{x_k^\\mathsf{T} x_k}$。\n    2.  求解 $y_{k+1}$：$(A - \\sigma_k I) y_{k+1} = x_k$。\n    3.  归一化：$x_{k+1} = \\frac{y_{k+1}}{\\lVert y_{k+1} \\rVert_2}$。\n\n    对于对称矩阵，一旦迭代向量 $x_k$ 足够接近一个特征向量，RQI 会表现出三次收敛。这意味着近似值中正确数字的位数在每次迭代后大约变为三倍，从而导致极快的收敛速度。\n\n**停止准则**\n\n对于所有这三种方法，当残差向量的范数 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$ 小于指定的容差 $\\varepsilon$ 时，迭代终止，其中 $\\lambda_k = R(x_k)$。这个残差衡量了当前的近似对 $( \\lambda_k, x_k )$ 满足特征值方程的程度。首次满足此条件的迭代次数 $k$ 是所期望的输出。如果在最大迭代次数内未满足该条件，则记录该最大次数。\n\n实现过程将通过定义三个函数来进行，每个算法一个。每个函数将迭代地生成向量序列并在每一步检查停止准则，返回迭代次数。然后将这些函数应用于三个指定的测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef power_iteration(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates a dominant eigenpair using Power Iteration.\n    \"\"\"\n    x = x0 / np.linalg.norm(x0)\n    for k in range(1, max_iter + 1):\n        # Calculate x_k\n        v = A @ x\n        x_k = v / np.linalg.norm(v)\n\n        # Check residual for x_k\n        # Since x_k is normalized, its L2 norm squared is 1.\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n\n        if residual_norm = tol:\n            return k\n\n        # Prepare for the next iteration\n        x = x_k\n\n    return max_iter\n\ndef inverse_iteration_fixed_shift(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates an eigenpair using inverse iteration with a fixed shift.\n    The shift is the Rayleigh quotient of the initial vector.\n    \"\"\"\n    # Normalize initial vector for stability, although given vectors are normalized.\n    # The problem specifies sigma0 = R(x0), where x0 is the given initial vector.\n    # Since all given x0 are unit norm, x0.T @ x0 = 1.\n    sigma0 = x0.T @ A @ x0\n    \n    try:\n        M = A - sigma0 * np.eye(A.shape[0])\n    except np.linalg.LinAlgError:\n        return max_iter # Fails if shift is an exact eigenvalue\n\n    x = x0 / np.linalg.norm(x0) # Start iteration with normalized vector\n\n    for k in range(1, max_iter + 1):\n        try:\n            # Solve (A - sigma0*I) y = x_{k-1}\n            y = np.linalg.solve(M, x)\n        except np.linalg.LinAlgError:\n            # Shift is an eigenvalue or matrix is numerically singular\n            return max_iter\n\n        x_k = y / np.linalg.norm(y)\n\n        # Check residual for x_k\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n\n        if residual_norm = tol:\n            return k\n\n        x = x_k\n\n    return max_iter\n\ndef rayleigh_quotient_iteration(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates an eigenpair using Rayleigh Quotient Iteration.\n    \"\"\"\n    x = x0 / np.linalg.norm(x0)\n    \n    for k in range(1, max_iter + 1):\n        # Update shift at each step using the Rayleigh quotient of x_{k-1}\n        sigma = x.T @ A @ x\n\n        try:\n            M = A - sigma * np.eye(A.shape[0])\n            # Solve (A - sigma_{k-1}*I) y = x_{k-1}\n            y = np.linalg.solve(M, x)\n        except np.linalg.LinAlgError:\n            # If the shift is an eigenvalue, the previous iterate was the eigenvector.\n            # Its residual should be zero or very small.\n            # The loop condition will have caught it in the previous iteration.\n            # This indicates a numerical breakdown or an exact hit.\n            return k-1 if k  1 else max_iter\n\n        x_k = y / np.linalg.norm(y)\n\n        # Check residual for x_k\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n        \n        if residual_norm = tol:\n            return k\n\n        x = x_k\n\n    return max_iter\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    n = 5\n    tol = 1e-10\n    max_iter = 1000\n\n    # Test Case 1\n    A1 = np.array([\n        [6, 2, 0, 0, 0],\n        [2, 5, 2, 0, 0],\n        [0, 2, 4, 2, 0],\n        [0, 0, 2, 3, 2],\n        [0, 0, 0, 2, 2]\n    ], dtype=float)\n    x0_1 = np.ones(n) / np.sqrt(n)\n\n    # Test Case 2\n    D = np.diag([1.0, 1.0 + 1e-6, 2.0, 3.0, 4.0])\n    cos_theta = 4.0 / 5.0\n    sin_theta = 3.0 / 5.0\n    Q = np.eye(n)\n    Q[0, 0] = cos_theta\n    Q[0, 1] = -sin_theta\n    Q[1, 0] = sin_theta\n    Q[1, 1] = cos_theta\n    A2 = Q.T @ D @ Q\n    x0_2 = np.zeros(n)\n    x0_2[0] = 1.0\n\n    # Test Case 3\n    A3 = np.fromfunction(lambda i, j: 1 / (i + j + 1), (n, n), dtype=float)\n    x0_3 = np.array([1, -1, 1, -1, 1]) / np.sqrt(n)\n    \n    test_cases = [\n        (A1, x0_1),\n        (A2, x0_2),\n        (A3, x0_3)\n    ]\n\n    results = []\n    for A, x0 in test_cases:\n        k_rqi = rayleigh_quotient_iteration(A, x0, tol, max_iter)\n        k_fixed = inverse_iteration_fixed_shift(A, x0, tol, max_iter)\n        k_power = power_iteration(A, x0, tol, max_iter)\n        \n        results.extend([k_rqi, k_fixed, k_power])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}