{
    "hands_on_practices": [
        {
            "introduction": "多重网格方法的核心在于其在不同网格间传递信息的能力，这依赖于限制和延拓这两个传递算子。本练习将通过一个思想实验，探讨一种特殊设计的限制算子——其权重之和为零——如何与不同频率的误差分量（此处由残差代表）相互作用 。通过这个实践，你将深入理解传递算子的设计如何决定其在粗网格上捕捉和表示误差特征的效率。",
            "id": "2416021",
            "problem": "给定一个在周期性域上的一维泊松方程离散模型。设该域为单位圆，由 $n$ 个等距点离散化，点间距为 $h = 1/n$，其中 $n$ 是一个偶数。定义离散负拉普拉斯算子 $A \\in \\mathbb{R}^{n \\times n}$，其具有周期性边界条件：\n$$(A \\mathbf{u})_i = \\frac{2 u_i - u_{i-1} - u_{i+1}}{h^2}, \\quad i \\in \\{0,1,\\dots,n-1\\},$$\n其中索引以 $n$ 为模进行计算。对于任意离散场 $\\mathbf{u} \\in \\mathbb{R}^n$ 和强迫项 $\\mathbf{f} \\in \\mathbb{R}^n$，定义残差 $\\mathbf{r}(\\mathbf{u}) = \\mathbf{f} - A \\mathbf{u}$。考虑限制算子 $R: \\mathbb{R}^n \\to \\mathbb{R}^{n/2}$，其使用一个权重之和为零的三点模板，具体如下：\n$$(R \\mathbf{r})_I = w_{-1}\\, r_{2I-1} + w_0\\, r_{2I} + w_{+1}\\, r_{2I+1}, \\quad I \\in \\{0,1,\\dots,\\tfrac{n}{2}-1\\},$$\n其中索引为周期性，权重为 $(w_{-1}, w_0, w_{+1}) = (1,-2,1)$，因此 $w_{-1} + w_0 + w_{+1} = 0$。\n\n您的任务是实现一个程序，针对下面指定的测试套件，为初始猜测解 $\\mathbf{u} = \\mathbf{0}$ 构建残差 $\\mathbf{r}(\\mathbf{u})$，然后计算标量值\n$$\\gamma = \\frac{\\lVert R \\mathbf{r}(\\mathbf{0}) \\rVert_2}{\\lVert \\mathbf{r}(\\mathbf{0}) \\rVert_2}。$$\n三角函数定义中使用的角度必须是弧度。不涉及物理单位；量 $\\gamma$ 是无量纲的。\n\n测试套件：\n- 情况 1：$n = 64$，$\\mathbf{f}$ 是所有分量 $f_i = 1$ 的常数向量。\n- 情况 2：$n = 64$，$\\mathbf{f}$ 由 $f_i = \\sin(2 \\pi x_i)$ 定义，其中 $x_i = i h$ 且 $h = 1/n$。\n- 情况 3：$n = 64$，$\\mathbf{f}$ 由 $f_i = (-1)^i$ 定义。\n- 情况 4：$n = 8$，$\\mathbf{f}$ 是所有分量 $f_i = 1$ 的常数向量。\n\n对于每种情况，程序必须以浮点数形式输出相应的 $\\gamma$ 值。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[a,b,c,d]”），结果按上述测试用例的顺序排列。答案必须是浮点数。不需要用户输入，程序必须是完全自包含且确定性的。",
            "solution": "在尝试任何解决方案之前，将首先对问题陈述进行严格的验证程序。\n\n### 步骤 1：提取已知信息\n问题陈述中明确提供的信息如下：\n- **域**：一个一维周期性域（单位圆），由 $n$ 个等距点离散化，其中 $n$ 是一个偶数。\n- **网格间距**：$h = 1/n$。\n- **离散算子**：离散负拉普拉斯算子 $A \\in \\mathbb{R}^{n \\times n}$ 通过其对向量 $\\mathbf{u} \\in \\mathbb{R}^n$ 的作用来定义：\n$$(A \\mathbf{u})_i = \\frac{2 u_i - u_{i-1} - u_{i+1}}{h^2}, \\quad i \\in \\{0,1,\\dots,n-1\\}$$\n其中索引以 $n$ 为模进行计算。\n- **残差**：对于给定的场 $\\mathbf{u}$ 和强迫项 $\\mathbf{f}$，残差向量为 $\\mathbf{r}(\\mathbf{u}) = \\mathbf{f} - A \\mathbf{u}$。\n- **限制算子**：限制算子 $R: \\mathbb{R}^n \\to \\mathbb{R}^{n/2}$ 定义为：\n$$(R \\mathbf{r})_I = w_{-1}\\, r_{2I-1} + w_0\\, r_{2I} + w_{+1}\\, r_{2I+1}, \\quad I \\in \\{0,1,\\dots,\\tfrac{n}{2}-1\\}$$\n其中 $\\mathbf{r}$ 的分量索引为周期性。\n- **限制权重**：限制算子的权重为 $(w_{-1}, w_0, w_{+1}) = (1, -2, 1)$。权重之和为 $w_{-1} + w_0 + w_{+1} = 1 - 2 + 1 = 0$。\n- **初始条件**：解的初始猜测是零向量 $\\mathbf{u} = \\mathbf{0}$。\n- **目标量**：计算标量比率 $\\gamma = \\frac{\\lVert R \\mathbf{r}(\\mathbf{0}) \\rVert_2}{\\lVert \\mathbf{r}(\\mathbf{0}) \\rVert_2}$。\n- **测试套件**：\n    - 情况 1：$n = 64$，$f_i = 1$（对于所有 $i$）。\n    - 情况 2：$n = 64$，$f_i = \\sin(2 \\pi x_i)$，其中 $x_i = i h$。\n    - 情况 3：$n = 64$，$f_i = (-1)^i$（对于所有 $i$）。\n    - 情况 4：$n = 8$，$f_i = 1$（对于所有 $i$）。\n\n### 步骤 2：使用提取的已知信息进行验证\n根据所需标准对问题进行评估：\n- **科学基础**：该问题设置在偏微分方程数值分析的背景下，特别是针对泊松方程的多重网格方法。离散拉普拉斯算子、残差和限制算子的定义是计算工程中的标准构造。对于一个生产级多重网格求解器来说，限制权重 $(1, -2, 1)$ 的选择不寻常，但在数学上是良定的。该问题根本上是合理的。\n- **适定性**：任务要求直接计算一个良定的量 $\\gamma$。对于任何给定的非零强迫向量 $\\mathbf{f}$，分母 $\\lVert \\mathbf{r}(\\mathbf{0}) \\rVert_2 = \\lVert \\mathbf{f} \\rVert_2$ 将为非零，计算将产生一个唯一、稳定的结果。\n- **客观性**：问题使用了精确的数学定义和客观的语言来陈述。没有主观或含糊的陈述。\n- **完整性和一致性**：所有必要的定义（$A$、$R$、$\\mathbf{r}$、$\\gamma$）、常数（权重）和数据（$n$ 和 $\\mathbf{f}$ 的测试用例）都已提供。设置中没有矛盾之处。\n- **其他缺陷**：该问题是可形式化的，与指定主题相关，计算上可行，并且其结果是可验证的。它没有任何列出的导致问题无效的缺陷。\n\n### 步骤 3：结论与行动\n问题是 **有效的**。将开始制定解决方案。\n\n### 求解推导\n目标是计算四种不同情况下的量 $\\gamma$。$\\gamma$ 的定义是：\n$$ \\gamma = \\frac{\\lVert R \\mathbf{r}(\\mathbf{0}) \\rVert_2}{\\lVert \\mathbf{r}(\\mathbf{0}) \\rVert_2} $$\n初始猜测解给定为 $\\mathbf{u} = \\mathbf{0}$。残差 $\\mathbf{r}(\\mathbf{u})$ 定义为 $\\mathbf{f} - A\\mathbf{u}$。代入 $\\mathbf{u} = \\mathbf{0}$，我们发现：\n$$ \\mathbf{r}(\\mathbf{0}) = \\mathbf{f} - A\\mathbf{0} = \\mathbf{f} $$\n因此，残差就是强迫向量 $\\mathbf{f}$。$\\gamma$ 的表达式简化为：\n$$ \\gamma = \\frac{\\lVert R \\mathbf{f} \\rVert_2}{\\lVert \\mathbf{f} \\rVert_2} $$\n每个测试用例的计算分三步进行：\n1.  构造强迫向量 $\\mathbf{f} \\in \\mathbb{R}^n$。\n2.  计算限制后的向量 $R\\mathbf{f} \\in \\mathbb{R}^{n/2}$。\n3.  计算两个向量的 L2 范数及其比率。\n\n限制后向量（我们记作 $\\mathbf{v} = R\\mathbf{f}$）的分量由以下公式给出：\n$$ v_I = (R\\mathbf{f})_I = f_{2I-1} - 2f_{2I} + f_{2I+1} $$\n其中 $I \\in \\{0, 1, \\dots, \\frac{n}{2}-1\\}$。$\\mathbf{f}$ 分量的索引必须周期性处理，即索引 $j$ 对应于 $j \\pmod n$。\n\n让我们分析不同类型强迫向量的行为。\n\n**情况 1 和 4：常数强迫向量**\n这里，对于所有 $i$，$f_i = c$，其中 $c=1$。情况 1 的大小为 $n=64$，情况 4 的大小为 $n=8$。\n限制向量 $R\\mathbf{f}$ 的分量为：\n$$ (R\\mathbf{f})_I = f_{2I-1} - 2f_{2I} + f_{2I+1} = c - 2c + c = 0 $$\n限制向量 $R\\mathbf{f}$ 是零向量。其范数 $\\lVert R\\mathbf{f} \\rVert_2$ 为 $0$。分母 $\\lVert \\mathbf{f} \\rVert_2 = \\sqrt{\\sum_{i=0}^{n-1} c^2} = \\sqrt{n c^2}$ 是非零的。因此，对于任何常数强迫向量，$\\gamma = 0$。这证实了情况 1 和情况 4 的结果将是 $0.0$。\n\n**情况 3：高频强迫向量**\n这里，$n=64$ 且 $f_i = (-1)^i$。这代表了网格上可分辨的最高频率模式 $\\cos(\\pi i)$。\n限制向量 $R\\mathbf{f}$ 的分量通过考虑索引的奇偶性来计算：\n$$ f_{2I} = (-1)^{2I} = 1 $$\n$$ f_{2I-1} = (-1)^{2I-1} = -1 $$\n$$ f_{2I+1} = (-1)^{2I+1} = -1 $$\n代入这些值：\n$$ (R\\mathbf{f})_I = (-1) - 2(1) + (-1) = -4 $$\n限制向量 $R\\mathbf{f}$ 是一个大小为 $m=n/2=32$ 的常数向量，所有分量都等于 $-4$。\n$\\mathbf{f}$ 的 L2 范数是 $\\lVert \\mathbf{f} \\rVert_2 = \\sqrt{\\sum_{i=0}^{63} ((-1)^i)^2} = \\sqrt{64} = 8$。\n$R\\mathbf{f}$ 的 L2 范数是 $\\lVert R\\mathbf{f} \\rVert_2 = \\sqrt{\\sum_{I=0}^{31} (-4)^2} = \\sqrt{32 \\times 16} = \\sqrt{512} = 16\\sqrt{2}$。\n比率为 $\\gamma = \\frac{16\\sqrt{2}}{8} = 2\\sqrt{2}$。\n\n**情况 2：低频强迫向量**\n这里，$n=64$ 且 $f_i = \\sin(2 \\pi x_i) = \\sin(2 \\pi i / n)$。这是网格上最平滑的非恒定傅里叶模式。\n$\\mathbf{f}$ 的 L2 范数为 $\\lVert \\mathbf{f} \\rVert_2 = \\sqrt{\\sum_{i=0}^{n-1} \\sin^2(2 \\pi i / n)}$。使用标准的离散傅里叶级数恒等式 $\\sum_{k=0}^{N-1} \\sin^2(2 \\pi jk/N) = N/2$（对于整数 $j$ 且 $1 \\le j < N/2$），我们有 $\\lVert \\mathbf{f} \\rVert_2 = \\sqrt{n/2} = \\sqrt{64/2} = \\sqrt{32}$。\n限制向量的分量为：\n$$ (R\\mathbf{f})_I = \\sin\\left(\\frac{2\\pi(2I-1)}{n}\\right) - 2\\sin\\left(\\frac{2\\pi(2I)}{n}\\right) + \\sin\\left(\\frac{2\\pi(2I+1)}{n}\\right) $$\n令 $\\theta_I = \\frac{2\\pi(2I)}{n}$ 和 $\\Delta\\theta = \\frac{2\\pi}{n}$。表达式变为 $(\\sin(\\theta_I-\\Delta\\theta) + \\sin(\\theta_I+\\Delta\\theta)) - 2\\sin(\\theta_I)$。使用和差化积恒等式，这等于 $2\\sin(\\theta_I)\\cos(\\Delta\\theta) - 2\\sin(\\theta_I) = 2\\sin(\\theta_I)(\\cos(\\Delta\\theta)-1)$。\n使用半角恒等式 $1-\\cos(x) = 2\\sin^2(x/2)$，这简化为：\n$$ (R\\mathbf{f})_I = -4 \\sin^2\\left(\\frac{\\Delta\\theta}{2}\\right) \\sin(\\theta_I) = -4 \\sin^2\\left(\\frac{\\pi}{n}\\right) \\sin\\left(\\frac{4\\pi I}{n}\\right) $$\n$R\\mathbf{f}$ 的范数是 $\\lVert R\\mathbf{f} \\rVert_2 = \\left|-4 \\sin^2\\left(\\frac{\\pi}{n}\\right)\\right| \\sqrt{\\sum_{I=0}^{n/2 - 1} \\sin^2\\left(\\frac{4\\pi I}{n}\\right)}$。\n这个和是 $\\sum_{I=0}^{m-1} \\sin^2\\left(\\frac{2\\pi I}{m}\\right)$，其中 $m=n/2=32$。这个和等于 $m/2 = (n/2)/2 = n/4 = 16$。\n所以，$\\lVert R\\mathbf{f} \\rVert_2 = 4 \\sin^2(\\pi/n) \\sqrt{n/4} = 4 \\sin^2(\\pi/64) \\sqrt{16} = 16 \\sin^2(\\pi/64)$。\n比率为 $\\gamma = \\frac{16 \\sin^2(\\pi/64)}{\\sqrt{32}} = \\frac{16 \\sin^2(\\pi/64)}{4\\sqrt{2}} = \\frac{4}{\\sqrt{2}} \\sin^2(\\pi/64) = 2\\sqrt{2} \\sin^2(\\pi/64)$。\n\n实现过程将以数值方式构造这些向量并计算范数，以求得每种情况下的 $\\gamma$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_gamma(n, f_vector):\n    \"\"\"\n    Calculates the ratio gamma for a given grid size n and forcing vector f.\n\n    The quantity is defined as gamma = ||R*r||_2 / ||r||_2, where r = f for u=0.\n    The restriction operator R is defined by (R*r)_I = r_{2I-1} - 2*r_{2I} + r_{2I+1}.\n\n    Args:\n        n (int): The number of grid points, must be even.\n        f_vector (np.ndarray): The forcing vector of size n.\n\n    Returns:\n        float: The computed value of gamma.\n    \"\"\"\n    \n    # For u=0, the residual r is simply the forcing vector f.\n    r = f_vector\n    \n    # Calculate the denominator: the L2 norm of the residual vector.\n    norm_r = np.linalg.norm(r)\n    \n    # If the norm of the residual is zero, gamma is undefined or 0.\n    # In this context (non-zero f), we can treat it as 0.\n    if norm_r == 0:\n        return 0.0\n\n    # The coarse grid has n/2 points.\n    n_coarse = n // 2\n    restricted_r = np.zeros(n_coarse)\n\n    # Apply the restriction operator R to the residual vector r.\n    # (R*r)_I = r_{2I-1} - 2*r_{2I} + r_{2I+1}, with periodic indexing.\n    for I in range(n_coarse):\n        # Python's % operator correctly handles negative numbers for periodic indexing.\n        # e.g., -1 % 64 = 63.\n        idx_minus_1 = (2 * I - 1) % n\n        idx_0 = (2 * I) % n\n        idx_plus_1 = (2 * I + 1) % n\n\n        restricted_r[I] = r[idx_minus_1] - 2 * r[idx_0] + r[idx_plus_1]\n    \n    # Calculate the numerator: the L2 norm of the restricted residual.\n    norm_restricted_r = np.linalg.norm(restricted_r)\n    \n    # Compute the final ratio.\n    gamma = norm_restricted_r / norm_r\n    \n    return gamma\n\ndef solve():\n    \"\"\"\n    Solves the problem for the four specified test cases and prints the results.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases_params = [\n        {'n': 64, 'id': 1},\n        {'n': 64, 'id': 2},\n        {'n': 64, 'id': 3},\n        {'n': 8,  'id': 4},\n    ]\n\n    results = []\n    for params in test_cases_params:\n        n = params['n']\n        case_id = params['id']\n        f = None\n\n        if case_id == 1: # n=64, f_i = 1\n            f = np.ones(n)\n        elif case_id == 2: # n=64, f_i = sin(2*pi*x_i)\n            h = 1.0 / n\n            x = np.arange(n) * h\n            f = np.sin(2 * np.pi * x)\n        elif case_id == 3: # n=64, f_i = (-1)^i\n            f = np.power(-1.0, np.arange(n))\n        elif case_id == 4: # n=8, f_i = 1\n            f = np.ones(n)\n        \n        gamma = calculate_gamma(n, f)\n        results.append(gamma)\n\n    # Final print statement in the exact required format.\n    # The format specifier ensures that the numbers are printed as floats (e.g., 0.0).\n    print(f\"[{','.join(map(str, [float(r) for r in results]))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在理解了传递算子的基本作用后，我们现在将所有关键部件——光滑子、限制、粗网格求解和延拓——组装成一个完整的双网格循环。本练习不仅要求你构建一个标准的迭代求解器，还引入了一个非标准的变体：“延拓光滑”。通过分析这个额外的光滑步骤对收敛性的影响，你将更深刻地理解多重网格循环中各个阶段如何相互作用，以及如何通过调整算法细节来优化求解性能。",
            "id": "2415975",
            "problem": "实现并评估一个用于通过有限差分法离散的一维 Dirichlet 边值问题的双网格校正格式，重点研究在将延长的粗网格校正量加到细网格近似解之前对其进行光滑处理的效果。细网格问题是求解线性系统 $A_h u_h = f_h$，其中 $A_h \\in \\mathbb{R}^{n \\times n}$ 是单位区间上带有齐次 Dirichlet 边界条件的负二阶导数算子 $-u''$ 的标准二阶中心有限差分离散，即 $A_h = \\frac{1}{h^2}\\,\\mathrm{tridiag}(-1,2,-1)$，其中 $h = \\frac{1}{n+1}$。对于所有计算，使用在内部网格点 $x_i = i h$（$i=1,\\dots,n$）处采样的网格函数 $u^{\\star}(x) = \\sin(\\pi x)$ 来定义精确解向量 $u_h^{\\star}$，并设置 $f_h = A_h u_h^{\\star}$ 以确保 $u_h^{\\star}$ 是精确的细网格解。\n\n您必须实现一个双网格 V-循环校正格式，包含以下组件和选项：\n- 细网格预光滑：对 $A_h u_h = f_h$ 应用 $\\nu_1$ 步带阻尼参数 $\\omega \\in (0,1)$ 的阻尼 Jacobi 迭代，其中一步 Jacobi 迭代更新为 $u \\leftarrow u + \\omega D_h^{-1}(f_h - A_h u)$，其中 $D_h = \\mathrm{diag}(A_h)$。\n- 残差限制：使用全加权限制算子 $R \\in \\mathbb{R}^{n_H \\times n}$，其中 $n_H = \\frac{n-1}{2}$ 且对于 $I=1,\\dots,n_H$，有 $(R r)_I = \\frac{1}{4} r_{2I-1} + \\frac{1}{2} r_{2I} + \\frac{1}{4} r_{2I+1}$。\n- 粗网格算子：使用 Galerkin 定义 $A_H = R A_h P$，其中 $P \\in \\mathbb{R}^{n \\times n_H}$ 是标准线性插值（在偶数索引处为注入，在奇数索引处为平均）。\n- 粗网格求解：精确求解 $A_H e_H = R(f_h - A_h u_h)$。\n- 校正量的延长：通过线性插值形成 $e_h = P e_H$。\n- 延长光滑：在更新细网格解之前，通过对齐次问题 $A_h e = 0$ 应用 $p$ 步使用相同阻尼参数 $\\omega$ 的阻尼 Jacobi 迭代来光滑化延长的校正量 $e_h$，即从 $e = e_h$ 开始，重复更新 $e \\leftarrow e + \\omega D_h^{-1}(0 - A_h e)$ 共 $p$ 步。\n- 校正与后光滑：更新 $u_h \\leftarrow u_h + e_h$，然后对 $A_h u_h = f_h$ 应用 $\\nu_2$ 步使用相同 $\\omega$ 的阻尼 Jacobi 后光滑。\n\n对于每个测试用例，用 $u_h^{(0)} = 0$ 初始化细网格近似解，执行恰好一次如上所述的双网格 V-循环，并计算定义为欧几里得范数之比的误差缩减因子 $ \\rho = \\frac{\\lVert u_h^{\\star} - u_h^{(1)} \\rVert_2}{\\lVert u_h^{\\star} - u_h^{(0)} \\rVert_2}$。将此标量作为浮点数报告。\n\n您的程序必须根据上述定义，为具有齐次 Dirichlet 边界条件的一维空间问题显式实现所有算子。必须严格按照规定使用 Galerkin 粗网格算子 $A_H$。Jacobi 对角部分必须是 $D_h = \\mathrm{diag}(A_h)$，并且在解光滑和延长光滑中都必须使用相同的 $D_h$。粗网格求解和构建 $f_h$ 的线性代数运算可以使用直接稠密线性求解器来执行。\n\n测试套件。您的程序必须执行以下测试用例并报告每个用例的误差缩减因子：\n- 案例 $1$：$(n, \\nu_1, \\nu_2, \\omega, p) = (63, 1, 1, 2/3, 0)$。\n- 案例 $2$：$(n, \\nu_1, \\nu_2, \\omega, p) = (63, 1, 1, 2/3, 1)$。\n- 案例 $3$：$(n, \\nu_1, \\nu_2, \\omega, p) = (63, 1, 1, 2/3, 3)$。\n- 案例 $4$：$(n, \\nu_1, \\nu_2, \\omega, p) = (127, 2, 2, 0.8, 0)$。\n- 案例 $5$：$(n, \\nu_1, \\nu_2, \\omega, p) = (7, 1, 1, 0.5, 2)$。\n\n答案规格。对于每个案例，计算如上定义的标量误差缩减因子 $\\rho$。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按案例1到5的顺序排列结果，每个浮点数四舍五入到8位小数。例如，要求的格式为 $[r_1,r_2,r_3,r_4,r_5]$，其中每个 $r_i$ 是一个小数点后恰好有8位数字的小数。",
            "solution": "经审阅，问题陈述有效。它在计算工程领域提出了一个明确定义的任务，该任务基于数值分析和多重网格方法的既定原理。参数、算子和所需的循环结构都以足够的精度被指定，以便能够得到唯一且可验证的解。我们将着手构建所需的双网格算法。\n\n问题的核心是求解线性系统 $A_h u_h = f_h$ ，该系统源于对区间 $[0, 1]$ 上带有齐次 Dirichlet 边界条件的一维泊松方程 $-u''(x) = f(x)$ 的有限差分离散化。\n\n1.  **离散化与问题设置**：\n    细网格 $\\Omega_h$ 由 $n$ 个内部点 $x_i = i h$（$i=1, \\dots, n$）组成，其中网格间距为 $h = \\frac{1}{n+1}$。算子 $A_h \\in \\mathbb{R}^{n \\times n}$ 是使用二阶中心差分格式的负二阶导数的矩阵表示。它是一个对称正定三对角矩阵，由下式给出\n    $$\n    A_h = \\frac{1}{h^2}\n    \\begin{pmatrix}\n    2 & -1 & & & \\\\\n    -1 & 2 & -1 & & \\\\\n     & \\ddots & \\ddots & \\ddots & \\\\\n     & & -1 & 2 & -1 \\\\\n     & & & -1 & 2\n    \\end{pmatrix}.\n    $$\n    精确解通过在网格点上对函数 $u^{\\star}(x) = \\sin(\\pi x)$ 进行采样来定义，从而得到向量 $u_h^{\\star} \\in \\mathbb{R}^n$。右端项 $f_h$ 被构造为 $f_h = A_h u_h^{\\star}$ 以确保一致性。这意味着 $f_h$ 是函数 $\\pi^2 \\sin(\\pi x)$ 的离散表示。迭代过程的初始近似解是零向量，$u_h^{(0)} = 0$。\n\n2.  **多重网格组件**：\n    双网格方法需要传递算子在细网格 $\\Omega_h$ 和粗网格 $\\Omega_H$ 之间传递信息。粗网格通过选取细网格上每隔一个点来定义，从而得到 $n_H = \\frac{n-1}{2}$ 个内部点。\n\n    -   **限制算子 ($R$)**: 全加权限制算子 $R \\in \\mathbb{R}^{n_H \\times n}$ 将细网格上的值平均到粗网格上。对于一个细网格向量 $r_h$，粗网格向量 $r_H = R r_h$ 的第 $I$ 个分量由格式 $[\\frac{1}{4}, \\frac{1}{2}, \\frac{1}{4}]$ 给出：\n        $$\n        (R r_h)_I = \\frac{1}{4} (r_h)_{2I-1} + \\frac{1}{2} (r_h)_{2I} + \\frac{1}{4} (r_h)_{2I+1}\n        $$\n        为清晰起见，此处使用基于1的索引。该格式以粗网格位置为中心应用，这些位置对应于细网格的偶数索引点。\n\n    -   **延长算子 ($P$)**: 线性插值延长算子 $P \\in \\mathbb{R}^{n \\times n_H}$ 将粗网格函数传递到细网格。它是限制算子的转置，并乘以一个因子2，即 $P = 2R^T$。该算子在对应的细网格位置注入粗网格值，并对中间的细网格点进行线性插值。\n\n    -   **粗网格算子 ($A_H$)**: 一个关键组件是粗网格算子 $A_H \\in \\mathbb{R}^{n_H \\times n_H}$。我们使用 Galerkin 公式，它提供了细网格算子的变分最优粗化表示：\n        $$\n        A_H = R A_h P.\n        $$\n        这种构造确保了对称性和正定性等重要属性从 $A_h$ 继承而来。\n\n    -   **光滑子**: 光滑子是阻尼 Jacobi 迭代。对于一个通用系统 $A u = f$，一步迭代由下式给出\n        $$\n        u \\leftarrow u + \\omega D^{-1}(f - A u),\n        $$\n        其中 $D = \\mathrm{diag}(A)$，$\\omega \\in (0, 1)$ 是阻尼参数。对于我们特定的算子 $A_h$，其对角线是一个常数矩阵，$D_h = \\frac{2}{h^2}I$，因此其逆矩阵的运算简化为乘以一个标量 $\\frac{h^2}{2}$。\n\n3.  **双网格 V-循环算法**：\n    从一个近似解 $u_h^{(k)}$ 开始，单个 V-循环包含以下步骤，以产生一个改进的近似解 $u_h^{(k+1)}$：\n    \n    a.  **预光滑**: 对细网格问题 $A_h u_h = f_h$ 应用 $\\nu_1$ 步阻尼 Jacobi 光滑子。\n        $$\n        \\tilde{u}_h \\leftarrow \\text{Smooth}^{\\nu_1}(A_h, f_h, u_h^{(k)}).\n        $$\n\n    b.  **残差计算**: 计算细网格上的残差，它代表了当前光滑后近似解的误差。\n        $$\n        r_h = f_h - A_h \\tilde{u}_h.\n        $$\n\n    c.  **限制**: 将细网格残差传递到粗网格。\n        $$\n        r_H = R r_h.\n        $$\n\n    d.  **粗网格求解**: 在粗网格上，求解残差方程以获得误差校正量 $e_H$。根据问题陈述，该系统被精确求解。\n        $$\n        A_H e_H = r_H \\implies e_H = A_H^{-1} r_H.\n        $$\n\n    e.  **延长**: 将粗网格校正量插值回细网格。\n        $$\n        e_h^{\\text{raw}} = P e_H.\n        $$\n\n    f.  **延长光滑**: 这是一个指定的非标准步骤。在进行最终校正之前，延长的误差校正量 $e_h^{\\text{raw}}$ 本身要被光滑化。这是通过对齐次问题 $A_h e_h = 0$ 应用 $p$ 次阻尼 Jacobi 迭代来实现的，迭代从 $e_h^{\\text{raw}}$ 开始。\n        $$\n        e_h \\leftarrow \\text{Smooth}^{p}(A_h, 0, e_h^{\\text{raw}}).\n        $$\n        其基本原理是，延长操作可能会在校正量中引入高频振荡；光滑操作可以抑制这些非光滑分量，从而可能提高校正的质量。如果 $p=0$，则 $e_h = e_h^{\\text{raw}}$。\n\n    g.  **校正**: 使用（光滑后的）校正量更新细网格近似解。\n        $$\n        \\hat{u}_h = \\tilde{u}_h + e_h.\n        $$\n\n    h.  **后光滑**: 对校正后的近似解 $\\hat{u}_h$ 应用 $\\nu_2$ 步阻尼 Jacobi 光滑子。\n        $$\n        u_h^{(k+1)} \\leftarrow \\text{Smooth}^{\\nu_2}(A_h, f_h, \\hat{u}_h).\n        $$\n        此步骤旨在抑制由粗网格校正过程引入的任何高频误差。\n\n4.  **评估**：\n    单个循环的有效性通过误差缩减因子 $\\rho$ 来衡量。从 $u_h^{(0)} = 0$ 开始，我们经过一个 V-循环后计算出 $u_h^{(1)}$。因子 $\\rho$ 是最终误差和初始误差的欧几里得范数之比：\n    $$\n    \\rho = \\frac{\\lVert u_h^{\\star} - u_h^{(1)} \\rVert_2}{\\lVert u_h^{\\star} - u_h^{(0)} \\rVert_2} = \\frac{\\lVert u_h^{\\star} - u_h^{(1)} \\rVert_2}{\\lVert u_h^{\\star} \\rVert_2}.\n    $$\n    实现过程显式地构造所有矩阵，并对每个测试用例执行一系列操作来计算该因子。",
            "answer": "```python\nimport numpy as np\n\ndef create_A_h(n):\n    \"\"\"\n    Constructs the finite difference matrix A_h for the 1D Poisson problem.\n    A_h = (1/h^2) * tridiag(-1, 2, -1).\n    \"\"\"\n    h = 1.0 / (n + 1)\n    # The matrix is (1/h^2) * (2*I - L - U) where L and U are sub/super-diagonals\n    A_h = (2.0 * np.eye(n) - np.eye(n, k=1) - np.eye(n, k=-1)) / (h**2)\n    return A_h, h\n\ndef create_R(n):\n    \"\"\"\n    Constructs the full-weighting restriction operator R.\n    (R r)_I = 1/4 * r_{2I-1} + 1/2 * r_{2I} + 1/4 * r_{2I+1} (1-based index)\n    \"\"\"\n    if n % 2 == 0:\n        raise ValueError(\"n must be odd for this coarse grid definition.\")\n    n_H = (n - 1) // 2\n    R = np.zeros((n_H, n))\n    # Python 0-based indexing for r_h: j = 0, ..., n-1\n    # Python 0-based indexing for r_H: I = 0, ..., n_H-1\n    # Mapping 1-based formula to 0-based index:\n    # (r_H)_I corresponds to coarse node I.\n    # Fine grid nodes involved are 2(I+1)-1, 2(I+1), 2(I+1)+1 (1-based)\n    # which are 2I, 2I+1, 2I+2 (0-based) in r_h.\n    for i in range(n_H):\n        j_left = 2 * i\n        j_center = 2 * i + 1\n        j_right = 2 * i + 2\n        R[i, j_left] = 0.25\n        R[i, j_center] = 0.5\n        R[i, j_right] = 0.25\n    return R\n\ndef damped_jacobi(A, u, f, omega, nu, inv_D_scalar):\n    \"\"\"\n    Performs nu steps of the damped Jacobi iteration.\n    For this specific A_h, D is a scalar matrix, so inv_D is a scalar multiplication.\n    \"\"\"\n    u_new = u.copy()\n    for _ in range(nu):\n        residual = f - A @ u_new\n        u_new += omega * inv_D_scalar * residual\n    return u_new\n\ndef run_two_grid_cycle(n, nu1, nu2, omega, p):\n    \"\"\"\n    Executes one two-grid V-cycle and computes the error-reduction factor.\n    \"\"\"\n    # 1. Setup grids, operators, and exact solution\n    A_h, h = create_A_h(n)\n    \n    n_H = (n - 1) // 2\n\n    x_h = np.linspace(h, 1.0 - h, n)\n    u_h_star = np.sin(np.pi * x_h)\n    f_h = A_h @ u_h_star\n\n    R = create_R(n)\n    P = 2 * R.T\n    \n    A_H = R @ A_h @ P\n\n    u_h = np.zeros(n)\n    \n    initial_error_norm = np.linalg.norm(u_h_star - u_h)\n    \n    # D^-1 for damped Jacobi is a scalar multiplication\n    inv_D_h_scalar = h**2 / 2.0\n\n    # 2. Pre-smoothing\n    u_tilde = damped_jacobi(A_h, u_h, f_h, omega, nu1, inv_D_h_scalar)\n\n    # 3. Residual computation and restriction\n    r_h = f_h - A_h @ u_tilde\n    r_H = R @ r_h\n\n    # 4. Coarse-grid solve (exact)\n    e_H = np.linalg.solve(A_H, r_H)\n    \n    # 5. Prolongation of correction\n    e_h_raw = P @ e_H\n\n    # 6. Prolongation smoothing\n    if p > 0:\n        # Homogeneous Jacobi: f=0\n        f_homogeneous = np.zeros(n)\n        e_h = damped_jacobi(A_h, e_h_raw, f_homogeneous, omega, p, inv_D_h_scalar)\n    else:\n        e_h = e_h_raw\n        \n    # 7. Correction\n    u_hat = u_tilde + e_h\n\n    # 8. Post-smoothing\n    u_h_1 = damped_jacobi(A_h, u_hat, f_h, omega, nu2, inv_D_h_scalar)\n\n    # 9. Compute error-reduction factor\n    final_error_norm = np.linalg.norm(u_h_star - u_h_1)\n    \n    rho = final_error_norm / initial_error_norm if initial_error_norm > 0 else 0.0\n    \n    return rho\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (n, nu1, nu2, omega, p)\n        (63, 1, 1, 2/3, 0),\n        (63, 1, 1, 2/3, 1),\n        (63, 1, 1, 2/3, 3),\n        (127, 2, 2, 0.8, 0),\n        (7, 1, 1, 0.5, 2),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, nu1, nu2, omega, p = case\n        rho = run_two_grid_cycle(n, nu1, nu2, omega, p)\n        results.append(rho)\n\n    # Format the output as requested, with 8 decimal places for each value.\n    formatted_results = [f\"{r:.8f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "真实的科学与工程计算中，多重网格求解器通常比简单的双网格V循环更为复杂和高效。这个高级练习将指导你实现一个完整的、递归的多层级算法，并探索更强大的循环策略，如W循环和随网格层级变化的自适应光滑步数 $\\nu(l)$ 。通过实现和比较这些高级策略，你将学会如何根据问题的特性设计和调整多重网格算法，这是从理论走向高性能计算实践的关键一步。",
            "id": "2416031",
            "problem": "您的任务是设计并实现一个可变平滑多重网格循环，其中平滑步骤的次数取决于网格层级。您需要在一维空间中进行工作，并考虑在单位区间上带有齐次狄利克雷边界条件的泊松方程所给出的边值问题，该问题通过二阶中心有限差分进行离散化。得到的线性系统是对称正定的，并且在每个内部网格点上，其作用为一个三对角算子。您的实现必须从以下基本框架开始：\n- 连续模型是一维泊松方程，带有齐次狄利克雷边界条件，写作 $-u''(x)=g(x)$，其中 $x\\in(0,1)$，且 $u(0)=u(1)=0$。\n- 在间距为 $h$ 的均匀网格上进行二阶中心有限差分近似，会得到层级 $l$ 上的线性系统 $A^{(l)} u^{(l)} = f^{(l)}$，其中 $A^{(l)}$ 是一个三对角算子，其对角线上元素为 $2/h_l^2$，紧邻的次对角线上元素为 $-1/h_l^2$，并且 $h_l = 1/(n_l+1)$，$n_l$ 是层级 $l$ 上的内部未知数数量。\n- 加权雅可比平滑由迭代 $u^{(l)} \\leftarrow u^{(l)} + \\omega \\left(D^{(l)}\\right)^{-1}\\left(f^{(l)} - A^{(l)} u^{(l)}\\right)$ 定义，其中 $\\omega$ 是选定的松弛参数，$D^{(l)}$ 是 $A^{(l)}$ 的对角部分。\n- 相邻层级之间的限制与延拓分别使用标准的全加权限制和线性插值延拓。如果 $r^{(l)}$ 是一个细网格向量，其大小为 $n_l = 2 n_{l+1} + 1$，则限制操作为 $(r^{(l+1)})_j = \\frac{1}{4} r^{(l)}_{2j} + \\frac{1}{2} r^{(l)}_{2j+1} + \\frac{1}{4} r^{(l)}_{2j+2}$，对于 $j=0,\\dots,n_{l+1}-1$；延拓操作通过在奇数索引处注入和在偶数索引处进行线性插值给出。\n- V-循环在每次访问时执行一次递归粗网格校正，而 W-循环在每次访问时执行两次递归粗网格校正。用 $\\gamma$ 表示循环指数，V-循环为 $\\gamma=1$，W-循环为 $\\gamma=2$。\n\n您的任务是实现一个多重网格循环，其中平滑步骤的次数 $ \\nu(l)$ 取决于网格层级 $ l$。层级编号必须为：最细网格为 $l=0$，最粗网格为 $l=L-1$，其中 $L$ 是层级总数。在每个层级上使用相同数量的前平滑和后平滑步骤，次数等于 $\\nu(l)$。\n\n网格层次结构从一个具有 $N$ 个内部点的最细网格开始构建，其中 $N = 2^L - 1$，对于某个整数 $L \\ge 2$。最粗层级的问题必须通过直接求解相应的三对角线性系统来精确求解。取右端项为常数，即 $g(x)\\equiv 1$，这对应于在最细层级上对所有内部点 $i$ 都有 $f^{(0)}_i = 1$，并使用齐次狄利克雷边界条件。将最细层级的近似解 $u^{(0)}$ 初始化为零向量。\n\n通过以下族之一来定义平滑方案 $\\nu(l)$，在每种情况下确保 $\\nu(l)$ 是一个不小于 $1$ 的整数：\n- 常数型：$\\nu(l) = \\mathrm{round}(c)$。\n- 线性型：$\\nu(l) = \\max\\{1,\\ \\mathrm{round}(a + b\\,l)\\}$。\n- 几何型：$\\nu(l) = \\max\\{1,\\ \\mathrm{round}(a\\,b^{\\,l})\\}$。\n\n使用加权雅可比平滑，松弛参数为 $\\omega = 2/3$。\n\n对于给定的 $N$、$\\gamma$、$\\nu(l)$ 的族及其参数，从最细层级上的零初始猜测 $u^{(0)}=0$ 开始运行 $K$ 个循环。设 $\\lVert r_k \\rVert_2$ 表示完成 $k$ 个循环后最细层级残差的欧几里得范数，$\\lVert r_0 \\rVert_2$ 为初始范数（当 $u^{(0)}=0$ 时）。报告观测到的每循环平均缩减因子\n$$\n\\rho_\\mathrm{obs} = \\left(\\frac{\\lVert r_K \\rVert_2}{\\lVert r_0 \\rVert_2}\\right)^{1/K}.\n$$\n您的程序必须为下面的每个测试用例计算 $\\rho_\\mathrm{obs}$，并在一行中以方括号括起来的逗号分隔列表形式打印结果，每个数字四舍五入到小数点后六位。不需要物理单位。\n\n测试套件：\n- 情况 $1$ (顺利路径)：$N=63$，$\\gamma=1$ (V-循环)，常数型 $\\nu(l)$ 且 $c=2$，以及 $K=8$。\n- 情况 $2$ (依赖层级的粗网格重平滑)：$N=63$，$\\gamma=1$ (V-循环)，线性型 $\\nu(l)$ 且 $a=1, b=1$，以及 $K=8$。\n- 情况 $3$ (具有更强粗网格平滑的 W-循环)：$N=63$，$\\gamma=2$ (W-循环)，线性型 $\\nu(l)$ 且 $a=1, b=2$，以及 $K=6$。\n- 情况 $4$ (平滑次数几何增长且最细网格更大)：$N=127$，$\\gamma=1$ (V-循环)，几何型 $\\nu(l)$ 且 $a=1, b=1.5$，以及 $K=6$。\n\n为确保科学真实性的算法要求：\n- 在每个层级上使用由中心有限差分模板 $(-1,2,-1)/h_l^2$ 所确定的精确三对角算子 $A^{(l)}$ 来形成残差并在最粗层级上求解。\n- 在相邻层级之间使用如上所述的全加权限制和线性插值延拓。\n- 对前平滑和后平滑都使用 $\\omega=2/3$ 的加权雅可比法，每个层级上的迭代次数均为 $\\nu(l)$。\n- 使用所定义的 $\\gamma$ 来实现 V-循环和 W-循环。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按测试用例的顺序排列结果，例如 $[\\rho_1,\\rho_2,\\rho_3,\\rho_4]$，其中每个 $\\rho_i$ 都四舍五入到小数点后六位。程序不得读取任何输入，并且必须只产生这唯一的输出行。",
            "solution": "该问题要求设计并实现一种用于一维泊松方程 $-u''(x) = g(x)$（在 $x \\in (0, 1)$ 上，带有齐次狄利克雷边界条件 $u(0) = u(1) = 0$）的多重网格方法。其关键特性是一种可变平滑策略，即平滑迭代的次数取决于网格层级。\n\n首先，我们对问题进行离散化。我们建立一个网格层级，用层级 $l$ 索引，其中 $l=0$ 对应最细的网格，$l=L-1$ 对应最粗的网格。最细网格有 $N$ 个内部点，其中 $N=2^L-1$（对于某个整数 $L \\ge 2$）。使用标准的粗化策略，层级 $l$ 上的内部点数 $n_l$ 由 $n_l = 2^{L-l}-1$ 给出。因此，下一个更粗层级上的点数为 $n_{l+1} = (n_l-1)/2$。层级 $l$ 上的网格间距为 $h_l = 1/(n_l+1)$。\n\n对二阶导数使用二阶中心有限差分近似，我们得到一个关于内部网格点未知值 $u^{(l)}$ 的线性方程组：$A^{(l)} u^{(l)} = f^{(l)}$。矩阵 $A^{(l)}$ 是一个 $n_l \\times n_l$ 的对称正定三对角矩阵，其元素为：\n$$\nA^{(l)}_{i,j} = \\frac{1}{h_l^2}\n\\begin{cases}\n2, & i=j \\\\\n-1, & |i-j|=1 \\\\\n0, & \\text{否则}\n\\end{cases}\n$$\n最细层级上的右端项向量 $f^{(l)}$ 由 $g(x) \\equiv 1$ 导出，因此对所有 $i$ 都有 $f^{(0)}_i = 1$。在更粗的层级上，$f^{(l)}$ 将是来自下一个更细层级的受限残差。\n\n多重网格方法的核心是一个递归循环。在层级 $l$ 上近似求解 $A^{(l)} u^{(l)} = f^{(l)}$ 的单个循环包括三个主要步骤：\n\n1.  **前平滑**：通过应用平滑算子来改进当前近似解 $u^{(l)}$。我们使用 $\\nu(l)$ 次加权雅可比方法迭代：\n    $$\n    u^{(l)} \\leftarrow u^{(l)} + \\omega (D^{(l)})^{-1} (f^{(l)} - A^{(l)} u^{(l)})\n    $$\n    这里，$D^{(l)}$ 是 $A^{(l)}$ 的对角部分，所以 $(D^{(l)})^{-1}_{ii} = h_l^2/2$。松弛参数给定为 $\\omega=2/3$。平滑步骤的次数 $\\nu(l)$ 是一个关于层级 $l$ 的函数，由所提供的常数、线性或几何方案之一确定。\n\n2.  **粗网格校正**：此步骤在更粗的网格上求解误差，那里的问题规模更小，计算成本更低。\n    a. 计算细网格上的残差：$r^{(l)} = f^{(l)} - A^{(l)} u^{(l)}$。\n    b. 将残差限制到下一个更粗的网格 $l+1$：$r^{(l+1)} = R^{(l \\to l+1)} r^{(l)}$。限制算子 $R^{(l \\to l+1)}$ 是全加权算子，在一维中其模板为 $[1/4, 1/2, 1/4]$。它作用于细网格向量 $v^{(l)}$ 上的方式为：\n    $$\n    (v^{(l+1)})_j = \\frac{1}{4} v^{(l)}_{2j} + \\frac{1}{2} v^{(l)}_{2j+1} + \\frac{1}{4} v^{(l)}_{2j+2}, \\quad j = 0, \\dots, n_{l+1}-1.\n    $$\n    c. 求解粗网格残差方程 $A^{(l+1)} e^{(l+1)} = r^{(l+1)}$。如果层级 $l+1$ 是最粗的网格（$l+1 = L-1$），则该方程被直接求解。在我们的情况下，最粗网格有 $n_{L-1}=1$ 个未知数，所以这是一个平凡的标量方程。如果层级 $l+1$ 不是最粗的，则该方程通过应用 $\\gamma$ 次多重网格循环来递归求解，初始猜测为 $e^{(l+1)}=0$。对于 V-循环，$\\gamma=1$；对于 W-循环，$\\gamma=2$。\n    d. 将粗网格误差校正延拓回细网格：$e^{(l)} = P^{(l+1 \\to l)} e^{(l+1)}$。延拓算子 $P^{(l+1 \\to l)}$ 是线性插值，它是全加权限制算子转置的 2 倍：$P^{(l+1 \\to l)} = 2 (R^{(l \\to l+1)})^T$。对于一个粗网格向量 $v^{(l+1)}$，其作用通过在细网格的奇数索引处注入和在偶数索引处取平均值来定义，同时尊重零边界条件：\n    $$\n    (v^{(l)})_{2j+1} = v^{(l+1)}_j \\\\\n    (v^{(l)})_{2j} = \\frac{1}{2} (v^{(l+1)}_{j-1} + v^{(l+1)}_j)\n    $$\n    其中边界值取为零（例如，$v^{(l+1)}_{-1} = 0$）。\n    e. 更新细网格解：$u^{(l)} \\leftarrow u^{(l)} + e^{(l)}$。\n\n3.  **后平滑**：为了抑制延拓步骤引入的任何高频误差，我们再次对更新后的近似解 $u^{(l)}$ 应用 $\\nu(l)$ 次加权雅可比平滑器。\n\n整个过程在最细层级（$l=0$）上以初始猜测 $u^{(0)}=0$ 启动。在执行指定数量的循环 $K$ 后，评估收敛性。性能由残差的欧几里得范数的每循环平均缩减因子 $\\rho_{\\text{obs}}$ 来衡量。这是根据初始残差范数 $\\lVert r_0 \\rVert_2 = \\lVert f^{(0)} - A^{(0)} u^{(0)}_0 \\rVert_2$ 和 $K$ 个循环后的最终残差范数 $\\lVert r_K \\rVert_2 = \\lVert f^{(0)} - A^{(0)} u^{(0)}_K \\rVert_2$ 计算得出的，使用公式：\n$$\n\\rho_{\\mathrm{obs}} = \\left(\\frac{\\lVert r_K \\rVert_2}{\\lVert r_0 \\rVert_2}\\right)^{1/K}\n$$\n实现部分将构建必要的算子，并为每个指定的测试用例执行递归循环，相应地计算 $\\rho_{\\mathrm{obs}}$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import diags\n\n# ===== Multigrid Component Implementations =====\n\ndef create_operator_A(n):\n    \"\"\"Creates the 1D Poisson matrix for a grid with n interior points.\"\"\"\n    h = 1.0 / (n + 1)\n    main_diag = np.full(n, 2.0 / h**2)\n    off_diag = np.full(n - 1, -1.0 / h**2)\n    return diags([off_diag, main_diag, off_diag], [-1, 0, 1], format='csr')\n\ndef apply_smoother(u, f, A, nu, omega):\n    \"\"\"Applies nu steps of the weighted Jacobi smoother.\"\"\"\n    u_new = np.copy(u)\n    # The diagonal of A is constant, so D_inv is a scalar multiplication.\n    # D_ii = 2 / h^2, so D_inv_ii = h^2 / 2\n    n = len(u)\n    h_sq = (1.0 / (n + 1))**2\n    D_inv_val = h_sq / 2.0\n    \n    for _ in range(nu):\n        residual = f - A @ u_new\n        u_new += omega * D_inv_val * residual\n    return u_new\n\ndef apply_restriction(r_fine):\n    \"\"\"Applies full-weighting restriction.\"\"\"\n    # Stencil is [1/4, 1/2, 1/4]\n    # Vectorized implementation for speed\n    n_fine = len(r_fine)\n    if n_fine == 1:\n        return np.array([])\n    r_coarse = 0.25 * r_fine[:-2:2] + 0.5 * r_fine[1:-1:2] + 0.25 * r_fine[2::2]\n    return r_coarse\n\ndef apply_prolongation(e_coarse, n_fine):\n    \"\"\"Applies linear interpolation prolongation.\"\"\"\n    n_coarse = len(e_coarse)\n    e_fine = np.zeros(n_fine)\n    \n    # Injection at odd indices\n    e_fine[1::2] = e_coarse\n    \n    # Interpolation at even indices (including boundaries)\n    padded_coarse = np.concatenate(([0], e_coarse, [0]))\n    e_fine[::2] = 0.5 * (padded_coarse[:-1] + padded_coarse[1:])\n    \n    return e_fine\n\ndef calculate_nu(level, family, params):\n    \"\"\"Calculates the number of smoothing steps for a given level.\"\"\"\n    if family == 'constant':\n        val = params['c']\n    elif family == 'linear':\n        val = params['a'] + params['b'] * level\n    elif family == 'geometric':\n        val = params['a'] * (params['b'] ** level)\n    else:\n        raise ValueError(f\"Unknown smoothing schedule family: {family}\")\n    \n    return max(1, int(np.round(val)))\n\ndef mg_cycle(level, u, f, grid_params):\n    \"\"\"Performs one recursive multigrid cycle.\"\"\"\n    ns, As, nus, gamma, omega = grid_params\n    \n    # Base case: on the coarsest level, solve exactly\n    if level == len(ns) - 1:\n        # For n=1, this is a 1x1 system A u = f -> u = f / A[0,0]\n        return f / As[level][0, 0]\n\n    # 1. Pre-smoothing\n    u = apply_smoother(u, f, As[level], nus[level], omega)\n\n    # 2. Coarse-grid correction\n    residual_fine = f - As[level] @ u\n    residual_coarse = apply_restriction(residual_fine)\n    \n    error_coarse = np.zeros_like(residual_coarse)\n    \n    # Recursive calls to solve the coarse-grid error equation\n    for _ in range(gamma):\n        error_coarse = mg_cycle(level + 1, error_coarse, residual_coarse, grid_params)\n        \n    error_fine = apply_prolongation(error_coarse, ns[level])\n    u += error_fine\n\n    # 3. Post-smoothing\n    u = apply_smoother(u, f, As[level], nus[level], omega)\n\n    return u\n\ndef solve():\n    \"\"\"Main function to run test cases and print results.\"\"\"\n    test_cases = [\n        {'N': 63, 'gamma': 1, 'nu_family': 'constant', 'nu_params': {'c': 2}, 'K': 8},\n        {'N': 63, 'gamma': 1, 'nu_family': 'linear', 'nu_params': {'a': 1, 'b': 1}, 'K': 8},\n        {'N': 63, 'gamma': 2, 'nu_family': 'linear', 'nu_params': {'a': 1, 'b': 2}, 'K': 6},\n        {'N': 127, 'gamma': 1, 'nu_family': 'geometric', 'nu_params': {'a': 1, 'b': 1.5}, 'K': 6},\n    ]\n\n    results = []\n    omega = 2.0 / 3.0\n\n    for case in test_cases:\n        N = case['N']\n        gamma = case['gamma']\n        nu_family = case['nu_family']\n        nu_params = case['nu_params']\n        K = case['K']\n\n        # 1. Setup grid hierarchy\n        L = int(np.log2(N + 1))\n        ns = [2**(L - l) - 1 for l in range(L)]\n        As = [create_operator_A(n) for n in ns]\n        nus = [calculate_nu(l, nu_family, nu_params) for l in range(L)]\n        \n        grid_params = (ns, As, nus, gamma, omega)\n\n        # 2. Initial state\n        u = np.zeros(N)\n        f = np.ones(N)\n\n        # 3. Calculate initial residual norm\n        r0_norm = np.linalg.norm(f) # Since u is zero, initial residual is f\n\n        # 4. Run K multigrid cycles\n        u_k = u\n        for _ in range(K):\n            u_k = mg_cycle(0, u_k, f, grid_params)\n\n        # 5. Calculate final residual norm and convergence factor\n        rK_norm = np.linalg.norm(f - As[0] @ u_k)\n        \n        if r0_norm == 0:\n             rho_obs = 0.0 if rK_norm == 0 else float('inf')\n        else:\n             rho_obs = (rK_norm / r0_norm)**(1.0 / K)\n        \n        results.append(f\"{rho_obs:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}