{
    "hands_on_practices": [
        {
            "introduction": "In computational engineering, a subtle error in notation can lead to code that produces physically plausible but incorrect results. This exercise puts you in the role of a \"debugger,\" tasking you with identifying a common but critical mistake in applying the deformation gradient tensor $F_{iJ}$. By applying the first principles of kinematic transformation with strict adherence to index conventions, you will uncover the error and compute the correct physical quantity, reinforcing that proper notation is essential for valid simulation.",
            "id": "2442467",
            "problem": "In a planar deformation of a continuous body, the deformation gradient tensor $F_{iJ}$ is measured at a material point and represented in the orthonormal bases of the spatial and material configurations by the matrix\n$$\nF_{iJ}=\\begin{pmatrix}\n1.15 & 0.40\\\\\n-0.25 & 0.95\n\\end{pmatrix}.\n$$\nA material fiber through the same point has the reference line element $dX_{J}=\\begin{pmatrix}2\\\\1\\end{pmatrix}$, which has length $|dX|=\\sqrt{2^{2}+1^{2}}$ and is expressed in millimeters. A postprocessing tool from a finite element analysis reports the current fiber length as $\\ell_{\\text{code}}=|d\\tilde{x}|$ where it computes $d\\tilde{x}_{J}=F_{iJ}\\,dX_{i}$, obtaining the numerical value $\\ell_{\\text{code}}=2.695\\,\\mathrm{mm}$ (rounded to four significant figures). This value appears physically plausible.\n\nDetermine the correct current length $\\ell$ of the fiber at this point by using index-consistent kinematic reasoning. Express your final answer in $\\mathrm{mm}$ and round to four significant figures. The final answer must be a single number.",
            "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Deformation gradient tensor: $F_{iJ}=\\begin{pmatrix} 1.15 & 0.40\\\\ -0.25 & 0.95 \\end{pmatrix}$\n- Reference line element: $dX_{J}=\\begin{pmatrix}2\\\\1\\end{pmatrix}$, in units of millimeters ($\\mathrm{mm}$).\n- Calculation by a postprocessing tool: $d\\tilde{x}_{J}=F_{iJ}\\,dX_{i}$.\n- Reported length from the tool: $\\ell_{\\text{code}}=|d\\tilde{x}|=2.695\\,\\mathrm{mm}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the principles of continuum mechanics, specifically the kinematics of deformation. It is well-posed, providing all necessary information to determine the correct length of a deformed material fiber. The core of the problem is to identify an error in the application of tensor notation. The expression $d\\tilde{x}_{J}=F_{iJ}\\,dX_{i}$ is kinematically incorrect, as it mismatches indices and implies a non-physical operation. However, the problem statement itself is not flawed; it presents this incorrect calculation as a premise to be critiqued. The numerical values are physically plausible, with $\\det(F) = (1.15)(0.95) - (0.40)(-0.25) = 1.1925 > 0$, consistent with a physically admissible deformation. The problem is objective and free of ambiguity beyond the intentional error presented for correction.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be provided.\n\nThe fundamental principle governing the deformation of an infinitesimal material line element $d\\mathbf{X}$ into a spatial line element $d\\mathbf{x}$ is given by the action of the deformation gradient tensor $\\mathbf{F}$. In index notation, using the standard convention where uppercase indices (e.g., $J$) refer to the material (reference) configuration and lowercase indices (e.g., $i$) refer to the spatial (current) configuration, this relationship is expressed as:\n$$dx_i = F_{iJ} dX_J$$\nHere, the repeated index $J$ on the right-hand side implies summation over the dimensions of the material space (in this case, from $1$ to $2$). This operation is a linear transformation that maps a vector from the material frame to the spatial frame, known as a push-forward operation.\n\nThe problem states that a postprocessing tool computes the deformed vector using the formula $d\\tilde{x}_{J}=F_{iJ}\\,dX_{i}$. This expression is fundamentally incorrect from the standpoint of tensor analysis and continuum mechanics.\n$1$. The material line element is $dX_J$, so its components should be indexed by $J$, not $i$. The expression uses $dX_i$.\n$2$. The summation is over the index $i$, which is a spatial index. The contraction should be between the material index of $F_{iJ}$ and the material index of $dX_J$.\n$3$. The resulting vector is denoted $d\\tilde{x}_{J}$, using a material index $J$. The deformed vector exists in the spatial configuration and must therefore carry a spatial index, such as $i$.\n\nThe operation performed by the code, $d\\tilde{x}_{J}=F_{iJ}\\,dX_{i}$, corresponds to the matrix operation $d\\tilde{\\mathbf{x}} = \\mathbf{F}^T d\\mathbf{X}$, where $\\mathbf{F}^T$ is the transpose of the deformation gradient. This is not the correct kinematic transformation for a material line element. The fact that the computed length $\\ell_{\\text{code}}=2.695\\,\\mathrm{mm}$ appears \"physically plausible\" is irrelevant to the mathematical and physical correctness of the underlying formula.\n\nWe now proceed with the correct calculation. The given quantities are:\n$$F_{iJ} = \\begin{pmatrix} 1.15 & 0.40 \\\\ -0.25 & 0.95 \\end{pmatrix}$$\n$$dX_J = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$$\nThe components of the deformed spatial line element $dx_i$ are calculated by matrix-vector multiplication, $d\\mathbf{x} = \\mathbf{F} d\\mathbf{X}$:\n$$\ndx_i = \\begin{pmatrix} 1.15 & 0.40 \\\\ -0.25 & 0.95 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}\n= \\begin{pmatrix} (1.15)(2) + (0.40)(1) \\\\ (-0.25)(2) + (0.95)(1) \\end{pmatrix}\n= \\begin{pmatrix} 2.3 + 0.4 \\\\ -0.5 + 0.95 \\end{pmatrix}\n= \\begin{pmatrix} 2.7 \\\\ 0.45 \\end{pmatrix}\n$$\nSo, the components of the deformed vector in the spatial basis are $dx_1 = 2.7$ and $dx_2 = 0.45$.\n\nThe correct current length of the fiber, $\\ell$, is the Euclidean norm (magnitude) of the vector $dx_i$:\n$$\\ell = |d\\mathbf{x}| = \\sqrt{(dx_1)^2 + (dx_2)^2}$$\nSubstituting the calculated components:\n$$\\ell = \\sqrt{(2.7)^2 + (0.45)^2} = \\sqrt{7.29 + 0.2025} = \\sqrt{7.4925}$$\nThe numerical value is:\n$$\\ell \\approx 2.7372431... \\, \\mathrm{mm}$$\nRounding to four significant figures as required:\n$$\\ell \\approx 2.737 \\, \\mathrm{mm}$$\nThis is the correct current length of the material fiber.",
            "answer": "$$\\boxed{2.737}$$"
        },
        {
            "introduction": "Many fundamental engineering analyses, from stress analysis to fluid dynamics, rely on decomposing tensors into more elementary parts like their symmetric, anti-symmetric, and isotropic components. This practice guides you through translating these formal index-notation definitions into a working computational algorithm. Completing this exercise will solidify your ability to bridge the gap between abstract mathematical theory and its practical implementation in engineering software.",
            "id": "2442512",
            "problem": "You are given an arbitrary real, square, second-order tensor $T_{ij}$ in a finite-dimensional Euclidean space with dimension $n \\in \\{2,3\\}$. Using the standard index conventions from tensor analysis in computational engineering, implement a program that, for each given $T_{ij}$, computes its decomposition into three parts: a symmetric part $S_{ij}$, an anti-symmetric part $A_{ij}$, and an isotropic (spherical) part $J_{ij}$. The decomposition must be derived from first principles using the following conceptual bases only: the definition of transposition of indices, the Kronecker delta $\\delta_{ij}$ as the identity tensor, the trace $\\mathrm{tr}(T) = T_{ii}$, and the Einstein summation convention (ESC). The isotropic part must be a tensor proportional to $\\delta_{ij}$. Your implementation must also verify that the deviatoric symmetric part $D_{ij}$ defined by $D_{ij} = S_{ij} - J_{ij}$ is traceless, and that the reconstruction $T_{ij} = D_{ij} + A_{ij} + J_{ij}$ holds numerically.\n\nYour program must:\n- Derive and implement the operations to compute $S_{ij}$, $A_{ij}$, and $J_{ij}$ from $T_{ij}$ using the definitions listed above. You must not rely on any unproven shortcuts.\n- For each input tensor $T_{ij}$, compute $S_{ij}$, $A_{ij}$, and $J_{ij}$, and then verify: \n  1. The isotropy of $J_{ij}$ as being proportional to $\\delta_{ij}$.\n  2. The tracelessness of $D_{ij} = S_{ij} - J_{ij}$ via $D_{ii} = 0$.\n  3. The exact reconstruction $T_{ij} = D_{ij} + A_{ij} + J_{ij}$ up to floating-point tolerance.\n- Adopt row-major (C-order) when flattening matrices for output aggregation.\n\nTest Suite:\nUse the following fixed test suite of inputs. Each $T_{ij}$ is given as a matrix for $n = 3$ or $n = 2$.\n- Case $1$ ($n = 3$): \n  $$\n  T^{(1)} = \\begin{bmatrix}\n  2 & -1 & 4 \\\\\n  3 & 0 & 5 \\\\\n  7 & -2 & 1\n  \\end{bmatrix}\n  $$\n- Case $2$ ($n = 3$): \n  $$\n  T^{(2)} = \\begin{bmatrix}\n  4 & 1 & -2 \\\\\n  1 & -3 & 0 \\\\\n  -2 & 0 & 5\n  \\end{bmatrix}\n  $$\n- Case $3$ ($n = 3$): \n  $$\n  T^{(3)} = \\begin{bmatrix}\n  0 & 2 & -1 \\\\\n  -2 & 0 & 3 \\\\\n  1 & -3 & 0\n  \\end{bmatrix}\n  $$\n- Case $4$ ($n = 2$): \n  $$\n  T^{(4)} = \\begin{bmatrix}\n  5 & -7 \\\\\n  9 & -1\n  \\end{bmatrix}\n  $$\n\nOutput specification:\n- For each case $k \\in \\{1,2,3,4\\}$, construct a single list by concatenating:\n  1. The entries of $S^{(k)}_{ij}$ flattened in row-major order, rounded to $6$ decimal places.\n  2. The entries of $A^{(k)}_{ij}$ flattened in row-major order, rounded to $6$ decimal places.\n  3. The entries of $J^{(k)}_{ij}$ flattened in row-major order, rounded to $6$ decimal places.\n  4. The scalar maximum absolute reconstruction error $\\max_{i,j} | T^{(k)}_{ij} - (S^{(k)}_{ij} - J^{(k)}_{ij} + A^{(k)}_{ij} + J^{(k)}_{ij}) |$, rounded to $12$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list of the four lists for the four cases, enclosed in square brackets (for example, a list of lists like $[ \\ldots ]$). No units are involved in this problem. Angles are not used.\n\nYour implementation must be fully deterministic, use the provided test suite exactly as stated, and must not require any user input. The final printed data types must be purely numeric (booleans, integers, or floats) or lists of these, as specified above. The floating-point rounding rules stated above must be applied to the components included in the output.",
            "solution": "The problem as stated is valid. It is scientifically grounded, well-posed, objective, and contains all necessary information for a unique and meaningful solution. The concepts of tensor decomposition into symmetric, anti-symmetric, and isotropic parts are fundamental in continuum mechanics and computational engineering. We will proceed to derive the solution from first principles, as is proper.\n\nAn arbitrary second-order tensor $T_{ij}$ in an $n$-dimensional space can be uniquely decomposed into its symmetric part $S_{ij}$ and its anti-symmetric (or skew-symmetric) part $A_{ij}$. The decomposition is additive:\n$$T_{ij} = S_{ij} + A_{ij}$$\nBy definition, a symmetric tensor does not change under transposition of its indices, $S_{ij} = S_{ji}$. An anti-symmetric tensor negates, $A_{ij} = -A_{ji}$.\n\nTo find the explicit forms for $S_{ij}$ and $A_{ij}$, we consider the transpose of $T_{ij}$:\n$$T_{ji} = S_{ji} + A_{ji}$$\nUsing the definitive properties of $S_{ij}$ and $A_{ij}$, this becomes:\n$$T_{ji} = S_{ij} - A_{ij}$$\nWe now possess a system of two linear equations for the two unknown tensors $S_{ij}$ and $A_{ij}$:\n$$(1) \\quad T_{ij} = S_{ij} + A_{ij}$$\n$$(2) \\quad T_{ji} = S_{ij} - A_{ij}$$\nAdding equation $(1)$ and $(2)$ yields:\n$$T_{ij} + T_{ji} = (S_{ij} + A_{ij}) + (S_{ij} - A_{ij}) = 2S_{ij}$$\nFrom which we isolate the symmetric part:\n$$S_{ij} = \\frac{1}{2}(T_{ij} + T_{ji})$$\nSubtracting equation $(2)$ from $(1)$ yields:\n$$T_{ij} - T_{ji} = (S_{ij} + A_{ij}) - (S_{ij} - A_{ij}) = 2A_{ij}$$\nFrom which we isolate the anti-symmetric part:\n$$A_{ij} = \\frac{1}{2}(T_{ij} - T_{ji})$$\nThis completes the first stage of decomposition. Note that the trace of the anti-symmetric part is necessarily zero: $A_{ii} = \\frac{1}{2}(T_{ii} - T_{ii}) = 0$. Consequently, the trace of the tensor $T_{ij}$ is identical to the trace of its symmetric part: $\\mathrm{tr}(T) = T_{ii} = S_{ii}$.\n\nThe second stage of decomposition separates the symmetric tensor $S_{ij}$ into an isotropic (or spherical) part $J_{ij}$ and a deviatoric part $D_{ij}$. This decomposition is also additive:\n$$S_{ij} = J_{ij} + D_{ij}$$\nThe isotropic part $J_{ij}$ is, by definition, a tensor proportional to the identity tensor, which in index notation is the Kronecker delta, $\\delta_{ij}$. Thus, we can write:\n$$J_{ij} = \\alpha \\delta_{ij}$$\nwhere $\\alpha$ is a scalar coefficient to be determined. The deviatoric part $D_{ij}$ is defined as being traceless, meaning its trace is zero: $D_{ii} = 0$. Note that the Einstein summation convention is implied for repeated indices.\n\nTo find the scalar $\\alpha$, we take the trace of the decomposition $S_{ij} = J_{ij} + D_{ij}$:\n$$S_{ii} = (J_{ij} + D_{ij})_{ii} = J_{ii} + D_{ii}$$\nSince $D_{ii} = 0$ by definition, we have $S_{ii} = J_{ii}$. We now compute the trace of $J_{ij}$:\n$$J_{ii} = (\\alpha \\delta_{ij})_{ii} = \\alpha \\delta_{ii}$$\nThe trace of the Kronecker delta in an $n$-dimensional space is the sum of its diagonal elements, $\\delta_{ii} = \\sum_{i=1}^{n} \\delta_{ii} = \\sum_{i=1}^{n} 1 = n$.\nTherefore, $J_{ii} = \\alpha n$.\nEquating the traces, $S_{ii} = \\alpha n$, we find the scalar coefficient $\\alpha$:\n$$\\alpha = \\frac{S_{ii}}{n}$$\nAs we established that $S_{ii} = T_{ii} = \\mathrm{tr}(T)$, the expression for $\\alpha$ simplifies to $\\alpha = \\frac{1}{n}\\mathrm{tr}(T)$.\nSubstituting this back gives the formula for the isotropic tensor:\n$$J_{ij} = \\frac{1}{n} T_{kk} \\delta_{ij}$$\nHere, we use $k$ for the summation index to avoid conflict with the free indices $i$ and $j$.\n\nThe deviatoric part is then found by subtraction:\n$$D_{ij} = S_{ij} - J_{ij} = S_{ij} - \\frac{1}{n} T_{kk} \\delta_{ij}$$\nThe original problem requires verification of the total reconstruction $T_{ij} = D_{ij} + A_{ij} + J_{ij}$. By substituting the definitions of the components, we see this is algebraically exact:\n$$D_{ij} + A_{ij} + J_{ij} = (S_{ij} - J_{ij}) + A_{ij} + J_{ij} = S_{ij} + A_{ij} = T_{ij}$$\nThe implementation will numerically verify this identity up to floating-point precision for each given tensor.\n\nThe algorithm for the implementation is as follows:\nFor each input tensor $T_{ij}$ of dimension $n$:\n$1$. Compute the transpose $T_{ji}$.\n$2$. Compute the symmetric part: $S_{ij} = \\frac{1}{2}(T_{ij} + T_{ji})$.\n$3$. Compute the anti-symmetric part: $A_{ij} = \\frac{1}{2}(T_{ij} - T_{ji})$.\n$4$. Compute the trace of the original tensor: $T_{kk} = \\sum_{k=1}^{n} T_{kk}$.\n$5$. Construct the identity tensor $\\delta_{ij}$ for dimension $n$.\n$6$. Compute the isotropic part: $J_{ij} = \\left(\\frac{1}{n} T_{kk}\\right) \\delta_{ij}$.\n$7$. The problem asks for verification of the tracelessness of the deviatoric part $D_{ij} = S_{ij} - J_{ij}$. We can confirm this analytically. The trace is $D_{ii} = S_{ii} - J_{ii} = T_{kk} - (\\frac{1}{n} T_{ll} \\delta_{ij})_{ii} = T_{kk} - \\frac{1}{n} T_{ll} \\delta_{ii} = T_{kk} - \\frac{1}{n} T_{ll} (n) = T_{kk} - T_{ll} = 0$. The implementation will confirm this numerically.\n$8$. Reconstruct the tensor: $T'_{ij} = (S_{ij} - J_{ij}) + A_{ij} + J_{ij} = S_{ij} + A_{ij}$.\n$9$. Calculate the maximum absolute reconstruction error: $\\epsilon = \\max_{i,j} |T_{ij} - T'_{ij}|$.\n$10$. Collate the flattened components $S_{ij}$, $A_{ij}$, $J_{ij}$ and the error $\\epsilon$ into the specified output format, respecting the rounding rules.\nThis procedure will be applied to all test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the tensor decomposition problem for a fixed test suite.\n    The function adheres to the strict output specification.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        np.array([[2, -1, 4], [3, 0, 5], [7, -2, 1]], dtype=float),\n        np.array([[4, 1, -2], [1, -3, 0], [-2, 0, 5]], dtype=float),\n        np.array([[0, 2, -1], [-2, 0, 3], [1, -3, 0]], dtype=float),\n        np.array([[5, -7], [9, -1]], dtype=float),\n    ]\n\n    all_results = []\n    \n    for T in test_cases:\n        # Get the dimension of the space\n        n = T.shape[0]\n\n        # 1. Derive Symmetric (S_ij) and Anti-symmetric (A_ij) parts\n        # S_ij = 1/2 * (T_ij + T_ji)\n        S = 0.5 * (T + T.T)\n        \n        # A_ij = 1/2 * (T_ij - T_ji)\n        A = 0.5 * (T - T.T)\n\n        # 2. Decompose Symmetric part S_ij into Isotropic (J_ij) and Deviatoric (D_ij) parts\n        # The isotropic part J_ij is proportional to the identity tensor (Kronecker delta).\n        # J_ij = alpha * delta_ij\n        # The deviatoric part D_ij is traceless: D_ii = 0.\n        # S_ij = J_ij + D_ij\n        # Taking the trace: S_ii = J_ii + D_ii = J_ii\n        # Trace of J_ij is J_ii = alpha * delta_ii = alpha * n\n        # Trace of S_ij is S_ii = tr(S) = tr(T)\n        # So, tr(T) = alpha * n  =>  alpha = tr(T) / n\n        tr_T = np.trace(T)\n        \n        # J_ij = (1/n) * tr(T) * delta_ij\n        J = (tr_T / n) * np.identity(n)\n\n        # D_ij = S_ij - J_ij\n        D = S - J\n        \n        # 3. Verification steps as required by the problem\n        # The problem requires verifying that D is traceless and that reconstruction holds.\n        # Tracelessness of D:\n        tr_D = np.trace(D)\n        # This should be zero up to floating point error. We assert this internally.\n        assert np.isclose(tr_D, 0.0), f\"Deviatoric part is not traceless: trace is {tr_D}\"\n\n        # Reconstruction: T_ij = D_ij + A_ij + J_ij\n        # This simplifies to T_ij = (S_ij - J_ij) + A_ij + J_ij = S_ij + A_ij\n        T_reconstructed = D + A + J\n        \n        # Calculate maximum absolute reconstruction error\n        max_reconstruction_error = np.max(np.abs(T - T_reconstructed))\n\n        # 4. Prepare output per specification\n        # Flattened components with rounding to 6 decimal places\n        s_flat = np.round(S.flatten(), 6).tolist()\n        a_flat = np.round(A.flatten(), 6).tolist()\n        j_flat = np.round(J.flatten(), 6).tolist()\n        \n        # Reconstruction error rounded to 12 decimal places\n        error_rounded = round(max_reconstruction_error, 12)\n\n        # Concatenate into a single list for the current case\n        case_result = s_flat + a_flat + j_flat + [error_rounded]\n        all_results.append(case_result)\n\n    # Final print statement in the exact required format.\n    # Produces a string representation of a list of lists: \"[[...],[...],...]\"\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Tensor notation is more than a compact way to write equations; it is a powerful engine for analytical derivation. This problem challenges you to use the formal definitions of the Kronecker delta $\\delta_{ij}$ and the Levi-Civita symbol $\\epsilon_{ijk}$ to derive the characteristic equation for a second-order tensor from the ground up. This practice moves beyond simple substitution to showcase how index manipulation can reveal fundamental mathematical structures, such as the eigenvalues that describe a tensor's principal properties.",
            "id": "2442529",
            "problem": "In computational engineering, symmetric second-order tensors arise in constitutive modeling and numerical discretizations. Consider a real, symmetric, second-order tensor $T_{ij}$ represented in an orthonormal basis. Using Einstein summation convention, an eigenpair $\\left(\\lambda, v_{i}\\right)$ satisfies the definition $T_{ij} v_{j} = \\lambda v_{i}$, where $\\lambda$ is a scalar and $v_{i}$ is a nonzero vector. The characteristic equation that determines admissible $\\lambda$ is defined by the determinant condition $\\det\\!\\left(T_{ij} - \\lambda \\delta_{ij}\\right) = 0$, where $\\delta_{ij}$ is the Kronecker delta.\n\nYou are given the specific symmetric, dimensionless tensor with components\n$T_{11} = 4$, $T_{12} = T_{21} = 1$, $T_{13} = T_{31} = 2$, $T_{22} = 3$, $T_{23} = T_{32} = 0$, $T_{33} = 5$.\nStarting strictly from the fundamental definitions of eigenvalues in index notation and the determinant expressed via the Levi–Civita symbol $\\epsilon_{ijk}$ and the Kronecker delta $\\delta_{ij}$, formulate the eigenvalue problem and derive the characteristic polynomial $p(\\lambda) = \\det\\!\\left(T_{ij} - \\lambda \\delta_{ij}\\right)$ explicitly. Express your final result as a single simplified polynomial in $\\lambda$. No rounding is required and no physical units are involved.",
            "solution": "The eigenvalue problem for a second-order tensor $T_{ij}$ in index notation is defined by the equation $T_{ij} v_{j} = \\lambda v_{i}$, where repeated indices imply summation (Einstein summation convention), $\\lambda$ is a scalar eigenvalue, and $v_{i}$ is a nonzero eigenvector. Nontrivial solutions for $v_{i}$ exist if and only if the determinant condition holds:\n\n$$\n\\det\\!\\left(T_{ij} - \\lambda \\delta_{ij}\\right) = 0.\n$$\n\nTo express the determinant in index notation from first principles, we use the Levi–Civita symbol $\\epsilon_{ijk}$ and the Kronecker delta $\\delta_{ij}$. For any $3 \\times 3$ array $A_{ij}$, the determinant is\n\n$$\n\\det(A) = \\frac{1}{3!}\\,\\epsilon_{ijk}\\,\\epsilon_{pqr}\\,A_{ip}\\,A_{jq}\\,A_{kr}.\n$$\n\nSetting $A_{ij} = T_{ij} - \\lambda \\delta_{ij}$ produces the characteristic polynomial:\n\n$$\np(\\lambda) = \\det\\!\\left(T_{ij} - \\lambda \\delta_{ij}\\right) = \\frac{1}{3!}\\,\\epsilon_{ijk}\\,\\epsilon_{pqr}\\,\\left(T_{ip} - \\lambda \\delta_{ip}\\right)\\left(T_{jq} - \\lambda \\delta_{jq}\\right)\\left(T_{kr} - \\lambda \\delta_{kr}\\right).\n$$\n\nTo evaluate this contraction, we use the identity\n\n$$\n\\epsilon_{ijk}\\,\\epsilon_{pqr} = \\delta_{ip}\\delta_{jq}\\delta_{kr} + \\delta_{iq}\\delta_{jr}\\delta_{kp} + \\delta_{ir}\\delta_{jp}\\delta_{kq} - \\delta_{ip}\\delta_{jr}\\delta_{kq} - \\delta_{iq}\\delta_{jp}\\delta_{kr} - \\delta_{ir}\\delta_{jq}\\delta_{kp}.\n$$\n\nCarrying out the contraction and grouping terms yields the standard expansion for a $3 \\times 3$ determinant in index form:\n\n$$\n\\det(A) = A_{11}(A_{22}A_{33} - A_{23}A_{32}) - A_{12}(A_{21}A_{33} - A_{23}A_{31}) + A_{13}(A_{21}A_{32} - A_{22}A_{31}),\n$$\n\nwhere $A_{ij} = T_{ij} - \\lambda \\delta_{ij}$. For the given symmetric tensor, the components are\n\n$$\nT_{11} = 4,\\quad T_{12} = T_{21} = 1,\\quad T_{13} = T_{31} = 2,\\quad T_{22} = 3,\\quad T_{23} = T_{32} = 0,\\quad T_{33} = 5.\n$$\n\nDefine $A_{ij} = T_{ij} - \\lambda \\delta_{ij}$, so explicitly\n\n$$\nA_{11} = 4 - \\lambda,\\quad A_{12} = 1,\\quad A_{13} = 2,\\quad A_{21} = 1,\\quad A_{22} = 3 - \\lambda,\\quad A_{23} = 0,\\quad A_{31} = 2,\\quad A_{32} = 0,\\quad A_{33} = 5 - \\lambda.\n$$\n\nSubstitute into the determinant expression:\n\n$$\n\\begin{aligned}\np(\\lambda) &= A_{11}(A_{22}A_{33} - A_{23}A_{32}) - A_{12}(A_{21}A_{33} - A_{23}A_{31}) + A_{13}(A_{21}A_{32} - A_{22}A_{31}) \\\\\n&= (4 - \\lambda)\\big((3 - \\lambda)(5 - \\lambda) - 0 \\cdot 0\\big) - 1\\big(1 \\cdot (5 - \\lambda) - 0 \\cdot 2\\big) + 2\\big(1 \\cdot 0 - (3 - \\lambda)\\cdot 2\\big).\n\\end{aligned}\n$$\n\nSimplify each term:\n\n$$\n(3 - \\lambda)(5 - \\lambda) = 15 - 8\\lambda + \\lambda^{2},\n$$\n\nso\n\n$$\n(4 - \\lambda)(15 - 8\\lambda + \\lambda^{2}) = 60 - 47\\lambda + 12\\lambda^{2} - \\lambda^{3}.\n$$\n\nThe remaining contributions are\n\n$$\n- 1 \\cdot (5 - \\lambda) = -5 + \\lambda,\\qquad 2\\big(0 - 2(3 - \\lambda)\\big) = -12 + 4\\lambda.\n$$\n\nCollect terms:\n\n$$\np(\\lambda) = \\left(60 - 47\\lambda + 12\\lambda^{2} - \\lambda^{3}\\right) + \\left(-5 + \\lambda\\right) + \\left(-12 + 4\\lambda\\right) = -\\lambda^{3} + 12\\lambda^{2} - 42\\lambda + 43.\n$$\n\nThus, starting from the eigenvalue definition and the determinant expressed via Levi–Civita and Kronecker symbols, the characteristic polynomial for the given symmetric tensor is\n\n$$\np(\\lambda) = -\\lambda^{3} + 12\\lambda^{2} - 42\\lambda + 43.\n$$\n\nThis polynomial encapsulates the characteristic equation $\\det\\!\\left(T_{ij} - \\lambda \\delta_{ij}\\right) = 0$.",
            "answer": "$$\\boxed{-\\lambda^{3} + 12\\lambda^{2} - 42\\lambda + 43}$$"
        }
    ]
}