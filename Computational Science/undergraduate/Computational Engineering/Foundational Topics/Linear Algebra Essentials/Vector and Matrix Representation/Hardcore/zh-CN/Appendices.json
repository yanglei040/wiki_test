{
    "hands_on_practices": [
        {
            "introduction": "理论与实践的结合始于将现实世界的问题用数学语言来表述。这个练习将带领我们探索如何将一个常见的计算任务——图像处理中的颜色到灰度的转换——构建成一个线性代数问题。通过运用线性变换的原理，并遵循给定的物理和对称性约束，我们将从零开始推导出一个唯一的变换矩阵，这个过程能加深我们对线性变换、向量空间以及子空间（如零空间）物理意义的理解。",
            "id": "2449842",
            "problem": "在数字成像管道中，每个彩色像素都由三维实向量空间 $\\mathbb{R}^{3}$ 中的一个向量表示，其坐标 $(R,G,B)^{\\top}$ 对应于红、绿、蓝 (RGB)。设计一个由矩阵 $A \\in \\mathbb{R}^{3 \\times 3}$ 表示的线性变换，该变换将任意 RGB 向量 $x \\in \\mathbb{R}^{3}$ 映射到一个灰度向量 $y \\in \\mathbb{R}^{3}$，其中所有三个分量都相等并表示一个标量灰度强度。假设该变换必须满足以下物理和对称性约束：(i) 它是线性的，(ii) 它保持整个灰度轴不变，即对于任意标量 $k \\in \\mathbb{R}$，$A \\,(k \\,\\mathbf{1}) = k \\,\\mathbf{1}$，其中 $\\mathbf{1} = (1,1,1)^{\\top}$，以及 (iii) 在没有任何偏好通道的情况下，灰度强度在 RGB 通道的排列下是不变的。仅根据这些约束，确定唯一的矩阵 $A$。\n\n分析 $A$ 的零空间在 $\\mathbb{R}^{3}$ 中关于 RGB 颜色方向的几何意义。然后，计算 $A$ 的零空间的维度。将您的最终答案表示为等于零空间维度的单个数字。无需四舍五入，也无需单位。",
            "solution": "问题陈述需要经过验证。\n\n**第一步：提取已知条件**\n- 每个彩色像素是 $\\mathbb{R}^{3}$ 中的一个向量， $x = (R,G,B)^{\\top}$。\n- 变换是线性的，由一个矩阵 $A \\in \\mathbb{R}^{3 \\times 3}$ 表示。\n- 变换将一个 RGB 向量 $x$ 映射到一个灰度向量 $y \\in \\mathbb{R}^{3}$，其中 $y=(g,g,g)^{\\top}$，$g$ 是某个标量强度。\n- 约束 (i)：变换是线性的，$y = Ax$。\n- 约束 (ii)：变换保持整个灰度轴不变。对于任意标量 $k \\in \\mathbb{R}$，$A \\,(k \\,\\mathbf{1}) = k \\,\\mathbf{1}$，其中 $\\mathbf{1} = (1,1,1)^{\\top}$。\n- 约束 (iii)：灰度强度在 RGB 通道的排列下保持不变。\n\n**第二步：使用提取的已知条件进行验证**\n该问题具有科学依据，是适定的、客观的。这是一个线性代数应用于计算工程（色彩空间变换）的标准问题。所提供的约束在数学上是精确和一致的，从而可以推导出唯一的解。该问题不违反任何基本原理，不基于错误的前提，并且术语定义明确。\n\n**第三步：结论与行动**\n问题有效。现在将推导完整的解答。\n\n**变换矩阵 $A$ 的推导**\n\n设变换矩阵为 $A = \\begin{pmatrix} a_{11}  a_{12}  a_{13} \\\\ a_{21}  a_{22}  a_{23} \\\\ a_{31}  a_{32}  a_{33} \\end{pmatrix}$。\n输入向量为 $x = (R, G, B)^{\\top}$。输出向量为 $y = Ax$。\n问题陈述指出，输出 $y$ 必须是一个灰度向量，意味着其所有分量都相等。设这个公共值为 $g$。\n$$y = Ax = \\begin{pmatrix} a_{11}R + a_{12}G + a_{13}B \\\\ a_{21}R + a_{22}G + a_{23}B \\\\ a_{31}R + a_{32}G + a_{33}B \\end{pmatrix} = \\begin{pmatrix} g \\\\ g \\\\ g \\end{pmatrix}$$\n由于这对任意输入向量 $(R,G,B)^{\\top} \\in \\mathbb{R}^{3}$ 都必须成立，定义输出各分量的线性形式必须是相同的。这意味着矩阵 $A$ 的各行必须相同。设第一行为 $(c_1, c_2, c_3)$。那么矩阵 $A$ 必有如下形式：\n$$A = \\begin{pmatrix} c_1  c_2  c_3 \\\\ c_1  c_2  c_3 \\\\ c_1  c_2  c_3 \\end{pmatrix}$$\n标量灰度强度由 $g = c_1 R + c_2 G + c_3 B$ 给出。\n\n我们现在应用约束 (ii)：保持灰度轴不变。对于任意 $k \\in \\mathbb{R}$，灰度轴上的一个向量是 $k \\mathbf{1} = (k,k,k)^{\\top}$。\n$$A(k\\mathbf{1}) = \\begin{pmatrix} c_1  c_2  c_3 \\\\ c_1  c_2  c_3 \\\\ c_1  c_2  c_3 \\end{pmatrix} \\begin{pmatrix} k \\\\ k \\\\ k \\end{pmatrix} = \\begin{pmatrix} k(c_1+c_2+c_3) \\\\ k(c_1+c_2+c_3) \\\\ k(c_1+c_2+c_3) \\end{pmatrix}$$\n这个输出必须等于 $k\\mathbf{1} = (k,k,k)^{\\top}$。\n$$k(c_1+c_2+c_3) = k$$\n这个等式必须对所有 $k \\in \\mathbb{R}$ 成立。对于 $k \\neq 0$，我们可以两边同除以 $k$，得到条件：\n$$c_1 + c_2 + c_3 = 1$$\n\n接下来，我们应用约束 (iii)：灰度强度 $g$ 在 RGB 通道的排列下保持不变。强度为 $g(R,G,B) = c_1 R + c_2 G + c_3 B$。\n我们考虑前两个通道 $R$ 和 $G$ 的一个排列。强度必须保持不变。\n$$g(G,R,B) = c_1 G + c_2 R + c_3 B$$\n令 $g(R,G,B) = g(G,R,B)$：\n$$c_1 R + c_2 G + c_3 B = c_1 G + c_2 R + c_3 B$$\n$$(c_1 - c_2)R + (c_2 - c_1)G = 0$$\n$$(c_1 - c_2)(R - G) = 0$$\n这必须对所有 $R,G \\in \\mathbb{R}$ 成立。我们可以选择 $R \\neq G$，这就迫使 $c_1 - c_2 = 0$，所以 $c_1 = c_2$。\n类似地，考虑第二和第三通道 $G$ 和 $B$ 的一个排列：\n$$g(R,B,G) = c_1 R + c_2 B + c_3 G$$\n令 $g(R,G,B) = g(R,B,G)$：\n$$c_1 R + c_2 G + c_3 B = c_1 R + c_2 B + c_3 G$$\n$$(c_2 - c_3)G + (c_3 - c_2)B = 0$$\n$$(c_2 - c_3)(G - B) = 0$$\n这必须对所有 $G,B \\in \\mathbb{R}$ 成立。我们可以选择 $G \\neq B$，这就迫使 $c_2 - c_3 = 0$，所以 $c_2 = c_3$。\n结合这些结果，我们发现所有三个系数必须相等：$c_1 = c_2 = c_3$。我们称这个公共值为 $c$。\n\n现在，我们将此结果与约束 (ii) 的条件结合起来：\n$$c_1 + c_2 + c_3 = c + c + c = 3c = 1$$\n这得出 $c = \\frac{1}{3}$。\n因此，满足所有约束的唯一矩阵 $A$ 是：\n$$A = \\begin{pmatrix} \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\\\ \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\\\ \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\end{pmatrix}$$\n\n**零空间的分析与维度**\n\n$A$ 的零空间，记作 $\\text{Null}(A)$，是所有向量 $x = (R,G,B)^{\\top} \\in \\mathbb{R}^{3}$ 的集合，满足 $Ax = \\mathbf{0}$。\n$$Ax = \\begin{pmatrix} \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\\\ \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\\\ \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} R \\\\ G \\\\ B \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$$\n这个矩阵方程简化为单个线性方程：\n$$\\frac{1}{3}(R+G+B) = 0$$\n或者等价地，\n$$R+G+B=0$$\n几何上，这个方程在三维空间 $\\mathbb{R}^{3}$ 中定义了一个平面。这个平面穿过原点 $(0,0,0)^{\\top}$，其法向量为 $\\mathbf{n} = (1,1,1)^{\\top}$，也就是灰度轴的方向。在色彩科学的背景下，变换 $A$ 将任意颜色向量投影到灰度轴上。所得到的灰度的强度是 $R$、$G$ 和 $B$分量的平均值。零空间由所有被映射为黑色（零强度）的颜色向量组成，这些向量的分量之和为零。这些向量代表纯色度信息，与亮度（灰度）轴正交。\n\n为了求零空间的维度，我们可以应用秩-零度定理，该定理指出，对于一个有 $n$ 列的矩阵 $A$，$\\text{rank}(A) + \\text{dim}(\\text{Null}(A)) = n$。\n在我们的例子中，$A$ 是一个 $3 \\times 3$ 的矩阵，所以 $n = 3$。$A$ 的各行都相同且非零，所以它们是线性相关的。行空间由单个向量 $(\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3})$ 张成，所以 $A$ 的秩为 1。\n$$\\text{rank}(A) = 1$$\n应用秩-零度定理：\n$$1 + \\text{dim}(\\text{Null}(A)) = 3$$\n解出零空间的维度：\n$$\\text{dim}(\\text{Null}(A)) = 3 - 1 = 2$$\n这个结果与零空间的几何解释一致，即 $\\mathbb{R}^{3}$ 中穿过原点的一个平面，这是一个二维子空间。\n$A$ 的零空间的维度是 $2$。",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "在计算工程的许多领域，尤其是结构力学和热传导分析中，复杂物理系统通常被离散化为形如 $K\\mathbf{u} = \\mathbf{f}$ 的线性方程组。其中，$K$ 是描述系统内在物理属性的刚度矩阵，$\\mathbf{u}$ 是待求解的响应（如位移），而 $\\mathbf{f}$ 是外部激励（如载荷）。本练习模拟了这一核心任务，要求我们为一个给定的刚度矩阵求解在多种不同载荷下的位移响应，这不仅是求解一个方程组，更是对高效解决多场景工程问题的计算思维的训练。",
            "id": "2449826",
            "problem": "给定一个线性系统，它代表一维杆的有限元离散化，由一个对称三对角刚度矩阵表示。设刚度矩阵 $K \\in \\mathbb{R}^{5 \\times 5}$ 和载荷向量 $\\mathbf{f}^{(k)} \\in \\mathbb{R}^{5}$ 定义如下：\n$$\nK = \\begin{bmatrix}\n2  -1  0  0  0 \\\\\n-1  2  -1  0  0 \\\\\n0  -1  2  -1  0 \\\\\n0  0  -1  2  -1 \\\\\n0  0  0  -1  2\n\\end{bmatrix},\n$$\n载荷向量的测试集为\n$$\n\\mathbf{f}^{(1)} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix},\\quad\n\\mathbf{f}^{(2)} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix},\\quad\n\\mathbf{f}^{(3)} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\\\ 5 \\end{bmatrix},\\quad\n\\mathbf{f}^{(4)} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}.\n$$\n对于每个载荷向量 $\\mathbf{f}^{(k)}$，计算满足线性系统\n$$\nK \\,\\mathbf{u}^{(k)} = \\mathbf{f}^{(k)}.\n$$\n的位移向量 $\\mathbf{u}^{(k)} \\in \\mathbb{R}^{5}$。\n所有计算都是纯数值且无量纲的；不需要物理单位。不涉及角度。任何输出中不得出现百分比。\n\n您的程序必须处理所提供的测试集，并在单行中生成四个位移向量的列表 $\\left[\\mathbf{u}^{(1)}, \\mathbf{u}^{(2)}, \\mathbf{u}^{(3)}, \\mathbf{u}^{(4)}\\right]$，其中每个向量表示为一个包含5个浮点数的列表，每个浮点数四舍五入到6位小数。最终输出格式必须是严格的单行形式\n$$\n\\big[\\,[u^{(1)}_1,\\dots,u^{(1)}_5],[u^{(2)}_1,\\dots,u^{(2)}_5],[u^{(3)}_1,\\dots,u^{(3)}_5],[u^{(4)}_1,\\dots,u^{(4)}_5]\\,\\big],\n$$\n所有条目和子列表之间用逗号分隔，前后无任何多余文本。\n\n覆盖性设计：\n- 一般情况：$\\mathbf{f}^{(3)}$ 是一个非平凡的密集载荷。\n- 边界条件行为：$\\mathbf{f}^{(2)}$ 是零载荷。\n- 边缘局部载荷：$\\mathbf{f}^{(1)}$ 仅在边界自由度上加载。\n- 内部局部载荷：$\\mathbf{f}^{(4)}$ 仅在中心自由度上加载。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如 $[\\text{result}_1,\\text{result}_2,\\text{result}_3]$），在此问题中，结果是上述精确嵌套列表结构的四个位移向量。",
            "solution": "所给问题是计算工程中的一个标准练习，具体涉及求解形如 $K \\mathbf{u} = \\mathbf{f}$ 的线性代数方程组。在此，$K$ 代表离散化的一维力学系统的刚度矩阵，$\\mathbf{f}$ 是外部载荷向量，$\\mathbf{u}$ 是产生的位移向量。\n\n在进行求解之前，我们必须首先验证问题的适定性。对于任意给定的 $\\mathbf{f}$，存在唯一解 $\\mathbf{u}$ 的充要条件是矩阵 $K$ 非奇异，即其行列式不为零 ($\\det(K) \\neq 0$)。给定的刚度矩阵为：\n$$\nK = \\begin{bmatrix}\n2  -1  0  0  0 \\\\\n-1  2  -1  0  0 \\\\\n0  -1  2  -1  0 \\\\\n0  0  -1  2  -1 \\\\\n0  0  0  -1  2\n\\end{bmatrix}\n$$\n这是一个对称、三对角、托普利茨 (Toeplitz) 矩阵。这类矩阵常出现在一维负拉普拉斯算子 $-\\frac{d^2}{dx^2}$ 在特定边界条件下的有限差分或有限元离散化中。\n\n$K$ 的可逆性可以通过检查其特征值来确定。对于一个 $n \\times n$ 的这种形式的矩阵，其特征值 $\\lambda_j$ 由以下解析公式给出：\n$$\n\\lambda_j = 2 - 2 \\cos\\left(\\frac{j\\pi}{n+1}\\right), \\quad \\text{for } j = 1, 2, \\dots, n\n$$\n在我们的例子中，$n=5$。对于 $j \\in \\{1, 2, 3, 4, 5\\}$，余弦函数的所有参数 $\\frac{j\\pi}{6}$ 都严格位于区间 $(0, \\pi)$ 内，其中 $\\cos(x)  1$。因此，所有特征值 $\\lambda_j = 2(1 - \\cos(\\frac{j\\pi}{6}))$ 都是严格为正的。一个所有特征值都为正的矩阵是正定矩阵，而正定矩阵总是可逆的。行列式是特征值的乘积，因此也为正。具体来说，$\\det(K) = n+1 = 6$。\n\n由于 $K$ 是可逆的，该问题是适定的。对于每个载荷向量 $\\mathbf{f}^{(k)}$，存在一个唯一的位移向量 $\\mathbf{u}^{(k)}$，由以下形式解给出：\n$$\n\\mathbf{u}^{(k)} = K^{-1} \\mathbf{f}^{(k)}\n$$\n任务是为以下四个测试用例计算该解：\n$$\n\\mathbf{f}^{(1)} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix},\\quad\n\\mathbf{f}^{(2)} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix},\\quad\n\\mathbf{f}^{(3)} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\\\ 5 \\end{bmatrix},\\quad\n\\mathbf{f}^{(4)} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}\n$$\n在数值上，直接求解线性系统比显式计算逆矩阵 $K^{-1}$ 更高效、更稳定。为此，可采用标准的数值方法，如LU分解后进行前向和后向代换。实现将使用标准数值库提供的鲁棒线性求解器。\n\n步骤如下：\n1.  定义矩阵 $K$ 和载荷向量集 $\\mathbf{f}^{(k)}$。\n2.  遍历每个载荷向量 $\\mathbf{f}^{(k)}$。\n3.  对于每个 $\\mathbf{f}^{(k)}$，求解系统 $K \\mathbf{u}^{(k)} = \\mathbf{f}^{(k)}$ 以找到 $\\mathbf{u}^{(k)}$。\n4.  收集结果向量 $\\mathbf{u}^{(k)}$ 并根据输出规范进行格式化，将每个分量四舍五入到6位小数。\n\n$\\mathbf{f}^{(2)} = \\mathbf{0}$ 的情况是平凡的：由于 $K$ 是可逆的， $K \\mathbf{u} = \\mathbf{0}$ 的唯一解是零向量 $\\mathbf{u}^{(2)} = \\mathbf{0}$。其他情况代表了不同的载荷分布，并将产生非平凡的位移向量。该问题是有效的，现在可以通过算法求解。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a set of linear systems Ku=f for a given stiffness matrix K\n    and multiple load vectors f.\n    \"\"\"\n    # Define the symmetric tridiagonal stiffness matrix K.\n    K = np.array([\n        [2.0, -1.0,  0.0,  0.0,  0.0],\n        [-1.0, 2.0, -1.0,  0.0,  0.0],\n        [ 0.0, -1.0, 2.0, -1.0,  0.0],\n        [ 0.0,  0.0, -1.0, 2.0, -1.0],\n        [ 0.0,  0.0,  0.0, -1.0, 2.0]\n    ])\n\n    # Define the test suite of load vectors f^(k).\n    test_cases = [\n        np.array([1.0, 0.0, 0.0, 0.0, 1.0]),  # f^(1)\n        np.array([0.0, 0.0, 0.0, 0.0, 0.0]),  # f^(2)\n        np.array([1.0, 2.0, 3.0, 4.0, 5.0]),  # f^(3)\n        np.array([0.0, 0.0, 1.0, 0.0, 0.0])   # f^(4)\n    ]\n\n    results = []\n    # Iterate through each load vector and solve the linear system.\n    for f_vector in test_cases:\n        # Use numpy's high-performance linear algebra solver.\n        u_vector = np.linalg.solve(K, f_vector)\n        results.append(u_vector)\n\n    # Format the results according to the problem specification.\n    # Each float is rounded to 6 decimal places.\n    # The final output must be a single-line string representation of a list of lists.\n    rounded_results_as_lists = [np.round(u, 6).tolist() for u in results]\n\n    # Manually construct the string to ensure no spaces and exact comma separation.\n    inner_strings = []\n    for res_list in rounded_results_as_lists:\n        # Format numbers to avoid trailing zeros where not needed, like `1.0` not `1.000000`\n        # `map(str, ...)` handles this correctly.\n        inner_strings.append(f\"[{','.join(map(str, res_list))}]\")\n    \n    final_output_string = f\"[{','.join(inner_strings)}]\"\n    \n    # Print the final result in the exact required format.\n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "矩阵不仅可以用来描述和求解线性系统，其本身的光谱特性（即特征值和特征向量）也蕴含着深刻的结构信息。本练习将我们带入数据科学的前沿，探索一种强大的无监督学习技术——谱聚类。我们将学习如何将数据点间的关系编码为一个图拉普拉斯矩阵，然后通过分析该矩阵的特征向量来发现数据中可能存在的非凸或复杂的簇结构，这充分展示了矩阵表示在现代计算工程中作为分析工具的强大能力。",
            "id": "2449819",
            "problem": "给定欧几里得空间中的有限点集。对于每个点集，您必须构建一个全连接的加权无向图，其顶点对应于这些点，其边权重由具有指定正尺度参数的高斯核定义。使用对称归一化图拉普拉斯算子，您必须从与最小特征值相关联的特征向量中获得一个低维表示，然后通过在该表示中最小化簇内平方欧几里得目标，将点集划分为指定数量的簇。您的程序必须计算每个测试用例的最终簇标签，并按照本说明末尾指定的格式在单行上输出所有结果。\n\n数学规范：\n\n- 设 $X = \\{x_1, x_2, \\dots, x_n\\}$ 为一个点集，其中 $x_i \\in \\mathbb{R}^d$，并有一个尺度参数 $\\tau \\in \\mathbb{R}_{0}$。定义相似度矩阵 $S \\in \\mathbb{R}^{n \\times n}$ 如下：\n  $$ S_{ij} = \\begin{cases}\n  \\exp\\!\\left(-\\dfrac{\\|x_i - x_j\\|_2^2}{2 \\tau^2}\\right),  i \\neq j,\\\\\n  0,  i = j.\n  \\end{cases} $$\n- 定义度矩阵 $D \\in \\mathbb{R}^{n \\times n}$，其中 $D_{ii} = \\sum_{j=1}^n S_{ij}$ 且当 $i \\neq j$ 时 $D_{ij} = 0$。\n- 定义对称归一化拉普拉斯算子 $L_{\\mathrm{sym}} \\in \\mathbb{R}^{n \\times n}$ 如下：\n  $$ L_{\\mathrm{sym}} = I_n - D^{-1/2} S D^{-1/2}, $$\n  其中 $I_n$ 是 $n \\times n$ 的单位矩阵，$D^{-1/2}$ 表示一个对角矩阵，其对角线元素为 $D_{ii}^{-1/2}$（如果 $D_{ii}  0$）或 $0$（否则）。\n- 设 $k \\in \\mathbb{Z}_{\\ge 1}$ 为指定的簇数。设 $(\\lambda_1, v_1), \\dots, (\\lambda_k, v_k)$ 为 $L_{\\mathrm{sym}}$ 的 $k$ 个特征对，对应于按非递减顺序排列的 $k$ 个最小特征值。选择标准正交的特征向量，并按如下方式固定每列 $v_j$ 的符号：找到一个索引 $p \\in \\{1,\\dots,n\\}$，使得 $|(v_j)_p|$ 达到最大值（如果多个索引达到最大值，则取最小的那个索引），如果 $(v_j)_p  0$，则用 $-v_j$ 替换 $v_j$。\n- 将列向量 $v_1, \\dots, v_k$ 构造成矩阵 $U \\in \\mathbb{R}^{n \\times k}$。对每一行进行归一化：对于 $i \\in \\{1,\\dots,n\\}$，定义\n  $$ \\tilde{u}_i = \\begin{cases}\n  \\dfrac{u_i}{\\|u_i\\|_2},  \\|u_i\\|_2  0,\\\\\n  0,  \\text{otherwise},\n  \\end{cases} $$\n  其中 $u_i^\\top$ 是 $U$ 的第 $i$ 行，$\\tilde{u}_i^\\top$ 是行归一化矩阵 $\\tilde{U} \\in \\mathbb{R}^{n \\times k}$ 的第 $i$ 行。\n- 通过解决以下聚类问题来定义标签 $\\ell_i \\in \\{0, 1, \\dots, k-1\\}$：\n  $$ \\min_{\\ell_1,\\dots,\\ell_n \\in \\{0,\\dots,k-1\\},\\, c_0,\\dots,c_{k-1} \\in \\mathbb{R}^k} \\sum_{i=1}^n \\left\\| \\tilde{u}_i - c_{\\ell_i} \\right\\|_2^2. $$\n  在所有最小化器中，强制执行以下确定性标签索引规则。设 $C = \\{c_0,\\dots,c_{k-1}\\}$ 为任意一组最优中心点。将这些中心点按升序字典序排序以获得一个有序列表；如果两个中心点完全相同，则通过分配给该中心的原始点索引的较小均值来打破平局（如果仍然相同，则通过较小的原始簇索引来打破平局）。重新索引簇，使标签 $0$ 对应于此有序列表中的第一个中心点，标签 $1$ 对应于第二个，依此类推。最终报告的标签 $\\ell_i$ 必须是在应用此重新索引之后的结果。\n\n测试套件：\n\n为以下每种情况计算标签 $\\ell_i$。坐标在 $\\mathbb{R}^2$ 中给出。\n\n- 案例 A（理想情况，两个良好分离的组）：\n  - $X_A = \\{(-2.0,\\, 0.0),\\; (-2.2,\\, 0.2),\\; (-1.8,\\, -0.3),\\; (2.0,\\, 0.0),\\; (2.1,\\, 0.1),\\; (1.9,\\, -0.2)\\}$。\n  - $\\tau_A = 0.9$。\n  - $k_A = 2$。\n- 案例 B（三个紧凑的组，每个角方向一个）：\n  - $X_B = \\{(0.0,\\, 0.0),\\; (0.2,\\, -0.1),\\; (-0.1,\\, 0.1),\\; (3.0,\\, 0.0),\\; (2.9,\\, -0.2),\\; (3.2,\\, 0.1),\\; (0.0,\\, 3.0),\\; (0.1,\\, 2.8),\\; (-0.2,\\, 3.1)\\}$。\n  - $\\tau_B = 0.9$。\n  - $k_B = 3$。\n- 案例 C（非凸结构：密集的中心和周围的环）：\n  - $X_C = \\{(0.1,\\, 0.1),\\; (-0.1,\\, -0.2),\\; (0.2,\\, -0.1),\\; (-0.2,\\, 0.0),\\; (2.0,\\, 0.0),\\; (1.4142,\\, 1.4142),\\; (0.0,\\, 2.0),\\; (-1.4142,\\, 1.4142),\\; (-2.0,\\, 0.0),\\; (-1.4142,\\, -1.4142),\\; (0.0,\\, -2.0),\\; (1.4142,\\, -1.4142)\\}$。\n  - $\\tau_C = 1.0$。\n  - $k_C = 2$。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果。每个案例的结果是按上面列出的点顺序排列的标签 $\\ell_i$ 列表。例如，总体输出必须严格格式化为：\n- $[{\\text{案例 A 的标签}},{\\text{案例 B 的标签}},{\\text{案例 C 的标签}}]$,\n使用方括号和逗号，不含额外的空格或文本。此问题不涉及角度或物理单位。所有数值均为给定的标准实数。",
            "solution": "所提出的问题是计算科学领域中的一个适定且标准的任务，特别是在机器学习和数据分析领域。它描述了由 Ng、Jordan 和 Weiss 提出的谱聚类算法，这是一种用于识别数据中（包括非凸结构）簇结构的强大技术。该问题具有科学依据，数学上精确，并提供了进行计算所需的所有信息。它要求实现一个确定性的过程，从构建图拉普拉斯算子到最终获得明确索引的聚类结果。此问题是有效的。\n\n解决方案的步骤是，首先构建一个更适合聚类的数据表示，然后在这个新的表示中应用标准的划分算法。这是谱聚类的核心原理：将一个可能在复杂高维空间中的聚类问题，转换为一个在源于相似性图谱特性的低维嵌入中的更简单问题。\n\n对于每个测试用例，算法步骤如下执行，每个测试用例由一组点 $X = \\{x_i\\}_{i=1}^n \\subset \\mathbb{R}^d$、一个尺度参数 $\\tau  0$ 和一个期望的簇数 $k$ 组成。\n\n首先，我们量化点之间的成对相似性。构建一个全连接的加权无向图，其顶点对应于点 $x_i$。两个不同点 $x_i$ 和 $x_j$ 之间边的权重由高斯核给出，它衡量了它们的亲和度。相似度矩阵 $S \\in \\mathbb{R}^{n \\times n}$ 的元素为：\n$$\nS_{ij} = \\exp\\!\\left(-\\frac{\\|x_i - x_j\\|_2^2}{2 \\tau^2}\\right) \\quad \\text{for } i \\neq j, \\quad \\text{and} \\quad S_{ii} = 0.\n$$\n参数 $\\tau$ 控制核的宽度，定义了衡量相似性的尺度。\n\n根据相似度矩阵，我们定义度矩阵 $D$ 为一个对角矩阵，其对角元素 $D_{ii}$ 是点 $x_i$ 的相似度之和：$D_{ii} = \\sum_{j=1}^n S_{ij}$。这代表了每个点对所有其他点的总亲和度。\n\n分析的核心对象是对称归一化图拉普拉斯算子 $L_{\\mathrm{sym}}$，定义为：\n$$\nL_{\\mathrm{sym}} = I_n - D^{-1/2} S D^{-1/2}\n$$\n其中 $I_n$ 是 $n \\times n$ 的单位矩阵。这种特定形式的拉普拉斯算子具有良好的性质，包括其真实特征值在 $[0, 2]$ 范围内。它的特征向量构成一个标准正交基，并提供了一个能够揭示簇结构的数据低维嵌入。对应于最小特征值（接近 $0$）的特征向量在图上变化最慢，这使它们成为识别准连通分量的理想选择，这些分量被解释为簇。\n\n我们计算与 $k$ 个最小特征值相对应的 $k$ 个特征向量 $v_1, \\dots, v_k$。这些特征向量是嵌入空间的基。为了确保确定性，必须解决特征向量中的任何符号模糊性——因为如果 $v$ 是一个特征向量，那么 $-v$ 也是。规定的规则实现了这一点：对于每个特征向量 $v_j$，我们识别出绝对值最大的元素，如果该元素为负，我们就翻转整个特征向量的符号。这使得基向量的选择是规范的。\n\n这 $k$ 个经过符号校正的特征向量被排列成一个矩阵 $U \\in \\mathbb{R}^{n \\times k}$ 的列。$U$ 的第 $i$ 行，表示为 $u_i^\\top$，代表了原始点 $x_i$ 在 $k$ 维嵌入空间中的新坐标。Ng-Jordan-Weiss 算法中的一个关键步骤是将这些行向量归一化为单位长度，得到一个矩阵 $\\tilde{U}$，其行为 $\\tilde{u}_i$：\n$$\n\\tilde{u}_i = \\frac{u_i}{\\|u_i\\|_2} \\quad \\text{if } \\|u_i\\|_2  0, \\quad \\text{and} \\quad \\tilde{u}_i = 0 \\text{ otherwise}.\n$$\n这将嵌入的点投影到 $\\mathbb{R}^k$ 中的单位超球面表面。理论分析表明，对于理想分离的数据，来自单个簇的所有点将映射到该超球面上的同一点。对于实际数据，来自一个簇的点将形成一个紧密的群组。\n\n最后一步是对这些新的表示 $\\{\\tilde{u}_i\\}_{i=1}^n$ 进行划分。这是一个经典的聚类问题，问题陈述通过最小化簇内平方和来定义：\n$$\n\\min_{\\{\\ell_i\\}, \\{c_j\\}} \\sum_{i=1}^n \\|\\tilde{u}_i - c_{\\ell_i}\\|_2^2\n$$\n这正是 k-均值聚类算法的目标函数。为了保证一个全局最优和确定性的解（这对于科学计算至关重要），我们不依赖于随机初始化。相反，对于所提供的小型数据集，我们穷尽地测试所有可能的初始化，其中 $k$ 个初始簇中心本身是从点集 $\\{\\tilde{u}_i\\}$ 中选择的。选择产生最小平方和的划分。\n\n最后，必须根据一个确定性规则对所得的簇标签进行索引。这解决了 k-均值标签的置换模糊性。最优的簇中心 $\\{c_j\\}_{j=0}^{k-1}$ 首先按其坐标的字典序排序。任何平局都通过分配给该簇的点的原始索引的均值来打破，进一步的平局则通过 k-均值算法产生的原始簇索引来打破。最终的标签 $\\{0, 1, \\dots, k-1\\}$ 基于这个排序顺序来分配。这个严格的程序确保了输出是唯一且可复现的。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\nfrom scipy.linalg import eigh\nfrom scipy.cluster.vq import kmeans2\nfrom itertools import combinations\n\ndef compute_clusters(X: np.ndarray, tau: float, k: int) -> list[int]:\n    \"\"\"\n    Performs spectral clustering on a set of points according to the problem specification.\n\n    Args:\n        X: An (n, d) array of n points in d-dimensional space.\n        tau: The scale parameter for the Gaussian kernel.\n        k: The number of clusters to find.\n\n    Returns:\n        A list of n integer labels for the points.\n    \"\"\"\n    n = X.shape[0]\n\n    # Step 1: Compute the similarity matrix S\n    dist_sq = squareform(pdist(X, 'sqeuclidean'))\n    S = np.exp(-dist_sq / (2 * tau**2))\n    np.fill_diagonal(S, 0)\n\n    # Step 2: Compute the degree matrix D and the symmetric Laplacian L_sym\n    d = S.sum(axis=1)\n    \n    # Use np.divide or a 'where' clause for safe inverse square root\n    d_inv_sqrt_vals = np.power(d, -0.5, where=d > 0, out=np.zeros_like(d, dtype=float))\n    D_inv_sqrt = np.diag(d_inv_sqrt_vals)\n    \n    L_sym = np.identity(n) - D_inv_sqrt @ S @ D_inv_sqrt\n\n    # Step 3: Compute the first k eigenvectors of L_sym\n    # eigh returns eigenvalues in ascending order and corresponding eigenvectors as columns\n    _, eigvecs = eigh(L_sym)\n    U = eigvecs[:, :k]\n\n    # Step 4: Fix sign ambiguity of eigenvectors\n    for j in range(k):\n        v = U[:, j]\n        # np.argmax returns the first index in case of ties, as required\n        p = np.argmax(np.abs(v))\n        if v[p]  0:\n            U[:, j] = -v\n\n    # Step 5: Normalize rows of U to get tilde_U\n    norms = np.linalg.norm(U, axis=1, keepdims=True)\n    tilde_U = np.divide(U, norms, out=np.zeros_like(U), where=norms != 0)\n\n    # Step 6: Perform k-means clustering on tilde_U\n    # To find the global minimum deterministically, we test all possible initial centroids from the dataset.\n    best_inertia = np.inf\n    best_centroids = None\n    best_labels = None\n    \n    point_indices = np.arange(n)\n    \n    # Iterate through all combinations of k points as initial centers\n    for init_indices in combinations(point_indices, k):\n        initial_centroids = tilde_U[list(init_indices), :]\n        \n        # Run kmeans2 with 'matrix' initialization\n        # iter=100 is a reasonable number of iterations for convergence\n        centroids, labels = kmeans2(tilde_U, initial_centroids, iter=100, minit='matrix')\n        \n        # Check if the number of resulting clusters is k\n        # kmeans2 might return fewer than k clusters if some initial centroids are very close\n        if len(centroids)  k:\n            # Reconstruct full centroid array if some clusters are empty\n            # This is a bit complex, and for these small problems, unlikely to be an issue.\n            # Simplified: we assume k centroids are returned.\n            pass\n\n        # Calculate inertia (within-cluster sum of squares)\n        inertia = 0.0\n        for j in range(len(centroids)):\n            cluster_points = tilde_U[labels == j]\n            if cluster_points.shape[0] > 0:\n                inertia += np.sum((cluster_points - centroids[j])**2)\n        \n        if inertia  best_inertia:\n            best_inertia = inertia\n            best_centroids = centroids\n            best_labels = labels\n\n    # Step 7: Re-index labels based on the deterministic sorting rule\n    sort_keys = []\n    for j in range(k):\n        center_coords = tuple(best_centroids[j])\n        indices_in_cluster = point_indices[best_labels == j]\n        # Handle empty clusters, although unlikely with our method\n        mean_orig_index = np.mean(indices_in_cluster) if len(indices_in_cluster) > 0 else -1.0\n        original_cluster_idx = j\n        sort_keys.append((center_coords, mean_orig_index, original_cluster_idx))\n\n    # Sort the keys to establish the canonical order of clusters\n    sorted_keys = sorted(sort_keys)\n    \n    # Create a mapping from old cluster indices to new ones\n    label_map = np.zeros(k, dtype=int)\n    for new_label, key_tuple in enumerate(sorted_keys):\n        old_label = key_tuple[2]\n        label_map[old_label] = new_label\n        \n    final_labels = label_map[best_labels]\n    \n    return final_labels.tolist()\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs the spectral clustering algorithm, and prints the final output.\n    \"\"\"\n    test_cases = [\n        (\n            # Case A\n            np.array([\n                [-2.0, 0.0], [-2.2, 0.2], [-1.8, -0.3],\n                [2.0, 0.0], [2.1, 0.1], [1.9, -0.2]\n            ]), 0.9, 2\n        ),\n        (\n            # Case B\n            np.array([\n                [0.0, 0.0], [0.2, -0.1], [-0.1, 0.1],\n                [3.0, 0.0], [2.9, -0.2], [3.2, 0.1],\n                [0.0, 3.0], [0.1, 2.8], [-0.2, 3.1]\n            ]), 0.9, 3\n        ),\n        (\n            # Case C\n            np.array([\n                [0.1, 0.1], [-0.1, -0.2], [0.2, -0.1], [-0.2, 0.0],\n                [2.0, 0.0], [1.4142, 1.4142], [0.0, 2.0], [-1.4142, 1.4142],\n                [-2.0, 0.0], [-1.4142, -1.4142], [0.0, -2.0], [1.4142, -1.4142]\n            ]), 1.0, 2\n        )\n    ]\n\n    results_as_strings = []\n    for X, tau, k in test_cases:\n        labels = compute_clusters(X, tau, k)\n        # Format each list of labels as a string \"[l1,l2,...]\"\n        labels_str = f\"[{','.join(map(str, labels))}]\"\n        results_as_strings.append(labels_str)\n    \n    # Final print statement in the exact required format\n    print(f\"[{','.join(results_as_strings)}]\")\n\nsolve()\n```"
        }
    ]
}