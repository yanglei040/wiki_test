{
    "hands_on_practices": [
        {
            "introduction": "本练习是灾难性抵消（catastrophic cancellation）的一个经典例证。我们将探索直接计算一个包含两个几乎相等数字相减的表达式，会如何导致精度的巨大损失，以及一个简单的代数重构如何能够恢复数值稳定性。这个练习强调了在将数学表达式付诸代码实现之前，对其进行分析的重要性。",
            "id": "2389878",
            "problem": "您的任务是评估在 $x$ 以弧度为单位且趋近于 $0$ 时，计算函数 $f(x) = \\dfrac{\\tan(x) - \\sin(x)}{x^3}$ 的数值稳定性和误差传播。您的程序必须为每个测试值 $x$ 实现 $f(x)$ 的两种不同数值计算方法，并相对于一个由截断级数展开构建的高精度参考值来量化每种计算方法的误差。\n\n定义和要求：\n\n- 使用弧度制。\n- 为任意给定的非零 $x$ 定义以下三种计算方法：\n  1. 直接计算 $f_{\\mathrm{dir}}(x) = \\dfrac{\\tan(x) - \\sin(x)}{x^3}$。\n  2. 通过三角变换获得的数值稳定计算方法\n     $$f_{\\mathrm{stab}}(x) = \\dfrac{2 \\sin(x) \\sin^2\\!\\left(\\dfrac{x}{2}\\right)}{x^3 \\cos(x)},$$\n     该方法通过使用 $1 - \\cos(x) = 2\\sin^2\\!\\left(\\dfrac{x}{2}\\right)$ 来避免相减抵消。\n  3. 一个由 $f(x)$ 的麦克劳林级数构建的参考值，截断到 $x^6$ 阶：\n     $$f_{\\mathrm{ref}}(x) = \\dfrac{1}{2} + \\dfrac{x^2}{8} + \\dfrac{91}{1680} x^4 + \\dfrac{529}{24192} x^6.$$\n     此参考值在 $|x| \\leq 10^{-1}$ 时有效，其其余项为 $\\mathcal{O}(x^8)$。\n\n- 对于每个 $x$，计算绝对相对误差\n  $$E_{\\mathrm{dir}}(x) = \\dfrac{\\left| f_{\\mathrm{dir}}(x) - f_{\\mathrm{ref}}(x) \\right|}{\\left| f_{\\mathrm{ref}}(x) \\right|}, \\quad E_{\\mathrm{stab}}(x) = \\dfrac{\\left| f_{\\mathrm{stab}}(x) - f_{\\mathrm{ref}}(x) \\right|}{\\left| f_{\\mathrm{ref}}(x) \\right|}.$$\n\n测试组：\n\n评估并报告以下输入（均为弧度）的误差：$x \\in \\{10^{-1}, 10^{-4}, 10^{-8}, -10^{-8}, 10^{-12}, 10^{-16}\\}$。\n\n最终输出格式：\n\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于每个测试值 $x$，该列表必须按顺序首先包含 $E_{\\mathrm{dir}}(x)$，然后包含 $E_{\\mathrm{stab}}(x)$。因此，对于以上述顺序给出的测试值，输出必须是\n$$[E_{\\mathrm{dir}}(10^{-1}), E_{\\mathrm{stab}}(10^{-1}), E_{\\mathrm{dir}}(10^{-4}), E_{\\mathrm{stab}}(10^{-4}), E_{\\mathrm{dir}}(10^{-8}), E_{\\mathrm{stab}}(10^{-8}), E_{\\mathrm{dir}}(-10^{-8}), E_{\\mathrm{stab}}(-10^{-8}), E_{\\mathrm{dir}}(10^{-12}), E_{\\mathrm{stab}}(10^{-12}), E_{\\mathrm{dir}}(10^{-16}), E_{\\mathrm{stab}}(10^{-16})].$$\n所有角度必须解释为弧度。所有报告的量必须是十进制浮点数。",
            "solution": "该问题陈述是有效的。这是一个计算物理学中的适定问题，它有科学依据、内部一致且没有歧义。它探讨了灾难性抵消这一基本数值概念及其缓解方法。\n\n核心任务是计算当 $x$ 趋近于 $0$ 时函数 $f(x) = \\dfrac{\\tan(x) - \\sin(x)}{x^3}$ 的值。此计算通过三种不同的方法进行，以展示和量化数值误差。\n\n第一种方法是直接计算，$f_{\\mathrm{dir}}(x) = \\dfrac{\\tan(x) - \\sin(x)}{x^3}$。这种形式容易出现灾难性抵消。当 $x \\approx 0$ 时，我们有 $\\tan(x) \\approx x$ 和 $\\sin(x) \\approx x$。在有限精度浮点运算中，$\\tan(x) - \\sin(x)$ 的计算涉及两个非常接近的数相减。该操作导致前面的有效数字相互抵消，使得结果主要由表示误差主导。这种精度损失随后被除以一个非常小的数 $x^3$ 所放大。\n\n为了理解 $f(x)$ 在小 $x$ 时的行为，我们检查其麦克劳林级数展开。$\\tan(x)$ 和 $\\sin(x)$ 的级数分别为：\n$$ \\tan(x) = x + \\frac{x^3}{3} + \\frac{2x^5}{15} + \\mathcal{O}(x^7) $$\n$$ \\sin(x) = x - \\frac{x^3}{6} + \\frac{x^5}{120} + \\mathcal{O}(x^7) $$\n将这些级数相减揭示了分子的真实行为：\n$$ \\tan(x) - \\sin(x) = \\left( \\frac{1}{3} - (-\\frac{1}{6}) \\right) x^3 + \\left( \\frac{2}{15} - \\frac{1}{120} \\right) x^5 + \\mathcal{O}(x^7) = \\frac{1}{2}x^3 + \\frac{1}{8}x^5 + \\mathcal{O}(x^7) $$\n因此，当 $x \\to 0$ 时，函数 $f(x)$ 趋近于一个有限的极限：\n$$ \\lim_{x \\to 0} f(x) = \\lim_{x \\to 0} \\frac{\\frac{1}{2}x^3 + \\frac{1}{8}x^5 + \\mathcal{O}(x^7)}{x^3} = \\frac{1}{2} $$\n直接公式试图通过减去两个数量级大得多（$\\mathcal{O}(x)$）的项来计算一个数量级很小（$\\mathcal{O}(x^3)$）的首项，这正是数值灾难的根源。\n\n第二种方法 $f_{\\mathrm{stab}}(x)$ 采用三角恒等式来重构表达式以避免这种抵消。推导如下：\n$$ f(x) = \\frac{\\frac{\\sin(x)}{\\cos(x)} - \\sin(x)}{x^3} = \\frac{\\sin(x) \\left( \\frac{1}{\\cos(x)} - 1 \\right)}{x^3} = \\frac{\\sin(x) (1 - \\cos(x))}{x^3 \\cos(x)} $$\n对于小 $x$ 来说，$1 - \\cos(x)$ 这一项仍然是一个有问题的减法。但是，可以使用半角恒等式 $1 - \\cos(x) = 2 \\sin^2\\left(\\frac{x}{2}\\right)$ 将其替换。这就得到了数值稳定的形式：\n$$ f_{\\mathrm{stab}}(x) = \\frac{2 \\sin(x) \\sin^2\\left(\\frac{x}{2}\\right)}{x^3 \\cos(x)} $$\n此表达式不包含近似相等量的减法，因此预期是数值稳定的。\n\n第三种方法使用 $f(x)$ 本身的截断麦克劳林级数，提供了一个高精度的参考值 $f_{\\mathrm{ref}}(x)$。从 $\\tan(x) - \\sin(x)$ 的展开式中，我们推导出 $f(x)$ 的级数，这与问题中提供的参考公式是完全一致的：\n$$ \\tan(x) - \\sin(x) = \\frac{1}{2}x^3 + \\frac{1}{8}x^5 + \\frac{91}{1680}x^7 + \\frac{529}{24192}x^9 + \\mathcal{O}(x^{11}) $$\n因此，将上式除以 $x^3$ 得到：\n$$ f(x) = \\frac{1}{2} + \\frac{1}{8}x^2 + \\frac{91}{1680}x^4 + \\frac{529}{24192}x^6 + \\mathcal{O}(x^8) $$\n这正是用作基准的 $f_{\\mathrm{ref}}(x)$。对于小 $x$ 来说，这种多项式求值是内在稳定的，因为它只涉及正项（因为 $x$ 是平方的）的加法和乘法。这使其成为一个理想的基准。\n\n数值实现将包括对应于 $f_{\\mathrm{dir}}$、$f_{\\mathrm{stab}}$ 和 $f_{\\mathrm{ref}}$ 的三个函数。然后我们将遍历测试组中的 $x$ 值：$\\{10^{-1}, 10^{-4}, 10^{-8}, -10^{-8}, 10^{-12}, 10^{-16}\\}$。对于每个 $x$，我们计算直接法和稳定法相对于参考值的绝对相对误差：\n$$ E_{\\mathrm{dir}}(x) = \\frac{\\left| f_{\\mathrm{dir}}(x) - f_{\\mathrm{ref}}(x) \\right|}{\\left| f_{\\mathrm{ref}}(x) \\right|}, \\quad E_{\\mathrm{stab}}(x) = \\frac{\\left| f_{\\mathrm{stab}}(x) - f_{\\mathrm{ref}}(x) \\right|}{\\left| f_{\\mathrm{ref}}(x) \\right|} $$\n由于 $f_{\\mathrm{ref}}(x)$ 是一个正常数（1/2）与非负项之和，其值总是大于或等于 1/2，因此在误差计算中没有除以零的风险。函数 $f(x)$ 是一个偶函数，意味着 $f(x) = f(-x)$，所以对于 $x=10^{-8}$ 和 $x=-10^{-8}$ 的结果预期是相同的。\n\n实现将使用霍纳法则（Horner's method）对 $f_{\\mathrm{ref}}(x)$ 进行多项式求值，以优化性能并保持数值精度。最终输出将是计算出的误差 $E_{\\mathrm{dir}}(x)$ 和 $E_{\\mathrm{stab}}(x)$ 的列表，按指定顺序排列。我们预计，当 $|x| \\to 0$ 时，$E_{\\mathrm{dir}}(x)$ 将急剧增加，而 $E_{\\mathrm{stab}}(x)$ 将保持很小，这证实了重构表达式的优越稳定性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef f_dir(x: float) - float:\n    \"\"\"\n    Direct evaluation of f(x) = (tan(x) - sin(x)) / x**3.\n    This form is prone to catastrophic cancellation for x near 0.\n    \"\"\"\n    if x == 0.0:\n        return 0.5  # The limit as x - 0\n    return (np.tan(x) - np.sin(x)) / (x**3)\n\ndef f_stab(x: float) - float:\n    \"\"\"\n    Numerically stable evaluation of f(x) using trigonometric rearrangement.\n    f_stab(x) = (2 * sin(x) * sin(x/2)**2) / (x**3 * cos(x)).\n    \"\"\"\n    if x == 0.0:\n        return 0.5  # The limit as x - 0\n    \n    # Pre-calculate common terms\n    sin_x = np.sin(x)\n    x_half = x / 2.0\n    sin_x_half = np.sin(x_half)\n    cos_x = np.cos(x)\n    x_cubed = x**3\n    \n    # Avoid division by zero if cos(x) is zero, though not for test cases\n    if cos_x == 0.0:\n        return np.inf * np.sign(sin_x)\n        \n    numerator = 2.0 * sin_x * sin_x_half**2\n    denominator = x_cubed * cos_x\n    \n    return numerator / denominator\n\ndef f_ref(x: float) - float:\n    \"\"\"\n    Reference evaluation of f(x) using its Maclaurin series expansion\n    truncated at the O(x^6) term.\n    f_ref(x) = 1/2 + x^2/8 + (91/1680)x^4 + (529/24192)x^6.\n    \"\"\"\n    if x == 0.0:\n        return 0.5\n        \n    # Use Horner's method for efficient and stable polynomial evaluation\n    y = x**2\n    c0 = 1.0 / 2.0\n    c1 = 1.0 / 8.0\n    c2 = 91.0 / 1680.0\n    c3 = 529.0 / 24192.0\n\n    return c0 + y * (c1 + y * (c2 + y * c3))\n\ndef solve():\n    \"\"\"\n    Main function to execute the problem's requirements.\n    It calculates and reports the relative errors for two numerical methods\n    against a reference value for a given set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        1e-1,\n        1e-4,\n        1e-8,\n        -1e-8,\n        1e-12,\n        1e-16\n    ]\n\n    results = []\n    for x in test_cases:\n        # Calculate the function value using all three methods\n        val_dir = f_dir(x)\n        val_stab = f_stab(x)\n        val_ref = f_ref(x)\n\n        # Calculate the absolute relative errors\n        # Note: abs(val_ref) is guaranteed to be = 0.5, so no division by zero\n        error_dir = np.abs(val_dir - val_ref) / np.abs(val_ref)\n        error_stab = np.abs(val_stab - val_ref) / np.abs(val_ref)\n        \n        results.append(error_dir)\n        results.append(error_stab)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在单次运算误差的基础上，本练习将演示微小的、重复的舍入误差如何在多次迭代中累积，从而破坏计算结果。你将比较一个交错级数的朴素求和与Kahan补偿求和算法，后者是一种旨在跟踪和纠正这些丢失的精度位的精巧技术。本练习揭示了对于迭代过程，算法的选择对保持准确性至关重要。",
            "id": "2389876",
            "problem": "本题要求您量化在二进制浮点算术中，对一个带有小常数偏差的交错序列求和时舍入误差的传播情况，并比较标准求和与 Kahan 补偿求和的误差行为。设序列定义为\n$$\na_k = (-1)^{k+1} + s \\quad \\text{for} \\quad k=1,2,\\ldots,N,\n$$\n其中 $s0$ 是一个实数偏差，$N$ 是一个正整数。对于下面指定的每个测试用例 $(N,s)$，请使用 IEEE $754$ 64位二进制算术计算以下内容：\n- 标准的从左到右浮点和\n$$\nS_{\\text{std}}(N,s) = \\sum_{k=1}^{N} a_k.\n$$\n- Kahan 补偿浮点和\n$$\nS_{\\text{kah}}(N,s) = \\sum_{k=1}^{N} a_k,\n$$\n其中求和必须使用 64位二进制算术下的 Kahan 补偿求和方法进行。\n\n设精确实数和为\n$$\nS_{\\text{exact}}(N,s) = \\sum_{k=1}^{N} \\left[(-1)^{k+1} + s\\right],\n$$\n该和被解释为没有浮点舍入的实数。对于每个测试用例，计算绝对误差\n$$\nE_{\\text{std}} = \\left| S_{\\text{std}}(N,s) - S_{\\text{exact}}(N,s) \\right|, \n\\quad\nE_{\\text{kah}} = \\left| S_{\\text{kah}}(N,s) - S_{\\text{exact}}(N,s) \\right|.\n$$\n\n测试套件：\n- 情况 $1$：$(N,s)=(200000,\\,10^{-16})$。\n- 情况 $2$：$(N,s)=(200000,\\,2\\times 10^{-16})$。\n- 情况 $3$：$(N,s)=(200000,\\,10^{-12})$。\n- 情况 $4$：$(N,s)=(200001,\\,10^{-16})$。\n- 情况 $5$：$(N,s)=(2,\\,10^{-16})$。\n\n您的程序必须为这 $5$ 种情况中的每一种输出一对浮点数 $(E_{\\text{std}}, E_{\\text{kah}})$，但需按以下顺序汇总到一个扁平列表中：\n$$\n\\left[E_{\\text{std}}^{(1)},E_{\\text{kah}}^{(1)},E_{\\text{std}}^{(2)},E_{\\text{kah}}^{(2)},E_{\\text{std}}^{(3)},E_{\\text{kah}}^{(3)},E_{\\text{std}}^{(4)},E_{\\text{kah}}^{(4)},E_{\\text{std}}^{(5)},E_{\\text{kah}}^{(5)}\\right].\n$$\n\n最终输出格式：\n- 生成仅一行，包含一个由方括号括起来的列表，列表项以逗号分隔，无额外空格。\n- 每个数字必须以科学计数法打印，并保留 $12$ 位有效数字。\n- 所需格式示例（仅为说明）：$[1.234000000000e-03,4.560000000000e-07]$。\n\n不涉及物理单位。不使用角度。请勿在列表前后打印任何额外文本。$S_{\\text{std}}(N,s)$ 和 $S_{\\text{kah}}(N,s)$ 的计算必须使用 64位二进制浮点算术执行，而精确实数和 $S_{\\text{exact}}(N,s)$ 必须仅用作误差计算的参考。每个测试用例的答案是如上定义的一对浮点数 $(E_{\\text{std}},E_{\\text{kah}})$，最终输出将按规定汇总所有情况。",
            "solution": "问题陈述是有效的。它在计算物理领域，特别是在浮点误差分析方面，提出了一个定义明确的数值实验。该问题在科学上基于数值分析的原理，问题设定良好，具有明确的目标和约束，并且没有任何事实或逻辑上的不一致。\n\n该问题要求对一个带有小正偏差的交错序列 $a_k = (-1)^{k+1} + s$ 进行标准（朴素）求和与 Kahan 补偿求和之间的定量比较。核心的数值挑战源于浮点算术的特性，特别是在对两个数量级差异巨大的数进行相加时会发生有效位损失。\n\n首先，让我们确定和的精确值，它将作为我们计算误差的基准。该和定义为：\n$$\nS_{\\text{exact}}(N,s) = \\sum_{k=1}^{N} \\left[(-1)^{k+1} + s\\right]\n$$\n它可以分为两部分：\n$$\nS_{\\text{exact}}(N,s) = \\left(\\sum_{k=1}^{N} (-1)^{k+1}\\right) + \\left(\\sum_{k=1}^{N} s\\right)\n$$\n第二项就是 $N \\cdot s$。第一项是交替的 $+1$ 和 $-1$ 的和。\n如果 $N$ 是偶数，和为 $(1-1) + (1-1) + \\ldots = 0$。\n如果 $N$ 是奇数，和为 $(1-1) + \\ldots + (1-1) + 1 = 1$。\n这可以简明地表示为 $N \\pmod 2$。\n因此，解释为实数的精确和由以下解析公式给出：\n$$\nS_{\\text{exact}}(N,s) = (N \\pmod 2) + Ns\n$$\n该公式将用作计算绝对误差 $E_{\\text{std}}$ 和 $E_{\\text{kah}}$ 的参考值。\n\n接下来，我们分析两种求和方法在 64位二进制浮点算术中的行为。\n\n标准求和 ($S_{\\text{std}}$)：\n标准方法通过一个简单的从左到右的循环来计算和：$S_k = S_{k-1} + a_k$。让我们追踪一下部分和。\n当 $k$ 为奇数时，序列的项为 $a_k \\approx 1$；当 $k$ 为偶数时，为 $a_k \\approx -1$。\n对于奇数 $k=2m-1$，部分和为 $S_{2m-1} = \\text{fl}(S_{2m-2} + a_{2m-1})$，其中 $\\text{fl}(\\cdot)$ 表示一个浮点运算。在这里，$S_{2m-2}$ 是 $m-1$ 对项 $(a_{2j-1}+a_{2j})$ 的和，每对的和为 $2s$。因此，$S_{2m-2} \\approx 2(m-1)s$，对于给定的参数来说这是一个小数。项 $a_{2m-1} \\approx 1$。\n因此，该加法是 $\\text{fl}(\\text{小数} + \\text{大数})$。在浮点算术中，这个操作会损失小数的大部分精度。$S_{2m-2}$ 的低位比特被截断。\n对于偶数 $k=2m$，部分和为 $S_{2m} = \\text{fl}(S_{2m-1} + a_{2m})$。由于 $S_{2m-1} \\approx 1$ 且 $a_{2m} \\approx -1$，此操作是灾难性抵消的一个例子，即两个几乎相等的数相减导致结果具有很大的相对误差。\n在每一步（尤其是在奇数步）引入的舍入误差会累积。对于大量的项 $N$，预计这种累积误差会变得非常显著，导致 $S_{\\text{std}}$ 严重偏离 $S_{\\text{exact}}$。\n\nKahan 补偿求和 ($S_{\\text{kah}}$)：\nKahan 求和算法正是为了缓解这个问题而设计的。它维护一个运行补偿变量 $c$，用于累积每次加法产生的舍入误差。每一步的算法如下：\n1. $y = a_k - c$\n2. $t = \\text{sum} + y$\n3. $c = (t - \\text{sum}) - y$\n4. $\\text{sum} = t$\n\n关键步骤是计算新的补偿项 $c = (t - \\text{sum}) - y$。在代数上，这个值应为零。然而，在浮点算术中，`t - sum` 恢复了 `y` 中已成功加到 `sum` 上的高位部分，再从此结果中减去 `y` 则分离出在加法 `sum + y` 中丢失的 `y` 的低位部分的相反数。这个丢失的部分 $c$ 随后会在加到运行总和之前，从*下一个*项 $a_{k+1}$ 中减去，从而有效地重新注入了丢失的精度。这个过程防止了舍入误差的系统性累积。因此，预计误差 $E_{\\text{kah}}$ 会非常小，与最终和的机器精度在同一数量级，并且不应随 $N$ 的增大而显著增长。\n\n对于 $N=2$ 的特殊情况，Kahan 算法没有任何优势。补偿项 $c$ 在第二次（也是最后一次）加法后计算，但从未被使用。因此，对于 $N=2$，$S_{\\text{std}}$ 和 $S_{\\text{kah}}$ 将是相同的，从而 $E_{\\text{std}} = E_{\\text{kah}}$。\n\n要实现的算法如下：\n对于每个测试用例 $(N, s)$：\n1. 将输入值 $s$ 转换为 64位二进制浮点数。\n2. 使用解析公式 $S_{\\text{exact}} = (N \\pmod 2) + Ns$ 计算参考值 $S_{\\text{exact}}$，并使用 64位二进制数进行算术运算。\n3. 实现一个从 $k=1$ 到 $N$ 的循环来计算 $S_{\\text{std}}$。在每次迭代中，计算 $a_k = (-1)^{k+1} + s$ 并将其加到运行总和中。\n4. 实现第二个从 $k=1$ 到 $N$ 的循环，使用上述的 Kahan 求和算法计算 $S_{\\text{kah}}$。所有变量（`sum`, `c`, `y`, `t`）必须是 64位二进制数。\n5. 计算绝对误差 $E_{\\text{std}} = |S_{\\text{std}} - S_{\\text{exact}}|$ 和 $E_{\\text{kah}} = |S_{\\text{kah}} - S_{\\text{exact}}|$。\n6. 收集生成的误差对。\n处理完所有测试用例后，将收集到的误差按规定格式化为单个列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and compares the error propagation of standard vs. Kahan summation\n    for an alternating sequence with a small bias.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (200000, 1e-16),\n        (200000, 2e-16),\n        (200000, 1e-12),\n        (200001, 1e-16),\n        (2, 1e-16),\n    ]\n\n    results = []\n    for N, s_val in test_cases:\n        # Use numpy.float64 to ensure computations are in IEEE 754 binary64.\n        s = np.float64(s_val)\n\n        # 1. Calculate the exact sum analytically.\n        # S_exact(N,s) = (N mod 2) + N*s\n        # The calculation is done in float64 to establish a consistent reference.\n        s_exact = np.float64(N % 2) + np.float64(N) * s\n\n        # 2. Compute the standard left-to-right floating-point sum.\n        s_std = np.float64(0.0)\n        for k in range(1, N + 1):\n            # Sequence term a_k = (-1)**(k+1) + s\n            # (-1)**(k+1) is 1 if k is odd, -1 if k is even.\n            term_sign = np.float64(1.0 if (k % 2 != 0) else -1.0)\n            a_k = term_sign + s\n            s_std += a_k\n\n        # 3. Compute the Kahan compensated floating-point sum.\n        s_kah = np.float64(0.0)\n        c = np.float64(0.0)  # A running compensation for lost low-order bits.\n        for k in range(1, N + 1):\n            term_sign = np.float64(1.0 if (k % 2 != 0) else -1.0)\n            a_k = term_sign + s\n            y = a_k - c\n            t = s_kah + y\n            # (t - s_kah) recovers the high-order part of y.\n            # Subtracting y recovers -(low part of y), which is the round-off error.\n            c = (t - s_kah) - y\n            s_kah = t\n\n        # 4. Compute the absolute errors.\n        e_std = np.abs(s_std - s_exact)\n        e_kah = np.abs(s_kah - s_exact)\n        \n        results.append(e_std)\n        results.append(e_kah)\n\n    # Final print statement in the exact required format.\n    # The format \"%.12e\" gives 1 digit before the decimal and 12 after,\n    # totaling 13 significant digits, which corresponds to the standard precision of scientific notation output.\n    formatted_results = [f\"{r:.12e}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现在，我们将分析扩展到计算工程中的一个基础算法：求解线性方程组。本练习将展示，如果朴素地实现高斯消去法，它可能会灾难性地失败，以及一个称为部分主元法（partial pivoting）的程序性修改如何确保其稳定性和可靠性。通过为特殊构造的矩阵比较使用和不使用主元法的解，你将亲身体会到设计稳健数值算法的重要性。",
            "id": "2375807",
            "problem": "编写一个完整的、可运行的程序，对于一组固定的线性方程组，定量地比较无行交换的高斯消元法与带部分主元法的高斯消元法中舍入误差和灾难性抵消的影响。所有消元和回代步骤的计算都必须使用单精度二进制浮点算术（即使用$32$-bit浮点数）进行，而您构建的任何参考值都可以使用双精度计算。\n\n对于已知精确解 $\\mathbf{x}_{\\mathrm{true}}$ 的线性方程组 $A \\mathbf{x} = \\mathbf{b}$，其近似解 $\\hat{\\mathbf{x}}$ 的相对前向误差定义为\n$$\nE(\\hat{\\mathbf{x}}) = \\frac{\\lVert \\hat{\\mathbf{x}} - \\mathbf{x}_{\\mathrm{true}} \\rVert_2}{\\lVert \\mathbf{x}_{\\mathrm{true}} \\rVert_2}.\n$$\n如果在无行交换的版本中因出现精确的零主元而无法继续计算，则将相应的相对误差定义为 $+\\infty$，并将其打印为字符串 \"inf\"。\n\n您的程序必须对下面的每个测试用例计算：\n- $\\hat{\\mathbf{x}}_{\\mathrm{np}}$：通过无任何行交换的高斯消元法获得的解，\n- $\\hat{\\mathbf{x}}_{\\mathrm{pp}}$：通过带部分主元法的高斯消元法获得的解（即，在每个消元步骤中，将当前行与当前列中具有最大绝对值主元的下方某行进行交换），\n\n两者都使用$32$-bit浮点算术进行。然后使用上述定义计算 $E(\\hat{\\mathbf{x}}_{\\mathrm{np}})$ 和 $E(\\hat{\\mathbf{x}}_{\\mathrm{pp}})$。\n\n使用以下测试套件。在每种情况下，使用双精度根据 $A$ 和指定的 $\\mathbf{x}_{\\mathrm{true}}$ 构建 $\\mathbf{b}$，即 $\\mathbf{b} = A \\mathbf{x}_{\\mathrm{true}}$，然后按要求使用单精度求解该方程组。\n\n- 测试用例 $1$（良态的 $2 \\times 2$ 系统）：\n  $$\n  A_1 = \\begin{bmatrix} 2  1 \\\\ 1  3 \\end{bmatrix}, \\quad \\mathbf{x}_{\\mathrm{true},1} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}.\n  $$\n- 测试用例 $2$（无主元法下会触发灾难性抵消）：令 $\\varepsilon = 10^{-20}$，\n  $$\n  A_2 = \\begin{bmatrix} \\varepsilon  1 \\\\ 1  1 \\end{bmatrix}, \\quad \\mathbf{x}_{\\mathrm{true},2} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}.\n  $$\n- 测试用例 $3$（无行交换时出现精确的零主元）：\n  $$\n  A_3 = \\begin{bmatrix} 0  1  1 \\\\ 1  1  1 \\\\ 1  1  2 \\end{bmatrix}, \\quad \\mathbf{x}_{\\mathrm{true},3} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}.\n  $$\n- 测试用例 $4$（$5$ 阶病态 Hilbert 系统）：对于索引 $i,j \\in \\{1,2,3,4,5\\}$，\n  $$\n  \\left(A_4\\right)_{ij} = \\frac{1}{i + j - 1}, \\quad \\mathbf{x}_{\\mathrm{true},4} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}.\n  $$\n\n角度单位不适用。物理单位不适用。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。对于每个测试用例 $k \\in \\{1,2,3,4\\}$，首先报告 $E(\\hat{\\mathbf{x}}_{\\mathrm{np}})$，然后报告 $E(\\hat{\\mathbf{x}}_{\\mathrm{pp}})$，按此顺序。因此，输出必须总共包含 $8$ 个条目，顺序如下\n$$\n\\left[E(\\hat{\\mathbf{x}}_{\\mathrm{np},1}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{pp},1}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{np},2}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{pp},2}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{np},3}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{pp},3}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{np},4}),\\,E(\\hat{\\mathbf{x}}_{\\mathrm{pp},4})\\right].\n$$\n每个有限浮点数必须四舍五入为以 $10$ 为底的科学记数法，小数点后恰好有 $6$ 位数字（例如，$1.234000\\mathrm{e}{-02}$），并且 $+\\infty$ 必须打印为 \"inf\"。您的程序不得读取任何输入，也不得产生任何额外的文本。",
            "solution": "该问题要求对带部分主元和不带部分主元的高斯消元法进行定量比较，重点关注灾难性抵消和舍入误差的影响。分析将在一个定义的线性方程组套件 $A \\mathbf{x} = \\mathbf{b}$ 上进行，其中求解过程被限制为单精度（$32$-位）浮点算术。近似解 $\\hat{\\mathbf{x}}$ 的质量通过其相对于已知真实解 $\\mathbf{x}_{\\mathrm{true}}$ 的相对前向误差 $E(\\hat{\\mathbf{x}})$ 来衡量。\n\n求解大小为 $n \\times n$ 的线性系统 $A \\mathbf{x} = \\mathbf{b}$ 的基本算法是高斯消元法。它包括两个阶段：前向消元和回代。前向消元阶段通过应用一系列初等行变换将矩阵 $A$ 转换为一个上三角矩阵 $U$。同样的操作也应用于向量 $\\mathbf{b}$ 以产生一个修改后的向量 $\\mathbf{c}$。系统从而被转换为一个等价的系统 $U \\mathbf{x} = \\mathbf{c}$，该系统可以通过回代轻松求解。\n\n对列 $k$（从 $0$ 到 $n-2$）的前向消元过程涉及使用主元元素 $A_{kk}$ 来消除其下方同一列中的系数。对于行 $k$ 下方的每一行 $i$（即 $i  k$），通过减去行 $k$ 的一个倍数来更新该行：\n$$\n\\text{Row}_i \\leftarrow \\text{Row}_i - m_{ik} \\cdot \\text{Row}_k\n$$\n其中乘数是 $m_{ik} = A_{ik} / A_{kk}$。只有当乘数 $m_{ik}$ 不会过大时，这个过程才是数值稳定的。如果主元元素 $A_{kk}$ 相对于其列中的其他元素为零或非常接近零，则乘数 $m_{ik}$ 可能会变得非常大。这会导致灾难性抵消：当我们计算 $A_{ij} - m_{ik} A_{kj}$ 时，如果 $m_{ik} A_{kj}$ 非常大且与 $A_{ij}$ 的量级相似，则减法可能导致许多有效数字的丢失。这会引入大量的舍入误差，该误差会通过后续计算传播，最终破坏最终解 $\\hat{\\mathbf{x}}$。\n\n所需的两种算法如下：\n\n1.  **无主元高斯消元法**：这是上面描述的朴素实现。它在不重新排序方程的情况下进行。其主要弱点是容易受到小主元或零主元的影响。如果遇到精确的零主元 $A_{kk}=0$，算法将失败，因为乘数 $m_{ik}$ 未定义。根据问题规范，此失败会导致无穷大误差，记为 \"inf\"。\n\n2.  **带部分主元的高斯消元法**：这是一种旨在增强数值稳定性的改进方法。在对列 $k$ 进行消元步骤之前，算法在子列 $\\{A_{ik} | i \\ge k\\}$ 中搜索绝对值最大的元素。设此元素为 $A_{pk}$。然后算法交换行 $p$ 和行 $k$。这确保了主元元素 $A_{kk}$ 是其列中（从对角线向下）可能的最大值，从而确保所有乘数 $|m_{ik}| = |A_{ik}/A_{kk}|$ 都小于或等于 $1$。该策略可防止乘数变得过大，并显著减轻灾难性抵消的风险。\n\n评估指标是相对前向误差，定义为：\n$$\nE(\\hat{\\mathbf{x}}) = \\frac{\\lVert \\hat{\\mathbf{x}} - \\mathbf{x}_{\\mathrm{true}} \\rVert_2}{\\lVert \\mathbf{x}_{\\mathrm{true}} \\rVert_2}\n$$\n其中 $\\lVert \\cdot \\rVert_2$ 表示欧几里得范数。该度量量化了计算解与真实解的偏差，该偏差是相对于真实解的量级而言的。\n\n测试套件旨在暴露无主元方法的特定弱点：\n- **测试用例 $1$**：一个良态的 $2 \\times 2$ 系统。预计两种方法都会产生高精度的结果，因为初始主元已经是其列中最大的。\n- **测试用例 $2$**：此用例的矩阵 $A_2$ 具有一个非常小的主元元素，$A_{11} = \\varepsilon = 10^{-20}$。虽然不完全是零，但在单精度算术中，这个值小到足以使其作为主元时产生一个非常大的乘数 $1/\\varepsilon$，从而在更新第二行时导致灾难性抵消。预计无主元解 $\\hat{\\mathbf{x}}_{\\mathrm{np}}$ 会非常不准确。部分主元法会交换行，使用 $1$ 作为主元，从而进行稳定的计算并得到准确的解 $\\hat{\\mathbf{x}}_{\\mathrm{pp}}$。\n- **测试用例 $3$**：此用例呈现了一个精确的零主元，$A_{11} = 0$。无主元算法必然失败，产生无穷大误差。部分主元法会将第 $1$ 行与第 $2$ 行或第 $3$ 行交换，这两行在第一列中都有非零元素，从而使算法能够继续进行并找到解。\n- **测试用例 $4$**：这涉及 $5 \\times 5$ 的 Hilbert 矩阵，该矩阵是出了名的病态。病态意味着 $A$ 或 $\\mathbf{b}$ 的微小变化可能导致解 $\\mathbf{x}$ 的巨大变化。虽然主元法通过控制乘数的增长来提高稳定性，但它无法消除病态系统固有的敏感性。因此，预计两种算法都会产生具有显著误差的解，但部分主元法仍应比无主元方法产生更准确的结果。\n\n实现将包括两个主要函数，分别对应高斯消元法的每个变体。这些函数将使用 $32$-位浮点数（`numpy.float32`）执行其所有内部算术。主过程将构建测试用例，使用双精度（`float64`）计算右侧向量 $\\mathbf{b} = A \\mathbf{x}_{\\mathrm{true}}$ 以获得高保真参考，调用单精度求解器，然后计算相对前向误差以生成最终报告。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_no_pivot(A: np.ndarray, b: np.ndarray) - np.ndarray | None:\n    \"\"\"\n    Solves Ax=b using Gaussian elimination without pivoting in single precision.\n    Returns the solution vector x, or None if a zero pivot is encountered.\n    \"\"\"\n    n = A.shape[0]\n    # Create an augmented matrix and cast to float32 for all computations\n    Aug = np.hstack([A, b.reshape(-1, 1)]).astype(np.float32)\n\n    # Forward elimination\n    for k in range(n - 1):\n        pivot = Aug[k, k]\n        if pivot == np.float32(0.0):\n            return None  # Failure due to exact zero pivot\n\n        for i in range(k + 1, n):\n            multiplier = Aug[i, k] / pivot\n            Aug[i, k:] -= multiplier * Aug[k, k:]\n\n    # Backward substitution\n    x_hat = np.zeros(n, dtype=np.float32)\n    for i in range(n - 1, -1, -1):\n        # Check for singularity detected after elimination\n        if Aug[i, i] == np.float32(0.0):\n            return None\n        \n        s = np.dot(Aug[i, i + 1:n], x_hat[i + 1:])\n        x_hat[i] = (Aug[i, n] - s) / Aug[i, i]\n\n    return x_hat\n\ndef solve_partial_pivot(A: np.ndarray, b: np.ndarray) - np.ndarray | None:\n    \"\"\"\n    Solves Ax=b using Gaussian elimination with partial pivoting in single precision.\n    Returns the solution vector x, or None if the matrix is singular.\n    \"\"\"\n    n = A.shape[0]\n    # Create an augmented matrix and cast to float32 for all computations\n    Aug = np.hstack([A, b.reshape(-1, 1)]).astype(np.float32)\n\n    # Forward elimination with pivoting\n    for k in range(n - 1):\n        # Find the row with the largest pivot in the current column\n        max_row_idx = k + np.argmax(np.abs(Aug[k:, k]))\n\n        # Swap rows if necessary\n        if max_row_idx != k:\n            Aug[[k, max_row_idx]] = Aug[[max_row_idx, k]]\n\n        pivot = Aug[k, k]\n        # If the pivot is zero after swapping, the matrix is singular\n        if pivot == np.float32(0.0):\n            return None\n\n        for i in range(k + 1, n):\n            multiplier = Aug[i, k] / pivot\n            Aug[i, k:] -= multiplier * Aug[k, k:]\n\n    # Backward substitution\n    x_hat = np.zeros(n, dtype=np.float32)\n    for i in range(n - 1, -1, -1):\n        if Aug[i, i] == np.float32(0.0):\n            return None # Singular matrix\n        \n        s = np.dot(Aug[i, i + 1:n], x_hat[i + 1:])\n        x_hat[i] = (Aug[i, n] - s) / Aug[i, i]\n\n    return x_hat\n\ndef relative_forward_error(x_hat: np.ndarray, x_true: np.ndarray) - float:\n    \"\"\"\n    Computes the relative forward error using double precision for accuracy.\n    \"\"\"\n    # Use float64 for higher precision error calculation\n    x_hat_64 = x_hat.astype(np.float64)\n    x_true_64 = x_true.astype(np.float64)\n    \n    norm_diff = np.linalg.norm(x_hat_64 - x_true_64, 2)\n    norm_true = np.linalg.norm(x_true_64, 2)\n    \n    if norm_true == 0:\n        return 0.0 if norm_diff == 0.0 else np.inf\n    \n    return norm_diff / norm_true\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # All matrices and vectors are initially defined in float64.\n    \n    # Test case 1\n    A1 = np.array([[2, 1], [1, 3]], dtype=np.float64)\n    x_true1 = np.array([1, -1], dtype=np.float64)\n\n    # Test case 2\n    eps = 1e-20\n    A2 = np.array([[eps, 1], [1, 1]], dtype=np.float64)\n    x_true2 = np.array([1, 1], dtype=np.float64)\n\n    # Test case 3\n    A3 = np.array([[0, 1, 1], [1, 1, 1], [1, 1, 2]], dtype=np.float64)\n    x_true3 = np.array([1, 2, 3], dtype=np.float64)\n\n    # Test case 4 (Hilbert matrix)\n    n4 = 5\n    A4 = np.zeros((n4, n4), dtype=np.float64)\n    for i in range(1, n4 + 1):\n        for j in range(1, n4 + 1):\n            A4[i-1, j-1] = 1.0 / (i + j - 1)\n    x_true4 = np.ones(n4, dtype=np.float64)\n\n    test_cases = [\n        (A1, x_true1),\n        (A2, x_true2),\n        (A3, x_true3),\n        (A4, x_true4),\n    ]\n\n    results = []\n    for A, x_true in test_cases:\n        # Construct b = A @ x_true in double precision\n        b = A @ x_true\n        \n        # --- No Pivoting ---\n        x_np = solve_no_pivot(A.copy(), b.copy())\n        if x_np is None:\n            err_np_str = \"inf\"\n        else:\n            err_np = relative_forward_error(x_np, x_true)\n            err_np_str = f\"{err_np:.6e}\"\n        results.append(err_np_str)\n        \n        # --- Partial Pivoting ---\n        x_pp = solve_partial_pivot(A.copy(), b.copy())\n        if x_pp is None:\n            # This case should not be reached with the given test problems\n            # but is included for robustness.\n            err_pp_str = \"inf\" \n        else:\n            err_pp = relative_forward_error(x_pp, x_true)\n            err_pp_str = f\"{err_pp:.6e}\"\n        results.append(err_pp_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}