{
    "hands_on_practices": [
        {
            "introduction": "这个基础练习旨在揭示理查森外推法的核心机制。通过将该技术应用于求解一个函数的极限，你将亲手处理误差项，观察如何从两个较低精度的估算中构造出一个更高精度的结果，从而牢固掌握误差对消这一核心思想。",
            "id": "456729",
            "problem": "考虑由 $ f(h) = \\frac{\\arcsin(h) - h}{h^3} $ (对于 $ h \\neq 0 $) 定义的函数。需要使用理查森外推法来近似求解 $ f(h) $ 在 $ h \\to 0 $ 时的极限。理查森外推法是一种序列加速方法，它通过组合不同步长的近似值来消除低阶误差项。\n\n假设使用 $ f(h) $ 近似极限的误差具有关于 $ h $ 的偶数次幂的渐近展开式。使用步长 $ h $ 和 $ h/2 $，对 $ f(h) $ 应用理查森外推法，并确定所得外推表达式在 $ h \\to 0 $ 时的极限。",
            "solution": "理查森外推法假设 $ f(h) $ 具有以下形式的渐近展开式：\n$$ f(h) = L + c_2 h^2 + c_4 h^4 + O(h^6), $$  \n其中 $ L $ 是所求的极限，而 $ c_2, c_4, \\ldots $ 是常数。\n\n在步长 $ h $ 和 $ h/2 $ 处计算 $ f $ 的值：\n$$ f(h) = L + c_2 h^2 + c_4 h^4 + O(h^6), $$  \n$$ f\\left(\\frac{h}{2}\\right) = L + c_2 \\left(\\frac{h}{2}\\right)^2 + c_4 \\left(\\frac{h}{2}\\right)^4 + O(h^6) = L + \\frac{c_2}{4} h^2 + \\frac{c_4}{16} h^4 + O(h^6). $$  \n\n构造一个线性组合以消除 $ h^2 $ 项：\n$$ R(h) = a f(h) + b f\\left(\\frac{h}{2}\\right), $$  \n其中 $ a $ 和 $ b $ 的选择需要满足：\n1. 常数项为 $ L $：$ a + b = 1 $。\n2. $ h^2 $ 的系数为零：$ a c_2 h^2 + b \\left( \\frac{c_2}{4} h^2 \\right) = 0 $，化简为 $ a + \\frac{b}{4} = 0 $。\n\n求解方程组：\n$$ a + b = 1, $$  \n$$ a + \\frac{b}{4} = 0. $$  \n用第一个方程减去第二个方程：\n$$ (a + b) - \\left(a + \\frac{b}{4}\\right) = 1 - 0 \\implies \\frac{3b}{4} = 1 \\implies b = \\frac{4}{3}. $$  \n代入第一个方程：\n$$ a + \\frac{4}{3} = 1 \\implies a = 1 - \\frac{4}{3} = -\\frac{1}{3}. $$  \n因此，外推表达式为：\n$$ R(h) = -\\frac{1}{3} f(h) + \\frac{4}{3} f\\left(\\frac{h}{2}\\right) = \\frac{4 f\\left(\\frac{h}{2}\\right) - f(h)}{3}. $$  \n\n需要求解 $ R(h) $ 在 $ h \\to 0 $ 时的极限。由于 $ R(h) $ 消除了 $ h^2 $ 项，它比 $ f(h) $ 更快地收敛到 $ L $。然而，为了显式地求出 $ L $，我们使用 $ \\arcsin(h) $ 的泰勒级数展开：\n$$ \\arcsin(h) = h + \\frac{1}{6} h^3 + \\frac{3}{40} h^5 + O(h^7). $$  \n代入 $ f(h) $：\n$$ f(h) = \\frac{\\left( h + \\frac{1}{6} h^3 + \\frac{3}{40} h^5 + O(h^7) \\right) - h}{h^3} = \\frac{\\frac{1}{6} h^3 + \\frac{3}{40} h^5 + O(h^7)}{h^3} = \\frac{1}{6} + \\frac{3}{40} h^2 + O(h^4). $$  \n同理，\n$$ f\\left(\\frac{h}{2}\\right) = \\frac{1}{6} + \\frac{3}{40} \\left(\\frac{h}{2}\\right)^2 + O(h^4) = \\frac{1}{6} + \\frac{3}{40} \\cdot \\frac{h^2}{4} + O(h^4) = \\frac{1}{6} + \\frac{3}{160} h^2 + O(h^4). $$  \n\n现在代入 $ R(h) $：\n$$ 4 f\\left(\\frac{h}{2}\\right) = 4 \\left( \\frac{1}{6} + \\frac{3}{160} h^2 + O(h^4) \\right) = \\frac{4}{6} + \\frac{12}{160} h^2 + O(h^4) = \\frac{2}{3} + \\frac{3}{40} h^2 + O(h^4), $$  \n$$ f(h) = \\frac{1}{6} + \\frac{3}{40} h^2 + O(h^4). $$  \n因此，\n$$ 4 f\\left(\\frac{h}{2}\\right) - f(h) = \\left( \\frac{2}{3} + \\frac{3}{40} h^2 \\right) - \\left( \\frac{1}{6} + \\frac{3}{40} h^2 \\right) + O(h^4) = \\frac{2}{3} - \\frac{1}{6} + \\left( \\frac{3}{40} - \\frac{3}{40} \\right) h^2 + O(h^4) = \\frac{4}{6} - \\frac{1}{6} + O(h^4) = \\frac{3}{6} + O(h^4) = \\frac{1}{2} + O(h^4). $$  \n所以，\n$$ R(h) = \\frac{4 f\\left(\\frac{h}{2}\\right) - f(h)}{3} = \\frac{ \\frac{1}{2} + O(h^4) }{3} = \\frac{1}{6} + O(h^4). $$  \n\n取 $ h \\to 0 $ 时的极限：\n$$ \\lim_{h \\to 0} R(h) = \\frac{1}{6}. $$",
            "answer": "$$ \\boxed{\\dfrac{1}{6}} $$"
        },
        {
            "introduction": "从理论走向实践，这个练习要求你改进一个求解常微分方程（ODE）的基础数值方法。你将运用理查森外推法，将一阶精度的前向欧拉法提升为二阶精度的求解器，这正是计算科学中开发高效、稳健工具的常用策略。通过动手编程，你将亲眼见证精度的显著提升。",
            "id": "2433093",
            "problem": "设计并实现一个复合数值方法。对于一个形为 $y^{\\prime}(t) = f(t,y)$、初始条件为 $y(t_0) = y_0$ 的常微分方程初值问题，该方法能自动对一个基本的一阶单步方法应用一步 Richardson 外推，以加速在指定最终时间 $T$ 上的全局误差的收敛速度。该基本方法必须是前向欧拉法，它使用均匀时间步长 $h = (T - t_0)/N$（对于某个整数 $N \\geq 1$）从 $t_n$ 推进到 $t_{n+1}$。该复合方法必须使用步长 $h$ 和 $h/2$（即分别使用 $N$ 步和 $2N$ 步）执行两次基本方法，然后在同一最终时间 $T$ 组合这两个近似值，以消去全局误差中的主阶项，而不使用任何预先指定的高阶公式。您的实现不得调用任何内置的常微分方程求解器。\n\n原则要求：\n- 从初值问题 $y^{\\prime}(t) = f(t,y)$ 及 $y(t_0) = y_0$ 的基本定义，以及单步法在时间 $T$ 的全局误差（定义为数值近似解与精确解 $y(T)$ 之差）的定义出发。\n- 仅假设关于精度阶的经过充分检验的事实：对于足够光滑的 $f$，前向欧拉法的全局误差与步长 $h$ 线性相关，即当 $h \\to 0$ 时，全局误差为 $\\mathcal{O}(h)$。\n- 应用单步 Richardson 思想：使用步长 $h$ 和 $h/2$ 计算出的两个近似值，并将它们组合起来，以消去全局误差中的主阶 $\\mathcal{O}(h)$ 项，从而在相同的光滑性假设下，得到一个误差与 $\\mathcal{O}(h^2)$ 成比例的近似值。不要在问题陈述中假设或使用任何“快捷”公式；相反，您的程序必须实现通用的步长减半和相消原理。\n\n角度单位要求：\n- 每当出现三角函数时，将其参数解释为弧度。\n\n测试套件：\n实现您的复合方法，并在以下四个初值问题上进行评估。对每种情况，计算：\n- 使用 $N$ 步在 $T$ 处的基本前向欧拉近似值，\n- 使用 $2N$ 步在 $T$ 处的基本前向欧拉近似值，\n- 通过从两个近似值中消去主阶 $\\mathcal{O}(h)$ 全局误差项而在 $T$ 处构造的外推近似值，\n- 使用 $N$ 步的基本方法的绝对全局误差，记为 $E_{\\mathrm{base}} = \\lvert Y_h(T) - y(T) \\rvert$，\n- 外推近似值的绝对全局误差，记为 $E_{\\mathrm{extra}} = \\lvert Y_{\\mathrm{extra}}(T) - y(T) \\rvert$，\n- 改进因子 $\\rho = E_{\\mathrm{base}}/E_{\\mathrm{extra}}$。\n\n四个测试用例如下：\n1. $f(t,y) = -y$, $t_0 = 0$, $y_0 = 1$, $T = 1$, $N = 10$。精确解 $y(t) = e^{-t}$。\n2. $f(t,y) = \\sin(t)$, $t_0 = 0$, $y_0 = 0$, $T = 1$, $N = 5$。精确解 $y(t) = 1 - \\cos(t)$。\n3. $f(t,y) = -15\\,y$, $t_0 = 0$, $y_0 = 1$, $T = 1$, $N = 10$。精确解 $y(t) = e^{-15 t}$。\n4. $f(t,y) = -y$, $t_0 = 0$, $y_0 = 1$, $T = 1$, $N = 1$。精确解 $y(t) = e^{-t}$。\n\n所有涉及三角函数的量都必须使用弧度。不涉及物理单位。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含按上述顺序列出的四个测试用例的改进因子 $\\rho$，四舍五入到六位小数，形式为用方括号括起来的逗号分隔列表，例如 $[\\rho_1,\\rho_2,\\rho_3,\\rho_4]$。\n- 每个 $\\rho$ 都必须是一个浮点数。\n\n您提交的必须是一个单一、完整、可运行的程序，该程序遵循稍后描述的执行环境，不接受任何输入，并严格按照上述格式输出一行。",
            "solution": "该问题被确定为有效。这是一个适定且在科学上合理的数值分析练习。我们将进行有原则的推导和实现。\n\n目标是为由常微分方程 $y^{\\prime}(t) = f(t,y)$ 和初始条件 $y(t_0) = y_0$ 定义的初值问题构造一个数值方法。目标是在最终时间 $T$ 处近似解 $y(T)$。\n\n指定的基本算法是前向欧拉法。这是一个单步法，它在离散时间点 $t_n = t_0 + n \\cdot h$ 生成一系列对真实解 $y(t_n)$ 的近似值 $Y_n$。步长 $h$ 是均匀的，由 $h = (T - t_0)/N$ 给出，其中 $N$ 是指定的步数。前向欧拉法的递推关系源自解在 $t_n$ 附近的一阶泰勒展开：\n$y(t_{n+1}) = y(t_n) + h \\cdot y'(t_n) + \\mathcal{O}(h^2)$。\n通过代入 $y'(t_n) = f(t_n, y(t_n))$ 并截断高阶项，我们得到数值格式：\n$$Y_{n+1} = Y_n + h \\cdot f(t_n, Y_n)$$\n其中 $Y_0 = y_0$。经过 $N$ 步后，此过程产生对真实解 $y(T)$ 的一个近似值 $Y_N$。我们把这个近似值记作 $Y_h(T)$。\n\n数值分析中的一个已知结果是，对于一个足够光滑的函数 $f$，前向欧拉法的全局误差有一个关于步长 $h$ 幂次的渐近展开。设 $Y(T)$ 为在时间 $T$ 的精确解。数值近似解 $Y_h(T)$ 可以表示为：\n$$Y_h(T) = Y(T) + C_1 h + C_2 h^2 + C_3 h^3 + \\dots$$\n其中系数 $C_k$ 依赖于函数 $f$ 及其导数，但与 $h$ 无关。误差的主项是 $C_1 h$，这确立了该方法的精度阶为 $1$，即全局误差为 $\\mathcal{O}(h)$。\n\n任务要求应用 Richardson 外推来提高此精度。这通过使用两种不同的步长计算解来实现。我们使用给定的步长 $h$（对应 $N$ 步）和减半的步长 $h/2$（对应 $2N$ 步）。设在时间 $T$ 的相应近似值分别为 $Y_h(T)$ 和 $Y_{h/2}(T)$。根据误差展开式，我们有：\n1. $Y_h(T) = Y(T) + C_1 h + C_2 h^2 + \\mathcal{O}(h^3)$\n2. $Y_{h/2}(T) = Y(T) + C_1 (h/2) + C_2 (h/2)^2 + \\mathcal{O}(h^3) = Y(T) + \\frac{1}{2} C_1 h + \\frac{1}{4} C_2 h^2 + \\mathcal{O}(h^3)$\n\n目标是找到 $Y_h(T)$ 和 $Y_{h/2}(T)$ 的一个线性组合，以消去主误差项 $C_1 h$。我们寻求一个形为 $\\alpha Y_{h/2}(T) + \\beta Y_h(T)$ 的外推近似值 $Y_{\\mathrm{extra}}(T)$，它能更好地逼近 $Y(T)$。为保证相容性，如果基本方法是精确的，那么该近似值也必须是精确的，这意味着 $\\alpha + \\beta = 1$。为了消去 $\\mathcal{O}(h)$ 误差项，组合误差展开式中 $C_1 h$ 的系数之和必须为零：\n$\\alpha (\\frac{1}{2}) + \\beta (1) = 0$。\n\n我们得到一个关于系数 $\\alpha$ 和 $\\beta$ 的二元线性方程组：\n$$\n\\begin{cases}\n\\alpha + \\beta = 1 \\\\\n\\frac{1}{2}\\alpha + \\beta = 0\n\\end{cases}\n$$\n用第一个方程减去第二个方程，得到 $\\frac{1}{2}\\alpha = 1$，即 $\\alpha = 2$。将此代入第一个方程，得到 $2 + \\beta = 1$，所以 $\\beta = -1$。\n\n因此，外推近似值由以下公式给出：\n$$Y_{\\mathrm{extra}}(T) = 2 Y_{h/2}(T) - Y_h(T)$$\n让我们验证这个新近似值的误差。误差为 $Y_{\\mathrm{extra}}(T) - Y(T)$。\n$Y_{\\mathrm{extra}}(T) - Y(T) = (2 Y_{h/2}(T) - Y_h(T)) - Y(T)$\n$Y_{\\mathrm{extra}}(T) - Y(T) = 2(Y_{h/2}(T) - Y(T)) - (Y_h(T) - Y(T))$\n使用误差展开式：\n$Y_{\\mathrm{extra}}(T) - Y(T) = 2 \\left( \\frac{1}{2} C_1 h + \\frac{1}{4} C_2 h^2 + \\mathcal{O}(h^3) \\right) - (C_1 h + C_2 h^2 + \\mathcal{O}(h^3))$\n$Y_{\\mathrm{extra}}(T) - Y(T) = (C_1 h + \\frac{1}{2} C_2 h^2 + \\mathcal{O}(h^3)) - (C_1 h + C_2 h^2 + \\mathcal{O}(h^3))$\n$Y_{\\mathrm{extra}}(T) - Y(T) = -\\frac{1}{2} C_2 h^2 + \\mathcal{O}(h^3)$\n\n现在主误差项为 $\\mathcal{O}(h^2)$ 阶，这证实了外推方法的精度阶为 $2$。\n\n实现将包含一个函数，该函数对给定的步数执行前向欧拉积分。该函数将被调用两次：一次使用 $N$ 步，另一次使用 $2N$ 步。然后，使用推导出的公式组合所得的近似值 $Y_h(T)$ 和 $Y_{h/2}(T)$ 来计算 $Y_{\\mathrm{extra}}(T)$。最后，计算绝对全局误差 $E_{\\mathrm{base}} = \\lvert Y_h(T) - y(T) \\rvert$ 和 $E_{\\mathrm{extra}} = \\lvert Y_{\\mathrm{extra}}(T) - y(T) \\rvert$，并对每个测试用例确定它们的比率 $\\rho = E_{\\mathrm{base}} / E_{\\mathrm{extra}}$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of applying Richardson extrapolation to the forward Euler method\n    for several ODE test cases and computes the error improvement factor.\n    \"\"\"\n\n    def forward_euler(f, t0, y0, T, N):\n        \"\"\"\n        Solves y'(t) = f(t, y) using the forward Euler method.\n        \n        Args:\n            f: The function defining the ODE, f(t, y).\n            t0: Initial time.\n            y0: Initial value.\n            T: Final time.\n            N: Number of steps.\n\n        Returns:\n            The numerical approximation of y(T).\n        \"\"\"\n        if N == 0:\n            return y0\n        \n        h = (T - t0) / N\n        t = t0\n        y = y0\n        \n        for _ in range(N):\n            y = y + h * f(t, y)\n            t = t + h\n            \n        return y\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"f\": lambda t, y: -y,\n            \"t0\": 0.0,\n            \"y0\": 1.0,\n            \"T\": 1.0,\n            \"N\": 10,\n            \"y_exact\": lambda t: np.exp(-t)\n        },\n        {\n            \"f\": lambda t, y: np.sin(t),\n            \"t0\": 0.0,\n            \"y0\": 0.0,\n            \"T\": 1.0,\n            \"N\": 5,\n            \"y_exact\": lambda t: 1.0 - np.cos(t)\n        },\n        {\n            \"f\": lambda t, y: -15.0 * y,\n            \"t0\": 0.0,\n            \"y0\": 1.0,\n            \"T\": 1.0,\n            \"N\": 10,\n            \"y_exact\": lambda t: np.exp(-15.0 * t)\n        },\n        {\n            \"f\": lambda t, y: -y,\n            \"t0\": 0.0,\n            \"y0\": 1.0,\n            \"T\": 1.0,\n            \"N\": 1,\n            \"y_exact\": lambda t: np.exp(-t)\n        }\n    ]\n\n    rho_values = []\n\n    for case in test_cases:\n        f = case[\"f\"]\n        t0 = case[\"t0\"]\n        y0 = case[\"y0\"]\n        T = case[\"T\"]\n        N = case[\"N\"]\n        y_exact_func = case[\"y_exact\"]\n\n        # Compute the base approximation with N steps (step size h)\n        Y_h = forward_euler(f, t0, y0, T, N)\n        \n        # Compute the base approximation with 2N steps (step size h/2)\n        Y_h_div_2 = forward_euler(f, t0, y0, T, 2 * N)\n\n        # Compute the extrapolated approximation\n        Y_extra = 2.0 * Y_h_div_2 - Y_h\n\n        # Compute the exact value at the final time T\n        y_exact_at_T = y_exact_func(T)\n\n        # Compute the absolute global error of the base method\n        E_base = np.abs(Y_h - y_exact_at_T)\n        \n        # Compute the absolute global error of the extrapolated approximation\n        E_extra = np.abs(Y_extra - y_exact_at_T)\n\n        # Compute the improvement factor rho\n        if E_extra == 0.0:\n            # If extrapolated error is zero, improvement is infinite (assuming base error is not zero).\n            # This is unlikely with floating point arithmetic for these problems.\n            rho = float('inf') if E_base != 0.0 else 1.0\n        else:\n            rho = E_base / E_extra\n            \n        rho_values.append(rho)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{val:.6f}\" for val in rho_values]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "真正掌握一门技术，既要了解其威力，也要洞悉其局限。本题将挑战你分析为何理查森外推法（在此以龙贝格积分形式出现）在处理一个看似简单的绝对值函数 $|x|$ 的积分时会失效。通过深入探究被积函数的性质，你将揭示光滑性假设在误差加速方法中的关键作用。",
            "id": "2435348",
            "problem": "考虑应用龙贝格积分（Romberg integration，即在步长为 $h, h/2, h/4, \\ldots$ 的复化梯形法则基础上构建的逐次理查森外推）来计算定积分 $\\int_{-1}^{1} |x| \\, dx$。在包含 $N$ 个子区间的均匀网格上，复化梯形法则的步长为 $h = \\frac{2}{N}$。你的任务是，从被积函数的可微性以及复化梯形法则的结构出发，推断龙贝格积分对此积分是否以及为何能（或不能）加速收敛。\n\n哪个陈述最能解释这种行为？\n\nA. 被积函数 $|x|$ 在 $x=0$ 处不可微，因此龙贝格积分所依赖的偶次幂误差展开式不成立。对于复化梯形法则，其全局误差与 $N$ 的奇偶性有关：当 $N$ 为奇数时（尖点严格位于一个子区间内部），误差为 $E_N = \\frac{h^2}{4}$；当 $N$ 为偶数时（尖点与一个节点重合，每个子区间内的函数都是线性的），误差为 $E_N = 0$。由于首项误差系数在步长细化过程中不是一个固定的常数，从 $h$ 到 $h/2$ 的第一次理查森外推可能会产生一个远离精确积分值的结果。\n\nB. 龙贝格积分失败，因为该积分是反常积分且在 $x=0$ 处发散，所以任何求积法则都无法有意义地应用。\n\nC. 龙贝格积分失败，因为 $|x|$ 在对称区间上是一个奇函数，在 $x=0$ 附近的抵消作用使得外推过程无效。\n\nD. 如果初始步长 $h$ 足够小，龙贝格积分就能成功；对于足够小的 $h$，$x=0$ 处的尖点会有效消失，从而恢复龙贝格积分所需要的光滑偶次幂误差展开。\n\nE. 龙贝格积分失败，因为复化梯形法则全局只有一阶精度，因此无论光滑性如何，偶次幂的理查森外推都不适用。",
            "solution": "该问题要求分析龙贝格积分在计算定积分 $I = \\int_{-1}^{1} |x| \\, dx$ 时的表现。分析的核心在于龙贝格积分的理论基础以及被积函数 $f(x) = |x|$ 的性质。\n\n首先，我们确定该积分的精确值。被积函数 $f(x) = |x|$ 是一个偶函数，因此在对称区间 $[-1, 1]$ 上的积分可以计算如下：\n$$ I = \\int_{-1}^{1} |x| \\, dx = 2 \\int_{0}^{1} x \\, dx = 2 \\left[ \\frac{x^2}{2} \\right]_{0}^{1} = 2 \\left( \\frac{1^2}{2} - \\frac{0^2}{2} \\right) = 1 $$\n积分的精确值为 $1$。\n\n接下来，我们分析龙贝格积分的基础。龙贝格积分是一种使用理查森外推（Richardson extrapolation）来加速复化梯形法则收敛的方法。对于一个积分 $I$，步长为 $h$ 的复化梯形法则近似值 $T(h)$ 具有由欧拉-麦克劳林公式（Euler-Maclaurin formula）给出的渐近误差展开：\n$$ T(h) = I + C_1 h^2 + C_2 h^4 + C_3 h^6 + \\dots $$\n这个展开式成立的前提是被积函数 $f(x)$ 在积分区间 $[a, b]$ 上足够光滑（即具有足够多阶的连续导数）。具体来说，要使展开式只包含 $h$ 的偶次幂，被积函数及其所有奇数阶导数必须在端点 $a$ 和 $b$ 处为零，或者函数是以 $b-a$ 为周期的周期函数。对于一般的非周期函数，展开式为 $T(h) = I + C_1 h^2 + C_2 h^4 + \\dots + K_p h^{2p} + O(h^{2p+2})$，这要求被积函数至少属于 $C^{2p+2}[a, b]$ 类。\n\n本问题中的被积函数是 $f(x) = |x|$。这个函数处处连续。然而，它的一阶导数是符号函数 $f'(x) = \\text{sgn}(x)$，在 $x=0$ 处有一个跳跃间断点。\n$$ f'(x) = \\begin{cases} -1  \\text{if } x  0 \\\\ 1  \\text{if } x > 0 \\end{cases} $$\n由于 $f'(x)$ 在 $x=0$ 处不连续，函数 $f(x)=|x|$ 不属于 $C^1[-1, 1]$ 类。因此，它也不属于 $C^2[-1, 1]$ 类。标准的欧拉-麦克劳林误差展开式的基本光滑性要求被破坏了。复化梯形法则的误差将不具有仅含 $h$ 的偶次幂的形式，因此，龙贝格积分的前提不成立。\n\n现在我们必须分析复化梯形法则对于这个特定被积函数的具体行为。该法则应用于 $[-1, 1]$ 上的一个含 $N$ 个子区间的均匀网格，步长为 $h = \\frac{2}{N}$，节点为 $x_k = -1 + k h$（$k=0, 1, \\dots, N$）。其行为关键取决于不可微点 $x=0$ 是否为网格节点。\n\n情况1：$N$ 为偶数。\n设 $N=2m$，其中 $m \\ge 1$ 为整数。步长为 $h = \\frac{2}{2m} = \\frac{1}{m}$。网格节点为 $x_k = -1 + \\frac{k}{m}$。对应于 $k=m$ 的节点是 $x_m = -1 + \\frac{m}{m} = 0$。因此，当 $N$ 为偶数时，不可微点 $x=0$ 始终是一个网格节点。复化梯形法则将每个子区间上的结果相加。在 $[-1, 0]$ 内的子区间上，被积函数是 $f(x)=-x$，是一个线性函数。在 $[0, 1]$ 内的子区间上，被积函数是 $f(x)=x$，也是一个线性函数。梯形法则对于线性函数是精确的（其误差项涉及被积函数的二阶导数，而线性函数的二阶导数为零）。因此，对于每个子区间的近似都是精确的，计算出的总积分也是精确的。当 $N$ 为偶数时，误差 $E_N = T_N - I = 0$。\n\n情况2：$N$ 为奇数。\n设 $N=2m+1$，其中 $m \\ge 0$ 为整数。步长为 $h = \\frac{2}{2m+1}$。网格节点为 $x_k = -1 + k \\frac{2}{2m+1}$。若 $x_k=0$，则需要 $-1 + k \\frac{2}{2m+1} = 0$，这意味着 $k = \\frac{2m+1}{2}$。这永远不是整数。因此，当 $N$ 为奇数时，点 $x=0$ 总是严格落在一个子区间的内部。这个子区间是 $[x_m, x_{m+1}]$，其中 $x_m = -1 + m h = \\frac{-(2m+1)+2m}{2m+1} = \\frac{-1}{2m+1}$ 且 $x_{m+1} = -1 + (m+1)h = \\frac{-(2m+1)+2m+2}{2m+1} = \\frac{1}{2m+1}$。注意，这个区间关于 $0$ 对称，长度为 $h$。复化梯形法则的误差完全来自于这单个子区间，因为在所有其他子区间上被积函数都是线性的。\n该子区间的梯形近似值为：\n$$ T_{[x_m, x_{m+1}]} = \\frac{h}{2} (f(x_m) + f(x_{m+1})) = \\frac{h}{2} \\left(\\left|\\frac{-1}{2m+1}\\right| + \\left|\\frac{1}{2m+1}\\right|\\right) = \\frac{h}{2} \\left(\\frac{1}{2m+1} + \\frac{1}{2m+1}\\right) = \\frac{h}{2} \\left(\\frac{2}{2m+1}\\right) = \\frac{h^2}{2} $$\n该子区间上的精确积分为：\n$$ I_{[x_m, x_{m+1}]} = \\int_{-1/(2m+1)}^{1/(2m+1)} |x|\\, dx = 2 \\int_0^{1/(2m+1)} x\\, dx = \\left[x^2\\right]_0^{1/(2m+1)} = \\left(\\frac{1}{2m+1}\\right)^2 = \\left(\\frac{h}{2}\\right)^2 = \\frac{h^2}{4} $$\n这个子区间的误差，也就是总误差 $E_N$，为 $E_N = T_{[x_m, x_{m+1}]} - I_{[x_m, x_{m+1}]} = \\frac{h^2}{2} - \\frac{h^2}{4} = \\frac{h^2}{4}$。当 $N$ 为奇数时，$E_N = \\frac{h^2}{4} \\ne 0$。\n\n理查森外推公式 $R_{k,1} = \\frac{4R_{k,0} - R_{k-1,0}}{3}$ 假设误差 $E(h) = C h^2 + O(h^4)$，其中 $C$ 是一个常数。我们的分析表明，误差序列是：当 $N$ 为奇数时 $E_N=h^2/4$，当 $N$ 为偶数时 $E_N=0$。当步长减半（$h \\to h/2$）时，区间数量加倍（$N \\to 2N$），如果 $N$ 是奇数，这会改变 $N$ 的奇偶性。这意味着误差项中的“常数”$C$ 并非不变，而是在交替变化。这使得外推失效。例如，如果我们从一个奇数 $N_0$（误差 $\\sim h_0^2/4$）开始，然后计算 $N_1=2N_0$（误差为 $0$），外推将产生一个很差的结果。\n\n现在，我们评估每个选项。\n\nA. 被积函数 $|x|$ 在 $x=0$ 处不可微，因此龙贝格积分所依赖的偶次幂误差展开式不成立。对于复化梯形法则，其全局误差与 $N$ 的奇偶性有关：当 $N$ 为奇数时（尖点严格位于一个子区间内部），误差为 $E_N = \\frac{h^2}{4}$；当 $N$ 为偶数时（尖点与一个节点重合，每个子区间内的函数都是线性的），误差为 $E_N = 0$。由于首项误差系数在步长细化过程中不是一个固定的常数，从 $h$ 到 $h/2$ 的第一次理查森外推可能会产生一个远离精确积分值的结果。\n这个陈述完美地总结了我们的推导过程。其中每一个论断都是正确的：不可微性、误差展开的失效、梯形法则误差的奇偶性依赖（奇数 $N$ 时 $E_N=h^2/4$，偶数 $N$ 时 $E_N=0$）、非常数的误差系数，以及由此导致的外推失败。\n结论：**正确**。\n\nB. 龙贝格积分失败，因为该积分是反常积分且在 $x=0$ 处发散，所以任何求积法则都无法有意义地应用。\n积分 $\\int_{-1}^{1} |x| \\, dx$ 是一个正常积分。被积函数 $|x|$ 在有限区间 $[-1, 1]$ 上是连续且有界的。该积分收敛于 $1$。这个陈述在事实上是错误的。\n结论：**不正确**。\n\nC. 龙贝格积分失败，因为 $|x|$ 在对称区间上是一个奇函数，在 $x=0$ 附近的抵消作用使得外推过程无效。\n函数 $f(x)=|x|$ 是一个偶函数，因为 $f(-x) = |-x| = |x| = f(x)$。该陈述的前提是错误的。\n结论：**不正确**。\n\nD. 如果初始步长 $h$ 足够小，龙贝格积分就能成功；对于足够小的 $h$，$x=0$ 处的尖点会有效消失，从而恢复龙贝格积分所需要的光滑偶次幂误差展开。\n$x=0$ 处的不可微性是函数 $|x|$ 的内在属性。它在任何尺度下都不会消失。减小步长 $h$ 不会使函数更光滑，也不会恢复所需的误差展开。依赖于奇偶性的误差行为无论 $h$ 的尺度如何都会持续存在。\n结论：**不正确**。\n\nE. 龙贝格积分失败，因为复化梯形法则全局只有一阶精度，因此无论光滑性如何，偶次幂的理查森外推都不适用。\n对于足够光滑（$C^2$）的函数，复化梯形法则是二阶精度（$O(h^2)$）的，而非一阶。在这种情况下，龙贝格积分的失败恰恰是由于光滑性问题，而该陈述却忽略了这一点。该陈述的前提是不正确的。\n结论：**不正确**。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}