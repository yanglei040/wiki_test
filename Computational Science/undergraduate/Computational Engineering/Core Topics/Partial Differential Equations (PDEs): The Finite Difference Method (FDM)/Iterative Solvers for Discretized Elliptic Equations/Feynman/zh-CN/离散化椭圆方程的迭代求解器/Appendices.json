{
    "hands_on_practices": [
        {
            "introduction": "对于由偏微分方程离散化产生的大型线性系统，显式地存储系数矩阵 $A$ 往往是不可行或效率低下的。一个关键的计算技巧是采用“无矩阵”方法，即通过一个函数来定义矩阵 $A$ 的作用，该函数计算矩阵向量乘积 $A\\mathbf{v}$ 而无需存储 $A$ 本身。本练习将指导您为经典的泊松问题实现共轭梯度（CG）方法，重点是采用这种高效的无矩阵范式，这是大规模科学计算中的一项基本技能。",
            "id": "2406207",
            "problem": "考虑一个线性系统，该系统由单位正方形上泊松方程的狄利克雷问题的标准五点有限差分格式产生。设连续问题为在 $(0,1)\\times(0,1)$ 上 $-\\Delta u = f$，并在边界上满足 $u=0$。对于一个每个坐标方向有 $n$ 个内部点的均匀网格，网格间距为 $h = \\frac{1}{n+1}$，未知数可以按字典序排列成 $\\mathbb{R}^{n^2}$ 中的一个向量。定义线性算子 $A:\\mathbb{R}^{n^2}\\to\\mathbb{R}^{n^2}$，它对应于带齐次狄利克雷边界条件的离散负拉普拉斯算子，由标准五点差分格式给出：对每个索引为 $(i,j)$（其中 $i\\in\\{1,\\dots,n\\}$ 且 $j\\in\\{1,\\dots,n\\}$）的内部网格点，其作用 $(A u)_{i,j}$ 为\n$$(A u)_{i,j} \\;=\\; \\frac{1}{h^2}\\left(4\\,u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1}\\right),$$\n根据狄利克雷边界条件，约定 $u_{0,j}=u_{n+1,j}=u_{i,0}=u_{i,n+1}=0$。$A u$ 的向量形式是通过将二维数组 $u_{i,j}$ 按行主序展平为一维数组得到的。算子 $A$ 是对称正定的。\n\n您的任务是编写一个完整的、可运行的程序，该程序针对一组测试用例，使用共轭梯度（CG）法的无矩阵实现来求解 $A u = b$。其中，对 $A$ 的唯一访问方式是通过一个计算 $v \\mapsto A v$ 的函数；不允许使用 $A$ 的任何显式稀疏或稠密矩阵表示。使用初始猜测 $u^{(0)}=0$，并在相对残差范数满足以下条件时终止：\n$$\\frac{\\|\\mathbf{r}^{(k)}\\|_2}{\\|\\mathbf{b}\\|_2} \\le \\mathrm{tol},$$\n或者当迭代次数超过预设的最大值时终止。任何三角函数的角度都必须以弧度为单位。\n\n为了使右端项与一个已知的精确离散解兼容，请使用如下构造的离散解：\n$$u_{i,j}^{\\star} \\;=\\; \\sin(\\pi x_i)\\,\\sin(\\pi y_j), \\quad x_i = i h,\\; y_j = j h,$$\n并通过将算子 $A$ 作用于 $u^{\\star}$ 来定义 $b := A u^{\\star}$，具体如上所述。对于每个测试用例，通过无矩阵求解器计算近似解 $u$，然后验证以下两个条件：\n- 最终的相对残差不大于指定的容差 $\\mathrm{tol}$。\n- 相对于 $u^{\\star}$ 的相对2-范数误差满足\n$$\\frac{\\|\\mathbf{u} - \\mathbf{u}^{\\star}\\|_2}{\\|\\mathbf{u}^{\\star}\\|_2} \\le 100\\,\\mathrm{tol}.$$\n\n测试套件：\n在以下参数对 $(n,\\mathrm{tol})$ 上评估您的程序：\n- $(1,\\,10^{-12})$，\n- $(8,\\,10^{-10})$，\n- $(32,\\,10^{-8})$，\n- $(64,\\,10^{-8})$。\n\n对于每个测试用例，返回一个布尔值，指示上述两个验证条件是否都得到满足。对于每种情况，使用等于 $n^2$ 的最大迭代次数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表，顺序与上面列出的测试用例相同。例如，如果所有测试用例都通过，则输出必须是\n\"[True,True,True,True]\"。",
            "solution": "问题陈述有效。它具有科学依据，是良态的且客观的。它提出了计算科学中的一个标准问题：使用迭代法求解由偏微分方程的有限差分格式导出的线性系统。所有参数和条件都已明确指定，足以得到一个唯一且可验证的解。\n\n任务是使用共轭梯度（CG）法的无矩阵实现来求解线性方程组 $A \\mathbf{u} = \\mathbf{b}$。该系统源于单位正方形 $\\Omega = (0,1) \\times (0,1)$ 上泊松方程 $-\\Delta u = f$ 的五点有限差分格式，并带有齐次狄利克雷边界条件，即在 $\\partial\\Omega$ 上 $u=0$。\n\n对于一个在每个坐标方向上有 $n$ 个内部点的均匀网格，网格间距为 $h = \\frac{1}{n+1}$。离散算子 $A$ 表示负拉普拉斯算子，它将网格点上的函数映射到另一个函数。它在内部点 $(i,j)$（其中 $i,j \\in \\{1, \\ldots, n\\}$）对网格函数 $u$ 的作用由五点差分格式给出：\n$$ (A u)_{i,j} = \\frac{1}{h^2} \\left( 4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1} \\right). $$\n通过设置当 $i$ 或 $j$ 为 $0$ 或 $n+1$ 时 $u_{i,j}=0$ 来引入 $u=0$ 的边界条件。由此产生的算子 $A$ 是对称正定的（SPD），这是共轭梯度法收敛的必要条件。\n\n该问题使用“精确解方法”（Method of Manufactured Solutions）来构造，以提供一个具有已知精确离散解的案例。指定的精确解为：\n$$ u_{i,j}^{\\star} = \\sin(\\pi x_i) \\sin(\\pi y_j), \\quad \\text{where } x_i = i h \\text{ and } y_j = j h. $$\n然后，右端项向量 $\\mathbf{b}$ 定义为 $\\mathbf{b} = A \\mathbf{u}^{\\star}$，它是通过将离散算子 $A$ 作用于已知解 $\\mathbf{u}^{\\star}$ 来计算的。\n\n解决方案的核心是共轭梯度算法。该算法是迭代的，特别适用于矩阵 $A$ 是对称正定的大型稀疏系统。这里的一个关键要求是实现必须是“无矩阵”的，意味着矩阵 $A$ 从未被显式构造或存储。取而代之的是，其作用 $\\mathbf{v} \\mapsto A\\mathbf{v}$ 由一个函数提供。\n\n算法流程如下：\n1. 初始化解向量 $\\mathbf{u}^{(0)} = \\mathbf{0}$。\n2. 计算初始残差 $\\mathbf{r}^{(0)} = \\mathbf{b} - A \\mathbf{u}^{(0)} = \\mathbf{b}$。\n3. 设置初始搜索方向 $\\mathbf{p}^{(0)} = \\mathbf{r}^{(0)}$。\n4. 对于 $k = 0, 1, 2, \\dots$，迭代直至收敛：\n    a. 计算矩阵向量乘积 $\\mathbf{v}^{(k)} = A \\mathbf{p}^{(k)}$。\n    b. 计算步长 $\\alpha_k = \\frac{\\mathbf{r}^{(k)T} \\mathbf{r}^{(k)}}{\\mathbf{p}^{(k)T} \\mathbf{v}^{(k)}}$。\n    c. 更新解：$\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + \\alpha_k \\mathbf{p}^{(k)}$。\n    d. 更新残差：$\\mathbf{r}^{(k+1)} = \\mathbf{r}^{(k)} - \\alpha_k \\mathbf{v}^{(k)}$。\n    e. 检查收敛性：如果 $\\frac{\\|\\mathbf{r}^{(k+1)}\\|_2}{\\|\\mathbf{b}\\|_2} \\le \\mathrm{tol}$，则终止。\n    f. 计算搜索方向的改进因子：$\\beta_k = \\frac{\\mathbf{r}^{(k+1)T} \\mathbf{r}^{(k+1)}}{\\mathbf{r}^{(k)T} \\mathbf{r}^{(k)}}$。\n    g. 更新搜索方向：$\\mathbf{p}^{(k+1)} = \\mathbf{r}^{(k+1)} + \\beta_k \\mathbf{p}^{(k)}$。\n\n该实现将 $A$ 的作用封装在一个专用函数中。此函数接受一个大小为 $n^2$ 的一维向量，在内部将其重塑为一个 $n \\times n$ 的二维网格，表示内部点上的解值。为了高效地应用五点差分格式，该网格用零进行填充，以表示齐次狄利克雷边界条件。然后，使用向量化的数组操作在填充后的网格上应用差分格式。得到的 $n \\times n$ 网格被展平回一个大小为 $n^2$ 的一维向量并返回。\n\n对于由参数对 $(n, \\mathrm{tol})$ 定义的每个测试用例，程序首先设置网格、无矩阵算子函数以及构造解 $\\mathbf{u}^{\\star}$ 及其对应的右端项 $\\mathbf{b}$。然后，以最大 $n^2$ 次迭代调用CG求解器。\n\n求解器终止后，会检查两个验证条件：\n1. 最终相对残差范数 $\\frac{\\|\\mathbf{r}^{(\\text{final})}\\|_2}{\\|\\mathbf{b}\\|_2}$ 必须小于或等于预设的容差 $\\mathrm{tol}$。\n2. 计算解 $\\mathbf{u}$ 与精确离散解 $\\mathbf{u}^{\\star}$ 之间的相对误差（以欧几里得范数衡量）$\\frac{\\|\\mathbf{u} - \\mathbf{u}^{\\star}\\|_2}{\\|\\mathbf{u}^{\\star}\\|_2}$ 不得超过 $100 \\times \\mathrm{tol}$。\n\n对于每个测试用例，会确定一个布尔结果，如果两个条件都满足则为`True`，否则为`False`。最终输出是这些布尔值的列表。",
            "answer": "```python\nimport numpy as np\n\ndef create_operator(n, h):\n    \"\"\"\n    Creates a matrix-free function for the 5-point discrete Laplacian operator A.\n\n    Args:\n        n (int): Number of interior grid points per dimension.\n        h (float): Grid spacing.\n\n    Returns:\n        A function that computes the matrix-vector product A*u.\n    \"\"\"\n    def A_op(u_vec):\n        \"\"\"\n        Applies the discrete Laplacian operator A to a vector u_vec.\n\n        Args:\n            u_vec (np.ndarray): A 1D vector of size n*n representing grid values.\n\n        Returns:\n            np.ndarray: The result of A*u_vec as a 1D vector.\n        \"\"\"\n        if n == 0:\n            return np.array([])\n        \n        # Reshape the 1D vector to a 2D grid\n        u_grid = u_vec.reshape((n, n))\n        \n        # Pad the grid with zeros to handle boundary conditions\n        u_padded = np.zeros((n + 2, n + 2))\n        u_padded[1:-1, 1:-1] = u_grid\n        \n        # Apply the 5-point stencil using vectorized operations\n        # The stencil is (4*u_ij - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1})\n        Au_grid = (4 * u_padded[1:-1, 1:-1] -\n                   u_padded[0:-2, 1:-1] -  # u_{i-1,j}\n                   u_padded[2:, 1:-1]   -  # u_{i+1,j}\n                   u_padded[1:-1, 0:-2] -  # u_{i,j-1}\n                   u_padded[1:-1, 2:])      # u_{i,j+1}\n        \n        # Scale by 1/h^2\n        Au_grid /= h**2\n        \n        # Flatten the resulting 2D grid back to a 1D vector\n        return Au_grid.flatten()\n    \n    return A_op\n\ndef cg_solver(A_op, b, tol, max_iter):\n    \"\"\"\n    Solves A*u = b using the Conjugate Gradient method.\n\n    Args:\n        A_op (callable): Matrix-free operator for A.\n        b (np.ndarray): Right-hand side vector.\n        tol (float): Convergence tolerance for the relative residual.\n        max_iter (int): Maximum number of iterations.\n\n    Returns:\n        tuple: A tuple containing the solution vector u and the final residual vector r.\n    \"\"\"\n    u = np.zeros_like(b)\n    r = b.copy()\n    p = r.copy()\n    rs_old = np.dot(r, r)\n    \n    b_norm = np.linalg.norm(b)\n    if b_norm == 0:\n        return u, r  # Trivial case: if b is zero, solution is zero.\n\n    for _ in range(max_iter):\n        Ap = A_op(p)\n        alpha = rs_old / np.dot(p, Ap)\n        \n        u += alpha * p\n        r -= alpha * Ap\n        \n        rs_new = np.dot(r, r)\n        \n        if np.sqrt(rs_new) / b_norm <= tol:\n            break\n            \n        p = r + (rs_new / rs_old) * p\n        rs_old = rs_new\n        \n    return u, r\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and produce the final output.\n    \"\"\"\n    test_cases = [\n        (1, 1e-12),\n        (8, 1e-10),\n        (32, 1e-8),\n        (64, 1e-8),\n    ]\n\n    results = []\n    for n, tol in test_cases:\n        h = 1.0 / (n + 1)\n        max_iter = n * n\n        \n        # 1. Create the matrix-free operator for A\n        A_op = create_operator(n, h)\n        \n        # 2. Create the manufactured solution u_star and right-hand side b = A*u_star\n        # The problem states u*_ij = sin(pi*x_i)*sin(pi*y_j) where x_i=ih, y_j=jh.\n        # This implies relating the first grid index to x and second to y.\n        i_coords = np.arange(1, n + 1) * h\n        j_coords = np.arange(1, n + 1) * h\n        # Use 'ij' indexing so grid[i,j] corresponds to (i_coords[i], j_coords[j])\n        xx, yy = np.meshgrid(i_coords, j_coords, indexing='ij')\n        \n        u_star_grid = np.sin(np.pi * xx) * np.sin(np.pi * yy)\n        u_star_vec = u_star_grid.flatten()\n        \n        b_vec = A_op(u_star_vec)\n        \n        # 3. Solve the system A*u = b using the CG solver\n        u_sol, r_final = cg_solver(A_op, b_vec, tol, max_iter)\n        \n        # 4. Perform verification\n        b_norm = np.linalg.norm(b_vec)\n        u_star_norm = np.linalg.norm(u_star_vec)\n\n        # Verification 1: Final relative residual\n        final_rel_res = np.linalg.norm(r_final) / b_norm if b_norm > 0 else 0.0\n        check1 = final_rel_res <= tol\n\n        # Verification 2: Relative error with respect to manufactured solution\n        rel_error = np.linalg.norm(u_sol - u_star_vec) / u_star_norm if u_star_norm > 0 else 0.0\n        check2 = rel_error <= 100 * tol\n        \n        # Both checks must pass\n        results.append(check1 and check2)\n\n    # Print the final result in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "虽然共轭梯度法功能强大，但其收敛速度严重依赖于系统矩阵 $A$ 的条件数，对于病态问题可能会非常缓慢。预条件处理是一种强大的加速技术，通过将原系统转化为一个条件数更优的等价系统来解决此问题。本练习将引导您实现对称逐次超松弛（SSOR）方法作为预条件子，并将其集成到共轭梯度求解器中，通过直接比较预处理前后求解器的性能，您将亲身体验预条件处理的有效性。",
            "id": "2406195",
            "problem": "考虑单位正方形 $\\Omega = (0,1)\\times(0,1)$ 上标量场 $u(x,y)$ 的椭圆边值问题，其带有齐次 Dirichlet 边界条件：\n$$\n-\\Delta u(x,y) = f(x,y)\\ \\text{在}\\ \\Omega,\\qquad u(x,y)=0\\ \\text{在}\\ \\partial\\Omega\\ \\text{上}.\n$$\n使用标准的五点有限差分法，在每个坐标方向有 $n$ 个内部点的均匀网格上对该问题进行离散化。令 $h = \\frac{1}{n+1}$ 表示网格间距。在每个内部网格点 $(i,j)$ 处，其中 $i,j\\in\\{1,2,\\dots,n\\}$ 且 $(x_i,y_j) = (ih,jh)$，离散方程为\n$$\n4\\,u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1} = h^2 f(x_i,y_j).\n$$\n对未知数进行字典序排序后，可得到一个维度为 $N \\times N$ 的线性系统 $A \\mathbf{u} = \\mathbf{b}$，其中 $N = n^2$，且 $A$ 是对称正定矩阵。在本问题中，取 $f(x,y) \\equiv 1$，因此向量 $\\mathbf{b}$ 的每个分量都等于 $h^2$。\n\n对给定的松弛参数 $\\omega \\in (0,2)$，对称逐次超松弛（SSOR）预条件子定义如下。将矩阵 $A$ 分解为 $A = D + L + U$，其中 $D$ 是 $A$ 的对角部分，$L$ 是 $A$ 的严格下三角部分，$U$ 是 $A$ 的严格上三角部分。SSOR 预条件子 $M(\\omega)$ 为\n$$\nM(\\omega) = (D + \\omega L)\\, D^{-1}\\, (D + \\omega U).\n$$\n\n你的任务是实现一个程序，对每个指定的测试用例 $(n,\\omega)$，使用以下方法求解线性系统 $A \\mathbf{u} = \\mathbf{b}$：\n- 无预条件的共轭梯度（CG）法，以及\n- 使用 SSOR 预条件子 $M(\\omega)$ 的预条件共轭梯度法。\n\n对这两种求解器，均使用零向量作为初始猜测，并在相对残差范数满足以下条件时停止：\n$$\n\\frac{\\lVert \\mathbf{r}_k \\rVert_2}{\\lVert \\mathbf{b} \\rVert_2} \\le 10^{-8},\n$$\n或者当迭代次数达到最大允许迭代次数 $N = n^2$ 时停止，以先发生者为准。对于每个测试用例，报告无预条件 CG 和 SSOR 预条件 CG 满足停止准则所需的迭代次数。\n\n使用实数运算。所有结果均为无量纲；不需要物理单位。\n\n测试集：\n- 用例 $1$：$(n,\\omega) = (16, 1.0)$。\n- 用例 $2$：$(n,\\omega) = (16, 1.5)$。\n- 用例 $3$：$(n,\\omega) = (32, 1.5)$。\n- 用例 $4$：$(n,\\omega) = (8, 1.9)$。\n- 用例 $5$：$(n,\\omega) = (8, 0.5)$。\n\n你的程序应生成单行输出，其中包含所有用例的结果，格式为逗号分隔的列表之列表。每个内部列表包含恰好两个整数，对应于该用例的 $[\\text{无预条件 CG 迭代次数}, \\text{SSOR 预条件 CG 迭代次数}]$，并严格按照测试集的顺序排列。例如，输出格式必须为\n$$\n[[k_1^{\\mathrm{CG}},k_1^{\\mathrm{SSOR}}],[k_2^{\\mathrm{CG}},k_2^{\\mathrm{SSOR}}],\\dots,[k_5^{\\mathrm{CG}},k_5^{\\mathrm{SSOR}}]].\n$$",
            "solution": "对问题陈述进行了严格审查，并确认其有效。这是一个计算工程领域的标准、适定问题，具体涉及由椭圆偏微分方程离散化所产生的线性系统的迭代求解。所有定义、参数和目标都以科学和数学的精度进行了陈述。不存在矛盾、歧义或不成立的前提。\n\n任务是使用两种方法求解线性系统 $A\\mathbf{u}=\\mathbf{b}$：共轭梯度（CG）法和使用对称逐次超松弛（SSOR）预条件子的预条件共轭梯度（PCG）法。该系统源于在单位正方形上，对带有齐次 Dirichlet 边界条件的泊松方程 $-\\Delta u = 1$ 进行的五点有限差分离散。\n\n解决方案的实现遵循以下设计原则：\n\n1.  **系统特性**：通过五点格式和字典序排序得到的矩阵 $A$ 是一个大型、稀疏、块三对角、对称正定（SPD）矩阵。其对角线元素为 $4$，对应于网格邻居的非对角线元素为 $-1$。向量 $\\mathbf{b}$ 的所有分量均等于 $h^2$，其中 $h = \\frac{1}{n+1}$ 是网格间距。\n\n2.  **无矩阵实现**：为了高效处理大维度 $N=n^2$，不显式构造矩阵 $A$。而是实现一个函数来计算矩阵向量乘积 $A\\mathbf{v}$。该函数将 $N$ 维向量 $\\mathbf{v}$ 重塑为 $n \\times n$ 网格，应用五点格式算子同时强制施加零边界条件，并返回得到的 $N$ 维向量。\n\n3.  **共轭梯度（CG）算法**：采用标准的 CG 方法实现。该方法适用于像 $A\\mathbf{u}=\\mathbf{b}$ 这样的对称正定系统。从初始猜测 $\\mathbf{u}_0 = \\mathbf{0}$ 开始，该算法生成一系列迭代解，以最小化误差的 $A$-范数。当残差的相对 L2-范数 $\\frac{\\lVert \\mathbf{r}_k \\rVert_2}{\\lVert \\mathbf{b} \\rVert_2}$ 降至容差 $10^{-8}$ 以下，或迭代次数达到最大值 $N$ 时，过程终止。\n\n4.  **SSOR 预处理**：SSOR 预条件子由 $M(\\omega) = (D + \\omega L) D^{-1} (D + \\omega U)$ 给出，其中 $A = D+L+U$ 是将矩阵 $A$ 分解为其对角部分（$D$）、严格下三角部分（$L$）和严格上三角部分（$U$）。对于本问题，有 $D=4I$。PCG 算法的核心是应用预条件子的逆，即求解系统 $M\\mathbf{z}=\\mathbf{r}$ 以得到 $\\mathbf{z}$。这通过两个步骤完成：\n    a. 一次前向替换，求解 $(D + \\omega L) \\mathbf{v} = \\mathbf{r}$ 以获得中间向量 $\\mathbf{v}$。在网格上，这对应于一次前向扫描：\n    $$v_{i,j} = \\frac{1}{4} (r_{i,j} + \\omega(v_{i-1,j} + v_{i,j-1}))$$\n    b. 一次后向替换，求解 $(D + \\omega U) \\mathbf{z} = D \\mathbf{v}$ 以获得结果 $\\mathbf{z}$。在网格上，这对应于一次后向扫描：\n    $$z_{i,j} = v_{i,j} + \\frac{\\omega}{4}(z_{i+1,j} + z_{i,j+1})$$\n    实现一个专用函数，通过这两次扫描来计算 $\\mathbf{z} = M^{-1}\\mathbf{r}$。\n\n5.  **预条件共轭梯度（PCG）算法**：通过将 SSOR 预条件子求解步骤集成到标准 CG 框架中来实现 PCG 方法。这等效于将 CG 应用于条件更好的系统 $M^{-1}A\\mathbf{u} = M^{-1}\\mathbf{b}$。其停止准则与无预条件 CG 方法的相同。\n\n对于每个测试用例 $(n, \\omega)$，计算并记录 CG 和 PCG 所需的迭代次数。最终输出将这些结果汇总成指定的列表之列表格式。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _matvec_A(v_1d, n):\n    \"\"\"\n    Computes the matrix-vector product A*v for the 2D Poisson problem.\n    The matrix A is not formed explicitly.\n    \"\"\"\n    v_2d = v_1d.reshape((n, n))\n    # Pad with 0 for homogeneous Dirichlet boundary conditions.\n    v_padded = np.pad(v_2d, pad_width=1, mode='constant', constant_values=0)\n    # Apply the 5-point stencil corresponding to the negative Laplacian.\n    av_2d = (4 * v_2d \n             - v_padded[1:-1, 0:-2]  # Left neighbor\n             - v_padded[1:-1, 2:]    # Right neighbor\n             - v_padded[0:-2, 1:-1]  # Bottom neighbor\n             - v_padded[2:, 1:-1])   # Top neighbor\n    return av_2d.flatten()\n\ndef _solve_ssor(r_1d, n, omega):\n    \"\"\"\n    Solves the SSOR preconditioning system Mz=r, returning z = M^-1 * r.\n    The preconditioner is M = (D + w*L) * D^-1 * (D + w*U), with D=4I.\n    This is solved via two sweeps: a forward substitution followed by a backward substitution.\n    \"\"\"\n    r_2d = r_1d.reshape((n, n))\n    \n    # --- Step 1: Forward substitution ---\n    # Solves (D + w*L)v = r, which is (4I + w*L)v = r.\n    # On the grid, this is: 4*v_ij - w*v_{i-1,j} - w*v_{i,j-1} = r_ij\n    v_2d = np.zeros((n, n))\n    for j in range(n):\n        for i in range(n):\n            v_left = v_2d[i - 1, j] if i > 0 else 0.0\n            v_down = v_2d[i, j - 1] if j > 0 else 0.0\n            v_2d[i, j] = (r_2d[i, j] + omega * (v_left + v_down)) / 4.0\n            \n    # --- Step 2: Backward substitution ---\n    # Solves (D + w*U)z = D*v, which is (4I + w*U)z = 4v.\n    # On the grid, this is: 4*z_ij - w*z_{i+1,j} - w*z_{i,j+1} = 4*v_ij\n    z_2d = np.zeros((n, n))\n    for j in range(n - 1, -1, -1):\n        for i in range(n - 1, -1, -1):\n            z_right = z_2d[i + 1, j] if i < n - 1 else 0.0\n            z_up = z_2d[i, j + 1] if j < n - 1 else 0.0\n            z_2d[i, j] = v_2d[i, j] + (omega / 4.0) * (z_right + z_up)\n            \n    return z_2d.flatten()\n\ndef _run_cg(n, b, b_norm, tol, max_iter):\n    \"\"\"Runs the unpreconditioned Conjugate Gradient solver.\"\"\"\n    x = np.zeros_like(b)\n    r = np.copy(b)  # Since x_0 is zero, r_0 = b - A*0 = b\n    p = np.copy(r)\n    rs_old = np.dot(r, r)\n\n    if np.sqrt(rs_old) / b_norm <= tol:\n        return 0\n\n    for i in range(max_iter):\n        ap = _matvec_A(p, n)\n        alpha = rs_old / np.dot(p, ap)\n        x += alpha * p\n        r -= alpha * ap\n        rs_new = np.dot(r, r)\n        \n        if np.sqrt(rs_new) / b_norm <= tol:\n            return i + 1\n            \n        p = r + (rs_new / rs_old) * p\n        rs_old = rs_new\n\n    return max_iter\n\ndef _run_pcg(n, omega, b, b_norm, tol, max_iter):\n    \"\"\"Runs the Preconditioned Conjugate Gradient solver with SSOR.\"\"\"\n    x = np.zeros_like(b)\n    r = np.copy(b)  # Since x_0 is zero, r_0 = b\n    \n    if b_norm == 0 or np.linalg.norm(r) / b_norm <= tol:\n        return 0\n\n    z = _solve_ssor(r, n, omega)\n    p = np.copy(z)\n    rz_old = np.dot(r, z)\n    \n    for i in range(max_iter):\n        ap = _matvec_A(p, n)\n        alpha = rz_old / np.dot(p, ap)\n        x += alpha * p\n        r -= alpha * ap\n        \n        if np.linalg.norm(r) / b_norm <= tol:\n            return i + 1\n            \n        z = _solve_ssor(r, n, omega)\n        rz_new = np.dot(r, z)\n        \n        if rz_old == 0:\n            return i + 1\n\n        p = z + (rz_new / rz_old) * p\n        rz_old = rz_new\n    \n    return max_iter\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, omega)\n        (16, 1.0),\n        (16, 1.5),\n        (32, 1.5),\n        (8, 1.9),\n        (8, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, omega = case\n        \n        # Setup problem parameters\n        N = n * n\n        h = 1.0 / (n + 1)\n        tol = 1e-8\n        max_iter = N\n\n        # Right-hand side vector b\n        b = (h**2) * np.ones(N)\n        b_norm = np.linalg.norm(b)\n\n        # Run unpreconditioned CG\n        cg_iters = _run_cg(n, b, b_norm, tol, max_iter)\n        \n        # Run SSOR-preconditioned CG\n        pcg_iters = _run_pcg(n, omega, b, b_norm, tol, max_iter)\n        \n        results.append([cg_iters, pcg_iters])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "许多现实世界的工程和物理问题涉及多个相互作用的场，其离散化后会产生具有明显块状结构的线性系统。针对这类系统，将经典的迭代思想从逐点更新推广到逐块更新是一种自然而有效的方法。本练习将介绍块雅可比（Block-Jacobi）和块高斯-赛德尔（Block-Gauss-Seidel）方法，并指导您为耦合椭圆问题实现这些方法，从而将您的技能扩展到求解更复杂的多物理场问题。",
            "id": "2406140",
            "problem": "考虑一个分块线性系统，该系统源于在带齐次Dirichlet边界条件的均匀方形网格上对一个双场椭圆算子进行离散化。令 $m \\in \\mathbb{N}$ 为每个空间方向上的内部网格点数，并令 $h = \\frac{1}{m+1}$。定义一维二阶差分矩阵 $T \\in \\mathbb{R}^{m \\times m}$ 为\n$$\nT = \\frac{1}{h^2}\\operatorname{tridiag}(-1,\\,2,\\,-1),\n$$\n以及二维离散负拉普拉斯算子 $L \\in \\mathbb{R}^{m^2 \\times m^2}$ 为\n$$\nL = I_m \\otimes T \\;+\\; T \\otimes I_m,\n$$\n其中 $I_m$ 表示大小为 $m$ 的单位矩阵，$\\otimes$ 表示Kronecker积。对于一个固定的标量 $\\sigma > 0$，令\n$$\nK = L + \\sigma I_{m^2}.\n$$\n给定耦合参数 $\\alpha \\in \\mathbb{R}$，定义分块矩阵 $A \\in \\mathbb{R}^{(2m^2)\\times(2m^2)}$ 为\n$$\nA \\;=\\;\n\\begin{bmatrix}\nK & \\alpha I_{m^2}\\\\\n\\alpha I_{m^2} & K\n\\end{bmatrix}.\n$$\n令精确离散场在内部网格点上逐分量地由下式给出\n$$\nu^{\\star}(x_i,y_j) = \\sin(\\pi x_i)\\sin(\\pi y_j), \\quad v^{\\star}(x_i,y_j) = \\sin(2\\pi x_i)\\sin(\\pi y_j),\n$$\n其中 $x_i = i h$，$y_j = j h$，且 $i,j \\in \\{1,2,\\dots,m\\}$。将这些值按字典序堆叠以获得向量 $u^{\\star}, v^{\\star} \\in \\mathbb{R}^{m^2}$，并定义右端项 $b \\in \\mathbb{R}^{2m^2}$ 为\n$$\n\\begin{bmatrix}b_1 \\\\ b_2\\end{bmatrix}\n=\nA\n\\begin{bmatrix}u^{\\star} \\\\ v^{\\star}\\end{bmatrix},\n\\quad \\text{即，}\\quad\nb_1 = Ku^{\\star} + \\alpha v^{\\star}, \\;\\; b_2 = \\alpha u^{\\star} + K v^{\\star}.\n$$\n\n设初始猜测为 $\\mathbb{R}^{2m^2}$ 中的零向量，停止容差为相对残差阈值 $\\tau = 10^{-8}$，其中在迭代步 $x^{(k)} \\in \\mathbb{R}^{2m^2}$ 的相对残差为\n$$\n\\rho^{(k)} \\;=\\; \\frac{\\|b - A x^{(k)}\\|_2}{\\|b\\|_2}.\n$$\n当满足 $\\rho^{(k)} \\le \\tau$ 的最小 $k$ 出现时，或当达到 $k_{\\max} = 10000$ 次迭代的最大次数时，终止迭代。\n\n现考虑两种分块不动点迭代。将一次通用迭代记为 $x^{(k)} = \\begin{bmatrix} u^{(k)} \\\\ v^{(k)} \\end{bmatrix}$，其中 $u^{(k)}, v^{(k)} \\in \\mathbb{R}^{m^2}$。\n\n- 选项A（分块对角分裂）：对每个迭代索引 $k \\ge 0$，计算\n$$\nu^{(k+1)} = K^{-1}\\left(b_1 - \\alpha v^{(k)}\\right), \\qquad\nv^{(k+1)} = K^{-1}\\left(b_2 - \\alpha u^{(k)}\\right).\n$$\n\n- 选项B（分块下三角分裂）：对每个迭代索引 $k \\ge 0$，计算\n$$\nu^{(k+1)} = K^{-1}\\left(b_1 - \\alpha v^{(k)}\\right), \\qquad\nv^{(k+1)} = K^{-1}\\left(b_2 - \\alpha u^{(k+1)}\\right).\n$$\n\n在两种选项中，$K^{-1}(\\cdot)$ 代表精确求解（在数值精度范围内）一个系数矩阵为 $K$ 的线性系统。量 $b_1$ 和 $b_2$ 的定义如上。\n\n测试套件。对所有用例使用 $\\sigma = 1$、零初始猜测以及上文定义的容差和最大迭代次数。评估以下五个测试用例，每个用例由数对 $(m,\\alpha)$ 和选项标签指定：\n1. $(m,\\alpha,\\text{Option}) = (8,\\,0.5,\\,\\text{A})$，\n2. $(m,\\alpha,\\text{Option}) = (8,\\,0.5,\\,\\text{B})$，\n3. $(m,\\alpha,\\text{Option}) = (1,\\,0.0,\\,\\text{A})$，\n4. $(m,\\alpha,\\text{Option}) = (12,\\,0.9,\\,\\text{A})$，\n5. $(m,\\alpha,\\text{Option}) = (12,\\,0.9,\\,\\text{B})$。\n\n对于每个测试用例，报告一个包含两个值的列表：终止时的迭代次数 $k$（一个整数）和最终的相对残差 $\\rho^{(k)}$（一个浮点数）。您的程序应生成单行输出，其中包含五个测试用例的结果，格式为一个包含在方括号内的逗号分隔列表，每个单独的测试用例结果以上述相同顺序显示为一个双元素列表。例如，所需的整体输出格式为\n$$\n[\\,[k_1,\\rho_1],[k_2,\\rho_2],[k_3,\\rho_3],[k_4,\\rho_4],[k_5,\\rho_5]\\,].\n$$\n此问题不涉及物理单位，三角函数中隐式出现的任何角度都必须以弧度为单位进行解释。",
            "solution": "在尝试求解之前，该问题经过了严格的验证过程。\n\n**步骤1：提取已知条件**\n从问题陈述中逐字提取的已知条件如下：\n- 网格参数: $m \\in \\mathbb{N}$\n- 网格间距: $h = \\frac{1}{m+1}$\n- 一维矩阵: $T = \\frac{1}{h^2}\\operatorname{tridiag}(-1,\\,2,\\,-1) \\in \\mathbb{R}^{m \\times m}$\n- 二维矩阵: $L = I_m \\otimes T \\;+\\; T \\otimes I_m \\in \\mathbb{R}^{m^2 \\times m^2}$\n- 移位参数: $\\sigma > 0$\n- 移位矩阵: $K = L + \\sigma I_{m^2}$\n- 耦合参数: $\\alpha \\in \\mathbb{R}$\n- 分块矩阵: $A \\;=\\; \\begin{bmatrix} K & \\alpha I_{m^2}\\\\ \\alpha I_{m^2} & K \\end{bmatrix} \\in \\mathbb{R}^{(2m^2)\\times(2m^2)}$\n- 精确离散场: $u^{\\star}(x_i,y_j) = \\sin(\\pi x_i)\\sin(\\pi y_j)$ 和 $v^{\\star}(x_i,y_j) = \\sin(2\\pi x_i)\\sin(\\pi y_j)$，其中 $x_i = i h$, $y_j = j h$, 且 $i,j \\in \\{1,2,\\dots,m\\}$。这些场被堆叠成向量 $u^{\\star}, v^{\\star} \\in \\mathbb{R}^{m^2}$。\n- 右端向量: $\\mathbf{b} = A\\begin{bmatrix}\\mathbf{u}^{\\star} \\\\ \\mathbf{v}^{\\star}\\end{bmatrix}$，其分量为 $\\mathbf{b}_1 = K\\mathbf{u}^{\\star} + \\alpha \\mathbf{v}^{\\star}$ 和 $\\mathbf{b}_2 = \\alpha \\mathbf{u}^{\\star} + K \\mathbf{v}^{\\star}$。\n- 初始条件: $\\mathbf{x}^{(0)} = \\mathbf{0} \\in \\mathbb{R}^{2m^2}$\n- 终止容差: $\\tau = 10^{-8}$\n- 最大迭代次数: $k_{\\max} = 10000$\n- 相对残差公式: $\\rho^{(k)} = \\frac{\\|\\mathbf{b} - A \\mathbf{x}^{(k)}\\|_2}{\\|\\mathbf{b}\\|_2}$\n- 迭代选项A（分块Jacobi）: $\\mathbf{u}^{(k+1)} = K^{-1}(\\mathbf{b}_1 - \\alpha \\mathbf{v}^{(k)})$, $\\mathbf{v}^{(k+1)} = K^{-1}(\\mathbf{b}_2 - \\alpha \\mathbf{u}^{(k)})$\n- 迭代选项B（分块Gauss-Seidel）: $\\mathbf{u}^{(k+1)} = K^{-1}(\\mathbf{b}_1 - \\alpha \\mathbf{v}^{(k)})$, $\\mathbf{v}^{(k+1)} = K^{-1}(\\mathbf{b}_2 - \\alpha \\mathbf{u}^{(k+1)})$\n- 所有测试用例的常数: $\\sigma = 1$。\n- 测试套件:\n  1. $(m,\\alpha,\\text{Option}) = (8,\\,0.5,\\,\\text{A})$\n  2. $(m,\\alpha,\\text{Option}) = (8,\\,0.5,\\,\\text{B})$\n  3. $(m,\\alpha,\\text{Option}) = (1,\\,0.0,\\,\\text{A})$\n  4. $(m,\\alpha,\\text{Option}) = (12,\\,0.9,\\,\\text{A})$\n  5. $(m,\\alpha,\\text{Option}) = (12,\\,0.9,\\,\\text{B})$\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学基础（关键）：** 该问题在基本上是合理的。它描述了在均匀网格上通过有限差分法离散化的耦合椭圆偏微分方程组的数值解。矩阵 $T$ 和 $L$ 分别是一维和二维负拉普拉斯算子的标准离散表示。分块矩阵 $A$ 是耦合场问题的典型特征。迭代求解策略，即选项A和选项B，可立即识别为分块Jacobi法和分块Gauss-Seidel法。这些都是数值分析和计算工程中的经典课题。\n- **适定性：** 矩阵 $T$ 是一个已知的正定对称Toeplitz矩阵。因此，Kronecker和 $L = I_m \\otimes T + T \\otimes I_m$ 也是对称正定的。当 $\\sigma = 1 > 0$ 时，矩阵 $K = L + \\sigma I_{m^2}$ 是对称且严格正定的，这保证了其可逆性。因此，涉及 $K$ 的线性求解是适定的。完整矩阵 $A$ 是对称的。其特征值是 $K \\pm \\alpha I_{m^2}$ 的特征值。对于所有指定的测试用例，参数 $(m, \\alpha)$ 确保 $|\\alpha|$ 小于 $K$ 的最小特征值，这意味着 $A$ 也是对称正定的。因此，线性系统 $A\\mathbf{x}=\\mathbf{b}$ 有唯一解。\n- **客观性（关键）：** 问题的定义具有数学上的精确性和严谨性，不含主观、模糊或非科学的语言。\n\n**步骤3：结论与行动**\n问题有效。它具有科学依据、适定性及客观性。将构建一个完整的解决方案。\n\n**方法论与求解推导**\n任务是使用两种不同的分块迭代法求解线性系统 $A\\mathbf{x}=\\mathbf{b}$，其中 $\\mathbf{x}=\\begin{bmatrix} \\mathbf{u} \\\\ \\mathbf{v} \\end{bmatrix}$。求解过程的实现方式是，首先建立离散系统，然后执行指定的迭代算法，直到满足终止准则。\n\n1.  **系统构建：**\n    对于给定的网格参数 $m$，计算网格尺寸 $h = 1/(m+1)$。子问题的规模为 $N = m^2$。\n    构建 $m \\times m$ 矩阵 $T$。\n    使用Kronecker积规则 $L=I_m \\otimes T + T \\otimes I_m$ 形成 $N \\times N$ 的离散拉普拉斯算子 $L$。\n    组装移位矩阵 $K = L + \\sigma I_N$，其中 $\\sigma=1$。由于 $K$ 是对称正定（SPD）的，为了提高效率，一次性计算其Cholesky分解 $K=R^T R$（其中 $R$ 是上三角矩阵）。然后，通过求解 $R^T\\mathbf{z}=\\mathbf{y}$（前向代入）和 $R\\mathbf{x}=\\mathbf{z}$（后向代入）来执行 $K^{-1}\\mathbf{y}$ 操作。\n    构建完整的 $2N \\times 2N$ 系统矩阵 $A$。\n\n2.  **右端项（RHS）构建：**\n    这是一个制造解问题。精确解 $\\mathbf{x}^{\\star} = \\begin{bmatrix}\\mathbf{u}^{\\star} \\\\ \\mathbf{v}^{\\star}\\end{bmatrix}$ 是已知的。\n    生成一个点网格 $(x_i, y_j)=(ih, jh)$，其中 $i,j \\in \\{1,\\dots,m\\}$。\n    在此网格上计算精确解场 $u^{\\star}$ 和 $v^{\\star}$。这些 $m \\times m$ 的数值数组通过字典序展平为 $N \\times 1$ 的向量。\n    RHS向量 $\\mathbf{b}$ 通过 $\\mathbf{b} = A \\mathbf{x}^{\\star}$ 计算得出。这确保了 $\\mathbf{x}^{\\star}$ 是离散系统 $A\\mathbf{x}=\\mathbf{b}$ 的真实解。范数 $\\|\\mathbf{b}\\|_2$ 被预先计算，用于相对残差的计算。\n\n3.  **迭代求解：**\n    迭代从零向量 $\\mathbf{x}^{(0)} = \\mathbf{0}$ 开始。对于 $k \\ge 1$，从 $\\mathbf{x}^{(k-1)}$ 计算迭代值 $\\mathbf{x}^{(k)}$ 的过程取决于所选的选项。令 $\\mathbf{x}^{(k)} = \\begin{bmatrix} \\mathbf{u}^{(k)} \\\\ \\mathbf{v}^{(k)} \\end{bmatrix}$。\n\n    - **选项A（分块Jacobi）：** $\\mathbf{u}^{(k)}$ 和 $\\mathbf{v}^{(k)}$ 的更新仅依赖于上一步迭代的值 $\\mathbf{x}^{(k-1)}$。\n    $$\n    \\mathbf{u}^{(k)} = K^{-1}\\left(\\mathbf{b}_1 - \\alpha \\mathbf{v}^{(k-1)}\\right) \\\\\n    \\mathbf{v}^{(k)} = K^{-1}\\left(\\mathbf{b}_2 - \\alpha \\mathbf{u}^{(k-1)}\\right)\n    $$\n    这对应于分裂 $A=M-N$，其中 $M_{\\text{J}} = \\operatorname{diag}(K,K)$。\n\n    - **选项B（分块Gauss-Seidel）：** $\\mathbf{v}^{(k)}$ 的更新使用了最新计算出的值 $\\mathbf{u}^{(k)}$。\n    $$\n    \\mathbf{u}^{(k)} = K^{-1}\\left(\\mathbf{b}_1 - \\alpha \\mathbf{v}^{(k-1)}\\right) \\\\\n    \\mathbf{v}^{(k)} = K^{-1}\\left(\\mathbf{b}_2 - \\alpha \\mathbf{u}^{(k)}\\right)\n    $$\n    这对应于分裂 $A=M-N$，其中 $M_{\\text{GS}}$ 是 $A$ 的分块下三角部分。\n\n4.  **终止准则：**\n    对于每次迭代 $k=1, 2, \\dots, k_{\\max}$，计算新的迭代值 $\\mathbf{x}^{(k)}$。评估相对残差 $\\rho^{(k)} = \\|\\mathbf{b} - A \\mathbf{x}^{(k)}\\|_2 / \\|\\mathbf{b}\\|_2$。如果 $\\rho^{(k)} \\le \\tau = 10^{-8}$，则迭代终止并报告数对 $[k, \\rho^{(k)}]$。如果循环完成至 $k=k_{\\max}$ 仍未满足容差，则报告最终值 $[k_{\\max}, \\rho^{(k_{\\max})}]$。\n\n对于问题中指定的每个测试用例，实现将精确遵循这些步骤。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import cho_factor, cho_solve\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        (8, 0.5, 'A'),\n        (8, 0.5, 'B'),\n        (1, 0.0, 'A'),\n        (12, 0.9, 'A'),\n        (12, 0.9, 'B'),\n    ]\n\n    sigma = 1.0\n    tau = 1e-8\n    k_max = 10000\n\n    results = []\n    for m, alpha, option in test_cases:\n        result = run_iteration(m, alpha, option, sigma, tau, k_max)\n        results.append(result)\n\n    # Format the final output string as a list of lists.\n    # str() on a list uses single quotes, which is fine, but we will be robust.\n    formatted_results = [f\"[{k},{res}]\" for k, res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef run_iteration(m, alpha, option, sigma, tau, k_max):\n    \"\"\"\n    Performs the iterative solution for a single test case.\n    \n    Args:\n        m (int): Number of interior grid points per direction.\n        alpha (float): Coupling parameter.\n        option (str): 'A' for block-Jacobi, 'B' for block-Gauss-Seidel.\n        sigma (float): Shift parameter for matrix K.\n        tau (float): Relative residual tolerance.\n        k_max (int): Maximum number of iterations.\n        \n    Returns:\n        list: A list containing [number_of_iterations, final_relative_residual].\n    \"\"\"\n    m_sq = m * m\n    h = 1.0 / (m + 1.0)\n    \n    # 1. System Construction\n    \n    # 1D second-difference matrix T\n    diag_T = np.full(m, 2.0)\n    offdiag_T = np.full(m - 1, -1.0)\n    T = (np.diag(diag_T) + np.diag(offdiag_T, k=1) + np.diag(offdiag_T, k=-1)) / h**2\n    \n    # 2D discrete Laplacian L\n    I_m = np.identity(m)\n    L = np.kron(I_m, T) + np.kron(T, I_m)\n    \n    # Shifted matrix K\n    I_msq = np.identity(m_sq)\n    K = L + sigma * I_msq\n    \n    # Full system matrix A\n    A = np.block([\n        [K, alpha * I_msq],\n        [alpha * I_msq, K]\n    ])\n    \n    # Pre-compute Cholesky factorization of K for efficient solves\n    cho_K = cho_factor(K)\n\n    # 2. Right-Hand Side (RHS) Formulation\n    \n    # Grid points\n    i = np.arange(1, m + 1)\n    grid_pts = i * h\n    x_grid, y_grid = np.meshgrid(grid_pts, grid_pts)\n\n    # Exact solution fields u_star, v_star\n    u_star_grid = np.sin(np.pi * x_grid) * np.sin(np.pi * y_grid)\n    v_star_grid = np.sin(2 * np.pi * x_grid) * np.sin(np.pi * y_grid)\n    \n    # Flatten to vectors in lexicographic order\n    u_star_vec = u_star_grid.flatten()\n    v_star_vec = v_star_grid.flatten()\n    \n    # Full exact solution vector and RHS\n    x_star = np.concatenate([u_star_vec, v_star_vec])\n    b = A @ x_star\n    b1 = b[:m_sq]\n    b2 = b[m_sq:]\n    b_norm = np.linalg.norm(b, 2)\n    \n    if b_norm == 0: # Avoid division by zero\n        return [0, 0.0]\n\n    # 3. Iterative Solution\n    \n    x_k = np.zeros(2 * m_sq) # Initial guess x^(0)\n    \n    # Check initial residual (for k=0)\n    res_vec = b - A @ x_k\n    rho = np.linalg.norm(res_vec, 2) / b_norm\n    if rho <= tau:\n        return [0, rho]\n        \n    for k in range(1, k_max + 1):\n        u_prev = x_k[:m_sq]\n        v_prev = x_k[m_sq:]\n        \n        # Compute x^(k)\n        if option == 'A': # Block-Jacobi\n            u_next = cho_solve(cho_K, b1 - alpha * v_prev)\n            v_next = cho_solve(cho_K, b2 - alpha * u_prev)\n        elif option == 'B': # Block-Gauss-Seidel\n            u_next = cho_solve(cho_K, b1 - alpha * v_prev)\n            v_next = cho_solve(cho_K, b2 - alpha * u_next)\n        else: # Should not happen\n            raise ValueError(\"Invalid option specified.\")\n            \n        x_k = np.concatenate([u_next, v_next])\n        \n        # Check termination criteria\n        res_vec = b - A @ x_k\n        rho = np.linalg.norm(res_vec, 2) / b_norm\n        \n        if rho <= tau:\n            return [k, rho]\n            \n    # If loop finishes, return result at k_max\n    return [k_max, rho]\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}