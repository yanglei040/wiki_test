{
    "hands_on_practices": [
        {
            "introduction": "要掌握自适应求解器，第一步是理解其核心机制。本练习将引导你通过一次手动的单步计算，来精确地观察嵌入式方法对如何生成误差估计，以及该估计值与方法的真实局部误差有何关系。通过这个基于纸笔的练习，你将为后续更复杂的编程任务奠定坚实的理论基础。",
            "id": "2388725",
            "problem": "考虑一个右端项为分段多项式的常微分方程 (ODE) 的初值问题：\n$$\n\\frac{dy}{dt} = f(t), \\quad y(0)=0,\n$$\n其中\n$$\nf(t) = \\begin{cases}\nt^{2},  0 \\le t \\le \\frac{1}{2} \\\\\n\\frac{1}{4} + \\left(t - \\frac{1}{2}\\right),  \\frac{1}{2} \\le t \\le 1\n\\end{cases}\n$$\n该右端项确保了解析解 $y(t)$ 在 $[0,1]$ 上是一个简单的分段多项式。\n\n一个数值求解器采用了一个嵌入式龙格-库塔 (RK) 对，该方法对由一阶显式欧拉法和二阶霍恩法组成。对于从 $t_{0}=0$ 到 $t_{1}=h$（其中 $0  h  \\frac{1}{2}$）的一个单步，请计算以下比值：\n$$\nR = \\frac{y(t_{1}) - y^{[1]}_{1}}{\\hat{e}_{1}}\n$$\n这里 $y(t_1)$ 是在时间 $t_1$ 处的精确解，$y^{[1]}_{1}$ 是由一阶方法得到的数值近似值，而 $\\hat{e}_{1} = y^{[2]}_{1} - y^{[1]}_{1}$ 是由两个数值解 $y^{[2]}_{1}$（二阶）和 $y^{[1]}_{1}$（一阶）构成的局部误差估计。\n\n请以最简分数的形式给出您的答案。",
            "solution": "该问题陈述经检验，具有科学依据、是适定且客观的。这是常微分方程数值分析中的一个标准问题，包含了获得唯一解所需的所有信息。其中没有矛盾或歧义。我们将开始推导。\n\n任务是确定精确比值 $R = \\frac{y(t_{1}) - y^{[1]}_{1}}{\\hat{e}_{1}}$，其中 $y(t_{1})$ 是在时间 $t_{1}$ 处的精确解，$y^{[1]}_{1}$ 是由一阶方法得到的数值近似值，而 $\\hat{e}_{1}$ 是嵌入式误差估计。单步从 $t_{0}=0$ 到 $t_{1}=h$，约束条件为 $0  h  \\frac{1}{2}$。初始条件是 $y(0)=0$。\n\n首先，我们确定初值问题 (IVP) 的精确解 $y(t)$。该 IVP 由下式给出\n$$\n\\frac{dy}{dt} = f(t), \\quad y(0)=0.\n$$\n对于积分区间 $[0, h]$，由于 $h  \\frac{1}{2}$，右端函数由第一种情况给出：\n$$\nf(t) = t^{2}, \\quad \\text{for } t \\in [0, h].\n$$\n我们通过直接积分来求解这个简化的 ODE：\n$$\ny(t) = \\int_{0}^{t} f(s) ds = \\int_{0}^{t} s^{2} ds = \\left[ \\frac{s^{3}}{3} \\right]_{0}^{t} = \\frac{t^{3}}{3}.\n$$\n在步末 $t_{1}=h$ 处，解的精确值为\n$$\ny(t_{1}) = y(h) = \\frac{h^{3}}{3}.\n$$\n\n接下来，我们使用所提供的嵌入式龙格-库塔对来计算数值近似值。该步从 $(t_{0}, y_{0})$ 开始，其中 $t_{0}=0$ 且 $y_{0}=y(0)=0$。\n\n级 $k_{1}$ 和 $k_{2}$ 的计算如下：\n第一级是：\n$$\nk_{1} = f(t_{0}, y_{0}) = f(0, 0) = 0^{2} = 0.\n$$\n注意，对于此问题，$f$ 只是 $t$ 的函数，因此 $f(t, y) = f(t)$。\n第二级是：\n$$\nk_{2} = f(t_{0}+h, y_{0} + h k_{1}) = f(0+h, 0 + h \\cdot 0) = f(h) = h^{2}.\n$$\n\n现在我们求出在 $t_{1}=h$ 处解的两个数值近似值。\n使用显式欧拉法的一阶近似值 $y^{[1]}_{1}$ 是：\n$$\ny^{[1]}_{1} = y_{0} + h k_{1} = 0 + h(0) = 0.\n$$\n使用霍恩法的二阶近似值 $y^{[2]}_{1}$ 是：\n$$\ny^{[2]}_{1} = y_{0} + \\frac{h}{2}(k_{1}+k_{2}) = 0 + \\frac{h}{2}(0 + h^{2}) = \\frac{h^{3}}{2}.\n$$\n\n根据这些结果，我们可以计算比值 $R$ 所需的各项。\n分子是一阶 (欧拉) 法的真实局部截断误差：\n$$\ny(t_{1}) - y^{[1]}_{1} = y(h) - y^{[1]}_{1} = \\frac{h^{3}}{3} - 0 = \\frac{h^{3}}{3}.\n$$\n分母是求解器的嵌入式局部误差估计：\n$$\n\\hat{e}_{1} = y^{[2]}_{1} - y^{[1]}_{1} = \\frac{h^{3}}{2} - 0 = \\frac{h^{3}}{2}.\n$$\n\n最后，我们计算比值 $R$：\n$$\nR = \\frac{y(t_{1}) - y^{[1]}_{1}}{\\hat{e}_{1}} = \\frac{\\frac{h^{3}}{3}}{\\frac{h^{3}}{2}}.\n$$\n由于 $h>0$，分子和分母中的 $h^{3}$ 项相互抵消：\n$$\nR = \\frac{1/3}{1/2} = \\frac{1}{3} \\cdot \\frac{2}{1} = \\frac{2}{3}.\n$$\n此结果与步长 $h$ 无关（在指定范围内），并且按要求是一个最简分数。",
            "answer": "$$\n\\boxed{\\frac{2}{3}}\n$$"
        },
        {
            "introduction": "在理解了误差估计的理论后，让我们将其付诸实践，构建一个完整的自适应求解器。此练习要求你实现著名的 Bogacki–Shampine 方法，并探究一个关键问题：一个有缺陷的局部误差估计器将如何影响求解器的全局精度？这个实验将生动地展示一个正确设计的误差控制器对于可靠的数值积分是何等重要。",
            "id": "2388676",
            "problem": "设计并实现一个基于嵌入式龙格-库塔对的自适应步长积分器，以研究不正确的局部误差估计如何影响全局误差。纯粹在常微分方程初值问题的数学背景下进行研究。您必须使用的基本依据是初值问题、局部截断误差的定义以及显式龙格-库塔方法的结构。\n\n问题要求：\n- 考虑一个由 $y'(t) = f(t,y(t))$ 和 $y(t_{0}) = y_{0}$ 给出的标量常微分方程初值问题。目标是从 $t_{0}$ 推进到最终时间 $T$。\n- 使用一个显式嵌入式龙格-库塔对，其中两个不同阶的公式共享相同的内部级，以在每一步提供两个近似值 $y_{n+1}$ 和 $\\hat{y}_{n+1}$。高阶近似值 $y_{n+1}$ 用作步长结果，其差值 $e_{n+1} = y_{n+1} - \\hat{y}_{n+1}$ 用作步长控制的局部误差估计。\n- 实现一个特定的、广泛使用的阶数为 $p$ 和 $q$（其中 $p  q$）的配对；为确保具体性和可复现性，请使用阶数为 $p=q+1$ 的 Bogacki–Shampine 对，即 $p = 3$ 和 $q = 2$。当一个步长被接受时，使用高阶近似值来推进解。\n- 实现两个版本的自adaptive控制器：\n  1. 正确的控制器使用低阶公式的正确嵌入式系数来计算局部误差估计 $e_{n+1}$。\n  2. 有缺陷的控制器通过有意更改嵌入式低阶权重来计算一个有缺陷的局部误差估计 $\\hat{e}_{n+1}$，具体如下：在形成差值之前，交换低阶规则的最后两个权重。换言之，如果低阶权重为 $\\{b_{1}^{(q)}, b_{2}^{(q)}, b_{3}^{(q)}, b_{4}^{(q)}\\}$，则有缺陷的控制器在构造 $\\hat{y}_{n+1}$ 时使用 $\\{b_{1}^{(q)}, b_{2}^{(q)}, b_{4}^{(q)}, b_{3}^{(q)}\\}$，因此 $\\hat{e}_{n+1} = y_{n+1} - \\hat{y}_{n+1}$。仅在步长接受和步长选择时使用此有缺陷的估计，而在接受步长后，仍使用高阶近似值 $y_{n+1}$ 来推进解。\n- 对标量状态使用标准误差范数：\n  $$\\mathrm{err\\_norm} = \\frac{|e_{n+1}|}{\\mathrm{atol} + \\mathrm{rtol} \\cdot \\max(|y_{n}|, |y_{n+1}|)}.$$\n  如果 $\\mathrm{err\\_norm} \\le 1$，则接受该步长。\n- 使用一个从 $p$ 阶方法的局部截断误差缩放中导出的步长控制器。如果一个步长被接受或拒绝，则提出一个新的步长\n  $$h_{\\mathrm{new}} = h \\cdot s \\cdot \\mathrm{err\\_norm}^{-1/(p+1)},$$\n  其中 $s$ 是一个安全因子。将 $h_{\\mathrm{new}}$ 限制在 $[\\alpha_{\\min} h, \\alpha_{\\max} h]$ 范围内，以避免不稳定的变化。使用 $p = 3$，$s = 0.9$，$\\alpha_{\\min} = 0.2$ 和 $\\alpha_{\\max} = 5$。\n- 在接受的步长上，使用 Bogacki–Shampine 对的高阶公式来推进解。对两个控制器使用相同的初始步长和控制器参数。\n\n测试问题与精确解：\n- 令 $f(t,y) = \\lambda y$，其中 $\\lambda  0$，$y(0) = 1$，精确解为 $y(t) = \\exp(\\lambda t)$。\n- 将最终时间 $T$ 时的全局误差定义为\n  $$E = |y_{\\mathrm{num}}(T) - y_{\\mathrm{exact}}(T)|.$$\n\n测试套件：\n提供以下参数集的结果，这些参数集构成测试套件（以下所有数字均为无量纲）：\n- A 例（正常路径）：$\\lambda = -1$, $T = 10$, $y_{0} = 1$, $\\mathrm{rtol} = 10^{-3}$, $\\mathrm{atol} = 10^{-12}$。\n- B 例（更严格的容差）：$\\lambda = -1$, $T = 10$, $y_{0} = 1$, $\\mathrm{rtol} = 10^{-6}$, $\\mathrm{atol} = 10^{-12}$。\n- C 例（衰减更快的动力学）：$\\lambda = -5$, $T = 2$, $y_{0} = 1$, $\\mathrm{rtol} = 10^{-6}$, $\\mathrm{atol} = 10^{-12}$。\n\n每种情况需要计算的内容：\n- 计算两个浮点数：\n  - $E_{\\mathrm{correct}}$：使用正确控制器得到的最终时间绝对误差。\n  - $E_{\\mathrm{flawed}}$：使用有缺陷控制器得到的最终时间绝对误差。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，并且本身是一个双元素列表 $[E_{\\mathrm{correct}}, E_{\\mathrm{flawed}}]$。例如：[[EcA,EfA],[EcB,EfB],[EcC,EfC]]。以一致、紧凑的十进制格式打印数值。",
            "solution": "对所提供的问题进行了严格的验证。\n\n**第 1 步：提取已知条件**\n- **初值问题 (IVP)**：一个标量常微分方程 (ODE) $y'(t) = f(t,y(t))$，其初始条件为 $y(t_0) = y_0$，将从 $t_{0}$ 积分到最终时间 $T$。\n- **数值方法**：一个显式嵌入式龙格-库塔对，阶数为 $p=3$ 和 $q=2$，具体为 Bogacki–Shampine 对。高阶（$p=3$）近似值 $y_{n+1}$ 用于推进解。\n- **局部误差估计**：高阶近似值 ($y_{n+1}$) 与低阶近似值 ($\\hat{y}_{n+1}$) 之间的差值 $e_{n+1} = y_{n+1} - \\hat{y}_{n+1}$ 作为局部截断误差的估计。\n- **控制器**：\n    1.  **正确的控制器**：使用标准的局部误差估计 $e_{n+1}$。\n    2.  **有缺陷的控制器**：使用一个有缺陷的估计 $\\hat{e}_{n+1} = y_{n+1} - \\hat{y}_{n+1, \\text{flawed}}$，其中 $\\hat{y}_{n+1, \\text{flawed}}$ 是通过交换低阶权重的最后两个元素计算得出的。这个有缺陷的估计仅用于步长控制。\n- **误差范数与接受条件**：缩放后的误差范数定义为 $\\mathrm{err\\_norm} = |e_{n+1}| / (\\mathrm{atol} + \\mathrm{rtol} \\cdot \\max(|y_{n}|, |y_{n+1}|))$。如果 $\\mathrm{err\\_norm} \\le 1$，则接受该步长。\n- **步长控制律**：新步长按 $h_{\\mathrm{new}} = h \\cdot s \\cdot \\mathrm{err\\_norm}^{-1/(p+1)}$ 提出，其中 $s = 0.9$，$p = 3$。结果被裁剪到 $[\\alpha_{\\min} h, \\alpha_{\\max} h]$ 范围内，其中 $\\alpha_{\\min} = 0.2$ 和 $\\alpha_{\\max} = 5$。\n- **测试问题**：$f(t,y) = \\lambda y$，其中 $y(0) = 1$。精确解为 $y(t) = \\exp(\\lambda t)$。\n- **全局误差度量**：$E = |y_{\\mathrm{num}}(T) - y_{\\mathrm{exact}}(T)|$。\n- **测试用例**：\n    - A 例：$\\lambda = -1$，$T = 10$，$y_{0} = 1$，$\\mathrm{rtol} = 10^{-3}$，$\\mathrm{atol} = 10^{-12}$。\n    - B 例：$\\lambda = -1$，$T = 10$，$y_{0} = 1$，$\\mathrm{rtol} = 10^{-6}$，$\\mathrm{atol} = 10^{-12}$。\n    - C 例：$\\lambda = -5$，$T = 2$，$y_{0} = 1$，$\\mathrm{rtol} = 10^{-6}$，$\\mathrm{atol} = 10^{-12}$。\n- **要求计算**：对于每种情况，计算正确控制器 ($E_{\\mathrm{correct}}$) 和有缺陷控制器 ($E_{\\mathrm{flawed}}$) 的最终时间全局误差。\n\n**第 2 步：使用提取的已知条件进行验证**\n该问题定义明确且科学上合理。它涉及计算工程中的一个基本主题：常微分方程自适应数值方法的设计与分析。所有参数和过程都以足够的精度指定，以允许唯一的实现。唯一未指定的参数是初始步长 $h_0$。这是一个小疏漏。为了在两个控制器之间进行可复现的比较，对两者使用相同的合理初始步长就足够了。我将假设在所有模拟中使用一个小的、固定的初始步长 $h_0$，这是一种标准方法。因此，该问题被认为是有效的。\n\n**第 3 步：结论与行动**\n该问题是**有效的**。将提供一个完整的、有理有据的解决方案。\n\n**基本原理与方法**\n\n问题要求对初值问题 $y'(t) = f(t,y(t))$，$y(t_0) = y_0$ 进行数值积分。这是通过使用自适应步长的龙格-库塔方法实现的。\n\n显式龙格-库塔方法通过一系列中间级评估，从 $t_n$ 处的解计算出时间 $t_{n+1} = t_n + h_n$ 处的解。对于一个 $s$ 级方法，我们有：\n$$k_i = f\\left(t_n + c_i h_n, y_n + h_n \\sum_{j=1}^{i-1} a_{ij} k_j\\right), \\quad i=1, \\dots, s$$\n$$y_{n+1} = y_n + h_n \\sum_{i=1}^s b_i k_i$$\n系数 $c_i$、$a_{ij}$ 和 $b_i$ 定义了具体的方法。\n\n嵌入式对使用同一组级值 $k_i$ 提供两个解，$y_{n+1}$（$p$ 阶）和 $\\hat{y}_{n+1}$（$q  p$ 阶）。\n$$y_{n+1} = y_n + h_n \\sum_{i=1}^s b_i k_i \\quad (\\text{order } p)$$\n$$\\hat{y}_{n+1} = y_n + h_n \\sum_{i=1}^s \\hat{b}_i k_i \\quad (\\text{order } q)$$\n差值 $e_{n+1} = y_{n+1} - \\hat{y}_{n+1} = h_n \\sum_{i=1}^s (b_i - \\hat{b}_i)k_i$ 提供了低阶方法的局部截断误差的估计。该误差估计用于控制步长 $h_n$。\n\n**Bogacki–Shampine 3(2) 对**\n\n指定的 Bogacki–Shampine 方法是一个 4 级方法，可产生一个 3 阶解和一个 2 阶解。它具有首末同级 (FSAL) 特性，意味着一个步长的最终级评估可以作为后续步长的第一级重复使用，从而提高效率。其结构如下：\n\n1.  计算三个中间级：\n    $$k_1 = f(t_n, y_n)$$\n    $$k_2 = f(t_n + \\frac{1}{2}h, y_n + \\frac{1}{2}h k_1)$$\n    $$k_3 = f(t_n + \\frac{3}{4}h, y_n + \\frac{3}{4}h k_2)$$\n2.  计算 3 阶近似值，用于推进解：\n    $$y_{n+1} = y_n + h\\left(\\frac{2}{9}k_1 + \\frac{1}{3}k_2 + \\frac{4}{9}k_3\\right)$$\n3.  使用推进后的解 $y_{n+1}$ 计算第四个级。这是 FSAL 级。\n    $$k_4 = f(t_n + h, y_{n+1})$$\n4.  计算用于误差估计的 2 阶近似值：\n    $$\\hat{y}_{n+1} = y_n + h\\left(\\frac{7}{24}k_1 + \\frac{1}{4}k_2 + \\frac{1}{3}k_3 + \\frac{1}{8}k_4\\right)$$\n局部误差估计为 $e_{n+1} = y_{n+1} - \\hat{y}_{n+1}$。\n\n**自适应步长控制**\n\n控制器的目标是调整步长 $h$，使局部误差估计满足给定的容差。误差相对于解的量级进行缩放：\n$$\\mathrm{err\\_norm} = \\frac{|e_{n+1}|}{\\mathrm{atol} + \\mathrm{rtol} \\cdot \\max(|y_{n}|, |y_{n+1}|)}$$\n其中 $\\mathrm{atol}$ 和 $\\mathrm{rtol}$ 分别是绝对和相对误差容差。\n\n如果 $\\mathrm{err\\_norm} \\le 1$，则接受该步长。如果接受，则推进解：$t_{n+1} = t_n + h$，$y_{n+1} = y_{n+1}$。如果拒绝，则使用一个更小的 $h$ 重新尝试该步长。\n\n在任何一种情况下，都会提出一个新的步长 $h_{\\mathrm{new}}$。基于局部误差表现为 $C \\cdot h^{p+1}$ 的假设，最优步长从当前误差中导出：\n$$h_{\\mathrm{new}} = h \\cdot s \\cdot \\left(\\frac{1}{\\mathrm{err\\_norm}}\\right)^{1/(p+1)}$$\n此处，$p=3$ 是用于步长预测的方法的阶数，$s=0.9$ 是一个确保鲁棒性的安全因子。新步长被裁剪以避免过大或过小的变化：$h_{\\mathrm{new}}$ 被限制在 $[\\alpha_{\\min} h, \\alpha_{\\max} h] = [0.2h, 5.0h]$ 范围内。\n\n**有缺陷的控制器**\n\n问题要求对一个有缺陷的控制器进行研究。缺陷被引入到局部误差估计中。2 阶方法的正确权重为 $\\hat{\\mathbf{b}} = [7/24, 1/4, 1/3, 1/8]$。缺陷在于交换了最后两个权重：\n$$\\hat{\\mathbf{b}}_{\\text{flawed}} = [7/24, 1/4, 1/8, 1/3]$$\n这导致了一个有缺陷的 2 阶近似值：\n$$\\hat{y}_{n+1, \\text{flawed}} = y_n + h\\left(\\frac{7}{24}k_1 + \\frac{1}{4}k_2 + \\frac{1}{8}k_3 + \\frac{1}{3}k_4\\right)$$\n有缺陷的误差估计为 $\\hat{e}_{n+1} = y_{n+1} - \\hat{y}_{n+1, \\text{flawed}}$。然后，这个 $\\hat{e}_{n+1}$ 被用于误差范数计算和随后的步长调整。关键是要注意，即使使用有缺陷的控制器，解仍然使用正确的 3 阶公式 $y_{n+1}$ 进行推进。缺陷只影响自适应机制，而不影响传播公式本身。\n\n**算法与实现**\n\n实现的核心将是一个 `adaptive_integrator` 函数，它执行以下循环：\n1.  初始化 $t=t_0$，$y=y_0$ 和一个初始步长 $h=h_0$。我们将使用 $h_0 = 10^{-2}$。计算第一级 $k_1 = f(t_0, y_0)$。\n2.  开始主循环，只要 $t  T$ 就继续。\n3.  在循环内部，为步长接受启动一个子循环。\n4.  在子循环中，计算级 $k_2, k_3$、3 阶解 $y_{n+1}$ 和最终级 $k_4$。\n5.  根据控制器类型（正确的或有缺陷的），计算适当的局部误差估计（$e_{n+1}$ 或 $\\hat{e}_{n+1}$）。\n6.  计算误差范数 $\\mathrm{err\\_norm}$。\n7.  如果 $\\mathrm{err\\_norm} \\le 1$，则接受该步长。推进时间和解（$t \\leftarrow t+h, y \\leftarrow y_{n+1}$）。该步长的级 $k_4$ 成为下一步长的新 $k_1$ (FSAL)。退出子循环。\n8.  如果 $\\mathrm{err\\_norm}  1$，则拒绝该步长。当前的 $y_{n+1}$ 被丢弃。子循环以一个新的、更小的步长 $h$ 继续。\n9.  在接受和拒绝两种情况下，都使用控制律和裁剪方法计算一个新的建议步长 $h_{\\mathrm{new}}$，并更新 $h$。\n10. 当 $t \\ge T$ 时主循环终止。对最后一步的步长进行最终调整，以确保积分恰好在 $T$ 处停止。\n\n此过程将对每个测试用例执行一次，分别使用正确的控制器和有缺陷的控制器。然后计算并报告最终的全局误差 $E = |y_{\\mathrm{num}}(T) - \\exp(\\lambda T)|$。有缺陷控制器的行为（比正确的控制器更激进还是更保守）将决定最终的全局误差是更大还是更小。该实验展示了全局误差对局部误差估计器正确性的敏感性，而局部误差估计器的正确性是自适应求解器可靠性的基础。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef adaptive_integrator(f, t0, y0, T, rtol, atol, h0, flawed_controller):\n    \"\"\"\n    Integrates an ODE using the adaptive Bogacki-Shampine 3(2) method.\n    \"\"\"\n    # Bogacki-Shampine coefficients and controller parameters\n    # The method structure:\n    # k1 = f(t, y)\n    # k2 = f(t + 1/2 h, y + 1/2 h k1)\n    # k3 = f(t + 3/4 h, y + 3/4 h k2)\n    # y_next = y + h * (2/9 k1 + 1/3 k2 + 4/9 k3)  (order 3 solution)\n    # k4 = f(t + h, y_next)                          (FSAL stage)\n    # error = y_next - y_hat_next, where y_hat_next is the order 2 solution.\n    # The error is computed using a difference of weights for better numerical stability.\n    \n    b3_weights = np.array([2/9, 1/3, 4/9, 0])      # Order 3 weights\n    b2_weights_correct = np.array([7/24, 1/4, 1/3, 1/8]) # Order 2 weights\n    b2_weights_flawed = np.array([7/24, 1/4, 1/8, 1/3])  # Flawed order 2 weights\n\n    if flawed_controller:\n        err_weights = b3_weights - b2_weights_flawed\n    else:\n        err_weights = b3_weights - b2_weights_correct\n\n    s = 0.9\n    p = 3\n    alpha_min = 0.2\n    alpha_max = 5.0\n\n    t = t0\n    y = y0\n    h = h0\n\n    # First stage evaluation (k1) for the first step\n    k1 = f(t, y)\n\n    while t  T:\n        if t + h > T:\n            h = T - t  # Adjust last step to hit T exactly\n\n        step_accepted = False\n        while not step_accepted:\n            # Prevent infinitely small step size\n            if abs(h)  1e-15 * T:\n                raise RuntimeError(\"Step size has become excessively small.\")\n\n            # Compute stages for BS(3,2)\n            k2 = f(t + 0.5 * h, y + 0.5 * h * k1)\n            k3 = f(t + 0.75 * h, y + 0.75 * h * k2)\n            y_next = y + h * (b3_weights[0] * k1 + b3_weights[1] * k2 + b3_weights[2] * k3)\n            k4 = f(t + h, y_next)\n\n            # Calculate local error estimate\n            local_error = h * (err_weights[0] * k1 + err_weights[1] * k2 + \n                               err_weights[2] * k3 + err_weights[3] * k4)\n\n            # Calculate scaled error norm\n            y_scale = atol + rtol * max(abs(y), abs(y_next))\n            err_norm = abs(local_error) / y_scale if y_scale > 0 else 0\n\n            # Step acceptance logic\n            if err_norm = 1.0:\n                step_accepted = True\n                t += h\n                y = y_next\n                # FSAL: k4 of this step is k1 of the next\n                k1 = k4\n                \n                # Update step size for the next step\n                if err_norm == 0:\n                    # Avoid division by zero and propose max increase\n                    h_new = h * alpha_max\n                else:\n                    h_new = h * s * (err_norm ** (-1.0 / (p + 1.0)))\n            else:\n                # Step rejected, reduce step size and retry\n                h_new = h * s * (err_norm ** (-1.0 / (p + 1.0)))\n\n            # Clip the new step size\n            h = max(h * alpha_min, min(h * alpha_max, h_new))\n\n    return y\n\ndef solve():\n    \"\"\"\n    Runs the simulation for the specified test cases and prints the results.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {'lambda': -1.0, 'T': 10.0, 'y0': 1.0, 'rtol': 1e-3, 'atol': 1e-12},\n        # Case B\n        {'lambda': -1.0, 'T': 10.0, 'y0': 1.0, 'rtol': 1e-6, 'atol': 1e-12},\n        # Case C\n        {'lambda': -5.0, 'T': 2.0, 'y0': 1.0, 'rtol': 1e-6, 'atol': 1e-12},\n    ]\n\n    results = []\n    h0 = 1e-2  # Fixed initial step size for all runs for fair comparison\n\n    for case in test_cases:\n        lambda_val = case['lambda']\n        T = case['T']\n        y0 = case['y0']\n        rtol = case['rtol']\n        atol = case['atol']\n\n        # Define the ODE and its exact solution\n        f = lambda t, y: lambda_val * y\n        y_exact_func = lambda t: np.exp(lambda_val * t)\n        \n        y_exact_T = y_exact_func(T)\n\n        # Run with correct controller\n        y_num_correct = adaptive_integrator(f, 0, y0, T, rtol, atol, h0, flawed_controller=False)\n        E_correct = abs(y_num_correct - y_exact_T)\n\n        # Run with flawed controller\n        y_num_flawed = adaptive_integrator(f, 0, y0, T, rtol, atol, h0, flawed_controller=True)\n        E_flawed = abs(y_num_flawed - y_exact_T)\n\n        results.append([E_correct, E_flawed])\n\n    # Format the output string as specified\n    output_str = '[' + ','.join([f'[{r[0]:.5e},{r[1]:.5e}]' for r in results]) + ']'\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "在真实的工程应用中，计算资源并非无限。这个高级练习模拟了一个常见的场景：你必须在固定的“计算预算”内解决问题。你将进行一次参数搜索，以找到初始步长和容差的最佳组合，从而最小化最终的全局误差，让你学会如何在成本、容差和精度之间进行关键的权衡。",
            "id": "2388727",
            "problem": "给定一个固定的函数求值预算 $N=10000$，您需要使用带有局部误差控制的显式嵌入式 Runge–Kutta 对来近似初值问题的解在最终时刻的值。对于下面定义的每个测试用例，从候选集合中选择一个初始步长 $h_0$ 和一个标量容差 $\\mathrm{TOL}$，以在函数求值预算的约束下，最小化终端时刻的最终全局误差。当出现角度时，必须以弧度为单位进行解释。\n\n数值积分器必须是一种单步法，基于一个显式嵌入式 Runge–Kutta 对。在每个大小为 $h$ 的尝试步长中，该方法会在一系列阶段点上计算右端函数 $f(t,y)$ 的值，并给出在新时刻解的两个不同阶的近似值 $y^{[p]}$ 和 $y^{[p-1]}$。局部误差估计是差值 $e=y^{[p]}-y^{[p-1]}$，当且仅当 $\\lVert e\\rVert_2 \\le \\mathrm{TOL}$ 时，大小为 $h$ 的步长被接受，其中 $\\lVert\\cdot\\rVert_2$ 表示 $\\mathbb{R}^d$ 中的欧几里得范数，d 等于状态维度。每次对 $f(t,y)$ 的阶段求值都计为一次函数求值，消耗预算 $N$。每次尝试的步长，无论接受与否，都会产生该 Runge-Kutta 对所要求的全部阶段求值次数。初始步长为 $h_0$。在每次尝试的步长中，不应超过最终时刻 $t_{\\mathrm{end}}$；如果 $t+h$ 会超过 $t_{\\mathrm{end}}$，则在该次尝试中使用 $h=t_{\\mathrm{end}}-t$。\n\n使用以下嵌入式 Runge–Kutta 系数，这是一个具有 $s=7$ 个阶段的 $5(4)$ 对。阶段横坐标为\n$$\nc_1=0,\\quad c_2=\\tfrac{1}{5},\\quad c_3=\\tfrac{3}{10},\\quad c_4=\\tfrac{4}{5},\\quad c_5=\\tfrac{8}{9},\\quad c_6=1,\\quad c_7=1.\n$$\n对于 $i=2,\\dots,7$ 和 $j=1,\\dots,i-1$，内部系数 $a_{ij}$ 为\n$$\n\\begin{aligned}\na_{21}=\\tfrac{1}{5},\\\\\na_{31}=\\tfrac{3}{40},\\ a_{32}=\\tfrac{9}{40},\\\\\na_{41}=\\tfrac{44}{45},\\ a_{42}=-\\tfrac{56}{15},\\ a_{43}=\\tfrac{32}{9},\\\\\na_{51}=\\tfrac{19372}{6561},\\ a_{52}=-\\tfrac{25360}{2187},\\ a_{53}=\\tfrac{64448}{6561},\\ a_{54}=-\\tfrac{212}{729},\\\\\na_{61}=\\tfrac{9017}{3168},\\ a_{62}=-\\tfrac{355}{33},\\ a_{63}=\\tfrac{46732}{5247},\\ a_{64}=\\tfrac{49}{176},\\ a_{65}=-\\tfrac{5103}{18656},\\\\\na_{71}=\\tfrac{35}{384},\\ a_{72}=0,\\ a_{73}=\\tfrac{500}{1113},\\ a_{74}=\\tfrac{125}{192},\\ a_{75}=-\\tfrac{2187}{6784},\\ a_{76}=\\tfrac{11}{84}.\n\\end{aligned}\n$$\n高阶权重 $b_j$ 和嵌入的低阶权重 $\\widehat{b}_j$ 为\n$$\n\\begin{aligned}\n\\mathbf{b}=\\Big[\\tfrac{35}{384}, 0, \\tfrac{500}{1113}, \\tfrac{125}{192}, -\\tfrac{2187}{6784}, \\tfrac{11}{84}, 0\\Big],\\\\\n\\mathbf{\\widehat{b}}=\\Big[\\tfrac{5179}{57600}, 0, \\tfrac{7571}{16695}, \\tfrac{393}{640}, -\\tfrac{92097}{339200}, \\tfrac{187}{2100}, \\tfrac{1}{40}\\Big].\n\\end{aligned}\n$$\n在时刻 $t$，给定状态 $y\\in\\mathbb{R}^d$ 和步长 $h$，阶段值为 $k_1=f(t,y)$ 以及\n$$\nk_i=f\\Big(t+c_i h,\\ y+h\\sum_{j=1}^{i-1} a_{ij}k_j\\Big),\\quad i=2,\\dots,7,\n$$\n两个近似解为\n$$\ny^{[5]}=y+h\\sum_{j=1}^{7} b_j k_j,\\quad y^{[4]}=y+h\\sum_{j=1}^{7} \\widehat{b}_j k_j,\n$$\n局部误差估计为 $e=y^{[5]}-y^{[4]}$。终端时刻的最终近似解是通过从初始时刻开始，使用被接受的步长前进，直到达到 $t_{\\mathrm{end}}$。\n\n对于误差控制和步长选择，将 $\\mathrm{TOL}$ 解释为绝对局部误差阈值，并使用接受准则 $\\lVert e\\rVert_2\\le \\mathrm{TOL}$。在任何一次尝试后，建议的下一步长 $h_{\\mathrm{new}}$ 必须具有以下形式\n$$\nh_{\\mathrm{new}}=\\alpha\\,h\\,\\max\\!\\Big(\\beta_{\\min},\\ \\min\\big(\\beta_{\\max},\\ (\\tfrac{\\mathrm{TOL}}{\\max(\\lVert e\\rVert_2,\\ \\epsilon)})^{1/5}\\big)\\Big),\n$$\n其中 $\\alpha$ 是一个安全因子，$\\beta_{\\min}$ 和 $\\beta_{\\max}$ 是限制因子，$\\epsilon$ 是一个小的正数以避免除以零。使用 $\\alpha=0.9$，$\\beta_{\\min}=0.2$，$\\beta_{\\max}=5$ 和 $\\epsilon=10^{-16}$。\n\n如果一个候选对 $(h_0,\\mathrm{TOL})$ 在达到终端時刻前，所有尝试步长（包括接受和拒绝的）的总阶段求值次数不超过 $N=10000$，则该候选对是可行的。如果一个候选对在达到终端时刻前耗尽了预算，则它是不可行的。在所有可行的候选对中，选择使最终全局误差最小化的那一对\n$$\nE=\\lVert y(t_{\\mathrm{end}})-y_{\\mathrm{true}}(t_{\\mathrm{end}})\\rVert_2,\n$$\n其中 $y_{\\mathrm{true}}$ 是精确解。如果有多个候选对在绝对容差 $10^{-12}$ 内达到相同的最小误差，则通过偏好总函数求值次数较少的那个来打破平局；如果仍然平局，则偏好较大的 $\\mathrm{TOL}$；如果仍然平局，则偏好较大的 $h_0$。\n\n使用以下候选集合：\n$$\nh_0\\in\\big\\{10^{-3},\\ 5\\cdot 10^{-3},\\ 10^{-2},\\ 5\\cdot 10^{-2},\\ 10^{-1},\\ 5\\cdot 10^{-1}\\big\\},\n$$\n$$\n\\mathrm{TOL}\\in\\big\\{10^{-6},\\ 3\\cdot 10^{-6},\\ 10^{-5},\\ 3\\cdot 10^{-5},\\ 10^{-4},\\ 3\\cdot 10^{-4},\\ 10^{-3},\\ 3\\cdot 10^{-3},\\ 10^{-2}\\big\\}.\n$$\n\n初值问题测试套件，包含精确解和所需定义域：\n- 案例 $\\mathrm{A}$：标量，$y'(t)=-10\\,y(t)$，$y(0)=1$，$t\\in[0,2]$，精确解 $y_{\\mathrm{true}}(t)=e^{-10 t}$。\n- 案例 $\\mathrm{B}$：标量，$y'(t)=y(t)^2-y(t)$，$y(0)=0.1$，$t\\in[0,3]$，精确解 $y_{\\mathrm{true}}(t)=\\dfrac{1}{1+9 e^{t}}$。\n- 案例 $\\mathrm{C}$：标量，$y'(t)=-100\\big(y(t)-\\cos t\\big)-\\sin t$，$y(0)=1$，$t\\in[0,2]$，精确解 $y_{\\mathrm{true}}(t)=\\cos t$。\n- 案例 $\\mathrm{D}$：维度为 $d=2$ 的向量，$y_1'(t)=y_2(t)$，$y_2'(t)=-y_1(t)$，其中 $y_1(0)=1$，$y_2(0)=0$，$t\\in[0,2\\pi]$，精确解 $y_{\\mathrm{true}}(t)=[\\cos t,\\ -\\sin t]^T$。\n\n对于每个案例，您的程序必须在指定候选集合中的所有 $(h_0,\\mathrm{TOL})$ 对上进行搜索，强制执行 $N=10000$ 次阶段求值的预算，并报告最优对及其产生的最终全局误差 $E$。\n\n最终输出规范：\n- 对于每个案例，生成一个列表 $[h_0^\\star,\\ \\mathrm{TOL}^\\star,\\ E^\\star]$，其中 $h_0^\\star$ 和 $\\mathrm{TOL}^\\star$ 是从候选集合中选择的值，$E^\\star$ 是最小最终全局误差，表示为四舍五入到 $8$ 位有效数字的浮点值。\n- 将四个案例的结果聚合到单行输出中，该输出包含一个用方括号括起来的逗号分隔列表，例如 $[[h_0^\\star,\\mathrm{TOL}^\\star,E^\\star],\\ \\dots]$。",
            "solution": "用户提供了一个科学严谨、定义明确、客观且完整的问题陈述。它描述了一项标准的计算工程任务：为自适应 Runge-Kutta 数值积分器寻找最优参数。所有必需的数据，包括特定的 Runge-Kutta 系数、步长控制算法、带精确解的测试问题集、候选参数集以及优化标准，均以清晰明确的方式提供。该问题遵循常微分方程数值分析的既定原则。因此，该问题是有效的，并且可以构建解决方案。\n\n解决方案框架被设计为在提供的离散候选参数集上进行系统性搜索。对于四个初值问题（IVP）中的每一个，算法都会在所有可能的初始步长 $h_0$ 和局部误差容差 $\\mathrm{TOL}$ 对上进行网格搜索。\n\n设计的核心是一个实现自适应步长 Runge-Kutta 积分器的函数。该积分器基于所提供的特定的 $s=7$ 阶段、$5(4)$ 阶嵌入式对，即公认的 Dormand-Prince 对。在每个时间步，此方法计算解的两个近似值：一个五阶精确解 $y^{[5]}$ 和一个四阶精确解 $y^{[4]}$。阶段值 $k_i$ 计算如下：\n$$\nk_1=f(t_n,y_n)\n$$\n$$\nk_i=f\\Big(t_n+c_i h,\\ y_n+h\\sum_{j=1}^{i-1} a_{ij}k_j\\Big),\\quad i=2,\\dots,7\n$$\n然后形成两个解的近似值：\n$$\ny_{n+1}^{[5]}=y_n+h\\sum_{j=1}^{7} b_j k_j\n$$\n$$\ny_{n+1}^{[4]}=y_n+h\\sum_{j=1}^{7} \\widehat{b}_j k_j\n$$\n这两个近似值之差 $e = y_{n+1}^{[5]} - y_{n+1}^{[4]}$ 用作局部截断误差的估计。\n\n步长控制逻辑如下。如果局部误差估计的欧几里得范数小于或等于指定的容差，即 $\\lVert e\\rVert_2 \\le \\mathrm{TOL}$，则认为大小为 $h$ 的尝试步长是成功的。如果步长被接受，则使用高阶近似推进数值解：$y_{n+1} = y_{n+1}^{[5]}$ 和 $t_{n+1} = t_n + h$。如果步长被拒绝，解保持在 $(t_n, y_n)$，并使用一个新的、更小的步长重新尝试该步骤。\n\n无论步长被接受还是被拒绝，都会使用提供的比例-积分（PI）控制公式计算后续尝试的新步长 $h_{\\mathrm{new}}$。此公式 $h_{\\mathrm{new}}=\\alpha\\,h\\,\\max\\!\\big(\\beta_{\\min},\\ \\min\\big(\\beta_{\\max},\\ (\\frac{\\mathrm{TOL}}{\\max(\\lVert e\\rVert_2,\\ \\epsilon)})^{1/5}\\big)\\big)$，根据目标容差与测量误差的比率来调整步长。安全因子 $\\alpha=0.9$ 提高了鲁棒性，而限制因子 $\\beta_{\\min}$ 和 $\\beta_{\\max}$ 防止步长变化过快。\n\n对于每个 $(h_0, \\mathrm{TOL})$ 对，积分器从初始时间 $t_0$ 运行到终端时间 $t_{\\mathrm{end}}$。总函数求值次数受到严格监控，不得超过 $N=10000$ 的预算。每次尝试的步长，无论成功与否，都会消耗 $s=7$ 次函数求值。如果在到达 $t_{\\mathrm{end}}$ 之前预算耗尽，则该 $(h_0, \\mathrm{TOL})$ 对被标记为不可行。\n\n对于所有可行的对，计算最终全局误差 $E = \\lVert y(t_{\\mathrm{end}}) - y_{\\mathrm{true}}(t_{\\mathrm{end}}) \\rVert_2$。算法识别出使该误差 $E$ 最小化的最优 $(h_0^\\star, \\mathrm{TOL}^\\star)$ 对。问题指定了一套严格的决胜规则：如果多个对产生的误差 $E$ 在最小值的 $10^{-12}$ 绝对容差范围内，则选择总函数求值次数最少的那个。进一步的平局通过偏好更大的 $\\mathrm{TOL}$，然后是更大的 $h_0$ 来解决。\n\n对四个指定的初值问题（IVP）中的每一个都重复此完整过程。最终输出是每个案例的最优参数 $(h_0^\\star, \\mathrm{TOL}^\\star)$ 和相应最小全局误差 $E^\\star$ 的集合，并按要求格式化。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# A class to hold the test case data for clarity.\nclass TestCase:\n    \"\"\"A container for an initial value problem specification.\"\"\"\n    def __init__(self, f, y0, t_span, y_true):\n        self.f = f\n        self.y0 = np.array(y0, dtype=np.float64)\n        self.t_span = t_span\n        self.y_true = y_true\n\ndef adaptive_rk_solver(case, h0, tol, budget, rk_params):\n    \"\"\"\n    Solves an IVP using an adaptive Runge-Kutta method.\n\n    Returns the final state, total function evaluations, and a feasibility flag.\n    \"\"\"\n    t_start, t_end = case.t_span\n    t = t_start\n    y = case.y0.copy()\n    h = h0\n    fevals = 0\n\n    A, B, B_ERR, C, S, P_ORDER, ALPHA, BETA_MIN, BETA_MAX, EPSILON = rk_params\n\n    while t  t_end:\n        if fevals + S > budget:\n            return None, fevals, False  # Infeasible: budget exceeded\n\n        current_h = min(h, t_end - t)\n        \n        step_accepted = False\n        temp_h = current_h\n\n        # This inner loop is for retrying a step if it's rejected\n        while not step_accepted:\n            if fevals + S > budget:\n                return None, fevals, False\n            \n            # Calculate stages for the Runge-Kutta step\n            k_stages = np.zeros((S, y.size), dtype=np.float64)\n            \n            k_stages[0] = case.f(t, y)\n            for i in range(1, S):\n                y_stage = y + temp_h * (A[i, :i] @ k_stages[:i, :])\n                k_stages[i] = case.f(t + C[i] * temp_h, y_stage)\n\n            fevals += S\n            \n            # Calculate local error estimate\n            y_err = temp_h * (B_ERR @ k_stages)\n            err_norm = np.linalg.norm(y_err)\n\n            # Propose new step size based on error\n            if err_norm == 0.0:\n                factor = BETA_MAX\n            else:\n                factor = (tol / err_norm)**(1.0 / P_ORDER)\n\n            h_new = ALPHA * temp_h * max(BETA_MIN, min(BETA_MAX, factor))\n\n            # Accept or reject the step\n            if err_norm = tol:\n                step_accepted = True\n                t += temp_h\n                y += temp_h * (B @ k_stages)  # Advance state with higher-order method\n                h = h_new\n            else:\n                # Step rejected, retry with smaller step\n                h = h_new\n                temp_h = h\n                if t + temp_h > t_end:\n                    temp_h = t_end - t\n                if abs(temp_h)  1e-16: # Failsafe\n                    return None, fevals, False\n    \n    return y, fevals, True\n\ndef solve():\n    \"\"\"\n    Main function to run the optimization for all test cases.\n    \"\"\"\n    # Candidate parameter sets\n    h0_candidates = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1]\n    tol_candidates = [1e-6, 3e-6, 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2]\n    \n    # RK and step-size control parameter definitions\n    C = np.array([0, 1/5, 3/10, 4/5, 8/9, 1, 1], dtype=np.float64)\n    A = np.array([\n        [0, 0, 0, 0, 0, 0, 0],\n        [1/5, 0, 0, 0, 0, 0, 0],\n        [3/40, 9/40, 0, 0, 0, 0, 0],\n        [44/45, -56/15, 32/9, 0, 0, 0, 0],\n        [19372/6561, -25360/2187, 64448/6561, -212/729, 0, 0, 0],\n        [9017/3168, -355/33, 46732/5247, 49/176, -5103/18656, 0, 0],\n        [35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0]\n    ], dtype=np.float64)\n    B = np.array([35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0], dtype=np.float64)\n    B_HAT = np.array([5179/57600, 0, 7571/16695, 393/640, -92097/339200, 187/2100, 1/40], dtype=np.float64)\n    B_ERR = B - B_HAT\n    S = 7\n    P_ORDER = 5\n    ALPHA = 0.9\n    BETA_MIN = 0.2\n    BETA_MAX = 5.0\n    EPSILON = 1e-16\n    N_BUDGET = 10000\n    \n    rk_params = (A, B, B_ERR, C, S, P_ORDER, ALPHA, BETA_MIN, BETA_MAX, EPSILON)\n\n    # Test case definitions\n    test_cases = [\n        TestCase(\n            f=lambda t, y: -10 * y,\n            y0=[1.0],\n            t_span=[0.0, 2.0],\n            y_true=lambda t: np.array([np.exp(-10 * t)])\n        ),\n        TestCase(\n            f=lambda t, y: y**2 - y,\n            y0=[0.1],\n            t_span=[0.0, 3.0],\n            y_true=lambda t: np.array([1.0 / (1.0 + 9.0 * np.exp(t))])\n        ),\n        TestCase(\n            f=lambda t, y: -100 * (y - np.cos(t)) - np.sin(t),\n            y0=[1.0],\n            t_span=[0.0, 2.0],\n            y_true=lambda t: np.array([np.cos(t)])\n        ),\n        TestCase(\n            f=lambda t, y: np.array([y[1], -y[0]]),\n            y0=[1.0, 0.0],\n            t_span=[0.0, 2 * np.pi],\n            y_true=lambda t: np.array([np.cos(t), -np.sin(t)])\n        )\n    ]\n    \n    final_results = []\n    for case in test_cases:\n        best_params = {'h0': None, 'tol': None, 'error': np.inf, 'fevals': N_BUDGET + 1}\n        \n        for h0 in h0_candidates:\n            for tol in tol_candidates:\n                y_final, fevals, feasible = adaptive_rk_solver(case, h0, tol, N_BUDGET, rk_params)\n                \n                if feasible:\n                    t_end = case.t_span[1]\n                    y_exact_final = case.y_true(t_end)\n                    error = np.linalg.norm(y_final - y_exact_final)\n                    \n                    is_better = False\n                    if error  best_params['error'] - 1e-12:\n                        is_better = True\n                    elif abs(error - best_params['error']) = 1e-12:\n                        if fevals  best_params['fevals']:\n                            is_better = True\n                        elif fevals == best_params['fevals']:\n                            if tol > best_params.get('tol', -1):\n                                is_better = True\n                            elif tol == best_params.get('tol', -1):\n                                if h0 > best_params.get('h0', -1):\n                                    is_better = True\n                    \n                    if is_better:\n                        best_params['h0'] = h0\n                        best_params['tol'] = tol\n                        best_params['error'] = error\n                        best_params['fevals'] = fevals\n                        \n        rounded_error = float(f\"{best_params['error']:.8g}\")\n        final_results.append([best_params['h0'], best_params['tol'], rounded_error])\n\n    print(str(final_results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}