{
    "hands_on_practices": [
        {
            "introduction": "Many physical systems, like the mass-spring-damper model, give rise to \"stiff\" ordinary differential equations where standard explicit methods require impractically small time steps for stability. This practice introduces the semi-implicit Euler method, a powerful technique that selectively treats the stiff components of the system implicitly to achieve much greater stability. By implementing this method for a mass-spring-damper system, you will directly observe its ability to handle large time steps where a fully explicit method would fail .",
            "id": "2402453",
            "problem": "You are given the one-dimensional mass–spring–damper model governed by the Ordinary Differential Equation (ODE): $$m \\, \\ddot{x}(t) + c \\, \\dot{x}(t) + k \\, x(t) = 0,$$ where $m$ is the mass in kilograms, $c$ is the viscous damping coefficient in kilograms per second, and $k$ is the spring stiffness in newtons per meter. Introduce the velocity variable $v(t) = \\dot{x}(t)$. Consider the following first-order time discretization of this system over uniform time steps of size $h$ seconds:\n$$v_{n+1} = \\frac{v_n - h \\, \\frac{k}{m} \\, x_n}{1 + h \\, \\frac{c}{m}}, \\quad x_{n+1} = x_n + h \\, v_{n+1},$$\nwith initial conditions $x_0$ and $v_0$. The quantities $x_n$ and $v_n$ approximate the position and velocity at discrete times $t_n = n h$.\n\nYour task is to write a complete, runnable program that:\n- Implements the above discrete-time update to propagate $x_n$ and $v_n$ for a prescribed number of steps $N$.\n- For each test case specified below, computes:\n  1. The final position $x_N$ in meters.\n  2. The final velocity $v_N$ in meters per second.\n  3. The final mechanical energy $$E_N = \\tfrac{1}{2} m v_N^2 + \\tfrac{1}{2} k x_N^2$$ in joules.\n  4. A boundedness indicator defined as follows: Let $M = \\max_{0 \\le n \\le N} \\max\\{|x_n|, |v_n|\\}$. Define the result to be $1$ if $M \\le B$ and $0$ otherwise, where $B = 10^6$.\n- All values $x_N$, $v_N$, and $E_N$ must be expressed in International System of Units (SI). Do not print units; the numerical values are interpreted in SI units.\n\nUse the following test suite, where each case is a tuple $(m, c, k, h, N, x_0, v_0)$:\n- Case $1$: $(1.0, 0.5, 100.0, 0.1, 500, 1.0, 0.0)$\n- Case $2$: $(1.0, 10.0, 2500.0, 0.02, 1000, 1.0, 0.0)$\n- Case $3$: $(1.0, 0.0, 1.0, 2.2, 200, 1.0, 0.0)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case, append the four values $[x_N, v_N, E_N, \\text{bounded}]$ in order, with the boundedness indicator represented as an integer $1$ for true and $0$ for false. The final output must therefore contain $12$ comma-separated entries corresponding to the three cases, in the order of the cases given above, for example:\n\"[x1,v1,E1,b1,x2,v2,E2,b2,x3,v3,E3,b3]\".",
            "solution": "The problem statement is first subjected to a rigorous validation to ensure its scientific and logical integrity before any attempt at a solution is made.\n\n### Step 1: Extract Givens\n\nThe following information is provided verbatim in the problem statement:\n- **Governing ODE:** $m \\, \\ddot{x}(t) + c \\, \\dot{x}(t) + k \\, x(t) = 0$, where $m$ is mass (kg), $c$ is damping coefficient (kg/s), and $k$ is spring stiffness (N/m).\n- **State variable:** $v(t) = \\dot{x}(t)$.\n- **Discretization scheme:**\n  - Time step: $h$ (s).\n  - Approximations at $t_n = n h$: $x_n, v_n$.\n  - Update equations:\n    $$v_{n+1} = \\frac{v_n - h \\, \\frac{k}{m} \\, x_n}{1 + h \\, \\frac{c}{m}}, \\quad x_{n+1} = x_n + h \\, v_{n+1}$$\n- **Initial conditions:** $x_0, v_0$.\n- **Task:** For a given number of steps $N$, compute:\n  1. Final position $x_N$ (m).\n  2. Final velocity $v_N$ (m/s).\n  3. Final mechanical energy $E_N = \\tfrac{1}{2} m v_N^2 + \\tfrac{1}{2} k x_N^2$ (J).\n  4. Boundedness indicator: Let $M = \\max_{0 \\le n \\le N} \\max\\{|x_n|, |v_n|\\}$. The indicator is $1$ if $M \\le B$ and $0$ otherwise, where $B = 10^6$.\n- **Test Cases:** Each case is a tuple $(m, c, k, h, N, x_0, v_0)$.\n  - Case $1$: $(1.0, 0.5, 100.0, 0.1, 500, 1.0, 0.0)$\n  - Case $2$: $(1.0, 10.0, 2500.0, 0.02, 1000, 1.0, 0.0)$\n  - Case $3$: $(1.0, 0.0, 1.0, 2.2, 200, 1.0, 0.0)$\n\n### Step 2: Validate Using Extracted Givens\n\n- **Scientific Grounding:** The governing equation is the fundamental linear model for a mass-spring-damper system, a cornerstone of classical mechanics. The definition of mechanical energy is correct. The numerical scheme is a legitimate method for solving Ordinary Differential Equations. The problem is scientifically sound.\n- **Well-Posedness:** The initial value problem for the ODE is well-posed. The provided discretization scheme is explicit in its update rules, meaning $x_{n+1}$ and $v_{n+1}$ are uniquely determined from $x_n$ and $v_n$. The denominator $1 + h \\, \\frac{c}{m}$ is non-zero for all valid physical parameters ($m>0, c\\ge 0, h>0$). The problem is well-posed.\n- **Objectivity:** The problem is phrased using precise, objective mathematical and physical terminology. The tasks are quantitative and unambiguous. The problem is objective.\n- **Completeness and Consistency:** All necessary constants, initial conditions, and parameters ($m, c, k, h, N, x_0, v_0, B$) are provided for each test case. The problem is self-contained and consistent. The units are specified in the International System of Units (SI), which is consistent.\n\n### Step 3: Verdict and Action\n\nThe problem statement is scientifically grounded, well-posed, and complete. It is deemed **valid**. A solution will be developed.\n\n### Solution\n\nThe solution requires the implementation of a numerical time-stepping algorithm to approximate the dynamics of a mass-spring-damper system.\n\n**1. Mathematical Formulation**\n\nThe second-order Ordinary Differential Equation (ODE)\n$$m \\, \\ddot{x}(t) + c \\, \\dot{x}(t) + k \\, x(t) = 0$$\nis transformed into a system of two first-order ODEs by introducing the velocity variable $v(t) = \\dot{x}(t)$. The system becomes:\n$$\n\\begin{cases}\n\\dot{x}(t) = v(t) \\\\\n\\dot{v}(t) = -\\frac{k}{m} x(t) - \\frac{c}{m} v(t)\n\\end{cases}\n$$\n\n**2. Discretization Scheme Analysis**\n\nThe provided update rules are:\n$$\nv_{n+1} = \\frac{v_n - h \\, \\frac{k}{m} \\, x_n}{1 + h \\, \\frac{c}{m}} \\tag{1}\n$$\n$$\nx_{n+1} = x_n + h \\, v_{n+1} \\tag{2}\n$$\nwhere $h$ is the time step, and $(x_n, v_n)$ are the approximations of $(x(t_n), v(t_n))$ at time $t_n = n h$.\n\nThis scheme can be identified as a semi-implicit method. By rearranging the equations into the form of finite differences, we can see its structure:\n$$\n\\frac{x_{n+1} - x_n}{h} = v_{n+1} \\quad \\text{(Implicit/Backward Euler step for position)}\n$$\n$$\n\\frac{v_{n+1} - v_n}{h} = -\\frac{k}{m} x_n - \\frac{c}{m} v_{n+1} \\quad \\text{(Mixed step for velocity)}\n$$\nThe velocity update uses the old position $x_n$ (an explicit or forward treatment of the spring force) and the new velocity $v_{n+1}$ (an implicit or backward treatment of the damping force). This structure often provides better stability than fully explicit methods, such as the standard forward Euler method, especially for stiff or oscillatory systems.\n\n**3. Stability Considerations for the Undamped Case**\n\nA critical aspect of numerical methods is stability. Consider Case $3$, where damping is absent ($c=0$). The parameter $c_m = c/m$ becomes $0$. The update equations simplify to:\n$$\nv_{n+1} = v_n - h \\frac{k}{m} x_n\n$$\n$$\nx_{n+1} = x_n + h v_{n+1}\n$$\nThis is the well-known symplectic Euler method. For the simple harmonic oscillator, its stability is conditional on the time step size. The stability criterion is $|h \\omega_0| \\le 2$, where $\\omega_0 = \\sqrt{k/m}$ is the natural angular frequency.\n\nFor Case $3$, we have $m=1.0$, $k=1.0$, and $h=2.2$. The natural frequency is $\\omega_0 = \\sqrt{1.0/1.0} = 1.0 \\, \\text{rad/s}$. We check the stability condition:\n$|h \\omega_0| = |2.2 \\times 1.0| = 2.2$\nSince $2.2 > 2.0$, the stability condition is violated. The numerical scheme is unstable for this choice of parameters. We must therefore predict that the numerical solution for Case $3$ will grow without bound, and the boundedness indicator should correctly be $0$. This is a feature of the test case, not a flaw in the problem.\n\n**4. Algorithmic Procedure**\n\nThe program will execute the following steps for each test case $(m, c, k, h, N, x_0, v_0)$:\n1.  Initialize the state variables $x = x_0$ and $v = v_0$.\n2.  Initialize a tracking variable for boundedness, $M_{max} = \\max(|x_0|, |v_0|)$.\n3.  Pre-compute the constant coefficients $\\frac{k}{m}$ and $\\frac{c}{m}$ to avoid redundant calculations inside the loop. The denominator term $1 + h \\frac{c}{m}$ will also be pre-computed.\n4.  Execute a loop for $n$ from $0$ to $N-1$:\n    a. Calculate $v_{n+1}$ using equation $(1)$.\n    b. Calculate $x_{n+1}$ using equation $(2)$.\n    c. Update the state: $(x_n, v_n) \\leftarrow (x_{n+1}, v_{n+1})$.\n    d. Update the tracker: $M_{max} = \\max(M_{max}, |x_{n+1}|, |v_{n+1}|)$.\n5.  After the loop completes, the final state is $(x_N, v_N)$.\n6.  Calculate the final energy $E_N = \\frac{1}{2} m v_N^2 + \\frac{1}{2} k x_N^2$.\n7.  Determine the boundedness indicator: $1$ if $M_{max} \\le 10^6$, and $0$ otherwise.\n8.  Collect the four results: $x_N, v_N, E_N,$ and the boundedness indicator.\n\nThis procedure will be systematically applied to all provided test cases to generate the final output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the mass-spring-damper problem for a given set of test cases\n    using the specified semi-implicit numerical scheme.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (m, c, k, h, N, x0, v0)\n    test_cases = [\n        (1.0, 0.5, 100.0, 0.1, 500, 1.0, 0.0),\n        (1.0, 10.0, 2500.0, 0.02, 1000, 1.0, 0.0),\n        (1.0, 0.0, 1.0, 2.2, 200, 1.0, 0.0),\n    ]\n\n    # Bounding constant B\n    BOUND = 10**6\n\n    results = []\n    \n    for case in test_cases:\n        m, c, k, h, N, x0, v0 = case\n\n        # Initialize state variables\n        x = float(x0)\n        v = float(v0)\n\n        # Initialize tracker for boundedness check\n        max_abs_val = max(abs(x), abs(v))\n\n        # Pre-compute coefficients for efficiency\n        k_over_m = k / m\n        c_over_m = c / m\n        denominator = 1.0 + h * c_over_m\n\n        # Time-stepping loop\n        for _ in range(int(N)):\n            # Apply the update equations\n            v_new = (v - h * k_over_m * x) / denominator\n            x_new = x + h * v_new\n\n            # Update the state\n            x, v = x_new, v_new\n            \n            # Update the maximum absolute value observed\n            max_abs_val = max(max_abs_val, abs(x), abs(v))\n\n        # Final state\n        x_N = x\n        v_N = v\n\n        # Calculate final mechanical energy\n        E_N = 0.5 * m * v_N**2 + 0.5 * k * x_N**2\n\n        # Determine boundedness indicator\n        is_bounded = 1 if max_abs_val = BOUND else 0\n\n        # Append results for this case\n        results.extend([x_N, v_N, E_N, is_bounded])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While the Forward Euler method is simple, its first-order accuracy is often insufficient for practical engineering problems. This exercise explores \"deferred correction,\" an elegant and general strategy for improving accuracy by bootstrapping from a low-order solution. You will first compute a preliminary solution using Forward Euler, use it to estimate the method's leading error term, and then re-solve the ODE with a corrective term to achieve second-order accuracy . This practice demonstrates how to systematically increase the convergence order of a numerical method, a powerful concept in algorithm design.",
            "id": "2402452",
            "problem": "You are asked to formalize and implement a deferred-correction improvement of the Forward Euler method for initial value problems of ordinary differential equations. Consider problems of the form $y'(t)=f(t,y(t))$ on a uniform grid $t_n=t_0+n h$, for $n=0,1,\\dots,N$, where $h=(T-t_0)/N$, with an initial condition $y(t_0)=y_0$. Define a preliminary Forward Euler approximation $y_n^{E}$ by $y_{n+1}^{E}=y_n^{E}+h\\,f(t_n,y_n^{E})$ with $y_0^{E}=y_0$. Using this completed Euler run, define an approximation of the leading error term $y''(t_n)$ by the difference quotient\n$$\n\\widehat{y''}(t_n) := \\frac{ f(t_{n+1},\\,y_{n+1}^{E}) - f(t_n,\\,y_n^{E}) }{h}.\n$$\nThen re-solve a corrected problem by a one-step method that incorporates this estimate so that the corrected numerical solution $y_n^{C}$ is defined by\n$$\ny_{n+1}^{C} := y_n^{C} + h\\,f(t_n,y_n^{C}) + \\frac{h^2}{2}\\,\\widehat{y''}(t_n), \\quad y_0^{C}=y_0.\n$$\nFor each test case below, compute the absolute error at the final time $T$ for both the Forward Euler solution and the corrected solution, and compute the error ratio defined as the Forward Euler error divided by the corrected error.\n\nIn addition, for the specified observed-order tests, compute the observed global order $p$ of the corrected method from two step sizes $h_1$ and $h_2=h_1/2$ via\n$$\np := \\frac{\\log\\big(e(h_1)/e(h_2)\\big)}{\\log(2)},\n$$\nwhere $e(h)$ is the absolute error at the final time $T$ obtained by the corrected method with step size $h$.\n\nAll answers must be expressed as dimensionless real numbers. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each number must be printed in decimal scientific notation rounded to six significant digits, for example $[1.234560\\mathrm{e}{-03},2.500000\\mathrm{e}{+00}]$.\n\nTest suite and required outputs:\n\n- Test case $1$ (happy path, linear autonomous): $y'(t)=\\lambda y(t)$ with $\\lambda=-3$, $t_0=0$, $T=1$, $y_0=1$, $h=0.1$. Exact value at $T$ is $y(T)=\\exp(\\lambda T)$. Output three numbers: the Forward Euler absolute error, the corrected absolute error, and their ratio.\n\n- Test case $2$ (boundary/edge: single step): $y'(t)=\\lambda y(t)$ with $\\lambda=-1$, $t_0=0$, $T=1$, $y_0=1$, $h=1$. Exact value at $T$ is $y(T)=\\exp(\\lambda T)$. Output three numbers as in Test case $1$.\n\n- Test case $3$ (nonlinear autonomous): $y'(t)=-y(t)^3$, $t_0=0$, $T=1$, $y_0=1$, $h=0.1$. Exact value at $T$ is $y(T)=1/\\sqrt{1+2T}$. Output three numbers as in Test case $1$.\n\n- Test case $4$ (time-dependent linear): $y'(t)=t - y(t)$, $t_0=0$, $T=1$, $y_0=0$, $h=0.1$. Exact value at $T$ is $y(T)=T-1+\\exp(-T)$. Output three numbers as in Test case $1$.\n\n- Test case $5$ (observed order on linear autonomous): For $y'(t)=\\lambda y(t)$ with $\\lambda=-3$, $t_0=0$, $T=1$, $y_0=1$, compute the corrected-method absolute error at $T$ for $h_1=0.2$ and $h_2=0.1$, and then compute $p$ by the formula above. Output one number: the observed order $p$.\n\n- Test case $6$ (observed order on nonlinear autonomous): For $y'(t)=-y(t)^3$, $t_0=0$, $T=1$, $y_0=1$, compute the corrected-method absolute error at $T$ for $h_1=0.2$ and $h_2=0.1$, and then compute $p$ by the formula above. Output one number: the observed order $p$.\n\nFinal output format: Your program must print a single line in the form\n$[r_1,r_2,\\dots,r_{14}]$\nwhere the entries, in order, are the three numbers for Test case $1$, the three numbers for Test case $2$, the three numbers for Test case $3$, the three numbers for Test case $4$, followed by the single number for Test case $5$ and the single number for Test case $6$, each rendered in decimal scientific notation with six significant digits as specified above.",
            "solution": "The problem presented is valid and formalizes a deferred-correction technique for improving the Forward Euler method for solving initial value problems of the form $y'(t)=f(t,y(t))$ with an initial condition $y(t_0)=y_0$. The method is scientifically sound, well-posed, and all terms and procedures are defined unambiguously. It constitutes a standard problem in the field of numerical analysis for ordinary differential equations. We proceed with the solution.\n\nThe fundamental principle behind this method is the correction of the leading term in the local truncation error of the Forward Euler method. The Taylor series expansion of the exact solution $y(t)$ around $t_n$ is given by\n$$\ny(t_{n+1}) = y(t_n) + h y'(t_n) + \\frac{h^2}{2} y''(t_n) + \\mathcal{O}(h^3),\n$$\nwhere $h$ is the step size and $y'(t) = f(t, y(t))$. The Forward Euler method, $y_{n+1} = y_n + h f(t_n, y_n)$, approximates this expansion by retaining only the terms up to first order in $h$. The local truncation error is therefore $y(t_{n+1}) - (y(t_n) + h f(t_n, y(t_n))) = \\frac{h^2}{2} y''(t_n) + \\mathcal{O}(h^3)$, which leads to a global error of order $\\mathcal{O}(h)$.\n\nTo improve the accuracy, one can attempt to estimate and include the second-order term, $\\frac{h^2}{2} y''(t_n)$. This defines an idealized second-order method. The challenge is that $y''(t_n)$ is generally unknown. The proposed deferred-correction scheme addresses this by using a two-stage process.\n\nFirst, a preliminary, complete solution trajectory, denoted by $y_n^E$, is computed using the standard Forward Euler method over the entire interval $[t_0, T]$:\n$$\ny_{n+1}^E = y_n^E + h f(t_n, y_n^E), \\quad y_0^E = y_0.\n$$\nAlthough this solution is only first-order accurate, with a global error of $\\mathcal{O}(h)$, it provides an approximation of the solution at all grid points $t_n$.\n\nSecond, this preliminary solution is used to estimate the second derivative of the true solution, $y''(t_n)$. The definition of the second derivative is $y''(t) = \\frac{d}{dt} y'(t) = \\frac{d}{dt} f(t, y(t))$. A first-order finite difference approximation to this derivative at time $t_n$ is $\\frac{f(t_{n+1}, y(t_{n+1})) - f(t_n, y(t_n))}{h}$. The method approximates this by substituting the values from the preliminary Euler run, $y_n^E$ and $y_{n+1}^E$, for the true solution values $y(t_n)$ and $y(t_{n+1})$:\n$$\n\\widehat{y''}(t_n) := \\frac{f(t_{n+1}, y_{n+1}^E) - f(t_n, y_n^E)}{h}.\n$$\nThis calculation is performed for all necessary steps, i.e., for $n=0, 1, \\dots, N-1$. Since $y_n^E = y(t_n) + \\mathcal{O}(h)$, it can be shown that this approximation is first-order accurate, $\\widehat{y''}(t_n) = y''(t_n) + \\mathcal{O}(h)$.\n\nFinally, a new, corrected solution $y_n^C$ is computed. The integration scheme is modified to include the estimated error term. This results in a new one-step method where the correction term is pre-computed and acts as a forcing function:\n$$\ny_{n+1}^C = y_n^C + h f(t_n, y_n^C) + \\frac{h^2}{2} \\widehat{y''}(t_n), \\quad y_0^C = y_0.\n$$\nThe local truncation error of this corrected method is $\\mathcal{O}(h^3)$, because the $\\mathcal{O}(h^2)$ term from the Taylor expansion is approximately cancelled by the correction term: $\\frac{h^2}{2} y''(t_n) - \\frac{h^2}{2} \\widehat{y''}(t_n) = \\frac{h^2}{2} (y''(t_n) - (y''(t_n) + \\mathcal{O}(h))) = \\mathcal{O}(h^3)$. A method with local truncation error of order $\\mathcal{O}(h^{p+1})$ generally has a global error of order $\\mathcal{O}(h^p)$. Thus, we expect this corrected method to be second-order accurate, with a global error of $\\mathcal{O}(h^2)$. This hypothesis is tested in the specified observed-order calculations.\n\nThe algorithm is implemented as a general solver function that accepts the differential equation $f$, initial and final times $t_0$ and $T$, initial value $y_0$, and step size $h$. This function first performs the Euler run, then computes the array of $\\widehat{y''}(t_n)$ values, and finally performs the corrected integration. This solver is then applied to each of the six test cases defined in the problem statement. The requested quantities—absolute errors for the Euler and corrected methods, their ratio, and the observed order of convergence—are calculated and collected for the final output. The number of steps $N$ is taken to be $(T-t_0)/h$, and for all test cases this ratio is an integer as required for a uniform grid. The exact solutions provided are used to compute the errors at the final time $T$. The observed order of convergence, $p$, is computed using the formula $p = \\log(e(h_1)/e(h_2)) / \\log(2)$, which directly follows from the assumption that the error $e(h)$ behaves as $e(h) \\approx C h^p$ for some constant $C$.",
            "answer": "```python\nimport numpy as np\n\ndef deferred_correction_solver(f, t0, T, y0, h):\n    \"\"\"\n    Solves an ODE y'(t) = f(t, y) using Forward Euler and a deferred correction method.\n\n    Args:\n        f (callable): The function f(t, y).\n        t0 (float): Initial time.\n        T (float): Final time.\n        y0 (float): Initial value y(t0).\n        h (float): Step size.\n\n    Returns:\n        tuple: A tuple containing:\n            - y_euler_final (float): The final value from the Forward Euler method.\n            - y_corrected_final (float): The final value from the corrected method.\n    \"\"\"\n    if not np.isclose((T - t0) / h, round((T - t0) / h)):\n        raise ValueError(\"T-t0 must be an integer multiple of h\")\n    N = int(round((T - t0) / h))\n    t_grid = np.linspace(t0, T, N + 1)\n\n    # Stage 1: Compute preliminary solution using Forward Euler\n    yE = np.zeros(N + 1)\n    yE[0] = y0\n    for n in range(N):\n        yE[n + 1] = yE[n] + h * f(t_grid[n], yE[n])\n\n    # Stage 1.5: Compute the approximation of the second derivative\n    ypp_hat = np.zeros(N)\n    for n in range(N):\n        ypp_hat[n] = (f(t_grid[n + 1], yE[n + 1]) - f(t_grid[n], yE[n])) / h\n\n    # Stage 2: Compute the corrected solution\n    yC = np.zeros(N + 1)\n    yC[0] = y0\n    for n in range(N):\n        yC[n + 1] = yC[n] + h * f(t_grid[n], yC[n]) + (h**2 / 2) * ypp_hat[n]\n\n    return yE[N], yC[N]\n\ndef solve():\n    \"\"\"\n    Runs all test cases and prints the formatted results.\n    \"\"\"\n    results = []\n\n    # Test Case 1: y'(t) = -3y(t), h=0.1\n    f1 = lambda t, y: -3 * y\n    t0_1, T_1, y0_1, h_1 = 0, 1, 1, 0.1\n    y_exact_1 = np.exp(-3 * T_1)\n    yE_1, yC_1 = deferred_correction_solver(f1, t0_1, T_1, y0_1, h_1)\n    err_E1 = np.abs(yE_1 - y_exact_1)\n    err_C1 = np.abs(yC_1 - y_exact_1)\n    ratio1 = err_E1 / err_C1\n    results.extend([err_E1, err_C1, ratio1])\n\n    # Test Case 2: y'(t) = -y(t), h=1.0\n    f2 = lambda t, y: -1 * y\n    t0_2, T_2, y0_2, h_2 = 0, 1, 1, 1.0\n    y_exact_2 = np.exp(-1 * T_2)\n    yE_2, yC_2 = deferred_correction_solver(f2, t0_2, T_2, y0_2, h_2)\n    err_E2 = np.abs(yE_2 - y_exact_2)\n    err_C2 = np.abs(yC_2 - y_exact_2)\n    ratio2 = err_E2 / err_C2\n    results.extend([err_E2, err_C2, ratio2])\n\n    # Test Case 3: y'(t) = -y(t)^3, h=0.1\n    f3 = lambda t, y: -y**3\n    t0_3, T_3, y0_3, h_3 = 0, 1, 1, 0.1\n    y_exact_3 = 1 / np.sqrt(1 + 2 * T_3)\n    yE_3, yC_3 = deferred_correction_solver(f3, t0_3, T_3, y0_3, h_3)\n    err_E3 = np.abs(yE_3 - y_exact_3)\n    err_C3 = np.abs(yC_3 - y_exact_3)\n    ratio3 = err_E3 / err_C3\n    results.extend([err_E3, err_C3, ratio3])\n\n    # Test Case 4: y'(t) = t - y(t), h=0.1\n    f4 = lambda t, y: t - y\n    t0_4, T_4, y0_4, h_4 = 0, 1, 0, 0.1\n    y_exact_4 = T_4 - 1 + np.exp(-T_4)\n    yE_4, yC_4 = deferred_correction_solver(f4, t0_4, T_4, y0_4, h_4)\n    err_E4 = np.abs(yE_4 - y_exact_4)\n    err_C4 = np.abs(yC_4 - y_exact_4)\n    ratio4 = err_E4 / err_C4\n    results.extend([err_E4, err_C4, ratio4])\n\n    # Test Case 5: Observed order for Test Case 1\n    h5_1, h5_2 = 0.2, 0.1\n    _, yC_h1_5 = deferred_correction_solver(f1, t0_1, T_1, y0_1, h5_1)\n    err_h1_5 = np.abs(yC_h1_5 - y_exact_1)\n    err_h2_5 = err_C1 # Re-use calculation from Test Case 1\n    p5 = np.log(err_h1_5 / err_h2_5) / np.log(2)\n    results.append(p5)\n\n    # Test Case 6: Observed order for Test Case 3\n    h6_1, h6_2 = 0.2, 0.1\n    _, yC_h1_6 = deferred_correction_solver(f3, t0_3, T_3, y0_3, h6_1)\n    y_exact_6 = y_exact_3\n    err_h1_6 = np.abs(yC_h1_6 - y_exact_6)\n    err_h2_6 = err_C3 # Re-use calculation from Test Case 3\n    p6 = np.log(err_h1_6 / err_h2_6) / np.log(2)\n    results.append(p6)\n\n    # Format output as specified\n    formatted_results = [f\"{x:.6e}\" for x in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "When simulating conservative systems like oscillators, it is crucial to understand how a numerical method affects conserved quantities like energy over long periods. Even improved schemes like Heun's method (the explicit trapezoidal rule) can introduce a slow drift in energy. This exercise provides a deep dive into analyzing this numerical artifact by tasking you to compare the measured amplitude growth in a simulation with the theoretical prediction derived from the method's stability function . This bridges the gap between abstract stability analysis and the concrete behavior of a numerical code.",
            "id": "2402465",
            "problem": "Consider the linear second-order ordinary differential equation $y'' = -k\\,y$ with $k > 0$. Rewrite it as a first-order system for the state vector $z(t) = \\begin{bmatrix} x(t) \\\\ v(t) \\end{bmatrix}$, where $x(t) = y(t)$ and $v(t) = y'(t)$. The system then has the form $z'(t) = A z(t)$ with a constant matrix $A \\in \\mathbb{R}^{2 \\times 2}$. Use the initial condition $x(0) = 1$ and $v(0) = 0$. Let $\\omega = \\sqrt{k}$, and define the amplitude functional $A(t) = \\sqrt{x(t)^2 + \\left(\\dfrac{v(t)}{\\omega}\\right)^2}$. The exact continuous-time dynamics preserve $A(t)$ for all $t \\ge 0$ under these conditions. In this task, your program must use Heun's method (explicit trapezoidal rule) with a fixed step size $h$ to advance the first-order system over a time interval $[0,T]$, where $N = T/h$ is an integer. For a given $(k,h,T)$, define the per-step complex-amplification factor of Heun's method evaluated at the purely imaginary eigenvalue $i \\omega$ as $R(i \\omega h) = 1 + i \\omega h + \\tfrac{1}{2}(i \\omega h)^2$, and let $g(h,\\omega) = |R(i \\omega h)|$. Let $G(N,h,\\omega) = \\left(g(h,\\omega)\\right)^N$ be the predicted amplitude multiplication factor after $N$ steps. For each test case, compute the absolute difference between the numerically measured amplitude multiplication factor and the theoretical prediction $G(N,h,\\omega)$. The numerically measured amplitude multiplication factor must be computed as $A(T)/A(0)$ using the Heun-discretized trajectory. Your program must evaluate the following test suite of parameter triples $(k,h,T)$:\n- $(k,h,T) = (1.0, 0.1, 10.0)$,\n- $(k,h,T) = (4.0, 0.05, 5.0)$,\n- $(k,h,T) = (1.0, 0.5, 50.0)$,\n- $(k,h,T) = (1.0, 0.001, 1.0)$.\nAll quantities are non-dimensional, and no physical units are required. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3,r_4]$), where each $r_j$ is the absolute difference defined above for the corresponding test case, written in scientific notation with exactly $12$ significant digits.",
            "solution": "The problem statement is valid. It is a well-posed problem in the field of computational engineering, specifically concerning the numerical analysis of ordinary differential equations. All parameters and conditions are provided, and the objective is scientifically sound and verifiable. We proceed with the solution.\n\nThe problem centers on the linear second-order ordinary differential equation (ODE) for a simple harmonic oscillator, given by $y'' = -k\\,y$ for a positive constant $k > 0$. To solve this numerically, we first convert it into a system of first-order ODEs. Let the state vector be $z(t) = \\begin{bmatrix} x(t) \\\\ v(t) \\end{bmatrix}$, where $x(t) = y(t)$ represents position and $v(t) = y'(t)$ represents velocity. The derivatives are $x'(t) = v(t)$ and $v'(t) = y''(t) = -k\\,x(t)$. This yields the matrix form $z'(t) = A z(t)$, where:\n$$\nA = \\begin{pmatrix} 0  1 \\\\ -k  0 \\end{pmatrix}\n$$\nThe initial conditions are specified as $x(0) = 1$ and $v(0) = 0$, which corresponds to an initial state vector of $$z(0) = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}.$$\n\nThe numerical integration is to be performed using Heun's method (also known as the explicit trapezoidal rule or a second-order Runge-Kutta method) with a fixed step size $h$. For a general first-order system $z' = f(t,z)$, the update from a state $z_n$ at time $t_n$ to $z_{n+1}$ at time $t_{n+1} = t_n + h$ is a two-stage process:\n1.  Predictor: $$z_{n+1}^* = z_n + h f(t_n, z_n)$$\n2.  Corrector: $$z_{n+1} = z_n + \\frac{h}{2} \\left[ f(t_n, z_n) + f(t_{n+1}, z_{n+1}^*) \\right]$$\n\nFor our linear system, $f(t,z) = A z$. Substituting this into the Heun's method formulation gives:\n$z_{n+1} = z_n + \\frac{h}{2} \\left[ A z_n + A(z_n + h A z_n) \\right] = z_n + \\frac{h}{2} \\left[ 2 A z_n + h A^2 z_n \\right]$\nThis simplifies to a linear update rule $z_{n+1} = M_H z_n$, where $M_H$ is the amplification matrix:\n$$\nM_H = I + hA + \\frac{h^2}{2} A^2\n$$\nThe matrix $A^2$ is $$\\begin{pmatrix} 0  1 \\\\ -k  0 \\end{pmatrix} \\begin{pmatrix} 0  1 \\\\ -k  0 \\end{pmatrix} = \\begin{pmatrix} -k  0 \\\\ 0  -k \\end{pmatrix} = -kI.$$\nSubstituting $A$ and $A^2$ into the expression for $M_H$:\n$$\nM_H = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + h \\begin{pmatrix} 0  1 \\\\ -k  0 \\end{pmatrix} + \\frac{h^2}{2} \\begin{pmatrix} -k  0 \\\\ 0  -k \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{kh^2}{2}  h \\\\ -kh  1 - \\frac{kh^2}{2} \\end{pmatrix}\n$$\nThe numerical simulation thus involves iteratively applying this matrix $N=T/h$ times to the initial state vector $z_0$: $z_N = (M_H)^N z_0$.\n\nThe theoretically predicted amplitude multiplication factor, $G(N,h,\\omega)$, is based on stability analysis. The behavior of the numerical solution is related to the eigenvalues of the matrix $A$, which are $\\lambda_{\\pm} = \\pm i\\sqrt{k} = \\pm i\\omega$. The stability function for Heun's method, when applied to a test equation $u'=\\lambda u$, is $R(z) = 1+z+\\frac{1}{2}z^2$, where $z=h\\lambda$. The eigenvalues of the amplification matrix $M_H$ are given by $R(h\\lambda_{\\pm})$. The factor $g(h,\\omega)$ is defined as the magnitude of this stability function evaluated at one of the eigenvalues, $i\\omega$:\n$$\ng(h,\\omega) = |R(i\\omega h)| = \\left| 1 + i\\omega h + \\frac{1}{2}(i\\omega h)^2 \\right| = \\left| \\left(1 - \\frac{\\omega^2 h^2}{2}\\right) + i(\\omega h) \\right|\n$$\nThe magnitude is calculated as:\n$$\ng(h,\\omega) = \\sqrt{\\left(1 - \\frac{\\omega^2 h^2}{2}\\right)^2 + (\\omega h)^2} = \\sqrt{1 - \\omega^2 h^2 + \\frac{\\omega^4 h^4}{4} + \\omega^2 h^2} = \\sqrt{1 + \\frac{\\omega^4 h^4}{4}}\n$$\nSince $\\omega^2 = k$, this becomes $g(h,\\omega) = \\sqrt{1 + \\frac{k^2 h^4}{4}}$. The theoretical total amplification factor after $N$ steps is predicted to be $G(N,h,\\omega) = (g(h,\\omega))^N$.\n\nThe numerically measured amplitude multiplication factor is $A(T)/A(0)$. The amplitude functional is $A(t) = \\sqrt{x(t)^2 + (v(t)/\\omega)^2}$.\nWith initial conditions $x(0) = 1$ and $v(0) = 0$, the initial amplitude is $A(0) = \\sqrt{1^2 + (0/\\omega)^2} = 1$.\nThe final amplitude is $A(T) = \\sqrt{x_N^2 + (v_N/\\omega)^2}$, where $z_N = \\begin{bmatrix} x_N \\\\ v_N \\end{bmatrix}$ is the state after $N$ steps.\nThe measured factor is therefore simply $A(T)$.\n\nA discrepancy between $A(T)$ and $G(N,h,\\omega)$ is expected. The theoretical prediction $G$ assumes the growth is governed solely by the magnitude of the eigenvalues of $M_H$. This holds if $M_H$ is a normal matrix ($M_H^T M_H = M_H M_H^T$) and the norm used is the standard Euclidean $2$-norm. For $k=1$, the matrix $M_H$ is indeed normal, and the amplitude functional $A(t)$ corresponds to the Euclidean norm of $z(t)$. In this special case, the measured amplitude growth must match the theoretical prediction exactly, and any difference will be due to floating-point representation error. However, for $k \\neq 1$, $M_H$ is not normal. The evolution of the specific energy-like norm $A(t)$ under the action of a non-normal matrix does not generally follow the spectral radius. The recurrence relation is $$A_{n+1}^2 = (g(h, \\omega))^2 A_n^2 + \\frac{(k-1)h^2}{k} v_n^2.$$ The additional positive term for $k>1$ (or negative for $k1$) causes a drift that is not captured by the simple eigenvalue analysis. The problem requires computing this exact discrepancy.\n\nThe solution requires implementing a loop that iterates the state $(x_n, v_n)$ for $N$ steps using the derived update equations for $x_{n+1}$ and $v_{n+1}$. Then, the final state $(x_N, v_N)$ is used to compute the measured factor $A(T)$. This is compared to the theoretical factor $G(N,h,\\omega) = (1 + k^2 h^4 / 4)^{N/2}$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the given problem by simulating an ODE with Heun's method and comparing\n    the numerical amplitude growth with the theoretical prediction from stability analysis.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (k, h, T)\n        (1.0, 0.1, 10.0),\n        (4.0, 0.05, 5.0),\n        (1.0, 0.5, 50.0),\n        (1.0, 0.001, 1.0)\n    ]\n\n    results = []\n    for k, h, T in test_cases:\n        # Number of steps. The problem statement guarantees this is an integer.\n        N = int(round(T / h))\n\n        # Initial conditions\n        x = 1.0\n        v = 0.0\n\n        # Pre-calculate coefficients for Heun's method update matrix\n        # z_{n+1} = M_H * z_n\n        # M_H = [[c1, c2], [c3, c1]]\n        # c1 = 1 - k*h^2/2\n        # c2 = h\n        # c3 = -k*h\n        c1 = 1.0 - k * h**2 / 2.0\n        c2 = h\n        c3 = -k * h\n\n        # Run the simulation for N steps\n        for _ in range(N):\n            x_new = c1 * x + c2 * v\n            v_new = c3 * x + c1 * v\n            x, v = x_new, v_new\n        \n        # The final state is (x, v) at time T.\n\n        # Calculate the numerically measured amplitude multiplication factor.\n        # A(t) = sqrt(x(t)^2 + (v(t)/omega)^2), omega^2 = k\n        # A(0) = sqrt(1^2 + (0/omega)^2) = 1\n        # Measured factor = A(T) / A(0) = A(T)\n        measured_factor = np.sqrt(x**2 + v**2 / k)\n\n        # Calculate the theoretical predicted amplitude multiplication factor.\n        # g = |R(i*omega*h)| = sqrt(1 + (k^2 * h^4) / 4)\n        # G = g^N = (1 + (k^2 * h^4) / 4)^(N/2)\n        g_sq = 1.0 + k**2 * h**4 / 4.0\n        theoretical_factor = np.power(g_sq, N / 2.0)\n\n        # Compute the absolute difference\n        abs_diff = np.abs(measured_factor - theoretical_factor)\n        results.append(abs_diff)\n\n    # Format the results for the final print statement.\n    # The output must be in scientific notation with exactly 12 significant digits.\n    # The format specifier \"{:.11e}\" achieves this.\n    formatted_results = [f\"{r:.11e}\" for r in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}