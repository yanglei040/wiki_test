{
    "hands_on_practices": [
        {
            "introduction": "本实践将引导您实现块雅可比（Block-Jacobi）法，它是基础雅可比迭代的一种重要拓展。通过将未知量分组并求解一系列更小的对角块系统，该方法不仅是预条件技术的一个直观入门，也揭示了并行计算中区域分解策略的核心思想。您将亲手为一个源于有限元离散的线性系统实现该方法，并探索分块大小对求解效率的影响。",
            "id": "2406589",
            "problem": "实现一个程序，该程序使用块-Jacobi 迭代法，为从均匀网格上的标准线性有限元离散化产生的系统构建并求解线性系统，其中单元被分组为连续的未知数块。考虑一个模型问题，该问题为一个对称正定系统，由区间 $[0,1]$ 上具有齐次 Dirichlet 边界条件的 Poisson 算子的一维弱形式构建。设 $N$ 表示 $[0,1]$ 上的均匀单元数量，$h$ 表示网格尺寸，由 $h = 1/N$ 给出。内部节点集由 $\\{1,2,\\ldots,N-1\\}$ 索引；内部未知数的数量为 $n = N-1$。设 $\\{\\varphi_i\\}_{i=1}^{n}$ 表示与内部节点相关的标准连续分段线性帽子基函数。定义刚度矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 为\n$$\nA_{ij} = \\int_{0}^{1} \\varphi_i'(x)\\,\\varphi_j'(x)\\,dx \\quad \\text{for all } i,j \\in \\{1,\\ldots,n\\}.\n$$\n该矩阵是对称正定的。定义右端向量 $b \\in \\mathbb{R}^{n}$ 为 $b = A \\mathbf{1}$，其中 $\\mathbf{1} \\in \\mathbb{R}^{n}$ 是所有分量均为 $1$ 的向量。因此，$A x = b$ 的精确解为 $x^\\star = \\mathbf{1}$。\n\n将索引集 $\\{1,\\ldots,n\\}$ 按如下方式划分为大小为 $m$ 的连续块。对于给定的正整数 $m$，定义块 $B_1 = \\{1,2,\\ldots,\\min(m,n)\\}$，块 $B_2 = \\{m+1,\\ldots,\\min(2m,n)\\}$，以此类推，如果 $m$ 不能整除 $n$，则最后一个块可能更小。这种块划分模拟了将连续的单元分组到更大的子区域，并将其关联的连续内部自由度分配给一个块，其约定是共享的界面节点属于右侧的块，但最后一个界面（如果适用）属于最后一个块。\n\n定义带有松弛参数 $\\omega \\in \\mathbb{R}$ 的块-Jacobi 迭代，其递推关系为\n$$\nx^{(k+1)} = x^{(k)} + \\omega\\, M^{-1} \\left(b - A x^{(k)}\\right),\n$$\n其中 $x^{(0)} = \\mathbf{0}$，且 $M$ 是由 $A$ 中对应于块 $B_\\ell$ 的主子矩阵置于其对角线上而形成的块对角矩阵，即\n$$\nM = \\mathrm{diag}\\left(A_{B_1 B_1}, A_{B_2 B_2}, \\ldots, A_{B_p B_p}\\right),\n$$\n其中 $p$ 是块的数量。在实践中，一次块更新对每个块 $B_\\ell$ 应用局部求解 $A_{B_\\ell B_\\ell} \\, \\delta_{B_\\ell} = r_{B_\\ell}$，其中 $r = b - A x^{(k)}$，然后聚合校正量 $\\delta_{B_\\ell}$，使得 $x^{(k+1)} = x^{(k)} + \\omega \\,\\delta$，其中 $\\delta$ 在 $B_\\ell$ 上的分量为 $\\delta_{B_\\ell}$，在其他位置为零。停止准则是满足相对残差的最小整数 $k \\ge 1$\n$$\n\\frac{\\lVert b - A x^{(k)} \\rVert_{2}}{\\lVert b \\rVert_{2}} \\le \\mathrm{tol},\n$$\n或达到上限 $k = k_{\\max}$，以先发生者为准。欧几里得范数由 $\\lVert \\cdot \\rVert_{2}$ 表示。\n\n测试套件。您的程序必须对以下参数集运行块-Jacobi方法，每个参数集定义一个独立的测试用例：\n- 用例 1：$N = 8$，$m = 1$，$\\omega = 1.0$，$\\mathrm{tol} = 10^{-10}$，$k_{\\max} = 10000$。\n- 用例 2：$N = 8$，$m = 2$，$\\omega = 1.0$，$\\mathrm{tol} = 10^{-10}$，$k_{\\max} = 10000$。\n- 用例 3：$N = 15$，$m = 4$，$\\omega = 0.8$，$\\mathrm{tol} = 10^{-10}$，$k_{\\max} = 10000$。\n- 用例 4：$N = 12$，$m = 11$，$\\omega = 1.0$，$\\mathrm{tol} = 10^{-12}$，$k_{\\max} = 10000$。\n- 用例 5：$N = 16$，$m = 3$，$\\omega = 1.0$，$\\mathrm{tol} = 10^{-10}$，$k_{\\max} = 10000$。\n\n对于每个用例，输出块-Jacobi方法满足停止准则所用的迭代次数 $k$。约定如果在 $k_{\\max}$ 次迭代内未达到收敛，则输出为 $k_{\\max}$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[k_1,k_2,k_3,k_4,k_5]$），其中 $k_i$ 是按上述顺序列出的用例 $i$ 的整数迭代计数。不应打印任何额外的文本或行。",
            "solution": "首先对问题陈述进行严格的验证过程。\n\n**步骤1：提取已知条件**\n- **模型问题**：区间 $[0,1]$ 上具有齐次 Dirichlet 边界条件的一维 Poisson 算子弱形式。\n- **离散化**：在 $N$ 个单元的均匀网格上使用标准线性有限元。\n- **网格尺寸**：$h = 1/N$。\n- **未知数**：$n = N-1$ 个内部自由度，由 $\\{1,2,\\ldots,n\\}$ 索引。\n- **基函数**：$\\{\\varphi_i\\}_{i=1}^{n}$，连续的分段线性帽子函数。\n- **刚度矩阵**：$A \\in \\mathbb{R}^{n \\times n}$，由 $A_{ij} = \\int_{0}^{1} \\varphi_i'(x)\\,\\varphi_j'(x)\\,dx$ 定义。该矩阵被声明为对称正定。\n- **右端项**：$b \\in \\mathbb{R}^{n}$，定义为 $b = A \\mathbf{1}$，其中 $\\mathbf{1}$ 是所有元素均为1的向量。因此，$A x = b$ 的精确解为 $x^\\star = \\mathbf{1}$。\n- **块划分**：索引集 $\\{1,\\ldots,n\\}$ 被划分为连续的块 $B_\\ell$。对于块大小 $m$，有 $B_1 = \\{1,2,\\ldots,\\min(m,n)\\}$，$B_2 = \\{m+1,\\ldots,\\min(2m,n)\\}$，以此类推。\n- **迭代方法**：带松弛参数 $\\omega$ 的块-Jacobi 法，定义为 $x^{(k+1)} = x^{(k)} + \\omega\\, M^{-1} (b - A x^{(k)})$。\n- **初始猜测**：$x^{(0)} = \\mathbf{0}$。\n- **预条件子**：$M = \\mathrm{diag}(A_{B_1 B_1}, A_{B_2 B_2}, \\ldots, A_{B_p B_p})$，其中 $A_{B_\\ell B_\\ell}$ 是 $A$ 的主子矩阵。\n- **停止准则**：使相对残差 $\\frac{\\lVert b - A x^{(k)} \\rVert_{2}}{\\lVert b \\rVert_{2}} \\le \\mathrm{tol}$ 的最小整数 $k \\ge 1$。\n- **最大迭代次数**：如果未满足准则，则为 $k = k_{\\max}$。\n- **测试用例**：\n    1. $N = 8$，$m = 1$，$\\omega = 1.0$，$\\mathrm{tol} = 10^{-10}$，$k_{\\max} = 10000$。\n    2. $N = 8$，$m = 2$，$\\omega = 1.0$，$\\mathrm{tol} = 10^{-10}$，$k_{\\max} = 10000$。\n    3. $N = 15$，$m = 4$，$\\omega = 0.8$，$\\mathrm{tol} = 10^{-10}$，$k_{\\max} = 10000$。\n    4. $N = 12$，$m = 11$，$\\omega = 1.0$，$\\mathrm{tol} = 10^{-12}$，$k_{\\max} = 10000$。\n    5. $N = 16$，$m = 3$，$\\omega = 1.0$，$\\mathrm{tol} = 10^{-10}$，$k_{\\max} = 10000$。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学依据**：该问题在科学上是合理的。它描述了将有限元法应用于一维泊松方程以及使用块-Jacobi求解器，这两者都是计算工程和数值线性代数中的标准且成熟的课题。\n- **适定性**：该问题是适定的。已知一维泊松问题的刚度矩阵 $A$ 是对称正定（SPD）的。右端项 $b$ 的构造保证了唯一解的存在。块对角预条件子 $M$ 是可逆的，因为其对角块是 SPD 矩阵 $A$ 的主子矩阵，因此它们自身也是 SPD 且可逆的。因此，该迭代方法是良定义的。\n- **完整性与一致性**：该问题是自洽的。为每个测试用例提供了构建和求解系统所需的所有参数、定义和条件。没有矛盾之处。\n\n**步骤3：结论与行动**\n问题陈述有效。它具有科学依据，是适定的且完整的。将构建一个解决方案。\n\n**基于原则的解决方案设计**\n\n任务是为从有限元离散化导出的线性系统 $Ax=b$ 实现一个块-Jacobi迭代求解器。解决方案需要三个主要部分：系统组装、块划分和迭代求解器算法。\n\n首先，我们构建刚度矩阵 $A$ 和右端向量 $b$。基函数 $\\varphi_i(x)$ 是分段线性的“帽子”函数，在区间 $((i-1)h, (i+1)h)$ 上非零。其导数 $\\varphi_i'(x)$ 是分段常数函数，在 $((i-1)h, ih)$ 上等于 $1/h$，在 $(ih, (i+1)h)$ 上等于 $-1/h$。矩阵元素 $A_{ij} = \\int_{0}^{1} \\varphi_i'(x)\\varphi_j'(x)dx$ 的积分仅在导数的支集重叠时非零，这发生在 $|i-j| \\le 1$ 的情况下。\n对角线元素为：\n$$\nA_{ii} = \\int_{(i-1)h}^{(i+1)h} (\\varphi_i'(x))^2 dx = \\int_{(i-1)h}^{ih} \\left(\\frac{1}{h}\\right)^2 dx + \\int_{ih}^{(i+1)h} \\left(-\\frac{1}{h}\\right)^2 dx = \\frac{1}{h^2}h + \\frac{1}{h^2}h = \\frac{2}{h}\n$$\n对于 $j=i+1$ 的非对角线元素为：\n$$\nA_{i,i+1} = \\int_{ih}^{(i+1)h} \\varphi_i'(x)\\varphi_{i+1}'(x) dx = \\int_{ih}^{(i+1)h} \\left(-\\frac{1}{h}\\right)\\left(\\frac{1}{h}\\right) dx = -\\frac{1}{h^2}h = -\\frac{1}{h}\n$$\n根据对称性，$A_{i+1,i} = -1/h$。因此，对于 $n = N-1$ 个未知数，矩阵 $A$ 是一个 $n \\times n$ 的对称三对角矩阵：\n$$\nA = \\frac{1}{h}\n\\begin{pmatrix}\n2  -1  0  \\cdots  0 \\\\\n-1  2  -1   \\vdots \\\\\n0  \\ddots  \\ddots  \\ddots  0 \\\\\n\\vdots   -1  2  -1 \\\\\n0  \\cdots  0  -1  2\n\\end{pmatrix}\n$$\n右端向量 $b$ 定义为 $b = A\\mathbf{1}$，其中 $\\mathbf{1}$ 是所有元素都为1的 $n \\times 1$ 向量。此操作可以在构建 $A$ 之后直接执行。已知精确解为 $x^\\star = \\mathbf{1}$。\n\n其次，将索引集 $\\{0, 1, \\dots, n-1\\}$（为实现方便使用基于0的索引）划分为连续的块。给定块大小 $m$，通过取 $m$ 个连续索引来生成块，如果 $m$ 不能整除 $n$，则最后一个块可能更小。例如，如果 $n=7$ 且 $m=3$，索引块为 $\\{0, 1, 2\\}$、$\\{3, 4, 5\\}$ 和 $\\{6\\}$。\n\n第三，实现块-Jacobi迭代。迭代由 $x^{(k+1)} = x^{(k)} + \\omega M^{-1} r^{(k)}$ 给出，其中 $r^{(k)} = b - A x^{(k)}$ 是第 $k$ 次迭代的残差。矩阵 $M$ 是与指定划分相对应的 $A$ 的块对角部分。迭代的核心是计算更新量 $\\delta^{(k)} = M^{-1} r^{(k)}$。由于 $M$ 是块对角的，这等效于为每个块 $B_\\ell$ 求解一组更小的独立线性系统：\n$$\nA_{B_\\ell B_\\ell} \\, \\delta_{B_\\ell}^{(k)} = r_{B_\\ell}^{(k)}\n$$\n其中 $A_{B_\\ell B_\\ell}$ 是 $A$ 中对应于块 $B_\\ell$ 中索引的主子矩阵，而 $r_{B_\\ell}^{(k)}$ 是残差的相应子向量。求解这些小系统，并将得到的块解 $\\delta_{B_\\ell}^{(k)}$ 组装成全局更新向量 $\\delta^{(k)}$。然后更新解：$x^{(k+1)} = x^{(k)} + \\omega \\delta^{(k)}$。\n\n完整的算法如下：\n1.  初始化 $k=0$ 和解向量 $x^{(0)} = \\mathbf{0}$。\n2.  计算右端项的范数 $\\lVert b \\rVert_2$，用于停止准则。\n3.  对于 $k = 1, 2, \\ldots, k_{\\max}$：\n    a. 计算残差 $r^{(k-1)} = b - A x^{(k-1)}$。\n    b. 对于划分中的每个块 $B_\\ell$：\n       i. 提取子矩阵 $A_{B_\\ell B_\\ell}$ 和子残差 $r_{B_\\ell}^{(k-1)}$。\n       ii. 求解局部系统 $A_{B_\\ell B_\\ell} \\delta_{B_\\ell} = r_{B_\\ell}^{(k-1)}$ 以找到局部校正量 $\\delta_{B_\\ell}$。\n    c. 从局部校正量 $\\delta_{B_\\ell}$ 组装全局校正向量 $\\delta$。\n    d. 更新解：$x^{(k)} = x^{(k-1)} + \\omega \\delta$。\n    e. 计算新的残差 $r^{(k)} = b - A x^{(k)}$。\n    f. 检查停止准则：如果 $\\lVert r^{(k)} \\rVert_2 / \\lVert b \\rVert_2 \\le \\mathrm{tol}$，则终止并返回 $k$。\n4.  如果循环完成而未收敛，则返回 $k_{\\max}$。\n\n对问题陈述中指定的每个测试用例实施此过程。使用 NumPy 有助于矩阵构造、向量运算，以及通过 `numpy.linalg.solve` 求解每个块的小型线性系统。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_block_jacobi(N, m, omega, tol, k_max):\n    \"\"\"\n    Solves the 1D Poisson FEM system using a block-Jacobi iterative method.\n\n    Args:\n        N (int): Number of uniform elements.\n        m (int): Block size for the Jacobi method.\n        omega (float): Relaxation parameter.\n        tol (float): Relative residual tolerance for convergence.\n        k_max (int): Maximum number of iterations.\n\n    Returns:\n        int: The number of iterations taken to converge, or k_max.\n    \"\"\"\n    n = N - 1\n    if n = 0:\n        return 0\n\n    h = 1.0 / N\n\n    # Assemble the stiffness matrix A for the 1D Poisson problem.\n    # A = (1/h) * tridiag(-1, 2, -1)\n    diag = np.full(n, 2.0 / h)\n    off_diag = np.full(n - 1, -1.0 / h)\n    A = np.diag(diag) + np.diag(off_diag, k=1) + np.diag(off_diag, k=-1)\n\n    # Assemble the right-hand side b such that the exact solution is a vector of ones.\n    b = A @ np.ones(n)\n    norm_b = np.linalg.norm(b)\n    \n    # Handle the trivial case where b is the zero vector.\n    if norm_b == 0.0:\n        return 0\n\n    # Partition the indices {0, ..., n-1} into contiguous blocks of size m.\n    blocks_indices = []\n    start_idx = 0\n    while start_idx  n:\n        end_idx = min(start_idx + m, n)\n        blocks_indices.append(list(range(start_idx, end_idx)))\n        start_idx = end_idx\n\n    # Initialize the solution vector.\n    x = np.zeros(n)\n\n    # Perform the block-Jacobi iteration.\n    for k in range(1, k_max + 1):\n        # Calculate residual: r = b - A*x\n        r = b - A @ x\n        \n        # Calculate the update delta by solving block systems: M * delta = r\n        delta = np.zeros(n)\n        for block_idx in blocks_indices:\n            # np.ix_ is used to perform advanced indexing for submatrix extraction.\n            ix_ = np.ix_(block_idx, block_idx)\n            A_block = A[ix_]\n            r_block = r[block_idx]\n            \n            # Solve the small linear system for the current block.\n            # Principal submatrices of an SPD matrix are SPD, so this is safe.\n            try:\n                delta_block = np.linalg.solve(A_block, r_block)\n                delta[block_idx] = delta_block\n            except np.linalg.LinAlgError:\n                # In case of numerical failure, we assume non-convergence.\n                return k_max\n\n        # Apply relaxed update to the solution vector.\n        x = x + omega * delta\n        \n        # Check the stopping criterion based on the relative residual of the new iterate.\n        res_new = b - A @ x\n        rel_res = np.linalg.norm(res_new) / norm_b\n        \n        if rel_res = tol:\n            return k\n            \n    # If the loop completes, max iterations have been reached without convergence.\n    return k_max\n\ndef solve():\n    \"\"\"\n    Runs the block-Jacobi solver for the predefined test suite and prints results.\n    \"\"\"\n    # (N, m, omega, tol, k_max)\n    test_cases = [\n        (8, 1, 1.0, 1e-10, 10000),\n        (8, 2, 1.0, 1e-10, 10000),\n        (15, 4, 0.8, 1e-10, 10000),\n        (12, 11, 1.0, 1e-12, 10000),\n        (16, 3, 1.0, 1e-10, 10000)\n    ]\n\n    results = []\n    for case in test_cases:\n        N, m, omega, tol, k_max = case\n        iterations = run_block_jacobi(N, m, omega, tol, k_max)\n        results.append(iterations)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "虽然迭代法的目标是逐步减小误差，但不同误差度量在迭代过程中的表现可能出乎意料且不直观。本练习将通过最速下降法，构建一个真实残差范数 $\\Vert r_k \\Vert_2$ 严格下降，而预条件残差范数 $\\Vert z_k \\Vert_2$ 却并非单调的场景。这个关键的教学案例将加深您对预条件本质的理解：预条件器通过变换线性系统以改善其谱特性来加速收敛，而非保证每一步迭代中所有相关度量都单调递减。",
            "id": "2406627",
            "problem": "要求您构建并探究一个数学上受控的教学示例，在该示例中，求解线性系统时，真实残差序列 $r_k$ 的欧几里得范数随迭代递减，而预处理残差序列 $z_k = M^{-1} r_k$ 的欧几里得范数在每一步不一定递减。其目的是从基本原理出发，推断算法选择和线性变换如何与范数及单调性相互作用。\n\n从以下基本点出发：\n- 线性系统为 $A x = b$，其中 $A$ 是对称正定（SPD）矩阵。\n- 最小化严格凸二次函数 $f(x) = \\tfrac{1}{2} x^\\top A x - b^\\top x$ 等价于求解 $A x = b$。\n- 最速下降法使用负梯度方向来更新迭代点 $x_k$，其选择的步长能使 $f$ 沿搜索方向最小化。$f$ 的梯度为 $-\\nabla f(x) = b - A x$，即真实残差 $r(x) = b - A x$。\n- 预处理器是一个线性算子 $M$，且 $M$ 是对称正定的；它对残差向量的作用由预处理残差 $z = M^{-1} r$ 表示。$z$ 的欧几里得范数通常与 $r$ 的欧几里得范数不同，并且在一个没有明确最小化该范数的算法下，其范数序列不一定是单调的。\n\n您的程序必须：\n- 实现用于对称正定系统的最速下降法，采用精确线搜索，从初始向量 $x_0$ 开始，为指定的迭代次数 $K$ 生成真实残差序列 $\\{r_k\\}_{k=0}^K$。\n- 对于给定的对称正定预处理器 $M$，在每个记录的迭代索引 $k$ 处计算 $z_k = M^{-1} r_k$。\n- 对每个测试用例，判断序列 $\\{\\lVert r_k \\rVert_2\\}_{k=0}^K$ 是否严格递减以及序列 $\\{\\lVert z_k \\rVert_2\\}_{k=0}^K$ 是否严格递减。为此，使用一个固定的数值容差 $\\varepsilon$ 以避免因舍入误差导致的假阴性。对于本问题，使用 $\\varepsilon = 10^{-12}$，并且如果对于所有的 $k$ 都有 $a_{k+1} \\le (1 - \\varepsilon) a_k$，则称序列 $\\{a_k\\}$ 是严格递减的。\n- 为每个测试用例报告两个整数：如果被测试的序列根据上述规则是严格递减的，则为 $1$，否则为 $0$。这对整数的顺序为 $[\\text{标志\\_真实残差}, \\text{标志\\_预处理残差}]$。\n\n测试套件（所有矩阵和向量均已明确给出，并在适当情况下为对称正定）：\n- 用例 A（说明即使 $\\lVert z_k \\rVert_2$ 不递减，$\\lVert r_k \\rVert_2$ 也可以递减）：\n  - $A = \\begin{bmatrix} 1  0 \\\\ 0  4 \\end{bmatrix}$，$b = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$，$x_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$。\n  - 预处理器作用 $M^{-1} = \\begin{bmatrix} 1  0.9 \\\\ 0.9  1 \\end{bmatrix}$。\n  - 迭代次数 $K = 3$。\n- 用例 B（单位预处理器，因此两个序列重合）：\n  - $A = \\begin{bmatrix} 1  0 \\\\ 0  4 \\end{bmatrix}$，$b = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$，$x_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$。\n  - 预处理器作用 $M^{-1} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$。\n  - 迭代次数 $K = 3$。\n- 用例 C（边界情况，无迭代，单调性因条件不存在而自然满足）：\n  - $A = \\begin{bmatrix} 1  0 \\\\ 0  4 \\end{bmatrix}$，$b = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$，$x_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$。\n  - 预处理器作用 $M^{-1} = \\begin{bmatrix} 1  0.9 \\\\ 0.9  1 \\end{bmatrix}$。\n  - 迭代次数 $K = 0$。\n\n数值和实现细节：\n- 使用双精度浮点运算。\n- 使用欧几里得范数 $\\lVert \\cdot \\rVert_2$ 计算残差范数。\n- 使用容差 $\\varepsilon = 10^{-12}$ 按上述规定判断是否严格递减。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个测试用例对应一个双整数列表 $[r\\_flag, z\\_flag]$。\n- 对于上述三个用例，格式因此是无空格的单行，形式为\n  - $[[r\\_A,z\\_A],[r\\_B,z\\_B],[r\\_C,z\\_C]]$\n  其中 $r\\_A, z\\_A, r\\_B, z\\_B, r\\_C, z\\_C$ 的每一个值是 $1$ 或 $0$。",
            "solution": "所述问题业经检验，被证实是科学上合理的、适定的和客观的。为得到唯一解所需的所有数据和定义均已提供。指定为对称正定（$A$ 和 $M^{-1}$）的矩阵已被验证具有此性质。该问题是数值线性代数中的一个标准练习，旨在阐明迭代方法的基本性质。因此，我们可以着手进行严谨的求解。\n\n该问题要求实现并分析用于求解线性系统 $A x = b$ 的最速下降法，其中 $A$ 是一个 $n \\times n$ 的对称正定（SPD）矩阵。此方法等价于求严格凸二次函数 $f(x) = \\frac{1}{2} x^\\top A x - b^\\top x$ 的最小值。该函数的梯度 $\\nabla f(x) = A x - b$ 是真实残差 $r(x) = b - A x$ 的负值。\n\n最速下降算法从一个初始猜测 $x_0$ 开始，生成一个迭代序列 $\\{x_k\\}$。在每次迭代 $k$ 中，更新沿着负梯度的方向进行，即残差 $r_k = b - A x_k$ 的方向。更新规则为：\n$$\nx_{k+1} = x_k + \\alpha_k r_k\n$$\n其中步长 $\\alpha_k$ 的选择是为了使函数 $f$ 沿搜索方向最小化。即，$\\alpha_k$ 是 $\\min_{\\alpha \\in \\mathbb{R}} f(x_k + \\alpha r_k)$ 的解。为求得这个最优的 $\\alpha_k$，我们将 $f(x_k + \\alpha r_k)$ 对 $\\alpha$ 的导数设为零：\n$$\n\\frac{d}{d\\alpha} f(x_k + \\alpha r_k) = \\nabla f(x_k + \\alpha r_k)^\\top r_k = (A(x_k + \\alpha r_k) - b)^\\top r_k = 0\n$$\n$$\n(A x_k - b + \\alpha A r_k)^\\top r_k = (-r_k + \\alpha A r_k)^\\top r_k = -r_k^\\top r_k + \\alpha r_k^\\top A r_k = 0\n$$\n由于 $A$ 是对称正定且 $r_k \\neq 0$，因此 $r_k^\\top A r_k > 0$，我们可以解出 $\\alpha_k$：\n$$\n\\alpha_k = \\frac{r_k^\\top r_k}{r_k^\\top A r_k}\n$$\n这就是精确线搜索步长的公式。\n\n残差序列 $\\{r_k\\}$ 可以迭代计算。根据定义 $r_{k+1} = b - A x_{k+1}$ 和 $x_{k+1}$ 的更新规则，我们推导出递推关系：\n$$\nr_{k+1} = r_k - \\alpha_k A r_k\n$$\n这个递推关系允许从 $r_0 = b - A x_0$ 开始直接计算残差序列。\n\n问题要求分析两个范数序列的单调性：真实残差的欧几里得范数序列 $\\{\\|r_k\\|_2\\}_{k=0}^K$ 和预处理残差的欧几里得范数序列 $\\{\\|z_k\\|_2\\}_{k=0}^K$，其中 $z_k = M^{-1} r_k$。\n\n对于对称正定系统上的最速下降法，目标函数值序列 $f(x_k)$ 是严格递减的。这等价于误差的能量范数 $\\|x_k - x^*\\|_A^2$ 的严格递减，其中 $x^*$ 是真实解。这也意味着残差的 $A^{-1}$-范数 $\\|r_k\\|_{A^{-1}}^2 = r_k^\\top A^{-1} r_k$ 是严格递减的。虽然对于一般的 $n > 2$ 情况，这并不能保证欧几里得范数 $\\|r_k\\|_2$ 严格递减，但对于给定的二维二次问题，可以证明 $\\|r_k\\|_2$ 确实是严格递减的。这与连续残差正交的性质 $r_{k+1}^\\top r_k = 0$ 有关，对于二维空间，这意味着搜索方向在两个正交方向之间循环。\n\n预处理残差是 $z_k = M^{-1} r_k$。从 $r_k$ 到 $z_k$ 的映射是一个线性变换。最速下降法没有针对 $\\|z_k\\|_2$ 进行任何优化。序列 $\\{\\|z_k\\|_2\\}$ 的行为取决于变换 $M^{-1}$ 如何与残差向量序列 $\\{r_k\\}$ 相互作用。如果残差向量 $r_{k+1}$ 的方向相比于 $r_k$ 的方向被 $M^{-1}$ 显著放大，那么即使 $\\|r_{k+1}\\|_2  \\|r_k\\|_2$，也可能出现 $\\|z_{k+1}\\|_2 > \\|z_k\\|_2$ 的情况。该问题的构建就是为了展示这种现象。\n\n待实现的算法如下：\n1. 对每个测试用例，定义矩阵 $A, M^{-1}$，向量 $b, x_0$ 和整数 $K$。\n2. 初始化两个列表 `r_norms` 和 `z_norms`，用于存储范数序列。\n3. 计算初始残差 $r_0 = b - A x_0$ 和初始预处理残差 $z_0 = M^{-1} r_0$。\n4. 计算它们的欧几里得范数 $\\|r_0\\|_2$ 和 $\\|z_0\\|_2$，并将其追加到各自的列表中。\n5. 对 $k$ 从 $0$ 到 $K-1$ 进行循环：\n   a. 计算步长 $\\alpha_k = (r_k^\\top r_k) / (r_k^\\top A r_k)$。\n   b. 计算下一个残差 $r_{k+1} = r_k - \\alpha_k A r_k$。\n   c. 计算下一个预处理残差 $z_{k+1} = M^{-1} r_{k+1}$。\n   d. 计算范数 $\\|r_{k+1}\\|_2$ 和 $\\|z_{k+1}\\|_2$ 并将其追加到列表中。\n6. 循环结束后，分析 `r_norms` 和 `z_norms` 的单调性。如果对于所有的 $j=0, \\dots, K-1$，都有 $a_{j+1} \\le (1 - \\varepsilon) a_j$ 成立（给定容差 $\\varepsilon = 10^{-12}$），则序列 $\\{a_j\\}_{j=0}^K$ 是严格递减的。\n7. 如果 $K=0$，序列只有一个元素，条件因不存在而自然成立。两个单调性标志都设置为 $1$。否则，遍历序列中的相邻对并检查条件。如果有任何一对违反了条件，则将相应的标志设置为 $0$。\n\n此过程将应用于三个测试用例中的每一个，以生成所需的输出。用例 A 旨在显示 $\\{\\|z_k\\|_2\\}$ 的非单调性。用例 B 中 $M^{-1}=I$，将显示两个序列都是单调的，因为 $z_k=r_k$。用例 C 涵盖了 $K=0$ 的边界条件。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by implementing the steepest descent method and\n    checking the monotonicity of true and preconditioned residual norms.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        {\n            \"A\": np.array([[1.0, 0.0], [0.0, 4.0]]),\n            \"b\": np.array([1.0, 1.0]),\n            \"x0\": np.array([0.0, 0.0]),\n            \"M_inv\": np.array([[1.0, 0.9], [0.9, 1.0]]),\n            \"K\": 3,\n            \"epsilon\": 1e-12\n        },\n        # Case B\n        {\n            \"A\": np.array([[1.0, 0.0], [0.0, 4.0]]),\n            \"b\": np.array([1.0, 1.0]),\n            \"x0\": np.array([0.0, 0.0]),\n            \"M_inv\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"K\": 3,\n            \"epsilon\": 1e-12\n        },\n        # Case C\n        {\n            \"A\": np.array([[1.0, 0.0], [0.0, 4.0]]),\n            \"b\": np.array([1.0, 1.0]),\n            \"x0\": np.array([0.0, 0.0]),\n            \"M_inv\": np.array([[1.0, 0.9], [0.9, 1.0]]),\n            \"K\": 0,\n            \"epsilon\": 1e-12\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        A = case[\"A\"]\n        b = case[\"b\"]\n        x0 = case[\"x0\"]\n        M_inv = case[\"M_inv\"]\n        K = case[\"K\"]\n        epsilon = case[\"epsilon\"]\n\n        r_norms = []\n        z_norms = []\n\n        # Initial step (k=0)\n        r = b - A @ x0\n        z = M_inv @ r\n        \n        r_norms.append(np.linalg.norm(r, 2))\n        z_norms.append(np.linalg.norm(z, 2))\n\n        # Iterations from k=0 to K-1\n        for _ in range(K):\n            r_dot_r = r @ r\n            Ar = A @ r\n            r_dot_Ar = r @ Ar\n            \n            # Avoid division by zero if r is already zero.\n            if abs(r_dot_Ar)  1e-15:\n                # If r is effectively zero, the sequence has converged and stays constant.\n                # This would fail the strict decrease test, but we can stop.\n                # Just append the same norm to maintain sequence length.\n                r_norms.append(r_norms[-1])\n                z_norms.append(z_norms[-1])\n                continue\n\n            alpha = r_dot_r / r_dot_Ar\n            r = r - alpha * Ar\n            z = M_inv @ r\n            \n            r_norms.append(np.linalg.norm(r, 2))\n            z_norms.append(np.linalg.norm(z, 2))\n        \n        # Check for strict decrease\n        r_flag = 1\n        z_flag = 1\n\n        if K > 0:\n            for k in range(K):\n                # Check true residual norm\n                if r_norms[k+1] > (1 - epsilon) * r_norms[k]:\n                    r_flag = 0\n                    \n                # Check preconditioned residual norm\n                if z_norms[k+1] > (1 - epsilon) * z_norms[k]:\n                    z_flag = 0\n        \n        # For K=0, the loops do not run, and the flags remain 1, which is\n        # the correct 'vacuously true' result.\n\n        results.append([r_flag, z_flag])\n\n    # Final print statement in the exact required format.\n    # The format requires no spaces, e.g., [[1,0],[1,1],[1,1]].\n    # str(results).replace(' ', '') achieves this.\n    print(str(results).replace(' ', ''))\n\nsolve()\n```"
        },
        {
            "introduction": "共轭梯度（CG）法是求解对称正定线性系统的首选方法之一，但其收敛性能严重依赖于系统的条件数。本实践将展示如何通过构造一个基于矩阵逆的多项式近似的预条件器，来显著加速CG方法的收敛。通过对比无预条件、雅可比预条件和多项式预条件的CG方法，您将亲身体验到预条件技术在解决大规模科学计算问题时所带来的巨大性能提升。",
            "id": "2406599",
            "problem": "给定一个形如 $A_n x = b$ 的对称正定线性方程组族，其中 $A_n \\in \\mathbb{R}^{n \\times n}$ 是在开放区间 $(0,1)$ 上带齐次 Dirichlet 边界条件的一维负拉普拉斯算子的标准二阶有限差分离散化。具体来说，$A_n$ 是一个三对角矩阵，其主对角线上的元素为 $2$，第一亚对角线和第一超对角线上的元素为 $-1$，其他位置的元素均为零。设 $b \\in \\mathbb{R}^n$ 是所有分量均为 $1$ 的向量，初始猜测值为 $x_0 = 0$。记 $D_n = \\mathrm{diag}(A_n)$ 为由 $A_n$ 的对角线元素构成的对角矩阵，记 $R_n = D_n - A_n$ 为其严格非对角部分。对于一个非负整数 $m$，定义 $m$ 阶多项式近似逆（截断 Neumann 级数）为\n$$\nP_m \\;=\\; \\sum_{k=0}^{m} \\left(D_n^{-1} R_n\\right)^k \\, D_n^{-1}.\n$$\n对于下文指定的每个测试用例，考虑以下三个迭代次数，每个迭代次数均定义为最小的整数 $k \\in \\{0,1,2,\\dots,n\\}$，使得所述方法产生的迭代解 $x_k$ 满足相对残差 $\\|b - A_n x_k\\|_2 / \\|b\\|_2 \\le \\tau$，其中 $\\tau = 10^{-8}$，最大迭代次数为 $n$：\n$1)$ $k_{\\mathrm{unpre}}(n)$，通过生成 $A_n$-共轭搜索方向并且在逐次仿射 Krylov 子空间 $x_0 + \\mathcal{K}_k(A_n, r_0)$ 上最小化残差 $\\|b - A_n x\\|_2$ 的方法获得，其中 $r_0 = b - A_n x_0$。\n$2)$ $k_{\\mathrm{jac}}(n)$，通过将相同方法应用于由对角预处理算子 $D_n^{-1}$ 定义的左预处理系统获得，即在每次迭代中使用辅助更新 $z = D_n^{-1} r$ 来代替 $z = r$。\n$3)$ $k_{\\mathrm{poly}}(n,m)$，通过将相同方法应用于由多项式算子 $P_m$ 定义的左预处理系统获得，即在每次迭代中使用辅助更新 $z = P_m r$。\n\n测试套件。对于下方的每个数对 $(n,m)$，计算并报告整数三元组 $[\\,k_{\\mathrm{unpre}}(n),\\,k_{\\mathrm{jac}}(n),\\,k_{\\mathrm{poly}}(n,m)\\,]$：\n- $(n,m) = (100,0)$\n- $(n,m) = (100,3)$\n- $(n,m) = (200,3)$\n- $(n,m) = (5,10)$\n\n您的程序应生成单行输出，其中包含用方括号括起来的、由逗号分隔的这些三元组列表。具体来说，输出格式必须为\n$[\\,[k_{\\mathrm{unpre}}(n_1),k_{\\mathrm{jac}}(n_1),k_{\\mathrm{poly}}(n_1,m_1)],\\,[k_{\\mathrm{unpre}}(n_2),k_{\\mathrm{jac}}(n_2),k_{\\mathrm{poly}}(n_2,m_2)],\\,\\dots\\,]$，不含多余的空格或文本。",
            "solution": "对所述问题进行验证。\n\n**步骤 1：提取已知条件**\n-   **线性方程组**：$A_n x = b$，其中 $A_n \\in \\mathbb{R}^{n \\times n}$ 是对称正定 (SPD) 的。\n-   **矩阵 $A_n$**：一个三对角矩阵，其主对角线元素为 $2$，第一亚对角线和第一超对角线元素为 $-1$。这代表了一维有限差分拉普拉斯算子。\n-   **向量 $b$**：$b \\in \\mathbb{R}^n$，其中 $b_i = 1$ 对所有 $i=1, \\dots, n$ 成立。\n-   **初始猜测值 $x_0$**：零向量，$x_0 = 0$。\n-   **矩阵分解**：$A_n = D_n - R_n$，其中 $D_n = \\mathrm{diag}(A_n) = 2I_n$，$R_n$ 是严格非对角部分。\n-   **多项式预条件子 $P_m$**：$P_m = \\sum_{k=0}^{m} (D_n^{-1} R_n)^k D_n^{-1}$。\n-   **迭代方法**：共轭梯度 (CG) 法，通过其生成 $A_n$-共轭搜索方向以及在 Krylov 子空间上以特定方式最小化残差的性质被正确识别。\n-   **停止准则**：相对残差 2-范数必须小于或等于容差 $\\tau = 10^{-8}$，即 $\\|b - A_n x_k\\|_2 / \\|b\\|_2 \\le \\tau$。\n-   **最大迭代次数**：$n$。\n-   **待计算量**：每个测试用例 $(n,m)$ 的三个迭代次数：\n    1.  $k_{\\mathrm{unpre}}(n)$：标准、无预处理的 CG。\n    2.  $k_{\\mathrm{jac}}(n)$：使用 Jacobi 预条件子 $M=D_n$ 进行预处理的 CG。\n    3.  $k_{\\mathrm{poly}}(n,m)$：使用多项式预条件子 $M^{-1}=P_m$ 进行预处理的 CG。\n-   **测试用例**：$(n,m) \\in \\{(100,0), (100,3), (200,3), (5,10)\\}$。\n\n**步骤 2：使用提取的已知条件进行验证**\n根据指定标准对问题进行评估。\n-   **科学依据**：该问题在根本上是合理的。它涉及对共轭梯度法的分析，这是数值线性代数中的一个基石算法，应用于一个由 Poisson 方程离散化产生的经典 SPD 矩阵。所提出的预条件子——Jacobi 和多项式（Neumann 级数）——都是标准技术。\n-   **适定性**：所有组成部分都得到了精确定义。矩阵 $A_n$ 已知是 SPD 矩阵，确保 CG 方法适用并将收敛到唯一解。迭代次数是由明确的停止准则确定的良定义量。多项式预条件子 $P_m$ 基于 $A_n^{-1}$ 的 Neumann 级数，对于指定的矩阵 $A_n$，该级数是收敛的，因为 Jacobi 迭代矩阵 $J=D_n^{-1}R_n$ 的谱半径 $\\rho(J) = \\cos(\\pi/(n+1))  1$。\n-   **客观性**：问题以精确、客观的数学语言陈述，没有歧义或主观内容。\n\n**步骤 3：结论与行动**\n问题是**有效的**。这是一个在计算工程领域中适定且有科学依据的问题。将构建一个解决方案。\n\n**方法论**\n解决方案的核心在于实现预处理共轭梯度 (PCG) 算法。标准的（无预处理的）CG 方法是 PCG 的一个特例，其中预条件子是单位矩阵。\n\n用预条件子 $M$ 求解 $Ax=b$ 的 PCG 算法如下：\n1.  初始化：$k=0$, $x_0 = 0$, $r_0 = b - A x_0 = b$。\n2.  如果 $\\|r_0\\|_2 / \\|b\\|_2 \\le \\tau$，以迭代次数 $k=0$ 终止。\n3.  求解 $z_0$：$M z_0 = r_0$。\n4.  设置搜索方向：$p_0 = z_0$。\n5.  对 $k = 0, 1, 2, \\dots$ 进行迭代，最多到 $n-1$：\n    a. 计算步长：$\\alpha_k = \\frac{r_k^T z_k}{p_k^T A p_k}$。\n    b. 更新解：$x_{k+1} = x_k + \\alpha_k p_k$。\n    c. 更新残差：$r_{k+1} = r_k - \\alpha_k A p_k$。\n    d. 检查收敛性：如果 $\\|r_{k+1}\\|_2 / \\|b\\|_2 \\le \\tau$，以迭代次数 $k+1$ 终止。\n    e. 应用预条件子：求解 $M z_{k+1} = r_{k+1}$。\n    f. 计算改进因子：$\\beta_k = \\frac{r_{k+1}^T z_{k+1}}{r_k^T z_k}$。\n    g. 更新搜索方向：$p_{k+1} = z_{k+1} + \\beta_k p_k$。\n\n通过改变“求解”步骤 ($M z = r$)，将使用这同一个算法来计算所有需要的迭代次数。\n\n**预条件子实现**\n所需的三种场景对应于预处理步骤 $z_k = M^{-1} r_k$ 的三种不同定义。\n\n1.  **无预处理 ($k_{\\mathrm{unpre}}$)**：这等价于设置 $M=I_n$，即单位矩阵。预处理步骤是平凡的：$z_k = r_k$。\n\n2.  **Jacobi 预处理 ($k_{\\mathrm{jac}}$)**：预条件子是 $M=D_n = \\mathrm{diag}(A_n)$。对于给定的矩阵 $A_n$，$D_n = 2I_n$。预处理步骤是一个简单的缩放：$z_k = D_n^{-1} r_k = \\frac{1}{2}r_k$。\n\n3.  **多项式预处理 ($k_{\\mathrm{poly}}$)**：预条件子由其逆定义，$M^{-1} = P_m$。预处理步骤是一个矩阵-向量乘积：$z_k = P_m r_k$。算子 $P_m$ 由下式给出\n    $$\n    P_m = \\sum_{j=0}^{m} (D_n^{-1} R_n)^j D_n^{-1}\n    $$\n    应用 $z_k = P_m r_k$ 的计算是高效的，无需显式构造矩阵 $P_m$。令 $T = D_n^{-1} R_n$ 且 $v = D_n^{-1} r_k$。问题简化为计算 $z_k = (\\sum_{j=0}^{m} T^j) v$。这可以通过一个迭代循环实现：\n    -   初始化和 $s = v$。\n    -   初始化项 $t = v$。\n    -   对于 $j = 1, \\dots, m$：\n        -   更新项：$t = Tt$。\n        -   更新和：$s = s + t$。\n    -   结果为 $z_k = s$。\n    由于 $D_n = 2I_n$ 且 $R_n$ 是一个在其第一非对角线上元素为 $1$ 的稀疏矩阵，矩阵-向量乘积 $Tt$ 的计算成本低，其开销为 $O(n)$ 次浮点运算。应用多项式预条件子的总成本为 $O(m \\cdot n)$。\n\n对于测试用例 $(n,m)=(100,0)$，多项式预条件子 $P_0$ 简化为 $P_0 = (D_n^{-1}R_n)^0 D_n^{-1} = I_n D_n^{-1} = D_n^{-1}$。这与 Jacobi 预条件子相同。因此，我们预期 $k_{\\mathrm{jac}}(100) = k_{\\mathrm{poly}}(100,0)$，这可作为实现的一致性检查。\n\n最终的实现将构造稀疏矩阵 $A_n$ 和 $R_n$ 以及向量 $b$，然后针对每个测试用例 $(n,m)$ 对三种预处理策略中的每一种执行 PCG 算法。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import sparse\n\ndef get_matrices(n):\n    \"\"\"Constructs the sparse matrices A_n and R_n.\"\"\"\n    # A_n is the 1D finite difference matrix: tridiagonal(-1, 2, -1)\n    diagonals_A = [-1 * np.ones(n - 1), 2 * np.ones(n), -1 * np.ones(n - 1)]\n    offsets_A = [-1, 0, 1]\n    A_n = sparse.diags(diagonals_A, offsets_A, shape=(n, n), format='csr')\n\n    # R_n = D_n - A_n. Since D_n = 2*I, R_n has 0 on diagonal, 1 on off-diagonals.\n    diagonals_R = [np.ones(n - 1), np.ones(n - 1)]\n    offsets_R = [-1, 1]\n    R_n = sparse.diags(diagonals_R, offsets_R, shape=(n, n), format='csr')\n    \n    return A_n, R_n\n\ndef poly_preconditioner_solve(r, R_matrix, m):\n    \"\"\"Computes z = P_m * r.\"\"\"\n    n = r.shape[0]\n    \n    # D_n = 2*I, so D_n_inv is a scaling by 0.5\n    d_inv_r = 0.5 * r\n    \n    # T = D_n_inv * R_n is a scaling of R_n by 0.5\n    T_mat = 0.5 * R_matrix\n\n    z = d_inv_r.copy()\n    t = d_inv_r.copy()\n    \n    for _ in range(m):\n        t = T_mat @ t\n        z += t\n        \n    return z\n\ndef pcg_solve(A, b, x_init, m_solve, tol, max_iter):\n    \"\"\"\n    Solves Ax=b using the Preconditioned Conjugate Gradient method.\n    \n    Args:\n        A: The system matrix (sparse).\n        b: The right-hand side vector.\n        x_init: The initial guess vector.\n        m_solve: A function that computes z = M_inv * r.\n        tol: The relative residual tolerance.\n        max_iter: The maximum number of iterations.\n        \n    Returns:\n        The number of iterations performed.\n    \"\"\"\n    x = x_init.copy()\n    r = b - A @ x\n    \n    norm_b = np.linalg.norm(b)\n    if norm_b == 0.0:\n        return 0\n\n    if np.linalg.norm(r) / norm_b = tol:\n        return 0\n\n    z = m_solve(r)\n    p = z.copy()\n    rz_old = r.dot(z)\n\n    for k in range(max_iter):\n        Ap = A @ p\n        alpha = rz_old / p.dot(Ap)\n        \n        x += alpha * p\n        r_new = r - alpha * Ap\n\n        if np.linalg.norm(r_new) / norm_b = tol:\n            return k + 1\n\n        z_new = m_solve(r_new)\n        rz_new = r_new.dot(z_new)\n        \n        beta = rz_new / rz_old\n        \n        p = z_new + beta * p\n        r = r_new\n        rz_old = rz_new\n\n    return max_iter\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (100, 0),\n        (100, 3),\n        (200, 3),\n        (5, 10),\n    ]\n\n    results = []\n    tau = 1e-8\n\n    for n, m in test_cases:\n        A_n, R_n = get_matrices(n)\n        b = np.ones(n)\n        x0 = np.zeros(n)\n        max_iter = n\n\n        # 1. Unpreconditioned CG\n        m_solve_unpre = lambda r: r\n        k_unpre = pcg_solve(A_n, b, x0, m_solve_unpre, tau, max_iter)\n        \n        # 2. Jacobi preconditioned CG\n        m_solve_jac = lambda r: 0.5 * r\n        k_jac = pcg_solve(A_n, b, x0, m_solve_jac, tau, max_iter)\n        \n        # 3. Polynomial preconditioned CG\n        m_solve_poly = lambda r: poly_preconditioner_solve(r, R_n, m)\n        k_poly = pcg_solve(A_n, b, x0, m_solve_poly, tau, max_iter)\n        \n        results.append([k_unpre, k_jac, k_poly])\n\n    # Format the output string as specified, with no extra whitespace.\n    inner_strings = [f\"[{r[0]},{r[1]},{r[2]}]\" for r in results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}