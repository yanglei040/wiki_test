{
    "hands_on_practices": [
        {
            "introduction": "Numerical instability can arise from multiple sources. This first practice focuses on the sensitivity of a polynomial's value to small perturbations in its coefficients, a common scenario when coefficients are derived from experimental data. Through this exercise , you will derive the relevant condition number from first principles and then design a simple, low-degree polynomial that is well-behaved at one point but catastrophically unstable at another. This will reveal how subtractive cancellation, where a near-zero result is obtained from the difference of large numbers, is a fundamental cause of ill-conditioning.",
            "id": "2378702",
            "problem": "You are asked to analyze the conditioning of polynomial evaluation with respect to perturbations in the polynomialâ€™s coefficients, a situation frequently arising in computational engineering when coefficients come from measurement or modeling uncertainties. Let the data be the coefficients of a polynomial $p(x) = \\sum_{k=0}^{n} a_{k} x^{k}$, and let the evaluation point $x$ be exact. Consider small, componentwise relative perturbations to the coefficients of the form $\\tilde{a}_{k} = a_{k} (1 + \\delta_{k})$ with $|\\delta_{k}| \\ll 1$, and let $\\tilde{p}(x) = \\sum_{k=0}^{n} \\tilde{a}_{k} x^{k}$ denote the perturbed value at the same $x$.\n\nStarting from the fundamental definitions of forward error and condition number, and using first-order (linearized) perturbation analysis, derive an expression for the coefficientwise relative condition number of the evaluation map $a \\mapsto p(x)$ at a fixed $x$. Use this expression to design a concrete polynomial $p(x)$ such that evaluation is well-conditioned at $x = 0$ but catastrophically ill-conditioned at $x = 1$ under these coefficientwise relative perturbations. Your design must be justified from first principles and should use the smallest possible degree that satisfies the stated properties. Provide your final polynomial in expanded standard form with simplified coefficients. The final answer must be a single analytic expression for $p(x)$.",
            "solution": "The problem requires the derivation of a condition number for polynomial evaluation and the design of a specific polynomial based on this analysis. The process must be validated and executed with scientific rigor.\n\n**Problem Validation**\n\nFirst, I shall validate the problem statement.\nThe givens are:\n1.  A polynomial $p(x) = \\sum_{k=0}^{n} a_{k} x^{k}$.\n2.  The data are the coefficients $a = (a_0, a_1, \\ldots, a_n)$.\n3.  The evaluation point $x$ is exact.\n4.  Perturbations are componentwise relative on the coefficients: $\\tilde{a}_{k} = a_{k} (1 + \\delta_{k})$ with $|\\delta_{k}| \\ll 1$.\n5.  The perturbed polynomial is $\\tilde{p}(x) = \\sum_{k=0}^{n} \\tilde{a}_{k} x^{k}$.\n6.  The objective is twofold:\n    a. Derive the coefficientwise relative condition number for the map $a \\mapsto p(x)$.\n    b. Design a polynomial $p(x)$ of smallest possible degree that is well-conditioned at $x = 0$ and catastrophically ill-conditioned at $x = 1$.\n\nThe problem is scientifically grounded, rooted in the standard theory of numerical analysis and perturbation theory. It is well-posed, with clear objectives and formalizable definitions. The terminology is precise and objective. There are no contradictions, missing information, or pseudoscientific claims. The problem is valid. We may proceed to the solution.\n\n**Part 1: Derivation of the Condition Number**\n\nThe evaluation of the polynomial $p(x)$ at a fixed point $x$ can be viewed as a function $f$ that maps the vector of coefficients $a = (a_0, a_1, \\ldots, a_n)^T$ to a scalar value $y = p(x)$.\nThe problem states that the coefficients $a_k$ are perturbed to $\\tilde{a}_k = a_k(1+\\delta_k)$, where $\\delta_k$ are small relative changes. This constitutes a backward error. The resulting change in the output, $\\tilde{p}(x) - p(x)$, leads to the forward error.\n\nThe absolute forward error is $\\Delta p(x) = \\tilde{p}(x) - p(x)$.\n$$ \\Delta p(x) = \\sum_{k=0}^{n} \\tilde{a}_{k} x^{k} - \\sum_{k=0}^{n} a_{k} x^{k} = \\sum_{k=0}^{n} (\\tilde{a}_{k} - a_{k}) x^{k} $$\nSubstituting the perturbation model $\\tilde{a}_{k} = a_{k}(1 + \\delta_{k})$, we get $\\tilde{a}_{k} - a_{k} = a_{k} \\delta_{k}$.\n$$ \\Delta p(x) = \\sum_{k=0}^{n} a_{k} \\delta_{k} x^{k} $$\nThis is an exact expression for the change in $p(x)$. Since we are performing a first-order analysis, higher-order terms in $\\delta_k$ are ignored, but here no such terms appear, so the expression is exact.\n\nThe relative forward error is $\\frac{|\\Delta p(x)|}{|p(x)|}$. The size of the input perturbation (the backward error) is defined componentwise. A natural measure for its magnitude is $\\epsilon = \\max_{k} |\\delta_k|$.\n\nThe condition number $\\kappa$ is defined as the maximum ratio of the relative forward error to the relative backward error, in the limit of infinitesimal perturbations:\n$$ \\kappa = \\lim_{\\epsilon \\to 0} \\sup_{\\max_k|\\delta_k| \\le \\epsilon} \\frac{ \\frac{|\\Delta p(x)|}{|p(x)|} }{ \\epsilon } $$\nLet us find the supremum of $|\\Delta p(x)|$ for a given $\\epsilon$. Using the triangle inequality:\n$$ |\\Delta p(x)| = \\left| \\sum_{k=0}^{n} a_{k} \\delta_{k} x^{k} \\right| \\le \\sum_{k=0}^{n} |a_{k}| |\\delta_{k}| |x|^{k} $$\nSince $|\\delta_k| \\le \\epsilon$ for all $k$, we can write:\n$$ \\sum_{k=0}^{n} |a_{k}| |\\delta_{k}| |x|^{k} \\le \\sum_{k=0}^{n} |a_{k}| \\epsilon |x|^{k} = \\epsilon \\sum_{k=0}^{n} |a_{k}| |x|^{k} $$\nThis upper bound is attainable. We can choose $\\delta_k = \\epsilon \\cdot \\text{sign}(a_k x^k)$, which satisfies $|\\delta_k| \\le \\epsilon$. With this choice, all terms in the sum $\\sum a_k \\delta_k x^k$ become non-negative, and the inequality becomes an equality.\nTherefore, the supremum is:\n$$ \\sup_{\\max_k|\\delta_k| \\le \\epsilon} |\\Delta p(x)| = \\epsilon \\sum_{k=0}^{n} |a_{k}| |x|^{k} $$\nSubstituting this into the definition of the condition number:\n$$ \\kappa = \\frac{1}{|p(x)|} \\lim_{\\epsilon \\to 0} \\frac{\\epsilon \\sum_{k=0}^{n} |a_{k}| |x|^{k}}{\\epsilon} = \\frac{\\sum_{k=0}^{n} |a_{k}| |x|^{k}}{|p(x)|} $$\nRecognizing that $p(x) = \\sum_{k=0}^{n} a_k x^k$, we arrive at the final expression for the coefficientwise relative condition number:\n$$ \\kappa(x) = \\frac{\\sum_{k=0}^{n} |a_{k}| |x|^{k}}{\\left| \\sum_{k=0}^{n} a_{k} x^{k} \\right|} $$\n\n**Part 2: Design of the Polynomial**\n\nWe must design a polynomial $p(x)$ of minimal degree such that its evaluation is well-conditioned at $x=0$ and catastrophically ill-conditioned at $x=1$. A condition number $\\kappa \\approx 1$ signifies a well-conditioned problem, while $\\kappa \\to \\infty$ signifies an ill-conditioned one.\n\n**Condition at $x=0$:**\nFor $x=0$, the condition number is (using the convention $0^0=1$):\n$$ \\kappa(0) = \\frac{\\sum_{k=0}^{n} |a_{k}| |0|^{k}}{\\left| \\sum_{k=0}^{n} a_{k} 0^{k} \\right|} = \\frac{|a_{0}|}{|a_{0}|} $$\nFor $\\kappa(0)$ to be defined and equal to $1$, we must have $a_0 \\neq 0$. With this simple constraint, evaluation at $x=0$ is always optimally well-conditioned.\n\n**Condition at $x=1$:**\nFor $x=1$, the condition number is:\n$$ \\kappa(1) = \\frac{\\sum_{k=0}^{n} |a_{k}| |1|^{k}}{\\left| \\sum_{k=0}^{n} a_{k} 1^{k} \\right|} = \\frac{\\sum_{k=0}^{n} |a_{k}|}{\\left| \\sum_{k=0}^{n} a_{k} \\right|} $$\nTo make this problem catastrophically ill-conditioned, we need $\\kappa(1)$ to be extremely large, ideally infinite. This occurs when the denominator is zero while the numerator is non-zero. The denominator is the absolute value of the sum of the coefficients, whereas the numerator is the sum of the absolute values of the coefficients. Ill-conditioning arises from subtractive cancellation, where $\\sum a_k$ is close to zero but some individual $|a_k|$ are large.\n\nWe seek the polynomial of the smallest degree that satisfies these properties.\n- **Degree $n=0$**: $p(x) = a_0$. We must have $a_0 \\neq 0$.\n  Then $\\kappa(1) = \\frac{|a_0|}{|a_0|} = 1$. The problem is well-conditioned. This degree is not sufficient.\n\n- **Degree $n=1$**: $p(x) = a_1 x + a_0$.\n  For well-conditioning at $x=0$, we require $a_0 \\neq 0$.\n  For catastrophic ill-conditioning at $x=1$, we require the denominator of $\\kappa(1)$ to be zero:\n  $$ \\left| \\sum_{k=0}^{1} a_k \\right| = |a_1 + a_0| = 0 \\implies a_1 = -a_0 $$\n  The numerator of $\\kappa(1)$ is $\\sum_{k=0}^{1} |a_k| = |a_1| + |a_0| = |-a_0| + |a_0| = 2|a_0|$. Since $a_0 \\neq 0$, the numerator is strictly positive.\n  With $a_1 = -a_0$ and $a_0 \\neq 0$, the condition number $\\kappa(1)$ becomes infinite.\n  We can choose the simplest non-zero value for $a_0$. Let $a_0 = 1$. This implies $a_1 = -1$.\n  The resulting polynomial is:\n  $$ p(x) = (-1)x + 1 = 1 - x $$\nThis is a polynomial of degree $1$, which is the minimum possible, as shown above.\nLet us verify the properties for $p(x) = 1-x$:\n- The coefficients are $a_0 = 1$ and $a_1 = -1$.\n- At $x=0$: $p(0) = 1$. The condition number is $\\kappa(0) = \\frac{|a_1|\\cdot|0| + |a_0|}{|p(0)|} = \\frac{|1|}{|1|} = 1$. This is well-conditioned.\n- At $x=1$: $p(1) = 1-1 = 0$. The condition number is $\\kappa(1) = \\frac{|a_1| + |a_0|}{|p(1)|} = \\frac{|-1| + |1|}{|0|} = \\frac{2}{0}$, which is infinite. This is catastrophically ill-conditioned.\n\nThe polynomial $p(x) = 1-x$ satisfies all requirements of the problem. It is of minimal degree and is presented in expanded standard form.",
            "answer": "$$\n\\boxed{1-x}\n$$"
        },
        {
            "introduction": "Beyond coefficient uncertainty, the stability of polynomial evaluation is also highly dependent on where it is evaluated. This practice  shifts our focus to the conditioning with respect to the input variable $x$ and explores the profound connection between evaluation stability and the location of a polynomial's roots. By analyzing a hypothetical polynomial whose roots are all clustered in a small interval, you will determine the worst-case scenario for evaluation far from this region, providing a clear illustration of why evaluating polynomials far from their \"region of interest\" can be a numerically perilous task.",
            "id": "2378696",
            "problem": "Consider a real polynomial $p$ of degree $n=37$ whose (not necessarily distinct) real roots $\\{r_k\\}_{k=1}^{37}$ all lie in the interval $[0,1]$. You will evaluate $p$ at the point $x^{\\ast}=150$. Using only fundamental definitions of conditioning for function evaluation with respect to input perturbations and standard properties of polynomials and derivatives, derive from first principles an expression for the relative condition number of evaluating $p$ at $x^{\\ast}$ with respect to perturbations in the input $x$. Then, over all such polynomials $p$ with arbitrary nonzero leading coefficient, determine the maximal possible value of this relative condition number at $x^{\\ast}$, given only that all roots lie in $[0,1]$. Provide your final answer as a single exact analytic expression. Do not round.",
            "solution": "The relative condition number, $\\kappa_f(x)$, for the evaluation of a differentiable function $f(x)$ at a point $x$ with respect to perturbations in $x$ is defined from first principles as the magnitude of the ratio of the relative error in the output to the relative error in the input for an infinitesimal perturbation. The formal expression is:\n$$ \\kappa_f(x) = \\left| \\frac{x f'(x)}{f(x)} \\right| $$\nThe problem concerns a real polynomial $p(x)$ of degree $n=37$. Let the roots of this polynomial be the set $\\{r_k\\}_{k=1}^{37}$, which are all real and lie in the interval $[0,1]$. The polynomial can be represented in its factored form using these roots:\n$$ p(x) = c \\prod_{k=1}^{n} (x - r_k) $$\nwhere $c$ is an arbitrary non-zero real constant representing the leading coefficient, and the degree is $n=37$.\n\nTo find the derivative $p'(x)$ required for the condition number, we employ logarithmic differentiation, which is a standard property derived from the rules of calculus. For any $x$ that is not a root of $p(x)$, we take the natural logarithm of the absolute value of $p(x)$:\n$$ \\ln|p(x)| = \\ln\\left|c \\prod_{k=1}^{n} (x - r_k)\\right| = \\ln|c| + \\sum_{k=1}^{n} \\ln|x - r_k| $$\nDifferentiating this expression with respect to $x$ yields the ratio $\\frac{p'(x)}{p(x)}$:\n$$ \\frac{p'(x)}{p(x)} = \\frac{d}{dx} \\left( \\ln|c| + \\sum_{k=1}^{n} \\ln|x - r_k| \\right) = \\sum_{k=1}^{n} \\frac{1}{x - r_k} $$\nThis expression for the logarithmic derivative of a polynomial is independent of the leading coefficient $c$.\n\nBy substituting this result into the fundamental definition of the relative condition number, we obtain the specific expression for the polynomial $p(x)$:\n$$ \\kappa_p(x) = \\left| x \\sum_{k=1}^{n} \\frac{1}{x - r_k} \\right| $$\nThis is the required expression derived from first principles.\n\nWe are tasked with evaluating this condition number at the point $x^{\\ast} = 150$. The degree is $n=37$, and all roots $r_k$ are constrained to the interval $[0, 1]$. At $x^{\\ast}=150$, the condition number is:\n$$ \\kappa_p(x^{\\ast}) = \\left| 150 \\sum_{k=1}^{37} \\frac{1}{150 - r_k} \\right| $$\nThe problem specifies that $r_k \\in [0, 1]$ for all $k \\in \\{1, \\dots, 37\\}$. Thus, for any root $r_k$, the term $150 - r_k$ is strictly positive, with values in the range $[149, 150]$. Consequently, each term $\\frac{1}{150 - r_k}$ in the sum is positive. The sum itself must be positive. Since the multiplier $x^{\\ast}=150$ is also positive, the entire expression within the absolute value signs is positive. We can therefore remove the absolute value:\n$$ \\kappa_p(x^{\\ast}) = 150 \\sum_{k=1}^{37} \\frac{1}{150 - r_k} $$\nTo find the maximal possible value of $\\kappa_p(x^{\\ast})$, we must maximize this expression over all valid choices of the roots $\\{r_k\\}_{k=1}^{37}$. This is equivalent to maximizing the sum:\n$$ S = \\sum_{k=1}^{37} \\frac{1}{150 - r_k} $$\nLet us analyze the behavior of an individual term of this sum, defined by the function $g(r) = \\frac{1}{150 - r}$, for $r \\in [0, 1]$. To determine the monotonicity of $g(r)$, we calculate its first derivative with respect to $r$:\n$$ g'(r) = \\frac{d}{dr} (150 - r)^{-1} = (-1)(150 - r)^{-2}(-1) = \\frac{1}{(150 - r)^2} $$\nSince the square of any non-zero real number is positive, $g'(r) > 0$ for all $r$ in the domain, including the interval $[0, 1]$. This shows that $g(r)$ is a strictly increasing function on its domain.\n\nThe sum $S$ is a sum of $37$ independent terms, $S = \\sum_{k=1}^{37} g(r_k)$. To maximize $S$, we must maximize each term $g(r_k)$ individually. Because $g(r)$ is strictly increasing on the interval $[0, 1]$, its maximum value is attained at the right endpoint of the interval, which is $r=1$.\nTherefore, the sum $S$ is maximized when all roots are chosen to be as large as possible, i.e., $r_k = 1$ for all $k=1, \\dots, 37$. This corresponds to a polynomial of the form $p(x) = c(x-1)^{37}$.\n\nSubstituting $r_k = 1$ for all $k$ into the expression for the sum gives the maximum value, $S_{\\max}$:\n$$ S_{\\max} = \\sum_{k=1}^{37} \\frac{1}{150 - 1} = \\sum_{k=1}^{37} \\frac{1}{149} = 37 \\times \\frac{1}{149} = \\frac{37}{149} $$\nFinally, the maximal possible value of the relative condition number at $x^{\\ast}=150$ is obtained by substituting $S_{\\max}$ back into the expression for $\\kappa_p(x^{\\ast})$:\n$$ \\kappa_{\\max} = 150 \\times S_{\\max} = 150 \\times \\frac{37}{149} = \\frac{5550}{149} $$\nThis fraction is irreducible, as $149$ is a prime number and it does not divide $5550$. This is the final exact analytical expression.",
            "answer": "$$ \\boxed{\\frac{5550}{149}} $$"
        },
        {
            "introduction": "Having explored how different factors can cause ill-conditioning, we now turn to a powerful mitigation strategy: the choice of basis. While two polynomials may be mathematically identical, their numerical behavior can differ drastically depending on their representation. In this exercise , you will compare the evaluation of a specific polynomial represented in the standard monomial basis versus the Newton basis. This direct, quantitative comparison will provide a striking demonstration of how a numerically aware choice of basis is a cornerstone of robust computational engineering.",
            "id": "2378682",
            "problem": "In computational engineering, the sensitivity of evaluating a polynomial at a point depends on how the polynomial is represented. Consider the monomial basis $\\{1, x, x^{2}, x^{3}\\}$ and the Newton basis associated with the nodes $t_{0}=10$, $t_{1}=11$, $t_{2}=12$, namely $\\{1,\\,(x-t_{0}),\\,(x-t_{0})(x-t_{1}),\\,(x-t_{0})(x-t_{1})(x-t_{2})\\}$. Define the polynomial\n$$\np(x) \\;=\\; 1 \\;+\\; (x-10) \\;+\\; (x-10)(x-11) \\;+\\; (x-10)(x-11)(x-12),\n$$\nand the evaluation point $x^{\\ast} = 11.5$.\n\nFor a fixed representation basis $\\{\\phi_{k}(x)\\}_{k=0}^{3}$ and its coefficient vector $a = (a_{0},a_{1},a_{2},a_{3})^{\\top}$ such that $p(x) = \\sum_{k=0}^{3} a_{k}\\,\\phi_{k}(x)$, the evaluation at $x^{\\ast}$ is the linear functional $y = \\sum_{k=0}^{3} a_{k}\\,\\phi_{k}(x^{\\ast})$. Using the Euclidean norm (two-norm), the absolute condition number of this functional is $\\|\\phi(x^{\\ast})\\|_{2}$, where $\\phi(x^{\\ast})=(\\phi_{0}(x^{\\ast}),\\ldots,\\phi_{3}(x^{\\ast}))^{\\top}$, and the relative condition number is\n$$\n\\kappa \\;=\\; \\frac{\\|a\\|_{2}\\,\\|\\phi(x^{\\ast})\\|_{2}}{|y|}.\n$$\n\nTreat the monomial representation and the Newton representation (with the nodes $10,11,12$) as two distinct bases for the same polynomial $p(x)$. Compute the ratio\n$$\nR \\;=\\; \\frac{\\kappa_{\\text{monomial}}}{\\kappa_{\\text{Newton}}},\n$$\nand round your final answer to four significant figures. No units are required.",
            "solution": "The problem statement is critically evaluated and found to be valid. It is scientifically grounded in the principles of numerical analysis, specifically the study of polynomial conditioning. The problem is well-posed, objective, self-contained, and all provided data are consistent and sufficient for arriving at a unique solution. We may therefore proceed with the derivation.\n\nThe objective is to compute the ratio $R = \\frac{\\kappa_{\\text{monomial}}}{\\kappa_{\\text{Newton}}}$, where $\\kappa$ is the relative condition number for polynomial evaluation. The polynomial is given by\n$$p(x) = 1 + (x-10) + (x-10)(x-11) + (x-10)(x-11)(x-12).$$\nThe evaluation point is $x^{\\ast} = 11.5$. The value of the polynomial at this point is\n$$p(11.5) = 1 + (11.5-10) + (11.5-10)(11.5-11) + (11.5-10)(11.5-11)(11.5-12)$$\n$$y = p(11.5) = 1 + (1.5) + (1.5)(0.5) + (1.5)(0.5)(-0.5) = 1 + 1.5 + 0.75 - 0.375 = 2.875.$$\n\nThe relative condition number for evaluating $p(x) = \\sum_{k=0}^{3} a_{k}\\phi_{k}(x)$ at $x^{\\ast}$ is given by\n$$\\kappa = \\frac{\\|a\\|_{2}\\|\\phi(x^{\\ast})\\|_{2}}{|y|},$$\nwhere $a = (a_{0}, a_{1}, a_{2}, a_{3})^{\\top}$ is the vector of coefficients and $\\phi(x^{\\ast}) = (\\phi_{0}(x^{\\ast}), \\phi_{1}(x^{\\ast}), \\phi_{2}(x^{\\ast}), \\phi_{3}(x^{\\ast}))^{\\top}$ is the vector of basis functions evaluated at $x^{\\ast}$.\n\nThe ratio $R$ is therefore\n$$R = \\frac{\\kappa_{\\text{monomial}}}{\\kappa_{\\text{Newton}}} = \\frac{\\frac{\\|a_{\\text{monomial}}\\|_{2}\\|\\phi_{\\text{monomial}}(x^{\\ast})\\|_{2}}{|y|}}{\\frac{\\|a_{\\text{Newton}}\\|_{2}\\|\\phi_{\\text{Newton}}(x^{\\ast})\\|_{2}}{|y|}} = \\frac{\\|a_{\\text{monomial}}\\|_{2}\\|\\phi_{\\text{monomial}}(x^{\\ast})\\|_{2}}{\\|a_{\\text{Newton}}\\|_{2}\\|\\phi_{\\text{Newton}}(x^{\\ast})\\|_{2}}.$$\nWe must now compute the four norms in this expression.\n\nFirst, we analyze the representation in the Newton basis. The basis functions are $\\phi_{0,N}(x) = 1$, $\\phi_{1,N}(x) = (x-10)$, $\\phi_{2,N}(x) = (x-10)(x-11)$, and $\\phi_{3,N}(x) = (x-10)(x-11)(x-12)$.\nFrom the definition of $p(x)$, the coefficient vector in this basis is directly given as\n$$a_{\\text{Newton}} = (1, 1, 1, 1)^{\\top}.$$\nThe Euclidean norm of this vector is\n$$\\|a_{\\text{Newton}}\\|_{2} = \\sqrt{1^{2} + 1^{2} + 1^{2} + 1^{2}} = \\sqrt{4} = 2.$$\nThe basis functions evaluated at $x^{\\ast} = 11.5$ are:\n$$\\phi_{0,N}(11.5) = 1$$\n$$\\phi_{1,N}(11.5) = 11.5 - 10 = 1.5$$\n$$\\phi_{2,N}(11.5) = (11.5 - 10)(11.5 - 11) = (1.5)(0.5) = 0.75$$\n$$\\phi_{3,N}(11.5) = (11.5 - 10)(11.5 - 11)(11.5 - 12) = (1.5)(0.5)(-0.5) = -0.375$$\nThe vector of evaluated basis functions is $\\phi_{\\text{Newton}}(x^{\\ast}) = (1, 1.5, 0.75, -0.375)^{\\top}$. Its norm is\n$$\\|\\phi_{\\text{Newton}}(x^{\\ast})\\|_{2} = \\sqrt{1^{2} + (1.5)^{2} + (0.75)^{2} + (-0.375)^{2}} = \\sqrt{1 + 2.25 + 0.5625 + 0.140625} = \\sqrt{3.953125}.$$\n\nSecond, we analyze the representation in the monomial basis, $\\{\\phi_{k,M}(x)\\}_{k=0}^{3} = \\{1, x, x^{2}, x^{3}\\}$. To find the coefficient vector $a_{\\text{monomial}}$, we must expand $p(x)$ into its standard polynomial form.\n$$p(x) = 1 + (x-10) + (x^{2} - 21x + 110) + (x^{2} - 21x + 110)(x-12)$$\n$$p(x) = 1 + (x-10) + (x^{2} - 21x + 110) + (x^{3} - 12x^2 - 21x^2 + 252x + 110x - 1320)$$\n$$p(x) = 1 + (x-10) + (x^{2} - 21x + 110) + (x^{3} - 33x^{2} + 362x - 1320)$$\nCollecting terms by powers of $x$:\n$$p(x) = x^{3} + (1 - 33)x^{2} + (1 - 21 + 362)x + (1 - 10 + 110 - 1320)$$\n$$p(x) = x^{3} - 32x^{2} + 342x - 1219.$$\nThe coefficient vector is $a_{\\text{monomial}} = (-1219, 342, -32, 1)^{\\top}$. Its norm is\n$$\\|a_{\\text{monomial}}\\|_{2} = \\sqrt{(-1219)^{2} + (342)^{2} + (-32)^{2} + 1^{2}} = \\sqrt{1485961 + 116964 + 1024 + 1} = \\sqrt{1603950}.$$\nThe monomial basis functions evaluated at $x^{\\ast} = 11.5$ are:\n$$\\phi_{0,M}(11.5) = (11.5)^{0} = 1$$\n$$\\phi_{1,M}(11.5) = (11.5)^{1} = 11.5$$\n$$\\phi_{2,M}(11.5) = (11.5)^{2} = 132.25$$\n$$\\phi_{3,M}(11.5) = (11.5)^{3} = 1520.875$$\nThe vector is $\\phi_{\\text{monomial}}(x^{\\ast}) = (1, 11.5, 132.25, 1520.875)^{\\top}$. Its norm is\n$$\\|\\phi_{\\text{monomial}}(x^{\\ast})\\|_{2} = \\sqrt{1^{2} + (11.5)^{2} + (132.25)^{2} + (1520.875)^{2}}$$\n$$\\|\\phi_{\\text{monomial}}(x^{\\ast})\\|_{2} = \\sqrt{1 + 132.25 + 17490.0625 + 2313063.4765625} = \\sqrt{2330686.7890625}.$$\n\nFinally, we compute the ratio $R$:\n$$R = \\frac{\\sqrt{1603950} \\cdot \\sqrt{2330686.7890625}}{2 \\cdot \\sqrt{3.953125}} = \\frac{1}{2} \\sqrt{\\frac{1603950 \\cdot 2330686.7890625}{3.953125}}$$\n$$R \\approx \\frac{1}{2} \\sqrt{\\frac{3.7383907 \\times 10^{12}}{3.953125}} \\approx \\frac{1}{2} \\sqrt{9.456813 \\times 10^{11}} \\approx \\frac{1}{2} (972461.49)$$\n$$R \\approx 486230.745.$$\nRounding to four significant figures gives $4.862 \\times 10^{5}$.",
            "answer": "$$\\boxed{4.862 \\times 10^{5}}$$"
        }
    ]
}