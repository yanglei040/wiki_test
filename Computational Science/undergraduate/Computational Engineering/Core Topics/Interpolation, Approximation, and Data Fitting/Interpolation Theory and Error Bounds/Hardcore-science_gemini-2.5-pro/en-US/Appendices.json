{
    "hands_on_practices": [
        {
            "introduction": "Is it possible for two different functions to have the exact same interpolating polynomial? This exercise explores the fundamental structure of the interpolation error, revealing that the difference between a function and its interpolant is directly related to a polynomial whose roots are the interpolation nodes. By working through this problem , you will gain a deeper insight into why the choice of nodes is crucial and how Chebyshev polynomials provide a powerful tool for minimizing interpolation error.",
            "id": "2404709",
            "problem": "Let $x_{1}, x_{2}, \\dots, x_{10}$ be the $10$ distinct nodes in $(-1,1)$ defined as the zeros of the Chebyshev polynomial of the first kind of degree $10$, where $T_{10}(x)$ is defined by $T_{10}(x) = \\cos\\!\\big(10\\,\\arccos(x)\\big)$. Consider the functions $f(x) = \\exp(x)$ and $g(x) = f(x) + \\alpha \\prod_{k=1}^{10} (x - x_{k})$, where $\\alpha$ is a real constant. \n\nUsing only fundamental properties of polynomial interpolation and the definition of $T_{10}(x)$ given above, justify that $f(x)$ and $g(x)$ have the same unique degree-$9$ interpolating polynomial at the nodes $\\{x_{k}\\}_{k=1}^{10}$. Then determine the unique positive value of $\\alpha$ such that \n$$\\max_{x \\in [-1,1]} |g(x) - f(x)| = \\frac{1}{8}.$$\n\nProvide the value of $\\alpha$ as your final answer. No rounding is required.",
            "solution": "The problem statement must first be validated for scientific soundness, well-posedness, and objectivity.\n\n**Step 1: Extract Givens**\n- Nodes: $x_{1}, x_{2}, \\dots, x_{10}$ are $10$ distinct nodes in the interval $(-1,1)$.\n- Definition of nodes: The nodes $\\{x_k\\}_{k=1}^{10}$ are the zeros of the Chebyshev polynomial of the first kind of degree $10$, $T_{10}(x)$.\n- Definition of Chebyshev polynomial: $T_{10}(x) = \\cos(10 \\arccos(x))$.\n- Function definitions: $f(x) = \\exp(x)$ and $g(x) = f(x) + \\alpha \\prod_{k=1}^{10} (x - x_{k})$, where $\\alpha$ is a real constant.\n- Condition: The unique positive value of $\\alpha$ must be determined such that $\\max_{x \\in [-1,1]} |g(x) - f(x)| = \\frac{1}{8}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is situated within the field of computational engineering, specifically in interpolation theory.\n1.  **Scientific or Factual Unsoundness**: The problem is built upon standard definitions and properties of polynomial interpolation and Chebyshev polynomials. The functions defined are standard elementary functions. There are no violations of mathematical logic or scientific principles.\n2.  **Non-Formalizable or Irrelevant**: The problem is a formal mathematical exercise directly relevant to the topic of interpolation and approximation theory.\n3.  **Incomplete or Contradictory Setup**: The problem is self-contained. All necessary information is provided.\n4.  **Unrealistic or Infeasible**: The conditions are mathematically sound and do not represent any physical or scientific impossibility.\n5.  **Ill-Posed or Poorly Structured**: The existence and uniqueness of an interpolating polynomial of a given degree through a given number of distinct points is a fundamental theorem of numerical analysis. The terms are well-defined.\n6.  **Outside Scientific Verifiability**: The claims and the result can be verified through direct mathematical derivation.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A solution will be provided.\n\nThe problem consists of two parts. First, we must justify that $f(x)$ and $g(x)$ share the same unique degree-$9$ interpolating polynomial at the specified nodes. Second, we must determine the positive constant $\\alpha$.\n\nLet $P_{9}(x)$ denote the unique polynomial of degree at most $9$ that interpolates a function at the $10$ distinct nodes $\\{x_k\\}_{k=1}^{10}$.\nFor the function $f(x)$, its interpolating polynomial, let us call it $P_{f}(x)$, must satisfy the conditions:\n$$P_{f}(x_k) = f(x_k) \\quad \\text{for } k = 1, 2, \\dots, 10.$$\nFor the function $g(x)$, its interpolating polynomial, let us call it $P_{g}(x)$, must satisfy the conditions:\n$$P_{g}(x_k) = g(x_k) \\quad \\text{for } k = 1, 2, \\dots, 10.$$\nThe function $g(x)$ is defined as $g(x) = f(x) + \\alpha \\prod_{j=1}^{10} (x - x_{j})$. Let us evaluate $g(x)$ at each of the interpolation nodes $x_k$:\n$$g(x_k) = f(x_k) + \\alpha \\prod_{j=1}^{10} (x_k - x_{j}).$$\nThe product term $\\prod_{j=1}^{10} (x_k - x_{j})$ contains the factor $(x_k - x_k)$ when the index $j$ equals $k$. This factor is equal to $0$. Consequently, the entire product is zero.\nThus, for each node $x_k$:\n$$g(x_k) = f(x_k) + \\alpha \\cdot 0 = f(x_k).$$\nThis shows that at the $10$ distinct interpolation nodes, the functions $f(x)$ and $g(x)$ have identical values. Therefore, their respective interpolating polynomials must satisfy:\n$$P_{g}(x_k) = g(x_k) = f(x_k) = P_{f}(x_k) \\quad \\text{for } k = 1, 2, \\dots, 10.$$\nConsider the difference polynomial $\\Delta(x) = P_{f}(x) - P_{g}(x)$. Since both $P_{f}(x)$ and $P_{g}(x)$ are polynomials of degree at most $9$, their difference $\\Delta(x)$ is also a polynomial of degree at most $9$.\nWe have shown that $\\Delta(x_k) = P_{f}(x_k) - P_{g}(x_k) = 0$ for all $10$ distinct nodes $\\{x_k\\}$. A polynomial of degree at most $9$ that has $10$ distinct roots must be the zero polynomial.\nTherefore, $\\Delta(x) = 0$ for all $x$, which implies $P_{f}(x) = P_{g}(x)$. This concludes the first part of the problem: $f(x)$ and $g(x)$ have the same unique degree-$9$ interpolating polynomial.\n\nNext, we must determine the value of $\\alpha$ from the condition:\n$$\\max_{x \\in [-1,1]} |g(x) - f(x)| = \\frac{1}{8}.$$\nLet us analyze the left-hand side of this equation. From the definition of $g(x)$, we have:\n$$g(x) - f(x) = \\left( f(x) + \\alpha \\prod_{k=1}^{10} (x - x_{k}) \\right) - f(x) = \\alpha \\prod_{k=1}^{10} (x - x_{k}).$$\nThe condition becomes:\n$$\\max_{x \\in [-1,1]} \\left| \\alpha \\prod_{k=1}^{10} (x - x_{k}) \\right| = \\frac{1}{8}.$$\nSince $\\alpha$ is a constant, we can write this as:\n$$|\\alpha| \\max_{x \\in [-1,1]} \\left| \\prod_{k=1}^{10} (x - x_{k}) \\right| = \\frac{1}{8}.$$\nThe nodes $\\{x_k\\}_{k=1}^{10}$ are the zeros of the Chebyshev polynomial $T_{10}(x)$. The polynomial $\\prod_{k=1}^{10} (x - x_{k})$ is a monic polynomial of degree $10$ with these same zeros.\nThe Chebyshev polynomial of the first kind of degree $n$, $T_n(x)$, has a leading coefficient of $2^{n-1}$ for $n \\ge 1$. For $n=10$, the leading coefficient is $2^{10-1} = 2^9$.\nThus, $T_{10}(x)$ can be written in its factored form as:\n$$T_{10}(x) = 2^9 \\prod_{k=1}^{10} (x - x_{k}).$$\nFrom this, we can express the product term:\n$$\\prod_{k=1}^{10} (x - x_{k}) = \\frac{T_{10}(x)}{2^9}.$$\nSubstituting this into our equation gives:\n$$|\\alpha| \\max_{x \\in [-1,1]} \\left| \\frac{T_{10}(x)}{2^9} \\right| = \\frac{1}{8}.$$\n$$|\\alpha| \\frac{1}{2^9} \\max_{x \\in [-1,1]} |T_{10}(x)| = \\frac{1}{8}.$$\nA fundamental property of the Chebyshev polynomial of the first kind, $T_n(x) = \\cos(n \\arccos(x))$, is that its maximum absolute value on the interval $[-1, 1]$ is $1$. This is because the function $\\cos(\\theta)$ oscillates between $-1$ and $1$.\nSo, $\\max_{x \\in [-1,1]} |T_{10}(x)| = 1$.\nThe equation simplifies to:\n$$|\\alpha| \\frac{1}{2^9} \\cdot 1 = \\frac{1}{8}.$$\n$$|\\alpha| \\frac{1}{512} = \\frac{1}{8}.$$\nSolving for $|\\alpha|$:\n$$|\\alpha| = \\frac{512}{8} = 64.$$\nThe problem asks for the unique positive value of $\\alpha$. Therefore, we select the positive solution.\n$$\\alpha = 64.$$\nThis completes the derivation.",
            "answer": "$$\\boxed{64}$$"
        },
        {
            "introduction": "In engineering and physics, we often have a choice between fitting data with a generic polynomial or a model derived from first principles. This practice contrasts a purely mathematical quadratic interpolant with a physically-motivated exponential decay model for radioactive decay, requiring you to derive an error bound for the polynomial from scratch. This exercise  demonstrates the practical importance of error bounds and highlights the trade-offs between general-purpose interpolation and model-driven curve fitting.",
            "id": "2404756",
            "problem": "A radioisotope sample exhibits nuclear decay that is well modeled by the fundamental first-order rate law from nuclear physics, which implies that the activity $A(t)$ satisfies $\\frac{dA}{dt}=-\\lambda A(t)$ with solution $A(t)=A(0)\\exp(-\\lambda t)$, where $\\lambda>0$ is the decay constant. An ideal detector records the activity at times $t=0,1,5$ days, yielding the following exact measurements: $A(0)=1000$ counts per second, $A(1)=1000\\cdot 2^{-2/5}$ counts per second, and $A(5)=250$ counts per second.\n\n- Using only these three measurements, construct the unique quadratic interpolant $p_2(t)$ that passes through the data points $(0,A(0))$, $(1,A(1))$, and $(5,A(5))$, and evaluate $p_2(3)$.\n- Independently, use the physical exponential decay model together with the endpoint measurements at $t=0$ and $t=5$ to determine the decay constant $\\lambda$ and predict the activity $A(3)$ at $t=3$ days.\n- Derive, from first principles and without invoking any shortcut formulas, an upper bound on the interpolation error at $t=3$ of the form $|A(3)-p_2(3)|\\leq B$, by combining a remainder estimate based on $A^{(3)}(t)$ with a bound on $|A^{(3)}(t)|$ obtained from the exponential decay model on the interval $[0,5]$. State the explicit bound $B$ you obtain.\n\nFinally, compute the absolute discrepancy $|p_2(3)-A(3)|$ and report its value. Round your answer to four significant figures and express it in counts per second. Provide only this single numerical value as your final answer. Angles are not involved in this problem.",
            "solution": "The supplied problem is first subjected to a validation procedure.\n\n**Step 1: Extract Givens**\n- The governing differential equation for activity $A(t)$ is $\\frac{dA}{dt}=-\\lambda A(t)$.\n- The physical model for activity is $A(t) = A(0)\\exp(-\\lambda t)$, where the decay constant $\\lambda > 0$.\n- The exact measurements at specific times are:\n  - $t_0=0$ days, $y_0 = A(0) = 1000$ counts per second.\n  - $t_1=1$ day, $y_1 = A(1) = 1000 \\cdot 2^{-2/5}$ counts per second.\n  - $t_2=5$ days, $y_2 = A(5) = 250$ counts per second.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, employing the standard first-order exponential decay model from nuclear physics. It is well-posed, as it requests a series of specific, computable quantities. The objectivity is clear from the precise mathematical language used. To ensure consistency, the given data points must satisfy the physical model for a single value of $\\lambda$. Using the endpoints $t_0=0$ and $t_2=5$:\n$A(5) = A(0) \\exp(-5\\lambda) \\implies 250 = 1000 \\exp(-5\\lambda)$.\nThis yields $\\exp(-5\\lambda) = \\frac{250}{1000} = \\frac{1}{4}$. From this, $-5\\lambda = \\ln(\\frac{1}{4}) = -\\ln(4) = -2\\ln(2)$, so $\\lambda = \\frac{2\\ln(2)}{5}$. This value is positive and thus physically valid.\nNow, we verify the data point at $t_1=1$ with this constant:\n$A(1) = A(0)\\exp(-\\lambda \\cdot 1) = 1000 \\exp(-\\frac{2\\ln(2)}{5}) = 1000 \\cdot (\\exp(\\ln(2)))^{-2/5} = 1000 \\cdot 2^{-2/5}$.\nThis is identical to the given value for $A(1)$. The problem is therefore self-contained, consistent, and scientifically sound.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution is now derived.\n\n**Part 1: Construction of the Quadratic Interpolant $p_2(t)$**\nThe unique quadratic polynomial $p_2(t)$ that interpolates the data points $(0, y_0)$, $(1, y_1)$, $(5, y_2)$ is constructed using the Lagrange form:\n$p_2(t) = y_0 L_0(t) + y_1 L_1(t) + y_2 L_2(t)$, where the Lagrange basis polynomials $L_i(t)$ are:\n$L_0(t) = \\frac{(t-1)(t-5)}{(0-1)(0-5)} = \\frac{1}{5}(t-1)(t-5)$.\n$L_1(t) = \\frac{(t-0)(t-5)}{(1-0)(1-5)} = -\\frac{1}{4}t(t-5)$.\n$L_2(t) = \\frac{(t-0)(t-1)}{(5-0)(5-1)} = \\frac{1}{20}t(t-1)$.\n\nWe must evaluate $p_2(t)$ at $t=3$. First, we compute the values of the basis polynomials at $t=3$:\n$L_0(3) = \\frac{(3-1)(3-5)}{5} = \\frac{(2)(-2)}{5} = -\\frac{4}{5}$.\n$L_1(3) = -\\frac{3(3-5)}{4} = -\\frac{3(-2)}{4} = \\frac{6}{4} = \\frac{3}{2}$.\n$L_2(3) = \\frac{3(3-1)}{20} = \\frac{3(2)}{20} = \\frac{6}{20} = \\frac{3}{10}$.\n\nNow we can compute $p_2(3)$:\n$p_2(3) = y_0 L_0(3) + y_1 L_1(3) + y_2 L_2(3)$\n$p_2(3) = (1000)(-\\frac{4}{5}) + (1000 \\cdot 2^{-2/5})(\\frac{3}{2}) + (250)(\\frac{3}{10})$\n$p_2(3) = -800 + 1500 \\cdot 2^{-2/5} + 75 = 1500 \\cdot 2^{-2/5} - 725$.\n\n**Part 2: Prediction from the Physical Model**\nThe decay constant $\\lambda$ was determined during validation as $\\lambda = \\frac{2\\ln(2)}{5}$. We use this to predict the true activity $A(3)$:\n$A(3) = A(0)\\exp(-3\\lambda) = 1000\\exp(-3 \\cdot \\frac{2\\ln(2)}{5}) = 1000\\exp(-\\frac{6}{5}\\ln(2))$.\nUsing the identity $\\exp(c \\ln a) = a^c$:\n$A(3) = 1000 \\cdot 2^{-6/5}$.\n\n**Part 3: Derivation of the Interpolation Error Bound**\nThe error for polynomial interpolation is given by $A(t) - p_n(t) = \\frac{A^{(n+1)}(\\xi)}{(n+1)!} \\prod_{i=0}^{n} (t-t_i)$ for some $\\xi$ in the interval containing the nodes and $t$. For our quadratic case ($n=2$), the error at $t=3$ is:\n$A(3) - p_2(3) = \\frac{A^{(3)}(\\xi)}{3!}(3-t_0)(3-t_1)(3-t_2) = \\frac{A^{(3)}(\\xi)}{6}(3-0)(3-1)(3-5)$, for some $\\xi \\in (0,5)$.\n$A(3) - p_2(3) = \\frac{A^{(3)}(\\xi)}{6}(3)(2)(-2) = -2 A^{(3)}(\\xi)$.\n\nThe absolute error is $|A(3) - p_2(3)| = 2|A^{(3)}(\\xi)|$.\nTo establish an upper bound $B$, we must find the maximum of $|A^{(3)}(t)|$ on the interval $[0,5]$. First, we compute the third derivative of $A(t) = A_0 \\exp(-\\lambda t)$:\n$A'(t) = -\\lambda A_0 \\exp(-\\lambda t)$\n$A''(t) = \\lambda^2 A_0 \\exp(-\\lambda t)$\n$A'''(t) = -\\lambda^3 A_0 \\exp(-\\lambda t)$.\nSo, $|A'''(t)| = \\lambda^3 A_0 \\exp(-\\lambda t)$. Since $\\lambda>0$, this function is monotonically decreasing for $t \\ge 0$. Its maximum value on $[0,5]$ occurs at $t=0$:\n$\\max_{t \\in [0,5]} |A'''(t)| = |A'''(0)| = \\lambda^3 A_0 \\exp(0) = \\lambda^3 A_0$.\n\nAn upper bound $B$ for the error magnitude is therefore:\n$|A(3) - p_2(3)| \\leq 2 \\max_{\\xi \\in [0,5]} |A^{(3)}(\\xi)| = 2 \\lambda^3 A_0$.\nSubstituting $A_0 = 1000$ and $\\lambda = \\frac{2\\ln(2)}{5}$:\n$B = 2 \\left(\\frac{2\\ln(2)}{5}\\right)^3 (1000) = 2 \\cdot \\frac{8(\\ln(2))^3}{125} \\cdot 1000 = \\frac{16(\\ln(2))^3}{125} \\cdot (1000) = 16(\\ln(2))^3 \\cdot 8 = 128(\\ln(2))^3$.\n\n**Part 4: Computation of the Absolute Discrepancy**\nFinally, we compute the numerical value of $|p_2(3) - A(3)|$:\n$|p_2(3) - A(3)| = |(1500 \\cdot 2^{-2/5} - 725) - (1000 \\cdot 2^{-6/5})|$.\nUsing numerical computations:\n$2^{-2/5} = 2^{-0.4} \\approx 0.75785828$\n$2^{-6/5} = 2^{-1.2} \\approx 0.43527530$\n\n$p_2(3) \\approx 1500(0.75785828) - 725 = 1136.78742 - 725 = 411.78742$.\n$A(3) \\approx 1000(0.43527530) = 435.27530$.\n\nThe absolute discrepancy is:\n$|411.78742 - 435.27530| = |-23.48788| \\approx 23.48788$.\nRounding to four significant figures gives $23.49$.",
            "answer": "$$\\boxed{23.49}$$"
        },
        {
            "introduction": "Standard interpolation error formulas rely on the smoothness of the function, but many real-world signals have sharp corners or kinks, such as $f(x)=|x|$. This problem challenges you to computationally investigate the interpolation of such a non-differentiable function and observe its convergence behavior firsthand. You will then derive a rigorous error bound using more advanced tools from approximation theory, namely the Lebesgue constant and the best uniform approximation error, learning how to handle cases where standard analysis fails .",
            "id": "2404724",
            "problem": "Consider the function $f(x)=|x|$ on the interval $[-1,1]$. For an integer $n \\ge 1$, define the Chebyshev nodes of the second kind by $x_j=\\cos\\left(\\dfrac{j\\pi}{n}\\right)$ for $j=0,1,\\dots,n$ (angles in radians). Let $p_n$ denote the unique degree-$n$ polynomial that interpolates $f$ at these nodes, that is, $p_n(x_j)=f(x_j)$ for all $j=0,1,\\dots,n$. Your task is to design a program that, for several values of $n$, computes the uniform (maximum) interpolation error on a fine grid and also computes a rigorous, analytic upper bound on this error obtained from first principles using foundational results of interpolation theory and approximation theory.\n\nYou must proceed from the following base:\n- The Lagrange interpolation polynomial is defined as the unique polynomial $p_n$ of degree at most $n$ that satisfies $p_n(x_j)=f(x_j)$ at $n+1$ distinct nodes $\\{x_j\\}_{j=0}^n$.\n- The Lebesgue constant $\\Lambda_n$ for a set of nodes $\\{x_j\\}_{j=0}^n$ is defined as the maximum, over $x\\in[-1,1]$, of the sum of the absolute values of the Lagrange basis polynomials evaluated at $x$.\n- The notion of best uniform approximation error $E_n(f):=\\inf\\{\\|f-q\\|_\\infty: q \\text{ is a polynomial of degree }\\le n\\}$ and the inequality that relates interpolation error, the Lebesgue constant, and best approximation error (without providing any special-case shortcut formulas).\n- The Chebyshev polynomials $T_k(x)$ form a system on $[-1,1]$ with $|T_k(x)|\\le 1$ for all $x\\in[-1,1]$.\n\nYour program must implement the following computational steps for each tested $n$:\n1. Construct the Chebyshev nodes $\\{x_j\\}_{j=0}^n$ on $[-1,1]$ and the corresponding data values $y_j=f(x_j)$.\n2. Build the Lagrange interpolant $p_n$ and evaluate it on a uniform grid of $m$ points in $[-1,1]$ with $m=10001$. Compute the observed maximum-norm interpolation error $\\max_{x\\in\\mathcal{G}} |f(x)-p_n(x)|$ over this grid $\\mathcal{G}$.\n3. From first principles, derive and compute a rigorous analytic upper bound $B_n$ that satisfies $\\|f - p_n\\|_\\infty \\le B_n$ by combining: \n   - A bound on the best uniform approximation error $E_n(f)$ obtained by representing $f$ via a Chebyshev series and bounding the tail using only the facts stated above (including $|T_k(x)|\\le 1$), and \n   - A bound in terms of the Lebesgue constant $\\Lambda_n$ for Chebyshev nodes of the second kind.\n   The final bound $B_n$ must be expressed as a concrete explicit formula in $n$ that can be computed numerically without any asymptotic notation, and it must be valid for all $n\\ge 1$.\n4. Report, for each tested $n$, both the observed error and the derived bound.\n\nAngle specification: all angles are in radians.\n\nTest suite:\n- Use the degrees $n\\in\\{1,2,3,4,8,16\\}$.\n\nOutput specification:\n- For each tested $n$, your program must produce a three-element list $[n, e_{\\text{obs}}, B_n]$, where $e_{\\text{obs}}$ is the observed maximum error on the specified grid and $B_n$ is the derived analytic upper bound.\n- The final program output must be a single line containing a list of these three-element lists, ordered by the test suite values of $n$, and printed as a comma-separated list enclosed in square brackets (for example, $[[n_1,e_{\\text{obs},1},B_{n_1}],[n_2,e_{\\text{obs},2},B_{n_2}],\\dots]$). All reported numbers must be in standard floating-point form without any units.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded, well-posed, objective, and complete. It constitutes a standard problem in numerical analysis and approximation theory. We shall therefore proceed with a complete solution.\n\nThe objective is to compute the observed maximum interpolation error for the function $f(x)=|x|$ on the interval $[-1,1]$ using a polynomial interpolant $p_n(x)$ of degree $n$ at the Chebyshev nodes of the second kind, and to derive and compute a rigorous analytic upper bound for this error.\n\nThe fundamental theorem connecting the interpolation error to the best approximation error is given by the inequality:\n$$ \\|f - p_n\\|_{\\infty} \\le (1 + \\Lambda_n) E_n(f) $$\nwhere $\\| \\cdot \\|_{\\infty}$ is the uniform norm on $[-1,1]$, $p_n$ is the polynomial interpolant of degree at most $n$ to the function $f$ at a given set of $n+1$ nodes, $\\Lambda_n$ is the Lebesgue constant for these nodes, and $E_n(f)$ is the error of the best uniform approximation to $f$ by a polynomial of degree at most $n$.\n\nLet $q_n^*$ be the polynomial of best approximation of degree $\\le n$ to $f$, so that $\\|f - q_n^*\\|_{\\infty} = E_n(f)$. Since $p_n$ interpolates $f$ at the nodes $\\{x_j\\}_{j=0}^n$, we have $p_n(x_j) = f(x_j)$. The polynomial $p_n - q_n^*$ is of degree at most $n$ and interpolates the function $f - q_n^*$ at the nodes $\\{x_j\\}$. By the definition of the Lagrange interpolating operator $L_n$, we can write $p_n - q_n^* = L_n(f - q_n^*)$. Taking the uniform norm, we get:\n$$ \\|p_n - q_n^*\\|_{\\infty} = \\|L_n(f - q_n^*)\\|_{\\infty} \\le \\|L_n\\| \\|f - q_n^*\\|_{\\infty} = \\Lambda_n E_n(f) $$\nUsing the triangle inequality, the total error is bounded by:\n$$ \\|f - p_n\\|_{\\infty} = \\|f - q_n^* - (p_n - q_n^*)\\|_{\\infty} \\le \\|f - q_n^*\\|_{\\infty} + \\|p_n - q_n^*\\|_{\\infty} \\le E_n(f) + \\Lambda_n E_n(f) = (1+\\Lambda_n)E_n(f) $$\nOur analytic error bound $B_n$ will be the product of upper bounds for $(1 + \\Lambda_n)$ and $E_n(f)$.\n\n**1. Bound on the Lebesgue Constant $\\Lambda_n$**\nFor the Chebyshev nodes of the second kind, $x_j = \\cos\\left(\\frac{j\\pi}{n}\\right)$ for $j=0, 1, \\dots, n$, a tight and well-established upper bound for the Lebesgue constant $\\Lambda_n$ is (see, for example, T.J. Rivlin, \"The Chebyshev Polynomials\"):\n$$ \\Lambda_n \\le \\frac{2}{\\pi} \\ln(n+1) + 1 $$\nThis bound is valid for all $n \\ge 1$. We will use this in our final formula.\n\n**2. Bound on the Best Approximation Error $E_n(f)$ for $f(x)=|x|$**\nTo bound $E_n(f)$, we utilize the Chebyshev series expansion of $f(x)=|x|$. Since $f(x)$ is an even function on $[-1,1]$, its Chebyshev expansion consists only of even-indexed Chebyshev polynomials $T_{2k}(x)$:\n$$ |x| = \\frac{c_0}{2} + \\sum_{k=1}^{\\infty} c_{2k} T_{2k}(x) $$\nThe coefficients $c_k$ are given by the formula $c_k = \\frac{2}{\\pi} \\int_{-1}^{1} \\frac{f(x)T_k(x)}{\\sqrt{1-x^2}} dx$.\nFor $k$ odd, the integrand $|x|T_k(x)$ is an odd function, so $c_k = 0$.\nFor $k=0$, $T_0(x)=1$:\n$$ c_0 = \\frac{4}{\\pi} \\int_0^1 \\frac{x}{\\sqrt{1-x^2}} dx = \\frac{4}{\\pi} [-\\sqrt{1-x^2}]_0^1 = \\frac{4}{\\pi} $$\nFor even indices $k=2m$ with $m \\ge 1$, we substitute $x=\\cos\\theta$:\n$$ c_{2m} = \\frac{4}{\\pi} \\int_0^{\\pi/2} \\cos\\theta \\cos(2m\\theta) d\\theta = \\frac{2}{\\pi} \\int_0^{\\pi/2} (\\cos((2m-1)\\theta) + \\cos((2m+1)\\theta)) d\\theta $$\n$$ c_{2m} = \\frac{2}{\\pi} \\left[ \\frac{\\sin((2m-1)\\theta)}{2m-1} + \\frac{\\sin((2m+1)\\theta)}{2m+1} \\right]_0^{\\pi/2} $$\n$$ c_{2m} = \\frac{2}{\\pi} \\left( \\frac{\\sin(m\\pi - \\pi/2)}{2m-1} + \\frac{\\sin(m\\pi + \\pi/2)}{2m+1} \\right) = \\frac{2}{\\pi} \\left( \\frac{(-1)^{m+1}}{2m-1} + \\frac{(-1)^m}{2m+1} \\right) $$\n$$ c_{2m} = \\frac{2}{\\pi}(-1)^{m+1} \\left( \\frac{1}{2m-1} - \\frac{1}{2m+1} \\right) = \\frac{2}{\\pi}(-1)^{m+1} \\frac{2}{4m^2-1} = \\frac{4(-1)^{m+1}}{\\pi(4m^2-1)} $$\nThe best approximation error $E_n(f)$ is bounded by the error of the truncated Chebyshev series $S_n(x) = \\frac{c_0}{2} + \\sum_{k=1}^n c_k T_k(x)$.\n$$ E_n(f) \\le \\|f - S_n\\|_{\\infty} = \\left\\|\\sum_{k=n+1}^{\\infty} c_k T_k(x)\\right\\|_{\\infty} \\le \\sum_{k=n+1}^{\\infty} |c_k| $$\nSince $c_k=0$ for odd $k$, the sum is over even indices $2m \\ge n+1$. Let $M$ be the smallest integer $m$ such that $2m \\ge n+1$, which is $M = \\lceil (n+1)/2 \\rceil$.\n$$ E_n(f) \\le \\sum_{m=M}^{\\infty} |c_{2m}| = \\sum_{m=M}^{\\infty} \\frac{4}{\\pi(4m^2-1)} = \\frac{4}{\\pi} \\sum_{m=M}^{\\infty} \\frac{1}{(2m-1)(2m+1)} $$\nUsing partial fraction decomposition $\\frac{1}{(2m-1)(2m+1)} = \\frac{1}{2}\\left(\\frac{1}{2m-1} - \\frac{1}{2m+1}\\right)$, the sum becomes a telescoping series:\n$$ \\sum_{m=M}^{\\infty} \\frac{1}{2}\\left(\\frac{1}{2m-1} - \\frac{1}{2m+1}\\right) = \\frac{1}{2} \\frac{1}{2M-1} $$\nTherefore, the bound on the best approximation error is:\n$$ E_n(f) \\le \\frac{4}{\\pi} \\cdot \\frac{1}{2(2M-1)} = \\frac{2}{\\pi(2\\lceil (n+1)/2 \\rceil - 1)} $$\nIf $n$ is even, $n=2k$, then $M=\\lceil(2k+1)/2\\rceil = k+1$. The bound is $\\frac{2}{\\pi(2(k+1)-1)} = \\frac{2}{\\pi(2k+1)} = \\frac{2}{\\pi(n+1)}$.\nIf $n$ is odd, $n=2k-1$, then $M=\\lceil(2k)/2\\rceil = k$. The bound is $\\frac{2}{\\pi(2k-1)} = \\frac{2}{\\pi n}$.\nA single formula covering both cases is $E_n(f) \\le \\frac{2}{\\pi(n + 1 - (n \\pmod 2))}$, which is valid for all $n \\ge 1$.\n\n**3. Final Analytic Error Bound $B_n$**\nCombining the bounds for $\\Lambda_n$ and $E_n(f)$, we construct our overall error bound $B_n$:\n$$ B_n = \\left(1 + \\Lambda_n^{\\text{bound}}\\right) E_n(f)^{\\text{bound}} = \\left(1 + \\left(\\frac{2}{\\pi} \\ln(n+1) + 1\\right)\\right) \\left(\\frac{2}{\\pi(n + 1 - (n \\pmod 2))}\\right) $$\n$$ B_n = \\left(2 + \\frac{2}{\\pi} \\ln(n+1)\\right) \\frac{2}{\\pi(n + 1 - (n \\pmod 2))} $$\nThis is our final, explicit, and computable formula for the upper bound on the interpolation error.\n\n**4. Computational Procedure**\nFor each given degree $n$, the following steps are performed:\n1. The $n+1$ Chebyshev nodes of the second kind, $x_j$, and the corresponding function values, $y_j=|x_j|$, are generated.\n2. The Lagrange interpolating polynomial $p_n(x)$ is constructed. For stable and efficient evaluation, we use the barycentric interpolation formula. The `scipy.interpolate.BarycentricInterpolator` function is suitable for this purpose.\n3. A fine uniform grid $\\mathcal{G}$ of $m=10001$ points is created on $[-1,1]$.\n4. The polynomial $p_n(x)$ and the function $f(x)=|x|$ are evaluated on the grid $\\mathcal{G}$. The observed maximum error is computed as $e_{\\text{obs}} = \\max_{x \\in \\mathcal{G}} |f(x) - p_n(x)|$.\n5. The analytic upper bound $B_n$ is computed using the formula derived above.\nThe results $[n, e_{\\text{obs}}, B_n]$ are collected for each test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import BarycentricInterpolator\n\ndef solve():\n    \"\"\"\n    Computes the interpolation error for f(x)=|x| using Chebyshev nodes\n    and calculates a rigorous analytic error bound.\n    \"\"\"\n\n    test_cases = [1, 2, 3, 4, 8, 16]\n    m_grid = 10001\n    x_grid = np.linspace(-1.0, 1.0, m_grid)\n    f_grid = np.abs(x_grid)\n\n    results = []\n\n    for n in test_cases:\n        # Step 1: Construct Chebyshev nodes and data values\n        # Chebyshev nodes of the second kind (extrema of T_n)\n        j = np.arange(n + 1)\n        x_nodes = np.cos(j * np.pi / n)\n        y_nodes = np.abs(x_nodes)\n\n        # Step 2: Build and evaluate the Lagrange interpolant\n        # Scipy's BarycentricInterpolator is a robust implementation of Lagrange interpolation\n        poly = BarycentricInterpolator(x_nodes, y_nodes)\n        pn_grid = poly(x_grid)\n\n        # Compute the observed maximum-norm interpolation error\n        observed_error = np.max(np.abs(f_grid - pn_grid))\n\n        # Step 3: Compute the rigorous analytic upper bound B_n\n        # The bound is derived from B_n = (1 + Lambda_n_bound) * E_n_bound\n        # where Lambda_n_bound is a bound for the Lebesgue constant and\n        # E_n_bound is a bound for the best approximation error.\n\n        # Bound on the Lebesgue constant for Chebyshev nodes of the 2nd kind:\n        # Lambda_n = (2/pi) * log(n+1) + 1\n        # The problem requires calculation from first principles, this is a standard result.\n        # Note: np.log is the natural logarithm (ln).\n        if n == 0: # handle log(1) case if n=0 were a possibility, but n=1\n            lambda_n_bound = 1.0\n        else:\n            lambda_n_bound = (2 / np.pi) * np.log(n + 1) + 1\n\n        # Bound on the best uniform approximation error E_n(f) for f(x)=|x|\n        # E_n(f) = 2 / (pi * (n + 1 - (n mod 2))) for n = 1\n        e_n_bound = (2 / np.pi) / (n + 1 - (n % 2))\n\n        # Combine bounds to get the final analytic bound B_n\n        # B_n = (1 + Lambda_n) * E_n(f)\n        analytic_bound = (1 + lambda_n_bound) * e_n_bound\n\n        # Step 4: Report the results\n        results.append([n, observed_error, analytic_bound])\n\n    # Final print statement in the exact required format.\n    # e.g., [[1,0.5,1.27],[2,0.2...]]\n    list_of_strings = []\n    for res in results:\n        list_of_strings.append(f\"[{res[0]},{res[1]},{res[2]}]\")\n    final_output = f\"[{','.join(list_of_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}