{
    "hands_on_practices": [
        {
            "introduction": "To begin, let's solidify our understanding of the fundamental mechanics of LU factorization. This first exercise  walks through the direct application of the algorithm without pivoting. Mastering this step-by-step process is crucial before we explore its limitations and the importance of more robust techniques.",
            "id": "1027925",
            "problem": "Perform the LU decomposition without pivoting on the matrix:  \n$$  \nA = \\begin{bmatrix}  \n1 & 2 & 3 \\\\  \n4 & 5 & 6 \\\\  \n7 & 8 & 10  \n\\end{bmatrix}  \n$$  \nwhere $A = LU$, $L$ is lower triangular with unit diagonal elements, and $U$ is upper triangular. Determine the entry in the third row and second column of $L$, denoted $l_{32}$.",
            "solution": "1. Write $A=LU$ with \n   $L=\\begin{bmatrix}1&0&0\\\\l_{21}&1&0\\\\l_{31}&l_{32}&1\\end{bmatrix}$,\n   $U=\\begin{bmatrix}u_{11}&u_{12}&u_{13}\\\\0&u_{22}&u_{23}\\\\0&0&u_{33}\\end{bmatrix}$.\n\n2. From the first row of $A=LU$:\n   $u_{11}=a_{11}=1,\\quad u_{12}=a_{12}=2,\\quad u_{13}=a_{13}=3.$\n\n3. From the first column of $A=LU$:\n   $l_{21}=\\frac{a_{21}}{u_{11}}=\\frac{4}{1}=4,\\quad\n    l_{31}=\\frac{a_{31}}{u_{11}}=\\frac{7}{1}=7.$\n\n4. From the $(2,2)$ entry of $A=LU$:\n   $u_{22}=a_{22}-l_{21}u_{12}=5-4\\cdot2=5-8=-3.$\n\n5. From the $(3,2)$ entry of $A=LU$:\n   $l_{32}=\\frac{a_{32}-l_{31}u_{12}}{u_{22}}\n           =\\frac{8-7\\cdot2}{-3}\n           =\\frac{8-14}{-3}\n           =\\frac{-6}{-3}\n           =2.$",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "Now that we have practiced the basic procedure, let's investigate a scenario where it breaks down. This thought experiment  presents a non-singular matrix for which naive LU factorization fails due to a zero pivot. Analyzing this failure is key to understanding why pivoting is not just an optimization, but a necessary strategy for algorithmic robustness.",
            "id": "2407904",
            "problem": "An economist is modeling a stylized network of cross-exposures among 3 financial sectors where each sector’s endogenous funding cost depends only on the other sectors’ short-term rates, not on its own. This deliberate modeling choice corresponds to an extreme case of cross-dependence with zero own-effect, which can arise under a numeraire normalization or a binding no-self-lending rule. The resulting linear system is represented as $A x = b$, with\n$$\nA \\;=\\; \\begin{pmatrix}\n0 & 1 & 1 \\\\\n1 & 0 & 1 \\\\\n1 & 1 & 0\n\\end{pmatrix},\n$$\nwhere the zero diagonal entries encode the absence of direct self-dependence and the off-diagonal ones encode symmetric cross-dependence. \n\nStarting from the core definitions of Gaussian elimination and Lower-Upper (LU) decomposition, explain why a naive LU factorization without pivoting fails for $A$ even though the underlying system is well-posed. Then, using only fundamental properties of determinants and elimination, determine the exact value of $\\det(A)$. Express your final answer in exact form with no rounding.",
            "solution": "The problem asks for two things: first, an explanation for the failure of a naive Lower-Upper (LU) decomposition for the given matrix $A$, and second, the calculation of the determinant of $A$ using fundamental principles.\n\nThe matrix in question is:\n$$\nA = \\begin{pmatrix}\n0 & 1 & 1 \\\\\n1 & 0 & 1 \\\\\n1 & 1 & 0\n\\end{pmatrix}\n$$\n\n**Part 1: Failure of Naive LU Decomposition without Pivoting**\n\nThe LU decomposition of a matrix $A$ is the process of finding a lower triangular matrix $L$ and an upper triangular matrix $U$ such that $A = LU$. Typically, $L$ is constrained to be unit lower triangular, meaning its diagonal elements are all $1$. The matrix $U$ is found through the process of Gaussian elimination, and the matrix $L$ stores the multipliers used to create zeros in the lower part of $A$.\n\nThe Gaussian elimination algorithm proceeds by using the diagonal elements, called pivots, to eliminate the non-zero entries below them in each column. Let us attempt this for matrix $A$.\n\nThe first step is to use the pivot element $a_{11}$ to eliminate the elements $a_{21}$ and $a_{31}$. The standard row operations are:\n$R_2 \\rightarrow R_2 - l_{21} R_1$\n$R_3 \\rightarrow R_3 - l_{31} R_1$\nwhere the multipliers are $l_{21} = \\frac{a_{21}}{a_{11}}$ and $l_{31} = \\frac{a_{31}}{a_{11}}$.\n\nIn our matrix $A$, the first pivot element is $a_{11} = 0$. The calculation of the first multiplier, $l_{21}$, requires the operation:\n$$\nl_{21} = \\frac{a_{21}}{a_{11}} = \\frac{1}{0}\n$$\nThis operation constitutes division by zero, which is an undefined mathematical operation. Consequently, the standard Gaussian elimination algorithm cannot proceed past the first step. Since the naive LU factorization algorithm is a direct implementation of this elimination process, it fails at the outset. This failure occurs precisely because the pivot element is zero. A remedy for this issue in practice is pivoting, which involves row interchanges to place a non-zero element in the pivot position. The problem specifies a \"naive\" factorization, which by definition excludes such pivoting strategies.\n\nThus, the naive computational algorithm for LU decomposition fails due to the presence of a zero on the diagonal in a pivot position.\n\n**Part 2: Calculation of $\\det(A)$ using Fundamental Properties**\n\nThe problem requires a determination of $\\det(A)$ using the properties of determinants under elementary row operations. The key properties are:\n1.  Swapping two rows of a matrix multiplies its determinant by $-1$.\n2.  Adding a multiple of one row to another row does not change the determinant.\n3.  The determinant of an upper triangular matrix is the product of its diagonal elements.\n\nWe will transform $A$ into an upper triangular form, keeping track of how the determinant changes.\n$$\nA = \\begin{pmatrix}\n0 & 1 & 1 \\\\\n1 & 0 & 1 \\\\\n1 & 1 & 0\n\\end{pmatrix}\n$$\nAs established, the pivot $a_{11} = 0$ is problematic. We perform a row swap, for instance $R_1 \\leftrightarrow R_2$. According to property $1$, this introduces a factor of $-1$.\n$$\n\\det(A) = - \\det \\begin{pmatrix}\n1 & 0 & 1 \\\\\n0 & 1 & 1 \\\\\n1 & 1 & 0\n\\end{pmatrix}\n$$\nThe new pivot is $1$, which is non-zero. The element $a_{21}$ is already $0$. We proceed to eliminate $a_{31} = 1$ by performing the row operation $R_3 \\rightarrow R_3 - R_1$. According to property $2$, this operation does not change the determinant.\n$$\n\\det(A) = - \\det \\begin{pmatrix}\n1 & 0 & 1 \\\\\n0 & 1 & 1 \\\\\n1-1 & 1-0 & 0-1\n\\end{pmatrix}\n= - \\det \\begin{pmatrix}\n1 & 0 & 1 \\\\\n0 & 1 & 1 \\\\\n0 & 1 & -1\n\\end{pmatrix}\n$$\nNow, we use the second pivot, $a_{22} = 1$, to eliminate the element $a_{32} = 1$. We perform the row operation $R_3 \\rightarrow R_3 - R_2$. Again, this does not alter the determinant.\n$$\n\\det(A) = - \\det \\begin{pmatrix}\n1 & 0 & 1 \\\\\n0 & 1 & 1 \\\\\n0-0 & 1-1 & -1-1\n\\end{pmatrix}\n= - \\det \\begin{pmatrix}\n1 & 0 & 1 \\\\\n0 & 1 & 1 \\\\\n0 & 0 & -2\n\\end{pmatrix}\n$$\nThe resulting matrix is an upper triangular matrix, let us call it $U$. According to property $3$, its determinant is the product of its diagonal elements:\n$$\n\\det(U) = (1)(1)(-2) = -2\n$$\nTherefore, the determinant of the original matrix $A$ is:\n$$\n\\det(A) = - \\det(U) = -(-2) = 2\n$$\nSince $\\det(A) = 2 \\neq 0$, the matrix $A$ is invertible, and the linear system $Ax=b$ has a unique solution for any vector $b$. This confirms the problem's own assertion that the underlying system is well-posed, despite the failure of the naive factorization algorithm.",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "Having established the necessity of pivoting, we can now harness the full power of the pivoted LU decomposition, expressed as $PA = LU$. This final practice  challenges you to use the factored form to solve a transposed system, $A^{\\top} x = b$, without ever forming the matrix $A$ itself. This exercise demonstrates the efficiency and elegance of working with matrix factors, a cornerstone of computational engineering.",
            "id": "2410733",
            "problem": "In computational engineering, the Lower–Upper (LU) factorization with row pivoting represents a matrix by a permutation and triangular factors, enabling efficient solving of linear systems. Suppose you are given a permutation matrix $P \\in \\mathbb{R}^{n \\times n}$, a unit lower-triangular matrix $L \\in \\mathbb{R}^{n \\times n}$, and an upper-triangular matrix $U \\in \\mathbb{R}^{n \\times n}$ such that $P A = L U$ for an unknown nonsingular matrix $A \\in \\mathbb{R}^{n \\times n}$. Using only fundamental properties of permutation matrices, triangular matrices, and transposition, derive an algorithm to solve the transposed system $A^{\\top} x = b$ without explicitly forming $A$ or $A^{\\top}$. Your derivation must start from the defining relation $P A = L U$ and the identities $P^{\\top} = P^{-1}$ and $\\left(X Y\\right)^{\\top} = Y^{\\top} X^{\\top}$, and must justify the order and type of triangular solves used.\n\nThen apply your derived algorithm to the concrete data below and compute the exact solution vector $x$:\n$$\nP = \\begin{pmatrix}\n0 & 0 & 1 \\\\\n0 & 1 & 0 \\\\\n1 & 0 & 0\n\\end{pmatrix}, \\quad\nL = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n2 & 1 & 0 \\\\\n-1 & 3 & 1\n\\end{pmatrix}, \\quad\nU = \\begin{pmatrix}\n2 & -1 & 1 \\\\\n0 & 3 & 4 \\\\\n0 & 0 & 5\n\\end{pmatrix}, \\quad\nb = \\begin{pmatrix}\n1 \\\\ 2 \\\\ 3\n\\end{pmatrix}.\n$$\nDo not explicitly form $A$ or $A^{\\top}$ in your computations; use only $P$, $L$, $U$, and $b$. Express your final answer as a single row vector with exact rational entries. No rounding is required.",
            "solution": "**Derivation of the Algorithm**\nThe objective is to solve the linear system $A^{\\top} x = b$ for the unknown vector $x$. The starting point is the given factorization $P A = L U$.\n\nFirst, we must express $A^{\\top}$ in terms of the given factors $P$, $L$, and $U$. From the initial equation, we isolate $A$:\n$$ P A = L U $$\nSince $P$ is a permutation matrix, its inverse is equal to its transpose, $P^{-1} = P^{\\top}$. Left-multiplying by $P^{\\top}$ yields:\n$$ P^{\\top} P A = P^{\\top} L U $$\n$$ I A = P^{\\top} L U $$\n$$ A = P^{\\top} L U $$\nNow, we take the transpose of this expression for $A$. Using the property $(XYZ)^{\\top} = Z^{\\top}Y^{\\top}X^{\\top}$, we obtain:\n$$ A^{\\top} = (P^{\\top} L U)^{\\top} = U^{\\top} L^{\\top} (P^{\\top})^{\\top} $$\nSince $(P^{\\top})^{\\top} = P$, the expression for $A^{\\top}$ simplifies to:\n$$ A^{\\top} = U^{\\top} L^{\\top} P $$\nSubstitute this into the system $A^{\\top} x = b$:\n$$ (U^{\\top} L^{\\top} P) x = b $$\nTo solve this system for $x$, we proceed by introducing intermediate vectors. This avoids matrix-matrix multiplications and allows us to solve a sequence of simpler systems. Let us define a vector $y$ as:\n$$ y = P x $$\nSubstituting this into the equation gives:\n$$ U^{\\top} L^{\\top} y = b $$\nNext, let us define a vector $z$ as:\n$$ z = L^{\\top} y $$\nSubstituting this gives:\n$$ U^{\\top} z = b $$\nThis sequence of substitutions defines a three-step algorithm for finding $x$:\n\n1.  **Solve for $z$**: Solve the system $U^{\\top} z = b$. Since $U$ is an upper-triangular matrix, its transpose $U^{\\top}$ is a lower-triangular matrix. This system is therefore solved efficiently using **forward substitution**.\n2.  **Solve for $y$**: Solve the system $L^{\\top} y = z$. Since $L$ is a unit lower-triangular matrix, its transpose $L^{\\top}$ is a unit upper-triangular matrix. This system is solved efficiently using **backward substitution**.\n3.  **Solve for $x$**: From the definition $y = P x$, we find $x$ by applying the inverse of $P$: $x = P^{-1} y$. Using the property $P^{-1} = P^{\\top}$, we get $x = P^{\\top} y$. This final step is a simple permutation of the elements of vector $y$.\n\nThis algorithm solves for $x$ without ever explicitly computing the matrix $A$ or its transpose $A^{\\top}$.\n\n**Application to Provided Data**\nWe now apply this algorithm to the given matrices and vector.\nThe provided data are:\n$$ P = \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{pmatrix}, \\quad L = \\begin{pmatrix} 1 & 0 & 0 \\\\ 2 & 1 & 0 \\\\ -1 & 3 & 1 \\end{pmatrix}, \\quad U = \\begin{pmatrix} 2 & -1 & 1 \\\\ 0 & 3 & 4 \\\\ 0 & 0 & 5 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} $$\nWe require the transposes of $U$, $L$, and $P$:\n$$ U^{\\top} = \\begin{pmatrix} 2 & 0 & 0 \\\\ -1 & 3 & 0 \\\\ 1 & 4 & 5 \\end{pmatrix}, \\quad L^{\\top} = \\begin{pmatrix} 1 & 2 & -1 \\\\ 0 & 1 & 3 \\\\ 0 & 0 & 1 \\end{pmatrix}, \\quad P^{\\top} = \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{pmatrix} $$\n**Step 1: Solve $U^{\\top} z = b$ by forward substitution.**\n$$ \\begin{pmatrix} 2 & 0 & 0 \\\\ -1 & 3 & 0 \\\\ 1 & 4 & 5 \\end{pmatrix} \\begin{pmatrix} z_1 \\\\ z_2 \\\\ z_3 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} $$\nFrom the first row: $2z_1 = 1 \\implies z_1 = \\frac{1}{2}$.\nFrom the second row: $-z_1 + 3z_2 = 2 \\implies -(\\frac{1}{2}) + 3z_2 = 2 \\implies 3z_2 = \\frac{5}{2} \\implies z_2 = \\frac{5}{6}$.\nFrom the third row: $z_1 + 4z_2 + 5z_3 = 3 \\implies \\frac{1}{2} + 4(\\frac{5}{6}) + 5z_3 = 3 \\implies \\frac{1}{2} + \\frac{10}{3} + 5z_3 = 3 \\implies \\frac{23}{6} + 5z_3 = 3 \\implies 5z_3 = 3 - \\frac{23}{6} = -\\frac{5}{6} \\implies z_3 = -\\frac{1}{6}$.\nSo, the intermediate vector $z$ is $z = \\begin{pmatrix} 1/2 \\\\ 5/6 \\\\ -1/6 \\end{pmatrix}$.\n\n**Step 2: Solve $L^{\\top} y = z$ by backward substitution.**\n$$ \\begin{pmatrix} 1 & 2 & -1 \\\\ 0 & 1 & 3 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{pmatrix} = \\begin{pmatrix} 1/2 \\\\ 5/6 \\\\ -1/6 \\end{pmatrix} $$\nFrom the third row: $y_3 = -\\frac{1}{6}$.\nFrom the second row: $y_2 + 3y_3 = \\frac{5}{6} \\implies y_2 + 3(-\\frac{1}{6}) = \\frac{5}{6} \\implies y_2 - \\frac{1}{2} = \\frac{5}{6} \\implies y_2 = \\frac{5}{6} + \\frac{3}{6} = \\frac{8}{6} = \\frac{4}{3}$.\nFrom the first row: $y_1 + 2y_2 - y_3 = \\frac{1}{2} \\implies y_1 + 2(\\frac{4}{3}) - (-\\frac{1}{6}) = \\frac{1}{2} \\implies y_1 + \\frac{8}{3} + \\frac{1}{6} = \\frac{1}{2} \\implies y_1 + \\frac{16}{6} + \\frac{1}{6} = \\frac{3}{6} \\implies y_1 + \\frac{17}{6} = \\frac{3}{6} \\implies y_1 = \\frac{3-17}{6} = -\\frac{14}{6} = -\\frac{7}{3}$.\nSo, the intermediate vector $y$ is $y = \\begin{pmatrix} -7/3 \\\\ 4/3 \\\\ -1/6 \\end{pmatrix}$.\n\n**Step 3: Compute $x = P^{\\top} y$.**\n$$ x = \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} -7/3 \\\\ 4/3 \\\\ -1/6 \\end{pmatrix} = \\begin{pmatrix} -1/6 \\\\ 4/3 \\\\ -7/3 \\end{pmatrix} $$\nThe final solution vector $x$ contains exact rational entries as required.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{1}{6} & \\frac{4}{3} & -\\frac{7}{3}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}