{
    "hands_on_practices": [
        {
            "introduction": "A core task of the code generator is instruction selection, where it translates abstract high-level operations into concrete machine instructions. This is rarely a one-to-one mapping; a single operation can often be implemented by multiple different instruction sequences. This exercise  places you in the role of the code generator, tasked with choosing the optimal way to perform a bitwise rotation on a hypothetical processor. By analyzing instruction latencies and hardware resource constraints, you will see firsthand how performance modeling is critical for generating efficient code.",
            "id": "3628158",
            "problem": "A compiler’s code generator must lower a high-level $64$-bit rotate-right by a compile-time constant amount $k$ on a $64$-bit value $x$ into target-machine operations. Consider a target Instruction Set Architecture (ISA) that represents a $64$-bit value as an ordered pair of $32$-bit registers $(x_{\\mathrm{lo}}, x_{\\mathrm{hi}})$ and supports the following instructions and machine resources:\n\n- One Shift unit $S$ that executes $64$-bit logical shifts left or right. Each $64$-bit shift has latency $\\ell_{S} = 2$ cycles. The unit is fully pipelined with initiation interval $1$ and there is exactly one such unit.\n- One Boolean unit $B$ that executes $64$-bit bitwise $\\mathrm{OR}$. Each $64$-bit $\\mathrm{OR}$ has latency $\\ell_{B} = 1$ cycle. The unit is fully pipelined with initiation interval $1$ and there is exactly one such unit.\n- One Funnel unit $F$ that executes a $32$-bit funnel shift-right of the form $\\mathrm{FSR32}(a,b,s)$, which conceptually forms the $64$-bit value $(b:a)$ by placing $a$ in the low half and $b$ in the high half, logically shifts it right by $s$ where $0 \\le s \\le 31$, and returns the low $32$ bits. Each $\\mathrm{FSR32}$ has latency $\\ell_{F} = 1$ cycle. The unit is fully pipelined with initiation interval $1$ and there is exactly one such unit.\n\nThe code generator may choose one of the following legal lowerings for a rotate-right by constant $k$:\n\n- Shift–OR lowering: emit one $64$-bit logical right shift by $k$, one $64$-bit logical left shift by $(64 - k)$, and one $64$-bit bitwise $\\mathrm{OR}$ of the two shift results.\n- Funnel-shift lowering: emit exactly two $\\mathrm{FSR32}$ instructions to produce the new low and high halves of the rotated value, using $(x_{\\mathrm{lo}}, x_{\\mathrm{hi}})$ as inputs when $0 \\le k  32$, and swapping the input-order and using shift amount $(k - 32)$ when $32 \\le k  64$. Assume the two $\\mathrm{FSR32}$ instructions write their results into two fresh $32$-bit destination registers, so no extra moves are needed, and the ordered pair of these two destination registers is the final result.\n\nAssume the input pair $(x_{\\mathrm{lo}}, x_{\\mathrm{hi}})$ is available at cycle $0$, the constant $k$ is embedded in instructions, there are no cache or fetch effects, and scheduling is constrained only by data dependencies and the single-instance functional units described above. Use the standard notion from basic-block scheduling that an instruction’s result becomes available exactly $\\ell$ cycles after it is issued, where $\\ell$ is that instruction’s latency.\n\nFor the specific constant $k = 37$, determine the minimal possible completion time, in cycles, to compute the rotated $64$-bit result when the code generator selects the best available lowering and the scheduler issues instructions as early as possible subject to the resource and dependency constraints. Express your final answer as a single integer number of cycles (no units in the final boxed answer).",
            "solution": "The user has requested the minimal completion time for a $64$-bit rotate-right operation by a constant amount $k=37$. The solution requires analyzing two different implementation strategies, or \"lowerings,\" on a target architecture with specified functional units and latencies, and then selecting the faster of the two. The analysis will proceed by constructing a schedule for each lowering, respecting data dependencies and resource constraints. The \"as early as possible\" scheduling policy is applied, and all functional units are fully pipelined with an initiation interval of $1$.\n\nThe input 64-bit value $x$ is represented by a pair of $32$-bit registers $(x_{\\mathrm{lo}}, x_{\\mathrm{hi}})$, which we interpret as the value $x = (x_{\\mathrm{hi}} \\ll 32) | x_{\\mathrm{lo}}$, where `|` denotes bitwise OR and `` denotes logical left shift. Inputs are available at cycle $0$.\n\n### Strategy 1: Shift–OR Lowering\n\nThis strategy implements the $64$-bit rotate-right operation $\\mathrm{ROTR}(x, k)$ using its definition:\n$$ \\mathrm{ROTR}(x, k) = (x \\gg k) | (x \\ll (64 - k)) $$\nwhere `` is logical right shift. For $k=37$, the operations are:\n1.  `Op1`: $t_1 = x \\gg 37$. This is a $64$-bit logical right shift.\n2.  `Op2`: $t_2 = x \\ll (64 - 37) = x \\ll 27$. This is a $64$-bit logical left shift.\n3.  `Op3`: $y = t_1 | t_2$. This is a $64$-bit bitwise $\\mathrm{OR}$.\n\nWe schedule these operations based on their dependencies and resource requirements.\n- **Dependencies**: `Op1` and `Op2` depend on the input $x$ (available at cycle $0$). `Op3` depends on the results of `Op1` and `Op2`.\n- **Resources**: `Op1` and `Op2` both require the Shift unit $S$. `Op3` requires the Boolean unit $B$.\n- **Latencies**: The latency of the Shift unit is $\\ell_S = 2$ cycles. The latency of the Boolean unit is $\\ell_B = 1$ cycle.\n- **Pipelining**: All units have an initiation interval of $1$, meaning a new instruction can be issued to a unit on every cycle.\n\nThe scheduling proceeds as follows:\n- **Cycle 0**: The input $x$ is available. Both `Op1` and `Op2` are ready. We can issue one of them to the Shift unit $S$. Let's issue `Op1`.\n  - Issue `Op1` ($x \\gg 37$) at cycle $0$. It uses unit $S$.\n  - The result $t_1$ will be available at cycle $0 + \\ell_S = 2$.\n- **Cycle 1**: `Op2` is ready. The Shift unit $S$ is available for a new instruction because its initiation interval is $1$.\n  - Issue `Op2` ($x \\ll 27$) at cycle $1$. It uses unit $S$.\n  - The result $t_2$ will be available at cycle $1 + \\ell_S = 3$.\n- **Cycle 2**: The result $t_1$ becomes available. `Op3` is not yet ready as it still awaits $t_2$.\n- **Cycle 3**: The result $t_2$ becomes available. Now both inputs for `Op3` ($t_1$ and $t_2$) are ready. The Boolean unit $B$ is available.\n  - Issue `Op3` ($t_1 | t_2$) at cycle $3$. It uses unit $B$.\n  - The final result $y$ will be available at cycle $3 + \\ell_B = 4$.\n\nThe completion time for the Shift–OR lowering is $4$ cycles.\n\n### Strategy 2: Funnel-shift Lowering\n\nThis strategy uses two specialized $32$-bit funnel shift instructions, $\\mathrm{FSR32}(a, b, s)$, which computes the low $32$ bits of the $64$-bit value $(b:a)$ after a logical right shift by $s$. The operation is equivalent to $(b \\ll (32-s)) | (a \\gg s)$.\nThe problem states that for $32 \\le k  64$, the input order is swapped and the shift amount is $s = k - 32$. For our specific case, $k=37$, so the shift amount is $s = 37 - 32 = 5$. The two $\\mathrm{FSR32}$ instructions must compute the new low and high halves of the rotated result, let's call them $y_{\\mathrm{lo}}$ and $y_{\\mathrm{hi}}$.\n\nLet's derive the expressions for $y_{\\mathrm{lo}}$ and $y_{\\mathrm{hi}}$ resulting from $\\mathrm{ROTR}(x, 37)$:\nThe new low half, $y_{\\mathrm{lo}}$, is composed of the low $32$ bits of $(x \\gg 37)$ and $(x \\ll 27)$.\n$$ y_{\\mathrm{lo}} = (x_{\\mathrm{lo}} \\ll 27) | (x_{\\mathrm{hi}} \\gg 5) $$\nThe new high half, $y_{\\mathrm{hi}}$, is composed of the high $32$ bits of the same expressions.\n$$ y_{\\mathrm{hi}} = (x_{\\mathrm{hi}} \\ll 27) | (x_{\\mathrm{lo}} \\gg 5) $$\nWe must match these expressions to the $\\mathrm{FSR32}$ instruction. With $s=5$:\n- To compute $y_{\\mathrm{lo}} = (x_{\\mathrm{lo}} \\ll 27) | (x_{\\mathrm{hi}} \\gg 5)$: We set $a = x_{\\mathrm{hi}}$ and $b = x_{\\mathrm{lo}}$.\n  - `OpA`: $y_{\\mathrm{lo}} = \\mathrm{FSR32}(x_{\\mathrm{hi}}, x_{\\mathrm{lo}}, 5)$.\n- To compute $y_{\\mathrm{hi}} = (x_{\\mathrm{hi}} \\ll 27) | (x_{\\mathrm{lo}} \\gg 5)$: We set $a = x_{\\mathrm{lo}}$ and $b = x_{\\mathrm{hi}}$.\n  - `OpB`: $y_{\\mathrm{hi}} = \\mathrm{FSR32}(x_{\\mathrm{lo}}, x_{\\mathrm{hi}}, 5)$.\n\nNow, we schedule `OpA` and `OpB`.\n- **Dependencies**: Both `OpA` and `OpB` depend on the inputs $x_{\\mathrm{lo}}$ and $x_{\\mathrm{hi}}$, which are available at cycle $0$. The two operations are independent of each other.\n- **Resources**: Both `OpA` and `OpB` require the Funnel unit $F$.\n- **Latencies**: The latency of the Funnel unit is $\\ell_F = 1$ cycle.\n- **Pipelining**: The unit has an initiation interval of $1$.\n\nThe scheduling proceeds as follows:\n- **Cycle 0**: Inputs are available. Both `OpA` and `OpB` are ready. We issue one to the Funnel unit $F$. Let's issue `OpA`.\n  - Issue `OpA` ($\\mathrm{FSR32}(x_{\\mathrm{hi}}, x_{\\mathrm{lo}}, 5)$) at cycle $0$. It uses unit $F$.\n  - The result $y_{\\mathrm{lo}}$ will be available at cycle $0 + \\ell_F = 1$.\n- **Cycle 1**: `OpB` is ready. Unit $F$ is available for a new instruction.\n  - Issue `OpB` ($\\mathrm{FSR32}(x_{\\mathrm{lo}}, x_{\\mathrm{hi}}, 5)$) at cycle $1$. It uses unit $F$.\n  - The result $y_{\\mathrm{hi}}$ will be available at cycle $1 + \\ell_F = 2$.\n\nThe complete $64$-bit result $(y_{\\mathrm{lo}}, y_{\\mathrm{hi}})$ is available only when both halves have been computed. The first half, $y_{\\mathrm{lo}}$, is ready at cycle $1$. The second half, $y_{\\mathrm{hi}}$, is ready at cycle $2$. Therefore, the total completion time is the maximum of these two ready times.\nCompletion time = $\\max(1, 2) = 2$ cycles.\n\n### Conclusion\n\nComparing the two strategies:\n- Shift–OR lowering completion time: $4$ cycles.\n- Funnel-shift lowering completion time: $2$ cycles.\n\nThe code generator selects the best (fastest) available lowering. In this case, the Funnel-shift lowering is superior. The minimal possible completion time is $2$ cycles.",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "Register allocation involves assigning an ever-changing set of variables to a small, fixed number of physical registers. A key optimization is \"move coalescing,\" which eliminates redundant copy instructions. However, as this practice problem  demonstrates, this optimization is not always a clear win. You will explore scenarios where coalescing, while removing an instruction, can inadvertently increase register pressure or interfere with valuable addressing modes, leading to slower code overall. This reveals the complex, often non-local, trade-offs that a code generator must constantly navigate.",
            "id": "3628152",
            "problem": "A code generator must decide whether to coalesce a move $t \\leftarrow s$ or keep it, trading off fewer moves against potential increases in register pressure and loss of profitable addressing modes. Work with the following base model and facts.\n\nBase model and facts:\n- Register allocation seeks to assign each live temporary to one of $K$ registers so that no two simultaneously live temporaries share a register. In the interference-graph model, each temporary is a node, and an edge connects two nodes if the corresponding live ranges overlap. A $K$-register allocator corresponds to a $K$-coloring of this graph.\n- A move $t \\leftarrow s$ that is coalesced merges $s$ and $t$ into one node whose adjacency set is the union of their neighbors. This can increase the node’s degree and can change colorability properties of the interference graph.\n- A spill occurs when no register can be assigned to a live temporary and it must be stored in memory.\n- Consider a machine with $K = 2$ general-purpose registers and the following instruction forms: arithmetic requires both operands in registers; memory load/store use a base register plus immediate offset. Additionally, the machine supports a base-update addressing mode for stores of the form store-back $[\\;b\\;]^+ \\leftarrow v$ which both stores to address in base register $b$ and updates $b$ (e.g., $b \\leftarrow b + c$ for some fixed constant $c$), clobbering $b$; to use this mode, the base register must be the one that will be clobbered by the store.\n\nCase setup for analysis:\n- Interference-graph case $G$: temporaries $\\{s,t,p,q\\}$ with edges $\\{(s,p),(p,q),(q,t)\\}$, and a move $t \\leftarrow s$. Note that $s$ and $t$ do not interfere. Assume a standard, naive simplify-based graph-coloring allocator that spills when no node has degree strictly less than $K$.\n- Addressing-mode case: later code performs a store with base-update using a base equal to $t$, while $s$ is used again later in arithmetic. The code generator may either keep $t \\leftarrow s$ and use $t$ as the clobbered base, or coalesce and make $s$ serve as the clobbered base.\n\nQuestion. Which of the following statements are correct under the model above? Select all that apply.\n\nA. In interference-graph case $G$ with $K = 2$, aggressive coalescing of $t \\leftarrow s$ (merging $s$ and $t$) can transform a $2$-colorable graph into one that is not $2$-colorable, forcing a spill for a naive $K$-coloring allocator, even though the uncoalesced graph is $2$-colorable.\n\nB. On the given machine with base-update stores, keeping the copy $t \\leftarrow s$ can enable use of the base-update addressing mode without extending the live range of $s$ or reintroducing extra moves, because $t$ can be the clobbered base while $s$ remains available for later uses. Coalescing $t$ and $s$ can remove this flexibility and either block the addressing mode or require another copy later.\n\nC. If $s$ and $t$ do not interfere (their live ranges do not overlap except at the copy), then coalescing them cannot increase any other temporary’s live range and therefore cannot adversely affect allocation.\n\nD. For any machine with $K$ registers, any sequence of aggressive coalescing operations that only contract non-interfering pairs preserves $K$-colorability of the interference graph; hence coalescing never causes spills that a non-coalescing allocator would avoid.",
            "solution": "The core of the problem lies in analyzing the consequences of coalescing a move instruction, $t \\leftarrow s$, within the framework of graph-coloring register allocation. The decision to coalesce involves a trade-off between eliminating a move instruction and potentially complicating the register allocation problem. The provided model specifies the parameters for this analysis.\n\n-   **Register Allocation Model**: Based on an interference graph where temporaries are nodes and an edge connects two nodes if their live ranges overlap. A machine with $K$ registers requires a $K$-coloring of this graph.\n-   **Coalescing**: Merging the nodes for $s$ and $t$ (which do not interfere) into a single node, say $st$. The new node $st$ inherits the neighbors of both $s$ and $t$, i.e., $N(st) = N(s) \\cup N(t)$.\n-   **Allocator Behavior**: A naive simplify-based allocator is used. This allocator applies a `simplify` rule, removing any node with a degree strictly less than $K$. If at any point all remaining nodes have a degree greater than or equal to $K$, the allocator gives up and `spills` a temporary to memory.\n-   **Machine Details**: $K=2$ general-purpose registers. A special `store-back` instruction, `store-back $[\\;b\\;]^+ \\leftarrow v$`, uses the register $b$ for the base address and subsequently clobbers (overwrites) it.\n\nWe will now evaluate each statement based on this model and the specific cases provided.\n\n**Analysis of Statement A**\n\nStatement A claims that coalescing $t \\leftarrow s$ in interference-graph case $G$ with $K=2$ can transform a $2$-colorable graph into one that is not, forcing a spill.\n\n1.  **Analyze the uncoalesced graph $G$**:\n    -   The set of temporaries (nodes) is $\\{s, t, p, q\\}$.\n    -   The interference edges are $\\{(s,p), (p,q), (q,t)\\}$. This forms a path graph: $s-p-q-t$.\n    -   The degrees of the nodes are: $d(s)=1$, $d(t)=1$, $d(p)=2$, $d(q)=2$.\n    -   The machine has $K=2$ registers. The simple allocator spills if it cannot find a node with degree $ K$, i.e., degree $ 2$.\n    -   In graph $G$, nodes $s$ and $t$ both have degree $1$, which is strictly less than $K=2$.\n    -   The allocator can `simplify` by removing $s$ (or $t$), then continue simplifying until the graph is empty. No spill is forced. For example, a valid simplification sequence is $s, t, p, q$.\n    -   Furthermore, the graph is a path, which is a bipartite graph and therefore $2$-colorable. A possible $2$-coloring is: Color $1$ for $\\{s, q\\}$ and Color $2$ for $\\{p, t\\}$.\n    -   Conclusion for uncoalesced graph: It is $2$-colorable and the naive allocator will not spill.\n\n2.  **Analyze the coalesced graph $G'$**:\n    -   The move $t \\leftarrow s$ is coalesced. Nodes $s$ and $t$ are merged into a single node, which we can call $st$. Note that $s$ and $t$ do not interfere in $G$.\n    -   The new set of nodes is $\\{st, p, q\\}$.\n    -   The neighbors of the new node $st$ are the union of the neighbors of $s$ and $t$: $N(st) = N(s) \\cup N(t) = \\{p\\} \\cup \\{q\\} = \\{p, q\\}$.\n    -   The edges in $G'$ are the original edge $(p,q)$ plus the new edges from coalescing: $(st,p)$ and $(st,q)$. The full edge set is $\\{(st, p), (st, q), (p, q)\\}$.\n    -   This new graph $G'$ is a $3$-clique ($K_3$), or a triangle.\n    -   The degrees of the nodes in $G'$ are: $d(st)=2$, $d(p)=2$, $d(q)=2$.\n    -   Now, consider the naive allocator with $K=2$. It looks for a node with degree $ 2$.\n    -   In $G'$, every node has degree $2$. There is no node with degree strictly less than $K=2$.\n    -   According to the specified rule, the allocator must spill.\n    -   A $3$-clique is not $2$-colorable; its chromatic number is $3$. Coalescing has indeed transformed a $2$-colorable graph into one that is not.\n\nThe analysis confirms that aggressive coalescing turned a graph that was easily colorable by the naive allocator into one that forces a spill.\n\n**Verdict for A: Correct.**\n\n**Analysis of Statement B**\n\nStatement B concerns the interaction between coalescing and the availability of a special addressing mode, `store-back`, which clobbers its base register.\n\n-   **Scenario**: A `store-back` instruction needs to use $t$ as its base. Later, the value of $s$ is needed for an arithmetic operation.\n\n1.  **Case 1: Keep the copy $t \\leftarrow s$**.\n    -   The program contains the instruction $t \\leftarrow s$. After the copy, $s$ and $t$ hold the same value but can be assigned to different registers.\n    -   Let's say register $R_s$ holds the value of $s$ and register $R_t$ holds the value of $t$.\n    -   The instruction `store-back` uses $t$ as its base. This means it will use the register $R_t$ and subsequently clobber it.\n    -   After the `store-back` instruction, the value in $R_t$ is destroyed, but the value of $s$ is still safe in register $R_s$.\n    -   The later arithmetic use of $s$ can proceed by using the value in $R_s$.\n    -   This strategy successfully enables the use of the profitable `store-back` addressing mode without requiring any extra save/restore instructions. The live range of $s$ effectively \"goes around\" the `store-back` instruction, while the live range of $t$ ends at that instruction.\n\n2.  **Case 2: Coalesce $t$ and $s$**.\n    -   $s$ and $t$ are merged into a single temporary, let's call it $s$. This temporary is assigned to a single register, say $R_s$.\n    -   The `store-back` instruction, which was originally to use $t$ as a base, must now use $s$ as its base.\n    -   The instruction executes, using $R_s$ as the base register, and then clobbers $R_s$.\n    -   The original value of $s$, which is needed for the subsequent arithmetic operation, has now been destroyed.\n    -   This presents the code generator with a dilemma:\n        -   (a) It can avoid using the `store-back` instruction and instead use a regular `store` followed by an `add`, losing the benefit of the special addressing mode (e.g., code size, speed).\n        -   (b) It can insert additional `move` instructions to save the value of $s$ before the `store-back` and restore it afterwards. This negates the benefit of eliminating the original $t \\leftarrow s$ copy.\n    -   In either case, coalescing has introduced a complication that either blocks the use of a profitable instruction or requires reintroducing moves.\n\nThe statement accurately describes this trade-off. Keeping the copy decouples the clobbered temporary ($t$) from the one that must be preserved ($s$), whereas coalescing forces a conflict.\n\n**Verdict for B: Correct.**\n\n**Analysis of Statement C**\n\nStatement C is: \"If $s$ and $t$ do not interfere... then coalescing them cannot increase any other temporary’s live range and therefore cannot adversely affect allocation.\"\n\nThis statement contains a premise and a conclusion.\n-   **Premise**: \"coalescing them cannot increase any other temporary’s live range\". When $s$ and $t$ are coalesced into $st$, the live range of $st$ is the union of the live ranges of $s$ and $t$. This operation does not alter the definition or use points of any *other* temporary (like $p$ or $q$ in our example), so their live ranges are indeed unaffected. The premise is correct.\n-   **Conclusion**: \"and therefore cannot adversely affect allocation\". This conclusion is a non sequitur. The adverse effect of coalescing is not on the live ranges of other temporaries, but on the structure of the interference graph itself.\n-   The analysis for statement A provides a direct counterexample. Coalescing $s$ and $t$ (which do not interfere) in graph $G$ did not change the live ranges of $p$ or $q$. However, it created a new node $st$ that interfered with *both* $p$ and $q$. This increased the degree of the coalesced node and the connectivity of the graph, leading to a spill that would not have occurred otherwise.\n-   The adverse effect on allocation stems from the increase in interference constraints on the *new, merged* temporary, which can make the graph more difficult, or impossible, to $K$-color.\n\n**Verdict for C: Incorrect.**\n\n**Analysis of Statement D**\n\nStatement D makes a very strong, general claim: \"For any machine with $K$ registers, any sequence of aggressive coalescing operations that only contract non-interfering pairs preserves $K$-colorability of the interference graph; hence coalescing never causes spills that a non-coalescing allocator would avoid.\"\n\n-   This statement claims that aggressive coalescing is \"safe\" with respect to $K$-colorability.\n-   The analysis for statement A serves as a perfect counterexample to this general claim.\n-   In that analysis, we started with a machine with $K=2$ registers.\n-   We had an interference graph $G$ that was $2$-colorable.\n-   We performed a single coalescing operation on a non-interfering pair, $(s, t)$.\n-   The resulting graph, $G'$, was not $2$-colorable (it was a $K_3$, requiring $3$ colors).\n-   Thus, the operation did *not* preserve $K$-colorability for $K=2$.\n-   The second clause, \"hence coalescing never causes spills...\", is also falsified by the same example. The naive allocator did not spill on $G$ but was forced to spill on $G'$.\n-   This demonstrates that aggressive coalescing is not a safe transformation in general. Real-world compilers use more conservative heuristics (like the Briggs or George heuristics) to decide when to coalesce, precisely to avoid creating uncolorable graphs.\n\n**Verdict for D: Incorrect.**",
            "answer": "$$\\boxed{AB}$$"
        },
        {
            "introduction": "When there are more live variables than available registers, some variables must be \"spilled\" to memory on the stack. An intelligent code generator's job doesn't end there; it must also manage this spill code to minimize its overhead. This hands-on practice  challenges you to optimize the stack layout for spilled variables. By analyzing the precise live intervals of each variable, you can identify \"lifetime holes\" and reuse stack slots, a process analogous to coloring an interval graph, to minimize the total memory footprint of the generated code.",
            "id": "3628173",
            "problem": "A code generator for a simple imperative language targets a machine with exactly $2$ physical registers available for temporaries. The Intermediate Representation (IR) of a single linear basic block is indexed by program points $\\{1,2,\\dots,16\\}$. Five temporaries $t_1, t_2, t_3, t_4, t_5$ have the following live segments (the notation $[a,b]$ means the temporary is live at every integer program point $p$ with $a \\leq p \\leq b$, and $\\cup$ denotes disjoint live segments due to lifetime holes), and each temporary has an associated storage width in bytes if spilled:\n\n- $t_1$: live at $[1,5] \\cup [9,11]$, width $8$.\n- $t_2$: live at $[3,7]$, width $4$.\n- $t_3$: live at $[4,5] \\cup [9,10]$, width $4$.\n- $t_4$: live at $[2,4] \\cup [10,12]$, width $16$.\n- $t_5$: live at $[8,15]$, width $4$.\n\nAt any program point $p$, at most $2$ live temporaries can occupy registers. Every live temporary not occupying a register at $p$ is considered spilled at $p$ and must occupy a stack slot of size at least its width. The code generator may change which temporaries are in registers over time, and may reuse the same stack slot for different spilled temporaries provided their spilled live segments do not overlap in time. A stack slot’s size is fixed to the maximum width of any temporary that ever occupies it. Assume no padding between slots and that the stack frame contribution from spill slots is the sum of their slot sizes. The objective is to choose, over all program points, which temporaries occupy registers and to color the spilled segments onto a minimal set of stack slots so that the total stack frame size due to spill slots is minimized.\n\nBased on the above, compute the minimal total stack frame size in bytes. Express your final answer in bytes. No rounding is required.",
            "solution": "The objective is to find the minimal stack frame size for spilled temporaries. The strategy is to determine the number of spills required at each program point, choose which temporaries to spill to minimize slot widths, and then determine the minimal number of slots needed to accommodate these spills without overlap.\n\nFirst, we identify the live temporaries and their widths at each program point to find where register pressure exceeds the available 2 registers.\n\nThe live intervals and widths are:\n- $t_1: [1,5] \\cup [9,11]$ (width 8)\n- $t_2: [3,7]$ (width 4)\n- $t_3: [4,5] \\cup [9,10]$ (width 4)\n- $t_4: [2,4] \\cup [10,12]$ (width 16)\n- $t_5: [8,15]$ (width 4)\n\nLet's find the live sets $L(p)$ for all program points and identify contention:\n- $L(1) = \\{t_1\\}$ (1 live)\n- $L(2) = \\{t_1, t_4\\}$ (2 live)\n- $L(3) = \\{t_1, t_2, t_4\\}$ (3 live) -> 1 spill needed.\n- $L(4) = \\{t_1, t_2, t_3, t_4\\}$ (4 live) -> 2 spills needed.\n- $L(5) = \\{t_1, t_2, t_3\\}$ (3 live) -> 1 spill needed.\n- $L(6,7) = \\{t_2\\}$ (1 live)\n- $L(8) = \\{t_5\\}$ (1 live)\n- $L(9) = \\{t_1, t_3, t_5\\}$ (3 live) -> 1 spill needed.\n- $L(10) = \\{t_1, t_3, t_4, t_5\\}$ (4 live) -> 2 spills needed.\n- $L(11) = \\{t_1, t_4, t_5\\}$ (3 live) -> 1 spill needed.\n- $L(12) = \\{t_4, t_5\\}$ (2 live)\n- $L(13..15) = \\{t_5\\}$ (1 live)\n- $L(16) = \\emptyset$\n\nAt points with more than 2 live temporaries, we must spill. To minimize total stack frame size, the optimal strategy is to spill temporaries with the smallest widths, as a slot's size is determined by the widest temporary it holds. The widths are $|t_4|=16$, $|t_1|=8$, and $|t_2|=|t_3|=|t_5|=4$.\n\nWe apply this strategy at each contention point by keeping the widest temporaries in registers:\n- **At p=3 ($L(3)=\\{t_1(8), t_4(16), t_2(4)\\}$):** Keep $t_4$ and $t_1$. Spill $t_2$ (width 4).\n- **At p=4 ($L(4)=\\{t_1(8), t_2(4), t_3(4), t_4(16)\\}$):** Keep $t_4$ and $t_1$. Spill $t_2$ and $t_3$ (both width 4).\n- **At p=5 ($L(5)=\\{t_1(8), t_2(4), t_3(4)\\}$):** Keep $t_1$ and one of the 4-byte temporaries. Spill the other. Let's spill $t_3$.\n- **At p=9 ($L(9)=\\{t_1(8), t_3(4), t_5(4)\\}$):** Keep $t_1$ and one of the 4-byte temporaries. Spill the other. Let's spill $t_3$.\n- **At p=10 ($L(10)=\\{t_1(8), t_3(4), t_4(16), t_5(4)\\}$):** Keep $t_4$ and $t_1$. Spill $t_3$ and $t_5$ (both width 4).\n- **At p=11 ($L(11)=\\{t_1(8), t_4(16), t_5(4)\\}$):** Keep $t_4$ and $t_1$. Spill $t_5$ (width 4).\n\nThis optimal spill plan ensures we only ever spill temporaries of width 4. The problem now reduces to finding the minimum number of 4-byte slots required. This is determined by the maximum number of temporaries that must be spilled simultaneously.\n\nLet's list the spilled temporaries at each point of contention:\n- p=3: $\\{t_2\\}$ (1 spill)\n- p=4: $\\{t_2, t_3\\}$ (2 spills)\n- p=5: $\\{t_3\\}$ (1 spill)\n- p=9: $\\{t_3\\}$ (1 spill)\n- p=10: $\\{t_3, t_5\\}$ (2 spills)\n- p=11: $\\{t_5\\}$ (1 spill)\n\nThe maximum number of simultaneous spills is 2, occurring at points 4 and 10. Therefore, a minimum of 2 stack slots are required. Since our strategy only spills 4-byte temporaries, both slots will be 4 bytes in size.\n\nWe can assign the spilled temporaries' live ranges to two 4-byte slots, $S_1$ and $S_2$:\n- **Slot $S_1$ (4 bytes):** can hold the spilled segment of $t_2$ during $[3,4]$ and the spilled segment of $t_5$ during $[10,11]$. These time intervals do not overlap.\n- **Slot $S_2$ (4 bytes):** can hold the spilled segment of $t_3$ during $[4,5]$ and $[9,10]$.\n\nLet's verify this assignment:\n- At p=4, $t_2$ occupies $S_1$ and $t_3$ occupies $S_2$. This works.\n- At p=10, $t_5$ occupies $S_1$ and $t_3$ occupies $S_2$. This also works.\nAt all other contention points, only one temporary is spilled, which can be placed in either available slot.\n\nThe minimal total stack frame size is the sum of the sizes of these two slots:\nTotal size = (size of $S_1$) + (size of $S_2$) = 4 bytes + 4 bytes = 8 bytes.",
            "answer": "$$\\boxed{8}$$"
        }
    ]
}