{
    "hands_on_practices": [
        {
            "introduction": "A core task of an instruction selector is to replace high-level operations with efficient sequences of machine instructions. This practice explores the classic optimization of \"strength reduction,\" where a multiplication by a constant is transformed into a series of cheaper shifts and additions. By analyzing different ways to represent the constant, you will see firsthand how a compiler's choice can dramatically affect performance based on a given cost model .",
            "id": "3646809",
            "problem": "A compiler backend targets an architecture whose instruction set contains three relevant operations with the following semantics and costs:\n- Left shift by an immediate amount: for any register value $v$ and nonnegative integer $p$, the operation returns $v \\ll p$ and costs $c_{s} = 3$ cycles.\n- Addition of two registers: for any register values $u$ and $v$, the operation returns $u + v$ and costs $c_{a} = 5$ cycles.\n- Subtraction of two registers: for any register values $u$ and $v$, the operation returns $u - v$ and costs $c_{a} = 5$ cycles.\n\nAssume unlimited registers and that copying a value between registers has negligible cost. A left shift by $p=0$ is a no-op and incurs zero cost. The compiler must implement the multiplication by a known, fixed integer constant $k$ using only these operations. The target program computes $y = k \\cdot x$ for an input register $x$. The instruction selector is restricted to strategies that form $y$ as a finite linear combination of shifted instances of $x$ with signs, specifically $y = \\sum_{i=1}^{m} s_{i} \\cdot (x \\ll p_{i})$, where each $s_{i} \\in \\{+1,-1\\}$ and each $p_{i}$ is a nonnegative integer. The combination is realized with binary additions and subtractions; no other operation is permitted.\n\nStarting from the foundational facts of binary representation and the identity $x \\ll p = x \\cdot 2^{p}$, derive the minimal-cost instruction sequence under this restriction for the case $k = 1023$. Express the minimal total cost in cycles as a single real-valued number. No rounding is necessary.",
            "solution": "The user wants me to solve the problem. I will first perform the validation.\n\n### Step 1: Extract Givens\n- Operation 1: Left shift. `$v \\ll p$`. Cost `$c_{s} = 3$` cycles for a nonnegative integer `$p > 0$`. Cost is `$0$` for `$p=0$`.\n- Operation 2: Addition. `$u + v$`. Cost `$c_{a} = 5$` cycles.\n- Operation 3: Subtraction. `$u - v$`. Cost `$c_{a} = 5$` cycles.\n- Assumption: Unlimited registers.\n- Assumption: Register copy cost is negligible.\n- Identity: `$x \\ll p = x \\cdot 2^{p}$`.\n- Task: Implement `$y = k \\cdot x$` for a known, fixed integer constant `$k$`.\n- Restriction: The implementation must have the form `$y = \\sum_{i=1}^{m} s_{i} \\cdot (x \\ll p_{i})$`, where `$s_{i} \\in \\{+1,-1\\}$` and `$p_{i}$` are nonnegative integers. The sum is computed using binary additions and subtractions.\n- Specific case: `$k = 1023$`.\n- Goal: Find the minimal total cost in cycles.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific or Factual Soundness**: The problem is based on established principles of computer arithmetic and compiler optimization, specifically strength reduction for multiplication by a constant. The identity `$x \\ll p = x \\cdot 2^{p}$` is a fundamental property of binary representations. The operations are standard in RISC-like architectures. The problem is scientifically sound.\n2.  **Non-Formalizable or Irrelevant**: The problem is highly formalizable as an optimization problem within the specified constraints. It is directly related to instruction selection strategies in compiler design.\n3.  **Incomplete or Contradictory Setup**: The problem is self-contained. It provides the set of allowed operations, their costs, the structure of the solution, and the specific constant `$k$` to be implemented. The costs are well-defined, including the zero-cost case for `$p=0$`. There are no contradictions.\n4.  **Unrealistic or Infeasible**: The setup is a simplified but plausible model of a real-world compiler problem. The assumption of unlimited registers is a common simplification for this type of analysis. The data and conditions are consistent and feasible within the model.\n5.  **Ill-Posed or Poorly Structured**: The problem is well-posed. It asks for the minimal cost, which defines a clear optimization objective. The search space is the set of representations of `$k$` as a sum/difference of powers of two. A minimal solution exists and is unique in terms of cost.\n6.  **Pseudo-Profound, Trivial, or Tautological**: The problem is not trivial. It requires comparing different strategies for representing the constant `$k$` and calculating the associated costs to find the optimum. The existence of multiple representations (e.g., standard binary vs. non-adjacent form) makes the optimization non-obvious.\n7.  **Outside Scientific Verifiability**: The solution is verifiable through direct calculation and comparison of costs for different valid instruction sequences.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the solution.\n\nThe problem requires finding the minimal cost to compute `$y = k \\cdot x$` for `$k = 1023$`, using a sequence of shift, add, and subtract operations. The allowed computational structure is `$y = \\sum_{i=1}^{m} s_{i} \\cdot (x \\ll p_{i})$`, where `$s_i \\in \\{+1,-1\\}$`. This is equivalent to finding a representation of the constant `$k$` of the form `$k = \\sum_{i=1}^{m} s_{i} \\cdot 2^{p_{i}}$` that minimizes the total instruction cost.\n\nThe total cost `$C$` is the sum of the costs of the shift operations and the costs of the addition/subtraction operations.\nTo compute `$y$`, we first need to generate `$m$` terms of the form `$x \\ll p_i$`. Then, these `$m$` terms must be combined using `$m-1$` additions or subtractions.\n\nLet's define the cost function more precisely.\n- The cost of a shift `$x \\ll p_i$` is `$c_s = 3$` if `$p_i > 0$`, and `0` if `$p_i = 0$`. Let `$N_s$` be the number of terms in the sum where `$p_i > 0$`. The total cost for shifts is `$N_s \\cdot c_s$`.\n- The cost of combining `$m$` terms requires `$m-1$` binary operations (additions or subtractions). The cost of each is `$c_a = 5$`. The total cost for these is `$(m-1) \\cdot c_a$`.\n\nThe total cost `$C$` for a given representation is therefore:\n$$C = N_s \\cdot c_s + (m-1) \\cdot c_a$$\nSubstituting the given costs, `$c_s = 3$` and `$c_a = 5$`:\n$$C = 3N_s + 5(m-1)$$\n\nTo minimize `$C$`, we must find a representation for `$k=1023$` that minimizes `$m$` and `$N_s$`. Since `$c_a > c_s$`, minimizing `$m$` (the number of terms) is the primary factor in reducing the cost.\n\nWe will explore two strategies for representing `$k = 1023$`.\n\n**Strategy 1: Standard Binary Representation**\n\nFirst, we express `$k=1023$` in its standard binary form.\n`$1023 = 2^{10} - 1$`. In binary, this is a sequence of ten `$1$`s: `$1111111111_2$`.\nThis corresponds to the sum:\n$$k = 1023 = \\sum_{i=0}^{9} 1 \\cdot 2^i = 2^9 + 2^8 + 2^7 + 2^6 + 2^5 + 2^4 + 2^3 + 2^2 + 2^1 + 2^0$$\nFor this representation:\n- The number of terms is `$m = 10$`.\n- The powers `$p_i$` are `$\\{9, 8, 7, 6, 5, 4, 3, 2, 1, 0\\}$`.\n- The number of shifts with `$p_i > 0$` is `$N_s = 9$`. The term `$2^0$` corresponds to `$x \\ll 0$`, which has a cost of `$0$`.\n- The number of additions required to sum these `$10$` terms is `$m-1 = 9$`.\n\nThe total cost for this strategy, `$C_1$`, is:\n$$C_1 = 3 \\cdot N_s + 5 \\cdot (m-1) = 3 \\cdot 9 + 5 \\cdot (10-1) = 27 + 5 \\cdot 9 = 27 + 45 = 72$$\nSo, the cost using the standard binary expansion is `72` cycles.\n\n**Strategy 2: Representation using Subtraction (Non-Adjacent Form)**\n\nA sequence of consecutive `$1$`s in a binary representation can be simplified using the identity `$\\sum_{i=j}^{n-1} 2^i = 2^n - 2^j$`.\nFor `$k=1023$`, which is `$\\sum_{i=0}^{9} 2^i$`, we have `$n=10$` and `$j=0$`.\n$$k = 1023 = 2^{10} - 2^0 = 1024 - 1$$\nThis is a representation of `$k$` as a difference of two powers of `$2$`.\n$$k = 1 \\cdot 2^{10} + (-1) \\cdot 2^0$$\nFor this representation:\n- The terms are `$2^{10}$` and `$-2^0$`. The number of terms is `$m=2$`.\n- The powers `$p_i$` are `$\\{10, 0\\}$`.\n- The number of shifts with `$p_i > 0$` is `$N_s = 1$` (for the `$p_1=10$` term). The `$p_2=0$` term has zero shift cost.\n- The number of operations to combine these `$2$` terms is `$m-1 = 1$` (a single subtraction).\n\nThe total cost for this strategy, `$C_2$`, is:\n$$C_2 = 3 \\cdot N_s + 5 \\cdot (m-1) = 3 \\cdot 1 + 5 \\cdot (2-1) = 3 + 5 = 8$$\nSo, the cost using this more compact representation is `8` cycles.\n\n**Optimality Analysis**\n\nWe have found two possible costs, `$C_1 = 72$` and `$C_2 = 8$`. The minimal cost found so far is `8`. We must determine if a lower cost is possible.\nThe cost function `$C = 3N_s + 5(m-1)$` increases with `$m$` and `$N_s$`. To achieve a minimal cost, we must use the smallest possible values for `$m$` and `$N_s$`.\n\n- A representation with `$m=1$` would mean `$k$` is a power of `$2$`. Since `$1023$` is not a power of `$2$`, we must have `$m \\ge 2$`.\n- The representation `$k = 2^{10} - 1$` uses the minimum possible number of terms, `$m=2$`.\n- With `$m=2$`, the cost is `$C = 3N_s + 5(2-1) = 3N_s + 5$`.\n- To represent `$1023$`, we must have at least one non-zero power of `$2$` (i.e. `$p_i > 0$`), so `$N_s \\ge 1$`.\n- The representation `$2^{10} - 1$` has one non-zero power (`$2^{10}$`), so `$N_s=1$`.\nThis configuration (`$m=2$`, `$N_s=1$`) yields a cost of `$3 \\cdot 1 + 5 = 8$`. This is the minimum possible cost for any representation with `$m=2$` terms.\n\nAny representation with `$m \\ge 3$` terms would have a cost `$C = 3N_s + 5(m-1) \\ge 3 \\cdot N_s + 5(3-1) = 3N_s + 10$`. Since `$N_s \\ge 1$`, this cost would be at least `13`, which is greater than `8`.\n\nTherefore, the representation of `$k = 1023$` as `$2^{10} - 1$` is optimal, and the minimal cost is `8` cycles.\n\nThe instruction sequence would be:\n1.  Compute `$t_1 = x \\ll 10$`. Cost: `3` cycles.\n2.  The value `$x$` is `$x \\ll 0$`. Cost: `0` cycles.\n3.  Compute `$y = t_1 - x$`. Cost: `5` cycles.\nTotal cost: `3 + 0 + 5 = 8` cycles.",
            "answer": "$$\n\\boxed{8}\n$$"
        },
        {
            "introduction": "Effective instruction selection goes beyond one-to-one translation; it involves recognizing patterns in the intermediate representation that match powerful hardware capabilities. This exercise focuses on a common scenario: array access within a loop. You will compare a naive instruction sequence against one that leverages a complex addressing mode, demonstrating how \"pattern matching\" allows the compiler to fold multiple arithmetic operations directly into memory instructions for significant performance gains .",
            "id": "3646830",
            "problem": "A compiler back end must generate target code for a tight loop in an Intermediate Representation (IR) that performs the element-wise update $a[i] = a[i] + k$ on a contiguous array of $n$ $64$-bit integers. The Intermediate Representation (IR) uses three-address code with explicit address arithmetic and load/store operations, and the target machine supports a scaled indexed addressing mode.\n\nThe loop body in IR (using temporaries $t_1, t_2, \\dots$) is:\nL:\n$t_1 \\leftarrow i \\times w$\n$t_2 \\leftarrow \\text{base\\_a} + t_1$\n$t_3 \\leftarrow \\text{load}(t_2)$\n$t_4 \\leftarrow t_3 + k$\n$\\text{store}(t_2, t_4)$\n$i \\leftarrow i + 1$\n$\\text{if } i  n \\text{ goto L}$\n\nAssume the following:\n- The element size is $w = 8$ bytes, so $a[i]$ resides at address $\\text{base\\_a} + i \\times w$.\n- The target machine supports a memory operand of the form $[r_b + r_i \\times s]$ in both load and store instructions, where $s \\in \\{1, 2, 4, 8\\}$.\n- The loop index $i$, bound $n$, constant $k$, and base address $\\text{base\\_a}$ are all kept in registers throughout the loop. Ignore loop setup costs and assume no register spills.\n- The cost model (latency per dynamic instruction) is:\n  - Integer addition or subtraction: $1$ cycle.\n  - Integer multiplication: $3$ cycles.\n  - Compare: $1$ cycle.\n  - Conditional branch (assume always correctly predicted): $1$ cycle.\n  - Load or store (with any legal addressing mode): $4$ cycles each.\n\nConsider two instruction selection strategies:\n- Strategy A (naïve): Materialize $i \\times w$ in a register and then add to $\\text{base\\_a}$ each iteration to compute the address used by load and store.\n- Strategy B (addressing-mode folding): Use the scaled indexed addressing mode $[\\text{base\\_a} + i \\times w]$ in both the load and the store, eliminating explicit computation of $i \\times w$ and the separate base addition in the loop body. The loop still increments $i$ by $1$ and performs the compare and branch.\n\nUsing only the assumptions above and starting from the given IR loop, derive the per-iteration dynamic cost for Strategy A and Strategy B, then compute the total cycle savings when processing $n = 4096$ elements with Strategy B instead of Strategy A. Express the final answer as a single exact real number. No rounding is required.",
            "solution": "The user wants me to analyze two instruction selection strategies for a given loop in an Intermediate Representation (IR), calculate their respective per-iteration costs, and determine the total cycle savings for a specific number of iterations.\n\nThe problem has been validated and is deemed valid as it is a well-posed, scientifically grounded problem from the field of compiler design. All necessary data and constraints are provided.\n\nFirst, we must determine the sequence of machine instructions and their associated costs for each strategy based on the provided IR and cost model. The loop performs `$n$` iterations, where `$n = 4096$`.\n\nLet's denote the cost per iteration for Strategy A as `$C_A$` and for Strategy B as `$C_B$`. The loop body in the IR is:\n1.  `$t_1 \\leftarrow i \\times w$`\n2.  `$t_2 \\leftarrow \\text{base\\_a} + t_1$`\n3.  `$t_3 \\leftarrow \\text{load}(t_2)$`\n4.  `$t_4 \\leftarrow t_3 + k$`\n5.  `$\\text{store}(t_2, t_4)$`\n6.  `$i \\leftarrow i + 1$`\n7.  `$\\text{if } i  n \\text{ goto L}$`\n\nThe machine instruction costs are given as:\n- Integer addition/subtraction: `$1$` cycle\n- Integer multiplication: `$3$` cycles\n- Compare: `$1$` cycle\n- Conditional branch: `$1$` cycle\n- Load or store: `$4$` cycles\n\nThe element size is `$w = 8$` bytes.\n\n**Analysis of Strategy A (Naïve)**\nThis strategy generates a separate machine instruction for each operation in the IR. We analyze the cost of the instructions corresponding to the loop body.\n\n1.  `$t_1 \\leftarrow i \\times w$`: This translates to a single integer multiplication instruction.\n    Cost: `$3$` cycles.\n2.  `$t_2 \\leftarrow \\text{base\\_a} + t_1$`: This is an integer addition to compute the final address.\n    Cost: `$1$` cycle.\n3.  `$t_3 \\leftarrow \\text{load}(t_2)$`: A load instruction using the computed address in a register.\n    Cost: `$4$` cycles.\n4.  `$t_4 \\leftarrow t_3 + k$`: The core element-wise addition.\n    Cost: `$1$` cycle.\n5.  `$\\text{store}(t_2, t_4)$`: A store instruction using the same computed address.\n    Cost: `$4$` cycles.\n6.  `$i \\leftarrow i + 1$`: The loop index increment.\n    Cost: `$1$` cycle.\n7.  `if i  n goto L`: This involves a comparison followed by a conditional branch.\n    - Compare `$i` with `$n$`: `$1$` cycle.\n    - Conditional branch: `$1$` cycle.\n    Total cost for loop control: `$1 + 1 = 2$` cycles.\n\nThe total cost per iteration for Strategy A is the sum of these costs:\n$$ C_A = 3 (\\text{mul}) + 1 (\\text{add}) + 4 (\\text{load}) + 1 (\\text{add}) + 4 (\\text{store}) + 1 (\\text{inc}) + 1 (\\text{cmp}) + 1 (\\text{branch}) $$\n$$ C_A = 16 \\text{ cycles} $$\n\n**Analysis of Strategy B (Addressing-Mode Folding)**\nThis strategy utilizes the target machine's scaled indexed addressing mode, `$[r_b + r_i \\times s]$`, to combine the address calculation into the load and store instructions. Here, `$r_b$` holds `$\\text{base\\_a}$`, `$r_i$` holds `$i$`, and the scale factor `$s$` is set to the element width `$w = 8$`. The machine supports `$s=8$`, so this is a legal optimization.\n\n1.  `$t_1 \\leftarrow i \\times w$` and `$t_2 \\leftarrow \\text{base\\_a} + t_1$`: These two IR statements are not translated into separate machine instructions. Instead, their functionality is \"folded\" into the addressing mode of the memory operations.\n    Cost: `$0$` cycles for explicit instructions.\n2.  `$t_3 \\leftarrow \\text{load}(t_2)$`: This becomes a single `load` instruction with the complex addressing mode `$[\\text{base\\_a} + i \\times 8]$`. The problem states that the cost of a `load` is `$4$` cycles, regardless of the addressing mode.\n    Cost: `$4$` cycles.\n3.  `$t_4 \\leftarrow t_3 + k$`: The core element-wise addition remains.\n    Cost: `$1$` cycle.\n4.  `$\\text{store}(t_2, t_4)$`: Similar to the `load`, this becomes a single `store` instruction using the `$[\\text{base\\_a} + i \\times 8]$` addressing mode. The cost is also `$4$` cycles.\n    Cost: `$4$` cycles.\n5.  `$i \\leftarrow i + 1$`: The loop index increment is unchanged.\n    Cost: `$1$` cycle.\n6.  `if i  n goto L`: The loop control logic is also unchanged.\n    - Compare `$i` with `$n$`: `$1$` cycle.\n    - Conditional branch: `$1$` cycle.\n    Total cost for loop control: `$1 + 1 = 2$` cycles.\n\nThe total cost per iteration for Strategy B is the sum of these costs:\n$$ C_B = 4 (\\text{load}) + 1 (\\text{add}) + 4 (\\text{store}) + 1 (\\text{inc}) + 1 (\\text{cmp}) + 1 (\\text{branch}) $$\n$$ C_B = 12 \\text{ cycles} $$\n\n**Calculation of Total Savings**\nThe savings per iteration is the difference between the costs of the two strategies:\n$$ S_{\\text{iter}} = C_A - C_B = 16 - 12 = 4 \\text{ cycles} $$\nThis saving comes from eliminating the explicit `MUL` (cost `$3$` cycles) and `ADD` (cost `$1$` cycle) instructions used for address calculation in Strategy A.\n\nThe total number of elements to process is `$n = 4096$`. This corresponds to `$4096$` iterations of the loop.\nThe total cycle savings, `$S_{\\text{total}}$`, is the per-iteration savings multiplied by the number of iterations:\n$$ S_{\\text{total}} = n \\times S_{\\text{iter}} = 4096 \\times 4 $$\n$$ S_{\\text{total}} = 16384 $$\nThe total cycle savings is `$16384$`.",
            "answer": "$$\\boxed{16384}$$"
        },
        {
            "introduction": "Optimal code generation often requires coordination between different compiler phases. This final practice demonstrates the crucial interplay between instruction selection and instruction scheduling when managing limited machine resources. Faced with constants too large to fit in an instruction's immediate field, you will discover that the best strategy involves reordering code to maximize the reuse of values loaded into a register, thereby minimizing costly memory access .",
            "id": "3646810",
            "problem": "You are targeting a simple scalar machine and must perform instruction selection for an Intermediate Representation (IR) basic block whose constants exceed the immediate-encoding range. The goal is to minimize the number of extra memory loads introduced solely to materialize large constants. Consider the following target and IR, and then choose the instruction-selection strategy that minimizes the number of literal loads per execution of the block.\n\nTarget machine model and constraints:\n- Immediate-encoding limit: an add-with-immediate instruction $\\mathrm{ADDI}\\ R_d, R_s, \\mathrm{imm}$ accepts only a signed $\\mathrm{imm}$ in the range $[-2{,}048, 2{,}047]$ (that is, $12$-bit signed).\n- Register-register add $\\mathrm{ADD}\\ R_d, R_s, R_t$ is available and uses only registers.\n- Literal load: $\\mathrm{LDRL}\\ R_d, [\\mathrm{PC}+\\mathrm{off}]$ loads a full $32$-bit literal from a pool (Program Counter (PC)-relative). Each $\\mathrm{LDRL}$ counts as exactly one “extra load” for the purpose of this problem.\n- Constant register constraint: the register allocator provides exactly one extra general-purpose register $r_c$ to hold any materialized literal. Any $\\mathrm{LDRL}$ must target $r_c$. At any point, $r_c$ holds at most one literal value; changing the value in $r_c$ requires issuing another $\\mathrm{LDRL}$ (one extra load). No other register may be used to hold a literal without spilling, which is disallowed here.\n- Mapping constraint: each IR addition must be implemented by exactly one machine $\\mathrm{ADD}$ or exactly one machine $\\mathrm{ADDI}$. You may not decompose a single IR addition into multiple adds to “accumulate” a large constant. Bringing an operand (a large constant) into a register using $\\mathrm{LDRL}$ is allowed, but the IR add itself is still exactly one $\\mathrm{ADD}$ or one $\\mathrm{ADDI}$.\n- Scheduling: within the basic block, you may reorder instructions if and only if data dependencies are preserved. No algebraic reassociation (such as changing the grouping of additions or creating new constants) is allowed.\n\nIR basic block (three-address code; variables $a,b,c,d$ are live on entry):\n- $t_1 := \\mathrm{add}(a, 50{,}000)$\n- $t_2 := \\mathrm{add}(b, 50{,}000)$\n- $t_3 := \\mathrm{add}(t_1, t_2)$\n- $t_4 := \\mathrm{add}(c, 70{,}000)$\n- $t_5 := \\mathrm{add}(t_3, 12)$\n- $t_6 := \\mathrm{add}(d, 1{,}024)$\n- $t_7 := \\mathrm{add}(t_6, 50{,}000)$\n\nFacts:\n- The immediates $12$ and $1{,}024$ are within the $12$-bit signed range and thus can use $\\mathrm{ADDI}$ without any literal loads.\n- The immediates $50{,}000$ and $70{,}000$ exceed the $12$-bit signed range and thus cannot be encoded in a single $\\mathrm{ADDI}$. To supply these to an $\\mathrm{ADD}$, you must materialize the constant in $r_c$ via $\\mathrm{LDRL}$ and then use $\\mathrm{ADD}$ with $r_c$ as the third operand.\n\nQuestion: Which strategy yields the minimal number of literal loads (i.e., $\\mathrm{LDRL}$ instructions) per execution of the block, under the constraints above?\n\nA. Do not reorder. For every IR addition with a large constant, issue $\\mathrm{LDRL}\\ r_c, \\text{const}$ immediately before the corresponding $\\mathrm{ADD}$ that uses it.\n\nB. Do not reorder. Hoist and keep $50{,}000$ in $r_c$ for the whole block (loading it once at block entry), using $\\mathrm{ADD}$ wherever $50{,}000$ is needed; when $70{,}000$ is needed, change $r_c$ to $70{,}000$ just before that use and then change $r_c$ back to $50{,}000$ for the later use.\n\nC. Legally reorder independent IR statements to cluster all uses of $50{,}000$ together before the single use of $70{,}000$; keep $50{,}000$ in $r_c$ across that cluster, then switch $r_c$ to $70{,}000$ once for its use.\n\nD. Legally reorder as in option C, but instead hoist and keep $70{,}000$ in $r_c$ and load $50{,}000$ on each of its uses.",
            "solution": "The user-provided problem is valid. It is a well-posed problem in compiler theory, specifically concerning instruction selection and scheduling, with clearly defined constraints and a measurable objective. All terms are standard in the discipline, and the model, though simplified, is scientifically grounded.\n\nThe problem asks for the instruction-selection strategy that minimizes the number of literal loads ($\\mathrm{LDRL}$ instructions) needed to handle large constants in a given Intermediate Representation (IR) basic block.\n\nFirst, let us formalize the IR and its dependencies. The IR instructions are:\n- $I_1: t_1 := \\mathrm{add}(a, 50{,}000)$\n- $I_2: t_2 := \\mathrm{add}(b, 50{,}000)$\n- $I_3: t_3 := \\mathrm{add}(t_1, t_2)$\n- $I_4: t_4 := \\mathrm{add}(c, 70{,}000)$\n- $I_5: t_5 := \\mathrm{add}(t_3, 12)$\n- $I_6: t_6 := \\mathrm{add}(d, 1{,}024)$\n- $I_7: t_7 := \\mathrm{add}(t_6, 50{,}000)$\n\nThe data dependencies form a directed acyclic graph (DAG):\n- $I_1 \\rightarrow I_3$ (because $I_3$ uses $t_1$)\n- $I_2 \\rightarrow I_3$ (because $I_3$ uses $t_2$)\n- $I_3 \\rightarrow I_5$ (because $I_5$ uses $t_3$)\n- $I_6 \\rightarrow I_7$ (because $I_7$ uses $t_6$)\nInstruction $I_4$ is independent of all other instructions in the block, as it uses an input variable $c$ and produces a result $t_4$ that is not used within the block.\n\nThe machine constraints state that any immediate value outside the range $[-2{,}048, 2{,}047]$ must be loaded from a literal pool into the dedicated register $r_c$ using an $\\mathrm{LDRL}$ instruction.\n- The constants $12$ and $1{,}024$ are within range and can be encoded in an $\\mathrm{ADDI}$ instruction without an extra load.\n- The constants $50{,}000$ and $70{,}000$ are outside this range. They require an $\\mathrm{LDRL}$ to load the value into $r_c$, followed by an $\\mathrm{ADD}$ instruction that uses $r_c$.\n\nThe large constants are used as follows:\n- The constant $50{,}000$ is used in $I_1$, $I_2$, and $I_7$.\n- The constant $70{,}000$ is used in $I_4$.\n\nThe goal is to minimize the total count of $\\mathrm{LDRL}$ instructions. This can be achieved by intelligently scheduling instructions and managing the contents of the constant register $r_c$. We will now evaluate each proposed strategy.\n\n### Analysis of Option A\n\n**Strategy**: Do not reorder. For every IR addition with a large constant, issue $\\mathrm{LDRL}\\ r_c, \\text{const}$ immediately before the corresponding $\\mathrm{ADD}$.\n\nThis is a naive, local strategy that does not attempt to reuse a constant already present in $r_c$. The instruction sequence is fixed as $I_1, I_2, I_3, I_4, I_5, I_6, I_7$.\n\n1.  For $I_1$ (uses $50{,}000$): Issue $\\mathrm{LDRL}\\ r_c, =50000$. (1 load)\n2.  For $I_2$ (uses $50{,}000$): The strategy dictates issuing an $\\mathrm{LDRL}$ for every use. Issue $\\mathrm{LDRL}\\ r_c, =50000$. (2 loads)\n3.  $I_3$ has no large constant.\n4.  For $I_4$ (uses $70{,}000$): Issue $\\mathrm{LDRL}\\ r_c, =70000$. (3 loads)\n5.  $I_5$ and $I_6$ have small immediates.\n6.  For $I_7$ (uses $50{,}000$): Issue $\\mathrm{LDRL}\\ r_c, =50000$. (4 loads)\n\nTotal literal loads: $4$.\n\n**Verdict**: Incorrect. This strategy is highly inefficient.\n\n### Analysis of Option B\n\n**Strategy**: Do not reorder. Hoist and keep $50{,}000$ in $r_c$ (loading it once at block entry), but when $70{,}000$ is needed, switch $r_c$ to $70{,}000$, and then switch it back to $50{,}000$ for the final use.\n\nThe instruction sequence is fixed. This strategy attempts to optimize reuse but is constrained by the fixed order.\n\n1.  At block entry: Issue $\\mathrm{LDRL}\\ r_c, =50000$. (1 load)\n2.  For $I_1$ (uses $50{,}000$): Use $r_c$. No new load.\n3.  For $I_2$ (uses $50{,}000$): Use $r_c$. No new load.\n4.  $I_3$ has no large constant.\n5.  For $I_4$ (uses $70{,}000$): The value in $r_c$ is $50{,}000$. We must switch. Issue $\\mathrm{LDRL}\\ r_c, =70000$. (2 loads)\n6.  After $I_4$, the strategy requires switching back to $50{,}000$ for the later use in $I_7$. Issue $\\mathrm{LDRL}\\ r_c, =50000$. (3 loads)\n7.  $I_5$ and $I_6$ have small immediates.\n8.  For $I_7$ (uses $50{,}000$): Use $r_c$, which now holds $50{,}000$. No new load.\n\nTotal literal loads: $3$.\n\n**Verdict**: Incorrect. This is better than strategy A, but the lack of reordering forces a suboptimal load-reload pattern.\n\n### Analysis of Option C\n\n**Strategy**: Legally reorder IR statements to cluster all uses of $50{,}000$ together before the single use of $70{,}000$. Keep $50{,}000$ in $r_c$ during its uses, then switch to $70{,}000$.\n\nThis strategy combines instruction scheduling with intelligent management of $r_c$. The goal is to perform all computations needing $50{,}000$ before any computation needing $70{,}000$. Since $I_4$ (using $70{,}000$) is independent of the other instruction chains, it can be moved after all other instructions. A legal, reordered schedule is: $I_1, I_2, I_3, I_6, I_7, I_5, I_4$. A simpler one that also achieves the goal:\n1.  $I_1: t_1 := \\mathrm{add}(a, 50{,}000)$\n2.  $I_2: t_2 := \\mathrm{add}(b, 50{,}000)$\n3.  $I_6: t_6 := \\mathrm{add}(d, 1{,}024)$\n4.  $I_7: t_7 := \\mathrm{add}(t_6, 50{,}000)$\n5.  $I_3: t_3 := \\mathrm{add}(t_1, t_2)$\n6.  $I_5: t_5 := \\mathrm{add}(t_3, 12)$\n7.  $I_4: t_4 := \\mathrm{add}(c, 70{,}000)$\n\nThis schedule is legal as all dependencies are respected. The sequence of large constant uses becomes: $50{,}000$ ($I_1$), $50{,}000$ ($I_2$), $50{,}000$ ($I_7$), and finally $70{,}000$ ($I_4$).\n\n1.  At block entry: Issue $\\mathrm{LDRL}\\ r_c, =50000$. (1 load)\n2.  For $I_1, I_2, I_7$: Use the value in $r_c$. No new loads.\n3.  For $I_4$ (uses $70{,}000$): The value in $r_c$ is $50{,}000$. We must switch. Issue $\\mathrm{LDRL}\\ r_c, =70000$. (2 loads)\n\nTotal literal loads: $2$.\n\n**Verdict**: Correct. This strategy is optimal. It minimizes the number of loads by scheduling instructions to maximize the reuse of the most frequent large constant before switching to another constant.\n\n### Analysis of Option D\n\n**Strategy**: Legally reorder as in option C, but instead hoist and keep $70{,}000$ and load $50{,}000$ on each of its uses.\n\nThis strategy reorders instructions but makes a poor choice of which constant to prioritize. A legal schedule would place $I_4$ first, followed by the other instructions, respecting their dependencies.\nExample schedule: $I_4, I_1, I_2, I_6, I_7, I_3, I_5$.\n\nThe loading strategy is described as \"hoist and keep $70{,}000$\" (an intelligent, global choice) but \"load $50{,}000$ on each of its uses\" (a naive, local choice). We evaluate the strategy as stated.\n\n1.  At block entry: Hoist the constant for $I_4$. Issue $\\mathrm{LDRL}\\ r_c, =70000$. (1 load)\n2.  For $I_4$: Use $r_c$.\n3.  For the first use of $50{,}000$ ($I_1$): Strategy says to load on each use. Issue $\\mathrm{LDRL}\\ r_c, =50000$. (2 loads)\n4.  For the second use of $50{,}000$ ($I_2$): Strategy says to load on each use. Issue $\\mathrm{LDRL}\\ r_c, =50000$. (3 loads)\n5.  For the third use of $50{,}000$ ($I_7$): Strategy says to load on each use. Issue $\\mathrm{LDRL}\\ r_c, =50000$. (4 loads)\n\nTotal literal loads: $4$.\nEven if \"load on each use\" were interpreted more charitably as \"load when needed\", this strategy would require loading $70{,}000$ first (1 load), then loading $50{,}000$ for the subsequent uses (1 load), for a total of $2$ loads, same as option C. However, the explicit phrasing \"load ... on each of its uses\" contrasts with the \"hoist and keep\" phrasing and suggests a naive implementation for the non-hoisted constant. This makes the strategy described in D inferior to C. Given the options, C describes the unambiguously optimal approach.\n\n**Verdict**: Incorrect. This strategy is suboptimal due to either prioritizing the less frequent constant or explicitly specifying a naive loading method for the more frequent one.\n\n**Conclusion**:\n- Strategy A: $4$ loads\n- Strategy B: $3$ loads\n- Strategy C: $2$ loads\n- Strategy D: $4$ loads\n\nThe minimal number of literal loads is $2$, achieved by strategy C.",
            "answer": "$$\\boxed{C}$$"
        }
    ]
}