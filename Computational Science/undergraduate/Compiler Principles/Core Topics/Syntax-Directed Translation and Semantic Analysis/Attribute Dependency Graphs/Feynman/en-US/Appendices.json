{
    "hands_on_practices": [
        {
            "introduction": "To build a solid foundation, we begin with the most fundamental type of attribute: the synthesized attribute. In this model, information flows strictly upwards through the parse tree, from children to parents. This first exercise  guides you through constructing an Attribute Dependency Graph (ADG) for a purely synthesized attribute and demonstrates a crucial principle: the validity of the evaluation order depends on the attribute dependencies, not on the syntactic structure of the grammar, such as left-recursion.",
            "id": "3622334",
            "problem": "Consider the context-free grammar with a single nonterminal $S$ and productions $S \\to S\\ S \\mid a$. Define a synthesized attribute $S.count$ that equals the number of leaf terminals $a$ in the subtree rooted at $S$. By definition of synthesized attributes, $S.count$ at a parent is a function of attributes of symbols in its production’s right-hand side, and never of attributes of its parent or siblings outside the subtree. For this grammar, specify semantic rules consistent with this definition.\n\nNow take the input string $aaaa$ and consider the following left-branching parse tree (induced by a left-recursive derivation), where each internal $S$ expands using $S \\to S\\ S$ until a leaf $S \\to a$ is used:\n- The root $S_0$ has children $S_1$ and $S_2$.\n- $S_1$ has children $S_3$ and $S_4$.\n- $S_3$ has children $S_5$ and $S_6$.\n- $S_5 \\to a$, $S_6 \\to a$, $S_4 \\to a$, and $S_2 \\to a$.\n\nUsing the standard definition of an attribute dependency graph (ADG), where each node is an occurrence of an attribute (here, occurrences of $S_i.count$ for each parse tree node $S_i$) and each directed edge $X \\to Y$ indicates that the value of attribute $Y$ directly depends on the value of attribute $X$, construct the ADG for this parse tree. Then, based on first principles about attributed grammars and dependency graphs, reason about whether left recursion in the grammar affects the schedulability or the evaluation order of $S.count$ for arbitrary parse trees of this grammar.\n\nSelect all statements that are correct:\n\nA. For any parse tree of this grammar under these attribute rules, the ADG is acyclic with edges directed from child attributes to their parent’s attribute, and any postorder traversal of the parse tree yields a valid evaluation schedule for all $S.count$. Left recursion does not introduce cycles.\n\nB. Because the grammar is left-recursive, the ADG necessarily contains a cycle of the form $S_i.count \\to S_i.count$ at some node, so evaluation of $S.count$ requires iterative fixed-point computation.\n\nC. The attribute scheme is $S$-attributed and can be computed in a single bottom-up pass (for example, during a Left-to-right Rightmost-derivation (LR) parse), regardless of whether the grammar is left- or right-recursive.\n\nD. Due to left recursion, $S.count$ must be evaluated strictly left-to-right following a leftmost derivation sequence; any other schedule risks using uninitialized attributes.\n\nE. Eliminating left recursion (e.g., by grammar transformation) fundamentally changes the set of valid schedules for $S.count$ because the attribute becomes inherited rather than synthesized.",
            "solution": "The problem statement is first validated to ensure it is scientifically sound, well-posed, and objective.\n\n### Step 1: Extract Givens\n-   **Grammar:** A context-free grammar with a single nonterminal $S$.\n-   **Productions:** $S \\to S\\ S \\mid a$.\n-   **Attribute:** A synthesized attribute named $S.count$.\n-   **Attribute Definition:** $S.count$ equals the number of leaf terminals $a$ in the subtree rooted at $S$.\n-   **Synthesized Attribute Property:** The value at a parent node is a function of the attributes of the symbols on the right-hand side of the production used at that node.\n-   **Input String:** $aaaa$.\n-   **Parse Tree:** A specific left-branching parse tree for the input string $aaaa$ is provided:\n    -   Root $S_0$ has children $S_1$ and $S_2$ (production $S_0 \\to S_1 S_2$).\n    -   $S_1$ has children $S_3$ and $S_4$ (production $S_1 \\to S_3 S_4$).\n    -   $S_3$ has children $S_5$ and $S_6$ (production $S_3 \\to S_5 S_6$).\n    -   Leaf productions are $S_5 \\to a$, $S_6 \\to a$, $S_4 \\to a$, and $S_2 \\to a$. The in-order traversal of the leaves yields the string $a a a a$.\n-   **Attribute Dependency Graph (ADG) Definition:** Nodes are attribute occurrences ($S_i.count$). A directed edge $X \\to Y$ indicates that the value of attribute $Y$ directly depends on the value of attribute $X$.\n-   **Task:** Construct the ADG for the given tree and reason about the effect of left recursion on the schedulability of $S.count$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded:** The problem uses standard, well-defined concepts from compiler theory, including context-free grammars, synthesized attributes, parse trees, attribute dependency graphs, and left recursion. The definitions provided align with established computer science principles.\n2.  **Well-Posed:** The problem is clearly stated. The grammar, attribute, and specific parse tree are unambiguously defined. The question asks for an analysis based on these definitions, which leads to a definite conclusion.\n3.  **Objective:** The language is formal and objective.\n\nThe problem statement is complete, consistent, and grounded in established theory.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. The solution process will now proceed.\n\n### Derivation and Analysis\n\nFirst, we must specify the semantic rules for the attribute $S.count$ based on its definition. These rules associate a computation with each production in the grammar.\n\n1.  For the production $S \\to a$: The subtree rooted at this $S$ consists of a single leaf node $a$. Therefore, the count of $a$'s is $1$.\n    -   Semantic rule: $S.count \\leftarrow 1$.\n\n2.  For the production $S_0 \\to S_1 S_2$ (using indices to distinguish occurrences): The terminals in the subtree of $S_0$ are the union of the terminals in the subtrees of its children, $S_1$ and $S_2$. Thus, the total count is the sum of the counts from the two child subtrees.\n    -   Semantic rule: $S_0.count \\leftarrow S_1.count + S_2.count$.\n\nThese two rules completely define the computation of $S.count$ for any parse tree generated by this grammar. The attribute is purely synthesized, as its value at a parent node depends only on the values of attributes at its children nodes (or is a constant, for a terminal production).\n\nNext, we analyze the properties of the attribute dependency graph (ADG). By definition, an edge exists from an attribute instance $X$ to an attribute instance $Y$ if the semantic rule for $Y$ uses the value of $X$.\nFor our rules:\n-   $S_0.count \\leftarrow S_1.count + S_2.count$: This creates dependency edges from $S_1.count$ to $S_0.count$ and from $S_2.count$ to $S_0.count$.\n-   $S.count \\leftarrow 1$: This creates no dependencies on other attributes.\n\nIn general, for any synthesized attribute, the dependency edges in the ADG always point from an attribute of a child node to an attribute of its parent node. Since a parse tree is a tree structure and a node cannot be its own ancestor, it is impossible to form a cycle by following these parent-pointing edges. Therefore, the ADG for any grammar with only synthesized attributes is always a Directed Acyclic Graph (DAG).\n\nA valid evaluation schedule for attributes is a topological sort of the ADG's nodes. Since dependencies flow up the tree, any evaluation order that computes attributes at child nodes before computing them at their parent node is valid. A post-order traversal of the parse tree has exactly this property: it visits a node only after all of its children have been visited. Thus, any post-order traversal yields a valid schedule.\n\nThe grammar $S \\to S\\ S \\mid a$ is left-recursive because the nonterminal $S$ appears as the leftmost symbol on the right-hand side of the production $S \\to S\\ S$. This property influences the structure of parse trees (tending to be left-deep, as in the example given), but it does not alter the fundamental nature of synthesized attributes. The dependencies for $S.count$ still flow strictly upwards from children to parents, so left recursion does not introduce cycles into the ADG.\n\n### Option-by-Option Evaluation\n\n**A. For any parse tree of this grammar under these attribute rules, the ADG is acyclic with edges directed from child attributes to their parent’s attribute, and any postorder traversal of the parse tree yields a valid evaluation schedule for all $S.count$. Left recursion does not introduce cycles.**\nThis statement accurately summarizes the properties of synthesized attributes.\n-   The ADG is indeed acyclic with edges from child to parent, as established above.\n-   A post-order traversal is a topological sort of this ADG, making it a valid evaluation schedule.\n-   Left recursion does not change the bottom-up data flow of synthesized attributes and thus does not create cycles.\nThe statement is entirely consistent with the theory of attribute grammars.\n**Verdict: Correct.**\n\n**B. Because the grammar is left-recursive, the ADG necessarily contains a cycle of the form $S_i.count \\to S_i.count$ at some node, so evaluation of $S.count$ requires iterative fixed-point computation.**\nThis is incorrect. A cycle of the form $S_i.count \\to S_i.count$ would imply a semantic rule where an attribute depends on itself, such as $S.count \\leftarrow S.count + 1$. The rules we derived are $S_0.count \\leftarrow S_1.count + S_2.count$ and $S.count \\leftarrow 1$. Neither rule is self-referential. Left recursion in the grammar does not imply circular dependencies in the attribute definitions for synthesized attributes.\n**Verdict: Incorrect.**\n\n**C. The attribute scheme is $S$-attributed and can be computed in a single bottom-up pass (for example, during a Left-to-right Rightmost-derivation (LR) parse), regardless of whether the grammar is left- or right-recursive.**\nAn attribute grammar is defined as S-attributed if it uses only synthesized attributes. This is the case here. A key property of S-attributed grammars is that their attributes can be evaluated during a single bottom-up parse. An LR parser performs a bottom-up parse by constructing the parse tree from the leaves to the root. When it performs a reduction by a production $A \\to \\beta$, the subtrees for the symbols in $\\beta$ have already been processed, so their attributes are known and can be used to compute the attribute for $A$. This evaluation strategy works for any S-attributed grammar, irrespective of its recursive structure.\n**Verdict: Correct.**\n\n**D. Due to left recursion, $S.count$ must be evaluated strictly left-to-right following a leftmost derivation sequence; any other schedule risks using uninitialized attributes.**\nA leftmost derivation corresponds to a pre-order traversal of the parse tree. In a pre-order traversal, a parent node is visited before its children. Attempting to evaluate a synthesized attribute like $S.count$ in this order would mean trying to compute the parent's attribute before the children's attributes are known, which violates the dependencies. For example, one would try to compute $S_0.count$ before $S_1.count$ and $S_2.count$, which is impossible. This evaluation strategy is suited for inherited attributes, not synthesized ones.\n**Verdict: Incorrect.**\n\n**E. Eliminating left recursion (e.g., by grammar transformation) fundamentally changes the set of valid schedules for $S.count$ because the attribute becomes inherited rather than synthesized.**\nThis statement is too strong and therefore false. While it is true that one common technique for eliminating left recursion (often to make a grammar suitable for LL parsing) involves introducing inherited attributes to pass information that was previously accumulated up a left-recursive spine, it is not a required outcome. The language generated by $S \\to S\\ S \\mid a$ is the set of all non-empty strings of $a$'s, i.e., $a^+$. An equivalent, unambiguous, and non-left-recursive grammar for this language is $S \\to a S \\mid a$. For this new grammar, we can define the count with purely synthesized attributes:\n-   For $S \\to a$: $S.count \\leftarrow 1$.\n-   For $S_0 \\to a S_1$: $S_0.count \\leftarrow 1 + S_1.count$.\nSince we found an equivalent non-left-recursive grammar for which the attribute remains synthesized, the claim that the attribute *must* become inherited is false. Therefore, the reasoning for the supposed fundamental change is flawed.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{AC}$$"
        },
        {
            "introduction": "While synthesized attributes are powerful, many real-world problems require more complex information flow. This practice  explores a classic compiler scenario where a simple, single-pass evaluation is insufficient. By analyzing the dependencies for calculating stack frame layouts, you will discover cases where attributes deep within the parse tree depend on values computed at the very top, illustrating why a full ADG and a general evaluation strategy like topological sorting are essential tools.",
            "id": "3622373",
            "problem": "Consider the following setting in compiler principles. An Attribute Grammar (AG) augments a context-free grammar with semantic attributes and equations. An Attribute Dependency Graph (ADG) is a directed graph whose nodes are attribute occurrences and whose edges represent direct dependencies induced by the semantic equations: there is a directed edge from attribute $a$ to attribute $b$ if the equation defining $b$ uses $a$. A well-formed AG should yield an acyclic ADG for any input, making a topological evaluation possible.\n\nSuppose we define a fragment of an AG that computes the stack frame layout of a function, with a synthesized attribute $F.size$ for the total frame size and, for each variable declaration, a synthesized attribute $Var.offset$ giving the distance from the bottom of the frame to the start of that variable’s storage. The stack grows downward, the frame has a fixed header overhead $h$, and variable sizes are determined by their types.\n\nGrammar fragment:\n- $F \\to \\text{func}~Id~\\{~DL~\\}$\n- $DL \\to V~DL \\mid \\epsilon$\n- $V \\to \\text{var}~Id~:~T~;$\n- $T \\to int \\mid float$\n\nGiven sizes $size(int) = 4$, $size(float) = 8$, and frame header overhead $h = 16$.\n\nAttributes:\n- $T.size$ is synthesized: $T.size := 4$ if $T \\to int$ and $T.size := 8$ if $T \\to float$.\n- $V.size$ is synthesized: $V.size := T.size$.\n- $DL.totalSize$ is synthesized: $DL.totalSize := 0$ when $DL \\to \\epsilon$, and $DL.totalSize := V.size + DL_1.totalSize$ when $DL \\to V~DL_1$.\n- $DL.prefix$ is inherited: $DL.prefix := 0$ at the $DL$ under $F$, and when $DL \\to V~DL_1$, propagate $V.prefix := DL.prefix$ and $DL_1.prefix := DL.prefix + V.size$.\n- $F.size$ is synthesized: $F.size := h + DL.totalSize$ at $F \\to \\text{func}~Id~\\{~DL~\\}$.\n- $V.offset$ is synthesized: $V.offset := F.size - (h + V.prefix + V.size)$ at $V \\to \\text{var}~Id~:~T~;$, which makes $Var.offset$ depend on $F.size$ and enforces that offsets are measured from the bottom of the frame.\n\nConsider the specific input:\n- A function $f$ with two local declarations in order: $x : int;$ and $y : float;$.\n\nLabel the occurrences in the parse tree as follows: the outer declaration list under $F$ is $DL_0$. The first variable declaration is $V_1$ with type $T_1$; the next declaration list is $DL_1$. The second variable declaration is $V_2$ with type $T_2$; the next declaration list is $DL_2$, and then $DL_2 \\to \\epsilon$.\n\nTask:\n1) Construct the Attribute Dependency Graph (ADG) for this input by listing the nodes (attribute occurrences) and directed edges induced by the above semantic rules. Your construction should make explicit the dependencies that force $Var.offset$ nodes to be evaluated after $F.size$.\n2) Based on your ADG, identify which of the following evaluation schemes ensures that every $Var.offset$ node is computed only after $F.size$ has been computed. Select all that apply.\n\nOptions:\nA. Evaluate attributes in a single left-to-right preorder traversal of the parse tree, computing each $V.offset$ immediately after its $V.size$ is known; update $F.size$ at the end.\nB. Construct the ADG from the semantic equations and perform a global topological sort over the ADG; evaluate attributes in the sorted order.\nC. Perform two passes over the tree: in the first pass, compute all $T.size$, $V.size$, $DL.totalSize$, and $F.size$; in the second pass, compute all $V.offset$ using the previously computed $F.size$ and the already established $V.prefix$ values.\nD. Redefine $V.offset$ to break its dependency on $F.size$ by setting $V.offset := h + V.prefix$; then compute all $V.offset$ before $F.size$ in a single pass.\n\nAnswer the multiple-choice part by selecting the option(s) that guarantee $Var.offset$ nodes are computed after $F.size$ while respecting the stated semantics.",
            "solution": "The problem statement has been validated and is deemed sound. It is a well-posed problem in the domain of compiler construction, specifically concerning attribute grammars and their evaluation. All definitions are clear, and the setup is internally consistent and scientifically grounded in computer science principles.\n\nThe core of the problem is to determine a correct evaluation strategy for a set of attributes defined by an attribute grammar. A correct evaluation strategy must respect the dependencies defined by the semantic equations. We will first construct the Attribute Dependency Graph (ADG) for the given input to make these dependencies explicit.\n\n### 1. Parse Tree and Attribute Instances\n\nFor the input `func f { var x : int; var y : float; }`, the parse tree, with labeled nodes as specified, is:\n$F \\to \\text{func}~Id~\\{~DL_0~\\}$\n$DL_0 \\to V_1~DL_1$\n$V_1 \\to \\text{var}~Id~:~T_1~;$\n$T_1 \\to int$\n$DL_1 \\to V_2~DL_2$\n$V_2 \\to \\text{var}~Id~:~T_2~;$\n$T_2 \\to float$\n$DL_2 \\to \\epsilon$\n\nThe nodes of the ADG are the attribute instances associated with the nodes of this parse tree.\n- **Synthesized attributes**: $T_1.size, T_2.size, V_1.size, V_2.size, DL_2.totalSize, DL_1.totalSize, DL_0.totalSize, F.size, V_1.offset, V_2.offset$.\n- **Inherited attributes**: $DL_0.prefix, V_1.prefix, DL_1.prefix, V_2.prefix, DL_2.prefix$.\n\n### 2. Attribute Dependency Graph (ADG) Construction\n\nThe directed edges of the ADG are determined by the semantic equations. An edge exists from attribute occurrence $a$ to $b$ (denoted $a \\to b$) if the value of $a$ is used to compute the value of $b$.\n\n1.  **Size Attributes (Synthesized)**: These dependencies generally flow up the parse tree.\n    - $T_1.size := 4$.\n    - $T_2.size := 8$.\n    - $V_1.size := T_1.size \\implies T_1.size \\to V_1.size$.\n    - $V_2.size := T_2.size \\implies T_2.size \\to V_2.size$.\n    - $DL_2.totalSize := 0$.\n    - $DL_1.totalSize := V_2.size + DL_2.totalSize \\implies \\{V_2.size, DL_2.totalSize\\} \\to DL_1.totalSize$.\n    - $DL_0.totalSize := V_1.size + DL_1.totalSize \\implies \\{V_1.size, DL_1.totalSize\\} \\to DL_0.totalSize$.\n    - $F.size := h + DL_0.totalSize \\implies DL_0.totalSize \\to F.size$.\n\n2.  **Prefix Attributes (Inherited)**: These dependencies generally flow down the parse tree, and from left to right among siblings.\n    - $DL_0.prefix := 0$.\n    - $V_1.prefix := DL_0.prefix \\implies DL_0.prefix \\to V_1.prefix$.\n    - $DL_1.prefix := DL_0.prefix + V_1.size \\implies \\{DL_0.prefix, V_1.size\\} \\to DL_1.prefix$.\n    - $V_2.prefix := DL_1.prefix \\implies DL_1.prefix \\to V_2.prefix$.\n    - $DL_2.prefix := DL_1.prefix + V_2.size \\implies \\{DL_1.prefix, V_2.size\\} \\to DL_2.prefix$.\n\n3.  **Offset Attributes (Synthesized)**: These are the critical attributes for this problem.\n    - $V_1.offset := F.size - (h + V_1.prefix + V_1.size) \\implies \\{F.size, V_1.prefix, V_1.size\\} \\to V_1.offset$.\n    - $V_2.offset := F.size - (h + V_2.prefix + V_2.size) \\implies \\{F.size, V_2.prefix, V_2.size\\} \\to V_2.offset$.\n\nThe crucial dependency is that the computation of both $V_1.offset$ and $V_2.offset$ requires the value of $F.size$. Let's trace the dependencies required to compute $F.size$:\nThe chain of dependencies to compute $F.size$ is purely synthesized and moves up the tree:\n$(T_1.size \\to V_1.size)$ and $(T_2.size \\to V_2.size) \\to (V_2.size, DL_2.totalSize \\to DL_1.totalSize) \\to (V_1.size, DL_1.totalSize \\to DL_0.totalSize) \\to (DL_0.totalSize \\to F.size)$.\nThis means that to compute $F.size$, information from the entire declaration list ($DL_0$) must be aggregated.\n\nThe dependency from $F.size$ to $V.offset$ is from an attribute of an ancestor node ($F$) to a synthesized attribute of a descendant node ($V_1$ or $V_2$). This makes it impossible to evaluate all attributes in a single depth-first traversal, as a simple pass cannot both collect information up to the root (to calculate $F.size$) and then use that root-level information to calculate attributes in the leaves ($V.offset$) within the same pass. The ADG is acyclic, so an evaluation order exists, but it is not a simple one.\n\nAny valid evaluation scheme must compute $F.size$ before computing $V_1.offset$ and $V_2.offset$.\n\n### 3. Evaluation of Options\n\nLet's evaluate each option against the derived dependencies.\n\n**A. Evaluate attributes in a single left-to-right preorder traversal of the parse tree, computing each $V.offset$ immediately after its $V.size$ is known; update $F.size$ at the end.**\nIn a preorder traversal, we visit the parent before its children. We would visit $F$, then $DL_0$, then $V_1$. At $V_1$, its children are processed, allowing the computation of $T_1.size$ and then $V_1.size$. The option then proposes to compute $V_1.offset$. The formula for $V_1.offset$ requires $F.size$. However, at this point in the traversal, we have not yet visited $V_2$, so $DL_1.totalSize$ and subsequently $DL_0.totalSize$ and $F.size$ cannot have been computed. The option itself states $F.size$ is updated \"at the end\". This directly violates the dependency edge $(F.size \\to V_1.offset)$ in the ADG.\n**Verdict: Incorrect.**\n\n**B. Construct the ADG from the semantic equations and perform a global topological sort over the ADG; evaluate attributes in the sorted order.**\nThis is the most general and theoretically sound method for attribute evaluation for any well-formed attribute grammar (i.e., one that yields an acyclic ADG). A topological sort of a directed acyclic graph (DAG) produces a linear ordering of its nodes such that for every directed edge from node $u$ to node $v$, $u$ comes before $v$ in the ordering. Since our ADG is acyclic and contains the edges $(F.size \\to V_1.offset)$ and $(F.size \\to V_2.offset)$, any topological sort will necessarily place the computation of $F.size$ before the computation of $V_1.offset$ and $V_2.offset$. This method, by definition, respects all dependencies.\n**Verdict: Correct.**\n\n**C. Perform two passes over the tree: in the first pass, compute all $T.size$, $V.size$, $DL.totalSize$, and $F.size$; in the second pass, compute all $V.offset$ using the previously computed $F.size$ and the already established $V.prefix$ values.**\nThis option describes a multi-pass evaluation strategy, which is a common practical approach for AGs that are not L-attributed.\n- **Pass 1:** Computes all attributes related to size. These are all synthesized attributes. Their dependencies flow up the parse tree. This pass can be implemented as a single post-order traversal (a bottom-up pass). At the end of this pass, the value of $F.size$ at the root node will be known.\n- **Pass 2:** Computes all $V.offset$ attributes. The rule for $V.offset$ requires $F.size$, $V.size$, and $V.prefix$. $F.size$ and all $V.size$ values are available from Pass 1. The $V.prefix$ attributes can also be computed during this pass (or a separate preliminary pass), as they depend on other prefixes and sizes which are all known. For instance, Pass 2 could be a pre-order traversal computing prefixes on the way down and then offsets.\nThe crucial aspect of this scheme is that $F.size$ is computed in its entirety in the first pass, before the second pass, which computes the $V.offset$ values, even begins. This explicitly ensures that the dependency $(F.size \\to V.offset)$ is satisfied.\n**Verdict: Correct.**\n\n**D. Redefine $V.offset$ to break its dependency on $F.size$ by setting $V.offset := h + V.prefix$; then compute all $V.offset$ before $F.size$ in a single pass.**\nThis option proposes altering the semantic rules of the attribute grammar. The problem asks for an evaluation scheme that works for the *given* semantics (\"while respecting the stated semantics\"). The proposed new rule, $V.offset := h + V.prefix$, defines an offset from the top of the variable area, not from the bottom of the frame as specified. This change yields different numerical values for the offsets and therefore does not compute the attribute as defined in the problem. For example, using the values calculated earlier ($h=16, V_1.prefix=0$), the new rule gives $V_1.offset = 16+0 = 16$, whereas the original rule gave $V_1.offset = 8$. Since this option does not respect the stated semantics, it is not a valid solution to the problem as posed.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{BC}$$"
        },
        {
            "introduction": "Attribute dependency graphs are not only for direct computation but also serve as a powerful framework for static analysis. This final exercise  delves into an advanced application: modeling dynamic, value-dependent behavior like boolean short-circuiting within a static graph. You will learn to approximate runtime possibilities by splitting a single value into over- and under-approximations ($val_{may}$ and $val_{must}$), a technique central to the field of abstract interpretation, thereby preserving a sound, analyzable ADG.",
            "id": "3622363",
            "problem": "Consider the following boolean-expression fragment of a mini language with short-circuit disjunction. The grammar is\n$\nE \\to E\\ \\text{or}\\ T \\mid T,\\quad\nT \\to \\text{id} \\mid \\text{true} \\mid \\text{false}.\n$\nShort-circuit semantics are as usual: in evaluating $\nE_1\\ \\text{or}\\ T\n$, the right operand $\nT\n$ is evaluated only if $\nE_1\n$ evaluates to $\n\\text{false}\n$.\n\nA standard synthesized attribute $\nE.val \\in \\{\\text{true},\\text{false}\\}\n$ is not statically representable by a single unconditional dependency in an attribute dependency graph (ADG) because the dependency on $\nT\n$ is conditional on the runtime value of $\nE_1\n$. To preserve a static directed acyclic graph of dependencies, consider splitting boolean truth into two synthesized attributes for every nonterminal $\nX\\in\\{E,T\\}\n$:\n$\nX.val_{may}\\in\\{\\text{true},\\text{false}\\}\n$ and $\nX.val_{must}\\in\\{\\text{true},\\text{false}\\}\n$, intended as an over- and under-approximation, respectively. Intuitively, $\nX.val_{may}=\\text{true}\n$ means the phrase denoted by $\nX\n$ can evaluate to $\n\\text{true}\n$ along some runtime path, and $\nX.val_{must}=\\text{true}\n$ means it evaluates to $\n\\text{true}\n$ along all runtime paths.\n\nAssume the following base cases for terminals, reflecting no static information about identifiers:\n$\n\\begin{aligned}\n&\\text{For }T\\to \\text{true}:\\quad T.val_{may}=\\text{true},\\quad T.val_{must}=\\text{true}.\\\\\n&\\text{For }T\\to \\text{false}:\\quad T.val_{may}=\\text{false},\\quad T.val_{must}=\\text{false}.\\\\\n&\\text{For }T\\to \\text{id}:\\quad T.val_{may}=\\text{true},\\quad T.val_{must}=\\text{false}.\n\\end{aligned}\n$\n\nFocus on the concrete input $\n\\text{id}\\ \\text{or}\\ \\text{false}\\ \\text{or}\\ \\text{true}\n$, which parses (by left associativity) as $\n(E\\ \\text{or}\\ T)\n$ where the left $\nE\n$ is $\n(\\text{id}\\ \\text{or}\\ \\text{false})\n$ and the right $\nT\n$ is $\n\\text{true}\n$.\n\nWhich option correctly specifies both:\n(1) sound and static synthesized-attribute equations for the production $\nE \\to E\\ \\text{or}\\ T\n$ in terms of $\nval_{may}\n$ and $\nval_{must}\n$, and\n(2) the corresponding ADG edges for that production that ensure a directed acyclic graph on the given parse tree, while yielding the correct root values on the given input?\n\nA. Use $\nE.val_{may} = E_1.val_{may} \\lor T.val_{may}\n$ and $\nE.val_{must} = E_1.val_{must} \\lor T.val_{must}\n$, where $\nE_1\n$ is the left $\nE\n$. For $\nE \\to E_1\\ \\text{or}\\ T\n$, include ADG edges from $\nE_1.val_{may}\n$ to $\nE.val_{may}\n$, from $\nT.val_{may}\n$ to $\nE.val_{may}\n$, from $\nE_1.val_{must}\n$ to $\nE.val_{must}\n$, and from $\nT.val_{must}\n$ to $\nE.val_{must}\n$. On $\n\\text{id}\\ \\text{or}\\ \\text{false}\\ \\text{or}\\ \\text{true}\n$, this yields root $\nE.val_{may}=\\text{true}\n$ and $\nE.val_{must}=\\text{true}\n$, and the ADG is acyclic.\n\nB. Use $\nE.val_{may} = E_1.val_{may} \\lor T.val_{may}\n$ and $\nE.val_{must} = E_1.val_{must} \\land T.val_{must}\n$. The ADG edges are as in A. On $\n\\text{id}\\ \\text{or}\\ \\text{false}\\ \\text{or}\\ \\text{true}\n$, the root has $\nE.val_{may}=\\text{true}\n$ and $\nE.val_{must}=\\text{false}\n$, and the ADG is acyclic.\n\nC. Because of short-circuiting, use $\nE.val_{may} = E_1.val_{may}\n$ and $\nE.val_{must} = E_1.val_{must}\n$, with ADG edges only from $\nE_1\n$ to $\nE\n$ for both attributes, omitting any edges from $\nT\n$ to $\nE\n$. On $\n\\text{id}\\ \\text{or}\\ \\text{false}\\ \\text{or}\\ \\text{true}\n$, the root has $\nE.val_{may}=\\text{true}\n$ and $\nE.val_{must}=\\text{false}\n$, and the ADG is acyclic.\n\nD. Introduce a synthesized guard $\nT.need\n$ with $\nT.need = \\lnot E_1.val_{may}\n$ and equations $\nE.val_{may} = E_1.val_{may} \\lor (T.need \\land T.val_{may})\n$, $\nE.val_{must} = E_1.val_{must} \\lor (T.need \\land T.val_{must})\n$. Add ADG edges $\nE_1.val_{may}\\to T.need\n$, $\nT.need\\to T.val_{may}\n$, $\nT.val_{may}\\to E.val_{may}\n$ and similarly for $\nval_{must}\n$. This preserves short-circuiting in the graph. On the given input the root has $\nE.val_{may}=\\text{true}\n$ and $\nE.val_{must}=\\text{true}\n$, but the ADG contains no cycles.",
            "solution": "### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Grammar**:\n  $E \\to E\\ \\text{or}\\ T \\mid T$\n  $T \\to \\text{id} \\mid \\text{true} \\mid \\text{false}$\n- **Semantics**: Short-circuit disjunction for $E_1\\ \\text{or}\\ T$. $T$ is evaluated only if $E_1$ evaluates to $\\text{false}$.\n- **Attributes**: For any nonterminal $X \\in \\{E, T\\}$, two synthesized attributes are defined:\n  - $X.val_{may} \\in \\{\\text{true}, \\text{false}\\}$: an over-approximation. $X.val_{may} = \\text{true}$ if the expression for $X$ *can* evaluate to $\\text{true}$.\n  - $X.val_{must} \\in \\{\\text{true}, \\text{false}\\}$: an under-approximation. $X.val_{must} = \\text{true}$ if the expression for $X$ *must* evaluate to $\\text{true}$.\n- **Base Cases for Terminals (via productions for T)**:\n  - For $T \\to \\text{true}$: $T.val_{may} = \\text{true}$, $T.val_{must} = \\text{true}$.\n  - For $T \\to \\text{false}$: $T.val_{may} = \\text{false}$, $T.val_{must} = \\text{false}$.\n  - For $T \\to \\text{id}$: $T.val_{may} = \\text{true}$, $T.val_{must} = \\text{false}$.\n- **Concrete Input**: The string $\\text{id}\\ \\text{or}\\ \\text{false}\\ \\text{or}\\ \\text{true}$.\n- **Parse Tree**: The input is parsed left-associatively, resulting in a structure equivalent to $((\\text{id}\\ \\text{or}\\ \\text{false})\\ \\text{or}\\ \\text{true})$. This corresponds to a parse tree where the root production is $E \\to E\\ \\text{or}\\ T$, with the left-hand $E$ being the root of the subtree for $(\\text{id}\\ \\text{or}\\ \\text{false})$ and the right-hand $T$ corresponding to $\\text{true}$.\n- **Question**: Find the option with (1) sound and static synthesized-attribute equations for $E \\to E\\ \\text{or}\\ T$ and (2) the correct corresponding attribute dependency graph (ADG) edges and resulting root values for the given input.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded**: The problem is rooted in standard compiler theory, specifically attribute grammars and static analysis. The concepts of over- and under-approximation ($val_{may}$, $val_{must}$) are standard techniques for abstract interpretation and static analysis of programs. The problem of modeling short-circuiting is a classic challenge. The setup is scientifically and factually sound.\n- **Well-Posed**: The problem is clearly defined. It specifies the grammar, the semantics to be modeled, the attributes to be used, the base cases, and a concrete input for testing. The goal is to find a set of attribute evaluation rules that satisfy certain properties (soundness, static dependency, acyclic ADG). This is a well-posed problem.\n- **Objective**: The language is technical and precise. Definitions are provided for the attributes and base cases. There are no subjective or ambiguous terms.\n- **Other checks**: The problem is self-contained and internally consistent. It is not trivial, as it requires understanding the interplay between short-circuit semantics and the constraints of S-attributed grammars (synthesized attributes only). It is not metaphorical or outside scientific verifiability.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is valid. It is a well-formed problem in computer science that tests fundamental concepts of attribute grammars and static analysis. The solution process may now proceed.\n\n---\n\n### Solution Derivation\n\nThe core task is to define sound, static attribute equations for the production $E \\to E_1\\ \\text{or}\\ T$ using only synthesized attributes. The use of \"synthesized\" is critical: it implies that the attributes of the parent node $E$ can only depend on the attributes of its children, $E_1$ and $T$. This structure automatically ensures that the dependency graph, when superimposed on the parse tree, is a Directed Acyclic Graph (DAG) because all dependencies flow upwards.\n\nLet's analyze the semantics for the two attributes based on the behavior of $E_1\\ \\text{or}\\ T$.\n\n**1. Analysis of $E.val_{may}$ (Over-approximation)**\n$E.val_{may}$ should be $\\text{true}$ if there is any execution path where $E_1\\ \\text{or}\\ T$ evaluates to $\\text{true}$. This occurs if:\n- $E_1$ can evaluate to $\\text{true}$. (In this case, the expression is $\\text{true}$ and $T$ is not evaluated.)\n- OR, $E_1$ can evaluate to $\\text{false}$ AND $T$ can evaluate to $\\text{true}$. (In this case, $T$ is evaluated and its $\\text{true}$ value determines the result.)\n\nA simple, sound over-approximation can combine these possibilities. The expression $E_1\\ \\text{or}\\ T$ can be $\\text{true}$ if $E_1$ can be $\\text{true}$ or if $T$ can be $\\text{true}$. This ignores the conditional evaluation of $T$, but it is still sound. If $E_1\\ \\text{or}\\ T$ can evaluate to $\\text{true}$, it must be that either $E_1$ could be $\\text{true}$ or $T$ could be $\\text{true}$. Therefore, a sound and simple rule is:\n$$E.val_{may} = E_1.val_{may} \\lor T.val_{may}$$\nThis rule is static and uses only synthesized attributes from children nodes.\n\n**2. Analysis of $E.val_{must}$ (Under-approximation)**\n$E.val_{must}$ should be $\\text{true}$ only if $E_1\\ \\text{or}\\ T$ evaluates to $\\text{true}$ on all possible execution paths. This occurs if:\n- $E_1$ must evaluate to $\\text{true}$. (In this case, the expression is always $\\text{true}$ regardless of $T$.)\n- OR, for every path where $E_1$ evaluates to $\\text{false}$, $T$ evaluates to $\\text{true}$.\n\nA simple, sound under-approximation is to check if either component provides a sufficient guarantee.\n- If $E_1$ must be $\\text{true}$ ($E_1.val_{must} = \\text{true}$), then $E_1\\ \\text{or}\\ T$ is always $\\text{true}$.\n- If $T$ must be $\\text{true}$ ($T.val_{must} = \\text{true}$), let's analyze the result. If an execution path makes $E_1$ $\\text{true}$, the result is $\\text{true}$. If an execution path makes $E_1$ $\\text{false}$, $T$ is evaluated. Since $T$ must be $\\text{true}$, the result is again $\\text{true}$. Thus, if $T.val_{must} = \\text{true}$, the expression $E_1\\ \\text{or}\\ T$ must be $\\text{true}$.\n\nSince either condition is sufficient, a sound rule is:\n$$E.val_{must} = E_1.val_{must} \\lor T.val_{must}$$\nThis rule, like the one for $val_{may}$, is static and relies only on synthesized attributes of children, preserving the S-attributed nature of the grammar.\n\n**Parse Tree and Input Evaluation**\n\nThe input $\\text{id}\\ \\text{or}\\ \\text{false}\\ \\text{or}\\ \\text{true}$ is parsed as $((\\text{id}\\ \\text{or}\\ \\text{false})\\ \\text{or}\\ \\text{true})$. Let's build the parse tree and evaluate attributes bottom-up.\n\n- Root production: $E_{root} \\to E_{mid}\\ \\text{or}\\ T_3$\n- Intermediate production: $E_{mid} \\to E_{low}\\ \\text{or}\\ T_2$ (due to $E \\to E\\ \\text{or}\\ T$ being the recursive rule)\n- Base productions: $E_{low} \\to T_1$, $T_1 \\to \\text{id}$, $T_2 \\to \\text{false}$, $T_3 \\to \\text{true}$.\n\nBase attribute values:\n- $T_1 (\\text{id}): T_1.val_{may} = \\text{true}, T_1.val_{must} = \\text{false}$.\n- $T_2 (\\text{false}): T_2.val_{may} = \\text{false}, T_2.val_{must} = \\text{false}$.\n- $T_3 (\\text{true}): T_3.val_{may} = \\text{true}, T_3.val_{must} = \\text{true}$.\n\nFor the production $E \\to T$, the rules are simply $E.val_{may} = T.val_{may}$ and $E.val_{must} = T.val_{must}$.\n- Evaluation for $E_{low}$: $E_{low}.val_{may} = T_1.val_{may} = \\text{true}$, $E_{low}.val_{must} = T_1.val_{must} = \\text{false}$.\n\nNow we evaluate each option's rules on this structure.\n\n### Option-by-Option Analysis\n\n**A. Use $E.val_{may} = E_1.val_{may} \\lor T.val_{may}$ and $E.val_{must} = E_1.val_{must} \\lor T.val_{must}$.**\n\n- **Rule Soundness**: As derived above, these rules are sound over- and under-approximations that respect the constraints of synthesized attributes.\n- **ADG**: The dependencies are from attributes of children ($E_1, T$) to the parent ($E$). This is the definition of a synthesized attribute scheme (S-attributed grammar), which always yields an acyclic ADG.\n- **Input Trace**:\n    1.  **$E_{mid} \\to E_{low}\\ \\text{or}\\ T_2$** (for `id or false`):\n        - $E_{mid}.val_{may} = E_{low}.val_{may} \\lor T_2.val_{may} = \\text{true} \\lor \\text{false} = \\text{true}$.\n        - $E_{mid}.val_{must} = E_{low}.val_{must} \\lor T_2.val_{must} = \\text{false} \\lor \\text{false} = \\text{false}$.\n        This is a correct static assessment: `id or false` may be true (if `id` is true) but does not have to be true.\n    2.  **$E_{root} \\to E_{mid}\\ \\text{or}\\ T_3$** (for `(id or false) or true`):\n        - $E_{root}.val_{may} = E_{mid}.val_{may} \\lor T_3.val_{may} = \\text{true} \\lor \\text{true} = \\text{true}$.\n        - $E_{root}.val_{must} = E_{mid}.val_{must} \\lor T_3.val_{must} = \\text{false} \\lor \\text{true} = \\text{true}$.\n- **Conclusion**: The final values at the root are $E_{root}.val_{may}=\\text{true}$ and $E_{root}.val_{must}=\\text{true}$. This is correct, as the expression `... or true` must always evaluate to `true`. All claims in this option (rules, ADG nature, and final values) are correct.\n\n**Verdict: Correct.**\n\n**B. Use $E.val_{may} = E_1.val_{may} \\lor T.val_{may}$ and $E.val_{must} = E_1.val_{must} \\land T.val_{must}$.**\n\n- **Rule Soundness**: The rule for $E.val_{must}$ is unsound. It states that $E_1\\ \\text{or}\\ T$ must be true only if both $E_1$ must be true AND $T$ must be true. This is incorrect. Consider the expression $\\text{true}\\ \\text{or}\\ \\text{false}$. It must evaluate to $\\text{true}$. Here, $E_1.val_{must}=\\text{true}$ and $T.val_{must}=\\text{false}$. The rule yields $E.val_{must} = \\text{true} \\land \\text{false} = \\text{false}$, which is an incorrect under-approximation.\n- **Input Trace**:\n    1.  **$E_{mid}$**: $E_{mid}.val_{must} = E_{low}.val_{must} \\land T_2.val_{must} = \\text{false} \\land \\text{false} = \\text{false}$.\n    2.  **$E_{root}$**: $E_{root}.val_{must} = E_{mid}.val_{must} \\land T_3.val_{must} = \\text{false} \\land \\text{true} = \\text{false}$.\n- **Conclusion**: This option yields a root value of $E.val_{must}=\\text{false}$ for an expression that must be `true`. The rule is unsound and the result is incorrect.\n\n**Verdict: Incorrect.**\n\n**C. Use $E.val_{may} = E_1.val_{may}$ and $E.val_{must} = E_1.val_{must}$.**\n\n- **Rule Soundness**: These rules completely ignore the right-hand operand $T$. This is fundamentally unsound. For the expression $\\text{false}\\ \\text{or}\\ \\text{true}$, which must be $\\text{true}$, these rules would propagate the attributes of $\\text{false}$ ($val_{may}=\\text{false}, val_{must}=\\text{false}$) and incorrectly conclude the expression must be $\\text{false}$.\n- **Input Trace**:\n    1.  **$E_{mid}$**: $E_{mid}.val_{must} = E_{low}.val_{must} = \\text{false}$.\n    2.  **$E_{root}$**: $E_{root}.val_{must} = E_{mid}.val_{must} = \\text{false}$.\n- **Conclusion**: Similar to option B, this yields a root value of $E.val_{must}=\\text{false}$ for an expression that must be `true`. The rules are unsound.\n\n**Verdict: Incorrect.**\n\n**D. Introduce a synthesized guard $T.need = \\lnot E_1.val_{may}$ ...**\n\n- **Rule Soundness and ADG Structure**: This option proposes that an attribute of the child node $T$ (namely, $T.need$) depends on an attribute of its sibling node $E_1$ (namely, $E_1.val_{may}$). This violates the definition of a synthesized attribute, which can only depend on attributes of its own children (or be a constant). This dependency structure belongs to an L-attributed grammar, not a purely synthesized one as stipulated. This is a critical formal error.\n- **Analysis of Equations**: Even ignoring the structural error, let's analyze the equations.\n  - $E.val_{may} = E_1.val_{may} \\lor (T.need \\land T.val_{may}) = E_1.val_{may} \\lor ((\\lnot E_1.val_{may}) \\land T.val_{may})$. A property of boolean algebra is $A \\lor (\\lnot A \\land B) = A \\lor B$. So this equation is simply an obfuscated version of $E.val_{may} = E_1.val_{may} \\lor T.val_{may}$, the same as in Option A.\n  - $E.val_{must} = E_1.val_{must} \\lor (T.need \\land T.val_{must}) = E_1.val_{must} \\lor ((\\lnot E_1.val_{may}) \\land T.val_{must})$. This rule is intended to be more precise by modeling the short-circuit condition. The term $\\lnot E_1.val_{may}$ means \"$E_1$ must be false\". The rule thus states: \"$E$ must be true if ($E_1$ must be true) or (($E_1$ must be false) and ($T$ must be true))\". This is a sound, and more precise, formulation of the condition for $val_{must}$.\n- **Input Trace**:\n    1.  **$E_{mid}$**: Here, $E_1$ is $E_{low}$ and $T$ is $T_2$.\n        - $E_{mid}.val_{must} = E_{low}.val_{must} \\lor ((\\lnot E_{low}.val_{may}) \\land T_2.val_{must}) = \\text{false} \\lor ((\\lnot \\text{true}) \\land \\text{false}) = \\text{false} \\lor (\\text{false} \\land \\text{false}) = \\text{false}$.\n    2.  **$E_{root}$**: Here, $E_1$ is $E_{mid}$ and $T$ is $T_3$.\n        - $E_{root}.val_{must} = E_{mid}.val_{must} \\lor ((\\lnot E_{mid}.val_{may}) \\land T_3.val_{must}) = \\text{false} \\lor ((\\lnot \\text{true}) \\land \\text{true}) = \\text{false} \\lor (\\text{false} \\land \\text{true}) = \\text{false}$.\n- **Conclusion**: The calculation yields $E_{root}.val_{must} = \\text{false}$. This contradicts the option's claim that the result is $E_{root}.val_{must}=\\text{true}$. Furthermore, the result itself is incorrect, as the expression must be true. The sophisticated rule fails because the antecedent approximations ($E_{mid}.val_{may}=\\text{true}$) are not precise enough for it to work. Due to the possibility that $E_{mid}$ is true, it conservatively refuses to consider the contribution from $T_3$, even though that contribution is what guarantees the final result. The option is incorrect due to (1) a fundamental error in attribute definition, (2) an incorrect claim about the resulting value, and (3) an actual computed result that is also incorrect.\n\n**Verdict: Incorrect.**\n\nFinal conclusion points to Option A as the only one that presents sound rules within the specified constraints and correctly evaluates the given example.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}