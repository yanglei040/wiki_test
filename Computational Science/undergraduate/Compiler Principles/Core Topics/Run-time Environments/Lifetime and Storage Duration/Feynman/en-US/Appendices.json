{
    "hands_on_practices": [
        {
            "introduction": "Understanding how a compiler allocates a finite number of registers to a potentially large number of variables is fundamental to optimization. This first exercise transforms this abstract problem into a concrete geometric one. By modeling variable lifetimes as intervals on a timeline, you will see how resource competition can be analyzed as a classic interval graph coloring problem, where the goal is to find the minimum number of resources needed to avoid conflicts. This practice builds intuition for resource management by connecting it to a visual and well-understood mathematical framework .",
            "id": "3649943",
            "problem": "A compiler for a simple imperative language performs allocation of storage locations (for example, physical registers) by reasoning about variable lifetimes along a linearized sequence of program points. A variable’s live range is the contiguous set of program points from its first definition to its last use, inclusive of the start point and exclusive of the end point, which can be modeled as a half-open interval on a one-dimensional timeline. This modeling is analogous to project management Gantt charts, where tasks occupy time intervals and resource conflicts occur when multiple tasks are active at the same time.\n\nConsider a straight-line fragment of code whose program points are totally ordered and treated as discrete indices on a timeline. The set of variables $\\{x_1, x_2, \\dots, x_{12}\\}$ has live ranges specified by the following half-open intervals $\\left[s,e\\right)$, where $s$ and $e$ are integer program points and a variable is considered live at any program point $t$ satisfying $s \\le t  e$:\n\n- $x_1: [0, 7)$\n- $x_2: [3, 12)$\n- $x_3: [5, 10)$\n- $x_4: [9, 15)$\n- $x_5: [11, 17)$\n- $x_6: [13, 20)$\n- $x_7: [14, 18)$\n- $x_8: [16, 22)$\n- $x_9: [1, 4)$\n- $x_{10}: [8, 9)$\n- $x_{11}: [2, 6)$\n- $x_{12}: [19, 24)$\n\nYou will reason from first principles: define variable live ranges, the interference graph induced by overlaps of live ranges, and the equivalence between interval graphs and these interference graphs for straight-line code. Using these foundations and well-tested facts about interval graphs and graph coloring, derive why minimizing resource conflicts can be reduced to an interval coloring problem whose minimum number of colors equals the maximum number of simultaneously overlapping intervals.\n\nFinally, compute the quantity $P$, defined as the maximum number of variables that are simultaneously live at any program point across the given set of intervals. Express your final answer as a single integer with no units and do not round.",
            "solution": "The problem statement is scientifically grounded, well-posed, objective, and self-contained. It describes a classic problem in compiler optimization—register allocation for straight-line code—and correctly maps it to the problem of coloring an interval graph. The givens are complete and consistent. Therefore, the problem is valid, and I will proceed with a full solution.\n\nThe problem requires a derivation from first principles followed by a computation.\n\nFirst, we establish the theoretical foundation.\n1.  A variable's **live range** is the set of program points where the variable holds a value that may be used in the future. For a straight-line code sequence, program points can be indexed by a single dimension (time). The live range of a variable $x_i$ is given as a half-open interval $[s_i, e_i)$, meaning $x_i$ is live at any program point $t$ such that $s_i \\le t  e_i$.\n\n2.  Two variables $x_i$ and $x_j$ are said to **interfere** if their live ranges overlap. This means there is at least one program point where both variables are simultaneously live. If they interfere, they cannot be stored in the same physical storage location (e.g., a register), as one would overwrite the value of the other. Mathematically, $x_i$ and $x_j$ interfere if their live range intervals have a non-empty intersection: $[s_i, e_i) \\cap [s_j, e_j) \\neq \\emptyset$.\n\n3.  The **interference graph** $G = (V, E)$ is constructed to represent these conflicts. The set of vertices $V$ is the set of program variables $\\{x_1, x_2, \\dots, x_{12}\\}$. An undirected edge $(x_i, x_j)$ is included in the set of edges $E$ if and only if variables $x_i$ and $x_j$ interfere. Because the vertices of this graph correspond to intervals on a line, and edges represent interval intersections, this specific type of graph is known as an **interval graph**.\n\n4.  The problem of minimizing the number of storage locations required is equivalent to the **graph coloring problem** on the interference graph $G$. A valid coloring of $G$ assigns a \"color\" (representing a unique storage location) to each vertex such that no two adjacent vertices share the same color. The minimum number of colors required for a valid coloring is the **chromatic number** of the graph, denoted $\\chi(G)$.\n\n5.  For a general graph, computing $\\chi(G)$ is an NP-hard problem. However, interval graphs belong to a special class of graphs known as **perfect graphs**. A fundamental property of any graph is that its chromatic number must be at least as large as the size of its largest clique, a quantity known as the **clique number**, $\\omega(G)$. A clique is a subset of vertices in which every two distinct vertices are adjacent. Thus, $\\chi(G) \\ge \\omega(G)$. For perfect graphs, this inequality becomes an equality: $\\chi(G) = \\omega(G)$.\n\n6.  In our interference graph, a clique corresponds to a set of variables whose live ranges all mutually overlap. The size of the largest clique, $\\omega(G)$, is therefore the maximum number of variables that are simultaneously live at any single program point. The problem defines this quantity as $P$.\nTherefore, the minimum number of storage locations required is $\\chi(G) = \\omega(G) = P$. This formally justifies why minimizing resource conflicts reduces to finding the maximum number of simultaneously overlapping intervals.\n\nNow, we compute the value of $P$ for the given set of $12$ variable live ranges.\nThe live ranges are:\n- $x_1: [0, 7)$\n- $x_2: [3, 12)$\n- $x_3: [5, 10)$\n- $x_4: [9, 15)$\n- $x_5: [11, 17)$\n- $x_6: [13, 20)$\n- $x_7: [14, 18)$\n- $x_8: [16, 22)$\n- $x_9: [1, 4)$\n- $x_{10}: [8, 9)$\n- $x_{11}: [2, 6)$\n- $x_{12}: [19, 24)$\n\nTo find the maximum number of simultaneously live variables, $P$, we can use a sweep-line approach. We examine the number of active intervals at various program points. The number of live variables can only change at the start or end points of the intervals. We can therefore analyze the intervals of time between consecutive event points (start or end of any live range).\n\n- For $t \\in [0, 1)$: $x_1$ is live. Count = $1$.\n- For $t \\in [1, 2)$: $x_1, x_9$ are live. Count = $2$.\n- For $t \\in [2, 3)$: $x_1, x_9, x_{11}$ are live. Count = $3$.\n- For $t \\in [3, 4)$: $x_1, x_2, x_9, x_{11}$ are live. Count = $4$.\n- For $t \\in [4, 5)$: $x_1, x_2, x_{11}$ are live. ($x_9$ is no longer live). Count = $3$.\n- For $t \\in [5, 6)$: $x_1, x_2, x_3, x_{11}$ are live. Count = $4$.\n- For $t \\in [6, 7)$: $x_1, x_2, x_3$ are live. ($x_{11}$ is no longer live). Count = $3$.\n- For $t \\in [7, 8)$: $x_2, x_3$ are live. ($x_1$ is no longer live). Count = $2$.\n- For $t \\in [8, 9)$: $x_2, x_3, x_{10}$ are live. Count = $3$.\n- For $t \\in [9, 10)$: $x_2, x_3, x_4$ are live. ($x_{10}$ is no longer live). Count = $3$.\n- For $t \\in [10, 11)$: $x_2, x_4$ are live. ($x_3$ is no longer live). Count = $2$.\n- For $t \\in [11, 12)$: $x_2, x_4, x_5$ are live. Count = $3$.\n- For $t \\in [12, 13)$: $x_4, x_5$ are live. ($x_2$ is no longer live). Count = $2$.\n- For $t \\in [13, 14)$: $x_4, x_5, x_6$ are live. Count = $3$.\n- For $t \\in [14, 15)$: $x_4, x_5, x_6, x_7$ are live. Count = $4$.\n- For $t \\in [15, 16)$: $x_5, x_6, x_7$ are live. ($x_4$ is no longer live). Count = $3$.\n- For $t \\in [16, 17)$: $x_5, x_6, x_7, x_8$ are live. Count = $4$.\n- For $t \\in [17, 18)$: $x_6, x_7, x_8$ are live. ($x_5$ is no longer live). Count = $3$.\n- For $t \\in [18, 19)$: $x_6, x_8$ are live. ($x_7$ is no longer live). Count = $2$.\n- For $t \\in [19, 20)$: $x_6, x_8, x_{12}$ are live. Count = $3$.\n- For $t \\in [20, 22)$: $x_8, x_{12}$ are live. ($x_6$ is no longer live). Count = $2$.\n- For $t \\in [22, 24)$: $x_{12}$ is live. ($x_8$ is no longer live). Count = $1$.\n\nBy inspecting the counts for each interval, the maximum value observed is $4$. This occurs in multiple time intervals, for example, during $[3, 4)$, $[5, 6)$, $[14, 15)$, and $[16, 17)$.\nThus, the maximum number of variables that are simultaneously live at any program point, $P$, is $4$. This implies that a minimum of $4$ storage locations are required to allocate these variables without conflict.\nThe quantity $P$ is the maximum of these counts.\n\n$P = \\max\\{1, 2, 3, 4, 3, 4, 3, 2, 3, 3, 2, 3, 2, 3, 4, 3, 4, 3, 2, 3, 2, 1\\} = 4$.",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "Building on the concept of overlapping lifetimes, this next practice moves from allocating uniform resources like registers to managing variable-sized allocations on the stack. The challenge is no longer just to count the maximum number of simultaneous live variables, but to calculate the peak total memory size required at any point in time. This exercise  demonstrates a more nuanced application of lifetime analysis, requiring a sweep-line approach to determine the minimal stack frame size, a crucial factor in a program's memory footprint.",
            "id": "3649968",
            "problem": "A compiler backend must assign stack-frame offsets to local variables so that different variables with overlapping lifetimes do not overlap in memory. Consider a single function whose local variables have lifetimes modeled as half-open time intervals on an abstract instruction-time axis, and whose sizes are given in bytes. A variable’s lifetime is the interval from its first definition to its last use, and its storage duration is the period during which the stack slot must be reserved for that variable. Two variables whose lifetimes overlap in time cannot occupy the same stack byte; variables with disjoint lifetimes may reuse the same stack bytes. Each variable must be assigned a fixed contiguous segment of the stack during its lifetime.\n\nYou are given the following set of local variables, each with a size and a lifetime interval $[a_i,b_i)$ on the time axis, where $a_i$ and $b_i$ are integers with $a_i lt; b_i$:\n- Variable $v_1$: size $14$ bytes, lifetime $[1,7)$.\n- Variable $v_2$: size $20$ bytes, lifetime $[3,11)$.\n- Variable $v_3$: size $18$ bytes, lifetime $[0,4)$.\n- Variable $v_4$: size $12$ bytes, lifetime $[6,9)$.\n- Variable $v_5$: size $10$ bytes, lifetime $[8,12)$.\n- Variable $v_6$: size $26$ bytes, lifetime $[2,5)$.\n\nAssume the stack grows “upward” from offset $0$, and the “height” $H$ of the allocation is the minimal maximum offset reached by any assigned byte across all time, measured from $0$ (so that the allocated region is $[0,H)$). Starting only from the core definitions of lifetime, storage duration, and the requirement that overlapping lifetimes must not overlap in memory, derive the provably minimal stack height $H$ required to allocate fixed offsets for all variables over their lifetimes. Express your final result as a single integer number of bytes. No rounding is required. Express the final answer in bytes.",
            "solution": "The problem requires finding the minimal total size of the stack frame needed to accommodate a set of local variables. The fundamental constraint is that any two variables whose lifetimes overlap must be allocated to non-overlapping memory regions. Since each variable is assigned a fixed offset for its entire lifetime, this implies that at any given point in abstract time $t$, all variables that are \"live\" (i.e., $t$ is within their lifetime interval) must simultaneously reside in memory.\n\nThe total amount of memory required at a specific time $t$ is the sum of the sizes of all variables live at that time. Let $s_i$ be the size of variable $v_i$ and $L_i = [a_i, b_i)$ be its lifetime. The set of variables live at time $t$ is $V(t) = \\{ v_i \\mid t \\in L_i \\}$. The total size of memory concurrently in use at time $t$ is given by the function $S(t)$:\n$$S(t) = \\sum_{v_i \\in V(t)} s_i$$\nSince the stack allocation must be sufficient for the memory requirements at *all* points in time, the total height of the stack, $H$, must be at least as large as the maximum memory requirement observed over the entire execution. An allocation of size $\\max_t S(t)$ is also sufficient, as we can always pack the live variables at any time $t$ into a contiguous block of size $S(t)$, which is less than or equal to the maximum. Therefore, the provably minimal stack height $H$ is precisely this maximum:\n$$H = \\max_{t \\ge 0} S(t)$$\nThe function $S(t)$ is a step function. Its value remains constant over intervals and only changes at the start-points ($a_i$) and end-points ($b_i$) of the variable lifetimes. These are the event points. To find the maximum of $S(t)$, we only need to evaluate it over the elementary intervals defined by these sorted event points.\n\nThe given variables are:\n- $v_1$: $s_1 = 14$, $L_1 = [1, 7)$\n- $v_2$: $s_2 = 20$, $L_2 = [3, 11)$\n- $v_3$: $s_3 = 18$, $L_3 = [0, 4)$\n- $v_4$: $s_4 = 12$, $L_4 = [6, 9)$\n- $v_5$: $s_5 = 10$, $L_5 = [8, 12)$\n- $v_6$: $s_6 = 26$, $L_6 = [2, 5)$\n\nThe distinct event points, in increasing order, are $0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12$. We now calculate the total size $S(t)$ of live variables for each interval defined by these points.\n\n1.  Interval $[0, 1)$:\n    - Live variables: $\\{v_3\\}$\n    - $S(t) = s_3 = 18$\n\n2.  Interval $[1, 2)$:\n    - Live variables: $\\{v_1, v_3\\}$\n    - $S(t) = s_1 + s_3 = 14 + 18 = 32$\n\n3.  Interval $[2, 3)$:\n    - Live variables: $\\{v_1, v_3, v_6\\}$\n    - $S(t) = s_1 + s_3 + s_6 = 14 + 18 + 26 = 58$\n\n4.  Interval $[3, 4)$:\n    - Live variables: $\\{v_1, v_2, v_3, v_6\\}$\n    - $S(t) = s_1 + s_2 + s_3 + s_6 = 14 + 20 + 18 + 26 = 78$\n\n5.  Interval $[4, 5)$:\n    - Live variables: $\\{v_1, v_2, v_6\\}$ (variable $v_3$ is no longer live as $t \\ge 4$)\n    - $S(t) = s_1 + s_2 + s_6 = 14 + 20 + 26 = 60$\n\n6.  Interval $[5, 6)$:\n    - Live variables: $\\{v_1, v_2\\}$ (variable $v_6$ is no longer live as $t \\ge 5$)\n    - $S(t) = s_1 + s_2 = 14 + 20 = 34$\n\n7.  Interval $[6, 7)$:\n    - Live variables: $\\{v_1, v_2, v_4\\}$\n    - $S(t) = s_1 + s_2 + s_4 = 14 + 20 + 12 = 46$\n\n8.  Interval $[7, 8)$:\n    - Live variables: $\\{v_2, v_4\\}$ (variable $v_1$ is no longer live as $t \\ge 7$)\n    - $S(t) = s_2 + s_4 = 20 + 12 = 32$\n\n9.  Interval $[8, 9)$:\n    - Live variables: $\\{v_2, v_4, v_5\\}$\n    - $S(t) = s_2 + s_4 + s_5 = 20 + 12 + 10 = 42$\n\n10. Interval $[9, 11)$:\n    - Live variables: $\\{v_2, v_5\\}$ (variable $v_4$ is no longer live as $t \\ge 9$)\n    - $S(t) = s_2 + s_5 = 20 + 10 = 30$\n\n11. Interval $[11, 12)$:\n    - Live variables: $\\{v_5\\}$ (variable $v_2$ is no longer live as $t \\ge 11$)\n    - $S(t) = s_5 = 10$\n\nFor $t \\ge 12$, no variables are live, so $S(t) = 0$.\n\nWe now find the maximum among all calculated values of $S(t)$:\n$$H = \\max\\{18, 32, 58, 78, 60, 34, 46, 32, 42, 30, 10\\}$$\nThe maximum value is $78$, which occurs during the time interval $[3, 4)$. During this interval, variables $v_1$, $v_2$, $v_3$, and $v_6$ are all simultaneously live, and their combined size dictates the peak memory requirement.\n\nThus, the provably minimal stack height required is $78$ bytes.",
            "answer": "$$\\boxed{78}$$"
        },
        {
            "introduction": "Real-world programs rarely follow a single, straight path. This final practice confronts the complexity of managing resource lifetimes in the presence of exceptions, early returns, and other forms of non-linear control flow. You are tasked with identifying a correct and robust dataflow analysis strategy that guarantees resource safety—preventing leaks and use-after-free errors—across all possible execution paths. This problem  highlights the critical importance of modeling a program's complete Control-Flow Graph, including exceptional edges, to build a truly correct and reliable compiler.",
            "id": "3650032",
            "problem": "A compiler backend must insert deallocation for a temporary buffer in the presence of exceptions. Consider the following pseudo-code with explicit allocation and no automatic destructors:\n\n- Input: an integer $n$ and a boolean $cond$.\n- Behavior:\n  - Allocate a temporary buffer $buf \\leftarrow \\text{alloc}(n)$.\n  - Enter a try block and call two functions $g(buf)$ and $h(buf)$, each of which may throw an exception of type $E$.\n  - If $cond$ holds between the two calls, return $0$ early from the function.\n  - If an exception $E$ is thrown by either call, transfer control to a catch handler that logs and returns $-1$.\n  - If the try block completes normally, return $1$.\n\nIn words: allocate $buf$, then\n- try:\n  - call $g(buf)$,\n  - if $cond$ then return $0$,\n  - call $h(buf)$,\n- catch $E$:\n  - log and return $-1$,\n- otherwise return $1$.\n\nAssume a Control-Flow Graph (CFG) is modeled as a directed graph $(V, E)$ with nodes for basic blocks and edges for possible control flow transfers. The CFG includes two disjoint edge sets: normal edges $E_{\\text{norm}}$ and exceptional edges $E_{\\text{exc}}$, where an exceptional edge $(u, v) \\in E_{\\text{exc}}$ models the transfer of control from a potentially throwing operation in node $u$ to its exception handler node $v$. A value is live at a program point if along some path from that point to a use there is no intervening deallocation or redefinition that blocks the use. The compiler’s current pass computes liveness and places a single deallocation after the try-catch region, but it ignores $E_{\\text{exc}}$ and only analyzes $E_{\\text{norm}}$.\n\nThis pass is observed to extend the lifetime of $buf$ incorrectly and to miss deallocation on exceptional and early-return paths. Your task is to select a dataflow formulation and a placement rule that:\n- treats the CFG with $E = E_{\\text{norm}} \\cup E_{\\text{exc}}$ as the underlying flow graph,\n- ensures safety (no use-after-free) and promptness (deallocate at the earliest safe point) of $buf$,\n- inserts deallocation along all paths, including those traversing $E_{\\text{exc}}$.\n\nWhich option achieves this goal?\n\nA. Perform a backward liveness analysis over the CFG restricted to $E_{\\text{norm}}$ only. Place a single deallocation at the post-dominator of the last use within normal control flow (e.g., just after the try-catch). This ensures deallocation is reached if no exception occurs and avoids double frees by construction.\n\nB. Perform a forward dataflow that computes, for each node, whether normal termination is guaranteed (treating any outgoing edge in $E_{\\text{exc}}$ as an immediate exit that makes the value dead). Then place deallocation only on the normal fall-through path before returns, because exceptional paths are assumed to unwind without needing explicit deallocation.\n\nC. Augment the CFG with $E_{\\text{exc}}$ and perform a standard backward liveness analysis for the temporary $buf$ over $E = E_{\\text{norm}} \\cup E_{\\text{exc}}$, using the union of successors (normal and exceptional). Insert deallocation on every boundary edge $(u \\rightarrow v)$ such that $buf$ is live out of $u$ but not live in at $v$. If needed, split critical edges to legalize insertion. This places deallocation along all normal and exceptional exits at the earliest safe points while preserving safety.\n\nD. Compute the nearest common post-dominator of all syntactic uses of $buf$ ignoring exceptions, and also emit a deallocation at the start of the catch handler. This guarantees at least one deallocation on both the normal and exceptional paths while avoiding complexity from dataflow on $E_{\\text{exc}}$.",
            "solution": "The core of the problem is to ensure that the resource $buf$ is deallocated exactly once on every possible path from its allocation to the function's exit. The paths are:\n1.  **Normal path:** `alloc` $\\rightarrow$ $g(buf)$ $\\rightarrow$ `!cond` $\\rightarrow$ $h(buf)$ $\\rightarrow$ `return 1`.\n2.  **Early-return path:** `alloc` $\\rightarrow$ $g(buf)$ $\\rightarrow$ `cond` $\\rightarrow$ `return 0`.\n3.  **Exceptional path 1:** `alloc` $\\rightarrow$ $g(buf)$ throws $\\rightarrow$ `catch E` $\\rightarrow$ `return -1`.\n4.  **Exceptional path 2:** `alloc` $\\rightarrow$ $g(buf)$ $\\rightarrow$ `!cond` $\\rightarrow$ $h(buf)$ throws $\\rightarrow$ `catch E` $\\rightarrow$ `return -1`.\n\nA correct solution must place `dealloc(buf)` on all four of these paths. It must be **safe**, meaning `dealloc(buf)` is never placed before the last use of $buf$ on any path. It must be **prompt**, meaning `dealloc(buf)` is placed as soon as $buf$ is no longer needed.\n\nThe standard and correct technique for this is based on **liveness analysis**. A variable is live at a point if its value might be used in the future. A variable is dead otherwise. The earliest safe point to deallocate a variable is immediately after it transitions from being live to dead.\n\nA backward liveness analysis computes, for each basic block $u$, the set of variables that are live upon entry (`LiveIn(u)`) and exit (`LiveOut(u)`). The dataflow equations are:\n$$\n\\text{LiveOut}(u) = \\bigcup_{s \\in \\text{succ}(u)} \\text{LiveIn}(s)\n$$\n$$\n\\text{LiveIn}(u) = \\text{Use}(u) \\cup (\\text{LiveOut}(u) - \\text{Def}(u))\n$$\nTo correctly handle all control flow paths, the set of successors, $\\text{succ}(u)$, must include both normal and exceptional successors. That is, the analysis must run on the CFG with the full edge set $E = E_{\\text{norm}} \\cup E_{\\text{exc}}$.\n\nThe optimal points for deallocation are on the control flow edges $(u, v)$ where the variable becomes dead. That is, for $buf$, we insert `dealloc(buf)` on an edge $(u, v)$ if $buf \\in \\text{LiveOut}(u)$ but $buf \\notin \\text{LiveIn}(v)$. This is the **liveness boundary**. If such an edge $(u, v)$ is a **critical edge** (i.e., $u$ has other successors or $v$ has other predecessors), the edge must be split by inserting a new empty block to create a dedicated place for the deallocation code.\n\nNow I will evaluate each option based on this framework.\n\n---\n\n**A. Perform a backward liveness analysis over the CFG restricted to $E_{\\text{norm}}$ only. Place a single deallocation at the post-dominator of the last use within normal control flow (e.g., just after the try-catch). This ensures deallocation is reached if no exception occurs and avoids double frees by construction.**\n\nThis option is **Incorrect**. Its primary flaw is that it explicitly restricts the analysis to $E_{\\text{norm}}$, thereby ignoring exceptional paths. This is the same error as the faulty compiler pass described in the problem. As a result, it will not place any deallocation on paths that traverse $E_{\\text{exc}}$, leading to memory leaks when exceptions are thrown. Furthermore, placing a single deallocation at a post-dominator fails to handle the early-return path (`if cond then return 0`), which bypasses the later parts of the normal control flow and thus may not pass through the chosen post-dominator block. This approach is neither complete nor prompt.\n\n---\n\n**B. Perform a forward dataflow that computes, for each node, whether normal termination is guaranteed (treating any outgoing edge in $E_{\\text{exc}}$ as an immediate exit that makes the value dead). Then place deallocation only on the normal fall-through path before returns, because exceptional paths are assumed to unwind without needing explicit deallocation.**\n\nThis option is **Incorrect**. It is based on a critically flawed premise: \"exceptional paths are assumed to unwind without needing explicit deallocation.\" The problem statement specifies \"explicit allocation and no automatic destructors,\" which is characteristic of languages like C or manual memory management in C++. In such a context, unhandled resources on an exceptional path cause leaks. This assumption directly contradicts the requirements of the problem. Additionally, by placing deallocation \"only on the normal fall-through path,\" it explicitly fails to deallocate on the early-return path and, by its flawed assumption, on the exceptional paths.\n\n---\n\n**C. Augment the CFG with $E_{\\text{exc}}$ and perform a standard backward liveness analysis for the temporary $buf$ over $E = E_{\\text{norm}} \\cup E_{\\text{exc}}$, using the union of successors (normal and exceptional). Insert deallocation on every boundary edge $(u \\rightarrow v)$ such that $buf$ is live out of $u$ but not live in at $v$. If needed, split critical edges to legalize insertion. This places deallocation along all normal and exceptional exits at the earliest safe points while preserving safety.**\n\nThis option is **Correct**. It perfectly describes the theoretically sound and practically complete solution derived above.\n- **Completeness:** By performing the analysis on the full CFG including $E_{\\text{exc}}$, it considers all possible control flow paths.\n- **Safety and Promptness:** The placement rule—inserting deallocation on the liveness boundary where $buf$ transitions from live to dead—is the definition of placing a deallocation at the earliest possible safe point. This ensures no use-after-free (safety) and no unnecessary lifetime extension (promptness).\n- **Practicality:** It correctly mentions the need to split critical edges, which is a necessary step for inserting code on CFG edges in a real compiler.\nThis approach correctly handles all four paths: normal, early-return, and both exceptional paths.\n\n---\n\n**D. Compute the nearest common post-dominator of all syntactic uses of $buf$ ignoring exceptions, and also emit a deallocation at the start of the catch handler. This guarantees at least one deallocation on both the normal and exceptional paths while avoiding complexity from dataflow on $E_{\\text{exc}}$.**\n\nThis option is **Incorrect**. This is an ad-hoc, heuristic approach that is incomplete. The syntactic uses of $buf$ are in $g(buf)$ and $h(buf)$. The control flow graph, ignoring exceptions, has a branch for the early return. The nearest common post-dominator of the blocks containing `g(buf)` and `h(buf)` would likely be the final `return 1` block or the function's exit block. A deallocation placed here would be completely missed by the early-return path (`if cond then return 0`). Therefore, this method leaks memory on the early-return path. While it attempts to patch the exception path by adding a deallocation in the `catch` handler, it fails to provide a comprehensive solution for all paths. It also fails the promptness requirement, as deallocations at a post-dominator or at the start of a handler are generally not at the earliest possible point.",
            "answer": "$$\\boxed{C}$$"
        }
    ]
}