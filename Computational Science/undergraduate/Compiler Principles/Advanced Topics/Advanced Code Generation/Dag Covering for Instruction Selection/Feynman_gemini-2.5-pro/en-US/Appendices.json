{
    "hands_on_practices": [
        {
            "introduction": "This first exercise lays the groundwork for optimal instruction selection by challenging you to find the most efficient way to cover a simple Directed Acyclic Graph (DAG). The key is to analyze the available instruction patterns, including complex ones like a fused multiply-add, and determine the combination that minimizes total cost . This practice hones the fundamental skill of mapping abstract operations to machine instructions in a cost-effective manner.",
            "id": "3634952",
            "problem": "A compiler back end performs instruction selection by covering an Intermediate Representation (IR) Directed Acyclic Graph (DAG) with instruction patterns so that each IR operation node is implemented by exactly one target instruction and the total cost is minimized. Consider the IR DAG for the arithmetic expression $$((a+b)\\times(c+d))+(a+b),$$ where the subexpression $$a+b$$ is explicitly shared. Let the DAG nodes be labeled as follows: $$n_{1}=\\mathrm{add}(a,b),\\quad n_{2}=\\mathrm{add}(c,d),\\quad n_{3}=\\mathrm{mul}(n_{1},n_{2}),\\quad n_{4}=\\mathrm{add}(n_{3},n_{1}).$$ All leaves $$a,b,c,d$$ are values already available in registers at zero cost.\n\nThe target machine supports the following instruction patterns (tree patterns), with costs in abstract units:\n- $$p_{\\mathrm{add}}:\\ \\mathrm{add}(x,y)\\ \\text{with cost}\\ 1.$$\n- $$p_{\\mathrm{mul}}:\\ \\mathrm{mul}(x,y)\\ \\text{with cost}\\ 2.$$\n- $$p_{\\mathrm{fma}}:\\ \\mathrm{add}(\\mathrm{mul}(x,y),z)\\ \\text{with cost}\\ 2.$$\n\nHere $$\\mathrm{add}$$ and $$\\mathrm{mul}$$ are commutative operators, and the fused multiply-add (FMA) instruction $$p_{\\mathrm{fma}}$$ may match either $$\\mathrm{add}(\\mathrm{mul}(x,y),z)$$ or $$\\mathrm{add}(z,\\mathrm{mul}(x,y))$$ due to commutativity. A pattern matches a node if the node’s operator and the shape of its subtree coincide with the pattern; when $$p_{\\mathrm{fma}}$$ is chosen at a node, it covers both that $$\\mathrm{add}$$ node and its $$\\mathrm{mul}$$ child in a single instruction. Each internal IR node must be covered exactly once by some chosen pattern, and leaves $$a,b,c,d$$ incur no cost. The total cost is the sum of the costs of the chosen patterns.\n\nUsing only the definitions of a Directed Acyclic Graph (DAG), pattern matching, and additive cost models for instruction selection, determine the minimum possible total cost to cover the DAG of the given expression. Report the minimum total cost as a single integer. No rounding is needed; provide an exact integer.",
            "solution": "The user wants me to solve the problem. I will first validate the problem statement.\n\n### Step 1: Extract Givens\n- **Intermediate Representation (IR) DAG:** The problem describes a Directed Acyclic Graph (DAG) for the expression `((a+b) * (c+d)) + (a+b)`.\n- **DAG Nodes:**\n  - $n_{1} = \\mathrm{add}(a,b)$\n  - $n_{2} = \\mathrm{add}(c,d)$\n  - $n_{3} = \\mathrm{mul}(n_{1},n_{2})$\n  - $n_{4} = \\mathrm{add}(n_{3},n_{1})$ (This is the root of the DAG).\n- **Leaf Nodes:** The leaves $a, b, c, d$ are values available in registers at zero cost.\n- **Instruction Patterns and Costs:**\n  - $p_{\\mathrm{add}}: \\mathrm{add}(x,y)$, with cost $1$.\n  - $p_{\\mathrm{mul}}: \\mathrm{mul}(x,y)$, with cost $2$.\n  - $p_{\\mathrm{fma}}: \\mathrm{add}(\\mathrm{mul}(x,y),z)$, with cost $2$.\n- **Operator Properties:** The operators $\\mathrm{add}$ and $\\mathrm{mul}$ are commutative.\n- **Covering Rule:** Each internal IR node ($n_1, n_2, n_3, n_4$) must be covered by exactly one chosen pattern. A pattern can cover more than one node (e.g., $p_{\\mathrm{fma}}$ covers an $\\mathrm{add}$ and a $\\mathrm{mul}$ node).\n- **Objective:** Determine the minimum possible total cost to cover the DAG. The total cost is the sum of the costs of the chosen patterns.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded:** The problem is a classic instance of instruction selection via DAG covering, a fundamental topic in compiler construction. The concepts of IR DAGs, pattern matching, and cost models are standard and scientifically sound.\n2.  **Well-Posed:** The problem provides a completely specified DAG, a finite set of tiles (patterns) with defined costs, and a clear objective function (minimize total cost) under a precise covering constraint (partitioning the node set). This structure guarantees that a solution exists and is unique (or has a unique minimum cost).\n3.  **Objective:** The problem is stated using formal, unambiguous language standard to computer science and compiler theory. It is free from subjective claims.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, contradiction, or ambiguity. It is a well-defined optimization problem within the domain of compiler theory.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. I will proceed with a full solution.\n\nThe task is to find a set of instruction patterns that collectively cover all internal nodes of the DAG, $\\{n_1, n_2, n_3, n_4\\}$, exactly once, such that the sum of the costs of the chosen patterns is minimized. This is equivalent to finding a minimum-cost partition of the set of nodes, where each block of the partition is covered by a single instruction pattern.\n\nThe nodes to be covered are $n_1 = \\mathrm{add}(a,b)$, $n_2 = \\mathrm{add}(c,d)$, $n_3 = \\mathrm{mul}(n_1,n_2)$, and the root $n_4 = \\mathrm{add}(n_3,n_1)$. Let $\\mathcal{N} = \\{n_1, n_2, n_3, n_4\\}$ be the set of internal nodes.\n\nWe analyze the possible patterns that can match at each node. A pattern is said to match at a node if that node is the root of the pattern.\n- At $n_1 = \\mathrm{add}(a,b)$: The only matching pattern is $p_{\\mathrm{add}}$. The leaves $a$ and $b$ do not form a `mul` subtree, so $p_{\\mathrm{fma}}$ cannot match. If chosen, this covers node $\\{n_1\\}$.\n- At $n_2 = \\mathrm{add}(c,d)$: Similarly, only $p_{\\mathrm{add}}$ can match. If chosen, this covers node $\\{n_2\\}$.\n- At $n_3 = \\mathrm{mul}(n_1,n_2)$: The only matching pattern is $p_{\\mathrm{mul}}$. If chosen, this covers node $\\{n_3\\}$.\n- At $n_4 = \\mathrm{add}(n_3,n_1)$:\n  1. The $p_{\\mathrm{add}}$ pattern can match. If chosen, this covers node $\\{n_4\\}$.\n  2. The $p_{\\mathrm{fma}}$ pattern, $\\mathrm{add}(\\mathrm{mul}(x,y),z)$, can also match. The problem states that $\\mathrm{add}$ is commutative, so the pattern can match $\\mathrm{add}(\\mathrm{mul}(...),...)$ or $\\mathrm{add}(...,\\mathrm{mul}(...))$. The node $n_4$ is $\\mathrm{add}(n_3,n_1)$. Since $n_3$ is a $\\mathrm{mul}$ node, this structure matches $p_{\\mathrm{fma}}$. If chosen, this pattern covers both the $\\mathrm{add}$ node $n_4$ and its child $\\mathrm{mul}$ node $n_3$. The set of covered nodes is $\\{n_3, n_4\\}$.\n\nTo find the minimum cost cover, we must make a choice for covering the root node $n_4$. This leads to two distinct cases for partitioning the node set $\\mathcal{N}$.\n\n**Case 1: Cover node $n_4$ using the $p_{\\mathrm{add}}$ pattern.**\n- We select the pattern $p_{\\mathrm{add}}$ to match at node $n_4$. This covers the node set $\\{n_4\\}$. The cost incurred is $1$.\n- The remaining nodes to be covered are $\\{n_1, n_2, n_3\\}$.\n- To cover node $n_3 = \\mathrm{mul}(n_1,n_2)$, we must use the $p_{\\mathrm{mul}}$ pattern. This covers the node set $\\{n_3\\}$. The cost incurred for this pattern is $2$.\n- The remaining nodes to be covered are $\\{n_1, n_2\\}$.\n- To cover node $n_1 = \\mathrm{add}(a,b)$, we must use the $p_{\\mathrm{add}}$ pattern. This covers the node set $\\{n_1\\}$. The cost is $1$.\n- To cover node $n_2 = \\mathrm{add}(c,d)$, we must use the $p_{\\mathrm{add}}$ pattern. This covers the node set $\\{n_2\\}$. The cost is $1$.\n- The complete cover consists of patterns matching at $n_4$, $n_3$, $n_1$, and $n_2$. The node sets covered are $\\{n_4\\}$, $\\{n_3\\}$, $\\{n_1\\}$, and $\\{n_2\\}$, which form a partition of $\\mathcal{N}$. This is a valid cover.\n- The total cost for this case is the sum of the costs of the chosen patterns: $1 (\\text{for } n_4) + 2 (\\text{for } n_3) + 1 (\\text{for } n_1) + 1 (\\text{for } n_2) = 5$.\n\n**Case 2: Cover node $n_4$ using the $p_{\\mathrm{fma}}$ pattern.**\n- We select the pattern $p_{\\mathrm{fma}}$ to match at node $n_4$. This pattern matches the structure $\\mathrm{add}(n_3, n_1)$ because $n_3$ is a $\\mathrm{mul}$ node. This single pattern covers both nodes $n_4$ and $n_3$. The set of covered nodes is $\\{n_3, n_4\\}$. The cost incurred is $2$.\n- The remaining nodes to be covered are $\\{n_1, n_2\\}$.\n- To cover node $n_1 = \\mathrm{add}(a,b)$, we must use the $p_{\\mathrm{add}}$ pattern. This covers $\\{n_1\\}$. The cost is $1$.\n- To cover node $n_2 = \\mathrm{add}(c,d)$, we must use the $p_{\\mathrm{add}}$ pattern. This covers $\\{n_2\\}$. The cost is $1$.\n- The complete cover consists of a $p_{\\mathrm{fma}}$ pattern at $n_4$ and $p_{\\mathrm{add}}$ patterns at $n_1$ and $n_2$. The node sets covered are $\\{n_3, n_4\\}$, $\\{n_1\\}$, and $\\{n_2\\}$, which form a partition of $\\mathcal{N}$. This is also a valid cover.\n- The total cost for this case is: $2 (\\text{for } n_4 \\text{ and } n_3) + 1 (\\text{for } n_1) + 1 (\\text{for } n_2) = 4$.\n\n**Conclusion**\nWe have enumerated all possible valid coverings of the DAG. The two possible total costs are $5$ and $4$. The minimum possible total cost is the minimum of these values.\n$$ \\min(5, 4) = 4 $$\nTherefore, the minimum cost to cover the given DAG is $4$. This is achieved by using one fused multiply-add instruction and two add instructions.",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "Moving from abstract costs to real-world hardware, this practice introduces a critical architectural constraint: the limited size of immediate operands. You will explore how a compiler must handle constants that are too large to be encoded directly into an instruction, requiring them to be materialized into registers first . The challenge lies in calculating the total cost, including these materialization steps, and recognizing the savings gained from sharing a single materialized constant across multiple uses.",
            "id": "3635002",
            "problem": "A compiler back end must perform instruction selection by directed acyclic graph (DAG) covering on the following intermediate representation. The target machine is a load-store architecture similar to Reduced Instruction Set Computer Five (RISC-V) with the following relevant properties:\n- All input variables $x$, $y$, and $z$ arrive in registers.\n- The machine supports arithmetic instructions with unit cost $1$: ADD, ADDI, and MUL.\n- The immediate form ADDI uses a signed $12$-bit immediate; that is, the immediate $i$ must satisfy $-2048 \\le i \\le 2047$ to be encodable directly.\n- The instruction LUI loads the high part of a constant into a register with unit cost $1$. Any constant $C$ with $|C| \\le 2047$ can be materialized in one instruction using ADDI with the zero register, and any constant $C$ with $|C| > 2047$ can be materialized in exactly $2$ instructions using LUI followed by ADDI. Assume the machine has enough registers so that once a constant is materialized it can be reused without additional spill costs.\n\nThe intermediate representation to be covered is a directed acyclic graph (DAG) with shared constant subexpressions:\n- Nodes:\n  - $n_{1} = \\mathrm{CONST}(5000)$\n  - $n_{2} = \\mathrm{CONST}(131071)$\n  - $n_{3} = \\mathrm{ADD}(x, n_{1})$\n  - $n_{4} = \\mathrm{ADD}(y, n_{1})$\n  - $n_{5} = \\mathrm{MUL}(z, n_{2})$\n  - $n_{6} = \\mathrm{ADD}(n_{5}, n_{1})$\n  - $n_{7} = \\mathrm{ADD}(n_{3}, n_{4})$\n  - $n_{8} = \\mathrm{ADD}(n_{7}, n_{6})$  (root)\n\nSemantics:\n- $\\mathrm{ADD}(a,b)$ denotes integer addition of $a$ and $b$.\n- $\\mathrm{MUL}(a,b)$ denotes integer multiplication of $a$ and $b$.\n- $\\mathrm{CONST}(C)$ denotes the integer constant $C$.\n- The constants $5000$ and $131071$ are greater than $2047$ in absolute value, hence they do not fit the ADDI immediate range.\n\nInstruction selection by DAG covering must choose patterns that map nodes to machine instructions while respecting immediate-range constraints and allowing the materialization of large constants via LUI followed by ADDI. Any use of a non-encodable constant as an operand to ADD or MUL requires that the constant has been materialized into a register beforehand. Materialized constants may be shared across all of their uses in the DAG at no additional materialization cost.\n\nUsing these rules and optimizing for the minimal total number of machine instructions, compute the minimal instruction count needed to cover the entire DAG rooted at $n_{8}$. Return only the minimal count as an integer. Assume no algebraic reassociation or reordering is permitted; you must cover exactly the given DAG. Assume all instructions have uniform cost $1$. You do not need to round your answer.",
            "solution": "We start from the core definitions of directed acyclic graph (DAG) covering for instruction selection in compiler back ends. A DAG $G$ encodes data dependences between operations. A cover maps DAG nodes to target-machine instruction patterns such that:\n- The semantics of each intermediate representation node are implemented by one or more target instructions.\n- Immediate-form instructions are permitted only when the constant operands fit the target’s immediate range.\n- Shared subgraphs (such as a constant node with multiple parents) can be implemented once and reused across parents, provided the target has sufficient registers. The total cost objective is the sum of the costs of the selected target instructions.\n\nGiven the target machine properties:\n- ADD has cost $1$ with two register operands.\n- ADDI has cost $1$ but is usable only if the immediate $i$ satisfies $-2048 \\le i \\le 2047$.\n- LUI has cost $1$ and can be composed with ADDI at cost $1$ to materialize any larger constant. By assumption, for $|C| > 2047$, a constant $C$ is materialized in exactly $2$ instructions via $\\mathrm{LUI} + \\mathrm{ADDI}$.\n\nWe analyze the DAG:\n- $n_{1} = \\mathrm{CONST}(5000)$ has $|5000| > 2047$, so it requires materialization. By the rule, materializing $5000$ costs $2$ instructions, via $\\mathrm{LUI} + \\mathrm{ADDI}$. Because $n_{1}$ is shared by $n_{3}$, $n_{4}$, and $n_{6}$, we can reuse the single materialized register holding $5000$ at no additional materialization cost.\n- $n_{2} = \\mathrm{CONST}(131071)$ has $|131071| > 2047$, so it also requires materialization. Materializing $131071$ costs $2$ instructions via $\\mathrm{LUI} + \\mathrm{ADDI}$. It is used once in $n_{5}$.\n\nNext, we enumerate the operator nodes and the feasible instruction choices under the immediate constraints:\n- $n_{3} = \\mathrm{ADD}(x, n_{1})$: Since $n_{1}$ is too large for an ADDI immediate, we cannot use ADDI with $5000$ directly. The only option is to use ADD with two registers: the register for $x$ and the register holding the materialized $5000$. Cost for this ADD is $1$.\n- $n_{4} = \\mathrm{ADD}(y, n_{1})$: Same reasoning as for $n_{3}$; cost $1$ for ADD.\n- $n_{5} = \\mathrm{MUL}(z, n_{2})$: There is no multiply-immediate instruction. We must multiply $z$ by the register holding the materialized $131071$. Cost for this MUL is $1$.\n- $n_{6} = \\mathrm{ADD}(n_{5}, n_{1})$: Again, since $n_{1}$ does not fit the immediate range, we must use ADD with two registers. Cost $1$.\n- $n_{7} = \\mathrm{ADD}(n_{3}, n_{4})$: Both inputs are registers produced by prior computations; ADD with two registers costs $1$.\n- $n_{8} = \\mathrm{ADD}(n_{7}, n_{6})$: Similarly, ADD with two registers costs $1$.\n\nNow we sum the costs, taking care to count each constant materialization once due to sharing:\n- Materialization costs for unique large constants:\n  - For $5000$: $2$ instructions (shared across $n_{3}$, $n_{4}$, and $n_{6}$).\n  - For $131071$: $2$ instructions (used in $n_{5}$).\n  The total for materializations is $2 + 2 = 4$.\n- Operator instruction costs:\n  - $n_{3}$: ADD, cost $1$.\n  - $n_{4}$: ADD, cost $1$.\n  - $n_{5}$: MUL, cost $1$.\n  - $n_{6}$: ADD, cost $1$.\n  - $n_{7}$: ADD, cost $1$.\n  - $n_{8}$: ADD, cost $1$.\n  The total for operators is $1 + 1 + 1 + 1 + 1 + 1 = 6$.\n\nTherefore, the minimal total instruction count is\n$$\n4 + 6 = 10.\n$$\n\nIt remains to justify optimality. Any attempt to use ADDI in place of ADD where $n_{1}$ or $n_{2}$ appear as operands is infeasible because $5000$ and $131071$ lie outside the immediate range $[-2048, 2047]$. There is no multiply-immediate instruction, so $n_{5}$ must use MUL with a materialized constant. There are no alternative patterns that reduce the number of ADDs needed to combine the intermediate results, because algebraic reassociation is disallowed and the DAG imposes the exact structure of additions. Because we can share the materialization of $5000$ across its three uses, any cover that materializes $5000$ more than once is strictly suboptimal. Hence the counted cover is optimal, and the minimal total instruction count is $10$.",
            "answer": "$$\\boxed{10}$$"
        },
        {
            "introduction": "Optimal instruction selection often involves strategic trade-offs that go beyond a direct translation of the input program. This final exercise presents a classic compiler dilemma: is it cheaper to compute a shared value once, or to duplicate the computation to enable more powerful, specialized instructions at each point of use ? Solving this requires a principled cost-benefit analysis to determine which combination of sharing and duplication yields the lowest overall execution cost.",
            "id": "3634928",
            "problem": "A compiler back end must perform instruction selection by covering an intermediate representation directed acyclic graph (DAG) with target machine instruction patterns. In the additive cost model, each chosen instruction contributes an integer cost, and the total cost is the sum over the DAG cover. Consider the following situation with one shared producer node feeding multiple consumers.\n\nThe producer node is $S = \\mathrm{SHL}(x, 1)$, a shift-left by a constant. The cost of $\\mathrm{SHL}$ by a constant is $1$ cost unit. The value $S$ is used by four consumer nodes:\n- $C_1 = \\mathrm{ADD}(S, a)$ with non-fused cost $2$.\n- $C_2 = \\mathrm{SUB}(b, S)$ with non-fused cost $2$.\n- $C_3 = \\mathrm{AND}(S, c)$ with non-fused cost $1$.\n- $C_4 = \\mathrm{XOR}(S, d)$ with non-fused cost $1$.\n\nThe target also provides fused instruction patterns that subsume the computation of $\\mathrm{SHL}(x,1)$ and the consumer operation, but these fused patterns are only applicable if the result $S$ is not shared (that is, the $\\mathrm{SHL}$ feeding that consumer is not used by any other consumer). The fused patterns and their costs are:\n- $\\mathrm{FADD}(x, a)$ computing $\\mathrm{ADD}(\\mathrm{SHL}(x,1), a)$ with cost $1$.\n- $\\mathrm{FSUB}(b, x)$ computing $\\mathrm{SUB}(b, \\mathrm{SHL}(x,1))$ with cost $2$.\n- $\\mathrm{FAND}(x, c)$ computing $\\mathrm{AND}(\\mathrm{SHL}(x,1), c)$ with cost $1$.\n- $\\mathrm{FXOR}(x, d)$ computing $\\mathrm{XOR}(\\mathrm{SHL}(x,1), d)$ with cost $2$.\n\nAssume the additive cost model and ignore register allocation and scheduling effects. You may choose to compute $S$ once and share it among any subset of the consumers (those consumers must then use the non-fused patterns), and optionally duplicate the computation of $\\mathrm{SHL}(x,1)$ within any subset of consumers to enable the corresponding fused patterns for those consumers. If no consumer shares $S$, you need not materialize $S$ separately.\n\nStarting from the foundational definitions of directed acyclic graph covering and the additive cost model, derive a principled decision criterion for when duplication is beneficial, and compute the exact minimal total cost achievable (in cost units) over all choices of which consumers, if any, should receive duplicated computations to enable fused patterns. Provide your final answer as a single integer number of cost units. No rounding is needed because all costs are integers.",
            "solution": "The problem asks for a decision criterion regarding instruction duplication and for the minimal total cost of a computation graph segment under an additive cost model. The problem is well-posed, scientifically grounded in compiler theory, and contains all necessary information for a unique solution.\n\nFirst, let us formalize the problem. We have a set of four consumer nodes, indexed by $i \\in \\{1, 2, 3, 4\\}$. For each consumer $i$, we are given two implementation choices:\n$1$. A non-fused instruction with cost $C_{nf,i}$. This instruction takes as input the value $S = \\mathrm{SHL}(x, 1)$, which is computed by a shared producer node. The cost of computing $S$ once is $C_{S} = 1$.\n$2$. A fused instruction with cost $C_{f,i}$. This instruction computes the equivalent of the consumer operation on the shifted value $\\mathrm{SHL}(x, 1)$ directly, and can only be used if the producer node $S$ is duplicated for this consumer (i.e., its result is not used by any other consumer). The cost $C_{f,i}$ includes the cost of the $\\mathrm{SHL}$ operation.\n\nThe given costs are:\n- Producer cost: $C_{S} = 1$.\n- Non-fused consumer costs: $C_{nf,1}=2$, $C_{nf,2}=2$, $C_{nf,3}=1$, $C_{nf,4}=1$.\n- Fused instruction costs: $C_{f,1}=1$, $C_{f,2}=2$, $C_{f,3}=1$, $C_{f,4}=2$.\n\nThe task is to partition the set of consumers $I = \\{1, 2, 3, 4\\}$ into two disjoint sets: $I_{share}$, the set of consumers that will use the result of a single, shared computation of $S$, and $I_{fuse}$, the set of consumers for which we will use fused instructions. The total cost is the sum of the costs of all chosen instructions.\n\nThe total cost function, $Cost(I_{share}, I_{fuse})$, can be expressed as:\n$$Cost(I_{share}, I_{fuse}) = (\\text{Cost of shared portion}) + (\\text{Cost of fused portion})$$\nThe cost of the fused portion is the sum of the costs of the individual fused instructions: $\\sum_{j \\in I_{fuse}} C_{f,j}$.\nThe cost of the shared portion depends on whether any nodes are actually sharing. If $I_{share}$ is not empty, we must pay the cost $C_{S}$ for the shared producer $S$, plus the costs for each non-fused consumer instruction. If $I_{share}$ is empty, this cost is $0$.\nLet $\\delta(I_{share})$ be an indicator function which is $1$ if $I_{share}$ is non-empty and $0$ otherwise. The total cost is:\n$$Cost(I_{share}, I_{fuse}) = \\delta(I_{share}) \\cdot C_{S} + \\sum_{i \\in I_{share}} C_{nf,i} + \\sum_{j \\in I_{fuse}} C_{f,j}$$\nSince $I_{share}$ and $I_{fuse}$ form a partition of $I$, we can define the problem as finding the set $I_{fuse} \\subseteq I$ that minimizes this function.\n\n**Principled Decision Criterion for Duplication**\n\nTo derive a criterion for when duplication (i.e., using a fused pattern) is beneficial, we can analyze the change in total cost, $\\Delta Cost$, when moving a single consumer $k$ from the shared group $I_{share}$ to the fused group $I_{fuse}$. We must consider two cases.\n\nCase 1: The shared group initially contains more than one consumer, i.e., $|I_{share}| > 1$.\nLet the initial partition be $(I_{share}, I_{fuse})$. The cost is $Cost_{old} = C_{S} + \\sum_{i \\in I_{share}} C_{nf,i} + \\sum_{j \\in I_{fuse}} C_{f,j}$.\nWe move consumer $k \\in I_{share}$ to the fused group. The new partition is $(I'_{share}, I'_{fuse})$ where $I'_{share} = I_{share} \\setminus \\{k\\}$ and $I'_{fuse} = I_{fuse} \\cup \\{k\\}$. Since $|I_{share}| > 1$, the new shared group $I'_{share}$ is not empty.\nThe new cost is $Cost_{new} = C_{S} + \\sum_{i \\in I'_{share}} C_{nf,i} + \\sum_{j \\in I'_{fuse}} C_{f,j} = C_{S} + (\\sum_{i \\in I_{share}} C_{nf,i} - C_{nf,k}) + (\\sum_{j \\in I_{fuse}} C_{f,j} + C_{f,k})$.\nThe change in cost is $\\Delta Cost = Cost_{new} - Cost_{old} = C_{f,k} - C_{nf,k}$.\nTherefore, duplication for consumer $k$ is beneficial if $\\Delta Cost < 0$, which implies $C_{f,k} < C_{nf,k}$.\n\nCase 2: The shared group initially contains only one consumer, i.e., $I_{share} = \\{k\\}$.\nThe initial cost is $Cost_{old} = C_{S} + C_{nf,k} + \\sum_{j \\in I_{fuse}} C_{f,j}$.\nWe move consumer $k$ to the fused group. The new shared group $I'_{share}$ is now empty.\nThe new cost is $Cost_{new} = 0 + \\sum_{j \\in I_{fuse} \\cup \\{k\\}} C_{f,j} = \\sum_{j \\in I_{fuse}} C_{f,j} + C_{f,k}$.\nThe change in cost is $\\Delta Cost = Cost_{new} - Cost_{old} = (C_{f,k} + \\sum_{j \\in I_{fuse}} C_{f,j}) - (C_{S} + C_{nf,k} + \\sum_{j \\in I_{fuse}} C_{f,j}) = C_{f,k} - C_{nf,k} - C_{S}$.\nTherefore, duplicating for the last shared consumer $k$ is beneficial if $\\Delta Cost < 0$, which implies $C_{f,k} < C_{nf,k} + C_{S}$.\n\n**Computation of Minimal Total Cost**\n\nSince there are only $4$ consumers, there are $2^4 = 16$ possible partitions. We can find the minimum by exhaustively evaluating the cost for each partition, grouped by the number of fused consumers, $|I_{fuse}|$.\n\nLet $I_{fuse}$ be the set of indices of fused consumers. Then $I_{share} = \\{1,2,3,4\\} \\setminus I_{fuse}$.\n\nCase $|I_{fuse}| = 0$: $I_{fuse} = \\emptyset$.\n$I_{share} = \\{1,2,3,4\\}$. The shared group is non-empty.\nTotal cost = $C_{S} + (C_{nf,1} + C_{nf,2} + C_{nf,3} + C_{nf,4}) = 1 + (2+2+1+1) = 7$.\n\nCase $|I_{fuse}| = 1$:\n- $I_{fuse}=\\{1\\}$: Cost = $(C_{S} + C_{nf,2}+C_{nf,3}+C_{nf,4}) + C_{f,1} = (1+2+1+1)+1 = 6$.\n- $I_{fuse}=\\{2\\}$: Cost = $(C_{S} + C_{nf,1}+C_{nf,3}+C_{nf,4}) + C_{f,2} = (1+2+1+1)+2 = 7$.\n- $I_{fuse}=\\{3\\}$: Cost = $(C_{S} + C_{nf,1}+C_{nf,2}+C_{nf,4}) + C_{f,3} = (1+2+2+1)+1 = 7$.\n- $I_{fuse}=\\{4\\}$: Cost = $(C_{S} + C_{nf,1}+C_{nf,2}+C_{nf,3}) + C_{f,4} = (1+2+2+1)+2 = 8$.\n\nCase $|I_{fuse}| = 2$:\n- $I_{fuse}=\\{1,2\\}$: Cost = $(C_{S} + C_{nf,3}+C_{nf,4}) + (C_{f,1}+C_{f,2}) = (1+1+1)+(1+2) = 6$.\n- $I_{fuse}=\\{1,3\\}$: Cost = $(C_{S} + C_{nf,2}+C_{nf,4}) + (C_{f,1}+C_{f,3}) = (1+2+1)+(1+1) = 6$.\n- $I_{fuse}=\\{1,4\\}$: Cost = $(C_{S} + C_{nf,2}+C_{nf,3}) + (C_{f,1}+C_{f,4}) = (1+2+1)+(1+2) = 7$.\n- $I_{fuse}=\\{2,3\\}$: Cost = $(C_{S} + C_{nf,1}+C_{nf,4}) + (C_{f,2}+C_{f,3}) = (1+2+1)+(2+1) = 7$.\n- $I_{fuse}=\\{2,4\\}$: Cost = $(C_{S} + C_{nf,1}+C_{nf,3}) + (C_{f,2}+C_{f,4}) = (1+2+1)+(2+2) = 8$.\n- $I_{fuse}=\\{3,4\\}$: Cost = $(C_{S} + C_{nf,1}+C_{nf,2}) + (C_{f,3}+C_{f,4}) = (1+2+2)+(1+2) = 8$.\n\nCase $|I_{fuse}| = 3$:\n- $I_{fuse}=\\{1,2,3\\}$: Cost = $(C_{S} + C_{nf,4}) + (C_{f,1}+C_{f,2}+C_{f,3}) = (1+1)+(1+2+1) = 6$.\n- $I_{fuse}=\\{1,2,4\\}$: Cost = $(C_{S} + C_{nf,3}) + (C_{f,1}+C_{f,2}+C_{f,4}) = (1+1)+(1+2+2) = 7$.\n- $I_{fuse}=\\{1,3,4\\}$: Cost = $(C_{S} + C_{nf,2}) + (C_{f,1}+C_{f,3}+C_{f,4}) = (1+2)+(1+1+2) = 7$.\n- $I_{fuse}=\\{2,3,4\\}$: Cost = $(C_{S} + C_{nf,1}) + (C_{f,2}+C_{f,3}+C_{f,4}) = (1+2)+(2+1+2) = 8$.\n\nCase $|I_{fuse}| = 4$: $I_{fuse} = \\{1,2,3,4\\}$.\n$I_{share} = \\emptyset$. The shared portion cost is $0$.\nTotal cost = $C_{f,1}+C_{f,2}+C_{f,3}+C_{f,4} = 1+2+1+2 = 6$.\n\nBy evaluating all $16$ possible configurations, we find that the minimal total cost is $6$ cost units. This minimum cost is achieved by several different configurations, for example, fusing only consumer $1$, or fusing all consumers.",
            "answer": "$$\\boxed{6}$$"
        }
    ]
}