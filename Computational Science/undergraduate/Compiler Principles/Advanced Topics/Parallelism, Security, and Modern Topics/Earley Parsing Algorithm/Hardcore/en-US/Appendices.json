{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp the Earley algorithm, there is no substitute for tracing its execution on paper. This first practice exercise guides you through the step-by-step construction of the Earley chart for a classic ambiguous grammar (). By manually applying the predictor, scanner, and completer operations, you will not only see the algorithm's mechanics in motion but also gain a deep insight into how it elegantly manages ambiguity by simultaneously exploring all possible parse trees.",
            "id": "3639800",
            "problem": "Consider the Context-Free Grammar (CFG) $G$ with start symbol $S$ and productions $S \\to S\\,S \\mid a$. Let the input string be $\\mathtt{aaa}$ of length $3$. Use the Earley parsing algorithm, which represents states as dotted items $[A \\to \\alpha\\,\\cdot\\,\\beta, i]$ where $A$ is a nonterminal, $\\alpha$ and $\\beta$ are (possibly empty) strings of terminals and nonterminals, the dot indicates the current position in the right-hand side, and $i$ is the origin index where this constituent began. The Earley algorithm uses three fundamental operations: Predictor (adds productions for a nonterminal immediately to the right of the dot), Scanner (consumes a matching terminal from the input to advance the dot), and Completer (when a constituent finishes, it advances any states that were waiting for it at their origins). Augment the grammar with a new start symbol $S'$ and production $S' \\to S$.\n\nConstruct the Earley chart $C_0, C_1, C_2, C_3$ for the input $\\mathtt{aaa}$, showing the items created by the Predictor, Scanner, and Completer at each position and maintaining origin indices. Based on the completed items and their backpointers implied by the Completer steps, reason from first principles how many distinct parse trees for $\\mathtt{aaa}$ this algorithm discovers under $G$. Provide your final answer as a single integer. No rounding is required, and no units should be included in the answer.",
            "solution": "The Context-Free Grammar, $G$, is given by the productions $S \\to S\\,S \\mid a$. The input string is $\\mathtt{aaa}$, which we denote as $w = w_1 w_2 w_3$ where $w_1=w_2=w_3=\\mathtt{a}$. As per the problem, we augment the grammar with a new start symbol $S'$ and a production $S' \\to S$. The augmented grammar $G'$ is:\n$S' \\to S$\n$S \\to S\\,S$\n$S \\to a$\n\nWe construct the Earley charts $C_0, C_1, C_2, C_3$. An item is of the form $[A \\to \\alpha\\,\\cdot\\,\\beta, i]$, where $i$ is the origin index in the input string (from $0$ to $3$).\n\n**Chart $C_0$:**\nTo initialize, we add an item for the augmented start rule at index $0$. We then apply the Predictor operation until no new items can be added.\n1. $[S' \\to \\cdot S, 0]$ (Seed)\n2. $[S \\to \\cdot S\\,S, 0]$ (Predictor on item 1, since $S$ is to the right of the dot)\n3. $[S \\to \\cdot a, 0]$ (Predictor on item 1)\n   (Applying Predictor on item 2 would re-generate items 2 and 3, so the chart is complete.)\n\n**Chart $C_1$ (after processing input $w_1 = \\mathtt{a}$):**\nWe first apply the Scanner to items in $C_0$ that expect the terminal $\\mathtt{a}$, then run Completer and Predictor to a fixed point.\n1. $[S \\to a \\cdot, 0]$ (Scanner on $[S \\to \\cdot a, 0]$ in $C_0$)\n2. $[S' \\to S \\cdot, 0]$ (Completer on item 1, advancing $[S' \\to \\cdot S, 0]$ from $C_0$)\n3. $[S \\to S \\cdot S, 0]$ (Completer on item 1, advancing $[S \\to \\cdot S S, 0]$ from $C_0$)\n4. $[S \\to \\cdot S\\,S, 1]$ (Predictor on item 3, for the $S$ needed at the current position, $1$)\n5. $[S \\to \\cdot a, 1]$ (Predictor on item 3)\n\n**Chart $C_2$ (after processing input $w_2 = \\mathtt{a}$):**\n1. $[S \\to a \\cdot, 1]$ (Scanner on $[S \\to \\cdot a, 1]$ in $C_1$)\n   Now we apply the Completer with this new completed item, $[S \\to a \\cdot, 1]$, which represents an $S$ spanning from index $1$ to $2$.\n2. $[S \\to S \\cdot S, 1]$ (Completer on item 1, advancing $[S \\to \\cdot S\\,S, 1]$ from $C_1$)\n3. $[S \\to S\\,S \\cdot, 0]$ (Completer on item 1, advancing $[S \\to S \\cdot S, 0]$ from $C_1$. This new item is a completed $S$ spanning $0$ to $2$.)\n   Now we apply the Completer again, with item 3.\n4. $[S' \\to S \\cdot, 0]$ (Completer on item 3, advancing $[S' \\to \\cdot S, 0]$ from $C_0$)\n5. $[S \\to S \\cdot S, 0]$ (Completer on item 3, advancing $[S \\to \\cdot S\\,S, 0]$ from $C_0$)\n   Finally, we apply the Predictor for the new non-completed items.\n6. $[S \\to \\cdot S\\,S, 2]$ (Predictor on items 2 and 5, for the $S$ needed at the current position, $2$)\n7. $[S \\to \\cdot a, 2]$ (Predictor on items 2 and 5)\n\n**Chart $C_3$ (after processing input $w_3 = \\mathtt{a}$):**\n1. $[S \\to a \\cdot, 2]$ (Scanner on $[S \\to \\cdot a, 2]$ in $C_2$)\n   This is a completed $S$ from index $2$ to $3$. We run the Completer.\n2. $[S \\to S \\cdot S, 2]$ (Completer on item 1, advancing $[S \\to \\cdot S\\,S, 2]$ from $C_2$)\n3. $[S \\to S\\,S \\cdot, 1]$ (Completer on item 1, advancing $[S \\to S \\cdot S, 1]$ from $C_2$. This is a completed $S$ from $1$ to $3$.)\n4. $[S \\to S\\,S \\cdot, 0]$ (Completer on item 1, advancing $[S \\to S \\cdot S, 0]$ from $C_2$. This is one way to form a completed $S$ from $0$ to $3$.)\n   We continue the Completer with newly completed items. The item $[S \\to S\\,S \\cdot, 1]$ from step 3 (an $S$ from $1$ to $3$) can complete waiting items.\n5. A second derivation for $[S \\to S\\,S \\cdot, 0]$ (Completer on item 3, advancing $[S \\to S \\cdot S, 0]$ from $C_1$). Note that while the resulting item is textually identical to item 4, its derivation path is distinct.\n   The items $[S \\to S\\,S \\cdot, 0]$, however they are derived, represent completed $S$ constituents from $0$ to $3$. They trigger further completions from $C_0$.\n6. $[S' \\to S \\cdot, 0]$ (Completer on items 4 and 5, advancing $[S' \\to \\cdot S, 0]$ from $C_0$). This item indicates a successful parse of the entire string.\n7. $[S \\to S \\cdot S, 0]$ (Completer on items 4 and 5, advancing $[S \\to \\cdot S\\,S, 0]$ from $C_0$).\nNo further items can be added. The presence of $[S' \\to S \\cdot, 0]$ in $C_3$ confirms the string $\\mathtt{aaa}$ is in the language.\n\n**Counting the Parse Trees:**\nThe number of distinct parse trees is the number of distinct derivations for the final accepting item, $[S' \\to S \\cdot, 0]$ in $C_3$. Since the production $S' \\to S$ is unambiguous, this count is equal to the number of ways a constituent $S$ spanning from index $0$ to $3$ can be formed.\n\nLet $N(A, i, j)$ denote the number of distinct parse trees for a nonterminal $A$ spanning the input substring from index $i$ to $j$. We can compute this from the chart structure in a bottom-up fashion.\n- A constituent from a terminal production like $S \\to a$ has exactly one derivation.\n  - $N(S, 0, 1)$ comes from $[S \\to a \\cdot, 0]$ in $C_1$, so $N(S, 0, 1) = 1$.\n  - $N(S, 1, 2)$ comes from $[S \\to a \\cdot, 1]$ in $C_2$, so $N(S, 1, 2) = 1$.\n  - $N(S, 2, 3)$ comes from $[S \\to a \\cdot, 2]$ in $C_3$, so $N(S, 2, 3) = 1$.\n\n- For a recursive production like $S \\to S\\,S$ spanning $(i, j)$, we must sum over all possible split points $k$ where $i < k < j$:\n  $N(S, i, j) = \\sum_{k=i+1}^{j-1} N(S, i, k) \\times N(S, k, j)$\n\n- We compute $N(S, 0, 2)$ for the substring $\\mathtt{aa}$: The only split point is $k=1$.\n  $N(S, 0, 2) = N(S, 0, 1) \\times N(S, 1, 2) = 1 \\times 1 = 1$.\n  This corresponds to the creation of $[S \\to S\\,S \\cdot, 0]$ in $C_2$.\n\n- We compute $N(S, 1, 3)$ for the substring $\\mathtt{aa}$: The only split point is $k=2$.\n  $N(S, 1, 3) = N(S, 1, 2) \\times N(S, 2, 3) = 1 \\times 1 = 1$.\n  This corresponds to the creation of $[S \\to S\\,S \\cdot, 1]$ in $C_3$.\n\n- Finally, we compute $N(S, 0, 3)$ for the full string $\\mathtt{aaa}$. The possible split points are $k=1$ and $k=2$.\n  $N(S, 0, 3) = N(S, 0, 1) \\times N(S, 1, 3) + N(S, 0, 2) \\times N(S, 2, 3)$\n  Substituting the values we found:\n  $N(S, 0, 3) = (1 \\times 1) + (1 \\times 1) = 1 + 1 = 2$.\n\nThese two terms correspond to the two distinct completion paths that form an $S$ over $(0, 3)$:\n1. The term $N(S, 0, 1) \\times N(S, 1, 3) = 1$ corresponds to a parse with the top-level structure $(S_{0,1} S_{1,3})$. In the chart, this is the completion of $[S \\to S \\cdot S, 0]$ from $C_1$ with the completed item for $S_{1,3}$, which is $[S \\to S\\,S \\cdot, 1]$ in $C_3$. This yields one parse tree. (Right-associative: $\\mathtt{a}(\\mathtt{aa})$).\n\n2. The term $N(S, 0, 2) \\times N(S, 2, 3) = 1$ corresponds to a parse with the top-level structure $(S_{0,2} S_{2,3})$. In the chart, this is the completion of $[S \\to S \\cdot S, 0]$ from $C_2$ with the completed item for $S_{2,3}$, which is $[S \\to a \\cdot, 2]$ in $C_3$. This yields a second, distinct parse tree. (Left-associative: $(\\mathtt{aa})\\mathtt{a}$).\n\nSince there are two ways to derive an $S$ that spans the entire input, the algorithm discovers two distinct parse trees.",
            "answer": "$$\n\\boxed{2}\n$$"
        },
        {
            "introduction": "While the Earley algorithm can parse any context-free grammar, its performance is not independent of the grammar's structure. This exercise focuses on analyzing this connection by comparing the parser's behavior on an original grammar versus its left-factored equivalent (). By quantifying the 'total item growth'—a proxy for the parser's workload—you will develop a practical understanding of how grammar transformations can influence parsing efficiency.",
            "id": "3639827",
            "problem": "Consider the context-free grammar (CFG) $G$ with start symbol $S$ given by the productions $S \\to a\\,A \\mid a\\,B$, $A \\to x$, and $B \\to y$. Let the left-factored refactoring $G^{\\mathrm{lf}}$ of $G$ be defined by introducing a new nonterminal $C$ such that $S \\to a\\,C$, $C \\to A \\mid B$, $A \\to x$, and $B \\to y$. Use the Earley parsing algorithm with the augmented start symbol $S_{0} \\to S$ to parse the input string $w = a\\,x$. The Earley algorithm constructs a sequence of sets (often called a chart), where the set at position $i$ is denoted $E_{i}$ and contains Earley items of the form $[A \\to \\alpha\\,\\bullet\\,\\beta, j]$, meaning a production $A \\to \\alpha\\beta$ with the dot indicating the current point in the right-hand side and $j$ the origin index.\n\nDefine the following two measurements:\n- The total prediction count for a grammar on input $w$ is the number of distinct items added by the predictor operation across all $E_{i}$ (counting each distinct item only once overall).\n- The total item growth for a grammar on input $w$ is the sum over all positions $i$ of the cardinalities $|E_{i}|$ after the chart at position $|w|$ is fully closed under predictor, scanner, and completer (with duplicates eliminated within each $E_{i}$).\n\nCompute the ratio $R$ of the total item growth for $G^{\\mathrm{lf}}$ to the total item growth for $G$ on the input $w = a\\,x$. Express your final $R$ as a simplified exact fraction. No rounding is required.",
            "solution": "The problem asks for the ratio of the total item growth for a left-factored context-free grammar, $G^{\\mathrm{lf}}$, to that of the original grammar, $G$, when parsing the input string $w = a\\,x$ using the Earley algorithm. The total item growth is defined as the sum of the cardinalities of all Earley sets, $\\sum_{i=0}^{|w|} |E_i|$.\n\nThe Earley algorithm constructs a series of sets, $E_0, E_1, \\dots, E_n$, for an input string of length $n$. Each set $E_i$ contains Earley items of the form $[A \\to \\alpha \\bullet \\beta, j]$, which indicates that we are at position $i$ in the input, matching a production $A \\to \\alpha \\beta$, and the part of the rule corresponding to $\\alpha$ has matched the input substring from position $j$ to $i$.\n\nThe algorithm uses three main operations to fill the sets:\n1.  **Predictor**: If $[A \\to \\alpha \\bullet B \\beta, j]$ is in $E_i$ and $B$ is a nonterminal, for each production $B \\to \\gamma$, add the item $[B \\to \\bullet \\gamma, i]$ to $E_i$.\n2.  **Scanner**: If $[A \\to \\alpha \\bullet a \\beta, j]$ is in $E_i$ and the next input symbol is $a$, add the item $[A \\to \\alpha a \\bullet \\beta, j]$ to $E_{i+1}$.\n3.  **Completer**: If $[B \\to \\gamma \\bullet, k]$ is in $E_i$, then for every item in $E_k$ of the form $[A \\to \\alpha \\bullet B \\beta, j]$, add the new item $[A \\to \\alpha B \\bullet \\beta, j]$ to $E_i$.\n\nWe will apply this algorithm to both grammars for the input string $w = a\\,x$, which has length $|w|=2$. We will construct sets $E_0, E_1,$ and $E_2$. The augmented start rule is $S_0 \\to S$.\n\n### Part 1: Analysis of Grammar $G$\n\nThe grammar $G$ is given by the productions:\n$S_0 \\to S$\n$S \\to a\\,A \\mid a\\,B$\n$A \\to x$\n$B \\to y$\n\n**Construction of the Earley Chart for $G$:**\n\n**Set $E_0$:**\n1.  Initialize with the augmented start rule: Add $[S_0 \\to \\bullet S, 0]$ to $E_0$.\n2.  **Predictor**: From $[S_0 \\to \\bullet S, 0]$, the dot is before a nonterminal $S$. We add all productions for $S$ with origin index $0$.\n    - Add $[S \\to \\bullet a A, 0]$ to $E_0$.\n    - Add $[S \\to \\bullet a B, 0]$ to $E_0$.\nThe new items have a dot before a terminal $a$, so no more predictions are made.\nThe final set is $E_0 = \\{ [S_0 \\to \\bullet S, 0], [S \\to \\bullet a A, 0], [S \\to \\bullet a B, 0] \\}$.\nThe cardinality is $|E_0| = 3$.\n\n**Set $E_1$:**\nThe next input symbol is $a$.\n1.  **Scanner**: We scan the items in $E_0$ for a dot before $a$.\n    - From $[S \\to \\bullet a A, 0]$, we scan $a$ and add $[S \\to a \\bullet A, 0]$ to $E_1$.\n    - From $[S \\to \\bullet a B, 0]$, we scan $a$ and add $[S \\to a \\bullet B, 0]$ to $E_1$.\n2.  **Predictor**: We close the set $E_1$.\n    - From $[S \\to a \\bullet A, 0]$, the dot is before $A$. We predict rules for $A$ with origin index $1$.\n        - Add $[A \\to \\bullet x, 1]$ to $E_1$.\n    - From $[S \\to a \\bullet B, 0]$, the dot is before $B$. We predict rules for $B$ with origin index $1$.\n        - Add $[B \\to \\bullet y, 1]$ to $E_1$.\nThe new items have dots before terminals, so no more predictions.\nThe final set is $E_1 = \\{ [S \\to a \\bullet A, 0], [S \\to a \\bullet B, 0], [A \\to \\bullet x, 1], [B \\to \\bullet y, 1] \\}$.\nThe cardinality is $|E_1| = 4$.\n\n**Set $E_2$:**\nThe next input symbol is $x$.\n1.  **Scanner**: We scan items in $E_1$ for a dot before $x$.\n    - From $[A \\to \\bullet x, 1]$, we scan $x$ and add $[A \\to x \\bullet, 1]$ to $E_2$.\n2.  **Completer**: We close the set $E_2$. The new item $[A \\to x \\bullet, 1]$ is a completed item with origin index $k=1$. We look for items in $E_1$ of the form $[X \\to \\alpha \\bullet A \\beta, j]$.\n    - We find $[S \\to a \\bullet A, 0]$ in $E_1$. We add $[S \\to a A \\bullet, 0]$ to $E_2$.\n3.  **Completer**: The new item $[S \\to a A \\bullet, 0]$ is a completed item with origin index $k=0$. We look for items in $E_0$ of the form $[X \\to \\alpha \\bullet S \\beta, j]$.\n    - We find $[S_0 \\to \\bullet S, 0]$ in $E_0$. We add $[S_0 \\to S \\bullet, 0]$ to $E_2$.\nThe set is now closed.\nThe final set is $E_2 = \\{ [A \\to x \\bullet, 1], [S \\to a A \\bullet, 0], [S_0 \\to S \\bullet, 0] \\}$.\nThe cardinality is $|E_2| = 3$.\n\n**Total Item Growth for $G$:**\nThe total item growth is the sum of the cardinalities:\n$\\text{Total}(G) = |E_0| + |E_1| + |E_2| = 3 + 4 + 3 = 10$.\n\n### Part 2: Analysis of Grammar $G^{\\mathrm{lf}}$\n\nThe left-factored grammar $G^{\\mathrm{lf}}$ is given by:\n$S_0 \\to S$\n$S \\to a\\,C$\n$C \\to A \\mid B$\n$A \\to x$\n$B \\to y$\n\n**Construction of the Earley Chart for $G^{\\mathrm{lf}}$:**\n\n**Set $E_0$:**\n1.  Initialize with the augmented start rule: Add $[S_0 \\to \\bullet S, 0]$ to $E_0$.\n2.  **Predictor**: From $[S_0 \\to \\bullet S, 0]$, predict all productions for $S$.\n    - Add $[S \\to \\bullet a C, 0]$ to $E_0$.\nThe new item has a dot before a terminal, so no more predictions.\nThe final set is $E_0 = \\{ [S_0 \\to \\bullet S, 0], [S \\to \\bullet a C, 0] \\}$.\nThe cardinality is $|E_0| = 2$.\n\n**Set $E_1$:**\nThe next input symbol is $a$.\n1.  **Scanner**: Scan items in $E_0$ for a dot before $a$.\n    - From $[S \\to \\bullet a C, 0]$, scan $a$ and add $[S \\to a \\bullet C, 0]$ to $E_1$.\n2.  **Predictor**: Close $E_1$.\n    - From $[S \\to a \\bullet C, 0]$, predict rules for $C$ with origin index $1$.\n        - Add $[C \\to \\bullet A, 1]$ to $E_1$.\n        - Add $[C \\to \\bullet B, 1]$ to $E_1$.\n    - From the new item $[C \\to \\bullet A, 1]$, predict rules for $A$ with origin index $1$.\n        - Add $[A \\to \\bullet x, 1]$ to $E_1$.\n    - From the new item $[C \\to \\bullet B, 1]$, predict rules for $B$ with origin index $1$.\n        - Add $[B \\to \\bullet y, 1]$ to $E_1$.\nThe new items have dots before terminals, so no more predictions.\nThe final set is $E_1 = \\{ [S \\to a \\bullet C, 0], [C \\to \\bullet A, 1], [C \\to \\bullet B, 1], [A \\to \\bullet x, 1], [B \\to \\bullet y, 1] \\}$.\nThe cardinality is $|E_1| = 5$.\n\n**Set $E_2$:**\nThe next input symbol is $x$.\n1.  **Scanner**: Scan items in $E_1$ for a dot before $x$.\n    - From $[A \\to \\bullet x, 1]$, scan $x$ and add $[A \\to x \\bullet, 1]$ to $E_2$.\n2.  **Completer**: Close $E_2$. The new item $[A \\to x \\bullet, 1]$ is a completed item ($k=1$). Look in $E_1$ for items of the form $[X \\to \\alpha \\bullet A \\beta, j]$.\n    - We find $[C \\to \\bullet A, 1]$ in $E_1$. Add $[C \\to A \\bullet, 1]$ to $E_2$.\n3.  **Completer**: The new item $[C \\to A \\bullet, 1]$ is a completed item ($k=1$). Look in $E_1$ for items of the form $[X \\to \\alpha \\bullet C \\beta, j]$.\n    - We find $[S \\to a \\bullet C, 0]$ in $E_1$. Add $[S \\to a C \\bullet, 0]$ to $E_2$.\n4.  **Completer**: The new item $[S \\to a C \\bullet, 0]$ is a completed item ($k=0$). Look in $E_0$ for items of the form $[X \\to \\alpha \\bullet S \\beta, j]$.\n    - We find $[S_0 \\to \\bullet S, 0]$ in $E_0$. Add $[S_0 \\to S \\bullet, 0]$ to $E_2$.\nThe set is now closed.\nThe final set is $E_2 = \\{ [A \\to x \\bullet, 1], [C \\to A \\bullet, 1], [S \\to a C \\bullet, 0], [S_0 \\to S \\bullet, 0] \\}$.\nThe cardinality is $|E_2| = 4$.\n\n**Total Item Growth for $G^{\\mathrm{lf}}$:**\nThe total item growth is the sum of the cardinalities:\n$\\text{Total}(G^{\\mathrm{lf}}) = |E_0| + |E_1| + |E_2| = 2 + 5 + 4 = 11$.\n\n### Part 3: Compute the Ratio $R$\n\nThe problem asks for the ratio of the total item growth for $G^{\\mathrm{lf}}$ to the total item growth for $G$.\n$R = \\frac{\\text{Total item growth for } G^{\\mathrm{lf}}}{\\text{Total item growth for } G}$\n$R = \\frac{11}{10}$.\n\nThis ratio is already a simplified exact fraction.",
            "answer": "$$\\boxed{\\frac{11}{10}}$$"
        },
        {
            "introduction": "The ultimate test of understanding is to build it yourself. This final hands-on practice challenges you to implement the Earley parser from first principles and instrument its core operations (). By adding performance counters for the predictor, scanner, and completer, you will be able to profile the algorithm's behavior on various grammars and identify which phases become 'hotspots' under different conditions, such as ambiguity or left recursion.",
            "id": "3639843",
            "problem": "You are to implement and instrument an Earley parsing algorithm for context-free grammars (CFGs), measuring the performance contribution of the three fundamental Earley operations: predictor, scanner, and completer. The goal is to derive, from first principles of compiler theory, counters that quantify how often each operation contributes unique state insertions to the chart during parsing, identify hotspots, and decide whether the input string is in the language defined by the grammar.\n\nFoundational base: Use the standard formalization of a context-free grammar as $G = (N, \\Sigma, P, S)$, where $N$ is a finite set of non-terminals, $\\Sigma$ is a finite set of terminals, $P$ is a finite set of productions of the form $A \\rightarrow \\alpha$ with $A \\in N$ and $\\alpha \\in (N \\cup \\Sigma)^\\ast$, and $S \\in N$ is the start symbol. The Earley parser maintains a sequence of chart sets $D_0, D_1, \\dots, D_n$ for an input of length $n$, where each element (an item) is an Earley state of the form $(p, \\cdot, i)$ representing a production index $p$, a dot position $\\cdot$ indicating how many symbols of the right-hand side have been recognized, and an origin position $i$ where this production began. The three operations are defined as follows:\n- Predictor: When an item expects a non-terminal $B$ next at chart position $i$, add items for all productions $B \\rightarrow \\gamma$ with dot at position $0$ and origin $i$ into $D_i$.\n- Scanner: When an item expects a terminal $a$ next and the next input symbol equals $a$ at position $i$, advance the item by one symbol into $D_{i+1}$.\n- Completer: When an item finishes a production $A \\rightarrow \\gamma$ at chart position $j$ with origin $i$, advance all items in $D_i$ that were waiting for $A$ into $D_j$.\n\nInstrumentation requirement: Count only successful insertions of new, unique items into chart sets caused by each operation. That is, increment the predictor counter when a predictor step inserts a previously unseen item into $D_i$, increment the scanner counter when a scanner step inserts a previously unseen item into $D_{i+1}$, and increment the completer counter when a completer step inserts a previously unseen item into $D_j$. Initialization of $D_0$ with items for the start symbol $S$ is not attributed to any of the three counters.\n\nAcceptance criterion: The input is accepted if and only if $D_n$ contains some completed item for a production whose left-hand side is the start symbol $S$ and whose origin is $0$.\n\nHotspot identification: Define the hotspot phase as the phase with the largest counter among predictor, scanner, and completer. In case of a tie, choose the smallest code by the following mapping: predictor $\\mapsto$ $0$, scanner $\\mapsto$ $1$, completer $\\mapsto$ $2$.\n\nTest suite: Your program must build the following grammars and run them on the specified input strings. Tokens are single characters, and $\\varepsilon$ denotes the empty string.\n\n- Test case $1$ (ambiguous balanced parentheses with empty string allowed):\n  - Non-terminals: $N = \\{ S \\}$, start $S$.\n  - Terminals: $\\Sigma = \\{ ( , ) \\}$.\n  - Productions $P$:\n    - $S \\rightarrow S \\, S$\n    - $S \\rightarrow ( \\, S \\, )$\n    - $S \\rightarrow \\varepsilon$\n  - Input string: $\\text{\"(()())\"}$.\n\n- Test case $2$ (Kleene star of $a$):\n  - Non-terminals: $N = \\{ S \\}$, start $S$.\n  - Terminals: $\\Sigma = \\{ a \\}$.\n  - Productions $P$:\n    - $S \\rightarrow a \\, S$\n    - $S \\rightarrow \\varepsilon$\n  - Input string: $\\text{\"aaaaa\"}$ (length $5$).\n\n- Test case $3$ (left-recursive addition over a sequence of $d$ tokens representing digits):\n  - Non-terminals: $N = \\{ S, D \\}$, start $S$.\n  - Terminals: $\\Sigma = \\{ +, d \\}$.\n  - Productions $P$:\n    - $S \\rightarrow S \\, + \\, D$\n    - $S \\rightarrow D$\n    - $D \\rightarrow d \\, D$\n    - $D \\rightarrow d$\n  - Input string: $\\text{\"ddd+dd\"}$.\n\n- Test case $4$ (non-accepting input):\n  - Non-terminals: $N = \\{ S \\}$, start $S$.\n  - Terminals: $\\Sigma = \\{ a, b \\}$.\n  - Productions $P$:\n    - $S \\rightarrow a \\, b$\n  - Input string: $\\text{\"ac\"}$.\n\nFinal output specification: Your program should produce a single line containing a comma-separated nested list, one inner list per test case, with the five integers in order: predictor count, scanner count, completer count, acceptance flag, hotspot code. For example, the format is $[ [ p_1 , s_1 , c_1 , a_1 , h_1 ] , [ p_2 , s_2 , c_2 , a_2 , h_2 ] , [ p_3 , s_3 , c_3 , a_3 , h_3 ] , [ p_4 , s_4 , c_4 , a_4 , h_4 ] ]$, where each $p_k$, $s_k$, $c_k$, $a_k$, and $h_k$ is an integer as defined above. There must be no spaces or additional text, and only this single line should be printed.\n\nAnswer types: The outputs for all test cases must be integers aggregated into the specified nested list. No external input is allowed; all grammars and inputs must be encoded within the program.\n\nDesign for coverage:\n- Test case $1$ exercises ambiguity and $\\varepsilon$-productions, stressing predictor and completer.\n- Test case $2$ exercises heavy scanning with simple recursion, stressing scanner.\n- Test case $3$ exercises left recursion and mixed terminal/non-terminal transitions, stressing all phases.\n- Test case $4$ is a rejection path, checking correctness of acceptance and counts near mismatch boundaries.",
            "solution": "The problem requires the implementation and instrumentation of an Earley parsing algorithm for context-free grammars. The solution must correctly parse given input strings against specified grammars, count the number of productive operations for the predictor, scanner, and completer phases, determine if the string is accepted, and identify the performance hotspot.\n\n### Foundational Principles of Earley Parsing\n\nThe Earley algorithm is a chart parsing algorithm for context-free grammars that can parse any context-free language. Its significance lies in its ability to handle all context-free grammars, including ambiguous and left-recursive ones, which pose problems for simpler top-down ($LL$) or bottom-up ($LR$) parsers. The algorithm operates by systematically building a sequence of chart sets, denoted $D_0, D_1, \\dots, D_n$, for an input string of length $n$.\n\nA grammar is formally defined as a $4$-tuple $G = (N, \\Sigma, P, S)$, where $N$ is the set of non-terminals, $\\Sigma$ is the set of terminals, $P$ is the set of production rules, and $S$ is the start symbol.\n\nEach chart set $D_k$ contains a collection of items (or states). An item is of the form $(A \\rightarrow \\alpha \\cdot \\beta, j)$, where $A \\rightarrow \\alpha \\beta$ is a production in $P$, the dot (`$\\cdot$`) indicates the current position in recognizing the production's right-hand side, and $j$ is the origin index in the input string where the matching for this production began. An item $(A \\rightarrow \\alpha \\cdot \\beta, j)$ in chart set $D_k$ signifies that the input substring from index $j$ to $k$ ($w_j \\dots w_{k-1}$) can be derived from $\\alpha$.\n\nThe algorithm proceeds by populating the chart sets $D_0, \\dots, D_n$ using three fundamental operations:\n\n1.  **Predictor (Top-Down Inference)**: The predictor is a top-down step. If the parser is at position $k$ and an item $(A \\rightarrow \\alpha \\cdot B \\beta, j)$ exists in $D_k$, it means we expect to see a sequence of symbols derivable from the non-terminal $B$ next. The predictor adds items for all productions of $B$ to the same chart set $D_k$. Specifically, for each production $B \\rightarrow \\gamma$, it adds the item $(B \\rightarrow \\cdot \\gamma, k)$ to $D_k$. This new item has its origin at the current position $k$, as we are just starting to look for a derivation of $B$.\n\n2.  **Scanner (Input Consumption)**: The scanner is the operation that connects the parser to the input string. If an item $(A \\rightarrow \\alpha \\cdot a \\beta, j)$ is in $D_k$, where $a$ is a terminal symbol, the scanner checks if the next input symbol, $w_k$, is equal to $a$. If they match, the scanner consumes the input symbol and adds a new, advanced item $(A \\rightarrow \\alpha a \\cdot \\beta, j)$ to the next chart set, $D_{k+1}$. This signifies that we have successfully matched another terminal from the input.\n\n3.  **Completer (Bottom-Up Recognition)**: The completer is a bottom-up step that is triggered when a production is fully recognized. If an item $(B \\rightarrow \\gamma \\cdot, j)$ is in $D_k$, it means we have successfully parsed a substring corresponding to the non-terminal $B$, which started at position $j$ and ended at position $k$. The completer then finds all items in the origin chart set $D_j$ that were waiting for this $B$. For each such item $(A \\rightarrow \\alpha \\cdot B \\beta, i)$ in $D_j$, the completer adds a new, advanced item $(A \\rightarrow \\alpha B \\cdot \\beta, i)$ to the current chart set $D_k$. This action effectively \"completes\" the pending parse that was waiting on $B$.\n\n### Algorithmic Implementation and Instrumentation\n\nThe implementation proceeds as follows:\nFirst, a chart of $n+1$ sets, $D_0, \\dots, D_n$, is initialized. $D_0$ is seeded with items $(S \\rightarrow \\cdot \\gamma, 0)$ for all productions of the start symbol $S$. This initialization is not counted by the instrumented counters.\n\nThe algorithm then iterates from $k = 0$ to $n$. For each $k$, the chart set $D_k$ is \"closed\" by repeatedly applying the predictor and completer operations to all items in $D_k$ until no new items can be added. This is managed using a worklist approach, where we iterate through the items in $D_k$, and any new items generated by the predictor or completer are added to the end of the list to be processed in the same pass.\n\nAfter $D_k$ is closed, and if $k < n$, the scanner operation is applied. It iterates through all items in $D_k$ and, for those expecting a terminal that matches the input symbol $w_k$, adds an advanced item to the next chart set, $D_{k+1}$.\n\nA critical requirement is the instrumentation: we must count the number of *unique* state insertions for each of the three operations. This is achieved by maintaining each chart set $D_k$ as a set data structure. Before adding a new item, we check if it already exists in the target set. If the item is new, it is added, and the corresponding counter ($predictor\\_count$, $scanner\\_count$, or $completer\\_count$) is incremented by $1$. This ensures the counters measure productive work rather than redundant computations.\n\n### Acceptance and Hotspot Analysis\n\nUpon completion of the final chart set, $D_n$, the input string is accepted if and only if $D_n$ contains at least one item of the form $(S \\rightarrow \\gamma \\cdot, 0)$. This indicates that a full derivation from the start symbol $S$ has been found that spans the entire input string from origin $0$ to the end $n$.\n\nThe performance hotspot is identified by finding the maximum value among the three counters: $p$ (predictor), $s$ (scanner), and $c$ (completer). A tie-breaking rule specifies that in case of a tie, the phase with the smallest integer code (predictor $\\mapsto 0$, scanner $\\mapsto 1$, completer $\\mapsto 2$) is chosen.\n\nThe solution is encapsulated in a C program that defines the necessary data structures for grammars, items, and chart sets, implements the parsing logic, and runs the four specified test cases, producing the final output in the required format.",
            "answer": "```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\n#define bool int\n#define true 1\n#define false 0\n\n// --- Constants and Data Structures ---\n\n#define MAX_SYMBOLS 16\n#define MAX_NON_TERMINALS 4\n#define MAX_PRODUCTIONS 10\n#define MAX_RHS_LEN 4\n#define MAX_INPUT_LEN 32\n#define MAX_CHART_ITEMS 256\n\n// Represents a production rule item in a chart set (e.g., A -> a . B c, j)\ntypedef struct {\n    int prod_idx; // Index into the grammar's production array\n    int dot_pos;  // Position of the dot in the RHS\n    int origin;   // Starting position in the input string\n} Item;\n\n// Represents a chart set (D_k)\ntypedef struct {\n    Item items[MAX_CHART_ITEMS];\n    int count;\n} StateSet;\n\n// Represents a production rule (e.g., A -> B C)\ntypedef struct {\n    int lhs;            // LHS non-terminal symbol ID\n    int rhs[MAX_RHS_LEN]; // Array of RHS symbol IDs\n    int rhs_len;        // Length of the RHS\n} Production;\n\n// Represents a context-free grammar\ntypedef struct {\n    int num_non_terminals;\n    int num_symbols;\n    int start_symbol;\n    Production productions[MAX_PRODUCTIONS];\n    int num_productions;\n} Grammar;\n\n// Represents the results for a single test case\ntypedef struct {\n    long p_count;\n    long s_count;\n    long c_count;\n    int accepted;\n    int hotspot;\n} Result;\n\n// Represents a full test case\ntypedef struct {\n    Grammar grammar;\n    const char* input;\n} TestCase;\n\n// --- Symbol Mappings ---\n\n// Unified symbol table for all test cases\nenum Symbol {\n    // Non-terminals (must be first and contiguous)\n    SYM_S, SYM_D,\n    // Terminals\n    SYM_LPAREN, SYM_RPAREN, SYM_A, SYM_PLUS, SYM_D_TERM, SYM_B, SYM_C_TERM,\n    // Special\n    SYM_INVALID\n};\n\nint char_to_symbol(char c) {\n    switch (c) {\n        case 'S': return SYM_S;\n        case 'D': return SYM_D;\n        case '(': return SYM_LPAREN;\n        case ')': return SYM_RPAREN;\n        case 'a': return SYM_A;\n        case '+': return SYM_PLUS;\n        case 'd': return SYM_D_TERM;\n        case 'b': return SYM_B;\n        case 'c': return SYM_C_TERM;\n        default:  return SYM_INVALID;\n    }\n}\n\n// --- Core Parser Logic ---\n\n// Adds an item to a state set if it's not already present.\n// Returns true if the item was added, false otherwise.\nbool add_to_set(StateSet* set, Item new_item) {\n    for (int i = 0; i < set->count; ++i) {\n        if (set->items[i].prod_idx == new_item.prod_idx &&\n            set->items[i].dot_pos == new_item.dot_pos &&\n            set->items[i].origin == new_item.origin) {\n            return false; // Item already exists\n        }\n    }\n    if (set->count < MAX_CHART_ITEMS) {\n        set->items[set->count++] = new_item;\n        return true;\n    }\n    // This should not happen with adequate MAX_CHART_ITEMS\n    fprintf(stderr, \"Error: Chart set capacity exceeded.\\n\");\n    exit(EXIT_FAILURE);\n}\n\n// The main Earley parser function\nResult run_earley(const Grammar* grammar, const char* input) {\n    int n = strlen(input);\n    if (n > MAX_INPUT_LEN) {\n        fprintf(stderr, \"Error: Input length exceeds MAX_INPUT_LEN.\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    StateSet* chart = calloc(n + 1, sizeof(StateSet));\n    if (!chart) {\n        fprintf(stderr, \"Error: Failed to allocate chart.\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    Result result = {0, 0, 0, 0, 0};\n\n    // Initialization: Add start symbol productions to chart[0]\n    for (int i = 0; i < grammar->num_productions; ++i) {\n        if (grammar->productions[i].lhs == grammar->start_symbol) {\n            Item start_item = {i, 0, 0};\n            add_to_set(&chart[0], start_item);\n        }\n    }\n\n    // Main loop: Iterate through input positions\n    for (int i = 0; i <= n; ++i) {\n        int current_item_idx = 0;\n        while (current_item_idx < chart[i].count) {\n            Item current_item = chart[i].items[current_item_idx];\n            current_item_idx++;\n            \n            const Production* prod = &grammar->productions[current_item.prod_idx];\n\n            if (current_item.dot_pos < prod->rhs_len) { // Incomplete item\n                int next_symbol = prod->rhs[current_item.dot_pos];\n                if (next_symbol < grammar->num_non_terminals) { // Non-terminal: PREDICTOR\n                    for (int p_idx = 0; p_idx < grammar->num_productions; ++p_idx) {\n                        if (grammar->productions[p_idx].lhs == next_symbol) {\n                            Item new_item = {p_idx, 0, i};\n                            if (add_to_set(&chart[i], new_item)) {\n                                result.p_count++;\n                            }\n                        }\n                    }\n                }\n            } else { // Complete item: COMPLETER\n                int origin_chart_idx = current_item.origin;\n                for (int j = 0; j < chart[origin_chart_idx].count; ++j) {\n                    Item origin_item = chart[origin_chart_idx].items[j];\n                    const Production* origin_prod = &grammar->productions[origin_item.prod_idx];\n                    if (origin_item.dot_pos < origin_prod->rhs_len &&\n                        origin_prod->rhs[origin_item.dot_pos] == prod->lhs) {\n                        \n                        Item advanced_item = {origin_item.prod_idx, origin_item.dot_pos + 1, origin_item.origin};\n                        if (add_to_set(&chart[i], advanced_item)) {\n                            result.c_count++;\n                        }\n                    }\n                }\n            }\n        }\n\n        // SCANNER: Move items to the next chart set if applicable\n        if (i < n) {\n            int input_sym = char_to_symbol(input[i]);\n            for (int j = 0; j < chart[i].count; ++j) {\n                Item item = chart[i].items[j];\n                const Production* prod = &grammar->productions[item.prod_idx];\n                if (item.dot_pos < prod->rhs_len) {\n                    int next_sym = prod->rhs[item.dot_pos];\n                    if (next_sym >= grammar->num_non_terminals && next_sym == input_sym) {\n                        Item advanced_item = {item.prod_idx, item.dot_pos + 1, item.origin};\n                        if (add_to_set(&chart[i + 1], advanced_item)) {\n                            result.s_count++;\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    // Acceptance Check\n    for (int i = 0; i < chart[n].count; ++i) {\n        Item item = chart[n].items[i];\n        const Production* prod = &grammar->productions[item.prod_idx];\n        if (prod->lhs == grammar->start_symbol &&\n            item.dot_pos == prod->rhs_len &&\n            item.origin == 0) {\n            result.accepted = 1;\n            break;\n        }\n    }\n    \n    // Hotspot Identification\n    long counts[] = {result.p_count, result.s_count, result.c_count};\n    long max_count = counts[0];\n    int hotspot_code = 0;\n    for (int i = 1; i < 3; ++i) {\n        if (counts[i] > max_count) {\n            max_count = counts[i];\n            hotspot_code = i;\n        }\n    }\n    result.hotspot = hotspot_code;\n\n    free(chart);\n    return result;\n}\n\n// --- Main Program ---\nint main(void) {\n    // --- Grammar and Test Case Definitions ---\n    \n    // Test Case 1\n    Grammar g1 = {\n        .num_non_terminals = 1, .start_symbol = SYM_S, .num_productions = 3\n    };\n    g1.productions[0] = (Production){SYM_S, {SYM_S, SYM_S}, 2};\n    g1.productions[1] = (Production){SYM_S, {SYM_LPAREN, SYM_S, SYM_RPAREN}, 3};\n    g1.productions[2] = (Production){SYM_S, {}, 0}; // Epsilon production\n\n    // Test Case 2\n    Grammar g2 = {\n        .num_non_terminals = 1, .start_symbol = SYM_S, .num_productions = 2\n    };\n    g2.productions[0] = (Production){SYM_S, {SYM_A, SYM_S}, 2};\n    g2.productions[1] = (Production){SYM_S, {}, 0};\n\n    // Test Case 3\n    Grammar g3 = {\n        .num_non_terminals = 2, .start_symbol = SYM_S, .num_productions = 4\n    };\n    g3.productions[0] = (Production){SYM_S, {SYM_S, SYM_PLUS, SYM_D}, 3};\n    g3.productions[1] = (Production){SYM_S, {SYM_D}, 1};\n    g3.productions[2] = (Production){SYM_D, {SYM_D_TERM, SYM_D}, 2};\n    g3.productions[3] = (Production){SYM_D, {SYM_D_TERM}, 1};\n\n    // Test Case 4\n    Grammar g4 = {\n        .num_non_terminals = 1, .start_symbol = SYM_S, .num_productions = 1\n    };\n    g4.productions[0] = (Production){SYM_S, {SYM_A, SYM_B}, 2};\n    \n    TestCase test_cases[] = {\n        {g1, \"(()())\"},\n        {g2, \"aaaaa\"},\n        {g3, \"ddd+dd\"},\n        {g4, \"ac\"},\n    };\n\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    Result results[num_cases];\n\n    // --- Run All Test Cases ---\n    for (int i = 0; i < num_cases; ++i) {\n        results[i] = run_earley(&test_cases[i].grammar, test_cases[i].input);\n    }\n    \n    // --- Print Final Output ---\n    printf(\"[\");\n    for (int i = 0; i < num_cases; ++i) {\n        printf(\"[%ld,%ld,%ld,%d,%d]\",\n               results[i].p_count,\n               results[i].s_count,\n               results[i].c_count,\n               results[i].accepted,\n               results[i].hotspot);\n        if (i < num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n\n    return EXIT_SUCCESS;\n}\n```"
        }
    ]
}