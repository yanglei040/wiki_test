{
    "hands_on_practices": [
        {
            "introduction": "在数据分析中，线性回归是一项基本任务，我们常常需要从数据点中寻找最佳拟合线。当数据点的数量超过模型参数时，这便构成了一个超定线性系统。本练习将引导你使用SVD来解决这个问题，通过计算摩尔-彭若斯伪逆，你可以找到一个在最小二乘意义下的最优解。这个实践展示了如何运用SVD来解决数据建模中的一个核心问题，为你提供了强大的数值稳定工具。",
            "id": "2154101",
            "problem": "一位数据科学家正尝试使用一个形式为 $y = mx + c$ 的简单线性模型来建模特征 $x$ 和目标变量 $y$ 之间的关系，其中 $m$ 是斜率，$c$ 是y轴截距。为了确定 $m$ 和 $c$ 的最优值，该科学家收集了以下四个数据点 $(x, y)$: $(-2, -1)$、$(-1, 1)$、$(1, 2)$ 和 $(2, 4)$。\n\n每个数据点都提供了一个关联 $m$ 和 $c$ 的线性方程。由于数据点（方程）的数量多于未知参数的数量，这构成了一个形式为 $A\\mathbf{x} = \\mathbf{b}$ 的超定线性方程组，其中解向量为 $\\mathbf{x} = \\begin{pmatrix} m \\\\ c \\end{pmatrix}$。目标是找到 $\\mathbf{x}$ 的最小二乘解，该解能最小化模型的预测值与实际 $y$ 值之间差的平方和。\n\n你的任务是找到这个最小二乘解。你必须遵循一个特定的程序：首先，根据给定的数据构建矩阵 $A$ 和向量 $\\mathbf{b}$。然后，计算 $A$ 的奇异值分解 (SVD)。利用 SVD，找到 Moore-Penrose 伪逆 $A^\\dagger$。最后，计算最小二乘解向量 $\\mathbf{x} = A^\\dagger\\mathbf{b}$。\n\n请以单个闭式解析表达式的形式，提供斜率 $m$ 和 y 轴截距 $c$ 的值。",
            "solution": "我们将 $y$ 建模为 $y = mx + c$。对于每个数据点 $(x_{i},y_{i})$，这给出了 $m x_{i} + c = y_{i}$。根据给定的四个点，矩阵 $A$ 和向量 $\\mathbf{b}$ 为\n$$\nA = \\begin{pmatrix}\n-2  1 \\\\\n-1  1 \\\\\n1  1 \\\\\n2  1\n\\end{pmatrix},\\quad\n\\mathbf{b} = \\begin{pmatrix}\n-1 \\\\\n1 \\\\\n2 \\\\\n4\n\\end{pmatrix}.\n$$\n我们计算奇异值分解 $A = U \\Sigma V^{T}$。从 $A^{T}A$ 开始：\n$$\nA^{T}A = \\begin{pmatrix}\n\\sum x_{i}^{2}  \\sum x_{i} \\\\\n\\sum x_{i}  \\sum 1\n\\end{pmatrix}\n= \\begin{pmatrix}\n10  0 \\\\\n0  4\n\\end{pmatrix}.\n$$\n因此，$A^{T}A$ 的特征值为 $10$ 和 $4$，其特征向量由标准基给出，所以我们可以取\n$$\nV = \\begin{pmatrix}\n1  0 \\\\\n0  1\n\\end{pmatrix},\\qquad\n\\Sigma_{r} = \\begin{pmatrix}\n\\sqrt{10}  0 \\\\\n0  2\n\\end{pmatrix}.\n$$\n对于细SVD (thin SVD)，$U_{r}$ 的列 $u_{1}$ 和 $u_{2}$ 是通过对 $A$ 的列进行归一化得到的：\n$$\nu_{1} = \\frac{1}{\\sqrt{10}}\\begin{pmatrix}-2\\\\-1\\\\1\\\\2\\end{pmatrix},\\qquad\nu_{2} = \\frac{1}{2}\\begin{pmatrix}1\\\\1\\\\1\\\\1\\end{pmatrix},\n$$\n所以 $U_{r} = \\begin{pmatrix}u_{1}  u_{2}\\end{pmatrix}$。Moore-Penrose 伪逆为 $A^{\\dagger} = V \\Sigma_{r}^{-1} U_{r}^{T}$。最小二乘解为 $\\mathbf{x} = A^{\\dagger}\\mathbf{b} = V \\Sigma_{r}^{-1} U_{r}^{T}\\mathbf{b}$。我们首先计算投影：\n$$\nu_{1}^{T}\\mathbf{b} = \\frac{1}{\\sqrt{10}}\\big((-2)(-1)+(-1)(1)+(1)(2)+(2)(4)\\big) = \\frac{11}{\\sqrt{10}},\n$$\n$$\nu_{2}^{T}\\mathbf{b} = \\frac{1}{2}\\big((-1)+1+2+4\\big) = 3.\n$$\n因此，$U_r^T \\mathbf{b} = \\begin{pmatrix} \\frac{11}{\\sqrt{10}} \\\\ 3 \\end{pmatrix}$。\n最后，我们计算 $\\mathbf{x} = V \\Sigma_{r}^{-1} (U_{r}^{T}\\mathbf{b})$：\n$$\n\\mathbf{x} = \\begin{pmatrix}\n1  0 \\\\\n0  1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\frac{1}{\\sqrt{10}}  0 \\\\\n0  \\frac{1}{2}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\frac{11}{\\sqrt{10}} \\\\\n3\n\\end{pmatrix}\n= \\begin{pmatrix}\n1  0 \\\\\n0  1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\frac{11}{10} \\\\\n\\frac{3}{2}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\frac{11}{10} \\\\\n\\frac{3}{2}\n\\end{pmatrix}.\n$$\n因此，最小二乘斜率和截距为 $m = \\frac{11}{10}$ 和 $c = \\frac{3}{2}$。",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{11}{10} \\\\ \\frac{3}{2}\\end{pmatrix}}$$"
        },
        {
            "introduction": "在构建推荐系统时，一个核心挑战是预测用户对未曾评价过的项目的评分，这本质上是一个矩阵填充问题。奇异值分解(SVD)假设用户的偏好并非完全随机，而是由少数几个潜在因素主导，因此可以用一个低秩矩阵来近似。本练习通过一个简化的场景，向你展示如何利用SVD提取出的最主要信息（即最佳一秩近似）来预测缺失的数据。这个过程是许多协同过滤推荐算法背后核心思想的直观体现。",
            "id": "2154142",
            "problem": "在数据分析领域，特别是在推荐系统中，一个常见的任务是预测用户对他们尚未评价的项目的潜在评分。这可以通过填充用户-项目矩阵中的缺失条目来建模。\n\n考虑一个小的用户-项目评分矩阵 $R$，它表示两个用户（行）对三个不同项目（列）的评分。其中一个评分是未知的，用问号表示。\n\n$$\nR = \\begin{pmatrix}\n1  1  ? \\\\\n0  1  1\n\\end{pmatrix}\n$$\n\n一种估算缺失评分的标准方法是利用已知数据的主导结构。步骤如下：\n1.  创建一个新矩阵 $A$，方法是取矩阵 $R$ 并将缺失的条目 '?' 替换为值 0。\n2.  确定矩阵 $A$ 的奇异值分解 (SVD)。\n3.  仅使用 SVD 中最重要的分量构建一个预测模型。该模型被称为 $A$ 的最佳秩一近似。\n\n遵循此步骤，确定缺失评分的预测数值。将您的答案表示为一个四舍五入到三位有效数字的实数。",
            "solution": "将缺失条目设为零的已知条目矩阵是\n$$\nA=\\begin{pmatrix}\n1  1  0\\\\\n0  1  1\n\\end{pmatrix}.\n$$\n$A$ 的 SVD 最佳秩一近似为 $\\sigma_{1} u_{1} v_{1}^{T}$，其中 $\\sigma_{1}$ 是最大的奇异值，$u_{1}, v_{1}$ 是对应的左、右奇异向量。\n\n计算 $A A^{T}$：\n$$\nA A^{T}=\n\\begin{pmatrix}\n1  1  0\\\\\n0  1  1\n\\end{pmatrix}\n\\begin{pmatrix}\n1  0\\\\\n1  1\\\\\n0  1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2  1\\\\\n1  2\n\\end{pmatrix}.\n$$\n从以下公式求其特征值\n$$\n\\det\\!\\left(\\begin{pmatrix}2  1\\\\ 1  2\\end{pmatrix}-\\lambda I\\right)\n=\\det\\!\\begin{pmatrix}2-\\lambda  1\\\\ 1  2-\\lambda\\end{pmatrix}\n=(2-\\lambda)^{2}-1=\\lambda^{2}-4\\lambda+3=0,\n$$\n解得 $\\lambda_{1}=3$ 和 $\\lambda_{2}=1$。因此，奇异值为 $\\sigma_{1}=\\sqrt{3}$ 和 $\\sigma_{2}=1$。\n\n对于 $\\lambda_{1}=3$，$A A^{T}$ 的一个特征向量满足\n$$\n\\begin{pmatrix}-1  1\\\\ 1  -1\\end{pmatrix}u=0 \\quad\\Rightarrow\\quad u\\propto \\begin{pmatrix}1\\\\ 1\\end{pmatrix}.\n$$\n归一化得到\n$$\nu_{1}=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1\\\\ 1\\end{pmatrix}.\n$$\n对应的右奇异向量是\n$$\nv_{1}=\\frac{1}{\\sigma_{1}}A^{T}u_{1}\n=\\frac{1}{\\sqrt{3}}\n\\begin{pmatrix}\n1  0\\\\\n1  1\\\\\n0  1\n\\end{pmatrix}\n\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1\\\\ 1\\end{pmatrix}\n=\\frac{1}{\\sqrt{6}}\\begin{pmatrix}1\\\\ 2\\\\ 1\\end{pmatrix}.\n$$\n因此，最佳秩一近似是\n$$\nA_{1}=\\sigma_{1} u_{1} v_{1}^{T}=\\sqrt{3}\\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1\\\\ 1\\end{pmatrix}\\right)\\left(\\frac{1}{\\sqrt{6}}\\begin{pmatrix}1  2  1\\end{pmatrix}\\right)\n=\\frac{1}{2}\\begin{pmatrix}1  2  1\\\\ 1  2  1\\end{pmatrix}.\n$$\n预测的缺失条目是 $A_{1}$ 的 $(1,3)$ 元素：\n$$\n(A_{1})_{1,3}=\\sigma_{1}\\,u_{1,1}\\,v_{1,3}\n=\\sqrt{3}\\cdot \\frac{1}{\\sqrt{2}}\\cdot \\frac{1}{\\sqrt{6}}\n=\\frac{\\sqrt{3}}{\\sqrt{12}}=\\frac{1}{2}=0.5.\n$$\n四舍五入到三位有效数字，预测值为 $0.500$。",
            "answer": "$$\\boxed{0.500}$$"
        },
        {
            "introduction": "真实世界的数据往往被稀疏但影响巨大的噪声或异常值所污染。从数据中分离出干净的低秩结构是数据预处理中的关键一步，而健壮主成分分析 (Robust PCA) 正是为此而生。本练习将带你体验一种名为“奇异值阈值” (SVT) 的核心操作，这是许多现代RPCA算法的基石。通过对奇异值进行软阈值化处理，我们可以有效地“压缩”数据矩阵的秩，从而在一次迭代中初步分离出低秩信号和稀疏噪声。这个实践让你一窥SVD在更高级的、基于优化的数据恢复技术中所扮演的关键角色。",
            "id": "2154141",
            "problem": "现代数据分析和机器学习中的一个基本技术是鲁棒主成分分析 (RPCA)，其目的是将数据矩阵 $M$ 分解为一个低秩分量 $L$ (代表主要结构) 和一个稀疏分量 $S$ (代表离群值或噪声)。许多 RPCA 算法中的一个关键步骤涉及应用奇异值阈值 (SVT) 算子。\n\nSVT 算子，对于给定的矩阵 $X$ 和阈值 $\\tau  0$，记为 $D_{\\tau}(X)$，其定义如下：\n1. 计算 $X$ 的奇异值分解 (SVD)：$X = U \\Sigma V^T$，其中 $\\Sigma$ 是由奇异值 $\\sigma_i$ 构成的对角矩阵。\n2. 对每个奇异值应用软阈值函数，形成一个新的对角矩阵 $\\Sigma_{\\tau}$：$(\\Sigma_{\\tau})_{ii} = \\max(0, \\sigma_i - \\tau)$。\n3. 重构矩阵：$D_{\\tau}(X) = U \\Sigma_{\\tau} V^T$。\n\n考虑一个被稀疏噪声污染的数据矩阵 $M$。我们希望执行一步恢复算法，通过计算 $L = D_{\\tau}(M)$ 来获得低秩分量 $L$ 的估计值。\n\n给定以下数据矩阵 $M$：\n$$\nM = \\begin{pmatrix} 6.0  1.0  7.0 \\\\ 2.0  8.0  0.0 \\\\ 7.0  0.0  7.0 \\end{pmatrix}\n$$\n该矩阵的 SVD 分解为 $M = U \\Sigma V^T$，其奇异值为 $\\sigma_1 = 12.0$，$\\sigma_2 = 6.0$ 和 $\\sigma_3 = 5.0$。相应的正交矩阵 $U$ 和 $V^T$ 如下：\n$$\nU = \\begin{pmatrix} -0.6667  -0.3333  -0.6667 \\\\ -0.3333  0.6667  0.6667 \\\\ -0.6667  0.6667  -0.3333 \\end{pmatrix}\n$$\n$$\nV^T = \\begin{pmatrix} -0.6667  -0.3333  -0.6667 \\\\ -0.6667  0.6667  -0.3333 \\\\ -0.3333  0.6667  0.6667 \\end{pmatrix}\n$$\n使用阈值 $\\tau = 8.0$，计算估计的低秩矩阵 $L = D_{\\tau}(M)$。将您的答案表示为一个矩阵，其中每个元素四舍五入到三位有效数字。",
            "solution": "我们使用奇异值阈值算子的定义：对于 $M=U\\Sigma V^{T}$ 和阈值 $\\tau0$，\n$$\nD_{\\tau}(M)=U\\,\\Sigma_{\\tau}\\,V^{T},\\quad \\text{with}\\quad \\Sigma_{\\tau}=\\operatorname{diag}\\big(\\max(0,\\sigma_{i}-\\tau)\\big).\n$$\n给定奇异值 $\\sigma_{1}=12.0$，$\\sigma_{2}=6.0$，$\\sigma_{3}=5.0$ 和 $\\tau=8.0$，我们得到\n$$\n\\Sigma_{\\tau}=\\operatorname{diag}(12-8,\\max(0,6-8),\\max(0,5-8))=\\operatorname{diag}(4,0,0).\n$$\n因此，\n$$\nL=D_{\\tau}(M)=U\\,\\Sigma_{\\tau}\\,V^{T}=4\\,u_{1}v_{1}^{T},\n$$\n其中 $u_{1}$ 和 $v_{1}$ 分别是第一个左奇异向量和右奇异向量（即 $U$ 的第一列和 $V$ 的第一列，等价于 $V^{T}$ 的第一行的转置）。根据所给数据，\n$$\nu_{1}=\\begin{pmatrix}-0.6667\\\\ -0.3333\\\\ -0.6667\\end{pmatrix},\\qquad v_{1}=\\begin{pmatrix}-0.6667\\\\ -0.3333\\\\ -0.6667\\end{pmatrix}.\n$$\n逐项计算外积 $u_{1}v_{1}^{T}$：\n$$\nu_{1}v_{1}^{T}=\\begin{pmatrix}\n0.6667^{2}  0.6667\\cdot 0.3333  0.6667^{2}\\\\\n0.3333\\cdot 0.6667  0.3333^{2}  0.3333\\cdot 0.6667\\\\\n0.6667^{2}  0.6667\\cdot 0.3333  0.6667^{2}\n\\end{pmatrix}\n=\\begin{pmatrix}\n0.44448889  0.22221111  0.44448889\\\\\n0.22221111  0.11108889  0.22221111\\\\\n0.44448889  0.22221111  0.44448889\n\\end{pmatrix}.\n$$\n乘以 $4$ 得到\n$$\nL=4\\,u_{1}v_{1}^{T}=\\begin{pmatrix}\n1.77795556  0.88884444  1.77795556\\\\\n0.88884444  0.44435556  0.88884444\\\\\n1.77795556  0.88884444  1.77795556\n\\end{pmatrix}.\n$$\n将每个元素四舍五入到三位有效数字，得到\n$$\nL\\approx\\begin{pmatrix}\n1.78  0.889  1.78\\\\\n0.889  0.444  0.889\\\\\n1.78  0.889  1.78\n\\end{pmatrix}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}1.78  0.889  1.78 \\\\ 0.889  0.444  0.889 \\\\ 1.78  0.889  1.78\\end{pmatrix}}$$"
        }
    ]
}