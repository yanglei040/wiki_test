{
    "hands_on_practices": [
        {
            "introduction": "The first step in mastering incomplete factorizations is understanding the mechanics of their construction. This exercise provides a concrete, hands-on opportunity to compute the Incomplete Cholesky factorization with zero fill-in, IC(0). By applying the algorithm to a small, symmetric positive definite matrix, you will solidify your understanding of how the sparse approximate factor $\\tilde{L}$ is derived directly from the original matrix $A$ .",
            "id": "2179135",
            "problem": "In the field of numerical analysis, iterative methods are often used to solve large systems of linear equations of the form $Ax=b$. To accelerate the convergence of these methods, a preconditioner matrix $M$ is used, transforming the system into $M^{-1}Ax = M^{-1}b$. A good preconditioner $M$ should approximate $A$ while being easy to invert. For symmetric positive definite matrices $A$, a common choice for $M$ is $\\tilde{L}\\tilde{L}^T$, where $\\tilde{L}$ is an approximate Cholesky factor of $A$.\n\nThe Incomplete Cholesky factorization with zero fill-in, denoted IC(0), is one such method to find $\\tilde{L}$. It computes a lower triangular matrix whose sparsity pattern (the set of positions of its non-zero entries) is forced to be identical to the sparsity pattern of the lower triangular part of the original matrix $A$. That is, if $a_{ij}=0$ for $i > j$, then the corresponding entry $\\tilde{l}_{ij}$ in the factor $\\tilde{L}$ is also forced to be zero.\n\nConsider the symmetric positive definite matrix $A$ given by:\n$$\nA = \\begin{pmatrix}\n4 & -1 & 0 \\\\\n-1 & 4 & -1 \\\\\n0 & -1 & 4\n\\end{pmatrix}\n$$\nCompute the Incomplete Cholesky factor $\\tilde{L}$ for this matrix $A$ using the IC(0) procedure. Present your answer as a $3 \\times 3$ matrix with exact analytical values for its entries.",
            "solution": "We seek a lower triangular matrix $\\tilde{L}$ with the same sparsity pattern as the lower triangular part of $A$ such that $A \\approx \\tilde{L}\\tilde{L}^{T}$. For a symmetric positive definite tridiagonal matrix like $A$, the exact Cholesky factor has no additional fill beyond the first subdiagonal, so IC(0) coincides with the exact Cholesky factor subject to the pattern constraint. Therefore, we write\n$$\n\\tilde{L}=\\begin{pmatrix}\n\\ell_{11} & 0 & 0 \\\\\n\\ell_{21} & \\ell_{22} & 0 \\\\\n0 & \\ell_{32} & \\ell_{33}\n\\end{pmatrix},\n\\quad \\text{with } \\ell_{33}>0, \\ell_{22}>0, \\ell_{11}>0,\n$$\nand enforce $\\tilde{L}\\tilde{L}^{T}=A$ entrywise.\n\nFrom the $(1,1)$ entry:\n$$\n\\ell_{11}^{2}=4 \\;\\Rightarrow\\; \\ell_{11}=2.\n$$\nFrom the $(2,1)$ entry:\n$$\n\\ell_{21}\\ell_{11}=-1 \\;\\Rightarrow\\; \\ell_{21}=-\\frac{1}{2}.\n$$\nFrom the $(2,2)$ entry:\n$$\n\\ell_{21}^{2}+\\ell_{22}^{2}=4 \\;\\Rightarrow\\; \\ell_{22}^{2}=4-\\left(\\frac{1}{2}\\right)^{2}=\\frac{15}{4} \\;\\Rightarrow\\; \\ell_{22}=\\frac{\\sqrt{15}}{2}.\n$$\nFrom the $(3,1)$ entry, the pattern imposes $\\ell_{31}=0$, which matches $a_{31}=0$.\n\nFrom the $(3,2)$ entry:\n$$\n\\ell_{32}\\ell_{22}=-1 \\;\\Rightarrow\\; \\ell_{32}=-\\frac{1}{\\ell_{22}}=-\\frac{2}{\\sqrt{15}}.\n$$\nFrom the $(3,3)$ entry:\n$$\n\\ell_{32}^{2}+\\ell_{33}^{2}=4 \\;\\Rightarrow\\; \\ell_{33}^{2}=4-\\left(\\frac{2}{\\sqrt{15}}\\right)^{2}=4-\\frac{4}{15}=\\frac{56}{15} \\;\\Rightarrow\\; \\ell_{33}=\\sqrt{\\frac{56}{15}}=\\frac{2\\sqrt{14}}{\\sqrt{15}}.\n$$\n\nThus the IC(0) factor is\n$$\n\\tilde{L}=\\begin{pmatrix}\n2 & 0 & 0 \\\\\n-\\frac{1}{2} & \\frac{\\sqrt{15}}{2} & 0 \\\\\n0 & -\\frac{2}{\\sqrt{15}} & \\frac{2\\sqrt{14}}{\\sqrt{15}}\n\\end{pmatrix}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}\n2 & 0 & 0 \\\\\n-\\frac{1}{2} & \\frac{\\sqrt{15}}{2} & 0 \\\\\n0 & -\\frac{2}{\\sqrt{15}} & \\frac{2\\sqrt{14}}{\\sqrt{15}}\n\\end{pmatrix}}$$"
        },
        {
            "introduction": "Once an incomplete factorization preconditioner $M = \\tilde{L}\\tilde{U}$ has been computed, its true value lies in efficiently solving the preconditioning equation $Mz = r$ that arises within each step of an iterative method. This practice problem demonstrates this crucial application, shifting the focus from generation to usage . You will see how the triangular nature of the factors allows for a rapid solution via forward and backward substitution, the core of why these preconditioners accelerate convergence.",
            "id": "2179164",
            "problem": "In many numerical methods for solving large sparse linear systems of the form $Ax=b$, a preconditioner $M$ is used to transform the system into an equivalent one that has better properties for iterative solvers. A widely used class of preconditioners is based on Incomplete LU (ILU) factorization, which computes an approximate LU factorization of the matrix $A$.\n\nConsider a preconditioned system $Mz = r$, which arises as a subproblem within an iterative method. The preconditioner $M$ is given by the product of two matrices, $M = \\tilde{L}\\tilde{U}$, which are the factors obtained from a zero-fill-in Incomplete LU factorization, ILU(0).\n\nThe factors are given by:\n$$\n\\tilde{L} = \\begin{pmatrix} 1 & 0 & 0 \\\\ -2 & 1 & 0 \\\\ 0 & 3 & 1 \\end{pmatrix} \\quad \\text{and} \\quad \\tilde{U} = \\begin{pmatrix} 4 & 1 & 0 \\\\ 0 & 5 & -1 \\\\ 0 & 0 & 2 \\end{pmatrix}\n$$\nThe vector $r$ is given by:\n$$\nr = \\begin{pmatrix} 7 \\\\ -20 \\\\ -16 \\end{pmatrix}\n$$\nFind the solution vector $z = \\begin{pmatrix} z_1 \\\\ z_2 \\\\ z_3 \\end{pmatrix}$ to the system $\\tilde{L}\\tilde{U}z = r$.\n\nWhich of the following vectors represents the correct solution $z$?\n\nA) $z = \\begin{pmatrix} 2 \\\\ -1 \\\\ 1 \\end{pmatrix}$\n\nB) $z = \\begin{pmatrix} 7 \\\\ -6 \\\\ 2 \\end{pmatrix}$\n\nC) $z = \\begin{pmatrix} 3.15 \\\\ -5.6 \\\\ -8 \\end{pmatrix}$\n\nD) $z = \\begin{pmatrix} 3.15 \\\\ 0.7 \\\\ -10.1 \\end{pmatrix}$",
            "solution": "We must solve the preconditioned system $\\tilde{L}\\tilde{U}z=r$. Set $y=\\tilde{U}z$ so that we first solve the unit lower-triangular system $\\tilde{L}y=r$, then solve the upper-triangular system $\\tilde{U}z=y$.\n\nGiven\n$$\n\\tilde{L}=\\begin{pmatrix}1&0&0\\\\-2&1&0\\\\0&3&1\\end{pmatrix},\\quad\n\\tilde{U}=\\begin{pmatrix}4&1&0\\\\0&5&-1\\\\0&0&2\\end{pmatrix},\\quad\nr=\\begin{pmatrix}7\\\\-20\\\\-16\\end{pmatrix}.\n$$\n\nForward substitution for $\\tilde{L}y=r$, with $y=\\begin{pmatrix}y_{1}\\\\y_{2}\\\\y_{3}\\end{pmatrix}$:\n$$\ny_{1}=7,\n$$\n$$\n-2y_{1}+y_{2}=-20\\;\\Rightarrow\\;y_{2}=-20+2y_{1}=-20+14=-6,\n$$\n$$\n3y_{2}+y_{3}=-16\\;\\Rightarrow\\;y_{3}=-16-3y_{2}=-16-3(-6)=-16+18=2.\n$$\nThus\n$$\ny=\\begin{pmatrix}7\\\\-6\\\\2\\end{pmatrix}.\n$$\n\nBackward substitution for $\\tilde{U}z=y$, with $z=\\begin{pmatrix}z_{1}\\\\z_{2}\\\\z_{3}\\end{pmatrix}$:\n$$\n2z_{3}=y_{3}=2\\;\\Rightarrow\\;z_{3}=1,\n$$\n$$\n5z_{2}-z_{3}=y_{2}=-6\\;\\Rightarrow\\;5z_{2}-1=-6\\;\\Rightarrow\\;5z_{2}=-5\\;\\Rightarrow\\;z_{2}=-1,\n$$\n$$\n4z_{1}+z_{2}=y_{1}=7\\;\\Rightarrow\\;4z_{1}-1=7\\;\\Rightarrow\\;4z_{1}=8\\;\\Rightarrow\\;z_{1}=2.\n$$\nTherefore\n$$\nz=\\begin{pmatrix}2\\\\-1\\\\1\\end{pmatrix},\n$$\nwhich corresponds to option A.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "While incomplete factorization methods are powerful, the simplest algorithms are not foolproof and can fail even for well-behaved, non-singular matrices. This exercise challenges you to construct a matrix for which the standard, no-pivoting ILU(0) algorithm breaks down due to an attempted division by zero . Grappling with such edge cases is essential for appreciating the numerical stability issues in practical computation and understanding the motivation behind more robust factorization techniques.",
            "id": "2179162",
            "problem": "In numerical linear algebra, Incomplete LU (ILU) factorizations are often used as preconditioners for solving large, sparse linear systems via iterative methods. The simplest of these is the ILU(0) factorization, which seeks an approximate factorization $A \\approx LU$, where the lower triangular matrix $L$ and upper triangular matrix $U$ are constrained to have the same sparsity patterns as the lower and upper triangular parts of the original matrix $A$.\n\nConsider the application of the standard, no-pivoting ILU(0) algorithm to a dense $2 \\times 2$ matrix $A$. In this scenario, the procedure is identical to the standard LU decomposition algorithm. The process computes the entries of $L = \\begin{pmatrix} 1 & 0 \\\\ l_{21} & 1 \\end{pmatrix}$ and $U = \\begin{pmatrix} u_{11} & u_{12} \\\\ 0 & u_{22} \\end{pmatrix}$ sequentially. A key step involves computing the multiplier $l_{21}$, which requires division by an entry from $A$.\n\nYour task is to construct a non-singular $2 \\times 2$ matrix $A$ with integer entries for which this standard ILU(0) algorithm fails due to division by zero. Present your answer as a $2 \\times 2$ matrix.",
            "solution": "Let $A$ be a general $2 \\times 2$ matrix with integer entries,\n$$\nA=\\begin{pmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22}\n\\end{pmatrix}.\n$$\nThe standard no-pivoting LU (hence ILU(0) for dense $A$) computes\n$$\nU=\\begin{pmatrix}\nu_{11} & u_{12} \\\\\n0 & u_{22}\n\\end{pmatrix}, \\quad\nL=\\begin{pmatrix}\n1 & 0 \\\\\nl_{21} & 1\n\\end{pmatrix},\n$$\nwith the steps\n$$\nu_{11}=a_{11}, \\quad u_{12}=a_{12}, \\quad l_{21}=\\frac{a_{21}}{u_{11}}, \\quad u_{22}=a_{22}-l_{21}u_{12}.\n$$\nThe division in $l_{21}=\\dfrac{a_{21}}{u_{11}}$ fails if and only if $u_{11}=a_{11}=0$. To ensure $A$ is still nonsingular, we require $\\det(A)\\neq 0$. For a $2 \\times 2$ matrix,\n$$\n\\det(A)=a_{11}a_{22}-a_{12}a_{21}.\n$$\nIf $a_{11}=0$, then $\\det(A)=-a_{12}a_{21}$, which is nonzero whenever $a_{12}\\neq 0$ and $a_{21}\\neq 0$.\n\nChoose the integer matrix\n$$\nA=\\begin{pmatrix}\n0 & 1 \\\\\n1 & 0\n\\end{pmatrix}.\n$$\nThen\n$$\n\\det(A)=0\\cdot 0 - 1\\cdot 1 = -1 \\neq 0,\n$$\nso $A$ is nonsingular. However, the LU/ILU(0) step gives $u_{11}=a_{11}=0$ and thus\n$$\nl_{21}=\\frac{a_{21}}{u_{11}}=\\frac{1}{0},\n$$\nwhich is undefined. Therefore, the standard ILU(0) algorithm fails on this nonsingular integer matrix due to division by zero.",
            "answer": "$$\\boxed{\\begin{pmatrix}0 & 1 \\\\ 1 & 0\\end{pmatrix}}$$"
        }
    ]
}