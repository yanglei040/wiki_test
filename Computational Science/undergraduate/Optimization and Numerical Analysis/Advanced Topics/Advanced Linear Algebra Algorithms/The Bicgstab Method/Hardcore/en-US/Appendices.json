{
    "hands_on_practices": [
        {
            "introduction": "Before diving into the complex mechanics of an iterative solver, it's essential to understand its fundamental goal. This first exercise is a simple but crucial thought experiment: what happens if our initial guess is already the exact solution? By analyzing this trivial case, you will solidify your understanding of the initial residual $r_0$ and the scalar $\\rho_1$, confirming that the algorithm correctly identifies a solved system and terminates immediately. ",
            "id": "2208859",
            "problem": "Consider the problem of solving a linear system of equations $Ax = b$, where $A$ is an $n \\times n$ invertible matrix, and $x$ and $b$ are column vectors in $\\mathbb{R}^n$. The Bi-Conjugate Gradient Stabilized (BiCGSTAB) method is a popular iterative algorithm for finding an approximate solution to this system.\n\nThe algorithm begins with an initial guess, $x_0$. Based on this guess, the initial residual vector is calculated as $r_0 = b - Ax_0$. An auxiliary \"shadow\" residual vector, $\\hat{r}_0$, is also chosen, typically such that its dot product with the initial residual is non-zero. In the first step of the iterative process (for index $i=1$), the algorithm computes a scalar parameter $\\rho_1$, which is defined as the dot product (or inner product) $\\rho_1 = \\hat{r}_0^T r_0$.\n\nSuppose that, by an exceptional stroke of luck, the chosen initial guess $x_0$ happens to be the exact solution to the system $Ax = b$. Based solely on this information, determine the value of the initial residual vector $r_0$ and the scalar parameter $\\rho_1$.\n\nSelect the correct statement from the options below.\n\nA. $r_0$ is the zero vector and $\\rho_1 = 0$.\n\nB. $r_0$ is the zero vector and $\\rho_1 = 1$.\n\nC. $r_0$ is the vector $b$ and $\\rho_1 = \\hat{r}_0^T b$.\n\nD. The values of $r_0$ and $\\rho_1$ depend on the specific choice of the shadow residual $\\hat{r}_0$.\n\nE. It is not possible to determine $r_0$ and $\\rho_1$ without knowing the specific matrix $A$ and vector $b$.",
            "solution": "We are given the linear system $Ax=b$ with $A \\in \\mathbb{R}^{n \\times n}$ invertible, and the BiCGSTAB setup with initial guess $x_{0}$, initial residual $r_{0}=b-Ax_{0}$, and shadow residual $\\hat{r}_{0}$ such that $\\rho_{1}=\\hat{r}_{0}^{T}r_{0}$.\n\nAssume $x_{0}$ is the exact solution to $Ax=b$. Denote the exact solution by $x^{\\ast}$, which satisfies $Ax^{\\ast}=b$. Since $x_{0}=x^{\\ast}$, we have\n$$\nAx_{0}=b.\n$$\nBy the definition of the residual,\n$$\nr_{0}=b-Ax_{0}=b-b=0,\n$$\nwhere $0$ denotes the zero vector in $\\mathbb{R}^{n}$.\n\nThe scalar $\\rho_{1}$ is defined by the inner product\n$$\n\\rho_{1}=\\hat{r}_{0}^{T}r_{0}.\n$$\nSince $r_{0}=0$, it follows that\n$$\n\\rho_{1}=\\hat{r}_{0}^{T}0=0,\n$$\nindependently of the choice of $\\hat{r}_{0}$.\n\nTherefore, the correct statement is that $r_{0}$ is the zero vector and $\\rho_{1}=0$, which corresponds to option A.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Having grasped the concept of the residual, we now move from theory to practice. This exercise will guide you through a complete, step-by-step execution of the BiCGSTAB algorithm on a small $2 \\times 2$ system. By manually calculating each intermediate quantity—from the search directions $p_k$ and $v_k$ to the step lengths $\\alpha_k$ and $\\omega_k$—you will demystify the algorithm's inner workings and observe its finite-termination property in exact arithmetic. ",
            "id": "2374444",
            "problem": "You will apply the BiConjugate Gradient Stabilized (BiCGSTAB) method to a nonsymmetric linear system to explicitly illustrate that, in exact arithmetic and with a standard choice of parameters, it requires two iterations to converge starting from the zero initial guess. Consider the linear system with\n- matrix $A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}$,\n- right-hand side $b = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$,\n- initial guess $x_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$,\n- identity preconditioner, and\n- shadow residual $\\hat{r} = r_0$, where $r_0 = b - A x_0$.\n\nAll inner products are the standard Euclidean ones. Work in exact arithmetic (that is, do not round intermediate quantities). Perform the BiCGSTAB iterations step-by-step, starting from the core definitions of residuals, search directions, and scalar coefficients that define the BiCGSTAB recurrence, and show that:\n1. After the first iteration, the residual is nonzero.\n2. After the second iteration, the method reaches the exact solution (residual equal to the zero vector).\n\nExplicitly compute and report all intermediate vectors and scalars used by BiCGSTAB up to convergence to substantiate these claims. Finally, provide the exact value of the first smoothing parameter $\\omega_1$ produced during the first BiCGSTAB iteration for this system. Express your final answer as an exact rational number. Do not round.",
            "solution": "The solution will be constructed by applying the BiCGSTAB algorithm step-by-step. The algorithm is as follows:\n\n**Initialization:**\n1. Given an initial guess $x_0$.\n2. Compute the initial residual $r_0 = b - Ax_0$.\n3. Choose a shadow residual vector $\\hat{r}_0$, such that $(\\hat{r}_0, r_0) \\neq 0$. Here, we are given $\\hat{r}_0 = r_0$.\n4. Set initial parameters for the recurrence: $\\rho_0 = 1$, $\\alpha_0 = 1$, $\\omega_0 = 1$.\n5. Set initial search directions: $p_0 = \\mathbf{0}$, $v_0 = \\mathbf{0}$.\n\n**Main Loop (for $k = 1, 2, \\dots$):**\n1. $\\rho_k = (\\hat{r}_0, r_{k-1})$\n2. $\\beta_k = \\frac{\\rho_k}{\\rho_{k-1}} \\frac{\\alpha_{k-1}}{\\omega_{k-1}}$\n3. $p_k = r_{k-1} + \\beta_k (p_{k-1} - \\omega_{k-1} v_{k-1})$\n4. $v_k = A p_k$\n5. $\\alpha_k = \\frac{\\rho_k}{(\\hat{r}_0, v_k)}$\n6. $s_k = r_{k-1} - \\alpha_k v_k$\n7. $t_k = A s_k$\n8. $\\omega_k = \\frac{(t_k, s_k)}{(t_k, t_k)}$\n9. $x_k = x_{k-1} + \\alpha_k p_k + \\omega_k s_k$\n10. $r_k = s_k - \\omega_k t_k$\n\nWe will now apply this algorithm to the given system.\n\n**Initialization ($k=0$):**\n- The system is defined by $A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}$ and $b = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$.\n- The initial guess is $x_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n- The initial residual is $r_0 = b - Ax_0 = b = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$.\n- The shadow residual is $\\hat{r}_0 = r_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$.\n- The initial parameters are set to $\\rho_0 = 1$, $\\alpha_0 = 1$, $\\omega_0 = 1$.\n- The initial direction vectors are $p_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ and $v_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n\n**Iteration 1 ($k=1$):**\n1. $\\rho_1 = (\\hat{r}_0, r_0) = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 1$.\n2. $\\beta_1 = \\frac{\\rho_1}{\\rho_0} \\frac{\\alpha_0}{\\omega_0} = \\frac{1}{1} \\frac{1}{1} = 1$.\n3. $p_1 = r_0 + \\beta_1(p_0 - \\omega_0 v_0) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + 1 \\left( \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} - 1 \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\right) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$.\n4. $v_1 = A p_1 = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}$.\n5. The denominator for $\\alpha_1$ is $(\\hat{r}_0, v_1) = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = 1$. Thus, $\\alpha_1 = \\frac{\\rho_1}{(\\hat{r}_0, v_1)} = \\frac{1}{1} = 1$.\n6. $s_1 = r_0 - \\alpha_1 v_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} - 1 \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix}$.\n7. $t_1 = A s_1 = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} = \\begin{pmatrix} -6 \\\\ -12 \\end{pmatrix}$.\n8. For $\\omega_1$, we compute the inner products:\n   $(t_1, s_1) = \\begin{pmatrix} -6 & -12 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} = (0)(-6) + (-3)(-12) = 36$.\n   $(t_1, t_1) = \\begin{pmatrix} -6 & -12 \\end{pmatrix} \\begin{pmatrix} -6 \\\\ -12 \\end{pmatrix} = (-6)^2 + (-12)^2 = 36 + 144 = 180$.\n   So, $\\omega_1 = \\frac{(t_1, s_1)}{(t_1, t_1)} = \\frac{36}{180} = \\frac{1}{5}$.\n9. $x_1 = x_0 + \\alpha_1 p_1 + \\omega_1 s_1 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + 1 \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + \\frac{1}{5} \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -\\frac{3}{5} \\end{pmatrix}$.\n10. $r_1 = s_1 - \\omega_1 t_1 = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} - \\frac{1}{5} \\begin{pmatrix} -6 \\\\ -12 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} - \\begin{pmatrix} -\\frac{6}{5} \\\\ -\\frac{12}{5} \\end{pmatrix} = \\begin{pmatrix} \\frac{6}{5} \\\\ -\\frac{3}{5} \\end{pmatrix}$.\n\nAfter the first iteration, the residual is $r_1 = \\begin{pmatrix} \\frac{6}{5} \\\\ -\\frac{3}{5} \\end{pmatrix}$, which is not the zero vector. This substantiates the first claim.\n\n**Iteration 2 ($k=2$):**\n1. $\\rho_2 = (\\hat{r}_0, r_1) = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} \\frac{6}{5} \\\\ -\\frac{3}{5} \\end{pmatrix} = \\frac{6}{5}$.\n2. $\\beta_2 = \\frac{\\rho_2}{\\rho_1} \\frac{\\alpha_1}{\\omega_1} = \\frac{6/5}{1} \\frac{1}{1/5} = \\frac{6}{5} \\cdot 5 = 6$.\n3. $p_2 = r_1 + \\beta_2(p_1 - \\omega_1 v_1) = \\begin{pmatrix} \\frac{6}{5} \\\\ -\\frac{3}{5} \\end{pmatrix} + 6 \\left( \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} - \\frac{1}{5} \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} \\right) = \\begin{pmatrix} \\frac{6}{5} \\\\ -\\frac{3}{5} \\end{pmatrix} + 6 \\begin{pmatrix} \\frac{4}{5} \\\\ -\\frac{3}{5} \\end{pmatrix} = \\begin{pmatrix} \\frac{6}{5} + \\frac{24}{5} \\\\ -\\frac{3}{5} - \\frac{18}{5} \\end{pmatrix} = \\begin{pmatrix} \\frac{30}{5} \\\\ -\\frac{21}{5} \\end{pmatrix} = \\begin{pmatrix} 6 \\\\ -\\frac{21}{5} \\end{pmatrix}$.\n4. $v_2 = A p_2 = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\begin{pmatrix} 6 \\\\ -\\frac{21}{5} \\end{pmatrix} = \\begin{pmatrix} 6 - \\frac{42}{5} \\\\ 18 - \\frac{84}{5} \\end{pmatrix} = \\begin{pmatrix} \\frac{30-42}{5} \\\\ \\frac{90-84}{5} \\end{pmatrix} = \\begin{pmatrix} -\\frac{12}{5} \\\\ \\frac{6}{5} \\end{pmatrix}$.\n5. The denominator for $\\alpha_2$ is $(\\hat{r}_0, v_2) = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} -\\frac{12}{5} \\\\ \\frac{6}{5} \\end{pmatrix} = -\\frac{12}{5}$. Thus, $\\alpha_2 = \\frac{\\rho_2}{(\\hat{r}_0, v_2)} = \\frac{6/5}{-12/5} = -\\frac{1}{2}$.\n6. $s_2 = r_1 - \\alpha_2 v_2 = \\begin{pmatrix} \\frac{6}{5} \\\\ -\\frac{3}{5} \\end{pmatrix} - \\left(-\\frac{1}{2}\\right) \\begin{pmatrix} -\\frac{12}{5} \\\\ \\frac{6}{5} \\end{pmatrix} = \\begin{pmatrix} \\frac{6}{5} \\\\ -\\frac{3}{5} \\end{pmatrix} - \\begin{pmatrix} \\frac{6}{5} \\\\ -\\frac{3}{5} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n7. Since $s_2 = \\mathbf{0}$, we have $t_2 = A s_2 = A \\mathbf{0} = \\mathbf{0}$.\n8. The formula for $\\omega_2$ becomes $\\frac{(t_2, s_2)}{(t_2, t_2)} = \\frac{0}{0}$. This is a so-called \"lucky breakdown\", which indicates that the exact solution will be found at this step. We can set $\\omega_2 = 0$.\n9. $x_2 = x_1 + \\alpha_2 p_2 + \\omega_2 s_2 = \\begin{pmatrix} 1 \\\\ -\\frac{3}{5} \\end{pmatrix} + \\left(-\\frac{1}{2}\\right) \\begin{pmatrix} 6 \\\\ -\\frac{21}{5} \\end{pmatrix} + 0 \\cdot \\mathbf{0} = \\begin{pmatrix} 1 - 3 \\\\ -\\frac{3}{5} + \\frac{21}{10} \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ -\\frac{6}{10} + \\frac{21}{10} \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ \\frac{15}{10} \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ \\frac{3}{2} \\end{pmatrix}$.\n10. $r_2 = s_2 - \\omega_2 t_2 = \\mathbf{0} - 0 \\cdot \\mathbf{0} = \\mathbf{0}$.\n\nThe residual $r_2$ is the zero vector, which means the algorithm has converged to the exact solution. This substantiates the second claim. To verify, we check the solution:\n$A x_2 = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\begin{pmatrix} -2 \\\\ \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} 1(-2) + 2(\\frac{3}{2}) \\\\ 3(-2) + 4(\\frac{3}{2}) \\end{pmatrix} = \\begin{pmatrix} -2 + 3 \\\\ -6 + 6 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = b$.\nThe solution is correct.\n\nThe problem asks for the value of the first smoothing parameter, $\\omega_1$. As calculated in the first iteration, this value is $\\omega_1 = \\frac{1}{5}$.",
            "answer": "$$\n\\boxed{\\frac{1}{5}}\n$$"
        },
        {
            "introduction": "The 'STAB' in BiCGSTAB highlights its key advantage: enhanced stability over its predecessor, the Biconjugate Gradient (BiCG) method. This advanced practice demonstrates a carefully constructed scenario where the BiCG algorithm suffers a fatal breakdown due to a loss of biorthogonality. You will first verify this breakdown and then see how BiCGSTAB's stabilizing step, which introduces the smoothing parameter $\\omega_k$, elegantly navigates the same problem, leading to a convergent solution. ",
            "id": "2376326",
            "problem": "You are asked to demonstrate, from first principles of Krylov subspace iterative methods, how breakdowns in the Bi-Conjugate Gradient (BiCG) method can occur while the Bi-Conjugate Gradient Stabilized (BiCGSTAB) method still converges on the same linear system. Consider the linear system $A x = b$ with\n$$\nA \\;=\\; \\begin{pmatrix}\n2 & 0 & 1\\\\\n1 & 3 & 0\\\\\n0 & 0 & 4\n\\end{pmatrix}, \n\\qquad\nb \\;=\\; \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix},\n\\qquad\nx_0 \\;=\\; \\begin{pmatrix} 0\\\\ 0\\\\ 0 \\end{pmatrix}.\n$$\nFor Bi-Conjugate Gradient (BiCG), set the initial residual $r_0 = b - A x_0$ and the initial shadow residual $\\tilde{r}_0 = r_0$. Using only the definitions of the first update step in BiCG (residuals and shadow residuals defined by single-step Krylov projections with a biorthogonality pairing), explicitly compute $r_1$ and $\\tilde{r}_1$ and verify that $r_1 \\neq 0$, $\\tilde{r}_1 \\neq 0$, and $r_1^{T}\\tilde{r}_1 = 0$, which implies BiCG breakdown at the next step.\n\nNext, apply the Bi-Conjugate Gradient Stabilized (BiCGSTAB) method to the same system with the same initial guess $x_0$, the same initial residual $r_0$, and a fixed shadow residual $\\hat{r}$ chosen as\n$$\n\\hat{r} \\;=\\; r_0 + \\begin{pmatrix} 0\\\\ 1\\\\ 0 \\end{pmatrix} \\;=\\; \\begin{pmatrix} 1\\\\ 1\\\\ 0 \\end{pmatrix}.\n$$\nUsing the standard definitions of the BiCGSTAB recurrence (scalar coefficients defined by inner products of $r_{k-1}$, $\\hat{r}$, and Krylov images under $A$), carry out the first BiCGSTAB iteration to compute the smoothing parameter $\\omega_1$.\n\nYour task is to provide the value of the scalar $\\omega_1$. Express your final answer exactly as a reduced fraction. No rounding is required. The final answer must be a single number with no units.",
            "solution": "The linear system under consideration is $A x = b$, with the givens:\n$$\nA \\;=\\; \\begin{pmatrix}\n2 & 0 & 1\\\\\n1 & 3 & 0\\\\\n0 & 0 & 4\n\\end{pmatrix}, \n\\qquad\nb \\;=\\; \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix},\n\\qquad\nx_0 \\;=\\; \\begin{pmatrix} 0\\\\ 0\\\\ 0 \\end{pmatrix}.\n$$\n\nFirst, we analyze the BiCG method. The initial residual is $r_0 = b - A x_0 = b - 0 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix}$.\nThe problem specifies setting the initial shadow residual $\\tilde{r}_0 = r_0$. Thus, $\\tilde{r}_0 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix}$.\nThe BiCG algorithm sets the initial search directions as $p_0 = r_0$ and $\\tilde{p}_0 = \\tilde{r}_0$.\nThe scalar $\\alpha_k$ is computed at each step $k$ as $\\alpha_k = \\frac{\\tilde{r}_k^T r_k}{\\tilde{p}_k^T A p_k}$.\nFor the first step ($k=0$):\nThe numerator is $\\tilde{r}_0^T r_0 = r_0^T r_0 = \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} = 1$.\nTo compute the denominator, we first find $A p_0$:\n$A p_0 = A r_0 = \\begin{pmatrix} 2 & 0 & 1\\\\ 1 & 3 & 0\\\\ 0 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix}$.\nThe denominator is then $\\tilde{p}_0^T A p_0 = \\tilde{r}_0^T (A r_0) = \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix} = 2$.\nThus, $\\alpha_0 = \\frac{1}{2}$.\n\nThe updated residuals $r_1$ and $\\tilde{r}_1$ are computed as follows:\n$r_1 = r_0 - \\alpha_0 A p_0 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} - \\frac{1}{2} \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1\\\\ 1/2\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0\\\\ -1/2\\\\ 0 \\end{pmatrix}$.\n$\\tilde{r}_1 = \\tilde{r}_0 - \\alpha_0 A^T \\tilde{p}_0$. The transpose of $A$ is $A^T = \\begin{pmatrix} 2 & 1 & 0\\\\ 0 & 3 & 0\\\\ 1 & 0 & 4 \\end{pmatrix}$.\n$A^T \\tilde{p}_0 = A^T \\tilde{r}_0 = \\begin{pmatrix} 2 & 1 & 0\\\\ 0 & 3 & 0\\\\ 1 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2\\\\ 0\\\\ 1 \\end{pmatrix}$.\n$\\tilde{r}_1 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} - \\frac{1}{2} \\begin{pmatrix} 2\\\\ 0\\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1\\\\ 0\\\\ 1/2 \\end{pmatrix} = \\begin{pmatrix} 0\\\\ 0\\\\ -1/2 \\end{pmatrix}$.\n\nWe verify that $r_1^T \\tilde{r}_1 = \\begin{pmatrix} 0 & -1/2 & 0 \\end{pmatrix} \\begin{pmatrix} 0\\\\ 0\\\\ -1/2 \\end{pmatrix} = 0$. Since the numerator for the next step's $\\alpha_1$ is $\\tilde{r}_1^T r_1$, the algorithm would break down.\n\nNext, we apply the BiCGSTAB method. The initial residual is $r_0 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix}$. The fixed shadow residual is given as $\\hat{r} = \\begin{pmatrix} 1\\\\ 1\\\\ 0 \\end{pmatrix}$.\nThe standard algorithm starts with initial values $\\rho_0=1$, $\\alpha_0=1$, $\\omega_0=1$, $p_0=0$, and $v_0=0$. We perform the first iteration ($k=1$).\n\n1. Compute $\\rho_1 = \\hat{r}^T r_0$:\n$\\rho_1 = \\begin{pmatrix} 1 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} = 1$.\n\n2. Compute $\\beta_1 = \\frac{\\rho_1}{\\rho_0} \\frac{\\alpha_0}{\\omega_0}$:\n$\\beta_1 = \\frac{1}{1} \\cdot \\frac{1}{1} = 1$.\n\n3. Compute $p_1 = r_0 + \\beta_1 (p_0 - \\omega_0 v_0)$:\n$p_1 = r_0 + 1 (0 - 1 \\cdot 0) = r_0 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix}$.\n\n4. Compute $v_1 = A p_1$:\n$v_1 = A r_0 = \\begin{pmatrix} 2 & 0 & 1\\\\ 1 & 3 & 0\\\\ 0 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix}$.\n\n5. Compute $\\alpha_1 = \\frac{\\rho_1}{\\hat{r}^T v_1}$:\n$\\hat{r}^T v_1 = \\begin{pmatrix} 1 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix} = (1)(2) + (1)(1) + (0)(0) = 3$.\n$\\alpha_1 = \\frac{1}{3}$.\n\n6. Compute the temporary residual $s_1 = r_0 - \\alpha_1 v_1$:\n$s_1 = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix} - \\frac{1}{3} \\begin{pmatrix} 2\\\\ 1\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 - 2/3\\\\ 0 - 1/3\\\\ 0 - 0 \\end{pmatrix} = \\begin{pmatrix} 1/3\\\\ -1/3\\\\ 0 \\end{pmatrix}$.\n\n7. Compute $t_1 = A s_1$:\n$t_1 = \\begin{pmatrix} 2 & 0 & 1\\\\ 1 & 3 & 0\\\\ 0 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} 1/3\\\\ -1/3\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2(1/3) + 0(-1/3) + 1(0) \\\\ 1(1/3) + 3(-1/3) + 0(0) \\\\ 0(1/3) + 0(-1/3) + 4(0) \\end{pmatrix} = \\begin{pmatrix} 2/3\\\\ 1/3 - 1\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2/3\\\\ -2/3\\\\ 0 \\end{pmatrix}$.\n\n8. Compute the smoothing parameter $\\omega_1 = \\frac{t_1^T s_1}{t_1^T t_1}$:\nThe numerator is $t_1^T s_1 = \\begin{pmatrix} 2/3 & -2/3 & 0 \\end{pmatrix} \\begin{pmatrix} 1/3\\\\ -1/3\\\\ 0 \\end{pmatrix} = (\\frac{2}{3})(\\frac{1}{3}) + (\\frac{-2}{3})(\\frac{-1}{3}) = \\frac{2}{9} + \\frac{2}{9} = \\frac{4}{9}$.\nThe denominator is $t_1^T t_1 = \\begin{pmatrix} 2/3 & -2/3 & 0 \\end{pmatrix} \\begin{pmatrix} 2/3\\\\ -2/3\\\\ 0 \\end{pmatrix} = (\\frac{2}{3})^2 + (\\frac{-2}{3})^2 = \\frac{4}{9} + \\frac{4}{9} = \\frac{8}{9}$.\n$\\omega_1 = \\frac{4/9}{8/9} = \\frac{4}{8} = \\frac{1}{2}$.\n\nThe value of the smoothing parameter $\\omega_1$ is $\\frac{1}{2}$.",
            "answer": "$$\n\\boxed{\\frac{1}{2}}\n$$"
        }
    ]
}