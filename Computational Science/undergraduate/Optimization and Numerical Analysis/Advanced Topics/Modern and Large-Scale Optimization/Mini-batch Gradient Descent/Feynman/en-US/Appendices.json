{
    "hands_on_practices": [
        {
            "introduction": "The core of any gradient-based optimization is the update step, where a model's parameters are adjusted to minimize a cost function. This first practice problem isolates this fundamental mechanic of mini-batch gradient descent. By applying the update rule with a given gradient $\\nabla J(\\theta_0)$ and learning rate $\\eta$, you will perform a single parameter adjustment, observing the direct application of the algorithm's central principle.",
            "id": "2187026",
            "problem": "A computational science student is training a simple predictive model. The model's behavior is controlled by a single dimensionless parameter, $\\theta$. The goal is to find the value of $\\theta$ that minimizes the model's prediction error, which is measured by a cost function $J(\\theta)$.\n\nThe student employs a numerical optimization technique known as gradient descent. The process starts with an initial guess for the parameter and iteratively refines it. Each update step is designed to move the parameter value in the direction opposite to the cost function's gradient. The magnitude of each step is determined by a parameter called the learning rate.\n\nThe student initializes the parameter at $\\theta_0 = 2$. For the first iteration, they use a subset of their data to compute the gradient of the cost function with respect to the parameter at this initial point. The computation yields a gradient value of $\\nabla J(\\theta_0) = 4$. The learning rate for the optimization process is set to $\\eta = 0.01$.\n\nCalculate the updated value of the parameter, $\\theta_1$, after this first iteration. Report your answer to three significant figures.",
            "solution": "We use the standard gradient descent update rule for a single parameter:\n$$\n\\theta_{k+1} = \\theta_{k} - \\eta \\frac{dJ}{d\\theta}\\bigg|_{\\theta=\\theta_{k}}.\n$$\nFor the first iteration with $k=0$, the given values are $\\theta_{0} = 2$, learning rate $\\eta = 0.01$, and gradient $\\nabla J(\\theta_{0}) = 4$. Substituting these into the update rule gives:\n$$\n\\theta_{1} = \\theta_{0} - \\eta \\nabla J(\\theta_{0}) = 2 - 0.01 \\times 4.\n$$\nCompute the product:\n$$\n0.01 \\times 4 = 0.04,\n$$\nso\n$$\n\\theta_{1} = 2 - 0.04 = 1.96.\n$$\nRounded to three significant figures, the value is $1.96$.",
            "answer": "$$\\boxed{1.96}$$"
        },
        {
            "introduction": "In a real-world setting, the gradient is not an arbitrary value; it is derived directly from a cost function that quantifies the model's error. This exercise takes the next logical step by tasking you with computing the gradient of a simple quadratic cost function before applying the update rule. This practice is crucial for understanding how a model's performance error dictates the precise direction and magnitude of its parameter correction.",
            "id": "2187016",
            "problem": "An engineer is developing a simple smart thermostat. The thermostat's goal is to learn a desired room temperature. The thermostat has a single internal parameter, $w$, which represents its current temperature setting in degrees Celsius. The model for the thermostat's setting is simple: the output setting is just the value of the parameter $w$, independent of any external sensor readings.\n\nTo train this parameter, the engineer uses a cost function $J(w; y) = (w - y)^2$, where $y$ is the target temperature in degrees Celsius provided by the user. The parameter $w$ is updated using mini-batch gradient descent.\n\nThe initial setting of the thermostat is $w_0 = 5.0$ degrees Celsius. The learning rate for the update algorithm is set to $\\eta = 0.1$. For the first training step, a mini-batch consisting of a single data point is used. This data point corresponds to a user's desired target temperature of $y = 10.0$ degrees Celsius.\n\nCalculate the value of the thermostat's parameter, $w_1$, after this single update step. Express your answer in degrees Celsius.",
            "solution": "The cost function is $J(w; y) = (w - y)^{2}$. Its gradient with respect to $w$ is obtained by differentiating:\n$$\n\\frac{\\partial J}{\\partial w} = 2(w - y).\n$$\nUsing mini-batch gradient descent with learning rate $\\eta$, the update rule is\n$$\nw_{1} = w_{0} - \\eta \\left.\\frac{\\partial J}{\\partial w}\\right|_{w=w_{0}}.\n$$\nSubstitute $w_{0} = 5.0$, $y = 10.0$, and $\\eta = 0.1$:\n$$\n\\left.\\frac{\\partial J}{\\partial w}\\right|_{w=w_{0}} = 2(5.0 - 10.0) = 2(-5.0) = -10.0,\n$$\n$$\nw_{1} = 5.0 - 0.1 \\times (-10.0) = 5.0 + 1.0 = 6.\n$$\nThus, after one update step, the thermostat parameter is $6$ in degrees Celsius.",
            "answer": "$$\\boxed{6}$$"
        },
        {
            "introduction": "Choosing an appropriate batch size involves a crucial trade-off between computational speed and update frequency, directly impacting overall training efficiency. This problem simulates a practical scenario where you must analyze the total training time for a full epoch under two different batch size configurations. By calculating this difference, you will develop a quantitative understanding of how batch size, $b$, affects the balance between per-step processing costs and the number of parameter updates per epoch.",
            "id": "2186989",
            "problem": "A machine learning engineer is analyzing the training performance of a neural network using mini-batch gradient descent. The total time to complete one epoch depends on the time spent processing the data samples and the time spent performing the parameter updates.\n\nThe training dataset contains $N = 1,228,800$ samples. The computational costs are characterized as follows:\n- The time required to perform the forward and backward propagation for a single data sample is $t_{sample} = 50.0$ microseconds.\n- The time required to execute one parameter update step (i.e., the optimizer step) is constant, irrespective of the batch size, and is given by $t_{update} = 10.0$ milliseconds.\n\nThe engineer compares two training configurations for one full epoch:\n- Configuration A uses a batch size of $b_A = 64$.\n- Configuration B uses a batch size of $b_B = 256$.\n\nFor this analysis, you can assume that the total number of samples $N$ is perfectly divisible by both batch sizes.\n\nCalculate the absolute difference in the total training time for one epoch between Configuration A and Configuration B. Express your final answer in seconds.",
            "solution": "The total time per epoch with batch size $b$ is the sum of sample-processing time and update time:\n$$\nT(b) = N\\,t_{sample} + \\left(\\frac{N}{b}\\right)t_{update}.\n$$\nThe absolute difference between configurations $A$ and $B$ is\n$$\n\\Delta T = |T(b_{A}) - T(b_{B})| = \\left|\\frac{N}{b_{A}} - \\frac{N}{b_{B}}\\right|t_{update}.\n$$\nWith $N=1{,}228{,}800$, $b_{A}=64$, $b_{B}=256$, and $t_{update}=10.0\\ \\text{ms}$,\n$$\n\\frac{N}{b_{A}} = \\frac{1{,}228{,}800}{64} = 19{,}200,\\qquad \\frac{N}{b_{B}} = \\frac{1{,}228{,}800}{256} = 4{,}800,\n$$\nso\n$$\n\\Delta T = (19{,}200 - 4{,}800)\\times 10.0\\ \\text{ms} = 144{,}000\\ \\text{ms} = 144\\ \\text{s}.\n$$\nNote that the sample-processing term $N t_{sample}$ cancels when taking the difference, so it does not affect $\\Delta T$.",
            "answer": "$$\\boxed{144}$$"
        }
    ]
}