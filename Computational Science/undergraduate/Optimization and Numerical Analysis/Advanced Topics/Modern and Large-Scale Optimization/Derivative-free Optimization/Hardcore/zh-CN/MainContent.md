## 引言
在许多现实世界的[优化问题](@entry_id:266749)中，我们无法像教科书那样轻易获得目标函数的梯度信息。当函数是一个内部逻辑未知的“黑箱”模拟、一次评估需要数小时的计算，或是测量数据充满噪声时，传统的梯度下降等方法便无用武之地。正是在这样的挑战下，无导数优化 (Derivative-Free Optimization, DFO) 应运而生，它提供了一套强大的工具集，仅通过查询函数值来寻找最优解，展示了其在现代科学与工程中的独特价值。

本文旨在系统地介绍无导数优化的世界。我们首先将在“原理与机制”一章中，深入剖析各[类核](@entry_id:178267)心DFO算法的内部工作方式，从经典的直接搜索方法到[群体智能](@entry_id:271638)的[元启发式算法](@entry_id:634913)，再到为昂贵函数量身定制的[贝叶斯优化](@entry_id:175791)。随后，在“应用与跨学科连接”一章，我们将跨越学科边界，展示这些理论如何在工程设计、机器学习[超参数优化](@entry_id:168477)乃至前沿科学发现中解决实际问题。最后，“动手实践”部分将提供具体的计算练习，让您亲身体验这些算法的核心步骤。

通过这趟学习之旅，您将不仅理解DFO方法的“是什么”和“为什么”，更能掌握“如何用”的实践智慧，为解决复杂的现实优化难题打下坚实的基础。

## 原理与机制

在优化领域，许多经典方法，如梯度下降法或[牛顿法](@entry_id:140116)，都依赖于[目标函数](@entry_id:267263)导数的存在和[可计算性](@entry_id:276011)。然而，在众多科学与工程问题中，这一前提往往不成立。[目标函数](@entry_id:267263)可能是一个“黑箱”，其内部机制未知，我们只能通过输入查询其输出值；或者函数值的计算成本极其高昂，使得导数的数值近似不切实际；再或者，函数本身存在噪声，导致导数信息不可靠。在这些情况下，**无导数优化 (Derivative-Free Optimization, DFO)** 方法便显示出其不可替代的价值。本章将深入探讨几[类核](@entry_id:178267)心的 DFO 方法的原理与机制。

### 核心挑战：[黑箱函数](@entry_id:163083)与噪声

DFO 方法旨在解决的一[类核](@entry_id:178267)心问题是**[黑箱函数](@entry_id:163083)**的优化。这类函数通常来源于复杂的计算机模拟或物理实验。例如，在工程设计中，一个[热电发电机](@entry_id:156128)的能量转换效率 $\eta$ 可能是某个[调节参数](@entry_id:756220) $\alpha$ 的函数。这个关系 $\eta(\alpha)$ 可能只能通过耗时的数值模拟获得，我们无法得到其解析导数，甚至连有效的[数值近似](@entry_id:161970)都难以实现 。在这种情况下，我们只能将模拟程序视为一个黑箱，输入 $\alpha$，获得 $\eta$，然后利用这一系列离散的函数值信息来指导优化进程。

另一个严峻的挑战是**噪声**的存在。当函数评估本身受到随机误差干扰时，基于导数的方法可能会彻底失效。假设一个自主探测车试图在一段一维山谷中寻找最低点，其真实海拔由平滑的二次函数 $f(x) = \frac{1}{2}(x - 5)^2$ 给出，但其高度计读数 $\hat{f}(x)$ 却包含噪声。考虑探测车从 $x_0 = 7$ 开始移动一步。如果采用[基于梯度的算法](@entry_id:188266)，它可能会通过有限差分来估计梯度，例如使用步长 $h=0.5$ 的[中心差分公式](@entry_id:139451)：$g_0 = \frac{\hat{f}(x_0 + h) - \hat{f}(x_0 - h)}{2h}$。假设噪声导致 $\hat{f}(7.5)=1.125$ 而 $\hat{f}(6.5)=3.125$，那么计算出的梯度为 $g_0 = \frac{1.125-3.125}{2 \cdot 0.5} = -2$。根据[梯度下降](@entry_id:145942)更新规则 $x_1 = x_0 - \alpha g_0$（设学习率 $\alpha=1.0$），新位置将是 $x_1 = 7 - 1.0 \cdot (-2) = 9$。这个结果显然是错误的，探测车非但没有靠近真正的最小值点 $x=5$，反而向错误的方向移动得更远。

相比之下，一种简单的直接搜索方法在同样的情况下可能表现得更稳健。该方法可以直接比较当前点 $x_0=7$ 及邻近点 $x_0-1=6$ 和 $x_0+1=8$ 的噪声函数值。如果观测值为 $\hat{f}(6)=0.6$, $\hat{f}(7)=1.8$, $\hat{f}(8)=4.8$，算法将选择观测值最小的点作为新位置，即 $x_1=6$。这一步成功地使探测车更接近[最小值点](@entry_id:634980)。这个例子  生动地说明了，当函数评估不可靠时，直接比较函数值大小的 DFO 策略通常比依赖于受噪声严重影响的梯度近似更为鲁棒。

### 直接搜索方法

直接搜索方法构成了 DFO 的一个基础类别，它们仅通过评估和比较一系列点上的[目标函数](@entry_id:267263)值来引导搜索方向，而不构建函数的显式模型或估计其导数。

#### [单峰函数](@entry_id:143107)[线搜索](@entry_id:141607)：[黄金分割法](@entry_id:146661)

对于[一维优化](@entry_id:635076)问题，如果已知[目标函数](@entry_id:267263)在某个区间内是**单峰 (unimodal)** 的（即只有一个[局部极值](@entry_id:144991)点），我们可以使用高效的[线搜索算法](@entry_id:139123)来缩小包含该极值点的区间。**[黄金分割法](@entry_id:146661) (Golden-Section Search)** 就是这样一种经典算法。

该算法的精妙之处在于它利用黄金分割比来选择新的试探点，从而确保每轮迭代都能以恒定的比例缩小搜索区间的长度，并且能够复用前一轮的计算结果。对于一个寻求最大值的[单峰函数](@entry_id:143107)，在区间 $[a, b]$ 内，算法会选取两个内部点 $c$ 和 $d$。这些点的位置由黄金分割比因子 $r = \frac{\sqrt{5} - 1}{2} \approx 0.618$ 决定：

$c = b - r(b - a)$
$d = a + r(b - a)$

通过比较 $f(c)$ 和 $f(d)$ 的大小，算法可以舍弃一部分不包含最大值的区间。例如，如果 $f(d) > f(c)$，由于函数的单峰性，最大值一定位于区间 $[c, b]$ 内，因此新的搜索区间就更新为 $[c, b]$。反之，如果 $f(c) > f(d)$，新区间则为 $[a, d]$。一个关键的效率提升在于，在下一轮迭代中，新的区间内的一个试探点恰好是上一轮留下的两个试探点之一，因此每轮迭代只需要进行一次新的函数评估 。经过 $N$ 次迭代，区间的长度将被缩减为原始长度的 $r^N$ 倍，从而稳定地逼近最优点。

#### 多维搜索：[模式搜索方法](@entry_id:635138)

将直接搜索的思想推广到多维空间，就产生了[模式搜索方法](@entry_id:635138)。这类方法通过在当前点周围探索一组预定义的“模式”方向来寻找改进。

最简单的[模式搜索](@entry_id:170858)是**坐标搜索法 (Coordinate Search)**。其策略非常直观：从一个初始点开始，依次沿着每个坐标轴的方向进行[一维搜索](@entry_id:172782)以寻找更优的点。完成一轮对所有坐标轴的搜索后，即完成一个“循环”。例如，对于一个二维函数 $f(x_1, x_2)$，从点 $P_k$ 开始，算法首先固定 $x_2$，仅改变 $x_1$（例如，尝试 $x_1 \pm \delta$）来最小化函数，移动到找到的最佳点；然后从该新点出发，固定新的 $x_1$，改变 $x_2$ 进行搜索。这个过程构成了一个完整的循环 。虽然简单，但坐标搜索在处理变量间具有强相关性的“峡谷”状函数时效率较低，因为它无法沿着斜对角线的方向有效前进。

为了克服坐标搜索的局限性，**Hooke-Jeeves [模式搜索](@entry_id:170858)**引入了一种加速机制。该算法包含两个核心步骤：**探索性移动 (Exploratory Move)** 和 **模式移动 (Pattern Move)**。

1.  **探索性移动**：与坐标搜索类似，从一个基点 $B_k$ 开始，沿着每个坐标轴尝试小步移动，寻找一个函数值更低的新点 $X_{new}$。
2.  **模式移动**：如果探索性移动成功找到了一个更好的点（即 $f(X_{new})  f(B_k)$），算法不仅会将新基点更新为 $B_{k+1} = X_{new}$，还会执行一次“模式移动”。它会计算一个“模式点” $P_{k+1}$，该点位于由前一个基点 $B_k$ 和新基点 $B_{k+1}$ 确定的方向上：
    $P_{k+1} = B_{k+1} + (B_{k+1} - B_k)$
    这个模式移动的本质是假设从 $B_k$ 到 $B_{k+1}$ 的方向是一个有希望的[下降方向](@entry_id:637058)，并沿着该方向进行一次“大胆”的跳跃，从而加速收敛。下一轮的探索性移动将从这个更具潜力的模式点 $P_{k+1}$ 开始，而不是从 $B_{k+1}$ 开始 。

#### Nelder-Mead 单纯形法

**Nelder-Mead 单纯形法**是另一种著名且应用广泛的直接搜索方法。它在 $n$ 维空间中维护一个由 $n+1$ 个顶点构成的**单纯形 (simplex)**（例如，在二维空间是一个三角形，三维空间是一个四面体）。算法的核心思想是通过一系列[几何变换](@entry_id:150649)（反射、扩张、收缩）来迭代地改变单纯形的形状和位置，使其逐步“爬向”函数的最小（或最大）值点。

在每一步迭代中，算法首先确定单纯形中函数值最高（最差）的顶点 $\mathbf{x}_w$、最低（最好）的顶点 $\mathbf{x}_b$ 以及次高的顶点 $\mathbf{x}_s$。然后，它试图用一个更好的点来替换最差顶点 $\mathbf{x}_w$。主要操作步骤如下：

1.  **反射 (Reflection)**：计算除 $\mathbf{x}_w$ 外其余 $n$ 个顶点的[质心](@entry_id:265015) $\mathbf{x}_o$，然后将 $\mathbf{x}_w$ 关于[质心](@entry_id:265015) $\mathbf{x}_o$ 反射，得到反射点 $\mathbf{x}_r$。
2.  **决策**：根据反射点 $\mathbf{x}_r$ 的函数值 $f_r$，算法采取不同策略：
    *   如果 $f_r  f_b$，说明反射方向非常好，甚至找到了比当前最好点还要好的点。此时算法会尝试**扩张 (Expansion)**，即沿着该方向再进一步，试图找到一个更优的扩张点 $\mathbf{x}_e$ 。
    *   如果 $f_b \le f_r  f_s$，说明反射点不错，但没有超越当前最好点。此时接受反射点 $\mathbf{x}_r$ 替换 $\mathbf{x}_w$。
    *   如果 $f_s \le f_r$，说明反射点效果不佳，算法将进行**收缩 (Contraction)**，即在 $\mathbf{x}_w$ 和 $\mathbf{x}_o$ 之间寻找一个更近的点。
    *   如果所有尝试都失败了，算法将执行**收缩 (Shrink)**，将除最好点外的所有顶点都向最好点 $\mathbf{x}_b$ 靠拢。

然而，Nelder-Mead 方法存在一个潜在的失效模式：**单纯形退化 (simplex degeneracy)**。当单纯形的 $n+1$ 个顶点变得共线（二维）或共面（三维）时，它就失去了在所有维度上探索的能力。例如，在二维空间中，如果三个顶点 $\mathbf{x}_1, \mathbf{x}_2, \mathbf{x}_3$ 位于同一直线上，那么它们的质心 $\mathbf{x}_o$ 也在这条线上。对最差点的反射操作所产生的反射点 $\mathbf{x}_r$ 同样会落在这条直线上。因此，新的单纯形仍然是退化的，算法的搜索被限制在一个低维[子空间](@entry_id:150286)中，从而可能导致停滞 。

### 元启发式与随机方法

与通常遵循确定性规则的直接搜索方法不同，元启发式方法引入了随机性，并常常从自然界的群体行为或物理过程中汲取灵感。这些方法在处理复杂、多模态的[全局优化](@entry_id:634460)问题时尤其有效。

#### 概念框架：基因型与表现型

在讨论许多[元启发式算法](@entry_id:634913)（特别是进化算法）时，区分**基因型 (genotype)** 和**表现型 (phenotype)** 至关重要。这个概念借用自生物学。

*   **基因型**：指[优化问题](@entry_id:266749)中决策变量的编码表示。这是算法直接操作的对象，如同生物的基因序列。
*   **表现型**：指由基因型解码后在问题空间中形成的具体解决方案或实体，如同生物体根据基因发育成的具体形态。

例如，在[空气动力学](@entry_id:193011)优化中，工程师可能使用进化算法来设计翼型。[翼型](@entry_id:195951)的厚度[分布](@entry_id:182848)可以由一个[参数化](@entry_id:272587)函数 $t(x) = A_1 x^{1/2}(1-x) + A_2 x(1-x)^2 + \dots$ 来描述。在这个问题中，系数向量 $(A_1, A_2, A_3, \dots)$ 就是**基因型**，它是算法在搜索空间中操作的编码。而由这组系数具体生成的翼型几何形状函数 $t(x)$ 则是**表现型**。算法通过对基因型进行[交叉](@entry_id:147634)、变异等操作，生成新的基因型，然后将其解码为表现型（翼型），并通过昂贵的[流体动力学仿真](@entry_id:142279)来评估其性能（如升阻比），这个性能值反过来决定了该基因型的“适应度” 。

#### [粒子群优化 (PSO)](@entry_id:167588)

**[粒子群优化](@entry_id:174073) (Particle Swarm Optimization, PSO)** 是一种模仿鸟群或鱼群[觅食行为](@entry_id:181461)的[群体智能](@entry_id:271638)算法。算法维护一个由多个“粒子”组成的“种群”，每个粒子代表搜索空间中的一个潜在解。每个粒子都具有位置 $\vec{x}$ 和速度 $\vec{v}$。

在每次迭代中，每个粒子的速度根据以下公式进行更新，该公式结合了三种影响：
$$ \vec{v}_{k+1} = w \vec{v}_k + c_1 r_1 (\vec{p}_k - \vec{x}_k) + c_2 r_2 (\vec{g}_k - \vec{x}_k) $$
其中：
*   $w \vec{v}_k$ 是**惯性项**，表示粒子保持当前运动状态的趋势。惯性权重 $w$ 控制着这一影响。
*   $c_1 r_1 (\vec{p}_k - \vec{x}_k)$ 是**认知项**，表示粒子向其自身历史最佳位置 $\vec{p}_k$ 学习的趋势。
*   $c_2 r_2 (\vec{g}_k - \vec{x}_k)$ 是**社会项**，表示粒子向整个种群迄今为止发现的最佳位置 $\vec{g}_k$ 学习的趋势。

$c_1, c_2$ 是学习因子，$r_1, r_2$ 是 $[0,1]$ 之间的随机数，为搜索过程引入了随机性。

**惯性权重 $w$** 在平衡算法的**探索 (exploration)**（在整个搜索空间中寻找新的可能区域）和**利用 (exploitation)**（在已知最优解附近进行精细搜索）方面起着至关重要的作用。一个较大的 $w$ 值（例如 $w=0.9$）会使粒子更倾向于保持其原始速度，从而增强其探索新区域的能力。相反，一个较小的 $w$ 值（例如 $w=0.1$）会减弱原始速度的影响，使粒子更快地被其个人最佳位置和全局最佳位置所吸引，从而加强[局部搜索](@entry_id:636449)和收敛能力 。在实践中，常常采用动态调整的 $w$，在优化初期使用较大的 $w$ 鼓励全局探索，后期则减小 $w$ 以促进局部收敛。

### 基于代理模型的优化 (SBO)

当[目标函数](@entry_id:267263)的单次评估成本极其高昂时（例如，需要数小时的 CFD 仿真或昂贵的物理实验），即使是最高效的 DFO 方法，如果需要成百上千次评估，其总成本也可能令人无法承受。**基于代理模型的优化 (Surrogate-Based Optimization, SBO)** 正是为应对这一挑战而生。

#### 核心思想：逼近黑箱

SBO 的核心思想是，用一个计算成本极低的**代理模型 (surrogate model)**（也称响应面模型）来近似昂贵的真实函数。优化的主循环不再是直接对真实函数进行操作，而是：

1.  在少量精心选择的点上评估昂贵的真实函数 $f(x)$。
2.  利用这些已知的 $(x, f(x))$ 数据点，构建或更新一个代理模型 $s(x)$。
3.  在廉价的代理模型 $s(x)$ 上进行大量搜索，以找到其最优点或最有希望改进的点。
4.  将此点作为下一个要评估的真实函数点，然后用新的数据点更新代理模型，重复此过程。

#### 一个简单示例：二次代理模型

假设一位[航空工程](@entry_id:193945)师需要找到能最小化[翼型](@entry_id:195951)[阻力系数](@entry_id:276893)的[攻角](@entry_id:267009) $x$。每次 CFD 仿真都非常耗时。工程师可以先进行几次仿真，得到数据点，例如 $(2.00, 1.125), (4.00, 0.525), (6.00, 0.725)$。然后，可以用一个简单的二次多项式 $s(x) = ax^2 + bx + c$ 来拟合这三个点。求解该二次函数的系数后，就可以轻易地计算出其最小值点 $x^* = -b/(2a)$。这个 $x^*$ 就成为对真实函数最优攻角的估计，也可以作为下一次昂贵 CFD 仿真的建议输入点 。

#### 更高级的方法：[贝叶斯优化](@entry_id:175791)

虽然简单的[多项式拟合](@entry_id:178856)是一种有效的策略，但**[贝叶斯优化](@entry_id:175791) (Bayesian Optimization, BO)** 提供了一个更为强大和理论上更完善的框架。BO 的独特之处在于它使用概率性的代理模型（通常是**[高斯过程](@entry_id:182192) (Gaussian Process, GP)**）并显式地处理不确定性。

在[贝叶斯优化](@entry_id:175791)的框架中，有两个关键组件 ：

1.  **代理模型 (Surrogate Model)**：BO 使用一个[概率模型](@entry_id:265150)（如高斯过程）来表示我们对未知函数 $f(x)$ 的“信念”。给定已观测的数据，该模型不仅提供对任意点 $x$ 的均值预测 $\mu(x)$（即对 $f(x)$ 值的最佳猜测），还提供了一个[不确定性度量](@entry_id:152963)，即标准差 $\sigma(x)$。在远离已知数据点的地方，$\sigma(x)$ 会很大，表示模型对该区域的函数值很不确定。

2.  **[采集函数](@entry_id:168889) (Acquisition Function)**：[采集函数](@entry_id:168889) $\alpha(x)$ 是一个用于决定下一个采样点的策略性函数。它本身并不是对 $f(x)$ 的近似，而是利用代理模型提供的均值 $\mu(x)$ 和不确定性 $\sigma(x)$ 来量化在点 $x$ 进行下一次评估的“价值”。一个好的[采集函数](@entry_id:168889)能够在**利用**（在 $\mu(x)$ 预测值好的区域进行采样，以期找到最小值）和**探索**（在 $\sigma(x)$ 值大的区域进行采样，以减少不确定性）之间做出明智的权衡。例如，“[期望提升](@entry_id:749168)”(Expected Improvement) 或“[置信上界](@entry_id:178122)”(Upper Confidence Bound) 等[采集函数](@entry_id:168889)都旨在实现这种平衡。

BO 的迭代过程就是通过最大化这个廉价的[采集函数](@entry_id:168889) $\alpha(x)$ 来找到下一个最有价值的采样点 $x_{next} = \arg\max_x \alpha(x)$，然后在该点上执行昂贵的真实函数评估，并将新的数据点加入观测集，以更新代理模型。通过这种方式，BO 能够以极高的样本效率智能地探索搜索空间，找到[全局最优解](@entry_id:175747)。