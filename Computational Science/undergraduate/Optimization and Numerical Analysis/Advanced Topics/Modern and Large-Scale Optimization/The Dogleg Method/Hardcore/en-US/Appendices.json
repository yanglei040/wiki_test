{
    "hands_on_practices": [
        {
            "introduction": "To begin building the dogleg path, we first explore the most intuitive direction for minimization: the path of steepest descent. This exercise focuses on calculating the Cauchy point, which is the optimal step along this direction that remains within the trust region. Mastering this calculation is key to understanding the first segment of the dogleg method's trajectory. ",
            "id": "2212704",
            "problem": "In the field of numerical optimization, trust-region methods are a class of algorithms for solving nonlinear programming problems. These methods iteratively find a step $p$ by minimizing a model function $m(p)$ of the true objective function within a \"trust region\" of radius $\\Delta$ around the current point $x_k$. The model is typically a quadratic approximation:\n$$m(p) = f(x_k) + g^T p + \\frac{1}{2} p^T B p$$\nwhere $g$ is the gradient of the objective function at $x_k$ and $B$ is an approximation to the Hessian matrix.\n\nA fundamental component of many trust-region algorithms (like the dogleg method) is the calculation of the Cauchy point, $p_C$. The Cauchy point is defined as the vector that minimizes the quadratic model $m(p)$ along the direction of steepest descent, subject to the constraint that the step lies within the trust region, i.e., $\\|p\\| \\le \\Delta$.\n\nConsider an optimization problem where, at the current iterate, the gradient is given by $g = \\begin{pmatrix} 3 \\\\ -4 \\end{pmatrix}$ and the Hessian approximation is the identity matrix, $B = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$. The trust-region radius is set to $\\Delta = 4$.\n\nCalculate the Cauchy point $p_C$ for this scenario. Your answer should be a single 2x1 column vector containing exact fractions.",
            "solution": "The problem asks for the Cauchy point, $p_C$, which is the solution to the following constrained optimization problem:\n$$ \\min_{p} \\quad m(p) = f(x_k) + g^T p + \\frac{1}{2} p^T B p $$\n$$ \\text{subject to} \\quad p = -\\tau g \\text{ for some } \\tau \\ge 0, \\quad \\text{and} \\quad \\|p\\| \\le \\Delta $$\n\nThe direction of search is the steepest descent direction, $d = -g$. Any point along this direction can be parameterized as $p(\\tau) = -\\tau g$ for a scalar $\\tau \\ge 0$.\n\nFirst, we substitute this into the quadratic model $m(p)$ to obtain a function of a single variable, $\\tau$:\n$$ \\phi(\\tau) = m(-\\tau g) = f(x_k) + g^T(-\\tau g) + \\frac{1}{2} (-\\tau g)^T B (-\\tau g) $$\n$$ \\phi(\\tau) = f(x_k) - \\tau (g^T g) + \\frac{1}{2} \\tau^2 (g^T B g) $$\nThe constant term $f(x_k)$ does not affect the minimizer, so we can focus on minimizing the $\\tau$-dependent part.\n\nNext, we translate the trust-region constraint $\\|p\\| \\le \\Delta$ into a constraint on $\\tau$:\n$$ \\|p(\\tau)\\| = \\|-\\tau g\\| = |\\tau| \\|g\\| = \\tau \\|g\\| \\le \\Delta $$\nSince we are seeking a step in the descent direction, $\\tau \\ge 0$. Thus, the constraint on $\\tau$ is:\n$$ 0 \\le \\tau \\le \\frac{\\Delta}{\\|g\\|} $$\n\nNow, let's find the unconstrained minimizer of the quadratic $\\phi(\\tau)$ by taking its derivative with respect to $\\tau$ and setting it to zero. This will give us the optimal step length, $\\tau^*$, in the absence of the trust-region constraint.\n$$ \\frac{d\\phi}{d\\tau} = -g^T g + \\tau (g^T B g) = 0 $$\nSolving for $\\tau$, we get:\n$$ \\tau^* = \\frac{g^T g}{g^T B g} $$\nThe second derivative is $\\frac{d^2\\phi}{d\\tau^2} = g^T B g$. If this is positive, we have found a minimum.\n\nLet's compute the required quantities using the given values:\n$g = \\begin{pmatrix} 3 \\\\ -4 \\end{pmatrix}$, $B = I = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$, and $\\Delta = 4$.\n\n1.  Calculate $g^T g$:\n    $g^T g = (3)(3) + (-4)(-4) = 9 + 16 = 25$.\n\n2.  Calculate $\\|g\\|$:\n    $\\|g\\| = \\sqrt{g^T g} = \\sqrt{25} = 5$.\n\n3.  Calculate $g^T B g$:\n    Since $B=I$, $g^T B g = g^T I g = g^T g = 25$.\n\nThe second derivative $g^T B g = 25  0$, so $\\phi(\\tau)$ is a convex parabola, and its unconstrained minimum is indeed at $\\tau^*$.\n\n4.  Calculate the unconstrained optimal step length $\\tau^*$:\n    $$ \\tau^* = \\frac{g^T g}{g^T B g} = \\frac{25}{25} = 1 $$\n\n5.  Determine the feasible interval for $\\tau$:\n    The constraint is $0 \\le \\tau \\le \\frac{\\Delta}{\\|g\\|}$.\n    $$ \\frac{\\Delta}{\\|g\\|} = \\frac{4}{5} = 0.8 $$\n    So, the feasible interval for $\\tau$ is $[0, 0.8]$.\n\n6.  Find the constrained optimal step length, $\\tau_C$. The unconstrained minimizer $\\tau^* = 1$ lies outside the feasible interval $[0, 0.8]$. Since $\\phi(\\tau)$ is a convex parabola with its minimum at $\\tau=1$, the minimum value of $\\phi(\\tau)$ over the interval $[0, 0.8]$ must occur at the boundary point closest to $\\tau=1$. This point is $\\tau = 0.8$.\n    Therefore, the step length for the Cauchy point is $\\tau_C = \\frac{\\Delta}{\\|g\\|} = \\frac{4}{5}$.\n\n7.  Calculate the Cauchy point $p_C$:\n    $$ p_C = -\\tau_C g = -\\frac{4}{5} \\begin{pmatrix} 3 \\\\ -4 \\end{pmatrix} = \\begin{pmatrix} -12/5 \\\\ 16/5 \\end{pmatrix} $$\n\nThe Cauchy point is $p_C = \\begin{pmatrix} -12/5 \\\\ 16/5 \\end{pmatrix}$. Let's verify its norm: $\\|p_C\\| = \\sqrt{(-12/5)^2 + (16/5)^2} = \\sqrt{\\frac{144+256}{25}} = \\sqrt{\\frac{400}{25}} = \\sqrt{16} = 4$, which is exactly equal to the trust-region radius $\\Delta$, as expected.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix} -\\frac{12}{5} \\\\ \\frac{16}{5} \\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The ultimate goal of our quadratic model is to find its unconstrained minimum, known as the Newton step. This step represents the ideal target for our optimization update if we can trust our model indefinitely. This practice will allow you to compute this crucial destination point, which defines the end of the dogleg path. ",
            "id": "2212755",
            "problem": "In a trust-region optimization algorithm, at the current iterate, the objective function is approximated by a quadratic model of the form $m(p) = f + g^T p + \\frac{1}{2} p^T B p$. This model describes the change in the objective function for a step $p$ from the current point. A key component in many trust-region strategies, such as the dogleg method, is the Newton step, which is the unconstrained minimizer of this quadratic model.\n\nGiven a gradient vector $g = \\begin{pmatrix} -4 \\\\ 6 \\end{pmatrix}$ and a positive-definite Hessian approximation matrix $B = \\begin{pmatrix} 2  0 \\\\ 0  3 \\end{pmatrix}$, calculate the Newton step $p_N$ for this quadratic model.",
            "solution": "The Newton step is the unconstrained minimizer of the quadratic model $m(p) = f + g^{T} p + \\frac{1}{2} p^{T} B p$. For a symmetric positive-definite $B$, the first-order optimality condition is obtained by setting the gradient with respect to $p$ to zero:\n$$\n\\nabla m(p) = g + B p = 0.\n$$\nThis yields the linear system\n$$\nB p_{N} = -g,\n$$\nso the Newton step is\n$$\np_{N} = -B^{-1} g.\n$$\nWith $g = \\begin{pmatrix} -4 \\\\ 6 \\end{pmatrix}$ and $B = \\begin{pmatrix} 2  0 \\\\ 0  3 \\end{pmatrix}$, the inverse is\n$$\nB^{-1} = \\begin{pmatrix} \\frac{1}{2}  0 \\\\ 0  \\frac{1}{3} \\end{pmatrix}.\n$$\nTherefore,\n$$\nB^{-1} g = \\begin{pmatrix} \\frac{1}{2}  0 \\\\ 0  \\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} -4 \\\\ 6 \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ 2 \\end{pmatrix},\n$$\nand\n$$\np_{N} = - \\begin{pmatrix} -2 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -2 \\end{pmatrix}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix} 2 \\\\ -2 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Now, we synthesize the concepts by constructing the full dogleg step. This final exercise simulates the most interesting case, where the Newton step is too far but the Cauchy point is well within reach, forcing the path to 'turn a corner'. You will calculate the final step by finding where the path segment connecting the Cauchy and Newton points intersects the trust-region boundary. ",
            "id": "2212758",
            "problem": "In the context of solving a trust-region subproblem in numerical optimization, the dogleg method is a popular technique for finding an approximate solution. This method constructs a trial step $p$ by following a path defined by two key vectors: the Cauchy point $p_U$ (the minimizer along the steepest descent direction) and the Newton point $p_N$ (the unconstrained minimizer of the quadratic model). The path consists of a line segment from the origin to $p_U$, followed by a line segment from $p_U$ to $p_N$. The final dogleg step $p$ is the point along this path that is farthest from the origin but still lies within the trust region, a sphere of radius $\\Delta$.\n\nConsider a specific iteration of an optimization algorithm where the Cauchy point and the Newton point are given by the vectors $p_U = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ and $p_N = \\begin{pmatrix} 4 \\\\ 4 \\end{pmatrix}$, respectively. The trust-region radius for this iteration is $\\Delta = 3$.\n\nDetermine the dogleg step vector $p$. Present your answer as a column vector with exact components.",
            "solution": "We are given $p_{U}=\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$, $p_{N}=\\begin{pmatrix}4 \\\\ 4\\end{pmatrix}$, and trust-region radius $\\Delta=3$. Compute the norms:\n$$\n\\|p_{U}\\|=\\sqrt{1^{2}+1^{2}}=\\sqrt{2},\\quad \\|p_{N}\\|=\\sqrt{4^{2}+4^{2}}=4\\sqrt{2}.\n$$\nSince $\\|p_{U}\\|\\Delta\\|p_{N}\\|$, the dogleg step lies on the segment from $p_{U}$ to $p_{N}$ and has norm exactly $\\Delta$. Parameterize the second segment by\n$$\np(\\tau)=p_{U}+\\tau\\,(p_{N}-p_{U}),\\quad \\tau\\in[0,1],\n$$\nwith $p_{N}-p_{U}=\\begin{pmatrix}3 \\\\ 3\\end{pmatrix}$. Then\n$$\np(\\tau)=\\begin{pmatrix}1+3\\tau \\\\ 1+3\\tau\\end{pmatrix},\\quad \\|p(\\tau)\\|^{2}=2\\,(1+3\\tau)^{2}.\n$$\nImpose the trust-region boundary condition $\\|p(\\tau)\\|=\\Delta$:\n$$\n2\\,(1+3\\tau)^{2}=9\\;\\Rightarrow\\;(1+3\\tau)^{2}=\\frac{9}{2}\\;\\Rightarrow\\;1+3\\tau=\\frac{3}{\\sqrt{2}},\n$$\nwhere the positive root is taken because $\\tau\\geq 0$. Hence\n$$\n3\\tau=\\frac{3}{\\sqrt{2}}-1\\;\\Rightarrow\\;\\tau=\\frac{1}{\\sqrt{2}}-\\frac{1}{3},\n$$\nwhich lies in $[0,1]$. Therefore\n$$\np=p(\\tau)=\\begin{pmatrix}1+3\\tau \\\\ 1+3\\tau\\end{pmatrix}=\\begin{pmatrix}\\frac{3}{\\sqrt{2}} \\\\ \\frac{3}{\\sqrt{2}}\\end{pmatrix}.\n$$\nEquivalently, rationalizing denominators gives $p=\\begin{pmatrix}\\frac{3\\sqrt{2}}{2} \\\\ \\frac{3\\sqrt{2}}{2}\\end{pmatrix}$. Both are exact forms.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{3\\sqrt{2}}{2} \\\\ \\frac{3\\sqrt{2}}{2}\\end{pmatrix}}$$"
        }
    ]
}