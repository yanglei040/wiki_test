{
    "hands_on_practices": [
        {
            "introduction": "Mastering Newton's method begins with understanding its core iterative step. This first exercise provides a direct, hands-on application of the procedure, guiding you through a single iteration for a system of nonlinear equations . By calculating the Jacobian matrix and solving the associated linear system, you will build a concrete understanding of how Newton's method refines an initial guess into a better approximation of the solution.",
            "id": "2190496",
            "problem": "An autonomous robot is programmed to navigate to a target location $(x, y)$ on a 2D plane. The target is defined as the intersection of two signal-defined paths. The equations for these paths are given by the following system of non-linear equations:\n$$\n\\begin{cases}\n    x^2 - y + \\cos(y) - 3 = 0 \\\\\n    x + y + \\sin(x) - 2 = 0\n\\end{cases}\n$$\nThe robot's current position is $\\mathbf{x}_0 = (x_0, y_0) = (1.5, 0.5)$. The coordinate system is measured in meters. To find the target, the robot's navigation algorithm will use Newton's method for systems of non-linear equations.\n\nPerform exactly one iteration of Newton's method to find the robot's next estimated position, $\\mathbf{x}_1 = (x_1, y_1)$. Assume that all arguments of trigonometric functions are given in radians.\n\nProvide the components of the updated position vector $\\mathbf{x}_1$. Express your answer for each component in meters, rounded to three significant figures.",
            "solution": "We frame the system as $\\mathbf{F}(x,y) = \\begin{pmatrix} f_{1}(x,y) \\\\ f_{2}(x,y) \\end{pmatrix}$ with\n$$\nf_{1}(x,y) = x^{2} - y + \\cos(y) - 3,\\quad f_{2}(x,y) = x + y + \\sin(x) - 2.\n$$\nNewton’s method for systems updates $\\mathbf{x}_{1} = \\mathbf{x}_{0} - J(\\mathbf{x}_{0})^{-1}\\mathbf{F}(\\mathbf{x}_{0})$, equivalently solve $J(\\mathbf{x}_{0})\\,\\mathbf{s} = -\\mathbf{F}(\\mathbf{x}_{0})$ for $\\mathbf{s}$ and set $\\mathbf{x}_{1} = \\mathbf{x}_{0} + \\mathbf{s}$.\n\nThe Jacobian is\n$$\nJ(x,y) = \\begin{pmatrix}\n\\frac{\\partial f_{1}}{\\partial x}  \\frac{\\partial f_{1}}{\\partial y} \\\\\n\\frac{\\partial f_{2}}{\\partial x}  \\frac{\\partial f_{2}}{\\partial y}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2x  -1 - \\sin(y) \\\\\n1 + \\cos(x)  1\n\\end{pmatrix}.\n$$\nAt $\\mathbf{x}_{0} = (x_{0},y_{0}) = (1.5, 0.5)$ (radians for trigonometric arguments),\n$$\n\\sin(0.5) \\approx 0.4794255386,\\quad \\cos(0.5) \\approx 0.8775825620,\\quad \\sin(1.5) \\approx 0.9974949866,\\quad \\cos(1.5) \\approx 0.0707372017.\n$$\nEvaluate the function:\n$$\n\\mathbf{F}(\\mathbf{x}_{0}) = \\begin{pmatrix}\n1.5^{2} - 0.5 + \\cos(0.5) - 3 \\\\\n1.5 + 0.5 + \\sin(1.5) - 2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-0.372417438 \\\\\n0.9974949866\n\\end{pmatrix}.\n$$\nEvaluate the Jacobian:\n$$\nJ(\\mathbf{x}_{0}) = \\begin{pmatrix}\n3  -1 - \\sin(0.5) \\\\\n1 + \\cos(1.5)  1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n3  -1.4794255386 \\\\\n1.0707372017  1\n\\end{pmatrix}.\n$$\nSet up and solve $J(\\mathbf{x}_{0})\\,\\mathbf{s} = -\\mathbf{F}(\\mathbf{x}_{0})$:\n$$\n\\begin{pmatrix}\n3  -1.4794255386 \\\\\n1.0707372017  1\n\\end{pmatrix}\n\\begin{pmatrix}\ns_{1} \\\\ s_{2}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.372417438 \\\\\n-0.9974949866\n\\end{pmatrix}.\n$$\nFrom the second equation, $s_{2} = -0.9974949866 - 1.0707372017\\,s_{1}$. Substitute into the first:\n$$\n(3 + 1.4794255386 \\cdot 1.0707372017)\\,s_{1} + 1.4794255386 \\cdot 0.9974949866 = 0.372417438,\n$$\nso\n$$\ns_{1} = \\frac{0.372417438 - 1.4794255386 \\cdot 0.9974949866}{3 + 1.4794255386 \\cdot 1.0707372017} \\approx \\frac{-1.103302119}{4.5840759613} \\approx -0.240682.\n$$\nThen\n$$\ns_{2} = -0.9974949866 - 1.0707372017\\,(-0.240682) \\approx -0.739788.\n$$\nUpdate the estimate:\n$$\nx_{1} = x_{0} + s_{1} \\approx 1.5 - 0.240682 = 1.259318,\\quad\ny_{1} = y_{0} + s_{2} \\approx 0.5 - 0.739788 = -0.239788.\n$$\nRounded to three significant figures (meters): $x_{1} \\approx 1.26$, $y_{1} \\approx -0.240$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 1.26  -0.240 \\end{pmatrix}}$$"
        },
        {
            "introduction": "This problem reveals the theoretical foundation of Newton's method. By applying the algorithm to a simple linear system, you will discover its remarkable efficiency in this special case, converging to the exact solution in a single step . This thought experiment clarifies that the method works by iteratively solving a sequence of linear approximations; if the function is already linear, the first approximation is exact.",
            "id": "2190469",
            "problem": "Consider a system of $n$ linear equations with $n$ unknowns, represented in matrix form as $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$, where $\\mathbf{A}$ is an invertible $n \\times n$ matrix, and $\\mathbf{x}, \\mathbf{b}$ are column vectors in $\\mathbb{R}^n$. Solving this system is equivalent to finding the root of the vector-valued function $\\mathbf{F}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} - \\mathbf{b}$.\n\nOne can attempt to find this root using Newton's method for systems. The iterative formula for Newton's method is given by:\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_k - [J_F(\\mathbf{x}_k)]^{-1} \\mathbf{F}(\\mathbf{x}_k)\n$$\nwhere $\\mathbf{x}_k$ is the approximation at iteration $k$, and $J_F(\\mathbf{x}_k)$ is the Jacobian matrix of the function $\\mathbf{F}$ evaluated at $\\mathbf{x}_k$.\n\nStarting with an arbitrary initial guess $\\mathbf{x}_0$, perform one full iteration of Newton's method to find the next approximation, $\\mathbf{x}_1$. Your task is to derive a simplified expression for $\\mathbf{x}_1$. The final expression may contain $\\mathbf{A}$, $\\mathbf{b}$, and $\\mathbf{x}_0$, or it may simplify further.",
            "solution": "We consider the system $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ and define the vector-valued function $\\mathbf{F}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} - \\mathbf{b}$. Newton's method for systems updates via\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_{k} - \\left[J_{F}(\\mathbf{x}_{k})\\right]^{-1}\\mathbf{F}(\\mathbf{x}_{k}),\n$$\nwhere $J_{F}(\\mathbf{x})$ is the Jacobian matrix of $\\mathbf{F}$.\n\nSince $\\mathbf{F}(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} - \\mathbf{b}$ is linear, its Jacobian is constant and equal to the matrix $\\mathbf{A}$ for all $\\mathbf{x}$:\n$$\nJ_{F}(\\mathbf{x}) = \\mathbf{A}.\n$$\nGiven that $\\mathbf{A}$ is invertible, we have $\\left[J_{F}(\\mathbf{x}_{0})\\right]^{-1} = \\mathbf{A}^{-1}$. Substituting into the Newton update with $\\mathbf{x}_{k} = \\mathbf{x}_{0}$,\n$$\n\\mathbf{x}_{1} = \\mathbf{x}_{0} - \\mathbf{A}^{-1}\\left(\\mathbf{A}\\mathbf{x}_{0} - \\mathbf{b}\\right).\n$$\nDistribute $\\mathbf{A}^{-1}$ and simplify:\n$$\n\\mathbf{x}_{1} = \\mathbf{x}_{0} - \\left(\\mathbf{x}_{0} - \\mathbf{A}^{-1}\\mathbf{b}\\right) = \\mathbf{A}^{-1}\\mathbf{b}.\n$$\nThus, after one iteration from any initial guess $\\mathbf{x}_{0}$, Newton's method yields the exact solution $\\mathbf{A}^{-1}\\mathbf{b}$.",
            "answer": "$$\\boxed{\\mathbf{A}^{-1}\\mathbf{b}}$$"
        },
        {
            "introduction": "A powerful algorithm is only truly understood when its limitations are clear. This problem explores a critical failure scenario where the Jacobian matrix becomes singular, making the update step $\\mathbf{x}_{k+1} = \\mathbf{x}_k - [J_F(\\mathbf{x}_k)]^{-1} \\mathbf{F}(\\mathbf{x}_k)$ impossible to compute . By connecting the algebraic condition of a singular Jacobian to its geometric meaning, you will gain a deeper appreciation for the conditions required for the method's success.",
            "id": "2190480",
            "problem": "Consider the system of two nonlinear equations:\n1. $x^2 + y^2 - 1 = 0$\n2. $y - x^3 = 0$\n\nAn attempt is made to find a numerical solution to this system using Newton's method for systems of equations. The initial guess for the solution is taken to be the point $(x_0, y_0) = (0, 2)$.\n\nWhich of the following statements best describes the outcome of the first iteration of Newton's method starting from this initial guess?\n\nA. The method successfully computes the next iteration $(x_1, y_1)$ as $(0, 1)$, which is one of the true roots of the system.\n\nB. The next iteration $(x_1, y_1)$ is computed to be the origin $(0, 0)$.\n\nC. The method fails because the Jacobian matrix evaluated at the initial guess is singular. Geometrically, this corresponds to the tangent lines to the respective level curves at the initial guess being parallel.\n\nD. The method produces a next iteration $(x_1, y_1)$ that is farther from the true roots than the initial guess, indicating divergence.\n\nE. The method fails because the initial guess lies on one of the solution curves.",
            "solution": "Let $f:\\mathbb{R}^{2}\\to\\mathbb{R}^{2}$ be given by\n$$\nf(x,y)=\\begin{pmatrix}\nf_{1}(x,y)\\\\\nf_{2}(x,y)\n\\end{pmatrix}\n=\\begin{pmatrix}\nx^{2}+y^{2}-1\\\\\ny-x^{3}\n\\end{pmatrix}.\n$$\nNewton’s method for systems computes $(x_{1},y_{1})=(x_{0},y_{0})+\\Delta$ by solving the linear system\n$$\nJ_{f}(x_{0},y_{0})\\,\\Delta=-f(x_{0},y_{0}),\n$$\nwhere $J_{f}$ is the Jacobian matrix of $f$:\n$$\nJ_{f}(x,y)=\\begin{pmatrix}\n\\frac{\\partial f_{1}}{\\partial x}  \\frac{\\partial f_{1}}{\\partial y}\\\\\n\\frac{\\partial f_{2}}{\\partial x}  \\frac{\\partial f_{2}}{\\partial y}\n\\end{pmatrix}\n=\\begin{pmatrix}\n2x  2y\\\\\n-3x^{2}  1\n\\end{pmatrix}.\n$$\nAt the initial guess $(x_{0},y_{0})=(0,2)$ we have\n$$\nJ_{f}(0,2)=\\begin{pmatrix}\n0  4\\\\\n0  1\n\\end{pmatrix},\n\\qquad\nf(0,2)=\\begin{pmatrix}\n0^{2}+2^{2}-1\\\\\n2-0^{3}\n\\end{pmatrix}\n=\\begin{pmatrix}\n3\\\\\n2\n\\end{pmatrix}.\n$$\nThe Newton step requires solving\n$$\n\\begin{pmatrix}\n0  4\\\\\n0  1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\Delta x\\\\\n\\Delta y\n\\end{pmatrix}\n=\n-\\begin{pmatrix}\n3\\\\\n2\n\\end{pmatrix}\n=\\begin{pmatrix}\n-3\\\\\n-2\n\\end{pmatrix}.\n$$\nThis yields the equations $4\\Delta y=-3$ and $\\Delta y=-2$, which are inconsistent. Equivalently, the Jacobian is singular since\n$$\n\\det J_{f}(0,2)=0\\cdot 1-4\\cdot 0=0,\n$$\nso the linear system has no solution and Newton’s method fails to produce $(x_{1},y_{1})$.\n\nGeometrically, the rows of $J_{f}(0,2)$ are proportional, which means the gradients of the two equations at $(0,2)$ are linearly dependent:\n$$\n\\nabla f_{1}(0,2)=(2\\cdot 0,2\\cdot 2)=(0,4),\\qquad \\nabla f_{2}(0,2)=(-3\\cdot 0^{2},1)=(0,1).\n$$\nParallel gradients imply the tangent lines to the level curves $f_{1}=0$ and $f_{2}=0$ at $(0,2)$ are parallel, matching the geometric description of a singular Jacobian.\n\nTherefore, the correct statement is that the method fails at the first iteration due to a singular Jacobian, with the geometric interpretation of parallel tangents.\n\nTo rule out other options: $(0,1)$ is not a solution since it does not satisfy $y=x^{3}$, $(0,0)$ cannot be reached because the Newton step is undefined here, divergence cannot be assessed without a defined step, and the initial guess does not lie on either solution curve since $f(0,2)\\neq 0$.",
            "answer": "$$\\boxed{C}$$"
        }
    ]
}