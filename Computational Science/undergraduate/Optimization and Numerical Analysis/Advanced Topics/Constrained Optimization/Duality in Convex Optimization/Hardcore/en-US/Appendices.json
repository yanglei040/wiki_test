{
    "hands_on_practices": [
        {
            "introduction": "The first step in leveraging the power of duality is understanding how to construct the dual problem from a given primal problem. This exercise provides a foundational workout in these mechanics. By working with a simple yet illustrative quadratic function subject to interval constraints, you will practice formulating the Lagrangian and then deriving the corresponding dual function by minimizing the Lagrangian with respect to the primal variable .",
            "id": "2167425",
            "problem": "Consider the optimization problem of minimizing the function $f(x) = c x^2$ with respect to the real variable $x$. The function is parameterized by a positive constant $c$. The optimization is subject to the constraint that $x$ must lie in the closed interval $[a, b]$, where $a$ and $b$ are real constants satisfying $a  b$.\n\nYour task is to formulate the Lagrange dual of this problem. Specifically, find the dual function $g(\\lambda, \\mu)$, where $\\lambda$ is the Lagrange multiplier associated with the constraint $a \\le x$ and $\\mu$ is the Lagrange multiplier associated with the constraint $x \\le b$. Express your answer for $g(\\lambda, \\mu)$ as a function of the parameters $a, b, c$ and the dual variables $\\lambda, \\mu$.",
            "solution": "We rewrite the constraints in standard inequality form as $g_{1}(x) = a - x \\le 0$ and $g_{2}(x) = x - b \\le 0$. Associate Lagrange multipliers $\\lambda \\ge 0$ with $g_{1}$ and $\\mu \\ge 0$ with $g_{2}$. The Lagrangian is\n$$\nL(x,\\lambda,\\mu) = c x^{2} + \\lambda(a - x) + \\mu(x - b) = c x^{2} + (\\mu - \\lambda)x + \\lambda a - \\mu b.\n$$\nThe dual function is $g(\\lambda,\\mu) = \\inf_{x \\in \\mathbb{R}} L(x,\\lambda,\\mu)$. Since $c  0$, $L$ is strictly convex in $x$. The minimizer satisfies the first-order condition\n$$\n\\frac{\\partial L}{\\partial x} = 2 c x + (\\mu - \\lambda) = 0 \\quad \\Rightarrow \\quad x^{\\ast} = \\frac{\\lambda - \\mu}{2 c}.\n$$\nSubstituting $x^{\\ast}$ into $L$ yields\n$$\ng(\\lambda,\\mu) = c \\left(\\frac{\\lambda - \\mu}{2 c}\\right)^{2} + (\\mu - \\lambda)\\left(\\frac{\\lambda - \\mu}{2 c}\\right) + \\lambda a - \\mu b = - \\frac{(\\mu - \\lambda)^{2}}{4 c} + \\lambda a - \\mu b,\n$$\nvalid for $\\lambda \\ge 0$ and $\\mu \\ge 0$.",
            "answer": "$$\\boxed{-\\frac{(\\mu - \\lambda)^{2}}{4 c} + \\lambda a - \\mu b}$$"
        },
        {
            "introduction": "After formulating a dual problem, the next crucial step is to understand its relationship with the primal solution. This exercise guides you through finding the \"saddle point\" of the Lagrangian, a point that represents a stable equilibrium between the primal and dual variables. You will use the powerful Karush-Kuhn-Tucker (KKT) conditions, which provide a complete characterization of the optimal solution for convex problems, linking primal feasibility, dual feasibility, and the core concept of complementary slackness .",
            "id": "2167418",
            "problem": "In a simplified machine learning scenario, the cost associated with a model parameter, $x$, is described by the quadratic function $f(x) = \\frac{1}{2}x^2$. To prevent underfitting and ensure the model has a minimum level of complexity, a domain expert imposes a constraint that the parameter $x$ must be at least 2. This leads to a constrained optimization problem.\n\nThe Lagrangian function for this problem is defined as $L(x, \\lambda) = f(x) + \\lambda g(x)$, where $g(x) \\le 0$ represents the inequality constraint and $\\lambda \\ge 0$ is the Lagrange multiplier.\n\nYour task is to find the saddle point $(x^*, \\lambda^*)$ of the Lagrangian. This point corresponds to the optimal parameter value $x^*$ that minimizes the cost function subject to the constraint, and the associated optimal Lagrange multiplier $\\lambda^*$.\n\nReport the saddle point as an ordered pair $(x^*, \\lambda^*)$.",
            "solution": "We are given the convex quadratic objective $f(x) = \\frac{1}{2}x^{2}$ and the inequality constraint $x \\geq 2$. To express this in the standard form $g(x) \\leq 0$, define $g(x) = 2 - x$, so the constraint is $g(x) \\leq 0$. The Lagrangian is\n$$\nL(x, \\lambda) = \\frac{1}{2}x^{2} + \\lambda(2 - x),\n$$\nwith dual feasibility $\\lambda \\geq 0$.\n\nFor a convex problem with affine constraint, the Karush–Kuhn–Tucker conditions are necessary and sufficient for optimality and for characterizing a saddle point. The KKT conditions are:\n- Primal feasibility: $g(x^{*}) \\leq 0$, i.e., $x^{*} \\geq 2$.\n- Dual feasibility: $\\lambda^{*} \\geq 0$.\n- Stationarity: $\\frac{\\partial L}{\\partial x}(x^{*}, \\lambda^{*}) = 0$.\n- Complementary slackness: $\\lambda^{*} g(x^{*}) = 0$.\n\nCompute the stationarity condition:\n$$\n\\frac{\\partial L}{\\partial x} = x - \\lambda \\quad \\Rightarrow \\quad x^{*} - \\lambda^{*} = 0 \\quad \\Rightarrow \\quad x^{*} = \\lambda^{*}.\n$$\nApply complementary slackness:\n$$\n\\lambda^{*}(2 - x^{*}) = 0.\n$$\nConsider the cases:\n- If $\\lambda^{*} = 0$, then from stationarity $x^{*} = 0$, which violates primal feasibility $x^{*} \\geq 2$; reject this case.\n- Therefore $2 - x^{*} = 0 \\Rightarrow x^{*} = 2$. Then by stationarity $\\lambda^{*} = x^{*} = 2$, which satisfies $\\lambda^{*} \\geq 0$ and $x^{*} \\geq 2$.\n\nThus, the unique KKT point is $(x^{*}, \\lambda^{*}) = (2, 2)$. Because the problem is convex with an affine constraint, this KKT point is the saddle point of the Lagrangian. Equivalently, verifying the saddle property: $L(x, 2)$ is minimized at $x = 2$, and $L(2, \\lambda) = 2$ for all $\\lambda \\geq 0$, with the dual maximizer at $\\lambda^{*} = 2$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 2  2 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Now we can apply our understanding to a more complex and realistic scenario. This practice problem involves minimizing a cost function with two variables, subject to both an equality and an inequality constraint, mirroring challenges found in engineering and resource allocation. By solving this problem, you will see how the principles of duality and the KKT conditions seamlessly integrate to handle multiple constraints and deliver the optimal solution, showcasing the true utility of these methods in practical optimization .",
            "id": "2167392",
            "problem": "Consider a system with two interacting components whose states are described by variables $x_1$ and $x_2$. The operational cost of the system is a function of these states, given by $C(x_1, x_2) = (x_1 - 4)^2 + (x_2 - 3)^2$. The system is subject to two operational constraints. First, a strict resource-sharing protocol requires that the sum of the states equals a constant value, i.e., $x_1 + x_2 = 5$. Second, a safety regulation imposes a limit on the combined state magnitude, requiring that the sum of the squares of the states does not exceed a threshold $M=13$, i.e., $x_1^2 + x_2^2 \\le 13$.\n\nYour task is to determine the optimal state $(x_1^*, x_2^*)$ that minimizes the operational cost $C(x_1, x_2)$ while satisfying both constraints.\n\nExpress your answer as a row matrix of the form $\\begin{pmatrix} x_1^*  x_2^* \\end{pmatrix}$.",
            "solution": "We minimize the convex quadratic cost subject to convex constraints. Because the feasible set is the intersection of the affine set $x_{1}+x_{2}=5$ with the disk $x_{1}^{2}+x_{2}^{2}\\leq 13$, it is convex and nonempty. A point that minimizes the cost on the affine set and lies in the disk is the global minimizer.\n\nFirst, minimize $C(x_{1},x_{2})=(x_{1}-4)^{2}+(x_{2}-3)^{2}$ subject to the equality $x_{1}+x_{2}=5$ using a Lagrange multiplier $\\lambda$. Define\n$$\nL(x_{1},x_{2},\\lambda)=(x_{1}-4)^{2}+(x_{2}-3)^{2}+\\lambda(x_{1}+x_{2}-5).\n$$\nStationarity and feasibility give\n$$\n\\frac{\\partial L}{\\partial x_{1}}=2(x_{1}-4)+\\lambda=0,\\quad \\frac{\\partial L}{\\partial x_{2}}=2(x_{2}-3)+\\lambda=0,\\quad \\frac{\\partial L}{\\partial \\lambda}=x_{1}+x_{2}-5=0.\n$$\nSubtracting the first two equations yields\n$$\n2(x_{1}-4)-2(x_{2}-3)=0 \\;\\;\\Rightarrow\\;\\; x_{1}-x_{2}=1.\n$$\nTogether with $x_{1}+x_{2}=5$, solving gives\n$$\nx_{1}=\\frac{(x_{1}+x_{2})+(x_{1}-x_{2})}{2}=\\frac{5+1}{2}=3,\\quad x_{2}=\\frac{(x_{1}+x_{2})-(x_{1}-x_{2})}{2}=\\frac{5-1}{2}=2.\n$$\nNow check the inequality constraint:\n$$\nx_{1}^{2}+x_{2}^{2}=3^{2}+2^{2}=9+4=13\\leq 13,\n$$\nso $(3,2)$ is feasible for both constraints.\n\nBecause the objective is strictly convex and the feasible set is convex, the KKT conditions are sufficient for global optimality. The point $(3,2)$ satisfies the KKT conditions for the full problem as well, for example with inequality multiplier $\\mu=0$:\n- Stationarity for the full Lagrangian $L=(x_{1}-4)^{2}+(x_{2}-3)^{2}+\\lambda(x_{1}+x_{2}-5)+\\mu(x_{1}^{2}+x_{2}^{2}-13)$ reduces to the equality-only case when $\\mu=0$ and is satisfied by $(3,2)$.\n- Primal feasibility holds: $x_{1}+x_{2}=5$ and $x_{1}^{2}+x_{2}^{2}-13=0\\leq 0$.\n- Complementary slackness holds: $\\mu(x_{1}^{2}+x_{2}^{2}-13)=0$.\n- Dual feasibility holds: $\\mu=0\\geq 0$.\n\nTherefore, the unique optimal state is $(x_{1}^{*},x_{2}^{*})=(3,2)$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 3  2 \\end{pmatrix}}$$"
        }
    ]
}