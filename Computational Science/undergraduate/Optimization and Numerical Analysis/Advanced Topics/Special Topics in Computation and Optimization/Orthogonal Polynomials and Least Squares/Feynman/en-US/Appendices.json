{
    "hands_on_practices": [
        {
            "introduction": "To fully appreciate the power of orthogonal polynomials, we must first understand how they are constructed. The Gram-Schmidt process is a fundamental algorithm that systematically transforms any set of linearly independent functions into an orthogonal one. This exercise  provides direct, hands-on practice with this crucial method, building geometric intuition about projecting a function onto another and finding the orthogonal component.",
            "id": "2192756",
            "problem": "Consider the vector space of all real-valued polynomials of degree at most two, defined on the interval $[-1, 1]$. We can define an inner product on this space for any two polynomials $f(x)$ and $g(x)$ as $\\langle f, g \\rangle = \\int_{-1}^{1} f(x)g(x) dx$. One possible basis for this space is the ordered set of polynomials $B = \\{v_0(x), v_1(x), v_2(x)\\}$, where $v_0(x) = 1$, $v_1(x) = x+1$, and $v_2(x) = x^2$.\n\nTo facilitate certain numerical computations, it is often useful to transform a given basis into an orthogonal one. Apply the Gram-Schmidt process to the ordered basis $B$ to generate a new set of orthogonal polynomials $\\{p_0(x), p_1(x), p_2(x)\\}$.\n\nDetermine the value of the third orthogonal polynomial, $p_2(x)$, when evaluated at $x = \\frac{1}{2}$. Express your answer as a fraction in simplest form.",
            "solution": "We are asked to apply the Gram-Schmidt process to the ordered basis $\\{v_0(x), v_1(x), v_2(x)\\} = \\{1, x+1, x^2\\}$ with the inner product $\\langle f, g \\rangle = \\int_{-1}^{1} f(x)g(x) dx$. The resulting orthogonal polynomials $\\{p_0(x), p_1(x), p_2(x)\\}$ are constructed as follows.\n\nFirst, we set the first orthogonal polynomial $p_0(x)$ to be equal to the first basis vector $v_0(x)$:\n$$p_0(x) = v_0(x) = 1$$\n\nNext, we find the second orthogonal polynomial $p_1(x)$ by subtracting the projection of $v_1(x)$ onto $p_0(x)$ from $v_1(x)$:\n$$p_1(x) = v_1(x) - \\frac{\\langle v_1, p_0 \\rangle}{\\langle p_0, p_0 \\rangle} p_0(x)$$\nTo compute this, we need to evaluate the required inner products.\n$$ \\langle p_0, p_0 \\rangle = \\int_{-1}^{1} (1)(1) dx = [x]_{-1}^{1} = 1 - (-1) = 2 $$\n$$ \\langle v_1, p_0 \\rangle = \\int_{-1}^{1} (x+1)(1) dx = \\left[\\frac{x^2}{2} + x\\right]_{-1}^{1} = \\left(\\frac{1}{2} + 1\\right) - \\left(\\frac{(-1)^2}{2} - 1\\right) = \\frac{3}{2} - \\left(-\\frac{1}{2}\\right) = 2 $$\nNow we can substitute these values back into the expression for $p_1(x)$:\n$$p_1(x) = (x+1) - \\frac{2}{2}(1) = x+1-1 = x$$\n\nFinally, we construct the third orthogonal polynomial $p_2(x)$ by subtracting the projections of $v_2(x)$ onto $p_0(x)$ and $p_1(x)$ from $v_2(x)$:\n$$p_2(x) = v_2(x) - \\frac{\\langle v_2, p_0 \\rangle}{\\langle p_0, p_0 \\rangle} p_0(x) - \\frac{\\langle v_2, p_1 \\rangle}{\\langle p_1, p_1 \\rangle} p_1(x)$$\nWe need to compute three more inner products. We already have $\\langle p_0, p_0 \\rangle = 2$.\n$$ \\langle p_1, p_1 \\rangle = \\int_{-1}^{1} (x)(x) dx = \\int_{-1}^{1} x^2 dx = \\left[\\frac{x^3}{3}\\right]_{-1}^{1} = \\frac{1}{3} - \\frac{-1}{3} = \\frac{2}{3} $$\n$$ \\langle v_2, p_0 \\rangle = \\int_{-1}^{1} (x^2)(1) dx = \\int_{-1}^{1} x^2 dx = \\left[\\frac{x^3}{3}\\right]_{-1}^{1} = \\frac{2}{3} $$\n$$ \\langle v_2, p_1 \\rangle = \\int_{-1}^{1} (x^2)(x) dx = \\int_{-1}^{1} x^3 dx = \\left[\\frac{x^4}{4}\\right]_{-1}^{1} = \\frac{1}{4} - \\frac{1}{4} = 0 $$\nNote that the integral for $\\langle v_2, p_1 \\rangle$ is zero because the integrand $x^3$ is an odd function integrated over a symmetric interval.\nNow, we substitute these values into the expression for $p_2(x)$:\n$$p_2(x) = x^2 - \\frac{2/3}{2}(1) - \\frac{0}{2/3}(x) = x^2 - \\frac{1}{3} - 0 = x^2 - \\frac{1}{3}$$\nThe set of orthogonal polynomials is $\\{1, x, x^2 - \\frac{1}{3}\\}$.\n\nThe problem asks for the value of $p_2(x)$ at $x = \\frac{1}{2}$.\n$$ p_2\\left(\\frac{1}{2}\\right) = \\left(\\frac{1}{2}\\right)^2 - \\frac{1}{3} = \\frac{1}{4} - \\frac{1}{3} $$\nTo subtract the fractions, we find a common denominator, which is 12:\n$$ p_2\\left(\\frac{1}{2}\\right) = \\frac{3}{12} - \\frac{4}{12} = -\\frac{1}{12} $$\nThe value of the third orthogonal polynomial at $x=1/2$ is $-\\frac{1}{12}$.",
            "answer": "$$\\boxed{-\\frac{1}{12}}$$"
        },
        {
            "introduction": "Once we have an orthogonal basis, such as the Legendre polynomials, solving least-squares problems becomes remarkably straightforward. Instead of setting up and solving a dense system of normal equations, we can find the coefficients of the best-fitting polynomial by simply projecting our target function onto each basis element. This practice  demonstrates this elegant projection technique, showcasing how orthogonality simplifies the approximation of a function like $f(x) = x^3$.",
            "id": "2192785",
            "problem": "Consider the function $f(x) = x^3$ defined on the interval $[-1, 1]$. We seek the polynomial of degree at most 2, let's denote it by $p(x)$, that provides the best least-squares approximation to $f(x)$ on this interval. The \"best\" approximation is the one that minimizes the integral of the squared error, $E = \\int_{-1}^{1} [f(x) - p(x)]^2 dx$.\n\nA robust method to find such an approximation is to project the function $f(x)$ onto the space of polynomials of degree at most 2 using an orthogonal basis. For the interval $[-1, 1]$, the Legendre polynomials form such a basis. The first three Legendre polynomials are given by:\n$P_0(x) = 1$\n$P_1(x) = x$\n$P_2(x) = \\frac{1}{2}(3x^2 - 1)$\n\nDetermine the best least-squares approximation polynomial, $p(x)$, for $f(x) = x^3$ on the interval $[-1, 1]$. Express your final answer as a polynomial in the standard basis (i.e., in terms of powers of $x$).",
            "solution": "We approximate $f(x)=x^{3}$ on $[-1,1]$ by its orthogonal projection onto the space $\\mathcal{P}_{2}$ of polynomials of degree at most $2$ with respect to the inner product $\\langle g,h\\rangle=\\int_{-1}^{1} g(x)h(x)\\,dx$. Using the orthogonal basis $\\{P_{0},P_{1},P_{2}\\}$ of Legendre polynomials on $[-1,1]$, the best least-squares approximation is\n$$\np(x)=\\sum_{n=0}^{2} c_{n} P_{n}(x), \\quad c_{n}=\\frac{\\langle f,P_{n}\\rangle}{\\langle P_{n},P_{n}\\rangle}.\n$$\nWe use $P_{0}(x)=1$, $P_{1}(x)=x$, $P_{2}(x)=\\frac{1}{2}(3x^{2}-1)$ and the orthogonality norms $\\langle P_{n},P_{n}\\rangle=\\frac{2}{2n+1}$.\n\nFirst, compute $c_{0}$:\n$$\nc_{0}=\\frac{\\int_{-1}^{1} x^{3}\\cdot 1\\,dx}{\\int_{-1}^{1} 1\\cdot 1\\,dx}=\\frac{\\int_{-1}^{1} x^{3}\\,dx}{2}=0,\n$$\nsince $x^{3}$ is odd and integrates to $0$ over $[-1,1]$.\n\nNext, compute $c_{1}$:\n$$\nc_{1}=\\frac{\\int_{-1}^{1} x^{3}\\cdot x\\,dx}{\\int_{-1}^{1} x\\cdot x\\,dx}\n=\\frac{\\int_{-1}^{1} x^{4}\\,dx}{\\int_{-1}^{1} x^{2}\\,dx}.\n$$\nEvaluate the integrals exactly:\n$$\n\\int_{-1}^{1} x^{4}\\,dx=\\left[\\frac{x^{5}}{5}\\right]_{-1}^{1}=\\frac{2}{5},\\qquad\n\\int_{-1}^{1} x^{2}\\,dx=\\left[\\frac{x^{3}}{3}\\right]_{-1}^{1}=\\frac{2}{3},\n$$\nhence\n$$\nc_{1}=\\frac{\\frac{2}{5}}{\\frac{2}{3}}=\\frac{3}{5}.\n$$\n\nFinally, compute $c_{2}$:\n$$\nc_{2}=\\frac{\\int_{-1}^{1} x^{3}\\cdot \\frac{1}{2}(3x^{2}-1)\\,dx}{\\int_{-1}^{1} \\left(\\frac{1}{2}(3x^{2}-1)\\right)^{2}\\,dx}.\n$$\nThe numerator integrand $x^{3}\\cdot \\frac{1}{2}(3x^{2}-1)$ is an odd function (product of an odd and an even function), so its integral over $[-1,1]$ is $0$. Therefore $c_{2}=0$.\n\nCombining the coefficients,\n$$\np(x)=c_{0}P_{0}(x)+c_{1}P_{1}(x)+c_{2}P_{2}(x)=0\\cdot 1+\\frac{3}{5}\\,x+0\\cdot \\frac{1}{2}(3x^{2}-1)=\\frac{3}{5}x.\n$$\nExpressed in the standard polynomial basis, $p(x)=\\frac{3}{5}x$.",
            "answer": "$$\\boxed{\\frac{3}{5}x}$$"
        },
        {
            "introduction": "While the Gram-Schmidt process is conceptually vital, the three-term recurrence relation offers a more computationally stable and efficient method for generating orthogonal polynomials, especially for discrete data sets. This approach is central to many numerical methods in data analysis, where orthogonality is defined by a weighted sum over discrete points rather than an integral. In this problem , you will calculate a key coefficient in this recurrence, connecting the abstract theory of orthogonality to its practical implementation with finite data.",
            "id": "2192741",
            "problem": "In the numerical analysis of experimental data, it is often advantageous to work with a basis of functions that are orthogonal with respect to the data points. Consider a set of four experimental measurements at coordinates $\\{x_i\\} = \\{0, 1, 3, 6\\}$. We are interested in generating a sequence of monic polynomials $\\{p_k(x)\\}_{k=0}^\\infty$ that are orthogonal with respect to a discrete inner product.\n\nThe inner product of two real-valued functions, $f(x)$ and $g(x)$, over this set of points is defined as:\n$$ \\langle f, g \\rangle = \\sum_{i=1}^{4} f(x_i) g(x_i) $$\nThe sequence of orthogonal monic polynomials is generated by the three-term recurrence relation:\n$p_{k+1}(x) = (x - \\alpha_k) p_k(x) - \\beta_k p_{k-1}(x)$\nfor $k \\ge 0$, with the initial conditions defined as $p_0(x) = 1$ and $p_{-1}(x) = 0$.\n\nYour task is to determine the exact value of the recurrence coefficient $\\alpha_1$. Express your final answer as a fraction in simplest form.",
            "solution": "We use the given discrete inner product\n$$\\langle f, g \\rangle = \\sum_{i=1}^{4} f(x_{i}) g(x_{i}), \\quad \\{x_{i}\\}=\\{0,1,3,6\\},$$\nand the monic three-term recurrence\n$$p_{k+1}(x)=(x-\\alpha_{k})p_{k}(x)-\\beta_{k}p_{k-1}(x), \\quad p_{0}(x)=1,\\; p_{-1}(x)=0.$$\n\nFor monic orthogonal polynomials, taking the inner product of the recurrence with $p_{k}$ yields\n$$\\langle p_{k+1},p_{k}\\rangle=\\langle (x-\\alpha_{k})p_{k},p_{k}\\rangle-\\beta_{k}\\langle p_{k-1},p_{k}\\rangle.$$\nBy orthogonality, $\\langle p_{k+1},p_{k}\\rangle=0$ and $\\langle p_{k-1},p_{k}\\rangle=0$, hence\n$$0=\\langle x p_{k},p_{k}\\rangle-\\alpha_{k}\\langle p_{k},p_{k}\\rangle,$$\nso\n$$\\alpha_{k}=\\frac{\\langle x p_{k},p_{k}\\rangle}{\\langle p_{k},p_{k}\\rangle}.$$\n\nFirst, compute $\\alpha_{0}$:\n$$\\alpha_{0}=\\frac{\\langle x p_{0},p_{0}\\rangle}{\\langle p_{0},p_{0}\\rangle}\n=\\frac{\\sum_{i=1}^{4} x_{i}}{\\sum_{i=1}^{4} 1}\n=\\frac{0+1+3+6}{4}\n=\\frac{10}{4}\n=\\frac{5}{2}.$$\nThus\n$$p_{1}(x)=x-\\alpha_{0}=x-\\frac{5}{2}.$$\n\nNow compute $\\alpha_{1}$ using\n$$\\alpha_{1}=\\frac{\\langle x p_{1},p_{1}\\rangle}{\\langle p_{1},p_{1}\\rangle}\n=\\frac{\\sum_{i=1}^{4} x_{i}\\,p_{1}(x_{i})^{2}}{\\sum_{i=1}^{4} p_{1}(x_{i})^{2}}.$$\nEvaluate $p_{1}(x)$ at the data points:\n$$p_{1}(0)=-\\frac{5}{2},\\quad p_{1}(1)=-\\frac{3}{2},\\quad p_{1}(3)=\\frac{1}{2},\\quad p_{1}(6)=\\frac{7}{2}.$$\nSquares:\n$$p_{1}(0)^{2}=\\frac{25}{4},\\quad p_{1}(1)^{2}=\\frac{9}{4},\\quad p_{1}(3)^{2}=\\frac{1}{4},\\quad p_{1}(6)^{2}=\\frac{49}{4}.$$\nDenominator:\n$$\\langle p_{1},p_{1}\\rangle=\\frac{25}{4}+\\frac{9}{4}+\\frac{1}{4}+\\frac{49}{4}=\\frac{84}{4}=21.$$\nNumerator:\n$$\\langle x p_{1},p_{1}\\rangle=0\\cdot\\frac{25}{4}+1\\cdot\\frac{9}{4}+3\\cdot\\frac{1}{4}+6\\cdot\\frac{49}{4}\n=\\frac{9}{4}+\\frac{3}{4}+\\frac{294}{4}=\\frac{306}{4}=\\frac{153}{2}.$$\nTherefore\n$$\\alpha_{1}=\\frac{\\frac{153}{2}}{21}=\\frac{153}{42}=\\frac{51}{14}.$$\nThis fraction is already in simplest form.",
            "answer": "$$\\boxed{\\frac{51}{14}}$$"
        }
    ]
}