{
    "hands_on_practices": [
        {
            "introduction": "To begin, let's ground our understanding of the condition number in its fundamental definition. This first practice treats the condition number, $\\kappa_2(A)$, as the ratio of the largest singular value ($\\sigma_{\\max}$) to the smallest ($\\sigma_{\\min}$), which represent the maximum and minimum stretching a matrix applies to a vector. By directly calculating this ratio from a given set of singular values, you will solidify the core computational skill in a practical context inspired by digital image processing .",
            "id": "1393626",
            "problem": "In the field of digital image processing, linear filters are often applied to images for effects like sharpening or blurring. The action of such a filter can be represented by a matrix transformation, $y = Ax$, where $x$ is the original image data vectorized, $A$ is the filter matrix, and $y$ is the resulting image data. The stability and sensitivity of this transformation to noise are critical concerns.\n\nAn engineer analyzes a new sharpening filter represented by a matrix $A$. The properties of this transformation are intimately linked to the matrix's singular values, which are obtained from its Singular Value Decomposition (SVD). The singular values quantify the degree to which the filter stretches or compresses data along specific directions. For the engineer's filter matrix $A$, the complete set of non-zero singular values is found to be $\\{500, 5, 0.1\\}$.\n\nA key metric for numerical stability is the condition number of the matrix. A large condition number indicates that the matrix is \"ill-conditioned,\" meaning that small errors or noise in the input image $x$ can be dramatically amplified in the output image $y$. This can also make reversing the filter an unstable process. To evaluate this risk, calculate the 2-norm condition number, denoted $\\kappa_2(A)$, for the given filter matrix. Provide the exact numerical value.",
            "solution": "We model the filter by a matrix $A$ with singular value decomposition $A = U \\Sigma V^{\\mathsf{T}}$, where the diagonal entries of $\\Sigma$ are the singular values $\\sigma_{i}(A)$. The spectral norm is given by $\\|A\\|_{2} = \\sigma_{\\max}(A)$. For a matrix with strictly positive smallest singular value, the $2$-norm condition number is\n$$\n\\kappa_{2}(A) = \\|A\\|_{2}\\,\\|A^{-1}\\|_{2} = \\frac{\\sigma_{\\max}(A)}{\\sigma_{\\min}(A)}.\n$$\nThe complete set of non-zero singular values of $A$ is $\\{500, 5, 0.1\\}$, so\n$$\n\\sigma_{\\max}(A) = 500, \\qquad \\sigma_{\\min}(A) = 0.1.\n$$\nTherefore,\n$$\n\\kappa_{2}(A) = \\frac{500}{0.1} = 5000.\n$$",
            "answer": "$$\\boxed{5000}$$"
        },
        {
            "introduction": "Beyond mere calculation, the true value of the condition number lies in its interpretation. What does a \"good\" or \"bad\" condition number tell us about a system? This exercise explores the ideal case by analyzing a 2D rotation matrix, a cornerstone of computer graphics and robotics. Calculating the condition number for this transformation will reveal what it means for an operation to be \"perfectly conditioned\" and why rotations are considered exceptionally stable from a numerical standpoint .",
            "id": "2210793",
            "problem": "A robotics engineer is simulating the motion of a 2D robotic arm. The simulation involves applying a sequence of rotations to position vectors. The engineer is concerned about the propagation of small numerical errors in the vector's components during these rotational transformations. To analyze this, they decide to compute the condition number of the rotation operation.\n\nA standard 2D rotation by an angle $\\theta$ is represented by the matrix:\n$$\nR(\\theta) = \\begin{pmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix}\n$$\nThe sensitivity of the linear system $Ax=b$ to perturbations in $b$ is quantified by the condition number of the matrix $A$, defined with respect to a given norm. For the vector 2-norm (Euclidean norm), the condition number is given by $\\kappa_2(A) = \\|A\\|_2 \\|A^{-1}\\|_2$, where $\\|A\\|_2$ is the matrix 2-norm induced by the vector 2-norm. The matrix 2-norm, also known as the spectral norm, is equal to the largest singular value of the matrix, $\\sigma_{\\max}(A)$.\n\nCalculate the 2-norm condition number, $\\kappa_2(R(\\theta))$, for any non-trivial rotation matrix $R(\\theta)$ (i.e., for $\\theta$ not an integer multiple of $2\\pi$). Based on your result, select the option below that correctly states the value of the condition number and its primary implication for the numerical stability of applying rotations.\n\nA. The condition number is 0. This implies that rotations can collapse vectors to the origin, causing a complete loss of information.\n\nB. The condition number is 1. This implies that applying a rotation does not amplify relative errors in the input vector, making the operation numerically ideal or \"perfectly conditioned\".\n\nC. The condition number is $\\sqrt{2}$. This indicates that relative errors can be magnified by approximately 41% during a rotation.\n\nD. The condition number is dependent on the angle $\\theta$, specifically $|\\sec(\\theta)| + |\\csc(\\theta)|$. This means that rotations by angles close to $\\pi/2$ or $3\\pi/2$ are highly unstable.\n\nE. The condition number is undefined because the matrix is singular for some angles. This means rotations are not always invertible, leading to catastrophic error propagation.",
            "solution": "Let $A=R(\\theta)=\\begin{pmatrix}\\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta\\end{pmatrix}$. Compute its transpose:\n$$\nA^{\\mathsf{T}}=\\begin{pmatrix}\\cos\\theta & \\sin\\theta \\\\ -\\sin\\theta & \\cos\\theta\\end{pmatrix}.\n$$\nThen\n$$\nA^{\\mathsf{T}}A=\\begin{pmatrix}\\cos\\theta & \\sin\\theta \\\\ -\\sin\\theta & \\cos\\theta\\end{pmatrix}\\begin{pmatrix}\\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta\\end{pmatrix}=\\begin{pmatrix}\\cos^{2}\\theta+\\sin^{2}\\theta & 0 \\\\ 0 & \\cos^{2}\\theta+\\sin^{2}\\theta\\end{pmatrix}=I,\n$$\nusing $\\cos^{2}\\theta+\\sin^{2}\\theta=1$ and cancellation of cross terms. Hence $A$ is orthogonal, so its singular values are the square roots of the eigenvalues of $A^{\\mathsf{T}}A=I$, all equal to $1$. Therefore,\n$$\n\\|A\\|_{2}=\\sigma_{\\max}(A)=1.\n$$\nSince $A^{-1}=A^{\\mathsf{T}}$ for orthogonal $A$, it follows that $\\|A^{-1}\\|_{2}=\\|A^{\\mathsf{T}}\\|_{2}=1$. The 2-norm condition number is\n$$\n\\kappa_{2}(A)=\\|A\\|_{2}\\,\\|A^{-1}\\|_{2}=1\\cdot 1=1.\n$$\nBecause an orthogonal matrix preserves the Euclidean norm, $ \\|Ax\\|_{2}=\\|x\\|_{2}$ for all $x$, applying a rotation does not amplify relative errors; the operation is perfectly conditioned. This holds for any $\\theta$, including non-trivial rotations (and even $\\theta$ equal to integer multiples of $2\\pi$).\nThe correct option is B.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "It's easy to fall into the trap of thinking that a matrix is well-behaved as long as its determinant isn't close to zero. This final practice is designed to dismantle that misconception by examining a simple shear matrix whose determinant is always $1$. You will see how such a matrix can become arbitrarily ill-conditioned, demonstrating that the condition number reveals a more nuanced aspect of numerical instability related to geometric distortion, which is not captured by the determinant alone .",
            "id": "1393610",
            "problem": "In numerical linear algebra, the condition number of a matrix provides a measure of how sensitive the solution of a system of linear equations is to small changes in the input data. A matrix with a high condition number is considered 'ill-conditioned'.\n\nConsider the following family of $2 \\times 2$ matrices, parameterized by a real number $k$:\n$$\nM(k) = \\begin{pmatrix} 1 & k \\\\ 0 & 1 \\end{pmatrix}\n$$\nThese matrices represent a horizontal shear transformation. For any value of $k$, the determinant of $M(k)$ is exactly 1. This might naively suggest that the matrix is always well-behaved. However, its condition number can become very large.\n\nThe condition number of an invertible matrix $A$ with respect to the matrix 2-norm (also known as the spectral norm) is defined as $\\kappa_2(A) = \\frac{\\sigma_{\\max}}{\\sigma_{\\min}}$, where $\\sigma_{\\max}$ and $\\sigma_{\\min}$ are the largest and smallest singular values of $A$, respectively. The singular values of $A$ are the square roots of the eigenvalues of the matrix $A^T A$.\n\nDetermine the exact positive value of $k$ for which the condition number $\\kappa_2(M(k))$ is equal to 50. Provide your answer as a single closed-form analytic expression.",
            "solution": "We are given $M(k)=\\begin{pmatrix}1 & k \\\\ 0 & 1\\end{pmatrix}$ and want the condition number in the $2$-norm $\\kappa_{2}(M(k))=\\sigma_{\\max}/\\sigma_{\\min}$ to equal $50$, where the singular values are the square roots of the eigenvalues of $M(k)^{\\mathsf{T}}M(k)$.\n\nFirst compute\n$$\nM(k)^{\\mathsf{T}}M(k)=\\begin{pmatrix}1 & 0 \\\\ k & 1\\end{pmatrix}\\begin{pmatrix}1 & k \\\\ 0 & 1\\end{pmatrix}\n=\\begin{pmatrix}1 & k \\\\ k & k^{2}+1\\end{pmatrix}.\n$$\nFor a symmetric $2\\times 2$ matrix $\\begin{pmatrix}a & b \\\\ b & d\\end{pmatrix}$, the eigenvalues are\n$$\n\\lambda_{\\pm}=\\frac{a+d\\pm\\sqrt{(a-d)^{2}+4b^{2}}}{2}.\n$$\nHere $a=1$, $b=k$, $d=k^{2}+1$, so\n$$\n\\lambda_{\\pm}=\\frac{k^{2}+2\\pm\\sqrt{k^{4}+4k^{2}}}{2}\n=\\frac{k^{2}+2\\pm |k|\\sqrt{k^{2}+4}}{2}.\n$$\nFor $k>0$, this is\n$$\n\\lambda_{\\max}=\\frac{k^{2}+2+k\\sqrt{k^{2}+4}}{2},\\quad\n\\lambda_{\\min}=\\frac{k^{2}+2-k\\sqrt{k^{2}+4}}{2}.\n$$\nThus the condition number is\n$$\n\\kappa_{2}(M(k))=\\sqrt{\\frac{\\lambda_{\\max}}{\\lambda_{\\min}}}\n=\\sqrt{\\frac{k^{2}+2+k\\sqrt{k^{2}+4}}{k^{2}+2-k\\sqrt{k^{2}+4}}}.\n$$\nSet this equal to $50$ and square both sides:\n$$\n2500=\\frac{k^{2}+2+k\\sqrt{k^{2}+4}}{k^{2}+2-k\\sqrt{k^{2}+4}}.\n$$\nIntroduce $X=k^{2}+2$ and $Y=k\\sqrt{k^{2}+4}$ (with $k>0$ so $Y>0$). Then\n$$\n2500=\\frac{X+Y}{X-Y}\\quad\\Longrightarrow\\quad X+Y=2500(X-Y).\n$$\nSolving for the ratio $r=\\frac{Y}{X}$ gives\n$$\n\\frac{Y}{X}=\\frac{2500-1}{2500+1}=\\frac{2499}{2501}.\n$$\nHence\n$$\nk\\sqrt{k^{2}+4}=\\frac{2499}{2501}\\,(k^{2}+2).\n$$\nLet $t=k^{2}\\ge 0$. Squaring both sides yields\n$$\nt(t+4)=\\left(\\frac{2499}{2501}\\right)^{2}(t+2)^{2}.\n$$\nWrite $c=\\left(\\frac{2499}{2501}\\right)^{2}$. Expanding and collecting terms,\n$$\nt^{2}+4t=c(t^{2}+4t+4)\n\\;\\Longrightarrow\\;\n(1-c)t^{2}+4(1-c)t-4c=0.\n$$\nSince $c<1$, divide by $(1-c)$:\n$$\nt^{2}+4t-\\frac{4c}{1-c}=0.\n$$\nCompute $\\frac{4c}{1-c}$ using $1-c=\\frac{2501^{2}-2499^{2}}{2501^{2}}=\\frac{10000}{2501^{2}}$, so\n$$\n\\frac{4c}{1-c}=\\frac{4\\cdot \\frac{2499^{2}}{2501^{2}}}{\\frac{10000}{2501^{2}}}=\\frac{2499^{2}}{2500}.\n$$\nThus\n$$\nt^{2}+4t-\\frac{2499^{2}}{2500}=0.\n$$\nThe discriminant is\n$$\n\\Delta=16+4\\cdot\\frac{2499^{2}}{2500}=16+\\frac{2499^{2}}{625}\n=\\frac{10000+2499^{2}}{625}=\\frac{2501^{2}}{625},\n$$\nso $\\sqrt{\\Delta}=\\frac{2501}{25}$. Therefore\n$$\nt=\\frac{-4+\\frac{2501}{25}}{2}=\\frac{\\frac{-100+2501}{25}}{2}=\\frac{2401}{50}.\n$$\nSince $t=k^{2}$ and $k>0$, we obtain\n$$\nk=\\sqrt{\\frac{2401}{50}}=\\frac{49}{\\sqrt{50}}=\\frac{49\\sqrt{2}}{10}.\n$$\nThis value of $k$ yields $\\kappa_{2}(M(k))=50$ by construction.",
            "answer": "$$\\boxed{\\frac{49\\sqrt{2}}{10}}$$"
        }
    ]
}