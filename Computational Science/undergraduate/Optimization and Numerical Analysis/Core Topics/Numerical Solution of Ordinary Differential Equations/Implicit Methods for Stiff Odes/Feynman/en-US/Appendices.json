{
    "hands_on_practices": [
        {
            "introduction": "The core feature of an implicit method is that calculating the next state, $y_{n+1}$, requires solving an equation where $y_{n+1}$ itself appears on both sides. This first exercise demystifies this process by applying the implicit midpoint rule to a simple linear Ordinary Differential Equation (ODE). By working through this foundational example , you will see how to rearrange the update formula and algebraically solve for $y_{n+1}$, turning the implicit relation into an explicit computational step.",
            "id": "2178584",
            "problem": "In computational physics, many problems require the numerical solution of Ordinary Differential Equations (ODEs). Consider a simplified model for the temperature, $y(t)$, of an electronic component over time. The rate of change of its temperature is described by the linear first-order ODE:\n$$ \\frac{dy}{dt} = ay + b $$\nwhere $y_n$ represents the known temperature at time $t_n$, and $a$ and $b$ are real constants determined by the component's physical properties and its environment.\n\nTo approximate the solution numerically, we can use an implicit method. One such method is the implicit midpoint rule, which calculates the state at the next time step, $y_{n+1} = y(t_n + h)$, using the formula:\n$$ y_{n+1} = y_n + h f\\left(t_n + \\frac{h}{2}, \\frac{y_n + y_{n+1}}{2}\\right) $$\nHere, $h$ is the constant time step size, and $f(t,y)$ is the function defining the ODE, i.e., $f(t,y) = \\frac{dy}{dt}$.\n\nBy applying a single step of the implicit midpoint rule to the given ODE, derive an explicit analytical expression for $y_{n+1}$ in terms of $y_n$, $h$, $a$, and $b$.",
            "solution": "We start with the ODE $ \\frac{dy}{dt} = a y + b $ and apply the implicit midpoint rule\n$$\ny_{n+1} = y_n + h f\\left(t_n + \\frac{h}{2}, \\frac{y_n + y_{n+1}}{2}\\right).\n$$\nHere $f(t,y) = a y + b$ is autonomous (independent of $t$), so\n$$\nf\\left(t_n + \\frac{h}{2}, \\frac{y_n + y_{n+1}}{2}\\right) = a \\left(\\frac{y_n + y_{n+1}}{2}\\right) + b.\n$$\nSubstituting into the update formula gives\n$$\ny_{n+1} = y_n + h \\left[ a \\left(\\frac{y_n + y_{n+1}}{2}\\right) + b \\right].\n$$\nExpanding and collecting terms in $y_{n+1}$,\n$$\ny_{n+1} = y_n + \\frac{a h}{2} y_n + \\frac{a h}{2} y_{n+1} + h b,\n$$\nwhich implies\n$$\n\\left(1 - \\frac{a h}{2}\\right) y_{n+1} = \\left(1 + \\frac{a h}{2}\\right) y_n + h b.\n$$\nSolving for $y_{n+1}$ yields the explicit analytical expression\n$$\ny_{n+1} = \\frac{\\left(1 + \\frac{a h}{2}\\right) y_n + h b}{1 - \\frac{a h}{2}}.\n$$",
            "answer": "$$\\boxed{\\frac{\\left(1 + \\frac{a h}{2}\\right) y_n + h b}{1 - \\frac{a h}{2}}}$$"
        },
        {
            "introduction": "Having seen how to formulate an implicit step, we now explore the primary reason for their use: superior stability, especially for stiff or oscillatory systems. Many physical systems, from planetary orbits to molecular vibrations, conserve quantities like energy. This exercise  examines a test problem for pure oscillations, revealing how a method like the Trapezoidal Rule can perfectly preserve the solution's magnitude, mirroring a conserved quantity, while another common implicit method introduces artificial numerical damping.",
            "id": "2178599",
            "problem": "In the stability analysis of numerical methods for Ordinary Differential Equations (ODEs), a key test problem for oscillatory systems is the equation $y'(t) = i\\omega y(t)$, with an initial condition $y(0) = y_0$. Here, $y(t)$ is a complex-valued function, $i = \\sqrt{-1}$, and $\\omega$ is a real, positive constant representing the angular frequency. The exact solution to this equation is $y(t) = y_0 \\exp(i\\omega t)$, and its magnitude $|y(t)|$ remains constant for all time $t$.\n\nAn ideal numerical method for such a problem would preserve this constant-magnitude property. Consider two implicit numerical methods for solving this ODE with a constant time step $h > 0$.\n\nMethod A (Backward Euler): The scheme is defined by the relation\n$$y_{n+1} = y_n + h (i\\omega y_{n+1})$$\n\nMethod B (Trapezoidal Rule): The scheme is defined by the relation\n$$y_{n+1} = y_n + \\frac{h}{2} (i\\omega y_n + i\\omega y_{n+1})$$\n\nLet $|y_n^{(A)}|$ and $|y_n^{(B)}|$ denote the magnitudes of the numerical solutions generated by Method A and Method B, respectively, at the time $t_n = n h$. For any choice of step size $h > 0$ and frequency $\\omega > 0$, which of the following statements correctly describes the evolution of these magnitudes?\n\nA. $|y_{n+1}^{(A)}| > |y_n^{(A)}|$ and $|y_{n+1}^{(B)}| > |y_n^{(B)}|$\n\nB. $|y_{n+1}^{(A)}| < |y_n^{(A)}|$ and $|y_{n+1}^{(B)}| = |y_n^{(B)}|$\n\nC. $|y_{n+1}^{(A)}| = |y_n^{(A)}|$ and $|y_{n+1}^{(B)}| < |y_n^{(B)}|$\n\nD. $|y_{n+1}^{(A)}| > |y_n^{(A)}|$ and $|y_{n+1}^{(B)}| = |y_n^{(B)}|$\n\nE. $|y_{n+1}^{(A)}| < |y_n^{(A)}|$ and $|y_{n+1}^{(B)}| < |y_n^{(B)}|$\n\nF. $|y_{n+1}^{(A)}| = |y_n^{(A)}|$ and $|y_{n+1}^{(B)}| > |y_n^{(B)}|$",
            "solution": "We analyze the linear test ODE $y'(t)=i\\omega y(t)$ under the two one-step implicit methods, each yielding a linear recurrence of the form $y_{n+1}=G y_n$ with a complex amplification factor $G$. The magnitude behavior is determined by $|G|$.\n\nFor Method A (Backward Euler), the update relation is\n$$\ny_{n+1}=y_n+h(i\\omega y_{n+1}).\n$$\nRearranging gives\n$$\n(1-i\\omega h)\\,y_{n+1}=y_n \\quad\\Rightarrow\\quad y_{n+1}=\\frac{1}{1-i\\omega h}\\,y_n.\n$$\nThus the amplification factor is\n$$\nG_{A}=\\frac{1}{1-i\\omega h}.\n$$\nIts magnitude is\n$$\n|G_{A}|^{2}=G_{A}\\overline{G_{A}}=\\frac{1}{(1-i\\omega h)(1+i\\omega h)}=\\frac{1}{1+(\\omega h)^{2}},\n$$\nso\n$$\n|G_{A}|=\\frac{1}{\\sqrt{1+(\\omega h)^{2}}}<1 \\quad\\text{for}\\quad h>0,\\ \\omega>0.\n$$\nTherefore,\n$$\n|y_{n+1}^{(A)}|=|G_{A}|\\,|y_{n}^{(A)}|<|y_{n}^{(A)}|.\n$$\n\nFor Method B (Trapezoidal Rule), the update relation is\n$$\ny_{n+1}=y_n+\\frac{h}{2}\\big(i\\omega y_n+i\\omega y_{n+1}\\big).\n$$\nRearranging gives\n$$\n\\big(1-\\tfrac{i\\omega h}{2}\\big)y_{n+1}=\\big(1+\\tfrac{i\\omega h}{2}\\big)y_n \\quad\\Rightarrow\\quad y_{n+1}=\\frac{1+\\tfrac{i\\omega h}{2}}{1-\\tfrac{i\\omega h}{2}}\\,y_n.\n$$\nThus the amplification factor is\n$$\nG_{B}=\\frac{1+\\tfrac{i\\omega h}{2}}{1-\\tfrac{i\\omega h}{2}}.\n$$\nThe numerator and denominator have equal magnitudes:\n$$\n\\left|1+\\tfrac{i\\omega h}{2}\\right|=\\sqrt{1+\\left(\\tfrac{\\omega h}{2}\\right)^{2}}=\\left|1-\\tfrac{i\\omega h}{2}\\right|,\n$$\nhence\n$$\n|G_{B}|=1,\n$$\nand therefore\n$$\n|y_{n+1}^{(B)}|=|y_{n}^{(B)}|.\n$$\n\nCombining these results, for any $h>0$ and $\\omega>0$, the Backward Euler method strictly decreases the magnitude while the Trapezoidal Rule preserves it exactly. This corresponds to option B.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "The stability of implicit methods is not a free lunch; it comes at the price of solving an algebraic equation at every time step. How we solve this equation is crucial. This practice  investigates a seemingly straightforward approach—a simple fixed-point iteration—to solve the Backward Euler equation for a stiff problem. You will discover that this iterative solver's convergence imposes a constraint on the step size that is just as strict as that of an explicit method, defeating the purpose of going implicit and motivating the need for more powerful solvers like Newton's method.",
            "id": "2178627",
            "problem": "Consider the numerical solution of a first-order Ordinary Differential Equation (ODE) that models a system's state, $y(t)$, which rapidly adjusts to a time-varying external signal, $g(t)$. The dynamics are described by the equation:\n$$ y'(t) = \\alpha (g(t) - y(t)) $$\nHere, $\\alpha$ is a large, positive constant, which makes the equation \"stiff\".\n\nTo solve this ODE numerically, we apply the Backward Euler method, which is an implicit scheme defined by:\n$$ y_{n+1} = y_n + h f(t_{n+1}, y_{n+1}) $$\nwhere $y_n \\approx y(t_n)$, $h$ is the time step, and $f(t,y) = \\alpha (g(t) - y)$.\n\nTo solve the implicit equation for $y_{n+1}$ at each time step, a simple fixed-point iteration is used. Starting from an initial guess $y_{n+1}^{(0)}$, the iteration proceeds as:\n$$ y_{n+1}^{(k+1)} = y_n + h \\alpha (g(t_{n+1}) - y_{n+1}^{(k)}) $$\nwhere $k=0, 1, 2, \\dots$ is the iteration index.\n\nFor this fixed-point iteration to be guaranteed to converge to the correct value of $y_{n+1}$ regardless of the initial guess, the step size $h$ must be strictly less than a certain critical value, which we will call $h_{crit}$. This critical value depends on the system's parameters.\n\nDetermine the expression for this critical step size $h_{crit}$ in terms of the parameter $\\alpha$.",
            "solution": "We begin from the Backward Euler step for the ODE $y'(t)=\\alpha\\left(g(t)-y(t)\\right)$:\n$$\ny_{n+1}=y_{n}+h\\,\\alpha\\left(g(t_{n+1})-y_{n+1}\\right).\n$$\nDefine the fixed-point mapping used in the iteration as\n$$\nF(y):=y_{n}+h\\,\\alpha\\left(g(t_{n+1})-y\\right)=y_{n}+h\\,\\alpha\\,g(t_{n+1})-h\\,\\alpha\\,y.\n$$\nThe fixed-point iteration is $y_{n+1}^{(k+1)}=F\\!\\left(y_{n+1}^{(k)}\\right)$, and the fixed point $y_{n+1}^{\\ast}$ satisfies\n$$\ny_{n+1}^{\\ast}=F\\!\\left(y_{n+1}^{\\ast}\\right).\n$$\nTo ensure convergence for any initial guess, $F$ must be a contraction on $\\mathbb{R}$. By the Banach fixed-point theorem, a sufficient (and in this linear case, necessary) condition is that the Lipschitz constant $L$ of $F$ satisfies $L<1$. Since $F$ is differentiable and linear in $y$, we compute\n$$\nF'(y)=-h\\,\\alpha,\n$$\nso the Lipschitz constant is\n$$\nL=\\sup_{y\\in\\mathbb{R}}|F'(y)|=|{-h\\,\\alpha}|=h\\,\\alpha.\n$$\nTherefore, the iteration converges for any initial guess if and only if\n$$\nh\\,\\alpha<1.\n$$\nEquivalently, the critical step size is\n$$\nh_{\\text{crit}}=\\frac{1}{\\alpha},\n$$\nand the requirement is $h<h_{\\text{crit}}$.\n\nAn equivalent error analysis yields the same condition: letting $e^{(k)}=y_{n+1}^{(k)}-y_{n+1}^{\\ast}$, one has\n$$\ne^{(k+1)}=F\\!\\left(y_{n+1}^{(k)}\\right)-F\\!\\left(y_{n+1}^{\\ast}\\right)=-h\\,\\alpha\\,e^{(k)},\n$$\nso $|e^{(k+1)}|=h\\,\\alpha\\,|e^{(k)}|$ tends to zero if and only if $h\\,\\alpha<1$, giving the same $h_{\\text{crit}}=\\frac{1}{\\alpha}$.",
            "answer": "$$\\boxed{\\frac{1}{\\alpha}}$$"
        }
    ]
}