## 引言
在[线性规划](@entry_id:138188)的广阔领域中，单纯形法是求解[优化问题](@entry_id:266749)的基石算法。然而，随着问题规模的急剧增长，尤其是在变量数量远超约束数量的场景下，标准单纯形法因其需要维护和更新庞大的单纯形表而变得计算成本高昂。为了克服这一瓶颈，**修正单纯形法**应运而生，它通过一种更为精巧和高效的方式，彻底改变了大规模[线性规划](@entry_id:138188)问题的求解[范式](@entry_id:161181)。本文旨在系统性地剖析这一强大的算法，揭示其计算效率背后的深刻原理及其在现代优化中的广泛应用。

本文将引导读者分三步深入探索修正单纯形法的世界。首先，在“**原理与机制**”一章中，我们将详细拆解算法的核心思想，阐明它如何仅依赖基[逆矩阵](@entry_id:140380)完成迭代，并探讨如逆矩阵乘积形式(PFI)和基再求逆等关键实现技术。接着，在“**应用与跨学科联系**”一章，我们将展示该方法如何自然地延伸至灵敏度分析，成为评估“影子价格”和进行后优化分析的利器，并揭示其作为列生成、丹齐-伍尔夫分解等高级分解算法核心引擎的角色。最后，通过“**动手实践**”部分，读者将有机会通过具体问题，加深对算法关键步骤的理解，例如如何定价、如何判断多重最优解等。通过这一结构化的学习路径，读者将不仅掌握修正单纯形法的操作方法，更能领会其作为连接理论与实践桥梁的深刻价值。

## 原理与机制

继前一章对线性规划和标准单纯形法的介绍之后，本章将深入探讨一种在计算上更为高效的算法——**修正单纯形法**（Revised Simplex Method）。与在每次迭代中更新整个单纯形表的标准方法不同，修正单纯形法通过仅维护和更新求解所需的核心信息，显著减少了计算开销，特别是在处理变量数量远大于约束数量的大规模问题时。本章将系统地阐述修正单纯形法的基本原理、核心机制及其在实践中的高效实现方式。

### 核心思想：[计算效率](@entry_id:270255)

标准单纯形法的主要计算负担在于每次迭[代时](@entry_id:173412)需要更新整个单纯形表。对于一个包含 $m$ 个约束和 $n$ 个决策变量的线性规划问题，在引入 $m$ 个[松弛变量](@entry_id:268374)后，总变量数达到 $N = n+m$。此时，单纯形表的维度约为 $m \times N$。每一次主元变换（pivot operation）都需要对这个表中的几乎所有元素进行更新，其计算复杂度大致为 $O(mN)$。当变量总数 $N$ 远大于约束数 $m$ 时，这种操作变得非常低效。

修正单纯形法的根本出发点是认识到，为了执行一次单纯形法的迭代，我们并不需要整个单纯形表中的所有信息。一次迭代的关键步骤仅包括：
1.  **检验最优性并选择入基变量**：这需要计算所有非基变量的[检验数](@entry_id:173345)（或称判别数、reduced cost）。
2.  **确定出基变量**：这需要计算入基变量在当前基下的表示，并执行[最小比率检验](@entry_id:634935)。
3.  **更新解**：完成基交换。

修正单纯形法发现，完成这些步骤所需的所有信息都可以从**基[矩阵的逆](@entry_id:140380)**（inverse of the basis matrix），即 $B^{-1}$，以及原始问题数据（$A, b, c$）中推导出来。它避免了对整个大规模单纯形表的存储和更新，转而只维护和更新一个尺寸为 $m \times m$ 的基逆矩阵 $B^{-1}$。

我们可以通过一个简化的[计算成本模型](@entry_id:747607)来量化这种效率优势 。假设标准单纯形法的迭代成本为 $C_S = mN$。对于修正单纯形法，其成本主要来自两个部分：(a) 涉及 $m \times m$ 基逆矩阵的运算（如计算单纯形乘子），成本约为 $O(m^2)$；(b) 对 $N-m$ 个非基变量进行“定价”（pricing），即计算它们的[检验数](@entry_id:173345)，成本约为 $O(m(N-m))$。因此，修正单纯形法的总迭代成本可以建模为 $C_R = k_1 m^2 + k_2 m(N-m)$，其中 $k_1$ 和 $k_2$ 是与具体实现相关的常数。

当 $N \gg m$ 时，我们有 $N-m \approx N$。此时 $C_S \approx mN$，而 $C_R$ 中的第二项占主导，也近似为 $k_2 mN$。然而，通过巧妙的实现，修正单纯形法在定价等步骤中的效率因子可以远小于 1，从而使其总成本显著低于标准方法。更重要的是，它避免了对 $m \times N$ 庞大矩阵的直接操作，这在内存使用和计算速度上都构成了决定性优势。

### 修正单纯形法迭代的力学过程

现在，我们将详细分解一次典型的修正单纯形法迭代过程。假设我们正在求解一个最大化问题，其[标准形式](@entry_id:153058)为：
最大化 $z = c^T x$
服从于 $Ax = b, x \ge 0$

我们从一个已知的基可行解开始，该解对应一个基矩阵 $B$（由 $A$ 中与基变量对应的列构成）及其逆矩阵 $B^{-1}$。

#### 步骤 1：定价——寻找入基变量

此步骤的目标是确定哪个非基变量进入基后能够最大程度地改进[目标函数](@entry_id:267263)值。

首先，我们计算**单纯形乘子**（simplex multipliers），也称为对偶变量向量，通常记作 $\pi^T$ 或 $y^T$。其计算公式为：
$$ \pi^T = c_B^T B^{-1} $$
其中，$c_B^T$ 是一个行向量，包含了当前基变量在[目标函数](@entry_id:267263)中的系数。单纯形乘子在经济学上可以解释为资源的“影子价格”，它衡量了每单位约束（资源）对目标函数的边际贡献。

例如，在一个生产[优化问题](@entry_id:266749)中，若基变量为 $\{x_1, x_2\}$，[目标函数](@entry_id:267263)为 $P = 5x_1 + 8x_2 + 6x_3$，则 $c_B^T = \begin{pmatrix} 5  8 \end{pmatrix}$。给定当前的基[逆矩阵](@entry_id:140380) $B^{-1}$，我们可以直接计算出 $\pi^T$ 。

得到单纯形乘子后，我们便可以计算每个**非基变量** $x_j$ 的**[检验数](@entry_id:173345)** $\bar{c}_j$：
$$ \bar{c}_j = c_j - \pi^T A_j = c_j - c_B^T B^{-1} A_j $$
其中，$c_j$ 是变量 $x_j$ 的原始目标函数系数，$A_j$ 是其在约束矩阵 $A$ 中的列向量。[检验数](@entry_id:173345) $\bar{c}_j$ 的含义是，当非基变量 $x_j$ 的值从 0 增加一个单位时，[目标函数](@entry_id:267263)值的净变化量。

对于最大化问题，如果所有的[检验数](@entry_id:173345) $\bar{c}_j$都小于或等于零，说明任何非基变量的增加都不能使目标函数值变得更大，因此当前解已达到最优。否则，我们选择具有最大正[检验数](@entry_id:173345)的非基变量作为**入基变量**（entering variable），记为 $x_k$。这个选择标准被称为“Dantzig's rule”。

例如，在一个最大化问题中，当前基为 $\{x_1, x_4, x_5\}$，[目标系数](@entry_id:637435)向量 $c_B^T = \begin{pmatrix} 5  0  0 \end{pmatrix}$。要计算非基变量 $x_2$ 的[检验数](@entry_id:173345)，我们需要其原始系数 $c_2 = 8$ 和列向量 $A_2$。通过计算 $c_B^T B^{-1} A_2$ 并从 $c_2$ 中减去，我们得到 $\bar{c}_2$ 的值。如果此值为正，则 $x_2$ 是一个潜在的入基候选者 。

#### 步骤 2：[最小比率检验](@entry_id:634935)——寻找出基变量

确定入基变量 $x_k$ 后，我们需要确定它可以在多大程度上增加，直到某个当前的基变量减少到零为止。这个即将变为零的基变量就是**出基变量**（leaving variable）。

为此，我们首先需要计算入基列向量 $A_k$ 在当前基下的表示，记为向量 $d$（或 $y_k$）：
$$ d = B^{-1} A_k $$
向量 $d$ 的第 $i$ 个分量 $d_i$ 表示当 $x_k$ 增加一个单位时，第 $i$ 个基变量 $x_{B_i}$ 将会减少的数量。值得注意的是，如果 $A_k$ 本身就是一个基列（例如，基矩阵 $B$ 的第 $i$ 列），那么它的表示 $d$ 就是一个单位向量 $e_i$ 。

同时，我们需要当前基变量的值，即**基解**（basic solution） $x_B$：
$$ x_B = B^{-1} b $$
其中 $b$ 是约束条件的右端向量。

接下来，我们执行**[最小比率检验](@entry_id:634935)**（minimum ratio test）。对于 $d$ 中所有大于零的分量 $d_i > 0$，我们计算比率 $\frac{x_{B_i}}{d_i}$。这个比率表示，为了使第 $i$ 个基变量 $x_{B_i}$ 降至零，入基变量 $x_k$ 所能增加的最大值。我们取所有这些比率中的最小值：
$$ \theta^* = \min_{i | d_i > 0} \left\{ \frac{x_{B_i}}{d_i} \right\} $$
如果所有 $d_i \le 0$，则问题是无界的，[算法终止](@entry_id:143996)。否则，$\theta^*$ 就是入基变量 $x_k$ 在本次迭代中能增加的最大值。使得比率达到最小值的那个基变量 $x_{B_r}$ 就是出基变量。

#### 步骤 3：主元变换——更新基

最后一步是执行主元变换（pivot），即用 $x_k$ 替换 $x_{B_r}$，形成新的基。在修正单纯形法中，这意味着我们需要得到新的基[逆矩阵](@entry_id:140380) $B_{\text{new}}^{-1}$。更新基解的值也很直接：新的入基变量值为 $x_k = \theta^*$，而新的基变量值为 $x_{B}^{\text{new}} = x_B - \theta^* d$。

至此，一次完整的迭代结束 。算法将带着新的基逆矩阵 $B_{\text{new}}^{-1}$ 返回步骤 1，开始下一次迭代，直到满足[最优性条件](@entry_id:634091)为止。

### 基逆矩阵的更新实现

如何高效地从旧的 $B^{-1}$ 计算出新的 $B_{\text{new}}^{-1}$ 是修正单纯形法实现的核心。新基矩阵 $B_{\text{new}}$ 是通过将旧基矩阵 $B$ 的第 $r$ 列（对应出基变量）替换为入基列 $A_k$ 得到的。这可以被视为对矩阵 $B$ 的一次**[秩一更新](@entry_id:137543)**（rank-one update）。

#### 理论基础：Sherman-Morrison-Woodbury 公式

从理论上讲，基[逆矩阵](@entry_id:140380)的更新可以通过 **Sherman-Morrison-Woodbury 公式**来精确描述。如果 $B_{\text{new}} = B + (A_k - b_r)e_r^T$，其中 $b_r$ 是 $B$ 的第 $r$ 列，$e_r$ 是第 $r$ 个标准单位向量，那么 $(B_{\text{new}})^{-1}$ 可以通过以下公式计算：
$$ (B + uv^T)^{-1} = B^{-1} - \frac{B^{-1}uv^T B^{-1}}{1 + v^T B^{-1}u} $$
其中 $u = A_k - b_r$，$v = e_r$。通过这种方式，我们可以直接从 $B^{-1}$ 和入基列 $A_k$ 计算出 $(B_{\text{new}})^{-1}$ 。虽然这个公式在理论上非常优雅，但直接计算它涉及多次矩阵-向量和向量-向量乘法，对于大规模问题可能不是最高效的方式。

#### 实践方法：[逆矩阵](@entry_id:140380)的乘积形式 (PFI)

在现代优化求解器中，一种更流行、更高效的方法是**[逆矩阵](@entry_id:140380)的乘积形式**（Product Form of the Inverse, PFI）。这种方法并不直接存储和更新 $B^{-1}$，而是将其表示为一系列**初等[变换矩阵](@entry_id:151616)**（elementary transformation matrices）的乘积，这些矩阵通常被称为**eta 矩阵**（eta matrices）。

一个 eta 矩阵 $E_t$ 代表第 $t$ 次迭代的基变换。它是一个单位矩阵，但其中一列（[主元列](@entry_id:148772)，即出基变量所在的列，设为第 $r$ 列）被所谓的 **eta 向量** $\eta$所替换。这个 $\eta$ 向量由前面计算出的更新后列向量 $d=B^{-1}A_k$ 派生而来：
$$ \eta_i = \begin{cases} -d_i / d_r  \text{if } i \neq r \\ 1 / d_r  \text{if } i = r \end{cases} $$
在第 $t$ 次迭代后，新的基逆矩阵可以表示为：
$$ B_t^{-1} = E_t B_{t-1}^{-1} $$
从初始基（通常是[单位矩阵](@entry_id:156724) $B_0=I$）开始，经过 $k$ 次迭代后，基[逆矩阵](@entry_id:140380)就表示为一串 eta 矩阵的乘积：
$$ B_k^{-1} = E_k E_{k-1} \cdots E_1 $$
PFI 方法的优势在于 eta 矩阵的稀疏性。由于每个 $E_t$ 仅有一列不同于[单位矩阵](@entry_id:156724)，存储它仅需存储非单位列（eta 向量）及其位置即可。在求解稀疏线性规划问题时，eta 向量本身也常常是稀疏的。

当需要计算 $v = B_k^{-1} u$ 这样的乘积时（例如，计算 $d=B^{-1}A_k$ 或 $x_B=B^{-1}b$），我们并不显式计算 $B_k^{-1}$，而是进行一系列的矩阵-向量乘法：
$$ v = E_k (E_{k-1} (\cdots (E_1 u)\cdots)) $$
这被称为一次 **FTRAN** (Forward Transformation)。类似地，计算 $\pi^T = c_B^T B_k^{-1}$ 则通过一次 **BTRAN** (Backward Transformation) 完成：
$$ \pi^T = (((c_B^T E_k) E_{k-1}) \cdots) E_1 $$
这种方法在计算上非常高效，因为它将一次大的[矩阵乘法](@entry_id:156035)分解为一系列与稀疏矩阵的乘法 。

#### PFI 与显式[逆矩阵](@entry_id:140380)的权衡

PFI 方法在内存使用上通常也优于显式存储 $B^{-1}$。显式存储一个 $m \times m$ 的稠密矩阵需要 $m^2$ 个单位的内存。而使用 PFI，在 $k$ 次迭代后，如果每个 eta 向量平均有 $p$ 个非单位元素，总存储量大约为 $k(2p+1)$（每个元素的值和索引，加上列索引）。只要 $k(2p+1)  m^2$，PFI 就更节省内存 。对于大规模问题，在迭代初期，$k$ 远小于 $m$，PFI 的优势非常明显。

#### 基 reinversion

PFI 方法的一个缺点是，随着迭代次数 $k$ 的增加，eta 矩阵链会越来越长，导致 FTRAN 和 BTRAN 操作的计算成本增加。更严重的是，由于[浮点运算](@entry_id:749454)的累积，[数值误差](@entry_id:635587)也可能在 eta 矩阵链中不断放大，影响解的精度。

为了解决这个问题，求解器会周期性地执行**基 reinversion**（或称基再求逆）。这是一个“清理”过程，具体操作如下：
1.  从原始矩阵 $A$ 中提取出当前基变量对应的列，显式地构成当前的基矩阵 $B$。
2.  使用数值稳定的方法（如 LU 分解）直接计算出 $B$ 的逆（或其[因子分解](@entry_id:150389)形式），得到一个全新的、精确的 $B^{-1}$。
3.  丢弃旧的、冗长的 eta 矩阵链，用这个新计算出的 $B^{-1}$ 作为下一次迭代的起点。

Reinversion 操作本身有一定计算成本，但它通过重置 eta 矩阵链，有效地控制了后续迭代的计算时间和数值误差，是维持修正单纯形法长期高效稳定运行的关键步骤。

### 对偶性与修正单纯形法

修正单纯形法的步骤与[线性规划](@entry_id:138188)的[对偶理论](@entry_id:143133)有着深刻而优美的联系。实际上，每一次 primal (原始) 单纯形法的迭代都可以被看作是在 dual (对偶) 问题解空间中的一次移动。

回忆一下， primal 问题的基可行解对应着 dual 问题的一个基解。修正单纯形法计算的**单纯形乘子 $\pi^T = c_B^T B^{-1}$ 正是这个 dual 基解的值**。

而 primal [检验数](@entry_id:173345) $\bar{c}_j = c_j - \pi^T A_j$ (对于最大化问题) 或 $\bar{c}_j = \pi^T A_j - c_j$ (对于最小化问题) 正是 dual 问题的**[松弛变量](@entry_id:268374)**的值。primal 问题的[最优性条件](@entry_id:634091)（所有 $\bar{c}_j \le 0$）等价于 dual 问题的可行性条件（所有 dual 约束都得到满足）。

当 primal 算法选择一个 $\bar{c}_k  0$ 的变量 $x_k$ 入基时，这对应于在 dual 问题中发现了一个被违反的约束。primal 算法的[最小比率检验](@entry_id:634935)确定了出基变量，这个过程在 dual 空间中表现为沿着一条边从一个 dual 基解（顶点）移动到另一个相邻的 dual 基解，目的是为了最终满足那个被违反的约束。

因此，执行一次完整的修正单纯形法迭代，从一个 primal 基 $\{x_{B_1}, \dots, x_{B_m}\}$ 移动到一个新的 primal 基 $\{x_{B'_1}, \dots, x_{B'_m}\}$，其内在含义是从一个 dual 解 $\pi$ 移动到了一个新的 dual 解 $\pi_{\text{new}}$ 。这种对偶视角不仅加深了我们对算法工作原理的理解，也为更高级的算法（如[对偶单纯形法](@entry_id:164344)）奠定了基础。

总之，修正单纯形法通过聚焦于核心信息——基[逆矩阵](@entry_id:140380)，并采用如 PFI 和 reinversion 等先进的计算策略，将单纯形理论转化为一个极其强大和高效的实用算法，构成了现代大规模线性规划求解器的基石。