{
    "hands_on_practices": [
        {
            "introduction": "这个练习解决了一个数值分析中的基本问题：要达到预期的精度需要多少计算量？通过应用梯形法则的误差界公式，我们可以计算出保证近似值在指定公差范围内所需的最小子区间数。这是规划高效可靠数值计算的一项关键技能。",
            "id": "2170455",
            "problem": "一位数值分析师的任务是使用复合梯形法则来近似计算定积分 $I = \\int_{0}^{\\pi/2} \\exp(x) \\cos(x) \\, dx$。对于一个定义在区间 $[a, b]$ 上、使用 $n$ 个子区间的函数 $f(x)$，该方法产生的误差 $E_T$ 受以下不等式约束：\n$$|E_T| \\le \\frac{K(b-a)^3}{12n^2}$$\n其中 $K$ 是满足对所有 $x \\in [a, b]$ 都有 $|f''(x)| \\le K$ 的任意数。\n\n为保证近似的绝对误差最多为 $10^{-4}$，所需的最小整数子区间数 $n$ 是多少？",
            "solution": "我们应用复合梯形法则的误差界\n$$|E_{T}| \\le \\frac{K(b-a)^{3}}{12 n^{2}},$$\n其中 $K$ 在 $[a,b]$ 上满足 $|f''(x)| \\le K$。对于在 $[0,\\frac{\\pi}{2}]$ 上的函数 $f(x)=\\exp(x)\\cos(x)$，计算其导数：\n$$f'(x)=\\exp(x)(\\cos x-\\sin x),$$\n$$f''(x)=\\exp(x)(\\cos x-\\sin x) + \\exp(x)(-\\sin x-\\cos x) = -2\\,\\exp(x)\\sin x.$$\n因此，\n$$|f''(x)|=2\\,\\exp(x)|\\sin x|=2\\,\\exp(x)\\sin x \\quad \\text{for } x \\in \\left[0,\\frac{\\pi}{2}\\right].$$\n令 $g(x)=\\exp(x)\\sin x$。那么在 $\\left(0,\\frac{\\pi}{2}\\right)$ 上，$g'(x)=\\exp(x)(\\sin x+\\cos x)0$，所以 $g$ 是递增的，并在 $x=\\frac{\\pi}{2}$ 处达到其最大值。因此，\n$$K=\\max_{x \\in [0,\\frac{\\pi}{2}]} |f''(x)| = 2\\,\\exp\\!\\left(\\frac{\\pi}{2}\\right).$$\n当 $a=0$，$b=\\frac{\\pi}{2}$ 时，误差界变为\n$$|E_{T}| \\le \\frac{2\\,\\exp\\!\\left(\\frac{\\pi}{2}\\right)\\left(\\frac{\\pi}{2}\\right)^{3}}{12 n^{2}} = \\frac{\\exp\\!\\left(\\frac{\\pi}{2}\\right)\\pi^{3}}{48\\,n^{2}}.$$\n为保证 $|E_{T}| \\le 10^{-4}$，我们需要\n$$\\frac{\\exp\\!\\left(\\frac{\\pi}{2}\\right)\\pi^{3}}{48\\,n^{2}} \\le 10^{-4} \\quad \\Longrightarrow \\quad n \\ge \\sqrt{\\frac{\\exp\\!\\left(\\frac{\\pi}{2}\\right)\\pi^{3}\\times 10^{4}}{48}}.$$\n现在进行数值计算以确定最小整数 $n$：\n$$\\exp\\!\\left(\\frac{\\pi}{2}\\right) \\approx 4.810477380965351, \\quad \\pi^{3} \\approx 31.0062766802998,$$\n$$\\exp\\!\\left(\\frac{\\pi}{2}\\right)\\pi^{3} \\approx 149.154992638,$$\n$$\\frac{\\exp\\!\\left(\\frac{\\pi}{2}\\right)\\pi^{3}\\times 10^{4}}{48} \\approx 3.10739568038 \\times 10^{4},$$\n$$\\sqrt{3.10739568038 \\times 10^{4}} \\approx 176.28.$$\n因此，满足该界的最小整数 $n$ 是 $n=177$。",
            "answer": "$$\\boxed{177}$$"
        },
        {
            "introduction": "理论误差界给出了一个最坏情况的保证，但实际误差是多少呢？这个练习探讨了一个有趣的情况：即使标准误差界不为零，梯形法则也能得出精确结果。通过分析奇函数在对称区间上的积分，我们可以揭示误差抵消的原理，从而更深入地理解求积法则的行为。",
            "id": "2170446",
            "problem": "考虑定积分 $I = \\int_{-a}^{a} x^3 \\, dx$，其中 $a$ 是一个正实数常量。我们希望分析复合梯形法则对于该积分的性能。\n\n首先，通过直接计算证明，两区间复合梯形法则（$n=2$）能得到 $I$ 的精确值。\n\n其次，使用复合梯形法则的标准公式计算该近似的理论误差界：\n$$|E_T| \\leq \\frac{(b-a)^3}{12n^2} \\max_{x \\in [a,b]} |f''(x)|$$\n其中 $[a,b]$ 是积分区间，$n$ 是子区间的数量，$f(x)$ 是被积函数。\n\n你会发现实际误差为零，但理论误差界是一个关于 $a$ 的非零函数。下列哪个陈述提供了正确且最具体的数学推理来解释这个明显的悖论？\n\nA. 梯形法则在对一个关于原点对称的区间上的任何奇函数进行积分时是精确的，而 $f(x)=x^3$ 是一个奇函数。\n\nB. 在更基本的误差公式 $E_T = -\\frac{(b-a)h^2}{12}f''(\\xi)$ 中，对于此特定的函数和区间配置，$\\xi$ 的值恰好为 $\\xi=0$。由于 $f''(0)=0$，误差为零。\n\nC. 标准误差界公式总是一个最坏情况下的上界。实际误差可以在零和这个界限之间的任何地方，而对于这个问题，它恰好偶然为零。\n\nD. 复合误差是每个子区间误差的总和。简化的全局误差界公式的推导隐含地假设二阶导数不会以允许系统性抵消的方式改变符号。对于对称子区间 $[-a, 0]$ 和 $[0, a]$，由于二阶导数 $f''(x)=6x$ 的奇对称性，第一个区间的误差贡献恰好被第二个区间的误差抵消。\n\nE. 所提供的误差界公式仅对在积分区间上二阶导数非负的函数有效，而 $f(x)=x^3$ 在 $[-a, a]$ 上违反了此条件。",
            "solution": "计算积分的精确值。$f(x)=x^{3}$ 的一个原函数是 $\\frac{x^{4}}{4}$，所以\n$$\nI=\\int_{-a}^{a} x^{3}\\,dx=\\left.\\frac{x^{4}}{4}\\right|_{-a}^{a}=\\frac{a^{4}}{4}-\\frac{(-a)^{4}}{4}=0.\n$$\n\n在 $[-a,a]$ 上应用两区间复合梯形法则。步长为\n$$\nh=\\frac{a-(-a)}{2}=a,\n$$\n节点为 $x_{0}=-a$，$x_{1}=0$，$x_{2}=a$。复合梯形近似值为\n$$\nT_{2}=\\frac{h}{2}\\big(f(x_{0})+2f(x_{1})+f(x_{2})\\big)=\\frac{a}{2}\\big(f(-a)+2f(0)+f(a)\\big).\n$$\n当 $f(x)=x^{3}$ 时，这给出\n$$\nT_{2}=\\frac{a}{2}\\big((-a)^{3}+2\\cdot 0^{3}+a^{3}\\big)=\\frac{a}{2}\\big(-a^{3}+a^{3}\\big)=0,\n$$\n这等于精确积分 $I=0$。因此，两区间复合梯形法则得到了精确值。\n\n现在计算理论误差界。标准界限是\n$$\n|E_{T}|\\leq \\frac{(b-a)^{3}}{12 n^{2}}\\max_{x\\in[a,b]}|f''(x)|.\n$$\n这里 $[a,b]=[-a,a]$（端点为 $-a$ 和 $a$），所以 $b-a=2a$，$n=2$，并且 $f''(x)=6x$。因此，\n$$\n\\max_{x\\in[-a,a]}|f''(x)|=\\max_{x\\in[-a,a]}|6x|=6a,\n$$\n并且\n$$\n|E_{T}|\\leq \\frac{(2a)^{3}}{12\\cdot 2^{2}}\\cdot 6a=\\frac{8a^{3}}{48}\\cdot 6a=\\frac{a^{3}}{6}\\cdot 6a=a^{4}.\n$$\n因此，误差界是 $a^{4}$，而实际误差为零。\n\n为了解释这一点，我们来观察两个对称子区间之间的精确抵消机制。对于 $f(x)=x^{3}$，在任何单个子区间 $[p,q]$ 上的精确局部梯形误差（其中 $E=I-T$）可以直接计算：\n$$\nE(p,q)=\\int_{p}^{q}x^{3}\\,dx-\\frac{q-p}{2}\\big(f(p)+f(q)\\big)\n=\\frac{q^{4}-p^{4}}{4}-\\frac{q-p}{2}\\big(p^{3}+q^{3}\\big).\n$$\n因式分解并化简：\n$$\n\\frac{q^{4}-p^{4}}{4}=\\frac{(q-p)(q+p)(q^{2}+p^{2})}{4},\\quad\n\\frac{q-p}{2}\\big(p^{3}+q^{3}\\big)=\\frac{(q-p)(p+q)(p^{2}-pq+q^{2})}{2},\n$$\n所以\n$$\nE(p,q)=(q-p)(p+q)\\left[\\frac{q^{2}+p^{2}}{4}-\\frac{p^{2}-pq+q^{2}}{2}\\right]\n=-(q-p)(p+q)\\frac{(p-q)^{2}}{4}.\n$$\n由于 $(p-q)^{2}=(q-p)^{2}$，这变为\n$$\nE(p,q)=-\\frac{(q-p)^{3}}{4}(p+q).\n$$\n将此公式应用于两个长度均为 $a$ 的子区间 $[-a,0]$ 和 $[0,a]$：\n$$\nE([-a,0])=-\\frac{a^{3}}{4}(-a+0)=\\frac{a^{4}}{4},\\qquad\nE([0,a])=-\\frac{a^{3}}{4}(0+a)=-\\frac{a^{4}}{4},\n$$\n它们精确抵消，得出总误差 $E=0$。\n\n因此，尽管误差界 $|E_{T}|\\leq a^{4}$ 是一个基于 $\\max|f''|$ 的有效最坏情况上界，但由于两个对称子区间误差的精确抵消（这是二阶导数 $f''(x)=6x$ 奇对称性的结果），实际的复合误差为零。在给出的选项中，D 选项最具体地描述了这一点。",
            "answer": "$$\\boxed{D}$$"
        },
        {
            "introduction": "我们如何确定理论误差公式 $E(h) \\sim K h^p$ 在实践中是成立的呢？这个高级练习将指导你完成一个计算实验，用数值方法验证收敛阶和误差常数。通过将数值模拟中观察到的误差与理论模型进行拟合，你将获得分析和验证数值算法的实践经验，这是计算科学中一种强大的技术。",
            "id": "2417998",
            "problem": "编写一个完整的、可运行的程序，该程序针对一组给定的光滑函数和区间，估算复合梯形法则的先行阶渐近误差律中的指数和带符号系数。对于区间 $[a,b]$ 上的函数 $f$，将具有 $n$ 个子区间和步长 $h=(b-a)/n$ 的复合梯形近似定义为\n$$\nT_n(f;[a,b]) \\equiv h\\left(\\tfrac{1}{2}f(a) + \\sum_{k=1}^{n-1} f(a+k h) + \\tfrac{1}{2}f(b)\\right),\n$$\n并将带符号的积分误差定义为\n$$\nE(h) \\equiv \\int_a^b f(x)\\,dx - T_n(f;[a,b]).\n$$\n假设对于足够小的 $h$，存在一个形式如下的渐近误差模型\n$$\nE(h) \\sim K\\, h^{p},\n$$\n其中 $p$ 是（正）阶数，$K$ 是带符号的误差项常数。对于一个固定的有限步长集合 $\\{h_i\\}$，按如下方式确定实数 $\\widehat{p}$ 和 $\\widehat{K}$：令 $y_i \\equiv \\ln|E(h_i)|$ 和 $x_i \\equiv \\ln h_i$，并选择 $(\\widehat{p},\\widehat{C})$ 以在 $\\widehat{p}\\in\\mathbb{R}$ 和 $\\widehat{C}0$ 的范围内最小化 $\\sum_i \\bigl(y_i - (\\ln \\widehat{C} + \\widehat{p}\\,x_i)\\bigr)^2$。定义符号 $s$ 为集合中最小步长 $h_\\star$ 处误差 $E(h_\\star)$ 的符号，并设置 $\\widehat{K} \\equiv s\\,\\widehat{C}$。所有三角函数的求值必须使用弧度制角。\n\n测试套件。使用以下四个测试用例，每个用例都有自己的区间 $[a,b]$ 和函数 $f$，步长集由子区间数 $n \\in \\{\\,8,16,32,64,128,256\\,\\}$ 生成，因此 $h=(b-a)/n$：\n- 用例 1：$f(x)=x^2$ 于 $[0,1]$。\n- 用例 2：$f(x)=\\sin(x)$ 于 $[0,\\pi]$。\n- 用例 3：$f(x)=e^{x}$ 于 $[0,1]$。\n- 用例 4：$f(x)=x^4-2x^2$ 于 $[0,1]$。\n\n对于每个用例，计算 $E(h)$ 所需的精确积分 $\\int_a^b f(x)\\,dx$ 值为：\n- 用例 1：$\\int_0^1 x^2\\,dx = \\tfrac{1}{3}$。\n- 用例 2：$\\int_0^\\pi \\sin(x)\\,dx = 2$。\n- 用例 3：$\\int_0^1 e^{x}\\,dx = e-1$。\n- 用例 4：$\\int_0^1 (x^4-2x^2)\\,dx = \\tfrac{1}{5}-\\tfrac{2}{3} = -\\tfrac{7}{15}$。\n\n作为参考，这些用例对应的理论带符号误差项常数 $K_{\\text{theory}}$ 为：\n- 用例 1：$K_{\\text{theory}} = -\\tfrac{1}{6}$。\n- 用例 2：$K_{\\text{theory}} = \\tfrac{1}{6}$。\n- 用例 3：$K_{\\text{theory}} = -\\tfrac{e-1}{12}$。\n- 用例 4：$K_{\\text{theory}} = \\tfrac{1}{30}$。\n\n你的程序必须对每个用例，根据应用于由 $n\\in\\{\\,8,16,32,64,128,256\\,\\}$ 确定的六个 $h$ 值的指定最小二乘准则，计算出 $(\\widehat{p},\\widehat{K})$ 对，并同时报告上面列出的 $K_{\\text{theory}}$。\n\n最终输出格式。你的程序应生成单行输出，其中包含一个含 4 个内部列表的列表，每个测试用例对应一个内部列表，每个内部列表按 $[\\widehat{p},\\widehat{K},K_{\\text{theory}}]$ 的顺序包含 3 个实数。每个实数必须四舍五入到 6 位小数。不应打印任何其他文本。例如，整体结构必须是单行，看起来像一个 JSON 风格的列表之列表，其中恰好有 4 个内部列表，每个内部列表恰好包含指定的 3 个数字，用逗号分隔，并用方括号括起来。",
            "solution": "该问题要求对一系列测试用例，数值估算复合梯形求积法则的收敛性质。严谨的方法始于对问题陈述的验证，我们发现该陈述在科学上是合理的、适定的且完整的。因此，我们可以着手求解。\n\n基本原理是使用复合梯形法则来近似定积分 $\\int_a^b f(x)\\,dx$。该法则将区间 $[a,b]$ 分割成 $n$ 个等宽 $h=(b-a)/n$ 的子区间。该近似值，记为 $T_n(f;[a,b])$，是这些子区间上梯形面积的总和：\n$$ T_n(f;[a,b]) \\equiv h\\left(\\frac{1}{2}f(a) + \\sum_{k=1}^{n-1} f(a+kh) + \\frac{1}{2}f(b)\\right). $$\n带符号的积分误差 $E(h)$ 定义为积分的精确解析值与此数值近似值之间的差：\n$$ E(h) \\equiv \\int_a^b f(x)\\,dx - T_n(f;[a,b]). $$\n对于任何足够光滑的函数 $f(x)$，Euler-Maclaurin 公式为此误差提供了一个关于步长 $h$ 幂次的渐近展开式。该展开式的先行项决定了当 $h \\to 0$ 时的收敛速度：\n$$ E(h) \\sim K h^p, $$\n其中 $p$ 是收敛阶数，$K$ 是带符号的主误差系数。对于复合梯形法则，如果函数的一阶导数 $f'(x)$ 连续且 $f'(a) \\neq f'(b)$，则收敛阶数为 $p=2$，误差系数由下式给出：\n$$ K = -\\frac{1}{12} [f'(b) - f'(a)]. $$\n这一理论结果适用于测试用例 1、2 和 3，其函数分别为 $f(x)=x^2$、$f(x)=\\sin(x)$ 和 $f(x)=e^x$。\n\n当 $f'(a) = f'(b)$ 时，会出现一种特殊情况。在这种情况下，Euler-Maclaurin 展开式中的 $h^2$ 项会消失。如果函数足够光滑且边界处的三阶导数不相等，即 $f'''(a) \\neq f'''(b)$，则展开式中下一个非零项（即 $h^4$ 阶项）将成为主导项。收敛阶数变为 $p=4$，系数 $K$ 由下式给出：\n$$ K = \\frac{1}{720} [f'''(b) - f'''(a)]. $$\n这正是测试用例 4 的情况，其函数为 $f(x) = x^4 - 2x^2$，区间为 $[0,1]$。对于此函数，$f'(x) = 4x^3 - 4x$，从而得出 $f'(1) = 0$ 和 $f'(0) = 0$。问题陈述中提供的理论误差常数 $K_{\\text{theory}} = \\frac{1}{30}$ 与此高阶分析一致，因为 $f'''(x) = 24x$，导致 $K = \\frac{1}{720}[24 - 0] = \\frac{24}{720} = \\frac{1}{30}$。\n\n问题的核心是从一组计算出的误差 $\\{E(h_i)\\}$ 中数值估算 $p$ 和 $K$。渐近关系 $|E(h)| \\approx C h^p$（其中 $C = |K|$）可通过取自然对数进行变换：\n$$ \\ln |E(h)| \\approx \\ln(C) + p \\ln(h). $$\n这个方程在 $\\ln(h)$ 和 $\\ln|E(h)|$ 上是线性的。它对应于线性模型 $y = c + mx$，其中标识为 $y_i = \\ln|E(h_i)|$，$x_i = \\ln(h_i)$，斜率 $m = p$，$y$ 轴截距 $c = \\ln(C)$。\n\n问题指定了使用最小二乘准则来确定估计值 $\\widehat{p}$ 和 $\\widehat{C}$。我们必须找到使残差平方和最小化的参数：\n$$ \\sum_{i} \\left(y_i - (\\ln \\widehat{C} + \\widehat{p} x_i)\\right)^2. $$\n这是一个标准的线性回归问题。斜率 $\\widehat{p}$ 和截距 $\\ln\\widehat{C}$ 的最优值可以使用从正规方程导出的闭式表达式计算，或者更简单地，使用像 `numpy.polyfit` 这样的数值库函数来计算。\n\n从回归中，我们得到估计的斜率 $\\widehat{p}$ 和截距 $\\ln\\widehat{C}$。然后误差系数的大小为 $\\widehat{C} = \\exp(\\ln\\widehat{C})$。为了恢复符号，我们遵循给定的步骤：符号 $s$ 取自用最小步长 $h_\\star$（对应于最大子区间数 $n=256$）计算出的误差 $E(h_\\star)$。带符号系数的最终估计值为 $\\widehat{K} = s \\cdot \\widehat{C}$。\n\n每个测试用例要实现的算法如下：\n1. 定义函数 $f(x)$、区间 $[a,b]$、精确积分值 $I_{\\text{exact}}$ 以及理论常数 $K_{\\text{theory}}$。\n2. 根据给定的子区间数 $n \\in \\{\\,8, 16, 32, 64, 128, 256\\,\\}$ 生成步长集合 $\\{h_i\\}$。\n3. 对每个 $h_i$，计算梯形近似值 $T_{n_i}$ 和相应的误差 $E(h_i) = I_{\\text{exact}} - T_{n_i}$。\n4. 构建用于回归的数据向量：$x_i = \\ln(h_i)$ 和 $y_i = \\ln(|E(h_i)|)$。\n5. 对数据点 $(x_i, y_i)$ 进行线性回归，以获得估计的斜率 $\\widehat{p}$ 和截距 $\\ln\\widehat{C}$。\n6. 计算估计的大小 $\\widehat{C} = \\exp(\\ln\\widehat{C})$。\n7. 确定符号 $s = \\text{sign}(E(h_\\star))$，其中 $h_\\star$ 是最小步长。\n8. 计算最终的带符号系数估计值 $\\widehat{K} = s \\cdot \\widehat{C}$。\n9. 收集所得的三元组 $(\\widehat{p}, \\widehat{K}, K_{\\text{theory}})$，并按照指定格式化以用于最终输出。\n该过程将系统地应用于所有四个测试用例。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Estimates the exponent and signed coefficient in the leading-order\n    asymptotic error law of the composite trapezoidal rule for a set of\n    test cases.\n    \"\"\"\n\n    def trapezoidal_rule(f, a, b, n):\n        \"\"\"\n        Computes the composite trapezoidal approximation of an integral.\n        \"\"\"\n        h = (b - a) / n\n        x = np.linspace(a, b, n + 1)\n        y = f(x)\n        return h * (np.sum(y) - 0.5 * (y[0] + y[-1]))\n\n    all_results = []\n\n    # Define the test cases\n    test_cases = [\n        {\n            \"f\": lambda x: x**2,\n            \"a\": 0.0,\n            \"b\": 1.0,\n            \"integral\": 1.0/3.0,\n            \"k_theory\": -1.0/6.0,\n        },\n        {\n            \"f\": lambda x: np.sin(x),\n            \"a\": 0.0,\n            \"b\": np.pi,\n            \"integral\": 2.0,\n            \"k_theory\": 1.0/6.0,\n        },\n        {\n            \"f\": lambda x: np.exp(x),\n            \"a\": 0.0,\n            \"b\": 1.0,\n            \"integral\": np.e - 1.0,\n            \"k_theory\": -(np.e - 1.0)/12.0,\n        },\n        {\n            \"f\": lambda x: x**4 - 2*x**2,\n            \"a\": 0.0,\n            \"b\": 1.0,\n            \"integral\": 1.0/5.0 - 2.0/3.0,\n            \"k_theory\": 1.0/30.0,\n        }\n    ]\n\n    n_values = [8, 16, 32, 64, 128, 256]\n\n    for case in test_cases:\n        f = case[\"f\"]\n        a = case[\"a\"]\n        b = case[\"b\"]\n        exact_integral = case[\"integral\"]\n        k_theory = case[\"k_theory\"]\n\n        h_vals = []\n        error_vals = []\n\n        for n in n_values:\n            h = (b - a) / n\n            approx_integral = trapezoidal_rule(f, a, b, n)\n            error = exact_integral - approx_integral\n            \n            h_vals.append(h)\n            error_vals.append(error)\n\n        h_vals = np.array(h_vals)\n        error_vals = np.array(error_vals)\n        \n        # Prepare data for linear regression: y = p*x + log(C)\n        # x = log(h), y = log(|E(h)|)\n        log_h = np.log(h_vals)\n        log_abs_error = np.log(np.abs(error_vals))\n\n        # Perform linear regression to find p (slope) and log(C) (intercept)\n        # np.polyfit returns coefficients in descending power order, so [slope, intercept] for degree 1\n        p_hat, log_C_hat = np.polyfit(log_h, log_abs_error, 1)\n\n        C_hat = np.exp(log_C_hat)\n\n        # Determine the sign from the error at the smallest h (largest n)\n        # The lists are ordered by increasing n, so the last element is what we need.\n        sign = np.sign(error_vals[-1])\n\n        K_hat = sign * C_hat\n\n        all_results.append((p_hat, K_hat, k_theory))\n\n    # Format the output as specified\n    formatted_results = []\n    for p_hat, k_hat, k_th in all_results:\n        formatted_results.append(f\"[{p_hat:.6f},{k_hat:.6f},{k_th:.6f}]\")\n    \n    # Print the single line of output\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}