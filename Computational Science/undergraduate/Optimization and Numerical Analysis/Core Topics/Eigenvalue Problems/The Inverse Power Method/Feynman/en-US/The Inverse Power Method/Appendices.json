{
    "hands_on_practices": [
        {
            "introduction": "To master any iterative algorithm, you must first understand a single step. This exercise isolates the foundational calculation of the inverse power method â€” solving the linear system $(A - \\sigma I)y_1 = x_0$. This gives you direct, hands-on practice with the core mechanic of the algorithm before you piece it together into a full iterative process .",
            "id": "1395843",
            "problem": "In a numerical algorithm, a sequence of vectors is generated starting from an initial vector $x_0$. The first unnormalized vector in this sequence, denoted as $y_1$, is found by solving the linear system $(A-\\sigma I)y_1 = x_0$, where $A$ is a square matrix, $\\sigma$ is a scalar shift, and $I$ is the identity matrix of the same dimension as $A$.\n\nGiven the matrix $$A = \\begin{pmatrix} 3 & -1 \\\\ -1 & 3 \\end{pmatrix},$$ the shift $\\sigma = 1.5$, and the initial vector $$x_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix},$$ determine the components of the vector $y_1$. Present your answer as a row matrix where each component is an exact fraction or decimal.",
            "solution": "We are asked to solve the linear system $(A-\\sigma I) y_{1} = x_{0}$ for $y_{1}$, where $A = \\begin{pmatrix} 3 & -1 \\\\ -1 & 3 \\end{pmatrix}$, $\\sigma = \\frac{3}{2}$, and $x_{0} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$.\n\nFirst compute the shifted matrix:\n$$\nA - \\sigma I = \\begin{pmatrix} 3 & -1 \\\\ -1 & 3 \\end{pmatrix} - \\frac{3}{2} \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{2} & -1 \\\\ -1 & \\frac{3}{2} \\end{pmatrix}.\n$$\nDenote $M = A - \\sigma I$. Then $y_{1} = M^{-1} x_{0}$. For a $2 \\times 2$ matrix $M = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$, we use $M^{-1} = \\frac{1}{\\det(M)} \\begin{pmatrix} d & -b \\\\ -c & a \\end{pmatrix}$. Here $a = d = \\frac{3}{2}$ and $b = c = -1$, so\n$$\n\\det(M) = \\left(\\frac{3}{2}\\right)\\left(\\frac{3}{2}\\right) - (-1)(-1) = \\frac{9}{4} - 1 = \\frac{5}{4},\n$$\nand\n$$\n\\operatorname{adj}(M) = \\begin{pmatrix} \\frac{3}{2} & 1 \\\\ 1 & \\frac{3}{2} \\end{pmatrix}.\n$$\nTherefore,\n$$\nM^{-1} = \\frac{1}{\\frac{5}{4}} \\begin{pmatrix} \\frac{3}{2} & 1 \\\\ 1 & \\frac{3}{2} \\end{pmatrix} = \\frac{4}{5} \\begin{pmatrix} \\frac{3}{2} & 1 \\\\ 1 & \\frac{3}{2} \\end{pmatrix}.\n$$\nMultiplying by $x_{0}$,\n$$\ny_{1} = M^{-1} x_{0} = \\frac{4}{5} \\begin{pmatrix} \\frac{3}{2} & 1 \\\\ 1 & \\frac{3}{2} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\frac{4}{5} \\begin{pmatrix} \\frac{3}{2} \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{6}{5} \\\\ \\frac{4}{5} \\end{pmatrix}.\n$$\nThus the components of $y_{1}$ are $\\frac{6}{5}$ and $\\frac{4}{5}$, which we present as a row matrix.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{6}{5} & \\frac{4}{5} \\end{pmatrix}}$$"
        },
        {
            "introduction": "After an iteration produces a new approximate eigenvector, how do we get the corresponding eigenvalue estimate? The Rayleigh quotient provides an elegant and accurate answer. This practice connects the iterative vector sequence to the eigenvalue we seek by demonstrating how to use the output of an inverse iteration to calculate this quotient .",
            "id": "1395847",
            "problem": "Consider the real symmetric matrix $A$ and the initial vector $x_0$ given by:\n$$A = \\begin{pmatrix} 2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 2 \\end{pmatrix}, \\quad x_0 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$$\nThe inverse power method is used to find an eigenvector of $A$. A single iteration of the unshifted inverse power method, starting from $x_0$, produces the vector $x_1$ according to the relation $x_1 = A^{-1} x_0$.\n\nUsing this new vector $x_1$, calculate the Rayleigh quotient, $R(x_1) = \\frac{x_1^T A x_1}{x_1^T x_1}$. This quotient provides an estimate for the eigenvalue of $A$ associated with the eigenvector that the inverse power method converges to (i.e., the eigenvalue with the smallest magnitude).\n\nExpress your answer as an exact fraction in simplest form.",
            "solution": "The problem asks for the Rayleigh quotient $R(x_1)$ for the matrix $A$, where the vector $x_1$ is obtained from one iteration of the inverse power method starting with $x_0$. The formula for the iteration is given as $x_1 = A^{-1} x_0$. The Rayleigh quotient is defined as $R(x_1) = \\frac{x_1^T A x_1}{x_1^T x_1}$.\n\nFirst, we need to compute the inverse of matrix $A$. The inverse is given by $A^{-1} = \\frac{1}{\\det(A)} \\text{adj}(A)$, where $\\text{adj}(A)$ is the adjugate matrix of $A$.\n\nLet's calculate the determinant of $A$:\n$$ \\det(A) = 2 \\begin{vmatrix} 2 & -1 \\\\ -1 & 2 \\end{vmatrix} - (-1) \\begin{vmatrix} -1 & -1 \\\\ 0 & 2 \\end{vmatrix} + 0 \\begin{vmatrix} -1 & 2 \\\\ 0 & -1 \\end{vmatrix} $$\n$$ \\det(A) = 2((2)(2) - (-1)(-1)) + 1((-1)(2) - (-1)(0)) + 0 $$\n$$ \\det(A) = 2(4 - 1) + 1(-2) = 2(3) - 2 = 6 - 2 = 4 $$\n\nNext, we find the matrix of cofactors.\n$$ C_{11} = +\\begin{vmatrix} 2 & -1 \\\\ -1 & 2 \\end{vmatrix} = 3 $$\n$$ C_{12} = -\\begin{vmatrix} -1 & -1 \\\\ 0 & 2 \\end{vmatrix} = 2 $$\n$$ C_{13} = +\\begin{vmatrix} -1 & 2 \\\\ 0 & -1 \\end{vmatrix} = 1 $$\n$$ C_{21} = -\\begin{vmatrix} -1 & 0 \\\\ -1 & 2 \\end{vmatrix} = 2 $$\n$$ C_{22} = +\\begin{vmatrix} 2 & 0 \\\\ 0 & 2 \\end{vmatrix} = 4 $$\n$$ C_{23} = -\\begin{vmatrix} 2 & -1 \\\\ 0 & -1 \\end{vmatrix} = 2 $$\n$$ C_{31} = +\\begin{vmatrix} -1 & 0 \\\\ 2 & -1 \\end{vmatrix} = 1 $$\n$$ C_{32} = -\\begin{vmatrix} 2 & 0 \\\\ -1 & -1 \\end{vmatrix} = 2 $$\n$$ C_{33} = +\\begin{vmatrix} 2 & -1 \\\\ -1 & 2 \\end{vmatrix} = 3 $$\n\nThe matrix of cofactors is $\\begin{pmatrix} 3 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix}$. The adjugate matrix is the transpose of the cofactor matrix, which is the same in this case because the cofactor matrix is symmetric.\n$$ \\text{adj}(A) = \\begin{pmatrix} 3 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix} $$\nTherefore, the inverse of $A$ is:\n$$ A^{-1} = \\frac{1}{4} \\begin{pmatrix} 3 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix} $$\n\nNow, we compute $x_1 = A^{-1} x_0$:\n$$ x_1 = \\frac{1}{4} \\begin{pmatrix} 3 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\frac{1}{4} \\begin{pmatrix} 3 \\\\ 2 \\\\ 1 \\end{pmatrix} $$\n\nThe Rayleigh quotient is scale-invariant. That is, for any non-zero scalar $c$, $R(cx) = R(x)$. Let $v = \\begin{pmatrix} 3 \\\\ 2 \\\\ 1 \\end{pmatrix}$. Then $x_1 = \\frac{1}{4}v$, and $R(x_1) = R(v) = \\frac{v^T A v}{v^T v}$. This simplifies the calculation by avoiding fractions.\n\nFirst, let's calculate the numerator, $v^T A v$. We start by computing $Av$:\n$$ Av = \\begin{pmatrix} 2 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 2 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2(3) + (-1)(2) + 0(1) \\\\ -1(3) + 2(2) + (-1)(1) \\\\ 0(3) + (-1)(2) + 2(1) \\end{pmatrix} = \\begin{pmatrix} 6 - 2 \\\\ -3 + 4 - 1 \\\\ -2 + 2 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nNow we compute $v^T(Av)$:\n$$ v^T(Av) = \\begin{pmatrix} 3 & 2 & 1 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ 0 \\\\ 0 \\end{pmatrix} = 3(4) + 2(0) + 1(0) = 12 $$\n\nNext, we calculate the denominator, $v^T v$:\n$$ v^T v = \\begin{pmatrix} 3 & 2 & 1 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 2 \\\\ 1 \\end{pmatrix} = 3^2 + 2^2 + 1^2 = 9 + 4 + 1 = 14 $$\n\nFinally, we compute the Rayleigh quotient:\n$$ R(x_1) = \\frac{v^T A v}{v^T v} = \\frac{12}{14} = \\frac{6}{7} $$",
            "answer": "$$\\boxed{\\frac{6}{7}}$$"
        },
        {
            "introduction": "In real-world scientific computing, especially with large matrices, efficiency is paramount. This problem moves beyond the theoretical mechanics to the practicalities of implementation, asking you to analyze the computational trade-offs between different strategies for solving the linear system at each step. Thinking about these costs is essential for choosing the right tool for the job and designing scalable numerical methods .",
            "id": "1395838",
            "problem": "In numerical linear algebra, the shifted inverse power method is used to find the eigenvalue of a matrix $A$ closest to a given shift $\\sigma$. A critical step in this algorithm involves repeatedly solving a linear system of the form $(A - \\sigma I)\\boldsymbol{z}_{k+1} = \\boldsymbol{y}_k$. Consider a very large, sparse, real, symmetric matrix $A$ of size $N \\times N$. The matrix is banded, with $m$ non-zero diagonals above the main diagonal and $m$ non-zero diagonals below it (for a total of $2m+1$ non-zero diagonals). We wish to perform $K$ iterations of the shifted inverse power method.\n\nTo solve the linear system in each iteration, two strategies are proposed:\n\n**Strategy 1 (Direct Method):** First, compute the Lower-Upper (LU) factorization of the matrix $M = A - \\sigma I$. This is a one-time cost. Then, for each of the $K$ iterations, solve the system using forward and backward substitution. The dominant computational costs (in floating-point operations, or flops) for a large $N$ are:\n- LU factorization for this banded matrix: $2Nm^2$ flops.\n- One forward and backward substitution: $4Nm$ flops.\n\n**Strategy 2 (Iterative Method):** For each of the $K$ power method iterations, solve the linear system using an iterative solver (such as the Jacobi or Gauss-Seidel method). We assume that for each system, this iterative solver requires a fixed number of inner iterations, $J$, to reach the desired accuracy. The dominant computational cost for this approach is:\n- One inner iteration of the iterative solver: $2N(2m+1)$ flops.\n\nYour task is to determine the breakeven point between these two strategies. Find an expression for the number of inner iterations, $J$, for which the total computational cost of Strategy 2 is exactly equal to the total computational cost of Strategy 1 over the course of $K$ power method iterations. Assume $N$, $K$, and $m$ are sufficiently large so that the provided dominant cost terms are accurate. Your final expression should be a function of $m$ and $K$.",
            "solution": "We compare total flop counts of the two strategies over $K$ outer iterations.\n\nFor Strategy 1 (direct with banded LU), the total cost is the one-time LU factorization plus $K$ triangular solves:\n$$\nC_{1}=2Nm^{2}+K\\cdot(4Nm)=2Nm^{2}+4KNm.\n$$\n\nFor Strategy 2 (iterative solve per outer iteration), each inner iteration costs $2N(2m+1)$ flops, and $J$ inner iterations are performed per outer iteration, for $K$ outer iterations total:\n$$\nC_{2}=K\\cdot J\\cdot 2N(2m+1).\n$$\n\nAt the breakeven point we set $C_{1}=C_{2}$ and solve for $J$:\n$$\n2Nm^{2}+4KNm=KJ\\cdot 2N(2m+1).\n$$\nDivide both sides by $2N$:\n$$\nm^{2}+2Km=KJ(2m+1).\n$$\nHence,\n$$\nJ=\\frac{m^{2}+2Km}{K(2m+1)}=\\frac{m(m+2K)}{K(2m+1)}.\n$$\nThis expression depends only on $m$ and $K$, as required.",
            "answer": "$$\\boxed{\\frac{m\\left(m+2K\\right)}{K\\left(2m+1\\right)}}$$"
        }
    ]
}