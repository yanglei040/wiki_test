{
    "hands_on_practices": [
        {
            "introduction": "To truly understand an algorithm, there's no substitute for walking through its steps. This first practice exercise provides a concrete opportunity to apply Brent's method manually for two iterations. By tracking the choices between the secant method, inverse quadratic interpolation, and bisection, you will gain a firsthand appreciation for the hybrid logic that makes this algorithm both fast and reliable. ",
            "id": "2157795",
            "problem": "Brent's method is a popular root-finding algorithm that combines the bisection method, the secant method, and inverse quadratic interpolation. Consider the function $f(x) = J_0(x)$, where $J_0(x)$ is the zeroth-order Bessel function of the first kind. We want to find the first positive root of this function.\n\nYou are given an initial bracketing interval for the root $[a_0, b_0] = [2.0, 3.0]$. Your task is to apply Brent's method for two full iterations to find a more accurate estimate of the root.\n\nThe logic of the method you must follow is:\n1.  At each step, with a current bracketing interval $[a, b]$ and a third point $c$ (the previous value of $b$), first attempt to use inverse quadratic interpolation with the points $(a, f(a))$, $(b, f(b))$, and $(c, f(c))$ to find a new estimate, $s$. This is only possible if $f(a)$, $f(b)$, and $f(c)$ are distinct.\n2.  If inverse quadratic interpolation is not possible or its result is not accepted, fall back to the secant method using the points $(a, f(a))$ and $(b, f(b))$ to find the estimate $s$.\n3.  The new estimate $s$ from either interpolation or the secant method is only accepted if it lies between $\\frac{3a+b}{4}$ and $b$.\n4.  If the estimate $s$ is not accepted, the bisection method is used instead, where the new estimate is the midpoint $s = \\frac{a+b}{2}$.\n5.  After finding the new estimate $s$, the interval $[a, b]$ and the point $c$ are updated for the next iteration based on the signs of the function values. The new interval must always bracket the root.\n\nTo perform the calculation, use the following pre-computed function values:\n- $J_0(2.0) = 0.22389$\n- $J_0(3.0) = -0.26005$\n- $J_0(2.46264) = -0.02495$\n- $J_0(2.41146) = -0.00282$\n\nCalculate the value of the best root estimate after two full iterations of the method have been completed. The best estimate is the endpoint of the final bracketing interval whose function value is closer to zero. Report your final answer rounded to four significant figures.",
            "solution": "We apply Brent’s method exactly as specified, using only the provided function values.\n\nLet $f(x)=J_{0}(x)$. Initially, $a_{0}=2.0$, $b_{0}=3.0$, with $f(a_{0})=0.223890$ and $f(b_{0})=-0.260050$, so the interval $[a_{0},b_{0}]$ brackets a root. For the first iteration, we take $c_{0}=a_{0}$ (so inverse quadratic interpolation is not possible because $a_{0}=c_{0}$).\n\nIteration 1:\n- Since inverse quadratic interpolation is not possible, use the secant method with $(a_{0},f(a_{0}))$ and $(b_{0},f(b_{0}))$:\n$$\ns_{1}\n= b_{0} - f(b_{0})\\frac{b_{0}-a_{0}}{f(b_{0})-f(a_{0})}\n= 3.0 - \\left(-0.26005\\right)\\frac{3.0-2.0}{-0.26005-0.22389}.\n$$\nCompute the denominator $f(b_{0})-f(a_{0})=-0.48394$, so\n$$\ns_{1}=3.0 - \\frac{-0.26005}{-0.48394}=3.0-0.53736=2.46264.\n$$\n- Acceptance check: $s_{1}$ must satisfy $\\frac{3a_{0}+b_{0}}{4} \\leq s_{1} \\leq b_{0}$. Here, $\\frac{3\\cdot 2.0 + 3.0}{4}=2.25$, and $2.25 \\leq 2.46264 \\leq 3.0$, so $s_{1}$ is accepted.\n- Update the bracketing interval using signs: $f(a_{0})\\cdot f(s_{1})=0.22389\\cdot(-0.02495)0$, so the new bracket is $[a_{1},b_{1}]=[a_{0},s_{1}]=[2.0,2.46264]$. Set $c_{1}=b_{0}=3.0$. The provided value $f(b_{1})=f(2.46264)=-0.02495$ will be used.\n\nIteration 2:\n- Attempt inverse quadratic interpolation with $(a_{1},f(a_{1}))=(2.0,0.22389)$, $(b_{1},f(b_{1}))=(2.46264,-0.02495)$, and $(c_{1},f(c_{1}))=(3.0,-0.26005)$, which have distinct function values. Using inverse quadratic interpolation (interpolating $x$ as a quadratic function of $y=f(x)$ and evaluating at $y=0$), the formula is\n$$\ns_{2}\n= x_{0}\\frac{f_{1}f_{2}}{(f_{0}-f_{1})(f_{0}-f_{2})}\n+ x_{1}\\frac{f_{0}f_{2}}{(f_{1}-f_{0})(f_{1}-f_{2})}\n+ x_{2}\\frac{f_{0}f_{1}}{(f_{2}-f_{0})(f_{2}-f_{1})},\n$$\nwith $(x_{0},f_{0})=(2.0,0.22389)$, $(x_{1},f_{1})=(2.46264,-0.02495)$, $(x_{2},f_{2})=(3.0,-0.26005)$.\nUsing the provided values (and arithmetic consistent with them), this yields\n$$\ns_{2}=2.41146.\n$$\n- Acceptance check: $s_{2}$ must satisfy $\\frac{3a_{1}+b_{1}}{4} \\leq s_{2} \\leq b_{1}$. Here, $\\frac{3\\cdot 2.0 + 2.46264}{4}=\\frac{8.46264}{4}=2.11566$, and $2.11566 \\leq 2.41146 \\leq 2.46264$, so $s_{2}$ is accepted.\n- Update the bracketing interval using signs: $f(a_{1})\\cdot f(s_{2})=0.22389\\cdot(-0.00282)0$, so the new bracket is $[a_{2},b_{2}]=[a_{1},s_{2}]=[2.0,2.41146]$. The provided value $f(b_{2})=f(2.41146)=-0.00282$ will be used.\n\nAfter two full iterations, the final bracketing interval is $[2.0,2.41146]$ with function values $f(2.0)=0.22389$ and $f(2.41146)=-0.00282$. The best estimate is the endpoint whose function value is closer to zero, namely $b_{2}=2.41146$. Rounding to four significant figures gives $2.411$.",
            "answer": "$$\\boxed{2.411}$$"
        },
        {
            "introduction": "The genius of Brent's method lies not just in its speed but in its robustness, as the algorithm's fallback to the bisection method is a critical safety net. This exercise explores a scenario where the function's geometry near the root—specifically, a vertical tangent—violates the smoothness assumptions that make interpolation methods effective. Analyzing this case will clarify why the bisection component is indispensable for guaranteeing convergence. ",
            "id": "2157793",
            "problem": "Brent's method is a popular root-finding algorithm that combines the reliability of the bisection method with the speed of interpolation-based techniques, namely the secant method and inverse quadratic interpolation. The algorithm attempts to use the faster interpolation methods when possible but falls back to the bisection method if the interpolation steps are not satisfactory.\n\nConsider the function $f(x) = \\text{sign}(x-2) \\sqrt{|x-2|}$, which has a root at $x=2$. When applying Brent's method to find this root, the interpolation-based steps are observed to perform poorly, causing the algorithm to rely heavily on the bisection fallback and thus converge much more slowly than expected.\n\nWhich of the following statements provides the most accurate mathematical reason for the poor performance of the interpolation-based steps (secant method and inverse quadratic interpolation) for this specific function near its root?\n\nA. The function is discontinuous at the root $x=2$.\n\nB. The function has an odd symmetry with respect to the root, i.e., $f(2+h) = -f(2-h)$, which forces the algorithm to take symmetric but slow steps.\n\nC. The function's first derivative is undefined at the root, approaching infinity as $x$ approaches the root.\n\nD. The function's second derivative is zero at the root, indicating an inflection point that slows down convergence.\n\nE. The algorithm fails because it can only be applied to polynomials, but the function involves a square root term.",
            "solution": "The goal is to understand why the interpolation-based components of Brent's method (secant method and inverse quadratic interpolation) perform poorly for the function $f(x) = \\text{sign}(x-2) \\sqrt{|x-2|}$ near its root $x=2$.\n\nFirst, let's analyze the function $f(x)$. The function is defined using the sign function and the absolute value. We can express it in a piecewise form to better understand its behavior around the root $x=2$.\n- If $x  2$, then $x-2  0$, so $\\text{sign}(x-2) = 1$ and $|x-2| = x-2$. Thus, $f(x) = \\sqrt{x-2}$.\n- If $x  2$, then $x-2  0$, so $\\text{sign}(x-2) = -1$ and $|x-2| = -(x-2) = 2-x$. Thus, $f(x) = -\\sqrt{2-x}$.\n- If $x = 2$, then $f(2) = \\text{sign}(0)\\sqrt{0} = 0 \\times 0 = 0$.\n\nThe interpolation methods used in Brent's algorithm, the secant method and inverse quadratic interpolation, achieve their fast convergence rates by assuming that the function is locally smooth and can be well-approximated by a low-degree polynomial (a line for the secant method, a quadratic for inverse quadratic interpolation). A key indicator of this smoothness is the behavior of the function's derivatives near the root.\n\nLet's compute the first derivative, $f'(x)$, for $x \\neq 2$.\n- For $x  2$, $f'(x) = \\frac{d}{dx}(\\sqrt{x-2}) = \\frac{d}{dx}((x-2)^{1/2}) = \\frac{1}{2}(x-2)^{-1/2} = \\frac{1}{2\\sqrt{x-2}}$.\n- For $x  2$, $f'(x) = \\frac{d}{dx}(-\\sqrt{2-x}) = -\\frac{1}{2}(2-x)^{-1/2}(-1) = \\frac{1}{2\\sqrt{2-x}}$.\n\nNow, we examine the limit of the derivative as $x$ approaches the root at $2$.\n- As $x \\to 2$ from the right ($x \\to 2^+$), the denominator $2\\sqrt{x-2} \\to 0^+$. Thus, $\\lim_{x\\to 2^+} f'(x) = +\\infty$.\n- As $x \\to 2$ from the left ($x \\to 2^-$), the denominator $2\\sqrt{2-x} \\to 0^+$. Thus, $\\lim_{x\\to 2^-} f'(x) = +\\infty$.\n\nSince the limit of the derivative approaches infinity from both sides, the derivative $f'(2)$ is undefined. Geometrically, this means the function has a vertical tangent at its root $x=2$.\n\nThis vertical tangent is the primary reason for the failure of the interpolation methods:\n1.  **Secant Method:** This method approximates the function with a secant line between two points $(x_n, f(x_n))$ and $(x_{n-1}, f(x_{n-1}))$. When these points are close to the root at $x=2$, the function is nearly vertical. The secant line will also be nearly vertical, and its intersection with the x-axis (the next root estimate) can be highly sensitive to small changes in the points, leading to inaccurate or unstable steps. The fundamental assumption of local linearity is violated.\n2.  **Inverse Quadratic Interpolation (IQI):** This method fits a quadratic polynomial to the *inverse* function, $x = f^{-1}(y)$. If the original function $f(x)$ has an infinite derivative at the root, the inverse function will have a derivative of zero. The derivative of the inverse is $(f^{-1})'(y) = 1/f'(x)$. As $x \\to 2$, $f'(x) \\to \\infty$, so $(f^{-1})'(0) = 0$. Let's look at the second derivative of the inverse. The inverse function is $x = 2+y|y|$. Its first derivative is $x'(y) = 2|y|$, and its second derivative is $x''(y) = 2 \\text{sign}(y)$, which has a jump discontinuity at $y=0$. A function with a discontinuous second derivative cannot be well-approximated by a single quadratic polynomial near that point.\n\nBecause both interpolation schemes fail to produce reliable and fast-converging estimates, Brent's method's logic will repeatedly reject their outputs and fall back to the guaranteed, but slow, bisection method.\n\nNow we evaluate the given options:\nA. The function is discontinuous at the root $x=2$. This is false. As shown above, $\\lim_{x\\to 2} f(x) = 0 = f(2)$, so the function is continuous.\nB. The function has an odd symmetry with respect to the root. This statement is true, as $f(2+h) = \\text{sign}(h)\\sqrt{|h|}$ and $-f(2-h) = -(\\text{sign}(-h)\\sqrt{|-h|}) = -(-\\text{sign}(h)\\sqrt{|h|}) = \\text{sign}(h)\\sqrt{|h|}$. However, this is not the cause of the poor performance. For example, $g(x) = x-2$ also has this symmetry, and Brent's method works perfectly.\nC. The function's first derivative is undefined at the root, approaching infinity as $x$ approaches the root. This is true, as demonstrated by our calculation. This infinite derivative (vertical tangent) violates the smoothness assumptions underlying the interpolation methods, causing them to perform poorly. This is the correct explanation.\nD. The function's second derivative is zero at the root. This is false. The first derivative is not even defined at the root, so the second derivative cannot be. Furthermore, for $x2$, $f''(x) = -\\frac{1}{4}(x-2)^{-3/2}$, which approaches $-\\infty$ as $x \\to 2^+$.\nE. The algorithm fails because it can only be applied to polynomials. This is false. Brent's method is a general-purpose root-finder applicable to a wide range of continuous functions.\n\nTherefore, the most accurate reason for the poor performance is the infinite derivative at the root.",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "A numerical algorithm is only as good as its inputs and the assumptions it's built upon, and while Brent's method checks for a sign change, it implicitly assumes the function is continuous within the bracketing interval. This thought experiment presents a \"pathological\" case where a vertical asymptote, not a root, causes the sign change. Predicting the algorithm's behavior here will sharpen your critical thinking and highlight the importance of understanding a function's behavior before applying a root-finding method. ",
            "id": "2157800",
            "problem": "Consider the function $f(x) = \\frac{1}{x - \\pi}$ on the initial bracketing interval $[a_0, b_0] = [3, 4]$. A computer program implements Brent's method to find a root of $f(x)$ within this interval, starting with the given bracket. The implementation uses standard double-precision floating-point arithmetic and adheres to the typical logic of Brent's method, which combines the bisection method, the secant method, and inverse quadratic interpolation. The method's termination condition is based on the width of the bracketing interval becoming smaller than a predefined tolerance.\n\nGiven that the initial interval satisfies the condition $f(a_0) f(b_0)  0$, which of the following statements most accurately describes the behavior and outcome of the algorithm?\n\nA. The algorithm will converge to the true root of the function $f(x)$.\n\nB. The algorithm will rapidly determine that no root exists within the interval $[3, 4]$ and terminate gracefully, reporting this fact.\n\nC. The sequence of iterates generated by the algorithm will converge towards $x=\\pi$, and the program will eventually terminate due to a runtime error such as division by zero or a floating-point overflow.\n\nD. The algorithm will enter an infinite loop where the bracketing interval $[a_k, b_k]$ fails to shrink, as the proposals from the secant method and inverse quadratic interpolation are always rejected.\n\nE. The algorithm will converge to one of the endpoints, either $x=3$ or $x=4$, because the function's magnitude is minimized at the points farthest from the vertical asymptote.",
            "solution": "We analyze the behavior of Brent’s method when applied to the function $f(x) = \\frac{1}{x - \\pi}$ on the interval $[3,4]$.\n\n1) Basic properties of $f$:\n- The function is defined for all $x \\in \\mathbb{R}$ with $x \\neq \\pi$ and has a simple pole (vertical asymptote) at $x=\\pi$.\n- $f$ has no real zeros, because $\\frac{1}{x-\\pi} = 0$ has no solution.\n- On $[3,4]$, we have $3  \\pi  4$, hence $f(3)  0$ and $f(4)  0$. Therefore, $f(3) f(4)  0$, but the sign change occurs because of the discontinuity at $x=\\pi$, not because of a zero.\n\n2) Brent’s method assumptions and invariants:\n- Brent’s method requires an initial bracketing interval $[a_{0}, b_{0}]$ with $f(a_{0}) f(b_{0})  0$ and implicitly uses the continuity of $f$ on the interval to guarantee the existence of a root by the intermediate value theorem. Here, continuity fails at $x=\\pi$.\n- Nonetheless, the algorithm maintains the bracketing invariant $f(a_{k}) f(b_{k})  0$. Because $f$ changes sign across $x=\\pi$ and is continuous on each side but not across the asymptote, this invariant implies $a_{k}  \\pi  b_{k}$ for all $k$.\n\n3) Bisection behavior within Brent’s method:\n- Let $m_{k} = \\frac{a_{k} + b_{k}}{2}$. Then\n$$\nf(m_{k}) = \\frac{1}{m_{k} - \\pi}.\n$$\n- The sign of $f(m_{k})$ equals the sign of $m_{k} - \\pi$. Therefore:\n  - If $m_{k}  \\pi$, then $f(m_{k})  0$ and the new bracket becomes $[m_{k}, b_{k}]$.\n  - If $m_{k}  \\pi$, then $f(m_{k})  0$ and the new bracket becomes $[a_{k}, m_{k}]$.\n- Thus, whenever a bisection step is taken, the bracketing interval strictly shrinks and continues to straddle $\\pi$:\n$$\na_{k} \\uparrow \\pi, \\quad b_{k} \\downarrow \\pi.\n$$\n\n4) Secant and inverse quadratic interpolation within Brent’s method:\n- The secant and inverse quadratic interpolation proposals, when accepted by Brent’s safeguards, lie within $(a_{k}, b_{k})$; hence they are on one side of $\\pi$. Their function values remain finite unless the proposed point equals $\\pi$ in floating-point arithmetic, in which case $f$ is undefined and a floating-point division by zero occurs.\n- If a proposed point is not acceptable (e.g., lies outside the interval or violates Brent’s acceptance criteria), Brent’s method reverts to bisection, which guarantees shrinkage of the bracket.\n\n5) Convergence and termination:\n- Because the interval always straddles $x=\\pi$ and the method guarantees shrinkage (at least via bisection), we have\n$$\n\\lim_{k \\to \\infty} a_{k} = \\pi^{-}, \\qquad \\lim_{k \\to \\infty} b_{k} = \\pi^{+}.\n$$\n- The method’s termination condition, as stated, is based on the width $|b_{k} - a_{k}|$ falling below a preset tolerance. Therefore, the algorithm will drive the iterates toward $x=\\pi$ and will attempt to evaluate $f$ at points increasingly close to $\\pi$.\n- Since $|f(x)| = \\left|\\frac{1}{x - \\pi}\\right| \\to \\infty$ as $x \\to \\pi$, the numerical evaluations of $f$ can become extremely large. In standard double-precision arithmetic, two failure modes are possible in principle:\n  - If an iterate equals the floating-point representation of $\\pi$, then a division by zero occurs.\n  - If $|x - \\pi|$ becomes so small that $\\left|\\frac{1}{x - \\pi}\\right|$ exceeds the largest representable finite number, a floating-point overflow occurs.\n- Independently of whether an exception is actually triggered before the tolerance criterion is met, the essential behavior is that the iterates converge to $x=\\pi$, not to a root (none exists). The algorithm does not “detect” absence of a root because it is misled by the sign change induced by the pole, not by a zero crossing.\n\n6) Elimination of options:\n- A is false: there is no root, so convergence to a true root cannot occur.\n- B is false: because $f(a_{0}) f(b_{0})  0$, the method assumes a root exists by continuity and does not “rapidly” detect the absence of a root.\n- D is false: Brent’s bisection safeguard ensures the bracket shrinks; no infinite loop with a fixed-width bracket occurs.\n- E is false: the method does not converge to an endpoint; it shrinks the interval around $\\pi$.\n- C correctly captures that the iterates converge to $x=\\pi$ and that numerical evaluation near the pole can lead to a computational failure such as division by zero or overflow. Among the given choices, this most accurately describes the behavior.",
            "answer": "$$\\boxed{C}$$"
        }
    ]
}