{
    "hands_on_practices": [
        {
            "introduction": "The first step in mastering the fixed-point iteration method is to confidently apply its governing convergence theorem. This exercise provides a classic scenario, asking you to verify if the iteration $x_{k+1} = \\cos(x_k)$ is guaranteed to converge on a given interval. You will need to check both key conditions from the Fixed-Point Theorem: that the function maps the interval to itself and that it is a contraction, reinforcing the theoretical foundation of the method. ",
            "id": "2162898",
            "problem": "A numerical analyst is tasked with finding the root of the equation $f(x) = x - \\cos(x) = 0$. They decide to use a fixed-point iteration method by rearranging the equation into the form $x = g(x)$. The chosen iteration scheme is defined as $x_{k+1} = \\cos(x_k)$, with an initial guess $x_0$ chosen from the interval $[0, 1]$. All calculations involving trigonometric functions assume the angles are measured in radians.\n\nWhich of the following statements correctly analyzes whether this iterative scheme is guaranteed to converge to the unique fixed point within the interval $[0, 1]$ for any arbitrary choice of $x_0 \\in [0, 1]$?\n\nA. Convergence is guaranteed because the function $g(x) = \\cos(x)$ maps the interval $[0, 1]$ to itself, and the magnitude of its derivative is strictly less than 1 for all points within this interval.\n\nB. Convergence is not guaranteed because the function $g(x) = \\cos(x)$ does not map the interval $[0, 1]$ to itself; for some values of $x$ in the interval, $g(x)$ falls outside of $[0, 1]$.\n\nC. Convergence is not guaranteed because the condition on the derivative is not met; there exists at least one point in the interval $[0, 1]$ where the magnitude of the derivative of $g(x) = \\cos(x)$ is equal to or greater than 1.\n\nD. Convergence is only guaranteed for specific starting points like $x_0=0.5$, but not for all starting points in the interval $[0, 1]$, as the conditions for global convergence on the interval are not fully satisfied.\n\nE. Convergence is guaranteed because the function $g(x) = \\cos(x)$ is continuous on the interval $[0, 1]$. The derivative condition is only relevant for determining the rate of convergence, not for guaranteeing it.",
            "solution": "We consider the fixed-point iteration $x_{k+1}=g(x_{k})$ with $g(x)=\\cos(x)$ on the interval $[0,1]$. To guarantee convergence to a unique fixed point for any $x_{0}\\in[0,1]$, we verify the conditions of the Banach fixed-point theorem: (i) $g$ maps $[0,1]$ into itself, and (ii) $g$ is a contraction on $[0,1]$.\n\nFirst, we show $g([0,1])\\subseteq[0,1]$. Since $g'(x)=-\\sin(x)\\leq 0$ on $[0,1]$, $g$ is nonincreasing on $[0,1]$. Therefore,\n$$\ng([0,1])=[g(1),g(0)]=[\\cos(1),\\cos(0)]=[\\cos(1),1].\n$$\nBecause $1\\frac{\\pi}{2}$, we have $\\cos(1)0$, hence $[\\cos(1),1]\\subseteq[0,1]$. Thus, $g$ maps the interval to itself.\n\nSecond, we show $g$ is a contraction on $[0,1]$. The derivative is $g'(x)=-\\sin(x)$, so\n$$\n|g'(x)|=|\\sin(x)|\\leq \\sin(1)1 \\quad \\text{for all } x\\in[0,1],\n$$\nsince $0\\leq x\\leq 1\\frac{\\pi}{2}$ and $\\sin$ is strictly increasing on $[0,\\frac{\\pi}{2}]$ with $\\sin\\!\\left(\\frac{\\pi}{2}\\right)=1$. By the mean value theorem, for all $x,y\\in[0,1]$,\n$$\n|g(x)-g(y)|\\leq \\sup_{z\\in[0,1]}|g'(z)|\\,|x-y|\\leq \\sin(1)\\,|x-y|,\n$$\nwith a Lipschitz constant $L=\\sin(1)$ satisfying $0\\leq L1$. Therefore, $g$ is a contraction on $[0,1]$.\n\nBy the Banach fixed-point theorem on the complete metric space $([0,1],|\\cdot|)$, there exists a unique fixed point $x^{\\ast}\\in[0,1]$ such that $x^{\\ast}=\\cos(x^{\\ast})$, and for any $x_{0}\\in[0,1]$, the sequence defined by $x_{k+1}=\\cos(x_{k})$ converges to $x^{\\ast}$.\n\nTherefore, the correct statement is that convergence is guaranteed because $g$ maps $[0,1]$ into itself and satisfies $|g'(x)|1$ on $[0,1]$. This corresponds to option A. The alternatives are incorrect: B is false since $g([0,1])\\subseteq[0,1]$; C is false because $\\sup_{[0,1]}|g'|=\\sin(1)1$; D is false because the contraction property ensures convergence for all $x_{0}\\in[0,1]$; E is false because continuity alone does not guarantee convergence without a contraction condition.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Convergence is not always a global property; it can be highly dependent on the starting point and the specific fixed point in question. This practice explores a function with two distinct fixed points, where the iteration is stable around one but unstable around the other. By analyzing different intervals, you will gain a deeper understanding of local convergence and the critical role the derivative's magnitude, $|g'(p)|$, plays in determining the stability of the iteration. ",
            "id": "2162900",
            "problem": "In a simplified model of a reversible chemical process, the dimensionless equilibrium concentration, $c$, of a certain product can be found by solving for the fixed points of the function $g(c) = \\frac{1}{3}(c^2+1)$. A numerical approach to find this concentration is the fixed-point iteration method, defined by the sequence $c_{n+1} = g(c_n)$ for $n \\ge 0$, starting with an initial guess $c_0$.\n\nThe convergence of this iteration to a unique fixed point within an interval $[a, b]$ is guaranteed by the Fixed-Point Theorem if two conditions are met:\n1.  For all $c \\in [a, b]$, the value of $g(c)$ is also in $[a, b]$ (i.e., $g$ maps the interval into itself).\n2.  There exists a constant $k  1$ such that the absolute value of the derivative, $|g'(c)|$, is less than or equal to $k$ for all $c \\in [a, b]$.\n\nThe function $g(c)$ has two distinct positive fixed points. Your task is to identify which one of the following intervals satisfies both conditions of the Fixed-Point Theorem, thereby guaranteeing convergence to the fixed point contained within that interval.\n\nWhich of the following intervals $[a, b]$ satisfies both conditions for convergence?\n\nA. $[0, 1.2]$\n\nB. $[2.5, 2.7]$\n\nC. $[1.4, 1.6]$\n\nD. $[-1, 2]$",
            "solution": "We are given the fixed-point iteration $c_{n+1} = g(c_{n})$ with $g(c) = \\frac{1}{3}\\left(c^{2} + 1\\right)$. The Fixed-Point (Banach) Contraction Theorem guarantees existence, uniqueness, and convergence to the fixed point in an interval $[a,b]$ if:\n1) $g([a,b]) \\subseteq [a,b]$ (interval is mapped into itself), and\n2) $\\sup_{c \\in [a,b]} |g'(c)| \\le k  1$ (contraction on $[a,b]$).\n\nCompute the derivative:\n$$\ng'(c) = \\frac{2}{3}c.\n$$\nHence, on any interval $[a,b]$, we have\n$$\n\\sup_{c \\in [a,b]} |g'(c)| = \\frac{2}{3}\\max\\{|a|,|b|\\}.\n$$\nThus the contraction condition holds if and only if $\\max\\{|a|,|b|\\}  \\frac{3}{2}$.\n\nWe now check each option for both conditions.\n\nOption A: $[0,1.2] = \\left[0,\\frac{6}{5}\\right]$.\n- Contraction: \n$$\n\\sup_{c \\in [0,6/5]} |g'(c)| = \\frac{2}{3}\\cdot \\frac{6}{5} = \\frac{4}{5}  1,\n$$\nso the contraction condition holds.\n- Mapping into itself: Since $g$ is even and increasing on $[0,\\infty)$,\n$$\ng([0,6/5]) = [g(0),g(6/5)].\n$$\nCompute the endpoints:\n$$\ng(0) = \\frac{1}{3} \\ge 0,\\qquad g\\!\\left(\\frac{6}{5}\\right) = \\frac{1}{3}\\left(1 + \\left(\\frac{6}{5}\\right)^{2}\\right) = \\frac{1}{3}\\left(1 + \\frac{36}{25}\\right) = \\frac{61}{75}.\n$$\nSince $0 \\le \\frac{1}{3} \\le \\frac{61}{75}  \\frac{6}{5}$ (because $61  90$), it follows that\n$$\ng([0,6/5]) \\subseteq [0,6/5].\n$$\nBoth conditions are satisfied for A.\n\nOption B: $[2.5,2.7] = \\left[\\frac{5}{2},\\frac{27}{10}\\right]$.\n- Contraction:\n$$\n\\sup_{c \\in [5/2,27/10]} |g'(c)| = \\frac{2}{3}\\cdot \\frac{27}{10} = \\frac{27}{15}  1,\n$$\nso the contraction condition fails.\n- Mapping into itself also fails, since\n$$\ng\\!\\left(\\frac{5}{2}\\right) = \\frac{1}{3}\\left(1 + \\frac{25}{4}\\right) = \\frac{29}{12}  \\frac{5}{2},\\quad\ng\\!\\left(\\frac{27}{10}\\right) = \\frac{1}{3}\\left(1 + \\frac{729}{100}\\right) = \\frac{829}{300}  \\frac{27}{10},\n$$\nhence $g([5/2,27/10]) \\not\\subseteq [5/2,27/10]$.\n\nOption C: $[1.4,1.6] = \\left[\\frac{7}{5},\\frac{8}{5}\\right]$.\n- Contraction:\n$$\n\\sup_{c \\in [7/5,8/5]} |g'(c)| = \\frac{2}{3}\\cdot \\frac{8}{5} = \\frac{16}{15}  1,\n$$\nso the contraction condition fails.\n- Mapping into itself also fails since\n$$\ng\\!\\left(\\frac{7}{5}\\right) = \\frac{1}{3}\\left(1 + \\frac{49}{25}\\right) = \\frac{74}{75}  \\frac{7}{5},\n$$\nhence $g([7/5,8/5]) \\not\\subseteq [7/5,8/5]$.\n\nOption D: $[-1,2]$.\n- Contraction:\n$$\n\\sup_{c \\in [-1,2]} |g'(c)| = \\frac{2}{3}\\cdot 2 = \\frac{4}{3}  1,\n$$\nso the contraction condition fails.\n- Mapping into itself holds because $g$ is even and increasing in $|c|$:\n$$\ng([-1,2]) = [g(0),g(2)] = \\left[\\frac{1}{3},\\frac{1}{3}(1+4)\\right] = \\left[\\frac{1}{3},\\frac{5}{3}\\right] \\subseteq [-1,2],\n$$\nbut without contraction this option does not satisfy the theoremâ€™s conditions.\n\nTherefore, only option A satisfies both the mapping and contraction conditions, guaranteeing convergence to the fixed point in that interval.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Moving beyond simply analyzing convergence, a numerical analyst often needs to design or optimize an iterative algorithm. This problem challenges you to do just that by adjusting a parameter in the iteration function to achieve the fastest possible local convergence. This exercise introduces the powerful idea that by making the derivative of the iteration function zero at the fixed point, we can transition from linear to a much faster, quadratic, rate of convergence. ",
            "id": "2162905",
            "problem": "A numerical procedure for finding a root of an equation $f(x)=0$ involves creating a fixed-point iteration scheme of the form $x_{k+1} = g(x_k)$, where the root is a fixed point of $g(x)$.\nConsider the quadratic equation $x^2 - 6x - 16 = 0$. An iteration scheme is proposed using the function $g(x) = x + c(x^2 - 6x - 16)$, where $c$ is a constant parameter. The choice of $c$ critically affects the performance of the algorithm.\n\nDetermine the exact value of the constant $c$ that provides the fastest possible local convergence of the iteration to the *positive* root of the equation.\n\nExpress your answer as a final numerical value.",
            "solution": "We seek a constant-step fixed-point iteration of the form $x_{k+1}=g(x_{k})$ with\n$$\ng(x)=x+c f(x), \\quad f(x)=x^{2}-6x-16,\n$$\nto converge as fast as possible to the positive root of $f(x)=0$.\n\nFirst, determine the positive root $r$ of $f(x)=0$. Solving the quadratic equation,\n$$\nx^{2}-6x-16=0 \\;\\;\\Rightarrow\\;\\; x=\\frac{6\\pm\\sqrt{36+64}}{2}=\\frac{6\\pm 10}{2}\\in\\{8,-2\\}.\n$$\nHence the positive root is $r=8$.\n\nFor a fixed-point iteration $x_{k+1}=g(x_{k})$ to converge locally to $r$, it is necessary that $g(r)=r$ and sufficient that $|g'(r)|1$. The local error satisfies, for $e_{k}=x_{k}-r$,\n$$\ne_{k+1}=g(r+e_{k})-g(r)=g'(r)e_{k}+\\frac{1}{2}g''(r)e_{k}^{2}+O(e_{k}^{3}).\n$$\nThus the asymptotic linear convergence factor is $|g'(r)|$, and the fastest local convergence is achieved by minimizing $|g'(r)|$. The optimal choice is to enforce $g'(r)=0$, which yields at least quadratic convergence.\n\nCompute $g'(x)$:\n$$\ng'(x)=1+c f'(x), \\quad f'(x)=2x-6.\n$$\nImpose $g'(r)=0$:\n$$\n0=1+c f'(r) \\;\\;\\Rightarrow\\;\\; c=-\\frac{1}{f'(r)}.\n$$\nEvaluate $f'(r)$ at $r=8$:\n$$\nf'(8)=2\\cdot 8-6=10.\n$$\nTherefore,\n$$\nc=-\\frac{1}{10}.\n$$\nThis choice makes $g'(r)=0$ and yields the fastest possible local convergence (quadratic order) for this family $g(x)=x+c f(x)$ with constant $c$.",
            "answer": "$$\\boxed{-\\frac{1}{10}}$$"
        }
    ]
}