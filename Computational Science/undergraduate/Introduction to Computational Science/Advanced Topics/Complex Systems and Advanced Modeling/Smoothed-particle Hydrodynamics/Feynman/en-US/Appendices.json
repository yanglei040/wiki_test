{
    "hands_on_practices": [
        {
            "introduction": "At the heart of Smoothed-Particle Hydrodynamics (SPH) lies the smoothing kernel, a weighting function that defines how properties are distributed and averaged in space. For the SPH method to accurately represent physical quantities and conserve mass, the kernel must satisfy the normalization condition, meaning its integral over all space must equal one. This exercise  provides a crucial first step in any SPH implementation: numerically verifying that your chosen kernel, the cubic spline, is correctly normalized in one, two, and three dimensions, thereby building confidence in this fundamental building block.",
            "id": "3194379",
            "problem": "You are given the task to design and implement a numerical experiment that verifies kernel normalization in Smoothed-Particle Hydrodynamics (SPH). The objective is to numerically approximate the spatial integral of a chosen SPH kernel $W(\\mathbf{r}, h)$ and test whether it is close to $1$ for a range of smoothing lengths $h$. The experiment should be formulated in purely mathematical and algorithmic terms and executed by a single, complete program.\n\nFundamental base: Use the standard, widely adopted cubic spline kernel definition from Smoothed-Particle Hydrodynamics (SPH). The kernel is radially symmetric, so $W(\\mathbf{r}, h) = W(r, h)$ with $r = \\lVert \\mathbf{r} \\rVert$. The cubic spline kernel is defined by the piecewise function\n$$\nW(r,h) = \\frac{\\sigma_d}{h^d}\n\\begin{cases}\n1 - \\frac{3}{2} q^2 + \\frac{3}{4} q^3, & 0 \\le q < 1, \\\\\n\\frac{1}{4} (2 - q)^3, & 1 \\le q < 2, \\\\\n0, & q \\ge 2,\n\\end{cases}\n$$\nwhere $q = \\frac{r}{h}$, $d \\in \\{1, 2, 3\\}$ is the spatial dimension, and $\\sigma_d$ is the dimension-dependent normalization constant:\n- For $d = 1$, $\\sigma_1 = \\frac{2}{3}$.\n- For $d = 2$, $\\sigma_2 = \\frac{10}{7\\pi}$.\n- For $d = 3$, $\\sigma_3 = \\frac{1}{\\pi}$.\n\nExperiment design requirements:\n- Numerically approximate the spatial integral $\\int_{\\mathbb{R}^d} W(\\mathbf{r}, h)\\, dV$ using a radial reduction. Since $W$ depends only on $r$, you must express the volume element $dV$ in terms of $r$:\n    - For $d = 1$, $dV = 2\\, dr$ over $r \\in [0, 2h]$.\n    - For $d = 2$, $dV = 2\\pi r\\, dr$ over $r \\in [0, 2h]$.\n    - For $d = 3$, $dV = 4\\pi r^2\\, dr$ over $r \\in [0, 2h]$.\n- Perform a numerical integration on the interval $r \\in [0, 2h]$ using a uniform partition of $N$ sample points and the composite trapezoid rule.\n- For each test case, compute the numerical approximation\n$$\nI(d,h,N) \\approx \\int_0^{2h} W(r,h)\\, S_d(r)\\, dr,\n$$\nwhere $S_d(r)$ is the corresponding radial surface measure factor, specifically $S_1(r) = 2$, $S_2(r) = 2\\pi r$, and $S_3(r) = 4\\pi r^2$.\n\nOutput specification:\n- For each test case, return a boolean indicating whether the numerical approximation $I(d,h,N)$ is within a tolerance of $10^{-5}$ of $1$, i.e., whether $\\lvert I(d,h,N) - 1 \\rvert \\le 10^{-5}$.\n- The final program output must be a single line containing the results for all test cases as a comma-separated list enclosed in square brackets (for example, `[True, False, True]` with Python booleans written as True or False).\n\nUnit specification:\n- The integral $\\int W\\, dV$ is dimensionless. All reported booleans are unitless.\n\nTest suite:\nEvaluate the following test cases, each given by the tuple $(d,h,N)$:\n1. $(1, 0.05, 100)$: Happy path in one dimension with small $h$ and moderate resolution $N$.\n2. $(2, 0.05, 100)$: Happy path in two dimensions with small $h$ and moderate resolution $N$.\n3. $(3, 0.05, 100)$: Happy path in three dimensions with small $h$ and moderate resolution $N$.\n4. $(3, 1.0, 1000)$: Larger $h$ in three dimensions with high resolution $N$.\n5. $(2, 0.5, 600)$: Moderate $h$ in two dimensions with high resolution $N$.\n6. $(1, 2.0, 1200)$: Large $h$ in one dimension with high resolution $N$.\n\nYour program must implement the above and produce a single line of output containing the six booleans in order as a comma-separated list enclosed in square brackets.",
            "solution": "The user-provided problem is valid. It is a well-posed, scientifically grounded task from the field of computational science, specifically concerning the verification of a fundamental property of Smoothed-Particle Hydrodynamics (SPH) kernels. All necessary information is provided, and the task is to implement a numerical experiment based on standard mathematical and algorithmic principles.\n\nThe solution is designed based on the following principles and their translation into an algorithm.\n\n### 1. The Principle of Kernel Normalization\n\nIn SPH, physical quantities are approximated by summing contributions from neighboring particles, weighted by a kernel function $W$. For the method to be accurate and conserve quantities like mass, the kernel must be normalized. This means its integral over all space must be equal to one:\n$$\n\\int_{\\mathbb{R}^d} W(\\mathbf{r}, h) \\, dV = 1\n$$\nHere, $d$ is the number of spatial dimensions, $h$ is the smoothing length which defines the kernel's support size, and $dV$ is the volume element. The problem asks to numerically verify this property for the cubic spline kernel.\n\n### 2. The Cubic Spline Kernel\n\nThe problem provides the definition of the standard cubic spline kernel, which is a piecewise polynomial function with compact support (it is non-zero only for $r < 2h$). Its formula is:\n$$\nW(r,h) = \\frac{\\sigma_d}{h^d}\n\\begin{cases}\n1 - \\frac{3}{2} q^2 + \\frac{3}{4} q^3, & 0 \\le q < 1, \\\\\n\\frac{1}{4} (2 - q)^3, & 1 \\le q < 2, \\\\\n0, & q \\ge 2,\n\\end{cases}\n$$\nwhere $r = \\lVert \\mathbf{r} \\rVert$ is the radial distance, $q = r/h$ is the normalized radius, and $\\sigma_d$ is a dimension-dependent constant ($\\sigma_1 = 2/3$, $\\sigma_2 = 10/(7\\pi)$, $\\sigma_3 = 1/\\pi$) specifically chosen to ensure the normalization property holds analytically.\n\nThe algorithmic implementation of this kernel involves creating a function that takes $r$, $h$, and $d$ as inputs. Inside this function, the value of $q$ is computed. Conditional logic is required to select the correct polynomial segment based on the value of $q$. For efficient computation on an array of $r$ values, NumPy's boolean array masking is an ideal choice to apply the piecewise formulas in a vectorized manner.\n\n### 3. Radial Reduction of the Integral\n\nThe kernel $W(r,h)$ is radially symmetric, meaning its value depends only on the distance $r$ from the origin, not on the direction. This symmetry allows for a significant simplification of the $d$-dimensional integral. We can transform the integral from Cartesian coordinates to generalized spherical coordinates. The volume element $dV$ becomes a function of $r$ and angular variables. Integrating over the angular variables first yields a factor that is the surface area of a hypersphere of radius $r$. This reduces the multi-dimensional integral to a one-dimensional integral over the radial coordinate $r$.\n$$\n\\int_{\\mathbb{R}^d} W(\\mathbf{r}, h) \\, dV = \\int_0^\\infty W(r,h) \\, S_d(r) \\, dr\n$$\nwhere $S_d(r)$ is the \"surface measure factor\" provided in the problem statement:\n- For $d=1$: The \"volume\" element is $dx$. The integral is $\\int_{-2h}^{2h} W(x,h) dx$. Due to even symmetry ($W$ depends on $r=|x|$), this is $2 \\int_0^{2h} W(r,h) dr$. Thus, $S_1(r) = 2$.\n- For $d=2$: The volume element is $dV = r \\, dr \\, d\\theta$. Integrating over $\\theta$ from $0$ to $2\\pi$ gives a factor of $2\\pi$. Thus, $S_2(r) = 2\\pi r$.\n- For $d=3$: The volume element is $dV = r^2 \\sin\\theta \\, dr \\, d\\theta \\, d\\phi$. Integrating over the solid angle ($\\int_0^{2\\pi} \\int_0^\\pi \\sin\\theta \\, d\\theta \\, d\\phi$) gives $4\\pi$. Thus, $S_3(r) = 4\\pi r^2$.\n\nSince the kernel has compact support up to $r=2h$ (i.e., $W(r,h) = 0$ for $r \\ge 2h$), the upper limit of integration becomes $2h$. The final integral to be computed numerically is:\n$$\nI(d,h) = \\int_0^{2h} W(r,h) \\, S_d(r) \\, dr\n$$\nThe integrand is $f(r) = W(r,h) S_d(r)$. The algorithm will construct this integrand by first calculating the kernel values $W(r,h)$ and then multiplying by the appropriate factor $S_d(r)$, which is selected based on the dimension $d$.\n\n### 4. Numerical Integration via Composite Trapezoid Rule\n\nTo approximate the definite integral $I(d,h)$, the problem specifies the composite trapezoid rule. This method approximates the area under the integrand by dividing the integration interval $[0, 2h]$ into a number of subintervals and summing the areas of the trapezoids formed by connecting the function values at the endpoints of each subinterval.\n\nFor an interval $[a,b]$ partitioned into $N-1$ subintervals by $N$ equally spaced points $\\{r_0, \\dots, r_{N-1}\\}$ with step size $\\Delta r = (b-a)/(N-1)$, the formula is:\n$$\n\\int_a^b f(r) dr \\approx \\frac{\\Delta r}{2} \\sum_{i=0}^{N-2} (f(r_i) + f(r_{i+1}))\n$$\nThis method is straightforward to implement and is well-suited for continuous integrands like the one in this problem. The error of the composite trapezoid rule decreases as the number of points $N$ increases.\n\nThe algorithmic implementation uses `numpy.linspace(0, 2*h, N)` to generate the array of $N$ sample points `r_vals`. The corresponding integrand values `f_vals` are then calculated. The `numpy.trapz(f_vals, r_vals)` function provides a direct, efficient, and numerically stable implementation of the composite trapezoid rule, which calculates the definite integral approximation.\n\n### 5. Algorithmic Synthesis\n\nThe complete algorithm is structured as follows:\n1.  A main `solve` function iterates through the list of test cases $(d,h,N)$.\n2.  For each test case, a helper function, say `calculate_integral_and_check_norm`, is called.\n3.  This helper function first generates an array of $N$ radial points $r_i$ uniformly spaced from $0$ to $2h$.\n4.  It then calls a dedicated kernel function, `cubic_spline_kernel(r, h, d)`, which computes the kernel values $W(r_i,h)$ for all points in a vectorized operation.\n5.  The helper function then computes the full integrand values $f(r_i) = W(r_i, h) S_d(r_i)$, selecting the correct $S_d(r_i)$ based on dimension $d$.\n6.  The numerical integral $I(d,h,N)$ is computed using `numpy.trapz`.\n7.  The absolute difference $|I(d,h,N) - 1|$ is compared against the specified tolerance of $10^{-5}$.\n8.  A boolean result (`True` or `False`) is returned and appended to a list of results.\n9.  Finally, the `solve` function formats this list of booleans into the required output string `\"[True,False,...]\"` and prints it.\n\nThis design directly translates the mathematical principles into a modular and verifiable program.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef cubic_spline_kernel(r: np.ndarray, h: float, d: int) -> np.ndarray:\n    \"\"\"\n    Computes the SPH cubic spline kernel W(r, h) for a given dimension d.\n    The input r is expected to be a NumPy array.\n    \"\"\"\n    # 1. Determine the dimension-dependent normalization constant sigma_d.\n    if d == 1:\n        sigma_d = 2.0 / 3.0\n    elif d == 2:\n        sigma_d = 10.0 / (7.0 * np.pi)\n    elif d == 3:\n        sigma_d = 1.0 / np.pi\n    else:\n        # This case should not be reached with the given test suite.\n        raise ValueError(\"Dimension d must be 1, 2, or 3.\")\n\n    # 2. Calculate the normalized radius q = r/h.\n    # A small epsilon is added to h to avoid division by zero if h is ever 0.\n    q = r / (h + 1e-12)\n\n    # 3. Apply the piecewise function definition using boolean masking for vectorization.\n    # Initialize an array of zeros with the same shape as q.\n    kernel_values_unscaled = np.zeros_like(q, dtype=float)\n\n    # Condition for 0 <= q < 1\n    mask1 = q < 1.0\n    q1 = q[mask1]\n    kernel_values_unscaled[mask1] = 1.0 - 1.5 * q1**2 + 0.75 * q1**3\n\n    # Condition for 1 <= q < 2\n    mask2 = (q >= 1.0) & (q < 2.0)\n    q2 = q[mask2]\n    kernel_values_unscaled[mask2] = 0.25 * (2.0 - q2)**3\n\n    # For q >= 2, the values remain 0 as initialized.\n\n    # 4. Scale by the main normalization factor.\n    normalization_factor = sigma_d / (h**d)\n    return normalization_factor * kernel_values_unscaled\n\ndef calculate_integral_and_check_norm(d: int, h: float, N: int) -> bool:\n    \"\"\"\n    Numerically integrates the kernel for a given test case and checks if it's normalized.\n    It returns True if |integral - 1| <= 1e-5, and False otherwise.\n    \"\"\"\n    # Tolerance for checking the normalization.\n    tolerance = 1e-5\n\n    # 1. Set up the integration domain [0, 2h] and N sample points.\n    r_vals = np.linspace(0.0, 2.0 * h, N)\n\n    # 2. Calculate the kernel values at the sample points.\n    W_vals = cubic_spline_kernel(r_vals, h, d)\n\n    # 3. Calculate the full integrand, W(r,h) * S_d(r), where S_d is the surface measure.\n    if d == 1:\n        # S_1(r) = 2\n        integrand = 2.0 * W_vals\n    elif d == 2:\n        # S_2(r) = 2 * pi * r\n        integrand = 2.0 * np.pi * r_vals * W_vals\n    else:  # d == 3\n        # S_3(r) = 4 * pi * r^2\n        integrand = 4.0 * np.pi * r_vals**2 * W_vals\n    \n    # 4. Perform numerical integration using the composite trapezoid rule.\n    # np.trapz implements this rule efficiently.\n    integral_value = np.trapz(integrand, r_vals)\n\n    # 5. Check if the result is within the specified tolerance of 1.\n    is_normalized = abs(integral_value - 1.0) <= tolerance\n    return is_normalized\n\ndef solve():\n    \"\"\"\n    Main function to run the numerical experiment for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (d, h, N).\n    test_cases = [\n        (1, 0.05, 100),\n        (2, 0.05, 100),\n        (3, 0.05, 100),\n        (3, 1.0, 1000),\n        (2, 0.5, 600),\n        (1, 2.0, 1200),\n    ]\n\n    results = []\n    for case in test_cases:\n        d, h, N = case\n        # For each case, calculate the integral and check the normalization condition.\n        result = calculate_integral_and_check_norm(d, h, N)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # str(True) is 'True', str(False) is 'False', matching problem requirements.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Moving from static properties to dynamics requires computing gradients, which are essential for modeling forces like the pressure gradient. In SPH, these gradients are approximated using the gradient of the smoothing kernel. This practice  focuses on a critical property of the kernel gradient: its anti-symmetry, expressed as $\\nabla_i W_{ij} = -\\nabla_j W_{ji}$. This property is the discrete embodiment of Newton's third law, ensuring that the force particle $i$ exerts on particle $j$ is equal and opposite to the force $j$ exerts on $i$, which is fundamental for conserving linear momentum in a simulation.",
            "id": "3194364",
            "problem": "You are given a two-dimensional Smoothed-Particle Hydrodynamics (SPH) setup where the smoothing kernel depends only on the scalar separation between particles. Starting from the fundamental base that the kernel is a radially symmetric function of the interparticle distance and that gradients follow the chain rule, you must design and implement a numerical test that quantifies, for several particle arrangements, the extent to which the kernel gradient computed with respect to one particle is the negative of the kernel gradient computed with respect to the other particle. Use the following foundations: the Euclidean norm, the chain rule for gradients, and radially symmetric smoothing kernels. Work entirely in two spatial dimensions, with all positions expressed in meters and smoothing lengths expressed in meters. Your outputs must be dimensionless floating-point numbers.\n\nImplement the following in your program:\n\n- Use the standard two-dimensional cubic spline kernel from Smoothed-Particle Hydrodynamics (SPH). The kernel is defined as a function of the separation distance $r$ and smoothing length $h$, with $q = r / h$. The kernel is given by\n$$\nW(r, h) = \\alpha_2 \\times\n\\begin{cases}\n1 - \\tfrac{3}{2} q^2 + \\tfrac{3}{4} q^3, & 0 \\le q < 1, \\\\\n\\tfrac{1}{4} (2 - q)^3, & 1 \\le q < 2, \\\\\n0, & q \\ge 2,\n\\end{cases}\n$$\nwhere\n$$ \\alpha_2 = \\frac{10}{7 \\pi h^2}. $$\nUsing the chain rule and radial symmetry, the magnitude of the gradient factor with respect to $r$ is determined by $\\tfrac{dW}{dr}$, where\n$$\n\\frac{dW}{dr} =\n\\alpha_2 \\times \\frac{1}{h} \\times\n\\begin{cases}\n-3 q + \\tfrac{9}{4} q^2, & 0 \\le q < 1, \\\\\n-\\tfrac{3}{4} (2 - q)^2, & 1 \\le q < 2, \\\\\n0, & q \\ge 2.\n\\end{cases}\n$$\nFor any pair of distinct particle positions $\\mathbf{x}_i$ and $\\mathbf{x}_j$, define the vector separation $\\mathbf{r}_{ij} = \\mathbf{x}_i - \\mathbf{x}_j$, its Euclidean norm $r_{ij} = \\lVert \\mathbf{r}_{ij} \\rVert_2$, and the unit direction $\\hat{\\mathbf{r}}_{ij} = \\mathbf{r}_{ij} / r_{ij}$ for $r_{ij} > 0$. The gradient with respect to particle $\\mathbf{x}_i$ is obtained by scaling $\\hat{\\mathbf{r}}_{ij}$ by $\\tfrac{dW}{dr}$, and the gradient with respect to particle $\\mathbf{x}_j$ is obtained analogously. At $r_{ij} = 0$, define the gradient to be the zero vector.\n\n- For each test case below, compute the maximum relative asymmetry over all unordered particle pairs, defined as\n$$\n\\rho = \\max_{i < j} \\frac{\\left\\lVert \\nabla_{\\mathbf{x}_i} W_{ij} + \\nabla_{\\mathbf{x}_j} W_{ji} \\right\\rVert_2}{\\left\\lVert \\nabla_{\\mathbf{x}_i} W_{ij} \\right\\rVert_2 + \\left\\lVert \\nabla_{\\mathbf{x}_j} W_{ji} \\right\\rVert_2 + \\epsilon},\n$$\nwhere $\\epsilon = 10^{-30}$ is used to avoid division by $0$. Report $\\rho$ as a dimensionless floating-point number for each test case. This metric equals $0$ when the gradients are perfectly anti-symmetric and is small (near machine precision) if numerical computations are consistent with the theoretical property.\n\nTest Suite and parameters:\n\n- Case $1$ (happy path): $N = 20$ points uniformly sampled on $[0, 1] \\times [0, 1]$ meters with pseudorandom seed $123$, smoothing length $h = 0.12$ meters.\n- Case $2$ (colinear symmetry): $N = 8$ points along the $x$-axis at $x$-coordinates $\\{-0.5, -0.25, -0.1, -0.01, 0.01, 0.1, 0.25, 0.5\\}$ meters with $y = 0$ meters, smoothing length $h = 0.10$ meters.\n- Case $3$ (uniform grid): $N = 25$ points on a $5 \\times 5$ uniform grid spanning $[0, 1] \\times [0, 1]$ meters, smoothing length $h = 0.08$ meters.\n- Case $4$ (near-coincident edge): $N = 10$ points created by sampling $5$ base points uniformly on $[0.4, 0.6] \\times [0.4, 0.6]$ meters with pseudorandom seed $321$, then duplicating each with an $x$-offset of $\\delta = 10^{-12}$ meters, smoothing length $h = 0.05$ meters.\n- Case $5$ (anisotropic rectangle): $N = 30$ points uniformly sampled on $[0, 2] \\times [0, 0.1]$ meters with pseudorandom seed $456$, smoothing length $h = 0.20$ meters.\n\nUnits and output:\n\n- All positions are in meters and smoothing lengths are in meters.\n- The reported $\\rho$ values are dimensionless and must be output as decimal floating-point numbers.\n- Your program should produce a single line of output containing the results for the five cases as a comma-separated list enclosed in square brackets, in the order of cases $1$ through $5$, for example, `[r_1, r_2, r_3, r_4, r_5]`.\n\nConstraints and implementation details:\n\n- Use double-precision floating-point arithmetic.\n- Define gradients to be the zero vector when $r_{ij} = 0$ to avoid division by $0$, consistent with radial symmetry.\n- Use the Euclidean two-norm for all vector norms.\n- Make no external assumptions beyond those stated and ensure scientific realism.",
            "solution": "The user has provided a problem in the domain of computational science, specifically concerning Smoothed-Particle Hydrodynamics (SPH). The problem's validity has been confirmed through a rigorous check of its scientific and mathematical foundations, its completeness, and its internal consistency. The problem is well-posed and provides a meaningful numerical task. Therefore, a complete solution is warranted.\n\nThe core of this problem is to numerically test a fundamental property of SPH kernels: the anti-symmetry of the gradient of the smoothing kernel. This property is a direct consequence of the kernel being a radially symmetric function of the distance between two particles. It is essential for ensuring the conservation of linear momentum in SPH simulations, as it effectively embodies Newton's third law for the pairwise particle interactions.\n\nLet us begin by formalizing the theoretical principle. The smoothing kernel $W$ is a function of the positions of two particles, $\\mathbf{x}_i$ and $\\mathbf{x}_j$, through the scalar distance $r_{ij} = \\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert_2$. We denote this as $W_{ij} = W(r_{ij}, h)$, where $h$ is the smoothing length.\n\nThe gradient of the kernel with respect to the coordinates of particle $i$, $\\nabla_{\\mathbf{x}_i} W_{ij}$, can be found using the chain rule:\n$$\n\\nabla_{\\mathbf{x}_i} W_{ij} = \\frac{d W(r_{ij}, h)}{d r_{ij}} \\nabla_{\\mathbf{x}_i} r_{ij}\n$$\nThe gradient of the distance $r_{ij} = \\sqrt{(\\mathbf{x}_i - \\mathbf{x}_j) \\cdot (\\mathbf{x}_i - \\mathbf{x}_j)}$ with respect to $\\mathbf{x}_i$ is the unit vector pointing from $\\mathbf{x}_j$ to $\\mathbf{x}_i$:\n$$\n\\nabla_{\\mathbf{x}_i} r_{ij} = \\frac{\\mathbf{x}_i - \\mathbf{x}_j}{\\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert_2} = \\hat{\\mathbf{r}}_{ij}\n$$\nThus, the gradient of the kernel with respect to $\\mathbf{x}_i$ is:\n$$\n\\nabla_{\\mathbf{x}_i} W_{ij} = \\frac{d W}{d r_{ij}} \\hat{\\mathbf{r}}_{ij}\n$$\n\nThe problem asks us to consider the sum $\\nabla_{\\mathbf{x}_i} W_{ij} + \\nabla_{\\mathbf{x}_j} W_{ji}$. The term $\\nabla_{\\mathbf{x}_j} W_{ji}$ is the gradient of the kernel evaluated for the pair $(j, i)$, taken with respect to the coordinates of particle $j$. Following the same derivation:\n$$\n\\nabla_{\\mathbf{x}_j} W_{ji} = \\frac{d W(r_{ji}, h)}{d r_{ji}} \\nabla_{\\mathbf{x}_j} r_{ji}\n$$\nwhere $r_{ji} = \\lVert \\mathbf{x}_j - \\mathbf{x}_i \\rVert_2$ and the unit vector is $\\hat{\\mathbf{r}}_{ji} = \\frac{\\mathbf{x}_j - \\mathbf{x}_i}{\\lVert \\mathbf{x}_j - \\mathbf{x}_i \\rVert_2}$.\n\nBy the properties of the Euclidean norm and vector subtraction:\n1.  The distances are equal: $r_{ij} = \\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert_2 = \\lVert -(\\mathbf{x}_j - \\mathbf{x}_i) \\rVert_2 = \\lVert \\mathbf{x}_j - \\mathbfx}_i \\rVert_2 = r_{ji}$.\n2.  The unit vectors are anti-parallel: $\\hat{\\mathbf{r}}_{ij} = \\frac{\\mathbf{x}_i - \\mathbf{x}_j}{r_{ij}} = -\\frac{\\mathbf{x}_j - \\mathbf{x}_i}{r_{ji}} = -\\hat{\\mathbf{r}}_{ji}$.\n\nSince $r_{ij} = r_{ji}$, the derivative term $\\frac{dW}{dr}$ is identical for both calculations. Therefore, we have:\n$$\n\\nabla_{\\mathbf{x}_j} W_{ji} = \\frac{d W}{d r_{ij}} (-\\hat{\\mathbf{r}}_{ij}) = - \\left( \\frac{d W}{d r_{ij}} \\hat{\\mathbf{r}}_{ij} \\right) = - \\nabla_{\\mathbf{x}_i} W_{ij}\n$$\nAnalytically, this leads to the exact anti-symmetry property:\n$$\n\\nabla_{\\mathbf{x}_i} W_{ij} + \\nabla_{\\mathbf{x}_j} W_{ji} = \\mathbf{0}\n$$\n\nThe purpose of the numerical test is to verify how well this analytical result holds under finite-precision floating-point arithmetic. The metric $\\rho$ is designed to measure the relative magnitude of the sum of the gradients compared to the sum of their individual magnitudes.\n$$\n\\rho = \\max_{i < j} \\frac{\\left\\lVert \\nabla_{\\mathbf{x}_i} W_{ij} + \\nabla_{\\mathbf{x}_j} W_{ji} \\right\\rVert_2}{\\left\\lVert \\nabla_{\\mathbf{x}_i} W_{ij} \\right\\rVert_2 + \\left\\lVert \\nabla_{\\mathbf{x}_j} W_{ji} \\right\\rVert_2 + \\epsilon}\n$$\nA value of $\\rho = 0$ indicates perfect numerical agreement with the theory, while a small non-zero value would indicate minor deviations due to floating-point representation and arithmetic. The small constant $\\epsilon = 10^{-30}$ ensures numerical stability if both gradients are zero (e.g., for particles outside each other's smoothing radii).\n\nThe algorithm to solve the problem for each test case is as follows:\n1.  Generate the particle positions $(\\mathbf{x}_1, \\ldots, \\mathbf{x}_N)$ according to the specifications of the test case.\n2.  Initialize a variable $\\rho_{\\max} = 0$.\n3.  Iterate through all unique unordered pairs of particles $(i, j)$ where $i < j$.\n4.  For each pair, perform two separate and complete calculations to determine the gradients, thereby allowing for any floating-point inaccuracies to manifest:\n    a. Calculate $\\nabla_{\\mathbf{x}_i} W_{ij}$. This involves computing $\\mathbf{r}_{ij} = \\mathbf{x}_i - \\mathbf{x}_j$, $r_{ij} = \\lVert \\mathbf{r}_{ij} \\rVert_2$, $\\hat{\\mathbf{r}}_{ij} = \\mathbf{r}_{ij} / r_{ij}$, and the derivative magnitude $\\frac{dW}{dr}(r_{ij}, h)$ using the provided piecewise formula for the cubic spline kernel.\n    b. Analogously, calculate $\\nabla_{\\mathbf{x}_j} W_{ji}$ by computing $\\mathbf{r}_{ji} = \\mathbf{x}_j - \\mathbf{x}_i$, $r_{ji} = \\lVert \\mathbf{r}_{ji} \\rVert_2$, and so on.\n5.  If $r_{ij} = 0$, the gradients are defined as the zero vector.\n6.  Compute the per-pair asymmetry $\\rho_{ij}$ using the formula for $\\rho$.\n7.  Update the maximum value: $\\rho_{\\max} = \\max(\\rho_{\\max}, \\rho_{ij})$.\n8.  The final value of $\\rho_{\\max}$ is the result for the test case.\n\nThe five test cases are designed to probe this property under different particle configurations: a general random distribution, a highly symmetric colinear arrangement, a regular grid, a case with nearly coincident particles to test numerical precision, and an anisotropic distribution. This provides a comprehensive test of the SPH gradient formulation's numerical robustness. The implementation will use double-precision floating-point arithmetic as standard in `numpy`.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef dWdr_cubic_spline_2d(r, h):\n    \"\"\"\n    Computes the magnitude of the gradient factor dW/dr for the 2D cubic spline kernel.\n\n    Args:\n        r (float): The scalar separation distance between two particles.\n        h (float): The smoothing length.\n\n    Returns:\n        float: The value of dW/dr.\n    \"\"\"\n    # The problem provides the normalization constant alpha_2.\n    alpha_2 = 10.0 / (7.0 * np.pi * h**2)\n    q = r / h\n\n    # The gradient factor depends on the value of q.\n    if q >= 2.0:\n        # Outside kernel support (compact support radius is 2h)\n        return 0.0\n    elif q >= 1.0:\n        # For 1 <= q < 2\n        factor = -0.75 * (2.0 - q)**2\n    elif q >= 0.0:\n        # For 0 <= q < 1\n        factor = -3.0 * q + (9.0 / 4.0) * q**2\n    else:\n        # This case should not be reached as r is a norm and is non-negative.\n        return 0.0\n    \n    # The full derivative is dW/dr = (1/h) * dW/dq\n    return alpha_2 * factor / h\n\ndef solve():\n    \"\"\"\n    Main function to run the five test cases and compute the maximum relative asymmetry rho.\n    \"\"\"\n    # Epsilon for numerical stability, as specified.\n    epsilon = 1e-30\n    \n    # List of parameters for each test case from the problem statement.\n    test_params = [\n        {'case': 1, 'N': 20, 'h': 0.12, 'seed': 123},\n        {'case': 2, 'N': 8, 'h': 0.10},\n        {'case': 3, 'N': 25, 'h': 0.08},\n        {'case': 4, 'N': 10, 'h': 0.05, 'seed': 321, 'delta': 1e-12},\n        {'case': 5, 'N': 30, 'h': 0.20, 'seed': 456},\n    ]\n\n    results = []\n    \n    # Process each test case.\n    for params in test_params:\n        # Step 1: Generate particle positions based on case-specific rules.\n        if params['case'] == 1:\n            rng = np.random.default_rng(params['seed'])\n            positions = rng.uniform(low=0.0, high=1.0, size=(params['N'], 2))\n        elif params['case'] == 2:\n            x_coords = np.array([-0.5, -0.25, -0.1, -0.01, 0.01, 0.1, 0.25, 0.5])\n            positions = np.zeros((params['N'], 2))\n            positions[:, 0] = x_coords\n        elif params['case'] == 3:\n            grid_points = np.linspace(0.0, 1.0, 5)\n            x, y = np.meshgrid(grid_points, grid_points)\n            positions = np.vstack([x.ravel(), y.ravel()]).T\n        elif params['case'] == 4:\n            rng = np.random.default_rng(params['seed'])\n            num_base_points = params['N'] // 2\n            base_points = rng.uniform(low=0.4, high=0.6, size=(num_base_points, 2))\n            offset_points = base_points.copy()\n            offset_points[:, 0] += params['delta']\n            positions = np.concatenate((base_points, offset_points))\n        elif params['case'] == 5:\n            rng = np.random.default_rng(params['seed'])\n            positions = rng.uniform(low=[0.0, 0.0], high=[2.0, 0.1], size=(params['N'], 2))\n\n        N = params['N']\n        h = params['h']\n        max_rho = 0.0\n\n        # Step 2: Iterate over all unique particle pairs (i, j) with i < j.\n        for i in range(N):\n            for j in range(i + 1, N):\n                # Perform two independent calculations to expose potential floating-point differences.\n                \n                # --- Gradient calculation for Nabla_i(W_ij) ---\n                vec_ij = positions[i] - positions[j]\n                norm_ij = np.linalg.norm(vec_ij)\n\n                if norm_ij == 0.0:\n                    # Gradients are zero vectors by definition for coincident particles. \n                    grad_i_Wij = np.zeros(2)\n                else:\n                    dwdr_val_ij = dWdr_cubic_spline_2d(norm_ij, h)\n                    grad_i_Wij = dwdr_val_ij * vec_ij / norm_ij\n\n                # --- Gradient calculation for Nabla_j(W_ji) ---\n                vec_ji = positions[j] - positions[i]\n                norm_ji = np.linalg.norm(vec_ji)\n                \n                if norm_ji == 0.0:\n                    grad_j_Wji = np.zeros(2)\n                else: \n                    dwdr_val_ji = dWdr_cubic_spline_2d(norm_ji, h)\n                    grad_j_Wji = dwdr_val_ji * vec_ji / norm_ji\n\n                # Step 3: Compute the asymmetry metric rho_ij for the pair.\n                numerator = np.linalg.norm(grad_i_Wij + grad_j_Wji)\n                denominator = np.linalg.norm(grad_i_Wij) + np.linalg.norm(grad_j_Wji) + epsilon\n\n                if denominator > epsilon:\n                    rho_ij = numerator / denominator\n                else: # This occurs if both gradients are zero.\n                    rho_ij = 0.0\n                \n                # Step 4: Update the maximum asymmetry found so far.\n                if rho_ij > max_rho:\n                    max_rho = rho_ij\n        \n        results.append(max_rho)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "With the kernel and its gradient verified, we can now apply the full SPH summation to compute a physical field. This exercise  investigates how the SPH density estimate, $\\rho_i = \\sum_j m_j W_{ij}$, is affected by the spatial arrangement of the particles themselves. By comparing the accuracy of the density calculation for a perfectly ordered lattice against a disordered, \"glass-like\" particle distribution, you will gain practical insight into a key aspect of the method's accuracy. This exploration highlights how particle disorder, while often seen as a source of noise, can actually help avoid the systematic errors inherent in perfectly regular structures.",
            "id": "2439536",
            "problem": "You are asked to quantitatively assess how particle disorder affects the accuracy of the Smoothed Particle Hydrodynamics (SPH) density estimate for a uniform, compressible fluid in two spatial dimensions. Consider a fluid occupying a periodic unit square domain with side length $L=1$ and area $A=L^2=1$. The fluid has constant surface density $\\rho_0=1$ expressed in dimensionless units. The domain is populated by $N$ equal-mass particles at positions $\\{\\mathbf{r}_i\\}_{i=1}^N$ with total mass $M=\\rho_0 A=1$, so each particle has mass $m=M/N=1/N$.\n\nFor any particle $i$, the SPH density estimate is defined by\n$$\n\\rho_i \\equiv \\sum_{j=1}^N m\\, W\\!\\left(\\lVert\\mathbf{r}_i - \\mathbf{r}_j\\rVert_\\mathrm{per},\\, h\\right),\n$$\nwhere $\\lVert\\cdot\\rVert_\\mathrm{per}$ denotes the minimum-image periodic distance on the unit torus and $W(r,h)$ is the standard cubic spline SPH kernel in two spatial dimensions with compact support $2h$ and smoothing length $h$. The smoothing length must be chosen as\n$$\nh = \\eta \\,\\Delta, \\quad \\text{with} \\quad \\Delta = \\sqrt{\\frac{A}{N}} = \\frac{1}{\\sqrt{N}},\n$$\nfor a fixed constant $\\eta=1.2$.\n\nTwo distinct particle arrangements must be considered for each specified value of $N$:\n\n- Lattice arrangement: particles placed on a regular square lattice of size $\\sqrt{N}\\times\\sqrt{N}$ within the unit square with periodic boundaries.\n- Glass-like arrangement: particles placed at the first $N$ points of the two-dimensional Halton sequence with bases $2$ and $3$, i.e., for $k=1,2,\\ldots,N$, the position is $\\mathbf{r}_k=\\big(\\phi_2(k),\\,\\phi_3(k)\\big)$ where $\\phi_b(k)$ is the radical-inverse function in base $b$.\n\nFor each arrangement and for each $N$, compute the following dimensionless error metrics comparing the SPH density estimate $\\{\\rho_i\\}$ to the exact uniform density $\\rho_0$:\n- The mean absolute relative error,\n$$\nE_1 = \\frac{1}{N}\\sum_{i=1}^N \\frac{\\left|\\rho_i-\\rho_0\\right|}{\\rho_0}.\n$$\n- The root-mean-square relative error,\n$$\nE_2 = \\frac{1}{\\sqrt{N}}\\left(\\sum_{i=1}^N \\left(\\frac{\\rho_i-\\rho_0}{\\rho_0}\\right)^2\\right)^{1/2}.\n$$\n- The maximum relative error,\n$$\nE_\\infty = \\max_{1\\le i\\le N} \\frac{\\left|\\rho_i-\\rho_0\\right|}{\\rho_0}.\n$$\n\nUse strictly dimensionless units throughout, and express all error values as decimal numbers (not as percentages). For each error metric, round the result to six decimal places.\n\nTest Suite:\nEvaluate the triplet $\\big[E_1,E_2,E_\\infty\\big]$ for the following ordered list of test cases, where each case specifies a pair $(N,\\text{arrangement})$:\n- $(N=100, \\text{lattice})$\n- $(N=100, \\text{glass})$\n- $(N=256, \\text{lattice})$\n- $(N=256, \\text{glass})$\n- $(N=441, \\text{lattice})$\n- $(N=441, \\text{glass})$\n\nAdopt the minimum-image periodic distance on the unit square torus for all pairwise separations in the kernel evaluations. For each $N$ in the lattice arrangement, assume $N$ is a perfect square so that the lattice is $\\sqrt{N}\\times\\sqrt{N}$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list of lists, each inner list corresponding to one test case in the specified order and containing the three rounded error values in the order $\\big[E_1,E_2,E_\\infty\\big]$. For example:\n`[[e11,e12,e13],[e21,e22,e23],...]`\nEnsure the numerical values are rounded to six decimal places and there is no additional text beyond this single line. Use dimensionless units for all computations and outputs.",
            "solution": "The problem statement has been validated and is determined to be scientifically sound, well-posed, and complete. It constitutes a standard numerical experiment in the field of computational physics to assess the accuracy of the Smoothed Particle Hydrodynamics (SPH) method. The task is to compute density errors for two-dimensional particle distributions. A direct computational approach will be employed as follows.\n\nThe core of the SPH methodology is the representation of a continuous field $A(\\mathbf{r})$ by a summation over a set of discrete particles. For the density field $\\rho$, this is expressed as:\n$$\n\\rho(\\mathbf{r}) = \\sum_{j} m_j W\\left(\\lVert\\mathbf{r} - \\mathbf{r}_j\\rVert,\\, h\\right)\n$$\nwhere $m_j$ and $\\mathbf{r}_j$ are the mass and position of particle $j$, and $W$ is a smoothing kernel with characteristic width $h$, the smoothing length. The problem specifies the SPH density estimate for a particle $i$ at position $\\mathbf{r}_i$ as:\n$$\n\\rho_i = \\sum_{j=1}^N m\\, W\\!\\left(\\lVert\\mathbf{r}_i - \\mathbf{r}_j\\rVert_\\mathrm{per},\\, h\\right)\n$$\nThe domain is a two-dimensional unit square with periodic boundary conditions, area $A=1$, and total mass $M=1$. The fluid has a constant reference surface density $\\rho_0=1$. For $N$ particles, each thus has mass $m = M/N = 1/N$. The distance $\\lVert\\mathbf{r}_i - \\mathbf{r}_j\\rVert_\\mathrm{per}$ is the minimum-image distance on the unit torus, calculated for a displacement vector $\\Delta\\mathbf{r} = (\\Delta x, \\Delta y)$ as $\\sqrt{(\\Delta x - \\text{round}(\\Delta x))^2 + (\\Delta y - \\text{round}(\\Delta y))^2}$.\n\nThe smoothing length $h$ is coupled to the mean particle separation $\\Delta$. For a two dimensional domain of area $A=1$ with $N$ particles, the mean separation is $\\Delta = \\sqrt{A/N} = 1/\\sqrt{N}$. The smoothing length is set to $h = \\eta \\Delta$, with the constant $\\eta = 1.2$.\n\nThe kernel $W(r, h)$ is the standard cubic spline for two dimensions, which is non-zero only for $r \\le 2h$. Its analytical form is:\n$$\nW(r,h) = \\frac{10}{7\\pi h^2} \\times \\begin{cases} 1 - \\frac{3}{2}q^2 + \\frac{3}{4}q^3 & 0 \\le q  1 \\\\ \\frac{1}{4}(2-q)^3  1 \\le q  2 \\\\ 0  q \\ge 2 \\end{cases}\n$$\nwhere $q = r/h$ is the normalized distance.\n\nThe analysis requires two particle configurations:\n1.  **Lattice arrangement**: Particles are positioned on a uniform $\\sqrt{N} \\times \\sqrt{N}$ grid. The coordinates for a particle $(i,j)$ are taken as $(\\frac{i+0.5}{\\sqrt{N}}, \\frac{j+0.5}{\\sqrt{N}})$ for $i,j \\in \\{0, 1, \\dots, \\sqrt{N}-1\\}$. This ensures the lattice is centered within the unit domain.\n2.  **Glass-like arrangement**: Particles are placed at the first $N$ points of the two-dimensional Halton sequence with bases $2$ and $3$. The position of the $k$-th particle ($k=1, \\dots, N$) is $\\mathbf{r}_k = (\\phi_2(k), \\phi_3(k))$, where $\\phi_b(k)$ is the radical-inverse function in base $b$.\n\nFor each configuration and specified value of $N$, the SPH-estimated densities $\\{\\rho_i\\}_{i=1}^N$ are compared against the exact density $\\rho_0=1$ using three error metrics:\n-   Mean absolute relative error: $E_1 = \\frac{1}{N}\\sum_{i=1}^N |\\rho_i-1|$\n-   Root-mean-square relative error: $E_2 = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N (\\rho_i-1)^2}$\n-   Maximum relative error: $E_\\infty = \\max_{1\\le i\\le N} |\\rho_i-1|$\n\nThe computational procedure is as follows:\n1.  For each test case, specified by $(N, \\text{arrangement})$, the particle positions $\\{\\mathbf{r}_i\\}$ are generated.\n2.  A matrix of pairwise periodic distances, $d_{ij} = \\lVert\\mathbf{r}_i - \\mathbf{r}_j\\rVert_\\mathrm{per}$, is computed for all $i,j \\in \\{1, \\dots, N\\}$. This calculation is vectorized for efficiency.\n3.  The kernel function $W(d_{ij}, h)$ is evaluated for all pairs, creating a matrix of kernel values.\n4.  The density for each particle $\\rho_i$ is computed by summing the $i$-th row of the kernel matrix and multiplying by the particle mass $m=1/N$.\n5.  The error metrics $E_1, E_2, E_\\infty$ are calculated from the vector of computed densities.\n6.  The final error values are rounded to six decimal places as required.\n\nThis entire procedure is implemented in Python using the `numpy` library to handle array operations efficiently.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the SPH density error problem.\n    \"\"\"\n    \n    # Define the problem constants and test cases.\n    RHO_0 = 1.0\n    ETA = 1.2\n    \n    test_cases = [\n        (100, 'lattice'),\n        (100, 'glass'),\n        (256, 'lattice'),\n        (256, 'glass'),\n        (441, 'lattice'),\n        (441, 'glass'),\n    ]\n\n    # --- Helper functions ---\n\n    def radical_inverse(k, base):\n        \"\"\"Computes the radical inverse of k in a given base.\"\"\"\n        inv = 0.0\n        f = 1.0 / base\n        while k  0:\n            inv += (k % base) * f\n            k //= base\n            f /= base\n        return inv\n\n    def generate_lattice(n_particles):\n        \"\"\"Generates particle positions on a regular square lattice.\"\"\"\n        n_side = int(np.sqrt(n_particles))\n        if n_side**2 != n_particles:\n            raise ValueError(\"N must be a perfect square for lattice arrangement\")\n        \n        points = np.zeros((n_particles, 2))\n        dx = 1.0 / n_side\n        \n        idx = 0\n        for i in range(n_side):\n            for j in range(n_side):\n                points[idx, 0] = (i + 0.5) * dx\n                points[idx, 1] = (j + 0.5) * dx\n                idx += 1\n        return points\n\n    def generate_glass(n_particles):\n        \"\"\"Generates particle positions from a Halton sequence.\"\"\"\n        points = np.zeros((n_particles, 2))\n        for k in range(1, n_particles + 1):\n            points[k-1, 0] = radical_inverse(k, 2)\n            points[k-1, 1] = radical_inverse(k, 3)\n        return points\n\n    def W_cubic_spline_vectorized(r, h):\n        \"\"\"Vectorized 2D cubic spline SPH kernel.\"\"\"\n        alpha_d = 10.0 / (7.0 * np.pi * h**2)\n        q = r / h\n        \n        res = np.zeros_like(q)\n        \n        # Condition: 1  q = 2\n        mask1 = (q  1.0)  (q = 2.0)\n        q1 = q[mask1]\n        res[mask1] = alpha_d * 0.25 * (2.0 - q1)**3\n        \n        # Condition: 0 = q = 1\n        mask2 = q = 1.0\n        q2 = q[mask2]\n        res[mask2] = alpha_d * (1.0 - 1.5 * q2**2 + 0.75 * q2**3)\n        \n        return res\n\n    def compute_errors(n_particles, arrangement_type):\n        \"\"\"\n        Computes the SPH density and error metrics for a given configuration.\n        \"\"\"\n        # 1. Set parameters\n        m = 1.0 / n_particles\n        delta = 1.0 / np.sqrt(n_particles)\n        h = ETA * delta\n\n        # 2. Generate particle positions\n        if arrangement_type == 'lattice':\n            positions = generate_lattice(n_particles)\n        elif arrangement_type == 'glass':\n            positions = generate_glass(n_particles)\n        else:\n            raise ValueError(f\"Unknown arrangement type: {arrangement_type}\")\n            \n        # 3. Compute pairwise periodic distances (vectorized)\n        delta_r = positions[:, np.newaxis, :] - positions[np.newaxis, :, :]\n        delta_r -= np.round(delta_r)  # Minimum image convention for unit domain\n        distances = np.linalg.norm(delta_r, axis=2)\n\n        # 4. Evaluate kernel for all pairs\n        kernel_values = W_cubic_spline_vectorized(distances, h)\n\n        # 5. Sum contributions to get densities\n        densities = m * np.sum(kernel_values, axis=1)\n\n        # 6. Compute error metrics\n        relative_errors = (densities - RHO_0) / RHO_0\n        \n        e1 = np.mean(np.abs(relative_errors))\n        e2 = np.sqrt(np.mean(relative_errors**2))\n        e_inf = np.max(np.abs(relative_errors))\n        \n        return [round(e1, 6), round(e2, 6), round(e_inf, 6)]\n\n    # --- Main execution loop ---\n    \n    all_results = []\n    for n, arr_type in test_cases:\n        errors = compute_errors(n, arr_type)\n        all_results.append(errors)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}