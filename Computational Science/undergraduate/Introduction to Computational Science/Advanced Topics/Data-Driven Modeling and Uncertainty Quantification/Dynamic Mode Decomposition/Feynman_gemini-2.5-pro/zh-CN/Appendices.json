{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握一个计算方法，最好的方式是从一个理想化的“基准”案例开始。这个练习旨在验证动态模式分解 (DMD) 的一个核心理论承诺：当数据由一个无噪声的线性动力系统生成时，DMD 能够精确地重构出该系统的演化算子。通过完成这个练习 ，你将亲手验证 DMD 在完美条件下的能力，为后续处理更复杂的现实世界问题打下坚实的基础。",
            "id": "2387371",
            "problem": "您的任务是评估通过精确动态模态分解 (DMD) 获得的数据驱动线性模型，在应用于由线性、时不变离散时间系统生成的无噪声快照时，是否能达到零重构误差。考虑一个在 $\\mathbb{C}^n$ 中的状态序列 $\\{x_k\\}_{k=0}^{m-1}$，它由递推式 $x_{k+1} = A x_k$ 生成，其中 $A \\in \\mathbb{C}^{n \\times n}$ 是一个常数矩阵。定义快照矩阵 $X_1 = [x_0, x_1, \\dots, x_{m-2}] \\in \\mathbb{C}^{n \\times (m-1)}$ 和 $X_2 = [x_1, x_2, \\dots, x_{m-1}] \\in \\mathbb{C}^{n \\times (m-1)}$。令 $\\widehat{A}$ 表示通过精确动态模态分解从数据对 $(X_1, X_2)$ 中生成的线性算子，其中使用 $X_1$ 的完整数值秩。定义归一化重构误差为\n$$\n\\varepsilon = \\frac{\\lVert X_2 - \\widehat{A} X_1 \\rVert_F}{\\lVert X_2 \\rVert_F},\n$$\n其中 $\\lVert \\cdot \\rVert_F$ 表示弗罗贝尼乌斯范数。如果一个数据集是无噪声的，由如上所述的线性时不变模型生成，并且算子 $\\widehat{A}$ 是使用 $X_1$ 的完整数值秩形成的，那么该数据集就满足精确 DMD 的条件。\n\n通过指定满足这些条件的 $A$、$x_0$ 和 $m$ 来构建三个合成数据集。对于每个数据集，通过 $x_{k+1} = A x_k$ 生成快照 $\\{x_k\\}$，并如上定义形成 $X_1$ 和 $X_2$。对于每个数据集，计算 $\\varepsilon$ 并返回一个布尔值，指示 $\\varepsilon \\leq 10^{-12}$ 是否成立。\n\n您的程序必须为以下测试套件实现此过程。在所有出现复数的情况下，角度均以弧度为单位，并且所有计算都在 $\\mathbb{C}$ 上进行。\n\n测试套件（每个项目符号完全指定一个数据集）：\n\n- 数据集 1（具有实特征值的可对角化矩阵）：\n  - 维度 $n = 3$，快照数量 $m = 6$。\n  - 选择 $W_1 = \\begin{bmatrix} 1  2  0 \\\\ 0  1  1 \\\\ 1  0  1 \\end{bmatrix}$ 和 $\\Lambda_1 = \\mathrm{diag}(0.8,\\, 1.2,\\, -0.5)$，并定义 $A_1 = W_1 \\Lambda_1 W_1^{-1}$。\n  - 初始状态 $x_0^{(1)} = \\begin{bmatrix} 1 \\\\ -1 \\\\ 2 \\end{bmatrix}$。\n\n- 数据集 2（包含一个振荡的复共轭对）：\n  - 维度 $n = 3$，快照数量 $m = 7$。\n  - 选择 $W_2 = I_3$（$3 \\times 3$ 单位矩阵），$\\Lambda_2 = \\mathrm{diag}\\!\\left(\\mathrm{e}^{\\mathrm{i}\\pi/6},\\, \\mathrm{e}^{-\\mathrm{i}\\pi/6},\\, 0.9\\right)$，并定义 $A_2 = \\Lambda_2$。\n  - 初始状态 $x_0^{(2)} = \\begin{bmatrix} 2 \\\\ 1 \\\\ -1 \\end{bmatrix}$。\n\n- 数据集 3（由于未激励的模态导致快照秩亏）：\n  - 维度 $n = 4$，快照数量 $m = 5$。\n  - 选择 $W_3 = I_4$（$4 \\times 4$ 单位矩阵），$\\Lambda_3 = \\mathrm{diag}(0.7,\\, 0.7,\\, 0.3,\\, 1.1)$，并定义 $A_3 = \\Lambda_3$。\n  - 初始状态 $x_0^{(3)} = \\begin{bmatrix} 3 \\\\ -2 \\\\ 0 \\\\ 0 \\end{bmatrix}$。\n\n对于每个数据集，您必须：\n1. 构建 $A$，通过 $x_{k+1} = A x_k$（其中 $k = 0, 1, \\dots, m-2$）生成 $x_k$，并形成 $X_1$ 和 $X_2$。\n2. 通过对 $(X_1, X_2)$ 应用精确动态模态分解，并使用 $X_1$ 的完整数值秩来计算 $\\widehat{A}$。\n3. 如上定义计算 $\\varepsilon$，并将其与 $10^{-12}$ 比较以获得布尔结果。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个数据集对应一个布尔值，顺序与上面给出的一致。例如，一个有效的输出看起来像“[True,True,True]”。",
            "solution": "目标是验证当方法使用数据的完整数值秩时，精确动态模态分解 (DMD) 对由线性时不变系统生成的无噪声快照能够产生零重构误差。数据构建和误差度量规定如下。给定 $A \\in \\mathbb{C}^{n \\times n}$、一个初始状态 $x_0 \\in \\mathbb{C}^n$ 和一个整数 $m \\ge 2$，定义 $x_{k+1} = A x_k$（其中 $k = 0, \\dots, m-2$），并设置\n$$\nX_1 = [x_0, x_1, \\dots, x_{m-2}] \\in \\mathbb{C}^{n \\times (m-1)}, \\quad\nX_2 = [x_1, x_2, \\dots, x_{m-1}] \\in \\mathbb{C}^{n \\times (m-1)}.\n$$\n根据构造，有 $X_2 = A X_1$。\n\n精确 DMD 算子 $\\widehat{A}$ 是 $X_1$ 列空间上的数据驱动线性映射，它将 $X_1$ 中的每个 $x_k$ 映射到 $X_2$ 中的 $x_{k+1}$。为了从数据中构造 $\\widehat{A}$，我们使用 $X_1$ 的奇异值分解 (SVD)。设 $X_1$ 具有（薄）SVD 分解\n$$\nX_1 = U_r S_r V_r^*,\n$$\n其中 $U_r \\in \\mathbb{C}^{n \\times r}$，$S_r \\in \\mathbb{R}^{r \\times r}$ 是对角线元素严格为正的对角矩阵，$V_r \\in \\mathbb{C}^{(m-1) \\times r}$ 具有标准正交列，且 $r = \\mathrm{rank}(X_1)$ 是从奇异值确定的完整数值秩。则精确 DMD 算子定义为\n$$\n\\widehat{A} = X_2 V_r S_r^{-1} U_r^*.\n$$\n我们现在证明，对于无噪声的序列数据，在精确算术中，这个选择保证了零重构误差。\n\n首先，观察到\n$$\n\\widehat{A} X_1 = X_2 V_r S_r^{-1} U_r^* \\, (U_r S_r V_r^*) = X_2 V_r V_r^*.\n$$\n矩阵 $V_r V_r^*$ 是 $\\mathbb{C}^{(m-1) \\times (m-1)}$ 中到 $X_1$ 行空间上的正交投影算子。对于序列化的无噪声数据，有 $X_2 = A X_1$，这意味着 $X_2$ 的行空间包含在 $X_1$ 的行空间内，因为左乘 $A$ 会形成 $X_1$ 各行的线性组合。因此，将 $X_2$ 投影到 $X_1$ 的行空间上会使其保持不变：\n$$\nX_2 V_r V_r^* = X_2.\n$$\n因此，\n$$\n\\widehat{A} X_1 = X_2,\n$$\n这意味着由\n$$\n\\varepsilon = \\frac{\\lVert X_2 - \\widehat{A} X_1 \\rVert_F}{\\lVert X_2 \\rVert_F}\n$$\n定义的重构误差在精确算术中恰好为零。\n\n在有限精度算术中，数值舍入误差会导致一个小的非零值。使用像 $10^{-12}$ 这样的严格容差可以捕捉到这一点并验证理论结果。\n\n接下来，我们证明测试套件中的每个数据集都满足所需条件：\n\n- 数据集 1：$A_1 = W_1 \\Lambda_1 W_1^{-1}$，其中 $W_1$ 可逆，$\\Lambda_1$ 是具有不同实特征值的对角矩阵。这确保了 $A_1$ 是可对角化的。快照是无噪声的，并满足 $X_2 = A_1 X_1$。$X_1$ 的数值秩等于由 $x_0^{(1)}$ 激励的不变子空间的维度，由于 $x_0^{(1)}$ 的选择和不同的特征值，这里的秩将是满秩。\n\n- 数据集 2：$A_2 = \\Lambda_2$，其中 $\\Lambda_2 = \\mathrm{diag}\\!\\left(\\mathrm{e}^{\\mathrm{i}\\pi/6}, \\mathrm{e}^{-\\mathrm{i}\\pi/6}, 0.9\\right)$。这个矩阵在 $\\mathbb{C}$ 上是对角的，因此是可对角化的，它有一个振荡的复共轭特征对和一个实数衰减特征值。快照是无噪声的，并由 $x_{k+1} = A_2 x_k$ 生成，因此 $X_2 = A_2 X_1$。数值秩是从 $X_1$ 的奇异值中检测出来的。\n\n- 数据集 3：$A_3 = \\Lambda_3$，其中 $\\Lambda_3 = \\mathrm{diag}(0.7, 0.7, 0.3, 1.1)$，且 $x_0^{(3)} = [3, -2, 0, 0]^T$。只有前两个特征模态被激励，因此快照位于一个二维不变子空间中，这使得 $X_1$ 是秩亏的（秩等于 $2$），尽管 $n=4$。使用完整数值秩 $r=2$ 构建的精确 DMD 仍然精确地满足 $\\widehat{A} X_1 = X_2$，因为数据保持无噪声，且 $X_2 = A_3 X_1$，$X_2$ 的行空间包含在 $X_1$ 的行空间中。\n\n程序的算法计划：\n1. 对于每个数据集，按规定构建 $A$，迭代生成 $x_k$，并形成 $X_1$ 和 $X_2$。\n2. 计算 $X_1$ 的薄 SVD 以获得 $U, S, V^*$，使用阈值 $S_i > \\tau$ 来确定数值秩 $r$，其中 $\\tau = \\max(n, m-1) \\cdot \\epsilon \\cdot S_1$，$\\epsilon$ 是机器精度。\n3. 截断为 $U_r, S_r, V_r$ 并计算 $\\widehat{A} = X_2 V_r S_r^{-1} U_r^*$。\n4. 计算 $\\varepsilon$ 并与 $10^{-12}$ 比较，为每个数据集生成布尔结果。\n5. 以所需的单行格式输出布尔值列表。\n\n因为这些数据集满足精确 DMD 的条件，所以在所有三种情况下，重构误差都应在指定容差内数值上为零。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef numerical_rank(S, shape, eps=None):\n    \"\"\"\n    Determine the numerical rank based on singular values S and matrix shape.\n    Uses threshold tau = max(shape) * eps * S[0].\n    \"\"\"\n    if eps is None:\n        eps = np.finfo(float).eps\n    if S.size == 0:\n        return 0\n    tau = max(shape) * eps * S[0]\n    return int(np.sum(S > tau))\n\ndef exact_dmd_operator(X1, X2):\n    \"\"\"\n    Compute the exact DMD operator A_hat = X2 V_r S_r^{-1} U_r^* using the full numerical rank.\n    \"\"\"\n    # Compute SVD of X1\n    U, s, Vh = np.linalg.svd(X1, full_matrices=False)\n    # Determine numerical rank\n    r = numerical_rank(s, X1.shape)\n    if r == 0:\n        # Degenerate case: no information\n        return np.zeros((X2.shape[0], X1.shape[0]), dtype=X1.dtype)\n    U_r = U[:, :r]\n    S_r_inv = np.diag(1.0 / s[:r])\n    V_r = Vh.conj().T[:, :r]\n    # Exact DMD operator\n    A_hat = X2 @ V_r @ S_r_inv @ U_r.conj().T\n    return A_hat\n\ndef generate_snapshots(A, x0, m):\n    \"\"\"\n    Generate snapshots x_0, x_1, ..., x_{m-1} using x_{k+1} = A x_k.\n    Returns X1 = [x0 ... x_{m-2}] and X2 = [x1 ... x_{m-1}].\n    \"\"\"\n    n = A.shape[0]\n    X = np.zeros((n, m), dtype=complex)\n    X[:, 0] = x0\n    for k in range(m - 1):\n        X[:, k + 1] = A @ X[:, k]\n    X1 = X[:, :-1]\n    X2 = X[:, 1:]\n    return X1, X2\n\ndef build_dataset_1():\n    # Dataset 1: A = W * Lambda * W^{-1}, real diagonalizable\n    W = np.array([[1, 2, 0],\n                  [0, 1, 1],\n                  [1, 0, 1]], dtype=float)\n    Lambda = np.diag([0.8, 1.2, -0.5])\n    Winv = np.linalg.inv(W)\n    A = (W @ Lambda @ Winv).astype(complex)\n    x0 = np.array([1, -1, 2], dtype=complex)\n    m = 6\n    return A, x0, m\n\ndef build_dataset_2():\n    # Dataset 2: complex conjugate pair and a real eigenvalue\n    lam1 = np.exp(1j * np.pi / 6.0)\n    lam2 = np.exp(-1j * np.pi / 6.0)\n    lam3 = 0.9 + 0j\n    A = np.diag([lam1, lam2, lam3]).astype(complex)\n    x0 = np.array([2, 1, -1], dtype=complex)\n    m = 7\n    return A, x0, m\n\ndef build_dataset_3():\n    # Dataset 3: rank-deficient snapshots (only first two modes excited)\n    A = np.diag([0.7, 0.7, 0.3, 1.1]).astype(complex)\n    x0 = np.array([3, -2, 0, 0], dtype=complex)\n    m = 5\n    return A, x0, m\n\ndef reconstruction_boolean(X1, X2, tol=1e-12):\n    A_hat = exact_dmd_operator(X1, X2)\n    diff = X2 - (A_hat @ X1)\n    num = np.linalg.norm(diff, ord='fro')\n    den = np.linalg.norm(X2, ord='fro')\n    # Handle the degenerate case where X2 is zero matrix\n    rel_err = 0.0 if den == 0.0 else (num / den)\n    return rel_err <= tol\n\ndef solve():\n    # Define the test cases from the problem statement.\n    datasets = [\n        build_dataset_1(),\n        build_dataset_2(),\n        build_dataset_3(),\n    ]\n\n    results = []\n    for A, x0, m in datasets:\n        X1, X2 = generate_snapshots(A, x0, m)\n        results.append(reconstruction_boolean(X1, X2, tol=1e-12))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "在理想情况下验证了 DMD 的准确性之后，我们现在转向更贴近现实的挑战。真实世界的测量数据往往会受到各种伪影的干扰，例如传感器随时间产生的线性漂移。这个练习  将向你展示，即使是这样一个简单的漂移，也可能误导 DMD 识别出一个实际上并不存在的虚假“增长”模式，更重要的是，它将教会你如何通过一种名为“去趋势”的数据预处理技术来消除这种伪影，从而揭示出数据背后真实的动态特性。",
            "id": "3121344",
            "problem": "给定一个离散时间线性时不变系统，其状态维度 $m = 3$，状态转移矩阵 $A \\in \\mathbb{R}^{3 \\times 3}$ 由一个稳定特征值的对角矩阵通过相似变换定义。真实系统根据线性时间步进动力学的基本定义 $x_{k+1} = A x_k$ 演化，并在整数时间索引 $k \\in \\{0,1,\\dots,K\\}$（其中 $K = 200$）处收集了一系列状态快照。真实初始条件为 $x_0 \\in \\mathbb{R}^3$。测量值受到每个传感器恒定的线性漂移（时间斜坡）的干扰，因此测量快照遵循模型 $x_k^{\\text{meas}} = x_k + d\\,k$，其中 $d \\in \\mathbb{R}^3$ 是一个恒定的漂移向量，$k$ 是时间索引。\n\n动态模态分解 (Dynamic Mode Decomposition, DMD) 是一种数据驱动的方法，它通过最小化连续快照之间的最小二乘预测误差来近似一个最佳拟合的线性算子，该算子将一个快照推进到下一个快照，然后分析该算子的特征值。您将研究线性漂移如何引入一个特征值接近 $1$ 的伪模态，以及对时间序列进行去趋势处理如何消除这种人为现象。\n\n请使用以下完全指定且可复现的设置。\n\n- 系统定义：\n  - 设相似矩阵为\n    $$P = \\begin{bmatrix} 1  1  0 \\\\ 0  1  1 \\\\ 1  0  1 \\end{bmatrix}, \\quad P^{-1} \\text{ 是良定义的。}$$\n  - 设特征值对角矩阵为\n    $$\\Lambda = \\operatorname{diag}(0.9,\\,0.8,\\,0.7)。$$\n  - 通过基本关系定义状态转移矩阵\n    $$A = P \\Lambda P^{-1}。$$\n  - 设真实初始条件为\n    $$x_0 = \\begin{bmatrix} 1.2 \\\\ -0.5 \\\\ 0.3 \\end{bmatrix}。$$\n  - 通过迭代基本时间步进规律 $x_{k+1} = A x_k$（其中 $k = 0,1,\\dots,K-1$）生成真实快照，从而形成快照矩阵\n    $$X_{\\text{true}} = \\begin{bmatrix} x_0  x_1  \\cdots  x_K \\end{bmatrix} \\in \\mathbb{R}^{3 \\times (K+1)}。$$\n\n- 漂移模型：\n  - 设漂移方向为固定向量\n    $$v = \\begin{bmatrix} 1.0 \\\\ 0.5 \\\\ -0.25 \\end{bmatrix}。$$\n  - 对于给定的非负标量 $d_{\\text{mag}}$，定义漂移向量为\n    $$d = d_{\\text{mag}}\\, v。$$\n  - 通过模型构建测量快照\n    $$x_k^{\\text{meas}} = x_k + d\\,k,$$\n    并形成\n    $$X_{\\text{meas}} = \\begin{bmatrix} x_0^{\\text{meas}}  x_1^{\\text{meas}}  \\cdots  x_K^{\\text{meas}} \\end{bmatrix}。$$\n\n- DMD 算子和特征值：\n  - 对于任何快照矩阵 $X \\in \\mathbb{R}^{m \\times (K+1)}$，定义配对数据矩阵\n    $$X_- = \\begin{bmatrix} x_0  x_1  \\cdots  x_{K-1} \\end{bmatrix}, \\quad X_+ = \\begin{bmatrix} x_1  x_2  \\cdots  x_K \\end{bmatrix}。$$\n  - 设 $\\widehat{A}$ 表示在最小二乘意义下将 $X_-$ 推进到 $X_+$ 的最佳拟合线性算子。计算 $\\widehat{A}$ 的特征值，并用集合 $\\{\\lambda_j\\}$ 表示。\n  - 定义“接近单位一”的诊断度量为\n    $$r(X) = \\min_j \\left| \\lambda_j - 1 \\right|,$$\n    其中模是 $\\mathbb{C}$ 中的复模。\n\n- 去趋势处理：\n  - 定义逐传感器的最小二乘线性去趋势如下。对于每个传感器（行）$i \\in \\{1,2,3\\}$，拟合直线 $a_i k + b_i$，使得对于该传感器的测量序列 $\\{x_{k,i}^{\\text{meas}}\\}$，在 $k \\in \\{0,1,\\dots,K\\}$ 上的残差平方和最小。从测量序列中减去拟合的趋势，生成去趋势后的快照矩阵 $X_{\\text{detrend}}$。\n\n您的任务：\n\n1.  仅使用提供的定义，实现上述 DMD 流程。具体来说：\n    -   对于每个指定的 $d_{\\text{mag}}$，构建 $A$，生成 $X_{\\text{true}}$，然后生成 $X_{\\text{meas}}$。\n    -   计算 $r(X_{\\text{meas}})$ 和 $r(X_{\\text{detrend}})$。\n2.  从第一性原理出发，解释为什么线性漂移 $x_k^{\\text{meas}} = x_k + d\\,k$ 会在 DMD 谱中引入一个接近 $1$ 的特征值，以及为什么去趋势处理会移除这个伪模态。\n3.  使用第 1 项的结果来评估每个测试用例的以下通过/失败标准。\n\n测试套件（请精确使用这些值）：\n\n- 通用参数：$m = 3$，$K = 200$，$P$，$\\Lambda$，$A$，$x_0$ 和 $v$ 如上定义。\n- 由 $d_{\\text{mag}}$ 指定的测试用例：\n  - 用例 1：$d_{\\text{mag}} = 0.01$。\n  - 用例 2：$d_{\\text{mag}} = 0$。\n  - 用例 3：$d_{\\text{mag}} = 0.05$。\n\n对于每个用例 $i \\in \\{1,2,3\\}$，设 $r_{\\text{before}}^{(i)} = r(X_{\\text{meas}})$ 和 $r_{\\text{after}}^{(i)} = r(X_{\\text{detrend}})$。根据以下规则定义布尔值 $b^{(i)}$：\n\n- 如果 $d_{\\text{mag}} > 0$（存在漂移）：当且仅当 $r_{\\text{before}}^{(i)} < 0.05$，$r_{\\text{after}}^{(i)} \\ge 0.08$ 且 $r_{\\text{after}}^{(i)} - r_{\\text{before}}^{(i)} \\ge 0.02$ 时，$b^{(i)}$ 为真。\n- 如果 $d_{\\text{mag}} = 0$（无漂移）：当且仅当 $r_{\\text{before}}^{(i)} \\ge 0.08$ 且 $r_{\\text{after}}^{(i)} \\ge 0.08$ 时，$b^{(i)}$ 为真。\n\n最终输出规格：\n\n- 您的程序必须生成单行输出，包含以下顺序的 $9$ 个结果：\n  $$\\big[r_{\\text{before}}^{(1)},\\, r_{\\text{after}}^{(1)},\\, b^{(1)},\\, r_{\\text{before}}^{(2)},\\, r_{\\text{after}}^{(2)},\\, b^{(2)},\\, r_{\\text{before}}^{(3)},\\, r_{\\text{after}}^{(3)},\\, b^{(3)}\\big].$$\n- 所有浮点数必须四舍五入到 $6$ 位小数。\n- 输出必须是方括号内以逗号分隔的列表，且没有空格（例如，$\\big[0.012345,0.098765,True,\\dots\\big]$）。\n\n注意：不涉及物理单位。不涉及角度。如果您内部的任何计算产生复数，请按上述规定使用复模计算 $\\left|\\cdot\\right|$，并输出四舍五入到 $6$ 位小数的实数非负距离。",
            "solution": "该问题要求分析动态模态分解 (DMD) 应用于受线性漂移污染的线性时不变 (LTI) 系统数据的情况。我们必须首先从第一性原理出发，解释为什么这种漂移会引入一个特征值接近 $1$ 的伪模态，以及为什么去趋势处理会消除这种人为现象。随后，我们将实现指定的 DMD 流程，以数值方式验证这些原理并评估一组通过/失败标准。\n\n### 理论分析\n\n#### 1. 动态模态分解 (DMD) 框架\n\nDMD 是一种数据驱动的方法，用于寻找一个最佳拟合的线性算子来近似动力学系统的演化。给定一系列状态测量值或“快照” $\\{x_k\\}_{k=0}^K$，我们构建两个数据矩阵：\n$$X_- = \\begin{bmatrix} x_0  x_1  \\cdots  x_{K-1} \\end{bmatrix}, \\quad X_+ = \\begin{bmatrix} x_1  x_2  \\cdots  x_K \\end{bmatrix}$$\nDMD 算法寻求一个矩阵 $\\widehat{A}$，它在最小二乘意义上能最好地将快照在时间上向前传播，即最小化 $\\|X_+ - \\widehat{A} X_-\\|_F^2$，其中 $\\|\\cdot\\|_F$ 是弗罗贝尼乌斯范数。这个优化问题的解由下式给出：\n$$\\widehat{A} = X_+ X_-^{\\dagger}$$\n其中 $X_-^{\\dagger}$ 是 $X_-$ 的 Moore-Penrose 伪逆。然后使用 $\\widehat{A}$ 的特征值和特征向量来表征系统的动力学。\n\n#### 2. 线性漂移引入的伪模态\n\n问题指明，真实系统动力学由 $x_{k+1} = A x_k$ 控制。真实系统矩阵 $A$ 的特征值给定为 $\\Lambda = \\operatorname{diag}(0.9, 0.8, 0.7)$。由于所有特征值的模都小于 $1$，系统是稳定的，状态向量 $x_k$ 随着时间索引 $k \\to \\infty$ 而衰减至零。\n\n然而，测量数据受到线性漂移的污染：\n$$x_k^{\\text{meas}} = x_k + d\\,k$$\n其中 $d$ 是一个恒定的漂移向量。让我们分析这种漂移对 DMD 算法的影响。现在，用于 DMD 的数据矩阵由测量快照构成：\n$$X_{\\text{meas},-} = \\begin{bmatrix} x_0^{\\text{meas}}  \\cdots  x_{K-1}^{\\text{meas}} \\end{bmatrix}, \\quad X_{\\text{meas},+} = \\begin{bmatrix} x_1^{\\text{meas}}  \\cdots  x_K^{\\text{meas}} \\end{bmatrix}$$\n连续测量快照之间的关系是：\n$$x_{k+1}^{\\text{meas}} = x_{k+1} + d(k+1) = A x_k + dk + d$$\nDMD 试图找到一个单一的算子 $\\widehat{A}$，使得 $x_{k+1}^{\\text{meas}} \\approx \\widehat{A} x_k^{\\text{meas}}$。代入测量状态的表达式：\n$$A x_k + dk + d \\approx \\widehat{A} (x_k + dk)$$\n随着 $k$ 变大，真实状态 $x_k$ 衰减至零。然而，漂移项 $dk$ 呈线性增长。因此，对于大的 $k$，动力学由漂移主导，近似变为：\n$$dk + d \\approx \\widehat{A}(dk) \\implies (k+1)d \\approx k \\widehat{A}d$$\n假设 $d \\neq 0$，这意味着 $\\widehat{A}d \\approx \\frac{k+1}{k} d$。DMD 算子 $\\widehat{A}$ 是在整个时间序列上计算出的单个矩阵。最小二乘拟合将受到后期大数值快照的严重影响，在这些快照中，比率 $\\frac{k+1}{k}$ 非常接近 $1$。因此，算法将找到一个算子 $\\widehat{A}$，它有一个与漂移方向 $d$ 紧密对齐的特征向量，其对应的特征值 $\\lambda$ 非常接近 $1$。这就是伪模态的来源，它不反映真实的底层动力学，而是测量的人为现象。因此，当存在漂移时，诊断度量 $r(X_{\\text{meas}}) = \\min_j |\\lambda_j - 1|$ 将接近于零。\n\n#### 3. 通过去趋势处理消除伪模态\n\n线性去趋势旨在识别并移除这种人为现象。对于数据矩阵 $X_{\\text{meas}}$ 的每个传感器（行）$i$，我们执行线性回归以找到一条直线 $y_{k,i} = a_i k + b_i$，该直线能最好地拟合时间序列 $\\{x_{k,i}^{\\text{meas}}\\}_{k=0}^K$。\n传感器 $i$ 的数据为 $x_{k,i}^{\\text{meas}} = x_{k,i} + d_i k$。由于 $x_{k,i}$ 是衰减指数之和，它表现为叠加在线性趋势 $d_i k$ 上的一个瞬态项。对于足够长的时间序列（大的 $K$），最小二乘拟合将精确估计斜率，得到 $a_i \\approx d_i$。截距 $b_i$ 将近似于瞬态部分 $x_{k,i}$ 的平均值。\n\n去趋势后的数据 $x_{k,i}^{\\text{detrend}}$ 是通过减去这个拟合趋势得到的：\n$$x_{k,i}^{\\text{detrend}} = x_{k,i}^{\\text{meas}} - (a_i k + b_i) \\approx (x_{k,i} + d_i k) - (d_i k + b_i) = x_{k,i} - b_i$$\n以向量形式表示，去趋势后的快照矩阵近似为 $X_{\\text{detrend}} \\approx X_{\\text{true}} - \\mathbf{b}\\mathbf{1}^T$，其中 $\\mathbf{b}$ 是截距向量，$\\mathbf{1}^T$ 是一个全为一的行向量。主导的线性漂移已被移除。\n\n当 DMD 应用于去趋势后的数据时，算法不再需要考虑那个伪增长模态。它现在试图建模的动力学是 $x_k^{\\text{detrend}}$ 的动力学，它紧密地遵循真实系统 $x_k$ 的动力学。因此，得到的 DMD 算子 $\\widehat{A}_{\\text{detrend}}$ 的特征值将是对真实系统特征值（$0.9, 0.8, 0.7$）的良好近似。诊断度量 $r(X_{\\text{detrend}})$ 现在将约等于 $\\min(|0.9-1|, |0.8-1|, |0.7-1|) = |0.9-1| = 0.1$。这个值显著大于从原始漂移数据中获得的接近零的值，从而证实了伪模态的移除。\n\n### 实现与验证\n\n任务的计算部分涉及将这些原理转化为代码。\n1.  **系统设置**：状态转移矩阵 $A$ 构建为 $A = P \\Lambda P^{-1}$。\n2.  **快照生成**：通过迭代 $x_{k+1} = A x_k$ 生成真实轨迹 $X_{\\text{true}}$。对于每个测试用例，计算漂移向量 $d=d_{\\text{mag}}v$，并通过将时间斜坡漂移项 $dk$ 添加到每个真实快照 $x_k$ 来形成测量快照矩阵 $X_{\\text{meas}}$。\n3.  **对测量数据进行 DMD**：形成矩阵 $X_{\\text{meas},-}$ 和 $X_{\\text{meas},+}$。使用伪逆计算 DMD 算子 $\\widehat{A}_{\\text{meas}} = X_{\\text{meas},+} X_{\\text{meas},-}^{\\dagger}$，其特征值产生 $r_{\\text{before}} = r(X_{\\text{meas}})$。\n4.  **去趋势处理**：对 $X_{\\text{meas}}$ 的每一行，针对时间索引 $k \\in \\{0, \\dots, K\\}$ 使用最小二乘法拟合一个线性多项式。从每一行中减去得到的线性趋势，生成 $X_{\\text{detrend}}$。\n5.  **对去趋势数据进行 DMD**：将相同的 DMD 过程应用于 $X_{\\text{detrend}}$，以计算 $\\widehat{A}_{\\text{detrend}}$ 并随后计算 $r_{\\text{after}} = r(X_{\\text{detrend}})$。\n6.  **标准评估**：使用为每个测试用例计算的度量 $r_{\\text{before}}$ 和 $r_{\\text{after}}$ 来评估指定的布尔条件。此流程的数值结果应与上述理论分析一致。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the DMD problem with linear drift artifact analysis.\n    \"\"\"\n    \n    # Common parameters\n    m = 3\n    K = 200\n    P = np.array([[1., 1., 0.], [0., 1., 1.], [1., 0., 1.]])\n    Lambda_diag = np.array([0.9, 0.8, 0.7])\n    x0 = np.array([1.2, -0.5, 0.3])\n    v = np.array([1.0, 0.5, -0.25])\n\n    # Test cases specified by d_mag\n    test_cases = [\n        0.01,  # Case 1\n        0.0,   # Case 2\n        0.05,  # Case 3\n    ]\n\n    # --- Step 1: System Definition ---\n    Lambda = np.diag(Lambda_diag)\n    try:\n        P_inv = np.linalg.inv(P)\n    except np.linalg.LinAlgError:\n        # This should not happen given the problem statement, but is good practice.\n        return \"Error: Matrix P is singular.\"\n    A = P @ Lambda @ P_inv\n\n    # --- Step 2: Generate True Snapshots ---\n    X_true = np.zeros((m, K + 1))\n    X_true[:, 0] = x0\n    for k in range(K):\n        X_true[:, k + 1] = A @ X_true[:, k]\n\n    def compute_dmd_and_r(X_snapshots):\n        \"\"\"\n        Computes the DMD operator and the metric r(X).\n        \"\"\"\n        X_minus = X_snapshots[:, :-1]\n        X_plus = X_snapshots[:, 1:]\n        \n        # Compute DMD operator A_hat = X_+ * pinv(X_-)\n        A_hat = X_plus @ np.linalg.pinv(X_minus)\n        \n        # Compute eigenvalues of A_hat\n        eigvals = np.linalg.eigvals(A_hat)\n        \n        # Compute the diagnostic metric r(X)\n        r_val = np.min(np.abs(eigvals - 1.0))\n        return r_val\n\n    def detrend_data(X_snapshots):\n        \"\"\"\n        Performs per-sensor least-squares linear detrending.\n        \"\"\"\n        num_sensors, num_snapshots = X_snapshots.shape\n        X_detrended = np.zeros_like(X_snapshots)\n        time_indices = np.arange(num_snapshots)\n        \n        for i in range(num_sensors):\n            # Fit a line (polynomial of degree 1)\n            coeffs = np.polyfit(time_indices, X_snapshots[i, :], 1)\n            # Construct the trend line\n            trend = coeffs[0] * time_indices + coeffs[1]\n            # Subtract the trend\n            X_detrended[i, :] = X_snapshots[i, :] - trend\n            \n        return X_detrended\n\n    results = []\n    \n    # --- Step 3: Process Each Test Case ---\n    for d_mag in test_cases:\n        # Construct measured snapshots with drift\n        d = d_mag * v\n        time_ramp = np.arange(K + 1)\n        drift_matrix = np.outer(d, time_ramp)\n        X_meas = X_true + drift_matrix\n        \n        # Compute r_before (on measured data)\n        r_before = compute_dmd_and_r(X_meas)\n        \n        # Detrend the data\n        X_detrend = detrend_data(X_meas)\n        \n        # Compute r_after (on detrended data)\n        r_after = compute_dmd_and_r(X_detrend)\n        \n        # Evaluate boolean flag b\n        b = False\n        if d_mag > 0:\n            if r_before < 0.05 and r_after >= 0.08 and (r_after - r_before) >= 0.02:\n                b = True\n        else: # d_mag == 0\n            if r_before >= 0.08 and r_after >= 0.08:\n                b = True\n        \n        # Append results for this case\n        results.append(round(r_before, 6))\n        results.append(round(r_after, 6))\n        results.append(b)\n\n    # --- Final Output Formatting ---\n    # Convert all items to string for joining\n    results_str = [str(item) for item in results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "即使经过了预处理，数据中通常也无法完全消除噪声。最后一个练习将带你深入 DMD 算法的数值核心，探讨如何处理微小噪声可能引发的计算不稳定性问题。我们将通过这个练习  探索在 DMD 计算中，对微小的奇异值求逆会如何放大噪声，从而破坏结果的准确性，并动手实践一种标准的解决方案——奇异值分解截断（SVD truncation），通过这种正则化技术来确保我们获得的动态模式是稳健和可靠的。",
            "id": "3121377",
            "problem": "你的任务是研究动态模态分解 (DMD) 流程中计算奇异值倒数的数值稳定性，并量化截断小奇异值对所计算特征值敏感性的影响。请从适用于计算科学导论课程的基本原理出发：从连续状态快照之间的最小二乘映射开始定义拟合目标，使用奇异值分解 (SVD) 构建伪逆，并论证因对小奇异值求逆而导致的不稳定性。然后，实现一个截断伪逆，将低于截断阈值的倒数置零，并量化当该截断值变化时特征值的敏感性。\n\n构建一个维度为 $n=2$ 的合成离散时间线性系统，其真实线性传播算子为 $A_{\\mathrm{true}} \\in \\mathbb{R}^{2 \\times 2}$，其中\n$$\nA_{\\mathrm{true}}=\\begin{bmatrix}0.96  0\\\\ 0  0.90\\end{bmatrix}.\n$$\n从初始条件\n$$\nx_0=\\begin{bmatrix}1.0\\\\-0.5\\end{bmatrix}\n$$\n通过 $x_{k+1}=A_{\\mathrm{true}}x_k$ 生成一个包含 $m=60$ 个状态快照的序列 $\\{x_k\\}_{k=0}^{m-1}$。\n构建数据矩阵\n$$\nX=[x_0, x_1, \\ldots, x_{m-2}],\\quad Y=[x_1, x_2, \\ldots, x_{m-1}].\n$$\n将 DMD 线性映射 $\\hat{A}$ 解释为最小化 $Y$ 与应用于 $X$ 的线性映射之间残差的弗罗贝尼乌斯范数的最小二乘解。使用奇异值分解来表示 $X$ 的伪逆，并通过截断小奇异值来稳定求逆过程。具体来说，如果 $X=U\\Sigma V^\\top$ 的奇异值为 $\\{\\sigma_i\\}$，则通过仅对满足 $\\sigma_i \\ge \\tau$ 的奇异值求逆，否则将逆值设为 $0$ 的方式来定义截断伪逆。使用此截断伪逆，按照标准投影方法构建降阶 DMD 算子。不要构建或使用任何绕过此推理过程的公式捷径。\n\n为研究敏感性，向 $X$ 和 $Y$ 中添加标准差为 $\\epsilon=10^{-4}$ 的独立同分布高斯测量噪声，以获得含噪数据 $\\tilde{X}$ 和 $\\tilde{Y}$。为保证可复现性，使用固定的随机种子 $s=2024$。对于每个截断阈值 $\\tau$，分别从干净数据和含噪数据中计算 DMD 特征值，并以复平面上两组有限特征值集合之间的对称 Hausdorff 距离作为标量敏感性度量。如果 $S$ 和 $T$ 是两个复数有限集，对称 Hausdorff 距离定义为\n$$\nH(S,T)=\\max\\Big\\{\\max_{z\\in S}\\min_{w\\in T}|z-w|,\\ \\max_{w\\in T}\\min_{z\\in S}|w-z|\\Big\\},\n$$\n并约定如果 $S$ 和 $T$ 均为空集，则 $H(S,T)=0$。\n\n为确保截断阈值覆盖从不截断到过度激进截断的范围，将截断阈值定义为 $X$ 的最大奇异值的倍数。令 $\\sigma_{\\max}$ 表示 $X$ 的最大奇异值。对于每个乘数 $\\alpha$，设置 $\\tau=\\alpha\\,\\sigma_{\\max}$。你的测试套件是以下乘数集合\n$$\n\\alpha \\in \\{0,\\ 10^{-8},\\ 10^{-2},\\ 2\\}.\n$$\n这包括理想情况（接近零的截断）、适度截断以及一个 $\\tau$ 大于 $\\sigma_{\\max}$ 的边界情况。\n\n程序要求：\n- 根据上述描述，基于最小二乘公式和奇异值分解实现 DMD 流程。\n- 通过将低于截断阈值 $\\tau$ 的奇异值的倒数置零来实现截断伪逆。\n- 对于每个 $\\tau$，为干净数据集和含噪数据集计算 DMD 特征值，然后计算两组特征值集合之间的对称 Hausdorff 距离 $H$。\n- 对于测试套件中的每个 $\\alpha$，报告一个浮点数敏感性值 $H$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果顺序与所提供的 $\\alpha$ 值顺序相同，每个浮点数四舍五入到恰好 $6$ 位小数（例如，$[0.123456,0.000001,0.314159,2.718282]$）。\n- 不应产生任何其他输出。\n\n如果在你的实现中出现角度，则无需报告；不要报告角度。所有量在内部都是无单位的实数或复数；最终报告的值是根据 $H$ 定义的无单位实数。",
            "solution": "该问题要求研究动态模态分解 (DMD) 方法的数值稳定性，特别关注截断小奇异值的影响。解决方案将从基本原理构建，首先将 DMD 表述为一个最小二乘问题，最终通过一个数值实验来量化在不同截断水平下特征值对噪声的敏感性。\n\n### 1. 作为最小二乘问题的动态模态分解\n\n动态模态分解旨在寻找一个线性算子 $\\hat{A}$，以最佳方式逼近一系列状态快照的演化。给定两个数据矩阵，$X = [x_0, x_1, \\ldots, x_{m-2}]$ 和 $Y = [x_1, x_2, \\ldots, x_{m-1}]$，其中每个 $x_k \\in \\mathbb{R}^n$ 是一个状态向量，我们假设存在线性关系 $Y \\approx \\hat{A}X$。最优算子 $\\hat{A}$ 通过最小化残差的弗罗贝尼乌斯范数来找到，这等同于在最小二乘意义下求解线性矩阵方程：\n$$\n\\min_{\\hat{A} \\in \\mathbb{R}^{n \\times n}} \\|Y - \\hat{A}X\\|_F^2\n$$\n该问题的解由 $\\hat{A} = YX^+$ 给出，其中 $X^+$ 是 $X$ 的 Moore-Penrose 伪逆。$\\hat{A}$ 的特征值和特征向量分别称为 DMD 特征值和 DMD 模态。\n\n### 2. 基于 SVD 的截断伪逆\n\n如果矩阵 $X$ 是病态的（即其条件数，即最大奇异值与最小奇异值之比，非常大），直接计算伪逆可能在数值上不稳定。在实践中，病态问题通常源于快照数据中的线性相关或近似线性相关，或源于测量噪声。奇异值分解 (SVD) 提供了一种计算伪逆的稳健方法，以及一种正则化该问题的机制。\n\n设 $X \\in \\mathbb{R}^{n \\times (m-1)}$ 的 SVD 为：\n$$\nX = U\\Sigma V^\\top\n$$\n其中 $U \\in \\mathbb{R}^{n \\times p}$、$\\Sigma \\in \\mathbb{R}^{p \\times p}$ 和 $V \\in \\mathbb{R}^{(m-1) \\times p}$ 是截断 SVD 矩阵，其中 $p = \\min(n, m-1)$。$U$ 和 $V$ 的列是标准正交的（$U^\\top U = I$，$V^\\top V = I$），而 $\\Sigma$ 是一个包含奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge \\ldots \\ge \\sigma_p \\ge 0$ 的对角矩阵。\n\n标准伪逆是 $X^+ = V\\Sigma^{-1}U^\\top$，其中 $\\Sigma^{-1}$ 是一个对角矩阵，其元素为 $1/\\sigma_i$。当对非常小的奇异值 $\\sigma_i$ 求逆时，会出现数值不稳定性，因为这会放大其对应的模态，而这些模态通常与噪声相关。\n\n为了稳定计算，我们引入一个截断伪逆 $X^+_\\tau$。通过只考虑达到或超过阈值 $\\tau$ 的奇异值 $\\sigma_i$ 来形成一个秩-r 近似：\n$$\nr = |\\{i \\mid \\sigma_i \\ge \\tau \\}|\n$$\n截断后的 SVD 矩阵为 $U_r \\in \\mathbb{R}^{n \\times r}$、$\\Sigma_r \\in \\mathbb{R}^{r \\times r}$ 和 $V_r \\in \\mathbb{R}^{(m-1) \\times r}$。然后，截断伪逆定义为：\n$$\nX^+_\\tau = V_r \\Sigma_r^{-1} U_r^\\top\n$$\n这有效地滤除了与低于 $\\tau$ 的奇异值相关的模态。\n\n### 3. 降阶 DMD 算子\n\n完整的 DMD 算子 $\\hat{A} = YX^+_\\tau$ 是一个 $n \\times n$ 的矩阵，可能很大。一种计算效率更高的方法是构建一个降阶算子 $\\tilde{A}$，它能捕捉主导子空间上的基本动力学。动力学被投影到由 $U_r$ 的列（通常称为本征正交分解 (POD) 模态）张成的子空间上。降阶算子 $\\tilde{A}$ 是 $\\hat{A}$ 在 $U_r$ 基下的表示：\n$$\n\\tilde{A} = U_r^\\top \\hat{A} U_r = U_r^\\top (Y X^+_\\tau) U_r\n$$\n代入 $X^+_\\tau$ 的表达式：\n$$\n\\tilde{A} = U_r^\\top (Y V_r \\Sigma_r^{-1} U_r^\\top) U_r\n$$\n由于 $U_r$ 的列是标准正交的（$U_r^\\top U_r = I_r$），表达式简化为：\n$$\n\\tilde{A} = U_r^\\top Y V_r \\Sigma_r^{-1}\n$$\n这个更小的 $r \\times r$ 矩阵 $\\tilde{A}$ 的特征值就是所求的 DMD 特征值。这种表述方式既计算高效，在数值上也更可取。\n\n### 4. 敏感性分析流程\n\n问题的核心是量化当数据被噪声扰动时，$\\tilde{A}$ 的特征值如何随截断阈值 $\\tau$ 的变化而变化。\n\n1.  **数据生成**：从真实的线性系统 $x_{k+1} = A_{\\mathrm{true}}x_k$ 生成一个干净的数据集 $(X, Y)$。\n2.  **噪声注入**：通过向 $X$ 和 $Y$ 添加标准差为 $\\epsilon = 10^{-4}$ 的独立同分布高斯噪声来创建一个含噪数据集 $(\\tilde{X}, \\tilde{Y})$。为了可复现性，使用相同的随机种子 $s=2024$。\n3.  **阈值计算**：截断阈值 $\\tau$ 是相对于*干净*数据矩阵 $X$ 的最大奇异值 $\\sigma_{\\max}$，通过一个乘数 $\\alpha$ 来确定的：$\\tau = \\alpha \\sigma_{\\max}$。\n4.  **特征值计算**：对于每个 $\\tau$，计算两组 DMD 特征值：\n    -   $S_{\\tau}$：来自干净数据 $(X, Y)$ 的特征值，使用 $X$ 的 SVD 和阈值 $\\tau$。\n    -   $T_{\\tau}$：来自含噪数据 $(\\tilde{X}, \\tilde{Y})$ 的特征值，使用 $\\tilde{X}$ 的 SVD 和相同的阈值 $\\tau$。\n5.  **敏感性量化**：每个 $\\tau$ 的敏感性通过两组复特征值集合之间的对称 Hausdorff 距离 $H(S_{\\tau}, T_{\\tau})$ 来衡量。对于有限集 $S$ 和 $T$，其定义为：\n    $$\n    H(S,T)=\\max\\Big\\{\\max_{z\\in S}\\min_{w\\in T}|z-w|,\\ \\max_{w\\in T}\\min_{z\\in S}|w-z|\\Big\\}\n    $$\n\n### 5. 算法实现\n\n对于每个指定的 $\\alpha$ 值，算法按以下步骤进行：\n\n1.  使用给定的 $A_{\\mathrm{true}}$、$x_0$ 和 $m=60$，生成大小为 $2 \\times 59$ 的干净数据矩阵 $X$ 和 $Y$。\n2.  通过添加 $\\epsilon=10^{-4}$ 和种子 $s=2024$ 的高斯噪声，生成含噪数据矩阵 $\\tilde{X}$ 和 $\\tilde{Y}$。\n3.  计算干净矩阵 $X$ 的 SVD，以找到其最大奇异值 $\\sigma_{\\max}$。\n4.  对于每个 $\\alpha \\in \\{0, 10^{-8}, 10^{-2}, 2\\}$：\n    a. 计算截断阈值 $\\tau = \\alpha \\sigma_{\\max}$。\n    b. 通过将降阶DMD算法应用于 $(X, Y)$ 并使用阈值 $\\tau$，计算干净的特征值 $S_\\tau$。此过程包括计算 $X$ 的 SVD，根据 $\\tau$ 截断至秩 $r$，并求出 $\\tilde{A}_{\\mathrm{clean}} = U_r^\\top Y V_r \\Sigma_r^{-1}$ 的特征值。\n    c. 通过将相同算法应用于 $(\\tilde{X}, \\tilde{Y})$ 并使用相同的阈值 $\\tau$，计算含噪的特征值 $T_\\tau$。此过程包括为 $\\tilde{X}$ 计算其特定的模态而进行的 SVD。\n    d. 如果给定数据集的秩 $r$ 为 $0$，则对应的特征值集合为空。\n    e. 计算对称 Hausdorff 距离 $H(S_\\tau, T_\\tau)$。请注意，当 $\\alpha=2$ 时，$\\tau$ 将超过所有奇异值，导致干净和含噪情况下的秩 $r$ 均为 $0$。两个空集之间的距离定义为 $0$。\n5.  收集计算出的距离，并将它们格式化为四舍五入到 $6$ 位小数的逗号分隔列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the DMD pipeline to study eigenvalue sensitivity to noise\n    as a function of singular value truncation.\n    \"\"\"\n    # Define the parameters from the problem statement.\n    A_true = np.array([[0.96, 0.0], [0.0, 0.90]])\n    x0 = np.array([[1.0], [-0.5]])\n    m = 60\n    epsilon = 1e-4\n    seed = 2024\n    alphas = [0.0, 1e-8, 1e-2, 2.0]\n\n    def symmetric_hausdorff(s_set, t_set):\n        \"\"\"\n        Computes the symmetric Hausdorff distance between two sets of complex numbers.\n        \"\"\"\n        s_set = np.asarray(s_set, dtype=np.complex128)\n        t_set = np.asarray(t_set, dtype=np.complex128)\n\n        if s_set.size == 0 and t_set.size == 0:\n            return 0.0\n        \n        # This case (one empty, one not) is not expected for the problem's parameters\n        # but is included for completeness. It represents infinite distance.\n        if s_set.size == 0 or t_set.size == 0:\n            return np.inf\n\n        # Create a matrix of pairwise absolute differences |s_i - t_j|\n        dist_matrix = np.abs(s_set[:, np.newaxis] - t_set[np.newaxis, :])\n\n        # unidirected Hausdorff distance h(S, T) = max_{s in S} min_{t in T} |s-t|\n        h1 = np.max(np.min(dist_matrix, axis=1))\n\n        # unidirected Hausdorff distance h(T, S) = max_{t in T} min_{s in S} |t-s|\n        h2 = np.max(np.min(dist_matrix, axis=0))\n\n        return np.max([h1, h2])\n\n    def compute_dmd_eigs(X_data, Y_data, tau):\n        \"\"\"\n        Computes DMD eigenvalues using a truncated SVD-based pseudoinverse.\n        \"\"\"\n        # Step 1: Compute the SVD of the input data matrix X_data.\n        U, s, Vh = np.linalg.svd(X_data, full_matrices=False)\n\n        # Step 2: Determine the rank for truncation based on the threshold tau.\n        rank = np.sum(s >= tau)\n\n        # If rank is 0, there are no eigenvalues.\n        if rank == 0:\n            return np.array([], dtype=np.complex128)\n\n        # Step 3: Truncate the SVD components.\n        Ur = U[:, :rank]\n        sr = s[:rank]\n        # Vh is V-transpose, so Vhr is the first `rank` rows of Vh.\n        Vhr = Vh[:rank, :]\n        Vr = Vhr.T\n\n        # Step 4: Construct the reduced-order DMD operator A_tilde.\n        # A_tilde = U_r^T * Y * V_r * Sigma_r^{-1}\n        # In code: Ur.T @ Y_data @ Vr @ np.diag(1/sr)\n        A_tilde = (Ur.T @ Y_data @ Vr) @ np.diag(1.0 / sr)\n\n        # Step 5: Compute and return the eigenvalues of A_tilde.\n        eigenvalues = np.linalg.eigvals(A_tilde)\n        return eigenvalues\n\n    # Generate the clean data sequence {x_k} from the true linear system.\n    snapshots = [x0]\n    for _ in range(m - 1):\n        snapshots.append(A_true @ snapshots[-1])\n    \n    # Form the clean data matrices X and Y.\n    all_snapshots = np.hstack(snapshots)\n    X = all_snapshots[:, :-1]\n    Y = all_snapshots[:, 1:]\n\n    # Add i.i.d. Gaussian noise to create the noisy data matrices.\n    rng = np.random.default_rng(seed)\n    noise_X = rng.normal(loc=0.0, scale=epsilon, size=X.shape)\n    noise_Y = rng.normal(loc=0.0, scale=epsilon, size=Y.shape)\n    X_tilde = X + noise_X\n    Y_tilde = Y + noise_Y\n\n    # Compute the maximum singular value of the clean data matrix X for reference.\n    _, s_clean, _ = np.linalg.svd(X, full_matrices=False)\n    sigma_max = s_clean[0]\n\n    # Iterate through the specified alpha values to compute sensitivities.\n    sensitivities = []\n    for alpha in alphas:\n        # Define the truncation cutoff threshold tau.\n        tau = alpha * sigma_max\n\n        # Compute DMD eigenvalues for both the clean and noisy datasets.\n        eigs_clean = compute_dmd_eigs(X, Y, tau)\n        eigs_noisy = compute_dmd_eigs(X_tilde, Y_tilde, tau)\n        \n        # Compute the sensitivity as the symmetric Hausdorff distance.\n        h_dist = symmetric_hausdorff(eigs_clean, eigs_noisy)\n        sensitivities.append(h_dist)\n\n    # Format the results according to the specified output format.\n    formatted_results = [f\"{res:.6f}\" for res in sensitivities]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}