{
    "hands_on_practices": [
        {
            "introduction": "截断奇异值分解（TSVD）正则化的核心在于通过截断奇异值来控制解的稳定性，但这会引入偏差。本练习将通过一个经典的反演问题——数值微分，让您亲手实践并探索这种基本的偏差-方差权衡。您将通过蒙特卡洛模拟，经验性地发现最佳截断水平$k$是如何在解的准确性与抗噪声稳定性之间取得精妙平衡的。",
            "id": "3201027",
            "problem": "考虑一个线性逆问题，其正向算子由一阶导数的有限差分近似构建。设 $n$ 为区间 $[0,1]$ 上的网格点数，均匀间距为 $h = 1/(n-1)$，网格位置为 $t_i = (i-1)h$，其中 $i = 1,2,\\dots,n$。定义一个 $(n-1) \\times n$ 矩阵 $A$，其离散一阶导数模板为\n$$\nA_{i,i} = -\\frac{1}{h}, \\quad A_{i,i+1} = \\frac{1}{h}, \\quad \\text{for } i=1,2,\\dots,n-1,\n$$\n且所有其他项均为零。设真实信号为向量 $x_{\\text{true}} \\in \\mathbb{R}^n$，其分量为\n$$\nx_{\\text{true},i} = \\sin(2\\pi t_i) + 0.1\\, t_i,\n$$\n其中正弦函数使用弧度作为角度单位。观测值由以下模型给出\n$$\nb = A x_{\\text{true}} + \\varepsilon,\n$$\n其中 $\\varepsilon \\in \\mathbb{R}^{n-1}$ 是加性观测噪声，其分量是独立同分布的，均值为零，并具有指定的标准差。\n\n设 $A$ 的奇异值分解 (SVD) 为 $A = U \\Sigma V^T$，其中 $U \\in \\mathbb{R}^{(n-1)\\times(n-1)}$，$V \\in \\mathbb{R}^{n\\times(n-1)}$ 具有标准正交列，$\\Sigma \\in \\mathbb{R}^{(n-1)\\times(n-1)}$ 是对角线上为非负奇异值的对角矩阵。考虑通过仅使用前 $k$ 个奇异三元组得到的截断奇异值分解 (TSVD) 估计量 $x_k$，其中 $k \\in \\{0,1,\\dots,n-1\\}$。\n\n你的任务是实现一个程序，对于下面指定的每个测试用例，构建 $A$ 和 $x_{\\text{true}}$，从具有给定标准差的零均值高斯分布中抽取 $L$ 个独立的噪声实现 $\\varepsilon$，并为每个指定的截断水平 $k$ 计算 TSVD 解 $x_k$。利用这 $L$ 个实现的蒙特卡洛采样，估计：\n1. 偏差平方，定义为\n$$\n\\| \\mathbb{E}[x_k] - x_{\\text{true}} \\|_2^2,\n$$\n其中期望是关于噪声分布计算的。\n2. 方差平方，定义为\n$$\n\\mathbb{E}\\left[ \\| x_k - \\mathbb{E}[x_k] \\|_2^2 \\right].\n$$\n3. 均方误差 (MSE)，定义为偏差平方和方差平方之和。\n\n对于每个测试用例，找出并报告使通过蒙特卡洛样本计算的经验均方误差最小的截断水平 $k$（一个整数）。如果存在相等的情况，选择其中最小的 $k$。为确保可复现性，在为每个测试用例生成噪声之前，使用固定的种子 $0$ 初始化随机数生成器。\n\n测试套件：\n- 案例 1 (一般情况)：$n = 50$，噪声标准差 $= 10^{-2}$，样本数 $L = 400$，候选截断水平 $k \\in \\{0,1,5,10,20,49\\}$。\n- 案例 2 (低噪声边界)：$n = 50$，噪声标准差 $= 10^{-6}$，样本数 $L = 400$，候选截断水平 $k \\in \\{0,1,5,10,20,49\\}$。\n- 案例 3 (高噪声边缘)：$n = 50$，噪声标准差 $= 5\\times 10^{-2}$，样本数 $L = 400$，候选截断水平 $k \\in \\{0,1,5,10,20,49\\}$。\n\n最终输出格式：\n你的程序应生成一行输出，其中包含三个测试用例的最佳截断水平，格式为用方括号括起来的逗号分隔列表，例如 $[k_1,k_2,k_3]$，其中每个 $k_i$ 是对应案例的经验均方误差的整数最小值点。",
            "solution": "我们从线性逆问题 $b = A x_{\\text{true}} + \\varepsilon$ 开始，其中 $A$ 是基于均匀网格构建的离散一阶导数算子。奇异值分解 (SVD) 将 $A$ 分解为 $A = U \\Sigma V^T$，其中 $U$ 和 $V$ 的列是标准正交的，$\\Sigma$ 是对角线上为非负奇异值 $\\sigma_i$ ($i=1,\\dots,n-1$) 的对角矩阵。Moore–Penrose 伪逆对应于使用所有非零奇异值，但这在存在小奇异值时会显著放大噪声。截断奇异值分解 (TSVD) 正则化将求逆过程限制在前 $k$ 个奇异分量上，以引入偏差为代价来换取方差的减小。\n\n根据 SVD，限制在前 $k$ 个右奇异向量张成的空间上的最小二乘解，可以通过将数据投影到前 $k$ 个左奇异向量上并按相应奇异值的倒数进行缩放来构造。具体而言，记 $U_k \\in \\mathbb{R}^{(n-1)\\times k}$ 为 $U$ 的前 $k$ 列，$V_k \\in \\mathbb{R}^{n\\times k}$ 为 $V$ 的前 $k$ 列，$\\Sigma_k \\in \\mathbb{R}^{k \\times k}$ 为前 $k$ 个奇异值构成的对角矩阵，则 TSVD 估计量可以写为\n$$\nx_k = V_k \\Sigma_k^{-1} U_k^T b.\n$$\n代入 $b = A x_{\\text{true}} + \\varepsilon$ 并使用 $A = U \\Sigma V^T$，则 $x_k$ 在噪声上的期望值（其中 $\\mathbb{E}[\\varepsilon] = 0$）为\n$$\n\\mathbb{E}[x_k] = V_k \\Sigma_k^{-1} U_k^T A x_{\\text{true}} = V_k \\Sigma_k^{-1} U_k^T U \\Sigma V^T x_{\\text{true}} = V_k V_k^T x_{\\text{true}}.\n$$\n因此，$\\mathbb{E}[x_k]$ 是 $x_{\\text{true}}$ 在前 $k$ 个右奇异向量张成的空间上的正交投影。偏差平方则为\n$$\n\\| \\mathbb{E}[x_k] - x_{\\text{true}} \\|_2^2 = \\| (I - V_k V_k^T) x_{\\text{true}} \\|_2^2,\n$$\n随着更多分量被截断（即 $k$ 更小），该值会增加。\n\n对于方差，当 $\\varepsilon$ 被建模为具有协方差 $\\sigma^2 I$ 的独立同分布零均值高斯噪声时，我们有波动\n$$\nx_k - \\mathbb{E}[x_k] = V_k \\Sigma_k^{-1} U_k^T \\varepsilon,\n$$\n且 $x_k$ 的协方差为\n$$\n\\operatorname{Cov}(x_k) = V_k \\Sigma_k^{-1} U_k^T (\\sigma^2 I) U_k \\Sigma_k^{-1} V_k^T = \\sigma^2\\, V_k \\Sigma_k^{-2} V_k^T.\n$$\n该偏差的期望平方范数是此协方差矩阵的迹：\n$$\n\\mathbb{E}\\left[ \\| x_k - \\mathbb{E}[x_k] \\|_2^2 \\right] = \\operatorname{trace}\\left( \\operatorname{Cov}(x_k) \\right) = \\sigma^2 \\sum_{i=1}^k \\frac{1}{\\sigma_i^2}.\n$$\n该方差随 $k$ 增大而增大，因为更多的奇异分量，特别是那些具有较小 $\\sigma_i$ 的分量，会加剧噪声放大。\n\n均方误差 (MSE) 可加性地分解为\n$$\n\\operatorname{MSE}(k) = \\| \\mathbb{E}[x_k] - x_{\\text{true}} \\|_2^2 + \\mathbb{E}\\left[ \\| x_k - \\mathbb{E}[x_k] \\|_2^2 \\right].\n$$\n最优截断水平 $k$ 在偏差（随 $k$ 增大而减小）和方差（随 $k$ 增大而增大）之间取得平衡。\n\n为实现每个测试用例的计算，算法步骤如下：\n1. 构建网格 $t_i = (i-1)/(n-1)$，其中 $i=1,\\dots,n$，间距为 $h = 1/(n-1)$。\n2. 使用一阶导数模板项 $A_{i,i}=-1/h$ 和 $A_{i,i+1}=1/h$ 构建矩阵 $A \\in \\mathbb{R}^{(n-1)\\times n}$。\n3. 定义基准真相信号 $x_{\\text{true}} \\in \\mathbb{R}^n$，其分量为 $x_{\\text{true},i}=\\sin(2\\pi t_i) + 0.1 t_i$，正弦函数参数使用弧度。\n4. 计算奇异值分解 $A = U \\Sigma V^T$，其中 $U \\in \\mathbb{R}^{(n-1)\\times(n-1)}$，对角奇异值 $\\sigma_i$ 位于 $\\Sigma$ 中，$V \\in \\mathbb{R}^{n\\times(n-1)}$。\n5. 对于每个候选截断水平 $k$，预计算线性算子 $M_k = V_k \\Sigma_k^{-1} U_k^T$，以便每个 TSVD 解可以通过 $x_k = M_k b$ 获得。\n6. 将随机数生成器初始化为固定种子 $0$。对于 $L$ 次独立试验，抽取高斯噪声 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2 I)$，形成 $b = A x_{\\text{true}} + \\varepsilon$，并对每个 $k$ 计算 $x_k^{(\\ell)} = M_k b$。\n7. 通过计算 $\\| \\bar{x}_k - x_{\\text{true}} \\|_2^2$ 来估计偏差平方，其中 $\\bar{x}_k$ 是样本均值 $\\bar{x}_k = \\frac{1}{L}\\sum_{\\ell=1}^L x_k^{(\\ell)}$。\n8. 通过计算样本平均值 $\\frac{1}{L} \\sum_{\\ell=1}^L \\| x_k^{(\\ell)} - \\bar{x}_k \\|_2^2$ 来估计方差平方。\n9. 将每个 $k$ 的估计偏差平方和方差平方相加，得到经验均方误差。\n10. 选择使经验均方误差最小的 $k$；如果多个 $k$ 值并列，则选择最小的 $k$。\n\n程序对三个指定的测试用例执行这些步骤。最后，它打印一行包含三个选定截断水平的输出，格式为 $[k_1,k_2,k_3]$。这个计算过程展示了截断奇异值分解中固有的偏差-方差权衡：较低的截断水平通过滤除放大噪声的分量来减少方差，但代价是引入偏差；而较高的截断水平会减少偏差，但可能因小奇异值放大噪声而增加方差。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef construct_derivative_matrix(n: int) -> np.ndarray:\n    \"\"\"\n    Construct (n-1) x n first-derivative finite-difference matrix with uniform spacing h.\n    A[i, i] = -1/h, A[i, i+1] = 1/h\n    \"\"\"\n    m = n - 1\n    h = 1.0 / (n - 1)\n    A = np.zeros((m, n), dtype=float)\n    idx = np.arange(m)\n    A[idx, idx] = -1.0 / h\n    A[idx, idx + 1] = 1.0 / h\n    return A\n\ndef construct_true_signal(n: int) -> np.ndarray:\n    \"\"\"\n    Construct x_true on [0,1]: x_true[i] = sin(2*pi*t_i) + 0.1*t_i, radians.\n    \"\"\"\n    t = np.linspace(0.0, 1.0, n)\n    x_true = np.sin(2.0 * np.pi * t) + 0.1 * t\n    return x_true\n\ndef precompute_tsvd_operators(A: np.ndarray, k_list: list[int]):\n    \"\"\"\n    Compute SVD of A and precompute M_k = V_k * Sigma_k^{-1} * U_k^T for all k in k_list.\n    Returns dict mapping k -> M_k.\n    \"\"\"\n    # Economy SVD\n    U, s, Vt = np.linalg.svd(A, full_matrices=False)\n    # Shapes: U (m x m), s (m,), Vt (m x n)\n    U_T = U.T  # (m x m)\n    n = Vt.shape[1]\n    M_ops = {}\n    for k in k_list:\n        if k == 0:\n            # M_0 is the zero operator (n x m)\n            M_ops[k] = np.zeros((n, A.shape[0]), dtype=float)\n            continue\n        # U_k^T: first k rows of U^T (k x m)\n        U_k_T = U_T[:k, :]\n        # V_k: first k rows of Vt, transposed -> (n x k)\n        V_k = Vt[:k, :].T\n        inv_s_k = 1.0 / s[:k]  # (k,)\n        # M_k = V_k @ diag(inv_s_k) @ U_k_T\n        # Implement diag(inv_s_k) @ U_k_T as (inv_s_k[:, None] * U_k_T)\n        M_k = V_k @ (inv_s_k[:, None] * U_k_T)\n        M_ops[k] = M_k\n    return M_ops\n\ndef empirical_bias_variance_mse(A: np.ndarray, x_true: np.ndarray, sigma: float, L: int, k_list: list[int], seed: int = 0):\n    \"\"\"\n    For given A, x_true, noise std sigma, number of samples L, and k_list,\n    compute empirical squared bias, squared variance, and MSE for each k using Monte Carlo.\n    Returns dict k -> (bias_sq, var_sq, mse) and the k minimizing mse (smallest k in case of tie).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    M_ops = precompute_tsvd_operators(A, k_list)\n    m = A.shape[0]\n    # Precompute b0 = A @ x_true\n    b0 = A @ x_true\n\n    # For each k, collect samples of x_k to compute mean and variance efficiently\n    stats = {}\n    # We will store sample means and second moments to avoid keeping all samples\n    # Welford's algorithm for vector means and sum of squared deviations\n    for k in k_list:\n        M_k = M_ops[k]\n        mean = np.zeros_like(x_true)\n        # sum of squared deviations for variance norm (E[||x - mean||^2]) estimation\n        # We'll accumulate sum of ||x - mean||^2 online\n        ssd = 0.0\n        count = 0\n        for _ in range(L):\n            eps = rng.normal(loc=0.0, scale=sigma, size=m)\n            b = b0 + eps\n            x_k = M_k @ b\n            count += 1\n            # Online mean update\n            delta = x_k - mean\n            mean += delta / count\n            # Online sum of squared deviations (Welford's/Chan's update for sum of squares of deviations)\n            ssd += np.dot(delta, x_k - mean)\n        # Bias squared\n        bias_sq = float(np.dot(mean - x_true, mean - x_true))\n        # Variance squared: average squared deviation norm\n        var_sq = float(ssd / L)\n        mse = bias_sq + var_sq\n        stats[k] = (bias_sq, var_sq, mse)\n\n    # Find k minimizing mse, tie-breaking by smallest k\n    best_k = None\n    best_mse = float('inf')\n    for k in sorted(k_list):\n        _, _, mse = stats[k]\n        if mse  best_mse:\n            best_mse = mse\n            best_k = k\n\n    return stats, best_k\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Each case: (n, noise_sigma, L, k_list)\n        (50, 1e-2, 400, [0, 1, 5, 10, 20, 49]),\n        (50, 1e-6, 400, [0, 1, 5, 10, 20, 49]),\n        (50, 5e-2, 400, [0, 1, 5, 10, 20, 49]),\n    ]\n\n    results = []\n    for n, sigma, L, k_list in test_cases:\n        A = construct_derivative_matrix(n)\n        x_true = construct_true_signal(n)\n        # Use fixed seed per case for reproducibility as instructed\n        _, best_k = empirical_bias_variance_mse(A, x_true, sigma, L, k_list, seed=0)\n        results.append(best_k)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "随着我们包含更多的奇异值分量（即增大$k$），解可能会变得不稳定。本练习将教您一种实用的诊断技术，通过监测解在奇异向量基下的系数来判断何时发生不稳定。您将实现一个算法来检测“系数尖峰”，这是一种噪声开始主导解的明确信号，从而为您在实践中选择合适的截断水平$k$提供一种具体的方法。",
            "id": "3201000",
            "problem": "给定一个线性反问题族，其模型为 $A x \\approx b$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是病态的，$b \\in \\mathbb{R}^{m}$ 可能被加性噪声污染。考虑使用截断奇异值分解（truncated SVD）作为一种正则化策略。$A$ 的奇异值分解定义为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 的非负对角元（奇异值）满足 $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_n  0$。对于一个截断水平 $k \\in \\{1,2,\\dots,n\\}$，定义截断子空间 $\\mathcal{S}_k = \\mathrm{span}\\{v_1,\\dots,v_k\\}$，其中 $v_i$ 是右奇异向量（$V$ 的列向量），并令 $x_k$ 为 $\\mathcal{S}_k$ 中使残差范数 $\\|A x - b\\|_2$ 在 $x \\in \\mathcal{S}_k$ 上最小的元素。\n\n您的任务是分析当 $k$ 增加时解的路径 $x_k$，特别关注具有大系数的沿 $v_i$ 的分量何时进入解中。$x_k$ 中 $v_i$ 的系数是在基 $\\{v_i\\}$ 下 $x_k$ 展开式的第 $i$ 个条目。对于每个 $i$，将系数大小序列定义为当 $k$ 增长时这些系数的绝对值。在实践中，当 $b$ 包含噪声时，对应于小奇异值的系数可能会变得很大，因为残差分量与左奇异向量对齐，并被 $1/\\sigma_i$ 放大。这种现象与不稳定性的开始有关，并且通常在系数序列中表现为“系数尖峰”。\n\n用纯粹的算法术语定义一个尖峰检测规则如下。令 $c_i$ 表示将截断从 $k=i-1$ 扩展到 $k=i$ 时出现的与 $v_i$ 相关联的系数（因此 $c_i$ 是 $x_i$ 中乘以 $v_i$ 的系数）。设 $p=5$，$\\alpha=3$，$\\beta=2$。令基线为前 $p$ 个绝对系数的均值，即 $\\mathrm{baseline} = \\frac{1}{p} \\sum_{i=1}^{p} |c_i|$。在第一个满足 $|c_i|  \\alpha \\cdot \\mathrm{baseline}$ 和 $|c_i|  \\beta \\cdot |c_{i-1}|$ 的索引 $ip$ 处声明一个尖峰。如果不存在这样的索引，则报告 $-1$。\n\n您的程序必须仅从奇异值分解和限制于子空间的最小二乘最小化的定义出发：\n- 利用 $U$ 和 $V$ 的正交性，通过求解在 $\\mathcal{S}_k$ 上的约束最小二乘问题，推导随着 $k$ 增加而进入 $x_k$ 的系数 $c_i$ 的形式。\n- 实现上述尖峰检测规则，以确定第一个尖峰索引 $k_{\\star}$。\n\n测试套件。实现以下3个测试用例，每个用例都由确定性伪随机构造完全指定。在每个用例中，奇异值是严格递减的，并由确保病态性的一个规划生成。通过显式奇异值分解来构造 $A$：通过对具有给定随机种子的标准正态矩阵应用QR分解来生成独立的类哈尔（Haar-like）正交矩阵 $U$ 和 $V$；定义 $\\Sigma$ 在其对角线上具有指定的奇异值；然后设置 $A = U_{[:,1:n]} \\Sigma V^{\\top}$。通过指定系数 $\\hat{x}_i$ 并在右奇异向量基中设置 $x_{\\mathrm{true}} = V \\hat{x}$ 来构造基准真相，其中 $\\hat{x} = (\\hat{x}_1,\\dots,\\hat{x}_n)^{\\top}$。然后设置 $b = A x_{\\mathrm{true}} + \\varepsilon$，其中噪声向量 $\\varepsilon$ 具有零均值和标准差 $\\sigma_{\\mathrm{noise}}$ 的独立正态分布条目；定义 $\\sigma_{\\mathrm{noise}} = \\mathrm{level} \\cdot \\|A x_{\\mathrm{true}}\\|_2 / \\sqrt{m}$，因此噪声相对于干净数据进行缩放。本问题不使用角度。不涉及物理单位。\n\n- 用例1（正常情况）：$m=50$, $n=40$, 随机种子 $1234$, 奇异值 $\\sigma_i = 10^{-(i-1)/8}$ for $i=1,\\dots,n$, 系数 $\\hat{x}_i = \\exp(-(i-1)/7)$ for $i=1,\\dots,n$, 噪声水平 $\\mathrm{level} = 10^{-3}$。\n- 用例2（边界情况，无噪声）：$m=50$, $n=40$, 随机种子 $2021$, 奇异值 $\\sigma_i = 10^{-(i-1)/8}$, 系数 $\\hat{x}_i = \\exp(-(i-1)/7)$, 噪声水平 $\\mathrm{level} = 0$。\n- 用例3（极端情况，更强的病态性和更多噪声）：$m=80$, $n=60$, 随机种子 $999$, 奇异值 $\\sigma_i = 10^{-(i-1)/6}$, 系数 $\\hat{x}_i = \\exp(-(i-1)/10)$, 噪声水平 $\\mathrm{level} = 2 \\cdot 10^{-2}$。\n\n对于每个用例，计算与增量包含 $v_i$ 相关联的系数序列 $c_i$，并应用 $p=5$, $\\alpha=3$, $\\beta=2$ 的尖峰检测规则。每个用例所需的输出是第一个尖峰出现的整数索引 $k_{\\star}$（对 $i$ 使用基于1的索引）；如果未检测到尖峰，则该用例输出 $-1$。\n\n最终输出格式。您的程序应生成一行输出，其中包含一个逗号分隔的列表，用方括号括起来，按顺序包含三个用例的结果，例如 $[k_1,k_2,k_3]$。不应打印任何额外的文本。",
            "solution": "所提出的问题是有效的。它是一个在计算科学领域中定义明确的任务，基于线性反问题和使用截断奇异值分解（TSVD）进行正则化的既定理论。该问题在科学上是合理的、自洽的、客观的，并为获得唯一解提供了所有必要的数据和算法定义。\n\n问题的核心是确定TSVD解的系数，然后应用一个特定的算法规则来检测噪声引起的不稳定性。我们首先从第一性原理推导这些系数的公式。\n\n问题是找到在给定截断水平 $k$ 下使残差范数最小化的解 $x_k$。解 $x_k$ 被约束在子空间 $\\mathcal{S}_k = \\mathrm{span}\\{v_1, \\dots, v_k\\}$ 中，其中 $v_i$ 是矩阵 $A$ 的右奇异向量。\n$$\nx_k = \\arg\\min_{x \\in \\mathcal{S}_k} \\|A x - b\\|_2^2\n$$\n任何向量 $x \\in \\mathcal{S}_k$ 都可以唯一地表示为标准正交基向量 $\\{v_1, \\dots, v_k\\}$ 的线性组合：\n$$\nx = \\sum_{i=1}^k c_i v_i\n$$\n其中 $c_i$ 是我们需要确定的系数。将此表示代入目标函数中，我们寻求最小化：\n$$\n\\left\\| A \\left(\\sum_{i=1}^k c_i v_i\\right) - b \\right\\|_2^2 = \\left\\| \\left(\\sum_{i=1}^k c_i A v_i\\right) - b \\right\\|_2^2\n$$\n根据奇异值分解的定义 $A = U \\Sigma V^{\\top}$，我们有基本关系 $A v_i = \\sigma_i u_i$ 对于 $i=1, \\dots, n$，其中 $u_i$ 是左奇异向量，$\\sigma_i$ 是奇异值。将此代入表达式中得到：\n$$\n\\left\\| \\left(\\sum_{i=1}^k c_i \\sigma_i u_i\\right) - b \\right\\|_2^2\n$$\n左奇异向量 $\\{u_i\\}_{i=1}^m$ 构成 $\\mathbb{R}^m$ 的一个标准正交基。向量的欧几里得范数的平方是其在任何标准正交基中坐标的平方和。我们可以将范数内的向量 $r = (\\sum_{i=1}^k c_i \\sigma_i u_i) - b$ 在左奇异向量基中表示。$r$ 沿 $u_j$ 的坐标是 $u_j^{\\top} r$。\n因此，范数的平方是：\n$$\n\\|r\\|_2^2 = \\sum_{j=1}^m (u_j^{\\top} r)^2 = \\sum_{j=1}^m \\left( u_j^{\\top} \\left( \\sum_{i=1}^k c_i \\sigma_i u_i \\right) - u_j^{\\top} b \\right)^2\n$$\n利用正交性 $u_j^{\\top} u_i = \\delta_{ij}$（克罗内克δ函数），表达式得以简化。\n对于 $j \\in \\{1, \\dots, k\\}$，项 $u_j^{\\top} (\\sum_{i=1}^k c_i \\sigma_i u_i)$ 变为 $c_j \\sigma_j$。\n对于 $j \\in \\{k+1, \\dots, m\\}$，项 $u_j^{\\top} (\\sum_{i=1}^k c_i \\sigma_i u_i)$ 变为 $0$。\n这使我们可以将对 $j$ 的求和分为两部分：\n$$\n\\|r\\|_2^2 = \\sum_{j=1}^k (c_j \\sigma_j - u_j^{\\top} b)^2 + \\sum_{j=k+1}^m (- u_j^{\\top} b)^2\n$$\n为了关于系数 $\\{c_1, \\dots, c_k\\}$ 最小化此表达式，我们只需要考虑第一个和，因为第二个和与这些系数无关。第一个和是非负项之和。当每个项都单独为零时，该和达到其最小值 $0$。因此，对于每个 $j \\in \\{1, \\dots, k\\}$，我们必须有：\n$$\nc_j \\sigma_j - u_j^{\\top} b = 0\n$$\n解出 $c_j$ 得到TSVD解系数的著名公式：\n$$\nc_j = \\frac{u_j^{\\top} b}{\\sigma_j}\n$$\n问题将 $c_i$ 定义为当截断水平从 $i-1$ 增加到 $i$ 时进入解的系数。我们的推导表明，基向量 $v_i$ 的系数由上述公式给出，并且不依赖于总的截断水平 $k$（只要 $k \\ge i$）。因此，要分析的系数序列就是 $\\{c_i\\}_{i=1}^n$。\n\n确定了系数的形式后，问题的其余部分是算法性的。\n1.  对于每个测试用例，我们从其指定的奇异值分解构造矩阵 $A$。这包括生成随机正交矩阵 $U$ 和 $V$ 以及具有指定奇异值的对角矩阵 $\\Sigma$。矩阵 $A$ 的形式为 $A = U_{econ} \\Sigma_{n \\times n} V^{\\top}$，其中 $U_{econ}$ 由 $U$ 的前 $n$ 列组成。\n2.  在右奇异向量基中构造“真实”解 $x_{\\mathrm{true}}$，并计算“干净”数据向量 $b_{\\mathrm{clean}} = A x_{\\mathrm{true}}$。\n3.  添加噪声以获得最终数据向量 $b = b_{\\mathrm{clean}} + \\varepsilon$，其中噪声标准差相对于干净信号的范数进行缩放。\n4.  使用推导出的公式 $c_i = (u_i^{\\top} b)/\\sigma_i$ 计算 $i=1, \\dots, n$ 的系数 $c_i$。\n5.  将指定的尖峰检测规则应用于绝对系数序列 $|c_i|$。使用参数 $p=5$、$\\alpha=3$ 和 $\\beta=2$，我们从前 $p$ 个系数计算基线：$\\mathrm{baseline} = \\frac{1}{p} \\sum_{i=1}^{p} |c_i|$。然后我们搜索第一个索引 $i  p$，使得 $|c_i|  \\alpha \\cdot \\mathrm{baseline}$ 和 $|c_i|  \\beta \\cdot |c_{i-1}|$ 同时成立。首次出现的基于1的索引即为结果。如果找不到这样的索引，结果为 $-1$。\n\n此过程将为问题陈述中指定的三个测试用例中的每一个实施。",
            "answer": "```python\nimport numpy as np\n\ndef run_case(m, n, seed, sigma_denominator, x_hat_denominator, level, p, alpha, beta):\n    \"\"\"\n    Runs a single test case for spike detection in TSVD.\n\n    Args:\n        m (int): Number of rows for matrix A.\n        n (int): Number of columns for matrix A.\n        seed (int): Random seed for reproducibility.\n        sigma_denominator (float): Denominator in the exponent for singular values.\n        x_hat_denominator (float): Denominator in the exponent for true coefficients.\n        level (float): Relative noise level.\n        p (int): Number of initial coefficients for baseline calculation.\n        alpha (float): Multiplier for the baseline threshold.\n        beta (float): Multiplier for the previous coefficient threshold.\n\n    Returns:\n        int: The 1-based index of the first detected spike, or -1 if no spike is found.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Construct matrices U, Sigma, V\n    # Generate Haar-like orthogonal matrices from QR of standard normal matrices\n    U_full, _ = np.linalg.qr(rng.standard_normal((m, m)))\n    V, _ = np.linalg.qr(rng.standard_normal((n, n)))\n    \n    # Use the economy-size U, which has orthonormal columns\n    U_econ = U_full[:, :n]\n\n    # Singular values (sigma_i = 10**(-(i-1)/C))\n    indices = np.arange(1, n + 1)\n    s_vals = 10.0**(-(indices - 1) / sigma_denominator)\n    Sigma_n = np.diag(s_vals)\n\n    # 2. Construct A, x_true, and b\n    A = U_econ @ Sigma_n @ V.T\n\n    # True solution coefficients in the V basis (x_hat_i = exp(-(i-1)/C))\n    x_hat = np.exp(-(indices - 1) / x_hat_denominator)\n    \n    # True solution vector\n    x_true = V @ x_hat\n\n    # Clean data vector b\n    b_clean = A @ x_true\n\n    # Additive noise\n    if level > 0.0:\n        norm_b_clean = np.linalg.norm(b_clean)\n        sigma_noise = level * norm_b_clean / np.sqrt(m)\n        noise = rng.normal(0.0, sigma_noise, size=m)\n        b = b_clean + noise\n    else:\n        b = b_clean\n\n    # 3. Compute TSVD solution coefficients\n    # c_i = (u_i^T b) / sigma_i\n    uT_b = U_econ.T @ b\n    c = uT_b / s_vals\n    c_abs = np.abs(c)\n\n    # 4. Apply spike detection rule\n    if n = p:\n        return -1\n\n    # Baseline using the first p coefficients (0-indexed to p-1)\n    baseline = np.mean(c_abs[0:p])\n\n    # Search for spike for indices i > p (1-based), which is i >= p (0-based)\n    for i in range(p, n):\n        cond1 = c_abs[i] > alpha * baseline\n        cond2 = c_abs[i] > beta * c_abs[i-1]\n        \n        if cond1 and cond2:\n            return i + 1  # Return 1-based index\n\n    return -1\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Define spike detection parameters\n    p = 5\n    alpha = 3.0\n    beta = 2.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: m=50, n=40, seed=1234, sigma_i=10^-(i-1)/8, x_hat_i=exp(-(i-1)/7), level=1e-3\n        {\"m\": 50, \"n\": 40, \"seed\": 1234, \"sigma_denom\": 8.0, \"x_hat_denom\": 7.0, \"level\": 1e-3},\n        # Case 2: m=50, n=40, seed=2021, sigma_i=10^-(i-1)/8, x_hat_i=exp(-(i-1)/7), level=0\n        {\"m\": 50, \"n\": 40, \"seed\": 2021, \"sigma_denom\": 8.0, \"x_hat_denom\": 7.0, \"level\": 0.0},\n        # Case 3: m=80, n=60, seed=999, sigma_i=10^-(i-1)/6, x_hat_i=exp(-(i-1)/10), level=2e-2\n        {\"m\": 80, \"n\": 60, \"seed\": 999, \"sigma_denom\": 6.0, \"x_hat_denom\": 10.0, \"level\": 2e-2},\n    ]\n\n    results = []\n    for case in test_cases:\n        k_star = run_case(\n            m=case[\"m\"],\n            n=case[\"n\"],\n            seed=case[\"seed\"],\n            sigma_denominator=case[\"sigma_denom\"],\n            x_hat_denominator=case[\"x_hat_denom\"],\n            level=case[\"level\"],\n            p=p,\n            alpha=alpha,\n            beta=beta\n        )\n        results.append(k_star)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "有时，问题的病态性质会因输入数据的尺度不佳而加剧。本练习将引导您探索一种主动提升数值稳定性的策略：预处理。您将研究简单的列缩放如何能显著改善矩阵的奇异谱，进而提升TSVD解的质量，并体会到在应用正则化之前，有时变换问题本身是更有效的途径。",
            "id": "3201033",
            "problem": "给定一系列形式为 $A x \\approx b$ 的线性反问题，其中 $A \\in \\mathbb{R}^{m \\times n}$ 且 $m \\geq n$，$b \\in \\mathbb{R}^{m}$。任务是研究对 $A$ 的列进行缩放如何改变其奇异谱，以及这种变化如何影响通过截断奇异值分解 (TSVD) 获得的解，并提出一个能改善数值稳定性的预处理步骤。你的程序必须仅从核心定义出发，实现以下内容。\n\n允许使用的基本原理：\n- 奇异值分解 (SVD) 的定义：任何实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 都允许分解为 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个对角矩阵，其非负的对角线元素（奇异值）按非递增顺序排列。\n- 最小二乘目标 $\\min_{x} \\|A x - b\\|_{2}$ 及其在 $A$ 具有满列秩时通过 $A$ 的伪逆求解的方法。\n- 当带有噪声的小奇异值在求逆时会放大 $b$ 中的噪声，这一概念为截断提供了动机。\n\n要求的方法：\n1. 实现一个 TSVD 求解器，给定 $A$、$b$ 和截断索引 $k$，通过将解限制在 $A$ 的前 $k$ 个右奇异向量所张成的空间内来计算近似解。除上述定义外，不得假定任何预先推导的公式。\n2. 实现对 $A$ 的列缩放预处理，使用对角矩阵 $D = \\mathrm{diag}(d_{1},\\dots,d_{n})$，其中 $d_{j} = \\max\\{\\|A_{:,j}\\|_{2}, \\delta\\}$，$\\delta  0$ 是一个小的下限参数，以避免除以零。将缩放后的系统定义为 $\\bar{A} = A D^{-1}$，并通过变量替换 $y = D x$ 使得 $\\bar{A} y \\approx b$。通过 TSVD 求解 $y$，然后通过 $x = D^{-1} y$ 恢复 $x$。\n3. 通过谱条件数 $\\kappa(A) = \\sigma_{\\max}(A) / \\sigma_{\\min}(A)$ 来量化缩放对奇异谱的影响，并报告改善因子 $\\kappa(A)/\\kappa(\\bar{A})$。\n4. 通过相对误差 $\\|x_{k} - x_{\\mathrm{true}}\\|_{2} / \\|x_{\\mathrm{true}}\\|_{2}$ 来量化缩放对 TSVD 解质量的影响，分别计算不进行缩放和采用所提出的缩放方法时的误差，并报告缩放是否改善了误差。\n\n测试套件：\n对于下述每个测试用例，构造 $b$ 为 $b = A x_{\\mathrm{true}} + \\eta$，其中 $\\eta$ 是一个给定的固定噪声向量。使用指定的截断索引 $k$。所有用例均使用下限参数 $\\delta = 10^{-12}$。\n\n- 案例 1 (良好缩放的基准)：\n  - $m = 4$, $n = 3$, $k = 2$.\n  - $A_{1}$ 的行向量为 $(1.0, 0.9, -0.3)$, $(0.4, -1.2, 0.5)$, $(-0.7, 0.3, 1.1)$, $(0.6, -0.8, 0.2)$。\n  - $x_{\\mathrm{true},1} = (0.5, -1.0, 0.3)$。\n  - $\\eta_{1} = (10^{-4}, -2 \\cdot 10^{-4}, 1.5 \\cdot 10^{-4}, -10^{-4})$。\n\n- 案例 2 (列尺度严重不平衡)：\n  - $m = 4$, $n = 3$, $k = 2$.\n  - 基础矩阵 $A_{2}^{\\mathrm{base}}$ 的行向量为 $(1.0, 0.0, 0.001)$, $(0.0, 1.0, 0.002)$, $(0.001, 0.002, 1.0)$, $(1.0, -1.0, 0.5)$。\n  - 列缩放向量 $s = (1.0, 10^{-3}, 10^{3})$；构造 $A_{2} = A_{2}^{\\mathrm{base}} \\cdot \\mathrm{diag}(s)$（即，将每列 $j$ 乘以 $s_{j}$）。\n  - $x_{\\mathrm{true},2} = (0.5, -0.3, 0.2)$。\n  - $\\eta_{2} = (0.1, -0.2, 0.15, -0.1)$。\n\n- 案例 3 (近似共线的列)：\n  - $m = 4$, $n = 3$, $k = 2$.\n  - $A_{3}$ 的行向量为 $(1.0, 1.0001, 0.0)$, $(2.0, 2.0002, 0.001)$, $(-1.0, -1.0001, -0.002)$, $(0.5, 0.50005, 0.0005)$。\n  - $x_{\\mathrm{true},3} = (1.0, -1.0, 2.0)$。\n  - $\\eta_{3} = (10^{-4}, -5 \\cdot 10^{-5}, 2 \\cdot 10^{-4}, -1.5 \\cdot 10^{-4})$。\n\n- 案例 4 (近似零列)：\n  - $m = 4$, $n = 3$, $k = 2$.\n  - $A_{4}$ 的行向量为 $(10^{-8}, 1.0, 0.0)$, $(2 \\cdot 10^{-8}, 0.0, 1.0)$, $(-10^{-8}, -1.0, -1.0)$, $(0.0, 0.5, 0.5)$。\n  - $x_{\\mathrm{true},4} = (1.0, 1.0, -1.0)$。\n  - $\\eta_{4} = (10^{-5}, -10^{-5}, 2 \\cdot 10^{-5}, -2 \\cdot 10^{-5})$。\n\n对于每个案例，按顺序计算并汇总以下四个量：\n- 不进行缩放的相对误差 $\\|x_{k}^{\\mathrm{unscaled}} - x_{\\mathrm{true}}\\|_{2} / \\|x_{\\mathrm{true}}\\|_{2}$，浮点数类型。\n- 进行缩放后的相对误差 $\\|x_{k}^{\\mathrm{scaled}} - x_{\\mathrm{true}}\\|_{2} / \\|x_{\\mathrm{true}}\\|_{2}$，浮点数类型。\n- 一个布尔标志，如果缩放后的相对误差严格小于未缩放的相对误差，则为 true，否则为 false。\n- 条件数改善因子 $\\kappa(A)/\\kappa(\\bar{A})$，浮点数类型。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个扁平列表，该列表包含了所有四个案例的结果，按顺序连接，并用方括号括起来，用逗号分隔，即：\n$[e_{1}^{\\mathrm{un}}, e_{1}^{\\mathrm{sc}}, \\mathrm{improve}_{1}, r_{1}, e_{2}^{\\mathrm{un}}, e_{2}^{\\mathrm{sc}}, \\mathrm{improve}_{2}, r_{2}, e_{3}^{\\mathrm{un}}, e_{3}^{\\mathrm{sc}}, \\mathrm{improve}_{3}, r_{3}, e_{4}^{\\mathrm{un}}, e_{4}^{\\mathrm{sc}}, \\mathrm{improve}_{4}, r_{4}]$,\n其中 $e_{i}^{\\mathrm{un}}$ 和 $e_{i}^{\\mathrm{sc}}$ 是浮点数，$\\mathrm{improve}_{i}$ 是布尔值，$r_{i}$ 是浮点数。在打印前将所有浮点数四舍五入到 6 位小数。",
            "solution": "该问题要求实现并分析一个用于求解形式为 $A x \\approx b$ 的线性反问题的截断奇异值分解 (TSVD) 求解器，并评估一种列缩放预处理技术。分析将在几个旨在突显不同数值病态来源的测试用例上进行。\n\n### 1. 截断奇异值分解 (TSVD)\n\n问题在于找到一个解 $x \\in \\mathbb{R}^{n}$，以最小化最小二乘目标函数：\n$$ \\min_{x} \\|A x - b\\|_{2}^{2} $$\n其中 $A \\in \\mathbb{R}^{m \\times n}$ 且 $m \\ge n$，$b \\in \\mathbb{R}^{m}$。矩阵 $A$ 的奇异值分解 (SVD) 为分析和解决此问题提供了一个强大的工具。$A$ 的 SVD 形式如下：\n$$ A = U \\Sigma V^{\\top} $$\n其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个矩形对角矩阵，其对角线上的非负实数 $\\sigma_{1} \\ge \\sigma_{2} \\ge \\dots \\ge \\sigma_{n} \\ge 0$ 是 $A$ 的奇异值。$U$ 的列（表示为 $\\{u_i\\}_{i=1}^m$）和 $V$ 的列（表示为 $\\{v_i\\}_{i=1}^n$）分别称为左奇异向量和右奇异向量。\n\n将 SVD 代入目标函数：\n$$ \\|U \\Sigma V^{\\top} x - b\\|_{2}^{2} $$\n由于 $U$ 是一个正交矩阵，左乘 $U^{\\top}$ 不会改变欧几里得范数，即 $\\|z\\|_2 = \\|U^{\\top}z\\|_2$。因此，我们可以变换目标函数：\n$$ \\|U^{\\top}(U \\Sigma V^{\\top} x - b)\\|_{2}^{2} = \\|\\Sigma V^{\\top} x - U^{\\top} b\\|_{2}^{2} $$\n让我们引入变量替换 $z = V^{\\top} x$。由于 $V$ 是正交的，所以 $x = Vz$。向量 $z$ 表示 $x$ 在由右奇异向量 $\\{v_i\\}$ 构成的基中的坐标。目标函数变为：\n$$ \\|\\Sigma z - c\\|_{2}^{2}, \\quad \\text{其中 } c = U^{\\top} b $$\n将此表达式按其分量展开可得：\n$$ \\sum_{i=1}^{n} (\\sigma_{i} z_{i} - c_{i})^{2} + \\sum_{i=n+1}^{m} c_{i}^{2} $$\n第二项是残差中不可改变的部分。为了最小化总和，我们必须选择 $z_i$ 来最小化第一项和中的每一项。对于非零奇异值 $\\sigma_i  0$，在 $z_{i} = c_{i} / \\sigma_{i}$ 时达到最小值。对于 $\\sigma_i = 0$，任何 $z_i$ 都是一个最小化子，但通常为了得到最小范数解，会选择 $z_i=0$。这就得到了众所周知的伪逆解：\n$$ x = Vz = \\sum_{i=1}^{n} \\frac{c_i}{\\sigma_i} v_i = \\sum_{i=1}^{n} \\frac{u_{i}^{\\top} b}{\\sigma_{i}} v_{i} $$\n其中求和仅限于 $\\sigma_i  0$ 的索引。在不适定问题 (ill-posed problems) 中，某些奇异值 $\\sigma_i$ 非常小（但非零），导致项 $(u_i^\\top b)/\\sigma_i$ 变得非常大。如果数据向量 $b$ 包含噪声，这个小的 $\\sigma_i$ 将会放大在 $u_i$ 方向上的噪声分量，从而破坏解。\n\nTSVD 是一种正则化方法，通过截断求和来解决此问题，从而滤除来自小奇异值的贡献。解被限制在由前 $k$ 个右奇异向量所张成的子空间内，其中 $k$ 是截断索引。TSVD 解 $x_k$ 定义为：\n$$ x_{k} = \\sum_{i=1}^{k} \\frac{u_{i}^{\\top} b}{\\sigma_{i}} v_{i} $$\n这等价于计算 $x_k = A_k^\\dagger b$，其中 $A_k = U_k \\Sigma_k V_k^\\top$ 是 $A$ 的最佳 $k$ 秩逼近。\n\n### 2. 列缩放预处理\n\n如果矩阵 $A$ 的各列范数差异巨大，该矩阵可能是病态的。列缩放是一种旨在缓解此问题的预处理形式。我们定义一个对角缩放矩阵 $D \\in \\mathbb{R}^{n \\times n}$，其对角线元素基于 $A$ 各列的范数：\n$$ D = \\mathrm{diag}(d_{1}, d_{2}, \\dots, d_{n}) \\quad \\text{with} \\quad d_{j} = \\max\\{\\|A_{:,j}\\|_{2}, \\delta\\} $$\n此处，$A_{:,j}$ 是 $A$ 的第 $j$ 列，$\\delta  0$ 是一个小的下限参数，用以防止对任何零列进行除零操作。\n\n然后我们定义一个缩放后的矩阵 $\\bar{A} = A D^{-1}$。原始问题 $Ax \\approx b$ 通过变量替换 $y = D x$（即 $x = D^{-1} y$）进行转换。将此代入问题可得：\n$$ A(D^{-1} y) \\approx b \\implies (A D^{-1}) y \\approx b \\implies \\bar{A} y \\approx b $$\n现在 $\\bar{A}$ 的列已被归一化（其 L2-范数约等于1），这通常会改善系统的条件。解决缩放后问题的步骤如下：\n1.  计算缩放矩阵 $D$ 和缩放后的矩阵 $\\bar{A} = A D^{-1}$。\n2.  使用带有截断参数 $k$ 的 TSVD 求解缩放后的系统 $\\bar{A} y \\approx b$ 以得到 $y_k$。\n$$ y_k = \\sum_{i=1}^{k} \\frac{\\bar{u}_{i}^{\\top} b}{\\bar{\\sigma}_{i}} \\bar{v}_{i} $$\n其中 $\\bar{A} = \\bar{U} \\bar{\\Sigma} \\bar{V}^\\top$ 是缩放后矩阵的 SVD。\n3.  通过逆转变量替换来恢复原始变量 $x$ 的解：$x_{k}^{\\mathrm{scaled}} = D^{-1} y_k$。\n\n### 3. 分析指标\n\n为了评估这种缩放策略的有效性，我们使用两个主要指标：\n\n1.  **谱条件数**：对于一个秩为 $n$ 的 $m \\times n$ 矩阵 $A$，其条件数为 $\\kappa(A) = \\sigma_{1}(A) / \\sigma_{n}(A)$。一个大的条件数表明问题是病态的。我们通过比率 $\\kappa(A)/\\kappa(\\bar{A})$ 来衡量缩放带来的改善。大于 1 的比率表示条件得到了改善。\n\n2.  **相对解误差**：给定真实解 $x_{\\mathrm{true}}$，我们可以使用相对误差来衡量计算出的解 $x_k$ 的准确度：\n$$ E_{\\mathrm{rel}} = \\frac{\\|x_{k} - x_{\\mathrm{true}}\\|_{2}}{\\|x_{\\mathrm{true}}\\|_{2}} $$\n我们将为无缩放的 TSVD 解 ($x_k^{\\mathrm{unscaled}}$) 和来自缩放系统的解 ($x_k^{\\mathrm{scaled}}$) 计算此误差，并进行比较。\n\n通过将此方法应用于指定的测试用例，我们可以系统地研究在不同类型的病态条件下，列缩放如何影响奇异值谱和正则化解的质量。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the results.\n    \"\"\"\n\n    # --- Test Case Definitions ---\n    delta = 1e-12\n\n    # Case 1: Well-scaled baseline\n    A1 = np.array([\n        [1.0, 0.9, -0.3],\n        [0.4, -1.2, 0.5],\n        [-0.7, 0.3, 1.1],\n        [0.6, -0.8, 0.2]\n    ])\n    xtrue1 = np.array([0.5, -1.0, 0.3])\n    eta1 = np.array([1e-4, -2e-4, 1.5e-4, -1e-4])\n    k1 = 2\n\n    # Case 2: Severely unbalanced column scales\n    A2_base = np.array([\n        [1.0, 0.0, 0.001],\n        [0.0, 1.0, 0.002],\n        [0.001, 0.002, 1.0],\n        [1.0, -1.0, 0.5]\n    ])\n    s2 = np.array([1.0, 1e-3, 1e3])\n    A2 = A2_base @ np.diag(s2)\n    xtrue2 = np.array([0.5, -0.3, 0.2])\n    eta2 = np.array([0.1, -0.2, 0.15, -0.1])\n    k2 = 2\n\n    # Case 3: Nearly collinear columns\n    A3 = np.array([\n        [1.0, 1.0001, 0.0],\n        [2.0, 2.0002, 0.001],\n        [-1.0, -1.0001, -0.002],\n        [0.5, 0.50005, 0.0005]\n    ])\n    xtrue3 = np.array([1.0, -1.0, 2.0])\n    eta3 = np.array([1e-4, -5e-5, 2e-4, -1.5e-4])\n    k3 = 2\n\n    # Case 4: Nearly zero column\n    A4 = np.array([\n        [1e-8, 1.0, 0.0],\n        [2e-8, 0.0, 1.0],\n        [-1e-8, -1.0, -1.0],\n        [0.0, 0.5, 0.5]\n    ])\n    xtrue4 = np.array([1.0, 1.0, -1.0])\n    eta4 = np.array([1e-5, -1e-5, 2e-5, -2e-5])\n    k4 = 2\n\n    test_cases = [\n        (A1, xtrue1, eta1, k1),\n        (A2, xtrue2, eta2, k2),\n        (A3, xtrue3, eta3, k3),\n        (A4, xtrue4, eta4, k4),\n    ]\n\n    results = []\n\n    def tsvd_solver(A, b, k):\n        \"\"\"\n        Computes the TSVD solution x_k for A*x = b.\n        x_k = sum_{i=1 to k} (u_i^T * b / s_i) * v_i\n        \"\"\"\n        # We need the \"economy\" SVD where U is m x n\n        U, s, Vt = np.linalg.svd(A, full_matrices=False)\n        \n        # Truncate to k\n        Uk = U[:, :k]\n        sk = s[:k]\n        Vtk = Vt[:k, :]\n\n        # Calculate solution for x_k\n        # compute alpha_i = u_i^T * b / s_i\n        # then x_k = V_k * alpha\n        # V_k = Vtk.T\n        alpha = (Uk.T @ b) / sk\n        x_k = Vtk.T @ alpha\n        return x_k\n\n    for A, xtrue, eta, k in test_cases:\n        m, n = A.shape\n        b = A @ xtrue + eta\n        \n        # --- Unscaled Analysis ---\n        x_unscaled = tsvd_solver(A, b, k)\n        err_unscaled = np.linalg.norm(x_unscaled - xtrue) / np.linalg.norm(xtrue)\n        \n        s_unscaled = np.linalg.svd(A, compute_uv=False)\n        # Assuming rank n, use sigma_n\n        cond_A = s_unscaled[0] / s_unscaled[n-1] if s_unscaled[n-1] > 0 else np.inf\n\n        # --- Scaled Analysis ---\n        col_norms = np.linalg.norm(A, axis=0)\n        d = np.maximum(col_norms, delta)\n        D_inv = np.diag(1.0 / d)\n        \n        A_bar = A @ D_inv\n        \n        y_scaled = tsvd_solver(A_bar, b, k)\n        x_scaled = D_inv @ y_scaled\n        \n        err_scaled = np.linalg.norm(x_scaled - xtrue) / np.linalg.norm(xtrue)\n        \n        s_scaled = np.linalg.svd(A_bar, compute_uv=False)\n        cond_A_bar = s_scaled[0] / s_scaled[n-1] if s_scaled[n-1] > 0 else np.inf\n        \n        # --- Collect Results ---\n        improvement_flag = err_scaled  err_unscaled\n        cond_improvement_factor = cond_A / cond_A_bar if cond_A_bar > 0 else np.inf\n\n        results.extend([\n            round(err_unscaled, 6),\n            round(err_scaled, 6),\n            improvement_flag,\n            round(cond_improvement_factor, 6)\n        ])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}