{
    "hands_on_practices": [
        {
            "introduction": "为了真正掌握集合卡尔曼滤波，理解其循序同化的核心机制至关重要。本练习通过一个假设情景，对比了批处理同化与循序同化策略，旨在揭示观测数据时效性的关键作用。通过计算和比较两种策略下的预报误差，你将亲身体会到为何像EnKF这样的循序方法在持续抑制模型误差增长方面表现优越 。",
            "id": "2382607",
            "problem": "您正在为计算工程中的一维过程监控任务设计一个数据同化方案。系统状态 $x_k$ 在一天内以小时为单位演化，由索引 $k \\in \\{0,1,\\dots,24\\}$ 标记，其中 $k=0$ 对应于协调世界时 (UTC) $00{:}00$。状态遵循一个线性随机模型，并每小时进行一次观测：\n- 状态动力学（随机游走）：$x_{k+1} = x_k + w_k$，其中 $w_k \\sim \\mathcal{N}(0,q)$ 且 $q = 1$。\n- 观测：$y_k = x_k + v_k$，其中 $v_k \\sim \\mathcal{N}(0,r)$ 且 $r = 1$。\n- $k=0$ 时的先验：$x_0 \\sim \\mathcal{N}(\\mu_0,P_0)$，其中 $P_0 = 10$。\n\n假设所有噪声都是相互独立的高斯噪声。考虑两种同化策略，这两种策略在无限集合极限下与线性的高斯 Kalman 滤波及其集合 Kalman 滤波器 (EnKF) 等效：\n\n- 策略 S_b（$00{:}00$ 批处理）：在 $k=0$ 时，您执行一次单一分析，使用当天所有的每小时观测值 $\\{y_0,\\dots,y_{23}\\}$，并将它们全部视为在 $k=0$ 时有效，观测算子为 $H=1$，误差方差为 $r$。在当天剩余时间内不执行进一步的更新；此后，状态不确定性由模型向前传播。\n- 策略 S_s（在有效时间顺序处理）：您在每个小时 $k$ 使用 $y_k$ 执行标准的顺序 Kalman 滤波器（或集合 Kalman 滤波器 (EnKF)）更新，小时之间协方差的时间更新仅由模型给出。\n\n关注在策略 S_s 下，在正午 $k=12$ 时，同化 $y_{12}$ 之前的先验（背景）预报不确定性。对于这些高斯设定，期望均方误差 (MSE) 等于误差方差，关于它的哪个陈述是正确的？\n\nA. 在 S_s 策略下，$k=12$ 时的先验 MSE 约为 $1.62$，而在 S_b 策略下，$k=12$ 时的先验 MSE 约为 $12.04$。\n\nB. 在 S_b 和 S_s 策略下，$k=12$ 时的先验 MSE 是相同的，因为两种策略都可以访问同一组每日观测数据。\n\nC. 在 S_b 策略下，$k=12$ 时的先验 MSE 小于 S_s 策略下的值，因为 S_b 在 $00{:}00$ 使用了更多的观测数据。\n\nD. 在 S_s 策略下，$k=12$ 时的先验 MSE 大于 S_b 策略下的值，因为过程噪声在 $00{:}00$ 和 $12{:}00$ 之间累积。",
            "solution": "问题陈述需经过验证。\n\n**步骤 1：提取已知条件**\n- 系统状态：$x_k$，离散时间索引 $k \\in \\{0,1,\\dots,24\\}$。\n- 状态动力学模型：$x_{k+1} = x_k + w_k$。\n- 过程噪声：$w_k \\sim \\mathcal{N}(0,q)$，方差 $q = 1$。\n- 观测模型：$y_k = x_k + v_k$。\n- 观测噪声：$v_k \\sim \\mathcal{N}(0,r)$，方差 $r = 1$。\n- $k=0$ 时的先验状态：$x_0 \\sim \\mathcal{N}(\\mu_0, P_0)$，方差 $P_0 = 10$。\n- 噪声特性：所有噪声项 $w_k$ 和 $v_k$ 都是相互独立的高斯噪声。\n- 策略 $S_b$：在 $k=0$ 时执行一次单一分析，使用所有观测值 $\\{y_0,\\dots,y_{23}\\}$，如同它们都是对 $x_0$ 的观测，观测算子为 $H=1$，误差方差为 $r=1$。随后，只进行模型传播。\n- 策略 $S_s$：应用标准的顺序 Kalman 滤波器，在每个小时 $k$ 使用观测值 $y_k$ 进行更新。\n- 待求量：时间 $k=12$ 时的先验（背景）预报均方误差 (MSE)，对于这个线性高斯系统，它等于误差方差。\n\n**步骤 2：使用提取的已知条件进行验证**\n-   **科学依据**：该问题描述了一个线性高斯状态空间模型，这是估计理论中的一个经典表示。使用随机游走作为动力学和线性观测是标准做法。Kalman 滤波器以及批处理与顺序估计的概念是数据同化和计算工程中的基本主题。该问题在科学上是合理的。\n-   **适定性**：所有必要的参数（$P_0, q, r$）、模型和同化策略都已明确定义。问题要求一个具体的、可计算的量（$k=12$ 时的先验方差）。可以从给定信息中推导出一个唯一的解。该问题是适定的。\n-   **客观性**：该问题使用精确的数学和技术术语陈述。策略 $S_b$ 中的假设是人为设定的，但为了理论比较的目的，其定义是清晰的。\n\n**步骤 3：结论与行动**\n问题陈述是有效的。可以推导出严谨的解。\n\n**解的推导**\n\n目标是计算两种不同数据同化策略在时间 $k=12$ 时的先验误差方差 (MSE)，分别表示为策略 $S_b$ 的 $P_{12}^b$ 和策略 $S_s$ 的 $P_{12, prior}^s$。\n\n**策略 $S_b$（$00{:}00$ 批处理）的分析**\n\n1.  **$k=0$ 时的分析**：在策略 $S_b$ 下，所有 $24$ 个观测值 $\\{y_0, \\dots, y_{23}\\}$ 被同时用来更新 $k=0$ 时的初始状态估计。问题陈述每个观测被视为 $y_i = x_0 + v_i$。这等同于用 $24$ 个独立的测量值来更新关于 $x_0$ 的先验信念。逆协方差（精度）的贝叶斯更新是可加的。\n    先验精度为 $P_0^{-1} = 10^{-1} = 0.1$。\n    每个观测提供的精度为 $H^T r^{-1} H = 1^T \\cdot 1^{-1} \\cdot 1 = 1$。\n    $k=0$ 时的后验精度，记为 $(P_{0, post}^b)^{-1}$，是先验精度与所有 $24$ 个观测提供的精度之和：\n    $$ (P_{0, post}^b)^{-1} = P_0^{-1} + \\sum_{i=0}^{23} H^T r^{-1} H = 10^{-1} + 24 \\cdot (1) = 0.1 + 24 = 24.1 $$\n    因此，$k=0$ 时的后验方差为：\n    $$ P_{0, post}^b = \\frac{1}{24.1} $$\n\n2.  **传播到 $k=12$**：在初始分析之后，状态不确定性仅根据模型动力学演化。状态传播为 $x_{k+1} = x_k + w_k$。误差协方差传播规则为 $P_{k+1} = P_k + q$。\n    从 $k=0$ 时的分析方差 $P_{0, post}^b$ 开始，我们将方差向前传播 $12$ 步，期间不进行任何进一步的数据同化。\n    $$ P_1^b = P_{0, post}^b + q $$\n    $$ P_2^b = P_1^b + q = P_{0, post}^b + 2q $$\n    通过归纳法，在 $k=12$ 时的方差为：\n    $$ P_{12}^b = P_{0, post}^b + 12q $$\n    代入已知值 $P_{0, post}^b = 1/24.1$ 和 $q=1$：\n    $$ P_{12}^b = \\frac{1}{24.1} + 12 \\approx 0.04149377... + 12 = 12.04149377... $$\n    策略 $S_b$ 在 $k=12$ 时的先验 MSE 约为 $12.04$。\n\n**策略 $S_s$（在有效时间顺序处理）的分析**\n\n1.  **Kalman 滤波器递归**：策略 $S_s$ 采用标准的 Kalman 滤波器。误差方差通过一系列的预报和分析步骤演化。设 $P_{k|k-1}$ 为时间 $k$ 时的先验（预报）方差， $P_{k|k}$ 为时间 $k$ 时的后验（分析）方差。\n    -   预报步骤：$P_{k|k-1} = P_{k-1|k-1} + q$\n    -   分析步骤：$(P_{k|k})^{-1} = (P_{k|k-1})^{-1} + H^T r^{-1} H$。当 $H=1$ 和 $r=1$ 时，这简化为 $(P_{k|k})^{-1} = (P_{k|k-1})^{-1} + 1$。\n\n2.  **稳态分析**：对于具有恒定参数（$q, r, H$）的系统，Kalman 滤波器的方差会收敛到一个稳态。经过几次迭代后，先验方差 $P_{k|k-1}$ 将趋近于一个常数值 $P_{ss, prior}$。我们来计算这个值。\n    在稳态下，$P_{k|k-1} = P_{k-1|k-2} = P_{ss, prior}$ 且 $P_{k|k} = P_{k-1|k-1} = P_{ss, post}$。\n    方程组变为：\n    $$ P_{ss, prior} = P_{ss, post} + q $$\n    $$ (P_{ss, post})^{-1} = (P_{ss, prior})^{-1} + 1 $$\n    将第一个方程代入第二个方程：\n    $$ (P_{ss, prior} - q)^{-1} = (P_{ss, prior})^{-1} + 1 $$\n    设 $P = P_{ss, prior}$。当 $q=1$ 时：\n    $$ \\frac{1}{P-1} = \\frac{1}{P} + 1 = \\frac{1+P}{P} $$\n    $$ P = (P-1)(P+1) = P^2 - 1 $$\n    这导出了一个二次方程：\n    $$ P^2 - P - 1 = 0 $$\n    先验方差 $P$ 的物理上有意义的（正）解是：\n    $$ P = \\frac{-(-1) + \\sqrt{(-1)^2 - 4(1)(-1)}}{2(1)} = \\frac{1 + \\sqrt{1+4}}{2} = \\frac{1+\\sqrt{5}}{2} $$\n    这个值是黄金比例，$\\phi \\approx 1.61803...$。\n\n3.  **收敛性**：初始先验方差为 $P_{0|-1} = P_0 = 10$。Kalman 滤波器递归将从这个初始值迅速收敛到稳态值。\n    -   $P_{0|0}^{-1} = 10^{-1} + 1 = 1.1 \\implies P_{0|0} = 1/1.1 \\approx 0.9091$。\n    -   $P_{1|0} = P_{0|0} + q \\approx 0.9091 + 1 = 1.9091$。\n    -   $P_{2|1} \\approx 1.656$。\n    -   $P_{3|2} \\approx 1.624$。\n    -   $P_{4|3} \\approx 1.619$。\n    收敛速度非常快。到 $k=12$ 时，先验方差 $P_{12|11}$ 在所有实际应用中都等于稳态值。\n    $$ P_{12, prior}^s \\approx \\frac{1+\\sqrt{5}}{2} \\approx 1.618 $$\n    策略 $S_s$ 在 $k=12$ 时的先验 MSE 约为 $1.62$。\n\n**逐项分析**\n\n-   **A. 在 S_s 策略下，$k=12$ 时的先验 MSE 约为 $1.62$，而在 S_b 策略下，$k=12$ 时的先验 MSE 约为 $12.04$。**\n    我们的计算得出 $P_{12, prior}^s \\approx 1.62$ 和 $P_{12}^b \\approx 12.04$。此选项中陈述的值与我们的推导一致。\n    **结论：正确。**\n\n-   **B. 在 S_b 和 S_s 策略下，$k=12$ 时的先验 MSE 是相同的，因为两种策略都可以访问同一组每日观测数据。**\n    我们的计算表明 $12.04 \\neq 1.62$。方差不相同。其推理是有缺陷的；数据同化的时间点至关重要。忽略观测值的时间有效性（如在 $S_b$ 中）并允许过程噪声在没有校正的情况下累积，会导致大得多的误差。\n    **结论：错误。**\n\n-   **C. 在 S_b 策略下，$k=12$ 时的先验 MSE 小于 S_s 策略下的值，因为 S_b 在 $00{:}00$ 使用了更多的观测数据。**\n    我们的计算表明 $P_{12}^b \\approx 12.04$ 而 $P_{12, prior}^s \\approx 1.62$，所以 $P_{12}^b > P_{12, prior}^s$。该陈述的前提是错误的。虽然 $S_b$ 在 $k=0$ 时实现了非常低的初始方差，但随后 $12$ 小时内由过程噪声（$12q = 12$）引起的未经校正的误差增长完全抵消了这种初始精度。\n    **结论：错误。**\n\n-   **D. 在 S_s 策略下，$k=12$ 时的先验 MSE 大于 S_b 策略下的值，因为过程噪声在 $00{:}00$ 和 $12{:}00$ 之间累积。**\n    我们的计算表明 $P_{12, prior}^s  P_{12}^b$。该陈述的前提是错误的。过程噪声在两种情况下都会累积，但在 $S_s$ 中，其影响被每小时的观测持续缓解，从而导致一个有界的、较低的误差方差。在 $S_b$ 中，过程噪声在 $12$ 小时内未经检查地累积。\n    **结论：错误。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在实际应用中，一个稳健的数据同化系统不仅需要能融合信息，还必须能识别并剔除有问题的观测数据。本练习将指导你实现一个关键的质量控制工具——基于新息向量的卡方检验（$\\chi^2$ test）。通过这个编程实践，你将学会如何利用统计原理来自动检测和拒绝异常值，从而防止它们污染你的分析结果，这是构建任何实用同化系统的基本技能 。",
            "id": "2382619",
            "problem": "给定一个用于数据同化中单个分析步骤的线性高斯观测设置。设预报状态的均值为 $\\mathbf{x}_f \\in \\mathbb{R}^n$，协方差为 $\\mathbf{P}_f \\in \\mathbb{R}^{n \\times n}$。测量值 $\\mathbf{y} \\in \\mathbb{R}^m$ 通过线性观测算子 $\\mathbf{H} \\in \\mathbb{R}^{m \\times n}$ 与状态相关，并带有协方差为 $\\mathbf{R} \\in \\mathbb{R}^{m \\times m}$ 的加性零均值高斯测量误差。定义新息向量 $\\mathbf{v} = \\mathbf{y} - \\mathbf{H}\\mathbf{x}_f$ 和新息协方差 $\\mathbf{S} = \\mathbf{H}\\mathbf{P}_f\\mathbf{H}^\\top + \\mathbf{R}$。在模型、协方差和观测与线性卡尔曼滤波器或集合卡尔曼滤波器在统计上一致的原假设下，二次型 $z = \\mathbf{v}^\\top \\mathbf{S}^{-1} \\mathbf{v}$ 服从自由度为 $m$ 的卡方（$\\chi^2$）分布。对于给定的显著性水平 $\\alpha \\in (0,1)$，将临界值 $c$ 定义为自由度为 $m$ 的 $\\chi^2$ 分布的上 $(1-\\alpha)$ 分位数。当且仅当 $z > c$ 时，应将测量值作为异常值拒绝。\n\n实现一个程序，对下面套件中的每个测试用例，根据上述规则计算接受或拒绝该测量的决策。每个测试用例的输出必须是布尔值：如果测量被拒绝，则为 `True`，否则为 `False`。不涉及物理单位。不出现角度。所有概率和显著性水平必须视为 $[0,1]$ 内的实数。该测试套件指定了不同的场景，包括一个典型情况、一个明显异常值、一个相关的多变量情况，以及一个 $z$ 恰好等于临界值且不得被拒绝的边界情况。\n\n使用以下测试套件，其中所有矩阵都按要求对称，并在需要时为正定：\n\n- 测试用例 1（单变量，典型接受）：\n  - $\\mathbf{H} = [\\,1.0\\,]$\n  - $\\mathbf{x}_f = [\\,0.0\\,]$\n  - $\\mathbf{P}_f = \\begin{bmatrix} 1.0 \\end{bmatrix}$\n  - $\\mathbf{R} = \\begin{bmatrix} 0.25 \\end{bmatrix}$\n  - $\\mathbf{y} = [\\,0.2\\,]$\n  - $\\alpha = 0.05$\n- 测试用例 2（单变量，明显异常值）：\n  - $\\mathbf{H} = [\\,1.0\\,]$\n  - $\\mathbf{x}_f = [\\,0.0\\,]$\n  - $\\mathbf{P}_f = \\begin{bmatrix} 0.5 \\end{bmatrix}$\n  - $\\mathbf{R} = \\begin{bmatrix} 0.1 \\end{bmatrix}$\n  - $\\mathbf{y} = [\\,3.0\\,]$\n  - $\\alpha = 0.01$\n- 测试用例 3（双变量，相关，接受）：\n  - $\\mathbf{H} = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}$\n  - $\\mathbf{x}_f = \\begin{bmatrix} 1.0 \\\\ -1.0 \\end{bmatrix}$\n  - $\\mathbf{P}_f = \\begin{bmatrix} 1.0  0.5 \\\\ 0.5  2.0 \\end{bmatrix}$\n  - $\\mathbf{R} = \\begin{bmatrix} 0.2  0.1 \\\\ 0.1  0.3 \\end{bmatrix}$\n  - $\\mathbf{y} = \\begin{bmatrix} 1.3 \\\\ -0.8 \\end{bmatrix}$\n  - $\\alpha = 0.05$\n- 测试用例 4（单变量，边界情况；因 $z = c$ 不拒绝）：\n  - $\\mathbf{H} = [\\,1.0\\,]$\n  - $\\mathbf{x}_f = [\\,0.0\\,]$\n  - $\\mathbf{P}_f = \\begin{bmatrix} 0.0 \\end{bmatrix}$\n  - $\\mathbf{R} = \\begin{bmatrix} 1.0 \\end{bmatrix}$\n  - $\\mathbf{y} = [\\,1.959963984540054\\,]$\n  - $\\alpha = 0.05$\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，`[result1,result2,result3,result4]`），顺序与上述测试用例相同。每个 `result` 必须是 `True` 或 `False`。",
            "solution": "检查问题陈述的有效性。\n\n步骤 1：提取已知条件\n问题为数据同化情景提供了以下定义和数据：\n- 预报状态均值：$\\mathbf{x}_f \\in \\mathbb{R}^n$\n- 预报状态协方差：$\\mathbf{P}_f \\in \\mathbb{R}^{n \\times n}$\n- 测量向量：$\\mathbf{y} \\in \\mathbb{R}^m$\n- 线性观测算子：$\\mathbf{H} \\in \\mathbb{R}^{m \\times n}$\n- 测量误差协方差：$\\mathbf{R} \\in \\mathbb{R}^{m \\times m}$（零均值高斯误差）\n- 新息向量：$\\mathbf{v} = \\mathbf{y} - \\mathbf{H}\\mathbf{x}_f$\n- 新息协方差：$\\mathbf{S} = \\mathbf{H}\\mathbf{P}_f\\mathbf{H}^\\top + \\mathbf{R}$\n- 检验统计量：$z = \\mathbf{v}^\\top \\mathbf{S}^{-1} \\mathbf{v}$\n- $z$ 的分布：自由度为 $m$ 的卡方（$\\chi^2$）分布。\n- 显著性水平：$\\alpha \\in (0,1)$\n- 临界值 $c$：自由度为 $m$ 的 $\\chi^2$ 分布的上 $(1-\\alpha)$ 分位数。\n- 拒绝规则：当且仅当 $z > c$ 时拒绝测量。\n\n问题提供了四个不同的测试用例，其中包含 $\\mathbf{H}$、$\\mathbf{x}_f$、$\\mathbf{P}_f$、$\\mathbf{R}$、$\\mathbf{y}$ 和 $\\alpha$ 的具体数值。\n\n步骤 2：使用提取的已知条件进行验证\n- **科学依据**：该问题描述了新息一致性检验，也称为卡方检验，这是数据同化中的一个标准、基本程序，尤其是在 Kalman 滤波器及其集合变体的背景下。其统计基础——即在给定的高斯假设下，二次型 $z = \\mathbf{v}^\\top \\mathbf{S}^{-1} \\mathbf{v}$ 服从 $\\chi^2$ 分布——是多元统计学中一个公认的结论。该问题在科学上和数学上都是合理的。\n- **适定性**：每个测试用例都提供了所有必要的输入（$\\mathbf{x}_f, \\mathbf{P}_f, \\mathbf{y}, \\mathbf{H}, \\mathbf{R}, \\alpha$）。目标是基于一个清晰、明确的规则（$z > c$）计算一个布尔决策。边界情况（$z = c$）的处理方式已明确规定，确保对于所有可能的 $z$ 值都有唯一的解。所提供的协方差矩阵是对称的，并按要求被描述为正定，这保证了新息协方差 $\\mathbf{S}$ 是可逆的。因此，该问题是适定的。\n- **客观性**：该问题使用精确的数学术语陈述。评估标准是一个严格的不等式，没有任何主观解释的余地。\n- **完整性和一致性**：该问题是自包含的。每个测试用例中所有矩阵和向量的维度对于所需的矩阵运算都是一致的。例如，在测试用例 3 中，$\\mathbf{H}$ 是 $2 \\times 2$，$\\mathbf{x}_f$ 是 $2 \\times 1$，所以 $\\mathbf{H}\\mathbf{x}_f$ 是 $2 \\times 1$，这与 $\\mathbf{y}$ 的维度（$2 \\times 1$）兼容。用于计算 $\\mathbf{S}$ 的维度也是一致的。\n- **其他标准**：该问题是可形式化的，与计算工程相关，其设置是现实的（尽管经过简化），并且是科学上可验证的。它没有违反任何指定的无效条件。\n\n步骤 3：结论与行动\n该问题是有效的。将构建一个解决方案。\n\n该解决方案要求为每个提供的测试用例实现卡方检验。每个用例的步骤如下：\n\n1.  确定观测空间的维度 $m$，即观测算子 $\\mathbf{H}$ 的行数（或测量向量 $\\mathbf{y}$ 的维度）。该值代表 $\\chi^2$ 分布的自由度。\n2.  计算新息向量 $\\mathbf{v} = \\mathbf{y} - \\mathbf{H}\\mathbf{x}_f$。该向量表示实际测量值 $\\mathbf{y}$ 与投影到观测空间中的预报状态 $\\mathbf{H}\\mathbf{x}_f$ 之间的差异。\n3.  计算新息协方差矩阵 $\\mathbf{S} = \\mathbf{H}\\mathbf{P}_f\\mathbf{H}^\\top + \\mathbf{R}$。该矩阵量化了新息中的总预期不确定性，结合了来自预报状态的不确定性（通过 $\\mathbf{H}$ 传播）和来自测量本身的不确定性。\n4.  计算检验统计量 $z = \\mathbf{v}^\\top \\mathbf{S}^{-1} \\mathbf{v}$。这是一个标量值，表示新息向量到原点的 Mahalanobis 距离的平方，并按其协方差进行归一化。它衡量在给定预期不确定性的情况下，新息的“意外”程度。该计算需要计算 $\\mathbf{S}$ 的逆。\n5.  对于给定的显著性水平 $\\alpha$，确定临界值 $c$。值 $c$ 是自由度为 $m$ 的 $\\chi^2$ 分布的上分位数，定义为 $P(\\chi^2_m \\le c) = 1 - \\alpha$。该值可以使用 $\\chi^2$ 分布的百分点函数（PPF），也称为逆累积分布函数，来获得。\n6.  将检验统计量 $z$ 与临界值 $c$ 进行比较。根据指定规则，如果 $z > c$，则拒绝该测量。这将产生一个布尔结果。边界情况 $z = c$ 导致不拒绝。\n\n此算法将应用于四个测试用例中的每一个。\n\n- 对于**测试用例 1**（单变量，典型接受）：\n  - $m=1$。$\\mathbf{v} = [0.2] - [1.0][0.0] = [0.2]$。\n  - $\\mathbf{S} = [1.0][1.0][1.0]^\\top + [0.25] = [1.25]$。\n  - $z = [0.2]^\\top [1.25]^{-1} [0.2] = 0.2 \\times (1/1.25) \\times 0.2 = 0.032$。\n  - 对于 $\\alpha=0.05$ 和 $m=1$ 自由度，临界值是 $c = \\chi^2_1\\text{.ppf}(0.95) \\approx 3.841$。\n  - 决策：$0.032 > 3.841$ 为假。接受该测量。\n\n- 对于**测试用例 2**（单变量，明显异常值）：\n  - $m=1$。$\\mathbf{v} = [3.0] - [1.0][0.0] = [3.0]$。\n  - $\\mathbf{S} = [1.0][0.5][1.0]^\\top + [0.1] = [0.6]$。\n  - $z = [3.0]^\\top [0.6]^{-1} [3.0] = 3.0 \\times (1/0.6) \\times 3.0 = 15.0$。\n  - 对于 $\\alpha=0.01$ 和 $m=1$ 自由度，临界值是 $c = \\chi^2_1\\text{.ppf}(0.99) \\approx 6.635$。\n  - 决策：$15.0 > 6.635$ 为真。拒绝该测量。\n\n- 对于**测试用例 3**（双变量，相关，接受）：\n  - $m=2$。$\\mathbf{x}_f = \\begin{bmatrix} 1.0 \\\\ -1.0 \\end{bmatrix}$。$\\mathbf{y} = \\begin{bmatrix} 1.3 \\\\ -0.8 \\end{bmatrix}$。$\\mathbf{H} = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}$。\n  - $\\mathbf{H}\\mathbf{x}_f = \\mathbf{x}_f = \\begin{bmatrix} 1.0 \\\\ -1.0 \\end{bmatrix}$。\n  - $\\mathbf{v} = \\begin{bmatrix} 1.3 \\\\ -0.8 \\end{bmatrix} - \\begin{bmatrix} 1.0 \\\\ -1.0 \\end{bmatrix} = \\begin{bmatrix} 0.3 \\\\ 0.2 \\end{bmatrix}$。\n  - 由于 $\\mathbf{H}$ 是单位矩阵，$\\mathbf{S} = \\mathbf{P}_f + \\mathbf{R} = \\begin{bmatrix} 1.0  0.5 \\\\ 0.5  2.0 \\end{bmatrix} + \\begin{bmatrix} 0.2  0.1 \\\\ 0.1  0.3 \\end{bmatrix} = \\begin{bmatrix} 1.2  0.6 \\\\ 0.6  2.3 \\end{bmatrix}$。\n  - 逆矩阵为 $\\mathbf{S}^{-1} = \\frac{1}{(1.2)(2.3) - (0.6)(0.6)} \\begin{bmatrix} 2.3  -0.6 \\\\ -0.6  1.2 \\end{bmatrix} = \\frac{1}{2.4} \\begin{bmatrix} 2.3  -0.6 \\\\ -0.6  1.2 \\end{bmatrix}$。\n  - $z = \\begin{bmatrix} 0.3  0.2 \\end{bmatrix} \\frac{1}{2.4} \\begin{bmatrix} 2.3  -0.6 \\\\ -0.6  1.2 \\end{bmatrix} \\begin{bmatrix} 0.3 \\\\ 0.2 \\end{bmatrix} = \\frac{1}{2.4} \\begin{bmatrix} 0.3  0.2 \\end{bmatrix} \\begin{bmatrix} 0.57 \\\\ 0.06 \\end{bmatrix} = \\frac{1}{2.4} (0.171 + 0.012) = \\frac{0.183}{2.4} = 0.07625$。\n  - 对于 $\\alpha=0.05$ 和 $m=2$ 自由度，临界值是 $c = \\chi^2_2\\text{.ppf}(0.95) \\approx 5.991$。\n  - 决策：$0.07625 > 5.991$ 为假。接受该测量。\n\n- 对于**测试用例 4**（单变量，边界情况）：\n  - $m=1$。$\\mathbf{v} = [1.959963984540054] - [1.0][0.0] = [1.959963984540054]$。\n  - $\\mathbf{S} = [1.0][0.0][1.0]^\\top + [1.0] = [1.0]$。\n  - $z = [1.959963984540054]^\\top [1.0]^{-1} [1.959963984540054] = (1.959963984540054)^2 \\approx 3.841458820694124$。\n  - 对于 $\\alpha=0.05$ 和 $m=1$ 自由度，临界值是 $c = \\chi^2_1\\text{.ppf}(0.95) \\approx 3.841458820694124$。\n  - $\\mathbf{y}$ 的值被构造成使得 $z$ 恰好等于 $c$。\n  - 决策：$z > c$ 为假。接受该测量。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Solves the outlier detection problem for a suite of test cases\n    based on the Chi-squared innovation consistency test.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1 (univariate, typical acceptance)\n        {\n            \"H\": np.array([[1.0]]),\n            \"x_f\": np.array([0.0]),\n            \"P_f\": np.array([[1.0]]),\n            \"R\": np.array([[0.25]]),\n            \"y\": np.array([0.2]),\n            \"alpha\": 0.05\n        },\n        # Test case 2 (univariate, clear outlier)\n        {\n            \"H\": np.array([[1.0]]),\n            \"x_f\": np.array([0.0]),\n            \"P_f\": np.array([[0.5]]),\n            \"R\": np.array([[0.1]]),\n            \"y\": np.array([3.0]),\n            \"alpha\": 0.01\n        },\n        # Test case 3 (bivariate, correlated, acceptance)\n        {\n            \"H\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"x_f\": np.array([1.0, -1.0]),\n            \"P_f\": np.array([[1.0, 0.5], [0.5, 2.0]]),\n            \"R\": np.array([[0.2, 0.1], [0.1, 0.3]]),\n            \"y\": np.array([1.3, -0.8]),\n            \"alpha\": 0.05\n        },\n        # Test case 4 (univariate, boundary case; do not reject because z = c)\n        {\n            \"H\": np.array([[1.0]]),\n            \"x_f\": np.array([0.0]),\n            \"P_f\": np.array([[0.0]]),\n            \"R\": np.array([[1.0]]),\n            \"y\": np.array([1.959963984540054]),\n            \"alpha\": 0.05\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Extract matrices and parameters for the current case.\n        H = case[\"H\"]\n        x_f = case[\"x_f\"]\n        P_f = case[\"P_f\"]\n        R = case[\"R\"]\n        y = case[\"y\"]\n        alpha = case[\"alpha\"]\n\n        # Step 1: Determine the degrees of freedom.\n        # m is the dimension of the observation space.\n        m = H.shape[0]\n\n        # Step 2: Compute the innovation vector.\n        # v = y - H * x_f\n        v = y - H @ x_f\n        \n        # Step 3: Compute the innovation covariance matrix.\n        # S = H * P_f * H^T + R\n        S = H @ P_f @ H.T + R\n        \n        # Step 4: Compute the test statistic.\n        # z = v^T * S^-1 * v\n        S_inv = np.linalg.inv(S)\n        # Reshape v to be a column vector for correct matrix multiplication if it's 1D\n        if v.ndim == 1:\n            v_col = v[:, np.newaxis]\n            z = (v_col.T @ S_inv @ v_col)[0, 0]\n        else:\n            z = (v.T @ S_inv @ v)[0, 0]\n\n        # Step 5: Determine the critical value.\n        # c is the upper (1-alpha) quantile of the Chi-squared distribution.\n        c = chi2.ppf(1 - alpha, df=m)\n        \n        # Step 6: Apply the decision rule.\n        # Reject if z  c.\n        is_rejected = z  c\n        \n        # The result must be a standard Python boolean\n        results.append(bool(is_rejected))\n\n    # Format output as a string representation of a list of booleans,\n    # with 'True' and 'False' (capitalized), as per Python's str(bool).\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "集合卡尔曼滤波的一个核心挑战是有限的集合规模可能导致预报误差协方差被低估，进而引发滤波器发散。本高级练习聚焦于解决这一问题的关键技术：协方差膨胀。你将实现一种基于新息统计（即Desroziers诊断法）的系统性方法来校准乘法膨胀因子 $\\lambda$，这对于在实际应用中维持集合的健康分布和确保滤波器性能至关重要 。",
            "id": "3123947",
            "problem": "给定一个典型的用于集成卡尔曼滤波器 (EnKF) 的线性高斯观测设置。观测模型为 $y = H x + \\varepsilon$，其中 $x$ 是状态， $H$ 是一个已知的线性观测算子，而 $\\varepsilon$ 是均值为零、协方差为 $R$ 的高斯噪声。集成预报提供了一个预报均值 $\\bar{x}^f$ 和一个预报协方差 $P^f$。新息为 $d = y - H \\bar{x}^f$。该集成使用乘性膨胀，它通过一个标量因子 $\\lambda \\geq 0$ 来缩放预报协方差，因此膨胀后的预报协方差为 $\\lambda P^f$。在线性高斯设置中，核心的诊断条件是新息协方差与预报和观测误差协方差之间的关系，即在乘性膨胀下的理论新息协方差为 $S(\\lambda) = H (\\lambda P^f) H^\\top + R$。\n\n给定一个从新息样本 $d$ 计算出的新息协方差的经验估计，记为 $\\widehat{S}$。您的任务是通过求解以下约束最小二乘问题来校准乘性膨胀因子 $\\lambda$：\n- 在区间 $[\\lambda_{\\min}, \\lambda_{\\max}]$ 上最小化 Frobenius 范数的平方 $J(\\lambda) = \\lVert \\widehat{S} - (H (\\lambda P^f) H^\\top + R) \\rVert_F^2$。\n- 如果 $H P^f H^\\top$ 是零矩阵（即新息对 $\\lambda$ 没有敏感度），则返回默认值 $\\lambda_{\\text{default}}$。\n\n所有矩阵都是实值矩阵且尺寸兼容。对于下面的每个测试用例，计算一个标量 $\\lambda^\\star$ 以求解上述问题，然后将其裁剪到区间 $[\\lambda_{\\min}, \\lambda_{\\max}]$ 内。最后，将每个 $\\lambda^\\star$ 四舍五入到三位小数。\n\n测试套件：\n- 情况 1（标量，良态）：\n  - $H = [1.0]$\n  - $P^f = [0.5]$\n  - $R = [0.2]$\n  - $\\widehat{S} = [0.9]$\n  - $\\lambda_{\\min} = 0.5$, $\\lambda_{\\max} = 2.0$, $\\lambda_{\\text{default}} = 1.0$\n- 情况 2（二维，精确一致）：\n  - $H = \\begin{bmatrix}1.0  0.0 \\\\ 0.0  1.0\\end{bmatrix}$\n  - $P^f = \\begin{bmatrix}0.3  0.1 \\\\ 0.1  0.2\\end{bmatrix}$\n  - $R = \\begin{bmatrix}0.05  0.0 \\\\ 0.0  0.04\\end{bmatrix}$\n  - $\\widehat{S} = \\begin{bmatrix}0.41  0.12 \\\\ 0.12  0.28\\end{bmatrix}$\n  - $\\lambda_{\\min} = 0.5$, $\\lambda_{\\max} = 2.0$, $\\lambda_{\\text{default}} = 1.0$\n- 情况 3（标量，下界激活）：\n  - $H = [1.0]$\n  - $P^f = [0.3]$\n  - $R = [0.5]$\n  - $\\widehat{S} = [0.45]$\n  - $\\lambda_{\\min} = 0.8$, $\\lambda_{\\max} = 2.0$, $\\lambda_{\\text{default}} = 1.0$\n- 情况 4（标量，零敏感度，回退到默认值）：\n  - $H = [0.0]$\n  - $P^f = [0.4]$\n  - $R = [0.1]$\n  - $\\widehat{S} = [0.3]$\n  - $\\lambda_{\\min} = 0.5$, $\\lambda_{\\max} = 2.0$, $\\lambda_{\\text{default}} = 1.33$\n- 情况 5（标量, 上界激活）：\n  - $H = [1.0]$\n  - $P^f = [0.2]$\n  - $R = [0.1]$\n  - $\\widehat{S} = [1.5]$\n  - $\\lambda_{\\min} = 0.5$, $\\lambda_{\\max} = 1.8$, $\\lambda_{\\text{default}} = 1.0$\n\n输出规格：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个条目是对应测试用例校准后的 $\\lambda^\\star$，四舍五入到三位小数。例如：$[1.234,0.999,1.500]$。\n\n注：\n- 所有角度均不适用。\n- 不涉及物理单位。",
            "solution": "用户希望解决一个约束优化问题，以校准在集成卡尔曼滤波器中使用的乘性膨胀因子 $\\lambda$。目标是在 $\\lambda$ 的区间约束下，最小化成本函数 $J(\\lambda)$，该函数定义为一个经验新息协方差与一个理论新息协方差之差的 Frobenius 范数的平方。\n\n问题表述为：对于 $\\lambda \\in [\\lambda_{\\min}, \\lambda_{\\max}]$，最小化 $J(\\lambda) = \\lVert \\widehat{S} - S(\\lambda) \\rVert_F^2$。\n理论新息协方差由 $S(\\lambda) = H (\\lambda P^f) H^\\top + R$ 给出。\n将 $S(\\lambda)$ 代入成本函数，我们得到：\n$$\nJ(\\lambda) = \\lVert \\widehat{S} - (H (\\lambda P^f) H^\\top + R) \\rVert_F^2\n$$\n因子 $\\lambda$ 是一个标量，因此可以从矩阵乘法中移出：\n$$\nJ(\\lambda) = \\lVert \\widehat{S} - (\\lambda H P^f H^\\top + R) \\rVert_F^2\n$$\n为简化推导，我们定义两个辅助矩阵：\n令 $A = H P^f H^\\top$。\n令 $B = \\widehat{S} - R$。\n\n使用这些定义，成本函数变为：\n$$\nJ(\\lambda) = \\lVert B - \\lambda A \\rVert_F^2\n$$\n实矩阵 $M$ 的 Frobenius 范数的平方定义为其元素平方和，也可以表示为 $M^\\top M$ 的迹，即 $\\lVert M \\rVert_F^2 = \\text{tr}(M^\\top M)$。将此应用于我们的成本函数：\n$$\nJ(\\lambda) = \\text{tr}\\left((B - \\lambda A)^\\top (B - \\lambda A)\\right)\n$$\n展开迹内的项：\n$$\nJ(\\lambda) = \\text{tr}(B^\\top B - \\lambda B^\\top A - \\lambda A^\\top B + \\lambda^2 A^\\top A)\n$$\n利用迹算子的线性性质：\n$$\nJ(\\lambda) = \\text{tr}(B^\\top B) - \\lambda \\text{tr}(B^\\top A) - \\lambda \\text{tr}(A^\\top B) + \\lambda^2 \\text{tr}(A^\\top A)\n$$\n矩阵 $P^f$、$R$ 和 $\\widehat{S}$ 是协方差矩阵，因此是对称的。这意味着辅助矩阵 $A$ 和 $B$ 也是对称的：\n$A^\\top = (H P^f H^\\top)^\\top = (H^\\top)^\\top (P^f)^\\top H^\\top = H P^f H^\\top = A$。\n$B^\\top = (\\widehat{S} - R)^\\top = \\widehat{S}^\\top - R^\\top = \\widehat{S} - R = B$。\n\n利用 $A$ 和 $B$ 的对称性以及迹的循环性质 ($\\text{tr}(XY) = \\text{tr}(YX)$)，我们可以简化表达式：\n$\\text{tr}(A^\\top B) = \\text{tr}(AB)$ 且 $\\text{tr}(B^\\top A) = \\text{tr}(BA)$。由于 $\\text{tr}(AB) = \\text{tr}(BA)$，这两个线性项是相同的。\n成本函数是关于 $\\lambda$ 的二次函数：\n$$\nJ(\\lambda) = \\lambda^2 \\text{tr}(A^2) - 2\\lambda \\text{tr}(AB) + \\text{tr}(B^2)\n$$\n为了找到最小化此函数的 $\\lambda$ 值，我们对 $\\lambda$求导并令其为零：\n$$\n\\frac{dJ}{d\\lambda} = 2\\lambda \\text{tr}(A^2) - 2 \\text{tr}(AB) = 0\n$$\n求解 $\\lambda$ 得到无约束最优解，我们记为 $\\lambda_{uc}$：\n$$\n2\\lambda_{uc} \\text{tr}(A^2) = 2 \\text{tr}(AB) \\implies \\lambda_{uc} = \\frac{\\text{tr}(AB)}{\\text{tr}(A^2)}\n$$\n此解在分母 $\\text{tr}(A^2)$ 非零时有效。项 $\\text{tr}(A^2)$ 等价于 $\\text{tr}(A^\\top A) = \\lVert A \\rVert_F^2$。该项为零当且仅当 $A$ 是零矩阵。问题陈述为此情况提供了具体说明：如果 $A = H P^f H^\\top$ 是零矩阵，则应使用值 $\\lambda_{\\text{default}}$。这与我们的推导完全一致，因为分母为零会使 $\\lambda_{uc}$ 未定义。\n\n最后一步是引入约束 $\\lambda \\in [\\lambda_{\\min}, \\lambda_{\\max}]$。约束问题的解 $\\lambda^\\star$ 是通过将候选值（$\\lambda_{uc}$ 或 $\\lambda_{\\text{default}}$）裁剪到指定区间内得到的。\n\n完整的算法如下：\n1. 给定矩阵 $H$、$P^f$、$R$、$\\widehat{S}$ 和标量 $\\lambda_{\\min}$、$\\lambda_{\\max}$、$\\lambda_{\\text{default}}$。\n2. 计算矩阵 $A = H P^f H^\\top$。\n3. 计算分母项 $d = \\text{tr}(A^2)$。\n4. 检查 $d$ 是否在数值上为零。\n   - 如果 $d \\approx 0$，则候选解为 $\\lambda_{\\text{cand}} = \\lambda_{\\text{default}}$。\n   - 否则，计算矩阵 $B = \\widehat{S} - R$，分子项 $n = \\text{tr}(AB)$，以及候选解 $\\lambda_{\\text{cand}} = n/d$。\n5. 最终最优值 $\\lambda^\\star$ 是通过将 $\\lambda_{\\text{cand}}$ 裁剪到允许的区间内找到的：\n   $$\n   \\lambda^\\star = \\max(\\lambda_{\\min}, \\min(\\lambda_{\\text{cand}}, \\lambda_{\\max}))\n   $$\n6. 然后按要求将 $\\lambda^\\star$ 的值四舍五入到三位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the constrained least-squares problem for calibrating the\n    multiplicative inflation factor lambda for a series of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {\n            \"H\": np.array([[1.0]]),\n            \"Pf\": np.array([[0.5]]),\n            \"R\": np.array([[0.2]]),\n            \"S_hat\": np.array([[0.9]]),\n            \"lambda_min\": 0.5,\n            \"lambda_max\": 2.0,\n            \"lambda_default\": 1.0,\n        },\n        # Case 2\n        {\n            \"H\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"Pf\": np.array([[0.3, 0.1], [0.1, 0.2]]),\n            \"R\": np.array([[0.05, 0.0], [0.0, 0.04]]),\n            \"S_hat\": np.array([[0.41, 0.12], [0.12, 0.28]]),\n            \"lambda_min\": 0.5,\n            \"lambda_max\": 2.0,\n            \"lambda_default\": 1.0,\n        },\n        # Case 3\n        {\n            \"H\": np.array([[1.0]]),\n            \"Pf\": np.array([[0.3]]),\n            \"R\": np.array([[0.5]]),\n            \"S_hat\": np.array([[0.45]]),\n            \"lambda_min\": 0.8,\n            \"lambda_max\": 2.0,\n            \"lambda_default\": 1.0,\n        },\n        # Case 4\n        {\n            \"H\": np.array([[0.0]]),\n            \"Pf\": np.array([[0.4]]),\n            \"R\": np.array([[0.1]]),\n            \"S_hat\": np.array([[0.3]]),\n            \"lambda_min\": 0.5,\n            \"lambda_max\": 2.0,\n            \"lambda_default\": 1.33,\n        },\n        # Case 5\n        {\n            \"H\": np.array([[1.0]]),\n            \"Pf\": np.array([[0.2]]),\n            \"R\": np.array([[0.1]]),\n            \"S_hat\": np.array([[1.5]]),\n            \"lambda_min\": 0.5,\n            \"lambda_max\": 1.8,\n            \"lambda_default\": 1.0,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        H = case[\"H\"]\n        Pf = case[\"Pf\"]\n        R = case[\"R\"]\n        S_hat = case[\"S_hat\"]\n        lambda_min = case[\"lambda_min\"]\n        lambda_max = case[\"lambda_max\"]\n        lambda_default = case[\"lambda_default\"]\n\n        # Calculate the matrix A = H * P^f * H^T\n        A = H @ Pf @ H.T\n\n        # Calculate the denominator term: trace(A^2)\n        # This is equivalent to the squared Frobenius norm of A.\n        denom = np.trace(A @ A)\n\n        # Check if the denominator is close to zero, which happens iff A is the zero matrix.\n        if np.isclose(denom, 0.0):\n            # If sensitivity to lambda is zero, use the default value.\n            lambda_cand = lambda_default\n        else:\n            # Calculate the matrix B = S_hat - R\n            B = S_hat - R\n            # Calculate the numerator term: trace(A * B)\n            num = np.trace(A @ B)\n            # Calculate the unconstrained optimal lambda\n            lambda_cand = num / denom\n\n        # Clip the result to the interval [lambda_min, lambda_max]\n        lambda_star = np.clip(lambda_cand, lambda_min, lambda_max)\n        \n        # Round to three decimal places.\n        # The output format requires explicit formatting for trailing zeros.\n        results.append(f\"{lambda_star:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}