{
    "hands_on_practices": [
        {
            "introduction": "Selection is the primary engine driving a Genetic Algorithm, giving preferential treatment to fitter individuals. To build a strong foundational understanding, it's useful to isolate this force and observe its effects. This practice invites you to simulate a simplified evolutionary scenario where only selection is at play, allowing you to witness how a single superior individual can propagate through a population and eventually achieve \"takeover.\" By comparing your simulation results with a deterministic mathematical approximation , you will gain a deeper intuition for the interplay between selection pressure and the stochastic effects of genetic drift.",
            "id": "3137411",
            "problem": "Consider a selection-only model of a Genetic Algorithm (GA), defined here as a Genetic Algorithm (GA) that generates each new generation solely by fitness-proportionate selection without crossover, mutation, or other operators. The population consists of two types: a single best individual and all other individuals. Let the population size be $N$, and let the selection intensity of the best individual be $s$, meaning the best individual has fitness $s$ while all other individuals have fitness $1$. The initial population contains $1$ best individual and $N-1$ others.\n\nAt generation $t$, let $k_t$ denote the number of best individuals. Under fitness-proportionate selection, the probability $p_t$ that a randomly selected offspring comes from the best type is given by the total fitness contribution of the best type divided by the total population fitness. The next generation has $N$ individuals sampled with replacement from the previous generation, so the number of best individuals $k_{t+1}$ is a random variable with a binomial distribution with $N$ trials and success probability $p_t$.\n\nDefine the takeover time $T$ as the smallest nonnegative integer $t$ such that $k_t = N$ (that is, the entire population consists of the best individual). Due to stochastic sampling, the best individual can go extinct, which implies $k_t = 0$ for all subsequent generations; in that case, the takeover time is undefined. For this problem, define the estimated takeover time as the conditional expectation of $T$ given that takeover occurs, approximated by Monte Carlo simulation.\n\nYour task is to:\n- Implement a simulation that, for given $(N,s)$, performs $R$ independent runs. Each run starts with $k_0 = 1$ and evolves by repeated fitness-proportionate sampling until either $k_t = N$ (takeover), $k_t = 0$ (extinction), or a preset generation cap is reached. For each run that reaches takeover, record the takeover time. Estimate the conditional expected takeover time by averaging the takeover times across successful runs.\n- Compute a deterministic approximation for the takeover time that arises from assuming multiplicative growth of the expected count of best individuals while the fraction of best individuals is small.\n- For each test case, report the absolute difference between the Monte Carlo estimate and the deterministic approximation, rounded to three decimal places.\n\nUse the following test suite:\n1. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (100, 1.5, 500, 1000, 42)$\n2. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (100, 1.01, 500, 10000, 43)$\n3. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (50, 2.0, 300, 200, 44)$\n4. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (10, 1.5, 1000, 200, 45)$\n5. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (200, 1.2, 300, 3000, 46)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the absolute error for the corresponding test case. If no runs in a test case achieve takeover within the generation cap, output the floating-point value $\\mathrm{nan}$ for that case. For example, the final output should look like $[e_1,e_2,e_3,e_4,e_5]$ where each $e_i$ is a floating-point number rounded to three decimal places.",
            "solution": "The user's problem statement has been validated and is determined to be sound. It is scientifically grounded in the principles of population genetics and computational science, specifically the Wright-Fisher model with selection. The problem is well-posed, with all necessary parameters and definitions provided for both the Monte Carlo simulation and the deterministic approximation. The objective is clear and formal. Therefore, I will now provide a complete solution.\n\nThe problem requires a comparison between a stochastic simulation of an evolutionary process and a simplified deterministic model of the same process. The goal is to compute the absolute difference between the takeover time estimated from a Monte-Carlo simulation and the takeover time predicted by a deterministic approximation.\n\nLet us define the parameters and variables as given:\n- $N$: The total population size.\n- $s$: The fitness of the \"best\" individual type, where $s > 1$. The fitness of all other individuals is $1$.\n- $k_t$: The number of best individuals in the population at generation $t$. The initial state is $k_0 = 1$.\n- $p_t$: The probability of selecting an offspring from the best type in generation $t$.\n\nThe core of the model lies in the transition from generation $t$ to $t+1$. The probability $p_t$ is determined by the proportion of total fitness contributed by the $k_t$ best individuals:\n$$\np_t = \\frac{k_t \\cdot s}{k_t \\cdot s + (N - k_t) \\cdot 1} = \\frac{s k_t}{s k_t + N - k_t}\n$$\nThe next generation is formed by $N$ independent samples with replacement from the current generation. Therefore, the number of best individuals in the next generation, $k_{t+1}$, follows a binomial distribution with $N$ trials and success probability $p_t$:\n$$\nk_{t+1} \\sim \\text{Binomial}(N, p_t)\n$$\n\nThe solution involves three main steps: deriving the deterministic approximation, outlining the Monte Carlo simulation, and calculating the final error.\n\n**1. Deterministic Approximation ($T_{det}$)**\n\nThe deterministic model approximates the stochastic process by tracking the expected number of individuals, $E[k_t]$. The expected value of $k_{t+1}$ given $k_t$ is $E[k_{t+1} | k_t] = N p_t$.\n$$\nE[k_{t+1} | k_t] = N \\left( \\frac{s k_t}{s k_t + N - k_t} \\right)\n$$\nThe problem specifies that the approximation should assume multiplicative growth while the fraction of best individuals, $x_t = k_t/N$, is small. When $x_t \\ll 1$, we can approximate the denominator:\n$$\ns k_t + N - k_t = N(1 + (s-1)\\frac{k_t}{N}) \\approx N\n$$\nSubstituting this into the expectation gives a simplified recurrence relation for the expected count, which we denote $\\bar{k}_t$:\n$$\n\\bar{k}_{t+1} \\approx N \\left( \\frac{s \\bar{k}_t}{N} \\right) = s \\bar{k}_t\n$$\nThis is a geometric progression. Starting with the initial condition $k_0 = 1$, the expected number of best individuals at generation $t$ grows exponentially:\n$$\n\\bar{k}_t \\approx k_0 s^t = s^t\n$$\nTakeover is defined as the point where the entire population consists of best individuals, i.e., when the count reaches $N$. We solve for the time $t$ required to satisfy this condition in our continuous approximation:\n$$\ns^t = N\n$$\nTaking the natural logarithm of both sides yields:\n$$\nt \\ln(s) = \\ln(N)\n$$\nThis gives the deterministic takeover time, $T_{det}$:\n$$\nT_{det} = \\frac{\\ln(N)}{\\ln(s)}\n$$\nThis approximation neglects the stochastic effects of random sampling (genetic drift), which can lead to extinction, especially when $k_t$ is small, or otherwise cause deviations from smooth exponential growth.\n\n**2. Monte Carlo Simulation Estimate ($T_{MC}$)**\n\nTo capture the stochastic nature of the process, we perform a Monte Carlo simulation. For each set of parameters $(N, s, R, \\text{max\\_gen}, \\text{seed})$, we conduct $R$ independent runs.\nEach run proceeds as follows:\n1.  Initialize the state: the generation count $t=0$ and the number of best individuals $k_0=1$.\n2.  Iterate through generations: for each generation, increment $t$.\n3.  Calculate the selection probability $p_t$ based on the current count $k_t$.\n4.  Sample the number of best individuals for the next generation, $k_{t+1}$, from a binomial distribution: $k_{t+1} = \\text{rng.binomial}(N, p_t)$, where `rng` is a seeded random number generator.\n5.  Check for termination conditions:\n    - If $k_{t+1} = N$ (takeover), record the current generation count $t+1$ as the takeover time for this run and stop the run.\n    - If $k_{t+1} = 0$ (extinction), stop the run without recording a time.\n    - If $t$ reaches the generation cap, `max_gen`, stop the run. This is a safeguard against excessively long runs.\nAfter all $R$ runs are completed, we will have a list of takeover times from the successful runs. The estimated conditional expected takeover time, $T_{MC}$, is the arithmetic mean of these recorded times. If no runs result in a takeover, $T_{MC}$ is considered undefined, represented as $\\mathrm{nan}$.\n\n**3. Error Calculation**\n\nFor each test case, the final result is the absolute difference between the Monte Carlo estimate and the deterministic approximation, rounded to three decimal places:\n$$\n\\Delta T = |T_{MC} - T_{det}|\n$$\nIf $T_{MC}$ is $\\mathrm{nan}$, the difference $\\Delta T$ is also $\\mathrm{nan}$. The implementation will calculate this value for each of the five provided test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the absolute difference between a Monte Carlo estimate and a\n    deterministic approximation for the takeover time in a selection-only\n    genetic algorithm model.\n    \"\"\"\n    test_cases = [\n        # (N, s, R, max_gen, seed)\n        (100, 1.5, 500, 1000, 42),\n        (100, 1.01, 500, 10000, 43),\n        (50, 2.0, 300, 200, 44),\n        (10, 1.5, 1000, 200, 45),\n        (200, 1.2, 300, 3000, 46),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, s, R, max_gen, seed = case\n\n        # Initialize random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # --- Monte Carlo Simulation ---\n        takeover_times = []\n        for _ in range(R):\n            k = 1  # Initial number of best individuals\n            for t in range(1, max_gen + 1):\n                # Check for termination conditions from the previous state\n                if k == N:\n                    takeover_times.append(t - 1)\n                    break\n                if k == 0:\n                    break\n\n                # Calculate selection probability\n                total_fitness_best = k * s\n                total_fitness_other = (N - k) * 1.0\n                total_fitness = total_fitness_best + total_fitness_other\n                \n                # Handle potential division by zero if population empties, though k=0 check prevents this\n                if total_fitness == 0:\n                    p = 0.0\n                else:\n                    p = total_fitness_best / total_fitness\n\n                # Sample the next generation\n                k = rng.binomial(N, p)\n            \n            # Check for takeover at the end of the loop (if max_gen is reached exactly)\n            else: # This 'else' belongs to the 'for t' loop\n                if k == N:\n                    takeover_times.append(max_gen)\n\n\n        # Calculate the MC estimate\n        if not takeover_times:\n            mc_estimate = np.nan\n        else:\n            mc_estimate = np.mean(takeover_times)\n\n        # --- Deterministic Approximation ---\n        # T_det = log(N) / log(s)\n        det_approx = np.log(N) / np.log(s)\n\n        # --- Calculate Absolute Difference ---\n        if np.isnan(mc_estimate):\n            diff = np.nan\n            results.append('nan')\n        else:\n            diff = np.abs(mc_estimate - det_approx)\n            results.append(f\"{diff:.3f}\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Beyond selection, a crucial design choice in any Genetic Algorithm is the representation—how a solution is encoded in its genotype. This choice is not merely a detail; it fundamentally shapes the search landscape that the algorithm explores. This exercise compares the two most common encodings for numerical problems, standard binary and Gray coding, on a classic optimization task . By analyzing how single-bit mutations translate into changes in the solution space, you will discover how different encodings create different \"neighborhoods\" and search biases, directly impacting the algorithm's ability to perform local search and find the optimum.",
            "id": "3132789",
            "problem": "You are to write a complete, runnable program that compares two genotype encodings used in Genetic Algorithms (Genetic Algorithm (GA)): standard binary encoding and Gray coding, when optimizing the sphere function. The objective function is the sphere function $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$ defined on a bounded hyper-rectangle $[L, U]^n$ with $L &lt; 0 &lt; U$. Each decision variable $x_i$ is represented by $b$ bits and decoded into a real value by uniform linear quantization.\n\nFundamental base and definitions to use:\n- The sphere function $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$ is separable by coordinates.\n- The genotype-to-phenotype mapping is a linear quantizer: for each coordinate, a $b$-bit code word represents an integer $k \\in \\{0,1,\\dots,2^b - 1\\}$ which maps to a real value $x = L + \\dfrac{U - L}{2^b - 1}\\,k$. This induces a uniform grid of $2^b$ points per coordinate including the endpoints $L$ and $U$.\n- For binary encoding, the code word is the standard base-$2$ representation of $k$. For Gray coding, the code word is the Gray encoding of $k$, and decoding applies Gray-to-binary conversion to recover the integer $k$ before the linear map to $x$.\n- A single-bit mutation is defined as flipping exactly one bit chosen uniformly at random among all $n b$ genotype bits.\n\nCompute and report the following for each test case:\n1) Discretization error. Define the discretization error as the minimum attainable value of $f(\\mathbf{x})$ over the discretized grid induced by the chosen $b$ (for either encoding; both induce the same set of phenotype grid points) minus the continuous optimum of $f(\\mathbf{x})$ over $[L, U]^n$. You must compute this quantity exactly, not by sampling.\n2) Search bias via one-step improvement probability. Define the one-step improvement probability $P_{\\mathrm{improve}}$ for an encoding as the probability (with respect to the uniform distribution over genotypes and uniform choice among $n b$ bit positions) that a single-bit flip strictly decreases $f(\\mathbf{x})$. You must compute this probability exactly by enumeration, not by simulation. Formally,\n$$\nP_{\\mathrm{improve}} = \\frac{1}{(2^b)^n \\cdot n b} \\sum_{\\text{genotypes } g} \\sum_{p=1}^{n b} \\mathbf{1}\\big(f(g^{(p)}) &lt; f(g)\\big),\n$$\nwhere $g^{(p)}$ is $g$ with bit $p$ flipped, and $\\mathbf{1}(\\cdot)$ is the indicator function. Use the separability of $f$ and the fact that the bit flip affects exactly one coordinate to reduce this to an equivalent exact enumeration over a single coordinate of $b$ bits.\n\nYour program must:\n- Implement both encodings (binary and Gray) exactly for any integer $b \\ge 1$.\n- Use exact logic instead of floating-point comparisons to test whether a bit flip improves a single coordinate’s contribution $x^2$, by observing that for symmetric bounds with $L = -U$ and uniform quantization with step size $\\Delta = \\dfrac{U - L}{2^b - 1}$, the per-coordinate value equals $x = \\Delta\\,(k - m)$ with $m = \\dfrac{2^b - 1}{2}$. Therefore, a flip improves the objective if and only if $\\lvert k' - m \\rvert &lt; \\lvert k - m \\rvert$, which is equivalent to $\\lvert 2k' - (2^b - 1) \\rvert &lt; \\lvert 2k - (2^b - 1) \\rvert$.\n- Compute the discretization error exactly from first principles, without numerically searching the grid. If $0 \\in [L, U]$, the continuous minimum is $0$ achieved at $\\mathbf{x} = \\mathbf{0}$; otherwise it is the closest boundary point to $0$ in each coordinate.\n- Output, for each test case, a list with four numbers: the discretization error under binary encoding, the discretization error under Gray coding, the one-step improvement probability under binary encoding, and the one-step improvement probability under Gray coding. All numbers must be printed as decimals rounded to $12$ places.\n\nTest suite:\nUse the following five test cases, each specified as a tuple $(n, b, L, U)$, where $n$ is the dimension, $b$ is the bit-length per coordinate, and $[L, U]$ is the bound interval:\n- $(\\,1,\\,3,\\,-1.0,\\,1.0\\,)$\n- $(\\,5,\\,4,\\,-1.0,\\,1.0\\,)$\n- $(\\,10,\\,8,\\,-1.0,\\,1.0\\,)$\n- $(\\,3,\\,1,\\,-1.0,\\,1.0\\,)$\n- $(\\,2,\\,12,\\,-1.0,\\,1.0\\,)$\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the five test cases as a comma-separated list of length five, where each element is itself a comma-separated list of four decimal numbers in the order described above, and every decimal is rounded to $12$ places. For example, a valid shape is\n$$\n[\\,[d_1^{\\text{bin}}, d_1^{\\text{gray}}, p_1^{\\text{bin}}, p_1^{\\text{gray}}],\\dots,[d_5^{\\text{bin}}, d_5^{\\text{gray}}, p_5^{\\text{bin}}, p_5^{\\text{gray}}]\\,].\n$$\nNo extra text should be printed.",
            "solution": "The user-provided problem has been analyzed and validated. It is scientifically grounded, well-posed, and all definitions and constraints are self-contained and consistent. The task is to compute two metrics, discretization error and one-step improvement probability, for binary and Gray encodings used in a genetic algorithm optimizing the sphere function.\n\n### 1. Discretization Error\n\nThe objective function is the sphere function $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$ over the domain $\\mathbf{x} \\in [L, U]^n$. For all test cases, $L = -1.0$ and $U = 1.0$, so $L < 0 < U$. The continuous minimum of $f(\\mathbf{x})$ is $f(\\mathbf{0}) = 0$, achieved at $\\mathbf{x} = \\mathbf{0}$.\n\nThe problem describes a uniform linear quantization scheme where each coordinate $x_i$ is mapped from a $b$-bit codeword. The codeword corresponds to an integer $k \\in \\{0, 1, \\dots, 2^b-1\\}$, which in turn maps to a real value $x_k = L + \\frac{U-L}{2^b-1}k$. The set of possible real values for each coordinate, the grid points, is determined by the range of $k$.\n\nBoth binary and Gray encodings provide a bijective mapping from the set of $b$-bit strings to the set of integers $\\{0, 1, \\dots, 2^b-1\\}$. Consequently, the set of achievable phenotype values (the grid points) is identical for both encodings. The discretization error, defined as the difference between the minimum value on the grid and the continuous minimum, is therefore independent of the choice between binary and Gray encoding.\n\nTo find the minimum value of $f(\\mathbf{x})$ on the grid, we must find the grid point $x_k$ closest to $0$ for each coordinate. The value of $k$ that makes $x_k$ closest to $0$ is the integer nearest to the real value $k_{\\text{real}} = -L \\frac{2^b-1}{U-L}$.\nGiven $L=-1.0$ and $U=1.0$, this becomes $k_{\\text{real}} = -(-1.0) \\frac{2^b-1}{1.0 - (-1.0)} = \\frac{2^b-1}{2}$.\nSince $b \\ge 1$, $2^b-1$ is always odd, so $k_{\\text{real}}$ is never an integer. The two integers closest to $k_{\\text{real}}$ are $k_1 = \\lfloor \\frac{2^b-1}{2} \\rfloor = 2^{b-1}-1$ and $k_2 = \\lceil \\frac{2^b-1}{2} \\rceil = 2^{b-1}$.\nThe corresponding phenotype values are:\n$x_{k_1} = -1.0 + \\frac{2.0}{2^b-1}(2^{b-1}-1) = \\frac{-(2^b-1) + 2^b-2}{2^b-1} = \\frac{-1}{2^b-1}$.\n$x_{k_2} = -1.0 + \\frac{2.0}{2^b-1}(2^{b-1}) = \\frac{-(2^b-1) + 2^b}{2^b-1} = \\frac{1}{2^b-1}$.\nThe minimum possible absolute value for a coordinate is $|x^*| = \\frac{1}{2^b-1}$.\nThe minimum value of $f(\\mathbf{x})$ on the discrete grid is achieved when each $|x_i| = |x^*|$, so $\\min_{\\text{grid}} f(\\mathbf{x}) = \\sum_{i=1}^{n} (x^*)^2 = n \\left(\\frac{1}{2^b-1}\\right)^2$.\nThe discretization error $D$ is thus:\n$$ D = \\min_{\\text{grid}} f(\\mathbf{x}) - \\min_{\\text{continuous}} f(\\mathbf{x}) = \\frac{n}{(2^b-1)^2} - 0 = \\frac{n}{(2^b-1)^2} $$\nThis value is the same for both binary and Gray encoding, so $D_{\\text{binary}} = D_{\\text{Gray}}$.\n\n### 2. One-Step Improvement Probability ($P_{\\mathrm{improve}}$)\n\nThe one-step improvement probability is defined as:\n$$ P_{\\mathrm{improve}} = \\frac{1}{(2^b)^n \\cdot nb} \\sum_{\\text{genotypes } g} \\sum_{p=1}^{nb} \\mathbf{1}\\big(f(g^{(p)}) < f(g)\\big) $$\nDue to the separability of the sphere function $f(\\mathbf{x}) = \\sum_{i=1}^n x_i^2$, a single-bit flip in the genotype affects only one coordinate, say $x_i \\to x_i'$. The condition for improvement $f(g^{(p)}) < f(g)$ simplifies to $(x_i')^2 < x_i^2$, which is equivalent to $|x_i'| < |x_i|$.\nThe total number of improving moves can be summed over each coordinate independently. Let $S$ be the total number of single-bit flips that result in an improvement for a single $b$-bit coordinate, summed over all $2^b$ possible states of that coordinate.\n$$ S = \\sum_{c \\in \\{0,1\\}^b} \\sum_{j=1}^{b} \\mathbf{1}\\big( |x'(c^{(j)})| < |x(c)| \\big) $$\nwhere $c$ is a $b$-bit codeword, $c^{(j)}$ is $c$ with bit $j$ flipped, and $x(c)$ is the phenotype value corresponding to $c$.\nThe total number of improving moves across all $n$ coordinates and all $(2^b)^n$ genotypes is $n \\cdot (2^b)^{n-1} \\cdot S$.\nSubstituting this into the probability formula simplifies it significantly:\n$$ P_{\\mathrm{improve}} = \\frac{n \\cdot (2^b)^{n-1} \\cdot S}{(2^b)^n \\cdot nb} = \\frac{S}{2^b \\cdot b} $$\nThis means we only need to analyze a single $b$-bit coordinate to find the probability. The value of $S$ will differ between binary and Gray encodings because the mapping from a codeword $c$ to an integer $k$ (and thus to a phenotype value $x$) is different.\n\nTo avoid floating-point inaccuracies, we use the suggested integer-based comparison. For $L=-U$, the condition $|x'| < |x|$ is equivalent to $|k' - m| < |k - m|$ where $m = (2^b-1)/2$. This can be rewritten by multiplying by $2$ as $|2k' - (2^b-1)| < |2k - (2^b-1)|$.\n\nThe algorithm to compute $S$ for each encoding is as follows:\n1.  Initialize a counter for improving moves, `improvements`, to $0$. Let $M = 2^b - 1$.\n2.  Iterate through each possible $b$-bit codeword $c$, represented by an integer from $0$ to $2^b-1$.\n3.  For each $c$, determine its integer value $k$ for the given encoding (binary or Gray).\n    - For binary encoding, $k_{\\text{bin}}$ is the integer value of $c$.\n    - For Gray encoding, $k_{\\text{gray}}$ is obtained by a Gray-to-binary conversion of $c$.\n4.  Calculate the fitness-related term for the current state: $V_{\\text{bin}} = |2k_{\\text{bin}} - M|$ and $V_{\\text{gray}} = |2k_{\\text{gray}} - M|$.\n5.  Iterate through each bit position $j$ from $0$ to $b-1$.\n    a. Determine the new codeword $c'$ by flipping bit $j$ of $c$.\n    b. Decode $c'$ to get the new integer values $k'_{\\text{bin}}$ and $k'_{\\text{gray}}$.\n    c. Calculate the new fitness terms $V'_{\\text{bin}} = |2k'_{\\text{bin}} - M|$ and $V'_{\\text{gray}} = |2k'_{\\text{gray}} - M|$.\n    d. If $V'_{\\text{bin}} < V_{\\text{bin}}$, increment the counter for binary encoding.\n    e. If $V'_{\\text{gray}} < V_{\\text{gray}}$, increment the counter for Gray encoding.\n6.  After iterating through all codewords and bit flips, the total counts $S_{\\text{bin}}$ and $S_{\\text{gray}}$ are obtained.\n7.  The probabilities are then $P_{\\mathrm{improve}}^{\\text{bin}} = S_{\\text{bin}} / (2^b \\cdot b)$ and $P_{\\mathrm{improve}}^{\\text{gray}} = S_{\\text{gray}} / (2^b \\cdot b)$.\n\nThis procedure is implemented exactly in the provided code.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes discretization error and one-step improvement probability for\n    binary and Gray encodings on the sphere function.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, b, L, U)\n        (1, 3, -1.0, 1.0),\n        (5, 4, -1.0, 1.0),\n        (10, 8, -1.0, 1.0),\n        (3, 1, -1.0, 1.0),\n        (2, 12, -1.0, 1.0),\n    ]\n\n    def gray_to_bin_int(g: int) -> int:\n        \"\"\"\n        Converts a Gray-coded integer to its corresponding binary integer value.\n        \"\"\"\n        b = g\n        mask = g >> 1\n        while mask > 0:\n            b ^= mask\n            mask >>= 1\n        return b\n\n    # Store results as formatted strings to match output specification.\n    formatted_results = []\n\n    for n, b, L, U in test_cases:\n        # 1. Discretization Error Calculation\n        # For L = -U, the continuous minimum is 0. The discrete grid point closest to 0\n        # for a coordinate is at |U|/(2^b - 1). The minimum of sum(x_i^2) is n * (|U|/(2^b - 1))^2.\n        # Since all test cases have U=1.0, this simplifies.\n        if (2**b - 1) == 0: # a_val is denominator\n             disc_error = float('inf') if n > 0 else 0.0 # handle b=0 case, though not in tests\n        else:\n             disc_error = n * (U / (2**b - 1))**2\n        \n        # Discretization error is independent of the encoding strategy, as both\n        # cover the same set of phenotype points.\n        d_bin = disc_error\n        d_gray = disc_error\n\n        # 2. One-Step Improvement Probability Calculation\n        improvements_bin = 0\n        improvements_gray = 0\n        num_states = 2**b\n        # Precompute a map from Gray coded integers to binary integers for efficiency.\n        gray_map = {g: gray_to_bin_int(g) for g in range(num_states)}\n        \n        # This value is used for the integer-based fitness comparison\n        # |2k' - M| < |2k - M| to avoid floating point issues.\n        M = num_states - 1\n\n        # Iterate over all possible b-bit codewords (represented as integers 0..2^b-1)\n        for c_int in range(num_states):\n            # For binary encoding, the integer value k is the codeword itself.\n            k_bin = c_int\n            # For Gray encoding, the codeword c_int must be converted to find k.\n            k_gray = gray_map[c_int]\n\n            # Objective value proxy for the current state for each encoding\n            val_bin = abs(2 * k_bin - M)\n            val_gray = abs(2 * k_gray - M)\n\n            # Iterate over all possible single-bit flips\n            for j in range(b):\n                # Flipping the j-th bit is equivalent to XOR with 2^j\n                c_prime_int = c_int ^ (1 << j)\n\n                # --- Binary Encoding ---\n                k_prime_bin = c_prime_int\n                val_prime_bin = abs(2 * k_prime_bin - M)\n                if val_prime_bin < val_bin:\n                    improvements_bin += 1\n\n                # --- Gray Encoding ---\n                k_prime_gray = gray_map[c_prime_int]\n                val_prime_gray = abs(2 * k_prime_gray - M)\n                if val_prime_gray < val_gray:\n                    improvements_gray += 1\n\n        # The total number of possible one-bit mutations for a single coordinate\n        # is the number of states times the number of bits.\n        total_mutations = num_states * b\n        \n        p_bin = improvements_bin / total_mutations if total_mutations > 0 else 0.0\n        p_gray = improvements_gray / total_mutations if total_mutations > 0 else 0.0\n\n        sub_result = [d_bin, d_gray, p_bin, p_gray]\n        result_str = f\"[{','.join(f'{x:.12f}' for x in sub_result)}]\"\n        formatted_results.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "In many real-world applications, from engineering design to financial modeling, the fitness of a solution cannot be measured perfectly. Evaluations may be corrupted by sensor noise, simulation randomness, or subjective human feedback. This practice challenges you to make a Genetic Algorithm robust in the face of such uncertainty . You will implement and test different strategies, such as tournament selection and fitness re-evaluation, to see how they help the algorithm maintain its direction and discover high-quality solutions even when the fitness landscape is noisy. This is a critical skill for moving from textbook examples to practical, real-world problem-solving.",
            "id": "3137379",
            "problem": "You are to implement and compare Genetic Algorithm (GA) selection strategies under noisy fitness evaluations. The fundamental base includes: (i) the definition of a GA population evolving by selection and variation; (ii) the OneMax objective $f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$ for bit-strings $\\mathbf{x} \\in \\{0,1\\}^{L}$; (iii) an observed noisy fitness $\\tilde{f}(\\mathbf{x}) = f(\\mathbf{x}) + \\epsilon$ with $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$; and (iv) the properties of expectations and variances of sums and averages of independent Gaussian variables. You must design a program that runs a GA with noisy evaluation and reports, for a set of specified test cases, the best true fitness found, defined as the maximum of $f(\\mathbf{x})$ observed at any time during the evolutionary run (best-so-far across generations), without noise.\n\nAlgorithmic setting to implement:\n- Representation: Individuals are bit-strings of length $L$ with $L = 24$.\n- Objective: True fitness $f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$.\n- Noisy evaluation: For a given noise standard deviation $\\sigma \\ge 0$, each evaluation draws an independent $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ and returns $\\tilde{f}(\\mathbf{x}) = f(\\mathbf{x}) + \\epsilon$.\n- Re-evaluation and aggregation: To mitigate noise, you may perform $m \\in \\mathbb{N}$ independent evaluations of the same individual, obtaining $\\tilde{f}_1,\\dots,\\tilde{f}_m$, and aggregate them by either the sample mean or the sample median. Denote the aggregate by $g_m(\\mathbf{x})$. For $m=1$, $g_1(\\mathbf{x}) = \\tilde{f}(\\mathbf{x})$. Within each generation, each individual’s aggregate $g_m(\\mathbf{x})$ is computed once and reused for all selection decisions in that generation.\n- Population: Size $N = 80$. Initial population is independent and identically distributed, with each bit sampled from the Bernoulli distribution with probability $1/2$ for $1$.\n- Selection strategies to implement:\n  1. Fitness-proportionate (roulette) selection using aggregated scores $g_m(\\mathbf{x})$: Let $w_i = g_m(\\mathbf{x}^{(i)})$ for the $i$-th individual. Compute shifted nonnegative weights $u_i = \\max\\{w_i - \\min_j w_j + \\delta, \\delta\\}$ for $\\delta = 10^{-9}$ to avoid nonpositive weights. Select $N$ parents with replacement, where the probability of selecting individual $i$ is $u_i / \\sum_{k=1}^{N} u_k$.\n  2. Tournament selection of size $\\tau = 3$ using aggregated scores $g_m(\\mathbf{x})$: To select one parent, sample $\\tau$ distinct indices uniformly from $\\{1,\\dots,N\\}$ and choose the individual with the maximum $g_m(\\mathbf{x})$ among them. Repeat until $N$ parents are selected.\n- Variation: Mutation-only variation. Each selected parent produces exactly one offspring by independent bit-flip mutations with probability $p_m = 1/L$ per bit. No crossover is used.\n- Replacement: Generational replacement. The $N$ offspring form the next generation. No explicit elitism is used. However, for reporting the result, maintain the best-so-far true fitness $\\max f(\\mathbf{x})$ observed across the entire run.\n- Generations: Run for $T = 250$ generations per test case.\n\nMathematical and statistical conventions:\n- All random variates are independent unless stated otherwise. Across different generations, new noise samples are drawn. Within each generation, each individual’s aggregated score $g_m(\\mathbf{x})$ is computed using fresh noise and reused in all selection decisions for that generation.\n- For $m > 1$, the aggregation function is either the sample mean or the sample median of $m$ independent noisy evaluations; both aggregators operate on independent and identically distributed Gaussian samples.\n\nTest suite:\nEach test case is a tuple $(\\sigma, \\text{selection}, m, \\text{aggregator}, s)$ where $\\sigma$ is the noise standard deviation, $\\text{selection}$ is either the string \"roulette\" or \"tournament\", $m$ is the positive integer number of re-evaluations per individual per generation, $\\text{aggregator}$ is either the string \"mean\" or \"median\", and $s$ is the integer seed to initialize a pseudorandom number generator. Use the following parameter sets:\n- Case $1$: $(0, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 42)$.\n- Case $2$: $(2, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 7)$.\n- Case $3$: $(2, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 7)$.\n- Case $4$: $(2, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 7)$.\n- Case $5$: $(6, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 13)$.\n- Case $6$: $(6, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 13)$.\n- Case $7$: $(6, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 13)$.\n- Case $8$: $(6, \\text{\"tournament\"}, 5, \\text{\"median\"}, 13)$.\n\nFor every test case, run the GA described above and return the integer best-so-far true fitness, i.e., the maximum over all individuals ever seen during the run of the exact OneMax score $f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$ without noise. All true-fitness computations are exact and have no noise.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test cases above. For example, the output should look like $[$$r_1$$,$$r_2$$,\\dots,$$r_8$$]$ where each $r_i$ is an integer best-so-far true fitness for case $i$.",
            "solution": "The user-provided problem has been analyzed and validated according to the specified criteria.\n\n### Step 1: Extract Givens\n- **Problem Domain**: Genetic Algorithm (GA) for the OneMax problem under noisy fitness evaluation.\n- **Objective Function (True Fitness)**: $f(\\mathbf{x}) = \\sum_{i=1}^{L} x_i$ for a bit-string $\\mathbf{x} \\in \\{0,1\\}^{L}$.\n- **Noisy Fitness Evaluation**: $\\tilde{f}(\\mathbf{x}) = f(\\mathbf{x}) + \\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$.\n- **GA Parameters**:\n    - Representation: Bit-strings of length $L = 24$.\n    - Population Size: $N = 80$.\n    - Generations: $T = 250$.\n    - Initial Population: Bits are i.i.d. Bernoulli with $p=1/2$.\n    - Variation: Per-bit mutation with probability $p_m = 1/L$. No crossover.\n    - Replacement: Generational replacement (offspring replace parents). No explicit elitism.\n- **Noise Handling**:\n    - Re-evaluation: $m$ independent evaluations per individual per generation.\n    - Aggregation Function ($g_m(\\mathbf{x})$): Sample mean or sample median of the $m$ evaluations. For $m=1$, $g_1(\\mathbf{x}) = \\tilde{f}(\\mathbf{x})$.\n- **Selection Strategies**:\n    1.  **Fitness-Proportionate (Roulette)**: Selects $N$ parents with replacement. Selection probability for individual $i$ is proportional to $u_i = \\max\\{w_i - \\min_j w_j + \\delta, \\delta\\}$, where $w_i = g_m(\\mathbf{x}^{(i)})$ and $\\delta = 10^{-9}$.\n    2.  **Tournament Selection**: Selects one parent by choosing the best individual from a randomly sampled tournament of size $\\tau = 3$. This is repeated $N$ times to form the parent pool.\n- **Reporting Metric**: The best true fitness $f(\\mathbf{x})$ observed across all individuals in all generations of a run (best-so-far).\n- **Test Cases**: A set of $8$ test cases is provided, each defined by a tuple $(\\sigma, \\text{selection}, m, \\text{aggregator}, s)$, where $s$ is the seed for the pseudorandom number generator.\n    - Case 1: $(0, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 42)$\n    - Case 2: $(2, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 7)$\n    - Case 3: $(2, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 7)$\n    - Case 4: $(2, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 7)$\n    - Case 5: $(6, \\text{\"roulette\"}, 1, \\text{\"mean\"}, 13)$\n    - Case 6: $(6, \\text{\"tournament\"}, 1, \\text{\"mean\"}, 13)$\n    - Case 7: $(6, \\text{\"tournament\"}, 5, \\text{\"mean\"}, 13)$\n    - Case 8: $(6, \\text{\"tournament\"}, 5, \\text{\"median\"}, 13)$\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is a standard exercise in computational science, specifically in the domain of evolutionary algorithms. The OneMax problem is a canonical benchmark, and modeling noisy objective functions with additive Gaussian noise is a well-established practice. All specified components (selection, mutation, etc.) are fundamental concepts in GAs. The problem is scientifically sound.\n2.  **Well-Posed**: All parameters ($L, N, T, p_m, \\tau$, etc.) are precisely defined. The initial conditions, termination condition (number of generations), and evaluation procedures are unambiguous. The use of a specific seed for the random number generator for each test case ensures that the stochastic simulation is reproducible, leading to a unique, verifiable solution for each case.\n3.  **Objective**: The problem description uses clear, formal, and objective language, free from any subjective or opinion-based statements.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is self-contained, scientifically sound, well-posed, and objective. There are no contradictions, ambiguities, or missing information. The task is a non-trivial but feasible implementation of a standard scientific simulation. Therefore, I will proceed with providing a complete solution.\n\nThe solution implements a Genetic Algorithm as specified. The core logic is encapsulated within a `run_ga` function that executes one full evolutionary run for a given set of parameters.\n\nThe algorithm proceeds as follows:\n1.  **Initialization**: A random number generator is seeded. The initial population of $N$ bit-strings is created, with each bit being $0$ or $1$ with equal probability. The `best_so_far_fitness` is initialized by computing the true fitness of every individual in this initial population and taking the maximum.\n2.  **Generational Loop**: The algorithm iterates for $T$ generations. In each generation:\n    a. **Evaluation**: For each individual in the current population, an aggregated fitness score $g_m(\\mathbf{x})$ is computed. This involves calculating the true fitness $f(\\mathbf{x})$, adding $m$ independent Gaussian noise variates $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$ to it, and then aggregating the $m$ noisy results using either the sample mean or median. These aggregated scores are stored for the selection step.\n    b. **Selection**: A pool of $N$ parents is selected from the current population based on the aggregated scores. The selection is performed using either the specified roulette wheel or tournament method.\n    c. **Variation**: Each of the $N$ selected parents produces one offspring. The offspring is generated by applying bit-flip mutation to a copy of the parent, where each bit has a probability $p_m = 1/L$ of being flipped.\n    d. **Replacement**: The set of $N$ offspring becomes the population for the next generation.\n    e. **Tracking**: The true fitness of all individuals in the new offspring population is calculated, and `best_so_far_fitness` is updated if a new maximum is found.\n3.  **Result**: After $T$ generations, the final `best_so_far_fitness` is returned as an integer.\n\nThe main script defines the test cases and iterates through them, calling `run_ga` for each one and collecting the results. Finally, it prints the results in the specified comma-separated format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define, run, and print the results of the GA test suite.\n    \"\"\"\n\n    def noisy_evaluation(true_f, sigma, m, aggregator, rng):\n        \"\"\"\n        Computes the aggregated noisy fitness score for an individual.\n        \n        Args:\n            true_f (float): The true fitness of the individual.\n            sigma (float): The standard deviation of the Gaussian noise.\n            m (int): The number of re-evaluations.\n            aggregator (str): The aggregation method ('mean' or 'median').\n            rng (np.random.Generator): The random number generator.\n            \n        Returns:\n            float: The aggregated noisy fitness score.\n        \"\"\"\n        if sigma == 0.0:\n            return true_f\n        \n        # Generate m independent noisy samples\n        noisy_samples = rng.normal(loc=true_f, scale=sigma, size=m)\n        \n        if m == 1:\n            return noisy_samples[0]\n        \n        if aggregator == \"mean\":\n            return np.mean(noisy_samples)\n        elif aggregator == \"median\":\n            return np.median(noisy_samples)\n        else:\n            # This path should not be reached with the given test cases.\n            raise ValueError(\"Invalid aggregator specified.\")\n\n    def roulette_selection(aggregated_scores, N, rng):\n        \"\"\"\n        Performs fitness-proportionate (roulette) selection.\n        \n        Args:\n            aggregated_scores (np.ndarray): Array of scores for the population.\n            N (int): Population size.\n            rng (np.random.Generator): The random number generator.\n        \n        Returns:\n            np.ndarray: An array of N selected parent indices.\n        \"\"\"\n        delta = 1e-9\n        # Shift scores to be non-negative to create weights.\n        # u_i = max{w_i - min_j w_j + delta, delta}\n        min_score = np.min(aggregated_scores)\n        weights = np.maximum(aggregated_scores - min_score + delta, delta)\n        \n        # Normalize weights to get selection probabilities.\n        sum_weights = np.sum(weights)\n        if sum_weights == 0:\n            # Uniform selection if all weights are zero (highly unlikely).\n            probabilities = np.full(N, 1.0 / N)\n        else:\n            probabilities = weights / sum_weights\n            \n        parent_indices = rng.choice(N, size=N, replace=True, p=probabilities)\n        return parent_indices\n\n    def tournament_selection(aggregated_scores, N, tau, rng):\n        \"\"\"\n        Performs tournament selection.\n        \n        Args:\n            aggregated_scores (np.ndarray): Array of scores for the population.\n            N (int): Population size.\n            tau (int): Tournament size.\n            rng (np.random.Generator): The random number generator.\n        \n        Returns:\n            np.ndarray: An array of N selected parent indices.\n        \"\"\"\n        parent_indices = np.zeros(N, dtype=int)\n        for i in range(N):\n            # Select tau distinct individuals for the tournament.\n            contender_indices = rng.choice(N, size=tau, replace=False)\n            contender_scores = aggregated_scores[contender_indices]\n            \n            # The winner is the one with the highest aggregated score.\n            winner_local_index = np.argmax(contender_scores)\n            winner_global_index = contender_indices[winner_local_index]\n            parent_indices[i] = winner_global_index\n            \n        return parent_indices\n\n    def mutation(parents, L, p_m, rng):\n        \"\"\"\n        Applies bit-flip mutation to a set of parents to create offspring.\n        \n        Args:\n            parents (np.ndarray): A (N, L) array of parent bit-strings.\n            L (int): The length of the bit-strings.\n            p_m (float): The per-bit mutation probability.\n            rng (np.random.Generator): The random number generator.\n            \n        Returns:\n            np.ndarray: A (N, L) array of offspring bit-strings.\n        \"\"\"\n        # Create a boolean mask for mutations. True indicates a flip.\n        mutation_mask = rng.random(size=parents.shape) < p_m\n        # Apply mutation using XOR operator.\n        offspring = parents ^ mutation_mask\n        return offspring.astype(np.int8)\n\n    def run_ga(L, N, T, sigma, selection_strat, m, aggregator, s):\n        \"\"\"\n        Runs a full Genetic Algorithm simulation for a single test case.\n        \n        Args:\n            L, N, T: GA structural parameters.\n            sigma, selection_strat, m, aggregator, s: Test case parameters.\n            \n        Returns:\n            int: The best-so-far true fitness found during the run.\n        \"\"\"\n        # --- Setup ---\n        rng = np.random.default_rng(s)\n        p_m = 1.0 / L\n        tau = 3  # Tournament size\n\n        # --- 1. Initialization ---\n        population = rng.integers(0, 2, size=(N, L), dtype=np.int8)\n        \n        # Calculate true fitness for the initial population (gen 0)\n        true_fitnesses = np.sum(population, axis=1)\n        best_so_far_fitness = np.max(true_fitnesses)\n\n        # --- 2. Generational Loop ---\n        for _ in range(T):\n            # --- a. Evaluation ---\n            # Calculate true fitnesses once per generation for noise calculation.\n            current_true_fitnesses = np.sum(population, axis=1)\n            \n            # Compute aggregated noisy scores for the current population.\n            aggregated_scores = np.array([\n                noisy_evaluation(f, sigma, m, aggregator, rng) for f in current_true_fitnesses\n            ])\n\n            # --- b. Selection ---\n            if selection_strat == \"roulette\":\n                parent_indices = roulette_selection(aggregated_scores, N, rng)\n            else:  # tournament\n                parent_indices = tournament_selection(aggregated_scores, N, tau, rng)\n            \n            parents = population[parent_indices]\n\n            # --- c. Variation ---\n            offspring = mutation(parents, L, p_m, rng)\n\n            # --- d. Replacement ---\n            population = offspring\n\n            # --- e. Update Best-So-Far ---\n            # The new population's individuals have been \"seen,\" so check their true fitness.\n            true_fitnesses_offspring = np.sum(population, axis=1)\n            current_max_true = np.max(true_fitnesses_offspring)\n            if current_max_true > best_so_far_fitness:\n                best_so_far_fitness = current_max_true\n        \n        return int(best_so_far_fitness)\n\n    # --- Main ---\n    # Global parameters for the GA.\n    L = 24\n    N = 80\n    T = 250\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (sigma, selection, m, aggregator, seed)\n        (0.0, \"roulette\", 1, \"mean\", 42),\n        (2.0, \"roulette\", 1, \"mean\", 7),\n        (2.0, \"tournament\", 1, \"mean\", 7),\n        (2.0, \"tournament\", 5, \"mean\", 7),\n        (6.0, \"roulette\", 1, \"mean\", 13),\n        (6.0, \"tournament\", 1, \"mean\", 13),\n        (6.0, \"tournament\", 5, \"mean\", 13),\n        (6.0, \"tournament\", 5, \"median\", 13),\n    ]\n\n    results = []\n    for case in test_cases:\n        sigma, selection, m, aggregator, s_seed = case\n        result = run_ga(L, N, T, sigma, selection, m, aggregator, s_seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}