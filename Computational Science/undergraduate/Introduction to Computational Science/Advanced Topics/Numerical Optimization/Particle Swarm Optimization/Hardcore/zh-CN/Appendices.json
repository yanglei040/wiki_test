{
    "hands_on_practices": [
        {
            "introduction": "任何基于群体的优化器都面临一个共同的挑战，即过早收敛，此时整个群体都陷入了搜索空间的次优区域。本练习将首先指导您刻意创建一个场景，让粒子群优化（PSO）算法陷入局部最优，从而让您对这种失效模式有直观的理解。接着，您将实现一种多样化策略，帮助粒子群逃离陷阱，找到全局最优解。",
            "id": "3160999",
            "problem": "您需要设计并实现一个一维粒子群优化（PSO）实验，该实验需展示一种最坏情况下的初始化，它会将粒子群困在一个严格的局部吸引盆地中，然后通过引入具有时变概率的随机跳跃来实现多样化，以缓解这种失效模式。您的程序必须模拟经典的PSO动态过程，并报告一个小型测试套件的量化结果。\n\n其基本原理是经典的PSO状态更新，在此重述。设在一维空间中有 $N$ 个粒子，粒子 $i$ 在时间 $t$ 的状态由其位置 $x_{i,t} \\in \\mathbb{R}$ 和速度 $v_{i,t} \\in \\mathbb{R}$ 给出。每个粒子都维持其个体最优位置 $p_{i,t}$，而整个粒子群则维持一个全局最优位置 $g_t$。经典更新公式如下\n$$\nv_{i,t+1} \\leftarrow \\omega\\, v_{i,t} \\;+\\; c_1\\, r_{1,i,t}\\, \\big(p_{i,t} - x_{i,t}\\big) \\;+\\; c_2\\, r_{2,i,t}\\, \\big(g_t - x_{i,t}\\big),\n$$\n$$\nx_{i,t+1} \\leftarrow x_{i,t} + v_{i,t+1},\n$$\n其中 $r_{1,i,t}, r_{2,i,t} \\sim \\mathrm{Uniform}([0,1])$ 是独立的随机变量。更新 $x_{i,t+1}$ 后，评估目标函数 $f(x_{i,t+1})$ 以标准方式更新 $p_{i,t+1}$ 和 $g_{t+1}$：当且仅当 $f(x_{i,t+1})  f(p_{i,t})$ 时，$p_{i,t+1}$ 替代 $p_{i,t}$；而 $g_{t+1}$ 是 $\\{p_{i,t+1}\\}_{i=1}^N$ 中的最优值。\n\n目标函数是一个光滑的多峰函数\n$$\nf(x) \\;=\\; x^2 \\;-\\; b \\exp\\!\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n$$\n参数为 $b = 12$、$\\mu = 4$ 和 $\\sigma = 0.5$。搜索域是闭区间 $\\mathcal{D} = [-L,L]$，其中 $L = 6$。每次更新后，位置必须被裁剪到 $\\mathcal{D}$ 范围内。\n\n导致陷入陷阱的最坏情况初始化：将所有粒子的位置初始化在 $x \\approx \\mu$ 附近的浅层局部吸引盆地中。具体而言，对于某个 $\\delta  0$，独立地从 $\\mathrm{Uniform}([\\mu - \\delta, \\mu + \\delta])$ 中采样 $x_{i,0}$，并设置 $v_{i,0} = 0$，$p_{i,0} = x_{i,0}$，以及将 $g_0$ 设为 $\\{p_{i,0}\\}$ 中的最优值。使用 $\\delta = 0.2$。这种构造确保了初始时对所有 $i$ 都有 $p_{i,0} - x_{i,0} = 0$，并且 $g_0$ 也位于同一个浅层吸引盆地中。\n\n通过随机跳跃实现多样化：在通过经典更新计算出 $x_{i,t+1}$ 之后、评估 $f(x_{i,t+1})$ 之前，对每个粒子 $i$ 独立地应用以下规则。以概率 $\\pi(t)$，从 $\\mathrm{Uniform}(\\mathcal{D})$ 中抽取一个新位置 $\\tilde{x}_{i,t+1}$，并设置 $x_{i,t+1} \\leftarrow \\tilde{x}_{i,t+1}$ 和 $v_{i,t+1} \\leftarrow 0$。否则，保持 $x_{i,t+1}$ 和 $v_{i,t+1}$ 不变。然后如上所述评估 $f(x_{i,t+1})$ 并更新 $p_{i,t+1}$ 和 $g_{t+1}$。这种多样化通过使得跳跃后的 $p_{i,t} - x_{i,t}$ 和 $g_t - x_{i,t}$ 非零，从而注入了探索能力，即使粒子群先前处于停滞状态。\n\n算法要求：\n- 根据每个测试用例的规定，使用带有参数 $\\omega$、$c_1$ 和 $c_2$ 的经典PSO更新。\n- 对所有测试用例使用上述相同的初始化机制，但使用所提供的不同随机种子。\n- 所有随机数，包括初始位置、$r_{1,i,t}$、$r_{2,i,t}$ 以及随机跳跃，都必须由一个按规定植入种子的可复现伪随机数生成器生成。\n- 每次位置更新和任何应用的跳跃之后，将位置裁剪到 $\\mathcal{D}$ 范围内。\n- 目标函数 $f(x)$ 必须按照其定义精确评估。本问题不涉及任何物理单位或角度。\n\n测试套件：实现五个测试用例，每个用例由一个元组 $(N, T, \\omega, c_1, c_2, \\pi(\\cdot), \\text{seed})$ 定义。概率调度 $\\pi(t)$ 是离散迭代索引 $t \\in \\{0,1,\\dots,T-1\\}$ 的函数。\n\n- 用例A（无多样化，多粒子）：$N = 20$，$T = 80$，$\\omega = 0.6$，$c_1 = 1.7$，$c_2 = 1.7$，$\\pi(t) \\equiv 0$，$\\text{seed} = 123$。\n- 用例B（恒定多样化，多粒子）：$N = 20$，$T = 80$，$\\omega = 0.6$，$c_1 = 1.7$，$c_2 = 1.7$，$\\pi(t) \\equiv 0.05$，$\\text{seed} = 123$。\n- 用例C（退火多样化）：$N = 10$，$T = 120$，$\\omega = 0.7$，$c_1 = 1.5$，$c_2 = 1.5$，$\\pi(t) = 0.3 \\cdot \\big(1 - \\frac{t}{T}\\big)$，$\\text{seed} = 456$。\n- 用例D（边缘用例，单粒子，无多样化）：$N = 1$，$T = 120$，$\\omega = 0.7$，$c_1 = 1.5$，$c_2 = 1.5$，$\\pi(t) \\equiv 0$，$\\text{seed} = 789$。\n- 用例E（边缘用例，单粒子，恒定多样化）：$N = 1$，$T = 120$，$\\omega = 0.7$，$c_1 = 1.5$，$c_2 = 1.5$，$\\pi(t) \\equiv 0.2$，$\\text{seed} = 789$。\n\n对于所有用例，使用相同的目标函数参数 $b = 12$，$\\mu = 4$，$\\sigma = 0.5$，定义域半宽度 $L = 6$ 和初始化宽度 $\\delta = 0.2$。\n\n所需输出：\n- 对于每个测试用例，运行PSO进行 $T$ 次迭代，并报告最终的最优目标值 $\\min_{i} f(p_{i,T})$，结果为浮点数，四舍五入到四位小数。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$\\,[\\text{result}_1,\\text{result}_2,\\dots]$）。顺序必须是 $[\\text{用例 A}, \\text{用例 B}, \\text{用例 C}, \\text{用例 D}, \\text{用例 E}]$。",
            "solution": "该问题提出了一个在优化方法领域内定义明确且可通过计算验证的任务，特别关注粒子群优化（PSO）。所有参数、方程和实验条件都得到了明确定义，使得该问题有效且不存在科学或逻辑上的不一致性。该设置旨在展示PSO的一种常见失效模式——过早收敛到局部最优解——以及一种使用概率性多样化机制的缓解策略。\n\n问题的核心是在几种参数配置下模拟一维PSO算法。该算法的目标是找到函数 $f(x)$ 的全局最小值：\n$$\nf(x) = x^2 - b \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n$$\n参数为 $b = 12$, $\\mu = 4$, 和 $\\sigma = 0.5$，搜索域为 $\\mathcal{D} = [-6, 6]$。该函数在 $x=0$ 附近有一个全局最小值，其值为 $f(x) \\approx 0$（更精确地，在 $x \\approx 0$ 处，$f(x)$ 的值是一个非常接近于零的负数）；在 $x \\approx 3.818$ 附近有一个显著的局部最小值，其值为 $f(x) \\approx 3.35$。\n\n算法过程将按如下方式实现，并遵循向量化原则以提高计算效率。\n\n**1. 系统状态与初始化**\n\n$N$ 个粒子组成的粒子群的状态由它们的位置 $x \\in \\mathbb{R}^N$ 和速度 $v \\in \\mathbb{R}^N$ 定义。每个粒子还记录其迄今为止找到的个体最优位置 $p_{best} \\in \\mathbb{R}^N$ 和相应的目标函数值 $f_{p_{best}} \\in \\mathbb{R}^N$。整个粒子群共同维护全局最优位置 $g_{best} \\in \\mathbb{R}$，即所有 $f_{p_{best}}$ 中的最小值所对应的个体最优位置。\n\n初始化被专门设计用来困住粒子群。所有粒子位置 $x_i$（其中 $i=1, \\dots, N$）均从均匀分布 $\\mathrm{Uniform}([\\mu - \\delta, \\mu + \\delta])$（即 $[3.8, 4.2]$）中抽取。该区域构成了局部最小值的吸引盆地。初始速度设为零，$v_{i,0}=0$。初始个体最优位置设为初始位置，$p_{best; i,0} = x_{i,0}$，而初始全局最优值 $g_{best,0}$ 则通过在这些初始位置上找到 $f(x)$ 的最小值来确定。一个根据各用例规定植入种子的可复现伪随机数生成器，确保了确定性的结果。\n\n**2. 迭代动力学**\n\n模拟进行 $T$ 个离散时间步（迭代）。在每个时间步 $t$，状态被更新至 $t+1$。\n\n**2.1. 速度与位置更新**\n\n经典PSO算法的核心是更新每个粒子的速度和位置。使用向量化表示，从时间 $t$ 到 $t+1$ 的更新如下：\n$$\nv_{t+1} \\leftarrow \\omega v_t + c_1 r_{1,t} \\odot (p_{best,t} - x_t) + c_2 r_{2,t} \\odot (g_{best,t} - x_t)\n$$\n$$\nx_{t+1} \\leftarrow x_t + v_{t+1}\n$$\n其中 $\\omega$、$c_1$ 和 $c_2$ 分别是惯性权重、认知系数和社会系数。符号 $r_{1,t}, r_{2,t} \\in \\mathbb{R}^N$ 表示从 $\\mathrm{Uniform}([0,1])$ 中独立抽取的随机数向量。运算符 $\\odot$ 表示逐元素乘法。\n\n**2.2. 通过随机跳跃实现多样化**\n\n为了对抗过早收敛，引入了随机跳跃机制。在位置更新后，对每个粒子 $i$ 作出一个随机决策。以时变概率 $\\pi(t)$，粒子的状态被重置：其位置 $x_{i,t+1}$ 被一个从整个搜索域 $\\mathcal{D}$ 中均匀抽取的新位置替换，其速度 $v_{i,t+1}$ 被重置为 $0$。这一行动打破了粒子与群体共识的联系，并强制其探索新区域。\n\n**2.3. 边界强制**\n\n在位置更新和任何可能的随机跳跃之后，所有粒子位置都必须被限制在搜索域 $\\mathcal{D} = [-L, L]$ 内。这是通过将位置向量 $x_{t+1}$ 中的值裁剪到 $[-6, 6]$ 范围来实现的。\n\n**2.4. 适应度评估与最优位置更新**\n\n对所有新的粒子位置 $x_{t+1}$ 评估目标函数 $f(x)$，以获得当前适应度值的向量 $f_{current}$。对于每个粒子 $i$，如果其新的适应度 $f_{current, i}$ 优于（即小于）其先前的个体最优适应度 $f_{p_{best}, i}$，则其个体最优值将被更新：$p_{best, i, t+1} \\leftarrow x_{i,t+1}$ 且 $f_{p_{best}, i, t+1} \\leftarrow f_{current, i}$。否则，它们保持不变。\n\n在更新完所有个体最优值之后，通过在更新后的集合 $\\{f_{p_{best}, i, t+1}\\}$ 中找到拥有全局最小个体最优值的粒子，来确定新的全局最优位置 $g_{best,t+1}$。\n\n**3. 模拟执行与输出**\n\n对问题陈述中定义的五个测试用例中的每一个都执行这整个迭代过程。每个用例都指定了参数 $(N, T, \\omega, c_1, c_2, \\pi(t), \\text{seed})$ 的唯一组合。经过 $T$ 次迭代后，记录下粒子群找到的最终最优目标值，即 $\\min_{i} f(p_{best, i, T})$。最终输出是这些值的列表，每个测试用例一个值，格式化为四位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the PSO simulation for all test cases and print results.\n    \"\"\"\n    # Fixed parameters from the problem statement\n    B_PARAM = 12.0\n    MU_PARAM = 4.0\n    SIGMA_PARAM = 0.5\n    L_PARAM = 6.0\n    DELTA_PARAM = 0.2\n\n    def objective_function(x, b=B_PARAM, mu=MU_PARAM, sigma=SIGMA_PARAM):\n        \"\"\"\n        Calculates the value of the objective function f(x).\n        \"\"\"\n        return x**2 - b * np.exp(-((x - mu)**2) / (2 * sigma**2))\n\n    def run_pso_simulation(N, T, omega, c1, c2, pi_func, seed):\n        \"\"\"\n        Runs a single PSO simulation with the given parameters.\n        \n        Args:\n            N (int): Number of particles.\n            T (int): Number of iterations.\n            omega (float): Inertia weight.\n            c1 (float): Cognitive coefficient.\n            c2 (float): Social coefficient.\n            pi_func (callable): Function pi(t, T) for jump probability.\n            seed (int): Seed for the random number generator.\n            \n        Returns:\n            float: The best objective value found after T iterations.\n        \"\"\"\n        # Initialize the pseudo-random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # 1. Initialization\n        # Initial positions are sampled near the local minimum trap\n        x = rng.uniform(MU_PARAM - DELTA_PARAM, MU_PARAM + DELTA_PARAM, size=N)\n        \n        # Initial velocities are zero\n        v = np.zeros(N)\n        \n        # Personal best positions initialized to starting positions\n        p_best_pos = np.copy(x)\n        \n        # Personal best values are f(p_best_pos)\n        p_best_val = objective_function(p_best_pos)\n        \n        # Global best position is the one with the minimum initial value\n        g_best_idx = np.argmin(p_best_val)\n        g_best_pos = p_best_pos[g_best_idx]\n        \n        # 2. Main PSO loop\n        for t in range(T):\n            # Generate random numbers for this iteration's updates\n            r1 = rng.random(size=N)\n            r2 = rng.random(size=N)\n            \n            # Canonical PSO updates (vectorized for efficiency)\n            # Velocity update\n            v = omega * v + c1 * r1 * (p_best_pos - x) + c2 * r2 * (g_best_pos - x)\n            \n            # Position update\n            x = x + v\n            \n            # Diversification via random jumps\n            pi_t = pi_func(t, T)\n            if pi_t > 0:\n                jump_rand = rng.random(size=N)\n                jump_mask = jump_rand  pi_t\n                \n                if np.any(jump_mask):\n                    num_jumps = np.sum(jump_mask)\n                    # Draw new positions for jumping particles\n                    x[jump_mask] = rng.uniform(-L_PARAM, L_PARAM, size=num_jumps)\n                    # Reset velocity for jumping particles\n                    v[jump_mask] = 0.0\n\n            # Clipping positions to the search domain [-L, L]\n            x = np.clip(x, -L_PARAM, L_PARAM)\n            \n            # Evaluate objective function for new positions\n            f_x = objective_function(x)\n            \n            # Update personal bests\n            improvement_mask = f_x  p_best_val\n            p_best_pos[improvement_mask] = x[improvement_mask]\n            p_best_val[improvement_mask] = f_x[improvement_mask]\n            \n            # Update global best\n            g_best_idx = np.argmin(p_best_val)\n            g_best_pos = p_best_pos[g_best_idx]\n            \n        # After T iterations, return the best objective value found by any particle,\n        # which is the minimum of the final personal best values.\n        return np.min(p_best_val)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: (N, T, omega, c1, c2, pi_func, seed) - No diversification\n        {'N': 20, 'T': 80, 'omega': 0.6, 'c1': 1.7, 'c2': 1.7, 'pi_func': lambda t, T_max: 0.0, 'seed': 123},\n        # Case B: Constant diversification\n        {'N': 20, 'T': 80, 'omega': 0.6, 'c1': 1.7, 'c2': 1.7, 'pi_func': lambda t, T_max: 0.05, 'seed': 123},\n        # Case C: Annealed diversification\n        {'N': 10, 'T': 120, 'omega': 0.7, 'c1': 1.5, 'c2': 1.5, 'pi_func': lambda t, T_max: 0.3 * (1 - t / T_max), 'seed': 456},\n        # Case D: Single particle, no diversification\n        {'N': 1, 'T': 120, 'omega': 0.7, 'c1': 1.5, 'c2': 1.5, 'pi_func': lambda t, T_max: 0.0, 'seed': 789},\n        # Case E: Single particle, constant diversification\n        {'N': 1, 'T': 120, 'omega': 0.7, 'c1': 1.5, 'c2': 1.5, 'pi_func': lambda t, T_max: 0.2, 'seed': 789},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_pso_simulation(**case)\n        results.append(f\"{result:.4f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "大多数现实世界的优化问题都涉及约束，定义了一个特定的可行搜索空间。一个关键问题是如何处理试图飞出这些边界的粒子。本练习探讨了三种常见的边界处理技术——吸收、反射和随机重启——让您能够比较它们对粒子群行为及其收敛能力的影响，特别是当最优解位于边界附近时。",
            "id": "3161093",
            "problem": "考虑在一个超矩形上对位移球目标函数进行有界最小化。设 $d \\in \\mathbb{N}$，下界和上界分别为 $l \\in \\mathbb{R}$ 和 $u \\in \\mathbb{R}$，且 $l  u$，位移向量为 $\\mathbf{a} \\in \\mathbb{R}^d$。定义目标函数为 $$f(\\mathbf{x}) = \\sum_{j=1}^{d} (x_j - a_j)^2,$$ 可行集为 $$\\Omega = [l,u]^d = \\{\\mathbf{x} \\in \\mathbb{R}^d \\mid \\forall j \\in \\{1,\\dots,d\\}, \\, l \\le x_j \\le u\\}.$$ 无约束最小化解为 $\\mathbf{x}^\\star = \\mathbf{a}$，此时 $f(\\mathbf{x}^\\star) = 0$。在箱形约束下，最小化解是 $\\mathbf{a}$ 在 $\\Omega$ 上的逐分量投影，即对每个 $j$ 有 $\\tilde{a}_j = \\min(\\max(a_j, l), u)$，得到 $\\mathbf{x}^\\star_\\Omega = \\tilde{\\mathbf{a}}$。\n\n您的任务是实现一个完整、可运行的程序，使用粒子群优化 (PSO) 算法在 $\\Omega$ 上最小化 $f(\\mathbf{x})$，并检验三种边界处理方案对可行性和收敛性的影响。粒子群优化 (PSO) 算法维护一个由 $N$ 个粒子组成的粒子群，在迭代次数为 $t$ 时，粒子的位置为 $\\mathbf{x}_i(t) \\in \\mathbb{R}^d$，速度为 $\\mathbf{v}_i(t) \\in \\mathbb{R}^d$。每个粒子会跟踪其个体最佳位置 $\\mathbf{p}_i(t)$，粒子群会跟踪全局最佳位置 $\\mathbf{g}(t)$。在每次迭代 $t$ 中，速度和位置根据标准的惯性 PSO 更新规则演化，其中 $$\\mathbf{v}_i(t+1) = w \\, \\mathbf{v}_i(t) + c_1 \\, \\mathbf{r}_1(t) \\odot (\\mathbf{p}_i(t) - \\mathbf{x}_i(t)) + c_2 \\, \\mathbf{r}_2(t) \\odot (\\mathbf{g}(t) - \\mathbf{x}_i(t)),$$ $$\\mathbf{x}_i(t+1) = \\mathbf{x}_i(t) + \\mathbf{v}_i(t+1),$$ 其中 $w \\in \\mathbb{R}$ 为惯性权重，$c_1 \\in \\mathbb{R}$ 和 $c_2 \\in \\mathbb{R}$ 分别为认知系数和社会系数，$\\mathbf{r}_1(t), \\mathbf{r}_2(t) \\in [0,1]^d$ 为从均匀分布中逐分量抽取的独立随机向量。算子 $\\odot$ 表示逐分量相乘。对于给定的 $v_{\\max} \\in \\mathbb{R}_{0}$，速度被逐分量限制在 $[-v_{\\max}, v_{\\max}]$ 区间内。初始位置在 $\\Omega$ 上均匀抽取，初始速度在 $[-v_{\\max}, v_{\\max}]^d$ 上均匀抽取。仅当观察到严格更小的目标函数值时，个体和全局最优值才会更新。\n\n当尝试的位置 $\\mathbf{x}_i^{\\mathrm{prop}}(t+1) = \\mathbf{x}_i(t) + \\mathbf{v}_i(t+1)$ 落在 $\\Omega$ 之外时，需要进行边界处理。请实现以下三种方案，每种方案对每个分量 $j$ 独立作用：\n\n- 反射 (Reflect)：如果 $x_{ij}^{\\mathrm{prop}} \\notin [l,u]$，则通过计算以下公式在区间 $[l,u]$ 上使用反射映射：$$z = \\frac{x_{ij}^{\\mathrm{prop}} - l}{u - l}, \\quad k = \\left\\lfloor z \\right\\rfloor, \\quad z_{\\mathrm{frac}} = z - k.$$ 设置 $$x_{ij}(t+1) = \\begin{cases} l + z_{\\mathrm{frac}}(u - l)  \\text{若 } k \\text{ 为偶数}, \\\\ u - z_{\\mathrm{frac}}(u - l)  \\text{若 } k \\text{ 为奇数}, \\end{cases}$$ 并在 $k$ 为奇数时翻转速度分量，即 $$v_{ij}(t+1) = \\begin{cases} v_{ij}(t+1)  \\text{若 } k \\text{ 为偶数}, \\\\ -v_{ij}(t+1)  \\text{若 } k \\text{ 为奇数}。 \\end{cases}$$ 如果 $x_{ij}^{\\mathrm{prop}} \\in [l,u]$，则保持 $x_{ij}(t+1) = x_{ij}^{\\mathrm{prop}}$ 和 $v_{ij}(t+1)$ 不变。\n\n- 吸收 (Absorb)：如果 $x_{ij}^{\\mathrm{prop}}  l$，则设置 $x_{ij}(t+1) = l$ 和 $v_{ij}(t+1) = 0$。如果 $x_{ij}^{\\mathrm{prop}}  u$，则设置 $x_{ij}(t+1) = u$ 和 $v_{ij}(t+1) = 0$。如果 $x_{ij}^{\\mathrm{prop}} \\in [l,u]$，则保持 $x_{ij}(t+1) = x_{ij}^{\\mathrm{prop}}$ 和 $v_{ij}(t+1)$ 不变。\n\n- 随机重启 (Random restart)：如果 $x_{ij}^{\\mathrm{prop}} \\notin [l,u]$，则将 $x_{ij}(t+1)$ 设置为从 $[l,u]$ 中均匀抽取的一个新值，并设置 $v_{ij}(t+1) = 0$。如果 $x_{ij}^{\\mathrm{prop}} \\in [l,u]$，则保持 $x_{ij}(t+1) = x_{ij}^{\\mathrm{prop}}$ 和 $v_{ij}(t+1)$ 不变。\n\n将可行性度量定义为运行过程中的尝试可行率，即：$$r_{\\mathrm{feasible}} = \\frac{\\text{提议 } \\mathbf{x}_i^{\\mathrm{prop}}(t+1) \\in \\Omega \\text{ 的数量}}{\\text{提议总数}} = \\frac{\\#\\{(i,t) \\mid \\mathbf{x}_i(t) + \\mathbf{v}_i(t+1) \\in \\Omega\\}}{N \\cdot T},$$ 其中 $T \\in \\mathbb{N}$ 是总迭代次数。\n\n通过容差 $\\varepsilon \\in \\mathbb{R}_{0}$ 定义收敛条件：如果在迭代 $t^\\star$ 时满足以下条件，则称运行在 $t^\\star$ 收敛：$$\\min_{i} f(\\mathbf{p}_i(t^\\star)) \\le \\varepsilon.$$ 记录此条件是否满足以及满足条件的最早 $t^\\star$，如果从未满足，则 $t^\\star = -1$。同时记录最终的最佳目标值 $$f^\\star = \\min_{i} f(\\mathbf{p}_i(T)).$$\n\n请实现带有上述边界处理和度量指标的 PSO 算法。为每个测试用例的随机数生成器使用独立且固定的种子，以确保可复现性。不涉及物理单位。所有角度（如有）均不适用。\n\n要实现的测试套件和参数：\n\n- 案例 1 (理想情况，反射)：$d=5$, $l=-5$, $u=5$, $a = [1.5, -2.0, 0.5, -1.0, 2.0]$, $N=30$, $T=200$, $w=0.7$, $c_1=1.5$, $c_2=1.5$, $v_{\\max}=5$, 边界方案 = 反射, 种子 $=42$, $\\varepsilon = 10^{-6}$。\n\n- 案例 2 (靠近上边界，吸收)：$d=5$, $l=-5$, $u=5$, $a = [4.9, 4.8, 4.7, 4.6, 4.5]$, $N=30$, $T=200$, $w=0.7$, $c_1=1.5$, $c_2=1.5$, $v_{\\max}=5$, 边界方案 = 吸收, 种子 $=123$, $\\varepsilon = 10^{-6}$。\n\n- 案例 3 (域内零值不可达，随机重启)：$d=5$, $l=-2$, $u=2$, $a = [10.0, 10.0, 10.0, 10.0, 10.0]$, $N=40$, $T=300$, $w=0.8$, $c_1=1.7$, $c_2=1.7$, $v_{\\max}=4$, 边界方案 = 随机重启, 种子 $=7$, $\\varepsilon = 10^{-6}$。\n\n- 案例 4 (低维度，过冲，反射)：$d=2$, $l=-1$, $u=1$, $a = [0.99, -0.99]$, $N=10$, $T=150$, $w=0.9$, $c_1=2.05$, $c_2=2.05$, $v_{\\max}=2$, 边界方案 = 反射, 种子 $=999$, $\\varepsilon = 10^{-6}$。\n\n- 案例 5 (小定义域，吸收)：$d=3$, $l=0$, $u=1$, $a = [0.9, 0.1, 0.5]$, $N=12$, $T=150$, $w=0.6$, $c_1=1.4$, $c_2=1.4$, $v_{\\max}=1$, 边界方案 = 吸收, 种子 $=2024$, $\\varepsilon = 10^{-6}$。\n\n最终输出格式：\n\n您的程序应生成一行输出，包含一个用方括号括起来的逗号分隔列表，其中每个结果本身是测试用例（按给定顺序）的列表 $[f^\\star, r_{\\mathrm{feasible}}, \\text{converged}, t^\\star]$。例如，输出应如下所示：$$[[f^\\star_1, r_{\\mathrm{feasible},1}, \\text{converged}_1, t^\\star_1], [f^\\star_2, r_{\\mathrm{feasible},2}, \\text{converged}_2, t^\\star_2], \\dots].$$ 类型必须如下：$f^\\star$ 是一个实数（浮点数），$r_{\\mathrm{feasible}}$ 是一个在 $[0,1]$ 内的实数（浮点数），$\\text{converged}$ 是一个布尔值，$t^\\star$ 是一个整数，其中 $-1$ 表示在 $T$ 次迭代内未收敛。",
            "solution": "我们正在最小化位移球函数 $$f(\\mathbf{x}) = \\sum_{j=1}^{d} (x_j - a_j)^2$$，其约束条件为箱形约束 $\\mathbf{x} \\in \\Omega = [l,u]^d$。位移球函数是严格凸函数，在 $\\mathbf{x}^\\star = \\mathbf{a}$ 处有唯一的无约束最小化解。在箱形约束下，最小化解是 $\\mathbf{a}$ 在 $\\Omega$ 上的投影，因此约束最小化解为 $\\mathbf{x}^\\star_\\Omega = \\tilde{\\mathbf{a}}$，其中对每个 $j$ 有 $\\tilde{a}_j = \\min(\\max(a_j, l), u)$，最小目标值为 $$f(\\mathbf{x}^\\star_\\Omega) = \\sum_{j=1}^{d} (\\tilde{a}_j - a_j)^2.$$ 如果 $\\mathbf{a} \\in \\Omega$，则 $\\mathbf{x}^\\star_\\Omega = \\mathbf{a}$ 且 $f(\\mathbf{x}^\\star_\\Omega) = 0$；如果 $\\mathbf{a}$ 的任何分量超出边界，则 $\\Omega$ 内的最小值严格为正。\n\n粒子群优化 (PSO)是一种基于群体的随机优化方法。它维护一个由 $N$ 个粒子组成的集合，每个粒子在迭代 $t$ 时都有位置 $\\mathbf{x}_i(t) \\in \\mathbb{R}^d$ 和速度 $\\mathbf{v}_i(t) \\in \\mathbb{R}^d$。更新规则融合了惯性、向粒子个体最优 $\\mathbf{p}_i(t)$ 的吸引力以及向全局最优 $\\mathbf{g}(t)$ 的吸引力。这种设计体现了两个基本原则：通过惯性和随机性进行探索，以及通过吸引到已知的良解进行利用。标准的惯性PSO更新公式为 $$\\mathbf{v}_i(t+1) = w \\, \\mathbf{v}_i(t) + c_1 \\, \\mathbf{r}_1(t) \\odot (\\mathbf{p}_i(t) - \\mathbf{x}_i(t)) + c_2 \\, \\mathbf{r}_2(t) \\odot (\\mathbf{g}(t) - \\mathbf{x}_i(t)),$$ $$\\mathbf{x}_i(t+1) = \\mathbf{x}_i(t) + \\mathbf{v}_i(t+1),$$ 其中 $\\mathbf{r}_1(t), \\mathbf{r}_2(t) \\in [0,1]^d$ 是独立的均匀随机向量。速度限制确保了有界的步长：$$v_{ij}(t+1) \\leftarrow \\operatorname{clip}(v_{ij}(t+1), -v_{\\max}, v_{\\max}).$$ 初始位置 $\\mathbf{x}_i(0)$ 从 $\\Omega$ 中均匀抽取，初始速度 $\\mathbf{v}_i(0)$ 从 $[-v_{\\max}, v_{\\max}]^d$ 中均匀抽取。每次位置更新后，我们评估 $f(\\mathbf{x}_i(t+1))$，如果出现改进，则更新个体最优 $\\mathbf{p}_i(t+1)$ 和全局最优 $\\mathbf{g}(t+1)$。\n\n当尝试的位置 $\\mathbf{x}_i^{\\mathrm{prop}}(t+1) = \\mathbf{x}_i(t) + \\mathbf{v}_i(t+1)$ 离开 $\\Omega$ 时，约束的存在要求进行边界处理。我们考察三种方案：\n\n1. 反射 (Reflect)：反射映射强制执行一个镜像边界，这在防止粒子离开定义域的同时保留了探索能力。对于单个分量 $j$，令 $$z = \\frac{x_{ij}^{\\mathrm{prop}} - l}{u - l}, \\quad k = \\left\\lfloor z \\right\\rfloor, \\quad z_{\\mathrm{frac}} = z - k.$$ 如果 $k$ 是偶数，我们设置 $$x_{ij}(t+1) = l + z_{\\mathrm{frac}}(u - l);$$ 如果 $k$ 是奇数，我们设置 $$x_{ij}(t+1) = u - z_{\\mathrm{frac}}(u - l).$$ $k$ 的奇偶性计算了区间穿越的次数；当 $k$ 为奇数时，该分量已经反弹了奇数次，因此我们翻转速度的符号：$$v_{ij}(t+1) \\leftarrow -v_{ij}(t+1).$$ 这种映射能正确处理任意的过冲，包括那些大于区间宽度 $u-l$ 的情况。\n\n2. 吸收 (Absorb)：吸收边界在发生越界时将位置钳制到最近的边界，并将相应的速度分量重置为零：$$x_{ij}(t+1) = \\begin{cases} l  \\text{若 } x_{ij}^{\\mathrm{prop}}  l, \\\\ u  \\text{若 } x_{ij}^{\\mathrm{prop}}  u, \\\\ x_{ij}^{\\mathrm{prop}}  \\text{其他情况}, \\end{cases} \\quad v_{ij}(t+1) = \\begin{cases} 0  \\text{若 } x_{ij}^{\\mathrm{prop}} \\notin [l,u], \\\\ v_{ij}(t+1)  \\text{其他情况}。 \\end{cases}$$ 该方案通过在撞击时抑制运动来阻止边界违规，可能减少振荡，但也会削弱边界附近的探索能力。\n\n3. 随机重启 (Random restart)：随机重启边界将越界的分量替换为从 $[l,u]$ 中均匀抽取的新随机值，并将其速度设为零：$$x_{ij}(t+1) \\sim \\mathcal{U}(l,u) \\quad \\text{若 } x_{ij}^{\\mathrm{prop}} \\notin [l,u], \\quad v_{ij}(t+1) \\leftarrow 0.$$ 该方案通过在发生违规时重新引入多样性来促进探索，这有助于逃离停滞，但可能减慢在精确边界最优解附近的收敛速度。\n\n为量化每种方案的效果，我们测量两个指标：\n\n- 尝试可行率 $$r_{\\mathrm{feasible}} = \\frac{\\#\\{(i,t) \\mid \\mathbf{x}_i(t) + \\mathbf{v}_i(t+1) \\in \\Omega\\}}{N \\cdot T},$$ 该指标统计修正前的提议，反映了在每种边界规则引导的动力学下，粒子尝试位于 $\\Omega$ 内部位置的频率。\n\n- 收敛行为：一个布尔值，指示全局最优解是否在任何迭代中达到阈值 $\\varepsilon$，以及满足条件的最早迭代次数 $t^\\star$：$$\\min_i f(\\mathbf{p}_i(t^\\star)) \\le \\varepsilon.$$ 我们也报告最终的最佳目标值 $$f^\\star = \\min_i f(\\mathbf{p}_i(T)).$$\n\n实现细节：\n\n- 每个测试用例的随机性都通过使用伪随机数生成器的固定种子来控制，以确保结果的可复现性。\n\n- 个体最优 $\\mathbf{p}_i(t)$ 仅在 $f(\\mathbf{x})$ 严格改进时更新，确保了个体最优值的单调不减。\n\n- 全局最优 $\\mathbf{g}(t)$ 跟踪每次迭代中所有个体最优中的最优者。\n\n- 在计算 $\\mathbf{v}_i(t+1)$ 之后和位置提议之前，速度被逐分量地限制在 $[-v_{\\max}, v_{\\max}]$ 内，以防止过度过冲。\n\n- 边界处理方案逐分量地应用于 $\\mathbf{x}_i^{\\mathrm{prop}}(t+1)$ 以产生最终的 $\\mathbf{x}_i(t+1)$ 和修正后的 $\\mathbf{v}_i(t+1)$，确保 $\\mathbf{x}_i(t+1) \\in \\Omega$。\n\n设计原理：\n\n- 位移球函数的二次结构提供了一个具有唯一最小值的平滑景观，使其成为观察PSO动力学以及探索与利用之间相互作用的理想选择。\n\n- 反射在保持可行性的同时保留了动量，通过减少长时间的偏离通常能提高 $r_{\\mathrm{feasible}}$，并且当最优解位于边界附近时可以加速收敛。\n\n- 吸收通过在边界处将速度置零来减少振荡，这可能减少边界穿越，从而增加 $r_{\\mathrm{feasible}}$，但由于动量损失，可能会减慢边界最优解附近的收敛速度。\n\n- 随机重启在发生违规时增加多样性，通常在运行初期会增加尝试违规的次数，但可能有助于多模态问题的收敛；对于凸的位移球问题，它可能减慢边界附近的精确收敛，但当无约束最小化解位于 $\\Omega$ 之外时，它能有效鼓励在约束最小化解 $\\mathbf{x}^\\star_\\Omega$ 附近的探索。\n\n计算考量：\n\n- 每次更新的成本为 $O(N d)$ 次运算，每个测试用例的总运行时间为 $O(N d T)$。\n\n- 使用给定的参数，该程序在计算上是轻量级的且完全确定性的。\n\n程序处理五个指定的测试用例，计算 $f^\\star$、$r_{\\mathrm{feasible}}$、收敛布尔值和 $t^\\star$，并按顺序输出一行包含每个案例的这些四元组结果列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef sphere_shifted(x, a):\n    # f(x) = sum_j (x_j - a_j)^2\n    diff = x - a\n    return np.dot(diff, diff)\n\ndef reflect_component(x_prop, v_comp, l, u):\n    # Reflective mapping with parity-based velocity flip\n    if l = x_prop = u:\n        return x_prop, v_comp\n    width = u - l\n    # Compute z, k = floor(z), z_frac = z - k\n    z = (x_prop - l) / width\n    k = math.floor(z)\n    z_frac = z - k\n    if k % 2 == 0:\n        x_new = l + z_frac * width\n        v_new = v_comp\n    else:\n        x_new = u - z_frac * width\n        v_new = -v_comp\n    # Numerical guard to ensure bounds inclusion\n    if x_new  l:\n        x_new = l\n    elif x_new > u:\n        x_new = u\n    return x_new, v_new\n\ndef absorb_component(x_prop, v_comp, l, u):\n    if x_prop  l:\n        return l, 0.0\n    elif x_prop > u:\n        return u, 0.0\n    else:\n        return x_prop, v_comp\n\ndef restart_component(x_prop, v_comp, l, u, rng):\n    if l = x_prop = u:\n        return x_prop, v_comp\n    else:\n        return rng.uniform(l, u), 0.0\n\ndef pso_run(d, l, u, a, N, T, w, c1, c2, vmax, scheme, seed, eps):\n    rng = np.random.default_rng(seed)\n    # Initialize positions uniformly in [l, u]^d\n    X = rng.uniform(l, u, size=(N, d))\n    # Initialize velocities uniformly in [-vmax, vmax]^d\n    V = rng.uniform(-vmax, vmax, size=(N, d))\n    # Personal bests and fitnesses\n    P = X.copy()\n    P_fit = np.array([sphere_shifted(P[i], a) for i in range(N)])\n    # Global best\n    g_idx = int(np.argmin(P_fit))\n    G = P[g_idx].copy()\n    G_fit = P_fit[g_idx]\n    # Metrics\n    total_props = N * T\n    feasible_props = 0\n    converged = False\n    t_star = -1\n\n    for t in range(1, T + 1):\n        for i in range(N):\n            # Random coefficients per particle and dimension\n            r1 = rng.uniform(0.0, 1.0, size=d)\n            r2 = rng.uniform(0.0, 1.0, size=d)\n            # Velocity update\n            V[i] = w * V[i] + c1 * r1 * (P[i] - X[i]) + c2 * r2 * (G - X[i])\n            # Clamp velocity\n            V[i] = np.clip(V[i], -vmax, vmax)\n            # Proposed position\n            X_prop = X[i] + V[i]\n            # Feasibility check before correction (attempted feasibility)\n            inside = (X_prop >= l - 1e-12)  (X_prop = u + 1e-12)\n            if np.all(inside):\n                feasible_props += 1\n            # Apply boundary handling per component\n            for j in range(d):\n                xpj = X_prop[j]\n                vj = V[i, j]\n                if scheme == '反射':\n                    x_new, v_new = reflect_component(xpj, vj, l, u)\n                elif scheme == '吸收':\n                    x_new, v_new = absorb_component(xpj, vj, l, u)\n                elif scheme == '随机重启':\n                    x_new, v_new = restart_component(xpj, vj, l, u, rng)\n                else:\n                    # Default: clamp (should not happen in provided tests)\n                    x_new = min(max(xpj, l), u)\n                    v_new = vj\n                X[i, j] = x_new\n                V[i, j] = v_new\n            # Evaluate and update personal best\n            f_val = sphere_shifted(X[i], a)\n            if f_val  P_fit[i]:\n                P[i] = X[i].copy()\n                P_fit[i] = f_val\n        # Update global best\n        g_idx = int(np.argmin(P_fit))\n        if P_fit[g_idx]  G_fit:\n            G_fit = P_fit[g_idx]\n            G = P[g_idx].copy()\n        # Convergence check\n        if (not converged) and (G_fit = eps):\n            converged = True\n            t_star = t\n\n    r_feasible = feasible_props / total_props\n    f_star = G_fit\n    return [f_star, r_feasible, converged, t_star]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: happy path, reflect\n        {\n            \"d\": 5, \"l\": -5.0, \"u\": 5.0,\n            \"a\": np.array([1.5, -2.0, 0.5, -1.0, 2.0], dtype=float),\n            \"N\": 30, \"T\": 200,\n            \"w\": 0.7, \"c1\": 1.5, \"c2\": 1.5,\n            \"vmax\": 5.0, \"scheme\": \"反射\",\n            \"seed\": 42, \"eps\": 1e-6\n        },\n        # Case 2: near upper boundary, absorb\n        {\n            \"d\": 5, \"l\": -5.0, \"u\": 5.0,\n            \"a\": np.array([4.9, 4.8, 4.7, 4.6, 4.5], dtype=float),\n            \"N\": 30, \"T\": 200,\n            \"w\": 0.7, \"c1\": 1.5, \"c2\": 1.5,\n            \"vmax\": 5.0, \"scheme\": \"吸收\",\n            \"seed\": 123, \"eps\": 1e-6\n        },\n        # Case 3: unattainable zero within domain, random restart\n        {\n            \"d\": 5, \"l\": -2.0, \"u\": 2.0,\n            \"a\": np.array([10.0, 10.0, 10.0, 10.0, 10.0], dtype=float),\n            \"N\": 40, \"T\": 300,\n            \"w\": 0.8, \"c1\": 1.7, \"c2\": 1.7,\n            \"vmax\": 4.0, \"scheme\": \"随机重启\",\n            \"seed\": 7, \"eps\": 1e-6\n        },\n        # Case 4: low dimension, overshoot, reflect\n        {\n            \"d\": 2, \"l\": -1.0, \"u\": 1.0,\n            \"a\": np.array([0.99, -0.99], dtype=float),\n            \"N\": 10, \"T\": 150,\n            \"w\": 0.9, \"c1\": 2.05, \"c2\": 2.05,\n            \"vmax\": 2.0, \"scheme\": \"反射\",\n            \"seed\": 999, \"eps\": 1e-6\n        },\n        # Case 5: small domain, absorb\n        {\n            \"d\": 3, \"l\": 0.0, \"u\": 1.0,\n            \"a\": np.array([0.9, 0.1, 0.5], dtype=float),\n            \"N\": 12, \"T\": 150,\n            \"w\": 0.6, \"c1\": 1.4, \"c2\": 1.4,\n            \"vmax\": 1.0, \"scheme\": \"吸收\",\n            \"seed\": 2024, \"eps\": 1e-6\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        res = pso_run(\n            d=case[\"d\"], l=case[\"l\"], u=case[\"u\"], a=case[\"a\"], N=case[\"N\"], T=case[\"T\"],\n            w=case[\"w\"], c1=case[\"c1\"], c2=case[\"c2\"], vmax=case[\"vmax\"],\n            scheme=case[\"scheme\"], seed=case[\"seed\"], eps=case[\"eps\"]\n        )\n        results.append(res)\n\n    # Final print statement in the exact required format (single line, no spaces).\n    # Convert to string and remove spaces for a compact bracketed list.\n    out = str(results).replace(\" \", \"\")\n    print(out)\n\nsolve()\n```"
        },
        {
            "introduction": "优化算法的性能通常通过其处理高维问题的能力来检验，这一挑战被称为“维度灾难”。本练习将指导您建立一个受控的数值基准测试，以系统地衡量随着搜索空间维度的增加，PSO的效率如何变化。这项实践介绍了算法基准测试的核心方法论，这是计算科学中的一项基本技能。",
            "id": "3161040",
            "problem": "要求您设计并实现一个受控数值基准，以研究搜索空间维度如何影响粒子群优化（PSO）在光滑凸测试函数上的性能。仅使用定义、广为接受的公式和可复现的随机化方法。您的程序必须是一个完整、可运行的程序，能够为每个测试维度计算并报告一个单一的汇总性能指标。\n\n任务。使用粒子群优化（PSO）最小化超立方体 $[-b,b]^d$ 上的函数 $f(\\mathbf{x}) = \\sum_{j=1}^{d} x_j^2$，其中 $b = 5$。该算法使用固定的惯性权重 $w$，以及固定的认知加速度 $c_1$ 和社会加速度 $c_2$。使用典型且广泛采用的PSO速度-位置更新规则，每个粒子和每个坐标使用独立的均匀随机因子：\n- 速度更新：在迭代 $t$ 时，对于每个粒子 $i$ 和维度 $j$：\n$$v_{i,j}^{(t+1)} = w \\, v_{i,j}^{(t)} + c_1 \\, r_{i,j}^{(t,1)} \\left(pbest_{i,j}^{(t)} - x_{i,j}^{(t)}\\right) + c_2 \\, r_{i,j}^{(t,2)} \\left(gbest_{j}^{(t)} - x_{i,j}^{(t)}\\right),$$\n其中 $r_{i,j}^{(t,1)}$ 和 $r_{i,j}^{(t,2)}$ 是从 $[0,1]$ 上的均匀分布中独立采样的随机变量。\n- 速度限制：逐分量强制 $v_{i,j}^{(t+1)} \\in [-v_{\\max}, v_{\\max}]$，其中 $v_{\\max} = 0.2 \\times 2b$。\n- 位置更新：\n$$x_{i,j}^{(t+1)} = \\mathrm{clip}\\left(x_{i,j}^{(t)} + v_{i,j}^{(t+1)}, -b, b\\right).$$\n\n初始化。对于给定的维度 $d$，使用 $m(d)$ 个粒子，其位置从 $[-b,b]^d$ 上的均匀分布中独立采样，速度从 $[-v_{\\max}, v_{\\max}]^d$ 上的均匀分布中独立采样。最初将每个粒子的个体最佳位置 $pbest_i$ 设置为其起始位置，并将全局最佳位置 $gbest$ 设置为所有初始 $pbest_i$ 中的最佳者。\n\n终止条件与度量。固定一个目标容差 $\\varepsilon > 0$ 和一个最大迭代预算 $T_{\\max}$。将“达到$\\varepsilon$的时间”（time-to-$\\varepsilon$）定义为最小的迭代次数 $T$，使得在完成第 $T$ 次迭代的位置更新后，当前迄今为止的最佳目标值满足 $f(gbest^{(T)}) \\le \\varepsilon$。如果在 $T_{\\max}$ 次迭代内从未满足此条件，则将“达到$\\varepsilon$的时间”定义为 $T_{\\max}$。\n\n基准协议。对于给定测试集中的每个维度 $d$，运行PSO算法 $R$ 次独立试验（每次使用不同的随机种子），并报告这 $R$ 次试验中“达到$\\varepsilon$的时间”的算术平均值。\n\n使用以下固定参数：\n- 惯性权重 $w = 0.7298$。\n- 认知加速度 $c_1 = 1.49618$。\n- 社会加速度 $c_2 = 1.49618$。\n- 边界参数 $b = 5$，因此 $v_{\\max} = 0.2 \\times 2b = 2$。\n- 迭代次数预算 $T_{\\max} = 500$。\n- 容差 $\\varepsilon = 10^{-6}$。\n- 试验次数 $R = 3$。\n- 种群规模方案 $m(d) = \\min(10d, 200)$。\n- 随机化：使用固定的基础种子 $s_0 = 1337$；对于维度 $d$ 和试验索引 $r \\in \\{0,1,\\dots,R-1\\}$，使用种子 $s(d,r) = s_0 + 100d + r$。\n\n测试集。您必须在以下维度上评估该基准：\n- $d \\in \\{1, 5, 20, 50\\}$。\n\n输出规范。您的程序应生成单行输出，按上述顺序包含每个 $d$ 的平均“达到$\\varepsilon$的时间”，格式为一个用逗号分隔的十进制数列表，并用方括号括起来，每个数字精确到小数点后三位。例如，输出必须形如 $[a_1,a_2,a_3,a_4]$，其中每个 $a_k$ 是一个精确到小数点后三位的浮点数。\n\n单位。“达到$\\varepsilon$的时间”是迭代次数的计数，因此是无量纲的；将其报告为实数（十进制数），以便在多次试验中进行平均。\n\n您的程序必须是自包含的，不需要任何输入，并严格遵守指定的输出格式。",
            "solution": "问题陈述经分析后被确定为**有效**。它在计算优化领域提出了一个定义明确且科学合理的数据实验。所有必要的参数、方程和评估协议都得到了清晰而精确的说明，从而可以实现可复现的实施。该任务是客观、自包含的，并基于粒子群优化（PSO）的既定原则。\n\n目标是在超立方体域 $\\mathbf{x} \\in [-b, b]^d$ 内最小化球函数，定义为 $f(\\mathbf{x}) = \\sum_{j=1}^{d} x_j^2$，其中 $d$ 是搜索空间的维度，边界参数为 $b=5$。该基准旨在分析PSO算法的性能如何随着维度的增加而变化。\n\n解决方案的核心在于实现经典的PSO算法。一个包含 $m(d)$ 个粒子的种群状态由其位置 $\\mathbf{x}_i$ 和速度 $\\mathbf{v}_i$ 描述，其中 $i=1, \\dots, m(d)$。在每次迭代 $t$ 中，每个粒子的速度和位置根据以下规则针对每个维度 $j$ 进行更新：\n\n1.  **速度更新**：粒子 $i$ 的速度根据其先前的速度、其个体历史最佳位置（$\\mathbf{pbest}_i$）以及整个种群发现的全局最佳位置（$\\mathbf{gbest}$）进行更新。\n    $$v_{i,j}^{(t+1)} = w \\, v_{i,j}^{(t)} + c_1 \\, r_{i,j}^{(t,1)} \\left(pbest_{i,j}^{(t)} - x_{i,j}^{(t)}\\right) + c_2 \\, r_{i,j}^{(t,2)} \\left(gbest_{j}^{(t)} - x_{i,j}^{(t)}\\right)$$\n    参数是固定的：惯性权重 $w = 0.7298$，认知加速度 $c_1 = 1.49618$，社会加速度 $c_2 = 1.49618$。项 $r_{i,j}^{(t,1)}$ 和 $r_{i,j}^{(t,2)}$ 是在每次迭代中为每个粒子和每个维度从 $[0,1]$ 上的均匀分布中独立采样的随机数。\n\n2.  **速度限制**：为防止粒子速度过大而导致种群不稳定，每个速度分量被限制在 $[-v_{\\max}, v_{\\max}]$ 范围内，其中 $v_{\\max} = 0.2 \\times (2b) = 2$。\n\n3.  **位置更新**：通过将更新后的速度加到当前位置上来计算粒子 $i$ 的新位置。然后对该位置进行硬裁剪，以确保其保持在搜索边界 $[-b, b]$ 内。\n    $$x_{i,j}^{(t+1)} = \\mathrm{clip}\\left(x_{i,j}^{(t)} + v_{i,j}^{(t+1)}, -b, b\\right)$$\n\n对测试集 $\\{1, 5, 20, 50\\}$ 中的每个维度 $d$ 执行基准协议。对于每个 $d$，执行以下步骤：\n-   种群规模设置为 $m(d) = \\min(10d, 200)$。\n-   算法运行 $R=3$ 次独立试验，以解释PSO的随机性。\n-   通过使用确定性种子策略来确保可复现性：对于维度 $d$ 中的试验 $r \\in \\{0, 1, 2\\}$，随机数生成器的种子设置为 $s(d,r) = 1337 + 100d + r$。\n-   在每次试验中，粒子的位置从 $[-5, 5]^d$ 中均匀采样进行初始化，速度从 $[-2, 2]^d$ 中均匀采样进行初始化。\n-   单次试验的性能度量是“达到$\\varepsilon$的时间”，定义为全局最佳目标值 $f(\\mathbf{gbest}^{(T)})$ 首次降至或低于容差 $\\varepsilon = 10^{-6}$ 时的迭代次数 $T$。\n-   如果在最大迭代预算 $T_{\\max} = 500$ 内未能达到此容差，则将“达到$\\varepsilon$的时间”设置为 $T_{\\max}$。\n-   每个维度 $d$ 的最终报告值是在 $R=3$ 次试验中获得的“达到$\\varepsilon$的时间”值的算术平均值。\n\n该实现使用Python编写，利用 `numpy` 库进行高效的向量化计算。这种方法避免了对粒子和维度的显式循环，使代码既简洁又高效。程序精确遵循了规定的协议，计算了平均性能指标，并按规定格式化了最终输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the PSO benchmark study.\n    It iterates through the specified dimensions, runs multiple trials for each,\n    computes the mean performance, and prints the final formatted result.\n    \"\"\"\n    \n    def run_pso_trial(d: int, seed: int) -> int:\n        \"\"\"\n        Executes a single trial of the Particle Swarm Optimization algorithm.\n\n        Args:\n            d: The dimension of the search space.\n            seed: The seed for the random number generator.\n\n        Returns:\n            The number of iterations to reach the target tolerance (\"time-to-epsilon\").\n        \"\"\"\n        rng = np.random.default_rng(seed)\n\n        # Fixed parameters from the problem statement\n        w = 0.7298\n        c1 = 1.49618\n        c2 = 1.49618\n        b = 5.0\n        v_max = 2.0\n        T_max = 500\n        eps = 1e-6\n        m = min(10 * d, 200)\n\n        # Initialization\n        # (m, d) array of particle positions\n        positions = rng.uniform(-b, b, size=(m, d))\n        # (m, d) array of particle velocities\n        velocities = rng.uniform(-v_max, v_max, size=(m, d))\n\n        # Personal best positions are initialized to the starting positions\n        pbest_positions = np.copy(positions)\n        # Objective function f(x) = sum(x_j^2)\n        pbest_values = np.sum(pbest_positions**2, axis=1)\n\n        # Global best initialization\n        gbest_idx = np.argmin(pbest_values)\n        gbest_value = pbest_values[gbest_idx]\n        gbest_position = np.copy(pbest_positions[gbest_idx])\n        \n        # If the solution is found at initialization (iteration 0)\n        if gbest_value = eps:\n            return 0\n\n        # Main optimization loop\n        for t in range(1, T_max + 1):\n            # Generate random factors for velocity update\n            r1 = rng.random(size=(m, d))\n            r2 = rng.random(size=(m, d))\n\n            # Update velocities (vectorized for all particles)\n            velocities = w * velocities + \\\n                         c1 * r1 * (pbest_positions - positions) + \\\n                         c2 * r2 * (gbest_position - positions)\n            \n            # Clamp velocities\n            velocities = np.clip(velocities, -v_max, v_max)\n\n            # Update positions\n            positions = positions + velocities\n            # Clip positions to stay within the search space\n            positions = np.clip(positions, -b, b)\n\n            # Evaluate objective function for all particles\n            current_values = np.sum(positions**2, axis=1)\n\n            # Update personal bests\n            improved_mask = current_values  pbest_values\n            pbest_values[improved_mask] = current_values[improved_mask]\n            pbest_positions[improved_mask] = positions[improved_mask]\n\n            # Update global best\n            min_pbest_idx = np.argmin(pbest_values)\n            if pbest_values[min_pbest_idx]  gbest_value:\n                gbest_value = pbest_values[min_pbest_idx]\n                gbest_position = pbest_positions[min_pbest_idx]\n\n            # Check for termination\n            if gbest_value = eps:\n                return t\n\n        # Return T_max if tolerance was not met\n        return T_max\n\n    # Benchmark protocol parameters\n    test_dims = [1, 5, 20, 50]\n    R = 3  # Number of trials\n    s0 = 1337  # Base seed\n\n    mean_results = []\n    for d in test_dims:\n        trial_times = []\n        for r in range(R):\n            # Calculate the deterministic seed for the trial\n            seed = s0 + 100 * d + r\n            time_to_eps = run_pso_trial(d, seed)\n            trial_times.append(time_to_eps)\n        \n        # Calculate the arithmetic mean of the time-to-epsilon\n        mean_time = np.mean(trial_times)\n        mean_results.append(mean_time)\n\n    # Format and print the final output as specified\n    formatted_results = [f'{res:.3f}' for res in mean_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        }
    ]
}