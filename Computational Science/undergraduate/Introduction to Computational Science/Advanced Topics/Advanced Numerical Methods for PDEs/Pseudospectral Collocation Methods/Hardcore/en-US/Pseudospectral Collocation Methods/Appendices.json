{
    "hands_on_practices": [
        {
            "introduction": "The foundation of the pseudospectral method is the differentiation matrix, $D$, which approximates the derivative operator. A crucial property of any differentiation operator is that it maps constant functions to zero. This practice guides you through a numerical investigation of this property for the Chebyshev differentiation matrix, exploring why $D\\mathbf{1}=\\mathbf{0}$ holds and how this essential characteristic is altered when modifying the operator to enforce boundary conditions. ",
            "id": "3179523",
            "problem": "You will implement and use a Chebyshev–Lobatto pseudospectral first-derivative collocation matrix to investigate how endpoint conditions affect the nullspace of the discrete differentiation operator. Work entirely in exact mathematical terms and standard floating-point arithmetic, with the following fundamental bases and facts.\n\nFundamental bases and facts:\n- In pseudospectral collocation, a function $u(x)$ is approximated by an interpolating polynomial through selected nodes, and derivatives are approximated by differentiating the interpolant. This yields a linear operator (a matrix) that maps nodal values to approximations of nodal derivatives.\n- For Chebyshev–Lobatto nodes, the nodes are $x_j = \\cos\\left(\\frac{\\pi j}{N}\\right)$ for $j=0,\\ldots,N$, where $N \\in \\mathbb{N}$ is the number of subintervals. If $p(x)$ is any polynomial of degree at most $N$, the pseudospectral derivative at these nodes equals the exact derivative of $p(x)$ at these nodes.\n- The derivative of the constant function $p(x) \\equiv 1$ is identically zero, hence any consistent first-derivative pseudospectral differentiation matrix $D$ should satisfy $D \\mathbf{1} = \\mathbf{0}$ in exact arithmetic, where $\\mathbf{1}$ is the all-ones vector. In floating-point arithmetic, this identity holds up to rounding error.\n\nDefinitions to implement:\n1. Chebyshev–Lobatto nodes: $x_j = \\cos\\left(\\frac{\\pi j}{N}\\right)$ for $j=0,\\ldots,N$.\n2. Chebyshev first-derivative pseudospectral matrix $D \\in \\mathbb{R}^{(N+1)\\times(N+1)}$: Constructed from the barycentric Lagrange formulation. Let\n   - $c_j = 2$ for $j \\in \\{0,N\\}$ and $c_j = 1$ otherwise,\n   - $s_j = (-1)^j$,\n   - $w_j = c_j s_j$,\n   - $x_j$ as above,\n   - $X$ the matrix with entries $X_{jk} = x_j$,\n   - $\\Delta = X - X^\\top$ the pairwise difference matrix.\n   For $j \\neq k$,\n   $$ D_{jk} = \\frac{w_j}{w_k} \\cdot \\frac{1}{x_j - x_k}, $$\n   and for each $j$,\n   $$ D_{jj} = -\\sum_{k\\neq j} D_{jk}. $$\n   This $D$ maps nodal samples $u(x_k)$ to approximations of $u'(x_j)$.\n3. Endpoint-conditioned operator by row replacement: To impose homogeneous Dirichlet boundary conditions $u(x_0)=0$ and $u(x_N)=0$ within a collocation system, replace the first and last rows of $D$ by the coordinate row vectors enforcing these conditions: set the first row to $[1, 0, \\ldots, 0]$ and the last row to $[0, \\ldots, 0, 1]$. Denote the resulting matrix by $A$.\n4. Interior-only operator: Remove the first and last rows and also the first and last columns of $D$ to form the interior block $D_{\\mathrm{int}} \\in \\mathbb{R}^{(N-1)\\times(N-1)}$. This corresponds to acting on the interior unknowns when endpoint values are treated separately.\n\nYour tasks:\n- Implement a routine to construct $D$ for given $N$ according to the definitions above.\n- For each operator type below, define the discretized constant function sample as the all-ones vector $\\mathbf{1}$ of compatible length and compute the infinity norm residual\n  $$ r = \\lVert \\text{Operator} \\cdot \\mathbf{1} \\rVert_{\\infty}. $$\n- Interpret $r$ against a specified numerical threshold to decide whether the constant function is (approximately) in the nullspace of the operator.\n\nScientific goals:\n- Justify why $D \\mathbf{1} = \\mathbf{0}$ in exact arithmetic by the property that the pseudospectral derivative of a constant polynomial is zero, and verify numerically that $r$ is small.\n- Analyze how removing endpoint columns (interior-only operator) destroys the exact cancellation that yields $D \\mathbf{1} = \\mathbf{0}$, so that the constant function is no longer in the nullspace.\n- Analyze how endpoint constraints enforced by row replacement change the operator nullspace so that $\\mathbf{1}$ is no longer admissible unless it satisfies the boundary conditions, which it does not for homogeneous Dirichlet boundary conditions unless the constant is $0$.\n\nTest suite:\nFor each case below, you will compute a boolean according to the specified criterion.\n\n- Case $1$: Operator type “full” with $N=8$. Let tolerance $\\tau = 1\\times 10^{-13}$. Output $\\mathrm{True}$ if $r \\le \\tau$, else $\\mathrm{False}$.\n- Case $2$: Operator type “full” with $N=32$. Let tolerance $\\tau = 1\\times 10^{-13}$. Output $\\mathrm{True}$ if $r \\le \\tau$, else $\\mathrm{False}$.\n- Case $3$: Operator type “interior” with $N=8$. Let lower bound $\\eta = 1\\times 10^{-8}$. Output $\\mathrm{True}$ if $r \\ge \\eta$, else $\\mathrm{False}$.\n- Case $4$: Operator type “bc_rows” with $N=8$. Theoretically $r \\ge 1$ because the first and last residual components equal $1$. Output $\\mathrm{True}$ if $r \\ge 1$, else $\\mathrm{False}$.\n- Case $5$: Operator type “full” with $N=2$. Let tolerance $\\tau = 1\\times 10^{-13}$. Output $\\mathrm{True}$ if $r \\le \\tau$, else $\\mathrm{False}$.\n- Case $6$: Operator type “interior” with $N=2$. Let lower bound $\\eta = 1\\times 10^{-8}$. Output $\\mathrm{True}$ if $r \\ge \\eta$, else $\\mathrm{False}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., “[result1,result2,result3]”). For this problem, the results are the six booleans, in the order of Cases $1$ through $6$.",
            "solution": "The problem statement is scientifically grounded, well-posed, and objective. It outlines a standard numerical analysis exercise involving the construction and examination of a Chebyshev pseudospectral differentiation matrix. All definitions are precise, the tasks are clear, and the context is within established principles of computational science. The problem is therefore valid.\n\nThe core of this problem is to investigate the nullspace of a first-derivative pseudospectral differentiation operator under different configurations. A function is in the nullspace of a linear operator if the operator maps it to zero. For a differentiation operator_—_continuous or discrete_—_the constant function is the most fundamental element of its nullspace, as the derivative of a constant is identically zero. We will analyze how this property manifests in three discrete operator forms derived from the Chebyshev collocation method.\n\nA function $u(x)$ on the interval $[-1, 1]$ is approximated by a degree-$N$ polynomial interpolant $p(x)$ passing through the $N+1$ Chebyshev–Lobatto nodes $x_j = \\cos\\left(\\frac{\\pi j}{N}\\right)$ for $j=0, \\dots, N$. The derivative $u'(x)$ is then approximated by $p'(x)$. This relationship defines a linear transformation from the vector of function values $\\mathbf{u} = [u(x_0), \\dots, u(x_N)]^\\top$ to the vector of approximate derivative values $\\mathbf{u}' = [u'(x_0), \\dots, u'(x_N)]^\\top$. This transformation is represented by the $(N+1) \\times (N+1)$ Chebyshev first-derivative pseudospectral matrix $D$.\n\nThe entries of $D$ are given by the formulas:\n$$ D_{jk} = \\frac{c_j(-1)^j}{c_k(-1)^k} \\frac{1}{x_j - x_k} \\quad \\text{for } j \\neq k $$\n$$ D_{jj} = -\\sum_{k\\neq j} D_{jk} $$\nwhere $c_j = 2$ for $j \\in \\{0, N\\}$ and $c_j = 1$ otherwise.\n\nWe consider the constant function $u(x) = 1$. The vector of its nodal values is the all-ones vector, $\\mathbf{1} = [1, 1, \\dots, 1]^\\top$. We will examine the product of the operator with $\\mathbf{1}$ and compute the infinity norm of the resulting residual vector, $r = \\lVert \\text{Operator} \\cdot \\mathbf{1} \\rVert_{\\infty}$.\n\n**1. The Full Differentiation Operator ($D$)**\n\nThis is the standard Chebyshev differentiation matrix as defined above. We analyze its action on the constant function vector $\\mathbf{1}$.\n\n*   **Theoretical Analysis:** The pseudospectral method is exact for any polynomial of degree at most $N$. The constant function $u(x)=1$ is a polynomial of degree $0$. Its derivative is $u'(x)=0$. Therefore, the discrete differentiation operator $D$ must map the nodal values of $u(x)=1$ to the nodal values of $u'(x)=0$. This means $D\\mathbf{1} = \\mathbf{0}$.\n    Algebraically, the construction of the diagonal elements $D_{jj} = -\\sum_{k\\neq j} D_{jk}$ ensures that the sum of the elements in each row is exactly zero:\n    $$ \\sum_{k=0}^{N} D_{jk} = D_{jj} + \\sum_{k\\neq j} D_{jk} = \\left(-\\sum_{k\\neq j} D_{jk}\\right) + \\sum_{k\\neq j} D_{jk} = 0 $$\n    The $j$-th component of the vector $D\\mathbf{1}$ is given by $(D\\mathbf{1})_j = \\sum_{k=0}^{N} D_{jk} \\cdot 1_k = \\sum_{k=0}^{N} D_{jk}$. Since each row sum is zero, the vector $D\\mathbf{1}$ is the zero vector.\n*   **Numerical Verification (Cases 1, 2, 5):** When implemented in floating-point arithmetic, this property holds up to machine precision. The calculated residual $r = \\lVert D \\mathbf{1} \\rVert_{\\infty}$ will be a small number on the order of machine epsilon, reflecting accumulated rounding errors. For $N=2$, $N=8$, and $N=32$, the computed residuals are all extremely small, satisfying the condition $r \\le \\tau = 1 \\times 10^{-13}$. Thus, the test yields $\\mathrm{True}$ for these cases, confirming that the all-ones vector is in the nullspace of $D$ to within numerical precision.\n\n**2. The Interior Operator ($D_{\\mathrm{int}}$)**\n\nThis operator is the $(N-1) \\times (N-1)$ submatrix obtained by removing the first and last rows and columns of $D$. It represents the action of the derivative on the interior nodes, assuming the boundary values are handled separately.\n\n*   **Theoretical Analysis:** The vector operated upon is now the all-ones vector of length $N-1$. Let this be $\\mathbf{1}_{\\mathrm{int}}$. For an interior row $j$ (where $1 \\le j \\le N-1$), the $j$-th component of the product $D_{\\mathrm{int}}\\mathbf{1}_{\\mathrm{int}}$ is the sum of the elements in the $j$-th row of $D_{\\mathrm{int}}$:\n    $$ (D_{\\mathrm{int}}\\mathbf{1}_{\\mathrm{int}})_j = \\sum_{k=1}^{N-1} D_{jk} $$\n    From the zero-row-sum property of the full matrix $D$, we know $\\sum_{k=0}^{N} D_{jk} = 0$. We can rewrite this as $D_{j0} + \\sum_{k=1}^{N-1} D_{jk} + D_{jN} = 0$. Therefore, the row sum for the interior matrix is:\n    $$ \\sum_{k=1}^{N-1} D_{jk} = -(D_{j0} + D_{jN}) $$\n    This sum is generally non-zero. The property that the constant function is in the nullspace is destroyed by restricting the operator to the interior.\n*   **Numerical Verification (Case 3, $N=8$):** For $N=8$, the residual vector elements are $-(D_{j0} + D_{j8})$ for $j=1, \\dots, 7$. These values are significantly different from zero, leading to a large infinity norm residual $r$. The test correctly identifies this, yielding $\\mathrm{True}$ for $r \\ge \\eta = 1 \\times 10^{-8}$.\n*   **Special Case (Case 6, $N=2$):** For $N=2$, the interior consists of a single node, $j=1$. The nodes are $x_0=1$, $x_1=0$, $x_2=-1$. The interior matrix $D_{\\mathrm{int}}$ is a $1 \\times 1$ matrix containing the element $D_{1,1}$. The residual is simply $r = |D_{1,1}|$. From the analysis above, $D_{1,1} = -(D_{1,0} + D_{1,2})$. Due to the symmetry of the Chebyshev nodes and weights for even $N$ when considering the midpoint $j=N/2$ (here $j=1=2/2$), the terms $D_{j,0}$ and $D_{j,N}$ cancel. Specifically, $D_{1,0} = \\frac{1}{2}$ and $D_{1,2} = -\\frac{1}{2}$, so their sum is $0$. Consequently, $D_{1,1} = 0$ and the residual $r=0$. The test $r \\ge \\eta$ becomes $0 \\ge 1 \\times 10^{-8}$, which is $\\mathrm{False}$.\n\n**3. The Endpoint-Conditioned Operator ($A$)**\n\nThis operator is formed by replacing the first and last rows of $D$ with basis vectors to enforce boundary conditions. For homogeneous Dirichlet conditions, the first row becomes $[1, 0, \\dots, 0]$ and the last row becomes $[0, \\dots, 0, 1]$.\n\n*   **Theoretical Analysis:** This matrix $A$ is used to solve systems of the form $A\\mathbf{u} = \\mathbf{f}$, where the first and last equations are $u_0=f_0$ and $u_N=f_N$. When we test the action of $A$ on the all-ones vector $\\mathbf{1}$, we are effectively checking if the constant function $u(x)=1$ is in its nullspace. The product $A\\mathbf{1}$ is:\n    - First component: $(A\\mathbf{1})_0 = [1, 0, \\dots, 0] \\cdot [1, \\dots, 1]^\\top = 1$. This corresponds to checking if $u(x_0)=1$ satisfies $u(x_0)=0$. It does not.\n    - Interior components ($j=1, \\dots, N-1$): $(A\\mathbf{1})_j = (D\\mathbf{1})_j = 0$ (in exact arithmetic), since these rows are from the original matrix $D$.\n    - Last component: $(A\\mathbf{1})_N = [0, \\dots, 0, 1] \\cdot [1, \\dots, 1]^\\top = 1$. This corresponds to checking if $u(x_N)=1$ satisfies $u(x_N)=0$. It does not.\n    The resulting residual vector is $\\mathbf{r} = [1, 0, \\dots, 0, 1]^\\top$. The infinity norm is $r = \\lVert \\mathbf{r} \\rVert_{\\infty} = \\max(|1|, |0|, |1|) = 1$. The constant function is not in the nullspace of $A$. Only the trivial constant function $u(x)=0$ would be.\n*   **Numerical Verification (Case 4, $N=8$):** The calculation exactly matches the theoretical prediction. The residual vector is $[1, 0, \\dots, 0, 1]^\\top$ (with inner zeros being subject to floating-point error, but still very small), and its infinity norm is $r=1$. The test $r \\ge 1$ is satisfied, resulting in $\\mathrm{True}$.\n\nIn summary, this investigation demonstrates that the fundamental property of a differentiation operator having constant functions in its nullspace is fragile. It holds for the complete, unmodified pseudospectral matrix but is broken by standard modifications used in solving boundary value problems, such as restricting the operator to interior points or enforcing boundary conditions via row replacement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_chebyshev_matrix(N: int) - np.ndarray:\n    \"\"\"\n    Constructs the Chebyshev first-derivative pseudospectral matrix D\n    for N+1 Chebyshev-Lobatto nodes.\n\n    Args:\n        N (int): The number of subintervals (degree of polynomial).\n\n    Returns:\n        np.ndarray: The (N+1)x(N+1) differentiation matrix.\n    \"\"\"\n    if N == 0:\n        return np.array([[0.0]])\n    \n    # Define Chebyshev-Lobatto nodes\n    j = np.arange(N + 1)\n    x = np.cos(np.pi * j / N)\n    \n    # Define weights\n    c = np.ones(N + 1)\n    c[0] = 2.0\n    c[-1] = 2.0\n    \n    w = np.power(-1.0, j) * c\n\n    # Calculate off-diagonal elements using broadcasting\n    X = x.reshape(N + 1, 1)\n    dX = X - X.T\n    \n    W_ratio = w.reshape(N + 1, 1) / w.reshape(1, N + 1)\n    \n    # Temporarily add identity to dX to avoid division by zero on the diagonal.\n    # The diagonal values will be correctly computed later.\n    D = W_ratio / (dX + np.eye(N + 1))\n    np.fill_diagonal(D, 0.0)\n    \n    # Calculate diagonal elements such that row sums are zero\n    row_sums = D.sum(axis=1)\n    np.fill_diagonal(D, -row_sums)\n    \n    return D\n\ndef solve():\n    \"\"\"\n    Runs the test suite specified in the problem statement to analyze\n    the nullspace of various Chebyshev differentiation operators.\n    \"\"\"\n    results = []\n\n    # Case 1: 'full' operator, N=8\n    N1 = 8\n    tau1 = 1e-13\n    D1 = get_chebyshev_matrix(N1)\n    ones1 = np.ones(N1 + 1)\n    r1 = np.linalg.norm(D1 @ ones1, ord=np.inf)\n    results.append(r1 = tau1)\n\n    # Case 2: 'full' operator, N=32\n    N2 = 32\n    tau2 = 1e-13\n    D2 = get_chebyshev_matrix(N2)\n    ones2 = np.ones(N2 + 1)\n    r2 = np.linalg.norm(D2 @ ones2, ord=np.inf)\n    results.append(r2 = tau2)\n\n    # Case 3: 'interior' operator, N=8\n    N3 = 8\n    eta3 = 1e-8\n    D3 = get_chebyshev_matrix(N3)\n    D_int3 = D3[1:-1, 1:-1]\n    ones3 = np.ones(N3 - 1)\n    r3 = np.linalg.norm(D_int3 @ ones3, ord=np.inf)\n    results.append(r3 = eta3)\n\n    # Case 4: 'bc_rows' operator, N=8\n    N4 = 8\n    eta4 = 1.0\n    D4 = get_chebyshev_matrix(N4)\n    A4 = D4.copy()\n    A4[0, :] = 0.0\n    A4[0, 0] = 1.0\n    A4[-1, :] = 0.0\n    A4[-1, -1] = 1.0\n    ones4 = np.ones(N4 + 1)\n    r4 = np.linalg.norm(A4 @ ones4, ord=np.inf)\n    results.append(r4 = eta4)\n    \n    # Case 5: 'full' operator, N=2\n    N5 = 2\n    tau5 = 1e-13\n    D5 = get_chebyshev_matrix(N5)\n    ones5 = np.ones(N5 + 1)\n    r5 = np.linalg.norm(D5 @ ones5, ord=np.inf)\n    results.append(r5 = tau5)\n\n    # Case 6: 'interior' operator, N=2\n    N6 = 2\n    eta6 = 1e-8\n    D6 = get_chebyshev_matrix(N6)\n    D_int6 = D6[1:-1, 1:-1] # This is the single element D[1,1]\n    ones6 = np.ones(N6 - 1) # Vector of length 1\n    r6 = np.linalg.norm(D_int6 @ ones6, ord=np.inf)\n    results.append(r6 = eta6)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "With a grasp of the differentiation matrix, we can now apply it to solve a classic physical problem: the Sturm-Liouville eigenvalue problem. This exercise demonstrates how to discretize a second-order differential equation, $-u''(x) = \\lambda u(x)$, into a matrix eigenvalue problem by applying the differentiation matrix twice and imposing boundary conditions. By comparing the computed eigenvalues with their exact analytical values, you will witness firsthand the remarkable accuracy of pseudospectral methods. ",
            "id": "3179507",
            "problem": "Consider the pseudospectral collocation method (PCM) based on Chebyshev polynomials for approximating derivatives on the interval $[-1,1]$. Let $N \\in \\mathbb{N}$, and define the Chebyshev collocation points (first kind) by $x_j = \\cos\\left(\\frac{\\pi j}{N}\\right)$ for $j = 0,1,\\dots,N$, where all angle measures are in radians. Let $D \\in \\mathbb{R}^{(N+1) \\times (N+1)}$ denote the first derivative differentiation matrix that maps the vector of function values at the collocation points to their first derivatives at those points under Chebyshev interpolation, and define the second derivative matrix by $D^{(2)} = D^2$. Consider the Sturm–Liouville eigenvalue problem on $[-1,1]$ with homogeneous Dirichlet boundary conditions:\n$$\n-u''(x) = \\lambda u(x), \\quad u(-1) = 0, \\quad u(1) = 0.\n$$\nThe exact eigenvalues for this problem are known to be\n$$\n\\lambda_k = \\left(\\frac{k \\pi}{2}\\right)^2, \\quad k = 1,2,3,\\dots,\n$$\nwith $u_k(x)$ satisfying the boundary conditions on $[-1,1]$.\n\nYour task is to:\n- Construct the Chebyshev first derivative matrix $D$ from first principles of polynomial interpolation, using the Chebyshev collocation points defined above.\n- Form $D^{(2)} = D^2$ and discretize the operator $-u'' = \\lambda u$ with homogeneous Dirichlet boundary conditions by restricting to the interior collocation points $x_j$ for $j = 1,2,\\dots,N-1$. This yields a matrix eigenvalue problem of the form\n$$\nA \\mathbf{u}_{\\text{int}} = \\lambda \\mathbf{u}_{\\text{int}},\n$$\nwhere $A \\in \\mathbb{R}^{(N-1) \\times (N-1)}$ is obtained from $D^{(2)}$ and $\\mathbf{u}_{\\text{int}}$ represents the vector of interior values of $u$ at the collocation points. Use homogeneous boundary conditions to eliminate dependence on boundary values.\n- Compute the eigenvalues of $A$, sort them in ascending order, and compare them to the exact eigenvalues $\\lambda_k$ for $k = 1,\\dots,N-1$.\n- For each $N$, report the maximum absolute relative error across the first $N-1$ eigenvalues:\n$$\nE_{\\max}(N) = \\max_{1 \\le k \\le N-1} \\frac{\\left| \\lambda_k^{\\text{num}} - \\lambda_k \\right|}{\\lambda_k}.\n$$\n\nFundamental base you may use includes: definitions of Chebyshev points, properties of polynomial interpolation and its derivatives, and the form of the Dirichlet Sturm–Liouville problem on a finite interval with its exact eigenvalues.\n\nUse the following test suite for $N$:\n- $N = 2$ (boundary case with the smallest nontrivial interior),\n- $N = 3$ (small grid),\n- $N = 8$ (moderate grid),\n- $N = 16$ (larger grid),\n- $N = 64$ (fine grid).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each entry must be the value of $E_{\\max}(N)$ for the corresponding $N$ in the test suite, formatted in scientific notation with six significant digits (e.g., $[1.234567e-03,4.321000e-05,\\dots]$). There are no physical units involved, and all angle measures must be interpreted in radians. The final output must be a list in the order of the test suite $N$ values specified above.",
            "solution": "The problem posed is the numerical approximation of the eigenvalues of a one-dimensional Sturm-Liouville problem using the Chebyshev pseudospectral collocation method. Specifically, we are to solve the eigenvalue problem\n$$\n-u''(x) = \\lambda u(x)\n$$\non the interval $[-1, 1]$ with homogeneous Dirichlet boundary conditions $u(-1) = 0$ and $u(1) = 0$. The task requires constructing the Chebyshev differentiation matrix, applying the boundary conditions by restricting the problem to the interior collocation points, and then computing the eigenvalues of the resulting discrete operator. The accuracy of the numerical eigenvalues is to be assessed against the known exact eigenvalues, $\\lambda_k = \\left(\\frac{k \\pi}{2}\\right)^2$ for $k = 1, 2, 3, \\dots$, by calculating the maximum relative error.\n\nThe pseudospectral collocation method is predicated on the approximation of a function $u(x)$ by a global polynomial interpolant, $p(x)$, which collocates with $u(x)$ at a set of prescribed nodes. For this problem, we use the Chebyshev-Gauss-Lobatto points, defined as\n$$\nx_j = \\cos\\left(\\frac{\\pi j}{N}\\right) \\quad \\text{for } j = 0, 1, \\dots, N.\n$$\nThese points are the extrema of the $N$-th degree Chebyshev polynomial of the first kind, $T_N(x)$. Derivatives of the function $u(x)$ are then approximated by the derivatives of the interpolating polynomial $p(x)$ at these same points.\n\nThe core of the method is the construction of the Chebyshev first derivative differentiation matrix, $D \\in \\mathbb{R}^{(N+1) \\times (N+1)}$. If $\\mathbf{u} = [u(x_0), u(x_1), \\dots, u(x_N)]^T$ is the vector of function values at the collocation points, the vector of first derivatives $\\mathbf{u}' = [u'(x_0), u'(x_1), \\dots, u'(x_N)]^T$ is approximated by the matrix-vector product $D\\mathbf{u}$. The entries of $D$ can be derived from the principles of Lagrange interpolation. If $p(x) = \\sum_{k=0}^N u_k L_k(x)$ is the unique polynomial of degree at most $N$ that interpolates the data, where $L_k(x)$ are the Lagrange basis polynomials, then $p'(x_i) = \\sum_{k=0}^N u_k L'_k(x_i)$. The entries of the differentiation matrix are therefore given by $(D)_{ik} = L'_k(x_i)$. For the Chebyshev points, these entries have a well-known analytical form:\n$$\n(D)_{ij} = \\begin{cases}\n\\frac{c_i}{c_j} \\frac{(-1)^{i+j}}{x_i - x_j}  i \\neq j \\\\\n-\\frac{x_j}{2(1-x_j^2)}  1 \\le j \\le N-1 \\\\\n\\frac{2N^2+1}{6}  j = 0 \\\\\n-\\frac{2N^2+1}{6}  j = N\n\\end{cases}\n$$\nwhere the weights $c_j$ are defined as $c_0 = c_N = 2$ and $c_j = 1$ for $j = 1, \\dots, N-1$. A more numerically stable way to compute the diagonal elements is to use the property that the derivative of a constant function is zero. This implies that the sum of each row of $D$ must be zero, leading to the relation $(D)_{ii} = -\\sum_{j \\neq i} (D)_{ij}$.\n\nThe second derivative is approximated by applying the first derivative operator twice. The vector of second derivatives, $\\mathbf{u}''$, is approximated by $D^2 \\mathbf{u}$, where $D^{(2)} = D^2$ is the second derivative differentiation matrix. The eigenvalue problem $-u''(x) = \\lambda u(x)$ is thus discretized as\n$$\n-D^{(2)} \\mathbf{u} = \\lambda \\mathbf{u}.\n$$\nThis represents a system of $N+1$ linear equations. The boundary conditions $u(-1) = 0$ and $u(1) = 0$ must now be enforced. Since $x_0 = \\cos(0) = 1$ and $x_N = \\cos(\\pi) = -1$, the conditions translate to $u_0 = u(x_0) = 0$ and $u_N = u(x_N) = 0$.\n\nWe can now reduce the system to only the interior points $j = 1, \\dots, N-1$. For an interior row $j$, the equation is:\n$$\n-\\sum_{k=0}^{N} (D^{(2)})_{jk} u_k = \\lambda u_j.\n$$\nSubstituting $u_0 = 0$ and $u_N = 0$, the sum simplifies:\n$$\n-(D^{(2)})_{j0} u_0 - \\sum_{k=1}^{N-1} (D^{(2)})_{jk} u_k - (D^{(2)})_{jN} u_N = \\lambda u_j\n$$\n$$\n-\\sum_{k=1}^{N-1} (D^{(2)})_{jk} u_k = \\lambda u_j.\n$$\nThis constitutes a standard matrix eigenvalue problem of size $(N-1) \\times (N-1)$:\n$$\nA \\mathbf{u}_{\\text{int}} = \\lambda \\mathbf{u}_{\\text{int}},\n$$\nwhere $\\mathbf{u}_{\\text{int}} = [u_1, u_2, \\dots, u_{N-1}]^T$ is the vector of function values at the interior points, and $A$ is the $(N-1) \\times (N-1)$ matrix formed by taking the negative of the submatrix of $D^{(2)}$ corresponding to rows and columns from $1$ to $N-1$.\n\nThe overall computational procedure is as follows:\n1.  For a given integer $N$, construct the $(N+1) \\times (N+1)$ Chebyshev differentiation matrix $D$.\n2.  Compute the second derivative matrix $D^{(2)} = D^2$.\n3.  Extract the interior submatrix from $-D^{(2)}$ to form the $(N-1) \\times (N-1)$ matrix $A$.\n4.  Compute the eigenvalues of $A$. Since the original operator is self-adjoint, the eigenvalues of $A$ will be real. They are sorted in ascending order to obtain the numerical approximations $\\lambda_k^{\\text{num}}$ for $k = 1, \\dots, N-1$.\n5.  Generate the exact eigenvalues $\\lambda_k = (\\frac{k\\pi}{2})^2$ for $k = 1, \\dots, N-1$.\n6.  Calculate the maximum absolute relative error, $E_{\\max}(N)$, over all computed eigenvalues:\n    $$\n    E_{\\max}(N) = \\max_{1 \\le k \\le N-1} \\frac{\\left| \\lambda_k^{\\text{num}} - \\lambda_k \\right|}{\\lambda_k}.\n    $$\nThis procedure is repeated for each value of $N$ in the specified test suite.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef construct_chebyshev_diff_matrix(N):\n    \"\"\"\n    Constructs the Chebyshev first derivative differentiation matrix.\n\n    Args:\n        N (int): The number of intervals, which defines the matrix size (N+1)x(N+1).\n\n    Returns:\n        numpy.ndarray: The (N+1)x(N+1) differentiation matrix D.\n    \"\"\"\n    if N == 0:\n        return np.array([[0.0]])\n        \n    size = N + 1\n    D = np.zeros((size, size))\n    x = np.cos(np.pi * np.arange(size) / N)\n    \n    # Weights for the formula\n    c = np.ones(size)\n    c[0] = 2.0\n    c[-1] = 2.0\n\n    # Off-diagonal elements\n    for i in range(size):\n        for j in range(size):\n            if i != j:\n                D[i, j] = (c[i] / c[j]) * ((-1)**(i + j)) / (x[i] - x[j])\n    \n    # Diagonal elements using the row-sum-to-zero property\n    for i in range(size):\n        D[i, i] = -np.sum(D[i, :])\n        \n    return D\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases and prints the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [2, 3, 8, 16, 64]\n    \n    results = []\n    \n    for N in test_cases:\n        # Step 1: Construct the Chebyshev first derivative matrix D.\n        D = construct_chebyshev_diff_matrix(N)\n        \n        # Step 2: Compute the second derivative matrix D^(2) = D^2.\n        D2 = D @ D\n        \n        # Step 3: Form the matrix A for the interior problem.\n        # The equation is -u'' = lambda*u. A is the discretization of -d^2/dx^2.\n        # Boundary conditions u(-1)=0, u(1)=0 are imposed by taking the submatrix\n        # corresponding to interior points (j=1, ..., N-1).\n        A = -D2[1:N, 1:N]\n        \n        # Step 4: Compute the eigenvalues of A.\n        # For a real matrix A, eigenvalues can be complex. The analytical problem\n        # has real eigenvalues, so we take the real part of the numerical solution.\n        # A should be nearly symmetric, yielding nearly real eigenvalues.\n        numerical_eigenvalues = np.sort(np.real(np.linalg.eigvals(A)))\n        \n        # Step 5: Compute the exact eigenvalues.\n        # The eigenvalues correspond to k = 1, 2, ..., N-1.\n        k = np.arange(1, N)\n        exact_eigenvalues = (k * np.pi / 2.0)**2\n        \n        # Step 6: Calculate the maximum absolute relative error.\n        # For N=2, A is 1x1, so there is only one eigenvalue.\n        if N  1:\n            relative_errors = np.abs(numerical_eigenvalues - exact_eigenvalues) / exact_eigenvalues\n            max_relative_error = np.max(relative_errors)\n        else: # Case N=1 has no interior points, so error is undefined.\n            max_relative_error = np.nan\n\n        results.append(max_relative_error)\n\n    # Final print statement in the exact required format.\n    # The example format \"1.234567e-03\" has 7 significant digits, which corresponds\n    # to a precision of 6 digits after the decimal point in scientific notation.\n    print(f\"[{','.join(f'{r:.6e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Moving beyond static problems, this practice tackles the challenge of solving time-dependent partial differential equations, such as the linear advection equation. Pseudospectral methods for hyperbolic problems can be prone to instability, but this can be remedied by carefully imposing boundary conditions using a Simultaneous Approximation Term (SAT). You will learn to construct a stable semi-discrete scheme and verify its stability using the energy method, a powerful tool for analyzing time-dependent numerical systems. ",
            "id": "3179536",
            "problem": "Consider the one-dimensional linear advection equation $u_t + a\\,u_x = 0$ on the closed interval $[-1,1]$, where $a$ is a constant advection speed. In a pseudospectral collocation approach, approximate spatial derivatives using Chebyshev–Gauss–Lobatto nodes and the associated first-derivative differentiation matrix. Impose an inflow boundary condition via a Simultaneous Approximation Term (SAT) in an upwind fashion. Investigate the stability of the resulting semi-discrete operator by an energy method in a discrete inner product consistent with the Chebyshev–Gauss–Lobatto quadrature.\n\nFundamental basis you must use:\n- The method of lines converts a partial differential equation into a system of ordinary differential equations by discretizing only in space, yielding $u_t = \\mathcal{L}\\,u$, where $\\mathcal{L}$ is the semi-discrete spatial operator.\n- Chebyshev–Gauss–Lobatto nodes are defined by $x_j = \\cos\\!\\left(\\frac{\\pi j}{N}\\right)$ for $j=0,1,\\dots,N$, where $N$ is the polynomial degree parameter, and they are used for collocation of derivatives.\n- The first-derivative pseudospectral differentiation matrix on Chebyshev–Gauss–Lobatto nodes is obtained by differentiating the Lagrange interpolation polynomials at the nodes.\n- The energy method assesses stability by studying the time rate of change of a discrete energy norm $\\|u\\|_H^2 = u^\\top H u$ for some symmetric positive definite matrix $H$ that defines a discrete inner product. Stability is indicated if $\\frac{d}{dt}\\|u\\|_H^2 \\le 0$ for all states $u$, which is equivalent to the symmetric matrix $S = H\\mathcal{L} + \\mathcal{L}^\\top H$ being negative semidefinite.\n\nYou must proceed as follows without using shortcut formulas that trivialize the derivation:\n1. Construct the Chebyshev–Gauss–Lobatto nodes $x_j$ on $[-1,1]$ for a given $N$.\n2. Derive and assemble the Chebyshev collocation first-derivative matrix $D$ by differentiating the Lagrange basis associated with these nodes and evaluating at the nodes.\n3. Choose a diagonal, symmetric positive definite quadrature weight matrix $H$ associated with Chebyshev–Gauss–Lobatto quadrature (you must use the weights consistent with the Chebyshev weight) so that $u^\\top H v$ approximates $\\int_{-1}^1 u(x)\\,v(x)\\,\\frac{dx}{\\sqrt{1-x^2}}$.\n4. Form the semi-discrete operator $\\mathcal{L}$ for the method of lines with an upwind SAT inflow boundary penalty of strength $s \\ge 0$, added only at the inflow boundary:\n   - If $a0$, the inflow boundary is at $x=-1$ (the left endpoint).\n   - If $a0$, the inflow boundary is at $x=+1$ (the right endpoint).\n   The upwind SAT penalty must penalize the deviation of the inflow boundary value through a rank-one term aligned with the inflow endpoint, scaled by the inverse of the corresponding quadrature weight so that its effect is measured in the $H$-inner product.\n5. Derive the symmetric part $S = H\\mathcal{L} + \\mathcal{L}^\\top H$ and explain how the energy method links the sign of its eigenvalues to stability.\n6. Implement a numerical test to check stability by computing the largest eigenvalue of $S$; report stability as a boolean by testing whether the largest eigenvalue is less than or equal to $10^{-10}$ (this tolerance accounts for floating-point roundoff).\n\nNo physical units or angles appear in this problem; all quantities are dimensionless. The final answers for the test suite must be booleans.\n\nTest Suite:\nUse the following parameter sets $(N,a,s)$, where $N$ is the number of intervals between Chebyshev–Gauss–Lobatto nodes (so there are $N+1$ nodes), $a$ is the advection speed, and $s$ is the upwind SAT penalty strength:\n- $(16, 1.0, 0.0)$\n- $(16, 1.0, 0.5)$\n- $(16, 1.0, 1.0)$\n- $(16, 1.0, 4.0)$\n- $(16, -1.0, 0.5)$\n- $(32, 1.0, 2.0)$\n- $(32, -1.0, 2.0)$\n\nProgram output specification:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,...]\"). Each entry must be a boolean indicating stability for its corresponding test case in the order listed above.",
            "solution": "The problem requires an analysis of the stability of a pseudospectral collocation method for the one-dimensional linear advection equation, $u_t + a\\,u_x = 0$, on the domain $x \\in [-1, 1]$. The stability is to be investigated using the energy method for a semi-discretization that employs a Simultaneous Approximation Term (SAT) to enforce the inflow boundary condition.\n\nThe method of lines is employed, which discretizes the spatial derivatives to convert the partial differential equation (PDE) into a system of ordinary differential equations (ODEs) of the form $\\frac{d\\vec{u}}{dt} = \\mathcal{L}\\vec{u}$. Here, $\\vec{u}(t)$ is a vector of the solution values at the collocation points at time $t$, and $\\mathcal{L}$ is the semi-discrete spatial operator.\n\n**1. Chebyshev–Gauss–Lobatto Nodes and Quadrature**\nThe solution $u(x,t)$ is approximated by a polynomial interpolant, and the PDE is enforced at a set of collocation points. We use the $N+1$ Chebyshev–Gauss–Lobatto (CGL) nodes on the interval $[-1, 1]$, defined as:\n$$\nx_j = \\cos\\left(\\frac{\\pi j}{N}\\right) \\quad \\text{for } j=0, 1, \\dots, N\n$$\nNote that the nodes are ordered from $x_0 = 1$ to $x_N = -1$.\n\nThe stability analysis utilizes an energy method based on a discrete inner product that approximates the continuous inner product $\\langle u, v \\rangle_w = \\int_{-1}^1 u(x)v(x) \\frac{dx}{\\sqrt{1-x^2}}$. The corresponding discrete inner product is $(\\vec{u}, \\vec{v})_H = \\vec{u}^\\top H \\vec{v}$, where $H$ is a diagonal, symmetric positive definite matrix containing the quadrature weights. For CGL nodes and the Chebyshev weight function $w(x) = (1-x^2)^{-1/2}$, the quadrature weights are given by:\n$$\nw_j = \\frac{\\pi}{c_j N} \\quad \\text{for } j=0, 1, \\dots, N\n$$\nwhere $c_0 = c_N = 2$ and $c_j = 1$ for $j=1, \\dots, N-1$. The quadrature matrix is $H = \\text{diag}(w_0, w_1, \\dots, w_N)$. This matrix is symmetric and positive definite. The discrete energy of the solution is $\\|\\vec{u}\\|_H^2 = \\vec{u}^\\top H \\vec{u}$.\n\n**2. Chebyshev Collocation Differentiation Matrix**\nThe spatial derivative $u_x$ at the CGL nodes is approximated by the matrix-vector product $D\\vec{u}$, where $D$ is the $(N+1) \\times (N+1)$ Chebyshev differentiation matrix. The entries of $D$ are obtained by differentiating the Lagrange interpolating polynomials associated with the nodes $\\{x_j\\}$ and evaluating them at these same nodes. The entries of $D$ are given by:\n$$\nD_{ij} = \\begin{cases}\n\\frac{c_i}{c_j} \\frac{(-1)^{i+j}}{x_i - x_j},  i \\neq j \\\\\n\\frac{-x_j}{2(1-x_j^2)},  i = j, \\quad j=1, \\dots, N-1 \\\\\n\\frac{2N^2+1}{6},  i = j = 0 \\\\\n-\\frac{2N^2+1}{6},  i = j = N\n\\end{cases}\n$$\nwhere the coefficients $c_j$ are the same as defined for the quadrature weights.\n\n**3. Semi-discrete Operator with SAT**\nThe semi-discretization of $u_t + a\\,u_x = 0$ is $\\frac{d\\vec{u}}{dt} = -aD\\vec{u}$. To enforce the boundary condition without sacrificing stability or accuracy, we add a Simultaneous Approximation Term (SAT). For this problem, we analyze stability with homogeneous boundary conditions, i.e., the prescribed inflow value is $0$.\n\nThe operator $\\mathcal{L}$ is constructed as $\\mathcal{L} = -aD + P$, where $P$ is the penalty operator. The penalty is applied at the inflow boundary in an upwind fashion.\n- If $a  0$, the advection is in the positive $x$ direction. Since our nodes are ordered from $x_0=1$ to $x_N=-1$, the inflow boundary is at $x = -1$, corresponding to node $j=N$.\n- If $a  0$, the advection is in the negative $x$ direction. The inflow boundary is at $x = 1$, corresponding to node $j=0$.\n\nThe SAT penalizes the deviation of the numerical solution at the inflow node from the prescribed boundary value (here, $0$). The penalty term for the ODE system is constructed as a rank-one modification affecting only the inflow node. As specified, the penalty strength $s$ is scaled by the inverse of the corresponding quadrature weight.\nFor $a  0$ (inflow at $j=N$): The penalty term added to the right-hand side is $-s \\frac{1}{H_{NN}} u_N \\vec{e}_N$. The operator is $\\mathcal{L} = -aD - \\frac{s}{H_{NN}} E_{NN}$, where $E_{NN}$ is a matrix with a single $1$ at entry $(N,N)$ and zeros elsewhere, and $\\vec{e}_N$ is the corresponding standard basis vector.\nFor $a  0$ (inflow at $j=0$): The penalty term is $-s \\frac{1}{H_{00}} u_0 \\vec{e}_0$. The operator is $\\mathcal{L} = -aD - \\frac{s}{H_{00}} E_{00}$.\n\n**4. Energy Method Stability Analysis**\nThe stability of the semi-discrete system $\\frac{d\\vec{u}}{dt} = \\mathcal{L}\\vec{u}$ is assessed by examining the time evolution of the discrete energy $\\|\\vec{u}\\|_H^2$:\n$$\n\\frac{d}{dt} \\|\\vec{u}\\|_H^2 = \\frac{d}{dt}(\\vec{u}^\\top H \\vec{u}) = \\dot{\\vec{u}}^\\top H \\vec{u} + \\vec{u}^\\top H \\dot{\\vec{u}}\n$$\nSubstituting $\\dot{\\vec{u}} = \\mathcal{L}\\vec{u}$:\n$$\n\\frac{d}{dt} \\|\\vec{u}\\|_H^2 = (\\mathcal{L}\\vec{u})^\\top H \\vec{u} + \\vec{u}^\\top H (\\mathcal{L}\\vec{u}) = \\vec{u}^\\top (\\mathcal{L}^\\top H + H \\mathcal{L}) \\vec{u} = \\vec{u}^\\top S \\vec{u}\n$$\nwhere $S = H\\mathcal{L} + \\mathcal{L}^\\top H$. The system is stable if the energy does not grow in time, i.e., $\\frac{d}{dt}\\|\\vec{u}\\|_H^2 \\le 0$ for any state $\\vec{u}$. This is equivalent to the symmetric matrix $S$ being negative semidefinite, which means all its eigenvalues must be non-positive ($\\lambda_k(S) \\le 0$).\n\nWe now derive $S$. A crucial property of the Chebyshev differentiation matrix $D$ and the CGL quadrature matrix $H$ is the discrete sum-by-parts formula:\n$$\nHD + D^\\top H = E_{00} - E_{NN}\n$$\nThis identity reflects the behavior of integration by parts at the discrete level.\n\nLet's compute $S$ for the two cases:\nCase 1: $a  0$ (inflow at $j=N$).\n$\\mathcal{L} = -aD - \\frac{s}{H_{NN}} E_{NN}$.\n$$\nS = H\\left(-aD - \\frac{s}{H_{NN}} E_{NN}\\right) + \\left(-aD - \\frac{s}{H_{NN}} E_{NN}\\right)^\\top H\n$$\n$$\nS = -a(HD + D^\\top H) - \\frac{s}{H_{NN}}(H E_{NN} + E_{NN}^\\top H)\n$$\nSince $H$ is diagonal, $H E_{NN} = H_{NN} E_{NN}$ and $E_{NN}^\\top H = H_{NN} E_{NN}$.\n$$\nS = -a(E_{00} - E_{NN}) - \\frac{s}{H_{NN}}(H_{NN} E_{NN} + H_{NN} E_{NN}) = -a E_{00} + a E_{NN} - 2s E_{NN}\n$$\n$$\nS = -a E_{00} + (a - 2s) E_{NN}\n$$\nThis matrix $S$ is diagonal, with entries $S_{00} = -a$, $S_{NN} = a-2s$, and all other diagonal entries being $0$. For $S$ to be negative semidefinite, all its diagonal entries must be non-positive. Since $a0$, $S_{00}=-a  0$. We require $a - 2s \\le 0$, which implies $s \\ge a/2$.\n\nCase 2: $a  0$ (inflow at $j=0$).\n$\\mathcal{L} = -aD - \\frac{s}{H_{00}} E_{00}$.\nA similar derivation yields:\n$$\nS = -a(E_{00} - E_{NN}) - \\frac{s}{H_{00}}(H E_{00} + E_{00}^\\top H) = -a E_{00} + a E_{NN} - 2s E_{00}\n$$\n$$\nS = (-a - 2s) E_{00} + a E_{NN}\n$$\nThis is a diagonal matrix with $S_{00} = -a - 2s$ and $S_{NN}=a$. Since $a0$, $S_{NN}=a0$. For negative semidefiniteness, we need $-a - 2s \\le 0$, which implies $2s \\ge -a$, or $s \\ge -a/2 = |a|/2$.\n\nIn both cases, for stability, the penalty parameter $s$ must satisfy $s \\ge |a|/2$.\n\n**5. Numerical Stability Test**\nThe numerical implementation will construct the matrices $D$, $H$, and $\\mathcal{L}$ for each test case $(N, a, s)$. It will then form the symmetric matrix $S = H\\mathcal{L} + \\mathcal{L}^\\top H$ and compute its eigenvalues. The scheme is considered stable if the largest eigenvalue of $S$ is less than or equal to a small tolerance, here $10^{-10}$, to account for floating-point arithmetic errors.\nThe test cases can be evaluated against the derived condition $s \\ge |a|/2$:\n- $(16, 1.0, 0.0)$: $0.0 \\ge 1.0/2 \\implies 0.0 \\ge 0.5$ (False, unstable).\n- $(16, 1.0, 0.5)$: $0.5 \\ge 1.0/2 \\implies 0.5 \\ge 0.5$ (True, stable).\n- $(16, 1.0, 1.0)$: $1.0 \\ge 1.0/2 \\implies 1.0 \\ge 0.5$ (True, stable).\n- $(16, 1.0, 4.0)$: $4.0 \\ge 1.0/2 \\implies 4.0 \\ge 0.5$ (True, stable).\n- $(16, -1.0, 0.5)$: $0.5 \\ge |-1.0|/2 \\implies 0.5 \\ge 0.5$ (True, stable).\n- $(32, 1.0, 2.0)$: $2.0 \\ge 1.0/2 \\implies 2.0 \\ge 0.5$ (True, stable).\n- $(32, -1.0, 2.0)$: $2.0 \\ge |-1.0|/2 \\implies 2.0 \\ge 0.5$ (True, stable).\nThe implementation should confirm these analytical predictions.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef chebyshev_diff_matrix(N):\n    \"\"\"\n    Constructs the Chebyshev collocation differentiation matrix on\n    Chebyshev-Gauss-Lobatto nodes.\n\n    Args:\n        N (int): The polynomial degree, resulting in N+1 nodes.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]: A tuple containing:\n            - D (np.ndarray): The (N+1)x(N+1) differentiation matrix.\n            - x (np.ndarray): The (N+1) CGL nodes.\n    \"\"\"\n    if N == 0:\n        return np.array([[0.]]), np.array([[0.]])\n    \n    # CGL nodes\n    j = np.arange(N + 1)\n    x = np.cos(np.pi * j / N)\n\n    # c_j coefficients\n    c = np.ones(N + 1)\n    c[0] = 2.0\n    c[N] = 2.0\n\n    # Off-diagonal entries\n    # Use broadcasting to create matrices of x_i and x_j\n    X = np.tile(x, (N + 1, 1))\n    x_diff = X - X.T\n    \n    # Create matrix of (-1)^(i+j)\n    i = np.arange(N + 1)[:, np.newaxis]\n    j = np.arange(N + 1)[np.newaxis, :]\n    sign_matrix = (-1.0)**(i + j)\n\n    # Create matrix of c_i/c_j\n    c_ratio = np.outer(c, 1.0 / c)\n\n    D = c_ratio * sign_matrix / (x_diff + np.eye(N + 1)) # Add identity to avoid div by zero on diag\n    \n    # Diagonal entries\n    D[np.diag_indices_from(D)] = 0.0 # Clear diagonal before setting final values\n    \n    # Interior points\n    for j_diag in range(1, N):\n        D[j_diag, j_diag] = -x[j_diag] / (2.0 * (1.0 - x[j_diag]**2))\n        \n    # Endpoints\n    D[0, 0] = (2.0 * N**2 + 1.0) / 6.0\n    D[N, N] = -(2.0 * N**2 + 1.0) / 6.0\n\n    return D, x\n\ndef chebyshev_quadrature_matrix(N):\n    \"\"\"\n    Constructs the diagonal quadrature matrix H for CGL nodes.\n\n    Args:\n        N (int): The polynomial degree.\n\n    Returns:\n        np.ndarray: The (N+1)x(N+1) diagonal quadrature matrix H.\n    \"\"\"\n    c = np.ones(N + 1)\n    c[0] = 2.0\n    c[N] = 2.0\n    \n    weights = np.pi / (c * N)\n    H = np.diag(weights)\n    return H\n\ndef solve():\n    \"\"\"\n    Main function to perform stability analysis for the given test cases.\n    \"\"\"\n    test_cases = [\n        # (N, a, s)\n        (16, 1.0, 0.0),\n        (16, 1.0, 0.5),\n        (16, 1.0, 1.0),\n        (16, 1.0, 4.0),\n        (16, -1.0, 0.5),\n        (32, 1.0, 2.0),\n        (32, -1.0, 2.0),\n    ]\n\n    results = []\n    stability_tolerance = 1e-10\n\n    for N, a, s in test_cases:\n        # Step 1  2: Get differentiation matrix and nodes\n        D, x = chebyshev_diff_matrix(N)\n        \n        # Step 3: Get quadrature matrix\n        H = chebyshev_quadrature_matrix(N)\n        \n        # Step 4: Form the semi-discrete operator L\n        # The base operator is -a*D\n        L = -a * D\n        \n        # Add the upwind SAT penalty term\n        if a  0:\n            # Inflow is at x = -1, which is node N\n            inflow_idx = N\n            H_inflow = H[inflow_idx, inflow_idx]\n            P = np.zeros((N + 1, N + 1))\n            P[inflow_idx, inflow_idx] = -s / H_inflow\n            L += P\n        elif a  0:\n            # Inflow is at x = 1, which is node 0\n            inflow_idx = 0\n            H_inflow = H[inflow_idx, inflow_idx]\n            P = np.zeros((N + 1, N + 1))\n            P[inflow_idx, inflow_idx] = -s / H_inflow\n            L += P\n        # If a = 0, there is no flow, and L is the zero matrix, which is stable.\n        # This case is not in the test suite.\n\n        # Step 5: Form the symmetric part S\n        S = H @ L + L.T @ H\n\n        # Step 6: Check stability by computing the largest eigenvalue of S\n        # Since S is symmetric, all eigenvalues are real.\n        eigenvalues = np.linalg.eigvalsh(S)\n        max_eigenvalue = np.max(eigenvalues)\n\n        is_stable = max_eigenvalue = stability_tolerance\n        results.append(is_stable)\n\n    # Expected: [False, True, True, True, True, True, True]\n    \n    print(f\"[{','.join(str(r) for r in results)}]\")\n\n\nsolve()\n```"
        }
    ]
}