{
    "hands_on_practices": [
        {
            "introduction": "To build solutions to complex problems, we often start with simple building blocks. In the Finite Element Method, these blocks are basis functions defined over small, simple domains like triangles. This first practice invites you to derive the most fundamental of these: the linear basis functions on a triangular element. By working through this exercise, you will uncover the elegant connection between their algebraic form, their geometric meaning as area ratios, and their direct application in computing the stiffness matrix which is central to solving physical problems like heat diffusion. ",
            "id": "2375619",
            "problem": "Consider a single triangular finite element in two spatial dimensions with vertices at $v_{1} = (0,0)$, $v_{2} = (2,0)$, and $v_{3} = (0,1)$. In the Finite Element Method (FEM) for the Poisson equation with a scalar, constant diffusion coefficient $k$, the standard linear (first-order) basis functions on a triangle are the barycentric coordinates associated with the vertices. The barycentric coordinates are defined as affine functions that are equal to $1$ at their associated vertex, equal to $0$ at the other two vertices, and sum to $1$ at every point of the triangle. They admit a geometric interpretation as ratios of subtriangle areas formed by a point and the element edges. The element stiffness matrix entries for the scalar diffusion problem are given by the bilinear form integral $K_{ij} = \\int_{T} k \\, \\nabla N_{i} \\cdot \\nabla N_{j} \\, \\mathrm{d}A$, where $N_{i}$ denote the shape functions and $T$ is the triangular element domain.\n\nTasks:\n1) Starting only from the defining properties of barycentric coordinates on a triangle (affine, partition of unity, and Kronecker delta property at the vertices), derive explicit expressions for the three linear shape functions $N_{1}(x,y)$, $N_{2}(x,y)$, and $N_{3}(x,y)$ on the given triangle. Use the area interpretation to justify the geometric meaning of each $N_{i}$ as the (signed) ratio of the area of the subtriangle opposite vertex $v_{i}$ to the total area of $T$.\n2) Prove the partition of unity property $N_{1} + N_{2} + N_{3} = 1$ and the nodal interpolation property $N_{i}(v_{j}) = \\delta_{ij}$ for $i,j \\in \\{1,2,3\\}$.\n3) Show that the gradients $\\nabla N_{i}$ are constant vectors on $T$, determine them explicitly, and explain their geometric interpretation in relation to the edges opposite the corresponding vertices.\n4) For the scalar diffusion problem with constant coefficient $k = 3$, compute the off-diagonal stiffness entry $K_{12} = \\int_{T} k \\, \\nabla N_{1} \\cdot \\nabla N_{2} \\, \\mathrm{d}A$ for this element. Express your final answer as a single exact real number. Do not round.",
            "solution": "The problem as stated is a standard, fundamental exercise in the theory of the Finite Element Method. It is scientifically grounded, well-posed, and free from any factual or logical inconsistencies. The definitions and tasks are clear and objective. Therefore, the problem is valid and we shall proceed to construct the solution with requisite rigor.\n\nThe triangular element $T$ is defined by vertices $v_{1} = (0,0)$, $v_{2} = (2,0)$, and $v_{3} = (0,1)$. The area of this triangle, denoted by $A$, is given by $A = \\frac{1}{2} \\times \\text{base} \\times \\text{height} = \\frac{1}{2} \\times 2 \\times 1 = 1$.\n\n**1) Derivation of Shape Functions**\n\nThe linear shape functions $N_{i}(x,y)$ are affine functions of the form $N_{i}(x,y) = a_{i}x + b_{i}y + c_{i}$. The coefficients for each function are determined by the Kronecker delta property at the vertices, $N_{i}(v_{j}) = \\delta_{ij}$.\n\nFor $N_{1}(x,y)$:\nWe impose the conditions $N_{1}(v_{1})=1$, $N_{1}(v_{2})=0$, and $N_{1}(v_{3})=0$.\n$N_{1}(0,0) = a_{1}(0) + b_{1}(0) + c_{1} = 1 \\implies c_{1} = 1$.\n$N_{1}(2,0) = a_{1}(2) + b_{1}(0) + c_{1} = 0 \\implies 2a_{1} + 1 = 0 \\implies a_{1} = -\\frac{1}{2}$.\n$N_{1}(0,1) = a_{1}(0) + b_{1}(1) + c_{1} = 0 \\implies b_{1} + 1 = 0 \\implies b_{1} = -1$.\nThus, $N_{1}(x,y) = -\\frac{1}{2}x - y + 1$.\n\nFor $N_{2}(x,y)$:\nWe impose the conditions $N_{2}(v_{1})=0$, $N_{2}(v_{2})=1$, and $N_{2}(v_{3})=0$.\n$N_{2}(0,0) = a_{2}(0) + b_{2}(0) + c_{2} = 0 \\implies c_{2} = 0$.\n$N_{2}(2,0) = a_{2}(2) + b_{2}(0) + c_{2} = 1 \\implies 2a_{2} = 1 \\implies a_{2} = \\frac{1}{2}$.\n$N_{2}(0,1) = a_{2}(0) + b_{2}(1) + c_{2} = 0 \\implies b_{2} = 0$.\nThus, $N_{2}(x,y) = \\frac{1}{2}x$.\n\nFor $N_{3}(x,y)$:\nWe impose the conditions $N_{3}(v_{1})=0$, $N_{3}(v_{2})=0$, and $N_{3}(v_{3})=1$.\n$N_{3}(0,0) = a_{3}(0) + b_{3}(0) + c_{3} = 0 \\implies c_{3} = 0$.\n$N_{3}(2,0) = a_{3}(2) + b_{3}(0) + c_{3} = 0 \\implies 2a_{3} = 0 \\implies a_{3} = 0$.\n$N_{3}(0,1) = a_{3}(0) + b_{3}(1) + c_{3} = 1 \\implies b_{3} = 1$.\nThus, $N_{3}(x,y) = y$.\n\nThe geometric interpretation of $N_{i}$ is the ratio of the area of the subtriangle formed by an arbitrary point $P=(x,y)$ and the edge opposite vertex $v_{i}$, to the total area of the element $T$. Let us verify this for $N_{1}$. The subtriangle opposite $v_{1}$ has vertices $P(x,y)$, $v_{2}(2,0)$, and $v_{3}(0,1)$. Its area, $A_{1}$, can be calculated using the shoelace formula:\n$$ A_{1} = \\frac{1}{2} | (x(0) + 2(1) + 0(y)) - (y(2) + 0(0) + 1(x)) | = \\frac{1}{2} | 2 - (2y+x) | $$\nFor any point $(x,y)$ inside the triangle $T$, we have $x > 0$, $y > 0$, and $\\frac{x}{2} + y < 1$, which implies $x+2y < 2$. The term inside the absolute value is positive. So, $A_{1} = \\frac{1}{2}(2 - x - 2y) = 1 - \\frac{1}{2}x - y$.\nThe ratio is $N_{1} = \\frac{A_{1}}{A} = \\frac{1 - \\frac{1}{2}x - y}{1} = 1 - \\frac{1}{2}x - y$. This matches our derived expression. Similar calculations for $N_{2}$ and $N_{3}$ confirm their geometric area-ratio definitions.\n\n**2) Proof of Properties**\n\nThe problem asks to prove properties that were already used in the derivation. We will verify that our derived expressions satisfy them.\n\nPartition of Unity: $N_{1} + N_{2} + N_{3} = 1$.\n$$ (1 - \\frac{1}{2}x - y) + (\\frac{1}{2}x) + (y) = 1 - \\frac{1}{2}x + \\frac{1}{2}x - y + y = 1 $$\nThe property holds for all $(x,y)$.\n\nNodal Interpolation Property: $N_{i}(v_{j}) = \\delta_{ij}$.\nLet us verify this for the $9$ combinations.\n$N_{1}(v_{1}) = 1 - \\frac{1}{2}(0) - 0 = 1$. $N_{1}(v_{2}) = 1 - \\frac{1}{2}(2) - 0 = 0$. $N_{1}(v_{3}) = 1 - \\frac{1}{2}(0) - 1 = 0$.\n$N_{2}(v_{1}) = \\frac{1}{2}(0) = 0$. $N_{2}(v_{2}) = \\frac{1}{2}(2) = 1$. $N_{2}(v_{3}) = \\frac{1}{2}(0) = 0$.\n$N_{3}(v_{1}) = 0$. $N_{3}(v_{2}) = 0$. $N_{3}(v_{3}) = 1$.\nAll conditions are satisfied, confirming $N_{i}(v_{j}) = \\delta_{ij}$.\n\n**3) Gradients of Shape Functions**\n\nThe gradient of a scalar function $f(x,y)$ is $\\nabla f = (\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y})$. Since the shape functions are affine, their partial derivatives are constants, and so are their gradients.\n$$ \\nabla N_{1} = \\left( \\frac{\\partial}{\\partial x}(1 - \\frac{1}{2}x - y), \\frac{\\partial}{\\partial y}(1 - \\frac{1}{2}x - y) \\right) = \\left(-\\frac{1}{2}, -1\\right) $$\n$$ \\nabla N_{2} = \\left( \\frac{\\partial}{\\partial x}(\\frac{1}{2}x), \\frac{\\partial}{\\partial y}(\\frac{1}{2}x) \\right) = \\left(\\frac{1}{2}, 0\\right) $$\n$$ \\nabla N_{3} = \\left( \\frac{\\partial}{\\partial x}(y), \\frac{\\partial}{\\partial y}(y) \\right) = (0, 1) $$\nThe gradients are indeed constant vectors across the element $T$.\n\nGeometric Interpretation: The gradient $\\nabla N_{i}$ is a vector that is orthogonal to the level sets of $N_{i}$. The level sets are lines where $N_{i}$ is constant. The line where $N_{i}=0$ is precisely the edge of the triangle opposite to vertex $v_{i}$. Therefore, $\\nabla N_{i}$ is a vector normal to the edge opposite $v_{i}$, pointing from the edge (where $N_{i}=0$) towards $v_{i}$ (where $N_{i}=1$), which is the direction of steepest ascent.\n- Edge opposite $v_{1}$: connects $v_{2}(2,0)$ and $v_{3}(0,1)$. Direction vector is $(-2,1)$. A normal vector is $(1,2)$. $\\nabla N_{1} = (-\\frac{1}{2}, -1) = -\\frac{1}{2}(1,2)$. This is indeed normal to the edge.\n- Edge opposite $v_{2}$: connects $v_{1}(0,0)$ and $v_{3}(0,1)$. Direction vector is $(0,1)$. A normal vector is $(1,0)$. $\\nabla N_{2} = (\\frac{1}{2}, 0) = \\frac{1}{2}(1,0)$. This is normal to the edge.\n- Edge opposite $v_{3}$: connects $v_{1}(0,0)$ and $v_{2}(2,0)$. Direction vector is $(2,0)$. A normal vector is $(0,1)$. $\\nabla N_{3} = (0,1)$, which is normal to the edge.\n\n**4) Computation of Stiffness Matrix Entry $K_{12}$**\n\nThe stiffness matrix entry $K_{12}$ is given by the formula $K_{12} = \\int_{T} k \\, \\nabla N_{1} \\cdot \\nabla N_{2} \\, \\mathrm{d}A$, with the diffusion coefficient $k=3$.\nFirst, calculate the dot product of the gradients:\n$$ \\nabla N_{1} \\cdot \\nabla N_{2} = \\left(-\\frac{1}{2}, -1\\right) \\cdot \\left(\\frac{1}{2}, 0\\right) = \\left(-\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) + (-1)(0) = -\\frac{1}{4} $$\nThe integrand is $k \\, \\nabla N_{1} \\cdot \\nabla N_{2} = 3 \\times (-\\frac{1}{4}) = -\\frac{3}{4}$.\nSince the integrand is a constant, the integral is this constant multiplied by the area of the domain of integration, $A = 1$.\n$$ K_{12} = \\int_{T} \\left(-\\frac{3}{4}\\right) \\mathrm{d}A = -\\frac{3}{4} \\int_{T} \\mathrm{d}A = -\\frac{3}{4} \\times A = -\\frac{3}{4} \\times 1 = -\\frac{3}{4} $$\nThe value of the off-diagonal stiffness entry is $-\\frac{3}{4}$.",
            "answer": "$$\\boxed{-\\frac{3}{4}}$$"
        },
        {
            "introduction": "A well-chosen set of basis functions should not only approximate a field accurately but also preserve its fundamental physical properties. One such property is the conservation of total 'mass' (or charge, or energy), which is tied to whether the basis set can represent a constant field, a property closely related to the partition of unity. This coding exercise provides a direct, hands-on test of this crucial principle, challenging you to investigate why some approximations conserve mass perfectly while others do not. ",
            "id": "3100728",
            "problem": "You will investigate mass conservation when approximating a scalar field on the interval $[0,1]$ using finite sets of basis (shape) functions. In this setting, a set of basis functions $\\{\\phi_i(x)\\}_{i=1}^n$ is said to form a partition of unity if $\\sum_{i=1}^n \\phi_i(x) = 1$ for all $x \\in [0,1]$. Mass is defined as the integral of a field over the domain, namely $m(u) = \\int_0^1 u(x)\\,dx$. A mass-conserving approximation $\\tilde{u}$ for a given field $u$ satisfies $m(\\tilde{u}) = m(u)$.\n\nUsing only the definitions of an inner product, linear span, and orthogonal projection in the Lebesgue space of square-integrable functions (L2), do the following:\n\n- For each specified basis $\\{\\phi_i\\}_{i=1}^n$ and target field $u(x)$ below, compute the coefficients $c \\in \\mathbb{R}^n$ that minimize the squared error $\\int_0^1 \\left(u(x) - \\sum_{i=1}^n c_i \\phi_i(x)\\right)^2 dx$. Let the resulting approximation be $\\tilde{u}(x) = \\sum_{i=1}^n c_i \\phi_i(x)$.\n- Compute the exact mass $m(u) = \\int_0^1 u(x)\\,dx$ and the approximate mass $m(\\tilde{u}) = \\int_0^1 \\tilde{u}(x)\\,dx$.\n- Declare the diagnostic boolean as true if $|m(\\tilde{u}) - m(u)| \\le \\tau$ and false otherwise, with absolute tolerance $\\tau = 10^{-10}$.\n- Your implementation must use numerically stable integration over $[0,1]$ for all required integrals, and must not rely on symbolic algebra.\n\nTest suite. Use the following $5$ test cases. The domain is always $[0,1]$ and the integrals are over this interval. The functions are:\n- Case $1$: Basis $\\{\\phi_1(x)=x,\\ \\phi_2(x)=x^2\\}$; target $u(x) = 1 + \\sin(2\\pi x)$.\n- Case $2$: Basis $\\{\\phi_1(x)=x,\\ \\phi_2(x)=x^2,\\ \\phi_3(x)=1\\}$; target $u(x) = 1 + \\sin(2\\pi x)$. This case tests the effect of adding a constant basis function.\n- Case $3$: Basis $\\{\\phi_1(x)=x,\\ \\phi_2(x)=1\\}$; target $u(x) = \\sin(6\\pi x)$.\n- Case $4$: Basis $\\{\\phi_1(x)=x^2\\}$; target $u(x) = 1$.\n- Case $5$: Basis $\\{\\phi_1(x)=x,\\ \\phi_2(x)=x^2\\}$; target $u(x) = 0$.\n\nOutput format. Your program should produce a single line of output containing the $5$ boolean results as a comma-separated list enclosed in square brackets, e.g., $[{\\rm True},{\\rm False},\\dots]$. No additional text should be printed. No physical units are involved in this problem. Angles appear only within trigonometric functions and are in radians by default.",
            "solution": "The problem requires us to determine whether a least-squares approximation of a function is mass-conserving for several choices of basis functions. The core of the problem lies in finding the coefficients of the approximation by minimizing the squared error in the $L^2$ norm, which is a standard orthogonal projection problem in a function space.\n\nLet the Hilbert space of square-integrable functions on the interval $[0,1]$ be denoted by $L^2([0,1])$. The inner product for two functions $f, g \\in L^2([0,1])$ is defined as:\n$$\n\\langle f, g \\rangle = \\int_0^1 f(x)g(x) \\, dx\n$$\nThe problem asks for the coefficients $c = (c_1, \\dots, c_n)^T \\in \\mathbb{R}^n$ that minimize the squared error, which is the squared $L^2$ norm of the difference between the target function $u(x)$ and its approximation $\\tilde{u}(x) = \\sum_{i=1}^n c_i \\phi_i(x)$.\n$$\nE(c_1, \\dots, c_n) = \\left\\| u - \\sum_{i=1}^n c_i \\phi_i \\right\\|^2 = \\int_0^1 \\left(u(x) - \\sum_{i=1}^n c_i \\phi_i(x)\\right)^2 dx\n$$\nTo find the minimum of this error functional $E$, we must set its partial derivatives with respect to each coefficient $c_j$ to zero for $j=1, \\dots, n$:\n$$\n\\frac{\\partial E}{\\partial c_j} = 0\n$$\nApplying the derivative, we get:\n$$\n\\frac{\\partial}{\\partial c_j} \\int_0^1 \\left(u(x) - \\sum_{i=1}^n c_i \\phi_i(x)\\right)^2 dx = \\int_0^1 2 \\left(u(x) - \\sum_{i=1}^n c_i \\phi_i(x)\\right) (-\\phi_j(x)) dx = 0\n$$\nThis simplifies to:\n$$\n\\int_0^1 \\left(\\sum_{i=1}^n c_i \\phi_i(x)\\right) \\phi_j(x) dx = \\int_0^1 u(x) \\phi_j(x) dx\n$$\nBy linearity of the integral, we can write this as:\n$$\n\\sum_{i=1}^n c_i \\int_0^1 \\phi_i(x) \\phi_j(x) dx = \\int_0^1 u(x) \\phi_j(x) dx\n$$\nUsing the inner product notation, this system of $n$ equations becomes:\n$$\n\\sum_{i=1}^n c_i \\langle \\phi_i, \\phi_j \\rangle = \\langle u, \\phi_j \\rangle \\quad \\text{for } j=1, \\dots, n\n$$\nThis is a system of linear equations, which can be expressed in matrix form as $Ac = b$, where:\n- $A$ is the Gram matrix, with entries $A_{ji} = \\langle \\phi_i, \\phi_j \\rangle$.\n- $b$ is a vector with entries $b_j = \\langle u, \\phi_j \\rangle$.\n- $c$ is the vector of unknown coefficients.\n\nAs long as the basis functions $\\{\\phi_i\\}_{i=1}^n$ are linearly independent, the Gram matrix $A$ is symmetric positive-definite and thus invertible. The unique solution for the coefficients is $c = A^{-1} b$.\n\nThe mass of a field $f(x)$ is defined as $m(f) = \\int_0^1 f(x) dx$. In inner product notation, this is $m(f) = \\langle f, 1 \\rangle$, where $1(x)=1$ is the constant function. The approximation $\\tilde{u}$ is mass-conserving if $m(\\tilde{u}) = m(u)$, which translates to $\\langle \\tilde{u}, 1 \\rangle = \\langle u, 1 \\rangle$.\n\nThe condition $\\sum_{i=1}^n c_i \\langle \\phi_i, \\phi_j \\rangle = \\langle u, \\phi_j \\rangle$ is equivalent to the orthogonality condition $\\langle u - \\tilde{u}, \\phi_j \\rangle = 0$ for all $j=1, \\dots, n$. This means the error vector $u - \\tilde{u}$ is orthogonal to every basis function. By linearity, the error vector is orthogonal to any function $v$ in the subspace spanned by the basis functions, $V = \\text{span}\\{\\phi_1, \\dots, \\phi_n\\}$. That is, $\\langle u - \\tilde{u}, v \\rangle = 0$ for all $v \\in V$.\n\nIf the constant function $1(x)$ belongs to the span of the basis functions (i.e., $1 \\in V$), we can set $v=1(x)$ in the orthogonality condition:\n$$\n\\langle u - \\tilde{u}, 1 \\rangle = 0 \\implies \\langle u, 1 \\rangle - \\langle \\tilde{u}, 1 \\rangle = 0 \\implies \\langle u, 1 \\rangle = \\langle \\tilde{u}, 1 \\rangle\n$$\nThis shows that $m(u) = m(\\tilde{u})$. Therefore, a sufficient condition for the least-squares approximation to be mass-conserving is that the constant function $1$ can be expressed as a linear combination of the basis functions.\n\nWe can apply this principle to the test cases:\n- Case $1$: Basis $\\{\\phi_1(x)=x, \\phi_2(x)=x^2\\}$. The function $1(x)$ cannot be written as $c_1 x + c_2 x^2$. Thus, $1 \\notin \\text{span}\\{x, x^2\\}$. Mass conservation is not guaranteed.\n- Case $2$: Basis $\\{\\phi_1(x)=x, \\phi_2(x)=x^2, \\phi_3(x)=1\\}$. The basis explicitly contains the constant function $1(x)$. Thus, $1 \\in \\text{span}\\{x, x^2, 1\\}$. Mass conservation is guaranteed.\n- Case $3$: Basis $\\{\\phi_1(x)=x, \\phi_2(x)=1\\}$. The basis explicitly contains the constant function $1(x)$. Thus, $1 \\in \\text{span}\\{x, 1\\}$. Mass conservation is guaranteed.\n- Case $4$: Basis $\\{\\phi_1(x)=x^2\\}$. The function $1(x)$ cannot be written as $c_1 x^2$. Thus, $1 \\notin \\text{span}\\{x^2\\}$. Mass conservation is not guaranteed.\n- Case $5$: Target $u(x)=0$. The exact mass is $m(u) = \\int_0^1 0\\,dx = 0$. The least-squares problem is to minimize $\\|\\sum c_i \\phi_i\\|^2$. For linearly independent basis functions, this is minimized only when all $c_i=0$. Thus $\\tilde{u}(x)=0$ and $m(\\tilde{u})=0$. Mass is trivially conserved regardless of the basis.\n\nThe computational procedure is as follows:\n1. For each test case, define the basis functions $\\phi_i(x)$ and the target function $u(x)$.\n2. Construct the Gram matrix $A$ where $A_{ji} = \\int_0^1 \\phi_i(x) \\phi_j(x) dx$.\n3. Construct the vector $b$ where $b_j = \\int_0^1 u(x) \\phi_j(x) dx$.\n4. Solve the linear system $Ac=b$ for the coefficients $c$.\n5. Calculate the exact mass $m(u) = \\int_0^1 u(x) dx$.\n6. Calculate the approximate mass $m(\\tilde{u}) = \\int_0^1 \\sum_{i=1}^n c_i \\phi_i(x) dx = \\sum_{i=1}^n c_i \\int_0^1 \\phi_i(x) dx$.\n7. Check if $|m(\\tilde{u}) - m(u)| \\le \\tau$ with $\\tau = 10^{-10}$.\n\nAll integrations are performed numerically using `scipy.integrate.quad`. The linear system is solved using `numpy.linalg.solve`.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Computes mass conservation diagnostics for L2-approximations of functions.\n    \"\"\"\n    \n    # Define the 5 test cases from the problem statement.\n    test_cases = [\n        {\n            \"basis\": [lambda x: x, lambda x: x**2],\n            \"target\": lambda x: 1 + np.sin(2 * np.pi * x)\n        },\n        {\n            \"basis\": [lambda x: x, lambda x: x**2, lambda x: 1.0],\n            \"target\": lambda x: 1 + np.sin(2 * np.pi * x)\n        },\n        {\n            \"basis\": [lambda x: x, lambda x: 1.0],\n            \"target\": lambda x: np.sin(6 * np.pi * x)\n        },\n        {\n            \"basis\": [lambda x: x**2],\n            \"target\": lambda x: 1.0\n        },\n        {\n            \"basis\": [lambda x: x, lambda x: x**2],\n            \"target\": lambda x: 0.0\n        }\n    ]\n\n    results = []\n    tolerance = 1e-10\n    domain = (0, 1)\n\n    for case in test_cases:\n        basis_funcs = case[\"basis\"]\n        target_func = case[\"target\"]\n        n = len(basis_funcs)\n\n        # 1. Construct the Gram matrix A and vector b\n        # A_ji = <phi_i, phi_j>\n        # b_j = <u, phi_j>\n        A = np.zeros((n, n))\n        b = np.zeros(n)\n\n        for j in range(n):\n            phi_j = basis_funcs[j]\n            # b_j entry\n            integrand_b = lambda x: target_func(x) * phi_j(x)\n            b[j], _ = quad(integrand_b, domain[0], domain[1])\n            \n            for i in range(n):\n                phi_i = basis_funcs[i]\n                # A_ji entry\n                integrand_A = lambda x: phi_i(x) * phi_j(x)\n                A[j, i], _ = quad(integrand_A, domain[0], domain[1])\n\n        # 2. Solve Ac = b for coefficients c\n        if n > 0:\n            c = np.linalg.solve(A, b)\n        else:\n            c = np.array([])\n\n        # 3. Calculate exact mass m(u)\n        exact_mass, _ = quad(target_func, domain[0], domain[1])\n        \n        # 4. Calculate approximate mass m(u_tilde)\n        # m(u_tilde) = sum(c_i * integral(phi_i))\n        mass_of_basis_funcs = np.array([quad(phi, domain[0], domain[1])[0] for phi in basis_funcs])\n        approximate_mass = np.dot(c, mass_of_basis_funcs)\n\n        # 5. Compare masses and store the boolean diagnostic\n        is_conserved = np.abs(approximate_mass - exact_mass) = tolerance\n        results.append(is_conserved)\n\n    # Format and print the final output\n    # The str() of a Python bool ('True', 'False') matches the required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once we know how to construct basis functions, a critical question arises in practice: what kind of basis functions should we use for the best performance? This final practice tackles the classic trade-off between using many simple, low-order elements ($h$-version) versus using a few sophisticated, high-order elements ($p$-version). By implementing both strategies to solve a Poisson problem, you will gain tangible insight into their convergence properties and learn how to make informed decisions to achieve accuracy efficiently. ",
            "id": "2375591",
            "problem": "Write a complete, runnable program that, for the one-dimensional Poisson boundary value problem on the unit interval with a smooth exact solution, compares accuracy against a simple, size-based computational cost metric for different combinations of mesh refinement and polynomial degree in the finite element method.\n\nConsider the boundary value problem on the domain $[0,1]$:\n- Find $u: [0,1] \\rightarrow \\mathbb{R}$ such that\n$$\n-u''(x) = f(x) \\quad \\text{for } x \\in (0,1), \\quad u(0)=0, \\; u(1)=0,\n$$\nwith the exact solution specified as\n$$\nu(x) = \\sin(2\\pi x),\n$$\nso that\n$$\nf(x) = (2\\pi)^2 \\sin(2\\pi x).\n$$\n\nLet $N \\in \\mathbb{N}$ be the number of uniform elements partitioning $[0,1]$ and let $p \\in \\mathbb{N}$ be the local polynomial degree. Use a standard conforming finite element space consisting of continuous, piecewise-polynomial Lagrange basis (shape) functions of degree $p$ on each element, constructed from the reference element $[-1,1]$ via an affine map, with the $p+1$ local interpolation nodes taken to be equispaced points in the reference coordinate. Impose the homogeneous Dirichlet boundary conditions strongly at $x=0$ and $x=1$.\n\nFormulate and solve the Galerkin problem: find $u_h$ in the finite element space with $u_h(0)=0$ and $u_h(1)=0$ such that\n$$\n\\int_0^1 u_h'(x)\\, v_h'(x) \\, dx \\;=\\; \\int_0^1 f(x)\\, v_h(x) \\, dx \\quad \\text{for all admissible } v_h.\n$$\n\nDefine the computational cost metric for a given pair $(N,p)$ as the total number of free (non-Dirichlet) degrees of freedom,\n$$\n\\text{cost}(N,p) \\equiv \\text{ndof}(N,p) = N\\,p - 1,\n$$\nwhich follows from the one-dimensional, continuous, degree-$p$ Lagrange finite element space on a uniform mesh with homogeneous Dirichlet boundary conditions at both endpoints. If $\\text{ndof}(N,p)=0$, interpret the discrete solution as the identically zero function.\n\nFor each specified test case $(N,p)$, compute:\n1. The integer $\\text{ndof}(N,p)$ as defined above.\n2. The $L^2$-norm of the error,\n$$\n\\lVert u - u_h \\rVert_{L^2(0,1)} \\;=\\; \\left( \\int_0^1 \\big(u(x)-u_h(x)\\big)^2 \\, dx \\right)^{1/2},\n$$\nevaluated to high numerical accuracy.\n\nTest Suite:\n- Case A (many low-order elements; $h$-version): $(N,p)=(64,1)$.\n- Case B (few high-order elements; $p$-version): $(N,p)=(4,8)$.\n- Case C (boundary-degenerate case): $(N,p)=(1,1)$.\n- Case D (intermediate): $(N,p)=(16,2)$.\n- Case E (extreme $p$-version on a single element): $(N,p)=(1,12)$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result must be a two-element list $[\\text{ndof}, \\text{error}]$ where $\\text{ndof}$ is an integer and $\\text{error}$ is a floating-point number rounded to $10$ significant digits. For the test suite ordered as A, B, C, D, E, the output must have the form:\n$$\n\\big[[\\text{ndof}_A,\\text{error}_A],[\\text{ndof}_B,\\text{error}_B],[\\text{ndof}_C,\\text{error}_C],[\\text{ndof}_D,\\text{error}_D],[\\text{ndof}_E,\\text{error}_E]\\big].\n$$",
            "solution": "The problem statement has been subjected to rigorous validation and is determined to be valid. It is scientifically grounded, well-posed, objective, and complete. It describes a standard problem in the numerical analysis of partial differential equations, specifically the finite element method (FEM) for the one-dimensional Poisson equation. All parameters, equations, and definitions are mathematically and scientifically consistent. We may therefore proceed with the solution.\n\nThe problem requires a comparison of accuracy versus a computational cost metric for different finite element discretizations of the boundary value problem:\n$$\n-u''(x) = f(x) \\quad \\text{for } x \\in (0,1), \\quad u(0)=0, \\; u(1)=0\n$$\nwhere the exact solution is given as $u(x) = \\sin(2\\pi x)$, which implies the forcing function is $f(x) = (2\\pi)^2 \\sin(2\\pi x)$.\n\nThe solution will be constructed following the principles of the Galerkin finite element method.\n\n### 1. Weak Formulation\nThe starting point is the weak (or variational) formulation of the problem. We multiply the differential equation by a sufficiently smooth test function $v(x)$ that satisfies the homogeneous boundary conditions, i.e., $v(0)=v(1)=0$, and integrate over the domain $\\Omega = [0,1]$.\n$$\n-\\int_0^1 u''(x) v(x) \\, dx = \\int_0^1 f(x) v(x) \\, dx\n$$\nApplying integration by parts to the left-hand side yields:\n$$\n\\int_0^1 u'(x) v'(x) \\, dx - \\left[ u'(x) v(x) \\right]_0^1 = \\int_0^1 f(x) v(x) \\, dx\n$$\nThe boundary term $[ u'(x) v(x) ]_0^1$ vanishes because the test function $v(x)$ is required to be zero at $x=0$ and $x=1$. We thus arrive at the weak formulation: find $u \\in H_0^1(0,1)$ such that\n$$\na(u,v) = L(v) \\quad \\forall v \\in H_0^1(0,1),\n$$\nwhere $a(u,v) = \\int_0^1 u'(x) v'(x) \\, dx$ is a bilinear form and $L(v) = \\int_0^1 f(x) v(x) \\, dx$ is a linear functional. $H_0^1(0,1)$ is the Sobolev space of functions with square-integrable first derivatives that vanish at the boundaries.\n\n### 2. Finite Element Discretization\nThe continuous problem is discretized by replacing the infinite-dimensional function space $H_0^1(0,1)$ with a finite-dimensional subspace $V_h \\subset H_0^1(0,1)$. The domain $[0,1]$ is partitioned into $N$ uniform elements $K_e = [x_e, x_{e+1}]$ of size $h=1/N$. On each element, the solution is approximated by a polynomial of degree $p$.\n\nThe finite element space $V_h$ consists of continuous, piecewise-polynomial functions of degree $p$. A basis for this space is constructed using global basis functions $\\phi_i(x)$, such that any function $u_h \\in V_h$ can be written as a linear combination:\n$$\nu_h(x) = \\sum_{i=1}^{\\text{ndof}} U_i \\phi_i(x)\n$$\nHere, $U_i$ are the unknown coefficients, which correspond to the values of $u_h$ at the interior nodes of the mesh, and $\\phi_i(x)$ are the basis functions associated with these nodes. The total number of degrees of freedom (DoFs) after enforcing the homogeneous Dirichlet boundary conditions is given as $\\text{ndof}(N,p) = Np-1$.\n\nThe Galerkin method seeks an approximate solution $u_h \\in V_h$ such that the weak form holds for all test functions $v_h \\in V_h$. By choosing the test functions to be the basis functions themselves, $v_h = \\phi_j(x)$, we obtain a system of linear equations:\n$$\n\\sum_{i=1}^{\\text{ndof}} \\left( \\int_0^1 \\phi_i'(x) \\phi_j'(x) \\, dx \\right) U_i = \\int_0^1 f(x) \\phi_j(x) \\, dx \\quad \\text{for } j=1, \\dots, \\text{ndof}\n$$\nThis is the linear system $\\mathbf{A}\\mathbf{U} = \\mathbf{b}$, where:\n-   The stiffness matrix $\\mathbf{A}$ has entries $A_{ji} = a(\\phi_i, \\phi_j) = \\int_0^1 \\phi_i'(x) \\phi_j'(x) \\, dx$.\n-   The load vector $\\mathbf{b}$ has entries $b_j = L(\\phi_j) = \\int_0^1 f(x) \\phi_j(x) \\, dx$.\n-   The solution vector $\\mathbf{U}$ contains the unknown coefficients $U_i$.\n\n### 3. System Assembly using a Reference Element\nThe integrals for $\\mathbf{A}$ and $\\mathbf{b}$ are computed by summing contributions from each element $K_e$. This process is standardized by mapping each physical element $K_e = [x_e, x_{e+1}]$ to a single reference element $\\hat{K} = [-1,1]$ via the affine transformation:\n$$\nx(\\xi) = x_e + \\frac{h}{2}(\\xi+1)\n$$\nThe differential element transforms as $dx = \\frac{h}{2}d\\xi$, and the derivative operator transforms as $\\frac{d}{dx} = \\frac{2}{h}\\frac{d}{d\\xi}$.\n\nThe basis functions on the reference element, $\\hat{\\phi}_j(\\xi)$, are degree-$p$ Lagrange polynomials defined by a set of $p+1$ equispaced nodes $\\xi_j = -1 + j\\frac{2}{p}$ for $j=0,\\dots,p$.\nThe element stiffness matrix and load vector for element $e$ are then computed on the reference element:\n$$\nA^e_{ij} = \\int_{-1}^1 \\left(\\frac{2}{h}\\frac{d\\hat{\\phi}_i}{d\\xi}\\right) \\left(\\frac{2}{h}\\frac{d\\hat{\\phi}_j}{d\\xi}\\right) \\frac{h}{2} d\\xi = \\frac{2}{h} \\int_{-1}^1 \\frac{d\\hat{\\phi}_i}{d\\xi} \\frac{d\\hat{\\phi}_j}{d\\xi} d\\xi\n$$\n$$\nb^e_i = \\int_{-1}^1 f(x(\\xi)) \\hat{\\phi}_i(\\xi) \\frac{h}{2} d\\xi\n$$\nThese integrals are evaluated numerically using Gauss-Legendre quadrature, which provides high accuracy. The local matrices $A^e$ and vectors $b^e$ are then assembled into the global system $\\mathbf{A}\\mathbf{U} = \\mathbf{b}$, respecting the mapping between local and global degrees of freedom and excluding the fixed boundary DoFs.\n\n### 4. Solution and Error Computation\nOnce assembled, the symmetric positive-definite linear system $\\mathbf{A}\\mathbf{U} = \\mathbf{b}$ is solved for the vector of coefficients $\\mathbf{U}$. This vector, augmented with the zero values at the boundaries, fully defines the approximate solution $u_h(x)$.\n\nThe accuracy of the solution is quantified by the $L^2$-norm of the error, defined as:\n$$\n\\lVert u - u_h \\rVert_{L^2(0,1)} = \\left( \\int_0^1 \\big(u(x)-u_h(x)\\big)^2 \\, dx \\right)^{1/2}\n$$\nThis integral is also computed element-wise using numerical quadrature on the reference element:\n$$\n\\lVert u - u_h \\rVert_{L^2(0,1)}^2 = \\sum_{e=0}^{N-1} \\int_{-1}^1 \\left( u(x(\\xi)) - \\sum_{j=0}^{p} U^e_j \\hat{\\phi}_j(\\xi) \\right)^2 \\frac{h}{2} d\\xi\n$$\nwhere $U^e_j$ are the computed coefficients of the solution corresponding to the nodes of element $e$.\n\nA special case arises for $(N,p)=(1,1)$, where $\\text{ndof}=0$. In this configuration, the only two nodes are the boundary nodes at $x=0$ and $x=1$. The strong imposition of $u_h(0)=0$ and $u_h(1)=0$ forces the linear interpolant to be identically zero, $u_h(x) \\equiv 0$. The error is then simply the $L^2$-norm of the exact solution, $\\lVert u \\rVert_{L^2} = (\\int_0^1 \\sin^2(2\\pi x) dx)^{1/2} = 1/\\sqrt{2}$.\n\nThe implementation will carry out these steps for each test case $(N, p)$ and report the computed $\\text{ndof}$ and error.",
            "answer": "```python\nimport numpy as np\nfrom numpy.polynomial.legendre import leggauss\n\ndef get_lagrange_basis_and_deriv(p, eval_points):\n    \"\"\"\n    Computes degree-p Lagrange basis functions and their derivatives on [-1, 1].\n    The basis is defined by p+1 equispaced nodes.\n\n    Args:\n        p (int): Polynomial degree.\n        eval_points (np.ndarray): Points in [-1, 1] to evaluate basis at.\n\n    Returns:\n        tuple: A tuple (phi, dphi) where:\n               - phi is a (num_eval_points, p+1) array of basis function values.\n               - dphi is a (num_eval_points, p+1) array of basis derivative values.\n    \"\"\"\n    if p == 0:\n        return np.ones((len(eval_points), 1)), np.zeros((len(eval_points), 1))\n\n    nodes = np.linspace(-1, 1, p + 1)\n    num_eval_points = len(eval_points)\n    phi = np.zeros((num_eval_points, p + 1))\n    dphi = np.zeros((num_eval_points, p + 1))\n\n    for j in range(p + 1):  # For each basis function phi_j\n        # Denominator for phi_j\n        denom = np.prod([nodes[j] - nodes[k] for k in range(p + 1) if k != j])\n        \n        for i, xi in enumerate(eval_points):  # For each evaluation point\n            # Numerator for phi_j(xi)\n            num = np.prod([xi - nodes[k] for k in range(p + 1) if k != j])\n            phi[i, j] = num / denom\n\n            # Derivative dphi_j/dxi using the product rule\n            d_num = 0.0\n            if p > 0:\n                for m_idx in range(p + 1):\n                    if m_idx == j:\n                        continue\n                    # Product of all (xi - nodes[k]) except for k=j and k=m_idx\n                    term = np.prod([xi - nodes[k] for k in range(p + 1) if k != j and k != m_idx])\n                    d_num += term\n            dphi[i, j] = d_num / denom\n    return phi, dphi\n\ndef solve_fem(N, p):\n    \"\"\"\n    Solves the 1D Poisson problem using the Finite Element Method.\n\n    Args:\n        N (int): Number of elements.\n        p (int): Polynomial degree.\n\n    Returns:\n        tuple: A tuple (ndof, error) where:\n               - ndof is the number of free degrees of freedom.\n               - error is the L2 norm of the error.\n    \"\"\"\n    ndof = N * p - 1\n    \n    # Handle the boundary-degenerate case where no free DoFs exist\n    if ndof = 0:\n        # The solution is u_h=0. Error is ||u-0||_L2 = ||u||_L2.\n        # integral from 0 to 1 of sin^2(2*pi*x) dx is 1/2.\n        error = np.sqrt(0.5)\n        return max(0, ndof), error\n\n    h = 1.0 / N\n\n    # 1. Reference element calculations\n    # Use a high-order quadrature rule for accuracy\n    quad_order = p + 8\n    xi_q, w_q = leggauss(quad_order)\n\n    # Get basis functions and derivatives at quadrature points\n    phi, dphi = get_lagrange_basis_and_deriv(p, xi_q)\n\n    # Pre-compute reference stiffness matrix component\n    A_hat_integrand = np.einsum('qi,qj->ijq', dphi, dphi)\n    A_hat = np.einsum('ijq,q->ij', A_hat_integrand, w_q)\n    \n    # 2. System Assembly\n    A = np.zeros((ndof, ndof))\n    b = np.zeros(ndof)\n\n    for e in range(N):  # Loop over elements\n        # Element stiffness matrix\n        A_e = (2.0 / h) * A_hat\n        \n        # Element load vector\n        x_q = (e + 0.5) * h + 0.5 * h * xi_q  # Quadrature points in physical element\n        f_vals = (2 * np.pi)**2 * np.sin(2 * np.pi * x_q)\n        b_e = np.einsum('q,qi,q->i', f_vals, phi, w_q) * (h / 2.0)\n\n        # Map local to global DOFs and assemble\n        for i in range(p + 1):\n            I = e * p + i  # Global index before removing BCs\n            if I > 0 and I  N * p:  # Check if it is a free DoF\n                # Assemble load vector\n                b[I - 1] += b_e[i]\n                for j in range(p + 1):\n                    J = e * p + j\n                    if J > 0 and J  N * p:  # Check if it is a free DoF\n                        # Assemble stiffness matrix\n                        A[I - 1, J - 1] += A_e[i, j]\n\n    # 3. Solve system for free DoFs\n    U_free = np.linalg.solve(A, b)\n\n    # Create full solution vector including BCs\n    U_full = np.zeros(N * p + 1)\n    U_full[1:N * p] = U_free\n    \n    # 4. Error calculation\n    total_error_sq = 0.0\n    for e in range(N):\n        # Get nodal values for this element\n        U_e = U_full[e * p : (e + 1) * p + 1]\n        \n        # u_h at quadrature points\n        u_h_vals = np.dot(phi, U_e)\n        \n        # u_exact at quadrature points\n        x_q = (e + 0.5) * h + 0.5 * h * xi_q\n        u_exact_vals = np.sin(2 * np.pi * x_q)\n        \n        # Error on element\n        error_sq_e = np.sum((u_exact_vals - u_h_vals)**2 * w_q) * (h / 2.0)\n        total_error_sq += error_sq_e\n        \n    error = np.sqrt(total_error_sq)\n    \n    return ndof, error\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (64, 1),  # Case A\n        (4, 8),   # Case B\n        (1, 1),   # Case C\n        (16, 2),  # Case D\n        (1, 12),  # Case E\n    ]\n\n    results = []\n    for N, p in test_cases:\n        ndof, error = solve_fem(N, p)\n        results.append((ndof, error))\n\n    # Format the output string exactly as requested\n    formatted_results = []\n    for ndof, error in results:\n        # Format error to 10 significant digits\n        formatted_error = f\"{error:.10g}\"\n        formatted_results.append(f\"[{ndof},{formatted_error}]\")\n    \n    print(f\"[[{','.join(formatted_results)}]]\")\n\nsolve()\n```"
        }
    ]
}