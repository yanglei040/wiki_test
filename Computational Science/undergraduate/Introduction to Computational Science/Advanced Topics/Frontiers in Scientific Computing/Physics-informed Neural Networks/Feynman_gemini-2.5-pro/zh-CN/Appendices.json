{
    "hands_on_practices": [
        {
            "introduction": "物理信息神经网络（PINN）的核心在于其独特的损失函数，它将物理定律和边界条件编码为一个统一的优化目标。这个练习将引导你为经典的静电学问题——泊松方程，构建这个基础的损失函数。通过将偏微分方程（PDE）的残差和边界条件的残差结合起来，你将亲手构建 PINN 的基石，这是掌握 PINN 公式化方法的第一步。",
            "id": "2126324",
            "problem": "一位研究人员正在构建一个物理信息神经网络 (PINN)，以寻找二维方形区域内静电势 $V(x,y)$ 的近似解。电势的物理行为由泊松方程描述：\n$$\n\\nabla^2 V(x,y) = -f(x,y)\n$$\n其中 $f(x,y)$ 表示给定的电荷分布密度，$\\nabla^2 = \\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2}$ 是拉普拉斯算子。电势定义在域 $D = \\{(x,y) \\mid -L \\le x \\le L, -L \\le y \\le L\\}$ 上。该域的边界 $\\partial D$ 保持零电势（接地），这施加了边界条件 $V(x,y) = 0$ 对所有 $(x,y) \\in \\partial D$ 成立。\n\nPINN 模型，记为 $\\hat{V}(x,y; \\theta)$，通过最小化一个包含问题物理信息的损失函数 $L(\\theta)$ 来学习近似 $V(x,y)$。此处，$\\theta$ 代表神经网络的所有可训练参数。损失函数使用两组离散点计算：\n1.  一组 $N_{pde}$ 个配置点，$S_{pde} = \\{(x_i, y_i) \\mid i=1, \\dots, N_{pde}\\}$，位于域 $D$ 的内部。\n2.  一组 $N_{bc}$ 个边界点，$S_{bc} = \\{(x_j, y_j) \\mid j=1, \\dots, N_{bc}\\}$，位于边界 $\\partial D$ 上。\n\n总损失函数 $L(\\theta)$ 是两个均方误差项之和：一个用于控制偏微分方程 ($L_{pde}$)，另一个用于边界条件 ($L_{bc}$)。\n\n构建总损失函数 $L(\\theta) = L_{pde} + L_{bc}$ 的数学表达式。您的表达式应使用网络输出 $\\hat{V}$、其二阶偏导数、函数 $f$、给定的点集及其各自的大小 $N_{pde}$ 和 $N_{bc}$ 来表示。",
            "solution": "我们从控制泊松方程和边界条件开始：\n$$\n\\nabla^{2}V(x,y)=-f(x,y), \\quad V(x,y)=0 \\text{ for } (x,y)\\in \\partial D.\n$$\n物理信息神经网络通过 $\\hat{V}(x,y;\\theta)$ 来近似 $V$。在内部配置点 $(x_{i},y_{i})\\in S_{pde}$ 处的偏微分方程残差通过将泊松方程施加于 $\\hat{V}$ 来定义：\n$$\nr_{i}(\\theta)=\\nabla^{2}\\hat{V}(x_{i},y_{i};\\theta)+f(x_{i},y_{i}).\n$$\n使用二维拉普拉斯算子的定义，这等价于\n$$\nr_{i}(\\theta)=\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i}).\n$$\n那么，在 $S_{pde}$ 上强制执行偏微分方程的均方误差为\n$$\nL_{pde}(\\theta)=\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(r_{i}(\\theta)\\right)^{2}=\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i})\\right)^{2}.\n$$\n边界条件 $V=0$ 在 $\\partial D$ 上通过惩罚 $\\hat{V}$ 在边界点 $(x_{j},y_{j})\\in S_{bc}$ 处与零的偏差来强制执行：\n$$\nL_{bc}(\\theta)=\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)-0\\right)^{2}=\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)\\right)^{2}.\n$$\n因此，总损失是这两个均方误差项之和：\n$$\nL(\\theta)=L_{pde}(\\theta)+L_{bc}(\\theta)=\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i})\\right)^{2}+\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)\\right)^{2}.\n$$",
            "answer": "$$\\boxed{\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i})\\right)^{2}+\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)\\right)^{2}}$$"
        },
        {
            "introduction": "许多现实世界的物理系统是随时间演化的，例如热量在物体中的传导。这个练习将我们的讨论从静态问题扩展到动态问题，以一维热方程为例。你将学习如何扩展损失函数，以包含初始条件和随时间变化的边界条件，这是使用 PINN 解决更广泛物理现象的关键一步。",
            "id": "2126340",
            "problem": "一位工程师正在为一根长度为 $L$ 的新型一维复合杆开发一个热传递模拟。杆上的温度分布 $u(x, t)$ 由一维热传导方程控制：\n$$\n\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}\n$$\n对于 $x \\in [0, L]$ 和 $t \\in [0, T]$，其中 $\\alpha$ 是材料的热扩散系数。\n\n在 $t=0$ 时的初始温度分布由 $u(x, 0) = \\sin\\left(\\frac{\\pi x}{L}\\right)$ 给出。\n边界条件如下：\n1. 在 $x=0$ 的一端保持恒定的零温度：$u(0, t) = 0$。\n2. 在 $x=L$ 的一端受到周期性热源的影响，导致一个随时间变化的温度：$u(L, t) = A \\cos(\\omega t)$，其中 $A$ 是振幅，$\\omega$ 是角频率。\n\n该工程师决定使用物理信息神经网络 (PINN) 来近似解 $u(x, t)$。PINN 由一个带有可训练参数 $\\theta$ 的神经网络 $\\hat{u}(x, t; \\theta)$ 表示。为了训练该网络，需要最小化一个总损失函数 $\\mathcal{L}_{\\text{total}}$。该损失函数是通过对采样点施加控制偏微分方程、初始条件和边界条件来构建的。\n\n采样点定义如下：\n- 从区域内部 $(0, L) \\times (0, T]$ 随机采样的一组 $N_p$ 个配置点 $\\{ (x_i^{(p)}, t_i^{(p)}) \\}_{i=1}^{N_p}$。\n- 在 $t=0$ 时从空间域 $[0, L]$ 随机采样的一组 $N_{ic}$ 个初始点 $\\{ x_j^{(ic)} \\}_{j=1}^{N_{ic}}$。\n- 对于每个边界，从时间域 $[0, T]$ 随机采样的一组 $N_{bc}$ 个边界时间点 $\\{ t_k^{(bc)} \\}_{k=1}^{N_{bc}}$。\n\n假设总损失是 PDE 残差、初始条件和边界条件的均方误差之和（权重相等），那么下列哪个表达式正确地表示了总损失函数 $\\mathcal{L}_{\\text{total}}$？\n\n为简洁起见，我们基于网络的输出 $\\hat{u} = \\hat{u}(x, t; \\theta)$ 定义以下各项：\n- $\\mathcal{L}_{\\text{PDE}} = \\frac{1}{N_p} \\sum_{i=1}^{N_p} \\left| \\frac{\\partial \\hat{u}}{\\partial t}(x_i^{(p)}, t_i^{(p)}) - \\alpha \\frac{\\partial^2 \\hat{u}}{\\partial x^2}(x_i^{(p)}, t_i^{(p)}) \\right|^2$\n- $\\mathcal{L}_{\\text{IC}} = \\frac{1}{N_{ic}} \\sum_{j=1}^{N_{ic}} \\left| \\hat{u}(x_j^{(ic)}, 0) - \\sin\\left(\\frac{\\pi x_j^{(ic)}}{L}\\right) \\right|^2$\n- $\\mathcal{L}_{\\text{BC,0}} = \\frac{1}{N_{bc}} \\sum_{k=1}^{N_{bc}} \\left| \\hat{u}(0, t_k^{(bc)}) \\right|^2$\n- $\\mathcal{L}_{\\text{BC,L}} = \\frac{1}{N_{bc}} \\sum_{k=1}^{N_{bc}} \\left| \\hat{u}(L, t_k^{(bc)}) - A \\cos(\\omega t_k^{(bc)}) \\right|^2$\n\nA. $\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{PDE}} + \\mathcal{L}_{\\text{IC}} + \\mathcal{L}_{\\text{BC,0}} + \\frac{1}{N_{bc}} \\sum_{k=1}^{N_{bc}} \\left| \\hat{u}(L, t_k^{(bc)}) - A \\right|^2$\n\nB. $\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{PDE}} + \\mathcal{L}_{\\text{BC,0}} + \\mathcal{L}_{\\text{BC,L}}$\n\nC. $\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{PDE}} + \\mathcal{L}_{\\text{IC}} + \\mathcal{L}_{\\text{BC,0}} + \\mathcal{L}_{\\text{BC,L}}$\n\nD. $\\mathcal{L}_{\\text{total}} = \\frac{1}{N_{ic}} \\sum_{j=1}^{N_{ic}} \\left| \\frac{\\partial \\hat{u}}{\\partial t}(x_j^{(ic)}, 0) - \\alpha \\frac{\\partial^2 \\hat{u}}{\\partial x^2}(x_j^{(ic)}, 0) \\right|^2 + \\mathcal{L}_{\\text{IC}} + \\mathcal{L}_{\\text{BC,0}} + \\mathcal{L}_{\\text{BC,L}}$\n\nE. $\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{PDE}} + \\frac{1}{N_{ic}} \\sum_{j=1}^{N_{ic}} \\left| \\hat{u}(x_j^{(ic)}, T) - \\sin\\left(\\frac{\\pi x_j^{(ic)}}{L}\\right) \\right|^2 + \\mathcal{L}_{\\text{BC,0}} + \\mathcal{L}_{\\text{BC,L}}$",
            "solution": "我们需要一个物理信息神经网络的损失函数，它以相等的权重，在时空内部施加控制偏微分方程，在 $x \\in [0,L]$ 上施加 $t=0$ 时的初始条件，以及在 $t \\in [0,T]$ 上施加 $x=0$ 和 $x=L$ 处的两个边界条件。PINN 的标准均方误差构造是以下这些分量的和：\n- 在内部 $(0,L) \\times (0,T]$ 的配置点 $(x_{i}^{(p)}, t_{i}^{(p)})$ 处施加的 PDE 残差，得到所定义的 $\\mathcal{L}_{\\text{PDE}}$。\n- 在 $t=0$ 时对采样的空间点 $x_{j}^{(ic)} \\in [0,L]$ 施加的初始条件，得到所定义的 $\\mathcal{L}_{\\text{IC}}$。\n- 在 $x=0$ 处对采样的时间点 $t_{k}^{(bc)} \\in [0,T]$ 施加的边界条件，得到所定义的 $\\mathcal{L}_{\\text{BC,0}}$。\n- 在 $x=L$ 处对采样的时间点 $t_{k}^{(bc)} \\in [0,T]$ 施加的边界条件，得到所定义的 $\\mathcal{L}_{\\text{BC,L}}$。\n\n在权重相等的情况下，正确的总损失是它们的和：\n$$\n\\mathcal{L}_{\\text{total}}=\\mathcal{L}_{\\text{PDE}}+\\mathcal{L}_{\\text{IC}}+\\mathcal{L}_{\\text{BC,0}}+\\mathcal{L}_{\\text{BC,L}}.\n$$\n现在来评估各个选项：\n- 选项 A 将 $x=L$ 处的边界目标用 $A$ 替换了 $A\\cos(\\omega t)$，这与给定的随时间变化的边界条件不符，因此是不正确的。\n- 选项 B 完全省略了初始条件项，这违反了施加初始条件的要求，因此是不正确的。\n- 选项 C 正是四个正确定义的、权重相等的分量之和，因此是正确的。\n- 选项 D 在 $t=0$ 的初始条件样本集上计算 PDE 残差，而不是在内部配置点上；这与所述的 PDE 残差点采样方式相矛盾，并且未能在内部充分施加 PDE，因此是不正确的。\n- 选项 E 施加了一个在最终时间 $t=T$ 时等于初始分布的条件，这在问题中没有规定，并且对于热传导方程，除非经过特殊构造，否则通常是不成立的；因此是不正确的。\n\n因此，正确的表达式是四个给定分量的简单相加，这对应于选项 C。",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "在前面的练习中，我们通过在损失函数中添加惩罚项（即“软约束”）来施加边界条件。这种方法虽然普遍，但并不保证网络输出能完美满足边界条件。本练习介绍了一种更为巧妙且稳健的技术，即通过修改网络输出的结构来“硬编码”边界条件，从而确保它们在任何时候都能被精确满足。",
            "id": "2126300",
            "problem": "在科学计算领域，物理信息神经网络（PINNs）已成为求解微分方程的强大工具。设计PINN的一个关键方面是确保其输出（即方程的近似解）满足给定的边界条件。一种实现这一目标的稳健方法是，通过构造来设计网络的最终输出函数，使其天然满足这些条件。\n\n考虑一个定义在空间域 $x \\in [0, L]$ 上的一维问题。一个神经网络提供了一个原始的、无约束的输出函数，记为 $\\hat{u}_{NN}(x)$。我们希望使用这个网络来寻找一个微分方程的近似解 $u(x)$，该解满足以下非齐次狄利克雷边界条件：\n$$u(0) = A$$\n$$u(L) = B$$\n其中，$A$、$B$ 和 $L > 0$ 是给定的实常数。\n\n你的任务是设计一个变换，它接收网络的原始输出 $\\hat{u}_{NN}(x)$ 并生成一个新函数 $u_{NN}(x)$，该函数将作为最终的近似解。这个变换必须保证，无论网络生成的函数 $\\hat{u}_{NN}(x)$ 是什么，$u_{NN}(x)$ 都能严格满足指定的边界条件。\n\n请给出 $u_{NN}(x)$ 的表达式，用原始网络输出 $\\hat{u}_{NN}(x)$ 以及参数 $x$、$L$、$A$ 和 $B$ 来表示。",
            "solution": "我们寻求一个变换，将原始网络输出 $\\hat{u}_{NN}(x)$ 映射到一个函数 $u_{NN}(x)$，使得对于任何 $\\hat{u}_{NN}(x)$，函数 $u_{NN}(x)$ 都能强制满足狄利克雷边界条件 $u_{NN}(0)=A$ 和 $u_{NN}(L)=B$。一种标准的构造方法是将 $u_{NN}(x)$ 分解为\n$$\nu_{NN}(x)=g(x)+s(x)\\,\\hat{u}_{NN}(x),\n$$\n其中 $g(x)$ 是任何满足边界条件的固定函数，而 $s(x)$ 是任何在两个边界处都为零的函数。具体来说，我们要求\n$$\ng(0)=A,\\quad g(L)=B,\\quad s(0)=0,\\quad s(L)=0.\n$$\n对于 $g(x)$，一个方便的选择是线性插值函数，\n$$\ng(x)=A\\left(1-\\frac{x}{L}\\right)+B\\left(\\frac{x}{L}\\right)=A+\\frac{B-A}{L}\\,x,\n$$\n对于 $s(x)$，一个简单的零化因子是\n$$\ns(x)=x(L-x),\n$$\n它满足 $s(0)=0$ 和 $s(L)=0$。因此，定义\n$$\nu_{NN}(x)=A\\left(1-\\frac{x}{L}\\right)+B\\left(\\frac{x}{L}\\right)+x(L-x)\\,\\hat{u}_{NN}(x).\n$$\n为了验证边界条件，在 $x=0$ 和 $x=L$ 处求值：\n$$\nu_{NN}(0)=A\\left(1-0\\right)+B\\left(0\\right)+0\\cdot L\\,\\hat{u}_{NN}(0)=A,\n$$\n$$\nu_{NN}(L)=A\\left(1-1\\right)+B\\left(\\frac{L}{L}\\right)+L( L-L)\\,\\hat{u}_{NN}(L)=B.\n$$\n因此，对于任意的 $\\hat{u}_{NN}(x)$，所构造的 $u_{NN}(x)$ 都严格满足 $u_{NN}(0)=A$ 和 $u_{NN}(L)=B$。",
            "answer": "$$\\boxed{A\\left(1-\\frac{x}{L}\\right)+B\\left(\\frac{x}{L}\\right)+x\\left(L-x\\right)\\hat{u}_{NN}(x)}$$"
        }
    ]
}