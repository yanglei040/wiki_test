{
    "hands_on_practices": [
        {
            "introduction": "理解一个算法的最好方法之一是探究其特殊的边界行为。本练习将引导你复现双共轭梯度稳定(BiCGSTAB)方法中一个有趣的现象——“幸运分解” (lucky breakdown)，即算法在某个迭代步中意外地提前找到了精确解。通过构造特定的矩阵和向量来触发这一事件，你将深入理解残差、搜索方向和系统矩阵之间的代数关系，从而对 BiCGSTAB 的内部工作机制有更清晰的认识。",
            "id": "3102131",
            "problem": "要求您实现一个完整、可运行的程序，该程序构建一个小型测试工具，以演示迭代克雷洛夫子空间方法中的一个特定现象，即双共轭梯度稳定方法 (BiCGSTAB) 中的“幸运分解”。请在由双精度浮点数模拟的精确算术中进行计算，并将向量和矩阵视为实数数组。\n\n您的程序必须执行以下操作。\n\n1. 用作基本基础的核心定义：\n   - 给定线性系统 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$，$x \\in \\mathbb{R}^{n}$，$b \\in \\mathbb{R}^{n}$。\n   - 给定初始猜测值 $x_0 \\in \\mathbb{R}^{n}$，定义初始残差 $r_0 = b - A x_0$。\n   - 使用标准的欧几里得内积 $(u, v) = \\sum_{i=1}^{n} u_i v_i$ 和诱导2-范数 $\\lVert u \\rVert_2 = \\sqrt{(u,u)}$。\n   - 实现双共轭梯度稳定方法 (BiCGSTAB)，同时使用 $r_0$ 作为固定的影子残差。使用基于残差范数低于某个容差的标准停止准则。\n\n2. 要检测的幸运分解事件：\n   - 在每次 BiCGSTAB 迭代中，计算标量步长 $\\alpha_k$ 和中间向量 $s_k = r_{k-1} - \\alpha_k A p_{k-1}$ 之后，如果在计算下一个稳定化步骤之前 $s_k = 0$（在浮点运算中，将 $\\lVert s_k \\rVert_2 \\le \\varepsilon$ 视作零），则称发生了“幸运分解”。在这种情况下，精确解已在该迭代中通过 $x_k = x_{k-1} + \\alpha_k p_{k-1}$ 提前找到。\n   - 您的程序必须仅在此意义上声明幸运分解。不要将 $r_0 = 0$ 的平凡情况计为幸运；也不要将仅在完成 $\\omega_k$ 稳定化步骤后才发生的收敛计为幸运。\n\n3. 数值容差：\n   - 使用 $\\varepsilon = 10^{-12}$ 的收敛和零检测容差来检查 $\\lVert s_k \\rVert_2$ 和 $\\lVert r_k \\rVert_2$。\n   - 对每个测试用例使用 $k_{\\max} = 1000$ 的最大迭代次数上限，以避免在病态输入下出现无限循环。\n\n4. 测试套件的设计与构建：\n   - 通过显式指定 $A$、$b$ 和 $x_0$ 来构建四个测试用例，以使测试工具涵盖以下行为。所有条目和大小都必须明确说明，并且所有矩阵都必须是非奇异的。\n     - 情况 L1 (对称幸运分解)：令 $A \\in \\mathbb{R}^{3 \\times 3}$ 为对角矩阵，其条目为 $A = \\mathrm{diag}(2, 3, 4)$，令 $x_0 = (0, 0, 0)^{\\top}$，并令 $b = (1, 0, 0)^{\\top}$。此配置的构建应使得 $r_0$ 是 $A$ 的一个特征向量，这在代数上使得能够通过 $s_0 = 0$ 提前得到精确解。\n     - 情况 L2 (非对称幸运分解)：令 $A \\in \\mathbb{R}^{2 \\times 2}$ 为上三角类若尔当块 $A = \\begin{bmatrix} 5  1 \\\\ 0  5 \\end{bmatrix}$，令 $x_0 = (0, 0)^{\\top}$，并令 $b = (1, 0)^{\\top}$。此配置同样应确保 $r_0$ 是 $A$ 的一个特征向量，因此即使 $A$ 不是对称的，同样的代数机制也可以触发 $s_0 = 0$。\n     - 情况 B1 (边界，非幸运)：令 $A \\in \\mathbb{R}^{2 \\times 2}$ 为对角矩阵 $A = \\mathrm{diag}(7, 8)$，选择 $x_{\\star} = (1, 2)^{\\top}$，设置 $b = A x_{\\star}$，并将初始猜测值设为精确解 $x_0 = x_{\\star}$。这会得到 $r_0 = 0$。这种情况不得计为幸运，因为不需要进行任何迭代。\n     - 情况 G1 (一般，非幸运)：令 $A \\in \\mathbb{R}^{2 \\times 2}$ 为对角矩阵 $A = \\mathrm{diag}(2, 3)$，令 $x_0 = (0, 0)^{\\top}$，并令 $b = (1, 1)^{\\top}$。此设置应产生一个正常的迭代序列，其中 $s_0 \\ne 0$，并且如果达到收敛，也是在稳定化步骤或后续迭代之后发生。\n\n5. 输出规范：\n   - 对于每个测试用例，如果某次迭代的 $\\alpha$ 步骤中发生了幸运分解（如上定义），您的程序必须输出整数 $1$，否则输出整数 $0$（包括 $r_0 = 0$ 的平凡情况和在 $\\omega$ 步骤之后的任何收敛）。\n   - 将四个结果汇总到一行中，以方括号括起来的逗号分隔列表形式打印，不含空格，顺序为 $[\\text{L1},\\text{L2},\\text{B1},\\text{G1}]$。例如，一个有效的输出可能看起来像 $[1,1,0,0]$。\n\n6. 角度单位、物理单位和百分比：\n   - 此任务不涉及任何物理量、角度或百分比。\n\n您的程序必须完全自包含，无需用户输入，并且必须遵守上述确切的输出格式。",
            "solution": "该问题要求实现双共轭梯度稳定 (BiCGSTAB) 迭代方法来求解线性系统 $A x = b$，并构建一个测试套件来演示一种被称为“幸运分解”的特定现象。\n\n线性系统由 $A x = b$ 给出，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是一个非奇异矩阵，而 $x, b \\in \\mathbb{R}^{n}$ 是向量。给定一个初始猜测值 $x_0$，初始残差为 $r_0 = b - A x_0$。BiCGSTAB 方法通过迭代地优化解的猜测值 $x_k$ 来最小化残差 $r_k = b - A x_k$。\n\nBiCGSTAB 算法，使用一个固定的影子残差 $\\hat{r}_0$（根据问题要求设为 $r_0$），可以表述如下：\n\n1.  初始化：\n    $x_0$ 是初始猜测值。\n    $r_0 = b - A x_0$。\n    如果 $\\lVert r_0 \\rVert_2$ 接近于零，则初始猜测值已经是解。\n    设置固定的影子残差 $\\hat{r}_0 = r_0$。\n    设置初始搜索方向 $p_0 = r_0$。\n    计算初始残差投影的范数平方 $\\rho_0 = (\\hat{r}_0, r_0)$。\n\n2.  对 $k = 1, 2, \\dots$ 进行迭代，直到收敛或达到最大迭代次数：\n    a. 计算矩阵向量乘积与搜索方向：$v_{k-1} = A p_{k-1}$。\n    b. 计算步长 $\\alpha_k$：\n       $$ \\alpha_k = \\frac{\\rho_{k-1}}{(\\hat{r}_0, v_{k-1})} = \\frac{(\\hat{r}_0, r_{k-1})}{(\\hat{r}_0, A p_{k-1})} $$\n    c. 沿搜索方向 $p_{k-1}$ 更新解，并计算一个中间残差 $s_k$：\n       $$ s_k = r_{k-1} - \\alpha_k v_{k-1} = r_{k-1} - \\alpha_k A p_{k-1} $$\n    d. **幸运分解检查**：如果 $\\lVert s_k \\rVert_2 \\le \\varepsilon$（其中 $\\varepsilon=10^{-12}$ 是一个很小的容差），则发生“幸运分解”。精确解被提前找到。最终解为 $x_k = x_{k-1} + \\alpha_k p_{k-1}$。我们报告此事件并终止。\n    e. 如果没有发生幸运分解，则继续进行稳定化步骤。计算矩阵向量乘积 $t_k = A s_k$。\n    f. 计算稳定化参数 $\\omega_k$：\n       $$ \\omega_k = \\frac{(t_k, s_k)}{(t_k, t_k)} $$\n    g. 对本次迭代的解和最终残差进行完整更新：\n       $$ x_k = x_{k-1} + \\alpha_k p_{k-1} + \\omega_k s_k $$\n       $$ r_k = s_k - \\omega_k t_k $$\n    h. 检查正常收敛：如果 $\\lVert r_k \\rVert_2 \\le \\varepsilon$，则终止。\n    i. 为下一次迭代做准备。更新投影范数和搜索方向：\n       $$ \\rho_k = (\\hat{r}_0, r_k) $$\n       $$ \\beta_k = \\frac{\\rho_k}{\\rho_{k-1}} \\frac{\\alpha_k}{\\omega_k} $$\n       $$ p_k = r_k + \\beta_k (p_{k-1} - \\omega_k v_{k-1}) $$\n\n问题的核心是检测幸运分解。当 $s_k=0$ 时会发生这种情况。让我们分析第一次迭代（$k=1$）时的这个条件。初始搜索方向是 $p_0 = r_0$。条件 $s_1 = 0$ 意味着：\n$$ s_1 = r_0 - \\alpha_1 A p_0 = r_0 - \\alpha_1 A r_0 = 0 $$\n$$ \\implies A r_0 = \\frac{1}{\\alpha_1} r_0 $$\n这个方程表明，当且仅当初始残差 $r_0$ 是矩阵 $A$ 的一个特征向量时，第一次迭代才会发生幸运分解。相应的步长 $\\alpha_1$ 将是特征值的倒数。测试用例的设计就是为了利用这一性质。\n\n- **情况 L1 (对称幸运分解)**：$A = \\mathrm{diag}(2, 3, 4)$，$x_0 = (0, 0, 0)^{\\top}$，$b = (1, 0, 0)^{\\top}$。\n  初始残差为 $r_0 = b - A x_0 = (1, 0, 0)^{\\top}$。这是对角矩阵 $A$ 的一个特征向量，其特征值为 $\\lambda=2$。因此，预计会发生幸运分解，算法应报告 $1$。\n\n- **情况 L2 (非对称幸运分解)**：$A = \\begin{bmatrix} 5  1 \\\\ 0  5 \\end{bmatrix}$，$x_0 = (0, 0)^{\\top}$，$b = (1, 0)^{\\top}$。\n  初始残差为 $r_0 = b - A x_0 = (1, 0)^{\\top}$。我们检查它是否是特征向量：$A r_0 = \\begin{pmatrix} 5 \\\\ 0 \\end{pmatrix} = 5 \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 5 r_0$。它是一个特征向量，特征值为 $\\lambda=5$。因此，这里也预计会发生幸运分解，结果是 $1$。\n\n- **情况 B1 (边界，非幸运)**：$A = \\mathrm{diag}(7, 8)$，$x_0 = x_{\\star} = (1, 2)^{\\top}$，$b = A x_{\\star}$。\n  初始残差为 $r_0 = b - A x_0 = A x_{\\star} - A x_{\\star} = 0$。在任何迭代开始之前，条件 $\\lVert r_0 \\rVert_2 \\le \\varepsilon$ 就已满足。根据问题陈述，这种平凡情况不被视为幸运分解。程序应报告 $0$。\n\n- **情况 G1 (一般，非幸运)**：$A = \\mathrm{diag}(2, 3)$，$x_0 = (0, 0)^{\\top}$，$b = (1, 1)^{\\top}$。\n  初始残差为 $r_0 = b - A x_0 = (1, 1)^{\\top}$。我们检查它是否是特征向量：$A r_0 = \\mathrm{diag}(2, 3) (1, 1)^{\\top} = (2, 3)^{\\top}$。由于 $(2, 3)^{\\top}$ 不是 $(1, 1)^{\\top}$ 的标量倍数，因此 $r_0$ 不是 $A$ 的特征向量。所以，$s_1 \\ne 0$，第一次迭代不会发生幸运分解。算法将正常进行。预期输出为 $0$。\n\n提供的程序实现了这一逻辑，正确地实例化了每个测试用例，运行了 BiCGSTAB 算法，并根据幸运分解的精确定义报告 $1$ 或 $0$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef bicgstab(A, b, x0, tol, max_iter):\n    \"\"\"\n    Implements the Biconjugate Gradient Stabilized (BiCGSTAB) method and detects \"lucky breakdowns\".\n\n    A \"lucky breakdown\" is detected if the intermediate residual 's' becomes zero\n    before the stabilization step.\n\n    Args:\n        A (np.ndarray): The matrix of the linear system.\n        b (np.ndarray): The right-hand side vector of the linear system.\n        x0 (np.ndarray): The initial guess for the solution.\n        tol (float): The tolerance for convergence and zero-detection.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        int: Returns 1 if a lucky breakdown occurred, 0 otherwise.\n    \"\"\"\n    x = np.copy(x0)\n    r = b - A @ x\n\n    # Per problem: do not count trivial convergence as a lucky breakdown.\n    if np.linalg.norm(r) = tol:\n        return 0\n\n    # Fixed shadow residual as per problem specification.\n    r_hat = np.copy(r)\n\n    rho = r_hat @ r\n    # Handle potential breakdown if rho is zero initially.\n    if abs(rho)  1e-50:\n        return 0 # Breakdown, not lucky.\n        \n    p = np.copy(r)\n    \n    is_lucky = 0\n\n    for _ in range(max_iter):\n        v = A @ p\n        \n        denom = r_hat @ v\n        # Handle potential breakdown.\n        if abs(denom)  1e-50:\n            return 0 # Breakdown, not lucky.\n\n        alpha = rho / denom\n        \n        s = r - alpha * v\n\n        # The specific \"lucky breakdown\" check as defined in the problem.\n        if np.linalg.norm(s) = tol:\n            x = x + alpha * p\n            is_lucky = 1\n            break\n\n        t = A @ s\n        \n        denom = t @ t\n        # If s is not zero, but As is, it's a breakdown. A must be singular, but problem guarantees nonsingular A.\n        # This check is for numerical stability with floating point arithmetic.\n        if abs(denom)  1e-50:\n            return 0 # Breakdown, not lucky.\n        \n        omega = (t @ s) / denom\n        \n        # Full update for x and r.\n        x = x + alpha * p + omega * s\n        r_new = s - omega * t\n\n        # Normal convergence check after the full stabilization step.\n        if np.linalg.norm(r_new) = tol:\n            break\n\n        rho_new = r_hat @ r_new\n\n        # Handle potential breakdown from rho or omega being zero.\n        if abs(rho)  1e-50 or abs(omega)  1e-50:\n            return 0 # Breakdown, not lucky.\n\n        beta = (rho_new / rho) * (alpha / omega)\n\n        # Update search direction p.\n        p = r_new + beta * (p - omega * v)\n\n        # Update r and rho for the next iteration.\n        r = r_new\n        rho = rho_new\n\n    return is_lucky\n\ndef solve():\n    # Define the parameters and test cases from the problem statement.\n    tol = 1e-12\n    max_iter = 1000\n\n    # Case L1 (symmetric lucky breakdown)\n    A1 = np.diag([2.0, 3.0, 4.0])\n    x0_1 = np.zeros(3)\n    b1 = np.array([1.0, 0.0, 0.0])\n\n    # Case L2 (nonsymmetric lucky breakdown)\n    A2 = np.array([[5.0, 1.0], [0.0, 5.0]])\n    x0_2 = np.zeros(2)\n    b2 = np.array([1.0, 0.0])\n\n    # Case B1 (boundary, no-lucky)\n    A3 = np.diag([7.0, 8.0])\n    x_star3 = np.array([1.0, 2.0])\n    b3 = A3 @ x_star3\n    x0_3 = np.copy(x_star3)\n\n    # Case G1 (general, no-lucky)\n    A4 = np.diag([2.0, 3.0])\n    x0_4 = np.zeros(2)\n    b4 = np.array([1.0, 1.0])\n\n    test_cases = [\n        (A1, b1, x0_1),  # L1\n        (A2, b2, x0_2),  # L2\n        (A3, b3, x0_3),  # B1\n        (A4, b4, x0_4),  # G1\n    ]\n\n    results = []\n    for A, b, x0 in test_cases:\n        is_lucky = bicgstab(A, b, x0, tol, max_iter)\n        results.append(is_lucky)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "掌握了算法的基本机制后，下一步是系统地评估其性能。本练习将理论与实践相结合，让你探索一个关键的数学概念——矩阵条件数——如何直接影响 BiCGSTAB 的收敛速度。你将通过奇异值分解 (SVD) 来生成具有精确控制条件数的非对称矩阵，并进行统计实验，从而亲手验证为什么良态问题 (well-conditioned problems) 比病态问题 (ill-conditioned problems) 更容易求解。",
            "id": "3102168",
            "problem": "要求您编写一个完整的程序，从基本原理出发实现双共轭梯度稳定方法 (BiCGSTAB)，并用它来研究在一系列具有受控条件数的稠密、随机、非对称线性系统上的统计收敛行为。此任务基于以下核心定义：线性系统 $A x = b$，通过在 Krylov 子空间上最小化残差 $r_k = b - A x_k$ 来对近似解 $x_k$ 进行迭代求精，以及基于奇异值的条件数概念。不得调用任何预先存在的求解器；您必须根据 Krylov 子空间方法和残差最小化的定义自行实现核心迭代，而不能依赖任何用于 BiCGSTAB 的专门库例程。\n\n给定一个方阵 $A \\in \\mathbb{R}^{n \\times n}$ 和一个右端向量 $b \\in \\mathbb{R}^n$，BiCGSTAB 通过仅使用与 $A$ 的矩阵-向量乘积和内积来迭代更新 $x_k$，从初始猜测 $x_0 = 0$ 开始，寻找一个满足 $A x = b$ 的 $x \\in \\mathbb{R}^n$。该方法使用一个固定的辅助向量 $\\hat{r}$ 并构造一个双正交序列，以稳定短递归的双共轭梯度 (Biconjugate Gradient) 步骤。收敛性通过将相对残差范数 $\\|r_k\\|_2 / \\|b\\|_2$ 与容差 $\\varepsilon$ 进行比较来评估。\n\n您必须使用奇异值分解 (SVD) 作为构造工具，生成具有指定条件数的随机稠密非对称测试矩阵 $A$：抽取一个标准正态矩阵 $G \\in \\mathbb{R}^{n \\times n}$，计算其奇异值分解 $G = U \\Sigma V^{\\top}$，其中 $U, V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，然后用一个对角矩阵替换 $\\Sigma$，该对角矩阵的对角线上包含指定的奇异值序列 $\\{ \\sigma_i \\}_{i=1}^n$，这些奇异值在 $\\sigma_{\\max} = 1$ 和 $\\sigma_{\\min} = 1/\\kappa$ 之间呈等比分布，其中 $\\kappa \\ge 1$ 是期望的条件数。定义 $A := U \\operatorname{diag}(\\sigma_1,\\dots,\\sigma_n) V^{\\top}$。当 $U \\ne V$ 时，这个 $A$ 通常是非对称的。对于每次实现，通过抽取独立的标准正态分布元素生成 $b$，并将其缩放至单位二范数，即强制 $\\|b\\|_2 = 1$。\n\n您的程序必须：\n- 实现双共轭梯度稳定方法 (BiCGSTAB) 来求解 $A x = b$，使用初始猜测 $x_0 = 0$，无预处理器，停止准则基于相对残差范数 $\\|r_k\\|_2 / \\|b\\|_2 \\le \\varepsilon$ 或达到最大迭代次数 $k_{\\max}$。如果在迭代中发生除零（例如，由于递归步骤中分母消失），则将其视为一次崩溃 (breakdown)，并将该次运行标记为在 $k_{\\max}$ 次迭代内未能收敛。\n- 对于每个条件数 $\\kappa$ 和多次独立实现，对每次运行记录：如果成功，则记录达到容差所需的迭代次数 $k$；如果不成功，则记录为 $k_{\\max}$；以及一个布尔成功标志，定义为是否在第 $k_{\\max}$ 次迭代之前或之时满足 $\\|r_k\\|_2 / \\|b\\|_2 \\le \\varepsilon$。\n- 对于每个 $\\kappa$，汇总所有实现的以下统计数据：成功运行中的平均迭代次数，成功运行中迭代次数的标准差，以及成功率，定义为在 $k_{\\max}$ 次迭代内满足容差的实现的比例。如果对于给定的 $\\kappa$ 没有成功的运行，则将平均值和标准差分别定义为 $k_{\\max}$ 和 $0$。\n\n使用以下固定的测试套件以确保可复现性和覆盖性：\n- 矩阵维度：$n = 60$。\n- 条件数：$\\kappa \\in \\{ 10^{1}, 10^{5}, 10^{12} \\}$。\n- 每个 $\\kappa$ 的独立实现次数：$8$。\n- 容差：$\\varepsilon = 10^{-8}$。\n- 最大迭代次数：$k_{\\max} = 300$。\n- 随机种子：使用固定种子 $12345$ 初始化一个伪随机数生成器，并从该生成器中抽取所有随机矩阵和向量，以确保可重复性。\n\n您的程序必须输出单行，其中包含一个由 $9$ 个浮点数组成的逗号分隔列表，每个数字四舍五入到恰好 $6$ 位小数，顺序如下：\n- 对于 $\\kappa = 10^{1}$：成功运行的平均迭代次数，成功运行的迭代次数标准差，成功率（表示为 $[0,1]$ 范围内的小数）。\n- 对于 $\\kappa = 10^{5}$：成功运行的平均迭代次数，成功运行的迭代次数标准差，成功率（表示为 $[0,1]$ 范围内的小数）。\n- 对于 $\\kappa = 10^{12}$：成功运行的平均迭代次数，成功运行的迭代次数标准差，成功率（表示为 $[0,1]$ 范围内的小数）。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，例如，示意形式为 [$r_1$,$r_2$,$r_3$,$r_4$,$r_5$,$r_6$,$r_7$,$r_8$,$r_9$]，其中每个 $r_i$ 是一个格式化为小数点后恰好有 $6$ 位的实数。不应打印任何其他文本。",
            "solution": "该问题是有效的，因为它提出了一个计算科学中定义明确的任务，该任务具有科学依据、自包含且客观。它要求实现双共轭梯度稳定 (BiCGSTAB) 方法，并将其应用于一组通过程序生成的、具有受控条件数的线性系统，然后对性能进行统计分析。所有参数、过程和输出格式都已明确规定，使用固定的随机种子确保了可复现性。我将继续提供解决方案。\n\n解决方案分为三个主要部分：\n1.  待实现的 BiCGSTAB 算法的详细描述。\n2.  构建具有指定条件数 $\\kappa$ 的测试矩阵 $A$ 的过程。\n3.  用于收集和处理收敛统计数据的数值实验设计。\n\n### 1. 双共轭梯度稳定 (BiCGSTAB) 算法\n\nBiCGSTAB 是一种用于求解形如 $A x = b$ 的非对称线性系统的迭代方法，其中 $A \\in \\mathbb{R}^{n \\times n}$ 且 $x, b \\in \\mathbb{R}^n$。它是一种 Krylov 子空间方法，旨在平滑双共轭梯度 (BiCG) 方法通常不稳定的收敛过程。实现将遵循标准算法，从初始猜测 $x_0 = 0$ 开始。\n\n该算法流程如下：\n\n**初始化：**\n1.  设置初始猜测 $x_0 = 0$。\n2.  计算初始残差 $r_0 = b - A x_0 = b$。\n3.  选择辅助残差向量 $\\hat{r}_0 = r_0$。\n4.  初始化标量：$\\rho_0 = 1$, $\\alpha_0 = 1$, $\\omega_0 = 1$。\n5.  初始化向量：$p_0 = 0$, $v_0 = 0$。\n6.  设置迭代计数器 $k = 1$。\n7.  预计算右端项的范数 $\\|b\\|_2$。根据问题规定，$b$ 是标准化的，因此 $\\|b\\|_2 = 1$。\n8.  收敛准则是 $\\|r_k\\|_2 \\le \\varepsilon$。\n\n**主迭代循环 (for $k = 1, 2, \\dots, k_{\\max}$):**\n1.  计算 $\\rho_k = \\hat{r}_0^\\top r_{k-1}$。如果 $\\rho_k \\approx 0$，则发生崩溃。\n2.  计算 $\\beta_{k-1} = \\frac{\\rho_k}{\\rho_{k-1}} \\frac{\\alpha_{k-1}}{\\omega_{k-1}}$。如果 $\\rho_{k-1} \\approx 0$ 或 $\\omega_{k-1} \\approx 0$，则发生崩溃。\n3.  更新搜索方向：$p_k = r_{k-1} + \\beta_{k-1} (p_{k-1} - \\omega_{k-1} v_{k-1})$。\n4.  计算矩阵-向量乘积 $v_k = A p_k$。\n5.  计算 $\\alpha_k$ 的分母：$d_\\alpha = \\hat{r}_0^\\top v_k$。如果 $d_\\alpha \\approx 0$，则发生崩溃。\n6.  计算步长 $\\alpha_k = \\rho_k / d_\\alpha$。\n7.  计算一个中间残差 $s_k = r_{k-1} - \\alpha_k v_k$。\n8.  计算矩阵-向量乘积 $t_k = A s_k$。\n9.  计算 $\\omega_k$ 的分母：$d_\\omega = t_k^\\top t_k$。如果 $d_\\omega \\approx 0$，则发生崩溃或停滞。\n10. 计算稳定化步长 $\\omega_k = (t_k^\\top s_k) / d_\\omega$。\n11. 更新解：$x_k = x_{k-1} + \\alpha_k p_k + \\omega_k s_k$。\n12. 更新残差：$r_k = s_k - \\omega_k t_k$。\n13. 检查收敛性：如果 $\\|r_k\\|_2 \\le \\varepsilon$，则方法成功。记录当前迭代次数 $k$。\n14. 下一次迭代的变量是 $x_k, r_k, p_k, v_k$，标量则更新为 $\\rho_k, \\alpha_k, \\omega_k$。\n\n如果循环完成但未收敛，则该次运行被视为失败，迭代次数记录为 $k_{\\max}$。任何除以接近零的值（崩溃）也被视为失败。\n\n### 2. 测试矩阵的构建\n\n为了研究算法性能作为问题条件数的函数，我们需要生成具有特定条件数 $\\kappa = \\sigma_{\\max} / \\sigma_{\\min}$ 的矩阵。奇异值分解 (SVD) 为此提供了一个构造工具。\n\n对于给定的维度 $n$ 和目标条件数 $\\kappa$，其过程如下：\n1.  使用指定的种子 $12345$ 初始化一个伪随机数生成器。\n2.  生成一个随机矩阵 $G \\in \\mathbb{R}^{n \\times n}$，其中每个元素都从标准正态分布 $\\mathcal{N}(0, 1)$ 中抽取。\n3.  计算 $G$ 的 SVD：$G = U \\Sigma' V^{\\top}$，其中 $U, V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma'$ 是包含 $G$ 的奇异值的对角矩阵。\n4.  定义一组新的奇异值 $\\{\\sigma_i\\}_{i=1}^n$，它们在 $\\sigma_{\\max} = 1$ 和 $\\sigma_{\\min} = 1/\\kappa$ 之间呈等比分布。这些值按降序排列，由以下公式给出：\n    $$ \\sigma_i = \\kappa^{-\\frac{i-1}{n-1}} \\quad \\text{for } i = 1, \\dots, n $$\n    这确保了 $\\sigma_1 = 1$ 和 $\\sigma_n = 1/\\kappa$，因此所得矩阵的条件数恰好为 $\\kappa$。\n5.  通过使用期望的奇异值重新组装 SVD 组件来构造新矩阵 $A$：\n    $$ A = U \\operatorname{diag}(\\sigma_1, \\sigma_2, \\dots, \\sigma_n) V^{\\top} $$\n    由于对于一个随机非对称矩阵 $G$，$U$ 和 $V$ 通常是不同的，因此生成的矩阵 $A$ 也将是非对称的。\n\n### 3. 实验设计与统计分析\n\n任务的核心是运行一系列数值实验并汇总结果。固定参数为：矩阵维度 $n=60$，容差 $\\varepsilon = 10^{-8}$，最大迭代次数 $k_{\\max} = 300$，以及每个 $\\kappa$ 的实现次数为 $8$。\n\n总体流程如下：\n1.  使用种子 $12345$ 初始化随机数生成器。\n2.  遍历每个指定的条件数 $\\kappa \\in \\{ 10^{1}, 10^{5}, 10^{12} \\}$。\n3.  对于每个 $\\kappa$，开始一个包含 $8$ 次独立实现的循环。\n4.  在此循环内部：\n    a. 使用上述 SVD 方法构建一个大小为 $60 \\times 60$ 且条件数为 $\\kappa$ 的矩阵 $A$。\n    b. 通过从 $\\mathcal{N}(0, 1)$ 中抽取 $60$ 个元素来生成右端向量 $b$，然后将该向量归一化，使其 L2 范数为单位1，即 $\\|b\\|_2 = 1$。\n    c. 使用实现的 BiCGSTAB 求解器求解系统 $A x = b$，其中 $x_0 = 0$，$\\varepsilon = 10^{-8}$，$k_{\\max} = 300$。\n    d. 记录所用的迭代次数和一个指示是否达到收敛的布尔标志。\n5.  在给定 $\\kappa$ 的 $8$ 次实现完成后：\n    a. 筛选结果，得到仅包含成功运行的迭代次数列表。\n    b. 计算成功率，即 (成功运行次数) / $8$。\n    c. 如果有一次或多次成功运行，计算这些迭代次数的均值和总体标准差。\n    d. 如果没有成功运行，则均值定义为 $k_{\\max}=300$，标准差定义为 $0$。\n6.  为每个 $\\kappa$ 收集三个统计数据（平均迭代次数、标准差、成功率）。\n7.  最后，将这 $9$ 个数字（$3$ 个 $\\kappa$ 值对应的 $3$ 个统计数据）格式化为单个逗号分隔的字符串，每个数字四舍五入到 $6$ 位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef bicgstab(A, b, x0, tol, max_iter):\n    \"\"\"\n    Implements the Biconjugate Gradient Stabilized (BiCGSTAB) method.\n\n    Args:\n        A (np.ndarray): The square matrix of the linear system.\n        b (np.ndarray): The right-hand side vector.\n        x0 (np.ndarray): The initial guess for the solution.\n        tol (float): The convergence tolerance for the relative residual norm.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        tuple: A tuple containing:\n            - k (int): The number of iterations performed.\n            - success (bool): True if converged, False otherwise.\n    \"\"\"\n    n = A.shape[0]\n    x = x0.copy()\n    r = b - A @ x\n    r_hat = r.copy()\n\n    # Per the problem description, ||b||_2 is 1, so the relative residual\n    # check ||r||/||b|| = tol simplifies to ||r|| = tol.\n    res_norm = np.linalg.norm(r)\n    if res_norm = tol:\n        return 0, True\n\n    # Initialize algorithm parameters for k=0 state\n    rho_prev = 1.0\n    alpha = 1.0\n    omega = 1.0\n    v = np.zeros(n)\n    p = np.zeros(n)\n\n    # A very small number to check for breakdown (division by zero)\n    breakdown_tol = 1e-50\n\n    for k in range(1, max_iter + 1):\n        rho = r_hat.T @ r\n\n        if abs(rho)  breakdown_tol:\n            return max_iter, False  # Breakdown\n\n        if k > 1:\n            if abs(rho_prev)  breakdown_tol or abs(omega)  breakdown_tol:\n                return max_iter, False # Breakdown\n            beta = (rho / rho_prev) * (alpha / omega)\n            p = r + beta * (p - omega * v)\n        else: # for k = 1\n            p = r\n\n        v = A @ p\n\n        r_hat_dot_v = r_hat.T @ v\n        if abs(r_hat_dot_v)  breakdown_tol:\n            return max_iter, False  # Breakdown\n\n        alpha = rho / r_hat_dot_v\n        \n        s = r - alpha * v\n\n        t = A @ s\n\n        t_dot_t = t.T @ t\n        if abs(t_dot_t)  breakdown_tol:\n            return max_iter, False # Stagnation or breakdown\n\n        omega = (t.T @ s) / t_dot_t\n\n        x += alpha * p + omega * s\n        r = s - omega * t\n\n        rho_prev = rho\n\n        res_norm = np.linalg.norm(r)\n        if res_norm = tol:\n            return k, True\n\n    return max_iter, False\n\n\ndef generate_matrix(n, kappa, rng):\n    \"\"\"\n    Generates a random dense nonsymmetric matrix with a specified condition number.\n\n    Args:\n        n (int): The dimension of the square matrix.\n        kappa (float): The desired condition number.\n        rng (np.random.Generator): The random number generator instance.\n\n    Returns:\n        np.ndarray: The generated n x n matrix.\n    \"\"\"\n    # Generate a random matrix from a standard normal distribution\n    G = rng.standard_normal((n, n))\n\n    # Compute the SVD\n    U, _, Vt = np.linalg.svd(G)\n    V = Vt.T\n\n    # Create a geometrically spaced sequence of singular values\n    # from sigma_max = 1 to sigma_min = 1/kappa\n    singular_values = np.logspace(0, -np.log10(kappa), n)\n    \n    # Construct the final matrix A = U * diag(singular_values) * V^T\n    A = U @ np.diag(singular_values) @ Vt\n\n    return A\n\n\ndef solve():\n    \"\"\"\n    Main function to run the experiment and produce the final output.\n    \"\"\"\n    # Fixed parameters from the problem statement\n    n = 60\n    kappas = [1e1, 1e5, 1e12]\n    num_realizations = 8\n    tol = 1e-8\n    max_iter = 300\n    seed = 12345\n\n    rng = np.random.default_rng(seed)\n\n    all_stats = []\n\n    for kappa in kappas:\n        iterations_list = []\n        success_list = []\n\n        for _ in range(num_realizations):\n            # Generate test matrix and vector\n            A = generate_matrix(n, kappa, rng)\n            b_unscaled = rng.standard_normal(n)\n            b = b_unscaled / np.linalg.norm(b_unscaled) # Enforce ||b||_2 = 1\n\n            x0 = np.zeros(n)\n\n            # Run BiCGSTAB\n            k, success = bicgstab(A, b, x0, tol, max_iter)\n\n            iterations_list.append(k)\n            success_list.append(success)\n\n        # Aggregate statistics for the current kappa\n        successful_iters = [k for k, s in zip(iterations_list, success_list) if s]\n        num_success = len(successful_iters)\n        success_rate = num_success / num_realizations\n\n        if num_success > 0:\n            mean_iters = np.mean(successful_iters)\n            # Use population standard deviation (ddof=0 is the default in np.std)\n            std_iters = np.std(successful_iters)\n        else:\n            # As per problem spec for zero successful runs\n            mean_iters = float(max_iter)\n            std_iters = 0.0\n\n        all_stats.extend([mean_iters, std_iters, success_rate])\n\n    # Format the final output string exactly as required\n    print(f\"[{','.join(f'{x:.6f}' for x in all_stats)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在解决实际问题时，我们很少直接使用算法的“原版”实现。本练习将带你进入优化 BiCGSTAB 性能的实用技术领域。你将通过实验比较不同的初始猜测、缩放策略（一种简单的预条件技术）以及“影子残差” (shadow residual) 的选择，来分析哪种调优参数对不同类型的线性系统收敛性影响最大，从而掌握提升求解器效率的实用技巧。",
            "id": "3102150",
            "problem": "给定一个形如 $A x = b$ 的线性系统，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是非对称矩阵， $b \\in \\mathbb{R}^n$。考虑使用双共轭梯度稳定方法 (BiCGSTAB) 求解此系统。Krylov子空间方法的核心思想是在一系列子空间 $\\mathcal{K}_k(A, r_0) = \\text{span}\\{r_0, A r_0, A^2 r_0, \\dots, A^{k-1} r_0\\}$ 中近似解 $x$，其中 $r_0 = b - A x_0$ 是初始残差。BiCGSTAB 使用固定的“影子残差”实现双正交性，并构造更新方向以减小残差多项式，同时稳定方法以避免振荡。收敛性受三个可调因素影响：影子残差 $\\tilde{r}$ 的选择、初始猜测值 $x_0$ 的选择以及线性系统的缩放变换。\n\n从线性系统、残差和Krylov子空间的定义出发，设计并实现BiCGSTAB，不使用任何专门的线性求解器库。您的实现必须允许以下调整：\n- 选择影子残差 $\\tilde{r} \\in \\mathbb{R}^n$。\n- 选择初始猜测值 $x_0 \\in \\mathbb{R}^n$。\n- 通过对角矩阵 $S$ 选择系统缩放。\n\n将第 $k$ 次迭代的相对残差定义为 $\\|b - A x_k\\|_2 / \\|b\\|_2$。使用 $10^{-8}$ 的停止容差（即要求 $\\|b - A x_k\\|_2 / \\|b\\|_2 \\le 10^{-8}$）以及 $200$ 次的最大迭代上限。如果方法发生崩溃（在必须为非零的标量中出现除以零的情况）或在最大迭代次数内未能达到容差，则将迭代次数记录为 $201$，并记录最后一次迭代计算的最终相对残差。\n\n实现三种缩放选项：\n- 不缩放：$S = I$。\n- 行缩放：定义 $S_{\\text{row}} = \\text{diag}(s_i)$，其中 $s_i = 1 / (\\|A_{i,:}\\|_2 + \\delta)$，$A_{i,:}$ 是 $A$ 的第 $i$ 行，$\\delta = 10^{-12}$。求解缩放后的系统 $S_{\\text{row}} A x = S_{\\text{row}} b$ 得到 $x$。\n- 对称对角缩放：定义 $S = \\text{diag}(s_i)$，其中 $s_i = 1 / \\sqrt{|A_{ii}| + \\delta}$，$\\delta = 10^{-12}$。代入 $x = S y$ 并求解 $S^{-1} A S y = S^{-1} b$ 得到 $y$，然后恢复 $x = S y$。\n\n实现三种影子残差选择：\n- $\\tilde{r} = r_0$。\n- $\\tilde{r} = r_0 / \\|r_0\\|_2$。\n- $\\tilde{r} = v$，其中 $v$ 是一个由预定种子生成的固定伪随机单位向量。\n\n实现三种初始猜测值选择：\n- $x_0 = 0$。\n- $x_0 = \\mathbf{1}$ (全为1的向量)。\n- $x_0 = D^{-1} b$，其中 $D = \\text{diag}(A)$，$D^{-1}$ 使用逐元素取倒数并进行安全处理：如果 $A_{ii} = 0$，则在该位置使用 $1$。\n\n为了分离每个调整参数的影响，将基线配置定义为 $\\tilde{r} = r_0$，$x_0 = 0$ 且不缩放。对于每个调整维度，仅改变该维度的参数，同时将其他两个维度保持在基线水平：\n- 对于影子残差维度，测试三种 $\\tilde{r}$ 选择，同时保持 $x_0 = 0$ 且不缩放。\n- 对于初始猜测值维度，测试三种 $x_0$ 选择，同时保持 $\\tilde{r} = r_0$ 且不缩放。\n- 对于缩放维度，测试三种缩放选择，同时保持 $\\tilde{r} = r_0$ 且 $x_0 = 0$。\n\n对于每个维度，将其改进定义为与基线相比迭代次数的减少量，即 $\\text{improvement} = \\text{iterations}_{\\text{baseline}} - \\min(\\text{iterations over the three variants in that dimension})$。如果在不同维度上的最佳变体之间迭代次数出现平局，则通过最小的最终相对残差来打破平局。如果仍然平局，则根据排序选择最小的索引：影子残差索引为 $0$，初始猜测值索引为 $1$，缩放索引为 $2$。\n\n构造以下三个测试用例。在所有情况下，对矩阵和向量的条目使用独立种子的伪随机数生成，作为独立同分布的标准正态样本。\n- 测试用例1（良态基线）：$n = 40$。使用种子 $12345$ 生成 $M$，并定义 $A = M + 10 I$。使用种子 $54321$ 生成 $b$。\n- 测试用例2（病态乘积）：$n = 40$。使用种子 $67890$ 生成 $M$，使用种子 $98765$ 生成 $N$，并定义 $A = M N + 0.01 I$。使用种子 $13579$ 生成 $b$。\n- 测试用例3（行范数变化剧烈）：$n = 60$。使用种子 $24680$ 生成 $M$。定义 $D = \\text{diag}(d_i)$，其中 $d_i = 10^{\\ell_i}$，$\\ell_i$ 在 $-4$ 到 $4$ 之间均匀分布（对于 $i = 1, \\dots, n$），并设置 $A = D M + 0.1 I$。使用种子 $86420$ 生成 $b$。\n\n对于伪随机影子向量 $v$，使用种子 $9999$ 并归一化为单位范数。\n\n您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表，其中每个条目是相应测试用例中对收敛性影响最大的调整参数的整数索引，基于定义的改进和平局打破规则：$[r_1, r_2, r_3]$，其中 $r_i \\in \\{0,1,2\\}$ 分别对应于影子残差选择（$0$）、初始猜测值（$1$）和缩放（$2$）。此问题不涉及任何物理单位。",
            "solution": "我们从线性系统 $A x = b$ 和残差的定义 $r = b - A x$ 开始。Krylov子空间方法寻求 $x_k \\in x_0 + \\mathcal{K}_k(A, r_0)$，其中 $r_0 = b - A x_0$，从而构造减小残差范数的近似解。双共轭梯度（BiCG）方法依赖于 $A$ 和 $A^\\top$ 的残差序列之间的双正交性，这可能表现出振荡收敛。双共轭梯度稳定方法（BiCGSTAB）通过将BiCG搜索方向与应用于残差的局部最小残差步（一种1次多项式稳定化）相结合来提高鲁棒性。\n\n定义影子残差 $\\tilde{r}$（也称为“左”向量或“影子”向量），它在整个迭代过程中保持不变。BiCGSTAB通过强制与 $\\tilde{r}$ 的双正交性来构造标量递推系数，并用一个短的最小残差校正来稳定每一步。\n\n给定 $x_0$，设置 $r_0 = b - A x_0$ 并选择 $\\tilde{r}$（要求 $\\langle \\tilde{r}, r_0 \\rangle \\neq 0$ 以避免崩溃）。初始化 $p_0 = 0$，$v_0 = 0$，$\\rho_0 = \\alpha_0 = \\omega_0 = 1$，并对 $k = 1, 2, \\dots$ 进行迭代，计算：\n$$\n\\rho_k = \\langle \\tilde{r}, r_{k-1} \\rangle,\n$$\n如果 $\\rho_k = 0$，则检查是否发生崩溃。定义\n$$\n\\beta_k = \\frac{\\rho_k}{\\rho_{k-1}} \\cdot \\frac{\\alpha_{k-1}}{\\omega_{k-1}},\n$$\n并更新搜索方向：\n$$\np_k = r_{k-1} + \\beta_k (p_{k-1} - \\omega_{k-1} v_{k-1}).\n$$\n应用算子：\n$$\nv_k = A p_k,\n$$\n并计算\n$$\n\\alpha_k = \\frac{\\rho_k}{\\langle \\tilde{r}, v_k \\rangle},\n$$\n如果分母为零，则检查是否发生崩溃。计算中间残差：\n$$\ns_k = r_{k-1} - \\alpha_k v_k,\n$$\n应用算子：\n$$\nt_k = A s_k,\n$$\n并计算稳定化参数\n$$\n\\omega_k = \\frac{\\langle t_k, s_k \\rangle}{\\langle t_k, t_k \\rangle},\n$$\n如果 $\\langle t_k, t_k \\rangle = 0$ 或 $\\omega_k = 0$，则检查是否发生崩溃。更新近似解和残差：\n$$\nx_k = x_{k-1} + \\alpha_k p_k + \\omega_k s_k,\n$$\n$$\nr_k = s_k - \\omega_k t_k.\n$$\n当相对残差 $\\|b - A x_k\\|_2 / \\|b\\|_2$ 小于容差时终止。该公式通过在每次迭代中混合一个残差最小化步骤（通过 $\\omega_k$）来稳定BiCG。\n\n影子残差 $\\tilde{r}$ 的选择影响双正交关系以及标量 $\\rho_k$ 和 $\\alpha_k$，从而影响在Krylov子空间中探索的方向和对崩溃的敏感性。常见的选择包括 $\\tilde{r} = r_0$、归一化的影子 $\\tilde{r} = r_0 / \\|r_0\\|_2$（以控制标量的大小），或一个可能改变双正交配对的伪随机单位向量。\n\n初始猜测值 $x_0$ 影响初始残差 $r_0$，从而影响初始Krylov子空间 $\\mathcal{K}_k(A, r_0)$。一个更好的 $x_0$（例如，在适当时使用对角缩放的猜测值 $x_0 = D^{-1} b$，其中 $D = \\text{diag}(A)$）可以通过从更接近解的位置开始来显著减少迭代次数。\n\n缩放变换线性系统以改善条件数。两种对角缩放策略是：\n- 行缩放：用 $S_{\\text{row}}$ 进行左乘，其条目为 $S_{\\text{row},ii} = 1 / (\\|A_{i,:}\\|_2 + \\delta)$。求解 $S_{\\text{row}} A x = S_{\\text{row}} b$ 得到 $x$。这会归一化行的范数而不改变变量。\n- 对称对角缩放：选择 $S = \\text{diag}(s_i)$，其中 $s_i = 1 / \\sqrt{|A_{ii}| + \\delta}$，代入 $x = S y$，并求解 $S^{-1} A S y = S^{-1} b$ 得到 $y$，从而得到 $x = S y$。这可以平衡矩阵对角线周围的元素，并可以改善条件数。\n\n在我们的实验中，我们将三个调整项中的两个保持在基线水平，同时改变第三个来衡量其对收敛的独立影响。我们通过相对于基线的迭代次数减少量来定义改进。打破平局的方法是比较最小的最终相对残差，然后是三个调整参数中的最小索引：影子残差（$0$）、初始猜测值（$1$）、缩放（$2$）。\n\n测试套件包括三个系统：\n1.  良态基线：$A = M + 10 I$，其中 $n = 40$，$M$ 从使用种子 $12345$ 的标准正态分布中抽取，$b$ 同样从使用种子 $54321$ 的分布中抽取。\n2.  病态乘积：$A = M N + 0.01 I$，其中 $n = 40$，$M$ 和 $N$ 分别从使用种子 $67890$ 和 $98765$ 的标准正态分布中抽取，$b$ 使用种子 $13579$ 抽取。\n3.  行范数变化剧烈：$A = D M + 0.1 I$，其中 $n = 60$，$M$ 使用种子 $24680$ 抽取，$D = \\text{diag}(d_i)$，其中 $d_i = 10^{\\ell_i}$，$\\ell_i$ 在 $-4$ 到 $4$ 之间均匀分布，$b$ 使用种子 $86420$ 抽取。\n\n对于伪随机影子向量 $v$，使用种子 $9999$ 并归一化为单位范数。容差为 $10^{-8}$，迭代上限为 $200$；失败或崩溃将导致迭代次数为 $201$。\n\n最终程序实现了带有这些调整项的BiCGSTAB，使用规定的变体运行三个测试用例，计算每个调整参数的改进，并输出一行：$[r_1, r_2, r_3]$，其中 $r_i$ 表示在指定的平局打破规则下，对测试用例 $i$ 的收敛性影响最大的调整参数的索引。这整合了Krylov方法和双正交性的数学原理与算法设计，从而可以通过受控实验来评估哪些调整项对收敛行为的影响最大。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_random_matrix(n, seed):\n    rng = np.random.default_rng(seed)\n    return rng.standard_normal((n, n))\n\ndef generate_random_vector(n, seed):\n    rng = np.random.default_rng(seed)\n    return rng.standard_normal(n)\n\ndef symmetric_diagonal_scaling(A, b, x0, delta=1e-12):\n    # S = diag(1/sqrt(|A_ii| + delta))\n    diag = np.abs(np.diag(A)) + delta\n    s = 1.0 / np.sqrt(diag)\n    S = np.diag(s)\n    S_inv = np.diag(1.0 / s)\n    A_s = S_inv @ A @ S\n    b_s = S_inv @ b\n    x0_s = S_inv @ x0\n    # Mapping from scaled variable y to original x: x = S y\n    def map_to_original(x_var):\n        return S @ x_var\n    return A_s, b_s, x0_s, map_to_original\n\ndef row_scaling(A, b, x0, delta=1e-12):\n    # S_row = diag(1 / (||A_i,:||_2 + delta))\n    row_norms = np.linalg.norm(A, axis=1) + delta\n    s = 1.0 / row_norms\n    S_row = np.diag(s)\n    A_s = S_row @ A\n    b_s = S_row @ b\n    x0_s = x0.copy()\n    def map_to_original(x_var):\n        return x_var\n    return A_s, b_s, x0_s, map_to_original\n\ndef no_scaling(A, b, x0):\n    def map_to_original(x_var):\n        return x_var\n    return A, b, x0, map_to_original\n\ndef make_shadow_vector(option, r0, n, seed_rand=9999):\n    if option == 'r0':\n        return r0.copy()\n    elif option == 'r0_norm':\n        norm = np.linalg.norm(r0)\n        if norm == 0.0:\n            return r0.copy()\n        return r0 / norm\n    elif option == 'rand':\n        rng = np.random.default_rng(seed_rand)\n        v = rng.standard_normal(n)\n        norm = np.linalg.norm(v)\n        if norm == 0.0:\n            # Rare edge case; fallback to r0\n            return make_shadow_vector('r0_norm', r0, n, seed_rand)\n        return v / norm\n    else:\n        raise ValueError(\"Unknown shadow option\")\n\ndef bicgstab_tuned(A, b, x0, scaling_option='none', shadow_option='r0',\n                   tol=1e-8, max_iter=200, shadow_seed=9999):\n    n = A.shape[0]\n    # Apply scaling transform\n    if scaling_option == 'none':\n        A_s, b_s, x0_s, map_to_original = no_scaling(A, b, x0)\n    elif scaling_option == 'row':\n        A_s, b_s, x0_s, map_to_original = row_scaling(A, b, x0)\n    elif scaling_option == 'sym':\n        A_s, b_s, x0_s, map_to_original = symmetric_diagonal_scaling(A, b, x0)\n    else:\n        raise ValueError(\"Unknown scaling option\")\n\n    # Initialize\n    x_var = x0_s.copy()\n    r = b_s - A_s @ x_var\n    r_hat = make_shadow_vector(shadow_option, r, n, seed_rand=shadow_seed)\n\n    # If initial residual is already small in original system, we can early exit\n    x_orig = map_to_original(x_var)\n    b_norm = np.linalg.norm(b)\n    r_orig = b - A @ x_orig\n    rel_res = np.linalg.norm(r_orig) / (b_norm if b_norm != 0.0 else 1.0)\n    if rel_res = tol:\n        return 0, rel_res\n\n    rho_prev = 1.0\n    alpha = 1.0\n    omega = 1.0\n    v = np.zeros_like(b_s)\n    p = np.zeros_like(b_s)\n\n    iters = 0\n    breakdown = False\n    for k in range(1, max_iter + 1):\n        rho = np.dot(r_hat, r)\n        if rho == 0.0 or not np.isfinite(rho):\n            breakdown = True\n            iters = max_iter + 1\n            break\n        beta = (rho / rho_prev) * (alpha / omega)\n        p = r + beta * (p - omega * v)\n        v = A_s @ p\n        denom_alpha = np.dot(r_hat, v)\n        if denom_alpha == 0.0 or not np.isfinite(denom_alpha):\n            breakdown = True\n            iters = max_iter + 1\n            break\n        alpha = rho / denom_alpha\n        s = r - alpha * v\n        t = A_s @ s\n        tt = np.dot(t, t)\n        if tt == 0.0 or not np.isfinite(tt):\n            breakdown = True\n            iters = max_iter + 1\n            break\n        omega = np.dot(t, s) / tt\n        if omega == 0.0 or not np.isfinite(omega):\n            breakdown = True\n            iters = max_iter + 1\n            break\n        x_var = x_var + alpha * p + omega * s\n        r = s - omega * t\n\n        x_orig = map_to_original(x_var)\n        r_orig = b - A @ x_orig\n        rel_res = np.linalg.norm(r_orig) / (b_norm if b_norm != 0.0 else 1.0)\n        iters = k\n        if rel_res = tol:\n            breakdown = False\n            break\n\n        rho_prev = rho\n\n    if breakdown or rel_res > tol:\n        # Mark as failure to converge within max_iter or breakdown\n        return max_iter + 1, rel_res\n    else:\n        return iters, rel_res\n\ndef initial_guess_options(A, b):\n    n = A.shape[0]\n    x0_zero = np.zeros(n)\n    x0_one = np.ones(n)\n    # Diagonal-based initial guess\n    d = np.diag(A)\n    d_safe = d.copy()\n    # Replace zeros with 1 to avoid division by zero\n    d_safe[d_safe == 0.0] = 1.0\n    x0_diag = b / d_safe\n    return {'zero': x0_zero, 'one': x0_one, 'diag': x0_diag}\n\ndef build_test_cases():\n    cases = []\n    # Case 1\n    n1 = 40\n    M1 = generate_random_matrix(n1, seed=12345)\n    A1 = M1 + 10.0 * np.eye(n1)\n    b1 = generate_random_vector(n1, seed=54321)\n    cases.append((A1, b1))\n    # Case 2\n    n2 = 40\n    M2 = generate_random_matrix(n2, seed=67890)\n    N2 = generate_random_matrix(n2, seed=98765)\n    A2 = M2 @ N2 + 0.01 * np.eye(n2)\n    b2 = generate_random_vector(n2, seed=13579)\n    cases.append((A2, b2))\n    # Case 3\n    n3 = 60\n    M3 = generate_random_matrix(n3, seed=24680)\n    logs = np.linspace(-4.0, 4.0, n3)\n    dvals = 10.0 ** logs\n    D3 = np.diag(dvals)\n    A3 = D3 @ M3 + 0.1 * np.eye(n3)\n    b3 = generate_random_vector(n3, seed=86420)\n    cases.append((A3, b3))\n    return cases\n\ndef evaluate_case(A, b, tol=1e-8, max_iter=200):\n    n = A.shape[0]\n    # Baseline configuration\n    x0_opts = initial_guess_options(A, b)\n    baseline_x0 = x0_opts['zero']\n    baseline_iters, baseline_relres = bicgstab_tuned(\n        A, b, baseline_x0,\n        scaling_option='none',\n        shadow_option='r0',\n        tol=tol, max_iter=max_iter, shadow_seed=9999\n    )\n\n    # Shadow residual variations (x0=zero, scaling=none)\n    shadow_variants = ['r0', 'r0_norm', 'rand']\n    best_shadow_iters = None\n    best_shadow_relres = None\n    for sh in shadow_variants:\n        iters, relres = bicgstab_tuned(\n            A, b, baseline_x0,\n            scaling_option='none',\n            shadow_option=sh,\n            tol=tol, max_iter=max_iter, shadow_seed=9999\n        )\n        if best_shadow_iters is None or iters  best_shadow_iters or (iters == best_shadow_iters and relres  best_shadow_relres):\n            best_shadow_iters = iters\n            best_shadow_relres = relres\n\n    # Initial guess variations (shadow=r0, scaling=none)\n    x0_variants = [('zero', x0_opts['zero']), ('one', x0_opts['one']), ('diag', x0_opts['diag'])]\n    best_x0_iters = None\n    best_x0_relres = None\n    for name, x0v in x0_variants:\n        iters, relres = bicgstab_tuned(\n            A, b, x0v,\n            scaling_option='none',\n            shadow_option='r0',\n            tol=tol, max_iter=max_iter, shadow_seed=9999\n        )\n        if best_x0_iters is None or iters  best_x0_iters or (iters == best_x0_iters and relres  best_x0_relres):\n            best_x0_iters = iters\n            best_x0_relres = relres\n\n    # Scaling variations (shadow=r0, x0=zero)\n    scaling_variants = ['none', 'row', 'sym']\n    best_scaling_iters = None\n    best_scaling_relres = None\n    for sc in scaling_variants:\n        iters, relres = bicgstab_tuned(\n            A, b, baseline_x0,\n            scaling_option=sc,\n            shadow_option='r0',\n            tol=tol, max_iter=max_iter, shadow_seed=9999\n        )\n        if best_scaling_iters is None or iters  best_scaling_iters or (iters == best_scaling_iters and relres  best_scaling_relres):\n            best_scaling_iters = iters\n            best_scaling_relres = relres\n\n    # Compute improvements\n    imp_shadow = baseline_iters - best_shadow_iters\n    imp_x0 = baseline_iters - best_x0_iters\n    imp_scaling = baseline_iters - best_scaling_iters\n\n    # Choose most affecting parameter based on improvement, tie-breaking by relres, then index order 0,1,2\n    improvements = [imp_shadow, imp_x0, imp_scaling]\n    best_improvement = max(improvements)\n\n    # Collect candidates with the same best improvement\n    candidates = []\n    for idx, imp in enumerate(improvements):\n        if imp == best_improvement:\n            # store corresponding best relres\n            if idx == 0:\n                rel = best_shadow_relres\n            elif idx == 1:\n                rel = best_x0_relres\n            else:\n                rel = best_scaling_relres\n            candidates.append((idx, rel))\n\n    # Tie-break by smallest final relative residual, then smallest index\n    candidates.sort(key=lambda x: (x[1], x[0]))\n    most_affecting_index = candidates[0][0]\n    return most_affecting_index\n\ndef solve():\n    cases = build_test_cases()\n    results = []\n    for (A, b) in cases:\n        idx = evaluate_case(A, b, tol=1e-8, max_iter=200)\n        results.append(idx)\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}