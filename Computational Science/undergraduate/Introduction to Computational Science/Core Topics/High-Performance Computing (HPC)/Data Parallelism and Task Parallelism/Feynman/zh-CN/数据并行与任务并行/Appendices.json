{
    "hands_on_practices": [
        {
            "introduction": "理论上，加法的顺序不应影响最终结果，但在计算机中，有限精度的浮点数运算并非如此。本练习旨在通过编码实践，揭示浮点数运算的非结合性 (non-associativity) 如何影响并行计算的结果。你将实现并比较几种不同的求和策略，包括数据并行和任务并行模式，并观察它们在面对极端数值时的精度差异 。",
            "id": "3116514",
            "problem": "您的任务是演示浮点数加法的非结合性如何在计算科学中常用的两种并行聚合策略下导致不同的数值结果，并使用高精度求和作为参考来量化这些误差。本练习的基础是电气和电子工程师协会（IEEE）754标准下的浮点数加法舍入模型，该模型断言，对于每次浮点数加法，计算结果 $\\operatorname{fl}(a+b)$ 等于 $(a+b)(1+\\delta)$，其中某个 $\\delta$ 满足 $|\\delta| \\le \\epsilon$，而 $\\epsilon$ 是相应浮点格式的机器epsilon。此模型意味着浮点数加法不满足结合律：对于一般的 $a$、$b$ 和 $c$，可能会有 $(a+b)+c \\ne a+(b+c)$。\n\n您的程序必须在双精度下实现对有限实数序列的以下求和策略：\n\n- 从左到右的顺序求和，产生 $S_{\\text{naive}}$。\n- 由平衡二叉树建模的数据并行成对归约，它迭代地将相邻元素配对并对每对求和，产生 $S_{\\text{pair}}$。\n- 任务并行的分块求和，它首先将序列划分为固定大小的块，在每个块内计算从左到右的和，然后从左到右对各块的总和进行求和，产生 $S_{\\text{chunk}}$。\n- 使用Kahan算法的补偿求和，产生 $S_{\\text{kahan}}$，作为高精度参考。\n\n将双精度的机器epsilon $\\epsilon$ 定义为环境为 $\\text{float64}$ 报告的值。对于每个测试用例，计算绝对误差 $E_{\\text{naive}} = |S_{\\text{naive}} - S_{\\text{kahan}}|$、$E_{\\text{pair}} = |S_{\\text{pair}} - S_{\\text{kahan}}|$ 和 $E_{\\text{chunk}} = |S_{\\text{chunk}} - S_{\\text{kahan}}|$。\n\n通过重复地将序列 $\\{x_0, x_1, \\dots, x_{n-1}\\}$ 替换为成对和的序列 $\\{x_0 + x_1, x_2 + x_3, \\dots\\}$ 来实现数据并行归约，当长度为奇数时，保留末尾的元素不变，直到只剩下一个值。通过将序列划分为固定大小为 $m$ 的连续块，对每个块从左到右求和，然后对得到的块总和从左到右求和来实现任务并行的分块求和。对所有测试用例使用块大小 $m = 64$。\n\n使用以下序列测试套件，旨在探测理想情况下的行为、极端相消和边界条件。每个序列 $\\mathcal{X}$ 按顺序列出其元素：\n\n- 测试用例1（大正数、小数正数、大负数）：\n  $$\\mathcal{X}_1 = \\{10^{16}, \\underbrace{1, 1, \\dots, 1}_{1000 \\text{ 次}}, -10^{16}\\}.$$\n- 测试用例2（大负数、小数正数、大正数）：\n  $$\\mathcal{X}_2 = \\{-10^{16}, \\underbrace{1, 1, \\dots, 1}_{1000 \\text{ 次}}, 10^{16}\\}.$$\n- 测试用例3（边界：相同的小整数）：\n  $$\\mathcal{X}_3 = \\{\\underbrace{1, 1, \\dots, 1}_{1000 \\text{ 次}}\\}.$$\n- 测试用例4（跨极值的交替相消）：\n  $$\\mathcal{X}_4 = \\{10^{16}, \\underbrace{-1, -1, \\dots, -1}_{1000 \\text{ 次}}, -10^{16}, \\underbrace{1, 1, \\dots, 1}_{1000 \\text{ 次}}\\}.$$\n\n对于每个测试用例 $\\mathcal{X}_i$，您的程序必须按顺序计算并返回以下7个浮点数值：\n$$[S_{\\text{kahan}}, S_{\\text{naive}}, S_{\\text{pair}}, S_{\\text{chunk}}, E_{\\text{naive}}, E_{\\text{pair}}, E_{\\text{chunk}}].$$\n\n最终输出格式：您的程序应生成单行输出，其中包含所有四个测试用例连接起来的结果，形式为一个用方括号括起来的逗号分隔列表。该列表必须首先包含测试用例1的7个值，然后是测试用例2的7个值，接着是测试用例3，然后是测试用例4，总共产生28个数字。例如，输出形状必须是\n$$[S_{\\text{kahan}}^{(1)}, S_{\\text{naive}}^{(1)}, S_{\\text{pair}}^{(1)}, S_{\\text{chunk}}^{(1)}, E_{\\text{naive}}^{(1)}, E_{\\text{pair}}^{(1)}, E_{\\text{chunk}}^{(1)}, \\dots, S_{\\text{kahan}}^{(4)}, S_{\\text{naive}}^{(4)}, S_{\\text{pair}}^{(4)}, S_{\\text{chunk}}^{(4)}, E_{\\text{naive}}^{(4)}, E_{\\text{pair}}^{(4)}, E_{\\text{chunk}}^{(4)}].$$\n\n不涉及物理单位或角度单位。所有数值答案必须以标准十进制表示法报告为浮点数。",
            "solution": "该问题要求实现并比较四种不同的双精度浮点数序列求和算法。本练习旨在展示浮点数加法非结合性的实际后果，这是数值分析中的一个基石概念，其根源在于IEEE 754标准所规定的实数的有限精度表示。这四种算法——朴素顺序求和、成对数据并行求和、分块任务并行求和以及Kahan补偿求和——将在一个旨在引发不同数值误差行为的测试套件上进行评估。Kahan算法将作为高精度基准，用以量化其他三种方法的误差。\n\n所有数值运算将使用双精度浮点算术执行，对应于指定Python环境中的`numpy.float64`数据类型。此精度的机器epsilon，记为$\\epsilon$，是满足$1.0 + \\epsilon \\ne 1.0$的最小数。\n\n四种求和算法定义如下：\n\n1.  **朴素求和 ($S_{\\text{naive}}$)**：这是最直接的方法，序列$\\{x_0, x_1, \\dots, x_{n-1}\\}$的元素被从左到右逐一累加。步骤$k$的和$S_k$为$S_{k-1} + x_k$，其中$S_{-1} = 0$。这种方法容易产生较大误差，特别是在对数量级差异巨大的数字求和（灾难性相消）或对长序列求和（舍入误差的累积）时。\n\n2.  **Kahan求和 ($S_{\\text{kahan}}$)**：这是一种补偿求和算法，能显著减少总和的数值误差。它通过维护一个运行的补偿变量$c$来工作，该变量累积每次加法中产生的误差（即丢失的低位比特）。对每个元素$x_i$，执行以下步骤：\n    - $y \\leftarrow x_i - c$：从当前项中减去先前的误差。\n    - $t \\leftarrow \\text{sum} + y$：将校正后的项加到运行总和中。\n    - $c \\leftarrow (t - \\text{sum}) - y$：新的误差是总和的增量与校正项之差。这捕捉了在`sum + y`加法中丢失的低位比特。\n    - $\\text{sum} \\leftarrow t$：更新总和。\n    结果$S_{\\text{kahan}}$被认为是真实和的高保真度参考。\n\n3.  **成对求和 ($S_{\\text{pair}}$)**：该算法使用平衡二叉树结构来模拟数据并行归约。序列通过对相邻元素对求和来重复处理：$\\{x_0, x_1, x_2, \\dots\\} \\rightarrow \\{x_0+x_1, x_2+x_3, \\dots\\}$。如果序列元素个数为奇数，最后一个元素将不参与求和，直接进入下一次迭代。此过程重复进行，直到只剩下一个元素。这种方法通常比朴素求和更精确，因为它使中间和的量级保持得更均衡，从而减少了相对误差的增长。其误差界与$\\log_2(n)\\epsilon$成正比，而朴素求和的误差界为$n\\epsilon$。\n\n4.  **分块求和 ($S_{\\text{chunk}}$)**：此算法模拟任务并行方法。输入序列首先被划分为固定大小$m=64$的连续子序列（块）。每个块使用朴素的从左到右方法独立求和（概念上是并行的）。然后，将得到的局部和列表（每个块一个）同样使用朴素的从左到右方法求和，得到最终结果$S_{\\text{chunk}}$。此方法的精度取决于数据在块内和块间的分布情况。\n\n分析过程首先是按规定生成四个测试序列，确保所有值均为`numpy.float64`。对于每个序列，我们使用四种算法中的每一种来计算总和。最后，我们通过计算它们各自的和与高精度Kahan和$S_{\\text{kahan}}$之间的绝对差来计算绝对误差$E_{\\text{naive}}$、$E_{\\text{pair}}$和$E_{\\text{chunk}}$。预期的行为是，对于涉及灾难性相消的测试用例（用例1、2、4），朴素、成对和分块方法将表现出显著误差，而Kahan方法将得到接近真实数学和的结果。对于表现良好的用例（用例3），预计所有方法都会很精确。\n\n实现将包括四个函数，每种求和算法一个，以及一个主`solve`函数，用于协调测试、计算和将最终输出格式化为包含28个浮点数的单个逗号分隔字符串。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares four floating-point summation algorithms\n    to demonstrate the effects of non-associativity in numerical computation.\n    \"\"\"\n\n    def sum_kahan(arr: np.ndarray) - np.float64:\n        \"\"\"Computes the sum of an array using Kahan's compensated summation algorithm.\"\"\"\n        s = np.float64(0.0)\n        c = np.float64(0.0)  # A running compensation for lost low-order bits.\n        for x in arr:\n            y = x - c\n            t = s + y\n            c = (t - s) - y\n            s = t\n        return s\n\n    def sum_naive(arr: np.ndarray) - np.float64:\n        \"\"\"Computes the sum of an array using simple left-to-right accumulation.\"\"\"\n        s = np.float64(0.0)\n        for x in arr:\n            s += x\n        return s\n\n    def sum_pair(arr: np.ndarray) - np.float64:\n        \"\"\"Computes the sum using a data-parallel pairwise reduction.\"\"\"\n        current_arr = arr.copy()\n        while len(current_arr)  1:\n            n = len(current_arr)\n            new_len = (n + 1) // 2\n            next_arr = np.zeros(new_len, dtype=np.float64)\n            for i in range(n // 2):\n                next_arr[i] = current_arr[2 * i] + current_arr[2 * i + 1]\n            if n % 2 != 0:\n                next_arr[-1] = current_arr[-1]\n            current_arr = next_arr\n        return current_arr[0] if len(current_arr)  0 else np.float64(0.0)\n        \n    def sum_chunk(arr: np.ndarray, chunk_size: int) - np.float64:\n        \"\"\"Computes the sum using a task-parallel chunked approach.\"\"\"\n        n = len(arr)\n        if n == 0:\n            return np.float64(0.0)\n        \n        num_chunks = (n + chunk_size - 1) // chunk_size\n        chunk_sums = np.zeros(num_chunks, dtype=np.float64)\n\n        for i in range(num_chunks):\n            start = i * chunk_size\n            end = min(start + chunk_size, n)\n            chunk = arr[start:end]\n            # Naive sum within each chunk\n            chunk_sums[i] = sum_naive(chunk)\n        \n        # Naive sum of the chunk sums\n        return sum_naive(chunk_sums)\n\n    # Define the test cases from the problem statement.\n    test_cases_defs = [\n        # Case 1: Large positive, small positives, large negative\n        np.concatenate(([np.float64(1e16)], np.ones(1000, dtype=np.float64), [np.float64(-1e16)])),\n        # Case 2: Large negative, small positives, large positive\n        np.concatenate(([np.float64(-1e16)], np.ones(1000, dtype=np.float64), [np.float64(1e16)])),\n        # Case 3: Identical small integers\n        np.ones(1000, dtype=np.float64),\n        # Case 4: Alternating cancellation\n        np.concatenate(([np.float64(1e16)], np.full(1000, -1.0, dtype=np.float64), [np.float64(-1e16)], np.ones(1000, dtype=np.float64)))\n    ]\n    \n    chunk_size = 64\n    all_results = []\n\n    for case_arr in test_cases_defs:\n        s_kahan = sum_kahan(case_arr)\n        s_naive = sum_naive(case_arr)\n        s_pair = sum_pair(case_arr)\n        s_chunk = sum_chunk(case_arr, chunk_size)\n\n        e_naive = np.abs(s_naive - s_kahan)\n        e_pair = np.abs(s_pair - s_kahan)\n        e_chunk = np.abs(s_chunk - s_kahan)\n\n        all_results.extend([s_kahan, s_naive, s_pair, s_chunk, e_naive, e_pair, e_chunk])\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了并行计算对数值精度的影响后，我们转向一个核心性能问题：如何高效地将任务分配给多个处理器以实现负载均衡。对于成本不均的“非均匀”工作负载，简单的静态分配可能导致性能瓶颈。此练习将引导你模拟并比较不同的调度策略——从静态数据分区到动态自适应调度，再到任务并行模型——以量化它们在吞吐量上的表现 。",
            "id": "3116484",
            "problem": "你将实现一个独立的程序，用于在粒度调优下比较数据并行和任务并行在非均匀工作负载上的表现。其理论基础包括完成时间、吞吐量以及针对独立任务的同构工作单元调度的定义。对于一组具有代价的独立任务，调度在同构的处理单元 (PEs) 上，完成时间是指最慢的那个 PE 的完成时间，而吞吐量是总工作量除以完成时间。从这些定义出发，推导指定策略的调度行为并计算吞吐量。\n\n定义和基本原则：\n- 假设有 $N$ 个任务，其非负代价为 $w_1, w_2, \\dots, w_N$。每个 $w_i$ 代表任务 $i$ 的计算代价，以抽象的“工作单元”计量，其中 $1$ 个工作单元等于 $1$ 个时间单位。\n- 假设有 $P$ 个同构的处理单元 (PEs)，$P \\ge 1$，每个处理单元执行任务的速率为每时间单位 $1$ 个工作单元。\n- 总工作量为 $W = \\sum_{i=1}^{N} w_i$。\n- 一个 PE 的负载是分配给它的任务的代价之和。系统完成时间为 $M = \\max\\{\\text{每个 PE 的负载}\\}$。\n- 吞吐量为 $T = W / M$，以“工作单元/时间单位”表示。输出的吞吐量值为浮点数，四舍五入到 $6$ 位小数。\n\n你将实现并比较以下调度策略：\n1. 静态数据并行分区 (连续)：将 $N$ 个任务按原始索引顺序划分为 $P$ 个连续的块，这些块的大小最多相差 $1$。形式上，令 $q = \\lfloor N / P \\rfloor$ 且 $r = N \\bmod P$。对于 PE $j$（其中 $0 \\le j  P$），如果 $j  r$，则分配一个大小为 $q + 1$ 的连续块，否则分配一个大小为 $q$ 的块。计算每个 PE 的负载，即其分配到的任务代价之和，然后计算 $M$ 和 $T$。\n\n2. 导向自调度 (动态数据并行)：维护一个按原始索引顺序排列的剩余任务队列。令 $R$ 为任意步骤中剩余任务的数量。当一个 PE 可用时，分配一个大小为 $k = \\max\\left(\\lceil \\alpha \\cdot R / P \\rceil, g_{\\min}\\right)$ 的任务块，并截断以确保 $k \\le R$，其中 $\\alpha \\in (0, 1]$ 和 $g_{\\min} \\in \\mathbb{N}$ 是给定的调优参数。每个分配的任务块是队列中接下来的 $k$ 个连续任务。通过模拟 PE 的完成时间来建模动态调度：初始时，所有 $P$ 个 PE 在时间 $0$ 均为空闲；每当最早完成的 PE 变为可用时，分配下一个任务块，并通过加上该任务块的代价来更新其完成时间。持续此过程直到所有任务都已分配。完成时间 $M$ 是所有 $P$ 个 PE 的最终完成时间中的最大值。然后计算 $T$。\n\n3. 分叉-连接任务并行 (固定粗粒度任务大小)：首先将原始任务列表粗化为固定大小 $g \\in \\mathbb{N}$ 的连续组（粗粒度任务），最后一组可能更小，同时保持原始顺序。每个粗粒度任务的代价等于其构成任务的代价之和。使用贪心列表调度法在 $P$ 个 PE 上调度这些粗粒度任务：在每一步，将下一个粗粒度任务分配给最早可用的 PE，并将其完成时间加上该粗粒度任务的代价。完成时间 $M$ 是所有 $P$ 个 PE 的最终完成时间中的最大值。然后计算 $T$。\n\n假设：\n- 所有任务都是独立的。\n- 调度开销可忽略不计 (为零)。\n- 代价 $w_i$ 是确定且已知的。\n- 时间和工作量共享相同单位，因此吞吐量 $T$ 的单位是一致的，量纲为“工作单元/时间单位”。\n\n实现者必须严格遵循上述模型，以确保结果具有可比性。\n\n测试套件：\n为每个测试用例计算在指定参数下的吞吐量三元组 $[T_{\\text{static}}, T_{\\text{guided}}, T_{\\text{fork\\_join}}]$。程序必须生成单行输出，其中包含用方括号括起来的结果，结果是这些三元组的逗号分隔列表，每个三元组也用方括号括起来。所有浮点数必须四舍五入到 $6$ 位小数。\n\n- 测试用例 1 (理想情况，非均匀工作负载)：\n  - $N = 20$, $P = 4$。\n  - 代价 $w$ (按索引顺序)：$[5, 1, 1, 1, 10, 1, 1, 3, 2, 8, 1, 1, 1, 7, 1, 1, 4, 1, 1, 12]$。\n  - 导向调度参数：$\\alpha = 1.0$, $g_{\\min} = 1$。\n  - 分叉-连接粗粒度任务大小：$g = 3$。\n\n- 测试用例 2 (边界情况：单个 PE)：\n  - $N = 10$, $P = 1$。\n  - 代价 $w$：$[2, 5, 1, 3, 4, 2, 6, 1, 1, 8]$。\n  - 导向调度参数：$\\alpha = 0.5$, $g_{\\min} = 1$。\n  - 分叉-连接粗粒度任务大小：$g = 2$。\n\n- 测试用例 3 (边缘情况：任务数少于 PE 数)：\n  - $N = 5$, $P = 8$。\n  - 代价 $w$：$[7, 1, 3, 2, 9]$。\n  - 导向调度参数：$\\alpha = 1.0$, $g_{\\min} = 1$。\n  - 分叉-连接粗粒度任务大小：$g = 1$。\n\n- 测试用例 4 (带有一个重任务的倾斜大型工作负载)：\n  - $N = 100$, $P = 8$。\n  - 代价 $w$ 定义为：对于所有 $i \\in \\{1, 2, \\dots, 100\\}$，$w_i = 1$，除了 $w_{50} = 100$。\n  - 导向调度参数：$\\alpha = 1.0$, $g_{\\min} = 1$。\n  - 分叉-连接粗粒度任务大小：$g = 10$。\n\n最终输出规范：\n- 你的程序应生成单行输出，其中包含用方括号括起来的结果，结果是每个测试用例三元组的逗号分隔列表，每个三元组也用方括号括起来。例如：$[[T_1^{\\text{static}},T_1^{\\text{guided}},T_1^{\\text{fork\\_join}}],[T_2^{\\text{static}},T_2^{\\text{guided}},T_2^{\\text{fork\\_join}}],\\dots]$，数值四舍五入到 $6$ 位小数，且不含空格。",
            "solution": "用户提供了一个计算问题，要求实现并比较三种并行任务调度策略：静态连续分区、导向自调度以及一种基于任务粗化和列表调度的分叉-连接模型。比较的主要指标是吞吐量，定义为总工作量除以完成时间。\n\n问题陈述经过了严格验证，并被认为是有效的。它在科学上基于并行计算和调度理论的原理，定义良好，具有精确的算法定义和完整的输入数据，并且其表述是客观的。所有术语，如完成时间、吞吐量，以及每种调度算法的具体细节都得到了明确定义。所提供的测试用例涵盖了多种场景，包括典型的非均匀工作负载、边界条件 ($P=1$)、边缘情况 ($N  P$)",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to run the scheduling simulations and print results.\n    \"\"\"\n\n    def solve_static(w, P):\n        \"\"\"\n        Calculates throughput using static contiguous partitioning.\n        \"\"\"\n        N = len(w)\n        if N == 0:\n            return 0.0\n        \n        total_work = np.sum(w)\n        if total_work == 0:\n            return 0.0\n\n        pe_loads = np.zeros(P)\n        \n        q = N // P\n        r = N % P\n        \n        current_task_idx = 0\n        for j in range(P):\n            block_size = q + 1 if j  r else q\n            if block_size > 0:\n                end_idx = current_task_idx + block_size\n                block_cost = np.sum(w[current_task_idx:end_idx])\n                pe_loads[j] = block_cost\n                current_task_idx = end_idx\n        \n        makespan = np.max(pe_loads) if P > 0 else 0.0\n        if makespan == 0:\n            return 0.0\n        \n        throughput = total_work / makespan\n        return throughput\n\n    def solve_guided(w, P, alpha, gmin):\n        \"\"\"\n        Calculates throughput using guided self-scheduling.\n        \"\"\"\n        N = len(w)\n        if N == 0:\n            return 0.0\n        \n        total_work = np.sum(w)\n        if total_work == 0:\n            return 0.0\n\n        pe_finish_times = np.zeros(P)\n        task_idx = 0\n        \n        while task_idx  N:\n            pe_idx = np.argmin(pe_finish_times)\n            \n            R = N - task_idx\n            k = int(math.ceil(alpha * R / P))\n            k = max(k, gmin)\n            k = min(k, R)\n            \n            end_idx = task_idx + k\n            chunk_cost = np.sum(w[task_idx:end_idx])\n            pe_finish_times[pe_idx] += chunk_cost\n            task_idx = end_idx\n            \n        makespan = np.max(pe_finish_times) if P > 0 else 0.0\n        if makespan == 0:\n            return 0.0\n            \n        throughput = total_work / makespan\n        return throughput\n\n    def solve_fork_join(w, P, g):\n        \"\"\"\n        Calculates throughput using fork-join with coarse tasking and list scheduling.\n        \"\"\"\n        N = len(w)\n        if N == 0:\n            return 0.0\n            \n        total_work = np.sum(w)\n        if total_work == 0:\n            return 0.0\n            \n        coarse_tasks = []\n        for i in range(0, N, g):\n            chunk = w[i : i + g]\n            coarse_tasks.append(np.sum(chunk))\n            \n        pe_finish_times = np.zeros(P)\n        \n        for cost in coarse_tasks:\n            pe_idx = np.argmin(pe_finish_times)\n            pe_finish_times[pe_idx] += cost\n            \n        makespan = np.max(pe_finish_times) if P > 0 else 0.0\n        if makespan == 0:\n            return 0.0\n            \n        throughput = total_work / makespan\n        return throughput\n\n    # Test case 4 workload generation\n    w4 = np.ones(100)\n    w4[49] = 100.0  # w_50 in 1-based indexing\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'w': [5, 1, 1, 1, 10, 1, 1, 3, 2, 8, 1, 1, 1, 7, 1, 1, 4, 1, 1, 12], 'P': 4, 'guided_params': (1.0, 1), 'fork_join_g': 3},\n        {'w': [2, 5, 1, 3, 4, 2, 6, 1, 1, 8], 'P': 1, 'guided_params': (0.5, 1), 'fork_join_g': 2},\n        {'w': [7, 1, 3, 2, 9], 'P': 8, 'guided_params': (1.0, 1), 'fork_join_g': 1},\n        {'w': w4.tolist(), 'P': 8, 'guided_params': (1.0, 1), 'fork_join_g': 10},\n    ]\n\n    results = []\n    for case in test_cases:\n        w_case = case['w']\n        P_case = case['P']\n        alpha_case, gmin_case = case['guided_params']\n        g_case = case['fork_join_g']\n\n        t_static = solve_static(w_case, P_case)\n        t_guided = solve_guided(w_case, P_case, alpha_case, gmin_case)\n        t_fork_join = solve_fork_join(w_case, P_case, g_case)\n        \n        results.append([t_static, t_guided, t_fork_join])\n\n    # Final print statement in the exact required format.\n    formatted_triples = [\n        f\"[{','.join([f'{val:.6f}' for val in triple])}]\" \n        for triple in results\n    ]\n    print(f\"[{','.join(formatted_triples)}]\")\n    \nsolve()\n```"
        },
        {
            "introduction": "许多重要的科学计算问题，如动态规划，其计算任务之间存在固有的数据依赖关系，这为并行化带来了挑战。本练习以经典的 Smith-Waterman 序列比对算法为例，让你探索如何在这种依赖性约束下设计并行策略。你将实现并对比两种不同的并行调度方式：细粒度的任务并行“波前”算法和粗粒度的数据并行“分块”算法，从而深入理解同步开销与计算粒度之间的权衡 。",
            "id": "3116592",
            "problem": "你需要实现两种算法调度，用于计算 Smith–Waterman 局部对齐的动态规划 (DP) 矩阵，并根据一个简单、明确说明的成本模型，从屏障频率及其对吞吐量的影响方面分析同步粒度。这两种调度是：跨 DP 反对角线的任务并行波前调度，以及跨瓦片反对角线的数据并行分块调度。对于给定的序列对，该实现必须在两种调度中计算出相同的 DP 矩阵，然后使用成本模型计算屏障数量和吞吐量。任何首字母缩略词在首次使用时必须定义；如果使用，动态规划 (DP) 和单指令多数据 (SIMD) 将首先完整写出。所有数学实体必须用 LaTeX 书写。\n\n基本原理。使用 Smith–Waterman 局部对齐的动态规划核心定义。设序列为 $A$ 和 $B$，长度分别为 $m$ 和 $n$。构建一个形状为 $(m+1)\\times(n+1)$ 的矩阵 $H$，其中第一行和第一列初始化为 $0$。对于 $i\\in\\{1,\\dots,m\\}$ 和 $j\\in\\{1,\\dots,n\\}$，定义\n$$\nH[i,j] = \\max\\Big(0,\\; H[i-1,j-1] + s(A[i],B[j]),\\; H[i-1,j] + g,\\; H[i,j-1] + g\\Big),\n$$\n其中 $s(\\cdot,\\cdot)$ 是替换得分，匹配时为 $+2$，错配时为 $-1$，$g=-1$ 是间隙罚分。此递推关系是该计算的科学基础。\n\n调度与同步。$H[i,j]$ 的依赖项是 $H[i-1,j-1]$、$H[i-1,j]$ 和 $H[i,j-1]$，因此具有相同索引和 $i+j=d$ 的单元格可以在所有索引和为 $i+j=d-1$ 的单元格计算完成后进行处理。这导出一个偏序关系，可以通过 DP 矩阵的反对角线（一个波前）进行拓扑调度。在任务并行波前调度中，每个反对角线之间插入一个屏障，以强制任务间的全局同步。在数据并行分块调度中，矩阵沿 $i$ 轴和 $j$ 轴被划分为大小为 $b_i$ 和 $b_j$ 的矩形瓦片，瓦片按其瓦片反对角线进行调度；每个瓦片反对角线之间插入一个屏障。在瓦片内部，计算按行主序顺序进行，以遵循瓦片内的依赖关系。\n\n成本模型与吞吐量。假设每个 DP 单元格的评估成本为 $c_{\\text{cell}}$ 个时间单位，每个屏障的成本为 $c_{\\text{barrier}}$ 个时间单位。DP 单元格的总数为 $N_{\\text{cells}}=m\\cdot n$。设 $B_{\\text{task}}$ 表示任务并行波前调度中的屏障数量，$B_{\\text{block}}$ 表示数据并行分块调度中的屏障数量。每种调度的总时间为\n$$\nT_{\\text{task}} = N_{\\text{cells}}\\cdot c_{\\text{cell}} + B_{\\text{task}}\\cdot c_{\\text{barrier}},\\quad\nT_{\\text{block}} = N_{\\text{cells}}\\cdot c_{\\text{cell}} + B_{\\text{block}}\\cdot c_{\\text{barrier}}.\n$$\n将吞吐量定义为\n$$\n\\Theta = \\frac{N_{\\text{cells}}}{T},\n$$\n单位为每个抽象时间单位的单元格数。你必须为每个测试用例计算 $B_{\\text{task}}$、$B_{\\text{block}}$、$\\Theta_{\\text{task}}$ 和 $\\Theta_{\\text{block}}$。\n\n实现内容。编写一个单一、完整的程序，该程序：\n- 以两种方式实现 Smith–Waterman DP：基于单元格反对角线的任务并行波前调度和基于瓦片反对角线的数据并行分块调度。对于给定的输入，两种实现必须计算出相同的 $H$。\n- 通过计算实际遍历的、包含工作的已调度反对角线的数量，来统计每种调度中的屏障数量。\n- 使用成本模型计算每种调度的吞吐量。\n\n单位。吞吐量必须以每个抽象时间单位的单元格数报告，形式为浮点数，四舍五入到六位小数。不涉及物理单位。不使用角度。不使用百分比。\n\n测试套件。使用以下固定输入。对于每个测试用例，给定 $A$、$B$、$b_i$、$b_j$、$c_{\\text{cell}}$ 和 $c_{\\text{barrier}}$。\n- 测试 1：$A=\\text{\"ACGTACGT\"}$ (长度 $8$), $B=\\text{\"ACGTACGA\"}$ (长度 $8$), $b_i=2$, $b_j=2$, $c_{\\text{cell}}=1.0$, $c_{\\text{barrier}}=10.0$.\n- 测试 2：$A=\\text{\"ATCGATCGATCGATCGATCGATCGATCGATCG\"}$ (长度 $32$), $B=\\text{\"ACGTACGT\"}$ (长度 $8$), $b_i=8$, $b_j=4$, $c_{\\text{cell}}=1.0$, $c_{\\text{barrier}}=5.0$.\n- 测试 3：$A=\\text{\"A\"}$ 重复 $64$ 次, $B=\\text{\"A\"}$ 重复 $64$ 次, $b_i=64$, $b_j=64$, $c_{\\text{cell}}=1.0$, $c_{\\text{barrier}}=50.0$.\n- 测试 4：$A=\\text{\"ACGTACGTACGTAC\"}$ (长度 $15$), $B=\\text{\"A\"}$ (长度 $1$), $b_i=3$, $b_j=1$, $c_{\\text{cell}}=1.0$, $c_{\\text{barrier}}=8.0$.\n- 测试 5：$A=\\text{\"ACGT\"}$ (长度 $4$), $B=\\text{\"TGCA\"}$ (长度 $4$), $b_i=1$, $b_j=1$, $c_{\\text{cell}}=1.0$, $c_{\\text{barrier}}=2.0$.\n\n要求输出。对于每个测试用例，输出列表 $[B_{\\text{task}},B_{\\text{block}},\\Theta_{\\text{task}},\\Theta_{\\text{block}}]$，其中屏障数量为整数，吞吐量为四舍五入到六位小数的浮点数。你的程序应生成单行输出，包含所有结果，形式为一个用逗号分隔的列表，并用方括号括起来，中间没有空格，例如，对于以上五个测试用例，格式为 $[[\\cdots],[\\cdots],[\\cdots]]$。",
            "solution": "该问题要求实现并分析两种用于 Smith-Waterman 局部序列对齐算法的并行调度策略。分析的重点是同步粒度（由所需屏障数量量化）及其在指定成本模型下对计算吞吐量的影响。\n\n计算的核心是一个动态规划 (DP) 算法。设两个序列为 $A$ 和 $B$，其各自的长度为 $m$ 和 $n$。构建一个大小为 $(m+1) \\times (n+1)$ 的 DP 矩阵，记为 $H$。该矩阵的元素根据以下递推关系计算，其中 $i \\in \\{1,\\dots,m\\}$ 且 $j \\in \\{1,\\dots,n\\}$：\n$$\nH[i,j] = \\max\\Big(0,\\; H[i-1,j-1] + s(A[i-1],B[j-1]),\\; H[i-1,j] + g,\\; H[i,j-1] + g\\Big)\n$$\n$H$ 的第一行和第一列初始化为 $0$。函数 $s(\\cdot,\\cdot)$ 是一个替换得分，定义为字符匹配时为 $+2$，错配时为 $-1$。参数 $g$ 是间隙罚分，给定为 $g=-1$。请注意，对于使用从 0 开始索引序列 $A$ 和 $B$ 的实现，问题数学表示法中的项 $s(A[i],B[j])$ 对应于代码中的 $s(A[i-1], B[j-1])$。\n\n元素 $H[i,j]$ 的计算依赖于其邻居 $H[i-1,j-1]$、$H[i-1,j]$ 和 $H[i,j-1]$。这种依赖结构决定了可能的并行化策略。具体来说，所有位于同一反对角线（由恒定的索引和 $d = i+j$ 定义）上的单元格 $(i,j)$ 都可以并发计算，因为它们的依赖项都位于先前的反对角线（$d-1$ 和 $d-2$）上。这通常被称为波前计算。\n\n**调度 1：任务并行波前调度**\n\n在此调度中，并行性体现在单个 DP 单元格的层面上。DP 矩阵的每个反对角线形成一个计算波前。在一个波前中所有单元格的计算完成后，会插入一个同步屏障，以确保下一个波前所需的所有值都已可用。\n\n索引 $i$ 的范围是从 $1$ 到 $m$，$j$ 的范围是从 $1$ 到 $n$。因此，和 $d=i+j$ 的范围从单元格 $(1,1)$ 的最小值 $1+1=2$ 到单元格 $(m,n)$ 的最大值 $m+n$。此范围内的每个不同 $d$ 值都对应一个包含待计算单元格的唯一反对角线。此类反对角线的总数，也就是所需屏障的数量，是从 $2$ 到 $m+n$（含两端）的整数值的数量。\n$$\nB_{\\text{task}} = (m+n) - 2 + 1 = m+n-1\n$$\n\n**调度 2：数据并行分块调度**\n\n这种调度通过将 DP 矩阵划分为大小为 $b_i \\times b_j$ 的矩形瓦片，引入了更粗粒度的并行性。计算逐个瓦片进行，而不是逐个单元格。瓦片之间的依赖结构反映了单元格之间的依赖结构：一个瓦片索引为 $(I,J)$ 的瓦片只有在其相邻瓦片 $(I-1,J-1)$、$(I-1,J)$ 和 $(I,J-1)$ 计算完成后才能计算。\n\n设沿 $i$ 轴（行）和 $j$ 轴（列）的瓦片数量分别为 $N_i$ 和 $N_j$。这些是通过将维度除以瓦片大小后向上取整来计算的：\n$$\nN_i = \\lceil m/b_i \\rceil, \\quad N_j = \\lceil n/b_j \\rceil\n$$\n在整数算术中，可以计算为 $N_i = (m + b_i - 1) // b_i$ 和 $N_j = (n + b_j - 1) // b_j$。\n\n与任务并行情况类似，也应用了波前调度，但在瓦片层面上。位于同一瓦片反对角线（由 $D = I+J$ 定义，其中 $I \\in \\{1, \\dots, N_i\\}$ 且 $J \\in \\{1, \\dots, N_j\\}$）上的所有瓦片可以并行处理。每个瓦片反对角线后插入一个屏障。瓦片索引的和 $D$ 的范围从 $1+1=2$ 到 $N_i+N_j$。屏障的总数就是此类瓦片反对角线的数量：\n$$\nB_{\\text{block}} = (N_i+N_j) - 2 + 1 = N_i+N_j-1\n$$\n在每个瓦片内部，单元格按顺序计算（例如，按行主序），以遵循局部的单元格级别依赖关系。\n\n**成本模型与吞吐量分析**\n\n每种调度的性能使用一个简单的成本模型进行评估。待计算的 DP 单元格总数为 $N_{\\text{cells}} = m \\times n$。假设每个单元格计算耗时 $c_{\\text{cell}}$ 个时间单位，每个同步屏障成本为 $c_{\\text{barrier}}$ 个时间单位。一个调度的总时间 $T$ 是所有单元格计算时间和所有屏障成本的总和。\n\n对于任务并行调度：\n$$\nT_{\\text{task}} = N_{\\text{cells}} \\cdot c_{\\text{cell}} + B_{\\text{task}} \\cdot c_{\\text{barrier}}\n$$\n对于数据并行分块调度：\n$$\nT_{\\text{block}} = N_{\\text{cells}} \\cdot c_{\\text{cell}} + B_{\\text{block}} \\cdot c_{\\text{barrier}}\n$$\n吞吐量 $\\Theta$ 定义为每个抽象时间单位计算的单元格数量：\n$$\n\\Theta = \\frac{N_{\\text{cells}}}{T}\n$$\n因此，对于这两种调度，我们计算：\n$$\n\\Theta_{\\text{task}} = \\frac{N_{\\text{cells}}}{T_{\\text{task}}} \\quad \\text{and} \\quad \\Theta_{\\text{block}} = \\frac{N_{\\text{cells}}}{T_{\\text{block}}}\n$$\n实现将为每个提供的测试用例执行这些计算，包括对两种调度方法完整计算 DP 矩阵 $H$，以确认它们产生相同的结果（如果实现正确，则必须如此）。主要输出是屏障计数（$B_{\\text{task}}, B_{\\text{block}}$）和吞吐量（$\\Theta_{\\text{task}}, \\Theta_{\\text{block}}$）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef smith_waterman_recurrence(H, s_val, i, j, g):\n    \"\"\"\n    Computes a single cell H[i, j] of the Smith-Waterman DP matrix.\n    H is the DP matrix.\n    s_val is the substitution score for the current characters.\n    i, j are the 1-based indices of the cell.\n    g is the gap penalty.\n    \"\"\"\n    match_score = H[i - 1, j - 1] + s_val\n    deletion_score = H[i - 1, j] + g\n    insertion_score = H[i, j - 1] + g\n    H[i, j] = max(0, match_score, deletion_score, insertion_score)\n\ndef compute_task_parallel(A, B, g, s):\n    \"\"\"\n    Computes the Smith-Waterman DP matrix using a task-parallel wavefront schedule.\n    Returns the computed matrix H and the number of barriers.\n    \"\"\"\n    m, n = len(A), len(B)\n    H = np.zeros((m + 1, n + 1), dtype=np.float64)\n    num_barriers = m + n - 1\n\n    # Iterate through anti-diagonals d = i + j\n    for d in range(2, m + n + 1):\n        # In a parallel implementation, the inner loop would be parallelized.\n        # Here, we simulate the sequential dependency between wavefronts.\n        for i in range(1, m + 1):\n            j = d - i\n            if 1 = j = n:\n                s_val = s(A[i - 1], B[j - 1])\n                smith_waterman_recurrence(H, s_val, i, j, g)\n    \n    return H, num_barriers\n\ndef compute_data_parallel_blocked(A, B, bi, bj, g, s):\n    \"\"\"\n    Computes the Smith-Waterman DP matrix using a data-parallel blocked schedule.\n    Returns the computed matrix H and the number of barriers.\n    \"\"\"\n    m, n = len(A), len(B)\n    H = np.zeros((m + 1, n + 1), dtype=np.float64)\n\n    # Calculate number of tiles\n    Ni = (m + bi - 1) // bi\n    Nj = (n + bj - 1) // bj\n    num_barriers = Ni + Nj - 1\n\n    # Iterate through tile anti-diagonals D = I + J\n    for D in range(2, Ni + Nj + 1):\n        # In a parallel implementation, the inner loop over tiles would be parallelized.\n        for I_tile in range(1, Ni + 1):\n            J_tile = D - I_tile\n            if 1 = J_tile = Nj:\n                # Process all cells within the tile (I_tile, J_tile) sequentially\n                i_start = (I_tile - 1) * bi + 1\n                i_end = min(I_tile * bi, m) + 1\n                j_start = (J_tile - 1) * bj + 1\n                j_end = min(J_tile * bj, n) + 1\n\n                for i in range(i_start, i_end):\n                    for j in range(j_start, j_end):\n                        s_val = s(A[i - 1], B[j - 1])\n                        smith_waterman_recurrence(H, s_val, i, j, g)\n                        \n    return H, num_barriers\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (A, B, bi, bj, c_cell, c_barrier)\n        (\"ACGTACGT\", \"ACGTACGA\", 2, 2, 1.0, 10.0),\n        (\"ATCGATCGATCGATCGATCGATCGATCGATCG\", \"ACGTACGT\", 8, 4, 1.0, 5.0),\n        (\"A\" * 64, \"A\" * 64, 64, 64, 1.0, 50.0),\n        (\"ACGTACGTACGTAC\", \"A\", 3, 1, 1.0, 8.0),\n        (\"ACGT\", \"TGCA\", 1, 1, 1.0, 2.0),\n    ]\n\n    # Smith-Waterman parameters\n    g = -1.0\n    s = lambda c1, c2: 2.0 if c1 == c2 else -1.0\n    \n    all_results_str = []\n\n    for A, B, bi, bj, c_cell, c_barrier in test_cases:\n        m, n = len(A), len(B)\n        N_cells = m * n\n\n        # Task-parallel schedule\n        H_task, B_task = compute_task_parallel(A, B, g, s)\n        T_task = N_cells * c_cell + B_task * c_barrier\n        Theta_task = N_cells / T_task if T_task > 0 else 0.0\n\n        # Data-parallel blocked schedule\n        H_block, B_block = compute_data_parallel_blocked(A, B, bi, bj, g, s)\n        T_block = N_cells * c_cell + B_block * c_barrier\n        Theta_block = N_cells / T_block if T_block > 0 else 0.0\n\n        # Verification step (optional, for developer sanity)\n        # assert np.allclose(H_task, H_block), \\\n        #     f\"Matrices do not match for case A='{A}', B='{B}'\"\n\n        case_result = [\n            str(B_task),\n            str(B_block),\n            f\"{Theta_task:.6f}\",\n            f\"{Theta_block:.6f}\"\n        ]\n        case_str = f\"[{','.join(case_result)}]\"\n        all_results_str.append(case_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        }
    ]
}