{
    "hands_on_practices": [
        {
            "introduction": "我们的第一个实践将深入探讨一个基础场景，其中系统性能同时受到多种资源类型（本例中为中央处理器CPU和输入/输出I/O）的限制。通过数学推导优化解，您将学会如何在约束系统中平衡工作负载以实现最大吞吐量。这个练习阐明了一个核心原则：为了达到理想的负载均衡，共享资源（如带宽）和工作量（如数据块大小）都应与各工作单元的处理能力成比例分配。",
            "id": "3155775",
            "problem": "您正在设计一个批处理压缩器，该压缩器将总数据大小为 $S$（单位：兆字节）的数据分配给 $W$ 个并行工作单元。工作单元 $j$ 的中央处理器（CPU）压缩速率为 $c_j$（单位：兆字节/秒）。所有工作单元从一个共享存储系统读取数据，该系统的总输入/输出（I/O）带宽为 $B$（单位：兆字节/秒），可以任意分配给各工作单元，作为瞬时带宽份额 $u_j$（单位：兆字节/秒），但需满足各份额之和不超过总带宽的约束。\n\n从以下基本原则出发：\n- 对于任何串行工作阶段，总时间是可加的。如果一个工作单元必须先读取然后计算，其时间是读取时间和计算时间之和。\n- 时间等于工作量除以速率。如果一个工作单元以速率 $r$ 处理数据量 $x$，所花费的时间为 $x/r$。\n\n将每个工作单元 $j$ 建模为处理一个大小为 $x_j$（单位：兆字节）的数据块。该工作单元以带宽份额 $u_j$（单位：兆字节/秒）进行读取，并以 CPU 速率 $c_j$（单位：兆字节/秒）进行计算。I/O 和 CPU 之间没有重叠；这些阶段是串行的。因此，工作单元 $j$ 的完成时间为\n$$\nt_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}.\n$$\n共享 I/O 带宽必须满足\n$$\n\\sum_{j=1}^{W} u_j \\le B,\n$$\n总数据约束为\n$$\n\\sum_{j=1}^{W} x_j = S,\n$$\n对于所有的 $j$，都有 $x_j \\ge 0$ 和 $u_j \\ge 0$。\n\n您的任务是：\n- 仅根据所述基本原则和约束，推导最优分配 $\\{x_j\\}_{j=1}^W$ 和 $\\{u_j\\}_{j=1}^W$，以最小化完工时间（makespan），定义为在均衡约束 $t_j = t$（对于所有 $x_j > 0$ 的 $j$）下的共同完成时间 $t$。\n- 将共同完成时间 $t$（单位：秒）表示为 $S$、$B$ 和 $\\{c_j\\}$ 的函数。\n- 提供最优数据块大小 $x_j$（单位：兆字节）和带宽份额 $u_j$（单位：兆字节/秒）关于 $S$、$B$ 和 $\\{c_j\\}$ 的显式公式。\n\n实现一个程序，为每个提供的测试用例计算一个列表，其中包含：\n- 首先，共同完成时间 $t$（单位：秒）。\n- 其次，数据块大小 $x_1, x_2, \\ldots, x_W$（单位：兆字节）。\n- 最后，带宽份额 $u_1, u_2, \\ldots, u_W$（单位：兆字节/秒）。\n\n所有数值输出必须以上述单位表示，并四舍五入到恰好 $6$ 位小数。程序必须将所有测试用例的结果聚合成单行：一个逗号分隔的列表，每个测试用例的列表用方括号括起来，整个聚合结果也用方括号括起来。例如，最终输出应如下所示\n$[$ $[\\,\\text{case1\\_values}\\,]$ $,$ $[\\,\\text{case2\\_values}\\,]$ $,$ $\\ldots$ $]$.\n\n测试套件：\n- Case $1$: $S = 1000$, $B = 400$, $\\{c_j\\} = [50, 100, 150]$.\n- Case $2$: $S = 800$, $B = 100000$, $\\{c_j\\} = [80, 40, 80]$.\n- Case $3$: $S = 600$, $B = 60$, $\\{c_j\\} = [500, 200, 100]$.\n- Case $4$: $S = 123$, $B = 500$, $\\{c_j\\} = [200]$.\n- Case $5$: $S = 100$, $B = 100$, $\\{c_j\\} = [1, 9]$.\n\n您的程序应生成单行输出，其中包含结果，格式为一个用方括号括起来的逗号分隔列表，每个测试用例由一个方括号列表表示，顺序为 $[t, x_1, \\ldots, x_W, u_1, \\ldots, u_W]$，所有数字四舍五入到恰好 $6$ 位小数，并且打印输出中不包含单位符号。",
            "solution": "根据既定标准对问题进行验证。\n\n### 步骤 1：提取已知条件\n- 总数据大小：$S$（兆字节）\n- 并行工作单元数量：$W$\n- 工作单元 $j$ 的 CPU 压缩速率：$c_j$（兆字节/秒）\n- 总共享 I/O 带宽：$B$（兆字节/秒）\n- 工作单元 $j$ 的带宽份额：$u_j$（兆字节/秒）\n- 工作单元 $j$ 的数据块大小：$x_j$（兆字节）\n- 工作单元 $j$ 的完成时间：$t_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}$\n- 带宽约束：$\\sum_{j=1}^{W} u_j \\le B$\n- 总数据约束：$\\sum_{j=1}^{W} x_j = S$\n- 非负约束：对于所有 $j=1, \\ldots, W$，有 $x_j \\ge 0$, $u_j \\ge 0$。\n- 优化目标：最小化完工时间 $t$。\n- 均衡约束：对于所有 $x_j > 0$ 的工作单元 $j$，有 $t_j = t$。\n\n### 步骤 2：使用提取的已知条件进行验证\n问题被评估为**有效**。\n- **科学依据**：该模型基于计算科学中性能建模的基本原理，特别是关于工作量、速率和时间的关系，并考虑了共享资源的约束。\n- **适定性**：该问题是一个定义明确的约束优化问题，旨在在均衡约束下最小化完工时间，这通常会有一个唯一且有意义的解。\n- **目标**：问题使用精确、无歧义的数学和物理术语进行陈述。\n- **完整性与一致性**：问题提供了推导唯一解所需的所有必要数据和约束。这些约束彼此一致。为最小化时间，隐含了将充分利用全部带宽容量，因此 $\\sum u_j = B$。\n- **现实性**：所用的物理量及其关系是性能分析中使用的现实简化模型。\n\n### 步骤 3：结论与行动\n问题有效。解决方案的推导如下。\n\n### 最优分配和完成时间的推导\n\n目标是最小化共同完成时间，即完工时间 $t$。该问题被表述为在给定约束条件下，找到实现此最小 $t$ 的 $\\{x_j\\}_{j=1}^W$ 和 $\\{u_j\\}_{j=1}^W$ 的值。\n\n对于任何被分配了非零数据块（$x_j > 0$）的工作单元 $j$，其完成时间由下式给出：\n$$t_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}$$\n均衡约束要求对于所有此类工作单元，$t_j = t$。\n$$t = x_j \\left(\\frac{1}{u_j} + \\frac{1}{c_j}\\right)$$\n此方程意味着，对于给定的完工时间 $t$，一个工作单元可以处理的数据量 $x_j$ 取决于其分配到的 I/O 带宽 $u_j$ 和其固有的 CPU 速率 $c_j$。\n\n为了在总工作量 $S$ 固定的情况下最小化 $t$，系统必须以其最大可能的聚合吞吐量运行。聚合吞吐量为 $\\frac{S}{t}$。最大化此吞吐量等同于最小化 $t$。\n\n让我们用 $t$ 和各个分配量来表示总工作量 $S$。首先，我们重排时间方程以求解 $x_j$：\n$$x_j = \\frac{t}{\\frac{1}{u_j} + \\frac{1}{c_j}} = t \\frac{u_j c_j}{u_j + c_j}$$\n对所有工作单元求和，我们使用总数据约束 $\\sum x_j = S$：\n$$S = \\sum_{j=1}^{W} x_j = \\sum_{j=1}^{W} t \\frac{u_j c_j}{u_j + c_j} = t \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j}$$\n由此，聚合吞吐量为：\n$$\\frac{S}{t} = \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j}$$\n我们的优化问题是通过选择带宽份额 $\\{u_j\\}$ 来最大化此聚合吞吐量，约束条件为 $\\sum_{j=1}^{W} u_j \\le B$ 和 $u_j \\ge 0$。为最大化吞吐量，系统不应因未充分利用 I/O 资源而被人为地形成瓶颈。因此，最优解必须位于约束的边界上，即 $\\sum_{j=1}^{W} u_j = B$。\n\n我们使用拉格朗日乘数法将其表述为一个约束优化问题。拉格朗日函数 $\\mathcal{L}$ 为：\n$$\\mathcal{L}(\\{u_j\\}, \\lambda) = \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j} - \\lambda \\left(\\sum_{j=1}^{W} u_j - B\\right)$$\n为了找到最优的 $\\{u_j\\}$，我们将 $\\mathcal{L}$ 对每个 $u_k$ 的偏导数设为零：\n$$\\frac{\\partial \\mathcal{L}}{\\partial u_k} = \\frac{\\partial}{\\partial u_k}\\left(\\frac{u_k c_k}{u_k + c_k}\\right) - \\lambda = 0$$\n使用除法求导法则，我们得到：\n$$\\frac{\\partial}{\\partial u_k}\\left(\\frac{u_k c_k}{u_k + c_k}\\right) = \\frac{c_k(u_k + c_k) - u_k c_k(1)}{(u_k + c_k)^2} = \\frac{c_k^2}{(u_k + c_k)^2}$$\n因此，对于每个工作单元 $k$，我们有：\n$$\\frac{c_k^2}{(u_k + c_k)^2} = \\lambda \\implies \\frac{c_k}{u_k + c_k} = \\sqrt{\\lambda}$$\n我们求解 $u_k$：\n$$u_k + c_k = \\frac{c_k}{\\sqrt{\\lambda}} \\implies u_k = c_k \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right)$$\n这表明 $u_k$ 与 $c_k$ 成正比。我们通过应用带宽约束 $\\sum u_k = B$ 来确定比例常数（与 $\\lambda$ 相关）：\n$$B = \\sum_{k=1}^{W} u_k = \\sum_{k=1}^{W} c_k \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) = \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) \\sum_{k=1}^{W} c_k$$\n设 $C_{\\text{total}} = \\sum_{k=1}^{W} c_k$。则：\n$$B = \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) C_{\\text{total}} \\implies \\frac{1}{\\sqrt{\\lambda}} - 1 = \\frac{B}{C_{\\text{total}}}$$\n将此代回 $u_k$ 的表达式：\n$$u_k = c_k \\left(\\frac{B}{C_{\\text{total}}}\\right) = B \\frac{c_k}{\\sum_{j=1}^W c_j}$$\n这就是最优带宽份额 $u_k$ 的显式公式。它规定了总带宽 $B$ 应按各工作单元的 CPU 速率 $c_k$ 成比例地分配。\n\n在找到最优的 $u_j$ 后，我们可以确定最小完工时间 $t$。首先，我们计算 $\\frac{u_j c_j}{u_j + c_j}$ 这一项：\n$$u_j + c_j = B \\frac{c_j}{C_{\\text{total}}} + c_j = c_j \\left(\\frac{B}{C_{\\text{total}}} + 1\\right) = c_j \\frac{B + C_{\\text{total}}}{C_{\\text{total}}}$$\n$$\\frac{u_j c_j}{u_j + c_j} = \\frac{\\left(B \\frac{c_j}{C_{\\text{total}}}\\right)c_j}{c_j \\frac{B + C_{\\text{total}}}{C_{\\text{total}}}} = \\frac{B c_j}{B + C_{\\text{total}}}$$\n聚合吞吐量是这些项的和：\n$$\\frac{S}{t} = \\sum_{j=1}^{W} \\frac{B c_j}{B + C_{\\text{total}}} = \\frac{B}{B + C_{\\text{total}}} \\sum_{j=1}^{W} c_j = \\frac{B \\, C_{\\text{total}}}{B + C_{\\text{total}}}$$\n求解 $t$，我们得到最小完工时间的公式：\n$$t = S \\frac{B + C_{\\text{total}}}{B \\, C_{\\text{total}}} = S \\left(\\frac{1}{B} + \\frac{1}{C_{\\text{total}}}\\right)$$\n这个简洁的结果表明，总时间由总工作量 $S$ 除以一个有效系统速率决定，该速率是总 I/O 带宽 $B$ 和总 CPU 速率 $C_{\\text{total}}$ 的调和组合。\n\n最后，我们找到最优的数据块大小 $x_j$。使用我们之前推导的 $x_j$ 表达式：\n$$x_j = t \\frac{u_j c_j}{u_j + c_j} = t \\left(\\frac{B c_j}{B + C_{\\text{total}}}\\right)$$\n代入 $t$ 的公式：\n$$x_j = S \\left(\\frac{B + C_{\\text{total}}}{B \\, C_{\\text{total}}}\\right) \\left(\\frac{B c_j}{B + C_{\\text{total}}}\\right) = S \\frac{c_j}{C_{\\text{total}}} = S \\frac{c_j}{\\sum_{k=1}^W c_k}$$\n这表明总数据 $S$ 也应按各工作单元的 CPU 速率 $c_j$ 成比例地进行分配。\n\n### 公式总结\n1.  **总 CPU 速率**：$C_{\\text{total}} = \\sum_{j=1}^{W} c_j$\n2.  **最优共同完成时间**：$t = S \\left(\\frac{1}{B} + \\frac{1}{C_{\\text{total}}}\\right)$\n3.  **最优数据块大小**：$x_j = S \\frac{c_j}{C_{\\text{total}}}$\n4.  **最优带宽份额**：$u_j = B \\frac{c_j}{C_{\\text{total}}}$\n\n这些公式将被用于实现，以解决给定的测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the optimal completion time, chunk sizes, and bandwidth shares\n    for a parallel processing problem.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1000, 400, [50, 100, 150]),     # Case 1\n        (800, 100000, [80, 40, 80]),    # Case 2\n        (600, 60, [500, 200, 100]),     # Case 3\n        (123, 500, [200]),              # Case 4\n        (100, 100, [1, 9]),             # Case 5\n    ]\n\n    all_results_str = []\n    \n    for S, B, c_j_list in test_cases:\n        # Convert inputs to numpy array for vectorized operations\n        c_j = np.array(c_j_list, dtype=float)\n        \n        # Calculate the total CPU rate\n        C_total = np.sum(c_j)\n\n        # Handle potential division by zero, though not expected from problem constraints.\n        if B == 0 or C_total == 0:\n            # This scenario corresponds to an infinite completion time.\n            # As the problem implies positive inputs, we proceed with calculation.\n            # A robust implementation might raise an error here.\n            continue\n\n        # Derived formula for the common completion time t\n        t = S * (1.0 / B + 1.0 / C_total)\n\n        # Derived formula for optimal chunk sizes x_j\n        x_j = S * (c_j / C_total)\n\n        # Derived formula for optimal bandwidth shares u_j\n        u_j = B * (c_j / C_total)\n\n        # Assemble the results for the current case in the specified order\n        case_result = [t] + x_j.tolist() + u_j.tolist()\n        \n        # Format each number to 6 decimal places and create the bracketed string\n        case_result_str = f\"[{','.join([f'{val:.6f}' for val in case_result])}]\"\n        all_results_str.append(case_result_str)\n\n    # Final print statement in the exact required format: a list of lists.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现实世界中的计算任务，其执行时间往往是不可预测的，这对静态的任务分配策略构成了挑战。本实践通过模拟，对比了固定的静态分区策略与灵活的动态调度策略。您将亲手实现并观察，在任务时长存在随机性的情况下，为何像中央任务队列这样的动态方法能够更有效地防止处理器闲置，从而在整体性能上超越静态方法。",
            "id": "3155817",
            "problem": "您必须编写一个完整、可运行的程序，该程序模拟并比较两种并行任务执行的负载均衡策略，同时控制工作实体数量、独立任务数量以及任务持续时间的方差。比较的对象是使用静态分区的分布式内存系统和使用动态调度的共享内存系统。程序必须是自包含的，不需要用户输入，并以单行形式产生指定的输出格式。\n\n使用的基本原理和定义：\n- 分布式内存系统将任务分配给不共享中心状态的处理器；在静态分区中，每个处理器接收一个预先确定的任务子集。共享内存系统提供一个所有线程都可访问的全局状态；在动态调度中，一个中心化队列一次向下一个可用的工作者提供一个任务。\n- 总工作量是所有任务持续时间的总和，记为 $W = \\sum_{i=1}^{n} t_i$，其中 $n$ 是任务数量，$t_i$ 是任务 $i$ 的持续时间。完工时间（makespan）是并行完成时间，记为 $T = \\max_{j \\in \\{1,\\dots,p\\}} L_j$，其中 $p$ 是处理器或线程的数量，$L_j$ 是工作者 $j$ 处理的总负载，包括任何开销。负载均衡旨在最小化 $L_j$ 的方差，从而使 $T$ 接近 $W/p$。\n- 每个任务持续时间 $t_i$ 必须是严格非负的，并以秒为单位计量。任何用于调度或通信的开销也必须以秒为单位计量。任何涉及物理时间的答案都应以秒为单位。\n\n模拟规格：\n- 任务是独立的，其持续时间 $t_i$ 从均值为 $\\mu$ 秒、标准差为 $\\sigma$ 秒的正态分布中抽样，并在 $0$ 处截断以确保非负性。为保证可复现性，每个测试用例使用一个带有固定种子的随机数生成器 (RNG)。\n- 分布式内存静态分区：使用连续分配将 $n$ 个任务划分为 $p$ 个块。前 $r = n \\bmod p$ 个处理器接收 $b+1$ 个任务，其余的 $p-r$ 个处理器接收 $b$ 个任务，其中 $b = \\left\\lfloor \\frac{n}{p} \\right\\rfloor$。处理器 $j$ 的负载为 $L^{\\text{dist}}_j = \\sum t_i + o_{\\text{dist}} \\cdot m_j$，其中 $m_j$ 是分配给处理器 $j$ 的任务数量，$o_{\\text{dist}}$ 是分布式内存的每任务开销（以秒为单位，例如通信或分派成本）。\n- 共享内存动态调度：维护一个包含 $n$ 个任务的中心化队列。$p$ 个工作者中的每一个在空闲时会重复地拉取下一个可用任务。工作者每处理一个任务，其完成时间增加 $t_i + o_{\\text{sh}}$，其中 $o_{\\text{sh}}$ 是共享内存的每任务开销（以秒为单位，例如竞争或调度器成本）。完工时间是所有工作者中的最大完成时间。\n\n您的程序必须实现这两种策略并计算它们的完工时间：\n- $T_{\\text{dist}} = \\max_j L^{\\text{dist}}_j$ 用于分布式静态分区。\n- $T_{\\text{sh}}$ 用于上述事件驱动分配的共享动态调度。\n\n要求输出：\n- 对于每个测试用例，计算比率 $R = \\frac{T_{\\text{dist}}}{T_{\\text{sh}}}$。该比率是无量纲的（无单位）。较大的 $R$ 值表示在该情况下，共享内存动态调度相对于分布式静态分区更快。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[r_1,r_2,r_3]$），其中每个 $r_k$ 是第 $k$ 个测试用例的浮点数比率。\n\n测试套件：\n使用以下参数集。所有与时间相关的量都必须以秒为单位处理。必须完全按照指定的方式应用 RNG 种子，以使结果具有确定性。\n- 案例 $1$ (理想路径，低方差): $p=4$, $n=100$, $\\mu=1.0$ 秒, $\\sigma=0.1$ 秒, $o_{\\text{sh}}=0.0005$ 秒, $o_{\\text{dist}}=0.005$ 秒, 种子 $=42$。\n- 案例 $2$ (高方差): $p=8$, $n=1000$, $\\mu=0.5$ 秒, $\\sigma=0.6$ 秒, $o_{\\text{sh}}=0.0002$ 秒, $o_{\\text{dist}}=0.01$ 秒, 种子 $=123$。\n- 案例 $3$ (边界: $p \\gg n$): $p=32$, $n=40$, $\\mu=1.0$ 秒, $\\sigma=0.5$ 秒, $o_{\\text{sh}}=0.0002$ 秒, $o_{\\text{dist}}=0.005$ 秒, 种子 $=98765$。\n- 案例 $4$ (中等方差，不同开销): $p=16$, $n=1000$, $\\mu=0.2$ 秒, $\\sigma=0.2$ 秒, $o_{\\text{sh}}=0.0001$ 秒, $o_{\\text{dist}}=0.002$ 秒, 种子 $=2023$。\n- 案例 $5$ (边缘: 零方差): $p=10$, $n=100$, $\\mu=1.0$ 秒, $\\sigma=0.0$ 秒, $o_{\\text{sh}}=0.0003$ 秒, $o_{\\text{dist}}=0.0003$ 秒, 种子 $=7$。\n\n程序约束：\n- 使用任何现代编程语言逻辑实现模拟，但最终提交必须是最终答案部分指定的 Python 代码。\n- 不要读取输入。按所列方式硬编码测试用例。\n- 使用所描述的精确输出格式：单行输出，包含一个用方括号括起来的、按顺序排列的五个案例的浮点数比率列表，以逗号分隔。",
            "solution": "该问题要求对并行计算中的两种基本负载均衡策略进行比较分析：用于分布式内存系统的静态分区和用于共享内存系统的动态调度。目标是在各种条件下模拟这两种策略，并使用它们的完工时间（makespan）之比来量化其相对性能。完工时间是指从计算开始到最后一个任务完成所经过的总时间。\n\n此模拟的基础是生成一个工作负载，它由一组 $n$ 个独立任务组成。每个任务 $i \\in \\{1, \\dots, n\\}$ 的持续时间 $t_i$ 是一个随机变量。根据规定，任务持续时间从具有给定均值 $\\mu$ 和标准差 $\\sigma$ 的正态分布中抽样。由于时间不能为负，任何小于 $0$ 的抽样值都将被截断为 $0$。这在数学上表示为 $t_i = \\max(0, X_i)$，其中每个 $X_i$ 是从分布 $N(\\mu, \\sigma^2)$ 中抽取的独立样本。为确保模拟的可复现性，每个测试用例的随机数生成器都使用固定的种子进行初始化。\n\n第一种策略是静态分区，这是分布式内存环境的典型特征，在这种环境中，处理器间通信成本高昂，因此倾向于在计算前预先分配工作。$n$ 个任务通过连续块分配的方式划分给 $p$ 个处理器。每个处理器的任务数量被确定为尽可能均衡：设 $b = \\lfloor n/p \\rfloor$ 为基本任务数，$r = n \\bmod p$ 为余数。前 $r$ 个处理器每个分配 $m_j = b+1$ 个任务，其后的 $p-r$ 个处理器每个分配 $m_j = b$ 个任务。处理器 $j$ 上的总负载，记为 $L^{\\text{dist}}_j$，是其分配到的任务持续时间总和加上总开销成本。开销被建模为分配给该处理器的每个任务的恒定成本 $o_{\\text{dist}}$。因此，负载计算为 $L^{\\text{dist}}_j = \\left(\\sum_{i \\in \\text{Tasks}_j} t_i\\right) + m_j \\cdot o_{\\text{dist}}$。由于在此模型中所有处理器同时开始，总完工时间 $T_{\\text{dist}}$ 由完成其工作耗时最长的处理器决定：$T_{\\text{dist}} = \\max_{j \\in \\{1, \\dots, p\\}} L^{\\text{dist}}_j$。\n\n第二种策略是通过中央队列进行动态调度，这是共享内存环境的典型特征，在这种环境中，线程可以高效地访问一个公共的工作池。这个过程被建模为事件驱动的模拟。我们有 $p$ 个工作者，在时间 $t=0$ 时全部处于空闲状态。$n$ 个任务被放置在一个概念上的队列中。每当一个工作者变为空闲，它就从队列的前端取走下一个可用的任务。为了实现这一点，我们可以维护 $p$ 个工作者中每一个的完成时间。最小优先队列是实现此目的的高效数据结构，因为它允许快速检索将最早可用的工作者。\n模拟过程如下：\n$1$. 初始化一个包含 $p$ 个条目的最小优先队列，每个条目的值为 $0$，代表每个工作者的初始可用时间。\n$2$. 对于 $n$ 个任务中的每一个，其持续时间为 $t_i$：\n    a. 从优先队列中提取最小时间 $t_{\\text{free}}$。这代表了任何工作者变为空闲的最早时间。\n    b. 将任务 $t_i$ 分配给该工作者。该工作者现在将被占用，直到一个新的完成时间，计算公式为 $t_{\\text{new}} = t_{\\text{free}} + t_i + o_{\\text{sh}}$，其中 $o_{\\text{sh}}$ 是访问共享队列的每任务开销。\n    c. 将这个新的完成时间 $t_{\\text{new}}$ 插回优先队列中。\n$3$. 在所有 $n$ 个任务都通过此过程分配完毕后，优先队列中的值代表了每个工作者处理的所有任务的最终完成时间。动态调度策略的完工时间 $T_{\\text{sh}}$ 是优先队列中的最大值，因为这对应于整个集合中最后一个任务完成的时间：$T_{\\text{sh}} = \\max(\\text{最终工作者完成时间})$。\n\n最后，为了比较这两种策略的有效性，我们计算无量纲比率 $R = \\frac{T_{\\text{dist}}}{T_{\\text{sh}}}$。比率 $R > 1$ 表示动态调度比静态分区更快（即完工时间更短），这表明其适应任务持续时间变化的能力超过了其开销。相反，比率 $R < 1$ 则表明静态分区更有效，这可能发生在任务持续时间统一且分布式开销 $o_{\\text{dist}}$ 小于共享开销 $o_{\\text{sh}}$ 的情况下。比率 $R \\approx 1$ 意味着性能相当。该比率作为每个测试用例的最终输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Simulates and compares distributed static partitioning and shared dynamic scheduling\n    for parallel task execution across a suite of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (p, n, mu, sigma, o_sh, o_dist, seed)\n    test_cases = [\n        (4, 100, 1.0, 0.1, 0.0005, 0.005, 42),\n        (8, 1000, 0.5, 0.6, 0.0002, 0.01, 123),\n        (32, 40, 1.0, 0.5, 0.0002, 0.005, 98765),\n        (16, 1000, 0.2, 0.2, 0.0001, 0.002, 2023),\n        (10, 100, 1.0, 0.0, 0.0003, 0.0003, 7)\n    ]\n\n    results = []\n    for p, n, mu, sigma, o_sh, o_dist, seed in test_cases:\n        # Step 1: Generate task durations using a seeded RNG\n        # for reproducibility.\n        rng = np.random.default_rng(seed)\n        tasks = rng.normal(loc=mu, scale=sigma, size=n)\n        # Enforce non-negativity by truncating at 0.\n        tasks = np.maximum(0, tasks)\n\n        # Step 2: Simulate distributed memory static partitioning.\n        T_dist = 0.0\n        if p > 0 and n > 0:\n            b = n // p  # Base number of tasks per processor\n            r = n % p   # Remainder, for processors getting an extra task\n            \n            processor_loads_dist = np.zeros(p)\n            task_idx = 0\n            for j in range(p):\n                num_tasks_for_proc = b + 1 if j < r else b\n                if num_tasks_for_proc > 0:\n                    end_idx = task_idx + num_tasks_for_proc\n                    assigned_tasks = tasks[task_idx:end_idx]\n                    work_duration = np.sum(assigned_tasks)\n                    overhead = num_tasks_for_proc * o_dist\n                    processor_loads_dist[j] = work_duration + overhead\n                    task_idx = end_idx\n            \n            T_dist = np.max(processor_loads_dist)\n\n        # Step 3: Simulate shared memory dynamic scheduling.\n        T_sh = 0.0\n        if p > 0 and n > 0:\n            # A min-heap tracks the time each worker becomes free.\n            worker_finish_times = [0.0] * p\n            heapq.heapify(worker_finish_times)\n            \n            for task_duration in tasks:\n                # Get the worker that finishes earliest.\n                earliest_finish_time = heapq.heappop(worker_finish_times)\n                \n                # Assign the current task to this worker and update its finish time.\n                new_finish_time = earliest_finish_time + task_duration + o_sh\n                heapq.heappush(worker_finish_times, new_finish_time)\n            \n            # The makespan is the time the last worker finishes.\n            T_sh = max(worker_finish_times)\n\n        # Step 4: Compute the ratio.\n        ratio = 0.0\n        if T_sh > 0:\n            ratio = T_dist / T_sh\n        elif T_dist > 0:\n            # This case (T_sh=0, T_dist>0) is unlikely but handle for robustness.\n            ratio = float('inf')\n        else:\n            # If both are 0 (e.g., n=0), their performance is identical.\n            ratio = 1.0\n\n        results.append(ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "负载均衡不仅限于分配独立的任务，也包括优化数据流经一系列处理阶段的效率。作为最后的实践，您将扮演系统设计师的角色，通过识别瓶颈、重组处理阶段以及重新分配计算资源来改进一个图像处理流水线。此练习将理论上的瓶颈分析与经验性的模拟验证相结合，让您在一个更宏观的系统层面实践负载均衡的艺术。",
            "id": "3155812",
            "problem": "一个图像处理流水线由 $J$ 个阶段的序列组成。每个阶段 $j \\in \\{1,\\dots,J\\}$ 都有一个确定的处理成本 $s_j$，单位为秒/图像。一个阶段可以有 $w_j$ 个相同的处理器（例如，处理器线程），每个处理器一次处理一个图像。图像按顺序流过流水线，一个图像必须在进入阶段2之前完成阶段1，依此类推。该系统是封闭的：没有外部到达，处理的是一批固定的 $M$ 张图像。你被允许对流水线进行两种类型的修改：重排阶段，以及将相邻阶段融合成复合阶段。融合会创建一个复合阶段，其处理成本是被融合阶段成本的总和，其处理器数量是被融合阶段分配的处理器数量的总和。所有阶段可用的处理器总数是一个固定的整数 $N_{\\text{total}}$。基准策略为每个阶段精确分配一个处理器，并且不使用任何超过 $J$ 的多余处理器（也就是说，如果 $N_{\\text{total}} > J$，那么多余的 $N_{\\text{total}} - J$ 个处理器在基准情况下是未被使用的）。\n\n从速率、流量守恒和串行系统中瓶颈的基本定义出发，推导出一个基于原理的方法来：\n- 根据基准策略，预测基准流水线配置的稳态吞吐量（单位：图像/秒），作为 $\\{s_j\\}$ 和 $\\{w_j\\}$ 的函数。\n- 构建一个优化的流水线，可以使用你选择的任何重排和融合方式，但融合后必须恰好有 $K$ 个复合阶段，并将 $N_{\\text{total}}$ 个处理器分配到这 $K$ 个复合阶段，以在整数处理器约束下最接近地均衡各个阶段的服务速率。你的优化必须能从第一性原理进行解释，并且不得假设任何未从所述基础推导出的公式。\n- 预测优化后流水线的稳态吞吐量（单位：图像/秒）。\n- 通过模拟 $M$ 张图像通过具有确定性服务时间和每个阶段有限处理器池的流水线来凭经验验证这两个预测，将经验吞吐量计算为 $M$ 除以该批次的总完成时间（以图像/秒表示）。时间单位使用秒，吞吐量单位使用图像/秒。\n\n设计你的程序以实现以下具体的测试套件。在每种情况下，优化必须产生恰好 $K$ 个复合阶段，并将所有 $N_{\\text{total}}$ 个处理器分配到这 $K$ 个复合阶段。对于经验验证，精确模拟 $M$ 张图像：\n- 测试 1：$J=4$， $s=[1.0,1.0,1.0,1.0]$ 秒， $N_{\\text{total}}=4$， $K=2$， $M=400$。\n- 测试 2：$J=4$， $s=[5.0,1.0,1.0,1.0]$ 秒， $N_{\\text{total}}=4$， $K=2$， $M=400$。\n- 测试 3：$J=1$， $s=[5.0]$ 秒， $N_{\\text{total}}=3$， $K=1$， $M=600$。\n- 测试 4：$J=5$， $s=[8.0,2.0,2.0,2.0,2.0]$ 秒， $N_{\\text{total}}=6$， $K=3$， $M=600$。\n\n你的程序必须：\n- 对于每个测试用例，计算预测的基准吞吐量（图像/秒）、预测的优化吞吐量（图像/秒）、经验测量的基准吞吐量（图像/秒）、经验测量的优化吞吐量（图像/秒）、预测的改进因子（定义为优化后的预测吞吐量除以基准预测吞吐量，无量纲），以及经验测量的改进因子（定义为优化后的经验吞吐量除以基准经验吞吐量，无量纲）。\n- 将所有吞吐量表示为图像/秒，所有改进因子表示为小数（无百分号），每个报告值四舍五入到恰好 $6$ 位小数。\n\n最终输出格式要求：\n- 你的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表。该列表必须按测试1到4的顺序包含每个测试的6个值：基准预测吞吐量、优化预测吞吐量、基准经验吞吐量、优化经验吞吐量、预测改进因子、经验改进因子。具体来说，输出形式应为 $\\left[\\text{T}_{1,\\text{base,pred}},\\text{T}_{1,\\text{opt,pred}},\\text{T}_{1,\\text{base,emp}},\\text{T}_{1,\\text{opt,emp}},\\text{I}_{1,\\text{pred}},\\text{I}_{1,\\text{emp}},\\dots,\\text{T}_{4,\\text{base,pred}},\\text{T}_{4,\\text{opt,pred}},\\text{T}_{4,\\text{base,emp}},\\text{T}_{4,\\text{opt,emp}},\\text{I}_{4,\\text{pred}},\\text{I}_{4,\\text{emp}}\\right]$，每个值四舍五入到6位小数。",
            "solution": "问题要求对串行图像处理流水线进行分析和优化。解决方案将首先建立控制此类系统吞吐量的基本原理。基于这些原理，我们将推导出预测基准和优化流水线配置性能的方法。最后，我们将描述一种用于验证这些预测的经验模拟方法。\n\n**1. 基本原理与吞吐量预测**\n\n处理流水线是一个由顺序阶段组成的系统。此类系统的整体性能由每个阶段处理其任务的速率决定。\n\n设阶段 $j \\in \\{1, \\dots, J\\}$ 的确定性处理成本为每张图像 $s_j$ 秒。这代表了该阶段处理单个图像的服务时间。因此，阶段 $j$ 的单个处理器的内在速率是 $1/s_j$ 图像/秒。如果阶段 $j$ 分配了 $w_j$ 个相同的并行处理器，其总服务能力或服务速率 $\\mu_j$ 是单个处理器速率的总和，前提是假设总有图像可供处理。\n$$\n\\mu_j = \\frac{w_j}{s_j} \\quad \\text{(图像/秒)}\n$$\n在稳态下运行的串行流水线中，流量守恒原则规定，长期平均吞吐量（我们称之为 $T$）必须在每个阶段都相同。此外，任何给定阶段的吞吐量不能超过其服务速率，因此对于所有 $j \\in \\{1, \\dots, J\\}$ 都有 $T \\leq \\mu_j$。\n\n这意味着整个系统的吞吐量受限于服务速率最低的阶段。这个阶段被称为瓶颈。因此，整个流水线的稳态吞吐量是其所有组成阶段服务速率的最小值：\n$$\nT = \\min_{j \\in \\{1, \\dots, J\\}} \\{\\mu_j\\} = \\min_{j \\in \\{1, \\dots, J\\}} \\left\\{ \\frac{w_j}{s_j} \\right\\}\n$$\n\n**2. 基准流水线分析**\n\n问题定义了一个基准策略，即为 $J$ 个阶段中的每一个都精确分配一个处理器，即对于所有 $j$，$w_j = 1$。来自 $N_{\\text{total}}$ 总池中的任何多余处理器都未被使用。\n\n将推导出的吞吐量公式应用于基准情况，我们得到：\n$$\nT_{\\text{base,pred}} = \\min_{j \\in \\{1, \\dots, J\\}} \\left\\{ \\frac{1}{s_j} \\right\\}\n$$\n这可以重写为：\n$$\nT_{\\text{base,pred}} = \\frac{1}{\\max_{j \\in \\{1, \\dots, J\\}} \\{s_j\\}}\n$$\n这个结果是直观的：具有单个处理器的流水线的吞吐量受限于任何单个阶段最长处理时间的倒数。\n\n**3. 优化流水线设计与分析**\n\n优化任务包括重排原始阶段并将它们融合成恰好 $K$ 个复合阶段，然后将 $N_{\\text{total}}$ 个处理器分配给这些新阶段以最大化吞吐量。\n\n设 $K$ 个复合阶段由 $k \\in \\{1, \\dots, K\\}$ 索引。设 $S_k$ 是融合成复合阶段 $k$ 的原始阶段处理成本的总和，设 $W_k$ 是分配给它的整数处理器数量。处理器总数是守恒的：$\\sum_{k=1}^K W_k = N_{\\text{total}}$。优化后流水线的吞吐量是 $T_{\\text{opt}} = \\min_k \\{W_k / S_k\\}$。\n\n为了最大化这个吞吐量，我们必须解决最大化最小值问题：$\\max \\left( \\min_k \\{W_k / S_k\\} \\right)$。当所有复合阶段的服务速率相等时，即 $W_1/S_1 = W_2/S_2 = \\dots = W_K/S_K$，这个目标达到最大化。\n\n这代表了一个关于阶段划分和处理器整数分配的复杂联合优化问题。一个稳健的启发式方法包括两个连续的步骤：\n\n**步骤 3.1：阶段融合（划分）**\n首先，我们将原始阶段成本集合 $\\{s_j\\}_{j=1}^J$ 划分为 $K$ 个子集。此步骤的目标是创建总成本 $\\{S_k\\}_{k=1}^K$ 尽可能均衡的复合阶段。这为后续的处理器分配提供了良好的基础。贪心算法对此很有效：将原始成本 $s_j$ 按降序排序。然后，迭代地将排序列表中的下一个成本添加到当前总和最小的分区。这种启发式方法倾向于产生均衡良好的分区。问题陈述允许重排，因此这对应于形成任意的、而不仅仅是相邻的融合。\n\n**步骤 3.2：处理器分配**\n给定复合成本 $S_k$，我们必须找到一个总和为 $N_{\\text{total}}$ 的整数分配 $\\{W_k\\}$，以最大化 $\\min_k \\{W_k / S_k\\}$。理想的非整数分配将是 $W_k^{\\text{ideal}} \\propto S_k$。为了找到最佳整数解，我们使用一个直接针对瓶颈的贪心迭代算法：\n1. 为 $K$ 个复合阶段中的每一个初始化一个处理器，即对所有 $k$，$W_k=1$。这使用了 $K$ 个处理器。\n2. 剩余的 $N_{\\text{rem}} = N_{\\text{total}} - K$ 个处理器被逐一分配。\n3. 在 $N_{\\text{rem}}$ 次迭代中的每一次，识别当前的瓶颈阶段 $k^*$，即速率 $W_k/S_k$ 最小的阶段。如果出现平局，则选择成本 $S_k$ 较大的阶段作为瓶颈。\n4. 向此瓶颈阶段增加一个处理器：$W_{k^*} \\leftarrow W_{k^*} + 1$。\n5. 重复此过程直到所有处理器都被分配。\n\n此过程逐步提高最低的阶段速率，直接解决最大化最小值目标。由此产生的优化流水线的预测吞吐量是：\n$$\nT_{\\text{opt,pred}} = \\min_{k \\in \\{1, \\dots, K\\}} \\left\\{ \\frac{W_k}{S_k} \\right\\}\n$$\n其中 $\\{S_k\\}$ 和 $\\{W_k\\}$ 是优化过程的结果。\n\n**4. 通过模拟进行经验验证**\n\n稳态吞吐量的理论预测忽略了处理有限批次 $M$ 张图像时的瞬态启动和结束效应。为了获得经验测量值，我们模拟了流水线的运行。\n\n该模拟可以使用从排队论推导出的递推关系进行高效建模。设 $C_{i,j}$ 为图像 $i$ ($i \\in \\{0, \\dots, M-1\\}$) 在阶段 $j$ ($j \\in \\{0, \\dots, J-1\\}$) 的完成时间。一个图像只有在满足两个条件后才能在阶段 $j$ 开始处理：\n1. 图像本身已到达阶段 $j$，这发生在其完成阶段 $j-1$ 时。这个时间是 $C_{i, j-1}$。\n2. 阶段 $j$ 的一个处理器可用。在有 $w_j$ 个处理器且图像按序处理的情况下，处理图像 $i$ 的处理器不会早于图像 $i-w_j$ 完成阶段 $j$ 的时间空闲下来。这个时间是 $C_{i-w_j, j}$。\n\n图像 $i$ 在阶段 $j$ 的开始时间是这两个时间的最大值。完成时间是开始时间加上服务时间 $s_j$。这给出了递推关系：\n$$\nC_{i,j} = \\max(C_{i, j-1}, C_{i-w_j, j}) + s_j\n$$\n边界条件是 $C_{i, -1} = 0$（图像在时间 $0$ 时可用于第一阶段）和对于 $k  0$ 的 $C_{k, j} = 0$。模拟通过计算所有图像和阶段的矩阵 $C_{i,j}$ 来进行。\n\n处理这批 $M$ 张图像的总时间是最后一张图像完成最后一个阶段的时间，即 $C_{M-1, J-1}$（使用从0开始的索引）。那么经验吞吐量是：\n$$\nT_{\\text{emp}} = \\frac{M}{C_{M-1, J-1}}\n$$\n对基准和优化后的流水线配置都执行此模拟。\n\n**5. 改进因子**\n\n优化的改进通过优化后的吞吐量与基准吞吐量的比率来量化。\n- 预测改进因子：$I_{\\text{pred}} = T_{\\text{opt,pred}} / T_{\\text{base,pred}}$\n- 经验改进因子：$I_{\\text{emp}} = T_{\\text{opt,emp}} / T_{\\text{base,emp}}$\n这些因子是无量纲的。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_predicted_throughput(s_list: list[float], w_list: list[int]) - float:\n    \"\"\"Calculates the predicted steady-state throughput of a pipeline.\"\"\"\n    if not s_list:\n        return np.inf\n    \n    min_rate = np.inf\n    for s, w in zip(s_list, w_list):\n        if s  0:\n            rate = w / s\n            if rate  min_rate:\n                min_rate = rate\n        else: # A stage with zero cost has infinite throughput\n            pass\n    return min_rate\n\ndef run_simulation(s_list: list[float], w_list: list[int], M: int) - float:\n    \"\"\"Simulates the pipeline to find the empirical throughput for M images.\"\"\"\n    num_stages = len(s_list)\n    if num_stages == 0:\n        return np.inf\n    if M == 0:\n        return 0.0\n\n    # completion_times[i, j] is the time image i completes stage j\n    completion_times = np.zeros((M, num_stages))\n\n    for j in range(num_stages):\n        s = s_list[j]\n        w = w_list[j]\n        if w == 0: # If a stage has no workers, no image can pass\n            return 0.0\n        for i in range(M):\n            # Time image i is available for stage j (finished previous stage)\n            arrival_time_at_stage_j = completion_times[i, j - 1] if j  0 else 0.0\n            \n            # Time a worker for image i becomes available.\n            # This is determined by when the (i-w)-th image finished *this* stage.\n            contention_finish_time = completion_times[i - w, j] if i = w else 0.0\n            \n            start_time = max(arrival_time_at_stage_j, contention_finish_time)\n            completion_times[i, j] = start_time + s\n            \n    total_time = completion_times[M - 1, num_stages - 1]\n    \n    if total_time == 0:\n        return np.inf\n        \n    return M / total_time\n\ndef optimize_pipeline(s: list[float], N_total: int, K: int) - tuple[list[float], list[int]]:\n    \"\"\"\n    Constructs an optimized pipeline by partitioning stages and allocating workers.\n    Returns the composite stage costs (S_opt) and worker allocations (W_opt).\n    \"\"\"\n    # 1. Partition original stages into K composite stages using a greedy algorithm\n    # to make partition sums as equal as possible.\n    if K == 0:\n        return [], []\n    \n    s_sorted_indices = np.argsort(s)[::-1]\n    s_sorted = [s[i] for i in s_sorted_indices]\n    \n    partition_sums = [0.0] * K\n    \n    for cost in s_sorted:\n        min_sum_idx = np.argmin(partition_sums)\n        partition_sums[min_sum_idx] += cost\n        \n    S_opt = partition_sums\n    \n    # 2. Allocate N_total workers to the K composite stages using a greedy iterative\n    # approach that adds workers to the current bottleneck.\n    if K  N_total:\n        # Fallback for an unlikely scenario: not enough workers for 1 per stage.\n        W_opt = [0] * K\n        for i in range(N_total):\n            W_opt[i] += 1\n        return S_opt, W_opt\n\n    W_opt = [1] * K\n    workers_to_distribute = N_total - K\n    \n    for _ in range(workers_to_distribute):\n        current_rates = [(w / s if s  0 else np.inf) for w, s in zip(W_opt, S_opt)]\n        \n        # Find the bottleneck stage (minimum rate), with tie-breaking.\n        min_rate = np.inf\n        bottleneck_idx = -1\n        \n        potential_bottlenecks = []\n        for i in range(K):\n            if current_rates[i]  min_rate:\n                min_rate = current_rates[i]\n                potential_bottlenecks = [i]\n            elif current_rates[i] == min_rate:\n                potential_bottlenecks.append(i)\n\n        if len(potential_bottlenecks) == 1:\n            bottleneck_idx = potential_bottlenecks[0]\n        else:\n            # Tie-break by choosing the stage with the largest cost S_k\n            max_s_val = -1.0\n            for idx in potential_bottlenecks:\n                if S_opt[idx]  max_s_val:\n                    max_s_val = S_opt[idx]\n                    bottleneck_idx = idx\n\n        if bottleneck_idx != -1:\n            W_opt[bottleneck_idx] += 1\n        else: # Should not happen if K  0\n            W_opt[0] += 1\n            \n    return S_opt, W_opt\n\ndef run_analysis(J, s, N_total, K, M):\n    \"\"\"Performs the full analysis for a single test case.\"\"\"\n    # Baseline calculations\n    s_base = list(s)\n    w_base = [1] * J\n    T_base_pred = get_predicted_throughput(s_base, w_base)\n    T_base_emp = run_simulation(s_base, w_base, M)\n\n    # Optimized calculations\n    S_opt, W_opt = optimize_pipeline(s, N_total, K)\n    T_opt_pred = get_predicted_throughput(S_opt, W_opt)\n    T_opt_emp = run_simulation(S_opt, W_opt, M)\n    \n    # Improvement factors\n    I_pred = T_opt_pred / T_base_pred if T_base_pred  0 else 0.0\n    I_emp = T_opt_emp / T_base_emp if T_base_emp  0 else 0.0\n    \n    return [T_base_pred, T_opt_pred, T_base_emp, T_opt_emp, I_pred, I_emp]\n\ndef solve():\n    \"\"\"Defines test cases and prints the final formatted result string.\"\"\"\n    test_cases = [\n        # J, s, N_total, K, M\n        (4, [1.0, 1.0, 1.0, 1.0], 4, 2, 400),\n        (4, [5.0, 1.0, 1.0, 1.0], 4, 2, 400),\n        (1, [5.0], 3, 1, 600),\n        (5, [8.0, 2.0, 2.0, 2.0, 2.0], 6, 3, 600)\n    ]\n\n    all_results = []\n    for J, s, N_total, K, M in test_cases:\n        case_results = run_analysis(J, s, N_total, K, M)\n        all_results.extend(case_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{val:.6f}' for val in all_results])}]\")\n\nsolve()\n```"
        }
    ]
}