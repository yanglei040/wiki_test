{
    "hands_on_practices": [
        {
            "introduction": "本节的第一个练习将介绍一个负载均衡的基础场景：在一组能力不同的并行工作单元中分配工作负载。你将为一个拥有不同 CPU 速度 ($c_j$) 并共享一个公共 I/O 资源 (总带宽为 $B$) 的系统建模，并运用数学优化方法推导出数据的理想分配方案。这个实践旨在阐明如何通过确保没有任何单个工作单元或资源成为不成比例的瓶颈，从而实现最短的完成时间 。",
            "id": "3155775",
            "problem": "您正在设计一个批处理压缩器，该压缩器将总数据大小为 $S$ (单位：兆字节) 的任务分配给 $W$ 个并行工作单元。工作单元 $j$ 的中央处理器 (CPU) 压缩速率为 $c_j$ (单位：兆字节/秒)。所有工作单元从一个共享存储系统读取数据，该系统的总输入/输出 (I/O) 带宽为 $B$ (单位：兆字节/秒)，该带宽可以任意分配给各工作单元，作为其瞬时带宽份额 $u_j$ (单位：兆字节/秒)，但需满足所有份额之和不超过总带宽的约束。\n\n从以下基本原则出发：\n- 对于任何串行工作阶段，总时间是累加的。如果一个工作单元必须先读取数据再进行计算，其耗时为读取时间与计算时间之和。\n- 时间等于工作量除以速率。如果一个工作单元以速率 $r$ 处理大小为 $x$ 的数据，所用时间为 $x/r$。\n\n将每个工作单元 $j$ 建模为处理一个大小为 $x_j$ (单位：兆字节) 的数据块。该工作单元以带宽份额 $u_j$ (单位：兆字节/秒) 读取数据，并以 CPU 速率 $c_j$ (单位：兆字节/秒) 进行计算。I/O 和 CPU 之间没有重叠；这些阶段是串行的。因此，工作单元 $j$ 的完成时间为\n$$\nt_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}.\n$$\n共享 I/O 带宽必须满足\n$$\n\\sum_{j=1}^{W} u_j \\le B,\n$$\n总数据约束为\n$$\n\\sum_{j=1}^{W} x_j = S,\n$$\n且对于所有 $j$，都有 $x_j \\ge 0$ 和 $u_j \\ge 0$。\n\n您的任务是：\n- 仅根据所述基本原则和约束，推导出最优分配方案 $\\{x_j\\}_{j=1}^W$ 和 $\\{u_j\\}_{j=1}^W$，以最小化完工时间 (makespan)，完工时间定义为在均衡约束 $t_j = t$ (对于所有 $x_j > 0$ 的 $j$) 下的共同完成时间 $t$。\n- 将共同完成时间 $t$ (单位：秒) 表示为 $S$、$B$ 和 $\\{c_j\\}$ 的函数。\n- 提供最优数据块大小 $x_j$ (单位：兆字节) 和带宽份额 $u_j$ (单位：兆字节/秒) 关于 $S$、$B$ 和 $\\{c_j\\}$ 的显式公式。\n\n实现一个程序，为每个提供的测试用例计算一个包含以下内容的列表：\n- 首先是共同完成时间 $t$ (单位：秒)。\n- 其次是数据块大小 $x_1, x_2, \\ldots, x_W$ (单位：兆字节)。\n- 最后是带宽份额 $u_1, u_2, \\ldots, u_W$ (单位：兆字节/秒)。\n\n所有数值输出必须以上述单位表示，并四舍五入到恰好 $6$ 位小数。程序必须将所有测试用例的结果汇总到一行：一个由逗号分隔的列表，其中每个测试用例的列表都用方括号括起来，整个汇总结果也用方括号括起来。例如，最终输出应如下所示：\n$[$ $[\\,\\text{case1\\_values}\\,]$ $,$ $[\\,\\text{case2\\_values}\\,]$ $,$ $\\ldots$ $]$。\n\n测试套件：\n- 用例 1：$S = 1000$, $B = 400$, $\\{c_j\\} = [50, 100, 150]$。\n- 用例 2：$S = 800$, $B = 100000$, $\\{c_j\\} = [80, 40, 80]$。\n- 用例 3：$S = 600$, $B = 60$, $\\{c_j\\} = [500, 200, 100]$。\n- 用例 4：$S = 123$, $B = 500$, $\\{c_j\\} = [200]$。\n- 用例 5：$S = 100$, $B = 100$, $\\{c_j\\} = [1, 9]$。\n\n您的程序应生成单行输出，其中包含一个由方括号括起来的、逗号分隔的结果列表，每个测试用例的结果按 $[t, x_1, \\ldots, x_W, u_1, \\ldots, u_W]$ 的顺序排列在一个方括号列表中，所有数字四舍五入到恰好 $6$ 位小数，且打印输出中不包含单位符号。",
            "solution": "根据既定标准对问题进行验证。\n\n### 步骤 1：提取已知条件\n- 总数据大小：$S$ (兆字节)\n- 并行工作单元数量：$W$\n- 工作单元 $j$ 的 CPU 压缩速率：$c_j$ (兆字节/秒)\n- 总共享 I/O 带宽：$B$ (兆字节/秒)\n- 工作单元 $j$ 的带宽份额：$u_j$ (兆字节/秒)\n- 工作单元 $j$ 的数据块大小：$x_j$ (兆字节)\n- 工作单元 $j$ 的完成时间：$t_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}$\n- 带宽约束：$\\sum_{j=1}^{W} u_j \\le B$\n- 总数据约束：$\\sum_{j=1}^{W} x_j = S$\n- 非负约束：对于所有 $j=1, \\ldots, W$，有 $x_j \\ge 0$, $u_j \\ge 0$。\n- 优化目标：最小化完工时间 $t$。\n- 均衡约束：对于所有 $x_j>0$ 的工作单元 $j$，$t_j=t$。\n\n### 步骤 2：使用提取的已知条件进行验证\n问题被评估为**有效**。\n- **科学性**：该模型基于计算科学中性能建模的基本原则，特别是关于工作量、速率和时间的关系，并考虑了共享资源的约束。\n- **良态性**：该问题是一个定义明确的约束优化问题，旨在在均衡约束下最小化完工时间，这通常会有一个唯一且有意义的解。\n- **客观性**：问题使用精确、无歧义的数学和物理术语进行陈述。\n- **完整性与一致性**：问题为推导唯一解提供了所有必要的数据和约束。各约束条件相互一致。为了最小化时间，隐含的条件是应充分利用全部带宽容量，因此 $\\sum u_j = B$。\n- **现实性**：所涉及的物理量及其关系是性能分析中使用的现实简化模型。\n\n### 步骤 3：结论与操作\n问题有效。解决方案的推导如下。\n\n### 最优分配和完成时间的推导\n\n目标是最小化共同完成时间，即完工时间 $t$。该问题被表述为在给定约束条件下，找到使 $t$ 达到最小值的 $\\{x_j\\}_{j=1}^W$ 和 $\\{u_j\\}_{j=1}^W$ 的值。\n\n对于任何被分配了非零数据块 ($x_j > 0$) 的工作单元 $j$，其完成时间由下式给出：\n$$t_j = \\frac{x_j}{u_j} + \\frac{x_j}{c_j}$$\n均衡约束要求所有此类工作单元的 $t_j = t$。\n$$t = x_j \\left(\\frac{1}{u_j} + \\frac{1}{c_j}\\right)$$\n该方程表明，对于给定的完工时间 $t$，一个工作单元可以处理的数据量 $x_j$ 取决于其分配到的 I/O 带宽 $u_j$ 及其固有的 CPU 速率 $c_j$。\n\n为了在总工作量 $S$ 固定的情况下最小化 $t$，系统必须以其最大可能的总吞吐率运行。总吞吐率为 $\\frac{S}{t}$。最大化此吞吐率等同于最小化 $t$。\n\n让我们用 $t$ 和各项分配来表示总工作量 $S$。首先，我们重新整理时间方程以求解 $x_j$：\n$$x_j = \\frac{t}{\\frac{1}{u_j} + \\frac{1}{c_j}} = t \\frac{u_j c_j}{u_j + c_j}$$\n对所有工作单元求和，我们使用总数据约束 $\\sum x_j = S$：\n$$S = \\sum_{j=1}^{W} x_j = \\sum_{j=1}^{W} t \\frac{u_j c_j}{u_j + c_j} = t \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j}$$\n由此，总吞吐率为：\n$$\\frac{S}{t} = \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j}$$\n我们的优化问题是在约束 $\\sum_{j=1}^{W} u_j \\le B$ 和 $u_j \\ge 0$ 下，通过选择带宽份额 $\\{u_j\\}$ 来最大化这个总吞吐率。为最大化吞吐率，系统不应因 I/O 资源未被充分利用而被人为地制造瓶颈。因此，最优解必须位于约束的边界上，即 $\\sum_{j=1}^{W} u_j = B$。\n\n我们使用拉格朗日乘数法将此问题表述为一个约束优化问题。拉格朗日函数 $\\mathcal{L}$ 为：\n$$\\mathcal{L}(\\{u_j\\}, \\lambda) = \\sum_{j=1}^{W} \\frac{u_j c_j}{u_j + c_j} - \\lambda \\left(\\sum_{j=1}^{W} u_j - B\\right)$$\n为求最优的 $\\{u_j\\}$，我们将 $\\mathcal{L}$ 对每个 $u_k$ 的偏导数设为零：\n$$\\frac{\\partial \\mathcal{L}}{\\partial u_k} = \\frac{\\partial}{\\partial u_k}\\left(\\frac{u_k c_k}{u_k + c_k}\\right) - \\lambda = 0$$\n使用微分的商法则，我们得到：\n$$\\frac{\\partial}{\\partial u_k}\\left(\\frac{u_k c_k}{u_k + c_k}\\right) = \\frac{c_k(u_k + c_k) - u_k c_k(1)}{(u_k + c_k)^2} = \\frac{c_k^2}{(u_k + c_k)^2}$$\n因此，对于每个工作单元 $k$，我们有：\n$$\\frac{c_k^2}{(u_k + c_k)^2} = \\lambda \\implies \\frac{c_k}{u_k + c_k} = \\sqrt{\\lambda}$$\n我们求解 $u_k$：\n$$u_k + c_k = \\frac{c_k}{\\sqrt{\\lambda}} \\implies u_k = c_k \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right)$$\n这表明 $u_k$ 与 $c_k$ 成正比。我们通过应用带宽约束 $\\sum u_k = B$ 来确定比例常数（与 $\\lambda$ 相关）：\n$$B = \\sum_{k=1}^{W} u_k = \\sum_{k=1}^{W} c_k \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) = \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) \\sum_{k=1}^{W} c_k$$\n令 $C_{\\text{total}} = \\sum_{k=1}^{W} c_k$。则：\n$$B = \\left(\\frac{1}{\\sqrt{\\lambda}} - 1\\right) C_{\\text{total}} \\implies \\frac{1}{\\sqrt{\\lambda}} - 1 = \\frac{B}{C_{\\text{total}}}$$\n将此结果代回 $u_k$ 的表达式中：\n$$u_k = c_k \\left(\\frac{B}{C_{\\text{total}}}\\right) = B \\frac{c_k}{\\sum_{j=1}^W c_j}$$\n这就是最优带宽份额 $u_k$ 的显式公式。它规定总带宽 $B$ 应按各工作单元的 CPU 速率 $c_k$ 成比例分配。\n\n找到最优的 $u_j$ 后，我们可以确定最小完工时间 $t$。首先，我们计算 $\\frac{u_j c_j}{u_j + c_j}$ 这一项：\n$$u_j + c_j = B \\frac{c_j}{C_{\\text{total}}} + c_j = c_j \\left(\\frac{B}{C_{\\text{total}}} + 1\\right) = c_j \\frac{B + C_{\\text{total}}}{C_{\\text{total}}}$$\n$$\\frac{u_j c_j}{u_j + c_j} = \\frac{\\left(B \\frac{c_j}{C_{\\text{total}}}\\right)c_j}{c_j \\frac{B + C_{\\text{total}}}{C_{\\text{total}}}} = \\frac{B c_j}{B + C_{\\text{total}}}$$\n总吞吐率是这些项的总和：\n$$\\frac{S}{t} = \\sum_{j=1}^{W} \\frac{B c_j}{B + C_{\\text{total}}} = \\frac{B}{B + C_{\\text{total}}} \\sum_{j=1}^{W} c_j = \\frac{B \\, C_{\\text{total}}}{B + C_{\\text{total}}}$$\n求解 $t$，我们得到最小完工时间的公式：\n$$t = S \\frac{B + C_{\\text{total}}}{B \\, C_{\\text{total}}} = S \\left(\\frac{1}{B} + \\frac{1}{C_{\\text{total}}}\\right)$$\n这个简洁的结果表明，总时间由总工作量 $S$ 除以一个有效系统速率决定，该有效速率的倒数是总 I/O 带宽 $B$ 和总 CPU 速率 $C_{\\text{total}}$ 的倒数之和。\n\n最后，我们求最优数据块大小 $x_j$。使用我们之前推导的 $x_j$ 表达式：\n$$x_j = t \\frac{u_j c_j}{u_j + c_j} = t \\left(\\frac{B c_j}{B + C_{\\text{total}}}\\right)$$\n代入 $t$ 的公式：\n$$x_j = S \\left(\\frac{B + C_{\\text{total}}}{B \\, C_{\\text{total}}}\\right) \\left(\\frac{B c_j}{B + C_{\\text{total}}}\\right) = S \\frac{c_j}{C_{\\text{total}}} = S \\frac{c_j}{\\sum_{k=1}^W c_k}$$\n这表明总数据 $S$ 也应按各工作单元的 CPU 速率 $c_j$ 成比例进行划分。\n\n### 公式总结\n1.  **总 CPU 速率**：$C_{\\text{total}} = \\sum_{j=1}^{W} c_j$\n2.  **最优共同完成时间**：$t = S \\left(\\frac{1}{B} + \\frac{1}{C_{\\text{total}}}\\right)$\n3.  **最优数据块大小**：$x_j = S \\frac{c_j}{C_{\\text{total}}}$\n4.  **最优带宽份额**：$u_j = B \\frac{c_j}{C_{\\text{total}}}$\n\n这些公式将被用于解决给定的测试用例。",
            "answer": "完整且可运行的 Python 3 代码如下。\n导入的模块必须符合指定的执行环境。\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the optimal completion time, chunk sizes, and bandwidth shares\n    for a parallel processing problem.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1000, 400, [50, 100, 150]),     # Case 1\n        (800, 100000, [80, 40, 80]),    # Case 2\n        (600, 60, [500, 200, 100]),     # Case 3\n        (123, 500, [200]),              # Case 4\n        (100, 100, [1, 9]),             # Case 5\n    ]\n\n    all_results_str = []\n    \n    for S, B, c_j_list in test_cases:\n        # Convert inputs to numpy array for vectorized operations\n        c_j = np.array(c_j_list, dtype=float)\n        \n        # Calculate the total CPU rate\n        C_total = np.sum(c_j)\n\n        # Handle potential division by zero, though not expected from problem constraints.\n        if B == 0 or C_total == 0:\n            # This scenario corresponds to an infinite completion time.\n            # As the problem implies positive inputs, we proceed with calculation.\n            # A robust implementation might raise an error here.\n            continue\n\n        # Derived formula for the common completion time t\n        t = S * (1.0 / B + 1.0 / C_total)\n\n        # Derived formula for optimal chunk sizes x_j\n        x_j = S * (c_j / C_total)\n\n        # Derived formula for optimal bandwidth shares u_j\n        u_j = B * (c_j / C_total)\n\n        # Assemble the results for the current case in the specified order\n        case_result = [t] + x_j.tolist() + u_j.tolist()\n        \n        # Format each number to 6 decimal places and create the bracketed string\n        case_result_str = f\"[{','.join([f'{val:.6f}' for val in case_result])}]\"\n        all_results_str.append(case_result_str)\n\n    # Final print statement in the exact required format: a list of lists.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在理想场景的基础上，这个实践将探讨不确定性的影响，这是现实世界计算中的一个普遍特征，因为任务的持续时间通常是未知的。你将通过模拟实现并比较两种经典的负载均衡策略：静态分区和动态调度。这项练习将通过实证分析，让你对预分配的简单性与自适应、即时任务分配的鲁棒性之间的基本权衡有具体的认识 。",
            "id": "3155817",
            "problem": "您必须编写一个完整的、可运行的程序，该程序模拟并比较两种用于并行任务执行的负载均衡策略，同时控制工作实体数量、独立任务数量以及任务时长的方差。比较的对象是使用静态分区的分布式内存系统和使用动态调度的共享内存系统。程序必须是自包含的，不需要用户输入，并以单行形式生成指定的输出格式。\n\n使用的基本原理和定义：\n- 分布式内存系统将任务分配给不共享中心化状态的处理器；在静态分区中，每个处理器接收一个预先确定的任务子集。共享内存系统提供一个所有线程都可访问的全局状态；在动态调度中，一个中央队列每次向下一个可用的工作者提供一个任务。\n- 总工作量是所有任务时长的总和，记为 $W = \\sum_{i=1}^{n} t_i$，其中 $n$ 是任务数量，$t_i$ 是任务 $i$ 的时长。完工时间（makespan）是并行完成时间，记为 $T = \\max_{j \\in \\{1,\\dots,p\\}} L_j$，其中 $p$ 是处理器或线程的数量，$L_j$ 是工作者 $j$ 处理的总负载（包括任何开销）。负载均衡旨在最小化 $L_j$ 的方差，从而使 $T$ 接近 $W/p$。\n- 每个任务时长 $t_i$ 必须是严格非负的，并以秒为单位计量。任何用于调度或通信的开销也必须以秒为单位计量。任何涉及物理时间的答案都以秒为单位。\n\n模拟规范：\n- 任务是独立的，其时长 $t_i$ 从均值为 $\\mu$ 秒、标准差为 $\\sigma$ 秒的正态分布中抽取，并在 $0$ 处截断以确保非负性。为保证可复现性，每个测试用例使用一个固定的随机数生成器（RNG）种子。\n- 分布式内存静态分区：使用连续分配将 $n$ 个任务划分为 $p$ 个块。前 $r = n \\bmod p$ 个处理器接收 $b+1$ 个任务，其余 $p-r$ 个处理器接收 $b$ 个任务，其中 $b = \\left\\lfloor \\frac{n}{p} \\right\\rfloor$。处理器 $j$ 上的负载为 $L^{\\text{dist}}_j = \\sum t_i + o_{\\text{dist}} \\cdot m_j$，其中 $m_j$ 是分配给处理器 $j$ 的任务数量，$o_{\\text{dist}}$ 是分布式内存的每任务开销（以秒为单位）（例如，通信或分派成本）。\n- 共享内存动态调度：维护一个包含 $n$ 个任务的中央队列。$p$ 个工作者中的每一个在空闲时会重复地拉取下一个可用任务。工作者的完成时间因其处理的每个任务而增加 $t_i + o_{\\text{sh}}$，其中 $o_{\\text{sh}}$ 是共享内存的每任务开销（以秒为单位）（例如，竞争或调度器成本）。完工时间是所有工作者中的最大完成时间。\n\n您的程序必须实现这两种策略并计算它们的完工时间：\n- 分布式静态分区的 $T_{\\text{dist}} = \\max_j L^{\\text{dist}}_j$。\n- 根据上述事件驱动分配得出的共享动态调度的 $T_{\\text{sh}}$。\n\n要求输出：\n- 对于每个测试用例，计算比率 $R = \\frac{T_{\\text{dist}}}{T_{\\text{sh}}}$。该比率是无量纲（无单位）的。较大的 $R$ 值表示在该情况下，共享内存动态调度相对于分布式静态分区速度更快。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[r_1,r_2,r_3]$），其中每个 $r_k$ 是第 $k$ 个测试用例的浮点数比率。\n\n测试套件：\n使用以下参数集。所有与时间相关的量都必须以秒为单位处理。必须严格按照规定应用 RNG 种子，以确保结果的确定性。\n- 用例 1（理想路径，低方差）：$p=4$, $n=100$, $\\mu=1.0$ 秒, $\\sigma=0.1$ 秒, $o_{\\text{sh}}=0.0005$ 秒, $o_{\\text{dist}}=0.005$ 秒, 种子 $=42$。\n- 用例 2（高方差）：$p=8$, $n=1000$, $\\mu=0.5$ 秒, $\\sigma=0.6$ 秒, $o_{\\text{sh}}=0.0002$ 秒, $o_{\\text{dist}}=0.01$ 秒, 种子 $=123$。\n- 用例 3（边界情况：$p \\gg n$）：$p=32$, $n=40$, $\\mu=1.0$ 秒, $\\sigma=0.5$ 秒, $o_{\\text{sh}}=0.0002$ 秒, $o_{\\text{dist}}=0.005$ 秒, 种子 $=98765$。\n- 用例 4（中等方差，不同开销）：$p=16$, $n=1000$, $\\mu=0.2$ 秒, $\\sigma=0.2$ 秒, $o_{\\text{sh}}=0.0001$ 秒, $o_{\\text{dist}}=0.002$ 秒, 种子 $=2023$。\n- 用例 5（边缘情况：零方差）：$p=10$, $n=100$, $\\mu=1.0$ 秒, $\\sigma=0.0$ 秒, $o_{\\text{sh}}=0.0003$ 秒, $o_{\\text{dist}}=0.0003$ 秒, 种子 $=7$。\n\n程序约束：\n- 使用任何现代编程语言逻辑实现模拟，但最终提交必须是最终答案部分指定的 Python 代码。\n- 不要读取输入。将测试用例按列表硬编码。\n- 使用所描述的精确输出格式：单行输出，包含五个按顺序排列的用例的浮点数比率列表，用方括号括起来并以逗号分隔。",
            "solution": "该问题要求对并行计算中两种基本的负载均衡策略进行比较分析：用于分布式内存系统的静态分区和用于共享内存系统的动态调度。目标是在各种条件下模拟这两种策略，并使用它们的完工时间（makespan）之比来量化其相对性能。完工时间是指从计算开始到最后一个任务完成所经过的总时间。\n\n此模拟的基础是生成一个工作负载，该负载由一组 $n$ 个独立任务组成。每个任务 $i \\in \\{1, \\dots, n\\}$ 的时长 $t_i$ 是一个随机变量。根据规定，任务时长从具有给定均值 $\\mu$ 和标准差 $\\sigma$ 的正态分布中抽取。由于时间不能为负，任何小于 $0$ 的采样值都将被截断为 $0$。这在数学上表示为 $t_i = \\max(0, X_i)$，其中每个 $X_i$ 是来自 $N(\\mu, \\sigma^2)$ 分布的独立样本。为确保模拟是可复现的，每个测试用例的随机数生成器都使用一个固定的种子进行初始化。\n\n第一种策略是静态分区，这是分布式内存环境的典型特征，该环境中处理器间通信成本高昂，因此倾向于在计算前预先分配工作。$n$ 个任务通过连续块分配的方式被划分给 $p$ 个处理器。每个处理器的任务数量被尽可能地均衡分配：设 $b = \\lfloor n/p \\rfloor$ 为基本任务数，$r = n \\bmod p$ 为余数。前 $r$ 个处理器各自分配 $m_j = b+1$ 个任务，随后的 $p-r$ 个处理器各自分配 $m_j = b$ 个任务。处理器 $j$ 的总负载，记为 $L^{\\text{dist}}_j$，是其分配到的任务时长总和加上一个总开销成本。该开销被建模为分配给该处理器的每个任务都有一个恒定的成本 $o_{\\text{dist}}$。因此，负载计算为 $L^{\\text{dist}}_j = \\left(\\sum_{i \\in \\text{Tasks}_j} t_i\\right) + m_j \\cdot o_{\\text{dist}}$。由于在此模型中所有处理器同时开始工作，总完工时间 $T_{\\text{dist}}$ 由完成其工作耗时最长的处理器决定：$T_{\\text{dist}} = \\max_{j \\in \\{1, \\dots, p\\}} L^{\\text{dist}}_j$。\n\n第二种策略是通过中央队列进行动态调度，这在共享内存环境中很典型，线程可以高效地访问一个公共的工作池。此过程被建模为事件驱动模拟。我们有 $p$ 个工作者，在时间 $t=0$ 时都初始为空闲状态。$n$ 个任务被放置在一个概念上的队列中。每当一个工作者变为空闲，它就从队列头部获取下一个可用的任务。为了实现这一点，我们可以维护 $p$ 个工作者中每一个的完成时间。最小优先队列是实现此目的的高效数据结构，因为它能快速检索到将最早可用的工作者。\n模拟过程如下：\n$1$. 初始化一个包含 $p$ 个条目的最小优先队列，每个条目的值都为 $0$，代表每个工作者的初始可用时间。\n$2$. 对于 $n$ 个任务中的每一个任务（时长为 $t_i$）：\n    a. 从优先队列中提取最小时间 $t_{\\text{free}}$。这代表了任何工作者变为空闲的最早时间。\n    b. 将任务 $t_i$ 分配给该工作者。该工作者现在将被占用，直到一个新的完成时间，该时间计算为 $t_{\\text{new}} = t_{\\text{free}} + t_i + o_{\\text{sh}}$，其中 $o_{\\text{sh}}$ 是访问共享队列的每任务开销。\n    c. 将这个新的完成时间 $t_{\\text{new}}$ 插回优先队列。\n$3$. 在所有 $n$ 个任务都通过此过程分配完毕后，优先队列中的值代表了每个工作者处理的所有任务的最终完成时间。动态调度策略的完工时间 $T_{\\text{sh}}$ 是优先队列中的最大值，因为它对应于整个任务集中最后一个任务完成的时间：$T_{\\text{sh}} = \\max(\\text{final worker finish times})$。\n\n最后，为了比较这两种策略的有效性，我们计算无量纲比率 $R = \\frac{T_{\\text{dist}}}{T_{\\text{sh}}}$。比率 $R > 1$ 表示动态调度比静态分区更快（即完工时间更短），这表明其适应任务时长变化的能力超过了其开销。相反，比率 $R < 1$ 则表明静态分区更高效，这种情况可能在任务时长均匀且分布式开销 $o_{\\text{dist}}$ 小于共享开销 $o_{\\text{sh}}$ 时发生。比率 $R \\approx 1$ 意味着性能相当。该比率是每个测试用例的最终输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Simulates and compares distributed static partitioning and shared dynamic scheduling\n    for parallel task execution across a suite of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (p, n, mu, sigma, o_sh, o_dist, seed)\n    test_cases = [\n        (4, 100, 1.0, 0.1, 0.0005, 0.005, 42),\n        (8, 1000, 0.5, 0.6, 0.0002, 0.01, 123),\n        (32, 40, 1.0, 0.5, 0.0002, 0.005, 98765),\n        (16, 1000, 0.2, 0.2, 0.0001, 0.002, 2023),\n        (10, 100, 1.0, 0.0, 0.0003, 0.0003, 7)\n    ]\n\n    results = []\n    for p, n, mu, sigma, o_sh, o_dist, seed in test_cases:\n        # Step 1: Generate task durations using a seeded RNG\n        # for reproducibility.\n        rng = np.random.default_rng(seed)\n        tasks = rng.normal(loc=mu, scale=sigma, size=n)\n        # Enforce non-negativity by truncating at 0.\n        tasks = np.maximum(0, tasks)\n\n        # Step 2: Simulate distributed memory static partitioning.\n        T_dist = 0.0\n        if p > 0 and n > 0:\n            b = n // p  # Base number of tasks per processor\n            r = n % p   # Remainder, for processors getting an extra task\n            \n            processor_loads_dist = np.zeros(p)\n            task_idx = 0\n            for j in range(p):\n                num_tasks_for_proc = b + 1 if j < r else b\n                if num_tasks_for_proc > 0:\n                    end_idx = task_idx + num_tasks_for_proc\n                    assigned_tasks = tasks[task_idx:end_idx]\n                    work_duration = np.sum(assigned_tasks)\n                    overhead = num_tasks_for_proc * o_dist\n                    processor_loads_dist[j] = work_duration + overhead\n                    task_idx = end_idx\n            \n            T_dist = np.max(processor_loads_dist)\n\n        # Step 3: Simulate shared memory dynamic scheduling.\n        T_sh = 0.0\n        if p > 0 and n > 0:\n            # A min-heap tracks the time each worker becomes free.\n            worker_finish_times = [0.0] * p\n            heapq.heapify(worker_finish_times)\n            \n            for task_duration in tasks:\n                # Get the worker that finishes earliest.\n                earliest_finish_time = heapq.heappop(worker_finish_times)\n                \n                # Assign the current task to this worker and update its finish time.\n                new_finish_time = earliest_finish_time + task_duration + o_sh\n                heapq.heappush(worker_finish_times, new_finish_time)\n            \n            # The makespan is the time the last worker finishes.\n            T_sh = max(worker_finish_times)\n\n        # Step 4: Compute the ratio.\n        ratio = 0.0\n        if T_sh > 0:\n            ratio = T_dist / T_sh\n        elif T_dist > 0:\n            # This case (T_sh=0, T_dist>0) is unlikely but handle for robustness.\n            ratio = float('inf')\n        else:\n            # If both are 0 (e.g., n=0), their performance is identical.\n            ratio = 1.0\n\n        results.append(ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们最后的实践将处理一个更复杂的系统：一个多阶段处理流水线，这在图像处理和数据流等领域很常见。这里的目标是通过识别最慢的阶段——即瓶颈——并通过融合阶段和重新分配工作单元来重组流水线，以优化吞吐量。这个问题要求你应用启发式优化技术，并通过模拟来验证你的设计，展示在复杂工作流中进行性能工程的实用方法 。",
            "id": "3155812",
            "problem": "一个图像处理流水线由 $J$ 个串行阶段组成。每个阶段 $j \\in \\{1,\\dots,J\\}$ 都有一个确定的处理成本 $s_j$，单位为秒/图像。一个阶段可以有 $w_j$ 个相同的处理器（例如，处理器线程），每个处理器一次处理一张图像。图像按顺序流经流水线，一张图像必须在完成阶段1后才能进入阶段2，以此类推。该系统是封闭的：没有外部到达，处理的是一个固定大小为 $M$ 的图像批次。允许对流水线进行两种类型的修改：重排阶段顺序，以及将相邻阶段融合成复合阶段。融合会创建一个复合阶段，其处理成本是被融合阶段成本之和，其处理器数量是被融合阶段分配的处理器数量之和。所有阶段可用的处理器总数是一个固定的整数 $N_{\\text{total}}$。基线策略为每个阶段精确分配一个处理器，并且不使用超出 $J$ 的任何剩余处理器（也就是说，如果 $N_{\\text{total}} > J$，那么多出的 $N_{\\text{total}} - J$ 个处理器在基线中是未使用的）。\n\n从串行系统中速率、流量守恒和瓶颈的基本定义出发，推导出一个基于原理的方法来：\n- 在基线策略下，预测基线流水线配置的稳态吞吐率（单位：图像/秒），作为 $\\{s_j\\}$ 和 $\\{w_j\\}$ 的函数。\n- 构建一个优化后的流水线，可以使用您选择的任何重排和融合方式，但融合后必须恰好有 $K$ 个复合阶段，并将 $N_{\\text{total}}$ 个处理器分配给这 $K$ 个复合阶段，以在整数处理器约束下最接近地均衡各个阶段的服务速率。您的优化必须能从第一性原理进行解释，并且不得假设任何未从所述基础推导出的公式。\n- 预测优化后流水线的稳态吞吐率（单位：图像/秒）。\n- 通过模拟 $M$ 张图像通过具有确定性服务时间和有限阶段处理器池的流水线的过程，来凭经验验证这两个预测。将经验吞吐率计算为 $M$ 除以批处理的总完成时间（以图像/秒表示）。时间单位使用秒，吞吐率单位使用图像/秒。\n\n设计您的程序以实现以下具体的测试套件。在每种情况下，优化必须产生恰好 $K$ 个复合阶段，并将所有 $N_{\\text{total}}$ 个处理器分配给这 $K$ 个复合阶段。为进行经验验证，精确模拟 $M$ 张图像：\n- 测试 1：$J=4$， $s=[1.0,1.0,1.0,1.0]$ 秒， $N_{\\text{total}}=4$， $K=2$， $M=400$。\n- 测试 2：$J=4$， $s=[5.0,1.0,1.0,1.0]$ 秒， $N_{\\text{total}}=4$， $K=2$， $M=400$。\n- 测试 3：$J=1$， $s=[5.0]$ 秒， $N_{\\text{total}}=3$， $K=1$， $M=600$。\n- 测试 4：$J=5$， $s=[8.0,2.0,2.0,2.0,2.0]$ 秒， $N_{\\text{total}}=6$， $K=3$， $M=600$。\n\n您的程序必须：\n- 对于每个测试用例，计算预测的基线吞吐率（图像/秒）、预测的优化后吞吐率（图像/秒）、经验测量的基线吞吐率（图像/秒）、经验测量的优化后吞吐率（图像/秒）、预测的改进因子（定义为优化后的预测吞吐率除以基线预测吞吐率，无量纲），以及经验测量的改进因子（定义为优化后的经验吞吐率除以基线经验吞吐率，无量纲）。\n- 所有吞吐率以图像/秒表示，所有改进因子以小数表示（不带百分号），每个报告值四舍五入到恰好 $6$ 位小数。\n\n最终输出格式要求：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须按测试1到4的顺序，包含每个测试的6个值：基线预测吞吐率、优化后预测吞吐率、基线经验吞吐率、优化后经验吞吐率、预测改进因子、经验改进因子。具体而言，输出格式应为 $\\left[\\text{T}_{1,\\text{base,pred}},\\text{T}_{1,\\text{opt,pred}},\\text{T}_{1,\\text{base,emp}},\\text{T}_{1,\\text{opt,emp}},\\text{I}_{1,\\text{pred}},\\text{I}_{1,\\text{emp}},\\dots,\\text{T}_{4,\\text{base,pred}},\\text{T}_{4,\\text{opt,pred}},\\text{T}_{4,\\text{base,emp}},\\text{T}_{4,\\text{opt,emp}},\\text{I}_{4,\\text{pred}},\\text{I}_{4,\\text{emp}}\\right]$，每个值四舍五入到 $6$ 位小数。",
            "solution": "该问题要求对串行图像处理流水线进行分析和优化。解决方案将首先建立控制此类系统吞吐率的基本原则。基于这些原则，我们将推导出预测基线和优化后流水线配置性能的方法。最后，我们将描述一种用于验证这些预测的经验模拟方法。\n\n**1. 基本原则与吞吐率预测**\n\n处理流水线是一个由顺序阶段组成的系统。此类系统的整体性能由每个阶段处理其任务的速率决定。\n\n设阶段 $j \\in \\{1, \\dots, J\\}$ 的确定性处理成本为 $s_j$ 秒/图像。这表示在该阶段处理单个图像的服务时间。因此，阶段 $j$ 单个处理器的内在速率是 $1/s_j$ 图像/秒。如果阶段 $j$ 分配了 $w_j$ 个相同的并行处理器，其总服务容量或服务速率 $\\mu_j$ 是单个处理器速率之和，前提是假设总有可供处理的图像。\n$$\n\\mu_j = \\frac{w_j}{s_j} \\quad \\text{(图像/秒)}\n$$\n在一个以稳态运行的串行流水线中，流量守恒原则规定，长期平均吞吐率（我们称之为 $T$）必须在每个阶段都相同。此外，任何给定阶段的吞吐率不能超过其服务速率，因此对于所有 $j \\in \\{1, \\dots, J\\}$，都有 $T \\leq \\mu_j$。\n\n这意味着整个系统的吞吐率受限于服务速率最低的阶段。这个阶段被称为瓶颈。因此，整个流水线的稳态吞吐率是其所有组成阶段服务速率的最小值：\n$$\nT = \\min_{j \\in \\{1, \\dots, J\\}} \\{\\mu_j\\} = \\min_{j \\in \\{1, \\dots, J\\}} \\left\\{ \\frac{w_j}{s_j} \\right\\}\n$$\n\n**2. 基线流水线分析**\n\n问题定义了一个基线策略，即为 $J$ 个阶段中的每一个都精确分配一个处理器，即对所有 $j$ 都有 $w_j = 1$。来自总池 $N_{\\text{total}}$ 的任何多余处理器都未使用。\n\n将推导出的吞吐率公式应用于基线情况，我们得到：\n$$\nT_{\\text{base,pred}} = \\min_{j \\in \\{1, \\dots, J\\}} \\left\\{ \\frac{1}{s_j} \\right\\}\n$$\n这可以重写为：\n$$\nT_{\\text{base,pred}} = \\frac{1}{\\max_{j \\in \\{1, \\dots, J\\}} \\{s_j\\}}\n$$\n这个结果是直观的：具有单个处理器的流水线的吞吐率受限于任何单个阶段最长处理时间的倒数。\n\n**3. 优化流水线设计与分析**\n\n优化任务包括重排原始阶段并将其融合成恰好 $K$ 个复合阶段，然后将 $N_{\\text{total}}$ 个处理器分配给这些新阶段以最大化吞吐率。\n\n设 $K$ 个复合阶段由 $k \\in \\{1, \\dots, K\\}$ 索引。设 $S_k$ 是融合成复合阶段 $k$ 的原始阶段处理成本之和，设 $W_k$ 是分配给它的整数处理器数量。处理器总数守恒：$\\sum_{k=1}^K W_k = N_{\\text{total}}$。优化后流水线的吞吐率为 $T_{\\text{opt}} = \\min_k \\{W_k / S_k\\}$。\n\n为了最大化此吞吐率，我们必须解决最大-最小化问题：$\\max \\left( \\min_k \\{W_k / S_k\\} \\right)$。当所有复合阶段的服务速率相等时，即 $W_1/S_1 = W_2/S_2 = \\dots = W_K/S_K$ 时，该目标函数达到最大值。\n\n这代表了一个关于阶段划分和处理器整数分配的复杂联合优化问题。一个稳健的启发式方法包括两个连续的步骤：\n\n**步骤 3.1：阶段融合（划分）**\n首先，我们将原始阶段成本集合 $\\{s_j\\}_{j=1}^J$ 划分为 $K$ 个子集。此步骤的目标是创建总成本 $\\{S_k\\}_{k=1}^K$ 尽可能均衡的复合阶段。这为后续的处理器分配提供了良好的基础。一个贪心算法对此很有效：将原始成本 $s_j$ 按降序排序。然后，迭代地将排序列表中的下一个成本添加到当前总和最小的分区中。这种启发式方法倾向于产生均衡的分区。问题陈述允许重排，因此这对应于形成任意的融合，而不仅仅是相邻的融合。\n\n**步骤 3.2：处理器分配**\n给定复合成本 $S_k$，我们必须找到一个总和为 $N_{\\text{total}}$ 的整数分配 $\\{W_k\\}$，以最大化 $\\min_k \\{W_k / S_k\\}$。理想的非整数分配将是 $W_k^{\\text{ideal}} \\propto S_k$。为了找到最佳整数解，我们使用一个直接针对瓶颈的贪心迭代算法：\n1. 为 $K$ 个复合阶段中的每一个初始化一个处理器，即对所有 $k$ 都有 $W_k=1$。这使用了 $K$ 个处理器。\n2. 剩下的 $N_{\\text{rem}} = N_{\\text{total}} - K$ 个处理器被逐一分配。\n3. 在 $N_{\\text{rem}}$ 次迭代的每一次中，识别当前的瓶颈阶段 $k^*$，即速率 $W_k/S_k$ 最小的阶段。如果出现平局，则选择成本 $S_k$ 较大的阶段作为瓶颈。\n4. 为这个瓶颈阶段增加一个处理器：$W_{k^*} \\leftarrow W_{k^*} + 1$。\n5. 重复此过程，直到所有处理器都被分配完毕。\n\n这个过程逐步提高了最低的阶段速率，直接解决了最大-最小化目标。由此产生的优化后流水线的预测吞吐率为：\n$$\nT_{\\text{opt,pred}} = \\min_{k \\in \\{1, \\dots, K\\}} \\left\\{ \\frac{W_k}{S_k} \\right\\}\n$$\n其中 $\\{S_k\\}$ 和 $\\{W_k\\}$ 是优化过程的结果。\n\n**4. 通过模拟进行经验验证**\n\n稳态吞吐率的理论预测忽略了处理有限批次 $M$ 张图像时的瞬态启动和结束效应。为了获得经验测量值，我们模拟流水线的运行。\n\n可以使用从排队论推导出的递推关系来高效地建模仿真。设 $C_{i,j}$ 为图像 $i$（$i \\in \\{0, \\dots, M-1\\}$）在阶段 $j$（$j \\in \\{0, \\dots, J-1\\}$）的完成时间。一张图像只有在满足两个条件后才能在阶段 $j$ 开始处理：\n1. 图像本身已到达阶段 $j$，这发生在其完成阶段 $j-1$ 时。这个时间是 $C_{i, j-1}$。\n2. 阶段 $j$ 的一个处理器可用。在有 $w_j$ 个处理器且图像按顺序处理的情况下，用于图像 $i$ 的处理器将不早于图像 $i-w_j$ 完成阶段 $j$ 的时间空闲。这个时间是 $C_{i-w_j, j}$。\n\n图像 $i$ 在阶段 $j$ 的开始时间是这两个时间的最大值。完成时间是开始时间加上服务时间 $s_j$。这给出了递推关系：\n$$\nC_{i,j} = \\max(C_{i, j-1}, C_{i-w_j, j}) + s_j\n$$\n边界条件是 $C_{i, -1} = 0$（图像在时间0时可用于第一阶段）和对于 $k  0$ 有 $C_{k, j} = 0$。仿真是通过计算所有图像和阶段的矩阵 $C_{i,j}$ 来进行的。\n\n处理这批 $M$ 张图像的总时间是最后一张图像完成最后一个阶段的时间，即 $C_{M-1, J-1}$（使用0-基索引）。那么经验吞吐率是：\n$$\nT_{\\text{emp}} = \\frac{M}{C_{M-1, J-1}}\n$$\n对基线和优化后的流水线配置都执行此模拟。\n\n**5. 改进因子**\n\n优化的改进效果通过优化后吞吐率与基线吞吐率的比率来量化。\n- 预测改进因子：$I_{\\text{pred}} = T_{\\text{opt,pred}} / T_{\\text{base,pred}}$\n- 经验改进因子：$I_{\\text{emp}} = T_{\\text{opt,emp}} / T_{\\text{base,emp}}$\n这些因子是无量纲的。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef get_predicted_throughput(s_list: list[float], w_list: list[int]) - float:\n    \"\"\"Calculates the predicted steady-state throughput of a pipeline.\"\"\"\n    if not s_list:\n        return np.inf\n    \n    min_rate = np.inf\n    for s, w in zip(s_list, w_list):\n        if s  0:\n            rate = w / s\n            if rate  min_rate:\n                min_rate = rate\n        else: # A stage with zero cost has infinite throughput\n            pass\n    return min_rate\n\ndef run_simulation(s_list: list[float], w_list: list[int], M: int) - float:\n    \"\"\"Simulates the pipeline to find the empirical throughput for M images.\"\"\"\n    num_stages = len(s_list)\n    if num_stages == 0:\n        return np.inf\n    if M == 0:\n        return 0.0\n\n    # completion_times[i, j] is the time image i completes stage j\n    completion_times = np.zeros((M, num_stages))\n\n    for j in range(num_stages):\n        s = s_list[j]\n        w = w_list[j]\n        if w == 0: # If a stage has no workers, no image can pass\n            return 0.0\n        for i in range(M):\n            # Time image i is available for stage j (finished previous stage)\n            arrival_time_at_stage_j = completion_times[i, j - 1] if j  0 else 0.0\n            \n            # Time a worker for image i becomes available.\n            # This is determined by when the (i-w)-th image finished *this* stage.\n            contention_finish_time = completion_times[i - w, j] if i = w else 0.0\n            \n            start_time = max(arrival_time_at_stage_j, contention_finish_time)\n            completion_times[i, j] = start_time + s\n            \n    total_time = completion_times[M - 1, num_stages - 1]\n    \n    if total_time == 0:\n        return np.inf\n        \n    return M / total_time\n\ndef optimize_pipeline(s: list[float], N_total: int, K: int) - tuple[list[float], list[int]]:\n    \"\"\"\n    Constructs an optimized pipeline by partitioning stages and allocating workers.\n    Returns the composite stage costs (S_opt) and worker allocations (W_opt).\n    \"\"\"\n    # 1. Partition original stages into K composite stages using a greedy algorithm\n    # to make partition sums as equal as possible.\n    if K == 0:\n        return [], []\n    \n    s_sorted_indices = np.argsort(s)[::-1]\n    s_sorted = [s[i] for i in s_sorted_indices]\n    \n    partition_sums = [0.0] * K\n    \n    for cost in s_sorted:\n        min_sum_idx = np.argmin(partition_sums)\n        partition_sums[min_sum_idx] += cost\n        \n    S_opt = partition_sums\n    \n    # 2. Allocate N_total workers to the K composite stages using a greedy iterative\n    # approach that adds workers to the current bottleneck.\n    if K  N_total:\n        # Fallback for an unlikely scenario: not enough workers for 1 per stage.\n        W_opt = [0] * K\n        for i in range(N_total):\n            W_opt[i] += 1\n        return S_opt, W_opt\n\n    W_opt = [1] * K\n    workers_to_distribute = N_total - K\n    \n    for _ in range(workers_to_distribute):\n        current_rates = [(w / s if s  0 else np.inf) for w, s in zip(W_opt, S_opt)]\n        \n        # Find the bottleneck stage (minimum rate), with tie-breaking.\n        min_rate = np.inf\n        bottleneck_idx = -1\n        \n        potential_bottlenecks = []\n        for i in range(K):\n            if current_rates[i]  min_rate:\n                min_rate = current_rates[i]\n                potential_bottlenecks = [i]\n            elif current_rates[i] == min_rate:\n                potential_bottlenecks.append(i)\n\n        if len(potential_bottlenecks) == 1:\n            bottleneck_idx = potential_bottlenecks[0]\n        else:\n            # Tie-break by choosing the stage with the largest cost S_k\n            max_s_val = -1.0\n            for idx in potential_bottlenecks:\n                if S_opt[idx]  max_s_val:\n                    max_s_val = S_opt[idx]\n                    bottleneck_idx = idx\n\n        if bottleneck_idx != -1:\n            W_opt[bottleneck_idx] += 1\n        else: # Should not happen if K > 0\n            W_opt[0] += 1\n            \n    return S_opt, W_opt\n\ndef run_analysis(J, s, N_total, K, M):\n    \"\"\"Performs the full analysis for a single test case.\"\"\"\n    # Baseline calculations\n    s_base = list(s)\n    w_base = [1] * J\n    T_base_pred = get_predicted_throughput(s_base, w_base)\n    T_base_emp = run_simulation(s_base, w_base, M)\n\n    # Optimized calculations\n    S_opt, W_opt = optimize_pipeline(s, N_total, K)\n    T_opt_pred = get_predicted_throughput(S_opt, W_opt)\n    T_opt_emp = run_simulation(S_opt, W_opt, M)\n    \n    # Improvement factors\n    I_pred = T_opt_pred / T_base_pred if T_base_pred  0 else 0.0\n    I_emp = T_opt_emp / T_base_emp if T_base_emp  0 else 0.0\n    \n    return [T_base_pred, T_opt_pred, T_base_emp, T_opt_emp, I_pred, I_emp]\n\ndef solve():\n    \"\"\"Defines test cases and prints the final formatted result string.\"\"\"\n    test_cases = [\n        # J, s, N_total, K, M\n        (4, [1.0, 1.0, 1.0, 1.0], 4, 2, 400),\n        (4, [5.0, 1.0, 1.0, 1.0], 4, 2, 400),\n        (1, [5.0], 3, 1, 600),\n        (5, [8.0, 2.0, 2.0, 2.0, 2.0], 6, 3, 600)\n    ]\n\n    all_results = []\n    for J, s, N_total, K, M in test_cases:\n        case_results = run_analysis(J, s, N_total, K, M)\n        all_results.extend(case_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{val:.6f}' for val in all_results])}]\")\n\nsolve()\n```"
        }
    ]
}