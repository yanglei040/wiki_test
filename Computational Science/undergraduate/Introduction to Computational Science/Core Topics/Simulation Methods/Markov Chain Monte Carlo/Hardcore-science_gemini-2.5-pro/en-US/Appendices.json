{
    "hands_on_practices": [
        {
            "introduction": "The heart of any Metropolis-Hastings algorithm is its acceptance-rejection step, which intelligently guides the sampler toward regions of high probability. This exercise provides a focused check on this core mechanism, stripping away the complexity of a full simulation to test your understanding of how a single move is evaluated . By calculating the acceptance probability for a specific proposed move, you will directly engage with the logic that allows MCMC to explore and ultimately map out a target distribution.",
            "id": "1371728",
            "problem": "A data scientist is implementing a Markov Chain Monte Carlo (MCMC) simulation to draw samples from a posterior probability distribution for a parameter $x$. The target distribution, $\\pi(x)$, is proportional to the exponential of the negative absolute value of the parameter, such that $\\pi(x) \\propto \\exp(-|x|)$.\n\nThe scientist uses the Metropolis algorithm with a symmetric proposal distribution $q(x'|x)$, where the probability of proposing a new state $x'$ given the current state $x$ is equal to the probability of proposing $x$ given $x'$ (i.e., $q(x'|x) = q(x|x')$).\n\nSuppose that at a certain step in the simulation, the current state of the chain is $x = 1.5$. The algorithm then proposes a move to a new candidate state $x' = 2.0$.\n\nCalculate the acceptance probability for this specific move. Your answer should be a dimensionless real number. Round your final answer to four significant figures.",
            "solution": "The Metropolis acceptance probability for a move from $x$ to $x'$ with a symmetric proposal $q(x'|x)=q(x|x')$ is\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\nGiven the target distribution $\\pi(x)\\propto \\exp(-|x|)$, the ratio simplifies to\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\nWith $x=1.5$ and $x'=2.0$, we have $|x|=1.5$ and $|x'|=2.0$, so\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\nTherefore,\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\nNumerically, $\\exp(-0.5)\\approx 0.6065$ when rounded to four significant figures.",
            "answer": "$$\\boxed{0.6065}$$"
        },
        {
            "introduction": "Beyond their use in Bayesian statistics, MCMC methods offer a versatile framework for tackling complex optimization problems. This hands-on practice challenges you to apply the Metropolis-Hastings algorithm to find the \"maximum cut\" of a graph, a classic problem in computer science and operations research . By framing the size of the cut as a target distribution, you will implement a sampler that navigates a vast, discrete state space to discover near-optimal solutions, demonstrating the power of MCMC as a general-purpose heuristic search algorithm.",
            "id": "3250464",
            "problem": "You are asked to implement the Metropolis–Hastings algorithm for a discrete state space to approximately solve the maximum cut problem on small undirected graphs. The state space is a set of binary assignments representing a bipartition. Start from the fundamental base that a Markov chain is a stochastic process over a countable state space with a transition kernel, and a desired stationary distribution is achieved by enforcing detailed balance. The Metropolis–Hastings construction ensures detailed balance with respect to a target distribution through an acceptance–rejection step.\n\nConsider an undirected, simple graph with vertex set $V=\\{0,1,\\dots,n-1\\}$ and edge set $E\\subseteq V\\times V$ without self-loops or duplicate edges. A cut is induced by a binary assignment $s\\in\\{-1,+1\\}^n$ where $s_i=+1$ means vertex $i$ is in one side and $s_i=-1$ means it is in the other side. The cut size $C(s)$ is the number of edges crossing the cut, given by\n$$\nC(s)=\\sum_{(i,j)\\in E}\\frac{1-s_i s_j}{2}.\n$$\nDefine a target distribution over states $s$ proportional to the exponential of the cut size,\n$$\n\\pi(s)\\propto \\exp\\left(\\lambda\\, C(s)\\right),\n$$\nwhere $\\lambda>0$ is an inverse-temperature parameter that concentrates mass on larger cuts.\n\nAt each step, propose a new state $s'$ from $s$ by selecting a vertex $i$ uniformly at random and flipping its assignment, i.e., $s'_i=-s_i$ and $s'_k=s_k$ for all $k\\neq i$. Let $q(s\\to s')$ denote this proposal probability. Because selecting a single vertex uniformly and flipping it is symmetric, we have $q(s\\to s')=q(s'\\to s)$. Use the Metropolis–Hastings acceptance probability\n$$\n\\alpha(s\\to s')=\\min\\left(1,\\frac{\\pi(s')\\,q(s'\\to s)}{\\pi(s)\\,q(s\\to s')}\\right),\n$$\nwhich in this symmetric case reduces to\n$$\n\\alpha(s\\to s')=\\min\\left(1,\\exp\\left(\\lambda\\,[C(s')-C(s)]\\right)\\right).\n$$\nNote that the change in cut size under a single-vertex flip can be computed locally. If $N(i)$ denotes the neighbor set of vertex $i$, then the change is\n$$\n\\Delta C=C(s')-C(s)=\\sum_{j\\in N(i)} s_i s_j.\n$$\nWith this, implement a Markov chain Monte Carlo (MCMC) method that starts from the all-$+1$ state, runs for a prescribed number of steps, and tracks the best cut size encountered (the maximum of $C(s)$ over the trajectory). The random number generator must be seeded per test case to ensure reproducibility. Use the following test suite, keeping all indices $0$-based:\n\n- Test case $1$ (triangle graph):\n  - $n=3$\n  - $E=\\{(0,1),(1,2),(0,2)\\}$\n  - number of steps $T=20000$\n  - inverse temperature $\\lambda=2.0$\n  - seed $s=7$\n- Test case $2$ (cycle of length $4$):\n  - $n=4$\n  - $E=\\{(0,1),(1,2),(2,3),(3,0)\\}$\n  - number of steps $T=30000$\n  - inverse temperature $\\lambda=2.0$\n  - seed $s=11$\n- Test case $3$ (empty graph):\n  - $n=4$\n  - $E=\\emptyset$\n  - number of steps $T=1000$\n  - inverse temperature $\\lambda=2.0$\n  - seed $s=5$\n- Test case $4$ (two disjoint edges):\n  - $n=4$\n  - $E=\\{(0,1),(2,3)\\}$\n  - number of steps $T=20000$\n  - inverse temperature $\\lambda=2.0$\n  - seed $s=13$\n\nYour program must implement the described Metropolis–Hastings algorithm on this discrete state space, compute the best cut size encountered during the Markov chain for each test case, and return the list of best cut sizes as integers. The final output format must be a single line containing the results as a comma-separated list enclosed in square brackets, for example, $[x_1,x_2,x_3,x_4]$, where each $x_k$ is the best cut size found for test case $k$.",
            "solution": "The problem statement has been validated and is deemed sound. It describes a well-posed application of the Metropolis-Hastings algorithm, a standard Markov chain Monte Carlo (MCMC) method, to the combinatorial optimization problem of finding the maximum cut in a graph. All components, including the state space, target distribution, proposal mechanism, and acceptance probability, are defined with scientific and mathematical correctness.\n\nThe objective is to implement this MCMC simulation to find an approximate maximum cut for several given graphs. The simulation starts from a deterministic state and evolves according to stochastic rules designed to favor states corresponding to larger cuts.\n\nThe core of the implementation is a function that executes the Metropolis-Hastings algorithm for a given graph and set of parameters. The process can be broken down into the following steps:\n\n1.  **Initialization**:\n    -   For a graph with $n$ vertices, the state of the system is represented by a vector $s \\in \\{-1, +1\\}^n$.\n    -   The simulation begins with the initial state $s = (+1, +1, \\dots, +1)$, where all vertices are in the same partition.\n    -   The initial cut size, $C(s) = \\sum_{(i,j)\\in E}\\frac{1-s_i s_j}{2}$, is calculated. For the all-$+1$ state, $s_i s_j = 1$ for all $i, j$, so the initial cut size is $C(s) = 0$.\n    -   A variable, `max_cut_size`, is initialized to this starting value (0) to track the largest cut size encountered during the simulation.\n    -   The graph structure is stored in an adjacency list for efficient retrieval of neighbors for any vertex $i$, denoted $N(i)$.\n    -   A pseudo-random number generator is seeded to ensure reproducibility for each test case.\n\n2.  **MCMC Simulation Loop**: The simulation proceeds for a specified number of steps, $T$. In each step, a new candidate state is proposed and then accepted or rejected.\n    -   **Proposal**: A new state $s'$ is proposed from the current state $s$. A vertex $i$ is chosen uniformly at random from $V = \\{0, 1, \\dots, n-1\\}$. The new state $s'$ is generated by flipping the assignment of this single vertex: $s'_i = -s_i$ and $s'_k = s_k$ for all $k \\neq i$. This proposal mechanism is symmetric, meaning the probability of proposing $s'$ from $s$ is equal to proposing $s$ from $s'$: $q(s \\to s') = q(s' \\to s) = 1/n$.\n\n    -   **Evaluation**: Instead of recalculating the entire cut size $C(s')$, which would be computationally expensive, we compute the change in cut size, $\\Delta C = C(s') - C(s)$. As derived in the problem statement, this change can be calculated locally and efficiently:\n        $$\n        \\Delta C = \\sum_{j \\in N(i)} s_i s_j\n        $$\n        This sum is over the neighbors $j$ of the flipped vertex $i$. If $i$ is an isolated vertex, $N(i)$ is empty, and $\\Delta C = 0$.\n\n    -   **Acceptance**: The proposed state $s'$ is accepted with the Metropolis-Hastings probability $\\alpha(s \\to s')$. Given the symmetric proposal, this simplifies to:\n        $$\n        \\alpha(s \\to s') = \\min\\left(1, \\frac{\\pi(s')}{\\pi(s)}\\right) = \\min\\left(1, \\frac{\\exp(\\lambda C(s'))}{\\exp(\\lambda C(s))}\\right) = \\min\\left(1, \\exp(\\lambda [C(s') - C(s)])\\right) = \\min(1, \\exp(\\lambda \\Delta C))\n        $$\n        To implement this, a random number $u$ is drawn from a uniform distribution on $[0, 1)$. If $u  \\alpha(s \\to s')$, the move is accepted.\n        -   If $\\Delta C > 0$, the cut size increases. Then $\\exp(\\lambda \\Delta C) > 1$, so $\\alpha = 1$, and the move is always accepted.\n        -   If $\\Delta C \\le 0$, the cut size does not increase. Then $\\exp(\\lambda \\Delta C) \\le 1$, so $\\alpha = \\exp(\\lambda \\Delta C)$, and the move is accepted with this probability. This allows the simulation to escape local optima.\n\n    -   **State Update**:\n        -   If the move is accepted, the state is updated to $s \\leftarrow s'$ (by flipping $s_i$), and the current cut size is updated by `current_cut_size` $\\leftarrow$ `current_cut_size` + $\\Delta C$.\n        -   If the move is rejected, the state $s$ and `current_cut_size` remain unchanged for the next iteration.\n\n    -   **Tracking Maximum**: After each step, the `current_cut_size` is compared with `max_cut_size`, and `max_cut_size` is updated if a larger cut has been found: `max_cut_size` $\\leftarrow \\max(\\text{max\\_cut\\_size, current\\_cut\\_size})$.\n\n3.  **Result**: After $T$ steps, the final value of `max_cut_size` is returned as the result for that test case. This entire procedure is repeated for each test case defined in the problem, with its specific graph, parameters, and random seed.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_mcmc_max_cut(n, edges, T, lambda_val, seed):\n    \"\"\"\n    Performs Metropolis-Hastings MCMC to find the approximate maximum cut of a graph.\n\n    Args:\n        n (int): The number of vertices in the graph.\n        edges (list of tuples): The edge set of the graph.\n        T (int): The number of MCMC steps to perform.\n        lambda_val (float): The inverse-temperature parameter.\n        seed (int): The seed for the random number generator.\n\n    Returns:\n        int: The maximum cut size found during the simulation.\n    \"\"\"\n    # 1. Setup the random number generator with the specified seed for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    # 2. Build an adjacency list for efficient neighbor lookup.\n    adj = [[] for _ in range(n)]\n    for u, v in edges:\n        adj[u].append(v)\n        adj[v].append(u)\n\n    # 3. Initialize the state vector s to all +1.\n    s = np.ones(n, dtype=np.int8)\n\n    # The initial cut size for an all-+1 state is always 0.\n    # C(s) = sum((1 - s_i*s_j)/2) = sum((1 - 1*1)/2) = 0.\n    current_cut_size = 0\n    max_cut_size = 0\n\n    # 4. Run the MCMC simulation for T steps.\n    for _ in range(T):\n        # a. Propose a new state by flipping a single vertex's assignment.\n        # Select a vertex 'i' uniformly at random.\n        i = rng.integers(n)\n\n        # b. Calculate the change in cut size (Delta C).\n        # This is a local computation: Delta_C = s_i * sum_{j in N(i)} s_j\n        # Using numpy's advanced indexing for efficiency.\n        if adj[i]:\n            delta_C = s[i] * np.sum(s[adj[i]])\n        else: # Handle isolated vertices\n            delta_C = 0\n\n        # c. Calculate the acceptance probability alpha.\n        # alpha = min(1, exp(lambda * Delta_C))\n        # If delta_C  0, the move improves the cut, so we always accept.\n        # The acceptance probability is 1.\n        if delta_C  0:\n            accept = True\n        else:\n            # If delta_C = 0, the move might be accepted to escape local optima.\n            acceptance_prob = np.exp(lambda_val * delta_C)\n            if rng.random()  acceptance_prob:\n                accept = True\n            else:\n                accept = False\n        \n        # d. Update state if the move is accepted.\n        if accept:\n            s[i] *= -1  # Flip the spin\n            current_cut_size += delta_C\n\n        # e. Track the maximum cut size encountered so far.\n        if current_cut_size  max_cut_size:\n            max_cut_size = current_cut_size\n            \n    return int(max_cut_size)\n\ndef solve():\n    \"\"\"\n    Defines and runs the test cases, then prints the results in the required format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1 (triangle graph)\n        {'n': 3, 'E': [(0, 1), (1, 2), (0, 2)], 'T': 20000, 'lambda': 2.0, 'seed': 7},\n        # Test case 2 (cycle of length 4)\n        {'n': 4, 'E': [(0, 1), (1, 2), (2, 3), (3, 0)], 'T': 30000, 'lambda': 2.0, 'seed': 11},\n        # Test case 3 (empty graph)\n        {'n': 4, 'E': [], 'T': 1000, 'lambda': 2.0, 'seed': 5},\n        # Test case 4 (two disjoint edges)\n        {'n': 4, 'E': [(0, 1), (2, 3)], 'T': 20000, 'lambda': 2.0, 'seed': 13},\n    ]\n\n    results = []\n    for case in test_cases:\n        best_cut = run_mcmc_max_cut(\n            n=case['n'],\n            edges=case['E'],\n            T=case['T'],\n            lambda_val=case['lambda'],\n            seed=case['seed']\n        )\n        results.append(best_cut)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A running MCMC sampler produces a stream of numbers, but how do we know if it is performing well? This diagnostic exercise addresses the crucial, and often counter-intuitive, art of tuning a sampler for efficiency . You will analyze a common scenario where a high acceptance rate, which might seem desirable, actually indicates poor exploration of the state space. This practice will deepen your understanding of the delicate balance required in setting the proposal step size to ensure your Markov chain mixes rapidly and explores the target distribution effectively.",
            "id": "2408757",
            "problem": "Consider a Bayesian posterior sampling problem from computational finance in which the scalar parameter $\\theta$ represents the expected excess return of an asset in a normal–normal conjugate model. For concreteness, assume the posterior density is Gaussian with density proportional to\n$$\n\\pi(\\theta) \\propto \\exp\\!\\left(-\\frac{(\\theta - \\mu)^2}{2\\sigma^2}\\right),\n$$\nfor known $\\mu$ and $\\sigma^2$. You implement a random-walk Metropolis–Hastings algorithm with symmetric proposal\n$$\nq(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\tau^2),\n$$\nand acceptance probability\n$$\n\\alpha(\\theta, \\theta') = \\min\\!\\left\\{1,\\ \\frac{\\pi(\\theta')}{\\pi(\\theta)}\\right\\}.\n$$\nAfter a long run, you observe an average acceptance rate $\\hat{a} \\approx 0.97$ (that is, $\\hat{a} \\approx 97\\%$). Which of the following statements about the implications for state-space exploration and appropriate action are correct?\n\nA. A very high acceptance rate implies low autocorrelation and good mixing, so the current proposal scale $\\tau$ should be kept unchanged.\n\nB. A very high acceptance rate typically indicates that $\\tau$ is too small; although most proposals are accepted, the expected squared jump per iteration is very small, which leads to slow exploration (high autocorrelation). Increasing $\\tau$ to reduce acceptance toward a moderate level (for example, around $0.44$ in 1-dimension) can improve exploration.\n\nC. To further improve exploration and reduce finite-sample bias, one should reduce $\\tau$ even more to push the acceptance rate closer to $1$.\n\nD. For a smooth, unimodal target and a symmetric random-walk proposal, as $\\tau \\to 0$, the acceptance rate tends to $1$ but the integrated autocorrelation time tends to $\\infty$, implying poor exploration despite near-certain acceptance.\n\nE. The stationary distribution of the chain depends on $\\tau$; when the acceptance rate is very high, the chain targets a distribution more concentrated than $\\pi(\\theta)$, which explains the poor exploration.",
            "solution": "The problem statement must first be validated for scientific and logical integrity.\n\n### Step 1: Extract Givens\nThe problem provides the following information:\n-   **Model**: A Bayesian posterior sampling problem from a normal-normal conjugate model.\n-   **Parameter**: A scalar parameter $\\theta$.\n-   **Target Posterior Density**: $\\pi(\\theta) \\propto \\exp\\!\\left(-\\frac{(\\theta - \\mu)^2}{2\\sigma^2}\\right)$, where $\\mu$ and $\\sigma^2$ are known constants. This is the density of a Gaussian distribution, $\\mathcal{N}(\\mu, \\sigma^2)$.\n-   **Algorithm**: Random-walk Metropolis-Hastings (RWMH).\n-   **Proposal Distribution**: A symmetric proposal, $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\tau^2)$. The parameter $\\tau$ is the proposal scale or step size.\n-   **Acceptance Probability**: $\\alpha(\\theta, \\theta') = \\min\\!\\left\\{1,\\ \\frac{\\pi(\\theta')}{\\pi(\\theta)}\\right\\}$.\n-   **Empirical Observation**: The average acceptance rate after a long run is $\\hat{a} \\approx 0.97$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to rigorous validation.\n1.  **Scientific Grounding**: The problem describes a canonical application of the Metropolis-Hastings algorithm, a fundamental tool in computational statistics and econometrics. The model (Gaussian posterior) and proposal mechanism (Gaussian random walk) constitute a standard textbook example. The problem is scientifically sound.\n2.  **Well-Posedness**: The question asks for an interpretation of a specific, well-defined outcome ($\\hat{a} \\approx 0.97$) of the algorithm. This leads to a diagnostic analysis of the sampler's performance, which is a standard task in MCMC practice. The problem is well-posed.\n3.  **Objectivity**: The problem is stated in precise, mathematical language, free from ambiguity or subjective content.\n4.  **Completeness and Consistency**: The problem provides all necessary information to analyze the performance of the MCMC sampler. There are no contradictions.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. It is a well-posed, scientifically grounded problem in the field of computational statistics. I will proceed with a full derivation and analysis.\n\n### Solution Derivation\nThe objective of the Metropolis-Hastings algorithm is to generate a sequence of samples $\\{\\theta_t\\}_{t=1}^N$ from a probability distribution $\\pi(\\theta)$ that is difficult to sample from directly. The algorithm constructs a Markov chain whose stationary distribution is the target distribution $\\pi(\\theta)$. For any valid proposal distribution, including the one specified with scale $\\tau > 0$, the algorithm is guaranteed to have $\\pi(\\theta)$ as its stationary distribution. The choice of $\\tau$, however, critically affects the algorithm's efficiency, i.e., the rate at which the chain explores the state space and converges to this stationary distribution.\n\nThe efficiency is determined by the trade-off between the proposal step size and the acceptance probability.\n-   If the proposal scale $\\tau$ is very small, a new proposal $\\theta' = \\theta_t + \\epsilon$ (where $\\epsilon \\sim \\mathcal{N}(0, \\tau^2)$) will be very close to the current state $\\theta_t$. Consequently, $\\pi(\\theta')$ will be very close to $\\pi(\\theta_t)$, the ratio $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ will be near $1$, and the acceptance probability $\\alpha(\\theta_t, \\theta')$ will be close to $1$. The chain accepts almost all proposals. However, because each step is minuscule, the chain moves very slowly. This results in a sequence of highly correlated samples and, therefore, poor exploration of the state space. This is known as slow mixing.\n-   If the proposal scale $\\tau$ is very large, a new proposal $\\theta'$ is likely to be far from the current state $\\theta_t$. If $\\theta_t$ is in a region of high probability, $\\theta'$ is likely to land in a region of much lower probability (the tails of the distribution). Thus, the ratio $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ will be very small, leading to a low acceptance probability. The chain will reject most proposals and remain at the same state $\\theta_t$ for many iterations. This also leads to high sample autocorrelation and poor exploration.\n\nThe observed average acceptance rate is $\\hat{a} \\approx 0.97$. This value is extremely high, indicating that the algorithm is operating in the first regime: the proposal scale $\\tau$ is too small. While the chain is constantly moving, its steps are too small to be efficient.\n\nOptimal tuning aims to maximize the sampler's efficiency, often by minimizing the autocorrelation of the samples. Theoretical research (e.g., Roberts, Gelman, and Gilks, 1997) has established optimal acceptance rates for RWMH algorithms. For a 1-dimensional target distribution like the one in this problem, the optimal acceptance rate that maximizes exploration efficiency is approximately $0.44$. The observed rate of $0.97$ is far from this optimal value, confirming that the sampler is poorly tuned. The correct action is to increase $\\tau$ to decrease the acceptance rate towards the optimal range.\n\n### Option-by-Option Analysis\n\n**A. A very high acceptance rate implies low autocorrelation and good mixing, so the current proposal scale $\\tau$ should be kept unchanged.**\nThis statement is fundamentally flawed. A very high acceptance rate is a classic symptom of an excessively small proposal step size, which leads to small, timid moves. This results in a chain where successive states are nearly identical, causing *high* autocorrelation and *poor* mixing. The recommendation to keep $\\tau$ unchanged is therefore incorrect.\nVerdict: **Incorrect**.\n\n**B. A very high acceptance rate typically indicates that $\\tau$ is too small; although most proposals are accepted, the expected squared jump per iteration is very small, which leads to slow exploration (high autocorrelation). Increasing $\\tau$ to reduce acceptance toward a moderate level (for example, around $0.44$ in $1$-dimension) can improve exploration.**\nThis statement is entirely correct. It accurately diagnoses the situation: an acceptance rate of $\\approx 0.97$ indicates that $\\tau$ is too small. It correctly identifies the consequence: the chain makes very small jumps, leading to slow exploration, which manifests as high autocorrelation. It correctly prescribes the remedy: increase $\\tau$. Finally, it correctly cites the theoretically optimal acceptance rate of $\\approx 0.44$ for a 1-dimensional problem. This is the standard, textbook diagnosis and response.\nVerdict: **Correct**.\n\n**C. To further improve exploration and reduce finite-sample bias, one should reduce $\\tau$ even more to push the acceptance rate closer to $1$.**\nThis statement recommends the exact opposite of the correct action. As established, an acceptance rate approaching $1$ is a sign of inefficiency. Reducing $\\tau$ further would only exacerbate the problem, making the steps even smaller and the exploration even slower. This would increase, not decrease, the autocorrelation and the variance of any statistical estimators computed from the chain's output.\nVerdict: **Incorrect**.\n\n**D. For a smooth, unimodal target and a symmetric random-walk proposal, as $\\tau \\to 0$, the acceptance rate tends to $1$ but the integrated autocorrelation time tends to $\\infty$, implying poor exploration despite near-certain acceptance.**\nThis is a precise theoretical statement that formalizes the pathology of a very small $\\tau$. As $\\tau \\to 0$, any proposed step $\\theta' = \\theta + \\epsilon$ will be infinitesimally close to $\\theta$. For a smooth density $\\pi$, $\\pi(\\theta') \\approx \\pi(\\theta)$, so the acceptance ratio $\\frac{\\pi(\\theta')}{\\pi(\\theta)} \\to 1$, and thus the acceptance rate goes to $1$. However, the chain is now a discrete approximation of a random walk. To explore a region of a fixed size, the number of steps required scales as $1/\\tau^2$. The integrated autocorrelation time (IACT), which measures the number of correlated samples equivalent to one independent sample, can be shown to scale as IACT $\\propto 1/\\tau^2$. Therefore, as $\\tau \\to 0$, the IACT $\\to \\infty$. This signifies a complete breakdown of efficient exploration. This statement is a cornerstone of the theory of optimal scaling for MCMC.\nVerdict: **Correct**.\n\n**E. The stationary distribution of the chain depends on $\\tau$; when the acceptance rate is very high, the chain targets a distribution more concentrated than $\\pi(\\theta)$, which explains the poor exploration.**\nThis statement contains a grave conceptual error. The Metropolis-Hastings algorithm is constructed to satisfy the detailed balance condition, $\\pi(\\theta) K(\\theta'|\\theta) = \\pi(\\theta') K(\\theta|\\theta')$, where $K$ is the transition kernel. This condition guarantees that the stationary distribution of the Markov chain is *exactly* the target distribution $\\pi(\\theta)$. This property holds for any valid choice of proposal scale $\\tau > 0$. The parameter $\\tau$ influences the *rate of convergence* to the stationary distribution and the *efficiency* of the sampler, but it does *not* alter the target distribution itself. The poor exploration is due to slow dynamics, not to targeting the wrong distribution.\nVerdict: **Incorrect**.",
            "answer": "$$\\boxed{BD}$$"
        }
    ]
}