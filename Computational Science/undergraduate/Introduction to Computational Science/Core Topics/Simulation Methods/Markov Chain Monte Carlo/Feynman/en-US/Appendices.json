{
    "hands_on_practices": [
        {
            "introduction": "At the heart of the Metropolis-Hastings algorithm lies the acceptance-rejection step, which determines whether the Markov chain moves to a new proposed state or remains at its current one. This exercise provides a foundational calculation of the acceptance probability, $\\alpha(x \\to x')$, for a simple continuous state space. Mastering this core mechanism is the first step toward understanding and implementing any MCMC sampler .",
            "id": "1371728",
            "problem": "A data scientist is implementing a Markov Chain Monte Carlo (MCMC) simulation to draw samples from a posterior probability distribution for a parameter $x$. The target distribution, $\\pi(x)$, is proportional to the exponential of the negative absolute value of the parameter, such that $\\pi(x) \\propto \\exp(-|x|)$.\n\nThe scientist uses the Metropolis algorithm with a symmetric proposal distribution $q(x'|x)$, where the probability of proposing a new state $x'$ given the current state $x$ is equal to the probability of proposing $x$ given $x'$ (i.e., $q(x'|x) = q(x|x')$).\n\nSuppose that at a certain step in the simulation, the current state of the chain is $x = 1.5$. The algorithm then proposes a move to a new candidate state $x' = 2.0$.\n\nCalculate the acceptance probability for this specific move. Your answer should be a dimensionless real number. Round your final answer to four significant figures.",
            "solution": "The Metropolis acceptance probability for a move from $x$ to $x'$ with a symmetric proposal $q(x'|x)=q(x|x')$ is\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\nGiven the target distribution $\\pi(x)\\propto \\exp(-|x|)$, the ratio simplifies to\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\nWith $x=1.5$ and $x'=2.0$, we have $|x|=1.5$ and $|x'|=2.0$, so\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\nTherefore,\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\nNumerically, $\\exp(-0.5)\\approx 0.6065$ when rounded to four significant figures.",
            "answer": "$$\\boxed{0.6065}$$"
        },
        {
            "introduction": "Simply implementing an MCMC sampler is not enough; we must also ensure it explores the state space efficiently, a property known as good \"mixing\". A key diagnostic is the average acceptance rate, but its interpretation can be counter-intuitive, as this exercise demonstrates . This problem challenges the common misconception that a higher acceptance rate is always better, forcing you to think critically about the trade-off between the size of proposed steps and the chain's ability to explore the entire parameter space effectively.",
            "id": "2408757",
            "problem": "Consider a Bayesian posterior sampling problem from computational finance in which the scalar parameter $\\theta$ represents the expected excess return of an asset in a normal–normal conjugate model. For concreteness, assume the posterior density is Gaussian with density proportional to\n$$\n\\pi(\\theta) \\propto \\exp\\!\\left(-\\frac{(\\theta - \\mu)^2}{2\\sigma^2}\\right),\n$$\nfor known $\\mu$ and $\\sigma^2$. You implement a random-walk Metropolis–Hastings algorithm with symmetric proposal\n$$\nq(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\tau^2),\n$$\nand acceptance probability\n$$\n\\alpha(\\theta, \\theta') = \\min\\!\\left\\{1,\\ \\frac{\\pi(\\theta')}{\\pi(\\theta)}\\right\\}.\n$$\nAfter a long run, you observe an average acceptance rate $\\hat{a} \\approx 0.97$ (that is, $\\hat{a} \\approx 97\\%$). Which of the following statements about the implications for state-space exploration and appropriate action are correct?\n\nA. A very high acceptance rate implies low autocorrelation and good mixing, so the current proposal scale $\\tau$ should be kept unchanged.\n\nB. A very high acceptance rate typically indicates that $\\tau$ is too small; although most proposals are accepted, the expected squared jump per iteration is very small, which leads to slow exploration (high autocorrelation). Increasing $\\tau$ to reduce acceptance toward a moderate level (for example, around $0.44$ in $1$-dimension) can improve exploration.\n\nC. To further improve exploration and reduce finite-sample bias, one should reduce $\\tau$ even more to push the acceptance rate closer to $1$.\n\nD. For a smooth, unimodal target and a symmetric random-walk proposal, as $\\tau \\to 0$, the acceptance rate tends to $1$ but the integrated autocorrelation time tends to $\\infty$, implying poor exploration despite near-certain acceptance.\n\nE. The stationary distribution of the chain depends on $\\tau$; when the acceptance rate is very high, the chain targets a distribution more concentrated than $\\pi(\\theta)$, which explains the poor exploration.",
            "solution": "The problem statement must first be validated for scientific and logical integrity.\n\n### Step 1: Extract Givens\nThe problem provides the following information:\n-   **Model**: A Bayesian posterior sampling problem from a normal-normal conjugate model.\n-   **Parameter**: A scalar parameter $\\theta$.\n-   **Target Posterior Density**: $\\pi(\\theta) \\propto \\exp\\!\\left(-\\frac{(\\theta - \\mu)^2}{2\\sigma^2}\\right)$, where $\\mu$ and $\\sigma^2$ are known constants. This is the density of a Gaussian distribution, $\\mathcal{N}(\\mu, \\sigma^2)$.\n-   **Algorithm**: Random-walk Metropolis-Hastings (RWMH).\n-   **Proposal Distribution**: A symmetric proposal, $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta, \\tau^2)$. The parameter $\\tau$ is the proposal scale or step size.\n-   **Acceptance Probability**: $\\alpha(\\theta, \\theta') = \\min\\!\\left\\{1,\\ \\frac{\\pi(\\theta')}{\\pi(\\theta)}\\right\\}$.\n-   **Empirical Observation**: The average acceptance rate after a long run is $\\hat{a} \\approx 0.97$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to rigorous validation.\n1.  **Scientific Grounding**: The problem describes a canonical application of the Metropolis-Hastings algorithm, a fundamental tool in computational statistics and econometrics. The model (Gaussian posterior) and proposal mechanism (Gaussian random walk) constitute a standard textbook example. The problem is scientifically sound.\n2.  **Well-Posedness**: The question asks for an interpretation of a specific, well-defined outcome ($\\hat{a} \\approx 0.97$) of the algorithm. This leads to a diagnostic analysis of the sampler's performance, which is a standard task in MCMC practice. The problem is well-posed.\n3.  **Objectivity**: The problem is stated in precise, mathematical language, free from ambiguity or subjective content.\n4.  **Completeness and Consistency**: The problem provides all necessary information to analyze the performance of the MCMC sampler. There are no contradictions.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. It is a well-posed, scientifically grounded problem in the field of computational statistics. I will proceed with a full derivation and analysis.\n\n### Solution Derivation\nThe objective of the Metropolis-Hastings algorithm is to generate a sequence of samples $\\{\\theta_t\\}_{t=1}^N$ from a probability distribution $\\pi(\\theta)$ that is difficult to sample from directly. The algorithm constructs a Markov chain whose stationary distribution is the target distribution $\\pi(\\theta)$. For any valid proposal distribution, including the one specified with scale $\\tau  0$, the algorithm is guaranteed to have $\\pi(\\theta)$ as its stationary distribution. The choice of $\\tau$, however, critically affects the algorithm's efficiency, i.e., the rate at which the chain explores the state space and converges to this stationary distribution.\n\nThe efficiency is determined by the trade-off between the proposal step size and the acceptance probability.\n-   If the proposal scale $\\tau$ is very small, a new proposal $\\theta' = \\theta_t + \\epsilon$ (where $\\epsilon \\sim \\mathcal{N}(0, \\tau^2)$) will be very close to the current state $\\theta_t$. Consequently, $\\pi(\\theta')$ will be very close to $\\pi(\\theta_t)$, the ratio $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ will be near $1$, and the acceptance probability $\\alpha(\\theta_t, \\theta')$ will be close to $1$. The chain accepts almost all proposals. However, because each step is minuscule, the chain moves very slowly. This results in a sequence of highly correlated samples and, therefore, poor exploration of the state space. This is known as slow mixing.\n-   If the proposal scale $\\tau$ is very large, a new proposal $\\theta'$ is likely to be far from the current state $\\theta_t$. If $\\theta_t$ is in a region of high probability, $\\theta'$ is likely to land in a region of much lower probability (the tails of the distribution). Thus, the ratio $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ will be very small, leading to a low acceptance probability. The chain will reject most proposals and remain at the same state $\\theta_t$ for many iterations. This also leads to high sample autocorrelation and poor exploration.\n\nThe observed average acceptance rate is $\\hat{a} \\approx 0.97$. This value is extremely high, indicating that the algorithm is operating in the first regime: the proposal scale $\\tau$ is too small. While the chain is constantly moving, its steps are too small to be efficient.\n\nOptimal tuning aims to maximize the sampler's efficiency, often by minimizing the autocorrelation of the samples. Theoretical research (e.g., Roberts, Gelman, and Gilks, 1997) has established optimal acceptance rates for RWMH algorithms. For a $1$-dimensional target distribution like the one in this problem, the optimal acceptance rate that maximizes exploration efficiency is approximately $0.44$. The observed rate of $0.97$ is far from this optimal value, confirming that the sampler is poorly tuned. The correct action is to increase $\\tau$ to decrease the acceptance rate towards the optimal range.\n\n### Option-by-Option Analysis\n\n**A. A very high acceptance rate implies low autocorrelation and good mixing, so the current proposal scale $\\tau$ should be kept unchanged.**\nThis statement is fundamentally flawed. A very high acceptance rate is a classic symptom of an excessively small proposal step size, which leads to small, timid moves. This results in a chain where successive states are nearly identical, causing *high* autocorrelation and *poor* mixing. The recommendation to keep $\\tau$ unchanged is therefore incorrect.\nVerdict: **Incorrect**.\n\n**B. A very high acceptance rate typically indicates that $\\tau$ is too small; although most proposals are accepted, the expected squared jump per iteration is very small, which leads to slow exploration (high autocorrelation). Increasing $\\tau$ to reduce acceptance toward a moderate level (for example, around $0.44$ in $1$-dimension) can improve exploration.**\nThis statement is entirely correct. It accurately diagnoses the situation: an acceptance rate of $\\approx 0.97$ indicates that $\\tau$ is too small. It correctly identifies the consequence: the chain makes very small jumps, leading to slow exploration, which manifests as high autocorrelation. It correctly prescribes the remedy: increase $\\tau$. Finally, it correctly cites the theoretically optimal acceptance rate of $\\approx 0.44$ for a $1$-dimensional problem. This is the standard, textbook diagnosis and response.\nVerdict: **Correct**.\n\n**C. To further improve exploration and reduce finite-sample bias, one should reduce $\\tau$ even more to push the acceptance rate closer to $1$.**\nThis statement recommends the exact opposite of the correct action. As established, an acceptance rate approaching $1$ is a sign of inefficiency. Reducing $\\tau$ further would only exacerbate the problem, making the steps even smaller and the exploration even slower. This would increase, not decrease, the autocorrelation and the variance of any statistical estimators computed from the chain's output.\nVerdict: **Incorrect**.\n\n**D. For a smooth, unimodal target and a symmetric random-walk proposal, as $\\tau \\to 0$, the acceptance rate tends to $1$ but the integrated autocorrelation time tends to $\\infty$, implying poor exploration despite near-certain acceptance.**\nThis is a precise theoretical statement that formalizes the pathology of a very small $\\tau$. As $\\tau \\to 0$, any proposed step $\\theta' = \\theta + \\epsilon$ will be infinitesimally close to $\\theta$. For a smooth density $\\pi$, $\\pi(\\theta') \\approx \\pi(\\theta)$, so the acceptance ratio $\\frac{\\pi(\\theta')}{\\pi(\\theta)} \\to 1$, and thus the acceptance rate goes to $1$. However, the chain is now a discrete approximation of a random walk. To explore a region of a fixed size, the number of steps required scales as $1/\\tau^2$. The integrated autocorrelation time (IACT), which measures the number of correlated samples equivalent to one independent sample, can be shown to scale as $\\text{IACT} \\propto 1/\\tau^2$. Therefore, as $\\tau \\to 0$, the IACT $\\to \\infty$. This signifies a complete breakdown of efficient exploration. This statement is a cornerstone of the theory of optimal scaling for MCMC.\nVerdict: **Correct**.\n\n**E. The stationary distribution of the chain depends on $\\tau$; when the acceptance rate is very high, the chain targets a distribution more concentrated than $\\pi(\\theta)$, which explains the poor exploration.**\nThis statement contains a grave conceptual error. The Metropolis-Hastings algorithm is constructed to satisfy the detailed balance condition, $\\pi(\\theta) K(\\theta'|\\theta) = \\pi(\\theta') K(\\theta|\\theta')$, where $K$ is the transition kernel. This condition guarantees that the stationary distribution of the Markov chain is *exactly* the target distribution $\\pi(\\theta)$. This property holds for any valid choice of proposal scale $\\tau  0$. The parameter $\\tau$ influences the *rate of convergence* to the stationary distribution and the *efficiency* of the sampler, but it does *not* alter the target distribution itself. The poor exploration is due to slow dynamics, not to targeting the wrong distribution.\nVerdict: **Incorrect**.",
            "answer": "$$\\boxed{BD}$$"
        },
        {
            "introduction": "An MCMC sampler is only guaranteed to converge to the correct target distribution if its underlying Markov chain is irreducible, meaning it can eventually reach any part of the state space from any other part. This hands-on coding problem asks you to build a scenario where this crucial property is violated, leading to a catastrophic failure of the sampler to explore a disconnected target distribution . Through this exercise, you will learn how to diagnose such failures and appreciate why theoretical guarantees are of profound practical importance for obtaining reliable results.",
            "id": "3157911",
            "problem": "You will implement and analyze a Metropolis–Hastings Markov Chain Monte Carlo (MCMC) sampler to demonstrate a convergence failure when the proposal kernel is not irreducible on a target distribution with disconnected support. Work entirely in one dimension. The target density $\\pi(x)$ is proportional to a uniform density on the disconnected set $S = [-3,-1] \\cup [1,3]$ and zero elsewhere. That is, $\\pi(x) \\propto 1$ for $x \\in S$ and $\\pi(x) = 0$ for $x \\notin S$. The Metropolis–Hastings chain uses proposals of the form $x' \\sim q(\\cdot \\mid x)$ and the acceptance probability $\\alpha(x,x') = \\min\\left(1, \\dfrac{\\pi(x')\\,q(x \\mid x')}{\\pi(x)\\,q(x' \\mid x)}\\right)$. You must start every chain at $x_0 = -2$, which lies in the left component $[-3,-1]$.\n\nFundamental base: Use the standard definitions of Markov chain, irreducibility, proposal kernel, Metropolis–Hastings acceptance probability, and the notion that a Markov chain Monte Carlo sampler targets $\\pi(x)$ if it is irreducible and aperiodic and satisfies detailed balance with respect to $\\pi(x)$, which a correctly implemented Metropolis–Hastings algorithm does by construction.\n\nYou will consider two proposal families:\n- Uniform bounded random walk with step size $\\Delta  0$: $q_{\\Delta}(x' \\mid x)$ is uniform on $[x-\\Delta, x+\\Delta]$.\n- Gaussian random walk with standard deviation $\\sigma  0$: $q_{\\sigma}(x' \\mid x)$ is $\\mathcal{N}(x, \\sigma^2)$.\n\nObservation: Since $\\pi(x)$ is constant on $S$ and zero outside $S$, for symmetric proposals (both the uniform bounded random walk and the Gaussian random walk are symmetric), the Metropolis–Hastings acceptance simplifies to accepting every proposal that lands in $S$ and rejecting every proposal that lands outside $S$.\n\nDefine the component label function as $c(x) = 0$ if $x \\in [-3,-1]$ and $c(x) = 1$ if $x \\in [1,3]$. Because the chain starts in $S$ and rejects any proposed state $x' \\notin S$, all states remain in $S$ after initialization. For analysis, use a burn-in of $B = 1000$ steps and then compute diagnostics on the remaining samples.\n\nYou must implement the following diagnostics for each chain after burn-in:\n1. The number of distinct components visited, which is the cardinality of $\\{c(x_t) : t \\ge B\\}$; express this as an integer in $\\{1,2\\}$.\n2. The fraction of post–burn-in samples in the right component, computed as $\\frac{1}{T-B}\\sum_{t=B}^{T-1} \\mathbf{1}\\{c(x_t)=1\\}$, where $T$ is the total number of steps; express as a decimal rounded to four digits after the decimal point.\n3. The empirical two-state transition matrix between the components, estimated from consecutive post–burn-in labels. Let $N_{ij}$ be the count of transitions from component $i$ at time $t$ to component $j$ at time $t+1$ for $t=B,\\dots,T-2$. Define $\\widehat{P}_{ij} = \\frac{N_{ij}}{\\sum_{k \\in \\{0,1\\}} N_{ik}}$ if the denominator is positive, and $\\widehat{P}_{ij} = 0$ if the denominator is zero. Report the off-diagonal entries $\\widehat{P}_{0,1}$ and $\\widehat{P}_{1,0}$ (each rounded to four digits after the decimal point).\n4. An estimated irreducibility flag for the two-component aggregated chain, defined as the boolean value of $(\\widehat{P}_{0,1}  0)$ and $(\\widehat{P}_{1,0}  0)$.\n\nYou must implement the sampler and compute these diagnostics for the test suite below. Use independent random number generator seeds for reproducibility as specified.\n\nTest suite:\n- Case 1 (non-irreducible): Uniform bounded proposal with $\\Delta = 1.5$, total steps $T = 5000$, random seed $12345$.\n- Case 2 (boundary non-irreducible): Uniform bounded proposal with $\\Delta = 2.0$, total steps $T = 5000$, random seed $12345$.\n- Case 3 (irreducible by range): Uniform bounded proposal with $\\Delta = 2.5$, total steps $T = 5000$, random seed $12345$.\n- Case 4 (irreducible by unbounded support): Gaussian proposal with $\\sigma = 1.0$, total steps $T = 6000$, random seed $67890$.\n\nGuidance on expected behavior based on first principles: The gap between components has width $2$. For the uniform bounded proposal, when $\\Delta  2$ the chain cannot traverse the gap in a single step and is therefore not irreducible on $S$; when $\\Delta = 2$ the only traversals would require proposing a jump of exactly $2$, which has probability $0$ under a continuous proposal, so the chain remains non-irreducible; when $\\Delta  2$, crosses become possible. For the Gaussian proposal, the support is unbounded so crosses have positive probability for any $\\sigma  0$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case contributes a sublist in the form [visited_components,positive_fraction,p01,p10,is_irreducible_estimated], where visited_components is an integer, positive_fraction, p01, and p10 are decimals rounded to four places, and is_irreducible_estimated is a boolean. The overall output must therefore be a single list of these four sublists with no spaces, for example: [[1,0.0000,0.0000,0.0000,False],[...],[...],[...]]. No external files or input are permitted; everything must run self-contained.\n\nAngle units are not applicable. Physical units are not applicable. Percentages must be expressed as decimals.",
            "solution": "The objective of this problem is to demonstrate a critical failure mode of the Metropolis-Hastings Markov Chain Monte Carlo (MCMC) algorithm: the failure to converge to the true target distribution when the underlying Markov chain is not irreducible. A Markov chain is irreducible if it is possible to go from any state to any other state in a finite number of steps. For an MCMC sampler to correctly sample from a target distribution $\\pi(x)$, its corresponding Markov chain must be irreducible over the entire support of $\\pi(x)$. If the proposal kernel makes certain regions of the support unreachable from others, the sampler will fail to explore the full distribution, leading to biased and incorrect estimates.\n\nWe will investigate this phenomenon using a one-dimensional target density $\\pi(x)$ that is uniform on a disconnected support set $S = [-3, -1] \\cup [1, 3]$ and zero elsewhere. The probability density is thus:\n$$\n\\pi(x) = \\begin{cases}\n    1/4  \\text{if } x \\in [-3, -1] \\cup [1, 3] \\\\\n    0  \\text{otherwise}\n\\end{cases}\n$$\nThe total length of the support $S$ is $( -1 - (-3)) + (3 - 1) = 2 + 2 = 4$.\n\nThe Metropolis-Hastings algorithm generates a sequence of states $\\{x_t\\}$ by proposing a new state $x'$ from a proposal distribution $q(x' \\mid x_t)$ and accepting it with probability:\n$$\n\\alpha(x_t, x') = \\min\\left(1, \\frac{\\pi(x') q(x_t \\mid x')}{\\pi(x_t) q(x' \\mid x_t)}\\right)\n$$\nWe will use two types of symmetric proposal kernels, for which $q(x \\mid x') = q(x' \\mid x)$. The acceptance probability simplifies to $\\alpha(x_t, x') = \\min(1, \\pi(x') / \\pi(x_t))$. Given our specific $\\pi(x)$, if the current state $x_t$ is in the support $S$, then $\\pi(x_t) = 1/4$.\n- If the proposed state $x'$ is also in $S$, then $\\pi(x') = 1/4$, the ratio is $1$, and the acceptance probability is $\\alpha(x_t, x') = 1$. The proposal is always accepted.\n- If the proposed state $x'$ is not in $S$, then $\\pi(x') = 0$, the ratio is $0$, and the acceptance probability is $\\alpha(x_t, x') = 0$. The proposal is always rejected, and the chain remains at $x_{t+1} = x_t$.\n\nThe chain is initialized at $x_0 = -2$, which lies in the left component of the support, $[-3,-1]$.\n\nThe two proposal kernels are:\n1.  A uniform bounded random walk, where $x' \\sim U(x - \\Delta, x + \\Delta)$. For the chain to be able to transition from the left component $[-3, -1]$ to the right component $[1, 3]$, the proposal interval must be able to bridge the gap of width $2$ between them. The rightmost point of the left component is $x = -1$. A proposal from this point lies in $[-1-\\Delta, -1+\\Delta]$. For this interval to overlap with $[1, 3]$, we must have $-1+\\Delta  1$, which implies $\\Delta  2$. If $\\Delta \\le 2$, it is impossible for the chain to jump from the left component to the right one, rendering the chain non-irreducible over $S$.\n2.  A Gaussian random walk, where $x' \\sim \\mathcal{N}(x, \\sigma^2)$. This distribution has unbounded support $(-\\infty, \\infty)$. Therefore, for any current state $x \\in S$ and any $\\sigma  0$, there is a non-zero probability density for proposing a new state $x'$ in any other part of the support. This ensures the chain is irreducible.\n\nTo analyze the behavior, we will simulate the chain for $T$ steps and discard the first $B = 1000$ steps as burn-in. We define a component label function $c(x)$, where $c(x) = 0$ for $x \\in [-3,-1]$ and $c(x) = 1$ for $x \\in [1,3]$. We compute the following diagnostics on the post-burn-in samples:\n1.  The number of distinct components visited, which must be $2$ for an irreducible chain that has mixed.\n2.  The fraction of samples in the right component ($c(x)=1$), which should approach $0.5$ for an irreducible chain sampling a symmetric distribution.\n3.  The off-diagonal entries $\\widehat{P}_{0,1}$ and $\\widehat{P}_{1,0}$ of the empirical transition matrix between components. These represent the estimated probability of jumping from component $0$ to $1$ and from $1$ to $0$, respectively.\n4.  An empirical flag for irreducibility, $(\\widehat{P}_{0,1}  0) \\land (\\widehat{P}_{1,0}  0)$, which should be true if and only if transitions between both components were observed.\n\nThe algorithm is implemented and evaluated for four test cases as specified, demonstrating the predicted behavior based on this theoretical analysis.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the MCMC simulations and print the final results.\n    \"\"\"\n\n    def run_mcmc(proposal_type, param, T, x0, seed):\n        \"\"\"\n        Generates a Markov chain using the Metropolis-Hastings algorithm.\n\n        Args:\n            proposal_type (str): 'uniform' or 'gaussian'.\n            param (float): Delta for uniform or sigma for Gaussian.\n            T (int): Total number of steps.\n            x0 (float): Initial state.\n            seed (int): Random number generator seed.\n\n        Returns:\n            np.ndarray: The generated Markov chain of length T.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        chain = np.zeros(T)\n        chain[0] = x0\n        current_x = x0\n\n        for t in range(T - 1):\n            if proposal_type == 'uniform':\n                proposal = rng.uniform(current_x - param, current_x + param)\n            elif proposal_type == 'gaussian':\n                proposal = rng.normal(current_x, param)\n            \n            # Check if the proposal is in the support S = [-3,-1] U [1,3]\n            in_S = (-3.0 = proposal = -1.0) or (1.0 = proposal = 3.0)\n            \n            # Simplified Metropolis-Hastings acceptance rule\n            if in_S:\n                current_x = proposal\n            \n            chain[t + 1] = current_x\n        \n        return chain\n\n    def analyze_chain(chain, B):\n        \"\"\"\n        Computes diagnostics for a given Markov chain after burn-in.\n\n        Args:\n            chain (np.ndarray): The Markov chain.\n            B (int): The number of burn-in steps.\n\n        Returns:\n            list: A list containing the computed diagnostics.\n        \"\"\"\n        post_burn_in = chain[B:]\n        \n        def component_label(x):\n            return 0 if -3.0 = x = -1.0 else 1\n\n        labels = [component_label(x) for x in post_burn_in]\n        \n        # 1. Number of distinct components visited\n        visited_components = len(set(labels))\n        \n        # 2. Fraction of post–burn-in samples in the right component\n        if not labels:\n            positive_fraction = 0.0\n        else:\n            num_in_right = sum(1 for label in labels if label == 1)\n            positive_fraction = num_in_right / len(labels)\n        \n        # 3. Empirical two-state transition matrix\n        N00, N01, N10, N11 = 0, 0, 0, 0\n        for i in range(len(labels) - 1):\n            if labels[i] == 0:\n                if labels[i+1] == 0: N00 += 1\n                else: N01 += 1\n            else: # labels[i] == 1\n                if labels[i+1] == 0: N10 += 1\n                else: N11 += 1\n                \n        N0_total = N00 + N01\n        N1_total = N10 + N11\n        \n        p01 = float(N01) / N0_total if N0_total > 0 else 0.0\n        p10 = float(N10) / N1_total if N1_total > 0 else 0.0\n        \n        # 4. Estimated irreducibility flag\n        is_irreducible_estimated = (p01 > 0) and (p10 > 0)\n        \n        return [visited_components, positive_fraction, p01, p10, is_irreducible_estimated]\n\n    test_cases = [\n        {'type': 'uniform', 'param': 1.5, 'T': 5000, 'seed': 12345},\n        {'type': 'uniform', 'param': 2.0, 'T': 5000, 'seed': 12345},\n        {'type': 'uniform', 'param': 2.5, 'T': 5000, 'seed': 12345},\n        {'type': 'gaussian', 'param': 1.0, 'T': 6000, 'seed': 67890}\n    ]\n    \n    B = 1000\n    x0 = -2.0\n    \n    all_results = []\n    for case in test_cases:\n        chain = run_mcmc(case['type'], case['param'], case['T'], x0, case['seed'])\n        diagnostics = analyze_chain(chain, B)\n        all_results.append(diagnostics)\n\n    result_strings = []\n    for diag in all_results:\n        # Format: [visited_components, positive_fraction, p01, p10, is_irreducible_estimated]\n        # Decimals rounded to 4 places.\n        s = (f\"[{diag[0]},{diag[1]:.4f},{diag[2]:.4f},\"\n             f\"{diag[3]:.4f},{diag[4]}]\")\n        result_strings.append(s)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        }
    ]
}