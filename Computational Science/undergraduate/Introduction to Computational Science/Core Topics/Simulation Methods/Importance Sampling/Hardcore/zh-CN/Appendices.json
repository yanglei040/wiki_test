{
    "hands_on_practices": [
        {
            "introduction": "成功实施重要性抽样的关键在于选择一个能够有效降低估计量方差的提议分布 $q(x)$。这个练习将带你深入探讨这一核心原则。通过分析推导一个提议分布的最优形式，你将亲身体会到，精心选择的 $q(x)$ 如何能显著提高估计的效率，这是设计高效蒙特卡洛方法的重要一步。",
            "id": "767870",
            "problem": "重要性采样是一种方差缩减技术，用于蒙特卡洛方法中，通过从一个不同的分布中抽取样本来估计某个特定分布的性质。假设我们希望估计期望 $I = E_p[f(X)] = \\int f(x) p(x) dx$，其中 $p(x)$ 是目标概率密度函数。我们可以不从 $p(x)$ 中采样，而是从一个提议分布 $q(x)$ 中抽取样本 $\\{X_i\\}_{i=1}^N$ 并构建如下估计量：\n$$ \\hat{I}_N = \\frac{1}{N} \\sum_{i=1}^N f(X_i) w(X_i) $$\n其中 $w(x) = \\frac{p(x)}{q(x)}$ 是重要性权重。该估计量是无偏的，即 $E_q[\\hat{I}_N] = I$。该方法的效率取决于估计量的方差，其方差由 $\\text{Var}_q(\\hat{I}_N) = \\frac{1}{N} \\text{Var}_q(f(X)w(X))$ 给出。为了在固定样本量 $N$ 的情况下最小化估计量的方差，必须最小化 $\\text{Var}_q(f(X)w(X))$。由于 $\\text{Var}_q(Y) = E_q[Y^2] - (E_q[Y])^2$ 且 $E_q[f(X)w(X)] = I$ 是一个关于 $q(x)$ 选择的常数，因此最小化方差等价于最小化二阶矩 $E_q[(f(X)w(X))^2]$。\n\n考虑一个场景，其中目标分布 $p(x)$ 是一个尺度参数为 $\\sigma_p$ 的瑞利分布。尺度参数为 $\\sigma$ 的瑞利分布的概率密度函数由下式给出：\n$$ g(x; \\sigma) = \\frac{x}{\\sigma^2} e^{-x^2 / (2\\sigma^2)} \\quad \\text{for } x \\ge 0 $$\n我们希望估计该目标分布的均值，因此 $f(x)=x$。我们选择另一个具有可调尺度参数 $\\sigma_q$ 的瑞利分布作为我们的提议分布 $q(x)$。\n\n推导使重要性采样估计量方差最小的提议尺度参数 $\\sigma_q$ 的最优值。用 $\\sigma_p$ 表示你的答案。",
            "solution": "我们希望最小化二阶矩\n$$M_2(\\sigma_q)=E_q[(f(X)w(X))^2]\n=\\int_0^\\infty x^2\\Bigl(\\frac{p(x)}{q(x)}\\Bigr)^2q(x)\\,dx\n=\\int_0^\\infty\\frac{x^2p(x)^2}{q(x)}\\,dx$$\n其中\n$$p(x)=\\frac{x}{\\sigma_p^2}e^{-x^2/(2\\sigma_p^2)},\\quad\nq(x)=\\frac{x}{\\sigma_q^2}e^{-x^2/(2\\sigma_q^2)}.$$\n代入可得\n$$M_2\n=\\int_0^\\infty\\frac{x^2\\,(x/\\sigma_p^2)^2e^{-x^2/\\sigma_p^2}}\n{(x/\\sigma_q^2)e^{-x^2/(2\\sigma_q^2)}}\\,dx\n=\\frac{\\sigma_q^2}{\\sigma_p^4}\\int_0^\\infty x^3e^{-ax^2}\\,dx,$$\n其中\n$$a=\\frac1{\\sigma_p^2}-\\frac1{2\\sigma_q^2}\n=\\frac{2\\sigma_q^2-\\sigma_p^2}{2\\sigma_p^2\\sigma_q^2}.$$\n使用\n$$\\int_0^\\infty x^3e^{-ax^2}dx=\\frac1{2a^2},$$\n我们得到\n$$M_2\n=\\frac{\\sigma_q^2}{\\sigma_p^4}\\,\\frac1{2a^2}\n=2\\,\\frac{\\sigma_q^6}{(2\\sigma_q^2-\\sigma_p^2)^2}.$$\n令 $x=\\sigma_q^2$ 并最小化\n$$F(x)=\\frac{x^3}{(2x-\\sigma_p^2)^2}$$\n通过求解 $dF/dx=0$。可以找到容许的临界点\n$$\\sigma_q^2=\\tfrac32\\,\\sigma_p^2,\n\\quad\\sigma_q=\\sigma_p\\sqrt{\\tfrac32}.$$",
            "answer": "$$\\boxed{\\sigma_p\\sqrt{\\frac{3}{2}}}$$"
        },
        {
            "introduction": "重要性抽样依赖于一个基本的数学假设：在目标分布为正的任何地方，提议分布也必须为正。这个“支撑集覆盖”条件不仅是理论上的细节，违反它会导致有偏甚至完全错误的估计结果。本练习旨在揭示支撑集不匹配的严重后果，并探讨一种修正此问题的标准技术，帮助你避免这个常见的陷阱。",
            "id": "3143026",
            "problem": "您的任务是为一个有界可测函数 $g$ 估计量 $\\mu = \\mathbb{E}_{p}[g(X)]$，其中 $X$ 是一个实值随机变量，其概率密度函数为 $p$。考虑以下科学上合理的情境：目标密度 $p$ 在区间 $[0, 2]$ 上均匀分布，而用于重要性采样的提议密度 $q$ 在区间 $[0, 1.5]$ 上均匀分布。具体来说，\n$$\np(x) = \\frac{1}{2}\\,\\mathbf{1}_{[0, 2]}(x), \\qquad q(x) = \\frac{2}{3}\\,\\mathbf{1}_{[0, 1.5]}(x),\n$$\n其中 $\\mathbf{1}_{A}(x)$ 是集合 $A$ 的指示函数。标准重要性采样方法使用从 $q$ 中抽取的独立同分布样本 $X_{1}, \\dots, X_{n} \\overset{\\text{i.i.d.}}{\\sim} q$ 和权重 $w(x) = \\frac{p(x)}{q(x)}$ 来构建 $\\mu$ 的估计量。在这种情况下，区间 $[1.5, 2]$ 在 $p$ 下具有正概率质量，但在 $q$ 下的概率质量为零，这在提议分布的支撑集中造成了间隙。\n\n为了弥补支撑集的间隙，一种常见的策略是用一个能保证支撑集覆盖的混合提议分布来替换 $q$。令 $r$ 为 $[0, 2]$ 上的均匀密度，即\n$$\nr(x) = \\frac{1}{2}\\,\\mathbf{1}_{[0, 2]}(x),\n$$\n并考虑混合提议分布\n$$\nq_{\\varepsilon}(x) = (1 - \\varepsilon)\\,q(x) + \\varepsilon\\,r(x),\n$$\n其中 $\\varepsilon \\in (0, 1)$。\n\n在此情境下，选择所有正确的陈述。\n\nA. 对于 $g(x) = 1$，使用 $q$ 的标准重要性采样估计量对于 $\\mu$ 是无偏的。\n\nB. $p$ 相对于 $q$ 绝对连续的条件（即 $p \\ll q$）在此不成立。因此，除非 $g(x)$ 在 $[1.5, 2]$ 上为 0，否则使用 $q$ 的标准重要性采样估计量是有偏的。\n\nC. 使用混合提议分布 $q_{\\varepsilon}$ 可以为任何有界函数 $g$ 恢复无偏性，并得到一个方差有限的重要性采样估计量；然而，当 $\\varepsilon \\to 0$ 时，方差可能变得任意大。\n\nD. 将权重 $\\frac{p(x)}{q(x)}$ 乘以一个固定常数以限制其大小，可以防止偏差并确保方差有限，即使 $q$ 在 $p$ 的支撑集部分区域上的密度为零。\n\nE. 改用自归一化重要性采样 (SNIS) 估计量无需满足支撑集覆盖条件；即使在 $p(x)  0$ 而 $q$ 的密度为零的区域，无偏性仍然成立。",
            "solution": "用户希望我验证问题陈述，如果有效，则提供一个评估每个选项的详细解决方案。\n\n### 问题验证\n\n**第1步：提取已知条件**\n- 待估计的量：$\\mu = \\mathbb{E}_{p}[g(X)]$。\n- $g$：一个有界可测函数。\n- $X$：一个实值随机变量。\n- 目标概率密度函数 (PDF)：$p(x) = \\frac{1}{2}\\,\\mathbf{1}_{[0, 2]}(x)$。\n- 用于标准重要性采样的提议 PDF：$q(x) = \\frac{2}{3}\\,\\mathbf{1}_{[0, 1.5]}(x)$。\n- 标准重要性采样使用独立同分布的样本 $X_{1}, \\dots, X_{n} \\sim q$。\n- 重要性权重：$w(x) = \\frac{p(x)}{q(x)}$。\n- 用于混合建模的次要密度：$r(x) = \\frac{1}{2}\\,\\mathbf{1}_{[0, 2]}(x)$。\n- 混合提议 PDF：$q_{\\varepsilon}(x) = (1 - \\varepsilon)\\,q(x) + \\varepsilon\\,r(x)$，其中 $\\varepsilon \\in (0, 1)$。\n\n**第2步：使用提取的已知条件进行验证**\n- **科学基础：** 该问题是计算统计学中的一个标准练习，特别是蒙特卡洛方法。重要性采样、概率密度、期望、偏差和方差等概念都是公认的数学和统计学原理。该设置是合理的。\n- **良构的：** 问题为密度 $p$、$q$ 和 $r$ 提供了具体的函数形式，并定义了估计量和感兴趣的量。它要求评估几个精确的陈述，这是一个明确定义的任务。\n- **客观的：** 问题是用精确、客观的数学语言陈述的。\n- **不完整或矛盾的设置：** 提供了所有必要的信息。密度函数定义良好且积分为 1。没有矛盾之处。\n- **不切实际或不可行：** 该设置是一个简化的理论案例，旨在说明重要性采样中的一个关键概念。它在物理上并非不切实际。\n- **病态或结构不良：** 所用术语在计算科学和统计学领域是标准且明确的。\n\n**第3步：结论与行动**\n问题陈述是有效的。它提出了一个清晰、一致且可解决的问题，植根于既定的统计理论。我将继续进行解答。\n\n### 求解推导\n\n待估计的量是在分布 $p$ 下 $g(X)$ 的期望值：\n$$\n\\mu = \\mathbb{E}_{p}[g(X)] = \\int_{-\\infty}^{\\infty} g(x)p(x)dx\n$$\n重要性采样的目标是通过从另一个分布 $q$ 中抽取样本并重新加权来估计这个值。基本恒等式为：\n$$\n\\mu = \\int_{-\\infty}^{\\infty} g(x) \\frac{p(x)}{q(x)} q(x) dx = \\mathbb{E}_{q}\\left[g(X)\\frac{p(X)}{q(X)}\\right]\n$$\n这个恒等式成立的充要条件是 $p$ 的支撑集是 $q$ 的支撑集的子集，即 $p(x)  0 \\implies q(x)  0$。这个条件也写作 $p$ 相对于 $q$ 绝对连续 ($p \\ll q$)。\n\n对于大小为 $n$ 的样本，标准（或“普通”）重要性采样估计量是：\n$$\n\\hat{\\mu}_{n} = \\frac{1}{n} \\sum_{i=1}^n g(X_i) w(X_i), \\quad \\text{其中 } X_i \\overset{\\text{i.i.d.}}{\\sim} q \\text{ 且 } w(x) = \\frac{p(x)}{q(x)}.\n$$\n该估计量的期望是：\n$$\n\\mathbb{E}[\\hat{\\mu}_{n}] = \\mathbb{E}_{q}\\left[g(X)w(X)\\right] = \\int_{\\{x: q(x)  0\\}} g(x)\\frac{p(x)}{q(x)} q(x) dx = \\int_{\\{x: q(x)  0\\}} g(x)p(x)dx.\n$$\n如果 $\\mathbb{E}[\\hat{\\mu}_{n}] = \\mu$，则估计量是无偏的。这要求 $\\int_{\\{x: q(x)  0\\}} g(x)p(x)dx = \\int_{\\{x: p(x)  0\\}} g(x)p(x)dx$，它成立的充要条件是 $\\int_{\\{x: p(x)0, q(x)=0\\}} g(x)p(x)dx = 0$。\n\n在这个问题中：\n- $p$ 的支撑集是 $\\text{supp}(p) = [0, 2]$。\n- $q$ 的支撑集是 $\\text{supp}(q) = [0, 1.5]$。\n$p(x)  0$ 且 $q(x) = 0$ 的集合是区间 $(1.5, 2]$。由于在此区间上 $p(x) = 1/2  0$，因此该估计量是有偏的，除非 $\\int_{1.5}^{2} g(x) dx = 0$。\n\n### 逐项分析\n\n**A. 对于 $g(x) = 1$，使用 $q$ 的标准重要性采样估计量对于 $\\mu$ 是无偏的。**\n\n首先，我们求出真实值 $\\mu$。对于 $g(x) = 1$：\n$$\n\\mu = \\mathbb{E}_{p}[1] = \\int_{0}^{2} 1 \\cdot p(x) dx = \\int_{0}^{2} \\frac{1}{2} dx = \\frac{1}{2} [x]_{0}^{2} = 1.\n$$\n接下来，我们求出估计量 $\\hat{\\mu}_{n}$ 的期望。样本 $X_i$ 是从 $q$ 中抽取的，其支撑集为 $[0, 1.5]$。\n$$\n\\mathbb{E}[\\hat{\\mu}_{n}] = \\int_{\\text{supp}(q)} g(x) \\frac{p(x)}{q(x)} q(x) dx = \\int_{0}^{1.5} 1 \\cdot p(x) dx = \\int_{0}^{1.5} \\frac{1}{2} dx = \\frac{1}{2} [x]_{0}^{1.5} = \\frac{1.5}{2} = 0.75.\n$$\n由于 $\\mathbb{E}[\\hat{\\mu}_{n}] = 0.75$ 且 $\\mu = 1$，该估计量是有偏的。\n\n结论：**错误**。\n\n**B. $p$ 相对于 $q$ 绝对连续的条件（即 $p \\ll q$）在此不成立。因此，除非 $g(x)$ 在 $[1.5, 2]$ 上为 0，否则使用 $q$ 的标准重要性采样估计量是有偏的。**\n\n绝对连续性条件 $p \\ll q$ 要求 $\\text{supp}(p) \\subseteq \\text{supp}(q)$。这里，$\\text{supp}(p) = [0, 2]$ 且 $\\text{supp}(q) = [0, 1.5]$。由于 $[0, 2] \\not\\subseteq [0, 1.5]$，该条件不成立。陈述的这部分是正确的。\n\n估计量的偏差由下式给出：\n$$\n\\text{Bias} = \\mathbb{E}[\\hat{\\mu}_{n}] - \\mu = \\int_{\\text{supp}(q)} g(x)p(x)dx - \\int_{\\text{supp}(p)} g(x)p(x)dx = -\\int_{\\text{supp}(p) \\setminus \\text{supp}(q)} g(x)p(x)dx.\n$$\n在这种情况下，这变成：\n$$\n\\text{Bias} = -\\int_{1.5}^{2} g(x)p(x)dx = -\\frac{1}{2} \\int_{1.5}^{2} g(x)dx.\n$$\n该估计量无偏的充要条件是这个偏差项为零。由于在 $(1.5, 2]$ 上 $p(x)  0$，这要求 $\\int_{1.5}^{2} g(x)dx = 0$。“$g(x) = 0$ on $[1.5, 2]$”是使这个积分为零的一个充分条件。对于一个一般的非负函数 $g$，它（几乎处处）也是一个必要条件。因此，该陈述准确地指出了支撑集条件的失效及其对偏差的直接影响，以及能够消除此偏差的关于 $g$ 的条件。\n\n结论：**正确**。\n\n**C. 使用混合提议分布 $q_{\\varepsilon}$ 可以为任何有界函数 $g$ 恢复无偏性，并得到一个方差有限的重要性采样估计量；然而，当 $\\varepsilon \\to 0$ 时，方差可能变得任意大。**\n\n混合提议分布是 $q_{\\varepsilon}(x) = (1 - \\varepsilon)\\,q(x) + \\varepsilon\\,r(x)$。由于 $\\text{supp}(q) = [0, 1.5]$ 且 $\\text{supp}(r) = [0, 2]$，混合分布的支撑集是 $\\text{supp}(q_{\\varepsilon}) = [0, 2]$。这与 $p(x)$ 的支撑集相匹配，因此 $p \\ll q_{\\varepsilon}$。这保证了使用 $q_{\\varepsilon}$ 的重要性采样估计量对于任何有界函数 $g$ 都是无偏的。\n\n估计量的方差与加权样本的二阶矩有关，这涉及到积分 $\\int g(x)^2 \\frac{p(x)^2}{q_{\\varepsilon}(x)} dx$。为使方差有限，该积分必须收敛。\n让我们分析在有问题的区间 $(1.5, 2]$ 上的被积函数。在这个区间上，$q(x) = 0$ 且 $p(x)=r(x)=1/2$。所以，$q_{\\varepsilon}(x) = \\varepsilon r(x) = \\varepsilon/2$。\n来自该区间的对方案差积分的贡献是：\n$$\n\\int_{1.5}^{2} g(x)^2 \\frac{p(x)^2}{q_{\\varepsilon}(x)} dx = \\int_{1.5}^{2} g(x)^2 \\frac{(1/2)^2}{\\varepsilon/2} dx = \\frac{1}{2\\varepsilon} \\int_{1.5}^{2} g(x)^2 dx.\n$$\n由于 $g$ 是有界的，对于任何固定的 $\\varepsilon  0$，这个积分是有限的。在 $[0, 1.5]$ 上的积分也是有限的，因为 $q_{\\varepsilon}(x)$ 被一个正常数从下方界定。因此，对于任何 $\\varepsilon \\in (0, 1)$，方差都是有限的。\n\n然而，当 $\\varepsilon \\to 0$ 时，项 $\\frac{1}{2\\varepsilon} \\int_{1.5}^{2} g(x)^2 dx$ 将发散到无穷大，除非 $g(x)=0$ 在 $(1.5, 2]$上。因此，当 $\\varepsilon \\to 0$ 时，方差可能变得任意大。该陈述在所有三点上都是正确的。\n\n结论：**正确**。\n\n**D. 将权重 $\\frac{p(x)}{q(x)}$ 乘以一个固定常数以限制其大小，可以防止偏差并确保方差有限，即使 $q$ 在 $p$ 的支撑集部分区域上的密度为零。**\n\n这种技术被称为权重截断。可以定义一个新权重 $w'(x) = \\min(w(x), C)$，其中 $C$ 是某个上限。得到的估计量是 $\\hat{\\mu}'_n = \\frac{1}{n} \\sum g(X_i) w'(X_i)$。其期望是 $\\mathbb{E}[\\hat{\\mu}'_n] = \\mathbb{E}_q[g(X) \\min(w(X), C)]$。这不等于 $\\mathbb{E}_q[g(X)w(X)]$，所以这个过程为了控制方差而*引入*了偏差。声称它“防止偏差”是错误的。\n此外，在当前问题中，问题不在于权重过大，而是在区域 $(1.5, 2]$ 完全缺乏样本。在采样区域 $[0, 1.5]$ 上的权重是常数：$w(x) = \\frac{p(x)}{q(x)} = \\frac{1/2}{2/3} = 3/4$。除非 $C  3/4$，否则对其进行限制没有效果。更重要的是，这种技术无法从 $(1.5, 2]$ 区域收集信息，因此由支撑集不匹配引起的偏差仍然存在。该陈述存在根本性缺陷。\n\n结论：**错误**。\n\n**E. 改用自归一化重要性采样 (SNIS) 估计量无需满足支撑集覆盖条件；即使在 $p(x)  0$ 而 $q$ 的密度为零的区域，无偏性仍然成立。**\n\n自归一化重要性采样 (SNIS) 估计量是 $\\hat{\\mu}_{SNIS} = \\frac{\\sum_{i=1}^n g(X_i) w(X_i)}{\\sum_{i=1}^n w(X_i)}$。这个估计量是随机变量的比率，对于有限样本量 $n$，即使在支撑集条件成立的情况下，它通常也是有偏的。它的主要优点是当 $p$ 仅在相差一个归一化常数的情况下已知时也能工作。对于有限的 $n$，“无偏性成立”的说法从一开始就是错误的。\n\n我们来检查一致性（当 $n \\to \\infty$ 时它是否收敛到 $\\mu$）。根据大数定律：\n- 分子平均值：$\\frac{1}{n}\\sum g(X_i)w(X_i) \\to \\mathbb{E}_q[g(X)w(X)] = \\int_{0}^{1.5} g(x)p(x)dx$。\n- 分母平均值：$\\frac{1}{n}\\sum w(X_i) \\to \\mathbb{E}_q[w(X)] = \\int_{0}^{1.5} p(x)dx$。\n\n因此，当 $n \\to \\infty$ 时，$\\hat{\\mu}_{SNIS} \\to \\frac{\\int_{0}^{1.5} g(x)p(x)dx}{\\int_{0}^{1.5} p(x)dx}$。这是关于 $g(X)$ 的期望值，但其概率分布是 $p(x)$ 被截断到 $[0, 1.5]$ 并重新归一化后的版本。这通常不等于 $\\mu = \\int_{0}^{2} g(x)p(x)dx$。例如，如果 $g(x) = x$，我们在思考过程中发现极限是 $0.75$，而真实值是 $1$。该估计量不是一致的，更不用说无偏了。支撑集条件 $p \\ll q$ 对于 SNIS 的一致性同样至关重要。\n\n结论：**错误**。",
            "answer": "$$\\boxed{BC}$$"
        },
        {
            "introduction": "重要性抽样最强大的应用之一，是在大型复杂系统中估计稀有事件的概率。这个计算实践项目将挑战你从零开始构建一个重要性采样器来解决这类问题。你将实现一种名为指数倾斜的常用策略，并学习处理在实际应用中出现的数值稳定性等工程挑战。",
            "id": "3241899",
            "problem": "考虑一个组合搜索空间，定义为集合 $\\mathcal{X} = \\{1,2,\\dots,m\\}^n$，该集合包含所有序列 $x = (x_1,x_2,\\dots,x_n)$，其中每个坐标 $x_i$ 是介于 $1$ 和 $m$ 之间的整数。一个从 $\\mathcal{X}$ 中均匀采样的随机搜索算法，在 $\\mathcal{X}$ 上引入了一个目标分布 $p(x)$，其中对每个 $x \\in \\mathcal{X}$ 都有 $p(x) = m^{-n}$。在 $\\mathcal{X}$ 上定义一个实值成本函数 $C(x)$，其形式为\n$$\nC(x) = \\sum_{i=1}^{n} a_i x_i,\n$$\n其中 $a_i  0$ 是固定系数。对于给定的阈值 $T  0$，如果 $C(x) \\le T$，则称解 $x$ 是令人满意的。我们感兴趣的量是概率\n$$\n\\pi = \\mathbb{P}_p\\big(C(X) \\le T\\big),\n$$\n其中 $X \\sim p$。\n\n根据期望和概率的定义以及测度变换原理，推导出一个可计算的 $\\pi$ 的重要性抽样估计量。该估计量使用一个在 $\\mathcal{X}$ 上易于处理的提议分布 $q(x)$，此分布构造为独立的、坐标级分布的乘积。具体来说，设 $q(x)$ 由独立坐标定义为\n$$\nq(x) = \\prod_{i=1}^{n} q_i(x_i),\n$$\n对于给定的参数 $\\beta \\ge 0$，\n$$\nq_i(k) \\propto \\exp\\big(-\\beta\\, a_i\\, k\\big), \\quad k \\in \\{1,2,\\dots,m\\}。\n$$\n必须包含每个坐标的归一化常数，以使 $q_i$ 成为 $\\{1,2,\\dots,m\\}$ 上的有效概率质量函数。使用此提议分布，实现一个程序，该程序：\n- 从 $q$ 中抽取 $N$ 个独立点 $X^{(1)}, X^{(2)}, \\dots, X^{(N)}$。\n- 为每个抽样点计算一个具有理论依据的重要性权重 $w(x)$。\n- 基于抽样点及其权重，生成 $\\pi$ 的估计量 $\\hat{\\pi}$。\n\n您必须通过在适当情况下在对数空间中进行运算，来确保在 $n$ 和 $m$ 较大时的数值稳定性。使用固定的伪随机种子，以使结果可复现。所有的抽样和估计都应是纯数学的，无单位。\n\n您的程序必须解决以下参数设置的测试套件。对于每个测试用例，返回单个重要性抽样估计值 $\\hat{\\pi}$，形式为浮点数：\n\n- 测试用例 1（一般情况）：$n = 12$, $m = 10$, $a_i = i$ 对于 $i = 1,2,\\dots,12$, $T = 300$, $\\beta = 0.2$, $N = 30000$, 种子 $= 42$。\n- 测试用例 2（通过 $\\beta = 0$ 实现的均匀基线）：$n = 12$, $m = 10$, $a_i = i$ 对于 $i = 1,2,\\dots,12$, $T = 300$, $\\beta = 0.0$, $N = 30000$, 种子 $= 43$。\n- 测试用例 3（稀有事件强调）：$n = 20$, $m = 20$, $a_i = ((i-1) \\bmod 5) + 1$ 对于 $i = 1,2,\\dots,20$, $T = 200$, $\\beta = 0.3$, $N = 40000$, 种子 $= 44$。\n- 测试用例 4（每个样本都满足条件的边界情况）：$n = 8$, $m = 15$, $a_i = 2$ 对于所有 $i$, $T = 240$, $\\beta = 0.5$, $N = 10000$, 种子 $= 45$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个浮点数四舍五入到六位小数，例如 $[r_1,r_2,r_3,r_4]$，其中每个 $r_j$ 对应于上面给出的第 $j$ 个测试用例的估计值。",
            "solution": "用户希望找到一个概率的重要性抽样估计量并加以实现。\n\n### 步骤1：问题验证\n\n问题是估计概率 $\\pi = \\mathbb{P}_p(C(X) \\le T)$，其中搜索空间为 $\\mathcal{X} = \\{1,2,\\dots,m\\}^n$，目标分布为均匀分布 $p(x) = m^{-n}$，成本函数为 $C(x) = \\sum_{i=1}^{n} a_i x_i$。必须使用带有特定提议分布 $q(x)$ 的重要性抽样进行估计。\n\n**提取的已知条件：**\n- **搜索空间**：$\\mathcal{X} = \\{1,2,\\dots,m\\}^n$。\n- **目标分布**：$p(x) = m^{-n}$ 对于所有 $x \\in \\mathcal{X}$。\n- **成本函数**：$C(x) = \\sum_{i=1}^{n} a_i x_i$，其中 $a_i  0$。\n- **关注事件**：$C(x) \\le T$，对于阈值 $T  0$。\n- **关注量**：$\\pi = \\mathbb{P}_p\\big(C(X) \\le T\\big)$。\n- **提议分布**：$q(x) = \\prod_{i=1}^{n} q_i(x_i)$，其中 $q_i(k) \\propto \\exp(-\\beta\\, a_i\\, k)$ 对于 $k \\in \\{1,2,\\dots,m\\}$ 和 $\\beta \\ge 0$。\n- **实现细节**：使用 $N$ 个样本，使用对数空间确保数值稳定性，使用固定种子，并解决四个指定的测试用例。\n\n**使用提取的已知条件进行验证：**\n1.  **科学性**：该问题是重要性抽样的一个标准应用，重要性抽样是蒙特卡洛方法中的一项基本技术，广泛应用于物理学、统计学和科学计算中。其数学公式基于已建立的概率论。该问题有效。\n2.  **良态性**：每个测试用例的所有参数（$n, m, a_i, T, \\beta, N$，种子）都已指定。要估计的分布和量都得到了明确的定义。可以推导出估计量的唯一形式。该问题有效。\n3.  **客观性**：问题使用形式化的数学语言陈述，所有术语都有明确定义。它不含主观性。该问题有效。\n4.  **完整性与一致性**：问题是自包含的，并提供了所有必要的信息。要求对提议分布进行归一化，这与概率质量函数的定义是一致的。该问题有效。\n5.  **可行性**：指定的参数在计算可行的范围内。提示正确地预见到了数值稳定性问题，并建议使用对数空间，这是一种标准做法。该问题有效。\n\n**结论**：该问题有效且定义明确。我将继续推导并实现解决方案。\n\n### 步骤2：重要性抽样估计量的推导\n\n概率 $\\pi$ 可以表示为关于目标分布 $p(x)$ 的指示函数 $\\mathbb{I}(\\cdot)$ 的期望：\n$$\n\\pi = \\mathbb{E}_p[\\mathbb{I}(C(X) \\le T)] = \\sum_{x \\in \\mathcal{X}} p(x) \\mathbb{I}(C(x) \\le T)\n$$\n利用测度变换原理，我们引入提议分布 $q(x)$，将期望重写为关于 $q$ 的期望：\n$$\n\\pi = \\sum_{x \\in \\mathcal{X}} \\frac{p(x)}{q(x)} q(x) \\mathbb{I}(C(x) \\le T) = \\mathbb{E}_q\\left[\\frac{p(X)}{q(X)} \\mathbb{I}(C(X) \\le T)\\right]\n$$\n项 $w(x) = \\frac{p(x)}{q(x)}$ 是重要性权重。重要性抽样估计量 $\\hat{\\pi}$ 是基于从 $q(x)$ 中抽取的 $N$ 个样本 $X^{(j)}$ 的这个新量的样本均值：\n$$\n\\hat{\\pi} = \\frac{1}{N} \\sum_{j=1}^{N} w(X^{(j)}) \\mathbb{I}(C(X^{(j)}) \\le T)\n$$\n\n要实现这一点，我们需要 $p(x)$、$q(x)$ 和 $w(x)$ 的显式形式。\n目标分布是 $p(x) = m^{-n}$。\n提议分布是 $q(x) = \\prod_{i=1}^{n} q_i(x_i)$。每个坐标级分布 $q_i$ 都必须被归一化：\n$$\nq_i(k) = \\frac{\\exp(-\\beta a_i k)}{Z_i}, \\quad \\text{对于 } k \\in \\{1, 2, \\dots, m\\}\n$$\n其中 $Z_i$ 是归一化常数（配分函数）：\n$$\nZ_i = \\sum_{k=1}^{m} \\exp(-\\beta a_i k)\n$$\n完整的提议分布是 $q(x) = \\frac{\\exp(-\\beta \\sum_{i=1}^n a_i x_i)}{\\prod_{i=1}^n Z_i} = \\frac{\\exp(-\\beta C(x))}{\\prod_{i=1}^n Z_i}$。\n\n重要性权重 $w(x)$ 是：\n$$\nw(x) = \\frac{p(x)}{q(x)} = \\frac{m^{-n}}{\\frac{\\exp(-\\beta C(x))}{\\prod_{i=1}^n Z_i}} = m^{-n} \\exp(\\beta C(x)) \\prod_{i=1}^n Z_i\n$$\n\n### 步骤3：数值实现与对数空间计算\n\n直接计算 $m^{-n}$ 和许多项的乘积在数值上是不稳定的。我们必须在对数空间中进行运算。\n\n重要性权重的对数是：\n$$\n\\log w(x) = \\log(m^{-n}) + \\log(\\exp(\\beta C(x))) + \\log\\left(\\prod_{i=1}^n Z_i\\right)\n$$\n$$\n\\log w(x) = -n \\log m + \\beta C(x) + \\sum_{i=1}^n \\log Z_i\n$$\n为了保证稳定性，归一化常数 $\\log Z_i$ 使用 log-sum-exp 技巧进行计算：\n$$\n\\log Z_i = \\log\\left(\\sum_{k=1}^{m} \\exp(-\\beta a_i k)\\right)\n$$\n设 $v_k = -\\beta a_i k$。设 $v_{\\max} = \\max_{k} \\{v_k\\} = -\\beta a_i$（因为 $a_i  0, \\beta \\ge 0, k \\ge 1$）。\n$$\n\\log Z_i = v_{\\max} + \\log\\left(\\sum_{k=1}^{m} \\exp(v_k - v_{\\max})\\right)\n$$\n在 $\\beta=0$ 的特殊情况下，$q_i(k)$ 成为 $\\{1,\\dots,m\\}$ 上的均匀分布，因此 $q_i(k) = 1/m$。在这种情况下，$q(x) = p(x)$，且所有权重 $w(x)=1$。我们的公式必须正确处理这种情况：如果 $\\beta=0$，则 $\\exp(-\\beta a_i k)=1$，所以 $Z_i = \\sum_{k=1}^m 1 = m$，且 $\\log Z_i = \\log m$。对数权重变为 $\\log w(x) = -n \\log m + 0 \\cdot C(x) + \\sum_{i=1}^n \\log m = -n \\log m + n \\log m = 0$，因此 $w(x)=1$，符合预期。\n\n然后可以按如下方式计算估计量：\n$$\n\\hat{\\pi} = \\frac{1}{N} \\sum_{j=1}^{N} \\mathbb{I}(C(X^{(j)}) \\le T) \\exp(\\log w(X^{(j)}))\n$$\n\n### 算法\n对于每个测试用例：\n1.  **设置**：初始化参数 $n, m, a, T, \\beta, N$，并使用给定的种子初始化随机数生成器。\n2.  **预计算**：\n    a. 对于每个坐标 $i \\in \\{1, \\dots, n\\}$，计算 $\\log Z_i$。单独处理 $\\beta=0$ 的情况。\n    b. 对于每个坐标 $i$，计算概率质量函数（PMF）向量 $P_i = [q_i(1), \\dots, q_i(m)]$。概率为 $q_i(k) = \\exp(-\\beta a_i k - \\log Z_i)$。\n3.  **抽样**：\n    a. 创建一个 $N \\times n$ 的矩阵来存储样本。\n    b. 对于每个坐标 $i$，从由 PMF $P_i$ 定义的离散分布中抽取 $N$ 个样本，并将其存储在矩阵的第 $i$ 列。这可以使用逆变换采样或库函数（如 `numpy.random.choice`）来完成。\n4.  **估计**：\n    a. 对于 $N$ 个样本向量中的每一个 $X^{(j)}$，计算成本 $C(X^{(j)}) = \\sum_i a_i X_i^{(j)}$。这可以向量化为矩阵-向量乘积。\n    b. 识别出 $C(X^{(j)}) \\le T$ 的样本。\n    c. 仅对这些令人满意的样本，计算对数权重 $\\log w(X^{(j)})$。\n    d. 通过指数运算将对数权重转换为权重并求和。\n    e. 将总和除以 $N$ 以获得最终估计值 $\\hat{\\pi}$。\n\n此过程提供了一种数值稳定且理论上可靠的方法来计算所需的估计值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a set of importance sampling problems.\n    \"\"\"\n    test_cases = [\n        # (n, m, a_rule, T, beta, N, seed)\n        (12, 10, 'i',      300, 0.2, 30000, 42),\n        (12, 10, 'i',      300, 0.0, 30000, 43),\n        (20, 20, 'mod',    200, 0.3, 40000, 44),\n        ( 8, 15, 'const',  240, 0.5, 10000, 45),\n    ]\n\n    results = []\n    \n    for n, m, a_rule, T, beta, N, seed in test_cases:\n        rng = np.random.default_rng(seed)\n\n        # 1. Generate 'a' vector based on rule\n        if a_rule == 'i':\n            a = np.arange(1, n + 1, dtype=np.float64)\n        elif a_rule == 'mod':\n            a = ((np.arange(n)) % 5) + 1.0\n        elif a_rule == 'const':\n            a = np.full(n, 2.0)\n\n        # 2. Pre-compute log_Z and sampling distributions (PMFs)\n        log_Z = np.zeros(n)\n        all_pmfs = []\n        k_vals = np.arange(1, m + 1, dtype=np.float64)\n\n        for i in range(n):\n            if beta == 0.0:\n                log_Z[i] = np.log(m)\n                pmf = np.full(m, 1.0 / m)\n            else:\n                # Use log-sum-exp trick for numerical stability\n                v = -beta * a[i] * k_vals\n                # v_max is the first element since k_vals is increasing and arg is negative\n                v_max = v[0] \n                log_Z[i] = v_max + np.log(np.sum(np.exp(v - v_max)))\n                \n                # Compute Probability Mass Function (PMF)\n                log_pmf = v - log_Z[i]\n                pmf = np.exp(log_pmf)\n            \n            # Normalize to correct for minute floating-point inaccuracies\n            pmf /= np.sum(pmf)\n            all_pmfs.append(pmf)\n\n        # 3. Generate N samples from the proposal distribution q(x)\n        samples = np.zeros((N, n), dtype=int)\n        for i in range(n):\n            samples[:, i] = rng.choice(k_vals, size=N, p=all_pmfs[i])\n            \n        # 4. Compute costs for all N samples (vectorized)\n        costs = samples @ a\n        \n        # 5. Filter for satisfactory samples\n        satisfactory_mask = costs = T\n        satisfactory_costs = costs[satisfactory_mask]\n        \n        pi_hat = 0.0\n        if satisfactory_costs.size > 0:\n            # 6. Compute importance weights for satisfactory samples\n            log_w_const = -n * np.log(m) + np.sum(log_Z)\n            log_weights = beta * satisfactory_costs + log_w_const\n            \n            # 7. Sum weights and compute the final estimator\n            # The sum is only over the satisfactory samples as per the estimator formula\n            total_sum_of_weights = np.sum(np.exp(log_weights))\n            pi_hat = total_sum_of_weights / N\n            \n        results.append(f\"{pi_hat:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}