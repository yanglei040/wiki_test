{
    "hands_on_practices": [
        {
            "introduction": "本练习旨在解决分层抽样中的一个核心问题：如何在不同层之间最有效地分配固定数量的样本。为了达到最高的整体精度，我们不能简单地平均分配样本。这个实践练习  将引导您从第一性原理出发，推导出著名的奈曼分配（Neyman Allocation）原则，证明一个层的最佳样本数量应与其规模和内部变异性成正比。",
            "id": "3198743",
            "problem": "考虑一个计算实验，旨在估计一个二元属性在某个定义域划分上的直方图，该定义域被划分为3个由 $k \\in \\{1,2,3\\}$ 索引的不相交区间。在区间 $k$ 中，每个抽样项都会产生一个独立的伯努利结果，其成功概率为 $p_{k} \\in (0,1)$，且各区间的单位样本成本相同。您计划在区间 $k$ 中收集 $n_{k}$ 个样本，总抽样预算受约束 $\\sum_{k=1}^{3} n_{k} = N$，其中 $N$ 是一个固定的正整数。对于每个区间 $k$，您通过在该区间收集的伯努利结果的样本均值 $\\hat{p}_{k}$ 来估计该区间的成功概率 $p_{k}$。您的目标是选择分配方案 $(n_{1}, n_{2}, n_{3})$，以最小化所有区间上估计量 $\\hat{p}_{k}$ 的均方误差 (MSE) 之和。\n\n请从伯努利抽样的基本性质和均方误差 (MSE) 的定义出发，推导出在约束条件 $\\sum_{k=1}^{3} n_{k} = N$ 下最小化总 MSE 的分配方案。然后，用 $N$, $p_{1}$, $p_{2}$ 和 $p_{3}$ 来表示区间 2 的最优分配，即 $n_{2}$ 的闭式表达式。请以精确形式给出 $n_{2}$ 的最终表达式，无需四舍五入。",
            "solution": "问题是在3个不相交的区间（由索引 $k \\in \\{1, 2, 3\\}$ 表示）中，找到总样本量 $N$ 的最优分配方案，以最小化各区间成功概率 $p_k$ 的估计量的总均方误差 (MSE)。该问题是适定的，并有坚实的统计学和优化原理作为科学依据。我们将进行完整的推导。\n\n首先，我们来定义区间 $k$ 中成功概率 $p_k$ 的估计量。我们收集 $n_k$ 个样本，其中每个样本都是一次独立的伯努利试验。令 $X_{k,i}$ (其中 $i=1, \\dots, n_k$) 为区间 $k$ 中第 $i$ 次试验结果的随机变量，成功时 $X_{k,i}=1$，失败时 $X_{k,i}=0$。成功概率为 $P(X_{k,i}=1) = p_k$。$p_k$ 的估计量，记为 $\\hat{p}_k$，是样本均值：\n$$\n\\hat{p}_k = \\frac{1}{n_k} \\sum_{i=1}^{n_k} X_{k,i}\n$$\n目标是最小化这些估计量各自的均方误差之和。参数 $\\theta$ 的估计量 $\\hat{\\theta}$ 的 MSE 定义为 $\\text{MSE}(\\hat{\\theta}) = E[(\\hat{\\theta} - \\theta)^2]$。MSE 也可以表示为估计量的方差与其偏差平方之和：$\\text{MSE}(\\hat{\\theta}) = \\text{Var}(\\hat{\\theta}) + (\\text{Bias}(\\hat{\\theta}))^2$。\n\n我们首先确定 $\\hat{p}_k$ 的 MSE。我们先计算其期望值以求得偏差。\n$$\nE[\\hat{p}_k] = E\\left[\\frac{1}{n_k} \\sum_{i=1}^{n_k} X_{k,i}\\right] = \\frac{1}{n_k} \\sum_{i=1}^{n_k} E[X_{k,i}]\n$$\n由于每个 $X_{k,i}$ 是参数为 $p_k$ 的伯努利随机变量，其期望值为 $E[X_{k,i}] = p_k$。\n$$\nE[\\hat{p}_k] = \\frac{1}{n_k} \\sum_{i=1}^{n_k} p_k = \\frac{1}{n_k} (n_k p_k) = p_k\n$$\n该估计量的偏差为 $\\text{Bias}(\\hat{p}_k) = E[\\hat{p}_k] - p_k = p_k - p_k = 0$。估计量 $\\hat{p}_k$ 是无偏的。\n由于偏差为零，MSE 等于估计量的方差：\n$$\n\\text{MSE}(\\hat{p}_k) = \\text{Var}(\\hat{p}_k)\n$$\n现在，我们计算 $\\hat{p}_k$ 的方差。由于样本 $X_{k,i}$ 是独立的，其和的方差等于各自方差之和。\n$$\n\\text{Var}(\\hat{p}_k) = \\text{Var}\\left(\\frac{1}{n_k} \\sum_{i=1}^{n_k} X_{k,i}\\right) = \\frac{1}{n_k^2} \\text{Var}\\left(\\sum_{i=1}^{n_k} X_{k,i}\\right) = \\frac{1}{n_k^2} \\sum_{i=1}^{n_k} \\text{Var}(X_{k,i})\n$$\n参数为 $p_k$ 的伯努利随机变量的方差为 $\\text{Var}(X_{k,i}) = p_k(1-p_k)$。\n$$\n\\text{Var}(\\hat{p}_k) = \\frac{1}{n_k^2} \\sum_{i=1}^{n_k} p_k(1-p_k) = \\frac{1}{n_k^2} n_k p_k(1-p_k) = \\frac{p_k(1-p_k)}{n_k}\n$$\n因此，区间 $k$ 中估计量的 MSE 为：\n$$\n\\text{MSE}(\\hat{p}_k) = \\frac{p_k(1-p_k)}{n_k}\n$$\n我们要最小化的总 MSE 是所有区间的 MSE 之和：\n$$\nL(n_1, n_2, n_3) = \\sum_{k=1}^{3} \\text{MSE}(\\hat{p}_k) = \\sum_{k=1}^{3} \\frac{p_k(1-p_k)}{n_k}\n$$\n该最小化问题受限于总样本数的约束：\n$$\n\\sum_{k=1}^{3} n_k = N\n$$\n这是一个约束优化问题。我们可以使用拉格朗日乘数法来解决它。我们将样本量 $n_k$ 视为连续的正实数变量。拉格朗日函数 $\\mathcal{L}$ 为：\n$$\n\\mathcal{L}(n_1, n_2, n_3, \\lambda) = \\sum_{k=1}^{3} \\frac{p_k(1-p_k)}{n_k} + \\lambda \\left(\\sum_{k=1}^{3} n_k - N\\right)\n$$\n为求最小值，我们对 $\\mathcal{L}$ 关于每个 $n_k$ 求偏导数，并令其为零。对于每个 $k \\in \\{1, 2, 3\\}$：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial n_k} = -\\frac{p_k(1-p_k)}{n_k^2} + \\lambda = 0\n$$\n这意味着：\n$$\n\\lambda = \\frac{p_k(1-p_k)}{n_k^2}\n$$\n由此，我们可以用 $\\lambda$ 表示 $n_k$：\n$$\nn_k^2 = \\frac{p_k(1-p_k)}{\\lambda} \\implies n_k = \\frac{\\sqrt{p_k(1-p_k)}}{\\sqrt{\\lambda}}\n$$\n我们取正平方根，因为 $n_k$ 必须是正数。这个结果表明，给定区间的最优样本量 $n_k$ 与该区间伯努利过程的标准差 $\\sigma_k = \\sqrt{p_k(1-p_k)}$ 成正比。\n\n现在，我们使用约束条件 $\\sum_{k=1}^{3} n_k = N$ 来确定拉格朗日乘子 $\\lambda$ 的值。\n$$\n\\sum_{k=1}^{3} \\frac{\\sqrt{p_k(1-p_k)}}{\\sqrt{\\lambda}} = N\n$$\n$$\n\\frac{1}{\\sqrt{\\lambda}} \\sum_{k=1}^{3} \\sqrt{p_k(1-p_k)} = N\n$$\n求解 $\\frac{1}{\\sqrt{\\lambda}}$：\n$$\n\\frac{1}{\\sqrt{\\lambda}} = \\frac{N}{\\sum_{j=1}^{3} \\sqrt{p_j(1-p_j)}}\n$$\n现在将此结果代回到 $n_k$ 的表达式中：\n$$\nn_k = \\sqrt{p_k(1-p_k)} \\left( \\frac{1}{\\sqrt{\\lambda}} \\right) = \\sqrt{p_k(1-p_k)} \\left( \\frac{N}{\\sum_{j=1}^{3} \\sqrt{p_j(1-p_j)}} \\right)\n$$\n这就得到了最优分配 $n_k$ 的通用公式：\n$$\nn_k = N \\frac{\\sqrt{p_k(1-p_k)}}{\\sum_{j=1}^{3} \\sqrt{p_j(1-p_j)}}\n$$\n问题具体要求的是区间 2 的最优分配的闭式表达式，即 $n_2$。将 $k=2$ 代入通用公式可得：\n$$\nn_2 = N \\frac{\\sqrt{p_2(1-p_2)}}{\\sqrt{p_1(1-p_1)} + \\sqrt{p_2(1-p_2)} + \\sqrt{p_3(1-p_3)}}\n$$\n这就是区间 2 的最优样本数的最终表达式，它用总样本量 $N$ 和各区间的成功概率 $p_1, p_2, p_3$ 表示。这种分配策略是分层抽样中 Neyman 分配的一种变体。",
            "answer": "$$\n\\boxed{N \\frac{\\sqrt{p_2(1-p_2)}}{\\sqrt{p_1(1-p_1)} + \\sqrt{p_2(1-p_2)} + \\sqrt{p_3(1-p_3)}}}\n$$"
        },
        {
            "introduction": "分层抽样是蒙特卡洛积分等计算方法中一种强大的方差缩减技术。这个动手编程问题  要求您比较两种构建分层来估计积分的方法：一种是简单的等宽划分，另一种是更精巧的、基于函数导数大小的划分策略。这将让您亲身体验到，智能地设计分层如何能用相同的计算量换取更精确的结果。",
            "id": "3198834",
            "problem": "你需要设计并实现一个完整的、可运行的程序，该程序使用分层抽样执行蒙特卡罗积分，以估算函数 $f(x)=\\exp(x)$ 在区间 $[0,1]$ 上的积分，并比较两种分层方案：等宽分层和由导数大小确定的非均匀宽度分层。程序必须遵循从积分和概率的第一性原理推导出的 principled algorithm（有原则的算法）。计算框架如下。\n\n从黎曼积分与均匀分布下的期望之间的基本等价性出发：对于 $[a,b]$ 上的任何可积函数 $f$，其积分满足\n$$\n\\int_a^b f(x)\\,dx \\;=\\; (b-a)\\,\\mathbb{E}\\big[f(U)\\big],\n$$\n其中 $U$ 是一个在 $[a,b]$ 上均匀分布的随机变量。这个恒等式为通过函数在均匀分布下的期望值来进行蒙特卡罗（随机化）积分估计提供了理论依据。分层抽样将区间划分为多个子区间（层），并分别估计每一层的贡献，然后将这些贡献作为加权和进行组合。其关键思想是，当分层结构能够捕捉被积函数的异质性时，划分可以减少方差。\n\n你的实现必须：\n- 使用 $K$ 个分层来划分 $[0,1]$，并采用两种方案：\n  1. 等宽方案：选择边界 $0=b_0  b_1  \\dots  b_K=1$，其中 $b_i = i/K$。\n  2. 导数加权方案：选择边界 $0=b_0  b_1  \\dots  b_K=1$，使得在每个子区间 $[b_{i-1}, b_i]$ 上导数的绝对值 $|f'(x)|$ 的积分是恒定的。对于 $f(x) = \\exp(x)$，这意味着 $\\int_{b_{i-1}}^{b_i} \\exp(x) \\, dx = \\frac{\\exp(1)-1}{K}$。\n- 总样本量为 $N$。将这些样本近似均匀地分配给 $K$ 个层（即，某些层可能有 $\\lfloor N/K \\rfloor$ 个样本，而其他层可能有 $\\lfloor N/K \\rfloor+1$ 个样本）。\n- 对于每种方案，计算积分的蒙特卡罗估计值，并计算其与真实值 $\\exp(1)-1$ 的绝对误差。\n- 程序必须对给定的测试用例集运行，并以特定格式打印结果。您必须使用伪随机数生成器，并使用 `12345` 作为种子，以确保结果的可复现性。\n- 最终输出应为单行文本，包含一个方括号内的列表，其中每个元素是对应测试用例的结果三元组 `[error_eq,error_dw,is_dw_better]`，其中 `error_eq` 是等宽方案的误差，`error_dw` 是导数加权方案的误差（均四舍五入到8位小数），`is_dw_better` 是一个布尔值，当且仅当 `error_dw  error_eq` 时为 `True`。例如：`[[0.001...,0.000...,True],[...]]`",
            "solution": "本问题要求实现一个程序，使用分层抽样来估计函数 $f(x)=\\exp(x)$ 在 $[0,1]$ 上的积分，并比较两种分层策略的性能。\n\n### 算法逻辑与推导\n\n1.  **分层蒙特卡洛积分**：\n    积分 $\\int_0^1 f(x) dx$ 可以被分解为 $K$ 个子区间的积分之和：\n    $$\n    I = \\int_0^1 f(x) dx = \\sum_{i=1}^K \\int_{b_{i-1}}^{b_i} f(x) dx\n    $$\n    其中 $0 = b_0  b_1  \\dots  b_K = 1$ 是分层边界。\n    每个子积分 $I_i = \\int_{b_{i-1}}^{b_i} f(x) dx$ 可以通过蒙特卡洛方法估计。根据期望的定义，\n    $$\n    I_i = (b_i - b_{i-1}) \\mathbb{E}[f(U_i)]\n    $$\n    其中 $U_i$ 是在 $[b_{i-1}, b_i]$ 上均匀分布的随机变量。我们可以在第 $i$ 层抽取 $n_i$ 个样本 $x_{i,j} \\sim \\text{Uniform}(b_{i-1}, b_i)$，然后估计 $I_i$ 为：\n    $$\n    \\hat{I}_i = (b_i - b_{i-1}) \\frac{1}{n_i} \\sum_{j=1}^{n_i} f(x_{i,j})\n    $$\n    总积分的估计值是各层估计值之和：$\\hat{I} = \\sum_{i=1}^K \\hat{I}_i$。\n\n2.  **分层方案**：\n    -   **方案1：等宽分层**\n        这是最简单的分层方法。将区间 $[0,1]$ 均匀划分为 $K$ 个子区间。第 $i$ 个边界点为：\n        $$b_i = \\frac{i}{K} \\quad \\text{for } i=0, 1, \\dots, K$$\n    -   **方案2：导数加权分层**\n        这种方法旨在使每个子区间内被积函数的变化“总量”大致相等，从而更智能地分配层。我们要求每个子区间上导数绝对值的积分是常数。对于 $f(x)=\\exp(x)$，其导数 $f'(x)=\\exp(x)$ 在 $[0,1]$ 上恒为正，所以 $|f'(x)|=f'(x)$。\n        我们要求对所有 $i=1, \\dots, K$：\n        $$\n        \\int_{b_{i-1}}^{b_i} \\exp(x) dx = C\n        $$\n        其中 $C$ 是一个常数。所有子积分之和等于总积分：$\\sum_{i=1}^K \\int_{b_{i-1}}^{b_i} \\exp(x) dx = \\int_0^1 \\exp(x) dx = \\exp(1)-1$。因此，$K \\cdot C = e-1$，即 $C = \\frac{e-1}{K}$。\n        现在我们来求解边界 $b_i$。\n        $$\n        \\int_{b_{i-1}}^{b_i} \\exp(x) dx = [\\exp(x)]_{b_{i-1}}^{b_i} = \\exp(b_i) - \\exp(b_{i-1}) = \\frac{e-1}{K}\n        $$\n        这是一个递推关系。对于 $i=1, \\dots, K$：$\\exp(b_i) = \\exp(b_{i-1}) + \\frac{e-1}{K}$。\n        由于 $b_0=0$，$\\exp(b_0)=1$，我们可以得到通项公式：\n        $$\n        \\exp(b_i) = \\exp(b_0) + i \\cdot \\frac{e-1}{K} = 1 + i \\frac{e-1}{K}\n        $$\n        因此，边界点由以下公式给出：\n        $$\n        b_i = \\ln\\left(1 + i \\frac{e-1}{K}\\right) \\quad \\text{for } i=0, 1, \\dots, K\n        $$\n\n3.  **样本分配**：\n    问题要求将总样本量 $N$ 近似均匀地分配给 $K$ 个层。一个直接的方法是，先计算每个层的基础样本数 $n_{base} = \\lfloor N/K \\rfloor$，然后将余下的 $N \\pmod K$ 个样本逐一分配给前 $N \\pmod K$ 个层。\n\n4.  **实现细节**：\n    -   `stratified_monte_carlo` 函数接收分层边界、各层样本数和随机数生成器。\n    -   在函数内部，对每个层，它生成 $[0,1]$ 上的均匀随机数，然后通过线性变换 $x = b_{i-1} + u \\cdot (b_i - b_{i-1})$ 将它们映射到正确的子区间 $[b_{i-1}, b_i]$。\n    -   计算这些样本点上的函数值的均值，乘以层宽度，得到该层的积分估计。\n    -   累加所有层的估计值得到最终结果。\n    -   主函数 `solve` 负责设置测试用例，计算两种方案的边界，调用积分函数，计算绝对误差，并按要求格式化输出。\n    -   使用 `np.random.default_rng(12345)` 来确保结果的可复现性。",
            "answer": "```python\nimport numpy as np\n\ndef stratified_monte_carlo(f, boundaries, sample_counts, rng):\n    \"\"\"\n    Performs stratified Monte Carlo integration.\n\n    Args:\n        f (callable): The function to integrate.\n        boundaries (np.ndarray): An array of stratum boundaries, size K+1.\n        sample_counts (list): A list of sample counts per stratum, size K.\n        rng (np.random.Generator): The random number generator instance.\n\n    Returns:\n        float: The estimated value of the integral.\n    \"\"\"\n    total_integral_estimate = 0.0\n    num_strata = len(sample_counts)\n    \n    for i in range(num_strata):\n        b_lower = boundaries[i]\n        b_upper = boundaries[i+1]\n        width = b_upper - b_lower\n        n_samples = sample_counts[i]\n        \n        if n_samples == 0:\n            continue\n            \n        # Generate n_samples uniform samples in [0, 1]\n        u_samples = rng.uniform(size=n_samples)\n        \n        # Transform samples to the stratum interval [b_lower, b_upper]\n        x_samples = b_lower + u_samples * width\n        \n        # Evaluate the function at the sample points\n        y_samples = f(x_samples)\n        \n        # Estimate the integral for the current stratum and add to total\n        total_integral_estimate += width * np.mean(y_samples)\n        \n    return total_integral_estimate\n\ndef solve():\n    \"\"\"\n    Main function to run the Monte Carlo integration comparison.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1000, 5),\n        (1000, 1),\n        (100, 10),\n        (5000, 50),\n        (1024, 7),\n    ]\n\n    # Initialize the random number generator with the specified seed for reproducibility.\n    rng = np.random.default_rng(12345)\n\n    # Define the function to integrate, f(x) = exp(x).\n    f = lambda x: np.exp(x)\n\n    # Analytically compute the true value of the integral from 0 to 1.\n    true_integral = np.exp(1.0) - 1.0\n\n    # Store formatted results for all test cases.\n    all_results_str = []\n\n    for N, K in test_cases:\n        # Step 1: Determine sample allocation per stratum.\n        if K > 0:\n            n_base = N // K\n            remainder = N % K\n            sample_counts = [n_base + 1] * remainder + [n_base] * (K - remainder)\n        else: # Handle case K=0 or K=1 where N samples are in one stratum\n            sample_counts = [N] if K == 1 else []\n\n\n        # -- Scheme 1: Equal-width stratification --\n        boundaries_eq = np.linspace(0.0, 1.0, K + 1 if K > 0 else 2)\n        integral_eq = stratified_monte_carlo(f, boundaries_eq, sample_counts, rng)\n        error_eq = np.abs(integral_eq - true_integral)\n\n        # -- Scheme 2: Derivative-weighted stratification --\n        # For f(x)=exp(x), |f'(x)|=exp(x). The boundaries b_i are chosen\n        # such that integral_{b_{i-1}}^{b_i} exp(x) dx is constant.\n        # This leads to b_i = ln(1 + i * (e-1)/K).\n        if K > 0:\n            integral_of_g = true_integral\n            const = integral_of_g / K\n            i_vals = np.arange(K + 1)\n            boundaries_dw = np.log(1.0 + i_vals * const)\n        else: # If K=0, no boundaries. If K=1, boundaries are [0,1].\n            boundaries_dw = np.array([0.0, 1.0]) if K==1 else np.array([])\n        \n        integral_dw = stratified_monte_carlo(f, boundaries_dw, sample_counts, rng)\n        error_dw = np.abs(integral_dw - true_integral)\n\n        # -- Step 3: Comparison and Formatting --\n        is_dw_better = error_dw  error_eq\n        \n        error_eq_rounded = f\"{error_eq:.8f}\"\n        error_dw_rounded = f\"{error_dw:.8f}\"\n        \n        # Build the result string for the current test case in the format [e,d,t].\n        case_result_str = f\"[{error_eq_rounded},{error_dw_rounded},{is_dw_better}]\"\n        all_results_str.append(case_result_str)\n\n    # Final print statement in the exact required format [[...],[...],...].\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现实世界中的抽样策略通常是动态和自适应的。这个问题  介绍了一种自适应协议，当某个层的观测内部方差过高时，就将其动态地分裂成两个子层。通过实施这一规则并计算估计量总方差的变化，您将深入理解如何通过调整分层结构来优化抽样过程，并提高估计的准确性。",
            "id": "3198787",
            "problem": "考虑一个划分为 $K$ 层的有限总体。设第 $k$ 层在总体中所占的比例为 $p_k$，层内总体标准差为 $\\sigma_k$。假设总体均值的估计量定义为各层样本均值的加权平均，其中第 $k$ 层的权重为 $p_k$。在第 $k$ 层内，抽取一个大小为 $n_k$ 的简单随机样本，并计算该层的样本均值。\n\n从方差、独立性的定义以及大总体下简单随机抽样的样本均值方差（因此忽略有限总体校正（FPC））出发，推导加权估计量方差的表达式，该表达式应使用 $p_k$、$\\sigma_k$ 和 $n_k$ 表示。\n\n对于任何估计的层内标准差 $\\hat{\\sigma}_k$ 较高的层 $k$，将应用一个自适应拆分协议。该协议如下：\n- 如果 $\\hat{\\sigma}_k$ 超过阈值 $T$ 且 $n_k \\geq 2$，则将层 $k$ 拆分为两个子层 $k_1$ 和 $k_2$，其总体比例分别为 $p_{k_1} = r_k \\, p_k$ 和 $p_{k_2} = (1 - r_k) \\, p_k$，其中 $r_k \\in (0,1)$ 已给出。使用测试用例中提供的子层内总体标准差 $\\sigma_{k_1}$ 和 $\\sigma_{k_2}$。\n- 按以下规则将层样本量 $n_k$ 在两个子层之间重新分配：$n_{k_1} = \\max\\{1, \\lfloor r_k \\, n_k \\rfloor\\}$ 和 $n_{k_2} = n_k - n_{k_1}$。如果向下取整操作后 $n_{k_1} \\geq n_k$，则设置 $n_{k_1} = n_k - 1$ 和 $n_{k_2} = 1$ 以确保两者都至少为 1。\n- 如果 $\\hat{\\sigma}_k \\leq T$ 或 $n_k  2$，则不拆分层 $k$。\n\n使用您推导出的加权估计量方差表达式，通过计算差值来计算此自适应拆分对方差的影响\n$$\n\\Delta = V_{\\text{post}} - V_{\\text{pre}},\n$$\n其中 $V_{\\text{pre}}$ 是拆分前的方差，$V_{\\text{post}}$ 是应用拆分协议后的方差。\n\n实现一个程序，对下面的每个测试用例，应用该协议，计算 $V_{\\text{pre}}$，计算 $V_{\\text{post}}$，并返回 $\\Delta$。\n\n使用以下测试套件。每个测试用例提供 $K$、数组 $p_k$、$\\sigma_k$、$\\hat{\\sigma}_k$、$n_k$、阈值 $T$，以及对于可能拆分的层，提供元组 $(r_k, \\sigma_{k_1}, \\sigma_{k_2})$。\n\n- 测试用例 1（一次拆分的一般情况）：\n  - $K = 3$\n  - $p = [\\,0.5,\\,0.3,\\,0.2\\,]$\n  - $\\sigma = [\\,3.0,\\,5.0,\\,2.0\\,]$\n  - $\\hat{\\sigma} = [\\,2.8,\\,5.4,\\,1.9\\,]$\n  - $n = [\\,50,\\,30,\\,20\\,]$\n  - $T = 4.0$\n  - 每层拆分信息：$[\\,\\text{无},\\,(0.6,\\,3.0,\\,6.0),\\,\\text{无}\\,]$\n\n- 测试用例 2（因阈值过高而不拆分）：\n  - $K = 3$\n  - $p = [\\,0.5,\\,0.3,\\,0.2\\,]$\n  - $\\sigma = [\\,3.0,\\,5.0,\\,2.0\\,]$\n  - $\\hat{\\sigma} = [\\,2.8,\\,5.4,\\,1.9\\,]$\n  - $n = [\\,50,\\,30,\\,20\\,]$\n  - $T = 6.0$\n  - 每层拆分信息：$[\\,\\text{无},\\,(0.6,\\,3.0,\\,6.0),\\,\\text{无}\\,]$\n\n- 测试用例 3（因层内样本量不足而阻止拆分）：\n  - $K = 2$\n  - $p = [\\,0.7,\\,0.3\\,]$\n  - $\\sigma = [\\,8.0,\\,1.0\\,]$\n  - $\\hat{\\sigma} = [\\,8.2,\\,0.9\\,]$\n  - $n = [\\,1,\\,10\\,]$\n  - $T = 5.0$\n  - 每层拆分信息：$[\\, (0.5,\\,6.0,\\,10.0),\\,\\text{无}\\,]$\n\n- 测试用例 4（极端分配导致子层样本量最小的拆分）：\n  - $K = 2$\n  - $p = [\\,0.4,\\,0.6\\,]$\n  - $\\sigma = [\\,4.0,\\,9.0\\,]$\n  - $\\hat{\\sigma} = [\\,4.1,\\,9.2\\,]$\n  - $n = [\\,3,\\,7\\,]$\n  - $T = 4.5$\n  - 每层拆分信息：$[\\,\\text{无},\\,(0.9,\\,5.0,\\,12.0)\\,]$\n\n- 测试用例 5（单层总体，拆分导致方差显著增加）：\n  - $K = 1$\n  - $p = [\\,1.0\\,]$\n  - $\\sigma = [\\,2.0\\,]$\n  - $\\hat{\\sigma} = [\\,10.0\\,]$\n  - $n = [\\,10\\,]$\n  - $T = 5.0$\n  - 每层拆分信息：$[\\, (0.1,\\,1.0,\\,10.0) \\,]$\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个 $\\Delta$ 值四舍五入到六位小数（例如，$[\\,\\delta_1,\\,\\delta_2,\\,\\delta_3,\\,\\delta_4,\\,\\delta_5\\,]$ 格式为 $[\\,0.123456,\\,0.000000,\\,\\ldots\\,]$）。",
            "solution": "### 分层估计量方差的推导\n\n我们的目标是推导总体均值估计量 $\\hat{\\mu}_{\\text{strat}}$ 的方差表达式。该估计量被定义为各层样本均值 $\\bar{y}_k$ 的加权平均：\n$$\n\\hat{\\mu}_{\\text{strat}} = \\sum_{k=1}^{K} p_k \\bar{y}_k\n$$\n其中 $p_k$ 是第 $k$ 层的总体比例，$\\bar{y}_k$ 是从第 $k$ 层抽取的 $n_k$ 个样本的均值。\n\n估计量的方差为：\n$$\nV(\\hat{\\mu}_{\\text{strat}}) = V\\left(\\sum_{k=1}^{K} p_k \\bar{y}_k\\right)\n$$\n根据分层抽样的核心原则，各层之间的抽样是独立进行的。这意味着各层的样本均值 $\\bar{y}_k$ (对于 $k=1, \\dots, K$) 是相互独立的随机变量。对于独立随机变量的和，其方差等于各项方差的和。因此：\n$$\nV(\\hat{\\mu}_{\\text{strat}}) = \\sum_{k=1}^{K} V(p_k \\bar{y}_k)\n$$\n由于层比例 $p_k$ 是已知的常数，我们可以利用方差的性质 $V(aX) = a^2 V(X)$（其中 $a$ 是常数）：\n$$\nV(\\hat{\\mu}_{\\text{strat}}) = \\sum_{k=1}^{K} p_k^2 V(\\bar{y}_k)\n$$\n问题规定，在层内进行简单随机抽样且总体很大（忽略有限总体校正）。对于从一个标准差为 $\\sigma_k$ 的总体中抽取的 $n_k$ 个样本，其样本均值 $\\bar{y}_k$ 的方差为：\n$$\nV(\\bar{y}_k) = \\frac{\\sigma_k^2}{n_k}\n$$\n将此表达式代入上式，我们得到分层估计量方差的最终表达式：\n$$\nV(\\hat{\\mu}_{\\text{strat}}) = \\sum_{k=1}^{K} \\frac{p_k^2 \\sigma_k^2}{n_k}\n$$\n这个公式将用于计算拆分前后的方差。\n\n### 计算方差变化 $\\Delta$ 的算法\n\n方差变化量 $\\Delta$ 定义为 $\\Delta = V_{\\text{post}} - V_{\\text{pre}}$。对于每个测试用例，算法步骤如下：\n\n1.  **计算拆分前方差 ($V_{\\text{pre}}$)**：\n    使用上述推导的方差公式和初始给定的参数 $p, \\sigma, n$ 来计算初始方差：\n    $$\n    V_{\\text{pre}} = \\sum_{k=1}^{K} \\frac{p_k^2 \\sigma_k^2}{n_k}\n    $$\n\n2.  **应用自适应拆分协议**：\n    我们生成一套新的参数（用 $p', \\sigma', n'$ 表示），代表协议应用后的分层状态。我们遍历初始的 $K$ 个层中的每一个层 $k$：\n    \n    *   **检查拆分条件**：当且仅当一个层的估计标准差 $\\hat{\\sigma}_k$ 超过阈值 $T$ **并且** 其样本量 $n_k$ 大于等于 $2$ 时，该层被拆分。\n        $$\n        (\\hat{\\sigma}_k > T) \\land (n_k \\geq 2)\n        $$\n    *   **如果层不拆分**：其参数被直接复制到拆分后的参数集中。一个新的层被添加到拆分后的配置中，其参数为 $p'_{\\text{new}} = p_k$, $\\sigma'_{\\text{new}} = \\sigma_k$, 和 $n'_{\\text{new}} = n_k$。\n    *   **如果层被拆分**：它将被两个新的子层 $k_1$ 和 $k_2$ 替代。这些子层的参数根据协议计算：\n        *   **比例**：原始比例 $p_k$ 根据给定的比率 $r_k$ 进行划分：\n            $$\n            p'_{k_1} = r_k \\, p_k \\quad \\text{and} \\quad p'_{k_2} = (1 - r_k) \\, p_k\n            $$\n        *   **标准差**：新的标准差 $\\sigma_{k_1}$ 和 $\\sigma_{k_2}$ 直接从测试用例的拆分信息中获取。\n        *   **样本量**：原始样本量 $n_k$ 被重新分配：\n            $$\n            n'_{k_1} = \\max\\{1, \\lfloor r_k \\, n_k \\rfloor\\}\n            $$\n            $$\n            n'_{k_2} = n_k - n'_{k_1}\n            $$\n            由于协议要求 $n_k \\ge 2$ 且 $r_k \\in (0,1)$，这个规则自动保证了 $n'_{k_1}$ 和 $n'_{k_2}$ 都至少为1。因此，问题描述中的附加条件（`If n_k1 >= n_k...`）实际上不会被触发。\n\n3.  **计算拆分后方差 ($V_{\\text{post}}$)**：\n    处理完所有初始层后，我们得到一个包含 $K'$ 个层的新的配置，其参数为 $p', \\sigma', n'$。通过将方差公式应用于这个新配置来计算拆分后的方差：\n    $$\n    V_{\\text{post}} = \\sum_{j=1}^{K'} \\frac{(p'_j)^2 (\\sigma'_j)^2}{n'_j}\n    $$\n\n4.  **计算 $\\Delta$**：\n    最终结果是拆分后方差与拆分前方差之差：\n    $$\n    \\Delta = V_{\\text{post}} - V_{\\text{pre}}\n    $$\n    该值随后被四舍五入到六位小数，用于最终输出。",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the stratified sampling variance problem for a suite of test cases.\n    \"\"\"\n    \n    test_cases = [\n        # Test case 1\n        {\n            \"K\": 3, \"p\": [0.5, 0.3, 0.2], \"sigma\": [3.0, 5.0, 2.0],\n            \"hat_sigma\": [2.8, 5.4, 1.9], \"n\": [50, 30, 20], \"T\": 4.0,\n            \"split_info\": [None, (0.6, 3.0, 6.0), None]\n        },\n        # Test case 2\n        {\n            \"K\": 3, \"p\": [0.5, 0.3, 0.2], \"sigma\": [3.0, 5.0, 2.0],\n            \"hat_sigma\": [2.8, 5.4, 1.9], \"n\": [50, 30, 20], \"T\": 6.0,\n            \"split_info\": [None, (0.6, 3.0, 6.0), None]\n        },\n        # Test case 3\n        {\n            \"K\": 2, \"p\": [0.7, 0.3], \"sigma\": [8.0, 1.0],\n            \"hat_sigma\": [8.2, 0.9], \"n\": [1, 10], \"T\": 5.0,\n            \"split_info\": [(0.5, 6.0, 10.0), None]\n        },\n        # Test case 4\n        {\n            \"K\": 2, \"p\": [0.4, 0.6], \"sigma\": [4.0, 9.0],\n            \"hat_sigma\": [4.1, 9.2], \"n\": [3, 7], \"T\": 4.5,\n            \"split_info\": [None, (0.9, 5.0, 12.0)]\n        },\n        # Test case 5\n        {\n            \"K\": 1, \"p\": [1.0], \"sigma\": [2.0], \"hat_sigma\": [10.0],\n            \"n\": [10], \"T\": 5.0,\n            \"split_info\": [(0.1, 1.0, 10.0)]\n        }\n    ]\n\n    results = []\n\n    def calculate_variance(p_vec, sigma_vec, n_vec):\n        \"\"\"Calculates the variance of the stratified estimator.\"\"\"\n        variance = 0.0\n        for i in range(len(p_vec)):\n            if n_vec[i] > 0:\n                variance += (p_vec[i]**2 * sigma_vec[i]**2) / n_vec[i]\n        return variance\n\n    for case in test_cases:\n        p, sigma, hat_sigma, n, T, split_info, K = \\\n            case[\"p\"], case[\"sigma\"], case[\"hat_sigma\"], case[\"n\"], case[\"T\"], case[\"split_info\"], case[\"K\"]\n        \n        # 1. Calculate pre-split variance\n        v_pre = calculate_variance(p, sigma, n)\n        \n        # 2. Apply adaptive splitting protocol\n        p_post, sigma_post, n_post = [], [], []\n        \n        for k in range(K):\n            # Check split condition: excess stdev and sufficient sample size\n            if hat_sigma[k] > T and n[k] >= 2:\n                # Stratum k splits\n                r_k, sigma_k1, sigma_k2 = split_info[k]\n                \n                # Proportions for sub-strata\n                p_k = p[k]\n                p_post.extend([r_k * p_k, (1 - r_k) * p_k])\n                \n                # Standard deviations for sub-strata\n                sigma_post.extend([sigma_k1, sigma_k2])\n                \n                # Sample sizes for sub-strata\n                n_k = n[k]\n                n_k1 = max(1, math.floor(r_k * n_k))\n                n_k2 = n_k - n_k1\n                n_post.extend([n_k1, n_k2])\n            else:\n                # Stratum k does not split\n                p_post.append(p[k])\n                sigma_post.append(sigma[k])\n                n_post.append(n[k])\n        \n        # 3. Calculate post-split variance\n        v_post = calculate_variance(p_post, sigma_post, n_post)\n        \n        # 4. Compute Delta\n        delta = v_post - v_pre\n        results.append(f\"{delta:.6f}\")\n        \n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}