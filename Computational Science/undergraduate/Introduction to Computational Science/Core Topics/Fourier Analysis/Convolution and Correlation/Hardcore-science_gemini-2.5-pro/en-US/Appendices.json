{
    "hands_on_practices": [
        {
            "introduction": "Convolution and cross-correlation are foundational operations in signal processing, yet the precise relationship between them can be subtle. This practice challenges you to explore this relationship head-on by constructing signals where the two operations produce different results . By carefully designing a filter kernel, you will investigate how its symmetry properties, combined with different boundary conditions (linear versus circular), determine whether convolution and cross-correlation are equivalent, providing a deep, operational understanding of these core concepts.",
            "id": "3114298",
            "problem": "You are to write a complete, runnable program that constructs and compares discrete convolution and discrete cross-correlation for carefully chosen real-valued signals under two boundary models: circular boundary conditions and zero-padding. Work from the core definitions of discrete convolution and discrete cross-correlation.\n\nUse the following foundational definitions as the basis for your reasoning and implementation. For two real-valued discrete-time signals $x[n]$ and $h[n]$ with finite lengths $N_x$ and $N_h$:\n- Linear convolution (with zero-padding) is defined by\n$$\ny_{\\text{lin}}[k] = \\sum_{n=-\\infty}^{\\infty} x[n]\\;h[k-n],\n$$\nwith the convention that values outside the supported indices are treated as zero. Practically, for finite $x[n]$ supported on $0 \\le n \\le N_x-1$ and $h[n]$ supported on $0 \\le n \\le N_h-1$, this sum reduces to indices where both $x[n]$ and $h[k-n]$ are defined within their supports. The output length is $N_x + N_h - 1$.\n- Linear cross-correlation (with zero-padding) is defined by\n$$\nr_{xh,\\text{lin}}[k] = \\sum_{n=-\\infty}^{\\infty} x[n]\\;h[n+k],\n$$\nagain with values outside supported indices treated as zero.\n- For circular boundary conditions with period $N$ (Circular Boundary Conditions (CBC)), define the circular convolution as\n$$\ny_{\\text{circ}}[k] = \\sum_{n=0}^{N-1} x[n]\\;h[(k-n)\\bmod N],\n$$\nand the circular cross-correlation as\n$$\nr_{xh,\\text{circ}}[k] = \\sum_{n=0}^{N-1} x[n]\\;h[(n+k)\\bmod N],\n$$\nfor $0 \\le k \\le N-1$.\n\nYour task is to craft signals $x[n]$ and $h[n]$ so that the circular convolution $x \\circledast h$ and the circular cross-correlation $r_{xh,\\text{circ}}[k]$ are numerically equal, but the linear (zero-padded) convolution and linear cross-correlation diverge. You must explain, in principle, why this can happen, explicitly identifying the role of flipping (time reversal) and boundary models.\n\nImplement the following three test cases to demonstrate coverage:\n- Test Case $1$ (designed to satisfy the circular equality but not the linear equality): Let $N = 5$, $x[n]$ be $[\\,3,\\,1,\\,4,\\,1,\\,5\\,]$, and $h[n]$ be $[\\,2,\\,5,\\,7,\\,7,\\,5\\,]$. Here, $h[n]$ is circularly even with respect to index $0$ because $h[1] = h[4]$ and $h[2] = h[3]$, ensuring equality under circular boundary conditions, but $h[n]$ is not palindromic under center flip, so zero-padded convolution and correlation diverge.\n- Test Case $2$ (designed to satisfy the linear equality but not the circular equality): Let $N = 5$, $x[n]$ be $[\\,2,\\,1,\\,0,\\,4,\\,3\\,]$, and $h[n]$ be $[\\,1,\\,2,\\,3,\\,2,\\,1\\,]$. Here, $h[n]$ is palindromic under center flip, ensuring linear convolution equals linear correlation, but $h[n]$ is not circularly even with respect to index $0$, so circular convolution and circular correlation diverge.\n- Test Case $3$ (edge case where both equalities hold): Let $N = 6$, $x[n]$ be $[\\,0,\\,1,\\,0,\\,2,\\,0,\\,3\\,]$, and $h[n]$ be constant $[\\,4,\\,4,\\,4,\\,4,\\,4,\\,4\\,]$, so both circular and linear equalities hold.\n\nAlgorithmic requirements:\n- Compute $y_{\\text{circ}}[k]$ and $r_{xh,\\text{circ}}[k]$ directly from their definitions using modular indexing for each $k$.\n- Compute $y_{\\text{lin}}[k]$ using standard linear convolution with zero-padding.\n- Compute $r_{xh,\\text{lin}}[k]$ using the definition given above. For implementation, it is acceptable to use the equivalence that linear cross-correlation equals linear convolution with the center-flipped version of $h[n]$, that is, define $\\mathrm{flip}(h)[m] = h[N_h - 1 - m]$, and compute $r_{xh,\\text{lin}}[k] = \\mathrm{conv}(x,\\mathrm{flip}(h))[k]$. This alignment produces the same output indexing as linear convolution for direct comparison.\n- Use a numerical tolerance for equality checks. Two sequences are considered equal if the maximum absolute elementwise difference is less than $10^{-12}$.\n\nRequired outputs:\n- For each test case, produce two boolean values: the first indicates whether $y_{\\text{circ}}[k]$ equals $r_{xh,\\text{circ}}[k]$ elementwise, and the second indicates whether $y_{\\text{lin}}[k]$ equals $r_{xh,\\text{lin}}[k]$ elementwise (under the convolution-aligned indexing produced via center-flip).\n- Your program should produce a single line of output containing the results as a comma-separated list of lists with no spaces, in the exact format\n$$\n[\\,[b_{1,1},b_{1,2}],\\,[b_{2,1},b_{2,2}],\\,[b_{3,1},b_{3,2}]\\,],\n$$\nwhere each $b_{i,j}$ is either $\\mathrm{True}$ or $\\mathrm{False}$.\n\nThere are no physical units involved in this problem. Angles and percentages do not appear.\n\nImplement the solution in Python, version $3.12$, using only the allowed libraries specified in the runtime environment.",
            "solution": "The solution to this problem rests on a precise understanding of the relationship between convolution and cross-correlation, and how this relationship is affected by different boundary conditionsâ€”specifically, zero-padding for linear operations and modular arithmetic for circular operations.\n\nThe fundamental definitions for discrete convolution and cross-correlation of two real-valued signals $x[n]$ and $h[n]$ are:\n- Convolution: $(x * h)[k] = \\sum_{n} x[n] h[k-n]$\n- Cross-correlation: $(x \\star h)[k] = \\sum_{n} x[n] h[n+k]$\n\nThe key insight is that cross-correlation can be expressed as a convolution with a time-reversed (flipped) version of the kernel $h[n]$. Let's define a time-reversal operator, $\\mathrm{rev}(\\cdot)$. The convolution $(x * \\mathrm{rev}(h))[k]$ is given by $\\sum_{n} x[n] (\\mathrm{rev}(h))[k-n]$. It can be shown that this expression is equivalent to the definition of cross-correlation, $(x \\star h)[k]$, provided the reversal operator and summation bounds are defined appropriately for the boundary model in use.\n\nConsequently, convolution and cross-correlation yield the same result, i.e., $(x * h)[k] = (x \\star h)[k]$, if and only if the convolution kernel $h[n]$ is symmetric under the specific time-reversal operation associated with the boundary model. This condition is $h[n] = \\mathrm{rev}(h)[n]$. The crux of the problem lies in the fact that the time-reversal operator is defined differently for linear and circular contexts.\n\n**1. Linear (Zero-Padded) Operations**\n\nFor finite-length signals like $x[n]$ of length $N_x$ and $h[n]$ of length $N_h$, linear operations assume the signals are zero outside their defined support. The corresponding time-reversal operator flips the kernel $h[n]$ about its center index. This is defined as:\n$$\n\\mathrm{rev}_{\\text{lin}}(h)[m] = h[N_h - 1 - m] \\quad \\text{for } 0 \\le m \\le N_h-1\n$$\nLinear convolution and linear cross-correlation are equal if and only if $h[m] = \\mathrm{rev}_{\\text{lin}}(h)[m]$, which means $h[m] = h[N_h - 1 - m]$. A sequence with this property is called **palindromic**. For example, $[\\,1,\\,2,\\,3,\\,2,\\,1\\,]$ is palindromic.\n\nThe problem specifies computing linear cross-correlation as the convolution of $x$ with the flipped version of $h$. This directly leverages the identity $(x \\star h)_{\\text{lin}} = (x * \\mathrm{rev}_{\\text{lin}}(h))_{\\text{lin}}$. Thus, the comparison for equality becomes a direct comparison between $(x * h)_{\\text{lin}}$ and $(x * \\mathrm{rev}_{\\text{lin}}(h))_{\\text{lin}}$.\n\n**2. Circular (Periodic) Operations**\n\nFor circular operations on signals of period $N$, the indices are treated modulo $N$. The circular time-reversal operator flips the kernel $h[n]$ around the index $n=0$ on a circle:\n$$\n\\mathrm{rev}_{\\text{circ}}(h)[n] = h[(-n) \\pmod N] \\quad \\text{for } 0 \\le n \\le N-1\n$$\nCircular convolution, $y_{\\text{circ}}[k] = \\sum_{n=0}^{N-1} x[n]\\;h[(k-n)\\bmod N]$, equals circular cross-correlation, $r_{xh,\\text{circ}}[k] = \\sum_{n=0}^{N-1} x[n]\\;h[(n+k)\\bmod N]$, if and only if $h[n] = \\mathrm{rev}_{\\text{circ}}(h)[n]$. This means $h[n] = h[(-n) \\pmod N]$. A sequence with this property is **circularly even**. For example, for $N=5$, this requires $h[1] = h[4]$ and $h[2] = h[3]$. The sequence $[\\,2,\\,5,\\,7,\\,7,\\,5\\,]$ is circularly even for $N=5$.\n\n**Discrepancy by Design**\n\nThe problem's test cases are designed to exploit the fact that palindromic symmetry and circular even symmetry are distinct properties. A signal can possess one without the other, which allows us to construct scenarios where one pair of operations (e.g., circular) results in equality while the other (e.g., linear) does not.\n\n- **Test Case 1**: $h = [\\,2,\\,5,\\,7,\\,7,\\,5\\,]$ and $N=5$.\n  - Circularly Even?: $h[1]=5$ and $h[(-1)\\bmod 5] = h[4]=5$. They are equal. $h[2]=7$ and $h[(-2)\\bmod 5] = h[3]=7$. They are equal. So, $h$ is circularly even. We expect $y_{\\text{circ}} = r_{xh,\\text{circ}}$.\n  - Palindromic?: $h[0]=2$ and $h[5-1-0] = h[4]=5$. They are not equal. So, $h$ is not palindromic. We expect $y_{\\text{lin}} \\ne r_{xh,\\text{lin}}$.\n  - Prediction: $[\\mathrm{True}, \\mathrm{False}]$\n\n- **Test Case 2**: $h = [\\,1,\\,2,\\,3,\\,2,\\,1\\,]$ and $N=5$.\n  - Palindromic?: $h[0]=1, h[4]=1$. $h[1]=2, h[3]=2$. It is palindromic. We expect $y_{\\text{lin}} = r_{xh,\\text{lin}}$.\n  - Circularly Even?: $h[1]=2$ and $h[(-1)\\bmod 5] = h[4]=1$. They are not equal. It is not circularly even. We expect $y_{\\text{circ}} \\ne r_{xh,\\text{circ}}$.\n  - Prediction: $[\\mathrm{False}, \\mathrm{True}]$\n\n- **Test Case 3**: $h = [\\,4,\\,4,\\,4,\\,4,\\,4,\\,4\\,]$ and $N=6$.\n  - A constant signal is trivially both palindromic ($h[m]=4$ and $h[6-1-m]=4$) and circularly even ($h[n]=4$ and $h[(-n)\\bmod 6]=4$). We expect both equalities to hold.\n  - Prediction: $[\\mathrm{True}, \\mathrm{True}]$\n\nThe implementation will follow these principles. Circular operations are computed directly from their summation definitions using loops and modular arithmetic. Linear operations utilize `numpy.convolve` for efficiency, with linear cross-correlation computed as the convolution with a center-flipped kernel, as specified in the problem statement. Equality is checked by ensuring the maximum absolute element-wise difference between the resulting sequences is below a tolerance of $10^{-12}$.",
            "answer": "```python\nimport numpy as np\n\ndef circular_convolution(x: np.ndarray, h: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes the circular convolution of two 1D signals x and h.\n    Assumes len(x) == len(h).\n    \"\"\"\n    N = len(x)\n    y = np.zeros(N)\n    for k in range(N):\n        for n in range(N):\n            y[k] += x[n] * h[(k - n) % N]\n    return y\n\ndef circular_cross_correlation(x: np.ndarray, h: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes the circular cross-correlation of two 1D signals x and h.\n    Assumes len(x) == len(h).\n    \"\"\"\n    N = len(x)\n    r = np.zeros(N)\n    for k in range(N):\n        for n in range(N):\n            r[k] += x[n] * h[(n + k) % N]\n    return r\n\ndef solve():\n    \"\"\"\n    Solves the problem by running three predefined test cases and\n    comparing convolution and cross-correlation under different boundary models.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, x_list, h_list)\n        (5, [3, 1, 4, 1, 5], [2, 5, 7, 7, 5]),\n        (5, [2, 1, 0, 4, 3], [1, 2, 3, 2, 1]),\n        (6, [0, 1, 0, 2, 0, 3], [4, 4, 4, 4, 4, 4]),\n    ]\n\n    results = []\n    tolerance = 1e-12\n\n    for N, x_list, h_list in test_cases:\n        x = np.array(x_list, dtype=float)\n        h = np.array(h_list, dtype=float)\n\n        # 1. Circular operations\n        y_circ = circular_convolution(x, h)\n        r_circ = circular_cross_correlation(x, h)\n        \n        # Check for circular equality\n        circ_diff = np.max(np.abs(y_circ - r_circ))\n        is_circ_equal = circ_diff < tolerance\n\n        # 2. Linear operations\n        # Linear convolution\n        y_lin = np.convolve(x, h, mode='full')\n        \n        # Linear cross-correlation via convolution with flipped kernel\n        # h_flipped[m] = h[N_h - 1 - m] is equivalent to h[::-1]\n        h_flipped = h[::-1]\n        r_lin = np.convolve(x, h_flipped, mode='full')\n\n        # Check for linear equality\n        lin_diff = np.max(np.abs(y_lin - r_lin))\n        is_lin_equal = lin_diff < tolerance\n\n        results.append([is_circ_equal, is_lin_equal])\n\n    # Format the output string as per the requirement: [[b1,b2],[b3,b4],...] with no spaces.\n    # str(True) -> 'True', str(False) -> 'False'\n    result_str = \",\".join([f\"[{b1},{b2}]\" for b1, b2 in results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Real-world signals are often distorted by the systems they pass through and corrupted by noise. This exercise tackles the important inverse problem of recovering a clean signal from a noisy, convolved measurement . You will derive and implement the Wiener deconvolution filter, a powerful tool that optimally balances inverting the convolution with suppressing noise. This practice provides a first-hand look at how statistical information about the signal and noise, in the form of their Power Spectral Densities, is used to design the ideal restoration filter.",
            "id": "3114304",
            "problem": "You are given a discrete-time, real-valued, finite-length signal model in which an unknown input $x$ is observed through a linear time-invariant system with impulse response $h$ and contaminated by additive noise $n$, producing $y$ according to $y = x * h + n$, where $*$ denotes discrete convolution. Your task is to derive, from first principles, the frequency-domain filter that minimizes the expected Mean Squared Error (MSE) between the estimate $\\hat{x}$ and the true input $x$, when $x$ and $n$ are wide-sense stationary and mutually independent, and when you are given the Power Spectral Density (PSD) $S_{xx}(\\omega)$ of $x$ and the PSD $S_{nn}(\\omega)$ of $n$. You must then implement the resulting Wiener deconvolution procedure to recover $\\hat{x}$ from $y$, using the Fast Fourier Transform (FFT) to operate in the frequency domain.\n\nBegin your derivation strictly from foundational definitions and principles appropriate to the topic. The permitted bases include: the definition of discrete convolution, the definition of wide-sense stationarity and its link to the autocorrelation and Power Spectral Density via the Fourier transform, the definition of the Mean Squared Error, and independence properties. Do not use or cite any pre-derived Wiener filter formula or intermediate shortcut expressions. Your derivation should establish the structure of the optimal frequency-domain estimator for $x$ based on $y$, the system frequency response $H(\\omega)$, and the spectra $S_{xx}(\\omega)$ and $S_{nn}(\\omega)$.\n\nImplementation requirements:\n- Use circular convolution of length $N$ to ensure that the discrete Fourier transform precisely diagonalizes convolution. For a sequence $x$ and an impulse response $h$ both represented at length $N$, form $y$ as $y = \\mathcal{F}^{-1}\\{\\mathcal{F}\\{x\\} \\cdot \\mathcal{F}\\{h\\}\\} + n$, where $\\mathcal{F}$ denotes the Discrete Fourier Transform and $\\mathcal{F}^{-1}$ its inverse.\n- Construct the frequency-domain deconvolution filter using your derived expression, applied pointwise over the discrete frequency grid $\\omega_k = 2\\pi k / N$ for $k = 0, 1, \\dots, N-1$.\n- Use the known parametric form of $S_{xx}(\\omega)$ when $x$ is an AutoRegressive (AR) of order $1$, namely $x[n] = \\phi x[n-1] + w[n]$ with $w[n]$ white Gaussian of variance $\\sigma_w^2$, so that $$S_{xx}(\\omega) = \\frac{\\sigma_w^2}{\\left|1 - \\phi e^{-j\\omega}\\right|^2}.$$ Use $S_{nn}(\\omega) = \\sigma_n^2$ for white Gaussian noise $n$ with variance $\\sigma_n^2$.\n- Generate all random sequences with fixed seeds as specified for reproducibility.\n\nTest suite and parameters:\nImplement your program to run the following three test cases without any user input. In each case, all sequences are of length $N$ and circular convolution is used.\n\n$1.$ Case A (moderate blur and moderate noise):\n- $N = 256$.\n- Input $x$ is AR($1$) with parameter $\\phi = 0.9$ and driving noise variance $\\sigma_w^2 = 1.0$.\n- Impulse response $h$ is a circularly symmetric discrete Gaussian kernel on the circle of length $N$ with standard deviation $s = 3.0$ samples, defined by $h[k] = \\exp\\left(-\\frac{1}{2}\\left(\\frac{d(k)}{s}\\right)^2\\right)$ for $k=0,\\dots,N-1$, where $d(k) = \\min(k, N-k)$, and normalized so that $\\sum_{k=0}^{N-1} h[k] = 1$.\n- Additive noise $n$ is white Gaussian with variance $\\sigma_n^2 = 0.2$.\n- Random seeds: use seed $x\\_seed = 0$ when generating the AR($1$) input and seed $n\\_seed = 10$ when generating the additive noise.\n\n$2.$ Case B (identity system and very low noise):\n- $N = 128$.\n- Input $x$ is AR($1$) with parameter $\\phi = 0.6$ and driving noise variance $\\sigma_w^2 = 1.0$.\n- Impulse response $h$ is the discrete delta, i.e., $h[0] = 1$ and $h[k] = 0$ for $k \\neq 0$.\n- Additive noise $n$ is white Gaussian with variance $\\sigma_n^2 = 0.01$.\n- Random seeds: use seed $x\\_seed = 1$ for the AR($1$) input and seed $n\\_seed = 11$ for the additive noise.\n\n$3.$ Case C (near-notched system and high noise):\n- $N = 512$.\n- Input $x$ is AR($1$) with parameter $\\phi = 0.95$ and driving noise variance $\\sigma_w^2 = 1.0$.\n- Impulse response $h$ is two-tap with $h[0] = 1$ and $h[1] = -0.95$, and $h[k] = 0$ for $k \\ge 2$.\n- Additive noise $n$ is white Gaussian with variance $\\sigma_n^2 = 0.5$.\n- Random seeds: use seed $x\\_seed = 2$ for the AR($1$) input and seed $n\\_seed = 12$ for the additive noise.\n\nFor each case, generate $x$ by simulating the AutoRegressive (AR) of order $1$ recursion $x[n] = \\phi x[n-1] + w[n]$ for $n = 0,\\dots,N-1$ with $x[0] = w[0]$ and $w[n]$ independent and identically distributed Gaussian samples with variance $\\sigma_w^2$. Generate $n$ as independent Gaussian samples with variance $\\sigma_n^2$. Construct $y$ via circular convolution at length $N$ and add $n$. Compute $\\hat{x}$ via your derived Wiener deconvolution filter using the known $S_{xx}(\\omega)$ and $S_{nn}(\\omega)$ at the discrete frequency grid.\n\nQuantifiable answers:\nFor each test case, compute the realized Mean Squared Error between the estimate and the true input, $$\\text{MSE} = \\frac{1}{N}\\sum_{n=0}^{N-1}\\left(\\hat{x}[n] - x[n]\\right)^2,$$ and report these three MSE values.\n\nFinal output format:\nYour program should produce a single line of output containing the three MSE values in the order Case A, Case B, Case C, as a comma-separated list enclosed in square brackets, with each value rounded to six decimal places (e.g., $[\\text{mse\\_A},\\text{mse\\_B},\\text{mse\\_C}]$).",
            "solution": "The problem is to derive and implement the optimal linear filter for estimating a signal $x$ from a measurement $y$, which is the result of convolving $x$ with a system response $h$ and adding noise $n$. The model is given by $y = x * h + n$, where $*$ denotes discrete convolution. The optimality criterion is the minimization of the Mean Squared Error (MSE) between the true signal $x$ and its estimate $\\hat{x}$.\n\nOur derivation proceeds from first principles, assuming that the signal $x$ and noise $n$ are real-valued, wide-sense stationary (WSS) random processes, and that they are mutually independent with zero mean. We are given their Power Spectral Densities (PSDs), denoted $S_{xx}(\\omega)$ and $S_{nn}(\\omega)$, respectively.\n\nLet the estimate $\\hat{x}$ be formed by applying a linear time-invariant (LTI) filter with impulse response $g$ to the observed signal $y$.\n$$\n\\hat{x}[k] = (g * y)[k] = \\sum_{m} g[k-m] y[m]\n$$\nThe estimation error is defined as $e[k] = x[k] - \\hat{x}[k]$. Our objective is to find the filter $g$ that minimizes the MSE, which for a WSS process is the expected value of the squared error, independent of the time index $k$.\n$$\n\\text{MSE} = J = E\\left[ e[k]^2 \\right]\n$$\nWe begin by expressing the error $e[k]$ in terms of the input signals and system responses.\n$$\ne[k] = x[k] - (g * y)[k] = x[k] - (g * (x * h + n))[k]\n$$\nUsing the linearity and associativity of convolution, we get:\n$$\ne[k] = x[k] - (g * h * x)[k] - (g * n)[k]\n$$\nThe MSE is the variance of the error signal, $J = E[e[k]^2]$. For WSS processes, the average power of a signal is given by its autocovariance at lag zero, $R_{ee}[0]$. By the Wiener-Khinchin theorem, this is related to the integral of its PSD, $S_{ee}(\\omega)$.\n$$\nJ = R_{ee}[0] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} S_{ee}(\\omega) \\,d\\omega\n$$\nTo minimize $J$, we can equivalently minimize the error PSD, $S_{ee}(\\omega)$, for each frequency $\\omega$. This is possible because the integrand is non-negative. We transition to the frequency domain using the Fourier Transform, which diagonalizes convolution for LTI systems. Let $\\mathcal{F}$ denote the Fourier Transform operator. Let $X(\\omega)$, $H(\\omega)$, $N(\\omega)$, $G(\\omega)$, and $E(\\omega)$ be the Fourier transforms of $x[k]$, $h[k]$, $n[k]$, $g[k]$, and $e[k]$, respectively.\n\nThe frequency-domain representation of the error is:\n$$\nE(\\omega) = X(\\omega) - G(\\omega) \\left( X(\\omega)H(\\omega) + N(\\omega) \\right)\n$$\nRearranging the terms, we get:\n$$\nE(\\omega) = X(\\omega) \\left( 1 - G(\\omega)H(\\omega) \\right) - G(\\omega)N(\\omega)\n$$\nThe PSD of the error, $S_{ee}(\\omega)$, is the expected value of the squared magnitude of its Fourier transform, $E(\\omega)$. For a discrete-time process of length $N$, this is formally defined as $S_{ee}(\\omega_k) = E[|E(\\omega_k)|^2]$.\n$$\nS_{ee}(\\omega) = E\\left[ \\left| X(\\omega) \\left( 1 - G(\\omega)H(\\omega) \\right) - G(\\omega)N(\\omega) \\right|^2 \\right]\n$$\nExpanding the magnitude squared term $|A-B|^2 = (A-B)(A-B)^* = |A|^2 - AB^* - A^*B + |B|^2$:\n$$\nS_{ee}(\\omega) = E\\left[ |X(\\omega)|^2 |1 - G(\\omega)H(\\omega)|^2 - X(\\omega)(1-G(\\omega)H(\\omega))G(\\omega)^*N(\\omega)^* - X(\\omega)^*(1-G(\\omega)H(\\omega))^*G(\\omega)N(\\omega) + |G(\\omega)|^2|N(\\omega)|^2 \\right]\n$$\nWe apply the expectation operator to each term. Since $x$ and $n$ are mutually independent and have zero mean, the cross-terms involving products of $X(\\omega)$ and $N(\\omega)$ have an expectation of zero. For instance, $E[X(\\omega)N(\\omega)^*] = E[X(\\omega)]E[N(\\omega)^*] = 0 \\cdot 0 = 0$.\nThis simplifies the expression significantly:\n$$\nS_{ee}(\\omega) = E\\left[ |X(\\omega)|^2 \\right] |1 - G(\\omega)H(\\omega)|^2 + |G(\\omega)|^2 E\\left[ |N(\\omega)|^2 \\right]\n$$\nBy definition, $S_{xx}(\\omega) = E[|X(\\omega)|^2]$ and $S_{nn}(\\omega) = E[|N(\\omega)|^2]$. Thus, the error PSD is:\n$$\nS_{ee}(\\omega) = S_{xx}(\\omega) |1 - G(\\omega)H(\\omega)|^2 + S_{nn}(\\omega) |G(\\omega)|^2\n$$\nOur goal is to find the complex-valued filter response $G(\\omega)$ that minimizes this expression for each $\\omega$. Let's expand the terms, temporarily omitting the dependence on $\\omega$ for clarity:\n$$\nS_{ee} = S_{xx} (1 - GH)(1 - G^*H^*) + S_{nn} GG^*\n$$\n$$\nS_{ee} = S_{xx} (1 - G^*H^* - GH + |G|^2|H|^2) + S_{nn} |G|^2\n$$\n$$\nS_{ee} = S_{xx} - S_{xx}G^*H^* - S_{xx}GH + |G|^2 \\left( S_{xx}|H|^2 + S_{nn} \\right)\n$$\nTo find the minimum with respect to the complex variable $G$, we can use Wirtinger calculus and set the derivative with respect to $G^*$ to zero, treating $G$ and $G^*$ as independent variables.\n$$\n\\frac{\\partial S_{ee}}{\\partial G^*} = -S_{xx}H^* + G \\left( S_{xx}|H|^2 + S_{nn} \\right)\n$$\nSetting this derivative to zero gives the optimal filter $G$:\n$$\n-S_{xx}H^* + G_{opt} \\left( S_{xx}|H|^2 + S_{nn} \\right) = 0\n$$\nSolving for $G_{opt}$:\n$$\nG_{opt}(\\omega) = \\frac{S_{xx}(\\omega)H(\\omega)^*}{S_{xx}(\\omega)|H(\\omega)|^2 + S_{nn}(\\omega)}\n$$\nThis is the celebrated Wiener deconvolution filter. The numerator term $S_{xx}(\\omega)H(\\omega)^*$ attempts to invert the system, weighted by the signal's power. The denominator is the PSD of the observed signal $y$, since $S_{yy}(\\omega) = E[|X(\\omega)H(\\omega)+N(\\omega)|^2] = S_{xx}(\\omega)|H(\\omega)|^2 + S_{nn}(\\omega)$, using the independence of $x$ and $n$. The filter can be rewritten as:\n$$\nG_{opt}(\\omega) = \\frac{1}{H(\\omega)} \\frac{S_{xx}(\\omega)|H(\\omega)|^2}{S_{xx}(\\omega)|H(\\omega)|^2 + S_{nn}(\\omega)} = \\frac{1}{H(\\omega)} \\frac{\\text{SNR}(\\omega) \\cdot |H(\\omega)|^2}{\\text{SNR}(\\omega) \\cdot |H(\\omega)|^2 + 1}\n$$\nwhere $\\text{SNR}(\\omega) = S_{xx}(\\omega)/S_{nn}(\\omega)$. This form shows that the filter approximates the inverse filter $1/H(\\omega)$ at frequencies where the signal-to-noise ratio is high, and attenuates the output at frequencies where the SNR is low, thus preventing noise amplification.\n\nFor the implementation, we use the discrete versions of these formulas. The continuous frequency $\\omega$ is replaced by discrete frequencies $\\omega_k = 2\\pi k/N$ for $k \\in \\{0, 1, \\dots, N-1\\}$. The Fourier transforms become Discrete Fourier Transforms (DFTs), which are computed using the Fast Fourier Transform (FFT) algorithm.\nThe frequency response of the system, $H(\\omega_k)$, is given by the FFT of the impulse response $h[n]$. The PSDs $S_{xx}[k]$ and $S_{nn}[k]$ are evaluated at these discrete frequencies.\n- For the AR($1$) process $x[n]=\\phi x[n-1]+w[n]$, the PSD is $S_{xx}(\\omega) = \\frac{\\sigma_w^2}{|1 - \\phi e^{-j\\omega}|^2}$.\n- For white noise $n[n]$, the PSD is constant: $S_{nn}(\\omega) = \\sigma_n^2$.\n\nThe implementation steps are as follows:\n1.  Generate the true signal $x[n]$ and additive noise $n[n]$ according to the given parameters and random seeds.\n2.  Define the impulse response $h[n]$ for the given case.\n3.  Compute the observed signal $y[n]$ using circular convolution via FFT: $y = \\mathcal{F}^{-1}\\{\\mathcal{F}\\{x\\} \\cdot \\mathcal{F}\\{h\\}\\} + n$.\n4.  Compute the frequency response $H[k] = \\mathcal{F}\\{h[n]\\}$.\n5.  Evaluate the PSDs $S_{xx}[k]$ and $S_{nn}[k]$ at discrete frequencies $\\omega_k$.\n6.  Construct the Wiener filter in the frequency domain: $G[k] = \\frac{S_{xx}[k]H[k]^*}{S_{xx}[k]|H[k]|^2 + S_{nn}[k]}$.\n7.  Apply the filter to the observed signal in the frequency domain: $\\hat{X}[k] = G[k] \\cdot \\mathcal{F}\\{y[n]\\}$.\n8.  Transform the estimate back to the time domain: $\\hat{x}[n] = \\mathcal{F}^{-1}\\{\\hat{X}[k]\\}$.\n9.  Compute the realized MSE: $\\frac{1}{N}\\sum_{n=0}^{N-1} (\\hat{x}[n] - x[n])^2$.\nThis procedure is repeated for all three test cases specified.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements the Wiener deconvolution filter for three test cases.\n    \"\"\"\n\n    def generate_ar1(N, phi, sigma_w_sq, seed):\n        \"\"\"Generates a single realization of an AR(1) process.\"\"\"\n        rng = np.random.default_rng(seed)\n        sigma_w = np.sqrt(sigma_w_sq)\n        w = rng.normal(scale=sigma_w, size=N)\n        x = np.zeros(N)\n        # Per problem spec: x[0] = w[0].\n        # Note: This makes the process not strictly stationary at the start.\n        x[0] = w[0]\n        for n in range(1, N):\n            x[n] = phi * x[n-1] + w[n]\n        return x\n\n    def run_case(N, phi, sigma_w_sq, h_def, sigma_n_sq, x_seed, n_seed):\n        \"\"\"\n        Runs a single deconvolution test case.\n\n        Args:\n            N (int): Signal length.\n            phi (float): AR(1) parameter for the input signal x.\n            sigma_w_sq (float): Driving noise variance for x.\n            h_def (tuple): Definition of the impulse response h.\n            sigma_n_sq (float): Variance of the additive white noise n.\n            x_seed (int): Random seed for generating x.\n            n_seed (int): Random seed for generating n.\n\n        Returns:\n            float: The mean squared error between the estimated signal and the true signal.\n        \"\"\"\n        # 1. Generate signals\n        x_true = generate_ar1(N, phi, sigma_w_sq, x_seed)\n        \n        rng_n = np.random.default_rng(n_seed)\n        noise = rng_n.normal(scale=np.sqrt(sigma_n_sq), size=N)\n\n        # 2. Define impulse response h\n        h = np.zeros(N)\n        htype, params = h_def\n        if htype == 'gaussian':\n            s = params['s']\n            k = np.arange(N)\n            d = np.minimum(k, N - k)\n            h = np.exp(-0.5 * (d / s)**2)\n            h /= np.sum(h) # Normalize\n        elif htype == 'delta':\n            h[0] = 1.0\n        elif htype == 'two-tap':\n            h[0] = 1.0\n            h[1] = -0.95\n\n        # 3. Create observed signal y = x * h + n using circular convolution\n        X_true_fft = np.fft.fft(x_true)\n        H_fft = np.fft.fft(h)\n        y_conv = np.real(np.fft.ifft(X_true_fft * H_fft))\n        y_obs = y_conv + noise\n\n        # 4. Construct the Wiener filter G\n        # Discrete frequencies\n        omega_k = (2 * np.pi / N) * np.arange(N)\n        \n        # PSD of AR(1) signal x\n        S_xx = sigma_w_sq / np.abs(1 - phi * np.exp(-1j * omega_k))**2\n        \n        # PSD of white noise n\n        S_nn = np.full(N, sigma_n_sq)\n        \n        # Wiener filter G in the frequency domain\n        G_numerator = S_xx * np.conj(H_fft)\n        G_denominator = S_xx * np.abs(H_fft)**2 + S_nn\n        G_fft = G_numerator / G_denominator\n\n        # 5. Apply the filter to estimate x\n        Y_obs_fft = np.fft.fft(y_obs)\n        X_hat_fft = G_fft * Y_obs_fft\n        x_hat = np.real(np.fft.ifft(X_hat_fft))\n\n        # 6. Calculate realized MSE\n        mse = np.mean((x_hat - x_true)**2)\n        \n        return mse\n\n    # --- Test Cases ---\n    test_cases = [\n        # Case A: Moderate blur, moderate noise\n        {\n            \"N\": 256, \"phi\": 0.9, \"sigma_w_sq\": 1.0,\n            \"h_def\": ('gaussian', {'s': 3.0}),\n            \"sigma_n_sq\": 0.2, \"x_seed\": 0, \"n_seed\": 10\n        },\n        # Case B: Identity system, very low noise\n        {\n            \"N\": 128, \"phi\": 0.6, \"sigma_w_sq\": 1.0,\n            \"h_def\": ('delta', {}),\n            \"sigma_n_sq\": 0.01, \"x_seed\": 1, \"n_seed\": 11\n        },\n        # Case C: Near-notched system, high noise\n        {\n            \"N\": 512, \"phi\": 0.95, \"sigma_w_sq\": 1.0,\n            \"h_def\": ('two-tap', {}),\n            \"sigma_n_sq\": 0.5, \"x_seed\": 2, \"n_seed\": 12\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        mse = run_case(**case)\n        results.append(mse)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{m:.6f}' for m in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The power of convolution extends far beyond traditional signal processing, finding surprising applications in fields like computer science. This exercise demonstrates a profound connection between signal processing algorithms and computational number theory by using convolution to perform multiplication of enormous integers . You will learn to reframe this arithmetic task as a polynomial multiplication, which can be solved efficiently by convolving the numbers' coefficients. To ensure perfect accuracy, you will implement this using the Number Theoretic Transform ($NTT$), an integer-based cousin of the Fast Fourier Transform ($FFT$), gaining insight into the abstract and universal nature of the convolution operation.",
            "id": "3114324",
            "problem": "You are asked to implement and analyze integer multiplication via discrete convolution using the Number Theoretic Transform (NTT), and to compare its operation count to Karatsuba multiplication for a large number of digits. The task must be solved from first principles and implemented as a complete, runnable program.\n\nYou must base your reasoning and design on the following core definitions and facts:\n- The discrete convolution of two sequences is defined by the rule: given sequences $\\{a_k\\}_{k=0}^{n-1}$ and $\\{b_k\\}_{k=0}^{m-1}$, their convolution $\\{c_k\\}_{k=0}^{n+m-2}$ is\n$$\nc_k = \\sum_{i=0}^{k} a_i \\, b_{k-i},\n$$\nwhere $a_i = 0$ for $i \\ge n$ and $b_j = 0$ for $j \\ge m$.\n- The coefficients of the product of two polynomials equal the discrete convolution of their coefficient sequences.\n- The Number Theoretic Transform (NTT) is a discrete Fourier transform over the finite field of integers modulo a prime, used to compute convolutions in time proportional to $O(N \\log N)$ when the transform length $N$ is a power of two that divides $p-1$ for a chosen prime modulus $p$ with a primitive root of unity.\n\nYour program must do the following, strictly adhering to the specifications:\n\n1) Implement multiplication of two nonnegative integers by mapping their decimal digits into coefficients of polynomials over a base $B$, performing a convolution via the Number Theoretic Transform (NTT) modulo a prime, and then handling carries to recover the exact decimal representation of the product.\n   - Use base $B = 10^3$ for chunking decimal digits into coefficients.\n   - Use the prime modulus $p = 998244353$ and a primitive root $g = 3$. Choose the transform length $L$ as the smallest power of two such that $L \\ge n+m-1$, where $n$ and $m$ are the numbers of base-$B$ digits of the two input integers.\n   - For the NTT, use a length-$L$ primitive root of unity $\\omega$ modulo $p$, where $\\omega = g^{(p-1)/L} \\bmod p$. Implement the inverse transform using $\\omega^{-1}$ and multiply all outputs by $L^{-1} \\bmod p$.\n   - To avoid modular wrap-around errors when using a single modulus, ensure the data used in the provided test suite respects the sufficient safety bound $S\\,(B-1)^2 < p$, where $S = \\min(n,m)$ is the maximum number of terms contributing to any convolution coefficient. For the given test cases below and $B=10^3$, this bound holds.\n\n2) From first principles, justify that integer multiplication via this method is correct by appealing to the definition of discrete convolution and the equality between polynomial multiplication and convolution of coefficients. You must not assume specialized formulas beyond these fundamentals.\n\n3) Provide a simple operation-count model to compare asymptotic costs:\n   - Let $N$ denote the chosen NTT length for a given convolution. Count the number of field multiplications for three transforms (two forward and one inverse) as $\\tfrac{3}{2}\\,N\\log_2 N$ and for the pointwise product as $N$, for a total $M_{\\mathrm{NTT}}(N) = \\tfrac{3}{2}\\,N\\log_2 N + N$ multiplications.\n   - For Karatsuba multiplication on $s$ base-$B$ digits per input integer (assume $s$ is a power of two for the model), count the number of scalar digit multiplications as $M_{\\mathrm{K}}(s) = s^{\\log_2 3}$, ignoring lower-order additions.\n   - To compare the methods for a target number of decimal digits $d$ with base $B=10^3$, set $s = \\lceil d / \\log_{10} B \\rceil = \\lceil d / 3 \\rceil$ and $N$ to the smallest power of two with $N \\ge 2s$. Report the ratio\n$$\nR(d) = \\frac{M_{\\mathrm{NTT}}(N)}{M_{\\mathrm{K}}(s)},\n$$\nrounded to six decimal places. This is a dimensionless comparison of multiplicative operation counts under a simplified model.\n\n4) Test suite. Your program must compute and aggregate results for the following test cases. In all cases, the inputs are decimal strings, and the outputs must be exact decimal strings. There are no physical units involved.\n   - Test case $\\#1$ (boundary with zero): multiply $a_1 = \\text{\"0\"}$ by $b_1 = \\text{\"12345678901234567890\"}$.\n   - Test case $\\#2$ (small happy path): multiply $a_2 = \\text{\"12345\"}$ by $b_2 = \\text{\"6789\"}$.\n   - Test case $\\#3$ (carry-stress within single-modulus safety): multiply $a_3 = \\text{\"999999999999999999999999\"}$ by $b_3 = \\text{\"999999999999999999999999\"}$, that is, each is the decimal string of the digit $\\text{\"9\"}$ repeated $24$ times.\n   - Test case $\\#4$ (larger but safe length): let $a_4$ be the $120$-digit string obtained by repeating $\\text{\"12345678901234567890\"}$ exactly $6$ times, and let $b_4$ be the $120$-digit string obtained by repeating $\\text{\"98765432109876543210\"}$ exactly $6$ times. For this case, also report the actual $L$ you used (the NTT length, a power of two) as an integer.\n\n5) Large-$d$ comparison. Using the model in item $3$, compute $R(d)$ for $d = 10^6$ decimal digits at base $B=10^3$, and include this value (rounded to six decimal places) in the final aggregated output.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$\n[\\;r_1,\\;r_2,\\;r_3,\\;r_4,\\;L_4,\\;R(10^6)\\;],\n$$\nwhere $r_i$ are booleans indicating whether the NTT-based product equals the exact Python integer product for test case $i$, $L_4$ is the NTT length used for test case $\\#4$ as an integer, and $R(10^6)$ is a float rounded to six decimal places. For example, your output format should look like $[\\text{True},\\text{True},\\text{True},\\text{True},1024,1.234567]$ if all tests pass with $L_4=1024$ and the computed ratio is approximately $1.234567$.",
            "solution": "The problem of multiplying two large integers can be rigorously mapped to the problem of multiplying two polynomials, which in turn can be solved efficiently using the Number Theoretic Transform (NTT) via the convolution theorem. The solution is constructed through a sequence of mathematically justified steps.\n\n### Principle-Based Design and Justification\n\n1.  **Integer Representation as Polynomials**\n\nAn arbitrary non-negative integer, say $A$, can be represented in a chosen base $B$. If $A$ is written in decimal, we can group its digits into blocks of size $\\log_{10}B$. For instance, with the specified base $B=10^3$, we group decimal digits in threes. This yields a sequence of coefficients $\\{a_i\\}_{i=0}^{n-1}$ such that $0 \\le a_i < B$ and\n$$\nA = \\sum_{i=0}^{n-1} a_i B^i\n$$\nThis representation is equivalent to evaluating the polynomial $P_A(x) = \\sum_{i=0}^{n-1} a_i x^i$ at the point $x=B$. Thus, we have $A = P_A(B)$.\n\n2.  **Integer Multiplication as Polynomial Convolution**\n\nTo multiply two integers, $A$ and $C$, we first represent them as polynomials $P_A(x)$ and $P_C(x)$ in a base $B$. Let $P_A(x) = \\sum_{i=0}^{n-1} a_i x^i$ and $P_C(x) = \\sum_{j=0}^{m-1} b_j x^j$. The product of these two polynomials is another polynomial, $P_P(x)$:\n$$\nP_P(x) = P_A(x) \\cdot P_C(x) = \\left(\\sum_{i=0}^{n-1} a_i x^i\\right) \\left(\\sum_{j=0}^{m-1} b_j x^j\\right) = \\sum_{k=0}^{n+m-2} c_k x^k\n$$\nBy expanding the product and collecting terms with the same power of $x$, the coefficient $c_k$ of $x^k$ is given by:\n$$\nc_k = \\sum_{i=0}^{k} a_i b_{k-i}\n$$\nThis is precisely the definition of the discrete convolution of the coefficient sequences $\\{a_i\\}$ and $\\{b_j\\}$, denoted $(a * b)_k$.\n\nThe integer product $A \\cdot C$ is obtained by evaluating the product polynomial $P_P(x)$ at $x=B$:\n$$\nA \\cdot C = P_A(B) \\cdot P_C(B) = P_P(B) = \\sum_{k=0}^{n+m-2} c_k B^k\n$$\nSince the convolution coefficients $c_k$ can be larger than the base $B$, this final summation requires a carry-propagation step to obtain the standard base-$B$ representation of the product. This establishes that integer multiplication is equivalent to convolving the coefficient sequences of the integers in a chosen base and then reconstructing the final integer value.\n\n3.  **Fast Convolution via Number Theoretic Transform (NTT)**\n\nThe convolution theorem states that the Discrete Fourier Transform (DFT) converts convolution into pointwise multiplication: $\\text{DFT}(a*b) = \\text{DFT}(a) \\odot \\text{DFT}(b)$, where $\\odot$ denotes element-wise multiplication. This allows for computing the convolution in $O(N \\log N)$ time using a Fast Fourier Transform (FFT) algorithm:\n$$\na * b = \\text{IDFT}(\\text{DFT}(a) \\odot \\text{DFT}(b))\n$$\nHowever, standard FFT relies on complex floating-point arithmetic, which introduces precision errors. For exact integer arithmetic, the Number Theoretic Transform (NTT) is employed. The NTT is a DFT defined over a finite field of integers modulo a prime, $\\mathbb{Z}_p$. To support a transform of length $L$, the prime $p$ must be chosen such that $L$ divides $p-1$. This ensures the existence of a primitive $L$-th root of unity in the field $\\mathbb{Z}_p$. The specified prime $p = 998244353 = 119 \\cdot 2^{23} + 1$ is an NTT-friendly prime that supports transform lengths $L$ that are powers of two up to $2^{23}$.\n\nThe NTT-based multiplication algorithm is as follows:\na.  Convert the two input integers from their decimal string representations to coefficient arrays $\\{a_i\\}$ and $\\{b_j\\}$ using base $B=10^3$. Let the number of coefficients be $n$ and $m$.\nb.  Choose the transform length $L$ to be the smallest power of two such that $L \\ge n+m-1$. This length is sufficient to represent the product polynomial's coefficients without aliasing.\nc.  Pad the coefficient arrays $\\{a_i\\}$ and $\\{b_j\\}$ with zeros to length $L$.\nd.  Compute the forward NTT of both padded arrays modulo $p$. This is done using a Cooley-Tukey FFT-style algorithm with arithmetic performed in $\\mathbb{Z}_p$.\ne.  Perform pointwise multiplication of the two transformed arrays, modulo $p$.\nf.  Compute the inverse NTT of the resulting array. This yields the convolution coefficients $\\{c_k\\}$, also modulo $p$.\n\nFor this method to be correct with a single modulus, the true convolution coefficients must not exceed the modulus $p$, i.e., $c_k < p$ for all $k$. The maximum value of a coefficient $c_k$ is bounded by $S \\cdot (B-1)^2$, where $S = \\min(n, m)$ is the maximum number of non-zero terms in the convolution sum, and $B-1$ is the maximum value of any input coefficient. The problem statement guarantees this safety bound, $S \\cdot (B-1)^2 < p$, holds for the provided test cases, ensuring that the result of the modular convolution is identical to the integer convolution.\n\ng.  Perform a carry-propagation step on the resulting coefficient array $\\{c_k\\}$ with base $B$ to compute the final integer product.\nh.  Convert the final base-$B$ representation back to a decimal string.\n\n4.  **Asymptotic Cost Comparison**\n\nThe problem provides simplified operation-count models for the multiplicative complexity of NTT-based and Karatsuba multiplication.\n-   **NTT:** The total number of multiplications is dominated by three transforms (two forward, one inverse) of length $N$, each costing $\\frac{1}{2}N\\log_2 N$ multiplications, plus one pointwise product of length $N$. This totals $M_{\\mathrm{NTT}}(N) = \\frac{3}{2}N\\log_2 N + N$.\n-   **Karatsuba:** For inputs with $s$ digits, Karatsuba multiplication has a recursive complexity that leads to $M_{\\mathrm{K}}(s) = s^{\\log_2 3}$ scalar multiplications.\n\nTo compare them for multiplying two $d$-digit decimal numbers using base $B=10^3$:\n-   The number of base-$B$ digits is $s = \\lceil d / \\log_{10}B \\rceil = \\lceil d/3 \\rceil$.\n-   The required transform length $N$ for the NTT-based method must be at least $n+m-1$. For the model, we assume $n \\approx m \\approx s$, so we need a length of at least $2s-1$. The model specifies using the smallest power of two, $N$, such that $N \\ge 2s$.\n-   For $d=10^6$, we have $s = \\lceil 10^6/3 \\rceil = 333334$. The required transform length is the smallest power of two greater than or equal to $2s=666668$, which is $N = 2^{20} = 1048576$.\n-   The number of multiplications are:\n    $$\n    M_{\\mathrm{NTT}}(1048576) = \\frac{3}{2}(1048576)\\log_2(1048576) + 1048576 = \\frac{3}{2}(2^{20})(20) + 2^{20} = 31 \\cdot 2^{20} = 32,505,856\n    $$\n    $$\n    M_{\\mathrm{K}}(333334) = (333334)^{\\log_2 3} \\approx (333334)^{1.58496} \\approx 5.666 \\times 10^8\n    $$\n-   The ratio is $R(10^6) = \\frac{M_{\\mathrm{NTT}}(N)}{M_{\\mathrm{K}}(s)} \\approx \\frac{3.251 \\times 10^7}{5.666 \\times 10^8} \\approx 0.057365$. This indicates that for million-digit numbers, the NTT-based method is asymptotically superior and requires significantly fewer multiplicative operations than Karatsuba's method under this simplified model.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to execute all parts of the problem:\n    1. Run the test suite for NTT-based multiplication.\n    2. Compute the operation count ratio for large-digit multiplication.\n    3. Print the results in the specified format.\n    \"\"\"\n\n    # --- Core Parameters from Problem Statement ---\n    P = 998244353  # Prime modulus\n    G = 3          # Primitive root modulo P\n    BASE = 10**3   # Base for polynomial representation\n    LOG_BASE = 3   # int(np.log10(BASE))\n\n    # --- Helper Functions ---\n\n    def mod_pow(base, exp, mod):\n        \"\"\"Computes (base^exp) % mod efficiently.\"\"\"\n        return pow(base, exp, mod)\n\n    def ntt(a, p, g, invert=False):\n        \"\"\"\n        Computes the Number Theoretic Transform (NTT) of array 'a'.\n        Uses an iterative Cooley-Tukey algorithm.\n        \"\"\"\n        L = len(a)\n        \n        # 1. Bit-reversal permutation\n        rev = [0] * L\n        for i in range(L):\n            rev[i] = rev[i >> 1] >> 1\n            if i & 1:\n                rev[i] |= L >> 1\n        \n        permuted_a = [a[i] for i in rev]\n\n        # 2. Main Cooley-Tukey loop\n        w_prim = mod_pow(g, (p - 1) // L, p)\n        if invert:\n            w_prim = mod_pow(w_prim, p - 2, p)  # Modular inverse for INTT\n\n        length = 2\n        while length <= L:\n            w_len = mod_pow(w_prim, L // length, p)\n            half_len = length // 2\n            i = 0\n            while i < L:\n                w = 1\n                for j in range(half_len):\n                    u = permuted_a[i + j]\n                    v = (permuted_a[i + j + half_len] * w) % p\n                    permuted_a[i + j] = (u + v) % p\n                    permuted_a[i + j + half_len] = (u - v + p) % p\n                    w = (w * w_len) % p\n                i += length\n            length <<= 1\n        \n        # 3. Final scaling for INTT\n        if invert:\n            L_inv = mod_pow(L, p - 2, p)\n            for i in range(L):\n                permuted_a[i] = (permuted_a[i] * L_inv) % p\n        \n        return permuted_a\n\n    def string_to_coeffs(s_num):\n        \"\"\"Converts a decimal string to a list of base-1000 coefficients.\"\"\"\n        if s_num == \"0\":\n            return [0]\n        coeffs = []\n        for i in range(len(s_num), 0, -LOG_BASE):\n            start = max(0, i - LOG_BASE)\n            coeffs.append(int(s_num[start:i]))\n        return coeffs\n\n    def ntt_multiply(a_str, b_str):\n        \"\"\"Multiplies two numbers (as strings) using NTT-based convolution.\"\"\"\n        if a_str == \"0\" or b_str == \"0\":\n            return \"0\", 1 # Default length if not computed\n\n        # 1. Convert strings to coefficient arrays\n        a_coeffs = string_to_coeffs(a_str)\n        b_coeffs = string_to_coeffs(b_str)\n        n = len(a_coeffs)\n        m = len(b_coeffs)\n\n        # 2. Determine transform length L\n        L = 1\n        while L < n + m - 1:\n            L <<= 1\n\n        # 3. Pad arrays\n        a_coeffs.extend([0] * (L - n))\n        b_coeffs.extend([0] * (L - m))\n\n        # 4. Perform convolution using NTT\n        a_ntt = ntt(a_coeffs, P, G)\n        b_ntt = ntt(b_coeffs, P, G)\n        \n        c_ntt = [(x * y) % P for x, y in zip(a_ntt, b_ntt)]\n        \n        conv_result = ntt(c_ntt, P, G, invert=True)\n\n        # 5. Handle carries to reconstruct the final number\n        result_coeffs = []\n        carry = 0\n        for c in conv_result:\n            val = c + carry\n            result_coeffs.append(val % BASE)\n            carry = val // BASE\n        \n        while carry > 0:\n            result_coeffs.append(carry % BASE)\n            carry //= BASE\n\n        # 6. Format the result back to a decimal string\n        while len(result_coeffs) > 1 and result_coeffs[-1] == 0:\n            result_coeffs.pop()\n        \n        first_digit = str(result_coeffs[-1])\n        other_digits = [str(d).zfill(LOG_BASE) for d in reversed(result_coeffs[:-1])]\n        \n        return first_digit + \"\".join(other_digits), L\n    \n    # --- Test Suite ---\n    test_cases = [\n        (\"0\", \"12345678901234567890\"),\n        (\"12345\", \"6789\"),\n        (\"9\" * 24, \"9\" * 24),\n        (\"12345678901234567890\" * 6, \"98765432109876543210\" * 6)\n    ]\n    \n    results = []\n    L4 = 0\n    \n    for i, (a, b) in enumerate(test_cases):\n        ntt_product, L_used = ntt_multiply(a, b)\n        py_product = str(int(a) * int(b))\n        results.append(ntt_product == py_product)\n        if i == 3: # Test case #4\n            L4 = L_used\n    \n    # --- Large-d Comparison ---\n    d = 10**6\n    s = np.ceil(d / LOG_BASE)\n    # N is the smallest power of two >= 2s\n    N = 1\n    while N < 2 * s:\n        N <<= 1\n    \n    M_NTT = 1.5 * N * np.log2(N) + N\n    M_K = s**np.log2(3)\n    R_d_large = M_NTT / M_K\n\n    # Combine all results for final output\n    final_output = results + [L4, round(R_d_large, 6)]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_output))}]\")\n\nsolve()\n```"
        }
    ]
}