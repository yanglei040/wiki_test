{
    "hands_on_practices": [
        {
            "introduction": "理论告诉我们，一个 $p$ 阶方法的全局截断误差 $E$ 与步长 $h$ 呈 $E \\approx C h^p$ 的关系。但是，我们如何在一个实际问题中验证一个未知求解器的阶呢？本练习将指导你通过一种称为“步长加倍”的实验，仅通过比较两个不同步长（例如 $h$ 和 $2h$）下的数值解误差，来估算任何“黑箱”求解器的收敛阶数 $p$。这是一种验证数值代码和理解误差行为的基本而强大的技术。",
            "id": "3156057",
            "problem": "考虑一个由 $y^{\\prime}(t) = y(t)$ 和 $y(0) = 1$ 定义的常微分方程 (ODE) 的初值问题 (IVP)。其精确解为 $y(t) = e^{t}$。一个单步 ODE 求解器通过映射 $y_{n+1} = \\Phi(t_{n}, y_{n}, h)$ 来推进数值状态，其中步长为 $h$，且 $t_{n+1} = t_{n} + h$。如果一个方法的全局截断误差在固定的最终时间 $T$ 处，对于足够小的 $h$，其大小按 $h$ 的幂次缩放，那么该方法的阶为 $p$。局部截断误差是将精确解代入数值更新公式时在单步内产生的差异；全局截断误差是在 $t = T$ 时的累积差异。\n\n你的任务是构建一个步长加倍实验，通过在求解 $y^{\\prime} = y$（精确解为 $y = e^{t}$）时测量全局截断误差 $E(h)$ 和 $E(2h)$，来估计一个黑盒 ODE 求解器的阶 $p$。该实验必须基于第一性原理：使用局部和全局截断误差的定义，并推导全局误差如何随 $h$ 的缩放而变化，而不要预先假设任何目标公式。实现两个黑盒单步求解器作为未知方法：一个前向 Euler 求解器和一个 Heun（显式梯形）求解器。将每个求解器视为一个黑盒函数，给定 $f$、$y_{0}$、$t_{0}$、$T$ 和 $h$，该函数使用固定步长返回在 $t = T$ 时的数值近似解 $y_{N}$，其中 $N = T/h$ 是一个整数。\n\n对于每组参数，使用步长 $h$ 和 $2h$ 计算在 $t = T$ 时的数值解；测量相应的全局截断误差 $E(h) = \\lvert y_{\\text{num}}(T; h) - e^{T} \\rvert$ 和 $E(2h) = \\lvert y_{\\text{num}}(T; 2h) - e^{T} \\rvert$；并利用方法阶数定义所蕴含的基本缩放关系，推导出 $p$ 的估计值。本问题不使用任何物理单位。不涉及角度。将每个估计的 $p$ 值表示为四舍五入到六位小数的浮点数。\n\n使用以下参数值测试套件，每个参数值指定为一个元组 $(\\text{solver}, T, h)$，其中 $T/h \\in \\mathbb{N}$ 且 $T/(2h) \\in \\mathbb{N}$：\n- $(\\text{Euler}, 1.0, 0.1)$，其中 $T = 1.0$，$h = 0.1$，\n- $(\\text{Heun}, 1.0, 0.1)$，其中 $T = 1.0$，$h = 0.1$，\n- $(\\text{Euler}, 2.0, 0.05)$，其中 $T = 2.0$，$h = 0.05$，\n- $(\\text{Heun}, 2.0, 0.05)$，其中 $T = 2.0$，$h = 0.05$，\n- $(\\text{Euler}, 1.0, 0.5)$，其中 $T = 1.0$，$h = 0.5$，\n- $(\\text{Heun}, 1.0, 0.001)$，其中 $T = 1.0$，$h = 0.001$。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的结果按上述顺序排列；例如，形如 [$p_{1},$ $p_{2},$ $p_{3},$ $p_{4},$ $p_{5},$ $p_{6}$] 的输出，其中每个 $p_{i}$ 都四舍五入到六位小数。",
            "solution": "用户提供了一个来自计算科学领域的有效且适定的问题陈述。该问题在科学上基于常微分方程（ODE）数值方法的理论，内容自洽，并有一个清晰、可验证的目标。\n\n任务是通过执行步长加倍实验来估计两个单步 ODE 求解器的收敛阶 $p$。这需要从第一性原理推导出 $p$ 的估计量，然后将其应用于一个特定的初值问题 (IVP)。\n\n### 阶估计量的原理与推导\n\n如果一个求解 ODE 的数值方法，其在固定最终时间 $T$ 的全局截断误差 $E$ 与步长 $h$ 满足以下关系，则称该方法的收敛阶为 $p$：\n$$\nE(h) = \\lvert y_{\\text{num}}(T; h) - y(T) \\rvert \\approx C h^p\n$$\n对于足够小的 $h$。其中，$y_{\\text{num}}(T; h)$ 是使用步长 $h$ 在时间 $T$ 得到的数值解，$y(T)$ 是精确解，$C$ 是一个常数，它依赖于 ODE、其解、最终时间 $T$ 以及具体方法，但假定与 $h$ 无关。\n\n为了在不知道常数 $C$ 的情况下估计 $p$，我们可以使用两个不同的步长来计算误差。问题指定了步长加倍实验，因此我们使用步长 $h$ 和 $2h$。根据缩放关系，误差分别为：\n$$\nE(h) \\approx C h^p \\quad (1)\n$$\n$$\nE(2h) \\approx C (2h)^p = C 2^p h^p \\quad (2)\n$$\n\n为了消去未知常数 $C$，我们可以将方程 $(2)$ 与方程 $(1)$ 相除：\n$$\n\\frac{E(2h)}{E(h)} \\approx \\frac{C 2^p h^p}{C h^p} = 2^p\n$$\n\n这个关系提供了一种直接估计 $p$ 的方法。通过对两边取以 2 为底的对数，我们分离出 $p$：\n$$\n\\log_2\\left(\\frac{E(2h)}{E(h)}\\right) \\approx \\log_2(2^p) = p\n$$\n\n因此，我们对方法阶数的估计量为：\n$$\np \\approx \\log_2\\left(\\frac{E(2h)}{E(h)}\\right)\n$$\n此公式直接从方法阶数的定义推导而来，并构成了我们数值实验的基础。\n\n### 数值实验的实现\n\n实验将在以下 IVP 上进行：\n- **ODE：** $y'(t) = y(t)$\n- **初始条件：** $y(0) = 1$\n- **精确解：** $y(t) = e^t$\n\nODE 的右侧由函数 $f(t, y) = y$ 给出。\n\n我们将实现两个“黑盒”单步求解器：\n\n1.  **前向 Euler 方法：** 这是一种显式一阶方法。从步骤 $n$ 推进到 $n+1$ 的更新规则是：\n    $$\n    y_{n+1} = y_n + h f(t_n, y_n)\n    $$\n    对于我们的特定 IVP，这变为 $y_{n+1} = y_n + h y_n = y_n(1+h)$。\n\n2.  **Heun 方法（显式梯形法则）：** 这是一种显式二阶方法，属于预测-校正方法或 Runge-Kutta 方法族。其更新规则是：\n    $$\n    k_1 = f(t_n, y_n)\n    $$\n    $$\n    k_2 = f(t_n + h, y_n + h k_1)\n    $$\n    $$\n    y_{n+1} = y_n + \\frac{h}{2}(k_1 + k_2)\n    $$\n    这可以看作是先进行一个初始的 Euler 步（预测步），然后对区间起点和预测终点的斜率进行平均（校正步）。\n\n对于问题陈述中指定的每个测试用例 $(\\text{solver}, T, h)$，执行以下算法：\n\n1.  设置初始条件 $y_0 = 1$ 和 $t_0 = 0$。\n2.  使用所选求解器以步长 $h$ 进行 $N_1 = T/h$ 步计算，得到数值解 $y_{\\text{num}}(T; h)$。\n3.  使用相同求解器以步长 $2h$ 进行 $N_2 = T/(2h)$ 步计算，得到数值解 $y_{\\text{num}}(T; 2h)$。\n4.  计算最终时间的精确解 $y(T) = e^T$。\n5.  确定全局截断误差：\n    $$\n    E(h) = \\lvert y_{\\text{num}}(T; h) - e^T \\rvert\n    $$\n    $$\n    E(2h) = \\lvert y_{\\text{num}}(T; 2h) - e^T \\rvert\n    $$\n6.  最后，使用推导出的公式计算估计的阶 $p$：\n    $$\n    p = \\log_2\\left(\\frac{E(2h)}{E(h)}\\right)\n    $$\n按要求将得到的 $p$ 值四舍五入到六位小数。对所有测试用例重复此过程。前向 Euler 方法预期将得到 $p \\approx 1$，而 Heun 方法应得到 $p \\approx 2$，估计的准确性取决于对于给定的步长 $h$，渐近误差行为的确立程度。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the estimated order of convergence for Euler and Heun methods\n    using a step-doubling experiment based on a set of test cases.\n    \"\"\"\n\n    def ode_f(t, y):\n        \"\"\"The right-hand side of the ODE y' = y.\"\"\"\n        return y\n\n    def forward_euler_solver(f, y0, t0, T, h):\n        \"\"\"\n        Solves an IVP using the Forward Euler method.\n        \n        Args:\n            f: The function f(t, y) for the ODE y' = f(t, y).\n            y0: The initial value y(t0).\n            t0: The initial time.\n            T: The final time.\n            h: The step size.\n        \n        Returns:\n            The numerical solution at time T.\n        \"\"\"\n        y = y0\n        t = t0\n        num_steps = int(np.round((T - t0) / h))\n        \n        for _ in range(num_steps):\n            y = y + h * f(t, y)\n            t = t + h\n            \n        return y\n\n    def heun_solver(f, y0, t0, T, h):\n        \"\"\"\n        Solves an IVP using Heun's method (explicit trapezoidal rule).\n        \n        Args:\n            f: The function f(t, y) for the ODE y' = f(t, y).\n            y0: The initial value y(t0).\n            t0: The initial time.\n            T: The final time.\n            h: The step size.\n        \n        Returns:\n            The numerical solution at time T.\n        \"\"\"\n        y = y0\n        t = t0\n        num_steps = int(np.round((T - t0) / h))\n        \n        for _ in range(num_steps):\n            k1 = f(t, y)\n            k2 = f(t + h, y + h * k1)\n            y = y + (h / 2.0) * (k1 + k2)\n            t = t + h\n            \n        return y\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\"Euler\", 1.0, 0.1),\n        (\"Heun\", 1.0, 0.1),\n        (\"Euler\", 2.0, 0.05),\n        (\"Heun\", 2.0, 0.05),\n        (\"Euler\", 1.0, 0.5),\n        (\"Heun\", 1.0, 0.001),\n    ]\n\n    solvers = {\n        \"Euler\": forward_euler_solver,\n        \"Heun\": heun_solver,\n    }\n\n    results = []\n    \n    for solver_name, T, h in test_cases:\n        solver_func = solvers[solver_name]\n        \n        # Initial conditions for the IVP y'=y, y(0)=1\n        y0 = 1.0\n        t0 = 0.0\n        \n        # Define the two step sizes for the experiment\n        h1 = h\n        h2 = 2.0 * h\n        \n        # Compute numerical solutions for both step sizes\n        y_num_h1 = solver_func(ode_f, y0, t0, T, h1)\n        y_num_h2 = solver_func(ode_f, y0, t0, T, h2)\n        \n        # Compute the exact solution at T\n        y_exact = np.exp(T)\n        \n        # Compute the global truncation errors\n        error_h1 = np.abs(y_num_h1 - y_exact)\n        error_h2 = np.abs(y_num_h2 - y_exact)\n        \n        # Estimate the order p\n        # p is approximately log2(E(2h) / E(h))\n        # Handle cases where error might be zero to avoid division by zero\n        if error_h1 == 0.0:\n            # If the smaller step size gives zero error, the order cannot be determined\n            # by this method. This is unlikely for these methods and ODE.\n            # We can represent this as infinity or NaN, but for the purpose of this\n            # problem, we assume non-zero error.\n            # In a real-world scenario, a different approach would be needed.\n            # Given the problem context, this case is not expected to occur.\n            p = np.nan \n        else:\n            p = np.log2(error_h2 / error_h1)\n        \n        results.append(p)\n\n    # Format results to six decimal places and create the final output string\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在上一节中，我们学会了如何通过误差与步长的关系来估计求解器的阶。现在，我们将更进一步：我们能否主动利用这种可预测的误差结构来提高解的精度？本练习将介绍理查森外推法（Richardson Extrapolation），这是一种强大的技术，它通过线性组合两次不同步长（如 $h$ 和 $h/2$）下计算出的数值解，来巧妙地消除主导的误差项，从而获得一个更高阶、更精确的近似解。这个练习展示了如何将对误差的理解从被动的分析工具转变为主动提升解质量的强大武器。",
            "id": "2409197",
            "problem": "实现一个完整的程序，对于一组形式为 $\\dfrac{dy}{dt} = f(t,y)$ 且 $y(0) = y_0$ 的初值问题，执行以下操作：从局部截断误差和全局截断误差的定义出发，推导出一个 Richardson 外推组合，该组合通过结合使用步长 $h$ 和 $h/2$ 计算出的两个欧拉解，来消除显式欧拉法的主要全局误差项。该组合必须基于全局误差以 $h$ 的幂次进行渐近展开的假设，从第一性原理推导得出，并且必须产生一个新的近似解，其全局截断误差的阶为 $\\mathcal{O}(h^2)$。\n\n你的推导必须基于以下基本事实：\n- 显式欧拉法由递推式 $y_{n+1} = y_n + h f(t_n, y_n)$ 定义，其中 $t_n = t_0 + n h$。\n- 局部截断误差是将精确解代入单个方法步骤中得到的单步缺陷，对于光滑的 $f$，其量级为 $\\mathcal{O}(h^2)$。\n- 在固定的最终时间 $T$，全局截断误差是经过 $N = T/h$ 步后，精确解与数值解之间累积的差异；对于显式欧拉法，其量级为 $\\mathcal{O}(h)$。\n\n你的程序必须实现：\n1. 一个函数，用于计算在最终时间 $T$ 处，使用均匀步长 $h$ 的显式欧拉解 $y_h(T)$。\n2. 一个 Richardson 外推组合，仅使用步长为 $h$ 和 $h/2$ 计算出的两个欧拉解，产生一个改进的近似解 $y_{\\mathrm{RE}}(T)$，其全局截断误差的量级为 $\\mathcal{O}(h^2)$。\n3. 一个经验性验证程序，该程序也计算步长为 $h/4$ 的解，以便你可以估计观测到的收敛阶：\n   - 对于显式欧拉法，估计 $p_{\\mathrm{E}} \\approx \\log_2\\left(\\dfrac{|y_h(T) - y(T)|}{|y_{h/2}(T) - y(T)|}\\right)$。\n   - 对于 Richardson 外推近似，首先构造 $y_{\\mathrm{RE}}(h) = \\mathrm{RE}(y_h, y_{h/2})$ 和 $y_{\\mathrm{RE}}(h/2) = \\mathrm{RE}(y_{h/2}, y_{h/4})$，然后估计 $p_{\\mathrm{RE}} \\approx \\log_2\\left(\\dfrac{|y_{\\mathrm{RE}}(h) - y(T)|}{|y_{\\mathrm{RE}}(h/2) - y(T)|}\\right)$。\n\n角度必须以弧度为单位进行解释。\n\n测试套件：\n对于下述每种情况，计算 $y_h(T)$、$y_{h/2}(T)$、$y_{h/4}(T)$，构造 $y_{\\mathrm{RE}}(h)$ 和 $y_{\\mathrm{RE}}(h/2)$，然后计算相对于精确解 $y(T)$ 的绝对误差。\n- 情况 A（指数衰减）：$\\dfrac{dy}{dt} = -3 y$，$y(0) = 1$，$T = 1$，基础步长 $h = 0.2$。精确解：$y(t) = e^{-3 t}$。\n- 情况 B（线性非齐次）：$\\dfrac{dy}{dt} = t + y$，$y(0) = 0$，$T = 1$，基础步长 $h = 0.2$。精确解：$y(t) = e^{t} - (t + 1)$。\n- 情况 C（变系数增长）：$\\dfrac{dy}{dt} = \\sin(t)\\, y$，$y(0) = 1$，$T = 1$，基础步长 $h = 0.2$。精确解：$y(t) = \\exp\\!\\big(1 - \\cos(t)\\big)$。\n\n对于每种情况，你的程序必须生成一个包含五个实数的列表：\n- 步长为 $h$ 的欧拉法的绝对全局误差，即 $E_h = |y_h(T) - y(T)|$。\n- 步长为 $h/2$ 的欧拉法的绝对全局误差，即 $E_{h/2} = |y_{h/2}(T) - y(T)|$。\n- 由 $h$ 和 $h/2$ 构建的 Richardson 外推近似的绝对全局误差，即 $E_{\\mathrm{RE}}(h) = |y_{\\mathrm{RE}}(h) - y(T)|$。\n- 上面定义的观测阶 $p_{\\mathrm{E}}$。\n- 上面定义的观测阶 $p_{\\mathrm{RE}}$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含三种情况的结果，按情况 A、情况 B、情况 C 的顺序，作为一个由三个列表组成的逗号分隔列表，并用一对单独的方括号括起来，其中不含任何空格。每个实数必须以科学记数法打印，并保留十位有效数字。例如，该行必须如下所示：\n[[E_h_A,E_h2_A,E_RE_A,pE_A,pRE_A],[E_h_B,E_h2_B,E_RE_B,pE_B,pRE_B],[E_h_C,E_h2_C,E_RE_C,pE_C,pRE_C]]\n确保所有三角函数的参数都以弧度为单位。由于本问题中所有量都是无量纲的，因此不需要单位。",
            "solution": "问题陈述经过验证。\n\n按原文提取给定条件：\n1.  初值问题：$\\dfrac{dy}{dt} = f(t,y)$，$y(0) = y_0$。\n2.  显式欧拉法递推式：$y_{n+1} = y_n + h f(t_n, y_n)$，其中 $t_n = t_0 + n h$。\n3.  显式欧拉法的局部截断误差量级为 $\\mathcal{O}(h^2)$。\n4.  在固定时间 $T$，显式欧拉法的全局截断误差量级为 $\\mathcal{O}(h)$。\n5.  任务：为两个步长为 $h$ 和 $h/2$ 的欧拉解推导一个 Richardson 外推组合，以消除主要的全局误差项，假设全局误差存在渐近展开。所得近似的全局误差阶必须为 $\\mathcal{O}(h^2)$。\n6.  任务：使用步长 $h$、$h/2$ 和 $h/4$ 进行经验性验证。\n7.  欧拉法的观测阶：$p_{\\mathrm{E}} \\approx \\log_2\\left(\\dfrac{|y_h(T) - y(T)|}{|y_{h/2}(T) - y(T)|}\\right)$。\n8.  Richardson 外推法的观测阶：$p_{\\mathrm{RE}} \\approx \\log_2\\left(\\dfrac{|y_{\\mathrm{RE}}(h) - y(T)|}{|y_{\\mathrm{RE}}(h/2) - y(T)|}\\right)$，其中 $y_{\\mathrm{RE}}(h) = \\mathrm{RE}(y_h, y_{h/2})$ 且 $y_{\\mathrm{RE}}(h/2) = \\mathrm{RE}(y_{h/2}, y_{h/4})$。\n9.  测试用例 A：$\\dfrac{dy}{dt} = -3 y$，$y(0) = 1$，$T = 1$，$h = 0.2$。精确解：$y(t) = e^{-3 t}$。\n10. 测试用例 B：$\\dfrac{dy}{dt} = t + y$，$y(0) = 0$，$T = 1$，$h = 0.2$。精确解：$y(t) = e^{t} - (t + 1)$。\n11. 测试用例 C：$\\dfrac{dy}{dt} = \\sin(t)\\, y$，$y(0) = 1$，$T = 1$，$h = 0.2$。精确解：$y(t) = \\exp\\!\\big(1 - \\cos(t)\\big)$。\n12. 每个用例的所需输出：一个包含五个数字的列表：$|y_h(T) - y(T)|$，$|y_{h/2}(T) - y(T)|$，$|y_{\\mathrm{RE}}(h) - y(T)|$，$p_{\\mathrm{E}}$ 和 $p_{\\mathrm{RE}}$。\n\n使用提取的给定条件进行验证：\n该问题具有科学依据。它涉及 Richardson 外推法，这是数值分析中用于提高数值方法精度的一种标准和基本技术。其前提——显式欧拉法的定义以及其局部和全局截断误差的阶——是常微分方程数值解研究中的标准结果。该问题是适定的；它要求对定义明确、具有唯一解析解的测试用例进行特定的推导和实现，确保可以获得并验证一个唯一且有意义的结果。语言客观、精确。该问题不违反任何无效性标准。这是一个与计算物理和数值方法直接相关的可形式化问题。\n\n结论：问题有效。将提供解决方案。\n\nRichardson 外推公式的推导必须按规定从第一性原理构建。该方法的基础是数值方案的全局误差存在渐近展开。对于全局误差为 $\\mathcal{O}(h)$ 阶的显式欧拉法，该展开式具有以下形式：\n$$\ny_h(T) = y(T) + C_1 h + C_2 h^2 + C_3 h^3 + \\dots\n$$\n这里，$y(T)$ 是在最终时间 $T$ 的精确解，$y_h(T)$ 是用步长 $h$ 获得的数值近似解，系数 $C_k$ 与 $h$ 无关，但依赖于函数 $f(t,y)$ 及其在各点的导数。主要误差项是 $C_1 h$。\n\n我们的目标是通过组合两次独立的计算来消除这个主要项。我们用步长 $h$ 进行数值积分，然后再次用步长 $h/2$ 进行。相应数值解的渐近展开式为：\n$$\n(1) \\quad y_h(T) = y(T) + C_1 h + C_2 h^2 + \\mathcal{O}(h^3)\n$$\n$$\n(2) \\quad y_{h/2}(T) = y(T) + C_1 \\frac{h}{2} + C_2 \\left(\\frac{h}{2}\\right)^2 + \\mathcal{O}(h^3) = y(T) + \\frac{1}{2} C_1 h + \\frac{1}{4} C_2 h^2 + \\mathcal{O}(h^3)\n$$\n我们寻求 $y_h(T)$ 和 $y_{h/2}(T)$ 的一个线性组合，以消除与 $C_1 h$ 成比例的项。设外推近似为 $y_{\\mathrm{RE}}(T)$。为消除 $C_1 h$，我们可以将方程 $(2)$ 乘以 $2$，然后减去方程 $(1)$：\n$$\n2 y_{h/2}(T) - y_h(T) = \\left(2y(T) + C_1 h + \\frac{1}{2} C_2 h^2 + \\dots\\right) - \\left(y(T) + C_1 h + C_2 h^2 + \\dots\\right)\n$$\n$$\n2 y_{h/2}(T) - y_h(T) = (2-1)y(T) + (1-1)C_1 h + \\left(\\frac{1}{2}-1\\right)C_2 h^2 + \\mathcal{O}(h^3)\n$$\n$$\n2 y_{h/2}(T) - y_h(T) = y(T) - \\frac{1}{2} C_2 h^2 + \\mathcal{O}(h^3)\n$$\n由此，我们定义 Richardson 外推解 $y_{\\mathrm{RE}}(T)$ 为：\n$$\ny_{\\mathrm{RE}}(T) = 2 y_{h/2}(T) - y_h(T)\n$$\n这个新近似的全局截断误差是差值 $y_{\\mathrm{RE}}(T) - y(T)$。根据我们的推导：\n$$\ny_{\\mathrm{RE}}(T) - y(T) = -\\frac{1}{2} C_2 h^2 + \\mathcal{O}(h^3)\n$$\n这证实了全局截断误差现在是 $\\mathcal{O}(h^2)$ 阶，符合要求。原始方法的主要误差项已被成功消除。\n\n计算实现将包括三个主要部分。首先，一个函数 `explicit_euler` 将使用一个恒定的步长 $h$ 求解给定的常微分方程，从初始时间 $t_0$ 到最终时间 $T$。该函数将实现递推式 $y_{k+1} = y_k + h f(t_k, y_k)$，迭代 $N = \\text{round}((T-t_0)/h)$ 次。\n\n其次，一个主程序将为每个测试用例执行逻辑。对于一个基础步长 $h$，它将使用步长 $h$、$h/2$ 和 $h/4$ 调用 `explicit_euler` 函数三次，以获得数值解 $y_h(T)$、$y_{h/2}(T)$ 和 $y_{h/4}(T)$。\n\n第三，该程序将使用这些数值结果进行经验分析。它将计算 Richardson 外推近似值：\n$$\ny_{\\mathrm{RE}}(h) = 2 y_{h/2}(T) - y_h(T)\n$$\n$$\ny_{\\mathrm{RE}}(h/2) = 2 y_{h/4}(T) - y_{h/2}(T)\n$$\n然后，相对于已知的精确解 $y(T)$ 计算绝对全局误差。最后，使用指定的对数公式计算观测到的收敛阶 $p_{\\mathrm{E}}$ 和 $p_{\\mathrm{RE}}$。这些经验阶数对于欧拉法应约等于 $1$，对于 Richardson 外推法应约等于 $2$，从而验证了精度的理论提升。所有测试用例的最终结果将根据指定格式进行格式化和打印。三角函数的输入将按科学计算中的标准以弧度处理。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements Richardson extrapolation for the explicit Euler method to solve\n    several initial value problems and empirically verifies the order of convergence.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"f\": lambda t, y: -3.0 * y,\n            \"y0\": 1.0,\n            \"T\": 1.0,\n            \"h\": 0.2,\n            \"exact_y\": lambda t: np.exp(-3.0 * t),\n        },\n        {\n            \"f\": lambda t, y: t + y,\n            \"y0\": 0.0,\n            \"T\": 1.0,\n            \"h\": 0.2,\n            \"exact_y\": lambda t: np.exp(t) - (t + 1.0),\n        },\n        {\n            \"f\": lambda t, y: np.sin(t) * y,\n            \"y0\": 1.0,\n            \"T\": 1.0,\n            \"h\": 0.2,\n            \"exact_y\": lambda t: np.exp(1.0 - np.cos(t)),\n        },\n    ]\n\n    def explicit_euler(f_ode, y_start, t_start, t_end, step_size):\n        \"\"\"\n        Computes the solution of an ODE using the explicit Euler method.\n        \"\"\"\n        t = t_start\n        y = y_start\n        # Use round() to avoid floating-point inaccuracies in step counting\n        num_steps = int(round((t_end - t_start) / step_size))\n        \n        for _ in range(num_steps):\n            y = y + step_size * f_ode(t, y)\n            t = t + step_size\n        return y\n\n    all_results = []\n    for case in test_cases:\n        f = case[\"f\"]\n        y0 = case[\"y0\"]\n        T = case[\"T\"]\n        h_base = case[\"h\"]\n        exact_y_func = case[\"exact_y\"]\n\n        # Define the three step sizes\n        h = h_base\n        h_half = h_base / 2.0\n        h_quarter = h_base / 4.0\n\n        # Compute Euler solutions for each step size\n        y_h = explicit_euler(f, y0, 0.0, T, h)\n        y_h_half = explicit_euler(f, y0, 0.0, T, h_half)\n        y_h_quarter = explicit_euler(f, y0, 0.0, T, h_quarter)\n\n        # Compute the exact solution at the final time T\n        y_exact = exact_y_func(T)\n\n        # Compute Richardson-extrapolated approximations\n        y_re_h = 2.0 * y_h_half - y_h\n        y_re_h_half = 2.0 * y_h_quarter - y_h_half\n\n        # Compute absolute errors\n        E_h = np.abs(y_h - y_exact)\n        E_h_half = np.abs(y_h_half - y_exact)\n        E_re_h = np.abs(y_re_h - y_exact)\n        E_re_h_half = np.abs(y_re_h_half - y_exact)\n\n        # Compute observed orders of convergence\n        # Handle cases where error is zero to avoid division by zero or log(0)\n        p_E = np.log2(E_h / E_h_half) if E_h_half > 0 else 0.0\n        p_RE = np.log2(E_re_h / E_re_h_half) if E_re_h_half > 0 else 0.0\n\n        results = [E_h, E_h_half, E_re_h, p_E, p_RE]\n        all_results.append(results)\n\n    # Format the final output string as specified\n    formatted_cases = []\n    for case_res in all_results:\n        formatted_nums = [f\"{num:.10e}\" for num in case_res]\n        formatted_cases.append(f\"[{','.join(formatted_nums)}]\")\n    \n    final_output = f\"[{','.join(formatted_cases)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "到目前为止，我们已经看到了高阶方法在追求精度方面的优势。但是，高阶方法是否总是更优的选择？本练习将挑战这一直觉。我们将构建一个场景，其中一个高阶的四阶龙格-库塔（RK4）方法产生的全局误差，竟然比一个简单的二阶方法的误差还要大。这个“反直觉”的例子揭示了一个深刻的道理：数值方法的收敛阶理论是建立在问题足够“光滑”的假设之上的，当这个假设被破坏时，高阶方法的优势可能会荡然无存，甚至表现更差。",
            "id": "2409223",
            "problem": "您的任务是构建并测试一个案例，其中高阶单步法比低阶单步法产生更大的全局截断误差（GTE），并通过计算进行验证。具体来说，请比较经典的4阶龙格-库塔法（RK4）与2阶休恩法（Heun's method，即显式梯形法）。请严格基于以下基本概念进行操作。\n\n- 基本定义：\n  - 对于一个常微分方程（ODE）的初值问题 $y'(t) = f(t,y(t))$，初始条件为 $y(t_0) = y_0$，其在时间 $t$ 的精确解为 $y(t)$。\n  - 一个p阶单步法的局部截断误差（LTE）是在假设前一步是精确的情况下，单步引入的误差。在足够光滑的条件下，对于步长 $h$，其量级为 $\\mathcal{O}(h^{p+1})$。\n  - 在最终时间 $T$ 的全局截断误差（GTE）是数值解与精确解在 $T$ 处的绝对差值。对于足够光滑的问题和足够小的 $h$，其量级为 $\\mathcal{O}(h^p)$。\n- 广泛使用的数值方法：\n  - 休恩法（显式梯形法则）通过以下方式从 $t_n$ 处的 $y_n$ 更新到 $y_{n+1}$：\n    $$y_{n+1} = y_n + \\frac{h}{2}\\left[f(t_n,y_n) + f\\!\\left(t_n+h,\\,y_n + h\\,f(t_n,y_n)\\right)\\right].$$\n  - 经典的RK4法通过以下分段计算从 $t_n$ 处的 $y_n$ 更新到 $y_{n+1}$：\n    $$k_1 = f(t_n, y_n),\\quad k_2 = f\\!\\left(t_n+\\frac{h}{2},\\, y_n + \\frac{h}{2}k_1\\right),\\quad k_3 = f\\!\\left(t_n+\\frac{h}{2},\\, y_n + \\frac{h}{2}k_2\\right),\\quad k_4 = f(t_n+h, y_n + h k_3),$$\n    $$y_{n+1} = y_n + \\frac{h}{6}\\left(k_1 + 2k_2 + 2k_3 + k_4\\right).$$\n\n任务要求：\n- 设计并分析一个常微分方程 $y'(t)=f(t,y)$ 和一个步长 $h$，使得在指定的最终时间 $T$ 时，RK4法产生的GTE比休恩法更大。您的设计必须在科学上真实且逻辑上一致。\n- 使用纯数学描述。若使用三角函数，需指明所有角度均为弧度。\n- 您必须实现一个程序，该程序：\n  - 定义用于验证的常微分方程及其精确解。\n  - 实现用于任意标量常微分方程 $y'(t)=f(t,y)$ 的休恩法和RK4法。\n  - 使用均匀步长 $h$ 从 $t_0$ 推进到 $T$，其中 $N = T/h$ 为整数。\n  - 计算每种方法的GTE，即 $|y_{\\text{num}}(T) - y_{\\text{exact}}(T)|$。\n  - 对每个测试案例，返回一个布尔值，指示RK4的GTE是否严格大于Heun法的GTE。\n- 角度必须以弧度为单位进行解释。\n\n测试套件：\n提供以下测试案例以覆盖不同方面（一个构造的反例、一个光滑稳定情况、一个振荡强迫项情况以及一个边界情况）：\n\n1. 在步长内有间断点的构造反例：\n   - ODE: $y'(t) = H(t-\\tau)$，其中 $H$ 是亥维赛阶跃函数，定义为当 $x  0$ 时 $H(x)=0$，当 $x \\ge 0$ 时 $H(x)=1$。\n   - 初始条件: $y(0)=0$。\n   - 参数: $\\tau = 0.49$, $h = 1.0$, $T = h$。\n   - 精确解: 若 $T \\le \\tau$，则 $y(T) = 0$，否则 $y(T) = T - \\tau$。\n   - 预期定性行为：Heun法（梯形法）仅在端点采样，将比RK4更接近精确积分，而RK4则在跳跃点附近的中点处赋予了很高的权重，导致RK4产生更大的GTE。\n\n2. 光滑衰减（稳定线性ODE）：\n   - ODE: $y'(t) = \\lambda\\, y(t)$。\n   - 初始条件: $y(0)=1$。\n   - 参数: $\\lambda = -10$, $h = 0.1$, $T = 1.0$。\n   - 精确解: $y(T) = e^{\\lambda T}$。\n   - 预期定性行为：RK4的GTE应小于Heun法。\n\n3. 光滑振荡强迫项，单步求积：\n   - ODE: $y'(t) = \\sin(\\Omega t)$，角度以弧度为单位。\n   - 初始条件: $y(0)=0$。\n   - 参数: $\\Omega = 50$, $h = 0.2$, $T = h$。\n   - 精确解: $y(T) = \\int_0^T \\sin(\\Omega t)\\,dt = \\frac{1-\\cos(\\Omega T)}{\\Omega}$。\n   - 预期定性行为：在这种情况下，RK4退化为辛普森法则，通常其GTE应小于Heun法（梯形法）。\n\n4. 区间内无跳跃的边界情况：\n   - ODE: $y'(t) = H(t-\\tau)$，如案例1。\n   - 初始条件: $y(0)=0$。\n   - 参数: $\\tau = 2.0$, $h = 1.0$, $T = h$。\n   - 精确解: $y(T) = 0$。\n   - 预期定性行为：两种方法都产生零误差；RK4的GTE不大于Heun法。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含测试套件的布尔结果，按顺序以逗号分隔并用方括号括起来，例如 $\\texttt{[True,False,False,False]}$。\n- 无用户输入。所有量均为无量纲量，适用时角度单位为弧度。",
            "solution": "手头的问题是有效的。这是一个适定的、有科学依据的数值分析练习，旨在探索常微分方程（ODE）求解器收敛渐近阶的局限性。核心任务是展示并用计算验证一个场景，在该场景中，一个更高阶的方法，特别是经典的四阶龙格-库塔法（RK4），产生的全局截断误差（GTE）比一个更低阶的方法，即休恩的二阶方法，要大。\n\n常微分方程数值方法的一般原理是，对于一个问题 $y'(t) = f(t,y(t))$，如果函数 $f$ 足够光滑，那么一个 $p$ 阶方法对于足够小的步长 $h$ 将产生一个量级为 $\\mathcal{O}(h^p)$ 的GTE。这种渐近行为意味着，对于小的 $h$，高阶方法更精确。然而，这一保证取决于两个关键条件：$f$ 的光滑性和 $h$ 的微小性。所给问题构造了一些违反这些条件的测试案例，以说明这一普遍规则的失效。\n\n待比较的方法是休恩法（Heun's method，阶数 $p=2$）：\n$$y_{n+1} = y_n + \\frac{h}{2}\\left[f(t_n,y_n) + f\\!\\left(t_n+h,\\,y_n + h\\,f(t_n,y_n)\\right)\\right]$$\n和经典的RK4法（阶数 $p=4$）：\n$$k_1 = f(t_n, y_n),\\quad k_2 = f\\!\\left(t_n+\\frac{h}{2},\\, y_n + \\frac{h}{2}k_1\\right),\\quad k_3 = f\\!\\left(t_n+\\frac{h}{2},\\, y_n + \\frac{h}{2}k_2\\right),\\quad k_4 = f(t_n+h, y_n + h k_3)$$\n$$y_{n+1} = y_n + \\frac{h}{6}\\left(k_1 + 2k_2 + 2k_3 + k_4\\right)$$\n\n让我们分析这些测试案例。\n\n测试案例1：构造的反例。\nODE是 $y'(t) = H(t-\\tau)$，其中 $y(0)=0$，$H$ 是亥维赛阶跃函数，定义为当 $x  0$ 时 $H(x)=0$，当 $x \\ge 0$ 时 $H(x)=1$。参数为 $\\tau = 0.49$, $h=1.0$, $T=1.0$。这是一个从 $t_0=0$ 到 $t_1=T=1.0$ 的单步积分。函数 $f(t,y) = H(t-0.49)$ 在 $t=0.49$ 处有一个跳跃间断点，该点位于积分区间 $[0, 1]$ 内部。\n精确解是右侧函数的积分：\n$$y_{\\text{exact}}(1.0) = \\int_0^{1.0} H(t-0.49) \\, dt = \\int_{0.49}^{1.0} 1 \\, dt = 1.0 - 0.49 = 0.51$$\n我们现在从 $t_0=0$ 时的 $y_0=0$ 开始计算数值解。\n对于休恩法，当 $f$ 不依赖于 $y$ 时，该方法即为梯形法则：\n$$f(t_0, y_0) = H(0 - 0.49) = 0$$\n$$f(t_0+h, y_0 + h f(t_0,y_0)) = f(1.0, 0) = H(1.0 - 0.49) = 1$$\n$$y_1^{\\text{Heun}} = y_0 + \\frac{h}{2}[f(t_0,y_0) + f(t_0+h, \\dots)] = 0 + \\frac{1.0}{2}[0 + 1] = 0.5$$\n休恩法的GTE为 $|y_1^{\\text{Heun}} - y_{\\text{exact}}(1.0)| = |0.5 - 0.51| = 0.01$。\n\n对于RK4法：\n$$k_1 = f(t_0, y_0) = H(0 - 0.49) = 0$$\n$$k_2 = f(t_0+\\frac{h}{2}, y_0+\\frac{h}{2}k_1) = f(0.5, 0) = H(0.5 - 0.49) = H(0.01) = 1$$\n$$k_3 = f(t_0+\\frac{h}{2}, y_0+\\frac{h}{2}k_2) = f(0.5, 0.5) = H(0.5 - 0.49) = H(0.01) = 1$$\n$$k_4 = f(t_0+h, y_0+hk_3) = f(1.0, 1.0) = H(1.0 - 0.49) = H(0.51) = 1$$\n$$y_1^{\\text{RK4}} = y_0 + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4) = 0 + \\frac{1.0}{6}(0 + 2(1) + 2(1) + 1) = \\frac{5}{6} \\approx 0.8333...$$\nRK4的GTE为 $|y_1^{\\text{RK4}} - y_{\\text{exact}}(1.0)| = |\\frac{5}{6} - 0.51| = |\\frac{500-306}{600}| = \\frac{194}{600} \\approx 0.3233...$。\n比较误差，$0.3233... > 0.01$。因此，GTE(RK4)严格大于GTE(Heun)。$f$ 缺乏光滑性，加上一个跨越间断点的大步长 $h$，导致了高阶方法的失效。RK4的内部分段在恰好越过跳跃点的中点（$t=0.5$）处对函数进行采样，导致其严重高估了函数在该区间上的平均值。而休恩法仅在端点采样，在这种特定情况下恰好得出了一个更合理的估计。\n\n测试案例2：光滑衰减。\nODE是 $y'(t) = \\lambda y(t)$，其中 $\\lambda=-10$，这是稳定性和准确性的标准测试。函数 $f(t,y) = -10y$ 是无限可微的（解析的）。步长为 $h=0.1$，最终时间为 $T=1.0$。这些条件满足渐近误差估计有意义的要求。我们期望四阶方法比二阶方法精确得多。因此，我们预计GTE(RK4)  GTE(Heun)。\n\n测试案例3：光滑振荡强迫项。\nODE是 $y'(t) = \\sin(\\Omega t)$，其中 $\\Omega=50$，这是一个简单的求积问题。步长 $h=0.2$ 与振荡周期 $T_{osc} = 2\\pi/\\Omega \\approx 0.126$ 相比是大的。该步长不满足奈奎斯特采样准则（$h \\ll T_{osc}/2$）。在这种情况下，渐近误差行为无法保证。对于这个问题，休恩法退化为积分的梯形法则，而RK4退化为辛普森法则。虽然辛普森法则通常更精确，但其精度取决于能否解析函数的特征。通过在 $t=0, 0.1, 0.2$ 处采样，对应 $\\Omega t$ 的值为 $0, 5, 10$ 弧度，该方法在中点处看到一个大的负值（$sin(5) \\approx -0.96$），这并不代表函数的平均行为，从而导致较大误差。在这种特定情况下，预计RK4会产生比Heun法更大的误差。\n\n测试案例4：边界情况。\nODE是 $y'(t) = H(t-\\tau)$，其中 $\\tau=2.0$，积分区间为 $[0, 1.0]$。间断点位于积分区间之外。在 $[0, 1.0]$ 上，函数 $f(t,y)=0$ 恒成立。精确解为 $y(1.0)=0$。对于任何仅在步长区间内计算 $f$ 的数值方法，所有函数求值都将得到 $0$。\n对于Heun法：$y_1 = 0 + \\frac{1.0}{2}[f(0,0) + f(1.0, \\dots)] = 0 + \\frac{1.0}{2}[0+0] = 0$。\n对于RK4法：$k_1, k_2, k_3, k_4$ 都将为 $0$，所以 $y_1 = 0$。\n两种方法都得出精确解，所以GTE(Heun) = GTE(RK4) = $0$。条件GTE(RK4) > GTE(Heun)（即 $0 > 0$）为假。\n\n总之，分析证实了更高阶的方法并非普遍更优。其性能关键取决于问题的光滑性以及步长相对于解的特征尺度的关系。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and verifies test cases comparing GTE of Heun's method and RK4.\n    \"\"\"\n\n    # --- Numerical Method Implementations ---\n\n    def heun_step(f, t, y, h):\n        \"\"\"Performs a single step of Heun's method.\"\"\"\n        k1 = f(t, y)\n        k2 = f(t + h, y + h * k1)\n        return y + (h / 2.0) * (k1 + k2)\n\n    def rk4_step(f, t, y, h):\n        \"\"\"Performs a single step of the classical RK4 method.\"\"\"\n        k1 = f(t, y)\n        k2 = f(t + h / 2.0, y + h / 2.0 * k1)\n        k3 = f(t + h / 2.0, y + h / 2.0 * k2)\n        k4 = f(t + h, y + h * k3)\n        return y + (h / 6.0) * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n\n    def ode_solver(stepper, f, y0, t0, T, h):\n        \"\"\"\n        Solves an ODE from t0 to T using a given stepper method.\n        `stepper` is a function like heun_step or rk4_step.\n        \"\"\"\n        t = t0\n        y = y0\n        # Ensure integer number of steps to avoid floating point accumulation errors\n        num_steps = round((T - t0) / h)\n        if not np.isclose(num_steps*h, T-t0):\n            # This check is for robustness, though problem statement guarantees integer N\n            raise ValueError(\"T-t0 must be an integer multiple of h\")\n            \n        for _ in range(num_steps):\n            y = stepper(f, t, y, h)\n            t += h\n        return y\n\n    # --- Test Case Definitions ---\n\n    def heaviside(x):\n        \"\"\"Heaviside step function as defined in the problem.\"\"\"\n        return 1.0 if x >= 0 else 0.0\n\n    test_cases = [\n        # Case 1: Constructed counterexample with a discontinuity\n        {\n            'f': lambda t, y, tau=0.49: heaviside(t - tau),\n            'y0': 0.0,\n            't0': 0.0,\n            'h': 1.0,\n            'T': 1.0,\n            'exact_sol': lambda T, tau=0.49: T - tau if T > tau else 0.0,\n        },\n        # Case 2: Smooth decay (stable linear ODE)\n        {\n            'f': lambda t, y, lam=-10.0: lam * y,\n            'y0': 1.0,\n            't0': 0.0,\n            'h': 0.1,\n            'T': 1.0,\n            'exact_sol': lambda T, lam=-10.0: np.exp(lam * T),\n        },\n        # Case 3: Smooth oscillatory forcing, single-step quadrature\n        {\n            'f': lambda t, y, omega=50.0: np.sin(omega * t),\n            'y0': 0.0,\n            't0': 0.0,\n            'h': 0.2,\n            'T': 0.2,\n            'exact_sol': lambda T, omega=50.0: (1.0 - np.cos(omega * T)) / omega,\n        },\n        # Case 4: Boundary case with no jump inside interval\n        {\n            'f': lambda t, y, tau=2.0: heaviside(t - tau),\n            'y0': 0.0,\n            't0': 0.0,\n            'h': 1.0,\n            'T': 1.0,\n            'exact_sol': lambda T, tau=2.0: T - tau if T > tau else 0.0,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        f = case['f']\n        y0 = case['y0']\n        t0 = case['t0']\n        h = case['h']\n        T = case['T']\n        exact_sol_func = case['exact_sol']\n\n        # Calculate numerical solutions\n        y_heun = ode_solver(heun_step, f, y0, t0, T, h)\n        y_rk4 = ode_solver(rk4_step, f, y0, t0, T, h)\n\n        # Calculate exact solution\n        y_exact = exact_sol_func(T)\n\n        # Calculate Global Truncation Errors\n        gte_heun = np.abs(y_heun - y_exact)\n        gte_rk4 = np.abs(y_rk4 - y_exact)\n\n        # Compare errors and append result\n        results.append(gte_rk4 > gte_heun)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}