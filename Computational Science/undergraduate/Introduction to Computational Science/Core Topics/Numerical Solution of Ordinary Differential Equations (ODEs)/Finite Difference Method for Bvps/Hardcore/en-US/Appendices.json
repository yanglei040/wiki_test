{
    "hands_on_practices": [
        {
            "introduction": "Before building complex solvers, it is crucial to have a firm grasp of the fundamental algebraic relationship created by the finite difference stencil. This exercise challenges you to work backward. Given a known numerical solution for a general Sturm-Liouville equation, you will use the discretized equation to deduce the corresponding source term at a specific grid point, solidifying your understanding of how the stencil connects the solution values, equation coefficients, and forcing function. ",
            "id": "1127150",
            "problem": "A one-dimensional boundary value problem is described by the Sturm-Liouville equation:\n$$\n\\frac{d}{dx}\\left(p(x)\\frac{dy}{dx}\\right) + q(x)y = f(x)\n$$\non the domain $x \\in [0, L]$. The functions $p(x)$ and $q(x)$ are given by $p(x) = 1 + \\alpha x^2$ and $q(x) = -\\beta$, where $\\alpha$ and $\\beta$ are positive constants.\n\nThe problem is discretized on a uniform grid with spacing $h$. Let $x_i = i h$ for $i=0, 1, 2, \\dots$ be the grid points, and let $y_i$ be the numerical approximation of the solution $y(x_i)$. The differential operator is approximated using a second-order accurate finite difference scheme at each interior node $x_i$:\n$$\n\\frac{1}{h^2}\\left[p_{i+1/2}(y_{i+1} - y_i) - p_{i-1/2}(y_i - y_{i-1})\\right] + q_i y_i = f_i\n$$\nwhere $p_{i \\pm 1/2} = p(x_i \\pm h/2)$, $q_i = q(x_i)$, and $f_i = f(x_i)$.\n\nSuppose that for the node at $x_k = k h$, the numerical solution has the values $y_{k-1} = A$, $y_k = B$, and $y_{k+1} = C$.\n\nDerive an expression for the value of the source term $f_k = f(x_k)$ in terms of $\\alpha, \\beta, h, k, A, B$, and $C$.",
            "solution": "We start from the finite-difference approximation at the interior node $x_k$:\n$$\n\\frac{1}{h^2}\\Bigl[p_{k+1/2}(y_{k+1}-y_k)\\;-\\;p_{k-1/2}(y_k-y_{k-1})\\Bigr]+q_k\\,y_k = f_k.\n$$\nSolve for $f_k$:\n$$\nf_k = \\frac{1}{h^2}\\Bigl[p_{k+1/2}(y_{k+1}-y_k) - p_{k-1/2}(y_k-y_{k-1})\\Bigr] + q_k\\,y_k.\n$$\nSubstitute $y_{k-1}=A$, $y_k=B$, $y_{k+1}=C$, $q_k=-\\beta$, and\n$$\np_{k\\pm1/2} = 1 + \\alpha\\bigl(x_k\\pm\\tfrac h2\\bigr)^2\n=1+\\alpha h^2\\bigl(k\\pm\\tfrac12\\bigr)^2.\n$$\nHence\n$$\nf_k\n=\\frac{(1+\\alpha h^2(k+\\tfrac12)^2)(C-B)\\;-\\;(1+\\alpha h^2(k-\\tfrac12)^2)(B-A)}{h^2}\n-\\beta\\,B.\n$$",
            "answer": "$$\\boxed{\\frac{(1+\\alpha h^2(k+\\tfrac12)^2)(C-B)-(1+\\alpha h^2(k-\\tfrac12)^2)(B-A)}{h^2}-\\beta B}$$"
        },
        {
            "introduction": "A key aspect of using numerical methods is understanding their accuracy and limitations. This coding practice guides you through implementing a finite difference solver and using it as a computational laboratory to explore the concept of convergence order. By testing your solver on problems with both a smooth ($C^{\\infty}$) solution and a less regular ($C^1$) solution, you will empirically verify a critical theoretical result: the accuracy of a finite difference scheme can be limited by the smoothness of the underlying solution being approximated. ",
            "id": "3127793",
            "problem": "Consider the one-dimensional Boundary Value Problem (BVP) for the scalar function $u(x)$ on the closed interval $[0,1]$ with homogeneous Dirichlet boundary conditions,\n$$\n-u''(x) = f(x), \\quad x \\in (0,1), \\quad u(0) = 0, \\quad u(1) = 0.\n$$\nStarting only from the Taylor expansion of a smooth function around a point and the definition of the second derivative, you must:\n- Derive the classical second-order central finite difference (FD) scheme on a uniform grid of $N$ interior points with grid spacing $h = \\frac{1}{N+1}$, using a three-point stencil for the approximation of $u''(x)$. Do not introduce any special treatment near discontinuities; apply the same stencil at every interior grid point.\n- Implement the resulting linear system that approximates $-u''(x) = f(x)$ with the given Dirichlet boundary conditions.\n- Compute the discrete $\\ell_{\\infty}$ error, defined on the interior grid nodes $\\{x_i = i h\\}_{i=1}^{N}$, by\n$$\n\\|e\\|_{\\infty} = \\max_{1 \\le i \\le N} \\left|u_{\\text{num}}(x_i) - u_{\\text{exact}}(x_i)\\right|,\n$$\nwhere $u_{\\text{num}}$ is the numerical solution and $u_{\\text{exact}}$ is the exact solution of the continuous BVP evaluated at the same grid nodes.\n- For a sequence of refinements characterized by grid spacings $h_1 > h_2 > \\cdots$, compute the observed order of convergence between two successive refinements via\n$$\np = \\frac{\\log\\left(\\|e(h_1)\\|_{\\infty} / \\|e(h_2)\\|_{\\infty}\\right)}{\\log\\left(h_1/h_2\\right)}.\n$$\nThe goal is to demonstrate that when the continuous solution is only $C^1$ (once continuously differentiable) but not $C^2$, the observed convergence order of the standard second-order central FD method reduces from approximately $2$ to approximately $1$.\n\nUse three test cases that share the same operator but differ in the right-hand side $f(x)$, chosen to control the regularity of the exact solution:\n\n- Case A (smooth “happy path”): $f(x) = \\sin(2\\pi x)$. The exact solution is $u(x) = \\dfrac{\\sin(2\\pi x)}{(2\\pi)^2}$, which satisfies $u(0) = 0$ and $u(1) = 0$. Use $N \\in \\{32, 64, 128, 256\\}$.\n\n- Case B (step right-hand side aligned with grid nodes): Let $s = \\tfrac{1}{2}$, $f_{\\text{L}} = 1$, and $f_{\\text{R}} = 2$. Define\n$$\nf(x) = \n\\begin{cases}\nf_{\\text{L}}, & 0 \\le x  s,\\\\\nf_{\\text{R}},  s \\le x \\le 1.\n\\end{cases}\n$$\nThen the exact solution $u(x)$ is piecewise quadratic, $C^1$ but not $C^2$, and is determined by enforcing $u(0) = 0$, $u(1) = 0$, and continuity of $u$ and $u'$ at $x = s$. Specifically, for $0 \\le x  s$,\n$$\nu(x) = -\\frac{f_{\\text{L}}}{2} x^2 + A x,\n$$\nand for $s \\le x \\le 1$,\n$$\nu(x) = -\\frac{f_{\\text{R}}}{2} x^2 + C x + D,\n$$\nwhere the constants $A, C, D$ are determined by the interface and boundary conditions. Use $N \\in \\{31, 63, 127, 255\\}$ so that $s = \\tfrac{1}{2}$ lies exactly on a grid node $x_i = i h$.\n\n- Case C (step right-hand side off-grid): Let $s = \\tfrac{3}{10}$, $f_{\\text{L}} = 1$, $f_{\\text{R}} = 2$, and $f(x)$ defined as in Case B. The exact solution is again piecewise quadratic, $C^1$ but not $C^2$, with the same form and constant determination as in Case B, but now with the different interface location $s = \\tfrac{3}{10}$. Use $N \\in \\{32, 64, 128, 256\\}$.\n\nFor Cases B and C, you must base your implementation on the piecewise exact solution implied by\n$$\n-u''(x) =\n\\begin{cases}\nf_{\\text{L}},  0 \\le x  s,\\\\\nf_{\\text{R}},  s \\le x \\le 1,\n\\end{cases}\n$$\ntogether with the interface conditions $u$ continuous at $x=s$, $u'$ continuous at $x=s$, and the boundary conditions $u(0) = 0$, $u(1) = 0$. These conditions uniquely determine the constants in the piecewise quadratic exact solution.\n\nYour program must:\n- For each test case, compute the discrete $\\ell_{\\infty}$ errors for each $N$ in the specified set and then compute the observed order $p$ using only the finest two refinements in that case.\n- Produce a single line of output containing a list with three floating-point numbers $[p_{\\text{A}}, p_{\\text{B}}, p_{\\text{C}}]$, where $p_{\\text{A}}$ corresponds to Case A, $p_{\\text{B}}$ to Case B, and $p_{\\text{C}}$ to Case C. Express each number rounded to two decimal places.\n\nNo physical units are involved in this problem. All angles, where they appear within trigonometric functions, are understood to be in radians.\n\nFinal output format:\n- A single line containing the three results as a comma-separated list enclosed in square brackets, for example $[1.98,1.03,1.01]$.",
            "solution": "The problem presented is a well-posed one-dimensional boundary value problem (BVP) for which a numerical solution is sought using the finite difference method. The task is to derive the numerical scheme, implement it for three distinct cases of varying solution regularity, and analyze the computational order of convergence to demonstrate the effect of reduced solution smoothness. The problem is scientifically sound, self-contained, and mathematically rigorous.\n\n### 1. Derivation of the Central Finite Difference Scheme\n\nThe foundation of the finite difference method lies in approximating derivatives using Taylor series expansions. Consider a sufficiently smooth scalar function $u(x)$. Its Taylor expansion around a point $x_i$ is given by:\n$$\nu(x_i + h) = u(x_i) + h u'(x_i) + \\frac{h^2}{2} u''(x_i) + \\frac{h^3}{6} u'''(x_i) + \\frac{h^4}{24} u^{(4)}(x_i) + O(h^5)\n$$\n$$\nu(x_i - h) = u(x_i) - h u'(x_i) + \\frac{h^2}{2} u''(x_i) - \\frac{h^3}{6} u'''(x_i) + \\frac{h^4}{24} u^{(4)}(x_i) + O(h^5)\n$$\nwhere $h$ is a small step size.\n\nAdding these two expansions, the terms with odd-powered derivatives ($u'$, $u'''$, etc.) cancel out:\n$$\nu(x_i + h) + u(x_i - h) = 2u(x_i) + h^2 u''(x_i) + \\frac{h^4}{12} u^{(4)}(x_i) + O(h^6)\n$$\nRearranging this equation to solve for the second derivative, $u''(x_i)$, yields:\n$$\nh^2 u''(x_i) = u(x_i + h) - 2u(x_i) + u(x_i - h) - \\frac{h^4}{12} u^{(4)}(x_i) + O(h^6)\n$$\nDividing by $h^2$, we obtain an expression for $u''(x_i)$:\n$$\nu''(x_i) = \\frac{u(x_i + h) - 2u(x_i) + u(x_i - h)}{h^2} - \\frac{h^2}{12} u^{(4)}(x_i) + O(h^4)\n$$\nThe expression $\\frac{u(x_i + h) - 2u(x_i) + u(x_i - h)}{h^2}$ is the classical three-point central finite difference approximation for the second derivative. The term $-\\frac{h^2}{12} u^{(4)}(\\xi)$ for some $\\xi \\in (x_i-h, x_i+h)$ is the leading term of the local truncation error. The approximation is therefore second-order accurate, denoted as $O(h^2)$, provided that the solution $u(x)$ is at least four times continuously differentiable ($u \\in C^4$).\n\n### 2. Discretization of the Boundary Value Problem\n\nThe BVP to be solved is $-u''(x) = f(x)$ on $x \\in (0,1)$ with $u(0)=0$ and $u(1)=0$. We introduce a uniform grid with $N$ interior points. The grid spacing is $h = \\frac{1}{N+1}$, and the grid points are $x_i = i h$ for $i=0, 1, \\dots, N+1$. The numerical solution at these points is denoted by $u_i \\approx u(x_i)$.\n\nWe replace the continuous second derivative in the BVP with its finite difference approximation at each interior grid point $x_i$ for $i=1, \\dots, N$:\n$$\n- \\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2} = f(x_i)\n$$\nMultiplying by $h^2$ and rearranging gives the discrete equation for each interior node:\n$$\n-u_{i-1} + 2u_i - u_{i+1} = h^2 f_i, \\quad \\text{for } i = 1, 2, \\dots, N,\n$$\nwhere $f_i = f(x_i)$.\n\nThis set of $N$ linear equations must incorporate the homogeneous Dirichlet boundary conditions, $u(0)=0$ and $u(1)=0$. In our discrete notation, this means $u_0 = 0$ and $u_{N+1} = 0$.\n\nFor the first interior point ($i=1$):\n$$\n-u_0 + 2u_1 - u_2 = h^2 f_1 \\implies 2u_1 - u_2 = h^2 f_1\n$$\nFor the last interior point ($i=N$):\n$$\n-u_{N-1} + 2u_N - u_{N+1} = h^2 f_N \\implies -u_{N-1} + 2u_N = h^2 f_N\n$$\nThese equations form a linear system $A\\mathbf{u}_{\\text{num}} = \\mathbf{b}$, where $\\mathbf{u}_{\\text{num}} = [u_1, u_2, \\dots, u_N]^T$ is the vector of unknown solution values at the interior points. The matrix $A$ is an $N \\times N$ symmetric, tridiagonal, positive definite matrix:\n$$\nA = \\begin{pmatrix}\n2  -1  0  \\cdots  0 \\\\\n-1  2  -1  \\cdots  0 \\\\\n0  \\ddots  \\ddots  \\ddots  0 \\\\\n\\vdots  \\cdots  -1  2  -1 \\\\\n0  \\cdots  0  -1  2\n\\end{pmatrix}\n$$\nThe right-hand side vector $\\mathbf{b}$ is given by:\n$$\n\\mathbf{b} = h^2 \\begin{pmatrix} f(x_1) \\\\ f(x_2) \\\\ \\vdots \\\\ f(x_N) \\end{pmatrix}\n$$\nSolving this linear system provides the numerical solution $\\mathbf{u}_{\\text{num}}$.\n\n### 3. Convergence Analysis and Solution Regularity\n\nThe global error of this method, $\\|u_{\\text{num}} - u_{\\text{exact}}\\|_\\infty$, is expected to be $O(h^2)$, which implies the observed order of convergence $p$ should be approximately $2$. This holds when the solution $u(x)$ is sufficiently smooth (specifically, $u \\in C^4[0,1]$).\n\nThe problem investigates scenarios where this smoothness condition is violated. If the solution $u(x)$ is only $C^1$, then its second derivative $u''(x)$ is continuous but not differentiable, and its third derivative $u'''(x)$ has jump discontinuities. This occurs when the source term $f(x)$ is piecewise continuous (e.g., a step function). At or near a point where $f(x)$ is discontinuous, the Taylor series argument justifying the $O(h^2)$ truncation error breaks down. The local truncation error becomes $O(1)$ or $O(h^{-1})$ if evaluated at the point of discontinuity, or $O(h)$ if the stencil straddles it. This larger local error pollutes the global solution, typically leading to a reduction in the overall convergence rate to $p \\approx 1$.\n\nThe three test cases are designed to demonstrate this phenomenon:\n- **Case A**: $f(x)$ is $C^\\infty$, so the exact solution $u(x)$ is also $C^\\infty$. We expect to observe $p \\approx 2$.\n- **Case B**: $f(x)$ has a step discontinuity at $x=1/2$. The grid is chosen such that this discontinuity always aligns with a grid point. The finite difference stencil is applied naively over this point.\n- **Case C**: $f(x)$ has a step discontinuity at $x=3/10$. The grid is such that the discontinuity lies between grid points.\n\nFor Cases B and C, the exact solution is piecewise quadratic and $C^1$. The constants in the piecewise solution are found by enforcing the boundary conditions $u(0)=u(1)=0$ and continuity of $u$ and $u'$ at the interface point $s$. This yields the general form:\nFor $x  s$: $u(x) = -\\frac{f_{\\text{L}}}{2}x^2 + C_1 x$\nFor $x \\ge s$: $u(x) = -\\left(f_{\\text{L}}sx - \\frac{f_{\\text{L}}}{2}s^2 + \\frac{f_{\\text{R}}}{2}(x-s)^2\\right) + C_1 x$\nwhere $$C_1 = f_{\\text{L}}s - \\frac{f_{\\text{L}}}{2}s^2 + \\frac{f_{\\text{R}}}{2}(1-s)^2.$$\n\nThe numerical experiment will compute the discrete $\\ell_\\infty$ error for a sequence of grid refinements and then calculate the observed order of convergence $p$ using the results from the two finest grids.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve_bvp(N, f_func):\n    \"\"\"\n    Solves the BVP -u'' = f(x) on [0,1] with u(0)=u(1)=0\n    using a central finite difference scheme with N interior points.\n    \"\"\"\n    h = 1.0 / (N + 1)\n    x = np.linspace(h, 1.0 - h, N)\n    \n    # Construct the right-hand side vector b\n    b = h**2 * f_func(x)\n    \n    # Construct the tridiagonal matrix A in banded format for solve_banded.\n    # The matrix ab has 3 rows.\n    # ab[0, :] = super-diagonal (not used at index 0)\n    # ab[1, :] = main diagonal\n    # ab[2, :] = sub-diagonal (not used at last index)\n    ab = np.zeros((3, N))\n    ab[0, 1:] = -1.0\n    ab[1, :] = 2.0\n    ab[2, :-1] = -1.0\n    \n    # Solve the linear system Au = b\n    u_num = linalg.solve_banded((1, 1), ab, b)\n    \n    return x, u_num\n\ndef calculate_order(errors, h_values):\n    \"\"\"\n    Calculates the order of convergence p from the last two refinements.\n    \"\"\"\n    # Use data from the two finest grids\n    e1 = errors[-2]  # Error on coarser grid\n    e2 = errors[-1]  # Error on finer grid\n    h1 = h_values[-2]  # Coarser grid spacing\n    h2 = h_values[-1]  # Finer grid spacing\n\n    p = np.log(e1 / e2) / np.log(h1 / h2)\n    return p\n\ndef run_case(f_func, u_exact_func, N_values):\n    \"\"\"\n    Runs a test case for a given f, u_exact, and list of N values.\n    Returns the observed order of convergence.\n    \"\"\"\n    errors = []\n    h_values = []\n    \n    for N in N_values:\n        h = 1.0 / (N + 1)\n        x_grid, u_num = solve_bvp(N, f_func)\n        u_exact = u_exact_func(x_grid)\n        \n        # Calculate discrete l-infinity error\n        l_inf_error = np.max(np.abs(u_num - u_exact))\n        \n        errors.append(l_inf_error)\n        h_values.append(h)\n        \n    # Compute order of convergence from the two finest grids\n    order = calculate_order(errors, h_values)\n    return order\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run them, and print the final results.\n    \"\"\"\n    # --- Case A: Smooth solution ---\n    f_A = lambda x: np.sin(2 * np.pi * x)\n    u_exact_A = lambda x: np.sin(2 * np.pi * x) / (2 * np.pi)**2\n    N_A = [32, 64, 128, 256]\n\n    # --- Case B: C^1 solution, discontinuity on grid node ---\n    s_B, fL_B, fR_B = 0.5, 1.0, 2.0\n    f_B = lambda x: np.where(x  s_B, fL_B, fR_B)\n    C1_B = fL_B * s_B - fL_B / 2 * s_B**2 + fR_B / 2 * (1 - s_B)**2\n    u_exact_B = lambda x: np.where(\n        x  s_B,\n        -0.5 * fL_B * x**2 + C1_B * x,\n        -(fL_B * s_B * x - 0.5 * fL_B * s_B**2 + 0.5 * fR_B * (x - s_B)**2) + C1_B * x\n    )\n    N_B = [31, 63, 127, 255]\n\n    # --- Case C: C^1 solution, discontinuity off-grid ---\n    s_C, fL_C, fR_C = 0.3, 1.0, 2.0\n    f_C = lambda x: np.where(x  s_C, fL_C, fR_C)\n    C1_C = fL_C * s_C - fL_C / 2 * s_C**2 + fR_C / 2 * (1 - s_C)**2\n    u_exact_C = lambda x: np.where(\n        x  s_C,\n        -0.5 * fL_C * x**2 + C1_C * x,\n        -(fL_C * s_C * x - 0.5 * fL_C * s_C**2 + 0.5 * fR_C * (x - s_C)**2) + C1_C * x\n    )\n    N_C = [32, 64, 128, 256]\n\n    test_cases = [\n        (f_A, u_exact_A, N_A),\n        (f_B, u_exact_B, N_B),\n        (f_C, u_exact_C, N_C),\n    ]\n\n    results = []\n    for f_func, u_exact_func, N_values in test_cases:\n        p = run_case(f_func, u_exact_func, N_values)\n        results.append(p)\n    \n    # Format the final output string with results rounded to two decimal places.\n    formatted_results = [f\"{r:.2f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While linear problems provide a great foundation, many important physical systems are inherently nonlinear. This advanced exercise challenges you to extend your skills to solve a nonlinear boundary value problem. You will combine finite difference discretization with the powerful Newton-Raphson method to handle the nonlinearity and use a parameter continuation approach to trace the solution as the problem's characteristics change, providing a gateway to solving a broader class of scientific problems. ",
            "id": "3127756",
            "problem": "Consider the nonlinear Boundary Value Problem (BVP) on the interval $[0,1]$ with homogeneous Dirichlet boundary conditions: find a function $u:[0,1]\\to\\mathbb{R}$ such that $$-u''(x)+\\lambda\\,u(x)^3=f(x),\\quad x\\in(0,1),\\qquad u(0)=0,\\quad u(1)=0,$$ where $f(x)$ is a given source function and $\\lambda\\in\\mathbb{R}$ is a continuation parameter. The goal is to approximate the solution $u(x)$ by a Finite Difference Method (FDM) and to track solution branches as $\\lambda$ varies using discrete Newton continuation.\n\nStart from fundamental base: \n- Approximate the second derivative by the standard central difference that follows from the definition of the derivative, $$u''(x_i)\\approx\\frac{u(x_{i-1})-2u(x_i)+u(x_{i+1})}{h^2},$$ where $x_i$ are grid points and $h$ is the uniform grid spacing.\n- Formulate the discrete nonlinear system by enforcing the differential equation at interior grid points.\n- Use Newton's method, originating from the root-finding principle for nonlinear equations $F(y)=0$, which linearizes the system at each iterate via the Jacobian matrix and solves for the Newton update.\n\nDiscretization details to implement:\n- Use a uniform grid with $N$ interior points, grid spacing $h=\\frac{1}{N+1}$, and interior nodes $x_i=i\\,h$ for $i=1,2,\\dots,N$.\n- Let $u_i\\approx u(x_i)$ and define the discrete residual vector $F(u;\\lambda)\\in\\mathbb{R}^N$ component-wise by $$F_i(u;\\lambda)=\\frac{2u_i-u_{i-1}-u_{i+1}}{h^2}+\\lambda\\,u_i^3-f(x_i),\\quad i=1,\\dots,N,$$ with the convention $u_0=0$ and $u_{N+1}=0$ from the boundary conditions.\n- For the Newton method, use the Jacobian $$J(u;\\lambda)=L+\\operatorname{diag}\\big(3\\lambda\\,u_1^2,\\dots,3\\lambda\\,u_N^2\\big),$$ where $L\\in\\mathbb{R}^{N\\times N}$ is the tridiagonal matrix representing the discrete operator $-\\frac{d^2}{dx^2}$ on the interior nodes, i.e., $L$ has diagonal entries $\\frac{2}{h^2}$ and off-diagonal entries $-\\frac{1}{h^2}$.\n\nContinuation strategy to implement:\n- At $\\lambda=0$, solve the linear system $L\\,u=f$ exactly to obtain an initial solution.\n- For subsequent $\\lambda$ values in a prescribed sequence, use the previously converged solution as the initial guess for Newton's method and iterate to convergence with a suitable stopping criterion.\n\nSource function specification:\n- Use the forcing function $f(x)=\\sin(\\pi x)$, which is smooth and compatible with the boundary conditions.\n\nConvergence and numerical details to implement:\n- Use a tolerance of $10^{-10}$ on the Euclidean norm of the residual for Newton's method convergence.\n- Limit the number of Newton iterations to $50$.\n- Employ a simple backtracking line search on the Newton step length to enhance robustness: if a full Newton step does not reduce the residual norm sufficiently, reduce the step length geometrically until a sufficient decrease is observed or a minimum step length threshold is reached.\n\nTest suite to ensure coverage:\n- Case $1$ (happy path): $N=50$, $\\lambda$ sequence $[0.0,\\,0.5,\\,1.0]$.\n- Case $2$ (coarse grid, stronger nonlinearity): $N=10$, $\\lambda$ sequence $[0.0,\\,2.0]$.\n- Case $3$ (fine grid, moderate nonlinearity): $N=150$, $\\lambda$ sequence $[0.0,\\,1.5]$.\n- Case $4$ (negative parameter branch): $N=50$, $\\lambda$ sequence $[0.0,\\,-1.0]$.\n\nRequired final outputs:\n- For each case, perform discrete Newton continuation along the specified $\\lambda$ sequence. At each $\\lambda$ value, after Newton converges, compute the discrete $\\ell_\\infty$ norm of the solution, i.e., $\\max_i |u_i|$.\n- Aggregate the results from all cases in the order listed above and within each case in the order of the $\\lambda$ sequence.\n- Round each reported $\\ell_\\infty$ norm to $6$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,\\dots]$), where each $r_k$ is a float rounded to $6$ decimal places. No additional text should be printed.",
            "solution": "The problem requires the numerical solution of a nonlinear boundary value problem (BVP) using the Finite Difference Method (FDM). The resulting system of nonlinear algebraic equations is to be solved using Newton's method. To handle the parameter-dependent nature of the problem, a simple continuation method is employed, where solutions for a sequence of parameter values $\\lambda$ are traced starting from a known solution at $\\lambda=0$.\n\nThe BVP is given by:\n$$\n-u''(x) + \\lambda u(x)^3 = f(x), \\quad x \\in (0, 1)\n$$\nwith homogeneous Dirichlet boundary conditions $u(0)=0$ and $u(1)=0$. The source function is specified as $f(x) = \\sin(\\pi x)$.\n\n**1. Finite Difference Discretization**\n\nWe first discretize the domain $[0,1]$. We introduce a uniform grid with $N$ interior points, defined by the nodes $x_i = i h$ for $i=0, 1, \\dots, N+1$, where $h = \\frac{1}{N+1}$ is the grid spacing. The boundary points are $x_0=0$ and $x_{N+1}=1$. We seek an approximate solution $u_i \\approx u(x_i)$ at the interior grid points $x_i$ for $i=1, \\dots, N$. The vector of unknowns is $u = [u_1, u_2, \\dots, u_N]^T \\in \\mathbb{R}^N$.\n\nThe second derivative $u''(x)$ is approximated at each interior node $x_i$ using the second-order central difference formula:\n$$\nu''(x_i) \\approx \\frac{u(x_{i-1}) - 2u(x_i) + u(x_{i+1})}{h^2} \\approx \\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2}\n$$\nSubstituting this into the differential equation and evaluating it at each interior node $x_i$ yields a system of $N$ algebraic equations:\n$$\n-\\frac{u_{i-1} - 2u_i + u_{i+1}}{h^2} + \\lambda u_i^3 = f(x_i), \\quad i=1, \\dots, N\n$$\nThe boundary conditions $u(0)=0$ and $u(1)=0$ are incorporated by setting $u_0=0$ and $u_{N+1}=0$. The system of equations can be rewritten as:\n$$\n\\frac{2u_i - u_{i-1} - u_{i+1}}{h^2} + \\lambda u_i^3 = f_i, \\quad i=1, \\dots, N\n$$\nwhere $f_i = f(x_i) = \\sin(\\pi x_i)$. This system must be solved for the unknown vector $u$.\n\nWe define a residual function $F: \\mathbb{R}^N \\to \\mathbb{R}^N$, where we seek the root $u$ such that $F(u; \\lambda) = 0$. The $i$-th component of the residual is:\n$$\nF_i(u; \\lambda) = \\frac{2u_i - u_{i-1} - u_{i+1}}{h^2} + \\lambda u_i^3 - f_i\n$$\nThe system can be expressed in a compact matrix-vector form:\n$$\nF(u; \\lambda) = L u + \\lambda u^{\\circ 3} - f = 0\n$$\nHere, $u^{\\circ 3}$ denotes the element-wise cube of the vector $u$, i.e., $(u^{\\circ 3})_i = u_i^3$. The vector $f \\in \\mathbb{R}^N$ has components $f_i = f(x_i)$. The matrix $L \\in \\mathbb{R}^{N \\times N}$ is the discrete representation of the negative second derivative operator $-\\frac{d^2}{dx^2}$ with homogeneous Dirichlet boundary conditions. It is a symmetric, tridiagonal matrix with entries:\n$$\nL_{ij} = \\begin{cases}\n2/h^2  \\text{if } i=j \\\\\n-1/h^2  \\text{if } |i-j|=1 \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\n\n**2. Newton's Method**\n\nTo solve the nonlinear system $F(u;\\lambda)=0$, we employ Newton's method. Starting with an initial guess $u^{(0)}$, we generate a sequence of iterates $u^{(k)}$ that we hope converge to the solution. The update from $u^{(k)}$ to $u^{(k+1)}$ is given by:\n$$\nu^{(k+1)} = u^{(k)} + \\Delta u^{(k)}\n$$\nwhere the Newton step $\\Delta u^{(k)}$ is the solution to the linear system:\n$$\nJ(u^{(k)}; \\lambda) \\Delta u^{(k)} = -F(u^{(k)}; \\lambda)\n$$\n$J(u^{(k)}; \\lambda)$ is the Jacobian matrix of $F$ with respect to $u$, evaluated at $u^{(k)}$. The entries of the Jacobian are $J_{ij}(u; \\lambda) = \\frac{\\partial F_i}{\\partial u_j}$.\n$$\n\\frac{\\partial F_i}{\\partial u_j} = \\frac{\\partial}{\\partial u_j} \\left( \\frac{2u_i - u_{i-1} - u_{i+1}}{h^2} + \\lambda u_i^3 - f_i \\right) =\n\\begin{cases}\n2/h^2 + 3\\lambda u_i^2  \\text{if } i=j \\\\\n-1/h^2  \\text{if } |i-j|=1 \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nThus, the Jacobian matrix is the sum of the constant matrix $L$ and a diagonal matrix dependent on $u$:\n$$\nJ(u; \\lambda) = L + \\operatorname{diag}(3\\lambda u_1^2, 3\\lambda u_2^2, \\dots, 3\\lambda u_N^2)\n$$\nThe Newton iteration terminates when the Euclidean norm of the residual vector falls below a specified tolerance, $\\|F(u^{(k)}; \\lambda)\\|_2  10^{-10}$, or when a maximum number of iterations ($50$) is reached.\n\n**3. Continuation Method and Line Search**\n\nWe use a simple parameter continuation method to find solutions for a sequence of $\\lambda$ values.\n- **Initial Step ($\\lambda=0$):** For $\\lambda_0 = 0$, the BVP becomes linear: $-u''(x)=f(x)$. The discrete system is $L u = f$. This system has a unique solution which can be found by a direct linear solve.\n- **Continuation Step:** For each subsequent parameter value $\\lambda_k$ in the sequence, we use the previously computed solution $u(\\lambda_{k-1})$ as the initial guess $u^{(0)}$ for the Newton's method to find $u(\\lambda_k)$.\n\nTo improve the robustness of Newton's method, especially when the initial guess is far from the solution, we incorporate a backtracking line search. A full Newton step $\\Delta u^{(k)}$ may not decrease the residual norm. The update is therefore modified to $u^{(k+1)} = u^{(k)} + \\alpha \\Delta u^{(k)}$, where $\\alpha \\in (0, 1]$ is a step-size parameter. We start with $\\alpha=1$ and, if the condition $\\|F(u^{(k)} + \\alpha \\Delta u^{(k)})\\|_2 \\ge \\|F(u^{(k)})\\|_2$ holds, we reduce $\\alpha$ by a fixed factor (e.g., $\\alpha \\leftarrow \\alpha/2$) and re-check. This process is repeated until a sufficient decrease in the residual norm is achieved or a minimum step size is reached.\n\n**4. Algorithm Summary**\n\nFor each test case specified by $(N, \\{\\lambda_k\\})$:\n1.  Set grid spacing $h = 1/(N+1)$. Create the grid points $x_i = i h$ for $i=1,\\dots,N$.\n2.  Construct the source vector $f$ with components $f_i = \\sin(\\pi x_i)$.\n3.  Construct the constant tridiagonal matrix $L$.\n4.  Handle $\\lambda_0=0$: Solve the linear system $Lu = f$ to obtain the initial solution $u_{sol}$. Compute and store its discrete $\\ell_\\infty$-norm, $\\max_i |(u_{sol})_i|$.\n5.  Iterate through the remaining $\\lambda_k$ values:\n    a. Use $u_{sol}$ from the previous step as the initial guess $u_{current}$ for Newton's method.\n    b. Start the Newton loop (for $j=0, 1, \\dots, 49$):\n        i.   Compute the residual vector $F_{current} = L u_{current} + \\lambda_k u_{current}^{\\circ 3} - f$.\n        ii.  If $\\|F_{current}\\|_2  10^{-10}$, the method has converged. Break the loop.\n        iii. Compute the Jacobian matrix $J_{current} = L + \\operatorname{diag}(3\\lambda_k u_{current}^{\\circ 2})$.\n        iv.  Solve the linear system $J_{current} \\Delta u = -F_{current}$ for the Newton step $\\Delta u$.\n        v.   Perform backtracking line search to find a suitable step length $\\alpha$.\n        vi.  Update the solution: $u_{current} \\leftarrow u_{current} + \\alpha \\Delta u$.\n    c. The converged solution is the final $u_{current}$. Set $u_{sol} = u_{current}$.\n    d. Compute and store the $\\ell_\\infty$-norm of $u_{sol}$.\n6.  Collect all calculated norms, round them to $6$ decimal places, and format them for the final output.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the nonlinear BVP using FDM and Newton continuation for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        (50, [0.0, 0.5, 1.0]),\n        (10, [0.0, 2.0]),\n        (150, [0.0, 1.5]),\n        (50, [0.0, -1.0])\n    ]\n\n    all_results = []\n    \n    for N, lambdas in test_cases:\n        # 1. Grid and problem setup\n        h = 1.0 / (N + 1)\n        x = np.linspace(h, 1.0 - h, N)\n        f = np.sin(np.pi * x)\n\n        # 2. Assemble the discrete Laplacian matrix L\n        diag_val = 2.0 / h**2\n        off_diag_val = -1.0 / h**2\n        L = np.diag(np.full(N, diag_val)) + \\\n            np.diag(np.full(N - 1, off_diag_val), k=1) + \\\n            np.diag(np.full(N - 1, off_diag_val), k=-1)\n\n        # 3. Continuation loop\n        u_sol = None\n        for lambd in lambdas:\n            if lambd == 0.0:\n                # 4. For lambda=0, solve the linear system\n                u_sol = np.linalg.solve(L, f)\n            else:\n                # 5. For lambda != 0, use Newton's method\n                u_current = u_sol.copy()  # Use previous solution as initial guess\n                \n                max_iter = 50\n                tol = 1e-10\n\n                for _ in range(max_iter):\n                    # a. Compute residual F(u)\n                    residual = L @ u_current + lambd * u_current**3 - f\n                    res_norm = np.linalg.norm(residual)\n\n                    if res_norm  tol:\n                        break\n\n                    # b. Compute Jacobian J(u)\n                    jacobian_diag = 3.0 * lambd * u_current**2\n                    jacobian = L + np.diag(jacobian_diag)\n\n                    # c. Solve for Newton step\n                    try:\n                        newton_step = np.linalg.solve(jacobian, -residual)\n                    except np.linalg.LinAlgError:\n                        # Jacobian is singular, convergence fails\n                        # For the purposes of this problem, we can expect this not to happen.\n                        # Marking the result as NaN if it does.\n                        u_current.fill(np.nan)\n                        break\n\n                    # d. Backtracking line search\n                    alpha = 1.0\n                    for _ in range(10): # max 10 backtracking steps\n                        u_next = u_current + alpha * newton_step\n                        next_residual = L @ u_next + lambd * u_next**3 - f\n                        if np.linalg.norm(next_residual)  res_norm:\n                            break\n                        alpha *= 0.5\n                    \n                    u_current = u_current + alpha * newton_step\n                \n                u_sol = u_current\n\n            # 6. Compute and store the l_infinity norm of the solution\n            l_inf_norm = np.max(np.abs(u_sol))\n            all_results.append(round(l_inf_norm, 6))\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}