{
    "hands_on_practices": [
        {
            "introduction": "理解迭代法收敛的本质是设计高效数值算法的第一步。本练习  将引导你运用局部傅里叶分析这一强大工具，从理论上剖析经典定常迭代法（如高斯-赛德尔法与SOR法）的收敛特性。通过推导误差放大因子，你将揭示不同方法如何抑制误差，并学会如何选取最优参数来显著加速收敛，为解决更复杂的问题奠定坚实的分析基础。",
            "id": "3148203",
            "problem": "考虑区间 $(0,1)$ 上的一维泊松方程 $-u''(x) = f(x)$，其狄利克雷边界条件为 $u(0) = 0$ 和 $u(1) = 0$。将区间离散化为 $N$ 个内部点，均匀步长为 $h = \\frac{1}{N+1}$，并使用二阶中心有限差分格式来近似 $-u''(x)$，以获得线性系统 $A \\mathbf{u} = \\mathbf{b}$，其中 $A$ 是一个三对角矩阵，其对角线元素为 $\\frac{2}{h^2}$，次对角线和超对角线元素为 $-\\frac{1}{h^2}$。考虑由标准矩阵分裂定义的定常迭代法：雅可比 (Jacobi) 法、前向字典序的高斯-赛德尔 (Gauss–Seidel) 法，以及带有松弛因子 $\\omega \\in (0,2)$ 的逐次超松弛 (SOR) 法。\n\n使用误差模式 $e^{\\mathrm{i} j \\theta}$（其中 $j$ 为整数网格索引，$\\theta \\in (0,\\pi)$ 为与狄利克雷边界条件一致的离散频率）的局部傅里叶分析 (LFA)，推导在此网格上雅可比和高斯-赛德尔迭代的误差放大因子。据此，用 $N$ 表示其迭代算子的谱半径，并解释哪种方法能更有效地抑制高频误差分量。\n\n然后，使用应用于 SOR 误差更新的相同 LFA 框架，确定使该问题的 SOR 迭代算子谱半径最小化的松弛因子 $\\omega$ 的值。将你的最终答案表示为仅依赖于 $N$ 的闭式解析表达式。无需四舍五入。松弛因子是无量纲的，不要包含单位。",
            "solution": "用户需要对一维泊松问题的定常迭代法进行详细分析。我将首先验证问题陈述，然后按要求进行推导。\n\n### 问题验证\n\n**第 1 步：提取已知条件**\n- **方程：** 区间 $(0,1)$ 上的一维泊松方程 $-u''(x) = f(x)$。\n- **边界条件：** 狄利克雷边界条件 $u(0) = 0$ 和 $u(1) = 0$。\n- **离散化：** 将区间离散化为 $N$ 个内部点，均匀步长为 $h = \\frac{1}{N+1}$。\n- **数值格式：** 用于 $-u''(x)$ 的二阶中心有限差分。\n- **线性系统：** $A \\mathbf{u} = \\mathbf{b}$，其中 $A$ 是一个三对角矩阵，其对角线元素为 $\\frac{2}{h^2}$，次对角线和超对角线元素为 $-\\frac{1}{h^2}$。\n- **迭代法：** 雅可比法、高斯-赛德尔法（前向字典序），以及带有参数 $\\omega \\in (0,2)$ 的逐次超松弛 (SOR) 法。\n- **分析方法：** 对误差模式 $e^{\\mathrm{i} j \\theta}$ 进行局部傅里叶分析 (LFA)，其中 $j$ 为整数网格索引，$\\theta \\in (0,\\pi)$ 为与狄利克雷边界条件一致的离散频率。\n- **任务：**\n    1. 使用 LFA 推导雅可比法和高斯-赛德尔法的误差放大因子。\n    2. 用 $N$ 表示其迭代算子的谱半径。\n    3. 解释哪种方法能更有效地抑制高频误差分量。\n    4. 使用应用于 SOR 误差更新的 LFA 框架，确定使 SOR 谱半径最小化的最优松弛因子 $\\omega$。\n    5. 将 $\\omega$ 的最终答案表示为关于 $N$ 的闭式表达式。\n\n**第 2 步：使用提取的已知条件进行验证**\n- **科学依据：** 这是一个数值分析和计算科学中的经典教科书示例。它涉及泊松方程的有限差分​​离散化以及标准迭代求解器（雅可比、高斯-赛德尔、SOR）的分析。局部傅里叶分析（也称为冯·诺依曼稳定性分析）是分析此类方法的标准技术。所有概念都已成熟并具有科学合理性。\n- **适定性：** 问题定义明确。它要求进行特定的推导（放大因子、谱半径）和一个优化问题（寻找最优 $\\omega$）。所有必要的信息和背景都已提供。迭代法理论保证了结果的存在性和唯一性。\n- **客观性：** 问题以精确、形式化的数学语言陈述，没有任何主观性、模糊性或观点。\n\n**第 3 步：结论与行动**\n问题是有效的。它是计算科学领域中一个标准的、适定的问题。我现在将进行求解。\n\n### 求解推导\n\n给定的偏微分方程为 $-u''(x) = f(x)$，且 $u(0)=u(1)=0$。\n设网格点为 $x_j = jh$，其中 $j=0, 1, \\dots, N+1$，步长 $h = \\frac{1}{N+1}$。在内部网格点 $x_j$ 处，使用二阶中心有限差分格式的离散方程为：\n$$-\\frac{u(x_{j-1}) - 2u(x_j) + u(x_{j+1})}{h^2} \\approx f(x_j)$$\n令 $u_j$ 为 $u(x_j)$ 的数值近似解。线性方程组为 $A \\mathbf{u} = \\mathbf{b}$，其中第 $j$ 行的方程为：\n$$\\frac{1}{h^2}(2u_j - u_{j-1} - u_{j+1}) = f_j$$\n在第 $k$ 次迭代时的误差定义为 $e_j^{(k)} = u_j - u_j^{(k)}$，其中 $u_j$ 是离散系统的精确解。误差根据迭代格式的齐次形式进行传播。\n\n**雅可比法**\n雅可比迭代同时更新解向量的所有分量，使用上一次迭代 $k$ 的值：\n$$u_j^{(k+1)} = \\frac{1}{2}(u_{j-1}^{(k)} + u_{j+1}^{(k)}) + \\frac{h^2}{2}f_j$$\n精确解 $u_j$ 满足 $u_j = \\frac{1}{2}(u_{j-1} + u_{j+1}) + \\frac{h^2}{2}f_j$。从此式中减去迭代方程，得到误差传播方程：\n$$e_j^{(k+1)} = \\frac{1}{2}(e_{j-1}^{(k)} + e_{j+1}^{(k)})$$\n我们通过代入单个误差模式 $e_j^{(k)} = (\\lambda_J(\\theta))^k e^{\\mathrm{i} j \\theta}$ 进行局部傅里叶分析，其中 $\\lambda_J(\\theta)$ 是放大因子。\n$$(\\lambda_J(\\theta))^{k+1} e^{\\mathrm{i} j \\theta} = \\frac{1}{2} \\left( (\\lambda_J(\\theta))^k e^{\\mathrm{i} (j-1) \\theta} + (\\lambda_J(\\theta))^k e^{\\mathrm{i} (j+1) \\theta} \\right)$$\n两边同除以 $(\\lambda_J(\\theta))^k e^{\\mathrm{i} j \\theta}$ 得到放大因子：\n$$\\lambda_J(\\theta) = \\frac{1}{2} (e^{-\\mathrm{i} \\theta} + e^{\\mathrm{i} \\theta}) = \\cos(\\theta)$$\n\n**高斯-赛德尔法**\n采用前向字典序的高斯-赛德尔法在当前迭代中使用可用的最新值：\n$$u_j^{(k+1)} = \\frac{1}{2}(u_{j-1}^{(k+1)} + u_{j+1}^{(k)}) + \\frac{h^2}{2}f_j$$\n误差传播方程为：\n$$e_j^{(k+1)} = \\frac{1}{2}(e_{j-1}^{(k+1)} + e_{j+1}^{(k)})$$\n对于像高斯-赛德尔这样具有优先扫描方向的方法，单个傅里叶模式 $e^{\\mathrm{i} j\\theta}$ 并不是迭代算子的特征向量。严格的 LFA 会更复杂。然而，LFA 仍然可以用来推导算子的“符号”(symbol)，它描述了单个傅里叶模式如何被转换，这对于分析平滑特性至关重要。将 $e_j^{(k)} = (\\lambda_{GS}(\\theta))^k e^{\\mathrm{i}j\\theta}$ 代入误差更新方程：\n$$(\\lambda_{GS}(\\theta))^{k+1} e^{\\mathrm{i} j \\theta} = \\frac{1}{2} \\left( (\\lambda_{GS}(\\theta))^{k+1} e^{\\mathrm{i} (j-1) \\theta} + (\\lambda_{GS}(\\theta))^k e^{\\mathrm{i} (j+1) \\theta} \\right)$$\n$$\\lambda_{GS}(\\theta) e^{\\mathrm{i} j \\theta} = \\frac{1}{2} \\left( \\lambda_{GS}(\\theta) e^{\\mathrm{i} (j-1) \\theta} + e^{\\mathrm{i} (j+1) \\theta} \\right)$$\n$$\\lambda_{GS}(\\theta) (1 - \\frac{1}{2} e^{-\\mathrm{i} \\theta}) = \\frac{1}{2} e^{\\mathrm{i} \\theta}$$\n$$\\lambda_{GS}(\\theta) = \\frac{e^{\\mathrm{i} \\theta}}{2 - e^{-\\mathrm{i} \\theta}}$$\n这个复数量是高斯-赛德尔的 LFA 符号。虽然它不是真正的特征值，但其模决定了模式 $\\theta$ 的衰减。\n\n**谱半径与高频衰减**\n狄利克雷边界条件 $u_0 = u_{N+1} = 0$ 意味着误差在边界处也为零。相应的离散傅里叶模式是正弦函数，它们是复指数 $e^{\\mathrm{i}j\\theta}$ 的组合。允许的离散频率为 $\\theta_m = \\frac{m\\pi}{N+1}$，其中 $m = 1, 2, \\dots, N$。\n\n迭代算子的谱半径是其特征值模的最大值。对于应用于此问题的雅可比法，傅里叶模式是特征向量，因此迭代矩阵 $T_J$ 的特征值为 $\\mu_m = \\lambda_J(\\theta_m) = \\cos(\\frac{m\\pi}{N+1})$。谱半径为：\n$$\\rho(T_J) = \\max_{m=1, \\dots, N} \\left| \\cos\\left(\\frac{m\\pi}{N+1}\\right) \\right| = \\cos\\left(\\frac{\\pi}{N+1}\\right)$$\n\n对于高斯-赛德尔的谱半径，我们不能简单地取 $|\\lambda_{GS}(\\theta_m)|$ 的最大值。相反，我们使用一个关于“一致有序”矩阵的基本定理，本问题中的矩阵 $A$ 就属于这类矩阵。该定理指出，高斯-赛德尔算子的谱半径是雅可比算子谱半径的平方：\n$$\\rho(T_{GS}) = (\\rho(T_J))^2 = \\cos^2\\left(\\frac{\\pi}{N+1}\\right)$$\n\n为了比较高频误差分量的衰减情况，我们考察当 $\\theta \\in [\\pi/2, \\pi]$ 时放大因子的模。\n对于雅可比法：$|\\lambda_J(\\theta)| = |\\cos(\\theta)|$。当 $\\theta \\to \\pi$ 时， $|\\lambda_J(\\theta)| \\to 1$。因此，雅可比法在抑制高频误差方面效率很低（它是一个差的平滑器）。\n对于高斯-赛德尔法，我们使用 LFA 符号的模：\n$$|\\lambda_{GS}(\\theta)| = \\left| \\frac{e^{\\mathrm{i} \\theta}}{2 - e^{-\\mathrm{i} \\theta}} \\right| = \\frac{1}{|2 - \\cos\\theta + \\mathrm{i}\\sin\\theta|} = \\frac{1}{\\sqrt{(2-\\cos\\theta)^2 + \\sin^2\\theta}} = \\frac{1}{\\sqrt{5-4\\cos\\theta}}$$\n对于高频 $\\theta \\in [\\pi/2, \\pi]$，$\\cos\\theta$ 的范围是从 $0$ 到 $-1$。$|\\lambda_{GS}(\\theta)|$ 在此范围内的最大值出现在 $\\theta=\\pi/2$ 处，其值为 $1/\\sqrt{5} \\approx 0.447$。在 $\\theta=\\pi$ 处，其值为 $1/3$。由于高频的放大因子被很好地限制在 1 以下，高斯-赛德尔法能有效抑制高频误差，是一个好的平滑器。显然，为此目的，高斯-赛德尔法比雅可比法更有效。\n\n**最优 SOR 因子**\nSOR 法是高斯-赛德尔法的外推：$u_j^{(k+1)} = (1-\\omega)u_j^{(k)} + \\omega u_j^{GS}$。误差传播方程为：\n$$e_j^{(k+1)} = (1-\\omega)e_j^{(k)} + \\frac{\\omega}{2}(e_{j-1}^{(k+1)} + e_{j+1}^{(k)})$$\n应用类似的 LFA 过程是可行的，但在代数上很复杂。一种更可靠的方法依赖于关于一致有序矩阵的成熟理论，该理论将 SOR 迭代矩阵 $T_{SOR}$ 的特征值 $\\lambda$ 与雅可比矩阵 $T_J$ 的特征值 $\\mu$ 联系起来：\n$$(\\lambda + \\omega - 1)^2 = \\lambda \\omega^2 \\mu^2$$\n$T_J$ 的特征值 $\\mu$ 是实数，且位于 $(-\\rho_J, \\rho_J)$ 内，其中 $\\rho_J = \\cos(\\frac{\\pi}{N+1})$。我们寻求选择 $\\omega$ 以最小化 $\\rho(T_{SOR}) = \\max_{\\mu} |\\lambda(\\mu, \\omega)|$。\n\n对上述关系的分析得出 $\\lambda$ 的模存在两种情况：\n1. 如果 $\\omega^2\\mu^2  4(\\omega-1)$（这要求 $\\omega  1$），则 $\\sqrt{\\lambda}$ 的根是共轭复数，且 $|\\lambda| = \\omega-1$。\n2. 如果 $\\omega^2\\mu^2 \\ge 4(\\omega-1)$，则根是实数，其模由 $|\\lambda| = \\left( \\frac{\\omega|\\mu| + \\sqrt{\\omega^2\\mu^2 - 4(\\omega-1)}}{2} \\right)^2$ 给出。这是关于 $|\\mu|$ 的增函数。\n\n$\\omega$ 的最优选择（记为 $\\omega_{opt}$）发生在两种情况下最大特征值模相等时。这发生在判别式为零的 $\\mu$ 的临界值与最大的雅可比特征值 $\\rho_J$ 重合时。\n$$\\omega_{opt}^2 \\rho_J^2 = 4(\\omega_{opt} - 1)$$\n重新整理得到关于 $\\omega_{opt}$ 的二次方程：\n$$\\rho_J^2 \\omega_{opt}^2 - 4\\omega_{opt} + 4 = 0$$\n解为：\n$$\\omega_{opt} = \\frac{4 \\pm \\sqrt{16 - 16\\rho_J^2}}{2\\rho_J^2} = \\frac{2(1 \\pm \\sqrt{1-\\rho_J^2})}{\\rho_J^2}$$\n代入 $\\rho_J = \\cos(\\frac{\\pi}{N+1})$，并注意到在给定的参数范围内 $\\sqrt{1-\\rho_J^2} = \\sin(\\frac{\\pi}{N+1})$：\n$$\\omega_{opt} = \\frac{2 \\left( 1 \\pm \\sin\\left(\\frac{\\pi}{N+1}\\right) \\right)}{\\cos^2\\left(\\frac{\\pi}{N+1}\\right)} = \\frac{2 \\left( 1 \\pm \\sin\\left(\\frac{\\pi}{N+1}\\right) \\right)}{1 - \\sin^2\\left(\\frac{\\pi}{N+1}\\right)} = \\frac{2 \\left( 1 \\pm \\sin\\left(\\frac{\\pi}{N+1}\\right) \\right)}{\\left(1 - \\sin\\left(\\frac{\\pi}{N+1}\\right)\\right)\\left(1 + \\sin\\left(\\frac{\\pi}{N+1}\\right)\\right)}$$\n这给出了两个可能的解：\n$$\\omega_1 = \\frac{2}{1 + \\sin\\left(\\frac{\\pi}{N+1}\\right)} \\quad \\text{和} \\quad \\omega_2 = \\frac{2}{1 - \\sin\\left(\\frac{\\pi}{N+1}\\right)}$$\n由于 SOR 的收敛性仅在 $\\omega \\in (0,2)$ 时得到保证，并且对于 $N \\ge 1$，有 $\\sin(\\frac{\\pi}{N+1})  0$，我们得到 $\\omega_1 \\in (1,2)$ 且 $\\omega_2  2$。因此，最优松弛因子是第一个解。\n$$\\omega_{opt} = \\frac{2}{1 + \\sin\\left(\\frac{\\pi}{N+1}\\right)}$$",
            "answer": "$$ \\boxed{ \\frac{2}{1 + \\sin\\left(\\frac{\\pi}{N+1}\\right)} } $$"
        },
        {
            "introduction": "当物理问题表现出强各向异性时，例如在某个方向上的传导率远大于其他方向，传统的逐点迭代法往往收敛缓慢。本实践练习  将让你通过编程实现线松弛法，来有效应对这一挑战。通过对比沿不同方向松弛的收敛速度，你将亲身体会到隐式处理强耦合变量的巨大优势，这是设计稳健迭代求解器的关键一课。",
            "id": "3148150",
            "problem": "实现并比较沿 $x$ 方向与沿 $y$ 方向的线松弛法，用于求解由以下线性二阶椭圆偏微分方程（PDE）给出的各向异性扩散模型问题：\n$$\n-\\partial_x\\big(\\alpha \\, \\partial_x u\\big) - \\partial_y\\big(\\beta \\, \\partial_y u\\big) = f \\quad \\text{in} \\quad \\Omega=(0,1)\\times(0,1),\n$$\n在 $\\partial\\Omega$ 上使用齐次狄利克雷边界条件 $u=0$。假设系数为常数，$\\alpha = r$ 和 $\\beta = 1$，其中 $r \\gg 1$ 表示与 $x$ 方向对齐的各向异性。在均匀的笛卡尔网格上离散化 $\\Omega$，该网格在 $x$ 和 $y$ 方向上分别有 $n_x$ 和 $n_y$ 个内部点，网格间距为 $h_x = 1/(n_x+1)$ 和 $h_y = 1/(n_y+1)$。对每个内部节点 $(i,j)$（其中 $1 \\le i \\le n_x$ 和 $1 \\le j \\le n_y$）使用标准的二阶中心差分离散格式：\n$$\n-\\frac{\\alpha}{h_x^2}\\big(u_{i+1,j}-2u_{i,j}+u_{i-1,j}\\big) \\;-\\; \\frac{\\beta}{h_y^2}\\big(u_{i,j+1}-2u_{i,j}+u_{i,j-1}\\big) \\;=\\; f_{i,j},\n$$\n在边界虚拟层上 $u=0$。设 $f(x,y)=\\sin(\\pi x)\\sin(\\pi y)$。内部初始值设为 $u=0$。\n\n从以下基本原理出发：(i) 将椭圆算子定义为散度形式的扩散算子，(ii) 二阶导数的有限差分近似，以及 (iii) Gauss–Seidel 迭代原理，推导出两种线松弛方案：\n\n- $x$-线松弛（沿固定的 $y$ 求解三对角系统）：对于每个固定的 $j$，求解关于 $i$ 的三对角系统。该系统隐式处理 $x$ 方向的耦合，并使用最新可用的值处理 $y$ 方向的耦合，按 $j$ 的字典正序进行。\n\n- $y$-线松弛（沿固定的 $x$ 求解三对角系统）：对于每个固定的 $i$，求解关于 $j$ 的三对角系统。该系统隐式处理 $y$ 方向的耦合，并使用最新可用的值处理 $x$ 方向的耦合，按 $i$ 的字典正序进行。\n\n对于每种方案，在离散 $L^2$ 范数下测量残差 $r = f - A u$：\n$$\n\\|r\\|_2 \\;=\\; \\Big(h_x h_y \\sum_{i=1}^{n_x}\\sum_{j=1}^{n_y} r_{i,j}^2\\Big)^{1/2}.\n$$\n将 $N$ 次线松弛扫描的经验平均每步收敛因子定义为几何平均值：\n$$\n\\rho \\;=\\; \\Bigg(\\frac{\\|r^{(N)}\\|_2}{\\|r^{(0)}\\|_2}\\Bigg)^{1/N},\n$$\n其中 $\\|r^{(k)}\\|_2$ 是在 $k$ 次完整的线松弛扫描后的残差范数。计算 $x$-线松弛的 $\\rho_x$ 和 $y$-线松弛的 $\\rho_y$，然后报告其比率：\n$$\n\\gamma \\;=\\; \\frac{\\rho_y}{\\rho_x}.\n$$\n若 $\\gamma1$，则表示 $x$-线松弛每步减少残差的速度比 $y$-线松弛快。\n\n您的程序必须实现这两种线松弛方案，并在线上使用精确的三对角求解器（Thomas 算法），从相同的初始猜测 $u=0$ 独立应用它们，并按规定计算 $\\gamma$。本问题中没有物理单位。由于 $\\sin$ 的标准数学定义，源项中的角度使用弧度。\n\n测试套件：\n- 情况 1：$n_x=64$, $n_y=64$, $r=10^3$, $N=8$。\n- 情况 2：$n_x=64$, $n_y=64$, $r=10$, $N=8$。\n- 情况 3：$n_x=64$, $n_y=64$, $r=1$, $N=8$。\n\n对于每种情况，计算单个浮点数 $\\gamma$ 并四舍五入到 $6$ 位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[result1,result2,result3]”）。在本问题中，输出必须是列表 $[\\gamma_1,\\gamma_2,\\gamma_3]$，按上面列出的顺序对应三个测试用例，每个值都四舍五入到 $6$ 位小数。",
            "solution": "该问题是有效的。这是一个适定的数值分析问题，基于椭圆偏微分方程迭代法的标准理论。所有参数、条件和要求的输出都已明确指定。\n\n该问题要求实现并比较两种用于求解各向异性扩散方程的线松弛方案。任务的核心在于从基本原理推导每种方案的迭代更新规则。\n\n控制偏微分方程（PDE）是：\n$$\n-\\partial_x\\big(\\alpha \\, \\partial_x u\\big) - \\partial_y\\big(\\beta \\, \\partial_y u\\big) = f\n$$\n在单位正方形 $\\Omega=(0,1)\\times(0,1)$上，边界条件为齐次狄利克雷条件 $u=0$ on $\\partial\\Omega$。系数为常数，$\\alpha = r$ 和 $\\beta = 1$，其中 $r \\ge 1$。源项为 $f(x,y)=\\sin(\\pi x)\\sin(\\pi y)$。\n\n我们首先对域和偏微分方程进行离散化。使用具有 $n_x$ 和 $n_y$ 个内部点的均匀网格，网格间距为 $h_x = 1/(n_x+1)$ 和 $h_y = 1/(n_y+1)$。在内部网格节点 $(i,j)$（其中 $1 \\le i \\le n_x$ 和 $1 \\le j \\le n_y$）处，对导数使用二阶中心差分近似，得到离散方程：\n$$\n-\\frac{\\alpha}{h_x^2}\\big(u_{i+1,j}-2u_{i,j}+u_{i-1,j}\\big) - \\frac{\\beta}{h_y^2}\\big(u_{i,j+1}-2u_{i,j}+u_{i,j-1}\\big) = f_{i,j}\n$$\n边界条件 $u=0$ 意味着对于任何与边界相邻的节点，其在域外对应的“虚拟”点上的 $u$ 值为零。例如，对于 $i=1$，$u_{0,j}=0$，对于 $j=n_y$，$u_{i,n_y+1}=0$。\n\n让我们重新整理离散方程以分离出 $u_{i,j}$ 项并识别耦合关系。设 $C_x = \\alpha/h_x^2$ 和 $C_y = \\beta/h_y^2$。方程变为：\n$$\n(2C_x + 2C_y)u_{i,j} - C_x(u_{i-1,j} + u_{i+1,j}) - C_y(u_{i,j-1} + u_{i,j+1}) = f_{i,j}\n$$\n这代表了大型线性方程组 $Au=f$ 中的一个方程，该方程组针对网格内部所有未知值 $u_{i,j}$。线松弛是一种为求解该系统而构造 Gauss-Seidel 型迭代的特定策略。\n\n**1. $x$-线松弛方案**\n\n在 $x$-线松弛中，我们逐行扫描网格进行迭代，在这种情况下，是沿着水平线（$j$ 恒定）。扫描以字典正序进行，从 $j=1$ 到 $n_y$。对于每一行 $j$，我们同时求解所有未知数 $u_{i,j}$（$i=1, \\dots, n_x$）。这意味着 $x$ 方向的耦合（与 $u_{i-1,j}$ 和 $u_{i+1,j}$）被隐式处理。而 $y$ 方向的耦合（与 $u_{i,j-1}$ 和 $u_{i,j+1}$）则使用最新更新的值进行显式处理，这是 Gauss-Seidel 方法的精髓。\n\n设 $k$ 为完整扫描的迭代指数。对于一个固定的行 $j$，我们正在计算未知数向量 $u_{*,j}^{(k+1)}$。来自下面一行 $u_{*,j-1}$ 的值已在当前扫描中计算，所以我们使用 $u_{*,j-1}^{(k+1)}$。来自上面一行 $u_{*,j+1}$ 的值来自上一次扫描，所以我们使用 $u_{*,j+1}^{(k)}$。在行 $j$ 上的未知数的方程组为：\n$$\n(2C_x + 2C_y)u_{i,j}^{(k+1)} - C_x u_{i-1,j}^{(k+1)} - C_x u_{i+1,j}^{(k+1)} = f_{i,j} + C_y u_{i,j-1}^{(k+1)} + C_y u_{i,j+1}^{(k)}\n$$\n对于 $i=1, \\dots, n_x$。这是一个关于 $n_x$ 个未知数 $u_{1,j}^{(k+1)}, \\dots, u_{n_x,j}^{(k+1)}$ 的 $n_x$ 个方程的三对角系统。该系统可以写成 $T_x U_j^{(k+1)} = d_j$，其中 $U_j^{(k+1)}$ 是行 $j$ 上的未知数向量。三对角矩阵 $T_x$ 具有：\n- 对角元素：$2(C_x + C_y) = 2(\\alpha/h_x^2 + \\beta/h_y^2)$\n- 次对角和超对角元素：$-C_x = -\\alpha/h_x^2$\n\n右侧向量 $d_j$ 的元素为：\n$$\n(d_j)_i = f_{i,j} + C_y\\left(u_{i,j-1}^{(k+1)} + u_{i,j+1}^{(k)}\\right)\n$$\n边界条件 $u_{0,j}=0$ 和 $u_{n_x+1,j}=0$ 被隐式地包含在内。对于从 $1$ 到 $n_y$ 的每个 $j$，使用像 Thomas 算法这样的精确求解器来求解这个三对角系统。\n\n**2. $y$-线松弛方案**\n\n推导过程与 $x$-线情况对称。我们沿着垂直线（$i$ 恒定）从 $i=1$ 到 $n_x$ 扫描网格。对于每一列 $i$，我们隐式地求解未知数 $u_{i,j}$（$j=1, \\dots, n_y$）。基于 Gauss-Seidel 原理，使用最新的值显式处理 $x$ 方向的耦合。\n\n对于一个固定的列 $i$，未知数 $u_{i,*}^{(k+1)}$ 的方程组为：\n$$\n(2C_x + 2C_y)u_{i,j}^{(k+1)} - C_y u_{i,j-1}^{(k+1)} - C_y u_{i,j+1}^{(k+1)} = f_{i,j} + C_x u_{i-1,j}^{(k+1)} + C_x u_{i+1,j}^{(k)}\n$$\n对于 $j=1, \\dots, n_y$。这构成了一个关于列 $i$ 上未知数向量 $U_i^{(k+1)}$ 的三对角系统 $T_y U_i^{(k+1)} = d_i$。矩阵 $T_y$ 具有：\n- 对角元素：$2(C_x + C_y) = 2(\\alpha/h_x^2 + \\beta/h_y^2)$\n- 次对角和超对角元素：$-C_y = -\\beta/h_y^2$\n\n右侧向量 $d_i$ 的元素为：\n$$\n(d_i)_j = f_{i,j} + C_x\\left(u_{i-1,j}^{(k+1)} + u_{i+1,j}^{(k)}\\right)\n$$\n对于从 $1$ 到 $n_x$ 的每个 $i$，求解该系统。\n\n**3. 性能分析**\n\n该问题具有由 $r = \\alpha/\\beta$ 控制的各向异性。当 $r \\gg 1$ 时，$x$ 方向的耦合强度（与 $C_x = r/h_x^2$ 成正比）远强于 $y$ 方向的耦合强度（与 $C_y = 1/h_y^2$ 成正比）。当线松弛方法隐式处理最强耦合时，它们最为有效。因此，对于 $r \\gg 1$ 的情况，沿强耦合方向隐式求解的 $x$-线松弛预计会比 $y$-线松弛收敛得快得多。当 $r \\to 1$ 时，问题变为各向同性，两种方法的性能应该变得相同。\n\n收敛速率由经验平均收敛因子 $\\rho$ 来量化，其定义为：\n$$\n\\rho = \\left(\\frac{\\|r^{(N)}\\|_2}{\\|r^{(0)}\\|_2}\\right)^{1/N}\n$$\n这里，$r^{(k)} = f - Au^{(k)}$ 是 $k$ 次扫描后的残差，范数是离散 $L^2$ 范数：\n$$\n\\|r\\|_2 = \\left(h_x h_y \\sum_{i=1}^{n_x}\\sum_{j=1}^{n_y} r_{i,j}^2\\right)^{1/2}\n$$\n$\\rho$ 值越小表示收敛越快。我们计算 $x$-线松弛的 $\\rho_x$ 和 $y$-线松弛的 $\\rho_y$，然后计算它们的比率 $\\gamma = \\rho_y / \\rho_x$。根据上述推理，我们预期当 $r  1$ 时 $\\gamma  1$，当 $r=1$ 时 $\\gamma \\approx 1$。\n\n该算法包括初始化解 $u^{(0)}=0$，计算初始残差范数 $\\|r^{(0)}\\|_2$，然后对每种松弛方案运行 $N$ 次迭代以找到 $u^{(N)}$。然后使用最终残差范数 $\\|r^{(N)}\\|_2$ 来计算 $\\rho$ 并随后计算 $\\gamma$。每次扫描中的三对角系统使用 `scipy.linalg` 中的 `solve_banded` 函数求解，这是一个高效且数值稳定的实现，等效于 Thomas 算法。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef calculate_residual_norm(u_padded, f_interior, alpha, beta, hx, hy):\n    \"\"\"\n    Calculates the discrete L2-norm of the residual r = f - A*u.\n    \n    Args:\n        u_padded (np.ndarray): Solution array of size (nx+2, ny+2) with boundaries.\n        f_interior (np.ndarray): Source term array of size (nx, ny).\n        alpha, beta (float): Diffusion coefficients.\n        hx, hy (float): Grid spacings.\n\n    Returns:\n        float: The discrete L2-norm of the residual.\n    \"\"\"\n    nx, ny = f_interior.shape\n    u_int = u_padded[1:-1, 1:-1]\n    \n    # Central difference approximation of the operator A*u using slicing on the padded array\n    u_ip1 = u_padded[2:, 1:-1]\n    u_im1 = u_padded[:-2, 1:-1]\n    u_jp1 = u_padded[1:-1, 2:]\n    u_jm1 = u_padded[1:-1, :-2]\n\n    # Note the negative sign in the PDE definition\n    Au = -alpha * (u_ip1 - 2 * u_int + u_im1) / hx**2 \\\n         -beta  * (u_jp1 - 2 * u_int + u_jm1) / hy**2\n    \n    r_interior = f_interior - Au\n    \n    # Discrete L2 norm: sqrt(hx*hy * sum(r_ij^2))\n    norm = np.linalg.norm(r_interior) * np.sqrt(hx * hy)\n    return norm\n\n\ndef solve_x_line(nx, ny, hx, hy, alpha, beta, f_interior, N):\n    \"\"\"\n    Solves the system using x-line relaxation for N sweeps.\n    \"\"\"\n    u = np.zeros((nx + 2, ny + 2))\n    \n    Cx = alpha / hx**2\n    Cy = beta / hy**2\n    \n    # Pre-assemble the constant tridiagonal matrix for all x-lines\n    diag_x = np.full(nx, 2 * Cx + 2 * Cy)\n    off_diag_x = np.full(nx - 1, -Cx)\n    A_x_banded = np.zeros((3, nx))\n    A_x_banded[0, 1:] = off_diag_x\n    A_x_banded[1, :] = diag_x\n    A_x_banded[2, :-1] = off_diag_x\n    \n    for _ in range(N):\n        u_prev_sweep = u.copy()\n        # Sweep along y-direction (fixed j), solving for lines in x\n        for j_pad in range(1, ny + 1):\n            j_py = j_pad - 1\n            # RHS: f_ij + C_y * (u_{i,j-1}^{(k+1)} + u_{i,j+1}^{(k)})\n            # u values from line j-1 are from the current sweep (u).\n            # u values from line j+1 are from the previous sweep (u_prev_sweep).\n            rhs = f_interior[:, j_py] + Cy * (u[1:-1, j_pad - 1] + u_prev_sweep[1:-1, j_pad + 1])\n            \n            line_solution = solve_banded((1, 1), A_x_banded, rhs)\n            u[1:-1, j_pad] = line_solution\n            \n    return u\n\n\ndef solve_y_line(nx, ny, hx, hy, alpha, beta, f_interior, N):\n    \"\"\"\n    Solves the system using y-line relaxation for N sweeps.\n    \"\"\"\n    u = np.zeros((nx + 2, ny + 2))\n    \n    Cx = alpha / hx**2\n    Cy = beta / hy**2\n    \n    # Pre-assemble the constant tridiagonal matrix for all y-lines\n    diag_y = np.full(ny, 2 * Cx + 2 * Cy)\n    off_diag_y = np.full(ny-1, -Cy)\n    A_y_banded = np.zeros((3, ny))\n    A_y_banded[0, 1:] = off_diag_y\n    A_y_banded[1, :] = diag_y\n    A_y_banded[2, :-1] = off_diag_y\n\n    for _ in range(N):\n        u_prev_sweep = u.copy()\n        # Sweep along x-direction (fixed i), solving for lines in y\n        for i_pad in range(1, nx + 1):\n            i_py = i_pad - 1\n            # RHS: f_ij + C_x * (u_{i-1,j}^{(k+1)} + u_{i+1,j}^{(k)})\n            # u values from line i-1 are from the current sweep (u).\n            # u values from line i+1 are from the previous sweep (u_prev_sweep).\n            rhs = f_interior[i_py, :] + Cx * (u[i_pad - 1, 1:-1] + u_prev_sweep[i_pad + 1, 1:-1])\n\n            line_solution = solve_banded((1, 1), A_y_banded, rhs)\n            u[i_pad, 1:-1] = line_solution\n            \n    return u\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (64, 64, 1000.0, 8),\n        (64, 64, 10.0, 8),\n        (64, 64, 1.0, 8),\n    ]\n\n    results = []\n    for case in test_cases:\n        nx, ny, r, N = case\n        \n        # Setup grid and problem parameters\n        alpha = r\n        beta = 1.0\n        hx = 1.0 / (nx + 1)\n        hy = 1.0 / (ny + 1)\n        \n        # Create grid coordinates for interior points\n        x_coords = np.linspace(hx, 1.0 - hx, nx)\n        y_coords = np.linspace(hy, 1.0 - hy, ny)\n        X, Y = np.meshgrid(x_coords, y_coords, indexing='ij')\n        \n        # Source term f(x,y)\n        f_interior = np.sin(np.pi * X) * np.sin(np.pi * Y)\n        \n        # Initial condition u=0 and initial residual\n        u0_padded = np.zeros((nx + 2, ny + 2))\n        r0_norm = calculate_residual_norm(u0_padded, f_interior, alpha, beta, hx, hy)\n\n        # X-line relaxation\n        uN_x = solve_x_line(nx, ny, hx, hy, alpha, beta, f_interior, N)\n        rN_x_norm = calculate_residual_norm(uN_x, f_interior, alpha, beta, hx, hy)\n        rho_x = (rN_x_norm / r0_norm)**(1.0 / N)\n        \n        # Y-line relaxation\n        uN_y = solve_y_line(nx, ny, hx, hy, alpha, beta, f_interior, N)\n        rN_y_norm = calculate_residual_norm(uN_y, f_interior, alpha, beta, hx, hy)\n        rho_y = (rN_y_norm / r0_norm)**(1.0 / N)\n        \n        # Compute the ratio gamma\n        gamma = rho_y / rho_x\n        results.append(round(gamma, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "除了定常迭代法，我们还可以构造在预定步数内实现最优误差衰减的非定常方法。这个高级练习  将带你探索切比雪夫半迭代法，它巧妙地将迭代求解与多项式逼近理论联系起来。你将从第一性原理出发，实现一个基于算子谱估计的矩阵无关（matrix-free）求解器，从而掌握构造最优迭代法的设计思想，并锻炼处理大规模问题的核心编程能力。",
            "id": "3148184",
            "problem": "要求您设计并实现一个完整的数值实验，将 Chebyshev 半迭代应用于一个对称正定 (SPD) 线性系统。该系统由椭圆偏微分方程 (PDE) 的标准有限差分格式化产生。该 SPD 系统为 $A u = b$，通过在单位正方形 $[0,1]\\times[0,1]$ 上对带有齐次 Dirichlet 边界条件的 Poisson 方程 $-\\nabla^2 u = f$ 进行离散化得到。您的任务是推导、实现并评估一种 Chebyshev 半迭代方法，该方法使用 $A$ 的估计极值特征值界来选择步长。推导必须从 Laplace 算子的基本有限差分近似和 Chebyshev 多项式的极小化极大性质开始，并且不应先验地假设任何迭代公式。\n\n背景与设置：\n- 在均匀网格上离散化 $-\\nabla^2 u = f$，每个坐标方向有 $N$ 个内部点，网格间距为 $h = 1/(N+1)$，并在边界上使用齐次 Dirichlet 边界数据 $u=0$。使用标准的 $5$ 点差分格式来近似 $-\\nabla^2$：在内部网格节点 $(i,j)$ 处，\n  $$\n  \\left(-\\nabla^2 u\\right)_{i,j} \\approx \\frac{4 u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1}}{h^2}.\n  $$\n  通过一个无矩阵算子隐式地构建相关的 SPD 矩阵 $A$，并通过在内部网格点上对 $f$ 进行采样来形成 $b$。使用 $f(x,y) = 2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$，这样连续问题对应的光滑解析解为 $u(x,y) = \\sin(\\pi x)\\sin(\\pi y)$。\n\n- 将 Chebyshev 半迭代实现为 $x^{(k+1)} = x^{(k)} + \\omega_k r^{(k)}$ 形式的非定常迭代，其中 $r^{(k)} = b - A x^{(k)}$，步长 $\\omega_k$ 使用 $A$ 的极值特征值界来选择。您必须：\n  1. 从 Chebyshev 多项式的定义及其在 $[-1,1]$ 上的极小化极大性质出发。\n  2. 将谱区间 $[\\lambda_{\\min}, \\lambda_{\\max}]$ 映射到 $[-1,1]$，并推导出一系列步长 $\\{\\omega_k\\}_{k=1}^m$，使得在给定的多项式次数 $m$ 之后，区间上的最大残差放大最小化。\n  3. 实现使用这些 $\\omega_k$ 的 $m$ 步 Chebyshev 半迭代，而不显式地构造矩阵 $A$。\n\n- 谱界：对于在 $N \\times N$ 内部网格上带有齐次 Dirichlet 边界的 $5$ 点 Laplacian 算子，一个经过充分检验的事实是，$A$ 的特征值位于一个区间 $[\\lambda_{\\min}^{\\mathrm{ex}}, \\lambda_{\\max}^{\\mathrm{ex}}]$ 内，该区间可以从一维特征值计算得出。具体来说，对于 $h = 1/(N+1)$ 和索引 $p,q \\in \\{1,2,\\dots,N\\}$，\n  $$\n  \\lambda_{p,q} = \\frac{4}{h^2}\\sin^2\\!\\left(\\frac{\\pi p}{2(N+1)}\\right) + \\frac{4}{h^2}\\sin^2\\!\\left(\\frac{\\pi q}{2(N+1)}\\right),\n  $$\n  因此，$\\lambda_{\\min}^{\\mathrm{ex}}$ 和 $\\lambda_{\\max}^{\\mathrm{ex}}$ 分别在 $(p,q)=(1,1)$ 和 $(p,q)=(N,N)$ 时出现。在此作业中，您必须使用以下估计值：\n  $$\n  \\lambda_{\\min} = s_{\\ell}\\,\\lambda_{\\min}^{\\mathrm{ex}}, \\quad \\lambda_{\\max} = s_{u}\\,\\lambda_{\\max}^{\\mathrm{ex}},\n  $$\n  其中 $s_{\\ell}0$ 和 $s_u0$ 是每个测试用例给定的比例因子，用以模拟不完美的先验知识。这些界的质量将影响迭代的有效性。所有三角计算必须使用弧度角。\n\n- 您的程序必须：\n  1. 通过在内部网格点 $(x_i,y_j)=(ih,jh)$（其中 $i,j\\in\\{1,\\dots,N\\}$）对 $f$ 进行采样来构造 $b$。\n  2. 使用 $x^{(0)}=0$ 进行初始化。\n  3. 使用您从区间 $[\\lambda_{\\min},\\lambda_{\\max}]$ 的分析中推导出的步长，精确运行 $m$ 步 Chebyshev 半迭代。\n  4. 对每个测试用例，返回相对残差范数 $\\|r^{(m)}\\|_2/\\|b\\|_2$ 作为浮点数，其中 $r^{(m)}=b-Ax^{(m)}$。\n  5. 不要显式地组装 $A$；通过 $5$ 点差分格式将 $A$ 应用于向量。\n\n测试套件：\n- 使用以下四个测试用例，每个用例由 $(N, m, s_{\\ell}, s_u)$ 指定：\n  1. $(N, m, s_{\\ell}, s_u) = (\\,31,\\,10,\\,1.0,\\,1.0\\,)$.\n  2. $(N, m, s_{\\ell}, s_u) = (\\,31,\\,10,\\,0.8,\\,1.2\\,)$.\n  3. $(N, m, s_{\\ell}, s_u) = (\\,63,\\,20,\\,1.0,\\,1.0\\,)$.\n  4. $(N, m, s_{\\ell}, s_u) = (\\,7,\\,4,\\,0.6,\\,1.4\\,)$.\n\n可量化输出：\n- 对每个测试用例，计算标量值 $q = \\|r^{(m)}\\|_2/\\|b\\|_2$ 并将其四舍五入到 $8$ 位小数。\n- 您的程序应生成单行输出，其中包含按上述测试用例顺序排列的结果，格式为方括号内以逗号分隔的列表，例如 $[q_1,q_2,q_3,q_4]$。\n\n约束和注意事项：\n- 实现必须是无矩阵的，并且不得形成稠密矩阵。使用 $5$ 点差分格式算子来应用 $A$。\n- 通过使用从您的 Chebyshev 推导中获得的步长来确保数值稳定性。\n- 所有计算都必须以无量纲单位进行，并且所有角度都必须是弧度。",
            "solution": "任务是设计、推导并实现一种 Chebyshev 半迭代方法，用于求解一个对称正定 (SPD) 线性系统 $Ax=b$。该系统源于单位正方形上 Poisson 方程的有限差分格式化。推导必须从基本原理开始，并且实现必须是无矩阵的。\n\n### 1. 离散化问题\n\nPoisson 方程 $-\\nabla^2 u = f$ 在区域 $[0,1]\\times[0,1]$ 的均匀网格上进行离散化，边界条件为齐次 Dirichlet 条件（边界上 $u=0$）。网格在每个坐标方向上有 $N$ 个内部点，从而得到网格间距 $h = 1/(N+1)$。在内部网格节点 $(i,j)$ 处，负 Laplacian 算子的标准 $5$ 点有限差分格式为\n$$\n(-\\nabla^2 u)_{i,j} \\approx \\frac{4 u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1}}{h^2}\n$$\n这种离散化产生了一个大小为 $N^2 \\times N^2$ 的稀疏 SPD 线性方程组 $Ax=b$，其中 $x$ 是一个向量，表示 $N^2$ 个内部网格点上 $u$ 的值。矩阵 $A$ 是离散的 Laplacian 算子，向量 $b$ 通过在内部网格点上计算源函数 $f(x,y) = 2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$ 的值而形成。我们被要求在不显式组装矩阵 $A$ 的情况下，将算子 $A$ 应用于向量。\n\n### 2. Chebyshev 半迭代\n\n问题指定了一种形式如下的迭代方法：\n$$\nx^{(k+1)} = x^{(k)} + \\omega_k r^{(k)}, \\quad \\text{with } r^{(k)} = b - Ax^{(k)}\n$$\n这是一种非定常 Richardson 迭代。让我们分析残差的传播。\n$$\nr^{(k+1)} = b - Ax^{(k+1)} = b - A(x^{(k)} + \\omega_k r^{(k)}) = (b - Ax^{(k)}) - \\omega_k A r^{(k)} = r^{(k)} - \\omega_k A r^{(k)} = (I - \\omega_k A)r^{(k)}\n$$\n经过 $m$ 步迭代，从初始猜测 $x^{(0)}$ 及其残差 $r^{(0)} = b - Ax^{(0)}$ 开始，残差变为：\n$$\nr^{(m)} = \\left( \\prod_{k=0}^{m-1} (I - \\omega_k A) \\right) r^{(0)}\n$$\n令 $R_m(\\lambda) = \\prod_{k=0}^{m-1} (1-\\omega_k \\lambda)$。这是一个关于 $\\lambda$ 的 $m$ 次多项式。我们可以将残差关系写为 $r^{(m)} = R_m(A)r^{(0)}$。该多项式的一个关键性质是 $R_m(0) = \\prod_{k=0}^{m-1} (1-0)=1$。\n\n我们的目标是在 $m$ 步之后最小化误差。由于 $A$ 是 SPD 矩阵，其特征向量构成一组基。要最小化残差 $r^{(m)}$ 的范数，需要找到一个多项式 $R_m(\\lambda)$，使其在 $A$ 的谱上的幅值最小，同时满足约束条件 $R_m(0)=1$。$A$ 的谱，记为 $\\sigma(A)$，位于区间 $[\\lambda_{\\min}^{\\mathrm{ex}}, \\lambda_{\\max}^{\\mathrm{ex}}]$ 内。我们被给予了这些界的估计值 $[\\lambda_{\\min}, \\lambda_{\\max}]$。因此，问题变成了一个约束下的极小化极大问题：\n$$\n\\min_{R_m} \\max_{\\lambda \\in [\\lambda_{\\min}, \\lambda_{\\max}]} |R_m(\\lambda)| \\quad \\text{subject to } R_m(0)=1 \\text{ and } \\deg(R_m) \\le m\n$$\n\n### 3. 最优参数的推导\n\n这个极小化极大问题由 Chebyshev 多项式解决。第一类 Chebyshev 多项式 $T_m(z)$ 是在所有 $m$ 次首一多项式中，在 $[-1,1]$ 上最大绝对值最小的唯一多项式。一个相关的性质是，对于任何点 $z_0 \\notin [-1,1]$，满足 $P_m(z_0)=1$ 且最小化 $\\max_{z \\in [-1,1]} |P_m(z)|$ 的 $m$ 次多项式 $P_m(z)$ 由 $P_m(z) = T_m(z)/T_m(z_0)$ 给出。\n\n我们首先使用线性变换将谱区间 $[\\lambda_{\\min}, \\lambda_{\\max}]$ 映射到区间 $[-1,1]$：\n$$\nz(\\lambda) = \\frac{2\\lambda - (\\lambda_{\\max}+\\lambda_{\\min})}{\\lambda_{\\max}-\\lambda_{\\min}}\n$$\n我们的约束条件是 $R_m(0)=1$。我们在 $z$ 域中找到对应于 $\\lambda=0$ 的点：\n$$\nz_0 = z(0) = -\\frac{\\lambda_{\\max}+\\lambda_{\\min}}{\\lambda_{\\max}-\\lambda_{\\min}}\n$$\n由于 $A$ 是 SPD 的，所以 $0  \\lambda_{\\min} \\le \\lambda_{\\max}$，这意味着 $z_0  -1$。那么最优残差多项式 $R_m(\\lambda)$ 由下式给出：\n$$\nR_m(\\lambda) = \\frac{T_m(z(\\lambda))}{T_m(z_0)} = \\frac{T_m\\left(\\frac{2\\lambda - \\lambda_{\\max} - \\lambda_{\\min}}{\\lambda_{\\max}-\\lambda_{\\min}}\\right)}{T_m\\left(-\\frac{\\lambda_{\\max}+\\lambda_{\\min}}{\\lambda_{\\max}-\\lambda_{\\min}}\\right)}\n$$\n迭代参数 $\\omega_k$ 由 $R_m(\\lambda)$ 的根决定。$R_m(\\lambda)$ 的根是使 $T_m(z(\\lambda))=0$ 成立的 $\\lambda$ 值。$T_m(z)$ 的根由下式给出：\n$$\n\\hat{z}_k = \\cos\\left(\\frac{(2k-1)\\pi}{2m}\\right), \\quad k=1, 2, \\dots, m\n$$\n我们通过对线性映射 $z(\\lambda)$ 求逆来找到 $R_m(\\lambda)$ 对应的根 $\\lambda_k^*$：\n$$\n\\lambda_k^* = \\frac{\\lambda_{\\max}+\\lambda_{\\min}}{2} + \\frac{\\lambda_{\\max}-\\lambda_{\\min}}{2} \\hat{z}_k = \\frac{\\lambda_{\\max}+\\lambda_{\\min}}{2} + \\frac{\\lambda_{\\max}-\\lambda_{\\min}}{2}\\cos\\left(\\frac{(2k-1)\\pi}{2m}\\right)\n$$\n残差多项式为 $R_m(\\lambda) = \\prod (1-\\omega_k \\lambda)$，所以它的根是 $1/\\omega_k$。因此，最优步长是根 $\\lambda_k^*$ 的倒数：\n$$\n\\omega_k = \\frac{1}{\\lambda_k^*} = \\left( \\frac{\\lambda_{\\max}+\\lambda_{\\min}}{2} + \\frac{\\lambda_{\\max}-\\lambda_{\\min}}{2}\\cos\\left(\\frac{(2k-1)\\pi}{2m}\\right) \\right)^{-1}, \\quad k=1, 2, \\dots, m\n$$\n$R_m(A)$ 中的乘积是可交换的，因此使用这 $m$ 个步长的顺序不影响 $m$ 次迭代后的最终结果。\n\n### 4. 算法总结\n\n对于每个测试用例 $(N, m, s_{\\ell}, s_u)$：\n1.  计算网格间距 $h=1/(N+1)$。\n2.  通过在 $N^2$ 个内部网格点上对 $f(x,y)$ 进行采样，构造大小为 $N^2$ 的右侧向量 $b$。\n3.  计算离散算子 $A$ 的精确特征值界：\n    $$\n    \\lambda_{\\min}^{\\mathrm{ex}} = \\frac{8}{h^2}\\sin^2\\left(\\frac{\\pi}{2(N+1)}\\right), \\quad \\lambda_{\\max}^{\\mathrm{ex}} = \\frac{8}{h^2}\\cos^2\\left(\\frac{\\pi}{2(N+1)}\\right)\n    $$\n4.  应用比例因子得到迭代的估计界：$\\lambda_{\\min} = s_{\\ell} \\lambda_{\\min}^{\\mathrm{ex}}$ 和 $\\lambda_{\\max} = s_{u} \\lambda_{\\max}^{\\mathrm{ex}}$。\n5.  使用上面推导的公式计算 $m$ 个 Chebyshev 步长 $\\{\\omega_k\\}_{k=1}^m$。\n6.  初始化解向量 $x^{(0)} = 0$。\n7.  对 $k$ 从 $0$ 到 $m-1$ 进行迭代：\n    a. 使用一个无矩阵函数计算 $A$ 的作用，从而得到残差 $r^{(k)} = b - Ax^{(k)}$。\n    b. 更新解 $x^{(k+1)} = x^{(k)} + \\omega_{k+1} r^{(k)}$。\n8.  经过 $m$ 步后，计算最终残差 $r^{(m)} = b - Ax^{(m)}$。\n9.  最终输出为相对残差范数 $q = \\|r^{(m)}\\|_2 / \\|b\\|_2$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of applying Chebyshev semi-iteration to the discretized \n    Poisson equation for a set of predefined test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (31, 10, 1.0, 1.0),\n        (31, 10, 0.8, 1.2),\n        (63, 20, 1.0, 1.0),\n        (7, 4, 0.6, 1.4),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N, m, s_ell, s_u = case\n        \n        # 1. Setup\n        h = 1.0 / (N + 1)\n        \n        # Grid points for evaluating the source function f(x,y)\n        grid_pts = np.linspace(h, 1.0 - h, N)\n        X, Y = np.meshgrid(grid_pts, grid_pts)\n        \n        # Construct the right-hand side vector b by sampling f\n        f_vals = 2 * np.pi**2 * np.sin(np.pi * X) * np.sin(np.pi * Y)\n        b = f_vals.flatten()\n        b_norm = np.linalg.norm(b)\n\n        # 2. Spectral bounds calculation\n        # Exact extremal eigenvalues of the 5-point discrete Laplacian\n        lambda_min_ex = (8.0 / h**2) * (np.sin(np.pi / (2.0 * (N + 1))))**2\n        lambda_max_ex = (8.0 / h**2) * (np.cos(np.pi / (2.0 * (N + 1))))**2\n        \n        # Estimated bounds for Chebyshev iteration\n        lambda_min = s_ell * lambda_min_ex\n        lambda_max = s_u * lambda_max_ex\n\n        # 3. Chebyshev step sizes (omegas) derivation\n        omegas = np.zeros(m)\n        center = (lambda_max + lambda_min) / 2.0\n        radius = (lambda_max - lambda_min) / 2.0\n        \n        for k in range(1, m + 1):\n            chebyshev_root = np.cos((2.0 * k - 1.0) * np.pi / (2.0 * m))\n            polynomial_root = center + radius * chebyshev_root\n            omegas[k-1] = 1.0 / polynomial_root\n\n        # 4. Matrix-free operator A (discrete Laplacian)\n        def apply_A(x_vec):\n            \"\"\"Applies the 5-point stencil operator A to a vector x_vec.\"\"\"\n            x_grid = x_vec.reshape((N, N))\n            \n            # Start with 4*u_ij\n            Ax_grid = 4.0 * x_grid\n            \n            # Subtract neighbors (u_i-1,j, u_i+1,j, u_i,j-1, u_i,j+1)\n            # These slicing operations correctly handle boundary conditions,\n            # as missing neighbors are implicitly zero (not subtracted).\n            if N > 1:\n                Ax_grid[1:, :] -= x_grid[:-1, :]  # u_i-1,j\n                Ax_grid[:-1, :] -= x_grid[1:, :]  # u_i+1,j\n                Ax_grid[:, 1:] -= x_grid[:, :-1]  # u_i,j-1\n                Ax_grid[:, :-1] -= x_grid[:, 1:]  # u_i,j+1\n\n            return Ax_grid.flatten() / h**2\n\n        # 5. Chebyshev Iteration\n        # Initialize solution vector x^(0) = 0\n        x = np.zeros(N * N)\n        \n        # Run m steps of the iteration: x^(k+1) = x^(k) + omega_k * r^(k)\n        for k in range(m):\n            residual = b - apply_A(x)\n            x = x + omegas[k] * residual\n\n        # 6. Final Evaluation\n        # Compute the final residual r^(m) = b - A*x^(m)\n        final_residual = b - apply_A(x)\n        \n        # Compute the relative residual norm and round to 8 decimal places\n        q = np.linalg.norm(final_residual) / b_norm\n        results.append(round(q, 8))\n\n    # Final print statement in the exact required format.\n    # The format specifier in f-string handles cases like '0.1' instead of '0.10000000'\n    # so we need to format it properly. Using map(str,...) is fine since round() already fixed precision.\n    formatted_results = [f\"{r:.8f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}