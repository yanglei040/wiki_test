{
    "hands_on_practices": [
        {
            "introduction": "第一个练习为你提供了一个进入插值世界的实用起点。我们将使用最基本的技术——线性插值，来估计两个已知测量值之间的一个缺失数据点。这个练习  展示了在一个简单的直线模型如何在现实世界（如环境监测）中提供快速且合理的近似值。",
            "id": "2218418",
            "problem": "一个环境监测站正在追踪某特定大气污染物在下午的浓度变化。该监测站以固定的时间间隔记录数据，但一次传感器故障导致了短时间的数据丢失。故障前最后一次可靠的测量在中午过后的 $t_0 = 2.00$ 小时进行，测得污染物浓度为 $C_0 = 87.2$ 十亿分率 (ppb)。传感器恢复后第一次可靠的测量在中午过后的 $t_1 = 5.00$ 小时进行，测得浓度为 $C_1 = 61.4$ ppb。\n\n为了估算缺失的数据，一位分析师决定使用两个已知数据点之间的线性插值来对浓度进行建模。使用该方法，估算中午过后 $t = 3.50$ 小时的污染物浓度。\n\n请以十亿分率 (ppb) 为单位给出你的答案，并四舍五入到三位有效数字。",
            "solution": "我们使用线性插值对两个已知数据点之间的浓度进行建模。对于在时间 $t$ 测量的量 $C$，在 $(t_{0}, C_{0})$ 和 $(t_{1}, C_{1})$ 之间的线性插值公式为\n$$\nC(t)=C_{0}+\\frac{C_{1}-C_{0}}{t_{1}-t_{0}}\\left(t-t_{0}\\right).\n$$\n代入给定值 $t_{0}=2.00$，$C_{0}=87.2$，$t_{1}=5.00$，$C_{1}=61.4$ 以及 $t=3.50$，我们计算斜率\n$$\n\\frac{C_{1}-C_{0}}{t_{1}-t_{0}}=\\frac{61.4-87.2}{5.00-2.00}=\\frac{-25.8}{3.00}=-8.6,\n$$\n以及时间偏移量\n$$\nt-t_{0}=3.50-2.00=1.50.\n$$\n因此，\n$$\nC(3.50)=87.2+(-8.6)\\times 1.50=87.2-12.9=74.3.\n$$\n四舍五入到三位有效数字，估算值为 $74.3$。",
            "answer": "$$\\boxed{74.3}$$"
        },
        {
            "introduction": "在掌握了线性模型之后，本问题将探索如何使用二次插值来捕捉更复杂的数据特征，例如曲率。你将确定一条穿过三个数据点的唯一抛物线，这在材料科学等领域是一项常见任务，因为在这些领域中，许多现象会表现出明显的极大值或极小值。这个练习  将加强代数性质与插值多项式几何形状之间的联系。",
            "id": "2181788",
            "problem": "一位材料科学家正在研究一种新开发的合金在热应力下的行为。该合金薄梁在其长度方向上位置 $x$ 处的挠度 $y(x)$ 得到了测量。在特定范围内的实验观察表明，挠度曲线可以被一个二次多项式 $y(x) = ax^2 + bx + c$ 精确建模。记录了三个精确的测量值：\n\n- 在位置 $x_1 = -1$ 处，挠度为 $y_1 = 8$。\n- 在位置 $x_2 = 2$ 处，挠度为 $y_2 = -1$。\n- 在位置 $x_3 = 5$ 处，挠度为 $y_3 = 8$。\n\n根据梁力学原理，对于这种特定设置，已知这三个测量点之一对应于最大挠度点（或最小，取决于 $a$ 的符号）。该点是抛物线的顶点。\n\n确定描述该挠度曲线的二次多项式 $y(x)$。请以标准形式 $y(x) = ax^2 + bx + c$ 给出您的答案。",
            "solution": "我们用二次函数 $y(x)=ax^{2}+bx+c$ 来为挠度建模。抛物线可以写成顶点式 $y(x)=a(x-h)^{2}+k$，其中 $(h,k)$ 是顶点，对称轴是 $x=h$。与 $h$ 等距的点的 $y$ 值相等。\n\n从数据中可知，$y(-1)=8$ 且 $y(5)=8$。$-1$ 和 $5$ 的中点是 $h=\\frac{-1+5}{2}=2$，所以对称轴是 $x=2$。已知其中一个测量点是顶点；由于 $y(2)=-1$ 并且这个值相对于另外两个值是极值，所以顶点是 $(h,k)=(2,-1)$。\n\n因此，该二次函数的形式为\n$$\ny(x)=a(x-2)^{2}-1.\n$$\n使用点 $(-1,8)$ 来求 $a$：\n$$\n8=a(-1-2)^{2}-1=a\\cdot 9-1 \\implies 9a=9 \\implies a=1.\n$$\n因此，\n$$\ny(x)=(x-2)^{2}-1=x^{2}-4x+4-1=x^{2}-4x+3.\n$$\n用 $x=5$ 检验，得到 $25-20+3=8$，与数据一致。因此，该二次函数是 $y(x)=x^{2}-4x+3$。",
            "answer": "$$\\boxed{x^{2}-4x+3}$$"
        },
        {
            "introduction": "这个高级计算实践深入探讨了插值的一个关键方面：通过策略性地选择节点来控制误差。你将通过编程实现并比较基于均匀分布节点与基于特定区域密集分布节点的插值多项式的精度。这项动手研究  揭示了为什么非均匀节点分布能够显著提高近似精度，这是高级数值方法中的一个基石概念。",
            "id": "3174893",
            "problem": "考虑函数 $f(x) = \\log(1+x)$，其定义域为 $x \\in [0,1]$，其中 $\\log$ 表示自然对数。本任务旨在研究函数 $f(x)$ 的多项式插值精度如何依赖于插值节点的分布，特别是比较节点在 $x=0$ 附近聚集与在 $[0,1]$ 上均匀分布这两种情况。您的研究必须基于多项式插值的核心定义以及由微积分推导出的标准误差表征，不得使用任何快捷公式或预先指定的计算表达式。\n\n您必须实现一个程序，对于给定的不同节点 $x_0, x_1, \\dots, x_N$ 和函数值 $f(x_i)$，构造出唯一的、次数至多为 $N$ 的多项式 $p_N(x)$，该多项式在这些节点上插值于 $f$，即对于所有 $i \\in \\{0,1,\\dots,N\\}$，均有 $p_N(x_i) = f(x_i)$。为了进行数值评估，您必须采用一种源于插值基本定义且数值稳定的方法，在指定区间的一组网格点上计算 $p_N(x)$ 的值，然后将其与 $f(x)$ 进行比较。\n\n对于给定的整数 $N \\geq 1$，定义两种节点族：\n- $[0,1]$ 上的均匀节点：$x_i^{\\mathrm{uni}} = \\frac{i}{N}$，其中 $i \\in \\{0,1,\\dots,N\\}$。\n- $[0,1]$ 上的聚集节点：$x_i^{\\mathrm{clu}} = \\left(\\frac{i}{N}\\right)^p$，其中 $i \\in \\{0,1,\\dots,N\\}$，$p$ 是一个大于 $1$ 的固定整数指数。在本问题中，使用 $p=3$。\n\n对于下方的每个测试用例，为指定的 $N$ 构建插值多项式 $p_N^{\\mathrm{uni}}(x)$ 和 $p_N^{\\mathrm{clu}}(x)$，在给定区间 $[a,b]$ 上的 $M=1001$ 个点的均匀网格上对它们进行求值，计算每种节点族在该区间上的最大绝对误差，\n$$\nE^{\\mathrm{uni}} = \\max_{x \\in [a,b]} \\left| f(x) - p_N^{\\mathrm{uni}}(x) \\right|, \\quad\nE^{\\mathrm{clu}} = \\max_{x \\in [a,b]} \\left| f(x) - p_N^{\\mathrm{clu}}(x) \\right|,\n$$\n并以浮点数形式报告比值 $R = \\frac{E^{\\mathrm{uni}}}{E^{\\mathrm{clu}}}$。比值 $R$ 量化了在 $x=0$ 附近聚集节点所带来的精度提升：$R > 1$ 的值表示在给定区间上，聚集节点的最大误差严格更小。\n\n测试套件（每个元组列出 $(N, p, a, b)$）：\n- 情况 1：$(4, 3, 0, 0.3)$：中等次数，$x=0$ 附近的局部区间。\n- 情况 2：$(4, 3, 0, 1)$：中等次数，整个区间。\n- 情况 3：$(8, 3, 0, 0.3)$：较高次数，$x=0$ 附近的局部区间。\n- 情况 4：$(8, 3, 0, 1)$：较高次数，整个区间。\n- 情况 5：$(1, 3, 0, 0.3)$：最低次数（线性），$x=0$ 附近的局部区间。\n\n您的程序必须生成单行输出，其中包含上述各情况的比值，以逗号分隔并用方括号括起来，顺序与给定情况的顺序一致。例如，输出格式必须为 $[R_1,R_2,R_3,R_4,R_5]$，其中每个 $R_k$ 都是按规定计算的浮点数。本问题不涉及任何物理单位或角度单位；所有量均为无量纲实数。",
            "solution": "核心任务是比较函数 $f(x) = \\log(1+x)$ 在区间 $[0,1]$ 上，使用两种不同的插值节点分布（均匀节点和在 $x=0$ 附近聚集的节点）时的插值精度。该比较通过在指定子区间上的最大绝对误差之比进行量化。\n\n对于任意 $N+1$ 个互不相同的节点 $\\{x_0, x_1, \\dots, x_N\\}$ 及相应的函数值 $\\{y_0, y_1, \\dots, y_N\\}$（其中 $y_i = f(x_i)$），存在一个唯一的、次数至多为 $N$ 的插值多项式 $p_N(x)$。该多项式满足对所有 $i \\in \\{0, 1, \\dots, N\\}$ 都有 $p_N(x_i) = y_i$。\n\n该多项式的一个基本表示形式是 Lagrange 形式：\n$$\np_N(x) = \\sum_{j=0}^{N} y_j L_j(x)\n$$\n其中 $L_j(x)$ 是 Lagrange 基多项式，定义为：\n$$\nL_j(x) = \\prod_{k=0, k \\neq j}^{N} \\frac{x - x_k}{x_j - x_k}\n$$\n虽然这个公式是基础的，但对多个点 $x$ 进行直接求值计算成本很高（每次求值为 $O(N^2)$），且可能存在数值不稳定性。一个更稳健的求值方法源于 Lagrange 形式，被称为重心插值公式。\n\n首先，我们定义节点多项式 $\\ell(x) = \\prod_{k=0}^{N} (x-x_k)$ 和重心权重 $w_j$：\n$$\nw_j = \\frac{1}{\\prod_{k=0, k \\neq j}^{N} (x_j - x_k)}\n$$\nLagrange 基多项式可以用这些量重写为：\n$$\nL_j(x) = \\ell(x) \\frac{w_j}{x-x_j}\n$$\n将其代入 Lagrange 公式，得到第一重心形式：\n$$\np_N(x) = \\ell(x) \\sum_{j=0}^{N} \\frac{w_j}{x - x_j} y_j\n$$\n为了进一步简化并提高稳定性，我们考虑对常数函数 $g(x)=1$ 进行插值。其插值多项式必须是 $g(x)$ 本身，因此有 $1 = \\sum_{j=0}^{N} L_j(x)$。代入 $L_j(x)$ 的重心表达式可得：\n$$\n1 = \\ell(x) \\sum_{j=0}^{N} \\frac{w_j}{x - x_j}\n$$\n用这个恒等式（该式对所有不等于节点的 $x$ 均成立）去除 $p_N(x)$ 的第一重心公式，我们得到第二（或“真”）重心形式：\n$$\np_N(x) = \\frac{\\sum_{j=0}^{N} \\frac{w_j}{x - x_j} y_j}{\\sum_{j=0}^{N} \\frac{w_j}{x - x_j}}\n$$\n这个公式非常适合计算。对于一组给定的节点，权重 $w_j$ 只需计算一次（一个 $O(N^2)$ 的过程）。之后，在任意点 $x$ 处计算 $p_N(x)$ 的值仅需 $O(N)$ 次运算。如果求值点 $x$ 与某个节点 $x_k$ 重合，该公式在解析上无定义，但我们知道插值多项式的值为 $p_N(x_k)=y_k$。此方法源于核心原理，并且数值稳定。\n\n多项式插值的理论误差由下式给出：\n$$\nf(x) - p_N(x) = \\frac{f^{(N+1)}(\\xi_x)}{(N+1)!} \\prod_{i=0}^{N} (x-x_i)\n$$\n其中 $\\xi_x$ 在包含所有节点和 $x$ 的最小区间内。对于函数 $f(x) = \\log(1+x)$，其导数为：\n$$\nf'(x) = (1+x)^{-1}, \\quad f''(x) = -(1+x)^{-2}, \\quad \\dots, \\quad f^{(k)}(x) = (-1)^{k-1} (k-1)! (1+x)^{-k}\n$$\n其 $(N+1)$ 阶导数为 $f^{(N+1)}(x) = (-1)^N N! (1+x)^{-(N+1)}$。该导数的绝对值 $|f^{(N+1)}(x)| = N!(1+x)^{-(N+1)}$ 在 $x=0$ 附近最大，并随 $x$ 的增加而减小。\n\n为了最小化总误差，节点多项式项 $\\prod_{i=0}^{N} (x-x_i)$ 应保持较小，尤其是在导数项较大的地方。与均匀节点 $x_i^{\\mathrm{uni}}=i/N$ 相比，聚集节点 $x_i^{\\mathrm{clu}} = (i/N)^p$（其中 $p=3$）在 $x=0$ 附近更密集。这种节点聚集的设计旨在减小节点多项式在 $x=0$ 附近的幅值，从而降低该区域的插值误差。\n\n对于每个测试用例 $(N, p, a, b)$，计算步骤如下：\n$1$. 定义函数 $f(x) = \\log(1+x)$。\n$2$. 在 $[0,1]$ 上生成两组各含 $N+1$ 个插值节点的集合：\n    - 均匀节点：$x_i^{\\mathrm{uni}} = \\frac{i}{N}$，其中 $i \\in \\{0, \\dots, N\\}$。\n    - 聚集节点：$x_i^{\\mathrm{clu}} = \\left(\\frac{i}{N}\\right)^p$，其中 $i \\in \\{0, \\dots, N\\}$ 且 $p=3$。\n$3$. 对每组节点，计算相应的函数值，例如 $y_i^{\\mathrm{uni}} = f(x_i^{\\mathrm{uni}})$。\n$4$. 对每组节点，使用 $O(N^2)$ 的直接公式计算重心权重 $w_j$。\n$5$. 在区间 $[a,b]$ 上创建一个包含 $M=1001$ 个点的精细均匀求值网格 $z_k$。\n$6$. 对每组节点，使用第二重心公式在求值网格的每个点 $z_k$ 上计算相应插值多项式（$p_N^{\\mathrm{uni}}(x)$ 和 $p_N^{\\mathrm{clu}}(x)$）的值。\n$7$. 在每个点 $z_k$ 上计算真实函数 $f(x)$ 的值。\n$8$. 在网格上计算每种情况的最大绝对误差：\n    $$\n    E^{\\mathrm{uni}} = \\max_{k} |f(z_k) - p_N^{\\mathrm{uni}}(z_k)|, \\quad E^{\\mathrm{clu}} = \\max_{k} |f(z_k) - p_N^{\\mathrm{clu}}(z_k)|\n    $$\n$9$. 计算并记录比值 $R = E^{\\mathrm{uni}} / E^{\\mathrm{clu}}$。\n对于 $N=1$ 的特殊情况，两种节点分布是相同的：$x_0^{\\mathrm{uni}} = x_0^{\\mathrm{clu}} = 0$ 且 $x_1^{\\mathrm{uni}} = x_1^{\\mathrm{clu}} = 1$。这意味着插值多项式是相同的，从而预期比值为 $R=1$。这可以作为一个有用的健全性检查。",
            "answer": "```python\nimport numpy as np\n\ndef get_barycentric_weights(nodes: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes barycentric weights for a given set of nodes.\n    w_j = 1 / product(x_j - x_k) for k != j.\n    \"\"\"\n    n_nodes = len(nodes)\n    weights = np.ones(n_nodes)\n    for j in range(n_nodes):\n        # The product can be calculated more stably in log space for large N,\n        # but for small N direct product is fine.\n        prod = 1.0\n        for k in range(n_nodes):\n            if k != j:\n                prod *= (nodes[j] - nodes[k])\n        weights[j] = 1.0 / prod\n    return weights\n\ndef evaluate_barycentric(nodes: np.ndarray, y_values: np.ndarray, weights: np.ndarray, eval_points: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Evaluates the interpolating polynomial at given points using the barycentric formula.\n    \"\"\"\n    poly_values = np.zeros_like(eval_points, dtype=np.float64)\n\n    for i, x in enumerate(eval_points):\n        # Check if evaluation point is one of the nodes to avoid division by zero\n        close_nodes_mask = np.isclose(x, nodes)\n        if np.any(close_nodes_mask):\n            node_idx = np.where(close_nodes_mask)[0][0]\n            poly_values[i] = y_values[node_idx]\n            continue\n        \n        # Barycentric formula (second form)\n        terms = weights / (x - nodes)\n        numerator = np.sum(terms * y_values)\n        denominator = np.sum(terms)\n        \n        # The denominator can be zero only if the polynomial degree is higher\n        # than N, which shouldn't happen for interpolation.\n        if denominator == 0:\n            # This case is unlikely but we handle it. Could happen with catastrophic cancellation.\n            # Find the closest node and return its value.\n            closest_node_idx = np.argmin(np.abs(x - nodes))\n            poly_values[i] = y_values[closest_node_idx]\n        else:\n            poly_values[i] = numerator / denominator\n            \n    return poly_values\n\ndef calculate_error_ratio(N: int, p: int, a: float, b: float, M: int = 1001) -> float:\n    \"\"\"\n    Calculates the ratio of max interpolation errors for uniform vs. clustered nodes.\n    \"\"\"\n    # The function to interpolate\n    func = np.log1p\n\n    # --- Uniform nodes ---\n    x_uni = np.linspace(0.0, 1.0, N + 1)\n    y_uni = func(x_uni)\n    w_uni = get_barycentric_weights(x_uni)\n\n    # --- Clustered nodes ---\n    # For N=1, (i/N)^p gives [0, 1], same as uniform.\n    if N > 0:\n        base_nodes = np.linspace(0.0, 1.0, N + 1)\n        x_clu = np.power(base_nodes, p)\n    else: # N=0, single node at 0\n        x_clu = np.array([0.0])\n    \n    y_clu = func(x_clu)\n    # If nodes are identical, ratio is 1.\n    if np.allclose(x_uni, x_clu):\n        return 1.0\n    w_clu = get_barycentric_weights(x_clu)\n\n    # --- Evaluation ---\n    eval_grid = np.linspace(a, b, M)\n    f_true = func(eval_grid)\n\n    # Evaluate uniform interpolant and its error\n    p_uni = evaluate_barycentric(x_uni, y_uni, w_uni, eval_grid)\n    error_uni = np.max(np.abs(f_true - p_uni))\n\n    # Evaluate clustered interpolant and its error\n    p_clu = evaluate_barycentric(x_clu, y_clu, w_clu, eval_grid)\n    error_clu = np.max(np.abs(f_true - p_clu))\n\n    # Avoid division by zero if clustered error is zero\n    if error_clu == 0.0:\n        # If uniform error is also zero, they are equally good (ratio 1).\n        # If uniform error is non-zero, clustered is infinitely better.\n        return 1.0 if error_uni == 0.0 else np.inf\n\n    return error_uni / error_clu\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # (N, p, a, b)\n        (4, 3, 0.0, 0.3),\n        (4, 3, 0.0, 1.0),\n        (8, 3, 0.0, 0.3),\n        (8, 3, 0.0, 1.0),\n        (1, 3, 0.0, 0.3),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, p, a, b = case\n        ratio = calculate_error_ratio(N, p, a, b)\n        results.append(ratio)\n\n    # Format the final output as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}