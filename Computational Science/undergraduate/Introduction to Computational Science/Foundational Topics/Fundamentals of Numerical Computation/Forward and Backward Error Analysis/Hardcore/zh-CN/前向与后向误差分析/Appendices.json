{
    "hands_on_practices": [
        {
            "introduction": "第一个实践将我们带到数值不稳定性的核心：两个相近数的减法。通过构建一个简化的浮点运算模型，这个练习让我们能够精确地计算前向误差、后向误差和条件数。这提供了一个直接的动手实践，展示了控制误差放大的基本关系，即一个微小且不可避免的输入误差如何导致灾难性巨大的输出误差 。",
            "id": "3132110",
            "problem": "给定标量函数 $f:\\mathbb{R}^2\\to\\mathbb{R}$，其定义为 $f(\\mathbf{x})=x_1-x_2$，其中 $\\mathbf{x}=(x_1,x_2)$。考虑一个简单的浮点模型，该模型首先将每个输入四舍五入到固定数量的有效十进制数字，然后精确地执行减法。具体来说，对于给定的正整数 $t$，计算值为\n$$\\widehat{f}=\\operatorname{fl}_t(x_1)-\\operatorname{fl}_t(x_2),$$\n其中 $\\operatorname{fl}_t(\\cdot)$ 表示使用“舍入到最近的偶数”（ties-to-even）规则，舍入到 $t$ 位有效十进制数字。\n\n您的任务是：\n1. 仅从前向误差、后向误差和条件数的核心定义出发，论证当 $x_1\\approx x_2$ 时，减法 $f(\\mathbf{x})=x_1-x_2$ 的行为。您必须：\n   - 对于输出 $y=f(\\mathbf{x})$ 和计算输出 $\\widehat{y}$，使用相对前向误差的定义：\n     $$\\text{相对前向误差}=\\frac{|\\widehat{y}-y|}{|y|},$$\n     其中 $y\\neq 0$。\n   - 在舍入优先模型下，使用后向误差的观点：将 $\\widehat{f}$ 解释为某个扰动输入 $\\tilde{\\mathbf{x}}=(\\tilde{x}_1,\\tilde{x}_2)$ 下的精确结果 $f(\\tilde{\\mathbf{x}})$，并将 $\\mathbf{x}$ 中的相对后向误差取为量\n     $$\\eta=\\max\\!\\left(\\frac{|\\tilde{x}_1-x_1|}{|x_1|},\\frac{|\\tilde{x}_2-x_2|}{|x_2|}\\right),$$\n     在此模型中，一个自然的选择是 $\\tilde{x}_i=\\operatorname{fl}_t(x_i)$。\n   - 从 $\\mathbf{x}$ 处相对条件数的基本定义出发，\n     $$\\kappa(\\mathbf{x})=\\lim_{\\rho\\to 0^+}\\ \\sup_{\\substack{\\Delta \\mathbf{x}\\neq \\mathbf{0}\\\\ \\max(|\\Delta x_1|/|x_1|,\\ |\\Delta x_2|/|x_2|)\\le \\rho}}\\ \\frac{\\left|\\ f(\\mathbf{x}+\\Delta \\mathbf{x})-f(\\mathbf{x})\\ \\right|/|f(\\mathbf{x})|}{\\max(|\\Delta x_1|/|x_1|,\\ |\\Delta x_2|/|x_2|)},$$\n     推导出专门针对 $f(\\mathbf{x})=x_1-x_2$ 的 $\\kappa(\\mathbf{x})$ 的显式公式，并解释为什么当 $x_1\\approx x_2$ 时它会变得很大。\n\n2. 实现一个程序，为每个指定的测试用例计算：\n   - 精确值 $f(\\mathbf{x})=x_1-x_2$。\n   - 计算值 $\\widehat{f}=\\operatorname{fl}_t(x_1)-\\operatorname{fl}_t(x_2)$，其中 $\\operatorname{fl}_t(\\cdot)$ 如上定义。\n   - 相对前向误差 $\\varepsilon=\\frac{|\\widehat{f}-f(\\mathbf{x})|}{|f(\\mathbf{x})|}$（所有答案必须以小数形式报告，而非百分比）。\n   - 在舍入优先模型下，$\\mathbf{x}$ 中的相对后向误差：\n     $$\\eta=\\max\\!\\left(\\frac{|\\operatorname{fl}_t(x_1)-x_1|}{|x_1|},\\frac{|\\operatorname{fl}_t(x_2)-x_2|}{|x_2|}\\right)。$$\n   - 从第一性原理出发，在任务1中得到的相对条件数 $\\kappa(\\mathbf{x})$（实现您推导出的表达式）。\n   - 放大因子 $A=\\varepsilon/\\eta$，它量化了微小的相对输入误差（后向误差）在输出中（前向误差）被放大的程度。\n\n3. 使用以下参数值的测试套件。每个测试用例是一个三元组 $(x_1,x_2,t)$，其中 $t$ 是舍入时使用的有效十进制数字的位数。这些用例都不会产生 $f(\\mathbf{x})=0$，因此相对前向误差是良定义的。\n   - 用例1（良态）：$(x_1,x_2,t)=\\left(12345.6789,\\ 2345.678901,\\ 7\\right)$。\n   - 用例2（小规模下的强相消）：$(x_1,x_2,t)=\\left(1.0000005,\\ 1.0000004,\\ 7\\right)$。\n   - 用例3（大规模下的强相消）：$(x_1,x_2,t)=\\left(100000003.0,\\ 100000000.0,\\ 7\\right)$。\n   - 用例4（中度相消）：$(x_1,x_2,t)=\\left(0.123456789,\\ 0.123446789,\\ 7\\right)$。\n\n4. 最终输出规范：\n   - 对于每个测试用例，按此确切顺序输出列表 $[A,\\ \\varepsilon,\\ \\eta,\\ \\kappa(\\mathbf{x})]$。\n   - 将所有用例聚合到单行中，作为这些列表的逗号分隔列表，并用方括号括起来，例如：\n     $$\\left[\\ [A_1,\\varepsilon_1,\\eta_1,\\kappa_1],\\ [A_2,\\varepsilon_2,\\eta_2,\\kappa_2],\\ \\ldots\\ \\right].$$\n   - 所有浮点数使用恰好10位有效数字的科学记数法打印（例如，$1.234567890\\times 10^{-3}$ 必须打印为 $1.2345678900\\mathrm{e}{-03}$）。\n\n科学真实性和约束：\n- 将所有量视为无量纲的实数。\n- 不涉及角度。\n- 所有误差量必须是小数或分数，而不是百分比。\n- 在十进制下，对 $\\operatorname{fl}_t(\\cdot)$ 使用“舍入到最近的偶数”规则。\n- 您的程序必须生成一行输出，其中包含按上述规定格式化的、用方括号括起来的逗号分隔列表的结果。",
            "solution": "所提出的问题是计算科学入门中一个有效且经典的练习，具体涉及一种基本算术运算的前向和后向误差分析。它具有科学依据，问题设定良好、客观且完整。任务是分析减法 $f(\\mathbf{x})=x_1-x_2$ 的数值稳定性，特别是在 $x_1 \\approx x_2$ 的相消抵消情况下。\n\n我们将首先根据所提供的定义推导必要的理论结果，然后实现一个程序来为给定的测试用例计算指定的量。\n\n### 第一部分：从第一性原理出发的理论分析\n\n**1. 相对条件数 $\\kappa(\\mathbf{x})$ 的推导**\n\n问题给出了函数 $f:\\mathbb{R}^2\\to\\mathbb{R}$ 在点 $\\mathbf{x}=(x_1, x_2)$ 处关于输入的相对扰动的相对条件数的形式化定义：\n$$\n\\kappa(\\mathbf{x})=\\lim_{\\rho\\to 0^+}\\ \\sup_{\\substack{\\Delta \\mathbf{x}\\neq \\mathbf{0}\\\\ \\max(|\\Delta x_1|/|x_1|,\\ |\\Delta x_2|/|x_2|)\\le \\rho}}\\ \\frac{\\left|\\ f(\\mathbf{x}+\\Delta \\mathbf{x})-f(\\mathbf{x})\\ \\right|/|f(\\mathbf{x})|}{\\max(|\\Delta x_1|/|x_1|,\\ |\\Delta x_2|/|x_2|)}\n$$\n让我们将此定义应用于函数 $f(\\mathbf{x}) = x_1 - x_2$。我们假设 $f(\\mathbf{x}) = x_1 - x_2 \\neq 0$ 且 $x_1, x_2 \\neq 0$。\n\n由扰动 $\\Delta\\mathbf{x}=(\\Delta x_1, \\Delta x_2)$ 引起的函数输出变化为：\n$$\nf(\\mathbf{x}+\\Delta \\mathbf{x}) - f(\\mathbf{x}) = ((x_1+\\Delta x_1) - (x_2+\\Delta x_2)) - (x_1 - x_2) = \\Delta x_1 - \\Delta x_2\n$$\n因此，输出的相对变化为：\n$$\n\\frac{|f(\\mathbf{x}+\\Delta \\mathbf{x}) - f(\\mathbf{x})|}{|f(\\mathbf{x})|} = \\frac{|\\Delta x_1 - \\Delta x_2|}{|x_1 - x_2|}\n$$\n令最大相对输入扰动为 $E_{\\text{rel}} = \\max\\left(\\frac{|\\Delta x_1|}{|x_1|}, \\frac{|\\Delta x_2|}{|x_2|}\\right)$。这意味着 $|\\Delta x_1| \\le E_{\\text{rel}} |x_1|$ 和 $|\\Delta x_2| \\le E_{\\text{rel}} |x_2|$。\n\n我们现在可以表示上确界内的比率：\n$$\n\\frac{\\left|\\ f(\\mathbf{x}+\\Delta \\mathbf{x})-f(\\mathbf{x})\\ \\right|/|f(\\mathbf{x})|}{E_{\\text{rel}}} = \\frac{|\\Delta x_1 - \\Delta x_2|/|x_1 - x_2|}{E_{\\text{rel}}}\n$$\n为了找到上确界，我们必须在给定的 $E_{\\text{rel}}=\\rho$ 下最大化项 $|\\Delta x_1 - \\Delta x_2|$。使用三角不等式：\n$$\n|\\Delta x_1 - \\Delta x_2| \\le |\\Delta x_1| + |\\Delta x_2| \\le \\rho |x_1| + \\rho |x_2| = \\rho (|x_1| + |x_2|)\n$$\n此上界可通过选择幅度最大且效应相反的扰动来达到。例如，如果我们选择 $\\Delta x_1 = \\rho x_1$ 和 $\\Delta x_2 = -\\rho x_2$，则 $E_{\\text{rel}} = \\max(|\\rho x_1|/|x_1|, |-\\rho x_2|/|x_2|) = \\rho$。等等，此选择得出 $|\\Delta x_1-\\Delta x_2| = |\\rho(x_1+x_2)| = \\rho|x_1+x_2|$。这不完全是界限 $\\rho(|x_1|+|x_2|)$。\n上确界是通过选择 $\\Delta x_1 = \\rho \\cdot \\text{sgn}(\\Delta x_1) \\cdot |x_1|$ 和 $\\Delta x_2 = \\rho \\cdot \\text{sgn}(\\Delta x_2) \\cdot |x_2|$，并设置符号以最大化差值来达到的。例如，选择 $\\Delta x_1 = \\rho|x_1|$ 和 $\\Delta x_2 = -\\rho|x_2|$ 并非一个有效的扰动选择，因为这可能意味着 $\\Delta x_1/x_1$ 的幅度不为 $\\rho$。\n正确的方法是选择 $\\Delta x_1$ 和 $\\Delta x_2$ 使得 $|\\Delta x_1|/|x_1| \\le \\rho$ 和 $|\\Delta x_2|/|x_2| \\le \\rho$。为了最大化 $|\\Delta x_1 - \\Delta x_2|$，我们选择例如 $\\Delta x_1 = \\rho \\cdot \\text{sgn}(x_1) \\cdot |x_1|'$，其中我们希望 $\\Delta x_1$ 为正，$\\Delta x_2$ 为负。上确界是通过选择 $\\Delta x_1$ 和 $\\Delta x_2$ 使得 $|\\Delta x_1| = \\rho|x_1|$，$|\\Delta x_2| = \\rho|x_2|$，且它们符号相反来达到的。例如，令 $\\Delta x_1 = \\rho|x_1|$ 和 $\\Delta x_2 = -\\rho|x_2|$。不，这不对。\n让我们选择 $\\Delta x_1$ 使得 $\\Delta x_1/x_1 = \\rho$（即 $\\Delta x_1 = \\rho x_1$）和 $\\Delta x_2$ 使得 $\\Delta x_2/x_2 = -\\rho$（即 $\\Delta x_2 = -\\rho x_2$）。通过这些选择，$E_{rel}=\\rho$。那么 $|\\Delta x_1 - \\Delta x_2| = |\\rho x_1 - (-\\rho x_2)| = \\rho|x_1+x_2|$。\n然而，正确找到上确界的标准推导确定了 $\\sup |\\Delta x_1 - \\Delta x_2| = \\rho(|x_1| + |x_2|)$。这可以通过设置 $\\Delta x_1 = \\rho|x_1|$ 和 $\\Delta x_2 = -\\rho|x_2|$ 来看到，如果我们选择 $\\Delta x_1 = \\rho \\cdot \\text{sgn}(x_1)|x_1| \\implies \\Delta x_1 = \\rho x_1$ 和 $\\Delta x_2 = -\\rho \\cdot \\text{sgn}(x_2)|x_2| \\implies \\Delta x_2 = -\\rho x_2$，它们满足约束条件（因为 $|x_1|/|x_1|=1$ 和 $|x_2|/|x_2|=1$）。产生的项是 $\\rho|x_1+x_2|$。一个不同的选择是 $\\Delta x_1 = \\rho x_1$ 和 $\\Delta x_2 = -\\rho x_2$。\n正确的界限确实是 $\\rho(|x_1|+|x_2|)$。这个最大值是在我们选择 $\\Delta x_1$ 和 $\\Delta x_2$ 具有相反符号和最大允许幅度时实现的，例如 $\\Delta x_1 = \\rho x_1$ 和 $\\Delta x_2 = -\\rho x_2$ 不够通用。我们应该选择 $\\Delta x_1 = \\rho |x_1|$ 和 $\\Delta x_2 = -\\rho |x_2|$ 或反之，但这可能违反相对误差的约束。\n让我们考虑扰动 $\\Delta x_1 = \\rho \\cdot \\alpha_1$ 和 $\\Delta x_2 = \\rho \\cdot \\alpha_2$，其中 $|\\alpha_1/x_1| \\le 1$ 和 $|\\alpha_2/x_2| \\le 1$。我们最大化 $|\\rho \\alpha_1 - \\rho \\alpha_2|$。\n在约束条件下， $|\\Delta x_1 - \\Delta x_2|$ 的正确上确界是 $\\rho(|x_1|+|x_2|)$。\n\n将此上确界代入条件数的表达式中：\n$$\n\\kappa(\\mathbf{x}) = \\lim_{\\rho\\to 0^+} \\frac{\\sup (|\\Delta x_1 - \\Delta x_2|)/|x_1 - x_2|}{\\rho} = \\lim_{\\rho\\to 0^+} \\frac{\\rho(|x_1| + |x_2|)/|x_1 - x_2|}{\\rho}\n$$\n对 $\\rho$ 的线性依赖性被消去，极限是平凡的。因此，推导出的公式是：\n$$\n\\kappa(\\mathbf{x}) = \\frac{|x_1| + |x_2|}{|x_1 - x_2|}\n$$\n\n**2. 当 $x_1 \\approx x_2$ 时 $\\kappa(\\mathbf{x})$ 的行为**\n\n当 $x_1$ 和 $x_2$ 的值很接近（$x_1 \\approx x_2$）时，分母 $|x_1 - x_2|$ 趋近于 $0$。假设 $x_1$ 和 $x_2$ 不接近于 $0$ 并且符号相同（这是灾难性相消的典型情况），则分子 $|x_1| + |x_2|$ 约等于 $2|x_1|$。因此，比率 $\\kappa(\\mathbf{x})$ 会变得非常大。一个大的条件数意味着问题是“病态的”，即输入中的小相对误差可能被放大成输出中的大相对误差。\n\n**3. 前向误差、后向误差和条件数之间的关系**\n\n问题定义了一个“舍入优先”的计算模型，其中 $\\widehat{f} = \\operatorname{fl}_t(x_1) - \\operatorname{fl}_t(x_2)$。这可以从后向误差的角度来看，通过定义一个扰动输入 $\\tilde{\\mathbf{x}} = (\\tilde{x}_1, \\tilde{x}_2) = (\\operatorname{fl}_t(x_1), \\operatorname{fl}_t(x_2))$。计算结果就是这个扰动输入的精确结果：$\\widehat{f} = f(\\tilde{\\mathbf{x}})$。\n\n相对后向误差 $\\eta$ 是对输入的相对扰动的大小：\n$$\n\\eta = \\max\\left(\\frac{|\\tilde{x}_1-x_1|}{|x_1|},\\frac{|\\tilde{x}_2-x_2|}{|x_2|}\\right)\n$$\n相对前向误差 $\\varepsilon$ 是输出中产生的相对扰动：\n$$\n\\varepsilon = \\frac{|\\widehat{f}-f(\\mathbf{x})|}{|f(\\mathbf{x})|} = \\frac{|f(\\tilde{\\mathbf{x}})-f(\\mathbf{x})|}{|f(\\mathbf{x})|}\n$$\n条件数 $\\kappa(\\mathbf{x})$ 将这两个量联系起来。对于小扰动，关系近似为：\n$$\n\\varepsilon \\approx \\kappa(\\mathbf{x}) \\cdot \\eta \\quad \\text{或更形式化地} \\quad \\varepsilon \\le \\kappa(\\mathbf{x}) \\cdot \\eta + O(\\eta^2)\n$$\n放大因子 $A = \\varepsilon / \\eta$ 是对由舍入引入的特定扰动下此关系的经验量化。由于条件数被定义为所有可能的小扰动的上确界，我们有不等式 $A \\le \\kappa(\\mathbf{x})$。\n\n当 $x_1 \\approx x_2$ 时，$\\kappa(\\mathbf{x})$ 很大。舍入过程引入了一个小的后向误差 $\\eta$，通常在机器精度的数量级。然而，这个小的输入误差被大的条件数放大，导致可能产生大的前向误差 $\\varepsilon$。这种现象称为**灾难性相消**：相近量的减法导致结果中有效数字的损失，不是因为减法本身不精确，而是因为它放大了输入中预先存在的舍入误差。\n\n**关于输出格式的说明**\n问题陈述要求“恰好10位有效数字”，但提供的数字 $1.234567890 \\times 10^{-3}$ 的格式化示例为 `1.2345678900e-03`。该示例输出有11位有效数字（小数点前1位，小数点后10位）。这带来了一个小小的歧义。我们将遵循明确的示例，因为它比一般性描述更具体。这对应于 Python 的格式说明符 `\"{:.10e}\"`。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef fl_t(x: float, t: int) -> float:\n    \"\"\"\n    Rounds a floating-point number x to t significant decimal digits.\n    Uses round-to-nearest, ties-to-even rule.\n    \"\"\"\n    if x == 0.0:\n        return 0.0\n\n    # Using np.float64 for calculations to maintain precision.\n    x = np.float64(x)\n\n    # Calculate the base-10 exponent of the number to find its magnitude.\n    exponent = np.floor(np.log10(np.abs(x)))\n    \n    # Calculate the power of 10 to scale the number.\n    # We want to move the decimal point so that there are t digits before it.\n    # Incorrect scaling power in thinking: Correct power to get `t` sig figs for rounding\n    # to integer is to scale by power of 10 that puts the t-th digit in the units place.\n    # e.g., for 123.45 and t=4, scale so it becomes 1234.5.\n    # Exponent is 2. Scale factor is 10^(4-(2+1)) = 10^1. 123.45 * 10 = 1234.5.\n    # scale_power = t - (exponent + 1)\n    \n    # A more direct way: to round to t sig-figs, we round x / 10^(e-t+1) to integer.\n    scale_power = exponent - t + 1\n    \n    # Scale the number. For example, to round 12345.67 to 3 sig figs,\n    # exponent=4, t=3. scale_power = 4-3+1 = 2.\n    # scaled_val = 12345.67 / 100 = 123.4567\n    scaled_val = x / (10.0**scale_power)\n    \n    # Python 3's round() and np.round() both implement round-half-to-even.\n    rounded_scaled_val = np.round(scaled_val)\n    \n    # Scale back to the original magnitude.\n    # result = 123.0 * 100 = 12300.0\n    result = rounded_scaled_val * (10.0**scale_power)\n    \n    return float(result)\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (well-conditioned)\n        (12345.6789, 2345.678901, 7),\n        # Case 2 (strong cancellation at small scale)\n        (1.0000005, 1.0000004, 7),\n        # Case 3 (strong cancellation at large scale)\n        (100000003.0, 100000000.0, 7),\n        # Case 4 (moderate cancellation)\n        (0.123456789, 0.123446789, 7)\n    ]\n\n    all_results = []\n\n    for x1_in, x2_in, t in test_cases:\n        # Use high-precision numpy floats for internal calculations\n        x1 = np.float64(x1_in)\n        x2 = np.float64(x2_in)\n\n        # 1. Exact value\n        f_exact = x1 - x2\n\n        # 2. Rounded inputs and computed value\n        x1_rounded = fl_t(x1, t)\n        x2_rounded = fl_t(x2, t)\n        f_computed = x1_rounded - x2_rounded\n\n        # 3. Relative forward error\n        # Problem statement guarantees f_exact is non-zero\n        rel_forward_error = np.abs(f_computed - f_exact) / np.abs(f_exact)\n\n        # 4. Relative backward error\n        # Problem statement inputs are non-zero.\n        rel_err_x1 = np.abs(x1_rounded - x1) / np.abs(x1)\n        rel_err_x2 = np.abs(x2_rounded - x2) / np.abs(x2)\n        rel_backward_error = np.max([rel_err_x1, rel_err_x2])\n\n        # 5. Relative condition number\n        condition_number = (np.abs(x1) + np.abs(x2)) / np.abs(f_exact)\n\n        # 6. Amplification factor\n        # If backward error is zero, forward error must also be zero.\n        # This implies exact computation, so amplification is not straightforward.\n        # For the given test cases, rel_backward_error will not be zero.\n        if rel_backward_error == 0.0:\n            # This case means the inputs didn't need rounding, so perturbation is 0.\n            # Forward error is also 0. The ratio 0/0 is indeterminate.\n            # A reasonable interpretation is that the amplification is bounded by kappa.\n            # We can also consider it 1.0, as there's no error to amplify.\n            # Let's assign it kappa, as it's the theoretical limit.\n            # However, for the given tests this branch is not taken.\n            amplification_factor = condition_number\n        else:\n            amplification_factor = rel_forward_error / rel_backward_error\n\n        # Store results for this case\n        all_results.append([amplification_factor, rel_forward_error, rel_backward_error, condition_number])\n\n    # Format the output as specified in the problem statement.\n    # The example \"1.2345678900e-03\" has 11 significant digits (1 before decimal, 10 after).\n    # This corresponds to the format specifier \"{:.10e}\".\n    def format_list(data_list):\n        return [f\"{val:.10e}\" for val in data_list]\n\n    formatted_cases = []\n    for result_case in all_results:\n        formatted_list_str =\",\".join(format_list(result_case))\n        formatted_cases.append(f\"[{formatted_list_str}]\")\n        \n    final_output_str = f\"[{','.join(formatted_cases)}]\"\n\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "在前一个概念的基础上，这个练习从简单的减法转移到一个常见数学函数的求值。在这里，你不仅要诊断灾难性抵消问题，还要通过实现一个数学上等价但数值上稳定的算法来主动解决它。这个实践强调了任何计算科学家都必须具备的一项关键技能：识别并重构不稳定的表达式以确保结果的可靠性 。",
            "id": "3232048",
            "problem": "设计并实现一个程序，对计算函数 $f(x)=\\sqrt{1+x}-1$（当 $x$ 的量级很小时）进行系统的前向误差和后向误差研究。从浮点计算中前向误差和后向误差的核心定义出发，并基于标准、经过充分检验的浮点模型：对于任何基本算术运算或初等函数求值，计算结果满足 $\\mathrm{fl}(a\\ \\mathrm{op}\\ b) = (a\\ \\mathrm{op}\\ b)(1+\\varepsilon)$，其中 $|\\varepsilon|\\le u$，$u$ 是格式的单位舍入；对于一个良态的初等函数 $g$，$\\mathrm{fl}(g(a)) = g(a)(1+\\varepsilon)$，其中 $|\\varepsilon|\\le u$。你的推导和算法设计必须依赖于这些原则。\n\n任务：\n- 构建两种算法，使用二进制64位浮点算术（即 $u \\approx 2^{-53}$）来计算 $f(x)$：\n  - 算法A：直接使用公式，该公式在 $x$ 很小时会出现相消抵消。\n  - 算法B：一个通过代数变换得到的数学上等价且数值稳定的形式，该形式避免了灾难性相消。\n- 对于每种算法，将输入 $x$ 的前向误差定义为 $| \\widehat{f}(x) - f(x) |$，其中 $\\widehat{f}(x)$ 是算法的浮点计算结果，$f(x)$ 是数学上的精确值。使用高精度算術来近似 $f(x)$，作为基准真值的替代。\n- 对于每种算法，通过精确求解方程 $\\widehat{f}(x) = f(x+\\delta)$ 来定义后向误差 $\\delta$（用 $\\widehat{f}(x)$ 和 $x$ 表示）。将 $|\\delta|$ 的大小作为后向误差报告。你的程序必须使用高精度算术来数值计算这个 $\\delta$，以避免在诊断计算本身中出现伪舍入。\n- 使用以下输入测试套件：\n  - $x = 10^{-8}$，\n  - $x = 10^{-16}$，\n  - $x = -10^{-8}$，\n  - $x = 0$，\n  - $x = -1 + 10^{-15}$。\n- 对于测试套件中的每个 $x$，按以下顺序输出一个包含四个浮点数的列表：\n  - 算法A的绝对前向误差，\n  - 算法B的绝对前向误差，\n  - 算法A的绝对后向误差 $|\\delta|$，\n  - 算法B的绝对后向误差 $|\\delta|$。\n- 你的程序应该生成单行输出，其中包含所有测试用例的结果，格式为一个用方括号括起来的逗号分隔列表，其中每个元素是对应测试输入的四元数列表，顺序与上文所列相同。\n\n注意与限制：\n- 所有的推导都必须仅使用上面给出的核心定义和浮点模型。不要使用或引用问题陈述中针对此特定表达式的任何专门的、预先推导出的误差界。\n- 在内部使用高精度算術来近似精确值以计算前向和后向误差；确保替代的精确性远超两种算法所使用的二进制64位算术的浮点噪声。\n- 不涉及物理单位；所有量均为无量纲实数。\n- 此任务不涉及角度。\n- 所有报告的数字必须是标准的十进制浮点值。",
            "solution": "所述问题是有效的：它在科学上基于数值分析的原理，问题提法清晰，目标明确，数据充分，并且没有主观或模糊的语言。因此，我们可以进行推导和实现。\n\n任务是为计算函数 $f(x) = \\sqrt{1+x} - 1$ 进行前向和后向误差分析，分析场景包括 $x$ 的量级很小以及 $x$ 接近 $-1$ 的情况。我们将设计两种算法，基于标准浮点算术模型分析它们的行为，并实现一个程序来计算和报告给定测试输入集的误差。\n\n设浮点模型定义如下：对于任何二元运算 $\\mathrm{op}$ 和任何初等函数 $g$，计算结果满足 $\\mathrm{fl}(a\\ \\mathrm{op}\\ b) = (a\\ \\mathrm{op}\\ b)(1+\\varepsilon_1)$ 和 $\\mathrm{fl}(g(a)) = g(a)(1+\\varepsilon_2)$，其中 $|\\varepsilon_i| \\le u$，$u$ 为单位舍入。对于指定的二进制64位算术，$u = 2^{-53}$。\n\n**算法设计**\n\n**算法A（直接方法）：**\n该算法使用给定的公式计算 $f(x)$：\n$f_A(x) = \\sqrt{1+x} - 1$。\n对于一个 $|x|$ 很小的输入 $x$，$1+x$ 的值非常接近 $1$。因此，平方根 $\\sqrt{1+x}$ 也非常接近 $1$。最后一步涉及到两个几乎相等的数相减，这种现象被称为灾难性相消。此操作会导致有效数字的损失。计算结果 $\\widehat{f_A}(x)$ 将具有很大的相对误差，并且绝对误差将与单位舍入 $u$ 的量级相当，而与真值 $f(x) \\approx x/2$ 的量级无关。这表明算法存在数值不稳定性。\n\n**算法B（稳定方法）：**\n为避免灾难性相消，我们可以通过分子乘以并除以其共轭表达式 $\\sqrt{1+x}+1$ 来重构 $f(x)$ 的表达式：\n$$ f(x) = (\\sqrt{1+x} - 1) \\times \\frac{\\sqrt{1+x} + 1}{\\sqrt{1+x} + 1} = \\frac{(1+x) - 1^2}{\\sqrt{1+x} + 1} = \\frac{x}{\\sqrt{1+x} + 1} $$\n这就得到了算法B：\n$f_B(x) = \\frac{x}{\\sqrt{1+x} + 1}$。\n当 $|x|$ 很小时，分母 $\\sqrt{1+x}+1$ 接近 $2$。所涉及的运算是与 $1$ 相加、开平方、再与 $1$ 相加，以及除以一个远离零的数。在這種情況下，这些运算都不是数值敏感的。该计算避免了几乎相等的量相减，因此预期是数值稳定的。计算结果 $\\widehat{f_B}(x)$ 的相对误差应该是单位舍入 $u$ 的一个小的倍数。\n\n**误差分析框架**\n\n**前向误差：**\n绝对前向误差定义为计算值 $\\widehat{f}(x)$ 与真实数学值 $f(x)$之差的绝对值：\n$$ E_f = |\\widehat{f}(x) - f(x)| $$\n为了在我们的分析中计算这个量，$f(x)$ 必须用比所研究的二进制64位算术高得多的精度来计算。这可作为“基准真值”的替代。\n\n**后向误差：**\n后向误差是衡量对输入 $x$ 的最小扰动 $\\delta$ 的度量，该扰动使得计算结果 $\\widehat{f}(x)$ 成为受扰动输入的精确结果。我们必须找到 $\\delta$ 使得：\n$$ \\widehat{f}(x) = f(x+\\delta) = \\sqrt{1 + (x+\\delta)} - 1 $$\n我们可以解这个方程求 $\\delta$。令 $y = \\widehat{f}(x)$：\n$$ y + 1 = \\sqrt{1 + x + \\delta} $$\n$$ (y + 1)^2 = 1 + x + \\delta $$\n$$ \\delta = (y + 1)^2 - 1 - x $$\n绝对后向误差是 $|\\delta|$。我们将使用这个公式来数值计算 $\\delta$，同样使用高精度算术以确保诊断计算本身不成为误差的来源。\n\n对于一个良态问题，一个数值稳定的算法将同时具有小的前向误差和小的前向误差。对于一个病态问题，稳定算法的特征是后向误差小，但仍可能表现出大的前向误差，因为问题本身会放大输入扰动。\n\n**测试用例分析**\n\n1.  对于 $x = 10^{-8}$ 和 $x = -10^{-8}$：\n    这里 $|x|$ 很小。算法A将遭受灾难性相消，导致大的前向误差（绝对误差 $\\approx u \\approx 10^{-16}$）和相对于 $x$ 而言大的后向误差。算法B是稳定的，将产生小的前向误差和后向误差。\n\n2.  对于 $x = 10^{-16}$：\n    这个 $x$ 的值小于二进制64位算术的单位舍入（$u = 2^{-53} \\approx 1.11 \\times 10^{-16}$）。因此，在浮点算术中，运算 $1.0 + x$ 会舍入为 $1.0$。\n    对于算法A，$\\widehat{f_A}(x) = \\mathrm{fl}(\\sqrt{1.0} - 1.0) = 0$。真值是 $f(10^{-16}) \\approx 0.5 \\times 10^{-16}$。前向误差为 $|0 - f(10^{-16})| \\approx 0.5 \\times 10^{-16}$。后向误差 $\\delta$ 来自于求解 $f(10^{-16}+\\delta)=0$，这意味着 $\\delta = -10^{-16}$。\n    对于算法B，$\\widehat{f_B}(x) = \\mathrm{fl}(x / (\\sqrt{1.0} + 1.0)) = \\mathrm{fl}(x/2)$。结果将非常接近真值 $f(x) \\approx x/2$，因此前向和后向误差都将极小。\n\n3.  对于 $x=0$：\n    两种算法都将精确计算出 $0$，而真值为 $f(0)=0$。所有误差度量都将是 $0$。\n\n4.  对于 $x = -1 + 10^{-15}$：\n    这里 $x$ 接近 $-1$，而不是 $0$。函数 $f(x)$ 的条件数为 $C_f(x) = \\left| \\frac{x f'(x)}{f(x)} \\right| = \\left| \\frac{\\sqrt{1+x}+1}{2\\sqrt{1+x}} \\right|$。当 $x \\to -1^+$ 时，$1+x \\to 0^+$ 且 $C_f(x) \\to \\infty$。该问题是高度病态的。\n    算法A的相消抵消问题在这里不会发生，因为 $\\sqrt{1+x} = \\sqrt{10^{-15}} \\approx 3.16 \\times 10^{-8}$，这个值并不接近 $1$。对于此输入，算法A和算法B都是稳定的。\n    因此，两种算法都应该表现出小的后向误差，量级约为 $u \\approx 10^{-16}$。然而，由于问题的极端病态性，这个小的后向误差（以及初始输入的表示误差）将被极大地放大，导致两种算法都产生大的前向误差。前向误差的量级大约为 $C_f(x) \\times |x| \\times u$。\n\n实现将遵循这些原则，使用高精度算術进行基准真值和误差计算。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport decimal\n\ndef solve():\n    \"\"\"\n    Performs a forward and backward error study for two algorithms computing\n    f(x) = sqrt(1+x) - 1.\n    \"\"\"\n    # Set a high precision for the decimal module to serve as \"exact\" arithmetic.\n    decimal.setcontext(decimal.Context(prec=100))\n\n    # Define the test cases. Using strings preserves precision for Decimal.\n    # The case '-1+1e-15' requires special construction.\n    test_case_defs = ['1e-8', '1e-16', '-1e-8', '0', ('-1', '1e-15')]\n\n    def get_decimal_from_def(case_def):\n        if isinstance(case_def, str):\n            return decimal.Decimal(case_def)\n        elif isinstance(case_def, tuple):\n            return decimal.Decimal(case_def[0]) + decimal.Decimal(case_def[1])\n\n    test_cases = [get_decimal_from_def(d) for d in test_case_defs]\n\n    all_results = []\n\n    one_dec = decimal.Decimal('1')\n\n    for x_dec in test_cases:\n        # Step 1: Compute the \"ground truth\" value using high-precision arithmetic.\n        # The function is defined for x >= -1.\n        if x_dec  -one_dec:\n            # This path is not taken by the problem's test suite.\n            continue\n        \n        # Exact mathematical value f(x)\n        f_exact = (one_dec + x_dec).sqrt() - one_dec\n\n        # Step 2: Convert input to standard float64 for algorithmic computation.\n        x_float = np.float64(x_dec)\n\n        # Step 3: Execute Algorithm A (direct, unstable for x approx 0).\n        # f_hat_A = sqrt(1+x) - 1\n        f_hat_A = np.sqrt(np.float64(1.0) + x_float) - np.float64(1.0)\n\n        # Step 4: Execute Algorithm B (re-rationalized, stable for x approx 0).\n        # f_hat_B = x / (sqrt(1+x) + 1)\n        if x_float == 0.0:\n            f_hat_B = np.float64(0.0)\n        else:\n            denominator = np.sqrt(np.float64(1.0) + x_float) + np.float64(1.0)\n            f_hat_B = x_float / denominator\n        \n        # Step 5: Compute forward errors. Convert float results to Decimal for\n        # high-precision subtraction from the exact value.\n        f_hat_A_dec = decimal.Decimal(f_hat_A)\n        f_hat_B_dec = decimal.Decimal(f_hat_B)\n        \n        forward_error_A = abs(f_hat_A_dec - f_exact)\n        forward_error_B = abs(f_hat_B_dec - f_exact)\n\n        # Step 6: Compute backward errors using the derived formula:\n        # delta = (f_hat(x) + 1)^2 - 1 - x\n        # All calculations are done in high precision.\n        delta_A = (f_hat_A_dec + one_dec)**2 - one_dec - x_dec\n        backward_error_A = abs(delta_A)\n\n        delta_B = (f_hat_B_dec + one_dec)**2 - one_dec - x_dec\n        backward_error_B = abs(delta_B)\n\n        # Append the four required error metrics for this test case.\n        # Convert final Decimal error values to float for output.\n        all_results.append([\n            float(forward_error_A),\n            float(forward_error_B),\n            float(backward_error_A),\n            float(backward_error_B)\n        ])\n\n    # Step 7: Format the final output string exactly as required.\n    # The output should be a string representing a list of lists,\n    # with no spaces inside the inner lists.\n    inner_lists_str = [f\"[{r[0]},{r[1]},{r[2]},{r[3]}]\" for r in all_results]\n    final_output = f\"[{','.join(inner_lists_str)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "我们的最后一个实践将误差分析的概念从标量函数扩展到矩阵算法。当我们正交化一组向量时，我们如何衡量“误差”？这个练习引入了一个关于后向误差的不同视角，将其定义为输出未能满足核心数学性质（在此例中为正交性）的程度。通过比较经典格拉姆-施密特算法和修正的格拉姆-施密特算法，你将亲眼看到实现上的一个微小改变如何对算法的稳定性产生巨大影响 。",
            "id": "3232097",
            "problem": "你的任务是比较两种广泛使用的标准正交化过程——经典Gram–Schmidt和修正Gram–Schmidt——在标准浮点运算中实现时的前向误差和后向误差。使用基于浮点运算模型的前向误差和后向误差定义：对于应用于实数的任何基本运算，其计算结果可以表示为 $\\mathrm{fl}(x \\,\\mathrm{op}\\, y) = (x \\,\\mathrm{op}\\, y)(1+\\delta)$，其中 $\\mathrm{op} \\in \\{+,-,\\times,\\div\\}$ 且 $|\\delta| \\le u$，$u$ 是所用算术的单位舍入。在精确算术中，Gram–Schmidt方法产生一个分解 $A = Q R$，其中 $Q^\\top Q = I$ 且 $R$ 是一个具有非负对角元的上三角矩阵。在浮点运算中，计算出的因子 $\\widehat{Q}$ 和 $\\widehat{R}$ 满足 $A \\approx \\widehat{Q}\\widehat{R}$ 和 $\\widehat{Q}^\\top \\widehat{Q} \\approx I$。\n\n你的程序必须：\n- 实现两个函数，给定一个满秩或秩亏的实矩阵 $A \\in \\mathbb{R}^{m \\times n}$（其中 $m \\ge n$），使用以下方法返回 $(Q,R)$：\n  1. 经典Gram–Schmidt（单遍，无再正交化）。\n  2. 修正Gram–Schmidt（单遍，无再正交化）。\n- 对于每对 $(Q,R)$ 和每个输入矩阵 $A$，计算：\n  1. 分解的前向误差，即相对谱范数残差\n     $$\\eta_{\\mathrm{fwd}} = \\frac{\\lVert A - Q R \\rVert_2}{\\lVert A \\rVert_2}.$$\n  2. 以正交性损失表示的后向误差\n     $$F = Q^\\top Q - I,\\quad \\eta_{\\mathrm{orth}} = \\lVert F \\rVert_2.$$\n- 所有矩阵范数均使用谱范数 $\\lVert \\cdot \\rVert_2$。\n- 将报告的每个标量值四舍五入到 $12$ 位小数。\n\n测试组：\n- 情况1（良态高矩阵）：\n  $$A_1 = \\begin{bmatrix}\n  1  2  3  4 \\\\\n  2  1  0  1 \\\\\n  0  1  2  3 \\\\\n  1  0  1  0 \\\\\n  2  2  2  2 \\\\\n  3  1  4  1\n  \\end{bmatrix} \\in \\mathbb{R}^{6 \\times 4}.$$\n- 情况2（近似线性相关的列）：令 $\\varepsilon = 10^{-8}$ 且\n  $$c_1 = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\\\ 5 \\end{bmatrix},\\quad\n  w = \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\\\ -1 \\\\ 1 \\end{bmatrix},\\quad\n  c_2 = c_1 + \\varepsilon w,\\quad\n  c_3 = \\begin{bmatrix} 2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 2 \\end{bmatrix},\\quad\n  A_2 = [\\, c_1\\ \\ c_2\\ \\ c_3 \\,] \\in \\mathbb{R}^{5 \\times 3}.$$\n- 情况3（希尔伯特型高矩阵，病态列）：对于 $m = 8$，$n = 5$，定义\n  $$\\left(A_3\\right)_{i,j} = \\frac{1}{i + j + 1},\\quad 0 \\le i \\le 7,\\ 0 \\le j \\le 4,$$\n  因此 $A_3 \\in \\mathbb{R}^{8 \\times 5}$。\n- 情况4（已是标准正交的列）：令 $m = 6$，$n = 3$，且\n  $$A_4 = \\begin{bmatrix}\n  1  0  0 \\\\\n  0  0  0 \\\\\n  0  1  0 \\\\\n  0  0  0 \\\\\n  0  0  0 \\\\\n  0  0  1\n  \\end{bmatrix} \\in \\mathbb{R}^{6 \\times 3}.$$\n\n对于每个测试用例 $A_k$，计算四个标量值：\n- $\\eta_{\\mathrm{fwd}}^{\\mathrm{CGS}}$，\n- $\\eta_{\\mathrm{fwd}}^{\\mathrm{MGS}}$，\n- $\\eta_{\\mathrm{orth}}^{\\mathrm{CGS}}$，\n- $\\eta_{\\mathrm{orth}}^{\\mathrm{MGS}}$，\n每个值都四舍五入到 $12$ 位小数。\n\n最终输出格式：\n- 你的程序应生成单行输出，包含所有四个情况的结果，格式为逗号分隔的列表的列表，每个内部列表按\n  $$[\\, \\eta_{\\mathrm{fwd}}^{\\mathrm{CGS}},\\ \\eta_{\\mathrm{fwd}}^{\\mathrm{MGS}},\\ \\eta_{\\mathrm{orth}}^{\\mathrm{CGS}},\\ \\eta_{\\mathrm{orth}}^{\\mathrm{MGS}} \\,],$$\n  的顺序排列，并用方括号括起来。例如：\n  $$[\\ [a_1,b_1,c_1,d_1],\\ [a_2,b_2,c_2,d_2],\\ [a_3,b_3,c_3,d_3],\\ [a_4,b_4,c_4,d_4]\\ ].$$\n\n所有计算必须使用标准双精度浮点运算进行。不允许用户输入；程序必须是独立的，并且必须以指定格式精确打印一行。所有报告的值都是无单位的实数，并四舍五入到 $12$ 位小数。",
            "solution": "该问题陈述是数值线性代数领域中一个有效、适定且客观的练习。它要求比较用于计算矩阵QR分解的两种标准算法：经典Gram-Schmidt（CGS）和修正Gram-Schmidt（MGS）。该问题具有科学依据，为待实现的算法和待计算的误差度量提供了精确的数学定义。所有必要的数据和测试条件都已提供，没有歧义或矛盾。任务是实现指定的算法和度量标准，并将它们应用于一组旨在突显CGS和MGS数值特性的测试用例。\n\n问题的核心是计算给定矩阵 $A \\in \\mathbb{R}^{m \\times n}$（其中 $m \\ge n$）的QR分解，这是一个 $A = QR$ 的分解，其中 $Q \\in \\mathbb{R}^{m \\times n}$ 具有标准正交列（$Q^\\top Q = I_n$），而 $R \\in \\mathbb{R}^{n \\times n}$ 是一个上三角矩阵。在浮点运算中，计算出的因子（表示为 $\\widehat{Q}$ 和 $\\widehat{R}$）将只能近似这些性质。\n\nGram-Schmidt过程是构造此类分解的一种基本方法。它生成一系列标准正交向量 $q_0, q_1, \\dots, q_{n-1}$，这些向量构成了矩阵 $A$ 列空间的一个标准正交基。需要实现的两个变体是：\n\n$1$. **经典Gram-Schmidt（CGS）**：该算法通过从 $A$ 的相应列 $a_j$ 中显式减去其在所有先前计算出的标准正交向量 $q_0, \\dots, q_{j-1}$ 上的投影来计算每个向量 $q_j$。对于列 $j$ 的所有投影计算都使用向量 $a_j$。对列 $j$ 的步骤如下：\n$$v_j = a_j - \\sum_{i=0}^{j-1} (q_i^\\top a_j) q_i$$\n$$r_{jj} = \\lVert v_j \\rVert_2, \\quad q_j = v_j / r_{jj}$$\n系数 $r_{ij} = q_i^\\top a_j$（其中 $i  j$）也会被计算。\n尽管CGS在数学上是正确的，但众所周知它在数值上是不稳定的。在计算 $q_i^\\top a_j$ 时的微小舍入误差可能导致计算出的 $\\widehat{Q}$ 的列严重丧失正交性。\n\n$2$. **修正Gram-Schmidt（MGS）**：这是CGS的一种代数上等价但数值上更稳定的重排。MGS不是将 $a_j$ 投影到每个 $q_i$ 上，而是在每一步更新 $A$ 的其余列。在计算出 $q_i$ 后，其分量将从所有后续列 $a_{i+1}, \\dots, a_{n-1}$ 中移除。这可以表示为：\n令对所有 $j$ 都有 $v^{(0)}_j = a_j$。对于 $i = 0, \\dots, n-1$：\n$$r_{ii} = \\lVert v^{(i)}_i \\rVert_2, \\quad q_i = v^{(i)}_i / r_{ii}$$\n对于 $j = i+1, \\dots, n-1$：\n$$r_{ij} = q_i^\\top v^{(i)}_j, \\quad v^{(i+1)}_j = v^{(i)}_j - r_{ij} q_i$$\n这个过程确保每个新向量都与已经正交化过的向量进行正交化，从而减少误差的累积，并得到一个其列向量更接近于完全正交的矩阵 $\\widehat{Q}$。\n\n在秩亏的情况下，向量 $v_j$（在CGS中）或 $v_i^{(i)}$（在MGS中）可能变为零或在数值上接近于零。实现将通过检查其范数是否低于一个小的容差（$10^{-12}$）来处理这种情况。如果是，则对应的列 $q_j$ 被设置为零向量，并且其在 $R$ 中的对角元 $r_{jj}$ 被设置为 $0$。\n\n这些算法的稳定性和准确性通过两个度量标准来评估：\n\n$1$. **前向误差**：$\\eta_{\\mathrm{fwd}} = \\frac{\\lVert A - \\widehat{Q} \\widehat{R} \\rVert_2}{\\lVert A \\rVert_2}$。这衡量了分解的相对残差。较小的值表示计算出的因子 $\\widehat{Q}$ 和 $\\widehat{R}$ 更准确地重构了原始矩阵 $A$。这可以解释为分解问题本身的后向稳定性的一个度量；计算出的因子是邻近矩阵 $A+E$ 的精确因子，而此误差度量了 $E$ 的大小。\n\n$2$. **正交性损失**：$\\eta_{\\mathrm{orth}} = \\lVert \\widehat{Q}^\\top \\widehat{Q} - I \\rVert_2$。这是算法在生成标准正交矩阵 $Q$ 这一性质上的后向误差的直接度量。接近 $0$ 的值表示 $\\widehat{Q}$ 的列几乎是标准正交的，而接近 $1$ 的值表示正交性严重损失。预期该度量标准能清晰地区分MGS的稳定性与CGS的不稳定性，尤其是在处理病态矩阵时。\n\n程序将实现CGS和MGS两种算法，将它们应用于四个提供的测试矩阵，并为每个分解计算两种误差度量。所有矩阵范数计算均使用谱范数 $\\lVert \\cdot \\rVert_2$。四个测试用例中每个用例的最终结果，包括两种算法的两种误差，都将被四舍五入到 $12$ 位小数，并以指定的列表的列表格式呈现。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef classical_gram_schmidt(A):\n    \"\"\"\n    Computes the QR factorization of a matrix A using Classical Gram-Schmidt.\n    \"\"\"\n    m, n = A.shape\n    Q = np.zeros((m, n), dtype=float)\n    R = np.zeros((n, n), dtype=float)\n    \n    for j in range(n):\n        v = A[:, j].copy()\n        for i in range(j):\n            R[i, j] = Q[:, i].T @ A[:, j] # Project a_j onto q_i\n            v -= R[i, j] * Q[:, i]\n            \n        norm_v = np.linalg.norm(v)\n        \n        if norm_v  1e-12:\n            R[j, j] = norm_v\n            Q[:, j] = v / R[j, j]\n        else:\n            R[j, j] = 0.0\n            # Q[:, j] remains a zero vector\n            \n    return Q, R\n\ndef modified_gram_schmidt(A):\n    \"\"\"\n    Computes the QR factorization of a matrix A using Modified Gram-Schmidt.\n    \"\"\"\n    m, n = A.shape\n    V = A.copy()\n    Q = np.zeros((m, n), dtype=float)\n    R = np.zeros((n, n), dtype=float)\n    \n    for i in range(n):\n        norm_v_i = np.linalg.norm(V[:, i])\n        R[i, i] = norm_v_i\n        \n        if R[i, i]  1e-12:\n            Q[:, i] = V[:, i] / R[i, i]\n            for j in range(i + 1, n):\n                R[i, j] = Q[:, i].T @ V[:, j]\n                V[:, j] -= R[i, j] * Q[:, i]\n        else:\n            # R[i, i] is already set to the small norm (or 0)\n            # Q[:, i] remains a zero vector.\n            # Projections of V[:, j] onto a zero Q[:, i] are zero, so R[i, j] for ji are zero\n            # and subsequent V columns are not modified.\n            pass\n            \n    return Q, R\n\ndef compute_errors(A, Q, R):\n    \"\"\"\n    Computes the forward error and orthogonality loss for a given QR factorization.\n    \"\"\"\n    m, n = A.shape\n    \n    # Forward error: ||A - QR||_2 / ||A||_2\n    norm_A = np.linalg.norm(A, 2)\n    if norm_A == 0:\n        fwd_error = 0.0\n    else:\n        fwd_error = np.linalg.norm(A - Q @ R, 2) / norm_A\n\n    # Orthogonality loss: ||Q^T Q - I||_2\n    if n  0:\n        orth_error = np.linalg.norm(Q.T @ Q - np.eye(n), 2)\n    else:\n        orth_error = 0.0\n        \n    return fwd_error, orth_error\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis on the defined test cases.\n    \"\"\"\n    # Case 1: Well-conditioned tall matrix\n    A1 = np.array([\n        [1, 2, 3, 4],\n        [2, 1, 0, 1],\n        [0, 1, 2, 3],\n        [1, 0, 1, 0],\n        [2, 2, 2, 2],\n        [3, 1, 4, 1]\n    ], dtype=float)\n\n    # Case 2: Nearly dependent columns\n    epsilon = 1e-8\n    c1 = np.array([1, 2, 3, 4, 5], dtype=float).reshape(-1, 1)\n    w = np.array([1, -1, 1, -1, 1], dtype=float).reshape(-1, 1)\n    c2 = c1 + epsilon * w\n    c3 = np.array([2, 0, 1, 0, 2], dtype=float).reshape(-1, 1)\n    A2 = np.hstack([c1, c2, c3])\n\n    # Case 3: Hilbert-type tall matrix\n    m3, n3 = 8, 5\n    A3 = np.fromfunction(lambda i, j: 1 / (i + j + 2), (m3, n3), dtype=float)\n\n    # Case 4: Already orthonormal columns\n    A4 = np.array([\n        [1, 0, 0],\n        [0, 0, 0],\n        [0, 1, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 1]\n    ], dtype=float)\n\n    test_cases = [A1, A2, A3, A4]\n    all_results = []\n\n    for A in test_cases:\n        # Classical Gram-Schmidt\n        Q_cgs, R_cgs = classical_gram_schmidt(A)\n        fwd_cgs, orth_cgs = compute_errors(A, Q_cgs, R_cgs)\n\n        # Modified Gram-Schmidt\n        Q_mgs, R_mgs = modified_gram_schmidt(A)\n        fwd_mgs, orth_mgs = compute_errors(A, Q_mgs, R_mgs)\n\n        case_results = [\n            round(fwd_cgs, 12),\n            round(fwd_mgs, 12),\n            round(orth_cgs, 12),\n            round(orth_mgs, 12)\n        ]\n        all_results.append(case_results)\n\n    # Format the output as a string representation of a list of lists.\n    # str() on a list adds spaces, which is what the example shows.\n    # Let's rebuild the string manually to match the required format without spaces inside brackets.\n    # [[a,b,c,d],[e,f,g,h]]\n    \n    result_strings = []\n    for res in all_results:\n        # The problem statement example has spaces inside brackets:\n        # `[\\, \\eta_{\\mathrm{fwd}}^{\\mathrm{CGS}},\\ \\eta_{\\mathrm{fwd}}^{\\mathrm{MGS}},\\ ... \\,]`\n        # The Python list str() representation `[1, 2, 3]` includes spaces.\n        # But another example `[[a_1,b_1,c_1,d_1],\\ [a_2,b_2,c_2,d_2],...` shows spaces too.\n        # I will use the python str() for simplicity, as it matches the visual spacing.\n        # Let's double check the output format. \"comma-separated list of the list\"\n        # `[[a_1,b_1,c_1,d_1],[a_2,b_2,c_2,d_2], ... ]` - No spaces in this representation.\n        # OK, I will remove the spaces.\n        inner_str = str(res).replace(\" \", \"\")\n        result_strings.append(inner_str)\n\n    # The problem description contains a subtle error in Case 3, where the Hilbert matrix\n    # should be 1/(i+j+1) for 0-indexed languages. The provided formula 1/(i+j+1) with 0-based indices is correct.\n    # However, the original code used 1/(i+j+2), which is incorrect. I will fix it back to 1/(i+j+1).\n    A3 = np.fromfunction(lambda i, j: 1 / (i + j + 1), (m3, n3), dtype=float)\n    # Re-run for case 3.\n    Q_cgs_3, R_cgs_3 = classical_gram_schmidt(A3)\n    fwd_cgs_3, orth_cgs_3 = compute_errors(A3, Q_cgs_3, R_cgs_3)\n    Q_mgs_3, R_mgs_3 = modified_gram_schmidt(A3)\n    fwd_mgs_3, orth_mgs_3 = compute_errors(A3, Q_mgs_3, R_mgs_3)\n    all_results[2] = [round(fwd_cgs_3,12), round(fwd_mgs_3,12), round(orth_cgs_3,12), round(orth_mgs_3,12)]\n    \n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}