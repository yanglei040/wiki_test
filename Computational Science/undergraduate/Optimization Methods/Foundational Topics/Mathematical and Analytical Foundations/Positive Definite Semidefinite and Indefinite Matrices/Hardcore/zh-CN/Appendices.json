{
    "hands_on_practices": [
        {
            "introduction": "在优化中，梯度下降法是最基本的方法之一，其核心思想是沿梯度的反方向进行线搜索。对于凸函数（其Hessian矩阵是正定的），这一策略保证了目标函数的下降。然而，当函数非凸时（Hessian矩阵是不定的）会发生什么？ 这个练习将通过一个具体的计算，揭示负曲率（对应于负特征值）如何使得精确线搜索失效，甚至导致目标函数值上升，从而深刻理解矩阵定性对算法行为的决定性影响。",
            "id": "3163346",
            "problem": "考虑无约束二次目标函数 $f(x) = \\tfrac{1}{2} x^{\\top} Q x$，其中 $Q \\in \\mathbb{R}^{n \\times n}$ 是对称矩阵。如果对于所有非零向量 $x$，都有 $x^{\\top} Q x > 0$，则矩阵 $Q$ 称为正定（PD）矩阵；如果存在非零向量 $x$ 和 $y$，使得 $x^{\\top} Q x > 0$ 且 $y^{\\top} Q y  0$，则称矩阵 $Q$ 为不定矩阵。在基于梯度的优化中，从当前点 $x$ 沿搜索方向 $p$ 进行的精确线搜索定义为，通过求解 $\\frac{d}{d\\alpha}\\phi(\\alpha) = 0$ 来选择一个步长 $\\alpha$，以最小化单变量函数 $\\phi(\\alpha) = f(x + \\alpha p)$。\n\n你的任务是，在给定的起始点使用最速下降方向 $p = -\\nabla f(x)$，比较正定（PD）矩阵 $Q$ 与不定矩阵 $Q$ 的精确线搜索行为。请处理以下两种情况：\n\n- 正定情况：$Q_{\\text{PD}} = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix}$ 和 $x_{\\text{PD}} = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$。\n- 不定情况：$Q_{\\text{indef}} = \\begin{pmatrix} 1  0 \\\\ 0  -3 \\end{pmatrix}$ 和 $x_{\\text{indef}} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n\n从梯度和精确线搜索的基本定义出发，不使用任何预先记下的快捷公式，对每种情况执行以下操作：\n\n1. 在给定点 $x$ 处，计算最速下降方向 $p = -\\nabla f(x)$。\n2. 推导并计算满足 $\\frac{d}{d\\alpha} f(x + \\alpha p) = 0$ 的精确线搜索步长 $\\alpha^{\\star}$。\n3. 评估目标函数的变化量 $\\Delta f = f(x + \\alpha^{\\star} p) - f(x)$。\n\n以行矩阵 $\\begin{pmatrix} \\alpha^{\\star}_{\\text{PD}}  \\alpha^{\\star}_{\\text{indef}}  \\Delta f_{\\text{PD}}  \\Delta f_{\\text{indef}} \\end{pmatrix}$ 的精确形式返回你的最终答案。无需四舍五入，且无单位。",
            "solution": "该问题要求在两种不同的对称矩阵 $Q$ 情景下（一种是 $Q$ 为正定（PD），另一种是 $Q$ 为不定），对无约束二次目标函数 $f(x) = \\frac{1}{2} x^{\\top} Q x$ 的精确线搜索过程进行分析。搜索方向被指定为最速下降方向 $p = -\\nabla f(x)$。\n\n首先，我们为我们感兴趣的量建立通用公式。目标函数为 $f(x) = \\frac{1}{2} x^{\\top} Q x$。该函数关于 $x$ 的梯度由下式给出：\n$$ \\nabla f(x) = \\frac{1}{2} (Q + Q^{\\top}) x $$\n由于 $Q$ 是对称的，即 $Q = Q^{\\top}$，这可将梯度简化为：\n$$ \\nabla f(x) = Qx $$\n在点 $x$ 处的最速下降方向 $p$ 定义为梯度的负值：\n$$ p = -\\nabla f(x) = -Qx $$\n精确线搜索旨在找到一个步长 $\\alpha$，以最小化单变量函数 $\\phi(\\alpha) = f(x + \\alpha p)$。我们首先构建此函数：\n$$ \\phi(\\alpha) = f(x + \\alpha p) = \\frac{1}{2} (x + \\alpha p)^{\\top} Q (x + \\alpha p) $$\n展开此表达式，我们得到：\n$$ \\phi(\\alpha) = \\frac{1}{2} (x^{\\top} + \\alpha p^{\\top}) Q (x + \\alpha p) = \\frac{1}{2} (x^{\\top}Qx + \\alpha x^{\\top}Qp + \\alpha p^{\\top}Qx + \\alpha^2 p^{\\top}Qp) $$\n由于 $x^{\\top}Qp$ 是一个标量，它等于其转置 $(x^{\\top}Qp)^{\\top} = p^{\\top}Q^{\\top}x$。给定 $Q=Q^{\\top}$，这可简化为 $p^{\\top}Qx$。因此，中间的两项是相同的。\n$$ \\phi(\\alpha) = \\frac{1}{2} x^{\\top}Qx + \\alpha p^{\\top}Qx + \\frac{1}{2} \\alpha^2 p^{\\top}Qp $$\n问题将寻找步长 $\\alpha^{\\star}$ 的过程定义为求解 $\\frac{d}{d\\alpha}\\phi(\\alpha) = 0$。我们计算关于 $\\alpha$ 的导数：\n$$ \\frac{d\\phi}{d\\alpha} = p^{\\top}Qx + \\alpha p^{\\top}Qp $$\n将导数设为零，得到驻点 $\\alpha^{\\star}$：\n$$ p^{\\top}Qx + \\alpha^{\\star} p^{\\top}Qp = 0 \\implies \\alpha^{\\star} = -\\frac{p^{\\top}Qx}{p^{\\top}Qp} $$\n我们可以通过代入 $Qx = -p$ 来简化此表达式：\n$$ \\alpha^{\\star} = -\\frac{p^{\\top}(-p)}{p^{\\top}Qp} = \\frac{p^{\\top}p}{p^{\\top}Qp} $$\n这个 $\\alpha^{\\star}$ 的表达式在 $p^{\\top}Qp \\neq 0$ 的条件下有效。\n\n目标函数的变化量为 $\\Delta f = f(x + \\alpha^{\\star} p) - f(x)$。使用 $\\phi(\\alpha)$ 的表达式，这等于 $\\phi(\\alpha^{\\star}) - \\phi(0)$。\n$$ \\Delta f = \\left( \\frac{1}{2} x^{\\top}Qx + \\alpha^{\\star} p^{\\top}Qx + \\frac{1}{2} (\\alpha^{\\star})^2 p^{\\top}Qp \\right) - \\frac{1}{2} x^{\\top}Qx $$\n$$ \\Delta f = \\alpha^{\\star} p^{\\top}Qx + \\frac{1}{2} (\\alpha^{\\star})^2 p^{\\top}Qp $$\n根据一阶条件 $p^{\\top}Qx + \\alpha^{\\star} p^{\\top}Qp = 0$，我们有 $p^{\\top}Qx = -\\alpha^{\\star} p^{\\top}Qp$。将此代入 $\\Delta f$ 的表达式中：\n$$ \\Delta f = \\alpha^{\\star} (-\\alpha^{\\star} p^{\\top}Qp) + \\frac{1}{2} (\\alpha^{\\star})^2 p^{\\top}Qp = -(\\alpha^{\\star})^2 p^{\\top}Qp + \\frac{1}{2} (\\alpha^{\\star})^2 p^{\\top}Qp = -\\frac{1}{2} (\\alpha^{\\star})^2 p^{\\top}Qp $$\n或者，代入 $p^{\\top}Qp = \\frac{p^{\\top}p}{\\alpha^{\\star}}$ 可得到另一种有用的形式：\n$$ \\Delta f = -\\frac{1}{2} (\\alpha^{\\star})^2 \\left( \\frac{p^{\\top}p}{\\alpha^{\\star}} \\right) = -\\frac{1}{2} \\alpha^{\\star} p^{\\top}p $$\n\n现在我们将这些通用公式应用于指定的两种情况。\n\n**情况 1：正定矩阵**\n给定的矩阵和起始点为：\n$Q_{\\text{PD}} = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix}$ 和 $x_{\\text{PD}} = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$。\n\n1.  计算最速下降方向 $p_{\\text{PD}}$：\n    $\\nabla f(x_{\\text{PD}}) = Q_{\\text{PD}} x_{\\text{PD}} = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} 4(1) + 1(-2) \\\\ 1(1) + 3(-2) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -5 \\end{pmatrix}$。\n    $p_{\\text{PD}} = -\\nabla f(x_{\\text{PD}}) = \\begin{pmatrix} -2 \\\\ 5 \\end{pmatrix}$。\n\n2.  使用 $\\alpha^{\\star} = \\frac{p^{\\top}p}{p^{\\top}Qp}$ 计算精确线搜索步长 $\\alpha^{\\star}_{\\text{PD}}$：\n    $p_{\\text{PD}}^{\\top} p_{\\text{PD}} = (-2)^2 + 5^2 = 4 + 25 = 29$。\n    $Q_{\\text{PD}} p_{\\text{PD}} = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} -2 \\\\ 5 \\end{pmatrix} = \\begin{pmatrix} 4(-2) + 1(5) \\\\ 1(-2) + 3(5) \\end{pmatrix} = \\begin{pmatrix} -3 \\\\ 13 \\end{pmatrix}$。\n    $p_{\\text{PD}}^{\\top} Q_{\\text{PD}} p_{\\text{PD}} = \\begin{pmatrix} -2  5 \\end{pmatrix} \\begin{pmatrix} -3 \\\\ 13 \\end{pmatrix} = (-2)(-3) + 5(13) = 6 + 65 = 71$。\n    $\\alpha^{\\star}_{\\text{PD}} = \\frac{29}{71}$。\n    $\\phi(\\alpha)$ 的二阶导数是 $\\frac{d^2\\phi}{d\\alpha^2} = p_{\\text{PD}}^{\\top} Q_{\\text{PD}} p_{\\text{PD}} = 71 > 0$。由于 $Q_{\\text{PD}}$ 是正定的，对于任何非零 $p$，这一点都得到保证。这个正的二阶导数证实了 $\\alpha^{\\star}_{\\text{PD}}$ 对应于一个最小值。\n\n3.  使用 $\\Delta f = -\\frac{1}{2} \\alpha^{\\star} p^{\\top}p$ 评估目标函数的变化量 $\\Delta f_{\\text{PD}}$：\n    $\\Delta f_{\\text{PD}} = -\\frac{1}{2} \\left( \\frac{29}{71} \\right) (29) = -\\frac{841}{142}$。目标函数值减小，这与最小化步骤的预期相符。\n\n**情况 2：不定矩阵**\n给定的矩阵和起始点为：\n$Q_{\\text{indef}} = \\begin{pmatrix} 1  0 \\\\ 0  -3 \\end{pmatrix}$ 和 $x_{\\text{indef}} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n\n1.  计算最速下降方向 $p_{\\text{indef}}$：\n    $\\nabla f(x_{\\text{indef}}) = Q_{\\text{indef}} x_{\\text{indef}} = \\begin{pmatrix} 1  0 \\\\ 0  -3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1(1) + 0(1) \\\\ 0(1) + (-3)(1) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -3 \\end{pmatrix}$。\n    $p_{\\text{indef}} = -\\nabla f(x_{\\text{indef}}) = \\begin{pmatrix} -1 \\\\ 3 \\end{pmatrix}$。\n\n2.  计算精确线搜索步长 $\\alpha^{\\star}_{\\text{indef}}$：\n    $p_{\\text{indef}}^{\\top} p_{\\text{indef}} = (-1)^2 + 3^2 = 1 + 9 = 10$。\n    $Q_{\\text{indef}} p_{\\text{indef}} = \\begin{pmatrix} 1  0 \\\\ 0  -3 \\end{pmatrix} \\begin{pmatrix} -1 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 1(-1) + 0(3) \\\\ 0(-1) + (-3)(3) \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -9 \\end{pmatrix}$。\n    $p_{\\text{indef}}^{\\top} Q_{\\text{indef}} p_{\\text{indef}} = \\begin{pmatrix} -1  3 \\end{pmatrix} \\begin{pmatrix} -1 \\\\ -9 \\end{pmatrix} = (-1)(-1) + 3(-9) = 1 - 27 = -26$。\n    $\\alpha^{\\star}_{\\text{indef}} = \\frac{p_{\\text{indef}}^{\\top} p_{\\text{indef}}}{p_{\\text{indef}}^{\\top} Q_{\\text{indef}} p_{\\text{indef}}} = \\frac{10}{-26} = -\\frac{5}{13}$。\n    $\\phi(\\alpha)$ 的二阶导数是 $\\frac{d^2\\phi}{d\\alpha^2} = p_{\\text{indef}}^{\\top} Q_{\\text{indef}} p_{\\text{indef}} = -26  0$。这个负值表明找到的驻点是一个局部最大值，而不是一个最小值。函数 $\\phi(\\alpha)$ 是一个开口向下的抛物线，下方无界，这意味着线搜索的真正最小值不存在。步长 $\\alpha^\\star$ 是应用指定程序的结果，但该程序未能找到最小值。$\\alpha^\\star$ 的负号意味着步长是沿着梯度方向而不是反梯度方向的。\n\n3.  评估目标函数的变化量 $\\Delta f_{\\text{indef}}$：\n    $\\Delta f_{\\text{indef}} = -\\frac{1}{2} \\alpha^{\\star}_{\\text{indef}} p_{\\text{indef}}^{\\top} p_{\\text{indef}} = -\\frac{1}{2} \\left( -\\frac{5}{13} \\right) (10) = \\frac{50}{26} = \\frac{25}{13}$。\n    目标函数值增加，这与沿搜索方向移动到局部最大值的情况相符。\n\n最后，我们将计算出的四个值组装成所要求的行矩阵。\n$$ \\begin{pmatrix} \\alpha^{\\star}_{\\text{PD}}  \\alpha^{\\star}_{\\text{indef}}  \\Delta f_{\\text{PD}}  \\Delta f_{\\text{indef}} \\end{pmatrix} = \\begin{pmatrix} \\frac{29}{71}  -\\frac{5}{13}  -\\frac{841}{142}  \\frac{25}{13} \\end{pmatrix} $$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{29}{71}  -\\frac{5}{13}  -\\frac{841}{142}  \\frac{25}{13} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "既然简单的线搜索方法在非凸问题上会失效，我们如何设计更可靠的算法呢？信赖域方法提供了一个强大的解决方案。它通过在模型可信的局部区域（“信赖域”）内求解一个子问题来保证算法的稳健性。 在这个练习中，你将利用Hessian矩阵的特征分解，从第一性原理出发求解一个信赖域子问题。这个过程将清晰地展示算法如何利用负曲率方向来有效降低目标函数值，这也是处理非凸问题的一个核心技巧。",
            "id": "3163285",
            "problem": "考虑无约束优化中的二次信赖域子问题：\n最小化 $q(\\mathbf{p}) = \\mathbf{g}^{\\top}\\mathbf{p} + \\tfrac{1}{2}\\mathbf{p}^{\\top}\\mathbf{H}\\mathbf{p}$，约束条件为 $\\|\\mathbf{p}\\|_{2} \\leq \\Delta$，其中 $\\|\\cdot\\|_{2}$ 表示欧几里得范数。设对称矩阵 $\\mathbf{H}$ 具有特征分解 $\\mathbf{H} = \\mathbf{Q}\\mathbf{\\Lambda}\\mathbf{Q}^{\\top}$，其中\n$$\\mathbf{Q} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1  1 \\\\ -1  1 \\end{pmatrix}, \\quad \\mathbf{\\Lambda} = \\begin{pmatrix} -2  0 \\\\ 0  1 \\end{pmatrix}。$$\n设梯度向量为 $\\mathbf{g} = \\mathbf{Q}\\begin{pmatrix} 0 \\\\ 3 \\end{pmatrix}$，信赖域半径为 $\\Delta = 2$。仅使用第一性原理（特征分解、欧几里得范数以及约束最小化的必要最优性条件的定义），通过特征分解显式地求解该信赖域子问题。识别负曲率方向并解释其对最优点的影响。然后计算精确的最小目标值 $q(\\mathbf{p}^{\\star})$。将你的最终答案以一个精确数值（不要四舍五入）的形式给出。",
            "solution": "该问题是求解二次信赖域子问题：\n$$ \\text{minimize} \\quad q(\\mathbf{p}) = \\mathbf{g}^{\\top}\\mathbf{p} + \\tfrac{1}{2}\\mathbf{p}^{\\top}\\mathbf{H}\\mathbf{p} \\quad \\text{subject to} \\quad \\|\\mathbf{p}\\|_{2} \\leq \\Delta $$\n其中海森矩阵 $\\mathbf{H}$ 具有给定的特征分解 $\\mathbf{H} = \\mathbf{Q}\\mathbf{\\Lambda}\\mathbf{Q}^{\\top}$，梯度为 $\\mathbf{g}$，信赖域半径为 $\\Delta$。\n\n首先，我们验证问题陈述的有效性。给定条件如下：\n$\\mathbf{Q} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1  1 \\\\ -1  1 \\end{pmatrix}$，$\\mathbf{\\Lambda} = \\begin{pmatrix} -2  0 \\\\ 0  1 \\end{pmatrix}$，$\\mathbf{g} = \\mathbf{Q}\\begin{pmatrix} 0 \\\\ 3 \\end{pmatrix}$，以及 $\\Delta = 2$。\n矩阵 $\\mathbf{Q}$ 是正交的，因为 $\\mathbf{Q}^{\\top}\\mathbf{Q} = \\frac{1}{2}\\begin{pmatrix} 1  -1 \\\\ 1  1 \\end{pmatrix}\\begin{pmatrix} 1  1 \\\\ -1  1 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} = \\mathbf{I}$。$\\mathbf{H}$ 的特征值是 $\\mathbf{\\Lambda}$ 的对角线元素，即 $\\lambda_1 = -2$ 和 $\\lambda_2 = 1$。由于一个特征值为负，$\\mathbf{H}$ 是一个不定矩阵。该问题是优化理论中一个标准的、适定的子问题。数据是一致且完整的。因此，该问题是有效的。\n\n为解决该问题，我们使用 $\\mathbf{H}$ 的特征向量基进行变量替换。令 $\\mathbf{p} = \\mathbf{Q}\\mathbf{s}$，其中 $\\mathbf{s} = \\begin{pmatrix} s_1 \\\\ s_2 \\end{pmatrix}$。由于 $\\mathbf{Q}$ 是一个正交矩阵，这种变换是一种旋转和/或反射，它保持欧几里得范数不变：\n$$ \\|\\mathbf{p}\\|_{2} = \\|\\mathbf{Q}\\mathbf{s}\\|_{2} = \\sqrt{(\\mathbf{Q}\\mathbf{s})^{\\top}(\\mathbf{Q}\\mathbf{s})} = \\sqrt{\\mathbf{s}^{\\top}\\mathbf{Q}^{\\top}\\mathbf{Q}\\mathbf{s}} = \\sqrt{\\mathbf{s}^{\\top}\\mathbf{I}\\mathbf{s}} = \\|\\mathbf{s}\\|_{2} $$\n约束条件 $\\|\\mathbf{p}\\|_{2} \\leq \\Delta$ 变为 $\\|\\mathbf{s}\\|_{2} \\leq \\Delta$。\n\n现在我们将目标函数 $q(\\mathbf{p})$ 用 $\\mathbf{s}$ 表示：\n$$ q(\\mathbf{p}) = \\mathbf{g}^{\\top}\\mathbf{p} + \\tfrac{1}{2}\\mathbf{p}^{\\top}\\mathbf{H}\\mathbf{p} = (\\mathbf{Q}\\hat{\\mathbf{g}})^{\\top}(\\mathbf{Q}\\mathbf{s}) + \\tfrac{1}{2}(\\mathbf{Q}\\mathbf{s})^{\\top}(\\mathbf{Q}\\mathbf{\\Lambda}\\mathbf{Q}^{\\top})(\\mathbf{Q}\\mathbf{s}) $$\n其中 $\\hat{\\mathbf{g}} = \\mathbf{Q}^{\\top}\\mathbf{g} = \\mathbf{Q}^{\\top}\\left(\\mathbf{Q}\\begin{pmatrix} 0 \\\\ 3 \\end{pmatrix}\\right) = \\begin{pmatrix} 0 \\\\ 3 \\end{pmatrix}$。\n利用 $\\mathbf{Q}$ 的正交性，目标函数简化为：\n$$ \\hat{q}(\\mathbf{s}) = \\hat{\\mathbf{g}}^{\\top}\\mathbf{Q}^{\\top}\\mathbf{Q}\\mathbf{s} + \\tfrac{1}{2}\\mathbf{s}^{\\top}\\mathbf{Q}^{\\top}\\mathbf{Q}\\mathbf{\\Lambda}\\mathbf{Q}^{\\top}\\mathbf{Q}\\mathbf{s} = \\hat{\\mathbf{g}}^{\\top}\\mathbf{s} + \\tfrac{1}{2}\\mathbf{s}^{\\top}\\mathbf{\\Lambda}\\mathbf{s} $$\n问题被转换为关于变量 $\\mathbf{s}$ 的等价问题：\n$$ \\text{minimize} \\quad \\hat{q}(\\mathbf{s}) = \\hat{\\mathbf{g}}^{\\top}\\mathbf{s} + \\tfrac{1}{2}\\mathbf{s}^{\\top}\\mathbf{\\Lambda}\\mathbf{s} \\quad \\text{subject to} \\quad \\|\\mathbf{s}\\|_{2} \\leq \\Delta $$\n代入给定值 $\\hat{\\mathbf{g}} = \\begin{pmatrix} 0 \\\\ 3 \\end{pmatrix}$，$\\mathbf{\\Lambda} = \\begin{pmatrix} -2  0 \\\\ 0  1 \\end{pmatrix}$ 和 $\\Delta=2$：\n$$ \\hat{q}(s_1, s_2) = \\begin{pmatrix} 0  3 \\end{pmatrix} \\begin{pmatrix} s_1 \\\\ s_2 \\end{pmatrix} + \\tfrac{1}{2} \\begin{pmatrix} s_1  s_2 \\end{pmatrix} \\begin{pmatrix} -2  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} s_1 \\\\ s_2 \\end{pmatrix} = 3s_2 - s_1^2 + \\tfrac{1}{2}s_2^2 $$\n约束条件为 $s_1^2 + s_2^2 \\leq 2^2 = 4$。\n\n目标函数中的 $-s_1^2$ 项对应于负特征值 $\\lambda_1 = -2$。该项表明目标函数随着 $|s_1|$ 的增大而减小。因此，$\\hat{q}(\\mathbf{s})$ 的无约束最小值不存在，约束问题的解必定位于信赖域的边界上，即 $\\|\\mathbf{s}\\|_{2} = \\Delta = 2$。\n在边界上，我们有 $s_1^2 + s_2^2 = 4$，这意味着 $s_1^2 = 4 - s_2^2$。$s_2$ 的定义域是 $[-2, 2]$。我们可以将 $s_1^2$ 代入目标函数，得到一个关于 $s_2$ 的一维问题：\n$$ \\hat{q}(s_2) = 3s_2 - (4-s_2^2) + \\tfrac{1}{2}s_2^2 = \\tfrac{3}{2}s_2^2 + 3s_2 - 4 $$\n我们需要在区间 $[-2, 2]$ 上找到这个关于 $s_2$ 的二次函数的最小值。函数 $\\hat{q}(s_2)$ 是一个开口向上的抛物线。其全局最小值出现在顶点处。通过将关于 $s_2$ 的导数设为零来找到顶点：\n$$ \\frac{d\\hat{q}}{ds_2} = 3s_2 + 3 = 0 \\implies s_2 = -1 $$\n由于 $s_2 = -1$ 在区间 $[-2, 2]$ 内，这是使 $\\hat{q}(s_2)$ 最小化的 $s_2$ 的值。\n当 $s_2 = -1$ 时，我们求出 $s_1^2$ 的相应值：\n$$ s_1^2 = 4 - s_2^2 = 4 - (-1)^2 = 3 \\implies s_1 = \\pm\\sqrt{3} $$\n因此，在 $\\mathbf{s}$ 空间中存在两个解：$\\mathbf{s}^{\\star} = \\begin{pmatrix} \\sqrt{3} \\\\ -1 \\end{pmatrix}$ 和 $\\mathbf{s}^{\\star} = \\begin{pmatrix} -\\sqrt{3} \\\\ -1 \\end{pmatrix}$。两者都得到相同的最小目标值。\n\n负曲率方向是对应于负特征值 $\\lambda_1 = -2$ 的特征向量。这是 $\\mathbf{Q}$ 的第一列，我们称之为 $\\mathbf{q}_1 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$。解 $\\mathbf{p}$ 在这个方向上的分量由 $s_1$ 给出。在信赖域约束允许的范围内，优化过程驱使解在该分量上具有尽可能大的模，即 $|s_1| = \\sqrt{3}$。条件 $\\hat{g}_1 = (\\mathbf{Q}^{\\top}\\mathbf{g})_1 = 0$ 是一种特殊情况，称为“困难情形”（hard case），因为梯度在负曲率方向上没有分量。这要求解必须沿负曲率方向移动一步到达信赖域边界才能找到最小值。\n\n最后，我们计算目标函数的精确最小值 $q(\\mathbf{p}^{\\star})$，它等于 $\\hat{q}(\\mathbf{s}^{\\star})$。我们可以使用任一个最优的 $\\mathbf{s}^{\\star}$ 向量。我们使用 $s_1 = \\sqrt{3}$ 和 $s_2 = -1$：\n$$ q(\\mathbf{p}^{\\star}) = \\hat{q}(\\sqrt{3}, -1) = 3(-1) - (\\sqrt{3})^2 + \\tfrac{1}{2}(-1)^2 = -3 - 3 + \\tfrac{1}{2} = -6 + \\tfrac{1}{2} = -5.5 $$\n或者，使用一维函数 $\\hat{q}(s_2)$：\n$$ q(\\mathbf{p}^{\\star}) = \\hat{q}(s_2=-1) = \\tfrac{3}{2}(-1)^2 + 3(-1) - 4 = \\tfrac{3}{2} - 3 - 4 = \\tfrac{3}{2} - 7 = \\tfrac{3-14}{2} = -\\tfrac{11}{2} $$\n最小目标值为 $-5.5$。",
            "answer": "$$\\boxed{-\\frac{11}{2}}$$"
        },
        {
            "introduction": "除了设计能处理非凸性的复杂算法外，另一种强大的策略是“凸化”问题，即用一个凸问题来近似原始的非凸问题。一种常见的方法是找到与原Hessian矩阵“最接近”的半正定（PSD）矩阵。 这个练习将引导你推导如何将一个对称矩阵投影到半正定矩阵锥上，这一过程等价于将其谱（特征值）进行阈值化处理。通过对比原始非凸问题和其凸化近似问题的解，你将亲身体会到这种转换对优化结果的巨大影响。",
            "id": "3163344",
            "problem": "设 $S^{n}$ 表示装备有 Frobenius 范数 $\\|X\\|_{F} = \\sqrt{\\sum_{i,j} X_{ij}^{2}}$ 的 $n \\times n$ 实对称矩阵空间。半正定 (PSD) 锥为 $\\mathcal{S}_{+}^{n} = \\{X \\in S^{n} : X \\succeq 0\\}$。正交群为 $\\mathcal{O}(n) = \\{U \\in \\mathbb{R}^{n \\times n} : U^{\\top} U = I\\}$。考虑投影问题：给定 $A \\in S^{n}$，求 $\\Pi_{\\mathcal{S}_{+}^{n}}(A) = \\arg\\min_{X \\in \\mathcal{S}_{+}^{n}} \\|X - A\\|_{F}^{2}$。\n\n仅从以下基本事实出发：(i) 实对称矩阵的谱定理（任意 $A \\in S^{n}$ 可写为 $A = U \\Lambda U^{\\top}$，其中 $U \\in \\mathcal{O}(n)$，$\\Lambda$ 是由实特征值组成的对角矩阵），以及 (ii) Frobenius 范数的正交不变性（对于 $U \\in \\mathcal{O}(n)$，有 $\\|U^{\\top} X U\\|_{F} = \\|X\\|_{F}$），完成以下任务：\n\n1. 在不预先假设任何投影公式的情况下，根据 $A$ 的特征值和特征向量推导出 $\\Pi_{\\mathcal{S}_{+}^{n}}(A)$ 的形式。您的推导必须仅依赖于上述事实以及凸最小化和 PSD 锥的基本性质。\n\n2. 将您的推导应用于给定的显式矩阵 $A \\in S^{3}$\n$$\nA = \\begin{pmatrix}\n3  0  0 \\\\\n0  1  0 \\\\\n0  0  -0.1\n\\end{pmatrix}.\n$$\n计算 $P = \\Pi_{\\mathcal{S}_{+}^{3}}(A)$ 以及 Frobenius 投影误差 $\\|A - P\\|_{F}^{2}$。\n\n3. 考虑单位球上的约束二次优化问题\n$$\n\\min_{x \\in \\mathbb{R}^{3}} \\;\\; f_{M}(x) = \\frac{1}{2}\\, x^{\\top} M x + b^{\\top} x \\quad \\text{约束条件为} \\quad \\|x\\|_{2} \\leq 1,\n$$\n其中 $b = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0.001 \\end{pmatrix}$，二次矩阵有两种选择：$M = A$ 和 $M = P$。分别计算 $f_{A}$ 和 $f_{P}$ 的精确最优值 $v_{A}^{\\star}$ 和 $v_{P}^{\\star}$。然后构造标量\n$$\nS \\;=\\; \\|A - P\\|_{F}^{2} \\;+\\; \\big|\\, v_{A}^{\\star} - v_{P}^{\\star} \\,\\big|.\n$$\n\n请给出 $S$ 的精确值作为您的最终答案。如果您选择将 $S$ 写成小数，请确保它是精确的，无需四舍五入。您的最终答案必须是一个实数。",
            "solution": "该问题经检验具有科学依据、问题设定良好且客观。这是矩阵分析和优化中的一个标准问题。\n\n按照问题陈述的要求，解答分为三个部分。\n\n第一部分：推导到半正定锥上的投影。\n\n问题是对于给定的对称矩阵 $A \\in S^{n}$，求 $\\Pi_{\\mathcal{S}_{+}^{n}}(A) = \\arg\\min_{X \\in \\mathcal{S}_{+}^{n}} \\|X - A\\|_{F}^{2}$。我们有两个已知事实：\n(i) 实对称矩阵的谱定理：任意 $A \\in S^{n}$ 可分解为 $A = U \\Lambda U^{\\top}$，其中 $U \\in \\mathcal{O}(n)$ 是一个正交矩阵，其列是 $A$ 的特征向量，$\\Lambda = \\mathrm{diag}(\\lambda_1, \\dots, \\lambda_n)$ 是相应实特征值组成的对角矩阵。\n(ii) Frobenius 范数的正交不变性：对于任意 $X \\in S^{n}$ 和任意 $Q \\in \\mathcal{O}(n)$，有 $\\|Q^{\\top} X Q\\|_{F} = \\|X\\|_{F}$。\n\n我们首先将 $A$ 的谱分解代入目标函数：\n$$ \\|X - A\\|_{F}^{2} = \\|X - U \\Lambda U^{\\top}\\|_{F}^{2} $$\n利用范数对 $Q = U$ 的正交不变性，我们可以将范数内的表达式左乘 $U^{\\top}$ 右乘 $U$ 而不改变其值：\n$$ \\|X - U \\Lambda U^{\\top}\\|_{F}^{2} = \\|U^{\\top}(X - U \\Lambda U^{\\top})U\\|_{F}^{2} = \\|U^{\\top}XU - U^{\\top}U\\Lambda U^{\\top}U\\|_{F}^{2} = \\|U^{\\top}XU - \\Lambda\\|_{F}^{2} $$\n我们定义一个新变量 $\\tilde{X} = U^{\\top}XU$。由于 $U$ 是正交的，映射 $X \\mapsto \\tilde{X}$ 是从 $S^n$到 $S^n$ 的一个双射。我们必须检查约束条件 $X \\in \\mathcal{S}_{+}^{n}$ 如何变换。一个矩阵 $X$ 是半正定的，当且仅当其所有特征值都是非负的。由于 $\\tilde{X}$ 和 $X$ 是相似矩阵，它们具有相同的特征值。因此，$X \\succeq 0$ 当且仅当 $\\tilde{X} \\succeq 0$。因此，优化问题等价于：\n$$ \\min_{\\tilde{X} \\in \\mathcal{S}_{+}^{n}} \\|\\tilde{X} - \\Lambda\\|_{F}^{2} $$\nFrobenius 范数的平方是矩阵各元素平方之和。设 $\\tilde{X}_{ij}$ 是 $\\tilde{X}$ 的元素，$\\lambda_i$ 是 $\\Lambda$ 的对角元素。\n$$ \\|\\tilde{X} - \\Lambda\\|_{F}^{2} = \\sum_{i,j=1}^{n} (\\tilde{X}_{ij} - \\Lambda_{ij})^2 = \\sum_{i=1}^{n} (\\tilde{X}_{ii} - \\lambda_i)^2 + \\sum_{i \\neq j} \\tilde{X}_{ij}^2 $$\n为最小化这个非负项之和，我们可以独立地最小化它们。当 $\\tilde{X}_{ij} = 0$ 对所有 $i \\neq j$ 成立时，$\\sum_{i \\neq j} \\tilde{X}_{ij}^2$ 项被最小化。这意味着最优矩阵 $\\tilde{X}$ 必须是对角矩阵。\n设最优矩阵为 $\\tilde{X}^{\\star} = \\mathrm{diag}(d_1, d_2, \\dots, d_n)$。对于对角矩阵，半正定的条件简化为要求其所有对角元素为非负，即 $d_i \\ge 0$ 对所有 $i \\in \\{1, \\dots, n\\}$。\n因此，问题简化为求解 $n$ 个独立的标量最小化问题：\n$$ \\min_{d_i \\ge 0} (d_i - \\lambda_i)^2 \\quad \\text{对于 } i = 1, \\dots, n $$\n这是将实数 $\\lambda_i$ 投影到非负实数轴 $[0, \\infty)$ 上的问题。解是明确的：如果 $\\lambda_i \\ge 0$，则在 $d_i = \\lambda_i$ 处达到最小值。如果 $\\lambda_i  0$，则在 $d_i = 0$ 处达到最小值。这可以紧凑地写为 $d_i = \\max(0, \\lambda_i)$。\n我们记 $\\Lambda_+ = \\mathrm{diag}(\\max(0, \\lambda_1), \\dots, \\max(0, \\lambda_n))$。在变换后的坐标系中，解为 $\\tilde{X}^{\\star} = \\Lambda_+$。\n为了在原始坐标中找到解 $P = \\Pi_{\\mathcal{S}_{+}^{n}}(A)$，我们进行逆变换：\n$$ P = U \\tilde{X}^{\\star} U^{\\top} = U \\Lambda_+ U^{\\top} $$\n这个推导给出了投影的显式形式：对 $A$ 进行谱分解，将所有负特征值置为零，然后重构矩阵。\n\n第二部分：应用于特定矩阵 $A$。\n\n给定的矩阵是 $A = \\begin{pmatrix} 3  0  0 \\\\ 0  1  0 \\\\ 0  0  -0.1 \\end{pmatrix}$。\n这个矩阵已经是 diagonal，所以其谱分解是平凡的。特征向量是标准基向量，所以 $U = I$，即 $3 \\times 3$ 单位矩阵。特征值是对角元素：$\\lambda_1 = 3$，$\\lambda_2 = 1$，和 $\\lambda_3 = -0.1$。\n根据第一部分推导出的公式，我们通过取每个特征值的正部来构造矩阵 $\\Lambda_+$：\n$\\max(0, \\lambda_1) = \\max(0, 3) = 3$。\n$\\max(0, \\lambda_2) = \\max(0, 1) = 1$。\n$\\max(0, \\lambda_3) = \\max(0, -0.1) = 0$。\n所以，$\\Lambda_+ = \\begin{pmatrix} 3  0  0 \\\\ 0  1  0 \\\\ 0  0  0 \\end{pmatrix}$。\n投影是 $P = \\Pi_{\\mathcal{S}_{+}^{3}}(A) = U \\Lambda_+ U^{\\top} = I \\Lambda_+ I = \\Lambda_+$。\n$$ P = \\begin{pmatrix} 3  0  0 \\\\ 0  1  0 \\\\ 0  0  0 \\end{pmatrix} $$\n接下来，我们计算 Frobenius 投影误差 $\\|A - P\\|_{F}^{2}$。\n$$ A - P = \\begin{pmatrix} 3  0  0 \\\\ 0  1  0 \\\\ 0  0  -0.1 \\end{pmatrix} - \\begin{pmatrix} 3  0  0 \\\\ 0  1  0 \\\\ 0  0  0 \\end{pmatrix} = \\begin{pmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  -0.1 \\end{pmatrix} $$\nFrobenius 范数的平方是各元素平方之和：\n$$ \\|A - P\\|_{F}^{2} = (0)^2 + (0)^2 + \\dots + (-0.1)^2 = 0.01 $$\n\n第三部分：约束二次优化。\n\n我们需要对 $M=A$ 和 $M=P$ 求解 $\\min_{x \\in \\mathbb{R}^{3}, \\|x\\|_{2} \\leq 1} f_{M}(x) = \\frac{1}{2}\\, x^{\\top} M x + b^{\\top} x$，其中 $b = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0.001 \\end{pmatrix}$。\n\n情况 1：$M=A$。\n目标函数是 $f_{A}(x) = \\frac{1}{2} x^{\\top} A x + b^{\\top} x$。该二次函数的 Hessian 矩阵是 $A = \\mathrm{diag}(3, 1, -0.1)$。由于 $A$ 有一个负特征值（$-0.1$），$f_A(x)$ 是非凸的，其在单位球上的最小值必然位于边界上，即 $\\|x\\|_{2}=1$。\n这是一个信赖域子问题。Karush-Kuhn-Tucker (KKT) 条件指出，解 $x^{\\star}$ 必须满足 $(A + \\mu I)x^{\\star} = -b$，其中某个拉格朗日乘子 $\\mu \\ge 0$。二阶必要条件要求 $A + \\mu I \\succeq 0$。这意味着 $A+\\mu I$ 的所有特征值必须为非负：$3+\\mu \\ge 0$，$1+\\mu \\ge 0$ 和 $-0.1+\\mu \\ge 0$。对于 $\\mu \\ge 0$，其中最紧的约束是 $\\mu \\ge 0.1$。\n我们求解 $x$：$x = -(A+\\mu I)^{-1}b$。\n$$ x = -\\begin{pmatrix} (3+\\mu)^{-1}  0  0 \\\\ 0  (1+\\mu)^{-1}  0 \\\\ 0  0  (-0.1+\\mu)^{-1} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 0.001 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ -0.001 / (-0.1+\\mu) \\end{pmatrix} $$\n我们施加边界条件 $\\|x\\|_2=1$：\n$$ \\left( \\frac{-0.001}{-0.1+\\mu} \\right)^2 = 1 \\implies |-0.1+\\mu| = 0.001 $$\n因为我们要求 $\\mu \\ge 0.1$，所以必须有 $-0.1+\\mu > 0$。因此，$-0.1+\\mu = 0.001$，解得 $\\mu = 0.101$。该值满足条件 $\\mu \\ge 0.1$。\n最优解是 $x_A^{\\star} = \\begin{pmatrix} 0 \\\\ 0 \\\\ -0.001 / (-0.1+0.101) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ -1 \\end{pmatrix}$。\n最优值是 $v_{A}^{\\star} = f_{A}(x_A^{\\star})$：\n$$ v_{A}^{\\star} = \\frac{1}{2} (x_A^{\\star})^{\\top} A x_A^{\\star} + b^{\\top} x_A^{\\star} = \\frac{1}{2} \\begin{pmatrix} 0  0  -1 \\end{pmatrix} \\begin{pmatrix} 3  0  0 \\\\ 0  1  0 \\\\ 0  0  -0.1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ -1 \\end{pmatrix} + \\begin{pmatrix} 0  0  0.001 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ -1 \\end{pmatrix} $$\n$$ v_{A}^{\\star} = \\frac{1}{2}(-0.1) + (-0.001) = -0.05 - 0.001 = -0.051 $$\n\n情况 2：$M=P$。\n目标函数是 $f_{P}(x) = \\frac{1}{2} x^{\\top} P x + b^{\\top} x$。Hessian 矩阵是 $P = \\mathrm{diag}(3, 1, 0)$，它是半正定的。因此 $f_P(x)$ 是凸的，这是一个凸优化问题。\n$$ f_P(x) = \\frac{1}{2}(3x_1^2 + x_2^2) + 0.001x_3 $$\n我们想在 $x_1^2 + x_2^2 + x_3^2 \\le 1$ 的约束下最小化这个函数。为了最小化总和，我们应使非负的二次项部分尽可能小，这在 $x_1=0$ 和 $x_2=0$ 时实现。问题简化为在 $x_3^2 \\le 1$（即 $-1 \\le x_3 \\le 1$）的约束下最小化 $0.001x_3$。\n$0.001x_3$ 的最小值在 $x_3$ 取最负值时达到，所以 $x_3 = -1$。\n最优解是 $x_P^{\\star} = \\begin{pmatrix} 0 \\\\ 0 \\\\ -1 \\end{pmatrix}$。\n最优值是 $v_{P}^{\\star} = f_{P}(x_P^{\\star})$：\n$$ v_{P}^{\\star} = \\frac{1}{2} (0) + 0.001(-1) = -0.001 $$\n\n$S$ 的最终计算。\n题目要求我们计算 $S = \\|A - P\\|_{F}^{2} + |v_{A}^{\\star} - v_{P}^{\\star}|$。\n我们有 $\\|A - P\\|_{F}^{2} = 0.01$。\n我们有 $v_A^{\\star} = -0.051$ 和 $v_P^{\\star} = -0.001$。\n$$ |v_{A}^{\\star} - v_{P}^{\\star}| = |-0.051 - (-0.001)| = |-0.050| = 0.05 $$\n因此，\n$$ S = 0.01 + 0.05 = 0.06 $$\n这是一个精确的小数值。",
            "answer": "$$\\boxed{0.06}$$"
        }
    ]
}