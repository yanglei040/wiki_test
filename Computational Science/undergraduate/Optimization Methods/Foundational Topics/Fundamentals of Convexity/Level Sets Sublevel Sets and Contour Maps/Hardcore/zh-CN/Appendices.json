{
    "hands_on_practices": [
        {
            "introduction": "在优化中，函数等高线的几何形状会极大地影响算法的性能。这个练习使用一个看似简单的函数 $f(x,y)=x^2$ 来演示一个“平坦峡谷”的情形，梯度下降法在这种情况下会遇到困难。通过探索其等高线以及正则化方法带来的影响，我们可以直观地理解为什么重塑这些等高线对于实现高效优化至关重要。",
            "id": "3141941",
            "problem": "考虑函数 $f:\\mathbb{R}^2\\to\\mathbb{R}$，定义为 $f(x,y)=x^2$。仅使用水平集 $\\{(x,y):f(x,y)=c\\}$、次水平集 $\\{(x,y):f(x,y)\\le c\\}$（对于标量 $c\\in\\mathbb{R}$）的定义，以及梯度法中基于梯度的更新 $z_{k+1}=z_k-\\alpha\\nabla f(z_k)$（对于步长 $\\alpha0$），判断下列哪个陈述是正确的。同时考虑添加一个小的二次正则化项得到 $g(x,y)=x^2+\\varepsilon y^2$（其中 $\\varepsilon0$），以及一个绝对值（也称为 $\\ell_1$）正则化项得到 $h(x,y)=x^2+\\lambda |y|$（其中 $\\lambda0$）。\n\nA. 对于 $c0$，水平集 $\\{(x,y):f(x,y)=c\\}$ 由两条垂直线 $x=\\pm\\sqrt{c}$ 组成，对于 $c=0$，它是 $y$ 轴。\n\nB. 对于 $c\\ge 0$，次水平集 $\\{(x,y):f(x,y)\\le c\\}$ 是垂直带状区域 $\\{(x,y):|x|\\le \\sqrt{c}\\}$，它在 $y$ 方向上是无界的。\n\nC. 对于应用于 $f$ 的梯度下降法，使用任意固定的步长 $\\alpha0$ 以及任意起始点 $(x_0,y_0)$（其中 $y_0\\ne 0$），迭代点的 $y$ 分量会随着迭代发生变化并趋向于 $0$。\n\nD. 对于 $g(x,y)=x^2+\\varepsilon y^2$（其中 $\\varepsilon0$），对于 $c0$，每个等高线 $\\{(x,y):g(x,y)=c\\}$ 是一个椭圆，并且只要 $y\\ne 0$，梯度就有一个非零的 $y$ 分量，使得梯度法在合适的步长下能够将 $x$ 和 $y$ 都收缩到 $0$。\n\nE. 将 $y$ 的二次项替换为绝对值（$\\ell_1$）项，得到 $h(x,y)=x^2+\\lambda |y|$（其中 $\\lambda0$），会产生平滑的圆形等高线，以及对于每一个 $y$ 都有非零 $y$ 分量的梯度。",
            "solution": "问题陈述已经过验证，被认为是有效的。它在科学上基于多元微积分和优化理论，问题提法良好，客观且自洽。我们可以开始分析每个陈述。\n\n核心函数和定义如下：\n- $f(x,y) = x^2$\n- $g(x,y) = x^2 + \\varepsilon y^2$ for $\\varepsilon  0$\n- $h(x,y) = x^2 + \\lambda |y|$ for $\\lambda  0$\n- 水平集: $S_c = \\{(x,y) \\in \\mathbb{R}^2 : f(x,y) = c\\}$\n- 次水平集: $K_c = \\{(x,y) \\in \\mathbb{R}^2 : f(x,y) \\le c\\}$\n- 梯度下降: $z_{k+1} = z_k - \\alpha \\nabla f(z_k)$，其中 $z_k = (x_k, y_k)^T$ 且 $\\alpha  0$。\n\n**对陈述 A 的分析**\n\n这个陈述是关于函数 $f(x,y) = x^2$ 的水平集。水平集由方程 $f(x,y)=c$ 定义，其中 $c \\in \\mathbb{R}$ 是某个常数。在这里，该方程为 $x^2 = c$。\n\n- 情况1：$c  0$。方程 $x^2=c$ 对 $x$ 有两个实数解：$x = \\sqrt{c}$ 和 $x = -\\sqrt{c}$。由于该方程对变量 $y$ 没有限制，所以水平集包含所有 $x$ 为这两个值之一的点 $(x,y)$。这正是由方程 $x=\\sqrt{c}$ 和 $x=-\\sqrt{c}$ 定义的两条垂直线。陈述的这部分是正确的。\n- 情况2：$c = 0$。方程变为 $x^2=0$，其唯一解为 $x=0$。同样，$y$ 不受约束。点集 $\\{(x,y) : x=0\\}$ 是 $y$ 轴的定义。陈述的这部分也是正确的。\n- 情况3：$c  0$。方程 $x^2=c$ 没有实数解，所以水平集是空集 $\\emptyset$。该陈述没有讨论这种情况，但它对 $c \\ge 0$ 的陈述是准确的。\n\n关于 A 的结论：该陈述是对 $f(x,y)$ 在 $c \\ge 0$ 时的水平集的正确描述。\n**结论：正确**\n\n**对陈述 B 的分析**\n\n这个陈述是关于函数 $f(x,y) = x^2$ 的次水平集。次水平集由不等式 $f(x,y) \\le c$ 定义，其中 $c \\in \\mathbb{R}$ 是某个常数。该陈述考虑了 $c \\ge 0$ 的情况。不等式为 $x^2 \\le c$。\n\n因为 $c \\ge 0$，我们可以对两边取平方根。不等式 $\\sqrt{x^2} \\le \\sqrt{c}$ 等价于 $|x| \\le \\sqrt{c}$。这可以进一步展开为 $-\\sqrt{c} \\le x \\le \\sqrt{c}$。由于对 $y$ 没有约束，这个不等式定义了垂直线 $x=-\\sqrt{c}$ 和 $x=\\sqrt{c}$ 之间（包括边界）的区域。这个区域是一个在 $y$ 方向上无限延伸的垂直带状区域，即在 $y$ 方向上是无界的。陈述中的描述，“垂直带状区域 $\\{(x,y):|x|\\le \\sqrt{c}\\}$, 它在 $y$ 方向上是无界的”，是对这个集合的精确和正确的刻画。\n\n关于 B 的结论：该陈述是对 $f(x,y)$ 在 $c \\ge 0$ 时的次水平集的正确描述。\n**结论：正确**\n\n**对陈述 C 的分析**\n\n这个陈述是关于应用于函数 $f(x,y) = x^2$ 的梯度下降算法的行为。首先，我们计算 $f$ 的梯度：\n$$ \\nabla f(x,y) = \\begin{pmatrix} \\frac{\\partial f}{\\partial x} \\\\ \\frac{\\partial f}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} 2x \\\\ 0 \\end{pmatrix} $$\n对于点 $z_k = (x_k, y_k)^T$，梯度下降的更新规则是 $z_{k+1} = z_k - \\alpha \\nabla f(z_k)$。用分量形式表示为：\n$$ x_{k+1} = x_k - \\alpha (2x_k) = (1 - 2\\alpha)x_k $$\n$$ y_{k+1} = y_k - \\alpha (0) = y_k $$\n$y$ 分量的更新规则是 $y_{k+1} = y_k$。这意味着对于任何步长 $\\alpha$，$y$ 分量的值在所有迭代中都保持不变：$y_k = y_{k-1} = \\dots = y_0$。\n该陈述声称“迭代点的 $y$ 分量会随着迭代发生变化并趋向于 $0$”。我们的推导表明 $y$ 分量根本不发生变化。它始终固定在初始值 $y_0$。因此，该陈述是错误的。$y$ 分量无法向最小值（即 $y$ 轴上的任意点）移动是优化这个函数的一个关键特征。\n\n关于 C 的结论：该陈述错误地描述了 $y$ 分量的演变。\n**结论：错误**\n\n**对陈述 D 的分析**\n\n这个陈述分析了正则化函数 $g(x,y) = x^2 + \\varepsilon y^2$（其中 $\\varepsilon  0$）。\n\n- 等高线：等高线（水平集）由 $g(x,y) = c$ 给出，其中 $c$ 为常数。对于 $c  0$，方程为 $x^2 + \\varepsilon y^2 = c$。两边除以 $c$，我们得到：\n$$ \\frac{x^2}{c} + \\frac{y^2}{c/\\varepsilon} = 1 \\quad \\text{或} \\quad \\frac{x^2}{(\\sqrt{c})^2} + \\frac{y^2}{(\\sqrt{c/\\varepsilon})^2} = 1 $$\n这是中心在原点、半轴长度分别为 $\\sqrt{c}$ 和 $\\sqrt{c/\\varepsilon}$ 的椭圆的标准方程。陈述的第一部分是正确的。\n\n- 梯度：$g(x,y)$ 的梯度是：\n$$ \\nabla g(x,y) = \\begin{pmatrix} 2x \\\\ 2\\varepsilon y \\end{pmatrix} $$\n梯度的 $y$ 分量是 $2\\varepsilon y$。因为 $\\varepsilon  0$，所以只要 $y \\neq 0$，这个分量就是非零的。陈述的第二部分是正确的。\n\n- 梯度下降动力学：更新规则是：\n$$ x_{k+1} = x_k - \\alpha(2x_k) = (1 - 2\\alpha)x_k $$\n$$ y_{k+1} = y_k - \\alpha(2\\varepsilon y_k) = (1 - 2\\alpha\\varepsilon)y_k $$\n为了使迭代收缩到 $0$，我们需要 $|1 - 2\\alpha|  1$ 和 $|1 - 2\\alpha\\varepsilon|  1$。\n第一个不等式意味着 $-1  1 - 2\\alpha  1$，解得 $0  \\alpha  1$。\n第二个不等式意味着 $-1  1 - 2\\alpha\\varepsilon  1$，解得 $0  \\alpha  1/\\varepsilon$。\n存在一个满足这两个条件的“合适的步长” $\\alpha$。例如，任何满足 $0  \\alpha  \\min(1, 1/\\varepsilon)$ 的 $\\alpha$ 都会导致 $|x_k|$ 和 $|y_k|$ 几何级数地减小并趋向于 $0$（除非它们从 $0$ 开始）。因此，梯度法可以将 $x$ 和 $y$ 都收缩到 $0$。陈述的最后一部分是正确的。\n\n关于 D 的结论：陈述的所有部分都是正确的。\n**结论：正确**\n\n**对陈述 E 的分析**\n\n这个陈述分析了函数 $h(x,y) = x^2 + \\lambda |y|$（其中 $\\lambda  0$）。\n\n- 等高线：等高线由 $x^2 + \\lambda |y| = c$ 给出。我们来分析其形状。对于给定的 $c  0$：\n    - 如果 $y \\ge 0$，方程为 $y = (c - x^2)/\\lambda$，这是一个开口向下的抛物线。\n    - 如果 $y  0$，方程为 $y = (x^2 - c)/\\lambda$，这是一个开口向上的抛物线。\n等高线由这两段抛物线弧沿着 $x$ 轴（在 $y=0$ 处）连接而成。最终的形状显然不是圆形。此外，函数 $|y|$ 在 $y=0$ 处不可微，这会在 $y=0$ 且 $|x| \\le \\sqrt{c}$ 的线段上造成水平集的一个“折痕”或尖角。因此，等高线不是“平滑的”。声称它们是“平滑的圆形等高线”是错误的。\n\n- 梯度：函数 $h(x,y)$ 在任何 $y=0$ 的点上关于 $y$ 都不可微。\n    - 对于 $y \\neq 0$，关于 $y$ 的偏导数是 $\\frac{\\partial h}{\\partial y} = \\lambda \\, \\text{sgn}(y)$，其中 $\\text{sgn}(y)$ 在 $y>0$ 时为 $+1$，在 $y0$ 时为 $-1$。在这种情况下，梯度的 $y$ 分量是 $\\pm\\lambda$，这是非零的。\n    - 对于 $y=0$，梯度没有定义。在优化中，我们会使用次梯度的概念。$|y|$ 在 $y=0$ 处的次微分是区间 $[-1, 1]$。因此，$h(x,y)$ 在点 $(x,0)$ 处关于 $y$ 的次微分是区间 $[-\\lambda, \\lambda]$。这个集合包含 $0$。\n该陈述声称梯度“对于每一个 $y$”都有一个非零的 $y$ 分量。这是错误的，因为当 $y=0$ 时梯度没有定义。即使使用更广泛的次梯度概念，我们也可以看到 $0$ 是 $y=0$ 处次梯度 $y$ 分量的一个可能值。\n\n关于 E 的结论：该陈述在多个方面都是错误的。等高线既不平滑也不是圆形，并且梯度并非对所有 $y$ 都定义，更不用说具有一个普遍非零的 $y$ 分量了。\n**结论：错误**\n\n结论总结：\n- A：正确\n- B：正确\n- C：错误\n- D：正确\n- E：错误\n\n正确的陈述是 A、B 和 D。",
            "answer": "$$\\boxed{ABD}$$"
        },
        {
            "introduction": "许多现实世界中的优化问题涉及的函数并非处处光滑。本练习通过将两个简单的二次函数取最大值来构造一个此类函数，从而探讨了这种情况。分析其独特的“花生形”等高线有助于我们理解不可微的“折痕”是如何形成的，并可视化凸函数的关键属性，例如全局最小值的唯一性。",
            "id": "3141952",
            "problem": "考虑函数 $f:\\mathbb{R}^2\\rightarrow\\mathbb{R}$，其定义为 $f(x,y)=\\max\\{(x-1)^2+y^2,\\,(x+1)^2+y^2\\}$。仅使用水平集 $\\{(x,y)\\in\\mathbb{R}^2:\\,f(x,y)=c\\}$、次水平集 $\\{(x,y)\\in\\mathbb{R}^2:\\,f(x,y)\\le c\\}$、凸性和可微性的基本定义，来分析等高线（水平集）的几何形状、次水平集的结构、极小值点的位置和性质，以及与基于梯度的优化相关的任何吸引盆边界现象。选择所有正确的陈述。\n\nA. 对于任意 $c\\ge 1$，次水平集 $\\{(x,y):\\,f(x,y)\\le c\\}$ 正是两个半径为 $\\sqrt{c}$、分别以 $(1,0)$ 和 $(-1,0)$ 为中心的圆盘的交集，并且对于 $c1$ 该集合为空。\n\nB. 函数 $f$ 是凸函数，在 $(0,0)$ 处取得唯一的全局最小值，最小值为 $1$。\n\nC. 函数 $f$ 的不可微点集恰好是垂直线 $\\{(0,y):\\,y\\in\\mathbb{R}\\}$。\n\nD. 对于任意 $c1$，水平集 $\\{(x,y):\\,f(x,y)=c\\}$ 由两条圆弧（一条来自以 $(1,0)$ 为中心、半径为 $\\sqrt{c}$ 的圆，另一条来自以 $(-1,0)$ 为中心、半径为 $\\sqrt{c}$ 的圆）组成，它们在点 $(0,\\pm\\sqrt{c-1})$ 处相交，形成一个“花生形”的闭合曲线；对于 $c=1$，水平集是单点 $(0,0)$；对于 $c1$，该集合为空。\n\nE. 在 $\\mathbb{R}^2$ 中任意位置初始化的梯度下降法表现出两个由直线 $x=0$ 分隔的吸引盆，并收敛到 $(\\pm 1,0)$ 附近的两个不同的局部极小值点。",
            "solution": "用户希望我验证以下问题，如果问题有效，则解决它。\n\n### 第1步：提取已知条件\n-   函数：`$f:\\mathbb{R}^2\\rightarrow\\mathbb{R}$` 定义为 `$f(x,y)=\\max\\{(x-1)^2+y^2,\\,(x+1)^2+y^2\\}$`。\n-   任务：使用水平集、次水平集、凸性和可微性的基本定义来分析函数 `$f$`。分析应涵盖等高线的几何形状、次水平集的结构、极小值点的位置和性质，以及基于梯度的优化的吸引盆边界现象。\n\n### 第2步：使用提取的已知条件进行验证\n1.  **科学基础**：该问题基于标准的、明确定义的数学概念。函数 `$f(x,y)$` 是两个二次多项式（抛物面）的最大值，这是优化和分析中的常见构造。水平集、次水平集、凸性、可微性和梯度下降等概念都是数学和工程学中的基本主题。该问题在科学上和数学上都是合理的。\n2.  **适定性**：对于所有 `$(x,y) \\in \\mathbb{R}^2$`，函数 `$f(x,y)$` 都是良定义的。所提出的关于其性质的问题是精确的分析性问题，其答案是唯一的、可验证的。\n3.  **客观性**：该问题以客观的数学语言陈述，没有任何模糊性、主观性或观点。\n4.  **完整性**：函数 `$f(x,y)$` 的定义是完整的，足以进行所需的分析。\n5.  **一致性**：问题陈述中没有矛盾。\n\n### 第3步：结论与行动\n问题陈述是有效的。这是一个数学分析和优化理论中的适定问题。我现在将着手解答。\n\n### 函数分析\n\n让我们定义 `$f_1(x,y) = (x-1)^2+y^2$` 和 `$f_2(x,y) = (x+1)^2+y^2$`。函数由 `$f(x,y) = \\max\\{f_1(x,y), f_2(x,y)\\}$` 给出。从几何上看，`$f_1(x,y)$` 是点 `$(x,y)$` 到 `$(1,0)$` 的欧几里得距离的平方，而 `$f_2(x,y)$` 是点 `$(x,y)$` 到 `$(-1,0)$` 的欧几里得距离的平方。\n\n函数 `$f(x,y)$` 等于 `$f_1(x,y)$` 或 `$f_2(x,y)$`，这取决于点 `$(x,y)$` 离 `$(1,0)$` 和 `$(-1,0)$` 中的哪一个更远。距离相等的点集是连接 `$(-1,0)$` 和 `$(1,0)$` 的线段的垂直平分线。这条垂直平分线就是直线 `$x=0$`。\n\n让我们用代数方法验证这一点：\n`$$f_1(x,y) = f_2(x,y)$$`\n`$$(x-1)^2+y^2 = (x+1)^2+y^2$$`\n`$$x^2 - 2x + 1 = x^2 + 2x + 1$$`\n`$$-2x = 2x \\implies 4x = 0 \\implies x=0$$`\n\n-   如果 `$x>0$`，点 `$(x,y)$` 离 `$(1,0)$` 比离 `$(-1,0)$` 更近。因此，到 `$(-1,0)$` 的距离更大，意味着 `$f_2(x,y) > f_1(x,y)$`。所以，`$f(x,y) = f_2(x,y) = (x+1)^2+y^2$`。\n-   如果 `$x0$`，点 `$(x,y)$` 离 `$(1,0)$` 比离 `$(-1,0)$` 更远。因此，`$f_1(x,y) > f_2(x,y)$`。所以，`$f(x,y) = f_1(x,y) = (x-1)^2+y^2$`。\n-   如果 `$x=0$`，`$f_1(0,y) = f_2(0,y) = 1+y^2$`。\n\n所以，该函数可以分段表示为：\n`$$ f(x,y) = \\begin{cases} (x-1)^2+y^2  \\text{if } x  0 \\\\ 1+y^2  \\text{if } x = 0 \\\\ (x+1)^2+y^2  \\text{if } x > 0 \\end{cases} $$`\n这可以更紧凑地写成：\n`$$ f(x,y) = \\begin{cases} (x-1)^2+y^2  \\text{if } x \\le 0 \\\\ (x+1)^2+y^2  \\text{if } x > 0 \\end{cases} $$`\n（将等号 `$x=0$` 放在哪一边是任意的）。\n\n### 逐项分析\n\n**A. 对于任意 `$c \\ge 1$`，次水平集 `$\\{(x,y):\\,f(x,y)\\le c\\}$` 正是两个半径为 `$\\sqrt{c}$`、分别以 `$(1,0)`` 和 `$(−1,0)$` 为中心的圆盘的交集，并且对于 `$c1$` 该集合为空。**\n\n次水平集 `$S_c$` 定义为 `$\\{(x,y) \\in \\mathbb{R}^2 : f(x,y) \\le c\\}$`。\n根据 `$f$` 的定义，这等价于 `$\\max\\{f_1(x,y), f_2(x,y)\\} \\le c$`。\n这个不等式成立当且仅当 `$f_1(x,y) \\le c$` 和 `$f_2(x,y) \\le c$` 都满足。\n1.  `$f_1(x,y) \\le c \\iff (x-1)^2+y^2 \\le c$`。这个不等式定义了一个以 `$(1,0)$` 为中心、半径为 `$\\sqrt{c}$` 的闭圆盘 `$D_1$`，前提是 `$c \\ge 0$`。\n2.  `$f_2(x,y) \\le c \\iff (x+1)^2+y^2 \\le c$`。这个不等式定义了一个以 `$(-1,0)$` 为中心、半径为 `$\\sqrt{c}$` 的闭圆盘 `$D_2$`，前提是 `$c \\ge 0$`。\n因此，次水平集 `$S_c$` 是这两个圆盘的交集：`$S_c = D_1 \\cap D_2$`。\n\n现在，我们必须找到 `$f(x,y)$` 的最小值。该函数是非负的。\n-   对于 `$x \\ge 0$`，`$f(x,y) = (x+1)^2+y^2$`。当 `$x \\ge 0$` 时，这个表达式的最小值在 `$x$` 和 `$y$` 尽可能小的时候出现，即 `$(x,y) \\to (0,0)$`。其值为 `$f(0,0) = (0+1)^2+0^2 = 1$`。\n-   对于 `$x \\le 0$`，`$f(x,y) = (x-1)^2+y^2$`。当 `$x \\le 0$` 时，这个表达式的最小值也出现在 `$(x,y) \\to (0,0)$`。其值为 `$f(0,0) = (0-1)^2+0^2 = 1$`。\n`$f(x,y)$` 的全局最小值是 `1`，在 `$(0,0)`` 处取得。\n这意味着对于任意 `$c1$`，不存在 `$(x,y)$` 使得 `$f(x,y) \\le c$`。因此，对于 `$c1$`，次水平集 `$S_c$` 为空。对于 `$c \\ge 1$`，该集合非空。\n\n该陈述断言，对于 `$c \\ge 1$`，次水平集是两个圆盘的交集，而对于 `$c1$` 它为空。我们的分析证实了此陈述的两个部分。\n\n结论：**正确**。\n\n**B. 函数 `$f$` 是凸函数，在 `$(0,0)$` 处取得唯一的全局最小值，最小值为 `$1$`。**\n\n首先，我们来分析凸性。函数 `$f_1(x,y) = (x-1)^2+y^2$` 和 `$f_2(x,y) = (x+1)^2+y^2$` 是凸函数。这可以通过检查它们的Hessian矩阵来验证。对于这两个函数，Hessian矩阵都是 `$\\begin{pmatrix} 2  0 \\\\ 0  2 \\end{pmatrix}$`，它处处是正定的。凸分析的一个基本定理指出，一组凸函数的逐点最大值也是一个凸函数。由于 `$f = \\max\\{f_1, f_2\\}$`，且 `$f_1, f_2$` 是凸的，所以 `$f$` 也是凸的。\n\n接下来，我们来分析最小值。正如在选项A的分析中确定的那样，`$f$` 的最小值是 `$1$`，并且在 `$(0,0)$` 处取得。为了检查这个最小值是否唯一，我们可以考察函数在 `$(0,0)$` 之外的行为。\n如果 `$(x,y) \\ne (0,0)$`：\n-   如果 `$x \\ge 0$`，`$f(x,y)=(x+1)^2+y^2$`。由于 `$(x,y) \\ne (0,0)`` 且 `$x \\ge 0$`，我们要么有 `$x>0$` 要么有 `$y \\ne 0$`（或两者都有）。如果 `$x>0$`，那么 `$(x+1)^2 > 1$`，所以 `$f(x,y) > 1$`。如果 `$x=0$` 且 `$y \\ne 0$`，那么 `$f(0,y) = 1+y^2 > 1$`。\n-   如果 `$x  0$`，`$f(x,y)=(x-1)^2+y^2$`。由于 `$x0$`，`$x-1  -1$`，所以 `$(x-1)^2 > 1$`，这意味着 `$f(x,y) > 1$`。\n在所有 `$(x,y) \\ne (0,0)$` 的情况下，我们都有 `$f(x,y) > 1 = f(0,0)$`。因此，`$(0,0)$` 是唯一的全局最小值点。\n\n该陈述正确地指出 `$f$` 是凸函数，并准确地描述了其唯一的全局最小值。\n\n结论：**正确**。\n\n**C. 函数 `$f$` 的不可微点集恰好是垂直线 `$\\{(0,y):\\,y\\in\\mathbb{R}\\}$`。**\n\n一个定义为两个可微函数 `$f=\\max\\{f_1, f_2\\}$` 的最大值的函数，在所有 `$f_1(z) \\ne f_2(z)$` 的点 `$z$` 处是可微的。在 `$f_1(z_0) = f_2(z_0)$` 的点 `$z_0$` 处，函数 `$f$` 可微当且仅当 `$\\nabla f_1(z_0) = \\nabla f_2(z_0)$`。否则，它就是不可微的。\n\n我们已经确定 `$f_1(x,y) = f_2(x,y)$` 恰好在直线 `$x=0$` 上成立。\n让我们计算 `$f_1$` 和 `$f_2$` 的梯度：\n`$\\nabla f_1(x,y) = [2(x-1), 2y]^T$`\n`$\\nabla f_2(x,y) = [2(x+1), 2y]^T$`\n\n现在我们在直线 `$x=0$` 上，对任意点 `$(0,y)`` 计算这些梯度：\n`$\\nabla f_1(0,y) = [-2, 2y]^T$`\n`$\\nabla f_2(0,y) = [2, 2y]^T$`\n\n为了使 `$f$` 在 `$(0,y)$` 处可微，我们需要 `$\\nabla f_1(0,y) = \\nabla f_2(0,y)$`。这将要求 `$-2 = 2$`，这是不成立的。因此，在直线 `$x=0$` 上的任何点，梯度都绝不相等。\n因此，函数 `$f$` 在任何点 `$(0,y)`` (其中 `$y \\in \\mathbb{R}$`) 都是不可微的。\n对于任何 `$x \\ne 0$` 的点，`$f$` 等于 `$f_1$` 或 `$f_2$`，它们都是多项式，因此是无限可微的。\n所以，不可微点集恰好是直线 `$x=0$`。\n\n结论：**正确**。\n\n**D. 对于任意 `$c>1$`，水平集 `$\\{(x,y):\\,f(x,y)=c\\}$` 由两条圆弧（一条来自以 `$(1,0)$` 为中心、半径为 `$\\sqrt{c}$` 的圆，另一条来自以 `$(−1,0)$` 为中心、半径为 `$\\sqrt{c}$` 的圆）组成，它们在点 `$(0,\\pm\\sqrt{c-1})$` 处相交，形成一个“花生形”的闭合曲线；对于 `$c=1$` 水平集是单点 `$(0,0)$`；对于 `$c1$` 它为空。**\n\n令 `$L_c = \\{(x,y) : f(x,y)=c\\}$`。\n-   **情况 `$c1$**：由于 `$\\min f(x,y) = 1$`，`$L_c$` 是空集。这部分是正确的。\n-   **情况 `$c=1$**：由于 `$(0,0)$` 是值为 `$1$` 的唯一全局最小值点，`$f(x,y)=1$` 当且仅当 `$(x,y)=(0,0)$`。所以 `$L_1 = \\{(0,0)\\}$`。这部分是正确的。\n-   **情况 `$c>1$**：一个点 `$(x,y)$` 在 `$L_c$` 中，如果 `$\\max\\{f_1(x,y), f_2(x,y)\\} = c$`。\n    -   考虑 `$x \\ge 0$` 的点。对于这些点，`$f(x,y) = f_2(x,y) = (x+1)^2+y^2$`。水平集条件是 `$(x+1)^2+y^2 = c$`。这是一个以 `$(-1,0)$` 为中心、半径为 `$\\sqrt{c}$` 的圆的方程。我们被限制在区域 `$x \\ge 0$` 中，所以这部分水平集是这个圆的一段圆弧。\n    -   考虑 `$x  0$` 的点。对于这些点，`$f(x,y) = f_1(x,y) = (x-1)^2+y^2$`。水平集条件是 `$(x-1)^2+y^2 = c$`。这是一个以 `$(1,0)$` 为中心、半径为 `$\\sqrt{c}$` 的圆的方程。我们被限制在区域 `$x  0$` 中，所以这部分水平集是这个圆的一段圆弧。\n    -   这两条弧在边界线 `$x=0$` 处相遇。为了找到交点，我们在任一方程中设 `$x=0$`（例如，在 `$(x+1)^2+y^2=c$` 中）：\n        `$(0+1)^2+y^2 = c \\implies 1+y^2=c \\implies y^2 = c-1 \\implies y = \\pm\\sqrt{c-1}`。\n        由于我们处于 `$c>1$` 的情况，`$c-1 > 0$`，所以这是两个不同的实数点，`$(0, \\sqrt{c-1})$` 和 `$(0, -\\sqrt{c-1})$`。\n    选项中提供的描述与此推导完全匹配。该曲线由来自不同圆的两条弧形成，在指定的点相遇。\n\n结论：**正确**。\n\n**E. 在 `$\\mathbb{R}^2$` 中任意位置初始化的梯度下降法表现出两个由直线 `$x=0$` 分隔的吸引盆，并收敛到 `$(\\pm 1,0)$` 附近的两个不同的局部极小值点。**\n\n这个陈述声称存在多个局部极小值点和相应的吸引盆。\n根据我们在选项B中的分析，我们知道 `$f$` 是一个凸函数。凸函数的一个关键性质是任何局部极小值也是全局极小值。我们发现 `$f$` 在 `$(0,0)$` 处有一个**唯一的全局最小值**。因此，不存在其他局部极小值点。点 `$(\\pm 1, 0)$` 不是 `$f$` 的极小值点。例如，`$f(1,0) = \\max\\{(1-1)^2+0^2, (1+1)^2+0^2\\} = \\max\\{0,4\\}=4$`，这显然不是最小值 `$1$`。\n\n对于具有唯一最小值的凸函数，一个正确配置的梯度下降（或对于不可微函数，次梯度下降）算法保证会收敛到该唯一最小值，无论起始点在哪里。这意味着整个空间 `$\\mathbb{R}^2$` 构成了全局最小值点 `$(0,0)$` 的单个吸引盆。\n\n因此，该陈述关于两个吸引盆和不同局部极小值点的说法是根本不正确的。梯度下降的行为总是朝向唯一的全局极小值点 `$(0,0)$` 移动。例如，如果从 `$x_0 > 0$` 开始，负梯度 `$-\\nabla f(x_0,y_0) = -[2(x_0+1), 2y_0]^T$` 指向减小 `$x$` 和 `$y$` 的方向。如果从 `$x_00$` 开始，负梯度 `$-\\nabla f(x_0,y_0) = -[2(x_0-1), 2y_0]^T$` 指向增大 `$x$`（因为 `$x_0-1$` 是负数）和减小 `$y$` 的方向。在这两种情况下，轨迹都被驱动向直线 `$x=0$`，并最终到达原点 `$(0,0)`。\n\n结论：**不正确**。",
            "answer": "$$\\boxed{ABCD}$$"
        },
        {
            "introduction": "基于我们对拉长的等高线会减慢优化速度的理解，本练习将采取一种更为主动的方法。我们将学习如何设计一个线性变换——这种技术被称为预处理——来将这些等高线重塑为更均匀、更接近圆形的形状。通过将一个高度各向异性的二次函数转换为各向同性的函数，我们可以直接看到坐标变换如何从根本上改善问题的几何结构，从而更好地应用梯度下降法。",
            "id": "3141910",
            "problem": "考虑二次连续可微函数 $f:\\mathbb{R}^{2}\\to\\mathbb{R}$，其定义为 $f(\\mathbf{x})=\\frac{1}{2}\\,\\mathbf{x}^{\\top}\\mathbf{H}\\,\\mathbf{x}$，其中 $\\mathbf{H}$ 是对称正定矩阵\n$$\n\\mathbf{H}=\\mathbf{R}(\\theta)^{\\top}\\begin{pmatrix}9  0 \\\\ 0  1\\end{pmatrix}\\mathbf{R}(\\theta),\n$$\n且 $\\mathbf{R}(\\theta)$ 是旋转矩阵\n$$\n\\mathbf{R}(\\theta)=\\begin{pmatrix}\\cos(\\theta)  -\\sin(\\theta) \\\\ \\sin(\\theta)  \\cos(\\theta)\\end{pmatrix}\n$$\n其中 $\\theta=\\frac{\\pi}{6}$。一个线性重参数化 $ \\mathbf{y}=\\mathbf{T}\\mathbf{x} $ 导出一个变换后的函数 $g(\\mathbf{y})=f(\\mathbf{T}^{-1}\\mathbf{y})$。仅使用水平集、线性变换和欧几里得范数的基本定义，分析 $g$ 的水平集如何依赖于 $\\mathbf{T}$ 和 $\\mathbf{H}$。然后，设计一个可逆线性映射 $\\mathbf{T}$，在欧几里得几何中尽可能地减少 $g$ 的水平集的各向异性，即最小化 $g$ 的海森矩阵的条件数（最大与最小特征值之比）。\n\n你的最终任务是，在你设计的 $\\mathbf{T}$ 下，以精确形式计算 $g$ 的海森矩阵的条件数。将你的最终答案表示为单个实数。无需四舍五入。",
            "solution": "用户要求我解决以下问题：\n考虑二次连续可微函数 $f:\\mathbb{R}^{2}\\to\\mathbb{R}$，其定义为 $f(\\mathbf{x})=\\frac{1}{2}\\,\\mathbf{x}^{\\top}\\mathbf{H}\\,\\mathbf{x}$，其中 $\\mathbf{H}$ 是对称正定矩阵\n$$\n\\mathbf{H}=\\mathbf{R}(\\theta)^{\\top}\\begin{pmatrix}9  0 \\\\ 0  1\\end{pmatrix}\\mathbf{R}(\\theta),\n$$\n且 $\\mathbf{R}(\\theta)$ 是旋转矩阵\n$$\n\\mathbf{R}(\\theta)=\\begin{pmatrix}\\cos(\\theta)  -\\sin(\\theta) \\\\ \\sin(\\theta)  \\cos(\\theta)\\end{pmatrix}\n$$\n其中 $\\theta=\\frac{\\pi}{6}$。一个线性重参数化 $ \\mathbf{y}=\\mathbf{T}\\mathbf{x} $ 导出一个变换后的函数 $g(\\mathbf{y})=f(\\mathbf{T}^{-1}\\mathbf{y})$。仅使用水平集、线性变换和欧几里得范数的基本定义，分析 $g$ 的水平集如何依赖于 $\\mathbf{T}$ 和 $\\mathbf{H}$。然后，设计一个可逆线性映射 $\\mathbf{T}$，在欧几里得几何中尽可能地减少 $g$ 的水平集的各向异性，即最小化 $g$ 的海森矩阵的条件数（最大与最小特征值之比）。\n\n你的最终任务是，在你设计的 $\\mathbf{T}$ 下，以精确形式计算 $g$ 的海森矩阵的条件数。将你的最终答案表示为单个实数。无需四舍五入。\n\n### 步骤1：提取已知条件\n-   函数 $f: \\mathbb{R}^{2} \\to \\mathbb{R}$ 定义为 $f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^{\\top}\\mathbf{H}\\mathbf{x}$。\n-   矩阵 $\\mathbf{H}$ 是一个对称正定矩阵，由 $\\mathbf{H} = \\mathbf{R}(\\theta)^{\\top} \\mathbf{D} \\mathbf{R}(\\theta)$ 给出，其中 $\\mathbf{D} = \\begin{pmatrix} 9  0 \\\\ 0  1 \\end{pmatrix}$。\n-   矩阵 $\\mathbf{R}(\\theta)$ 是一个旋转矩阵 $\\mathbf{R}(\\theta) = \\begin{pmatrix} \\cos(\\theta)  -\\sin(\\theta) \\\\ \\sin(\\theta)  \\cos(\\theta) \\end{pmatrix}$。\n-   旋转角为 $\\theta = \\frac{\\pi}{6}$。\n-   线性重参数化由 $\\mathbf{y} = \\mathbf{T}\\mathbf{x}$ 给出，其中 $\\mathbf{T}$ 是一个可逆矩阵。\n-   变换后的函数 $g: \\mathbb{R}^{2} \\to \\mathbb{R}$ 定义为 $g(\\mathbf{y}) = f(\\mathbf{T}^{-1}\\mathbf{y})$。\n-   目标是设计 $\\mathbf{T}$ 以最小化 $g$ 的海森矩阵的条件数。\n-   最终输出应该是可达到的最小条件数。\n\n### 步骤2：使用提取的已知条件进行验证\n问题在数学上是良定义的且内部一致。\n-   **科学依据**：问题植根于线性代数、多变量微积分和数值优化的标准概念，特别涉及二次型、水平集、海森矩阵和条件数。矩阵 $\\mathbf{D}$ 的对角线元素（9和1）为正，使其成为正定矩阵。由于 $\\mathbf{R}(\\theta)$ 是一个正交矩阵，矩阵 $\\mathbf{H}$ 也是对称正定的，因为它与 $\\mathbf{D}$ 正交相似。它的特征值与 $\\mathbf{D}$ 的特征值相同，即9和1。所有定义都是标准且正确的。\n-   **良定性**：问题要求设计一个变换 $\\mathbf{T}$ 来最小化一个良定义的量（海森矩阵的条件数）。最优解存在且在不改变条件数的某些变换下是唯一的。任务是找到这个最小化的条件数的值，它是一个唯一的实数。\n-   **目标**：语言精确，没有主观性。术语“各向异性”与条件数正式关联，为优化提供了清晰的量化标准。\n-   **完整性**：问题提供了推导解决方案所需的所有必要信息。所有矩阵和函数都已完全指定。\n\n问题没有表现出任何无效性缺陷。在优化方法的背景下，这是一个有效且可解的问题。\n\n### 步骤3：结论与行动\n问题有效。我将继续提供完整的解决方案。\n\n***\n\n函数 $f(\\mathbf{x})$ 是一个二次型，其海森矩阵为 $\\nabla^2 f(\\mathbf{x}) = \\mathbf{H}$。$f$ 的水平集由方程 $f(\\mathbf{x}) = c$ 给出（其中 $c  0$ 为某个常数），这等价于 $\\frac{1}{2}\\mathbf{x}^{\\top}\\mathbf{H}\\mathbf{x} = c$。这些水平集是以原点为中心的椭圆。这些椭圆的形状和方向由 $\\mathbf{H}$ 的特征值和特征向量决定。\n\n$\\mathbf{H} = \\mathbf{R}(\\theta)^{\\top}\\mathbf{D}\\mathbf{R}(\\theta)$ 的结构是其谱分解，其中 $\\mathbf{D} = \\begin{pmatrix} 9  0 \\\\ 0  1 \\end{pmatrix}$ 是特征值对角矩阵，$\\mathbf{R}(\\theta)^{\\top}$ 的列是对应的特征向量。$\\mathbf{H}$ 的特征值为 $\\lambda_{\\max}(\\mathbf{H}) = 9$ 和 $\\lambda_{\\min}(\\mathbf{H}) = 1$。$\\mathbf{H}$ 的条件数由其最大与最小特征值之比给出：\n$$\n\\kappa(\\mathbf{H}) = \\frac{\\lambda_{\\max}(\\mathbf{H})}{\\lambda_{\\min}(\\mathbf{H})} = \\frac{9}{1} = 9.\n$$\n这个条件数量化了 $f$ 的水平集的各向异性。$\\kappa(\\mathbf{H})  1$ 的值表示水平集是拉伸的椭圆而不是圆形。椭圆主半轴的长度之比为 $\\sqrt{\\kappa(\\mathbf{H})} = \\sqrt{9} = 3$。\n\n接下来，我们分析变换后的函数 $g(\\mathbf{y})$。重参数化为 $\\mathbf{y} = \\mathbf{T}\\mathbf{x}$，由于 $\\mathbf{T}$ 是可逆的，这意味着 $\\mathbf{x} = \\mathbf{T}^{-1}\\mathbf{y}$。将此代入 $f$ 的定义，得到 $g$ 的表达式：\n$$\ng(\\mathbf{y}) = f(\\mathbf{T}^{-1}\\mathbf{y}) = \\frac{1}{2}(\\mathbf{T}^{-1}\\mathbf{y})^{\\top}\\mathbf{H}(\\mathbf{T}^{-1}\\mathbf{y}) = \\frac{1}{2}\\mathbf{y}^{\\top}(\\mathbf{T}^{-1})^{\\top}\\mathbf{H}\\mathbf{T}^{-1}\\mathbf{y}.\n$$\n这表明 $g(\\mathbf{y})$ 也是一个二次型。其海森矩阵，我们记作 $\\mathbf{H}_g$，为：\n$$\n\\mathbf{H}_g = \\nabla^2 g(\\mathbf{y}) = (\\mathbf{T}^{-1})^{\\top}\\mathbf{H}\\mathbf{T}^{-1}.\n$$\n问题要求设计可逆线性映射 $\\mathbf{T}$，以尽可能减少 $g$ 的水平集的各向异性。这等价于最小化 $g$ 的海森矩阵的条件数 $\\kappa(\\mathbf{H}_g)$。任何对称正定矩阵的条件数总是大于或等于1。可能的最小值为 $\\kappa(\\mathbf{H}_g) = 1$，这当且仅当 $\\mathbf{H}_g$ 的所有特征值都相等时才会出现。这意味着 $\\mathbf{H}_g$ 必须是单位矩阵的标量倍数，即 $\\mathbf{H}_g = \\alpha\\mathbf{I}$，其中 $\\alpha  0$ 为某个标量。\n\n我们的设计目标是找到一个 $\\mathbf{T}$ 使得 $\\mathbf{H}_g = \\alpha\\mathbf{I}$。我们选择最简单的情况，即 $\\alpha=1$，因此我们的目标是找到 $\\mathbf{T}$ 使得 $\\mathbf{H}_g = \\mathbf{I}$。\n$$\n(\\mathbf{T}^{-1})^{\\top}\\mathbf{H}\\mathbf{T}^{-1} = \\mathbf{I}.\n$$\n从左边乘以 $\\mathbf{T}^{\\top}$，从右边乘以 $\\mathbf{T}$，我们得到：\n$$\n\\mathbf{H} = \\mathbf{T}^{\\top}\\mathbf{T}.\n$$\n这个方程表明我们需要找到 $\\mathbf{H}$ 的一个矩阵“平方根”。由于 $\\mathbf{H}$ 是对称正定的，这样的矩阵 $\\mathbf{T}$ 是存在的。一个常见且构造性的选择是 $\\mathbf{H}$ 的主平方根，记作 $\\mathbf{H}^{1/2}$。主平方根是唯一的、对称的且正定的。\n\n使用 $\\mathbf{H}$ 的谱分解 $\\mathbf{H} = \\mathbf{R}(\\theta)^{\\top}\\mathbf{D}\\mathbf{R}(\\theta)$，我们可以将 $\\mathbf{H}^{1/2}$ 定义为：\n$$\n\\mathbf{H}^{1/2} = \\mathbf{R}(\\theta)^{\\top}\\mathbf{D}^{1/2}\\mathbf{R}(\\theta),\n$$\n其中 $\\mathbf{D}^{1/2} = \\begin{pmatrix} \\sqrt{9}  0 \\\\ 0  \\sqrt{1} \\end{pmatrix} = \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix}$。\n我们将变换矩阵 $\\mathbf{T}$ 设计为这个主平方根，即 $\\mathbf{T} = \\mathbf{H}^{1/2}$。由于 $\\mathbf{H}^{1/2}$ 是对称的，所以 $\\mathbf{T}^{\\top} = (\\mathbf{H}^{1/2})^{\\top} = \\mathbf{H}^{1/2} = \\mathbf{T}$。\n然后，我们验证条件 $\\mathbf{H} = \\mathbf{T}^{\\top}\\mathbf{T}$：\n$$\n\\mathbf{T}^{\\top}\\mathbf{T} = (\\mathbf{H}^{1/2})^{\\top}\\mathbf{H}^{1/2} = \\mathbf{H}^{1/2}\\mathbf{H}^{1/2} = (\\mathbf{R}(\\theta)^{\\top}\\mathbf{D}^{1/2}\\mathbf{R}(\\theta))(\\mathbf{R}(\\theta)^{\\top}\\mathbf{D}^{1/2}\\mathbf{R}(\\theta)).\n$$\n由于 $\\mathbf{R}(\\theta)$ 是一个正交矩阵，$\\mathbf{R}(\\theta)\\mathbf{R}(\\theta)^{\\top} = \\mathbf{I}$。该表达式简化为：\n$$\n\\mathbf{T}^{\\top}\\mathbf{T} = \\mathbf{R}(\\theta)^{\\top}\\mathbf{D}^{1/2}(\\mathbf{R}(\\theta)\\mathbf{R}(\\theta)^{\\top})\\mathbf{D}^{1/2}\\mathbf{R}(\\theta) = \\mathbf{R}(\\theta)^{\\top}\\mathbf{D}^{1/2}\\mathbf{I}\\mathbf{D}^{1/2}\\mathbf{R}(\\theta) = \\mathbf{R}(\\theta)^{\\top}(\\mathbf{D}^{1/2})^2\\mathbf{R}(\\theta) = \\mathbf{R}(\\theta)^{\\top}\\mathbf{D}\\mathbf{R}(\\theta) = \\mathbf{H}.\n$$\n因此，选择 $\\mathbf{T} = \\mathbf{H}^{1/2}$ 是一个有效的设计。现在我们计算在此 $\\mathbf{T}$ 的选择下的海森矩阵 $\\mathbf{H}_g$。\n$$\n\\mathbf{H}_g = (\\mathbf{T}^{-1})^{\\top}\\mathbf{H}\\mathbf{T}^{-1} = ((\\mathbf{H}^{1/2})^{-1})^{\\top}\\mathbf{H}(\\mathbf{H}^{1/2})^{-1}.\n$$\n由于 $\\mathbf{H}^{1/2}$ 是对称的，它的逆 $(\\mathbf{H}^{1/2})^{-1}$ 也是对称的。因此，$((\\mathbf{H}^{1/2})^{-1})^{\\top} = (\\mathbf{H}^{1/2})^{-1}$。\n$$\n\\mathbf{H}_g = (\\mathbf{H}^{1/2})^{-1}\\mathbf{H}(\\mathbf{H}^{1/2})^{-1} = (\\mathbf{H}^{1/2})^{-1}(\\mathbf{H}^{1/2}\\mathbf{H}^{1/2})(\\mathbf{H}^{1/2})^{-1}.\n$$\n根据矩阵乘法的结合律：\n$$\n\\mathbf{H}_g = ((\\mathbf{H}^{1/2})^{-1}\\mathbf{H}^{1/2})(\\mathbf{H}^{1/2}(\\mathbf{H}^{1/2})^{-1}) = \\mathbf{I} \\cdot \\mathbf{I} = \\mathbf{I}.\n$$\n变换后函数 $g$ 的海森矩阵是单位矩阵 $\\mathbf{I}$。单位矩阵的特征值都等于1。\n因此，对于这个设计的变换 $\\mathbf{T}$，$\\mathbf{H}_g$ 的特征值为 $\\lambda_{\\max}(\\mathbf{H}_g) = 1$ 和 $\\lambda_{\\min}(\\mathbf{H}_g) = 1$。\n$g$ 的海森矩阵的条件数为：\n$$\n\\kappa(\\mathbf{H}_g) = \\frac{\\lambda_{\\max}(\\mathbf{H}_g)}{\\lambda_{\\min}(\\mathbf{H}_g)} = \\frac{1}{1} = 1.\n$$\n这是正定矩阵可能的最小条件数，因此我们设计的变换 $\\mathbf{T} = \\mathbf{H}^{1/2}$ 最优地减少了各向异性，使得 $g$ 的水平集成为正圆形。$\\theta=\\frac{\\pi}{6}$ 的具体值对于最终的数值答案来说是不需要的，因为最优的重参数化能适应任何旋转。",
            "answer": "$$\n\\boxed{1}\n$$"
        }
    ]
}