{
    "hands_on_practices": [
        {
            "introduction": "当我们思考一个函数的最小值时，我们常常会直觉地认为它是在一个单点上取到的。然而，最优解并不总是唯一的。这个练习  提供了一个直观的例子，展示了函数 $f(x,y)=x^2y^2$ 在一个正方形区域上的最小值并非在一个孤立点，而是在一个构成十字交叉形状的连续点集上达到的。通过解决这个问题，你将把一个简单的代数条件与一个二维几何对象联系起来，从而加深对 $\\operatorname{argmin}$ 是一个*集合*这一核心概念的理解。",
            "id": "3098641",
            "problem": "设 $f:\\mathbb{R}^{2}\\to\\mathbb{R}$ 定义为 $f(x,y)=x^{2}y^{2}$，可行集为闭合正方形 $D=[-1,1]^{2}=\\{(x,y)\\in\\mathbb{R}^{2}:-1\\leq x\\leq 1,\\,-1\\leq y\\leq 1\\}$。仅使用优化理论的核心定义，确定 $f$ 在 $D$ 上的 $\\operatorname{argmin}$ 集合，并基于第一性原理阐释其在 $D$ 内的几何形状。然后，计算该 $\\operatorname{argmin}$ 集合的一维欧几里得总长度，其长度理解为构成它的所有线段的长度之和，交叉点只计算一次。将最终答案表示为一个精确的数。",
            "solution": "用户想解决以下问题：设 $f:\\mathbb{R}^{2}\\to\\mathbb{R}$ 定义为 $f(x,y)=x^{2}y^{2}$，可行集为闭合正方形 $D=[-1,1]^{2}=\\{(x,y)\\in\\mathbb{R}^{2}:-1\\leq x\\leq 1,\\,-1\\leq y\\leq 1\\}$。仅使用优化理论的核心定义，确定 $f$ 在 $D$ 上的 $\\operatorname{argmin}$ 集合，并基于第一性原理阐释其在 $D$ 内的几何形状。然后，计算该 $\\operatorname{argmin}$ 集合的一维欧几里得总长度，其长度理解为构成它的所有线段的长度之和，交叉点只计算一次。将最终答案表示为一个精确的数。\n\n这是一个有效的优化问题。它自成体系，具有数学和科学基础，并且是适定的。函数 $f(x,y) = x^2 y^2$ 在紧集 $D = [-1,1]^2$ 上是连续的，因此根据极值定理，全局最小值存在。问题要求找到达到该最小值的点集（$\\operatorname{argmin}$ 集合）及其几何性质，这些都是明确定义的数学任务。所有提供的信息都清晰、一致，并且足以得出一个唯一解。\n\n我们首先回顾 $\\operatorname{argmin}$ 集合的正式定义。对于定义在集合 $D$ 上的函数 $f$，$f$ 在 $D$ 上的 $\\operatorname{argmin}$ 是 $D$ 中使得 $f$ 达到其最小值的点的集合。设 $m = \\min_{(x,y) \\in D} f(x,y)$。那么，我们记为 $S^*$ 的 $\\operatorname{argmin}$ 集合由下式给出：\n$$S^* = \\operatorname{argmin}_{(x,y) \\in D} f(x,y) = \\{(x,y) \\in D \\mid f(x,y) = m\\}$$\n\n第一步是确定函数 $f(x,y) = x^2y^2$ 在可行集 $D = [-1,1]^2$ 上的最小值 $m$。该函数可以写成 $f(x,y) = (xy)^2$。对于任意实数 $x$ 和 $y$，项 $x^2$ 和 $y^2$ 都是非负的。也就是说，$x^2 \\geq 0$ 且 $y^2 \\geq 0$。因此，它们的乘积 $f(x,y) = x^2y^2$ 对所有 $(x,y) \\in \\mathbb{R}^2$ 也必须是非负的，因此对所有 $(x,y) \\in D$ 也是非负的。\n$$f(x,y) = x^2y^2 \\geq 0$$\n一个非负函数能取的最低可能值是 $0$。我们必须验证在定义域 $D$ 内的某个点 $(x,y)$，函数 $f(x,y)$ 是否能达到这个值。条件 $f(x,y) = 0$ 等价于：\n$$x^2y^2 = 0$$\n这个方程成立当且仅当 $x^2 = 0$ 或 $y^2 = 0$，可以简化为 $x=0$ 或 $y=0$。\n\n所以，函数 $f(x,y)$ 在至少一个坐标为零的任意点 $(x,y)$ 处达到值 $0$。既然我们已经确定对于所有点 $f(x,y) \\geq 0$，并且在 $D$ 内可以达到值 $0$（例如，在点 $(0,0) \\in D$ 处，$f(0,0)=0$），那么 $f$ 在 $D$ 上的全局最小值是 $m=0$。\n\n现在我们可以确定 $\\operatorname{argmin}$ 集合 $S^*$。这是定义域 $D$ 中所有满足 $f(x,y)=0$ 的点 $(x,y)$ 的集合。\n$$S^* = \\{(x,y) \\in D \\mid f(x,y) = 0\\}$$\n如上所述，这个条件当且仅当 $x=0$ 或 $y=0$ 时满足。所以，我们在寻找正方形 $D = [-1,1]^2$ 中 $x$ 坐标或 $y$ 坐标等于零的点的集合。\n$$S^* = \\{(x,y) \\in [-1,1]^2 \\mid x=0 \\text{ 或 } y=0\\}$$\n这个集合可以表示为两个子集的并集：\n1.  $x=0$ 的点集：$S_x = \\{(0,y) \\mid -1 \\leq y \\leq 1\\}$。\n2.  $y=0$ 的点集：$S_y = \\{(x,0) \\mid -1 \\leq x \\leq 1\\}$。\n所以，$\\operatorname{argmin}$ 集合是 $S^* = S_x \\cup S_y$。\n\n接下来，我们解释这个集合的几何形状。定义域 $D$ 是一个以原点为中心、边长为 $2$ 的正方形。集合 $S_x$ 是 $y$ 轴上从点 $(0,-1)$ 到 $(0,1)$ 的垂直线段。集合 $S_y$ 是 $x$ 轴上从点 $(-1,0)$ 到 $(1,0)$ 的水平线段。这两个线段的并集 $S^*$ 形成一个以原点为中心的“+”字形，其臂延伸到正方形 $D$ 的边界。这两条线段相交于原点 $(0,0)$。\n\n最后，我们计算集合 $S^*$ 的一维欧几里得总长度。问题指定要求将线段的长度相加，交叉点只计算一次。集合 $S^*$ 是线段 $S_x$ 和线段 $S_y$ 的并集。\n从 $(0,-1)$ 到 $(0,1)$ 的垂直线段 $S_x$ 的长度是其端点之间的欧几里得距离：\n$$L_x = \\sqrt{(0-0)^2 + (1 - (-1))^2} = \\sqrt{0^2 + 2^2} = 2$$\n从 $(-1,0)$ 到 $(1,0)$ 的水平线段 $S_y$ 的长度是：\n$$L_y = \\sqrt{(1 - (-1))^2 + (0 - 0)^2} = \\sqrt{2^2 + 0^2} = 2$$\n两个集合的并集的总长度是它们各自长度之和减去它们交集的长度。两个线段的交集是 $x=0$ 和 $y=0$ 同时成立的单一点：\n$$S_x \\cap S_y = \\{(0,0)\\}$$\n一个单点的一维测度（长度）为 $0$。因此，$S^*$ 的总长度 $L$ 为：\n$$L = L_x + L_y - \\text{Length}(S_x \\cap S_y) = 2 + 2 - 0 = 4$$\n或者，我们可以将这个十字形看作由四条长度为 $1$ 的不同线段组成，它们都在原点相交：从 $(-1,0)$ 到 $(0,0)$ 的线段，从 $(0,0)$ 到 $(1,0)$ 的线段，从 $(0,-1)$ 到 $(0,0)$ 的线段，以及从 $(0,0)$ 到 $(0,1)$ 的线段。它们的长度之和为 $1+1+1+1 = 4$。两种方法都得到相同的结果。总长度为 $4$。",
            "answer": "$$\n\\boxed{4}\n$$"
        },
        {
            "introduction": "在机器学习和统计学等许多应用中，我们常常需要在一个约束集合内优化某个函数。这个练习  将探讨一个深刻的问题：约束集的“形状”如何从根本上改变解集的性质。通过对比在由 $\\ell_1$ 范数和 $\\ell_2$ 范数定义的两种不同几何约束下最大化同一个线性函数 $a^{\\top}x$，你将亲手揭示为什么 $\\ell_1$ 约束倾向于产生“稀疏”解——这是现代数据科学中一个极其重要的特性。",
            "id": "3098617",
            "problem": "设 $n \\in \\mathbb{N}$ 且 $a \\in \\mathbb{R}^{n}$ 为一个非零向量。考虑在两个不同的单位球上最大化同一个线性泛函的两个优化问题：\n- $A_1 \\coloneqq \\operatorname{argmax}\\{a^{\\top}x : \\|x\\|_1 \\leq 1\\}$,\n- $A_2 \\coloneqq \\operatorname{argmax}\\{a^{\\top}x : \\|x\\|_2 \\leq 1\\}$,\n其中 $\\|\\cdot\\|_1$ 表示 $\\ell_1$ 范数，$\\|\\cdot\\|_2$ 表示欧几里得范数。\n\n仅从 $\\operatorname{argmax}$、$\\ell_1$ 和 $\\ell_2$ 范数的定义、三角不等式以及柯西-施瓦茨不等式出发，确定集合 $A_1$ 和 $A_2$ 的确切形式，并指出它们的仿射维数（即包含每个集合的最小仿射子空间的维数）。令 $M \\coloneqq \\max_{1 \\leq i \\leq n} |a_i|$ 和 $J \\coloneqq \\{i \\in \\{1,\\dots,n\\} : |a_i| = M\\}$，并记 $k \\coloneqq |J|$。因为 $a \\neq 0$，所以我们假设 $k \\geq 1$。\n\n以 $k$ 的函数形式，计算量 $\\Delta \\coloneqq \\dim(A_1) - \\dim(A_2)$ 的闭式解。你的最终答案必须是关于 $k$ 的单个解析表达式。无需四舍五入。",
            "solution": "我们首先回顾将要使用的定义和基本不等式。对于一个集合 $S \\subset \\mathbb{R}^{n}$ 和一个函数 $f : \\mathbb{R}^{n} \\to \\mathbb{R}$，$\\operatorname{argmax}_{x \\in S} f(x)$ 表示集合 $S$ 中使得 $f$ 在 $S$ 上达到其最大值的点 $x$ 的集合。$\\ell_{1}$ 范数是 $\\|x\\|_{1} = \\sum_{i=1}^{n} |x_{i}|$，$\\ell_{2}$ 范数是 $\\|x\\|_{2} = \\left(\\sum_{i=1}^{n} x_{i}^{2}\\right)^{1/2}$。我们将使用三角不等式 $|u+v| \\leq |u| + |v|$ 和柯西-施瓦茨不等式 $|u^{\\top}v| \\leq \\|u\\|_{2}\\|v\\|_{2}$，以及基本界 $\\sum_{i=1}^{n} |a_{i}||x_{i}| \\leq \\left(\\max_{i} |a_{i}|\\right)\\sum_{i=1}^{n} |x_{i}|$。\n\n我们分别分析这两个问题，然后比较得到的 argmax 集合。\n\n第 $1$ 步：在 $\\ell_{2}$ 约束下对 $A_{2}$ 进行刻画。对任意满足 $\\|x\\|_{2} \\leq 1$ 的 $x$，应用柯西-施瓦茨不等式：\n$$\na^{\\top}x \\leq \\|a\\|_{2}\\|x\\|_{2} \\leq \\|a\\|_{2}.\n$$\n因此，最优值至多为 $\\|a\\|_{2}$。柯西-施瓦茨不等式中的等号成立当且仅当 $x$ 是 $a$ 的标量倍数，即对于某个 $\\lambda \\in \\mathbb{R}$，有 $x = \\lambda a$。为了同时满足 $\\|x\\|_{2} \\leq 1$ 并达到上界 $\\|a\\|_{2}$，我们需要 $\\|x\\|_{2} = 1$ 且 $a^{\\top}x = \\|a\\|_{2}\\|x\\|_{2} = \\|a\\|_{2}$。这要求 $x$ 与 $a$ 方向相同，即 $x = a/\\|a\\|_{2}$。因此，\n$$\nA_{2} = \\left\\{\\frac{a}{\\|a\\|_{2}}\\right\\}.\n$$\n该集合是一个单点集，所以其仿射维数为 $0$，即 $\\dim(A_{2}) = 0$。\n\n第 $2$ 步：在 $\\ell_{1}$ 约束下对 $A_{1}$ 进行刻画。对任意满足 $\\|x\\|_{1} \\leq 1$ 的 $x$，我们有如下界：\n$$\na^{\\top}x = \\sum_{i=1}^{n} a_{i} x_{i} \\leq \\sum_{i=1}^{n} |a_{i}||x_{i}| \\leq \\left(\\max_{1 \\leq i \\leq n} |a_{i}|\\right) \\sum_{i=1}^{n} |x_{i}| \\leq M.\n$$\n因此，最优值至多为 $M$。我们现在刻画不等式链中等号同时成立的条件：\n- 对于第一个不等式，我们要求对每个 $i$ 都有 $a_{i}x_{i} = |a_{i}||x_{i}|$，这等价于 $x_{i}$ 与 $a_{i}$ 同号（或 $x_{i} = 0$）。\n- 对于第二个不等式，我们要求只要 $|x_{i}|  0$，就必须有 $|a_{i}| = M$；也就是说，$x$ 的支撑集必须包含在 $J = \\{i : |a_{i}| = M\\}$ 中。\n- 对于第三个不等式，我们需要 $\\|x\\|_{1} = 1$。\n\n结合这些条件，等号成立的情况恰好是满足以下条件的 $x \\in \\mathbb{R}^{n}$ 的集合：\n$$\nx_{i} = 0 \\text{ (对于 } i \\notin J),\\quad x_{i} \\text{ 的符号为 } \\operatorname{sign}(a_{i}) \\text{ (对于 } i \\in J),\\quad \\sum_{i \\in J} |x_{i}| = 1.\n$$\n等价地，令 $t_{i} \\coloneqq |x_{i}| \\geq 0$ (对于 $i \\in J$)，条件变为\n$$\n\\sum_{i \\in J} t_{i} = 1,\\quad t_{i} \\geq 0 \\text{ (对于每个 } i \\in J),\n$$\n其中对于 $i \\in J$ 有 $x_{i} = \\operatorname{sign}(a_{i})\\,t_{i}$，对于 $i \\notin J$ 有 $x_{i} = 0$。集合 $\\{t \\in \\mathbb{R}^{k}_{\\ge 0} : \\sum_{i \\in J} t_{i} = 1\\}$ 是一个 $k-1$ 维的标准单纯形，而将 $t$ 映射到 $x$（即赋予固定符号并嵌入到 $\\mathbb{R}^{n}$ 中）的映射是到 $A_{1}$ 上的一个仿射同构。因此，\n$$\n\\dim(A_{1}) = k - 1.\n$$\n\n第 $3$ 步：计算仿射维数之差。根据以上结果，\n$$\n\\Delta \\coloneqq \\dim(A_{1}) - \\dim(A_{2}) = (k - 1) - 0 = k - 1.\n$$\n此公式对任何满足 $k = |J| \\geq 1$ 的非零向量 $a$ 都有效。在 $k=1$ 的特殊情况下，两个 argmax 集合都是单点集，且 $\\Delta = 0$；当 $k  1$ 时，$\\ell_{1}$ 的 argmax 集合是一个 $(k-1)$ 维的面，而 $\\ell_{2}$ 的 argmax 集合仍然是一个单点，从而得到所推导出的 $\\Delta = k-1$。",
            "answer": "$$\\boxed{k-1}$$"
        },
        {
            "introduction": "知道 $\\operatorname{argmin}$ 集合的存在是一回事，而通过算法找到它则是另一回事。这个动手编程练习  将让你探索一个标准优化算法——梯度下降法——在处理一个不满足常见理论假设的函数时的行为。通过在函数 $f(x)=\\sqrt{|x|}$ 上实现并观察梯度下降，你将直接看到一个“陡峭”的函数如何导致算法步长过大，在最小值附近剧烈振荡而无法平稳收敛。这个练习为你连接理论性质（如 Lipschitz 连续性）与实际算法性能（如收敛行为）提供了一座至关重要的桥梁。",
            "id": "3098631",
            "problem": "考虑函数 $f:\\mathbb{R}\\to\\mathbb{R}$，其定义为 $f(x)=\\sqrt{|x|}$。本题旨在分析其 $\\operatorname{argmin}$ 集合和 $\\varepsilon$-近似-$\\operatorname{argmin}$ 集合，验证其正则性性质，并经验性地展示梯度下降（GD）方法对于一个非 Lipschitz 函数如何在非平凡的近似-$\\operatorname{argmin}$ 区域内外徘徊。仅使用下面指定的基本定义和性质。\n\n需要使用的基本定义：\n- $f$ 的 $\\operatorname{argmin}$ 集合为 $\\operatorname{argmin} f := \\{x\\in\\mathbb{R} : f(x) = \\inf_{y\\in\\mathbb{R}} f(y)\\}$。\n- $\\varepsilon$-近似-$\\operatorname{argmin}$ 集合（也称为 $\\varepsilon$-近似最小化子集合）为 $A_{\\varepsilon} := \\{x\\in\\mathbb{R} : f(x) \\le \\inf_{y\\in\\mathbb{R}} f(y) + \\varepsilon \\}$，对于任意 $\\varepsilon  0$。\n- 如果对于所有 $x,y\\in\\mathbb{R}$，都有 $|f(x)-f(y)| \\le L|x-y|$ 成立，则称函数 $f$ 是 Lipschitz 连续的，其中常数 $L0$。\n- 具有固定步长 $\\alpha0$ 的梯度下降（GD）在梯度存在时更新 $x_{k+1} := x_k - \\alpha \\nabla f(x_k)$；如果某一点的梯度不存在，为避免迭代未定义，本次模拟中取 $\\nabla f(0):=0$。\n\n任务：\n1. 从第一性原理证明 $f(x)=\\sqrt{|x|}$ 有一个唯一的最小化子，确定 $\\operatorname{argmin} f$，并验证 $f$ 在 $x=0$ 的任何邻域上都不是 Lipschitz 连续的。\n2. 对一般的 $\\varepsilon0$ 显式地刻画 $A_{\\varepsilon}$，并用 $\\varepsilon$ 表示其宽度。\n3. 对函数 $f$ 实现梯度下降法，在导数存在的地方使用它：对于 $x\\neq 0$，使用 $\\nabla f(x)=\\frac{1}{2}\\frac{\\operatorname{sign}(x)}{\\sqrt{|x|}}$，对于 $x=0$，设置 $\\nabla f(0):=0$。运行迭代 $x_{k+1} := x_k - \\alpha \\nabla f(x_k)$，其中 $k=0,1,\\dots,N-1$。\n4. 对每次模拟，计算以下量化指标：\n   - $x$ 域中 $A_{\\varepsilon}$ 的宽度，即区间 $A_{\\varepsilon}$ 的长度。\n   - 在 $A_{\\varepsilon}$ 内部的迭代点比例，定义为 $\\frac{1}{N}\\sum_{k=0}^{N-1} \\mathbf{1}\\{|x_k|\\le \\varepsilon^2\\}$，其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n   - $A_{\\varepsilon}$ 的边界穿越次数，定义为迭代序列 $\\{x_k\\}_{k=0}^{N-1}$ 中成员资格在 $A_{\\varepsilon}$ 内外切换的次数（即序列在 $A_{\\varepsilon}$ 内部和外部之间切换了多少次）。\n   - $\\{x_k\\}$ 中的符号变化次数，定义为满足 $\\operatorname{sign}(x_{k}) \\ne \\operatorname{sign}(x_{k-1})$ 的索引 $k$ 的总数，约定 $\\operatorname{sign}(0):=0$。\n5. 使用以下测试套件，其设计旨在覆盖一般行为和边界情况：\n   - 测试 1（理想路径，中等步长）：$(x_0,\\alpha,\\varepsilon,N) = (1.0,\\,0.2,\\,0.1,\\,200)$。\n   - 测试 2（较小步长）：$(x_0,\\alpha,\\varepsilon,N) = (1.0,\\,0.02,\\,0.1,\\,200)$。\n   - 测试 3（从最小化子开始）：$(x_0,\\alpha,\\varepsilon,N) = (0.0,\\,0.2,\\,0.1,\\,200)$。\n   - 测试 4（近零初始值，中等步长）：$(x_0,\\alpha,\\varepsilon,N) = (10^{-6},\\,0.2,\\,0.1,\\,200)$。\n\n最终输出规范：\n- 对于每个测试用例，你的程序必须输出一个列表 $[w,\\rho,c,s]$，其中 $w$ 是 $A_{\\varepsilon}$ 的宽度（浮点数），$\\rho$ 是内部迭代点比例（浮点数），$c$ 是边界穿越次数（整数），$s$ 是符号变化次数（整数）。\n- 你的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表，其中按顺序列出四个测试用例的结果。例如，输出格式必须类似于 $[[w_1,\\rho_1,c_1,s_1],[w_2,\\rho_2,c_2,s_2],[w_3,\\rho_3,c_3,s_3],[w_4,\\rho_4,c_4,s_4]]$。\n- 本问题不涉及物理单位或角度单位。所有输出均为指定类型的实值浮点数或整数。",
            "solution": "问题陈述已经过评估，被认为是有效的。它在科学上基于实分析和优化理论，具有所有必要的定义和参数，问题设定良好，并且其表述是客观的。因此，我们可以进行完整的解答。\n\n该问题要求对函数 $f(x) = \\sqrt{|x|}$ 进行多部分分析，重点是其最小化性质以及应用于其上的梯度下降（GD）算法的行为。该函数是一个非光滑、非 Lipschitz 目标函数的典型例子，对标准优化方法构成了挑战。\n\n### 第 1 部分：最小化子和 Lipschitz 连续性分析\n\n首先，我们证明 $f(x)=\\sqrt{|x|}$ 有一个唯一的最小化子，并确定 $\\operatorname{argmin}$ 集合。$f$ 的定义域是 $\\mathbb{R}$。绝对值函数 $|x|$ 总是非负的，即对所有 $x \\in \\mathbb{R}$，有 $|x| \\ge 0$。平方根函数对于非负输入是单调递增的。因此，$f(x) = \\sqrt{|x|} \\ge \\sqrt{0} = 0$。$f(x)$ 的最小可能值为 0。\n\n函数的下确界是 $\\inf_{y\\in\\mathbb{R}} f(y) = 0$。我们现在确定达到该下确界的点集。这就是 $\\operatorname{argmin}$ 集合：\n$$ \\operatorname{argmin} f = \\{x\\in\\mathbb{R} : f(x) = 0\\} $$\n$$ f(x) = 0 \\iff \\sqrt{|x|} = 0 \\iff |x| = 0 \\iff x = 0 $$\n因此，最小化子是唯一的，位于 $x=0$。\n$$ \\operatorname{argmin} f = \\{0\\} $$\n\n接下来，我们验证 $f$ 在 $x=0$ 的任何邻域上都不是 Lipschitz 连续的。如果存在一个常数 $L0$，使得对于集合 $S \\subseteq \\mathbb{R}$ 中的所有 $x, y$，不等式 $|f(x)-f(y)| \\le L|x-y|$ 都成立，则称函数 $f$ 在该集合上是 Lipschitz 连续的。\n让我们考虑 0 的任意邻域，比如 $(-\\delta, \\delta)$，其中 $\\delta  0$。为了证明 $f$ 在此邻域上不是 Lipschitz 的，我们必须证明对于 $x, y \\in (-\\delta, \\delta)$，比率 $\\frac{|f(x)-f(y)|}{|x-y|}$ 是无界的。\n我们选择 $y=0$ 和 $x \\in (0, \\delta)$。\n那么 $f(y) = f(0) = 0$ 且 $f(x) = \\sqrt{x}$。该比率变为：\n$$ \\frac{|f(x)-f(0)|}{|x-0|} = \\frac{|\\sqrt{x}-0|}{|x-0|} = \\frac{\\sqrt{x}}{x} = \\frac{1}{\\sqrt{x}} $$\n当我们让 $x$ 从正方向趋近于 0（$x \\to 0^+$）时，这个比率 $\\frac{1}{\\sqrt{x}}$ 的值趋于无穷大。由于这个比率在任何区间 $(0, \\delta)$ 上都是无界的，因此找不到有限的 Lipschitz 常数 $L$ 来满足在 0 的任何邻域内所有点上的定义。因此，$f(x)=\\sqrt{|x|}$ 在 $x=0$ 的任何邻域上都不是 Lipschitz 连续的。\n\n### 第 2 部分：$\\varepsilon$-近似-$\\operatorname{argmin}$ 集合的刻画\n\n$\\varepsilon$-近似-$\\operatorname{argmin}$ 集合 $A_{\\varepsilon}$ 定义为：\n$$ A_{\\varepsilon} := \\{x\\in\\mathbb{R} : f(x) \\le \\inf_{y\\in\\mathbb{R}} f(y) + \\varepsilon \\} $$\n从第 1 部分可知，$\\inf_{y\\in\\mathbb{R}} f(y) = 0$。将其代入定义可得：\n$$ A_{\\varepsilon} = \\{x\\in\\mathbb{R} : \\sqrt{|x|} \\le \\varepsilon \\} $$\n由于 $\\varepsilon  0$ 且 $\\sqrt{|x|} \\ge 0$，我们可以对不等式两边进行平方而不改变其方向：\n$$ |x| \\le \\varepsilon^2 $$\n这个不等式等价于区间 $[-\\varepsilon^2, \\varepsilon^2]$。因此，该集合的显式刻画为：\n$$ A_{\\varepsilon} = [-\\varepsilon^2, \\varepsilon^2] $$\n$A_{\\varepsilon}$ 的宽度是该区间的长度，计算方式为其端点之差：\n$$ w = \\varepsilon^2 - (-\\varepsilon^2) = 2\\varepsilon^2 $$\n这证实了问题陈述中用于计算 $A_\\varepsilon$ 内部迭代点比例的条件 $\\{|x_k|\\le \\varepsilon^2\\}$ 确实是 $A_\\varepsilon$ 成员资格的正确条件。\n\n### 第 3 部分：梯度下降模拟分析\n\n梯度下降（GD）的更新规则是 $x_{k+1} := x_k - \\alpha \\nabla f(x_k)$。对于 $x \\neq 0$，$f(x)=\\sqrt{|x|}$ 的梯度是 $\\nabla f(x) = \\frac{d}{dx} \\sqrt{|x|} = \\frac{\\operatorname{sign}(x)}{2\\sqrt{|x|}}$。问题指定在模拟中使用 $\\nabla f(0) := 0$。这个选择是一个有效的次梯度，因为 $f$ 在 $x=0$ 处的次微分是 $\\partial f(0)=\\mathbb{R}$。\n\n$\\nabla f(x)$ 的关键特征是其大小 $|\\nabla f(x)| = \\frac{1}{2\\sqrt{|x|}}$ 在 $x \\to 0$ 时趋于无穷大。这违反了梯度下降收敛的标准条件，该条件要求梯度是 Lipschitz 连续的（即变化率有界）。这种无界性导致当迭代点 $x_k$ 靠近最小化子 $x=0$ 时，算法会采取极大的步长。\n\n梯度下降的更新可以分段写为：\n$$ x_{k+1} = \\begin{cases} x_k - \\alpha \\frac{1}{2\\sqrt{x_k}}  \\text{若 } x_k  0 \\\\ x_k - \\alpha \\frac{-1}{2\\sqrt{-x_k}}  \\text{若 } x_k  0 \\\\ 0  \\text{若 } x_k = 0 \\end{cases} $$\n如果一个迭代点恰好落在 $x=0$ 上，它将在所有后续迭代中保持不变。然而，由于浮点数运算的性质和更新规则，仅当起始点为 $x_0=0$ 时才能保证这一点。\n\n当一个迭代点 $x_k$ 很小但非零时（即在 $A_\\varepsilon$ 内部），项 $\\frac{\\alpha}{2\\sqrt{|x_k|}}$ 会变得非常大。下一个迭代点 $x_{k+1}$ 将约等于 $-\\alpha \\nabla f(x_k)$，导致一个大的跳跃，越过位于 $x=0$ 的最小值，并落在原点另一侧很远的地方。这导致了“徘徊”行为，即迭代序列反复进入小的邻域 $A_\\varepsilon$ 后又立即被弹出。这将表现为 $A_\\varepsilon$ 的高边界穿越次数和序列 $\\{x_k\\}$ 中的高符号变化次数。\n\n- **测试 1 ($x_0=1.0, \\alpha=0.2, \\varepsilon=0.1, N=200$)**：对于相对较大的步长 $\\alpha$，过冲现象将非常明显。我们预计只有一小部分迭代点会留在 $A_\\varepsilon$ 内部，并且会有大量的边界穿越和符号变化。\n- **测试 2 ($x_0=1.0, \\alpha=0.02, \\varepsilon=0.1, N=200$)**：步长小了十倍。步长大小 $\\alpha |\\nabla f(x_k)|$ 会更小，导致更小的过冲。迭代点仍会徘徊，但不会那么剧烈。与测试 1 相比，我们预计在 $A_\\varepsilon$ 内部的迭代点比例会更高，穿越和符号变化的次数会更少。\n- **测试 3 ($x_0=0.0, \\alpha=0.2, \\varepsilon=0.1, N=200$)**：起始点是最小化子。由于我们定义了 $\\nabla f(0)=0$，第一次更新为 $x_1 = 0 - \\alpha \\cdot 0 = 0$。所有后续迭代点都将是 0。因此，所有迭代点都将在 $A_\\varepsilon$ 内部，边界穿越次数和符号变化次数都为零。\n- **测试 4 ($x_0=10^{-6}, \\alpha=0.2, \\varepsilon=0.1, N=200$)**：起始点非常接近 0，并且在 $A_\\varepsilon = [-0.01, 0.01]$ 内部。梯度大小 $|\\nabla f(10^{-6})|$ 将会巨大（约 500）。更新步长将是巨大的，导致剧烈的过冲。这个案例将最清楚地展示不稳定性，表现为（在第一个迭代点之后）$A_\\varepsilon$ 内部的迭代点比例非常低，以及大量的穿越和符号变化。\n\n这些理论预期将通过最终答案中实现的数值模拟得到证实。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by running Gradient Descent simulations\n    for the function f(x) = sqrt(|x|) and calculating specified metrics.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (x_0, alpha, epsilon, N)\n        (1.0, 0.2, 0.1, 200),\n        (1.0, 0.02, 0.1, 200),\n        (0.0, 0.2, 0.1, 200),\n        (1e-6, 0.2, 0.1, 200),\n    ]\n\n    results = []\n    for x0, alpha, epsilon, N in test_cases:\n        # --- Run Gradient Descent Simulation ---\n        x_iterates = np.zeros(N, dtype=np.float64)\n        x_iterates[0] = x0\n\n        for k in range(N - 1):\n            x_k = x_iterates[k]\n            \n            # Calculate gradient based on the problem's definition\n            if x_k == 0.0:\n                grad_f = 0.0\n            else:\n                grad_f = np.sign(x_k) / (2.0 * np.sqrt(np.abs(x_k)))\n\n            # Update rule for Gradient Descent\n            x_k_plus_1 = x_k - alpha * grad_f\n            x_iterates[k + 1] = x_k_plus_1\n            \n        # --- Compute Quantitative Indicators ---\n\n        # 1. Width of A_epsilon\n        # A_epsilon is the interval [-epsilon^2, epsilon^2]\n        # Width w = epsilon^2 - (-epsilon^2) = 2 * epsilon^2\n        w = 2.0 * epsilon**2\n\n        # 2. Fraction of iterates inside A_epsilon\n        # The condition for being inside A_epsilon is |x_k| = epsilon^2\n        is_inside = np.abs(x_iterates) = epsilon**2\n        rho = np.mean(is_inside)\n\n        # 3. Number of boundary crossings of A_epsilon\n        # A crossing occurs if an iterate is inside and the next is outside, or vice versa.\n        # This is equivalent to checking where the 'is_inside' status toggles.\n        # We compare element k with element k-1 for k=1...N-1.\n        crossings = np.sum(is_inside[1:] != is_inside[:-1])\n        c = int(crossings)\n        \n        # 4. Number of sign changes in {x_k}\n        # A sign change occurs if sign(x_k) != sign(x_{k-1})\n        # np.sign(0) is 0, which correctly handles iterates that are exactly zero.\n        signs = np.sign(x_iterates)\n        sign_changes = np.sum(signs[1:] != signs[:-1])\n        s = int(sign_changes)\n\n        # Append the results for the current test case\n        results.append([w, rho, c, s])\n\n    # Final print statement in the exact required format.\n    # The map(str, results) ensures each inner list is converted to its string representation.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}