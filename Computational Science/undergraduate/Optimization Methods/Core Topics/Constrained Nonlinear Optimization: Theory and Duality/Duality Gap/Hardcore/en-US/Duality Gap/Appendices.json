{
    "hands_on_practices": [
        {
            "introduction": "In convex optimization, we often benefit from strong duality, where the optimal values of the primal and dual problems are equal, resulting in a zero duality gap. This powerful property, however, relies on certain \"constraint qualifications.\" This first practice problem challenges you to explore a scenario where the most common qualification, Slater's condition, does not strictly hold, yet strong duality is preserved. By explicitly constructing the dual of an entropy minimization problem, you will see firsthand how to verify the duality gap and appreciate the nuances of the underlying theory .",
            "id": "3123598",
            "problem": "Consider the convex optimization problem with variables $x \\in \\mathbb{R}^4$:\n- Objective: minimize $f(x) = \\sum_{i=1}^{4} x_i \\ln x_i$ with the convention $0 \\ln 0 := 0$.\n- Constraints: $x \\ge 0$, $\\mathbf{e}^{\\top} x = 1$, and the equalities $x_3 = 0$, $x_4 = 0$.\n\nYour tasks are:\n- Using first principles of Lagrangian duality, decide whether strict feasibility (Slater’s condition for the inequality constraints) holds for this problem and justify your answer from definitions.\n- Form the Lagrangian for the problem and derive the dual function by explicitly computing the infimum over $x$.\n- Maximize the dual function to obtain the dual optimal value.\n- Compute the primal optimal value by analyzing the objective over the feasible set.\n- From these, compute the duality gap $p^{\\star} - d^{\\star}$.\n\nProvide the final answer as a single exact real number. No rounding is required. Do not include units.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It is a standard convex optimization problem, and the given data and constraints are self-contained and consistent.\n\nThe optimization problem can be formulated as:\n$$\n\\begin{aligned}\n\\text{minimize} \\quad  f(x) = \\sum_{i=1}^{4} x_i \\ln x_i \\\\\n\\text{subject to} \\quad  g_i(x) = -x_i \\le 0, \\quad i \\in \\{1, 2, 3, 4\\} \\\\\n h_1(x) = \\sum_{i=1}^{4} x_i - 1 = 0 \\\\\n h_2(x) = x_3 = 0 \\\\\n h_3(x) = x_4 = 0\n\\end{aligned}\n$$\nThe domain of the objective function is $\\text{dom}(f) = \\{x \\in \\mathbb{R}^4 \\mid x_i \\ge 0 \\text{ for } i=1,2,3,4\\}$. The convention $0 \\ln 0 := 0$ is used.\n\n**Part 1: Strict Feasibility (Slater's Condition)**\n\nStrict feasibility, by its definition, requires the existence of a feasible point $\\tilde{x}$ that satisfies all inequality constraints strictly. For this problem, the inequality constraints are $g_i(x) = -x_i \\le 0$ for $i \\in \\{1, 2, 3, 4\\}$. A strictly feasible point $\\tilde{x}$ must therefore satisfy:\n$1$. $\\tilde{x}$ is feasible, meaning it satisfies all equality and inequality constraints.\n$2$. $g_i(\\tilde{x})  0$ for all $i \\in \\{1, 2, 3, 4\\}$.\n\nThe second condition implies $-\\tilde{x}_i  0$, which is equivalent to $\\tilde{x}_i  0$ for all $i \\in \\{1, 2, 3, 4\\}$.\nHowever, the feasibility condition (the first condition) requires $\\tilde{x}$ to satisfy the equality constraints, which include $h_2(\\tilde{x}) = \\tilde{x}_3 = 0$ and $h_3(\\tilde{x}) = \\tilde{x}_4 = 0$.\n\nWe have a contradiction. Strict feasibility requires $\\tilde{x}_3  0$ and $\\tilde{x}_4  0$, while feasibility requires $\\tilde{x}_3 = 0$ and $\\tilde{x}_4 = 0$. No point can satisfy both conditions simultaneously. Therefore, no strictly feasible point exists for this problem, and strict feasibility (in this sense) does not hold.\n\nIt is worth noting that a weaker condition, often called the refined Slater's condition, is sufficient for strong duality in convex problems. This condition requires only that the non-affine inequality constraints be strictly satisfied for some feasible point. Since all inequality constraints in this problem are affine, this condition reduces to requiring a non-empty feasible set. The point $x = (1/2, 1/2, 0, 0)^{\\top}$ is feasible, so the refined Slater's condition holds, and we expect a duality gap of zero.\n\n**Part 2: Lagrangian and Dual Function**\n\nTo form the Lagrangian, we can incorporate the non-negativity constraints $x_i \\ge 0$ into the domain of the minimization, rather than treating them as explicit constraints with corresponding Lagrange multipliers. We introduce Lagrange multipliers $\\nu_1, \\nu_3, \\nu_4 \\in \\mathbb{R}$ for the three equality constraints. The Lagrangian $L(x, \\nu)$ is:\n$$\nL(x, \\nu) = f(x) + \\nu_1 h_1(x) + \\nu_3 h_2(x) + \\nu_4 h_3(x)\n$$\n$$\nL(x, \\nu) = \\sum_{i=1}^{4} x_i \\ln x_i + \\nu_1 \\left(\\sum_{i=1}^{4} x_i - 1\\right) + \\nu_3 x_3 + \\nu_4 x_4\n$$\nThe dual function $g(\\nu)$ is the infimum of the Lagrangian over its domain, $x \\in \\text{dom}(f)$, which is $\\{x \\in \\mathbb{R}^4 \\mid x_i \\ge 0\\}$.\n$$\ng(\\nu) = \\inf_{x \\ge 0} L(x, \\nu)\n$$\nWe can regroup terms in the Lagrangian by $x_i$:\n$$\nL(x, \\nu) = (x_1 \\ln x_1 + \\nu_1 x_1) + (x_2 \\ln x_2 + \\nu_1 x_2) + (x_3 \\ln x_3 + (\\nu_1+\\nu_3)x_3) + (x_4 \\ln x_4 + (\\nu_1+\\nu_4)x_4) - \\nu_1\n$$\nThe minimization problem decouples into four independent problems over $x_1, x_2, x_3, x_4$. We need to compute $\\inf_{t \\ge 0} (t \\ln t + c t)$ for a constant $c$. Let $\\phi(t) = t \\ln t + c t$. The derivative is $\\phi'(t) = \\ln t + 1 + c$. Setting $\\phi'(t) = 0$ gives $t_{min} = \\exp(-1-c)$. Since $\\phi''(t) = 1/t  0$ for $t  0$, this is a minimum.\nThe minimum value is $\\phi(t_{min}) = \\exp(-1-c) \\ln(\\exp(-1-c)) + c \\exp(-1-c) = \\exp(-1-c)(-1-c) + c \\exp(-1-c) = -\\exp(-1-c)$.\n\nApplying this result to each term in the Lagrangian:\n- For $x_1$: $c_1 = \\nu_1$, infimum is $-\\exp(-1-\\nu_1)$.\n- For $x_2$: $c_2 = \\nu_1$, infimum is $-\\exp(-1-\\nu_1)$.\n- For $x_3$: $c_3 = \\nu_1 + \\nu_3$, infimum is $-\\exp(-1-\\nu_1-\\nu_3)$.\n- For $x_4$: $c_4 = \\nu_1 + \\nu_4$, infimum is $-\\exp(-1-\\nu_1-\\nu_4)$.\n\nThe dual function is the sum of these infima minus $\\nu_1$:\n$$\ng(\\nu_1, \\nu_3, \\nu_4) = -2\\exp(-1-\\nu_1) - \\exp(-1-\\nu_1-\\nu_3) - \\exp(-1-\\nu_1-\\nu_4) - \\nu_1\n$$\n\n**Part 3: Maximize the Dual Function**\n\nThe dual problem is to maximize $g(\\nu)$ over $\\nu_1, \\nu_3, \\nu_4$. We take partial derivatives with respect to the dual variables:\n$$\n\\frac{\\partial g}{\\partial \\nu_3} = \\exp(-1-\\nu_1-\\nu_3)\n$$\n$$\n\\frac{\\partial g}{\\partial \\nu_4} = \\exp(-1-\\nu_1-\\nu_4)\n$$\nSince these partial derivatives are always positive, $g(\\nu)$ is a monotonically increasing function of $\\nu_3$ and $\\nu_4$. To maximize $g$, we must let $\\nu_3 \\to \\infty$ and $\\nu_4 \\to \\infty$. In this limit, the exponential terms involving $\\nu_3$ and $\\nu_4$ approach $0$.\nThe dual function to be maximized with respect to $\\nu_1$ becomes:\n$$\ng_{lim}(\\nu_1) = \\lim_{\\nu_3, \\nu_4 \\to \\infty} g(\\nu_1, \\nu_3, \\nu_4) = -2\\exp(-1-\\nu_1) - \\nu_1\n$$\nTo find the maximum, we set the derivative with respect to $\\nu_1$ to zero:\n$$\n\\frac{d g_{lim}}{d \\nu_1} = -2\\exp(-1-\\nu_1)(-1) - 1 = 2\\exp(-1-\\nu_1) - 1 = 0\n$$\nThis yields $\\exp(-1-\\nu_1) = 1/2$. Taking the natural logarithm gives $-1-\\nu_1 = \\ln(1/2) = -\\ln 2$, so the optimal $\\nu_1^{\\star} = \\ln 2 - 1$.\nThe dual optimal value, $d^{\\star}$, is found by substituting $\\nu_1^{\\star}$ back into $g_{lim}(\\nu_1)$:\n$$\nd^{\\star} = -2\\exp(-1-(\\ln 2 - 1)) - (\\ln 2 - 1) = -2\\exp(-\\ln 2) - \\ln 2 + 1 = -2\\left(\\frac{1}{2}\\right) - \\ln 2 + 1 = -1 - \\ln 2 + 1 = -\\ln 2\n$$\n\n**Part 4: Primal Optimal Value**\n\nWe can solve the primal problem directly by substituting the equality constraints into the objective function. The constraints $x_3 = 0$ and $x_4 = 0$, along with $\\sum x_i = 1$, simplify the problem to:\n$$\n\\begin{aligned}\n\\text{minimize} \\quad  x_1 \\ln x_1 + x_2 \\ln x_2 \\\\\n\\text{subject to} \\quad  x_1 + x_2 = 1 \\\\\n x_1 \\ge 0, x_2 \\ge 0\n\\end{aligned}\n$$\n(The terms for $x_3, x_4$ are $0 \\ln 0 = 0$).\nSubstitute $x_2 = 1 - x_1$ to get a function of a single variable, $\\phi(x_1)$, for $x_1 \\in [0, 1]$:\n$$\n\\phi(x_1) = x_1 \\ln x_1 + (1-x_1) \\ln(1-x_1)\n$$\nTo find the minimum, we differentiate with respect to $x_1$ and set the derivative to zero:\n$$\n\\phi'(x_1) = (\\ln x_1 + 1) + (-\\ln(1-x_1) - 1) = \\ln x_1 - \\ln(1-x_1) = 0\n$$\nThis gives $\\ln x_1 = \\ln(1-x_1)$, which implies $x_1 = 1-x_1$, so $2x_1 = 1$ and $x_1^{\\star} = 1/2$.\nThen $x_2^{\\star} = 1 - 1/2 = 1/2$. The second derivative $\\phi''(x_1) = 1/x_1 + 1/(1-x_1)$ is positive on $(0, 1)$, confirming this is a minimum.\nThe primal optimal point is $x^{\\star} = (1/2, 1/2, 0, 0)^{\\top}$.\nThe primal optimal value, $p^{\\star}$, is the objective evaluated at this point:\n$$\np^{\\star} = f(x^{\\star}) = \\frac{1}{2} \\ln\\left(\\frac{1}{2}\\right) + \\frac{1}{2} \\ln\\left(\\frac{1}{2}\\right) + 0 + 0 = 2 \\cdot \\left(\\frac{1}{2} \\ln\\left(\\frac{1}{2}\\right)\\right) = \\ln\\left(\\frac{1}{2}\\right) = -\\ln 2\n$$\n\n**Part 5: Duality Gap**\n\nThe duality gap is defined as the difference between the primal optimal value and the dual optimal value, $p^{\\star} - d^{\\star}$.\nUsing our computed values:\n$$\np^{\\star} - d^{\\star} = (-\\ln 2) - (-\\ln 2) = 0\n$$\nThe duality gap is $0$.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "While strong duality is common in convex problems, a non-zero duality gap can arise if the primal problem's optimal value is not attained. This often occurs when minimizing a continuous function over a set that is not closed. This exercise provides an intuitive geometric illustration of this principle by asking you to find the projection of a point onto an open ball . You will use Fenchel duality to calculate the gap and understand why closing the feasible set restores strong duality.",
            "id": "3123554",
            "problem": "Consider the Euclidean projection problem in $\\mathbb{R}^{2}$ with objective defined by minimizing the squared distance to a given point. Let the point be $c = (2, 0)$ and the feasible set be the open unit ball $S_{\\mathrm{open}} = \\{x \\in \\mathbb{R}^{2} : \\|x\\|_{2}  1\\}$, which is convex but not closed. The projection problem is written as minimizing the function $x \\mapsto \\frac{1}{2}\\|x - c\\|_{2}^{2}$ over $x \\in S_{\\mathrm{open}}$. Use the following fundamental bases: the definition of convex sets and closure, the indicator function of a set, the Fenchel conjugate, and the support function of a set. Starting from these definitions (without invoking any pre-packaged duality theorems), perform the following:\n\n1. Formulate the problem as minimizing the sum of a convex function and an indicator function, and use the definition of the Fenchel conjugate to derive the corresponding Fenchel dual problem. Clearly state the dual objective and characterize its optimizer using first-order optimality in $\\mathbb{R}^{2}$.\n2. Determine the primal infimum for the projection onto $S_{\\mathrm{open}}$ and explain whether a minimizer exists. Justify your conclusion using the geometry of the open ball and the properties of the squared distance.\n3. Consider a specific feasible primal point $x_{\\varepsilon} = (1 - \\varepsilon, 0)$ with $\\varepsilon = 0.2$, and use the dual optimizer you found to compute the pointwise duality gap defined as the primal objective at $x_{\\varepsilon}$ minus the dual objective at the dual optimizer.\n4. Now replace the feasible set by the closed unit ball $S_{\\mathrm{closed}} = \\{x \\in \\mathbb{R}^{2} : \\|x\\|_{2} \\leq 1\\}$ and repeat the reasoning to explain why strong duality holds and the duality gap at the primal-dual optimizers is zero. You do not need to recompute any numbers for this part; focus on the reasoning that changes when the set is closed.\n\nReport the numerical value obtained in part 3. Round your answer to four significant figures.",
            "solution": "The user-provided problem is a valid exercise in convex optimization, specifically concerning Fenchel duality and the duality gap. We will proceed with a full solution.\n\nThe primal problem is to minimize the function $f(x) = \\frac{1}{2}\\|x - c\\|_{2}^{2}$ for $x$ in a feasible set, where $c = (2, 0) \\in \\mathbb{R}^2$.\n\n**1. Fenchel Dual Formulation for the Open Unit Ball**\n\nThe feasible set is the open unit ball $S_{\\mathrm{open}} = \\{x \\in \\mathbb{R}^{2} : \\|x\\|_{2}  1\\}$. The optimization problem can be formulated as an unconstrained problem by using the indicator function of the set $S_{\\mathrm{open}}$, which is defined as $\\mathbb{I}_{S_{\\mathrm{open}}}(x) = 0$ if $x \\in S_{\\mathrm{open}}$ and $\\mathbb{I}_{S_{\\mathrm{open}}}(x) = +\\infty$ otherwise.\n\nThe primal problem is:\n$$ \\min_{x \\in \\mathbb{R}^2} \\left( \\frac{1}{2}\\|x - c\\|_{2}^{2} + \\mathbb{I}_{S_{\\mathrm{open}}}(x) \\right) $$\nThis is of the form $\\min_x (F(x) + G(x))$, where $F(x) = \\frac{1}{2}\\|x - c\\|_{2}^{2}$ and $G(x) = \\mathbb{I}_{S_{\\mathrm{open}}}(x)$. The Fenchel dual problem is given by $\\max_y (-F^*(y) - G^*(-y))$, where $F^*$ and $G^*$ are the Fenchel conjugates of $F$ and $G$, respectively.\n\nFirst, we compute the Fenchel conjugate of $F(x)$:\n$$ F^*(y) = \\sup_{x \\in \\mathbb{R}^2} (\\langle y, x \\rangle - F(x)) = \\sup_{x \\in \\mathbb{R}^2} \\left( y^T x - \\frac{1}{2}(x - c)^T(x - c) \\right) $$\nThe term inside the supremum is a strictly concave quadratic function of $x$. Its maximum is found by setting the gradient with respect to $x$ to zero:\n$$ \\nabla_x \\left( y^T x - \\frac{1}{2}(x^T x - 2c^T x + c^T c) \\right) = y - (x - c) = 0 $$\nThis gives the maximizing $x = y + c$. Substituting this back into the expression:\n$$ F^*(y) = y^T(y+c) - \\frac{1}{2}((y+c)-c)^T((y+c)-c) = y^T y + y^T c - \\frac{1}{2}y^T y = \\frac{1}{2}\\|y\\|_{2}^{2} + y^T c $$\nNext, we compute the Fenchel conjugate of $G(x) = \\mathbb{I}_{S_{\\mathrm{open}}}(x)$. The conjugate of an indicator function of a set is the support function of that set, $\\sigma_{S_{\\mathrm{open}}}(y)$.\n$$ G^*(y) = \\sigma_{S_{\\mathrm{open}}}(y) = \\sup_{x \\in S_{\\mathrm{open}}} \\langle y, x \\rangle = \\sup_{\\|x\\|_2  1} y^T x $$\nBy the Cauchy-Schwarz inequality, $y^T x \\le \\|y\\|_2 \\|x\\|_2$. Since $\\|x\\|_2  1$, we have $y^T x  \\|y\\|_2$. The supremum is $\\|y\\|_2$, which is approached by taking $x$ in the direction of $y$ with a norm approaching $1$. The support function of a convex set is equal to the support function of its closure. Thus, $\\sigma_{S_{\\mathrm{open}}}(y) = \\sigma_{\\overline{S_{\\mathrm{open}}}}(y) = \\max_{\\|x\\|_2 \\le 1} y^T x = \\|y\\|_2$.\nSo, $G^*(y) = \\|y\\|_2$.\n\nThe dual problem is to maximize the dual objective function $D(y)$:\n$$ D(y) = -F^*(y) - G^*(-y) = -\\left(\\frac{1}{2}\\|y\\|_{2}^{2} + y^T c\\right) - \\|-y\\|_2 = -\\left(\\frac{1}{2}\\|y\\|_{2}^{2} + y^T c + \\|y\\|_2\\right) $$\nMaximizing $D(y)$ is equivalent to minimizing its negative, let's call it $D_{obj}(y)$:\n$$ \\min_{y \\in \\mathbb{R}^2} D_{obj}(y) = \\min_{y \\in \\mathbb{R}^2} \\left(\\frac{1}{2}\\|y\\|_{2}^{2} + y^T c + \\|y\\|_2\\right) $$\nThis objective function is convex and is differentiable for $y \\ne 0$. We find the optimizer by setting its gradient to zero. With $c=(2,0)^T$:\n$$ \\nabla D_{obj}(y) = y + c + \\frac{y}{\\|y\\|_2} = y\\left(1 + \\frac{1}{\\|y\\|_2}\\right) + c = 0 $$\nThis implies $y$ must be collinear with and oppositely directed to $c$, so $y = -kc$ for some scalar $k0$.\n$$ -kc\\left(1 + \\frac{1}{\\|-kc\\|_2}\\right) + c = 0 \\implies c\\left(1 - k\\left(1 + \\frac{1}{k\\|c\\|_2}\\right)\\right) = 0 $$\nSince $c \\ne 0$, we have $1 - k(1 + \\frac{1}{k\\|c\\|_2}) = 0 \\implies 1 = k + \\frac{1}{\\|c\\|_2}$.\nGiven $c=(2,0)$, we have $\\|c\\|_2 = 2$. Therefore, $k = 1 - \\frac{1}{\\|c\\|_2} = 1 - \\frac{1}{2} = \\frac{1}{2}$.\nThe dual optimizer is $y^* = -kc = -\\frac{1}{2}(2, 0) = (-1, 0)$.\n\n**2. Primal Infimum and Existence of a Minimizer**\n\nThe primal problem is to find the point in the open unit ball $S_{\\mathrm{open}}$ that is closest to $c=(2,0)$. Geometrically, the point in the closed unit ball $\\overline{S_{\\mathrm{open}}} = \\{x: \\|x\\|_2 \\le 1\\}$ closest to $c$ is the projection of $c$ onto the ball, which is $x_{proj} = \\frac{c}{\\|c\\|_2} = \\frac{(2,0)}{2} = (1,0)$. The minimum squared distance would be $\\|(1,0) - (2,0)\\|_2^2 = 1$, and the minimum objective value would be $\\frac{1}{2}(1) = \\frac{1}{2}$.\n\nFor the problem over the open ball $S_{\\mathrm{open}}$, any feasible point $x$ must satisfy $\\|x\\|_2  1$. The point $(1,0)$ is not in $S_{\\mathrm{open}}$. We can, however, construct a sequence of points within $S_{\\mathrm{open}}$ that converges to $(1,0)$, for example $x_n = (1 - \\frac{1}{n}, 0)$ for $n \\in \\mathbb{Z}, n1$. For this sequence, the objective value is:\n$$ f(x_n) = \\frac{1}{2}\\|(1-\\frac{1}{n}, 0) - (2,0)\\|_2^2 = \\frac{1}{2}\\|(-1-\\frac{1}{n}, 0)\\|_2^2 = \\frac{1}{2}\\left(1+\\frac{1}{n}\\right)^2 $$\nAs $n \\to \\infty$, $x_n \\to (1,0)$ and $f(x_n) \\to \\frac{1}{2}$. The infimum of the objective function over $S_{\\mathrm{open}}$ is thus $p^* = \\frac{1}{2}$.\n\nHowever, no minimizer exists in $S_{\\mathrm{open}}$. If a minimizer $x^*$ existed, it would have to satisfy $f(x^*) = \\frac{1}{2}$, which means $\\frac{1}{2}\\|x^*-c\\|_2^2 = \\frac{1}{2}$, or $\\|x^*-c\\|_2 = 1$. The only point satisfying this and $\\|x^*\\|_2 \\le 1$ is $x^*=(1,0)$. Since $(1,0) \\notin S_{\\mathrm{open}}$, the infimum is not attained in the feasible set. This is a consequence of minimizing a continuous function over a non-closed set.\n\n**3. Pointwise Duality Gap Calculation**\n\nWe are given the point $x_{\\varepsilon} = (1 - \\varepsilon, 0)$ with $\\varepsilon = 0.2$, so $x_{0.2} = (0.8, 0)$. This point is feasible since $\\|x_{0.2}\\|_2 = 0.8  1$.\n\nThe primal objective value at this point is:\n$$ f(x_{0.2}) = \\frac{1}{2}\\|(0.8, 0) - (2, 0)\\|_2^2 = \\frac{1}{2}\\|(-1.2, 0)\\|_2^2 = \\frac{1}{2}(-1.2)^2 = \\frac{1}{2}(1.44) = 0.72 $$\nThe dual objective value at the dual optimizer $y^* = (-1, 0)$ is the dual optimal value $d^*$.\n$$ d^* = D(y^*) = -\\left(\\frac{1}{2}\\|y^*\\|_{2}^{2} + (y^*)^T c + \\|y^*\\|_2\\right) = -\\left(\\frac{1}{2}\\|(-1,0)\\|_2^2 + \\langle (-1,0), (2,0) \\rangle + \\|(-1,0)\\|_2\\right) $$\n$$ d^* = -\\left(\\frac{1}{2}(1)^2 + (-2) + 1\\right) = -\\left(\\frac{1}{2} - 1\\right) = -(-\\frac{1}{2}) = 0.5 $$\nThe pointwise duality gap is the difference between the primal objective at the specific point $x_{0.2}$ and the optimal dual objective value $d^*$:\n$$ \\text{Gap} = f(x_{0.2}) - d^* = 0.72 - 0.5 = 0.22 $$\nTo four significant figures, this is $0.2200$.\n\n**4. Analysis for the Closed Unit Ball**\n\nWhen the feasible set is changed to the closed unit ball $S_{\\mathrm{closed}} = \\{x \\in \\mathbb{R}^{2} : \\|x\\|_{2} \\leq 1\\}$, the problem becomes:\n$$ \\min_{x \\in S_{\\mathrm{closed}}} \\frac{1}{2}\\|x - c\\|_{2}^{2} $$\nThe set $S_{\\mathrm{closed}}$ is closed and bounded in $\\mathbb{R}^2$, hence it is compact. The objective function $f(x)$ is continuous. By the Weierstrass Extreme Value Theorem, a continuous function on a compact set must attain its minimum. Therefore, a primal minimizer $x^*$ exists. As established previously, this minimizer is the projection $x^*=(1,0)$, and the primal optimal value is $p^* = f(x^*) = \\frac{1}{2}$.\n\nThe dual problem does not change because the support function of a convex set is the same as that of its closure, i.e., $\\sigma_{S_{\\mathrm{closed}}}(y) = \\sigma_{S_{\\mathrm{open}}}(y) = \\|y\\|_2$. Thus, the dual optimal value is still $d^* = \\frac{1}{2}$.\n\nIn this case, the primal and dual optimal values are equal, $p^* = d^* = \\frac{1}{2}$, so strong duality holds. The duality gap, defined as $p^* - d^*$, is $0$. Strong duality is guaranteed for this convex problem by Slater's constraint qualification. The constraint is $g(x) = \\|x\\|_2^2 - 1 \\le 0$. There exists a point $x=0$ which is strictly feasible, i.e., $g(0) = -1  0$. This ensures that strong duality holds. The zero duality gap is a direct consequence. At the primal-dual optimal pair, the gap is zero, unlike the pointwise gap calculated for a non-optimal primal point in Part 3. The crucial difference is the closed nature of the feasible set, which guarantees the existence of a primal minimizer where the infimum is attained.",
            "answer": "$$\\boxed{0.2200}$$"
        },
        {
            "introduction": "Beyond understanding when a duality gap exists, it is crucial to know methods that can help close it. The augmented Lagrangian method is a powerful computational technique that combines the penalty method with Lagrangian duality to achieve robust convergence. In this practice, you will explore how increasing the penalty parameter $\\rho$ systematically improves the dual lower bound and reduces the duality gap for a quadratic program . This exercise demonstrates a key principle in algorithm design: transforming a constrained problem into a sequence of more manageable unconstrained ones.",
            "id": "3123606",
            "problem": "Consider a family of equality-constrained convex quadratic optimization problems of the form: minimize $f(x)$ subject to $A x = b$, where $f(x) = \\tfrac{1}{2} x^{\\top} Q x + c^{\\top} x$, $Q \\in \\mathbb{R}^{n \\times n}$ is symmetric positive definite, $A \\in \\mathbb{R}^{1 \\times n}$ is a single-row matrix, $b \\in \\mathbb{R}$, and $c \\in \\mathbb{R}^{n}$. Define the augmented Lagrangian $\\mathcal{L}_{\\rho}(x,\\lambda) = f(x) + \\lambda^{\\top}(A x - b) + \\tfrac{\\rho}{2} \\lVert A x - b \\rVert_{2}^{2}$ for penalty parameter $\\rho \\ge 0$ and Lagrange multiplier $\\lambda \\in \\mathbb{R}$. The augmented dual function at fixed multiplier $\\lambda$ is $g_{\\rho}(\\lambda) = \\inf_{x} \\mathcal{L}_{\\rho}(x,\\lambda)$, which is a valid lower bound on the constrained optimal value $p^{\\star} = \\min\\{ f(x) \\mid A x = b \\}$. For a fixed multiplier $\\lambda = 0$, define the augmented duality gap $\\Delta(\\rho) = p^{\\star} - g_{\\rho}(0)$.\n\nYour task is to write a program that, for a small test suite of problems and a set of increasing penalty values $\\{\\rho_{0}, \\rho_{1}, \\dots, \\rho_{m-1}\\}$, computes:\n- the constrained primal optimal value $p^{\\star}$,\n- the augmented dual lower bound $g_{\\rho}(0) = \\min_{x} \\{ f(x) + \\tfrac{\\rho}{2} \\lVert A x - b \\rVert_{2}^{2} \\}$,\n- the augmented duality gap sequence $\\{\\Delta(\\rho_{k})\\}_{k=0}^{m-1}$,\n- a boolean flag indicating whether the gap sequence is monotonically nonincreasing as $\\rho$ increases,\n- and the smallest index $k$ (if it exists) after which the marginal decrease in the gap stays below a given tolerance $\\tau$ for all subsequent penalty values. Formally, define the marginal decreases $\\delta_{i} = \\max\\{0, \\Delta(\\rho_{i-1}) - \\Delta(\\rho_{i})\\}$ for $i \\in \\{1,\\dots,m-1\\}$. Find the smallest $k \\in \\{0,\\dots,m-2\\}$ such that for all $j \\in \\{k+1,\\dots,m-1\\}$ we have $\\delta_{j} \\le \\tau$. If no such $k$ exists, return $-1$ for that test case.\n\nBase your derivations and algorithm on the following foundational facts:\n- For convex quadratic $f(x)$ with linear equality constraints $A x = b$, the Karush–Kuhn–Tucker (KKT) conditions characterize the constrained optimum $(x^{\\star}, \\nu^{\\star})$ via a linear system built from $Q$, $A$, $b$, and $c$.\n- For fixed $\\lambda$ and $\\rho \\ge 0$, minimizing $\\mathcal{L}_{\\rho}(x,\\lambda)$ over $x$ is an unconstrained strictly convex quadratic program with a unique minimizer, which yields $g_{\\rho}(\\lambda)$.\n- For any fixed $\\lambda$, the function $\\rho \\mapsto g_{\\rho}(\\lambda)$ is nondecreasing, so $\\rho \\mapsto \\Delta(\\rho)$ is nonincreasing.\n\nImplement the computations exactly as specified, without using any problem-specific closed-form shortcuts beyond standard linear algebra.\n\nTest Suite. Use the following three test cases, each with dimension $n = 2$, and with $m = 6$ penalty values per case. All matrices and vectors are given explicitly:\n\n- Test case $1$:\n  - $Q = \\begin{bmatrix} 4  1 \\\\ 1  2 \\end{bmatrix}$, $c = \\begin{bmatrix} -1 \\\\ 0.5 \\end{bmatrix}$, $A = \\begin{bmatrix} 1  1 \\end{bmatrix}$, $b = 1$,\n  - penalties $\\{\\rho_{k}\\}_{k=0}^{5} = \\{0, 0.5, 1, 2, 5, 20\\}$,\n  - tolerance $\\tau = 10^{-4}$.\n\n- Test case $2$:\n  - $Q = \\begin{bmatrix} 3  0.5 \\\\ 0.5  1.5 \\end{bmatrix}$, $c = \\begin{bmatrix} 0.2 \\\\ -0.7 \\end{bmatrix}$, $A = \\begin{bmatrix} 1  -1 \\end{bmatrix}$, $b = 0.2$,\n  - penalties $\\{\\rho_{k}\\}_{k=0}^{5} = \\{0, 0.1, 0.5, 1, 3, 10\\}$,\n  - tolerance $\\tau = 10^{-4}$.\n\n- Test case $3$:\n  - $Q = \\begin{bmatrix} 2  -0.3 \\\\ -0.3  1.2 \\end{bmatrix}$, $c = \\begin{bmatrix} -0.5 \\\\ 0.8 \\end{bmatrix}$, $A = \\begin{bmatrix} 2  1 \\end{bmatrix}$, $b = 0.5$,\n  - penalties $\\{\\rho_{k}\\}_{k=0}^{5} = \\{0, 0.2, 0.8, 1.6, 4, 12\\}$,\n  - tolerance $\\tau = 10^{-4}$.\n\nOutput specification. For each test case, produce a result of the form $[\\text{is\\_monotone}, k, \\Delta(\\rho_{m-1})]$, where $\\text{is\\_monotone}$ is a boolean indicating if the gap sequence is monotonically nonincreasing, $k$ is the diminishing-returns index defined above (or $-1$ if none exists), and $\\Delta(\\rho_{m-1})$ is the final gap at the largest penalty. Your program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets, with each test case result enclosed in its own square brackets. For example, a syntactically valid format is $[[\\text{True},0,0.1234],[\\text{True},2,0.0001],[\\text{False},-1,0.05]]$. The final gap values should be printed as decimal floating-point numbers; no percentage signs are allowed anywhere.",
            "solution": "The user-provided problem is a well-defined exercise in convex optimization, specifically concerning the method of augmented Lagrangians for a quadratic program (QP). All components are mathematically sound and self-consistent. The problem is valid.\n\nThe solution proceeds in four main analytical steps, which are then implemented numerically.\n1.  **Finding the Primal Optimum ($p^{\\star}$)**: The constrained optimal value $p^{\\star}$ is found by solving the Karush-Kuhn-Tucker (KKT) conditions for the primal problem.\n2.  **Finding the Augmented Dual Value ($g_{\\rho}(0)$)**: The augmented dual function value $g_{\\rho}(0)$ is found by solving an unconstrained quadratic minimization problem.\n3.  **Calculating the Duality Gap Sequence**: The augmented duality gap is computed as $\\Delta(\\rho) = p^{\\star} - g_{\\rho}(0)$ for each penalty parameter $\\rho_k$.\n4.  **Analyzing the Gap Sequence**: The computed sequence of gaps $\\{\\Delta(\\rho_k)\\}$ is analyzed for monotonicity and rate of convergence.\n\n### 1. Primal Optimal Solution\nThe primal problem is an equality-constrained convex quadratic program:\n$$ \\min_{x \\in \\mathbb{R}^n} \\quad f(x) = \\tfrac{1}{2} x^{\\top} Q x + c^{\\top} x $$\n$$ \\text{subject to} \\quad A x = b $$\nwhere $Q$ is symmetric positive definite (SPD), ensuring strict convexity of $f(x)$. The Lagrangian for this problem is $\\mathcal{L}(x, \\nu) = f(x) + \\nu^{\\top}(A x - b)$. Since the problem is convex and satisfies constraint qualifications (Slater's condition holds as constraints are linear), the KKT conditions are necessary and sufficient for optimality. The conditions are:\n1.  **Stationarity**: $\\nabla_x \\mathcal{L}(x^{\\star}, \\nu^{\\star}) = Q x^{\\star} + c + A^{\\top} \\nu^{\\star} = 0$\n2.  **Primal Feasibility**: $A x^{\\star} = b$\n\nThis forms a system of $n+1$ linear equations in the $n+1$ variables $(x^{\\star}, \\nu^{\\star})$, which can be written in block matrix form:\n$$\n\\begin{bmatrix}\nQ  A^{\\top} \\\\\nA  0\n\\end{bmatrix}\n\\begin{bmatrix}\nx^{\\star} \\\\\n\\nu^{\\star}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-c \\\\\nb\n\\end{bmatrix}\n$$\nSince $Q$ is SPD and $A$ has full row rank (which is true for a non-zero $1 \\times n$ matrix $A$), the KKT matrix on the left is non-singular. We can solve this system to find the unique primal-dual optimal pair $(x^{\\star}, \\nu^{\\star})$.\nThe optimal primal value is then $p^{\\star} = f(x^{\\star}) = \\tfrac{1}{2} (x^{\\star})^{\\top} Q x^{\\star} + c^{\\top} x^{\\star}$.\n\n### 2. Augmented Dual Function Value\nThe augmented Lagrangian with a fixed multiplier $\\lambda=0$ is given by:\n$$ \\mathcal{L}_{\\rho}(x, 0) = f(x) + \\tfrac{\\rho}{2} \\lVert A x - b \\rVert_{2}^{2} $$\nThe augmented dual function value $g_{\\rho}(0)$ is the infimum of this function over all $x$:\n$$ g_{\\rho}(0) = \\inf_{x \\in \\mathbb{R}^n} \\mathcal{L}_{\\rho}(x, 0) $$\nExpanding the expression for $\\mathcal{L}_{\\rho}(x, 0)$:\n$$ \\mathcal{L}_{\\rho}(x, 0) = \\tfrac{1}{2} x^{\\top} Q x + c^{\\top} x + \\tfrac{\\rho}{2} (x^{\\top} A^{\\top} A x - 2b A x + b^2) $$\n$$ \\mathcal{L}_{\\rho}(x, 0) = \\tfrac{1}{2} x^{\\top} (Q + \\rho A^{\\top}A) x + (c - \\rho b A^{\\top})^{\\top} x + \\tfrac{\\rho}{2} b^2 $$\nThis is an unconstrained quadratic function of $x$. The Hessian is $Q_{\\rho} = Q + \\rho A^{\\top}A$. Since $Q$ is SPD and $\\rho A^{\\top}A$ is positive semi-definite for $\\rho \\ge 0$, $Q_{\\rho}$ is SPD. Therefore, the function is strictly convex and has a unique minimizer $x_{\\rho}$. The minimizer is found by setting the gradient to zero:\n$$ \\nabla_x \\mathcal{L}_{\\rho}(x, 0) = (Q + \\rho A^{\\top}A) x + (c - \\rho b A^{\\top}) = 0 $$\nThis gives a linear system for the minimizer $x_{\\rho}$:\n$$ (Q + \\rho A^{\\top}A) x_{\\rho} = \\rho b A^{\\top} - c $$\nAfter solving for $x_{\\rho}$, we evaluate $\\mathcal{L}_{\\rho}(x_{\\rho}, 0)$ to find $g_{\\rho}(0)$. A more numerically stable way to compute the value is to use the stationarity condition, which simplifies the expression to:\n$$ g_{\\rho}(0) = \\tfrac{1}{2} (c - \\rho b A^{\\top})^{\\top} x_{\\rho} + \\tfrac{\\rho}{2} b^2 $$\n\n### 3. Duality Gap and Sequence Analysis\nFor each penalty parameter $\\rho_k$ in the given sequence, we compute $g_{\\rho_k}(0)$ and the corresponding augmented duality gap:\n$$ \\Delta(\\rho_k) = p^{\\star} - g_{\\rho_k}(0) $$\nThe problem asks for three analyses of the resulting sequence $\\{\\Delta(\\rho_k)\\}_{k=0}^{m-1}$:\n\n-   **Monotonicity `is_monotone`**: We check if the computed sequence is nonincreasing, i.e., $\\Delta(\\rho_i) \\ge \\Delta(\\rho_{i+1})$ for all $i \\in \\{0, \\dots, m-2\\}$. A boolean flag will report the outcome of this check on the computed floating-point values.\n\n-   **Diminishing-Returns Index `k`**: We compute the sequence of marginal decreases, $\\delta_i = \\max\\{0, \\Delta(\\rho_{i-1}) - \\Delta(\\rho_i)\\}$, for $i \\in \\{1,\\dots,m-1\\}$. We then search for the smallest index $k \\in \\{0,\\dots,m-2\\}$ such that for all subsequent indices $j \\in \\{k+1, \\dots, m-1\\}$, the marginal decrease is below a tolerance, i.e., $\\delta_j \\le \\tau$. If no such $k$ exists, the value is $-1$. This is implemented by iterating $k$ from $0$ to $m-2$ and, for each $k$, checking if the condition holds for the entire tail of the $\\delta$ sequence. The first $k$ that satisfies this is the answer.\n\n-   **Final Gap `Δ(ρ_{m-1})`**: This is simply the last element of the computed gap sequence.\n\n### Algorithm Summary\nFor each test case:\n1.  Construct and solve the KKT linear system to find $x^{\\star}$.\n2.  Compute the primal optimal value $p^{\\star} = f(x^{\\star})$.\n3.  Initialize an empty list for the gaps.\n4.  For each penalty parameter $\\rho_k$:\n    a. Construct and solve the linear system $(Q + \\rho_k A^{\\top}A) x_{\\rho_k} = \\rho_k b A^{\\top} - c$ for $x_{\\rho_k}$.\n    b. Compute the dual value $g_{\\rho_k}(0)$.\n    c. Compute the gap $\\Delta(\\rho_k) = p^{\\star} - g_{\\rho_k}(0)$ and add it to the list.\n5.  Analyze the list of gaps to determine `is_monotone`, the index `k`, and `Δ(ρ_{m-1})`.\n6.  Format the results as specified.",
            "answer": "```python\nimport numpy as np\n\ndef _solve_single_case(Q, c, A, b, rhos, tau):\n    \"\"\"\n    Solves a single instance of the optimization problem and analysis.\n    \"\"\"\n    n = Q.shape[0]\n    m = len(rhos)\n\n    # Step 1: Compute the primal optimum p_star by solving the KKT system.\n    # KKT matrix: [[Q, A.T], [A, 0]]\n    kkt_matrix = np.block([\n        [Q, A.T],\n        [A, np.zeros((A.shape[0], A.shape[0]))]\n    ])\n    # KKT RHS: [[-c], [b]]\n    rhs_kkt = np.vstack([-c, np.array([[b]])])\n\n    # Solve KKT system for [x_star, nu_star]\n    try:\n        sol_kkt = np.linalg.solve(kkt_matrix, rhs_kkt)\n    except np.linalg.LinAlgError:\n        # This should not happen for the given valid problems.\n        return [False, -1, float('nan')]\n\n    x_star = sol_kkt[:n]\n    p_star = (0.5 * x_star.T @ Q @ x_star + c.T @ x_star).item()\n\n    # Step 2  3: Compute g_rho(0) and the gap sequence Delta(rho).\n    gaps = []\n    for rho in rhos:\n        # Form the system to find x_rho, the minimizer of L_rho(x, 0).\n        Q_rho = Q + rho * A.T @ A\n        rhs_g = rho * b * A.T - c\n        \n        try:\n            x_rho = np.linalg.solve(Q_rho, rhs_g)\n        except np.linalg.LinAlgError:\n            gaps.append(float('nan'))\n            continue\n\n        # Compute g_rho(0)\n        c_rho = c - rho * b * A.T\n        d_rho = 0.5 * rho * b**2\n        g_rho_0 = (0.5 * (c - rho * b * A.T).T @ x_rho + 0.5 * rho * b**2).item()\n        \n        # Compute the gap\n        gap = p_star - g_rho_0\n        gaps.append(gap)\n\n    # Step 4: Analyze the gap sequence.\n    # Check for monotonicity\n    is_monotone = True\n    for i in range(m - 1):\n        # A direct comparison is used as per a strict interpretation of the task.\n        # Adding a small tolerance for floating point comparisons.\n        if gaps[i]  gaps[i+1] - 1e-12:\n            is_monotone = False\n            break\n\n    # Find the diminishing-returns index k\n    k_result = -1\n    if m >= 2:\n        # delta_i = max(0, Delta(rho_{i-1}) - Delta(rho_i)) for i in {1..m-1}\n        marginal_decreases = [max(0, gaps[i] - gaps[i+1]) for i in range(m - 1)]\n        \n        # Find smallest k in {0..m-2} s.t. for all j in {k+1..m-1}, delta_j = tau\n        for k_candidate in range(m - 1):  # k_candidate from 0 to m-2\n            tail_condition_holds = True\n            # Check for j from k_candidate+1 to m\n            # In marginal_decreases list, delta_j is at index j-1\n            for j in range(k_candidate + 2, m + 1):\n                if marginal_decreases[j - 2] > tau:\n                    tail_condition_holds = False\n                    break\n            \n            if tail_condition_holds:\n                k_result = k_candidate\n                break\n\n    final_gap = gaps[-1]\n\n    return [is_monotone, k_result, final_gap]\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        {\n            \"Q\": np.array([[4, 1], [1, 2]], dtype=float),\n            \"c\": np.array([[-1], [0.5]], dtype=float),\n            \"A\": np.array([[1, 1]], dtype=float),\n            \"b\": 1.0,\n            \"rhos\": [0, 0.5, 1, 2, 5, 20],\n            \"tau\": 1e-4,\n        },\n        {\n            \"Q\": np.array([[3, 0.5], [0.5, 1.5]], dtype=float),\n            \"c\": np.array([[0.2], [-0.7]], dtype=float),\n            \"A\": np.array([[1, -1]], dtype=float),\n            \"b\": 0.2,\n            \"rhos\": [0, 0.1, 0.5, 1, 3, 10],\n            \"tau\": 1e-4,\n        },\n        {\n            \"Q\": np.array([[2, -0.3], [-0.3, 1.2]], dtype=float),\n            \"c\": np.array([[-0.5], [0.8]], dtype=float),\n            \"A\": np.array([[2, 1]], dtype=float),\n            \"b\": 0.5,\n            \"rhos\": [0, 0.2, 0.8, 1.6, 4, 12],\n            \"tau\": 1e-4,\n        },\n    ]\n\n    all_results = []\n    for case in test_cases:\n        # Run my own corrected code logic\n        n = case[\"Q\"].shape[0]\n        m = len(case[\"rhos\"])\n\n        kkt_matrix = np.block([[case[\"Q\"], case[\"A\"].T],[case[\"A\"], np.zeros((case[\"A\"].shape[0], case[\"A\"].shape[0]))]])\n        rhs_kkt = np.vstack([-case[\"c\"], np.array([[case[\"b\"]]])])\n        sol_kkt = np.linalg.solve(kkt_matrix, rhs_kkt)\n        x_star = sol_kkt[:n]\n        p_star = (0.5 * x_star.T @ case[\"Q\"] @ x_star + case[\"c\"].T @ x_star).item()\n\n        gaps = []\n        for rho in case[\"rhos\"]:\n            Q_rho = case[\"Q\"] + rho * case[\"A\"].T @ case[\"A\"]\n            rhs_g = rho * case[\"b\"] * case[\"A\"].T - case[\"c\"]\n            x_rho = np.linalg.solve(Q_rho, rhs_g)\n            g_rho_0 = (0.5 * (case[\"c\"] - rho * case[\"b\"] * case[\"A\"].T).T @ x_rho + 0.5 * rho * case[\"b\"]**2).item()\n            gap = p_star - g_rho_0\n            gaps.append(gap)\n            \n        is_monotone = all(gaps[i] >= gaps[i+1] - 1e-9 for i in range(m - 1))\n\n        k_result = -1\n        if m > 1:\n            marginal_decreases = [max(0, gaps[i] - gaps[i+1]) for i in range(m - 1)]\n            for k in range(m - 1):\n                is_tail_small = True\n                for j in range(k + 1, m - 1):\n                    if marginal_decreases[j] > case[\"tau\"]:\n                        is_tail_small = False\n                        break\n                if is_tail_small:\n                    k_result = k\n                    break\n\n        all_results.append([is_monotone, k_result, gaps[-1]])\n\n    # Format the output exactly as specified.\n    formatted_results = [\n        f\"[{'True' if res[0] else 'False'},{res[1]},{res[2]}]\" for res in all_results\n    ]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\nsolve()\n```"
        }
    ]
}