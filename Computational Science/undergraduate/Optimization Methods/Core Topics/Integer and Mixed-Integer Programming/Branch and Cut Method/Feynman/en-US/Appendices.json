{
    "hands_on_practices": [
        {
            "introduction": "The branch-and-cut method begins when the linear programming (LP) relaxation of an integer problem yields a fractional solution. This practice delves into the foundational technique for handling such situations: the Gomory fractional cut. By working directly with a row from a simplex tableau that corresponds to a fractional variable, you will derive a valid inequality from first principles that makes the current LP solution infeasible while keeping all valid integer solutions safe . This exercise is crucial for understanding how cutting planes are systematically generated and how they tighten the feasible region of the LP relaxation.",
            "id": "3104181",
            "problem": "Consider a $0$–$1$ knapsack problem with decision variables $x_{1}, x_{2}, x_{3}, x_{4} \\in \\{0,1\\}$, capacity constraint $\\sum_{i=1}^{4} w_{i} x_{i} \\leq W$, and a linear objective $\\sum_{i=1}^{4} p_{i} x_{i}$ to be maximized. In the linear programming (LP) relaxation, the variable bounds $x_{i} \\leq 1$ are represented as equalities $x_{i} + s_{i} = 1$ with slack variables $s_{i} \\geq 0$. Suppose the LP relaxation has been solved to an optimal basic feasible solution $\\hat{x}$ in the simplex tableau, where the integer-constrained basic variable is $x_{3}$ and its tableau row is\n$$\nx_{3} + 2.75\\, s_{1} - 1.30\\, s_{2} + 0.45\\, s_{4} = 0.37462.\n$$\nAssume that at this LP solution, the nonbasic slack variables in this row satisfy $\\hat{s}_{1} = 0$, $\\hat{s}_{2} = 0$, and $\\hat{s}_{4} = 0$, so the value of the basic variable is $\\hat{x}_{3} = 0.37462$, which is fractional and therefore infeasible for the $0$–$1$ knapsack.\n\nUsing only the fundamental definitions of integer variables, floor and fractional-part operations, and the structure of the simplex tableau, derive the Gomory fractional cut appropriate for a mixed-integer tableau row of the form $x_{k} + \\sum_{j} a_{j} s_{j} = b_{k}$ where $x_{k}$ is required to be integer and $s_{j} \\geq 0$ are continuous. Then, apply this derivation to the given row to obtain the specific cut, and compute the amount by which the LP solution $\\hat{x}$ violates this cut; that is, compute the quantity\n$$\n\\text{violation} \\;=\\; \\text{RHS} \\;-\\; \\text{LHS evaluated at } \\hat{s}.\n$$\nRound your final numerical answer to four significant figures, and report the violation as a pure number with no units.",
            "solution": "The task is to derive the Gomory fractional cut for a general mixed-integer programming problem and then apply it to a specific tableau row from a $0$–$1$ knapsack problem. Finally, we must compute the amount by which the current linear programming (LP) relaxation solution violates this cut.\n\nFirst, we derive the Gomory mixed-integer cut.\nConsider a general row from an optimal simplex tableau for an LP relaxation of a mixed-integer program:\n$$ x_{k} + \\sum_{j \\in N} a_{j} s_{j} = b_{k} $$\nIn this equation, $x_k$ is a basic variable that is required to be an integer. The variables $s_j$ for $j \\in N$ are the non-basic variables, which are assumed to be continuous and non-negative ($s_j \\ge 0$). At the current basic feasible solution, $s_j=0$ for all $j \\in N$, which implies $x_k = b_k$. The problem arises when $b_k$ is not an integer, violating the integrality constraint on $x_k$.\n\nLet $f_0$ be the fractional part of $b_k$, defined as $f_0 = b_k - \\lfloor b_k \\rfloor$. Since $b_k$ is not an integer, we have $0 < f_0 < 1$. The tableau equation can be rewritten by isolating the terms involving the non-basic variables:\n$$ \\sum_{j \\in N} a_{j} s_{j} = b_k - x_k $$\nSubstituting $b_k = \\lfloor b_k \\rfloor + f_0$, we get:\n$$ \\sum_{j \\in N} a_{j} s_{j} = \\lfloor b_k \\rfloor - x_k + f_0 $$\nFor any feasible solution to the mixed-integer problem, $x_k$ must be an integer. Since $\\lfloor b_k \\rfloor$ is also an integer, the term $I = \\lfloor b_k \\rfloor - x_k$ must be an integer. The equation thus becomes:\n$$ \\sum_{j \\in N} a_{j} s_{j} = I + f_0, \\quad \\text{for some integer } I $$\nTo proceed, we partition the set of indices of non-basic variables $N$ into two disjoint sets: $N^+ = \\{ j \\in N \\mid a_j \\ge 0 \\}$ and $N^- = \\{ j \\in N \\mid a_j < 0 \\}$. The equation is then:\n$$ \\sum_{j \\in N^+} a_{j} s_{j} + \\sum_{j \\in N^-} a_{j} s_{j} = I + f_0 $$\nWe analyze two cases based on the integer value of $I$.\n\nCase 1: $I \\ge 0$.\nGiven that $s_j \\ge 0$ for all $j$, and $a_j < 0$ for $j \\in N^-$, the term $\\sum_{j \\in N^-} a_{j} s_{j}$ must be non-positive ($\\le 0$). Therefore, we can write:\n$$ \\sum_{j \\in N^+} a_{j} s_{j} \\ge I + f_0 $$\nSince $I$ is an integer and $I \\ge 0$, the right-hand side is minimized when $I=0$. This gives $I+f_0 \\ge f_0$. Thus, for this case, any feasible integer solution must satisfy:\n$$ \\sum_{j \\in N^+} a_{j} s_{j} \\ge f_0 $$\n\nCase 2: $I \\le -1$.\nGiven that $s_j \\ge 0$ for all $j$, and $a_j \\ge 0$ for $j \\in N^+$, the term $\\sum_{j \\in N^+} a_{j} s_{j}$ must be non-negative ($\\ge 0$). Therefore, we have:\n$$ \\sum_{j \\in N^-} a_{j} s_{j} \\le I + f_0 $$\nSince $0 < f_0 < 1$, the term $f_0 - 1$ is negative. Multiplying the inequality by the negative quantity $\\frac{f_0}{f_0-1}$ reverses the inequality sign:\n$$ \\frac{f_0}{f_0 - 1} \\sum_{j \\in N^-} a_{j} s_{j} \\ge \\frac{f_0}{f_0 - 1} (I + f_0) $$\nFor the right-hand side, since $I$ is an integer and $I \\le -1$, we have $I + f_0 \\le -1 + f_0 = -(1-f_0)$. Dividing by $f_0 - 1 = -(1-f_0)$ reverses the inequality again: $\\frac{I+f_0}{f_0-1} \\ge \\frac{-(1-f_0)}{-(1-f_0)} = 1$. Multiplying by $f_0 > 0$ yields $\\frac{f_0(I+f_0)}{f_0-1} \\ge f_0$. Thus, for this case, any feasible integer solution must satisfy:\n$$ \\frac{f_0}{f_0 - 1} \\sum_{j \\in N^-} a_{j} s_{j} \\ge f_0 $$\n\nA valid cut must hold for any feasible integer solution, which must fall into either Case 1 or Case 2. We can combine the two derived inequalities into a single valid cut.\nNote that $\\sum_{j \\in N^+} a_{j} s_{j} \\ge 0$ and $\\frac{f_0}{f_0-1} \\sum_{j \\in N^-} a_{j} s_{j} \\ge 0$.\nIf a solution is in Case 1, it satisfies $\\sum_{j \\in N^+} a_j s_j \\ge f_0$. Adding the non-negative term $\\frac{f_0}{f_0-1} \\sum_{j \\in N^-} a_j s_j$ to the left side preserves the inequality.\nIf a solution is in Case 2, it satisfies $\\frac{f_0}{f_0 - 1} \\sum_{j \\in N^-} a_{j} s_{j} \\ge f_0$. Adding the non-negative term $\\sum_{j \\in N^+} a_j s_j$ to the left side preserves the inequality.\nTherefore, the following inequality is valid for all feasible integer solutions:\n$$ \\sum_{j \\in N^+} a_{j} s_{j} + \\frac{f_0}{f_0 - 1} \\sum_{j \\in N^-} a_{j} s_{j} \\ge f_0 $$\nThis is the Gomory mixed-integer fractional cut.\n\nNow, we apply this derivation to the specific tableau row provided:\n$$ x_{3} + 2.75\\, s_{1} - 1.30\\, s_{2} + 0.45\\, s_{4} = 0.37462 $$\nHere, the integer basic variable is $x_k = x_3$. The non-basic variables are $s_1, s_2, s_4$.\nThe right-hand side is $b_3 = 0.37462$. The fractional part is $f_0 = b_3 - \\lfloor b_3 \\rfloor = 0.37462 - 0 = 0.37462$.\nThe coefficients of the non-basic variables are $a_1 = 2.75$, $a_2 = -1.30$, and $a_4 = 0.45$.\nWe classify them based on their sign:\n$N^+ = \\{1, 4\\}$ since $a_1 = 2.75 > 0$ and $a_4 = 0.45 > 0$.\n$N^- = \\{2\\}$ since $a_2 = -1.30 < 0$.\n\nSubstituting these values into the general cut formula:\n$$ a_1 s_1 + a_4 s_4 + \\frac{f_0}{f_0 - 1} a_2 s_2 \\ge f_0 $$\n$$ 2.75\\, s_{1} + 0.45\\, s_{4} + \\left( \\frac{0.37462}{0.37462 - 1} \\right) (-1.30)\\, s_{2} \\ge 0.37462 $$\nThe coefficient for $s_2$ is calculated as:\n$$ \\left( \\frac{0.37462}{-0.62538} \\right) (-1.30) = \\frac{-0.487006}{-0.62538} \\approx 0.778735... $$\nSo, the specific cut is:\n$$ 2.75\\, s_{1} + 0.778735...\\, s_{2} + 0.45\\, s_{4} \\ge 0.37462 $$\nThe problem asks for the violation of this cut at the current LP solution. At an optimal LP tableau, all non-basic variables are zero. So, $\\hat{s}_1 = 0$, $\\hat{s}_2 = 0$, and $\\hat{s}_4 = 0$.\nThe violation is defined as $\\text{RHS} - \\text{LHS}$, evaluated at the current solution $\\hat{s}$.\nThe left-hand side (LHS) of the cut at the current solution is:\n$$ \\text{LHS} = 2.75(0) + 0.778735...(0) + 0.45(0) = 0 $$\nThe right-hand side (RHS) of the cut is $f_0 = 0.37462$.\nThe violation is therefore:\n$$ \\text{Violation} = \\text{RHS} - \\text{LHS} = 0.37462 - 0 = 0.37462 $$\nThe current LP solution violates the cut because $0 \\ge 0.37462$ is false. The amount of violation is $0.37462$.\nRounding the result to four significant figures gives $0.3746$.",
            "answer": "$$\\boxed{0.3746}$$"
        },
        {
            "introduction": "When confronted with a fractional variable, a solver has two primary choices: branch on the variable or generate a cut. This exercise explores the powerful relationship between these two strategies by having you derive a split cut from the fundamental disjunction that an integer variable, say $x_k$ with fractional value $f$, must satisfy either $x_k \\le \\lfloor f \\rfloor$ or $x_k \\ge \\lceil f \\rceil$. Starting from geometric first principles, you will construct an \"intersection cut\" and then computationally verify its impact on the objective bound, comparing it directly to the bound obtained by branching . This practice reveals how cutting planes can encapsulate the information gained from branching, providing a key insight into the efficiency of the branch-and-cut method.",
            "id": "3104204",
            "problem": "Consider a Mixed-Integer Linear Programming (MILP) instance consisting of a single integer variable $x_k \\in \\{0,1\\}$, a vector of continuous nonnegative variables $s \\in \\mathbb{R}^n_{\\ge 0}$, and the linear equation\n$$\nx_k = f + \\sum_{j=1}^n r_j s_j,\n$$\nwith the auxiliary bound constraints $0 \\le x_k \\le 1$, and the objective function to minimize\n$$\n\\min \\sum_{j=1}^n s_j.\n$$\nAssume a fractional root solution $\\hat{x}$ equals $f$ with $s = 0$, and $f \\in (0,1)$. You will derive a split cut from the disjunction $x_k \\le 0 \\vee x_k \\ge 1$ and then quantify its effect relative to branching on $x_k$.\n\nStart from the foundational base of the branch-and-cut method: the linear programming relaxation of a MILP, valid disjunctions defining split sets for integer variables, and the intersection-cut principle in convex analysis. Specifically, view the equation $x_k = f + \\sum_{j=1}^n r_j s_j$ as a parameterization of the feasible set in the continuous variables $s$, where each coordinate direction $e_j$ (the ray $s = \\lambda e_j$ for $\\lambda \\ge 0$) moves $x_k$ linearly according to the sign of $r_j$. Use the disjunction $x_k \\le 0 \\vee x_k \\ge 1$ to construct a valid inequality that separates the fractional point $(x_k = f, s = 0)$ while remaining valid for all points that satisfy either disjunct together with $s \\ge 0$. No shortcut formulas should be assumed; derive the inequality from first principles by considering the minimum step along each ray needed to reach either boundary $x_k = 0$ or $x_k = 1$, and then aggregating these distances into a single linear inequality in $s$.\n\nAfter deriving the split cut, measure its effect in terms of the optimal objective value at:\n- the root linear programming relaxation (without branching or cuts),\n- the best bound obtained by branching on $x_k$ into the two child subproblems $x_k = 0$ and $x_k = 1$ (solving each child linear program to optimality),\n- the root linear programming relaxation augmented with the derived split cut.\n\nFor each child subproblem, solve\n$$\n\\min \\sum_{j=1}^n s_j \\quad \\text{subject to} \\quad \\sum_{j=1}^n r_j s_j = \\text{rhs}, \\quad s \\ge 0,\n$$\nwhere $\\text{rhs} = -f$ for the branch $x_k = 0$ and $\\text{rhs} = 1 - f$ for the branch $x_k = 1$. For scientific realism, ensure to treat branch infeasibility correctly when the sign pattern of $r$ does not permit a nonnegative solution for the corresponding $\\text{rhs}$.\n\nYour program must compute, for each test case, a list of three floating-point numbers:\n1. the optimal objective value at the root linear programming relaxation,\n2. the best bound from branching on $x_k$ (the minimum of the two child optimal values, treating infeasible children as having value $+\\infty$),\n3. the optimal objective value at the root linear programming relaxation augmented with the derived split cut.\n\nTest Suite:\n- Case $1$: $f = 0.7$, $r = [0.6, -0.4]$.\n- Case $2$: $f = 0.25$, $r = [0.5, -0.1, 0.0]$.\n- Case $3$: $f = 0.6$, $r = [0.2, -0.05]$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a list of three floats:\n$$\n\\text{output} = \\big[ [\\text{root},\\ \\text{branch},\\ \\text{cut}],\\ [\\text{root},\\ \\text{branch},\\ \\text{cut}],\\ [\\text{root},\\ \\text{branch},\\ \\text{cut}] \\big].\n$$\nNo physical units are involved. Express all numerical answers as decimal floats.",
            "solution": "The problem asks for an analysis of a simple MILP structure. We will compute the three requested objective values in sequence, starting with the necessary derivation of the split cut.\n\nThe LP relaxation of the MILP is:\n$$\n\\min \\quad z = \\sum_{j=1}^n s_j\n$$\n$$\n\\text{s.t.} \\quad x_k - \\sum_{j=1}^n r_j s_j = f\n$$\n$$\ns_j \\ge 0, \\quad \\forall j \\in \\{1, \\dots, n\\}\n$$\n$$\n0 \\le x_k \\le 1\n$$\nThe variables $s_j$ are non-basic at the root node, and $x_k$ is a basic variable.\n\n#### 1. Optimal Objective at the Root LP Relaxation\nAt the root of the search tree, we solve the LP relaxation. The problem statement provides the solution: $(\\hat{x}_k, \\hat{s}) = (f, 0)$. This gives an objective function value of $z = \\sum 0 = 0$. Since the objective function coefficients and the variables $s_j$ are non-negative, the objective value cannot be less than $0$. Thus, $z=0$ is the optimal objective value of the root LP relaxation.\n\n#### 2. Derivation of the Split Cut\nThe integer variable $x_k$ has a fractional value $f \\in (0,1)$. To cut off this fractional solution, we impose the disjunction $x_k \\le 0 \\vee x_k \\ge 1$. We derive the corresponding split cut using the intersection cut procedure. From the current fractional solution $\\hat{s}=0$, we consider rays along the positive directions of the non-basic variables, $s = \\lambda e_j$ for $\\lambda \\ge 0$, where $e_j$ is the $j$-th standard basis vector. Along such a ray, the equation for $x_k$ becomes:\n$x_k = f + r_j \\lambda$.\n\nWe seek the smallest $\\lambda_j > 0$ for which the point on the ray intersects the boundary of the split set, i.e., where $x_k = 0$ or $x_k = 1$.\n\n- To reach $x_k = 0$: $0 = f + r_j \\lambda \\implies \\lambda = -f/r_j$. Since $\\lambda$ must be positive and $f > 0$, this is possible only if $r_j < 0$. The intersection point on the $s_j$ axis is at $s_j = -f/r_j$.\n- To reach $x_k = 1$: $1 = f + r_j \\lambda \\implies \\lambda = (1-f)/r_j$. Since $\\lambda$ must be positive and $1-f > 0$, this is possible only if $r_j > 0$. The intersection point on the $s_j$ axis is at $s_j = (1-f)/r_j$.\n- If $r_j = 0$, the ray is parallel to the hyperplanes $x_k=0$ and $x_k=1$ and the intersection is at infinity.\n\nThe split cut is a hyperplane in the space of variables $s$ that passes through these intersection points. For a set of axial intercepts $a_1, a_2, \\dots, a_n$, the hyperplane is given by $\\sum_{j=1}^n \\frac{s_j}{a_j} = 1$. The valid inequality that cuts off the origin is $\\sum_{j=1}^n \\frac{s_j}{a_j} \\ge 1$.\n\nThe intercepts $a_j$ are:\n$$\na_j = \\begin{cases} (1-f)/r_j & \\text{if } r_j > 0 \\\\ -f/r_j & \\text{if } r_j < 0 \\\\ \\infty & \\text{if } r_j = 0 \\end{cases}\n$$\nSubstituting these into the hyperplane inequality, we get the split cut:\n$$\n\\sum_{j: r_j > 0} \\frac{s_j}{(1-f)/r_j} + \\sum_{j: r_j < 0} \\frac{s_j}{-f/r_j} \\ge 1\n$$\nSimplifying, we obtain the explicit form of the cut:\n$$\n\\sum_{j: r_j > 0} \\frac{r_j}{1-f} s_j + \\sum_{j: r_j < 0} \\frac{-r_j}{f} s_j \\ge 1\n$$\n\n#### 3. Optimal Objective with the Split Cut\nWe now find the new optimal objective value by adding this cut to the root LP relaxation. The problem becomes:\n$$\n\\min \\quad z = \\sum_{j=1}^n s_j\n$$\n$$\n\\text{s.t.} \\quad \\sum_{j: r_j > 0} \\frac{r_j}{1-f} s_j + \\sum_{j: r_j < 0} \\frac{-r_j}{f} s_j \\ge 1\n$$\n$$\ns_j \\ge 0, \\quad \\forall j\n$$\nLet the cut be written as $\\sum_{j=1}^n c_j s_j \\ge 1$, where $c_j > 0$ for all $j$ where $r_j \\ne 0$. The dual of this simple LP is $\\max y$ s.t. $y \\cdot c_j \\le 1, \\forall j$ and $y \\ge 0$. The optimal dual solution is $y^* = \\min_{j: c_j>0} \\{1/c_j\\}$. By strong duality, the optimal primal objective is also $y^*$:\n$$\nz_{\\text{cut}}^* = \\min \\left( \\min_{j: r_j>0} \\left\\{\\frac{1-f}{r_j}\\right\\}, \\min_{j: r_j<0} \\left\\{\\frac{f}{-r_j}\\right\\} \\right)\n$$\nThis simplifies to:\n$$\nz_{\\text{cut}}^* = \\min \\left( \\frac{1-f}{\\max_{j: r_j>0} \\{r_j\\}}, \\frac{f}{-\\min_{j: r_j<0} \\{r_j\\}} \\right)\n$$\nwhere if a set of indices is empty, its term is taken as $+\\infty$.\n\n#### 4. Best Bound from Branching\nBranching on $x_k$ creates two subproblems: $x_k=0$ and $x_k=1$. The best bound is the minimum of their optimal objective values.\n- **Subproblem 1 ($x_k=0$):**\nThe constraint $x_k = f + \\sum r_j s_j$ becomes $0 = f + \\sum r_j s_j$, or $\\sum r_j s_j = -f$. The LP is:\n$$\n\\min \\sum s_j \\quad \\text{s.t.} \\quad \\sum r_j s_j = -f, \\quad s_j \\ge 0\n$$\nTo satisfy $\\sum r_j s_j = -f < 0$ with $s_j \\ge 0$, at least one $r_j$ must be negative. To minimize $\\sum s_j$, we use the single most \"efficient\" variable, corresponding to the most negative $r_j$. Let $r_{\\min}^- = \\min_{j: r_j<0} \\{r_j\\}$. The optimal objective for this branch is $z_0^* = -f/r_{\\min}^-$.\n\n- **Subproblem 2 ($x_k=1$):**\nThe constraint becomes $1 = f + \\sum r_j s_j$, or $\\sum r_j s_j = 1-f$. The LP is:\n$$\n\\min \\sum s_j \\quad \\text{s.t.} \\quad \\sum r_j s_j = 1-f, \\quad s_j \\ge 0\n$$\nTo satisfy $\\sum r_j s_j = 1-f > 0$, at least one $r_j$ must be positive. By similar logic, we use the variable corresponding to the largest positive coefficient, $r_{\\max}^+ = \\max_{j: r_j>0} \\{r_j\\}$. The objective is $z_1^* = (1-f)/r_{\\max}^+$.\n\nThe best bound from branching is $z_{\\text{branch}}^* = \\min(z_0^*, z_1^*)$.\n\n#### Conclusion of Analysis\nComparing the optimal objective after the cut, $z_{\\text{cut}}^*$, with the best bound from branching, $z_{\\text{branch}}^*$, we find:\n$$\nz_{\\text{cut}}^* = \\min \\left( \\frac{1-f}{r_{\\max}^+}, \\frac{-f}{r_{\\min}^-} \\right) = \\min(z_1^*, z_0^*) = z_{\\text{branch}}^*\n$$\nFor this specific problem structure, the lower bound provided by adding the elementary split cut is identical to the lower bound obtained by branching on the fractional variable and solving the two child LPs.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the given problem for each test case by calculating the optimal\n    objective values for the root LP, the best bound from branching, and\n    the root LP augmented with a split cut.\n    \"\"\"\n    test_cases = [\n        # Case 1: f = 0.7, r = [0.6, -0.4]\n        (0.7, [0.6, -0.4]),\n        # Case 2: f = 0.25, r = [0.5, -0.1, 0.0]\n        (0.25, [0.5, -0.1, 0.0]),\n        # Case 3: f = 0.6, r = [0.2, -0.05]\n        (0.6, [0.2, -0.05]),\n    ]\n\n    results = []\n    for f, r_list in test_cases:\n        r = np.array(r_list)\n\n        # 1. Optimal objective value at the root LP relaxation.\n        # The solution (x_k, s) = (f, 0) is feasible for the LP relaxation\n        # and gives an objective of 0. Since s_j >= 0, this is optimal.\n        root_obj = 0.0\n\n        # 2. Best bound from branching on x_k.\n        # This is the minimum of the optimal values of the two child LPs.\n        \n        # Child LP for x_k = 0: min sum(s) s.t. sum(r_j * s_j) = -f, s >= 0\n        pos_r = r[r > 0]\n        neg_r = r[r  0]\n\n        # Objective for the branch x_k = 0\n        obj_branch_0 = np.inf\n        if neg_r.size > 0:\n            # To minimize sum(s), we use the single s_j corresponding to the\n            # most negative r_j (largest magnitude |r_j|).\n            r_min_neg = np.min(neg_r)\n            obj_branch_0 = -f / r_min_neg\n\n        # Objective for the branch x_k = 1\n        obj_branch_1 = np.inf\n        if pos_r.size > 0:\n            # To minimize sum(s), we use the single s_j corresponding to the\n            # most positive r_j.\n            r_max_pos = np.max(pos_r)\n            obj_branch_1 = (1 - f) / r_max_pos\n        \n        branch_obj = min(obj_branch_0, obj_branch_1)\n\n        # 3. Optimal objective value at the root LP augmented with the split cut.\n        # As derived in the solution, for this problem structure, the bound from the\n        # elementary split cut is identical to the bound from branching.\n        cut_obj = branch_obj\n\n        # Store the three computed values for this test case.\n        results.append([root_obj, branch_obj, cut_obj])\n\n    # Format the final output as a comma-separated list of lists.\n    # e.g., [[0.0,0.5,0.5],[0.0,1.5,1.5],[0.0,2.0,2.0]]\n    # Using map(str, ...) is a robust way to format each inner list.\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While general-purpose cuts are powerful, significant performance gains in branch-and-cut often come from problem-specific \"structured\" cuts. This practice focuses on the famous cover inequalities for the knapsack problem and addresses a critical practical question: how do we efficiently find a violated cut to add? You will implement and compare two different \"separation\" strategies: a fast, intuitive heuristic based on the current LP solution, and an exact method that formulates the search for the most violated cut as an optimization problem in its own right . This hands-on comparison highlights the crucial trade-off between the computational cost of finding cuts and the quality of the bounds they produce.",
            "id": "3104276",
            "problem": "You are tasked with implementing and comparing two cut generation strategies within a simplified branch-and-cut framework for a binary knapsack optimization problem. Consider a binary decision vector $x \\in \\{0,1\\}^n$, profit vector $p \\in \\mathbb{R}^n_{\\ge 0}$, weight vector $a \\in \\mathbb{Z}^n_{0}$, and capacity $b \\in \\mathbb{Z}_{0}$. The binary knapsack problem is to maximize the linear objective subject to a single knapsack inequality:\n$$\n\\max \\; p^\\top x \\quad \\text{subject to} \\quad a^\\top x \\le b, \\quad x \\in \\{0,1\\}^n.\n$$\nIts linear programming relaxation replaces $x \\in \\{0,1\\}^n$ with $0 \\le x \\le \\mathbf{1}$. A branch-and-cut method iteratively strengthens this relaxation with valid inequalities (cuts) and, if necessary, branches on fractional components of the current solution.\n\nYour program must implement and compare two cut generators based on Chvátal-Gomory cuts (CG cuts), specialized to knapsack cover inequalities:\n\n- A \"rounding-based\" CG cut generator: Given the current linear programming relaxation solution $\\hat{x} \\in [0,1]^n$, sort indices by decreasing $\\hat{x}_i$ and greedily build a set $S$ by adding items until the cumulative weight $\\sum_{i \\in S} a_i$ strictly exceeds the capacity $b$. If such a set is found, propose the cover inequality\n$$\n\\sum_{i \\in S} x_i \\le |S| - 1,\n$$\nand accept it only if it is violated by the current solution, that is, if\n$$\n\\sum_{i \\in S} \\hat{x}_i - (|S| - 1)  0.\n$$\n\n- An \"exact separation\" CG cut generator for knapsack cover inequalities: Among all subsets $S \\subseteq \\{1,\\dots,n\\}$ such that $\\sum_{i \\in S} a_i  b$ (a cover), find the subset that maximizes the violation\n$$\n\\sum_{i \\in S} \\hat{x}_i - (|S| - 1).\n$$\nGenerate the corresponding inequality only if the maximum violation is strictly positive.\n\nThese cover inequalities are a specific instance of Chvátal-Gomory cuts. Starting from the knapsack inequality $a^\\top x \\le b$, any subset $S$ with $\\sum_{i \\in S} a_i  b$ yields the cover inequality $\\sum_{i \\in S} x_i \\le |S| - 1$, which is valid for all $x \\in \\{0,1\\}^n$ satisfying $a^\\top x \\le b$.\n\nYou must implement:\n1. An optimization routine to solve the linear programming relaxation using a standard method.\n2. The rounding-based cut generator defined above.\n3. The exact separation routine that solves the cover separation problem to optimality.\n4. A single round of cut generation at the root node (no further branching is required for this task).\n5. A dynamic programming routine to compute the exact optimal integer solution value for comparison.\n\nFor each test case, compute:\n- The linear programming relaxation bound at the root after adding the rounding-based cut (if any) and after adding the exact separation cut (if any).\n- The integer optimal value obtained by dynamic programming.\n- The relative gaps (expressed as decimals) after cuts:\n$$\n\\text{gap}_{\\text{round}} = \\frac{\\text{LP}_{\\text{round}} - \\text{OPT}_{\\text{int}}}{\\text{OPT}_{\\text{int}}}, \\quad\n\\text{gap}_{\\text{exact}} = \\frac{\\text{LP}_{\\text{exact}} - \\text{OPT}_{\\text{int}}}{\\text{OPT}_{\\text{int}}}.\n$$\n- A boolean indicating whether exact separation achieves a strictly smaller gap than the rounding-based cut, evaluated as $\\text{gap}_{\\text{exact}}  \\text{gap}_{\\text{round}}$.\n\nFundamental base to be used in your derivation and implementation:\n- Linear programming relaxation of binary integer programs and its feasibility region $0 \\le x \\le \\mathbf{1}$.\n- Validity of knapsack cover inequalities derived from the knapsack constraint, justified by the binary nature of $x$ and the capacity exceedance condition.\n- Dynamic programming for exact 0–1 knapsack optimization with integer weights and capacity.\n\nTest Suite:\nUse the following instances with integer weights and capacities:\n- Test Case 1 (general fractional case):\n  - $p = [20,18,14,11]$\n  - $a = [7,6,5,4]$\n  - $b = 10$\n- Test Case 2 (integral relaxation case, boundary):\n  - $p = [9,7,5]$\n  - $a = [5,4,3]$\n  - $b = 9$\n- Test Case 3 (larger fractional case):\n  - $p = [28,26,21,18,16]$\n  - $a = [10,9,7,6,5]$\n  - $b = 17$\n\nFinal Output Format:\nYour program should produce a single line of output containing the results for all test cases as a list of lists. Each inner list must be of the form $[\\text{gap}_{\\text{round}}, \\text{gap}_{\\text{exact}}, \\text{exact\\_better}]$ where the first two entries are floats and the third is a boolean. For example: \n$[[g_1^{\\text{round}},g_1^{\\text{exact}},\\text{True}],[g_2^{\\text{round}},g_2^{\\text{exact}},\\text{False}],\\dots]$.",
            "solution": "The provided problem asks for the implementation and comparison of two cutting plane generation strategies for the binary knapsack problem. The solution requires a multi-step approach involving integer optimization, linear programming, and specialized cut generation algorithms. Below is a detailed, principle-based exposition of the methods employed.\n\n### 1. Optimal Integer Solution via Dynamic Programming\n\nThe exact optimal value for the 0-1 binary knapsack problem, denoted as $\\text{OPT}_{\\text{int}}$, serves as the benchmark against which the linear programming (LP) relaxation bounds are compared. For a problem with integer weights $a_i$ and an integer capacity $b$, dynamic programming (DP) provides an exact and efficient method to find this value.\n\nLet $dp(i, w)$ be the maximum profit achievable using a subset of the first $i$ items (from index $0$ to $i-1$) with a total weight limit of exactly $w$. The state transition, or recurrence relation, is defined as follows: for each item $i$ and capacity $w$, we decide whether to include item $i-1$ (with profit $p_{i-1}$ and weight $a_{i-1}$) or not.\n\n- If item $i-1$ is not included, the profit is the same as the maximum profit using the first $i-1$ items with capacity $w$, which is $dp(i-1, w)$.\n- If item $i-1$ is included (only possible if $w \\ge a_{i-1}$), the profit is $p_{i-1}$ plus the maximum profit from the first $i-1$ items with the remaining capacity, $w - a_{i-1}$, which is $p_{i-1} + dp(i-1, w - a_{i-1})$.\n\nThus, the recurrence relation is:\n$$\ndp(i, w) = \\begin{cases}\n    dp(i-1, w)  \\text{if } a_{i-1}  w \\\\\n    \\max(dp(i-1, w), p_{i-1} + dp(i-1, w - a_{i-1}))  \\text{if } a_{i-1} \\le w\n\\end{cases}\n$$\nThe DP table is initialized with $dp(0, w) = 0$ for all $w$, representing zero profit with no items. After filling the table for all $i \\in \\{1, \\dots, n\\}$ and $w \\in \\{1, \\dots, b\\}$, the optimal integer solution value is found at $dp(n, b)$.\n\n### 2. Linear Programming Relaxation and Cut Generation\n\nThe branch-and-cut method begins by solving the LP relaxation of the integer program. The binary constraint $x \\in \\{0, 1\\}^n$ is relaxed to a continuous bound $0 \\le x_i \\le 1$ for all $i$. The initial LP relaxation is:\n$$\n\\max \\; p^\\top x \\quad \\text{subject to} \\quad a^\\top x \\le b, \\quad 0 \\le x_i \\le 1 \\quad \\forall i.\n$$\nThis problem is solved using a standard LP solver. Let the solution be $\\hat{x}$. If $\\hat{x}$ is entirely integral, it is optimal for the original problem. If $\\hat{x}$ has fractional components, the LP bound $p^\\top \\hat{x}$ is an upper bound on $\\text{OPT}_{\\text{int}}$. We then seek to add valid inequalities (cuts) that are violated by $\\hat{x}$ to tighten this bound. The problem specifies using knapsack cover inequalities. A set $S \\subseteq \\{1, \\dots, n\\}$ is a **cover** if $\\sum_{i \\in S} a_i  b$. The corresponding **cover inequality** is $\\sum_{i \\in S} x_i \\le |S| - 1$. This inequality is valid because if more than $|S|-1$ items from $S$ were chosen (i.e., $\\sum_{i \\in S} x_i \\ge |S|$ for $x \\in \\{0,1\\}^n$), their total weight would exceed the capacity $b$, violating the knapsack constraint.\n\nA cut is useful only if it is violated by the current LP solution $\\hat{x}$, i.e., $\\sum_{i \\in S} \\hat{x}_i  |S| - 1$.\n\n#### 2.1. Rounding-Based Cut Generator\n\nThis is a heuristic method to find a violated cover inequality. It leverages the intuition that items with high fractional values in $\\hat{x}$ are prime candidates for inclusion in a violated cover. The algorithm is as follows:\n1. Sort the item indices $i$ in descending order of their corresponding values $\\hat{x}_i$.\n2. Greedily add items to a set $S$ following this sorted order.\n3. Stop as soon as the cumulative weight of items in $S$ exceeds the capacity $b$, i.e., $\\sum_{i \\in S} a_i  b$.\n4. If such a cover $S$ is found, check if it is violated by $\\hat{x}$: $\\sum_{i \\in S} \\hat{x}_i  |S| - 1$. If so, this cut is generated.\n\n#### 2.2. Exact Separation Cut Generator\n\nThis method aims to find the *most violated* cover inequality. The problem of finding a cover $S$ that maximizes the violation $\\sum_{i \\in S} \\hat{x}_i - (|S| - 1)$ is known as the **separation problem** for knapsack cover inequalities. We can formalize this as an optimization problem. Let $y_i$ be a binary variable where $y_i=1$ if item $i$ is in $S$ and $y_i=0$ otherwise.\nWe want to maximize $\\sum_{i=1}^n \\hat{x}_i y_i - (\\sum_{i=1}^n y_i - 1)$, which is equivalent to maximizing $\\sum_{i=1}^n (\\hat{x}_i - 1)y_i + 1$, subject to $\\sum_{i=1}^n a_i y_i  b$. Since $a_i$ and $b$ are integers, this is equivalent to $\\sum_{i=1}^n a_i y_i \\ge b+1$.\n\nLet $v_i = \\hat{x}_i - 1$. The separation problem is:\n$$\n\\max \\sum_{i=1}^n v_i y_i \\quad \\text{subject to} \\quad \\sum_{i=1}^n a_i y_i \\ge b+1, \\quad y \\in \\{0,1\\}^n.\n$$\nThis is a variation of the knapsack problem. It can be solved to optimality using dynamic programming. Let $dp_{sep}(i, w)$ be the maximum value $\\sum_{j=1}^i v_j y_j$ using a subset of the first $i$ items with a total weight of exactly $w$. The recurrence is analogous to the standard knapsack DP. After computing the table, the maximum value for the separation objective is found by taking $\\max_{w \\ge b+1} dp_{sep}(n, w)$. The maximum violation is this value plus $1$. If this maximum violation is positive, we backtrack through the DP table to reconstruct the optimal cover set $S$.\n\n### 3. Comparison and Evaluation\n\nFor each test case, the procedure is:\n1. Compute $\\text{OPT}_{\\text{int}}$ using the knapsack DP.\n2. Solve the initial LP relaxation to get the root solution $\\hat{x}$.\n3. Generate a cut using the rounding-based heuristic. If a valid, violated cut is found, add it to the LP and re-solve to get $\\text{LP}_{\\text{round}}$. If no cut is found, $\\text{LP}_{\\text{round}}$ is the initial LP value.\n4. Generate a cut using the exact separation routine. If a valid, violated cut is found, add it to the initial LP and re-solve to get $\\text{LP}_{\\text{exact}}$. If no cut is found, $\\text{LP}_{\\text{exact}}$ is the initial LP value.\n5. Compute the relative gaps $\\text{gap}_{\\text{round}} = (\\text{LP}_{\\text{round}} - \\text{OPT}_{\\text{int}}) / \\text{OPT}_{\\text{int}}$ and $\\text{gap}_{\\text{exact}} = (\\text{LP}_{\\text{exact}} - \\text{OPT}_{\\text{int}}) / \\text{OPT}_{\\text{int}}$.\n6. Determine if the exact method provided a strictly better gap, i.e., $\\text{gap}_{\\text{exact}}  \\text{gap}_{\\text{round}}$.\n\nThis structured comparison allows for a quantitative assessment of the effectiveness of a simple heuristic versus an exact (but more computationally intensive) method for generating cutting planes.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases and prints the final result.\n    \"\"\"\n    test_cases = [\n        {\n            \"p\": np.array([20, 18, 14, 11], dtype=float),\n            \"a\": np.array([7, 6, 5, 4], dtype=int),\n            \"b\": 10\n        },\n        {\n            \"p\": np.array([9, 7, 5], dtype=float),\n            \"a\": np.array([5, 4, 3], dtype=int),\n            \"b\": 9\n        },\n        {\n            \"p\": np.array([28, 26, 21, 18, 16], dtype=float),\n            \"a\": np.array([10, 9, 7, 6, 5], dtype=int),\n            \"b\": 17\n        },\n    ]\n\n    all_results = []\n\n    def solve_knapsack_dp(p, a, b):\n        \"\"\"Solves the 0-1 knapsack problem using dynamic programming.\"\"\"\n        n = len(p)\n        dp = np.zeros((n + 1, b + 1), dtype=float)\n        for i in range(1, n + 1):\n            profit = p[i - 1]\n            weight = a[i - 1]\n            for w in range(b + 1):\n                if weight = w:\n                    dp[i, w] = max(dp[i - 1, w], profit + dp[i - 1, w - weight])\n                else:\n                    dp[i, w] = dp[i - 1, w]\n        return dp[n, b]\n\n    def solve_lp(p, A_ub, b_ub):\n        \"\"\"Helper function to solve the LP relaxation.\"\"\"\n        n = len(p)\n        c = -p\n        bounds = [(0, 1) for _ in range(n)]\n        # Using 'highs' for robustness and performance, as recommended by SciPy.\n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n        if res.success:\n            return -res.fun, res.x\n        else:\n            # For this problem, LPs should always be feasible.\n            raise RuntimeError(\"LP solver failed.\")\n\n    def rounding_cut_generator(x_hat, a, b):\n        \"\"\"Generates a cover inequality using a rounding-based heuristic.\"\"\"\n        n = len(a)\n        indices = np.argsort(-x_hat)\n        cover_s = []\n        current_weight = 0\n        for idx in indices:\n            cover_s.append(idx)\n            current_weight += a[idx]\n            if current_weight > b:\n                break\n        else:  # 'else' on a for-loop executes if the loop completed without break\n            return None # No cover found\n\n        violation = np.sum(x_hat[cover_s]) - (len(cover_s) - 1)\n        if violation > 1e-9:\n            return cover_s\n        return None\n\n    def exact_separation_generator(x_hat, a, b):\n        \"\"\"Finds the most violated cover inequality using dynamic programming.\"\"\"\n        n = len(a)\n        v = x_hat - 1  # Profits for the separation problem\n        total_weight = int(np.sum(a))\n        \n        # dp[i, w]: max value for items up to i-1 with exact weight w\n        dp = np.full((n + 1, total_weight + 1), -np.inf)\n        parent = {} # For backtracking\n        dp[0, 0] = 0\n\n        for i in range(1, n + 1):\n            profit = v[i - 1]\n            weight = a[i - 1]\n            for w in range(total_weight + 1):\n                # Case 1: Don't include item i-1\n                dp[i, w] = dp[i-1, w]\n                parent[(i, w)] = (i-1, w)\n\n                # Case 2: Include item i-1\n                if w >= weight:\n                    val_with_item = profit + dp[i-1, w - weight]\n                    if val_with_item > dp[i, w]:\n                        dp[i, w] = val_with_item\n                        parent[(i, w)] = (i-1, w - weight)\n\n        max_val = -np.inf\n        best_w = -1\n        capacity_limit = b + 1\n        \n        for w in range(capacity_limit, total_weight + 1):\n            if dp[n, w] > max_val:\n                max_val = dp[n, w]\n                best_w = w\n        \n        max_violation = max_val + 1\n        if max_violation > 1e-9:\n            # Backtrack to find the cover set\n            cover_s = []\n            curr_w = best_w\n            for i in range(n, 0, -1):\n                prev_i, prev_w = parent[(i, curr_w)]\n                if curr_w != prev_w: # This means item i-1 was taken\n                    cover_s.append(i-1)\n                    curr_w = prev_w\n            return cover_s\n        return None\n\n    for case in test_cases:\n        p, a, b = case[\"p\"], case[\"a\"], case[\"b\"]\n        n = len(p)\n        \n        opt_int = solve_knapsack_dp(p, a, b)\n        \n        A_orig = a.reshape(1, -1)\n        b_orig = np.array([b])\n        \n        lp_root_val, x_hat = solve_lp(p, A_orig, b_orig)\n\n        # Rounding-based cut path\n        S_round = rounding_cut_generator(x_hat, a, b)\n        lp_round_val = lp_root_val\n        if S_round:\n            cut_row = np.zeros(n)\n            cut_row[S_round] = 1\n            A_new = np.vstack([A_orig, cut_row])\n            b_new = np.append(b_orig, [len(S_round) - 1])\n            lp_round_val, _ = solve_lp(p, A_new, b_new)\n        \n        # Exact separation cut path\n        S_exact = exact_separation_generator(x_hat, a, b)\n        lp_exact_val = lp_root_val\n        if S_exact:\n            cut_row = np.zeros(n)\n            cut_row[S_exact] = 1\n            A_new = np.vstack([A_orig, cut_row])\n            b_new = np.append(b_orig, [len(S_exact) - 1])\n            lp_exact_val, _ = solve_lp(p, A_new, b_new)\n            \n        # Calculate gaps and comparison\n        if opt_int > 0:\n            gap_round = (lp_round_val - opt_int) / opt_int\n            gap_exact = (lp_exact_val - opt_int) / opt_int\n        else: # Handle case of zero optimal value to avoid division by zero\n            gap_round = lp_round_val if lp_round_val > 0 else 0.0\n            gap_exact = lp_exact_val if lp_exact_val > 0 else 0.0\n\n        exact_better = gap_exact  gap_round - 1e-9\n\n        all_results.append([round(gap_round, 6), round(gap_exact, 6), exact_better])\n\n    # Format the final output string exactly as requested.\n    result_str = \"[\" + \",\".join(f\"[{r[0]},{r[1]},{str(r[2]).lower()}]\" for r in all_results) + \"]\"\n    print(result_str.replace(\"True\", \"true\").replace(\"False\", \"false\"))\n\nsolve()\n```"
        }
    ]
}