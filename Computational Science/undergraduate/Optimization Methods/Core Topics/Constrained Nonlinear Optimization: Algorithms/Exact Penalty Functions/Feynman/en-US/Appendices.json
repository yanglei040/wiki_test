{
    "hands_on_practices": [
        {
            "introduction": "This first practice explores the theoretical heart of exact penalty methods. By analyzing a standard quadratic program, you will uncover the crucial link between the penalty parameter $\\rho$ and the Lagrange multiplier of the original constrained problem. This exercise will guide you through deriving the exactness condition from first principles, demonstrating why the penalty must be large enough to overcome the dual forces of the constraints .",
            "id": "3261558",
            "problem": "Consider the convex quadratic program (QP) with a single linear equality constraint: minimize the function $f(x)$ subject to the constraint $g(x)=0$, where $x \\in \\mathbb{R}^{2}$, \n$$\nf(x) \\equiv \\frac{1}{2} x_{1}^{2} + x_{2}^{2} - 4 x_{1} - 2 x_{2}, \\qquad g(x) \\equiv x_{1} + x_{2} - 1.\n$$\nBecause the Hessian matrix of $f$ is positive definite, the constrained problem has a unique optimal solution. Define the $\\ell_{1}$ exact penalty function $F_{\\rho}(x)$ with penalty parameter $\\rho \\ge 0$ by\n$$\nF_{\\rho}(x) \\equiv f(x) + \\rho \\, |g(x)|.\n$$\nWork from first principles as follows. First, determine the unique optimal solution $x^{\\star}$ and the associated Lagrange multiplier $\\lambda^{\\star}$ for the constrained QP using the Karush–Kuhn–Tucker (KKT) conditions. Next, use the subdifferential characterization of optimality for convex, possibly nonsmooth functions to establish the necessary and sufficient condition on the penalty parameter $\\rho$ for which $x^{\\star}$ is also a global minimizer of $F_{\\rho}(x)$. Finally, determine the minimum value of $\\rho$ that guarantees that minimizing $F_{\\rho}(x)$ recovers the constrained solution $x^{\\star}$. Express your final answer as an exact value (no rounding). The final answer must be a single real number.",
            "solution": "The problem is to find the minimum value of the penalty parameter $\\rho$ such that the unconstrained minimizer of the exact penalty function $F_{\\rho}(x) \\equiv f(x) + \\rho |g(x)|$ coincides with the optimal solution of the equality-constrained QP. The fundamental tools are the Karush–Kuhn–Tucker (KKT) conditions for the equality-constrained convex program and the subdifferential optimality condition for convex, possibly nonsmooth functions.\n\nStep 1: Solve the equality-constrained QP and find the Lagrange multiplier. The Lagrangian for the constrained problem is\n$$\n\\mathcal{L}(x,\\lambda) \\equiv f(x) + \\lambda\\, g(x)\n= \\frac{1}{2} x_{1}^{2} + x_{2}^{2} - 4 x_{1} - 2 x_{2} + \\lambda (x_{1} + x_{2} - 1).\n$$\nThe gradient with respect to $x$ is\n$$\n\\nabla_{x} \\mathcal{L}(x,\\lambda) = \\begin{pmatrix} x_{1} - 4 + \\lambda \\\\ 2 x_{2} - 2 + \\lambda \\end{pmatrix}.\n$$\nThe KKT conditions for the equality-constrained convex problem are stationarity and primal feasibility:\n$$\nx_{1} - 4 + \\lambda = 0, \\qquad 2 x_{2} - 2 + \\lambda = 0, \\qquad x_{1} + x_{2} = 1.\n$$\nFrom the first two equations,\n$$\nx_{1} = 4 - \\lambda, \\qquad x_{2} = \\frac{2 - \\lambda}{2} = 1 - \\frac{\\lambda}{2}.\n$$\nImposing feasibility $x_{1} + x_{2} = 1$ gives\n$$\n(4 - \\lambda) + \\left(1 - \\frac{\\lambda}{2}\\right) = 1 \\;\\;\\Longrightarrow\\;\\; 5 - \\frac{3}{2}\\lambda = 1 \\;\\;\\Longrightarrow\\;\\; \\lambda^{\\star} = \\frac{8}{3}.\n$$\nThen\n$$\nx_{1}^{\\star} = 4 - \\frac{8}{3} = \\frac{4}{3}, \\qquad x_{2}^{\\star} = 1 - \\frac{1}{2}\\cdot \\frac{8}{3} = 1 - \\frac{4}{3} = -\\frac{1}{3}.\n$$\nThus the unique solution is $x^{\\star} = \\big(\\frac{4}{3}, -\\frac{1}{3}\\big)$ with Lagrange multiplier $\\lambda^{\\star} = \\frac{8}{3}$.\n\nStep 2: Subdifferential optimality for the exact penalty function. The function $F_{\\rho}(x) = f(x) + \\rho |g(x)|$ is convex because it is the sum of a convex quadratic and a nonnegative multiple of a convex absolute value of an affine function. The subdifferential of $|t|$ at $t = 0$ is the interval $[-1, 1]$, and the chain rule for subgradients of compositions with affine maps gives\n$$\n\\partial \\big(\\rho |g(x)|\\big)\\big|_{g(x)=0} = \\rho \\, \\{ s \\, \\nabla g(x) : s \\in [-1,1] \\}.\n$$\nSince $g(x) = x_{1} + x_{2} - 1$, we have $\\nabla g(x) = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. The first-order optimality condition for a convex, possibly nonsmooth function $F_{\\rho}$ at a point $\\bar{x}$ is\n$$\n\\mathbf{0} \\in \\nabla f(\\bar{x}) + \\partial \\big(\\rho |g(\\bar{x})|\\big).\n$$\nWe investigate whether the constrained solution $x^{\\star}$ with $g(x^{\\star}) = 0$ can be a minimizer of $F_{\\rho}$. At $x^{\\star}$,\n$$\n\\mathbf{0} \\in \\nabla f(x^{\\star}) + \\rho \\, \\{ s \\, \\nabla g(x^{\\star}) : s \\in [-1,1] \\}.\n$$\nBy the KKT stationarity for the constrained problem, there exists $\\lambda^{\\star}$ such that\n$$\n\\nabla f(x^{\\star}) + \\lambda^{\\star} \\nabla g(x^{\\star}) = \\mathbf{0}.\n$$\nTherefore, the subgradient optimality condition at $x^{\\star}$ for $F_{\\rho}$ is equivalent to the existence of $s \\in [-1,1]$ with\n$$\n\\lambda^{\\star} = \\rho \\, s.\n$$\nSuch an $s$ exists if and only if $|\\lambda^{\\star}| \\le \\rho$.\n\nStep 3: Minimal penalty parameter. Since $F_{\\rho}$ is convex and $f$ is strongly convex, when the subgradient condition holds at $x^{\\star}$, the point $x^{\\star}$ is the unique global minimizer of $F_{\\rho}$. The necessary and sufficient condition for exactness at $x^{\\star}$ is $|\\lambda^{\\star}| \\le \\rho$. Hence, the minimum penalty parameter that guarantees recovery of $x^{\\star}$ by minimizing $F_{\\rho}$ is\n$$\n\\rho_{\\min} = |\\lambda^{\\star}| = \\left| \\frac{8}{3} \\right| = \\frac{8}{3}.\n$$\nTherefore, the required minimal value of the penalty parameter is $\\frac{8}{3}$.",
            "answer": "$$\\boxed{\\frac{8}{3}}$$"
        },
        {
            "introduction": "Why must the penalty parameter be \"sufficiently large\"? This exercise provides a vivid illustration by constructing a scenario with a carefully chosen objective function. You will investigate how an insufficient penalty can create \"spurious\" minima in the infeasible region, leading to an incorrect solution. This practice is designed to build your intuition about the competitive interplay between minimizing the objective function and satisfying the problem's constraints .",
            "id": "3126635",
            "problem": "Consider the constrained optimization problem in one dimension: minimize a cost function $f(x)$ subject to a single inequality constraint $g(x) \\leq 0$. The feasible set is $\\mathcal{F} = \\{x \\in \\mathbb{R} : x \\leq 0\\}$. Define the cost function $f$ to have a plateau on an infeasible interval by\n$$\nf(x) =\n\\begin{cases}\n5,  x \\leq 0, \\\\\n11,  0  x  1, \\\\\n1,  1 \\leq x \\leq 2, \\\\\n10 + (x-2)^2,  x  2,\n\\end{cases}\n$$\nand define the inequality constraint by $g(x) = x$, so $\\mathcal{F} = (-\\infty, 0]$. Consider the standard $\\ell_1$-type exact penalty function $P_\\mu(x) = f(x) + \\mu \\max\\{0, g(x)\\} = f(x) + \\mu \\max\\{0, x\\}$ with penalty parameter $\\mu  0$.\n\nStarting from the definitions of feasibility and exact penalty, analyze whether the penalized objective $P_\\mu$ can introduce spurious local minima away from the feasible set $\\mathcal{F}$ when $\\mu$ is insufficiently large, and determine the condition on $\\mu$ under which this occurs in the scenario above. Then choose the most accurate statement below.\n\nA. In this scenario, $x=1$ is a strict local minimizer of $P_\\mu$ that lies outside $\\mathcal{F}$. If $\\mu  4$, $x=1$ is also a global minimizer of $P_\\mu$, so insufficient $\\mu$ introduces an infeasible minimizer; for $\\mu \\geq 4$, all global minimizers are feasible, although the infeasible local minimum at $x=1$ remains higher than the feasible minimum.\n\nB. For any $\\mu  0$, $P_\\mu$ cannot have local minima outside $\\mathcal{F}$ because the penalty term always forces minimizers into $\\mathcal{F}$.\n\nC. Spurious local minima can only occur if $f$ is strictly convex on the infeasible region; a plateau in $f$ prevents infeasible local minima for any $\\mu$.\n\nD. Exact penalty functions are exact for all $\\mu  0$; therefore, the set of minimizers of $P_\\mu$ always coincides with the set of solutions to the constrained problem, regardless of the shape of $f$.",
            "solution": "To solve this problem, we must analyze the behavior of the exact penalty function $P_\\mu(x) = f(x) + \\mu \\max\\{0, x\\}$ and find its global minimizers.\n\n1.  **Analyze the original constrained problem.**\n    The problem is to minimize $f(x)$ subject to $x \\le 0$. The feasible set is $\\mathcal{F} = (-\\infty, 0]$. For any $x$ in this set, the cost function is constant: $f(x) = 5$. Therefore, the optimal value of the constrained problem is 5, and any point in $(-\\infty, 0]$ is a solution.\n\n2.  **Analyze the penalized function $P_\\mu(x)$.**\n    We examine the function in different regions.\n    *   **In the feasible region ($x \\le 0$):** Here, $\\max\\{0, x\\} = 0$, so the penalty function is simply $P_\\mu(x) = f(x) + 0 = 5$. The minimum value of $P_\\mu(x)$ in the feasible region is 5.\n    *   **In the infeasible region ($x > 0$):** Here, $\\max\\{0, x\\} = x$, so the penalty function becomes $P_\\mu(x) = f(x) + \\mu x$. We analyze this over the piecewise intervals of $f(x)$:\n        *   For $0  x  1$: $P_\\mu(x) = 11 + \\mu x$. This function is strictly increasing.\n        *   For $1 \\le x \\le 2$: $P_\\mu(x) = 1 + \\mu x$. This function is also strictly increasing. Its minimum on this interval is at $x=1$, where $P_\\mu(1) = 1 + \\mu$.\n        *   For $x > 2$: $P_\\mu(x) = 10 + (x-2)^2 + \\mu x$. Its derivative is $2(x-2) + \\mu$, which is strictly positive for $x > 2$ and $\\mu > 0$. So, the function is strictly increasing here as well.\n\n3.  **Identify spurious local minima.**\n    A spurious (infeasible) local minimum can occur where the function value is lower than in its immediate vicinity. Let's examine the point $x=1$.\n    *   $P_\\mu(1) = 1 + \\mu$.\n    *   For $x$ slightly greater than 1 (e.g., in $(1, 2]$), $P_\\mu(x) = 1 + \\mu x > 1 + \\mu = P_\\mu(1)$.\n    *   For $x$ slightly less than 1 (e.g., in $(0, 1)$), $P_\\mu(x) = 11 + \\mu x$. As $x \\to 1^-$, $P_\\mu(x) \\to 11 + \\mu$. Since $11 + \\mu > 1 + \\mu$, the function values to the immediate left of $x=1$ are higher than at $x=1$.\n    Therefore, $x=1$ is a strict local minimizer for any $\\mu > 0$. Since $x=1$ is infeasible, it is a spurious local minimum.\n\n4.  **Find the condition for a spurious global minimum.**\n    For the penalty method to fail, this spurious local minimum at $x=1$ must be a global minimum. This happens if its value is less than the minimum value in the feasible region.\n    $$ P_\\mu(1)  \\min_{x \\le 0} P_\\mu(x) $$\n    $$ 1 + \\mu  5 \\implies \\mu  4 $$\n    If $\\mu  4$, the global minimum of $P_\\mu(x)$ is at the infeasible point $x=1$. If $\\mu \\ge 4$, the global minimum value is 5, which is achieved in the feasible set $(-\\infty, 0]$. (At the boundary case $\\mu=4$, $x=1$ is also a global minimizer, so the set of global minimizers includes an infeasible point).\n\n5.  **Evaluate the options.**\n    *   **A:** This statement correctly identifies that $x=1$ is a spurious local minimizer. It correctly states that if $\\mu  4$, $x=1$ becomes the global minimizer. It also correctly notes that for $\\mu \\ge 4$, the infeasible local minimum at $x=1$ has a value greater than or equal to the feasible minimum. This aligns perfectly with our analysis.\n    *   **B:** This is false. We found a spurious local minimum at $x=1$.\n    *   **C:** This is false. The plateaus in $f(x)$ are what create the spurious minimum at the jump discontinuity.\n    *   **D:** This is false. The core idea of exact penalty functions is that exactness is only guaranteed for a *sufficiently large* $\\mu$. Our analysis shows the method is not exact for $\\mu  4$.\n\nThus, option A is the most accurate description.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "This final practice transitions from analytical theory to computational practice. You will implement the proximal gradient method, a powerful modern algorithm for solving non-smooth optimization problems like those arising from exact penalties. This exercise requires you to derive the necessary components from first principles and then apply your code to test cases, verifying the theoretical exactness conditions you have learned through concrete numerical results .",
            "id": "3126615",
            "problem": "Consider the constrained optimization problem in $\\mathbb{R}^n$:\nminimize $f(x)$ subject to $x \\ge 0$ coordinate-wise, where $f(x) = \\frac{1}{2}\\lVert x - c \\rVert_2^2$ for a given vector $c \\in \\mathbb{R}^n$. An exact penalty approach replaces the constraints with a nonsmooth penalty $\\psi_\\mu(x) = \\mu \\sum_{i=1}^n \\max(0,-x_i)$, and minimizes the penalized objective $P_\\mu(x) = f(x) + \\psi_\\mu(x)$ for a penalty parameter $\\mu  0$. The proximal gradient method (Proximal Gradient (PG)) for minimizing $P_\\mu$ with a constant step-size $s  0$ alternates a gradient step on $f$ and a proximal step on $\\psi_\\mu$. Use only the following fundamental bases: the definition of the proximal operator, the definition of the gradient, the concept of Lipschitz continuity of gradients, and the Karush-Kuhn-Tucker (KKT) optimality conditions.\n\nTasks:\n1. Derive from first principles the proximal operator of the function $\\psi_\\mu(x)$, coordinate-wise, using only its definition and elementary calculus. You must not use any pre-derived \"shortcut\" formulas. The proximal operator of a function $\\phi$ at a point $y$ with parameter $t  0$ is defined by $\\operatorname{prox}_{t\\phi}(y) = \\arg\\min_{x} \\left\\{ \\frac{1}{2}\\lVert x - y \\rVert_2^2 + t \\phi(x) \\right\\}$.\n2. Using your derivation, implement the proximal gradient iteration for the composite function $P_\\mu(x) = f(x) + \\psi_\\mu(x)$, starting from $x^{(0)} = 0$, with a constant step-size $s$ satisfying $0  s \\le 1$. The gradient of $f$ must be derived from its definition.\n3. For a given $c$ and $\\mu$, determine whether the exact penalty is \"exact,\" meaning that the minimizer of $P_\\mu$ coincides with the solution to the constrained problem $\\min_{x \\ge 0} f(x)$. Use the Karush-Kuhn-Tucker (KKT) conditions to identify the threshold on $\\mu$ (in terms of the optimal multipliers) that guarantees exactness. In this special case, this threshold can be expressed in terms of the data $c$.\n4. For each test case below, run the proximal gradient method until convergence (you may stop when the successive iterates differ in $\\ell_2$-norm by less than $10^{-12}$ or after a maximum of $2000$ iterations, whichever comes first). Compare the final iterate to:\n   - the constrained solution $x^\\star_{\\text{con}} = \\arg\\min_{x \\ge 0} f(x)$ in cases where the penalty is exact (i.e., $\\mu$ at or above the threshold), and\n   - the unique minimizer of $P_\\mu$ in cases where the penalty is not exact (i.e., $\\mu$ below the threshold). In this separable setting, derive this minimizer coordinate-wise from first principles.\n5. Your program must output a single line containing a comma-separated list of the $\\ell_2$-norm differences between the final iterate and the appropriate target solution for each test case, enclosed in square brackets. Each number must be rounded to eight decimal places, with no spaces.\n\nDefinitions and facts to use as the fundamental base:\n- The proximal operator definition: $\\operatorname{prox}_{t\\phi}(y) = \\arg\\min_{x} \\left\\{ \\frac{1}{2}\\lVert x - y \\rVert_2^2 + t \\phi(x) \\right\\}$.\n- The gradient of $f(x) = \\frac{1}{2}\\lVert x - c \\rVert_2^2$ is $\\nabla f(x) = x - c$, derived from the definition of the gradient.\n- If $\\nabla f$ is $L$-Lipschitz continuous, then a constant step-size $s$ satisfying $0  s \\le \\frac{1}{L}$ ensures convergence of proximal gradient to a minimizer under standard convexity assumptions. In this problem, $L = 1$.\n- Exactness of the $\\ell_1$-type penalty hinges on choosing $\\mu$ not less than the largest optimal Lagrange multiplier from the Karush-Kuhn-Tucker (KKT) conditions of the constrained problem.\n\nTest suite:\n- Test case $1$: $c = [-2.0, 1.5, -0.3]$, $\\mu = 2.0$, $s = 1.0$. Use the constrained solution as the target.\n- Test case $2$: $c = [-2.0, 1.5, -0.3]$, $\\mu = 2.5$, $s = 0.25$. Use the constrained solution as the target.\n- Test case $3$: $c = [-2.0, -0.5]$, $\\mu = 0.7$, $s = 0.5$. Use the penalized minimizer as the target.\n- Test case $4$: $c = [0.0, -10^{-8}, 3\\cdot 10^{-9}]$, $\\mu = 10^{-8}$, $s = 1.0$. Use the constrained solution as the target.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each number rounded to eight decimal places and with no spaces, for example, $\"[0.00000000,0.12345678,0.00000001]\"$.",
            "solution": "This problem requires several analytical derivations followed by a numerical implementation.\n\n**1. Derivation of the Proximal Operator**\nThe proximal operator for the penalty term $\\psi_\\mu(x)$ with step-size $s$ is $\\operatorname{prox}_{s\\psi_\\mu}(y)$. Since $\\psi_\\mu(x)$ is separable, we can derive the operator coordinate-wise. For each coordinate $i$, we solve:\n$$ \\arg\\min_{x_i \\in \\mathbb{R}} \\left\\{ \\frac{1}{2}(x_i - y_i)^2 + s \\mu \\max(0, -x_i) \\right\\} $$\nLet $h(x_i) = \\frac{1}{2}(x_i - y_i)^2 + s \\mu \\max(0, -x_i)$. We analyze two cases:\n*   **Case A: $x_i \\ge 0$.** The problem becomes $\\min_{x_i \\ge 0} \\frac{1}{2}(x_i - y_i)^2$. The unconstrained minimizer is $x_i=y_i$. If $y_i \\ge 0$, this is the solution. If $y_i  0$, the minimum on $[0, \\infty)$ is at the boundary, $x_i=0$.\n*   **Case B: $x_i  0$.** The problem becomes $\\min_{x_i  0} \\frac{1}{2}(x_i - y_i)^2 - s \\mu x_i$. The derivative is $(x_i - y_i) - s\\mu$. Setting to zero gives the minimizer $x_i = y_i + s\\mu$. This solution is valid if $y_i + s\\mu  0$, i.e., $y_i  -s\\mu$.\n\nCombining these results:\n*   If $y_i \\ge 0$, the solution is $x_i = y_i$.\n*   If $y_i \\le -s\\mu$, the solution is $x_i = y_i + s\\mu$.\n*   If $-s\\mu  y_i  0$, the minimum in Case A is at $x_i=0$, and the unconstrained minimum for Case B ($y_i+s\\mu$) is positive, meaning the minimum on $(-\\infty, 0)$ is at the boundary $x_i=0$. Thus, the overall minimum is at $x_i = 0$.\n\nThe coordinate-wise proximal operator is:\n$$ [\\operatorname{prox}_{s\\psi_\\mu}(y)]_i = \\begin{cases} y_i  \\text{if } y_i \\ge 0 \\\\ 0  \\text{if } -s\\mu  y_i  0 \\\\ y_i + s\\mu  \\text{if } y_i \\le -s\\mu \\end{cases} $$\n\n**2. Proximal Gradient Iteration**\nThe iteration is $x^{(k+1)} = \\operatorname{prox}_{s\\psi_\\mu}(x^{(k)} - s \\nabla f(x^{(k)}))$.\nGiven $f(x) = \\frac{1}{2}\\|x-c\\|_2^2$, the gradient is $\\nabla f(x) = x - c$. The argument to the prox operator is $y^{(k)} = x^{(k)} - s(x^{(k)} - c) = (1-s)x^{(k)} + sc$.\n\n**3. Analysis of Exactness and Target Solutions**\nWe must determine the appropriate target solution for each test case.\n*   **Constrained Solution ($x^\\star_{\\text{con}}$):** The problem is $\\min_{x \\ge 0} \\frac{1}{2}\\|x-c\\|_2^2$. This is a projection onto the non-negative orthant. The solution is found coordinate-wise: $x^\\star_{\\text{con}, i} = \\max(0, c_i)$. The optimal Lagrange multipliers from the KKT conditions are $\\lambda_i^\\star = \\max(0, -c_i)$.\n*   **Penalized Solution ($x^\\star_{\\text{pen}}$):** The minimizer of $P_\\mu(x)$ is found by setting the subgradient to zero: $0 \\in x - c + \\mu \\partial(\\sum \\max(0, -x_i))$. This also separates by coordinate, yielding:\n$$ x^\\star_{\\text{pen}, i} = \\begin{cases} c_i  \\text{if } c_i  0 \\\\ 0  \\text{if } -\\mu \\le c_i \\le 0 \\\\ c_i + \\mu  \\text{if } c_i  -\\mu \\end{cases} $$\n*   **Exactness Condition:** The penalty is exact if $x^\\star_{\\text{pen}} = x^\\star_{\\text{con}}$. Comparing the solutions, they are identical if and only if for all $i$ with $c_i  0$, we have $-\\mu \\le c_i$. This is equivalent to $\\mu \\ge -c_i$ for all such $i$. The condition for exactness is $\\mu \\ge \\max_{i} \\max(0, -c_i) = \\max_i \\lambda_i^\\star$.\n\n**4. Analysis for Test Cases**\n*   **Case 1:** $c = [-2.0, 1.5, -0.3]$, $\\mu = 2.0$. Critical $\\mu$ is $\\mu_{\\text{crit}} = \\max(2.0, 0, 0.3) = 2.0$. Since $\\mu \\ge \\mu_{\\text{crit}}$, the penalty is exact. Target is $x^\\star_{\\text{con}} = [\\max(0,-2), \\max(0,1.5), \\max(0,-0.3)] = [0, 1.5, 0]$.\n*   **Case 2:** $c = [-2.0, 1.5, -0.3]$, $\\mu = 2.5$. $\\mu_{\\text{crit}} = 2.0$. Since $\\mu > \\mu_{\\text{crit}}$, penalty is exact. Target is $x^\\star_{\\text{con}} = [0, 1.5, 0]$.\n*   **Case 3:** $c = [-2.0, -0.5]$, $\\mu = 0.7$. $\\mu_{\\text{crit}} = \\max(2.0, 0.5) = 2.0$. Since $\\mu  \\mu_{\\text{crit}}$, penalty is not exact. Target is $x^\\star_{\\text{pen}}$.\n    *   $c_1=-2.0  -\\mu=-0.7 \\implies x_1 = c_1+\\mu = -1.3$.\n    *   $c_2=-0.5 \\in [-\\mu, 0] \\implies x_2 = 0$.\n    *   Target is $[-1.3, 0]$.\n*   **Case 4:** $c = [0.0, -10^{-8}, 3\\cdot 10^{-9}]$, $\\mu = 10^{-8}$. $\\mu_{\\text{crit}} = \\max(0, 10^{-8}, 0) = 10^{-8}$. Since $\\mu \\ge \\mu_{\\text{crit}}$, penalty is exact. Target is $x^\\star_{\\text{con}} = [\\max(0,0), \\max(0,-10^{-8}), \\max(0,3\\cdot 10^{-9})] = [0, 0, 3\\cdot 10^{-9}]$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the optimization problem for a suite of test cases using the\n    Proximal Gradient method with an exact penalty function.\n    \"\"\"\n\n    test_cases = [\n        {'c': np.array([-2.0, 1.5, -0.3]), 'mu': 2.0, 's': 1.0},\n        {'c': np.array([-2.0, 1.5, -0.3]), 'mu': 2.5, 's': 0.25},\n        {'c': np.array([-2.0, -0.5]), 'mu': 0.7, 's': 0.5},\n        {'c': np.array([0.0, -1e-8, 3e-9]), 'mu': 1e-8, 's': 1.0},\n    ]\n\n    results = []\n    \n    # Convergence parameters\n    max_iter = 2000\n    tol = 1e-12\n\n    for case in test_cases:\n        c, mu, s = case['c'], case['mu'], case['s']\n        \n        # --- Determine the target solution ---\n        # The critical penalty parameter is the max of the optimal Lagrange multipliers\n        mu_crit = np.max(np.maximum(0, -c))\n        \n        target_solution = np.zeros_like(c)\n        if mu >= mu_crit:\n            # Exact penalty: target is the solution to the constrained problem\n            # x*_con = max(0, c_i) for each component\n            target_solution = np.maximum(0, c)\n        else:\n            # Not exact: target is the minimizer of the penalized problem\n            # x*_pen,i = c_i if c_i > 0\n            # x*_pen,i = 0 if -mu = c_i = 0\n            # x*_pen,i = c_i + mu if c_i  -mu\n            x_pen = np.zeros_like(c)\n            mask_pos = c > 0\n            mask_neg_small = (-mu = c)  (c = 0)\n            mask_neg_large = c  -mu\n            \n            x_pen[mask_pos] = c[mask_pos]\n            x_pen[mask_neg_small] = 0.0\n            x_pen[mask_neg_large] = c[mask_neg_large] + mu\n            target_solution = x_pen\n\n        # --- Proximal Gradient Method ---\n        x = np.zeros_like(c)\n        for _ in range(max_iter):\n            x_prev = x.copy()\n            \n            # Gradient step for the smooth part f(x)\n            # y = x - s * grad(f(x)) = x - s * (x - c)\n            y = (1 - s) * x + s * c\n            \n            # Proximal step for the non-smooth part psi_mu(x)\n            # prox(y)_i = y_i if y_i >= 0\n            # prox(y)_i = 0 if -s*mu  y_i  0\n            # prox(y)_i = y_i + s*mu if y_i = -s*mu\n            x = np.zeros_like(y)\n            mask_pos = y >= 0\n            mask_neg = y = -s * mu\n            \n            x[mask_pos] = y[mask_pos]\n            x[mask_neg] = y[mask_neg] + s * mu\n            \n            # Check for convergence\n            if np.linalg.norm(x - x_prev)  tol:\n                break\n        \n        # Calculate the L2 norm of the difference\n        diff = np.linalg.norm(x - target_solution)\n        results.append(f\"{diff:.8f}\")\n\n    # Print the final result in the specified format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}