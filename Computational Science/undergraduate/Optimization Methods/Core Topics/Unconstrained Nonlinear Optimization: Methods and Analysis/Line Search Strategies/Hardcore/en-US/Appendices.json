{
    "hands_on_practices": [
        {
            "introduction": "To build a strong foundation, we begin with a core exercise that connects the theoretical ideal of an exact line search to the practical reality of an inexact one. For the special case of a quadratic function, which forms the basis of many advanced optimization methods, it is possible to derive a closed-form expression for the perfect step size, $\\alpha^\\star$, that exactly minimizes the function along a given search direction. This practice challenges you to derive this optimal step and compare it with the step size accepted by the widely-used Armijo backtracking rule, providing a concrete benchmark for understanding the mechanics and trade-offs of inexact search strategies. ",
            "id": "3143370",
            "problem": "Consider the quadratic function $f(x) = \\tfrac{1}{2} x^{\\top} Q x + b^{\\top} x$ with $Q \\in \\mathbb{R}^{2 \\times 2}$ symmetric and positive definite and $b \\in \\mathbb{R}^{2}$. Let\n$$\nQ = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix}, \\quad b = \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}, \\quad x_{k} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}.\n$$\nDefine the search direction $p$ to be the negative gradient at $x_{k}$, that is $p = - \\nabla f(x_{k})$.\n\nTasks:\n- Starting from the definition of exact line search along a direction, treat $\\varphi(\\alpha) = f(x_{k} + \\alpha p)$ as a univariate function of $\\alpha \\in \\mathbb{R}$ and, using only core definitions (the gradient of $f$, the directional derivative, and first-order optimality for a univariate quadratic), derive the closed-form optimizer $\\alpha^{\\star}$ in terms of $Q$, $\\nabla f(x_{k})$, and $p$.\n- Evaluate the derived $\\alpha^{\\star}$ for the specific $Q$, $b$, $x_{k}$, and $p$ given above.\n- Using the Armijo backtracking rule (also called the sufficient decrease rule) with parameters $c = \\tfrac{1}{4}$, $\\rho = \\tfrac{1}{2}$, and initial trial step $\\alpha_{0} = 1$, determine the first accepted step size $\\alpha_{\\mathrm{BT}}$ along $p$ starting from $x_{k}$. The Armijo condition to be checked at each candidate $\\alpha$ is\n$$\nf(x_{k} + \\alpha p) \\leq f(x_{k}) + c \\, \\alpha \\, \\nabla f(x_{k})^{\\top} p.\n$$\n- Report the ratio $\\alpha_{\\mathrm{BT}} / \\alpha^{\\star}$ as a simplified exact fraction. Provide your final answer as this single ratio. No rounding is required.",
            "solution": "The user has provided a problem statement that requires validation before proceeding to a solution.\n\n### Step 1: Extract Givens\nThe problem provides the following information:\n- A quadratic function $f(x) = \\frac{1}{2} x^{\\top} Q x + b^{\\top} x$.\n- The matrix $Q = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix}$ is a symmetric and positive definite matrix in $\\mathbb{R}^{2 \\times 2}$.\n- The vector $b = \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$ is a vector in $\\mathbb{R}^{2}$.\n- The current point is $x_{k} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$.\n- The search direction is defined as $p = - \\nabla f(x_{k})$.\n- An exact line search seeks to find $\\alpha^{\\star}$ that minimizes the univariate function $\\varphi(\\alpha) = f(x_{k} + \\alpha p)$.\n- A backtracking line search is to be performed using the Armijo rule with parameters $c = \\frac{1}{4}$, $\\rho = \\frac{1}{2}$, and an initial trial step size $\\alpha_{0} = 1$.\n- The Armijo condition is specified as $f(x_{k} + \\alpha p) \\leq f(x_{k}) + c \\, \\alpha \\, \\nabla f(x_{k})^{\\top} p$.\n- The final output should be the ratio $\\frac{\\alpha_{\\mathrm{BT}}}{\\alpha^{\\star}}$ as a simplified exact fraction.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to a rigorous validation process.\n- **Scientific Grounding**: The problem is located within the well-established field of numerical optimization. The function, concepts (gradient descent, line search), and methods (exact and backtracking) are all standard topics in optimization theory. The provided matrix $Q$ is symmetric, and its principal minors are $\\det(4) = 4  0$ and $\\det(Q) = (4)(3) - (1)(1) = 11  0$, confirming it is positive definite. This ensures the function $f(x)$ is strictly convex, which is a standard assumption for these methods. The problem is thus scientifically and mathematically sound.\n- **Well-Posedness**: The problem is clearly stated and provides all necessary data and definitions to find a unique solution. The function is defined, the starting point is given, the search direction rule is explicit, and the parameters for the backtracking algorithm are all specified.\n- **Objectivity**: The problem is stated in precise mathematical language, free from any subjectivity or ambiguity.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid** as it is self-contained, scientifically sound, objective, and well-posed. A solution will be provided.\n\n### Solution Derivation\n\nThe solution process consists of four main parts as requested by the problem statement.\n\n**Part 1: Derivation of the exact line search step size $\\alpha^{\\star}$**\n\nThe univariate function to be minimized is $\\varphi(\\alpha) = f(x_{k} + \\alpha p)$, where $\\alpha \\in \\mathbb{R}$. We substitute the expression for $f(x)$ into $\\varphi(\\alpha)$:\n$$\n\\varphi(\\alpha) = \\frac{1}{2} (x_{k} + \\alpha p)^{\\top} Q (x_{k} + \\alpha p) + b^{\\top} (x_{k} + \\alpha p)\n$$\nExpanding this expression, we get:\n$$\n\\varphi(\\alpha) = \\frac{1}{2} (x_{k}^{\\top}Qx_{k} + \\alpha x_{k}^{\\top}Qp + \\alpha p^{\\top}Qx_{k} + \\alpha^2 p^{\\top}Qp) + b^{\\top}x_{k} + \\alpha b^{\\top}p\n$$\nSince $Q$ is symmetric, $x_{k}^{\\top}Qp = (p^{\\top}Q^{\\top}x_{k})^{\\top} = (p^{\\top}Qx_{k})^{\\top}$. As this is a scalar, it equals $p^{\\top}Qx_{k}$. We can group the terms by powers of $\\alpha$:\n$$\n\\varphi(\\alpha) = \\left(\\frac{1}{2} p^{\\top}Qp\\right)\\alpha^2 + (p^{\\top}Qx_{k} + b^{\\top}p)\\alpha + \\left(\\frac{1}{2}x_{k}^{\\top}Qx_{k} + b^{\\top}x_{k}\\right)\n$$\nThe gradient of $f(x)$ is $\\nabla f(x) = Qx + b$. The term linear in $\\alpha$ can be rewritten as:\n$$\np^{\\top}Qx_{k} + b^{\\top}p = p^{\\top}(Qx_{k} + b) = p^{\\top}\\nabla f(x_k)\n$$\nThe constant term is simply $f(x_k)$. Thus, $\\varphi(\\alpha)$ is a quadratic function of $\\alpha$:\n$$\n\\varphi(\\alpha) = \\left(\\frac{1}{2} p^{\\top}Qp\\right)\\alpha^2 + \\left(p^{\\top}\\nabla f(x_k)\\right)\\alpha + f(x_k)\n$$\nTo find the minimizer $\\alpha^{\\star}$, we take the derivative with respect to $\\alpha$ and set it to zero.\n$$\n\\varphi'(\\alpha) = ( p^{\\top}Qp )\\alpha + p^{\\top}\\nabla f(x_k) = 0\n$$\nSolving for $\\alpha$ gives the optimal step size $\\alpha^{\\star}$:\n$$\n\\alpha^{\\star} = - \\frac{p^{\\top}\\nabla f(x_k)}{p^{\\top}Qp}\n$$\nThe second derivative is $\\varphi''(\\alpha) = p^{\\top}Qp$. Since $Q$ is positive definite and $p \\neq 0$ (as we are not at the optimum), $p^{\\top}Qp  0$, confirming that $\\alpha^{\\star}$ is indeed a minimizer. The problem defines $p = -\\nabla f(x_k)$, so we can also write $\\alpha^{\\star}$ as:\n$$\n\\alpha^{\\star} = - \\frac{(-\\nabla f(x_k))^{\\top}\\nabla f(x_k)}{(-\\nabla f(x_k))^{\\top}Q(-\\nabla f(x_k))} = \\frac{\\nabla f(x_k)^{\\top}\\nabla f(x_k)}{\\nabla f(x_k)^{\\top}Q\\nabla f(x_k)}\n$$\nWe will use the form involving $p$ for the calculations.\n\n**Part 2: Evaluation of $\\alpha^{\\star}$**\n\nFirst, we calculate the gradient $\\nabla f(x_k)$ at $x_{k} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$:\n$$\n\\nabla f(x_k) = Qx_k + b = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 1 \\end{pmatrix} + \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}\n$$\nThe search direction is $p = -\\nabla f(x_k)$:\n$$\np = - \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ -2 \\end{pmatrix}\n$$\nNow we compute the terms in the formula for $\\alpha^{\\star}$:\nThe numerator is $p^{\\top}\\nabla f(x_k)$:\n$$\np^{\\top}\\nabla f(x_k) = \\begin{pmatrix} -2  -2 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix} = (-2)(2) + (-2)(2) = -4 - 4 = -8\n$$\nThe denominator is $p^{\\top}Qp$:\n$$\nQp = \\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix} \\begin{pmatrix} -2 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} 4(-2) + 1(-2) \\\\ 1(-2) + 3(-2) \\end{pmatrix} = \\begin{pmatrix} -8 - 2 \\\\ -2 - 6 \\end{pmatrix} = \\begin{pmatrix} -10 \\\\ -8 \\end{pmatrix}\n$$\n$$\np^{\\top}Qp = \\begin{pmatrix} -2  -2 \\end{pmatrix} \\begin{pmatrix} -10 \\\\ -8 \\end{pmatrix} = (-2)(-10) + (-2)(-8) = 20 + 16 = 36\n$$\nFinally, we calculate $\\alpha^{\\star}$:\n$$\n\\alpha^{\\star} = - \\frac{-8}{36} = \\frac{8}{36} = \\frac{2}{9}\n$$\n\n**Part 3: Determination of the backtracking step size $\\alpha_{\\mathrm{BT}}$**\n\nThe Armijo backtracking condition is $f(x_{k} + \\alpha p) \\leq f(x_{k}) + c \\, \\alpha \\, \\nabla f(x_{k})^{\\top} p$.\nThe parameters are $c = \\frac{1}{4}$, $\\rho = \\frac{1}{2}$, and $\\alpha_0 = 1$.\nLet's evaluate the terms in the inequality.\nThe value of the function at $x_k$ is:\n$$\nf(x_k) = \\frac{1}{2}x_{k}^{\\top}Qx_{k} + b^{\\top}x_{k} = \\frac{1}{2}\\begin{pmatrix} 1  0 \\end{pmatrix}\\begin{pmatrix} 4  1 \\\\ 1  3 \\end{pmatrix}\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} -2  1 \\end{pmatrix}\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\frac{1}{2}(4) + (-2) = 2 - 2 = 0\n$$\nThe right-hand side (RHS) of the Armijo condition is:\n$$\n\\text{RHS} = f(x_k) + c \\alpha \\nabla f(x_k)^{\\top} p = 0 + \\left(\\frac{1}{4}\\right)\\alpha(-8) = -2\\alpha\n$$\nFrom Part 1, the left-hand side (LHS) is $\\varphi(\\alpha) = f(x_k + \\alpha p) = (\\frac{1}{2} p^{\\top}Qp)\\alpha^2 + (p^{\\top}\\nabla f(x_k))\\alpha + f(x_k)$. Using the values we found:\n$$\n\\text{LHS} = \\frac{1}{2}(36)\\alpha^2 + (-8)\\alpha + 0 = 18\\alpha^2 - 8\\alpha\n$$\nThe Armijo condition becomes:\n$$\n18\\alpha^2 - 8\\alpha \\leq -2\\alpha\n$$\n$$\n18\\alpha^2 - 6\\alpha \\leq 0\n$$\n$$\n6\\alpha(3\\alpha - 1) \\leq 0\n$$\nSince the step size $\\alpha$ must be positive, we can divide by $6\\alpha$ without changing the inequality direction:\n$$\n3\\alpha - 1 \\leq 0 \\implies \\alpha \\leq \\frac{1}{3}\n$$\nNow we perform the backtracking search starting with $\\alpha_0 = 1$:\n- **Try $\\alpha = 1$**: Is $1 \\leq \\frac{1}{3}$? No. The condition is not satisfied. Update $\\alpha \\leftarrow \\rho \\alpha = \\frac{1}{2} \\times 1 = \\frac{1}{2}$.\n- **Try $\\alpha = \\frac{1}{2}$**: Is $\\frac{1}{2} \\leq \\frac{1}{3}$? No. (Since $3 \\leq 2$ is false). The condition is not satisfied. Update $\\alpha \\leftarrow \\rho \\alpha = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}$.\n- **Try $\\alpha = \\frac{1}{4}$**: Is $\\frac{1}{4} \\leq \\frac{1}{3}$? Yes. (Since $3 \\leq 4$ is true). The condition is satisfied.\nThe first accepted step size is $\\alpha_{\\mathrm{BT}} = \\frac{1}{4}$.\n\n**Part 4: Calculation of the ratio**\n\nThe final task is to compute the ratio $\\frac{\\alpha_{\\mathrm{BT}}}{\\alpha^{\\star}}$:\n$$\n\\frac{\\alpha_{\\mathrm{BT}}}{\\alpha^{\\star}} = \\frac{\\frac{1}{4}}{\\frac{2}{9}} = \\frac{1}{4} \\times \\frac{9}{2} = \\frac{9}{8}\n$$\nThe ratio is required as a simplified exact fraction.",
            "answer": "$$\\boxed{\\frac{9}{8}}$$"
        },
        {
            "introduction": "Real-world optimization problems are rarely as well-behaved as simple quadratics. Algorithms must be robust enough to handle difficult function landscapes, such as extremely flat regions where the gradient is nearly zero. In this thought experiment, we analyze how a standard backtracking line search behaves on a function with such a plateau. By examining the Armijo condition using a Taylor expansion, you will discover potential numerical pitfalls and understand why practical implementations require safeguards, like a minimum step size, to ensure progress and prevent stalling due to finite-precision arithmetic. ",
            "id": "3143423",
            "problem": "Consider the one-dimensional function $f(x) = \\log\\!\\big(1 + e^{a x}\\big)$ with a fixed constant $a  0$. A line search is performed along a descent direction $p \\in \\mathbb{R}$ from a current iterate $x$ using the standard backtracking strategy with parameters $c \\in (0,1)$ and $\\rho \\in (0,1)$. The backtracking line search attempts to find a step size $\\alpha$ such that the Armijo sufficient decrease condition holds:\n$$\nf(x + \\alpha p) \\leq f(x) + c \\, \\alpha \\, \\nabla f(x)^{\\top} p.\n$$\nAssume $x$ is in the flat plateau region, i.e., $x \\ll 0$, so that both the gradient and curvature of $f$ are small. For analysis, take the governing base as follows: (i) first principles definitions of gradient and Hessian, where $\\nabla f(x) = f'(x)$ and $\\nabla^{2} f(x) = f''(x)$ and (ii) the second-order Taylor expansion with remainder for twice continuously differentiable functions, which implies for sufficiently small $\\alpha$,\n$$\nf(x + \\alpha p) \\approx f(x) + \\alpha \\, \\nabla f(x)^{\\top} p + \\tfrac{1}{2} \\alpha^{2} p^{\\top} \\nabla^{2} f(x) p.\n$$\nYou will analyze how backtracking behaves when the directional derivative $d := \\nabla f(x)^{\\top} p$ is tiny and propose safeguards for the minimal step size $\\alpha$.\n\nCompute $f'(x)$ and $f''(x)$ symbolically, and use their asymptotic behavior for $x \\ll 0$ to reason about the Armijo condition. Then evaluate the following statements and select all that are correct.\n\nA) For steepest descent, i.e., $p = -\\nabla f(x)$, in the plateau region the Armijo condition is typically easy to satisfy with an $\\alpha$ of order one (e.g., the initial trial step), even though $\\nabla f(x)^{\\top} p$ is tiny, because the curvature $p^{\\top} \\nabla^{2} f(x) p$ is also tiny; consequently the accepted $\\alpha$ can be large while the actual step $\\alpha p$ is very small in norm.\n\nB) If instead one uses a fixed-norm descent direction $p = -1$ (independent of $\\|\\nabla f(x)\\|$), the second-order analysis of the Armijo condition yields an upper bound on admissible step sizes of the form\n$$\n\\alpha \\leq \\frac{2(1-c)\\big(-\\nabla f(x)^{\\top} p\\big)}{p^{\\top} \\nabla^{2} f(x) p},\n$$\nwhich, for $f(x) = \\log(1+e^{a x})$ at $x \\ll 0$, simplifies to an $\\mathcal{O}(1/a)$ constant that does not vanish as $x \\to -\\infty$.\n\nC) A principled safeguard against pathological shrinkage of $\\alpha$ during backtracking when $\\nabla f(x)^{\\top} p$ is tiny is to impose a lower bound $\\alpha_{\\min}  0$ such that the guaranteed decrease $c \\, \\alpha_{\\min} \\big(-\\nabla f(x)^{\\top} p\\big)$ exceeds a chosen threshold tied to numerical noise (for example, comparable to the function-evaluation precision); if repeated backtracking would push $\\alpha$ below $\\alpha_{\\min}$, the algorithm should either accept $\\alpha_{\\min}$ and proceed or switch strategy (for example, restart, rescale the direction, or terminate).\n\nD) Increasing the Armijo parameter $c$ closer to $1$ makes the Armijo condition easier to satisfy when $\\nabla f(x)^{\\top} p$ is tiny and therefore reduces the number of backtracking steps.\n\nE) On the plateau of $f(x) = \\log(1+e^{a x})$ at large negative $x$, the curvature is so small that the strong Wolfe curvature condition, namely $\\big|\\nabla f(x+\\alpha p)^{\\top} p\\big| \\leq c_{2} \\big|\\nabla f(x)^{\\top} p\\big|$ with $c_{2} \\in (c,1)$, is automatically satisfied for any $\\alpha  0$ along any descent direction.\n\nSelect all correct options.",
            "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded in the field of numerical optimization, well-posed, objective, and internally consistent. We may proceed with the solution.\n\nFirst, we compute the first and second derivatives of the function $f(x) = \\log(1 + e^{ax})$ with respect to $x$, for a constant $a  0$.\nUsing the chain rule, the first derivative (gradient in one dimension) is:\n$$\n\\nabla f(x) = f'(x) = \\frac{1}{1 + e^{ax}} \\cdot \\frac{d}{dx}(e^{ax}) = \\frac{a e^{ax}}{1 + e^{ax}}.\n$$\nThe second derivative (Hessian in one dimension) is found by differentiating $f'(x)$ using the quotient rule:\n$$\n\\nabla^2 f(x) = f''(x) = \\frac{(a^2 e^{ax})(1 + e^{ax}) - (a e^{ax})(a e^{ax})}{(1 + e^{ax})^2} = \\frac{a^2 e^{ax} + a^2 e^{2ax} - a^2 e^{2ax}}{(1 + e^{ax})^2} = \\frac{a^2 e^{ax}}{(1 + e^{ax})^2}.\n$$\nNote that since $a  0$, $e^{ax}  0$, hence $f'(x)  0$ and $f''(x)  0$ for all $x \\in \\mathbb{R}$. This means the function $f(x)$ is strictly increasing and strictly convex.\n\nNext, we analyze the asymptotic behavior of these derivatives in the \"flat plateau region,\" which corresponds to $x \\ll 0$, or $x \\to -\\infty$. As $x \\to -\\infty$, $e^{ax} \\to 0$.\n$$\nf'(x) = \\frac{a e^{ax}}{1 + e^{ax}} \\approx \\frac{a e^{ax}}{1} = a e^{ax}.\n$$\n$$\nf''(x) = \\frac{a^2 e^{ax}}{(1 + e^{ax})^2} \\approx \\frac{a^2 e^{ax}}{1^2} = a^2 e^{ax}.\n$$\nBoth the gradient and the curvature become very small as $x \\to -\\infty$, justifying the term \"flat plateau region\". Notably, in this region, we have the approximate relationship $f''(x) \\approx a f'(x)$.\n\nThe Armijo sufficient decrease condition is given by:\n$$\nf(x + \\alpha p) \\leq f(x) + c \\alpha \\nabla f(x)^{\\top} p.\n$$\nUsing a second-order Taylor expansion for a small step size $\\alpha  0$ along a descent direction $p$ (where $\\nabla f(x)^{\\top} p  0$):\n$$\nf(x + \\alpha p) \\approx f(x) + \\alpha \\nabla f(x)^{\\top} p + \\frac{1}{2} \\alpha^2 p^{\\top} \\nabla^2 f(x) p.\n$$\nSubstituting this into the Armijo condition gives:\n$$\nf(x) + \\alpha \\nabla f(x)^{\\top} p + \\frac{1}{2} \\alpha^2 p^{\\top} \\nabla^2 f(x) p \\leq f(x) + c \\alpha \\nabla f(x)^{\\top} p.\n$$\nSubtracting common terms and dividing by $\\alpha  0$:\n$$\n\\nabla f(x)^{\\top} p + \\frac{1}{2} \\alpha p^{\\top} \\nabla^2 f(x) p \\leq c \\nabla f(x)^{\\top} p.\n$$\nRearranging the terms:\n$$\n\\frac{1}{2} \\alpha p^{\\top} \\nabla^2 f(x) p \\leq (c-1) \\nabla f(x)^{\\top} p.\n$$\nSince $f$ is convex, $\\nabla^2 f(x)  0$, so $p^{\\top} \\nabla^2 f(x) p = p^2 f''(x) \\geq 0$. Also, $c \\in (0,1)$, so $c-1  0$. And for a descent direction, $\\nabla f(x)^{\\top} p  0$. Both sides of the inequality are positive (or zero if $p=0$). Assuming $p \\neq 0$, we can solve for $\\alpha$:\n$$\n\\alpha \\leq \\frac{2(c-1)\\nabla f(x)^{\\top} p}{p^{\\top} \\nabla^2 f(x) p} = \\frac{2(1-c)(-\\nabla f(x)^{\\top} p)}{p^{\\top} \\nabla^2 f(x) p}.\n$$\nThis inequality gives an upper bound on the step sizes for which the Armijo condition is expected to be satisfied. The backtracking algorithm starts with an initial guess (e.g., $\\alpha=1$) and multiplies it by $\\rho \\in (0,1)$ until the condition is met. The first $\\alpha$ that satisfies the condition is accepted.\n\nNow we evaluate each statement.\n\n**A) For steepest descent, i.e., $p = -\\nabla f(x)$, in the plateau region the Armijo condition is typically easy to satisfy with an $\\alpha$ of order one (e.g., the initial trial step), even though $\\nabla f(x)^{\\top} p$ is tiny, because the curvature $p^{\\top} \\nabla^{2} f(x) p$ is also tiny; consequently the accepted $\\alpha$ can be large while the actual step $\\alpha p$ is very small in norm.**\n\nLet's check this. The steepest descent direction is $p = -f'(x)$.\nThe directional derivative is $\\nabla f(x)^{\\top} p = f'(x)p = f'(x)(-f'(x)) = -(f'(x))^2$. As $x \\ll 0$, $f'(x) \\approx a e^{ax}$ is tiny, so $(f'(x))^2$ is extremely tiny.\nThe curvature term is $p^{\\top} \\nabla^2 f(x) p = p^2 f''(x) = (-f'(x))^2 f''(x) = (f'(x))^2 f''(x)$. This is also extremely tiny.\nThe upper bound on $\\alpha$ from our Taylor analysis is:\n$$\n\\alpha \\leq \\frac{2(1-c)(-(f'(x)p))}{p^2 f''(x)} = \\frac{2(1-c)(-(-(f'(x))^2))}{(-f'(x))^2 f''(x)} = \\frac{2(1-c)(f'(x))^2}{(f'(x))^2 f''(x)} = \\frac{2(1-c)}{f''(x)}.\n$$\nFor $x \\ll 0$, $f''(x) \\approx a^2 e^{ax}$, which is a very small positive number. Therefore, the upper bound $\\frac{2(1-c)}{a^2 e^{ax}}$ is a very large number.\nThis means that even a large initial trial step, such as $\\alpha=1$, is very likely to satisfy the condition, as it will be much smaller than this large upper bound. Thus, the Armijo condition is easy to satisfy.\nThe resulting step is $\\alpha p = -\\alpha f'(x)$. Even if $\\alpha$ is of order $1$, since $f'(x)$ is tiny, the step magnitude $\\|\\alpha p\\| = \\alpha|f'(x)|$ is very small.\nThe statement is consistent with our analysis.\n\n**Verdict: Correct.**\n\n**B) If instead one uses a fixed-norm descent direction $p = -1$ (independent of $\\|\\nabla f(x)\\|$), the second-order analysis of the Armijo condition yields an upper bound on admissible step sizes of the form $\\alpha \\leq \\frac{2(1-c)\\big(-\\nabla f(x)^{\\top} p\\big)}{p^{\\top} \\nabla^{2} f(x) p}$, which, for $f(x) = \\log(1+e^{a x})$ at $x \\ll 0$, simplifies to an $\\mathcal{O}(1/a)$ constant that does not vanish as $x \\to -\\infty$.**\n\nWe use the derived upper bound on $\\alpha$ with $p = -1$. Since $f'(x)0$, $p=-1$ is a descent direction as required.\n$$\n\\alpha \\leq \\frac{2(1-c)(-\\nabla f(x)^{\\top} p)}{p^{\\top} \\nabla^2 f(x) p} = \\frac{2(1-c)(-f'(x)p)}{p^2 f''(x)}.\n$$\nSubstituting $p = -1$:\n$$\n\\alpha \\leq \\frac{2(1-c)(-f'(x)(-1))}{(-1)^2 f''(x)} = \\frac{2(1-c)f'(x)}{f''(x)}.\n$$\nNow we use the asymptotic forms for $x \\ll 0$: $f'(x) \\approx a e^{ax}$ and $f''(x) \\approx a^2 e^{ax}$.\n$$\n\\alpha \\leq \\frac{2(1-c)(a e^{ax})}{a^2 e^{ax}} = \\frac{2(1-c)}{a}.\n$$\nThis upper bound is a constant with respect to $x$. It is of order $\\mathcal{O}(1/a)$ and clearly does not vanish as $x \\to -\\infty$. The statement is fully supported by the analysis.\n\n**Verdict: Correct.**\n\n**C) A principled safeguard against pathological shrinkage of $\\alpha$ during backtracking when $\\nabla f(x)^{\\top} p$ is tiny is to impose a lower bound $\\alpha_{\\min}  0$ such that the guaranteed decrease $c \\, \\alpha_{\\min} \\big(-\\nabla f(x)^{\\top} p\\big)$ exceeds a chosen threshold tied to numerical noise (for example, comparable to the function-evaluation precision); if repeated backtracking would push $\\alpha$ below $\\alpha_{\\min}$, the algorithm should either accept $\\alpha_{\\min}$ and proceed or switch strategy (for example, restart, rescale the direction, or terminate).**\n\nThis statement describes a standard and essential practice in the implementation of numerical optimization algorithms. The guaranteed decrease in the objective function, as per the Armijo model, is $f(x) - (f(x) + c \\alpha \\nabla f(x)^{\\top} p) = -c \\alpha \\nabla f(x)^{\\top} p$. When the directional derivative $\\nabla f(x)^{\\top} p$ is tiny, this decrease can become smaller than the machine precision (e.g., $\\epsilon_{mach} \\approx 10^{-16}$ for double precision) or other sources of numerical noise in the evaluation of $f(x)$. In such cases, the inequality $f(x + \\alpha p) \\leq f(x) + c \\alpha \\nabla f(x)^{\\top} p$ cannot be reliably evaluated. Repeatedly reducing $\\alpha$ via backtracking (multiplying by $\\rho$) will eventually lead to such a pathologically small step size, causing the algorithm to stall or behave unpredictably. Imposing a minimum step size $\\alpha_{\\min}$ prevents this. If the backtracking procedure would result in $\\alpha  \\alpha_{\\min}$, it indicates a problem with the current search, often that the algorithm is near a very flat region or has found an approximate stationary point. The options listed (accepting $\\alpha_{\\min}$, terminating, or changing strategy) are the standard responses. This statement accurately reflects sound engineering principles for robust optimization software.\n\n**Verdict: Correct.**\n\n**D) Increasing the Armijo parameter $c$ closer to $1$ makes the Armijo condition easier to satisfy when $\\nabla f(x)^{\\top} p$ is tiny and therefore reduces the number of backtracking steps.**\n\nThe Armijo condition is $f(x + \\alpha p) \\leq f(x) + c \\alpha \\nabla f(x)^{\\top} p$. Since $p$ is a descent direction, $\\nabla f(x)^{\\top} p  0$. The parameter $c$ is in the interval $(0,1)$.\nThe term $c \\alpha \\nabla f(x)^{\\top} p$ is a negative quantity that represents the desired decrease in $f$.\nIf we increase $c$ towards $1$, the product $c (-\\nabla f(x)^{\\top} p)$ becomes larger. This means we are demanding a larger decrease in the function value for a given step size $\\alpha$. The line $y(\\alpha) = f(x) + c \\alpha \\nabla f(x)^{\\top} p$ becomes steeper (more negative slope). This makes the inequality $f(x+\\alpha p) \\le y(\\alpha)$ *stricter* or *harder* to satisfy.\nA stricter condition generally requires a smaller step size $\\alpha$ to be met. Therefore, starting from an initial guess, more backtracking steps (reductions of $\\alpha$) will be needed to find an acceptable $\\alpha$. The statement claims the opposite.\n\n**Verdict: Incorrect.**\n\n**E) On the plateau of $f(x) = \\log(1+e^{a x})$ at large negative $x$, the curvature is so small that the strong Wolfe curvature condition, namely $\\big|\\nabla f(x+\\alpha p)^{\\top} p\\big| \\leq c_{2} \\big|\\nabla f(x)^{\\top} p\\big|$ with $c_{2} \\in (c,1)$, is automatically satisfied for any $\\alpha  0$ along any descent direction.**\n\nThe strong Wolfe curvature condition in one dimension is $|f'(x+\\alpha p) p| \\leq c_2 |f'(x) p|$. Assuming $p \\neq 0$, this simplifies to $|f'(x+\\alpha p)| \\leq c_2 |f'(x)|$.\nThe function $f'(x) = \\frac{a e^{ax}}{1+e^{ax}}$ is always positive. A descent direction $p$ must therefore be negative, i.e., $p  0$. So the condition becomes $f'(x+\\alpha p) \\leq c_2 f'(x)$.\nThe second derivative $f''(x)$ is always positive, so $f'(x)$ is a strictly increasing function.\nFor any $\\alpha  0$ and $p  0$, we have $x+\\alpha p  x$. Because $f'$ is strictly increasing, this implies $f'(x+\\alpha p)  f'(x)$.\nHowever, the condition requires $f'(x+\\alpha p) \\leq c_2 f'(x)$, where $c_2 \\in (c,1)$, so $c_2  1$.\nConsider the limit as $\\alpha \\to 0^+$. By continuity of $f'$, we have $\\lim_{\\alpha \\to 0^+} f'(x+\\alpha p) = f'(x)$.\nThis means that for any $\\delta  0$, there exists an $\\epsilon  0$ such that for all $\\alpha \\in (0, \\epsilon)$, we have $f'(x) - f'(x+\\alpha p)  \\delta$. In particular, the ratio $f'(x+\\alpha p) / f'(x)$ approaches $1$.\nSince $c_2  1$, there will always be a sufficiently small $\\alpha  0$ for which $f'(x+\\alpha p)  c_2 f'(x)$.\nTherefore, the statement that the condition holds for *any* $\\alpha  0$ is false. It fails for sufficiently small $\\alpha$.\n\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{ABC}$$"
        },
        {
            "introduction": "The ultimate test of understanding is to move from analysis to implementation. This final practice asks you to code two different gradient descent algorithms: one using a standard monotone backtracking search and another using a more advanced nonmonotone strategy. You will test these implementations on the famously challenging Rosenbrock function, known for its narrow, curving valley that foils simple methods. By comparing the convergence behavior of the two approaches, you will gain direct insight into the practical performance trade-offs and appreciate why relaxing the demand for strict descent at every single step can sometimes lead to faster overall convergence. ",
            "id": "3143371",
            "problem": "Design and implement two line search strategies for minimizing a twice continuously differentiable function using the gradient descent framework, and compare their iteration counts. The target function is the Rosenbrock function in two variables, defined for $x = (x_1,x_2)$ by $f(x) = (1 - x_1)^2 + 100(x_2 - x_1^2)^2$. Use the following foundational base: the first-order Taylor model of a differentiable function around a point $x$ along a direction $p$ and the concept of descent directions with $p$ chosen as the negative gradient $p = -\\nabla f(x)$. Build your derivations from this base without invoking any specialized formulas not justified from it.\n\nYour tasks are:\n- Implement a gradient descent method that, at iteration $k$, computes a search direction $p_k$ and a step size $\\alpha_k$, then updates $x_{k+1} = x_k + \\alpha_k p_k$.\n- Implement a monotone backtracking line search that enforces sufficient decrease relative to the current iterate. The acceptance criterion must be based on the notion of sufficient decrease derived from the first-order model, with parameters $\\alpha_0$, $c_1$, and $\\beta$, where $0  c_1  1$ and $0  \\beta  1$.\n- Implement a nonmonotone line search in the sense of Grippo–Lampariello–Lucidi (GLL), which allows temporary increases in $f(x)$ by comparing to a reference value defined from a fixed-size window of recent function values. Use a window size parameter $m \\in \\mathbb{N}$.\n- Use the search direction $p_k = -\\nabla f(x_k)$ for both strategies.\n- Terminate when the Euclidean norm of the gradient satisfies $\\|\\nabla f(x_k)\\|_2 \\leq \\text{tol}$ or when a maximum number of iterations is reached.\n\nImplement both strategies and test them on the Rosenbrock function. For each test case, measure the number of iterations each method takes to meet the termination criterion and report the pair of iteration counts as integers $[\\text{iters}_{\\text{monotone}}, \\text{iters}_{\\text{nonmonotone}}]$.\n\nTest suite:\n- Case 1 (general behavior near the curved valley): initial point $x^{(0)} = (-1.2, 1.0)$, tolerance $\\text{tol} = 10^{-6}$, maximum iterations $N_{\\max} = 10000$, initial step size $\\alpha_0 = 1.0$, sufficient decrease parameter $c_1 = 10^{-4}$, backtracking factor $\\beta = 0.5$, GLL memory $m = 5$.\n- Case 2 (boundary condition at the minimizer): initial point $x^{(0)} = (1.0, 1.0)$, tolerance $\\text{tol} = 10^{-6}$, maximum iterations $N_{\\max} = 10000$, $\\alpha_0 = 1.0$, $c_1 = 10^{-4}$, $\\beta = 0.5$, $m = 5$.\n- Case 3 (degenerate nonmonotone window equals monotone): initial point $x^{(0)} = (-1.2, 1.0)$, tolerance $\\text{tol} = 10^{-6}$, maximum iterations $N_{\\max} = 10000$, $\\alpha_0 = 1.0$, $c_1 = 10^{-4}$, $\\beta = 0.5$, $m = 1$.\n- Case 4 (different basin start): initial point $x^{(0)} = (0.0, 0.0)$, tolerance $\\text{tol} = 10^{-6}$, maximum iterations $N_{\\max} = 10000$, $\\alpha_0 = 1.0$, $c_1 = 10^{-4}$, $\\beta = 0.5$, $m = 10$.\n- Case 5 (stricter tolerance): initial point $x^{(0)} = (-1.2, 1.0)$, tolerance $\\text{tol} = 10^{-8}$, maximum iterations $N_{\\max} = 20000$, $\\alpha_0 = 1.0$, $c_1 = 10^{-4}$, $\\beta = 0.5$, $m = 5$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a two-element list of integers $[\\text{iters}_{\\text{monotone}}, \\text{iters}_{\\text{nonmonotone}}]$. For example: $[[12,9],[0,0],[...],...]$.\n- No physical units or angles are involved in this problem, so none are required in the output.",
            "solution": "The problem requires the design, implementation, and comparison of two line search strategies—monotone backtracking and non-monotone Grippo–Lampariello–Lucidi (GLL)—within a gradient descent optimization framework. The objective is to minimize the two-dimensional Rosenbrock function.\n\n**1. Preliminaries: The Rosenbrock Function and Gradient Descent**\n\nThe target for minimization is the Rosenbrock function, a standard benchmark for optimization algorithms known for its narrow, curved, parabolic valley. In two dimensions, for a vector $x = (x_1, x_2)$, it is defined as:\n$$f(x) = (1 - x_1)^2 + 100(x_2 - x_1^2)^2$$\nThe function is twice continuously differentiable. Its global minimum is at $x = (1, 1)$, where $f(1, 1) = 0$.\n\nThe optimization method is gradient descent, an iterative first-order algorithm. At each iteration $k$, the current iterate $x_k$ is updated to a new iterate $x_{k+1}$ by moving a certain distance (the step size $\\alpha_k$) in the direction of steepest descent, which is the negative of the gradient, $p_k = -\\nabla f(x_k)$. The update rule is:\n$$x_{k+1} = x_k + \\alpha_k p_k$$\nTo implement this, we must first compute the gradient of the Rosenbrock function, $\\nabla f(x)$. The partial derivatives are:\n$$\n\\frac{\\partial f}{\\partial x_1} = -2(1 - x_1) + 100 \\cdot 2(x_2 - x_1^2)(-2x_1) = 400x_1^3 - 400x_1x_2 + 2x_1 - 2\n$$\n$$\n\\frac{\\partial f}{\\partial x_2} = 100 \\cdot 2(x_2 - x_1^2)(1) = 200(x_2 - x_1^2)\n$$\nThus, the gradient vector is:\n$$\n\\nabla f(x) = \\begin{pmatrix} 400x_1^3 - 400x_1x_2 + 2x_1 - 2 \\\\ 200(x_2 - x_1^2) \\end{pmatrix}\n$$\nThe core of the problem lies in determining the step size $\\alpha_k$ at each iteration using two different line search strategies.\n\n**2. Monotone Backtracking Line Search**\n\nThis strategy ensures a sufficient decrease in the function value at every iteration. The criterion for accepting a step size $\\alpha$ is derived from the first-order Taylor expansion of the function $f$ at $x_k$ along the search direction $p_k$:\n$$f(x_k + \\alpha p_k) \\approx f(x_k) + \\alpha \\nabla f(x_k)^T p_k$$\nSince $p_k = -\\nabla f(x_k)$, the directional derivative $\\nabla f(x_k)^T p_k = -\\nabla f(x_k)^T \\nabla f(x_k) = -\\|\\nabla f(x_k)\\|_2^2$ is negative (as long as $x_k$ is not a stationary point). The linear model thus predicts a decrease in $f$ for any positive $\\alpha$.\n\nHowever, the function is curved, so we cannot expect the actual decrease to match the linear prediction. The sufficient decrease condition, also known as the Armijo condition, requires the actual decrease to be at least a fraction $c_1$ of the predicted decrease:\n$$f(x_k + \\alpha p_k) \\leq f(x_k) + c_1 \\alpha \\nabla f(x_k)^T p_k$$\nwhere $c_1 \\in (0, 1)$ is a small constant, typically on the order of $10^{-4}$.\n\nThe backtracking algorithm to find a suitable $\\alpha_k$ is as follows:\n1. Start with an initial trial step size, $\\alpha = \\alpha_0$ (e.g., $\\alpha_0 = 1.0$).\n2. While the sufficient decrease condition $f(x_k + \\alpha p_k) \\leq f(x_k) + c_1 \\alpha \\nabla f(x_k)^T p_k$ is not satisfied:\n3. Reduce the step size by a backtracking factor $\\beta \\in (0, 1)$: $\\alpha \\leftarrow \\beta \\alpha$.\n4. The first value of $\\alpha$ that satisfies the condition is chosen as the step size $\\alpha_k$.\n\n**3. Nonmonotone Line Search (Grippo–Lampariello–Lucidi)**\n\nStrictly enforcing a decrease at every step can be inefficient in narrow, winding valleys, as it may force unnecessarily small step sizes. The GLL nonmonotone strategy relaxes this requirement by allowing for occasional increases in the function value. This is achieved by modifying the right-hand side of the Armijo condition. Instead of comparing $f(x_k + \\alpha p_k)$ to the current value $f(x_k)$, it is compared to a reference value $R_k$ that represents the recent history of function values.\n\nThe reference value $R_k$ is defined as the maximum function value over a window of the last $m$ iterations, including the current one:\n$$R_k = \\max_{0 \\leq j \\leq \\min(k, m-1)} \\{ f(x_{k-j}) \\}$$\nwhere $m \\in \\mathbb{N}$ is the memory size of the window.\n\nThe nonmonotone sufficient decrease condition is then:\n$$f(x_k + \\alpha p_k) \\leq R_k + c_1 \\alpha \\nabla f(x_k)^T p_k$$\nThe backtracking procedure for finding $\\alpha_k$ is identical to the monotone case, but using this modified condition. By allowing the new point to be evaluated against a potentially higher reference value from the recent past, this strategy can accept larger step sizes, which may allow it to \"cut across\" the curves of the valley more effectively, potentially leading to faster overall convergence.\n\nIf the memory parameter is set to $m=1$, then $R_k = \\max\\{f(x_k)\\} = f(x_k)$, and the GLL line search reduces exactly to the monotone backtracking line search.\n\n**4. Implementation and Termination**\n\nBoth strategies will be implemented within a gradient descent solver. The process at each iteration $k$ is:\n1. Compute the gradient $g_k = \\nabla f(x_k)$.\n2. Check for termination: if the Euclidean norm of the gradient $\\|\\nabla f(x_k)\\|_2$ is less than or equal to a specified tolerance $\\text{tol}$, the algorithm has converged.\n3. Define the search direction $p_k = -g_k$.\n4. Use either the monotone or nonmonotone backtracking procedure to find an acceptable step size $\\alpha_k$.\n5. Update the iterate: $x_{k+1} = x_k + \\alpha_k p_k$.\nThe process is also terminated if a maximum number of iterations, $N_{\\max}$, is reached. The number of iterations required for convergence is recorded for each method and test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Designs, implements, and compares monotone and non-monotone line search\n    strategies for minimizing the Rosenbrock function using gradient descent.\n    \"\"\"\n\n    # === Function Definitions ===\n\n    def rosenbrock(x: np.ndarray) - float:\n        \"\"\"Computes the Rosenbrock function value.\"\"\"\n        return (1 - x[0])**2 + 100 * (x[1] - x[0]**2)**2\n\n    def rosenbrock_grad(x: np.ndarray) - np.ndarray:\n        \"\"\"Computes the gradient of the Rosenbrock function.\"\"\"\n        grad_x1 = 400 * x[0]**3 - 400 * x[0] * x[1] + 2 * x[0] - 2\n        grad_x2 = 200 * (x[1] - x[0]**2)\n        return np.array([grad_x1, grad_x2])\n\n    # === Gradient Descent Implementations ===\n\n    def gradient_descent_monotone(x0: np.ndarray, tol: float, n_max: int, \n                                  alpha0: float, c1: float, beta: float) - int:\n        \"\"\"Gradient descent with monotone backtracking line search.\"\"\"\n        x = np.copy(x0)\n        for k in range(n_max):\n            g = rosenbrock_grad(x)\n            \n            if np.linalg.norm(g) = tol:\n                return k\n\n            p = -g\n            \n            # Monotone backtracking line search (Armijo condition)\n            alpha = alpha0\n            f_x = rosenbrock(x)\n            grad_f_dot_p = np.dot(g, p)\n            \n            while rosenbrock(x + alpha * p)  f_x + c1 * alpha * grad_f_dot_p:\n                alpha *= beta\n                \n            x = x + alpha * p\n            \n        return n_max\n\n    def gradient_descent_nonmonotone(x0: np.ndarray, tol: float, n_max: int, \n                                     alpha0: float, c1: float, beta: float, m: int) - int:\n        \"\"\"Gradient descent with non-monotone (GLL) line search.\"\"\"\n        x = np.copy(x0)\n        # Use a deque for an efficient fixed-size history of function values\n        f_history = deque(maxlen=m)\n        \n        for k in range(n_max):\n            f_k = rosenbrock(x)\n            g = rosenbrock_grad(x)\n\n            if np.linalg.norm(g) = tol:\n                return k\n\n            # Add current function value to history before computing reference\n            f_history.append(f_k)\n            reference_f = np.max(f_history)\n            \n            p = -g\n            \n            # Non-monotone line search\n            alpha = alpha0\n            grad_f_dot_p = np.dot(g, p)\n            \n            while rosenbrock(x + alpha * p)  reference_f + c1 * alpha * grad_f_dot_p:\n                alpha *= beta\n            \n            x = x + alpha * p\n            \n        return n_max\n\n    # === Test Suite Execution ===\n\n    test_cases = [\n        # Case 1: general behavior\n        {'x0': np.array([-1.2, 1.0]), 'tol': 1e-6, 'n_max': 10000, 'alpha0': 1.0, 'c1': 1e-4, 'beta': 0.5, 'm': 5},\n        # Case 2: start at minimizer\n        {'x0': np.array([1.0, 1.0]), 'tol': 1e-6, 'n_max': 10000, 'alpha0': 1.0, 'c1': 1e-4, 'beta': 0.5, 'm': 5},\n        # Case 3: nonmonotone with m=1 (should equal monotone)\n        {'x0': np.array([-1.2, 1.0]), 'tol': 1e-6, 'n_max': 10000, 'alpha0': 1.0, 'c1': 1e-4, 'beta': 0.5, 'm': 1},\n        # Case 4: different starting point\n        {'x0': np.array([0.0, 0.0]), 'tol': 1e-6, 'n_max': 10000, 'alpha0': 1.0, 'c1': 1e-4, 'beta': 0.5, 'm': 10},\n        # Case 5: stricter tolerance\n        {'x0': np.array([-1.2, 1.0]), 'tol': 1e-8, 'n_max': 20000, 'alpha0': 1.0, 'c1': 1e-4, 'beta': 0.5, 'm': 5},\n    ]\n\n    results_str_list = []\n    for case in test_cases:\n        iters_mono = gradient_descent_monotone(\n            case['x0'], case['tol'], case['n_max'], case['alpha0'], case['c1'], case['beta']\n        )\n        \n        iters_nonmono = gradient_descent_nonmonotone(\n            case['x0'], case['tol'], case['n_max'], case['alpha0'], case['c1'], case['beta'], case['m']\n        )\n        \n        results_str_list.append(f\"[{iters_mono},{iters_nonmono}]\")\n\n    print(f\"[{','.join(results_str_list)}]\")\n\nsolve()\n```"
        }
    ]
}