## 引言

在科学与工程的众多领域，寻找[非线性](@entry_id:637147)函数的最优解是一个普遍而核心的挑战。牛顿法以其二次收敛的卓越速度，为解决这类问题提供了强有力的理论框架。然而，其致命的弱点在于对目标函数Hessian矩阵（[二阶导数](@entry_id:144508)矩阵）的依赖：在大规模问题中，计算、存储乃至求逆一个巨大的Hessian矩阵，其成本往往高得令人望而却步。这构成了理论优雅性与实际可行性之间的巨大鸿沟。

拟牛顿法（Quasi-Newton Methods）正是为了跨越这一鸿沟而诞生的巧妙解决方案。它们继承了[牛顿法](@entry_id:140116)快速收敛的优点，同时创造性地绕过了对真实Hessian矩阵的直接计算。其核心思想是：能否仅通过观测函数梯度（[一阶导数](@entry_id:749425)）在迭代过程中的变化，来逐步构建和完善一个对Hessian矩阵的有效近似？本文旨在深入剖析支撑这一思想的数学基石——[割线方程](@entry_id:164522)。

本文将引导读者完成一次从理论到实践的深度探索。我们将分为三个章节：
*   在“原理与机制”中，我们将详细推导[割线方程](@entry_id:164522)，揭示其如何将一阶的梯度信息转化为二阶的曲率近似。我们将探讨BFGS和SR1等经典更新公式是如何在该方程的约束下被构建出来，并分析它们各自的特性，如对称性、正定性保持以及对不同函数几何的[适应能力](@entry_id:194789)。
*   在“应用与跨学科联系”中，我们将走出纯粹的数学理论，展示拟牛顿法如何在[机器学习模型](@entry_id:262335)训练、计算物理的能量最小化、工程结构的有限元分析以及经济均衡建模等现实世界问题中发挥关键作用。
*   最后，在“动手实践”部分，你将有机会通过具体的计算和编程练习，亲手实现并验证这些算法的机制，从而将理论知识内化为实践技能。

让我们首先深入拟牛顿法的核心，探究其赖以建立的基石——[割线方程](@entry_id:164522)的原理与机制。

## 原理与机制

在[非线性优化](@entry_id:143978)领域，[牛顿法](@entry_id:140116)通过利用[目标函数](@entry_id:267263)的[二阶导数](@entry_id:144508)（即Hessian矩阵）来确定搜索方向，从而实现了快速的局部收敛。然而，计算、存储和求逆Hessian矩阵的成本在许多大规模问题中是令人望而却步的。[拟牛顿法](@entry_id:138962)（Quasi-Newton methods）应运而生，其核心思想是绕过直接计算Hessian矩阵，转而通过一系列迭代来构建并更新一个Hessian矩阵（或其[逆矩阵](@entry_id:140380)）的近似。本章将深入探讨[拟牛顿法](@entry_id:138962)的基石——[割线方程](@entry_id:164522)（secant equation），并阐述其如何驱动各种著名的更新公式（如BFGS和SR1）的机制。

### [割线方程](@entry_id:164522)：从梯度到曲率的桥梁

拟牛顿法的核心在于如何利用已有的信息（即函数在某些点上的梯度）来推断函数的局部曲率。曲率本质上是二阶信息，而梯度是一阶信息。[割线方程](@entry_id:164522)巧妙地在两者之间建立了一座桥梁。

让我们考虑一个二次[连续可微函数](@entry_id:200349) $f: \mathbb{R}^n \to \mathbb{R}$。根据[泰勒定理](@entry_id:144253)，函数 $f$ 在点 $x_{k+1}$ 处的梯度 $\nabla f(x_{k+1})$ 可以在点 $x_k$ 附近进行一阶展开：
$$
\nabla f(x_{k+1}) \approx \nabla f(x_k) + \nabla^2 f(x_k) (x_{k+1} - x_k)
$$
其中 $\nabla^2 f(x_k)$ 是函数在 $x_k$ 处的真实Hessian矩阵。[拟牛顿法](@entry_id:138962)的精神在于用一个近似矩阵 $B_{k+1}$ 来代替真实的Hessian矩阵 $\nabla^2 f(x_k)$。这个新的近似矩阵 $B_{k+1}$ 被要求精确地模拟函数在最近一次迭代步上的行为。也就是说，我们要求上述近似关系对于 $B_{k+1}$ 来说是一个等式。

为了方便表示，我们定义两个关键向量：
- **位移向量 (displacement vector)**: $s_k = x_{k+1} - x_k$
- **梯度差向量 (gradient difference vector)**: $y_k = \nabla f(x_{k+1}) - \nabla f(x_k)$

将这些定义代入并用 $B_{k+1}$ 替换 $\nabla^2 f(x_k)$，我们得到[拟牛顿法](@entry_id:138962)的核心方程：
$$
y_k = B_{k+1} s_k
$$
这个方程被称为**[割线方程](@entry_id:164522)**或**拟牛顿条件** 。它规定了新的Hessian近似矩阵 $B_{k+1}$ 必须满足的条件：当它作用于最新的位移向量 $s_k$ 时，其结果必须等于最新的梯度差向量 $y_k$。

#### 几何解释

[割线方程](@entry_id:164522)具有清晰的几何意义。我们可以构建一个关于梯度 $\nabla f(x)$ 的[线性模型](@entry_id:178302)，该模型以 $x_{k+1}$ 为中心，使用 $B_{k+1}$ 作为其“导数”（即Hessian的近似）：
$$
m_{k+1}(x) = \nabla f(x_{k+1}) + B_{k+1}(x - x_{k+1})
$$
[割线方程](@entry_id:164522)的本质是要求这个新建立的线性模型 $m_{k+1}(x)$ 能够精确地“插值”上一步的梯度信息。也就是说，当我们将上一个迭代点 $x_k$ 代入这个模型时，我们希望得到上一个点的真实梯度 $\nabla f(x_k)$：
$$
m_{k+1}(x_k) = \nabla f(x_k)
$$
将 $x = x_k$ 代入模型定义，我们得到：
$$
\nabla f(x_{k+1}) + B_{k+1}(x_k - x_{k+1}) = \nabla f(x_k)
$$
整理上式，利用 $s_k = x_{k+1} - x_k$，即可恢复[割线方程](@entry_id:164522)：
$$
B_{k+1} s_k = \nabla f(x_{k+1}) - \nabla f(x_k) = y_k
$$
因此，[割线方程](@entry_id:164522)强制要求Hessian近似矩阵 $B_{k+1}$ 所定义的梯度线性模型，必须与最近一次迭代中观测到的真实梯度变化完全吻合 。这就像在多维空间中，用一条“[割线](@entry_id:178768)”的行为来近似曲线的局部曲率。

### [割线方程](@entry_id:164522)的核心属性与要求

[割线方程](@entry_id:164522)虽然形式简洁，但它蕴含了[拟牛顿法](@entry_id:138962)得以有效运作的若干基本前提和深刻属性。

#### 可微性要求

[割线方程](@entry_id:164522)的定义本身就隐含了对[目标函数](@entry_id:267263) $f(x)$ [光滑性](@entry_id:634843)的要求。向量 $y_k$ 是通过计算两个不同点的梯度之差得到的。如果函数在某个迭代点 $x_{k+1}$ 处不可微，那么 $\nabla f(x_{k+1})$ 就没有定义，从而导致 $y_k$ 无法计算，整个[更新过程](@entry_id:273573)随即失败。

例如，考虑优化一个带有[绝对值](@entry_id:147688)项的函数 $f(x, y) = 3|x - 2| + (y+1)^2$。该函数在直线 $x=2$ 上的所有点都不可微。假设某次迭代从 $x_k = (4, 1)$ 移动到 $x_{k+1} = (2, 0)$。在 $x_k$ 处，梯度是明确的 $\nabla f(x_k) = (3, 4)$。然而，在 $x_{k+1}$ 处，由于 $x$ 坐标为 $2$，梯度 $\nabla f(x_{k+1})$ 未定义。因此，无法构建 $y_k$，算法无法继续进行 。这说明，拟牛顿法天然适用于至少一阶连续可微的函数。

#### 对线性项的[不变性](@entry_id:140168)

[割线方程](@entry_id:164522)捕捉的是函数的二阶信息（曲率）。一个有力的证明是，它对于函数的一次项和常数项是不敏感的。假设我们有一个新的目标函数 $g(x) = f(x) + c^T x + d$，其中 $c$ 是一个常数向量，d是一个常数标量。新函数的梯度为 $\nabla g(x) = \nabla f(x) + c$。

如果我们使用与原来完全相同的迭代步 $x_k$ 和 $x_{k+1}$，那么新的位移向量 $s_k'$ 显然与 $s_k$ 相同。我们来计算新的梯度差向量 $y_k'$：
$$
y_k' = \nabla g(x_{k+1}) - \nabla g(x_k) = (\nabla f(x_{k+1}) + c) - (\nabla f(x_k) + c) = \nabla f(x_{k+1}) - \nabla f(x_k) = y_k
$$
这意味着，向目标函数添加任意线性部分都不会改变 $s_k$ 和 $y_k$ 这两个核心向量。因此，由它们定义的[割线方程](@entry_id:164522)以及后续的所有拟牛顿[更新过程](@entry_id:273573)，都独立于函数的一阶和零阶信息，纯粹致力于逼近其二阶特性 。

#### 退化情况的启示

[割线方程](@entry_id:164522)也能深刻反映函数的局部几何形态。考虑一种特殊情况：算法在两个不同的点之间移动（$s_k \neq 0$），但梯度在这两点完全相同（$\nabla f(x_{k+1}) = \nabla f(x_k)$）。这在几何上可能发生于一个“平坦”的山谷或山脊区域。在这种情况下，梯度差向量 $y_k = 0$。

[割线方程](@entry_id:164522)变为：
$$
B_{k+1} s_k = 0
$$
由于 $s_k$ 是一个非[零向量](@entry_id:156189)，这个方程的成立意味着 $s_k$ 位于矩阵 $B_{k+1}$ 的零空间（null space）中。一个矩阵如果存在非零的[零空间](@entry_id:171336)，它必定是**奇异的**（singular），即其[行列式](@entry_id:142978)为零，不可逆。因此，当梯度在移动过程中没有发生变化时，任何满足[割线条件](@entry_id:164914)的Hessian近似矩阵 $B_{k+1}$ 都必须是奇异的 。这再次表明，[割线方程](@entry_id:164522)能够将函[数的几何](@entry_id:192990)特性（如梯度的局部不变性）转化为其Hessian近似矩阵的代数性质（如奇异性）。

### [割线方程](@entry_id:164522)的逆形式

在实际应用中，求解线性方程组 $B_k p_k = -\nabla f(x_k)$ 来获得牛顿方向 $p_k$ 可能仍然耗时。因此，许多拟牛顿法（特别是BFGS）选择直接逼近Hessian的**逆矩阵**，记为 $H_k \approx (\nabla^2 f(x_k))^{-1}$。这样，搜索方向就可以通过简单的矩阵-向量乘法得到：$p_k = -H_k \nabla f(x_k)$。

我们可以通过对[割线方程](@entry_id:164522) $B_{k+1}s_k = y_k$ 两边左乘 $H_{k+1} = B_{k+1}^{-1}$ 来得到逆形式的[割线方程](@entry_id:164522)：
$$
H_{k+1} y_k = s_k
$$
这个方程被称为**逆[割线方程](@entry_id:164522)**。它的解释是：新的逆Hessian近似矩阵 $H_{k+1}$ 应该能将梯度差向量 $y_k$ 映射回位移向量 $s_k$。这恰好是逆映射的期望行为。所有基于逆Hessian近似的拟牛顿更新（如逆[BFGS算法](@entry_id:263685)）都以此方程为基础 。

### 从方程到算法：更新的构建

[割线方程](@entry_id:164522) $B_{k+1}s_k = y_k$ 是一个包含 $n$ 个[线性方程](@entry_id:151487)的系统，其中 $B_{k+1}$ 是一个 $n \times n$ 矩阵。如果我们要求 $B_{k+1}$ 是对称的，那么它有 $n(n+1)/2$ 个独立元素。当 $n > 1$ 时，这是一个**欠定[方程组](@entry_id:193238)**（underdetermined system），意味着存在无穷多个解。

#### 欠定性及其后果

[割线方程](@entry_id:164522)的欠定性是拟牛顿法的核心挑战与机遇。挑战在于，我们必须引入额外的准则来从无穷多的解中选择一个“最好”的 $B_{k+1}$。机遇在于，这种自由度允许我们设计出具有各种优良性质（如保持[正定性](@entry_id:149643)）的更新公式。

这种欠定性也意味着，仅凭一次迭代的信息，我们只能约束Hessian近似在 $s_k$ 方向上的行为，而对其正交方向上的行为几乎一无所知。

为了说明这一点，考虑一个三维凸二次函数 $f(x) = \frac{1}{2}x^{\top}Qx$，其中 $Q = \mathrm{diag}(1, 10, 100)$。真实Hessian的逆为 $Q^{-1} = \mathrm{diag}(1, 0.1, 0.01)$。假设我们从原点出发，沿 $s_k = e_1 = (1,0,0)^T$ 方向移动。此时 $y_k = Qs_k = e_1$。逆[割线方程](@entry_id:164522)为 $H_{k+1}e_1 = e_1$。

考虑一个[对角形式](@entry_id:264850)的近似 $H_{k+1} = \mathrm{diag}(1, \alpha, \beta)$。显然，只要第一个对角元素为1，无论 $\alpha, \beta$ 取任何正值，[割线方程](@entry_id:164522)都成立。假设我们选择了一个极不准确的近似，例如 $\alpha=250, \beta=1$，即 $H_{k+1} = \mathrm{diag}(1, 250, 1)$。现在我们在一个与 $s_k$ 正交的方向 $u = e_2 = (0,1,0)^T$ 上比较近似曲率和真实曲率。近似的逆曲率为 $u^{\top}H_{k+1}u = 250$，而真实的逆曲率为 $u^{\top}Q^{-1}u = 0.1$。两者相差巨大 。这表明，单步[割线条件](@entry_id:164914)只能保证沿最新搜索方向的曲率信息被正确吸收，而其他方向的曲率信息可能非常不准确，甚至完全错误。正因如此，拟牛顿法需要通过一系列不同方向的迭代来逐步完善整个Hessian近似。

#### 拟牛顿更新的一般原则

几乎所有拟牛顿更新公式都遵循一个共同的哲学：**最小变化原则**。即，在所有满足[割线方程](@entry_id:164522) $B_{k+1}s_k=y_k$ 的矩阵 $B_{k+1}$ 中，我们选择那个与前一个近似矩阵 $B_k$ “最接近”的。这里的“接近”可以通过不同的[矩阵范数](@entry_id:139520)来衡量，从而衍生出不同的更新族。

#### 对称性的关键作用

在构建更新时，我们通常强制要求 $B_{k+1}$ 保持对称性，因为真实的Hessian矩阵是对称的。更重要的是，对称性与[正定性](@entry_id:149643)相结合，是保证算法稳定下降的关键。

如果放弃对称性，会发生什么？我们可以构造一个通用的非[对称秩一更新](@entry_id:636357)公式。从 $B_{k+1} = B_k + u_k v_k^{\top}$ 出发，代入[割线方程](@entry_id:164522)可以解得 $u_k = \frac{y_k - B_k s_k}{v_k^{\top}s_k}$（只要 $v_k^{\top}s_k \neq 0$）。

现在考虑一个具体例子：优化二次函数 $f(x) = \frac{1}{2}x^{\top}Qx$，$Q=\mathrm{diag}(1,4)$。从 $x_0=(1,1)^T$ 和 $B_0=I$ 开始，执行一步单位步长的最速下降，得到 $s_0=(-1,-4)^T$ 和新的梯度 $g_1=(0,-12)^T$。如果我们选择一个特定的 $v_0$，例如 $v_0=(-5,1)^T$，并使用上述公式计算出一个非对称的 $B_1$，然后用它来确定下一个搜索方向 $p_1 = -B_1^{-1}g_1$。计算会发现 $g_1^{\top}p_1 > 0$ 。这意味着 $p_1$ 不是一个下降方向！这个例子生动地说明了，一个非对称的Hessian近似可能会导致算法产生一个增加函数值的方向，从而破坏[线搜索方法](@entry_id:172705)的收敛保证。因此，**对称性**是[拟牛顿法](@entry_id:138962)（尤其是用于[线搜索](@entry_id:141607)的）一个至关重要的结构性要求。

### 关键更新公式及其机制

基于上述原则，研究者们发展了多种更新公式。其中，BFGS和SR1是最具[代表性](@entry_id:204613)的两种。

#### BFGS更新与正定性保持

**BFGS (Broyden–Fletcher–Goldfarb–Shanno)** 更新是目前最流行和最成功的拟牛顿方法。其Hessian近似的更新公式为：
$$
B_{k+1}^{\mathrm{BFGS}} = B_k - \frac{B_k s_k s_k^T B_k}{s_k^T B_k s_k} + \frac{y_k y_k^T}{y_k^T s_k}
$$
BFGS最卓越的特性是它能够在特定条件下**保持正定性**。如果初始矩阵 $B_k$ 是对称正定的，并且满足所谓的**曲率条件 (curvature condition)** $s_k^T y_k > 0$，那么更新后的矩阵 $B_{k+1}^{\mathrm{BFGS}}$ 也将是[对称正定](@entry_id:145886)的。

**曲率条件 $s_k^T y_k > 0$** 的意义重大。从泰勒展开我们知道 $y_k \approx (\nabla^2 f) s_k$，因此 $s_k^T y_k \approx s_k^T (\nabla^2 f) s_k$。这个值代表了函数在 $s_k$ 方向上的曲率。正值表示函数在该方向上是局部凸的。在实际算法中，线搜索步骤（如满足[Wolfe条件](@entry_id:171378)的线搜索）的一个目的就是找到一个步长 $\alpha_k$，使得 $s_k = \alpha_k p_k$ 满足此曲率条件。

如果曲率条件不满足，BFGS更新可能会失去正定性。考虑一个非[凸函数](@entry_id:143075) $f(x,y)=\frac{1}{2}x_{1}^{2}-\frac{1}{2}x_{2}^{2}$。如果我们从原点 $x_k=(0,0)^T$ 出发，选择一个不恰当的步 $s_k=(1,2)^T$，我们会计算出 $s_k^{\top}y_k = -3  0$。此时，即使从一个正定的 $B_k=I$ 开始，应用BFGS公式得到的 $B_{k+1}$ 也会包含负[特征值](@entry_id:154894)，从而变成一个[不定矩阵](@entry_id:634961) 。这个例子警示我们，BFGS的稳定性严重依赖于[线搜索](@entry_id:141607)过程与更新公式之间的协同工作。

#### [SR1更新](@entry_id:636357)与不定Hessian的捕捉

**SR1 (Symmetric Rank-One)** 更新是另一种重要的公式。其推导非常直观：寻找一个唯一的对称秩一校[正矩阵](@entry_id:149490) $C = \gamma u u^T$ 使得 $B_{k+1} = B_k + C$ 满足[割线方程](@entry_id:164522)。推导可得：
$$
B_{k+1}^{\mathrm{SR1}} = B_k + \frac{(y_k - B_k s_k)(y_k - B_k s_k)^T}{(y_k - B_k s_k)^T s_k}
$$
与BFGS相比，SR1有几个显著不同：
1.  它不要求曲率条件 $s_k^T y_k  0$ 成立。
2.  即使从一个正定矩阵出发，SR1也**不保证**生成一个[正定矩阵](@entry_id:155546)。它可以产生不定甚至负定矩阵。
3.  当分母 $(y_k - B_k s_k)^T s_k$ 接近零时，更新可能会变得不稳定。

SR1的这种“灵活性”是一把双刃剑。一方面，[数值不稳定性](@entry_id:137058)使其在某些情况下不可靠。另一方面，它能够生成不定Hessian近似的能力，使其在处理含有非凸区域（如[鞍点](@entry_id:142576)）的问题时，能更准确地捕捉真实的函数几何形态。

考虑一个[鞍点](@entry_id:142576)函数 $f(x,y) = x^2 - y^2$，其真实Hessian为 $\mathrm{diag}(2, -2)$，是不定的。如果我们从 $B_0=I$ 开始，并取一个特定的步 $s_0$，[SR1更新](@entry_id:636357)可能会产生一个具有正负[特征值](@entry_id:154894)的矩阵 $B_1^{\mathrm{SR1}}$（例如，[特征值](@entry_id:154894)为 $1$ 和 $-10$），从而正确地反映了函数在一个方向上凸，在另一个方向上凹的[鞍点](@entry_id:142576)特性。相比之下，在满足 $s_0^T y_0  0$ 的情况下，BFGS更新会强制生成一个正定矩阵 $B_1^{\mathrm{BFGS}}$，等于人为地将函数模型扭曲成局部凸的，从而丢失了关于[负曲率](@entry_id:159335)的关键信息 。

### [拟牛顿法](@entry_id:138962)与问题结构

最后，值得一提的是，[拟牛顿法](@entry_id:138962)能够一定程度上适应问题的内在结构。例如，对于**可分离函数**（separable functions），即 $f(x) = \sum_{i=1}^n f_i(x_i)$，其真实的Hessian矩阵是对角的。如果我们的初始近似 $B_k$ 是对角的，并且某一步的位移 $s_k$ 只在一个分量上有值（即只沿一个坐标轴移动），那么由于梯度的可分离性，$y_k$ 也将只在对应的分量上有值。

在这种情况下，可以证明，BFGS更新的两个秩一校正项也都是对角矩阵（实际上只有一个对角元素非零）。因此，更新后的 $B_{k+1}$ 依然保持对角结构，并且只有与移动方向对应的那个对角元素被更新了 。这表明，拟牛顿更新确实是利用局部信息 ($s_k, y_k$) 来智能地、有针对性地修正模型，而不会不必要地破坏模型已有的良好结构。

综上所述，[割线方程](@entry_id:164522)是[拟牛顿法](@entry_id:138962)的理论核心，它通过观测到的梯度变化来推断未知的曲率。然而，由于其欠定性，必须引入额外的准则（如最小变化、对称性、[正定性](@entry_id:149643)保持）来构造具体的更新算法。不同的选择（如BFGS和SR1）导致了具有不同特性和适用范围的算法，它们在稳定性、对函数几何的捕捉能力以及与[线搜索策略](@entry_id:636391)的互动上表现出深刻的差异。理解这些原理与机制，是有效应用和发展优化算法的关键。