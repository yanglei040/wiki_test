{
    "hands_on_practices": [
        {
            "introduction": "The most fundamental question we can ask about an optimization problem is whether a feasible solution exists at all. This exercise challenges you to determine the exact condition for a feasible region, defined by both linear and non-linear constraints, to be non-empty . By applying a classic inequality, you will pinpoint the critical threshold at which solutions become possible, honing your skills in analyzing the existence of solutions.",
            "id": "3129067",
            "problem": "Let $x = (x_{1}, x_{2}) \\in \\mathbb{R}^{2}$. Consider the constraint set defined by $x_{1} \\ge 0$, $x_{2} \\ge 0$, and $x_{1}x_{2} \\ge 1$. A point $x$ is called feasible for a given parameter $\\alpha \\in \\mathbb{R}$ if it also satisfies the linear inequality $x_{1} + x_{2} \\le \\alpha$. Using only the foundational definition that a feasible region is the set of points that simultaneously satisfy all constraints, determine the smallest real number $\\alpha^{\\ast}$ such that there exists at least one feasible point if and only if $\\alpha \\ge \\alpha^{\\ast}$. Provide $\\alpha^{\\ast}$ in exact form as a single real number. Do not round your answer.",
            "solution": "The problem requires finding the smallest real number $\\alpha^{\\ast}$ such that a feasible region, defined by a set of inequalities, is non-empty if and only if a parameter $\\alpha$ satisfies $\\alpha \\ge \\alpha^{\\ast}$.\n\nThe set of all constraints for a point $x = (x_{1}, x_{2}) \\in \\mathbb{R}^{2}$ to be considered feasible is given by:\n1. $x_{1} \\ge 0$\n2. $x_{2} \\ge 0$\n3. $x_{1}x_{2} \\ge 1$\n4. $x_{1} + x_{2} \\le \\alpha$\n\nFor the set of feasible points to be non-empty, there must exist at least one point $(x_{1}, x_{2})$ that satisfies all four inequalities simultaneously. Let the set of points satisfying the first three constraints be denoted by $S$.\n$S = \\{ (x_{1}, x_{2}) \\in \\mathbb{R}^{2} \\mid x_{1} \\ge 0, x_{2} \\ge 0, x_{1}x_{2} \\ge 1 \\}$.\nThe feasible region is the intersection of the set $S$ and the half-plane defined by $x_{1} + x_{2} \\le \\alpha$. This intersection is non-empty if and only if there is at least one point in $S$ for which the sum $x_{1} + x_{2}$ is less than or equal to $\\alpha$.\n\nThis condition can be rephrased. The smallest value of $\\alpha$ for which the feasible region is non-empty must be the minimum possible value of the sum $x_1 + x_2$ for any point $(x_1, x_2)$ in the set $S$. Let this minimum value be $\\alpha^{\\ast}$.\nIf $\\alpha  \\alpha^{\\ast}$, then for any $(x_1, x_2) \\in S$, we have $x_1 + x_2 \\ge \\alpha^{\\ast}  \\alpha$, so the constraint $x_1 + x_2 \\le \\alpha$ can never be satisfied. The feasible region is empty.\nIf $\\alpha \\ge \\alpha^{\\ast}$, then the point $(x_1^{\\ast}, x_2^{\\ast}) \\in S$ that achieves the minimum sum $\\alpha^{\\ast}$ will satisfy $x_1^{\\ast} + x_2^{\\ast} = \\alpha^{\\ast} \\le \\alpha$. This point is therefore in the feasible region, making it non-empty.\n\nConsequently, the problem is equivalent to solving the following optimization problem:\nFind the minimum value of the function $f(x_{1}, x_{2}) = x_{1} + x_{2}$ subject to the constraints $x_{1} \\ge 0$, $x_{2} \\ge 0$, and $x_{1}x_{2} \\ge 1$.\n\nWe can solve this using the Arithmetic Mean-Geometric Mean (AM-GM) inequality. The AM-GM inequality states that for any non-negative real numbers $a$ and $b$, the following holds:\n$$ \\frac{a+b}{2} \\ge \\sqrt{ab} $$\nEquality holds if and only if $a=b$.\n\nFrom the constraints, we have $x_{1} \\ge 0$ and $x_{2} \\ge 0$. The constraint $x_{1}x_{2} \\ge 1$ implies that neither $x_{1}$ nor $x_{2}$ can be zero, so we must have $x_{1}  0$ and $x_{2}  0$. We can therefore apply the AM-GM inequality with $a = x_{1}$ and $b = x_{2}$:\n$$ \\frac{x_{1} + x_{2}}{2} \\ge \\sqrt{x_{1}x_{2}} $$\nMultiplying by $2$, we get:\n$$ x_{1} + x_{2} \\ge 2\\sqrt{x_{1}x_{2}} $$\nWe are also given the constraint $x_{1}x_{2} \\ge 1$. Since the square root function is monotonically increasing for non-negative arguments, we can take the square root of both sides of this inequality:\n$$ \\sqrt{x_{1}x_{2}} \\ge \\sqrt{1} = 1 $$\nCombining the two results, we have:\n$$ x_{1} + x_{2} \\ge 2\\sqrt{x_{1}x_{2}} \\ge 2(1) = 2 $$\nThis shows that for any point $(x_{1}, x_{2})$ satisfying the first three constraints, the sum $x_{1} + x_{2}$ must be greater than or equal to $2$. The minimum possible value for this sum is $2$.\n\nThis minimum value is achieved when the equality conditions for both inequalities are met.\n1. The equality in the AM-GM inequality ($x_{1} + x_{2} = 2\\sqrt{x_{1}x_{2}}$) holds if and only if $x_{1} = x_{2}$.\n2. The equality in the second step ($\\sqrt{x_{1}x_{2}} = 1$) holds if and only if $x_{1}x_{2} = 1$.\n\nTo find the point where the minimum is achieved, we solve the system of equations:\n$$ x_{1} = x_{2} $$\n$$ x_{1}x_{2} = 1 $$\nSubstituting the first equation into the second gives $x_{1}^{2} = 1$. Since we know $x_{1}  0$, we must have $x_{1} = 1$. This implies $x_{2} = 1$.\n\nAt the point $(1, 1)$, the constraints are satisfied: $1 \\ge 0$, $1 \\ge 0$, and $(1)(1) = 1 \\ge 1$. The value of the sum is $x_{1} + x_{2} = 1 + 1 = 2$.\nThis confirms that the minimum value of $x_{1} + x_{2}$ subject to the constraints is indeed $2$.\n\nTherefore, the smallest real number $\\alpha^{\\ast}$ for which the feasible region is non-empty is $2$.\nFor any $\\alpha \\ge 2$, the point $(1, 1)$ is a feasible point. For any $\\alpha  2$, no point can satisfy all constraints.\nThe value of $\\alpha^{\\ast}$ is thus $2$.",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "Feasible regions are not always simple polygons; they can have complex geometries defined by various mathematical constructs, such as vector norms. This practice asks you to explore a feasible region bounded by the interplay of the $\\ell_1$ and $\\ell_2$ norms, which are ubiquitous in modern data science and engineering . You will move beyond simple calculation to characterize the region's fundamental geometric and topological properties, such as convexity and connectedness, thereby building a deeper intuition for the structure of optimization problems.",
            "id": "3129136",
            "problem": "Consider the set of feasible solutions in $\\mathbb{R}^{n}$ defined by the simultaneous constraints $\\|x\\|_{1} \\le \\alpha$ and $\\|x\\|_{2} \\ge \\beta$, where $\\|x\\|_{1} = \\sum_{i=1}^{n} |x_{i}|$ is the $\\ell_{1}$ norm and $\\|x\\|_{2} = \\left(\\sum_{i=1}^{n} x_{i}^{2}\\right)^{1/2}$ is the Euclidean ($\\ell_{2}$) norm. Let $n \\ge 2$, and suppose $\\alpha \\ge 0$ and $\\beta \\ge 0$ are real parameters.\n\nStarting from core definitions of norms and standard inequalities such as the Cauchy–Schwarz inequality and the triangle inequality, rigorously determine the necessary and sufficient condition on $(\\alpha,\\beta)$ for the feasible region to be nonempty in $\\mathbb{R}^{n}$. Then, for the case $n=2$, characterize the geometric shape of the feasible region when it is nonempty by describing its boundary sets using equations and by classifying its boundedness, convexity, and connectedness.\n\nFinally, define\n$$\nc \\;=\\; \\sup\\left\\{\\frac{\\beta}{\\alpha} \\;:\\; \\text{the feasible set } \\{x \\in \\mathbb{R}^{n} : \\|x\\|_{1} \\le \\alpha,\\; \\|x\\|_{2} \\ge \\beta\\} \\text{ is nonempty with } \\alpha0 \\right\\}.\n$$\nCompute the exact value of $c$. Provide $c$ as a single real number. No rounding is required.",
            "solution": "**Part 1: Condition for a Nonempty Feasible Region**\n\nLet the feasible region be denoted by $S = \\{x \\in \\mathbb{R}^{n} : \\|x\\|_{1} \\le \\alpha \\text{ and } \\|x\\|_{2} \\ge \\beta\\}$. The problem asks for the necessary and sufficient condition on the parameters $(\\alpha, \\beta)$ for the set $S$ to be nonempty, given $n \\ge 2$, $\\alpha \\ge 0$, and $\\beta \\ge 0$.\n\nFirst, we establish the relationship between the $\\ell_1$ and $\\ell_2$ norms for any vector $x \\in \\mathbb{R}^n$.\nThe square of the $\\ell_1$ norm is\n$$\n\\|x\\|_{1}^{2} = \\left(\\sum_{i=1}^{n} |x_{i}|\\right)^{2} = \\sum_{i=1}^{n} x_{i}^{2} + \\sum_{i \\ne j} |x_{i}||x_{j}| = \\|x\\|_{2}^{2} + \\sum_{i \\ne j} |x_{i}||x_{j}|.\n$$\nSince $|x_i||x_j| \\ge 0$, the sum $\\sum_{i \\ne j} |x_{i}||x_{j}|$ is non-negative. Therefore, $\\|x\\|_{1}^{2} \\ge \\|x\\|_{2}^{2}$, which implies $\\|x\\|_{1} \\ge \\|x\\|_{2}$ because norms are non-negative.\n\nNow we derive the condition for $S$ to be nonempty.\n\n**Necessity**: Assume $S$ is nonempty. This means there exists at least one vector $x_0 \\in S$. By definition of $S$, this vector $x_0$ must satisfy both constraints:\n1. $\\|x_0\\|_{1} \\le \\alpha$\n2. $\\|x_0\\|_{2} \\ge \\beta$\n\nUsing the general inequality $\\|x\\|_{2} \\le \\|x\\|_{1}$ for our specific vector $x_0$, we can form the following chain of inequalities:\n$$\n\\beta \\le \\|x_0\\|_{2} \\le \\|x_0\\|_{1} \\le \\alpha.\n$$\nThis directly implies that $\\beta \\le \\alpha$. Thus, the condition $\\alpha \\ge \\beta$ is necessary for the feasible region to be nonempty.\n\n**Sufficiency**: Assume the condition $\\alpha \\ge \\beta$ holds. We need to show that there exists at least one vector $x \\in S$. Let us construct such a vector. Consider the vector $x_v \\in \\mathbb{R}^n$ given by $x_v = (\\alpha, 0, 0, \\ldots, 0)$.\nLet's compute the norms of $x_v$:\n$$\n\\|x_v\\|_{1} = |\\alpha| + |0| + \\cdots + |0| = \\alpha \\quad (\\text{since } \\alpha \\ge 0).\n$$\n$$\n\\|x_v\\|_{2} = \\sqrt{\\alpha^2 + 0^2 + \\cdots + 0^2} = \\sqrt{\\alpha^2} = \\alpha \\quad (\\text{since } \\alpha \\ge 0).\n$$\nNow we check if $x_v$ satisfies the constraints for being in $S$:\n1. $\\|x_v\\|_{1} \\le \\alpha \\implies \\alpha \\le \\alpha$, which is true.\n2. $\\|x_v\\|_{2} \\ge \\beta \\implies \\alpha \\ge \\beta$, which is true by our assumption.\nSince both constraints are satisfied, the vector $x_v$ is in $S$, and therefore $S$ is nonempty.\n\nCombining necessity and sufficiency, the condition for the feasible region to be nonempty is $\\alpha \\ge \\beta$.\n\n**Part 2: Geometric Characterization for n=2**\n\nFor $n=2$, the feasible region is $S = \\{(x_1, x_2) \\in \\mathbb{R}^2 : |x_1| + |x_2| \\le \\alpha \\text{ and } \\sqrt{x_1^2 + x_2^2} \\ge \\beta\\}$. We assume the non-emptiness condition $\\alpha \\ge \\beta$ holds.\n\nThe set $S_1 = \\{(x_1, x_2) : |x_1| + |x_2| \\le \\alpha\\}$ is a closed, solid square centered at the origin, with vertices at $(\\alpha, 0)$, $(0, \\alpha)$, $(-\\alpha, 0)$, and $(0, -\\alpha)$.\nThe set $S_2 = \\{(x_1, x_2) : \\sqrt{x_1^2 + x_2^2} \\ge \\beta\\}$ is the set of all points on or outside the circle of radius $\\beta$ centered at the origin.\nThe feasible region $S = S_1 \\cap S_2$ is the part of the solid square that lies on or outside the circle of radius $\\beta$. It is a square with a circular \"hole\".\n\n**Boundary Sets**: The boundary of $S_1$ is the square $|x_1|+|x_2|=\\alpha$. The boundary of the excluded region is the circle $x_1^2+x_2^2=\\beta^2$. The boundary of the feasible region $S$ is composed of parts of both:\n- The segments of the square $|x_1| + |x_2| = \\alpha$ that lie outside the circle, i.e., where $x_1^2 + x_2^2 \\ge \\beta^2$.\n- The arcs of the circle $x_1^2 + x_2^2 = \\beta^2$ that lie inside the square, i.e., where $|x_1| + |x_2| \\le \\alpha$.\n\n**Boundedness**: The feasible region $S$ is a subset of the $\\ell_1$-ball $S_1$. The set $S_1$ is closed and bounded (compact). Any subset of a bounded set is bounded. Therefore, the feasible region $S$ is bounded.\n\n**Convexity**:\n- If $\\beta=0$, the second constraint $\\sqrt{x_1^2+x_2^2} \\ge 0$ is always satisfied. The feasible region becomes $S_1$, which is a convex set.\n- If $\\beta  0$, the set is not convex. To show this, let $\\alpha \\ge \\beta  0$. Consider the points $x = (\\beta, 0)$ and $y = (-\\beta, 0)$.\n  - For $x$: $\\|x\\|_1 = |\\beta| + |0| = \\beta$. Since $\\beta \\le \\alpha$, $\\|x\\|_1 \\le \\alpha$. Also, $\\|x\\|_2 = \\sqrt{\\beta^2+0^2} = \\beta$, so $\\|x\\|_2 \\ge \\beta$. Thus, $x \\in S$.\n  - For $y$: Similarly, $\\|y\\|_1 = \\beta \\le \\alpha$ and $\\|y\\|_2 = \\beta \\ge \\beta$. Thus, $y \\in S$.\n  - Now consider the midpoint $z = \\frac{1}{2}x + \\frac{1}{2}y = (0,0)$. For $z$, $\\|z\\|_1=0 \\le \\alpha$, but $\\|z\\|_2=0  \\beta$. So, $z \\notin S$.\n  Since the line segment connecting two points in $S$ is not entirely contained in $S$, the region is not convex for $\\beta  0$.\n\n**Connectedness**: The feasible region is path-connected, and therefore connected, for any $\\alpha, \\beta$ for which it is nonempty. The region is the union of four parts, one in each quadrant, connected along the axes. For example, the part in the first quadrant, $S_{Q1} = \\{(x_1, x_2) : x_1 \\ge 0, x_2 \\ge 0, x_1+x_2 \\le \\alpha, x_1^2+x_2^2 \\ge \\beta^2\\}$, is path-connected. This part connects to the part in the second quadrant along the non-negative $x_2$-axis. The shared boundary is the set of points $\\{(0, x_2) : \\beta \\le x_2 \\le \\alpha\\}$. Since we assume $\\alpha \\ge \\beta$, this set of connection points is a line segment (or a point if $\\alpha=\\beta$), and is never empty. Similarly, all four quadrant regions are connected to their neighbors along the axes, forming a single connected region.\n\n**Part 3: Computation of c**\n\nThe constant $c$ is defined as\n$$\nc \\;=\\; \\sup\\left\\{\\frac{\\beta}{\\alpha} \\;:\\; \\text{the feasible set } \\{x \\in \\mathbb{R}^{n} : \\|x\\|_{1} \\le \\alpha,\\; \\|x\\|_{2} \\ge \\beta\\} \\text{ is nonempty with } \\alpha0 \\right\\}.\n$$\nFrom Part 1, we established that the feasible set is nonempty if and only if $\\alpha \\ge \\beta$.\nThe definition of $c$ involves the additional constraints $\\alpha  0$ and (from the problem givens) $\\beta \\ge 0$.\nSo, we are looking for the supremum of the set of ratios $R = \\{\\frac{\\beta}{\\alpha} \\mid \\alpha  0, \\beta \\ge 0, \\text{ and } \\alpha \\ge \\beta\\}$.\nLet $r = \\frac{\\beta}{\\alpha}$. The conditions on $r$ are:\n1. $\\alpha  0 \\implies$ the ratio is well-defined.\n2. $\\beta \\ge 0 \\implies r\\alpha \\ge 0 \\implies r \\ge 0$ (since $\\alpha  0$).\n3. $\\alpha \\ge \\beta \\implies \\alpha \\ge r\\alpha \\implies 1 \\ge r$ (since $\\alpha  0$).\n\nCombining these, the set of all possible values for the ratio $\\frac{\\beta}{\\alpha}$ is the set of all $r$ such that $0 \\le r \\le 1$. This is the closed interval $[0, 1]$.\nThe supremum of a set is its least upper bound. For the interval $[0, 1]$, the supremum is $1$.\nTherefore, the value of $c$ is $1$. This result is independent of the dimension $n$.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "In practical scenarios, collected data often fails to satisfy theoretical models, placing it outside the feasible region. This problem presents a powerful and intuitive method for resolving such inconsistencies by finding the \"closest\" valid point within the feasible set . This technique, known as projection onto a convex set, quantifies the \"degree of infeasibility\" and provides a principled way to correct data, illustrating a direct and meaningful application of optimization in data analysis.",
            "id": "3129154",
            "problem": "A dataset in two measured quantities is represented by the vector $y \\in \\mathbb{R}^{2}$ with $y = (2.2,\\,-0.4)$. Suppose the domain expert requires any acceptable (feasible) corrected dataset $x \\in \\mathbb{R}^{2}$ to satisfy the linear conservation rule $x_{1} + x_{2} = 2$ together with minimum-threshold bounds $x_{1} \\geq 1$ and $x_{2} \\geq 0.5$. The set of all feasible corrections is therefore the convex set $C = \\{x \\in \\mathbb{R}^{2} \\mid x_{1} + x_{2} = 2,\\ x_{1} \\geq 1,\\ x_{2} \\geq 0.5\\}$.\n\nUsing the shortest-distance-to-feasibility principle, quantify the dataset’s inconsistency with the constraints by solving the optimization problem\n$$\n\\min_{x \\in \\mathbb{R}^{2}} \\ \\|x - y\\|_{2} \\quad \\text{subject to } x \\in C.\n$$\nDenote the optimal value by $d(y,C)$ and interpret geometrically which constraints are active at the closest feasible point.\n\nProvide the value of $d(y,C)$ as your final answer. Express your answer exactly in simplest radical form (no rounding).",
            "solution": "The problem as stated constitutes a well-posed optimization problem. It asks for the projection of a point $y \\in \\mathbb{R}^{2}$ onto a closed, non-empty, convex set $C$. By the Hilbert projection theorem, a unique solution exists. The problem is to find the point $x \\in C$ that minimizes the Euclidean distance to a given point $y = (2.2, -0.4)$.\n\nThe optimization problem is:\n$$ \\min_{x \\in \\mathbb{R}^{2}} \\|x - y\\|_{2} \\quad \\text{subject to } x \\in C $$\nwhere $C = \\{x \\in \\mathbb{R}^{2} \\mid x_{1} + x_{2} = 2,\\ x_{1} \\geq 1,\\ x_{2} \\geq 0.5\\}$. The vector $y$ is given as $(2.2, -0.4)$.\n\nMinimizing $\\|x - y\\|_{2}$ is equivalent to minimizing its square, $\\|x - y\\|_{2}^{2}$, which is a differentiable function. For convenience, we define the objective function $f(x)$ to be half of the squared distance:\n$$ f(x) = \\frac{1}{2} \\|x - y\\|_{2}^{2} = \\frac{1}{2} \\left( (x_1 - 2.2)^{2} + (x_2 - (-0.4))^{2} \\right) = \\frac{1}{2} \\left( (x_1 - 2.2)^{2} + (x_2 + 0.4)^{2} \\right) $$\nThe constraints defining the feasible set $C$ can be written in standard form for applying the Karush-Kuhn-Tucker (KKT) conditions:\n\\begin{align*}\nh(x) = x_1 + x_2 - 2 = 0 \\\\\ng_1(x) = 1 - x_1 \\leq 0 \\\\\ng_2(x) = 0.5 - x_2 \\leq 0\n\\end{align*}\nSince the objective function $f(x)$ is strictly convex and the feasible set $C$ is convex (as it is the intersection of a hyperplane and two closed half-spaces), any point satisfying the KKT conditions will be the unique global minimum.\n\nThe Lagrangian function is:\n$$ L(x, \\lambda, \\mu_1, \\mu_2) = f(x) + \\lambda h(x) + \\mu_1 g_1(x) + \\mu_2 g_2(x) $$\n$$ L(x, \\lambda, \\mu_1, \\mu_2) = \\frac{1}{2}((x_1 - 2.2)^{2} + (x_2 + 0.4)^{2}) + \\lambda(x_1 + x_2 - 2) + \\mu_1(1 - x_1) + \\mu_2(0.5 - x_2) $$\nThe KKT conditions are:\n1.  **Stationarity**: $\\nabla_x L = 0$\n    $$ \\frac{\\partial L}{\\partial x_1} = (x_1 - 2.2) + \\lambda - \\mu_1 = 0 $$\n    $$ \\frac{\\partial L}{\\partial x_2} = (x_2 + 0.4) + \\lambda - \\mu_2 = 0 $$\n2.  **Primal Feasibility**:\n    $$ x_1 + x_2 - 2 = 0 $$\n    $$ x_1 \\geq 1 $$\n    $$ x_2 \\geq 0.5 $$\n3.  **Dual Feasibility**:\n    $$ \\mu_1 \\geq 0 $$\n    $$ \\mu_2 \\geq 0 $$\n4.  **Complementary Slackness**:\n    $$ \\mu_1(1 - x_1) = 0 $$\n    $$ \\mu_2(0.5 - x_2) = 0 $$\n\nWe analyze the possible cases based on which inequality constraints are active.\n\n**Case 1: Both inequality constraints are inactive.**\nThis implies $x_1  1$ and $x_2  0.5$. From complementary slackness, $\\mu_1 = 0$ and $\\mu_2 = 0$.\nThe stationarity equations become:\n$$ x_1 - 2.2 + \\lambda = 0 \\implies x_1 = 2.2 - \\lambda $$\n$$ x_2 + 0.4 + \\lambda = 0 \\implies x_2 = -0.4 - \\lambda $$\nSubstituting into the equality constraint $x_1 + x_2 = 2$:\n$$ (2.2 - \\lambda) + (-0.4 - \\lambda) = 2 $$\n$$ 1.8 - 2\\lambda = 2 \\implies -2\\lambda = 0.2 \\implies \\lambda = -0.1 $$\nThis gives the candidate point:\n$$ x_1 = 2.2 - (-0.1) = 2.3 $$\n$$ x_2 = -0.4 - (-0.1) = -0.3 $$\nWe check primal feasibility for the inequalities: $x_1 = 2.3  1$ (satisfied), but $x_2 = -0.3 \\geq 0.5$ is false. Thus, this case is not the solution.\n\n**Case 2: The constraint $x_1 \\geq 1$ is active, and $x_2 \\geq 0.5$ is inactive.**\nThis implies $x_1 = 1$ and $x_2  0.5$. From complementary slackness, $\\mu_2 = 0$ (and $\\mu_1 \\ge 0$).\nFrom $x_1 = 1$, the equality constraint $x_1 + x_2 = 2$ gives $1 + x_2 = 2 \\implies x_2 = 1$.\nThe point is $(1, 1)$. This point is primally feasible: $x_1=1 \\ge 1$ and $x_2=1  0.5$.\nNow we check the stationarity and dual feasibility conditions with $x_1=1$, $x_2=1$, and $\\mu_2=0$:\n$$ (1 - 2.2) + \\lambda - \\mu_1 = 0 \\implies -1.2 + \\lambda - \\mu_1 = 0 $$\n$$ (1 + 0.4) + \\lambda - 0 = 0 \\implies 1.4 + \\lambda = 0 \\implies \\lambda = -1.4 $$\nSubstituting $\\lambda = -1.4$ into the first equation:\n$$ -1.2 - 1.4 - \\mu_1 = 0 \\implies \\mu_1 = -2.6 $$\nThis violates the dual feasibility condition $\\mu_1 \\geq 0$. Thus, this case is not the solution.\n\n**Case 3: The constraint $x_2 \\geq 0.5$ is active, and $x_1 \\geq 1$ is inactive.**\nThis implies $x_2 = 0.5$ and $x_1  1$. From complementary slackness, $\\mu_1 = 0$ (and $\\mu_2 \\ge 0$).\nFrom $x_2 = 0.5$, the equality constraint $x_1 + x_2 = 2$ gives $x_1 + 0.5 = 2 \\implies x_1 = 1.5$.\nThe point is $(1.5, 0.5)$. This point is primally feasible: $x_1=1.5  1$ and $x_2=0.5 \\ge 0.5$.\nNow we check the remaining KKT conditions with $x_1=1.5$, $x_2=0.5$, and $\\mu_1=0$:\n$$ (1.5 - 2.2) + \\lambda - 0 = 0 \\implies -0.7 + \\lambda = 0 \\implies \\lambda = 0.7 $$\n$$ (0.5 + 0.4) + \\lambda - \\mu_2 = 0 \\implies 0.9 + \\lambda - \\mu_2 = 0 $$\nSubstituting $\\lambda = 0.7$ into the second equation:\n$$ 0.9 + 0.7 - \\mu_2 = 0 \\implies \\mu_2 = 1.6 $$\nThe dual feasibility conditions are satisfied: $\\mu_1=0 \\geq 0$ and $\\mu_2=1.6 \\geq 0$.\nAll KKT conditions are met. Therefore, the unique optimal solution is $x^* = (1.5, 0.5)$.\n\n**Case 4: Both inequality constraints are active.**\nThis implies $x_1=1$ and $x_2=0.5$. However, $x_1+x_2=1+0.5=1.5 \\ne 2$. This violates the primal feasibility of the equality constraint. Thus, this case is impossible.\n\nThe optimal feasible point is $x^* = (1.5, 0.5)$. At this point, the equality constraint $x_1+x_2=2$ is satisfied by definition. The inequality constraint $x_2 \\ge 0.5$ is active (since $x_2^*=0.5$), while the constraint $x_1 \\ge 1$ is inactive (since $x_1^*=1.5  1$). This is consistent with our KKT analysis where $\\mu_2  0$ and $\\mu_1 = 0$.\n\nThe problem asks for the optimal value $d(y,C)$, which is the distance $\\|x^* - y\\|_{2}$.\n$$ d(y,C) = \\|x^* - y\\|_{2} = \\sqrt{(1.5 - 2.2)^2 + (0.5 - (-0.4))^2} $$\n$$ d(y,C) = \\sqrt{(-0.7)^2 + (0.9)^2} $$\n$$ d(y,C) = \\sqrt{0.49 + 0.81} = \\sqrt{1.3} $$\nTo express this in simplest radical form:\n$$ \\sqrt{1.3} = \\sqrt{\\frac{13}{10}} = \\frac{\\sqrt{13}}{\\sqrt{10}} = \\frac{\\sqrt{13} \\cdot \\sqrt{10}}{\\sqrt{10} \\cdot \\sqrt{10}} = \\frac{\\sqrt{130}}{10} $$\nThe inconsistency of the dataset $y$ with the constraints, quantified by the shortest distance to feasibility, is $\\frac{\\sqrt{130}}{10}$.",
            "answer": "$$\n\\boxed{\\frac{\\sqrt{130}}{10}}\n$$"
        }
    ]
}