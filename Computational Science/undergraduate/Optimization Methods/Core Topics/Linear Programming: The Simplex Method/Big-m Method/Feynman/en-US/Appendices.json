{
    "hands_on_practices": [
        {
            "introduction": "The Big-M method is a powerful extension of the simplex algorithm, but it requires the problem to be in a specific standard form. This first exercise focuses on that foundational step, guiding you through the process of converting inequalities into equalities using slack, surplus, and artificial variables, which are essential for creating an initial feasible solution. ",
            "id": "2209125",
            "problem": "Consider the following Linear Programming (LP) problem:\n\nMinimize $Z = 3x_1 + 5x_2$\n\nSubject to the constraints:\n1. $x_1 + 4x_2 \\le 12$\n2. $-2x_1 + x_2 \\le -5$\n3. $x_1, x_2 \\ge 0$\n\nTo solve this LP problem using the Big M method, it must first be converted into standard form. This involves introducing slack variables (denoted by $s_i$), surplus variables (also denoted by $s_i$), and artificial variables (denoted by $a_i$) to transform the inequalities into a system of linear equations with a non-negative right-hand side.\n\nWhich of the following options represents the correct system of constraint equations for the initial simplex tableau of the Big M method?\n\nA.\n$x_1 + 4x_2 + s_1 = 12$\n$2x_1 - x_2 - s_2 + a_1 = 5$\n\nB.\n$x_1 + 4x_2 + s_1 = 12$\n$-2x_1 + x_2 + s_2 = -5$\n\nC.\n$x_1 + 4x_2 + s_1 = 12$\n$2x_1 - x_2 + s_2 = 5$\n\nD.\n$x_1 + 4x_2 + s_1 = 12$\n$2x_1 - x_2 - s_2 = 5$\n\nE.\n$x_1 + 4x_2 + s_1 + a_1 = 12$\n$2x_1 - x_2 - s_2 + a_2 = 5$",
            "solution": "We start with the LP:\nMinimize $Z = 3x_{1} + 5x_{2}$ subject to\n$$x_{1} + 4x_{2} \\leq 12,$$\n$$-2x_{1} + x_{2} \\leq -5,$$\n$$x_{1}, x_{2} \\geq 0.$$\n\nTo form the initial simplex tableau for the Big M method, constraints must be converted to equalities with nonnegative right-hand sides, introducing slack, surplus, and artificial variables as needed.\n\nFor the first constraint $x_{1} + 4x_{2} \\leq 12$ with a nonnegative right-hand side, we add a slack variable $s_{1} \\geq 0$:\n$$x_{1} + 4x_{2} + s_{1} = 12.$$\n\nFor the second constraint $-2x_{1} + x_{2} \\leq -5$, the right-hand side is negative. Multiply both sides by $-1$ to obtain a nonnegative right-hand side, which reverses the inequality:\n$$2x_{1} - x_{2} \\geq 5.$$\nA $\\geq$ constraint is converted to equality by subtracting a surplus variable and adding an artificial variable to enable an initial basic feasible solution:\n$$2x_{1} - x_{2} - s_{2} + a_{1} = 5,$$\nwith $s_{2} \\geq 0$ and $a_{1} \\geq 0$.\n\nThus, the correct system for the initial simplex tableau is\n$$x_{1} + 4x_{2} + s_{1} = 12,$$\n$$2x_{1} - x_{2} - s_{2} + a_{1} = 5,$$\nwhich corresponds to option A.\n\nOptions B, C, and D fail to both ensure a nonnegative right-hand side and include the necessary artificial variable for the $\\geq$ constraint. Option E incorrectly introduces an artificial variable in the first constraint where the slack variable already provides a valid basic variable.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "The true power of the Big-M method lies in modeling logical conditions, such as 'either-or' choices in mixed-integer programming. This practice challenges you to formulate such a disjunction and determine the smallest valid 'Big M' constant, revealing the crucial concept of a 'tight' formulation. ",
            "id": "3102348",
            "problem": "A single real-valued decision variable $x$ is bounded as $x \\in [0,100]$. You wish to enforce the logical disjunction $x \\leq 30$ or $x \\geq 70$ using a binary decision variable $y \\in \\{0,1\\}$ within the framework of Mixed-Integer Linear Programming (MILP). Starting from the fundamental definition that the large-constant (big-$M$) method uses upper and lower bounding constants to deactivate linear constraints depending on the value of a binary variable, derive a linear inequality system that models the disjunction via the big-$M$ method. Using only the given bounds on $x$ and the thresholds $30$ and $70$, determine the smallest valid constant $M$ that makes the formulation correct for all feasible values of $x$ and $y$. Then, analyze the continuous relaxation in which $y \\in [0,1]$ and prove that with this minimal $M$, the relaxed feasible region in the extended space $(x,y)$ is exactly the convex hull of the original disjunctive region. Provide your final answer as the minimal value of $M$. No rounding is required.",
            "solution": "The problem requires the derivation of a Mixed-Integer Linear Programming (MILP) model for a logical disjunction using the big-$M$ method, the determination of the minimal valid constant $M$, and an analysis of the continuous relaxation.\n\n### Step 1: Formulating the Disjunction with the Big-M Method\n\nThe logical disjunction to be modeled is $x \\leq 30$ or $x \\geq 70$. The decision variable $x$ is a real number bounded by $x \\in [0, 100]$. A binary variable $y \\in \\{0,1\\}$ is introduced to control the disjunction.\n\nLet us define the relationship between the binary variable $y$ and the two conditions:\n- If $y=1$, the constraint $x \\leq 30$ must be active.\n- If $y=0$, the constraint $x \\geq 70$ must be active.\n\nTo use the big-$M$ method, we first rewrite the inequalities in the standard form $f(x) \\leq 0$:\n1. $x - 30 \\leq 0$\n2. $70 - x \\leq 0$\n\nThe general big-$M$ formulation for a disjunction of two inequalities, $f_1(x) \\leq 0$ or $f_2(x) \\leq 0$, using a binary variable $y$ is:\n$$f_1(x) \\leq M(1-y)$$\n$$f_2(x) \\leq M y$$\nHere, we associate $y=1$ with the first inequality being active ($f_1(x) \\leq 0$) and $y=0$ with the second being active ($f_2(x) \\leq 0$).\n\nApplying this to our specific problem, we have $f_1(x) = x-30$ and $f_2(x) = 70-x$. The system of inequalities becomes:\n$$x - 30 \\leq M(1-y) \\quad (1)$$\n$$70 - x \\leq M y \\quad (2)$$\n\nLet's verify this formulation:\n- If $y=1$: Inequality (1) becomes $x - 30 \\leq M(0) \\implies x \\leq 30$. Inequality (2) becomes $70 - x \\leq M(1) \\implies 70 - x \\leq M$. The second inequality must be redundant for any feasible $x$ under the condition $x \\leq 30$.\n- If $y=0$: Inequality (1) becomes $x - 30 \\leq M(1) \\implies x-30 \\leq M$. This inequality must be redundant for any feasible $x$ under the condition $x \\geq 70$. Inequality (2) becomes $70 - x \\leq M(0) \\implies 70 - x \\leq 0 \\implies x \\geq 70$.\n\nThe formulation correctly models the disjunction, provided the constant $M$ is chosen to be sufficiently large.\n\n### Step 2: Determining the Minimal Valid Constant $M$\n\nThe constant $M$ must be large enough to make the \"inactive\" constraint non-restrictive over the feasible domain of $x$. The overall domain for $x$ is given as $[0, 100]$.\n\n1.  Consider the case when $y=0$, which enforces $x \\geq 70$. The other constraint is $x - 30 \\leq M$. This must hold for all values of $x$ that are possible in this case. The possible range for $x$ is thus $[70, 100]$. To ensure $x-30 \\leq M$ is always satisfied, $M$ must be greater than or equal to the maximum possible value of the left-hand side, $x-30$, over this range.\n    $$M \\geq \\max_{x \\in [70, 100]} (x-30)$$\n    The expression $x-30$ is maximized when $x$ is maximized, i.e., at $x=100$.\n    $$M \\geq 100 - 30 = 70$$\n\n2.  Consider the case when $y=1$, which enforces $x \\leq 30$. The other constraint is $70 - x \\leq M$. This must hold for all values of $x$ that are possible in this case. The possible range for $x$ is thus $[0, 30]$. To ensure $70-x \\leq M$ is always satisfied, $M$ must be greater than or equal to the maximum possible value of the left-hand side, $70-x$, over this range.\n    $$M \\geq \\max_{x \\in [0, 30]} (70-x)$$\n    The expression $70-x$ is maximized when $x$ is minimized, i.e., at $x=0$.\n    $$M \\geq 70 - 0 = 70$$\n\nBoth conditions require $M \\geq 70$. Therefore, the smallest valid value for the constant $M$ is $70$.\n\nThe final inequality system using the minimal $M$ is:\n$$x - 30 \\leq 70(1-y)$$\n$$70 - x \\leq 70y$$\n$$x \\in [0, 100], \\quad y \\in \\{0, 1\\}$$\n\n### Step 3: Analysis of the Continuous Relaxation\n\nThe problem asks to prove that the continuous relaxation of this formulation, with the minimal $M=70$, yields the convex hull of the disjunctive feasible region.\n\nThe feasible set for the MILP in the $(x,y)$-space is the union of two disjoint sets (line segments):\n- For $y=0$: $x \\in [70, 100]$. This gives the set $S_0 = \\{(x,0) \\mid x \\in [70, 100]\\}$.\n- For $y=1$: $x \\in [0, 30]$. This gives the set $S_1 = \\{(x,1) \\mid x \\in [0, 30]\\}$.\nThe total feasible set is $S_{MILP} = S_0 \\cup S_1$. This set consists of two line segments in the plane, whose endpoints are $(70,0)$, $(100,0)$, $(0,1)$, and $(30,1)$.\n\nThe convex hull of $S_{MILP}$, denoted $\\text{conv}(S_{MILP})$, is the smallest convex set containing $S_{MILP}$. Since $S_{MILP}$ is composed of two line segments, its convex hull is the polygon formed by their four endpoints: $(70,0)$, $(100,0)$, $(30,1)$, and $(0,1)$.\n\nThe continuous relaxation of the MILP formulation is obtained by allowing $y$ to take any real value in $[0,1]$. The region of the continuous relaxation, let's call it $P$, is defined by the following inequalities:\n1. $x \\in [0, 100]$\n2. $y \\in [0, 1]$\n3. $x - 30 \\leq 70(1-y) \\implies x + 70y \\leq 100$\n4. $70 - x \\leq 70y \\implies x + 70y \\geq 70$\n\nThe set $P$ is a polyhedron. To prove that $P = \\text{conv}(S_{MILP})$, we can show that the vertices of the polyhedron $P$ are precisely the endpoints of the segments in $S_{MILP}$. Let's find the vertices of $P$ by intersecting its boundary inequalities.\n\n- Intersection of $y=0$ and $x+70y=70$: $x=70$. Point: $(70,0)$.\n- Intersection of $y=0$ and $x=100$: Point: $(100,0)$. (This also satisfies $x+70y = 100 \\leq 100$ and $100 \\geq 70$).\n- Intersection of $y=1$ and $x+70y=100$: $x+70=100 \\implies x=30$. Point: $(30,1)$.\n- Intersection of $y=1$ and $x=0$: Point: $(0,1)$. (This also satisfies $x+70y = 70 \\geq 70$ and $70 \\leq 100$).\n- Intersection of $x=0$ and $x+70y=70$: $70y=70 \\implies y=1$. Point: $(0,1)$.\n\nThe vertices of the feasible region $P$ of the continuous relaxation are $(70,0)$, $(100,0)$, $(30,1)$, and $(0,1)$. These are exactly the four extreme points that define $\\text{conv}(S_{MILP})$. Since $P$ is a convex polygon whose vertices are the extreme points of $\\text{conv}(S_{MILP})$, the two sets are identical. Thus, $P = \\text{conv}(S_{MILP})$.\n\nThis proves that using the minimal value $M=70$ results in a \"tight\" formulation, where the linear programming relaxation defines the convex hull of the integer solutions.\n\nThe question asks for the minimal value of $M$. Based on the derivation, this value is $70$.",
            "answer": "$$\n\\boxed{70}\n$$"
        },
        {
            "introduction": "Manually calculating tight $M$ values for every constraint can be impractical in large-scale models. This hands-on programming exercise bridges theory and practice by guiding you to design a preprocessing pipeline that automates this task by solving a series of auxiliary linear programs. ",
            "id": "3102341",
            "problem": "Consider a family of Mixed-Integer Linear Programming (MILP) models with binary decision variables and continuous decision variables. A common modeling device is the \"big-$M$\" method, where a linear inequality constraint is conditionally enforced by a binary variable. The following mathematical setting is used. Let the continuous variables be collected in a vector $x \\in \\mathbb{R}^n$, and suppose $x$ has simple bound constraints $l \\le x \\le u$, where $l \\in \\mathbb{R}^n$ and $u \\in \\mathbb{R}^n$ are given lower and upper bounds. Additionally, there may be shared linear constraints independent of the binary variables, collected as $A_{\\text{shared}} x \\le d$, where $A_{\\text{shared}} \\in \\mathbb{R}^{m \\times n}$ and $d \\in \\mathbb{R}^m$. Each big-$M$ constraint is specified by a row vector $a_i \\in \\mathbb{R}^n$ and a scalar $b_i \\in \\mathbb{R}$, and is written as $a_i^\\top x \\le b_i + M_i (1 - y_i)$, where $y_i \\in \\{0,1\\}$ is a binary variable. When $y_i = 1$, the original linear inequality $a_i^\\top x \\le b_i$ must be satisfied; when $y_i = 0$, the inequality is relaxed by the addition of a sufficiently large constant $M_i$.\n\nYour task is to design and implement a preprocessing pipeline that tightens the constants $M_i$ by solving, for each big-$M$ constraint, a Linear Programming (LP) problem. Linear Programming (LP) is the optimization of a linear objective function over a feasible region defined by linear equality and inequality constraints. The fundamental base for this derivation is the definition of feasibility for linear systems, the boundedness of polyhedra under box constraints, and the fact that a linear function attains its maximum over a nonempty compact polyhedron. For each big-$M$ constraint indexed by $i$, consider the LP that seeks the largest possible violation of the original inequality over the feasible region specified by the shared constraints and the bounds. That LP uses the objective equal to the left-hand side minus the right-hand side constant of the constraint, subject to $A_{\\text{shared}} x \\le d$ and $l \\le x \\le u$. The tightened $M_i$ is then selected as the nonnegative maximum violation, ensuring the relaxation does not inadvertently tighten the constraint when the corresponding binary variable is $0$.\n\nImplement the pipeline and apply it to the following test suite of toy models. All constants are dimensionless; no physical units are involved. For each test case, compute a list whose entries are the tightened $M_i$ values for each big-$M$ constraint in that case, ordered as given.\n\nTest Case $1$:\n- Continuous variables: $x_1, x_2$.\n- Bounds: $0 \\le x_1 \\le 5$, $0 \\le x_2 \\le 3$.\n- Shared constraints: $x_1 + x_2 \\le 5$.\n- Big-$M$ constraints:\n  - Constraint $1$: $2 x_1 + 1 x_2 \\le 4 + M_1 (1 - y_1)$.\n  - Constraint $2$: $-1 x_1 + 3 x_2 \\le 7 + M_2 (1 - y_2)$.\n\nTest Case $2$:\n- Continuous variables: $x_1, x_2$.\n- Bounds: $0 \\le x_1 \\le 5$, $0 \\le x_2 \\le 5$.\n- Shared constraints: $x_1 + x_2 \\le 10$.\n- Big-$M$ constraints:\n  - Constraint $1$: $0.5 x_1 + 0.5 x_2 \\le 10 + M_1 (1 - y_1)$.\n\nTest Case $3$:\n- Continuous variables: $x_1, x_2, x_3$.\n- Bounds: $0 \\le x_1 \\le 4$, $0 \\le x_2 \\le 4$, $0 \\le x_3 \\le 4$.\n- Shared constraints: none.\n- Big-$M$ constraints:\n  - Constraint $1$: $0 x_1 + 0 x_2 + 0 x_3 \\le 1 + M_1 (1 - y_1)$.\n\nTest Case $4$:\n- Continuous variables: $x_1, x_2, x_3$.\n- Bounds: $0 \\le x_1 \\le 10$, $0 \\le x_2 \\le 10$, $0 \\le x_3 \\le 10$.\n- Shared constraints: $2 x_1 + x_2 \\le 12$, $x_2 + x_3 \\le 9$.\n- Big-$M$ constraints:\n  - Constraint $1$: $3 x_1 - 1 x_2 + 0.5 x_3 \\le 8 + M_1 (1 - y_1)$.\n  - Constraint $2$: $1 x_1 + 2 x_2 + 3 x_3 \\le 7 + M_2 (1 - y_2)$.\n\nYour program must solve, for each big-$M$ constraint in each test case, the LP that maximizes the violating expression subject to the provided bounds and shared constraints, and then set $M_i$ to the nonnegative maximized value. The final output format must be a single line containing a comma-separated list of lists, one per test case, each inner list containing the tightened $M_i$ values in order. For example, the output should look like $[[m_{1,1}, m_{1,2}], [m_{2,1}], [m_{3,1}], [m_{4,1}, m_{4,2}]]$, where $m_{t,i}$ is the tightened value for constraint $i$ in test case $t$.",
            "solution": "The core task is to tighten the \"big-$M$\" constants in a series of Mixed-Integer Linear Programming (MILP) formulations. A generic big-$M$ constraint has the form $a_i^\\top x \\le b_i + M_i (1 - y_i)$, where $y_i \\in \\{0,1\\}$ is a binary decision variable and $x \\in \\mathbb{R}^n$ is a vector of continuous decision variables.\n\nThe purpose of this formulation is to use the binary variable $y_i$ to switch the constraint $a_i^\\top x \\le b_i$ on or off.\n- If $y_i = 1$, the term $M_i (1 - y_i)$ becomes $0$, and the constraint enforces $a_i^\\top x \\le b_i$.\n- If $y_i = 0$, the term $M_i (1 - y_i)$ becomes $M_i$, and the constraint becomes $a_i^\\top x \\le b_i + M_i$.\n\nFor the formulation to be correct, the value of $M_i$ must be chosen large enough so that the relaxed constraint $a_i^\\top x \\le b_i + M_i$ does not eliminate any feasible solutions for $x$ that would otherwise be permissible when $y_i=0$. That is, the inequality must be redundant for any $x$ that satisfies the other problem constraints. In optimization, an unnecessarily large value of $M_i$ can lead to poor numerical performance and a weak linear programming relaxation, significantly slowing down the solution process. Therefore, it is advantageous to select the smallest possible valid value for $M_i$.\n\nThe tightest (smallest) valid value for $M_i$ is one that is just large enough to accommodate the maximum possible value of the expression $a_i^\\top x - b_i$ over the feasible region of $x$. This feasible region, which we denote by $\\mathcal{F}$, is defined by the shared constraints and variable bounds that are independent of the binary variables:\n$$\n\\mathcal{F} = \\{ x \\in \\mathbb{R}^n \\mid A_{\\text{shared}} x \\le d, \\text{ and } l \\le x \\le u \\}\n$$\nThe tightest possible value for the relaxation term, $M_i$, is the supremum of the violation $a_i^\\top x - b_i$ over this region:\n$$\nM_i^{\\text{ideal}} = \\sup_{x \\in \\mathcal{F}} \\{ a_i^\\top x - b_i \\}\n$$\nThe problem specifies that the feasible region for $x$ is defined by linear inequalities $A_{\\text{shared}} x \\le d$ and simple bounds $l \\le x \\le u$. This region $\\mathcal{F}$ is a polyhedron. Because it is constrained by finite lower and upper bounds, this polyhedron is compact (closed and bounded), provided it is non-empty. According to the fundamental theorem of linear programming (an application of the Weierstrass Extreme Value Theorem), a linear function attains its maximum and minimum over a non-empty compact set. Thus, the supremum is a maximum, and it can be found by solving a Linear Programming (LP) problem.\n\nFor each big-$M$ constraint $i$, we formulate the following LP:\n$$\n\\begin{align*}\nz_i^* = \\max_{x} \\quad & a_i^\\top x - b_i \\\\\n\\text{s.t.} \\quad & A_{\\text{shared}} x \\le d \\\\\n& l \\le x \\le u\n\\end{align*}\n$$\nSince the constant term $-b_i$ in the objective does not affect the optimal solution $x^*$, we can equivalently solve for $\\max_{x} (a_i^\\top x)$ and then subtract $b_i$. Standard LP solvers are typically designed for minimization. To maximize $a_i^\\top x$, we can minimize $-a_i^\\top x$. Let $v_i^* = \\min_{x \\in \\mathcal{F}} (-a_i^\\top x)$. Then $\\max_{x \\in \\mathcal{F}} (a_i^\\top x) = -v_i^*$, and the maximum violation is $z_i^* = -v_i^* - b_i$.\n\nThe problem states that the tightened $M_i$ must be nonnegative. Thus, the final value for $M_i$ is given by:\n$$\nM_i^{\\text{tight}} = \\max \\{ 0, z_i^* \\} = \\max \\{ 0, -v_i^* - b_i \\}\n$$\nWe apply this procedure to each constraint in each test case.\n\n**Worked Example: Test Case 1**\n- Variables: $x = [x_1, x_2]^\\top$.\n- Feasible region $\\mathcal{F}$:\n  - $0 \\le x_1 \\le 5$\n  - $0 \\le x_2 \\le 3$\n  - $x_1 + x_2 \\le 5$\nThis region is a convex polygon whose vertices are $(0,0)$, $(5,0)$, $(2,3)$, and $(0,3)$. The maximum of any linear function over this region will occur at one of these vertices.\n\n**Constraint 1:** $2 x_1 + 1 x_2 \\le 4 + M_1 (1 - y_1)$.\nHere, $a_1 = [2, 1]^\\top$ and $b_1 = 4$. We need to find $\\max_{x \\in \\mathcal{F}} (2x_1 + x_2)$. We evaluate the objective function at each vertex:\n- At $(0,0)$: $2(0) + 1(0) = 0$.\n- At $(5,0)$: $2(5) + 1(0) = 10$.\n- At $(2,3)$: $2(2) + 1(3) = 7$.\n- At $(0,3)$: $2(0) + 1(3) = 3$.\nThe maximum value of $a_1^\\top x$ is $10$.\nThe maximum violation is $z_1^* = 10 - b_1 = 10 - 4 = 6$.\nThe tightened value is $M_1 = \\max\\{0, 6\\} = 6$.\n\n**Constraint 2:** $-1 x_1 + 3 x_2 \\le 7 + M_2 (1 - y_2)$.\nHere, $a_2 = [-1, 3]^\\top$ and $b_2 = 7$. We need to find $\\max_{x \\in \\mathcal{F}} (-x_1 + 3x_2)$. We evaluate this objective at the vertices:\n- At $(0,0)$: $-1(0) + 3(0) = 0$.\n- At $(5,0)$: $-1(5) + 3(0) = -5$.\n- At $(2,3)$: $-1(2) + 3(3) = 7$.\n- At $(0,3)$: $-1(0) + 3(3) = 9$.\nThe maximum value of $a_2^\\top x$ is $9$.\nThe maximum violation is $z_2^* = 9 - b_2 = 9 - 7 = 2$.\nThe tightened value is $M_2 = \\max\\{0, 2\\} = 2$.\n\nThe results for Test Case $1$ are $[6, 2]$. The same methodology is applied to the remaining test cases using a numerical LP solver, as implemented in the provided code.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef solve():\n    \"\"\"\n    Solves for tightened big-M values for a suite of MILP test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        {\n            \"l\": np.array([0, 0]),\n            \"u\": np.array([5, 3]),\n            \"A_shared\": np.array([[1, 1]]),\n            \"d_shared\": np.array([5]),\n            \"big_M_constraints\": [\n                {\"a\": np.array([2, 1]), \"b\": 4},\n                {\"a\": np.array([-1, 3]), \"b\": 7},\n            ]\n        },\n        # Test Case 2\n        {\n            \"l\": np.array([0, 0]),\n            \"u\": np.array([5, 5]),\n            \"A_shared\": np.array([[1, 1]]),\n            \"d_shared\": np.array([10]),\n            \"big_M_constraints\": [\n                {\"a\": np.array([0.5, 0.5]), \"b\": 10},\n            ]\n        },\n        # Test Case 3\n        {\n            \"l\": np.array([0, 0, 0]),\n            \"u\": np.array([4, 4, 4]),\n            \"A_shared\": None, # No shared constraints\n            \"d_shared\": None,\n            \"big_M_constraints\": [\n                {\"a\": np.array([0, 0, 0]), \"b\": 1},\n            ]\n        },\n        # Test Case 4\n        {\n            \"l\": np.array([0, 0, 0]),\n            \"u\": np.array([10, 10, 10]),\n            \"A_shared\": np.array([[2, 1, 0], [0, 1, 1]]),\n            \"d_shared\": np.array([12, 9]),\n            \"big_M_constraints\": [\n                {\"a\": np.array([3, -1, 0.5]), \"b\": 8},\n                {\"a\": np.array([1, 2, 3]), \"b\": 7},\n            ]\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        case_results = []\n        bounds = list(zip(case[\"l\"], case[\"u\"]))\n        A_ub = case[\"A_shared\"]\n        b_ub = case[\"d_shared\"]\n\n        for constr in case[\"big_M_constraints\"]:\n            a = constr[\"a\"]\n            b = constr[\"b\"]\n            \n            # We want to maximize a^T * x.\n            # scipy.optimize.linprog minimizes its objective, so we minimize -a^T * x.\n            # The objective vector for linprog is c = -a.\n            c = -a\n            \n            # Solve the LP\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n\n            if not res.success:\n                # This case indicates an issue like infeasibility or unboundedness.\n                # However, all problems here are well-posed with non-empty compact feasible sets.\n                # We can raise an error for robustness, though it's not expected here.\n                raise RuntimeError(f\"LP solver failed for case with objective a={a}, b={b}.\")\n\n            # The solver minimizes c^T * x, so res.fun = min(-a^T * x)\n            # This means max(a^T * x) = -res.fun\n            max_ax = -res.fun\n            \n            # The maximum violation is max(a^T * x - b)\n            max_violation = max_ax - b\n            \n            # The tightened M is the nonnegative maximum violation\n            tightened_M = max(0, max_violation)\n            case_results.append(tightened_M)\n            \n        all_results.append(case_results)\n\n    # Format the final output string as specified\n    # Example: [[6.0, 2.0], [0.0], [0.0], [14.5, 26.0]]\n    def format_list(lst):\n        return f\"[{','.join(map(str, lst))}]\"\n    \n    final_output_str = f\"[{','.join(map(format_list, all_results))}]\"\n\n    # Final print statement in the exact required format.\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}