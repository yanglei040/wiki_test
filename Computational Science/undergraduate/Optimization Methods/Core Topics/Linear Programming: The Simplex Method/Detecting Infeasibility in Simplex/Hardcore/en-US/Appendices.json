{
    "hands_on_practices": [
        {
            "introduction": "This first practice provides a guided tour through the two-phase simplex method, the fundamental algorithm for handling linear programs that lack an obvious initial feasible solution. We will take a simple, clearly infeasible linear program and use the formal machinery of artificial variables to systematically prove its infeasibility. This exercise will help you master the mechanics of the Phase I procedure and understand how it produces a tangible certificate of contradiction. ",
            "id": "3118125",
            "problem": "Consider the following Linear Program (LP): minimize $x_1$ subject to the constraints $x_1 = 2$, $x_2 = 2$, $x_1 + x_2 \\le 3$, and $x_1, x_2 \\ge 0$. Your task is to decide feasibility using the two-phase Simplex method and to exhibit an explicit infeasibility certificate by row combination.\n\nTasks:\n1. Construct the Phase I auxiliary problem in standard form by introducing a slack variable and artificial variables as needed. Clearly state the Phase I objective and the auxiliary constraints.\n2. Identify an initial basic feasible solution (BFS) for the auxiliary problem and write the Phase I objective in canonical form consistent with that BFS.\n3. Perform the necessary Phase I pivots symbolically (do not skip steps) to reach an optimal Phase I solution. State the optimal value of the Phase I objective and interpret what this implies about feasibility of the original LP.\n4. Using only the original three constraints (without artificial variables), derive explicit multipliers on the two equalities and the inequality that algebraically combine them into the contradiction $0 \\le -1$. Present the single-line inequality obtained by your combination to certify infeasibility, and identify the corresponding multipliers.\n5. Report, as your final numerical answer, the minimum value of the Phase I objective. No rounding is needed.",
            "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\nThe given linear program (LP) is:\n- Objective function: minimize $z = x_1$\n- Constraints:\n    1. $x_1 = 2$\n    2. $x_2 = 2$\n    3. $x_1 + x_2 \\le 3$\n    4. $x_1 \\ge 0$\n    5. $x_2 \\ge 0$\n\nThe tasks are:\n1. Construct the Phase I auxiliary problem in standard form.\n2. Find an initial basic feasible solution (BFS) and put the Phase I problem in canonical form.\n3. Perform Phase I pivots to find the optimal Phase I solution and interpret the result.\n4. Derive an explicit infeasibility certificate by finding multipliers for the original constraints.\n5. Report the minimum value of the Phase I objective.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard exercise in linear programming, a well-established branch of mathematics and optimization theory.\n- **Well-Posed:** The problem provides a clear objective function and a set of linear constraints. The questions are specific and lead to a definite conclusion about the feasibility of the LP. The problem is not underspecified or overconstrained in a way that makes it unsolvable; its infeasibility is a valid outcome to be demonstrated.\n- **Objective:** The problem is stated using precise mathematical language without ambiguity or subjective-opinion based claims.\n\nThe problem is self-contained, consistent, and meets all criteria for a valid problem.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution\n\nThe original LP is shown to be infeasible by inspection: the first two constraints, $x_1 = 2$ and $x_2 = 2$, imply $x_1 + x_2 = 4$. This contradicts the third constraint, $x_1 + x_2 \\le 3$. The two-phase simplex method provides a systematic way to detect this infeasibility.\n\n**Task 1: Construct the Phase I Auxiliary Problem**\nTo convert the original LP to standard form for the simplex method, we introduce a slack variable $s_1 \\ge 0$ for the inequality constraint. The constraints become:\n1. $x_1 = 2$\n2. $x_2 = 2$\n3. $x_1 + x_2 + s_1 = 3$\n4. $x_1, x_2, s_1 \\ge 0$\n\nTo find an initial basic feasible solution (BFS), we need a set of basic variables that form an identity matrix in the constraint matrix. The current system does not have an obvious basis. We introduce artificial variables $a_1 \\ge 0$ and $a_2 \\ge 0$ into the equality constraints. The slack variable $s_1$ can serve as a basic variable for the third constraint. The augmented system of constraints for the Phase I problem is:\n1. $x_1 + a_1 = 2$\n2. $x_2 + a_2 = 2$\n3. $x_1 + x_2 + s_1 = 3$\n4. $x_1, x_2, s_1, a_1, a_2 \\ge 0$\n\nThe Phase I objective is to minimize the sum of the artificial variables. Let this objective be $w$.\nPhase I Objective: minimize $w = a_1 + a_2$.\nIf the minimum value of $w$ is greater than zero ($w_{min} > 0$), it means that at least one artificial variable is positive in the optimal solution of the Phase I problem, which implies that the original LP has no feasible solution. If $w_{min} = 0$, the original LP is feasible.\n\n**Task 2: Initial BFS and Canonical Form**\nFor the auxiliary problem, we can select an initial basis consisting of the variables we introduced to form an identity submatrix: $B = \\{a_1, a_2, s_1\\}$. The non-basic variables are $N = \\{x_1, x_2\\}$. Setting the non-basic variables to zero ($x_1=0, x_2=0$), we get the initial BFS for the auxiliary problem: $a_1 = 2$, $a_2 = 2$, $s_1 = 3$.\n\nThe Phase I objective function, $w = a_1 + a_2$, must be expressed in terms of the non-basic variables. From the first two constraints of the auxiliary problem:\n$a_1 = 2 - x_1$\n$a_2 = 2 - x_2$\nSubstituting these into the objective function:\n$w = (2 - x_1) + (2 - x_2) = 4 - x_1 - x_2$.\nFor a minimization problem, the simplex tableau is set up with the objective function row representing $z_j - c_j$, the reduced costs. We rearrange the objective as $w + x_1 + x_2 = 4$.\nThe initial simplex tableau for Phase I is:\n| Basis | $x_1$ | $x_2$ | $s_1$ | $a_1$ | $a_2$ | RHS |\n|---|---|---|---|---|---|---|\n| $a_1$ | $1$ | $0$ | $0$ | $1$ | $0$ | $2$ |\n| $a_2$ | $0$ | $1$ | $0$ | $0$ | $1$ | $2$ |\n| $s_1$ | $1$ | $1$ | $1$ | $0$ | $0$ | $3$ |\n|---|---|---|---|---|---|---|\n| $w$ | $1$ | $1$ | $0$ | $0$ | $0$ | $4$ |\n\nThe bottom row represents the coefficients of the objective function $w + x_1 + x_2 - 4 = 0$, and the rightmost entry in that row is the current value of $w$. The reduced costs for the non-basic variables $x_1$ and $x_2$ are $1$ and $1$, respectively. Since these are positive, the current solution is not optimal for the minimization problem.\n\n**Task 3: Perform Phase I Pivots**\nWe proceed with the simplex algorithm.\n*Pivot 1:*\nThe reduced costs for $x_1$ and $x_2$ are both $1$. We can choose either to enter the basis. Let's choose $x_1$. To determine the leaving variable, we perform the minimum ratio test:\n- Row 1 ($a_1$): $2/1 = 2$\n- Row 2 ($a_2$): $2/0 \\to \\infty$\n- Row 3 ($s_1$): $3/1 = 3$\nThe minimum ratio is $2$, so the variable $a_1$ leaves the basis. The pivot element is $1$ in the first row, first column.\nPerforming the pivot operations:\n- $R_1' = R_1$\n- $R_2' = R_2$\n- $R_3' = R_3 - R_1$\n- $R_w' = R_w - R_1$\nThe tableau after the first pivot is:\n| Basis | $x_1$ | $x_2$ | $s_1$ | $a_1$ | $a_2$ | RHS |\n|---|---|---|---|---|---|---|\n| $x_1$ | $1$ | $0$ | $0$ | $1$ | $0$ | $2$ |\n| $a_2$ | $0$ | $1$ | $0$ | $0$ | $1$ | $2$ |\n| $s_1$ | $0$ | $1$ | $1$ | $-1$ | $0$ | $1$ |\n|---|---|---|---|---|---|---|\n| $w$ | $0$ | $1$ | $0$ | $-1$ | $0$ | $2$ |\n\n*Pivot 2:*\nThe new reduced cost for $x_2$ is $1 > 0$, so $x_2$ enters the basis. The minimum ratio test is:\n- Row 1 ($x_1$): $2/0 \\to \\infty$\n- Row 2 ($a_2$): $2/1 = 2$\n- Row 3 ($s_1$): $1/1 = 1$\nThe minimum ratio is $1$, so $s_1$ leaves the basis. The pivot element is $1$ in the third row, second column.\nPerforming the pivot operations:\n- $R_3'' = R_3'$\n- $R_1'' = R_1'$\n- $R_2'' = R_2' - R_3'$\n- $R_w'' = R_w' - R_3'$\nThe tableau after the second pivot is:\n| Basis | $x_1$ | $x_2$ | $s_1$ | $a_1$ | $a_2$ | RHS |\n|---|---|---|---|---|---|---|\n| $x_1$ | $1$ | $0$ | $0$ | $1$ | $0$ | $2$ |\n| $a_2$ | $0$ | $0$ | $-1$ | $1$ | $1$ | $1$ |\n| $x_2$ | $0$ | $1$ | $1$ | $-1$ | $0$ | $1$ |\n|---|---|---|---|---|---|---|\n| $w$ | $0$ | $0$ | $-1$ | $0$ | $0$ | $1$ |\n\nThe reduced costs for all non-basic variables ($s_1$ and $a_1$) are less than or equal to zero ($-1$ and $0$). This indicates that we have reached the optimal solution for the Phase I problem. The minimum value of the Phase I objective is $w_{min} = 1$.\nSince $w_{min} = 1 > 0$, the original LP is infeasible. This is because the optimal solution to the auxiliary problem has $a_2=1$, meaning it is impossible to satisfy the original constraints with all artificial variables equal to zero.\n\n**Task 4: Infeasibility Certificate**\nAn infeasibility certificate is a linear combination of the original constraints that results in a logical contradiction. We seek multipliers $y_1, y_2, y_3$ for the constraints:\n1. $x_1 = 2$\n2. $x_2 = 2$\n3. $x_1 + x_2 \\le 3$\n\nThe multipliers for the equality constraints ($y_1, y_2$) can be of any sign, while the multiplier for the $\\le$ inequality ($y_3$) must be non-negative to preserve the direction of the inequality when combined.\nLet's try to derive the contradiction $0 \\le -1$.\nWe can take the third constraint:\n$x_1 + x_2 \\le 3$\nFrom the first two constraints, we have $x_1=2$ and $x_2=2$. Let's subtract these from the inequality. To do this formally using multipliers, we multiply the equalities by $-1$ and add them to the inequality (which is multiplied by $+1$).\nLet $y_1=-1$, $y_2=-1$, and $y_3=1$. The multiplier $y_3=1$ is non-negative, so this is valid. The combined inequality is:\n$$\n\\begin{align*}\ny_3(x_1 + x_2) + y_1(x_1) + y_2(x_2) \\le y_3(3) + y_1(2) + y_2(2) \\\\\n1(x_1 + x_2) - 1(x_1) - 1(x_2) \\le 1(3) - 1(2) - 1(2) \\\\\n(x_1 + x_2 - x_1 - x_2) \\le (3 - 2 - 2) \\\\\n0 \\le -1\n\\end{align*}\n$$\nThis is a clear contradiction. The single-line inequality obtained by this combination is $0 \\le -1$. This algebraically certifies that no non-negative values of $x_1$ and $x_2$ can satisfy all three constraints simultaneously.\nThe corresponding multipliers are: a multiplier of $-1$ on the constraint $x_1=2$, a multiplier of $-1$ on the constraint $x_2=2$, and a multiplier of $1$ on the constraint $x_1+x_2 \\le 3$.\n\n**Task 5: Report the Minimum Value of the Phase I Objective**\nAs determined in Task 3, the minimum value of the Phase I objective function $w$ at the termination of the Phase I simplex procedure is $1$.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "Moving beyond the mechanics, this exercise connects the outcome of the simplex method to a more profound concept in duality theory: Farkas' Lemma. You will see how the infeasibility of a primal system guarantees the existence of a \"certificate\" vector in a related dual system, providing an alternative and powerful way to prove inconsistency. This practice demonstrates that infeasibility is not just an algorithmic outcome, but a fundamental geometric property of the constraint system. ",
            "id": "3118166",
            "problem": "Consider the linear program that seeks a feasible point subject to the equality constraint and lower bounds: find $x_1$ and $x_2$ such that $x_1 + x_2 = 1$, $x_1 \\ge 1$, and $x_2 \\ge 1$. Using the standard approach to the simplex method, first convert the problem to standard form with nonnegativity by splitting variables with lower bounds: define $x_1 = 1 + z_1$ and $x_2 = 1 + z_2$ where $z_1 \\ge 0$ and $z_2 \\ge 0$. Then:\n\n1) Write the resulting equality constraint as $A z = b$ and identify $A$ and $b$.\n\n2) Use a Phase I construction of the simplex method with an artificial variable to argue infeasibility. Then, appeal to the fundamental separating certificate guaranteed by Farkas’ Lemma: if $A z = b$, $z \\ge 0$ is infeasible, there exists a vector $y$ such that $A^{\\top} y \\ge 0$ and $b^{\\top} y  0$.\n\n3) Impose the normalization $b^{\\top} y = -1$ to remove scaling ambiguity and compute the corresponding $y$. Report the value of $y$ as your final answer. Express your answer as an exact number (no rounding).",
            "solution": "The problem will be addressed in three parts as requested: converting to standard form, demonstrating infeasibility using a Phase I simplex approach, and computing the certificate of infeasibility based on Farkas' Lemma.\n\nFirst, we perform the problem validation.\n## Step 1: Extract Givens\n- Feasibility problem: Find $x_1, x_2$ such that $x_1 + x_2 = 1$, $x_1 \\ge 1$, and $x_2 \\ge 1$.\n- Variable transformation: $x_1 = 1 + z_1$ and $x_2 = 1 + z_2$, where $z_1 \\ge 0$ and $z_2 \\ge 0$.\n- Task 1: Write the resulting problem in the form $A z = b$ and identify the matrix $A$ and vector $b$.\n- Task 2: Use a Phase I simplex method with an artificial variable to prove infeasibility. Then, state the conditions for the certificate of infeasibility $y$ according to Farkas' Lemma: $A^{\\top} y \\ge 0$ and $b^{\\top} y  0$.\n- Task 3: Compute the unique vector $y$ under the normalization condition $b^{\\top} y = -1$.\n\n## Step 2: Validate Using Extracted Givens\nThe problem is a standard exercise in linear programming, specifically concerning the detection of infeasibility and the duality concepts embodied by Farkas' Lemma.\n- **Scientifically Grounded:** The problem is based entirely on the established mathematical principles of linear algebra and optimization theory, specifically the simplex method and Farkas' Lemma.\n- **Well-Posed:** The problem is well-defined. The initial system of inequalities is clearly stated. The transformation and subsequent tasks guide the user through a standard, rigorous procedure to find a certificate of infeasibility. The normalization condition ensures a unique solution.\n- **Objective:** The problem is stated using precise mathematical language, free of any subjectivity or ambiguity.\n\nThe problem is self-contained, consistent, and scientifically sound. No flaws are detected.\n\n## Step 3: Verdict and Action\nThe problem is valid. We proceed with the solution.\n\n### Part 1: Conversion to Standard Form\nThe initial problem is to find a feasible point $(x_1, x_2)$ satisfying:\n$x_1 + x_2 = 1$\n$x_1 \\ge 1$\n$x_2 \\ge 1$\nWe are given the variable transformation $x_1 = 1 + z_1$ and $x_2 = 1 + z_2$. The lower bound constraints $x_1 \\ge 1$ and $x_2 \\ge 1$ are incorporated into the definition of the new variables $z_1$ and $z_2$ by requiring $z_1 \\ge 0$ and $z_2 \\ge 0$.\n\nWe substitute these transformations into the equality constraint:\n$(1 + z_1) + (1 + z_2) = 1$\n$2 + z_1 + z_2 = 1$\n$z_1 + z_2 = -1$\nThe problem is now transformed into finding a vector $z = \\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix}$ that satisfies:\n$z_1 + z_2 = -1$\n$z_1 \\ge 0, \\quad z_2 \\ge 0$\nThis can be written in the matrix form $Az = b$, where:\n- The coefficient matrix is $A = \\begin{pmatrix} 1  1 \\end{pmatrix}$.\n- The variable vector is $z = \\begin{pmatrix} z_1 \\\\ z_2 \\end{pmatrix}$.\n- The right-hand side vector is $b = \\begin{pmatrix} -1 \\end{pmatrix}$.\n\n### Part 2: Phase I Simplex and Farkas' Lemma\nThe transformed problem is to find a feasible solution to $z_1 + z_2 = -1$ subject to $z_1 \\ge 0, z_2 \\ge 0$. It is immediately apparent that no solution can exist, as the sum of two non-negative numbers cannot be negative. We now formalize this conclusion using the Phase I simplex method.\n\nThe standard simplex method requires the right-hand side of constraints to be non-negative. We multiply the constraint equation by $-1$:\n$-z_1 - z_2 = 1$\nTo start the simplex algorithm, we need an initial basic feasible solution. Since there is no identity submatrix in the coefficient matrix $\\begin{pmatrix} -1  -1 \\end{pmatrix}$, we introduce a non-negative artificial variable $a_1 \\ge 0$. The Phase I problem is to minimize the sum of artificial variables, which in this case is just $a_1$.\nMinimize $w = a_1$\nSubject to:\n$-z_1 - z_2 + a_1 = 1$\n$z_1 \\ge 0, \\quad z_2 \\ge 0, \\quad a_1 \\ge 0$\nWe form the initial simplex tableau. The initial basis consists of the artificial variable, so we have a basic feasible solution $a_1 = 1$, with non-basic variables $z_1=0$ and $z_2=0$. The objective function $w$ must be expressed in terms of the non-basic variables. From the constraint, we have $a_1 = 1 + z_1 + z_2$.\nSo, the Phase I objective is to minimize $w = 1 + z_1 + z_2$.\nIn a minimization tableau, the reduced costs for the non-basic variables are the coefficients of these variables in the objective function expression, which are $\\bar{c}_{z_1} = 1$ and $\\bar{c}_{z_2} = 1$. Since all reduced costs are non-negative, the current basic feasible solution ($a_1=1, z_1=0, z_2=0$) is optimal for the Phase I problem.\n\nThe optimal value of the Phase I objective is $w_{\\min} = 1$. Since $w_{\\min} > 0$, it signifies that it is impossible to drive the artificial variable to zero. Therefore, the original system of constraints is infeasible.\n\nFarkas' Lemma provides a formal certificate of this infeasibility. It states that exactly one of the following two systems has a solution:\n1. $Az = b$, $z \\ge 0$\n2. $A^{\\top}y \\ge 0$, $b^{\\top}y  0$\n\nSince we have proven that system (1) is infeasible, a vector $y$ satisfying the conditions of system (2) must exist. This $y$ is the certificate of infeasibility.\n\n### Part 3: Computing the Certificate of Infeasibility\nWe use the matrices $A = \\begin{pmatrix} 1  1 \\end{pmatrix}$ and $b = \\begin{pmatrix} -1 \\end{pmatrix}$ derived in Part 1. The system for $y$ is defined over a vector space whose dimension equals the number of constraints in the primal problem. Here, there is one constraint, so $y$ is a scalar.\n\nThe first condition is $A^{\\top}y \\ge 0$.\nThe transpose of $A$ is $A^{\\top} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\nThe inequality becomes:\n$$A^{\\top}y = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} y = \\begin{pmatrix} y \\\\ y \\end{pmatrix} \\ge \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\nThis implies $y \\ge 0$.\n\nThe second condition is $b^{\\top}y  0$.\nThe transpose of $b$ is $b^{\\top} = \\begin{pmatrix} -1 \\end{pmatrix}$.\nThe inequality becomes:\n$$b^{\\top}y = \\begin{pmatrix} -1 \\end{pmatrix} y = -y  0$$\nThis implies $y > 0$.\n\nThus, any strictly positive scalar $y$ serves as a valid certificate of infeasibility. The problem imposes a normalization condition to find a specific certificate: $b^{\\top}y = -1$.\nSubstituting the expression for $b^{\\top}y$:\n$$-y = -1$$\nSolving for $y$, we get:\n$$y = 1$$\nThis value $y=1$ satisfies the condition $y>0$. Therefore, it is the unique certificate of infeasibility under the given normalization.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Real-world solvers must contend with the limitations of floating-point arithmetic, where theory and practice can diverge. This problem explores the Big-M method, an alternative to the two-phase approach, and reveals its sensitivity to parameter choices and numerical tolerances. By analyzing a case where the penalty parameter $M$ is chosen poorly, you will gain an appreciation for the numerical robustness required for reliable optimization software and the importance of understanding how an algorithm's parameters can influence its conclusion. ",
            "id": "3118196",
            "problem": "Consider the linear program (LP)\nminimize the original objective $f(x) = -x$\nsubject to the two-sided bound constraints\n$x \\le 1$,\n$x \\ge 1 + 10^{-6}$,\nand nonnegativity $x \\ge 0$.\nThis LP is to be attacked by a single-phase Big-$M$ formulation that introduces an artificial variable to handle the “$\\ge$” side. In standard equality form with slack/surplus and an artificial variable, this becomes\nfind $x, s_1, s_2, a \\ge 0$ to minimize the Big-$M$ objective\n$-x + M a$\nsubject to\n$x + s_1 = 1$,\n$x - s_2 + a = 1 + 10^{-6}$.\nA practitioner sets $M = 10$ and uses a feasibility tolerance $\\tau = 10^{-5}$, classifying an artificial variable $a$ as “zero” whenever $a \\le \\tau$. Based on first principles (definitions of feasibility and the Big-$M$ construction), analyze what the Big-$M$ formulation actually does on this instance and how numerical tolerances may alter the practical conclusion.\nSelect all statements that are correct.\n\nA. With $M = 10$, the Big-$M$ problem has the optimal basic solution $x = 1$, $s_1 = 0$, $s_2 = 0$, $a = 10^{-6}$, with objective value $-1 + 10 \\cdot 10^{-6}$. Because $a = 10^{-6}  \\tau$, a tolerance-based implementation may mistakenly declare the original LP “feasible.”\n\nB. The original LP is infeasible. In the Phase I sense (minimizing the sum of artificial variables), the minimal attainable value of $a$ over the auxiliary feasible set equals $10^{-6}  0$, so at least one artificial variable must remain strictly positive.\n\nC. Choosing $M$ sufficiently large, for example $M \\ge 10^{6}$, guarantees that any decrease in $a$ by at least $10^{-6}$ dominates any possible change in the original objective over the auxiliary feasible set. The method therefore prioritizes minimizing $a$ and correctly flags infeasibility because the minimized value is $10^{-6}  0$.\n\nD. Multiplying the second equality by $10^{6}$ (replacing it by $10^{6} x - 10^{6} s_2 + 10^{6} a = 10^{6} + 1$) changes the feasible set and can eliminate the infeasibility, so the scaled system may become feasible.",
            "solution": "The user wants a critical analysis of a linear programming problem involving the Big-$M$ method and numerical tolerances.\n\n**Problem Statement Validation**\n\nFirst, I will validate the problem statement.\n\n**Step 1: Extract Givens**\n- Original LP objective: minimize $f(x) = -x$\n- Original LP constraints: $x \\le 1$, $x \\ge 1 + 10^{-6}$, $x \\ge 0$.\n- Big-$M$ formulation variables: $x, s_1, s_2, a \\ge 0$.\n- Big-$M$ formulation objective: minimize $-x + M a$.\n- Big-$M$ formulation constraints:\n  1. $x + s_1 = 1$\n  2. $x - s_2 + a = 1 + 10^{-6}$\n- Practitioner's parameters: $M = 10$, feasibility tolerance $\\tau = 10^{-5}$.\n- Tolerance rule: an artificial variable $a$ is considered \"zero\" if $a \\le \\tau$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the theory of linear programming and numerical analysis, specifically concerning the Big-$M$ method for handling infeasibility. The provided information is self-consistent and well-posed. The constraints of the original LP, $x \\le 1$ and $x \\ge 1 + 10^{-6}$, are mutually exclusive, which means the original LP is infeasible. This is not a flaw in the problem statement but rather the central feature to be analyzed. The Big-$M$ formulation is correctly derived from the original LP by converting inequalities to standard equality form using slack ($s_1$), surplus ($s_2$), and artificial ($a$) variables. The problem is objective and uses precise mathematical language. There are no violations of scientific principles, incompleteness, or ambiguity. The problem is a valid and instructive example of potential pitfalls in numerical optimization.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. I will now proceed with the derivation and analysis.\n\n**Principle-Based Derivation**\n\n**1. Analysis of the Original LP**\nThe feasible set for the original linear program is the set of all $x$ satisfying $x \\le 1$, $x \\ge 1 + 10^{-6}$, and $x \\ge 0$. The first two constraints are contradictory, as there is no real number $x$ such that $x \\le 1$ and simultaneously $x \\ge 1 + 10^{-6}$. Therefore, the feasible set of the original LP is empty, and the problem is **infeasible**.\n\n**2. Analysis of the Big-$M$ Formulation**\nThe Big-$M$ method introduces non-negative variables to create an auxiliary problem that is always feasible. The constraints of this auxiliary problem are:\n1. $x + s_1 = 1$\n2. $x - s_2 + a = 1 + 10^{-6}$\n3. $x, s_1, s_2, a \\ge 0$\n\nFrom constraint (1), we can express $x$ in terms of $s_1$: $x = 1 - s_1$. Since $x \\ge 0$ and $s_1 \\ge 0$, this implies $0 \\le x \\le 1$ and $0 \\le s_1 \\le 1$.\nSubstituting $x = 1 - s_1$ into constraint (2):\n$(1 - s_1) - s_2 + a = 1 + 10^{-6}$\n$a = 1 + 10^{-6} - 1 + s_1 + s_2$\n$$a = 10^{-6} + s_1 + s_2$$\nSince $s_1 \\ge 0$ and $s_2 \\ge 0$, the minimum possible value of the artificial variable $a$ over the auxiliary feasible set is $10^{-6}$, which occurs when $s_1 = 0$ and $s_2 = 0$.\n\nNow, let's analyze the Big-$M$ objective function, $Z = -x + M a$. We substitute the expressions for $x$ and $a$ in terms of $s_1$ and $s_2$:\n$Z(s_1, s_2) = -(1 - s_1) + M(10^{-6} + s_1 + s_2)$\n$Z(s_1, s_2) = -1 + s_1 + M \\cdot 10^{-6} + M s_1 + M s_2$\n$$Z(s_1, s_2) = (-1 + M \\cdot 10^{-6}) + (M+1)s_1 + M s_2$$\nTo minimize $Z$ subject to $s_1 \\ge 0$ and $s_2 \\ge 0$, we examine the coefficients of $s_1$ and $s_2$. For any $M > 0$, the coefficients $(M+1)$ and $M$ are both strictly positive. Therefore, the minimum value of $Z$ is achieved when $s_1$ and $s_2$ are at their minimum possible values, i.e., $s_1 = 0$ and $s_2 = 0$.\n\nThis optimal choice yields the following solution for the Big-$M$ problem:\n- $s_1 = 0$\n- $s_2 = 0$\n- $x = 1 - s_1 = 1$\n- $a = 10^{-6} + s_1 + s_2 = 10^{-6}$\n\nThis solution $(x, s_1, s_2, a) = (1, 0, 0, 10^{-6})$ is a basic feasible solution and is optimal for any $M > 0$. The optimal value of the artificial variable is $a_{opt} = 10^{-6}$. According to the theory of the Big-$M$ method, if the optimal solution to the auxiliary problem has any artificial variables with a value strictly greater than zero, the original LP is infeasible. Here, $a_{opt} = 10^{-6} > 0$, so the correct conclusion is that the original LP is infeasible.\n\n**Option-by-Option Analysis**\n\n**A. With $M = 10$, the Big-$M$ problem has the optimal basic solution $x = 1$, $s_1 = 0$, $s_2 = 0$, $a = 10^{-6}$, with objective value $-1 + 10 \\cdot 10^{-6}$. Because $a = 10^{-6}  \\tau$, a tolerance-based implementation may mistakenly declare the original LP “feasible.”**\nAs derived above, for any $M>0$, including $M=10$, the optimal solution is indeed $(x, s_1, s_2, a) = (1, 0, 0, 10^{-6})$. This is a basic solution. The objective value is $Z = -x + M a = -1 + 10 \\cdot 10^{-6}$. The practitioner uses a feasibility tolerance $\\tau = 10^{-5}$. The optimal value of the artificial variable is $a = 10^{-6}$. Since $10^{-6}  10^{-5}$, we have $a  \\tau$. An implementation using this tolerance would treat $a$ as numerically zero. Based on the rule that the original problem is feasible if all artificial variables are zero, the implementation would incorrectly conclude that the LP is feasible. This statement accurately describes the numerical failure.\nVerdict: **Correct**.\n\n**B. The original LP is infeasible. In the Phase I sense (minimizing the sum of artificial variables), the minimal attainable value of $a$ over the auxiliary feasible set equals $10^{-6} > 0$, so at least one artificial variable must remain strictly positive.**\nAs established in the initial analysis, the original LP is indeed infeasible. A Phase I procedure focuses exclusively on minimizing the sum of artificial variables. In this problem, there is only one artificial variable, $a$. The task is to find $\\min a$ subject to the auxiliary constraints. As derived, $a = 10^{-6} + s_1 + s_2$ for $s_1, s_2 \\ge 0$. The minimum value is unequivocally $a_{min} = 10^{-6}$, achieved at $s_1 = s_2 = 0$. Since $a_{min} > 0$, the artificial variable cannot be driven to zero. This is the standard criterion for declaring an LP infeasible using a Phase I method. The statement is a perfectly accurate summary of the situation from a Phase I perspective.\nVerdict: **Correct**.\n\n**C. Choosing $M$ sufficiently large, for example $M \\ge 10^{6}$, guarantees that any decrease in $a$ by at least $10^{-6}$ dominates any possible change in the original objective over the auxiliary feasible set. The method therefore prioritizes minimizing $a$ and correctly flags infeasibility because the minimized value is $10^{-6} > 0$.**\nThis statement describes the theoretical principle of the Big-$M$ method. The penalty parameter $M$ must be large enough to make the term $M a$ dominate the original objective, $-x$. The range of the original objective $-x$ over the auxiliary feasible set ($0 \\le x \\le 1$) is $[-1, 0]$, so its maximum variation is $1$. For $M$ to be \"sufficiently large\", it must ensure that any reduction in $a$ is prioritized. Choosing $M > \\frac{\\text{max variation of } -x}{\\text{minimal non-zero value of } a} = \\frac{1}{10^{-6}} = 10^6$ would be a standard heuristic. So, $M \\ge 10^6$ is a valid example. For this problem, we showed that any $M > 0$ is sufficient to find the optimal solution with $a = 10^{-6}$. Because the minimized value of $a$ is $10^{-6} > 0$, a theoretically sound implementation of the Big-$M$ method (one without the tolerance issue described in A) will correctly identify the original LP as infeasible. The statement correctly describes the principle and its correct outcome.\nVerdict: **Correct**.\n\n**D. Multiplying the second equality by $10^{6}$ (replacing it by $10^{6} x - 10^{6} s_2 + 10^{6} a = 10^{6} + 1$) changes the feasible set and can eliminate the infeasibility, so the scaled system may become feasible.**\nThe second equality constraint is $x - s_2 + a = 1 + 10^{-6}$. Multiplying an equation by a non-zero constant ($10^6$ in this case) results in an equivalent equation. The set of all tuples $(x, s_1, s_2, a)$ that satisfy the original system of constraints is identical to the set that satisfies the system with the scaled second constraint. Therefore, the feasible set of the auxiliary problem is unchanged. Since the feasible set is the same, the minimum attainable value of $a$ remains $10^{-6}$. The infeasibility of the original LP is an intrinsic property of its own constraints ($x \\le 1$ and $x \\ge 1 + 10^{-6}$) and cannot be \"eliminated\" by an equivalent algebraic manipulation of the auxiliary problem. While such scaling can affect the numerical behavior of algorithms like the simplex method, it does not change the mathematical nature of the feasible set or the problem's feasibility status. The statement's claims are fundamentally incorrect.\nVerdict: **Incorrect**.",
            "answer": "$$\\boxed{ABC}$$"
        }
    ]
}