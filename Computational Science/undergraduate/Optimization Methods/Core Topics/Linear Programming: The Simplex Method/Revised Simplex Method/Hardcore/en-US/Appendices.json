{
    "hands_on_practices": [
        {
            "introduction": "The best way to internalize an algorithm is to execute it yourself. This comprehensive exercise guides you through multiple iterations of the revised simplex method from a starting basis to the final optimal solution. By computing all the essential components like the dual vector $y$, reduced costs $\\bar{c}_N$, and the search direction $d$ at each step, you will build a solid, practical foundation in the mechanics of the algorithm.",
            "id": "3172864",
            "problem": "Consider the following linear program in standard form for maximization. Let $x \\in \\mathbb{R}^{3}$ denote decision variables and let $s \\in \\mathbb{R}^{2}$ denote slack variables. The data are\n$$\n\\max\\ z \\;=\\; 3 x_{1} \\;+\\; 2 x_{2} \\;+\\; 4 x_{3}\n$$\nsubject to\n$$\n\\begin{aligned}\nx_{1} \\;+\\; 2 x_{2} \\;+\\; x_{3} \\;+\\; s_{1} \\;&=\\; 8,\\\\\n2 x_{1} \\;+\\; x_{2} \\;+\\; 3 x_{3} \\;+\\; s_{2} \\;&=\\; 12,\\\\\nx_{1}, x_{2}, x_{3}, s_{1}, s_{2} \\;&\\ge\\; 0.\n\\end{aligned}\n$$\nLet the initial basis be the slack-variable basis $B_{0} = \\{s_{1}, s_{2}\\}$, yielding the initial basic feasible solution $x_{B} = b$. Use the revised simplex method with Dantzigâ€™s rule (choose the entering nonbasic variable with the largest positive reduced cost in each iteration). At each iteration, compute:\n- the basic solution $x_{B} = B^{-1} b$,\n- the dual vector $y^{\\top} = c_{B}^{\\top} B^{-1}$,\n- the entering-column search direction for basic variables $d_{B} = -\\,B^{-1} a_{j}$ if $x_{j}$ enters, together with $d_{j} = 1$ and $d_{i} = 0$ for all other nonbasic indices,\n- the step length $\\theta = \\min\\{ -x_{B,i}/d_{B,i} : d_{B,i} < 0\\}$,\n- the reduced costs of the nonbasic variables $\\bar{c}_{N} = c_{N} - A_{N}^{\\top} y$.\n\nProceed with pivots until optimality is certified by the revised simplex optimality condition for maximization (all reduced costs of nonbasic variables are nonpositive). Report the final optimal objective value $z^{\\star}$ as an exact rational number. The final answer must be a single number. No rounding is required.",
            "solution": "The problem statement is a standard linear programming problem to be solved using a specified algorithm, the revised simplex method. The data, constraints, and objective function are clearly defined and mathematically consistent. The problem is well-posed, scientifically grounded in the field of optimization, and contains no ambiguities or contradictions. Therefore, the problem is deemed valid and a solution will be furnished.\n\nThe linear program is given by:\n$$ \\max z = 3 x_{1} + 2 x_{2} + 4 x_{3} $$\nsubject to\n$$ x_{1} + 2 x_{2} + x_{3} + s_{1} = 8 $$\n$$ 2 x_{1} + x_{2} + 3 x_{3} + s_{2} = 12 $$\n$$ x_{1}, x_{2}, x_{3}, s_{1}, s_{2} \\ge 0 $$\n\nLet the vector of all variables be $(x_1, x_2, x_3, s_1, s_2)$. The problem can be written in matrix form $\\max c^\\top x$ subject to $Ax = b$ and $x \\ge 0$.\nThe matrices and vectors are:\n$$ A = \\begin{pmatrix} 1 & 2 & 1 & 1 & 0 \\\\ 2 & 1 & 3 & 0 & 1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 3 & 2 & 4 & 0 & 0 \\end{pmatrix}^\\top $$\nThe variable indices are $\\{1, 2, 3, 4, 5\\}$ corresponding to $x_1, x_2, x_3, s_1, s_2$.\n\n**Iteration 0**\n\nThe initial basis consists of the slack variables $\\{s_1, s_2\\}$, so the set of basic indices is $\\mathcal{B} = \\{4, 5\\}$ and nonbasic indices is $\\mathcal{N} = \\{1, 2, 3\\}$.\n\nThe basis matrix $B$ and its inverse $B^{-1}$ are:\n$$ B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}, \\quad B^{-1} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\nThe costs of the basic variables are $c_B = (c_4, c_5)^\\top = (0, 0)^\\top$.\n\n- Basic solution: $x_B = B^{-1} b = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix} = \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix}$. Thus, $s_1 = 8$, $s_2 = 12$. The objective value is $z = c_B^\\top x_B = 0$.\n- Dual vector: $y^{\\top} = c_B^\\top B^{-1} = \\begin{pmatrix} 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\end{pmatrix}$. Thus, $y = (0, 0)^\\top$.\n- Reduced costs of nonbasic variables $\\bar{c}_N = c_N - A_N^\\top y$:\n  - $\\bar{c}_1 = c_1 - y^{\\top} a_1 = 3 - \\begin{pmatrix} 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = 3$.\n  - $\\bar{c}_2 = c_2 - y^{\\top} a_2 = 2 - \\begin{pmatrix} 0 & 0 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 2$.\n  - $\\bar{c}_3 = c_3 - y^{\\top} a_3 = 4 - \\begin{pmatrix} 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = 4$.\nThe vector of reduced costs is $\\bar{c}_N = (3, 2, 4)^\\top$. Since there are positive reduced costs, the current solution is not optimal. By Dantzig's rule, we choose the variable with the largest positive reduced cost to enter the basis. This is $x_3$, with $\\bar{c}_3 = 4$.\n\n- Entering-column search direction: $d_B = -B^{-1} a_3 = -\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -3 \\end{pmatrix}$.\n- Step length: $\\theta = \\min\\{-x_{B,i}/d_{B,i} : d_{B,i} < 0\\} = \\min\\{-8/(-1), -12/(-3)\\} = \\min\\{8, 4\\} = 4$.\nThe minimum ratio corresponds to the second basic variable, $s_2$. Thus, $s_2$ leaves the basis.\n\n**Iteration 1**\n\nThe new basis is $\\{s_1, x_3\\}$, so $\\mathcal{B} = \\{4, 3\\}$ and $\\mathcal{N} = \\{1, 2, 5\\}$.\nThe basis matrix $B$ and its inverse $B^{-1}$ are:\n$$ B = \\begin{pmatrix} a_4 & a_3 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\\\ 0 & 3 \\end{pmatrix}, \\quad B^{-1} = \\frac{1}{3}\\begin{pmatrix} 3 & -1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & -1/3 \\\\ 0 & 1/3 \\end{pmatrix} $$\nThe costs of the basic variables are $c_B = (c_4, c_3)^\\top = (0, 4)^\\top$.\n\n- Basic solution: $x_B = B^{-1} b = \\begin{pmatrix} 1 & -1/3 \\\\ 0 & 1/3 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix} = \\begin{pmatrix} 8-4 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 4 \\end{pmatrix}$. Thus, $s_1 = 4$, $x_3 = 4$. The objective value is $z = c_B^\\top x_B = 0(4) + 4(4) = 16$.\n- Dual vector: $y^{\\top} = c_B^\\top B^{-1} = \\begin{pmatrix} 0 & 4 \\end{pmatrix} \\begin{pmatrix} 1 & -1/3 \\\\ 0 & 1/3 \\end{pmatrix} = \\begin{pmatrix} 0 & 4/3 \\end{pmatrix}$.\n- Reduced costs of nonbasic variables $\\bar{c}_N = c_N - A_N^\\top y$:\n  - $\\bar{c}_1 = c_1 - y^{\\top} a_1 = 3 - \\begin{pmatrix} 0 & 4/3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = 3 - 8/3 = 1/3$.\n  - $\\bar{c}_2 = c_2 - y^{\\top} a_2 = 2 - \\begin{pmatrix} 0 & 4/3 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 2 - 4/3 = 2/3$.\n  - $\\bar{c}_5 = c_5 - y^{\\top} a_5 = 0 - \\begin{pmatrix} 0 & 4/3 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = -4/3$.\nThe largest positive reduced cost is $\\bar{c}_2 = 2/3$, so $x_2$ enters the basis.\n\n- Entering-column search direction: $d_B = -B^{-1} a_2 = -\\begin{pmatrix} 1 & -1/3 \\\\ 0 & 1/3 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = -\\begin{pmatrix} 2-1/3 \\\\ 1/3 \\end{pmatrix} = \\begin{pmatrix} -5/3 \\\\ -1/3 \\end{pmatrix}$.\n- Step length: $\\theta = \\min\\{-x_{B,i}/d_{B,i} : d_{B,i} < 0\\} = \\min\\{-4/(-5/3), -4/(-1/3)\\} = \\min\\{12/5, 12\\} = 12/5$.\nThe minimum ratio corresponds to the first basic variable, $s_1$. Thus, $s_1$ leaves the basis.\n\n**Iteration 2**\n\nThe new basis is $\\{x_2, x_3\\}$, so $\\mathcal{B} = \\{2, 3\\}$ and $\\mathcal{N} = \\{1, 4, 5\\}$.\nThe basis matrix $B$ and its inverse $B^{-1}$ are:\n$$ B = \\begin{pmatrix} a_2 & a_3 \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix}, \\quad B^{-1} = \\frac{1}{5}\\begin{pmatrix} 3 & -1 \\\\ -1 & 2 \\end{pmatrix} = \\begin{pmatrix} 3/5 & -1/5 \\\\ -1/5 & 2/5 \\end{pmatrix} $$\nThe costs of the basic variables are $c_B = (c_2, c_3)^\\top = (2, 4)^\\top$.\n\n- Basic solution: $x_B = B^{-1} b = \\begin{pmatrix} 3/5 & -1/5 \\\\ -1/5 & 2/5 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix} = \\begin{pmatrix} (24-12)/5 \\\\ (-8+24)/5 \\end{pmatrix} = \\begin{pmatrix} 12/5 \\\\ 16/5 \\end{pmatrix}$. Thus, $x_2 = 12/5$, $x_3 = 16/5$. The objective value is $z = c_B^\\top x_B = 2(12/5) + 4(16/5) = (24+64)/5 = 88/5$.\n- Dual vector: $y^{\\top} = c_B^\\top B^{-1} = \\begin{pmatrix} 2 & 4 \\end{pmatrix} \\begin{pmatrix} 3/5 & -1/5 \\\\ -1/5 & 2/5 \\end{pmatrix} = \\begin{pmatrix} (6-4)/5 & (-2+8)/5 \\end{pmatrix} = \\begin{pmatrix} 2/5 & 6/5 \\end{pmatrix}$.\n- Reduced costs of nonbasic variables $\\bar{c}_N = c_N - A_N^\\top y$:\n  - $\\bar{c}_1 = c_1 - y^{\\top} a_1 = 3 - \\begin{pmatrix} 2/5 & 6/5 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = 3 - (2/5 + 12/5) = 3 - 14/5 = 1/5$.\n  - $\\bar{c}_4 = c_4 - y^{\\top} a_4 = 0 - \\begin{pmatrix} 2/5 & 6/5 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = -2/5$.\n  - $\\bar{c}_5 = c_5 - y^{\\top} a_5 = 0 - \\begin{pmatrix} 2/5 & 6/5 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = -6/5$.\nThe only positive reduced cost is $\\bar{c}_1 = 1/5$, so $x_1$ enters the basis.\n\n- Entering-column search direction: $d_B = -B^{-1} a_1 = -\\begin{pmatrix} 3/5 & -1/5 \\\\ -1/5 & 2/5 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = -\\begin{pmatrix} (3-2)/5 \\\\ (-1+4)/5 \\end{pmatrix} = \\begin{pmatrix} -1/5 \\\\ -3/5 \\end{pmatrix}$.\n- Step length: $\\theta = \\min\\{-x_{B,i}/d_{B,i} : d_{B,i} < 0\\} = \\min\\{-(12/5)/(-1/5), -(16/5)/(-3/5)\\} = \\min\\{12, 16/3\\} = 16/3$.\nThe minimum ratio corresponds to the second basic variable, $x_3$. Thus, $x_3$ leaves the basis.\n\n**Iteration 3**\n\nThe new basis is $\\{x_2, x_1\\}$, so $\\mathcal{B} = \\{2, 1\\}$ and $\\mathcal{N} = \\{3, 4, 5\\}$.\nThe basis matrix $B$ and its inverse $B^{-1}$ are:\n$$ B = \\begin{pmatrix} a_2 & a_1 \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}, \\quad B^{-1} = \\frac{1}{3}\\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} = \\begin{pmatrix} 2/3 & -1/3 \\\\ -1/3 & 2/3 \\end{pmatrix} $$\nThe costs of the basic variables are $c_B = (c_2, c_1)^\\top = (2, 3)^\\top$.\n\n- Basic solution: $x_B = B^{-1} b = \\begin{pmatrix} 2/3 & -1/3 \\\\ -1/3 & 2/3 \\end{pmatrix} \\begin{pmatrix} 8 \\\\ 12 \\end{pmatrix} = \\begin{pmatrix} (16-12)/3 \\\\ (-8+24)/3 \\end{pmatrix} = \\begin{pmatrix} 4/3 \\\\ 16/3 \\end{pmatrix}$. Thus, $x_2 = 4/3$, $x_1 = 16/3$. The objective value is $z = c_B^\\top x_B = 2(4/3) + 3(16/3) = (8+48)/3 = 56/3$.\n- Dual vector: $y^{\\top} = c_B^\\top B^{-1} = \\begin{pmatrix} 2 & 3 \\end{pmatrix} \\begin{pmatrix} 2/3 & -1/3 \\\\ -1/3 & 2/3 \\end{pmatrix} = \\begin{pmatrix} (4-3)/3 & (-2+6)/3 \\end{pmatrix} = \\begin{pmatrix} 1/3 & 4/3 \\end{pmatrix}$.\n- Reduced costs of nonbasic variables $\\bar{c}_N = c_N - A_N^\\top y$:\n  - $\\bar{c}_3 = c_3 - y^{\\top} a_3 = 4 - \\begin{pmatrix} 1/3 & 4/3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = 4 - (1/3 + 12/3) = 4 - 13/3 = -1/3$.\n  - $\\bar{c}_4 = c_4 - y^{\\top} a_4 = 0 - \\begin{pmatrix} 1/3 & 4/3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = -1/3$.\n  - $\\bar{c}_5 = c_5 - y^{\\top} a_5 = 0 - \\begin{pmatrix} 1/3 & 4/3 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = -4/3$.\n\nAll reduced costs of the nonbasic variables are nonpositive ($\\bar{c}_3 = -1/3 \\le 0$, $\\bar{c}_4 = -1/3 \\le 0$, $\\bar{c}_5 = -4/3 \\le 0$). The optimality condition for maximization is satisfied. The current solution is optimal.\n\nThe optimal objective value is $z^\\star = 56/3$.",
            "answer": "$$\n\\boxed{\\frac{56}{3}}\n$$"
        },
        {
            "introduction": "The simplex method is powerful because it not only solves problems but also diagnoses their structure. This problem focuses on a critical diagnostic capability: identifying an unbounded linear program. You will examine the search direction vector $d$ for an entering variable and discover the specific condition that signals that the objective function can be increased without limit.",
            "id": "2197696",
            "problem": "An operations research analyst is solving a manufacturing optimization problem formulated as the following Linear Program (LP) using the revised simplex method:\nMaximize $Z = 3x_1 - x_2$\nSubject to:\n$x_1 - 2x_2 + x_3 = 10$\n$-2x_1 + x_2 + x_4 = 5$\n$x_1, x_2, x_3, x_4 \\ge 0$\n\nAfter an initial pivot, the set of basic variables is $\\{x_1, x_4\\}$. The inverse of the corresponding basis matrix $B$ is found to be:\n$$B^{-1} = \\begin{pmatrix} 1 & 0 \\\\ 2 & 1 \\end{pmatrix}$$\nThe analyst performs a pricing step and determines that the current basic feasible solution is not optimal and that variable $x_2$ should enter the basis. The column vector from the original constraint matrix corresponding to $x_2$ is $A_2 = \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$.\n\nThe next step in the revised simplex method is to compute the search direction vector $d = B^{-1}A_2$ to determine which variable should leave the basis. Based on the result of this computation, which of the following conclusions is correct?\n\nA. The current basic solution is optimal.\n\nB. The Linear Program is unbounded.\n\nC. Variable $x_1$ must leave the basis.\n\nD. Variable $x_4$ must leave the basis.\n\nE. The Linear Program is infeasible.",
            "solution": "In the revised simplex method, once an entering variable $x_{j}$ is chosen, the search direction for the basic variables is given by the vector $d = B^{-1}A_{j}$, where $A_{j}$ is the $j$th column of the original constraint matrix and $B^{-1}$ is the inverse of the current basis matrix.\n\nHere, the entering variable is $x_{2}$ and the given data are $B^{-1} = \\begin{pmatrix} 1 & 0 \\\\ 2 & 1 \\end{pmatrix}$ and $A_{2} = \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$. Compute the direction:\n$$\nd = B^{-1}A_{2} = \n\\begin{pmatrix} 1 & 0 \\\\ 2 & 1 \\end{pmatrix}\n\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}\n=\n\\begin{pmatrix} 1\\cdot(-2) + 0\\cdot 1 \\\\ 2\\cdot(-2) + 1\\cdot 1 \\end{pmatrix}\n=\n\\begin{pmatrix} -2 \\\\ -3 \\end{pmatrix}.\n$$\n\nIf $\\theta \\ge 0$ denotes the step size by which we increase the entering variable $x_{2}$, the basic variables update as $x_{B}(\\theta) = x_{B}(0) - \\theta d$. Primal feasibility requires $x_{B}(\\theta) \\ge 0$. This imposes upper bounds only from components with $d_{i} > 0$, via the minimum ratio test $\\theta \\le \\min\\{x_{B,i}/d_{i} : d_{i} > 0\\}$. In this case $d = \\begin{pmatrix} -2 \\\\ -3 \\end{pmatrix}$ has all components strictly negative, so $x_{B}(\\theta)$ increases componentwise as $\\theta$ increases and there is no feasibility bound on $\\theta$.\n\nSince the pricing step has already determined that $x_{2}$ should enter (i.e., moving in this direction improves the objective), and there is no bound on the step length, the Linear Program is unbounded in the improving direction. Therefore, no variable leaves the basis and the correct conclusion is that the LP is unbounded.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "For real-world applications, especially large-scale ones, the numerical stability of an algorithm is as important as its theoretical correctness. This advanced exercise introduces a more robust variant of the revised simplex method that avoids explicit matrix inversion by updating a QR factorization of the basis matrix. You will perform one of these updates using Givens rotations, gaining insight into the sophisticated numerical techniques used in modern optimization solvers.",
            "id": "2197697",
            "problem": "In optimizing numerical stability for the revised simplex method, one advanced technique replaces the explicit computation of the basis inverse with an update scheme for the QR factorization of the basis matrix. Consider an iteration of such an algorithm.\n\nLet the current $m \\times m$ basis matrix be $B = [b_1, \\dots, b_m]$, with a known QR factorization $B = QR$, where $Q$ is an orthogonal matrix and $R$ is an upper triangular matrix. A pivot operation involves replacing one column $b_p$ of the basis matrix with an entering column $a_q$ from the original constraint matrix $A$, resulting in a new basis matrix $B_{\\text{new}} = [b_1, \\dots, b_{p-1}, a_q, b_{p+1}, \\dots, b_m]$.\n\nThe QR factorization of $B_{\\text{new}}$ can be found efficiently. First, one computes the matrix $H = Q^T B_{\\text{new}}$. Because $Q^T B = R$, the columns of $H$ are the same as the columns of $R$, except for the $p$-th column, which becomes $Q^T a_q$. This makes $H$ an upper Hessenberg matrix (i.e., $H_{ij} = 0$ for $i > j+1$). To restore the upper triangular form, a sequence of Givens rotations is applied to annihilate the subdiagonal elements of $H$. For a given $p$, this sequence is $G = G_{m-1,m} \\cdots G_{p+1,p+2} G_{p,p+1}$, where $G_{k, k+1}$ is a Givens rotation in the $(k, k+1)$ plane. The new upper triangular matrix is then $R_{\\text{new}} = GH$.\n\nSuppose for a problem with $m=3$ constraints, the algorithm is at a state with the basis matrix\n$$B = \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix}$$\nand its corresponding QR factorization is given by\n$$Q = \\begin{pmatrix} 1/\\sqrt{2} & 1/\\sqrt{6} & -1/\\sqrt{3} \\\\ 1/\\sqrt{2} & -1/\\sqrt{6} & 1/\\sqrt{3} \\\\ 0 & 2/\\sqrt{6} & 1/\\sqrt{3} \\end{pmatrix}, \\quad R = \\begin{pmatrix} \\sqrt{2} & 1/\\sqrt{2} & 1/\\sqrt{2} \\\\ 0 & \\sqrt{3/2} & 1/\\sqrt{6} \\\\ 0 & 0 & 2/\\sqrt{3} \\end{pmatrix}$$\nIn the current pivot step, the column $b_2$ (the second column of $B$) is chosen to leave the basis, so $p=2$. It is replaced by the entering column vector $a_q = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$.\n\nFollowing the procedure described, determine the new upper triangular matrix $R_{\\text{new}}$.",
            "solution": "The goal is to compute the new upper triangular matrix $R_{\\text{new}}$ after updating the basis matrix $B$. The process involves two main steps: forming the intermediate upper Hessenberg matrix $H$ and then applying a Givens rotation to restore its upper triangular structure.\n\n**Step 1: Form the upper Hessenberg matrix $H$.**\n\nThe current basis is $B = [b_1, b_2, b_3]$, and the new basis is $B_{\\text{new}} = [b_1, a_q, b_3]$, since the second column ($p=2$) is replaced.\nThe matrix $H$ is defined as $H = Q^T B_{\\text{new}} = Q^T [b_1, a_q, b_3] = [Q^T b_1, Q^T a_q, Q^T b_3]$.\n\nFrom the given QR factorization $B=QR$, we know that $Q^T B = R$. This means $Q^T[b_1, b_2, b_3] = [r_1, r_2, r_3]$, where $r_i$ are the columns of $R$.\nTherefore, the first and third columns of $H$ are simply the first and third columns of $R$:\n$h_1 = r_1 = \\begin{pmatrix} \\sqrt{2} \\\\ 0 \\\\ 0 \\end{pmatrix}$\n$h_3 = r_3 = \\begin{pmatrix} 1/\\sqrt{2} \\\\ 1/\\sqrt{6} \\\\ 2/\\sqrt{3} \\end{pmatrix}$\n\nThe second column of $H$, $h_2$, is given by $Q^T a_q$. We compute this product:\n$$h_2 = Q^T a_q = \\begin{pmatrix} 1/\\sqrt{2} & 1/\\sqrt{2} & 0 \\\\ 1/\\sqrt{6} & -1/\\sqrt{6} & 2/\\sqrt{6} \\\\ -1/\\sqrt{3} & 1/\\sqrt{3} & 1/\\sqrt{3} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$$\n$$h_2 = \\begin{pmatrix} (1/\\sqrt{2}) \\cdot 1 + (1/\\sqrt{2}) \\cdot 1 + 0 \\cdot 1 \\\\ (1/\\sqrt{6}) \\cdot 1 + (-1/\\sqrt{6}) \\cdot 1 + (2/\\sqrt{6}) \\cdot 1 \\\\ (-1/\\sqrt{3}) \\cdot 1 + (1/\\sqrt{3}) \\cdot 1 + (1/\\sqrt{3}) \\cdot 1 \\end{pmatrix} = \\begin{pmatrix} 2/\\sqrt{2} \\\\ 2/\\sqrt{6} \\\\ 1/\\sqrt{3} \\end{pmatrix} = \\begin{pmatrix} \\sqrt{2} \\\\ \\sqrt{2/3} \\\\ 1/\\sqrt{3} \\end{pmatrix}$$\n\nNow we assemble the matrix $H$:\n$$H = [h_1, h_2, h_3] = \\begin{pmatrix} \\sqrt{2} & \\sqrt{2} & 1/\\sqrt{2} \\\\ 0 & \\sqrt{2/3} & 1/\\sqrt{6} \\\\ 0 & 1/\\sqrt{3} & 2/\\sqrt{3} \\end{pmatrix}$$\nThis is an upper Hessenberg matrix, with a single non-zero subdiagonal element at $H_{3,2} = 1/\\sqrt{3}$.\n\n**Step 2: Apply a Givens rotation to restore upper triangular form.**\n\nWe need to annihilate the element $H_{3,2}$. Since the leaving column index is $p=2$ and $m=3$, the general sequence of rotations $G_{m-1,m} \\cdots G_{p,p+1}$ simplifies to a single rotation, $G_{2,3}$. This rotation acts on rows 2 and 3.\n\nA Givens rotation matrix $G_{2,3}$ has the form $\\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & c & s \\\\ 0 & -s & c \\end{pmatrix}$, where $c=\\cos\\theta$ and $s=\\sin\\theta$. It is designed such that when applied to $H$, the new element at position $(3,2)$ is zero.\n$$ \\begin{pmatrix} c & s \\\\ -s & c \\end{pmatrix} \\begin{pmatrix} H_{2,2} \\\\ H_{3,2} \\end{pmatrix} = \\begin{pmatrix} \\text{new } H_{2,2}' \\\\ 0 \\end{pmatrix} $$\nThe condition for the second component to be zero is $-s \\cdot H_{2,2} + c \\cdot H_{3,2} = 0$.\nWe have $H_{2,2} = \\sqrt{2/3}$ and $H_{3,2} = 1/\\sqrt{3}$.\nThe values for $c$ and $s$ can be calculated as:\n$$r = \\sqrt{H_{2,2}^2 + H_{3,2}^2} = \\sqrt{(\\sqrt{2/3})^2 + (1/\\sqrt{3})^2} = \\sqrt{2/3 + 1/3} = \\sqrt{1} = 1$$\n$$c = \\frac{H_{2,2}}{r} = \\frac{\\sqrt{2/3}}{1} = \\sqrt{2/3}$$\n$$s = \\frac{H_{3,2}}{r} = \\frac{1/\\sqrt{3}}{1} = 1/\\sqrt{3}$$\nSo, the Givens rotation matrix is:\n$$G_{2,3} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & \\sqrt{2/3} & 1/\\sqrt{3} \\\\ 0 & -1/\\sqrt{3} & \\sqrt{2/3} \\end{pmatrix}$$\n\nFinally, we compute $R_{\\text{new}} = G_{2,3} H$:\n$$R_{\\text{new}} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & \\sqrt{2/3} & 1/\\sqrt{3} \\\\ 0 & -1/\\sqrt{3} & \\sqrt{2/3} \\end{pmatrix} \\begin{pmatrix} \\sqrt{2} & \\sqrt{2} & 1/\\sqrt{2} \\\\ 0 & \\sqrt{2/3} & 1/\\sqrt{6} \\\\ 0 & 1/\\sqrt{3} & 2/\\sqrt{3} \\end{pmatrix}$$\n\nThe first row of $R_{\\text{new}}$ is the same as the first row of $H$: $(\\sqrt{2}, \\sqrt{2}, 1/\\sqrt{2})$.\n\nThe second row of $R_{\\text{new}}$ is:\n$R_{\\text{new},21} = 0$\n$R_{\\text{new},22} = (\\sqrt{2/3})(\\sqrt{2/3}) + (1/\\sqrt{3})(1/\\sqrt{3}) = 2/3 + 1/3 = 1$\n$R_{\\text{new},23} = (\\sqrt{2/3})(1/\\sqrt{6}) + (1/\\sqrt{3})(2/\\sqrt{3}) = \\sqrt{2/18} + 2/3 = \\sqrt{1/9} + 2/3 = 1/3 + 2/3 = 1$\n\nThe third row of $R_{\\text{new}}$ is:\n$R_{\\text{new},31} = 0$\n$R_{\\text{new},32} = (-1/\\sqrt{3})(\\sqrt{2/3}) + (\\sqrt{2/3})(1/\\sqrt{3}) = 0$ (as expected)\n$R_{\\text{new},33} = (-1/\\sqrt{3})(1/\\sqrt{6}) + (\\sqrt{2/3})(2/\\sqrt{3}) = -1/\\sqrt{18} + 2\\sqrt{2}/3 = -1/(3\\sqrt{2}) + 2\\sqrt{2}/3 = -\\sqrt{2}/6 + 4\\sqrt{2}/6 = 3\\sqrt{2}/6 = \\sqrt{2}/2 = 1/\\sqrt{2}$\n\nAssembling the matrix $R_{\\text{new}}$ gives:\n$$R_{\\text{new}} = \\begin{pmatrix} \\sqrt{2} & \\sqrt{2} & 1/\\sqrt{2} \\\\ 0 & 1 & 1 \\\\ 0 & 0 & 1/\\sqrt{2} \\end{pmatrix}$$\nThis is the new upper triangular matrix.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\sqrt{2} & \\sqrt{2} & \\frac{1}{\\sqrt{2}} \\\\\n0 & 1 & 1 \\\\\n0 & 0 & \\frac{1}{\\sqrt{2}}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}