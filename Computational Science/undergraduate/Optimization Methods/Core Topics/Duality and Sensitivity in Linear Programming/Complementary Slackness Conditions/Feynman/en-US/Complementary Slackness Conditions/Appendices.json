{
    "hands_on_practices": [
        {
            "introduction": "The complementary slackness theorem provides a powerful check for the optimality of a proposed solution to a linear program. Before diving into complex solving algorithms, it's crucial to understand how to verify if a candidate solution is indeed optimal. This practice provides a concrete scenario to test your understanding of the conditions by systematically checking them for a given primal-dual solution pair .",
            "id": "2160340",
            "problem": "A food production company makes two types of baked goods: 'Standard' and 'Deluxe'. The production is constrained by the availability of two special ingredients (A and B) and total oven time. The company wants to maximize profit. The optimization problem is modeled as a Linear Program (LP).\n\nThe primal LP is formulated as follows:\nMaximize $Z = 3x_1 + 5x_2$\nSubject to:\n1. $x_1 \\le 4$             (Ingredient A constraint, in kg)\n2. $2x_2 \\le 12$            (Ingredient B constraint, in kg)\n3. $3x_1 + 2x_2 \\le 18$    (Oven time constraint, in hours)\n4. $x_1, x_2 \\ge 0$\n\nwhere $x_1$ and $x_2$ are the quantities (in hundreds of units) of 'Standard' and 'Deluxe' goods produced, respectively.\n\nThe corresponding dual LP is:\nMinimize $W = 4y_1 + 12y_2 + 18y_3$\nSubject to:\n1. $y_1 + 3y_3 \\ge 3$\n2. $2y_2 + 2y_3 \\ge 5$\n3. $y_1, y_2, y_3 \\ge 0$\n\nwhere $y_1, y_2, y_3$ are the shadow prices associated with Ingredient A, Ingredient B, and oven time, respectively.\n\nAn analyst has proposed a potential optimal solution pair: a primal solution vector $x' = (2, 6)$ and a dual solution vector $y'=(0, 1, 1.5)$. According to the theory of complementary slackness, for a pair of feasible primal and dual solutions to be optimal, specific conditions must hold. Your task is to check these conditions for the given pair $(x', y')$.\n\nWhich one of the following complementary slackness conditions is NOT satisfied by the proposed solution pair?\n\nA. The condition associated with the primal variable $x_1$.\n\nB. The condition associated with the primal variable $x_2$.\n\nC. The condition associated with the first primal inequality constraint (Ingredient A).\n\nD. The condition associated with the second primal inequality constraint (Ingredient B).\n\nE. The condition associated with the third primal inequality constraint (Oven time).",
            "solution": "To determine which complementary slackness condition is not satisfied, we must systematically check all five conditions for the given primal solution $x'=(x_1', x_2') = (2, 6)$ and dual solution $y'=(y_1', y_2', y_3') = (0, 1, 1.5)$. First, we confirm both solutions are feasible.\nFor $x'=(2,6)$:\n1. $x_1' = 2 \\le 4$ (OK)\n2. $2x_2' = 2(6) = 12 \\le 12$ (OK)\n3. $3x_1' + 2x_2' = 3(2) + 2(6) = 18 \\le 18$ (OK)\nPrimal solution is feasible.\n\nFor $y'=(0, 1, 1.5)$:\n1. $y_1' + 3y_3' = 0 + 3(1.5) = 4.5 \\ge 3$ (OK)\n2. $2y_2' + 2y_3' = 2(1) + 2(1.5) = 2+3=5 \\ge 5$ (OK)\nDual solution is feasible.\n\nThe complementary slackness conditions can be stated in two parts:\n1.  If a primal decision variable $x_j'$ is positive ($x_j' > 0$), then the $j$-th dual constraint must be tight (i.e., hold with equality).\n2.  If a primal constraint is not tight (i.e., has positive slack), then the corresponding dual variable $y_i'$ must be zero.\n\nLet's examine each condition:\n\n**A. The condition associated with the primal variable $x_1$.**\nThe primal variable is $x_1' = 2$. Since $x_1' > 0$, the corresponding first dual constraint, $y_1 + 3y_3 \\ge 3$, must be tight. Let's substitute the values from $y'$:\n$y_1' + 3y_3' = 0 + 3 \\times (1.5) = 4.5$.\nThe condition requires this to be equal to 3. Since $4.5 \\neq 3$, this complementary slackness condition is **not satisfied**.\n\n**B. The condition associated with the primal variable $x_2$.**\nThe primal variable is $x_2' = 6$. Since $x_2' > 0$, the corresponding second dual constraint, $2y_2 + 2y_3 \\ge 5$, must be tight. Let's substitute the values from $y'$:\n$2y_2' + 2y_3' = 2 \\times (1) + 2 \\times (1.5) = 2 + 3 = 5$.\nThe condition requires this to be equal to 5. Since $5 = 5$, this complementary slackness condition is satisfied.\n\n**C. The condition associated with the first primal inequality constraint (Ingredient A).**\nThe first primal constraint is $x_1 \\le 4$. Let's calculate its slack using $x_1' = 2$:\nSlack = $4 - x_1' = 4 - 2 = 2$.\nSince the slack is non-zero ($2 > 0$), the constraint is not tight. Therefore, the corresponding dual variable, $y_1'$, must be zero.\nThe proposed dual solution gives $y_1' = 0$. Since this is true, this complementary slackness condition is satisfied.\n\n**D. The condition associated with the second primal inequality constraint (Ingredient B).**\nThe second primal constraint is $2x_2 \\le 12$. Let's calculate its slack using $x_2' = 6$:\nSlack = $12 - 2x_2' = 12 - 2(6) = 12 - 12 = 0$.\nSince the slack is zero, the constraint is tight. The complementary slackness condition ($y_2' \\times \\text{slack} = 0$) is always satisfied when the slack is zero, regardless of the value of the dual variable. This condition is satisfied.\n\n**E. The condition associated with the third primal inequality constraint (Oven time).**\nThe third primal constraint is $3x_1 + 2x_2 \\le 18$. Let's calculate its slack using $x'=(2, 6)$:\nSlack = $18 - (3x_1' + 2x_2') = 18 - (3(2) + 2(6)) = 18 - (6 + 12) = 18 - 18 = 0$.\nSince the slack is zero, the constraint is tight. As with the previous case, the condition is automatically satisfied.\n\nBased on the step-by-step verification, only the condition associated with the primal variable $x_1$ is violated.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Beyond just verifying optimality, complementary slackness offers a constructive method for solving linear programs if partial information is available. When the optimal solution to the dual problem is known, the conditions create a system of equations that can directly reveal the optimal primal solution. This exercise challenges you to apply this principle, transforming the abstract theory into a practical problem-solving tool .",
            "id": "2160337",
            "problem": "Consider the following Linear Programming (LP) problem, which we will refer to as the primal problem (P):\n\nMaximize the objective function $Z = 15x_1 + 6x_2 + 10x_3$\n\nSubject to the constraints:\n1. $x_1 + x_2 + 2x_3 \\le 9$\n2. $3x_1 + x_2 + x_3 \\le 17$\n3. $x_1 \\ge 0, x_2 \\ge 0, x_3 \\ge 0$\n\nYou are given that the optimal solution vector for the corresponding dual problem is $y^* = (y_1^*, y_2^*) = (3, 4)$. Using only this information and the principle of complementary slackness, determine the optimal solution vector $x^* = (x_1^*, x_2^*, x_3^*)$ for the primal problem (P). The final answer should be expressed as a row vector.",
            "solution": "Write the primal in matrix form as maximize $c^{\\top}x$ subject to $Ax \\le b$, $x \\ge 0$, where\n$$\nA=\\begin{pmatrix}\n1 & 1 & 2\\\\\n3 & 1 & 1\n\\end{pmatrix},\\quad\nb=\\begin{pmatrix}\n9\\\\\n17\n\\end{pmatrix},\\quad\nc=\\begin{pmatrix}\n15\\\\\n6\\\\\n10\n\\end{pmatrix}.\n$$\nThe dual is minimize $b^{\\top}y$ subject to $A^{\\top}y \\ge c$, $y \\ge 0$, i.e.,\n$$\n\\begin{aligned}\n&y_{1}+3y_{2} \\ge 15,\\\\\n&y_{1}+y_{2} \\ge 6,\\\\\n&2y_{1}+y_{2} \\ge 10,\\\\\n&y_{1} \\ge 0,\\; y_{2} \\ge 0.\n\\end{aligned}\n$$\nGiven $y^{*}=(3,4)$, compute the dual slack vector $A^{\\top}y^{*}-c$ componentwise:\n$$\n\\begin{aligned}\n&(A^{\\top}y^{*}-c)_{1}=(1)(3)+(3)(4)-15=15-15=0,\\\\\n&(A^{\\top}y^{*}-c)_{2}=(1)(3)+(1)(4)-6=7-6=1,\\\\\n&(A^{\\top}y^{*}-c)_{3}=(2)(3)+(1)(4)-10=10-10=0.\n\\end{aligned}\n$$\nBy complementary slackness, for each $j$, $x_{j}^{*}\\big((A^{\\top}y^{*}-c)_{j}\\big)=0$. Since the second component of the dual slack is positive (1 > 0), this implies\n$$\nx_{2}^{*}\\cdot 1=0 \\implies x_{2}^{*}=0,\n$$\nwhile $x_{1}^{*}$ and $x_{3}^{*}$ are not forced to be zero by this condition.\n\nComplementary slackness also gives, for each $i$, $y_{i}^{*}\\big(b_{i}-(Ax^{*})_{i}\\big)=0$. Since $y_{1}^{*}=3>0$ and $y_{2}^{*}=4>0$, both primal constraints must be tight:\n$$\n\\begin{aligned}\nx_{1}+x_{2}+2x_{3}&=9,\\\\\n3x_{1}+x_{2}+x_{3}&=17.\n\\end{aligned}\n$$\nWith $x_{2}^{*}=0$, we solve the system:\n$$\n\\begin{aligned}\nx_{1}+2x_{3}&=9,\\\\\n3x_{1}+x_{3}&=17.\n\\end{aligned}\n$$\nFrom the first equation, $x_{1}=9-2x_{3}$. Substitute into the second:\n$$\n3(9-2x_{3})+x_{3}=17 \\;\\Rightarrow\\; 27-6x_{3}+x_{3}=17 \\;\\Rightarrow\\; -5x_{3}=-10 \\;\\Rightarrow\\; x_{3}^{*}=2.\n$$\nThen $x_{1}^{*}=9-2(2)=5$. The nonnegativity constraints $x_1^* \\ge 0, x_3^* \\ge 0$ hold. The solution satisfies all complementary slackness conditions. As a consistency check, the primal objective equals the dual objective:\n$$\n15x_{1}^{*}+6x_{2}^{*}+10x_{3}^{*}=15(5)+6(0)+10(2)=95,\\quad b^{\\top}y^{*}=9(3)+17(4)=27+68=95.\n$$\nTherefore, the optimal primal solution is $x^{*}=(5,0,2)$.",
            "answer": "$$\\boxed{\\begin{pmatrix}5 & 0 & 2\\end{pmatrix}}$$"
        },
        {
            "introduction": "In many textbook examples, optimal solutions are well-behaved, but real-world problems can exhibit a property called degeneracy, which has significant implications for algorithms. This advanced practice explores the concept of *strict* complementary slackness and what happens when it fails. By analyzing a degenerate case, you will gain insight into the sensitivity of solutions and the numerical challenges that can arise in optimization software .",
            "id": "3109916",
            "problem": "Consider the linear programming (LP) problem in primal standard form: minimize $c^{\\top} x$ subject to $A x = b$, $x \\ge 0$, where $A \\in \\mathbb{R}^{m \\times n}$ has full row rank. The associated dual is to maximize $b^{\\top} y$ subject to $A^{\\top} y \\le c$, which can be represented with dual slack variables $s \\ge 0$ satisfying $A^{\\top} y + s = c$. The Karush–Kuhn–Tucker (KKT) conditions for optimality consist of primal feasibility ($A x = b$, $x \\ge 0$), dual feasibility ($A^{\\top} y + s = c$, $s \\ge 0$), and complementary slackness ($x_j s_j = 0$ for each index $j \\in \\{1,\\dots,n\\}$).\n\nConstruct the specific instance with $A = [1\\ 1]$, $b = 1$, and $c = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$. \n\nTasks:\n- From first principles, write down the primal and dual problems for this instance and explain the KKT conditions (without invoking any shortcut formulas beyond the definitions above).\n- Find a primal–dual optimal pair $(x^{\\star}, y^{\\star}, s^{\\star})$ and verify complementary slackness $x_j^{\\star} s_j^{\\star} = 0$ for $j \\in \\{1,2\\}$. Identify an index $j$ for which both $x_j^{\\star} = 0$ and $s_j^{\\star} = 0$ hold at the optimum, thereby demonstrating the failure of strict complementarity (strict complementarity is the condition $x_j^{\\star} + s_j^{\\star} > 0$ for all $j$).\n- Perform a sensitivity thought experiment: perturb the cost to $c(\\varepsilon) = \\begin{bmatrix} 1 \\\\ 1 + \\varepsilon \\end{bmatrix}$ with a small parameter $\\varepsilon \\in \\mathbb{R}$, and reason about how the optimal solution $x^{\\star}(\\varepsilon)$ and the active set change with the sign of $\\varepsilon$. Discuss the implications of the strict complementarity failure you observed for sensitivity and for the numerical stability of algorithms such as the Simplex method and interior-point methods when $\\varepsilon$ is near $0$.\n\nSelect the single best statement among the options that accurately reflects the conclusions of your analysis for this instance:\n\nA. There exists an optimal primal–dual pair with $x_1^{\\star} = 0$ and $s_1^{\\star} = 0$, so strict complementarity fails. Because the optimal set is a nontrivial face, arbitrarily small perturbations of $c$ can cause discontinuous changes in the optimal basic variables, and both the Simplex method and interior-point methods may exhibit stalling or ill-conditioning near this degenerate optimum.\n\nB. Strict complementarity holds for all optimal solutions, so small perturbations of $c$ leave the basic variables unchanged, and algorithms are guaranteed to converge in a single iteration.\n\nC. Complementary slackness is violated because $x_2^{\\star} s_2^{\\star} = 1 \\cdot 0 \\ne 0$.\n\nD. Under the perturbation $c(\\varepsilon) = \\begin{bmatrix} 1 \\\\ 1 + \\varepsilon \\end{bmatrix}$, the unique optimal solution remains $x_1^{\\star} = 0$, $x_2^{\\star} = 1$ for all sufficiently small $\\varepsilon$, demonstrating robustness to cost changes.\n\nE. Degeneracy affects only the dual problem; in the primal, strict complementarity cannot fail when $A$ has full row rank, and the Simplex method cannot stall in problems with a single equality constraint.",
            "solution": "The primal problem is to minimize $x_1 + x_2$ subject to $x_1 + x_2 = 1$, with $x_1, x_2 \\ge 0$. The objective function is constant on the feasible set, so any feasible point is optimal. The optimal set is the line segment connecting $(1,0)$ and $(0,1)$.\nThe dual problem is to maximize $y$ subject to $y \\le 1$ and $y \\le 1$. The unique dual optimal solution is $y^{\\star} = 1$.\nThe dual slack variables are given by $y + s_1 = 1$ and $y + s_2 = 1$. With $y^{\\star} = 1$, we get $s_1^{\\star} = 0$ and $s_2^{\\star} = 0$.\n\nLet's test for strict complementarity failure. Strict complementarity requires $x_j^{\\star} + s_j^{\\star} > 0$ for all $j$. Let's pick the primal optimal solution $x^{\\star} = (0, 1)$. The corresponding primal-dual pair is $(x^{\\star}, y^{\\star}, s^{\\star}) = ((0, 1), 1, (0, 0))$.\nFor $j=1$: $x_1^{\\star} + s_1^{\\star} = 0 + 0 = 0$. This violates strict complementarity. Thus, strict complementarity fails. This demonstrates that Option A's first claim is correct (for the optimal solution where $x^{\\star}=(0,1)$, we have $x_1^{\\star}=0$ and $s_1^{\\star}=0$).\n\nNow, let's perform the sensitivity analysis. We perturb the cost to $c(\\varepsilon) = \\begin{bmatrix} 1 \\\\ 1 + \\varepsilon \\end{bmatrix}$. The primal objective becomes to minimize $x_1 + (1+\\varepsilon)x_2$. Substituting $x_1 = 1 - x_2$, the objective is to minimize $(1 - x_2) + (1+\\varepsilon)x_2 = 1 + \\varepsilon x_2$, for $x_2 \\in [0, 1]$.\n- If $\\varepsilon > 0$, we must minimize $x_2$, so the unique optimal solution is $x_2^{\\star} = 0$, which means $x^{\\star} = (1, 0)$.\n- If $\\varepsilon  0$, we must maximize $x_2$, so the unique optimal solution is $x_2^{\\star} = 1$, which means $x^{\\star} = (0, 1)$.\nAs $\\varepsilon$ crosses 0, the optimal solution jumps discontinuously from $(0, 1)$ to $(1, 0)$. This confirms the claim in Option A about sensitivity to perturbations.\n\nThis degeneracy (multiple optimal solutions at $\\varepsilon=0$) and failure of strict complementarity lead to numerical issues. The Simplex method can \"stall\" by pivoting between basic solutions (like $(1,0)$ and $(0,1)$) with the same objective value. Interior-point methods face ill-conditioned matrices near the optimum because both primal and dual variables for the same index are approaching zero, which hinders convergence.\n\nTherefore, Option A correctly summarizes all these points.\n- Option B is incorrect because strict complementarity fails.\n- Option C is mathematically incorrect ($1 \\cdot 0 = 0$).\n- Option D is incorrect as the solution is highly sensitive to the sign of $\\varepsilon$.\n- Option E makes several false claims: degeneracy is present in both primal (multiple optima) and dual (redundant constraints), strict complementarity can and does fail, and Simplex can stall.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}