{
    "hands_on_practices": [
        {
            "introduction": "线性规划（Linear Programming, LP）是最基础也是最重要的优化问题之一。虽然我们常常直接使用其对称的对偶形式，但从更通用的拉格朗日对偶框架出发，可以揭示其深刻的内在联系。这个练习将指导你从第一性原理出发，为标准的线性规划问题推导出其对偶问题。通过这个过程，并利用互补松弛性（complementary slackness）求解一个具体实例，你将深入理解原始问题和对偶问题解之间的机械联系。",
            "id": "3139594",
            "problem": "考虑以下标准不等式形式的最小化线性规划 (LP) 问题：最小化线性目标函数，约束条件为线性不等式约束和非负性约束，\n$$\\min_{x \\in \\mathbb{R}^{n}} \\; c^{\\top} x \\quad \\text{subject to} \\quad A x \\ge b, \\; x \\ge 0,$$\n其中 $A \\in \\mathbb{R}^{m \\times n}$，$b \\in \\mathbb{R}^{m}$，且 $c \\in \\mathbb{R}^{n}$。使用基本的拉格朗日对偶框架以及弱对偶和强对偶的定义（不使用任何预先记下的对偶公式），通过为每个不等式约束引入适当的非负拉格朗日乘子，推导出与上述原始问题相对应的对偶优化问题。明确说明所得到的对偶决策变量、约束和目标函数。\n\n接下来，将问题具体化到维度为 $m = 3$ 和 $n = 2$ 的具体实例，由下式给出：\n$$A = \\begin{pmatrix} 2  0 \\\\ 0  3 \\\\ 1  1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 4 \\\\ 3 \\\\ 5 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 5 \\\\ 4 \\end{pmatrix}.$$\n使用从线性规划的 Karush-Kuhn-Tucker (KKT) 条件推导出的互补松弛性，来确定对于此实例，在最优解处，哪些原始约束 $A x \\ge b$ 是紧的，哪些是松的。然后，推断出对偶最优解，并通过强对偶性验证其最优性。最后，计算此实例的最优原始目标值 $c^{\\top} x^{\\star}$，并将其表示为一个精确的实数。最终答案无需四舍五入。",
            "solution": "用户提供了一个关于线性规划（LP）对偶性的多部分问题。第一部分要求使用拉格朗日框架从第一性原理出发，对对偶问题进行形式化推导。第二部分涉及将此理论应用于一个具体的 LP 实例，以找到原始和对偶最优解，验证最优性，并确定最优目标值。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n问题提供了以下信息：\n1.  一个标准不等式形式的原始LP问题：\n    $$\\min_{x \\in \\mathbb{R}^{n}} \\; c^{\\top} x \\quad \\text{subject to} \\quad A x \\ge b, \\; x \\ge 0$$\n    其中 $A \\in \\mathbb{R}^{m \\times n}$，$b \\in \\mathbb{R}^{m}$，且 $c \\in \\mathbb{R}^{n}$。\n2.  一项任务，要求使用拉格朗日框架，通过引入非负拉格朗日乘子来推导对偶问题。\n3.  一个维度为 $m = 3$ 和 $n = 2$ 的具体实例：\n    $$A = \\begin{pmatrix} 2  0 \\\\ 0  3 \\\\ 1  1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 4 \\\\ 3 \\\\ 5 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 5 \\\\ 4 \\end{pmatrix}$$\n4.  一项任务，要求使用互补松弛性来确定对于此实例，在最优解处哪些原始约束 $A x \\ge b$ 是紧的，推断出对偶最优解，通过强对偶性验证最优性，并计算最优原始目标值 $c^{\\top} x^{\\star}$。\n\n**步骤2：使用提取的已知条件进行验证**\n\n该问题是数学优化领域的一个标准、基础的练习，特别关注线性规划中的对偶理论。\n-   **科学依据：** 该问题完全基于优化和线性代数中已建立的数学原理。它没有任何科学或事实上的不健全之处。\n-   **适定性：** 问题结构清晰。所要求的推导是一个标准程序，具体的LP实例是明确定义的，并且有唯一的最优解，使其成为一个适定问题。\n-   **客观性：** 语言精确、数学化，没有任何主观性或歧义。\n-   **完整性：** 所有必要的数据（$A, b, c$）和理论背景（拉格朗日对偶、KKT条件、互补松弛性）都已提供，或者是解决此类问题的标准先决条件。该问题是自洽的。\n\n**步骤3：结论与行动**\n\n该问题是有效的。它是一个适定的、有科学依据的、客观的数学优化问题。我将继续提供完整解答。\n\n### 第1部分：对偶问题的推导\n\n原始问题如下：\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\; c^{\\top} x \\quad \\text{subject to} \\quad A x \\ge b, \\; x \\ge 0\n$$\n为了应用拉格朗日框架，我们首先将不等式约束表示为 $f_i(x) \\le 0$ 的形式。约束条件是：\n1.  $A x \\ge b \\iff b - A x \\le 0$ (一组 $m$ 个不等式)\n2.  $x \\ge 0 \\iff -x \\le 0$ (一组 $n$ 个不等式)\n\n我们为这些约束中的每一个引入非负拉格朗日乘子。令 $\\lambda \\in \\mathbb{R}^m$ 为约束 $b - A x \\le 0$ 的乘子向量，因此 $\\lambda \\ge 0$。令 $\\mu \\in \\mathbb{R}^n$ 为约束 $-x \\le 0$ 的乘子向量，因此 $\\mu \\ge 0$。\n\n拉格朗日函数 $L(x, \\lambda, \\mu)$ 定义为目标函数加上各乘子与其对应约束函数的乘积之和：\n$$\nL(x, \\lambda, \\mu) = c^{\\top} x + \\lambda^{\\top}(b - A x) + \\mu^{\\top}(-x)\n$$\n我们可以通过收集包含原始变量 $x$ 的项来重新整理这些项：\n$$\nL(x, \\lambda, \\mu) = c^{\\top} x - \\lambda^{\\top} A x - \\mu^{\\top} x + \\lambda^{\\top} b\n$$\n$$\nL(x, \\lambda, \\mu) = (c^{\\top} - \\lambda^{\\top} A - \\mu^{\\top})x + b^{\\top} \\lambda\n$$\n使用转置可以将其写得更紧凑：\n$$\nL(x, \\lambda, \\mu) = (c - A^{\\top} \\lambda - \\mu)^{\\top}x + b^{\\top} \\lambda\n$$\n拉格朗日对偶函数，记为 $g(\\lambda, \\mu)$，定义为拉格朗日函数关于原始变量 $x$ 的下确界：\n$$\ng(\\lambda, \\mu) = \\inf_{x \\in \\mathbb{R}^n} L(x, \\lambda, \\mu) = \\inf_{x \\in \\mathbb{R}^n} \\left[ (c - A^{\\top} \\lambda - \\mu)^{\\top}x + b^{\\top} \\lambda \\right]\n$$\n下确界内的表达式是 $x$ 的一个仿射（线性加常数）函数。如果 $x$ 的系数向量非零，即 $c - A^{\\top} \\lambda - \\mu \\ne 0$，则该函数下无界，其下确界为 $-\\infty$。为了得到对偶函数的有限值，$x$ 的线性项必须为零。这对对偶变量 $\\lambda$ 和 $\\mu$ 施加了一个约束：\n$$\nc - A^{\\top} \\lambda - \\mu = 0\n$$\n当这个条件成立时，拉格朗日函数就与 $x$ 无关，其值就是 $b^{\\top} \\lambda$。因此，对偶函数是：\n$$\ng(\\lambda, \\mu) = \\begin{cases}\nb^{\\top}\\lambda  \\text{if } c - A^{\\top}\\lambda - \\mu = 0 \\\\\n-\\infty  \\text{otherwise}\n\\end{cases}\n$$\n对偶问题是在对偶变量的约束条件下最大化对偶函数：\n$$\n\\max_{\\lambda, \\mu} \\; g(\\lambda, \\mu) \\quad \\text{subject to} \\quad \\lambda \\ge 0, \\; \\mu \\ge 0\n$$\n最大化 $g(\\lambda, \\mu)$ 等价于在使 $g(\\lambda, \\mu)$ 有限的条件下最大化 $b^{\\top}\\lambda$。因此，对偶问题是：\n$$\n\\max_{\\lambda, \\mu} \\; b^{\\top}\\lambda \\quad \\text{subject to} \\quad c - A^{\\top}\\lambda - \\mu = 0, \\quad \\lambda \\ge 0, \\quad \\mu \\ge 0\n$$\n我们可以消去对偶变量 $\\mu$。约束 $c - A^{\\top}\\lambda - \\mu = 0$ 意味着 $\\mu = c - A^{\\top}\\lambda$。非负性约束 $\\mu \\ge 0$ 于是变为 $c - A^{\\top}\\lambda \\ge 0$，这等价于 $A^{\\top}\\lambda \\le c$。\n\n将此代回优化问题，我们得到仅用对偶变量 $\\lambda$ 表示的对偶问题：\n-   对偶决策变量：$\\lambda \\in \\mathbb{R}^m$。\n-   对偶目标函数：最大化 $b^{\\top}\\lambda$。\n-   对偶约束：$A^{\\top}\\lambda \\le c$ 和 $\\lambda \\ge 0$。\n\n最终得到的对偶问题是：\n$$\n\\max_{\\lambda \\in \\mathbb{R}^{m}} \\; b^{\\top} \\lambda \\quad \\text{subject to} \\quad A^{\\top}\\lambda \\le c, \\; \\lambda \\ge 0\n$$\n\n### 第2部分：具体实例分析\n\n问题给出了具体实例：\n$$A = \\begin{pmatrix} 2  0 \\\\ 0  3 \\\\ 1  1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 4 \\\\ 3 \\\\ 5 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 5 \\\\ 4 \\end{pmatrix}$$\n令 $x = (x_1, x_2)^{\\top}$。原始问题是：\n$$\n\\min_{x_1, x_2} \\; 5x_1 + 4x_2\n$$\n约束条件为：\n$$\n\\begin{align*}\n2x_1 \\ge 4 \\\\\n3x_2 \\ge 3 \\\\\nx_1 + x_2 \\ge 5 \\\\\nx_1, x_2 \\ge 0\n\\end{align*}\n$$\n这些约束简化为 $x_1 \\ge 2$，$x_2 \\ge 1$，以及 $x_1 + x_2 \\ge 5$。非负性约束 $x_1 \\ge 0, x_2 \\ge 0$ 是多余的。\n\n为了找到原始最优解 $x^{\\star}$，我们可以考察可行域的顶点。边界是 $x_1=2$，$x_2=1$ 和 $x_1+x_2=5$。顶点是这些直线的可行交点。\n-   $x_1=2$ 和 $x_1+x_2=5$ 的交点：$2+x_2=5 \\implies x_2=3$。该点为 $(2, 3)$，是可行的。\n-   $x_2=1$ 和 $x_1+x_2=5$ 的交点：$x_1+1=5 \\implies x_1=4$。该点为 $(4, 1)$，是可行的。\n目标函数为 $z(x_1, x_2) = 5x_1 + 4x_2$。我们在顶点处对其求值：\n-   在 $(2, 3)$ 处：$z = 5(2) + 4(3) = 10 + 12 = 22$。\n-   在 $(4, 1)$ 处：$z = 5(4) + 4(1) = 20 + 4 = 24$。\n最小目标值为 $22$，在原始最优解 $x^{\\star} = (2, 3)^{\\top}$ 处取得。\n\n现在我们确定在 $x^{\\star} = (2, 3)$ 处，$A x \\ge b$ 的哪些约束是紧的：\n1.  $2x_1^{\\star} \\ge 4 \\implies 2(2) = 4$。这是**紧的**。\n2.  $3x_2^{\\star} \\ge 3 \\implies 3(3) = 9 > 3$。这是**松的**。\n3.  $x_1^{\\star} + x_2^{\\star} \\ge 5 \\implies 2+3 = 5$。这是**紧的**。\n\n线性规划的 Karush-Kuhn-Tucker (KKT) 条件蕴含了互补松弛性。令 $\\lambda = (\\lambda_1, \\lambda_2, \\lambda_3)^{\\top}$ 为对偶变量。互补松弛性条件是：\n-   $\\lambda_i ((Ax^{\\star})_i - b_i) = 0$ 对 $i=1, 2, 3$ 成立。\n-   $(c - A^{\\top}\\lambda^{\\star})_j x_j^{\\star} = 0$ 对 $j=1, 2$ 成立。\n\n从第一组条件可知，由于第二个原始约束是松的，其对应的对偶变量必须为零：$\\lambda_2^{\\star} = 0$。\n\n从第二组条件可知：\n-   对于 $j=1$：$x_1^{\\star} = 2 > 0$，因此第一个对偶约束必须是紧的：$(A^{\\top}\\lambda^{\\star})_1 = c_1$。\n    使用 $A^{\\top} = \\begin{pmatrix} 2  0  1 \\\\ 0  3  1 \\end{pmatrix}$，得到 $2\\lambda_1^{\\star} + 0\\lambda_2^{\\star} + 1\\lambda_3^{\\star} = 5 \\implies 2\\lambda_1^{\\star} + \\lambda_3^{\\star} = 5$。\n-   对于 $j=2$：$x_2^{\\star} = 3 > 0$，因此第二个对偶约束必须是紧的：$(A^{\\top}\\lambda^{\\star})_2 = c_2$。\n    得到 $0\\lambda_1^{\\star} + 3\\lambda_2^{\\star} + 1\\lambda_3^{\\star} = 4 \\implies 3\\lambda_2^{\\star} + \\lambda_3^{\\star} = 4$。\n\n我们现在有一个方程组来求解对偶最优解 $\\lambda^{\\star}$：\n1.  $\\lambda_2^{\\star} = 0$\n2.  $2\\lambda_1^{\\star} + \\lambda_3^{\\star} = 5$\n3.  $3\\lambda_2^{\\star} + \\lambda_3^{\\star} = 4$\n\n将 $\\lambda_2^{\\star}=0$ 代入第三个方程，得到 $3(0) + \\lambda_3^{\\star} = 4$，所以 $\\lambda_3^{\\star} = 4$。\n将 $\\lambda_3^{\\star}=4$ 代入第二个方程，得到 $2\\lambda_1^{\\star} + 4 = 5$，所以 $2\\lambda_1^{\\star} = 1$，即 $\\lambda_1^{\\star} = \\frac{1}{2}$。\n推断出的对偶最优解是 $\\lambda^{\\star} = (\\frac{1}{2}, 0, 4)^{\\top}$。\n\n为了验证最优性，我们使用强对偶性。我们检查原始和对偶目标值是否相等。\n-   原始最优目标值：$p^{\\star} = c^{\\top}x^{\\star} = 5(2) + 4(3) = 22$。\n-   对偶最优目标值：$d^{\\star} = b^{\\top}\\lambda^{\\star} = 4\\lambda_1^{\\star} + 3\\lambda_2^{\\star} + 5\\lambda_3^{\\star} = 4(\\frac{1}{2}) + 3(0) + 5(4) = 2 + 0 + 20 = 22$。\n\n由于 $p^{\\star} = d^{\\star} = 22$，并且 $x^{\\star}$ 和 $\\lambda^{\\star}$ 对各自的问题都是可行的（我们必须检查 $\\lambda^{\\star}$ 的对偶可行性：$\\lambda^{\\star} \\ge 0$ 成立，并且 $A^{\\top}\\lambda^{\\star} \\le c$ 也成立，因为两个约束都以等式形式成立），我们已经验证了两个解的最优性。\n\n最后的要求是计算最优原始目标值 $c^{\\top}x^{\\star}$。如前计算，该值为 $22$。",
            "answer": "$$\n\\boxed{22}\n$$"
        },
        {
            "introduction": "在理解了线性规划中的强对偶性之后，一个自然的问题是：当问题不是凸的（non-convex）时，会发生什么？这个练习旨在探索一个非凸优化问题，它清晰地展示了弱对偶性（weak duality）普遍成立，而强对偶性（strong duality）则可能失效。通过分别计算原始最优值 $p^{\\star}$ 和对偶最优值 $d^{\\star}$，你将亲手算出一个非零的“对偶间隙”（duality gap）。这个具体的例子会让你深刻记住，为什么凸性是保证强对偶性的一个关键条件。",
            "id": "3217490",
            "problem": "考虑以下带决策变量 $x_{1}$ 和 $x_{2}$ 的约束最小化问题：\n最小化 $f(x_{1}, x_{2}) = x_{1} + x_{2}$，满足不等式约束 $x_{1} x_{2} \\geq 1$，$x_{1} \\geq 0$ 和 $x_{2} \\geq 0$。\n当写成标准不等式形式 $g_{i}(x_{1}, x_{2}) \\leq 0$ 时，该问题是非凸的，因为函数 $g(x_{1}, x_{2}) = 1 - x_{1} x_{2}$ 不是凸函数，尽管可行集是闭合且非空的。利用拉格朗日函数的基本定义、对偶函数作为原始变量的下确界，以及弱对偶性，确定该问题的精确原始最优值和精确对偶最优值。然后计算对偶间隙，其定义为 $p^{\\star} - d^{\\star}$，其中 $p^{\\star}$ 是原始最优值，$d^{\\star}$ 是对偶最优值。请以一个无单位的精确数字作为最终答案。无需四舍五入。",
            "solution": "用户要求我解决以下问题：\n最小化 $f(x_{1}, x_{2}) = x_{1} + x_{2}$，满足不等式约束 $x_{1} x_{2} \\geq 1$，$x_{1} \\geq 0$ 和 $x_{2} \\geq 0$。\n\n### 第 1 步：提取已知条件\n- 待最小化的目标函数：$f(x_{1}, x_{2}) = x_{1} + x_{2}$。\n- 决策变量：$x_{1}, x_{2}$。\n- 约束条件：\n  1. $g_1(x_1, x_2): x_{1} x_{2} \\geq 1$\n  2. $g_2(x_1, x_2): x_{1} \\geq 0$\n  3. $g_3(x_1, x_2): x_{2} \\geq 0$\n- 问题指出，将第一个约束表示为 $1 - x_1 x_2 \\leq 0$ 会使其成为非凸的。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题是数值方法和科学计算领域中一个定义明确的约束优化问题。\n- **科学依据**：该问题基于优化理论的数学原理。所有函数都是标准的代数函数。拉格朗日对偶、原始/对偶问题和对偶间隙等概念是该领域的核心。关于 $g(x_1, x_2) = 1 - x_1 x_2$ 是非凸的说法是正确的；其黑塞矩阵为 $\\begin{pmatrix} 0  -1 \\\\ -1  0 \\end{pmatrix}$，其特征值为 $\\pm 1$，因此是不定的。\n- **适定性**：该问题是自洽的。它有明确的目标函数和非空的可行域。原始问题存在唯一的最优解。对偶问题也定义明确。\n- **客观性**：语言精确，没有歧义或主观陈述。\n\n该问题是有效的。\n\n### 第 3 步：结论与行动\n该问题是有效的。我现在将继续进行求解。\n\n### 原始问题\n原始问题是要求解在约束条件 $x_{1} x_{2} \\geq 1$，$x_{1} \\geq 0$ 和 $x_{2} \\geq 0$ 下 $f(x_{1}, x_{2}) = x_{1} + x_{2}$ 的最小值。令 $p^{\\star}$ 表示原始最优值。\n\n约束条件 $x_{1} \\geq 0$，$x_{2} \\geq 0$ 和 $x_{1}x_{2} \\geq 1$ 意味着我们必须有 $x_{1} > 0$ 和 $x_{2} > 0$。\n根据算术平均值-几何平均值 (AM-GM) 不等式，对于任意非负数 $x_{1}$ 和 $x_{2}$，我们有：\n$$ \\frac{x_{1} + x_{2}}{2} \\geq \\sqrt{x_{1}x_{2}} $$\n利用约束条件 $x_{1}x_{2} \\geq 1$，我们可以写出：\n$$ \\sqrt{x_{1}x_{2}} \\geq \\sqrt{1} = 1 $$\n结合这些不等式可得：\n$$ \\frac{x_{1} + x_{2}}{2} \\geq 1 $$\n$$ x_{1} + x_{2} \\geq 2 $$\n这表明目标函数 $f(x_{1}, x_{2})$ 的下界为 $2$。当且仅当 AM-GM 不等式中的等号成立时，可以达到最小值 $2$，这种情况发生在 $x_{1} = x_{2}$ 时。\n将 $x_{1} = x_{2}$ 代入约束条件 $x_{1}x_{2} \\geq 1$，我们得到：\n$$ x_{1}^{2} \\geq 1 $$\n由于 $x_{1} > 0$，这意味着 $x_{1} \\geq 1$。为了达到和 $x_1+x_2 = 2x_1$ 的最小值，我们必须为 $x_1$ 选择可能的最小值，即 $x_{1} = 1$。\n这给出了最优点 $(x_{1}^{\\star}, x_{2}^{\\star}) = (1, 1)$。该点满足所有约束条件：$1 \\times 1 = 1 \\geq 1$，$1 \\geq 0$ 和 $1 \\geq 0$。\n原始最优值是目标函数在该点的值：\n$$ p^{\\star} = f(1, 1) = 1 + 1 = 2 $$\n\n### 对偶问题\n为了构建对偶问题，我们首先将约束条件写成标准形式 $g_{i}(x) \\leq 0$：\n1. $c_{1}(x_{1}, x_{2}) = 1 - x_{1}x_{2} \\leq 0$\n2. $c_{2}(x_{1}, x_{2}) = -x_{1} \\leq 0$\n3. $c_{3}(x_{1}, x_{2}) = -x_{2} \\leq 0$\n\n拉格朗日函数 $L(x_1, x_2, \\lambda_1, \\lambda_2, \\lambda_3)$ 定义为：\n$$ L(x_{1}, x_{2}, \\lambda_{1}, \\lambda_{2}, \\lambda_{3}) = f(x_{1}, x_{2}) + \\lambda_{1} c_{1}(x_{1}, x_{2}) + \\lambda_{2} c_{2}(x_{1}, x_{2}) + \\lambda_{3} c_{3}(x_{1}, x_{2}) $$\n其中 $\\lambda_{1}, \\lambda_{2}, \\lambda_{3} \\geq 0$ 是拉格朗日乘子（对偶变量）。\n代入函数，我们有：\n$$ L(x_{1}, x_{2}, \\lambda) = (x_{1} + x_{2}) + \\lambda_{1}(1 - x_{1}x_{2}) + \\lambda_{2}(-x_{1}) + \\lambda_{3}(-x_{2}) $$\n我们可以通过收集 $x_{1}$ 和 $x_{2}$ 的系数来重新排列各项：\n$$ L(x_{1}, x_{2}, \\lambda) = (1 - \\lambda_{2})x_{1} + (1 - \\lambda_{3})x_{2} - \\lambda_{1}x_{1}x_{2} + \\lambda_{1} $$\n拉格朗日对偶函数 $q(\\lambda)$ 是拉格朗日函数关于原始变量 $x_{1}$ 和 $x_{2}$ 的下确界：\n$$ q(\\lambda_{1}, \\lambda_{2}, \\lambda_{3}) = \\inf_{x_{1}, x_{2} \\in \\mathbb{R}} L(x_{1}, x_{2}, \\lambda_{1}, \\lambda_{2}, \\lambda_{3}) $$\n项 $L(x_{1}, x_{2}, \\lambda)$ 是一个关于 $x_1, x_2$ 的函数，包含一个双线性项 $- \\lambda_{1}x_{1}x_{2}$。\n如果 $\\lambda_{1} > 0$，该函数是一个双曲抛物面，其下方无界。对于任何 $\\lambda_1 > 0$，我们可以选择 $x_1=x_2=x$ 并让 $x \\to \\infty$，由于 $- \\lambda_1 x^2$ 项的存在，这将导致 $L \\to -\\infty$。因此，如果 $\\lambda_{1} > 0$，下确界为 $-\\infty$。\n如果 $\\lambda_{1} = 0$，拉格朗日函数变成一个线性函数：\n$$ L(x_{1}, x_{2}, \\lambda) = (1 - \\lambda_{2})x_{1} + (1 - \\lambda_{3})x_{2} $$\n为了使这个线性函数在 $\\mathbb{R}^2$ 上的下确界是有限的（即不为 $-\\infty$），$x_{1}$ 和 $x_{2}$ 的系数必须为零。这要求：\n$$ 1 - \\lambda_{2} = 0 \\implies \\lambda_{2} = 1 $$\n$$ 1 - \\lambda_{3} = 0 \\implies \\lambda_{3} = 1 $$\n因此，为了使对偶函数不为 $-\\infty$，对偶变量必须满足 $\\lambda_{1} = 0$，$\\lambda_{2} = 1$ 和 $\\lambda_{3} = 1$。这些值也满足非负性约束 $\\lambda_i \\ge 0$。\n在这个特定点 $(\\lambda_{1}, \\lambda_{2}, \\lambda_{3}) = (0, 1, 1)$，拉格朗日函数为：\n$$ L(x_{1}, x_{2}, 0, 1, 1) = (1-1)x_{1} + (1-1)x_{2} - 0 \\cdot x_{1}x_{2} + 0 = 0 $$\n在该点，对偶函数的值为：\n$$ q(0, 1, 1) = \\inf_{x_{1}, x_{2} \\in \\mathbb{R}} 0 = 0 $$\n对于任何其他非负对偶变量集合，$q(\\lambda) = -\\infty$。\n\n对偶问题是最大化对偶函数 $q(\\lambda)$，约束条件为 $\\lambda_{i} \\geq 0$：\n$$ d^{\\star} = \\sup_{\\lambda_{1},\\lambda_{2},\\lambda_{3} \\geq 0} q(\\lambda_{1}, \\lambda_{2}, \\lambda_{3}) $$\n由于 $q(\\lambda)$ 在一个特定点为 $0$，在其他所有地方均为 $-\\infty$，因此上确界为 $0$：\n$$ d^{\\star} = 0 $$\n\n### 对偶间隙\n对偶间隙是原始最优值 $p^{\\star}$ 和对偶最优值 $d^{\\star}$ 之间的差值：\n$$ \\text{Duality Gap} = p^{\\star} - d^{\\star} $$\n代入计算出的值：\n$$ \\text{Duality Gap} = 2 - 0 = 2 $$\n这个非零对偶间隙 ($p^{\\star} > d^{\\star}$) 的存在是因为该问题不是凸的（具体来说，约束函数 $1-x_1x_2$ 不是凸函数），因此强对偶性不成立。弱对偶性，即 $p^{\\star} \\geq d^{\\star}$，总是成立的，并且在这里也得到了满足。",
            "answer": "$$\n\\boxed{2}\n$$"
        },
        {
            "introduction": "对偶性不仅是优美的理论，更是强大的计算工具，尤其适用于具有特殊结构的问题。这个练习将引导你实现一个对偶上升（dual ascent）算法，该算法通过迭代求解（通常更简单的）对偶问题来找到原始问题的解。你将看到弱对偶性如何在每一步迭代中提供不断改进的界，而强对偶性则保证了当对偶算法收敛时，我们也能得到原始问题的最优解。这架起了从理论到实际算法应用的桥梁。",
            "id": "3198179",
            "problem": "考虑以下原始形式的可分离凸优化问题：最小化凸函数之和，受限于单个线性耦合约束。具体来说，对于给定的正整数 $n$，给定的系数 $a_i \\in \\mathbb{R}$ 且对于所有 $i \\in \\{1,\\dots,n\\}$ 都有 $a_i > 0$，给定的系数 $c_i \\in \\mathbb{R}$ 对于所有 $i \\in \\{1,\\dots,n\\}$，以及给定的标量 $b \\in \\mathbb{R}$，考虑以下问题\n$$\n\\min_{x \\in \\mathbb{R}^n} \\sum_{i=1}^n \\left(\\tfrac{1}{2} a_i x_i^2 + c_i x_i \\right)\n\\quad \\text{subject to} \\quad \\sum_{i=1}^n x_i = b.\n$$\n您的任务是从第一性原理出发，为与此问题相关的拉格朗日对偶问题推导并实现一个对偶上升法，并用它来实证说明弱对偶性和强对偶性的作用。您必须从拉格朗日函数、对偶函数和对偶问题的基本定义，以及凸性和可微性的基本性质开始。不要假设任何超出这些定义和基本性质的专门结果。\n\n要求：\n\n1) 使用拉格朗日函数的定义推导出对偶函数 $g(\\lambda)$，其中 $\\lambda \\in \\mathbb{R}$ 是等式约束的拉格朗日乘子，并推导出定义 $g(\\lambda)$ 的内部最小化的最小化子 $x^\\star(\\lambda)$ 的形式。仅使用以下事实：对于可分离的凸函数，关于 $x$ 的下确界可以跨坐标分解，以及可微凸函数的一阶最优性条件。\n\n2) 使用对偶函数和对偶问题的定义，证明为什么 $g(\\lambda)$ 关于 $\\lambda$ 是凹函数，并从第一性原理计算其梯度 $g'(\\lambda)$。根据给定的参数 $\\{a_i\\}_{i=1}^n$ 确定 $g'(\\lambda)$ 的一个全局利普希茨常数 $L$。然后，设计一个形式如下的对偶上升算法\n$$\n\\lambda^{k+1} = \\lambda^k + t \\, g'(\\lambda^k),\n$$\n其中常数步长 $t \\in (0, 2/L)$ 对于具有 $L$-利普希茨梯度的连续可微凹函数能保证上升。解释为什么这个选择会产生一个单调非减的对偶目标值序列 $\\{g(\\lambda^k)\\}_{k \\ge 0}$，从而通过弱对偶性产生一个有效的下界序列。\n\n3) 精确说明此问题何时满足强对偶性。将其与可行点的存在性（Slater 条件针对等式约束的特化版本）联系起来。利用这一点，解释为什么对偶上升序列会收敛到对偶最优点 $\\lambda^\\star$，以及为什么相关的原始最小化子 $x^\\star(\\lambda^k)$ 会收敛到原始最优解 $x^\\star$。\n\n4) 实现对偶上升算法，设计如下：\n- 在每次迭代 $k$ 中，使用您在第 1 项中的推导计算 $x^\\star(\\lambda^k)$。\n- 使用第 2 项中描述的步长 $t = 1/L$ 更新 $\\lambda^{k+1}$。\n- 在每次迭代中记录对偶目标值 $g(\\lambda^k)$。\n\n5) 对于每个测试用例，还要解析地计算原始最优解 $x^\\star$、最优原始目标值 $p^\\star$ 和对偶最优值 $d^\\star$。使用这些值来评估：\n- 经过 $K$ 次迭代后的最终对偶下界间隙 $p^\\star - g(\\lambda^K)$。\n- 经过 $K$ 次迭代后的可行性残差 $\\left|\\sum_{i=1}^n x^\\star(\\lambda^K) - b\\right|$。\n- 一个布尔值，指示对偶目标值序列在数值容差 $10^{-12}$ 内是否构成单调非减序列。\n\n测试套件：\n在以下四个测试用例上运行您的程序，每个用例迭代 $K = 100$ 次，初始乘子为 $\\lambda^0 = 0$：\n- 测试 1：$n = 3$, $a = (1.0, 2.0, 3.0)$, $c = (0.5, -1.0, 2.0)$, $b = 1.0$。\n- 测试 2：$n = 1$, $a = (4.0)$, $c = (-2.0)$, $b = 3.0$。\n- 测试 3：$n = 4$, $a = (0.1, 10.0, 5.0, 0.2)$, $c = (1.0, -3.0, 0.5, 2.0)$, $b = -1.0$。\n- 测试 4：$n = 2$, $a = (1.0, 1.0)$, $c = (0.0, 0.0)$, $b = 0.0$。\n\n对于每个测试用例，输出一个列表，包含：\n- 对偶值序列单调性的布尔值（如果在容差 $10^{-12}$ 内非减，则为 True）。\n- 最终下界间隙 $p^\\star - g(\\lambda^K)$，为浮点数，四舍五入到 $6$ 位小数。\n- 可行性残差 $\\left|\\sum_{i=1}^n x^\\star(\\lambda^K) - b\\right|$，为浮点数，四舍五入到 $6$ 位小数。\n- 欧几里得距离 $\\|x^\\star(\\lambda^K) - x^\\star\\|_2$，为浮点数，四舍五入到 $6$ 位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是以下格式的列表\n$$\n[\\text{monotone}, \\; \\text{gap}, \\; \\text{feas\\_res}, \\; \\text{x\\_dist}],\n$$\n其中浮点数四舍五入到 $6$ 位小数。例如，两个测试用例的有效总输出可能如下所示\n$$\n[[\\text{True},0.000001,0.000000,0.000123],[\\text{True},0.000000,0.000000,0.000000]]。\n$$\n此问题中没有物理单位，也没有角度；所有量都是使用标准算术单位的实数。",
            "solution": "该问题定义明确，在凸优化领域有坚实的科学基础，并包含了所有必要信息。它是自洽的、一致的，并且没有任何歧义或无效前提。因此，这是一个有效的问题。\n\n原始问题由下式给出：\n$$\np^\\star = \\min_{x \\in \\mathbb{R}^n} \\sum_{i=1}^n \\left(\\tfrac{1}{2} a_i x_i^2 + c_i x_i \\right) \\quad \\text{subject to} \\quad \\sum_{i=1}^n x_i = b.\n$$\n目标函数 $f(x) = \\sum_{i=1}^n (\\tfrac{1}{2} a_i x_i^2 + c_i x_i)$ 是严格凸函数，因为其 Hessian 矩阵是对角矩阵，对角线元素为 $a_i > 0$。约束是线性的（因此是仿射的）。这是一个凸优化问题。\n\n**1. 对偶函数的推导**\n\n问题的拉格朗日函数是通过将单个等式约束 $\\sum_{i=1}^n x_i - b = 0$ 与一个拉格朗日乘子 $\\lambda \\in \\mathbb{R}$ 结合到目标函数中形成的：\n$$\nL(x, \\lambda) = \\sum_{i=1}^n \\left(\\tfrac{1}{2} a_i x_i^2 + c_i x_i \\right) + \\lambda \\left(\\sum_{i=1}^n x_i - b\\right).\n$$\n拉格朗日函数在变量 $x_i$ 上是可分离的，这意味着它可以重写为各项仅依赖于单个 $x_i$ 的和：\n$$\nL(x, \\lambda) = \\sum_{i=1}^n \\left( \\tfrac{1}{2} a_i x_i^2 + c_i x_i + \\lambda x_i \\right) - \\lambda b.\n$$\n拉格朗日对偶函数 $g(\\lambda)$ 定义为拉格朗日函数关于原始变量 $x$ 的下确界：\n$$\ng(\\lambda) = \\inf_{x \\in \\mathbb{R}^n} L(x, \\lambda).\n$$\n由于可分离性，下确界可以分配到和的每一项：\n$$\ng(\\lambda) = \\left( \\sum_{i=1}^n \\inf_{x_i \\in \\mathbb{R}} \\left( \\tfrac{1}{2} a_i x_i^2 + (c_i + \\lambda) x_i \\right) \\right) - \\lambda b.\n$$\n对于每个 $i$，下确界内的项，我们称之为 $f_i(x_i) = \\tfrac{1}{2} a_i x_i^2 + (c_i + \\lambda) x_i$，是关于 $x_i$ 的严格凸二次函数，因为 $a_i > 0$。其下确界在导数关于 $x_i$ 为零的唯一点达到。这是可微凸函数的一阶最优性条件。\n$$\n\\frac{\\partial f_i}{\\partial x_i} = a_i x_i + c_i + \\lambda = 0.\n$$\n解出 $x_i$ 得到最小化子 $x_i^\\star(\\lambda)$ 作为对偶变量 $\\lambda$ 的函数：\n$$\nx_i^\\star(\\lambda) = - \\frac{c_i + \\lambda}{a_i}.\n$$\n将此最小化子代回 $f_i(x_i)$ 的表达式中，得到第 $i$ 项的下确界：\n$$\n\\inf_{x_i} f_i(x_i) = \\tfrac{1}{2} a_i \\left( - \\frac{c_i + \\lambda}{a_i} \\right)^2 + (c_i + \\lambda) \\left( - \\frac{c_i + \\lambda}{a_i} \\right) = \\frac{(c_i + \\lambda)^2}{2a_i} - \\frac{(c_i + \\lambda)^2}{a_i} = - \\frac{(c_i + \\lambda)^2}{2a_i}.\n$$\n对所有 $i$ 求和并减去 $\\lambda b$ 项，我们得到对偶函数的显式形式：\n$$\ng(\\lambda) = - \\sum_{i=1}^n \\frac{(c_i + \\lambda)^2}{2a_i} - \\lambda b.\n$$\n\n**2. 对偶上升算法设计**\n\n对偶问题是最大化对偶函数：$d^\\star = \\max_{\\lambda \\in \\mathbb{R}} g(\\lambda)$。\n\n**$g(\\lambda)$ 的凹性和梯度**：\n对偶函数 $g(\\lambda)$ 是一个函数族 $\\{L(x, \\cdot)\\}_{x \\in \\mathbb{R}^n}$ 的逐点下确界，其中每个函数 $L(x, \\lambda)$ 在 $\\lambda$ 中都是仿射的。一组仿射（因此是凹）函数的下确界总是凹的。这个一般性质保证了 $g(\\lambda)$ 是一个凹函数，我们也可以通过计算其二阶导数来验证这一点。\n\n从第一性原理出发，我们可以计算 $g(\\lambda)$ 的梯度。一个一般性结果（Danskin 定理的一个特例）指出，如果 $x^\\star(\\lambda)$ 是 $L(x, \\lambda)$ 的唯一最小化子，那么 $g(\\lambda)$ 的梯度就是 $L(x, \\lambda)$ 关于 $\\lambda$ 的梯度，在 $x = x^\\star(\\lambda)$ 处求值：\n$$\ng'(\\lambda) = \\frac{d}{d\\lambda} L(x^\\star(\\lambda), \\lambda) = \\sum_{i=1}^n x_i^\\star(\\lambda) - b.\n$$\n代入 $x_i^\\star(\\lambda)$ 的表达式：\n$$\ng'(\\lambda) = \\sum_{i=1}^n \\left( - \\frac{c_i + \\lambda}{a_i} \\right) - b.\n$$\n这个梯度是根据对偶变量 $\\lambda$ 恢复出的解 $x^\\star(\\lambda)$ 的原始可行性残差。最大化 $g(\\lambda)$ 等价于找到一个 $\\lambda$ 使得 $g'(\\lambda) = 0$，这对应于找到一个对偶变量，使得恢复出的原始解是可行的。\n\n**$g'(\\lambda)$ 的利普希茨常数**：\n为了找到 $g'(\\lambda)$ 的全局利普希茨常数，我们计算其关于 $\\lambda$ 的导数（即 $g''(\\lambda)$）：\n$$\ng''(\\lambda) = \\frac{d}{d\\lambda} \\left( \\sum_{i=1}^n \\left( - \\frac{c_i}{a_i} - \\frac{\\lambda}{a_i} \\right) - b \\right) = - \\sum_{i=1}^n \\frac{1}{a_i}.\n$$\n因为对所有 $i$ 都有 $a_i > 0$，所以 $g''(\\lambda)$ 是一个负常数。$g'(\\lambda)$ 的利普希茨常数 $L$ 是其导数绝对值的上确界，即 $|g''(\\lambda)|$：\n$$\nL = \\sup_{\\lambda \\in \\mathbb{R}} |g''(\\lambda)| = \\left| - \\sum_{i=1}^n \\frac{1}{a_i} \\right| = \\sum_{i=1}^n \\frac{1}{a_i}.\n$$\n**对偶上升法**：\n我们旨在使用梯度上升法解决 $\\max_\\lambda g(\\lambda)$：\n$$\n\\lambda^{k+1} = \\lambda^k + t \\, g'(\\lambda^k),\n$$\n其中 $t > 0$ 是步长。对于一个具有 $L$-利普希茨梯度的连续可微凹函数 $g$，以下不等式成立（凹函数的下降引理的一个推论）：\n$$\ng(\\lambda^{k+1}) = g(\\lambda^k + t \\, g'(\\lambda^k)) \\ge g(\\lambda^k) + t(g'(\\lambda^k))^2 - \\frac{L t^2}{2} (g'(\\lambda^k))^2 = g(\\lambda^k) + t\\left(1 - \\frac{Lt}{2}\\right)(g'(\\lambda^k))^2.\n$$\n为保证上升，即 $g(\\lambda^{k+1}) \\ge g(\\lambda^k)$，我们需要项 $t\\left(1 - \\frac{Lt}{2}\\right)$ 为非负。由于 $t>0$，这要求 $1 - \\frac{Lt}{2} \\ge 0$，即 $t \\le \\frac{2}{L}$。为了在 $g'(\\lambda^k) \\ne 0$ 时实现严格上升，我们需要 $t \\in (0, 2/L)$。选择 $t=1/L$ 在此范围内，并保证对偶目标值序列 $\\{g(\\lambda^k)\\}$ 是非减的。根据弱对偶性原理，$g(\\lambda) \\le p^\\star$ 对任意 $\\lambda$ 成立。因此，对偶上升算法生成了一个关于原始最优值的不断改进的下界序列。\n\n**3. 强对偶性与收敛**\n\n强对偶性，即原始和对偶最优值相等（$p^\\star = d^\\star$），对该问题成立。原始问题是凸的，其约束是仿射的。对于仿射约束，斯莱特条件仅要求可行集非空。一个可行点是任何满足 $\\sum_{i=1}^n x_i = b$ 的 $x \\in \\mathbb{R}^n$。例如，$x = (b, 0, \\dots, 0)$ 是一个可行点。因此，可行集非空，强对偶性成立。\n\n因为强对偶性成立，对偶函数的最大值 $d^\\star$ 等于原始目标函数的最小值 $p^\\star$。步长为 $t \\in (0, 2/L)$ 的对偶上升算法保证收敛到最大化 $g(\\lambda)$ 的对偶最优解 $\\lambda^\\star$。在此最优点上，梯度必须为零，因为 $g$ 是可微的且问题是无约束的：\n$$\ng'(\\lambda^\\star) = \\sum_{i=1}^n x_i^\\star(\\lambda^\\star) - b = 0.\n$$\n这个条件意味着从对偶最优解恢复出的原始解 $x^\\star(\\lambda^\\star)$ 是可行的：$\\sum_{i=1}^n x_i^\\star(\\lambda^\\star) = b$。点 $(x^\\star(\\lambda^\\star), \\lambda^\\star)$ 满足 Karush-Kuhn-Tucker (KKT) 条件：\n1.  **原始可行性**：$\\sum_{i=1}^n x_i^\\star(\\lambda^\\star) - b = 0$（如上所示）。\n2.  **拉格朗日平稳性**：$\\nabla_x L(x^\\star(\\lambda^\\star), \\lambda^\\star) = 0$。这通过 $x^\\star(\\lambda)$ 的定义得到满足，该定义是通过将拉格朗日函数关于 $x_i$ 的梯度设为零推导出来的。\n\n由于原始问题是凸的，KKT 条件对于最优性是充分的。因此，$x^\\star = x^\\star(\\lambda^\\star)$ 是原始最优解。对偶上升序列 $\\lambda^k \\to \\lambda^\\star$ 的收敛性以及映射 $\\lambda \\mapsto x^\\star(\\lambda)$ 的连续性（它是仿射的）确保了恢复的原始解序列 $x^\\star(\\lambda^k)$ 收敛到原始最优解 $x^\\star$。\n\n**4. 解析解**\n\n为了找到解析解，我们直接求解 KKT 条件。我们需要找到 $(\\lambda, x)$ 使得：\n$$\na_i x_i + c_i + \\lambda = 0 \\quad \\forall i \\in \\{1, \\dots, n\\} \\quad \\text{and} \\quad \\sum_{i=1}^n x_i = b.\n$$\n从第一个方程，我们得到 $x_i = -(c_i + \\lambda)/a_i$。代入第二个方程：\n$$\n\\sum_{i=1}^n \\left(-\\frac{c_i + \\lambda}{a_i}\\right) = b \\implies -\\sum_{i=1}^n \\frac{c_i}{a_i} - \\lambda \\sum_{i=1}^n \\frac{1}{a_i} = b.\n$$\n解出最优拉格朗日乘子 $\\lambda^\\star$：\n$$\n\\lambda^\\star = - \\frac{b + \\sum_{i=1}^n (c_i / a_i)}{\\sum_{i=1}^n (1 / a_i)}.\n$$\n最优原始解 $x^\\star$ 的分量为 $x^\\star_i = -(c_i + \\lambda^\\star)/a_i$。最优原始值为 $p^\\star = \\sum_{i=1}^n (\\frac{1}{2} a_i (x_i^\\star)^2 + c_i x_i^\\star)$。这些解析结果用于评估。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the separable quadratic optimization problem using a dual ascent method\n    and evaluates its performance against the analytical solution.\n    \"\"\"\n\n    test_cases = [\n        {'n': 3, 'a': np.array([1.0, 2.0, 3.0]), 'c': np.array([0.5, -1.0, 2.0]), 'b': 1.0},\n        {'n': 1, 'a': np.array([4.0]), 'c': np.array([-2.0]), 'b': 3.0},\n        {'n': 4, 'a': np.array([0.1, 10.0, 5.0, 0.2]), 'c': np.array([1.0, -3.0, 0.5, 2.0]), 'b': -1.0},\n        {'n': 2, 'a': np.array([1.0, 1.0]), 'c': np.array([0.0, 0.0]), 'b': 0.0},\n    ]\n\n    K = 100\n    TOL = 1e-12\n    all_results = []\n\n    for case in test_cases:\n        a, c, b = case['a'], case['c'], case['b']\n\n        # 1. Compute analytical optimal solution\n        sum_c_over_a = np.sum(c / a)\n        sum_1_over_a = np.sum(1.0 / a)\n        \n        lambda_star = -(b + sum_c_over_a) / sum_1_over_a\n        x_star = -(c + lambda_star) / a\n        p_star = np.sum(0.5 * a * x_star**2 + c * x_star)\n\n        # 2. Implement dual ascent algorithm\n        lambda_k = 0.0\n        g_history = []\n        \n        # Lipschitz constant for the gradient of the dual function\n        L = sum_1_over_a\n        # Step size\n        t = 1.0 / L if L > 0 else 0.0\n\n        for _ in range(K):\n            # Record dual objective value g(lambda_k)\n            g_k = -0.5 * np.sum((c + lambda_k)**2 / a) - lambda_k * b\n            g_history.append(g_k)\n\n            # Recover primal variable x(lambda_k)\n            x_k = -(c + lambda_k) / a\n            \n            # Compute gradient g'(lambda_k)\n            grad_g_k = np.sum(x_k) - b\n            \n            # Update lambda\n            lambda_k = lambda_k + t * grad_g_k\n\n        # 3. Compute metrics at the final iterate lambda_K\n        lambda_K = lambda_k\n        g_at_lambda_K = -0.5 * np.sum((c + lambda_K)**2 / a) - lambda_K * b\n        x_at_lambda_K = -(c + lambda_K) / a\n        \n        # Metric 1: Monotonicity of the dual objective sequence\n        is_monotone = all(g_history[i] >= g_history[i-1] - TOL for i in range(1, len(g_history)))\n\n        # Metric 2: Final lower-bound gap\n        gap = p_star - g_at_lambda_K\n\n        # Metric 3: Final feasibility residual for the primal solution\n        feas_res = np.abs(np.sum(x_at_lambda_K) - b)\n        \n        # Metric 4: Distance to optimal primal solution\n        x_dist = np.linalg.norm(x_at_lambda_K - x_star)\n\n        # Format results\n        case_result = [\n            is_monotone,\n            round(gap, 6),\n            round(feas_res, 6),\n            round(x_dist, 6)\n        ]\n        all_results.append(case_result)\n\n    # Final print statement in the exact required format\n    # The string representation of a list of lists will match the desired format.\n    print(str(all_results).replace(\"'\", \"\").replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}