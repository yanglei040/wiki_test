{
    "hands_on_practices": [
        {
            "introduction": "The performance of any local search algorithm is dominated by the cost of evaluating neighboring solutions. This practice highlights the critical difference between re-calculating the objective function from scratch and using an efficient incremental update, often called a \"delta\" calculation. By analyzing the computational complexity for the Traveling Salesman Problem, you will gain a concrete understanding of why incremental evaluation is not just an optimization, but a necessity for tackling non-trivial problem sizes .",
            "id": "3190915",
            "problem": "Consider Tabu Search (TS) applied to the Traveling Salesman Problem (TSP) on a complete, symmetric, metric graph with $n$ cities. A tour is represented by a permutation of $n$ cities, and its objective value $f$ is the sum of the distances along the ordered cycle. At each TS iteration, the algorithm evaluates all swap moves of two distinct non-adjacent positions in the permutation and selects the best admissible move according to the change in objective $\\Delta f$. Assume the following operational model for computational cost:\n- Each distance lookup between two cities costs $1$ unit.\n- Each scalar arithmetic operation (addition or subtraction) costs $1$ unit.\n- The current tour cost $f_{\\text{current}}$ is known at the start of the iteration.\n\nDefine a swap move by indices $(p,q)$ with $p \\neq q$, where $p$ and $q$ are not adjacent on the cycle. For such a swap, exactly four edges in the tour are affected: the two edges incident to the city at position $p$ and the two edges incident to the city at position $q$.\n\nTwo evaluation strategies are considered for computing $\\Delta f$ for each candidate swap:\n- Incremental evaluation: compute $\\Delta f$ by summing the four new edge distances and subtracting the sum of the four old edge distances. For a single non-adjacent swap $(p,q)$, this requires $8$ distance lookups and $7$ scalar arithmetic operations.\n- Naive recomputation: compute the total cost of the new tour from scratch by summing all $n$ edge distances and then subtract $f_{\\text{current}}$ to obtain $\\Delta f$. For a single swap $(p,q)$, this requires $n$ distance lookups, $n-1$ additions to sum the cycle, and $1$ subtraction to form $\\Delta f$.\n\nIn one TS iteration, all unordered non-adjacent swap pairs are evaluated. The total number of such pairs is\n$$\nM \\;=\\; \\frac{n(n-1)}{2} \\;-\\; n \\;=\\; \\frac{n(n-3)}{2}.\n$$\nUsing the operational model above, derive the exact symbolic expression for the ratio $R(n)$ of the total per-iteration computational cost of naive recomputation to the total per-iteration computational cost of incremental evaluation. Provide $R(n)$ simplified as a single rational function of $n$. No rounding is required, and no units are needed in the final expression.",
            "solution": "Let $C_{\\text{inc}}$ be the computational cost for a single move using incremental evaluation, and $C_{\\text{naive}}$ be the cost using naive recomputation. According to the problem's operational model:\n\n1.  **Cost of a Single Incremental Evaluation ($C_{\\text{inc}}$):**\n    - The problem states this requires 8 distance lookups and 7 scalar arithmetic operations.\n    - $C_{\\text{inc}} = (8 \\text{ lookups} \\times 1 \\text{ unit/lookup}) + (7 \\text{ ops} \\times 1 \\text{ unit/op}) = 8 + 7 = 15$ units.\n\n2.  **Cost of a Single Naive Recomputation ($C_{\\text{naive}}$):**\n    - This requires $n$ distance lookups, $n-1$ additions, and 1 subtraction.\n    - $C_{\\text{naive}} = (n \\text{ lookups} \\times 1 \\text{ unit/lookup}) + ((n-1) \\text{ ops} + 1 \\text{ op}) \\times 1 \\text{ unit/op} = n + n = 2n$ units.\n\nThe total number of moves evaluated in one iteration is given as $M = \\frac{n(n-3)}{2}$.\n\nLet $T_{\\text{inc}}$ and $T_{\\text{naive}}$ be the total per-iteration costs for the incremental and naive strategies, respectively.\n\n3.  **Total Per-Iteration Cost:**\n    - Total Incremental Cost: $T_{\\text{inc}} = M \\times C_{\\text{inc}} = \\frac{n(n-3)}{2} \\times 15$.\n    - Total Naive Cost: $T_{\\text{naive}} = M \\times C_{\\text{naive}} = \\frac{n(n-3)}{2} \\times 2n$.\n\n4.  **Ratio of Total Costs ($R(n)$):**\n    - The required ratio is $R(n) = \\frac{T_{\\text{naive}}}{T_{\\text{inc}}}$.\n    - $R(n) = \\frac{\\frac{n(n-3)}{2} \\times 2n}{\\frac{n(n-3)}{2} \\times 15}$\n    - The common factor $M = \\frac{n(n-3)}{2}$ cancels from the numerator and denominator.\n    - $R(n) = \\frac{2n}{15}$",
            "answer": "$$\n\\boxed{\\frac{2n}{15}}\n$$"
        },
        {
            "introduction": "While theoretical analysis is essential, true understanding often comes from implementation. This practice guides you from analysis to building a complete Tabu Search solver for the classic Traveling Salesman Problem (TSP). You will implement the core components of Tabu Search—including a neighborhood structure, an attribute-based tabu list, and an aspiration criterion—to create a functional optimization tool . This hands-on coding exercise also explores the fundamental trade-off between search intensity and computational cost by comparing a full neighborhood scan with a restricted candidate list strategy.",
            "id": "3190936",
            "problem": "Implement and empirically evaluate two candidate list strategies within Tabu Search for a symmetric Euclidean Traveling Salesperson Problem (TSP). The objective is to compare a full neighborhood scan against a restricted candidate list of size $k$ in terms of per-iteration computational cost and solution quality. The problem must be solved by writing a complete, runnable program.\n\nYou are given the following foundational definitions and assumptions:\n- The Traveling Salesperson Problem is defined on a complete graph with $n$ nodes (cities), where each undirected edge $(i,j)$ has a symmetric distance $d_{ij} = d_{ji} \\ge 0$. The objective function $f(\\pi)$ for a tour (permutation) $\\pi$ is the sum of the Euclidean distances along the cycle induced by $\\pi$, that is $f(\\pi) = \\sum_{t=0}^{n-1} d_{\\pi_t,\\pi_{t+1 \\bmod n}}$.\n- A neighborhood operator is defined by the $2$-opt move. For indices $ij$, reversing the segment $\\pi[i:j]$ yields a new tour. The elementary cost change (delta) under a $2$-opt move can be computed from four edges in $O(1)$ time.\n- Tabu Search (TS) uses short-term memory to forbid recently made moves. Use an attribute-based tabu list that forbids removing recently added edges for a fixed tabu tenure $T_{\\text{tenure}}$. Use an aspiration criterion that allows any tabu move that yields a strict improvement over the globally best objective value seen so far.\n- The per-iteration computational cost is measured as the number of objective-change computations, that is, the number of $2$-opt delta evaluations performed during move selection in one iteration. Summed over iterations, this yields the total number of objective evaluations.\n\nYou must implement two strategies to select the move at each iteration:\n- Full neighborhood scan: examine the entire $2$-opt neighborhood defined by all pairs $(i,j)$ with $0 \\le i  j \\le n-1$ except $(i,j)=(0,n-1)$, compute the delta cost for each move, and select the best admissible (non-tabu or aspirational) move. If no admissible move exists, select the best move regardless of tabu status.\n- Restricted candidate list (RCL) of size $k$: uniformly sample, without replacement, exactly $k$ distinct valid $2$-opt moves from the same neighborhood as above, evaluate only those $k$ moves, and select the best admissible move among them. If none of the $k$ sampled moves are admissible, select the best move among them regardless of tabu. The sampling must be reproducible under a fixed random seed.\n\nInitialization and data generation:\n- Generate $n$ points independently and identically distributed in the unit square using a pseudo-random generator with a specified integer seed $s$, each coordinate drawn from $\\mathcal{U}[0,1]$.\n- Use the Euclidean metric to compute the distance matrix $D \\in \\mathbb{R}^{n \\times n}$ with entries $d_{ij} = \\sqrt{(x_i-x_j)^2 + (y_i-y_j)^2}$.\n- Build the initial tour deterministically using the greedy nearest-neighbor heuristic starting from node $0$ (break ties by the smallest index).\n\nAlgorithmic details to enforce:\n- Represent a $2$-opt move by indices $(i,j)$ with $0 \\le i  j \\le n-1$ and exclude only the trivial reversal $(0,n-1)$ to avoid a pure tour reversal equivalence.\n- The $O(1)$ delta for a $2$-opt move $(i,j)$ is given by removing edges $(\\pi_{i-1},\\pi_i)$ and $(\\pi_j,\\pi_{j+1 \\bmod n})$ and adding edges $(\\pi_{i-1},\\pi_j)$ and $(\\pi_i,\\pi_{j+1 \\bmod n})$. Count exactly one objective evaluation per such delta computation, and do not count any other operations.\n- After applying a $2$-opt move, insert the two newly added undirected edges into the tabu list for $T_{\\text{tenure}}$ iterations. A candidate is tabu if any of the to-be-added edges is currently tabu. Apply the aspiration criterion strictly when the resulting tour has an objective strictly less than the global best so far.\n\nMeasurement and outputs:\n- For each test case, run Tabu Search for exactly $T$ iterations under both strategies: full neighborhood scan and restricted candidate list. Record:\n  1. Average per-iteration objective evaluation count for full scan, defined as total deltas computed divided by $T$.\n  2. Average per-iteration objective evaluation count for restricted candidate list of size $k$.\n  3. Relative solution-quality gap defined as $(f_{\\text{RCL}}^\\star - f_{\\text{Full}}^\\star)/f_{\\text{Full}}^\\star$, where $f_{\\text{Full}}^\\star$ and $f_{\\text{RCL}}^\\star$ are the best objective values found by each strategy.\n  4. The two best objective values $f_{\\text{Full}}^\\star$ and $f_{\\text{RCL}}^\\star$.\n- Express all objective values and the relative gap as dimensionless real numbers (no physical units). The relative gap must be reported as a decimal number, not a percentage.\n\nTest suite:\nYour program must execute the following four test cases in the exact order shown. Each test case is the tuple $(n,T,k,s,T_{\\text{tenure}})$:\n- Case $1$: $(10, 120, 1, 42, 7)$\n- Case $2$: $(12, 150, 20, 7, 7)$\n- Case $3$: $(14, 180, 90, 123, 8)$\n- Case $4$: $(6, 80, 2, 5, 5)$\n\nFinal output format:\n- For each case, output a list of five numbers in the order: [average evaluations per iteration (full), average evaluations per iteration (RCL), relative quality gap, best full-scan objective, best RCL objective].\n- Round the two average evaluation counts to $2$ decimals, the relative quality gap to $6$ decimals, and both objective values to $6$ decimals.\n- Your program should produce a single line of output containing the results as a comma-separated list of these per-case lists, enclosed in square brackets; for example: [[c1_full,c1_rcl,qgap1,bf1,br1],[c2_full,c2_rcl,qgap2,bf2,br2],...].",
            "solution": "The user wants to implement and evaluate two candidate list strategies for a Tabu Search (TS) algorithm applied to the symmetric Euclidean Traveling Salesperson Problem (TSP). This requires a detailed implementation of the TSP environment, the TS metaheuristic with specific components, and the two competing strategies, followed by an empirical comparison based on provided test cases.\n\n### **1. Problem Formulation**\nThe problem is defined as the symmetric Traveling Salesperson Problem (TSP) on a complete graph $G=(V, E)$, where $V$ is a set of $n$ cities (nodes) located in the unit square $[0,1] \\times [0,1]$. The cost (distance) $d_{ij}$ for each edge $(i, j) \\in E$ is the Euclidean distance between cities $i$ and $j$. A solution is a tour, which is a permutation $\\pi$ of the cities. The objective is to find a tour that minimizes the total length, given by the function $f(\\pi) = \\sum_{t=0}^{n-1} d_{\\pi_t, \\pi_{(t+1) \\pmod n}}$.\n\n### **2. Neighborhood Structure and Move Evaluation**\nThe neighborhood of a solution is defined by the **2-opt operator**. A 2-opt move transforms a tour by selecting two non-adjacent edges, removing them, and reconnecting the four resulting endpoints in the only other way that produces a valid tour. This is equivalent to reversing a segment of the tour. A move is defined by a pair of indices $(i, j)$ with $0 \\le i  j \\le n-1$, corresponding to the reversal of the path segment $\\pi[i \\ldots j]$. The problem specifies excluding the trivial full-tour reversal $(i,j)=(0, n-1)$.\n\nThe change in tour length (delta) resulting from a 2-opt move can be calculated in $O(1)$ time. If the edges $(\\pi_{i-1}, \\pi_i)$ and $(\\pi_j, \\pi_{j+1})$ are removed and replaced by $(\\pi_{i-1}, \\pi_j)$ and $(\\pi_i, \\pi_{j+1})$ (where indices are modulo $n$), the delta is:\n$$ \\Delta = d(\\pi_{i-1}, \\pi_j) + d(\\pi_i, \\pi_{j+1}) - d(\\pi_{i-1}, \\pi_i) - d(\\pi_j, \\pi_{j+1}) $$\nEach such computation is counted as one objective evaluation, which serves as the primary measure of computational cost per iteration.\n\n### **3. Tabu Search Framework**\nThe Tabu Search (TS) algorithm is a metaheuristic that guides a local search method to escape local optima. The implementation follows these specific rules:\n\n-   **Tabu List**: An attribute-based short-term memory is used. When a 2-opt move is performed, the two newly **added** edges are declared tabu.\n-   **Tabu Tenure ($T_{\\text{tenure}}$)**: An edge placed on the tabu list is forbidden from being re-added for a fixed number of subsequent iterations, $T_{\\text{tenure}}$. A move is tabu if it would require adding an edge that is currently on the tabu list.\n-   **Aspiration Criterion**: The tabu status of a move can be overridden if performing the move results in a new tour with a total length strictly less than the best-so-far solution found during the entire search ($f(\\pi_{\\text{new}})  f(\\pi^\\star)$).\n-   **Move Selection Rule**: In each iteration, the best \"admissible\" move (i.e., non-tabu or satisfying the aspiration criterion) from a set of candidates is chosen. If no admissible move is found within the candidate set, the best move from that set is selected, regardless of its tabu status.\n\n### **4. Candidate List Strategies**\nThe core of the problem is to compare two strategies for generating the candidate set of moves at each iteration:\n\n1.  **Full Neighborhood Scan**: The candidate set consists of all possible $N = \\frac{n(n-1)}{2}-1$ valid 2-opt moves. The algorithm evaluates the delta for every move in this set and selects the best admissible one. This is an exhaustive local search, maximizing the chance of finding a good move at the cost of high computational effort per iteration (exactly $N$ evaluations).\n\n2.  **Restricted Candidate List (RCL)**: The candidate set is a small subset of the full neighborhood. Exactly $k$ distinct 2-opt moves are uniformly sampled without replacement from the set of all possible moves. Only these $k$ moves are evaluated. This strategy significantly reduces the computational cost per iteration (to $k$ evaluations) but is non-exhaustive, risking to miss the best moves available in the full neighborhood.\n\n### **5. Initialization**\nTo ensure reproducibility, the search process is initialized deterministically:\n-   **City Coordinates**: For a given seed $s$, $n$ points are generated with coordinates drawn from a uniform distribution $\\mathcal{U}[0,1]$.\n-   **Initial Tour**: The initial solution is constructed using the greedy nearest-neighbor heuristic, starting from city $0$. Ties in distance are broken by selecting the city with the smaller index.\n\n### **6. Algorithmic Implementation and Metrics**\nThe implementation is encapsulated in a class for each test case. This class manages problem data generation, the two TS runs, and result calculation.\n\n-   **Data Structures**: A `numpy` array stores the tour permutation. A `dict` serves as the tabu list, mapping edge tuples `(u, v)` (with $uv$) to the iteration number at which their tabu status expires.\n-   **Reproducibility**: The `numpy.random.default_rng` with the specified seed $s$ is used for both city coordinate generation and the RCL sampling process to guarantee consistent results.\n-   **Main Loop**: For each strategy, the TS algorithm runs for a fixed number of iterations $T$. In each iteration, it generates a candidate list, evaluates the moves, selects and applies one based on the rules, and updates the current solution, best-found solution, and tabu list.\n-   **Metrics**: After $T$ iterations, the following metrics are computed for each strategy:\n    1.  Average evaluations per iteration: Total delta computations divided by $T$. This will be $\\frac{n(n-1)}{2}-1$ for the full scan and $k$ for the RCL.\n    2.  Best objective value found: $f_{\\text{Full}}^\\star$ and $f_{\\text{RCL}}^\\star$.\n    3.  Relative quality gap: $(f_{\\text{RCL}}^\\star - f_{\\text{Full}}^\\star) / f_{\\text{Full}}^\\star$, measuring the quality loss of RCL relative to the full scan.\n\nThe final output is a list of lists, where each inner list contains these five formatted metrics for one test case.",
            "answer": "```python\nimport numpy as np\nfrom scipy.spatial import distance_matrix\n\nclass TSPSolver:\n    \"\"\"\n    Implements and compares Tabu Search with full-scan and RCL strategies for TSP.\n    \"\"\"\n    def __init__(self, n, T, k, s, T_tenure):\n        self.n = n\n        self.T = T\n        self.k = k\n        self.seed = s\n        self.T_tenure = T_tenure\n\n        # Generate problem data using the specified seed\n        self.rng = np.random.default_rng(self.seed)\n        self.points = self.rng.random((self.n, 2))\n        self.dist_matrix = distance_matrix(self.points, self.points)\n        \n        # Pre-compute all valid 2-opt moves\n        self.all_moves = self._generate_all_moves()\n        self.num_all_moves = len(self.all_moves)\n\n    def _generate_all_moves(self):\n        \"\"\"Generates all valid 2-opt moves (i, j) with 0 = i  j  n, excluding (0, n-1).\"\"\"\n        moves = []\n        for i in range(self.n):\n            for j in range(i + 1, self.n):\n                if i == 0 and j == self.n - 1:\n                    continue\n                moves.append((i, j))\n        return moves\n\n    def _get_initial_tour(self):\n        \"\"\"Builds an initial tour using the nearest-neighbor heuristic from node 0.\"\"\"\n        tour = [0]\n        unvisited = set(range(1, self.n))\n        current_city = 0\n        while unvisited:\n            distances_to_unvisited = {\n                city: self.dist_matrix[current_city, city] for city in unvisited\n            }\n            min_dist_val = min(distances_to_unvisited.values())\n            candidates = [\n                city for city, dist in distances_to_unvisited.items() if dist == min_dist_val\n            ]\n            next_city = min(candidates)\n            \n            tour.append(next_city)\n            unvisited.remove(next_city)\n            current_city = next_city\n        return tour\n\n    def _calculate_tour_cost(self, tour):\n        \"\"\"Calculates the total length of a given tour.\"\"\"\n        cost = 0.0\n        for i in range(self.n):\n            cost += self.dist_matrix[tour[i], tour[(i + 1) % self.n]]\n        return cost\n\n    def _tabu_search(self, strategy):\n        \"\"\"\n        Executes the Tabu Search algorithm for a given strategy ('full' or 'rcl').\n        \"\"\"\n        # A separate RNG for sampling to ensure reproducibility based on the main seed.\n        sampling_rng = np.random.default_rng(self.seed)\n\n        # Initialization\n        initial_tour = self._get_initial_tour()\n        current_tour = np.array(initial_tour)\n        best_tour = current_tour.copy()\n        current_obj = self._calculate_tour_cost(current_tour)\n        best_obj = current_obj\n        \n        tabu_until = {}  # Maps tabu edges to the iteration they become available\n        total_evals = 0\n\n        for iter_num in range(1, self.T + 1):\n            if strategy == 'full':\n                moves_to_check_indices = range(self.num_all_moves)\n                evals_this_iter = self.num_all_moves\n            else: # rcl\n                k_effective = min(self.k, self.num_all_moves)\n                moves_to_check_indices = sampling_rng.choice(\n                    self.num_all_moves, size=k_effective, replace=False\n                )\n                evals_this_iter = k_effective\n            \n            total_evals += evals_this_iter\n            \n            best_delta_in_iter = np.inf\n            best_move_in_iter = None\n            best_admissible_delta = np.inf\n            best_admissible_move = None\n\n            for move_idx in moves_to_check_indices:\n                i, j = self.all_moves[move_idx]\n                \n                # Delta calculation (O(1))\n                p_im1_idx = i - 1\n                p_jp1_idx = (j + 1) % self.n\n                p_im1 = current_tour[p_im1_idx]\n                p_i = current_tour[i]\n                p_j = current_tour[j]\n                p_jp1 = current_tour[p_jp1_idx]\n\n                delta = (self.dist_matrix[p_im1, p_j] + self.dist_matrix[p_i, p_jp1] -\n                         self.dist_matrix[p_im1, p_i] - self.dist_matrix[p_j, p_jp1])\n\n                # Admissibility Check\n                new_obj = current_obj + delta\n                \n                # Aspiration\n                is_aspirated = new_obj  best_obj\n                \n                # Tabu check for the two edges to be added\n                edge1 = tuple(sorted((p_im1, p_j)))\n                edge2 = tuple(sorted((p_i, p_jp1)))\n                is_tabu = (tabu_until.get(edge1, 0) >= iter_num or\n                           tabu_until.get(edge2, 0) >= iter_num)\n                \n                is_admissible = (not is_tabu) or is_aspirated\n                \n                if is_admissible:\n                    if delta  best_admissible_delta:\n                        best_admissible_delta = delta\n                        best_admissible_move = (i, j)\n                \n                if delta  best_delta_in_iter:\n                    best_delta_in_iter = delta\n                    best_move_in_iter = (i, j)\n            \n            # Select move for this iteration\n            if best_admissible_move is not None:\n                move_to_apply = best_admissible_move\n                delta_to_apply = best_admissible_delta\n            else:\n                move_to_apply = best_move_in_iter\n                delta_to_apply = best_delta_in_iter\n\n            if move_to_apply is None:\n                continue\n\n            # Apply the chosen move\n            i, j = move_to_apply\n            \n            # Get cities for tabu update before reversal\n            p_im1_idx = i - 1\n            p_jp1_idx = (j + 1) % self.n\n            p_im1 = current_tour[p_im1_idx]\n            p_i = current_tour[i]\n            p_j = current_tour[j]\n            p_jp1 = current_tour[p_jp1_idx]\n\n            # Reverse the tour segment\n            current_tour[i : j + 1] = current_tour[i : j + 1][::-1]\n            current_obj += delta_to_apply\n\n            if current_obj  best_obj:\n                best_obj = current_obj\n                best_tour = current_tour.copy()\n\n            # Update tabu list with newly added edges\n            edge1 = tuple(sorted((p_im1, p_j)))\n            edge2 = tuple(sorted((p_i, p_jp1)))\n            tabu_expiry_iter = iter_num + self.T_tenure\n            tabu_until[edge1] = tabu_expiry_iter\n            tabu_until[edge2] = tabu_expiry_iter\n        \n        avg_evals = total_evals / self.T\n        return best_obj, avg_evals\n\n    def run_comparison(self):\n        \"\"\"Runs both strategies and computes the required metrics.\"\"\"\n        f_full_star, avg_evals_full = self._tabu_search(strategy='full')\n        f_rcl_star, avg_evals_rcl = self._tabu_search(strategy='rcl')\n        \n        if f_full_star == 0:\n            rel_gap = 0.0\n        else:\n            rel_gap = (f_rcl_star - f_full_star) / f_full_star\n            \n        return [avg_evals_full, avg_evals_rcl, rel_gap, f_full_star, f_rcl_star]\n\ndef solve():\n    test_cases = [\n        # (n, T, k, s, T_tenure)\n        (10, 120, 1, 42, 7),\n        (12, 150, 20, 7, 7),\n        (14, 180, 90, 123, 8),\n        (6, 80, 2, 5, 5),\n    ]\n\n    results_for_print = []\n    for case in test_cases:\n        solver = TSPSolver(*case)\n        result = solver.run_comparison()\n        \n        avg_full_str = f\"{result[0]:.2f}\"\n        avg_rcl_str = f\"{result[1]:.2f}\"\n        gap_str = f\"{result[2]:.6f}\"\n        best_full_str = f\"{result[3]:.6f}\"\n        best_rcl_str = f\"{result[4]:.6f}\"\n        \n        results_for_print.append(\n            f\"[{avg_full_str},{avg_rcl_str},{gap_str},{best_full_str},{best_rcl_str}]\"\n        )\n        \n    print(f\"[{','.join(results_for_print)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "A working Tabu Search solver can be significantly improved by refining its memory structure; what the search remembers is as important as for how long it remembers it. This exercise challenges you to think critically about the definition of a tabu attribute, which is the basic unit of memory in the search. By comparing two different ways to encode tabu status for a node-insertion move in the TSP, you will explore how this design choice directly impacts the algorithm's ability to diversify its search and escape local optima .",
            "id": "3190979",
            "problem": "A research team is comparing two recency-based memory encodings in a Tabu Search solver for the symmetric metric Traveling Salesman Problem (TSP), where the objective is to minimize the sum of edge lengths in a Hamiltonian cycle. The solver uses the same neighborhood generator across experiments: a node-insertion move that removes a node and reinserts it between a chosen predecessor and successor. Tabu tenure is fixed at $t$ iterations in both experiments, and aspiration by best is applied identically. The two attribute encodings differ as follows:\n\n- Edge-addition encoding: when a node-insertion move places node $k$ between nodes $i$ and $j$, the undirected edges $(i,k)$ and $(k,j)$ that are added to the tour are declared tabu for $t$ iterations. Any candidate move that would add either of these edges during their tenure is prohibited unless aspiration applies.\n\n- Node-insertion encoding: when a node-insertion move places node $k$ between nodes $i$ and $j$, the ordered triple $(i,k,j)$ is declared tabu for $t$ iterations. Only the exact reinsertion of node $k$ between $i$ and $j$ during its tenure is prohibited unless aspiration applies.\n\nAssume a typical intermediate-scale instance with $n$ cities, where the solver evaluates candidate node-insertion moves in a manner that, over many iterations, makes the added edges and insertion triples approximately uniformly distributed across their respective domains. Let $m = \\frac{n(n-1)}{2}$ denote the number of undirected edges in the complete graph. Under these assumptions and keeping $t$ fixed, which statement is best supported by first-principles reasoning about cycling prevention, effective coverage of the candidate set by tabu restrictions, and the role of aspiration in symmetric metric TSP?\n\nA. Edge-addition encoding tends to yield higher-quality solutions because it more frequently blocks immediate reconstruction of recently used edges, thereby reducing short-term cycling while still permitting inclusion of high-quality short edges via aspiration.\n\nB. Node-insertion encoding tends to yield higher-quality solutions because its attribute space is larger, causing fewer tabu conflicts and thus enabling stronger intensification around current local minima.\n\nC. Both encodings tend to yield similar solution quality when $t$ is fixed, since equal tenure equalizes the number of prohibited moves regardless of attribute definition.\n\nD. In symmetric metric TSP, solution quality is insensitive to attribute encoding because neighborhood move recurrence is negligible over realistic iteration budgets.",
            "solution": "The user wants me to analyze and compare two different tabu attribute encoding schemes for a Tabu Search algorithm applied to the symmetric metric Traveling Salesman Problem (TSP).\n\n### Step 1: Extract Givens\n\n1.  **Problem Domain:** Symmetric metric Traveling Salesman Problem (TSP).\n2.  **Objective Function:** Minimize the total length of the Hamiltonian cycle.\n3.  **Algorithm:** Tabu Search (TS).\n4.  **Neighborhood Structure:** Node-insertion move (remove a node $k$ and reinsert it between two other nodes, $i$ and $j$).\n5.  **Tabu Tenure ($t$):** A fixed number of iterations, identical for both schemes.\n6.  **Aspiration Criterion:** Aspiration by best is used (a tabu move is permitted if it leads to a solution better than any found so far).\n7.  **Scheme 1 (Edge-addition encoding):** When a move inserts node $k$ between $i$ and $j$, the new undirected edges $(i,k)$ and $(k,j)$ are made tabu for $t$ iterations. Any move that would add a tabu edge is prohibited (unless aspiration applies).\n8.  **Scheme 2 (Node-insertion encoding):** When a move inserts node $k$ between $i$ and $j$, the ordered triple $(i,k,j)$ is made tabu for $t$ iterations. Only the exact move of reinserting $k$ between $i$ and $j$ is prohibited (unless aspiration applies).\n9.  **Assumptions:**\n    *   The instance has $n$ cities and is of intermediate scale.\n    *   The number of undirected edges is $m = \\frac{n(n-1)}{2}$.\n    *   Over time, the added edges and insertion triples are approximately uniformly distributed across their respective domains.\n10. **Question:** Evaluate which statement is best supported by reasoning about cycling prevention, coverage of the candidate set, and the role of aspiration.\n\n### Step 2: Validate Using Extracted Givens\n\n1.  **Scientifically Grounded:** The problem is firmly rooted in the established theory of metaheuristics and combinatorial optimization. Tabu Search, TSP, neighborhood structures, tabu attributes, and aspiration criteria are all standard, well-defined concepts. The comparison of different memory structures is a central topic in the study of TS.\n2.  **Well-Posed:** The problem provides two clearly distinct schemes and asks for a comparative analysis based on first principles. The assumptions, while simplifying, create a basis for a logical deduction about the relative performance of the two schemes. A unique, best-supported conclusion can be drawn.\n3.  **Objective:** The problem statement is written in precise, technical language, free from subjectivity or ambiguity.\n\nThe problem is self-contained, consistent, and scientifically sound. It presents a valid, non-trivial question in the field of optimization methods.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. I will proceed with the solution derivation.\n\n### Derivation and Analysis\n\nThe core of the problem lies in comparing the *restrictiveness* of the two tabu attribute encodings and its implication on the search dynamics for the TSP. The effectiveness of a Tabu Search algorithm hinges on a delicate balance between intensification (exploiting good regions of the search space) and diversification (exploring new regions to escape local optima). The tabu list is the primary mechanism for diversification.\n\nLet's analyze the impact of a single move—inserting node $k$ between nodes $i$ and $j$—under each encoding scheme.\n\n1.  **Node-insertion Encoding:**\n    *   **Attribute:** The ordered triple $(i,k,j)$.\n    *   **Restriction:** This scheme makes the specific action of \"inserting node $k$ between node $i$ and node $j$\" tabu. It forbids exactly one potential move from the entire neighborhood of future solutions.\n    *   **Restrictiveness:** This is a very *low* level of restriction. It directly prevents the immediate reversal of a move in a very narrow sense. For example, it does not prevent inserting $k$ between some other pair of nodes, say $(i,p)$, nor does it prevent inserting another node $q$ between $i$ and $j$.\n    *   **Attribute Space Size:** The number of possible ordered triples $(i,k,j)$ with distinct $i, j, k$ is $n(n-1)(n-2)$, which is of order $O(n^3)$. A large attribute space generally corresponds to less restrictive tabu declarations, as the probability of a random move matching a specific tabu attribute is lower.\n    *   **Search Behavior:** This scheme provides weak diversification. Since it only blocks the exact same insertion, the search can easily perform a series of moves that circle back to a previously visited region or solution using slightly different moves. This favors intensification, as the search is less constrained in exploring the local neighborhood of the current solution.\n\n2.  **Edge-addition Encoding:**\n    *   **Attribute:** The two undirected edges $(i,k)$ and $(k,j)$ that are formed by the insertion.\n    *   **Restriction:** This scheme makes the *components* of the new solution tabu. Any future candidate move that would re-form the edge $(i,k)$ or the edge $(k,j)$ is forbidden. A single tabu on an edge, say $(i,k)$, prohibits a class of moves. For example, it prohibits inserting node $k$ next to node $i$ (in either direction, since the edge is undirected), and it prohibits inserting node $i$ next to node $k$.\n    *   **Restrictiveness:** This is a significantly *higher* level of restriction than the node-insertion encoding. A single move renders a whole set of future moves tabu, not just one.\n    *   **Attribute Space Size:** The number of possible undirected edges is $m = \\frac{n(n-1)}{2}$, which is of order $O(n^2)$. A smaller attribute space generally corresponds to a more restrictive tabu declaration.\n    *   **Search Behavior:** This scheme provides strong diversification. By forbidding the reuse of recently added edges, it forces the search to find alternative ways to construct a tour, pushing it into structurally different regions of the solution space. This is highly effective at preventing short-term cycling and escaping local optima.\n\n**Connecting to the Symmetric Metric TSP context:**\n\n*   The TSP is an NP-hard problem with a notoriously difficult search landscape characterized by a vast number of local minima. Effective diversification is critical to finding high-quality solutions. A search that only intensifies will almost certainly get trapped in a poor local optimum.\n*   The primary role of the tabu list is to provide this diversification. Therefore, a more restrictive encoding that more effectively drives the search away from recently visited regions is, in principle, more desirable for a hard problem like TSP.\n*   The main risk of a highly restrictive scheme is that it may forbid moves that are part of an optimal or near-optimal solution path. In metric TSP, good solutions are composed of short edges. The edge-addition scheme might temporarily forbid the use of a very good short edge. This is where the **aspiration criterion** plays a crucial role. It acts as a safety valve, allowing a tabu move if it leads to a new best-ever solution. This allows the search to use a \"critical\" tabu edge if it's the key to a major improvement, mitigating the primary risk of the restrictive strategy.\n\n**Conclusion:** The edge-addition encoding implements a more powerful diversification strategy. The strong push to new regions of the search space, combined with the aspiration criterion safety-net, is a more robust strategy for tackling the TSP than the weak diversification offered by the node-insertion encoding. The latter's emphasis on intensification is less likely to be effective in escaping the multitude of local optima.\n\n### Option-by-Option Analysis\n\n*   **A. Edge-addition encoding tends to yield higher-quality solutions because it more frequently blocks immediate reconstruction of recently used edges, thereby reducing short-term cycling while still permitting inclusion of high-quality short edges via aspiration.**\n    *   This statement accurately identifies that the edge-addition encoding is more restrictive (\"more frequently blocks... reconstruction\"). It correctly states that this leads to better prevention of cycling (\"reducing short-term cycling\"). Critically, it correctly identifies the role of aspiration as a mechanism that mitigates the downside of this restrictiveness, especially for a problem like TSP where specific components (short edges) are valuable. The conclusion that this combination leads to higher-quality solutions is well-supported by the principles of Tabu Search applied to NP-hard problems.\n    *   **Verdict: Correct.**\n\n*   **B. Node-insertion encoding tends to yield higher-quality solutions because its attribute space is larger, causing fewer tabu conflicts and thus enabling stronger intensification around current local minima.**\n    *   The premises are correct: the attribute space is larger, leading to fewer tabu conflicts and enabling stronger intensification. However, the conclusion that this leads to *higher-quality solutions* is questionable for the TSP. The primary challenge in TSP is escaping local optima, which requires strong diversification, not just intensification. This option prioritizes the weaker aspect of the search strategy for this problem class.\n    *   **Verdict: Incorrect.**\n\n*   **C. Both encodings tend to yield similar solution quality when $t$ is fixed, since equal tenure equalizes the number of prohibited moves regardless of attribute definition.**\n    *   The premise \"equal tenure equalizes the number of prohibited moves\" is false. The number of moves prohibited by making an edge tabu is much larger than the number of moves prohibited by making an insertion-triple tabu. Therefore, the foundation of this argument is incorrect.\n    *   **Verdict: Incorrect.**\n\n*   **D. In symmetric metric TSP, solution quality is insensitive to attribute encoding because neighborhood move recurrence is negligible over realistic iteration budgets.**\n    *   The premise \"neighborhood move recurrence is negligible\" is factually incorrect. The tendency to cycle or return to recently visited states is a fundamental problem in local search, and it is the very reason Tabu Search was developed. If move recurrence were negligible, a simple local search would be sufficient, and the tabu mechanism would be pointless.\n    *   **Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}