{
    "hands_on_practices": [
        {
            "introduction": "The best way to truly understand an algorithm is to build it. This first exercise guides you through implementing the canonical Differential Evolution (DE) algorithm from scratch. You will not only code the core mutation, crossover, and selection operators, but also integrate two critical features for robust optimization: a restart schedule to escape local optima and bounce-back boundary handling to maintain population feasibility. Mastering this implementation on classic multimodal test functions like the Rastrigin and Ackley functions will provide a solid foundation for your practical skills .",
            "id": "3120583",
            "problem": "You are asked to implement a complete, deterministic program that minimizes multimodal objective functions using Differential Evolution with a restart schedule and bounce-back boundary handling. The program must embody first-principles reasoning in the design of its algorithmic steps and produce numerical results for a specified test suite.\n\nDifferential Evolution (DE) is a population-based optimization method defined for a function $f : \\mathbb{R}^d \\to \\mathbb{R}$ over bound constraints $[\\mathbf{L}, \\mathbf{U}]$, where $\\mathbf{L}, \\mathbf{U} \\in \\mathbb{R}^d$ and $\\mathbf{L}_j < \\mathbf{U}_j$ for all $j \\in \\{1, \\dots, d\\}$. The core DE operators are specified from foundational elements:\n\n1. Initialization: Sample $N_p$ candidate vectors uniformly at random in $[\\mathbf{L}, \\mathbf{U}]$, where $N_p \\in \\mathbb{N}$ is the population size.\n\n2. Mutation (DE/rand/1): For each target index $i$, pick three distinct indices $r_1, r_2, r_3$ (all different from $i$) and form the donor vector\n$$\n\\mathbf{v}_i = \\mathbf{x}_{r_1} + F \\cdot (\\mathbf{x}_{r_2} - \\mathbf{x}_{r_3}),\n$$\nwhere $F \\in \\mathbb{R}$ is the mutation factor.\n\n3. Crossover (binomial, also called uniform crossover): For each component $j \\in \\{1, \\dots, d\\}$,\n$$\nu_{i, j} = \n\\begin{cases}\nv_{i, j}, & \\text{if } \\text{rand} \\le CR \\text{ or } j = j_{\\text{rand}}, \\\\\nx_{i, j}, & \\text{otherwise},\n\\end{cases}\n$$\nwhere $CR \\in [0, 1]$ is the crossover rate, $\\text{rand}$ is a new independent sample from the uniform distribution on $[0, 1]$, and $j_{\\text{rand}}$ is a uniformly selected index in $\\{1, \\dots, d\\}$ to ensure at least one component comes from the donor vector.\n\n4. Selection (greedy): If $f(\\mathbf{u}_i) \\le f(\\mathbf{x}_i)$ then set $\\mathbf{x}_i \\leftarrow \\mathbf{u}_i$, else keep $\\mathbf{x}_i$ unchanged.\n\nBound handling must ensure feasibility of trial vectors. Implement bounce-back reflection for feasibility as follows: For any scalar component $y \\in \\mathbb{R}$ with lower bound $L$ and upper bound $U$, repeatedly reflect across the violated boundary until $y \\in [L, U]$,\n$$\ny \\leftarrow \n\\begin{cases}\n2L - y, & \\text{if } y < L, \\\\\n2U - y, & \\text{if } y > U,\n\\end{cases}\n$$\nand repeat if the reflected $y$ still violates the bounds. When bounce-back is disabled, instead use clipping\n$$\ny \\leftarrow \\min(\\max(y, L), U).\n$$\n\nDefine stagnation and the restart schedule precisely. Track the best objective value in each generation,\n$$\nf^\\star(g) = \\min_{i \\in \\{1, \\dots, N_p\\}} f(\\mathbf{x}_i(g)),\n$$\nwhere $\\mathbf{x}_i(g)$ is individual $i$ at generation $g$. Let $\\epsilon = 10^{-12}$. A generation is considered to improve if $f^\\star(g) < f^\\star(g-1) - \\epsilon$. A stagnation streak is a sequence of consecutive generations with no improvement. When the stagnation streak length reaches $S \\in \\mathbb{N}$, trigger a restart schedule by resetting the mutation factor and crossover rate to exploratory values $(F_{\\text{explore}}, CR_{\\text{explore}})$ for exactly $g_{\\text{explore}} \\in \\mathbb{N}$ generations. During this exploratory window, use $(F, CR) = (F_{\\text{explore}}, CR_{\\text{explore}})$. After the window ends, revert to base values $(F_{\\text{base}}, CR_{\\text{base}})$. If another stagnation streak of length $S$ occurs later, trigger another exploratory window in the same manner.\n\nUse the following multimodal objective functions, each widely used and well tested:\n\n- Rastrigin function in $d$ dimensions with parameter $A = 10$ and global minimum at $\\mathbf{x} = \\mathbf{0}$:\n$$\nf_{\\text{Rastrigin}}(\\mathbf{x}) = A d + \\sum_{j=1}^{d} \\left( x_j^2 - A \\cos(2\\pi x_j) \\right).\n$$\n\n- Ackley function in $d$ dimensions with parameters $a = 20$, $b = 0.2$, and $c = 2\\pi$, with global minimum at $\\mathbf{x} = \\mathbf{0}$:\n$$\nf_{\\text{Ackley}}(\\mathbf{x}) = -a \\exp\\left( -b \\sqrt{ \\frac{1}{d} \\sum_{j=1}^d x_j^2 } \\right)\n- \\exp\\left( \\frac{1}{d} \\sum_{j=1}^d \\cos(c x_j) \\right)\n+ a + e.\n$$\n\nYour program must implement the described Differential Evolution process with bounce-back boundary handling and the restart schedule. It must be deterministic by using fixed random seeds per test case.\n\nTest Suite:\nFor each test case below, run Differential Evolution for exactly $G_{\\max}$ generations and return the final best objective value as a floating-point number.\n\n- Case $1$ (happy path, Rastrigin bounce-back):\n  - Function: $f_{\\text{Rastrigin}}$.\n  - Dimension: $d = 5$.\n  - Bounds: $L_j = -5.12$, $U_j = 5.12$ for all $j$.\n  - Population size: $N_p = 40$.\n  - Generations: $G_{\\max} = 300$.\n  - Base parameters: $F_{\\text{base}} = 0.5$, $CR_{\\text{base}} = 0.9$.\n  - Exploratory parameters: $F_{\\text{explore}} = 0.95$, $CR_{\\text{explore}} = 0.2$.\n  - Stagnation threshold: $S = 25$.\n  - Exploratory window length: $g_{\\text{explore}} = 10$.\n  - Bounce-back: enabled.\n  - Random seed: $42$.\n\n- Case $2$ (Ackley bounce-back, higher ruggedness):\n  - Function: $f_{\\text{Ackley}}$.\n  - Dimension: $d = 5$.\n  - Bounds: $L_j = -32.768$, $U_j = 32.768$ for all $j$.\n  - Population size: $N_p = 30$.\n  - Generations: $G_{\\max} = 400$.\n  - Base parameters: $F_{\\text{base}} = 0.7$, $CR_{\\text{base}} = 0.6$.\n  - Exploratory parameters: $F_{\\text{explore}} = 1.0$, $CR_{\\text{explore}} = 0.1$.\n  - Stagnation threshold: $S = 40$.\n  - Exploratory window length: $g_{\\text{explore}} = 15$.\n  - Bounce-back: enabled.\n  - Random seed: $123$.\n\n- Case $3$ (Rastrigin bounce-back, frequent restarts edge case):\n  - Function: $f_{\\text{Rastrigin}}$.\n  - Dimension: $d = 2$.\n  - Bounds: $L_j = -5.12$, $U_j = 5.12$ for all $j$.\n  - Population size: $N_p = 10$.\n  - Generations: $G_{\\max} = 200$.\n  - Base parameters: $F_{\\text{base}} = 0.5$, $CR_{\\text{base}} = 0.9$.\n  - Exploratory parameters: $F_{\\text{explore}} = 1.2$, $CR_{\\text{explore}} = 0.1$.\n  - Stagnation threshold: $S = 5$.\n  - Exploratory window length: $g_{\\text{explore}} = 8$.\n  - Bounce-back: enabled.\n  - Random seed: $7$.\n\n- Case $4$ (Ackley with clipping instead of bounce-back, for comparative analysis):\n  - Function: $f_{\\text{Ackley}}$.\n  - Dimension: $d = 5$.\n  - Bounds: $L_j = -32.768$, $U_j = 32.768$ for all $j$.\n  - Population size: $N_p = 30$.\n  - Generations: $G_{\\max} = 400$.\n  - Base parameters: $F_{\\text{base}} = 0.7$, $CR_{\\text{base}} = 0.6$.\n  - Exploratory parameters: $F_{\\text{explore}} = 1.0$, $CR_{\\text{explore}} = 0.1$.\n  - Stagnation threshold: $S = 40$.\n  - Exploratory window length: $g_{\\text{explore}} = 15$.\n  - Bounce-back: disabled (use clipping).\n  - Random seed: $123$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the four final best objective values from the test suite in order as a comma-separated list enclosed in square brackets, for example $[$result1$,$result2$,$result3$,$result4$]$. Each result must be a floating-point number and the printed line must contain no other text.",
            "solution": "The problem requires the implementation of the Differential Evolution (DE) algorithm, incorporating a specific restart schedule for stagnation and a bounce-back boundary handling mechanism. The solution will be validated against a suite of test cases on standard multimodal benchmark functions. The entire process must be deterministic, achieved through the use of fixed random seeds for each test case.\n\nThe design of the solution follows from the first principles of population-based stochastic optimization and the specific operators defined in the problem statement.\n\nFirst, we define the objective functions. The Rastrigin function in $d$ dimensions with parameter $A$ is given by:\n$$\nf_{\\text{Rastrigin}}(\\mathbf{x}) = A d + \\sum_{j=1}^{d} \\left( x_j^2 - A \\cos(2\\pi x_j) \\right)\n$$\nThe Ackley function in $d$ dimensions with parameters $a$, $b$, and $c$ is given by:\n$$\nf_{\\text{Ackley}}(\\mathbf{x}) = -a \\exp\\left( -b \\sqrt{ \\frac{1}{d} \\sum_{j=1}^d x_j^2 } \\right)\n- \\exp\\left( \\frac{1}{d} \\sum_{j=1}^d \\cos(c x_j) \\right)\n+ a + e\n$$\nwhere $e$ is the base of the natural logarithm, $e \\approx 2.71828$.\n\nThe core of the algorithm is the Differential Evolution process.\n1.  **Initialization**: An initial population of $N_p$ candidate vectors, $\\{\\mathbf{x}_1, \\dots, \\mathbf{x}_{N_p}\\}$, is created. Each vector $\\mathbf{x}_i \\in \\mathbb{R}^d$ is sampled from a uniform distribution within the specified bounds $[\\mathbf{L}, \\mathbf{U}]$. That is, for each component $j \\in \\{1, \\dots, d\\}$, $x_{i,j}$ is sampled from $U(L_j, U_j)$. The process is seeded to ensure reproducibility.\n\n2.  **Generational Loop**: The algorithm iterates for a maximum of $G_{\\max}$ generations. In each generation, a new population of trial vectors is created and compared against the current population.\n\n3.  **Mutation**: For each target vector $\\mathbf{x}_i$ in the current population, a donor vector $\\mathbf{v}_i$ is generated using the \"DE/rand/1\" strategy. Three distinct indices $r_1, r_2, r_3 \\in \\{1, \\dots, N_p\\}$ are chosen randomly, ensuring they are also different from the target index $i$. The donor vector is then computed as:\n    $$\n    \\mathbf{v}_i = \\mathbf{x}_{r_1} + F \\cdot (\\mathbf{x}_{r_2} - \\mathbf{x}_{r_3})\n    $$\n    Here, $F \\in \\mathbb{R}$ is the mutation factor, a crucial parameter that controls the amplification of the differential variation.\n\n4.  **Crossover**: A trial vector $\\mathbf{u}_i$ is formed by combining components from the target vector $\\mathbf{x}_i$ and the donor vector $\\mathbf{v}_i$. The specified binomial crossover scheme is employed. For each component $j \\in \\{1, \\dots, d\\}$:\n    $$\n    u_{i, j} = \n    \\begin{cases}\n    v_{i, j}, & \\text{if } \\text{rand}_j \\le CR \\text{ or } j = j_{\\text{rand}}, \\\\\n    x_{i, j}, & \\text{otherwise},\n    \\end{cases}\n    $$\n    where $CR \\in [0, 1]$ is the crossover rate, $\\text{rand}_j$ is a new sample from $U(0, 1)$ for each component, and $j_{\\text{rand}}$ is a randomly chosen index from $\\{1, \\dots, d\\}$. The $j=j_{\\text{rand}}$ condition guarantees that the trial vector $\\mathbf{u}_i$ receives at least one component from the donor vector $\\mathbf{v}_i$.\n\n5.  **Boundary Handling**: The trial vector $\\mathbf{u}_i$ may have components that lie outside the feasible bounds $[\\mathbf{L}, \\mathbf{U}]$. These must be corrected before function evaluation.\n    *   **Clipping**: The simpler method, used when bounce-back is disabled, is to clip the component to the boundary: $u_{i,j} \\leftarrow \\min(\\max(u_{i,j}, L_j), U_j)$.\n    *   **Bounce-back Reflection**: This method reflects the out-of-bounds component back into the feasible range across the violated boundary. For a component $y$ and bounds $[L, U]$, the rule is:\n        $$\n        y \\leftarrow \n        \\begin{cases}\n        2L - y, & \\text{if } y < L, \\\\\n        2U - y, & \\text{if } y > U.\n        \\end{cases}\n        $$\n        Since a single reflection may not be sufficient if the component is far outside the boundary (e.g., $y < L - (U-L)$), this process must be applied iteratively in a loop until $y \\in [L, U]$.\n\n6.  **Selection**: A greedy selection policy determines whether the trial vector $\\mathbf{u}_i$ replaces the target vector $\\mathbf{x}_i$ in the next generation. The objective function values are compared:\n    $$\n    \\mathbf{x}_i^{\\text{next}} = \n    \\begin{cases}\n    \\mathbf{u}_i, & \\text{if } f(\\mathbf{u}_i) \\le f(\\mathbf{x}_i), \\\\\n    \\mathbf{x}_i, & \\text{otherwise}.\n    \\end{cases}\n    $$\n    This ensures that the population's fitness can only improve or stay the same over generations.\n\n7.  **Restart Schedule**: This mechanism is designed to escape local optima by periodically promoting exploration. It is governed by a stagnation counter.\n    *   Let $f^\\star(g)$ be the best objective value in the population at generation $g$. Improvement is defined as $f^\\star(g) < f^\\star(g-1) - \\epsilon$, where $\\epsilon = 10^{-12}$ is a small tolerance to account for floating-point inaccuracies.\n    *   A `stagnation_streak` counter is incremented for each consecutive generation without improvement. It is reset to $0$ upon improvement.\n    *   If `stagnation_streak` reaches the threshold $S$, a restart is triggered. The DE parameters $(F, CR)$ are set to their exploratory values $(F_{\\text{explore}}, CR_{\\text{explore}})$ for a duration of $g_{\\text{explore}}$ generations. The `stagnation_streak` counter is reset to $0$ to prevent immediate re-triggering.\n    *   An `exploratory_counter` manages the duration of this phase. It is initialized to $g_{\\text{explore}}$ and decremented each generation. When it reaches $0$, the parameters $(F, CR)$ revert to their base values $(F_{\\text{base}}, CR_{\\text{base}})$.\n\nBy combining these principled steps into a deterministic program (via fixed seeding), we can systematically evaluate the algorithm's performance on the specified test suite. The final output for each case will be the best objective function value found after $G_{\\max}$ generations.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the execution of all test cases.\n    \"\"\"\n    \n    # Define objective functions\n    def rastrigin(x, A=10):\n        d = len(x)\n        return A * d + np.sum(x**2 - A * np.cos(2 * np.pi * x))\n\n    def ackley(x, a=20, b=0.2, c=2*np.pi):\n        d = len(x)\n        sum_sq_term = -b * np.sqrt(np.sum(x**2) / d)\n        sum_cos_term = np.sum(np.cos(c * x)) / d\n        return -a * np.exp(sum_sq_term) - np.exp(sum_cos_term) + a + np.e\n\n    # Define test cases as a list of dictionaries\n    test_cases = [\n        {\n            \"name\": \"Case 1\",\n            \"function\": rastrigin,\n            \"d\": 5,\n            \"bounds\": (-5.12, 5.12),\n            \"Np\": 40,\n            \"G_max\": 300,\n            \"F_base\": 0.5, \"CR_base\": 0.9,\n            \"F_explore\": 0.95, \"CR_explore\": 0.2,\n            \"S\": 25,\n            \"g_explore\": 10,\n            \"bounce_back\": True,\n            \"seed\": 42,\n        },\n        {\n            \"name\": \"Case 2\",\n            \"function\": ackley,\n            \"d\": 5,\n            \"bounds\": (-32.768, 32.768),\n            \"Np\": 30,\n            \"G_max\": 400,\n            \"F_base\": 0.7, \"CR_base\": 0.6,\n            \"F_explore\": 1.0, \"CR_explore\": 0.1,\n            \"S\": 40,\n            \"g_explore\": 15,\n            \"bounce_back\": True,\n            \"seed\": 123,\n        },\n        {\n            \"name\": \"Case 3\",\n            \"function\": rastrigin,\n            \"d\": 2,\n            \"bounds\": (-5.12, 5.12),\n            \"Np\": 10,\n            \"G_max\": 200,\n            \"F_base\": 0.5, \"CR_base\": 0.9,\n            \"F_explore\": 1.2, \"CR_explore\": 0.1,\n            \"S\": 5,\n            \"g_explore\": 8,\n            \"bounce_back\": True,\n            \"seed\": 7,\n        },\n        {\n            \"name\": \"Case 4\",\n            \"function\": ackley,\n            \"d\": 5,\n            \"bounds\": (-32.768, 32.768),\n            \"Np\": 30,\n            \"G_max\": 400,\n            \"F_base\": 0.7, \"CR_base\": 0.6,\n            \"F_explore\": 1.0, \"CR_explore\": 0.1,\n            \"S\": 40,\n            \"g_explore\": 15,\n            \"bounce_back\": False, # Use clipping\n            \"seed\": 123,\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        final_best_val = run_de(case)\n        results.append(f\"{final_best_val:.12f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef run_de(params):\n    \"\"\"\n    Executes the Differential Evolution algorithm for a single test case.\n    \"\"\"\n    # Unpack parameters\n    obj_func = params[\"function\"]\n    d = params[\"d\"]\n    L, U = params[\"bounds\"]\n    bounds = np.array([L, U] * d).reshape(d, 2)\n    Np = params[\"Np\"]\n    G_max = params[\"G_max\"]\n    F_base, CR_base = params[\"F_base\"], params[\"CR_base\"]\n    F_explore, CR_explore = params[\"F_explore\"], params[\"CR_explore\"]\n    S = params[\"S\"]\n    g_explore = params[\"g_explore\"]\n    use_bounce_back = params[\"bounce_back\"]\n    seed = params[\"seed\"]\n    epsilon = 1e-12\n\n    # Initialize random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # 1. Initialization\n    population = rng.uniform(L, U, size=(Np, d))\n    fitness = np.array([obj_func(ind) for ind in population])\n    \n    # Restart schedule state variables\n    stagnation_streak = 0\n    exploratory_counter = 0\n    F, CR = F_base, CR_base\n    best_obj_val = np.min(fitness)\n\n    population_indices = list(range(Np))\n\n    # 2. Main generational loop\n    for _ in range(G_max):\n        new_population = population.copy()\n        new_fitness = fitness.copy()\n\n        for i in range(Np):\n            # 3. Mutation (DE/rand/1)\n            choices = population_indices[:i] + population_indices[i+1:]\n            r1, r2, r3 = rng.choice(choices, size=3, replace=False)\n            \n            x_r1 = population[r1]\n            x_r2 = population[r2]\n            x_r3 = population[r3]\n\n            donor_vector = x_r1 + F * (x_r2 - x_r3)\n\n            # 4. Crossover (Binomial)\n            target_vector = population[i]\n            trial_vector = target_vector.copy()\n            \n            rand_vals = rng.random(size=d)\n            j_rand = rng.integers(0, d)\n            \n            crossover_mask = (rand_vals <= CR) | (np.arange(d) == j_rand)\n            trial_vector[crossover_mask] = donor_vector[crossover_mask]\n            \n            # 5. Boundary Handling\n            if use_bounce_back:\n                # Iterative bounce-back\n                for j in range(d):\n                    while trial_vector[j] < bounds[j, 0] or trial_vector[j] > bounds[j, 1]:\n                        if trial_vector[j] < bounds[j, 0]:\n                            trial_vector[j] = 2 * bounds[j, 0] - trial_vector[j]\n                        if trial_vector[j] > bounds[j, 1]:\n                            trial_vector[j] = 2 * bounds[j, 1] - trial_vector[j]\n            else:\n                # Clipping\n                np.clip(trial_vector, bounds[:, 0], bounds[:, 1], out=trial_vector)\n\n            # 6. Selection (Greedy)\n            trial_fitness = obj_func(trial_vector)\n            if trial_fitness <= fitness[i]:\n                new_population[i] = trial_vector\n                new_fitness[i] = trial_fitness\n        \n        population = new_population\n        fitness = new_fitness\n\n        # 7. Restart Schedule Logic\n        current_best_gen_val = np.min(fitness)\n        \n        if current_best_gen_val < best_obj_val - epsilon:\n            stagnation_streak = 0\n        else:\n            stagnation_streak += 1\n        \n        best_obj_val = min(best_obj_val, current_best_gen_val)\n        \n        # Manage state for the *next* generation's parameters\n        if exploratory_counter > 0:\n            exploratory_counter -= 1\n            if exploratory_counter == 0:\n                F, CR = F_base, CR_base\n        \n        if stagnation_streak >= S:\n            F, CR = F_explore, CR_explore\n            exploratory_counter = g_explore\n            stagnation_streak = 0\n\n    return np.min(fitness)\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "The performance of any population-based algorithm is sensitive to its starting population. This practice explores how to give your optimizer a better head start using a technique called Opposition-Based Learning (OBL). You will implement and compare a standard uniform random sampling with an opposition-based initialization strategy, quantifying the benefit on a simple convex problem. This exercise will help you develop an intuition for how domain characteristics, such as symmetry, influence the effectiveness of different initialization schemes .",
            "id": "3120621",
            "problem": "You are asked to implement and compare two initialization strategies that can be used to warm-start a Differential Evolution algorithm for minimizing the function $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2$ over a hyper-rectangular domain. Your comparison must be performed under a fixed, limited budget of objective evaluations.\n\nStart from the following fundamental base:\n- The Euclidean norm of a vector $\\mathbf{x} \\in \\mathbb{R}^d$ is defined by $\\|\\mathbf{x}\\| = \\sqrt{\\sum_{i=1}^d x_i^2}$. Therefore, the objective $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2$ is $f(\\mathbf{x}) = \\sum_{i=1}^d x_i^2$, attaining its global minimum value $0$ at $\\mathbf{x}=\\mathbf{0}$ whenever $\\mathbf{0}$ lies in the domain.\n- The hyper-rectangular domain is described by componentwise bounds $\\mathbf{l} \\le \\mathbf{x} \\le \\mathbf{u}$, with $\\mathbf{l} = (l,\\dots,l)$ and $\\mathbf{u} = (u,\\dots,u)$ for scalar bounds $l < u$.\n- Opposition-Based Learning (OBL) defines the pointwise opposite of $\\mathbf{x}$ with respect to bounds $\\mathbf{l}$ and $\\mathbf{u}$ as $\\tilde{\\mathbf{x}}$ with components $\\tilde{x}_i = l_i + u_i - x_i$. When $l=-u$, this is reflection through the origin, $\\tilde{\\mathbf{x}} = -\\mathbf{x}$.\n\nYour task:\n- Implement two warm-start sampling strategies under a fixed evaluation budget $M$:\n  1. Pure Uniform Sampling (URS): draw $M$ independent samples $\\mathbf{x}^{(1)},\\dots,\\mathbf{x}^{(M)}$ uniformly from $[l,u]^d$, evaluate $f$ on all of them, and define the warm-start quality as $q_{\\mathrm{URS}}=\\min_{1\\le k\\le M} f(\\mathbf{x}^{(k)})$.\n  2. Opposition-Based Initialization (OBI) using Opposition-Based Learning (OBL): draw $M/2$ independent base points $\\mathbf{x}^{(1)},\\dots,\\mathbf{x}^{(M/2)}$ uniformly from $[l,u]^d$, form their pointwise opposites $\\tilde{\\mathbf{x}}^{(k)}$ via $\\tilde{x}^{(k)}_i = l_i + u_i - x^{(k)}_i$, evaluate $f$ on both each base point and its opposite, and define the warm-start quality as $q_{\\mathrm{OBI}}=\\min\\{ f(\\mathbf{x}^{(k)}), f(\\tilde{\\mathbf{x}}^{(k)}) : 1\\le k\\le M/2 \\}$. Assume $M$ is even so that $M/2$ is an integer.\n- For each strategy, ensure that exactly $M$ function evaluations are counted, so the comparison is fair under the limited evaluation budget.\n\nComparison metric:\n- For each test case, compute the scalar $c = q_{\\mathrm{URS}} - q_{\\mathrm{OBI}}$. A positive value of $c$ indicates that opposition-based initialization delivered a strictly better (smaller) warm-start objective value under the same budget.\n\nImplementation details:\n- Use independent and identically distributed (i.i.d.) sampling from the uniform distribution on $[l,u]^d$.\n- All computations must be carried out in double precision floating point.\n- Randomness must be controlled via a pseudo-random seed so that results are exactly reproducible.\n\nTest suite:\n- Evaluate your implementation on the following five test cases, each specified as a tuple $(d,l,u,M,s)$:\n  1. $(d,l,u,M,s) = (2, -5, 5, 100, 42)$.\n  2. $(d,l,u,M,s) = (10, -1, 1, 200, 7)$.\n  3. $(d,l,u,M,s) = (30, -100, 100, 60, 123)$.\n  4. $(d,l,u,M,s) = (5, 0, 1, 10, 999)$.\n  5. $(d,l,u,M,s) = (1, -10, 10, 2, 2024)$.\n\nRequired final output:\n- Your program must output a single line containing a Python-style list of the five scalars $c$ for the test cases above, in the same order as listed, with each value rounded to exactly six decimal places using standard rounding rules. For example: \"[0.123456,-0.000001,0.500000,0.000000,1.234568]\".\n- Angles and physical units do not apply. All outputs are unitless real numbers.\n\nScientific realism and constraints:\n- Ensure that the implementation exactly follows the definitions above and counts objective evaluations as specified.\n- Do not provide any additional commentary or diagnostics in the program output.",
            "solution": "We formalize the comparison using core definitions from optimization and probability. The objective is $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2 = \\sum_{i=1}^d x_i^2$, which is a strictly convex, radially symmetric function minimized at $\\mathbf{0}$ when feasible. The domain is the hyper-rectangle $[l,u]^d$ with $l < u$. The goal of a warm start is to supply initial points with low objective values to a subsequent optimization algorithm such as Differential Evolution, but here we focus only on the initialization phase under a constrained budget of objective evaluations.\n\nThe two strategies are:\n\n- Pure Uniform Sampling (URS): draw $M$ i.i.d. samples from the uniform distribution on $[l,u]^d$ and take the best objective value found. This uses exactly $M$ evaluations. Because samples are independent, the minimum over $M$ i.i.d. draws tends to decrease as $M$ grows.\n\n- Opposition-Based Initialization (OBI) using Opposition-Based Learning (OBL): for each base point $\\mathbf{x}^{(k)}$ drawn uniformly, construct its pointwise opposite $\\tilde{\\mathbf{x}}^{(k)}$ given by $\\tilde{x}^{(k)}_i = l_i + u_i - x^{(k)}_i$. This reflection is about the midpoint $\\frac{l_i + u_i}{2}$ of each coordinate interval. The budget is enforced by drawing $M/2$ base points and evaluating both each base and its opposite, totaling $M$ function evaluations. The best objective among these $M$ evaluations is the warm-start quality.\n\nCorrectness and fairness:\n- Both strategies expend exactly $M$ evaluations, ensuring a fair comparison.\n- The OBL mapping preserves feasibility: if $x^{(k)}_i \\in [l_i,u_i]$ then $\\tilde{x}^{(k)}_i = l_i + u_i - x^{(k)}_i \\in [l_i,u_i]$.\n\nQualitative analysis grounded in the objective's structure:\n- When the domain is symmetric about the origin, i.e., $l = -u$, the opposition mapping reduces to $\\tilde{\\mathbf{x}} = -\\mathbf{x}$. Because $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2 = \\|-\\mathbf{x}\\|^2$, each evaluated pair $(\\mathbf{x}, -\\mathbf{x})$ yields identical objective values. Under a fixed budget $M$, OBI produces $M/2$ distinct base locations (with duplicates only via symmetry) but evaluates both signs; URS, by contrast, produces $M$ independent draws. Therefore, with $l=-u$, the per-pair best in OBI is the same as either element, offering no improvement per pair while sacrificing the total count of independent locations by a factor of $2$. Consequently, the minimum over $M$ independent URS draws can be smaller than the minimum over $M/2$ independent base draws in OBI, leading to $c = q_{\\mathrm{URS}} - q_{\\mathrm{OBI}}$ that is nonpositive or negative on average.\n\n- When the domain is asymmetric relative to the minimizer, for example $[0,1]^d$ where the minimizer $\\mathbf{0}$ sits on the lower bound, the opposition mapping $\\tilde{x}_i = 1 - x_i$ reflects $x_i$ about $0.5$. For $x_i$ near $1$, the opposite brings it closer to $0$; hence $f(\\tilde{\\mathbf{x}})$ can be significantly smaller than $f(\\mathbf{x})$. In this setting, evaluating both $\\mathbf{x}$ and $\\tilde{\\mathbf{x}}$ increases the chance that at least one of the pair is closer to the minimizer. Although OBI evaluates only $M/2$ base points, the best-of-pair effect can produce a smaller minimum than URS under the same budget $M$, potentially yielding positive $c$.\n\nAlgorithmic design:\n1. For URS with given $(d,l,u,M,s)$:\n   - Initialize a pseudo-random number generator with seed $s$.\n   - Draw an array of $M$ vectors with components sampled i.i.d. from the uniform distribution on $[l,u]$.\n   - Compute $f$ for each vector as the sum of squares of its components.\n   - Record $q_{\\mathrm{URS}}$ as the minimum of these $M$ values.\n\n2. For OBI with the same $(d,l,u,M,s)$:\n   - Initialize an independent pseudo-random number generator with the same seed $s$ to ensure a fair and reproducible comparison in terms of underlying randomness per test case, while maintaining independence between strategies’ samples in implementation by separate draws or by distinct streams if desired. Using the same seed for each strategy’s own generator ensures reproducibility, and because we draw according to the specified distributions, any correlation across strategies does not affect correctness of the per-strategy distributions.\n   - Draw $M/2$ base vectors uniformly from $[l,u]^d$.\n   - Compute their opposites $\\tilde{\\mathbf{x}}$ via $\\tilde{x}_i = l + u - x_i$.\n   - Evaluate $f$ on both sets and take $q_{\\mathrm{OBI}}$ as the minimum over these $M$ objective values.\n\n3. Compute $c = q_{\\mathrm{URS}} - q_{\\mathrm{OBI}}$.\n\nEdge cases from the test suite:\n- $(1, -10, 10, 2, 2024)$ is a boundary case with the smallest even budget and one dimension. With $l = -u$, OBI evaluates a pair $(x,-x)$ with equal objective values, while URS evaluates two i.i.d. draws; the comparison can slightly favor URS due to independence.\n- Higher dimension $(30, -100, 100, 60, 123)$ with wide bounds and limited budget tests the effect of high dimensionality, where typical distances from the origin are larger and the difference between strategies is driven more by sample count than per-pair opposition benefits.\n- The asymmetric case $(5, 0, 1, 10, 999)$ can showcase a benefit for OBI because reflecting about the midpoint can move points closer to the minimizer at the origin.\n\nOutput:\n- For each of the five test cases, compute $c$ and round to six decimal places.\n- Output a single line with a Python-style list of these five values in order. No additional text may be printed.\n\nThis approach adheres to the core definitions of the objective function, the domain, and Opposition-Based Learning, and it ensures that the comparison under a limited evaluation budget is principled and reproducible. The randomized nature of sampling is fully controlled by fixed seeds, guaranteeing identical outputs across runs. The conclusions align with the geometry of $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2$ and the symmetry or asymmetry of the domain bounds.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef f_obj(x: np.ndarray) -> np.ndarray:\n    # Computes f(x) = ||x||^2 for a batch of points (rows of x)\n    # Returns a 1D array of objective values.\n    return np.sum(x * x, axis=1)\n\ndef uniform_best_min(d: int, l: float, u: float, M: int, seed: int) -> float:\n    rng = np.random.default_rng(seed)\n    # Sample M points uniformly in [l,u]^d\n    X = rng.uniform(l, u, size=(M, d))\n    vals = f_obj(X)\n    return float(np.min(vals))\n\ndef opposition_best_min(d: int, l: float, u: float, M: int, seed: int) -> float:\n    assert M % 2 == 0, \"M must be even for opposition-based evaluation budget.\"\n    rng = np.random.default_rng(seed)\n    base_count = M // 2\n    X = rng.uniform(l, u, size=(base_count, d))\n    X_opp = (l + u) - X\n    vals_base = f_obj(X)\n    vals_opp = f_obj(X_opp)\n    # Combine both sets of evaluations (total M evaluations)\n    min_val = float(np.min(np.concatenate([vals_base, vals_opp], axis=0)))\n    return min_val\n\ndef run_case(d: int, l: float, u: float, M: int, seed: int) -> float:\n    q_urs = uniform_best_min(d, l, u, M, seed)\n    q_obi = opposition_best_min(d, l, u, M, seed)\n    return q_urs - q_obi  # Positive means OBI better\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is (d, l, u, M, seed)\n    test_cases = [\n        (2, -5.0, 5.0, 100, 42),\n        (10, -1.0, 1.0, 200, 7),\n        (30, -100.0, 100.0, 60, 123),\n        (5, 0.0, 1.0, 10, 999),\n        (1, -10.0, 10.0, 2, 2024),\n    ]\n\n    results = []\n    for d, l, u, M, seed in test_cases:\n        c = run_case(d, l, u, M, seed)\n        results.append(c)\n\n    # Round to exactly six decimal places and format as required.\n    formatted = \"[\" + \",\".join(f\"{v:.6f}\" for v in results) + \"]\"\n    print(formatted)\n\nsolve()\n```"
        },
        {
            "introduction": "Differential Evolution is inherently a continuous-space optimizer, but can it be applied to problems with integer variables? This exercise explores a common and practical heuristic: solving a continuous relaxation of the problem and then rounding the result. You will apply DE to a simple integer optimization problem and quantify the 'rounding bias'—the difference in solution quality between this heuristic and the true optimal integer solution. This practice demonstrates how to adapt continuous algorithms for discrete domains, a valuable skill in real-world engineering and logistics problems .",
            "id": "3120707",
            "problem": "Consider the discrete optimization of an integer vector $\\mathbf{k}\\in\\mathbb{Z}^n$ under bound constraints. Let the objective be $f(\\mathbf{k})=\\sum_{i=1}^n \\lvert k_i - 3\\rvert$, where each coordinate $k_i$ is constrained by $\\ell_i \\le k_i \\le u_i$ with $\\ell_i,u_i\\in\\mathbb{Z}$ and $\\ell_i \\le u_i$. You will approximate the discrete problem using a continuous surrogate and then map the continuous solution back to the integer domain. Specifically, define the continuous surrogate $g(\\mathbf{x})=\\sum_{i=1}^n \\lvert x_i - 3\\rvert$ with $\\mathbf{x}\\in\\mathbb{R}^n$ and box constraints $\\ell_i \\le x_i \\le u_i$. Using Differential Evolution (DE) on $\\mathbb{R}^n$, minimize $g(\\mathbf{x})$ over the box-constraints to obtain a continuous minimizer $\\mathbf{x}^\\star$. Map $\\mathbf{x}^\\star$ to the integer domain by rounding each coordinate to the nearest integer with ties rounding up, that is, for each $i$, compute $k^{\\mathrm{DE}}_i = \\min\\big(\\max\\big(\\lfloor x_i^\\star + 0.5 \\rfloor,\\ell_i\\big),u_i\\big)$ to enforce feasibility. Then compute the discrete objective $f(\\mathbf{k}^{\\mathrm{DE}})$. Independently, compute the exact discrete optimum value $f(\\mathbf{k}^\\star)$ where $\\mathbf{k}^\\star\\in\\mathbb{Z}^n$ minimizes $f(\\mathbf{k})$ under the same bounds. Define the rounding bias for a given instance as $b = f(\\mathbf{k}^{\\mathrm{DE}}) - f(\\mathbf{k}^\\star)$. Your task is to implement a program that, for each specified test case, carries out the described steps and returns the rounding bias $b$ as a floating-point number.\n\nUse the following test suite of bound-constraint instances, expressed as lists of $(\\ell_i,u_i)$ pairs that define the box for each coordinate:\n- Test case $1$: $n=5$, bounds are $(\\ell_i,u_i)=(0,10)$ for all $i\\in\\{1,2,3,4,5\\}$.\n- Test case $2$: $n=4$, bounds are $(\\ell_i,u_i)=(4,8)$ for all $i\\in\\{1,2,3,4\\}$.\n- Test case $3$: $n=3$, bounds are $(\\ell_1,u_1)=(2,2)$, $(\\ell_2,u_2)=(3,3)$, $(\\ell_3,u_3)=(5,5)$.\n- Test case $4$: $n=6$, bounds are $(\\ell_1,u_1)=(0,5)$, $(\\ell_2,u_2)=(1,1)$, $(\\ell_3,u_3)=(10,10)$, $(\\ell_4,u_4)=(2,7)$, $(\\ell_5,u_5)=(4,4)$, $(\\ell_6,u_6)=(3,9)$.\n\nThe program should use Differential Evolution (DE) on the continuous surrogate $g(\\mathbf{x})$ with the given bounds, then apply the rounding and clamping rule described above to obtain $\\mathbf{k}^{\\mathrm{DE}}$ and compute $f(\\mathbf{k}^{\\mathrm{DE}})$. It must also compute the true discrete optimum value $f(\\mathbf{k}^\\star)$ exactly. For each test case, output the rounding bias $b$ as defined above.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one entry per test case, in the order $[b_1,b_2,b_3,b_4]$ corresponding to test cases $1$ through $4$. No physical units or angles are involved in this problem, and all outputs are real numbers (floating-point).",
            "solution": "The user-provided problem statement is critically analyzed and found to be valid. It is a well-posed problem in the domain of numerical optimization that is scientifically grounded and formally specified.\n\nThe problem requires the calculation of a \"rounding bias,\" denoted by $b$, for several instances of a discrete optimization problem. This bias is defined as the difference between the objective function value obtained by a heuristic method and the value from the exact optimal solution. The heuristic involves solving a continuous relaxation of the problem and then rounding the solution back to the integer domain.\n\nLet's break down the required calculations into a systematic, step-by-step procedure.\n\n### 1. The Discrete Optimization Problem\n\nThe core task is to minimize the objective function $f(\\mathbf{k}) = \\sum_{i=1}^n \\lvert k_i - 3\\rvert$ for an integer vector $\\mathbf{k} = (k_1, k_2, \\ldots, k_n) \\in \\mathbb{Z}^n$. The search space is constrained by a set of lower and upper bounds for each coordinate: $\\ell_i \\le k_i \\le u_i$, where $\\ell_i, u_i \\in \\mathbb{Z}$.\n\n### 2. Finding the Exact Discrete Optimum, $f(\\mathbf{k}^\\star)$\n\nThe objective function $f(\\mathbf{k})$ is separable, meaning it can be expressed as a sum of functions of individual variables: $f(\\mathbf{k}) = \\sum_{i=1}^n f_i(k_i)$, where $f_i(k_i) = \\lvert k_i - 3\\rvert$. To minimize the sum, we can minimize each term $f_i(k_i)$ independently over its respective domain $[\\ell_i, u_i]$.\n\nThe function $f_i(k_i) = \\lvert k_i - 3\\rvert$ measures the distance from $k_i$ to the value $3$. The minimum value is achieved when $k_i$ is the integer in the interval $[\\ell_i, u_i]$ that is closest to $3$. Let this optimal integer be $k_i^\\star$.\n\nWe can determine $k_i^\\star$ as follows:\n- If the value $3$ is within the interval $[\\ell_i, u_i]$, i.e., $\\ell_i \\le 3 \\le u_i$, then the closest integer is $3$ itself. So, $k_i^\\star = 3$.\n- If $3 < \\ell_i$, then all integers in the interval are greater than $3$. The one closest to $3$ is the smallest, which is $\\ell_i$. So, $k_i^\\star = \\ell_i$.\n- If $3 > u_i$, then all integers in the interval are less than $3$. The one closest to $3$ is the largest, which is $u_i$. So, $k_i^\\star = u_i$.\n\nThis logic can be compactly expressed using a clipping operation. Since $\\ell_i$ and $u_i$ are integers, the optimal discrete value $k_i^\\star$ for the $i$-th coordinate is given by clamping the target value $3$ to the interval $[\\ell_i, u_i]$:\n$$k_i^\\star = \\max(\\ell_i, \\min(u_i, 3))$$\nThe exact optimal integer vector is $\\mathbf{k}^\\star = (k_1^\\star, k_2^\\star, \\ldots, k_n^\\star)$. The minimum objective value is then:\n$$f(\\mathbf{k}^\\star) = \\sum_{i=1}^n \\lvert k_i^\\star - 3\\rvert$$\n\n### 3. The Continuous Relaxation and Rounding Heuristic\n\nThe problem specifies a heuristic approach to find an approximate integer solution.\n\n**Step 3a: The Continuous Surrogate Problem**\nThe discrete problem is relaxed into a continuous one by allowing the variables to be real numbers. The surrogate objective function is $g(\\mathbf{x}) = \\sum_{i=1}^n \\lvert x_i - 3\\rvert$, where $\\mathbf{x} = (x_1, x_2, \\ldots, x_n) \\in \\mathbb{R}^n$ is subject to the same box constraints, $\\ell_i \\le x_i \\le u_i$.\n\nSimilar to the discrete case, the minimum of this continuous, separable function occurs when each $x_i$ is the real number in $[\\ell_i, u_i]$ closest to $3$. This gives the exact continuous minimizer $\\mathbf{x}^\\star$ with coordinates:\n$$x_i^\\star = \\max(\\ell_i, \\min(u_i, 3))$$\nNotably, since $\\ell_i$ and $u_i$ are integers, the coordinates $x_i^\\star$ of the true continuous minimizer are themselves integers, and in fact, $\\mathbf{x}^\\star = \\mathbf{k}^\\star$.\n\n**Step 3b: Numerical Optimization with Differential Evolution (DE)**\nThe problem mandates using the Differential Evolution (DE) algorithm to find the continuous minimizer. DE is a stochastic, population-based optimizer. For a simple convex function like $g(\\mathbf{x})$, DE is expected to find a solution vector $\\mathbf{x}^{\\mathrm{DE}}$ that is a very close floating-point approximation of the true minimizer $\\mathbf{x}^\\star$.\n\n**Step 3c: Rounding and Clamping**\nThe numerically obtained continuous solution $\\mathbf{x}^{\\mathrm{DE}}$ is mapped back to the integer domain to get an approximate integer solution, $\\mathbf{k}^{\\mathrm{DE}}$. The rule for each coordinate is:\n$$k^{\\mathrm{DE}}_i = \\min\\big(\\max\\big(\\lfloor x^{\\mathrm{DE}}_i + 0.5 \\rfloor,\\ell_i\\big),u_i\\big)$$\nThe operation $\\lfloor z + 0.5 \\rfloor$ corresponds to rounding $z$ to the nearest integer, with halves (e.g., $2.5$) rounded up. The surrounding $\\min$ and $\\max$ functions ensure the resulting integer $k^{\\mathrm{DE}}_i$ lies within the feasible range $[\\ell_i, u_i]$.\n\n**Step 3d: Evaluating the Heuristic Solution**\nThe objective function is then evaluated at this new integer vector $\\mathbf{k}^{\\mathrm{DE}}$:\n$$f(\\mathbf{k}^{\\mathrm{DE}}) = \\sum_{i=1}^n \\lvert k_i^{\\mathrm{DE}} - 3\\rvert$$\n\n### 4. Calculating the Rounding Bias\n\nThe final step is to compute the rounding bias $b$, defined as the difference between the objective value of the heuristic solution and the exact optimal value:\n$$b = f(\\mathbf{k}^{\\mathrm{DE}}) - f(\\mathbf{k}^\\star)$$\n\n### Expected Result\nSince the true continuous minimizer $\\mathbf{x}^\\star$ is identical to the true discrete minimizer $\\mathbf{k}^\\star$, and DE is expected to find a very accurate approximation $\\mathbf{x}^{\\mathrm{DE}} \\approx \\mathbf{x}^\\star$, it is highly probable that the rounding step will recover the exact integer solution. That is, for each coordinate $i$, it is expected that the error $|x^{\\mathrm{DE}}_i - x_i^\\star|$ will be much less than $0.5$, leading to $\\lfloor x^{\\mathrm{DE}}_i + 0.5 \\rfloor = x_i^\\star = k_i^\\star$. After clamping (which would have no effect as $k_i^\\star$ is already in bounds), we would find $\\mathbf{k}^{\\mathrm{DE}} = \\mathbf{k}^\\star$. This would imply $f(\\mathbf{k}^{\\mathrm{DE}}) = f(\\mathbf{k}^\\star)$ and thus a rounding bias $b = 0$. The implementation will computationally verify this for each test case.\n\nThe provided Python code will execute these steps faithfully for each test case, including running the DE optimization. A fixed random seed will be used for DE to ensure reproducibility.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import differential_evolution\n\ndef solve():\n    \"\"\"\n    Solves the optimization problem for all test cases and prints the rounding bias.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1: n=5, bounds (0,10) for all i\n        [(0, 10)] * 5,\n        # Test case 2: n=4, bounds (4,8) for all i\n        [(4, 8)] * 4,\n        # Test case 3: n=3, bounds (2,2), (3,3), (5,5)\n        [(2, 2), (3, 3), (5, 5)],\n        # Test case 4: n=6, bounds (0,5), (1,1), (10,10), (2,7), (4,4), (3,9)\n        [(0, 5), (1, 1), (10, 10), (2, 7), (4, 4), (3, 9)],\n    ]\n\n    results = []\n    # Use a fixed seed for the stochastic DE algorithm for reproducibility.\n    RANDOM_SEED = 42\n    \n    # The target value for the objective function.\n    TARGET_VALUE = 3\n\n    for bounds in test_cases:\n        # Extract lower and upper bounds as numpy arrays for vectorized operations.\n        lower_bounds = np.array([b[0] for b in bounds])\n        upper_bounds = np.array([b[1] for b in bounds])\n\n        # 1. Compute the exact discrete optimum f(k*)\n        # The optimal integer k_i* is the integer in [l_i, u_i] closest to 3.\n        # This is equivalent to clipping the target value 3 to the integer interval.\n        k_star = np.clip(TARGET_VALUE, lower_bounds, upper_bounds)\n        f_k_star = np.sum(np.abs(k_star - TARGET_VALUE))\n\n        # 2. Minimize the continuous surrogate g(x) using Differential Evolution\n        # Define the continuous objective function g(x).\n        def g(x):\n            return np.sum(np.abs(x - TARGET_VALUE))\n\n        # Run the DE optimization.\n        de_result = differential_evolution(\n            g, \n            bounds, \n            seed=RANDOM_SEED\n        )\n        x_star_de = de_result.x\n\n        # 3. Map the continuous solution x* back to the integer domain\n        # The rule is to round to the nearest integer (ties round up), then clamp.\n        # floor(x + 0.5) implements this rounding rule.\n        k_de_rounded = np.floor(x_star_de + 0.5)\n        \n        # Clamp the rounded vector to ensure it is within the feasible integer domain.\n        k_de = np.clip(k_de_rounded, lower_bounds, upper_bounds)\n\n        # Compute the objective value for the DE-based integer solution.\n        f_k_de = np.sum(np.abs(k_de - TARGET_VALUE))\n\n        # 4. Compute the rounding bias b\n        bias = f_k_de - f_k_star\n        results.append(float(bias))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}