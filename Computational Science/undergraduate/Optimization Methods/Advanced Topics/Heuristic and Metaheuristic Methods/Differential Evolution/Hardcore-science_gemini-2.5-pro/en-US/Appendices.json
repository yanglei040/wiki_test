{
    "hands_on_practices": [
        {
            "introduction": "To truly master Differential Evolution, there is no substitute for building it from the ground up. This practice guides you through implementing a complete DE solver, incorporating not just the core mutation and crossover operators, but also advanced features essential for robust performance. You will implement a restart schedule to escape local optima and a 'bounce-back' boundary handling technique, giving you firsthand experience with the practical engineering of a powerful optimization algorithm. ",
            "id": "3120583",
            "problem": "You are asked to implement a complete, deterministic program that minimizes multimodal objective functions using Differential Evolution with a restart schedule and bounce-back boundary handling. The program must embody first-principles reasoning in the design of its algorithmic steps and produce numerical results for a specified test suite.\n\nDifferential Evolution (DE) is a population-based optimization method defined for a function $f : \\mathbb{R}^d \\to \\mathbb{R}$ over bound constraints $[\\mathbf{L}, \\mathbf{U}]$, where $\\mathbf{L}, \\mathbf{U} \\in \\mathbb{R}^d$ and $\\mathbf{L}_j < \\mathbf{U}_j$ for all $j \\in \\{1, \\dots, d\\}$. The core DE operators are specified from foundational elements:\n\n1. Initialization: Sample $N_p$ candidate vectors uniformly at random in $[\\mathbf{L}, \\mathbf{U}]$, where $N_p \\in \\mathbb{N}$ is the population size.\n\n2. Mutation (DE/rand/1): For each target index $i$, pick three distinct indices $r_1, r_2, r_3$ (all different from $i$) and form the donor vector\n$$\n\\mathbf{v}_i = \\mathbf{x}_{r_1} + F \\cdot (\\mathbf{x}_{r_2} - \\mathbf{x}_{r_3}),\n$$\nwhere $F \\in \\mathbb{R}$ is the mutation factor.\n\n3. Crossover (binomial, also called uniform crossover): For each component $j \\in \\{1, \\dots, d\\}$,\n$$\nu_{i, j} = \n\\begin{cases}\nv_{i, j}, & \\text{if } \\text{rand} \\le CR \\text{ or } j = j_{\\text{rand}}, \\\\\nx_{i, j}, & \\text{otherwise},\n\\end{cases}\n$$\nwhere $CR \\in [0, 1]$ is the crossover rate, $\\text{rand}$ is a new independent sample from the uniform distribution on $[0, 1]$, and $j_{\\text{rand}}$ is a uniformly selected index in $\\{1, \\dots, d\\}$ to ensure at least one component comes from the donor vector.\n\n4. Selection (greedy): If $f(\\mathbf{u}_i) \\le f(\\mathbf{x}_i)$ then set $\\mathbf{x}_i \\leftarrow \\mathbf{u}_i$, else keep $\\mathbf{x}_i$ unchanged.\n\nBound handling must ensure feasibility of trial vectors. Implement bounce-back reflection for feasibility as follows: For any scalar component $y \\in \\mathbb{R}$ with lower bound $L$ and upper bound $U$, repeatedly reflect across the violated boundary until $y \\in [L, U]$,\n$$\ny \\leftarrow \n\\begin{cases}\n2L - y, & \\text{if } y < L, \\\\\n2U - y, & \\text{if } y > U,\n\\end{cases}\n$$\nand repeat if the reflected $y$ still violates the bounds. When bounce-back is disabled, instead use clipping\n$$\ny \\leftarrow \\min(\\max(y, L), U).\n$$\n\nDefine stagnation and the restart schedule precisely. Track the best objective value in each generation,\n$$\nf^\\star(g) = \\min_{i \\in \\{1, \\dots, N_p\\}} f(\\mathbf{x}_i(g)),\n$$\nwhere $\\mathbf{x}_i(g)$ is individual $i$ at generation $g$. Let $\\epsilon = 10^{-12}$. A generation is considered to improve if $f^\\star(g) < f^\\star(g-1) - \\epsilon$. A stagnation streak is a sequence of consecutive generations with no improvement. When the stagnation streak length reaches $S \\in \\mathbb{N}$, trigger a restart schedule by resetting the mutation factor and crossover rate to exploratory values $(F_{\\text{explore}}, CR_{\\text{explore}})$ for exactly $g_{\\text{explore}} \\in \\mathbb{N}$ generations. During this exploratory window, use $(F, CR) = (F_{\\text{explore}}, CR_{\\text{explore}})$. After the window ends, revert to base values $(F_{\\text{base}}, CR_{\\text{base}})$. If another stagnation streak of length $S$ occurs later, trigger another exploratory window in the same manner.\n\nUse the following multimodal objective functions, each widely used and well tested:\n\n- Rastrigin function in $d$ dimensions with parameter $A = 10$ and global minimum at $\\mathbf{x} = \\mathbf{0}$:\n$$\nf_{\\text{Rastrigin}}(\\mathbf{x}) = A d + \\sum_{j=1}^{d} \\left( x_j^2 - A \\cos(2\\pi x_j) \\right).\n$$\n\n- Ackley function in $d$ dimensions with parameters $a = 20$, $b = 0.2$, and $c = 2\\pi$, with global minimum at $\\mathbf{x} = \\mathbf{0}$:\n$$\nf_{\\text{Ackley}}(\\mathbf{x}) = -a \\exp\\left( -b \\sqrt{ \\frac{1}{d} \\sum_{j=1}^d x_j^2 } \\right)\n- \\exp\\left( \\frac{1}{d} \\sum_{j=1}^d \\cos(c x_j) \\right)\n+ a + e.\n$$\n\nYour program must implement the described Differential Evolution process with bounce-back boundary handling and the restart schedule. It must be deterministic by using fixed random seeds per test case.\n\nTest Suite:\nFor each test case below, run Differential Evolution for exactly $G_{\\max}$ generations and return the final best objective value as a floating-point number.\n\n- Case $1$ (happy path, Rastrigin bounce-back):\n  - Function: $f_{\\text{Rastrigin}}$.\n  - Dimension: $d = 5$.\n  - Bounds: $L_j = -5.12$, $U_j = 5.12$ for all $j$.\n  - Population size: $N_p = 40$.\n  - Generations: $G_{\\max} = 300$.\n  - Base parameters: $F_{\\text{base}} = 0.5$, $CR_{\\text{base}} = 0.9$.\n  - Exploratory parameters: $F_{\\text{explore}} = 0.95$, $CR_{\\text{explore}} = 0.2$.\n  - Stagnation threshold: $S = 25$.\n  - Exploratory window length: $g_{\\text{explore}} = 10$.\n  - Bounce-back: enabled.\n  - Random seed: $42$.\n\n- Case $2$ (Ackley bounce-back, higher ruggedness):\n  - Function: $f_{\\text{Ackley}}$.\n  - Dimension: $d = 5$.\n  - Bounds: $L_j = -32.768$, $U_j = 32.768$ for all $j$.\n  - Population size: $N_p = 30$.\n  - Generations: $G_{\\max} = 400$.\n  - Base parameters: $F_{\\text{base}} = 0.7$, $CR_{\\text{base}} = 0.6$.\n  - Exploratory parameters: $F_{\\text{explore}} = 1.0$, $CR_{\\text{explore}} = 0.1$.\n  - Stagnation threshold: $S = 40$.\n  - Exploratory window length: $g_{\\text{explore}} = 15$.\n  - Bounce-back: enabled.\n  - Random seed: $123$.\n\n- Case $3$ (Rastrigin bounce-back, frequent restarts edge case):\n  - Function: $f_{\\text{Rastrigin}}$.\n  - Dimension: $d = 2$.\n  - Bounds: $L_j = -5.12$, $U_j = 5.12$ for all $j$.\n  - Population size: $N_p = 10$.\n  - Generations: $G_{\\max} = 200$.\n  - Base parameters: $F_{\\text{base}} = 0.5$, $CR_{\\text{base}} = 0.9$.\n  - Exploratory parameters: $F_{\\text{explore}} = 1.2$, $CR_{\\text{explore}} = 0.1$.\n  - Stagnation threshold: $S = 5$.\n  - Exploratory window length: $g_{\\text{explore}} = 8$.\n  - Bounce-back: enabled.\n  - Random seed: $7$.\n\n- Case $4$ (Ackley with clipping instead of bounce-back, for comparative analysis):\n  - Function: $f_{\\text{Ackley}}$.\n  - Dimension: $d = 5$.\n  - Bounds: $L_j = -32.768$, $U_j = 32.768$ for all $j$.\n  - Population size: $N_p = 30$.\n  - Generations: $G_{\\max} = 400$.\n  - Base parameters: $F_{\\text{base}} = 0.7$, $CR_{\\text{base}} = 0.6$.\n  - Exploratory parameters: $F_{\\text{explore}} = 1.0$, $CR_{\\text{explore}} = 0.1$.\n  - Stagnation threshold: $S = 40$.\n  - Exploratory window length: $g_{\\text{explore}} = 15$.\n  - Bounce-back: disabled (use clipping).\n  - Random seed: $123$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the four final best objective values from the test suite in order as a comma-separated list enclosed in square brackets, for example $[$result1$,$result2$,$result3$,$result4$]$. Each result must be a floating-point number and the printed line must contain no other text.",
            "solution": "The problem requires the implementation of the Differential Evolution (DE) algorithm, incorporating a specific restart schedule for stagnation and a bounce-back boundary handling mechanism. The solution will be validated against a suite of test cases on standard multimodal benchmark functions. The entire process must be deterministic, achieved through the use of fixed random seeds for each test case.\n\nThe design of the solution follows from the first principles of population-based stochastic optimization and the specific operators defined in the problem statement.\n\nFirst, we define the objective functions. The Rastrigin function in $d$ dimensions with parameter $A$ is given by:\n$$\nf_{\\text{Rastrigin}}(\\mathbf{x}) = A d + \\sum_{j=1}^{d} \\left( x_j^2 - A \\cos(2\\pi x_j) \\right)\n$$\nThe Ackley function in $d$ dimensions with parameters $a$, $b$, and $c$ is given by:\n$$\nf_{\\text{Ackley}}(\\mathbf{x}) = -a \\exp\\left( -b \\sqrt{ \\frac{1}{d} \\sum_{j=1}^d x_j^2 } \\right)\n- \\exp\\left( \\frac{1}{d} \\sum_{j=1}^d \\cos(c x_j) \\right)\n+ a + e\n$$\nwhere $e$ is the base of the natural logarithm, $e \\approx 2.71828$.\n\nThe core of the algorithm is the Differential Evolution process.\n1.  **Initialization**: An initial population of $N_p$ candidate vectors, $\\{\\mathbf{x}_1, \\dots, \\mathbf{x}_{N_p}\\}$, is created. Each vector $\\mathbf{x}_i \\in \\mathbb{R}^d$ is sampled from a uniform distribution within the specified bounds $[\\mathbf{L}, \\mathbf{U}]$. That is, for each component $j \\in \\{1, \\dots, d\\}$, $x_{i,j}$ is sampled from $U(L_j, U_j)$. The process is seeded to ensure reproducibility.\n\n2.  **Generational Loop**: The algorithm iterates for a maximum of $G_{\\max}$ generations. In each generation, a new population of trial vectors is created and compared against the current population.\n\n3.  **Mutation**: For each target vector $\\mathbf{x}_i$ in the current population, a donor vector $\\mathbf{v}_i$ is generated using the \"DE/rand/1\" strategy. Three distinct indices $r_1, r_2, r_3 \\in \\{1, \\dots, N_p\\}$ are chosen randomly, ensuring they are also different from the target index $i$. The donor vector is then computed as:\n    $$\n    \\mathbf{v}_i = \\mathbf{x}_{r_1} + F \\cdot (\\mathbf{x}_{r_2} - \\mathbf{x}_{r_3})\n    $$\n    Here, $F \\in \\mathbb{R}$ is the mutation factor, a crucial parameter that controls the amplification of the differential variation.\n\n4.  **Crossover**: A trial vector $\\mathbf{u}_i$ is formed by combining components from the target vector $\\mathbf{x}_i$ and the donor vector $\\mathbf{v}_i$. The specified binomial crossover scheme is employed. For each component $j \\in \\{1, \\dots, d\\}$:\n    $$\n    u_{i, j} = \n    \\begin{cases}\n    v_{i, j}, & \\text{if } \\text{rand}_j \\le CR \\text{ or } j = j_{\\text{rand}}, \\\\\n    x_{i, j}, & \\text{otherwise},\n    \\end{cases}\n    $$\n    where $CR \\in [0, 1]$ is the crossover rate, $\\text{rand}_j$ is a new sample from $U(0, 1)$ for each component, and $j_{\\text{rand}}$ is a randomly chosen index from $\\{1, \\dots, d\\}$. The $j=j_{\\text{rand}}$ condition guarantees that the trial vector $\\mathbf{u}_i$ receives at least one component from the donor vector $\\mathbf{v}_i$.\n\n5.  **Boundary Handling**: The trial vector $\\mathbf{u}_i$ may have components that lie outside the feasible bounds $[\\mathbf{L}, \\mathbf{U}]$. These must be corrected before function evaluation.\n    *   **Clipping**: The simpler method, used when bounce-back is disabled, is to clip the component to the boundary: $u_{i,j} \\leftarrow \\min(\\max(u_{i,j}, L_j), U_j)$.\n    *   **Bounce-back Reflection**: This method reflects the out-of-bounds component back into the feasible range across the violated boundary. For a component $y$ and bounds $[L, U]$, the rule is:\n        $$\n        y \\leftarrow \n        \\begin{cases}\n        2L - y, & \\text{if } y < L, \\\\\n        2U - y, & \\text{if } y > U.\n        \\end{cases}\n        $$\n        Since a single reflection may not be sufficient if the component is far outside the boundary (e.g., $y < L - (U-L)$), this process must be applied iteratively in a loop until $y \\in [L, U]$.\n\n6.  **Selection**: A greedy selection policy determines whether the trial vector $\\mathbf{u}_i$ replaces the target vector $\\mathbf{x}_i$ in the next generation. The objective function values are compared:\n    $$\n    \\mathbf{x}_i^{\\text{next}} = \n    \\begin{cases}\n    \\mathbf{u}_i, & \\text{if } f(\\mathbf{u}_i) \\le f(\\mathbf{x}_i), \\\\\n    \\mathbf{x}_i, & \\text{otherwise}.\n    \\end{cases}\n    $$\n    This ensures that the population's fitness can only improve or stay the same over generations.\n\n7.  **Restart Schedule**: This mechanism is designed to escape local optima by periodically promoting exploration. It is governed by a stagnation counter.\n    *   Let $f^\\star(g)$ be the best objective value in the population at generation $g$. Improvement is defined as $f^\\star(g) < f^\\star(g-1) - \\epsilon$, where $\\epsilon = 10^{-12}$ is a small tolerance to account for floating-point inaccuracies.\n    *   A `stagnation_streak` counter is incremented for each consecutive generation without improvement. It is reset to $0$ upon improvement.\n    *   If `stagnation_streak` reaches the threshold $S$, a restart is triggered. The DE parameters $(F, CR)$ are set to their exploratory values $(F_{\\text{explore}}, CR_{\\text{explore}})$ for a duration of $g_{\\text{explore}}$ generations. The `stagnation_streak` counter is reset to $0$ to prevent immediate re-triggering.\n    *   An `exploratory_counter` manages the duration of this phase. It is initialized to $g_{\\text{explore}}$ and decremented each generation. When it reaches $0$, the parameters $(F, CR)$ revert to their base values $(F_{\\text{base}}, CR_{\\text{base}})$.\n\nBy combining these principled steps into a deterministic program (via fixed seeding), we can systematically evaluate the algorithm's performance on the specified test suite. The final output for each case will be the best objective function value found after $G_{\\max}$ generations.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the execution of all test cases.\n    \"\"\"\n    \n    # Define objective functions\n    def rastrigin(x, A=10):\n        d = len(x)\n        return A * d + np.sum(x**2 - A * np.cos(2 * np.pi * x))\n\n    def ackley(x, a=20, b=0.2, c=2*np.pi):\n        d = len(x)\n        sum_sq_term = -b * np.sqrt(np.sum(x**2) / d)\n        sum_cos_term = np.sum(np.cos(c * x)) / d\n        return -a * np.exp(sum_sq_term) - np.exp(sum_cos_term) + a + np.e\n\n    # Define test cases as a list of dictionaries\n    test_cases = [\n        {\n            \"name\": \"Case 1\",\n            \"function\": rastrigin,\n            \"d\": 5,\n            \"bounds\": (-5.12, 5.12),\n            \"Np\": 40,\n            \"G_max\": 300,\n            \"F_base\": 0.5, \"CR_base\": 0.9,\n            \"F_explore\": 0.95, \"CR_explore\": 0.2,\n            \"S\": 25,\n            \"g_explore\": 10,\n            \"bounce_back\": True,\n            \"seed\": 42,\n        },\n        {\n            \"name\": \"Case 2\",\n            \"function\": ackley,\n            \"d\": 5,\n            \"bounds\": (-32.768, 32.768),\n            \"Np\": 30,\n            \"G_max\": 400,\n            \"F_base\": 0.7, \"CR_base\": 0.6,\n            \"F_explore\": 1.0, \"CR_explore\": 0.1,\n            \"S\": 40,\n            \"g_explore\": 15,\n            \"bounce_back\": True,\n            \"seed\": 123,\n        },\n        {\n            \"name\": \"Case 3\",\n            \"function\": rastrigin,\n            \"d\": 2,\n            \"bounds\": (-5.12, 5.12),\n            \"Np\": 10,\n            \"G_max\": 200,\n            \"F_base\": 0.5, \"CR_base\": 0.9,\n            \"F_explore\": 1.2, \"CR_explore\": 0.1,\n            \"S\": 5,\n            \"g_explore\": 8,\n            \"bounce_back\": True,\n            \"seed\": 7,\n        },\n        {\n            \"name\": \"Case 4\",\n            \"function\": ackley,\n            \"d\": 5,\n            \"bounds\": (-32.768, 32.768),\n            \"Np\": 30,\n            \"G_max\": 400,\n            \"F_base\": 0.7, \"CR_base\": 0.6,\n            \"F_explore\": 1.0, \"CR_explore\": 0.1,\n            \"S\": 40,\n            \"g_explore\": 15,\n            \"bounce_back\": False, # Use clipping\n            \"seed\": 123,\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        final_best_val = run_de(case)\n        results.append(f\"{final_best_val:.12f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef run_de(params):\n    \"\"\"\n    Executes the Differential Evolution algorithm for a single test case.\n    \"\"\"\n    # Unpack parameters\n    obj_func = params[\"function\"]\n    d = params[\"d\"]\n    L, U = params[\"bounds\"]\n    bounds = np.array([L, U] * d).reshape(d, 2)\n    Np = params[\"Np\"]\n    G_max = params[\"G_max\"]\n    F_base, CR_base = params[\"F_base\"], params[\"CR_base\"]\n    F_explore, CR_explore = params[\"F_explore\"], params[\"CR_explore\"]\n    S = params[\"S\"]\n    g_explore = params[\"g_explore\"]\n    use_bounce_back = params[\"bounce_back\"]\n    seed = params[\"seed\"]\n    epsilon = 1e-12\n\n    # Initialize random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # 1. Initialization\n    population = rng.uniform(L, U, size=(Np, d))\n    fitness = np.array([obj_func(ind) for ind in population])\n    \n    # Restart schedule state variables\n    stagnation_streak = 0\n    exploratory_counter = 0\n    F, CR = F_base, CR_base\n    best_obj_val = np.min(fitness)\n\n    population_indices = list(range(Np))\n\n    # 2. Main generational loop\n    for _ in range(G_max):\n        new_population = population.copy()\n        new_fitness = fitness.copy()\n\n        for i in range(Np):\n            # 3. Mutation (DE/rand/1)\n            choices = population_indices[:i] + population_indices[i+1:]\n            r1, r2, r3 = rng.choice(choices, size=3, replace=False)\n            \n            x_r1 = population[r1]\n            x_r2 = population[r2]\n            x_r3 = population[r3]\n\n            donor_vector = x_r1 + F * (x_r2 - x_r3)\n\n            # 4. Crossover (Binomial)\n            target_vector = population[i]\n            trial_vector = target_vector.copy()\n            \n            rand_vals = rng.random(size=d)\n            j_rand = rng.integers(0, d)\n            \n            crossover_mask = (rand_vals <= CR) | (np.arange(d) == j_rand)\n            trial_vector[crossover_mask] = donor_vector[crossover_mask]\n            \n            # 5. Boundary Handling\n            if use_bounce_back:\n                # Iterative bounce-back\n                for j in range(d):\n                    while trial_vector[j] < bounds[j, 0] or trial_vector[j] > bounds[j, 1]:\n                        if trial_vector[j] < bounds[j, 0]:\n                            trial_vector[j] = 2 * bounds[j, 0] - trial_vector[j]\n                        if trial_vector[j] > bounds[j, 1]:\n                            trial_vector[j] = 2 * bounds[j, 1] - trial_vector[j]\n            else:\n                # Clipping\n                np.clip(trial_vector, bounds[:, 0], bounds[:, 1], out=trial_vector)\n\n            # 6. Selection (Greedy)\n            trial_fitness = obj_func(trial_vector)\n            if trial_fitness <= fitness[i]:\n                new_population[i] = trial_vector\n                new_fitness[i] = trial_fitness\n        \n        population = new_population\n        fitness = new_fitness\n\n        # 7. Restart Schedule Logic\n        current_best_gen_val = np.min(fitness)\n        \n        if current_best_gen_val < best_obj_val - epsilon:\n            stagnation_streak = 0\n        else:\n            stagnation_streak += 1\n        \n        best_obj_val = min(best_obj_val, current_best_gen_val)\n        \n        # Manage state for the *next* generation's parameters\n        if exploratory_counter > 0:\n            exploratory_counter -= 1\n            if exploratory_counter == 0:\n                F, CR = F_base, CR_base\n        \n        if stagnation_streak >= S:\n            F, CR = F_explore, CR_explore\n            exploratory_counter = g_explore\n            stagnation_streak = 0\n\n    return np.min(fitness)\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "A powerful optimization run often begins with a smart start. This exercise explores Opposition-Based Initialization (OBI), a clever heuristic designed to improve the quality of the initial population by sampling not just random points, but their opposites as well. By comparing this strategy against standard uniform sampling, you will gain insight into how the geometry of the search space affects initialization and learn a practical technique to accelerate convergence. ",
            "id": "3120621",
            "problem": "You are asked to implement and compare two initialization strategies that can be used to warm-start a Differential Evolution algorithm for minimizing the function $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2$ over a hyper-rectangular domain. Your comparison must be performed under a fixed, limited budget of objective evaluations.\n\nStart from the following fundamental base:\n- The Euclidean norm of a vector $\\mathbf{x} \\in \\mathbb{R}^d$ is defined by $\\|\\mathbf{x}\\| = \\sqrt{\\sum_{i=1}^d x_i^2}$. Therefore, the objective $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2$ is $f(\\mathbf{x}) = \\sum_{i=1}^d x_i^2$, attaining its global minimum value $0$ at $\\mathbf{x}=\\mathbf{0}$ whenever $\\mathbf{0}$ lies in the domain.\n- The hyper-rectangular domain is described by componentwise bounds $\\mathbf{l} \\le \\mathbf{x} \\le \\mathbf{u}$, with $\\mathbf{l} = (l,\\dots,l)$ and $\\mathbf{u} = (u,\\dots,u)$ for scalar bounds $l < u$.\n- Opposition-Based Learning (OBL) defines the pointwise opposite of $\\mathbf{x}$ with respect to bounds $\\mathbf{l}$ and $\\mathbf{u}$ as $\\tilde{\\mathbf{x}}$ with components $\\tilde{x}_i = l_i + u_i - x_i$. When $l=-u$, this is reflection through the origin, $\\tilde{\\mathbf{x}} = -\\mathbf{x}$.\n\nYour task:\n- Implement two warm-start sampling strategies under a fixed evaluation budget $M$:\n  1. Pure Uniform Sampling (URS): draw $M$ independent samples $\\mathbf{x}^{(1)},\\dots,\\mathbf{x}^{(M)}$ uniformly from $[l,u]^d$, evaluate $f$ on all of them, and define the warm-start quality as $q_{\\mathrm{URS}}=\\min_{1\\le k\\le M} f(\\mathbf{x}^{(k)})$.\n  2. Opposition-Based Initialization (OBI) using Opposition-Based Learning (OBL): draw $M/2$ independent base points $\\mathbf{x}^{(1)},\\dots,\\mathbf{x}^{(M/2)}$ uniformly from $[l,u]^d$, form their pointwise opposites $\\tilde{\\mathbf{x}}^{(k)}$ via $\\tilde{x}^{(k)}_i = l_i + u_i - x^{(k)}_i$, evaluate $f$ on both each base point and its opposite, and define the warm-start quality as $q_{\\mathrm{OBI}}=\\min\\{ f(\\mathbf{x}^{(k)}), f(\\tilde{\\mathbf{x}}^{(k)}) : 1\\le k\\le M/2 \\}$. Assume $M$ is even so that $M/2$ is an integer.\n- For each strategy, ensure that exactly $M$ function evaluations are counted, so the comparison is fair under the limited evaluation budget.\n\nComparison metric:\n- For each test case, compute the scalar $c = q_{\\mathrm{URS}} - q_{\\mathrm{OBI}}$. A positive value of $c$ indicates that opposition-based initialization delivered a strictly better (smaller) warm-start objective value under the same budget.\n\nImplementation details:\n- Use independent and identically distributed (i.i.d.) sampling from the uniform distribution on $[l,u]^d$.\n- All computations must be carried out in double precision floating point.\n- Randomness must be controlled via a pseudo-random seed so that results are exactly reproducible.\n\nTest suite:\n- Evaluate your implementation on the following five test cases, each specified as a tuple $(d,l,u,M,s)$:\n  1. $(d,l,u,M,s) = (2, -5, 5, 100, 42)$.\n  2. $(d,l,u,M,s) = (10, -1, 1, 200, 7)$.\n  3. $(d,l,u,M,s) = (30, -100, 100, 60, 123)$.\n  4. $(d,l,u,M,s) = (5, 0, 1, 10, 999)$.\n  5. $(d,l,u,M,s) = (1, -10, 10, 2, 2024)$.\n\nRequired final output:\n- Your program must output a single line containing a Python-style list of the five scalars $c$ for the test cases above, in the same order as listed, with each value rounded to exactly six decimal places using standard rounding rules. For example: \"[0.123456,-0.000001,0.500000,0.000000,1.234568]\".\n- Angles and physical units do not apply. All outputs are unitless real numbers.\n\nScientific realism and constraints:\n- Ensure that the implementation exactly follows the definitions above and counts objective evaluations as specified.\n- Do not provide any additional commentary or diagnostics in the program output.",
            "solution": "We formalize the comparison using core definitions from optimization and probability. The objective is $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2 = \\sum_{i=1}^d x_i^2$, which is a strictly convex, radially symmetric function minimized at $\\mathbf{0}$ when feasible. The domain is the hyper-rectangle $[l,u]^d$ with $l < u$. The goal of a warm start is to supply initial points with low objective values to a subsequent optimization algorithm such as Differential Evolution, but here we focus only on the initialization phase under a constrained budget of objective evaluations.\n\nThe two strategies are:\n\n- Pure Uniform Sampling (URS): draw $M$ i.i.d. samples from the uniform distribution on $[l,u]^d$ and take the best objective value found. This uses exactly $M$ evaluations. Because samples are independent, the minimum over $M$ i.i.d. draws tends to decrease as $M$ grows.\n\n- Opposition-Based Initialization (OBI) using Opposition-Based Learning (OBL): for each base point $\\mathbf{x}^{(k)}$ drawn uniformly, construct its pointwise opposite $\\tilde{\\mathbf{x}}^{(k)}$ given by $\\tilde{x}^{(k)}_i = l_i + u_i - x^{(k)}_i$. This reflection is about the midpoint $\\frac{l_i + u_i}{2}$ of each coordinate interval. The budget is enforced by drawing $M/2$ base points and evaluating both each base and its opposite, totaling $M$ function evaluations. The best objective among these $M$ evaluations is the warm-start quality.\n\nCorrectness and fairness:\n- Both strategies expend exactly $M$ evaluations, ensuring a fair comparison.\n- The OBL mapping preserves feasibility: if $x^{(k)}_i \\in [l_i,u_i]$ then $\\tilde{x}^{(k)}_i = l_i + u_i - x^{(k)}_i \\in [l_i,u_i]$.\n\nQualitative analysis grounded in the objective's structure:\n- When the domain is symmetric about the origin, i.e., $l = -u$, the opposition mapping reduces to $\\tilde{\\mathbf{x}} = -\\mathbf{x}$. Because $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2 = \\|-\\mathbf{x}\\|^2$, each evaluated pair $(\\mathbf{x}, -\\mathbf{x})$ yields identical objective values. Under a fixed budget $M$, OBI produces $M/2$ distinct base locations (with duplicates only via symmetry) but evaluates both signs; URS, by contrast, produces $M$ independent draws. Therefore, with $l=-u$, the per-pair best in OBI is the same as either element, offering no improvement per pair while sacrificing the total count of independent locations by a factor of $2$. Consequently, the minimum over $M$ independent URS draws can be smaller than the minimum over $M/2$ independent base draws in OBI, leading to $c = q_{\\mathrm{URS}} - q_{\\mathrm{OBI}}$ that is nonpositive or negative on average.\n\n- When the domain is asymmetric relative to the minimizer, for example $[0,1]^d$ where the minimizer $\\mathbf{0}$ sits on the lower bound, the opposition mapping $\\tilde{x}_i = 1 - x_i$ reflects $x_i$ about $0.5$. For $x_i$ near $1$, the opposite brings it closer to $0$; hence $f(\\tilde{\\mathbf{x}})$ can be significantly smaller than $f(\\mathbf{x})$. In this setting, evaluating both $\\mathbf{x}$ and $\\tilde{\\mathbf{x}}$ increases the chance that at least one of the pair is closer to the minimizer. Although OBI evaluates only $M/2$ base points, the best-of-pair effect can produce a smaller minimum than URS under the same budget $M$, potentially yielding positive $c$.\n\nAlgorithmic design:\n1. For URS with given $(d,l,u,M,s)$:\n   - Initialize a pseudo-random number generator with seed $s$.\n   - Draw an array of $M$ vectors with components sampled i.i.d. from the uniform distribution on $[l,u]$.\n   - Compute $f$ for each vector as the sum of squares of its components.\n   - Record $q_{\\mathrm{URS}}$ as the minimum of these $M$ values.\n\n2. For OBI with the same $(d,l,u,M,s)$:\n   - Initialize an independent pseudo-random number generator with the same seed $s$ to ensure a fair and reproducible comparison in terms of underlying randomness per test case, while maintaining independence between strategies’ samples in implementation by separate draws or by distinct streams if desired. Using the same seed for each strategy’s own generator ensures reproducibility, and because we draw according to the specified distributions, any correlation across strategies does not affect correctness of the per-strategy distributions.\n   - Draw $M/2$ base vectors uniformly from $[l,u]^d$.\n   - Compute their opposites $\\tilde{\\mathbf{x}}$ via $\\tilde{x}_i = l + u - x_i$.\n   - Evaluate $f$ on both sets and take $q_{\\mathrm{OBI}}$ as the minimum over these $M$ objective values.\n\n3. Compute $c = q_{\\mathrm{URS}} - q_{\\mathrm{OBI}}$.\n\nEdge cases from the test suite:\n- $(1, -10, 10, 2, 2024)$ is a boundary case with the smallest even budget and one dimension. With $l = -u$, OBI evaluates a pair $(x,-x)$ with equal objective values, while URS evaluates two i.i.d. draws; the comparison can slightly favor URS due to independence.\n- Higher dimension $(30, -100, 100, 60, 123)$ with wide bounds and limited budget tests the effect of high dimensionality, where typical distances from the origin are larger and the difference between strategies is driven more by sample count than per-pair opposition benefits.\n- The asymmetric case $(5, 0, 1, 10, 999)$ can showcase a benefit for OBI because reflecting about the midpoint can move points closer to the minimizer at the origin.\n\nOutput:\n- For each of the five test cases, compute $c$ and round to six decimal places.\n- Output a single line with a Python-style list of these five values in order. No additional text may be printed.\n\nThis approach adheres to the core definitions of the objective function, the domain, and Opposition-Based Learning, and it ensures that the comparison under a limited evaluation budget is principled and reproducible. The randomized nature of sampling is fully controlled by fixed seeds, guaranteeing identical outputs across runs. The conclusions align with the geometry of $f(\\mathbf{x}) = \\|\\mathbf{x}\\|^2$ and the symmetry or asymmetry of the domain bounds.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef f_obj(x: np.ndarray) -> np.ndarray:\n    # Computes f(x) = ||x||^2 for a batch of points (rows of x)\n    # Returns a 1D array of objective values.\n    return np.sum(x * x, axis=1)\n\ndef uniform_best_min(d: int, l: float, u: float, M: int, seed: int) -> float:\n    rng = np.random.default_rng(seed)\n    # Sample M points uniformly in [l,u]^d\n    X = rng.uniform(l, u, size=(M, d))\n    vals = f_obj(X)\n    return float(np.min(vals))\n\ndef opposition_best_min(d: int, l: float, u: float, M: int, seed: int) -> float:\n    assert M % 2 == 0, \"M must be even for opposition-based evaluation budget.\"\n    rng = np.random.default_rng(seed)\n    base_count = M // 2\n    X = rng.uniform(l, u, size=(base_count, d))\n    X_opp = (l + u) - X\n    vals_base = f_obj(X)\n    vals_opp = f_obj(X_opp)\n    # Combine both sets of evaluations (total M evaluations)\n    min_val = float(np.min(np.concatenate([vals_base, vals_opp], axis=0)))\n    return min_val\n\ndef run_case(d: int, l: float, u: float, M: int, seed: int) -> float:\n    q_urs = uniform_best_min(d, l, u, M, seed)\n    q_obi = opposition_best_min(d, l, u, M, seed)\n    return q_urs - q_obi  # Positive means OBI better\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is (d, l, u, M, seed)\n    test_cases = [\n        (2, -5.0, 5.0, 100, 42),\n        (10, -1.0, 1.0, 200, 7),\n        (30, -100.0, 100.0, 60, 123),\n        (5, 0.0, 1.0, 10, 999),\n        (1, -10.0, 10.0, 2, 2024),\n    ]\n\n    results = []\n    for d, l, u, M, seed in test_cases:\n        c = run_case(d, l, u, M, seed)\n        results.append(c)\n\n    # Round to exactly six decimal places and format as required.\n    formatted = \"[\" + \",\".join(f\"{v:.6f}\" for v in results) + \"]\"\n    print(formatted)\n\nsolve()\n```"
        },
        {
            "introduction": "Differential Evolution is a stochastic algorithm, but what is the nature of that 'stochasticity,' and does it matter? This advanced practice challenges you to investigate the very heart of the algorithm: its source of randomness. By systematically replacing a standard pseudorandom number generator with a highly structured quasi-random sequence and a deliberately low-quality generator, you will explore DE's sensitivity to the statistical properties of its random inputs, revealing a deeper layer of its behavior. ",
            "id": "3120582",
            "problem": "Consider the unconstrained minimization of two objective functions over a bounded hypercube. Let $d \\in \\mathbb{N}$ be the dimension and define the feasible set as $\\Omega = \\{\\mathbf{x} \\in \\mathbb{R}^d \\mid -5 \\le x_i \\le 5 \\text{ for all } i \\in \\{1,\\ldots,d\\}\\}$. The two objectives are: (i) the smooth convex function $f_1(\\mathbf{x}) = \\sum_{i=1}^d x_i^2$, and (ii) the non-smooth convex function $f_2(\\mathbf{x}) = \\sum_{i=1}^d |x_i|$. The global minimizer of both is $\\mathbf{x}^\\star = \\mathbf{0}$ with optimal value $0$.\n\nImplement the Differential Evolution (DE) algorithm from first principles, using the canonical “DE/rand/1/bin” strategy with constant differential weight and binomial crossover. The algorithm starts from a population $\\{\\mathbf{x}_i^{(0)}\\}_{i=1}^{N_p} \\subset \\Omega$ and iteratively applies, for each target vector $\\mathbf{x}_i^{(t)}$:\n- mutation to generate a donor vector $\\mathbf{v}_i^{(t)}$ by combining distinct indices $r_1, r_2, r_3 \\in \\{1,\\ldots,N_p\\} \\setminus \\{i\\}$ and a fixed differential weight $F \\in (0,2)$ as $\\mathbf{v}_i^{(t)} = \\mathbf{x}_{r_1}^{(t)} + F \\left(\\mathbf{x}_{r_2}^{(t)} - \\mathbf{x}_{r_3}^{(t)}\\right)$, followed by projection to $\\Omega$ via componentwise clipping,\n- binomial crossover to build a trial vector $\\mathbf{u}_i^{(t)}$ using a crossover rate $CR \\in [0,1]$: for each component $j \\in \\{1,\\ldots,d\\}$, set $u_{i,j}^{(t)} = v_{i,j}^{(t)}$ if a uniform variate over $[0,1)$ is no greater than $CR$ or if $j$ equals a uniformly selected forced index $j_{\\text{rand}} \\in \\{1,\\ldots,d\\}$; otherwise set $u_{i,j}^{(t)} = x_{i,j}^{(t)}$,\n- selection to update $\\mathbf{x}_i^{(t+1)}$ as $\\mathbf{u}_i^{(t)}$ if $f(\\mathbf{u}_i^{(t)}) \\le f(\\mathbf{x}_i^{(t)})$, else retain $\\mathbf{x}_i^{(t)}$.\n\nInvestigate sensitivity of Differential Evolution to the quality of the random number generator by replacing the standard independent draws from the Uniform distribution on $[0,1)$, denoted $\\mathcal{U}(0,1)$, with two alternatives:\n- a Sobol low-discrepancy sequence $S$ over $[0,1)$ without scrambling, used in place of every call that requires a uniform variate,\n- a deliberately low-quality Linear Congruential Generator (LCG) defined by $u_{n+1} = (a u_n + c) \\bmod m$ with $m = 2^{16}$, $a = 137$, $c = 187$, and output scaled to $[0,1)$ by $u_{n}/m$.\n\nDesign the implementation so that the only source of randomness in the algorithm is the stream that replaces $\\mathcal{U}(0,1)$. To isolate the effect of the random stream, construct the initial population deterministically and identically across all random-stream choices for a given pair $(d,N_p)$ by sampling $N_p$ points from a fixed Sobol sequence in dimension $d$ (without scrambling) and mapping them linearly to $\\Omega$. Use constant differential weight $F$ and crossover rate $CR$ across all runs unless specified otherwise in the test case.\n\nYour program must run the Differential Evolution algorithm for a fixed evaluation budget (convert evaluations to an integer number of generations by dividing by $N_p$ and taking the floor; ensure at least one generation), then report the best objective value $\\min_i f(\\mathbf{x}_i^{(T)})$ found at termination. No physical units or angle units are involved. All outputs must be real numbers (floating point).\n\nTest suite:\n- Case $1$: random stream is standard $\\mathcal{U}(0,1)$ implemented with the default pseudorandom generator, objective $f_1$, dimension $d=10$, population size $N_p=40$, evaluation budget $E=4000$, differential weight $F=0.8$, crossover rate $CR=0.9$.\n- Case $2$: random stream is Sobol, objective $f_1$, dimension $d=10$, population size $N_p=40$, evaluation budget $E=4000$, $F=0.8$, $CR=0.9$.\n- Case $3$: random stream is low-quality LCG, objective $f_1$, dimension $d=10$, population size $N_p=40$, evaluation budget $E=4000$, $F=0.8$, $CR=0.9$.\n- Case $4$: random stream is standard $\\mathcal{U}(0,1)$, objective $f_2$, dimension $d=10$, population size $N_p=40$, evaluation budget $E=4000$, $F=0.8$, $CR=0.9$.\n- Case $5$: random stream is Sobol, objective $f_2$, dimension $d=10$, population size $N_p=40$, evaluation budget $E=4000$, $F=0.8$, $CR=0.9$.\n- Case $6$: random stream is low-quality LCG, objective $f_2$, dimension $d=10$, population size $N_p=40$, evaluation budget $E=4000$, $F=0.8$, $CR=0.9$.\n- Case $7$: boundary condition with small dimension $d=2$ and small population $N_p=10$, random stream is standard $\\mathcal{U}(0,1)$, objective $f_1$, evaluation budget $E=500$, $F=0.8$, $CR=0.9$.\n- Case $8$: boundary condition with small dimension $d=2$ and small population $N_p=10$, random stream is Sobol, objective $f_1$, evaluation budget $E=500$, $F=0.8$, $CR=0.9$.\n- Case $9$: boundary condition with small dimension $d=2$ and small population $N_p=10$, random stream is low-quality LCG, objective $f_1$, evaluation budget $E=500$, $F=0.8$, $CR=0.9$.\n\nFinal output format:\nYour program should produce a single line of output containing the best objective values for Cases $1$ through $9$ in order, as a comma-separated list enclosed in square brackets (for example, $[v_1,v_2,\\ldots,v_9]$), where each $v_k$ is the best value found for Case $k$ expressed as a floating-point number.",
            "solution": "The user-provided problem statement is judged to be **valid**. It is a well-defined computational task in the field of numerical optimization. The problem is scientifically grounded, self-contained, and formalizable. It specifies the Differential Evolution (DE) algorithm, objective functions, parameter space, termination criteria, and a clear experimental design to investigate the algorithm's sensitivity to the quality of its underlying random number generator. The request is to implement the DE algorithm and three different random number sources from first principles and report the optimization results for a given test suite.\n\nThe solution proceeds by first constructing an abstraction for the random number generator. A `RandomSource` class is designed to encapsulate three distinct streams of random numbers as specified:\n$1$. The standard pseudorandom number generator (PRNG) provided by `numpy.random.default_rng`.\n$2$. A one-dimensional Sobol quasi-random (low-discrepancy) sequence, implemented using `scipy.stats.qmc.Sobol`.\n$3$. A low-quality Linear Congruential Generator (LCG) with the specified parameters: recurrence relation $u_{n+1} = (a u_n + c) \\pmod m$, with modulus $m = 2^{16}$, multiplier $a = 137$, and increment $c = 187$.\n\nTo adhere to the problem's constraint that this random stream be the *only* source of randomness, all stochastic operations within the DE algorithm—selection of parent indices, choice of the forced-crossover index, and the crossover probability checks—are implemented to draw exclusively from a single instance of this `RandomSource` class. A fixed seed is used for all random sources to ensure deterministic and reproducible execution, which is essential for a meaningful comparison.\n\nThe initial population is generated deterministically, as required, to be identical for all test cases that share the same dimension $d$ and population size $N_p$. This is achieved by using a separate, fixed-seed Sobol sequence generator to sample $N_p$ points in the unit hypercube $[0,1)^d$ and then linearly scaling these points to the search domain $\\Omega = [-5, 5]^d$. This isolates the impact of the random stream used during the evolutionary process itself.\n\nThe core algorithm is an implementation of the \"DE/rand/1/bin\" strategy. For each individual $\\mathbf{x}_i$ in the current population (the target vector):\n- **Mutation**: Three other distinct individuals $\\mathbf{x}_{r_1}$, $\\mathbf{x}_{r_2}$, and $\\mathbf{x}_{r_3}$ are chosen randomly from the population. A donor vector $\\mathbf{v}_i$ is created using the formula $\\mathbf{v}_i = \\mathbf{x}_{r_1} + F (\\mathbf{x}_{r_2} - \\mathbf{x}_{r_3})$, where $F$ is the differential weight. The components of $\\mathbf{v}_i$ are then clipped to remain within the search bounds $[-5, 5]$.\n- **Crossover**: A trial vector $\\mathbf{u}_i$ is formed by combining components from the target vector $\\mathbf{x}_i$ and the donor vector $\\mathbf{v}_i$. The crossover is binomial: for each dimension $j$, the component $u_{i,j}$ is taken from the donor $v_{i,j}$ if a random number from the stream is less than or equal to the crossover rate $CR$. To ensure the trial vector is not identical to the target, at least one component is guaranteed to be from the donor vector; this is accomplished by selecting a random index $j_{\\text{rand}}$ that is forced to crossover.\n- **Selection**: The objective function value of the trial vector, $f(\\mathbf{u}_i)$, is computed and compared to that of the target vector, $f(\\mathbf{x}_i)$. If the trial vector is better or equal in fitness ($f(\\mathbf{u}_i) \\le f(\\mathbf{x}_i)$), it replaces the target vector in the next generation's population. Otherwise, the target vector is retained.\n\nThe process is iterated for a number of generations $T$, which is determined by the evaluation budget $E$ and population size $N_p$ as $T = \\lfloor E / N_p \\rfloor$. Finally, the minimum objective function value found in the terminal population, $\\min_i f(\\mathbf{x}_i^{(T)})$, is reported for each test case.\nThe two objective functions are the Sphere function, $f_1(\\mathbf{x}) = \\sum_{i=1}^d x_i^2$, and the L1-norm, $f_2(\\mathbf{x}) = \\sum_{i=1}^d |x_i|$.\n\nThe implementation is structured to run through the nine specified test cases, configuring the dimension, population size, objective function, and random number stream for each, before printing the final results in the required format.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import qmc\n\ndef solve():\n    \"\"\"\n    Solves the problem by implementing Differential Evolution and running it\n    against the specified test suite. All helper classes and functions are\n    defined within this scope to create a self-contained script.\n    \"\"\"\n\n    class RandomSource:\n        \"\"\"\n        An abstraction for different random number streams, ensuring all randomness\n        in the DE algorithm comes from a single, switchable source.\n        \"\"\"\n        def __init__(self, stream_type, seed):\n            self.stream_type = stream_type\n            if stream_type == 'standard':\n                self.rng = np.random.default_rng(seed)\n            elif stream_type == 'sobol':\n                # Sobol sequence is 1-dimensional as it's used for all random calls sequentially.\n                self.rng = qmc.Sobol(d=1, scramble=False, seed=seed)\n            elif stream_type == 'lcg':\n                self.m = 2**16\n                self.a = 137\n                self.c = 187\n                # Initialize state with the seed, ensuring it's within the modulus range.\n                self.lcg_state = int(seed % self.m)\n            else:\n                raise ValueError(f\"Unknown random stream type: {stream_type}\")\n\n        def random(self):\n            \"\"\"Returns a single float in [0, 1).\"\"\"\n            if self.stream_type == 'standard':\n                return self.rng.random()\n            elif self.stream_type == 'sobol':\n                # Sobol generates points; we extract one number at a time from this 1D sequence.\n                return self.rng.random(n=1)[0, 0]\n            elif self.stream_type == 'lcg':\n                self.lcg_state = (self.a * self.lcg_state + self.c) % self.m\n                return self.lcg_state / self.m\n\n        def choice(self, population_size, target_idx, count):\n            \"\"\"\n            Selects 'count' distinct indices from {0, ..., Np-1} \\ {target_idx}\n            using the underlying random stream via Fisher-Yates shuffle.\n            \"\"\"\n            indices = list(range(population_size))\n            indices.pop(target_idx)\n            n = len(indices)\n            for i in range(n - 1, 0, -1):\n                j = int(self.random() * (i + 1))\n                indices[i], indices[j] = indices[j], indices[i]\n            return indices[:count]\n\n        def rand_int(self, high):\n            \"\"\"Returns a random integer in [0, high-1].\"\"\"\n            return int(self.random() * high)\n\n    def f1_sphere(x):\n        \"\"\"The smooth convex function f1(x) = sum(x_i^2).\"\"\"\n        return np.sum(x**2)\n\n    def f2_l1_norm(x):\n        \"\"\"The non-smooth convex function f2(x) = sum(|x_i|).\"\"\"\n        return np.sum(np.abs(x))\n\n    def generate_initial_population(Np, d, bounds_tuple, seed):\n        \"\"\"\n        Generates a deterministic initial population using a Sobol sequence,\n        independent of the main algorithm's random source.\n        \"\"\"\n        sobol_gen = qmc.Sobol(d=d, scramble=False, seed=seed)\n        points_unit = sobol_gen.random(n=Np)\n        low, high = bounds_tuple[0][0], bounds_tuple[1][0]\n        return low + (high - low) * points_unit\n\n    def differential_evolution(objective_func, bounds, Np, F, CR, E, random_source_type, seed):\n        \"\"\"\n        Implements the \"DE/rand/1/bin\" Differential Evolution algorithm.\n        \"\"\"\n        d = len(bounds[0])\n        generations = E // Np\n        if generations < 1:\n            generations = 1\n\n        random_source = RandomSource(stream_type=random_source_type, seed=seed)\n\n        initial_pop_seed = 42\n        pop = generate_initial_population(Np, d, bounds, seed=initial_pop_seed)\n        \n        fitnesses = np.array([objective_func(x) for x in pop])\n        \n        for _ in range(generations):\n            for i in range(Np):\n                # Mutation\n                r1, r2, r3 = random_source.choice(population_size=Np, target_idx=i, count=3)\n                \n                donor_vector = pop[r1] + F * (pop[r2] - pop[r3])\n                donor_vector = np.clip(donor_vector, bounds[0], bounds[1])\n                \n                # Crossover\n                target_vector = pop[i]\n                trial_vector = np.copy(target_vector)\n                j_rand = random_source.rand_int(high=d)\n                \n                for j in range(d):\n                    if random_source.random() <= CR or j == j_rand:\n                        trial_vector[j] = donor_vector[j]\n                \n                # Selection\n                trial_fitness = objective_func(trial_vector)\n                \n                if trial_fitness <= fitnesses[i]:\n                    pop[i] = trial_vector\n                    fitnesses[i] = trial_fitness\n                    \n        return np.min(fitnesses)\n\n    test_cases = [\n        # Case 1\n        {'stream': 'standard', 'func': f1_sphere, 'd': 10, 'Np': 40, 'E': 4000, 'F': 0.8, 'CR': 0.9},\n        # Case 2\n        {'stream': 'sobol', 'func': f1_sphere, 'd': 10, 'Np': 40, 'E': 4000, 'F': 0.8, 'CR': 0.9},\n        # Case 3\n        {'stream': 'lcg', 'func': f1_sphere, 'd': 10, 'Np': 40, 'E': 4000, 'F': 0.8, 'CR': 0.9},\n        # Case 4\n        {'stream': 'standard', 'func': f2_l1_norm, 'd': 10, 'Np': 40, 'E': 4000, 'F': 0.8, 'CR': 0.9},\n        # Case 5\n        {'stream': 'sobol', 'func': f2_l1_norm, 'd': 10, 'Np': 40, 'E': 4000, 'F': 0.8, 'CR': 0.9},\n        # Case 6\n        {'stream': 'lcg', 'func': f2_l1_norm, 'd': 10, 'Np': 40, 'E': 4000, 'F': 0.8, 'CR': 0.9},\n        # Case 7\n        {'stream': 'standard', 'func': f1_sphere, 'd': 2, 'Np': 10, 'E': 500, 'F': 0.8, 'CR': 0.9},\n        # Case 8\n        {'stream': 'sobol', 'func': f1_sphere, 'd': 2, 'Np': 10, 'E': 500, 'F': 0.8, 'CR': 0.9},\n        # Case 9\n        {'stream': 'lcg', 'func': f1_sphere, 'd': 2, 'Np': 10, 'E': 500, 'F': 0.8, 'CR': 0.9},\n    ]\n\n    results = []\n    # Using a single fixed seed makes the entire suite of tests deterministic.\n    main_algorithm_seed = 12345\n\n    for case in test_cases:\n        bounds = (np.full(case['d'], -5.0), np.full(case['d'], 5.0))\n        \n        result = differential_evolution(\n            objective_func=case['func'],\n            bounds=bounds,\n            Np=case['Np'],\n            F=case['F'],\n            CR=case['CR'],\n            E=case['E'],\n            random_source_type=case['stream'],\n            seed=main_algorithm_seed\n        )\n        results.append(result)\n        \n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}