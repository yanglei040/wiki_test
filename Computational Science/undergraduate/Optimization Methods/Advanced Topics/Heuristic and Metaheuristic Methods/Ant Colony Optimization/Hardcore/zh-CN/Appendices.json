{
    "hands_on_practices": [
        {
            "introduction": "信息素挥发是蚁群优化中的一个关键机制，它能帮助算法“忘记”旧的、可能已非最优的路径信息，从而避免过早收敛。这个练习将此机制单独分离出来，让你通过建立一个简单的数学模型来理解信息素随时间衰减的过程。通过这个练习，你将掌握信息素动态变化的基础。",
            "id": "3097760",
            "problem": "考虑蚁群优化 (ACO)，其中边上的信息素强度被建模为一个标量变量 $ \\tau $，它由于挥发和增强而在离散的迭代中发生变化。在此设置中，挥发由一个广泛使用的规则定义，即在每次迭代中，当前信息素的一个固定比例 $ \\rho $ 会挥发，其中 $0  \\rho  1$，而增强是蚂蚁根据所找到解的质量沉积新信息素的增加过程。假设存在一条边，其初始信息素强度为 $ \\tau_0 $，并且在 $ t $ 次迭代期间完全没有增强。\n\n仅使用这些原理，从第一性原理出发，推导出 $ t $ 次迭代后信息素强度 $ \\tau^{(t)} $ 的表达式，该表达式应以 $ \\tau_0 $、$ \\rho $ 和 $ t $ 表示。然后，对于 $ \\tau_0 = 2.0 $、$ \\rho = 0.1 $ 和 $ t = 10 $，计算你的表达式的值。将你的最终答案表示为一个四舍五入到四位有效数字的实数。",
            "solution": "该问题是有效的，因为它科学地基于蚁群优化的原理，提法恰当，有足够的信息来获得唯一解，并以客观、正式的语言表述。其中没有矛盾、歧义或事实性错误。\n\n该问题要求在只有挥发的情况下，推导单条边经过 $t$ 次迭代后的信息素强度 $\\tau^{(t)}$，然后用特定参数对其进行数值计算。\n\n设 $\\tau^{(k)}$ 为第 $k$ 次迭代后边上的信息素强度。在开始时，即任何迭代之前，初始条件为：\n$$\n\\tau^{(0)} = \\tau_0\n$$\n问题陈述，在每次迭代中，当前信息素的一个固定比例 $\\rho$ 会挥发。在第 $k+1$ 次迭代期间挥发的信息素量为 $\\rho \\tau^{(k)}$。因此，剩余的信息素量是迭代开始时的初始量减去挥发的量。更新规则可表述为：\n$$\n\\tau^{(k+1)} = \\tau^{(k)} - \\rho \\tau^{(k)}\n$$\n这可以通过提取 $\\tau^{(k)}$ 来简化：\n$$\n\\tau^{(k+1)} = (1 - \\rho) \\tau^{(k)}\n$$\n这是一个一阶线性齐次递推关系。问题指明没有信息素增强。因此，这个递推关系完全描述了信息素水平在迭代过程中的动态变化。\n\n我们可以通过从初始状态 $\\tau^{(0)} = \\tau_0$ 开始展开来解这个递推关系。\n\n第一次迭代后（$k=1$）：\n$$\n\\tau^{(1)} = (1 - \\rho) \\tau^{(0)} = (1 - \\rho) \\tau_0\n$$\n\n第二次迭代后（$k=2$）：\n$$\n\\tau^{(2)} = (1 - \\rho) \\tau^{(1)} = (1 - \\rho) [(1 - \\rho) \\tau_0] = (1 - \\rho)^2 \\tau_0\n$$\n\n第三次迭代后（$k=3$）：\n$$\n\\tau^{(3)} = (1 - \\rho) \\tau^{(2)} = (1 - \\rho) [(1 - \\rho)^2 \\tau_0] = (1 - \\rho)^3 \\tau_0\n$$\n\n观察此规律，我们可以将公式推广到任意迭代次数 $t$。项 $(1 - \\rho)$ 的指数始终与经过的迭代次数相匹配。因此，$ t $ 次迭代后信息素强度的表达式为：\n$$\n\\tau^{(t)} = (1 - \\rho)^t \\tau_0\n$$\n这是从第一性原理推导出的表达式。\n\n接下来，我们需要用给定的具体值来计算这个表达式：\n初始信息素强度 $\\tau_0 = 2.0$。\n挥发率 $\\rho = 0.1$。\n迭代次数 $t = 10$。\n\n将这些值代入推导出的公式：\n$$\n\\tau^{(10)} = (1 - 0.1)^{10} \\times 2.0\n$$\n$$\n\\tau^{(10)} = (0.9)^{10} \\times 2.0\n$$\n首先，我们计算 $(0.9)^{10}$ 的值：\n$$\n(0.9)^{10} \\approx 0.3486784401\n$$\n现在，我们将此结果乘以初始强度 $\\tau_0 = 2.0$：\n$$\n\\tau^{(10)} \\approx 0.3486784401 \\times 2.0 = 0.6973568802\n$$\n问题要求最终答案表示为四舍五入到四位有效数字的实数。\n计算出的值为 $0.6973568802$。\n第一个有效数字是 $6$。\n四位有效数字是 $6$、$9$、$7$ 和 $3$。\n第五位有效数字是 $5$。根据标准的四舍五入规则，如果下一位数字是 $5$ 或更大，我们对最后一位有效数字进行向上取整。\n因此，数字 $3$ 向上取整为 $4$。\n最终的数值答案是 $0.6974$。",
            "answer": "$$\n\\boxed{0.6974}\n$$"
        },
        {
            "introduction": "蚁群优化的核心在于其概率性决策规则，该规则巧妙地平衡了基于局部信息的“贪婪”选择（启发式信息）和基于群体智慧的“经验”选择（信息素）。这个思想实验构建了一个启发式信息具有误导性的极端场景，让你亲手调节参数 $\\alpha$ 和 $\\beta$ 来观察它们如何影响算法在探索（exploration）和利用（exploitation）之间的权衡。这对于理解如何调优蚁群优化算法至关重要。",
            "id": "3097720",
            "problem": "您将设计并分析蚁群优化 (Ant Colony Optimization, ACO) 在旅行商问题 (Travelling Salesperson Problem, TSP) 环境下的单步决策，以构建一个启发式信息强烈偏向次优长边的病态案例。然后，您将衡量调整信息素和启发式信息的指数（分别表示为 $ \\alpha $ 和 $ \\beta $）是减轻还是加剧了这种偏差。\n\n基本原理：\n- 在蚁群优化 (ACO) 中，位于节点 $ i $ 的蚂蚁选择下一个节点 $ j $ 的概率与信息素强度和启发式分值的乘积成正比，两者的指数分别为 $ \\alpha $ 和 $ \\beta $。给定候选集 $ \\mathcal{N}(i) $，转移概率为\n$$\np_{ij} = \\frac{ \\tau_{ij}^{\\alpha} \\, \\eta_{ij}^{\\beta} }{ \\sum_{k \\in \\mathcal{N}(i)} \\tau_{ik}^{\\alpha} \\, \\eta_{ik}^{\\beta} }.\n$$\n- 对于无向图，信息素矩阵 $ \\tau_{ij} $ 和启发式矩阵 $ \\eta_{ij} $ 是非负且对称的。\n\n构建图和误导性启发式信息：\n- 考虑一个包含节点 $ \\{0,1,2,3,4\\} $ 的完全无向图，其对称距离 $ d_{ij} $ 如下：\n  - $ d_{01} = 100 $,\n  - $ d_{0,2} = d_{0,3} = d_{0,4} = 2 $,\n  - $ d_{12} = d_{13} = d_{14} = 2 $,\n  - $ d_{23} = d_{24} = d_{34} = 2 $,\n  - 对于所有 $ i $，$ d_{ii} = 0 $，且对于所有 $ i \\neq j $，$ d_{ij} = d_{ji} $。\n- 按如下方式定义一个病态的启发式信息 $ \\eta_{ij} $：\n  - 对于除边 $ (0,1) $ 之外的所有边，令 $ \\eta_{ij} = 1 / d_{ij} $。\n  - 对于单㸸边 $ (0,1) $，将其启发式信息覆盖为一个较大的值 $ \\eta_{01} = \\eta_{10} = H_{\\mathrm{bad}} $，其中 $ H_{\\mathrm{bad}} = 10 $。\n- 均匀初始化信息素：对于所有 $ i \\neq j $，有 $ \\tau_{ij} = 1 $。\n\n目标测量量：\n- 考虑一只位于节点 $ 0 $ 的蚂蚁，其可行的下一节点为 $ \\mathcal{N}(0) = \\{1,2,3,4\\} $。对于给定的配对 $ (\\alpha, \\beta) $，计算该蚂蚁下一步选择节点 $ 1 $ 的单步选择概率，即选择次优长边 $ (0,1) $ 的概率：\n$$\nP_{\\mathrm{bad}}(\\alpha,\\beta) \\equiv p_{0,1} = \\frac{ \\tau_{0,1}^{\\alpha} \\, \\eta_{0,1}^{\\beta} }{ \\sum_{j \\in \\{1,2,3,4\\}} \\tau_{0,j}^{\\alpha} \\, \\eta_{0,j}^{\\beta} }.\n$$\n\n测试套件：\n- 为以下 $ (\\alpha,\\beta) $ 对评估 $ P_{\\mathrm{bad}}(\\alpha,\\beta) $，以探究不同方面的影响：\n  1. $ (\\alpha,\\beta) = (1,1) $：标准基线。\n  2. $ (\\alpha,\\beta) = (0.1,1) $：降低信息素影响，同时保持启发式信息影响不变。\n  3. $ (\\alpha,\\beta) = (1,5) $：大幅增加启发式信息影响。\n  4. $ (\\alpha,\\beta) = (1,0) $：忽略启发式信息，边界情况。\n  5. $ (\\alpha,\\beta) = (2,1) $：增加信息素影响，同时保持启发式信息影响不变。\n\n答案要求：\n- 您的程序必须使用上述基本的 ACO 转移概率规则、指定的图、启发式信息和信息素值，为每个测试用例计算 $ P_{\\mathrm{bad}}(\\alpha,\\beta) $。\n- 输出格式：生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表包含与测试套件顺序相同的 5 个结果。每个结果必须是精确到 6 位小数的实数。格式示例： \"[$0.123456$,$0.234567$,$0.345678$,$0.456789$,$0.567890$]\"。\n- 不需要用户输入，也不得使用外部文件。",
            "solution": "我们从蚁群优化 (Ant Colony Optimization, ACO) 关于概率性转移的核心原理出发。对于当前节点 $ i $ 和候选邻居节点 $ \\mathcal{N}(i) $，转移概率为\n$$\np_{ij} = \\frac{ \\tau_{ij}^{\\alpha} \\, \\eta_{ij}^{\\beta} }{ \\sum_{k \\in \\mathcal{N}(i)} \\tau_{ik}^{\\alpha} \\, \\eta_{ik}^{\\beta} }.\n$$\n这源于 ACO 的设计原则，即蚂蚁偏好具有更高信息素强度和更高启发式期望值的边，这种偏好由分别控制对信息素和启发式信息敏感度的指数 $ \\alpha $ 和 $ \\beta $ 调节。\n\n我们通过定义一个图来构建一个病态实例，其中真正的长边 $ (0,1) $ 的距离为 $ d_{01} = 100 $，远大于其他地方长度为 $ d = 2 $ 的短边。在传统的 TSP 启发式信息 $ \\eta_{ij} = 1 / d_{ij} $ 中，长边没有吸引力。为了制造这种病态情况，我们将边 $ (0,1) $ 的启发式信息覆盖为一个较大的误导性值 $ H_{\\mathrm{bad}} = 10 $，同时保持所有其他启发式信息为其常规值。信息素被均匀初始化为 $ \\tau_{ij} = 1 $。\n\n我们评估在节点 $ 0 $ 处的单步决策，其可行邻居为 $ \\{1,2,3,4\\} $。由于对所有 $ j $ 都有 $ \\tau_{0j} = 1 $，转移概率简化为\n$$\np_{0j} = \\frac{ 1^{\\alpha} \\eta_{0j}^{\\beta} }{ \\sum_{k \\in \\{1,2,3,4\\}} 1^{\\alpha} \\eta_{0k}^{\\beta} } \n= \\frac{ \\eta_{0j}^{\\beta} }{ \\sum_{k \\in \\{1,2,3,4\\}} \\eta_{0k}^{\\beta} }.\n$$\n因此，在信息素均匀的初始决策中，$ \\alpha $ 不影响概率；只有 $ \\beta $ 起作用。节点 $ 0 $ 处的具体启发式信息值为：\n- $ \\eta_{0,1} = H_{\\mathrm{bad}} = 10 $,\n- $ \\eta_{0,2} = \\eta_{0,3} = \\eta_{0,4} = 1 / 2 = 0.5 $.\n\n因此，\n$$\nP_{\\mathrm{bad}}(\\alpha,\\beta) = p_{0,1} = \\frac{ (10)^{\\beta} }{ (10)^{\\beta} + 3 \\cdot (0.5)^{\\beta} }.\n$$\n现在我们为测试套件计算这个值：\n\n1. 情况 $ (\\alpha,\\beta) = (1,1) $：\n$$\nP_{\\mathrm{bad}} = \\frac{ 10^{1} }{ 10^{1} + 3 \\cdot 0.5^{1} } = \\frac{ 10 }{ 10 + 1.5 } = \\frac{ 20 }{ 23 } \\approx 0.869565.\n$$\n\n2. 情况 $ (\\alpha,\\beta) = (0.1,1) $：\n由于 $ \\tau_{0j} $ 是均匀的，$ \\alpha $ 的影响被抵消。因此这与情况 1 相等：\n$$\nP_{\\mathrm{bad}} \\approx 0.869565.\n$$\n\n3. 情况 $ (\\alpha,\\beta) = (1,5) $：\n$$\nP_{\\mathrm{bad}} = \\frac{ 10^{5} }{ 10^{5} + 3 \\cdot 0.5^{5} } \n= \\frac{ 100000 }{ 100000 + 3 \\cdot \\frac{1}{32} } \n= \\frac{ 100000 }{ 100000 + 0.09375 } \n\\approx 0.999999.\n$$\n\n4. 情况 $ (\\alpha,\\beta) = (1,0) $：\n这里启发式信息被忽略，因此所有邻居节点的选择概率相等：\n$$\nP_{\\mathrm{bad}} = \\frac{ 1 }{ 1 + 3 \\cdot 1 } = \\frac{ 1 }{ 4 } = 0.25.\n$$\n\n5. 情况 $ (\\alpha,\\beta) = (2,1) $：\n同样，由于 $ \\tau_{0j} $ 是均匀的，所以 $ \\alpha $ 不影响初始决策：\n$$\nP_{\\mathrm{bad}} \\approx 0.869565.\n$$\n\n关于偏差校正的解释：\n- 在信息素均匀的情况下，将 $ \\alpha $ 从 $ 1 $ 减小到 $ 0.1 $ 并不会改变 $ P_{\\mathrm{bad}} $，因此它在初始决策时不能校正偏差。\n- 将 $ \\beta $ 从 $ 1 $ 增加到 $ 5 $ 会使 $ P_{\\mathrm{bad}} $ 急剧增加并趋近于 $ 1 $，因此它加剧了由误导性启发式信息引入的偏差。\n- 设置 $ \\beta = 0 $ 会完全移除启发式信息的影响，并产生相等的概率，这在这个单步场景中消除了偏差。\n\n程序将以数值方式计算这些概率，并按照要求的单行格式打印它们，每个值都精确到 6 位小数，如下所示\n$$\n[\\;0.869565,\\;0.869565,\\;0.999999,\\;0.250000,\\;0.869565\\;].\n$$",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_p_bad(alpha: float, beta: float) - float:\n    \"\"\"\n    Compute P_bad(alpha, beta) = probability of choosing the misleading long edge (0-1)\n    at the first decision from node 0, given uniform pheromone and pathological heuristic.\n    \"\"\"\n    # Uniform pheromone on all edges\n    tau = {\n        1: 1.0,\n        2: 1.0,\n        3: 1.0,\n        4: 1.0,\n    }\n    # Pathological heuristic: override (0,1) with a large value; others use 1/d with d=2\n    H_bad = 10.0\n    eta = {\n        1: H_bad,\n        2: 1.0 / 2.0,\n        3: 1.0 / 2.0,\n        4: 1.0 / 2.0,\n    }\n\n    # Candidate neighbors from node 0\n    neighbors = [1, 2, 3, 4]\n\n    # Compute numerator for j=1\n    num = (tau[1] ** alpha) * (eta[1] ** beta)\n\n    # Compute denominator over all neighbors\n    denom = 0.0\n    for j in neighbors:\n        denom += (tau[j] ** alpha) * (eta[j] ** beta)\n\n    # Guard against numerical issues (should not occur with given values)\n    if denom == 0.0:\n        return 0.0\n\n    return num / denom\n\ndef solve():\n    # Define the test cases from the problem statement: (alpha, beta)\n    test_cases = [\n        (1.0, 1.0),    # baseline\n        (0.1, 1.0),    # decreased alpha\n        (1.0, 5.0),    # increased beta\n        (1.0, 0.0),    # heuristic ignored\n        (2.0, 1.0),    # increased alpha\n    ]\n\n    results = []\n    for alpha, beta in test_cases:\n        p_bad = compute_p_bad(alpha, beta)\n        # Round to exactly 6 decimal places as required\n        results.append(f\"{p_bad:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}