{
    "hands_on_practices": [
        {
            "introduction": "掌握粒子群优化 (PSO) 的第一步是理解其核心驱动机制——速度更新方程。本练习将这个关键方程分解为惯性、个体认知和社会学习三个部分，让你亲手计算这些不同力量如何共同引导粒子的飞行轨迹。通过这个基础计算，你将为后续构建完整的PSO算法打下坚实的基础。",
            "id": "2166499",
            "problem": "一架自主无人机是一个机群的一部分，正在一个广阔的开放场地中搜索最大强度的无线电信号位置，该场地被建模为一个二维笛卡尔平面。搜索过程由粒子群优化 (PSO) 算法引导。在每个时间步，每架无人机根据其当前速度、自身找到的最佳位置以及整个机群中任何无人机找到的最佳位置来更新其速度。\n\n在时间步 $t+1$ 时，单个粒子（无人机）的速度更新由以下方程给出：\n$$ \\vec{v}(t+1) = \\omega \\vec{v}(t) + c_1 r_1 (\\vec{p} - \\vec{x}(t)) + c_2 r_2 (\\vec{g} - \\vec{x}(t)) $$\n其中：\n- $\\vec{v}(t)$ 是无人机的当前速度矢量。\n- $\\vec{x}(t)$ 是无人机的当前位置矢量。\n- $\\vec{p}$ 是无人机迄今为止找到的个体最佳位置。\n- $\\vec{g}$ 是整个机群迄今为止找到的全局最佳位置。\n- $\\omega$ 是惯性权重，控制先前速度的影响。\n- $c_1$ 和 $c_2$ 分别是认知系数和社会系数，用于衡量个体最佳位置和全局最佳位置的影响。\n- $r_1$ 和 $r_2$ 是在 $[0, 1]$ 上均匀分布的随机数。\n\n考虑在特定时间步 $t$ 的一架特定无人机。该无人机的状态和机群参数如下：\n- 当前位置：$\\vec{x}(t) = \\begin{pmatrix} 8.0  14.0 \\end{pmatrix}$\n- 当前速度：$\\vec{v}(t) = \\begin{pmatrix} -1.0  2.0 \\end{pmatrix}$\n- 个体最佳位置：$\\vec{p} = \\begin{pmatrix} 10.0  12.0 \\end{pmatrix}$\n- 全局最佳位置：$\\vec{g} = \\begin{pmatrix} 11.0  10.0 \\end{pmatrix}$\n- 惯性权重：$\\omega = 0.7$\n- 认知系数：$c_1 = 1.5$\n- 社会系数：$c_2 = 1.5$\n对于此特定更新步骤，生成的随机数为 $r_1 = 0.4$ 和 $r_2 = 0.9$。\n\n计算无人机的新速度矢量 $\\vec{v}(t+1)$。所有位置以米为单位，速度以米/秒 (m/s) 为单位。将您的答案表示为一个2元素行矩阵 $[v_x, v_y]$，单位为 m/s。将矢量的每个分量四舍五入到三位有效数字。",
            "solution": "我们应用 PSO 速度更新规则\n$$\\vec{v}(t+1)=\\omega \\vec{v}(t)+c_{1}r_{1}\\left(\\vec{p}-\\vec{x}(t)\\right)+c_{2}r_{2}\\left(\\vec{g}-\\vec{x}(t)\\right).$$\n计算位移矢量：\n$$\\vec{p}-\\vec{x}(t)=\\begin{pmatrix}10.0-8.0 \\\\ 12.0-14.0\\end{pmatrix}=\\begin{pmatrix}2 \\\\ -2\\end{pmatrix},\\quad \\vec{g}-\\vec{x}(t)=\\begin{pmatrix}11.0-8.0 \\\\ 10.0-14.0\\end{pmatrix}=\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}.$$\n计算每一项：\n$$\\omega \\vec{v}(t)=0.7\\begin{pmatrix}-1.0 \\\\ 2.0\\end{pmatrix}=\\begin{pmatrix}-0.7 \\\\ 1.4\\end{pmatrix},$$\n$$c_{1}r_{1}\\left(\\vec{p}-\\vec{x}(t)\\right)=1.5\\cdot 0.4\\begin{pmatrix}2 \\\\ -2\\end{pmatrix}=0.6\\begin{pmatrix}2 \\\\ -2\\end{pmatrix}=\\begin{pmatrix}1.2 \\\\ -1.2\\end{pmatrix},$$\n$$c_{2}r_{2}\\left(\\vec{g}-\\vec{x}(t)\\right)=1.5\\cdot 0.9\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}=1.35\\begin{pmatrix}3 \\\\ -4\\end{pmatrix}=\\begin{pmatrix}4.05 \\\\ -5.4\\end{pmatrix}.$$\n将各项贡献相加得到\n$$\\vec{v}(t+1)=\\begin{pmatrix}-0.7 \\\\ 1.4\\end{pmatrix}+\\begin{pmatrix}1.2 \\\\ -1.2\\end{pmatrix}+\\begin{pmatrix}4.05 \\\\ -5.4\\end{pmatrix}=\\begin{pmatrix}4.55 \\\\ -5.2\\end{pmatrix}.$$\n将每个分量四舍五入到三位有效数字，得到\n$$\\vec{v}(t+1)=\\begin{pmatrix}4.55 \\\\ -5.20\\end{pmatrix}.$$\n表示为行矩阵，结果为 $\\begin{pmatrix}4.55  -5.20\\end{pmatrix}$，单位为米/秒。",
            "answer": "$$\\boxed{\\begin{pmatrix}4.55  -5.20\\end{pmatrix}}$$"
        },
        {
            "introduction": "从单步计算到完整实现，是掌握任何算法的必经之路。在实践中，纯粹的PSO更新规则可能会导致粒子速度过大，出现“种群爆炸”而无法收敛。这个动手编程练习将引导你探索一种关键的稳定性机制——速度限制 (velocity clamping)。通过实现并测试不同的速度上限 $v^{\\max}$，你将深入理解如何在全局探索和局部开采之间取得微妙的平衡。",
            "id": "3161041",
            "problem": "您需要研究粒子群优化（PSO）中速度限制（velocity clamping）的影响。粒子群优化（PSO）是一种基于种群的随机搜索方法，它通过使用受个体和社会信息影响的速度来迭代更新粒子的位置。考虑一个由 $N$ 个粒子组成的粒子群，每个粒子都有一个位置 $x_j \\in \\mathbb{R}^d$ 和一个速度 $v_j \\in \\mathbb{R}^d$，其中 $j \\in \\{1,\\dots,N\\}$ 是粒子的索引，$d$ 是维度。令 $p_j$ 表示粒子 $j$ 迄今为止找到的个体最佳位置，令 $g$ 表示整个粒子群找到的全局最佳位置。速度限制在每次迭代中对每个分量强制施加一个边界 $\\lVert v_j \\rVert_{\\infty} \\le v^{\\max}$，这意味着对于所有 $k \\in \\{1,\\dots,d\\}$，每个分量都满足 $\\lvert v_{j,k} \\rvert \\le v^{\\max}$。\n\n基本原理。从离散时间迭代优化方法的核心定义和随机搜索的成熟理论出发：\n- 迭代方法使用一个结合了前一状态的惯性和与误差信号成比例的修正反馈的规则来更新状态。在 PSO 中，惯性是先前的速度，修正信号是与 $p_j$ 和 $g$ 的差异，并由随机系数进行调节。\n- 目标函数是实值、连续且有下界的。您将使用球函数 $f(x) = \\sum_{k=1}^d x_k^2$，这是一个凸函数，在 $x^\\star = 0$ 处有唯一的全局最小值，且 $f(x^\\star) = 0$。\n\n您的任务：\n1. 基于上述基本原理（不使用简化公式），推导出体现了惯性以及对 $p_j$ 和 $g$ 的修正反馈的离散时间更新方程，并引入将速度的每个分量限制在 $v^{\\max}$ 内的速度限制算子。定性和定量地解释速度限制如何影响在有界域上对 $f(x)$ 最小值点的收敛速度。\n2. 实现一个 PSO 变体，使用推导出的速度限制来最小化函数 $f(x) = \\sum_{k=1}^d x_k^2$ 在空间 $[-5,5]^d$ 上的值。对所有测试用例使用以下固定的超参数：维度 $d = 5$，粒子群规模 $N = 25$，惯性权重 $w = 0.7$，迭代次数 $T = 100$，并使用位置限制以始终将 $x_j$ 保持在 $[-5,5]^d$ 内。在每次迭代中，为所有粒子 $j$ 和维度 $k$ 重新抽取独立的随机变量 $r_{1,j,k}, r_{2,j,k} \\sim \\mathcal{U}(0,1)$，其中 $\\mathcal{U}(0,1)$ 表示在 $[0,1]$ 上的均匀分布。\n3. 为保证可复现性，请使用确定性的伪随机种子。对于索引为 $i$（从 $i=0$ 开始）的测试用例和索引为 $r \\in \\{0,\\dots,R-1\\}$ 的重复实验，使用 $s = 1000 + 100 \\cdot i + r$ 为随机数生成器设置种子，并为每个测试用例运行 $R = 5$ 次独立的重复实验。在 $[-5,5]^d$ 内均匀初始化位置 $x_j$，将初始个体最佳位置 $p_j$ 设置为这些位置，相应地初始化全局最佳位置 $g$，并在 $[-v^{\\max}, v^{\\max}]^d$ 内均匀初始化速度 $v_j$。\n4. 对于每个测试用例，在 $T$ 次迭代后，计算 $R$ 次重复实验的平均最佳发现值 $\\bar{f}(g)$，其中 $f(g)$ 是在每次重复实验的最终全局最佳位置上计算的。您的程序必须输出一行，其中包含所有测试用例的这些平均值，格式为用方括号括起来的逗号分隔列表，例如 $[a_1,a_2,\\dots,a_m]$，其中每个 $a_i$ 是一个浮点数。\n\n测试套件。评估以下 $m = 6$ 个参数集，每个参数集以 $(c_1,c_2,v^{\\max})$ 的形式给出：\n- 情况 0：$(c_1,c_2,v^{\\max}) = (2.0, 2.0, 0.0)$，无移动的边界情况。\n- 情况 1：$(c_1,c_2,v^{\\max}) = (2.0, 2.0, 0.5)$，具有对称认知和社会项的中等限制。\n- 情况 2：$(c_1,c_2,v^{\\max}) = (2.0, 2.0, 2.0)$，具有对称认知和社会项的较大限制。\n- 情况 3：$(c_1,c_2,v^{\\max}) = (3.0, 0.5, 1.0)$，认知主导模式，中等限制。\n- 情况 4：$(c_1,c_2,v^{\\max}) = (0.5, 3.0, 1.0)$，社会主导模式，中等限制。\n- 情况 5：$(c_1,c_2,v^{\\max}) = (1.0, 1.0, 1.0)$，弱对称影响。\n\n答案规格。对于每种情况，计算出的平均最佳发现值 $\\bar{f}(g)$ 是一个浮点数。您的程序应生成单行输出，其中包含结果，格式为用方括号括起来的逗号分隔列表（例如，$[r_0,r_1,r_2,r_3,r_4,r_5]$）。不允许有其他输出。",
            "solution": "该问题要求推导和实现一种带有速度限制的粒子群优化（PSO）算法，并分析该限制对收敛性的影响。验证证实了该问题具有科学依据、提法明确且内容完整。因此，我们可以着手进行严谨的求解。\n\n### 1. PSO 更新方程的推导\n\n我们从离散时间迭代优化方法的基本原理入手。在离散时间步 $t$，粒子群中每个粒子 $j$ 的状态由其位置向量 $x_j(t) \\in \\mathbb{R}^d$ 和速度向量 $v_j(t) \\in \\mathbb{R}^d$ 描述。目标是迭代更新这些状态，以找到目标函数 $f(x)$ 的最小值。\n\n**速度更新规则：**\n问题指出，速度的更新规则必须结合惯性和修正反馈。下一个时间步的速度 $v_j(t+1)$ 由三个分量构成：\n\n1.  **惯性：** 粒子倾向于沿其当前方向继续运动。这被建模为其先前速度的一部分，由惯性权重 $w$ 控制。惯性项为 $w v_j(t)$。\n\n2.  **认知修正反馈：** 每个粒子被引向其自身找到的最佳位置，表示为 $p_j(t)$。这代表了粒子的个体经验。“误差信号”是向量差 $(p_j(t) - x_j(t))$。修正项与该差异成正比，由认知加速系数 $c_1$ 和一个随机元素 $r_{1,j}(t)$ 调节以引入探索。该项为 $c_1 r_{1,j}(t) \\odot (p_j(t) - x_j(t))$，其中 $\\odot$ 表示逐元素相乘，而 $r_{1,j}(t)$ 的每个分量都从均匀分布 $\\mathcal{U}(0,1)$ 中抽取。\n\n3.  **社会修正反馈：** 每个粒子也被引向整个粒子群中任何粒子找到的最佳位置，表示为 $g(t)$。这代表了粒子群的集体经验。误差信号是 $(g(t) - x_j(t))$。修正项与此成正比，由社会加速系数 $c_2$ 和一个随机元素 $r_{2,j}(t) \\sim \\mathcal{U}(0,1)$ 调节。该项为 $c_2 r_{2,j}(t) \\odot (g(t) - x_j(t))$。\n\n将这三个分量组合起来，得到限制前的速度向量方程，我们表示为 $v'_j(t+1)$:\n$$\nv'_j(t+1) = w v_j(t) + c_1 r_{1,j}(t) \\odot (p_j(t) - x_j(t)) + c_2 r_{2,j}(t) \\odot (g(t) - x_j(t))\n$$\n对于每个维度 $k \\in \\{1, \\dots, d\\}$ 的分量形式为：\n$$\nv'_{j,k}(t+1) = w v_{j,k}(t) + c_1 r_{1,j,k}(t) (p_{j,k}(t) - x_{j,k}(t)) + c_2 r_{2,j,k}(t) (g_k(t) - x_{j,k}(t))\n$$\n\n**速度限制：**\n问题要求每个速度分量的大小都受 $v^{\\max}$ 限制，即 $|v_{j,k}| \\le v^{\\max}$。我们定义一个限制算子 $C_{v^{\\max}}(\\cdot)$，它应用此约束。对于一个标量值 $u$，该算子为：\n$$\nC_{v^{\\max}}(u) = \\text{sign}(u) \\cdot \\min(|u|, v^{\\max}) = \\max(-v^{\\max}, \\min(u, v^{\\max}))\n$$\n该算子逐分量地应用于限制前的速度向量 $v'_j(t+1)$，以获得最终速度 $v_j(t+1)$:\n$$\nv_{j,k}(t+1) = C_{v^{\\max}}(v'_{j,k}(t+1)) \\quad \\forall k \\in \\{1, \\dots, d\\}\n$$\n\n**位置更新与限制：**\n根据离散时间系统中速度的基本定义，使用新计算出的速度更新粒子的位置：\n$$\nx_j(t+1) = x_j(t) + v_j(t+1)\n$$\n为确保粒子保持在搜索域内（此处指定为 $[-5, 5]^d$），在更新后应用位置限制机制。对于每个分量 $k$：\n$$\nx_{j,k}(t+1) \\leftarrow \\max(-5, \\min(x_{j,k}(t+1), 5))\n$$\n\n**最佳位置更新：**\n更新粒子位置后，评估其新的适应度值 $f(x_j(t+1))$。个体最佳和全局最佳位置更新如下：\n-   **个体最佳：** 如果 $f(x_j(t+1))  f(p_j(t))$，则 $p_j(t+1) = x_j(t+1)$。否则，$p_j(t+1) = p_j(t)$。\n-   **全局最佳：** 全局最佳位置 $g(t+1)$ 从所有个体最佳位置的集合 $\\{p_j(t+1) \\mid j=1, \\dots, N\\}$ 中选出，使得 $f(g(t+1)) = \\min_{j} f(p_j(t+1))$。\n\n### 2. 速度限制分析\n\n**定性分析：**\n速度限制是控制粒子群动态的关键机制。\n-   **稳定性：** 如果没有限制，粒子的速度可能会无限制地增加，这种现象被称为“粒子群爆炸”。如果参数 $w, c_1, c_2$ 产生不稳定的动态，就会发生这种情况。一个爆炸的粒子群其粒子移动速度极快，以至于它们会“飞越”搜索空间中的有利区域，从而严重损害或完全阻止收敛。限制对粒子在一次迭代中可以移动的步长施加了硬性限制，从而确保搜索过程的稳定性。\n-   **探索与利用的权衡：** $v^{\\max}$ 的值直接调节了全局探索和局部利用之间的平衡。\n    -   一个**较小**的 $v^{\\max}$ 会迫使粒子采取小步长。这增强了当前位置周围的局部搜索（利用），但如果最优解很远，可能会减慢收敛速度。它还增加了粒子群过早陷入局部最小值的风险，因为粒子可能缺乏逃逸的动量。\n    -   一个**较大**的 $v^{\\max}$ 允许粒子快速穿越搜索空间，促进了全局搜索（探索）。然而，如果 $v^{\\max}$太大，限制将变得无效，从而重新带来不稳定和过冲的风险。\n-   **边界情况 ($v^{\\max} = 0.0$)：** 这是一个退化情况。规范要求在 $[-v^{\\max}, v^{\\max}]^d$ 内均匀初始化速度，对于 $v^{\\max}=0.0$ 这意味着所有初始速度 $v_j(0)$ 都为 $0$。在随后的每次迭代中，速度更新会计算一个非零的 $v'_{j,k}(t+1)$（除非粒子已经位于 $p_j=g=x_j$ 的点上），但限制算子 $C_{0.0}(\\cdot)$ 会立即将其强制变回 $0$。因此，对于所有 $t>0$，$v_j(t)=0$。最终，$x_j(t+1) = x_j(t) + 0 = x_j(t)$。粒子永远不会离开它们的初始位置。最终的全局最佳解将仅仅是在初始随机生成的种群中找到的最佳解。\n\n**定量分析：**\n通过考虑粒子的步长，可以分析速度限制对球函数 $f(x) = \\sum_{k=1}^d x_k^2$ 收敛速度的影响。\n-   **远离最优解时：** 当粒子 $j$ 远离位于 $x^\\star = 0$ 的全局最小值时，项 $(p_{j,k} - x_{j,k})$ 和 $(g_k - x_{j,k})$ 可能会很大。这导致未限制的速度 $v'_{j,k}$ 的量值很大。如果 $|v'_{j,k}| > v^{\\max}$，限制就会被激活，将 $|v_{j,k}|$ 设置为 $v^{\\max}$。在此区域，粒子向最优解的移动不受粒子群动态的限制，而是受硬性限制 $v^{\\max}$ 的限制。收敛速度近似为线性的，因为粒子每次迭代移动的距离接近一个常数，欧几里得距离最多为 $\\sqrt{d} \\cdot v^{\\max}$。一个较大的 $v^{\\max}$（例如，情况2 vs. 情况1）将允许更快地接近全局最优解的吸引盆。\n-   **接近最优解时：** 当粒子接近最优解时，其位置 $x_j$、其个体最佳 $p_j$ 和全局最佳 $g$ 彼此接近，并且也接近 $x^\\star=0$。差异 $(p_j - x_j)$ 和 $(g - x_j)$ 变小。因此，计算出的速度 $v'_j$ 的量值自然会减小。最终，对于所有分量，都有 $|v'_{j,k}| \\le v^{\\max}$，限制不再激活。在此阶段，收敛由系数 $w, c_1, c_2$ 所描述的线性系统的特征动态所支配。这些参数的选择决定了最终的收敛速度以及粒子是会稳定地收敛到最优解还是在其周围振荡。\n-   **认知与社会主导（情况3 vs. 情况4）：** 对于凸的、单峰的球函数，强大的社会拉力（$c_2 > c_1$，情况4）通常是有益的。它鼓励整个粒子群迅速收敛到迄今为止找到的单一最佳位置。强大的认知拉力（$c_1 > c_2$，情况3）鼓励粒子在自己的最佳位置周围进行探索，从而促进多样性。虽然这对于多峰问题很有用，但对于像球函数这样的简单单峰函数，它可能会减慢收敛速度，因为粒子群不会那么快地聚集。因此，我们预期情况4会比情况3产生更好（更低）的最终适应度值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the PSO problem for a suite of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (c1, c2, v_max)\n    test_cases = [\n        (2.0, 2.0, 0.0),  # Case 0\n        (2.0, 2.0, 0.5),  # Case 1\n        (2.0, 2.0, 2.0),  # Case 2\n        (3.0, 0.5, 1.0),  # Case 3\n        (0.5, 3.0, 1.0),  # Case 4\n        (1.0, 1.0, 1.0),  # Case 5\n    ]\n\n    # Fixed hyperparameters\n    d = 5          # Dimension\n    N = 25         # Swarm size\n    w = 0.7        # Inertia weight\n    T = 100        # Number of iterations\n    R = 5          # Number of replicates\n    x_min, x_max = -5.0, 5.0 # Search space bounds\n\n    # Objective function (Sphere function)\n    def f(x):\n        # x is an (N, d) array of positions\n        return np.sum(x**2, axis=1)\n\n    results = []\n    # Loop through each test case\n    for i, (c1, c2, v_max) in enumerate(test_cases):\n        replicate_best_vals = []\n        \n        # Run R independent replicates for each test case\n        for r in range(R):\n            # Seed the random number generator for reproducibility\n            seed = 1000 + 100 * i + r\n            rng = np.random.default_rng(seed)\n\n            # --- Initialization ---\n            # Initialize positions uniformly in the search space\n            positions = rng.uniform(x_min, x_max, size=(N, d))\n            \n            # Initialize velocities uniformly in [-v_max, v_max]\n            velocities = rng.uniform(-v_max, v_max, size=(N, d))\n            \n            # Initialize personal best positions and values\n            pbest_positions = np.copy(positions)\n            pbest_values = f(pbest_positions)\n            \n            # Initialize global best position and value\n            min_idx = np.argmin(pbest_values)\n            gbest_position = np.copy(pbest_positions[min_idx])\n            gbest_value = pbest_values[min_idx]\n\n            # --- Iterations ---\n            for _ in range(T):\n                # Generate random coefficients for velocity update\n                r1 = rng.random(size=(N, d))\n                r2 = rng.random(size=(N, d))\n                \n                # Update velocities (with inertia, cognitive, and social components)\n                # The gbest_position (1,d) is broadcasted for the subtraction\n                new_velocities = (w * velocities +\n                                  c1 * r1 * (pbest_positions - positions) +\n                                  c2 * r2 * (gbest_position - positions))\n                \n                # Apply velocity clamping\n                velocities = np.clip(new_velocities, -v_max, v_max)\n                \n                # Update positions\n                positions = positions + velocities\n                \n                # Apply position clamping (containment in search space)\n                positions = np.clip(positions, x_min, x_max)\n                \n                # Evaluate new positions\n                current_values = f(positions)\n                \n                # Update personal bests\n                improvement_mask = current_values  pbest_values\n                pbest_positions[improvement_mask] = positions[improvement_mask]\n                pbest_values[improvement_mask] = current_values[improvement_mask]\n                \n                # Update global best\n                min_pbest_idx = np.argmin(pbest_values)\n                if pbest_values[min_pbest_idx]  gbest_value:\n                    gbest_value = pbest_values[min_pbest_idx]\n                    gbest_position = np.copy(pbest_positions[min_pbest_idx])\n            \n            # Store the final global best value for this replicate\n            replicate_best_vals.append(gbest_value)\n            \n        # Compute the average best-found value across replicates for the current case\n        avg_best_value = np.mean(replicate_best_vals)\n        results.append(avg_best_value)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "元启发式算法（如PSO）的真正威力在于其强大的适应性。这个高级实践将挑战你将PSO的核心思想从其原生的连续域扩展到经典的离散优化问题——0-1背包问题。这需要对“速度”和“位置”进行创造性的重新诠释，将速度理解为影响决策变量（是否选择一个物品）的概率。完成这个练习后，你将体会到如何将PSO的灵感应用于更广泛的优化场景中。",
            "id": "3161067",
            "problem": "要求您从粒子群优化（PSO）的第一性原理出发，为 $0$-$1$ 背包问题设计并实现一个二进制粒子群优化（PSO）算法。在连续域中，PSO 维持一个由具有位置和速度的粒子组成的种群，并通过惯性以及对个体最佳和全局最佳的吸引力来使其演化。在位置必须是二进制的离散域中，将速度重新解释为控制比特位变化的随机趋势，并推导出一个从速度到比特位翻转概率的概率映射。实现所得算法，并将其应用于一组指定的背包问题实例。\n\n出发点和要求：\n- 从每个粒子 $i$ 具有一个位置向量 $x_i \\in \\{0,1\\}^d$ 和一个速度向量 $v_i \\in \\mathbb{R}^d$ 的原理开始。更新必须由一个惯性项以及对粒子的个体最佳和种群的全局最佳的吸引力来控制。更新必须通过在 $\\left[0,1\\right]$ 区间内的独立均匀随机变量对每个粒子和每个维度进行随机化。\n- 在离散设置中，将速度重新解释为决定比特位翻转概率的参数。基于经过充分测试的数学函数，选择一个从 $\\mathbb{R}$ 到 $\\left(0,1\\right)$ 的平滑、单调映射，并推导出一个映射 $p_j$，使得翻转比特位 $j$ 的概率为 $p_j$。然后通过以概率 $p_j$ 翻转 $x_{ij}$ 或保持 $x_{ij}$ 不变来更新每个比特位。确保您的映射是无量纲的，并且随着 $\\lvert v_{ij} \\rvert$ 的增加而适当地饱和。\n- 对于 $0$-$1$ 背包问题目标，设有物品重量 $w_j$ 和价值 $u_j$，以及容量 $C$。可行目标为 $\\sum_{j=1}^{d} u_j x_j$，约束条件为 $\\sum_{j=1}^{d} w_j x_j \\le C$。为了在搜索过程中处理不可行解，使用一个惩罚目标函数，该函数减去一个与容量超出量的平方成正比的惩罚项。具体来说，对于一个候选解 $x$，计算惩罚目标 $F(x) = \\sum_{j=1}^{d} u_j x_j - \\lambda \\cdot \\max\\!\\left(0, \\sum_{j=1}^{d} w_j x_j - C\\right)^2$，其中 $\\lambda$ 是一个正的惩罚系数。您的程序最终必须返回发现的最佳可行目标值（而非惩罚值）。如果在迭代预算内没有发现可行解，则返回 $0$。\n- 通过使用一个在所有测试案例中共享的伪随机数生成器种子 $42$，以及在每次迭代中为每个粒子和维度进行独立的均匀随机抽样，来固定所有随机性。\n- 使用 PSO 超参数：惯性权重 $w = 0.7$，认知系数 $c_1 = 1.6$，社会系数 $c_2 = 1.6$，速度限制 $v_{\\min} = -4$ 和 $v_{\\max} = 4$，种群规模 $N = 60$ 个粒子，迭代预算 $T = 300$，以及惩罚系数 $\\lambda = 100$。\n\n测试套件：\n在以下四个背包实例上实现您的算法。在所有情况下，$d$ 等于物品列表的长度。\n1. 案例 A (通用，中等规模):\n   - 重量 $[2,3,5,7,1,4,1]$\n   - 价值 $[10,5,15,7,6,18,3]$\n   - 容量 $15$\n2. 案例 B (边界：容量非常小):\n   - 重量 $[5,8,3]$\n   - 价值 $[9,11,4]$\n   - 容量 $4$\n3. 案例 C (边界：容量大于总重量):\n   - 重量 $[1,1,1,1]$\n   - 价值 $[2,2,2,2]$\n   - 容量 $10$\n4. 案例 D (边缘情况：多个价值相等的最佳子集):\n   - 重量 $[3,2,2,1]$\n   - 价值 $[5,3,3,2]$\n   - 容量 $5$\n\n实现细节和评估：\n- 将位置表示为 $0$-$1$ 向量，速度表示为实数向量。使用惯性和对个体最佳及全局最佳的随机吸引力来按维度更新速度。每次更新后将速度裁剪到 $[v_{\\min}, v_{\\max}]$ 范围内。\n- 推导并使用一个从速度到比特位翻转概率的概率映射，该映射应是平滑的、关于速度单调的，并且将 $\\mathbb{R}$ 映射到 $(0,1)$；然后相应地执行随机比特位翻转。\n- 评估惩罚目标 $F(x)$ 以更新个体最佳和全局最佳。在每次迭代中，同时跟踪到目前为止观察到的最佳可行目标 $\\sum u_j x_j$；这是每个测试案例需要报告的数值。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含四个案例的最佳可行目标值，格式为方括号内由逗号分隔的列表，例如 $[v_A,v_B,v_C,v_D]$，其中 $v_A$、$v_B$、$v_C$ 和 $v_D$ 是整数。输出必须只有一行，并采用这种方括号逗号分隔的格式。",
            "solution": "所述问题是有效的，因为它描述了优化方法领域内一个明确定义的计算任务。它要求为 $0$-$1$ 背包问题设计和实现一个二进制粒子群优化（BPSO）算法。所有必要的参数和测试案例都已提供。任务的一个关键部分是推导出一个从粒子的连续速度到其位置的离散、二进制变化的映射。这个推导过程需要仔细考虑，以确保最终算法在动态上是合理的。\n\n我们从粒子群优化（PSO）的第一性原理开始。一个由 $N$ 个粒子组成的种群在一个 $d$ 维搜索空间中进行探索。对于有 $d$ 个物品的 $0$-$1$ 背包问题，每个粒子 $i$ 都有一个位置向量 $\\mathbf{x}_i \\in \\{0, 1\\}^d$，其中 $x_{ij} = 1$ 表示物品 $j$ 被放入背包，而 $x_{ij} = 0$ 表示未被放入。每个粒子还有一个速度向量 $\\mathbf{v}_i \\in \\mathbb{R}^d$，它影响粒子在搜索空间中的移动。\n\nPSO 的核心是一个迭代过程，其中粒子根据它们自己找到的最佳解和整个种群找到的最佳解来调整其速度。在迭代 $t+1$ 时，粒子 $i$ 在维度 $j$ 上的速度更新由下式给出：\n$$v_{ij}(t+1) = w v_{ij}(t) + c_1 r_{1j}(t) (\\text{pbest}_{ij} - x_{ij}(t)) + c_2 r_{2j}(t) (\\text{gbest}_j - x_{ij}(t))$$\n其中：\n- $w = 0.7$ 是惯性权重，控制前一速度的影响。\n- $c_1 = 1.6$ 和 $c_2 = 1.6$ 分别是认知系数和社会系数，它们衡量向个体最佳和全局最佳位置的吸引力。\n- $r_{1j}(t)$ 和 $r_{2j}(t)$ 是在每次迭代中为每个粒子和每个维度从均匀分布 $U(0, 1)$ 中独立抽取的随机数。\n- $\\mathbf{pbest}_i$ 是粒子 $i$ 迄今为止找到的个体最佳位置。\n- $\\mathbf{gbest}$ 是整个种群中任何粒子迄今为止找到的全局最佳位置。\n- $x_{ij}(t)$ 是当前的位置比特位。\n\n每次更新后，速度 $v_{ij}$ 被限制在 $[v_{\\min}, v_{\\max}]$ 范围内，即 $[-4, 4]$，以防止不受控制的发散。\n\nBPSO 中的关键步骤是将连续速度 $v_{ij}$ 转换为二进制位置 $x_{ij}$ 的变化。问题要求一个到“翻转概率”的映射。一个字面上的解释，即翻转比特位 $x_{ij}$ 的概率由 $v_{ij}$ 的单调函数（例如 sigmoid 函数）决定，会导致有缺陷的动态。例如，如果 $x_{ij}=1$ 并且目标（例如 $\\text{pbest}_{ij}$）是 $0$，速度 $v_{ij}$ 会变为负数。一个 sigmoid 映射 $P(\\text{flip}) = S(v_{ij})$ 此时会产生一个低的翻转概率，从而阻碍粒子向更优解移动。\n\n因此，一种更有原则性且功能上正确的方法，是遵循 Kennedy 和 Eberhart 的经典 BPSO 模型，将速度解释为控制比特位处于状态 $1$ 的概率。我们选择 logistic sigmoid 函数进行此映射，因为它平滑、单调，并将 $\\mathbb{R}$ 映射到 $(0, 1)$，满足所有问题约束：\n$$S(v) = \\frac{1}{1 + e^{-v}}$$\n位置更新规则定义如下：对于每个维度 $j$，抽取一个随机数 $r_{3j} \\sim U(0,1)$。新的比特位 $x_{ij}(t+1)$ 根据概率 $S(v_{ij}(t+1))$ 进行设置：\n$$x_{ij}(t+1) = \\begin{cases} 1  \\text{if } r_{3j}  S(v_{ij}(t+1)) \\\\ 0  \\text{otherwise} \\end{cases}$$\n这种表述能够正确引导种群：一个大的正速度会增加比特位为 $1$ 的概率，而一个大的负速度则会增加其为 $0$ 的概率。\n\n为了处理背包容量约束 $\\sum_{j=1}^{d} w_j x_j \\le C$，我们使用惩罚方法。一个潜在解 $\\mathbf{x}$ 的适应度通过一个惩罚目标函数 $F(\\mathbf{x})$ 来评估，种群的目标是最大化该函数。该函数定义为总价值减去与容量超出量平方成正比的惩罚：\n$$F(\\mathbf{x}) = \\left(\\sum_{j=1}^{d} u_j x_j\\right) - \\lambda \\cdot \\max\\left(0, \\left(\\sum_{j=1}^{d} w_j x_j\\right) - C\\right)^2$$\n惩罚系数给定为 $\\lambda = 100$。个体最佳 $\\mathbf{pbest}_i$ 和全局最佳 $\\mathbf{gbest}$ 基于此惩罚适应度值 $F(\\mathbf{x})$ 进行更新。\n\n在整个搜索过程中，我们还必须跟踪找到的最佳*可行*解。一个单独的变量存储满足容量约束的位置 $\\mathbf{x}$ 所产生的最高目标值 $\\sum u_j x_j$。这是需要报告的值。如果在 $T=300$ 次迭代后没有找到可行解，结果为 $0$。\n\n整体算法流程如下：\n1.  **初始化**：将随机种子设置为 $42$。对于一个由 $N=60$ 个粒子组成的种群，在 $\\{0, 1\\}^d$ 中随机初始化位置 $\\mathbf{x}_i$，并将速度 $\\mathbf{v}_i$ 初始化为零。为每个粒子评估初始的惩罚适应度 $F(\\mathbf{x}_i)$。设置 $\\mathbf{pbest}_i = \\mathbf{x}_i$。通过找到具有最高初始适应度的粒子来确定初始的 $\\mathbf{gbest}$。将迄今为止找到的最佳可行值初始化为 $0$（或初始化为初始种群中最佳可行解的值）。\n2.  **迭代**：对于 $t = 1, \\dots, T$：\n    a. 对于每个粒子 $i = 1, \\dots, N$：\n        i. 使用 PSO 更新方程更新速度向量 $\\mathbf{v}_i$ 的每个分量 $v_{ij}$，并将其限制在 $[-4, 4]$ 范围内。\n        ii. 使用 sigmoid 映射和随机抽样更新位置向量 $\\mathbf{x}_i$ 的每个分量 $x_{ij}$。\n    b. 为所有粒子的新位置评估惩罚适应度 $F(\\mathbf{x}_i)$。\n    c. 对于每个粒子，如果其新的适应度大于其个体最佳适应度，则更新 $\\mathbf{pbest}_i$ 及其相关的适应度值。\n    d. 通过在整个种群中选择最佳的 $\\mathbf{pbest}_i$ 来确定新的 $\\mathbf{gbest}$。\n    e. 检查所有新位置的可行性。如果一个可行位置产生的值高于当前已知的最佳可行值，则更新后者。\n3.  **终止**：经过 $T$ 次迭代后，算法终止。最终结果是记录的最佳可行值。\n此过程将应用于四个指定的背包问题实例中的每一个。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expit as sigmoid\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the BPSO algorithm for each.\n    The final print statement produces the required single-line output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        {\n            \"weights\": np.array([2, 3, 5, 7, 1, 4, 1]),\n            \"values\": np.array([10, 5, 15, 7, 6, 18, 3]),\n            \"capacity\": 15\n        },\n        # Case B\n        {\n            \"weights\": np.array([5, 8, 3]),\n            \"values\": np.array([9, 11, 4]),\n            \"capacity\": 4\n        },\n        # Case C\n        {\n            \"weights\": np.array([1, 1, 1, 1]),\n            \"values\": np.array([2, 2, 2, 2]),\n            \"capacity\": 10\n        },\n        # Case D\n        {\n            \"weights\": np.array([3, 2, 2, 1]),\n            \"values\": np.array([5, 3, 3, 2]),\n            \"capacity\": 5\n        }\n    ]\n\n    # PSO hyperparameters as specified in the problem\n    params = {\n        \"swarm_size\": 60,\n        \"iterations\": 300,\n        \"inertia_weight\": 0.7,\n        \"cognitive_coeff\": 1.6,\n        \"social_coeff\": 1.6,\n        \"v_min\": -4.0,\n        \"v_max\": 4.0,\n        \"penalty_coeff\": 100.0,\n        \"seed\": 42\n    }\n\n    # Set the global seed for reproducibility across all test cases\n    np.random.seed(params[\"seed\"])\n\n    results = []\n    for case in test_cases:\n        best_value = run_bpso(\n            case[\"weights\"],\n            case[\"values\"],\n            case[\"capacity\"],\n            params\n        )\n        results.append(best_value)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef run_bpso(weights, values, capacity, params):\n    \"\"\"\n    Executes the Binary Particle Swarm Optimization for a single knapsack instance.\n    \"\"\"\n    d = len(weights)\n    N = params[\"swarm_size\"]\n    T = params[\"iterations\"]\n    w = params[\"inertia_weight\"]\n    c1 = params[\"cognitive_coeff\"]\n    c2 = params[\"social_coeff\"]\n    v_min = params[\"v_min\"]\n    v_max = params[\"v_max\"]\n    lambda_ = params[\"penalty_coeff\"]\n\n    # 1. Initialization\n    # Initialize positions: N particles, d dimensions.\n    positions = np.random.randint(0, 2, size=(N, d))\n    # Initialize velocities to zero arrays.\n    velocities = np.zeros((N, d), dtype=float)\n    \n    # Initialize personal best positions and fitness\n    pbest_positions = np.copy(positions)\n    \n    # Evaluate initial fitness using the penalized objective function\n    total_values = positions @ values\n    total_weights = positions @ weights\n    violations = np.maximum(0, total_weights - capacity)\n    pbest_fitness = total_values - lambda_ * (violations ** 2)\n\n    # Initialize global best position and its fitness from personal bests\n    gbest_idx = np.argmax(pbest_fitness)\n    gbest_position = np.copy(pbest_positions[gbest_idx])\n    gbest_fitness = pbest_fitness[gbest_idx]\n\n    # Initialize tracker for the best feasible objective value found so far\n    best_feasible_value = 0\n    feasible_mask = (total_weights = capacity)\n    if np.any(feasible_mask):\n        best_feasible_value = np.max(total_values[feasible_mask])\n\n    # 2. Main PSO Loop\n    for _ in range(T):\n        # Generate random numbers for velocity update (one matrix for c1, one for c2)\n        r1 = np.random.rand(N, d)\n        r2 = np.random.rand(N, d)\n\n        # Update velocities based on inertia, personal best, and global best\n        velocities = (w * velocities +\n                      c1 * r1 * (pbest_positions - positions) +\n                      c2 * r2 * (gbest_position - positions))\n        \n        # Clamp velocities to the range [v_min, v_max]\n        np.clip(velocities, v_min, v_max, out=velocities)\n        \n        # Update positions using the sigmoid function\n        prob_one = sigmoid(velocities)\n        rand_matrix = np.random.rand(N, d)\n        positions = (rand_matrix  prob_one).astype(int)\n        \n        # Evaluate fitness of new positions\n        current_values = positions @ values\n        current_weights = positions @ weights\n        current_violations = np.maximum(0, current_weights - capacity)\n        current_fitness = current_values - lambda_ * (current_violations ** 2)\n        \n        # Update personal bests\n        update_mask = current_fitness > pbest_fitness\n        pbest_positions[update_mask] = positions[update_mask]\n        pbest_fitness[update_mask] = current_fitness[update_mask]\n\n        # Update global best\n        current_gbest_idx = np.argmax(pbest_fitness)\n        if pbest_fitness[current_gbest_idx] > gbest_fitness:\n            gbest_fitness = pbest_fitness[current_gbest_idx]\n            gbest_position = np.copy(pbest_positions[current_gbest_idx])\n        \n        # Update the best feasible objective value found so far\n        feasible_mask = (current_weights = capacity)\n        if np.any(feasible_mask):\n            max_feasible_in_iter = np.max(current_values[feasible_mask])\n            if max_feasible_in_iter > best_feasible_value:\n                best_feasible_value = max_feasible_in_iter\n    \n    return int(best_feasible_value)\n\nsolve()\n```"
        }
    ]
}