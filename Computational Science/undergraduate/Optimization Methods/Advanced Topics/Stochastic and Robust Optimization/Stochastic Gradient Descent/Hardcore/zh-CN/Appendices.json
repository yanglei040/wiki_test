{
    "hands_on_practices": [
        {
            "introduction": "要真正理解随机梯度下降法（SGD），最好的起点是亲手执行一次更新。这个练习将引导你完成一个最基本的SGD步骤：使用单个数据点的梯度来更新模型参数。通过这个具体计算，你将掌握SGD的核心机制，为后续更深入的概念打下坚实基础 。",
            "id": "2206637",
            "problem": "一个迭代优化算法用于寻找使成本函数最小化的参数 $x$。总成本函数是几个分量函数的平均值：$F(x) = \\frac{1}{N}\\sum_{i=1}^{N} f_i(x)$。在这个具体案例中，分量函数是二次的，由 $f_i(x) = (x - c_i)^2$ 给出，其中常数为 $c_i = i$，对于 $i = 1, 2, \\dots, 10$，因此 $N=10$。\n\n优化过程从参数的一个初始猜测值 $x_0$ 开始。在每一步中，通过仅使用一个随机选择的分量函数 $f_j(x)$，从当前估计值 $x_k$ 计算出一个新的估计值 $x_{k+1}$。更新规则定义为：\n$$x_{k+1} = x_k - \\eta \\left( \\frac{d f_j(x)}{dx} \\bigg|_{x=x_k} \\right)$$\n其中 $\\eta$ 是一个常数，称为学习率。\n\n给定初始参数值 $x_0 = 10.0$ 和学习率 $\\eta = 0.1$，计算经过一次更新步骤后参数 $x_1$ 的值。对于这第一步，使用的分量函数是索引为 $j=5$ 的 $f_j(x)$。",
            "solution": "我们已知分量函数的形式为 $f_{i}(x) = (x - c_{i})^{2}$，其中 $c_{i} = i$。对于第一次更新，选择的索引是 $j=5$，所以 $f_{5}(x) = (x - 5)^{2}$。\n\n更新规则是\n$$\nx_{k+1} = x_{k} - \\eta \\left.\\frac{d f_{j}(x)}{dx}\\right|_{x=x_{k}}.\n$$\n使用幂法则和链式法则，所选分量函数的导数是\n$$\n\\frac{d f_{5}(x)}{dx} = \\frac{d}{dx}\\left[(x - 5)^{2}\\right] = 2(x - 5).\n$$\n在当前迭代值 $x_{0} = 10$ 处求值得到\n$$\n\\left.\\frac{d f_{5}(x)}{dx}\\right|_{x=10} = 2(10 - 5) = 10.\n$$\n当学习率 $\\eta = 0.1$ 时，更新变为\n$$\nx_{1} = x_{0} - \\eta \\cdot 10 = 10 - 0.1 \\times 10 = 10 - 1 = 9.\n$$\n因此，在使用 $f_{5}$ 进行一次更新步骤后，参数值为 $x_{1} = 9$。",
            "answer": "$$\\boxed{9}$$"
        },
        {
            "introduction": "掌握了单步更新的计算方法后，我们来探讨SGD中“随机”二字的真正含义。与使用全部数据计算“精确”梯度的标准梯度下降不同，SGD的梯度估计本身是一个随机变量。这个练习  让你计算这个随机梯度的方差，从而量化其“不确定性”或“噪声”，这正是SGD诸多独特行为的根源。",
            "id": "2206620",
            "problem": "在许多机器学习问题中，目标是最小化一个损失函数 $F(x)$，该函数在结构上是某个数据集上的平均值。一种常见的形式是 $F(x) = \\frac{1}{N} \\sum_{i=1}^{N} f_i(x)$，其中 $f_i(x)$ 是与第 $i$ 个数据点相关的损失，$x$ 是模型参数。\n\n考虑一个简化的一维问题，我们希望找到最小化损失函数的参数 $x$。数据集仅包含两个数据点 ($N=2$)，这导致了以下分量损失函数：\n$$f_1(x) = (x-2)^2$$\n$$f_2(x) = (x+2)^2$$\n因此，总损失函数为 $F(x) = \\frac{1}{2} (f_1(x) + f_2(x))$。\n\n随机梯度下降 (SGD) 是一种迭代优化算法，它在每一步中近似计算 $F(x)$ 的真实梯度。在其最简单的形式中，我们首先从 $\\{1, 2\\}$ 中均匀随机地选择一个索引 $i$，然后计算相应分量函数的梯度，从而得到一个随机梯度估计量（我们记为 $g(x)$），即 $g(x) = \\nabla f_i(x)$。在这个一维问题中，梯度算子 $\\nabla$ 就是关于 $x$ 的导数，即 $\\frac{d}{dx}$。\n\n计算随机梯度估计量 $g(x)$ 在特定点 $x = 1$ 处的方差。",
            "solution": "给定 $f_{1}(x)=(x-2)^{2}$ 和 $f_{2}(x)=(x+2)^{2}$，随机梯度估计量 $g(x)$ 的定义是：从 $\\{1,2\\}$ 中均匀选择 $i$，并设 $g(x)=\\frac{d}{dx}f_{i}(x)$。首先计算分量梯度：\n$$\n\\frac{d}{dx}f_{1}(x)=2(x-2), \\quad \\frac{d}{dx}f_{2}(x)=2(x+2).\n$$\n在 $x=1$ 处，$g(1)$ 的取值为\n$$\ng(1)=2(1-2)=-2 \\quad \\text{概率为 } \\frac{1}{2}, \\quad g(1)=2(1+2)=6 \\quad \\text{概率为 } \\frac{1}{2}.\n$$\n计算 $g(1)$ 的期望：\n$$\n\\mathbb{E}[g(1)]=\\frac{1}{2}(-2)+\\frac{1}{2}(6)=2.\n$$\n这等于 $F$ 在 $x=1$ 处的真实梯度，因为\n$$\nF'(x)=\\frac{1}{2}\\left(2(x-2)+2(x+2)\\right)=2x \\implies F'(1)=2.\n$$\n计算二阶矩：\n$$\n\\mathbb{E}[g(1)^{2}]=\\frac{1}{2}\\left((-2)^{2}+6^{2}\\right)=\\frac{1}{2}(4+36)=20.\n$$\n因此，方差为\n$$\n\\operatorname{Var}(g(1))=\\mathbb{E}[g(1)^{2}]-\\left(\\mathbb{E}[g(1)]\\right)^{2}=20-2^{2}=16.\n$$\n因此，随机梯度估计量在 $x=1$ 处的方差为 $16$。",
            "answer": "$$\\boxed{16}$$"
        },
        {
            "introduction": "随机梯度带来的噪声既是挑战也是机遇。一个常见的误解是，优化算法的每一步都必须使总损失函数下降。本练习  将通过一个具体的反例挑战这一直觉，你会发现，单个SGD步骤完全有可能导致整体损失函数的上升。理解这一点，是把握SGD优化路径“曲折前进”本质的关键。",
            "id": "2206653",
            "problem": "在机器学习领域，优化算法通过最小化损失函数来训练模型参数。考虑一个具有单个标量参数 $w$ 的简单模型。目标是最小化总损失函数 $F(w)$，它被定义为在一个包含两个数据点的小型数据集上各个损失函数的平均值。总损失函数由下式给出：\n\n$$F(w) = \\frac{1}{2}\\left[f_1(w) + f_2(w)\\right]$$\n\n与这两个数据点相关的各个损失函数为：\n\n$$f_1(w) = \\frac{1}{2}(w - 2)^2$$\n$$f_2(w) = \\frac{1}{2}(w - 10)^2$$\n\n训练过程从初始参数值 $w_0 = 3$ 开始。使用学习率为 $\\eta = 2$ 的随机梯度下降 (SGD) 算法执行单个更新步骤。对于这个特定的更新，梯度仅使用第一个数据点的损失函数 $f_1(w)$ 来计算。\n\n计算由这次 SGD 单步更新导致的总损失函数值的变化量 $F(w_1) - F(w_0)$。将您的最终答案四舍五入到三位有效数字。",
            "solution": "给定 $F(w)=\\frac{1}{2}\\left[f_{1}(w)+f_{2}(w)\\right]$，其中 $f_{1}(w)=\\frac{1}{2}(w-2)^{2}$ 且 $f_{2}(w)=\\frac{1}{2}(w-10)^{2}$。初始参数为 $w_{0}=3$。学习率为 $\\eta=2$ 的单步 SGD 更新仅使用 $f_{1}$ 的梯度。\n\n一维 SGD 更新规则为\n$$\nw_{1}=w_{0}-\\eta\\,\\frac{d f_{1}}{d w}\\bigg|_{w=w_{0}}.\n$$\n计算导数：\n$$\n\\frac{d f_{1}}{d w}=\\frac{d}{d w}\\left[\\frac{1}{2}(w-2)^{2}\\right]=(w-2).\n$$\n在 $w_{0}=3$ 处求值：\n$$\n\\frac{d f_{1}}{d w}\\bigg|_{w=3}=3-2=1.\n$$\n因此更新后的参数为\n$$\nw_{1}=3-2\\cdot 1=1.\n$$\n\n现在计算 $F(w_{0})$：\n$$\nf_{1}(3)=\\frac{1}{2}(3-2)^{2}=\\frac{1}{2},\\quad f_{2}(3)=\\frac{1}{2}(3-10)^{2}=\\frac{1}{2}\\cdot 49=\\frac{49}{2},\n$$\n$$\nF(3)=\\frac{1}{2}\\left(\\frac{1}{2}+\\frac{49}{2}\\right)=\\frac{1}{2}\\cdot\\frac{50}{2}=\\frac{1}{2}\\cdot 25=\\frac{25}{2}.\n$$\n\n计算 $F(w_{1})$：\n$$\nf_{1}(1)=\\frac{1}{2}(1-2)^{2}=\\frac{1}{2},\\quad f_{2}(1)=\\frac{1}{2}(1-10)^{2}=\\frac{1}{2}\\cdot 81=\\frac{81}{2},\n$$\n$$\nF(1)=\\frac{1}{2}\\left(\\frac{1}{2}+\\frac{81}{2}\\right)=\\frac{1}{2}\\cdot\\frac{82}{2}=\\frac{1}{2}\\cdot 41=\\frac{41}{2}.\n$$\n\n因此，总损失的变化量为\n$$\nF(w_{1})-F(w_{0})=\\frac{41}{2}-\\frac{25}{2}=\\frac{16}{2}=8.\n$$\n四舍五入到三位有效数字，结果为 $8.00$。",
            "answer": "$$\\boxed{8.00}$$"
        }
    ]
}