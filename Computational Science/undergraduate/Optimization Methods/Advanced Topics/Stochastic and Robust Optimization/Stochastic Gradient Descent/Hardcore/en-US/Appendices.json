{
    "hands_on_practices": [
        {
            "introduction": "Stochastic Gradient Descent (SGD) is a workhorse algorithm for training large-scale models. Its power lies in its efficiency: instead of calculating the gradient of the loss function over the entire dataset, it uses just a single data point or a small \"mini-batch.\" This first practice exercise  walks you through the fundamental mechanics of a single SGD update step, providing a concrete feel for how model parameters are adjusted based on a single piece of information. This is the foundational skill for understanding how SGD navigates a complex loss landscape.",
            "id": "2206637",
            "problem": "An iterative optimization algorithm is used to find a parameter $x$ that minimizes a cost function. The total cost function is an average of several component functions: $F(x) = \\frac{1}{N}\\sum_{i=1}^{N} f_i(x)$. In this specific case, the component functions are quadratic and given by $f_i(x) = (x - c_i)^2$, where the constants are $c_i = i$ for $i = 1, 2, \\dots, 10$, and thus $N=10$.\n\nThe optimization process starts with an initial guess for the parameter, $x_0$. At each step, a new estimate, $x_{k+1}$, is calculated from the current estimate, $x_k$, by using only a single, randomly chosen component function, $f_j(x)$. The update rule is defined as:\n$$x_{k+1} = x_k - \\eta \\left( \\frac{d f_j(x)}{dx} \\bigg|_{x=x_k} \\right)$$\nwhere $\\eta$ is a constant known as the learning rate.\n\nGiven an initial parameter value of $x_0 = 10.0$ and a learning rate of $\\eta = 0.1$, compute the value of the parameter $x_1$ after one update step. For this first step, the component function used is $f_j(x)$ with the index $j=5$.",
            "solution": "We are given component functions of the form $f_{i}(x) = (x - c_{i})^{2}$ with $c_{i} = i$. For the first update, the chosen index is $j=5$, so $f_{5}(x) = (x - 5)^{2}$.\n\nThe update rule is\n$$\nx_{k+1} = x_{k} - \\eta \\left.\\frac{d f_{j}(x)}{dx}\\right|_{x=x_{k}}.\n$$\nUsing the power rule and chain rule, the derivative of the chosen component is\n$$\n\\frac{d f_{5}(x)}{dx} = \\frac{d}{dx}\\left[(x - 5)^{2}\\right] = 2(x - 5).\n$$\nEvaluating at the current iterate $x_{0} = 10$ gives\n$$\n\\left.\\frac{d f_{5}(x)}{dx}\\right|_{x=10} = 2(10 - 5) = 10.\n$$\nWith learning rate $\\eta = 0.1$, the update becomes\n$$\nx_{1} = x_{0} - \\eta \\cdot 10 = 10 - 0.1 \\times 10 = 10 - 1 = 9.\n$$\nThus, after one update step using $f_{5}$, the parameter value is $x_{1} = 9$.",
            "answer": "$$\\boxed{9}$$"
        },
        {
            "introduction": "While each SGD step is designed to reduce the loss for the specific data point being used, it does not guarantee a decrease in the *total* loss function across the entire dataset. This is a crucial and sometimes counter-intuitive aspect of SGD, leading to a \"zigzagging\" path towards the minimum. This exercise  directly demonstrates how a single, valid SGD update can actually lead to an increase in the overall loss, highlighting the stochastic and often erratic nature of the optimization process.",
            "id": "2206653",
            "problem": "In the field of machine learning, optimization algorithms are used to train model parameters by minimizing a loss function. Consider a simple model with a single scalar parameter, $w$. The goal is to minimize a total loss function, $F(w)$, which is defined as the average of the individual loss functions over a small dataset of two data points. The total loss function is given by:\n\n$$F(w) = \\frac{1}{2}\\left[f_1(w) + f_2(w)\\right]$$\n\nThe individual loss functions associated with the two data points are:\n\n$$f_1(w) = \\frac{1}{2}(w - 2)^2$$\n$$f_2(w) = \\frac{1}{2}(w - 10)^2$$\n\nThe training process begins with an initial parameter value of $w_0 = 3$. A single update step is performed using the Stochastic Gradient Descent (SGD) algorithm with a learning rate of $\\eta = 2$. For this specific update, the gradient is computed using only the loss function of the first data point, $f_1(w)$.\n\nCalculate the change in the value of the total loss function, $F(w_1) - F(w_0)$, that results from this single SGD update. Round your final answer to three significant figures.",
            "solution": "We are given $F(w)=\\frac{1}{2}\\left[f_{1}(w)+f_{2}(w)\\right]$ with $f_{1}(w)=\\frac{1}{2}(w-2)^{2}$ and $f_{2}(w)=\\frac{1}{2}(w-10)^{2}$. The initial parameter is $w_{0}=3$. A single SGD step with learning rate $\\eta=2$ uses only the gradient of $f_{1}$.\n\nThe SGD update rule in one dimension is\n$$\nw_{1}=w_{0}-\\eta\\,\\frac{d f_{1}}{d w}\\bigg|_{w=w_{0}}.\n$$\nCompute the derivative:\n$$\n\\frac{d f_{1}}{d w}=\\frac{d}{d w}\\left[\\frac{1}{2}(w-2)^{2}\\right]=(w-2).\n$$\nEvaluate at $w_{0}=3$:\n$$\n\\frac{d f_{1}}{d w}\\bigg|_{w=3}=3-2=1.\n$$\nThus the updated parameter is\n$$\nw_{1}=3-2\\cdot 1=1.\n$$\n\nNow compute $F(w_{0})$:\n$$\nf_{1}(3)=\\frac{1}{2}(3-2)^{2}=\\frac{1}{2},\\quad f_{2}(3)=\\frac{1}{2}(3-10)^{2}=\\frac{1}{2}\\cdot 49=\\frac{49}{2},\n$$\n$$\nF(3)=\\frac{1}{2}\\left(\\frac{1}{2}+\\frac{49}{2}\\right)=\\frac{1}{2}\\cdot\\frac{50}{2}=\\frac{1}{2}\\cdot 25=\\frac{25}{2}.\n$$\n\nCompute $F(w_{1})$:\n$$\nf_{1}(1)=\\frac{1}{2}(1-2)^{2}=\\frac{1}{2},\\quad f_{2}(1)=\\frac{1}{2}(1-10)^{2}=\\frac{1}{2}\\cdot 81=\\frac{81}{2},\n$$\n$$\nF(1)=\\frac{1}{2}\\left(\\frac{1}{2}+\\frac{81}{2}\\right)=\\frac{1}{2}\\cdot\\frac{82}{2}=\\frac{1}{2}\\cdot 41=\\frac{41}{2}.\n$$\n\nTherefore, the change in the total loss is\n$$\nF(w_{1})-F(w_{0})=\\frac{41}{2}-\\frac{25}{2}=\\frac{16}{2}=8.\n$$\nRounded to three significant figures, this is $8.00$.",
            "answer": "$$\\boxed{8.00}$$"
        },
        {
            "introduction": "The randomness inherent in SGD is often more of a feature than a bug. In complex, non-convex optimization landscapes filled with many \"valleys\" (local minima), this noise can act as a powerful exploration mechanism. This hands-on problem  illustrates a scenario where standard Gradient Descent gets stuck in a suboptimal local minimum, but the noise in SGD provides the \"kick\" needed to jump over a potential barrier and continue its search for a better, global minimum.",
            "id": "2206623",
            "problem": "An optimization specialist is studying the behavior of different gradient-based algorithms on a one-dimensional non-convex loss surface. The idealized loss function is given by:\n$$L(w) = \\frac{1}{4}w^4 - \\frac{1}{3}w^3 - 3w^2$$\nwhere $w$ is a scalar parameter to be optimized.\n\nThe specialist considers two optimization algorithms, both starting from the initial parameter value $w_0 = -2.0$. Both algorithms use a fixed learning rate of $\\eta = 0.1$.\n\n1.  **Full-batch Gradient Descent (GD)**: The update rule is $w_{k+1} = w_k - \\eta L'(w_k)$.\n\n2.  **Stochastic Gradient Descent (SGD)**: The update is $w_{k+1} = w_k - \\eta \\hat{g}(w_k)$, where $\\hat{g}(w_k)$ is a noisy estimate of the gradient. This noisy gradient is modeled as $\\hat{g}(w_k) = L'(w_k) + \\xi_k$, where $\\xi_k$ is a random noise term drawn at each step $k$. For this analysis, the noise $\\xi_k$ is drawn from a simple discrete distribution: it takes the value $+\\sigma$ with probability $0.5$ and $-\\sigma$ with probability $0.5$, for some noise amplitude $\\sigma  0$.\n\nA key feature of this loss landscape is a potential barrier that separates a local minimum from the global minimum. For the SGD algorithm, the inherent noise provides a chance to \"jump\" over this barrier. Determine the minimum value of the noise amplitude $\\sigma$ for which there is a non-zero probability for the SGD process, starting at $w_0 = -2.0$, to move to a parameter value $w_1  0$ in a single update step.\n\nExpress your answer as a single real number.",
            "solution": "Compute the gradient of the loss:\n$$L'(w) = \\frac{\\mathrm{d}}{\\mathrm{d}w}\\left(\\frac{1}{4}w^{4} - \\frac{1}{3}w^{3} - 3w^{2}\\right) = w^{3} - w^{2} - 6w.$$\n\nAt the initial point $w_{0} = -2$,\n$$L'(-2) = (-2)^{3} - (-2)^{2} - 6(-2) = -8 - 4 + 12 = 0.$$\n\nFor full-batch GD, $w_{1} = w_{0} - \\eta L'(w_{0}) = -2 - 0 = -2$, so there is no movement.\n\nFor SGD, the noisy gradient estimate at $w_{0}$ is $\\hat{g}(w_{0}) = L'(w_{0}) + \\xi_{0} = \\xi_{0}$, where $\\xi_{0} \\in \\{+\\sigma, -\\sigma\\}$ with equal probability. The update is\n$$w_{1} = w_{0} - \\eta \\hat{g}(w_{0}) = -2 - \\eta \\xi_{0}.$$\n\nThere are two cases:\n- If $\\xi_{0} = -\\sigma$, then $w_{1} = -2 + \\eta \\sigma$.\n- If $\\xi_{0} = +\\sigma$, then $w_{1} = -2 - \\eta \\sigma$.\n\nTo have a non-zero probability that $w_{1}  0$ in one step, it suffices that the favorable outcome $\\xi_{0} = -\\sigma$ can make $w_{1}  0$. This requires\n$$-2 + \\eta \\sigma  0 \\quad \\Longleftrightarrow \\quad \\eta \\sigma  2 \\quad \\Longleftrightarrow \\quad \\sigma  \\frac{2}{\\eta}.$$\n\nWith the given $\\eta = 0.1$,\n$$\\sigma  \\frac{2}{0.1} = 20.$$\n\nThus, any $\\sigma$ strictly greater than $20$ yields a non-zero probability (specifically, one-half) that $w_{1}  0$ in a single step. The threshold value is $20$; at $\\sigma = 20$, the best-case update reaches $w_{1} = 0$ but not $w_{1}  0$.",
            "answer": "$$\\boxed{20}$$"
        }
    ]
}