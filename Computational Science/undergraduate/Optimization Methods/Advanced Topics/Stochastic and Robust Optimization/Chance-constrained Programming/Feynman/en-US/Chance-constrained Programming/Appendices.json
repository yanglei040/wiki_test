{
    "hands_on_practices": [
        {
            "introduction": "The most direct way to solve a chance-constrained program is to reformulate its probabilistic constraints into equivalent deterministic forms. This practice problem demonstrates this foundational technique in a common scenario where uncertain parameters follow a Normal distribution. By working through this exercise , you will gain hands-on experience in converting a stochastic linear program into a standard linear program that can be solved with conventional methods.",
            "id": "2177257",
            "problem": "A cutting-edge Quantum Software-as-a-Service (SaaS) company offers computational time on its quantum processors to external clients. The company runs two main types of hybrid quantum-classical jobs for its clients: Variational Quantum Eigensolver (VQE) jobs and Quantum Approximate Optimization Algorithm (QAOA) jobs. The head of operations needs to determine the optimal number of each type of job to run per day to maximize revenue, subject to several resource limitations.\n\nLet $x_1$ be the number of VQE jobs and $x_2$ be the number of QAOA jobs scheduled per day. The company's revenue is given by the objective function $Z = 10000x_1 + 4000x_2$, measured in dollars.\n\nThe scheduling is subject to the following constraints:\n1.  **Qubit-Hour Capacity:** The company's quantum processor has a firm, deterministic daily capacity of 180 total qubit-hours. Each VQE job requires 1 qubit-hour, and each QAOA job requires 2 qubit-hours.\n2.  **Classical CPU Constraint:** Both algorithms require a classical optimization loop that runs on a shared high-performance computing cluster. The total available Central Processing Unit (CPU) time, $B_C$, is stochastic due to unpredictable demand from other internal processes. Its availability is modeled by a normal distribution with a mean of $\\mu_C = 183$ core-hours and a standard deviation of $\\sigma_C = 20$ core-hours. Each VQE job requires 2 core-hours and each QAOA job requires 3 core-hours. The operations team requires that the scheduled jobs can be completed with a probability of at least 95%.\n3.  **Control System Constraint:** The jobs also rely on a specialized Field-Programmable Gate Array (FPGA) for qubit control, whose available processing time, $B_S$, is also stochastic. It follows a normal distribution with a mean of $\\mu_S = 279$ time-units and a standard deviation of $\\sigma_S = 25$ time-units. Each VQE job consumes 4 time-units, and each QAOA job consumes 1 time-unit. The team mandates that this resource constraint is met with a probability of at least 97.5%.\n\nFor your calculations, you may use the fact that for a standard normal random variable $Z \\sim N(0, 1)$, its $\\alpha$-quantile $z_{\\alpha}$ is the value such that $P(Z \\le z_{\\alpha}) = \\alpha$. The necessary quantiles are $z_{0.05} = -1.65$ and $z_{0.025} = -1.96$.\n\nAssuming that $x_1$ and $x_2$ can be non-integer values (representing partially completed or batched jobs), determine the maximum possible daily revenue. Express your answer in dollars.",
            "solution": "We maximize the linear revenue function $Z = 10000 x_1 + 4000 x_2$ subject to deterministic and chance constraints.\n\nThe deterministic qubit-hour capacity is $x_1 + 2 x_2 \\leq 180$.\n\nFor the CPU chance constraint, let $L_{C} = 2 x_1 + 3 x_2$ be the required core-hours and $B_{C} \\sim N(\\mu_{C}, \\sigma_{C}^{2})$ with $\\mu_{C} = 183$ and $\\sigma_{C} = 20$ be the available core-hours. The requirement is $P(B_{C} \\geq L_{C}) \\geq 0.95$. This is equivalent to $P(B_{C} \\leq L_{C}) \\leq 0.05$. Standardizing with $Z \\sim N(0, 1)$ gives\n$$\nP\\!\\left(Z \\leq \\frac{L_{C} - \\mu_{C}}{\\sigma_{C}}\\right) \\leq 0.05 \\quad \\Longrightarrow \\quad \\frac{L_{C} - \\mu_{C}}{\\sigma_{C}} \\leq z_{0.05}.\n$$\nHence $L_{C} \\leq \\mu_{C} + \\sigma_{C} z_{0.05}$. Using $z_{0.05} = -1.65$,\n$$\n2 x_1 + 3 x_2 \\leq 183 + 20(-1.65) = 150.\n$$\n\nFor the FPGA chance constraint, let $L_{S} = 4 x_1 + x_2$ and $B_{S} \\sim N(\\mu_{S}, \\sigma_{S}^{2})$ with $\\mu_{S} = 279$ and $\\sigma_{S} = 25$. The requirement is $P(B_{S} \\geq L_{S}) \\geq 0.975$, i.e., $P(B_{S} \\leq L_{S}) \\leq 0.025$. Standardizing yields\n$$\n\\frac{L_{S} - \\mu_{S}}{\\sigma_{S}} \\leq z_{0.025},\n$$\nso $L_{S} \\leq \\mu_{S} + \\sigma_{S} z_{0.025}$. Using $z_{0.025} = -1.96$,\n$$\n4 x_1 + x_2 \\leq 279 + 25(-1.96) = 230.\n$$\n\nThe full linear program is\n$$\n\\text{maximize } Z = 10000 x_1 + 4000 x_2\n$$\nsubject to\n$$\nx_1 + 2 x_2 \\leq 180,\\quad 2 x_1 + 3 x_2 \\leq 150,\\quad 4 x_1 + x_2 \\leq 230,\\quad x_1 \\geq 0,\\ x_2 \\geq 0.\n$$\n\nWe find candidate optimal vertices by intersecting binding constraints:\n1) Intersection of $2 x_1 + 3 x_2 = 150$ and $4 x_1 + x_2 = 230$:\nFrom $4 x_1 + x_2 = 230$, $x_2 = 230 - 4 x_1$. Substitute into $2 x_1 + 3 x_2 = 150$:\n$$\n2 x_1 + 3(230 - 4 x_1) = 150 \\Longrightarrow 2 x_1 + 690 - 12 x_1 = 150 \\Longrightarrow -10 x_1 = -540 \\Longrightarrow x_1 = 54.\n$$\nThen $x_2 = 230 - 4 \\cdot 54 = 14$. This point satisfies $x_1 + 2 x_2 = 54 + 28 = 82 \\leq 180$.\n\n2) Intersection of $2 x_1 + 3 x_2 = 150$ with axes: $(x_1, x_2) = (0,50)$ and $(75,0)$. The point $(75,0)$ violates $4 x_1 + x_2 \\leq 230$ since $300 > 230$, so it is infeasible. The point $(0,50)$ is feasible.\n\n3) Intersection of $4 x_1 + x_2 = 230$ with axes: $(x_1, x_2) = (57.5,0)$ and $(0,230)$. The point $(0,230)$ violates $2 x_1 + 3 x_2 \\leq 150$ since $690 > 150$, so it is infeasible. The point $(57.5,0)$ is feasible.\n\nThe remaining bounds and the constraint $x_1 + 2 x_2 \\leq 180$ are nonbinding at these candidates. Evaluate the objective:\n- At $(54,14)$: $Z = 10000 \\cdot 54 + 4000 \\cdot 14 = 540000 + 56000 = 596000$.\n- At $(57.5,0)$: $Z = 10000 \\cdot 57.5 = 575000$.\n- At $(0,50)$: $Z = 4000 \\cdot 50 = 200000$.\n- At $(0,0)$: $Z = 0$.\n\nTherefore, the maximum revenue occurs at $(x_1, x_2) = (54, 14)$ with $Z = 596000$ dollars.",
            "answer": "$$\\boxed{596000}$$"
        },
        {
            "introduction": "Analytical conversion is not always possible, especially when dealing with complex, high-dimensional, or non-standard probability distributions. This is where numerical methods like the Sample-Average Approximation (SAA) become essential. This exercise  guides you through implementing the SAA method to solve a chance-constrained assignment problem, providing practical experience with a powerful and widely used simulation-based approach to stochastic optimization.",
            "id": "3107870",
            "problem": "A discrete chance-constrained assignment model is specified as follows. There is a single task that must be assigned to exactly one candidate among $J$ candidates. For each candidate $j \\in \\{0,1,\\dots,J-1\\}$ and each resource index $i \\in \\{1,2,\\dots,m\\}$, the random resource consumption is an integer-valued random variable $a_{i j}(\\xi)$, where $\\xi$ denotes the underlying random outcome. The deterministic capacity for resource $i$ is $b_i \\in \\mathbb{Z}_{+}$. The decision variables are binary $x_j \\in \\{0,1\\}$ with the assignment constraint $\\sum_{j=0}^{J-1} x_j = 1$. The chance constraints require that, with probability at least $1-\\alpha$, all resource capacities are respected:\n$$\n\\mathbb{P}\\left(\\sum_{j=0}^{J-1} a_{i j}(\\xi)\\, x_j \\le b_i \\text{ for all } i=1,\\dots,m \\right) \\ge 1 - \\alpha.\n$$\nThe objective is to minimize the deterministic assignment cost $\\sum_{j=0}^{J-1} c_j x_j$ subject to the chance constraints and the binary assignment constraint.\n\nTo test the Sample-Average Approximation (SAA) approach using integer uncertainty, your program must:\n- Generate $N$ independent scenarios of the random coefficients for each test case using a fixed pseudorandom seed $s=2025$.\n- For each candidate $j$, compute the empirical fraction of scenarios in which all constraints $\\sum_{j=0}^{J-1} a_{i j}(\\xi) x_j \\le b_i$ (which reduces to $a_{i j}(\\xi) \\le b_i$ because exactly one $x_j$ can be $1$) are satisfied simultaneously for all $i$.\n- Declare $j$ SAA-feasible if the empirical fraction is at least $1-\\alpha$.\n- Among all SAA-feasible candidates, select the one with minimum cost $c_j$. In case of ties on cost, select the smallest index $j$. If no candidate is SAA-feasible, return $-1$.\n\nRandom coefficients $a_{i j}(\\xi)$ are integer-valued and independently distributed across resources $i$, candidates $j$, and scenarios, using either the Poisson distribution with mean $\\mu_{i j}$ or the Binomial distribution with parameters $n_{i j}$ and $p_{i j}$. All data are provided deterministically for each test case. No physical units or angles are involved. All required numerical answers are integers.\n\nUse the following test suite of three cases. In each case, the goal is to output the selected candidate index. The program must use the fixed seed $s=2025$ for scenario generation to ensure reproducibility.\n\nTest Case $1$ (happy path, Poisson uncertainty):\n- Resources: $m = 2$, candidates: $J = 4$.\n- Capacities: $b = [10, 15]$ (i.e., $b_1 = 10$, $b_2 = 15$).\n- Costs: $c = [9.0, 7.5, 12.0, 8.1]$.\n- Risk level: $\\alpha = 0.2$.\n- Sample size: $N = 2000$.\n- Distributions (Poisson means $\\mu_{i j}$):\n  - $j=0$: $(\\mu_{1,0}, \\mu_{2,0}) = (7, 12)$.\n  - $j=1$: $(\\mu_{1,1}, \\mu_{2,1}) = (5, 16)$.\n  - $j=2$: $(\\mu_{1,2}, \\mu_{2,2}) = (8, 8)$.\n  - $j=3$: $(\\mu_{1,3}, \\mu_{2,3}) = (6, 11)$.\n\nTest Case $2$ (boundary, strict chance constraint with $\\alpha = 0$):\n- Resources: $m = 3$, candidates: $J = 3$.\n- Capacities: $b = [5, 6, 4]$.\n- Costs: $c = [5.0, 2.0, 1.5]$.\n- Risk level: $\\alpha = 0.0$.\n- Sample size: $N = 200$.\n- Distributions:\n  - $j=0$: Binomial with $(n, p)$ per resource: $(5, 0.5)$, $(6, 0.4)$, $(4, 0.7)$.\n  - $j=1$: Poisson with means $(7, 6, 3)$.\n  - $j=2$: Poisson with means $(6, 8, 5)$.\n\nTest Case $3$ (edge case, mixed uncertainty and moderate tolerance):\n- Resources: $m = 2$, candidates: $J = 5$.\n- Capacities: $b = [10, 9]$.\n- Costs: $c = [4.0, 5.5, 6.0, 3.5, 2.0]$.\n- Risk level: $\\alpha = 0.5$.\n- Sample size: $N = 50$.\n- Distributions:\n  - $j=0$: Binomial with $(n, p)$ per resource: $(10, 0.8)$, $(9, 0.6)$.\n  - $j=1$: Poisson with means $(12, 7)$.\n  - $j=2$: Poisson with means $(9, 10)$.\n  - $j=3$: Binomial $(11, 0.4)$ and Poisson mean $8$ for the two resources.\n  - $j=4$: Binomial with $(n, p)$ per resource: $(10, 0.9)$, $(9, 0.9)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the selected candidate indices for the three test cases as a comma-separated list enclosed in square brackets, for example, $[j_1,j_2,j_3]$, where each $j_k$ is an integer. No additional text or whitespace is permitted in the output line.",
            "solution": "The problem requires finding the minimum-cost candidate for a task assignment problem subject to a set of chance constraints, solved using the Sample-Average Approximation (SAA) method. The decision is to choose exactly one candidate $j$ from a set of $J$ candidates, indexed $j \\in \\{0, 1, \\dots, J-1\\}$. This is modeled using binary decision variables $x_j \\in \\{0, 1\\}$ with the constraint $\\sum_{j=0}^{J-1} x_j = 1$.\n\nThe core of the problem lies in the chance constraint:\n$$\n\\mathbb{P}\\left(\\sum_{j=0}^{J-1} a_{i j}(\\xi)\\, x_j \\le b_i \\text{ for all } i=1,\\dots,m \\right) \\ge 1 - \\alpha.\n$$\nHere, $a_{i j}(\\xi)$ is the random resource consumption for resource $i$ by candidate $j$, $b_i$ is the deterministic capacity of resource $i$, and $1-\\alpha$ is the minimum required probability of satisfying all resource constraints simultaneously. Since exactly one candidate $j$ is selected (i.e., $x_j=1$ and all other $x_k=0$), the system of inequalities within the probability operator simplifies for a given choice of $j$ to:\n$$\na_{i j}(\\xi) \\le b_i \\text{ for all } i=1,\\dots,m.\n$$\nThe problem is to find the candidate $j$ that minimizes the deterministic cost $c_j$ while satisfying this probabilistic constraint.\n\nThe Sample-Average Approximation (SAA) method is employed to handle the stochastic nature of the problem. SAA replaces the true probability distribution with an empirical distribution derived from a finite number of random samples, or scenarios. The procedure defined in the problem is as follows:\n\n1.  **Scenario Generation**: For each candidate $j$ and each resource $i$, we generate $N$ independent samples of the random variable $a_{i j}(\\xi)$. This creates $N$ scenarios. A fixed pseudorandom seed $s=2025$ is used to ensure the reproducibility of these scenarios. Let the $k$-th scenario for resource consumption be $a_{ij}^{(k)}$ for $k=1, \\dots, N$. The random variables $a_{ij}$ are drawn from specified Poisson or Binomial distributions.\n\n2.  **Empirical Probability Calculation**: For each candidate $j$, we estimate the probability of satisfying all resource constraints. This is done by calculating the fraction of the $N$ scenarios in which the simplified constraint system $a_{ij}^{(k)} \\le b_i$ holds for all resources $i=1, \\dots, m$. The empirical probability for candidate $j$, denoted $\\hat{p}_j$, is:\n    $$\n    \\hat{p}_j = \\frac{1}{N} \\sum_{k=1}^{N} \\mathbb{I}(a_{ij}^{(k)} \\le b_i \\text{ for all } i=1, \\dots, m)\n    $$\n    where $\\mathbb{I}(\\cdot)$ is the indicator function, which equals $1$ if its argument is true and $0$ otherwise.\n\n3.  **Feasibility Check**: A candidate $j$ is declared SAA-feasible if its empirical probability meets the required risk level:\n    $$\n    \\hat{p}_j \\ge 1 - \\alpha.\n    $$\n\n4.  **Optimal Candidate Selection**: From the set of all SAA-feasible candidates, we select the one that minimizes the cost $c_j$. If two or more feasible candidates have the same minimum cost, the one with the smallest index $j$ is chosen. If no candidates are found to be SAA-feasible, the result is $-1$.\n\nThe implementation will process each of the three test cases sequentially. A single `numpy.random.default_rng` instance is initialized with the seed $s=2025$ and used for all random number generation throughout the execution to ensure consistency and reproducibility.\n\nFor a given test case with parameters $m$, $J$, $b$, $c$, $\\alpha$, $N$, and the specified distributions, the algorithm proceeds as follows:\n- An empty list, `saa_feasible_candidates`, is created to store the indices and costs of candidates that pass the feasibility check.\n- For each candidate $j$ from $0$ to $J-1$:\n    - For each resource $i$ from $1$ to $m$, an array of $N$ random samples for $a_{ij}$ is generated according to its specified distribution (Poisson or Binomial). This results in $m$ arrays of size $N$.\n    - These arrays are used to check, for each of the $N$ scenarios, whether the condition $a_{ij}^{(k)} \\le b_i$ is met for all $i$ simultaneously.\n    - The number of scenarios satisfying this condition is counted, and the empirical probability $\\hat{p}_j$ is calculated.\n    - If $\\hat{p}_j \\ge 1 - \\alpha$, the pair $(c_j, j)$ is added to the `saa_feasible_candidates` list.\n- After evaluating all candidates, the `saa_feasible_candidates` list is examined.\n    - If the list is empty, the result for the test case is $-1$.\n    - Otherwise, the list is sorted first by cost (ascending) and then by index (ascending) as a tie-breaker. The index of the first element in the sorted list is the solution.\nThis procedure is repeated for all three test cases to produce the final output.\n\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of chance-constrained assignment problems using\n    the Sample-Average Approximation (SAA) method.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        {\n            \"m\": 2, \"J\": 4,\n            \"b\": [10, 15],\n            \"c\": [9.0, 7.5, 12.0, 8.1],\n            \"alpha\": 0.2,\n            \"N\": 2000,\n            \"distributions\": [\n                [{'type': 'poisson', 'params': {'mu': 7}}, {'type': 'poisson', 'params': {'mu': 12}}], # j=0\n                [{'type': 'poisson', 'params': {'mu': 5}}, {'type': 'poisson', 'params': {'mu': 16}}], # j=1\n                [{'type': 'poisson', 'params': {'mu': 8}}, {'type': 'poisson', 'params': {'mu': 8}}],  # j=2\n                [{'type': 'poisson', 'params': {'mu': 6}}, {'type': 'poisson', 'params': {'mu': 11}}], # j=3\n            ]\n        },\n        # Test Case 2\n        {\n            \"m\": 3, \"J\": 3,\n            \"b\": [5, 6, 4],\n            \"c\": [5.0, 2.0, 1.5],\n            \"alpha\": 0.0,\n            \"N\": 200,\n            \"distributions\": [\n                [{'type': 'binomial', 'params': {'n': 5, 'p': 0.5}}, {'type': 'binomial', 'params': {'n': 6, 'p': 0.4}}, {'type': 'binomial', 'params': {'n': 4, 'p': 0.7}}], # j=0\n                [{'type': 'poisson', 'params': {'mu': 7}}, {'type': 'poisson', 'params': {'mu': 6}}, {'type': 'poisson', 'params': {'mu': 3}}], # j=1\n                [{'type': 'poisson', 'params': {'mu': 6}}, {'type': 'poisson', 'params': {'mu': 8}}, {'type': 'poisson', 'params': {'mu': 5}}], # j=2\n            ]\n        },\n        # Test Case 3\n        {\n            \"m\": 2, \"J\": 5,\n            \"b\": [10, 9],\n            \"c\": [4.0, 5.5, 6.0, 3.5, 2.0],\n            \"alpha\": 0.5,\n            \"N\": 50,\n            \"distributions\": [\n                [{'type': 'binomial', 'params': {'n': 10, 'p': 0.8}}, {'type': 'binomial', 'params': {'n': 9, 'p': 0.6}}], # j=0\n                [{'type': 'poisson', 'params': {'mu': 12}}, {'type': 'poisson', 'params': {'mu': 7}}], # j=1\n                [{'type': 'poisson', 'params': {'mu': 9}}, {'type': 'poisson', 'params': {'mu': 10}}], # j=2\n                [{'type': 'binomial', 'params': {'n': 11, 'p': 0.4}}, {'type': 'poisson', 'params': {'mu': 8}}], # j=3\n                [{'type': 'binomial', 'params': {'n': 10, 'p': 0.9}}, {'type': 'binomial', 'params': {'n': 9, 'p': 0.9}}], # j=4\n            ]\n        }\n    ]\n\n    # Initialize a single random number generator for reproducibility.\n    rng = np.random.default_rng(seed=2025)\n    \n    results = []\n\n    for case in test_cases:\n        J = case['J']\n        m = case['m']\n        c = case['c']\n        b = np.array(case['b'])\n        alpha = case['alpha']\n        N = case['N']\n        distributions = case['distributions']\n        \n        saa_feasible_candidates = []\n\n        for j in range(J):\n            # samples_matrix will hold all N scenarios for candidate j.\n            # Shape will be (m, N).\n            samples_matrix = np.zeros((m, N), dtype=int)\n            \n            for i in range(m):\n                dist_info = distributions[j][i]\n                dist_type = dist_info['type']\n                dist_params = dist_info['params']\n\n                if dist_type == 'poisson':\n                    samples_matrix[i, :] = rng.poisson(lam=dist_params['mu'], size=N)\n                elif dist_type == 'binomial':\n                    samples_matrix[i, :] = rng.binomial(n=dist_params['n'], p=dist_params['p'], size=N)\n\n            # Check constraints for each scenario.\n            # b_col has shape (m, 1) to enable broadcasting over N scenarios.\n            b_col = b.reshape(-1, 1)\n            \n            # satisfied_matrix is a boolean matrix of shape (m, N).\n            satisfied_matrix = (samples_matrix <= b_col)\n            \n            # A scenario is feasible if ALL m constraints are met.\n            # scenario_is_feasible is a boolean array of shape (N,).\n            scenario_is_feasible = np.all(satisfied_matrix, axis=0)\n            \n            num_satisfied_scenarios = np.sum(scenario_is_feasible)\n            \n            emp_prob = num_satisfied_scenarios / N\n            \n            if emp_prob >= (1 - alpha):\n                saa_feasible_candidates.append({'cost': c[j], 'index': j})\n\n        if not saa_feasible_candidates:\n            results.append(-1)\n        else:\n            # Sort by cost (primary key) and then by index (secondary key).\n            best_candidate = sorted(saa_feasible_candidates, key=lambda x: (x['cost'], x['index']))[0]\n            results.append(best_candidate['index'])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```",
            "answer": "[3,0,4]"
        },
        {
            "introduction": "Properly modeling the structure of uncertainty is just as important as choosing the right solution algorithm. A common temptation when facing multiple stochastic constraints is to aggregate them into a single, simpler constraint. This thought experiment  serves as a critical counterexample, revealing how such aggregation can be profoundly misleading by ignoring the dependence structure between random variables, leading to solutions that appear safe but are in fact infeasible.",
            "id": "3107959",
            "problem": "Consider a joint chance-constrained optimization model with $2$ random linear constraints driven by a bivariate random vector $\\boldsymbol{\\xi} = (\\xi_{1}, \\xi_{2})$. The joint chance constraint requires\n$$\n\\mathbb{P}\\left(\\xi_{1} x \\le b_{1},\\ \\xi_{2} x \\le b_{2}\\right) \\ge 1 - \\alpha,\n$$\nwhere $x \\in \\mathbb{R}$ is the decision variable, $b_{1}, b_{2} \\in \\mathbb{R}$ are deterministic bounds, and $\\alpha \\in (0,1)$ is a risk level. A common relaxation aggregates the left-hand sides and imposes a single chance constraint\n$$\n\\mathbb{P}\\left(\\xi_{1} x + \\xi_{2} x \\le b_{1} + b_{2}\\right) \\ge 1 - \\alpha.\n$$\nStarting from the foundational definition that a chance constraint requires the probability of satisfaction of the stated event to be at least $1 - \\alpha$, construct a counterexample that reveals how replacing the joint chance constraint with the aggregated single chance constraint can be misleading when the distribution exhibits tail dependence structure. Use the following scientifically sound setup:\n\n- Let $U \\sim \\mathrm{Unif}(0,1)$ be a scalar random variable with a uniform distribution on $[0,1]$.\n- Define $\\xi_{1} := 2U$ and $\\xi_{2} := 2(1-U)$, so that $(\\xi_{1}, \\xi_{2})$ has perfectly negative tail dependence (extreme values occur in an oppositional pattern).\n- Fix $x := 1$, $b_{1} := 1$, $b_{2} := 1$, and choose any $\\alpha \\in (0,1)$.\n\nUnder this setup:\n1. Compute $\\mathbb{P}\\left(\\xi_{1} + \\xi_{2} \\le 2\\right)$ and $\\mathbb{P}\\left(\\xi_{1} \\le 1,\\ \\xi_{2} \\le 1\\right)$ from first principles.\n2. To quantify the misleading nature of the aggregation, define\n$$\n\\Delta := \\mathbb{P}\\left(\\xi_{1} + \\xi_{2} \\le 2\\right) - \\mathbb{P}\\left(\\xi_{1} \\le 1,\\ \\xi_{2} \\le 1\\right).\n$$\nCompute the exact value of $\\Delta$.\n\nYour final answer must be the single real number equal to $\\Delta$. No rounding is required.",
            "solution": "The problem requires the computation of a specific quantity, $\\Delta$, which measures the difference in probabilities between a joint chance constraint and its aggregated relaxation, under a specified probabilistic model designed to highlight the pitfalls of such a relaxation. The model is defined by a bivariate random vector $(\\xi_{1}, \\xi_{2})$ whose components are functions of a single underlying uniform random variable $U \\sim \\mathrm{Unif}(0,1)$. The parameters are fixed at $x=1$, $b_{1}=1$, and $b_{2}=1$.\n\nFirst, we must evaluate the probability associated with the aggregated constraint:\n$$ \\mathbb{P}\\left(\\xi_{1} x + \\xi_{2} x \\le b_{1} + b_{2}\\right) $$\nSubstituting the given values $x=1$, $b_{1}=1$, and $b_{2}=1$, the expression becomes:\n$$ \\mathbb{P}\\left(\\xi_{1} + \\xi_{2} \\le 2\\right) $$\nThe random variables $\\xi_{1}$ and $\\xi_{2}$ are defined as:\n$$ \\xi_{1} := 2U $$\n$$ \\xi_{2} := 2(1-U) $$\nWe can compute the sum $\\xi_{1} + \\xi_{2}$ directly by substituting these definitions:\n$$ \\xi_{1} + \\xi_{2} = 2U + 2(1-U) = 2U + 2 - 2U = 2 $$\nThe sum $\\xi_{1} + \\xi_{2}$ is a constant value, $2$, regardless of the outcome of the random variable $U$. The event inside the probability is therefore $\\xi_{1} + \\xi_{2} \\le 2$, which is equivalent to the statement $2 \\le 2$. This is a certain event, one that is always true. The probability of a certain event is, by definition, $1$.\n$$ \\mathbb{P}\\left(\\xi_{1} + \\xi_{2} \\le 2\\right) = 1 $$\n\nSecond, we evaluate the probability of the original joint chance constraint:\n$$ \\mathbb{P}\\left(\\xi_{1} x \\le b_{1}, \\xi_{2} x \\le b_{2}\\right) $$\nSubstituting the same parameter values, we get:\n$$ \\mathbb{P}\\left(\\xi_{1} \\le 1, \\xi_{2} \\le 1\\right) $$\nThis is the probability of the intersection of two events. We must translate these events into conditions on the underlying random variable $U$.\nThe first event, $\\xi_{1} \\le 1$, becomes:\n$$ 2U \\le 1 \\implies U \\le \\frac{1}{2} $$\nThe second event, $\\xi_{2} \\le 1$, becomes:\n$$ 2(1-U) \\le 1 \\implies 1-U \\le \\frac{1}{2} \\implies \\frac{1}{2} \\le U $$\nFor the joint event $(\\xi_{1} \\le 1 \\text{ and } \\xi_{2} \\le 1)$ to occur, both conditions on $U$ must be satisfied simultaneously: $U \\le \\frac{1}{2}$ and $U \\ge \\frac{1}{2}$. The only real number that satisfies both inequalities is $U = \\frac{1}{2}$. Therefore, the joint event is equivalent to the event that $U$ takes the specific value $\\frac{1}{2}$.\n$$ \\mathbb{P}\\left(\\xi_{1} \\le 1, \\xi_{2} \\le 1\\right) = \\mathbb{P}\\left(U = \\frac{1}{2}\\right) $$\nThe random variable $U$ is specified to have a uniform distribution on the interval $[0,1]$, which is a continuous probability distribution. For any continuous random variable, the probability of it taking on any single, precise value is $0$.\n$$ \\mathbb{P}\\left(U = \\frac{1}{2}\\right) = 0 $$\nThus, the probability of satisfying the joint constraint is $0$.\n\nFinally, we compute $\\Delta$, the difference between the two probabilities:\n$$ \\Delta := \\mathbb{P}\\left(\\xi_{1} + \\xi_{2} \\le 2\\right) - \\mathbb{P}\\left(\\xi_{1} \\le 1,\\ \\xi_{2} \\le 1\\right) $$\nSubstituting the values we have calculated:\n$$ \\Delta = 1 - 0 = 1 $$\nThis result quantifies the error introduced by the aggregation. While the aggregated constraint suggests the solution is perfectly safe (probability of satisfaction is $1$), the true joint probability of satisfaction is $0$, meaning the solution is infeasible under the original, more accurate model.",
            "answer": "$$\\boxed{1}$$"
        }
    ]
}