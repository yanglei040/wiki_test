{
    "hands_on_practices": [
        {
            "introduction": "This practice addresses a fundamental question in stochastic optimization: how must the step size $\\eta_t$ decay over time to guarantee convergence in the presence of noise? You will explore this by analyzing a power-law schedule, $\\eta_t = \\eta_0 t^{-\\alpha}$, and deriving the critical role of the exponent $\\alpha$ in ensuring that the accumulated error from gradient noise diminishes over time. This exercise  solidifies the theoretical underpinnings of the celebrated Robbins-Monro conditions for stochastic approximation.",
            "id": "3185967",
            "problem": "Consider Stochastic Gradient Descent (SGD), defined by the iterative update $x_{t+1} = x_t - \\eta_t g_t$, on the one-dimensional objective $f(x) = \\frac{1}{2}x^2$, where the true gradient is $\\nabla f(x_t) = x_t$. Assume the stochastic gradient is $g_t = x_t + \\xi_t$, where $(\\xi_t)_{t \\geq 0}$ are independent, identically distributed random variables satisfying $\\mathbb{E}[\\xi_t] = 0$ and $\\mathrm{Var}(\\xi_t) = \\sigma^2$, independent of the past. Let the step size schedule be $\\eta_t = \\eta_0 t^{-\\alpha}$ with fixed constants $\\eta_0  0$ and $\\alpha \\in (0, \\frac{1}{2})$, and let the initial condition $x_0$ be deterministic and finite.\n\nStarting only from the stated definitions of SGD, the objective and its gradient, and basic properties of variance and expectation, perform the following:\n\n1. Derive a closed recursion for $\\mathbb{E}[x_{t+1}^2]$ in terms of $\\eta_t$, $\\mathbb{E}[x_t^2]$, and $\\sigma^2$.\n2. Using an asymptotic analysis justified by the slowly varying step size schedule $\\eta_t = \\eta_0 t^{-\\alpha}$, determine the leading-order behavior of $\\mathbb{E}[x_t^2]$ as $t \\to \\infty$, clarifying how it relates to the instantaneous “noise floor” induced by the stochastic gradient.\n3. Compute the exact value of the scaled limit\n$$\nL \\;=\\; \\lim_{t \\to \\infty} \\frac{t^{\\alpha}\\,\\mathbb{E}[x_t^2]}{\\eta_0 \\sigma^2}.\n$$\n\nYou must present $L$ as a single closed-form constant. No numerical rounding is required. This construction serves as a counterexample showing that for $\\alpha  \\frac{1}{2}$, the sequence exhibits a non-vanishing normalized error floor of order $\\mathcal{O}(\\eta_t \\sigma^2)$ in the sense captured by the limit $L$ above.",
            "solution": "The user wants to analyze the asymptotic behavior of Stochastic Gradient Descent (SGD) on a simple one-dimensional quadratic objective. The analysis will proceed in three parts as requested: deriving a recursion for the second moment of the state, determining its asymptotic behavior, and computing a specific scaled limit.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   SGD update rule: $x_{t+1} = x_t - \\eta_t g_t$\n-   Objective function: $f(x) = \\frac{1}{2}x^2$\n-   True gradient: $\\nabla f(x_t) = x_t$\n-   Stochastic gradient: $g_t = x_t + \\xi_t$\n-   Noise process $(\\xi_t)_{t \\geq 0}$: independent, identically distributed (i.i.d.) random variables.\n-   Noise properties: $\\mathbb{E}[\\xi_t] = 0$ and $\\mathrm{Var}(\\xi_t) = \\mathbb{E}[\\xi_t^2] - (\\mathbb{E}[\\xi_t])^2 = \\sigma^2$. Since $\\mathbb{E}[\\xi_t]=0$, this implies $\\mathbb{E}[\\xi_t^2] = \\sigma^2$. The noise is independent of the past, i.e., of $x_0, x_1, \\dots, x_t$.\n-   Step size schedule: $\\eta_t = \\eta_0 t^{-\\alpha}$ for constants $\\eta_0  0$ and $\\alpha \\in (0, \\frac{1}{2})$.\n-   Initial condition: $x_0$ is a deterministic and finite value.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is a standard, fundamental exercise in the analysis of stochastic optimization algorithms, specifically SGD. The setup is a canonical model used in textbooks and research papers to understand the convergence properties of SGD.\n-   **Well-Posed:** The problem is well-posed. All variables and parameters are clearly defined, and the constraints on them (e.g., $\\alpha \\in (0, \\frac{1}{2})$) are specified. The tasks are precise mathematical objectives leading to a unique answer.\n-   **Objective:** The problem is stated in precise, formal mathematical language, free of ambiguity or subjective claims.\n\n**Step 3: Verdict and Action**\nThe problem is valid as it is scientifically grounded, well-posed, and objective. I will proceed with the solution.\n\n### Part 1: Derivation of the Recursion for $\\mathbb{E}[x_{t+1}^2]$\n\nWe begin with the SGD update rule:\n$$\nx_{t+1} = x_t - \\eta_t g_t\n$$\nSubstitute the expression for the stochastic gradient $g_t = x_t + \\xi_t$:\n$$\nx_{t+1} = x_t - \\eta_t (x_t + \\xi_t) = (1 - \\eta_t)x_t - \\eta_t \\xi_t\n$$\nNext, we square both sides of the equation:\n$$\nx_{t+1}^2 = \\left( (1 - \\eta_t)x_t - \\eta_t \\xi_t \\right)^2 = (1 - \\eta_t)^2 x_t^2 - 2(1 - \\eta_t)\\eta_t x_t \\xi_t + \\eta_t^2 \\xi_t^2\n$$\nNow, we take the expectation of both sides. Let $\\mathcal{F}_t$ be the sigma-algebra generated by the history of the process up to time $t$, i.e., $\\sigma(x_0, \\xi_0, \\dots, \\xi_{t-1})$. The iterate $x_t$ is measurable with respect to $\\mathcal{F}_t$. We use the law of total expectation, $\\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[Y | \\mathcal{F}_t]]$.\n$$\n\\mathbb{E}[x_{t+1}^2] = \\mathbb{E}\\left[ (1 - \\eta_t)^2 x_t^2 - 2(1 - \\eta_t)\\eta_t x_t \\xi_t + \\eta_t^2 \\xi_t^2 \\right]\n$$\nBy linearity of expectation:\n$$\n\\mathbb{E}[x_{t+1}^2] = (1 - \\eta_t)^2 \\mathbb{E}[x_t^2] - 2(1 - \\eta_t)\\eta_t \\mathbb{E}[x_t \\xi_t] + \\eta_t^2 \\mathbb{E}[\\xi_t^2]\n$$\nWe evaluate the expectation terms involving the noise $\\xi_t$.\nFor the cross-term $\\mathbb{E}[x_t \\xi_t]$, we condition on the past:\n$$\n\\mathbb{E}[x_t \\xi_t] = \\mathbb{E}[\\mathbb{E}[x_t \\xi_t | \\mathcal{F}_t]] = \\mathbb{E}[x_t \\mathbb{E}[\\xi_t | \\mathcal{F}_t]]\n$$\nSince $\\xi_t$ is independent of the past, $\\mathbb{E}[\\xi_t | \\mathcal{F}_t] = \\mathbb{E}[\\xi_t] = 0$. Thus:\n$$\n\\mathbb{E}[x_t \\xi_t] = \\mathbb{E}[x_t \\cdot 0] = 0\n$$\nFor the noise variance term, we are given $\\mathbb{E}[\\xi_t]=0$ and $\\mathrm{Var}(\\xi_t)=\\sigma^2$, so:\n$$\n\\mathbb{E}[\\xi_t^2] = \\mathrm{Var}(\\xi_t) + (\\mathbb{E}[\\xi_t])^2 = \\sigma^2 + 0^2 = \\sigma^2\n$$\nSubstituting these results back into the equation for $\\mathbb{E}[x_{t+1}^2]$:\n$$\n\\mathbb{E}[x_{t+1}^2] = (1 - \\eta_t)^2 \\mathbb{E}[x_t^2] + \\eta_t^2 \\sigma^2\n$$\nExpanding the squared term $(1-\\eta_t)^2 = 1 - 2\\eta_t + \\eta_t^2$, we obtain the final closed recursion:\n$$\n\\mathbb{E}[x_{t+1}^2] = (1 - 2\\eta_t + \\eta_t^2) \\mathbb{E}[x_t^2] + \\eta_t^2 \\sigma^2\n$$\n\n### Part 2: Asymptotic Analysis of $\\mathbb{E}[x_t^2]$\n\nLet $w_t = \\mathbb{E}[x_t^2]$. The recursion is:\n$$\nw_{t+1} = (1 - 2\\eta_t + \\eta_t^2) w_t + \\eta_t^2 \\sigma^2\n$$\nThis can be rewritten as a difference equation:\n$$\nw_{t+1} - w_t = (-2\\eta_t + \\eta_t^2) w_t + \\eta_t^2 \\sigma^2\n$$\nThe problem states that the step size schedule $\\eta_t = \\eta_0 t^{-\\alpha}$ is \"slowly varying\". This justifies a quasi-stationary analysis. In this regime, the system's state $w_t$ adapts quickly to the slow changes in the parameter $\\eta_t$. We can therefore approximate the asymptotic behavior by finding the \"moving fixed point\" of the dynamics, which corresponds to setting the change $w_{t+1} - w_t$ to zero.\n$$\n0 \\approx (-2\\eta_t + \\eta_t^2) w_t + \\eta_t^2 \\sigma^2\n$$\nSolving for $w_t$:\n$$\n(2\\eta_t - \\eta_t^2) w_t \\approx \\eta_t^2 \\sigma^2\n$$\n$$\nw_t \\approx \\frac{\\eta_t^2 \\sigma^2}{2\\eta_t - \\eta_t^2} = \\frac{\\eta_t \\sigma^2}{2 - \\eta_t}\n$$\nThis expression describes the \"instantaneous noise floor\" mentioned in the problem. It represents the equilibrium level where the drift towards the origin (due to the term $-2\\eta_t w_t$) is balanced by the variance introduced by the stochastic noise (the term $\\eta_t^2 \\sigma^2$) and the higher-order self-correction term $\\eta_t^2 w_t$.\n\nAs $t \\to \\infty$, we have $\\eta_t = \\eta_0 t^{-\\alpha} \\to 0$ since $\\alpha  0$. Therefore, the denominator $2 - \\eta_t \\to 2$. The leading-order asymptotic behavior of $\\mathbb{E}[x_t^2]$ is:\n$$\nw_t = \\mathbb{E}[x_t^2] \\sim \\frac{\\eta_t \\sigma^2}{2} = \\frac{\\eta_0 \\sigma^2}{2} t^{-\\alpha}\n$$\nThis result highlights why the second Robbins-Monro condition ($\\sum \\eta_t^2  \\infty$) is crucial for the error variance to vanish. For the schedule $\\eta_t = \\eta_0 t^{-\\alpha}$, the sum of squares $\\sum_t \\eta_t^2 = \\eta_0^2 \\sum_t t^{-2\\alpha}$ converges only if $2\\alpha  1$ (i.e., $\\alpha  1/2$). In this problem, the condition $\\alpha \\in (0, 1/2)$ means that the step sizes are not square-summable, and this violation leads to a non-vanishing error floor. Our asymptotic analysis precisely captures the magnitude of this floor, showing it decays at the same rate as the step size $\\eta_t$.\n\n### Part 3: Computation of the Scaled Limit $L$\n\nWe are asked to compute the exact value of the scaled limit:\n$$\nL = \\lim_{t \\to \\infty} \\frac{t^{\\alpha}\\,\\mathbb{E}[x_t^2]}{\\eta_0 \\sigma^2}\n$$\nUsing the asymptotic result for $\\mathbb{E}[x_t^2] = w_t$ from Part 2, we substitute the more precise expression $w_t \\approx \\frac{\\eta_t \\sigma^2}{2 - \\eta_t}$ into the limit.\n$$\nL = \\lim_{t \\to \\infty} \\frac{t^{\\alpha} \\left( \\frac{\\eta_t \\sigma^2}{2 - \\eta_t} \\right)}{\\eta_0 \\sigma^2}\n$$\nNow, substitute the definition of the step size, $\\eta_t = \\eta_0 t^{-\\alpha}$:\n$$\nL = \\lim_{t \\to \\infty} \\frac{t^{\\alpha} \\left( \\frac{(\\eta_0 t^{-\\alpha}) \\sigma^2}{2 - \\eta_0 t^{-\\alpha}} \\right)}{\\eta_0 \\sigma^2}\n$$\nThe terms $t^{\\alpha}$ and $t^{-\\alpha}$ in the numerator cancel out:\n$$\nL = \\lim_{t \\to \\infty} \\frac{\\frac{\\eta_0 \\sigma^2}{2 - \\eta_0 t^{-\\alpha}}}{\\eta_0 \\sigma^2}\n$$\nWe can cancel the common factor $\\eta_0 \\sigma^2$:\n$$\nL = \\lim_{t \\to \\infty} \\frac{1}{2 - \\eta_0 t^{-\\alpha}}\n$$\nSince $\\alpha  0$, as $t \\to \\infty$, the term $t^{-\\alpha} \\to 0$. Therefore, the limit is:\n$$\nL = \\frac{1}{2 - 0} = \\frac{1}{2}\n$$\nThe value of the limit is a constant, independent of $\\eta_0$, $\\sigma^2$, and $\\alpha$ (within the specified range). This confirms that for $\\alpha  1/2$, the normalized error $\\frac{\\mathbb{E}[x_t^2]}{\\eta_t \\sigma^2}$ converges to a non-zero constant.",
            "answer": "$$\n\\boxed{\\frac{1}{2}}\n$$"
        },
        {
            "introduction": "Building on the theory of convergence, this computational exercise explores how different step-size schedules perform on more realistic, multi-dimensional problems where the loss function's curvature varies by direction. By implementing and comparing several schedules on quadratic functions with varying eigenvalue spectra , you will gain practical insight into how the largest eigenvalue $\\lambda_{\\max}$ constrains the choice of step size, while the smallest eigenvalue $\\lambda_{\\min}$ often governs the ultimate rate of convergence.",
            "id": "3185955",
            "problem": "Consider minimizing a strictly convex quadratic objective using Stochastic Gradient Descent (SGD). Let the objective be defined by the symmetric positive definite (SPD) matrix $Q \\in \\mathbb{R}^{d \\times d}$, with the loss function $f(x) = \\tfrac{1}{2} x^{\\top} Q x$. The classical gradient descent iteration is $x_{t+1} = x_t - \\eta_t \\nabla f(x_t)$, where $\\eta_t$ is the step size at iteration $t$. For analysis, assume that stochasticity is negligible and focus on the deterministic contraction along each eigendirection of $Q$.\n\nStarting from the fundamental behavior of linear iterations and the spectral decomposition of $Q$, determine the largest constant step size $\\eta_{\\mathrm{safe}}$ that guarantees asymptotic stability of the iteration across all eigendirections. Then, compare how three step-size schedules affect the decay of error components aligned with the smallest and largest eigenvalues of $Q$:\n- Constant schedule: $\\eta_t = \\eta_0$, with $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$.\n- Inverse-time schedule: $\\eta_t = \\dfrac{\\eta_0}{1 + t}$, with $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$.\n- Exponential schedule: $\\eta_t = \\eta_0 \\cdot \\gamma^{t}$, with $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$ and fixed $\\gamma = 0.9$.\n\nUse the following principle to quantify decay speed per eigendirection: if $y_t$ denotes the error component along an eigendirection with eigenvalue $\\lambda$, then the per-step linear contraction factor is $|1 - \\eta_t \\lambda|$. Define the half-life $H(\\lambda)$ for a schedule as the smallest nonnegative integer $t$ such that $\\prod_{\\tau=0}^{t-1} |1 - \\eta_{\\tau} \\lambda| \\leq 0.5$. If this condition does not occur within a finite horizon $T_{\\max}$, report $-1$. Use $T_{\\max} = 200$ and the fixed exponential decay parameter $\\gamma = 0.9$ in all test cases.\n\nYour task is to:\n1. Derive $\\eta_{\\mathrm{safe}}$ from first principles of linear stability for gradient descent on an SPD quadratic in terms of the spectrum of $Q$.\n2. For each test case, compute $\\eta_{\\mathrm{safe}}$ and the half-lives for the smallest eigenvalue $\\lambda_{\\min}$ and the largest eigenvalue $\\lambda_{\\max}$ under each of the three schedules described above, with $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$.\n3. Ensure per-iteration stability of the schedules; if a schedule violates the stability condition at any iteration within $[0, T_{\\max}-1]$, still compute the half-life using the definition above. The half-life definition already accounts for oscillatory but contracting behavior via the absolute value.\n\nImplement a program that performs this computation for the following test suite of spectra and scaling parameters:\n- Test case $1$: eigenvalues $[1.0, 1.0, 1.0, 100.0]$, $\\rho = 0.9$.\n- Test case $2$: eigenvalues $[1.0, 2.0, 3.0, 4.0]$, $\\rho = 0.9$.\n- Test case $3$: eigenvalues $[0.01, 0.05, 0.1, 10.0]$, $\\rho = 0.5$.\n- Test case $4$: eigenvalues $[5.0, 5.0, 5.0]$, $\\rho = 0.9$.\n- Test case $5$: eigenvalues $[1.0, 1000.0]$, $\\rho = 0.9$.\n\nFor each test case, output a nested list containing:\n$[\\eta_{\\mathrm{safe}}, H_{\\min}^{\\text{const}}, H_{\\max}^{\\text{const}}, H_{\\min}^{\\text{inv}}, H_{\\max}^{\\text{inv}}, H_{\\min}^{\\text{exp}}, H_{\\max}^{\\text{exp}}]$,\nwhere $H_{\\min}^{\\cdot}$ and $H_{\\max}^{\\cdot}$ denote the half-lives for the smallest and largest eigenvalues under the specified schedule.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[ [\\ldots], [\\ldots], \\ldots ]$). No external input is required, and there are no physical units. All angles, if any, are irrelevant to this problem.",
            "solution": "The user wants to analyze the convergence of gradient descent on a strictly convex quadratic objective function $f(x) = \\tfrac{1}{2} x^{\\top} Q x$, where $Q$ is a symmetric positive definite (SPD) matrix. The analysis focuses on the deterministic update rule $x_{t+1} = x_t - \\eta_t \\nabla f(x_t)$, ignoring stochastic effects.\n\n### Step 1: Derivation of the Safe Step Size $\\eta_{\\mathrm{safe}}$\n\nThe gradient of the objective function is $\\nabla f(x) = Qx$. The gradient descent iteration is therefore:\n$$\nx_{t+1} = x_t - \\eta_t Q x_t = (I - \\eta_t Q) x_t\n$$\nThe unique minimizer of this strongly convex function is $x^* = 0$. Thus, the vector $x_t$ also represents the error at iteration $t$. The convergence of the method depends on the behavior of the operator $(I - \\eta_t Q)$.\n\nTo analyze this, we perform a change of basis to the eigenbasis of $Q$. Since $Q$ is real and symmetric, it admits a spectral decomposition $Q = V \\Lambda V^\\top$, where $V$ is an orthogonal matrix whose columns are the eigenvectors $v_i$ of $Q$, and $\\Lambda$ is a diagonal matrix containing the corresponding real eigenvalues $\\lambda_i$. Since $Q$ is positive definite, all its eigenvalues are strictly positive, i.e., $\\lambda_i  0$ for all $i$.\n\nLet us define the error in the eigenbasis as $z_t = V^\\top x_t$. Then $x_t = V z_t$. Substituting this into the iteration equation gives:\n$$\nV z_{t+1} = (I - \\eta_t V \\Lambda V^\\top) V z_t\n$$\nMultiplying by $V^\\top$ from the left and using the orthogonality of $V$ (i.e., $V^\\top V = I$), we simplify the expression:\n$$\nz_{t+1} = V^\\top (V I V^\\top - \\eta_t V \\Lambda V^\\top) V z_t = (V^\\top V I V^\\top V - \\eta_t V^\\top V \\Lambda V^\\top V) z_t = (I - \\eta_t \\Lambda) z_t\n$$\nThis decouples the dynamics of the error into $d$ independent scalar equations, one for each component $z_{t,i}$ corresponding to the eigenvalue $\\lambda_i$:\n$$\nz_{t+1, i} = (1 - \\eta_t \\lambda_i) z_{t, i}\n$$\nFor the iteration to be asymptotically stable with a constant step size $\\eta_t = \\eta  0$, the error must contract at each step for every component. This requires the magnitude of the contraction factor to be strictly less than $1$ for all $i$:\n$$\n|1 - \\eta \\lambda_i|  1\n$$\nThis inequality is equivalent to the tandem conditions $-1  1 - \\eta \\lambda_i$ and $1 - \\eta \\lambda_i  1$.\nThe second condition, $1 - \\eta \\lambda_i  1$, simplifies to $-\\eta \\lambda_i  0$. As $\\eta  0$ and $\\lambda_i  0$, this is always satisfied.\nThe first condition, $-1  1 - \\eta \\lambda_i$, simplifies to $\\eta \\lambda_i  2$, which means $\\eta  \\frac{2}{\\lambda_i}$.\n\nFor the iteration to be stable for any initial condition, this must hold for all eigenvalues $\\lambda_i$. The most stringent constraint is imposed by the largest eigenvalue, $\\lambda_{\\max} = \\max_i \\lambda_i$. Therefore, the step size must satisfy:\n$$\n\\eta  \\frac{2}{\\lambda_{\\max}}\n$$\nThe problem asks for the largest constant step size $\\eta_{\\mathrm{safe}}$ that guarantees asymptotic stability. This corresponds to the supremum of the allowable range for $\\eta$. Thus, we define:\n$$\n\\eta_{\\mathrm{safe}} = \\frac{2}{\\lambda_{\\max}}\n$$\n\n### Step 2: Half-Life Calculation for Different Schedules\n\nThe decay of the error component along the $i$-th eigendirection over $t$ steps is given by the cumulative product of the per-step contraction factors:\n$$\nP_t(\\lambda_i) = \\prod_{\\tau=0}^{t-1} |1 - \\eta_{\\tau} \\lambda_i|\n$$\nThe half-life, $H(\\lambda)$, is defined as the smallest non-negative integer $t$ such that $P_t(\\lambda) \\leq 0.5$. We are asked to compute this for the smallest eigenvalue, $\\lambda_{\\min}$, and the largest eigenvalue, $\\lambda_{\\max}$, for three different step-size schedules, all derived from a base step size $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$. A maximum iteration horizon $T_{\\max} = 200$ is imposed.\n\nThe schedules are:\n1.  **Constant Schedule**: $\\eta_t = \\eta_0$. The contraction factor is constant for a given $\\lambda$.\n2.  **Inverse-Time Schedule**: $\\eta_t = \\frac{\\eta_0}{1 + t}$. The step size decays, so the contraction factor $|1 - \\eta_t \\lambda|$ approaches $1$ as $t \\to \\infty$. This implies slower convergence at later stages.\n3.  **Exponential Schedule**: $\\eta_t = \\eta_0 \\cdot \\gamma^t$, with $\\gamma = 0.9$. The step size decays exponentially, which is faster than the inverse-time schedule.\n\nThe computational procedure for each test case is as follows:\n1.  Extract $\\lambda_{\\min}$ and $\\lambda_{\\max}$ from the given spectrum.\n2.  Calculate $\\eta_{\\mathrm{safe}} = 2 / \\lambda_{\\max}$.\n3.  Calculate $\\eta_0 = \\rho \\cdot \\eta_{\\mathrm{safe}}$ using the given $\\rho$.\n4.  For each of the three schedules and for each eigenvalue in $\\{\\lambda_{\\min}, \\lambda_{\\max}\\}$:\n    a. Initialize a cumulative product $P = 1.0$.\n    b. Iterate $\\tau$ from $0$ to $T_{\\max}-1$.\n    c. In each iteration, compute the step size $\\eta_{\\tau}$ according to the schedule.\n    d. Update the product: $P \\leftarrow P \\cdot |1 - \\eta_{\\tau} \\lambda|$.\n    e. If $P \\leq 0.5$, the half-life is $\\tau+1$. Record this value and terminate the inner loop for this $(\\lambda, \\text{schedule})$ pair.\n    f. If the loop completes without the condition being met, the half-life is recorded as $-1$.\n5.  Assemble the results for the test case into the specified list format: $[\\eta_{\\mathrm{safe}}, H_{\\min}^{\\text{const}}, H_{\\max}^{\\text{const}}, H_{\\min}^{\\text{inv}}, H_{\\max}^{\\text{inv}}, H_{\\min}^{\\text{exp}}, H_{\\max}^{\\text{exp}}]$.\nThis procedure is implemented for each provided test case.",
            "answer": "```python\nimport numpy as np\n\ndef calculate_half_life(lambda_val: float, schedule_name: str, eta_0: float, T_max: int, gamma: float) - int:\n    \"\"\"\n    Calculates the half-life for a given eigenvalue and step-size schedule.\n\n    The half-life is the smallest integer t such that the cumulative product of\n    contraction factors is = 0.5.\n\n    Args:\n        lambda_val: The eigenvalue.\n        schedule_name: The name of the schedule ('const', 'inv', 'exp').\n        eta_0: The initial step size.\n        T_max: The maximum number of iterations to check.\n        gamma: The decay factor for the exponential schedule.\n\n    Returns:\n        The half-life as an integer, or -1 if not reached within T_max.\n    \"\"\"\n    cumulative_product = 1.0\n    for t_idx in range(T_max):\n        eta_t = 0.0\n        if schedule_name == 'const':\n            eta_t = eta_0\n        elif schedule_name == 'inv':\n            eta_t = eta_0 / (1.0 + t_idx)\n        elif schedule_name == 'exp':\n            eta_t = eta_0 * (gamma ** t_idx)\n        \n        contraction_factor = abs(1.0 - eta_t * lambda_val)\n        cumulative_product *= contraction_factor\n        \n        if cumulative_product = 0.5:\n            return t_idx + 1\n            \n    return -1\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        # (eigenvalues, rho)\n        ([1.0, 1.0, 1.0, 100.0], 0.9),\n        ([1.0, 2.0, 3.0, 4.0], 0.9),\n        ([0.01, 0.05, 0.1, 10.0], 0.5),\n        ([5.0, 5.0, 5.0], 0.9),\n        ([1.0, 1000.0], 0.9),\n    ]\n\n    T_max = 200\n    gamma = 0.9\n\n    results = []\n    for eigenvalues, rho in test_cases:\n        lambda_min = min(eigenvalues)\n        lambda_max = max(eigenvalues)\n        \n        # 1. Derive eta_safe from first principles.\n        # Stability requires |1 - eta*lambda|  1 for all eigenvalues lambda.\n        # This implies eta  2/lambda for all lambda.\n        # The tightest constraint is from lambda_max, so eta  2/lambda_max.\n        # eta_safe is the supremum of this range.\n        eta_safe = 2.0 / lambda_max\n        \n        eta_0 = rho * eta_safe\n        \n        # 2. Compute half-lives for the three schedules.\n        \n        # Constant schedule\n        H_min_const = calculate_half_life(lambda_min, 'const', eta_0, T_max, gamma)\n        H_max_const = calculate_half_life(lambda_max, 'const', eta_0, T_max, gamma)\n        \n        # Inverse-time schedule\n        H_min_inv = calculate_half_life(lambda_min, 'inv', eta_0, T_max, gamma)\n        H_max_inv = calculate_half_life(lambda_max, 'inv', eta_0, T_max, gamma)\n\n        # Exponential schedule\n        H_min_exp = calculate_half_life(lambda_min, 'exp', eta_0, T_max, gamma)\n        H_max_exp = calculate_half_life(lambda_max, 'exp', eta_0, T_max, gamma)\n        \n        case_result = [eta_safe, H_min_const, H_max_const, H_min_inv, H_max_inv, H_min_exp, H_max_exp]\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "This advanced practice moves from using pre-defined schedules to learning them automatically, a technique at the heart of modern meta-learning. You will tackle an optimization problem where the parameters of the step-size schedule itself are the variables to be learned. This involves deriving and implementing a reverse-mode differentiation algorithm from first principles to compute the required \"hypergradients\" , providing a hands-on look inside the mechanics of powerful automatic differentiation frameworks.",
            "id": "3185953",
            "problem": "You are given a deterministic, finite-horizon unrolled optimization using Stochastic Gradient Descent (SGD), where the goal is to learn a step-size schedule by optimizing schedule parameters through hypergradients. Consider the convex quadratic objective in $\\mathbb{R}^3$ defined by\n$$\nf(x) = \\frac{1}{2} x^\\top A x - b^\\top x,\n$$\nwhere $A \\in \\mathbb{R}^{3 \\times 3}$ is symmetric positive definite and $b \\in \\mathbb{R}^3$. The state is updated for $T$ iterations according to the stochastic gradient descent rule\n$$\nx_{t+1} = x_t - \\eta_t(\\theta)\\big(\\nabla f(x_t) + \\xi_t\\big),\n$$\nwhere $\\nabla f(x_t) = A x_t - b$, $\\xi_t \\in \\mathbb{R}^3$ is a fixed stochastic perturbation independent of $\\theta$, and the step-size schedule is parameterized by\n$$\n\\eta_t(\\theta) = \\frac{\\exp(\\theta_0)}{1 + \\exp(\\theta_1)\\, t}, \\quad \\theta = (\\theta_0,\\theta_1) \\in \\mathbb{R}^2.\n$$\nThe schedule learning objective is to adjust $\\theta$ to minimize $f(x_T(\\theta))$ by using the hypergradient $\\nabla_\\theta f(x_T(\\theta))$ that results from differentiating through the unrolled $T$ updates.\n\nStarting only from (i) the definition of Stochastic Gradient Descent (SGD), (ii) the chain rule for differentiation, and (iii) the symmetry and positive definiteness of $A$, perform the following:\n\n1. Derive, from first principles, a reverse-mode computation for the hypergradient $\\nabla_\\theta f(x_T(\\theta))$ without using any automatic differentiation software. Your derivation must explicitly show how to propagate adjoints for the state variables backward in time and how to accumulate the gradient contributions with respect to the schedule parameters $\\theta$.\n\n2. Implement a program that:\n   - Simulates the $T$ updates from an initial condition $x_0 = 0$ using the given schedule $\\eta_t(\\theta)$, a fixed matrix $A$, and vector $b$.\n   - Computes $\\nabla_\\theta f(x_T(\\theta))$ via the derived reverse-mode hypergradient.\n   - Verifies correctness by computing a central finite-difference approximation to $\\nabla_\\theta f(x_T(\\theta))$ using the same fixed noise sequence $\\{\\xi_t\\}_{t=0}^{T-1}$, and returns the Euclidean norm of the difference between the reverse-mode hypergradient and its finite-difference approximation.\n   - Quantifies computational overhead as the ratio of the number of dense matrix-vector multiplications required to compute the hypergradient versus the number required to compute only $f(x_T(\\theta))$ (i.e., forward simulation and final objective evaluation). Assume $A$ is used as a dense matrix, count each multiplication by $A$ as one unit of cost, and justify the counts you use.\n\n3. Use the following fixed data for all simulations:\n   - Matrix $A$:\n     $$\n     A = \\begin{bmatrix}\n     3  1  0 \\\\\n     1  2  0 \\\\\n     0  0  1.5\n     \\end{bmatrix}\n     $$\n   - Vector $b$:\n     $$\n     b = \\begin{bmatrix}\n     1 \\\\\n     -2 \\\\\n     0.5\n     \\end{bmatrix}\n     $$\n   - Initial condition $x_0 = \\begin{bmatrix}0 \\\\ 0 \\\\ 0\\end{bmatrix}$.\n   - Noise vectors $\\xi_t$ are independent draws from a normal distribution with zero mean and covariance $\\sigma^2 I_3$. The randomness must be held fixed within each test case by using a fixed seed to generate the entire sequence $\\{\\xi_t\\}$ for that case. The noise is independent of $\\theta$.\n\n4. Implement the reverse-mode hypergradient using the backward recurrence derived in part 1. Do not use any automatic differentiation tools.\n\n5. Test Suite. Run your program on the following three parameter sets:\n   - Case 1 (boundary case): $T = 1$, $\\theta = (-1.5, -10.0)$, $\\sigma = 0.0$, noise seed $= 0$.\n   - Case 2 (general case): $T = 50$, $\\theta = (-1.0, 0.5)$, $\\sigma = 0.1$, noise seed $= 1$.\n   - Case 3 (long-horizon case): $T = 200$, $\\theta = (-2.0, -0.2)$, $\\sigma = 0.05$, noise seed $= 2$.\n\n6. For each case, your program must output two floating-point numbers:\n   - The Euclidean norm of the difference between the reverse-mode hypergradient and the central finite-difference approximation.\n   - The computational overhead ratio as defined above.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order\n$$\n[\\Delta_1, R_1, \\Delta_2, R_2, \\Delta_3, R_3],\n$$\nwhere $\\Delta_i$ is the Euclidean norm difference and $R_i$ is the overhead ratio for case $i$.",
            "solution": "The user-provided problem has been validated and is determined to be a well-posed, scientifically grounded problem in the field of optimization. The task requires the derivation and implementation of a reverse-mode automatic differentiation algorithm to compute a hypergradient for a step-size schedule in Stochastic Gradient Descent (SGD).\n\nThe solution is presented in two parts: first, a principled derivation of the reverse-mode hypergradient computation, and second, an analysis of the computational overhead.\n\n### Part 1: Derivation of the Reverse-Mode Hypergradient\n\nThe objective is to compute the gradient of the loss function $L(\\theta) = f(x_T(\\theta))$ with respect to the schedule parameters $\\theta = (\\theta_0, \\theta_1)$. The loss function is defined as $f(x) = \\frac{1}{2} x^\\top A x - b^\\top x$, and the final state $x_T$ is the result of $T$ SGD iterations. The gradient of $f$ with respect to its input $x$ is $\\nabla_x f(x) = Ax - b$.\n\nThe SGD update rule is given by\n$$x_{t+1} = x_t - \\eta_t(\\theta) g_t,$$\nfor $t = 0, 1, \\dots, T-1$, where $x_0=0$, $g_t = \\nabla f(x_t) + \\xi_t = Ax_t - b + \\xi_t$, and the step-size $\\eta_t(\\theta)$ is a function of $\\theta$.\n\nBy the chain rule, a change in $\\theta$ induces a change in the final loss $L$ as follows:\n$$\\nabla_\\theta L(\\theta) = \\left(\\frac{\\partial x_T}{\\partial \\theta}\\right)^\\top \\nabla_{x_T} f(x_T).$$\nHere, $\\frac{\\partial x_T}{\\partial \\theta}$ is the Jacobian matrix of the final state $x_T$ with respect to the parameters $\\theta$. Computing this Jacobian explicitly (forward-mode differentiation) can be inefficient. Reverse-mode differentiation avoids this by propagating gradients backward in time.\n\nLet's define the adjoint state vector $p_t \\in \\mathbb{R}^3$ as the sensitivity of the final loss $L$ with respect to the state $x_t$:\n$$p_t = \\left(\\frac{\\partial x_T}{\\partial x_t}\\right)^\\top \\nabla_{x_T} f(x_T).$$\nBy definition, the adjoint at the final time $T$ is the gradient of the loss with respect to the final state:\n$$p_T = \\left(\\frac{\\partial x_T}{\\partial x_T}\\right)^\\top \\nabla_{x_T} f(x_T) = I^\\top \\nabla_{x_T} f(x_T) = A x_T - b.$$\n\nWe can derive a backward recurrence for the adjoints. From the state update rule, we find the Jacobian of the state transition:\n$$\\frac{\\partial x_{t+1}}{\\partial x_t} = \\frac{\\partial}{\\partial x_t} \\left(x_t - \\eta_t(\\theta)(Ax_t - b + \\xi_t)\\right) = I - \\eta_t(\\theta) A.$$\nUsing the chain rule for the adjoints:\n$$p_t = \\left(\\frac{\\partial x_T}{\\partial x_t}\\right)^\\top p_T = \\left(\\frac{\\partial x_{t+1}}{\\partial x_t} \\cdot \\frac{\\partial x_T}{\\partial x_{t+1}}\\right)^\\top p_T = \\left(\\frac{\\partial x_{t+1}}{\\partial x_t}\\right)^\\top \\left(\\frac{\\partial x_T}{\\partial x_{t+1}}\\right)^\\top p_T = \\left(\\frac{\\partial x_{t+1}}{\\partial x_t}\\right)^\\top p_{t+1}.$$\nSubstituting the Jacobian and using the symmetry of matrix $A$ ($A=A^\\top$):\n$$p_t = (I - \\eta_t A)^\\top p_{t+1} = (I - \\eta_t A) p_{t+1} = p_{t+1} - \\eta_t A p_{t+1}.$$\nThis recurrence allows us to compute $p_t$ for $t = T-1, \\dots, 0$, starting from $p_T$.\n\nNow, we can compute the gradient of the loss with respect to the parameters $\\theta$. The total derivative of $L$ is a sum of contributions from each time step where $\\theta$ has a direct influence. In this problem, $\\theta$ influences each state update through the step size $\\eta_t$.\nThe gradient of $L$ with respect to a component $\\theta_j$ is given by\n$$\\frac{\\partial L}{\\partial \\theta_j} = \\sum_{t=0}^{T-1} \\left(\\frac{\\partial L}{\\partial x_{t+1}}\\right)^\\top \\frac{\\partial x_{t+1}}{\\partial \\theta_j},$$\nwhere $\\frac{\\partial L}{\\partial x_{t+1}}$ represents the partial derivative holding later states fixed, which is precisely our adjoint $p_{t+1}^\\top$. The term $\\frac{\\partial x_{t+1}}{\\partial \\theta_j}$ is the partial derivative of the update rule with respect to $\\theta_j$, holding $x_t$ fixed:\n$$\\frac{\\partial x_{t+1}}{\\partial \\theta_j} = \\frac{\\partial}{\\partial \\theta_j} \\left(x_t - \\eta_t(\\theta) g_t\\right) = -g_t \\frac{\\partial \\eta_t(\\theta)}{\\partial \\theta_j}.$$\nCombining these, we get the expression for the hypergradient components:\n$$\\frac{\\partial L}{\\partial \\theta_j} = -\\sum_{t=0}^{T-1} (p_{t+1}^\\top g_t) \\frac{\\partial \\eta_t}{\\partial \\theta_j}.$$\n\nWe need the partial derivatives of the step-size function $\\eta_t(\\theta) = \\frac{\\exp(\\theta_0)}{1 + t \\exp(\\theta_1)}$:\n1.  For $\\theta_0$:\n    $$\\frac{\\partial \\eta_t}{\\partial \\theta_0} = \\frac{\\exp(\\theta_0)}{1 + t \\exp(\\theta_1)} = \\eta_t.$$\n2.  For $\\theta_1$:\n    $$\\frac{\\partial \\eta_t}{\\partial \\theta_1} = \\exp(\\theta_0) \\frac{-1}{(1 + t \\exp(\\theta_1))^2} (t \\exp(\\theta_1)) = -\\eta_t \\frac{t \\exp(\\theta_1)}{1 + t \\exp(\\theta_1)}.$$\n\nSubstituting these into the sum for each component of $\\nabla_\\theta L$:\n$$\\frac{\\partial L}{\\partial \\theta_0} = -\\sum_{t=0}^{T-1} (p_{t+1}^\\top g_t) \\eta_t.$$\n$$\\frac{\\partial L}{\\partial \\theta_1} = -\\sum_{t=0}^{T-1} (p_{t+1}^\\top g_t) \\left(-\\eta_t \\frac{t \\exp(\\theta_1)}{1 + t \\exp(\\theta_1)}\\right) = \\sum_{t=0}^{T-1} (p_{t+1}^\\top g_t) \\eta_t \\frac{t \\exp(\\theta_1)}{1 + t \\exp(\\theta_1)}.$$\n\nThe complete algorithm for computing the hypergradient $\\nabla_\\theta L = \\left(\\frac{\\partial L}{\\partial \\theta_0}, \\frac{\\partial L}{\\partial \\theta_1}\\right)$ is:\n\n1.  **Forward Pass**:\n    *   Initialize $x_0 = 0$.\n    *   For $t = 0, \\dots, T-1$:\n        *   Compute $\\eta_t = \\frac{\\exp(\\theta_0)}{1 + t \\exp(\\theta_1)}$.\n        *   Compute $g_t = Ax_t - b + \\xi_t$.\n        *   Update $x_{t+1} = x_t - \\eta_t g_t$.\n    *   Store the trajectories $\\{x_t\\}_{t=0}^T$ and $\\{g_t\\}_{t=0}^{T-1}$. (Alternatively, store only $\\{x_t\\}$ and recompute $g_t$ in the backward pass).\n\n2.  **Backward Pass**:\n    *   Initialize hypergradient components: $\\nabla_{\\theta_0} L = 0$, $\\nabla_{\\theta_1} L = 0$.\n    *   Initialize the adjoint state: $p_T = Ax_T - b$.\n    *   For $t = T-1, \\dots, 0$:\n        *   Retrieve $g_t$ from storage.\n        *   Compute the scalar term $\\alpha_t = p_{t+1}^\\top g_t$.\n        *   Compute $\\eta_t$ and its derivative-related term.\n        *   Accumulate gradient for $\\theta_0$: $\\nabla_{\\theta_0} L = \\nabla_{\\theta_0} L - \\alpha_t \\eta_t$.\n        *   Accumulate gradient for $\\theta_1$: $\\nabla_{\\theta_1} L = \\nabla_{\\theta_1} L + \\alpha_t \\eta_t \\frac{t \\exp(\\theta_1)}{1 + t \\exp(\\theta_1)}$.\n        *   Propagate the adjoint backward: $p_t = p_{t+1} - \\eta_t A p_{t+1}$.\n\n### Part 2: Computational Overhead Justification\n\nThe computational cost is measured in units of dense matrix-vector multiplications involving the matrix $A$.\n\n**Cost to compute $f(x_T(\\theta))$ (Denominator):** This involves the full forward simulation to obtain $x_T$ and the final evaluation of the objective function.\n1.  **Forward Simulation**: The loop runs $T$ times (for $t=0, \\dots, T-1$). In each iteration, we compute $g_t = Ax_t - b + \\xi_t$, which requires one matrix-vector multiplication ($Ax_t$). Total for simulation: $T$ multiplications.\n2.  **Final Objective Evaluation**: The objective is $f(x_T) = \\frac{1}{2} x_T^\\top A x_T - b^\\top x_T$. This requires computing the vector $A x_T$. Total for evaluation: $1$ multiplication.\nThe total cost for the forward evaluation is therefore $T + 1$ matrix-vector multiplications.\n\n**Cost to compute $\\nabla_\\theta f(x_T(\\theta))$ (Numerator):** This involves the forward pass, initialization of the backward pass, and the backward pass itself.\n1.  **Forward Pass**: Same as above, requires storing intermediate states. Cost: $T$ multiplications.\n2.  **Backward Pass Initialization**: We must compute $p_T = Ax_T - b$. This requires one matrix-vector multiplication ($Ax_T$). Cost: $1$ multiplication.\n3.  **Backward Pass Propagation**: The loop runs $T$ times (for $t=T-1, \\dots, 0$). In each iteration, we compute $p_t = p_{t+1} - \\eta_t A p_{t+1}$, which requires one matrix-vector multiplication ($A p_{t+1}$). Total for propagation: $T$ multiplications.\nThe total cost for the hypergradient computation is $T$ (forward) $+ 1$ (init) $+ T$ (backward) $= 2T + 1$ matrix-vector multiplications.\n\n**Overhead Ratio:** The ratio $R$ of the hypergradient cost to the forward evaluation cost is:\n$$R = \\frac{2T+1}{T+1}.$$\nAs $T \\to \\infty$, this ratio approaches $2$, indicating that the gradient computation is only about twice as expensive as the function evaluation, a key advantage of reverse-mode differentiation.\nFor the specific cases:\n-   Case 1 ($T=1$): $R = (2(1)+1)/(1+1) = 3/2 = 1.5$.\n-   Case 2 ($T=50$): $R = (2(50)+1)/(50+1) = 101/51 \\approx 1.9804$.\n-   Case 3 ($T=200$): $R = (2(200)+1)/(200+1) = 401/201 \\approx 1.9950$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for hypergradient computation.\n    \"\"\"\n    # Fixed data from the problem statement\n    A = np.array([\n        [3.0, 1.0, 0.0],\n        [1.0, 2.0, 0.0],\n        [0.0, 0.0, 1.5]\n    ])\n    b = np.array([1.0, -2.0, 0.5])\n    \n    # Test suite from the problem statement\n    test_cases = [\n        # (T, theta, sigma, seed)\n        (1, np.array([-1.5, -10.0]), 0.0, 0),\n        (50, np.array([-1.0, 0.5]), 0.1, 1),\n        (200, np.array([-2.0, -0.2]), 0.05, 2),\n    ]\n\n    results = []\n\n    for T, theta, sigma, seed in test_cases:\n        # Generate the fixed noise sequence for this case\n        np_rng = np.random.default_rng(seed)\n        xi_sequence = np_rng.normal(0, sigma, size=(T, 3))\n\n        # Compute hypergradient using the derived reverse-mode algorithm\n        grad_rm = compute_hypergradient_reverse_mode(T, theta, A, b, xi_sequence)\n\n        # Compute hypergradient using central finite differences for verification\n        grad_fd = compute_hypergradient_finite_diff(T, theta, A, b, xi_sequence)\n        \n        # Calculate the Euclidean norm of the difference\n        delta = np.linalg.norm(grad_rm - grad_fd)\n\n        # Calculate the computational overhead ratio\n        # Numerator (Hypergradient cost): T (forward) + 1 (p_T) + T (backward) = 2T + 1\n        # Denominator (Forward eval cost): T (simulation) + 1 (f(x_T)) = T + 1\n        ratio = (2 * T + 1) / (T + 1)\n\n        results.extend([delta, ratio])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef step_size_schedule(t, theta):\n    \"\"\"Computes the step size eta_t(theta).\"\"\"\n    return np.exp(theta[0]) / (1.0 + t * np.exp(theta[1]))\n\ndef objective_function(x, A, b):\n    \"\"\"Computes the objective function f(x).\"\"\"\n    return 0.5 * x.T @ A @ x - b.T @ x\n\ndef simulate_sgd(T, theta, A, b, xi_sequence):\n    \"\"\"Performs the forward simulation of SGD.\"\"\"\n    dim = A.shape[0]\n    x_traj = np.zeros((T + 1, dim))\n    g_traj = np.zeros((T, dim))\n    \n    x = np.zeros(dim) # x_0 = 0\n    x_traj[0] = x\n    \n    for t in range(T):\n        eta_t = step_size_schedule(t, theta)\n        g_t = A @ x - b + xi_sequence[t]\n        \n        x = x - eta_t * g_t\n        \n        x_traj[t + 1] = x\n        g_traj[t] = g_t\n        \n    return x_traj, g_traj\n\ndef compute_hypergradient_reverse_mode(T, theta, A, b, xi_sequence):\n    \"\"\"Computes the hypergradient via the derived reverse-mode algorithm.\"\"\"\n    # 1. Forward Pass\n    x_traj, g_traj = simulate_sgd(T, theta, A, b, xi_sequence)\n    x_T = x_traj[-1]\n    \n    # 2. Backward Pass\n    grad_theta = np.zeros(2)\n    \n    # Initialize adjoint state\n    p = A @ x_T - b  # p_T\n    \n    for t in range(T - 1, -1, -1):\n        # Retrieve needed values\n        g_t = g_traj[t]\n        eta_t = step_size_schedule(t, theta)\n        \n        # Compute scalar term\n        alpha_t = p.T @ g_t\n        \n        # Accumulate gradients for theta_0 and theta_1\n        grad_theta[0] -= alpha_t * eta_t\n        if t  0: # The term for theta_1 is zero when t=0\n             grad_theta[1] += alpha_t * eta_t * (t * np.exp(theta[1])) / (1.0 + t * np.exp(theta[1]))\n        \n        # Propagate adjoint\n        p = p - eta_t * (A.T @ p) # A.T = A since A is symmetric\n        \n    return grad_theta\n\ndef compute_hypergradient_finite_diff(T, theta, A, b, xi_sequence, h=1e-7):\n    \"\"\"Computes the hypergradient via central finite differences for verification.\"\"\"\n    grad_theta_fd = np.zeros(2)\n    \n    for i in range(2):\n        theta_plus = np.copy(theta)\n        theta_minus = np.copy(theta)\n        \n        theta_plus[i] += h\n        theta_minus[i] -= h\n        \n        # Run forward simulation with perturbed theta, using the *same* noise\n        x_traj_plus, _ = simulate_sgd(T, theta_plus, A, b, xi_sequence)\n        x_T_plus = x_traj_plus[-1]\n        \n        x_traj_minus, _ = simulate_sgd(T, theta_minus, A, b, xi_sequence)\n        x_T_minus = x_traj_minus[-1]\n\n        # Compute objective values\n        f_plus = objective_function(x_T_plus, A, b)\n        f_minus = objective_function(x_T_minus, A, b)\n        \n        # Central difference formula\n        grad_theta_fd[i] = (f_plus - f_minus) / (2 * h)\n        \n    return grad_theta_fd\n\nsolve()\n```"
        }
    ]
}