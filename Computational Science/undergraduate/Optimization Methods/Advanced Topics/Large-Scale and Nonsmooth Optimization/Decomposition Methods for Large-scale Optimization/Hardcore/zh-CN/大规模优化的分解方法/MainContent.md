## 引言
在当今数据驱动的世界中，从复杂的物流[网络调度](@entry_id:276267)、金融投资组合管理，到大型机器学习模型的训练，我们无时无刻不面临着[大规模优化](@entry_id:168142)问题。这些问题的决策变量成千上万，约束条件错综复杂，使得传统的“整体式”求解方法常常因计算量过大或内存不足而变得不切实际。

然而，许多大规模问题并非铁板一块，其内部往往隐藏着特殊的结构，例如由多个相对独立的子系统通过少数共享资源或全局约束耦合而成。如何有效利用这种结构，将一个庞大到难以处理的问题“化整为零，[分而治之](@entry_id:273215)”，正是分解方法所要解决的核心问题，也是优化领域一个深刻而持久的主题。

本文将系统地引导你进入分解方法的世界。我们将分为三个部分：首先，在“原理与机制”一章中，我们将深入剖析几类主流分解方法（如[拉格朗日松弛](@entry_id:635609)、[Dantzig-Wolfe分解](@entry_id:634017)、[Benders分解](@entry_id:635451)和ADMM）的数学基础和算法流程。接着，在“应用与跨学科联系”一章中，我们将通过丰富的案例，展示这些方法如何在运筹管理、经济系统和机器学习等领域解决真实世界的问题。最后，在“动手实践”部分，你将有机会通过编程练习，亲手实现并体验这些强大的算法。通过这趟旅程，你将掌握应对[大规模优化](@entry_id:168142)挑战的核心策略。

## 原理与机制

在“引言”部分，我们已经了解了[大规模优化](@entry_id:168142)问题的普遍性及其对计算方法提出的挑战。许多这类问题，尽管整体规模庞大，但其内部往往呈现出一种特殊的结构：它们可以被看作是由多个较小的、相对独立的子问题组成的，而这些子问题之间通过少数“耦合”或“联动”的约束或变量联系在一起。分解方法的核心思想正是利用这种结构，将一个大规模的、难以直接求解的“[主问题](@entry_id:635509)”分解为一系列易于处理的子问题，并通过一个高层协调机制来[整合子](@entry_id:152047)问题的解，最终得到原问题的解。

本章将深入探讨分解方法的“原理与机制”。我们将从分解思想的三个主要流派——基于价格的分解、基于重构的分解和基于变量分裂的分解——入手，系统地阐述各类方法的数学原理、算法机制及其适用场景。

### 分解思想：化繁为简的核心策略

[大规模优化](@entry_id:168142)问题的一个典型结构是**块可分（block-separable）**[目标函数](@entry_id:267263)与**耦合约束（coupling constraints）**的结合。考虑如下形式的问题：
$$
\min_{x_1, \dots, x_k} \sum_{i=1}^k f_i(x_i) \quad \text{subject to} \quad \sum_{i=1}^k g_i(x_i) \le b
$$
其中，每个 $f_i(x_i)$ 是一个只依赖于局部变量 $x_i$ 的函数。如果没有耦合约束 $\sum_{i=1}^k g_i(x_i) \le b$，这个问题就可以分解为 $k$ 个完全独立的[优化问题](@entry_id:266749)，并行求解。耦合约束的存在打破了这种完全的可分离性，它要求所有子问题的决策必须共同满足一个或多个全局[资源限制](@entry_id:192963)。

另一种常见的结构是目标函数本身就包含耦合变量。例如，考虑一个[最小二乘问题](@entry_id:164198) ：
$$
\min_{x \in \mathbb{R}^n} \sum_{i=1}^k \|A_i x - b_i\|_2^2 \quad \text{subject to} \quad \sum_{i=1}^k D_i x \le d
$$
这里，[目标函数](@entry_id:267263)是多个二次项的和，但每个二次项都依赖于同一个全局变量 $x$。变量 $x$ 成为了所有子目标之间的“耦合”媒介。这种结构在统计学、机器学习和信号处理中非常普遍。

面对这些结构，分解方法提供了系统性的解决方案。我们可以根据其核心机制的不同，将其分为三大类：
1.  **基于价格的分解 (Price-Based Decomposition)**：这种方法通过引入[拉格朗日乘子](@entry_id:142696)（即“价格”）来将耦合约束吸收到[目标函数](@entry_id:267263)中，从而使问题解耦。其代表是**对偶分解 (Dual Decomposition)** 和 **[拉格朗日松弛](@entry_id:635609) (Lagrangian Relaxation)**。
2.  **基于重构的分解 (Reformulation-Based Decomposition)**：这种方法通过对子问题的[可行域](@entry_id:136622)进行数学上的等价重构（例如，用其所有极点的凸组合来表示），将原问题变换为一个等价的、但变量数量巨大的“[主问题](@entry_id:635509)”，然后通过“列生成”等技术来求解。其代表是 **Dantzig-Wolfe 分解**。
3.  **基于变量分裂的分解 (Variable-Splitting Decomposition)**：这种方法通过引入辅助变量和一致性约束来显式地分离问题的不同部分。例如，对于耦合变量问题，可以为每个子问题引入一个局部变量副本，并强制它们与一个全局变量相等。其代表是 **Benders 分解**和**交替方向乘子法 (ADMM)**。

接下来的小节将详细阐述这三大类方法的原理和机制。

### 基于价格的分解：对偶分解与[拉格朗日松弛](@entry_id:635609)

基于价格的分解方法源于一个深刻的经济学直觉：通过为共享的、稀缺的资源设定一个“价格”，可以引导各个独立的决策者（子问题）做出符合全局利益（满足耦合约束）的选择。这个“价格”在数学上就是[拉格朗日对偶](@entry_id:638042)变量。

#### [拉格朗日对偶](@entry_id:638042)与子问题

考虑一个具有可分目标和耦合约束的典型问题 ：
$$
\min_{\\{x_j\\}_{j=1}^J} \sum_{j=1}^{J} f_j(x_j) \quad \text{subject to} \quad \sum_{j=1}^{J} A_j x_j = b
$$
这里，每个 $f_j(x_j)$ 是代理 $j$ 的私有成本，而 $\sum_{j=1}^{J} A_j x_j = b$ 是一个必须共同遵守的全局资源平衡约束。

为了分解这个问题，我们为耦合约束引入[拉格朗日乘子](@entry_id:142696)（或称对偶变量）向量 $\lambda \in \mathbb{R}^m$，并构造**[拉格朗日函数](@entry_id:174593)** $L(\\{x_j\\}, \lambda)$：
$$
L(\\{x_j\\}, \lambda) = \sum_{j=1}^{J} f_j(x_j) + \lambda^T \left(\sum_{j=1}^{J} A_j x_j - b\right)
$$
通过重新整理，我们可以发现该函数在变量 $x_j$ 上是可分的：
$$
L(\\{x_j\\}, \lambda) = \left( \sum_{j=1}^{J} (f_j(x_j) + \lambda^T A_j x_j) \right) - \lambda^T b
$$
接下来，我们定义**对[偶函数](@entry_id:163605)** $g(\lambda)$ 为[拉格朗日函数](@entry_id:174593)关于所有原始变量 $x_j$ 的下确界：
$$
g(\lambda) = \inf_{\\{x_j\\}} L(\\{x_j\\}, \lambda) = \sum_{j=1}^{J} \left( \inf_{x_j} (f_j(x_j) + \lambda^T A_j x_j) \right) - \lambda^T b
$$
这个定义揭示了分解的核心：对于一个给定的价格向量 $\lambda$，计算对[偶函数](@entry_id:163605) $g(\lambda)$ 的值可以分解为 $J$ 个独立的**子问题**。每个代理 $j$ 只需解决自己的局部问题：
$$
\min_{x_j} (f_j(x_j) + \lambda^T A_j x_j)
$$
这个子问题的目标函数可以解释为代理 $j$ 在考虑其私有成本 $f_j(x_j)$ 和使用资源所付出的成本（或得到的补贴） $\lambda^T A_j x_j$ 后的总成本。

**[拉格朗日对偶问题](@entry_id:637210)** (或称[主问题](@entry_id:635509)) 就是最大化对[偶函数](@entry_id:163605)：
$$
\max_{\lambda} g(\lambda)
$$
无论原始问题是否为凸，对[偶函数](@entry_id:163605) $g(\lambda)$ 总是[凹函数](@entry_id:274100)，因此对偶问题是一个凸[优化问题](@entry_id:266749)。在满足一定[正则性条件](@entry_id:166962)（如 Slater 条件）下，强对偶性成立，即原始问题的最优值与[对偶问题](@entry_id:177454)的最优值相等。此时，通过求解对偶问题，我们可以得到原始问题的解。这一过程被称为**[拉格朗日松弛](@entry_id:635609) (Lagrangian Relaxation)**，因为它通过将“硬”约束松弛为目标函数中的“软”惩罚项来获得问题的下界 。

#### 对偶上升法：一个经济学诠释

求解[对偶问题](@entry_id:177454)最直接的方法之一是**对偶上升法 (Dual Ascent)**，这是一种梯度上升算法。对[偶函数](@entry_id:163605) $g(\lambda)$ 的梯度有一个非常优美的形式：
$$
\nabla g(\lambda) = \sum_{j=1}^{J} A_j x_j(\lambda) - b
$$
其中 $x_j(\lambda)$ 是在给定价格 $\lambda$ 下，代理 $j$ 的子问题的最优解。$\nabla g(\lambda)$ 正是耦合约束的**残差 (residual)**，即总资源使用量与可用量之差。

对偶上升法的迭代更新规则为：
$$
\lambda^{k+1} = \lambda^k + \alpha_k \nabla g(\lambda^k) = \lambda^k + \alpha_k \left(\sum_{j=1}^{J} A_j x_j^k - b\right)
$$
其中 $\alpha_k > 0$ 是步长。这个更新规则具有鲜明的经济学意义 ：
- 如果某一资源的总使用量超过了其可用量（例如，$(\sum A_j x_j^k - b)_i > 0$），则该资源的“价格” $\lambda_i$ 就会被调高。
- 反之，如果某一资源有剩余，其价格就会被调低。

这个过程就像一个市场协调机制：中央协调员（算法）发布价格，各代理（子问题）根据价格独立做出最优决策，然后协调员根据资源供需情况调整价格，如此循环往复，直到市场出清（即资源约束被满足，$\nabla g(\lambda) \approx 0$）。此时的最优对偶变量 $\lambda^\star$ 也被称为**影子价格 (shadow price)**，它量化了每单位[资源的边际价值](@entry_id:634589)。

为了使这个过程更具体，让我们考虑一个可分凸二次规划问题 ，其中 $f_i(x_i) = \frac{1}{2} x_i^T Q_i x_i + q_i^T x_i$ ($Q_i$ 为[正定矩阵](@entry_id:155546))。子问题 $\min_{x_i} (f_i(x_i) + \lambda^T A_i x_i)$ 的最优解可以通过设置梯度为零直接求得：
$$
Q_i x_i + q_i + A_i^T \lambda = 0 \implies x_i^*(\lambda) = -Q_i^{-1}(q_i + A_i^T \lambda)
$$
将此解代入梯度表达式，我们便可以实施对偶上升算法。对于这类问题，对偶函数 $g(\lambda)$ 是一个光滑的凹二次函数，可以使用更高效的梯度法（如共轭梯度法）或坐标上升法进行求解 。

### 基于重构的分解：[Dantzig-Wolfe分解](@entry_id:634017)与列生成

Dantzig-Wolfe (DW) 分解是另一种强大的分解技术，主要用于具有特定块角结构（block-angular structure）的线性规划问题。其核心思想不是通过价格来协调，而是通过对子问题[可行域](@entry_id:136622)的几何重构来实现。

考虑如下结构的[线性规划](@entry_id:138188)问题：
$$
\min \sum_{k=1}^{K} c_k^T x_k \quad \text{subject to} \quad \sum_{k=1}^{K} A_k x_k = b, \quad x_k \in X_k \quad \forall k
$$
这里，约束分为两类：耦合约束 $\sum A_k x_k = b$ 和独立的块约束 $x_k \in X_k$。每个 $X_k$ 是一个由线性等式和不等式定义的[多面体](@entry_id:637910)。

#### [主问题](@entry_id:635509)与凸包表示

根据[表示定理](@entry_id:637872)，任何有界多面体（多胞体）内的点都可以表示为其所有**极点 (extreme points)** 的凸组合。即使 $X_k$ 是无界的，其内的任何点也可以表示为极点和**极射线 (extreme rays)** 的组合。为简化讨论，我们假设所有 $X_k$ 都是有界[多胞体](@entry_id:635589)。

令 $\mathcal{P}_k$ 为多胞体 $X_k$ 的所有极点的集合。那么，任何[可行解](@entry_id:634783) $x_k \in X_k$ 都可以被写成：
$$
x_k = \sum_{p \in \mathcal{P}_k} \lambda_{k,p} p, \quad \text{where} \quad \sum_{p \in \mathcal{P}_k} \lambda_{k,p} = 1, \quad \lambda_{k,p} \ge 0
$$
将这个表达式代入原问题，我们就得到了一个关于新变量 $\lambda_{k,p}$ 的等价问题，称为**[主问题](@entry_id:635509) (Master Problem)** ：
$$
\min \sum_{k=1}^{K} \sum_{p \in \mathcal{P}_k} (c_k^T p) \lambda_{k,p}
$$
$$
\text{s.t.} \quad \sum_{k=1}^{K} \sum_{p \in \mathcal{P}_k} (A_k p) \lambda_{k,p} = b \quad (\text{原耦合约束})
$$
$$
\sum_{p \in \mathcal{P}_k} \lambda_{k,p} = 1 \quad \forall k \quad (\text{凸性约束})
$$
$$
\lambda_{k,p} \ge 0 \quad \forall k, p
$$
这个[主问题](@entry_id:635509)的结构非常特殊：它的行数相对较少（等于耦合约束和凸性约束的总数），但列数（变量数）可能极其庞大，因为一个[多面体](@entry_id:637910)的极点数量可能是天文数字。

#### 列生成与[定价子问题](@entry_id:636537)

直接构建并求解完整的[主问题](@entry_id:635509)是不现实的。**列生成 (Column Generation)** 技术应运而生。其思想类似于单纯形法，从一个只包含少数几列（变量）的**受限[主问题](@entry_id:635509) (Restricted Master Problem, RMP)** 开始，然后迭代地寻找并添加能够改进目标函数的“有价值”的新列。

在单纯形法的框架中，一个非基变量是否有价值，取决于其**折算成本 (reduced cost)**是否为负。列生成的关键步骤是**[定价子问题](@entry_id:636537) (pricing subproblem)**，即在庞大的未包含列的集合中，寻找具有最小（最负）折算成本的列。

假设当前 RMP 的最优解给出了耦合约束的[对偶变量](@entry_id:143282) $\pi$ 和第 $k$ 个[凸性](@entry_id:138568)约束的对偶变量 $\phi_k$。对于一个来自块 $k$ 的、由极点 $p \in \mathcal{P}_k$ 定义的潜在列，其折算成本 $\bar{c}_{k,p}$ 为：
$$
\bar{c}_{k,p} = (\text{原成本}) - (\text{对偶变量}) \cdot (\text{列向量}) = (c_k^T p) - (\pi^T (A_k p) + \phi_k) = (c_k - A_k^T \pi)^T p - \phi_k
$$
为了找到对所有 $k$ 和 $p$ 具有最小折算成本的列，我们可以为每个块 $k$ 独立地求解以下[定价子问题](@entry_id:636537) ：
$$
\min_{p \in \mathcal{P}_k} \left\{ (c_k - A_k^T \pi)^T p \right\} - \phi_k
$$
由于线性函数在多面体上的最小值必然在其某个极点上达到，上述问题等价于在整个[可行域](@entry_id:136622) $X_k$ 上求解一个线性规划：
$$
z_k^* = \min_{x_k \in X_k} (c_k - A_k^T \pi)^T x_k
$$
第 $k$ 个块能提供的最小折算成本就是 $z_k^* - \phi_k$。如果对于某个 $k$，我们发现 $z_k^*  \phi_k$，那么该子问题的最优解（一个极点）就构成了一个具有负折算成本的新列，可以被添加到 RMP 中。如果对所有 $k$ 都有 $z_k^* \ge \phi_k$，则说明不存在任何可以改进当前解的列，RMP 的解即为完整[主问题](@entry_id:635509)的最优解。

[定价子问题](@entry_id:636537)本身是一个[优化问题](@entry_id:266749)，其结构取决于 $X_k$ 的定义。在著名的**切削库存问题 (cutting-stock problem)** 中，[定价子问题](@entry_id:636537)是一个**整数背包问题** 。在**[车辆路径问题](@entry_id:636757) (Vehicle Routing Problem, VRP)** 中，[定价子问题](@entry_id:636537)则是一个**资源约束[最短路径问题](@entry_id:273176) (Resource Constrained Shortest Path Problem, RCSPP)** 。

#### 与[切平面](@entry_id:136914)的对偶关系

列生成与另一种重要的[优化算法](@entry_id:147840)——**切平面法 (Cutting-Plane Method)**——之间存在深刻的对偶关系。考虑[主问题](@entry_id:635509) (MP) 的对偶问题 (DP)：
$$
\max \pi^T b + \sum_k \phi_k \quad \text{s.t.} \quad \pi^T A_k p + \phi_k \le c_k^T p \quad \forall p \in \mathcal{P}_k, \forall k
$$
这个对偶问题有 $m+K$ 个变量（$\pi$ 和 $\phi_k$），但有天文数字般的约束（每个极点对应一个）。用[切平面](@entry_id:136914)法求解它，意味着我们从一个松弛了大部分约束的对偶问题开始，然后迭代地寻找并添加当前解所违反的约束。寻找被违反的约束的“分离问题” (separation problem)，正是要找到一个极点 $p$ 使得 $\pi^T A_k p + \phi_k > c_k^T p$，这等价于 $(c_k - A_k^T \pi)^T p - \phi_k  0$。这恰好就是列生成中的[定价子问题](@entry_id:636537)！因此，**对原始问题应用列生成，等价于对其对偶问题应用[切平面](@entry_id:136914)法** 。

#### [整数规划](@entry_id:178386)应用：分支定价法

当原始问题是[整数规划](@entry_id:178386)时，即使求解了[主问题](@entry_id:635509)的 LP 松弛，得到的解 $\lambda_{k,p}$ 也可能是分数值，无法直接对应到整数解。**分支定价法 (Branch-and-Price)** 将列生成嵌入到**分支定界 (Branch-and-Bound)** 框架中来解决这个问题。在分支定界树的每个节点上，我们都通过列生成来求解一个 LP 松弛。

分支定价法的关键和难点在于**分支策略**的设计。一个好的分支规则必须能够有效地分割问题的[解空间](@entry_id:200470)，同时保持[定价子问题](@entry_id:636537)的结构和可解性。直接对[主问题](@entry_id:635509)的变量 $\lambda_r$ 进行分支（例如，令 $\lambda_r = 0$ 或 $\lambda_r=1$）通常效果不佳，因为它针对的是指数多列中的一列，会导致搜索树非常不平衡。一个更有效的策略是基于原始问题中的变量进行分支，例如，在 VRP 中，可以对某条弧 $(i,j)$ 的使用情况进行分支 ：
-   一个分支是 $x_{ij}=0$，即禁止任何路径使用弧 $(i,j)$。这在[定价子问题](@entry_id:636537)中很容易实现，只需在求解 RCSPP [时移](@entry_id:261541)除该弧即可。
-   另一个分支是 $x_{ij}=1$，即强制某条路径必须使用弧 $(i,j)$。这也会相应地修改 RCSPP 的结构。

这种分支方式能更有效地处理分数解，并且与[定价子问题](@entry_id:636537)的结构兼容，是分支定价法中的标准实践。

### 基于变量分裂的分解：[Benders分解](@entry_id:635451)与ADMM

最后一类分解方法的核心思想是通过引入新变量和一致性约束来“分裂”问题，从而[解耦](@entry_id:637294)。

#### [Benders分解](@entry_id:635451)：[主问题](@entry_id:635509)与[割平面](@entry_id:177960)

Benders 分解（或称 Benders' Decomposition）特别适用于那些具有“难”变量（通常是整数或[离散变量](@entry_id:263628)）和“易”变量（通常是连续变量）的[混合整数规划](@entry_id:173755)问题。一旦“难”变量的值被固定，“易”变量上的剩余问题就变得容易求解（例如，变成一个线性规划）。

以一个[两阶段随机规划](@entry_id:635828)或[设施选址问题](@entry_id:172318)为例 ：
1.  **第一阶段 (Master Problem)**：决策者需要做出一些战略性决策，例如决定在哪些位置开设配送中心。这些决策由整数变量 $y$ 表示。
2.  **第二阶段 (Subproblem)**：在给定第一阶段决策 $y$ 的情况下，决策者需要解决一个运营层面的问题，例如以最低成本将货物从已开设的中心运送到各个需求点。这些决策由连续变量 $x$ 表示。

Benders 分解的流程如下：
1.  **[主问题](@entry_id:635509)**：只包含“难”变量 $y$ 和一个辅助变量 $\theta$（用于估计第二阶段的成本）。[主问题](@entry_id:635509)的目标是最小化第一阶段成本加上预估的第二阶段成本。
2.  **迭代**：[主问题](@entry_id:635509)提出一个候选决策 $\bar{y}$。
3.  **子问题**：将 $\bar{y}$ 代入原问题，得到一个关于“易”变量 $x$ 的子问题（通常是 LP）。然后求解这个子问题。

子问题的求解结果会通过其**对偶信息**反馈给[主问题](@entry_id:635509)，形成**Benders [割平面](@entry_id:177960) (Benders cuts)**，从而逐步完善对第二阶段成本的估计。
-   **[最优性割](@entry_id:636431) (Optimality Cut)**：如果子问题有最优解，说明决策 $\bar{y}$ 是可行的。子问题的对偶解可以构造一个关于 $y$ 的[线性不等式](@entry_id:174297)，为第二阶段成本函数 $Q(y)$ 提供一个下界。这个不等式被添加回[主问题](@entry_id:635509)，形式为 $\theta \ge (\text{...}) + (\text{...})y$。这会“切掉”当前高估了收益的解 $(\bar{y}, \bar{\theta})$ 。
-   **[可行性割](@entry_id:637168) (Feasibility Cut)**：如果子问题不可行（例如，开设的中心总容量无法满足总需求），说明决策 $\bar{y}$ 是不可行的。根据 **Farkas 引理**，此时子问题的[对偶问题](@entry_id:177454)是无界的。我们可以从对偶问题的一个**极射线**出发，构造一个只涉及 $y$ 的不等式。这个不等式会从[主问题](@entry_id:635509)的[可行域](@entry_id:136622)中“切掉”不可行的决策 $\bar{y}$ 。

Benders 分解与[拉格朗日松弛](@entry_id:635609)在处理同类问题（如网络设计）时，体现了不同的哲学 。Benders 分解通过在[原始变量](@entry_id:753733)空间中添加[割平面](@entry_id:177960)来逼近问题的[价值函数](@entry_id:144750)，而[拉格朗日松弛](@entry_id:635609)则通过在[对偶空间](@entry_id:146945)中最大化下界来求解。

#### [交替方向乘子法](@entry_id:163024) ([ADMM](@entry_id:163024))

交替方向乘子法 (Alternating Direction Method of Multipliers, [ADMM](@entry_id:163024)) 是近年来非常流行的一种分解算法，它结合了对偶分解和[增广拉格朗日方法](@entry_id:165608)的优点，具有非常好的收敛性和鲁棒性。

ADMM 特别适用于求解如下形式的凸[优化问题](@entry_id:266749)：
$$
\min_{x, z} f(x) + g(z) \quad \text{subject to} \quad Ax + Bz = c
$$
许多问题都可以转化为这种形式。例如，前面提到的耦合变量问题  可以通过引入局部变量 $x_i$ 和全局一致性变量 $z$ 来重写 ：
$$
\min_{\\{x_i\\}, z} \sum_{i=1}^m f_i(x_i) + g(z) \quad \text{subject to} \quad x_i = z, \quad \forall i
$$
其中 $f_i(x_i)$ 是局部目标（如最小二乘损失），$g(z)$ 是施加在全局变量上的正则项（如 $\ell_1$ 范数以鼓励[稀疏性](@entry_id:136793)）。

[ADMM](@entry_id:163024) 的核心是**增广[拉格朗日函数](@entry_id:174593) (Augmented Lagrangian)**，它在标准[拉格朗日函数](@entry_id:174593)的基础上增加了一个二次惩罚项，以增强凸性和改善收敛性：
$$
L_\rho(\\{x_i\\}, z, \\{y_i\\}) = \sum_i f_i(x_i) + g(z) + \sum_i y_i^T(x_i - z) + \frac{\rho}{2}\sum_i \|x_i - z\|_2^2
$$
其中 $\rho0$ 是惩罚参数。ADMM 并不是联合最小化所有变量，而是采用**[交替最小化](@entry_id:198823)**的策略，在一个迭代步中依次更新 $x_i$、 $z$ 和对偶变量 $y_i$：

1.  **$x$-更新**：固定 $z$ 和 $y_i$，求解关于 $x_i$ 的最小化问题。由于 $x_i$ 之间是解耦的，这个步骤可以为所有 $i$ 并行执行。
2.  **$z$-更新**：固定更新后的 $x_i$ 和旧的 $y_i$，求解关于 $z$ 的最小化问题。
3.  **对偶更新**：使用标准的对偶上升法更新[对偶变量](@entry_id:143282) $y_i$。

以共识-稀疏性问题为例 ，其中 $f_i(x_i) = \frac{1}{2}\|A_i x_i - b_i\|_2^2$ 且 $g(z) = \lambda\|z\|_1$：
-   $x_i$-更新是一个无约束的二次规划，有[闭式](@entry_id:271343)解。
-   $z$-更新问题形如 $\min_z (\lambda\|z\|_1 + \frac{m\rho}{2}\|z-v\|_2^2)$。这个问题的解恰好是**[软阈值算子](@entry_id:755010) (soft-thresholding operator)** $S_{\lambda/(m\rho)}(v)$。这揭示了 ADMM 与**[近端算法](@entry_id:174451) (proximal algorithms)** 的深刻联系。[软阈值算子](@entry_id:755010)将 $v$ 中[绝对值](@entry_id:147688)小于阈值的元素压缩到零，从而产生稀疏解。
-   对偶更新则简单地累加约束的残差。

#### ADMM的收敛性与扩展

对于凸问题，[ADMM](@entry_id:163024) 的收敛性理论非常完善，即使在很弱的假设下也能保证收敛。然而，在处理非凸问题时（例如，当 $f(x)$ 或 $g(z)$ 非凸时），标准的 ADMM 可能会发散 。

对一个简单的非凸二次问题应用 [ADMM](@entry_id:163024)，可以通过分析其[迭代矩阵](@entry_id:637346)的谱半径来精确判断其收敛性。当谱半径大于1时，算法会线性发散 。

在实践中，有多种方法可以“拯救”或改善非凸 ADMM 的收敛性：
-   **近端正则化**：在非凸的子问题（例如 $x$-更新）中加入一个近端项，如 $\frac{\tau}{2}\|x-x^k\|^2$，使其变为强凸，从而稳定迭代。
-   **主化-最小化 (Majorization-Minimization)**：将非凸目标函数用一个更易于优化的上界（通常是二次函数）来替代。
-   **自适应惩罚参数**：启发式地调整惩罚参数 $\rho$。一种常见的策略（称为残差平衡）是：当原始残差（如 $\|x^k-z^k\|$）相对于对偶残差较大时，增加 $\rho$ 以加强约束；反之则减小 $\rho$。这种方法在实践中非常有效，但缺乏普适的收敛性保证 。

这些扩展使得 [ADMM](@entry_id:163024) 成为一个不仅理论优美，而且在实践中极其灵活和强大的工具，广泛应用于统计、机器学习、图像处理等领域的[大规模优化](@entry_id:168142)问题中。