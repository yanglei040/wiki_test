{
    "hands_on_practices": [
        {
            "introduction": "Before diving into complex algorithms, it's crucial to understand the landscape of the problems we are trying to solve. When we use Lagrangian relaxation, the resulting dual problem is often not smooth, featuring \"kinks\" or non-differentiable points. This exercise  provides a hands-on exploration of this non-smooth nature, asking you to derive the dual function for a simple piecewise-linear problem. By implementing different subgradient selection rules, you will see firsthand how the concept of a subgradient generalizes the derivative and how different choices at these kinks can lead to different ascent paths toward the optimum.",
            "id": "3116743",
            "problem": "Consider the following convex, separable optimization problem with a single coupling equality constraint, designed to be solved by Lagrangian dual decomposition:\nMinimize over $x \\in \\mathbb{R}^2$:\n$F(x) = f_1(x_1) + f_2(x_2)$\nsubject to the coupling constraint $x_1 + x_2 = b$ and bound constraints $0 \\le x_i \\le 1$ for $i \\in \\{1,2\\}$, where\n$f_i(x_i) = M_i \\cdot \\max\\{0, x_i - s_i\\}$,\nwith parameters $M_1 = 1.5$, $s_1 = 0.2$, $M_2 = 0.5$, $s_2 = 0.8$, and coupling right-hand side $b = 0.6$.\n\nThe Lagrangian is\n$\\mathcal{L}(x,\\lambda) = f_1(x_1) + f_2(x_2) + \\lambda \\,(x_1 + x_2 - b)$,\nand the Lagrangian dual function is\n$d(\\lambda) = \\inf_{0 \\le x_1 \\le 1,\\,0 \\le x_2 \\le 1} \\mathcal{L}(x,\\lambda)$.\nBecause the problem is separable in the blocks $x_1$ and $x_2$, the infimum decomposes into the sum of two scalar infima plus an affine term. This decomposition generally yields a concave, piecewise linear $d(\\lambda)$ that can be nondifferentiable at certain multipliers where each block has multiple minimizers of its local Lagrangian subproblem.\n\nTask:\n1) Derive from first principles the block-optimal response $x_i^\\star(\\lambda)$ for each block $i \\in \\{1,2\\}$, given fixed $\\lambda \\in \\mathbb{R}$, by minimizing the scalar function $f_i(x_i) + \\lambda x_i$ over $x_i \\in [0,1]$. Your derivation must begin from the definitions above and basic properties of convex piecewise-linear functions and must not assume any pre-given closed-form for $x_i^\\star(\\lambda)$.\n2) Using the characterization of $x_i^\\star(\\lambda)$, express the dual function value $d(\\lambda)$ and a valid subgradient $g(\\lambda)$ of $d(\\lambda)$ at $\\lambda$ in terms of $x_1^\\star(\\lambda)$, $x_2^\\star(\\lambda)$, and $b$. Explain why the subgradient set can be multi-valued for certain $\\lambda$ and how tie-breaking among multiple primal minimizers selects a particular ascent direction.\n3) Implement two ascent rules to maximize $d(\\lambda)$:\n   - Standard diminishing-step subgradient ascent: $\\lambda_{k+1} = \\lambda_k + \\alpha_k \\, g_k$ with $\\alpha_k = c / \\sqrt{k+1}$, where $c > 0$ is a constant and $g_k$ is a chosen subgradient at $\\lambda_k$.\n   - Polyak step-size ascent: $\\lambda_{k+1} = \\lambda_k + \\alpha_k \\, g_k$ with $\\alpha_k = \\dfrac{d^\\star - d(\\lambda_k)}{\\lVert g_k \\rVert^2}$, where $d^\\star$ is the optimal dual value. For this problem, determine $d^\\star$ from first principles by analyzing the primal optimum. If $g_k = 0$, set $\\alpha_k = 0$.\n4) To make the multi-path behavior explicit, when a block’s local minimizer is not unique, apply a deterministic tie-breaking rule to select $x_i^\\star(\\lambda)$:\n   - Rule “min”: choose the smallest minimizer in the argmin set.\n   - Rule “max”: choose the largest minimizer in the argmin set.\n   These rules imply potentially different subgradients and thus different ascent paths whenever $\\lambda$ is at a nondifferentiable point of $d(\\lambda)$ for some block.\n\nTesting requirements:\nYour program must implement the dual decomposition oracle and both ascent rules, then run the following six test cases and report the final dual values. In all cases, express the final outputs as real numbers rounded to six decimal places.\n\nFixed problem data for all tests:\n- Number of blocks: $2$,\n- $(M_1, s_1) = (1.5, 0.2)$, $(M_2, s_2) = (0.5, 0.8)$,\n- Coupling right-hand side: $b = 0.6$.\n\nInterpretation of a test case tuple: $(\\text{rule}, \\lambda_0, T, c, \\text{tie})$ where:\n- $\\text{rule} \\in \\{\\text{standard}, \\text{polyak}\\}$ selects the step rule,\n- $\\lambda_0 \\in \\mathbb{R}$ is the initial multiplier,\n- $T \\in \\mathbb{N}$ is the number of iterations,\n- $c \\in \\mathbb{R}_{>0}$ is the step-size constant used only for the standard rule (ignored for Polyak),\n- $\\text{tie} \\in \\{\\text{min}, \\text{max}\\}$ selects the tie-breaking rule.\n\nTest suite:\n- Test $1$: $(\\text{standard}, 0.0, 1, 2.0, \\text{min})$,\n- Test $2$: $(\\text{standard}, 0.0, 1, 2.0, \\text{max})$,\n- Test $3$: $(\\text{polyak}, 0.0, 5, 0.0, \\text{min})$,\n- Test $4$: $(\\text{standard}, 0.2, 10, 0.5, \\text{min})$,\n- Test $5$: $(\\text{polyak}, 0.2, 10, 0.0, \\text{min})$,\n- Test $6$: $(\\text{standard}, -0.5, 1, 0.5, \\text{max})$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the exact test order above, where each entry is the final dual value $d(\\lambda_T)$ rounded to six decimal places (e.g., “[0.000000,-0.123456,...]”). No additional text should be printed.\n\nAngle units do not apply. No physical units apply. All numerical constants in your program must match the values given here exactly. The program must be self-contained and require no user input.",
            "solution": "The problem is deemed valid as it is scientifically grounded in convex optimization theory, well-posed with all necessary information, and stated objectively. We proceed with a complete solution.\n\nThe optimization problem is to minimize a convex, separable function $F(x) = f_1(x_1) + f_2(x_2)$ subject to a coupling linear constraint $x_1 + x_2 = b$ and box constraints $0 \\le x_i \\le 1$. The functions are given by $f_i(x_i) = M_i \\cdot \\max\\{0, x_i - s_i\\}$.\n\nThe methodology is Lagrangian dual decomposition. The Lagrangian is:\n$$\n\\mathcal{L}(x,\\lambda) = f_1(x_1) + f_2(x_2) + \\lambda (x_1 + x_2 - b)\n$$\nThe dual function $d(\\lambda)$ is the infimum of the Lagrangian over the feasible set of $x$:\n$$\nd(\\lambda) = \\inf_{0 \\le x_1 \\le 1,\\,0 \\le x_2 \\le 1} \\mathcal{L}(x,\\lambda)\n$$\nDue to separability, this decomposes into:\n$$\nd(\\lambda) = \\left( \\inf_{0 \\le x_1 \\le 1} \\{f_1(x_1) + \\lambda x_1\\} \\right) + \\left( \\inf_{0 \\le x_2 \\le 1} \\{f_2(x_2) + \\lambda x_2\\} \\right) - \\lambda b\n$$\n\n### 1. Derivation of the Block-Optimal Response $x_i^\\star(\\lambda)$\n\nThe first task is to find the optimal response $x_i^\\star(\\lambda)$ for each block $i \\in \\{1, 2\\}$ by solving the scalar subproblem:\n$$\n\\min_{x_i \\in [0, 1]} L_i(x_i, \\lambda) \\quad \\text{where} \\quad L_i(x_i, \\lambda) = f_i(x_i) + \\lambda x_i\n$$\nThe function $f_i(x_i) = M_i \\cdot \\max\\{0, x_i - s_i\\}$ is convex and piecewise-linear. The function $L_i(x_i, \\lambda)$ is therefore also convex. The minimizer of a convex function over an interval $[0,1]$ is determined by its subgradient. The optimality condition is that $0$ must be in the subgradient of $L_i$ at the minimum $x_i^\\star$, denoted $\\partial_{x_i} L_i(x_i^\\star, \\lambda)$.\n\nThe subgradient of $L_i(x_i, \\lambda)$ with respect to $x_i$ is $\\partial_{x_i} L_i(x_i, \\lambda) = \\partial f_i(x_i) + \\lambda$. The subgradient of $f_i(x_i)$ is:\n$$\n\\partial f_i(x_i) =\n\\begin{cases}\n    \\{0\\} & \\text{if } x_i < s_i \\\\\n    [0, M_i] & \\text{if } x_i = s_i \\\\\n    \\{M_i\\} & \\text{if } x_i > s_i\n\\end{cases}\n$$\nThus, the subgradient of the subproblem objective is:\n$$\n\\partial_{x_i} L_i(x_i, \\lambda) =\n\\begin{cases}\n    \\{\\lambda\\} & \\text{if } x_i < s_i \\\\\n    [\\lambda, \\lambda + M_i] & \\text{if } x_i = s_i \\\\\n    \\{\\lambda + M_i\\} & \\text{if } x_i > s_i\n\\end{cases}\n$$\nWe seek $x_i^\\star(\\lambda) \\in [0, 1]$ such that $0 \\in \\partial_{x_i} L_i(x_i^\\star(\\lambda), \\lambda)$. We analyze this condition for different values of $\\lambda$:\n\n1.  If $\\lambda > 0$: $\\partial_{x_i} L_i$ is strictly positive for all $x_i \\in [0,1]$. $L_i(x_i, \\lambda)$ is strictly increasing. The minimum over $[0, 1]$ occurs at $x_i^\\star(\\lambda) = 0$.\n2.  If $\\lambda = 0$: The subgradient is $\\{0\\}$ for $x_i < s_i$, $[0, M_i]$ at $x_i = s_i$, and $\\{M_i\\}$ for $x_i > s_i$. The optimality condition $0 \\in \\partial_{x_i} L_i$ is satisfied for all $x_i \\in [0, s_i]$. The set of minimizers is $[0, s_i]$ (assuming $s_i \\in [0,1]$).\n3.  If $-M_i < \\lambda < 0$: The subgradient is negative for $x_i < s_i$ and positive for $x_i > s_i$. The condition $0 \\in [\\lambda, \\lambda + M_i]$ is met at the kink point $x_i = s_i$. Thus, the unique minimizer is $x_i^\\star(\\lambda) = s_i$.\n4.  If $\\lambda = -M_i$: The subgradient is $\\{-M_i\\}$ for $x_i < s_i$, $[-M_i, 0]$ at $x_i = s_i$, and $\\{0\\}$ for $x_i > s_i$. The optimality condition is met for all $x_i \\in [s_i, 1]$. The set of minimizers is $[s_i, 1]$.\n5.  If $\\lambda < -M_i$: $\\partial_{x_i} L_i$ is strictly negative for all $x_i \\in [0,1]$. $L_i(x_i, \\lambda)$ is strictly decreasing. The minimum over $[0, 1]$ occurs at $x_i^\\star(\\lambda) = 1$.\n\nIn summary, the argmin set for the subproblem is:\n$$\n\\text{argmin}_{x_i \\in [0, 1]} L_i(x_i, \\lambda) =\n\\begin{cases}\n    \\{1\\} & \\text{if } \\lambda < -M_i \\\\\n    [s_i, 1] & \\text{if } \\lambda = -M_i \\\\\n    \\{s_i\\} & \\text{if } -M_i < \\lambda < 0 \\\\\n    [0, s_i] & \\text{if } \\lambda = 0 \\\\\n    \\{0\\} & \\text{if } \\lambda > 0\n\\end{cases}\n$$\nThe tie-breaking rules select a single value from the set-valued cases:\n-   Rule \"min\": choose the smallest value in the argmin set. At $\\lambda=-M_i$, $x_i^\\star = s_i$. At $\\lambda=0$, $x_i^\\star = 0$.\n-   Rule \"max\": choose the largest value in the argmin set. At $\\lambda=-M_i$, $x_i^\\star = 1$. At $\\lambda=0$, $x_i^\\star = s_i$.\n\n### 2. Dual Function and Subgradient\n\nThe value of the dual function is obtained by substituting the optimal response $x_i^\\star(\\lambda)$ back into the definition:\n$$\nd(\\lambda) = \\sum_{i=1}^2 (f_i(x_i^\\star(\\lambda)) + \\lambda x_i^\\star(\\lambda)) - \\lambda b\n$$\nwhere $x_i^\\star(\\lambda)$ is any selection from the argmin set. A subgradient of the concave function $d(\\lambda)$ at $\\lambda$ is given by the residual of the coupling constraint:\n$$\ng(\\lambda) = x_1^\\star(\\lambda) + x_2^\\star(\\lambda) - b\n$$\nThe subgradient set $\\partial d(\\lambda)$ can be multi-valued. This occurs precisely when the subproblem minimizer $x_i^\\star(\\lambda)$ is not unique for at least one block $i$. As shown above, this happens at $\\lambda = -M_i$ or $\\lambda = 0$. For such $\\lambda$, the set of possible subgradients is $\\{x_1+x_2-b \\mid x_i \\in \\text{argmin } L_i(x_i,\\lambda)\\}$. The tie-breaking rule deterministically selects a primal minimizer, which in turn selects a single subgradient from this set to use as an ascent direction.\n\n### 3. Ascent Rules and Optimal Dual Value\n\nThe dual problem is to maximize the concave function $d(\\lambda)$. We use subgradient ascent: $\\lambda_{k+1} = \\lambda_k + \\alpha_k g_k$.\n\n-   **Standard Diminishing-Step Subgradient Ascent**: The step-size is $\\alpha_k = c/\\sqrt{k+1}$ for a constant $c > 0$ and iteration index $k$. The update rule is:\n    $$\n    \\lambda_{k+1} = \\lambda_k + \\frac{c}{\\sqrt{k+1}} g_k\n    $$\n-   **Polyak Step-Size Ascent**: The step-size is $\\alpha_k = \\frac{d^\\star - d(\\lambda_k)}{\\|g_k\\|^2}$, where $d^\\star$ is the optimal dual value. Strong duality holds for this problem, so $d^\\star$ equals the optimal primal value $p^\\star$. We find $p^\\star$ by solving the primal problem directly.\n    Minimize $F(x_1, x_2) = 1.5 \\max\\{0, x_1-0.2\\} + 0.5 \\max\\{0, x_2-0.8\\}$, subject to $x_1+x_2 = 0.6$ and $x_i \\in [0,1]$.\n    Substitute $x_2=0.6-x_1$ into the objective and constraints. The constraint $0 \\le x_2 \\le 1$ implies $0 \\le 0.6-x_1 \\le 1$, which means $-0.4 \\le x_1 \\le 0.6$. Combined with $0 \\le x_1 \\le 1$, the feasible range for $x_1$ is $[0, 0.6]$.\n    The objective becomes a function of $x_1$:\n$$\n\\phi(x_1) = 1.5 \\max\\{0, x_1-0.2\\} + 0.5 \\max\\{0, (0.6-x_1)-0.8\\} \\quad \\text{for } x_1 \\in [0, 0.6]\n$$\n$$\n\\phi(x_1) = 1.5 \\max\\{0, x_1-0.2\\} + 0.5 \\max\\{0, -x_1-0.2\\}\n$$\n    For $x_1 \\in [0, 0.6]$, the term $-x_1-0.2$ is always negative, so $\\max\\{0,-x_1-0.2\\} = 0$. The objective simplifies to $\\phi(x_1) = 1.5 \\max\\{0, x_1-0.2\\}$. This function is non-decreasing in $x_1$. Its minimum over $[0,0.6]$ occurs where $x_1-0.2 \\le 0$, i.e., $x_1 \\in [0, 0.2]$. For any such $x_1$, the value is $\\phi(x_1) = 0$.\n    Thus, the optimal primal value is $p^\\star=0$, and so $d^\\star = 0$.\n    The Polyak update rule is:\n    $$\n    \\lambda_{k+1} = \\lambda_k + \\frac{0 - d(\\lambda_k)}{\\|g_k\\|^2} g_k\n    $$\n    If $g_k = 0$, the optimum is reached and the step-size $\\alpha_k$ is set to $0$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the specified dual decomposition problem for a set of test cases.\n    \"\"\"\n    # Fixed problem data\n    M1, s1 = 1.5, 0.2\n    M2, s2 = 0.5, 0.8\n    b = 0.6\n    d_star = 0.0\n    TOL = 1e-9  # Tolerance for floating point comparisons\n\n    # Test suite\n    test_cases = [\n        # (rule, lambda_0, T, c, tie)\n        ('standard', 0.0, 1, 2.0, 'min'),\n        ('standard', 0.0, 1, 2.0, 'max'),\n        ('polyak', 0.0, 5, 0.0, 'min'),\n        ('standard', 0.2, 10, 0.5, 'min'),\n        ('polyak', 0.2, 10, 0.0, 'min'),\n        ('standard', -0.5, 1, 0.5, 'max'),\n    ]\n\n    results = []\n    for case in test_cases:\n        rule, lambda_0, T, c, tie = case\n        \n        # Use a dictionary to map parameters to blocks\n        blocks = {\n            1: {'M': M1, 's': s1},\n            2: {'M': M2, 's': s2}\n        }\n\n        def get_x_star(M, s, lam, tie_rule):\n            \"\"\"\n            Calculates the optimal response x_i^*(lambda) for a single block.\n            \"\"\"\n            if lam > TOL:\n                return 0.0\n            elif abs(lam) = TOL:  # lam is close to 0\n                return 0.0 if tie_rule == 'min' else s\n            elif lam > -M + TOL:  # -M  lam  0\n                return s\n            elif abs(lam + M) = TOL:  # lam is close to -M\n                return s if tie_rule == 'min' else 1.0\n            else:  # lam  -M\n                return 1.0\n\n        def get_dual_quantities(lam, tie_rule):\n            \"\"\"\n            Computes the dual function value d(lambda) and a subgradient g(lambda).\n            \"\"\"\n            x1_star = get_x_star(blocks[1]['M'], blocks[1]['s'], lam, tie_rule)\n            x2_star = get_x_star(blocks[2]['M'], blocks[2]['s'], lam, tie_rule)\n            \n            f1 = blocks[1]['M'] * max(0, x1_star - blocks[1]['s'])\n            f2 = blocks[2]['M'] * max(0, x2_star - blocks[2]['s'])\n            \n            d_val = f1 + f2 + lam * (x1_star + x2_star - b)\n            g_val = x1_star + x2_star - b\n            \n            return d_val, g_val\n\n        lam = lambda_0\n        for k in range(T):\n            d_k, g_k = get_dual_quantities(lam, tie)\n            \n            if abs(g_k)  TOL:\n                alpha_k = 0.0\n            elif rule == 'standard':\n                alpha_k = c / np.sqrt(k + 1)\n            elif rule == 'polyak':\n                alpha_k = (d_star - d_k) / (g_k**2)\n            else:\n                raise ValueError(\"Unknown rule specified\")\n            \n            lam = lam + alpha_k * g_k\n            \n        final_d_val, _ = get_dual_quantities(lam, tie)\n        results.append(final_d_val)\n\n    # Format the final output as specified\n    results_str = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Building on the fundamentals of subgradient ascent, this practice applies Lagrangian relaxation to a common large-scale structure: a separable quadratic objective with a single linear coupling constraint. You will implement a dual subgradient algorithm from scratch and, critically, investigate the role of the step-size parameter, $\\alpha_k$. This exercise  illuminates a core trade-off in dual decomposition: the choice of step size influences not only the convergence speed of the dual value but also the feasibility of the primal solution recovered from the process. Comparing the algorithm's performance with a precisely calculated optimal solution will give you a clear measure of the duality gap and feasibility violation.",
            "id": "3116747",
            "problem": "You are given a family of convex, separable optimization problems with a single linear coupling constraint. For an integer $m \\ge 2$, each problem has the form\n$$\n\\min_{x \\in \\mathbb{R}^m} \\;\\; f(x) = \\sum_{i=1}^m f_i(x_i)\n\\quad \\text{subject to} \\quad \\sum_{i=1}^m A_i x_i = b, \\quad \\ell_i \\le x_i \\le u_i,\n$$\nwhere each component function is quadratic,\n$$\nf_i(x_i) = \\tfrac{1}{2} q_i x_i^2 + c_i x_i,\n$$\nwith $q_i  0$, and the bounds satisfy $\\ell_i  u_i$ so the feasible set is nonempty and bounded. The coupling is a single scalar equality constraint with coefficients $A_i$ and right-hand side $b$.\n\nStarting from the definitions of the (unaugmented) Lagrangian and its dual function, consider the standard Lagrangian relaxation with dual variable $\\lambda \\in \\mathbb{R}$,\n$$\n\\mathcal{L}(x,\\lambda) = \\sum_{i=1}^m f_i(x_i) + \\lambda \\Big( \\sum_{i=1}^m A_i x_i - b \\Big),\n$$\nand the dual function $g(\\lambda) = \\inf_{x \\in [\\ell,u]} \\mathcal{L}(x,\\lambda)$ where $[\\ell,u]$ denotes the box $\\prod_{i=1}^m [\\ell_i,u_i]$. The dual problem is to maximize $g(\\lambda)$ over $\\lambda \\in \\mathbb{R}$. Use a constant-step subgradient ascent on the dual with step size equal to $1/\\rho$, where $\\rho  0$ is a user-chosen penalty parameter. Specifically, from an initial $\\lambda_0 = 0$, iterate for $k = 0,1,\\ldots,T-1$:\n- Compute $x^{(k)} \\in \\arg\\min_{\\ell \\le x \\le u}\\, \\mathcal{L}(x,\\lambda_k)$ (this is separable over indices $i$).\n- Compute the scalar subgradient $r_k = \\sum_{i=1}^m A_i x_i^{(k)} - b$.\n- Update $\\lambda_{k+1} = \\lambda_k + \\frac{1}{\\rho}\\, r_k$.\n\nAfter $T$ iterations, form the averaged primal candidate $\\bar{x} = \\frac{1}{T} \\sum_{k=0}^{T-1} x^{(k)}$. Let $p^\\star$ denote the optimal primal value of the original constrained problem, and let $d_{\\text{best}}$ denote the best dual value observed across the $T$ iterations, i.e., $d_{\\text{best}} = \\max_{0 \\le k \\le T-1} g(\\lambda_k)$. Quantify:\n- The duality gap $p^\\star - d_{\\text{best}}$ (a nonnegative float).\n- The primal feasibility residual of the recovered average $|\\sum_{i=1}^m A_i \\bar{x}_i - b|$ (a nonnegative float).\n\nYour program must:\n1. Compute $p^\\star$ to high accuracy using only the problem’s core definitions and first-order optimality principles. You must not assume any pre-derived closed forms. Use a numerically robust scalar root-finding approach for the single Lagrange multiplier associated with the equality constraint and the Karush–Kuhn–Tucker conditions to handle the box constraints.\n2. Implement the dual subgradient ascent described above with constant step $1/\\rho$, evaluate $g(\\lambda_k)$ at each iteration using the minimizing $x^{(k)}$, and track $d_{\\text{best}}$.\n3. Recover $\\bar{x}$ and compute the feasibility residual.\n4. Report for each test case the pair of floats: first $p^\\star - d_{\\text{best}}$, then $|\\sum_{i=1}^m A_i \\bar{x}_i - b|$. Each float should be rounded to $6$ decimal places.\n\nFundamental base you must use:\n- The definition of the Lagrangian $\\mathcal{L}(x,\\lambda)$ for equality constraints.\n- The definition of the dual function $g(\\lambda) = \\inf_x \\mathcal{L}(x,\\lambda)$ and the fact that a subgradient of $g$ at $\\lambda$ is the primal residual $\\sum_i A_i x_i^\\star(\\lambda) - b$ for any minimizer $x^\\star(\\lambda)$ of $\\mathcal{L}(\\cdot,\\lambda)$ over the box constraints.\n- The Karush–Kuhn–Tucker conditions for convex quadratic programs with a single linear equality and bound constraints, used to compute $p^\\star$ by a scalar search over the Lagrange multiplier.\n\nTest Suite:\nUse the following five test cases, each specified as $(m, q, c, A, \\ell, u, b, T, \\rho)$, where vectors are given in coordinate order:\n- Case $1$ (happy path, medium scale): $m = 4$, $q = [\\,2,\\,1,\\,4,\\,3\\,]$, $c = [\\,0,\\,-1,\\,2,\\,-0.5\\,]$, $A = [\\,1,\\,-2,\\,1.5,\\,1\\,]$, $\\ell = [\\,-1,\\,0,\\,-0.5,\\,-2\\,]$, $u = [\\,2,\\,2,\\,1.5,\\,1\\,]$, $b = 0.7$, $T = 200$, $\\rho = 0.5$.\n- Case $2$ (same data, milder step): $m = 4$, $q = [\\,2,\\,1,\\,4,\\,3\\,]$, $c = [\\,0,\\,-1,\\,2,\\,-0.5\\,]$, $A = [\\,1,\\,-2,\\,1.5,\\,1\\,]$, $\\ell = [\\,-1,\\,0,\\,-0.5,\\,-2\\,]$, $u = [\\,2,\\,2,\\,1.5,\\,1\\,]$, $b = 0.7$, $T = 200$, $\\rho = 2$.\n- Case $3$ (same data, small step): $m = 4$, $q = [\\,2,\\,1,\\,4,\\,3\\,]$, $c = [\\,0,\\,-1,\\,2,\\,-0.5\\,]$, $A = [\\,1,\\,-2,\\,1.5,\\,1\\,]$, $\\ell = [\\,-1,\\,0,\\,-0.5,\\,-2\\,]$, $u = [\\,2,\\,2,\\,1.5,\\,1\\,]$, $b = 0.7$, $T = 200$, $\\rho = 20$.\n- Case $4$ (boundary optimum on upper bounds): $m = 3$, $q = [\\,1,\\,1,\\,1\\,]$, $c = [\\,0.1,\\,-0.2,\\,0.3\\,]$, $A = [\\,1,\\,1,\\,1\\,]$, $\\ell = [\\,0,\\,0,\\,0\\,]$, $u = [\\,1,\\,1,\\,1\\,]$, $b = 3$, $T = 200$, $\\rho = 2$.\n- Case $5$ (ill-conditioned curvature): $m = 4$, $q = [\\,0.1,\\,10,\\,0.5,\\,8\\,]$, $c = [\\,0,\\,0,\\,0,\\,0\\,]$, $A = [\\,1,\\,1,\\,-1,\\,2\\,]$, $\\ell = [\\,-1,\\,-1,\\,-1,\\,-1\\,]$, $u = [\\,1,\\,1,\\,1,\\,1\\,]$, $b = 0.3$, $T = 200$, $\\rho = 2$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in order, for each of the five cases, first the duality gap and then the feasibility residual, both rounded to $6$ decimal places. For example, the output must look like\n$$\n[\\;g_1,\\;r_1,\\;g_2,\\;r_2,\\;g_3,\\;r_3,\\;g_4,\\;r_4,\\;g_5,\\;r_5\\;],\n$$\nwhere $g_j$ is $p^\\star - d_{\\text{best}}$ and $r_j$ is $|\\sum_i A_i \\bar{x}_i - b|$ for case $j$. No other text must be printed.",
            "solution": "The problem presents a convex, separable quadratic optimization problem with a single linear coupling constraint and box constraints. The task is to compute the exact primal optimal value, implement a dual subgradient ascent algorithm, and report the resulting duality gap and primal feasibility residual.\n\nThe problem is valid. It is scientifically grounded in the principles of convex optimization and duality theory. The objective function $f(x) = \\sum_{i=1}^m f_i(x_i)$, with each $f_i(x_i) = \\frac{1}{2} q_i x_i^2 + c_i x_i$ and $q_i  0$, is strictly convex. The feasible set, defined by the intersection of a hyperplane $\\sum_{i=1}^m A_i x_i = b$ and a compact box $[\\ell, u] = \\prod_{i=1}^m [\\ell_i, u_i]$, is convex and compact. The problem statement guarantees this set is nonempty. Consequently, a unique optimal solution $x^\\star$ exists, and the problem is well-posed. All parameters and algorithmic details are specified precisely, making the problem self-contained and objective.\n\nOur solution proceeds in two primary stages: first, the computation of the exact primal optimal value $p^\\star$ through the Karush-Kuhn-Tucker (KKT) conditions; and second, the implementation of the specified dual subgradient method to find the best dual bound $d_{\\text{best}}$ and the averaged primal solution $\\bar{x}$.\n\n### Part 1: Exact Primal Solution via KKT Conditions\n\nTo find the exact primal optimal value $p^\\star$, we solve the primal problem directly. The problem is:\n$$\n\\min_{x \\in \\mathbb{R}^m} \\;\\; \\sum_{i=1}^m \\left(\\tfrac{1}{2} q_i x_i^2 + c_i x_i\\right)\n\\quad \\text{s.t.} \\quad \\sum_{i=1}^m A_i x_i = b, \\quad \\ell_i \\le x_i \\le u_i \\text{ for } i=1,\\ldots,m.\n$$\nThis is a convex optimization problem. The KKT conditions provide necessary and sufficient conditions for optimality. We introduce a Lagrange multiplier $\\nu \\in \\mathbb{R}$ for the equality constraint, and multipliers $\\mu_{l,i} \\ge 0$ and $\\mu_{u,i} \\ge 0$ for the lower and upper bound constraints $x_i \\ge \\ell_i$ and $x_i \\le u_i$, respectively. The full Lagrangian is:\n$$\n\\mathcal{L}_{\\text{full}}(x, \\nu, \\mu_l, \\mu_u) = \\sum_{i=1}^m \\left(\\tfrac{1}{2} q_i x_i^2 + c_i x_i\\right) + \\nu \\left(\\sum_{i=1}^m A_i x_i - b\\right) - \\sum_{i=1}^m \\mu_{l,i} (x_i - \\ell_i) + \\sum_{i=1}^m \\mu_{u,i} (u_i - x_i).\n$$\nThe KKT stationarity condition requires $\\nabla_{x_i} \\mathcal{L}_{\\text{full}} = 0$ for each $i=1,\\ldots,m$:\n$$\nq_i x_i + c_i + \\nu A_i - \\mu_{l,i} + \\mu_{u,i} = 0.\n$$\nThe complementary slackness conditions are $\\mu_{l,i} (x_i - \\ell_i) = 0$ and $\\mu_{u,i} (u_i - x_i) = 0$.\nWe analyze the three possibilities for $x_i$ at the optimum:\n1.  If $\\ell_i  x_i  u_i$, then $\\mu_{l,i} = \\mu_{u,i} = 0$, which implies $q_i x_i + c_i + \\nu A_i = 0$, so $x_i = \\frac{-c_i - \\nu A_i}{q_i}$.\n2.  If $x_i = \\ell_i$, then $\\mu_{u,i} = 0$. Stationarity gives $\\mu_{l,i} = q_i \\ell_i + c_i + \\nu A_i$. The dual feasibility $\\mu_{l,i} \\ge 0$ requires $q_i \\ell_i + c_i + \\nu A_i \\ge 0$, or $\\frac{-c_i - \\nu A_i}{q_i} \\le \\ell_i$.\n3.  If $x_i = u_i$, then $\\mu_{l,i} = 0$. Stationarity gives $\\mu_{u,i} = -(q_i u_i + c_i + \\nu A_i)$. The dual feasibility $\\mu_{u,i} \\ge 0$ requires $q_i u_i + c_i + \\nu A_i \\le 0$, or $\\frac{-c_i - \\nu A_i}{q_i} \\ge u_i$.\n\nCombining these cases, for a given optimal multiplier $\\nu^\\star$, each component $x_i^\\star$ of the optimal solution is given by projecting the unconstrained minimizer onto the feasible interval $[\\ell_i, u_i]$:\n$$\nx_i^\\star(\\nu) = \\text{proj}_{[\\ell_i, u_i]} \\left( \\frac{-c_i - \\nu A_i}{q_i} \\right) = \\max\\left(\\ell_i, \\min\\left(u_i, \\frac{-c_i - \\nu A_i}{q_i}\\right)\\right).\n$$\nThe optimal multiplier $\\nu^\\star$ is the value that ensures the primal equality constraint is satisfied:\n$$\n\\phi(\\nu) := \\sum_{i=1}^m A_i x_i^\\star(\\nu) - b = 0.\n$$\nThe function $\\phi(\\nu)$ is continuous and monotonically non-increasing because each component $A_i x_i^\\star(\\nu)$ is a non-increasing function of $\\nu$. The problem guarantees that a feasible solution exists, which implies that the value $b$ lies within the achievable range of $\\sum_{i=1}^m A_i x_i$ for $x \\in [\\ell, u]$. This ensures that the equation $\\phi(\\nu) = 0$ has at least one solution $\\nu^\\star$. We can find this root using a numerical scalar root-finding method, such as Brent's method, on a sufficiently large interval. Once $\\nu^\\star$ is found, the optimal primal solution is $x^\\star = (x_1^\\star(\\nu^\\star), \\ldots, x_m^\\star(\\nu^\\star))$, and the optimal value is $p^\\star = f(x^\\star) = \\sum_{i=1}^m (\\frac{1}{2} q_i (x_i^\\star)^2 + c_i x_i^\\star)$.\n\n### Part 2: Dual Subgradient Ascent Method\n\nThe dual subgradient method operates on the dual problem, which is to maximize the dual function $g(\\lambda)$. The (unaugmented) Lagrangian is:\n$$\n\\mathcal{L}(x,\\lambda) = \\sum_{i=1}^m f_i(x_i) + \\lambda \\left( \\sum_{i=1}^m A_i x_i - b \\right).\n$$\nThe dual function is $g(\\lambda) = \\inf_{\\ell \\le x \\le u} \\mathcal{L}(x,\\lambda)$. The minimization in the definition of $g(\\lambda)$ is separable over the components of $x$:\n$$\ng(\\lambda) = \\sum_{i=1}^m \\left( \\min_{\\ell_i \\le x_i \\le u_i} \\left\\{ \\tfrac{1}{2} q_i x_i^2 + (c_i + \\lambda A_i) x_i \\right\\} \\right) - \\lambda b.\n$$\nFor a given $\\lambda$, the minimizing $x_i(\\lambda)$ is found, as in the KKT analysis, by projecting the unconstrained minimizer of the quadratic term onto $[\\ell_i, u_i]$:\n$$\nx_i(\\lambda) = \\text{proj}_{[\\ell_i, u_i]} \\left( \\frac{-(c_i + \\lambda A_i)}{q_i} \\right).\n$$\nA subgradient of the concave function $g(\\lambda)$ at a point $\\lambda_k$ is given by the primal residual $r_k = \\sum_{i=1}^m A_i x_i^{(k)} - b$, where $x^{(k)}$ is any minimizer $x(\\lambda_k)$. The subgradient ascent algorithm updates the dual variable $\\lambda$ in the direction of a subgradient. Starting with $\\lambda_0 = 0$, the iterative process for $k = 0, 1, \\ldots, T-1$ is:\n1.  Compute the primal minimizer for the current dual variable $\\lambda_k$:\n    $x^{(k)} = (x_1(\\lambda_k), \\ldots, x_m(\\lambda_k))$.\n2.  Compute the dual function value $g(\\lambda_k) = \\mathcal{L}(x^{(k)}, \\lambda_k)$ and update the best-so-far dual value: $d_{\\text{best}} = \\max(d_{\\text{best}}, g(\\lambda_k))$.\n3.  Compute the subgradient (primal residual): $r_k = \\sum_{i=1}^m A_i x_i^{(k)} - b$.\n4.  Update the dual variable using the specified constant step size $1/\\rho$:\n    $\\lambda_{k+1} = \\lambda_k + \\frac{1}{\\rho} r_k$.\n\nAfter $T$ iterations, we obtain the averaged primal candidate $\\bar{x} = \\frac{1}{T} \\sum_{k=0}^{T-1} x^{(k)}$.\n\n### Part 3: Quantified Metrics\n\nWith the values computed above, we calculate the two required metrics:\n1.  **Duality Gap**: This measures the difference between the true primal optimum and the best dual bound found by the algorithm: $p^\\star - d_{\\text{best}}$. By weak duality, this value is always non-negative.\n2.  **Primal Feasibility Residual**: This measures how well the recovered average solution respects the coupling constraint: $|\\sum_{i=1}^m A_i \\bar{x}_i - b|$.\n\nThese calculations are performed for each test case provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results in the required format.\n    \"\"\"\n    test_cases = [\n        # Case 1 (happy path, medium scale)\n        (4, [2.0, 1.0, 4.0, 3.0], [0.0, -1.0, 2.0, -0.5], [1.0, -2.0, 1.5, 1.0], \n         [-1.0, 0.0, -0.5, -2.0], [2.0, 2.0, 1.5, 1.0], 0.7, 200, 0.5),\n        # Case 2 (same data, milder step)\n        (4, [2.0, 1.0, 4.0, 3.0], [0.0, -1.0, 2.0, -0.5], [1.0, -2.0, 1.5, 1.0],\n         [-1.0, 0.0, -0.5, -2.0], [2.0, 2.0, 1.5, 1.0], 0.7, 200, 2.0),\n        # Case 3 (same data, small step)\n        (4, [2.0, 1.0, 4.0, 3.0], [0.0, -1.0, 2.0, -0.5], [1.0, -2.0, 1.5, 1.0],\n         [-1.0, 0.0, -0.5, -2.0], [2.0, 2.0, 1.5, 1.0], 0.7, 200, 20.0),\n        # Case 4 (boundary optimum on upper bounds)\n        (3, [1.0, 1.0, 1.0], [0.1, -0.2, 0.3], [1.0, 1.0, 1.0], \n         [0.0, 0.0, 0.0], [1.0, 1.0, 1.0], 3.0, 200, 2.0),\n        # Case 5 (ill-conditioned curvature)\n        (4, [0.1, 10.0, 0.5, 8.0], [0.0, 0.0, 0.0, 0.0], [1.0, 1.0, -1.0, 2.0],\n         [-1.0, -1.0, -1.0, -1.0], [1.0, 1.0, 1.0, 1.0], 0.3, 200, 2.0),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        m, q, c, A, ll, u, b, T, rho = [np.array(v) if isinstance(v, list) else v for v in case]\n        \n        # --- Part 1: Compute p_star (exact primal optimum) via KKT and root-finding ---\n        \n        def get_x_star_from_nu(nu, q, c, A, ll, u):\n            \"\"\"Calculates x*(nu) = proj_[l,u] ( (-c - nu*A) / q )\"\"\"\n            unconstrained_x = (-c - nu * A) / q\n            return np.maximum(ll, np.minimum(u, unconstrained_x))\n\n        def phi(nu, q, c, A, ll, u, b):\n            \"\"\"The function sum(A_i * x_i*(nu)) - b, whose root is nu_star\"\"\"\n            x_star = get_x_star_from_nu(nu, q, c, A, ll, u)\n            return np.dot(A, x_star) - b\n\n        # Find nu_star by solving phi(nu)=0 using a robust bracketing strategy\n        nu_search_min, nu_search_max = -1e5, 1e5\n        phi_at_min = phi(nu_search_min, q, c, A, ll, u, b)\n        phi_at_max = phi(nu_search_max, q, c, A, ll, u, b)\n\n        # Since feasibility is guaranteed, phi_at_max = 0 = phi_at_min\n        if np.isclose(phi_at_min, 0.0):\n            nu_star = nu_search_min\n        elif np.isclose(phi_at_max, 0.0):\n            nu_star = nu_search_max\n        else:\n            # A root must exist in the interval\n            nu_star = brentq(phi, nu_search_min, nu_search_max, args=(q, c, A, ll, u, b))\n\n        x_star = get_x_star_from_nu(nu_star, q, c, A, ll, u)\n        p_star = np.sum(0.5 * q * x_star**2 + c * x_star)\n\n        # --- Part 2: Dual Subgradient Ascent ---\n        \n        lambda_k = 0.0\n        x_sum = np.zeros(m)\n        d_best = -np.inf\n\n        for _ in range(T):\n            # Compute x_k which minimizes L(x, lambda_k) over the box\n            unconstrained_x = (-c - lambda_k * A) / q\n            x_k = np.maximum(ll, np.minimum(u, unconstrained_x))\n            x_sum += x_k\n\n            # Compute subgradient r_k\n            r_k = np.dot(A, x_k) - b\n            \n            # Compute dual function value g(lambda_k) = inf_x L(x, lambda_k)\n            g_lambda_k = np.sum(0.5 * q * x_k**2 + c * x_k) + lambda_k * r_k\n            if g_lambda_k > d_best:\n                d_best = g_lambda_k\n            \n            # Update lambda\n            lambda_k += (1.0 / rho) * r_k\n        \n        # --- Part 3: Final Computations ---\n        x_bar = x_sum / T\n        \n        duality_gap = p_star - d_best\n        feasibility_residual = np.abs(np.dot(A, x_bar) - b)\n        \n        all_results.extend([duality_gap, feasibility_residual])\n        \n    # Format and print the final output as a single-line string\n    print(f\"[{','.join(f'{r:.6f}' for r in all_results)}]\")\n\n# Execute the self-contained solution process\nsolve()\n```"
        },
        {
            "introduction": "Not all decomposition is dual. This practice introduces Benders decomposition, a powerful \"primal\" decomposition technique that works by partitioning variables rather than dualizing constraints. You will tackle a two-stage linear program where decisions made in the first stage (the master problem) affect the feasibility and cost of the second stage (the subproblem). This exercise  guides you through the entire Benders logic: deriving the subproblem's dual to generate \"cuts\" that inform the master problem. You will learn to generate both optimality cuts, which approximate the subproblem's cost, and feasibility cuts, which rule out master decisions that make the subproblem impossible to solve.",
            "id": "3116814",
            "problem": "Consider the following two-stage linear optimization problem amenable to Benders decomposition. The master decision variable is $x \\in [0,3]$. For any fixed $x$, the subproblem is the Linear Programming (LP) problem\n$$\n\\begin{aligned}\n\\text{minimize}_{y_1,y_2} \\quad  y_1 + y_2 \\\\\n\\text{subject to} \\quad  y_1 + y_2 = d(x), \\\\\n y_1 \\leq 2, \\\\\n y_2 \\leq 2, \\\\\n y_1 \\geq 0,\\; y_2 \\geq 0,\n\\end{aligned}\n$$\nwhere $d(x) = 3 - 2x$. The master objective is to minimize $5x + \\theta$, where $\\theta$ is a surrogate for the subproblem cost and will be constrained through Benders cuts. The subproblem is degenerately multiple optimal whenever it is feasible, because any feasible pair $(y_1,y_2)$ with $y_1 + y_2 = d(x)$ achieves the same objective value $y_1 + y_2$.\n\nTasks:\n1. Derive the dual of the subproblem from first principles, using the fundamental primal-dual pairing between linear programs and the principle of weak/strong duality.\n2. Identify an extreme point that yields a finite optimal dual solution (for the case where the subproblem is feasible) and derive the associated Benders optimality cut on $\\theta$ as a function of $x$.\n3. Identify extreme rays of the dual feasible set that cause dual unboundedness corresponding to subproblem infeasibility for some values of $x$, and derive the associated Benders feasibility cuts, explicitly in terms of $x$.\n4. Perform cut redundancy detection via LP post-processing: among the feasibility cuts you derived, identify any cut that is redundant when $x \\in [0,3]$ by formulating and solving the appropriate one-dimensional LP that maximizes the violation of the candidate cut over the master domain.\n5. Using only the non-redundant cuts and the optimality cut, write the resulting master problem and solve it to obtain the optimal objective value of $5x + \\theta$.\n\nYour final answer must be the single real number equal to the optimal value of $5x + \\theta$. No rounding is required and no units are involved. Express only the final number in your answer.",
            "solution": "The user wants me to solve a two-stage linear optimization problem using Benders decomposition. I will proceed by completing the five specified tasks.\n\n### Problem Validation\nThe problem statement describes a standard two-stage linear program with a single first-stage variable $x$ and a second-stage (subproblem) involving variables $y_1, y_2$. The structure is suitable for Benders decomposition. All variables, functions, and constraints are clearly defined. The problem is mathematically well-posed, scientifically grounded in optimization theory, and objectively stated. No flaws are detected. I will proceed with the solution.\n\n### Task 1: Derive the dual of the subproblem\n\nThe subproblem for a fixed $x$ is given by:\n$$\n\\begin{aligned}\n\\text{minimize}_{y_1,y_2} \\quad  y_1 + y_2 \\\\\n\\text{subject to} \\quad  y_1 + y_2 = d(x) \\\\\n y_1 \\leq 2 \\\\\n y_2 \\leq 2 \\\\\n y_1 \\geq 0,\\; y_2 \\geq 0\n\\end{aligned}\n$$\nwhere $d(x) = 3 - 2x$. To derive the dual, we first express this LP in a standard form. We introduce non-negative slack variables $s_1, s_2$ for the upper bounds on $y_1, y_2$. The subproblem becomes:\n$$\n\\begin{aligned}\n\\text{minimize} \\quad  y_1 + y_2 + 0s_1 + 0s_2 \\\\\n\\text{subject to} \\quad  y_1 + y_2 \\quad\\quad\\quad = 3 - 2x \\\\\n y_1 \\quad\\quad + s_1 \\quad = 2 \\\\\n \\quad\\quad y_2 \\quad\\quad + s_2 = 2 \\\\\n y_1, y_2, s_1, s_2 \\geq 0\n\\end{aligned}\n$$\nThis is a standard form LP: $\\min \\{c^T \\mathbf{y} \\mid A\\mathbf{y} = b, \\mathbf{y} \\geq 0\\}$, where $\\mathbf{y} = (y_1, y_2, s_1, s_2)^T$. The corresponding dual problem is $\\max \\{\\pi^T b \\mid A^T\\pi \\leq c\\}$, where $\\pi = (\\pi_0, \\pi_1, \\pi_2)^T$ is the vector of dual variables associated with the three equality constraints, and these dual variables are unrestricted in sign.\n\nThe matrices and vectors are:\n$$ c = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad A = \\begin{pmatrix} 1  1  0  0 \\\\ 1  0  1  0 \\\\ 0  1  0  1 \\end{pmatrix}, \\quad b(x) = \\begin{pmatrix} 3-2x \\\\ 2 \\\\ 2 \\end{pmatrix} $$\nThe dual constraints $A^T\\pi \\leq c$ are:\n$$\n\\begin{pmatrix}\n1  1  0 \\\\\n1  0  1 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix}\n\\begin{pmatrix} \\pi_0 \\\\ \\pi_1 \\\\ \\pi_2 \\end{pmatrix}\n\\leq\n\\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThis gives the following inequalities:\n1. $\\pi_0 + \\pi_1 \\leq 1$\n2. $\\pi_0 + \\pi_2 \\leq 1$\n3. $\\pi_1 \\leq 0$\n4. $\\pi_2 \\leq 0$\n\nThe dual objective function to maximize is $\\pi^T b(x)$:\n$$\n(3-2x)\\pi_0 + 2\\pi_1 + 2\\pi_2\n$$\nSo, the dual of the subproblem is:\n$$\n\\begin{aligned}\n\\text{maximize}_{\\pi_0, \\pi_1, \\pi_2} \\quad  (3-2x)\\pi_0 + 2\\pi_1 + 2\\pi_2 \\\\\n\\text{subject to} \\quad  \\pi_0 + \\pi_1 \\leq 1 \\\\\n \\pi_0 + \\pi_2 \\leq 1 \\\\\n \\pi_1 \\leq 0 \\\\\n \\pi_2 \\leq 0\n\\end{aligned}\n$$\n\n### Task 2: Derive the Benders optimality cut\n\nAn optimality cut is generated from an extreme point of the dual feasible set for a value of $x$ where the subproblem is feasible and has a finite optimal value. The primal subproblem is feasible if there exist $y_1, y_2$ such that $y_1+y_2 = d(x)$ and $0 \\leq y_1, y_2 \\leq 2$. The sum $y_1+y_2$ can take any value in $[0,4]$. Thus, the subproblem is feasible if and only if $0 \\leq d(x) \\leq 4$.\n$$ 0 \\leq 3-2x \\implies 2x \\leq 3 \\implies x \\leq 1.5 $$\n$$ 3-2x \\leq 4 \\implies -1 \\leq 2x \\implies x \\geq -0.5 $$\nGiven the master variable domain $x \\in [0,3]$, the subproblem is feasible for $x \\in [0, 1.5]$.\n\nFor $x$ in this range, the dual problem must have a finite optimal solution. Let's find an extreme point of the dual feasible region. An extreme point is a vertex formed by the intersection of at least three binding constraint planes. Let's test the constraints:\n$\\pi_0 + \\pi_1 = 1$, $\\pi_1 = 0$, $\\pi_2 = 0$. This gives $\\pi_0=1$. The point is $(\\pi_0, \\pi_1, \\pi_2) = (1,0,0)$. Let's check if it's feasible:\n- $1 + 0 \\leq 1$ (satisfied)\n- $1 + 0 \\leq 1$ (satisfied)\n- $0 \\leq 0$ (satisfied)\n- $0 \\leq 0$ (satisfied)\nThe point $(1,0,0)$ is an extreme point of the dual feasible set.\nThe dual objective function at this point is $(3-2x)(1)+2(0)+2(0) = 3-2x$.\nWhen the subproblem is feasible, its optimal objective value is given by $Q(x) = d(x) = 3-2x$. By strong duality, this is also the optimal value of the dual. The optimality cut is $\\theta \\geq Q(x)$, where $Q(x)$ is approximated by the value of the dual objective at one of its extreme points. Using the extreme point $\\pi^*=(1,0,0)$, we obtain the Benders optimality cut:\n$$\n\\theta \\geq (3-2x)\\pi_0^* + 2\\pi_1^* + 2\\pi_2^*\n$$\n$$\n\\theta \\geq 3-2x\n$$\n\n### Task 3: Derive Benders feasibility cuts\n\nFeasibility cuts are generated for values of $x$ where the subproblem is infeasible. This occurs when the dual is unbounded. The directions of unboundedness are the extreme rays of the dual's recession cone.\nThe recession cone is defined by the homogeneous system of inequalities:\n$$\n\\begin{aligned}\nd_0 + d_1 \\leq 0 \\\\\nd_0 + d_2 \\leq 0 \\\\\nd_1 \\leq 0 \\\\\nd_2 \\leq 0\n\\end{aligned}\n$$\nA Benders feasibility cut is derived from an extreme ray $r=(\\pi_0, \\pi_1, \\pi_2)$ of this cone if it provides a direction of unboundedness for the dual objective, i.e., $r^T c_D  0$, where $c_D = (3-2x, 2, 2)^T$. The cut is then of the form $r^T b(x) \\leq 0$.\nThe subproblem is infeasible for $x \\in [0,3]$ when $x1.5$ (since $d(x)  0$) or $x-0.5$ (since $d(x)4$).\n\nCase 1: $x  1.5$, which implies $3-2x  0$.\nLet's find an extreme ray that leads to an unbounded objective. Consider the ray $r_1 = (-1, 0, 0)$. It is in the recession cone: $-1+0\\leq0$, $-1+0\\leq0$, $0\\leq0$, $0\\leq0$.\nThe change in the dual objective along this ray is $(3-2x)(-1) + 2(0) + 2(0) = 2x-3$. For $x1.5$, $2x-3  0$, so the dual is unbounded along this ray.\nThe corresponding feasibility cut is $r_1^T b(x) \\leq 0$:\n$$ (-1,0,0) \\cdot (3-2x, 2, 2)^T \\leq 0 \\implies -(3-2x) \\leq 0 \\implies 2x-3 \\leq 0 \\implies x \\leq 1.5 $$\nThis cut removes the region $x  1.5$ from the feasible set of the master problem.\n\nCase 2: $x  -0.5$, which implies $3-2x  4$.\nLet's find another extreme ray. Consider $r_2 = (1, -1, -1)$. It is in the recession cone: $1-1=0\\leq0$, $1-1=0\\leq0$, $-1\\leq0$, $-1\\leq0$.\nThe change in the dual objective along this ray is $(3-2x)(1) + 2(-1) + 2(-1) = 3-2x-4 = -2x-1$.\nFor $x  -0.5$, $-2x  1$, so $-2x-1  0$. The dual is unbounded along this ray.\nThe corresponding feasibility cut is $r_2^T b(x) \\leq 0$:\n$$ (1,-1,-1) \\cdot (3-2x, 2, 2)^T \\leq 0 \\implies (3-2x) - 2 - 2 \\leq 0 \\implies -2x-1 \\leq 0 \\implies x \\geq -0.5 $$\nThis cut removes the region $x  -0.5$.\n\nThe two feasibility cuts are $x \\leq 1.5$ and $x \\geq -0.5$.\n\n### Task 4: Perform cut redundancy detection\n\nThe master problem for $x$ is constrained by its original domain $[0,3]$ and the feasibility cuts. The resulting feasible region for $x$ is given by:\n$$ \\{ x \\mid 0 \\leq x \\leq 3, \\quad x \\leq 1.5, \\quad x \\geq -0.5 \\} $$\nCombining these inequalities, we get $0 \\leq x \\leq 1.5$.\nWe check for redundancy among the feasibility cuts $x \\leq 1.5$ and $x \\geq -0.5$ over the master domain $x \\in [0,3]$.\n\nA cut is redundant if it is implied by other cuts and domain constraints.\nThe constraint $x \\geq -0.5$ is a candidate for redundancy. We check if it is redundant given the master domain constraint $x \\in [0,3]$.\nPer the problem instruction, we maximize the violation of this candidate cut over the domain defined by other constraints. The violation of $x \\geq -0.5$ can be expressed as $-0.5 - x$. We seek to maximize this value.\n$$\n\\max_{x} \\quad -0.5 - x \\quad \\text{s.t.} \\quad 0 \\leq x \\leq 1.5\n$$\nThe maximum occurs at the minimum value of $x$, which is $x=0$. The maximum violation is $-0.5-0 = -0.5$. Since the maximum violation is not positive, the cut $x \\geq -0.5$ is never violated on the feasible region defined by the other constraints. It is therefore redundant.\n\nThe non-redundant feasibility cut is $x \\leq 1.5$.\n\n### Task 5: Solve the master problem\n\nThe final master problem incorporates the non-redundant feasibility cut and the optimality cut:\n$$\n\\begin{aligned}\n\\text{minimize}_{x, \\theta} \\quad  5x + \\theta \\\\\n\\text{subject to} \\quad  0 \\leq x \\leq 1.5 \\\\\n \\theta \\geq 3-2x\n\\end{aligned}\n$$\nThe objective is to minimize $5x+\\theta$. To achieve this, for any given $x$, we should choose the smallest possible value for $\\theta$, which is $\\theta = 3-2x$ as per the constraint. Substituting this into the objective function, we obtain a problem in terms of $x$ alone:\n$$\n\\text{minimize}_{x} \\quad 5x + (3-2x) \\quad \\text{s.t.} \\quad 0 \\leq x \\leq 1.5\n$$\nThe objective simplifies to:\n$$\n\\text{minimize}_{x} \\quad 3x+3 \\quad \\text{s.t.} \\quad 0 \\leq x \\leq 1.5\n$$\nThe function $f(x)=3x+3$ is a linear function with a positive slope ($3$). Therefore, its minimum value over the interval $[0, 1.5]$ is attained at the left endpoint, $x=0$.\nThe optimal value for $x$ is $x^*=0$.\nThe corresponding optimal value of the objective function is $3(0)+3=3$.\n\nThe optimal solution to the overall problem is $x^*=0$, with the subproblem cost being $Q(0)=3-2(0)=3$.\nThe optimal value of the master objective function is $5x^* + Q(x^*) = 5(0) + 3 = 3$.",
            "answer": "$$\n\\boxed{3}\n$$"
        }
    ]
}