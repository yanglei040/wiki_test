{
    "hands_on_practices": [
        {
            "introduction": "本练习将通过一个经典的生产平滑问题，向您展示确定性动态规划中前向递推的基本应用。我们将追踪系统的“状态”（即库存偏差），并计算在每个时间阶段到达各个状态所需的最小累积成本 。这个过程完美地诠释了前向递推的核心思想：从初始时刻开始，一步步向前推导状态和成本，直至找到全局最优解。",
            "id": "3130922",
            "problem": "一个制造商计划在$T=4$个周期的离散有限时间范围内进行生产，以平滑围绕目标平均产量的库存波动。设每期的生产决策为$x_t$，目标平均值为$\\bar{x}$。通过前向递推$d_{t+1} = d_t + x_t - \\bar{x}$定义累积偏差（库存偏差）状态，初始条件为$d_1 = 0$。库存波动的每期惩罚是下一状态的绝对偏差，即$|d_{t+1}|$。最终偏差必须为零，$d_{5} = 0$，以强制实现期末平衡。目标是在满足前向状态递推和以下时变生产可行集的约束下，最小化总惩罚$\\sum_{t=1}^{4} |d_{t+1}|$：\n- 在 $t=1$ 时：$x_1 \\in \\{8,\\,10\\}$。\n- 在 $t=2$ 时：$x_2 \\in \\{8,\\,12\\}$。\n- 在 $t=3$ 时：$x_3 \\in \\{10,\\,12\\}$。\n- 在 $t=4$ 时：$x_4 \\in \\{8,\\,10\\}$。\n取$\\bar{x} = 10$。\n使用动态规划的最优性原理，构建一个前向递推，将最小累积惩罚传播到每个可达状态$d_{t+1}$，并强制执行终端约束$d_5=0$。然后计算满足所有约束的最优生产序列所能达到的最小总惩罚值$\\sum_{t=1}^{4} |d_{t+1}|$。将您的最终答案报告为单个实数。无需四舍五入。",
            "solution": "正如问题陈述所建议的，此问题可以使用前向递推方法解决。我们将系统在第$t$期开始时的状态定义为累积偏差$d_t$。决策变量是产量$x_t$。状态转移方程由$d_{t+1} = d_t + x_t - \\bar{x}$给出，其中$\\bar{x}=10$。初始状态为$d_1 = 0$。\n\n设$J_t(d_t)$为在第$t$期开始时达到状态$d_t$的最小累积惩罚。目标是找到满足约束条件的$\\min \\sum_{t=1}^{4} |d_{t+1}|$。这等价于找到$J_5(d_5=0)$。最小成本的前向递推为：\n$$J_{t+1}(d_{t+1}) = \\min_{d_t, x_t} \\{ J_t(d_t) + |d_{t+1}| \\}$$\n其中，最小化是针对所有导致状态$d_{t+1} = d_t + x_t - 10$的前一状态$d_t$和可行决策$x_t$对进行的。\n\n我们分阶段进行。\n\n**阶段 1：从 $t=1$ 到 $t=2$**\n系统从状态$d_1 = 0$开始，初始成本为$J_1(0)=0$。\n可用的生产决策为$x_1 \\in \\{8, 10\\}$。\n\n-   如果 $x_1 = 8$：下一状态为 $d_2 = d_1 + x_1 - 10 = 0 + 8 - 10 = -2$。\n    达到此状态的累积成本为 $J_2(-2) = J_1(0) + |d_2| = 0 + |-2| = 2$。\n-   如果 $x_1 = 10$：下一状态为 $d_2 = d_1 + x_1 - 10 = 0 + 10 - 10 = 0$。\n    达到此状态的累积成本为 $J_2(0) = J_1(0) + |d_2| = 0 + |0| = 0$。\n\n在第$t=2$期开始时，可达状态为$d_2 \\in \\{-2, 0\\}$，其最小成本分别为$J_2(-2)=2$和$J_2(0)=0$。\n\n**阶段 2：从 $t=2$ 到 $t=3$**\n可用的生产决策为$x_2 \\in \\{8, 12\\}$。我们从每个可达状态$d_2$计算下一个状态$d_3$及其成本。\n\n-   从 $d_2 = -2$（当前成本$J_2(-2)=2$）开始：\n    -   如果 $x_2 = 8$：$d_3 = -2 + 8 - 10 = -4$。新成本：$J_2(-2) + |-4| = 2 + 4 = 6$。\n    -   如果 $x_2 = 12$：$d_3 = -2 + 12 - 10 = 0$。新成本：$J_2(-2) + |0| = 2 + 0 = 2$。\n-   从 $d_2 = 0$（当前成本$J_2(0)=0$）开始：\n    -   如果 $x_2 = 8$：$d_3 = 0 + 8 - 10 = -2$。新成本：$J_2(0) + |-2| = 0 + 2 = 2$。\n    -   如果 $x_2 = 12$：$d_3 = 0 + 12 - 10 = 2$。新成本：$J_2(0) + |2| = 0 + 2 = 2$。\n\n在第$t=3$期开始时，可达状态为$d_3 \\in \\{-4, -2, 0, 2\\}$。由于没有状态被多条路径到达，我们不需要取最小值。最小成本为：\n-   $J_3(-4) = 6$\n-   $J_3(-2) = 2$\n-   $J_3(0) = 2$\n-   $J_3(2) = 2$\n\n**阶段 3：从 $t=3$ 到 $t=4$**\n可用的生产决策为$x_3 \\in \\{10, 12\\}$。\n\n-   从 $d_3 = -4$（成本 $6$）开始：\n    -   $x_3 = 10 \\implies d_4 = -4+10-10 = -4$。成本：$6+|-4|=10$。\n    -   $x_3 = 12 \\implies d_4 = -4+12-10 = -2$。成本：$6+|-2|=8$。\n-   从 $d_3 = -2$（成本 $2$）开始：\n    -   $x_3 = 10 \\implies d_4 = -2+10-10 = -2$。成本：$2+|-2|=4$。\n    -   $x_3 = 12 \\implies d_4 = -2+12-10 = 0$。成本：$2+|0|=2$。\n-   从 $d_3 = 0$（成本 $2$）开始：\n    -   $x_3 = 10 \\implies d_4 = 0+10-10 = 0$。成本：$2+|0|=2$。\n    -   $x_3 = 12 \\implies d_4 = 0+12-10 = 2$。成本：$2+|2|=4$。\n-   从 $d_3 = 2$（成本 $2$）开始：\n    -   $x_3 = 10 \\implies d_4 = 2+10-10 = 2$。成本：$2+|2|=4$。\n    -   $x_3 = 12 \\implies d_4 = 2+12-10 = 4$。成本：$2+|4|=6$。\n\n在第$t=4$期开始时，可达状态为$d_4 \\in \\{-4, -2, 0, 2, 4\\}$。某些状态可以通过多条路径达到，因此我们应用最优性原理，为每个状态取最小成本。\n-   $J_4(-4)$：仅从 $d_3 = -4, x_3=10$ 到达。成本 $10$。因此，$J_4(-4) = 10$。\n-   $J_4(-2)$：从 ($d_3=-4, x_3=12$) 到达，成本 $8$；从 ($d_3=-2, x_3=10$) 到达，成本 $4$。因此，$J_4(-2) = \\min(8, 4) = 4$。\n-   $J_4(0)$：从 ($d_3=-2, x_3=12$) 到达，成本 $2$；从 ($d_3=0, x_3=10$) 到达，成本 $2$。因此，$J_4(0) = \\min(2, 2) = 2$。\n-   $J_4(2)$：从 ($d_3=0, x_3=12$) 到达，成本 $4$；从 ($d_3=2, x_3=10$) 到达，成本 $4$。因此，$J_4(2) = \\min(4, 4) = 4$。\n-   $J_4(4)$：仅从 $d_3 = 2, x_3=12$ 到达。成本 $6$。因此，$J_4(4) = 6$。\n\n$t=4$时的最小成本总结：$J_4(-4)=10$, $J_4(-2)=4$, $J_4(0)=2$, $J_4(2)=4$, $J_4(4)=6$。\n\n**阶段 4：从 $t=4$ 到 $t=5$**\n可用的生产决策为$x_4 \\in \\{8, 10\\}$。我们必须强制执行终端约束$d_5=0$。状态转移为$d_5 = d_4 + x_4 - 10$。该约束意味着$0 = d_4 + x_4 - 10$，或$x_4 = 10 - d_4$。\n我们检查哪些可达状态$d_4$会导致一个可行的$x_4$。总成本将是$J_4(d_4) + |d_5| = J_4(d_4) + |0| = J_4(d_4)$。\n\n-   如果 $d_4 = -4$：需要 $x_4 = 10 - (-4) = 14$。这不在$\\{8, 10\\}$中，因此该路径不可行。\n-   如果 $d_4 = -2$：需要 $x_4 = 10 - (-2) = 12$。这不在$\\{8, 10\\}$中，因此该路径不可行。\n-   如果 $d_4 = 0$：需要 $x_4 = 10 - 0 = 10$。这在$\\{8, 10\\}$中。该路径可行。总成本为$J_4(0) = 2$。\n-   如果 $d_4 = 2$：需要 $x_4 = 10 - 2 = 8$。这在$\\{8, 10\\}$中。该路径可行。总成本为$J_4(2) = 4$。\n-   如果 $d_4 = 4$：需要 $x_4 = 10 - 4 = 6$。这不在$\\{8, 10\\}$中，因此该路径不可行。\n\n可行生产序列的可能总惩罚为$2$和$4$。其中的最小值即为最优值。\n最小总惩罚 $= \\min(2, 4) = 2$。\n为了验证，一个最优序列是$x=(10, 8, 12, 10)$。状态为$d_1=0 \\to d_2=0 \\to d_3=-2 \\to d_4=0 \\to d_5=0$。总惩罚为$|0| + |-2| + |0| + |0| = 2$。\n另一个最优序列是$x=(8, 12, 10, 10)$。状态为$d_1=0 \\to d_2=-2 \\to d_3=0 \\to d_4=0 \\to d_5=0$。总惩罚为$|-2| + |0| + |0| + |0| = 2$。\n最小总惩罚为$2$。",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "接下来，我们将进入一个随机性场景，探讨如何利用前向递推来优化项目管理的决策。这个练习的核心在于，前向递推不仅可以用来累积成本，还可以用来推演概率分布的演化 。您将学习如何基于不同决策，模拟项目完成概率随时间的变化，从而在预算约束下找到最大化成功率的行动序列。",
            "id": "3131011",
            "problem": "考虑一个离散时间随机项目，该项目被建模为一个三状态马尔可夫决策过程 (MDP)，其中项目状态为 $s \\in \\{0,1,2\\}$，$s=0$ 表示“尚未开始或仍处于初始里程碑”，$s=1$ 表示“处于中间里程碑的进展中”，$s=2$ 表示“已完成”。时间由 $t \\in \\{0,1,\\dots,T\\}$ 索引，在 $t=0$ 时的初始分布在 $s=0$ 处是退化的（即 $\\mathbb{P}(s_0=0)=1$ 且 $\\mathbb{P}(s_0=1)=\\mathbb{P}(s_0=2)=0$）。在每个时间步 $t$，从一个有限的行动集合中选择一个行动 $a_t$。一个行动 $a$ 具有一个相关的非负成本 $c(a)$，并以指定的非负增量增加从 $s=0$ 前进到 $s=1$ 以及从 $s=1$ 前进到 $s=2$ 的概率。设基准前进概率为 $\\theta_0 \\in [0,1]$（从 $s=0$ 到 $s=1$）和 $\\theta_1 \\in [0,1]$（从 $s=1$ 到 $s=2$）。对于任何行动 $a$，定义增量 $\\delta_0(a) \\ge 0$ 和 $\\delta_1(a) \\ge 0$，并设行动修正后的前进概率分别为 $\\min\\{1, \\theta_0 + \\delta_0(a)\\}$ 和 $\\min\\{1, \\theta_1 + \\delta_1(a)\\}$。停留在 $s=0$ 或 $s=1$ 的概率是从这些状态前进概率的补集，且 $s=2$ 是吸收态。项目经理有一个硬性预算 $B \\ge 0$，必须选择一个行动序列 $(a_0,\\dots,a_{T-1})$，使得 $\\sum_{t=0}^{T-1} c(a_t) \\le B$。\n\n您的任务是：\n- 从全概率定律和马尔可夫性质出发，推导一个前向递归，以在选定行动下传播从时间 $t$ 到 $t+1$ 的状态概率分布。利用此递归计算在时间 $T$ 时处于状态 $s=2$ 的概率（“满足截止日期”的概率），对于任何给定的行动序列，记为 $p_T(2)$。\n- 构建选择 $(a_0,\\dots,a_{T-1})$ 的优化问题，以在预算约束 $\\sum_{t=0}^{T-1} c(a_t) \\le B$ 下最大化 $p_T(2)$，并通过探索所有可行的行动序列来为指定的测试套件求解。\n\n使用以下参数值的测试套件。在每种情况下，初始分布在 $t=0$ 时都集中在 $s=0$。行动 $a$ 下的前进概率如上所述，使用给定的 $\\theta_0$、$\\theta_1$、$\\delta_0(a)$ 和 $\\delta_1(a)$ 定义，其中 $s=2$ 是吸收态，所有非前进概率等于相应的补集。为某个案例列出的所有行动在该案例的每个时间步都可用。\n\n- 案例 $1$ (一般顺利路径): $T=3$, $B=2$, $\\theta_0=0.3$, $\\theta_1=0.4$, 行动集 $\\{a=0,a=1\\}$，成本 $c(0)=0$, $c(1)=1$, 增量 $\\delta_0(0)=0.0$, $\\delta_1(0)=0.0$, $\\delta_0(1)=0.2$, $\\delta_1(1)=0.25$。\n- 案例 $2$ (预算紧张且时间范围更长): $T=4$, $B=1$, $\\theta_0=0.2$, $\\theta_1=0.3$, 行动集 $\\{a=0,a=1\\}$，成本 $c(0)=0$, $c(1)=1$, 增量 $\\delta_0(0)=0.0$, $\\delta_1(0)=0.0$, $\\delta_0(1)=0.3$, $\\delta_1(1)=0.2$。\n- 案例 $3$ (截止日期的边界条件): $T=0$, $B=10$, $\\theta_0=0.5$, $\\theta_1=0.5$, 行动集 $\\{a=0\\}$，成本 $c(0)=0$，增量 $\\delta_0(0)=0.0$, $\\delta_1(0)=0.0$。\n- 案例 $4$ (多种行动强度): $T=2$, $B=2$, $\\theta_0=0.25$, $\\theta_1=0.35$, 行动集 $\\{a=0,a=1,a=2\\}$，成本 $c(0)=0$, $c(1)=1$, $c(2)=2$, 增量 $\\delta_0(0)=0.0$, $\\delta_1(0)=0.0$, $\\delta_0(1)=0.35$, $\\delta_1(1)=0.15$, $\\delta_0(2)=0.6$, $\\delta_1(2)=0.4$。\n\n对于每个案例，计算最佳可行行动序列所能达到的最优“满足截止日期”概率 $p_T(2)$。将每个案例的最终答案表示为一个保留六位小数的十进制实数。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，“[result1,result2,result3,result4]”）。",
            "solution": "该问题要求两个主要交付成果：首先，推导一个三状态马尔可夫决策过程 (MDP) 的状态概率的前向递归；其次，构建并求解一个优化问题，以在预算约束下最大化项目完成概率。该问题定义明确，科学上合理，并提供了所有必要的数据。\n\n令项目在时间 $t$ 的状态为一个随机变量 $S_t \\in \\{0, 1, 2\\}$，其中 $0$ 代表初始状态，$1$ 代表中间状态，$2$ 代表完成状态。我们将时间 $t$ 的状态概率分布定义为一个向量 $\\mathbf{p}_t = [p_t(0), p_t(1), p_t(2)]^T$，其中 $p_t(s) = \\mathbb{P}(S_t=s)$。给定的初始条件是 $\\mathbf{p}_0 = [1, 0, 0]^T$。\n\n在每个时间步 $t \\in \\{0, \\dots, T-1\\}$，选择一个行动 $a_t$。系统的演化由转移概率矩阵 $\\mathbf{P}(a_t)$ 决定，其元素 $P_{ij}(a) = \\mathbb{P}(S_{t+1}=j | S_t=i, a_t=a)$ 由所选行动确定。设 $\\theta_0$ 和 $\\theta_1$ 为基准前进概率，$\\delta_0(a)$ 和 $\\delta_1(a)$ 为与行动相关的增量。行动修正后的前进概率为：\n$$\n\\pi_0(a) = \\min\\{1, \\theta_0 + \\delta_0(a)\\} \\quad (\\text{从状态 } 0 \\text{ 到 } 1)\n$$\n$$\n\\pi_1(a) = \\min\\{1, \\theta_1 + \\delta_1(a)\\} \\quad (\\text{从状态 } 1 \\text{ 到 } 2)\n$$\n状态 $s=2$ 是吸收态。因此，一个行动 $a$ 的转移概率矩阵为：\n$$\n\\mathbf{P}(a) = \\begin{pmatrix}\n1 - \\pi_0(a)  \\pi_0(a)  0 \\\\\n0  1 - \\pi_1(a)  \\pi_1(a) \\\\\n0  0  1\n\\end{pmatrix}\n$$\n\n第一个任务是推导状态概率的前向递归。根据全概率定律，在时间 $t+1$ 处于状态 $j$ 的概率是从时间 $t$ 的任何状态 $i$ 转移到时间 $t+1$ 的状态 $j$ 的概率之和：\n$$\np_{t+1}(j) = \\mathbb{P}(S_{t+1}=j) = \\sum_{i=0}^{2} \\mathbb{P}(S_{t+1}=j | S_t=i) \\mathbb{P}(S_t=i)\n$$\n给定在时间 $t$ 选择了行动 $a_t$，并援引马尔可夫性质（即给定现在，未来与过去无关），我们有 $\\mathbb{P}(S_{t+1}=j | S_t=i) = \\mathbb{P}(S_{t+1}=j | S_t=i, a_t) = P_{ij}(a_t)$。这引出了前向递归规则：\n$$\np_{t+1}(j) = \\sum_{i=0}^{2} P_{ij}(a_t) p_t(i)\n$$\n以矩阵形式表示为 $\\mathbf{p}_{t+1} = \\mathbf{P}(a_t)^T \\mathbf{p}_t$。对每个状态展开此式，得到显式递归关系：\n1.  对于状态 $s=0$： $p_{t+1}(0) = (1-\\pi_0(a_t))p_t(0)$。\n2.  对于状态 $s=1$： $p_{t+1}(1) = \\pi_0(a_t) p_t(0) + (1-\\pi_1(a_t))p_t(1)$。\n3.  对于状态 $s=2$： $p_{t+1}(2) = \\pi_1(a_t) p_t(1) + p_t(2)$。\n\n这些方程允许对于任何给定的行动序列 $(a_0, \\dots, a_{T-1})$，将状态概率分布从 $\\mathbf{p}_0$ 传播到 $\\mathbf{p}_T$。最终的完成概率是 $p_T(2)$。\n\n第二个任务是构建并求解优化问题。目标是选择一个行动序列，以在总预算约束 $B$ 下，最大化在截止时间 $T$ 时处于完成状态 $s=2$ 的概率。设 $\\mathcal{A}=(a_0, \\dots, a_{T-1})$ 为一个行动序列。目标函数是 $p_T(2;\\mathcal{A})$，使用上面推导的递归计算。约束是行动的总成本 $\\sum_{t=0}^{T-1} c(a_t) \\le B$。优化问题是：\n$$\n\\max_{\\mathcal{A}=(a_0, \\dots, a_{T-1})} \\quad p_T(2;\\mathcal{A})\n$$\n约束条件：\n$$\n\\sum_{t=0}^{T-1} c(a_t) \\le B\n$$\n$$\na_t \\in \\text{Action Set for all } t\n$$\n由于在给定的测试案例中，时间范围 $T$ 和行动集是有限的，因此可能的行动序列总数是有限的。解决此问题的一个直接且有效的方法是对所有可能的行动序列执行穷举搜索。对于每个序列，我们首先通过检查其总成本是否满足预算约束来验证其是否可行。如果可行，我们使用前向递归计算由此产生的完成概率 $p_T(2)$。最优完成概率是所有可行序列中找到的最大值。\n\n对于一个特定的测试案例，算法按以下步骤进行：\n1. 将变量 `max_p_T_2` 初始化为 $0$。\n2. 生成所有长度为 $T$ 的可能行动序列。对于一个有 $|\\mathcal{S}_A|$ 个行动的问题，存在 $|\\mathcal{S}_A|^T$ 个这样的序列。\n3. 对于每个序列 $(a_0, \\dots, a_{T-1})$：\n   a. 计算总成本 $C = \\sum_{t=0}^{T-1} c(a_t)$。\n   b. 如果 $C > B$，则因不可行而丢弃该序列。\n   c. 如果 $C \\le B$，通过初始化 $\\mathbf{p}_0 = [1, 0, 0]^T$ 并从 $t=0$ 到 $t=T-1$ 迭代递归 $\\mathbf{p}_{t+1} = \\mathbf{P}(a_t)^T \\mathbf{p}_t$ 来计算 $p_T(2)$。\n   d. 更新 `max_p_T_2` = $\\max(\\text{max\\_p\\_T\\_2}, p_T(2))$。\n4. `max_p_T_2` 的最终值是该测试案例的解。此过程应用于指定的四个案例中的每一个。",
            "answer": "```python\nimport numpy as np\nfrom itertools import product\n\ndef solve():\n    \"\"\"\n    Solves the MDP optimization problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        {\n            \"T\": 3, \"B\": 2, \"theta_0\": 0.3, \"theta_1\": 0.4,\n            \"actions\": {\n                0: {\"cost\": 0, \"delta_0\": 0.0, \"delta_1\": 0.0},\n                1: {\"cost\": 1, \"delta_0\": 0.2, \"delta_1\": 0.25}\n            }\n        },\n        {\n            \"T\": 4, \"B\": 1, \"theta_0\": 0.2, \"theta_1\": 0.3,\n            \"actions\": {\n                0: {\"cost\": 0, \"delta_0\": 0.0, \"delta_1\": 0.0},\n                1: {\"cost\": 1, \"delta_0\": 0.3, \"delta_1\": 0.2}\n            }\n        },\n        {\n            \"T\": 0, \"B\": 10, \"theta_0\": 0.5, \"theta_1\": 0.5,\n            \"actions\": {\n                0: {\"cost\": 0, \"delta_0\": 0.0, \"delta_1\": 0.0}\n            }\n        },\n        {\n            \"T\": 2, \"B\": 2, \"theta_0\": 0.25, \"theta_1\": 0.35,\n            \"actions\": {\n                0: {\"cost\": 0, \"delta_0\": 0.0, \"delta_1\": 0.0},\n                1: {\"cost\": 1, \"delta_0\": 0.35, \"delta_1\": 0.15},\n                2: {\"cost\": 2, \"delta_0\": 0.6, \"delta_1\": 0.4}\n            }\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        T = case[\"T\"]\n        B = case[\"B\"]\n        theta_0 = case[\"theta_0\"]\n        theta_1 = case[\"theta_1\"]\n        actions = case[\"actions\"]\n\n        # Handle the boundary case where T=0.\n        # The project state is the initial state, so p_0(2) = 0.\n        if T == 0:\n            results.append(0.0)\n            continue\n            \n        action_ids = list(actions.keys())\n        all_sequences = product(action_ids, repeat=T)\n        \n        max_p_T_2 = 0.0\n\n        for seq in all_sequences:\n            # Check feasibility of the sequence against the budget\n            cost = sum(actions[a][\"cost\"] for a in seq)\n            if cost > B:\n                continue\n\n            # If feasible, compute the deadline-met probability p_T(2)\n            # Initial state probabilities: p_0 = [P(s=0), P(s=1), P(s=2)]\n            p = np.array([1.0, 0.0, 0.0])\n\n            # Apply forward recursion for T steps\n            for t in range(T):\n                action_id = seq[t]\n                action = actions[action_id]\n                \n                # Calculate action-modified transition probabilities\n                pi_0 = min(1.0, theta_0 + action[\"delta_0\"])\n                pi_1 = min(1.0, theta_1 + action[\"delta_1\"])\n\n                p_next_0 = p[0] * (1.0 - pi_0)\n                p_next_1 = p[0] * pi_0 + p[1] * (1.0 - pi_1)\n                p_next_2 = p[1] * pi_1 + p[2]\n\n                p = np.array([p_next_0, p_next_1, p_next_2])\n\n            p_T_2 = p[2]\n            \n            # Update the maximum probability found\n            if p_T_2 > max_p_T_2:\n                max_p_T_2 = p_T_2\n        \n        results.append(round(max_p_T_2, 6))\n\n    # Format and print the final output exactly as specified.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "本练习展示了前向动态规划在解决随机资源分配问题中的强大能力。这里的“状态”被定义为到当前时刻为止已花费的累积预算 。我们将构建一个价值函数，它表示在给定已消耗预算的情况下，到某个时间点所能达成的最小期望违规次数。这个实践旨在帮助您掌握一种在不确定性环境下，解决预算约束序贯决策问题的通用范式。",
            "id": "3130969",
            "problem": "给定一个有限期随机资源分配问题，其目标是最小化预期约束违规次数。在每个离散时间步 $t \\in \\{0,1,\\dots,T-1\\}$，您选择一个非负标量决策 $x_t \\in \\mathbb{R}_{\\ge 0}$。系统受制于一个随机不等式约束，由函数 $g_t(x_t,\\xi_t) = \\xi_t - x_t$ 表示，其中 $\\xi_t$ 是一个随机变量。在时间 $t$ 发生违规的条件是 $g_t(x_t,\\xi_t)  0$，等价于 $\\xi_t  x_t$。设运行中的违规计数为前向递归\n$$\nV_{t+1} = V_t + \\mathbb{1}\\{\\xi_t  x_t\\}, \\quad V_0 = 0,\n$$\n其中 $\\mathbb{1}\\{\\cdot\\}$ 表示指示函数。您的目标是选择序列 $(x_0,\\dots,x_{T-1})$ 以最小化预期总违规次数 $\\mathbb{E}[V_T]$，并满足总预算约束 $\\sum_{t=0}^{T-1} x_t \\le B$。\n\n假设以下模型和基本事实：\n- 对于每个 $t$，随机变量 $\\xi_t$ 是独立的，并服从均值为 $\\mu_t$、标准差为 $\\sigma_t$ 的正态分布，记为 $\\xi_t \\sim \\mathcal{N}(\\mu_t,\\sigma_t^2)$。\n- 指示函数满足 $\\mathbb{E}[\\mathbb{1}\\{A\\}] = \\mathbb{P}(A)$，对于任何事件 $A$。\n- 期望的线性性成立：对于随机变量 $Y_t$，有 $\\mathbb{E}\\Big[\\sum_t Y_t\\Big] = \\sum_t \\mathbb{E}[Y_t]$。\n- 正态随机变量的生存函数是良定义且可数值计算的。\n\n仅从以上基础（定义和定律）出发，完成以下任务。\n\n1) 推导违规计数的条件期望的前向递归，并得出关于决策 $x_t$ 和生存概率 $\\mathbb{P}(\\xi_t  x_t)$ 的 $\\mathbb{E}[V_T]$ 的非渐近表达式。\n\n2) 将预算约束下的 $\\mathbb{E}[V_T]$ 优化问题重构为一个在离散化行动空间上的有限期动态规划问题。具体来说，设决策网格步长为 $\\Delta  0$，并将每个 $x_t$ 限制在网格 $\\{0,\\Delta,2\\Delta,\\dots\\}$ 上，从而使得 $t$ 步后花费的累积预算是 $\\Delta$ 的整数倍。定义一个前向动态规划状态 $b_t \\in \\{0,\\Delta,2\\Delta,\\dots,B\\}$，表示到时间 $t$ 为止使用的累积资源，并定义一个值函数 $F_t(b)$，表示到时间 $t$ 为止，使用恰好为 $b$ 的预算可实现的最小预期违规次数。提供将 $F_t$ 更新到 $F_{t+1}$ 的前向递归，并解释这如何在强制执行预算可行性 $\\sum_{t=0}^{T-1} x_t \\le B$ 的同时，实现对预期违规次数的前向递归。\n\n3) 对以下测试套件进行前向递归的数值实现。在每个测试用例中，您必须计算：\n- 在所有位于网格上的 $(x_t)$ 中，最小预期违规次数 $\\min \\mathbb{E}[V_T]$，\n- 以及一个对应的、满足 $\\sum_{t=0}^{T-1} x_t^\\star \\le B$ 的网格可行最优分配 $(x_0^\\star,\\dots,x_{T-1}^\\star)$。\n\n使用正态生存函数精确评估 $\\mathbb{P}(\\xi_t  x_t)$（不使用蒙特卡洛采样）。您的程序必须通过前向动态规划解决每个测试用例，并输出一行包含结果列表的文本，每个测试用例一个结果。其中每个测试用例的结果是一个列表，其第一个条目是最小预期违规次数，后续条目是按时间顺序排列的最优分配。\n\n测试套件：\n- 案例 A：$T=4$, $\\mu=(1.5,2.0,1.0,3.0)$, $\\sigma=(0.5,1.0,1.5,0.75)$, $B=3.0$, $\\Delta=0.25$。\n- 案例 B：$T=3$, $\\mu=(0.0,0.5,-0.5)$, $\\sigma=(1.0,1.5,0.5)$, $B=0.0$, $\\Delta=0.5$。\n- 案例 C：$T=5$, $\\mu=(0.5,0.5,0.5,0.5,0.5)$, $\\sigma=(0.25,0.25,0.25,0.25,0.25)$, $B=5.0$, $\\Delta=0.5$。\n\n输出格式和数值细节：\n- 对于每个测试用例，输出一个列表，其第一个元素是四舍五入到六位小数的最小预期违规次数，其后是最优决策 $(x_0^\\star,\\dots,x_{T-1}^\\star)$，以十进制数（$\\Delta$ 的倍数）表示。\n- 将所有测试用例的结果聚合到一个列表中，并精确地打印一行包含该列表的文本，不含任何额外文字。例如，打印的行应具有 $[\\text{caseA},\\text{caseB},\\text{caseC}]$ 的形式，其中每个 $\\text{caseX}$ 本身都是一个如上所述的列表。\n- 没有物理单位，也没有角度；所有量都是无单位的实数。",
            "solution": "该问题要求解决一个有限期随机资源分配问题。\n\n### 步骤 1：预期总违规次数 $\\mathbb{E}[V_T]$ 的表达式\n\n期末的总违规次数 $V_T$ 是通过展开给定的 $V_{t+1}$ 前向递归得到的：\n$$\nV_{t+1} = V_t + \\mathbb{1}\\{\\xi_t  x_t\\}, \\quad V_0 = 0\n$$\n从 $t=0$ 到 $T-1$ 展开此式，我们得到：\n$$\nV_T = V_0 + \\sum_{t=0}^{T-1} \\mathbb{1}\\{\\xi_t  x_t\\} = \\sum_{t=0}^{T-1} \\mathbb{1}\\{\\xi_t  x_t\\}\n$$\n目标是最小化这个量的期望值 $\\mathbb{E}[V_T]$。利用给定的期望线性性原理和指示函数的期望性质 $\\mathbb{E}[\\mathbb{1}\\{A\\}] = \\mathbb{P}(A)$，我们可以写出：\n$$\n\\mathbb{E}[V_T] = \\mathbb{E}\\left[\\sum_{t=0}^{T-1} \\mathbb{1}\\{\\xi_t  x_t\\}\\right] = \\sum_{t=0}^{T-1} \\mathbb{E}[\\mathbb{1}\\{\\xi_t  x_t\\}] = \\sum_{t=0}^{T-1} \\mathbb{P}(\\xi_t  x_t)\n$$\n这是预期总违规次数的非渐近表达式。量 $\\mathbb{P}(\\xi_t  x_t)$ 是正态随机变量 $\\xi_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$ 在 $x_t$ 处的生存函数值。\n\n优化问题现在可以表述为：\n$$\n\\min_{x_0, \\dots, x_{T-1}} \\sum_{t=0}^{T-1} \\mathbb{P}(\\xi_t  x_t)\n$$\n受限于：\n$$\n\\sum_{t=0}^{T-1} x_t \\le B, \\quad x_t \\ge 0 \\quad \\forall t \\in \\{0, \\dots, T-1\\}\n$$\n\n### 步骤 2：前向动态规划公式化\n\n我们使用前向动态规划来重构该问题。该问题结构具有可加分离的目标函数和线性总和约束，非常适合这种方法。\n\n- **阶段**: 阶段按时间索引，$t = 0, 1, \\dots, T-1$。\n- **离散化**: 决策 $x_t$ 和预算 $B$ 被离散化为步长 $\\Delta  0$ 的整数倍。\n- **状态**: 阶段 $t$ 的状态是到该阶段为止（包括该阶段）所花费的累积预算。设 $b_t = \\sum_{i=0}^t x_i$。阶段 $t$ 的状态空间是 $\\{0, \\Delta, \\dots, B\\}$。\n- **值函数**: 如题所述，$F_t(b)$ 是从阶段 $0$ 到阶段 $t$，使用恰好为 $b$ 的累积预算所能实现的最小预期违规次数。\n- **成本函数**: 在阶段 $t$ 使用决策 $x_t$ 产生的成本是 $C_t(x_t) = \\mathbb{P}(\\xi_t  x_t)$。\n\nDP 递归过程如下：\n\n**初始化（阶段 $t=0$）:**\n在第一阶段，决策 $x_0$ 决定了初始累积预算 $b_0 = x_0$。值函数是在此阶段产生的成本。\n对于每个可能的累积预算 $b \\in \\{0, \\Delta, \\dots, B\\}$：\n$$\nF_0(b) = C_0(b) = \\mathbb{P}(\\xi_0  b)\n$$\n我们还存储导致此状态的决策，即 $\\pi_0(b) = b$。\n\n**递归（阶段 $t=1, \\dots, T-1$）:**\n为了计算阶段 $t$ 累积预算为 $b$ 时的值函数 $F_t(b)$，我们考虑在阶段 $t$ 可能做出的所有决策 $x_t \\in \\{0, \\Delta, \\dots, b\\}$。如果在阶段 $t$ 花费 $x_t$，那么前一阶段的累积预算必定是 $b - x_t$。达到该前一状态的最小成本是 $F_{t-1}(b - x_t)$。因此，新的总成本是 $F_{t-1}(b - x_t) + C_t(x_t)$。我们选择使该和最小化的决策 $x_t$。\n对于每个 $t \\in \\{1, \\dots, T-1\\}$ 和每个累积预算状态 $b \\in \\{0, \\Delta, \\dots, B\\}$：\n$$\nF_t(b) = \\min_{x_t \\in \\{0, \\Delta, \\dots, b\\}} \\left\\{ F_{t-1}(b - x_t) + C_t(x_t) \\right\\}\n$$\n该状态对应的最优决策被存储下来：\n$$\n\\pi_t(b) = \\arg\\min_{x_t \\in \\{0, \\Delta, \\dots, b\\}} \\left\\{ F_{t-1}(b - x_t) + C_t(x_t) \\right\\}\n$$\n\n**最终解与策略重构:**\n在计算完直到阶段 $T-1$ 的值函数表后，总的最小预期违规次数是表最后一行的最小值，因为使用的总预算可以是任何小于等于 $B$ 的值。\n$$\n\\min \\mathbb{E}[V_T] = \\min_{b \\in \\{0, \\Delta, \\dots, B\\}} F_{T-1}(b)\n$$\n设 $B^\\star$ 是实现此最小值的最优最终累积预算：\n$$\nB^\\star = \\arg\\min_{b \\in \\{0, \\Delta, \\dots, B\\}} F_{T-1}(b)\n$$\n最优分配序列 $(x_0^\\star, x_1^\\star, \\dots, x_{T-1}^\\star)$ 通过从此最终最优状态回溯来重构：\n- 设 $b_{T-1}^\\star = B^\\star$。\n- $x_{T-1}^\\star = \\pi_{T-1}(b_{T-1}^\\star)$。\n- 对于 $t = T-2, \\dots, 0$，递推计算：\n    - $b_t^\\star = b_{t+1}^\\star - x_{t+1}^\\star$。\n    - $x_t^\\star = \\pi_t(b_t^\\star)$。\n\n此过程得出最小预期违规次数和相应的网格可行最优分配。\n\n### 步骤 3：数值实现\n上述逻辑在 Python 中实现。对于 $\\xi_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$，概率 $\\mathbb{P}(\\xi_t  x_t)$ 使用生存函数 `scipy.stats.norm.sf(x_t, loc=mu_t, scale=sigma_t)` 计算。DP 表使用 `numpy` 数组构建，回溯过程恢复最优策略。该实现处理指定的测试用例并按要求格式化输出。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves a stochastic resource allocation problem using forward dynamic programming.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"T\": 4,\n            \"mu\": (1.5, 2.0, 1.0, 3.0),\n            \"sigma\": (0.5, 1.0, 1.5, 0.75),\n            \"B\": 3.0,\n            \"Delta\": 0.25,\n        },\n        {\n            \"T\": 3,\n            \"mu\": (0.0, 0.5, -0.5),\n            \"sigma\": (1.0, 1.5, 0.5),\n            \"B\": 0.0,\n            \"Delta\": 0.5,\n        },\n        {\n            \"T\": 5,\n            \"mu\": (0.5, 0.5, 0.5, 0.5, 0.5),\n            \"sigma\": (0.25, 0.25, 0.25, 0.25, 0.25),\n            \"B\": 5.0,\n            \"Delta\": 0.5,\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        T = case[\"T\"]\n        mu = case[\"mu\"]\n        sigma = case[\"sigma\"]\n        B = case[\"B\"]\n        Delta = case[\"Delta\"]\n\n        # Use integer indices for budget levels to avoid floating point issues\n        # Number of discrete budget levels\n        num_budget_levels = int(round(B / Delta)) + 1\n        \n        # DP table F[t][b_idx] stores the min cost up to stage t with cumulative budget b_idx*Delta\n        F = np.full((T, num_budget_levels), np.inf)\n        \n        # Policy table pi[t][b_idx] stores the optimal decision x_t\n        pi = np.full((T, num_budget_levels), np.nan)\n\n        # Precompute costs C[t][x_idx] = P(xi_t > x_idx*Delta)\n        # The decision x_t can be at most B\n        num_decision_levels = int(round(B / Delta)) + 1\n        C = np.zeros((T, num_decision_levels))\n        for t in range(T):\n            for x_idx in range(num_decision_levels):\n                x_val = x_idx * Delta\n                C[t, x_idx] = norm.sf(x_val, loc=mu[t], scale=sigma[t])\n\n        # Initialization (Stage t=0)\n        # The cumulative budget b_0 is simply the decision x_0\n        for b0_idx in range(num_budget_levels):\n            x0_idx = b0_idx\n            F[0, b0_idx] = C[0, x0_idx]\n            pi[0, b0_idx] = x0_idx * Delta\n\n        # Forward recursion (Stages t=1 to T-1)\n        for t in range(1, T):\n            for b_cum_idx in range(num_budget_levels):\n                min_cost = np.inf\n                best_xt_val = -1.0\n\n                # Iterate through possible decisions x_t at stage t\n                # The cumulative budget b_cum_idx is already given.\n                # The decision x_t can't be larger than the cumulative budget\n                max_xt_idx = b_cum_idx\n                for xt_idx in range(max_xt_idx + 1):\n                    b_prev_idx = b_cum_idx - xt_idx\n                    \n                    cost_at_t = C[t, xt_idx]\n                    total_cost = F[t - 1, b_prev_idx] + cost_at_t\n\n                    if total_cost  min_cost:\n                        min_cost = total_cost\n                        best_xt_val = xt_idx * Delta\n                \n                F[t, b_cum_idx] = min_cost\n                pi[t, b_cum_idx] = best_xt_val\n\n        # Find the final optimal solution\n        # The total budget can be = B, so we look for min cost across all final states\n        final_costs = F[T - 1, :]\n        min_total_cost = np.min(final_costs)\n        \n        # In case of ties, numpy.argmin returns the first occurrence\n        final_b_cum_idx = np.argmin(final_costs)\n        final_b_cum_val = final_b_cum_idx * Delta\n\n        # Backtrack to find the optimal allocation\n        x_opt = np.zeros(T)\n        current_b_cum = final_b_cum_val\n        for t in range(T - 1, -1, -1):\n            current_b_cum_idx = int(round(current_b_cum / Delta))\n            x_opt[t] = pi[t, current_b_cum_idx]\n            current_b_cum -= x_opt[t]\n        \n        # Format the output for the current case\n        case_result = [f\"{min_total_cost:.6f}\"]\n        case_result.extend([f\"{val:.2f}\".rstrip('0').rstrip('.') if val != 0 else \"0.0\" for val in x_opt])\n        results.append(case_result)\n\n    # Format the final output string as a list of lists\n    # Example: [[...], [...], [...]]\n    output_str = \"[\" + \",\".join([\"[\" + \",\".join(map(str, res)) + \"]\" for res in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}