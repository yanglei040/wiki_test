## 引言
在许多科学与工程实践中，我们面临着优化“黑箱”函数的挑战——这些函数可以通过昂贵的实验或模拟进行评估，但其导数信息却无法获取或计算成本过高。我们如何才能在没有梯度指引的情况下，系统而高效地找到最优解？[基于模型的无导数优化](@entry_id:637561)方法（Model-based Derivative-free Optimization, DFO）为这一根本性问题提供了强有力的解答。与[随机搜索](@entry_id:637353)或[模式搜索](@entry_id:170858)相比，这类方法通过构建目标函数的局部“地图”或代理模型，实现了更智能、更快速的收敛。

本文旨在全面介绍[基于模型的无导数优化](@entry_id:637561)这一强大[范式](@entry_id:161181)。我们将从其核心工作原理出发，逐步深入其在复杂现实世界问题中的应用，并最终通过实践加深理解。

在“原则与机制”一章中，我们将深入探讨算法的基石：如何通过插值或回归构建代理模型，以及如何利用信赖域框架来有效管理这些模型，确保搜索过程的稳健性。随后，在“应用与跨学科连接”一章中，我们将展示这些理论如何在机器学习[超参数优化](@entry_id:168477)、工程[模型校准](@entry_id:146456)以及带有复杂约束和多目标结构的问题中发挥作用。最后，“动手实践”部分将提供一系列精心设计的问题，帮助您将理论知识转化为实践技能。

让我们首先进入第一章，揭开基于模型的[无导数方法](@entry_id:162705)背后的精妙原则与机制。

## 原则与机制

在上一章引言的基础上，本章将深入探讨[基于模型的无导数优化](@entry_id:637561)方法的核心原则与内在机制。这些方法的核心思想是，通过迭代构建和优化一个相对简单的**代理模型 (surrogate model)** 来逼近[目标函数](@entry_id:267263)的局部行为，从而在不依赖显式导数的情况下，高效地指导搜索过程。我们将系统地阐述如何构建这些模型、如何在使用中对其进行有效管理，以及如何应对实际应用中遇到的噪声和[模型不确定性](@entry_id:265539)等挑战。

### 代理模型：逼近黑箱

所有基于模型的[无导数方法](@entry_id:162705)都始于一个基本前提：尽管我们无法或不愿计算目标函数 $f(x)$ 的导数，但我们可以通过在少量采样点上的函数值来构建一个廉价的局部近似模型 $m(x)$。这个模型充当了 $f(x)$ 的“替身”或“代理”，我们通过分析和优化这个代理模型来获得关于 $f(x)$ 的洞见，并决定下一步的搜索方向。

#### 通过插值构建模型

构建代理模型最直接的方法是**插值 (interpolation)**。其要求是代理模型 $m(x)$ 在所有已知的采样点 $x_i$ 上必须精确地等于观测到的函数值 $y_i = f(x_i)$。

让我们从一个最简单的场景开始。假设我们正在处理一个[一维优化](@entry_id:635076)问题，并希望构建一个二次代理模型 $m(x) = ax^2 + bx + c$。一个二次函数由三个参数 $(a, b, c)$ 唯一确定，因此，我们至少需要三个采样点来确定这个模型。例如，如果我们在三个点 $(-1, 4.5)$, $(0.5, 1.0)$ 和 $(2, 6.0)$ 处评估了目标函数，我们可以通过建立一个线性方程组来求解模型系数 。具体而言，我们将这三个点代入模型方程：

$a(-1)^2 + b(-1) + c = 4.5$
$a(0.5)^2 + b(0.5) + c = 1.0$
$a(2)^2 + b(2) + c = 6.0$

这是一个关于 $(a, b, c)$ 的三元一次[方程组](@entry_id:193238)。求解这个系统，我们就能得到唯一的二次插值模型。这个过程体现了插值建模的核心：将模型参数的求解问题转化为一个线性代数问题。

这个思想可以自然地推广到更高维度。例如，要在一个 $n$ 维空间中构建一个[线性模型](@entry_id:178302) $m(x) = c + g^T x$，模型包含一个标量截距 $c$ 和一个梯度向量 $g \in \mathbb{R}^n$，总共有 $n+1$ 个未知参数。因此，我们通常需要 $n+1$ 个插值点来唯一确定这个[线性模型](@entry_id:178302)。

#### 几何构型 (Poisedness) 的挑战

然而，仅仅拥有足够数量的点是不够的；这些点的**几何构型 (geometry)** 也至关重要。一个“良好”的几何构型，我们称之为**良态的 (well-poised)**，能确保插值模型被唯一且稳定地确定。反之，一个**病态的 (ill-poised)** 几何构型则会导致模型参数的非唯一性或对微小扰动的极端敏感性。

考虑一个在 $\mathbb{R}^3$ 中构建[线性模型](@entry_id:178302) $m(x) = c + g^T x$ 的例子。理论上我们需要 $3+1=4$ 个点。假设我们选择了四个点 $y_0, y_1, y_2, y_3$。为了唯一确定[梯度向量](@entry_id:141180) $g$，点集需要满足一个关键的几何条件：由这些点生成的差向量，例如 $\{y_1 - y_0, y_2 - y_0, y_3 - y_0\}$，必须是[线性无关](@entry_id:148207)的。换句话说，这四个点不能共面（或共线、共点）。

如果这些点共面，例如它们都位于平面 $x_3=5$ 上，那么任何沿着该平面[法线](@entry_id:167651)方向（如 $(0,0,1)$）的梯度分量变化，都不会影响模型在这些点上的插值结果。这是因为对于任何两个位于平面上的点 $y_i, y_j$，它们的差向量 $y_i - y_j$ 与[法线](@entry_id:167651) $n$ 正交。因此，$g^T(y_i-y_j) = (g+\alpha n)^T(y_i-y_j)$ 对任何标量 $\alpha$ 成立。这意味着[梯度向量](@entry_id:141180) $g$ 的法向分量无法被唯一确定 。在这种情况下，优化算法可能会陷入困境。如果真实的下降方向恰好是这个法向方向，那么基于这个病态模型所预测的梯度将完全忽略这个方向，导致算法停滞不前。

因此，在构建插值模型时，算法必须主动管理插值点集，确保其几何构型始终是良态的。这通常涉及到在必要时替换旧的插值点，以引入新的几何信息，从而保证模型对目标函数的逼近是全面且无偏的。

除了线性或二次[多项式模型](@entry_id:752298)，**[径向基函数](@entry_id:754004) (Radial Basis Functions, RBFs)** 也常被用作代理模型，它们形如 $m(x) = \sum_{j=1}^N w_j \phi(\Vert x - x_j \Vert)$，其中 $\phi(r)$ 是一个仅依赖于距离的核函数（如 $r^3$ 或 $\exp(-(r/\varepsilon)^2)$）。RBF 模型非常灵活，能够拟合复杂的函数形态，但同样需要良态的插值点集来保证其系数 $w_j$ 的稳定求解。

### 信赖域框架：管理模型

拥有一个代理模型只是第一步。接下来的关键问题是：我们应该在多大程度上“信任”这个模型？**信赖域 (Trust-Region, TR)** 框架为我们提供了一个优雅而强大的机制来回答这个问题。

TR方法的核心思想是在当前迭代点 $x_k$ 周围定义一个半径为 $\Delta_k$ 的区域（信赖域），并假设我们的代理模型 $m_k(s)$ 在这个区域内是 $f(x_k+s)$ 的一个可靠近似。然后，我们通过求解一个子问题来找到一个试验步长 $s_k$：
$$
s_k = \arg\min_{\Vert s \Vert \le \Delta_k} m_k(s)
$$
这个子问题寻找在信赖域内能使代理模型值最小化的步长。

#### 步长接受与半径控制

找到了试验步长 $s_k$ 后，我们不能盲目地接受它。我们需要评估这一步的“实际效果”与“模型预测效果”之间的一致性。为此，我们定义两个关键指标：

1.  **实际下降量 (Actual Reduction, ared)**：$f(x_k) - f(x_k + s_k)$，表示目标函数值的真实减少量。
2.  **预测下降量 (Predicted Reduction, pred)**：$m_k(0) - m_k(s_k)$，表示代理模型预测的函数值减少量。

这两个量的比值，记为 $\rho_k = \frac{\text{ared}}{\text{pred}}$，是[信赖域方法](@entry_id:138393)的核心驱动力 。$\rho_k$ 的值反映了模型预测的准确性：

*   **$\rho_k$ 接近或大于1**：表示实际下降量与预测下降量非常吻合，甚至超出了预期。这说明模型在当前信赖域内非常可靠。
*   **$\rho_k$ 是一个小的正数**：表示实际下降量远小于预测值。模型过于乐观，但方向可能是正确的。
*   **$\rho_k$ 是负数或零**：表示试验步长没有带来任何实际的函数下降，甚至导致函数值上升。模型预测完全失败。

基于 $\rho_k$ 的值，我们建立一套步长接受和信赖域半径更新的规则。通常会设定两个阈值 $0  \eta_1  \eta_2  1$：

*   **如果 $\rho_k \le \eta_1$（例如 $\eta_1 = 0.1$）**：模型表现差。我们**拒绝**这一步（$x_{k+1} = x_k$），并缩小信赖域半径（例如 $\Delta_{k+1} = \beta \Delta_k$，其中 $\beta \in (0,1)$，如 $\beta=0.5$），因为当前模型在较大区域内不可信。这次迭代称为**失败迭代 (failure iteration)** 。
*   **如果 $\eta_1  \rho_k \le \eta_2$（例如 $\eta_2 = 0.75$）**：模型表现尚可。我们**接受**这一步（$x_{k+1} = x_k + s_k$），但保持信赖域半径不变（$\Delta_{k+1} = \Delta_k$），因为模型质量没有好到让我们更有信心地扩大搜索范围。
*   **如果 $\rho_k > \eta_2$**：模型表现出色。我们**接受**这一步（$x_{k+1} = x_k + s_k$），并扩大信赖域半径（例如 $\Delta_{k+1} = \gamma \Delta_k$，其中 $\gamma > 1$，如 $\gamma=2.0$），以期在下一次迭代中取得更大进展。这次迭代称为**成功迭代 (successful iteration)** 。

通过这个简单的反馈机制，信赖域算法能够动态地调整其对代理模型的“信任程度”，在模型准确时采取大胆的步伐，在模型失准时变得保守，从而保证了算法的稳定性和收敛性。

#### 确保模型可靠性

尽管 $\rho_k$ 机制非常强大，但它并非万无一失。在某些病态情况下，一个非常大的 $\rho_k$ 值可能并非源于一个好模型，而恰恰是一个坏模型的征兆。

考虑一个例子 ：真实函数在某点附近非常陡峭（梯度和曲率都很大），而我们的代理模型由于某种原因（如不良的插值点）建立得非常“平坦”，严重低估了梯度和曲率。这个“胆小”的模型会预测一个非常小的下降量 (pred)。然而，当我们按照这个模型给出的方向走出一步时，由于真实函数很陡，我们可能会获得一个相当大的实际下降量 (ared)。此时，$\rho_k = \frac{\text{ared}}{\text{pred}}$ 的值会因为分母极小而变得异常大。算法会误以为模型质量极高并大幅增加信赖域半径，但这实际上是将一个错误的模型应用到了更广的范围，可能导致后续优化的失败。

为了防范这类问题，先进的算法会引入额外的模型可靠性检查。一个常见的风险来自代理模型的**曲率信息**，即二次模型中的海森矩阵 $B_k$。插值产生的 $B_k$ 可能存在很大的负[特征值](@entry_id:154894)，这意味着模型在某个方向上是强非凸的，会导致预测下降量 pred 异常大。

一个简单的判断标准，如“只要 $\lambda_{\min}(B_k)  0$ 就认为模型不可靠”，是过于草率的。因为即便是对凸函数的近似，插值模型也可能产生小的负[特征值](@entry_id:154894)。一个更具原则性的标准是，比较二次项带来的预测下降与一次项（梯度）带来的预测下降的相对大小 。当模型沿最负曲率方向的下降潜力（约为 $-\frac{1}{2}\lambda_{\min}(B_k)\Delta_k^2$）与沿[最速下降](@entry_id:141858)方向的下降潜力（约为 $\Vert g_k \Vert \Delta_k$）相当或更大时，我们才认为模型的[海森矩阵](@entry_id:139140)是危险的。这可以表示为一个经过标度的条件：
$$
\lambda_{\min}(B_k) \le - \eta \frac{2 \Vert g_k \Vert}{\Delta_k}
$$
其中 $g_k$ 是模型梯度，$\eta$ 是一个正常数。当这个条件成立，并且 $\rho_k$ 值也显示模型预测失败时，算法就应该判定 $B_k$ 不可靠，并临时切换到一个更稳健的策略，例如忽略二次项，仅使用梯度信息计算步长（即所谓的**柯西步 (Cauchy step)**）。

### 高级模型管理策略

随着算法的进行，我们不仅要被动地评估模型，还需要主动地管理和改进模型，尤其是在面对实际问题中常见的噪声和不确定性时。

#### 带噪声环境下的建模

当[目标函数](@entry_id:267263)评估值包含随机噪声时，即我们观测到的是 $y_i = f(x_i) + \epsilon_i$，其中 $\epsilon_i$ 是噪声，插值建模会遇到严重问题。因为插值模型会试图精确地穿过每一个含噪声的数据点，这实际上是在“拟合噪声”，会导致模型参数的巨大[方差](@entry_id:200758)和极差的预测能力，这种现象称为**[过拟合](@entry_id:139093) (overfitting)**。

在这种情况下，**回归 (regression)** 是比插值更稳健的选择 。回归模型使用比模型参数数量更多的点（$N > p$），并通过最小化模型预测值与观测值之间的[误差平方和](@entry_id:149299)（即最小二乘法）来确定模型参数。通过利用更多的信息，回归模型能够有效地“平均掉”噪声的影响，捕捉数据背后的真实趋势。

从统计学角度看，[模型参数估计](@entry_id:752080)的协方差矩阵为 $\mathrm{Cov}(\hat{\beta}) = \sigma^2 (\Phi^T \Phi)^{-1}$，其中 $\sigma^2$ 是噪声[方差](@entry_id:200758)，$\Phi$ 是[设计矩阵](@entry_id:165826)。总参数[方差](@entry_id:200758)由 $\sigma^2 \mathrm{trace}((\Phi^T \Phi)^{-1})$ 衡量。使用更多的点进行回归通常能减小 $\mathrm{trace}((\Phi^T \Phi)^{-1})$ 这一项，从而降低参数[方差](@entry_id:200758)，得到更可靠的模型。因此，一个有效的策略是：估算噪声水平 $\hat{\sigma}^2$（例如通过在同一点重复评估），然后计算并比较插值模型和[回归模型](@entry_id:163386)的总参数[方差估计](@entry_id:268607)值 $\hat{V}$，选择[方差](@entry_id:200758)更小的那个。

在有噪声的情况下，如何分配有限的函数评估预算也成为一个微妙的权衡问题 。假设我们有一个评估预算，可以选择在新的位置采样（以获取更多几何信息，例如学习曲率），也可以在已有的点上重复采样（通过平均来降低该点的噪声影响）。要构建一个一维二次模型，我们至少需要在三个不同的点[上采样](@entry_id:275608)才能确定曲率。如果只在两个点上重复采样，尽管可以降低这两点上的噪声，但模型的[海森矩阵](@entry_id:139140)（或二次项系数）将无法被确定，导致预测[方差](@entry_id:200758)无穷大。因此，在预算允许的情况下，首要任务是保证点集具有良态的几何构型，其次才是通过重复采样来抑制噪声。

#### 主动改进模型

一个成熟的DFO算法不仅会根据历史数据构建模型，还会智能地选择下一个评估点的位置，以期最大程度地改进模型或加速优化进程。这引出了**探索 (exploration)** 与 **利用 (exploitation)** 之间的经典权衡。

*   **利用**：在我们当前模型认为最可能出现函数最小值的地方进行评估。这对应于寻找使模型预测值 $m_k(s)$ 最小的点。
*   **探索**：在我们模型最不确定的地方进行评估。这有助于减少模型的不确定性，提高模型的全局准确性，避免因模型错误而陷入局部最优。

一个好的点选择策略应该在这两者之间取得平衡 。常见的策略包括：

1.  **置信下界 (Lower Confidence Bound, LCB)**：构建一个“[采集函数](@entry_id:168889)”，如 $LCB(s) = m_k(s) - \kappa_k \sigma_k(s)$，其中 $\sigma_k(s)$ 是模型在点 $s$ 处的[不确定性度量](@entry_id:152963)（例如，高斯过程代理模型的后验标准差）。然[后选择](@entry_id:154665)使 LCB 最小的点。这个策略会同时偏爱模型预测值低（利用）和不确定性高（探索）的点。

2.  **$\epsilon$-约[束方法](@entry_id:636307)**：首先设定一个探索的最低要求，即只在[模型不确定性](@entry_id:265539)大于某个阈值 $\tau_k$ 的区域内进行搜索，然后在这个可行域内，选择能最大化预测下降的点。这种方法将探索作为约束，在满足探索需求的前提下进行利用。

此外，当有多个候选模型（例如，使用不同核函数或参数的RBF模型）时，我们也需要一种高效的方法来从中选择最优者 。一种强大的技术是**[留一法交叉验证](@entry_id:637718) (Leave-One-Out Cross-Validation, LOO-CV)**。传统上，LOO-CV需要对每个候选模型进行 $N$ 次训练（每次留出一个点），计算成本高昂。然而，对于插值模型，存在一个高效的计算捷径：对于第 $i$ 个点的留一预测误差 $e_i^{(-i)}$，可以直接通过一次全数据拟合的结果计算得到，公式为 $e_i^{(-i)} = w_i / (A^{-1})_{ii}$，其中 $w_i$ 是全[数据拟合](@entry_id:149007)的第 $i$ 个系数，$(A^{-1})_{ii}$ 是插值矩阵逆的第 $i$ 个对角元素。这使得我们能够在不增加函数评估次数和少量额外计算成本的情况下，对模型组合进行有效的评估和选择。

### 原则性[终止准则](@entry_id:136282)

任何迭代优化算法都需要一个明确的[终止准则](@entry_id:136282)来判断何时停止搜索。对于基于模型的[无导数方法](@entry_id:162705)，一个健壮的[终止准则](@entry_id:136282)必须同时考虑三个方面，以确保算法确实收敛到了一个近似的（一阶）最优点 。

1.  **近似[最优性条件](@entry_id:634091)**：由于我们没有真实梯度，我们使用模型梯度 $\nabla m_k(0)$ 作为其代理。因此，一个核心条件是模型梯度范数足够小：$\Vert \nabla m_k(0) \Vert \le \varepsilon_g$。

2.  **模型可靠性**：仅当模型 $m_k$ 是对 $f$ 的良好近似时，$\nabla m_k(0)$ 才可信。因此，我们需要确认模型在近期表现稳定且良好。一个好的条件是，在最近的 $L$ 次迭代中，$\rho$ 值一直保持在1附近，例如 $|\rho_j - 1| \le \varepsilon_{\rho}$。

3.  **局部收敛性指标**：信赖域半径 $\Delta_k$ 的大小反映了算法的搜索尺度。当算法收敛时，$\Delta_k$ 通常会变得很小。因此，我们还应要求 $\Delta_k \le \varepsilon_{\Delta}$。

只有当这三个条件**同时**满足时，我们才有充分的理由相信，算法已经找到了一个近似的平稳点，并且这个判断是基于一个可靠的局部模型。任何只依赖其中一两个条件的准则都可能导致过早或错误的终止。例如，仅凭 $\Delta_k$ 很小就终止可能是因为算法因模型质量差而陷入困境；仅凭 $\Vert \nabla m_k(0) \Vert$ 很小就终止则可能源于一个不可靠的模型给出的错误信息。

综上所述，[基于模型的无导数优化](@entry_id:637561)方法是一个由多个相互关联的原则和机制构成的精密系统。从构建良态的插值模型，到在信赖域框架内对其进行动态管理，再到处理噪声和平衡[探索与利用](@entry_id:174107)，每一步都体现了在信息有限的条件下进行有效优化的深刻思想。