{
    "hands_on_practices": [
        {
            "introduction": "在基于模型的无导数优化中，一个核心任务是仅使用函数值来构建目标函数的局部代理模型，并从中提取梯度等信息。此实践旨在通过一个数值实验，让您亲手验证代理模型的准确性如何受到采样点几何构型（即“布点”）和采样半径的深刻影响。通过在一个已知真实梯度的二次函数上构建局部线性模型，您将量化不同采样策略对梯度估计误差的作用，从而直观理解模型“适定性”（poise）的重要性。",
            "id": "3153344",
            "problem": "考虑一个使用局部线性模型进行基于模型的无导数梯度近似的确定性实验。设维度为 $n=2$。通过二次模型定义二次连续可微的目标函数 $f:\\mathbb{R}^2\\to\\mathbb{R}$\n$$\nf(\\mathbf{x})=\\tfrac{1}{2}\\,\\mathbf{x}^{\\top}Q\\,\\mathbf{x}+ \\mathbf{c}^{\\top}\\mathbf{x},\n$$\n其中\n$$\nQ=\\begin{bmatrix}3  1\\\\1  2\\end{bmatrix},\\quad \\mathbf{c}=\\begin{bmatrix}1\\\\-2\\end{bmatrix}.\n$$\n设建模中心为\n$$\n\\mathbf{x}_c=\\begin{bmatrix}0.5\\\\-0.3\\end{bmatrix}.\n$$\n根据多元微积分的基本原理，$\\mathbf{x}_c$ 处的真实梯度是雅可比矩阵（对于标量值函数，即为其梯度）\n$$\n\\nabla f(\\mathbf{x}_c)=Q\\,\\mathbf{x}_c+\\mathbf{c}.\n$$\n一种标准的基于模型的无导数方法仅通过函数值构建一个仿射模型 $m(\\mathbf{x})=a+\\mathbf{g}^{\\top}(\\mathbf{x}-\\mathbf{x}_c)$，具体方法是对 $\\mathbf{x}_c$ 附近的样本点集 $\\{\\mathbf{y}_i\\}_{i=1}^m$ 进行最小二乘拟合，其中 $\\mathbf{s}_i=\\mathbf{y}_i-\\mathbf{x}_c$ 是小位移。估计梯度是从拟合中得到的向量 $\\widehat{\\mathbf{g}}$。科学现实性要求样本集的几何形状影响可辨识性和准确性，并且采样半径控制着在线性模型中忽略曲率所引入的截断误差。\n\n从最小二乘法的基本定义和 $f$ 在 $\\mathbf{x}_c$ 周围的一阶泰勒展开出发，设计一个程序，为每个指定的测试用例构建样本集，使用线性最小二乘法拟合仿射模型，并返回梯度估计误差的欧几里得范数\n$$\n\\left\\|\\widehat{\\mathbf{g}}-\\nabla f(\\mathbf{x}_c)\\right\\|_2.\n$$\n用于在圆上放置点的角度必须以弧度表示。在这个纯数学环境中，不适用任何物理单位。\n\n实现以下测试套件，该套件通过采样半径改变样本密度，通过点的排列改变几何质量。在所有情况下，将中心设置在 $\\mathbf{x}_c$，并在每个采样点上精确计算 $f$ 的值：\n\n- 情况 A (分布良好的几何形状，较大半径)：在 $\\mathbf{x}_c$ 周围半径为 $r=0.5$ 的圆上，有 $m=12$ 个等距点。角度为 $2\\pi i/m$，$i=0,1,\\dots,m-1$，单位为弧度。\n- 情况 B (分布良好的几何形状，较小半径)：在 $\\mathbf{x}_c$ 周围半径为 $r=0.01$ 的圆上，有 $m=12$ 个如上所述的等距点。\n- 情况 C (近似共线的几何形状，较大半径)：点沿着直线方向 $\\mathbf{v}=\\begin{bmatrix}1\\\\ \\varepsilon\\end{bmatrix}$（其中 $\\varepsilon=10^{-3}$）分布，缩放到半径 $r=0.5$，有 $m=12$ 个在区间 $[-1,1]$ 内等距分布的偏移量 $t_i$；$\\mathbf{s}_i=r\\,t_i\\,\\mathbf{v}/\\|\\mathbf{v}\\|_2$。\n- 情况 D (近似共线的几何形状，较小半径)：与情况 C 相同，但半径为 $r=0.01$。\n- 情况 E (退化几何形状)：$m=12$ 个点全部位于 $\\mathbf{x}_c$ (即，对所有 $i$，$\\mathbf{s}_i=\\mathbf{0}$)。\n- 情况 F (最小的分布良好的集合)：在半径为 $r=0.1$ 的圆上，位于角度 $0$、$2\\pi/3$ 和 $4\\pi/3$ 弧度处的 $m=3$ 个点。\n- 情况 G (最小的近似共线集合)：$m=3$ 个点，其中 $\\mathbf{v}=\\begin{bmatrix}1\\\\ \\varepsilon\\end{bmatrix}$ 且 $\\varepsilon=10^{-6}$，偏移量 $t\\in\\{-1,0,1\\}$，半径 $r=0.1$；$\\mathbf{s}_i=r\\,t_i\\,\\mathbf{v}/\\|\\mathbf{v}\\|_2$。\n\n对于每种情况，用一列 1 和 $\\mathbf{s}_i$ 的分量构成设计矩阵，求解关于 $(a,\\widehat{\\mathbf{g}})$ 的线性最小二乘问题，并报告标量误差 $\\left\\|\\widehat{\\mathbf{g}}-\\nabla f(\\mathbf{x}_c)\\right\\|_2$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[result1,result2,result3]”），结果按情况 A 到 G 的顺序排列。",
            "solution": "该问题要求设计一个数值实验，以评估一种基于模型的无导数梯度估计算法的准确性。我们将首先验证问题陈述，然后从基本原理出发开发一个解决方案。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n- **目标函数：** $f(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^{\\top}Q\\mathbf{x} + \\mathbf{c}^{\\top}\\mathbf{x}$，其中 $\\mathbf{x} \\in \\mathbb{R}^2$。\n- **矩阵 Q：** $Q=\\begin{bmatrix}3  1\\\\1  2\\end{bmatrix}$。\n- **向量 c：** $\\mathbf{c}=\\begin{bmatrix}1\\\\-2\\end{bmatrix}$。\n- **建模中心：** $\\mathbf{x}_c=\\begin{bmatrix}0.5\\\\-0.3\\end{bmatrix}$。\n- **真实梯度：** $\\nabla f(\\mathbf{x}_c) = Q\\mathbf{x}_c + \\mathbf{c}$。\n- **仿射模型：** $m(\\mathbf{x}) = a + \\mathbf{g}^{\\top}(\\mathbf{x}-\\mathbf{x}_c)$。待估计的参数是标量截距 $a$ 和梯度向量 $\\widehat{\\mathbf{g}}$。\n- **样本点：** 使用位移 $\\mathbf{s}_i = \\mathbf{y}_i - \\mathbf{x}_c$ 来生成样本点 $\\mathbf{y}_i$。\n- **方法：** 对样本集 $\\{\\mathbf{y}_i\\}_{i=1}^m$ 求解一个线性最小二乘问题以找到 $(a, \\widehat{\\mathbf{g}})$。\n- **输出指标：** 梯度估计误差的欧几里得范数，$\\|\\widehat{\\mathbf{g}} - \\nabla f(\\mathbf{x}_c)\\|_2$。\n- **测试用例：**\n    - **A：** $r=0.5, m=12$，圆形几何构型。\n    - **B：** $r=0.01, m=12$，圆形几何构型。\n    - **C：** $r=0.5, m=12$，近似共线几何构型，其中 $\\mathbf{v}=\\begin{bmatrix}1\\\\10^{-3}\\end{bmatrix}$。\n    - **D：** $r=0.01, m=12$，与 C 相同的近似共线几何构型。\n    - **E：** $r$ 未定义 (所有点都在中心)，$m=12$，退化几何构型，其中 $\\mathbf{s}_i=\\mathbf{0}$。\n    - **F：** $r=0.1, m=3$，最小分布良好的圆形几何构型。\n    - **G：** $r=0.1, m=3$，最小近似共线几何构型，其中 $\\mathbf{v}=\\begin{bmatrix}1\\\\10^{-6}\\end{bmatrix}$，偏移量 $t\\in\\{-1,0,1\\}$。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题牢固地植根于数值优化领域，特别是在无导数方法的分析中。使用二次测试函数和线性模型是分析算法属性的标准技术。最小二乘拟合、模型适定性以及样本几何形状影响等概念是该领域的核心。所有数学公式都是正确的。\n- **适定性：** 该问题是适定的。只要设计矩阵是列满秩的，最小二乘问题就有唯一解。这些测试用例旨在探索该条件在不同稳定程度下成立的场景（情况 A、B、C、D、F）以及不成立的场景（情况 E、G）。这些失败案例本身是分析的重要组成部分，并会导致标准数值线性代数程序产生可预测的结果。\n- **客观性：** 问题陈述是精确、定量的，并且没有主观因素。\n\n**步骤 3：结论与行动**\n该问题在科学上是合理的、适定的和客观的。这是数值分析中一个有效且有指导意义的练习。我们将继续进行完整的解答。\n\n### 基于原理的解决方案设计\n\n任务的核心是通过拟合一个局部仿射模型 $m(\\mathbf{x}) = a + \\mathbf{g}^{\\top}(\\mathbf{x}-\\mathbf{x}_c)$，仅使用在一组样本点 $\\{\\mathbf{y}_i\\}_{i=1}^m$ 上计算的函数值，来近似函数 $f:\\mathbb{R}^n \\to \\mathbb{R}$ 在点 $\\mathbf{x}_c$ 处的梯度。\n\n**1. 理论阐述**\n\n我们寻求找到参数 $a \\in \\mathbb{R}$ 和 $\\widehat{\\mathbf{g}} \\in \\mathbb{R}^n$，以最小化模型在样本点上的预测值与真实函数值之间的平方差之和。设位移向量为 $\\mathbf{s}_i = \\mathbf{y}_i - \\mathbf{x}_c$。在 $\\mathbf{y}_i$ 处评估的模型为 $m(\\mathbf{y}_i) = a + \\widehat{\\mathbf{g}}^{\\top}\\mathbf{s}_i$。最小二乘问题是：\n$$ \\min_{a, \\widehat{\\mathbf{g}}} \\sum_{i=1}^m \\left( (a + \\widehat{\\mathbf{g}}^{\\top}\\mathbf{s}_i) - f(\\mathbf{y}_i) \\right)^2 $$\n这是一个标准的线性最小二乘问题。设参数向量为 $\\boldsymbol{\\theta} = \\begin{bmatrix} a \\\\ \\widehat{\\mathbf{g}} \\end{bmatrix} \\in \\mathbb{R}^{1+n}$。对于我们的问题，$n=2$，因此 $\\boldsymbol{\\theta} \\in \\mathbb{R}^3$。我们可以将该系统表示为矩阵形式 $M\\boldsymbol{\\theta} \\approx \\mathbf{f}_{vals}$，其中：\n-   $M$ 是 $m \\times (1+n)$ 的设计矩阵。每一行对应一个样本点：\n    $$ M = \\begin{bmatrix} 1  \\mathbf{s}_1^{\\top} \\\\ 1  \\mathbf{s}_2^{\\top} \\\\ \\vdots  \\vdots \\\\ 1  \\mathbf{s}_m^{\\top} \\end{bmatrix} = \\begin{bmatrix} 1  s_{1,1}  s_{1,2} \\\\ 1  s_{2,1}  s_{2,2} \\\\ \\vdots  \\vdots  \\vdots \\\\ 1  s_{m,1}  s_{m,2} \\end{bmatrix} $$\n-   $\\mathbf{f}_{vals}$ 是 $m \\times 1$ 的函数求值向量：\n    $$ \\mathbf{f}_{vals} = \\begin{bmatrix} f(\\mathbf{y}_1) \\\\ f(\\mathbf{y}_2) \\\\ \\vdots \\\\ f(\\mathbf{y}_m) \\end{bmatrix} $$\n最小化 $\\|M\\boldsymbol{\\theta} - \\mathbf{f}_{vals}\\|_2^2$ 的最小二乘解 $\\boldsymbol{\\theta}^*$ 可通过求解正规方程 $M^{\\top}M\\boldsymbol{\\theta} = M^{\\top}\\mathbf{f}_{vals}$ 得到。在实践中，会使用数值稳定的算法，例如基于 QR 分解或奇异值分解 (SVD) 的算法。估计梯度 $\\widehat{\\mathbf{g}}$ 由解向量 $\\boldsymbol{\\theta}^*$ 的最后 $n=2$ 个分量组成。\n\n**2. 二次函数的误差分析**\n\n给定的目标函数 $f(\\mathbf{x})$ 是一个二次函数。它在 $\\mathbf{x}_c$ 周围的泰勒级数展开是精确的，并在二阶项处终止：\n$$ f(\\mathbf{x}_c + \\mathbf{s}) = f(\\mathbf{x}_c) + \\nabla f(\\mathbf{x}_c)^{\\top}\\mathbf{s} + \\frac{1}{2}\\mathbf{s}^{\\top}\\nabla^2 f(\\mathbf{x}_c)\\mathbf{s} $$\n对于给定的 $f$，梯度为 $\\nabla f(\\mathbf{x}) = Q\\mathbf{x} + \\mathbf{c}$，海森矩阵为常数 $\\nabla^2 f(\\mathbf{x}) = Q$。因此，函数值的向量可以写为：\n$$ \\mathbf{f}_{vals, i} = f(\\mathbf{x}_c) + \\nabla f(\\mathbf{x}_c)^{\\top}\\mathbf{s}_i + \\frac{1}{2}\\mathbf{s}_i^{\\top}Q\\mathbf{s}_i $$\n最小二乘求解器实际上是试图将一个线性模型拟合到这个二次数据上。差异源于二次项 $\\frac{1}{2}\\mathbf{s}_i^{\\top}Q\\mathbf{s}_i$，这是仿射模型的截断误差。估计梯度的误差 $\\Delta\\mathbf{g} = \\widehat{\\mathbf{g}} - \\nabla f(\\mathbf{x}_c)$ 直接归因于样本集的几何形状（编码在 $M$ 中）如何将这些二次项映射到解中。可以证明，参数向量的误差为 $\\Delta\\boldsymbol{\\theta} = (M^{\\top}M)^{-1}M^{\\top}\\mathbf{b}$，其中 $b_i = \\frac{1}{2}\\mathbf{s}_i^{\\top}Q\\mathbf{s}_i$。因此，梯度估计 $\\widehat{\\mathbf{g}}$ 的质量关键取决于 $M$ 的性质，这个概念被称为样本集的“适定性”。\n\n**3. 实现步骤**\n\n我们将为每个测试用例实现一个遵循以下步骤的程序。\n\n**步骤 A：初始化**\n首先，我们定义恒定问题参数 $Q$、$\\mathbf{c}$ 和 $\\mathbf{x}_c$。然后我们计算真实梯度，它将作为我们的基准：\n$$ \\nabla f(\\mathbf{x}_c) = Q\\mathbf{x}_c + \\mathbf{c} = \\begin{bmatrix}3  1\\\\1  2\\end{bmatrix}\\begin{bmatrix}0.5\\\\-0.3\\end{bmatrix} + \\begin{bmatrix}1\\\\-2\\end{bmatrix} = \\begin{bmatrix}1.2\\\\-0.1\\end{bmatrix} + \\begin{bmatrix}1\\\\-2\\end{bmatrix} = \\begin{bmatrix}2.2\\\\-2.1\\end{bmatrix} $$\n\n**步骤 B：各用例计算循环**\n对于情况 A 到 G 中的每一种，我们执行以下操作：\n1.  **生成样本位移：** 创建一个 $m \\times 2$ 的矩阵 $S$，其中每一行都是由该情况指定的位移向量 $\\mathbf{s}_i^{\\top}$（例如，圆上的点，直线上的点）。\n2.  **函数求值：** 通过 $\\mathbf{y}_i = \\mathbf{x}_c + \\mathbf{s}_i$ 形成样本点。对每个 $\\mathbf{y}_i$ 计算函数 $f(\\mathbf{y}_i) = \\tfrac{1}{2}\\mathbf{y}_i^{\\top}Q\\mathbf{y}_i + \\mathbf{c}^{\\top}\\mathbf{y}_i$ 的值，以创建向量 $\\mathbf{f}_{vals}$。\n3.  **构造设计矩阵：** 通过在位移矩阵 $S$ 前面增广一列 1 来构造 $m \\times 3$ 的设计矩阵 $M$。\n4.  **求解最小二乘问题：** 使用数值线性最小二乘求解器找到最小化 $\\|M\\boldsymbol{\\theta} - \\mathbf{f}_{vals}\\|_2$ 的 $\\boldsymbol{\\theta}^* = [a, \\widehat{g}_1, \\widehat{g}_2]^{\\top}$。这通过提供最小范数解来鲁棒地处理秩亏情况（E 和 G）。\n5.  **提取梯度并计算误差：** 从 $\\boldsymbol{\\theta}^*$ 中提取估计梯度 $\\widehat{\\mathbf{g}} = [\\widehat{g}_1, \\widehat{g}_2]^{\\top}$。最终误差计算为差值的欧几里得范数：$\\|\\widehat{\\mathbf{g}} - \\nabla f(\\mathbf{x}_c)\\|_2$。\n\n这个系统性过程允许直接比较采样半径和几何排列如何影响梯度近似的准确性。例如，由于误差项的抵消，我们期望情况 A 和 B 中的对称几何构型能够产生高度准确的结果（误差接近机器精度），而情况 C、D 和 G 中的病态几何构型将导致更大的误差。情况 E 代表了可辨识性的完全失败。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the gradient estimation error in a model-based derivative-free\n    method for a series of test cases.\n    \"\"\"\n    \n    # Define problem constants\n    Q = np.array([[3.0, 1.0], [1.0, 2.0]])\n    c = np.array([1.0, -2.0])\n    xc = np.array([0.5, -0.3])\n    \n    # Define the quadratic objective function\n    def f(x):\n        return 0.5 * x.T @ Q @ x + c.T @ x\n        \n    # Calculate the true gradient at xc\n    grad_true = Q @ xc + c\n    \n    # Define the test suite\n    test_cases = [\n        # Case A: well-spread, larger radius\n        {'name': 'A', 'r': 0.5, 'm': 12, 'type': 'circle'},\n        # Case B: well-spread, smaller radius\n        {'name': 'B', 'r': 0.01, 'm': 12, 'type': 'circle'},\n        # Case C: nearly collinear, larger radius\n        {'name': 'C', 'r': 0.5, 'm': 12, 'type': 'line', 'eps': 1e-3},\n        # Case D: nearly collinear, smaller radius\n        {'name': 'D', 'r': 0.01, 'm': 12, 'type': 'line', 'eps': 1e-3},\n        # Case E: degenerate geometry\n        {'name': 'E', 'm': 12, 'type': 'degenerate'},\n        # Case F: minimal well-spread set\n        {'name': 'F', 'r': 0.1, 'm': 3, 'type': 'circle'},\n        # Case G: minimal nearly collinear set\n        {'name': 'G', 'r': 0.1, 'm': 3, 'type': 'line', 'eps': 1e-6, 't_offsets': [-1, 0, 1]},\n    ]\n    \n    results = []\n    \n    for case in test_cases:\n        m = case['m']\n        \n        # 1. Generate sample displacements S\n        S = np.zeros((m, 2))\n        \n        if case['type'] == 'circle':\n            r = case['r']\n            if case['name'] == 'F':\n                angles = np.array([0, 2 * np.pi / 3, 4 * np.pi / 3])\n            else: # Cases A, B\n                angles = np.linspace(0, 2 * np.pi, m, endpoint=False)\n            S[:, 0] = r * np.cos(angles)\n            S[:, 1] = r * np.sin(angles)\n            \n        elif case['type'] == 'line':\n            r = case['r']\n            eps = case['eps']\n            v = np.array([1.0, eps])\n            v_norm = v / np.linalg.norm(v)\n            if 't_offsets' in case: # Case G\n                t = np.array(case['t_offsets'])\n            else: # Cases C, D\n                t = np.linspace(-1.0, 1.0, m)\n            S = t[:, np.newaxis] * v_norm\n            \n        elif case['type'] == 'degenerate': # Case E\n            # S is already initialized to zeros\n            pass\n\n        # 2. Evaluate function\n        Y = xc + S\n        f_vals = np.array([f(y) for y in Y])\n        \n        # 3. Construct design matrix M\n        M = np.hstack([np.ones((m, 1)), S])\n        \n        # 4. Solve least-squares problem\n        # theta = [a, g_hat_1, g_hat_2]\n        # Use rcond=None to use machine precision for rank detection\n        theta, _, _, _ = np.linalg.lstsq(M, f_vals, rcond=None)\n        \n        # 5. Extract gradient and compute error\n        g_hat = theta[1:]\n        error = np.linalg.norm(g_hat - grad_true)\n        results.append(error)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{res:.12e}' for res in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "局部多项式模型是无导数优化中的常用工具，但它们并非万能，其有效性存在基本限制。当目标函数的振荡频率过高，超出了采样点所能解析的范围时，模型会“看到”一个被扭曲的、频率更低的假象，这种现象被称为“混叠”（aliasing）。本练习将引导您设计一个课程化的测试，通过构建具有可控振荡的合成函数，并与采样分辨率和模型复杂度进行对比，从而让您凭经验识别出多项式模型因混叠效应而失效的临界条件。",
            "id": "3153263",
            "problem": "要求您实现一个独立的程序，用于构建和评估具有可控振荡的合成函数的局部多项式模型，以便根据经验确定这些模型何时因混叠而失效。其背景是基于模型的无导数方法，其中局部代理模型是根据采样函数值构建的，而无需访问导数。使用的基本原理包括：多项式最小二乘拟合的定义、在信赖域上对函数进行均匀采样，以及奈奎斯特-香农采样定理 (Nyquist-Shannon Sampling Theorem, NSST)。该定理指出，具有最大频率的带限信号需要一个最小采样率以避免混叠。\n\n待研究的合成函数是一维的，并定义在原点周围的对称信赖域上。每个函数都由一个多项式部分和具有可调角频率与振幅的正弦项的有限和构成。具体定义如下\n$$\nf(x) \\;=\\; \\sum_{j=0}^{p_{\\mathrm{base}}} a_j x^j \\;+\\; \\sum_{k=1}^{K} \\alpha_k \\,\\sin\\!\\big(\\omega_k x\\big),\n$$\n其中 $x$ 是无量纲的，所有角度均以弧度为单位，$p_{\\mathrm{base}}$ 是基函数的多项式次数，$a_j$ 是实系数，$K$ 是振荡分量的数量，$\\alpha_k$ 是振幅，$\\omega_k$ 是角频率。要拟合的局部多项式代理模型 $m(x)$ 的次数为 $p$，它是通过在区间 $[-r, r]$ 内的 $n$ 个均匀间隔的样本上进行最小二乘法构建的，其中 $r$ 是信赖域半径，且 $n \\geq p+1$。\n\n对于每个测试用例，您的程序必须执行以下步骤：\n- 使用指定的系数和振荡参数构建合成函数 $f(x)$。\n- 在 $[-r, r]$ 区间内以 $h = \\frac{2r}{n-1}$ 的间距对 $f(x)$ 进行 $n$ 个均匀间隔点的采样。\n- 通过求解最小二乘问题，拟合一个次数为 $p$ 的局部多项式模型，以确定以下表达式中的系数 $\\{c_j\\}_{j=0}^p$\n$$\nm(x) \\;=\\; \\sum_{j=0}^{p} c_j x^j.\n$$\n- 在 $[-r, r]$ 区间内一个包含 $N_{\\mathrm{val}}$ 个点的精细验证网格上评估模型保真度，并计算由下式定义的归一化均方根误差 (NRMSE)：\n$$\n\\mathrm{NRMSE} \\;=\\; \\sqrt{\\frac{\\sum_{i=1}^{N_{\\mathrm{val}}} \\big(m(x_i) - f(x_i)\\big)^2}{\\sum_{i=1}^{N_{\\mathrm{val}}} \\big(f(x_i)\\big)^2 \\;+\\; \\epsilon}},\n$$\n其中 $\\epsilon$ 是一个小的正常数，用以避免除以零。如果 $\\mathrm{NRMSE} \\ge \\tau$，则声明因混叠而失效，其中 $\\tau$ 是一个指定的阈值。\n\n为实现测试覆盖，需要设计一系列测试用例，通过改变振荡频率、采样分辨率和模型次数来探究混叠的发生点。使用以下测试套件，其中所有角度均以弧度为单位，所有量均为无量纲：\n- 测试用例 1 (理想情况，低频被良好解析):\n  - 基多项式次数 $p_{\\mathrm{base}} = 0$，系数 $a_0 = 0$。\n  - 振荡：$K = 1$，振幅 $\\alpha_1 = 1$，角频率 $\\omega_1 = 2$。\n  - 信赖域半径 $r = 1$，样本数 $n = 9$，模型次数 $p = 3$，阈值 $\\tau = 0.2$，验证点数 $N_{\\mathrm{val}} = 401$。\n- 测试用例 2 (边界情况，高频略微欠解析):\n  - $p_{\\mathrm{base}} = 0$, $a_0 = 0$。\n  - $K = 1$，振幅 $\\alpha_1 = 1$，角频率 $\\omega_1 = 10$。\n  - $r = 1$, $n = 7$, $p = 3$, $\\tau = 0.2$, $N_{\\mathrm{val}} = 401$。\n- 测试用例 3 (对相同高频提高分辨率):\n  - $p_{\\mathrm{base}} = 0$, $a_0 = 0$。\n  - $K = 1$，振幅 $\\alpha_1 = 1$，角频率 $\\omega_1 = 10$。\n  - $r = 1$, $n = 13$, $p = 3$, $\\tau = 0.2$, $N_{\\mathrm{val}} = 401$。\n- 测试用例 4 (多频率，最高分量欠解析):\n  - $p_{\\mathrm{base}} = 0$, $a_0 = 0$。\n  - $K = 2$，$(\\alpha_1, \\omega_1) = (0.5, 5)$，$(\\alpha_2, \\omega_2) = (0.5, 20)$。\n  - $r = 1$, $n = 9$, $p = 3$, $\\tau = 0.2$, $N_{\\mathrm{val}} = 401$。\n- 测试用例 5 (更高次模型与良好解析的高频):\n  - $p_{\\mathrm{base}} = 0$, $a_0 = 0$。\n  - $K = 1$，振幅 $\\alpha_1 = 1$，角频率 $\\omega_1 = 12$。\n  - $r = 1$, $n = 21$, $p = 5$, $\\tau = 0.2$, $N_{\\mathrm{val}} = 401$。\n\n您的程序必须为每个测试用例生成一个布尔结果：如果检测到失效，则为 $ \\mathrm{True}$，否则为 $ \\mathrm{False}$。最终输出必须是单行文本，其中包含所有测试用例的结果，形式为方括号括起来的逗号分隔列表，例如 $[ \\mathrm{True}, \\mathrm{False}, \\mathrm{False}, \\mathrm{True}, \\mathrm{False} ]$。所有三角函数参数都必须视为弧度，不涉及其他单位。不允许用户输入或外部文件；所有参数均按上文规定固定。",
            "solution": "该问题要求在无导数优化的背景下，对局部多项式代理模型的失效进行实证研究。具体来说，我们需要确定这种模型何时无法准确表示一个由正弦振荡组成的底层函数。这种失效被称为混叠，发生在采样率不足以捕捉函数高频分量时。分析的核心基于多项式最小二乘拟合和奈奎斯特-香农采样定理的原理。\n\n首先，我们来形式化局部多项式模型的构建过程。给定一个目标函数 $f(x)$，需要在某个半径 $r > 0$ 的对称信赖域（即区间 $[-r, r]$）内对其进行近似。局部模型 $m(x)$ 是一个次数为 $p$ 的多项式：\n$$\nm(x) = \\sum_{j=0}^{p} c_j x^j\n$$\n系数 $c_0, c_1, \\ldots, c_p$ 是未知的，必须被确定。在基于模型的无导数方法中，这些系数是通过在信赖域内的一组 $n$ 个采样点 $\\{x_i\\}_{i=1}^n$ 上评估真实函数 $f(x)$ 来找到的，从而得到函数值 $\\{y_i = f(x_i)\\}_{i=1}^n$。问题规定这些点是均匀分布的，间距为 $h = \\frac{2r}{n-1}$。为了唯一确定一个多项式模型，我们必须有至少 $p+1$ 个点，因此 $n \\ge p+1$。\n\n系数 $\\mathbf{c} = [c_0, c_1, \\ldots, c_p]^T$ 是通过求解一个线性最小二乘问题找到的。我们旨在最小化模型预测值与采样函数值之间的平方差之和：\n$$\n\\min_{\\mathbf{c}} \\sum_{i=1}^{n} \\left( m(x_i) - y_i \\right)^2\n$$\n这等同于在最小二乘意义上求解方程组 $V\\mathbf{c} \\approx \\mathbf{y}$，其中 $\\mathbf{y} = [y_1, y_2, \\ldots, y_n]^T$ 是采样函数值的向量，而 $V$ 是一个 $n \\times (p+1)$ 的范德蒙德矩阵 (Vandermonde matrix)，其元素由 $V_{ij} = x_i^{j-1}$ 给出（对于 $i=1, \\ldots, n$ 和 $j=1, \\ldots, p+1$）。这个超定系统的解由正规方程给出：\n$$\n(V^T V) \\mathbf{c} = V^T \\mathbf{y}\n$$\n\n需要研究的核心科学原理是混叠。合成函数的定义如下：\n$$\nf(x) \\;=\\; \\sum_{j=0}^{p_{\\mathrm{base}}} a_j x^j \\;+\\; \\sum_{k=1}^{K} \\alpha_k \\,\\sin\\!\\big(\\omega_k x\\big)\n$$\n该函数是一个基多项式和一组角频率为 $\\omega_k$ 的正弦波之和。根据奈奎斯特-香农采样定理，要准确重建一个信号，采样频率必须严格大于信号中最大频率的两倍。在我们的情境中，采样是空间上的，而不是时间上的。采样间隔为 $h = \\frac{2r}{n-1}$。空间采样率为 $f_s = 1/h = \\frac{n-1}{2r}$。我们函数 $f(x)$ 中的最大频率是 $f_{\\max} = \\frac{\\max_k(\\omega_k)}{2\\pi}$。因此，奈奎斯特准则为：\n$$\nf_s > 2 f_{\\max} \\quad \\implies \\quad \\frac{n-1}{2r} > 2 \\left( \\frac{\\max_k(\\omega_k)}{2\\pi} \\right) \\quad \\implies \\quad \\frac{\\pi(n-1)}{r} > \\max_k(\\omega_k)\n$$\n如果违反此条件，高频正弦分量 $\\sin(\\omega_k x)$ 将会发生混叠；这些样本点看起来会像是来自一个频率更低的正弦波，而多项式模型 $m(x)$ 可能会试图去拟合这个低频波形。这会导致模型对真实函数 $f(x)$ 的表示很差，从而产生很高的近似误差。\n\n为了量化这个误差，我们在一个包含 $N_{\\mathrm{val}}$ 个点的精细验证网格上计算归一化均方根误差 (NRMSE)：\n$$\n\\mathrm{NRMSE} \\;=\\; \\sqrt{\\frac{\\sum_{i=1}^{N_{\\mathrm{val}}} \\big(m(x_i) - f(x_i)\\big)^2}{\\sum_{i=1}^{N_{\\mathrm{val}}} \\big(f(x_i)\\big)^2 \\;+\\; \\epsilon}}\n$$\n其中 $\\epsilon$ 是一个小的正则化常数（例如 $10^{-12}$），用以防止除以零。对于给定的阈值 $\\tau$，如果 $\\mathrm{NRMSE} \\ge \\tau$，则声明模型失效。\n\n每个测试用例的算法流程如下：\n1.  使用指定的参数（$p_{\\mathrm{base}}, a_j, K, \\alpha_k, \\omega_k$）定义目标函数 $f(x)$。对于所有给定案例，$p_{\\mathrm{base}}=0, a_0=0$，从而将 $f(x)$ 简化为正弦波之和。\n2.  在 $[-r, r]$ 区间内生成 $n$ 个均匀间隔的采样点 $x_i$。\n3.  计算相应的函数值 $y_i = f(x_i)$。\n4.  求解最小二乘问题，以找到次数为 $p$ 的多项式模型 $m(x)$ 的系数 $\\{c_j\\}_{j=0}^p$。\n5.  在 $[-r, r]$ 区间内生成一个包含 $N_{\\mathrm{val}}$ 个点的精细验证网格。\n6.  在此验证网格上评估 $f(x)$ 和 $m(x)$。\n7.  使用指定公式计算 NRMSE。\n8.  将 NRMSE 与阈值 $\\tau$ 进行比较。如果 $\\mathrm{NRMSE} \\ge \\tau$，则检测到失效（$\\mathrm{True}$）。否则，认为模型是足够的（$\\mathrm{False}$）。\n\n此流程将应用于所提供的五个测试用例中的每一个。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n\n    # A small constant to prevent division by zero in NRMSE calculation.\n    epsilon = 1e-12\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: happy path, low frequency well-resolved\n        {'p_base': 0, 'a_coeffs': [0], 'oscillations': [(1, 2)], \n         'r': 1, 'n': 9, 'p': 3, 'tau': 0.2, 'N_val': 401},\n        # Case 2: boundary, slightly under-resolved high frequency\n        {'p_base': 0, 'a_coeffs': [0], 'oscillations': [(1, 10)], \n         'r': 1, 'n': 7, 'p': 3, 'tau': 0.2, 'N_val': 401},\n        # Case 3: improved resolution for the same high frequency\n        {'p_base': 0, 'a_coeffs': [0], 'oscillations': [(1, 10)], \n         'r': 1, 'n': 13, 'p': 3, 'tau': 0.2, 'N_val': 401},\n        # Case 4: multiple frequencies, highest component under-resolved\n        {'p_base': 0, 'a_coeffs': [0], 'oscillations': [(0.5, 5), (0.5, 20)], \n         'r': 1, 'n': 9, 'p': 3, 'tau': 0.2, 'N_val': 401},\n        # Case 5: higher-degree model with well-resolved high frequency\n        {'p_base': 0, 'a_coeffs': [0], 'oscillations': [(1, 12)], \n         'r': 1, 'n': 21, 'p': 5, 'tau': 0.2, 'N_val': 401}\n    ]\n\n    results = []\n    for params in test_cases:\n        # Extract parameters for the current test case\n        r = params['r']\n        n = params['n']\n        p = params['p']\n        tau = params['tau']\n        N_val = params['N_val']\n        oscillations = params['oscillations']\n        \n        # 1. Construct the synthetic function f(x)\n        def f(x_values):\n            # The problem specifies p_base=0, a_0=0 for all cases,\n            # so the base polynomial term is zero.\n            y = np.zeros_like(x_values, dtype=float)\n            for alpha, omega in oscillations:\n                y += alpha * np.sin(omega * x_values)\n            return y\n\n        # 2. Sample f(x) at n uniformly spaced points in [-r, r]\n        x_samples = np.linspace(-r, r, n)\n        y_samples = f(x_samples)\n\n        # 3. Fit a local polynomial model of degree p\n        # np.polyfit solves the least-squares problem and returns coefficients\n        # in descending order of power.\n        model_coeffs = np.polyfit(x_samples, y_samples, p)\n        \n        # Create a callable model from the coefficients\n        m = np.poly1d(model_coeffs)\n\n        # 4. Evaluate the model fidelity on a fine validation grid\n        x_val = np.linspace(-r, r, N_val)\n        y_f_val = f(x_val)\n        y_m_val = m(x_val)\n\n        # 5. Compute the Normalized Root-Mean-Square Error (NRMSE)\n        sum_sq_err = np.sum((y_m_val - y_f_val) ** 2)\n        sum_sq_f = np.sum(y_f_val ** 2)\n        \n        nrmse = np.sqrt(sum_sq_err / (sum_sq_f + epsilon))\n        \n        # 6. Declare a breakdown if NRMSE >= tau\n        is_breakdown = nrmse >= tau\n        results.append(is_breakdown)\n\n    # Final print statement in the exact required format [True, False, ...]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "标准的信赖域方法通常使用球形区域来约束优化步长，但这对于曲率在不同方向上差异巨大的“病态”函数而言效率低下。一个更先进的策略是使用各向异性信赖域，其形状为椭球体，能够更好地适应函数的局部几何特性，从而产生更有效的寻优步。本练习将挑战您实现并对比球形与椭球形两种信赖域方法，通过变量变换和迭代求解器，您将亲眼见证，让算法的几何结构与函数的内在几何结构相匹配，能够如何显著提升在困难问题上的优化性能。",
            "id": "3153334",
            "problem": "给定一个场景，其中目标函数的曲率在不同坐标轴上差异巨大，您需要在一个基于模型的无导数优化框架中，比较球形信赖域与由椭球范数定义的各向异性信賴域的有效性。核心任务是实现一个程序，该程序为多个测试用例，仅使用函数评估值构建一个局部二次模型，然后在两种不同的范数下求解信赖域子问题以提出步长。程序必须报告椭球范数是否比欧几里得范数产生了严格更优或相等的目标函数下降。\n\n该问题的基础包括以下要素：\n- 在点 $\\mathbf{x}_k$ 附近的目标函数的局部二次模型，表示为 $m(\\mathbf{s}) = c + \\mathbf{g}^\\top \\mathbf{s} + \\frac{1}{2}\\mathbf{s}^\\top H \\mathbf{s}$，其中 $\\mathbf{s} = \\mathbf{x} - \\mathbf{x}_k$，$c \\in \\mathbb{R}$，$\\mathbf{g} \\in \\mathbb{R}^n$，且 $H \\in \\mathbb{R}^{n \\times n}$ 是对称矩阵。\n- 信赖域子问题，即求解近似最小化模型 $m(\\mathbf{s})$ 的步长 $\\mathbf{s}$，约束条件为范数约束 $\\|\\mathbf{s}\\| \\leq \\Delta$，其中 $\\Delta  0$ 是信赖域半径。\n- 由椭球范数 $\\|\\mathbf{s}\\|_M = \\sqrt{\\mathbf{s}^\\top M \\mathbf{s}}$ 定义的各向异性信赖域，其中 $M \\in \\mathbb{R}^{n \\times n}$ 是对称正定矩阵，因此约束变为 $\\|\\mathbf{s}\\|_M \\leq \\Delta$。\n- 变量替换变换 $\\mathbf{y} = L\\mathbf{s}$，其中 $L \\in \\mathbb{R}^{n \\times n}$ 满足 $L^\\top L = M$，这将 $\\|\\mathbf{s}\\|_M \\leq \\Delta$ 转换为欧几里得约束 $\\|\\mathbf{y}\\| \\leq \\Delta$，并将模型转换为 $m(\\mathbf{s}) = c + (L^{-\\top}\\mathbf{g})^\\top \\mathbf{y} + \\frac{1}{2}\\mathbf{y}^\\top (L^{-\\top}HL^{-1}) \\mathbf{y}$。\n\n您的程序必须实现以下功能。\n- 仅使用目标函数在一组邻近点上的评估值，在 $\\mathbf{x}_k$ 周围构建一个局部二次模型。使用最小二乘拟合来确定模型 $m(\\mathbf{s})$ 的系数 $c$、$\\mathbf{g}$ 和对称矩阵 $H$。设计矩阵应使用特征 $\\left[1, s_1, \\dots, s_n, \\frac{1}{2}s_1^2, \\dots, \\frac{1}{2}s_n^2, s_1 s_2, \\dots\\right]$，并通过对二次项仅使用唯一的 $\\{i \\leq j\\}$ 对来确保 $H$ 的对称性。\n- 为信赖域子问题实现一个截断共轭梯度求解器，在欧几里得范数 $\\|\\cdot\\|$ 和通过变量变换 $\\mathbf{y} = L\\mathbf{s}$ 的椭球范数 $\\|\\cdot\\|_M$ 下求解。使用 Steihaug 方法来处理潜在的边界命中或负曲率方向，而無需显式线搜索。\n- 使用实际目标函数评估真实的目标函数下降，并比较这两个步长。为每个测试用例报告一个布尔值，指示椭球范数是否获得了小于或等于欧几里得范数所获得的目标函数值。\n\n目标函数是形式为\n$$\nf(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^\\top Q \\mathbf{x} + \\mathbf{q}^\\top \\mathbf{x},\n$$\n的严格凸二次函数，其中 $Q \\in \\mathbb{R}^{n \\times n}$ 是对称正定矩阵，$\\mathbf{q} \\in \\mathbb{R}^n$。您不能直接使用梯度或Hessian矩阵；所有模型信息都必须从函数评估中推断出来。\n\n在以下测试套件下，为维度 $n = 3$ 实现该程序。每个测试用例指定了 $Q$、$\\mathbf{q}$、起始点 $\\mathbf{x}_k$、信赖域半径 $\\Delta$、用于模型构建的采样半径 $h$ 以及用于椭球范数的度量矩阵 $M$。请使用以下测试套件。\n- 测试用例1（顺利路径各向异性）：$Q = \\operatorname{diag}(1000, 1, 0.01)$ 且 $Q_{12} = Q_{21} = 20$，所有其他非对角元素为 $0$；$\\mathbf{q} = [0, 0, -1]^\\top$；$\\mathbf{x}_k = [0, 0, 0]^\\top$；$\\Delta = 0.1$；$h = 0.05$；$M = Q$。\n- 测试用例2（各向同性曲率）：$Q = \\operatorname{diag}(5, 5, 5)$，所有非对角元素为 $0$；$\\mathbf{q} = [1, -1, 0.5]^\\top$；$\\mathbf{x}_k = [0, 0, 0]^\\top$；$\\Delta = 0.1$；$h = 0.05$；$M = I$。\n- 测试用例3（近乎平坦的轴）：$Q = \\operatorname{diag}(100, 0.001, 100)$ 且 $Q_{13} = Q_{31} = 5$，所有其他非对角元素为 $0$；$\\mathbf{q} = [0, -1, 0]^\\top$；$\\mathbf{x}_k = [0, 0, 0]^\\top$；$\\Delta = 0.05$；$h = 0.025$；$M = Q$。\n- 测试用例4（非常小的信赖域半径边界）：$Q = \\operatorname{diag}(50, 2, 0.5)$，所有非对角元素为 $0$；$\\mathbf{q} = [0.1, -0.2, 0.3]^\\top$；$\\mathbf{x}_k = [0, 0, 0]^\\top$；$\\Delta = 0.001$；$h = 0.0005$；$M = Q$。\n\n对于每个测试用例，从形如 $\\mathbf{x}_k$、$\\mathbf{x}_k \\pm h \\mathbf{e}_i$（其中 $i \\in \\{1, 2, 3\\}$）以及 $\\mathbf{x}_k \\pm h (\\mathbf{e}_i + \\mathbf{e}_j)$（其中 $i  j$）的点构建模型，其中 $\\mathbf{e}_i$ 是 $\\mathbb{R}^3$ 中的标准基向量。这将产生一个包含13个点的集合。在这些点上通过最小二乘法拟合模型参数 $(c, \\mathbf{g}, H)$。\n\n对于每种范数（欧几里得范数和椭球范数），使用 Steihaug 的截断共轭梯度法在适当的变量空间中求解信赖域子问题。使用 $\\mathbf{s}_E$ 表示欧几里得步长，$\\mathbf{s}_M$ 表示求解器返回的椭球步长。计算实际的目标函数值 $f(\\mathbf{x}_k + \\mathbf{s}_E)$ 和 $f(\\mathbf{x}_k + \\mathbf{s}_M)$，并为每个测试用例输出一个布尔值，指示是否 $f(\\mathbf{x}_k + \\mathbf{s}_M) \\leq f(\\mathbf{x}_k + \\mathbf{s}_E)$。\n\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$\\left[\\text{result}_1, \\text{result}_2, \\text{result}_3, \\text{result}_4\\right]$）。每个 $\\text{result}_i$ 必须是一个布尔值（$\\text{True}$ 或 $\\text{False}$）。不允许使用外部输入或文件。",
            "solution": "该问题要求在一个基于模型的无导数优化算法中，比较球形（欧几里得范数）信赖域与椭球信赖域的有效性。该比较在一组涉及表现出各向异性曲率的严格凸二次目标函数的测试用例上进行。解决方案的核心包括三个主要步骤：构建目标函数的局部二次模型，为每种范数求解信赖域子问题，以及比较所得步长实现的真实目标函数下降。\n\n### 1. 二次模型构建\n\n优化器无法知晓目标函数，只能通过函数评估值访问。我们在点 $\\mathbf{x}_k$ 周围构建目标函数 $f(\\mathbf{x})$ 的局部二次模型 $m(\\mathbf{s})$。该模型由下式给出：\n$$\nm(\\mathbf{s}) = c + \\mathbf{g}^\\top \\mathbf{s} + \\frac{1}{2}\\mathbf{s}^\\top H \\mathbf{s}\n$$\n其中 $\\mathbf{s} = \\mathbf{x} - \\mathbf{x}_k$，$c \\in \\mathbb{R}$ 是一个常数偏移量，$\\mathbf{g} \\in \\mathbb{R}^n$ 是模型梯度，而 $H \\in \\mathbb{R}^{n \\times n}$ 是对称的模型Hessian矩阵。对于此问题，维度为 $n=3$。\n\n模型的系数，即 $c$、$\\mathbf{g}$ 和 $H$ 的唯一元素，是通过对在一组采样点上评估的函数值进行最小二乘拟合来确定的。我们有 $1+3+6=10$ 个未知系数：$c, g_1, g_2, g_3, H_{11}, H_{22}, H_{33}, H_{12}, H_{13}, H_{23}$。问题指定使用围绕 $\\mathbf{x}_k$ 的13个采样点 $\\mathbf{x}_j$，这些点是通过大小为 $h$ 的步长 $\\mathbf{s}_j$ 生成的。位移向量 $\\mathbf{s}_j$ 的集合是 $\\{\\mathbf{0}\\} \\cup \\{\\pm h \\mathbf{e}_i\\}_{i=1}^3 \\cup \\{\\pm h (\\mathbf{e}_i + \\mathbf{e}_j)\\}_{1 \\le i  j \\le 3}$。\n\n令 $\\boldsymbol{\\beta}$ 为模型系数的向量：\n$$\n\\boldsymbol{\\beta} = [c, g_1, g_2, g_3, H_{11}, H_{22}, H_{33}, H_{12}, H_{13}, H_{23}]^\\top\n$$\n模型可以表示为基函数 $\\phi_k(\\mathbf{s})$ 的线性组合：\n$$\nm(\\mathbf{s}) = \\beta_0 \\cdot 1 + \\sum_{i=1}^3 \\beta_i s_i + \\sum_{i=1}^3 \\beta_{3+i} \\left(\\frac{1}{2}s_i^2\\right) + \\beta_7 s_1s_2 + \\beta_8 s_1s_3 + \\beta_9 s_2s_3\n$$\n对于13个样本位移中的每一个 $\\mathbf{s}_j$，我们形成一个特征向量 $\\boldsymbol{\\phi}(\\mathbf{s}_j) = [1, s_{j,1}, s_{j,2}, s_{j,3}, \\frac{1}{2}s_{j,1}^2, \\frac{1}{2}s_{j,2}^2, \\frac{1}{2}s_{j,3}^2, s_{j,1}s_{j,2}, s_{j,1}s_{j,3}, s_{j,2}s_{j,3}]^\\top$。这些向量构成了设计矩阵 $\\Phi \\in \\mathbb{R}^{13 \\times 10}$ 的行。我们还将对应的目标函数值 $y_j = f(\\mathbf{x}_k + \\mathbf{s}_j)$ 收集到一个向量 $\\mathbf{y} \\in \\mathbb{R}^{13}$ 中。系数向量 $\\boldsymbol{\\beta}$ 通过求解线性最小二乘问题找到：\n$$\n\\min_{\\boldsymbol{\\beta}} \\|\\Phi \\boldsymbol{\\beta} - \\mathbf{y}\\|_2^2\n$$\n解由 $\\boldsymbol{\\beta} = (\\Phi^\\top \\Phi)^{-1} \\Phi^\\top \\mathbf{y}$ 给出。从 $\\boldsymbol{\\beta}$ 中，我们组装出模型参数 $c, \\mathbf{g}, H$。\n\n### 2. 信赖域子问题\n\n一旦模型 $m(\\mathbf{s})$ 构建完成，我们求解一个步长 $\\mathbf{s}$，使其在半径为 $\\Delta > 0$ 的信赖域内最小化模型。\n\n#### 2.1. 球形信赖域（欧几里得范数）\n标准的信赖域子问题是求解：\n$$\n\\min_{\\mathbf{s} \\in \\mathbb{R}^n} m(\\mathbf{s}) \\quad \\text{subject to} \\quad \\|\\mathbf{s}\\|_2 \\leq \\Delta\n$$\n其中 $\\|\\mathbf{s}\\|_2 = \\sqrt{\\mathbf{s}^\\top \\mathbf{s}}$ 是欧几里得范数。\n\n#### 2.2. 橢球信赖域（椭球范数）\n各向异性信赖域可以使用对称正定矩阵 $M$ 来定义：\n$$\n\\min_{\\mathbf{s} \\in \\mathbb{R}^n} m(\\mathbf{s}) \\quad \\text{subject to} \\quad \\|\\mathbf{s}\\|_M \\leq \\Delta\n$$\n其中 $\\|\\mathbf{s}\\|_M = \\sqrt{\\mathbf{s}^\\top M \\mathbf{s}}$。这个问题通过变量替换来解决。令 $M = L^\\top L$ 为 $M$ 的 Cholesky分解。我们定义一个新变量 $\\mathbf{y} = L\\mathbf{s}$，这意味着 $\\mathbf{s} = L^{-1}\\mathbf{y}$。约束转换为标准的欧几里得范数约束：\n$$\n\\|\\mathbf{s}\\|_M^2 = \\mathbf{s}^\\top M \\mathbf{s} = \\mathbf{s}^\\top L^\\top L \\mathbf{s} = (L\\mathbf{s})^\\top (L\\mathbf{s}) = \\mathbf{y}^\\top \\mathbf{y} = \\|\\mathbf{y}\\|_2^2 \\leq \\Delta^2\n$$\n目标模型被重写为关于 $\\mathbf{y}$ 的形式：\n$$\nm(\\mathbf{s}(\\mathbf{y})) = c + \\mathbf{g}^\\top (L^{-1}\\mathbf{y}) + \\frac{1}{2}(L^{-1}\\mathbf{y})^\\top H (L^{-1}\\mathbf{y}) = c + (L^{-\\top}\\mathbf{g})^\\top \\mathbf{y} + \\frac{1}{2}\\mathbf{y}^\\top (L^{-\\top}HL^{-1}) \\mathbf{y}\n$$\n这定义了一个新的二次模型 $m'(\\mathbf{y}) = c + \\mathbf{g}'^\\top \\mathbf{y} + \\frac{1}{2}\\mathbf{y}^\\top H' \\mathbf{y}$，其中 $\\mathbf{g}' = L^{-\\top}\\mathbf{g}$ 且 $H' = L^{-\\top}HL^{-1}$。子问题变成了在 $\\mathbf{y}$ 空间中的标准球形信赖域问题：\n$$\n\\min_{\\mathbf{y} \\in \\mathbb{R}^n} m'(\\mathbf{y}) \\quad \\text{subject to} \\quad \\|\\mathbf{y}\\|_2 \\leq \\Delta\n$$\n在求解出最优步长 $\\mathbf{y}^*$ 后，我们变换回原始空间以获得步长：$\\mathbf{s}_M = L^{-1}\\mathbf{y}^*$。在问题是各向异性的情况下，选择 $M$ 来近似 $f$ 的真实Hessian矩阵可以产生更好的步长，因为它对子问题进行了预处理。\n\n### 3. Steihaug 的截断共轭梯度法\n\n信赖域子问题使用 Steihaug 方法近似求解。此方法将共轭梯度（CG）算法应用于二次型 $q(\\mathbf{s}) = \\mathbf{g}^\\top \\mathbf{s} + \\frac{1}{2}\\mathbf{s}^\\top H \\mathbf{s}$，并在步长离开信赖域或遇到非正曲率方向时终止。\n\n该算法过程如下：\n1.  初始化步长 $\\mathbf{s}_0 = \\mathbf{0}$，残差 $\\mathbf{r}_0 = \\mathbf{g}$，以及方向 $\\mathbf{d}_0 = -\\mathbf{r}_0$。\n2.  对于 $k=0, 1, 2, \\dots$：\n    a. 检查非正曲率：如果 $\\mathbf{d}_k^\\top H \\mathbf{d}_k \\leq 0$，计算一个步长 $\\tau > 0$ 使得 $\\|\\mathbf{s}_k + \\tau \\mathbf{d}_k\\|_2 = \\Delta$。最终解为 $\\mathbf{s}_k + \\tau \\mathbf{d}_k$。终止。\n    b. 计算CG步长：$\\alpha_k = (\\mathbf{r}_k^\\top \\mathbf{r}_k) / (\\mathbf{d}_k^\\top H \\mathbf{d}_k)$。\n    c. 计算一个预期的新步长：$\\mathbf{s}_{k+1} = \\mathbf{s}_k + \\alpha_k \\mathbf{d}_k$。\n    d. 检查信赖域边界：如果 $\\|\\mathbf{s}_{k+1}\\|_2 \\geq \\Delta$，计算一个步长 $\\tau > 0$ 使得 $\\|\\mathbf{s}_k + \\tau \\mathbf{d}_k\\|_2 = \\Delta$。最终解为 $\\mathbf{s}_k + \\tau \\mathbf{d}_k$。终止。\n    e. 更新残差：$\\mathbf{r}_{k+1} = \\mathbf{r}_k + \\alpha_k H \\mathbf{d}_k$。\n    f. 检查收敛性：如果 $\\|\\mathbf{r}_{k+1}\\|_2$ 低于某个容忍度，以 $\\mathbf{s}_{k+1}$ 终止。\n    g. 更新搜索方向：$\\beta_k = (\\mathbf{r}_{k+1}^\\top \\mathbf{r}_{k+1}) / (\\mathbf{r}_k^\\top \\mathbf{r}_k)$，以及 $\\mathbf{d}_{k+1} = -\\mathbf{r}_{k+1} + \\beta_k \\mathbf{d}_k$。\n\n步骤2a和2d中的 $\\tau$ 值通过求解二次方程 $(\\mathbf{d}_k^\\top \\mathbf{d}_k)\\tau^2 + (2\\mathbf{s}_k^\\top \\mathbf{d}_k)\\tau + (\\mathbf{s}_k^\\top \\mathbf{s}_k - \\Delta^2) = 0$ 的正根得到。\n\n### 4. 比较与最终输出\n\n对于每个测试用例，我们执行以下过程：\n1.  从函数评估值构建二次模型 $(c, \\mathbf{g}, H)$。\n2.  使用 Steihaug 方法求解欧几里得范数的子问题，得到 $\\mathbf{s}_E$。\n3.  通过将模型变换为 $(\\mathbf{g}', H')$，使用 Steihaug 方法找到 $\\mathbf{y}^*$，并变换回原始空间得到 $\\mathbf{s}_M = L^{-1}\\mathbf{y}^*$，来求解椭球范数的子问题。\n4.  在新点处评估真实目标函数：$f(\\mathbf{x}_k+\\mathbf{s}_E)$ 和 $f(\\mathbf{x}_k+\\mathbf{s}_M)$。\n5.  测试用例的结果是表达式 $f(\\mathbf{x}_k+\\mathbf{s}_M) \\leq f(\\mathbf{x}_k+\\mathbf{s}_E)$ 的布尔值。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import cholesky, solve_triangular\n\ndef solve():\n    \"\"\"\n    Main solver function that iterates through test cases and performs the comparison.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"Q\": np.array([[1000, 20, 0], [20, 1, 0], [0, 0, 0.01]]),\n            \"q\": np.array([0, 0, -1]),\n            \"xk\": np.array([0, 0, 0]),\n            \"Delta\": 0.1, \"h\": 0.05,\n            \"M\": np.array([[1000, 20, 0], [20, 1, 0], [0, 0, 0.01]])\n        },\n        {\n            \"Q\": np.array([[5, 0, 0], [0, 5, 0], [0, 0, 5]]),\n            \"q\": np.array([1, -1, 0.5]),\n            \"xk\": np.array([0, 0, 0]),\n            \"Delta\": 0.1, \"h\": 0.05,\n            \"M\": np.eye(3)\n        },\n        {\n            \"Q\": np.array([[100, 0, 5], [0, 0.001, 0], [5, 0, 100]]),\n            \"q\": np.array([0, -1, 0]),\n            \"xk\": np.array([0, 0, 0]),\n            \"Delta\": 0.05, \"h\": 0.025,\n            \"M\": np.array([[100, 0, 5], [0, 0.001, 0], [5, 0, 100]])\n        },\n        {\n            \"Q\": np.array([[50, 0, 0], [0, 2, 0], [0, 0, 0.5]]),\n            \"q\": np.array([0.1, -0.2, 0.3]),\n            \"xk\": np.array([0, 0, 0]),\n            \"Delta\": 0.001, \"h\": 0.0005,\n            \"M\": np.array([[50, 0, 0], [0, 2, 0], [0, 0, 0.5]])\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_comparison(params)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef objective_function(x, Q, q):\n    \"\"\" The true objective function f(x) = 0.5*x'Qx + q'x. \"\"\"\n    return 0.5 * x.T @ Q @ x + q.T @ x\n\ndef build_model(f_obj, xk, h):\n    \"\"\" Constructs a quadratic model via least-squares fit. \"\"\"\n    n = len(xk)\n    e = np.eye(n)\n    \n    sample_s = [np.zeros(n)]\n    # Points on axes\n    for i in range(n):\n        sample_s.append(h * e[:, i])\n        sample_s.append(-h * e[:, i])\n    # Points on planes\n    for i in range(n):\n        for j in range(i + 1, n):\n            sample_s.append(h * (e[:, i] + e[:, j]))\n            sample_s.append(-h * (e[:, i] + e[:, j]))\n\n    sample_s = np.array(sample_s)\n    y = np.array([f_obj(xk + s) for s in sample_s])\n\n    # Design matrix Phi\n    Phi = np.zeros((len(sample_s), 10))\n    Phi[:, 0] = 1.0  # c\n    Phi[:, 1:4] = sample_s # g\n    Phi[:, 4:7] = 0.5 * sample_s**2 # H_ii\n    Phi[:, 7] = sample_s[:, 0] * sample_s[:, 1] # H_12\n    Phi[:, 8] = sample_s[:, 0] * sample_s[:, 2] # H_13\n    Phi[:, 9] = sample_s[:, 1] * sample_s[:, 2] # H_23\n\n    beta, _, _, _ = np.linalg.lstsq(Phi, y, rcond=None)\n    \n    c = beta[0]\n    g = beta[1:4]\n    H = np.zeros((n,n))\n    H[0, 0], H[1, 1], H[2, 2] = beta[4], beta[5], beta[6]\n    H[0, 1] = H[1, 0] = beta[7]\n    H[0, 2] = H[2, 0] = beta[8]\n    H[1, 2] = H[2, 1] = beta[9]\n    \n    # We need to model the change m(s) = f(xk+s)-f(xk), so g is correct,\n    # H is correct, but c should be m(0)=0. The solver doesn't use c.\n    # The gradient g and Hessian H are for the full model m(s) approx f(xk+s).\n    # Since the TRS solver minimizes m(s) starting from s=0, the constant part of the\n    # model (c) does not affect the optimal step s.\n    return g, H\n\n\ndef steihaug_cg(g, H, Delta, tol=1e-9):\n    \"\"\"\n    Solves the trust-region subproblem using Steihaug's truncated CG method.\n    min g's + 0.5 s'Hs  s.t. ||s|| = Delta\n    \"\"\"\n    n = len(g)\n    s = np.zeros(n)\n    r = g\n    d = -r\n\n    if np.linalg.norm(r)  tol:\n        return s\n\n    for _ in range(n):\n        dTHd = d.T @ H @ d\n        \n        if dTHd = 0:\n            # Negative curvature direction. Find intersection with boundary.\n            tau = solve_tau_quadratic(s, d, Delta)\n            return s + tau * d\n\n        alpha = (r.T @ r) / dTHd\n        s_new = s + alpha * d\n\n        if np.linalg.norm(s_new) >= Delta:\n            # Step exits trust region. Find intersection.\n            tau = solve_tau_quadratic(s, d, Delta)\n            return s + tau * d\n        \n        s = s_new\n        r_new = r + alpha * (H @ d)\n\n        if np.linalg.norm(r_new)  tol:\n            return s\n            \n        beta = (r_new.T @ r_new) / (r.T @ r)\n        d = -r_new + beta * d\n        r = r_new\n    \n    return s\n\ndef solve_tau_quadratic(s, d, Delta):\n    \"\"\"\n    Solves for tau > 0 in ||s + tau*d||^2 = Delta^2\n    \"\"\"\n    a = d.T @ d\n    b = 2 * (s.T @ d)\n    c = s.T @ s - Delta**2\n    discriminant = b**2 - 4*a*c\n    # We seek the positive root, which corresponds to moving \"forward\" along d.\n    # Since a > 0 and c = 0, the product ac is negative, discriminant is always positive\n    # and sqrt(discriminant) >= |b|, so -b + sqrt >= 0.\n    tau = (-b + np.sqrt(discriminant)) / (2 * a)\n    return tau\n\ndef run_comparison(params):\n    \"\"\"\n    Runs a single comparison for a given set of parameters.\n    \"\"\"\n    Q, q, xk, Delta, h, M = params['Q'], params['q'], params['xk'], params['Delta'], params['h'], params['M']\n    \n    f_obj = lambda x: objective_function(x, Q, q)\n\n    # 1. Build quadratic model\n    g, H = build_model(f_obj, xk, h)\n\n    # 2. Solve for Euclidean step s_E\n    s_E = steihaug_cg(g, H, Delta)\n\n    # 3. Solve for Ellipsoidal step s_M\n    L = cholesky(M, lower=True)\n    \n    g_prime = solve_triangular(L, g, lower=True, trans='T')\n    \n    temp = solve_triangular(L, H, lower=True, trans='T')\n    H_prime = solve_triangular(L, temp.T, lower=True, trans='T').T\n\n    y_star = steihaug_cg(g_prime, H_prime, Delta)\n    s_M = solve_triangular(L, y_star, lower=True, trans='T')\n\n    # 4. Compare true objective values\n    f_E = f_obj(xk + s_E)\n    f_M = f_obj(xk + s_M)\n    \n    return f_M = f_E\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}