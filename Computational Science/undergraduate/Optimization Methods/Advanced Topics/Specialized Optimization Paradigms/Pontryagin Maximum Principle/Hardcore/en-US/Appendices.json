{
    "hands_on_practices": [
        {
            "introduction": "Let's begin our hands-on exploration with a classic time-optimal control problem. The goal is to steer a system from an initial state to a target in the shortest time possible, a common task in fields from robotics to electronics. This first practice  examines a simple first-order system, providing an intuitive entry point where the principle suggests using the most extreme control input to achieve the objective as quickly as possible.",
            "id": "1600522",
            "problem": "A simple electronic circuit consists of a capacitor and a leaky resistor. The dynamics of the voltage $x(t)$ across the capacitor are modeled by the first-order linear differential equation:\n$$ \\frac{dx}{dt} = -x(t) + u(t) $$\nHere, $x(t)$ is the voltage in volts at time $t$, and $u(t)$ is a controllable voltage source, also in volts, which represents the control input. Due to power supply limitations, the control input is constrained such that $|u(t)| \\le 1$ for all time $t \\ge 0$.\n\nThe initial voltage on the capacitor is measured to be $x(0) = 5.0$ V. Your task is to determine the control strategy $u(t)$ that drives the capacitor's voltage to zero in the shortest possible time. Calculate this minimum time, $t_f$, required to reach the final state $x(t_f) = 0$.\n\nExpress your answer for the minimum time in seconds, rounded to three significant figures.",
            "solution": "We are given the controlled linear system\n$$\n\\frac{dx}{dt}=-x(t)+u(t), \\quad |u(t)|\\le 1, \\quad x(0)=5.\n$$\nWe want to minimize the time to reach $x(t_{f})=0$. The general solution for any measurable input $u(t)$ with the integrating factor method (using the factor $\\exp(t)$) is\n$$\nx(t)=x(0)\\exp(-t)+\\int_{0}^{t}\\exp\\bigl(-(t-s)\\bigr)u(s)\\,ds.\n$$\nSince the kernel $\\exp\\bigl(-(t-s)\\bigr)$ is strictly positive for $0\\le s\\le t$, the state $x(t)$ is minimized pointwise in time by choosing the smallest admissible input, namely\n$$\nu(t)\\equiv -1.\n$$\nTherefore, for any admissible control $u$, one has $x(t)\\ge x_{-1}(t)$ for all $t\\ge 0$, where $x_{-1}$ denotes the trajectory under $u\\equiv -1$. Hence the earliest hitting time of $x=0$ is achieved by $u\\equiv -1$.\n\nWith $u(t)\\equiv -1$, the system is\n$$\n\\frac{dx}{dt}=-x(t)-1.\n$$\nSolving this linear ODE, using the standard form $x(t)=(x(0)-u_{0})e^{-t}+u_{0}$ for constant input $u_{0}$, gives\n$$\nx(t)=(5-(-1))\\exp(-t)-1=6\\exp(-t)-1.\n$$\nThe hitting time $t_{f}$ satisfies $x(t_{f})=0$, so\n$$\n6\\exp(-t_{f})-1=0 \\quad \\Longrightarrow \\quad \\exp(-t_{f})=\\frac{1}{6} \\quad \\Longrightarrow \\quad t_{f}=\\ln 6.\n$$\nNumerically, to three significant figures,\n$$\nt_{f}\\approx 1.79.\n$$\nThus the minimum-time control is $u(t)\\equiv -1$ until $x$ reaches zero, and the minimum time is $t_{f}=\\ln 6\\approx 1.79$ seconds. Per the final answer format, we report only the numerical value rounded to three significant figures.",
            "answer": "$$\\boxed{1.79}$$"
        },
        {
            "introduction": "Having seen how constant maximum effort works for a simple system, we now tackle a more complex scenario involving a second-order system. In this case , simply applying maximum control in one direction will not guide the system to the origin; a corrective action is needed. This exercise guides you through deriving the \"switching curve,\" a critical concept in control theory that tells you exactly when to switch from full acceleration to full braking to perfectly hit your target.",
            "id": "3162819",
            "problem": "Consider the time-optimal control problem for the double integrator with bounded control. The system dynamics are given by\n$$\\dot{x}_1 = x_2, \\quad \\dot{x}_2 = u,$$\nwith the control constraint\n$$|u| \\leq 1.$$\nGiven an arbitrary initial condition $(x_1(0), x_2(0))$ and the fixed terminal condition\n$$x_1(T) = 0, \\quad x_2(T) = 0,$$\nthe objective is to minimize the transfer time $T$. Using the Pontryagin Maximum Principle (PMP), start from the fundamental definitions of the Hamiltonian, costate dynamics, transversality conditions for free final time, and the minimization condition to derive the optimal control structure. Show from first principles that the costate $\\lambda_2$ is affine in time and that an optimal trajectory has at most one switch. Then, by eliminating the costate and switching time using the state dynamics and the condition that the last arc must exactly reach the terminal manifold with zero velocity, derive the switching curve in the $(x_1,x_2)$-plane as a single explicit function $x_1 = \\Phi(x_2)$ that is valid for all $x_2 \\in \\mathbb{R}$. Your final answer must be the explicit analytic expression for this switching curve. No numerical approximation is required, and no units are involved. Provide the final expression for $x_1$ as a function of $x_2$ only.",
            "solution": "The objective is to minimize the final time $T$. This can be expressed as minimizing the cost functional $J = \\int_0^T 1 \\, dt$. The integrand is $L(x, u, t) = 1$. The state vector is $x(t) = \\begin{pmatrix} x_1(t) \\\\ x_2(t) \\end{pmatrix}$, and the state dynamics in vector form are $\\dot{x} = f(x, u) = \\begin{pmatrix} x_2 \\\\ u \\end{pmatrix}$.\n\nAccording to Pontryagin's Minimum Principle, we first define the Hamiltonian $H$.\n$$H(\\lambda, x, u) = L(x, u, t) + \\lambda^T f(x, u)$$\n$$H = 1 + \\lambda_1 x_2 + \\lambda_2 u$$\nwhere $\\lambda = \\begin{pmatrix} \\lambda_1 \\\\ \\lambda_2 \\end{pmatrix}$ is the costate vector.\n\nThe costate (or adjoint) equations are given by $\\dot{\\lambda} = -\\frac{\\partial H}{\\partial x}$.\n$$\\dot{\\lambda}_1 = -\\frac{\\partial H}{\\partial x_1} = 0$$\n$$\\dot{\\lambda}_2 = -\\frac{\\partial H}{\\partial x_2} = -\\lambda_1$$\nIntegrating the first equation gives $\\lambda_1(t) = c_1$, where $c_1$ is a constant. Substituting this into the second equation gives $\\dot{\\lambda}_2 = -c_1$. Integrating this yields:\n$$\\lambda_2(t) = -c_1 t + c_2$$\nwhere $c_2$ is another constant of integration. This demonstrates that the costate $\\lambda_2(t)$ is an affine function of time $t$.\n\nThe PMP requires that the optimal control $u^*(t)$ minimizes the Hamiltonian at every instant $t \\in [0, T]$ over the set of admissible controls $U = [-1, 1]$.\n$$u^*(t) = \\arg\\min_{u \\in [-1, 1]} H(\\lambda(t), x(t), u) = \\arg\\min_{u \\in [-1, 1]} (1 + \\lambda_1 x_2 + \\lambda_2 u)$$\nTo minimize $H$, we must minimize the term $\\lambda_2 u$. The optimal control law is therefore a function of the sign of $\\lambda_2(t)$:\n- If $\\lambda_2(t)  0$, we choose $u(t) = -1$.\n- If $\\lambda_2(t)  0$, we choose $u(t) = 1$.\n- If $\\lambda_2(t) = 0$, the Hamiltonian is independent of $u$. This is a singular case.\n\nThis control structure can be written compactly as $u^*(t) = -\\operatorname{sgn}(\\lambda_2(t))$, provided $\\lambda_2(t) \\neq 0$. If $\\lambda_2(t) = 0$ over a finite time interval, then $\\dot{\\lambda}_2(t)$ must also be zero on that interval. This would imply $\\lambda_1(t) = 0$ for that interval. If both costates are zero, the costate vector is trivial, which is disallowed by a necessary condition of the PMP (non-triviality condition). Thus, $\\lambda_2(t)$ can only be zero at isolated points in time. Since $\\lambda_2(t)$ is a linear (affine) function of time, it can cross the axis $\\lambda_2=0$ at most once (if $c_1 \\neq 0$). Consequently, an optimal trajectory can have at most one control switch.\n\nThe switching curve is the set of states in the $(x_1, x_2)$-plane from which the origin can be reached by applying a constant control, either $u=+1$ or $u=-1$. These are the final segments of any optimal trajectory. We derive this curve by analyzing the system dynamics in reverse time from the origin, or equivalently, by finding the initial states that can be driven to the origin in time $T$ with a constant control.\n\nCase 1: Constant control $u = -1$.\nThe system dynamics are $\\dot{x}_2 = -1$ and $\\dot{x}_1 = x_2$.\nIntegrating from an initial state $(x_1(0), x_2(0))$:\n$x_2(t) = x_2(0) - t$\n$x_1(t) = x_1(0) + x_2(0)t - \\frac{1}{2}t^2$\nWe require the state to reach the origin $(0,0)$ at time $T$.\n$x_2(T) = x_2(0) - T = 0 \\implies T = x_2(0)$. Since $T  0$, we must have $x_2(0)  0$.\n$x_1(T) = x_1(0) + x_2(0)T - \\frac{1}{2}T^2 = 0$.\nSubstituting $T = x_2(0)$:\n$x_1(0) + x_2(0)(x_2(0)) - \\frac{1}{2}(x_2(0))^2 = 0$\n$x_1(0) + \\frac{1}{2}x_2(0)^2 = 0$\nDropping the $(0)$ notation for the initial state, we get the curve for any state $(x_1, x_2)$:\n$$x_1 = -\\frac{1}{2}x_2^2, \\quad \\text{for } x_2 \\ge 0$$\nThis is the part of the switching curve where the final control action is $u=-1$.\n\nCase 2: Constant control $u = +1$.\nThe system dynamics are $\\dot{x}_2 = 1$ and $\\dot{x}_1 = x_2$.\nIntegrating from $(x_1(0), x_2(0))$:\n$x_2(t) = x_2(0) + t$\n$x_1(t) = x_1(0) + x_2(0)t + \\frac{1}{2}t^2$\nWe require the state to reach $(0,0)$ at time $T$.\n$x_2(T) = x_2(0) + T = 0 \\implies T = -x_2(0)$. Since $T  0$, this requires $x_2(0)  0$.\n$x_1(T) = x_1(0) + x_2(0)T + \\frac{1}{2}T^2 = 0$.\nSubstituting $T = -x_2(0)$:\n$x_1(0) + x_2(0)(-x_2(0)) + \\frac{1}{2}(-x_2(0))^2 = 0$\n$x_1(0) - x_2(0)^2 + \\frac{1}{2}x_2(0)^2 = 0$\n$x_1(0) - \\frac{1}{2}x_2(0)^2 = 0$\nThis gives the curve for any state $(x_1,x_2)$:\n$$x_1 = \\frac{1}{2}x_2^2, \\quad \\text{for } x_2 \\le 0$$\nThis is the part of the switching curve where the final control action is $u=+1$.\n\nThe complete switching curve, denoted $\\mathcal{S}$, is the union of these two parabolic arcs and the origin:\n$$\\mathcal{S} = \\left\\{ (x_1, x_2) \\in \\mathbb{R}^2 \\mid (x_1 = -\\frac{1}{2}x_2^2 \\text{ and } x_2 \\ge 0) \\lor (x_1 = \\frac{1}{2}x_2^2 \\text{ and } x_2 \\le 0) \\right\\}$$\nWe need to express this as a single explicit function $x_1 = \\Phi(x_2)$.\nWe observe that for $x_2  0$, the curve is $x_1 = -\\frac{1}{2}x_2^2$.\nFor $x_2  0$, the curve is $x_1 = \\frac{1}{2}x_2^2$.\nThis piecewise definition can be unified using the absolute value function $|x_2|$ or the sign function $\\operatorname{sgn}(x_2)$. Let's use the absolute value.\nIf $x_2 \\ge 0$, then $|x_2| = x_2$. The expression $x_1 = -\\frac{1}{2}x_2|x_2|$ becomes $x_1 = -\\frac{1}{2}x_2(x_2) = -\\frac{1}{2}x_2^2$. This matches the first piece.\nIf $x_2 \\le 0$, then $|x_2| = -x_2$. The expression $x_1 = -\\frac{1}{2}x_2|x_2|$ becomes $x_1 = -\\frac{1}{2}x_2(-x_2) = \\frac{1}{2}x_2^2$. This matches the second piece.\nThus, the switching curve is described by the single explicit function:\n$$x_1 = -\\frac{1}{2}x_2|x_2|$$\nThis function $\\Phi(x_2) = -\\frac{1}{2}x_2|x_2|$ is the required expression for the switching curve, valid for all $x_2 \\in \\mathbb{R}$.",
            "answer": "$$\\boxed{x_1 = -\\frac{1}{2}x_{2}|x_{2}|}$$"
        },
        {
            "introduction": "Our final practice expands the scope of our problems to demonstrate the versatility of the Pontryagin Maximum Principle. Instead of aiming for a fixed point, we now seek to reach a target *region*—in this case, a circle—while minimizing a cost that balances both control energy and time. This problem  introduces the crucial transversality conditions, which are essential for solving problems with free final times and terminal state constraints.",
            "id": "1600523",
            "problem": "A particle in a two-dimensional Cartesian plane, with position vector $\\mathbf{x}(t) = [x_1(t), x_2(t)]^T$, is controlled by a velocity input $\\mathbf{u}(t) = [u_1(t), u_2(t)]^T$. The dynamics of the particle are governed by the simple integrator model:\n$$\n\\dot{\\mathbf{x}}(t) = \\mathbf{u}(t)\n$$\nThe particle starts at the origin at time $t=0$, i.e., $\\mathbf{x}(0) = [0, 0]^T$. The objective is to steer the particle to a target circle of radius $R$ centered at the origin. The final time, $t_f$, is not fixed and is determined by when the particle first reaches this circle. The terminal condition is therefore given by the manifold equation $x_1(t_f)^2 + x_2(t_f)^2 = R^2$.\n\nThe goal is to find a control input $\\mathbf{u}(t)$ that minimizes the objective functional $J$, which represents a combination of control energy and time duration:\n$$\nJ = \\int_{0}^{t_f} \\left( \\frac{1}{2} (u_1(t)^2 + u_2(t)^2) + 1 \\right) dt\n$$\n\nDetermine the minimum possible value of this objective functional, $J_{min}$, in terms of the radius $R$.",
            "solution": "We apply Pontryagin’s Minimum Principle to the problem of minimizing\n$$\nJ=\\int_{0}^{t_{f}}\\left(\\frac{1}{2}\\left(u_{1}(t)^{2}+u_{2}(t)^{2}\\right)+1\\right)dt=\\int_{0}^{t_{f}}\\left(\\frac{1}{2}\\|\\mathbf{u}(t)\\|^{2}+1\\right)dt\n$$\nsubject to the dynamics $\\dot{\\mathbf{x}}(t)=\\mathbf{u}(t)$, initial condition $\\mathbf{x}(0)=\\mathbf{0}$, free final time $t_{f}$, and terminal manifold $g(\\mathbf{x}(t_{f}))=\\|\\mathbf{x}(t_{f})\\|^{2}-R^{2}=0$.\n\nDefine the Hamiltonian\n$$\nH(\\mathbf{x},\\mathbf{u},\\boldsymbol{\\lambda})=\\frac{1}{2}\\|\\mathbf{u}\\|^{2}+1+\\boldsymbol{\\lambda}^{T}\\mathbf{u}.\n$$\nStationarity with respect to $\\mathbf{u}$ gives\n$$\n\\frac{\\partial H}{\\partial \\mathbf{u}}=\\mathbf{u}+\\boldsymbol{\\lambda}=\\mathbf{0}\\quad\\Rightarrow\\quad \\mathbf{u}^{*}(t)=-\\boldsymbol{\\lambda}(t).\n$$\nThe costate dynamics are\n$$\n\\dot{\\boldsymbol{\\lambda}}(t)=-\\frac{\\partial H}{\\partial \\mathbf{x}}=\\mathbf{0}\\quad\\Rightarrow\\quad \\boldsymbol{\\lambda}(t)=\\boldsymbol{\\lambda}_{0} \\text{ (constant)}.\n$$\nTherefore the optimal control is constant, $\\mathbf{u}^{*}(t)=-\\boldsymbol{\\lambda}_{0}$, and the state evolves as\n$$\n\\mathbf{x}(t)=\\int_{0}^{t}\\mathbf{u}^{*}(\\tau)\\,d\\tau=\\mathbf{u}^{*}\\,t=-\\boldsymbol{\\lambda}_{0}\\,t.\n$$\nThe terminal manifold condition is\n$$\n\\|\\mathbf{x}(t_{f})\\|^{2}=R^{2}\\quad\\Rightarrow\\quad \\|\\mathbf{u}^{*}\\|^{2}\\,t_{f}^{2}=R^{2}\\quad\\Rightarrow\\quad t_{f}=\\frac{R}{\\|\\mathbf{u}^{*}\\|}.\n$$\nBecause the final time is free and there is no terminal cost, the transversality condition yields\n$$\nH(t_{f})=0.\n$$\nSubstituting $\\mathbf{u}^{*}=-\\boldsymbol{\\lambda}_{0}$ into the Hamiltonian gives\n$$\nH=\\frac{1}{2}\\|\\mathbf{u}^{*}\\|^{2}+1+\\boldsymbol{\\lambda}_{0}^{T}\\mathbf{u}^{*}\n=\\frac{1}{2}\\|\\mathbf{u}^{*}\\|^{2}+1-\\|\\boldsymbol{\\lambda}_{0}\\|^{2}\n=\\frac{1}{2}\\|\\mathbf{u}^{*}\\|^{2}+1-\\|\\mathbf{u}^{*}\\|^{2}\n=1-\\frac{1}{2}\\|\\mathbf{u}^{*}\\|^{2}.\n$$\nSetting $H(t_{f})=0$ yields\n$$\n1-\\frac{1}{2}\\|\\mathbf{u}^{*}\\|^{2}=0\\quad\\Rightarrow\\quad \\|\\mathbf{u}^{*}\\|^{2}=2\\quad\\Rightarrow\\quad \\|\\mathbf{u}^{*}\\|=\\sqrt{2}.\n$$\nHence\n$$\nt_{f}=\\frac{R}{\\sqrt{2}}.\n$$\nThe optimal cost is then\n$$\nJ_{\\min}=\\int_{0}^{t_{f}}\\left(\\frac{1}{2}\\|\\mathbf{u}^{*}\\|^{2}+1\\right)dt\n=\\int_{0}^{t_{f}}\\left(\\frac{1}{2}\\cdot 2+1\\right)dt\n=\\int_{0}^{t_{f}}2\\,dt\n=2t_{f}\n=2\\cdot\\frac{R}{\\sqrt{2}}\n=\\sqrt{2}\\,R.\n$$\nFor completeness, the same value can be obtained by a direct variational argument. For any fixed $t_{f}$ and terminal point $\\mathbf{y}$ with $\\|\\mathbf{y}\\|=R$, the minimal control energy is achieved by a constant control $\\mathbf{u}(t)=\\mathbf{y}/t_{f}$, yielding\n$$\nJ(t_{f})=\\frac{1}{2}\\int_{0}^{t_{f}}\\|\\mathbf{u}\\|^{2}dt+\\int_{0}^{t_{f}}1\\,dt=\\frac{1}{2}\\cdot t_{f}\\cdot\\frac{R^{2}}{t_{f}^{2}}+t_{f}=\\frac{R^{2}}{2t_{f}}+t_{f}.\n$$\nMinimizing over $t_{f}0$ by setting $\\frac{dJ}{dt_{f}}=-\\frac{R^{2}}{2t_{f}^{2}}+1=0$ gives $t_{f}=R/\\sqrt{2}$, and thus $J_{\\min}=\\sqrt{2}\\,R$, consistent with the Pontryagin analysis.",
            "answer": "$$\\boxed{\\sqrt{2}R}$$"
        }
    ]
}