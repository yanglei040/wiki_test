{
    "hands_on_practices": [
        {
            "introduction": "To truly master an algorithm, one must understand not only how it works, but also when it works best and when it falters. This first practice explores the performance spectrum of signed radix-4 Booth recoding by examining its behavior on specific input patterns. By analyzing the best-case (long runs of identical bits) and worst-case (alternating bits) scenarios, you will develop a deep intuition for the algorithm's core principle of reducing partial products by exploiting bit-level redundancy .",
            "id": "3652101",
            "problem": "Consider multiplying a fixed-width $n$-bit two's complement multiplier $Q$ by an $n$-bit two's complement multiplicand $M$ using signed radix-$4$ Booth recoding. Let $Q$ have bits $q_{n-1}\\dots q_{1}q_{0}$ with $q_{k}\\in\\{0,1\\}$, and define an auxiliary bit $q_{-1}=0$. In radix-$4$ Booth recoding, the multiplier $Q$ is rewritten as a sum of signed base-$4$ digits $d_{i}\\in\\{-2,-1,0,+1,+2\\}$ with positional weights $4^{i}$, formed from overlapping triplets $\\left(q_{2i+1},q_{2i},q_{2i-1}\\right)$ for $i=0,1,\\dots$, so that the partial products are $d_{i}\\cdot M\\cdot 4^{i}$ and the number of non-zero partial products equals the count of indices $i$ with $d_{i}\\neq 0$. The intent of Booth recoding is to reduce the number of non-zero partial products by encoding runs of identical bits in $Q$.\n\nWhich of the following statements about the bit-patterns of $Q$ and the resulting number of non-zero partial products under signed radix-$4$ Booth recoding are correct?\n\nA. For $Q=00\\cdots 0$ (all bits are $0$), the number of non-zero partial products is $0$. For $Q=11\\cdots 1$ (all bits are $1$, which represents $-1$ in two's complement), the number of non-zero partial products is exactly $1$, independent of $n$.\n\nB. Among all $n$-bit patterns, alternating bits such as $Q=10\\,10\\,\\cdots$ or $Q=01\\,01\\,\\cdots$ maximize the number of non-zero partial products, and the count equals $\\lceil n/2\\rceil$.\n\nC. A single contiguous run of ones, $Q=00\\cdots 0111\\cdots 100\\cdots 0$, maximizes the number of non-zero partial products, because each triplet must recode to either $+2$ or $-2$.\n\nD. The maximum possible number of non-zero partial products under signed radix-$4$ Booth for $n$-bit $Q$ is $n$, achieved when $Q$ alternates as $10\\,10\\,\\cdots$.\n\nSelect all correct options and justify them from the fundamental bit-level interpretation of two's complement and the first principles of signed radix-$4$ Booth recoding (grouping bits in overlapping triplets and eliminating runs).",
            "solution": "The problem statement describes the signed radix-$4$ Booth recoding algorithm for multiplying two $n$-bit two's complement numbers, a multiplier $Q$ and a multiplicand $M$. The core of the algorithm is to recode the multiplier $Q$ into a sequence of signed digits $d_i \\in \\{-2, -1, 0, +1, +2\\}$. The number of partial products is determined by the number of these digits, which is $k = \\lceil n/2 \\rceil$. The number of *non-zero* partial products is the number of digits $d_i$ that are not equal to $0$.\n\nThe digits $d_i$ are generated by examining overlapping triplets of bits from the multiplier $Q$. Let $Q$ be represented by bits $q_{n-1} \\dots q_1 q_0$. We define an auxiliary bit $q_{-1}=0$. For two's complement numbers, any bits beyond the most significant bit, $q_k$ for $k \\ge n$, are assumed to be sign extensions, i.e., $q_k = q_{n-1}$ for $k \\ge n$.\n\nThe triplet for digit $d_i$ is $(q_{2i+1}, q_{2i}, q_{2i-1})$. The value of the digit $d_i$ is computed as $d_i = q_{2i-1} + q_{2i} - 2q_{2i+1}$. This provides a lookup table:\n- $(0,0,0) \\implies d_i = 0+0-2(0) = 0$\n- $(0,0,1) \\implies d_i = 1+0-2(0) = +1$\n- $(0,1,0) \\implies d_i = 0+1-2(0) = +1$\n- $(0,1,1) \\implies d_i = 1+1-2(0) = +2$\n- $(1,0,0) \\implies d_i = 0+0-2(1) = -2$\n- $(1,0,1) \\implies d_i = 1+0-2(1) = -1$\n- $(1,1,0) \\implies d_i = 0+1-2(1) = -1$\n- $(1,1,1) \\implies d_i = 1+1-2(1) = 0$\n\nA non-zero partial product is generated if and only if the corresponding triplet is not $(0,0,0)$ or $(1,1,1)$.\n\nLet's evaluate each statement.\n\n**A. For $Q=00\\cdots 0$ (all bits are $0$), the number of non-zero partial products is $0$. For $Q=11\\cdots 1$ (all bits are $1$, which represents $-1$ in two's complement), the number of non-zero partial products is exactly $1$, independent of $n$.**\n\n- **Case 1: $Q = 00\\cdots0$**\nIf all bits of $Q$ are $0$, then $q_i=0$ for $0 \\le i  n$. With $q_{-1}=0$, every possible triplet $(q_{2i+1}, q_{2i}, q_{2i-1})$ will be $(0,0,0)$. According to the lookup table, this triplet recodes to $d_i=0$. Thus, all digits $d_i$ are $0$, and the number of non-zero partial products is $0$. This part of the statement is correct.\n\n- **Case 2: $Q = 11\\cdots1$**\nThis bit pattern represents the number $-1$ in two's complement representation for any word length $n \\ge 1$. Here, $q_i=1$ for $0 \\le i  n$. We also have $q_{-1}=0$.\nLet's analyze the digits $d_i$:\n- For $i=0$: The triplet is $(q_1, q_0, q_{-1})$. Since $q_1=1$, $q_0=1$, and $q_{-1}=0$, the triplet is $(1,1,0)$. This recodes to $d_0 = 0+1-2(1) = -1$. This is a non-zero digit.\n- For $i  0$ such that $2i+1  n$: The triplet is $(q_{2i+1}, q_{2i}, q_{2i-1})$. Since $2i-1 \\ge 1$, all three bits in the triplet are from $Q$ and are equal to $1$. The triplet is $(1,1,1)$. This recodes to $d_i = 1+1-2(1) = 0$.\n- For the final digit: This concerns the sign-extended bits. The total number of digits is $\\lceil n/2 \\rceil$. Let $k = \\lceil n/2 \\rceil - 1$ be the index of the final digit. The triplet is $(q_{2k+1}, q_{2k}, q_{2k-1})$. Bits $q_{2k}$ and $q_{2k-1}$ are part of the original number (or the last bit for odd $n$) and are equal to $1$. The bit $q_{2k+1}$ is a sign-extension of $q_{n-1}$. Since $q_{n-1}=1$, we have $q_{2k+1}=1$. Thus, the final triplet is also $(1,1,1)$, which recodes to $d_k=0$.\nTherefore, only $d_0$ is non-zero. The number of non-zero partial products is exactly $1$. This holds for any $n \\ge 1$. The value of $Q$ is correctly calculated as $d_0 \\cdot 4^0 = -1 \\cdot 1 = -1$.\nThe entire statement is correct.\n\nVerdict for A: **Correct**.\n\n**B. Among all $n$-bit patterns, alternating bits such as $Q=10\\,10\\,\\cdots$ or $Q=01\\,01\\,\\cdots$ maximize the number of non-zero partial products, and the count equals $\\lceil n/2\\rceil$.**\n\nThe total number of recoded digits (and thus partial products) is $\\lceil n/2 \\rceil$. To maximize the number of *non-zero* partial products, we need to generate a non-zero digit $d_i$ for every possible value of $i$. This means we must avoid forming the triplets $(0,0,0)$ and $(1,1,1)$. These triplets are formed by runs of identical bits. Alternating bit patterns are the antithesis of runs of identical bits. Let's analyze them.\n\n- **Case 1: $Q$ has the pattern $0101\\cdots$ (i.e., $q_{2j}=1, q_{2j+1}=0$).**\n- For $i=0$: The triplet is $(q_1, q_0, q_{-1}) = (0, 1, 0)$. This recodes to $d_0 = 0+1-2(0) = +1$.\n- For $i0$: The triplet is $(q_{2i+1}, q_{2i}, q_{2i-1})$. $q_{2i+1}=0$ (odd index), $q_{2i}=1$ (even index), $q_{2i-1}=0$ (odd index). The triplet is $(0,1,0)$, which recodes to $d_i=+1$. This holds as long as the bits are within $Q$.\n- For the last digit (if $n$ is odd, $n=2k+1$): $Q$ ends in $q_{n-1}=q_{2k}=1$. We need the triplet $(q_{2k+1}, q_{2k}, q_{2k-1})$. The pattern is $q_{2j}=1$, $q_{2j+1}=0$. Wait. The problem statement says $Q=0101...$. This implies $q_0=1, q_1=0, q_2=1, ...$. So $q_{2j}=1$ and $q_{2j+1}=0$.\n  - $i=0$: $(q_1, q_0, q_{-1}) = (0,1,0) \\implies d_0=+1$.\n  - $i0$: $(q_{2i+1}, q_{2i}, q_{2i-1}) = (0,1,0) \\implies d_i=+1$. This works as long as $2i+1  n$.\n  - Sign extension: If $n$ is even ($n=2k$), $q_{n-1}=q_{2k-1}=0$. The last triplet index $i=k-1$ involves bits up to $q_{2k-1}=q_{n-1}$, so no sign extension needed. All digits are $+1$.\n  - If $n$ is odd ($n=2k+1$), $q_{n-1}=q_{2k}=1$. The last triplet index is $i=k$. We use $(q_{2k+1}, q_{2k}, q_{2k-1})$. $q_{2k}=1, q_{2k-1}=0$. The sign bit is $q_{2k}=1$, so its extension is $q_{2k+1}=1$. The triplet is $(1,1,0)$, which gives $d_k=-1$. Still non-zero.\nIn all cases, for the pattern $0101\\cdots$, every recoded digit $d_i$ is non-zero.\n\n- **Case 2: $Q$ has the pattern $1010\\cdots$ (i.e., $q_{2j}=0, q_{2j+1}=1$).**\n- For $i=0$: The triplet is $(q_1, q_0, q_{-1}) = (1, 0, 0)$. This recodes to $d_0 = 0+0-2(1)=-2$.\n- For $i0$: The triplet is $(q_{2i+1}, q_{2i}, q_{2i-1}) = (1, 0, 1)$. This recodes to $d_i = 1+0-2(1)=-1$.\n- Sign extension: If $n$ is odd ($n=2k+1$), $q_{n-1}=q_{2k}=0$. The last triplet is $(q_{2k+1}, q_{2k}, q_{2k-1})=(0,0,1)$, giving $d_k=+1$.\nIn all cases, for the pattern $1010\\cdots$, every recoded digit $d_i$ is non-zero.\n\nSince alternating bit patterns ensure that none of the triplets are $(0,0,0)$ or $(1,1,1)$, every one of the $\\lceil n/2 \\rceil$ digits is non-zero. This is the maximum possible number.\n\nVerdict for B: **Correct**.\n\n**C. A single contiguous run of ones, $Q=00\\cdots 0111\\cdots 100\\cdots 0$, maximizes the number of non-zero partial products, because each triplet must recode to either $+2$ or $-2$.**\n\nThis statement is contrary to the very purpose of Booth's algorithm, which is to efficiently handle long runs of identical bits.\nLet's consider a number with a single run of $1$s, such as $Q=...0011...1100...$.\n- In the region of all $0$s, all triplets are $(0,0,0)$, giving $d_i=0$.\n- In the interior of the run of $1$s, all triplets are $(1,1,1)$, giving $d_i=0$.\n- Non-zero digits can only arise at the boundaries of the run of $1$s.\n- At the start of the run (a $0 \\to 1$ transition): A triplet will span this boundary. For example, in $...0011...$, we might form triplet $(0,1,1)$, which recodes to $d_i=+2$, or $(0,0,1)$ which recodes to $d_i=+1$.\n- At the end of the run (a $1 \\to 0$ transition): A triplet will span this boundary. For example, in $...1100...$, we might form triplet $(1,0,0)$, which recodes to $d_j=-2$, or $(1,1,0)$ which recodes to $d_j=-1$.\nA single run of $1$s will produce at most two non-zero digits, one near the start of the run and one near the end. For large $n$, $2$ is much smaller than the maximum of $\\lceil n/2 \\rceil$ achieved by alternating patterns. Therefore, this pattern does not maximize the number of non-zero partial products; it minimizes it.\nFurthermore, the reason given, \"because each triplet must recode to either $+2$ or $-2$\", is false. As shown, digits $+1$ and $-1$ can easily be generated at the boundaries. For example, if $Q=...0001110...$ and we form a triplet around the start of the run as $(q_{2i+1}, q_{2i}, q_{2i-1})=(0,0,1)$, this yields $d_i=+1$.\nThe statement is incorrect on both counts.\n\nVerdict for C: **Incorrect**.\n\n**D. The maximum possible number of non-zero partial products under signed radix-$4$ Booth for $n$-bit $Q$ is $n$, achieved when $Q$ alternates as $10\\,10\\,\\cdots$.**\n\nThe radix-$4$ scheme groups bits into pairs (with one bit of overlap). For an $n$-bit multiplier, this results in $\\lceil n/2 \\rceil$ groups or digits. The total number of partial products (whether zero or non-zero) is $\\lceil n/2 \\rceil$. Consequently, the maximum possible number of *non-zero* partial products cannot exceed this value.\nThe statement claims the maximum is $n$. For any $n  2$, $n  \\lceil n/2 \\rceil$. For example, if $n=8$, the maximum number of non-zero partial products is $8/2 = 4$, not $8$. The statement fundamentally mistakes the number of recoded digits for the number of bits in the multiplier. While the pattern $1010\\cdots$ does maximize the number of non-zero products, the value of that maximum is $\\lceil n/2 \\rceil$, not $n$.\n\nVerdict for D: **Incorrect**.\n\nFinal conclusion: Statements A and B are correct.",
            "answer": "$$\\boxed{AB}$$"
        },
        {
            "introduction": "After an algorithm like Booth recoding generates a set of partial products, the next challenge is to sum them efficiently in hardware. This practice moves from the abstract algorithm to the concrete implementation of the reduction phase using a Wallace-style tree of compressors. You will derive a method to calculate the exact number of 3:2 compressors (full adders) required, thereby quantifying how an algorithm's output directly translates into hardware complexity and cost .",
            "id": "3652024",
            "problem": "Consider unsigned integer multiplication implemented at the bit level. A 3:2 compressor (functionally identical to a full adder) takes three single-bit inputs of the same weight $2^{i}$ and produces two single-bit outputs: a sum bit at weight $2^{i}$ and a carry bit at weight $2^{i+1}$. A bit heap is described by its column height profile $\\{H_{i}\\}$, where $H_{i}$ is the number of one-bit signals initially present in column $i$ (weight $2^{i}$) before any compression. The goal of Wallace-style column compression is to reduce every column to at most two bits, using only 3:2 compressors, with carries propagating to higher-weight columns.\n\nStarting from the core definitions of bit addition and 3:2 compression, derive a formula that gives, for a general column height profile $\\{H_{i}\\}$, the minimal number of 3:2 compressors required in each column (and hence in total) to reduce every column to at most two bits. Your derivation must account for carries generated by compression in lower-weight columns that enter higher-weight columns.\n\nThen apply your formula to the following two scientifically realistic column height profiles for $8$-bit by $8$-bit multiplication:\n\n- Array multiplier (schoolbook partial products): for $i = 0,1,\\dots,14$, \n$$\nH_{i}^{\\text{array}} = \n\\begin{cases}\ni+1,  0 \\leq i \\leq 7, \\\\\n15 - i,  8 \\leq i \\leq 14,\n\\end{cases}\n$$\nwhich explicitly is\n$$\n\\{H_{i}^{\\text{array}}\\}_{i=0}^{14} = \\{1,2,3,4,5,6,7,8,7,6,5,4,3,2,1\\}.\n$$\n\n- Radix-$4$ Booth recoding (no sign-correction bits present, four partial-product rows shifted by $0,2,4,6$): for $i = 0,1,\\dots,14$, the profile is\n$$\n\\{H_{i}^{\\text{Booth}}\\}_{i=0}^{14} = \\{1,1,2,2,3,3,4,4,3,3,2,2,1,1,0\\}.\n$$\n\nCompute the minimal number of 3:2 compressors required for each profile and report the difference (array minus Booth) as a single real-valued number. No rounding is required. Express your final answer as a pure number without units.",
            "solution": "The problem asks for a derivation of a formula for the number of 3:2 compressors required to reduce a bit heap, and then to apply this formula to two specific examples.\n\n### Part 1: Derivation of the General Formula\n\nA 3:2 compressor, also known as a full adder, is a fundamental component in parallel multipliers. It takes three one-bit inputs of the same arithmetic weight, say $2^i$, and produces two one-bit outputs: a sum bit of weight $2^i$ and a carry bit of weight $2^{i+1}$. This operation can be represented as: $3$ bits at column $i \\rightarrow 1$ bit at column $i$ and $1$ bit at column $i+1$.\n\nLet's analyze the reduction of a single column $i$ with an initial height of $h$ bits. The goal is to reduce this height to at most $2$ using 3:2 compressors. Each compressor reduces the number of bits in the current column by $3-1 = 2$. The reduction may require multiple stages.\n\nLet $h_0 = h$ be the initial height of the column.\nIn the first stage of reduction, we can apply $k_1 = \\lfloor h_0/3 \\rfloor$ compressors. These compressors consume $3k_1$ bits from the column.\nThe outputs are:\n1. $k_1$ sum bits, which remain in the current column $i$.\n2. $k_1$ carry bits, which are passed to the next higher-weight column, $i+1$.\n\nThe number of bits in column $i$ that were not processed by any compressor is $h_0 \\pmod 3$.\nTherefore, the new height of column $i$, after one stage of compression, is the sum of the sum bits produced and the unprocessed bits:\n$$h_1 = k_1 + (h_0 \\pmod 3) = \\lfloor \\frac{h_0}{3} \\rfloor + (h_0 \\pmod 3)$$\nIf $h_1  2$, this new set of $h_1$ bits must be further compressed. This process is repeated. Let $h_j$ be the height of the column at stage $j$. The reduction proceeds as:\n$$h_{j+1} = \\lfloor \\frac{h_j}{3} \\rfloor + (h_j \\pmod 3)$$\nThis continues until a stage $m$ is reached where $h_m \\le 2$.\n\nThe total number of compressors used in this column is the sum of the compressors used in each stage: $N_{\\text{comp}}(h) = \\sum_{j=0}^{m-1} k_{j+1} = \\sum_{j=0}^{m-1} \\lfloor h_j/3 \\rfloor$.\nSimilarly, the total number of carry bits generated and passed to the next column is $C_{\\text{out}}(h) = \\sum_{j=0}^{m-1} k_{j+1}$.\nThus, for a single column of initial height $h$, the number of compressors required, $N_{\\text{comp}}(h)$, is equal to the number of carries it generates, $C_{\\text{out}}(h)$.\n\nLet's define a function $f(h)$ that represents this quantity, $N_{\\text{comp}}(h) = C_{\\text{out}}(h)$.\nBased on the staged reduction, we can write a recursive formula for $f(h)$:\n- If $h \\le 2$, no compressors are needed, so $f(h) = 0$.\n- If $h  2$, we use $\\lfloor h/3 \\rfloor$ compressors in the first stage, and the problem reduces to compressing a column of height $h' = \\lfloor h/3 \\rfloor + (h \\pmod 3)$. So, $f(h) = \\lfloor h/3 \\rfloor + f(\\lfloor h/3 \\rfloor + (h \\pmod 3))$.\n\nThis recursive formula allows us to calculate the number of compressors for any given column height.\n\nNow, consider a general bit heap profile $\\{H_i\\}$. The compression of columns is not independent due to the propagation of carries. The process must be performed sequentially from the least significant column ($i=0$) upwards.\n\nLet $N_i$ be the number of compressors used in column $i$, and let $C_i$ be the number of carries generated in column $i$ and passed to column $i+1$. As established, $N_i = C_i$.\nLet $H_i$ be the initial height of column $i$ from the problem statement.\nLet $H'_i$ be the total height of column $i$ before compression, which includes carries from the previous column.\nWe start with $C_{-1} = 0$.\n\nFor each column $i=0, 1, 2, \\dots$:\n1. The total height to be compressed is $H'_i = H_i + C_{i-1}$.\n2. The number of compressors required for this column is $N_i = f(H'_i)$.\n3. The number of carries passed to the next column is $C_i = N_i$.\n\nThis leads to the following recurrence relation for the number of compressors $N_i$ in each column $i$:\n$$N_i = f(H_i + N_{i-1}), \\quad \\text{with } N_{-1}=0$$\nwhere $f(h)$ is the recursive function defined previously. The total number of 3:2 compressors for the entire bit heap is the sum over all columns:\n$$N_{\\text{total}} = \\sum_i N_i$$\nThis constitutes the general formula and procedure.\n\n### Part 2: Application to Specific Profiles\n\nFirst, we pre-compute the values of $f(h)$ for relevant heights $h$.\n$f(0)=0, f(1)=0, f(2)=0$\n$f(3) = \\lfloor 3/3 \\rfloor + f(1) = 1+0=1$\n$f(4) = \\lfloor 4/3 \\rfloor + f(2) = 1+0=1$\n$f(5) = \\lfloor 5/3 \\rfloor + f(3) = 1+1=2$\n$f(6) = \\lfloor 6/3 \\rfloor + f(2) = 2+0=2$\n$f(7) = \\lfloor 7/3 \\rfloor + f(3) = 2+1=3$\n$f(8) = \\lfloor 8/3 \\rfloor + f(4) = 2+1=3$\n$f(9) = \\lfloor 9/3 \\rfloor + f(3) = 3+1=4$\n$f(10) = \\lfloor 10/3 \\rfloor + f(4) = 3+1=4$\n$f(11) = \\lfloor 11/3 \\rfloor + f(5) = 3+2=5$\n$f(12) = \\lfloor 12/3 \\rfloor + f(4) = 4+1=5$\n$f(13) = \\lfloor 13/3 \\rfloor + f(5) = 4+2=6$\n\n**Profile 1: Array Multiplier**\nThe initial profile is $\\{H_{i}^{\\text{array}}\\}_{i=0}^{14} = \\{1,2,3,4,5,6,7,8,7,6,5,4,3,2,1\\}$.\nWe compute $N_i^{\\text{array}} = C_i^{\\text{array}} = f(H_i^{\\text{array}} + C_{i-1}^{\\text{array}})$ with $C_{-1}^{\\text{array}} = 0$.\n\n$i=0: H'_0 = 1+0=1 \\implies N_0^{\\text{array}} = f(1)=0$. $C_0=0$.\n$i=1: H'_1 = 2+0=2 \\implies N_1^{\\text{array}} = f(2)=0$. $C_1=0$.\n$i=2: H'_2 = 3+0=3 \\implies N_2^{\\text{array}} = f(3)=1$. $C_2=1$.\n$i=3: H'_3 = 4+1=5 \\implies N_3^{\\text{array}} = f(5)=2$. $C_3=2$.\n$i=4: H'_4 = 5+2=7 \\implies N_4^{\\text{array}} = f(7)=3$. $C_4=3$.\n$i=5: H'_5 = 6+3=9 \\implies N_5^{\\text{array}} = f(9)=4$. $C_5=4$.\n$i=6: H'_6 = 7+4=11 \\implies N_6^{\\text{array}} = f(11)=5$. $C_6=5$.\n$i=7: H'_7 = 8+5=13 \\implies N_7^{\\text{array}} = f(13)=6$. $C_7=6$.\n$i=8: H'_8 = 7+6=13 \\implies N_8^{\\text{array}} = f(13)=6$. $C_8=6$.\n$i=9: H'_9 = 6+6=12 \\implies N_9^{\\text{array}} = f(12)=5$. $C_9=5$.\n$i=10: H'_{10} = 5+5=10 \\implies N_{10}^{\\text{array}} = f(10)=4$. $C_{10}=4$.\n$i=11: H'_{11} = 4+4=8 \\implies N_{11}^{\\text{array}} = f(8)=3$. $C_{11}=3$.\n$i=12: H'_{12} = 3+3=6 \\implies N_{12}^{\\text{array}} = f(6)=2$. $C_{12}=2$.\n$i=13: H'_{13} = 2+2=4 \\implies N_{13}^{\\text{array}} = f(4)=1$. $C_{13}=1$.\n$i=14: H'_{14} = 1+1=2 \\implies N_{14}^{\\text{array}} = f(2)=0$. $C_{14}=0$.\n\nTotal compressors for array multiplier:\n$$N_{\\text{total}}^{\\text{array}} = 0+0+1+2+3+4+5+6+6+5+4+3+2+1+0 = 42$$\n\n**Profile 2: Radix-4 Booth Recoding**\nThe initial profile is $\\{H_{i}^{\\text{Booth}}\\}_{i=0}^{14} = \\{1,1,2,2,3,3,4,4,3,3,2,2,1,1,0\\}$.\nWe compute $N_i^{\\text{Booth}} = C_i^{\\text{Booth}} = f(H_i^{\\text{Booth}} + C_{i-1}^{\\text{Booth}})$ with $C_{-1}^{\\text{Booth}} = 0$.\n\n$i=0: H'_0 = 1+0=1 \\implies N_0^{\\text{Booth}} = f(1)=0$. $C_0=0$.\n$i=1: H'_1 = 1+0=1 \\implies N_1^{\\text{Booth}} = f(1)=0$. $C_1=0$.\n$i=2: H'_2 = 2+0=2 \\implies N_2^{\\text{Booth}} = f(2)=0$. $C_2=0$.\n$i=3: H'_3 = 2+0=2 \\implies N_3^{\\text{Booth}} = f(2)=0$. $C_3=0$.\n$i=4: H'_4 = 3+0=3 \\implies N_4^{\\text{Booth}} = f(3)=1$. $C_4=1$.\n$i=5: H'_5 = 3+1=4 \\implies N_5^{\\text{Booth}} = f(4)=1$. $C_5=1$.\n$i=6: H'_6 = 4+1=5 \\implies N_6^{\\text{Booth}} = f(5)=2$. $C_6=2$.\n$i=7: H'_7 = 4+2=6 \\implies N_7^{\\text{Booth}} = f(6)=2$. $C_7=2$.\n$i=8: H'_8 = 3+2=5 \\implies N_8^{\\text{Booth}} = f(5)=2$. $C_8=2$.\n$i=9: H'_9 = 3+2=5 \\implies N_9^{\\text{Booth}} = f(5)=2$. $C_9=2$.\n$i=10: H'_{10} = 2+2=4 \\implies N_{10}^{\\text{Booth}} = f(4)=1$. $C_{10}=1$.\n$i=11: H'_{11} = 2+1=3 \\implies N_{11}^{\\text{Booth}} = f(3)=1$. $C_{11}=1$.\n$i=12: H'_{12} = 1+1=2 \\implies N_{12}^{\\text{Booth}} = f(2)=0$. $C_{12}=0$.\n$i=13: H'_{13} = 1+0=1 \\implies N_{13}^{\\text{Booth}} = f(1)=0$. $C_{13}=0$.\n$i=14: H'_{14} = 0+0=0 \\implies N_{14}^{\\text{Booth}} = f(0)=0$. $C_{14}=0$.\n\nTotal compressors for Booth-recoded multiplier:\n$$N_{\\text{total}}^{\\text{Booth}} = 0+0+0+0+1+1+2+2+2+2+1+1+0+0+0 = 12$$\n\n### Part 3: Final Calculation\n\nThe problem asks for the difference in the number of compressors, which is:\n$$N_{\\text{total}}^{\\text{array}} - N_{\\text{total}}^{\\text{Booth}} = 42 - 12 = 30$$\nThe Booth-recoded multiplier requires $30$ fewer 3:2 compressors than the array multiplier for this $8$-bit by $8$-bit case. This illustrates a primary advantage of Booth's algorithm: it reduces the number of partial products, leading to a smaller and faster reduction tree.",
            "answer": "$$\\boxed{30}$$"
        },
        {
            "introduction": "Our final practice synthesizes all the components of a multiplier into a single, high-performance system design challenge. Achieving the high clock frequencies of modern processors requires breaking complex logic paths into smaller, timed stages using pipelining. This exercise tasks you with calculating the delay of each part of a complete multiplier and strategically inserting pipeline registers to meet an aggressive clock speed target, bridging the gap between component-level theory and practical processor design .",
            "id": "3652039",
            "problem": "You are designing a signed $N=64$ fixed-width integer multiplier using radix-$4$ Booth recoding, a Wallace-style tree of 3:2 compressors, and a final carry-propagate adder (CPA) implemented as a parallel-prefix adder. The multiplier will be deeply pipelined with registers inserted only at stage boundaries that coincide with whole operations: Booth recoding and partial product selection, individual compressor levels in the reduction tree, and prefix levels inside the CPA. The target maximum clock frequency is $f_{\\max}=2~\\mathrm{GHz}$.\n\nUse the following realistic standard-cell timing model in a mature nanoscale complementary metal–oxide–semiconductor (CMOS) library:\n- Fanout-of-$4$ inverter delay $t_{\\mathrm{FO4}}=35~\\mathrm{ps}$.\n- Two-input gates $\\mathrm{AND2}$ or $\\mathrm{OR2}$: $1.0\\,t_{\\mathrm{FO4}}$.\n- Two-input $\\mathrm{XOR2}$: $2.0\\,t_{\\mathrm{FO4}}$.\n- Two-to-one multiplexer $\\mathrm{MUX2}$: $2.0\\,t_{\\mathrm{FO4}}$.\n- One full-adder based 3:2 compressor level delay (sum/carry) including local interconnect: $2.6\\,t_{\\mathrm{FO4}}$.\n- Pipeline register (flip-flop) timing overhead per stage, including clock-to-$Q$, setup time, and local clock skew: $t_{\\mathrm{reg}}=80~\\mathrm{ps}$.\n\nArchitectural assumptions:\n- Radix-$4$ Booth recoding is applied to the $64$-bit multiplier operand, yielding $M=\\lceil N/2\\rceil$ partial-product rows aligned by wiring shifts. The Booth recoder and partial-product selection network per bit are realized by a decoder and a small multiplexer network that select from $\\{0,\\pm X,\\pm 2X\\}$, where $X$ is the multiplicand. Model the end-to-end delay of the complete recoding and partial-product generation block as $D_{\\mathrm{BR}}=7\\,t_{\\mathrm{FO4}}$.\n- The partial products are reduced by a Wallace tree of 3:2 compressors and occasional 2:2 compressors until only two rows remain. Model the height reduction per level as a factor of approximately $3/2$, and count the number of compressor levels $L$ required to reduce $M$ rows to $2$ rows by iterating the height reduction.\n- The CPA is a Kogge–Stone parallel-prefix adder with $\\lceil \\log_{2}(N)\\rceil$ prefix levels. Model each prefix level as $2.0\\,t_{\\mathrm{FO4}}$, the precompute generate/propagate formation as $1.0\\,t_{\\mathrm{FO4}}$, and the final sum $\\mathrm{XOR}$ as $2.0\\,t_{\\mathrm{FO4}}$. Ignore long-wire penalties beyond the given per-level delays.\n\nFundamental timing rule: the per-stage clock period must satisfy $T_{\\mathrm{clk}} \\ge t_{\\mathrm{reg}} + t_{\\mathrm{logic}}$, where $t_{\\mathrm{logic}}$ is the worst-case combinational delay within that stage. The target period is $T_{\\mathrm{clk}}=1/f_{\\max}$.\n\nTask:\n- Determine the minimum total number of pipeline stages required to meet $f_{\\max}=2~\\mathrm{GHz}$.\n- In your reasoning, explicitly compute $L$ for the Wallace tree and justify how many compressor levels can be grouped into one pipeline stage under the timing constraint. Also justify how many pipeline stages are needed inside the CPA.\n- You must assign which stage or stages are used for Booth recoding and partial-product selection, which for compressor levels, and which for the CPA, ensuring every stage meets the timing constraint.\n\nExpress your final answer as a single integer equal to the minimum number of pipeline stages. No rounding is required. Do not include any units in your final answer.",
            "solution": "The problem requires determining the minimum number of pipeline stages for a $64$-bit signed integer multiplier to operate at a maximum clock frequency of $f_{\\max}=2~\\mathrm{GHz}$. The design comprises three main parts: Booth recoding and partial product generation, a Wallace tree for partial product reduction, and a Kogge-Stone adder for the final summation. The solution involves calculating the delay of each part and partitioning them into pipeline stages such that the combinational logic delay in any stage does not exceed the maximum allowed value.\n\nFirst, we establish the fundamental timing constraints. The target maximum clock frequency is $f_{\\max}=2~\\mathrm{GHz}$, which corresponds to a minimum clock period of:\n$$T_{\\mathrm{clk}} = \\frac{1}{f_{\\max}} = \\frac{1}{2 \\times 10^9~\\mathrm{Hz}} = 0.5~\\mathrm{ns} = 500~\\mathrm{ps}$$\nThe timing rule for each pipeline stage is given by $T_{\\mathrm{clk}} \\ge t_{\\mathrm{reg}} + t_{\\mathrm{logic}}$. The pipeline register overhead is $t_{\\mathrm{reg}}=80~\\mathrm{ps}$. Therefore, the maximum allowable combinational logic delay within any single pipeline stage is:\n$$t_{\\mathrm{logic,max}} = T_{\\mathrm{clk}} - t_{\\mathrm{reg}} = 500~\\mathrm{ps} - 80~\\mathrm{ps} = 420~\\mathrm{ps}$$\nThe problem provides a standard-cell timing model based on the fanout-of-$4$ inverter delay, $t_{\\mathrm{FO4}} = 35~\\mathrm{ps}$. We can express the maximum logic delay in terms of this unit:\n$$t_{\\mathrm{logic,max}} = \\frac{420~\\mathrm{ps}}{35~\\mathrm{ps}/t_{\\mathrm{FO4}}} = 12~t_{\\mathrm{FO4}}$$\n\nNow, we analyze each part of the multiplier design to determine the number of stages required.\n\n1. Booth Recoding and Partial Product Generation\nThe problem states that the end-to-end delay of the radix-$4$ Booth recoder and partial product selection network is modeled as $D_{\\mathrm{BR}} = 7~t_{\\mathrm{FO4}}$. In absolute time, this delay is:\n$$D_{\\mathrm{BR}} = 7 \\times 35~\\mathrm{ps} = 245~\\mathrm{ps}$$\nSince this delay is less than the maximum allowable logic delay ($245~\\mathrm{ps}  420~\\mathrm{ps}$), this entire block can be implemented within a single pipeline stage.\nNumber of stages for Booth recoding = $1$.\n\n2. Wallace Tree Reduction\nThe multiplier operand has a width of $N=64$ bits. With radix-$4$ Booth recoding, the number of partial products to be summed is given as $M = \\lceil N/2 \\rceil = \\lceil 64/2 \\rceil = 32$. The Wallace tree reduces these $32$ rows to $2$ rows using 3:2 compressors. We must calculate the number of compressor levels, $L$, required for this reduction. Let $H_k$ be the number of rows after level $k$, with $H_0=32$. The number of rows is reduced at each level according to the formula $H_{k+1} = 2 \\cdot \\lfloor H_k/3 \\rfloor + (H_k \\pmod 3)$.\n- $H_0 = 32$\n- $H_1 = 2 \\cdot \\lfloor 32/3 \\rfloor + (32 \\pmod 3) = 2 \\cdot 10 + 2 = 22$\n- $H_2 = 2 \\cdot \\lfloor 22/3 \\rfloor + (22 \\pmod 3) = 2 \\cdot 7 + 1 = 15$\n- $H_3 = 2 \\cdot \\lfloor 15/3 \\rfloor + (15 \\pmod 3) = 2 \\cdot 5 + 0 = 10$\n- $H_4 = 2 \\cdot \\lfloor 10/3 \\rfloor + (10 \\pmod 3) = 2 \\cdot 3 + 1 = 7$\n- $H_5 = 2 \\cdot \\lfloor 7/3 \\rfloor + (7 \\pmod 3) = 2 \\cdot 2 + 1 = 5$\n- $H_6 = 2 \\cdot \\lfloor 5/3 \\rfloor + (5 \\pmod 3) = 2 \\cdot 1 + 2 = 4$\n- $H_7 = 2 \\cdot \\lfloor 4/3 \\rfloor + (4 \\pmod 3) = 2 \\cdot 1 + 1 = 3$\n- $H_8 = 2 \\cdot \\lfloor 3/3 \\rfloor + (3 \\pmod 3) = 2 \\cdot 1 + 0 = 2$\nThe reduction requires $L=8$ levels of compressors.\n\nThe delay of a single 3:2 compressor level is given as $t_{\\mathrm{comp}} = 2.6~t_{\\mathrm{FO4}}$. In absolute time:\n$$t_{\\mathrm{comp}} = 2.6 \\times 35~\\mathrm{ps} = 91~\\mathrm{ps}$$\nTo minimize pipeline stages, we group as many compressor levels as possible into a single stage. The maximum number of levels per stage is:\n$$\\text{Levels per stage} = \\left\\lfloor \\frac{t_{\\mathrm{logic,max}}}{t_{\\mathrm{comp}}} \\right\\rfloor = \\left\\lfloor \\frac{420~\\mathrm{ps}}{91~\\mathrm{ps}} \\right\\rfloor = \\lfloor 4.615... \\rfloor = 4$$\nWith a total of $L=8$ levels and a maximum of $4$ levels per stage, the minimum number of stages for the Wallace tree is:\n$$\\text{Number of stages for Wallace tree} = \\left\\lceil \\frac{L}{4} \\right\\rceil = \\left\\lceil \\frac{8}{4} \\right\\rceil = 2$$\nThese two stages would comprise levels $1-4$ and levels $5-8$ of the compressor tree, respectively. The delay of each of these stages is $4 \\times 91~\\mathrm{ps} = 364~\\mathrm{ps}$, which is within the $420~\\mathrm{ps}$ budget.\n\n3. Final Carry-Propagate Adder (CPA)\nThe final adder is a $64$-bit Kogge-Stone parallel-prefix adder. Its operation can be broken down into three logical parts with specified delays:\n- Pre-computation of generate/propagate signals: $t_{\\mathrm{pre}} = 1.0~t_{\\mathrm{FO4}} = 35~\\mathrm{ps}$.\n- Prefix tree computation: The number of levels for $N=64$ is $\\lceil \\log_{2}(N) \\rceil = \\lceil \\log_{2}(64) \\rceil = 6$. The delay per level is $t_{\\mathrm{prefix}} = 2.0~t_{\\mathrm{FO4}} = 70~\\mathrm{ps}$.\n- Final sum XOR: $t_{\\mathrm{sum}} = 2.0~t_{\\mathrm{FO4}} = 70~\\mathrm{ps}$.\n\nThe problem allows inserting pipeline registers between these distinct operations (pre-computation, each prefix level, final sum). We must group these operations into the minimum number of stages. We apply a greedy approach to fill each stage's delay budget.\n- Stage CPA-1: Start with pre-computation ($35~\\mathrm{ps}$). We can add prefix levels.\n  - Delay with $k$ prefix levels: $t_{\\mathrm{pre}} + k \\cdot t_{\\mathrm{prefix}} = 35 + k \\cdot 70$.\n  - For $k=5$, the delay is $35 + 5 \\cdot 70 = 35 + 350 = 385~\\mathrm{ps}$. This is $\\le 420~\\mathrm{ps}$.\n  - For $k=6$, the delay is $35 + 6 \\cdot 70 = 35 + 420 = 455~\\mathrm{ps}$, which exceeds the budget.\n  - So, the first CPA stage can contain the pre-computation block and $5$ prefix levels. The delay is $385~\\mathrm{ps}$.\n- Stage CPA-2: The remaining logic consists of $1$ prefix level and the final sum XOR.\n  - The delay is $t_{\\mathrm{prefix}} + t_{\\mathrm{sum}} = 70~\\mathrm{ps} + 70~\\mathrm{ps} = 140~\\mathrm{ps}$.\n  - This is well within the $420~\\mathrm{ps}$ budget.\nThus, the CPA requires a minimum of $2$ pipeline stages.\n\nTotal Pipeline Stages\nTo find the total minimum number of pipeline stages for the entire multiplier, we sum the stages required for each part:\n$$N_{\\mathrm{stages}} = (\\text{Stages for Booth}) + (\\text{Stages for Wallace tree}) + (\\text{Stages for CPA})$$\n$$N_{\\mathrm{stages}} = 1 + 2 + 2 = 5$$\nThe final architecture consists of $5$ pipeline stages:\n- Stage $1$: Booth Recoding and Partial Product Generation (delay $245~\\mathrm{ps}$).\n- Stage $2$: Wallace Tree Compressor Levels $1-4$ (delay $364~\\mathrm{ps}$).\n- Stage $3$: Wallace Tree Compressor Levels $5-8$ (delay $364~\\mathrm{ps}$).\n- Stage $4$: CPA Pre-computation and Prefix Levels $1-5$ (delay $385~\\mathrm{ps}$).\n- Stage $5$: CPA Prefix Level $6$ and Final Sum (delay $140~\\mathrm{ps}$).\n\nAll stages satisfy the timing constraint $t_{\\mathrm{logic}} \\le 420~\\mathrm{ps}$. Therefore, the minimum total number of pipeline stages is $5$.",
            "answer": "$$\\boxed{5}$$"
        }
    ]
}