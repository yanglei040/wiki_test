{
    "hands_on_practices": [
        {
            "introduction": "To truly understand the trade-offs between synchronous and asynchronous buses, we must analyze their performance beyond ideal conditions. This first practice problem models a realistic scenario with variable device service times. By calculating the expected transfer time for each bus type, you will gain a hands-on appreciation for how a synchronous bus's rigid clock quantization compares to an asynchronous bus's adaptive timing.",
            "id": "3683502",
            "problem": "A computer system is built with two peripheral interconnects: a synchronous bus and an asynchronous bus. You are tasked with modeling an on-chip performance counter that estimates the average number of bus clock cycles per data transfer on the synchronous bus and comparing it to the average handshake duration on the asynchronous bus under workload variability.\n\nAssume the following operational definitions and conditions:\n\n- On the synchronous bus, each transfer consists of an address phase followed by a data phase. The bus samples data only on clock boundaries. If the device’s service time exceeds the time until the next sampling boundary, the bus inserts wait states until a sampling boundary occurs at or after the service completion. The performance counter records the total number of bus clock cycles that were spent actively performing transfers over a long observation window and the total number of completed transfers.\n\n- On the asynchronous bus, a classical four-phase request–acknowledge handshake is used: request asserted, acknowledge asserted, request deasserted, acknowledge deasserted. Each control transition incurs a fixed propagation delay. The acknowledge is not asserted until the device completes its service.\n\n- The device service time is a random variable modeling workload variability: with probability $p$, the service time equals $x_{f}$ (fast case), and with probability $1 - p$, it equals $x_{s}$ (slow case). The same service time variability applies on both buses.\n\nYou are given the following parameters:\n\n- Synchronous bus clock frequency $f = 200$ megahertz.\n- Control-signal propagation delay per transition on the asynchronous bus $t_{p} = 1$ nanosecond.\n- Fast service time $x_{f} = 7$ nanoseconds.\n- Slow service time $x_{s} = 19$ nanoseconds.\n- Fast-case probability $p = 0.7$.\n\nUsing only first-principles definitions of the synchronous transfer timing and the four-phase asynchronous handshake timeline:\n\n1. Derive the expected number of clock cycles per transfer on the synchronous bus as would be reported by the performance counter over a long window.\n2. Derive the expected handshake duration on the asynchronous bus.\n3. Compute the ratio $R$ of the asynchronous bus’s expected handshake duration to the synchronous bus’s expected transfer time in seconds.\n\nExpress the final ratio $R$ as a simplified exact fraction. No rounding is required, and the ratio is dimensionless. Do not include any units in your final answer.",
            "solution": "This problem requires a first-principles analysis of the expected performance of a synchronous and an asynchronous bus under a probabilistic workload.\n\nThe given parameters are:\n- Synchronous bus clock frequency, $f = 200 \\times 10^6$ Hz.\n- Asynchronous bus control-signal propagation delay per transition, $t_p = 1 \\times 10^{-9}$ s.\n- Fast service time, $x_f = 7 \\times 10^{-9}$ s.\n- Slow service time, $x_s = 19 \\times 10^{-9}$ s.\n- Probability of a fast service time, $p = 0.7$.\n\nThe service time, $x$, is a random variable with probability mass function $P(x=x_f) = p$ and $P(x=x_s) = 1-p$.\n\n**1. Analysis of the Synchronous Bus**\n\nFirst, we determine the clock period, $T_{clk}$, of the synchronous bus.\n$$T_{clk} = \\frac{1}{f} = \\frac{1}{200 \\times 10^6 \\text{ Hz}} = 5 \\times 10^{-9} \\text{ s} = 5 \\text{ ns}$$\n\nA transfer on the synchronous bus consists of an address phase and a data phase. A standard and minimal model for such a protocol assumes the address phase takes one clock cycle. The device service, of duration $x$, starts after the address is issued. The data can only be sampled at a rising clock edge. Therefore, wait states are inserted until the first clock edge that occurs at or after the service is complete.\n\nLet a transfer start at time $t=0$. The address phase consumes one clock cycle, so it ends at time $t=T_{clk}$. The service of duration $x$ begins at this point, and the data becomes available at time $T_{clk} + x$. The total duration of the transfer must be an integer number of clock cycles, $C_{sync}(x)$, such that the total time, $C_{sync}(x) \\cdot T_{clk}$, is at least $T_{clk} + x$.\n$$C_{sync}(x) \\cdot T_{clk} \\ge T_{clk} + x$$\nThe number of cycles is the smallest integer satisfying this condition, which is found using the ceiling function:\n$$C_{sync}(x) = \\left\\lceil \\frac{T_{clk} + x}{T_{clk}} \\right\\rceil = 1 + \\left\\lceil \\frac{x}{T_{clk}} \\right\\rceil$$\n\nWe apply this model to the two service time cases:\nFor the fast case ($x_f = 7 \\text{ ns}$):\n$$C_{sync}(x_f) = 1 + \\left\\lceil \\frac{7 \\text{ ns}}{5 \\text{ ns}} \\right\\rceil = 1 + \\lceil 1.4 \\rceil = 1 + 2 = 3 \\text{ cycles}$$\nFor the slow case ($x_s = 19 \\text{ ns}$):\n$$C_{sync}(x_s) = 1 + \\left\\lceil \\frac{19 \\text{ ns}}{5 \\text{ ns}} \\right\\rceil = 1 + \\lceil 3.8 \\rceil = 1 + 4 = 5 \\text{ cycles}$$\n\nThe expected number of clock cycles per transfer, $E[C_{sync}]$, is the weighted average of the cycles for the fast and slow cases.\n$$E[C_{sync}] = p \\cdot C_{sync}(x_f) + (1-p) \\cdot C_{sync}(x_s)$$\n$$E[C_{sync}] = (0.7)(3) + (1-0.7)(5) = (0.7)(3) + (0.3)(5) = 2.1 + 1.5 = 3.6$$\nThis is the answer to the first part of the problem.\n\n**2. Analysis of the Asynchronous Bus**\n\nThe asynchronous bus uses a four-phase handshake protocol. The duration of this handshake, $T_{async}(x)$, for a given service time $x$ can be determined by summing the delays of each phase:\n1. The master asserts the request signal. It takes a time $t_p$ to propagate to the slave.\n2. The slave receives the request, performs the service (duration $x$), and then asserts the acknowledge signal.\n3. The acknowledge signal propagates back to the master, which takes another $t_p$.\n4. The master receives the acknowledge and deasserts the request. This signal propagates to the slave in $t_p$.\n5. The slave receives the deasserted request and deasserts the acknowledge. This signal travels back to the master in $t_p$.\nThe total duration of the handshake is the sum of the service time and the four propagation delays.\n$$T_{async}(x) = x + 4t_p$$\n\nWe apply this model to the two service time cases with $t_p = 1 \\text{ ns}$:\nFor the fast case ($x_f = 7 \\text{ ns}$):\n$$T_{async}(x_f) = 7 \\text{ ns} + 4(1 \\text{ ns}) = 11 \\text{ ns}$$\nFor the slow case ($x_s = 19 \\text{ ns}$):\n$$T_{async}(x_s) = 19 \\text{ ns} + 4(1 \\text{ ns}) = 23 \\text{ ns}$$\n\nThe expected handshake duration, $E[T_{async}]$, is the weighted average.\n$$E[T_{async}] = p \\cdot T_{async}(x_f) + (1-p) \\cdot T_{async}(x_s)$$\n$$E[T_{async}] = (0.7)(11 \\text{ ns}) + (0.3)(23 \\text{ ns}) = 7.7 \\text{ ns} + 6.9 \\text{ ns} = 14.6 \\text{ ns}$$\nThis is the answer to the second part of the problem.\n\n**3. Calculation of the Ratio R**\n\nThe problem asks for the ratio $R$ of the asynchronous bus's expected handshake duration to the synchronous bus's expected transfer time in seconds.\nThe numerator is $E[T_{async}] = 14.6 \\text{ ns}$.\n\nThe denominator is the expected transfer time on the synchronous bus, $E[T_{sync}]$. The time for a synchronous transfer with service time $x$ is $T_{sync}(x) = C_{sync}(x) \\cdot T_{clk}$. The expected time is:\n$$E[T_{sync}] = E[C_{sync}(x) \\cdot T_{clk}]$$\nSince $T_{clk}$ is a constant, we can write:\n$$E[T_{sync}] = E[C_{sync}] \\cdot T_{clk}$$\nUsing the result from Part 1, $E[C_{sync}] = 3.6$, and $T_{clk} = 5 \\text{ ns}$:\n$$E[T_{sync}] = 3.6 \\cdot 5 \\text{ ns} = 18 \\text{ ns}$$\n\nNow we can compute the ratio $R$:\n$$R = \\frac{E[T_{async}]}{E[T_{sync}]} = \\frac{14.6 \\text{ ns}}{18 \\text{ ns}} = \\frac{14.6}{18}$$\n\nTo express this as a simplified exact fraction, we convert the decimal to a fraction:\n$$R = \\frac{146}{180}$$\nWe simplify the fraction by dividing the numerator and denominator by their greatest common divisor, which is $2$:\n$$R = \\frac{146 \\div 2}{180 \\div 2} = \\frac{73}{90}$$\nSince $73$ is a prime number and does not divide $90$, the fraction is fully simplified.",
            "answer": "$$\\boxed{\\frac{73}{90}}$$"
        },
        {
            "introduction": "Performance is not just about speed; energy efficiency is a critical design constraint in modern systems. This exercise delves into the fundamental principles of CMOS power consumption to compare the energy cost of a synchronous and an asynchronous bus. You will see how the concept of an \"activity factor,\" which reflects how often data changes, reveals a key advantage of asynchronous designs in low-activity scenarios.",
            "id": "3683515",
            "problem": "Consider a wide on-chip data bus implemented in Complementary Metal-Oxide-Semiconductor (CMOS) technology. The bus has width $w$ bits, and each bit line presents a load capacitance $C_{\\ell}$. The supply voltage is $V$. Assume that static leakage and short-circuit power are negligible, and model each bit line transition as charging or discharging an effective capacitor through a resistive network.\n\nThe bus is used in two regimes:\n- A synchronous regime at high clock frequency, where successive words on the bus are independent and each bit is equally likely to be $0$ or $1$.\n- An asynchronous regime with sparse data activity, where only a small fraction of bit positions experience a $0 \\to 1$ transition between successive words.\n\nUse first principles of energy transfer when charging a capacitor through a resistive path from $0$ to $V$ to derive the expected energy drawn from the supply per transferred word in each regime as a function of $w$, $C_{\\ell}$, $V$, and the activity factor $\\alpha$ defined as the expected fraction of bit positions that undergo a $0 \\to 1$ transition between successive words. For the synchronous regime, derive $\\alpha$ based on the independence and equiprobability assumptions. Then evaluate the ratio of asynchronous to synchronous energy per word for the following parameters:\n- Bus width $w = 128$,\n- Line capacitance per bit $C_{\\ell} = 0.20 \\,\\text{pF}$,\n- Supply voltage $V = 0.90 \\,\\text{V}$,\n- Asynchronous activity factor $\\alpha_{\\text{async}} = 0.05$.\n\nExpress the final result as the single ratio $R = \\dfrac{E_{\\text{async}}}{E_{\\text{sync}}}$. No rounding is required. If you compute intermediate energies, express them in Joules.",
            "solution": "This problem requires an analysis of the expected energy consumption per word transfer for synchronous and asynchronous buses, based on first principles of CMOS power consumption. The solution proceeds in three main steps:\n1.  Derive the energy drawn from the power supply for a single $0 \\to 1$ bit transition.\n2.  Formulate the expected energy per word transfer for both the synchronous and asynchronous regimes using the concept of an activity factor.\n3.  Calculate the ratio of the asynchronous energy to the synchronous energy.\n\n**Step 1: Energy for a Single Bit Transition**\nThe problem asks to consider the energy transfer when charging a capacitor through a resistive path. Let a single bit line be modeled as a capacitor of capacitance $C_{\\ell}$. A $0 \\to 1$ transition corresponds to charging this capacitor from an initial voltage of $0$ to the supply voltage $V$. The charging occurs from the voltage supply $V$ through the pull-up network, which has some effective resistance.\n\nThe instantaneous current flowing from the supply during charging is $i(t)$. The instantaneous power drawn from the supply is $P(t) = V i(t)$. The total energy drawn from the supply, $E_{\\text{supply}}$, is the integral of this power over the entire charging duration (from $t=0$ to $t \\to \\infty$):\n$$E_{\\text{supply}} = \\int_0^\\infty P(t) \\,dt = \\int_0^\\infty V i(t) \\,dt$$\nSince the supply voltage $V$ is constant, we can write:\n$$E_{\\text{supply}} = V \\int_0^\\infty i(t) \\,dt$$\nThe integral of the current over time is the total charge $Q$ that flows from the supply to the capacitor to charge it to voltage $V$. The charge stored on a capacitor is given by $Q = C_{\\ell}V$.\nSubstituting this into the energy equation, we get:\n$$E_{\\text{supply}} = V Q = V(C_{\\ell}V) = C_{\\ell}V^2$$\nThis is the total energy drawn from the power supply for one $0 \\to 1$ transition on a single bit line. It is a fundamental result that half of this energy, $\\frac{1}{2}C_{\\ell}V^2$, is stored in the capacitor, and the other half is dissipated as heat in the resistive path.\n\nFor a $1 \\to 0$ transition, the capacitor $C_{\\ell}$ discharges to ground through the pull-down network. The stored energy, $\\frac{1}{2}C_{\\ell}V^2$, is dissipated as heat in the pull-down transistors. No energy is drawn from the supply $V$ during this process.\nFor $0 \\to 0$ and $1 \\to 1$ transitions, the capacitor voltage does not change, and thus no dynamic energy is consumed.\nTherefore, dynamic energy is drawn from the supply only during $0 \\to 1$ transitions.\n\n**Step 2: Expected Energy per Word**\nThe total energy drawn from the supply per word transfer depends on the expected number of bit lines that transition from $0$ to $1$.\nLet $\\alpha$ be the activity factor, defined as the expected fraction of bit positions that undergo a $0 \\to 1$ transition between successive words. This is equivalent to the probability of a single bit line transitioning from $0$ to $1$.\nFor a bus of width $w$, the expected number of $0 \\to 1$ transitions per word transfer, $N_{0 \\to 1}$, is:\n$$N_{0 \\to 1} = w \\alpha$$\nThe total expected energy drawn from the supply per word, $E_{\\text{word}}$, is the product of the expected number of $0 \\to 1$ transitions and the energy per transition:\n$$E_{\\text{word}} = N_{0 \\to 1} \\times E_{\\text{supply}} = (w \\alpha) (C_{\\ell}V^2) = w \\alpha C_{\\ell}V^2$$\n\n**Synchronous Regime:**\nIn the synchronous regime, successive words are independent, and each bit is equally likely to be $0$ or $1$. Let $b_t$ be the state of a bit at time $t$.\n$$P(b_t=0) = \\frac{1}{2} \\quad \\text{and} \\quad P(b_t=1) = \\frac{1}{2}$$\nThe activity factor for the synchronous regime, $\\alpha_{\\text{sync}}$, is the probability of a $0 \\to 1$ transition from time $t-1$ to $t$. Due to independence:\n$$\\alpha_{\\text{sync}} = P(b_{t-1}=0 \\text{ and } b_t=1) = P(b_{t-1}=0) \\times P(b_t=1) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4} = 0.25$$\nThe expected energy per word in the synchronous regime is:\n$$E_{\\text{sync}} = w \\alpha_{\\text{sync}} C_{\\ell}V^2 = w (0.25) C_{\\ell}V^2$$\n\n**Asynchronous Regime:**\nIn the asynchronous regime, the activity factor $\\alpha_{\\text{async}}$ is given directly in the problem statement as a parameter reflecting sparse data activity.\n$$\\alpha_{\\text{async}} = 0.05$$\nThe expected energy per word in the asynchronous regime is:\n$$E_{\\text{async}} = w \\alpha_{\\text{async}} C_{\\ell}V^2 = w (0.05) C_{\\ell}V^2$$\n\n**Step 3: Ratio of Energies**\nThe problem requires the evaluation of the ratio $R = \\frac{E_{\\text{async}}}{E_{\\text{sync}}}$.\n$$R = \\frac{w \\alpha_{\\text{async}} C_{\\ell}V^2}{w \\alpha_{\\text{sync}} C_{\\ell}V^2}$$\nThe terms for bus width ($w$), line capacitance ($C_{\\ell}$), and supply voltage ($V$) cancel out. The ratio depends only on the activity factors of the two regimes.\n$$R = \\frac{\\alpha_{\\text{async}}}{\\alpha_{\\text{sync}}}$$\nSubstituting the values for the activity factors:\n$$R = \\frac{0.05}{0.25} = \\frac{5}{25} = \\frac{1}{5} = 0.2$$\nThe specific numerical values for $w$, $C_{\\ell}$, and $V$ are not required to calculate the final ratio, as they are identical for both regimes and thus cancel out. The ratio shows that the bus consumes $5$ times more energy per word in the synchronous, random-data regime than in the asynchronous, sparse-data regime described.",
            "answer": "$$\\boxed{0.2}$$"
        },
        {
            "introduction": "Connecting asynchronous and synchronous domains is a common but perilous task in system design, with the primary danger being metastability. This final practice tackles this advanced challenge by quantifying the reliability of a flip-flop synchronizer, a standard circuit for mitigating this risk. By calculating the exponential improvement in Mean Time Between Failures (MTBF), you will learn why adding even one extra stage to a synchronizer is a crucial and powerful design technique.",
            "id": "3683482",
            "problem": "A System-on-Chip (SoC) integrates an asynchronous peripheral that asserts a status signal with an average independent toggle rate of $f_{\\text{in}}$, which is sampled by a synchronous bus clocked at frequency $f_{\\text{clk}}$. To mitigate metastability at the clock-domain crossing, the bus interface designer considers a chain of edge-triggered flip-flops as a synchronizer. The metastability dynamics of the first flip-flop’s internal node follow an exponential decay model: the probability that the node remains metastable beyond time $t$ decays exponentially with time constant $\\tau$, and the density at $t=0$ is characterized by an effective aperture parameter $T_{0}$ that sets the scale of rare-event likelihood in the model. Assume independent sampling opportunities occur at a rate proportional to $f_{\\text{in}} f_{\\text{clk}}$, and use this exponential model as the foundational base for estimating the Mean Time Between Failures (MTBF).\n\nThe designer is comparing a two-flip-flop synchronizer against a three-flip-flop synchronizer. Let the clock period be $T_{\\text{clk}} = 1/f_{\\text{clk}}$, the aggregate clock-to-output plus routing delay from one stage to the next be $t_{\\text{pd}}$, and the setup time of the receiving flip-flop be $t_{\\text{setup}}$. For an $N$-stage synchronizer, take the available metastability resolution time to the final sampling as\n$$\nT_{\\text{res}}(N) = (N-1) \\, T_{\\text{clk}} - t_{\\text{pd}} - t_{\\text{setup}}.\n$$\nStarting from the exponential metastability decay model and the fact that the failure rate is the product of the opportunity rate and the probability that metastability persists until the final sampling event, derive the expression for the MTBF of an $N$-stage synchronizer and then specialize it to $N=2$ and $N=3$ to obtain the ratio\n$$\nR \\equiv \\frac{\\text{MTBF}_{3}}{\\text{MTBF}_{2}}.\n$$\n\nUse the following device and system parameters:\n- $f_{\\text{in}} = 10\\,\\text{MHz}$,\n- $f_{\\text{clk}} = 250\\,\\text{MHz}$,\n- $t_{\\text{pd}} = 70\\,\\text{ps}$,\n- $t_{\\text{setup}} = 50\\,\\text{ps}$,\n- $\\tau = 50\\,\\text{ps}$,\n- $T_{0} = 1.0 \\times 10^{-10}\\,\\text{s}$.\n\nCompute the numerical value of $R$ under these assumptions. Express your answer as a pure number with no units, and round your answer to three significant figures.",
            "solution": "The problem requires the derivation and calculation of the ratio of the Mean Time Between Failures (MTBF) for a 3-stage synchronizer to that of a 2-stage synchronizer. The MTBF is the reciprocal of the failure rate.\n\nThe failure rate for a synchronizer is determined by the rate at which metastable events are initiated and the probability that such an event does not resolve within the time allowed. A widely accepted formula for the MTBF of a synchronizer, consistent with the exponential decay model described in the problem, is:\n$$\n\\text{MTBF} = \\frac{\\exp(T_{\\text{res}}/\\tau)}{C \\cdot f_{\\text{clk}} \\cdot f_{\\text{in}}}\n$$\nwhere $T_{\\text{res}}$ is the time available for the metastable state to resolve, $\\tau$ is the technology-dependent time constant for this resolution, $f_{\\text{clk}}$ is the sampling clock frequency, $f_{\\text{in}}$ is the rate of data transitions on the asynchronous input, and $C$ is a constant of proportionality. The problem identifies this constant with the effective time aperture of the flip-flop, given as $T_0$. Therefore, for an $N$-stage synchronizer, we have:\n$$\n\\text{MTBF}_{N} = \\frac{\\exp(T_{\\text{res}}(N)/\\tau)}{T_0 f_{\\text{clk}} f_{\\text{in}}}\n$$\nThe problem provides a specific formula for the resolution time, $T_{\\text{res}}(N)$, for an $N$-stage synchronizer:\n$$\nT_{\\text{res}}(N) = (N-1) T_{\\text{clk}} - t_{\\text{pd}} - t_{\\text{setup}}\n$$\nHere, $T_{\\text{clk}} = 1/f_{\\text{clk}}$ is the clock period.\n\nWe need to find the ratio $R = \\text{MTBF}_{3} / \\text{MTBF}_{2}$. Let's first write the expressions for $\\text{MTBF}_{2}$ and $\\text{MTBF}_{3}$ using the given formulas.\n\nFor a $2$-stage synchronizer ($N=2$):\n$$\nT_{\\text{res}}(2) = (2-1) T_{\\text{clk}} - t_{\\text{pd}} - t_{\\text{setup}} = T_{\\text{clk}} - t_{\\text{pd}} - t_{\\text{setup}}\n$$\n$$\n\\text{MTBF}_{2} = \\frac{\\exp(T_{\\text{res}}(2)/\\tau)}{T_0 f_{\\text{clk}} f_{\\text{in}}}\n$$\n\nFor a $3$-stage synchronizer ($N=3$):\n$$\nT_{\\text{res}}(3) = (3-1) T_{\\text{clk}} - t_{\\text{pd}} - t_{\\text{setup}} = 2 T_{\\text{clk}} - t_{\\text{pd}} - t_{\\text{setup}}\n$$\n$$\n\\text{MTBF}_{3} = \\frac{\\exp(T_{\\text{res}}(3)/\\tau)}{T_0 f_{\\text{clk}} f_{\\text{in}}}\n$$\n\nNow, we can compute the ratio $R$:\n$$\nR = \\frac{\\text{MTBF}_{3}}{\\text{MTBF}_{2}} = \\frac{\\frac{\\exp(T_{\\text{res}}(3)/\\tau)}{T_0 f_{\\text{clk}} f_{\\text{in}}}}{\\frac{\\exp(T_{\\text{res}}(2)/\\tau)}{T_0 f_{\\text{clk}} f_{\\text{in}}}}\n$$\nThe common denominator term $T_0 f_{\\text{clk}} f_{\\text{in}}$ cancels out, leaving:\n$$\nR = \\frac{\\exp(T_{\\text{res}}(3)/\\tau)}{\\exp(T_{\\text{res}}(2)/\\tau)} = \\exp\\left(\\frac{T_{\\text{res}}(3) - T_{\\text{res}}(2)}{\\tau}\\right)\n$$\nLet's calculate the difference in resolution times:\n$$\nT_{\\text{res}}(3) - T_{\\text{res}}(2) = (2 T_{\\text{clk}} - t_{\\text{pd}} - t_{\\text{setup}}) - (T_{\\text{clk}} - t_{\\text{pd}} - t_{\\text{setup}})\n$$\n$$\nT_{\\text{res}}(3) - T_{\\text{res}}(2) = 2 T_{\\text{clk}} - T_{\\text{clk}} = T_{\\text{clk}}\n$$\nSubstituting this result back into the expression for $R$, we obtain a simplified symbolic expression:\n$$\nR = \\exp\\left(\\frac{T_{\\text{clk}}}{\\tau}\\right)\n$$\nThis result shows that, within the given model, the improvement in MTBF from adding one synchronizer stage is an exponential function of the ratio of the clock period to the metastability time constant.\n\nTo find the numerical value of $R$, we must first calculate $T_{\\text{clk}}$ from the given $f_{\\text{clk}}$.\nThe given parameters are:\n- $f_{\\text{clk}} = 250\\,\\text{MHz} = 250 \\times 10^6\\,\\text{Hz}$\n- $\\tau = 50\\,\\text{ps} = 50 \\times 10^{-12}\\,\\text{s}$\n\nFirst, we calculate the clock period $T_{\\text{clk}}$:\n$$\nT_{\\text{clk}} = \\frac{1}{f_{\\text{clk}}} = \\frac{1}{250 \\times 10^6\\,\\text{Hz}} = 4.0 \\times 10^{-9}\\,\\text{s}\n$$\nTo maintain consistent units for the ratio $T_{\\text{clk}}/\\tau$, we can express $T_{\\text{clk}}$ in picoseconds:\n$$\nT_{\\text{clk}} = 4.0 \\times 10^{-9}\\,\\text{s} = 4000 \\times 10^{-12}\\,\\text{s} = 4000\\,\\text{ps}\n$$\nNow we compute the dimensionless exponent:\n$$\n\\frac{T_{\\text{clk}}}{\\tau} = \\frac{4000\\,\\text{ps}}{50\\,\\text{ps}} = 80\n$$\nFinally, we can calculate the value of the ratio $R$:\n$$\nR = \\exp(80) \\approx 5.540622 \\times 10^{34}\n$$\nRounding the result to three significant figures, as requested:\n$$\nR \\approx 5.54 \\times 10^{34}\n$$\nThis demonstrates the dramatic improvement in reliability achieved by adding an extra flip-flop stage to the synchronizer chain.",
            "answer": "$$ \\boxed{5.54 \\times 10^{34}} $$"
        }
    ]
}