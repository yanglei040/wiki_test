{
    "hands_on_practices": [
        {
            "introduction": "编程I/O的核心在于一个基本的权衡：CPU检查设备状态的频率越高，响应延迟就越低，但相应的CPU开销也越大。本练习旨在量化这种权衡关系。通过推导在给定CPU预算下最小化延迟的最佳轮询周期，学生将学会如何在系统响应速度和资源消耗之间做出工程决策。",
            "id": "3670436",
            "problem": "一个单核中央处理器 (CPU) 使用程序化输入/输出 (I/O) 方式管理一个设备，它每隔 $T_{p}$ 秒周期性地轮询设备的状态寄存器。每次轮询消耗固定的 CPU 时间 $c$（单位为秒），并且当检测到设备事件时，每个事件需要固定的处理时间 $s$（单位为秒）。事件以平均速率 $\\lambda$（单位为事件/秒）从设备到达，且到达时刻与轮询时刻无关。CPU 每秒时间中的一部分 $U$ 被预算并保留给该设备（即，该设备的总 CPU 需求不得超过每秒 $U$ 秒）。\n\n假设以下基本事实：\n\n- 在周期为 $T_{p}$ 的周期性轮询下，如果事件到达时刻与轮询调度无关，则期望检测延迟为 $T_{p}/2$。\n- 从事件到达至其处理完成的平均延迟 $L$ 可以建模为期望检测延迟与单位事件处理时间之和，即 $L = T_{p}/2 + s$，前提是系统稳定，从而排队影响可以忽略不计。\n- 设备每秒消耗的总 CPU 时间等于轮询开销与事件处理时间之和，即 $c/T_{p} + Ts$，其中 $T$ 是已处理事件的速率（吞吐量），单位为事件/秒。\n\n任务：\n\n1) 利用 CPU 预算约束，将最大可持续吞吐量 $T$ 表示为 $T_{p}$、$s$、$c$ 和 $U$ 的函数，假设系统在无积压（稳定状态）下运行。\n\n2) 对于一个给定的外部到达速率 $\\lambda$，系统必须在不超过 CPU 预算 $U$ 的情况下维持该速率。请确定能够最小化平均延迟 $L$ 的轮询周期 $T_{p}^{\\star}$，该周期需满足稳定性约束，即在遵守 CPU 预算的同时，设备的吞吐量至少为 $\\lambda$。请说明参数所需的任何可行性条件。\n\n请以 $c$、$s$、$\\lambda$ 和 $U$ 表示的 $T_{p}^{\\star}$ 的单一封闭形式表达式给出您的最终答案。最终答案中不要包含单位。如果在推导中使用了任何近似，请从第一性原理出发进行论证。无需进行数值计算。",
            "solution": "我们从陈述的基本原理出发，建立所需的关系。\n\nCPU 预算下的吞吐量：\n\n- 每次轮询消耗 $c$ 秒 CPU 时间，且每 $T_{p}$ 秒发生一次，因此每秒的轮询开销为 $c/T_{p}$。\n- 如果设备每秒处理 $T$ 个事件，每个事件需要 $s$ 秒 CPU 时间，那么事件处理每秒消耗 $Ts$ 秒 CPU 时间。\n- 在预算 $U$ 下，每秒分配给该设备的总 CPU 时间必须满足\n$$\n\\frac{c}{T_{p}} + Ts \\leq U.\n$$\n在此约束下求解最大可行吞吐量，我们得到\n$$\nT \\leq \\frac{U - \\frac{c}{T_{p}}}{s}.\n$$\n因此，作为 $T_{p}$ 函数的最大可持续吞吐量（容量）为\n$$\nT_{\\max}(T_{p}) = \\frac{U - \\frac{c}{T_{p}}}{s},\n$$\n条件是 $U - \\frac{c}{T_{p}} \\geq 0$，等价于 $T_{p} \\geq \\frac{c}{U}$。这就是任务1所要求的表达式。\n\n平均延迟：\n\n- 在具有独立到达的周期性轮询下，期望检测延迟为 $T_{p}/2$。\n- 单位事件服务时间为 $s$。\n- 在稳定状态下忽略排队效应（即，处理速率等于到达速率且不超过容量），平均延迟建模为\n$$\nL(T_{p}) = \\frac{T_{p}}{2} + s.\n$$\n\n维持速率 $\\lambda$ 的优化问题：\n\n- 为了稳定地维持外部到达速率 $\\lambda$，系统容量必须满足\n$$\nT_{\\max}(T_{p}) \\geq \\lambda \\quad \\Longleftrightarrow \\quad \\frac{U - \\frac{c}{T_{p}}}{s} \\geq \\lambda.\n$$\n这个不等式等价于\n$$\n\\frac{c}{T_{p}} \\leq U - \\lambda s,\n$$\n（当 $U - \\lambda s > 0$ 时）可重排为\n$$\nT_{p} \\geq \\frac{c}{U - \\lambda s}.\n$$\n条件 $U - \\lambda s > 0$ 是一个可行性要求：若不满足此条件，则无论如何选择 $T_{p}$，都无法提供足够的 CPU 时间来以速率 $\\lambda$ 处理事件。\n\n- 平均延迟 $L(T_{p}) = \\frac{T_{p}}{2} + s$ 是关于 $T_{p}$ 的严格递增函数，因此在约束条件 $T_{p} \\geq \\frac{c}{U - \\lambda s}$ 下最小化 $L$ 的目标，可以通过选择最小的可行 $T_{p}$ 来实现，即\n$$\nT_{p}^{\\star} = \\frac{c}{U - \\lambda s},\n$$\n在可行性条件 $U > \\lambda s$ 下。\n\n这个选择也自动满足了容量非负性的条件 $T_{p} \\geq \\frac{c}{U}$，因为 $\\lambda s \\geq 0$ 意味着 $U - \\lambda s \\leq U$，从而 $\\frac{c}{U - \\lambda s} \\geq \\frac{c}{U}$。\n\n总结：\n\n- 当 $T_{p} \\geq \\frac{c}{U}$ 时，作为 $T_{p}$ 函数的最大可持续吞吐量为 $T_{\\max}(T_{p}) = \\frac{U - \\frac{c}{T_{p}}}{s}$。\n- 在 CPU 预算 $U$ 内维持到达速率 $\\lambda$ 并最小化延迟的轮询周期为 $T_{p}^{\\star} = \\frac{c}{U - \\lambda s}$，条件是 $U > \\lambda s$。\n\n所要求的最终封闭形式表达式为 $T_{p}^{\\star} = \\frac{c}{U - \\lambda s}$。",
            "answer": "$$\\boxed{\\frac{c}{U - \\lambda s}}$$"
        },
        {
            "introduction": "除了宏观的性能权衡，编程I/O的轮询循环在微架构层面也存在“隐藏成本”。一个看似简单的循环会与CPU流水线中的分支预测器等高级特性发生交互。本练习通过建立一个概率模型，帮助我们计算当设备事件最终发生时，分支预测失败所导致的性能损失，从而将高级的I/O概念与底层的硬件执行效率联系起来。",
            "id": "3670472",
            "problem": "一个中央处理器 (CPU) 执行一个编程的输入/输出 (I/O) 轮询循环，该循环重复测试一个实现为内存映射状态位的设备就绪标志。该循环体仅由一条指令组成：一条条件后向分支指令，它在每次迭代中重新评估该标志，并在设备未就绪时向后分支。流水线中的分支预测器使用一种固定策略，即假定设备未就绪。当预测器出错时，流水线会产生 $c_{bm}$ 个周期的分支预测错误刷新惩罚。将设备就绪情况建模为跨迭代的一系列独立试验，其中在每次迭代中，设备就绪的概率为 $p$，未就绪的概率为 $1-p$。并假设当设备未就绪时，分支结果与预测器匹配；当设备就绪时，分支结果与预测器偏离。使用以下定义：每指令周期数 (CPI) 是总周期数除以总提交指令数，并且由离散事件引起的预期额外周期数等于该事件周期成本的期望值。\n\n从这些定义出发，推导该轮询循环中仅由分支预测错误引起的 CPI 膨胀 $\\Delta \\mathrm{CPI}$，并计算当 $p = 0.08$ 和 $c_{bm} = 17$ 时的数值。以每指令周期数表示你的最终答案，并四舍五入到四位有效数字。",
            "solution": "问题要求推导和计算在一个特定的编程 I/O 轮询循环中，由分支预测错误引起的每指令周期数 (CPI) 膨胀，记为 $\\Delta \\mathrm{CPI}$。\n\n首先，我们确立问题中给出的定义和关系。每指令周期数 (CPI) 定义为执行的总周期数与提交的总指令数之比：\n$$\n\\mathrm{CPI} = \\frac{\\text{Total Cycles}}{\\text{Total Instructions}}\n$$\n总周期数可以分解为一个基准部分 ($C_{base}$) 和一个惩罚部分 ($C_{penalty}$)。基准部分表示假设没有流水线停顿或刷新时执行的周期数，而惩罚部分表示由于分支预测错误等事件引起的额外周期数。\n$$\n\\text{Total Cycles} = C_{base} + C_{penalty}\n$$\n因此，CPI可以写成基准 CPI 和一个膨胀项 $\\Delta \\mathrm{CPI}$ 的和，该膨胀项代表了来自惩罚周期的贡献。\n$$\n\\mathrm{CPI} = \\frac{C_{base}}{\\text{Total Instructions}} + \\frac{C_{penalty}}{\\text{Total Instructions}} = \\mathrm{CPI}_{base} + \\Delta \\mathrm{CPI}\n$$\n问题要求的是仅由分支预测错误引起的 CPI 膨胀。这对应于以下项：\n$$\n\\Delta \\mathrm{CPI} = \\frac{C_{penalty}}{\\text{Total Instructions}}\n$$\n由于设备就绪是一个概率过程，我们必须使用期望值。CPI 膨胀是每条提交指令的预期惩罚周期数。\n$$\n\\Delta \\mathrm{CPI} = \\frac{E[C_{penalty}]}{\\text{Total Instructions}}\n$$\n问题指出，轮询循环由单条指令组成：一个条件后向分支。这意味着循环的每次迭代都只提交一条指令。因此，分析“每次迭代”等同于分析“每条指令”。\n\n让我们来确定每条指令的预期惩罚周期数。只有在发生分支预测错误时才会产生惩罚。\n分支预测器使用一种固定策略，总是假定设备未就绪。这意味着预测器总是预测分支将被采用（循环返回）。\n如果实际结果与预测不同，就会发生预测错误。分支结果取决于设备状态：\n\\begin{itemize}\n    \\item 如果设备未就绪（以概率 $1-p$ 发生），则条件分支被采用。预测（“未就绪”/分支采用）是正确的。\n    \\item 如果设备就绪（以概率 $p$ 发生），则分支不被采用，循环终止。预测（“未就绪”/分支采用）是错误的。\n\\end{itemize}\n因此，当且仅当设备就绪时，才会发生分支预测错误。在任何给定的迭代中（因此对于每条执行的分支指令），预测错误的概率是 $p$。\n\n单次分支预测错误的惩罚为 $c_{bm}$ 个周期。如果预测正确，惩罚为 $0$ 个周期。我们可以将单条指令的惩罚周期数建模为一个离散随机变量 $C_{penalty, instr}$，它以概率 $p$ 取值 $c_{bm}$，以概率 $1-p$ 取值 $0$。\n\n每条指令的预期额外周期数是该随机变量的期望值：\n$$\nE[C_{penalty, instr}] = (c_{bm} \\times p) + (0 \\times (1-p)) = p \\times c_{bm}\n$$\n这个期望值代表了在轮询循环中执行的每条指令所增加的平均惩罚周期数。根据定义，这就是由分支预测错误引起的 CPI 膨胀。\n$$\n\\Delta \\mathrm{CPI} = p \\times c_{bm}\n$$\n现在，我们将给定的数值代入这个表达式。我们已知：\n\\begin{itemize}\n    \\item 设备就绪的概率，$p = 0.08$。\n    \\item 分支预测错误惩罚，$c_{bm} = 17$ 个周期。\n\\end{itemize}\n代入这些值，我们计算 $\\Delta \\mathrm{CPI}$：\n$$\n\\Delta \\mathrm{CPI} = 0.08 \\times 17\n$$\n$$\n\\Delta \\mathrm{CPI} = 1.36\n$$\n问题要求答案四舍五入到四位有效数字。计算出的值 $1.36$ 有三位有效数字。为了用四位有效数字表示，我们在末尾追加一个零。\n$$\n\\Delta \\mathrm{CPI} = 1.360 \\text{ 每指令周期数}\n$$",
            "answer": "$$\\boxed{1.360}$$"
        },
        {
            "introduction": "在现代计算机系统中，CPU和像直接内存访问（DMA）控制器这样的外设会并发地访问内存。确保CPU在正确的时间以正确的顺序读取到DMA写入的数据，在弱内存排序模型下是一个重要且复杂的问题。本练习探讨了在CPU与DMA协作时保证数据一致性的关键，强调了为什么必须使用内存栅栏（memory fences）或获取-释放（acquire-release）语义等显式指令来保证程序的正确性。",
            "id": "3670422",
            "problem": "一个实现了弱序内存模型的单处理器系统中的中央处理器 (CPU) 通过轮询一个完成标志来进行程序化输入/输出 (I/O)，而此时一个直接内存访问 (DMA) 引擎正在传输数据。内存系统是缓存一致的：DMA 对物理内存的写入会传播到一致性点，并将使 CPU 缓存中的任何缓存副本无效或更新。考虑以下场景。\n\n一个 DMA 引擎在物理地址范围 $\\left[B, B + N - 1\\right]$ 写入一个连续缓冲区，然后将物理地址 $F$ 处的完成标志设置为值 $1$。该 DMA 引擎被编程为按程序顺序发出其写入：它对数据缓冲区执行一系列写入 $\\{W_d(i)\\}$，随后是一次将 $1$ 存入 $F$ 的写入 $W_f$。互连总线会保持 DMA 引擎的程序顺序，即在所有之前的写入 $\\{W_d(i)\\}$ 到达一致性点之前，$W_f$ 不会对其他代理可见。CPU 轮询 $F$，在观察到 $F = 1$ 后，读取缓冲区 $\\left[B, B + N - 1\\right]$。\n\n设相关的抽象操作为：\n- 对于 DMA：数据写入 $W_d(0), W_d(1), \\ldots, W_d(k)$，随后是标志写入 $W_f$（将 $1$ 存入 $F$）。\n- 对于 CPU：在一个轮询循环中重复进行标志加载 $L_f$，直到 $L_f$ 返回 $1$，然后从 $\\left[B, B + N - 1\\right]$ 进行数据加载 $L_b(j)$。\n\n假设：\n- 缓存一致性结构为每个位置提供单写多读一致性，并且从特定写入返回的读取意味着该写入对读取者可见。\n- 在没有显式排序指令的情况下，CPU 可能会重排加载与其他加载的顺序，以及加载与更早加载的顺序。\n- CPU 不执行任何显式缓存维护操作。\n\n问题：哪些 CPU 侧的排序原语足以保证，在轮询循环观察到 $F = 1$ 后，所有后续对缓冲区的 CPU 读取 $L_b(j)$ 都能观察到由 DMA 写入 $W_d(i)$ 所写的值，即为所有 $i, j$ 建立一个可靠的顺序 $$W_d(i) \\rightarrow W_f \\rightarrow L_f \\rightarrow L_b(j) \\text{ for all } i, j?$$ 选择所有适用的选项。\n\nA. 在轮询循环中使用 acquire 语义读取标志 $F$（对 $F$ 进行 load-acquire），或者等效地，在 $L_f$ 返回 $1$ 的那次迭代之后、任何 $L_b(j)$ 之前，立即执行一个读内存屏障，且无其他栅栏。假设 DMA 仅在所有 $W_d(i)$ 在一致性点可见之后才发出 $W_f$。\n\nB. 在进入轮询循环前执行一次完整内存屏障；此后对标志和缓冲区都使用 relaxed 加载。\n\nC. 仅依赖缓存一致性以及 DMA 最后写入标志这一事实；将所有 CPU 加载都作为无栅栏的 relaxed 加载来执行。\n\nD. 当 CPU 稍后为了重用而通过向 $F$ 写入 $0$ 来清除标志时，在那时对 $F$ 使用 store-release；在读取 $F$ 的操作周围不需要排序。\n\nE. 在轮询循环观察到 $F = 1$ 后，在任何 $L_b(j)$ 之前执行一个完整内存屏障，然后使用 relaxed 加载读取缓冲区。",
            "solution": "### 问题陈述的验证\n\n**步骤 1：提取已知条件**\n-   系统：具有弱序内存模型的单处理器 CPU。\n-   I/O：对完成标志进行程序化 I/O（轮询）。\n-   数据传输：一个直接内存访问 (DMA) 引擎。\n-   内存系统：缓存一致的。DMA 对物理内存的写入会传播到一致性点，并使 CPU 缓存副本无效或更新。\n-   DMA 操作：\n    1.  向物理地址范围 $[B, B + N - 1]$ 的连续缓冲区写入。这些写入表示为 $\\{W_d(i)\\}$。\n    2.  将物理地址 $F$ 处的完成标志设置为值 $1$。这次写入表示为 $W_f$。\n-   DMA 顺序：DMA 按程序顺序发出写入：$\\{W_d(i)\\}$ 后跟 $W_f$。\n-   互连行为：在所有先前的写入 $\\{W_d(i)\\}$ 到达一致性点之前，$W_f$ 不会对其他代理可见。这有效地为所有 $i$ 建立了顺序 $W_d(i) \\rightarrow W_f$。\n-   CPU 操作：\n    1.  在一个轮询循环中重复从地址 $F$ 加载。这些加载表示为 $L_f$。\n    2.  当一个加载 $L_f$ 返回值 $1$ 时，循环终止。\n    3.  循环之后，CPU 读取 $[B, B + N - 1]$ 处的缓冲区。这些加载表示为 $L_b(j)$。\n-   假设：\n    1.  缓存一致性提供单写多读一致性。从特定写入返回的读取意味着该写入可见。\n    2.  在没有显式排序指令的情况下，CPU 可能会重排加载与其他加载的顺序，以及加载与更早加载的顺序。\n    3.  CPU 不执行任何显式缓存维护操作。\n-   问题：哪些 CPU 侧的排序原语足以保证顺序 $W_d(i) \\rightarrow W_f \\rightarrow L_f \\rightarrow L_b(j)$ 对所有相关的 $i, j$ 成立？\n\n**步骤 2：使用提取的已知条件进行验证**\n问题陈述描述了一个经典的生产者-消费者同步问题，涉及在一个具有弱序内存模型的系统上，DMA 引擎（生产者）和 CPU（消费者）之间的同步。\n-   **科学依据：**该问题坚实地基于计算机体系结构的既定原则，包括内存一致性模型（弱序）、缓存一致性、DMA 和同步原语（内存屏障、acquire/release 语义）。这些是该领域的基础主题。\n-   **定义良好：**该问题定义明确。它指定了生产者 (DMA) 和消费者 (CPU) 的行为和能力、内存子系统的属性以及一个明确的目标：确保 CPU 正确观察到 DMA 写入的数据。问题要求找出在 CPU 侧实现这一目标所需的充分条件。\n-   **客观性：**语言技术性强、精确且无歧义。像“弱序内存模型”、“缓存一致的”、“acquire 语义”和“内存屏障”等术语在计算机科学中都有标准的、正式的定义。\n-   **完整性和一致性：**问题提供了所有必要的信息。DMA 的标志写入 $W_f$ 在所有数据写入 $W_d(i)$ 全局可见之前不可见的保证是关键信息，它模拟了生产者侧的“release 序列”。CPU 重排加载的能力是需要解决的核心挑战。没有矛盾之处。\n\n**步骤 3：结论与行动**\n问题陈述是有效的。这是一个在计算机体系结构领域中定义良好、科学合理且清晰的问题。我将继续推导解决方案。\n\n### 解决方案的推导\n\n问题要求建立一个事件的因果链，以确保 CPU 读取正确的数据。期望的顺序是 $W_d(i) \\rightarrow W_f \\rightarrow L_f \\rightarrow L_b(j)$。让我们逐一分析这个链条的每个环节。\n\n1.  **$W_d(i) \\rightarrow W_f$ (生产者侧排序)：** 问题陈述保证了这一点。它声明，“互连总线会保持 DMA 引擎的程序顺序，即在所有之前的写入 $\\{W_d(i)\\}$ 到达一致性点之前，$W_f$ 不会对其他代理可见。” 这意味着生产者的操作是正确排序的。用内存模型的术语来说，对标志的写入 $W_f$ 起到了“release”操作的作用，确保所有之前的内存操作（数据写入 $W_d(i)$）在 release 操作本身变得可见之前都已完成并可见。\n\n2.  **$W_f \\rightarrow L_f$ (同步)：** CPU 轮询地址 $F$ 处的标志。当其加载操作 $L_f$ 返回由 $W_f$ 写入的值 $1$ 时，缓存一致性协议保证了写入 $W_f$ 已经完成并且对 CPU 可见。这建立了从生产者到消费者的交接。\n\n3.  **$L_f \\rightarrow L_b(j)$ (消费者侧排序)：** 这是问题的核心。CPU 具有弱序内存模型，可以重排加载与其他加载的顺序。在 CPU 的程序中：\n    ```\n    loop:\n      val = Load(F)\n      if val == 0 goto loop\n    // Exit loop\n    data = Load(B+j)\n    ```\n    CPU 可能会在从标志 $F$ 的加载 $L_f$ 明确返回值为 $1$ *之前*，推测性地执行从缓冲区的加载 $L_b(j)$。如果发生这种重排，$L_b(j)$ 可能会读取到缓冲区中的过时数据，从而打破因果链。为防止这种情况，CPU 侧需要一个显式的排序原语。该原语必须阻止后续的内存操作（如 $L_b(j)$）被重排到观察到标志变化的关键加载 $L_f$ 之前执行。这就是 **acquire** 操作的定义。\n\n一个 acquire 操作确保所有在程序顺序中出现在它*之后*的内存操作都将在 acquire 操作完成*之后*执行。这与生产者的 release 操作配对。release 保证了之前的写入是可见的；acquire 保证了在执行任何后续操作之前，这种可见性已经建立。\n\n因此，CPU 必须在看到 $F=1$ 之后、读取缓冲区之前执行一个 acquire 操作。这可以通过两种主要方式实现：\n-   使用具有 acquire 语义的加载（`load-acquire`）来读取标志 $F$。\n-   使用常规（relaxed）加载来读取标志 $F$，然后在退出循环后，执行一个 acquire fence（也称为读内存屏障，或更强的，完整内存屏障）。\n\n### 选项评估\n\n**A. 在轮询循环中使用 acquire 语义读取标志 $F$（对 $F$ 进行 load-acquire），或者等效地，在 $L_f$ 返回 $1$ 的那次迭代之后、任何 $L_b(j)$ 之前，立即执行一个读内存屏障，且无其他栅栏。假设 DMA 仅在所有 $W_d(i)$ 在一致性点可见之后才发出 $W_f$。**\n\n此选项提出了两种方法，两者都实现了必要的 acquire 语义。\n-   **对 $F$ 进行 `load-acquire`**：对 $F$ 执行 `load-acquire` 确保任何后续的内存操作，包括缓冲区加载 $L_b(j)$，不能被重排到此加载之前发生。这正确地强制了 $L_f \\rightarrow L_b(j)$ 的顺序。\n-   **读内存屏障**：在循环之后（即在 $L_f$ 返回 $1$ 之后）和缓冲区加载 $L_b(j)$ 之前放置一个读内存屏障（一个 acquire fence），也强制了所需的顺序。该屏障阻止了后续加载相对于先前加载的重排。\n两种方法都正确地建立了与生产者的 release 类行为配对所需的消费者侧排序。\n**结论：正确。**\n\n**B. 在进入轮询循环前执行一次完整内存屏障；此后对标志和缓冲区都使用 relaxed 加载。**\n\n内存屏障对其在程序流中出现位置之前的操作与之后的操作进行排序。将屏障放在轮询循环*之前*，并不能阻止屏障*之后*的代码内部操作的重排。弱序 CPU 仍然可以自由地将来自缓冲区的 relaxed 加载 $L_b(j)$ 重排到来自标志的 relaxed 加载 $L_f$ 之前执行。屏障的位置不正确，无法强制 $L_f \\rightarrow L_b(j)$ 的顺序。\n**结论：不正确。**\n\n**C. 仅依赖缓存一致性以及 DMA 最后写入标志这一事实；将所有 CPU 加载都作为无栅栏的 relaxed 加载来执行。**\n\n这是在弱序系统上会失败的天真方法。缓存一致性保证写入最终会被传播，并且读取会看到一个一致的值，但它并不对*不同*内存位置（如 $F$ 和 $B$）的读取施加顺序。问题明确指出“CPU 可能会重排加载与其他加载的顺序”。没有栅栏或 acquire 语义，加载 $L_b(j)$ 可能会被重排到最后的 $L_f$ 之前，导致读取到过时的数据。\n**结论：不正确。**\n\n**D. 当 CPU 稍后为了重用而通过向 $F$ 写入 $0$ 来清除标志时，在那时对 $F$ 使用 store-release；在读取 $F$ 的操作周围不需要排序。**\n\n这个选项涉及一个在关键数据读取发生*很久之后*才发生的操作（清除标志）。`store-release` 会对存储操作*之前*的内存操作与存储操作本身进行排序。它对先前的加载（$L_f$ 和 $L_b(j)$）的顺序没有影响。排序问题必须在读取时解决，而不是通过一个后续不相关的写入来追溯解决。\n**结论：不正确。**\n\n**E. 在轮询循环观察到 $F = 1$ 后，在任何 $L_b(j)$ 之前执行一个完整内存屏障，然后使用 relaxed 加载读取缓冲区。**\n\n完整内存屏障是最强的排序原语。它阻止任何先前的内存操作与任何后续的内存操作发生重排。通过将其放置在轮询循环之后（在 $L_f$ 返回 $1$ 之后）和缓冲区读取（$L_b(j)$）之前，它强制所有 $L_b(j)$ 必须在 $L_f$ 之后发生。这提供了 acquire 语义（防止后续操作上移）以及 release 语义（防止先前操作下移）。这里需要的是 acquire 语义，所以完整屏障是足够的。这是一个正确但可能比必要更强的解决方案。\n**结论：正确。**",
            "answer": "$$\\boxed{AE}$$"
        }
    ]
}