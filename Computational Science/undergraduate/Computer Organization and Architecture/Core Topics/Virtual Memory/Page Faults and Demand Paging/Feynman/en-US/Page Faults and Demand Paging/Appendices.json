{
    "hands_on_practices": [
        {
            "introduction": "The most critical question in demand paging is: how much do page faults slow down the system? This exercise introduces the Effective Access Time ($EAT$), a fundamental model used to quantify this performance penalty. By working through this problem, you will learn to relate the average memory access time to the page fault rate and the time it takes to service a fault, giving you a powerful tool for performance analysis. ",
            "id": "3663138",
            "problem": "A computer system implements demand paging in its virtual memory subsystem. Consider a single memory reference by a running process. Either the referenced page is resident and the reference completes in main memory, or the reference triggers a page fault and must be serviced by the operating system and the backing store before completion. Assume the following are true:\n\n- The probability that a reference triggers a page fault is $p$ (constant across references and independent).\n- If the reference does not trigger a page fault, the time to complete the reference is $t_{m}$.\n- If the reference triggers a page fault, the time from the start of the reference to completion (including operating system handling, backing-store transfer, and instruction restart) is $t_{pf}$.\n- The average time to complete a reference over many references, known as the Effective Access Time (EAT), is denoted by $L$.\n\nEngineers require that the average performance meets a target Effective Access Time of $L = 300 \\,\\mathrm{ns}$. The system’s main-memory access time is $t_{m} = 100 \\,\\mathrm{ns}$, and the measured page-fault service time is $t_{pf} = 5.0 \\,\\mathrm{ms}$.\n\nStarting from the definition of expected value for a Bernoulli outcome and the above scenario constraints, derive an expression that relates $L$, $t_{m}$, $t_{pf}$, and $p$. Then solve symbolically for $p$ in terms of $L$, $t_{m}$, and $t_{pf}$, and compute the numerical value of $p$ for the given parameters. Finally, determine the bounds on $L$ that make the derived $p$ feasible (i.e., $0 \\leq p \\leq 1$) and explain the result qualitatively. Express the numerical value of $p$ as a unitless decimal and round your answer to four significant figures.",
            "solution": "The problem statement has been evaluated and is deemed valid. It is scientifically grounded in the principles of computer architecture and probability theory, well-posed with a clear objective, and internally consistent. We may proceed with the solution.\n\nThe problem asks for the derivation of an expression for the Effective Access Time ($L$), the symbolic solution for the page fault probability ($p$), the numerical value of $p$ for the given parameters, and an analysis of the feasible bounds on $L$.\n\nFirst, we derive the expression for the Effective Access Time, $L$. A memory reference is a stochastic event with two possible outcomes:\n1.  The reference does not trigger a page fault. This occurs with probability $1-p$. The time to complete the reference is the main memory access time, $t_m$.\n2.  The reference triggers a page fault. This occurs with probability $p$. The time to service the fault and complete the reference is $t_{pf}$.\n\nThe Effective Access Time ($L$) is defined as the expected value of the time for a memory reference. For a discrete random variable, the expected value is the sum of the value of each outcome multiplied by its probability of occurrence. Therefore, $L$ is given by:\n$$L = (1-p) \\cdot t_m + p \\cdot t_{pf}$$\n\nThis equation relates the four quantities $L$, $t_m$, $t_{pf}$, and $p$.\n\nNext, we solve this expression symbolically for $p$. We perform algebraic manipulation on the derived equation:\n$$L = t_m - p \\cdot t_m + p \\cdot t_{pf}$$\nTo isolate $p$, we rearrange the terms:\n$$L - t_m = p \\cdot (t_{pf} - t_m)$$\nAssuming $t_{pf} \\neq t_m$ (which is a physical necessity, as servicing a page fault is orders of magnitude slower than a memory access, so $t_{pf} > t_m$), we can divide by $(t_{pf} - t_m)$:\n$$p = \\frac{L - t_m}{t_{pf} - t_m}$$\nThis is the symbolic expression for the page fault probability $p$.\n\nNow, we compute the numerical value of $p$ using the given parameters:\n- Target Effective Access Time, $L = 300 \\,\\mathrm{ns}$\n- Main-memory access time, $t_m = 100 \\,\\mathrm{ns}$\n- Page-fault service time, $t_{pf} = 5.0 \\,\\mathrm{ms}$\n\nBefore substituting these values, we must ensure they are in consistent units. We will convert all times to nanoseconds ($ns$), noting that $1 \\,\\mathrm{ms} = 10^6 \\,\\mathrm{ns}$.\n$$t_{pf} = 5.0 \\,\\mathrm{ms} = 5.0 \\times 10^6 \\,\\mathrm{ns}$$\nSubstituting the numerical values into the expression for $p$:\n$$p = \\frac{300\\,\\mathrm{ns} - 100\\,\\mathrm{ns}}{5.0 \\times 10^6\\,\\mathrm{ns} - 100\\,\\mathrm{ns}}$$\n$$p = \\frac{200}{4999900}$$\n$$p = \\frac{2}{49999}$$\nAs a decimal value, this is:\n$$p \\approx 0.0000400008...$$\nThe problem requires rounding to four significant figures. The first significant figure is $4$. The next three significant figures are $0$, $0$, and $0$. The fifth significant digit is $0$, so we do not round up.\n$$p \\approx 0.00004000$$\n\nFinally, we determine the bounds on $L$ that make the derived probability $p$ feasible. A probability must lie in the range $0 \\leq p \\leq 1$. Using our symbolic expression for $p$:\n$$0 \\leq \\frac{L - t_m}{t_{pf} - t_m} \\leq 1$$\nAs established, $t_{pf} > t_m$, so the denominator $(t_{pf} - t_m)$ is a positive quantity. We can multiply through the inequality by this term without changing the direction of the inequality signs.\n\nThe lower bound is found from $0 \\leq \\frac{L - t_m}{t_{pf} - t_m}$:\n$$0 \\leq L - t_m$$\n$$t_m \\leq L$$\n\nThe upper bound is found from $\\frac{L - t_m}{t_{pf} - t_m} \\leq 1$:\n$$L - t_m \\leq t_{pf} - t_m$$\n$$L \\leq t_{pf}$$\n\nCombining these results, the feasible range for the Effective Access Time $L$ is:\n$$t_m \\leq L \\leq t_{pf}$$\n\nQualitatively, this result is entirely logical. The Effective Access Time, $L$, is a weighted average of the fastest possible access time ($t_m$) and the slowest possible access time ($t_{pf}$). By definition, an average of a set of values cannot be smaller than the minimum value in the set or larger than the maximum value.\n- If $L = t_m$, the system achieves the fastest possible performance. This can only happen if page faults never occur, which corresponds to $p = \\frac{t_m - t_m}{t_{pf} - t_m} = 0$.\n- If $L = t_{pf}$, the system exhibits the slowest possible performance. This occurs if every memory reference results in a page fault, corresponding to $p = \\frac{t_{pf} - t_m}{t_{pf} - t_m} = 1$.\nAny $L$ outside this range $[t_m, t_{pf}]$ would imply a value of $p$ less than $0$ or greater than $1$, which is physically and mathematically impossible for a probability.\nFor the given parameters, the bounds are $100\\,\\mathrm{ns} \\leq L \\leq 5.0 \\times 10^6\\,\\mathrm{ns}$. The target $L = 300\\,\\mathrm{ns}$ is within this valid range.",
            "answer": "$$\\boxed{0.00004000}$$"
        },
        {
            "introduction": "Not all page faults are equally costly. This practice delves into the page fault service time by examining the crucial difference between evicting a \"clean\" page versus a \"dirty\" page that has been modified. You will model the expected time cost of page eviction, a key component of the overall page fault penalty, by incorporating the probability of a page being dirty and the bandwidth of the backing store. ",
            "id": "3663206",
            "problem": "A computer system uses demand paging with a write-back cache under memory pressure. When a page frame must be evicted, the Operating System (OS) checks whether the page is dirty. Assume the following modeling assumptions grounded in standard definitions of demand paging and write-back policies:\n\n- A page is dirty at eviction with long-run fraction $w$.\n- If the page is dirty, it must be written to the backing store via a page-out data path that sustains a constant sequential bandwidth $B$.\n- If the page is clean, no write to the backing store is performed and any metadata overhead is negligible compared to data transfer time.\n- The page size is $S$ bytes.\n- Ignore queueing and fixed-latency effects; treat the transfer time for a dirty eviction as the time to transmit $S$ bytes at bandwidth $B$.\n\nStarting from the definition of expected value for a Bernoulli outcome (dirty versus clean), derive the expected time per eviction and compute its value for $w = 0.37$, $S = 16\\,\\mathrm{KiB}$, and $B = 800\\,\\mathrm{MiB/s}$. Express the final time in microseconds and round your answer to four significant figures.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective. The problem statement describes a simplified but standard model of page eviction in a demand-paged memory system. The concepts of a dirty page, write-back, backing store, page size, and I/O bandwidth are all fundamental and correctly used within the context of computer architecture. The provided values for the parameters are physically plausible. The objective is clearly stated: to derive an expression for the expected eviction time and compute its numerical value under given conditions. The problem is therefore deemed valid.\n\nThe solution proceeds by first deriving the symbolic expression for the expected eviction time and then substituting the given numerical values.\n\nLet $T$ be the random variable representing the time required for a single page eviction. The problem specifies two possible outcomes for an eviction, based on whether the page is dirty or clean.\n\n1.  **Page is dirty**: This event occurs with a given probability $w$. If the page is dirty, it must be written to the backing store. The time required for this operation, $T_{dirty}$, is the time to transfer the page data of size $S$ at a constant bandwidth $B$. Queueing and latency effects are explicitly ignored. Thus,\n    $$T_{dirty} = \\frac{S}{B}$$\n2.  **Page is clean**: This event occurs with probability $1 - w$. If the page is clean, no write to the backing store is performed, and any associated overhead is considered negligible. Therefore, the time taken in this case, $T_{clean}$, is zero.\n    $$T_{clean} = 0$$\n\nThe expected value of a discrete random variable is the sum of the value of each outcome multiplied by its probability of occurrence. Applying this definition to the eviction time $T$, we get the expected eviction time, $E[T]$:\n$$E[T] = T_{dirty} \\cdot P(\\text{page is dirty}) + T_{clean} \\cdot P(\\text{page is clean})$$\nSubstituting the expressions for the times and probabilities:\n$$E[T] = \\left(\\frac{S}{B}\\right) \\cdot w + (0) \\cdot (1 - w)$$\nThis simplifies to the symbolic expression for the expected time per eviction:\n$$E[T] = w \\frac{S}{B}$$\n\nNow, we substitute the provided numerical values into this expression:\n-   Long-run fraction of dirty pages, $w = 0.37$\n-   Page size, $S = 16\\,\\mathrm{KiB}$\n-   Backing store bandwidth, $B = 800\\,\\mathrm{MiB/s}$\n\nBefore performing the calculation, we must convert the units to a consistent base. We will use bytes for size and bytes per second for bandwidth. Note that KiB (kibibyte) and MiB (mebibyte) are binary prefixes:\n-   $1\\,\\mathrm{KiB} = 2^{10}\\,\\text{bytes} = 1024\\,\\text{bytes}$\n-   $1\\,\\mathrm{MiB} = 2^{20}\\,\\text{bytes} = 1048576\\,\\text{bytes}$\n\nSo, the given parameters in base units are:\n-   $S = 16 \\times 2^{10}\\,\\text{bytes}$\n-   $B = 800 \\times 2^{20}\\,\\text{bytes/s}$\n\nSubstituting these into the expression for $E[T]$:\n$$E[T] = 0.37 \\times \\frac{16 \\times 2^{10}\\,\\text{bytes}}{800 \\times 2^{20}\\,\\text{bytes/s}}$$\nThe resulting unit is seconds (s). We can simplify the expression:\n$$E[T] = 0.37 \\times \\frac{16}{800 \\times 2^{10}}\\,\\text{s}$$\n$$E[T] = 0.37 \\times \\frac{16}{800 \\times 1024}\\,\\text{s}$$\n$$E[T] = 0.37 \\times \\frac{16}{819200}\\,\\text{s}$$\n$$E[T] = 0.37 \\times \\frac{1}{51200}\\,\\text{s}$$\n$$E[T] = \\frac{0.37}{51200}\\,\\text{s} \\approx 7.2265625 \\times 10^{-6}\\,\\text{s}$$\n\nThe problem requires the final answer to be expressed in microseconds ($\\mu$s). Since $1\\,\\text{s} = 10^6\\,\\mu$s:\n$$E[T] = (7.2265625 \\times 10^{-6}) \\times 10^6\\,\\mu\\text{s}$$\n$$E[T] = 7.2265625\\,\\mu\\text{s}$$\n\nFinally, the problem requires rounding the answer to four significant figures. The first four significant figures are $7, 2, 2, 6$. The fifth digit is $5$, which requires rounding up the preceding digit.\n$$E[T] \\approx 7.227\\,\\mu\\text{s}$$",
            "answer": "$$\\boxed{7.227}$$"
        },
        {
            "introduction": "The page fault rate is not a fixed constant; it is determined by the program's memory access pattern and the OS's page replacement algorithm. This comprehensive programming exercise challenges you to implement two key replacement policies—the ideal Least Recently Used (LRU) and a practical approximation, Aging—from first principles. By simulating their behavior on a given reference string, you will gain a deep, practical understanding of how these algorithms function and directly impact system performance. ",
            "id": "3663131",
            "problem": "You are to write a complete program that simulates demand paging under two page replacement policies for a given finite sequence of virtual page references: (i) the Least Recently Used (LRU) policy and (ii) the aging policy that approximates LRU by periodically sampling reference bits into per-page counters. The task is to compute, for each test case, the total number of page faults under each policy and aggregate the results in a single line.\n\nThe fundamental base for this problem consists of the following accepted facts and definitions:\n- A page fault occurs when a process references a virtual page that is not resident in any physical frame; the operating system then loads the referenced page into a frame, potentially evicting another page if all frames are full. Replace decisions do not alter the definition of a page fault, which arises from the absence of a referenced page in memory at the time of reference.\n- Demand paging loads a page into memory when and only when it is referenced.\n- The Least Recently Used (LRU) policy evicts the resident page whose most recent use lies farthest in the past.\n- The aging approximation to LRU maintains, for each resident page, a $w$-bit unsigned counter and a one-bit reference bit. A periodic event, which we call an epoch and denote by $\\epsilon$, occurs after exactly $E$ processed references (that is, after each block of $E$ references). At the end of each epoch, every resident page updates its counter and clears its reference bit. This approximates recency by exponentially decaying the counters while injecting the latest reference information.\n\nYour program must implement both policies from first principles as follows.\n\nShared setup for both policies:\n- Physical memory has $F \\ge 1$ frames.\n- The reference string is a finite sequence of nonnegative integers, each integer being a virtual page number.\n- All frames are empty at time $t=1$ (before the first reference). All per-page data structures (such as counters and reference bits) are initialized to $0$ for pages not in memory.\n- Each processed reference increments the processed-reference count by $1$, used to determine epoch boundaries for the aging policy.\n\nLRU policy:\n- On a reference to page $p$ at time $t$:\n  - If $p$ is resident, update its last-used time to $t$ (hit).\n  - If $p$ is not resident (page fault):\n    - If there is a free frame, load $p$ into it and record its last-used time as $t$.\n    - Otherwise, evict the resident page with the smallest last-used time (the least recently used). If there is a tie, evict the page with the smallest page number. Then load $p$ and set its last-used time to $t$.\n  - Count one page fault exactly when $p$ was not resident at the moment of reference.\n\nAging policy:\n- Parameters: epoch length $E \\in \\mathbb{N}$ and counter width $w \\in \\mathbb{N}$ with $w \\ge 1$.\n- Per resident page, maintain:\n  - A one-bit reference bit $r \\in \\{0,1\\}$.\n  - A $w$-bit unsigned counter $c \\in \\{0,1,\\dots,2^w-1\\}$.\n- On a reference to page $p$ at time $t$:\n  - If $p$ is resident, set $r \\leftarrow 1$ for $p$ (hit).\n  - If $p$ is not resident (page fault):\n    - If there is a free frame, load $p$ into it with $c \\leftarrow 0$ and $r \\leftarrow 1$.\n    - Otherwise, choose a victim among resident pages by minimizing $c$; if multiple pages have the same minimal $c$, choose the one with the smallest page number. Evict the chosen victim, then load $p$ with $c \\leftarrow 0$ and $r \\leftarrow 1$.\n  - After handling the reference (including any eviction and load), if the processed-reference count is a multiple of $E$, then an epoch ends and the following update is applied to each resident page independently:\n    - Let $\\text{msb} = 2^{w-1}$. Replace $c$ by $c' = \\left\\lfloor \\frac{c}{2} \\right\\rfloor + r \\cdot \\text{msb}$ (this is a logical right shift by one and insertion of $r$ into the most significant bit), and then set $r \\leftarrow 0$. Only resident pages are updated.\n- Count one page fault exactly when $p$ was not resident at the moment of reference. Note carefully the event order: replacement decisions for the current reference are made using the current $c$ and $r$ values before the epoch update; if the current reference completes an epoch (the total processed-reference count becomes a multiple of $E$), the update is performed after this reference is fully handled.\n\nImplement both policies faithfully with the specified tie-breaking to ensure determinism.\n\nTest suite:\nYour program must compute page faults under both policies for the following four test cases. In each case, pages are listed in order of reference from time $t=1$ to time $t=N$.\n1. Case A (general mixed locality):\n   - Frames $F=3$, epoch length $E=4$, counter width $w=8$.\n   - Reference string $\\langle 0,1,2,3,2,1,0,3,2,1,0,3 \\rangle$.\n2. Case B (fine-grained sampling approximating LRU):\n   - Frames $F=2$, epoch length $E=1$, counter width $w=8$.\n   - Reference string $\\langle 1,2,1,2,1,2,3 \\rangle$.\n3. Case C (very coarse sampling, long epoch):\n   - Frames $F=3$, epoch length $E=100$, counter width $w=8$.\n   - Reference string $\\langle 1,2,3,4,1,2,3,4 \\rangle$.\n4. Case D (single-frame boundary condition):\n   - Frames $F=1$, epoch length $E=3$, counter width $w=8$.\n   - Reference string $\\langle 1,2,3,4,1,2,3,4 \\rangle$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of pairs, enclosed in square brackets, where each pair is itself a bracketed list $[x,y]$ with $x$ equal to the total number of page faults under the aging policy and $y$ equal to the total number of page faults under the LRU policy, in the same order as the test cases above.\n- For example, the output must have the exact shape \"[[a1,b1],[a2,b2],[a3,b3],[a4,b4]]\" with no spaces and no additional text.\n\nAll numbers involved are pure counts; there are no physical units. Angles are not involved. Fractions or percentages are not involved. The only valid outputs are integers, and the final result must follow the formatting rule above.",
            "solution": "The problem requires the simulation of two page replacement algorithms, Least Recently Used (LRU) and an aging-based approximation, to determine the number of page faults for a given set of memory reference strings. The problem is well-defined, with explicit rules for state initialization, hit/fault handling, eviction, and tie-breaking, ensuring a deterministic and verifiable outcome.\n\n### Core Concepts\n\n**Demand Paging**: A memory management technique where pages are loaded from secondary storage into physical memory only when they are referenced. A reference to a page not in memory triggers a **page fault**, an exception handled by the operating system to load the required page.\n\n**Page Replacement Policy**: When a page fault occurs and all physical memory frames are occupied, a replacement policy decides which resident page to evict (the victim) to make space for the new page. The goal is to minimize page faults by evicting pages that are least likely to be used in the near future.\n\n### Algorithm Implementation from First Principles\n\nOur simulation environment for each test case consists of $F$ physical frames, initially empty. We process a reference string $\\langle p_1, p_2, \\dots, p_N \\rangle$ sequentially.\n\n#### 1. Least Recently Used (LRU) Policy\n\nThe LRU policy is based on the principle of temporal locality: if a page has been used recently, it is likely to be used again soon. Conversely, a page that has not been used for a long time is a good candidate for eviction.\n\n**State Management**: For each resident page, we must track when it was last accessed. We use a time counter, $t$, which increments with each reference, starting from $t=1$. Each frame in memory stores the page number and the time $t$ of its last reference.\n\n**Simulation Steps**: For each reference to page $p$ at time $t$:\n1.  **Search**: We search the $F$ frames for page $p$.\n2.  **Hit**: If $p$ is found in a frame, it is a memory hit. We update the last-used time for this frame to the current time $t$. No page fault occurs.\n3.  **Fault**: If $p$ is not found, a page fault occurs. We increment the fault count.\n    *   **Free Frame Available**: If there is an empty frame, we load page $p$ into it. We record its page number and set its last-used time to $t$.\n    *   **No Free Frames**: All frames are full. We must evict a victim page. According to the LRU policy, the victim is the page with the minimum last-used time.\n        *   **Tie-Breaking**: If multiple pages share the same minimum last-used time, the problem specifies that the one with the smallest page number must be evicted.\n    *   After eviction, we load page $p$ into the newly freed frame, setting its last-used time to $t$.\n\n#### 2. Aging Policy (LRU Approximation)\n\nThe aging policy approximates LRU without needing to store a timestamp for every memory access. It uses a finite-bit counter to estimate how recently a page has been used.\n\n**State Management**: For each resident page, we maintain two pieces of state:\n*   A $w$-bit unsigned integer counter, $c$.\n*   A $1$-bit reference flag, $r$.\n\nThe simulation proceeds in **epochs**. An epoch is a fixed interval of $E$ memory references.\n\n**Simulation Steps**: For each reference to page $p$:\n1.  **Search**: We search the $F$ frames for page $p$.\n2.  **Hit**: If $p$ is found, it is a hit. We set the reference bit for its frame to $r \\leftarrow 1$.\n3.  **Fault**: If $p$ is not found, a page fault occurs. We increment the fault count.\n    *   **Free Frame Available**: If there is an empty frame, we load page $p$ into it. We initialize its state to counter $c \\leftarrow 0$ and reference bit $r \\leftarrow 1$.\n    *   **No Free Frames**: We must select a victim. The victim is the page with the smallest counter value $c$. This page is heuristically considered the \"least recently used\".\n        *   **Tie-Breaking**: If multiple pages share the same minimum counter value, the one with the smallest page number is chosen for eviction.\n    *   After eviction, we load page $p$ into the freed frame, initializing its state to $c \\leftarrow 0$ and $r \\leftarrow 1$.\n4.  **Epoch Update**: After the reference (and any resulting fault handling) is fully processed, we check if the total number of processed references is a multiple of the epoch length $E$. If so, the following update is applied to **every resident page**:\n    *   The counter $c$ is shifted one bit to the right (an integer division by $2$).\n    *   The reference bit $r$ is moved into the most significant bit (MSB) of the counter.\n    *   The reference bit $r$ is cleared to $0$.\n    *   The update rule is formally: $c_{new} = \\lfloor \\frac{c_{old}}{2} \\rfloor + r_{old} \\cdot 2^{w-1}$. Then, $r_{new} \\leftarrow 0$.\n\nThis mechanism gives precedence to recently referenced pages. A page with $r=1$ during an epoch update will have a large value added to its counter, marking it as \"recently used.\" Counters of unreferenced pages gradually decay towards $0$ through repeated right-shifts, making them candidates for future eviction.\n\n### Calculation for Test Cases\n\nFollowing these precise rules, we simulate both algorithms for each given test case to find the total page faults. The detailed step-by-step traces confirm the following results:\n*   **Case A**: `F=3, E=4`, String: $\\langle 0,1,2,3,2,1,0,3,2,1,0,3 \\rangle$. Aging results in 7 faults. LRU results in 10 faults.\n*   **Case B**: `F=2, E=1`, String: $\\langle 1,2,1,2,1,2,3 \\rangle$. Aging results in 3 faults. LRU results in 3 faults. The frequent epoch updates allow the aging algorithm to closely track recency, matching the performance of ideal LRU.\n*   **Case C**: `F=3, E=100`, String: $\\langle 1,2,3,4,1,2,3,4 \\rangle$. Aging results in 6 faults. LRU results in 8 faults. The very long epoch prevents the counters from updating, causing the aging algorithm to make different (and in this case, better) eviction choices than LRU.\n*   **Case D**: `F=1, E=3`, String: $\\langle 1,2,3,4,1,2,3,4 \\rangle$. With only one frame, any reference to a new page number is a fault. Both algorithms result in 8 faults.\nThe final aggregated results match the output of the provided reference code.",
            "answer": "```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\n// A struct representing a physical memory frame\ntypedef struct {\n    int valid;\n    int page_number;\n\n    // For LRU policy\n    int last_used_time;\n\n    // For Aging policy\n    unsigned int counter;\n    int reference_bit;\n} Frame;\n\n// A struct to hold the parameters for a single test case\ntypedef struct {\n    int F; // Number of frames\n    int E; // Epoch length for Aging\n    int W; // Counter width for Aging\n    const int* ref_string;\n    int ref_string_len;\n    const char* name;\n} TestCase;\n\n// Simulates the LRU page replacement policy\nint simulate_lru(const TestCase* tc) {\n    Frame* frames = (Frame*)malloc(tc->F * sizeof(Frame));\n    memset(frames, 0, tc->F * sizeof(Frame));\n    int page_faults = 0;\n    int time = 0;\n\n    for (int i = 0; i < tc->ref_string_len; ++i) {\n        time++;\n        int current_page = tc->ref_string[i];\n        int page_found_idx = -1;\n\n        // Search for the page in frames\n        for (int j = 0; j < tc->F; ++j) {\n            if (frames[j].valid && frames[j].page_number == current_page) {\n                page_found_idx = j;\n                break;\n            }\n        }\n\n        if (page_found_idx != -1) { // Page hit\n            frames[page_found_idx].last_used_time = time;\n        } else { // Page fault\n            page_faults++;\n            int free_frame_idx = -1;\n            for (int j = 0; j < tc->F; ++j) {\n                if (!frames[j].valid) {\n                    free_frame_idx = j;\n                    break;\n                }\n            }\n\n            if (free_frame_idx != -1) { // Free frame available\n                frames[free_frame_idx].valid = 1;\n                frames[free_frame_idx].page_number = current_page;\n                frames[free_frame_idx].last_used_time = time;\n            } else { // No free frames, find victim\n                int victim_idx = 0;\n                for (int j = 1; j < tc->F; ++j) {\n                    if (frames[j].last_used_time < frames[victim_idx].last_used_time) {\n                        victim_idx = j;\n                    } else if (frames[j].last_used_time == frames[victim_idx].last_used_time) {\n                        if (frames[j].page_number < frames[victim_idx].page_number) {\n                            victim_idx = j;\n                        }\n                    }\n                }\n                frames[victim_idx].page_number = current_page;\n                frames[victim_idx].last_used_time = time;\n            }\n        }\n    }\n    free(frames);\n    return page_faults;\n}\n\n// Simulates the Aging page replacement policy\nint simulate_aging(const TestCase* tc) {\n    Frame* frames = (Frame*)malloc(tc->F * sizeof(Frame));\n    memset(frames, 0, tc->F * sizeof(Frame));\n    int page_faults = 0;\n    int processed_refs = 0;\n    unsigned int msb = (tc->W > 0) ? (1u << (tc->W - 1)) : 0;\n\n    for (int i = 0; i < tc->ref_string_len; ++i) {\n        processed_refs++;\n        int current_page = tc->ref_string[i];\n        int page_found_idx = -1;\n\n        // Search for the page in frames\n        for (int j = 0; j < tc->F; ++j) {\n            if (frames[j].valid && frames[j].page_number == current_page) {\n                page_found_idx = j;\n                break;\n            }\n        }\n\n        if (page_found_idx != -1) { // Page hit\n            frames[page_found_idx].reference_bit = 1;\n        } else { // Page fault\n            page_faults++;\n            int free_frame_idx = -1;\n            for (int j = 0; j < tc->F; ++j) {\n                if (!frames[j].valid) {\n                    free_frame_idx = j;\n                    break;\n                }\n            }\n\n            if (free_frame_idx != -1) { // Free frame available\n                frames[free_frame_idx].valid = 1;\n                frames[free_frame_idx].page_number = current_page;\n                frames[free_frame_idx].counter = 0;\n                frames[free_frame_idx].reference_bit = 1;\n            } else { // No free frames, find victim\n                int victim_idx = 0;\n                for (int j = 1; j < tc->F; ++j) {\n                   if (frames[j].counter < frames[victim_idx].counter) {\n                       victim_idx = j;\n                   } else if (frames[j].counter == frames[victim_idx].counter) {\n                       if (frames[j].page_number < frames[victim_idx].page_number) {\n                           victim_idx = j;\n                       }\n                   }\n                }\n                frames[victim_idx].page_number = current_page;\n                frames[victim_idx].counter = 0;\n                frames[victim_idx].reference_bit = 1;\n            }\n        }\n        \n        // Epoch update\n        if (processed_refs % tc->E == 0) {\n            for (int j = 0; j < tc->F; ++j) {\n                if (frames[j].valid) {\n                    frames[j].counter = (frames[j].counter >> 1) | (frames[j].reference_bit * msb);\n                    frames[j].reference_bit = 0;\n                }\n            }\n        }\n    }\n    \n    free(frames);\n    return page_faults;\n}\n\nint main(void) {\n    // Define reference strings for test cases\n    const int ref_A[] = {0, 1, 2, 3, 2, 1, 0, 3, 2, 1, 0, 3};\n    const int ref_B[] = {1, 2, 1, 2, 1, 2, 3};\n    const int ref_C[] = {1, 2, 3, 4, 1, 2, 3, 4};\n    const int ref_D[] = {1, 2, 3, 4, 1, 2, 3, 4};\n\n    TestCase test_cases[] = {\n        {3, 4, 8, ref_A, sizeof(ref_A) / sizeof(ref_A[0]), \"Case A\"},\n        {2, 1, 8, ref_B, sizeof(ref_B) / sizeof(ref_B[0]), \"Case B\"},\n        {3, 100, 8, ref_C, sizeof(ref_C) / sizeof(ref_C[0]), \"Case C\"},\n        {1, 3, 8, ref_D, sizeof(ref_D) / sizeof(ref_D[0]), \"Case D\"}\n    };\n\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    int results[num_cases][2];\n\n    for (int i = 0; i < num_cases; ++i) {\n        results[i][0] = simulate_aging(&test_cases[i]);\n        results[i][1] = simulate_lru(&test_cases[i]);\n    }\n\n    printf(\"[\");\n    for (int i = 0; i < num_cases; ++i) {\n        printf(\"[%d,%d]\", results[i][0], results[i][1]);\n        if (i < num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n\n    return EXIT_SUCCESS;\n}\n```"
        }
    ]
}