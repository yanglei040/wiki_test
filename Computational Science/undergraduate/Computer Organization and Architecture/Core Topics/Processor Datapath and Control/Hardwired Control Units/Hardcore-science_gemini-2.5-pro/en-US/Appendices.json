{
    "hands_on_practices": [
        {
            "introduction": "A hardwired control unit translates instruction opcodes into control signals through combinational logic. This first practice brings this concept to life by tasking you with the gate-level implementation of a control decoder. You will take minimized Boolean expressions for key control signals and realize them using only 2-input NAND gates, a universal gate type favored in manufacturing . This exercise hones your skills in applying De Morgan's laws and logic optimization to build an efficient, physically realizable circuit from an abstract specification.",
            "id": "3646582",
            "problem": "A hardwired control unit for a simplified reduced instruction set computer (RISC) uses a $4$-bit opcode field $\\{I_3,I_2,I_1,I_0\\}$ and a $3$-bit function field $\\{F_2,F_1,F_0\\}$ for register-type instructions. The outputs of the control unit include the register write-enable $\\text{RegWrite}$ and a single-bit arithmetic and logic unit (ALU) operation select $\\text{ALUop}_{\\text{sub}}$ that chooses subtraction when asserted. The control designer has already minimized the control logic to the following Boolean specifications in sum-of-products form using only the instruction bits:\n- Let $R = \\overline{I_3}\\,\\overline{I_2}\\,\\overline{I_1}\\,\\overline{I_0}$ denote the register-type opcode.\n- Let $\\text{ADDI} = I_3\\,\\overline{I_2}\\,\\overline{I_1}\\,\\overline{I_0}$ denote add-immediate.\n- Let $\\text{LW} = \\overline{I_3}\\,\\overline{I_2}\\,I_1\\,I_0$ denote load word.\n- Let $\\text{BEQ} = \\overline{I_3}\\,I_2\\,\\overline{I_1}\\,\\overline{I_0}$ denote branch if equal.\n\nThe outputs to be implemented are\n- $\\text{RegWrite} = R \\cdot \\big(F_2 + F_1 + \\overline{F_0}\\big) + \\text{ADDI} + \\text{LW}$, which asserts for all register-type arithmetic functions except jump-register (encoded by $F_2 F_1 F_0 = 0\\,0\\,1$), and for add-immediate and load word,\n- $\\text{ALUop}_{\\text{sub}} = \\text{BEQ} + \\big(R \\cdot \\overline{F_2} \\cdot F_1 \\cdot \\overline{F_0}\\big)$, which asserts for branch-equal and for the register-type subtract function (encoded by $F_2 F_1 F_0 = 0\\,1\\,0$).\n\nImplement both $\\text{RegWrite}$ and $\\text{ALUop}_{\\text{sub}}$ using a network composed solely of $2$-input NAND gates. The only available primary inputs are the true (non-complemented) bits $I_3,I_2,I_1,I_0,F_2,F_1,F_0$. You may create inverted literals using a NAND gate with its two inputs tied together. Unlimited fan-out is permitted. You may share any intermediate NAND sub-networks between the two outputs; each physical $2$-input NAND gate counts once even if it drives more than one place. Your objective is to minimize the total count of $2$-input NAND gates by logically factoring and sharing intermediate signals where appropriate, subject to the given specifications.\n\nStarting only from the fundamental Boolean algebra laws and the universality of NAND (that any Boolean function can be realized with NAND gates by using inversion, conjunction, and De Morgan transformations), derive a gate-level implementation plan and compute the minimum total number of $2$-input NAND gates required to realize both $\\text{RegWrite}$ and $\\text{ALUop}_{\\text{sub}}$ together under the stated constraints. Express your final answer as a single integer equal to this minimum total number of $2$-input NAND gates. No rounding is needed.",
            "solution": "The user wants to implement two Boolean logic functions, $\\text{RegWrite}$ and $\\text{ALUop}_{\\text{sub}}$, using only $2$-input NAND gates, with the goal of minimizing the total gate count. The available inputs are the true (non-complemented) bits $\\{I_3, I_2, I_1, I_0\\}$ and $\\{F_2, F_1, F_0\\}$.\n\nFirst, we must validate the problem.\n**Step 1: Extract Givens**\n- **Inputs:** $I_3, I_2, I_1, I_0, F_2, F_1, F_0$ (all are single bits).\n- **Intermediate definitions:**\n  - $R = \\overline{I_3}\\,\\overline{I_2}\\,\\overline{I_1}\\,\\overline{I_0}$\n  - $\\text{ADDI} = I_3\\,\\overline{I_2}\\,\\overline{I_1}\\,\\overline{I_0}$\n  - $\\text{LW} = \\overline{I_3}\\,\\overline{I_2}\\,I_1\\,I_0$\n  - $\\text{BEQ} = \\overline{I_3}\\,I_2\\,\\overline{I_1}\\,\\overline{I_0}$\n- **Output functions:**\n  - $\\text{RegWrite} = R \\cdot \\big(F_2 + F_1 + \\overline{F_0}\\big) + \\text{ADDI} + \\text{LW}$\n  - $\\text{ALUop}_{\\text{sub}} = \\text{BEQ} + \\big(R \\cdot \\overline{F_2} \\cdot F_1 \\cdot \\overline{F_0}\\big)$\n- **Constraints:**\n  - Implementation must use only $2$-input NAND gates.\n  - Inverters are constructed from $2$-input NAND gates with tied inputs.\n  - Unlimited fan-out is permitted.\n  - Intermediate logic networks may be shared.\n- **Objective:** Minimize the total count of $2$-input NAND gates.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is a standard digital logic design and optimization task. It is scientifically grounded in Boolean algebra and computer architecture principles. The definitions are clear, the objective is well-defined, and there are no apparent contradictions, ambiguities, or violations of scientific principles. The problem is thus deemed valid.\n\n**Step 3: Verdict and Action**\nThe problem is valid. The solution process will now proceed.\n\n**Derivation of the Minimal NAND Gate Implementation**\nOur strategy is to implement the functions in a canonical two-level NAND-NAND structure, which corresponds to a sum-of-products (SOP) form. We will first expand the functions into a minimal SOP form and then identify common sub-expressions to share gates.\n\nThe Boolean equations are:\n$\\text{RegWrite} = R \\cdot (F_2 + F_1 + \\overline{F_0}) + \\text{ADDI} + \\text{LW}$\n$\\text{ALUop}_{\\text{sub}} = \\text{BEQ} + (R \\cdot \\overline{F_2} \\cdot F_1 \\cdot \\overline{F_0})$\n\nLet's expand $\\text{RegWrite}$ into its full SOP form by distributing $R$:\n$\\text{RegWrite} = (R \\cdot F_2) + (R \\cdot F_1) + (R \\cdot \\overline{F_0}) + \\text{ADDI} + \\text{LW}$\n\nThe complete set of product terms ($P_i$) across both functions is:\n$P_1 = R \\cdot F_2 = \\overline{I_3}\\,\\overline{I_2}\\,\\overline{I_1}\\,\\overline{I_0}\\,F_2$\n$P_2 = R \\cdot F_1 = \\overline{I_3}\\,\\overline{I_2}\\,\\overline{I_1}\\,\\overline{I_0}\\,F_1$\n$P_3 = R \\cdot \\overline{F_0} = \\overline{I_3}\\,\\overline{I_2}\\,\\overline{I_1}\\,\\overline{I_0}\\,\\overline{F_0}$\n$P_4 = \\text{ADDI} = I_3\\,\\overline{I_2}\\,\\overline{I_1}\\,\\overline{I_0}$\n$P_5 = \\text{LW} = \\overline{I_3}\\,\\overline{I_2}\\,I_1\\,I_0$\n$P_6 = \\text{BEQ} = \\overline{I_3}\\,I_2\\,\\overline{I_1}\\,\\overline{I_0}$\n$P_7 = R \\cdot \\overline{F_2} \\cdot F_1 \\cdot \\overline{F_0} = \\overline{I_3}\\,\\overline{I_2}\\,\\overline{I_1}\\,\\overline{I_0}\\,\\overline{F_2}\\,F_1\\,\\overline{F_0}$\n\nThe implementation will be based on the NAND-NAND realization of an SOP expression $F = \\sum_i P_i = \\overline{\\prod_i \\overline{P_i}} = \\text{NAND}(\\overline{P_1}, \\overline{P_2}, \\dots)$. This requires generating the negated product terms ($\\overline{P_i}$) in the first level and then combining them with a final NAND gate in the second level.\n\n**Gate-by-Gate Construction and Counting**\nThe cost of implementing an $n$-input AND gate with $2$-input NAND gates is $2(n-1)$, and for an $n$-input NAND gate, it is $2(n-1)-1=2n-3$. We will build the circuit step-by-step, counting each unique $2$-input NAND gate once.\n\n**1. Input Inverters (6 gates)**\nThe functions require inverted versions of $I_3, I_2, I_1, I_0, F_2, F_0$. Each inversion costs one $2$-input NAND gate.\n- $\\overline{I_3}, \\overline{I_2}, \\overline{I_1}, \\overline{I_0}, \\overline{F_2}, \\overline{F_0}$\n- Gate Count (GC): $6$\n\n**2. Shared 2-Input AND Sub-expressions (4 gates)**\nMany product terms share common pairs of literals. We build these shared AND terms first. A 2-input AND requires one NAND followed by an inverter (another NAND), for a total of 2 gates.\n- Let $A_1 = \\overline{I_3}\\overline{I_2}$. This requires $2$ gates. $A_1$ is now available.\n- Let $A_2 = \\overline{I_1}\\overline{I_0}$. This similarly requires $2$ gates. $A_2$ is now available.\n- GC: $6 + 4 = 10$.\n\n**3. The R-type Signal (2 gates)**\nThe signal $R = \\overline{I_3}\\overline{I_2}\\overline{I_1}\\overline{I_0}$ can be constructed as $R=A_1 \\cdot A_2$.\n- This $2$-input AND operation costs $2$ gates. The signal $R$ is now available.\n- GC: $10 + 2 = 12$.\n\n**4. First-Level NANDs for $\\text{RegWrite}$ terms (Part 1 -- R-based) (3 gates)**\nThese are the negated product terms $\\overline{P_1}, \\overline{P_2}, \\overline{P_3}$. Each is a 2-input NAND.\n- $\\overline{P_1} = \\overline{R \\cdot F_2} = \\text{NAND}(R, F_2)$. (1 gate)\n- $\\overline{P_2} = \\overline{R \\cdot F_1} = \\text{NAND}(R, F_1)$. (1 gate)\n- $\\overline{P_3} = \\overline{R \\cdot \\overline{F_0}} = \\text{NAND}(R, \\overline{F_0})$. (1 gate)\n- GC: $12 + 3 = 15$. $\\overline{P_1}, \\overline{P_2}, \\overline{P_3}$ are available.\n\n**5. First-Level NANDs for $\\text{RegWrite}$ terms (Part 2 -- ADDI, LW) (6 gates)**\n- To create $\\overline{P_4} = \\overline{I_3\\,\\overline{I_2}\\,\\overline{I_1}\\,\\overline{I_0}} = \\overline{(I_3\\,\\overline{I_2}) \\cdot A_2}$:\n  - Build $T_4 = I_3\\,\\overline{I_2}$ (2 gates).\n  - $\\overline{P_4} = \\text{NAND}(T_4, A_2)$ (1 gate). Total: $3$ gates.\n- To create $\\overline{P_5} = \\overline{\\overline{I_3}\\,\\overline{I_2}\\,I_1\\,I_0} = \\overline{A_1 \\cdot (I_1\\,I_0)}$:\n  - Build $T_5 = I_1\\,I_0$ (2 gates).\n  - $\\overline{P_5} = \\text{NAND}(A_1, T_5)$ (1 gate). Total: $3$ gates.\n- GC: $15 + 3 + 3 = 21$. $\\overline{P_4}, \\overline{P_5}$ are available.\n\n**6. First-Level NAND for $\\text{ALUop}_{\\text{sub}}$ term (BEQ) (3 gates)**\n- To create $\\overline{P_6} = \\overline{\\overline{I_3}\\,I_2\\,\\overline{I_1}\\,\\overline{I_0}} = \\overline{(\\overline{I_3}\\,I_2) \\cdot A_2}$:\n  - Build $T_6 = \\overline{I_3}\\,I_2$ (2 gates).\n  - $\\overline{P_6} = \\text{NAND}(T_6, A_2)$ (1 gate). Total: $3$ gates.\n- GC: $21 + 3 = 24$. $\\overline{P_6}$ is available.\n\n**7. First-Level NAND for $\\text{ALUop}_{\\text{sub}}$ term (SUB) (4 gates)**\n- The term is $P_7 = R \\cdot \\overline{F_2} \\cdot F_1 \\cdot \\overline{F_0}$. Notice that this can be factored using $P_2 = R \\cdot F_1$. So, $P_7 = P_2 \\cdot (\\overline{F_2} \\cdot \\overline{F_0})$.\n- To create $\\overline{P_7} = \\overline{P_2 \\cdot (\\overline{F_2} \\cdot \\overline{F_0})}$:\n  - We have $\\overline{P_2}$ from step 4. Invert it to get $P_2$: $\\text{NAND}(\\overline{P_2}, \\overline{P_2})$ (1 gate).\n  - Build $T_7 = \\overline{F_2} \\cdot \\overline{F_0}$ (2 gates).\n  - $\\overline{P_7} = \\text{NAND}(P_2, T_7)$ (1 gate). Total: $4$ gates.\n- GC: $24 + 4 = 28$. $\\overline{P_7}$ is available.\n\n**8. Second-Level NANDs for Final Outputs (5 gates)**\n- $\\text{RegWrite} = \\text{NAND}(\\overline{P_1}, \\overline{P_2}, \\overline{P_3}, \\overline{P_4}, \\overline{P_5})$. This is a $5$-input NAND gate.\n  - A $k$-input NAND gate can be implemented as a tree of $k-1$ $2$-input NAND gates.\n  - For $k=5$, this requires $5-1=4$ gates.\n- $\\text{ALUop}_{\\text{sub}} = \\text{NAND}(\\overline{P_6}, \\overline{P_7})$. This is a $2$-input NAND gate.\n  - For $k=2$, this requires $2-1=1$ gate.\n- GC: $28 + 4 + 1 = 33$.\n\nThe total gate count, after systematically constructing the circuit with sharing of common sub-expressions, is $33$.\n\n**Summary of Gate Count**\n- Inverters: $6$\n- Shared 2-input ANDs ($A_1, A_2$): $4$\n- Signal R: $2$\n- Negated terms $\\overline{P_1}, \\overline{P_2}, \\overline{P_3}$: $3$\n- Negated term $\\overline{P_4}$: $3$\n- Negated term $\\overline{P_5}$: $3$\n- Negated term $\\overline{P_6}$: $3$\n- Negated term $\\overline{P_7}$: $4$\n- Final $\\text{RegWrite}$ output logic: $4$\n- Final $\\text{ALUop}_{\\text{sub}}$ output logic: $1$\n- **Total**: $6+4+2+3+3+3+3+4+4+1 = 33$ gates.\n\nThis represents a complete and optimized implementation under the specified constraints.",
            "answer": "$$\\boxed{33}$$"
        },
        {
            "introduction": "A control unit's logical correctness is only half the story; its speed is paramount to processor performance. This exercise moves from static logic design to dynamic timing analysis within a pipelined datapath . By analyzing the propagation delays along critical paths—from ALU flag generation to their use in branch decisions—you will determine the minimum clock period and thus the maximum frequency at which the processor can reliably operate. This practice is essential for understanding how control logic interacts with the datapath under the strict timing constraints of a synchronous system.",
            "id": "3646600",
            "problem": "A synchronous, edge-triggered, hardwired control unit orchestrates a classic $5$-stage pipeline (Instruction Fetch, Instruction Decode, Execute, Memory, Write Back). To guarantee that the Arithmetic Logic Unit (ALU) flags—Zero, Carry, and Overflow—are stable when used by the branch decision network, the design discipline mandates that these flags be captured in a dedicated flag register at the end of the Execute stage and only then be consumed by the branch decision logic. The branch decision logic selects the next Program Counter (PC) through a multiplexer based on the decoded branch condition, the captured flags, and a computed branch target.\n\nAssume a single global clock with skew $t_{\\mathrm{skew}}$, and edge-triggered flip-flops with specified clock-to-$Q$ and setup times. Consider the following measured delays (worst-case unless marked “min”):\n\n- From the Execute stage input register (ID/EX) to the flag register:\n  - ID/EX register clock-to-$Q$: $t_{\\mathrm{cq}}^{\\mathrm{ID/EX}} = 0.15\\,\\mathrm{ns}$, with minimum $t_{\\mathrm{cq,min}}^{\\mathrm{ID/EX}} = 0.08\\,\\mathrm{ns}$.\n  - ALU propagation delay: $t_{\\mathrm{ALU}} = 2.60\\,\\mathrm{ns}$, with minimum $t_{\\mathrm{ALU,min}} = 1.00\\,\\mathrm{ns}$.\n  - Flag generation logic delay: $t_{\\mathrm{flag}} = 0.25\\,\\mathrm{ns}$, with minimum $t_{\\mathrm{flag,min}} = 0.10\\,\\mathrm{ns}$.\n  - Flag register setup time: $t_{\\mathrm{setup}}^{\\mathrm{Flag}} = 0.09\\,\\mathrm{ns}$, and hold time $t_{\\mathrm{hold}}^{\\mathrm{Flag}} = 0.02\\,\\mathrm{ns}$.\n\n- From the flag register to the PC register:\n  - Flag register clock-to-$Q$: $t_{\\mathrm{cq}}^{\\mathrm{Flag}} = 0.12\\,\\mathrm{ns}$.\n  - Branch decision combinational logic delay: $t_{\\mathrm{branch}} = 0.50\\,\\mathrm{ns}$.\n  - Branch target adder delay: $t_{\\mathrm{add}} = 0.85\\,\\mathrm{ns}$.\n  - PC selection multiplexer delay: $t_{\\mathrm{mux}} = 0.28\\,\\mathrm{ns}$.\n  - PC register setup time: $t_{\\mathrm{setup}}^{\\mathrm{PC}} = 0.10\\,\\mathrm{ns}$.\n\n- Global clock skew: $t_{\\mathrm{skew}} = 0.04\\,\\mathrm{ns}$.\n\n- All other stage-to-stage worst-case register-to-register paths in the pipeline have delays less than or equal to $1.80\\,\\mathrm{ns}$, so they are not critical compared to the Execute-to-Flag and Flag-to-PC paths above.\n\nStarting from the foundational synchronous timing constraints for edge-triggered systems (register-to-register setup and hold requirements), and recognizing that flags must be captured before being used by control, derive the minimal feasible clock period $T_{\\mathrm{clk}}$ that simultaneously satisfies:\n- The Execute-to-Flag capture path (so that flags are captured correctly), and\n- The Flag-to-PC control path in the following cycle (so that the branch decision based on captured flags arrives at the PC register in time).\n\nThen compute the maximum clock frequency $f_{\\max} = 1/T_{\\mathrm{clk}}$. Express the final answer in $\\mathrm{MHz}$ and round your answer to four significant figures.",
            "solution": "The problem requires the determination of the minimal feasible clock period, $T_{\\mathrm{clk}}$, for a synchronous pipelined processor, which is governed by the timing constraints of its critical paths. The maximum clock frequency, $f_{\\max}$, is the reciprocal of this minimal period. The analysis must adhere to the fundamental principles of synchronous digital circuit timing for edge-triggered registers, specifically the setup and hold time constraints.\n\nThe setup time constraint dictates that the data input to a flip-flop must be stable for a minimum duration, the setup time ($t_{\\mathrm{setup}}$), before the active clock edge arrives. For a data path between a source register (Reg1) and a destination register (Reg2), this constraint determines the minimum clock period. The total delay for data to propagate from the output of Reg1, through the intermediate combinational logic, and arrive at the input of Reg2 must be less than the clock period, accounting for the setup time of Reg2 and any clock skew ($t_{\\mathrm{skew}}$) between the registers. In the worst-case for setup time, the clock arrives at the destination register earlier than at the source register, reducing the available time for data propagation. The governing inequality is:\n$$T_{\\mathrm{clk}} \\ge t_{\\mathrm{cq,max}}^{\\mathrm{Reg1}} + t_{\\mathrm{logic,max}} + t_{\\mathrm{setup}}^{\\mathrm{Reg2}} + t_{\\mathrm{skew}}$$\nwhere $t_{\\mathrm{cq,max}}^{\\mathrm{Reg1}}$ is the maximum clock-to-Q delay of the source register, and $t_{\\mathrm{logic,max}}$ is the maximum propagation delay of the combinational logic path.\n\nThe overall minimal clock period for the system is the maximum of the minimal periods required by all individual register-to-register paths. The problem identifies two specific paths of interest, in addition to a general constraint for all other paths. We will analyze each in turn.\n\n1.  The Execute-to-Flag Capture Path:\nThis path propagates data from the ID/EX pipeline register through the ALU and flag generation logic to the input of the dedicated flag register.\nThe source register is the ID/EX register, and the destination is the flag register.\nThe combinational logic delay is the sum of the ALU delay and the flag generation logic delay:\n$t_{\\mathrm{logic,1}} = t_{\\mathrm{ALU}} + t_{\\mathrm{flag}} = 2.60\\,\\mathrm{ns} + 0.25\\,\\mathrm{ns} = 2.85\\,\\mathrm{ns}$.\nThe minimum clock period required by this path, $T_{\\mathrm{clk,1}}$, is found by applying the setup time constraint:\n$$T_{\\mathrm{clk,1}} \\ge t_{\\mathrm{cq}}^{\\mathrm{ID/EX}} + (t_{\\mathrm{ALU}} + t_{\\mathrm{flag}}) + t_{\\mathrm{setup}}^{\\mathrm{Flag}} + t_{\\mathrm{skew}}$$\nSubstituting the given maximum delay values:\n$$T_{\\mathrm{clk,1}} \\ge 0.15\\,\\mathrm{ns} + (2.60\\,\\mathrm{ns} + 0.25\\,\\mathrm{ns}) + 0.09\\,\\mathrm{ns} + 0.04\\,\\mathrm{ns}$$\n$$T_{\\mathrm{clk,1}} \\ge 0.15\\,\\mathrm{ns} + 2.85\\,\\mathrm{ns} + 0.09\\,\\mathrm{ns} + 0.04\\,\\mathrm{ns}$$\n$$T_{\\mathrm{clk,1}} \\ge 3.13\\,\\mathrm{ns}$$\n\n2.  The Flag-to-PC Control Path (and associated PC update logic):\nThis path determines the address to be loaded into the Program Counter (PC) register. The logic involves multiple signals converging on the PC selection multiplexer. The final value at the PC register's input depends on the last-arriving signal to the MUX logic.\nThe inputs to the PC selection MUX are the computed branch target address and other potential next-PC values (e.g., PC+$4$). The MUX's select signal comes from the branch decision logic.\n- The branch target address path originates from the ID/EX register (holding PC and immediate offset) and passes through the branch target adder. The time from the clock edge for this signal to become stable at the MUX's data input is $t_{\\mathrm{cq}}^{\\mathrm{ID/EX}} + t_{\\mathrm{add}}$.\n- The branch decision path originates from the flag register and passes through the branch decision logic. The time from the clock edge for this signal to become stable at the MUX's select input is $t_{\\mathrm{cq}}^{\\mathrm{Flag}} + t_{\\mathrm{branch}}$.\n\nThe MUX output will be stable only after the latest of these input signals has arrived and propagated through the MUX. The total propagation delay, $T_{\\mathrm{prop,2}}$, from the launching clock edge to the D-input of the PC register is:\n$$T_{\\mathrm{prop,2}} = \\max(t_{\\mathrm{cq}}^{\\mathrm{ID/EX}} + t_{\\mathrm{add}}, t_{\\mathrm{cq}}^{\\mathrm{Flag}} + t_{\\mathrm{branch}}) + t_{\\mathrm{mux}}$$\nCalculating the two terms inside the $\\max$ function:\n$$t_{\\mathrm{cq}}^{\\mathrm{ID/EX}} + t_{\\mathrm{add}} = 0.15\\,\\mathrm{ns} + 0.85\\,\\mathrm{ns} = 1.00\\,\\mathrm{ns}$$\n$$t_{\\mathrm{cq}}^{\\mathrm{Flag}} + t_{\\mathrm{branch}} = 0.12\\,\\mathrm{ns} + 0.50\\,\\mathrm{ns} = 0.62\\,\\mathrm{ns}$$\nThe longer path is the branch target computation. Thus:\n$$T_{\\mathrm{prop,2}} = \\max(1.00\\,\\mathrm{ns}, 0.62\\,\\mathrm{ns}) + 0.28\\,\\mathrm{ns} = 1.00\\,\\mathrm{ns} + 0.28\\,\\mathrm{ns} = 1.28\\,\\mathrm{ns}$$\nThe minimum clock period required by this path, $T_{\\mathrm{clk,2}}$, is given by the setup constraint for the PC register:\n$$T_{\\mathrm{clk,2}} \\ge T_{\\mathrm{prop,2}} + t_{\\mathrm{setup}}^{\\mathrm{PC}} + t_{\\mathrm{skew}}$$\n$$T_{\\mathrm{clk,2}} \\ge 1.28\\,\\mathrm{ns} + 0.10\\,\\mathrm{ns} + 0.04\\,\\mathrm{ns}$$\n$$T_{\\mathrm{clk,2}} \\ge 1.42\\,\\mathrm{ns}$$\n\n3.  Other Pipeline Paths:\nThe problem states that all other register-to-register paths impose a timing constraint less than or equal to $1.80\\,\\mathrm{ns}$. This provides a third constraint for the clock period:\n$$T_{\\mathrm{clk,3}} \\ge 1.80\\,\\mathrm{ns}$$\nThis value is interpreted as the minimum clock period required by the slowest of these other paths.\n\nTo ensure correct operation of the entire pipeline, the system's clock period $T_{\\mathrm{clk}}$ must be long enough to satisfy all paths simultaneously. Therefore, the minimum feasible clock period is the maximum of the individual path requirements:\n$$T_{\\mathrm{clk,min}} = \\max(T_{\\mathrm{clk,1}}, T_{\\mathrm{clk,2}}, T_{\\mathrm{clk,3}})$$\n$$T_{\\mathrm{clk,min}} = \\max(3.13\\,\\mathrm{ns}, 1.42\\,\\mathrm{ns}, 1.80\\,\\mathrm{ns}) = 3.13\\,\\mathrm{ns}$$\nThe critical path that limits the clock speed is the Execute-to-Flag capture path.\n\nAs a matter of due diligence, we should verify that the hold time constraint is not violated for the critical path, as a hold violation can invalidate a design. The hold constraint requires that the data at a flip-flop's input remains stable for a duration $t_{\\mathrm{hold}}$ after the clock edge. This is threatened by short paths. The condition is:\n$$t_{\\mathrm{cq,min}}^{\\mathrm{Reg1}} + t_{\\mathrm{logic,min}} \\ge t_{\\mathrm{hold}}^{\\mathrm{Reg2}} + t_{\\mathrm{skew}}$$\nFor the Execute-to-Flag path:\n$t_{\\mathrm{logic,min}} = t_{\\mathrm{ALU,min}} + t_{\\mathrm{flag,min}} = 1.00\\,\\mathrm{ns} + 0.10\\,\\mathrm{ns} = 1.10\\,\\mathrm{ns}$.\nChecking the inequality:\n$$t_{\\mathrm{cq,min}}^{\\mathrm{ID/EX}} + t_{\\mathrm{logic,min}} \\ge t_{\\mathrm{hold}}^{\\mathrm{Flag}} + t_{\\mathrm{skew}}$$\n$$0.08\\,\\mathrm{ns} + 1.10\\,\\mathrm{ns} \\ge 0.02\\,\\mathrm{ns} + 0.04\\,\\mathrm{ns}$$\n$$1.18\\,\\mathrm{ns} \\ge 0.06\\,\\mathrm{ns}$$\nThe hold condition is met with a substantial margin. The design is valid.\n\nFinally, the maximum clock frequency $f_{\\max}$ is the reciprocal of the minimum clock period:\n$$f_{\\max} = \\frac{1}{T_{\\mathrm{clk,min}}} = \\frac{1}{3.13\\,\\mathrm{ns}} = \\frac{1}{3.13 \\times 10^{-9}\\,\\mathrm{s}} \\approx 319.4888... \\times 10^{6}\\,\\mathrm{Hz} = 319.4888...\\,\\mathrm{MHz}$$\nRounding to four significant figures as required, we get $319.5\\,\\mathrm{MHz}$.",
            "answer": "$$\\boxed{319.5}$$"
        },
        {
            "introduction": "To enhance performance, modern processors often feature superscalar pipelines capable of issuing multiple instructions per cycle. This creates contention for shared resources, which the hardwired control unit must manage. This final practice challenges you to design the arbitration logic for a dual-issue pipeline with a single shared ALU . You will first derive the Boolean expressions for a priority-based grant scheme to resolve structural hazards, and then analyze the resulting throughput, providing a clear link between low-level control logic and its impact on processor performance.",
            "id": "3646627",
            "problem": "A dual-issue, in-order central processing unit (CPU) pipeline has a single shared Arithmetic Logic Unit (ALU) resource. In each cycle, the decode stage presents up to $2$ instructions to the dispatch stage in fixed positions called slot $0$ and slot $1$. Only ALU-type instructions contend for the single ALU; memory and branch instructions use other fully independent, fully pipelined resources. The ALU has an initiation interval of $I = 1$, meaning it can accept at most $1$ ALU operation per cycle. Assume no cross-cycle ALU busy carryover beyond this initiation constraint.\n\nThe hardwired control unit generates combinational request and grant signals per cycle using only the currently decoded instruction types and per-instruction readiness. Let $A_0$ and $A_1$ be Boolean signals that are $1$ if the instruction in slot $0$ or slot $1$ is an ALU-type instruction, respectively. Let $R_0$ and $R_1$ be Boolean signals that are $1$ if the instruction in slot $0$ or slot $1$ is ready to issue (all operands available and no inter-instruction data hazard), respectively. Define request signals $Q_0 = R_0 \\land A_0$ and $Q_1 = R_1 \\land A_1$. The control must output ALU grant signals $G_0$ and $G_1$ such that at most one of $G_0$ or $G_1$ is $1$ in a given cycle, with fixed priority to slot $0$ on within-cycle contention. Let $H$ be a structural hazard detect signal that is $1$ exactly when, in the current cycle, there is ALU contention that forces slot $1$ to be stalled.\n\nTasks:\n- From first principles of Boolean mutual exclusion and structural hazard definition, derive minimal sum-of-products expressions for $G_0$, $G_1$, and $H$ in terms of $Q_0$ and $Q_1$ under the stated ALU initiation interval $I = 1$ assumption.\n- Using your $G_0$ and $G_1$, model the random throughput of ALU issues per cycle. Assume slot $0$ and slot $1$ instruction types are independent across the two slots, operand readiness is always true in this experiment, and the per-slot probabilities that a decoded instruction is ALU-type are $p_0 = 0.60$ for slot $0$ and $p_1 = 0.55$ for slot $1$. Compute the steady-state expected number of ALU instructions issued per cycle.\n\nRound your final numerical answer to four significant figures and express it in operations per cycle.",
            "solution": "The problem statement has been meticulously analyzed and is determined to be valid. It is scientifically grounded in the principles of computer architecture, well-posed, objective, and internally consistent. We may therefore proceed with a formal solution.\n\nThe problem is divided into two parts: first, the derivation of Boolean logic expressions for control signals, and second, the calculation of the expected ALU throughput under a probabilistic model.\n\n**Part 1: Derivation of Control Signal Logic**\n\nThe control logic must arbitrate access to a single Arithmetic Logic Unit (ALU) for two potential instruction issue slots, slot $0$ and slot $1$. The inputs to this logic are the ALU request signals for each slot, $Q_0$ and $Q_1$. The outputs are the grant signals $G_0$ and $G_1$, and a structural hazard signal $H$. The core constraints are that at most one grant can be active per cycle ($I=1$), and slot $0$ has fixed priority over slot $1$.\n\nA request signal $Q_i$ is defined as $Q_i = R_i \\land A_i$, where $A_i$ is true if the instruction in slot $i$ is of ALU-type and $R_i$ is true if the instruction is ready.\n\nDerivation of $G_0$:\nThe grant signal for slot $0$, $G_0$, is determined by its request status. Since slot $0$ has the highest priority, it is granted the ALU whenever it issues a request, irrespective of the status of slot $1$.\nTherefore, the Boolean expression for $G_0$ is directly the request signal $Q_0$.\n$$G_0 = Q_0$$\n\nDerivation of $G_1$:\nThe grant signal for slot $1$, $G_1$, depends on two conditions. First, slot $1$ must request the ALU, so $Q_1$ must be true. Second, the shared ALU must be available. Due to the fixed priority scheme, the ALU is available to slot $1$ only if slot $0$ does not request it. The condition for slot $0$ not requesting the ALU is $\\neg Q_0$. Combining these, slot $1$ is granted the ALU only if it requests it AND slot $0$ does not.\n$$G_1 = \\neg Q_0 \\land Q_1$$\nWe can verify that this logic respects the mutual exclusion constraint: $G_0 \\land G_1 = Q_0 \\land (\\neg Q_0 \\land Q_1) = (Q_0 \\land \\neg Q_0) \\land Q_1 = \\text{False} \\land Q_1 = \\text{False}$. This confirms that at most one grant signal can be true in any given cycle.\n\nDerivation of $H$:\nThe structural hazard signal $H$ is defined to be $1$ when ALU contention forces slot $1$ to be stalled. A stall occurs for slot $1$ if it validly requests the ALU ($Q_1=1$) but is denied the grant ($G_1=0$). The denial must be due to resource contention, which in this priority scheme means the higher-priority slot $0$ also requested the resource ($Q_0=1$). Thus, the hazard condition occurs precisely when both slots request the single ALU simultaneously.\n$$H = Q_0 \\land Q_1$$\nIn this situation, $Q_0=1$ causes $G_0=1$ and $G_1=0$, stalling the ready ALU instruction in slot $1$.\n\nThe minimal sum-of-products expressions are:\n- $G_0 = Q_0$\n- $G_1 = \\neg Q_0 \\land Q_1$\n- $H = Q_0 \\land Q_1$\n\n**Part 2: Calculation of Expected ALU Throughput**\n\nWe are asked to compute the steady-state expected number of ALU instructions issued per cycle. Let this quantity be $E[N_{ALU}]$. An instruction is issued if its corresponding grant signal is active. The total number of ALU instructions issued in a cycle is $N_{ALU} = G_0 + G_1$, where the Boolean values $0$ and $1$ are treated as integers.\n\nBy the linearity of expectation, $E[N_{ALU}] = E[G_0 + G_1] = E[G_0] + E[G_1]$.\nFor a Boolean random variable $X$, its expectation $E[X]$ is equal to its probability of being true, $P(X=1)$.\nThus, $E[N_{ALU}] = P(G_0=1) + P(G_1=1)$.\n\nFor this calculation, we are given the following assumptions:\n1. Operand readiness is always true: $R_0 = 1$ and $R_1 = 1$. This simplifies the request signals to $Q_0 = A_0$ and $Q_1 = A_1$.\n2. The grant logic then becomes $G_0 = A_0$ and $G_1 = \\neg A_0 \\land A_1$.\n3. The probabilities of an instruction being an ALU type are $p_0 = P(A_0=1) = 0.60$ and $p_1 = P(A_1=1) = 0.55$.\n4. The events $A_0$ and $A_1$ are statistically independent.\n\nWe can now compute the probabilities for the grant signals:\nThe probability of granting the ALU to slot $0$ is:\n$$P(G_0=1) = P(A_0=1) = p_0$$\nThe probability of granting the ALU to slot $1$ requires $A_1=1$ and $A_0=0$. Due to independence:\n$$P(G_1=1) = P(\\neg A_0 \\land A_1) = P(A_0=0) \\times P(A_1=1)$$\nSince $P(A_0=0) = 1 - P(A_0=1) = 1 - p_0$, we have:\n$$P(G_1=1) = (1-p_0)p_1$$\n\nThe expected number of ALU instructions issued per cycle is the sum of these probabilities:\n$$E[N_{ALU}] = p_0 + (1-p_0)p_1$$\nSubstituting the given numerical values:\n$$p_0 = 0.60$$\n$$p_1 = 0.55$$\n$$E[N_{ALU}] = 0.60 + (1 - 0.60) \\times 0.55$$\n$$E[N_{ALU}] = 0.60 + (0.40) \\times 0.55$$\n$$E[N_{ALU}] = 0.60 + 0.22$$\n$$E[N_{ALU}] = 0.82$$\nThe problem requires the answer to be rounded to four significant figures. Therefore, the result is $0.8200$ operations per cycle.",
            "answer": "$$\n\\boxed{0.8200}\n$$"
        }
    ]
}