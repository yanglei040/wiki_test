## 引言
在任何现代计算设备的核心，处理器都扮演着无可替代的角色。但处理器是如何将抽象的程序指令转化为具体的物理操作的？这个问题的答案深植于[计算机体系结构](@entry_id:747647)中最基本也最重要的一对概念：数据通路（Datapath）与控制通路（Control Path）。对许多学习者而言，将ALU、寄存器等孤立的硬件单元，与一个能够自主执行复杂程序的完整处理器联系起来，存在一道认知鸿沟。填补这道鸿沟的关键，就在于理解数据通路如何构建了执行操作的“骨架”，以及控制通路如何作为“神经系统”来精确指挥这个骨架的每一个动作。

本文旨在系统性地阐明这两者之间的关系。在**第一章：原理与机制**中，我们将深入剖析数据通路的构成和控制通路的两种主流实现方式——[硬布线控制](@entry_id:164082)与[微程序](@entry_id:751974)控制，并探讨它们之间至关重要的时序同步问题。接着，在**第二章：应用与跨学科连接**中，我们将视野拓宽，展示这些基础原理如何应用于[性能优化](@entry_id:753341)、[系统可靠性](@entry_id:274890)保障，以及在多核系统、专用加速器等复杂场景中的具体实践。最后，**第三章：动手实践**将提供一系列精心设计的问题，帮助您将理论知识转化为解决实际工程挑战的能力。让我们首先进入处理器的内部，揭开数据通路与控制通路协同工作的神秘面纱。

## 原理与机制

在上一章介绍处理器的基本构成后，本章将深入探讨[计算机体系结构](@entry_id:747647)中一对核心概念——**数据通路 (Datapath)** 与 **控制通路 (Control Path)** 的内在原理与协同机制。数据通路，常被喻为处理器的“肌肉”，包含了执行运算、存储数据所需的所有硬件单元，例如[算术逻辑单元](@entry_id:178218)（ALU）、寄存器文件、多路选择器（MUX）和内部总线。而控制通路，则是处理器的“大脑”，它根据指令的要求和数据通路的状态，生成一系列精确计时的控制信号，指挥数据通路完成正确的操作。二者之间的精妙协作，共同决定了处理器的功能、性能与效率。

### 控制通路的实现策略

控制单元的核心任务是根据当前指令的[操作码](@entry_id:752930)（opcode）和处理器的状态（如ALU的[零标志位](@entry_id:756823)），在正确的时刻，向数据通路的各个组件（如ALU、寄存器文件、MUX）发出正确的[控制信号](@entry_id:747841)。实现这一功能的两大主流策略是[硬布线控制](@entry_id:164082)和[微程序](@entry_id:751974)控制。

#### [硬布线控制](@entry_id:164082)

**[硬布线控制](@entry_id:164082) (Hardwired Control)** 的思想是，将[控制信号](@entry_id:747841)的生成逻辑完全用[组合逻辑](@entry_id:265083)电路实现。其核心是一个**[有限状态机](@entry_id:174162) (Finite State Machine, FSM)**，状态的转移和输出（即控制信号）由当前[状态和](@entry_id:193625)外部输入（主要是指令[操作码](@entry_id:752930)）共同决定。这种方式的电路结构在设计完成后便被固定下来，如同硬件线路“写死”一般。

在设计[硬布线控制器](@entry_id:750165)的FSM时，一个关键的工程决策是状态的编码方式。不同的编码策略直接影响到控制器的面积（所用[触发器](@entry_id:174305)的数量）和性能（[时钟频率](@entry_id:747385)）。

- **二[进制](@entry_id:634389)编码 (Binary Encoding)**：此方案使用最少数量的[触发器](@entry_id:174305)来表示所有状态。对于一个有 $S$ 个状态的FSM，仅需要 $k = \lceil \log_{2} S \rceil$ 个[触发器](@entry_id:174305)。例如，8个状态只需要3个[触发器](@entry_id:174305)。这种编码方式在硬件面积上最为经济。然而，其性能可能受限。因为在每个周期，控制逻辑都需要先“解码”当前的二[进制](@entry_id:634389)状态（这通常需要一个有 $k$ 个输入的[与门](@entry_id:166291)或等效逻辑），然后再根据该[状态和](@entry_id:193625)指令输入计算出下一[状态和](@entry_id:193625)输出信号。随着状态数 $S$ 的增加，$k$ 也会增加，这使得解码和下一状态逻辑变得更加复杂，逻辑延迟增长，从而限制了FSM能达到的[最高时钟频率](@entry_id:169681)。

- **独热码编码 (One-Hot Encoding)**：此方案为每个[状态分配](@entry_id:172668)一个独立的[触发器](@entry_id:174305)。在任何时刻，有且仅有一个[触发器](@entry_id:174305)的输出为高电平，用以表示当前所处的状态。因此，一个有 $S$ 个状态的FSM需要 $S$ 个[触发器](@entry_id:174305)，这在面积上代价较高。然而，其性能优势十分显著。因为状态的“解码”过程被完全豁免了——判断当前是否处于某个特定状态，只需检查对应的那根信号线即可。这使得生成下一[状态和](@entry_id:193625)输出信号的[组合逻辑](@entry_id:265083)大大简化，通常只包含几级简单的门电路。因此，独热码编码的FSM通常具有更短的**[关键路径延迟](@entry_id:748059) (critical path delay)** $t_{cp}$，能够支持更高的时钟频率，这对于高性能[处理器设计](@entry_id:753772)至关重要 。

总的来说，二进制编码以面积换性能，而独热码编码以性能换面积。在现代高性能[处理器设计](@entry_id:753772)中，速度往往是首要考虑因素，因此尽管需要更多的[触发器](@entry_id:174305)，独热码编码依然被广泛采用。

#### [微程序](@entry_id:751974)控制

与[硬布线控制](@entry_id:164082)将逻辑固化在门电路中不同，**[微程序](@entry_id:751974)控制 (Microprogrammed Control)** 将控制信号以二进制代码的形式，存放在一个专用的高速[只读存储器](@entry_id:175074)（ROM）中，这个存储器被称为**[控制存储器](@entry_id:747842) (Control Store, CS)**。每一组二[进制](@entry_id:634389)代码（称为一条**微指令 (microinstruction)**）对应着在一个[时钟周期](@entry_id:165839)内需要发出的所有[控制信号](@entry_id:747841)。执行一条机器指令被转化为执行一串微指令构成的**[微程序](@entry_id:751974) (microprogram)**。整个控制单元的核心是一个**[微序器](@entry_id:751977) (microsequencer)**，它负责产生下一条微指令的地址，并从[控制存储器](@entry_id:747842)中取出微指令。

一条微指令的内部结构，即**微[指令格式](@entry_id:750681)**，是设计中的核心权衡。 的一个设计场景揭示了这种权衡。假设一个处理器的数据通路包含ALU、内存接口和寄存器写回等多个可并行操作的资源组。

- **水平与[垂直微码](@entry_id:756486)**：微指令的设计存在一个从“水平”到“垂直”的[光谱](@entry_id:185632)。**[水平微码](@entry_id:750376) (Horizontal Microcode)** 倾向于为每个[控制信号](@entry_id:747841)或每组[互斥](@entry_id:752349)的[控制信号](@entry_id:747841)分配独立的比特位。这使得一条微指令能够同时控制多个数据通路资源并行工作，潜力巨大，但会导致微指令非常宽，从而增大[控制存储器](@entry_id:747842)的体积。相对地，**[垂直微码](@entry_id:756486) (Vertical Microcode)** 将控制信号编码，用较少的比特位表示多种操作，执行时需要额外的译码器。这能显著缩减微指令宽度，但降低了并行性。

- **字段编码权衡**：在实践中，常采用[混合策略](@entry_id:145261)。例如，可以将微指令划分为多个字段，每个字段控制一个特定的资源（如ALU操作字段、内存操作字段）。在每个字段内部，又可以选择**独热码（完全水平）**或**二[进制](@entry_id:634389)编码（编码）**。选择独热码，字段宽度等于操作数，无需译码，简单快速；选择二进制编码，字段宽度为 $\lceil \log_2(\text{操作数}+1) \rceil$，节省了微指令位宽，但数据通路端需要相应的译码器来还原控制信号。设计者必须在微指令总宽度（决定[控制存储器](@entry_id:747842)总容量，例如 $512 \text{ words} \times W \text{ bits} \le 16384 \text{ bits}$）、译码逻辑复杂度和并行操作能力之间做出最佳选择 。

除了控制数据通路的字段，微指令还必须包含用于控制[微程序](@entry_id:751974)流程的**序列控制字段**，例如下一条微指令的地址、分支条件选择等。

#### 性能比较：硬布线 vs. [微程序](@entry_id:751974)

硬布线和[微程序](@entry_id:751974)控制的性能瓶颈截然不同 。

- **[硬布线控制器](@entry_id:750165)**的周期时间受限于最长的组合逻辑路径延迟，即从[状态寄存器](@entry_id:755408)输出，经过指令译码和下一状态生成逻辑，直到下一个状态被锁存到寄存器输入的延迟，即 $t_{decode}$。这条路径的复杂性随指令集规模和复杂度的增加而显著增加。

- **[微程序控制器](@entry_id:169198)**的周期时间则取决于两个并行过程中的较慢者：(1) 从[控制存储器](@entry_id:747842)（CS）读取当前微指令内容所需的时间 $t_{CS}$；(2) [微序器](@entry_id:751977)计算下一条微指令地址所需的时间 $t_{uPC\_next}$。即，周期 $\ge \max(t_{CS}, t_{uPC\_next})$。$t_{uPC\_next}$ 的路径可能包括从当前微指令或机器指令[操作码](@entry_id:752930)中选择地址、通过地址选择MUX等。

一个常见的情况是，虽然[微序器](@entry_id:751977)的下一地址生成逻辑（$t_{uPC\_next}$）可能比复杂的硬布线译码逻辑（$t_{decode}$）要快，但[控制存储器](@entry_id:747842)本身的访问时间 $t_{CS}$ 可能非常长，尤其是当微指令很宽或[控制存储器](@entry_id:747842)很大时。在这种情况下，$t_{CS}$ 会成为整个控制器的性能瓶颈，使得[微程序控制器](@entry_id:169198)的整体[时钟频率](@entry_id:747385)低于[硬布线控制器](@entry_id:750165)。然而，[微程序](@entry_id:751974)控制的最大优势在于其灵活性：修改指令集的功能或修复设计错误，可能只需更新[控制存储器](@entry_id:747842)的内容，而无需重新设计和制造硬件。

### 数据通路与控制通路的接口：时序即一切

数据通路和控制通路之间的交互并非简单的命令与执行，而是一个必须在纳秒级精度上严格同步的舞蹈。时序的正确性是保证处理器功能正确的基石。

#### 同步时序与时序风险

在一个同步数字系统中，所有操作都由统一的时钟信号协调。对于一个寄存器（[触发器](@entry_id:174305)），它会在时钟的有效边沿（例如，上升沿）采样其D输入端的数据。为了让寄存器能正确锁存数据，其D输入信号必须在时钟有效边沿到来的一个**[建立时间](@entry_id:167213) ($t_{su}$)** 之前保持稳定，并在时钟边沿后的一个**[保持时间](@entry_id:266567) ($t_h$)**之内继续保持稳定。

控制信号，如寄存器的写使能（Write-Enable），本质上也是数据，同样遵循这一规则。考虑一个场景：ALU的计算结果需要在周期末尾被写入目标寄存器。控制通路产生的写使能信号必须准时到达，以确保寄存器能在正确的周期锁存ALU的结果。 描绘了一个典型的时序失败案例：

假设一个时钟周期为 $T = 2.50 \text{ ns}$，目标寄存器的[建立时间](@entry_id:167213)为 $t_{su} = 0.06 \text{ ns}$。这意味着，寄存器的所有输入（包括数据和写使能控制）必须在 $t = 2.50 - 0.06 = 2.44 \text{ ns}$ 之前稳定下来。如果数据通路（ALU）的计算能在 $1.35 \text{ ns}$ 时完成，但控制通路的译码逻辑非常复杂，导致写使能信号直到 $2.46 \text{ ns}$ 才最终稳定，这就发生了**[建立时间](@entry_id:167213)违例 (setup time violation)**。在 $2.44 \text{ ns}$ 到 $2.50 \text{ ns}$ 这个关键的建立时间窗口内，[控制信号](@entry_id:747841)仍在变化，这可能导致寄存器锁存一个不确定的、亚稳态的值，或者完全锁存错误的数据，从而导致系统崩溃。此外，[组合逻辑](@entry_id:265083)中存在的**毛刺 (glitch)**（短暂的伪脉冲）如果出现在[控制信号](@entry_id:747841)上，尤其危险，可能导致寄存器发生意外的写操作。

#### 保证时序正确性：流水化控制信号

解决上述时序问题的标准工程方法是**流水化[控制信号](@entry_id:747841) (pipelining the control signal)**。 的正确解法正是此道。其核心思想是，不要在数据正被处理的同一流水级内才开始为该数据生成控制信号。而是将[控制信号](@entry_id:747841)的生成逻辑提前一个或多个流水级。

例如，在ID（指令译码）阶段，当指令被译码时，我们就生成它在后续EX（执行）或WB（写回）阶段所需要的所有[控制信号](@entry_id:747841)。然后，将这些[控制信号](@entry_id:747841)与指令本身一起，锁存在流水级寄存器中，并随着数据在数据通路中流动而同步传递。这样，当数据到达ALU进行计算时，其对应的写使能信号早已在前一个[时钟周期](@entry_id:165839)末被稳定地锁存在流水级寄存器中，并在当前周期的开始就已准备就绪，稳定地作用于目标MUX或寄存器。这种方法确保了[控制信号](@entry_id:747841)和它所控制的数据在时间上“步调一致”，彻底消除了由于[控制路径](@entry_id:747840)过长而导致的延迟问题。

而一些看似简单的“修复”方法往往是危险的。例如，试图通过插入缓冲器来调整延迟，只会让原本就慢的信号变得更慢 。更危险的是**[时钟门控](@entry_id:170233) (clock gating)**，即用未寄存的、可能带有毛刺的控制信号去控制时钟的通断，这极易引入灾难性的时序错误，是[同步设计](@entry_id:163344)中的大忌。

#### 物理设计挑战：[扇出](@entry_id:173211)

从[逻辑设计](@entry_id:751449)走向物理实现，另一个严峻的挑战是**[扇出](@entry_id:173211) (fan-out)**。一个全局性的控制信号，比如一个全局写使能，可能需要同时驱动成百上千个寄存器。在物理层面，每个被驱动的门输入端都表现为一个小电容，大量的[扇出](@entry_id:173211)意味着驱动器面临巨大的电容负载 $C_{load}$。根据基本的[RC延迟](@entry_id:262267)模型（延迟约等于 $R_{driver} \times C_{load}$），高电容负载会导致信号的[传播延迟](@entry_id:170242)急剧增加，从而引发时序违例 。

为了应对高[扇出](@entry_id:173211)带来的时序问题，设计者会采用以下策略：

1.  **缓冲器树 (Buffer Tree)**：在驱动器和最终负载之间插入一个或多个层次的**缓冲器 (buffer)**。一个缓冲器本身是一个强驱动能力的[逻辑门](@entry_id:142135)。通过构建一个树状结构，原始的全局驱动器只需驱动少数几个一级缓冲器，每个一级缓冲器再驱动若干个二级缓冲器或部分最终负载。这种[分而治之](@entry_id:273215)的策略将一个巨大的电容负载分解为多个小负载，利用缓冲器的驱动能力，有效降低了总的[传播延迟](@entry_id:170242)。例如，一个两级缓冲树可以将一个原本超过 $1200 \text{ ps}$ 的延迟降低到 $150 \text{ ps}$ 以内 。

2.  **逻辑复制 (Logic Replication)**：与其用一个中央源头驱动所有负载，不如将产生[控制信号](@entry_id:747841)的逻辑本身复制多份，分散到芯片的不同区域。每个复制的逻辑单元只负责驱动其邻近的一小部分负载。虽然这增加了面积，但极大地缩短了连线长度并减小了每个驱动器的[扇出](@entry_id:173211)，是解决大规模[扇出](@entry_id:173211)时序问题的有效手段。

这些物理设计层面的优化，是确保控制通路在现实芯片中能够满足严苛时序要求的重要保证。

### 流水线处理器中的控制：管理冲突

在现代流水线处理器中，控制通路的角色变得更为复杂。它不仅要指挥单周期操作，更要作为交通警察，主动侦测和解决指令间因并行执行而引发的各种**冲突 (hazard)**。

#### [数据冲突](@entry_id:748203)与转发

**写后读 (Read-After-Write, RAW)** 冲突是最常见的[数据冲突](@entry_id:748203)。它发生在一条指令试图读取一个寄存器，而该寄存器的最新值是由其前面尚未完成的指令写入的。控制单元必须能够检测到这种情况。

一种严谨的检测方法是使用类似**记分板 (scoreboard)** 的结构。我们可以用形式化的[布尔逻辑](@entry_id:143377)来描述探测RAW冲突的条件 。假设我们追踪着流水线中 $k-1$ 条比当前指令（索引为$k$）更早的指令。对于指令 $k$ 要读取的任何一个寄存器 $r$，如果存在这样一条更早的指令 $j$ ($j  k$)，它满足以下所有条件，那么指令 $k$ 就必须暂停（stall）：
1.  指令 $j$ 会写入寄存器 $r$ ($D_{rj}=1$)。
2.  指令 $j$ 是在指令 $k$ 之前，**最近的**一个写入寄存器 $r$ 的指令（即在 $j$ 和 $k$ 之间，没有其他指令 $l$ 也写入寄存器 $r$，即 $\bigwedge_{l=j+1}^{k-1} (\neg D_{rl})$）。
3.  指令 $j$ 尚未完成其[写回](@entry_id:756770)操作 ($w_j=0$)。

综合起来，指令 $k$ 的暂停信号 $s_k$ 可以表达为对所有可能的前序指令 $j$ 和所有寄存器 $r$ 的检查：
$$s_k = \bigvee_{j=1}^{k-1} \left( (\neg w_j) \wedge \bigvee_{r=1}^{R} \left( U_{rk} \wedge D_{rj} \wedge \bigwedge_{l=j+1}^{k-1} (\neg D_{rl}) \right) \right)$$
其中 $U_{rk}$ 表示指令 $k$ 读取寄存器 $r$。

虽然暂停流水线可以解决RAW冲突，但效率低下。更优的解决方案是**[数据转发](@entry_id:169799) (data forwarding)** 或称**旁路 (bypassing)**。其思想是：与其等待数据被写回寄存器文件再读取，不如将计算结果从产生它的流水级（如EX或MEM级）直接“转发”给需要它的后续指令的输入端。

这需要在数据通路中增加硬件：在ALU的输入端添加[多路选择器](@entry_id:172320)（MUX），使其不仅能从寄存器文件中选择操作数，还能从EX/MEM或MEM/WB流水级寄存器中选择。同时，控制通路也需要增加相应的**比较器 (comparator)** 逻辑 。对于每个操作数，控制逻辑都需要将其源寄存器号与流水线中后续阶段所有指令的目的寄存器号进行比较。如果匹配，并且那条指令有效，控制逻辑就会控制MUX选择转发来的数据。

这种转发硬件的成本随着处理器并行度的增加而增长。对于一个发射宽度为 $n$ 的[超标量处理器](@entry_id:755658)，如果每个ALU操作数都能从后续所有 $3n$ 个可能的结果中选择（EX、MEM、WB各 $n$ 个），那么控制逻辑所需的比较器数量将以 $O(n^2)$ 的规模增长（每个操作数需要 $3n$ 个比较器，共 $2n$ 个操作数，总计 $6n^2$ 个比较器），而数据通路所需的MUX成本则以 $O(n)$ 增长。这揭示了高性能[处理器设计](@entry_id:753772)中控制逻辑复杂度的急剧膨胀 。

#### 控制冲突与分支预测

当流水线遇到分支指令时，在分支结果（是否跳转）和目标[地址计算](@entry_id:746276)出来之前，处理器无法确定下一条应该取哪条指令，这导致了**控制冲突 (control hazard)**。

为了减少分支指令带来的性能损失，现代处理器广泛使用**分支目标缓冲器 (Branch Target Buffer, BTB)**。BTB是一个小型高速缓存，它存储了最近执行过的分支指令的地址以及它们的跳转目标地址。在IF（取指）阶段，处理器用当前PC访问BTB。如果命中，就直接使用BTB提供的预测目标地址来获取下一条指令，从而避免了[流水线停顿](@entry_id:753463)。

但如果**BTB未命中 (miss)**，处理器就必须退回到“慢速路径” 。对于一条普通的PC相对分支，其目标地址需要在ID阶段解码出偏移量，然后在EX阶段通过ALU计算出来。从分支指令被取出、发现BTB未命中，到其在EX阶段算出正确的目标地址，这期间会经过数个时钟周期（例如，2个周期）。

在此期间，控制通路必须采取精确的措施。一种称为“未命中时插入气泡 (bubble-on-miss)”的策略要求：为了避免取到错误路径的指令（这会需要后续的冲刷操作，代价更高），控制单元必须在检测到BTB未命中的那一刻起，立即**暂停取指 (stall IF stage)**，并在后续的流水线中插入**气泡 (bubble)**，即无效操作（NOP）。暂停会一直持续到EX阶段计算出正确的目标地址为止，然后取指单元才会被导向到新的地址。这个过程展示了控制单元如何主动管理流水线的流动，以应对可预见的延迟事件 。

#### 高级控制：[推测执行](@entry_id:755202)与精确状态

现代高性能处理器将分支预测和[乱序执行](@entry_id:753020)结合，实现了**[推测执行](@entry_id:755202) (speculative execution)**。处理器会根据分支预测的结果，大胆地执行预测路径上的指令，即使前面的分支指令尚未最终解析。这极大地提升了性能，但也带来了一个严峻的挑战：如果预测错误，如何收场？

对于寄存器操作，**[寄存器重命名](@entry_id:754205) (register renaming)** 技术可以优雅地解决这个问题。但对于那些具有**不可逆副作用 (irreversible side-effects)** 的指令，如内存写操作、I/O操作，情况就复杂得多 。如果一条被[推测执行](@entry_id:755202)的STORE指令错误地将数据写入内存或一个I/O设备，这个操作通常是无法“撤销”的。

为了解决这个问题，处理器必须保证**精确状态 (precise state)**。这意味着，无论内部如何[乱序](@entry_id:147540)、推测地执行，从外部程序员的视角看，所有指令都必须像是严格按照程序顺序一条条执行完成的。当发生分支预测错误或异常时，处理器必须能够恢复到一个干净、正确的体系结构状态。

实现这一目标的核心机制是**将执行与提交解耦 (decoupling execution from commit)**。

- 所有指令在[乱序执行](@entry_id:753020)后，其结果并不会立即更新到最终的体系结构状态（如[主存](@entry_id:751652)或架构寄存器文件）。相反，它们的结果被保存在一个称为**[重排序缓冲](@entry_id:754246) (Reorder Buffer, ROB)** 的结构中。
- 指令按照原始的程序顺序被放入ROB，也必须严格按照这个顺序从ROB的头部**提交 (commit)** 或称**引退 (retire)**。
- 只有当一条指令到达ROB头部，并且确认它之前的所有分支预测都正确、没有发生任何异常时，它才被允许提交。
- 对于有副作用的指令，例如STORE指令，其执行结果（目标地址和数据）会被暂存在一个**存储缓冲 (Store Buffer/Queue)** 中。这个条目会一直被持有，直到对应的STORE指令在ROB中被提交。只有在提交的那一刻，数据才会被真正写入内存系统。对于CSR或I/O写操作，也采用类似的延迟写入机制。
- 如果检测到分支预测错误，所有在ROB中位于该分支指令之后的所有“年轻”指令都会被一次性**冲刷 (flush)**。它们在存储缓冲中对应的条目也会被一并丢弃。由于这些操作从未真正“发生”在体系结构状态上，因此不会留下任何痕迹，处理器状态得以完美恢复。

这个“执行-缓冲-有序提交”的模型是现代[乱序执行](@entry_id:753020)处理器控制通路设计的基石，它在追求极致性能的同时，保证了程序的正确性和可预测性 。

### 更广阔的视角：流式数据通路与流控

除了传统的冯·诺依曼[处理器流水线](@entry_id:753773)，许多计算系统（如网络处理器、GPU、硬件加速器）采用了**流式数据通路 (streaming datapath)** 的设计。在这种模型中，控制的核心问题从指令冲突管理转变为[数据流](@entry_id:748201)的顺畅传输，即**流控 (flow control)**。

流式系统中最经典的[握手协议](@entry_id:174594)是**有效/就绪 (valid/ready)** 机制 。
- 数据发送方（上游）用 `valid` 信号线来表示其输出数据是有效的。
- 数据接收方（下游）用 `ready` 信号线来表示它已准备好接收新数据。
- 只有当 `valid` 和 `ready` 在一个时钟周期内同时为高时，[数据传输](@entry_id:276754)才会发生。

如果下游因为繁忙而无法接收新数据，它会撤销（置低）其 `ready` 信号。上游检测到 `valid=1` 但 `ready=0` 时，必须保持其输出数据和 `valid` 信号不变，进入暂停状态。这种暂停状态会像涟漪一样向上游传播，这种现象称为**反压 (backpressure)**。

在没有缓冲的情况下，下游任何一个周期的暂停都会立刻导致整个上游流水线全线停摆。为了缓解这种情况，设计者会在流水级之间插入**弹性缓冲 (elastic buffer)**。一个容量为 $C$ 的缓冲器可以吸收 $C-1$ 个周期的下游暂停而无需向上游传递反压。例如，一个**滑带缓冲 (skid buffer)**，作为一种常见的容量为2的弹性缓冲，可以在下游暂停的第一个周期内吸收数据，从而让上游可以继续正常工作一拍。通过在[关键路径](@entry_id:265231)上配置深度合适的缓冲，可以有效地平滑掉突发性的暂停，[解耦](@entry_id:637294)上下游的性能波动，从而提升整个系统的吞吐率 。