{
    "hands_on_practices": [
        {
            "introduction": "A processor's maximum clock rate is not an arbitrary value; it is fundamentally determined by the physical characteristics of its circuits. In this exercise, you will step into the role of a hardware designer to tackle a core challenge in pipelined processor design: balancing the amount of work in each stage to minimize the clock period and thus maximize the clock frequency . This practice provides a concrete understanding of how the physical propagation delay of logic gates and register overheads directly constrain a CPU's top speed.",
            "id": "3627441",
            "problem": "A synchronous pipeline is built by inserting flip-flop registers between a fixed sequence of combinational blocks so that each pipeline stage contains a contiguous subsequence of blocks. The path delay within a stage is the sum of the delays of the blocks assigned to that stage. The clock period must be long enough for launched data to propagate through the slowest stage and meet the capture requirements of the receiving register, taking into account register timing overheads such as clock-to-output latency, setup time, and clock skew/uncertainty. Assume hold-time constraints are satisfied by design and interconnect delay is included in each given blockâ€™s delay.\n\nYou are given a strictly feed-forward datapath consisting of $8$ combinational blocks in a fixed order. The gate-level timing analysis reports the following worst-case propagation delays (in nanoseconds) for the blocks in order:\n$1.4$, $0.9$, $0.7$, $1.1$, $0.6$, $0.8$, $1.0$, $0.5$.\n\nYou may insert exactly $2$ sets of registers to form $d=3$ pipeline stages, and stages must be formed from contiguous groups of blocks in the given order. Every stage-to-stage register contributes the following overheads: clock-to-output latency of $0.10\\,\\mathrm{ns}$, setup time of $0.05\\,\\mathrm{ns}$, and clock skew/uncertainty budget of $0.02\\,\\mathrm{ns}$. Assume identical overheads for all stages.\n\nWhich option gives an optimal contiguous partition into $3$ stages that minimizes the maximum per-stage combinational delay and, based on that, the minimum achievable clock period and the corresponding maximum clock rate? Report the clock rate both in gigahertz (GHz) and megahertz (MHz), where gigahertz (GHz) and megahertz (MHz) respectively mean $10^{9}$ and $10^{6}$ cycles per second.\n\nA. Partition: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$. Minimum clock period $T_{\\min}=2.57\\,\\mathrm{ns}$; maximum clock rate $f_{\\max}\\approx 0.389\\,\\mathrm{GHz}=389\\,\\mathrm{MHz}$.\n\nB. Partition: $\\{1.4,\\,0.9,\\,0.7\\}\\,|\\,\\{1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$. Minimum clock period $T_{\\min}=3.17\\,\\mathrm{ns}$; maximum clock rate $f_{\\max}\\approx 0.316\\,\\mathrm{GHz}=316\\,\\mathrm{MHz}$.\n\nC. Partition: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1\\}\\,|\\,\\{0.6,\\,0.8,\\,1.0,\\,0.5\\}$. Minimum clock period $T_{\\min}=3.07\\,\\mathrm{ns}$; maximum clock rate $f_{\\max}\\approx 0.326\\,\\mathrm{GHz}=326\\,\\mathrm{MHz}$.\n\nD. Partition: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$. Minimum clock period $T_{\\min}=2.40\\,\\mathrm{ns}$; maximum clock rate $f_{\\max}\\approx 0.417\\,\\mathrm{GHz}=417\\,\\mathrm{MHz}$.",
            "solution": "The problem requires finding an optimal partitioning of a sequence of $8$ combinational blocks into $3$ contiguous pipeline stages to minimize the clock period. The minimum clock period is determined by the slowest stage, which is the stage with the maximum total delay. The total delay of a stage includes the propagation delay through its combinational logic and the overheads associated with the pipeline registers.\n\nFirst, we validate the problem statement.\n\n### Step 1: Extract Givens\n- Number of combinational blocks: $n=8$.\n- Propagation delays of the blocks in order ($t_1, \\dots, t_8$) in nanoseconds ($\\mathrm{ns}$): $1.4$, $0.9$, $0.7$, $1.1$, $0.6$, $0.8$, $1.0$, $0.5$.\n- Number of pipeline stages: $d=3$. This requires inserting $2$ sets of registers.\n- Stages must be formed from contiguous blocks.\n- Register timing overheads (identical for all stages):\n  - Clock-to-output latency, $t_{c-q} = 0.10\\,\\mathrm{ns}$.\n  - Setup time, $t_{setup} = 0.05\\,\\mathrm{ns}$.\n  - Clock skew/uncertainty, $t_{skew} = 0.02\\,\\mathrm{ns}$.\n- The objective is to find the partition that minimizes the maximum per-stage combinational delay and then calculate the minimum achievable clock period ($T_{\\min}$) and maximum clock rate ($f_{\\max}$).\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically sound, well-posed, and objective. It describes a standard optimization problem in digital pipeline design. The concepts used (combinational delay, register overheads, clock period) are fundamental to computer architecture. The provided values are realistic. All necessary information is present, and there are no contradictions. The problem is valid.\n\n### Step 3: Derivation of the Solution\n\nThe first step is to find the optimal partitioning of the $8$ blocks into $3$ contiguous stages. A partition is defined by two cut points. Let the first cut be after block $i$ and the second after block $j$, where $1 \\le i < j < 8$. The three stages will consist of blocks $\\{1, \\dots, i\\}$, $\\{i+1, \\dots, j\\}$, and $\\{j+1, \\dots, 8\\}$. We need to find the partition $(i, j)$ that minimizes the maximum combinational delay among the three stages. Let $T_k$ be the combinational delay of stage $k$. We want to find $\\min_{partitions} \\max(T_1, T_2, T_3)$.\n\nThe delays of the blocks are $t_1=1.4$, $t_2=0.9$, $t_3=0.7$, $t_4=1.1$, $t_5=0.6$, $t_6=0.8$, $t_7=1.0$, $t_8=0.5$ (all in $\\mathrm{ns}$). The total combinational delay is $1.4+0.9+0.7+1.1+0.6+0.8+1.0+0.5 = 7.0\\,\\mathrm{ns}$.\n\nLet's evaluate the partitions, focusing on those presented in the options, to find the one with the minimal maximum stage delay.\n\n1.  **Partition from Options A and D:** $\\{1.4, 0.9\\} | \\{0.7, 1.1, 0.6\\} | \\{0.8, 1.0, 0.5\\}$\n    - Stage 1 delay: $T_1 = 1.4 + 0.9 = 2.3\\,\\mathrm{ns}$.\n    - Stage 2 delay: $T_2 = 0.7 + 1.1 + 0.6 = 2.4\\,\\mathrm{ns}$.\n    - Stage 3 delay: $T_3 = 0.8 + 1.0 + 0.5 = 2.3\\,\\mathrm{ns}$.\n    - The maximum combinational delay for this partition is $t_{max\\_comb} = \\max(2.3, 2.4, 2.3) = 2.4\\,\\mathrm{ns}$.\n\n2.  **Partition from Option B:** $\\{1.4, 0.9, 0.7\\} | \\{1.1, 0.6\\} | \\{0.8, 1.0, 0.5\\}$\n    - Stage 1 delay: $T_1 = 1.4 + 0.9 + 0.7 = 3.0\\,\\mathrm{ns}$.\n    - Stage 2 delay: $T_2 = 1.1 + 0.6 = 1.7\\,\\mathrm{ns}$.\n    - Stage 3 delay: $T_3 = 0.8 + 1.0 + 0.5 = 2.3\\,\\mathrm{ns}$.\n    - The maximum combinational delay for this partition is $t_{max\\_comb} = \\max(3.0, 1.7, 2.3) = 3.0\\,\\mathrm{ns}$.\n\n3.  **Partition from Option C:** $\\{1.4, 0.9\\} | \\{0.7, 1.1\\} | \\{0.6, 0.8, 1.0, 0.5\\}$\n    - Stage 1 delay: $T_1 = 1.4 + 0.9 = 2.3\\,\\mathrm{ns}$.\n    - Stage 2 delay: $T_2 = 0.7 + 1.1 = 1.8\\,\\mathrm{ns}$.\n    - Stage 3 delay: $T_3 = 0.6 + 0.8 + 1.0 + 0.5 = 2.9\\,\\mathrm{ns}$.\n    - The maximum combinational delay for this partition is $t_{max\\_comb} = \\max(2.3, 1.8, 2.9) = 2.9\\,\\mathrm{ns}$.\n\nComparing the maximum combinational delays: $2.4\\,\\mathrm{ns}$ (for partition A/D), $3.0\\,\\mathrm{ns}$ (for B), and $2.9\\,\\mathrm{ns}$ (for C). The partition from A/D yields the minimum possible maximum stage delay. A more exhaustive search would confirm that $2.4\\,\\mathrm{ns}$ is indeed the optimal value. For example, a partition $\\{1.4, 0.9\\}, \\{0.7, 1.1, 0.6\\}, \\{0.8, 1.0, 0.5\\}$ with cuts after blocks $2$ and $5$ yields delays $\\{2.3, 2.4, 2.3\\}$, whose max is $2.4$. Another partition $\\{1.4\\}, \\{0.9, 0.7, 1.1\\}, \\{0.6, 0.8, 1.0, 0.5\\}$ yields delays $\\{1.4, 2.7, 2.9\\}$, whose max is $2.9$. The partition from A/D is indeed optimal.\n\nThe problem asks for the minimum achievable clock period based on this optimal partition. The formula for the minimum clock period, $T_{\\min}$, is the sum of the maximum combinational stage delay and the total register overhead:\n$$T_{\\min} = t_{max\\_comb} + t_{c-q} + t_{setup} + t_{skew}$$\nThe total register overhead is:\n$$t_{overhead} = 0.10\\,\\mathrm{ns} + 0.05\\,\\mathrm{ns} + 0.02\\,\\mathrm{ns} = 0.17\\,\\mathrm{ns}$$\nUsing the optimal maximum combinational delay, $t_{max\\_comb} = 2.4\\,\\mathrm{ns}$:\n$$T_{\\min} = 2.4\\,\\mathrm{ns} + 0.17\\,\\mathrm{ns} = 2.57\\,\\mathrm{ns}$$\nThe maximum achievable clock rate, $f_{\\max}$, is the reciprocal of the minimum clock period:\n$$f_{\\max} = \\frac{1}{T_{\\min}} = \\frac{1}{2.57 \\times 10^{-9}\\,\\mathrm{s}}$$\n$$f_{\\max} \\approx 0.389105... \\times 10^9\\,\\mathrm{Hz}$$\nConverting to gigahertz (GHz) and megahertz (MHz):\n$$f_{\\max} \\approx 0.389\\,\\mathrm{GHz} = 389\\,\\mathrm{MHz}$$\n\nNow, we evaluate each option based on these calculations.\n\n### Option-by-Option Analysis\n\n**A. Partition: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$. Minimum clock period $T_{\\min}=2.57\\,\\mathrm{ns}$; maximum clock rate $f_{\\max}\\approx 0.389\\,\\mathrm{GHz}=389\\,\\mathrm{MHz}$.**\n- **Partition:** This is the optimal partition that minimizes the maximum combinational stage delay ($2.4\\,\\mathrm{ns}$).\n- **Minimum Clock Period:** The calculated $T_{\\min} = 2.57\\,\\mathrm{ns}$ matches the value given in this option.\n- **Maximum Clock Rate:** The calculated $f_{\\max} \\approx 0.389\\,\\mathrm{GHz}=389\\,\\mathrm{MHz}$ also matches the values given.\n- **Verdict:** Correct.\n\n**B. Partition: $\\{1.4,\\,0.9,\\,0.7\\}\\,|\\,\\{1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$. Minimum clock period $T_{\\min}=3.17\\,\\mathrm{ns}$; maximum clock rate $f_{\\max}\\approx 0.316\\,\\mathrm{GHz}=316\\,\\mathrm{MHz}$.**\n- **Partition:** This partition is not optimal. Its maximum combinational delay is $3.0\\,\\mathrm{ns}$, which is greater than the optimal value of $2.4\\,\\mathrm{ns}$. Therefore, it does not lead to the minimum achievable clock period. The numbers presented ($T_{\\min} = 3.0\\,\\mathrm{ns} + 0.17\\,\\mathrm{ns} = 3.17\\,\\mathrm{ns}$ and $f_{\\max} = 1/3.17\\,\\mathrm{ns} \\approx 0.316\\,\\mathrm{GHz}$) are consistent for this specific partition, but the partition itself is suboptimal.\n- **Verdict:** Incorrect.\n\n**C. Partition: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1\\}\\,|\\,\\{0.6,\\,0.8,\\,1.0,\\,0.5\\}$. Minimum clock period $T_{\\min}=3.07\\,\\mathrm{ns}$; maximum clock rate $f_{\\max}\\approx 0.326\\,\\mathrm{GHz}=326\\,\\mathrm{MHz}$.**\n- **Partition:** This partition is not optimal. Its maximum combinational delay is $2.9\\,\\mathrm{ns}$, which is greater than the optimal value of $2.4\\,\\mathrm{ns}$. It does not lead to the minimum achievable clock period. Similar to option B, the subsequent calculations ($T_{\\min} = 2.9\\,\\mathrm{ns} + 0.17\\,\\mathrm{ns} = 3.07\\,\\mathrm{ns}$ and $f_{\\max} = 1/3.07\\,\\mathrm{ns} \\approx 0.326\\,\\mathrm{GHz}$) are consistent for the given suboptimal partition, but this does not answer the question.\n- **Verdict:** Incorrect.\n\n**D. Partition: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$. Minimum clock period $T_{\\min}=2.40\\,\\mathrm{ns}$; maximum clock rate $f_{\\max}\\approx 0.417\\,\\mathrm{GHz}=417\\,\\mathrm{MHz}$.**\n- **Partition:** This is the correct optimal partition.\n- **Minimum Clock Period:** The value given is $T_{\\min} = 2.40\\,\\mathrm{ns}$. This is the maximum combinational delay, $t_{max\\_comb}$, but it erroneously omits the total register overhead of $0.17\\,\\mathrm{ns}$. The correct minimum clock period is $2.57\\,\\mathrm{ns}$.\n- **Maximum Clock Rate:** The rate given is based on the incorrect period: $1/(2.40\\,\\mathrm{ns}) \\approx 0.417\\,\\mathrm{GHz}$. As the period is incorrect, so is the rate.\n- **Verdict:** Incorrect.\n\nBased on the analysis, only option A provides the correct optimal partition and the correctly calculated minimum clock period and maximum clock rate derived from it.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Once a processor's clock rate is set, overall performance is governed by the interplay between frequency ($f$), cycles per instruction ($CPI$), and instruction count ($IC$). This practice uses the classic CPU performance equation to analyze a common dilemma: is it more effective to improve hardware by increasing the clock rate or to improve software by reducing the number of instructions executed? By comparing the speedup from two different enhancement strategies, you will gain a deeper appreciation for how each component of the performance equation uniquely contributes to execution time .",
            "id": "3627419",
            "problem": "A single-threaded program executes on a given processor. Let the baseline program execution be characterized by an Instruction Count (IC) of $IC_0$, an average Cycles Per Instruction (CPI) of $CPI_0$, and a clock frequency $f_0$. Consider two possible improvements, each applied independently and each leaving $CPI$ unchanged:\n- Software improvement: the Instruction Count is reduced to $(1 - 0.2)\\,IC_0$ while the clock frequency remains $f_0$.\n- Hardware improvement: the clock frequency is increased to $(1 + 0.2)\\,f_0$ while the Instruction Count remains $IC_0$.\n\nUsing only fundamental definitions that relate program execution time, the number of cycles, and the clock frequency, derive the speedup in each case relative to the baseline and then compute the ratio\n$$\\frac{\\text{speedup due to software improvement}}{\\text{speedup due to hardware improvement}}.$$\nProvide your final answer as a reduced fraction. The ratio is unitless, so do not include units. Do not round; give the exact value.",
            "solution": "The analysis begins with the fundamental relationship governing processor performance. The total execution time, $T$, of a program is determined by the number of instructions executed (Instruction Count, $IC$), the average number of clock cycles required per instruction ($CPI$), and the processor's clock cycle time ($\\tau_c$) or its inverse, the clock frequency ($f = \\frac{1}{\\tau_c}$). The relationship is given by:\n$$T = IC \\times CPI \\times \\tau_c = \\frac{IC \\times CPI}{f}$$\n\nWe are tasked with evaluating the speedup resulting from two independent improvements relative to a baseline execution. Speedup, $S$, is defined as the ratio of the execution time before the improvement ($T_{old}$) to the execution time after the improvement ($T_{new}$):\n$$S = \\frac{T_{old}}{T_{new}}$$\n\nFirst, we establish the baseline execution time, $T_0$, using the given initial parameters:\n$$T_0 = \\frac{IC_0 \\times CPI_0}{f_0}$$\n\nNext, we analyze the software improvement. Let the new parameters be denoted with a subscript 'sw'.\nThe Instruction Count is reduced to $(1 - 0.2)$ of the original: $IC_{sw} = (1 - 0.2)IC_0 = 0.8 IC_0$.\nThe $CPI$ and clock frequency remain unchanged: $CPI_{sw} = CPI_0$ and $f_{sw} = f_0$.\nThe execution time after the software improvement, $T_{sw}$, is:\n$$T_{sw} = \\frac{IC_{sw} \\times CPI_{sw}}{f_{sw}} = \\frac{(0.8 IC_0) \\times CPI_0}{f_0}$$\nThe speedup due to the software improvement, $S_{sw}$, is the ratio of the baseline time to the new time:\n$$S_{sw} = \\frac{T_0}{T_{sw}} = \\frac{\\frac{IC_0 \\times CPI_0}{f_0}}{\\frac{0.8 IC_0 \\times CPI_0}{f_0}}$$\nThe terms $IC_0$, $CPI_0$, and $f_0$ cancel out, yielding:\n$$S_{sw} = \\frac{1}{0.8} = \\frac{1}{\\frac{8}{10}} = \\frac{10}{8} = \\frac{5}{4}$$\n\nNow, we analyze the hardware improvement. Let the new parameters be denoted with a subscript 'hw'.\nThe clock frequency is increased to $(1 + 0.2)$ of the original: $f_{hw} = (1 + 0.2)f_0 = 1.2 f_0$.\nThe Instruction Count and $CPI$ remain unchanged: $IC_{hw} = IC_0$ and $CPI_{hw} = CPI_0$.\nThe execution time after the hardware improvement, $T_{hw}$, is:\n$$T_{hw} = \\frac{IC_{hw} \\times CPI_{hw}}{f_{hw}} = \\frac{IC_0 \\times CPI_0}{1.2 f_0}$$\nThe speedup due to the hardware improvement, $S_{hw}$, is the ratio of the baseline time to this new time:\n$$S_{hw} = \\frac{T_0}{T_{hw}} = \\frac{\\frac{IC_0 \\times CPI_0}{f_0}}{\\frac{IC_0 \\times CPI_0}{1.2 f_0}}$$\nThe terms $IC_0$, $CPI_0$, and $f_0$ cancel out, yielding:\n$$S_{hw} = \\frac{1}{\\frac{1}{1.2}} = 1.2 = \\frac{12}{10} = \\frac{6}{5}$$\n\nFinally, we compute the required ratio of the speedup from the software improvement to the speedup from the hardware improvement:\n$$\\frac{S_{sw}}{S_{hw}} = \\frac{\\frac{5}{4}}{\\frac{6}{5}}$$\nTo divide by a fraction, we multiply by its reciprocal:\n$$\\frac{S_{sw}}{S_{hw}} = \\frac{5}{4} \\times \\frac{5}{6} = \\frac{5 \\times 5}{4 \\times 6} = \\frac{25}{24}$$\nThis fraction is already in its reduced form, as the numerator is $5^2$ and the denominator is $2^3 \\times 3$, so there are no common factors.",
            "answer": "$$\\boxed{\\frac{25}{24}}$$"
        },
        {
            "introduction": "Modern performance analysis requires looking beyond the CPU core to the entire system, especially the memory hierarchy. This problem explores a more realistic performance model where execution time is a mix of frequency-dependent CPU work and frequency-independent memory latency. You will discover how changing the clock speed can alter which function in a program becomes the performance \"hotspot,\" a critical insight for developers using profiling tools to optimize software on systems with features like Dynamic Voltage and Frequency Scaling (DVFS) .",
            "id": "3627421",
            "problem": "A software profiler running on a modern processor reports per-function cycle counts that include all pipeline activity and stalls. Consider a workload with two dominant functions, labeled $A$ and $B$. In a microarchitectural model that suppresses main memory latency, function $A$ executes $c_{A} = 2.0 \\times 10^{9}$ non-memory cycles per run, and function $B$ executes $c_{B} = 1.0 \\times 10^{9}$ non-memory cycles per run. Across a typical run on real hardware, each main memory access incurs an absolute delay of $L = 50 \\times 10^{-9}$ seconds regardless of the core frequency, due to the external memory device. Function $A$ performs $m_{A} = 12{,}000{,}000$ main memory accesses per run, and function $B$ performs $m_{B} = 18{,}666{,}667$ main memory accesses per run. Assume that the processor uses Dynamic Voltage and Frequency Scaling (DVFS), so the core clock frequency $f$ can vary between runs, with clock cycle time $T = 1/f$.\n\nStarting only from the core definitions that execution time equals the number of cycles multiplied by the clock cycle time and that each main-memory access contributes a fixed absolute delay $L$ to the run, derive from first principles an expression for the execution time $t_{i}(f)$ of function $i \\in \\{A, B\\}$ as a function of $f$, $c_{i}$, $m_{i}$, and $L$. Then, determine the threshold frequency $f^{\\*}$ at which $t_{A}(f^{\\*}) = t_{B}(f^{\\*})$. Finally, briefly explain why the ranking of hotspots by time can differ between runs when $f$ changes across $f^{\\*}$.\n\nRound your final numerical answer for $f^{\\*}$ to four significant figures and express it in gigahertz (GHz).",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective, representing a standard performance modeling exercise in computer architecture.\n\nThe total execution time of a function is modeled as the sum of the time spent on non-memory processor cycles and the total delay from main memory accesses.\n\nLet $t_{i}(f)$ be the execution time for a function $i \\in \\{A, B\\}$ running on a processor with core clock frequency $f$. Let $c_{i}$ be the number of non-memory cycles and $m_{i}$ be the number of main memory accesses for function $i$. The clock cycle time is $T = 1/f$. Each main memory access incurs a fixed, absolute delay of $L$.\n\nThe time spent on non-memory cycles is the product of the number of cycles and the duration of each cycle:\n$$\n\\text{Time}_{\\text{cycles}} = c_{i} \\times T = \\frac{c_{i}}{f}\n$$\nThe total delay from main memory accesses is the product of the number of accesses and the fixed delay per access:\n$$\n\\text{Time}_{\\text{memory}} = m_{i} \\times L\n$$\nBased on the problem's definition, the total execution time $t_{i}(f)$ is the sum of these two components. This gives the expression for the execution time of function $i$ as a function of $f$:\n$$\nt_{i}(f) = \\frac{c_{i}}{f} + m_{i}L\n$$\nThis is the required expression derived from first principles. For the two functions $A$ and $B$, the execution times are:\n$$\nt_{A}(f) = \\frac{c_{A}}{f} + m_{A}L\n$$\n$$\nt_{B}(f) = \\frac{c_{B}}{f} + m_{B}L\n$$\nNext, we determine the threshold frequency $f^{\\*}$ at which the execution times of the two functions are equal, i.e., $t_{A}(f^{\\*}) = t_{B}(f^{\\*})$.\n$$\n\\frac{c_{A}}{f^{\\*}} + m_{A}L = \\frac{c_{B}}{f^{\\*}} + m_{B}L\n$$\nTo solve for $f^{\\*}$, we rearrange the terms to isolate $f^{\\*}$:\n$$\n\\frac{c_{A}}{f^{\\*}} - \\frac{c_{B}}{f^{\\*}} = m_{B}L - m_{A}L\n$$\n$$\n\\frac{c_{A} - c_{B}}{f^{\\*}} = (m_{B} - m_{A})L\n$$\nProvided that $c_A \\neq c_B$ and $m_A \\neq m_B$, we can write:\n$$\nf^{\\*} = \\frac{c_{A} - c_{B}}{(m_{B} - m_{A})L}\n$$\nNow, we substitute the given numerical values:\n-   $c_{A} = 2.0 \\times 10^{9}$\n-   $c_{B} = 1.0 \\times 10^{9}$\n-   $m_{A} = 12,000,000 = 1.2 \\times 10^{7}$\n-   $m_{B} = 18,666,667$\n-   $L = 50 \\times 10^{-9}$ s\n\nFirst, we calculate the differences:\n$$\nc_{A} - c_{B} = (2.0 \\times 10^{9}) - (1.0 \\times 10^{9}) = 1.0 \\times 10^{9}\n$$\n$$\nm_{B} - m_{A} = 18,666,667 - 12,000,000 = 6,666,667\n$$\nNow, substitute these into the expression for $f^{\\*}$:\n$$\nf^{\\*} = \\frac{1.0 \\times 10^{9}}{6,666,667 \\times (50 \\times 10^{-9})} = \\frac{1.0 \\times 10^{9}}{333,333,350 \\times 10^{-9}} = \\frac{1.0 \\times 10^{9}}{0.33333335}\n$$\n$$\nf^{\\*} \\approx 2,999,999,850 \\text{ Hz}\n$$\nThis frequency is equivalent to $2.999999850$ GHz. The problem requires rounding this value to four significant figures.\n$$\nf^{\\*} \\approx 3.000 \\text{ GHz} = 3.000 \\times 10^{9} \\text{ Hz}\n$$\n\nFinally, we explain why the ranking of hotspots by time can differ when the clock frequency $f$ changes across the threshold $f^{\\*}$.\nA hotspot is a function that consumes the most execution time. The ranking depends on the comparison between $t_{A}(f)$ and $t_{B}(f)$. The execution time is composed of a frequency-dependent term (computation time, $c_{i}/f$) and a frequency-independent term (memory access time, $m_{i}L$).\n\nFunction $A$ is more compute-intensive ($c_{A} > c_{B}$), while function $B$ is more memory-intensive ($m_{B} > m_{A}$).\n-   When the frequency $f$ is low ($f < f^{\\*}$) and the cycle time $T=1/f$ is long, the computation time component $c_{i}/f$ is large and tends to dominate the total execution time. Since $c_{A} > c_{B}$, it follows that $t_{A}(f) > t_{B}(f)$. In this regime, function $A$ is the primary hotspot.\n-   When the frequency $f$ is high ($f > f^{\\*}$) and the cycle time $T=1/f$ is short, the computation time $c_{i}/f$ becomes smaller, and the constant memory access time $m_{i}L$ becomes a more significant contributor to the total execution time. Since $m_{B} > m_{A}$, the total memory delay for function $B$ is greater than for function $A$. For sufficiently high $f$, this term dominates, leading to $t_{B}(f) > t_{A}(f)$. In this regime, function $B$ becomes the primary hotspot.\n\nThe threshold frequency $f^{\\*}$ is precisely the crossover point where the relative dominance of the compute-bound and memory-bound characteristics of the functions inverts. Thus, changing the processor frequency across this threshold $f^{\\*}$ can change which function takes longer to execute, thereby altering the hotspot ranking.",
            "answer": "$$\\boxed{3.000}$$"
        }
    ]
}