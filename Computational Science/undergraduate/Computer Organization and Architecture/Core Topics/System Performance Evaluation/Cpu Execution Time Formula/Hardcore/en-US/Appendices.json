{
    "hands_on_practices": [
        {
            "introduction": "Improving processor performance is often a game of trade-offs. An optimization that reduces the cycle count for one type of instruction might inadvertently increase the total number of instructions. This exercise  explores a classic compiler optimization, strength reduction, where costly division operations are replaced by faster multiplications. You will quantitatively analyze whether the benefit of a lower $CPI$ for these operations outweighs the overhead of additional instructions.",
            "id": "3631100",
            "problem": "A program runs on a single-core Central Processing Unit (CPU) whose pipeline yields different cycle counts across instruction classes due to microarchitectural latencies. The dynamic instruction mix before any transformation is as follows: arithmetic division instructions comprise $5\\%$ of the executed instructions and take $12$ cycles each; arithmetic multiplication instructions comprise $10\\%$ of the executed instructions and take $4$ cycles each; add, subtract, and logic instructions comprise $35\\%$ of the executed instructions and take $1$ cycle each; load and store instructions comprise $35\\%$ of the executed instructions and take $2$ cycles each; control-transfer (branch) instructions comprise $15\\%$ of the executed instructions and take $3$ cycles each. A semantics-preserving code transformation replaces every arithmetic division operation with an equivalent multiplication by a precomputed reciprocal, thereby changing those $5\\%$ of instructions from $12$ cycles to $4$ cycles. The transformation also introduces additional bookkeeping in the form of extra add instructions equal to $2\\%$ of the original instruction count, each costing $1$ cycle. Assume the clock frequency is unchanged and the transformation does not alter the cycle period.\n\nUsing only foundational definitions of execution cycles and time, determine the net change in total execution time as a multiplicative factor, $T_{\\text{new}}/T_{\\text{old}}$. Round your answer to four significant figures. Since the requested quantity is dimensionless, no unit is required.",
            "solution": "The foundational definitions we use are: (1) total execution time $T$ equals the product of the total number of clock cycles and the clock cycle period, and (2) the total number of clock cycles equals the sum, over all executed instructions, of the cycles used per instruction. Equivalently, if $IC$ denotes the total dynamic Instruction Count (IC) and $\\overline{CPI}$ denotes the average Cycles Per Instruction (CPI), then the total cycles equal $IC \\times \\overline{CPI}$, and $T = IC \\times \\overline{CPI} \\times t_{c}$, where $t_{c}$ is the cycle period. When comparing two versions at the same $t_{c}$, the ratio of execution times equals the ratio of total cycle counts.\n\nLet the original instruction count be $N$. The original class counts are:\n- divisions: $0.05N$, each costing $12$ cycles, contributing $0.05N \\times 12 = 0.60N$ cycles,\n- multiplications: $0.10N$, each costing $4$ cycles, contributing $0.10N \\times 4 = 0.40N$ cycles,\n- add/logic: $0.35N$, each costing $1$ cycle, contributing $0.35N \\times 1 = 0.35N$ cycles,\n- memory (loads/stores): $0.35N$, each costing $2$ cycles, contributing $0.35N \\times 2 = 0.70N$ cycles,\n- branches: $0.15N$, each costing $3$ cycles, contributing $0.15N \\times 3 = 0.45N$ cycles.\n\nThus the original total cycles are\n$$\n\\text{cycles}_{\\text{old}} = (0.60 + 0.40 + 0.35 + 0.70 + 0.45)N = 2.50N,\n$$\nso the original average $CPI$ is\n$$\n\\overline{CPI}_{\\text{old}} = \\frac{\\text{cycles}_{\\text{old}}}{N} = 2.50.\n$$\n\nAfter transformation, all division instructions are replaced by multiplications with $4$ cycles, so divisions contribute $0$, and the multiplication count increases by $0.05N$ to $0.15N$; these contribute $0.15N \\times 4 = 0.60N$ cycles. The transformation also adds $0.02N$ extra add instructions at $1$ cycle each, increasing add/logic from $0.35N$ to $0.37N$, which contributes $0.37N \\times 1 = 0.37N$ cycles. Memory and branch counts remain $0.35N$ and $0.15N$, contributing $0.35N \\times 2 = 0.70N$ and $0.15N \\times 3 = 0.45N$ cycles, respectively. Therefore, the new total cycles are\n$$\n\\text{cycles}_{\\text{new}} = (0.60 + 0.37 + 0.70 + 0.45)N = 2.12N.\n$$\n\nThe new instruction count is $N_{\\text{new}} = 1.02N$, so the new average $CPI$ is\n$$\n\\overline{CPI}_{\\text{new}} = \\frac{\\text{cycles}_{\\text{new}}}{N_{\\text{new}}} = \\frac{2.12N}{1.02N} = \\frac{2.12}{1.02}.\n$$\n\nThe net change in execution time, as a multiplicative factor, is\n$$\n\\frac{T_{\\text{new}}}{T_{\\text{old}}} = \\frac{\\text{cycles}_{\\text{new}}}{\\text{cycles}_{\\text{old}}} = \\frac{2.12N}{2.50N} = \\frac{2.12}{2.50} = 0.848.\n$$\n\nRounding to four significant figures yields $0.8480$.",
            "answer": "$$\\boxed{0.8480}$$"
        },
        {
            "introduction": "The average $CPI$ is not a single, fixed number; it is a composite value heavily influenced by memory system performance. Stalls from cache misses and TLB misses can add significant overhead to the base execution cycles. This practice  models a real-world web server scenario, demonstrating how techniques like HTTP keep-alive can improve performance by \"warming up\" caches and TLBs, thereby reducing miss rates and overall request latency.",
            "id": "3631109",
            "problem": "A web server runs on a Central Processing Unit (CPU) with clock frequency $f = 3.2 \\times 10^{9} \\text{ cycles/s}$. For the application logic of a single HTTP request, the dynamic instruction count is $IC = 2.5 \\times 10^{6}$ instructions. The base cycles per instruction (with all memory hierarchy hits) is $\\mathrm{CPI}_{\\mathrm{base}} = 0.8$. Memory stalls arise from the instruction cache (I-cache), data cache (D-cache), and the Translation Lookaside Buffer (TLB) for both instruction fetches (iTLB) and data accesses (dTLB). Assume the following:\n- Each instruction fetches one instruction from the I-cache.\n- The average number of data memory references per instruction is $m_{d} = 0.35$.\n- Miss penalties (in cycles) are: I-cache $= 30$, D-cache $= 40$, TLB (both iTLB and dTLB) $= 100$.\n- Under a cold connection (no reuse), the miss rates are: I-cache per instruction $r_{I,\\mathrm{cold}} = 0.004$, D-cache per data reference $r_{D,\\mathrm{cold}} = 0.02$, iTLB per instruction $r_{i,\\mathrm{cold}} = 0.0002$, dTLB per data reference $r_{d,\\mathrm{cold}} = 0.0005$.\n- Under a warm state (with reuse), the miss rates are: I-cache per instruction $r_{I,\\mathrm{warm}} = 0.0005$, D-cache per data reference $r_{D,\\mathrm{warm}} = 0.003$, iTLB per instruction $r_{i,\\mathrm{warm}} = 0.00005$, dTLB per data reference $r_{d,\\mathrm{warm}} = 0.0001$.\n\nInitially, the server does not use HTTP persistent connections (keep-alive), so every request experiences cold behavior. The server then enables keep-alive, and each connection carries on average $k = 8$ requests: the first request per connection is cold and each subsequent request is warm. Assume that stall penalties from I-cache, D-cache, iTLB, and dTLB are additive with no overlap, that $\\mathrm{CPI}_{\\mathrm{base}}$ and penalties do not change, and that the instruction count $IC$ per request is unchanged by keep-alive.\n\nUsing only core definitions of cycles, time, and average cycles per instruction, compute the average reduction in CPU execution time per request, defined as\n$$\\Delta T = T_{\\text{no KA}} - T_{\\text{with KA}},$$\nwhere $T_{\\mathrm{no\\ KA}}$ is the CPU time per request when every request is cold, and $T_{\\mathrm{with\\ KA}}$ is the average CPU time per request when each connection has one cold request and $k-1$ warm requests. Express your final answer in microseconds and round your answer to four significant figures.",
            "solution": "The problem requires the calculation of the average reduction in CPU execution time per request when HTTP persistent connections (keep-alive) are enabled. The fundamental relationship governing CPU execution time is given by the CPU performance equation:\n$$T_{CPU} = \\frac{N_{cycles}}{f}$$\nwhere $T_{CPU}$ is the execution time in seconds, $N_{cycles}$ is the total number of CPU cycles, and $f$ is the clock frequency in cycles per second. The total number of cycles can be expressed as the product of the instruction count ($IC$) and the average cycles per instruction ($\\mathrm{CPI}$):\n$$N_{cycles} = IC \\times \\mathrm{CPI}$$\nCombining these, the execution time for a single request is:\n$$T = \\frac{IC \\times \\mathrm{CPI}}{f}$$\nThe total $\\mathrm{CPI}$ is the sum of the base $\\mathrm{CPI}$ (assuming no memory stalls) and the additional $\\mathrm{CPI}$ contributed by various stall sources. The problem states that stalls from the I-cache, D-cache, iTLB, and dTLB are additive.\n$$\\mathrm{CPI}_{total} = \\mathrm{CPI}_{\\mathrm{base}} + \\mathrm{CPI}_{\\mathrm{stalls}}$$\n$$\\mathrm{CPI}_{\\mathrm{stalls}} = \\mathrm{CPI}_{I} + \\mathrm{CPI}_{D} + \\mathrm{CPI}_{iTLB} + \\mathrm{CPI}_{dTLB}$$\nThe stall CPI for each component is the product of the number of memory accesses of that type per instruction, the miss rate for that access type, and the corresponding miss penalty in cycles.\n\n1.  **Instruction Cache (I-cache) stalls per instruction**: Each instruction requires one fetch.\n    $$\\mathrm{CPI}_{I} = (\\text{misses per instruction}) \\times (\\text{miss penalty}) = r_{I} \\times P_{I}$$\n2.  **Data Cache (D-cache) stalls per instruction**: There are $m_d$ data references per instruction.\n    $$\\mathrm{CPI}_{D} = (\\text{data refs per instruction}) \\times (\\text{miss rate per ref}) \\times (\\text{miss penalty}) = m_{d} \\times r_{D} \\times P_{D}$$\n3.  **Instruction TLB (iTLB) stalls per instruction**: Each instruction fetch is a memory access that needs translation.\n    $$\\mathrm{CPI}_{iTLB} = (\\text{instruction fetches per instruction}) \\times (\\text{miss rate per fetch}) \\times (\\text{miss penalty}) = 1 \\times r_{i} \\times P_{T} = r_{i} \\times P_{T}$$\n4.  **Data TLB (dTLB) stalls per instruction**: Each data reference is a memory access that needs translation.\n    $$\\mathrm{CPI}_{dTLB} = (\\text{data refs per instruction}) \\times (\\text{miss rate per ref}) \\times (\\text{miss penalty}) = m_{d} \\times r_{d} \\times P_{T}$$\n\nCombining these, the general expression for the total $\\mathrm{CPI}$ is:\n$$\\mathrm{CPI} = \\mathrm{CPI}_{\\mathrm{base}} + r_{I}P_{I} + m_{d}r_{D}P_{D} + r_{i}P_{T} + m_{d}r_{d}P_{T}$$\n\nWe are given the following parameters:\n- $\\mathrm{CPI}_{\\mathrm{base}} = 0.8$\n- $m_{d} = 0.35$\n- $P_{I} = 30$ cycles\n- $P_{D} = 40$ cycles\n- $P_{T} = 100$ cycles\n\nFirst, we calculate $\\mathrm{CPI}$ for a cold request, $\\mathrm{CPI}_{\\mathrm{cold}}$, using the cold miss rates:\n$r_{I,\\mathrm{cold}} = 0.004$, $r_{D,\\mathrm{cold}} = 0.02$, $r_{i,\\mathrm{cold}} = 0.0002$, $r_{d,\\mathrm{cold}} = 0.0005$.\n$$\\mathrm{CPI}_{\\mathrm{cold}} = 0.8 + (0.004)(30) + (0.35)(0.02)(40) + (0.0002)(100) + (0.35)(0.0005)(100)$$\n$$\\mathrm{CPI}_{\\mathrm{cold}} = 0.8 + 0.12 + 0.28 + 0.02 + 0.0175 = 1.2375$$\n\nNext, we calculate $\\mathrm{CPI}$ for a warm request, $\\mathrm{CPI}_{\\mathrm{warm}}$, using the warm miss rates:\n$r_{I,\\mathrm{warm}} = 0.0005$, $r_{D,\\mathrm{warm}} = 0.003$, $r_{i,\\mathrm{warm}} = 0.00005$, $r_{d,\\mathrm{warm}} = 0.0001$.\n$$\\mathrm{CPI}_{\\mathrm{warm}} = 0.8 + (0.0005)(30) + (0.35)(0.003)(40) + (0.00005)(100) + (0.35)(0.0001)(100)$$\n$$\\mathrm{CPI}_{\\mathrm{warm}} = 0.8 + 0.015 + 0.042 + 0.005 + 0.0035 = 0.8655$$\n\nNow we can determine the execution times for the two scenarios.\n**Scenario 1: No Keep-Alive ($T_{\\mathrm{no\\ KA}}$)**\nIn this scenario, every request is a cold request. The CPU time per request is:\n$$T_{\\mathrm{no\\ KA}} = \\frac{IC \\times \\mathrm{CPI}_{\\mathrm{cold}}}{f}$$\n\n**Scenario 2: With Keep-Alive ($T_{\\mathrm{with\\ KA}}$)**\nIn this scenario, a connection consists of $k=8$ requests: one cold request and $k-1=7$ warm requests. The total number of cycles for one connection is:\n$$N_{cycles, conn} = (IC \\times \\mathrm{CPI}_{\\mathrm{cold}}) \\times 1 + (IC \\times \\mathrm{CPI}_{\\mathrm{warm}}) \\times (k-1)$$\nThe average CPU time per request, $T_{\\mathrm{with\\ KA}}$, is the total time for the connection divided by the number of requests, $k$:\n$$T_{\\mathrm{with\\ KA}} = \\frac{N_{cycles, conn}}{k \\times f} = \\frac{IC \\times (\\mathrm{CPI}_{\\mathrm{cold}} + (k-1)\\mathrm{CPI}_{\\mathrm{warm}})}{k \\times f}$$\n\nThe problem asks for the average reduction in CPU execution time per request, $\\Delta T$:\n$$\\Delta T = T_{\\mathrm{no\\ KA}} - T_{\\mathrm{with\\ KA}}$$\nSubstituting the expressions for the times:\n$$\\Delta T = \\frac{IC \\times \\mathrm{CPI}_{\\mathrm{cold}}}{f} - \\frac{IC \\times (\\mathrm{CPI}_{\\mathrm{cold}} + (k-1)\\mathrm{CPI}_{\\mathrm{warm}})}{k \\times f}$$\nWe can factor out $\\frac{IC}{f}$:\n$$\\Delta T = \\frac{IC}{f} \\left( \\mathrm{CPI}_{\\mathrm{cold}} - \\frac{\\mathrm{CPI}_{\\mathrm{cold}} + (k-1)\\mathrm{CPI}_{\\mathrm{warm}}}{k} \\right)$$\nPutting the terms in the parenthesis over a common denominator $k$:\n$$\\Delta T = \\frac{IC}{f} \\left( \\frac{k\\mathrm{CPI}_{\\mathrm{cold}} - (\\mathrm{CPI}_{\\mathrm{cold}} + (k-1)\\mathrm{CPI}_{\\mathrm{warm}})}{k} \\right)$$\n$$\\Delta T = \\frac{IC}{f} \\left( \\frac{(k-1)\\mathrm{CPI}_{\\mathrm{cold}} - (k-1)\\mathrm{CPI}_{\\mathrm{warm}}}{k} \\right)$$\nThis simplifies to:\n$$\\Delta T = \\frac{IC \\times (k-1)}{f \\times k} \\left(\\mathrm{CPI}_{\\mathrm{cold}} - \\mathrm{CPI}_{\\mathrm{warm}}\\right)$$\nThis expression represents the total time saved across the $k-1$ warm requests, amortized over all $k$ requests in the connection.\n\nNow, we substitute the known values into this final expression:\n$IC = 2.5 \\times 10^{6}$\n$f = 3.2 \\times 10^{9}$\n$k = 8$\n$\\mathrm{CPI}_{\\mathrm{cold}} = 1.2375$\n$\\mathrm{CPI}_{\\mathrm{warm}} = 0.8655$\n$$\\Delta T = \\frac{(2.5 \\times 10^{6}) \\times (8-1)}{(3.2 \\times 10^{9}) \\times 8} \\left(1.2375 - 0.8655\\right)$$\n$$\\Delta T = \\frac{2.5 \\times 10^{6} \\times 7}{25.6 \\times 10^{9}} \\left(0.372\\right)$$\n$$\\Delta T = \\frac{17.5 \\times 10^{6}}{25.6 \\times 10^{9}} \\times 0.372$$\n$$\\Delta T \\approx (0.68359375 \\times 10^{-3}) \\times 0.372$$\n$$\\Delta T \\approx 0.000254296875 \\text{ s}$$\nThe problem requires the answer in microseconds ($\\mu\\mathrm{s}$), where $1 \\text{ s} = 10^{6} \\mu\\mathrm{s}$.\n$$\\Delta T \\approx 0.000254296875 \\times 10^{6} \\mu\\mathrm{s} = 254.296875 \\mu\\mathrm{s}$$\nRounding to four significant figures, we get:\n$$\\Delta T \\approx 254.3 \\mu\\mathrm{s}$$",
            "answer": "$$\\boxed{254.3}$$"
        },
        {
            "introduction": "In modern processor design, speed is not the only goal; energy efficiency is equally critical. This problem  introduces the concept of Dynamic Voltage and Frequency Scaling (DVFS) and a key metric for evaluating efficiency: the Energy-Delay Product ($EDP$). By analyzing how power and execution time scale with frequency, you will determine the optimal operating point that provides the best balance between performance and energy consumption.",
            "id": "3631106",
            "problem": "A single-threaded program executes on a Central Processing Unit (CPU) that supports Dynamic Voltage and Frequency Scaling (DVFS). Over the supported DVFS range, the cycles per instruction (CPI) of the program is invariant with frequency, and the program executes a fixed instruction count. The CPUâ€™s dynamic power dominates and obeys a measured scaling law with clock frequency $f$: the average power satisfies $P \\propto f^{\\gamma}$ with $\\gamma = 3$ for this design over its safe operating region. The execution time $T$ for the fixed program is determined by the number of cycles times the clock period. The processor allows the clock frequency $f$ to be set anywhere in the closed interval $[1.2, 3.6]$ GHz.\n\nDefine the energy-delay product (EDP) of running the program once as $EDP = E \\cdot T$, where $E$ is the total energy consumed during the run and $T$ is the execution time. Assume steady-state average power during the run, negligible leakage, and that voltage scaling consistent with the given power law is already embedded in the empirically observed exponent $\\gamma$.\n\nUsing only fundamental definitions of execution time and energy, and the stated scaling law, determine the single operating frequency $f$ within the allowed interval that minimizes $EDP$ for this program. Express your final answer in GHz and round your answer to three significant figures.",
            "solution": "The problem asks to determine the operating frequency $f$ within a specified range that minimizes the energy-delay product (EDP) for a program running on a CPU with Dynamic Voltage and Frequency Scaling (DVFS).\n\nFirst, we must formulate the energy-delay product, defined as $EDP = E \\cdot T$, as a function of the clock frequency $f$. This requires finding expressions for the execution time $T$ and the total energy consumed $E$ in terms of $f$.\n\nThe execution time $T$ of a program is given by the total number of cycles required to execute the program divided by the clock frequency.\n$$T = \\frac{\\text{Number of Cycles}}{\\text{Clock Frequency}}$$\nThe total number of cycles is the product of the instruction count ($IC$) and the average cycles per instruction ($CPI$). The problem states that both $IC$ and $CPI$ are constant for this program, regardless of the operating frequency. Let us denote the constant total number of cycles as $N_c = IC \\cdot CPI$.\nThus, the execution time $T$ as a function of frequency $f$ is:\n$$T(f) = \\frac{N_c}{f}$$\nThis shows that execution time is inversely proportional to the clock frequency, $T \\propto f^{-1}$.\n\nNext, we determine the total energy consumed, $E$. Energy is the integral of power over time. Assuming a steady-state average power $P$ during the execution time $T$, the energy is simply their product:\n$$E = P \\cdot T$$\nThe problem states that the average power $P$ scales with frequency $f$ according to the law $P \\propto f^{\\gamma}$, with the exponent $\\gamma = 3$. We can express this relationship with a constant of proportionality, $k_P$:\n$$P(f) = k_P f^{\\gamma} = k_P f^{3}$$\nwhere $k_P$ is a positive constant that depends on the specifics of the circuit design and program activity.\n\nNow we can write the energy $E$ as a function of frequency $f$ by substituting the expressions for $P(f)$ and $T(f)$:\n$$E(f) = P(f) \\cdot T(f) = (k_P f^{3}) \\cdot \\left(\\frac{N_c}{f}\\right) = k_P N_c f^{2}$$\nThis shows that the energy consumption is proportional to the square of the clock frequency, $E \\propto f^{2}$.\n\nWith expressions for both $E(f)$ and $T(f)$, we can now write the energy-delay product $EDP$ as a function of $f$:\n$$EDP(f) = E(f) \\cdot T(f)$$\nSubstituting the derived functions:\n$$EDP(f) = (k_P N_c f^{2}) \\cdot \\left(\\frac{N_c}{f}\\right) = k_P N_c^2 f$$\nLet's define a new constant $K = k_P N_c^2$. Since $k_P > 0$ and $N_c > 0$, the constant $K$ is also positive. The expression simplifies to:\n$$EDP(f) = K f$$\nThe energy-delay product is directly proportional to the clock frequency $f$.\n\nThe task is to find the frequency $f$ that minimizes $EDP(f)$ within the allowed closed interval $[1.2, 3.6]$ GHz. The function $EDP(f) = K f$ is a linear function of $f$ with a positive slope $K$. A monotonically increasing function over a closed interval attains its minimum value at the lower bound of the interval.\n\nThe given interval for the frequency $f$ is $[1.2, 3.6]$ GHz.\nTherefore, the frequency that minimizes the $EDP$ is the lowest possible frequency in this range:\n$$f_{optimal} = f_{min} = 1.2 \\, \\text{GHz}$$\nThe problem requires the answer to be rounded to three significant figures. The value $1.2$ GHz, when expressed with three significant figures, is $1.20$ GHz.",
            "answer": "$$\\boxed{1.20}$$"
        }
    ]
}