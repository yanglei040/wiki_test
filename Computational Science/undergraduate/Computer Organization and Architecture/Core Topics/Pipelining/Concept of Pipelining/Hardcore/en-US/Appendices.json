{
    "hands_on_practices": [
        {
            "introduction": "A key benefit of pipelining is the ability to sustain a throughput of one instruction per cycle in an ideal scenario. However, real-world execution is often disrupted by stalls, which are like \"bubbles\" that interrupt this smooth flow. This first practice provides a foundational understanding of how such a disruption propagates through the pipeline, demonstrating that a single-cycle delay at the beginning has a direct and cumulative impact on every instruction that follows. By analyzing the lifecycle of a single bubble in a controlled, hazard-free environment , you will build a crucial intuition for the fundamental cost of pipeline stalls.",
            "id": "3629259",
            "problem": "Consider a scalar, in-order, five-stage instruction pipeline with stages Instruction Fetch (IF), Instruction Decode and Register Read (ID), Execute (EX), Memory Access (MEM), and Write Back (WB). Each stage has a latency of exactly one clock cycle, and the pipeline issues at most one instruction per cycle. Assume an infinite stream of mutually independent instructions that imposes no data, structural, or control hazards beyond those described, and that the pipeline registers advance their contents at the end of each cycle.\n\nDefine a bubble as an intentionally inserted empty slot that advances one stage per cycle exactly as a real instruction would, occupying a stage but performing no work in that cycle. At cycle $0$, a single bubble is introduced into IF, so that IF performs no fetch at cycle $0$. Starting at cycle $1$, IF fetches one real instruction per cycle thereafter without interruption.\n\nLet $m \\in \\mathbb{N}$ be the number of consecutive real instructions following the bubble that enter IF beginning at cycle $1$, so that the first of these $m$ instructions is fetched at cycle $1$, the second at cycle $2$, and so on. Consider two scenarios:\n- Baseline scenario $\\mathcal{B}$ with no bubble, in which the pipeline begins fetching real instructions at cycle $0$ and continues to fetch one per cycle.\n- Bubble scenario $\\mathcal{S}$ described above, with the single bubble at cycle $0$ and real instruction fetches beginning at cycle $1$.\n\nFor each instruction $i \\in \\{1,2,\\dots,m\\}$, let $c_i$ denote its completion cycle (the cycle in which it enters WB) in $\\mathcal{B}$, and let $c_i'$ denote its completion cycle in $\\mathcal{S}$. Define the total cycle waste over these $m$ instructions as\n$$\nW(m) \\;=\\; \\sum_{i=1}^{m} \\left( c_i' \\;-\\; c_i \\right),\n$$\nwhich aggregates, across the $m$ instructions, the additional cycles each instruction spends in the system due solely to the presence of the bubble at cycle $0$.\n\nStarting from fundamental definitions of pipeline staging, latency, and advancement per cycle, derive $W(m)$ as a closed-form expression in $m$. Express your final answer as an exact analytic expression. No rounding is required, and no units should be included in the final expression.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**Step 1: Extract Givens**\n- Pipeline: Scalar, in-order, five-stage.\n- Stages: Instruction Fetch (IF), Instruction Decode and Register Read (ID), Execute (EX), Memory Access (MEM), Write Back (WB).\n- Stage Latency: $1$ clock cycle per stage.\n- Issue Rate: At most $1$ instruction per cycle.\n- Instructions: Mutually independent, no data, structural, or control hazards beyond the specified bubble.\n- Pipeline Advancement: Registers advance at the end of each cycle.\n- Bubble: An empty slot that advances one stage per cycle.\n- Scenario $\\mathcal{S}$ (Bubble):\n  - Cycle $0$: Bubble introduced into IF.\n  - Cycle $1$ onwards: IF fetches one real instruction per cycle.\n- Variable $m$: $m \\in \\mathbb{N}$, the number of real instructions fetched, starting at cycle $1$.\n- Scenario $\\mathcal{B}$ (Baseline):\n  - Cycle $0$ onwards: IF fetches one real instruction per cycle.\n- Completion Cycle: The cycle in which an instruction *enters* the WB stage. $c_i$ is the completion cycle for instruction $i$ in $\\mathcal{B}$, and $c_i'$ is the completion cycle for instruction $i$ in $\\mathcal{S}$.\n- Total Cycle Waste: $W(m) = \\sum_{i=1}^{m} (c_i' - c_i)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem describes a classic, idealized instruction pipeline, a fundamental concept in computer organization and architecture. All terms (pipeline stages, latency, bubble, cycle counting) are standard and precisely defined. The two scenarios, $\\mathcal{B}$ and $\\mathcal{S}$, are constructed to isolate a specific effect, and the quantity to be calculated, $W(m)$, is explicitly formulated. The problem is self-contained, logically consistent, and scientifically sound. It is a well-posed problem with a unique, derivable solution.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A full solution will be derived.\n\n**Derivation**\n\nThe pipeline has $5$ stages, and each stage takes $1$ clock cycle. The stages are IF, ID, EX, MEM, and WB. An instruction progresses sequentially through these stages. Let $t_{fetch}$ be the cycle in which an instruction is fetched and enters the IF stage.\n\n- The instruction is in the IF stage during cycle $t_{fetch}$.\n- It advances to the ID stage at the end of cycle $t_{fetch}$ and is in ID during cycle $t_{fetch} + 1$.\n- It advances to the EX stage and is in EX during cycle $t_{fetch} + 2$.\n- It advances to the MEM stage and is in MEM during cycle $t_{fetch} + 3$.\n- It advances to the WB stage and is in WB during cycle $t_{fetch} + 4$.\n\nThe problem defines the completion cycle as the cycle in which an instruction *enters* the WB stage. Based on the timing above, the completion cycle $c$ for an instruction fetched at cycle $t_{fetch}$ is given by:\n$$\nc = t_{fetch} + 4\n$$\n\nWe will now apply this relationship to both scenarios for the set of $m$ instructions, indexed from $i=1$ to $m$.\n\n**Baseline Scenario $\\mathcal{B}$**\nIn this scenario, the pipeline begins fetching instructions at cycle $0$ and fetches one instruction per cycle.\n- The first instruction ($i=1$) is fetched at cycle $t_{fetch,1} = 0$.\n- The second instruction ($i=2$) is fetched at cycle $t_{fetch,2} = 1$.\n- The $i$-th instruction is fetched at cycle $t_{fetch,i} = i - 1$.\n\nThe completion cycle for the $i$-th instruction, $c_i$, is therefore:\n$$\nc_i = t_{fetch,i} + 4 = (i - 1) + 4 = i + 3\n$$\n\n**Bubble Scenario $\\mathcal{S}$**\nIn this scenario, a bubble is introduced at cycle $0$. Real instruction fetches begin at cycle $1$.\n- The first instruction ($i=1$) is fetched at cycle $t'_{fetch,1} = 1$.\n- The second instruction ($i=2$) is fetched at cycle $t'_{fetch,2} = 2$.\n- The $i$-th instruction is fetched at cycle $t'_{fetch,i} = i$.\n\nHere, the prime notation (') is used to distinguish fetch cycles and completion cycles in scenario $\\mathcal{S}$ from those in scenario $\\mathcal{B}$. The completion cycle for the $i$-th instruction, $c_i'$, is:\n$$\nc_i' = t'_{fetch,i} + 4 = i + 4\n$$\n\n**Calculation of Total Cycle Waste $W(m)$**\nThe total cycle waste is defined as $W(m) = \\sum_{i=1}^{m} (c_i' - c_i)$. We can first find the difference for a single arbitrary instruction $i$.\n$$\nc_i' - c_i = (i + 4) - (i + 3) = 1\n$$\nThis result demonstrates that each instruction $i \\in \\{1, 2, \\dots, m\\}$ is delayed by exactly one clock cycle in scenario $\\mathcal{S}$ compared to scenario $\\mathcal{B}$. This is a direct consequence of the initial bubble occupying the first available fetch slot at cycle $0$, causing every subsequent instruction to be fetched one cycle later than it would have been in the baseline case.\n\nNow, we can compute the total cycle waste by summing this constant delay over all $m$ instructions:\n$$\nW(m) = \\sum_{i=1}^{m} (c_i' - c_i) = \\sum_{i=1}^{m} 1\n$$\nThe sum of $1$ repeated $m$ times is simply $m$.\n$$\nW(m) = m\n$$\nThis is the final closed-form expression for the total cycle waste.",
            "answer": "$$\n\\boxed{m}\n$$"
        },
        {
            "introduction": "Having established the impact of a pipeline stall, we now explore one of its most common causes: the data hazard. When an instruction needs a result that a previous instruction has not yet produced, the pipeline must be managed to ensure correctness. This exercise contrasts two fundamental strategies for handling such Read-After-Write (RAW) hazards: relying on intelligent hardware with forwarding and automatic stalling, versus using a compiler to enforce correctness by inserting `NOP` instructions. By meticulously tracing a short instruction sequence through the pipeline under both scenarios , you will directly compare the cycle-by-cycle execution and quantify the performance difference between these hardware and software approaches.",
            "id": "3629331",
            "problem": "A five-stage pipeline in a load/store reduced instruction set computing (RISC) design consists of Instruction Fetch (IF), Instruction Decode and Register Read (ID), Execute (EX), Memory Access (MEM), and Writeback (WB), each taking exactly one cycle. The register file is read during ID and written during WB. A Read After Write (RAW) hazard occurs when an instruction needs a register value that has not yet been written by a preceding instruction. Assume the following two hardware configurations:\n\n1. No forwarding: The pipeline does not forward intermediate results. A consumer instruction may read a producer’s destination register only in an ID stage that occurs strictly after the producer’s WB stage completes.\n2. Full forwarding with hardware hazard detection: Arithmetic results may be forwarded from a producer’s EX stage to the consumer’s EX stage in the immediately following cycle. Load results may be forwarded from a producer’s MEM stage to the consumer’s EX stage in the immediately following cycle. The hazard detection unit automatically stalls exactly one cycle on a load-use dependence when needed; otherwise, it does not stall.\n\nConsider the instruction sequence:\n- $I_1$: $LW\\ R_1,\\ 0(R_2)$\n- $I_2$: $ADD\\ R_3,\\ R_1,\\ R_4$\n- $I_3$: $SUB\\ R_5,\\ R_3,\\ R_6$\n\nThere are no cache misses or control hazards, and the pipeline starts empty with $I_1$ fetched in cycle $1$. A compiler for the no-forwarding configuration may insert No Operation (NOP) instructions to avoid hazards; each NOP occupies the pipeline like a normal instruction.\n\nUsing the definitions above, determine:\n- The minimum number of NOPs the compiler must insert between $I_1$ and $I_2$, and between $I_2$ and $I_3$, in the no-forwarding configuration, such that all RAW hazards are prevented.\n- The total number of cycles to complete the three-instruction sequence under the no-forwarding configuration with the minimum NOPs you found.\n- The total number of cycles to complete the same sequence under the full-forwarding configuration with hardware hazard detection and no compiler-inserted NOPs.\n\nFinally, compute the ratio of the total cycles in the no-forwarding configuration (with the minimum NOPs inserted) to the total cycles in the full-forwarding configuration (with hardware hazard detection). Express your final answer as a single simplified fraction. No rounding is required.",
            "solution": "The problem requires an analysis of a three-instruction sequence on a five-stage RISC pipeline under two different hardware configurations. The pipeline stages are Instruction Fetch (IF), Instruction Decode and Register Read (ID), Execute (EX), Memory Access (MEM), and Writeback (WB), with each stage taking one cycle. The instruction sequence exhibits Read-After-Write (RAW) data hazards.\n\nThe instruction sequence is:\n- $I_1$: $LW\\ R_1,\\ 0(R_2)$ (Producer for $R_1$)\n- $I_2$: $ADD\\ R_3,\\ R_1,\\ R_4$ (Consumer of $R_1$, producer for $R_3$)\n- $I_3$: $SUB\\ R_5,\\ R_3,\\ R_6$ (Consumer of $R_3$)\n\nWe analyze the two hardware configurations separately.\n\n### Configuration 1: No Forwarding\nIn this configuration, a RAW hazard is resolved only when the value is available in the register file. A value written by a producer instruction in its WB stage is available for a consumer instruction to read in its ID stage only if the consumer's ID stage occurs in a cycle strictly after the producer's WB stage completes. Hazards are resolved by having a compiler insert No-Operation (NOP) instructions.\n\n**Hazard between $I_1$ and $I_2$:**\n$I_1$ ($LW$) produces a value for register $R_1$. $I_2$ ($ADD$) consumes this value.\nLet's establish the timeline for $I_1$, which is fetched in cycle $1$.\n- $I_1$ IF: Cycle $1$\n- $I_1$ ID: Cycle $2$\n- $I_1$ EX: Cycle $3$\n- $I_1$ MEM: Cycle $4$\n- $I_1$ WB: Cycle $5$\nThe value for $R_1$ is written to the register file at the end of cycle $5$. Therefore, the ID stage of any instruction that reads $R_1$ must begin no earlier than cycle $6$.\n\nWithout any NOPs, $I_2$ would be fetched in cycle $2$ and enter its ID stage in cycle $3$. This is too early and would read the old value of $R_1$. To delay the ID stage of $I_2$ to cycle $6$, we must delay its fetch. The ID stage is the second stage of the pipeline, so for $ID(I_2)$ to be in cycle $6$, $IF(I_2)$ must be in cycle $5$.\nSince instructions are fetched sequentially each cycle, and $I_1$ is fetched in cycle $1$, fetching $I_2$ in cycle $5$ implies that three other instructions must be fetched in cycles $2$, $3$, and $4$. These are the NOPs inserted by the compiler.\n- Cycle $1$: Fetch $I_1$\n- Cycle $2$: Fetch $NOP_1$\n- Cycle $3$: Fetch $NOP_2$\n- Cycle $4$: Fetch $NOP_3$\n- Cycle $5$: Fetch $I_2$\nThus, a minimum of $3$ NOPs must be inserted between $I_1$ and $I_2$.\n\n**Hazard between $I_2$ and $I_3$:**\n$I_2$ ($ADD$) produces a value for register $R_3$. $I_3$ ($SUB$) consumes this value.\nWith the $3$ NOPs inserted between $I_1$ and $I_2$, the timeline for $I_2$ is:\n- $I_2$ IF: Cycle $5$\n- $I_2$ ID: Cycle $6$\n- $I_2$ EX: Cycle $7$\n- $I_2$ MEM: Cycle $8$\n- $I_2$ WB: Cycle $9$\nThe value for $R_3$ is written to the register file at the end of cycle $9$. Therefore, the ID stage of $I_3$ must begin no earlier than cycle $10$.\n\nFor $ID(I_3)$ to be in cycle $10$, $IF(I_3)$ must be in cycle $9$.\nWe know $I_2$ is fetched in cycle $5$. Fetching $I_3$ in cycle $9$ implies that three other instructions must be fetched in cycles $6$, $7$, and $8$.\n- Cycle $5$: Fetch $I_2$\n- Cycle $6$: Fetch $NOP_4$\n- Cycle $7$: Fetch $NOP_5$\n- Cycle $8$: Fetch $NOP_6$\n- Cycle $9$: Fetch $I_3$\nThus, a minimum of $3$ NOPs must be inserted between $I_2$ and $I_3$.\n\n**Total Cycles for No-Forwarding Configuration:**\nThe full sequence of instructions executed by the pipeline is: $I_1, NOP, NOP, NOP, I_2, NOP, NOP, NOP, I_3$.\nThis is a total of $N=9$ instructions. For a $k=5$ stage pipeline, the total number of cycles to execute $N$ instructions is $k + (N-1)$.\nTotal cycles = $5 + (9-1) = 5 + 8 = 13$.\nAlternatively, the last instruction, $I_3$, is fetched in cycle $9$. Its WB stage will complete $4$ cycles later.\n- $I_3$ IF: Cycle $9$\n- $I_3$ ID: Cycle $10$\n- $I_3$ EX: Cycle $11$\n- $I_3$ MEM: Cycle $12$\n- $I_3$ WB: Cycle $13$\nThe entire sequence completes at the end of cycle $13$.\n\n### Configuration 2: Full Forwarding with Hardware Hazard Detection\nIn this configuration, no NOPs are inserted. The hardware handles hazards through forwarding and stalling.\nInstructions are fetched in consecutive cycles: $I_1$ in cycle $1$, $I_2$ in cycle $2$, and $I_3$ in cycle $3$.\n\n**Hazard between $I_1$ and $I_2$ (Load-Use):**\n- $I_1$ ($LW$) has its data available from memory at the end of its MEM stage.\n- $I_2$ ($ADD$) needs the value of $R_1$ for its EX stage.\nLet's draw the unstalled pipeline:\n| Cycle | 1    | 2    | 3    | 4    | 5    |\n|-------|------|------|------|------|------|\n| $I_1$   | IF   | ID   | EX   | MEM  | WB   |\n| $I_2$   |      | IF   | ID   | EX   | MEM  |\n$I_1$ has the data ready at the end of cycle $4$. $I_2$ needs it at the beginning of its EX stage, which is the beginning of cycle $4$. The data is available too late.\nThe forwarding rule for loads is from the producer's MEM stage to the consumer's EX stage in the *next* cycle (i.e., MEM at cycle $t$ can forward to EX at cycle $t+1$). To make this work, the EX stage of $I_2$ must be delayed to cycle $5$. This requires a one-cycle stall.\nThe problem statement confirms this: \"The hazard detection unit automatically stalls exactly one cycle on a load-use dependence\".\nThe stall is introduced when the hazard is detected in cycle $3$ (when $I_2$ is in ID). The pipeline stalls for one cycle (cycle $4$), and then execution resumes.\n\n**Hazard between $I_2$ and $I_3$ (ALU-ALU):**\n- $I_2$ ($ADD$) has its result available at the end of its EX stage.\n- $I_3$ ($SUB$) needs this result for its EX stage.\nThe forwarding rule for arithmetic operations is from the producer's EX stage to the consumer's EX stage in the *next* cycle (EX at cycle $t$ to EX at cycle $t+1$).\nLet's build the complete pipeline diagram, including the one-cycle stall from the first hazard.\n| Cycle | 1    | 2    | 3    | 4 (Stall) | 5    | 6    | 7    | 8    |\n|-------|------|------|------|-----------|------|------|------|------|\n| $I_1$   | IF   | ID   | EX   | MEM       | WB   |      |      |      |\n| $I_2$   |      | IF   | ID   | ID        | EX   | MEM  | WB   |      |\n| $I_3$   |      |      | IF   | IF        | ID   | EX   | MEM  | WB   |\n\nIn cycle $4$, $I_2$ and $I_3$ are stalled in their current stages (ID and IF, respectively), while $I_1$ proceeds. A bubble is effectively inserted into the pipeline.\n- $I_2$'s EX stage is now in cycle $5$. The MEM-to-EX forward from $I_1$ (MEM in cycle $4$) works as required.\n- $I_3$'s EX stage is in cycle $6$.\n- $I_2$ (producer) has its EX stage in cycle $5$. $I_3$ (consumer) has its EX stage in cycle $6$. The EX-to-EX forwarding path works perfectly, so no additional stall is required.\n\n**Total Cycles for Full-Forwarding Configuration:**\nThe last instruction, $I_3$, completes its WB stage at the end of cycle $8$.\nTherefore, the total number of cycles to complete the sequence is $8$.\n\n### Final Calculation: Ratio of Cycles\nThe problem asks for the ratio of the total cycles in the no-forwarding configuration to the total cycles in the full-forwarding configuration.\n\n- Total cycles (No Forwarding), $C_{NF} = 13$\n- Total cycles (Full Forwarding), $C_{F} = 8$\n\nThe ratio is $\\frac{C_{NF}}{C_{F}} = \\frac{13}{8}$.\nThis is a simplified fraction.\nThe minimum number of NOPs for the no-forwarding case is $3$ between $I_1$ and $I_2$, and $3$ between $I_2$ and $I_3$. The total cycles are $13$ for no-forwarding and $8$ for full-forwarding. The final ratio is $\\frac{13}{8}$.",
            "answer": "$$\\boxed{\\frac{13}{8}}$$"
        },
        {
            "introduction": "In our final practice, we shift from analyzing existing pipelines to evaluating a proposed architectural improvement. A frequent performance bottleneck is the \"load-use\" hazard, where a one-cycle stall persists even with forwarding. This problem challenges you to assess a redesign that splits a pipeline stage to eliminate this specific stall. Your task is to conduct a complete performance analysis, considering not only the improvement in Cycles Per Instruction ($CPI$) but also the impact on the processor's clock period ($T_{clk}$), a crucial trade-off in pipeline design. By calculating the overall speedup , you will engage in the kind of quantitative reasoning that drives real-world processor engineering.",
            "id": "3629255",
            "problem": "A five-stage in-order pipeline consisting of Instruction Fetch (IF), Instruction Decode and register read (ID), Execute (EX), Memory Access (MEM), and Write Back (WB) is implemented with full data bypassing except for the classic load-use case. The per-stage logic delays are as follows: IF has delay $180\\,\\text{ps}$, ID has delay $170\\,\\text{ps}$, EX has delay $160\\,\\text{ps}$, MEM has delay $360\\,\\text{ps}$, and WB has delay $140\\,\\text{ps}$. Each pipeline register adds a latch overhead of $40\\,\\text{ps}$ to the cycle time. Assume first-level data memory always hits and branch penalties are negligible.\n\nA workload is hazard-dominated: across a long dynamic instruction stream of $N \\gg 1$ instructions, a fraction $f = 0.70$ of instruction boundaries are load-use hazards where a load is immediately followed by a dependent instruction. In the baseline pipeline, even with full bypassing, each such load-use hazard incurs exactly one stall cycle because the loaded data becomes available only at the end of the MEM stage and cannot satisfy the dependent instruction’s EX stage timing without a bubble.\n\nAn enhanced design adds one extra pipeline stage by splitting MEM into two equal logic stages, MEM1 and MEM2, each with half of the MEM logic delay. The latch overhead per stage remains $40\\,\\text{ps}$. The memory is organized so that the loaded value is available by the end of MEM1, enabling correct forwarding to the dependent instruction’s EX stage in the next cycle without any stall. All other aspects of the machine and workload remain unchanged, and there are no new structural hazards.\n\nUsing only first principles such as the definition of Cycles Per Instruction (CPI), the relationship between execution time, CPI, and clock period, and the definition of speedup as a ratio of execution times, derive and compute the overall speedup of the enhanced design over the baseline for this workload. Express the final speedup as a single real number and round your answer to four significant figures.",
            "solution": "The problem is deemed valid as it is scientifically grounded in the principles of computer architecture, is well-posed with sufficient data for a unique solution, and is expressed in objective, formal language. We can proceed with the analysis.\n\nThe overall speedup of the enhanced design relative to the baseline design is defined as the ratio of their respective execution times. The execution time ($T_{exec}$) for a program is given by the iron law of processor performance:\n$$T_{exec} = N \\times \\text{CPI} \\times T_{clk}$$\nwhere $N$ is the number of dynamic instructions, CPI is the average number of clock cycles per instruction, and $T_{clk}$ is the clock cycle time (or period).\n\nThe speedup ($S$) can therefore be expressed as:\n$$S = \\frac{T_{exec, base}}{T_{exec, enh}} = \\frac{N \\times \\text{CPI}_{base} \\times T_{clk, base}}{N \\times \\text{CPI}_{enh} \\times T_{clk, enh}}$$\nSince the workload is the same for both designs, the number of instructions $N$ is constant and cancels out:\n$$S = \\frac{\\text{CPI}_{base} \\times T_{clk, base}}{\\text{CPI}_{enh} \\times T_{clk, enh}}$$\nTo compute the speedup, we must first determine the clock period and CPI for each design.\n\nFirst, we analyze the baseline design.\nThe clock period ($T_{clk}$) of a pipelined processor is determined by the delay of its slowest stage plus the overhead of the pipeline register (latch). The stage delays for the baseline five-stage pipeline are given as:\n$T_{IF} = 180\\,\\text{ps}$\n$T_{ID} = 170\\,\\text{ps}$\n$T_{EX} = 160\\,\\text{ps}$\n$T_{MEM} = 360\\,\\text{ps}$\n$T_{WB} = 140\\,\\text{ps}$\nThe latch overhead is $T_{latch} = 40\\,\\text{ps}$.\n\nThe clock period for the baseline design, $T_{clk, base}$, is:\n$$T_{clk, base} = \\max(T_{IF}, T_{ID}, T_{EX}, T_{MEM}, T_{WB}) + T_{latch}$$\n$$T_{clk, base} = \\max(180, 170, 160, 360, 140)\\,\\text{ps} + 40\\,\\text{ps}$$\n$$T_{clk, base} = 360\\,\\text{ps} + 40\\,\\text{ps} = 400\\,\\text{ps}$$\n\nNext, we determine the CPI for the baseline design, $\\text{CPI}_{base}$. The CPI is the sum of the ideal CPI (which is $1$ for a pipeline) and the stall cycles per instruction.\n$$\\text{CPI} = 1 + \\text{Stall cycles per instruction}$$\nStalls are caused by load-use hazards. A fraction $f = 0.70$ of instructions are dependent on an immediately preceding load, and each such hazard incurs a $1$-cycle stall.\n$$\\text{Stall cycles per instruction} = (\\text{Fraction of instructions causing stalls}) \\times (\\text{Stalls per occurrence})$$\n$$\\text{Stall cycles per instruction}_{base} = f \\times 1 = 0.70 \\times 1 = 0.70$$\nTherefore, the CPI for the baseline design is:\n$$\\text{CPI}_{base} = 1 + 0.70 = 1.70$$\n\nNow, we analyze the enhanced design.\nThe MEM stage is split into two equal stages, MEM1 and MEM2. The new pipeline has six stages: IF, ID, EX, MEM1, MEM2, WB. The delays are:\n$T_{IF} = 180\\,\\text{ps}$\n$T_{ID} = 170\\,\\text{ps}$\n$T_{EX} = 160\\,\\text{ps}$\n$T_{MEM1} = \\frac{T_{MEM}}{2} = \\frac{360}{2}\\,\\text{ps} = 180\\,\\text{ps}$\n$T_{MEM2} = \\frac{T_{MEM}}{2} = \\frac{360}{2}\\,\\text{ps} = 180\\,\\text{ps}$\n$T_{WB} = 140\\,\\text{ps}$\n\nThe clock period for the enhanced design, $T_{clk, enh}$, is determined by the new set of stage delays and the same latch overhead $T_{latch} = 40\\,\\text{ps}$.\n$$T_{clk, enh} = \\max(180, 170, 160, 180, 180, 140)\\,\\text{ps} + 40\\,\\text{ps}$$\n$$T_{clk, enh} = 180\\,\\text{ps} + 40\\,\\text{ps} = 220\\,\\text{ps}$$\n\nNext, we determine the CPI for the enhanced design, $\\text{CPI}_{enh}$. In this design, the memory is organized such that the loaded value is available by the end of the MEM1 stage, which resolves the load-use hazard without any stalls.\n$$\\text{Stall cycles per instruction}_{enh} = f \\times 0 = 0.70 \\times 0 = 0$$\nTherefore, the CPI for the enhanced design is ideal:\n$$\\text{CPI}_{enh} = 1 + 0 = 1.00$$\n\nFinally, we can compute the overall speedup $S$.\n$$S = \\frac{\\text{CPI}_{base} \\times T_{clk, base}}{\\text{CPI}_{enh} \\times T_{clk, enh}} = \\frac{1.70 \\times 400\\,\\text{ps}}{1.00 \\times 220\\,\\text{ps}}$$\n$$S = \\frac{680}{220} = \\frac{68}{22} = \\frac{34}{11}$$\n$$S \\approx 3.090909...$$\nRounding the result to four significant figures gives:\n$$S = 3.091$$",
            "answer": "$$\\boxed{3.091}$$"
        }
    ]
}