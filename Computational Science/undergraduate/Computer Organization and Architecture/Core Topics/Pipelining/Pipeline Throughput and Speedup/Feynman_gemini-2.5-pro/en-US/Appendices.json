{
    "hands_on_practices": [
        {
            "introduction": "The ideal speedup of a pipeline is limited by real-world constraints, most notably data hazards that cause stalls. This exercise provides a foundational model for quantifying this performance degradation. By deriving the relationship between the probability of a data hazard stall and overall performance from first principles, you will build an essential formula for analyzing how program characteristics affect pipeline throughput.",
            "id": "3666173",
            "problem": "A scalar, in-order processor implements a balanced pipeline of $s$ stages with operand forwarding (also known as bypassing). Each stage has latency $t$, so the pipeline clock period is $t$. There are no structural hazards and no control hazards. Data hazards may occur: for each dynamic instruction in a long loop of $N$ instructions, independently, there is a probability $p_d$ that a read-after-write dependency will not be fully covered by forwarding and will cause exactly one stall cycle before the dependent instruction can issue.\n\nUsing only foundational definitions of average performance metrics and limits, do the following:\n\n- From first principles, derive the expected Cycles Per Instruction (CPI) of the pipelined processor in terms of $p_d$.\n- Taking the unpipelined baseline to be a multi-cycle implementation of the same datapath that completes each instruction in $s$ cycles of duration $t$ (i.e., its CPI is $s$ and its cycle time is $t$), compute the speedup $S$ defined as the ratio of total execution time of the unpipelined machine to that of the pipelined machine for the loop as $N \\to \\infty$.\n\nExpress the final speedup $S$ as a closed-form analytic expression in terms of $s$ and $p_d$. Report only the speedup $S$ as your final answer. No rounding is required.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of computer architecture, well-posed with sufficient and consistent information, and objectively stated. The problem requires a first-principles derivation of processor performance metrics, which is a standard and formalizable task in the field.\n\nThe analysis proceeds in two parts as requested: first, the derivation of the expected Cycles Per Instruction (CPI) for the pipelined processor, and second, the calculation of the speedup $S$.\n\nFirst, we derive the expected CPI for the pipelined processor, denoted as $CPI_{pipe}$. The CPI is defined as the average number of clock cycles required to execute one instruction. It can be expressed as the sum of the CPI for an ideal pipeline and the average number of stall cycles per instruction.\n$$\nCPI_{pipe} = CPI_{ideal} + CPI_{stalls}\n$$\nFor an ideal scalar pipeline operating in a steady state (which is a valid assumption given the problem's condition of a long loop with $N \\to \\infty$), one instruction completes on every clock cycle. Therefore, the ideal CPI is $1$.\n$$\nCPI_{ideal} = 1\n$$\nThe problem states that the only source of performance degradation is data hazards that result in stalls. For any given instruction, there is a probability $p_d$ that it will cause exactly one stall cycle. Other instructions cause zero stall cycles. The contribution of stalls to the CPI, $CPI_{stalls}$, is the expected number of stall cycles per instruction. This is calculated by multiplying the probability of a stall event by the number of cycles per stall.\n$$\nCPI_{stalls} = (\\text{Probability of stall}) \\times (\\text{Stall cycles per event})\n$$\nGiven the probability of a stall is $p_d$ and the duration is $1$ cycle, we have:\n$$\nCPI_{stalls} = p_d \\times 1 = p_d\n$$\nCombining these results, the expected CPI for the pipelined processor is:\n$$\nCPI_{pipe} = CPI_{ideal} + CPI_{stalls} = 1 + p_d\n$$\nNext, we compute the speedup $S$. Speedup is defined as the ratio of the total execution time of the unpipelined baseline machine to that of the pipelined machine.\n$$\nS = \\frac{T_{unpipelined}}{T_{pipelined}}\n$$\nThe total execution time ($T$) for a program with $N$ instructions is given by the general performance equation:\n$$\nT = N \\times CPI \\times \\tau\n$$\nwhere $N$ is the instruction count, CPI is the cycles per instruction, and $\\tau$ is the clock cycle time. We are considering the limit as $N \\to \\infty$, which allows us to ignore the transient effects of filling and draining the pipeline, as these constant terms become negligible compared to the terms that grow linearly with $N$.\n\nFor the unpipelined baseline machine:\nThe number of instructions is $N$.\nThe CPI is given as $s$, so $CPI_{unpipe} = s$.\nThe cycle time is given as $t$, so $\\tau_{unpipe} = t$.\nThe execution time is therefore:\n$$\nT_{unpipelined} = N \\times CPI_{unpipe} \\times \\tau_{unpipe} = N \\times s \\times t\n$$\n\nFor the pipelined machine:\nThe number of instructions is $N$.\nThe CPI was derived above as $CPI_{pipe} = 1 + p_d$.\nThe cycle time is given as $t$, so $\\tau_{pipe} = t$.\nThe execution time is therefore:\n$$\nT_{pipelined} = N \\times CPI_{pipe} \\times \\tau_{pipe} = N \\times (1 + p_d) \\times t\n$$\n\nNow, we can compute the speedup $S$ by substituting these execution time expressions into the speedup formula:\n$$\nS = \\frac{T_{unpipelined}}{T_{pipelined}} = \\frac{N \\times s \\times t}{N \\times (1 + p_d) \\times t}\n$$\nThe terms for instruction count, $N$, and clock cycle time, $t$, cancel out from the numerator and the denominator. This yields the final expression for the speedup:\n$$\nS = \\frac{s}{1 + p_d}\n$$\nThis expression represents the speedup as a function of the number of pipeline stages, $s$, and the probability of a data hazard stall, $p_d$. The ideal speedup of a pipeline is $s$, which is achieved when there are no stalls ($p_d = 0$). The term $1 + p_d$ in the denominator represents the performance penalty factor due to stalls.",
            "answer": "$$\n\\boxed{\\frac{s}{1 + p_d}}\n$$"
        },
        {
            "introduction": "Understanding the impact of hazards is the first step; actively mitigating them is the next. This practice delves into the crucial interaction between hardware capabilities, like data forwarding, and software optimizations, such as instruction scheduling. By reordering code to resolve a common load-use data hazard, you will see firsthand how a compiler can minimize stalls and maximize a processor's effective throughput.",
            "id": "3666138",
            "problem": "A $5$-stage Reduced Instruction Set Computer (RISC) pipeline implements the following stages in order: Instruction Fetch (IF), Instruction Decode and Register Read (ID), Execute or Address Compute (EX), Memory Access (MEM), and Write Back (WB). The processor is single-issue and in-order. Each pipeline stage takes exactly $1$ cycle. The data path supports full forwarding (also called bypassing) from EX/MEM and MEM/WB pipeline registers to EX, and hazard detection inserts stalls only when required to preserve correctness. All data memory accesses are cache hits and complete in the MEM stage in $1$ cycle. There are no structural hazards and no control hazards. The value produced by a load is available for forwarding only after its MEM stage completes; therefore, a dependent arithmetic instruction placed immediately after a load would require exactly $1$ stall cycle, while placing at least $1$ independent instruction between a load and its dependent arithmetic instruction eliminates that stall.\n\nConsider a straight-line basic block consisting of $M$ repetitions, where $M \\ge 2$, of an alternating load and use pattern with no inter-pair dependences. For each $i \\in \\{1,2,\\dots,M\\}$, the pair is:\n- Load: $\\mathrm{LD}\\ r_i \\leftarrow \\mathrm{Mem}[a_i]$\n- Use: $\\mathrm{ADD}\\ u_i \\leftarrow r_i + c_i$\nwith all $r_i$, $u_i$ distinct across $i$, all addresses $a_i$ distinct, and each $c_i$ independent of all $r_j$. A compiler is allowed to reorder instructions arbitrarily as long as, for each $i$, the $\\mathrm{ADD}$ that uses $r_i$ occurs after its corresponding $\\mathrm{LD}$.\n\nStarting from the definition of cycles per instruction (CPI) and the foundational behavior of a single-issue $k$-stage pipeline, derive the minimal achievable average CPI for this block when optimal software scheduling and full forwarding are used. Your derivation must explicitly account for pipeline fill and drain effects. Express your final answer as a single, closed-form expression in terms of $M$ only. No rounding is required, and CPI is unitless.",
            "solution": "The problem asks for the minimal achievable average Cycles Per Instruction (CPI) for a given code block on a specific $5$-stage RISC pipeline.\n\nThe definition of average CPI is the total number of execution cycles divided by the total number of instructions.\n$$\n\\text{CPI} = \\frac{\\text{Total Cycles}}{\\text{Total Instructions}}\n$$\nThe code block consists of $M$ pairs of a load ($\\mathrm{LD}$) and a dependent add ($\\mathrm{ADD}$) instruction. Thus, the total number of instructions, $N_{\\text{instr}}$, is $2M$.\n$$\nN_{\\text{instr}} = 2M\n$$\nTo find the minimal CPI, we must find the minimum possible number of total cycles required to execute these $2M$ instructions. This is achieved by finding an optimal instruction schedule that minimizes pipeline stalls.\n\nThe pipeline has $k=5$ stages: IF, ID, EX, MEM, WB. Each stage takes $1$ cycle. The pipeline is single-issue and in-order. Full forwarding is available. The critical performance constraint is the data hazard between a load instruction and an instruction that uses its result. The problem states that the value from a load is available for forwarding only after its MEM stage completes. An arithmetic instruction, such as $\\mathrm{ADD}$, requires its operands for its EX stage.\n\nLet's analyze the timing of a load-use pair without any scheduling:\n$\\mathrm{LD}\\ r_i, \\dots$\n$\\mathrm{ADD}\\ u_i, r_i, \\dots$\n\nLet the $\\mathrm{LD}$ instruction enter the IF stage at cycle $t$.\n- Cycle $t$: $\\mathrm{LD}$ in IF\n- Cycle $t+1$: $\\mathrm{LD}$ in ID, $\\mathrm{ADD}$ in IF\n- Cycle $t+2$: $\\mathrm{LD}$ in EX, $\\mathrm{ADD}$ in ID\n- Cycle $t+3$: $\\mathrm{LD}$ in MEM, $\\mathrm{ADD}$ in EX\n\nAt the beginning of cycle $t+3$, the $\\mathrm{ADD}$ instruction is in its EX stage and requires the value for register $r_i$. The $\\mathrm{LD}$ instruction is in its MEM stage and will only produce this value at the end of cycle $t+3$. The value is written to the MEM/WB pipeline register and is available for forwarding at the beginning of cycle $t+4$. Therefore, a data hazard exists. The hazard detection logic must stall the $\\mathrm{ADD}$ instruction in the pipeline for one cycle.\n\nCorrected execution with stall:\n- Cycle $t+3$: $\\mathrm{LD}$ in MEM, $\\mathrm{ADD}$ is stalled (remains in ID stage).\n- Cycle $t+4$: $\\mathrm{LD}$ in WB, $\\mathrm{ADD}$ proceeds to EX. The value of $r_i$ is forwarded from the now-populated MEM/WB register to the EX stage.\nThis confirms the problem statement that a dependent instruction immediately following a load requires a $1$-cycle stall.\n\nThe problem also states that placing at least $1$ independent instruction between the load and the dependent use eliminates this stall. A compiler is permitted to reorder instructions, with the only constraint being that for each pair $i$, the $\\mathrm{LD}_i$ must precede its corresponding $\\mathrm{ADD}_i$.\n\nTo minimize total cycles, we must find a schedule that eliminates all such stalls. An optimal strategy is to reorder the instructions to maximize the distance between each $\\mathrm{LD}_i$ and its dependent $\\mathrm{ADD}_i$. Since all load instructions are independent of each other (they write to distinct registers $r_i$) and all add instructions are independent of each other (they write to distinct registers $u_i$), a valid and highly effective schedule is to group all load instructions first, followed by all add instructions.\n\nThe proposed optimal schedule is:\n$L_1, L_2, \\dots, L_M, A_1, A_2, \\dots, A_M$\nwhere $L_i$ denotes $\\mathrm{LD}\\ r_i \\leftarrow \\mathrm{Mem}[a_i]$ and $A_i$ denotes $\\mathrm{ADD}\\ u_i \\leftarrow r_i + c_i$.\n\nLet's verify that this schedule is stall-free for $M \\ge 2$. In this sequence, there are no data dependencies among the first $M$ load instructions, so they can be issued back-to-back without stalls. The subsequent add instructions may have dependencies on the loads. Consider the $i$-th add instruction, $A_i$. It is the $(M+i)$-th instruction in the sequence. It depends on the result of the $i$-th load instruction, $L_i$.\n\n- The instruction $L_i$ enters the pipeline at cycle $i$. Its value is produced at the end of its MEM stage, which occurs at cycle $i + (4-1) = i+3$. The result is available for forwarding starting from cycle $i+4$.\n- The instruction $A_i$ enters the pipeline at cycle $M+i$. It reaches its EX stage at cycle $(M+i) + (3-1) = M+i+2$.\n\nFor $A_i$ to execute without a stall, its EX stage must begin no earlier than when the result of $L_i$ is available for forwarding. This gives the condition:\n$$\n\\text{Start of EX stage for } A_i \\ge \\text{Start of cycle when } L_i \\text{'s result is available}\n$$\n$$\nM + i + 2 \\ge i + 4\n$$\n$$\nM \\ge 2\n$$\nThe problem specifies that $M \\ge 2$. Therefore, this condition is met for all pairs $(L_i, A_i)$. This proves that the proposed schedule of all loads followed by all adds is completely stall-free.\n\nSince we have found a schedule with zero stalls, this represents the minimal execution time. The total number of cycles for a sequence of $N_{\\text{instr}}$ instructions executing on a $k$-stage pipeline with no stalls is given by the sum of the cycles to fill the pipeline and the cycles to issue the remaining instructions. The first instruction takes $k$ cycles to complete. Subsequent $N_{\\text{instr}}-1$ instructions complete at a rate of one per cycle.\n$$\n\\text{Total Cycles} = k + (N_{\\text{instr}} - 1) = k - 1 + N_{\\text{instr}}\n$$\nFor this problem, the pipeline depth is $k=5$ and the total number of instructions is $N_{\\text{instr}} = 2M$.\nSubstituting these values, the minimal total cycles is:\n$$\n\\text{Total Cycles}_{\\text{min}} = (5 - 1) + 2M = 4 + 2M\n$$\nNow we can calculate the minimal average CPI using its definition:\n$$\n\\text{CPI}_{\\text{min}} = \\frac{\\text{Total Cycles}_{\\text{min}}}{N_{\\text{instr}}} = \\frac{4 + 2M}{2M}\n$$\nSimplifying this expression gives:\n$$\n\\text{CPI}_{\\text{min}} = \\frac{4}{2M} + \\frac{2M}{2M} = \\frac{2}{M} + 1\n$$\nThis is the final closed-form expression for the minimal average CPI in terms of $M$.",
            "answer": "$$\n\\boxed{1 + \\frac{2}{M}}\n$$"
        },
        {
            "introduction": "While simple pipeline models are instructive, real-world performance analysis often involves deciphering data from complex, superscalar processors. This exercise simulates the work of a performance engineer, challenging you to analyze a processor's issue trace. You will learn to reconstruct a machine's capabilities, identify the primary performance bottleneck from concrete data, and quantify the potential speedup from a specific hardware upgrade.",
            "id": "3666121",
            "problem": "A superscalar processor implements a dynamically scheduled pipeline with the following stages: Fetch, Decode, Rename, Dispatch, Issue, Execute, Write Back, and Commit. The front end maintains a non-empty instruction window during the interval of interest, branch prediction is assumed perfect, and the Commit stage can retire as many micro-operations per cycle as the Issue stage can initiate in steady state. Functional units and their Issue capacities per cycle are: integer arithmetic and logic units (two identical ports handling both simple integer arithmetic and integer multiply), and a single memory Issue port handling both loads and stores. All Issue decisions are logged at cycle resolution, and each logged entry records which micro-operations were issued and, when fewer than the maximum are issued, the reason the next candidate could not be issued.\n\nYou are given the following segment of the Issue trace, covering cycles $0$ through $11$ inclusive. In each bullet, micro-operation types are denoted by $\\mathrm{A}$ for integer arithmetic or logic, $\\mathrm{M}$ for integer multiply, and $\\mathrm{L}$ for memory (load or store).\n\n- Cycle $0$: issued $\\mathrm{A}, \\mathrm{A}, \\mathrm{L}$.\n- Cycle $1$: issued $\\mathrm{A}, \\mathrm{A}, \\mathrm{L}$.\n- Cycle $2$: issued $\\mathrm{A}, \\mathrm{M}, \\mathrm{L}$.\n- Cycle $3$: issued $\\mathrm{A}, \\mathrm{L}$; one additional ready $\\mathrm{L}$ could not issue because the single memory Issue port was already used in this cycle.\n- Cycle $4$: issued $\\mathrm{A}, \\mathrm{A}, \\mathrm{L}$.\n- Cycle $5$: issued $\\mathrm{A}, \\mathrm{A}, \\mathrm{L}$.\n- Cycle $6$: issued $\\mathrm{A}, \\mathrm{M}, \\mathrm{L}$.\n- Cycle $7$: issued $\\mathrm{A}, \\mathrm{L}$; one additional ready $\\mathrm{L}$ could not issue because the single memory Issue port was already used in this cycle.\n- Cycle $8$: issued $\\mathrm{A}, \\mathrm{L}$; one additional ready $\\mathrm{L}$ could not issue because the single memory Issue port was already used in this cycle.\n- Cycle $9$: issued $\\mathrm{A}, \\mathrm{A}$; one additional ready $\\mathrm{A}$ could not issue because only $2$ integer ports are available per cycle.\n- Cycle $10$: issued $\\mathrm{A}, \\mathrm{L}$; one additional ready $\\mathrm{L}$ could not issue because the single memory Issue port was already used in this cycle.\n- Cycle $11$: issued $\\mathrm{A}, \\mathrm{A}, \\mathrm{L}$.\n\nTasks:\n- From first principles, reconstruct the effective pipeline width at the Issue stage over this interval.\n- Identify the dominant bottleneck responsible for reduced Issue counts below the reconstructed width.\n- Using the steady-state equivalence between Issue and Commit throughput under the given assumptions, infer the Instructions Per Cycle (IPC) over cycles $0$ to $11$.\n- Suppose the identified bottleneck stage is optimized by adding a second memory Issue port, with all other aspects unchanged and the front end still keeping the window non-empty. Under this modification, in any cycle where an additional ready $\\mathrm{L}$ previously could not issue solely due to memory port unavailability, it will now issue. Compute the resulting throughput speedup factor, defined as the ratio of the new IPC to the original IPC, over the same $12$-cycle interval.\n\nExpress the final speedup factor as an exact fraction.",
            "solution": "The problem statement is first validated against the specified criteria.\n\n### Step 1: Extract Givens\n- **Processor Architecture**: Superscalar, dynamically scheduled pipeline.\n- **Pipeline Stages**: Fetch, Decode, Rename, Dispatch, Issue, Execute, Write Back, and Commit.\n- **Processor State**: Non-empty instruction window, perfect branch prediction.\n- **Commit Rate**: Equal to Issue rate in steady state.\n- **Functional Units and Issue Capacities (Original)**:\n    - Two identical ports for integer arithmetic ($\\mathrm{A}$) and integer multiply ($\\mathrm{M}$).\n    - One single port for memory operations (loads and stores, $\\mathrm{L}$).\n- **Issue Trace Data (Cycles $0$ to $11$)**:\n    - Cycle $0$: issued $\\mathrm{A}, \\mathrm{A}, \\mathrm{L}$.\n    - Cycle $1$: issued $\\mathrm{A}, \\mathrm{A}, \\mathrm{L}$.\n    - Cycle $2$: issued $\\mathrm{A}, \\mathrm{M}, \\mathrm{L}$.\n    - Cycle $3$: issued $\\mathrm{A}, \\mathrm{L}$; one additional ready $\\mathrm{L}$ could not issue (memory port saturation).\n    - Cycle $4$: issued $\\mathrm{A}, \\mathrm{A}, \\mathrm{L}$.\n    - Cycle $5$: issued $\\mathrm{A}, \\mathrm{A}, \\mathrm{L}$.\n    - Cycle $6$: issued $\\mathrm{A}, \\mathrm{M}, \\mathrm{L}$.\n    - Cycle $7$: issued $\\mathrm{A}, \\mathrm{L}$; one additional ready $\\mathrm{L}$ could not issue (memory port saturation).\n    - Cycle $8$: issued $\\mathrm{A}, \\mathrm{L}$; one additional ready $\\mathrm{L}$ could not issue (memory port saturation).\n    - Cycle $9$: issued $\\mathrm{A}, \\mathrm{A}$; one additional ready $\\mathrm{A}$ could not issue (integer port saturation).\n    - Cycle $10$: issued $\\mathrm{A}, \\mathrm{L}$; one additional ready $\\mathrm{L}$ could not issue (memory port saturation).\n    - Cycle $11$: issued $\\mathrm{A}, \\mathrm{A}, \\mathrm{L}$.\n- **Proposed Modification**: Add a second memory Issue port.\n- **Task Requirements**:\n    1. Reconstruct the effective pipeline width at the Issue stage.\n    2. Identify the dominant bottleneck.\n    3. Infer the Instructions Per Cycle (IPC) for the original configuration.\n    4. Compute the throughput speedup factor with the modification.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It describes a conventional superscalar processor model and provides a consistent data set for analysis. The concepts of issue width, structural hazards, and IPC are fundamental to computer architecture. The assumptions (e.g., perfect branch prediction, non-empty instruction window) are standard simplifications used in performance analysis to isolate specific effects, in this case, the limitations of the Issue stage. The data is self-consistent; for example, the reason for not issuing a third micro-operation in cycle $3$ (memory port unavailable) aligns with the stated configuration of one memory port. The problem is formalizable and directly relevant to the topic. It does not contain contradictions, ambiguities, or scientifically unsound premises.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\n\n**1. Reconstruct the effective pipeline width at the Issue stage.**\nThe effective pipeline width at the Issue stage, also known as the issue width or machine width, is defined by the maximum number of micro-operations that can be issued in a single cycle. This is determined by the number of available issue ports for the functional units.\nThe processor has:\n- $2$ issue ports for integer operations ($\\mathrm{A}$ or $\\mathrm{M}$).\n- $1$ issue port for memory operations ($\\mathrm{L}$).\nThe total maximum number of micro-operations that can be issued concurrently in one cycle is the sum of these port capacities.\n$$ \\text{Issue Width} = (\\text{Integer Ports}) + (\\text{Memory Ports}) = 2 + 1 = 3 $$\nThus, the effective pipeline width at the Issue stage is $3$. This is confirmed by the trace, as no cycle issues more than $3$ micro-operations, and several cycles (e.g., cycle $0$, $1$, $2$) achieve this maximum.\n\n**2. Identify the dominant bottleneck.**\nA bottleneck is a resource that limits the overall throughput. In this context, it is a structural hazard that prevents the processor from achieving its maximum issue width of $3$ in every cycle. We analyze the cycles where fewer than $3$ micro-operations were issued due to resource saturation.\nThe trace provides the following reasons for reduced issue counts:\n- Cycle $3$: $1$ ready $\\mathrm{L}$ could not issue due to the single memory port being used.\n- Cycle $7$: $1$ ready $\\mathrm{L}$ could not issue due to the single memory port being used.\n- Cycle $8$: $1$ ready $\\mathrm{L}$ could not issue due to the single memory port being used.\n- Cycle $9$: $1$ ready $\\mathrm{A}$ could not issue due to the two integer ports being used.\n- Cycle $10$: $1$ ready $\\mathrm{L}$ could not issue due to the single memory port being used.\n\nLet's count the number of times each resource caused a stall:\n- Stalls due to memory port saturation: $4$ cycles ($3, 7, 8, 10$).\n- Stalls due to integer port saturation: $1$ cycle ($9$).\n\nThe memory port is responsible for limiting performance in $4$ out of the $12$ cycles, whereas the integer ports are a limiting factor in only $1$ cycle. Therefore, the single memory Issue port is the dominant bottleneck.\n\n**3. Infer the Instructions Per Cycle (IPC) over the interval.**\nThe problem states that Issue and Commit throughput are equivalent. Therefore, we can calculate the average throughput by counting the total number of micro-operations issued and dividing by the number of cycles. We will refer to this metric as IPC, as is common in this context. The interval spans from cycle $0$ to $11$, which is a total of $11 - 0 + 1 = 12$ cycles.\n\nTotal micro-operations issued ($N_{\\text{ops, original}}$):\n- Cycle $0$: $3$ ops\n- Cycle $1$: $3$ ops\n- Cycle $2$: $3$ ops\n- Cycle $3$: $2$ ops\n- Cycle $4$: $3$ ops\n- Cycle $5$: $3$ ops\n- Cycle $6$: $3$ ops\n- Cycle $7$: $2$ ops\n- Cycle $8$: $2$ ops\n- Cycle $9$: $2$ ops\n- Cycle $10$: $2$ ops\n- Cycle $11$: $3$ ops\n\n$$ N_{\\text{ops, original}} = 3+3+3+2+3+3+3+2+2+2+2+3 = 31 $$\nThe original IPC is the average number of micro-operations issued per cycle.\n$$ \\mathrm{IPC}_{\\text{original}} = \\frac{N_{\\text{ops, original}}}{\\text{Total Cycles}} = \\frac{31}{12} $$\n\n**4. Compute the throughput speedup factor.**\nThe proposed modification is the addition of a second memory Issue port. The new configuration is:\n- $2$ integer ports\n- $2$ memory ports\nThe maximum issue width is now $2+2=4$. The problem states that any ready $\\mathrm{L}$ operation that was previously stalled due to memory port saturation will now issue. We re-evaluate the issue counts for the modified machine ($N_{\\text{ops, new}}$).\n\n- Cycle $0, 1, 2, 4, 5, 6, 11$: Issue count was $3$, no stalls. Count remains $3$.\n- Cycle $3$: Originally issued $2$ ops. One ready $\\mathrm{L}$ was stalled. With a second memory port, this $\\mathrm{L}$ can issue. New issue count: $2+1=3$.\n- Cycle $7$: Originally issued $2$ ops. One ready $\\mathrm{L}$ was stalled. With a second memory port, this $\\mathrm{L}$ can issue. New issue count: $2+1=3$.\n- Cycle $8$: Originally issued $2$ ops. One ready $\\mathrm{L}$ was stalled. With a second memory port, this $\\mathrm{L}$ can issue. New issue count: $2+1=3$.\n- Cycle $9$: Originally issued $2$ ops. One ready $\\mathrm{A}$ was stalled due to integer port saturation. Adding a memory port does not resolve this. New issue count remains $2$.\n- Cycle $10$: Originally issued $2$ ops. One ready $\\mathrm{L}$ was stalled. With a second memory port, this $\\mathrm{L}$ can issue. New issue count: $2+1=3$.\n\nThe total number of micro-operations issued in the new configuration is:\n$$ N_{\\text{ops, new}} = (3 \\times 7) + 3 + 3 + 3 + 2 + 3 = 21 + 14 = 35 $$\nAlternatively, we can calculate the increase from the original count. The four memory port stalls are eliminated, adding $4$ more issued operations.\n$$ N_{\\text{ops, new}} = N_{\\text{ops, original}} + 4 = 31 + 4 = 35 $$\nThe new IPC over the same $12$-cycle interval is:\n$$ \\mathrm{IPC}_{\\text{new}} = \\frac{N_{\\text{ops, new}}}{\\text{Total Cycles}} = \\frac{35}{12} $$\nThe speedup factor is the ratio of the new IPC to the original IPC.\n$$ \\text{Speedup} = \\frac{\\mathrm{IPC}_{\\text{new}}}{\\mathrm{IPC}_{\\text{original}}} = \\frac{35/12}{31/12} = \\frac{35}{31} $$\nThe speedup factor, as an exact fraction, is $\\frac{35}{31}$.",
            "answer": "$$\\boxed{\\frac{35}{31}}$$"
        }
    ]
}