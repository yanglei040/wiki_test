{
    "hands_on_practices": [
        {
            "introduction": "Choosing the right cache block size is a classic optimization problem. A larger block can exploit spatial locality to reduce the miss rate, but it also increases the time it takes to transfer the block from memory, raising the miss penalty. This exercise  provides a quantitative framework to explore this fundamental trade-off, asking you to find the optimal block size that minimizes the overall Cycles Per Instruction ($CPI$) for a program with mixed memory access patterns.",
            "id": "3624223",
            "problem": "A single-issue in-order processor executes a large program composed of two kernels with distinct memory access patterns. The processor’s base Cycles Per Instruction (CPI) with no memory stalls is $CPI_{0}=1.00$ cycles per instruction. Misses in the first-level cache (Level-1 (L1)) stall the pipeline with a service time composed of a fixed off-chip latency plus a transfer time proportional to the cache block (line) size.\n\nAssume the following well-tested facts and definitions:\n- Cycles Per Instruction (CPI) is total cycles divided by the number of retired instructions.\n- Total cycles equal the sum of base execution cycles and stall cycles.\n- For a memory access that misses in the cache, the miss service time is the sum of a fixed latency to first response and a linear transfer time for the entire block. Denote the fixed latency by $L$ (in cycles), the block size by $B$ (in bytes), and the sustained memory bandwidth by $W$ (in bytes per cycle), so the miss service time is $L + B/W$ cycles.\n- If a kernel issues $r$ memory references per instruction and has a miss probability per reference $m(B)$ (a unitless fraction), then the expected stall cycles per instruction contributed by that kernel equals $r \\, m(B)$ times the miss service time.\n\nThe program consists of a mixture by instruction count of the two kernels:\n- Kernel $\\mathcal{A}$ (streaming): fraction $f_{\\mathcal{A}}=0.6$ of the retired instructions; memory-reference intensity $r_{\\mathcal{A}}=0.6$ references per instruction; empirical miss-rate fit $m_{\\mathcal{A}}(B)=\\frac{8}{B}+0.01$, valid for $B \\in [16,256]$ bytes.\n- Kernel $\\mathcal{B}$ (strided/random-like): fraction $f_{\\mathcal{B}}=0.4$ of the retired instructions; memory-reference intensity $r_{\\mathcal{B}}=0.3$ references per instruction; empirical miss-rate fit $m_{\\mathcal{B}}(B)=\\frac{4}{B}+0.3$, valid for $B \\in [16,256]$ bytes.\n\nThe off-chip fixed latency is $L=50$ cycles, and the sustained bandwidth is $W=8$ bytes per cycle. Assume that misses serialize execution (no overlap of miss penalties) and that the empirical miss-rate fits already incorporate all effects of compulsory, capacity, and conflict behavior for the considered $B$.\n\nUsing only the foundational definitions above, derive the overall CPI as a function of $B$ for this program mixture and determine the cache block size $B$ (in bytes) in the continuous range $[16,256]$ that minimizes the CPI. Report only the optimal $B$ and ignore any hardware constraints on block sizes being powers of two. Express your final answer in bytes, rounded to four significant figures.",
            "solution": "The problem is validated as scientifically grounded, well-posed, objective, complete, and verifiable. It represents a standard optimization problem in computer architecture. I will now proceed with a formal derivation.\n\nThe overall Cycles Per Instruction, denoted as $CPI$, for the processor is the sum of the base CPI, $CPI_{0}$, and the stall cycles per instruction due to memory accesses.\n$$\nCPI = CPI_{0} + \\text{StallCyclesPerInstruction}_{\\text{total}}\n$$\nThe base CPI is given as $CPI_{0} = 1.00$. The total stall cycles per instruction is the weighted average of the stall cycles contributed by each kernel, where the weights are the fractions of instructions belonging to each kernel.\n$$\n\\text{StallCyclesPerInstruction}_{\\text{total}} = f_{\\mathcal{A}} \\cdot (\\text{Stalls per instruction})_{\\mathcal{A}} + f_{\\mathcal{B}} \\cdot (\\text{Stalls per instruction})_{\\mathcal{B}}\n$$\nAccording to the problem definition, the stall cycles per instruction for a given kernel are the product of its memory references per instruction ($r$), its miss rate per reference ($m(B)$), and the miss service time. The miss service time is given as the sum of a fixed latency $L$ and a transfer time $B/W$.\n$$\n\\text{Miss Service Time} = L + \\frac{B}{W}\n$$\nThe stall cycles per instruction for Kernel $\\mathcal{A}$ and Kernel $\\mathcal{B}$ are therefore:\n$$\n(\\text{Stalls per instruction})_{\\mathcal{A}} = r_{\\mathcal{A}} \\cdot m_{\\mathcal{A}}(B) \\cdot \\left( L + \\frac{B}{W} \\right)\n$$\n$$\n(\\text{Stalls per instruction})_{\\mathcal{B}} = r_{\\mathcal{B}} \\cdot m_{\\mathcal{B}}(B) \\cdot \\left( L + \\frac{B}{W} \\right)\n$$\nSubstituting these into the expression for total stall cycles:\n$$\n\\text{StallCyclesPerInstruction}_{\\text{total}} = \\left[ f_{\\mathcal{A}} r_{\\mathcal{A}} m_{\\mathcal{A}}(B) + f_{\\mathcal{B}} r_{\\mathcal{B}} m_{\\mathcal{B}}(B) \\right] \\cdot \\left( L + \\frac{B}{W} \\right)\n$$\nLet's define the effective miss rate per instruction for the program mixture, $M(B)$, as the term in the brackets:\n$$\nM(B) = f_{\\mathcal{A}} r_{\\mathcal{A}} m_{\\mathcal{A}}(B) + f_{\\mathcal{B}} r_{\\mathcal{B}} m_{\\mathcal{B}}(B)\n$$\nThe overall $CPI$ as a function of the block size $B$ is then:\n$$\nCPI(B) = CPI_{0} + M(B) \\cdot \\left( L + \\frac{B}{W} \\right)\n$$\nWe are given the following values:\n- $CPI_{0} = 1.00$\n- $L=50$ cycles\n- $W=8$ bytes/cycle\n- For Kernel $\\mathcal{A}$: $f_{\\mathcal{A}}=0.6$, $r_{\\mathcal{A}}=0.6$, $m_{\\mathcal{A}}(B) = \\frac{8}{B} + 0.01$\n- For Kernel $\\mathcal{B}$: $f_{\\mathcal{B}}=0.4$, $r_{\\mathcal{B}}=0.3$, $m_{\\mathcal{B}}(B) = \\frac{4}{B} + 0.3$\n\nFirst, we compute the products $f_{\\mathcal{A}} r_{\\mathcal{A}}$ and $f_{\\mathcal{B}} r_{\\mathcal{B}}$:\n$$\nf_{\\mathcal{A}} r_{\\mathcal{A}} = 0.6 \\times 0.6 = 0.36\n$$\n$$\nf_{\\mathcal{B}} r_{\\mathcal{B}} = 0.4 \\times 0.3 = 0.12\n$$\nNow, substitute these into the expression for $M(B)$:\n$$\nM(B) = 0.36 \\left( \\frac{8}{B} + 0.01 \\right) + 0.12 \\left( \\frac{4}{B} + 0.3 \\right)\n$$\nExpanding and collecting terms:\n$$\nM(B) = \\frac{0.36 \\times 8}{B} + 0.36 \\times 0.01 + \\frac{0.12 \\times 4}{B} + 0.12 \\times 0.3\n$$\n$$\nM(B) = \\frac{2.88}{B} + 0.0036 + \\frac{0.48}{B} + 0.036\n$$\n$$\nM(B) = \\frac{2.88 + 0.48}{B} + (0.0036 + 0.036) = \\frac{3.36}{B} + 0.0396\n$$\nNow, we can write the full expression for $CPI(B)$:\n$$\nCPI(B) = 1.00 + \\left( \\frac{3.36}{B} + 0.0396 \\right) \\cdot \\left( 50 + \\frac{B}{8} \\right)\n$$\nTo find the minimum, we must first expand this expression:\n$$\nCPI(B) = 1.00 + \\left( \\frac{3.36}{B} \\cdot 50 + \\frac{3.36}{B} \\cdot \\frac{B}{8} + 0.0396 \\cdot 50 + 0.0396 \\cdot \\frac{B}{8} \\right)\n$$\n$$\nCPI(B) = 1.00 + \\left( \\frac{168}{B} + \\frac{3.36}{8} + 1.98 + \\frac{0.0396}{8} B \\right)\n$$\nCalculating the constant terms:\n$$\n\\frac{3.36}{8} = 0.42\n$$\n$$\n\\frac{0.0396}{8} = 0.00495\n$$\nSo the expression for $CPI(B)$ becomes:\n$$\nCPI(B) = 1.00 + \\frac{168}{B} + 0.42 + 1.98 + 0.00495 B\n$$\nCombining all constant terms:\n$$\nCPI(B) = (1.00 + 0.42 + 1.98) + \\frac{168}{B} + 0.00495 B\n$$\n$$\nCPI(B) = 3.40 + \\frac{168}{B} + 0.00495 B\n$$\nTo find the block size $B$ that minimizes $CPI(B)$, we compute the derivative of $CPI(B)$ with respect to $B$ and set it to zero.\n$$\n\\frac{d}{dB} CPI(B) = \\frac{d}{dB} \\left( 3.40 + 168 B^{-1} + 0.00495 B \\right)\n$$\n$$\n\\frac{d}{dB} CPI(B) = 0 - 168 B^{-2} + 0.00495 = -\\frac{168}{B^2} + 0.00495\n$$\nSetting the derivative to zero to find the critical point:\n$$\n-\\frac{168}{B^2} + 0.00495 = 0\n$$\n$$\n\\frac{168}{B^2} = 0.00495\n$$\n$$\nB^2 = \\frac{168}{0.00495} \\approx 33939.39\n$$\nSolving for $B$:\n$$\nB = \\sqrt{\\frac{168}{0.00495}}\n$$\n$$\nB \\approx 184.226474 \\text{ bytes}\n$$\nTo confirm this is a minimum, we examine the second derivative:\n$$\n\\frac{d^2}{dB^2} CPI(B) = \\frac{d}{dB} \\left( -168 B^{-2} + 0.00495 \\right) = (-2)(-168) B^{-3} = \\frac{336}{B^3}\n$$\nSince the block size $B$ must be positive, the second derivative $\\frac{336}{B^3}$ is always positive. This confirms that the function $CPI(B)$ is convex and the critical point corresponds to a global minimum.\n\nThe calculated optimal value $B \\approx 184.226$ bytes is within the specified valid range of $B \\in [16, 256]$. The problem asks for the result rounded to four significant figures.\n$$\nB = 184.2 \\text{ bytes}\n$$",
            "answer": "$$\\boxed{184.2}$$"
        },
        {
            "introduction": "Beyond the general trade-off between miss rate and miss penalty, cache performance is deeply affected by how memory addresses map to cache sets. This practice  delves into the problem of conflict misses, where different data items compete for the same cache location due to their addresses. You will analyze how the interplay between memory layout, data access patterns, and cache block size can lead to systematic index aliasing, and determine the optimal block size to minimize these conflicts.",
            "id": "3624208",
            "problem": "Consider a single-level direct-mapped cache in a computer system with capacity $C = 64 \\times 1024$ bytes. The cache block (line) size $B$ must be chosen from the set $\\{128, 256, 512\\}$ bytes. There are two large arrays $X$ and $Y$ stored in main memory. Each array holds double-precision floating-point elements, so the element size is $e = 8$ bytes. The base address of $X$ is $a_0$, which is aligned to every candidate $B$ (i.e., $a_0 \\equiv 0 \\pmod{B}$ for any chosen $B$). The base address of $Y$ is $a_0 + d$ where $d = 65{,}400$ bytes. The program sequentially traverses both arrays in lockstep: at iteration $i \\in \\{0,1,2,\\dots\\}$, it accesses $X[i]$ and then $Y[i]$.\n\nUse the standard definition of cache indexing for a direct-mapped cache: for a memory address $A$, the block number is $b(A) = \\left\\lfloor \\frac{A}{B} \\right\\rfloor$ and the cache set index is $s(A) = b(A) \\bmod N_s$, where $N_s = \\frac{C}{B}$ is the number of sets. Two accesses alias in the index if they map to the same set, i.e., $s(A_1) = s(A_2)$.\n\nStarting only from these definitions and the given parameters:\n- Derive a closed-form expression for the long-run fraction of iterations (over one full period induced by modular arithmetic on block offsets) in which $X[i]$ and $Y[i]$ alias in the index, as a function of $d$ and $B$. Your expression must be in terms of $d$, $B$, $C$, and $e$, and may use the floor function, the greatest common divisor $\\gcd(\\cdot,\\cdot)$, and modular congruences. Let this fraction be denoted by $\\alpha(d,B)$.\n- Using your expression, evaluate $\\alpha(d,B)$ for the three candidate values of $B$ and determine the value of $B$ that minimizes index aliasing (and thus minimizes conflict misses) for the given $d$. If there is a tie, select the smallest $B$.\n- Express the optimal $B$ in bytes. No rounding is required. The final answer must be given as a two-entry row matrix, with the first entry equal to the optimal $B$ and the second entry equal to your general closed-form expression for $\\alpha(d,B)$.",
            "solution": "The problem is evaluated as valid, as it is self-contained, scientifically grounded in the principles of computer architecture, and well-posed. We may proceed with a formal solution.\n\nThe core of the problem is to determine when two memory accesses, one to array $X$ and one to array $Y$, map to the same cache set index. We are given a direct-mapped cache. The address of the $i$-th element of array $X$ is $A_X(i) = a_0 + i \\cdot e$, and for array $Y$ is $A_Y(i) = a_0 + d + i \\cdot e$.\n\nAccording to the provided definitions, the cache set index $s$ for a memory address $A$ is given by $s(A) = \\lfloor A / B \\rfloor \\bmod N_s$, where $B$ is the cache block size, and $N_s = C/B$ is the number of sets in the cache. Two accesses to addresses $A_1$ and $A_2$ alias in the index if $s(A_1) = s(A_2)$. This is equivalent to the condition on their block numbers:\n$$\n\\lfloor A_1/B \\rfloor \\equiv \\lfloor A_2/B \\rfloor \\pmod{N_s}\n$$\nFor the given access pattern, aliasing occurs at iteration $i$ if:\n$$\n\\lfloor \\frac{a_0 + i \\cdot e}{B} \\rfloor \\equiv \\lfloor \\frac{a_0 + d + i \\cdot e}{B} \\rfloor \\pmod{N_s}\n$$\nThe base address $a_0$ is aligned to every candidate block size $B$, meaning $a_0$ is a multiple of $B$. We can write $a_0 = k \\cdot B$ for some integer $k$. Substituting this into the congruence relation yields:\n$$\n\\lfloor \\frac{k \\cdot B + i \\cdot e}{B} \\rfloor \\equiv \\lfloor \\frac{k \\cdot B + d + i \\cdot e}{B} \\rfloor \\pmod{N_s}\n$$\n$$\nk + \\lfloor \\frac{i \\cdot e}{B} \\rfloor \\equiv k + \\lfloor \\frac{d + i \\cdot e}{B} \\rfloor \\pmod{N_s}\n$$\nSubtracting $k$ from both sides, the aliasing condition simplifies to:\n$$\n\\lfloor \\frac{i \\cdot e}{B} \\rfloor \\equiv \\lfloor \\frac{d + i \\cdot e}{B} \\rfloor \\pmod{N_s}\n$$\nLet us analyze the term $\\lfloor (d + i \\cdot e) / B \\rfloor$. We can decompose $d$ with respect to $B$ as $d = q_d B + r_d$, where $q_d = \\lfloor d/B \\rfloor$ is the quotient and $r_d = d \\bmod B$ is the remainder, with $0 \\le r_d < B$. Similarly, let $i \\cdot e = q_{ie} B + r_{ie}$, where $q_{ie} = \\lfloor (i \\cdot e)/B \\rfloor$ and $r_{ie} = (i \\cdot e) \\bmod B$.\nSubstituting these into the congruence:\n$$\nq_{ie} \\equiv \\lfloor \\frac{(q_d B + r_d) + (q_{ie} B + r_{ie})}{B} \\rfloor \\pmod{N_s}\n$$\n$$\nq_{ie} \\equiv q_d + q_{ie} + \\lfloor \\frac{r_d + r_{ie}}{B} \\rfloor \\pmod{N_s}\n$$\nThis simplifies to the fundamental aliasing condition for iteration $i$:\n$$\n0 \\equiv \\lfloor \\frac{d}{B} \\rfloor + \\left\\lfloor \\frac{(d \\bmod B) + ((i \\cdot e) \\bmod B)}{B} \\right\\rfloor \\pmod{C/B}\n$$\nLet $\\Delta(i) = \\lfloor ((d \\bmod B) + ((i \\cdot e) \\bmod B)) / B \\rfloor$. Since $0 \\le d \\bmod B < B$ and $0 \\le (i \\cdot e) \\bmod B < B$, the sum in the numerator is in the range $[0, 2B-2]$. Therefore, $\\Delta(i)$ can only take values $0$ or $1$.\nThe aliasing condition becomes $ \\lfloor d/B \\rfloor + \\Delta(i) \\equiv 0 \\pmod{C/B} $.\n\nThe value of $\\Delta(i)$ depends on $i$ through the term $(i \\cdot e) \\bmod B$. This sequence is periodic. The length of the period, $P$, is the smallest positive integer such that $P \\cdot e \\equiv 0 \\pmod B$. This is given by $P = B / \\gcd(e, B)$. Let $g = \\gcd(e, B)$. Over one period of iterations $i \\in \\{0, 1, \\dots, P-1\\}$, the values of $(i \\cdot e) \\bmod B$ are precisely the $P$ distinct multiples of $g$ in the range $[0, B-1]$, namely $\\{0, g, 2g, \\dots, (P-1)g\\}$.\n\nWe analyze the aliasing condition over one such period. Two distinct cases arise for the congruence $ \\lfloor d/B \\rfloor + \\Delta(i) \\equiv 0 \\pmod{C/B} $, depending on the value of $\\Delta(i)$:\n\\begin{enumerate}\n    \\item Case $\\Delta(i)=0$: The condition is $\\lfloor d/B \\rfloor \\equiv 0 \\pmod{C/B}$. This occurs when $(d \\bmod B) + ((i \\cdot e) \\bmod B) < B$.\n    \\item Case $\\Delta(i)=1$: The condition is $\\lfloor d/B \\rfloor + 1 \\equiv 0 \\pmod{C/B}$. This occurs when $(d \\bmod B) + ((i \\cdot e) \\bmod B) \\ge B$.\n\\end{enumerate}\nSince $C/B > 1$ for all candidate values of $B$, these two conditions on $\\lfloor d/B \\rfloor$ are mutually exclusive.\n\nLet's find the number of iterations in a period $P$ for which $\\Delta(i)=0$ and $\\Delta(i)=1$. Let $r_d = d \\bmod B$.\n$\\Delta(i)=1$ when $(i \\cdot e) \\bmod B \\ge B - r_d$. The values of $(i \\cdot e) \\bmod B$ are multiples of $g=\\gcd(e,B)$. The number of such values, $N_{\\Delta=1}$, is the number of multiples of $g$ in the interval $[B-r_d, B-1]$. This count is given by $\\lfloor (B-1)/g \\rfloor - \\lceil (B-r_d)/g \\rceil + 1 = (P-1) - \\lceil (B-r_d)/g \\rceil + 1 = P - \\lceil (B-r_d)/g \\rceil$.\nThe number of iterations where $\\Delta(i)=0$, $N_{\\Delta=0}$, is $P - N_{\\Delta=1} = \\lceil (B-r_d)/g \\rceil = \\lceil (B-(d \\bmod B))/\\gcd(e,B) \\rceil$.\n\nThe long-run fraction of aliasing iterations, $\\alpha(d,B)$, is the number of aliasing iterations in a period divided by the period length $P$.\n\\begin{itemize}\n    \\item If $\\lfloor d/B \\rfloor \\equiv 0 \\pmod{C/B}$, aliasing happens only when $\\Delta(i)=0$. The fraction is $\\alpha(d,B) = N_{\\Delta=0} / P$.\n    \\item If $\\lfloor d/B \\rfloor + 1 \\equiv 0 \\pmod{C/B}$, aliasing happens only when $\\Delta(i)=1$. The fraction is $\\alpha(d,B) = N_{\\Delta=1} / P = (P-N_{\\Delta=0})/P = 1 - N_{\\Delta=0}/P$.\n    \\item Otherwise, no aliasing occurs, and $\\alpha(d,B) = 0$.\n\\end{itemize}\nThis yields the following piecewise expression for $\\alpha(d,B)$. To adhere to the allowed functions, we replace $\\lceil x \\rceil$ with $-\\lfloor -x \\rfloor$:\nLet $N_0(d,B) = -\\lfloor -\\frac{B - (d \\bmod B)}{\\gcd(e,B)} \\rfloor$.\n$\\alpha(d,B) = \\begin{cases} \\frac{N_0(d,B)}{B/\\gcd(e,B)} & \\text{if } \\lfloor d/B \\rfloor \\equiv 0 \\pmod{C/B} \\\\ 1 - \\frac{N_0(d,B)}{B/\\gcd(e,B)} & \\text{if } \\lfloor d/B \\rfloor + 1 \\equiv 0 \\pmod{C/B} \\\\ 0 & \\text{otherwise} \\end{cases}$\n\nNow, we evaluate this expression for the given parameters: $d = 65400$, $C = 64 \\times 1024 = 65536$, and $e = 8$.\n\n\\textbf{Case 1: $B=128$ bytes}\n\\begin{itemize}\n    \\item $\\gcd(e,B) = \\gcd(8, 128) = 8$.\n    \\item $N_s = C/B = 65536 / 128 = 512$.\n    \\item $\\lfloor d/B \\rfloor = \\lfloor 65400 / 128 \\rfloor = \\lfloor 510.9375 \\rfloor = 510$.\n    \\item We check the congruence conditions for $\\lfloor d/B \\rfloor = 510$ and $N_s=512$:\n    $510 \\not\\equiv 0 \\pmod{512}$ and $510+1 = 511 \\not\\equiv 0 \\pmod{512}$.\n    \\item Since neither condition is met, $\\alpha(65400, 128) = 0$.\n\\end{itemize}\n\n\\textbf{Case 2: $B=256$ bytes}\n\\begin{itemize}\n    \\item $\\gcd(e,B) = \\gcd(8, 256) = 8$.\n    \\item $N_s = C/B = 65536 / 256 = 256$.\n    \\item $\\lfloor d/B \\rfloor = \\lfloor 65400 / 256 \\rfloor = \\lfloor 255.46875 \\rfloor = 255$.\n    \\item We check the congruence conditions for $\\lfloor d/B \\rfloor = 255$ and $N_s=256$:\n    $255 \\not\\equiv 0 \\pmod{256}$, but $255+1 = 256 \\equiv 0 \\pmod{256}$.\n    \\item This is the second case of our formula. We calculate $N_0(d,B)$:\n    $d \\bmod B = 65400 \\bmod 256 = 120$.\n    $N_0(65400,256) = \\lceil \\frac{256-120}{8} \\rceil = \\lceil \\frac{136}{8} \\rceil = \\lceil 17 \\rceil = 17$.\n    The period is $P = B/g = 256/8 = 32$.\n    $\\alpha(65400, 256) = 1 - \\frac{17}{32} = \\frac{15}{32}$.\n\\end{itemize}\n\n\\textbf{Case 3: $B=512$ bytes}\n\\begin{itemize}\n    \\item $\\gcd(e,B) = \\gcd(8, 512) = 8$.\n    \\item $N_s = C/B = 65536 / 512 = 128$.\n    \\item $\\lfloor d/B \\rfloor = \\lfloor 65400 / 512 \\rfloor = \\lfloor 127.734375 \\rfloor = 127$.\n    \\item We check the congruence conditions for $\\lfloor d/B \\rfloor = 127$ and $N_s=128$:\n    $127 \\not\\equiv 0 \\pmod{128}$, but $127+1 = 128 \\equiv 0 \\pmod{128}$.\n    \\item This is also the second case. We calculate $N_0(d,B)$:\n    $d \\bmod B = 65400 \\bmod 512 = 376$.\n    $N_0(65400,512) = \\lceil \\frac{512-376}{8} \\rceil = \\lceil \\frac{136}{8} \\rceil = \\lceil 17 \\rceil = 17$.\n    The period is $P = B/g = 512/8 = 64$.\n    $\\alpha(65400, 512) = 1 - \\frac{17}{64} = \\frac{47}{64}$.\n\\end{itemize}\n\nComparing the aliasing fractions:\n\\begin{itemize}\n    \\item $\\alpha(d, 128) = 0$\n    \\item $\\alpha(d, 256) = 15/32 = 0.46875$\n    \\item $\\alpha(d, 512) = 47/64 \\approx 0.734375$\n\\end{itemize}\nThe minimum aliasing fraction is $0$, which is achieved with a block size of $B=128$ bytes. Therefore, the optimal block size is $128$.\n\nThe final answer requires the optimal $B$ and the general closed-form expression for $\\alpha(d,B)$.\nThe general expression, using only the allowed functions, is:\n$$\n\\alpha(d,B) =\n\\begin{cases}\n\\frac{-\\lfloor -\\frac{B - (d \\bmod B)}{\\gcd(e,B)} \\rfloor}{B/\\gcd(e,B)} & \\text{if } \\lfloor d/B \\rfloor \\equiv 0 \\pmod{C/B} \\\\\n1 - \\frac{-\\lfloor -\\frac{B - (d \\bmod B)}{\\gcd(e,B)} \\rfloor}{B/\\gcd(e,B)} & \\text{if } \\lfloor d/B \\rfloor + 1 \\equiv 0 \\pmod{C/B} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$",
            "answer": "$$\\boxed{\\pmatrix{128 & \\begin{cases} \\frac{-\\lfloor -\\frac{B - (d \\bmod B)}{\\gcd(e,B)} \\rfloor}{B/\\gcd(e,B)} & \\text{if } \\lfloor d/B \\rfloor \\equiv 0 \\pmod{C/B} \\\\ 1 - \\frac{-\\lfloor -\\frac{B - (d \\bmod B)}{\\gcd(e,B)} \\rfloor}{B/\\gcd(e,B)} & \\text{if } \\lfloor d/B \\rfloor + 1 \\equiv 0 \\pmod{C/B} \\\\ 0 & \\text{otherwise} \\end{cases} }}$$"
        },
        {
            "introduction": "In modern multi-core systems, cache coherence introduces new challenges, and the block size plays a critical role. This problem  explores the concept of \"false sharing,\" a performance pitfall where independent data accessed by different cores happen to reside on the same cache line. By analyzing a producer-consumer queue, you will quantify the probability of false sharing and calculate the overhead required to prevent it, highlighting the importance of memory layout in parallel programming.",
            "id": "3624217",
            "problem": "A software system implements a Single Producer Single Consumer (SPSC) queue as a contiguous byte array (ring buffer) in main memory. Messages are variable-sized and packed back-to-back in the buffer, with no explicit alignment or padding. The processor’s data cache uses fixed-size cache lines of size $B$ bytes. Each cache line contains addresses whose integer division by $B$ yields the same quotient; two objects share a cache line if any byte of each lies within the same such $B$-sized interval.\n\nAssume the following scientifically realistic conditions:\n- The starting address of the buffer is uniformly random modulo $B$, i.e., its displacement from the nearest lower cache-line boundary is uniformly distributed over $\\{0, 1, \\dots, B-1\\}$ and independent of message sizes. This models typical allocator variability and ensures no fixed alignment to cache lines at the buffer base.\n- The queue is large enough that wrap-around effects can be ignored for the purpose of local cache-line interactions.\n- Message sizes $S_i$ (in bytes) are independent of this base displacement and may be arbitrary positive integers; neither their distribution nor any particular value is revealed to you. The messages are packed without any padding: the start of message $i+1$ is immediately after the end of message $i$.\n\nDefine a “false sharing event” at boundary $i$ to occur if messages $i$ and $i+1$ occupy at least one common cache line, so that the end of message $i$ and the start of message $i+1$ lie in the same cache line. Consider the following:\n\n1. Using only core definitions of cache lines and modular arithmetic on addresses, derive the expected false sharing frequency $f(B)$, defined as the expected fraction of boundaries at which messages share a cache line, expressed as a function of $B$ alone. Your derivation should start from the definition that two consecutive messages share a line if and only if the end position of the first message is not at a cache-line boundary.\n\n2. Propose a line-aware padding scheme that eliminates inter-message line sharing by inserting, after each message, the minimum number of pad bytes needed so that the next message begins at the next cache-line boundary. Let $p_i$ be the per-boundary padding in bytes under this scheme, and assume the same uniformity conditions as above on the displacement of message ends modulo $B$. Derive the exact expected padding per boundary, $\\mathbb{E}[p_i]$, as an analytic function of $B$.\n\nPresent your final answer as a row matrix whose first entry is the exact expression for $f(B)$ (dimensionless as a decimal fraction) and whose second entry is the exact expression for $\\mathbb{E}[p_i]$ in bytes. No rounding is required; provide exact expressions in terms of $B$. Express the padding in bytes.",
            "solution": "The problem statement has been validated and is deemed to be scientifically grounded, well-posed, objective, and internally consistent. It presents a solvable problem in computer systems performance analysis.\n\n**Part 1: Derivation of the expected false sharing frequency $f(B)$**\n\nLet $B$ be the size of a cache line in bytes, where $B$ is a positive integer. Cache lines are defined as contiguous blocks of memory of size $B$ aligned to addresses that are multiples of $B$. An address $A$ belongs to a cache line identified by the quotient $\\lfloor A/B \\rfloor$.\n\nA false sharing event at the boundary between message $i$ and message $i+1$ occurs if the end of message $i$ and the start of message $i+1$ lie in the same cache line. Let $A_i$ be the address of the last byte of message $i$. The first byte of message $i+1$ is at address $A_i+1$. The condition for false sharing is that the cache line containing $A_i$ is the same as the cache line containing $A_i+1$. This is expressed mathematically as:\n$$\n\\lfloor \\frac{A_i}{B} \\rfloor = \\lfloor \\frac{A_i+1}{B} \\rfloor\n$$\nThis equality holds if and only if $A_i+1$ is not a multiple of $B$. In terms of modular arithmetic, this is equivalent to:\n$$\n(A_i+1) \\pmod B \\neq 0\n$$\nwhich is the same as:\n$$\nA_i \\pmod B \\neq B-1\n$$\nThis confirms the problem's starting premise: false sharing occurs if and only if the end position of the first message is not at a cache-line boundary (i.e., not the last byte of a cache line).\n\nLet $d_i = A_i \\pmod B$ be the displacement of the end of message $i$ from the start of its cache line. The variable $d_i$ can take any integer value in the set $\\{0, 1, \\dots, B-1\\}$.\n\nThe problem states that the starting address of the buffer, let's call it $A_{start}$, is uniformly random modulo $B$. This means its displacement $d_{start} = A_{start} \\pmod B$ is a discrete uniform random variable on $\\{0, 1, \\dots, B-1\\}$. The address of the end of message $i$ can be written as:\n$$\nA_i = A_{start} + \\left( \\sum_{j=1}^{i} S_j \\right) - 1\n$$\nwhere $S_j$ is the size of message $j$. Taking this modulo $B$, we get:\n$$\nd_i = A_i \\pmod B = \\left( (A_{start} \\pmod B) + \\left( \\left( \\sum_{j=1}^{i} S_j \\right) - 1 \\right) \\right) \\pmod B\n$$\nLet $X = A_{start} \\pmod B$. $X$ is uniformly distributed on $\\{0, 1, \\dots, B-1\\}$. Let $Y_i = \\left( \\left( \\sum_{j=1}^{i} S_j \\right) - 1 \\right) \\pmod B$. The problem states that message sizes $S_j$ are independent of the buffer's base displacement. Therefore, the random variable $Y_i$ is independent of $X$. The displacement $d_i$ is given by $d_i = (X + Y_i) \\pmod B$.\n\nA fundamental result in probability theory states that the sum (modulo $N$) of a discrete uniform random variable on $\\{0, 1, \\dots, N-1\\}$ and any independent integer-valued random variable is also a discrete uniform random variable on $\\{0, 1, \\dots, N-1\\}$. In our case, $N=B$. Therefore, $d_i$ is uniformly distributed over the set $\\{0, 1, \\dots, B-1\\}$. The probability of $d_i$ taking any specific value $k$ in this set is:\n$$\nP(d_i = k) = \\frac{1}{B} \\quad \\text{for } k \\in \\{0, 1, \\dots, B-1\\}\n$$\nThe false sharing frequency, $f(B)$, is the probability of a false sharing event at an arbitrary boundary. This event occurs when $d_i \\neq B-1$. We can calculate this probability as $1$ minus the probability of the complementary event, $d_i = B-1$:\n$$\nf(B) = P(d_i \\neq B-1) = 1 - P(d_i = B-1)\n$$\nUsing the uniform distribution of $d_i$:\n$$\nf(B) = 1 - \\frac{1}{B} = \\frac{B-1}{B}\n$$\n\n**Part 2: Derivation of the expected padding per boundary $\\mathbb{E}[p_i]$**\n\nThe proposed padding scheme inserts a minimum number of pad bytes, $p_i \\ge 0$, after message $i$ such that message $i+1$ begins at the next cache-line boundary.\n\nThe end of message $i$ is at address $A_i$. The storage for message $i+1$ starts after the padding. The starting address of message $i+1$ will be $A_{start, i+1} = A_i + 1 + p_i$. The condition is that this address must be a multiple of $B$, i.e., the start of a new cache line.\n$$\n(A_i + 1 + p_i) \\pmod B = 0\n$$\nLet's use the displacement $d_i = A_i \\pmod B$. The equation becomes:\n$$\n(d_i + 1 + p_i) \\pmod B = 0\n$$\nSince $d_i \\in \\{0, 1, \\dots, B-1\\}$ and $p_i \\ge 0$, the smallest non-negative $p_i$ that satisfies this congruence makes the term inside the parentheses equal to $B$.\n$$\nd_i + 1 + p_i = B\n$$\nSolving for $p_i$, we find the number of pad bytes required for a given displacement $d_i$:\n$$\np_i = B - 1 - d_i\n$$\nThis function correctly maps the displacement $d_i$ to the required padding. For instance, if $d_i=B-1$ (message ends at the last byte of a line), $p_i = B - 1 - (B-1) = 0$ bytes of padding are needed. If $d_i=0$ (message ends at the first byte of a line), $p_i = B - 1 - 0 = B-1$ bytes are needed to fill the rest of the line.\n\nWe need to find the expected padding, $\\mathbb{E}[p_i]$. We use the linearity of expectation:\n$$\n\\mathbb{E}[p_i] = \\mathbb{E}[B - 1 - d_i] = \\mathbb{E}[B] - \\mathbb{E}[1] - \\mathbb{E}[d_i] = B - 1 - \\mathbb{E}[d_i]\n$$\nThe problem states to assume the same uniformity conditions for the message ends, which we derived in Part 1. The displacement $d_i$ is a discrete uniform random variable on $\\{0, 1, \\dots, B-1\\}$. The expectation of such a variable is:\n$$\n\\mathbb{E}[d_i] = \\sum_{k=0}^{B-1} k \\cdot P(d_i=k) = \\sum_{k=0}^{B-1} k \\cdot \\frac{1}{B} = \\frac{1}{B} \\sum_{k=0}^{B-1} k\n$$\nThe sum of the first $B-1$ non-negative integers is given by the formula $\\frac{(B-1)B}{2}$.\n$$\n\\mathbb{E}[d_i] = \\frac{1}{B} \\left( \\frac{(B-1)B}{2} \\right) = \\frac{B-1}{2}\n$$\nSubstituting this result back into the expression for $\\mathbb{E}[p_i]$:\n$$\n\\mathbb{E}[p_i] = B - 1 - \\frac{B-1}{2} = (B - 1) \\left( 1 - \\frac{1}{2} \\right) = \\frac{B-1}{2}\n$$\nThe expected padding per boundary is $\\frac{B-1}{2}$ bytes.\n\nThe final answer requires a row matrix containing $f(B)$ and $\\mathbb{E}[p_i]$.\nThe first entry is $f(B) = \\frac{B-1}{B}$.\nThe second entry is $\\mathbb{E}[p_i] = \\frac{B-1}{2}$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{B-1}{B} & \\frac{B-1}{2} \\end{pmatrix}}\n$$"
        }
    ]
}