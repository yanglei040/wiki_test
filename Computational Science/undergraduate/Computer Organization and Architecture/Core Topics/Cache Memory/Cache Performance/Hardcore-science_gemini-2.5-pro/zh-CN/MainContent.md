## 引言
在现代[计算机体系结构](@entry_id:747647)中，处理器速度与[主存](@entry_id:751652)速度之间的差距日益悬殊，高速缓存（Cache）成为弥合这一性能鸿沟的关键。然而，仅仅设计一个缓存是不够的，我们如何量化其效率并系统地进行优化？本文旨在解决这一核心问题，为深入理解和提升缓存性能提供一个全面的分析框架。在接下来的内容中，读者将首先在“原理与机制”一章学习衡量缓存性能的基础理论，如[平均内存访问时间](@entry_id:746603)（AMAT）和3C模型；接着，在“应用与跨学科联系”一章，探索这些理论如何在算法设计、[高性能计算](@entry_id:169980)及[操作系统](@entry_id:752937)等实际场景中发挥作用；最后，通过“动手实践”一章的练习巩固所学知识。让我们首先深入探讨支撑缓存性能分析的基石——其核心原理与机制。

## 原理与机制

在理解了高速缓存的[基本组织](@entry_id:136556)结构之后，我们现在转向一个核心问题：如何量化并优化其性能。高速缓存的有效性直接决定了处理器在多大程度上能够避免访问缓慢[主存](@entry_id:751652)所带来的性能瓶颈。本章将深入探讨衡量高速缓存性能的基本原理，分析导致性能下降的根本机制，并介绍一系列旨在最小化处理器等待内存时间的架构设计与优化策略。

### [平均内存访问时间](@entry_id:746603)：核心性能度量

衡量内存系统性能最重要和最基础的指标是**[平均内存访问时间](@entry_id:746603) (Average Memory Access Time, AMAT)**。AMAT 代表了处理器执行一次内存访问（读取或写入）所期望的平均耗时。这个指标之所以关键，是因为它将高速缓存的多个性能维度——命中时间、缺失率和缺失代价——整合进一个单一的、具有物理意义的数值中。

我们可以从第一性原理，即[全期望定律](@entry_id:265946)，来推导 AMAT 的表达式。对于任何一次内存访问，其结果只有两种[互斥](@entry_id:752349)的可能性：**高速缓存命中 (cache hit)** 或 **高速缓存缺失 (cache miss)**。

- **命中时间 ($t_h$)**：在高速缓存中找到所需数据所花费的时间。
- **缺失率 ($MR$)**：访问高速缓存但未能找到数据的概率，通常表示为小数。
- **命中率 ($HR$)**：在高速缓存中找到数据的概率，等于 $1 - MR$。
- **缺失代价 ($t_m$)**：发生高速缓存缺失后，从下一级存储（如二级缓存或主内存）获取数据所需的**额外**时间。

一次命中的总时间是 $t_h$。一次缺失的总时间，是首先花费 $t_h$ 来确定数据不在缓存中，然后再花费 $t_m$ 来获取数据，总计为 $t_h + t_m$。根据[期望值](@entry_id:153208)的定义，AMAT 是这两种情况时间的加权平均值：

$AMAT = HR \cdot t_h + MR \cdot (t_h + t_m)$
$AMAT = (1 - MR) \cdot t_h + MR \cdot (t_h + t_m)$
$AMAT = t_h - MR \cdot t_h + MR \cdot t_h + MR \cdot t_m$

通过代数化简，我们得到 AMAT 的标准形式 ：

$AMAT = t_h + MR \cdot t_m$

这个简洁的公式是高速缓存性能分析的基石。它揭示了优化内存性能的三条主要路径：降低命中时间 $t_h$，降低缺失率 $MR$，或降低缺失代价 $t_m$。

为了更深刻地理解这三个变量的相对重要性，我们可以考察 AMAT 对 $MR$ 和 $t_m$ 的敏感度，即计算其[偏导数](@entry_id:146280) 。

$\frac{\partial AMAT}{\partial MR} = t_m$

$\frac{\partial AMAT}{\partial t_m} = MR$

这一结果意义重大。它表明，将缺失率 $MR$ 降低一个微小的量 $\Delta MR$，AMAT 的改善幅度将是 $\Delta MR \cdot t_m$。由于缺失代价 $t_m$（例如，访问[主存](@entry_id:751652)）通常非常大（可能是几十到几百个[时钟周期](@entry_id:165839)），因此 AMAT 对缺失率的变化高度敏感。相比之下，将缺失代价 $t_m$ 降低一个微小的量 $\Delta t_m$，AMAT 的改善幅度仅为 $\Delta t_m \cdot MR$。由于对于一个设计良好的缓存，缺失率 $MR$ 通常是一个很小的值（例如，小于 $0.1$），因此 AMAT 对缺失代价的绝对变化不那么敏感。

这个分析告诉我们一个重要的设计原则：**在大多数情况下，降低缺失率通常比同等程度地降低缺失代价能带来更大的性能收益**。这解释了为什么架构师们愿意投入巨大的努力来设计更复杂的算法和结构以降低哪怕是一点点的缺失率。

### 解构高速缓存缺失：3C模型

为了有效地降低缺失率，我们必须首先理解缺失发生的原因。一个被广泛接受的分类框架是 **3C 模型**，它将所有高速缓存缺失分为三种独立的类型：强制性缺失、容量缺失和冲突缺失 。

#### 强制性缺失 (Compulsory Misses)

**强制性缺失**，又称**冷启动缺失 (cold-start misses)**，是由于程序首次访问一个内存块所引起的。当一个内存块第一次被访问时，它必然不在缓存中，因此必须从[主存](@entry_id:751652)中获取。这种缺失是不可避免的，因为数据必须在某个时刻被首次加载。

要隔离和测量强制性缺失，我们可以设计一个微基准测试：在一个清空的（冷的）缓存上，对一个数据结构进行单次、不重复的遍历。例如，考虑一个程序顺序读取一个 $32 \text{ KiB}$ 的数组，其元素大小为 $8 \text{ B}$，而缓存块大小为 $64 \text{ B}$。每个 $64 \text{ B}$ 的缓存块包含 $64 / 8 = 8$ 个元素。当第一个元素被访问时，会发生一次强制性缺失，整个 $64 \text{ B}$ 的块被加载到缓存中。随后对该块内其余 $7$ 个元素的访问将是命中。因此，在这个理想的顺序访问模式下，每 $8$ 次访问中有 $1$ 次是强制性缺失，缺失率 $M_c = \frac{1}{8} = 0.125$。

对于一个包含 L1 和 L2 两级缓存的系统，如果整个系统是冷启动，那么 L1 的强制性缺失也必然导致 L2 的强制性缺失。假设 L1 命中时间 $t_1 = 1$ 周期，L2 命中时间 $t_2 = 10$ 周期，内存访问惩罚 $t_m = 100$ 周期，那么在这种纯强制性缺失的场景下，AMAT 将是：
$AMAT_c = t_1 + M_c \cdot (t_2 + M_{2|1} \cdot t_m) = 1 + 0.125 \cdot (10 + 1 \cdot 100) = 14.75$ 周期。
由缺失所引入的惩罚时间为 $13.75$ 周期，占总 AMAT 的 $13.75 / 14.75 \approx 93.2\%$，显示了即使是不可避免的强制性缺失也会对性能产生巨大影响 。

增加缓存块大小是利用[空间局部性](@entry_id:637083)来减少强制性缺失的有效手段。

#### 容量缺失 (Capacity Misses)

**容量缺失**发生在缓存无法容纳程序在一段时间内需要访问的所有数据块时。即使缓存是全相联的（即没有冲突），如果程序的工作集（active data set）大小超过了缓存的总容量，一些数据块仍然会被替换出去，在将来需要时再次访问就会导致缺失。

为了专门引发容量缺失，我们可以设计一个微基准测试，让程序反复访问一个大小超过 L1 缓存但小于 L2 缓存的工作集。例如，在一个拥有 $64 \text{ KiB}$ L1 缓存和 $512 \text{ KiB}$ L2 缓存的系统上，我们可以让程序反复遍历一个 $256 \text{ KiB}$ 的数组。在程序的第一遍遍历之后，整个数组将被加载到 L2 缓存中。在后续的遍历中，当访问数组的开头部[分时](@entry_id:274419)，会发现对应的数据块已因访问数组的后半部分而被从 L1 缓存中逐出。因此，几乎每次对 L1 的访问都会是容量缺失，即 $M_k \approx 1$。然而，由于整个工作集都驻留在 L2 中，这些 L1 缺失几乎总能在 L2 中命中，即 L2 的条件缺失率 $M_{2|1} \approx 0$。

在这种情况下，AMAT 将是：
$AMAT_k = t_1 + M_k \cdot (t_2 + M_{2|1} \cdot t_m) = 1 + 1 \cdot (10 + 0 \cdot 100) = 11$ 周期。
由缺失引入的惩罚时间为 $10$ 周期，占总 AMAT 的 $10 / 11 \approx 90.9\%$ 。

减少容量缺失最直接的方法是增加缓存的容量。

#### 冲突缺失 (Conflict Misses)

**冲突缺失**发生在当多个内存块需要映射到同一个缓存组（set），而该组的相联度不足以同时容纳所有这些块时。即使缓存总容量足够大，可以容纳整个[工作集](@entry_id:756753)，这种“[地址映射](@entry_id:170087)冲突”也会导致不必要的替换和缺失。这种缺失是直接映射和[组相联缓存](@entry_id:754709)的副作用。

一个经典的冲突缺失微基准测试是，反复访问一小组内存地址，这些地址都映射到 L1 缓存的同一个组。例如，一个 $64 \text{ KiB}$、4 路组相联的 L1 缓存，块大小为 $64 \text{ B}$，共有 $256$ 个组。内存中地址相隔 $16 \text{ KiB}$ ($256 \times 64 \text{ B}$) 的块会映射到同一个 L1 组。如果我们循环访问 5 个这样的地址，由于该组只能容纳 4 个块，根据 LRU（[最近最少使用](@entry_id:751225)）替换策略，每次访问都会发现要找的块正好是被前 4 次访问所替换掉的那个。这种现象称为**缓存[抖动](@entry_id:200248) (cache thrashing)**。

在这种场景下，L1 的缺失率接近 1，即 $M_f \approx 1$。由于这 5 个块（总大小为 $5 \times 64 \text{ B} = 320 \text{ B}$）可以轻松地装入 L2 缓存中，这些 L1 缺失几乎总能在 L2 中命中，$M_{2|1} \approx 0$。其 AMAT 计算与容量缺失的例子相同，为 11 周期 。

增加缓存的相联度是减少冲突缺失的主要方法。

### 高速缓存关键参数与性能权衡

3C 模型为我们提供了理解缺失来源的框架。现在，我们将探讨如何通过调整高速缓存的三个关键设计参数——块大小、相联度和容量——来优化 AMAT。重要的是，这些参数之间存在复杂的权衡关系，优化一个参数往往会以牺牲另一个为代价。

#### 块大小与[空间局部性](@entry_id:637083)

缓存块是数据在内存和缓存之间传输的最小单位。调整块大小 $B$ 会对性能产生双重影响。

一方面，增大块大小可以更好地利用**空间局部性**。当程序访问一个地址时，它很可能在不久的将来访问附近的地址。一个更大的块会预先将更多相邻数据取入缓存，从而可能将未来的访问转化为命中。

考虑一个程序以固定步长 $s$ 访问一个大数组 。当一次访问导致缺失时，一个大小为 $B$ 的块被加载。如果步长 $s$ 小于块大小 $B$，那么接下来的 $\lfloor (B-1)/s \rfloor$ 次访问都有可能命中在这个新加载的块中。在一个理想化的[稳态模型](@entry_id:157508)中，对于满足 $s \le B$ 的情况，每加载一个新块会带来 1 次缺失和 $(B/s - 1)$ 次命中。因此，缺失率可以表示为：

$MR(s) = \frac{1}{1 + (B/s - 1)} = \frac{s}{B}$

这个模型清晰地表明，对于给定的步长 $s$，增加块大小 $B$ 可以线性地降低缺失率。例如，对于 $B = 64 \text{ bytes}$，$s = 16 \text{ bytes}$，$t_h=0.8 \text{ ns}$，$t_m=100 \text{ ns}$ 的系统，缺失率为 $MR = 16/64 = 0.25$。其 AMAT 为 $0.8 + 0.25 \cdot 100 = 25.8 \text{ ns}$。如果将块大小加倍到 $128 \text{ bytes}$，缺失率将减半至 $0.125$，AMAT 会显著降低。

然而，增加块大小并非没有代价 。
1.  **增加缺失代价**：虽然我们常将 $t_m$ 视为常数，但它实际上也依赖于 $B$。从主存传输一个更大的块需要更长的时间。
2.  **增加冲突/容量缺失**：对于一个固定容量 $C$ 的缓存，增加块大小 $B$ 意味着缓存中的总块数 $N = C/B$ 减少了。更少的块数意味着程序的不同部分更容易竞争同一缓存块，从而增加了冲突和容量缺失的风险。
3.  **可能增加命中时间**：更大的块可能需要更宽的数据通路和更复杂的选择逻辑，这可能会轻微增加 $t_h$。

一个更完整的性能模型可能会将这些因素都包含进来。例如，我们可以将 AMAT 表示为 $B$ 的函数 $AMAT(B) = t_h(B) + MR(B) \cdot t_m(B)$。假设命中时间 $t_h(B)$ 随 $B$ 对数增长，而缺失率 $MR(B)$ 包含一个正比于 $1/B$ 的[空间局部性](@entry_id:637083)项和一个正比于 $B$ 的冲突项，即 $MR(B) = m_c + \frac{k}{B} + \gamma \frac{B}{C}$。通过对这个 AMAT 函数求导并令其为零，就可以找到一个使 AMAT 最小化的**最优块大小**。例如，对于一个具体的参数集，通过求解二次方程，可以发现最优块大小可能在 $64 \text{ bytes}$ 附近 ，这与现代处理器中常见的 L1 缓存块大小相符。

#### 相联度与冲突缺失

相联度 $A$ 决定了一个内存块可以被放置在缓存中的多少个位置。增加相联度是应对冲突缺失的主要武器。一个[直接映射缓存](@entry_id:748451) ($A=1$) 对[地址映射](@entry_id:170087)的限制最严格，而一个[全相联缓存](@entry_id:749625) ($A=N$) 则完全没有冲突缺失。

提高相联度的主要好处是降低缺失率。然而，这种改进同样伴随着代价，主要是命中时间的增加 。在一个 $A$-路[组相联缓存](@entry_id:754709)中，为了判断是否命中，需要并行地比较 $A$ 个标签，然后从 $A$ 个[数据块](@entry_id:748187)中选择一个。这个过程所需的硬件（比较器和多路选择器）的复杂性和延迟会随着 $A$ 的增加而增加。

因此，这里存在一个关键的权衡：增加相联度带来的缺失率降低所节省的时间，是否足以弥补其导致的命中时间增加？我们可以量化这个决策。假设将相联度从 $A$ 增加到 $2A$，导致命中时间增加了 $\Delta t$，同时缺失率降低了 $\Delta MR$。

原始的 AMAT 为: $AMAT_1 = t_h + MR \cdot t_m$
新的 AMAT 为: $AMAT_2 = (t_h + \Delta t) + (MR - \Delta MR) \cdot t_m$

为了使这项改进有益，必须满足 $AMAT_2  AMAT_1$：

$(t_h + \Delta t) + (MR - \Delta MR) \cdot t_m  t_h + MR \cdot t_m$
$\Delta t - \Delta MR \cdot t_m  0$
$\Delta MR \cdot t_m > \Delta t$

这个不等式给出了一个明确的决策准则：只有当缺失率的降低所节省的惩罚时间（左侧）大于命中时间的增加（右侧）时，增加相联度才是值得的。我们可以定义一个**临界缺失率降低** $\Delta MR_{crit} = \frac{\Delta t}{t_m}$。任何大于此值的 $\Delta MR$ 都会带来性能提升。例如，如果命中时间增加 $0.2 \text{ ns}$，而缺失代价为 $35 \text{ ns}$，那么缺失率必须至少降低 $0.2 / 35 \approx 0.0057$ 才能实现净收益 。

#### 容量与性能成本

增加高速缓存的总容量 $C$ 是减少容量缺失的最直接方法。根据经验性的**“平方根定律”**，缓存的缺失率通常与容量的平方根成反比，即 $MR \propto \frac{1}{\sqrt{C}}$。

然而，增加容量的成本是多方面的。首先，也是最明显的，是芯片面积和[功耗](@entry_id:264815)的增加。更大的缓存需要更多的 S[RAM](@entry_id:173159) 单元。其次，更大的物理结构会导致更长的[信号传播延迟](@entry_id:271898)，从而**增加命中时间** $t_h$。这种延迟的增长通常被建模为与容量的对数或平方根成正比。

与前面类似，这也构成了一个[优化问题](@entry_id:266749) 。假设我们将 L1 缓存的容量相对于基线扩大一个因子 $\beta \ge 1$。我们可以根据经验数据建立模型，例如 $t_h(\beta) = b + c \ln(\beta)$ 和 $MR(\beta) = a \beta^{-p}$ (其中 $p \approx 0.5$ 对应平方根定律)。在一个两级缓存系统中，L1 的缺失代价是 L2 的 AMAT，即 $MP_1 = t_{h2} + MR_2 \cdot t_{mem}$。

完整的 AMAT 函数为：

$AMAT(\beta) = t_h(\beta) + MR(\beta) \cdot MP_1 = (b + c \ln(\beta)) + (a \beta^{-p}) \cdot MP_1$

通过对 $\beta$ 求导并找到导数为零的点，我们可以确定一个最优的容量缩放因子 $\beta_{opt}$，它平衡了更大容量带来的缺失率降低和命中时间增加。对于一组给定的经验参数，计算出的最优缩放因子可能为 $\beta=2.56$ ，这表明相对于基线设计，将 L1 容量扩大到约 2.5 倍可以达到最佳性能。

### 高级高速[缓存层次结构](@entry_id:747056)[性能优化](@entry_id:753341)

现代处理器采用复杂的[内存层次结构](@entry_id:163622)，其中包含[多级缓存](@entry_id:752248)和精密的管理策略。理解这些高级机制对于全面评估和优化系统性能至关重要。

#### 多级层次结构中的策略交互

在[多级缓存](@entry_id:752248)系统中，AMAT 的计算可以递归地进行。对于一个两级缓存系统，总的 AMAT 是 L1 的命中时间加上 L1 缺失所带来的惩罚。而 L1 的缺失惩罚正是访问 L2 系统的 AMAT ：

$AMAT = t_{h1} + MR_1 \cdot AMAT_2$
$AMAT = t_{h1} + MR_1 \cdot (t_{h2} + MR_2 \cdot t_m)$

其中，$MR_1$ 是 L1 的**局部缺失率**（访问 L1 的请求中有多大比例会缺失），而 $MR_2$ 是 L2 的**局部缺失率**（访问 L2 的请求中有多大比例会缺失）。

在这种层次结构中，不同设计决策之间的交互变得更加复杂。

**分离式 vs. 统一式 L1 缓存 (Split vs. Unified Caches)**
一个经典的设计选择是使用分离的 L1 [指令缓存](@entry_id:750674)和[数据缓存](@entry_id:748188)，还是使用一个统一的 L1 缓存。
- **分离式缓存**：为指令和数据提供独立的缓存和端口。优点是带宽高（指令和数据访问可以并行），且两者之间没有干扰。缺点是静态分区可能导致资源浪费，例如，一个数据密集型程序可能使[数据缓存](@entry_id:748188)溢出，而[指令缓存](@entry_id:750674)却大部分空闲。
- **统一式缓存**：指令和数据共享同一个缓存。优点是缓存空间可以被动态地分配给需求更多的一方，提高了空间利用率。缺点是可能导致**[缓存污染](@entry_id:747067) (cache pollution)**，即一种类型的访问（如流式数据）可能会逐出另一种类型（如循环中的指令）的有用数据，增加了冲突缺失。此外，通常需要更复杂的访问端口来处理并发的指令和数据请求，并且命中时间可能更长。

选择哪种方案取决于具体的工作负载。例如，考虑一个 $55\%$ 指令、$45\%$ 数据的负载 。一个分离式设计（$32\text{KB}$ [指令缓存](@entry_id:750674) + $32\text{KB}$ [数据缓存](@entry_id:748188)）和一个统一式设计（$64\text{KB}$ 统一缓存）的性能对比，需要分别计算两种情况下的 AMAT。如果指令和数据的工作集都很大，统一缓存可能会因为两种访问流的相互干扰而导致更高的整体缺失率，尽管其总容量更大。再加上分离式缓存通常有更快的命中时间，最终可能导致分离式设计的 AMAT 更低，性能更好 。

**包含策略 (Inclusion Policies)**
包含策略定义了[多级缓存](@entry_id:752248)之间内容的约束关系。
- **包含式 (Inclusive)**：要求 L2 缓存必须是 L1 缓存的超集。即，任何存在于 L1 的块也必须存在于 L2。这简化了[缓存一致性协议](@entry_id:747051)的实现，因为检查一个块是否存在于片上[缓存层次结构](@entry_id:747056)中，只需检查 L2 即可。但它的缺点是浪费了 L2 的容量，因为 L1 中的内容在 L2 中被复制了一份。其**有效总容量**为 $C_{eff} = C_2$。
- **排他式 (Exclusive)**：保证 L1 和 L2 的内容是完全不相交的。一个块要么在 L1，要么在 L2，但不能同时存在。这最大化了缓存的有效总容量，达到 $C_{eff} = C_1 + C_2$。缺点是实现更复杂，例如，从 L1 逐出的块必须被移入 L2。

这个选择直接影响 L2 的缺失率。在排他式策略下，L2 看到了更大的[有效容量](@entry_id:748806)，其全局缺失率会更低。我们可以使用一个经验性的缺失率模型 $m(C)$ 和缓存的**栈属性 (stack property)** 来量化这种差异 。L1 的局部缺失率 $MR_1 = m(C_1)$ 在两种策略下是相同的。而 L2 的局部缺失率 $MR_2 = \frac{m(C_{tot})}{m(C_1)}$，其中 $C_{tot}$ 是总[有效容量](@entry_id:748806)。

对于包含式缓存，$C_{tot}^{inc} = C_2$。对于排他式缓存，$C_{tot}^{exc} = C_1 + C_2$。由于 $C_1 + C_2 > C_2$，排他式缓存的 $MR_2$ 会更低。这会导致排他式设计的 AMAT 更低。例如，在一个具体场景中，排他式策略相比包含式策略可以将 AMAT 降低约 $0.485$ 个周期，显示了[有效容量](@entry_id:748806)最大化带来的性能优势 。

#### 写策略对性能的影响

程序的写操作给缓存设计带来了额外的复杂性。对于**[写回](@entry_id:756770) (write-back)** 策略，写操作只更新缓存中的数据，并将该缓存块标记为“脏”(dirty)。该块只有在被从缓存中逐出时，才会被写回下一级内存。

这种策略显著影响了缺失代价的计算 。当发生缓存缺失并且需要替换一个现有块时，如果被替换的块是“干净的”（未被修改），则可以直接丢弃。但如果它是“脏的”，则必须在获取新块之前（或之后，取决于具体设计）将其写回内存。

这使得缺失代价不再是一个固定的值，而是一个[期望值](@entry_id:153208)。假设获取新块的延迟是 $T_{fetch}$，写回一个脏块的延迟是 $T_{wb}$，并且在一个给定的工作负载下，被逐出的块是脏的概率为 $d$。那么，平均缺失代价 $T_{miss\_penalty}$ 变为：

$T_{miss\_penalty} = (1-d) \cdot T_{fetch} + d \cdot (T_{fetch} + T_{wb})$
$T_{miss\_penalty} = T_{fetch} + d \cdot T_{wb}$

平均缺失代价由固定的获取延迟和概率性的写回延迟组成。对于一个写密集型应用，脏块概率 $d$ 可能很高。例如，若 $T_{fetch}=36 \text{ ns}$，$T_{wb}=24 \text{ ns}$，而 $d=0.35$，则平均缺失代价为 $36 + 0.35 \cdot 24 = 44.4 \text{ ns}$。这个增加的缺失代价会直接反映在最终的 AMAT 计算中，突显了写操作对整体性能的显著影响 。

#### 非阻塞高速缓存与[延迟隐藏](@entry_id:169797)

传统的、简单的缓存设计是**阻塞式 (blocking)** 的：当发生一次缺失时，处理器会暂停执行，直到该缺失被完全服务。然而，现代高性能处理器几乎都采用**非阻塞 (non-blocking)** 或**无锁 (lockup-free)** 的缓存设计。

[非阻塞缓存](@entry_id:752546)允许处理器在处理一次或多次缓存缺失的同时，继续执行其他不依赖于[缺失数据](@entry_id:271026)的指令。这种能力被称为**命中于缺失之下 (hit-under-miss)** 或 **缺失于缺失之下 (miss-under-miss)**。

这种重叠执行的能力可以有效地“隐藏”一部分缺失代价。考虑一个实现了命中于缺失之下的 L1 缓存 。假设在 L1 缺失的服务期间，处理器能够继续执行并成功地在 L1 中命中了其他访问。如果这部分重叠是完美的，那么对于一部分 L1 缺失事件，其对 AMAT 的影响就好像它们是命中一样，因为它们的延迟被完全隐藏在了其他有用的工作中。

我们可以对此进行建模。假设有一部分比例为 $p$ 的 L1 缺失能够被完全重叠。这意味着，在计算 AMAT 时，这部分缺失不会产生额外的惩罚时间。只有剩下 $(1-p)$ 比例的 L1 缺失会产生完整的 L1 缺失代价。因此，AMAT 的公式被修正为：

$AMAT_{effective} = t_{h1} + (1-p) \cdot MR_1 \cdot (t_{h2} + MR_2 \cdot t_m)$

这里，有效的缺失率惩罚项被缩减了 $(1-p)$ 倍。例如，如果 $p=0.50$，这意味着一半的 L1 缺失延迟被隐藏了，这将极大地降低 AMAT。如果一个基线系统的 AMAT 为 $t_{h1} + MR_1 \cdot (\text{penalty})$，那么引入这种重叠能力后，AMAT 将变为 $t_{h1} + (1-p) \cdot MR_1 \cdot (\text{penalty})$。对于一个 $MR_1=0.08$ 且 L1 缺失代价为 $36$ 周期的系统，若 $p=0.5$，AMAT 中的惩罚部分将从 $0.08 \times 36 = 2.88$ 周期降低到 $0.04 \times 36 = 1.44$ 周期，这是一个巨大的性能提升 。这说明，通过[乱序执行](@entry_id:753020)和[非阻塞缓存](@entry_id:752546)等[微架构](@entry_id:751960)技术来隐藏[内存延迟](@entry_id:751862)，是与通过优化缓存参数来直接降低延迟同等重要的[性能优化](@entry_id:753341)途径。