{
    "hands_on_practices": [
        {
            "introduction": "The principle of duality often reveals profound connections between seemingly different design choices. This practice explores duality at the most fundamental level of computer arithmetic: the representation of negative numbers. By examining the relationship between two's complement and one's complement negation, you will discover how the architectural choice of an adder with a constant carry-in versus one with an end-around carry reflects a deep mathematical duality between arithmetic modulo $2^n$ and modulo $2^n - 1$. This exercise clarifies why these two popular number systems are not arbitrary alternatives, but are, in fact, mathematical duals of one another.",
            "id": "3668141",
            "problem": "An $n$-bit binary datapath must support negation in both two’s complement and one’s complement number systems using a single ripple-carry adder in the Arithmetic Logic Unit (ALU). Let $U = 2^n - 1$ denote the all-ones mask. The bitwise complement of an $n$-bit word $x$ is denoted $\\overline{x}$, and the end-around carry addition rule means that when two $n$-bit words are added and a carry-out from the most significant bit occurs, that carry-out is wrapped and added into the least significant bit. The datapath has two hardware configuration choices: either inject a constant $+1$ as the least significant carry-in, or tie the carry-out back to the least significant carry-in to realize end-around carry.\n\nUsing only the following foundations:\n- For any $x \\in \\{0,1,\\dots,U\\}$, the bitwise complement satisfies $\\overline{x} = U - x$ in ordinary unsigned arithmetic, because $x + \\overline{x} = U$.\n- Addition modulo $m$ is defined by equivalence classes of integers under congruence $\\bmod\\, m$ and has additive inverses given by $m - x$ for $x \\not\\equiv 0 \\pmod m$ and $0$ for $x \\equiv 0 \\pmod m$.\n- End-around carry addition on $n$-bit words is equivalent to addition modulo $U = 2^n - 1$ when identifying the two representations of zero in one’s complement.\n\nDerive, from these principles, the relationship between negation in the two systems and explain the minimal hardware differences needed to implement each. Then select all statements that correctly follow from this derivation.\n\nA. In an $n$-bit datapath, two’s complement negation maps $x$ to $2^n - x \\pmod{2^n}$, which can be realized as $\\overline{x}$ with an additional $+1$. In one’s complement with end-around carry, negation maps $x$ to $2^n - 1 - x \\pmod{2^n - 1}$, which is exactly $\\overline{x}$. Under the duality that exchanges modulus $2^n$ with modulus $2^n - 1$, the role of the explicit $+1$ in two’s complement is exchanged with the carry wrap in one’s complement.\n\nB. The duality fails because end-around carry addition is not associative, so it cannot be modeled as addition modulo $2^n - 1$.\n\nC. The bitwise complement operator is self-dual under exchanging logical AND and OR by De Morgan’s laws; therefore, the duality between the two negation schemes follows from De Morgan’s laws alone without any modular arithmetic reasoning.\n\nD. A single $n$-bit ripple-carry adder can implement both negation schemes by using an explicit least significant carry-in of $1$ for two’s complement and by tying the adder’s carry-out to its least significant carry-in for one’s complement; this realizes the duality by swapping a dedicated $+1$ source with a wraparound carry connection.\n\nE. In two’s complement, there are two distinct representations of zero, so matching it to one’s complement requires discarding one representation to preserve duality.",
            "solution": "The derivation proceeds from the definitions of negation in two's complement and one's complement systems.\n\n1.  **One's Complement Negation**: In an $n$-bit system, the bitwise complement $\\overline{x}$ is arithmetically equivalent to $(2^n - 1) - x$. One's complement arithmetic operates modulo $2^n - 1$, which is implemented using an end-around carry adder. The additive inverse (negation) of a number $x$ is the number $y$ such that $x + y \\equiv 0 \\pmod{2^n - 1}$. This value is $y = (2^n - 1) - x$, which is precisely the bitwise complement $\\overline{x}$. Thus, negation in one's complement is simply bitwise inversion.\n\n2.  **Two's Complement Negation**: Two's complement arithmetic operates modulo $2^n$. The additive inverse (negation) of a number $x$ is the number $y$ such that $x + y \\equiv 0 \\pmod{2^n}$. This value is $y = 2^n - x$ (for $x \\neq 0$). We can rewrite this using the identity for the bitwise complement: $2^n - x = ((2^n - 1) - x) + 1 = \\overline{x} + 1$. Thus, negation in two's complement is implemented as bitwise inversion followed by an increment.\n\nWith these derivations, we can evaluate the options:\n\n*   **A. Correct.** This statement accurately summarizes the derivations above. Two's complement negation maps $x \\to 2^n - x \\pmod{2^n}$, realized as $\\overline{x} + 1$. One's complement negation maps $x \\to 2^n - 1 - x \\pmod{2^n - 1}$, realized as $\\overline{x}$. It correctly identifies the duality: the arithmetic modulus changes ($2^n$ vs. $2^n - 1$), and the implementation of negation swaps an explicit $+1$ operation for a structural end-around carry mechanism.\n\n*   **B. Incorrect.** Addition with end-around carry is mathematically equivalent to addition modulo $2^n - 1$. This operation forms a valid cyclic group and is therefore associative.\n\n*   **C. Incorrect.** De Morgan's laws describe the duality between logical AND and OR operations. The duality between two's and one's complement is an arithmetic duality concerning number representation and modular arithmetic. While both are \"dualities,\" they are not directly related in the way suggested.\n\n*   **D. Correct.** This statement accurately describes how a single hardware adder can be adapted for operations in both systems. To compute $A - B$ (equivalent to $A + (-B)$) in two's complement, the ALU computes $A + \\overline{B} + 1$ by inverting $B$ and setting the adder's carry-in to $1$. To perform addition in one's complement, the adder's carry-out is fed back to its carry-in to implement end-around carry. This correctly maps the mathematical duality to a hardware duality: swapping a fixed carry-in source for a feedback path.\n\n*   **E. Incorrect.** This statement is reversed. Two's complement has a single, unique representation for zero ($00\\dots0$). One's complement has two representations for zero ($+0=00\\dots0$ and $-0=11\\dots1$).\n\nTherefore, statements A and D correctly describe the relationship.",
            "answer": "$$\\boxed{AD}$$"
        },
        {
            "introduction": "Building on the foundation of number representation, we now explore how duality manifests in the operations of the Arithmetic Logic Unit (ALU), the computational core of a processor. This problem focuses on the relationship between the carry and borrow flags during subtraction. You will derive from first principles the elegant dual relationship between the carry-out flag produced when subtraction is implemented as addition ($A + \\overline{B} + 1$) and the conceptual borrow flag needed for $A - B$. This hands-on derivation illustrates a powerful optimization in hardware design, where one piece of information (the carry flag) can be used to generate its dual (the borrow flag) with a simple inversion, saving logic and resources.",
            "id": "3668114",
            "problem": "Consider an $n$-bit Arithmetic Logic Unit (ALU) that implements subtraction $A - B$ using two’s complement as the addition $A + \\overline{B} + 1$, where $\\overline{B}$ is the bitwise complement of $B$. Let $A, B \\in \\{0, 1, \\dots, 2^{n} - 1\\}$ be interpreted as unsigned $n$-bit integers, and let $C_{add}$ denote the carry-out bit from the Most Significant Bit (MSB) produced by the addition $A + \\overline{B} + 1$. Define the subtraction borrow flag $C_{sub}$ to be $1$ if a borrow occurs in $A - B$ (equivalently, if $A < B$), and $0$ otherwise.\n\nStarting only from the fundamental definitions of two’s complement, unsigned $n$-bit ranges, and the meaning of carry-out and borrow, derive an expression for the borrow flag $C_{sub}$ entirely in terms of $C_{add}$ (not involving $A$ or $B$ explicitly). You must justify the expression from first principles of binary arithmetic.\n\nThen, for $n = 8$ with the specific operands $A = 0101\\,1110_{2}$ and $B = 1010\\,0011_{2}$, evaluate the value of the borrow flag $C_{sub}$ produced by the ALU using the $A + \\overline{B} + 1$ implementation. Report the value of $C_{sub}$ as your final answer. No rounding is required and no physical units are involved.",
            "solution": "The goal is to derive the relationship between the subtraction borrow flag $C_{sub}$ and the addition carry-out flag $C_{add}$ when subtraction $A-B$ is performed as $A + \\overline{B} + 1$.\n\n1.  **Derivation**: The ALU computes the sum $S = A + \\overline{B} + 1$. In unsigned $n$-bit arithmetic, the bitwise complement $\\overline{B}$ is equal to $(2^n - 1) - B$. Substituting this into the sum gives the full, un-truncated arithmetic result:\n    $$ S_{full} = A + ((2^n - 1) - B) + 1 = A - B + 2^n $$\n    The $n$-bit ALU result is $S_{full} \\pmod{2^n}$. The carry-out from the MSB, $C_{add}$, is $1$ if $S_{full} \\ge 2^n$ and $0$ otherwise.\n\n2.  **Analysis**: We analyze this based on the definition of the borrow flag, $C_{sub}$.\n    *   **Case 1: No borrow occurs ($A \\ge B$)**. By definition, $C_{sub} = 0$. Since $A \\ge B$, the term $A-B$ is non-negative ($A-B \\ge 0$). Therefore, the full sum is $S_{full} = (A - B) + 2^n \\ge 2^n$. Since the sum is greater than or equal to $2^n$, a carry-out must be generated. Thus, $C_{add} = 1$. In this case, $C_{sub} = 0$ and $C_{add} = 1$.\n    *   **Case 2: A borrow occurs ($A  B$)**. By definition, $C_{sub} = 1$. Since $A  B$, the term $A-B$ is negative ($A-B  0$). Therefore, the full sum is $S_{full} = (A - B) + 2^n  2^n$. Since the sum is less than $2^n$, no carry-out is generated. Thus, $C_{add} = 0$. In this case, $C_{sub} = 1$ and $C_{add} = 0$.\n\n3.  **Conclusion**: From both cases, we see a consistent inverse relationship: $C_{sub} = \\overline{C_{add}}$. The borrow flag is the logical negation of the carry flag produced by the adder.\n\n4.  **Calculation**: For $n=8$, we have $A = 0101\\,1110_{2}$ and $B = 1010\\,0011_{2}$. We compute $A + \\overline{B} + 1$.\n    *   $B = 1010\\,0011_{2}$\n    *   $\\overline{B} = 0101\\,1100_{2}$\n    *   The addition is:\n        ```\n          0101 1110  (A)\n        + 0101 1100  (B-bar)\n        +         1  (Carry-in)\n        -----------\n          1011 1011\n        ```\n    The 8-bit sum is $1011\\,1011_{2}$. There is no carry-out from the most significant bit. Therefore, $C_{add} = 0$.\n    Using our derived relationship, the borrow flag is $C_{sub} = \\overline{C_{add}} = \\overline{0} = 1$. This is consistent with the fact that, as unsigned integers, $A=94$ is less than $B=163$, so a borrow is required for the subtraction $A-B$.",
            "answer": "$$ \\boxed{1} $$"
        },
        {
            "introduction": "The principle of duality scales from low-level arithmetic to high-level system control, such as managing the flow of instructions in a processor pipeline. This exercise applies duality to design hazard detection logic, a critical component for ensuring correct execution and maximizing performance. You will transform a \"hazard mask,\" which identifies conditions that must cause a stall, into its dual \"issue-permit\" signal, which identifies conditions that allow execution to proceed safely. Working through this problem demonstrates how recasting a problem in its dual form, often using De Morgan's laws, can lead to more intuitive and efficient control logic, a common practice in modern microarchitecture design.",
            "id": "3668128",
            "problem": "Consider a scalar, in-order, single-issue, five-stage pipeline with stages instruction fetch (IF), instruction decode and register read (ID), execute (EX), memory access (MEM), and write back (WB). The pipeline implements full bypassing (forwarding) for arithmetic and logic instructions whose results are produced in the execute stage, but a load-use hazard remains: if an instruction in the execute stage is a load, the value it will write to its destination register is not available until the end of the memory access stage in the next cycle, so an immediately following instruction that needs that value cannot enter the execute stage in the next cycle.\n\nDefine the following Boolean vector signals over a register file of size $N=8$ (registers $r_0,\\dots,r_7$):\n- The read-demand vector $R_d(t)$ at cycle $t$ has bit $i$ set to $1$ if, at cycle $t$, the instruction in the instruction decode and register read stage reads register $r_i$, and $0$ otherwise.\n- The write-pending vector $W_s(t)$ at cycle $t$ has bit $i$ set to $1$ if, at cycle $t$, there is a load instruction in the execute stage that will write register $r_i$ and whose value will not be available to the next cycle’s execute stage, and $0$ otherwise.\n\nA bitwise hazard mask is defined by the Boolean conjunction $mask(t) = R_d(t) \\cdot W_s(t)$, where the dot denotes bitwise conjunction across the $N$ bits. The pipeline interlock uses a dual “issue-permit” vector $unmask(t)$ to decide safety: issue is permitted in cycle $t$ if and only if every bit of $unmask(t)$ is $1$; otherwise a single-cycle bubble is inserted, holding the instruction in the instruction decode and register read stage and freezing instruction fetch.\n\nStarting only from the axioms of Boolean algebra and the principle of duality, derive an expression for $unmask(t)$ in terms of $R_d(t)$ and $W_s(t)$ without introducing any new primitives. Then, apply your derived $unmask(t)$ to evaluate the following instruction sequence under the stated pipeline rules. Assume all arithmetic and logic instructions produce results in the execute stage that can be forwarded without stalls; the load-use hazard is the only source of stalls. The instruction sequence is:\n\n$I_1$: load $r_1 \\leftarrow M[r_2]$  \n$I_2$: add $r_3 \\leftarrow r_1 + r_4$  \n$I_3$: add $r_5 \\leftarrow r_3 + r_6$  \n$I_4$: load $r_3 \\leftarrow M[r_7]$  \n$I_5$: add $r_0 \\leftarrow r_3 + r_1$  \n$I_6$: add $r_7 \\leftarrow r_0 + r_3$\n\nCompute the total number of clock cycles required to complete all $6$ instructions, including initial pipeline fill and any stalls induced by the interlock using your $unmask(t)$ expression. Express your final answer as a single integer number of cycles. No rounding is needed.",
            "solution": "The problem requires deriving an expression for the `unmask(t)` vector and then calculating the total execution time for a given instruction sequence.\n\nFirst, we derive the expression for the issue-permit vector, $unmask(t)$. A pipeline stall is required if a load-use hazard is detected. A hazard exists for a register $r_i$ if the instruction in the ID stage reads it ($R_{d,i}(t)=1$) AND a load instruction in the EX stage is pending a write to it ($W_{s,i}(t)=1$). This is captured by the bitwise hazard mask, $mask_i(t) = R_{d,i}(t) \\cdot W_{s,i}(t)$. The pipeline must stall if a hazard exists for *any* register, which corresponds to the logical OR of all bits in the mask vector being 1. Let $Stall(t)$ be the signal to stall.\n$$Stall(t) = \\bigvee_{i=0}^{N-1} mask_i(t) = \\bigvee_{i=0}^{N-1} (R_{d,i}(t) \\cdot W_{s,i}(t))$$\nThe pipeline is permitted to issue an instruction if it does not have to stall, so the global issue permit signal $Permit(t)$ is the negation of the stall signal: $Permit(t) = \\neg Stall(t)$.\n$$Permit(t) = \\neg \\left( \\bigvee_{i=0}^{N-1} (R_{d,i}(t) \\cdot W_{s,i}(t)) \\right)$$\nApplying De Morgan's laws, which are a direct consequence of the principle of duality, we transform this expression:\n$$Permit(t) = \\bigwedge_{i=0}^{N-1} \\neg(R_{d,i}(t) \\cdot W_{s,i}(t))$$\nThe problem states that issue is permitted if and only if every bit of the dual \"issue-permit\" vector $unmask(t)$ is 1. This means $Permit(t) = \\bigwedge_{i=0}^{N-1} unmask_i(t)$. By comparing the two expressions for $Permit(t)$, we can identify the expression for each bit of the $unmask$ vector:\n$$unmask_i(t) = \\neg(R_{d,i}(t) \\cdot W_{s,i}(t))$$\nIn vector notation, this is $unmask(t) = \\neg(R_d(t) \\cdot W_s(t))$. The issue-permit vector is the bitwise complement of the hazard mask vector.\n\nSecond, we trace the pipeline to find the total execution time. The pipeline has 5 stages, so without stalls, 6 instructions would take $m - 1 + k = 5 - 1 + 6 = 10$ cycles. We add cycles for any stalls. A stall occurs if an instruction in ID depends on the result of a `load` instruction in EX.\n\n*   **Cycle 3**: $I_1$ (`load r1`) is in EX, and $I_2$ (`add r3 - r1 + r4`) is in ID. $I_2$ reads $r_1$. A hazard exists. $I_2$ is stalled in the ID stage for one cycle. **(+1 cycle)**\n*   **Cycle 4**: A bubble is inserted into the EX stage. $I_1$ moves to MEM.\n*   **Cycle 5**: $I_2$ enters EX. The value of $r_1$ is forwarded from the MEM stage of $I_1$.\n*   **Cycle 6**: $I_2$ (`add r3`) is in MEM, $I_3$ (`add r5 - r3 + r6`) is in EX. The dependency on $r_3$ is an ALU-to-ALU dependency, which is resolved by forwarding without a stall.\n*   **Cycle 7**: $I_4$ (`load r3`) is in EX, and $I_5$ (`add r0 - r3 + r1`) is in ID. $I_5$ reads $r_3$. A load-use hazard exists. $I_5$ is stalled in the ID stage. **(+1 cycle)**\n*   **Cycle 8**: A bubble is inserted into the EX stage. $I_4$ moves to MEM.\n*   **Cycle 9**: $I_5$ enters EX. The value of $r_3$ is forwarded from $I_4$.\n*   **Cycle 10**: $I_5$ (`add r0`) is in MEM, $I_6$ (`add r7 - r0 + r3`) is in EX. $I_6$ needs $r_0$ (from $I_5$) and $r_3$ (from $I_4$). The value of $r_0$ is forwarded from $I_5$. The value of $r_3$ from the `load` instruction $I_4$ was written back to the register file at the end of cycle 9, so it is available for $I_6$ to read. No stall occurs.\n\nThere are two stall cycles in total.\nTotal Cycles = Baseline Cycles + Stall Cycles = $10 + 2 = 12$.\nThe final instruction, $I_6$, completes its WB stage at the end of cycle 12.",
            "answer": "$$\\boxed{12}$$"
        }
    ]
}