{
    "hands_on_practices": [
        {
            "introduction": "To effectively design and optimize a warehouse-scale computer, we must first understand the structure of the applications it runs. Modern services are often built as a collection of smaller, interconnected microservices, forming a dependency graph for each user request. This exercise guides you through analyzing such a graph to find its \"critical path\"—the longest sequence of dependent tasks that determines the minimum possible end-to-end latency. Mastering this analysis is the first step toward identifying true performance bottlenecks in a complex distributed system .",
            "id": "3688299",
            "problem": "A microservice deployment in a Warehouse-Scale Computer (WSC) is modeled as a directed acyclic graph (DAG) with node set $V = \\{A,B,C,D,E,F\\}$ and edge set $E = \\{(A,B),(A,C),(B,D),(B,E),(C,F)\\}$. Each node $i \\in V$ represents a microservice that, upon invocation, performs local processing for time $t_i$ and then, if it has outgoing edges, issues calls to all immediate successors concurrently and waits until all of them have completed before it returns. Assume the following per-node processing times (in milliseconds): $t_A = 12$, $t_B = 8$, $t_C = 15$, $t_D = 40$, $t_E = 20$, $t_F = 30$. The call fan-outs are $f_A = 2$, $f_B = 2$, $f_C = 1$, and $f_D = f_E = f_F = 0$. The root of the DAG is $A$, and leaves are $D$, $E$, and $F$. Assume negligible network delay and abundant resources so that all parallel calls run without queueing interference.\n\nUsing only first principles appropriate to performance modeling of parallel compositions in computer organization and architecture—namely, that issuing independent calls concurrently and waiting for all to complete yields an effective downstream wait equal to the maximum of the branch completion times—derive the end-to-end latency from the root $A$ to completion. Then, under the assumption that there is a unique critical path and that infinitesimal reductions in a single $t_i$ do not change the identity of that path, determine the sensitivity vector $\\mathbf{s}$ where the component $s_i$ equals the first-order change in the end-to-end latency at $A$ per unit decrease in $t_i$, for $i$ ordered as $(A,B,C,D,E,F)$. Report the latency rounded to four significant figures and express it in milliseconds. Your final answer must be a single row matrix whose first entry is the latency value and whose remaining entries are the six components of $\\mathbf{s}$ in the order $(A,B,C,D,E,F)$.",
            "solution": "The user wants me to solve a performance modeling problem for a microservice deployment in a Warehouse-Scale Computer (WSC).\n\n### Step 1: Problem Validation\n\nFirst, I must validate the problem statement.\n\n#### Step 1.1: Extract Givens\n- **Node Set**: $V = \\{A,B,C,D,E,F\\}$.\n- **Edge Set**: $E = \\{(A,B),(A,C),(B,D),(B,E),(C,F)\\}$, representing a directed acyclic graph (DAG).\n- **Execution Model**: A node $i$ executes for a local processing time $t_i$. If it has successors, it calls them concurrently and waits for all to complete. The total latency of a node is its local processing time plus the time spent waiting for its downstream calls.\n- **Principle for Downstream Wait**: The wait time for concurrent calls is the maximum of the completion times of the parallel branches.\n- **Node Processing Times (in milliseconds)**: $t_A = 12$, $t_B = 8$, $t_C = 15$, $t_D = 40$, $t_E = 20$, $t_F = 30$.\n- **Graph Structure**: Root is $A$; leaves are $D$, $E$, and $F$.\n- **Assumptions**: Network delay is negligible. Resources are abundant, so no queueing interference occurs. There is a unique critical path, and infinitesimal reductions in a single $t_i$ do not alter its identity.\n- **Tasks**:\n  1. Derive the end-to-end latency from the root $A$.\n  2. Determine the sensitivity vector $\\mathbf{s} = (s_A, s_B, s_C, s_D, s_E, s_F)$, where $s_i$ is the first-order change in end-to-end latency per unit decrease in $t_i$.\n- **Reporting Format**:\n  1. The latency must be rounded to four significant figures and expressed in milliseconds.\n  2. The final answer is a single row matrix containing the latency and the six components of $\\mathbf{s}$.\n\n#### Step 1.2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is well-grounded in the principles of performance analysis for parallel and distributed systems, a core topic in computer organization and architecture. The use of a DAG to model dependencies and the critical path method to find latency are standard techniques.\n- **Well-Posedness**: The problem is well-posed. The graph, processing times, and rules for calculation are all explicitly provided, leading to a unique solution for latency and sensitivity.\n- **Objectivity**: The problem statement is objective, quantitative, and free of subjective or ambiguous language, with the minor exception of the phrasing for \"sensitivity,\" which will be addressed in the solution through a reasoned interpretation based on disciplinary convention.\n- **Flaw Analysis**:\n  - The problem does not violate scientific principles.\n  - It is formalizable and directly relevant to the specified domain.\n  - The givens are complete and consistent. The fan-out data, while redundant, matches the provided edge set.\n  - The assumptions (e.g., negligible delay) are standard simplifications in first-order modeling and do not render the problem invalid.\n  - The structure ensures a unique, stable solution.\n\n#### Step 1.3: Verdict and Action\nThe problem is valid. I will now proceed with a full solution.\n\n### Step 2: Solution Derivation\n\n#### Part 1: End-to-End Latency Calculation\n\nThe end-to-end latency of a service call graph is determined by the critical path, which is the longest path from the root to a leaf in terms of total execution time. Let $L(i)$ be the total latency of the subgraph rooted at node $i$. This can be defined recursively based on the problem description.\n\nFor any leaf node $i$ (a node with no successors), its latency is simply its own processing time:\n$$L(i) = t_i$$\n\nFor any non-leaf node $i$, its latency is its own processing time plus the maximum of the latencies of its successor branches, as the calls are concurrent and the node must wait for all to finish:\n$$L(i) = t_i + \\max_{j \\in \\text{succ}(i)} \\{L(j)\\}$$\nwhere $\\text{succ}(i)$ is the set of immediate successors of node $i$.\n\nWe calculate the latencies by working backward from the leaves of the DAG: $D$, $E$, and $F$.\n\n1.  **Latency of Leaf Nodes**:\n    $L(D) = t_D = 40 \\, \\text{ms}$\n    $L(E) = t_E = 20 \\, \\text{ms}$\n    $L(F) = t_F = 30 \\, \\text{ms}$\n\n2.  **Latency of Internal Nodes**:\n    -   Node $C$ has one successor, $F$.\n        $$L(C) = t_C + L(F) = 15 + 30 = 45 \\, \\text{ms}$$\n    -   Node $B$ has two successors, $D$ and $E$.\n        $$L(B) = t_B + \\max\\{L(D), L(E)\\} = 8 + \\max\\{40, 20\\} = 8 + 40 = 48 \\, \\text{ms}$$\n\n3.  **Latency of Root Node**:\n    -   Node $A$ has two successors, $B$ and $C$. The end-to-end latency is $L(A)$.\n        $$L(A) = t_A + \\max\\{L(B), L(C)\\} = 12 + \\max\\{48, 45\\} = 12 + 48 = 60 \\, \\text{ms}$$\n\nThe end-to-end latency is $60 \\, \\text{ms}$. The problem requires this value to be rounded to four significant figures, which is $60.00 \\, \\text{ms}$.\n\n#### Part 2: Sensitivity Vector Calculation\n\nThe sensitivity $s_i$ is defined as \"the first-order change in the end-to-end latency at $A$ per unit decrease in $t_i$\". Let the total latency be $L_{total} = L(A)$. The first-order change $\\Delta L_{total}$ resulting from a small change $\\Delta t_i$ is given by $\\Delta L_{total} \\approx \\frac{\\partial L_{total}}{\\partial t_i} \\Delta t_i$. For a \"unit decrease in $t_i$\", we have $\\Delta t_i = -1$. Thus, the change is $-\\frac{\\partial L_{total}}{\\partial t_i}$.\n\nIt is a standard convention in performance engineering to define sensitivity as the direct partial derivative $\\frac{\\partial L_{total}}{\\partial t_i}$, which represents the rate of change of the total latency with respect to a component's latency. This value is non-negative and indicates the magnitude of impact. We will adopt this standard definition, where $s_i = \\frac{\\partial L_{total}}{\\partial t_i}$. A value of $s_i=1$ means that a change in $t_i$ causes an identical change in $L_{total}$, whereas $s_i=0$ means a change in $t_i$ has no first-order effect on $L_{total}$.\n\nTo calculate these derivatives, we first identify the critical path. The critical path is the sequence of nodes that determined the maximum at each fork:\n- At node $A$, the branch through $B$ was chosen because $L(B) = 48  L(C) = 45$.\n- At node $B$, the branch through $D$ was chosen because $L(D) = 40  L(E) = 20$.\nThus, the unique critical path is $A \\rightarrow B \\rightarrow D$.\n\nThe problem states that we can assume infinitesimal changes do not alter the critical path. This allows us to express the total latency $L_{total}$ as a simple sum of the processing times of the nodes on this critical path:\n$$L_{total}(t_A, t_B, t_C, t_D, t_E, t_F) = t_A + t_B + t_D$$\n\nNow we can compute the sensitivity components $s_i = \\frac{\\partial L_{total}}{\\partial t_i}$ for each node $i \\in V$:\n\n-   $s_A = \\frac{\\partial}{\\partial t_A}(t_A + t_B + t_D) = 1$\n-   $s_B = \\frac{\\partial}{\\partial t_B}(t_A + t_B + t_D) = 1$\n-   $s_C = \\frac{\\partial}{\\partial t_C}(t_A + t_B + t_D) = 0$ (Node $C$ is not on the critical path)\n-   $s_D = \\frac{\\partial}{\\partial t_D}(t_A + t_B + t_D) = 1$\n-   $s_E = \\frac{\\partial}{\\partial t_E}(t_A + t_B + t_D) = 0$ (Node $E$ is not on the critical path)\n-   $s_F = \\frac{\\partial}{\\partial t_F}(t_A + t_B + t_D) = 0$ (Node $F$ is not on the critical path)\n\nThe sensitivity vector $\\mathbf{s}$, with components ordered as $(A,B,C,D,E,F)$, is therefore:\n$$\\mathbf{s} = (1, 1, 0, 1, 0, 0)$$\n\n#### Part 3: Final Answer Formulation\n\nThe final answer must be a single row matrix containing the latency (rounded to four significant figures) followed by the six components of the sensitivity vector $\\mathbf{s}$.\n\n-   Latency: $60.00$\n-   Sensitivity Vector: $(1, 1, 0, 1, 0, 0)$\n\nThe final matrix is $(60.00, 1, 1, 0, 1, 0, 0)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n60.00  1  1  0  1  0  0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "After mapping an application's dependencies, the next challenge is provisioning sufficient resources for each component to perform its task efficiently. This practice moves from logical structure to physical capacity planning, using queuing theory—a cornerstone of performance analysis. You will determine the minimum number of processor cores required for a microservice to meet its Service Level Objective (SLO) for response time, demonstrating how to make data-driven decisions about resource allocation. The problem also explores the trade-off between using general-purpose cores and specialized accelerators, a common design choice in modern WSCs .",
            "id": "3688262",
            "problem": "A Warehouse-Scale Computer (WSC) operates a microservice tier that receives external requests and dispatches them to a pool of identical Central Processing Unit (CPU) cores. To reason about capacity planning, use the following scientifically standard assumptions: request arrivals form a Poisson process with rate $\\lambda$ requests per second, individual service times on any given core are independent and exponentially distributed with mean rate $\\mu$ requests per second per core, and cores serve requests under First-Come-First-Served (FCFS) scheduling. Under these conditions, the general request lane can be modeled as an $\\mathrm{M}/\\mathrm{M}/k$ queue, where $k$ is the number of active general-purpose cores.\n\nThe WSC enforces a Service Level Objective (SLO) on the expected queuing delay $W_q$, defined as the expected time a request waits in the queue before service begins (not including service time). The SLO requires $W_q \\leq W_0$, where $W_0$ is a specified bound in seconds.\n\nBaseline configuration:\n- Arrival rate is $\\lambda = 800$ requests per second.\n- Each general-purpose core has mean service rate $\\mu = 150$ requests per second.\n- The SLO bound is $W_0 = 0.040$ seconds.\n\nSpecialized express-lane configuration:\n- A fraction $p = 0.25$ of arrivals are identified as simple requests and are routed to a separate pool of specialized accelerators (the express lane), leaving the remaining $(1-p)$ of arrivals for the general-purpose cores.\n- There are $m = 2$ identical accelerators, each with mean service rate $\\mu_s = 500$ requests per second.\n- The general-purpose pool remains as an $\\mathrm{M}/\\mathrm{M}/k$ queue serving the remaining arrivals, while the express lane forms an $\\mathrm{M}/\\mathrm{M}/m$ queue serving the offloaded arrivals.\n- The SLO requires that both lanes individually satisfy $W_q \\leq W_0$.\n\nUsing only the above assumptions and definitions, determine:\n1. The minimal integer number of general-purpose cores $k_{\\mathrm{base}}$ needed in the baseline configuration such that the expected queuing delay satisfies $W_q \\leq W_0$.\n2. The minimal integer number of general-purpose cores $k_{\\mathrm{spec}}$ needed in the specialized express-lane configuration such that both the general-purpose lane and the express lane individually satisfy $W_q \\leq W_0$.\n\nFinally, compute the reduction in general-purpose cores due to the specialized express lane, defined as $\\Delta k = k_{\\mathrm{base}} - k_{\\mathrm{spec}}$. Express your final answer as a single integer. All intermediate quantities in your reasoning must be expressed in seconds for time and requests per second for rates. No rounding instructions are necessary for the final integer.",
            "solution": "The problem statement has been validated and found to be scientifically grounded, well-posed, and objective. It presents a standard performance analysis scenario in computer systems architecture using established principles of queuing theory. All necessary parameters are provided, and the problem is free of contradictions or ambiguities.\n\nThe problem requires the analysis of two queuing systems based on the $\\mathrm{M}/\\mathrm{M}/k$ model. An $\\mathrm{M}/\\mathrm{M}/k$ queue models a system with Poisson arrivals (the first M), exponential service times (the second M), and $k$ parallel servers. The core formulas for analyzing such a system are:\n1.  The offered load, $A$, is the ratio of arrival rate $\\lambda$ to the service rate of a single server $\\mu$: $A = \\frac{\\lambda}{\\mu}$. This represents the expected number of busy servers if there were infinitely many.\n2.  The system is stable only if the total service capacity exceeds the arrival rate, i.e., $k\\mu  \\lambda$. This is equivalent to the condition that the traffic intensity, $\\rho = \\frac{\\lambda}{k\\mu} = \\frac{A}{k}$, must be less than $1$.\n3.  The probability that an arriving request must wait in the queue, $P_q$, is given by the Erlang C formula, denoted $C(k, A)$:\n    $$P_q = C(k, A) = \\frac{\\frac{A^k}{k!(1-\\rho)}}{\\sum_{n=0}^{k-1} \\frac{A^n}{n!} + \\frac{A^k}{k!(1-\\rho)}}$$\n4.  The expected queuing delay, $W_q$, can be calculated using the probability of queuing:\n    $$W_q = \\frac{P_q}{k\\mu - \\lambda}$$\n    For the system to be viable, we must find the smallest integer $k$ such that the stability condition is met and the Service Level Objective (SLO), $W_q \\leq W_0$, is satisfied.\n\n**1. Determine the minimal cores for the baseline configuration, $k_{\\mathrm{base}}$**\n\nIn the baseline configuration, we have:\n-   Arrival rate: $\\lambda = 800$ requests/second.\n-   Mean service rate per core: $\\mu = 150$ requests/second.\n-   SLO bound: $W_0 = 0.040$ seconds.\n\nFirst, we determine the minimum number of cores required for stability:\n$k \\mu  \\lambda \\implies k \\times 150  800 \\implies k  \\frac{800}{150} = \\frac{16}{3} \\approx 5.333$.\nThe smallest integer number of cores that ensures stability is $k=6$.\n\nNow, we must verify if $k=6$ satisfies the SLO, $W_q \\leq 0.040$ s. We calculate $W_q$ for $k=6$.\nThe offered load is $A = \\frac{\\lambda}{\\mu} = \\frac{800}{150} = \\frac{16}{3}$.\nThe traffic intensity is $\\rho = \\frac{A}{k} = \\frac{16/3}{6} = \\frac{16}{18} = \\frac{8}{9}$.\n\nWe compute the terms for the Erlang C formula, $C(6, 16/3)$.\nThe sum in the denominator is:\n$$S = \\sum_{n=0}^{k-1} \\frac{A^n}{n!} = \\sum_{n=0}^{5} \\frac{(16/3)^n}{n!} = 1 + \\frac{16}{3} + \\frac{(16/3)^2}{2!} + \\frac{(16/3)^3}{3!} + \\frac{(16/3)^4}{4!} + \\frac{(16/3)^5}{5!}$$\n$$S = 1 + \\frac{16}{3} + \\frac{128}{9} + \\frac{2048}{81} + \\frac{8192}{243} + \\frac{131072}{3645} = \\frac{3645 + 19440 + 51840 + 92160 + 122880 + 131072}{3645} = \\frac{421037}{3645}$$\nThe queuing term in the formula is:\n$$Q = \\frac{A^k}{k!(1-\\rho)} = \\frac{(16/3)^6}{6!(1 - 8/9)} = \\frac{16^6 / 3^6}{720(1/9)} = \\frac{16777216 / 729}{80} = \\frac{16777216}{58320} = \\frac{1048576}{3645}$$\nThe probability of queuing is:\n$$P_q = C(6, 16/3) = \\frac{Q}{S+Q} = \\frac{1048576/3645}{421037/3645 + 1048576/3645} = \\frac{1048576}{1469613}$$\nNow we calculate the expected queuing delay $W_q$:\n$$W_q = \\frac{P_q}{k\\mu - \\lambda} = \\frac{1048576 / 1469613}{6 \\times 150 - 800} = \\frac{1048576 / 1469613}{100} = \\frac{1048576}{146961300} \\approx 0.00714 \\text{ s}$$\nSince $W_q \\approx 0.00714 \\text{ s} \\leq 0.040 \\text{ s}$, the SLO is satisfied for $k=6$. As $W_q$ is a monotonically decreasing function of $k$ for stable systems, and $k=6$ is the minimum integer value for stability, it is also the minimal number of cores that meets the SLO.\nThus, $k_{\\mathrm{base}} = 6$.\n\n**2. Determine the minimal general-purpose cores for the specialized configuration, $k_{\\mathrm{spec}}$**\n\nIn this configuration, the traffic is split.\n\n**Express lane (Accelerators):**\nA fraction $p=0.25$ of arrivals are routed here.\n-   Arrival rate: $\\lambda_s = p \\lambda = 0.25 \\times 800 = 200$ requests/second.\n-   Number of servers: $m=2$.\n-   Service rate per server: $\\mu_s = 500$ requests/second.\n-   The SLO is $W_{q,s} \\leq W_0 = 0.040$ s.\n\nFirst, check stability: $m \\mu_s = 2 \\times 500 = 1000  \\lambda_s = 200$. The system is stable.\nOffered load: $A_s = \\lambda_s / \\mu_s = 200 / 500 = 0.4$.\nTraffic intensity: $\\rho_s = A_s / m = 0.4 / 2 = 0.2$.\nUsing the Erlang C formula for $m=2$:\n$$P_{q,s} = C(2, 0.4) = \\frac{\\frac{0.4^2}{2!(1-0.2)}}{ \\frac{0.4^0}{0!} + \\frac{0.4^1}{1!} + \\frac{0.4^2}{2!(1-0.2)}} = \\frac{\\frac{0.16}{1.6}}{1 + 0.4 + \\frac{0.16}{1.6}} = \\frac{0.1}{1.4+0.1} = \\frac{0.1}{1.5} = \\frac{1}{15}$$\nThe expected queuing delay is:\n$$W_{q,s} = \\frac{P_{q,s}}{m\\mu_s - \\lambda_s} = \\frac{1/15}{1000 - 200} = \\frac{1/15}{800} = \\frac{1}{12000} \\approx 0.000083 \\text{ s}$$\nSince $W_{q,s} \\ll 0.040$ s, the express lane satisfies the SLO.\n\n**General-purpose lane:**\nThe remaining fraction $(1-p) = 0.75$ of arrivals are routed here.\n-   Arrival rate: $\\lambda_g = (1-p) \\lambda = 0.75 \\times 800 = 600$ requests/second.\n-   Service rate per core: $\\mu = 150$ requests/second.\n-   The number of cores is $k_{\\mathrm{spec}}$, which we need to find.\n-   The SLO is $W_{q,g} \\leq W_0 = 0.040$ s.\n\nStability requires: $k_{\\mathrm{spec}} \\mu  \\lambda_g \\implies k_{\\mathrm{spec}} \\times 150  600 \\implies k_{\\mathrm{spec}}  4$.\nThe minimum integer number of cores for stability is $k_{\\mathrm{spec}}=5$.\n\nWe check if $k_{\\mathrm{spec}}=5$ satisfies the SLO.\nOffered load: $A_g = \\lambda_g / \\mu = 600 / 150 = 4$.\nTraffic intensity: $\\rho_g = A_g / k_{\\mathrm{spec}} = 4 / 5 = 0.8$.\n\nWe compute the terms for the Erlang C formula, $C(5, 4)$.\nThe sum in the denominator:\n$$S_g = \\sum_{n=0}^{4} \\frac{4^n}{n!} = 1 + 4 + \\frac{4^2}{2} + \\frac{4^3}{6} + \\frac{4^4}{24} = 1 + 4 + 8 + \\frac{32}{3} + \\frac{32}{3} = 13 + \\frac{64}{3} = \\frac{103}{3}$$\nThe queuing term:\n$$Q_g = \\frac{A_g^{k_{\\mathrm{spec}}}}{k_{\\mathrm{spec}}!(1-\\rho_g)} = \\frac{4^5}{5!(1-4/5)} = \\frac{1024}{120(1/5)} = \\frac{1024}{24} = \\frac{128}{3}$$\nThe probability of queuing:\n$$P_{q,g} = C(5, 4) = \\frac{Q_g}{S_g+Q_g} = \\frac{128/3}{103/3 + 128/3} = \\frac{128}{231}$$\nThe expected queuing delay is:\n$$W_{q,g} = \\frac{P_{q,g}}{k_{\\mathrm{spec}}\\mu - \\lambda_g} = \\frac{128/231}{5 \\times 150 - 600} = \\frac{128/231}{150} = \\frac{128}{34650} \\approx 0.00369 \\text{ s}$$\nSince $W_{q,g} \\approx 0.00369 \\text{ s} \\leq 0.040 \\text{ s}$, the SLO is met for $k_{\\mathrm{spec}}=5$. This is the minimal integer satisfying stability, so it is the required number of cores.\nThus, $k_{\\mathrm{spec}} = 5$.\n\n**3. Compute the reduction in general-purpose cores, $\\Delta k$**\n\nThe reduction in cores is the difference between the baseline requirement and the specialized configuration requirement.\n$$\\Delta k = k_{\\mathrm{base}} - k_{\\mathrm{spec}} = 6 - 5 = 1$$\nThe introduction of the specialized express lane allows for a reduction of $1$ general-purpose core while satisfying all SLOs.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Warehouse-scale systems are not static; they are constantly evolving with software updates and maintenance. A critical operational challenge is to perform these changes without disrupting the service or degrading performance for users. This final practice simulates a \"rolling update\" scenario, where servers are updated one by one, and tasks you with calculating the impact on a key performance metric: the cache hit ratio. By modeling the transient effects of server removal and rejoining, you will learn how to quantify the performance cost of essential operational procedures, bridging the gap between system design and real-world system management .",
            "id": "3688243",
            "problem": "A warehouse-scale computer (WSC) operates a cache-sharded, key-addressed service across $N$ homogeneous cache nodes. Keys are assigned to nodes by either Consistent Hashing (CH) or Rendezvous Hashing (RH). Assume the minimal-disruption property holds for both: when a node is removed, only keys that were mapped to that node are remapped; when a node is added, only a fraction of keys proportional to the new node’s share are remapped. The system serves a uniform, independent Poisson stream of read requests with total rate $\\Lambda$ requests per second across $K$ equally popular keys, so each key receives a Poisson process of rate $\\rho = \\Lambda/K$. All caches are fully warm at time $t=0$.\n\nThe cluster performs a rolling update in which exactly one node at a time is taken out of service and then returned after a fixed dwell time. The update proceeds at a constant rate of $u$ nodes per second, so the per-node dwell time is $\\tau = 1/u$ and the total rolling update duration is $T = N \\tau$. When a node is removed, all keys on that node are remapped to other nodes instantly; when the node returns, those keys are remapped back to it. Whenever a key is remapped onto a node whose cache does not yet contain the key, the first access to that key on that node during the subsequent interval incurs exactly one cache miss to fetch and warm the key; subsequent accesses while it remains on that node are cache hits. There is no background warming and no eviction during the interval of interest.\n\nTake the following concrete parameters: $N = 120$, $u = 0.25$ nodes per second, $K = 5 \\times 10^{6}$ keys, and $\\Lambda = 1.5 \\times 10^{6}$ requests per second.\n\nUsing the facts above, and treating both Consistent Hashing (CH) and Rendezvous Hashing (RH) under the minimal-disruption assumption, compute the expected average cache hit ratio over the entire rolling update interval $[0, T]$. Express your final answer as a decimal rounded to four significant figures.",
            "solution": "We begin from two well-tested facts:\n\n1. Minimal-disruption property for both Consistent Hashing (CH) and Rendezvous Hashing (RH): removing a node remaps exactly those keys assigned to that node; adding or returning a node remaps only the keys that the node will own thereafter.\n\n2. Superposition/splitting properties of a Poisson process: if total requests arrive as a Poisson process at rate $\\Lambda$ spread uniformly over $K$ keys, then each key experiences an independent Poisson process of rate $\\rho = \\Lambda/K$. For a Poisson process of rate $\\rho$, the probability of observing at least one request in an interval of length $\\Delta$ is $1 - \\exp(-\\rho \\Delta)$.\n\nSet the given parameters. The per-node dwell time is $\\tau = 1/u$, so\n$$\n\\tau = \\frac{1}{0.25} = 4 \\text{ s}.\n$$\nThe total rolling update duration is\n$$\nT = N \\tau = 120 \\times 4 = 480 \\text{ s}.\n$$\nThe per-key request rate is\n$$\n\\rho = \\frac{\\Lambda}{K} = \\frac{1.5 \\times 10^{6}}{5 \\times 10^{6}} = 0.3 \\text{ s}^{-1}.\n$$\n\nUnder minimal disruption, when a particular node is removed, exactly the keys that were on it are remapped. Since keys are evenly spread, each node holds a fraction $1/N$ of the keys, i.e., $K/N$ keys. For those $K/N$ keys, while the node is down for $\\tau$ seconds, each key experiences an extra miss if and only if it is requested at least once during that interval. The probability a given key is requested at least once during $\\tau$ is\n$$\np = 1 - \\exp(-\\rho \\tau) = 1 - \\exp(-0.3 \\times 4) = 1 - \\exp(-1.2).\n$$\n\nWhen the node returns after $\\tau$, those same $K/N$ keys are remapped back to it. The cache on that node does not contain those keys, so for each such key there will be one extra miss upon its first request after rejoin. For node $i$ in the sequence ($i = 1, 2, \\dots, N$), it rejoins at time $t = i \\tau$, and the remaining time until the end of the rolling update is\n$$\nT_{\\text{res}}(i) = T - i \\tau = (N - i)\\tau.\n$$\nThe probability that a given key sees at least one request in $T_{\\text{res}}(i)$ is\n$$\nq_i = 1 - \\exp\\!\\big(-\\rho \\, T_{\\text{res}}(i)\\big) = 1 - \\exp\\!\\big(-\\rho (N - i)\\tau\\big).\n$$\n\nBy linearity of expectation, the expected number of extra misses due to the removal window for node $i$ is $(K/N) p$, and due to the rejoin period is $(K/N) q_i$. Summing over all $N$ nodes, the total expected number of extra misses across the entire rolling update is\n$$\nM_{\\text{extra}} = \\sum_{i=1}^{N} \\frac{K}{N}\\, p \\;+\\; \\sum_{i=1}^{N} \\frac{K}{N}\\, q_i \\;=\\; K p \\;+\\; \\frac{K}{N} \\sum_{i=1}^{N} q_i.\n$$\nDefine $r \\equiv \\exp(-\\rho \\tau) = \\exp(-1.2)$. Then $p = 1 - r$, and we can rewrite the average of $q_i$ over $i$ using $j = N - i$:\n$$\n\\frac{1}{N} \\sum_{i=1}^{N} q_i \\;=\\; \\frac{1}{N} \\sum_{j=0}^{N-1} \\big(1 - \\exp(-\\rho j \\tau)\\big) \\;=\\; 1 - \\frac{1}{N} \\sum_{j=0}^{N-1} r^{\\,j}.\n$$\nThe sum $\\sum_{j=0}^{N-1} r^{\\,j}$ is a geometric series:\n$$\n\\sum_{j=0}^{N-1} r^{\\,j} \\;=\\; \\frac{1 - r^{N}}{1 - r}.\n$$\nTherefore,\n$$\n\\frac{1}{N} \\sum_{i=1}^{N} q_i \\;=\\; 1 - \\frac{1}{N} \\cdot \\frac{1 - r^{N}}{1 - r}.\n$$\nThus\n$$\nM_{\\text{extra}} \\;=\\; K \\left[(1 - r) \\;+\\; 1 - \\frac{1}{N} \\cdot \\frac{1 - r^{N}}{1 - r}\\right].\n$$\n\nThe total number of requests during the rolling update is\n$$\nR_{\\text{tot}} = \\Lambda T = \\Lambda N \\tau.\n$$\nAssuming the baseline hit ratio absent any remapping would be effectively $1$ over the horizon (all caches begin warm and no other misses occur), the average hit ratio over the rolling update under either CH or RH is\n$$\nH \\;=\\; 1 \\;-\\; \\frac{M_{\\text{extra}}}{R_{\\text{tot}}}\n\\;=\\; 1 \\;-\\; \\frac{K \\left[(1 - r) + 1 - \\frac{1}{N} \\cdot \\frac{1 - r^{N}}{1 - r}\\right]}{\\Lambda N \\tau}.\n$$\n\nNow substitute the numerical values. First compute $r$:\n$$\nr = \\exp(-1.2) \\approx 0.30119421191220214.\n$$\nThen\n$$\n1 - r \\approx 0.6988057880877979, \\quad r^{N} = \\exp(-1.2 \\times 120) = \\exp(-144) \\approx 5.311092249679095 \\times 10^{-63} \\approx 0 \\text{ for our precision}.\n$$\nHence\n$$\n\\frac{1}{N} \\cdot \\frac{1 - r^{N}}{1 - r} \\approx \\frac{1}{120} \\cdot \\frac{1}{0.6988057880877979} \\approx 0.011926710133396018,\n$$\nand\n$$\n(1 - r) + 1 - \\frac{1}{N} \\cdot \\frac{1 - r^{N}}{1 - r} \\;\\approx\\; 0.6988057880877979 + 1 - 0.011926710133396018 \\;\\approx\\; 1.686879077954402.\n$$\nTherefore,\n$$\nM_{\\text{extra}} \\approx K \\times 1.686879077954402 \\approx (5 \\times 10^{6}) \\times 1.686879077954402 \\approx 8.43439538977201 \\times 10^{6}.\n$$\nThe total number of requests during the rolling update is\n$$\nR_{\\text{tot}} = \\Lambda N \\tau = (1.5 \\times 10^{6}) \\times 120 \\times 4 = 7.2 \\times 10^{8}.\n$$\nFinally, the average hit ratio is\n$$\nH \\approx 1 - \\frac{8.43439538977201 \\times 10^{6}}{7.2 \\times 10^{8}} \\approx 1 - 0.011714438040795 \\approx 0.988285561959205.\n$$\n\nUnder the assumptions stated, both Consistent Hashing (CH) and Rendezvous Hashing (RH) yield the same minimal-disruption remapping pattern for a single-node rolling update, so the computed $H$ applies to both. Rounding to four significant figures yields\n$$\nH \\approx 0.9883.\n$$",
            "answer": "$$\\boxed{0.9883}$$"
        }
    ]
}