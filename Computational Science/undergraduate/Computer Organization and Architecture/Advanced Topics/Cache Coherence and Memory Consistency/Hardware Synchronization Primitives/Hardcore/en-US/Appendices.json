{
    "hands_on_practices": [
        {
            "introduction": "Mastering concurrent programming requires understanding subtle performance pitfalls that are not immediately obvious from the code. One of the most common issues in multicore systems is \"false sharing,\" where logically independent variables happen to reside on the same cache line, leading to severe performance degradation from unnecessary cache coherence traffic. This exercise  provides a practical scenario to quantify the impact of false sharing and evaluate the efficiency of a standard mitigation technique—padding data structures to align with cache line boundaries. By working through this, you will develop a concrete understanding of the trade-off between memory usage and performance.",
            "id": "3645711",
            "problem": "A symmetric multiprocessor uses the Modified, Exclusive, Shared, Invalid (MESI) cache coherence protocol. Consider an array of locks used by $T$ software threads pinned one-to-one to $T$ distinct cores. Each thread repeatedly acquires and releases a dedicated lock variable located at a unique index in a contiguous lock array. Each lock operation performs an atomic write to a single lock word. The array consists of $N$ locks, and each lock word is $s$ bytes. The cache line size is $C$ bytes. Assume $N = T$ and that the lock array is laid out contiguously in memory with no gaps unless explicitly padded. All cores run at identical steady rates and the per-thread lock operation arrival process is independent and Poisson with rate $r$ operations per second.\n\nUnder MESI, a write to a cache line by one core invalidates other cores’ copies of the same line. When distinct locks that map to the same cache line are written by different cores, the line ownership ping-pongs and causes false-sharing coherence misses. Ignore compulsory and capacity misses; only count additional coherence misses caused by false sharing between distinct locks that reside on the same cache line.\n\nYou evaluate a mitigation by padding each lock so that each lock occupies a full cache line, eliminating false sharing between locks. Padding increases total memory footprint from $N s$ bytes to $N C$ bytes.\n\nGiven the parameters $T = N = 24$, $s = 8$ bytes, $C = 64$ bytes, and $r = 5.0 \\times 10^{4}$ operations per second per thread, compute the efficiency of padding defined as the number of false-sharing coherence misses avoided per additional kibibyte of memory per second. A kibibyte is $1024$ bytes. Express the final efficiency in misses per second per kibibyte and round your answer to four significant figures.",
            "solution": "The problem statement has been evaluated and is deemed valid. It is scientifically grounded in the principles of computer architecture, specifically cache coherence protocols and performance analysis. The problem is well-posed, providing all necessary parameters and a clear, objective definition of the quantity to be calculated. There are no contradictions, ambiguities, or factual inaccuracies.\n\nThe objective is to compute the efficiency of padding, which is defined as the number of false-sharing coherence misses avoided per additional kibibyte of memory per second. We can express this efficiency, $E$, as:\n$$E = \\frac{\\text{Total false-sharing misses avoided per second}}{\\text{Additional memory footprint in kibibytes}}$$\n\nWe will calculate the numerator and the denominator separately.\n\nFirst, let us determine the number of false-sharing coherence misses that occur in the original, unpadded configuration. The mitigation strategy of padding each lock to occupy a full cache line eliminates all false sharing between locks. Therefore, the number of misses avoided is equal to the total number of false-sharing misses in the unpadded system.\n\nThe givens are:\nNumber of threads/cores, $T = 24$.\nNumber of locks, $N = 24$.\nLock word size, $s = 8$ bytes.\nCache line size, $C = 64$ bytes.\nPer-thread lock operation rate, $r = 5.0 \\times 10^{4}$ operations/second.\n\nIn the unpadded configuration, multiple locks can reside on a single cache line. The number of locks per cache line, $k$, is:\n$$k = \\left\\lfloor \\frac{C}{s} \\right\\rfloor = \\left\\lfloor \\frac{64 \\text{ bytes}}{8 \\text{ bytes}} \\right\\rfloor = 8$$\nSince the lock array is contiguous, the $N=24$ locks are arranged into groups of $k=8$ locks, with each group sharing a single cache line. The number of such groups, $N_g$, is:\n$$N_g = \\frac{N}{k} = \\frac{24}{8} = 3$$\nEach of these $3$ groups of locks is accessed by a corresponding group of $8$ distinct cores. Within each group, the $8$ cores contend for ownership of their shared cache line.\n\nLet us analyze the dynamics within one such group of $k=8$ cores. Each core in the group performs atomic writes to its dedicated lock at a rate $r$. The total rate of write operations to the single shared cache line from this group is $k \\times r$. A false-sharing coherence miss occurs when a core attempts to write to the line, but another core holds the line in an exclusive (Modified) state due to a preceding write.\n\nGiven that the per-thread lock operation arrivals are independent and Poisson, we can determine the probability that a given write operation results in a miss. A write operation by a core will be a hit only if that same core performed the immediately preceding write to that cache line. Since all $k$ cores in the group have a statistically identical write rate $r$, the probability that the next write to the line comes from any specific core is $\\frac{1}{k}$. Therefore, the probability that the next write is a hit (comes from the same core that just wrote) is $\\frac{1}{k}$. The probability that the next write is a miss (comes from one of the other $k-1$ cores) is $1 - \\frac{1}{k} = \\frac{k-1}{k}$.\n\nThe rate of false-sharing misses for a single group of $k$ cores, $M_{group}$, is the total write rate to the line multiplied by the probability of a miss:\n$$M_{group} = (k \\times r) \\times \\left(\\frac{k-1}{k}\\right) = (k-1)r$$\nFor our parameters, the miss rate per group is:\n$$M_{group} = (8-1)r = 7r$$\nSince there are $N_g=3$ such independent groups, the total rate of false-sharing misses for the entire system, $M_{total}$, is:\n$$M_{total} = N_g \\times M_{group} = 3 \\times (7r) = 21r$$\nThis value represents the number of misses avoided by the padding scheme. Substituting the value of $r$:\n$$M_{total} = 21 \\times (5.0 \\times 10^{4} \\text{ s}^{-1}) = 105 \\times 10^{4} \\text{ s}^{-1} = 1.05 \\times 10^{6} \\text{ misses/second}$$\nThis is the numerator for our efficiency calculation.\n\nNext, we calculate the denominator: the additional memory footprint in kibibytes.\nOriginal memory footprint: $M_{orig} = N \\times s = 24 \\times 8 \\text{ bytes} = 192 \\text{ bytes}$.\nPadded memory footprint: $M_{pad} = N \\times C = 24 \\times 64 \\text{ bytes} = 1536 \\text{ bytes}$.\nThe additional memory required, $\\Delta M_{bytes}$, is:\n$$\\Delta M_{bytes} = M_{pad} - M_{orig} = N(C-s) = 24 \\times (64 - 8) = 24 \\times 56 = 1344 \\text{ bytes}$$\nThe problem requires this to be expressed in kibibytes (KiB), where $1 \\text{ KiB} = 1024$ bytes.\n$$\\Delta M_{KiB} = \\frac{\\Delta M_{bytes}}{1024} = \\frac{1344}{1024} = 1.3125 \\text{ KiB}$$\nThis is the denominator for our efficiency calculation.\n\nFinally, we compute the efficiency, $E$:\n$$E = \\frac{M_{total}}{\\Delta M_{KiB}} = \\frac{1.05 \\times 10^{6} \\text{ misses/second}}{1.3125 \\text{ KiB}} = 800000 \\frac{\\text{misses}}{\\text{s} \\cdot \\text{KiB}}$$\nWriting this in scientific notation and rounding to four significant figures as requested:\n$$E = 8.000 \\times 10^{5} \\frac{\\text{misses}}{\\text{s} \\cdot \\text{KiB}}$$",
            "answer": "$$\\boxed{8.000 \\times 10^{5}}$$"
        },
        {
            "introduction": "At the heart of many synchronization strategies is an atomic instruction like Compare-And-Swap ($CAS$). While $CAS$ provides a powerful guarantee of atomicity, its real-world performance depends heavily on the level of contention from competing threads. This practice  bridges the gap between abstract probability and concrete microarchitectural performance. You will model the process of acquiring a lock using $CAS$ as a sequence of probabilistic trials and then translate this model into an expected execution time in CPU cycles, considering the different costs of success, failure, and backoff.",
            "id": "3645749",
            "problem": "A group of threads contends for ownership of a single-word lock using the hardware primitive Compare-And-Swap (CAS). Assume independent contention: each CAS attempt across all threads succeeds with constant probability $p$, independently of other attempts, and on failure the thread immediately performs another CAS after a fixed backoff. Model the sequence of CAS attempts by a series of independent Bernoulli trials and use this model to derive the expected number of CAS retries before a success as a function of $p$. Then, map this expected retry count to cycles on the following microarchitecture.\n\nMicroarchitecture model (Auriga-64):\n- Each CAS attempt has a decode/dispatch/execute overhead of $c_{i} = 12$ cycles.\n- A successful CAS incurs an additional coherence completion cost of $c_{s} = 80$ cycles.\n- A failed CAS incurs an additional coherence miss cost of $c_{f} = 40$ cycles.\n- After each failed CAS, the thread performs a fixed backoff of $b = 60$ cycles before the next attempt.\n\nAssume the thread repeats attempts until the first successful CAS. Using only the independence assumption and core definitions of Bernoulli trials and geometric waiting times, derive a symbolic expression for the expected number of retries and then for the expected total cycles required to achieve one successful CAS on Auriga-64 in terms of $p$, $c_{i}$, $c_{s}$, $c_{f}$, and $b$. Finally, evaluate this expected cycle count for $p = 0.3$ and report only the expected cycles. Round your answer to four significant figures. Express the final expected cycles in cycles.",
            "solution": "The Compare-And-Swap (CAS) operation attempts to atomically compare the value in memory to an expected value and, if equal, swap in a new value. Under independent contention, each attempt succeeds with probability $p$ and fails with probability $1-p$, independently of all other attempts.\n\nFoundational model and definitions:\n- Each attempt is a Bernoulli trial with success probability $p$.\n- Let $R$ be the random variable counting the number of failures before the first success. By definition, $R$ follows a geometric distribution over $\\{0,1,2,\\dots\\}$ with parameter $p$, since $R=k$ means $k$ consecutive failures followed by one success, yielding\n$$\n\\Pr(R = k) = (1-p)^{k} p, \\quad k \\in \\{0,1,2,\\dots\\}.\n$$\n- The number of attempts $T$ until the first success is $T = R + 1$.\n\nDerivation of the expected number of retries:\nWe compute $\\mathbb{E}[R]$ directly from the geometric distribution. Using the power series identity $\\sum_{k=0}^{\\infty} x^{k} = \\frac{1}{1-x}$ for $|x| < 1$, differentiate with respect to $x$ to obtain\n$$\n\\sum_{k=0}^{\\infty} k x^{k-1} = \\frac{1}{(1-x)^{2}} \\quad \\Rightarrow \\quad \\sum_{k=0}^{\\infty} k x^{k} = \\frac{x}{(1-x)^{2}}.\n$$\nSet $x = 1-p$ with $0 < p \\leq 1$ so that $|x|<1$, then\n$$\n\\mathbb{E}[R] = \\sum_{k=0}^{\\infty} k \\Pr(R=k) = \\sum_{k=0}^{\\infty} k (1-p)^{k} p = p \\cdot \\frac{1-p}{(1-(1-p))^{2}} = p \\cdot \\frac{1-p}{p^{2}} = \\frac{1-p}{p}.\n$$\nHence,\n$$\n\\mathbb{E}[R] = \\frac{1-p}{p}, \\quad \\text{and} \\quad \\mathbb{E}[T] = \\mathbb{E}[R] + 1 = \\frac{1}{p}.\n$$\n\nMapping to cycles:\nEach attempt incurs the base instruction overhead $c_{i}$. A single successful CAS additionally incurs $c_{s}$. Each failure additionally incurs $c_{f}$ and a backoff of $b$ cycles before the next attempt. Therefore, the total cycles $C$ to achieve one success after $R$ failures and $T=R+1$ attempts can be written as\n$$\nC = c_{i} \\cdot T + c_{s} + (c_{f} + b) \\cdot R.\n$$\nTaking expectation with respect to the geometric distribution and using linearity of expectation,\n$$\n\\mathbb{E}[C] = c_{i} \\cdot \\mathbb{E}[T] + c_{s} + (c_{f} + b) \\cdot \\mathbb{E}[R].\n$$\nSubstitute the expressions for $\\mathbb{E}[T]$ and $\\mathbb{E}[R]$:\n$$\n\\mathbb{E}[C] = c_{i} \\cdot \\frac{1}{p} + c_{s} + (c_{f} + b) \\cdot \\frac{1-p}{p}.\n$$\n\nNumerical evaluation for the Auriga-64 parameters and $p = 0.3$:\nGiven $c_{i} = 12$, $c_{s} = 80$, $c_{f} = 40$, $b = 60$, and $p = 0.3$,\n$$\n\\mathbb{E}[C] = 12 \\cdot \\frac{1}{0.3} + 80 + (40 + 60) \\cdot \\frac{1-0.3}{0.3}.\n$$\nCompute the terms:\n$$\n12 \\cdot \\frac{1}{0.3} = 12 \\cdot \\frac{10}{3} = 40,\n$$\n$$\n(40 + 60) = 100,\n$$\n$$\n\\frac{1-0.3}{0.3} = \\frac{0.7}{0.3} = \\frac{7}{3},\n$$\nso\n$$\n\\mathbb{E}[C] = 40 + 80 + 100 \\cdot \\frac{7}{3} = 120 + \\frac{700}{3} = \\frac{360 + 700}{3} = \\frac{1060}{3}.\n$$\nThus, the expected cycles are\n$$\n\\mathbb{E}[C] = \\frac{1060}{3} \\approx 353.333\\ldots\n$$\nRounded to four significant figures, this is $353.3$ cycles.",
            "answer": "$$\\boxed{353.3}$$"
        },
        {
            "introduction": "Beyond performance, the primary challenge in concurrent programming is ensuring correctness. Atomic primitives like Compare-And-Swap ($CAS$), while powerful, can introduce subtle bugs if not used carefully. This exercise  explores the infamous \"ABA problem,\" a race condition that can corrupt lock-free data structures. You will analyze the standard solution, known as tagged pointers, and determine the minimum number of tag bits required to guarantee correctness under specific system constraints, linking a logical solution to the physical reality of memory alignment on modern hardware.",
            "id": "3645713",
            "problem": "A system implements a lock-free Last-In-First-Out (LIFO) stack using an atomic compare-and-swap (CAS) on the stack head pointer. The compare-and-swap (CAS) operation atomically compares the contents of a memory location to a given expected value and, only if they are the same, atomically updates that location to a new value. To mitigate the \"ABA\" problem—where a thread observes the head pointer value as $A$, it changes to $B$, and then back to $A$ before the thread performs its CAS—the system uses tagged pointers: a version counter is embedded in the low-order bits of the head pointer and incremented on every successful head update.\n\nAssume nodes are allocated on a $64$-bit architecture with $16$-byte alignment, so every valid node address has its $4$ least significant bits equal to $0$, which can be repurposed to hold a version tag. Let the version tag be a $b$-bit counter that increments by $1$ modulo $2^{b}$ on every successful push or pop that updates the head pointer.\n\nThe runtime uses Epoch-Based Reclamation (EBR), which bounds the number of head updates that can occur between any thread’s load of the head pointer and its subsequent CAS attempt. Specifically, in the worst case, at most $R = 12$ successful head updates can occur during that window.\n\nStarting from the definitions of atomic CAS semantics, modulo arithmetic for counters, and the property of pointer alignment that fixes low-order bits at zero for valid addresses, derive the minimal number of tag bits $b$ required to ensure the tag cannot wrap within the worst-case window and thus prevent an ABA from being undetected. You must also ensure that $b$ does not exceed the number of low-order bits guaranteed zero by alignment. Provide the final answer as a single integer. No units are required.",
            "solution": "The problem requires the determination of the minimum number of bits, $b$, for a version tag to prevent the ABA problem in a lock-free stack implementation. The solution must satisfy two primary constraints: the tag must not wrap around within a specified window of operations, and the number of bits used for the tag must not exceed the number of bits available due to memory alignment.\n\nFirst, let us formalize the problem of an undetected ABA in this context. A thread reads a head pointer value, which is a composite of a memory address and a version tag. Let this initial value be $(A, T)$, where $A$ is the address and $T$ is the tag. The thread then proceeds with some work before attempting a compare-and-swap (CAS) operation. An ABA problem occurs if, during this interval, the head pointer changes to some other value $(B, T+1)$, and then subsequently changes back to a value with the original address $A$, say $(A, T')$. An undetected ABA occurs if the final state of the head pointer is identical to the one initially read, i.e., if $(A, T') = (A, T)$, which implies $T' = T$.\n\nThe version tag is a $b$-bit counter that increments by $1$ on every successful update to the head pointer. This incrementation is performed modulo $2^b$. If the initial tag is $T$, after $N$ successful updates, the new tag $T'$ will be given by the relation:\n$$T' = (T + N) \\pmod{2^b}$$\nAn undetected ABA on address $A$ is possible if the tag value returns to its original value $T$ after $N$ updates. This corresponds to the condition $T' = T$, which means:\n$$(T + N) \\pmod{2^b} = T$$\nThis equation holds if and only if $N$ is a multiple of the modulus, $2^b$. That is:\n$$N \\equiv 0 \\pmod{2^b}$$\nSince an ABA scenario implies at least one change, we are concerned with $N \\ge 1$. Thus, for an undetected ABA to occur, the number of updates $N$ must be a non-zero multiple of $2^b$.\n\nThe problem states that Epoch-Based Reclamation (EBR) guarantees that at most $R = 12$ successful head updates can occur in the window between a thread's load of the head pointer and its subsequent CAS attempt. This means the number of intervening updates, $N$, is bounded by $1 \\le N \\le R = 12$.\n\nTo guarantee that an ABA is always detected, we must ensure that the tag cannot wrap back to its original value within this window. This requires that the condition $N \\equiv 0 \\pmod{2^b}$ is never met for any possible value of $N$ in the range $[1, R]$. To ensure this, the smallest non-zero multiple of $2^b$, which is $2^b$ itself, must be larger than the maximum possible value of $N$. The maximum value for $N$ is $R$. Therefore, we must satisfy the inequality:\n$$2^b > R$$\nSubstituting the given value $R=12$:\n$$2^b > 12$$\nWe must find the smallest integer $b$ that satisfies this inequality. We can test values of $b$:\nFor $b=1$, $2^1 = 2$, which is not greater than $12$.\nFor $b=2$, $2^2 = 4$, which is not greater than $12$.\nFor $b=3$, $2^3 = 8$, which is not greater than $12$.\nFor $b=4$, $2^4 = 16$, which is greater than $12$.\nThus, the minimum number of bits required to prevent tag wrap-around is $b = 4$.\n\nNext, we must verify this result against the physical constraint imposed by pointer alignment. The system uses a $64$-bit architecture, and nodes are allocated with $16$-byte alignment. An address is $16$-byte aligned if it is a multiple of $16$. In binary representation, the number $16$ is $10000_2$. Any memory address that is a multiple of $16$ must therefore have its $4$ least significant bits equal to $0$. These $4$ bits are thus available to be repurposed for storing the version tag without conflicting with the address information.\nThe number of available bits is $4$. Our derived minimal requirement is $b=4$. Since $b=4$ does not exceed the number of available bits ($4 \\le 4$), this solution is physically realizable.\n\nTherefore, the minimal number of tag bits $b$ that both prevents an undetected ABA within the worst-case window and fits within the available low-order bits of the pointer is $4$.",
            "answer": "$$\\boxed{4}$$"
        }
    ]
}