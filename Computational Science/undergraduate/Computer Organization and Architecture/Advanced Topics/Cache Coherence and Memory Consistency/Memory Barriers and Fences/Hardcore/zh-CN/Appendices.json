{
    "hands_on_practices": [
        {
            "introduction": "在并发编程中，确保一个线程能按正确的顺序看到另一个线程的工作结果是一项根本性挑战。为了提升性能，现代处理器可能会重排内存操作，但这可能导致难以察觉的错误。本练习  提出了一个经典的消息传递场景，旨在帮助你理解如何使用释放 (release) 和获取 (acquire) 内存屏障来强制建立“先于发生” (happens-before) 关系，从而保证数据在被消费前已安全发布。",
            "id": "3656212",
            "problem": "考虑在不同中央处理器（CPU）上运行的两个线程之间的以下消息传递模式：\n\n- 共享状态：一个字节数组 $B[0 \\ldots N-1]$ 和一个标志 $R$；初始时，$B$ 的内容未指定，且 $R = 0$。\n- 写入线程 $T_w$ 按程序顺序执行：对于每个索引 $i$（其中 $0 \\le i \\le N-1$），将 $0$ 写入 $B[i]$，然后将 $1$ 写入 $R$。\n- 读取线程 $T_r$ 执行：自旋直到读取到 $R = 1$，然后立即读取所有元素 $B[0 \\ldots N-1]$ 并依赖于每次读取的值都等于 $0$。\n\n假设在一个弱序多处理器上，该处理器具有按位置的缓存一致性，但没有对独立位置的隐式全局排序，且以下情况为真：\n\n- 除非受到同步的约束，否则线程内的程序顺序并不意味着对其他线程在不同位置上的可见性顺序。\n- 释放屏障（release fence）禁止将之前的内存访问重排到屏障之后；获取屏障（acquire fence）禁止将之后的内存访问重排到屏障之前。\n- 除非被排序阻止，否则对一个位置的写入可能会在对其他位置的更早写入之前对其他 CPU 可见。\n- 正确性标准是：一旦 $T_r$ 观察到 $R = 1$，对于所有 $i$（其中 $0 \\le i \\le N-1$），$T_w$ 设置 $B[i] = 0$ 的所有写入必须对 $T_r$ 可见。\n\n你的任务是确保读取者在 $B$ 的任何元素仍持有清零前的值时，永远不会观察到 $R = 1$。请选择屏障的最小化放置和强度，以便在各种弱序但具有缓存一致性的架构上，建立必要的排序来保证正确性标准。“最小化”意味着在这些架构上，足以强制写入者对 $B$ 的清零操作先行发生于（happens-before）读取者看到 $R = 1$ 后对 $B$ 进行后续读取所需的最小总排序强度和数量。\n\n哪个选项正确指定了最小化的屏障？\n\nA. 在 $T_w$ 中：在对 $B$ 清零和写入 $R \\leftarrow 1$ 之间放置一个释放屏障。在 $T_r$ 中：在读取到 $R = 1$ 之后、读取任何 $B$ 的元素之前，立即放置一个获取屏障。\n\nB. 在 $T_w$ 中：在对 $B$ 清零和写入 $R \\leftarrow 1$ 之间放置一个释放屏障。在 $T_r$ 中：不需要屏障；在观察到 $R = 1$ 后立即读取 $B$。\n\nC. 在 $T_w$ 中：不需要屏障；在对 $B$ 清零后写入 $R \\leftarrow 1$。在 $T_r$ 中：在读取到 $R = 1$ 之后、读取任何 $B$ 的元素之前，立即放置一个获取屏障。\n\nD. 在 $T_w$ 和 $T_r$ 的关键操作前后都放置一个完全顺序一致性屏障（兼具获取和释放效应），即每个线程围绕清零和标志操作放置 $2$ 个完全屏障。\n\nE. 仅在 $T_r$ 中通过从读取的 $R$ 计算单个索引 $j$ 然后首先读取 $B[j]$ 来引入数据依赖关系；任何地方都不需要屏障，对 $B$ 的其余读取按普通程序顺序进行。",
            "solution": "**基于原理的推导：**\n1.  **识别风险：** 核心问题是内存重排序。在弱序系统上，$T_w$ 对标志 $R$ 的写入（即 $R = 1$）可能会在对数组 $B$ 进行清零的写入对其他 CPU 可见*之前*就变得可见。这是因为写入操作针对的是不同的内存位置（$R$ vs. $B[i]$）。\n2.  **风险如何表现：** $T_r$ 可能会看到 $R = 1$，退出其自旋循环，并立即开始读取 $B$ 数组。如果对 $B$ 的写入尚未对 $T_r$ 的 CPU 可见，$T_r$ 将会从 $B$ 中读取旧的、未指定的值，从而违反正确性标准。\n3.  **制定所需的排序：** 我们需要建立一个“先行发生”（happens-before）关系。具体来说，$T_w$ 对数组 $B$ 的所有写入必须先行发生于 $T_w$ 对 $R$ 的写入。而 $T_r$ 对 $R$ 的读取（看到值 $1$）必须先行发生于 $T_r$ 对数组 $B$ 的所有读取。对 $R$ 的同步必须将这两个事件链连接起来。\n4.  **应用同步原语（屏障）：**\n    *   **写入方（$T_w$）：** 我们需要防止写入 $R = 1$ 的操作被重排序到写入 $B$ 的操作*之前*。换句话说，屏障*之前*的所有内存操作（对 $B$ 的写入）必须在屏障*之后*的任何内存操作（对 $R$ 的写入）之前完成并变得可见。**释放屏障**的定义是禁止将*之前的*内存访问重排到屏障*之后*。这正是所需要的。因此，$T_w$ 中的序列必须是：\n        1.  将 $B$ 清零。\n        2.  `release_fence()`\n        3.  写入 $R = 1$。\n        释放屏障确保当 $R = 1$ 对任何其他CPU可见时，所有先前对 $B$ 的写入也都是可见的。\n    *   **读取方（$T_r$）：** 我们需要防止读取 $B$ 的操作被重排序到读取 $R$（并看到值 $1$）的操作*之前*。换句话说，屏障*之后*的所有内存操作（对 $B$ 的读取）不能在屏障*之前*的内存操作（对 $R$ 的读取）之前执行。**获取屏障**的定义是禁止将*之后的*内存访问重排到屏障*之前*。这正是所需要的。因此，$T_r$ 中的序列必须是：\n        1.  自旋读取 $R$ 直到其为 $1$。\n        2.  `acquire_fence()`\n        3.  读取 $B$ 数组。\n        获取屏障确保对 $B$ 的读取只会在观察到 $R$ 为 $1$ 的读取完成后才会发生。\n5.  **释放-获取配对：** $T_w$ 中的释放屏障与 $T_r$ 中的获取屏障配对。释放操作“发布”数据（$B$ 数组）以及标志 $R$。获取操作“订阅”这次发布。当 $T_r$ 读取到 $R = 1$（一个在释放屏障后写入的值），然后执行一个获取屏障时，它被保证能看到 $T_w$ 中所有在释放屏障*之前*发生的内存写入。这就建立了写入者对 $B$ 的清零操作和读取者对 $B$ 的读取操作之间必要的“先行发生”关系。\n6.  **最小性：** 这种释放-获取对是用于此单向数据传输模式的标准、最小机制。\n    *   仅使用释放屏障（选项B）是不够的，因为读取者的CPU可以投机性地将其对 $B$ 的读取重排到对 $R$ 的读取确认值为 $1$ *之前*。\n    *   仅使用获取屏障（选项C）是不够的，因为写入者的CPU可以重排对 $R$ 的写入，使其在对 $B$ 的写入*之前*可见。\n    *   使用完全屏障（选项D）是过度的。一个完全屏障（获取+释放）比必要的更强。例如，$T_w$ 不需要获取效应，$T_r$ 也不需要释放效应。这违反了“最小化”的要求。\n    *   使用数据依赖（选项E）有时可以在某些架构上创建排序保证（例如，$B[j]$ 其中 $j$ 依赖于 $R$），但它不是一个通用的解决方案。首先，它只对 $B[j]$ 的读取进行排序，而对 $B$ 的其他元素没有排序。其次，并非所有架构都保证数据依赖性意味着对其他独立位置的内存排序。这是一种微妙且特定于架构的技巧，不是问题陈述所要求的通用和鲁棒的解决方案（“在各种弱序但具有缓存一致性的架构上”）。标准的屏障模型不作此假设。因此，显式屏障是正确、可移植的解决方案。\n\n**逐项分析选项**\n\n*   **A. 在 $T_w$ 中：在对 $B$ 清零和写入 $R \\leftarrow 1$ 之间放置一个释放屏障。在 $T_r$ 中：在读取到 $R = 1$ 之后、读取任何 $B$ 的元素之前，立即放置一个获取屏障。**\n    *   这与推导出的解决方案完全一致。$T_w$ 中的释放屏障防止了先前的写入（$B[i] = 0$）被重排到后续的写入（$R = 1$）之后。$T_r$ 中的获取屏障防止了后续的读取（$B[i]$）被重排到先前的读取（$R == 1$）之前。这种配对建立了必要的先行发生关系。这是该问题的经典解决方案。它是最小化的，因为两个屏障都是必需的，并且没有使用更强的屏障。\n    *   结论：**正确**。\n\n*   **B. 在 $T_w$ 中：在对 $B$ 清零和写入 $R \\leftarrow 1$ 之间放置一个释放屏障。在 $T_r$ 中：不需要屏障；在观察到 $R = 1$ 后立即读取 $B$。**\n    *   这是不够的。$T_w$ 中的释放屏障正确地对写入者的操作进行了排序。然而，在 $T_r$ 中没有获取屏障的情况下，读取者的处理器可以自由地将对 $B$ 的读取重排到对 $R$ 的读取确认值为 $1$ *之前*发生。这可能是由于推测执行。CPU可能会猜测循环将终止，预取并读取 $B$ 的值，之后才发现 $R$ 变成了 $1$。如果 $T_w$ 对 $B$ 的写入还不可见，$T_r$ 将读取到陈旧数据。\n    *   结论：**不正确**。\n\n*   **C. 在 $T_w$ 中：不需要屏障；在对 $B$ 清零后写入 $R \\leftarrow 1$。在 $T_r$ 中：在读取到 $R = 1$ 之后、读取任何 $B$ 的元素之前，立即放置一个获取屏障。**\n    *   这同样是不够的。$T_r$ 中的获取屏障正确地对读取者的操作进行了排序。然而，在 $T_w$ 中没有释放屏障的情况下，写入者的处理器或内存系统可以自由地使写入 $R = 1$ 的操作在使写入 $B[i] = 0$ 的操作可见*之前*对其他CPU可见。在这种情况下，$T_r$ 可能正确地执行其部分（读取 $R=1$，然后屏障，然后读取 $B$），但它仍然会从 $B$ 中读取陈旧数据，因为那些写入尚未被 $T_w$ 发布。\n    *   结论：**不正确**。\n\n*   **D. 在 $T_w$ 和 $T_r$ 的关键操作前后都放置一个完全顺序一致性屏障（兼具获取和释放效应），即每个线程围绕清零和标志操作放置 $2$ 个完全屏障。**\n    *   这种方法可行。完全屏障是一种非常强的屏障，可以阻止所有跨越它的重排序。按所述方式放置它们肯定会强制执行所需的排序。然而，问题要求**最小化**的放置和强度。这个解决方案不是最小化的。例如，在 $T_w$ 中，我们只需要防止先前的写入移动到屏障*之后*（释放语义）。我们不需要防止后续操作移动到屏障*之前*（获取语义）。对于 $T_r$ 也是如此，我们只需要获取语义，而不需要释放语义。使用四个完全屏障是严重的过度设计。\n    *   结论：**不正确**。\n\n*   **E. 仅在 $T_r$ 中通过从读取的 $R$ 计算单个索引 $j$ 然后首先读取 $B[j]$ 来引入数据依赖关系；任何地方都不需要屏障，对 $B$ 的其余读取按普通程序顺序进行。**\n    *   这依赖于“地址依赖排序”规则，该规则存在于某些（但非全部）弱序架构上。该规则指出，如果 `读 A -> 数据依赖 -> 读地址 B`，那么对 `A` 的读取被排序在对 `B` 的读取之前。然而，这个问题指定了“在各种弱序但具有缓存一致性的架构上”。这种依赖排序并非普遍保证。关键是，即使它确实对 $B[j]$ 的读取进行了排序，它也*不保证*对任何其他 $B[i]$（其中 $i \\ne j$）的读取进行排序。问题要求*所有* $B[i]$ 都被正确读取。因此，这不是一个通用或完整的解决方案。例如，标准的 C++ 和 Java 内存模型明确指出，数据依赖不足以同步其他非依赖的内存访问。\n    *   结论：**不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "释放-获取协议在线程之间构成了一种契约：写入方承诺在发出信号前会发布其数据，而读取方则承诺在读取数据前会先获取该信号。如果这一契约被打破会发生什么？本实践问题  探讨了一个常见的陷阱，即读取方使用了“松散” (relaxed) 内存顺序，未能与写入方的“释放” (release) 操作同步。通过分析这个数据竞争，你将更深刻地体会到为什么匹配的内存顺序对于程序正确性至关重要。",
            "id": "3656251",
            "problem": "考虑在弱序指令集架构 (ISA) 上运行的两个线程，一个写入线程和一个读取线程。有两个共享变量：一个初始化为 $0$ 的普通整数 $data$，以及一个初始化为 $0$ 的原子标志 $ready$。写入线程按程序顺序执行：首先 $data \\leftarrow 42$，然后对 $ready$ 进行具有释放语义的原子存储，设置 $ready \\leftarrow 1$。读取线程使用松散加载在 $ready$ 上自旋，直到观察到 $ready = 1$，然后将 $data$ 读入本地寄存器 $r$。具体来说：\n- 写入线程: $data \\leftarrow 42$; `atomic_store_release`($ready, 1$).\n- 读取线程: while (`atomic_load_relaxed`($ready$) $==$ $0$) { } ; $r \\leftarrow data$.\n\n假设缓存一致性为每个位置提供单一全局顺序，但其本身并不对不同位置的操作进行排序，并且语言和硬件允许在所选原子语义的约束下进行编译器和硬件重排。在这些假设下，根据程序顺序、缓存一致性、释放/获取同步以及先行发生 (happens-before) 的核心定义进行推理，并回答以下问题：\n\n哪个选项最能描述在读取线程看到 $ready = 1$ 后，$r$ 是否可能被观察为 $0$，并指出了一个依赖适当内存屏障或栅栏的正确的最小修复方案？\n\nA. 不会。由于缓存一致性，观察到 $ready = 1$ 保证了 $data$ 是最新的；不需要栅栏。\n\nB. 会。写入线程带有释放语义的存储仅相对于读取线程匹配的获取加载来对其之前的写入进行排序；松散加载不会同步，因此在弱内存模型上 $r$ 可能为 $0$。一个最小修复方案是使自旋加载成为获取加载，或者在读取 $ready$ 和读取 $data$ 之间插入一个获取栅栏。\n\nC. 会。但修复方案是将 $data$ 声明为原子变量并以松散语义读取它；不需要对 $ready$ 进行排序。\n\nD. 不会。对 $ready$ 的释放存储会禁止任何后续的读取线程对其后续加载进行重排，因此当前写法是安全的。\n\nE. 会。但最小修复方案是让写入线程对 $ready$ 使用顺序一致性存储；读取线程无需更改。",
            "solution": "### 解决方案推导\n\n这个问题的核心在于“先行发生”(happens-before)关系，它定义了不同线程中操作之间的形式化内存排序保证。\n\n1.  **程序顺序与释放语义（写入线程）**：写入线程按程序顺序执行其操作。\n    - $W_1$: $data \\leftarrow 42$\n    - $W_2$: `atomic_store_release`($ready, 1$)\n    操作 $W_2$ 的 `release` 语义保证了同一线程中所有之前的内存写入（在此例中为 $W_1$）对与此操作同步的其他线程可见。一个 `release` 操作充当一个屏障，防止 $W_1$ 被重排到 $W_2$ 之后。因此，从写入线程的角度来看，内存系统被指示将 $data$ 的新值提供给其他核心的时间不晚于 $ready$ 的新值。\n\n2.  **松散语义与重排（读取线程）**：读取线程执行：\n    - $R_1$: 一个 `atomic_load_relaxed`($ready$) 的循环，直到读到 $1$。\n    - $R_2$: $r \\leftarrow data$\n    $ready$ 的加载使用 `relaxed` 内存顺序。`relaxed` 原子操作只保证原子性（加载不会看到“撕裂”值），但它们不提供任何同步或排序保证。具体来说，一个 `relaxed` 加载不会与一个 `release` 存储“同步于”(synchronizes-with)。\n\n3.  **同步失败**：为了保证对 $data$ 的写入在读取 $data$ 之前可见，必须在 $W_1$ 和 $R_2$ 之间建立“先行发生”(happens-before)关系。在释放-获取模型中，如果 `release` 存储（$W_2$）与一个 `acquire` 加载“同步于”(synchronizes-with)，则可以实现这一点。由于读取线程执行的是 `relaxed` 加载（$R_1$），因此没有发生这种同步。\n\n4.  **在弱序 ISA 上的后果**：没有同步点，系统可以自由地重排操作。\n    - 对 $data$ 的写入和对 $ready$ 的写入位于两个不同的内存位置。缓存一致性保证了对 $ready$ 的所有写入有一个全局顺序，对 $data$ 的所有写入有另一个独立的全局顺序，但它不保证 $data$ 相对于 $ready$ 的可见性顺序。\n    - 写入线程对 $ready$ 的存储有可能在对 $data$ 的存储变得可见之前，就对读取线程的核心可见。读取线程的核心可能看到 $ready = 1$ 并退出循环，但其后续对 $data$ 的读取可能由其本地缓存提供服务，而该缓存仍持有旧值 $0$。\n    - 或者，读取线程的处理器本身也可能重排操作，在循环 ($R_1$) 明确终止之前，推测性地执行对 $data$ 的加载 ($R_2$)。在没有适当的内存栅栏/屏障的情况下，只要满足数据依赖性，弱序处理器就被允许进行此类重排。\n\n因此，读取线程完全有可能观察到 $ready = 1$ 之后，从 $data$ 读取到初始值 $0$ 到 $r$ 中。该代码存在数据竞争。\n\n5.  **最小修复方案**：为了修正这个数据竞争，必须在写入线程对 $ready$ 的存储与读取线程后续对 $data$ 的加载之间建立“同步于”(synchronizes-with)关系。写入线程的 `release` 存储必须与读取线程的 `acquire` 操作配对。有两种标准方法可以实现这一点：\n    a.  修改读取线程对标志的加载：将 `atomic_load_relaxed`($ready$) 更改为 `atomic_load_acquire`($ready$)。这是最直接的修复。`acquire` 加载与 `release` 存储同步，从而建立先行发生关系。`acquire` 语义充当一个屏障，确保写入线程先前对 $data$ 的写入在读取线程中任何后续内存操作（如读取 $data$）执行之前是可见的。\n    b.  插入一个 `acquire` 栅栏：在循环中保留 `relaxed` 加载，但在循环之后、读取 $data$ 之前插入一个 `acquire` 栅栏。\n        `while (atomic_load_relaxed(ready) == 0) { }`\n        `atomic_thread_fence(memory_order_acquire);`\n        `$r \\leftarrow data$;`\n        `acquire` 栅栏与之前的 `release` 存储同步，提供与 `acquire` 加载相同的保证。\n\n两种修复方案都被认为是最小的。\n\n### 逐项选项分析\n\n**A. 不会。由于缓存一致性，观察到 $ready = 1$ 保证了 $data$ 是最新的；不需要栅栏。**\n- **分析**：这个陈述从根本上是错误的。正如问题的假设和上面的推导所述，缓存一致性为单个内存位置提供一致性，但并不强制不同位置（$data$ 和 $ready$）之间的排序。这混淆了“缓存一致性”(coherence)和“内存连贯性”(consistency)之间的区别。\n- **结论**：错误。\n\n**B. 会。写入线程带有释放语义的存储仅相对于读取线程匹配的获取加载来对其之前的写入进行排序；松散加载不会同步，因此在弱内存模型上 $r$ 可能为 $0$。一个最小修复方案是使自旋加载成为获取加载，或者在读取 $ready$ 和读取 $data$ 之间插入一个获取栅栏。**\n- **分析**：这个陈述正确地指出 $r$ 可能为 $0$。它准确地解释了原因：一个 `release` 存储需要一个匹配的 `acquire` 操作来同步，而 `relaxed` 加载不提供此功能。然后它正确地指出了两个标准的最小修复方案：将加载更改为 `acquire` 或插入一个 `acquire` 栅栏。此分析与现代内存模型的原理完全一致。\n- **结论**：正确。\n\n**C. 会。但修复方案是将 $data$ 声明为原子变量并以松散语义读取它；不需要对 $ready$ 进行排序。**\n- **分析**：这是错误的。仅仅将 $data$ 设为原子变量并对其使用 `relaxed` 加载并不能解决排序问题。核心问题是线程之间缺乏同步，而这正是 $ready$ 标志的目的。如果没有对 $ready$ 的排序，相对于对 $ready$ 的读取，$data$ 的读取仍然可能被重排或读到旧值。这个提议的修复方案未能建立必要的先行发生关系。\n- **结论**：错误。\n\n**D. 不会。对 $ready$ 的释放存储会禁止任何后续的读取线程对其后续加载进行重排，因此当前写法是安全的。**\n- **分析**：这个陈述是错误的。一个线程的 `release` 存储不会对一个没有执行相应 `acquire` 操作的无关读取线程施加排序约束。排序保证是有条件的，取决于读取线程是否参与了同步协议。\n- **结论**：错误。\n\n**E. 会。但最小修复方案是让写入线程对 $ready$ 使用顺序一致性存储；读取线程无需更改。**\n- **分析**：在写入线程上使用顺序一致性存储（`atomic_store_seq_cst`）确实可以修复数据竞争，因为一个 `seq_cst` 操作会与另一个线程中读取该写入值的任何原子操作同步。然而，问题要求的是一个*最小*修复方案。释放-获取排序是专门为这种单向同步设计的，并且比顺序一致性限制更少（因此可能性能更高）。将写入线程从 `release` 升级到 `seq_cst` 是一个比必要更强的更改。最小的修复是在读取线程端用一个匹配的 `acquire` 来完成现有的 `release` 操作，如选项 B 所述。\n- **结论**：错误。",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "内存屏障对保证正确性至关重要，但它们并非没有代价。要理解其性能影响，我们必须审视底层的硬件，特别是存储缓冲区 (store buffer)。本问题  提供了一个简化但富有洞察力的模型，用以说明一个完全内存屏障 (full memory fence) 如何与存储缓冲区交互。通过计算其导致的停顿周期，你将能够量化强内存顺序与处理器性能之间的权衡。",
            "id": "3656213",
            "problem": "一个处理器核心实现了一个容量为 $k$ 个条目的存储缓冲区，用以在相干内存系统中将存储指令的发射与达到全局可见性解耦。一个完整的内存屏障要求，在屏障之后任何指令可以继续执行之前，所有在屏障之前发射的存储指令都必须变为全局可见。在此模型中，当一个存储操作已提交到末级缓存或主存，并且其相干性更新已得到确认时，该存储即达到全局可见性，这个过程从存储开始提交的时刻算起，需要 $L$ 个周期。假设以下经过充分检验的事实和定义：\n\n- 存储缓冲区是一个先进先出（FIFO）的待处理存储队列，容量为 $k$。\n- 一个完整的内存屏障必须阻塞核心，直到存储缓冲区中所有在屏障之前发射的存储指令都清空，从而确保屏障之后的任何内存操作都不会被感知为发生在屏障之前的任何存储操作之前。\n- 内存系统按程序顺序从缓冲区提交存储，且无重叠，即任一时刻最多只有一个存储可以处于提交阶段，每个存储的提交需要 $L$ 个周期才能达到全局可见性。这模拟了强排序约束下严格串行化的写提交路径。\n\n假设在屏障执行前一刻，存储缓冲区已满，包含 $k$ 个存储，且所有这些存储都在屏障之前发射。请根据排序和延迟的基本原理，推导由于该屏障导致核心经历的最大停顿周期数，作为 $k$ 和 $L$ 的函数。请用一个封闭形式的解析表达式（以周期为单位）表示你的最终答案。无需四舍五入。",
            "solution": "### 停顿周期的推导\n\n令 $T=0$ 表示完整内存屏障指令开始执行的时刻。在这一点上，处理器核心停顿。停顿将持续到存储缓冲区中的所有 $k$ 个存储都达到全局可见性为止。\n\n存储缓冲区是一个包含 $k$ 个存储的FIFO队列。让我们按程序顺序将这些存储表示为 $S_1, S_2, \\dots, S_k$。$S_1$ 是最旧的存储（在队头），而 $S_k$ 是最新的存储（在队尾）。\n\n问题陈述指出，内存系统按程序顺序从缓冲区提交这些存储。这意味着 $S_1$ 将首先被提交，然后是 $S_2$，以此类推，直到 $S_k$。\n\n关键的约束是写提交路径是“严格串行化”且“无重叠”的。这意味着一个存储的提交过程必须完全完成后，下一个存储的提交过程才能开始。问题定义了一个存储的提交过程，从其启动到达到全局可见性，需要 $L$ 个周期。这暗示了对于每个存储，串行化的提交资源将被占用 $L$ 个周期的时长。\n\n我们现在可以构建每个存储的提交和全局可见性的时间线，从 $T=0$ 时的停顿开始。\n\n1.  **存储 $S_1$**：在 $T=0$ 时，内存系统开始提交第一个存储 $S_1$。\n    - 提交过程开始于 $T_{\\text{start},1} = 0$。\n    - 这个过程需要 $L$ 个周期。\n    - $S_1$ 在时间 $T_{\\text{visible},1} = T_{\\text{start},1} + L = 0 + L = L$ 变为全局可见。\n\n2.  **存储 $S_2$**：由于严格串行化和无重叠规则，对 $S_2$ 的提交直到对 $S_1$ 的提交过程结束才能开始。资源在 $T=L$ 时变为空闲。\n    - 对 $S_2$ 的提交过程开始于 $T_{\\text{start},2} = L$。\n    - 这个过程同样需要 $L$ 个周期。\n    - $S_2$ 在时间 $T_{\\text{visible},2} = T_{\\text{start},2} + L = L + L = 2L$ 变为全局可见。\n\n3.  **存储 $S_3$**：对 $S_3$ 的提交在 $S_2$ 的过程完成后开始。\n    - 对 $S_3$ 的提交过程开始于 $T_{\\text{start},3} = 2L$。\n    - 它在时间 $T_{\\text{visible},3} = T_{\\text{start},3} + L = 2L + L = 3L$ 变为全局可见。\n\n通过归纳法，我们可以为第 $i$ 个存储 $S_i$（其中 $i$ 是从 $1$ 到 $k$ 的整数）建立一个通用公式。\n\n-   **存储 $S_i$**：存储 $S_i$ 的提交过程在前面的 $(i-1)$ 个存储完成其提交过程后开始。其中每一个都需要 $L$ 个周期。\n    - $S_i$ 的提交过程开始于时间 $T_{\\text{start},i} = (i-1)L$。\n    - 它在 $L$ 个周期后变为全局可见，时间点为 $T_{\\text{visible},i} = T_{\\text{start},i} + L = (i-1)L + L = iL$。\n\n屏障指令会使核心停顿，直到在 $T=0$ 时缓冲区中的所有存储都变为全局可见。这个条件只有当最后一个存储 $S_k$ 变为全局可见时才被满足。\n\n$S_k$ 变为全局可见的时间点可以通过在我们的通用公式中设置 $i=k$ 来找到：\n$$\nT_{\\text{visible},k} = kL\n$$\n\n由于停顿从 $T=0$ 开始，到 $T=kL$ 结束，所以总的停顿持续时间为 $kL$ 个周期。在指定的模型下，这是最大（也是唯一）的停顿周期数。\n\n因此，由于屏障导致核心经历的最大停顿周期数是缓冲区中的存储数量 $k$ 与每个存储达到全局可见性的延迟 $L$ 的乘积。",
            "answer": "$$\n\\boxed{kL}\n$$"
        }
    ]
}