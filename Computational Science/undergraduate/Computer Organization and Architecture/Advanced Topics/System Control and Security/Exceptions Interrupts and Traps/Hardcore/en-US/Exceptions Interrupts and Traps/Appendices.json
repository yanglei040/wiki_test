{
    "hands_on_practices": [
        {
            "introduction": "The precise behavior of exception handling is not just an academic detail; it is the bedrock of system stability and correctness. This first practice presents a classic debugging scenario where a trap handler, designed with incorrect assumptions, causes a program to skip a critical instruction after a fault. By tracing the value of the Exception Program Counter ($EPC$) from the moment of the trap to the return, you will diagnose the logical error, reinforcing the fundamental semantics of how synchronous traps are managed .",
            "id": "3640478",
            "problem": "A 32-bit Reduced Instruction Set Computer (RISC) processor uses fixed-length $4$-byte instructions and precise exceptions. By definition of precise exceptions, when a synchronous trap occurs at program counter, the hardware records the Program Counter (PC) of the instruction that caused the exception into the Exception Program Counter (EPC), sets $PC$ to the trap vector, and flushes the pipeline so no later instruction has committed. The return-from-exception instruction (denoted here as $ERET$) restores control by setting $PC \\leftarrow EPC$.\n\nConsider the following experiment: a user program triggers a synchronous trap at address $0x00001000$ on a load instruction. The trap handler prologue saves general-purpose registers to the stack and, for debugging purposes inherited from an earlier interrupt-only design, includes a line that adjusts $EPC$ by one instruction before any fix-ups:\n\n- The handler sets Stack Pointer (SP) to make room for a frame: $SP \\leftarrow SP - 20$.\n- It stores several registers at offsets $0$, $4$, and $8$ from $SP$.\n- It stores $EPC$ at offset $12$ from $SP$.\n- It stores the handler’s return address register at offset $16$ from $SP$.\n- It then executes an unconditional adjustment $EPC \\leftarrow EPC + 4$ (intended to “skip” the faulting instruction).\n- After fixing the fault (for example, mapping the missing page), the handler executes $ERET$, which by definition sets $PC \\leftarrow EPC$.\n\nEmpirically, after $ERET$, the observed $PC$ is $0x00001004$ and the user’s faulting load at $0x00001000$ does not re-execute. Using only the fundamental semantics stated above for $EPC$, $PC$, and $ERET$, and the described handler prologue, which explanation best accounts for returning to the wrong $PC$?\n\nA. The handler misinterprets the $EPC$ semantics and erroneously increments $EPC$ by one instruction ($+4$ bytes) in the prologue. Because $EPC$ already contains the address of the faulting instruction, this off-by-one adjustment forces $ERET$ to resume at $0x00001004$ instead of $0x00001000$.\n\nB. The hardware records $EPC$ as the next sequential $PC$ ($PC + 4$) for synchronous traps, so resuming at $0x00001004$ is the expected behavior and there is no bug.\n\nC. The prologue’s stack layout is off by one slot, so on restore the handler loads $EPC$ from the return-address slot and $ERET$ jumps to $0x00001004$; the off-by-one arises from misaligned stack offsets rather than $EPC$ semantics.\n\nD. The branch delay slot semantics cause $EPC$ to point to the delay slot, and the unconditional $ERET$ resumes at $PC + 4$; the off-by-one is due to delayed branching even though the faulting instruction is a load.",
            "solution": "The problem statement is critically validated before proceeding to a solution.\n\n### Step 1: Extract Givens\n- **Processor**: $32$-bit Reduced Instruction Set Computer (RISC).\n- **Instruction Size**: Fixed-length $4$-byte instructions.\n- **Exception Model**: Precise exceptions.\n- **Synchronous Trap Definition**:\n    - Occurs at a specific program counter ($PC$).\n    - Hardware action: The $PC$ of the instruction that caused the exception is recorded into the Exception Program Counter ($EPC$).\n    - Hardware action: $PC$ is set to the trap vector.\n    - Hardware action: The pipeline is flushed.\n- **Return from Exception Instruction ($ERET$) Definition**:\n    - Restores control by setting $PC \\leftarrow EPC$.\n- **Experimental Scenario**:\n    - A user program triggers a synchronous trap.\n    - Trap location ($PC$): $0x00001000$.\n    - Faulting instruction type: A load instruction.\n- **Trap Handler Prologue Actions**:\n    1.  $SP \\leftarrow SP - 20$.\n    2.  Store general-purpose registers at offsets $0$, $4$, and $8$ from $SP$.\n    3.  Store $EPC$ at offset $12$ from $SP$.\n    4.  Store the handler’s return address register at offset $16$ from $SP$.\n    5.  Execute an unconditional adjustment: $EPC \\leftarrow EPC + 4$.\n- **Post-Fixup Action**: The handler executes $ERET$.\n- **Observed Empirical Result**:\n    - After $ERET$, the observed $PC$ is $0x00001004$.\n    - The faulting load instruction at $0x00001000$ does not re-execute.\n- **Question**: Based *only* on the provided semantics and description, what is the best explanation for returning to the wrong $PC$?\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is evaluated for validity.\n- **Scientifically Grounded**: The problem describes a standard exception handling model in a RISC architecture, consistent with real-world processors (e.g., MIPS). The concepts of a program counter ($PC$), an exception program counter ($EPC$), precise exceptions, synchronous traps (faults), a trap handler, and a return-from-exception instruction ($ERET$) are fundamental topics in computer organization and architecture. The description is factually and scientifically sound.\n- **Well-Posed**: The problem is well-posed. It provides explicit definitions for the behavior of the hardware upon a trap and upon executing $ERET$. It describes a sequence of events and a clear, specific outcome. The question asks for a logical explanation that connects the initial state and the handler's actions to the final outcome. A unique and deterministic solution can be derived from the provided information.\n- **Objective**: The language is precise and technical. All actions and states are described quantitatively (e.g., memory addresses, register operations). There is no subjective or ambiguous terminology.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. It is self-contained, logically consistent, and grounded in established principles of computer architecture. A solution will be derived.\n\n### Derivation of the Correct Behavior\nThe core of the analysis is to trace the value of the $EPC$ register through the sequence of events.\n\n1.  **Trap Initiation**: A synchronous trap occurs while executing the instruction at $PC = 0x00001000$.\n2.  **Hardware Response to Trap**: As per the problem definition (\"the hardware records the Program Counter (PC) of the instruction that caused the exception into the Exception Program Counter (EPC)\"), the hardware performs the following operation:\n    $$EPC \\leftarrow 0x00001000$$\n    At this point, control is transferred to the trap handler.\n3.  **Trap Handler Execution**: The handler begins its prologue. The relevant action for this analysis is the explicit modification of the $EPC$ register. The problem states the handler executes:\n    $$EPC \\leftarrow EPC + 4$$\n    Substituting the value of $EPC$ from the previous step:\n    $$EPC \\leftarrow 0x00001000 + 4$$\n    $$EPC \\leftarrow 0x00001004$$\n    The other prologue actions, such as saving registers to the stack, do not alter the value of the hardware $EPC$ register that will be used by $ERET$. They are distractions from the core logic.\n4.  **Return from Exception**: After the fault is presumably fixed, the handler executes the $ERET$ instruction. The behavior of $ERET$ is explicitly defined as:\n    $$PC \\leftarrow EPC$$\n    Using the current value of the $EPC$ register:\n    $$PC \\leftarrow 0x00001004$$\n5.  **Conclusion**: The processor resumes execution at the instruction located at address $0x00001004$. This means the instruction at $0x00001000$ is skipped. This derived result ($PC = 0x00001004$) perfectly matches the observed empirical result.\n\nThe reason this is considered the \"wrong PC\" is that for a faulting instruction (like a load that causes a page fault), the standard behavior after fixing the fault is to re-execute that same instruction. This would require returning to its address, $0x00001000$. The handler's action of incrementing $EPC$ is a bug for this type of exception; it treats the fault as if it were an event (like a software interrupt/`syscall`) that should be \"skipped\" upon return. The error is therefore squarely in the logic of the trap handler software.\n\n### Option-by-Option Analysis\n\n**A. The handler misinterprets the $EPC$ semantics and erroneously increments $EPC$ by one instruction ($+4$ bytes) in the prologue. Because $EPC$ already contains the address of the faulting instruction, this off-by-one adjustment forces $ERET$ to resume at $0x00001004$ instead of $0x00001000$.**\nThis option correctly identifies the chain of events as derived above. The hardware correctly sets $EPC$ to the faulting address ($0x00001000$). The handler software then incorrectly modifies this value to $0x00001004$. The $ERET$ instruction then uses this modified value, leading to the observed outcome. The phrase \"misinterprets the EPC semantics\" is an accurate high-level description of the bug: the handler fails to understand that for this type of trap, the $EPC$ value should be preserved to allow re-execution.\n**Verdict: Correct.**\n\n**B. The hardware records $EPC$ as the next sequential $PC$ ($PC + 4$) for synchronous traps, so resuming at $0x00001004$ is the expected behavior and there is no bug.**\nThis option contradicts a fundamental premise given in the problem statement. The problem explicitly defines that \"the hardware records the Program Counter (PC) of the instruction that caused the exception into the Exception Program Counter (EPC)\". This means $EPC$ is set to $PC$, not $PC+4$. If this option were true, the hardware would set $EPC$ to $0x00001004$ initially. Then the handler's adjustment ($EPC \\leftarrow EPC + 4$) would yield $EPC = 0x00001008$. $ERET$ would then cause a jump to $0x00001008$, which contradicts the observed outcome of $0x00001004$.\n**Verdict: Incorrect.**\n\n**C. The prologue’s stack layout is off by one slot, so on restore the handler loads $EPC$ from the return-address slot and $ERET$ jumps to $0x00001004$; the off-by-one arises from misaligned stack offsets rather than $EPC$ semantics.**\nThis option posits a stack restore operation that is not described in the problem. The handler is described as *storing* values to the stack in its prologue, and then executing $ERET$. The definition of $ERET$ is $PC \\leftarrow EPC$, meaning it reads directly from the hardware $EPC$ register. There is no mention of an epilogue that restores registers from the stack before $ERET$. The final value of the hardware $EPC$ register is determined by the $EPC \\leftarrow EPC + 4$ instruction, not by any load from the stack.\n**Verdict: Incorrect.**\n\n**D. The branch delay slot semantics cause $EPC$ to point to the delay slot, and the unconditional $ERET$ resumes at $PC + 4$; the off-by-one is due to delayed branching even though the faulting instruction is a load.**\nThis option introduces the concept of a branch delay slot, which is not mentioned anywhere in the problem description. One must reason *only* from the given information. Furthermore, branch delay slots are associated with branch instructions. The faulting instruction is explicitly a *load* instruction, making branch delay slot semantics irrelevant to the fault itself. The provided information is sufficient to explain the outcome without speculating about unmentioned architectural features.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "After understanding the mechanics of a single exception, we now consider the cumulative effect of multiple, nested interrupts. In resource-constrained environments like embedded systems, stack overflow is a catastrophic failure, and this exercise guides you through a worst-case analysis to prevent it. You will calculate the total stack consumption from a chain of preempting interrupts, determining the maximum safe nesting depth and learning how to budget a critical system resource—memory—to ensure reliability .",
            "id": "3640485",
            "problem": "A single-core embedded processor implements vectored, preemptive interrupts using a single downward-growing stack for both thread mode and handler mode. An Interrupt Service Routine (ISR) is a routine executed in response to an interrupt. On every interrupt entry, the hardware automatically saves a context frame on the current stack; the compiler-generated ISR prologue then saves additional software state on the same stack. There is no tail-chaining or lazy stacking; every interrupt entry pushes a full hardware frame, and every ISR uses the same worst-case prologue.\n\nAssume the following concrete, architecture-level facts, all of which are invariant across interrupts and nesting depth:\n\n- The total stack size is $S=3072$ bytes.\n- At the instant of the first interrupt arrival, the thread already uses $B=1024$ bytes of stack.\n- A guard margin $G=256$ bytes must remain unused to account for asynchronous activity and safety margin, so that exceeding $S-G$ bytes of usage is unsafe.\n- On each interrupt entry, the hardware pushes a fixed frame consisting of the return program counter ($8$ bytes), the processor status ($8$ bytes), and the interrupt identifier ($8$ bytes), followed by padding to maintain $16$-byte alignment of the stack pointer on entry to the ISR. The resulting hardware frame is $32$ bytes per entry.\n- Each ISR prologue conservatively saves $6$ callee-saved registers at $8$ bytes each and allocates $16$ bytes of local spill area, maintaining $16$-byte alignment. The resulting software usage per ISR is $64$ bytes.\n- There are $P=24$ distinct, strictly ordered interrupt priorities, and preemption occurs only from a higher-priority interrupt into a lower-priority ISR. At most one ISR per priority can be active at a time.\n\nConsider a worst-case nested preemption scenario on a time axis $t$, where a lowest-priority ISR begins at time $t_0$, and immediately upon entry is preempted by a higher-priority interrupt at $t_1$, which is in turn preempted at $t_2$, and so on, constructing a time diagram of nesting depth $d$ with strictly increasing times $t_0  t_1  \\dots  t_{d-1}$ and strictly increasing priorities. At each preemption, the stack grows by the sum of the hardware frame and the ISR software prologue for the new ISR, and no ISR returns until the maximum nesting depth is reached.\n\nStarting from the definitions of interrupts, the invariant that each nested interrupt adds its own independent context to the stack, and the requirement that total stack usage must stay strictly below the unsafe threshold, derive from first principles a closed-form expression for the maximum safe nesting depth $d_{\\max}$ as a function of $S$, $B$, $G$, and the per-level stack growth. Then, using the parameters given above, compute the value of $d_{\\max}$. Report the maximum safe nesting depth as an exact integer (unitless).",
            "solution": "The problem is first validated against the specified criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- Total stack size: $S=3072$ bytes.\n- Initial thread stack usage: $B=1024$ bytes.\n- Guard margin: $G=256$ bytes.\n- Hardware frame size per interrupt: $H=32$ bytes. This includes an $8$-byte return program counter, $8$-byte processor status, $8$-byte interrupt identifier, and padding for $16$-byte alignment.\n- Software stack usage per ISR: $W_{sw}=64$ bytes. This includes $6$ registers at $8$ bytes each ($48$ bytes) and $16$ bytes for a local spill area, maintaining $16$-byte alignment.\n- Number of distinct, strictly ordered interrupt priorities: $P=24$.\n- The condition for an unsafe state is if stack usage exceeds $S-G$.\n- The scenario is a worst-case nested preemption, where each interrupt adds a full context frame to the stack.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem statement describes a standard model of stack management for preemptive, nested interrupts in an embedded system. The concepts of hardware/software context saving, stack guards, and priority-based preemption are fundamental principles in computer architecture and real-time operating systems. The provided values are realistic. The problem is scientifically sound.\n- **Well-Posed:** The problem is clearly defined with all necessary parameters ($S$, $B$, $G$, per-level stack costs) provided. It asks for a specific, computable quantity, the maximum safe nesting depth $d_{\\max}$. The constraints are unambiguous. A unique, stable solution exists.\n- **Objective:** The problem is stated in precise, technical language, free of subjectivity or opinion.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid** as it is scientifically grounded, well-posed, and objective. A solution will be derived.\n\n### Solution Derivation\n\nThe fundamental principle governing this problem is that the total stack usage must not exceed the maximum safe limit. The stack grows downwards, but its size (usage) is a positive quantity measured from the stack base.\n\nLet $S$ be the total size of the stack, $B$ be the initial stack usage by the thread before any interrupts occur, and $G$ be the required guard margin that must remain unused. The maximum permissible stack usage, $U_{max}$, is therefore the total stack size minus the guard margin.\n$$U_{max} = S - G$$\n\nIn the worst-case scenario described, a series of $d$ nested interrupts occur. Each interrupt level adds a fixed amount of data to the stack. This per-level stack growth, let's call it $W_{level}$, is the sum of the hardware-pushed context frame, $H$, and the software-managed context saved by the ISR prologue, $W_{sw}$.\n$$W_{level} = H + W_{sw}$$\n\nLet $d$ be the nesting depth of the interrupts. Since each of the $d$ nested interrupts consumes $W_{level}$ bytes on the stack, the total stack usage contributed by the interrupts is $d \\cdot W_{level}$.\n\nThe total stack usage, $U(d)$, for a nesting depth of $d$ is the sum of the initial thread usage $B$ and the usage from the $d$ nested interrupts.\n$$U(d) = B + d \\cdot W_{level}$$\n\nFor the system to remain in a safe state, the total stack usage $U(d)$ must be less than or equal to the maximum permissible usage $U_{max}$.\n$$U(d) \\leq U_{max}$$\nSubstituting the expressions for $U(d)$ and $U_{max}$:\n$$B + d \\cdot W_{level} \\leq S - G$$\n\nTo find the maximum safe nesting depth, $d_{\\max}$, we must solve this inequality for the largest possible integer value of $d$.\n$$d \\cdot W_{level} \\leq S - B - G$$\n$$d \\leq \\frac{S - B - G}{W_{level}}$$\n\nSince the nesting depth $d$ must be an integer, the maximum value it can safely take, $d_{\\max}$, is the floor of the expression on the right-hand side.\n$$d_{\\max} = \\left\\lfloor \\frac{S - B - G}{W_{level}} \\right\\rfloor$$\nThis expression gives the maximum depth as constrained by stack space. The problem also states there are $P=24$ distinct priorities, which imposes an absolute physical limit on nesting depth. The true maximum depth is therefore the minimum of the value derived from the stack constraint and the number of priorities. However, the question specifically asks for the maximum *safe* nesting depth, which refers to the resource limit. We will calculate the value from the formula and verify it does not exceed $P$.\n\nNow, we substitute the given numerical values into the derived expressions.\n- $S = 3072$ bytes\n- $B = 1024$ bytes\n- $G = 256$ bytes\n- $H = 32$ bytes\n- $W_{sw} = 64$ bytes\n- $P = 24$\n\nFirst, calculate the per-level stack growth, $W_{level}$:\n$$W_{level} = H + W_{sw} = 32 + 64 = 96 \\text{ bytes}$$\nNext, calculate the available stack space for interrupt contexts, which is the total size less the initial usage and the guard:\n$$\\text{Available Space} = S - B - G = 3072 - 1024 - 256 = 1792 \\text{ bytes}$$\nNow, we can find the maximum nesting depth:\n$$d_{\\max} = \\left\\lfloor \\frac{1792}{96} \\right\\rfloor$$\nTo simplify the fraction $\\frac{1792}{96}$, we can divide both the numerator and the denominator by their greatest common divisor. Both are divisible by $32$.\n$$d_{\\max} = \\left\\lfloor \\frac{1792 \\div 32}{96 \\div 32} \\right\\rfloor = \\left\\lfloor \\frac{56}{3} \\right\\rfloor$$\nEvaluating the fraction:\n$$\\frac{56}{3} = 18.666...$$\nApplying the floor function gives the maximum integer depth:\n$$d_{\\max} = \\lfloor 18.666... \\rfloor = 18$$\nThis result, $18$, is less than the total number of interrupt priorities, $P=24$. Therefore, the limiting factor is the available stack space, not the number of priorities. The maximum safe nesting depth is $18$.",
            "answer": "$$\n\\boxed{18}\n$$"
        },
        {
            "introduction": "Beyond correctness and robustness, a key goal in system design is performance. This final practice explores an elegant optimization technique known as lazy context switching, where the system avoids expensive work on the chance it might not be needed. By building a probabilistic cost model, you will compare this 'lazy' policy to an 'eager' one, deriving the break-even point where one becomes more efficient than the other and gaining insight into the trade-offs that shape modern operating systems .",
            "id": "3640499",
            "problem": "A computer system implements lazy floating-point context switching to reduce average interrupt handling cost. Consider a single-core Central Processing Unit (CPU) running an Operating System (OS) with two alternative policies for handling the Floating-Point Unit (FPU) state across interrupt-induced context switches, in the presence of hardware exceptions and traps:\n\n- Eager policy: On every interrupt-induced context switch, the OS saves the outgoing task’s FPU state and restores the incoming task’s FPU state immediately.\n- Lazy policy: On an interrupt-induced context switch, the OS does not save the FPU state. Instead, it sets a software flag and marks the FPU as unavailable. If the incoming task executes a floating-point instruction, a synchronous trap occurs, after which the OS saves the outgoing FPU state and restores the incoming FPU state, enabling the FPU.\n\nAssume the following scientifically realistic costs, expressed in CPU cycles:\n- Saving the FPU state costs $C_{s} = 520$.\n- Restoring the FPU state costs $C_{r} = 480$.\n- Trap handling overhead for the first floating-point instruction (including exception entry/exit and minimal register frame handling) costs $C_{t} = 300$.\n- Book-keeping overhead incurred by the lazy policy at each context switch (such as setting the task-switched flag and disabling the FPU) costs $C_{\\ell} = 35$.\n- Interrupt entry/exit overhead $C_{i}$ is identical for both policies and can be treated as a common additive constant.\n\nLet $p$ denote the probability that the incoming task executes at least one floating-point instruction before the next context switch. Assume each task either triggers zero or one trap under the lazy policy per context switch.\n\nStarting from the foundational definitions of asynchronous interrupts, synchronous traps, and expected value in probability theory, and without using any shortcut formulas, do the following:\n1. Derive the expected cycles per interrupt-induced context switch under the eager policy as a function of $C_{s}$, $C_{r}$, and $C_{i}$.\n2. Derive the expected cycles per interrupt-induced context switch under the lazy policy as a function of $p$, $C_{\\ell}$, $C_{t}$, $C_{s}$, $C_{r}$, and $C_{i}$.\n3. Derive an expression for the expected cycles saved per interrupt when using the lazy policy instead of the eager policy as a function of $p$, $C_{\\ell}$, $C_{t}$, $C_{s}$, and $C_{r}$ (express this in cycles per interrupt).\n4. Determine the critical probability $p^{\\star}$ such that the expected cycles saved per interrupt is zero, meaning the lazy and eager policies have equal expected cost. Evaluate $p^{\\star}$ numerically for the given constants.\n\nExpress the expected cycles saved in cycles per interrupt. Report only the final value of $p^{\\star}$ as a dimensionless number. Round your value of $p^{\\star}$ to four significant figures.",
            "solution": "The problem requires an analysis of two policies for handling Floating-Point Unit (FPU) state during an interrupt-induced context switch. We will model the costs based on probabilistic principles to determine the performance trade-offs. The analysis will be performed by first validating the problem statement and then proceeding through a step-by-step derivation.\n\n### Problem Validation\nThe given problem is valid.\n1.  **Givens Extracted**:\n    *   Cost to save FPU state: $C_s = 520$ cycles.\n    *   Cost to restore FPU state: $C_r = 480$ cycles.\n    *   Trap handling overhead for lazy policy: $C_t = 300$ cycles.\n    *   Book-keeping overhead for lazy policy per context switch: $C_{\\ell} = 35$ cycles.\n    *   Common interrupt entry/exit overhead: $C_i$ cycles.\n    *   Probability of the incoming task executing a floating-point instruction: $p$.\n2.  **Validation Verdict**:\n    *   **Scientifically Grounded**: The problem describes lazy FPU context switching, a standard optimization technique in operating systems. The distinction between asynchronous interrupts and synchronous traps is fundamental to computer architecture. The use of expected value is the correct mathematical tool for analyzing performance under probabilistic conditions.\n    *   **Well-Posed**: The problem is clearly stated with all necessary parameters defined. It asks for specific derivations and a numerical result, which can be uniquely determined from the given information.\n    *   **Objective**: The problem is expressed using precise, technical terminology and provides objective numerical data without subjective bias.\n\nThe problem is therefore valid and a solution can be derived.\n\n### Foundational Principles\nAn **asynchronous interrupt** is an event generated by hardware external to the CPU's current instruction stream (e.g., a disk controller signalling I/O completion). Its timing is unpredictable with respect to the program's execution. A **synchronous trap** (or exception) is an event that occurs as a direct result of executing an instruction (e.g., division by zero, or, in this problem, attempting to use a disabled FPU).\n\nThe **expected value** of a discrete random variable $X$, denoted $E[X]$, is a probability-weighted average of all its possible values. If $X$ can take values $\\{x_1, x_2, \\dots, x_n\\}$ with corresponding probabilities $\\{P(X=x_1), P(X=x_2), \\dots, P(X=x_n)\\}$, its expected value is given by:\n$$E[X] = \\sum_{k=1}^{n} x_k P(X=x_k)$$\nIn our context, the random variable is the number of cycles required for a context switch, which depends on whether the incoming task uses the FPU.\n\n### Task 1: Expected Cycles for the Eager Policy ($E_{eager}$)\nUnder the eager policy, the FPU state of the outgoing task is always saved, and the FPU state of the incoming task is always restored on every interrupt-induced context switch. This sequence of operations is deterministic. The total cost is the sum of the common interrupt overhead and the specific costs for saving and restoring the FPU state.\nThe cost is constant for every context switch.\n$$\n\\text{Cost}_{eager} = C_i + C_s + C_r\n$$\nSince this cost is incurred with a probability of $1$, the expected number of cycles per context switch, $E_{eager}$, is equal to this cost.\n$$\nE_{eager} = C_i + C_s + C_r\n$$\n\n### Task 2: Expected Cycles for the Lazy Policy ($E_{lazy}$)\nUnder the lazy policy, the cost depends on whether the incoming task executes a floating-point instruction. There are two mutually exclusive outcomes for each context switch:\n\n1.  **Case 1: The incoming task does not execute any floating-point instruction.** This event occurs with probability $1-p$. In this case, the OS only incurs the initial book-keeping overhead to disable the FPU. The expensive save and restore operations are completely avoided. The cost for this case is:\n    $$\n    \\text{Cost}_1 = C_i + C_{\\ell}\n    $$\n2.  **Case 2: The incoming task executes at least one floating-point instruction.** This event occurs with probability $p$. The first attempt to execute a floating-point instruction triggers a synchronous trap. The OS trap handler then saves the FPU state of the previous task and restores the FPU state for the current task. The total cost includes the book-keeping overhead, the trap handling overhead, and the costs of saving and restoring the FPU state. The cost for this case is:\n    $$\n    \\text{Cost}_2 = C_i + C_{\\ell} + C_t + C_s + C_r\n    $$\n\nUsing the definition of expected value, the expected cycles per context switch for the lazy policy, $E_{lazy}$, is the sum of the costs of each case weighted by their respective probabilities:\n$$\nE_{lazy} = (\\text{Cost}_1 \\times (1-p)) + (\\text{Cost}_2 \\times p)\n$$\nSubstituting the cost expressions:\n$$\nE_{lazy} = (C_i + C_{\\ell})(1-p) + (C_i + C_{\\ell} + C_t + C_s + C_r)p\n$$\nWe can simplify this expression by distributing the terms:\n$$\nE_{lazy} = C_i(1-p) + C_{\\ell}(1-p) + C_i p + C_{\\ell} p + (C_t + C_s + C_r)p\n$$\n$$\nE_{lazy} = C_i - C_i p + C_{\\ell} - C_{\\ell} p + C_i p + C_{\\ell} p + p(C_t + C_s + C_r)\n$$\nThe terms $-C_i p$ and $+C_i p$ cancel, as do $-C_{\\ell} p$ and $+C_{\\ell} p$. This leads to the simplified form:\n$$\nE_{lazy} = C_i + C_{\\ell} + p(C_t + C_s + C_r)\n$$\n\n### Task 3: Expected Cycles Saved per Interrupt ($\\Delta E$)\nThe expected cycles saved, $\\Delta E$, is the difference between the expected cost of the eager policy and the expected cost of the lazy policy.\n$$\n\\Delta E = E_{eager} - E_{lazy}\n$$\nSubstituting the expressions derived in Tasks 1 and 2:\n$$\n\\Delta E = (C_i + C_s + C_r) - \\left( C_i + C_{\\ell} + p(C_t + C_s + C_r) \\right)\n$$\nThe common interrupt overhead, $C_i$, cancels out:\n$$\n\\Delta E = C_s + C_r - C_{\\ell} - p(C_t + C_s + C_r)\n$$\nThis expression can be rearranged to highlight the savings versus the additional costs:\n$$\n\\Delta E = (1-p)(C_s + C_r) - C_{\\ell} - pC_t\n$$\nThis form shows that with probability $1-p$, we save the cost of a full save/restore, $C_s+C_r$. However, we always incur the lazy book-keeping cost $C_{\\ell}$, and with probability $p$, we incur the additional trap cost $C_t$. Both forms are equivalent. We will use the first derived form for the next step.\n$$\n\\Delta E = (C_s + C_r - C_{\\ell}) - p(C_t + C_s + C_r)\n$$\n\n### Task 4: Critical Probability ($p^{\\star}$)\nThe critical probability, $p^{\\star}$, is the value of $p$ for which the two policies have equal expected cost. This occurs when the expected cycles saved, $\\Delta E$, is zero.\n$$\n\\Delta E = 0\n$$\n$$\n(C_s + C_r - C_{\\ell}) - p^{\\star}(C_t + C_s + C_r) = 0\n$$\nSolving for $p^{\\star}$:\n$$\np^{\\star}(C_t + C_s + C_r) = C_s + C_r - C_{\\ell}\n$$\n$$\np^{\\star} = \\frac{C_s + C_r - C_{\\ell}}{C_t + C_s + C_r}\n$$\nNow, we substitute the given numerical values: $C_s = 520$, $C_r = 480$, $C_t = 300$, and $C_{\\ell} = 35$.\n$$\np^{\\star} = \\frac{520 + 480 - 35}{300 + 520 + 480}\n$$\n$$\np^{\\star} = \\frac{1000 - 35}{300 + 1000}\n$$\n$$\np^{\\star} = \\frac{965}{1300}\n$$\nPerforming the division:\n$$\np^{\\star} \\approx 0.74230769...\n$$\nRounding to four significant figures, we get:\n$$\np^{\\star} \\approx 0.7423\n$$\nThis means that if more than approximately $74.23\\%$ of context switches are followed by a floating-point instruction, the eager policy becomes more efficient than the lazy policy.",
            "answer": "$$\\boxed{0.7423}$$"
        }
    ]
}