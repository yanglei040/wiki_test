{
    "hands_on_practices": [
        {
            "introduction": "The transition from user mode to supervisor mode is a fundamental operation in modern computing, but it is not without cost. This exercise will guide you through a detailed performance analysis of a system call, breaking down the total overhead into discrete components such as pipeline stalls, state preservation, and cache interactions. By quantifying the cycle cost of each step , you will develop a concrete understanding of the intricate microarchitectural events that underpin this critical privilege transition.",
            "id": "3669149",
            "problem": "A Reduced Instruction Set Computer (RISC) processor uses a five-stage pipeline with stages Instruction Fetch (IF), Instruction Decode (ID), Execute (EX), Memory Access (MEM), and Write Back (WB). The processor supports a user mode and a privileged supervisor mode, toggled by a mode bit in the Processor State Register (PSR). A system call from user mode triggers a trap into supervisor mode, which drains the pipeline, dispatches to a trap handler, and performs setup before executing privileged instructions. The architecture uses register windows similar to the Scalable Processor Architecture (SPARC), where a trap into supervisor mode attempts to switch to a supervisor window; if the register windows are exhausted, a register window spill is performed to memory by the trap handler. On return to user mode, the pipeline is refilled and user-visible architectural state is restored.\n\nUse the following scenario and fundamental facts to model the total cycle cost of a single system call transition from user mode to supervisor mode and back. The total cycle cost is defined as the sum of the cycle costs of saving the required state, taking the trap, entering supervisor mode, and returning to user mode. You must compute this total and provide a single numerical answer.\n\nFundamental base and scenario:\n- Traps from user mode to supervisor mode drain the pipeline by halting fetch and allowing in-flight instructions to complete. In a pipeline with $p$ stages, draining costs $p$ cycles, and refilling later costs $p$ cycles.\n- Trap vector dispatch is performed after the drain and takes a fixed number of cycles due to trap routing and privilege checks.\n- The supervisor entry sequence executes a small number of privileged setup instructions and may introduce bubbles due to control hazards.\n- The trap handler saves special registers and performs a register window spill when required; saves and spills are implemented via store instructions to the Level-1 (L1) data cache.\n- On return to user mode, the handler restores special registers and performs a register window fill via load instructions; after toggling back to user mode, the pipeline is refilled.\n\nGiven parameters:\n- Pipeline has $p = 5$ stages.\n- Trap vector dispatch cost $C_{\\text{vector}} = 12$ cycles.\n- The trap handler saves $n_{s} = 6$ special registers: Program Counter (PC), Next Program Counter (nPC), Processor State Register (PSR), Window Invalid Mask (WIM), Trap Base Register (TBR), and User Stack Pointer (USP).\n- A register window spill occurs on entry, spilling $n_{w} = 16$ registers, with a fixed spill overhead of $o_{s} = 4$ cycles due to spill control sequencing.\n- The average cycles per store to the L1 data cache is modeled by $c_{s} = h_{s} \\cdot 1 + (1 - h_{s}) \\cdot m_{s}$, with hit rate $h_{s} = 0.75$ and miss penalty $m_{s} = 8$ cycles.\n- Supervisor entry executes $n_{e} = 5$ setup instructions (e.g., toggling the PSR mode bit, loading the kernel stack pointer), incurring $b = 2$ bubble cycles due to control hazards.\n- On return, the handler restores $n_{r} = 3$ special registers ($PC$, $nPC$, $PSR$) and performs a register window fill of $n_{w} = 16$ registers, with a fixed fill overhead of $o_{f} = 4$ cycles.\n- The average cycles per load to the L1 data cache is modeled by $c_{\\ell} = h_{\\ell} \\cdot 1 + (1 - h_{\\ell}) \\cdot m_{\\ell}$, with hit rate $h_{\\ell} = 0.80$ and miss penalty $m_{\\ell} = 10$ cycles.\n\nCompute the total cycle cost $C$ for this system call, aggregating the following components:\n- Trap handling cost (pipeline drain plus trap vector dispatch).\n- State save cost on entry (saving special registers and performing the register window spill).\n- Supervisor entry sequencing cost.\n- Return-to-user cost (pipeline refill plus restoring special registers and performing the register window fill).\n\nExpress your final answer as a single real-valued number of cycles. Round your answer to four significant figures. No units are required in the final boxed value.",
            "solution": "The problem requires the computation of the total cycle cost, $C$, of a system call transition. The total cost is the sum of four distinct components: the trap handling cost, the state save cost, the supervisor entry sequencing cost, and the return-to-user cost. We will calculate each component systematically based on the provided parameters.\n\nThe total cost $C$ is given by the sum:\n$$C = C_{\\text{trap\\_entry}} + C_{\\text{save}} + C_{\\text{supervisor\\_entry}} + C_{\\text{return}}$$\n\nWe begin by calculating each term.\n\n1.  **Trap Handling Cost ($C_{\\text{trap\\_entry}}$)**\n    This cost comprises the pipeline drain and the trap vector dispatch. The pipeline has $p = 5$ stages, so draining it costs $p = 5$ cycles. The trap vector dispatch cost is given as $C_{\\text{vector}} = 12$ cycles.\n    $$C_{\\text{trap\\_entry}} = p + C_{\\text{vector}} = 5 + 12 = 17 \\text{ cycles}$$\n\n2.  **State Save Cost on Entry ($C_{\\text{save}}$)**\n    This cost includes saving special registers and performing a register window spill. Both actions involve store operations to the Level-$1$ (L$1$) data cache. First, we must calculate the average cycles per store, $c_s$.\n    The formula for $c_s$ is given by $c_{s} = h_{s} \\cdot 1 + (1 - h_{s}) \\cdot m_{s}$, with a store hit rate $h_{s} = 0.75$ and a miss penalty $m_{s} = 8$ cycles.\n    $$c_{s} = (0.75 \\cdot 1) + (1 - 0.75) \\cdot 8 = 0.75 + (0.25 \\cdot 8) = 0.75 + 2 = 2.75 \\text{ cycles/store}$$\n    The total number of registers to be saved is the sum of special registers, $n_s = 6$, and registers from the window spill, $n_w = 16$. The spill operation also has a fixed overhead of $o_s = 4$ cycles.\n    $$C_{\\text{save}} = (n_s + n_w) \\cdot c_s + o_s = (6 + 16) \\cdot 2.75 + 4 = 22 \\cdot 2.75 + 4$$\n    $$C_{\\text{save}} = 60.5 + 4 = 64.5 \\text{ cycles}$$\n\n3.  **Supervisor Entry Sequencing Cost ($C_{\\text{supervisor\\_entry}}$)**\n    This is the cost of executing $n_e = 5$ setup instructions, which incur $b = 2$ bubble cycles due to control hazards. The cost is the sum of the cycles for the instructions (assuming a single cycle per instruction in a steady state, as pipeline fill/drain effects are accounted for elsewhere) and the bubble cycles.\n    $$C_{\\text{supervisor\\_entry}} = n_e + b = 5 + 2 = 7 \\text{ cycles}$$\n\n4.  **Return-to-User Cost ($C_{\\text{return}}$)**\n    This cost is composed of the pipeline refill, restoring special registers, and performing a register window fill. The pipeline refill cost is equal to the number of stages, $p = 5$ cycles. The register operations involve loads from the L$1$ data cache. First, we calculate the average cycles per load, $c_{\\ell}$.\n    The formula for $c_{\\ell}$ is given by $c_{\\ell} = h_{\\ell} \\cdot 1 + (1 - h_{\\ell}) \\cdot m_{\\ell}$, with a load hit rate $h_{\\ell} = 0.80$ and a miss penalty $m_{\\ell} = 10$ cycles.\n    $$c_{\\ell} = (0.80 \\cdot 1) + (1 - 0.80) \\cdot 10 = 0.80 + (0.20 \\cdot 10) = 0.80 + 2 = 2.80 \\text{ cycles/load}$$\n    The number of special registers to restore is $n_r = 3$, and the number of registers for the window fill is $n_w = 16$. The fill operation incurs a fixed overhead of $o_f = 4$ cycles.\n    $$C_{\\text{return}} = p + (n_r + n_w) \\cdot c_{\\ell} + o_f = 5 + (3 + 16) \\cdot 2.80 + 4$$\n    $$C_{\\text{return}} = 9 + 19 \\cdot 2.80 = 9 + 53.2 = 62.2 \\text{ cycles}$$\n\nFinally, we sum the four components to find the total cycle cost $C$.\n$$C = C_{\\text{trap\\_entry}} + C_{\\text{save}} + C_{\\text{supervisor\\_entry}} + C_{\\text{return}}$$\n$$C = 17 + 64.5 + 7 + 62.2$$\n$$C = 150.7$$\nThe problem requires the answer to be rounded to four significant figures. The calculated value $150.7$ already has four significant figures, so no further rounding is needed.",
            "answer": "$$\\boxed{150.7}$$"
        },
        {
            "introduction": "Building on the concept of trap overhead, we now explore its impact on a common operating system service: virtual memory management. This practice examines the copy-on-write (COW) mechanism, where a trap to supervisor mode is necessary to handle a page fault and create a private copy of a memory page. You will calculate the total end-to-end latency of this operation , learning to combine processor-bound costs (measured in cycles) with memory-bound costs (measured by bandwidth) to analyze real-world system performance.",
            "id": "3669132",
            "problem": "A user-mode thread on a uniprocessor system writes to a memory page that is currently shared under copy-on-write (COW). On the write, the processor detects a protection violation and raises a synchronous trap into the operating system running in supervisor mode. The kernel resolves the COW fault by allocating a new physical page, copying the old page’s contents into it, updating the page table to point to the new page with write permission, invalidating the Translation Lookaside Buffer (TLB; Translation Lookaside Buffer), and then returning to user mode. Assume the following:\n\n- The processor frequency is $f = 3.2 \\times 10^{9}\\,\\text{Hz}$.\n- The page size is $P = 4\\,\\text{KiB}$.\n- The effective sustained memory bandwidth available to the kernel copy routine during this fault is $B = 12 \\times 2^{30}\\,\\text{bytes}/\\text{s}$.\n- The trap entry and return sequence, including saving and restoring state and minimal dispatcher work, consumes a total of $1520$ cycles on this workload.\n- The page allocator’s metadata work (lock acquisition, free-list manipulation, and bookkeeping), excluding the actual data copy, consumes $840$ cycles.\n- The page table update and local TLB invalidation sequence (no inter-processor shootdown) consumes $680$ cycles.\n- All phases occur strictly sequentially with no overlap. Ignore cache warm-up effects beyond what is reflected in the provided cycle and bandwidth parameters.\n\nStarting only from the definitions that (i) a trap is a controlled transfer from user mode to supervisor mode with an associated state save/restore cost measured in cycles, (ii) time per cycle is $1/f$, and (iii) bulk copy time for a page of size $P$ at sustained bandwidth $B$ is $P/B$, determine the total end-to-end latency for servicing this single COW write fault, measured from the instant of the faulting instruction’s trap to the instant control returns to user mode after the mapping is updated.\n\nExpress your final numerical answer in microseconds and round your answer to four significant figures.",
            "solution": "The total end-to-end latency, $T_{total}$, for servicing the copy-on-write fault is the sum of the latencies of the individual, sequential phases described in the problem. The process can be broken down into two types of costs: those measured in processor cycles and the cost of the bulk data transfer.\n\nThe total latency is given by:\n$$T_{total} = T_{overhead} + T_{copy}$$\nwhere $T_{overhead}$ is the time spent on processor-bound tasks (trap handling, page allocation, and page table updates), and $T_{copy}$ is the time spent on the memory-bound page copy operation.\n\nFirst, we calculate the total number of cycles, $C_{overhead}$, for the processor-bound tasks. This is the sum of the cycles for each specified phase:\n$$C_{overhead} = C_{trap} + C_{alloc} + C_{update}$$\nSubstituting the given values:\n$$C_{overhead} = 1520 + 840 + 680 = 3040\\,\\text{cycles}$$\n\nThe time duration of one processor cycle is the reciprocal of the processor frequency, $T_{cycle} = 1/f$. Therefore, the total time for the overhead tasks is:\n$$T_{overhead} = \\frac{C_{overhead}}{f}$$\nSubstituting the values for $C_{overhead}$ and $f$:\n$$T_{overhead} = \\frac{3040}{3.2 \\times 10^9\\,\\text{Hz}}$$\n\nNext, we calculate the time required for copying the page data, $T_{copy}$. This time is given by the page size, $P$, divided by the effective memory bandwidth, $B$:\n$$T_{copy} = \\frac{P}{B}$$\n\nBefore substituting the values, we must ensure consistent units. The page size is $P = 4\\,\\text{KiB}$. A kibibyte (KiB) is $2^{10}$ bytes.\n$$P = 4 \\times 2^{10}\\,\\text{bytes}$$\nThe memory bandwidth is given as $B = 12 \\times 2^{30}\\,\\text{bytes/s}$.\nSubstituting these into the expression for $T_{copy}$:\n$$T_{copy} = \\frac{4 \\times 2^{10}\\,\\text{bytes}}{12 \\times 2^{30}\\,\\text{bytes/s}} = \\frac{4}{12} \\times \\frac{2^{10}}{2^{30}}\\,\\text{s} = \\frac{1}{3} \\times 2^{-20}\\,\\text{s}$$\n\nNow we can compute the total latency, $T_{total}$, by summing the two components:\n$$T_{total} = T_{overhead} + T_{copy} = \\frac{3040}{3.2 \\times 10^9}\\,\\text{s} + \\frac{1}{3} \\times 2^{-20}\\,\\text{s}$$\n\nWe will now compute the numerical value for each term.\nFor the overhead time:\n$$T_{overhead} = \\frac{3040}{3.2 \\times 10^9} = \\frac{3.04 \\times 10^3}{3.2 \\times 10^9} = 0.95 \\times 10^{-6}\\,\\text{s}$$\n\nFor the copy time:\n$2^{20} = (2^{10})^2 = 1024^2 = 1048576$.\n$$T_{copy} = \\frac{1}{3 \\times 1048576} = \\frac{1}{3145728} \\approx 0.31789145 \\times 10^{-6}\\,\\text{s}$$\n\nSumming the two time components:\n$$T_{total} = (0.95 \\times 10^{-6} + 0.31789145 \\times 10^{-6})\\,\\text{s}$$\n$$T_{total} = (0.95 + 0.31789145) \\times 10^{-6}\\,\\text{s}$$\n$$T_{total} \\approx 1.26789145 \\times 10^{-6}\\,\\text{s}$$\n\nThe problem requires the final answer to be expressed in microseconds ($\\mu\\text{s}$), where $1\\,\\mu\\text{s} = 10^{-6}\\,\\text{s}$.\n$$T_{total} \\approx 1.26789145\\,\\mu\\text{s}$$\n\nFinally, we round the result to four significant figures. The first four significant figures are $1.267$. The fifth digit is $8$, so we round up the fourth digit.\n$$T_{total} \\approx 1.268\\,\\mu\\text{s}$$",
            "answer": "$$\\boxed{1.268}$$"
        },
        {
            "introduction": "The strict separation between user and supervisor modes is not merely an organizational choice; it is a cornerstone of system security and stability. This final exercise challenges you to think like a security architect by analyzing why a common vulnerability—a stack buffer overflow—fails to escalate privileges on a well-designed processor. By identifying the multiple, layered hardware defenses that work in concert to thwart the attack , you will gain a deeper appreciation for the critical role that privilege levels play in building robust and trustworthy computing systems.",
            "id": "3669128",
            "problem": "An architecture provides two privilege levels, User mode ($U$) and Supervisor mode ($S$), and enforces the following well-tested and widely used mechanisms:\n\n- On a system call trap from $U$ to $S$ (for example via an instruction like $ECALL$), the Central Processing Unit (CPU) saves the current user Program Counter ($PC$) into a privileged exception register ($EPC$), switches the current Stack Pointer ($SP$) from the user stack pointer $SP_u$ to a privileged kernel stack pointer $SP_k$ stored in a privileged control register, updates the privilege state to $S$, and pushes a trap frame on the kernel stack pointed to by $SP_k$.\n- On return from the trap, the operating system (OS) executes a privileged return instruction (for example $SRET$) that restores $PC$ from $EPC$ and restores $SP$ to $SP_u$ such that execution resumes in $U$ at the instruction following the original $ECALL$.\n- The virtual memory system uses page table entries (PTEs) with a user/supervisor bit. Instruction fetch, load, and store from $U$ are permitted only on pages marked as user-accessible. Kernel code and data pages are marked supervisor-only, so fetching an instruction from a supervisor-only page while in $U$ triggers a protection fault.\n- The calling convention uses a hardware-managed shadow stack. For every $CALL$, the hardware pushes the return address onto an internal Shadow Stack (SS) whose pointer ($SSP$) is not directly accessible to software. For every $RET$, the hardware compares the return address on the regular stack to the top entry on the SS and raises an exception if they differ, preventing control-flow hijacking. Only on a successful match does the CPU pop from the SS and transfer control.\n\nA developer constructs the following user-mode test harness intended to escalate privileges by manipulating return addresses:\n\n- In $U$, a function $foo$ allocates a local buffer of size $N = 64$ bytes on the user stack at some user virtual address $A_u$. A bug allows copying $N + 16 = 80$ bytes into this buffer, overwriting the saved return address in $foo$'s activation record on the user stack.\n- The harness overwrites the saved return address with the address $A_k = 0xFFFF000000100000$, which is known to lie within a kernel text page mapped read-only and supervisor-only. Assume the kernel text occupies a range $[A_k, A_k + 0x1000)$ and is not mapped as user-accessible in the PTEs.\n- Immediately after corrupting the saved return address, $foo$ issues an $ECALL$ to invoke a system service. The kernel handler executes some code in $S$ and returns back to $U$ with $SRET$.\n- After the return to $U$, execution in $foo$ proceeds to the epilogue, which executes a $RET$ from $foo$.\n\nSelect all statements that correctly explain why this harness fails to transfer control to $A_k$ (that is, why it fails to execute code at $A_k$ at any privilege level), in the architecture described.\n\nA. The forged user-mode saved return address cannot influence control flow while in $S$ because on $ECALL$ the CPU switches to $SP_k$, saves $PC$ in $EPC$, and the kernel returns with $SRET$ using $EPC$; the kernel never consults the user stack for control data during trap handling.\n\nB. When the $RET$ in $U$ attempts to use the forged return address $A_k$, the hardware-managed shadow stack detects a mismatch between the on-stack return address and the protected SS entry and raises an exception before any control transfer, blocking the exploit in $U$.\n\nC. Even if the shadow stack were absent, attempting to transfer control to $A_k$ from $U$ would fail because instruction fetch from $A_k$ would violate the user/supervisor permission check on the PTE, triggering a protection fault and preventing execution of supervisor-only code in $U$.\n\nD. The exploit would succeed if the attacker had instead placed $A_k$ on the kernel stack before the $ECALL$; upon returning from the system call, the kernel would pop $A_k$ from its own stack and jump to it in $S$.\n\nProvide your choice(s) as letters.",
            "solution": "The problem describes an attempt to escalate privilege from User mode ($U$) to Supervisor mode ($S$) on a hypothetical, yet realistic, processor architecture. The attack involves a classic stack-based buffer overflow to overwrite a function's return address. We will analyze the sequence of events and the architectural features to determine why the attack fails.\n\nThe sequence of events is as follows:\n1.  In user mode ($U$), the function `foo` is executing. A buffer overflow on the user stack overwrites the saved return address for `foo`. The original, correct return address is replaced with a forged address, $A_k = 0xFFFF000000100000$, which points to a location within a supervisor-only kernel code page.\n2.  Crucially, the architecture features a hardware-managed shadow stack (SS). When `foo` was initially called, the correct return address was pushed onto this protected SS. This SS is not affected by the buffer overflow on the user stack.\n3.  After the stack corruption, `foo` executes an `ECALL` instruction, trapping into the kernel.\n4.  The CPU handles the trap by switching to Supervisor mode ($S$), saving the user-mode Program Counter ($PC_{user}$) into the Exception Program Counter register ($EPC$), and switching the stack pointer from the user stack pointer ($SP_u$) to the kernel stack pointer ($SP_k$). Control is transferred to the kernel's system call handler.\n5.  The kernel executes its service routine in $S$ mode, using the kernel stack. The corrupted user stack is not used for kernel control flow.\n6.  To return to user mode, the kernel executes a privileged `SRET` instruction. This instruction restores the $PC$ from the value stored in `EPC` and switches the privilege level back to $U$. Execution resumes in `foo` at the instruction immediately following the `ECALL`.\n7.  The function `foo` continues execution until its epilogue, where it executes a `RET` instruction to return to its caller.\n8.  The `RET` instruction attempts to transfer control. It pops the forged address $A_k$ from the user stack. The hardware then compares this address with the legitimate return address stored on the shadow stack.\n\nWe will now evaluate each of the provided statements based on this sequence and the architectural rules.\n\nA. **The forged user-mode saved return address cannot influence control flow while in $S$ because on $ECALL$ the CPU switches to $SP_k$, saves $PC$ in $EPC$, and the kernel returns with $SRET$ using $EPC$; the kernel never consults the user stack for control data during trap handling.**\n\nThis statement accurately describes the trap handling mechanism. The transition from $U$ to $S$ via `ECALL` and the return from $S$ to $U$ via `SRET` form a secure and isolated pathway. The control flow return path for the exception is managed through the dedicated `EPC` register, not through any data on the user stack. The kernel operates on its own private stack ($SP_k$). Therefore, the corruption of the return address on the user stack has no effect on the execution flow while the CPU is in Supervisor mode or during the immediate return from the system call. This is a key security feature that prevents the exploit from hijacking the kernel directly during the system call. This statement correctly identifies one reason the overall attack strategy fails.\n\n**Verdict: Correct.**\n\nB. **When the $RET$ in $U$ attempts to use the forged return address $A_k$, the hardware-managed shadow stack detects a mismatch between the on-stack return address and the protected SS entry and raises an exception before any control transfer, blocking the exploit in $U$.**\n\nThis statement describes the event that occurs when `foo` attempts to return to its caller. After the `SRET` returns control to `foo`, the function eventually executes a `RET` instruction. According to the problem description, the hardware performs two actions on `RET`: it reads the return address from the regular stack (which is the forged address $A_k$) and compares it to the return address popped from the shadow stack (which is the original, legitimate address). Since the buffer overflow only modified the user stack, these two addresses will not match. The architecture specifies that in case of a mismatch, an exception is raised. This hardware check, a form of Control-Flow Integrity (CFI), directly prevents the corrupted return address from being used to hijack control flow. The jump to $A_k$ is never attempted.\n\n**Verdict: Correct.**\n\nC. **Even if the shadow stack were absent, attempting to transfer control to $A_k$ from $U$ would fail because instruction fetch from $A_k$ would violate the user/supervisor permission check on the PTE, triggering a protection fault and preventing execution of supervisor-only code in $U$.**\n\nThis statement considers a hypothetical scenario without the shadow stack, which highlights another layer of defense. In this case, the `RET` instruction would pop $A_k$ from the stack and attempt to set the Program Counter ($PC$) to this value. However, execution is still in User mode ($U$). The address $A_k$ is in a page marked \"supervisor-only\" in its Page Table Entry (PTE). The virtual memory system is specified to enforce this protection: \"Instruction fetch... from $U$ are permitted only on pages marked as user-accessible.\" Therefore, the Memory Management Unit (MMU) would detect a privilege violation when trying to fetch an instruction from $A_k$ while in $U$ mode. This would trigger a protection fault, which is an exception that transfers control to the OS kernel. The malicious code at $A_k$ would not be executed. This statement correctly identifies a fundamental memory protection mechanism that also causes the attack to fail.\n\n**Verdict: Correct.**\n\nD. **The exploit would succeed if the attacker had instead placed $A_k$ on the kernel stack before the $ECALL$; upon returning from the system call, the kernel would pop $A_k$ from its own stack and jump to it in $S$.**\n\nThis statement is fundamentally flawed. The premise \"placed $A_k$ on the kernel stack before the $ECALL$\" is impossible under the described architecture. The kernel stack resides in memory pages marked as \"supervisor-only\". A process running in User mode ($U$) does not have the necessary permissions to write to these pages. Any attempt by the user-mode harness to write to an address on the kernel stack would result in a protection fault, halting the malicious code long before it could execute an `ECALL`. Furthermore, the conclusion is also incorrect. Kernels do not \"pop\" arbitrary addresses from their stack and jump to them upon returning from a system call. The return from a system call is handled by the `SRET` instruction, which uses the `EPC` register. Any returns from functions *within* the kernel use addresses placed on the kernel stack by `CALL` instructions executed by the kernel itself. The premise is impossible and the conclusion misrepresents kernel operation.\n\n**Verdict: Incorrect.**\n\nIn summary, statements A, B, and C all describe valid and distinct reasons, based on the provided architectural features, why the described privilege escalation harness fails to transfer control to the target address $A_k$.",
            "answer": "$$\\boxed{ABC}$$"
        }
    ]
}