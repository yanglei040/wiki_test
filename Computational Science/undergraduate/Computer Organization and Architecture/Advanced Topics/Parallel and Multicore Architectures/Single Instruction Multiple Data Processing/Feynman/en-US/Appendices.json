{
    "hands_on_practices": [
        {
            "introduction": "The essence of Single Instruction, Multiple Data (SIMD) processing is applying one instruction to many data points in parallel. This practice demonstrates the fundamental technique of masking, which transforms conditional logic into branchless arithmetic, a cornerstone of efficient SIMD programming. You will implement a common task—converting text to lowercase—to make this abstract concept tangible and learn how to handle arrays that are not a perfect multiple of the vector width.",
            "id": "3677497",
            "problem": "You are given a sequence of unsigned bytes representing American Standard Code for Information Interchange (ASCII) character codes. In ASCII, uppercase letters have numeric codes from $65$ to $90$ inclusive, and their lowercase counterparts are obtained by adding $32$ to the uppercase code. Single Instruction, Multiple Data (SIMD) processing applies the same operation to multiple independent data lanes simultaneously. In software, we can emulate SIMD by partitioning the input into fixed-size groups and applying the same computations to each element in a group using masks.\n\nStarting from the following fundamental base:\n- The ASCII codes for uppercase letters are in the closed interval $[65, 90]$.\n- The ASCII codes for lowercase letters are exactly $32$ greater than their uppercase counterparts.\n- A mask predicate can be defined per lane to indicate whether a condition is true ($1$) or false ($0$), and this mask can be used to conditionally add $32$ to lanes that match the uppercase range without branching.\n\nDesign and implement a program that, for an input array $X$ of length $n$, a vector width $w$, and for each lane index $i$, produces an output array $Y$ such that\n- If lane $i$ holds $x_i$ with $65 \\le x_i \\le 90$, then the output lane holds $y_i = x_i + 32$.\n- Otherwise, the output lane holds $y_i = x_i$.\nProcess the input in groups of $w$ lanes to emulate SIMD, and correctly handle any tail elements when $n$ is not a multiple of $w$.\n\nThe following test suite must be hard-coded into your program:\n- Test case $1$: $w=8$, $X=[72,101,108,108,111,44,32,83,73,77,68,33]$.\n- Test case $2$: $w=4$, $X=[65,66,67,88,89,90]$.\n- Test case $3$: $w=4$, $X=[]$ (empty).\n- Test case $4$: $w=8$, $X=[64,65,66,90,91]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a comma-separated list of integers enclosed in square brackets. For example, the output format must be exactly like\n$[[y^{(1)}_0,y^{(1)}_1,\\dots],[y^{(2)}_0,y^{(2)}_1,\\dots],[\\dots],[\\dots]]$\nwith no spaces inserted anywhere.\n\nThe required outputs are lists of integers (ASCII codes). No physical units are involved, and all angles or percentages are irrelevant to this task. Ensure scientific realism by treating only values in the ASCII range and preserving non-uppercase inputs.\n\nYour program must be a complete, runnable C23 program that performs the computation described above and prints the single-line aggregated output for the test suite in the exact format specified.",
            "solution": "The problem requires the design and implementation of an algorithm to convert uppercase ASCII characters in a byte array to their lowercase counterparts, emulating Single Instruction, Multiple Data (SIMD) processing.\n\nThe problem can be formally stated as follows. Given an input array $X = [x_0, x_1, \\dots, x_{n-1}]$ of $n$ unsigned bytes representing ASCII codes, and a vector width $w$, we are to produce an output array $Y = [y_0, y_1, \\dots, y_{n-1}]$. The transformation rule for each element, or lane, $i$ is defined as:\n$$\ny_i = \\begin{cases} x_i + 32 & \\text{if } 65 \\le x_i \\le 90 \\\\ x_i & \\text{otherwise} \\end{cases}\n$$\nThe condition $65 \\le x_i \\le 90$ corresponds to the ASCII codes for the uppercase English letters 'A' through 'Z'. The addition of the offset $32$ correctly converts an uppercase character code to its lowercase equivalent.\n\nA core requirement is to perform this conditional operation without using explicit programmatic branching (e.g., `if-else` statements) on the data values, which mirrors how vector processors operate. This is achieved by defining a mask. For each lane $i$, we can compute a predicate mask bit, $m_i$, which evaluates to $1$ if the condition is met and $0$ otherwise. The logical condition for an uppercase character is the conjunction $(x_i \\ge 65) \\land (x_i \\le 90)$. In C and similar languages, the result of this boolean expression is directly convertible to an integer, yielding $m_i \\in \\{0, 1\\}$.\n\nUsing this mask bit $m_i$, the transformation rule can be rewritten as a single, branchless arithmetic expression:\n$$\ny_i = x_i + m_i \\times 32\n$$\nIf $x_i$ is an uppercase letter, $m_i=1$, and the expression becomes $y_i = x_i + 32$. If $x_i$ is not an uppercase letter, $m_i=0$, and the expression becomes $y_i = x_i + 0$, which is simply $y_i = x_i$. This formulation is ideal for SIMD execution, where the same arithmetic operations (multiplication and addition) are applied across all data lanes, with the mask providing the per-lane data-dependent control.\n\nThe algorithm must emulate SIMD processing by operating on the input array $X$ in contiguous groups of $w$ lanes. The processing of the array of length $n$ therefore proceeds in two stages:\n1.  **Vectorized Processing**: The algorithm iterates over the full-sized vectors. The number of such vectors is $N_{vec} = \\lfloor n/w \\rfloor$. The loop processes elements from index $0$ to $N_{vec} \\times w - 1$. Within each vector, the branchless transformation $y_i = x_i + ((x_i \\ge 65) \\land (x_i \\le 90)) \\times 32$ is applied to each of the $w$ lanes.\n2.  **Tail Processing**: If $n$ is not an exact multiple of $w$, there will be $n \\pmod w$ elements remaining at the end of the array. These elements, from index $N_{vec} \\times w$ to $n-1$, are processed individually using the same scalar branchless transformation.\n\nThis two-stage approach ensures that all elements are processed correctly while adhering to the specified SIMD-emulation model. Special cases, such as an empty input array ($n=0$) or an array shorter than the vector width ($n < w$), are naturally handled. In the case of $n=0$, no processing occurs. In the case of $n < w$, the vectorized processing loop does not execute ($N_{vec}=0$), and all elements are handled by the tail processing logic.",
            "answer": "```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n// #include <complex.h>\n// #include <threads.h>\n// #include <stdatomic.h>\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    int w;\n    const unsigned char* X;\n    int n;\n} TestCase;\n\n// Processes the input array X and stores the result in Y, emulating SIMD.\nvoid to_lowercase_simd_emulated(unsigned char* Y, const unsigned char* X, int n, int w) {\n    if (n == 0) {\n        return;\n    }\n    // A robust check for w, although test cases have w > 0.\n    if (w <= 0) {\n        w = 1;\n    }\n\n    int num_full_vectors = n / w;\n    int tail_start_index = num_full_vectors * w;\n\n    // 1. Process full vectors of width 'w'\n    for (int i = 0; i < tail_start_index; ++i) {\n        // Create a mask: 1 if uppercase, 0 otherwise.\n        unsigned char is_uppercase = (X[i] >= 65) && (X[i] <= 90);\n        // Apply transformation without branching.\n        Y[i] = X[i] + 32 * is_uppercase;\n    }\n\n    // 2. Process the remaining tail elements\n    for (int i = tail_start_index; i < n; ++i) {\n        unsigned char is_uppercase = (X[i] >= 65) && (X[i] <= 90);\n        Y[i] = X[i] + 32 * is_uppercase;\n    }\n}\n\nint main(void) {\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        {8, (const unsigned char[]){72,101,108,108,111,44,32,83,73,77,68,33}, 12},\n        {4, (const unsigned char[]){65,66,67,88,89,90}, 6},\n        {4, (const unsigned char[]){}, 0},\n        {8, (const unsigned char[]){64,65,66,90,91}, 5}\n    };\n\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    unsigned char* results[num_cases];\n\n    // Calculate the result for each test case.\n    for (int i = 0; i < num_cases; ++i) {\n        int n = test_cases[i].n;\n        if (n > 0) {\n            results[i] = malloc(n * sizeof(unsigned char));\n            if (results[i] == NULL) {\n                // Handle memory allocation failure\n                for(int j = 0; j < i; ++j) {\n                    free(results[j]);\n                }\n                return EXIT_FAILURE;\n            }\n            to_lowercase_simd_emulated(results[i], test_cases[i].X, n, test_cases[i].w);\n        } else {\n            results[i] = NULL; // Sentinel for empty arrays\n        }\n    }\n\n    // Print the results in the EXACT required format.\n    printf(\"[\");\n    for (int i = 0; i < num_cases; ++i) {\n        printf(\"[\");\n        int n = test_cases[i].n;\n        if (n > 0) {\n            for (int j = 0; j < n; ++j) {\n                printf(\"%d\", results[i][j]);\n                if (j < n - 1) {\n                    printf(\",\");\n                }\n            }\n        }\n        printf(\"]\");\n        if (i < num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\\n\");\n\n    // Free allocated memory.\n    for (int i = 0; i < num_cases; ++i) {\n        if (results[i] != NULL) {\n            free(results[i]);\n        }\n    }\n\n    return EXIT_SUCCESS;\n}\n```"
        },
        {
            "introduction": "Writing SIMD logic is the first step; understanding its performance is the key to optimization. This exercise guides you through building a performance model to analyze a vectorized operation, helping you identify whether your code is limited by instruction latency or hardware throughput. You will discover how a software technique like loop unrolling can hide latency and unlock the full potential of the processor's parallel execution units.",
            "id": "3677549",
            "problem": "A Single Instruction, Multiple Data (SIMD) implementation of the scaled vector addition operation (SAXPY) updates elements according to $y_i = \\alpha x_i + y_i$, where $\\alpha$ is a scalar and $x_i, y_i$ are single-precision floating-point elements. Consider a processor core that executes this kernel in a steady-state loop over a very large array length $N$ (assume $N$ is a multiple of the SIMD vector width). The following machine characteristics hold:\n\n- The SIMD vector width is $W = 8$ single-precision elements per vector register.\n- The load unit can retire at most $R_{L} = 2$ vector loads per cycle.\n- The store unit can retire at most $R_{S} = 1$ vector store per cycle.\n- The arithmetic unit can issue at most $R_{F} = 2$ fused multiply-add (FMA) instructions per cycle.\n- The latency of a vector FMA is $L_{F} = 4$ cycles from issue to the point where its result can be used in a dependent instruction.\n- The vector register file has $R_{\\mathrm{tot}} = 16$ architectural vector registers. One vector register is reserved to hold the broadcasted scalar $\\alpha$ for the duration of the loop. Each unrolled, independent SAXPY update chain requires $r_{\\mathrm{chain}} = 3$ live vector registers (for the loaded slice of $x$, the loaded slice of $y$, and the computed result until it is stored).\n\nAssume the following:\n\n- All data are in the first-level data cache and bandwidth from cache to registers is not a bottleneck beyond the stated load/store throughputs.\n- The front end is not a bottleneck; instruction fetch/decode/rename can sustain the stated throughputs.\n- The scalar $\\alpha$ is already broadcast into a vector register; do not account separately for its broadcast cost.\n- The loop is software-unrolled by a factor $u \\in \\mathbb{N}$ to expose $u$ independent chains, with perfect scheduling across units.\n- Ignore loop overheads, alignment effects, and assume no address-generation limits beyond the given rates.\n\nTasks:\n\n1. Starting from the definitions of throughput (operations completed per cycle), latency (cycles from issue to result availability), and the work per vector update of SAXPY, derive an analytic expression for the steady-state cycles per vector, $C_{\\mathrm{vec}}(u)$, as a function of the unroll factor $u$, the throughputs $R_{L}, R_{S}, R_{F}$, and the FMA latency $L_{F}$. Then derive the cycles per element, $C_{\\mathrm{elem}}(u)$, in terms of $C_{\\mathrm{vec}}(u)$ and the vector width $W$.\n\n2. Using the register-file constraint, determine the maximum admissible unroll, $u_{\\max}$, as a function of $R_{\\mathrm{tot}}$ and $r_{\\mathrm{chain}}$ given that one register is reserved for $\\alpha$.\n\n3. Using the concrete parameter values given above, determine the smallest unroll factor $u^{\\star}$ that minimizes $C_{\\mathrm{elem}}(u)$ subject to the resource constraint $u \\leq u_{\\max}$. Provide only the value of $u^{\\star}$ as your final answer.",
            "solution": "The Single Instruction, Multiple Data (SIMD) SAXPY update of one vector of width $W$ elements performs the following per-vector work:\n\n- Loads: $2$ vector loads (one for $x$, one for $y$).\n- Arithmetic: $1$ vector fused multiply-add (FMA) that computes $\\alpha x + y$.\n- Stores: $1$ vector store (to write back the updated $y$).\n\nBy definition, a throughput $R$ given in operations per cycle implies that performing $k$ such operations in steady state requires at least $k / R$ cycles if nothing else is a bottleneck and if the operations are fully overlapped within that functional class. For separate functional classes that can operate concurrently (load unit, store unit, arithmetic unit), the steady-state cycles per vector is governed by the slowest of the concurrently active pipelines, i.e., the maximum of the cycles implied by each pipeline.\n\nHowever, arithmetic operations can also be latency limited when they form a dependency chain. The definition of latency $L_{F}$ means that if one repeatedly issues dependent FMAs on the same data chain, the sustained rate is at most one FMA every $L_{F}$ cycles for that chain. Exposing instruction-level parallelism via unrolling to $u$ independent chains allows interleaving up to $u$ FMAs across cycles, so the effective FMA issue rate becomes the minimum of the front-end/ports throughput $R_{F}$ and the latency-limited rate $u / L_{F}$. Therefore, the effective FMA operations per cycle is\n$$\n\\text{FMA\\_rate}(u) = \\min\\left(R_{F}, \\frac{u}{L_{F}}\\right),\n$$\nso the cycles per vector required by the arithmetic unit to retire one FMA is\n$$\nC_{F}(u) = \\frac{1}{\\text{FMA\\_rate}(u)} = \\max\\left(\\frac{1}{R_{F}}, \\frac{L_{F}}{u}\\right).\n$$\n\nThe load and store pipelines have no inter-chain dependencies by assumption and thus are purely throughput bound. For one SAXPY vector update, the loads require $2$ vector load operations and the stores require $1$ vector store operation. Hence, the minimal cycles per vector imposed by each memory pipeline are\n$$\nC_{L} = \\frac{2}{R_{L}}, \\qquad C_{S} = \\frac{1}{R_{S}}.\n$$\n\nBecause the load, store, and arithmetic pipelines operate concurrently in steady state, the cycles per vector, $C_{\\mathrm{vec}}(u)$, must be at least the maximum of these three time contributions:\n$$\nC_{\\mathrm{vec}}(u) = \\max\\left(C_{L},\\, C_{S},\\, C_{F}(u)\\right) = \\max\\left(\\frac{2}{R_{L}},\\, \\frac{1}{R_{S}},\\, \\max\\left(\\frac{1}{R_{F}}, \\frac{L_{F}}{u}\\right)\\right).\n$$\nSince $\\max(a,b,\\max(c,d)) = \\max(a,b,c,d)$, we can also write\n$$\nC_{\\mathrm{vec}}(u) = \\max\\left(\\frac{2}{R_{L}},\\, \\frac{1}{R_{S}},\\, \\frac{1}{R_{F}},\\, \\frac{L_{F}}{u}\\right).\n$$\n\nEach vector update covers $W$ elements, so the cycles per element is\n$$\nC_{\\mathrm{elem}}(u) = \\frac{C_{\\mathrm{vec}}(u)}{W} = \\frac{1}{W}\\,\\max\\left(\\frac{2}{R_{L}},\\, \\frac{1}{R_{S}},\\, \\frac{1}{R_{F}},\\, \\frac{L_{F}}{u}\\right).\n$$\n\nNext, the register-file constraint limits the number of simultaneously live, independent chains that can be maintained. One register is reserved for $\\alpha$, leaving $R_{\\mathrm{tot}} - 1$ registers available for live state across unrolled chains. Each chain requires $r_{\\mathrm{chain}}$ registers. Therefore, the maximum admissible unroll is\n$$\nu_{\\max} = \\left\\lfloor \\frac{R_{\\mathrm{tot}} - 1}{r_{\\mathrm{chain}}} \\right\\rfloor.\n$$\n\nWe now instantiate the given parameter values:\n- $W = 8$,\n- $R_{L} = 2$,\n- $R_{S} = 1$,\n- $R_{F} = 2$,\n- $L_{F} = 4$,\n- $R_{\\mathrm{tot}} = 16$,\n- $r_{\\mathrm{chain}} = 3$.\n\nCompute the per-pipeline steady-state cycle requirements that are independent of $u$:\n$$\nC_{L} = \\frac{2}{R_{L}} = \\frac{2}{2} = 1,\n\\qquad\nC_{S} = \\frac{1}{R_{S}} = \\frac{1}{1} = 1,\n\\qquad\n\\frac{1}{R_{F}} = \\frac{1}{2} = 0.5.\n$$\nTherefore, ignoring latency, the throughput-limited cycles per vector is\n$$\nC_{\\mathrm{vec}}^{(0)} = \\max\\left(C_{L}, C_{S}, \\frac{1}{R_{F}}\\right) = \\max\\left(1, 1, 0.5\\right) = 1.\n$$\nThe latency-aware arithmetic contribution is\n$$\nC_{F}(u) = \\max\\left(\\frac{1}{R_{F}}, \\frac{L_{F}}{u}\\right) = \\max\\left(0.5, \\frac{4}{u}\\right).\n$$\nHence the overall cycles per vector as a function of $u$ is\n$$\nC_{\\mathrm{vec}}(u) = \\max\\left(1, \\max\\left(0.5, \\frac{4}{u}\\right)\\right) = \\max\\left(1, \\frac{4}{u}\\right).\n$$\nThis shows that:\n- For $u \\leq 3$, we have $\\frac{4}{u} \\geq \\frac{4}{3} > 1$, so $C_{\\mathrm{vec}}(u) = \\frac{4}{u}$ and the kernel is latency limited.\n- For $u \\geq 4$, we have $\\frac{4}{u} \\leq 1$, so $C_{\\mathrm{vec}}(u) = 1$ and the kernel is throughput limited by loads/stores.\n\nThus, the smallest unroll that fully hides FMA latency to reach the throughput-limited regime is the smallest integer $u$ such that\n$$\n\\frac{L_{F}}{u} \\leq C_{\\mathrm{vec}}^{(0)} \\quad \\Longleftrightarrow \\quad u \\geq \\frac{L_{F}}{C_{\\mathrm{vec}}^{(0)}} = \\frac{4}{1} = 4,\n$$\nso $u \\geq 4$ suffices in the absence of resource constraints.\n\nNow apply the register-file constraint:\n$$\nu_{\\max} = \\left\\lfloor \\frac{R_{\\mathrm{tot}} - 1}{r_{\\mathrm{chain}}} \\right\\rfloor = \\left\\lfloor \\frac{16 - 1}{3} \\right\\rfloor = \\left\\lfloor \\frac{15}{3} \\right\\rfloor = 5.\n$$\nBecause $u_{\\max} = 5 \\geq 4$, the resource constraint does not prevent choosing $u = 4$. The best unroll factor that minimizes $C_{\\mathrm{elem}}(u)$ while using the fewest resources is therefore\n$$\nu^{\\star} = 4.\n$$\n(For completeness, note that at $u^{\\star}$ the cycles per element is $C_{\\mathrm{elem}}(u^{\\star}) = \\frac{1}{W} = \\frac{1}{8}$, but only $u^{\\star}$ is requested as the final answer.)",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "A powerful SIMD engine can easily be starved for data, and memory access patterns are often the true performance bottleneck. This practice explores the critical concept of memory alignment, a frequent source of performance degradation in vectorized code. By analyzing a stencil operation with misaligned data, you will quantify the steep cost of unaligned memory accesses and understand why data layout is paramount for high performance.",
            "id": "3677516",
            "problem": "A Single Instruction, Multiple Data (SIMD) vectorized one-dimensional three-point stencil computes, for interior indices $i$, the update $y[i] \\leftarrow \\alpha \\cdot x[i-1] + \\beta \\cdot x[i] + \\gamma \\cdot x[i+1]$ on single-precision data. The vector unit operates on $w$ elements per instruction with a vector size of $B$ bytes, where each element is $4$ bytes, so that $B = 32$ and $w = 8$. The implementation uses a naive vectorized loop body that, per iteration, performs three vector loads (for the left, center, and right input neighborhoods) and one vector store (for the output). The output array $y$ is $B$-byte aligned. The input array $x$ has a base address with an unaligned byte offset $\\delta$ relative to $B$-byte alignment, with $\\delta = 4$. Ignore loop prologue/epilogue and boundary handling by assuming a pre-trimmed interior region of $N$ elements with $N$ divisible by $w$; use $N = 65536$.\n\nThe microarchitectural model is as follows. The processor core issues memory operations in order with no overlap and no memory-level parallelism. An aligned vector load or store that starts at an address congruent to $0 \\pmod{B}$ accesses one $B$-byte region. An unaligned vector load is implemented as two aligned $B$-byte loads from adjacent $B$-byte regions plus a shuffle that costs $t_{\\mathrm{shuf}}$ cycles; the store is aligned in this problem and accesses one $B$-byte region. Each $B$-byte region access that hits in Level 1 (L1) cache costs $t_{\\mathrm{L1}}$ cycles; each $B$-byte region access that misses in L1 but hits in Level 2 (L2) cache costs $t_{\\mathrm{L2}}$ cycles. Take $t_{\\mathrm{L1}} = 4$, $t_{\\mathrm{L2}} = 12$, and $t_{\\mathrm{shuf}} = 1$. The arithmetic part of the stencil, using fused multiply-adds where applicable, is throughput-limited to $c_{\\mathrm{comp}}$ cycles per vector iteration with $c_{\\mathrm{comp}} = 2$.\n\nWork from first principles of SIMD alignment and cache access granularity to determine how the unaligned base offset $\\delta$ affects the number of $B$-byte region accesses in the three loads per iteration. Then, using the model above, derive the total cycle counts to process the $N$-element interior region in two scenarios: Scenario A, where all memory region accesses hit in L1; and Scenario B, where all memory region accesses miss in L1 but hit in L2. Finally, compute the slowdown factor $S$, defined as the ratio of the total cycles in Scenario B over Scenario A. Provide $S$ as an exact rational number with no units. Do not round.",
            "solution": "The core of the problem is to determine the cycle cost of a single iteration of the vectorized stencil loop and then use this to compare the two specified scenarios.\n\nThe loop processes $N=65536$ elements using a vector width of $w=8$ elements. The total number of iterations is $N_{\\text{iter}} = \\frac{N}{w} = \\frac{65536}{8} = 8192$.\n\nLet us analyze the memory accesses for a single iteration, say iteration $k$, which processes output elements from index $i = k \\cdot w$ to $i = k \\cdot w + w - 1$. The stencil $y[i] \\leftarrow \\alpha \\cdot x[i-1] + \\beta \\cdot x[i] + \\gamma \\cdot x[i+1]$ is vectorized. This requires loading three vectors from the input array $x$ and storing one vector to the output array $y$.\n\nThe element size is $s = 4$ bytes. The vector size is $B = 32$ bytes.\nLet the base address of an array `arr` be denoted by $\\text{addr(arr[0])}$. The byte address of element `arr[j]` is $\\text{addr(arr[0])} + j \\cdot s$. An access is $B$-byte aligned if its starting address is a multiple of $B$.\n\n1.  **Output Store to `y`**:\n    The iteration stores results for `y[k \\cdot w]` through `y[k \\cdot w + w - 1]`. This is a single vector store operation starting at the address of `y[k \\cdot w]`.\n    The array `y` is $B$-byte aligned, so $\\text{addr(y[0])} \\pmod B = 0$.\n    The address of the store is $\\text{addr(y[k \\cdot w])} = \\text{addr(y[0])} + (k \\cdot w) \\cdot s = \\text{addr(y[0])} + k \\cdot 8 \\cdot 4 = \\text{addr(y[0])} + 32k$.\n    The alignment is checked by:\n    $$ \\text{addr(y[k \\cdot w])} \\pmod{32} = (\\text{addr(y[0])} + 32k) \\pmod{32} = 0 $$\n    This is an **aligned** vector store. It accesses one $B$-byte region.\n\n2.  **Input Loads from `x`**:\n    The array `x` has a base address with an offset $\\delta=4$, so $\\text{addr(x[0])} \\pmod B = 4$.\n    The address of an element `x[j]` is $\\text{addr(x[j])} = \\text{addr(x[0])} + j \\cdot s$. Its alignment is:\n    $$ \\text{addr(x[j])} \\pmod{32} = (\\text{addr(x[0])} + 4j) \\pmod{32} = (4 + 4j) \\pmod{32} $$\n    Three vector loads are performed per iteration:\n    \n    a. **Center Load**: This load fetches `x[k \\cdot w], \\dots, x[k \\cdot w + w - 1]` for the $\\beta \\cdot x[i]$ term. It starts at `x[k \\cdot w]`.\n    The start address alignment is:\n    $$ \\text{addr(x[k \\cdot w])} \\pmod{32} = (4 + 4 \\cdot k \\cdot w) \\pmod{32} = (4 + 4 \\cdot 8k) \\pmod{32} = (4 + 32k) \\pmod{32} = 4 $$\n    Since $4 \\neq 0$, this is an **unaligned** load. It requires two $B$-byte region accesses and one shuffle operation.\n\n    b. **Left Load**: This load fetches `x[k \\cdot w - 1], \\dots, x[k \\cdot w + w - 2]` for the $\\alpha \\cdot x[i-1]$ term. It starts at `x[k \\cdot w - 1]`.\n    The start address alignment is:\n    $$ \\text{addr(x[k \\cdot w - 1])} \\pmod{32} = (4 + 4 \\cdot (k \\cdot w - 1)) \\pmod{32} = (4 + 4 \\cdot (8k - 1)) \\pmod{32} = (4 + 32k - 4) \\pmod{32} = 0 $$\n    This is an **aligned** load. It accesses one $B$-byte region.\n\n    c. **Right Load**: This load fetches `x[k \\cdot w + 1], \\dots, x[k \\cdot w + w]` for the $\\gamma \\cdot x[i+1]$ term. It starts at `x[k \\cdot w + 1]`.\n    The start address alignment is:\n    $$ \\text{addr(x[k \\cdot w + 1])} \\pmod{32} = (4 + 4 \\cdot (k \\cdot w + 1)) \\pmod{32} = (4 + 4 \\cdot (8k + 1)) \\pmod{32} = (4 + 32k + 4) \\pmod{32} = 8 $$\n    Since $8 \\neq 0$, this is an **unaligned** load. It requires two $B$-byte region accesses and one shuffle operation.\n\n**Total Cost Per Iteration**:\nBased on the analysis above, we can sum the resources required for one vector iteration:\n- Total $B$-byte region accesses:\n    - Left Load (aligned): $1$\n    - Center Load (unaligned): $2$\n    - Right Load (unaligned): $2$\n    - Store (aligned): $1$\n    - Total accesses per iteration: $N_{\\text{access}} = 1 + 2 + 2 + 1 = 6$.\n- Total shuffle operations:\n    - Left Load: $0$\n    - Center Load: $1$\n    - Right Load: $1$\n    - Store: $0$\n    - Total shuffles per iteration: $N_{\\text{shuf}} = 1 + 1 = 2$.\n\nThe total cycle cost per iteration, $T_{\\text{iter}}$, is the sum of memory access costs and computation cost. The memory operations are sequential. Let $t_{\\text{region}}$ be the cost of one region access.\n$$ T_{\\text{iter}} = N_{\\text{access}} \\cdot t_{\\text{region}} + N_{\\text{shuf}} \\cdot t_{\\text{shuf}} + c_{\\text{comp}} $$\n$$ T_{\\text{iter}} = 6 \\cdot t_{\\text{region}} + 2 \\cdot t_{\\text{shuf}} + c_{\\text{comp}} $$\n\nNow we can calculate the cost per iteration for each scenario.\n\n**Scenario A: All L1 Hits**\nIn this scenario, $t_{\\text{region}} = t_{\\mathrm{L1}} = 4$ cycles.\nThe cost per iteration, $T_A$, is:\n$$ T_A = (6 \\cdot 4) + (2 \\cdot 1) + 2 = 24 + 2 + 2 = 28 \\text{ cycles} $$\n\n**Scenario B: All L1 Misses, L2 Hits**\nIn this scenario, $t_{\\text{region}} = t_{\\mathrm{L2}} = 12$ cycles.\nThe cost per iteration, $T_B$, is:\n$$ T_B = (6 \\cdot 12) + (2 \\cdot 1) + 2 = 72 + 2 + 2 = 76 \\text{ cycles} $$\n\n**Slowdown Factor S**\nThe total cycle count for a scenario is the cost per iteration multiplied by the number of iterations, $N_{\\text{iter}}$.\n- Total cycles for Scenario A: $C_A = N_{\\text{iter}} \\cdot T_A$.\n- Total cycles for Scenario B: $C_B = N_{\\text{iter}} \\cdot T_B$.\n\nThe slowdown factor $S$ is the ratio of these total cycle counts:\n$$ S = \\frac{C_B}{C_A} = \\frac{N_{\\text{iter}} \\cdot T_B}{N_{\\text{iter}} \\cdot T_A} = \\frac{T_B}{T_A} $$\nSubstituting the calculated values:\n$$ S = \\frac{76}{28} $$\nThis is an exact rational number as requested. We can simplify the fraction by dividing the numerator and denominator by their greatest common divisor, which is $4$.\n$$ S = \\frac{76 \\div 4}{28 \\div 4} = \\frac{19}{7} $$\nThis is the final slowdown factor.",
            "answer": "$$\n\\boxed{\\frac{19}{7}}\n$$"
        }
    ]
}