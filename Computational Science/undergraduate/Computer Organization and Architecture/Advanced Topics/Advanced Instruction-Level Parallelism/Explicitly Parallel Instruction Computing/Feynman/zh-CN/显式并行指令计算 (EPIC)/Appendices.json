{
    "hands_on_practices": [
        {
            "introduction": "在理想情况下，VLIW（超长指令字）指令包中的每个槽位都应填满有用的指令。然而在现实中，指令流的统计特性和固定的硬件模板会导致槽位浪费（即插入 NOP 指令）。本练习  旨在通过一个概率模型来量化这种效率损失，为您提供一种分析处理器性能的基本工具，并帮助您理解指令级并行性的理论上限。",
            "id": "3640780",
            "problem": "考虑一台显式并行指令计算（Explicitly Parallel Instruction Computing, EPIC）机器，其超长指令字（Very Long Instruction Word, VLIW）束的宽度为 $3$，每个束内为每种功能单元类别（内存（M）、算术（A）和分支（B））都恰好设有一个槽位。模板强制要求，在单个周期内发出的单个束中，每种类型的指令最多只能放置一条。假设指令流处于稳态，其中每条指令的类别是独立同分布的，其类型概率为 $(\\mu_{M}, \\mu_{A}, \\mu_{B})$，其中 $\\mu_{M} + \\mu_{A} + \\mu_{B} = 1$ 且 $\\mu_{M}, \\mu_{A}, \\mu_{B} \\in [0,1]$。\n\n编译器按如下方式执行有序的贪心打包：当开始一个新的束时，它会按程序顺序扫描指令流，当且仅当当前束中该指令类别的槽位仍为空时，才将遇到的指令放入当前束中；一旦遇到一条指令，其类别在当前束中的槽位已被占用，则立即关闭并发出当前束，并以该指令开始一个新的束。当所有三个槽位都被填满时，该束也会被立即关闭。\n\n假设除了结构模板之外，没有数据或控制依赖关系限制指令的放置，并且所有指令类别在上述概率意义上是独立的。请仅使用基本的概率和期望定律，推导出以下两项的封闭形式解析表达式（作为 $\\mu_{M}$、$\\mu_{A}$ 和 $\\mu_{B}$ 的函数）：\n- 每个发出的束中已利用槽位的期望数量，以及\n- 每个发出的束中被浪费槽位的期望数量。\n\n请将您的最终结果表示为一个 $1 \\times 2$ 的行矩阵 $\\bigl[\\,U \\;\\; W\\,\\bigr]$，其中 $U$ 是每个束中已利用槽位的期望数量，$W$ 是每个束中被浪费槽位的期望数量。无需进行数值代入，也无需四舍五入。请用 $\\mu_{M}$、$\\mu_{A}$ 和 $\\mu_{B}$ 表示您的最简封闭形式答案。",
            "solution": "用户希望我解决一个与计算机体系结构相关的概率问题。\n\n**1. 问题验证**\n\n首先，我将验证问题陈述。\n\n*   **步骤 1：提取已知条件**\n    *   机器：显式并行指令计算（EPIC），使用超长指令字（VLIW）束。\n    *   束宽度：$3$ 个槽位。\n    *   槽位类别：内存（M）、算术（A）、分支（B）。每类一个槽位。\n    *   指令流：稳态、独立同分布（i.i.d.）的指令。\n    *   指令类别概率：$(\\mu_{M}, \\mu_{A}, \\mu_{B})$，其中 $\\mu_{M} + \\mu_{A} + \\mu_{B} = 1$ 且 $\\mu_{M}, \\mu_{A}, \\mu_{B} \\in [0,1]$。\n    *   编译器打包算法：有序、贪心。\n    *   放置规则：如果指令类别的槽位为空，则将指令放入当前束中。\n    *   终止规则 1（冲突）：如果指令类别的槽位已被占用，则关闭并发出当前束。新的束以这条冲突的指令开始。\n    *   终止规则 2（已满）：如果所有三个槽位都被填满，则关闭并发出该束。\n    *   假设：无数据或控制依赖。指令类别在概率上独立。\n    *   目标：推导 $U$（每个束中已利用槽位的期望数量）和 $W$（每个束中被浪费槽位的期望数量）的表达式。\n\n*   **步骤 2：使用已知条件进行验证**\n    *   **科学性**：该问题是计算机体系结构性能分析中一个明确定义的练习，使用了一个标准的 VLIW/EPIC 处理器简化模型。使用概率论来建模指令流是一种常见且有效的方法。\n    *   **适定性**：该问题为打包过程提供了一套完整的规则和一个完整的概率模型。需要计算的量（期望值）定义明确，可以导出一个唯一的解。\n    *   **客观性**：问题陈述使用了来自计算机体系结构和概率论的精确、客观的术语。\n    *   **结论**：该问题没有科学缺陷、歧义或矛盾。这是一个有效、可解的问题。\n\n*   **步骤 3：判断与行动**\n    *   **判断**：问题有效。\n    *   **行动**：开始求解。\n\n**2. 解题推导**\n\n问题要求计算每个 VLIW 束中已利用槽位的期望数量 $U$ 和被浪费槽位的期望数量 $W$。每个束的固定宽度为 $3$ 个槽位。因此，对于任何给定的束，已利用槽位数加上被浪费槽位数总是等于 $3$。根据期望的线性性质，这个关系对它们的期望值也成立：$U + W = 3$。我们的主要目标是推导出 $U$。\n\n设 $N$ 为一个已完成的束中已利用槽位（指令）数量的随机变量。根据问题的规则，$N$ 的取值范围为 $\\{1, 2, 3\\}$。已利用槽位的期望数量为 $U = E[N]$。\n\n对于非负整数值随机变量的期望，有一个很有用的恒等式：$E[N] = \\sum_{k=1}^{\\infty} P(N \\ge k)$。由于束的最大尺寸为 $3$，这个和可以截断为：\n$$U = E[N] = P(N \\ge 1) + P(N \\ge 2) + P(N \\ge 3)$$\n\n我们现在将根据贪心打包过程计算这些概率。设 $T_i$ 表示按程序顺序排列的指令流中第 $i$ 条指令的类别（类型）。这些类型是独立同分布的，其概率为 $P(T_i=M) = \\mu_M$，$P(T_i=A) = \\mu_A$ 和 $P(T_i=B) = \\mu_B$。\n\n*   **计算 $P(N \\ge 1)$：**\n    打包过程始于取第一条可用指令并将其放入一个空的束中。这总是可行的。因此，每个束至少包含一条指令。\n    $$P(N \\ge 1) = 1$$\n\n*   **计算 $P(N \\ge 2)$：**\n    一个束将包含至少两条指令，当且仅当指令流中的第二条指令 $T_2$ 与第一条指令 $T_1$ 不冲突。如果它们的类别相同，则发生冲突。因此，我们需要 $T_2 \\neq T_1$。\n    $$P(N \\ge 2) = P(T_2 \\neq T_1) = 1 - P(T_2 = T_1)$$\n    事件 $T_2 = T_1$ 可以根据具体类别进行划分。使用全概率公式以及 $T_1$ 和 $T_2$ 的独立性：\n    $$P(T_2 = T_1) = P(T_1=M, T_2=M) + P(T_1=A, T_2=A) + P(T_1=B, T_2=B)$$\n    $$P(T_2 = T_1) = P(T_1=M)P(T_2=M) + P(T_1=A)P(T_2=A) + P(T_1=B)P(T_2=B)$$\n    $$P(T_2 = T_1) = \\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2}$$\n    因此，一个束中至少有两条指令的概率是：\n    $$P(N \\ge 2) = 1 - (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2})$$\n\n*   **计算 $P(N \\ge 3)$：**\n    一个束将包含至少三条指令，当且仅当头两条指令的类别不同（$T_2 \\neq T_1$），并且第三条指令的类别也与前两条都不同（$T_3 \\notin \\{T_1, T_2\\}$）。如果满足此条件，则第三条指令被放入，此时束已满（包含 M、A、B 每类指令各一条）。由于一个已满的束会立即关闭，所以 $N \\ge 3$ 的条件与 $N=3$ 的条件是相同的。\n    当指令类型序列 $(T_1, T_2, T_3)$ 是 $(M, A, B)$ 的一个排列时，事件 $N=3$ 发生。这样的排列共有 $3! = 6$ 种。由于独立性，一个特定排列（例如 $(M, A, B)$）的概率是 $\\mu_{M}\\mu_{A}\\mu_{B}$。对所有 $6$ 种排列求和：\n    $$P(N \\ge 3) = P(N=3) = \\mu_{M}\\mu_{A}\\mu_{B} + \\mu_{M}\\mu_{B}\\mu_{A} + \\mu_{A}\\mu_{M}\\mu_{B} + \\mu_{A}\\mu_{B}\\mu_{M} + \\mu_{B}\\mu_{M}\\mu_{A} + \\mu_{B}\\mu_{A}\\mu_{M}$$\n    $$P(N \\ge 3) = 6\\mu_{M}\\mu_{A}\\mu_{B}$$\n\n*   **计算 $U = E[N]$：**\n    我们现在可以将这些概率相加，求出已利用槽位的期望数量。\n    $$U = P(N \\ge 1) + P(N \\ge 2) + P(N \\ge 3)$$\n    $$U = 1 + \\left(1 - (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2})\\right) + 6\\mu_{M}\\mu_{A}\\mu_{B}$$\n    合并各项，得到 $U$ 的最终表达式：\n    $$U = 2 - (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2}) + 6\\mu_{M}\\mu_{A}\\mu_{B}$$\n\n*   **计算 $W$：**\n    被浪费槽位的期望数量 $W$ 是总槽位数 $3$ 减去已利用槽位的期望数量。\n    $$W = 3 - U$$\n    $$W = 3 - \\left(2 - (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2}) + 6\\mu_{M}\\mu_{A}\\mu_{B}\\right)$$\n    $$W = 3 - 2 + (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2}) - 6\\mu_{M}\\mu_{A}\\mu_{B}$$\n    $$W = 1 + \\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2} - 6\\mu_{M}\\mu_{A}\\mu_{B}$$\n\n推导出的 $U$ 和 $W$ 的表达式即为所求的、以 $\\mu_{M}$、$\\mu_{A}$ 和 $\\mu_{B}$ 为变量的封闭形式解析函数。",
            "answer": "$$\\boxed{\\begin{pmatrix} 2 - (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2}) + 6\\mu_{M}\\mu_{A}\\mu_{B}  1 + \\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2} - 6\\mu_{M}\\mu_{A}\\mu_{B} \\end{pmatrix}}$$"
        },
        {
            "introduction": "现在，让我们从统计分析转向编译器的具体任务。为 EPIC/VLIW 处理器编写编译器需要解决一个复杂的难题：如何在遵守数据依赖和处理器严格模板规则的同时，将指令安排到指令包中以最大化并行性。本练习  将让您扮演编译器的角色，挑战您为一段代码找到最优调度方案，从而揭示依赖关系与硬件限制之间的相互作用。",
            "id": "3640835",
            "problem": "一个显式并行指令计算（Explicitly Parallel Instruction Computing, EPIC）处理器每个周期发出固定宽度的指令包，每个指令包恰好包含 $3$ 条指令，并使用模板来限制哪些功能单元类型可以一起出现。一个指令包模板按顺序指定了三个槽的类型，并且只有以下模板可用：\n- $\\mathsf{MMI}$，\n- $\\mathsf{MII}$，\n- $\\mathsf{MIF}$，\n- $\\mathsf{FII}$，\n- $\\mathsf{MIB}$。\n\n在这里，$\\mathsf{M}$ 表示内存操作（加载或存储），$\\mathsf{I}$ 表示整数算术或比较，$\\mathsf{F}$ 表示浮点操作，$\\mathsf{B}$ 表示分支。如果所选模板中的某个槽类型无法由该类型的就绪指令填充，则该槽必须被一个该类型的空操作（表示为 $\\mathsf{NOP}$）占用，该空操作仍会消耗该槽。\n\n一个指令包内的所有指令被假定在同一个停止组（stop group）中；因此，任何写后读（read-after-write）依赖都强制消费者指令必须被调度在其生产者指令之后的一个严格更晚的指令包中。只要保留数据和控制依赖关系，允许跨越原始程序顺序进行重排序。\n\n考虑以下包含 $8$ 条指令的直线型代码片段，及其类型和依赖关系：\n- $\\text{L}_{1}$: $\\mathsf{M}$ 加载 $r_{1} \\leftarrow [a]$。\n- $\\text{L}_{2}$: $\\mathsf{M}$ 加载 $r_{2} \\leftarrow [b]$。\n- $\\text{A}_{1}$: $\\mathsf{I}$ 加法 $r_{3} \\leftarrow r_{1} + r_{5}$，依赖于 $\\text{L}_{1}$。\n- $\\text{A}_{2}$: $\\mathsf{I}$ 加法 $r_{4} \\leftarrow r_{2} + r_{6}$，依赖于 $\\text{L}_{2}$。\n- $\\text{S}_{1}$: $\\mathsf{M}$ 存储 $[c] \\leftarrow r_{3}$，依赖于 $\\text{A}_{1}$。\n- $\\text{F}_{1}$: $\\mathsf{F}$ 乘法 $f_{1} \\leftarrow f_{2} \\times f_{3}$，与所有其他指令无关。\n- $\\text{C}_{1}$: $\\mathsf{I}$ 比较 $p_{1} \\leftarrow r_{4}, r_{7}$，依赖于 $\\text{A}_{2}$。\n- $\\text{B}_{1}$: $\\mathsf{B}$ 基于 $p_{1}$ 分支，依赖于 $\\text{C}_{1}$。\n\n任务：\n- 考虑到模板集 $\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$、3槽指令包宽度以及无包内依赖规则，确定在保持语义的同时调度所有 $8$ 条指令所需的最小指令包数量。您可以根据需要对指令进行重排序，但每个指令包必须使用一个允许的模板，并在必要时插入适合类型的 $\\mathsf{NOP}$。\n- 在您的推理中，明确展示模板限制如何阻止完美打包直观的三元组（例如两个加载操作和一个浮点操作），并提出一个有效的、逐指令包的指令排序方案以达到最小值。\n\n仅报告最小指令包数量作为您的最终答案。无需四舍五入。",
            "solution": "该问题要求在一个具有特定架构约束的显式并行指令计算（EPIC）处理器上，调度给定的 8 条指令序列所需的最小指令包数量。\n\n首先，我们必须严格验证问题陈述。\n问题提供了一套完整的已知条件：一个具有 3 槽指令包的 EPIC 处理器模型，一个包含五个指令包模板的固定集合（$\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$），一个包含 8 条指令及其类型（$\\mathsf{M}, \\mathsf{I}, \\mathsf{F}, \\mathsf{B}$）的列表，以及它们之间的数据依赖关系。关于写后读（RAW）依赖（无包内依赖）的调度规则已明确说明。该问题在科学上基于计算机体系结构和编译器优化的原理，提出了一个适定（well-posed）的目标，并且没有歧义或矛盾。因此，该问题是有效的。\n\n为了解决这个问题，我们首先分析依赖关系以确定理论上的最小指令包数量。这些依赖关系可以表示为一个有向无环图（DAG）：\n- $\\text{L}_{1} \\rightarrow \\text{A}_{1} \\rightarrow \\text{S}_{1}$\n- $\\text{L}_{2} \\rightarrow \\text{A}_{2} \\rightarrow \\text{C}_{1} \\rightarrow \\text{B}_{1}$\n- $\\text{F}_{1}$ (独立)\n\n指令及其类型如下：\n- $\\text{L}_{1}$: $\\mathsf{M}$\n- $\\text{L}_{2}$: $\\mathsf{M}$\n- $\\text{A}_{1}$: $\\mathsf{I}$\n- $\\text{A}_{2}$: $\\mathsf{I}$\n- $\\text{S}_{1}$: $\\mathsf{M}$\n- $\\text{F}_{1}$: $\\mathsf{F}$\n- $\\text{C}_{1}$: $\\mathsf{I}$\n- $\\text{B}_{1}$: $\\mathsf{B}$\n\n“无包内依赖”规则指出，如果指令 $\\text{J}$ 依赖于指令 $\\text{I}$，那么 $\\text{J}$ 必须被调度在包含 $\\text{I}$ 的指令包之后的一个严格更晚的指令包中。依赖关系图中最长路径的长度，即关键路径（critical path），因此确立了所需指令包数量的下限。\n\n在这种情况下，最长的依赖链是 $\\text{L}_{2} \\rightarrow \\text{A}_{2} \\rightarrow \\text{C}_{1} \\rightarrow \\text{B}_{1}$。该路径长度为 $4$（包含 $4$ 条指令）。这意味着仅调度这四条指令就需要至少 $4$ 个独立的指令包：一个用于 $\\text{L}_{2}$，随后一个用于 $\\text{A}_{2}$，第三个用于 $\\text{C}_{1}$，第四个用于 $\\text{B}_{1}$。因此，最小指令包数量至少为 $4$。基于指令总数的理论最小值 $\\lceil 8/3 \\rceil = 3$，被这个依赖约束所取代。\n\n我们现在的任务是确定，在给定可用模板 $\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$ 的情况下，一个恰好包含 $4$ 个指令包的调度是否可以实现。我们将尝试构建这样一个调度。\n\n**指令包 1:**\n准备好被调度的指令集合（即没有未满足依赖的指令）是 $\\text{L}_{1}(\\mathsf{M})$、$\\text{L}_{2}(\\mathsf{M})$ 和 $\\text{F}_{1}(\\mathsf{F})$。一个最优的启发式方法是尽早调度来自最长依赖链的指令。在这里，$\\text{L}_{1}$ 和 $\\text{L}_{2}$ 都开启了依赖链。\n\n问题要求展示模板限制如何约束调度。一个直观的方法是将这三个就绪指令 $\\{\\text{L}_{1}, \\text{L}_{2}, \\text{F}_{1}\\}$ 一起调度。这将需要一个 $\\mathsf{MMF}$ 类型（或其排列）的指令包模板。然而，检查可用模板 $\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$，可以发现不存在这样的模板。模板集无法在单个指令包中容纳两个内存操作和一个浮点操作。这是一个关键的限制。\n\n为了在后续周期中最大化并行执行，我们应该尽早执行两个加载指令 $\\text{L}_{1}$ 和 $\\text{L}_{2}$。这会使其依赖指令 $\\text{A}_{1}$ 和 $\\text{A}_{2}$ 更早地就绪。$\\mathsf{MMI}$ 模板允许调度两个内存操作。第三个槽用于 $\\mathsf{I}$ 型指令，但由于没有就绪的 $\\mathsf{I}$ 型指令，因此无法填充。因此，我们必须使用一个空操作指令，$\\text{NOP}_{\\mathsf{I}}$。\n- **指令包 1:** $\\{\\text{L}_{1}(\\mathsf{M}), \\text{L}_{2}(\\mathsf{M}), \\text{NOP}_{\\mathsf{I}}\\}$，使用 $\\mathsf{MMI}$ 模板。\n\n**指令包 2:**\n指令包 1 执行后，指令 $\\text{L}_{1}$ 和 $\\text{L}_{2}$ 完成。新的就绪指令集是：\n- $\\text{A}_{1}(\\mathsf{I})$，依赖于 $\\text{L}_{1}$。\n- $\\text{A}_{2}(\\mathsf{I})$，依赖于 $\\text{L}_{2}$。\n- $\\text{F}_{1}(\\mathsf{F})$，从一开始就已就绪。\n我们有一个 $\\mathsf{F}$ 型和两个 $\\mathsf{I}$ 型的就绪指令。$\\mathsf{FII}$ 模板与这个集合完美匹配。\n- **指令包 2:** $\\{\\text{F}_{1}(\\mathsf{F}), \\text{A}_{1}(\\mathsf{I}), \\text{A}_{2}(\\mathsf{I})\\}$，使用 $\\mathsf{FII}$ 模板。由于它们之间没有依赖关系，包内的顺序无关紧要。\n\n**指令包 3:**\n指令包 2 执行后，指令 $\\text{A}_{1}$、$\\text{A}_{2}$ 和 $\\text{F}_{1}$ 完成。新的就绪指令集是：\n- $\\text{S}_{1}(\\mathsf{M})$，依赖于 $\\text{A}_{1}$。\n- $\\text{C}_{1}(\\mathsf{I})$，依赖于 $\\text{A}_{2}$。\n我们有一个 $\\mathsf{M}$ 型和一个 $\\mathsf{I}$ 型的就绪指令。指令 $\\text{B}_{1}$ 尚未就绪，因为它依赖于 $\\text{C}_{1}$。我们必须选择一个能容纳 $\\text{S}_{1}$ 和 $\\text{C}_{1}$ 的模板。有几个模板可以配合 $\\text{NOP}$ 工作，例如 $\\mathsf{MII}$ 或 $\\mathsf{MIF}$。我们使用 $\\mathsf{MII}$。\n- **指令包 3:** $\\{\\text{S}_{1}(\\mathsf{M}), \\text{C}_{1}(\\mathsf{I}), \\text{NOP}_{\\mathsf{I}}\\}$，使用 $\\mathsf{MII}$ 模板。\n\n**指令包 4:**\n指令包 3 执行后，指令 $\\text{S}_{1}$ 和 $\\text{C}_{1}$ 完成。只剩下一条指令：\n- $\\text{B}_{1}(\\mathsf{B})$，依赖于 $\\text{C}_{1}$（现已完成）。\n唯一支持分支（$\\mathsf{B}$）指令的模板是 $\\mathsf{MIB}$。由于没有其他就绪指令，另外两个槽必须用 NOP 填充。\n- **指令包 4:** $\\{\\text{NOP}_{\\mathsf{M}}, \\text{NOP}_{\\mathsf{I}}, \\text{B}_{1}(\\mathsf{B})\\}$，使用 $\\mathsf{MIB}$ 模板。\n\n所有 $8$ 条指令都已在 $4$ 个指令包中被调度。\n最终的调度方案是：\n1.  $\\{\\text{L}_{1}, \\text{L}_{2}, \\text{NOP}_{\\mathsf{I}}\\}$\n2.  $\\{\\text{F}_{1}, \\text{A}_{1}, \\text{A}_{2}\\}$\n3.  $\\{\\text{S}_{1}, \\text{C}_{1}, \\text{NOP}_{\\mathsf{I}}\\}$\n4.  $\\{\\text{NOP}_{\\mathsf{M}}, \\text{NOP}_{\\mathsf{I}}, \\text{B}_{1}\\}$\n\n既然我们因关键路径长度确定了理论最小值为 $4$ 个指令包，并且我们已成功构建了一个有效的 $4$ 指令包调度方案，我们可以得出结论，最小指令包数量为 $4$。",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "本练习探讨了 EPIC 架构中一个关键而微妙的方面：推测执行与谓词执行的结合。如果一条推测执行的指令（其后可能因谓词为假而被取消）触发了像缺页这样的异常，会发生什么？这个思想实验  揭示了为何简单的处理方式会违反体系结构规约，并阐明了为何像“延迟异常”这样的机制对于构建正确且高性能的 EPIC 处理器至关重要。",
            "id": "3640849",
            "problem": "考虑显式并行指令计算（EPIC）中谓词执行的基础语义：一个谓词指令由一个布尔谓词 $p \\in \\{0,1\\}$ 守护，架构约定要求当 $p=1$ 时，该指令对其架构状态产生正常影响，而当 $p=0$ 时，该指令不产生任何形式的架构影响，包括禁止引发本应发生的同步异常（如页面错误）。同时，回顾传统 von Neumann 机模型中内存异常的基本规则：引用无效或未映射地址的加载指令会在使用点引发一个同步异常，并阻止后续的架构状态更新提交。\n\nEPIC 微架构可以并行发射谓词指令以利用静态指令级并行性，这可能在 $p$ 的最终值已知之前进行，前提是它遵守架构的谓词执行约定。一个维护此约定的常见机制是延迟异常：一个推测性加载会产生一个携带延迟异常标签的“毒化”值（例如，Intel Itanium 系列中的“Not a Thing” (NaT) 位），并且只有当程序控制逻辑上在一个真谓词下需要该值时（通过一个显式检查指令验证），异常才会被引发。如果没有这种延迟机制，即使指令的谓词为假，机器也可能在无效访问时立即引发异常。\n\n设计以下实验，以明确谓词执行和数据相关加载之间的相互作用。假设内存系统具有以下属性：\n- 所有严格小于 $4096$ 的虚拟地址都是无效的，如果被普通加载指令解引用，会引发页面错误。\n- 内存内容满足 $\\text{mem}[8192] = 12288$ 和 $\\text{mem}[12288] = 7$。\n\n考虑一个静态调度的 EPIC 指令包，其中包含2个谓词加载指令且没有分支：\n- 加载指令 $L_1$：如果 $p$ 为真，则计算 $r_1 \\leftarrow \\text{mem}[r_2]$。\n- 加载指令 $L_2$：如果 $p$ 为真，则计算 $r_3 \\leftarrow \\text{mem}[r_1]$。\n指令包中的所有其他指令都是相互独立且无副作用的。微架构在 $p$ 为提交而最终解析之前，在同一个周期并行发射 $L_1$ 和 $L_2$。该指令包在两种测试条件下执行：\n- 测试条件 $\\mathsf{T\\_A}$：在发射时，$p=1$ 且 $r_2=8192$。\n- 测试条件 $\\mathsf{T\\_B}$：在发射时，$p=0$ 且 $r_2=0$。\n\n在两种架构策略下分析该实验：\n- 策略 $\\mathsf{ND}$ (不延迟, No Deferral)：所有加载都是普通加载，任何异常在内存系统检测到无效访问时立即引发。\n- 策略 $\\mathsf{DE}$ (延迟异常, Deferred Exceptions)：加载指令 $L_1$ 和 $L_2$ 是推测性的，如果它们的地址会导致错误，则各自产生一个带有延迟异常标签的毒化值；异常只有在后续由一个在 $p=1$ 下执行的显式检查指令引发，并且毒化值会通过相关依赖的使用进行传播。\n\n以下哪个陈述正确地描述了实验的结果？\n\nA. 在策略 $\\mathsf{ND}$ 和测试条件 $\\mathsf{T\\_B}$ 下，即使 $p=0$，机器也可能因为 $L_1$ 引发同步异常，这违反了架构的谓词执行约定。\n\nB. 在策略 $\\mathsf{DE}$ 下，测试条件 $\\mathsf{T\\_B}$ 不会引发异常，因为当 $p=0$ 时，来自 $L_1$ 的毒化值（以及任何传播到 $L_2$ 的毒化值）在架构上从未被需要；而测试条件 $\\mathsf{T\\_A}$ 产生 $r_3=7$。\n\nC. 从 $L_1$ 到 $L_2$ 的数据相关性使得延迟异常机制不足以应对；在测试条件 $\\mathsf{T\\_B}$ 中，$L_2$ 将总是引发异常，因为地址计算与谓词 $p$ 无关。\n\nD. 一个推测性发射谓词加载指令的正确 EPIC 实现必须确保谓词求值先于地址转换；因此，在所有情况下，即使没有延迟异常机制，对于 $p=0$ 也不会引发异常。",
            "solution": "该问题陈述是计算机体系结构领域一个定义明确的思想实验，具体涉及显式并行指令计算（EPIC）这一主题。所有提供的信息都具有科学依据、内部一致，并且足以进行严谨的分析。诸如谓词执行、延迟异常、推测执行和页面错误等术语的用法均符合其在该领域的标准含义。因此，该问题是有效的。\n\n我们将针对每种架构策略和测试条件的组合，分析实验的结果。该指令包包含两个数据相关的加载指令：\n- $L_1$：如果 $p$ 为真，则计算 $r_1 \\leftarrow \\text{mem}[r_2]$。\n- $L_2$：如果 $p$ 为真，则计算 $r_3 \\leftarrow \\text{mem}[r_1]$。\n\n指令 $L_1$ 和 $L_2$ 在谓词 $p$ 解析之前，于同一个周期并行发射。这意味着推测执行。从 $L_1$ 到 $L_2$ 的数据相关性意味着 $L_2$ 的内存访问执行必须等待 $L_1$ 的结果。我们假设存在一个从 $L_1$ 的执行阶段到 $L_2$ 的地址计算阶段的标准前向通路。\n\n内存系统具有以下已定义的属性：\n- 任何地址 $A  4096$ 都是无效的，并会导致页面错误。\n- $\\text{mem}[8192] = 12288$。\n- $\\text{mem}[12288] = 7$。\n\n### 对策略 $\\mathsf{ND}$ (不延迟) 的分析\n\n在此策略下，任何异常都在内存系统检测到时立即引发。\n\n**测试条件 $\\mathsf{T\\_A}$：** $p=1, r_2=8192$。\n1.  $L_1$ 被推测执行。它将其地址计算为 $r_2$ 的值，即 $8192$。\n2.  地址 $8192$ 是有效的（即 $\\ge 4096$）。内存系统读取 $\\text{mem}[8192]$，其值为 $12288$。\n3.  $L_2$ 被推测执行。它需要 $L_1$ 的结果来计算其地址。值 $12288$ 从 $L_1$ 前向传递过来。\n4.  $L_2$ 将其地址计算为 $12288$。这是一个有效地址。内存系统读取 $\\text{mem}[12288]$，其值为 $7$。\n5.  谓词 $p$ 解析为 $1$。两条指令都在正确的路径上。\n6.  结果提交到架构状态：$r_1$ 更新为 $12288$，$r_3$ 更新为 $7$。没有异常发生。\n\n**测试条件 $\\mathsf{T\\_B}$：** $p=0, r_2=0$。\n1.  $L_1$ 被推测执行。它将其地址计算为 $r_2$ 的值，即 $0$。\n2.  地址 $0$ 是无效的（即 $ 4096$）。\n3.  在策略 $\\mathsf{ND}$ 下，内存系统立即引发一个同步异常（页面错误）。\n4.  此异常发生在 $L_1$ 的推测执行期间，在谓词 $p$ 被解析并用于取消该指令之前。机器暂停或将控制权转移给异常处理程序。\n5.  谓词执行的架构约定规定，对于 $p=0$，指令必须没有架构影响，这包括不引发异常。通过在一个本应被作废的指令上产生错误，该微架构违反了架构约定。\n\n### 对策略 $\\mathsf{DE}$ (延迟异常) 的分析\n\n在此策略下，推测执行期间的无效内存访问不会立即引发异常。取而代之的是，它会为结果寄存器产生一个“毒化”值（例如，在结果寄存器上设置一个“Not-a-Thing”或 NaT 位）。这个毒化值会通过相关指令传播。只有当一条指令试图在真谓词下使用该毒化值时，异常才会被引发。\n\n**测试条件 $\\mathsf{T\\_A}$：** $p=1, r_2=8192$。\n执行过程与 $\\mathsf{ND}$ 情况相同。\n1.  $L_1$ 访问有效地址 $8192$ 并读取值 $12288$。没有产生毒化值。\n2.  $L_2$ 访问有效地址 $12288$ 并读取值 $7$。没有产生毒化值。\n3.  谓词 $p$ 为 $1$。结果不是毒化值，因此任何对延迟异常的检查都会通过。结果 $r_1 \\leftarrow 12288$ 和 $r_3 \\leftarrow 7$ 被提交。$r_3$ 中的最终值为 $7$。\n\n**测试条件 $\\mathsf{T\\_B}$：** $p=0, r_2=0$。\n1.  $L_1$ 被推测执行。它将其地址计算为 $0$。\n2.  地址 $0$ 是无效的。微架构不会产生错误，而是为目标寄存器 $r_1$ 生成一个毒化值。\n3.  $L_2$ 被推测执行。它需要 $L_1$ 的结果作为其地址。策略规定毒化值会传播。当 $L_2$ 试图使用 $r_1$ 的毒化值时，其自身的目标为 $r_3$ 的结果也被标记为毒化。$L_2$ 的内存访问可能被完全抑制。\n4.  谓词 $p$ 解析为 $0$。\n5.  $p=0$ 的架构约定指示谓词指令不起作用。$r_1$ 和 $r_3$ 的毒化结果被丢弃。架构寄存器不被更新。\n6.  延迟的异常永远不会被引发，因为毒化值在真谓词下从未被“架构上需要”。引发异常的条件（在 $p=1$ 下的显式检查）未被满足。因此，没有异常发生。\n\n### 选项评估\n\n**A. 在策略 $\\mathsf{ND}$ 和测试条件 $\\mathsf{T\\_B}$ 下，即使 $p=0$，机器也可能因为 $L_1$ 引发同步异常，这违反了架构的谓词执行约定。**\n我们对策略 $\\mathsf{ND}$ 和条件 $\\mathsf{T\\_B}$ 的分析表明，$L_1$ 试图访问无效地址 $0$。由于异常不被延迟，页面错误会立即被引发。这发生在推测执行期间，在假谓词 ($p=0$) 能取消该指令之前。这直接违反了 EPIC 架构约定，该约定要求谓词为假的指令不能有任何架构级副作用。\n**结论：正确。**\n\n**B. 在策略 $\\mathsf{DE}$ 下，测试条件 $\\mathsf{T\\_B}$ 不会引发异常，因为当 $p=0$ 时，来自 $L_1$ 的毒化值（以及任何传播到 $L_2$ 的毒化值）在架构上从未被需要；而测试条件 $\\mathsf{T\\_A}$ 产生 $r_3=7$。**\n这个陈述有两个部分。\n1.  对于 $\\mathsf{DE}$ 和 $\\mathsf{T\\_B}$ ($p=0$, $r_2=0$)：我们的分析表明，$L_1$ 产生一个毒化值并传播到 $L_2$。因为 $p=0$，谓词指令被取消，它们的结果（包括毒化标签）被丢弃，延迟的异常也永远不会被触发。所以，没有异常被引发。这部分是正确的。\n2.  对于 $\\mathsf{DE}$ 和 $\\mathsf{T\\_A}$ ($p=1$, $r_2=8192$)：我们的分析表明，$L_1$ 加载 $\\text{mem}[8192]=12288$，然后 $L_2$ 加载 $\\text{mem}[12288]=7$。由于 $p=1$，结果 $r_3=7$ 被提交。这部分也是正确的。\n由于陈述的两部分都为真，所以整个陈述是正确的。\n**结论：正确。**\n\n**C. 从 $L_1$ 到 $L_2$ 的数据相关性使得延迟异常机制不足以应对；在测试条件 $\\mathsf{T\\_B}$ 中，$L_2$ 将总是引发异常，因为地址计算与谓词 $p$ 无关。**\n这个陈述声称延迟异常机制不足。我们对策略 $\\mathsf{DE}$ 和条件 $\\mathsf{T\\_B}$ 的分析证明了并非如此。毒化值的生成和传播机制，结合最终对谓词的检查，正确地处理了这种情况。异常*不会*被引发，因为 $p=0$。地址计算独立于谓词这一前提是推测执行存在风险的原因，但这恰恰是延迟异常机制旨在解决的问题。因此，异常将总是被引发的结论是错误的。\n**结论：不正确。**\n\n**D. 一个推测性发射谓词加载指令的正确 EPIC 实现必须确保谓词求值先于地址转换；因此，在所有情况下，即使没有延迟异常机制，对于 $p=0$ 也不会引发异常。**\n这个陈述提出了一种特定的、保守的实现策略，并将其作为正确性的强制要求（“必须确保”）。该策略涉及在内存访问前解析谓词，这确实可以防止在条件 $\\mathsf{T\\_B}$ 中发生错误。然而，这样做会引入一个控制相关，可能会严重限制指令级并行性，从而破坏 EPIC 理念的一个关键目标。问题将延迟异常描述为一种“常见机制”，用以在*允许*推测性加载在谓词已知前发射的同时，维护架构约定。延迟异常机制作为一种解决方案的存在证明了选项 D 中提出的策略并非构建正确实现的*唯一*方法。因此，“必须确保”的说法是错误的。\n**结论：不正确。**",
            "answer": "$$\\boxed{AB}$$"
        }
    ]
}