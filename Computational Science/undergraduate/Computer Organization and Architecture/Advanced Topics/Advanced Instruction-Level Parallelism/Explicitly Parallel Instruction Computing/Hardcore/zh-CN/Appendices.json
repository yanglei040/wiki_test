{
    "hands_on_practices": [
        {
            "introduction": "显式并行指令计算（EPIC）架构的性能在很大程度上取决于编译器将指令有效地调度到指令包中的能力。这个练习将您置于编译器的位置，挑战您在满足数据依赖性和固定的硬件模板限制的条件下，为一个代码片段找到最快的执行方案。通过解决这个具体的调度难题，您将亲身体验到在并行性和硬件资源约束之间进行权衡的优化过程。",
            "id": "3640835",
            "problem": "一台显式并行指令计算 (EPIC) 处理器每个周期发出宽度固定、恰好包含 $3$ 条指令的指令包，使用模板来限制哪些功能单元类型可以一起出现。一个指令包模板按顺序指定了三个槽位类型，并且只有以下模板可用：\n- $\\mathsf{MMI}$，\n- $\\mathsf{MII}$，\n- $\\mathsf{MIF}$，\n- $\\mathsf{FII}$，\n- $\\mathsf{MIB}$。\n\n这里，$\\mathsf{M}$ 表示内存操作（加载或存储），$\\mathsf{I}$ 表示整数算术或比较，$\\mathsf{F}$ 表示浮点操作，$\\mathsf{B}$ 表示分支。如果所选模板中的某个槽位类型无法由一条就绪的该类型指令填充，则该槽位必须被一个该类型的空操作（表示为 $\\mathsf{NOP}$）占据，该空操作仍然会消耗这个槽位。\n\n一个指令包内的所有指令被假定在同一个停止组中；因此，任何写后读依赖都会强制消费者指令被调度在严格晚于其生产者指令的指令包中。只要数据和控制依赖得以保持，允许跨越原始程序顺序进行重排序。\n\n考虑以下包含 $8$ 条指令的直线代码片段，及其类型和依赖关系：\n- $\\text{L}_{1}$: $\\mathsf{M}$ 加载 $r_{1} \\leftarrow [a]$。\n- $\\text{L}_{2}$: $\\mathsf{M}$ 加载 $r_{2} \\leftarrow [b]$。\n- $\\text{A}_{1}$: $\\mathsf{I}$ 加法 $r_{3} \\leftarrow r_{1} + r_{5}$，依赖于 $\\text{L}_{1}$。\n- $\\text{A}_{2}$: $\\mathsf{I}$ 加法 $r_{4} \\leftarrow r_{2} + r_{6}$，依赖于 $\\text{L}_{2}$。\n- $\\text{S}_{1}$: $\\mathsf{M}$ 存储 $[c] \\leftarrow r_{3}$，依赖于 $\\text{A}_{1}$。\n- $\\text{F}_{1}$: $\\mathsf{F}$ 乘法 $f_{1} \\leftarrow f_{2} \\times f_{3}$，与其他所有指令无关。\n- $\\text{C}_{1}$: $\\mathsf{I}$ 比较 $p_{1} \\leftarrow r_{4}, r_{7}$，依赖于 $\\text{A}_{2}$。\n- $\\text{B}_{1}$: $\\mathsf{B}$ 基于 $p_{1}$ 的分支，依赖于 $\\text{C}_{1}$。\n\n任务：\n- 考虑到模板集 $\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$、$3$-槽位指令包宽度以及无指令包内依赖规则，确定在保持语义的同时，调度所有 $8$ 条指令所需的最少指令包数量。您可以根据需要重排序指令，但每个指令包必须使用一个允许的模板，并在必要时插入类型匹配的 $\\mathsf{NOP}$。\n- 在您的推理过程中，明确展示模板限制如何阻止完美填充直观的三元组（例如两个加载操作和一个浮点操作），并提出一个有效的、逐指令包的指令排序方案以达到最小值。\n\n仅报告最少的指令包数量作为您的最终答案。无需四舍五入。",
            "solution": "问题要求在一台具有特定架构约束的显式并行指令计算 (EPIC) 处理器上，调度给定的 8 条指令序列所需的最少指令包数量。\n\n首先，我们必须严格验证问题陈述。\n问题提供了一套完整的已知条件：一个具有 $3$-槽位指令包的 EPIC 处理器模型，一个包含五种模板的固定集合（$\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$），一个包含 $8$ 条指令及其类型（$\\mathsf{M}, \\mathsf{I}, \\mathsf{F}, \\mathsf{B}$）的列表，以及它们之间的数据依赖关系。关于写后读 (RAW) 依赖的调度规则（无指令包内依赖）被明确说明。该问题在科学上基于计算机体系结构和编译器优化的原理，提出了一个定义明确的目标，并且没有歧义或矛盾。因此，该问题是有效的。\n\n为了解决这个问题，我们首先分析依赖关系，以确定理论上的最小指令包数量。依赖关系可以表示为一个有向无环图 (DAG)：\n- $\\text{L}_{1} \\rightarrow \\text{A}_{1} \\rightarrow \\text{S}_{1}$\n- $\\text{L}_{2} \\rightarrow \\text{A}_{2} \\rightarrow \\text{C}_{1} \\rightarrow \\text{B}_{1}$\n- $\\text{F}_{1}$ (独立)\n\n指令及其类型如下：\n- $\\text{L}_{1}$: $\\mathsf{M}$\n- $\\text{L}_{2}$: $\\mathsf{M}$\n- $\\text{A}_{1}$: $\\mathsf{I}$\n- $\\text{A}_{2}$: $\\mathsf{I}$\n- $\\text{S}_{1}$: $\\mathsf{M}$\n- $\\text{F}_{1}$: $\\mathsf{F}$\n- $\\text{C}_{1}$: $\\mathsf{I}$\n- $\\text{B}_{1}$: $\\mathsf{B}$\n\n“无指令包内依赖”规则指出，如果指令 $\\text{J}$ 依赖于指令 $\\text{I}$，那么 $\\text{J}$ 必须被调度在严格晚于包含 $\\text{I}$ 的指令包中。因此，依赖关系图中最长路径的长度，即关键路径，确立了所需指令包数量的下界。\n\n在本例中，最长的依赖链是 $\\text{L}_{2} \\rightarrow \\text{A}_{2} \\rightarrow \\text{C}_{1} \\rightarrow \\text{B}_{1}$。这条路径的长度为 $4$（包含 $4$ 条指令）。这意味着仅调度这四条指令就需要至少 $4$ 个独立的指令包：一个用于 $\\text{L}_{2}$，其后的一个用于 $\\text{A}_{2}$，第三个用于 $\\text{C}_{1}$，第四个用于 $\\text{B}_{1}$。因此，最少指令包数量至少为 $4$。基于指令总数的理论最小值 $\\lceil 8/3 \\rceil = 3$，被这个依赖约束所取代。\n\n我们现在的任务是确定，在给定可用模板 $\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$ 的情况下，一个恰好包含 $4$ 个指令包的调度是否可以实现。我们将尝试构建这样一个调度。\n\n**指令包 1：**\n可以被调度（即没有未满足的依赖关系）的指令集合是 $\\text{L}_{1}(\\mathsf{M})$、$\\text{L}_{2}(\\mathsf{M})$ 和 $\\text{F}_{1}(\\mathsf{F})$。一种最优的启发式方法是尽早调度来自最长依赖链的指令。在这里，$\\text{L}_{1}$ 和 $\\text{L}_{2}$ 都开启了依赖链。\n\n问题要求展示模板限制如何约束调度。一个直观的方法是把三条就绪指令 $\\{\\text{L}_{1}, \\text{L}_{2}, \\text{F}_{1}\\}$ 调度在一起。这将需要一个类型为 $\\mathsf{MMF}$（或其排列）的指令包模板。然而，检查可用模板集 $\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$ 后发现，并不存在这样的模板。该模板集无法在单个指令包中容纳两个内存操作和一个浮点操作。这是一个关键的约束。\n\n为了在后续周期中最大化并行执行，我们应该尽早执行两个加载操作 $\\text{L}_{1}$ 和 $\\text{L}_{2}$。这使得它们的后续指令 $\\text{A}_{1}$ 和 $\\text{A}_{2}$ 能更快就绪。$\\mathsf{MMI}$ 模板允许调度两个内存操作。第三个用于 $\\mathsf{I}$ 类型指令的槽位无法被填充，因为没有 $\\mathsf{I}$ 类型的指令就绪。因此，我们必须使用一个空操作指令 $\\text{NOP}_{\\mathsf{I}}$。\n- **指令包 1：** $\\{\\text{L}_{1}(\\mathsf{M}), \\text{L}_{2}(\\mathsf{M}), \\text{NOP}_{\\mathsf{I}}\\}$，使用 $\\mathsf{MMI}$ 模板。\n\n**指令包 2：**\n在指令包 1 之后，指令 $\\text{L}_{1}$ 和 $\\text{L}_{2}$ 已完成。新的就绪指令集是：\n- $\\text{A}_{1}(\\mathsf{I})$，依赖于 $\\text{L}_{1}$。\n- $\\text{A}_{2}(\\mathsf{I})$，依赖于 $\\text{L}_{2}$。\n- $\\text{F}_{1}(\\mathsf{F})$，从一开始就已就绪。\n我们有一条 $\\mathsf{F}$ 类型和两条 $\\mathsf{I}$ 类型的就绪指令。$\\mathsf{FII}$ 模板与此集合完美匹配。\n- **指令包 2：** $\\{\\text{F}_{1}(\\mathsf{F}), \\text{A}_{1}(\\mathsf{I}), \\text{A}_{2}(\\mathsf{I})\\}$，使用 $\\mathsf{FII}$ 模板。由于它们之间没有依赖关系，指令包内的顺序无关紧要。\n\n**指令包 3：**\n在指令包 2 之后，指令 $\\text{A}_{1}$、$\\text{A}_{2}$ 和 $\\text{F}_{1}$ 已完成。新的就绪指令集是：\n- $\\text{S}_{1}(\\mathsf{M})$，依赖于 $\\text{A}_{1}$。\n- $\\text{C}_{1}(\\mathsf{I})$，依赖于 $\\text{A}_{2}$。\n我们有一条 $\\mathsf{M}$ 类型和一条 $\\mathsf{I}$ 类型的就绪指令。指令 $\\text{B}_{1}$ 尚未就绪，因为它依赖于 $\\text{C}_{1}$。我们必须选择一个能容纳 $\\text{S}_{1}$ 和 $\\text{C}_{1}$ 的模板。有几个模板可以通过使用 $\\text{NOP}$ 来实现，例如 $\\mathsf{MII}$ 或 $\\mathsf{MIF}$。我们使用 $\\mathsf{MII}$。\n- **指令包 3：** $\\{\\text{S}_{1}(\\mathsf{M}), \\text{C}_{1}(\\mathsf{I}), \\text{NOP}_{\\mathsf{I}}\\}$，使用 $\\mathsf{MII}$ 模板。\n\n**指令包 4：**\n在指令包 3 之后，指令 $\\text{S}_{1}$ 和 $\\text{C}_{1}$ 已完成。只剩下一条指令：\n- $\\text{B}_{1}(\\mathsf{B})$，依赖于 $\\text{C}_{1}$（现已完成）。\n唯一支持分支（$\\mathsf{B}$）指令的模板是 $\\mathsf{MIB}$。由于没有其他就绪指令，另外两个槽位必须用 NOP 填充。\n- **指令包 4：** $\\{\\text{NOP}_{\\mathsf{M}}, \\text{NOP}_{\\mathsf{I}}, \\text{B}_{1}(\\mathsf{B})\\}$，使用 $\\mathsf{MIB}$ 模板。\n\n所有 $8$ 条指令都已在 $4$ 个指令包中被调度。\n最终的调度方案如下：\n1.  $\\{\\text{L}_{1}, \\text{L}_{2}, \\text{NOP}_{\\mathsf{I}}\\}$\n2.  $\\{\\text{F}_{1}, \\text{A}_{1}, \\text{A}_{2}\\}$\n3.  $\\{\\text{S}_{1}, \\text{C}_{1}, \\text{NOP}_{\\mathsf{I}}\\}$\n4.  $\\{\\text{NOP}_{\\mathsf{M}}, \\text{NOP}_{\\mathsf{I}}, \\text{B}_{1}\\}$\n\n由于我们因关键路径长度确立了 $4$ 个指令包的理论最小值，并且我们成功地构建了一个有效的 4-指令包调度方案，因此我们可以得出结论，所需的最少指令包数量是 $4$。",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "在解决了单个代码块的调度之后，一个自然的问题是：从宏观上看，这种架构的效率如何？真实世界的程序是长指令流，其特性最好用统计模型来描述。本练习采用概率论的方法，通过分析一个简化的EPIC处理器在处理随机指令流时的行为，来量化其平均性能。这有助于我们理解指令混合特性如何影响指令槽的利用率和浪费率，从而揭示系统级的性能瓶颈。",
            "id": "3640780",
            "problem": "考虑一台显式并行指令计算（EPIC）机器，该机器发行宽度为 $3$ 的超长指令字（VLIW）指令包，每个功能单元类别恰好有一个槽位：内存 $(M)$、算术 $(A)$ 和分支 $(B)$。模板强制要求，在一个周期内发行的单个指令包中，每类指令最多只能放置一条。假设存在一个稳态指令流，其中每条指令的类别是独立同分布的，其类型概率为 $(\\mu_{M}, \\mu_{A}, \\mu_{B})$，其中 $\\mu_{M} + \\mu_{A} + \\mu_{B} = 1$ 且 $\\mu_{M}, \\mu_{A}, \\mu_{B} \\in [0,1]$。\n\n编译器按如下方式执行顺序的贪婪打包：当开始一个新的指令包时，它按程序顺序扫描指令流，当且仅当当前指令包中该指令类别的槽位仍然为空时，才将遇到的每条指令放入当前包中；当遇到一条指令，其类别在当前包中的槽位已被占用时，当前指令包立即关闭并发行，然后以该指令开始一个新的指令包。当所有三个槽位都被填满时，指令包也会立即关闭。\n\n假设除了结构模板外，没有数据或控制依赖关系限制指令的放置，并且所有指令类别在上述概率意义上是独立的。仅使用基本概率和期望定律，推导出以下两项的闭式解析表达式，作为 $\\mu_{M}$、$\\mu_{A}$ 和 $\\mu_{B}$ 的函数：\n- 每个发行的指令包中已用槽位的期望数量，以及\n- 每个发行的指令包中浪费槽位的期望数量。\n\n请将您的最终结果表示为一个 $1 \\times 2$ 的行矩阵 $\\bigl[\\,U \\;\\; W\\,\\bigr]$，其中 $U$ 是每个指令包中已用槽位的期望数量，而 $W$ 是每个指令包中浪费槽位的期望数量。不需要进行数值代入，也无需四舍五入。请用 $\\mu_{M}$、$\\mu_{A}$ 和 $\\mu_{B}$ 以最简闭式形式表示您的答案。",
            "solution": "用户希望我解决一个与计算机体系结构相关的概率问题。\n\n**1. 问题验证**\n\n首先，我将验证问题陈述。\n\n*   **步骤 1：提取已知条件**\n    *   机器：显式并行指令计算（EPIC），使用超长指令字（VLIW）指令包。\n    *   指令包宽度：$3$ 个槽位。\n    *   槽位类别：内存 $(M)$、算术 $(A)$、分支 $(B)$。每类一个槽位。\n    *   指令流：稳态、独立同分布（i.i.d.）的指令。\n    *   指令类别概率：$(\\mu_{M}, \\mu_{A}, \\mu_{B})$，其中 $\\mu_{M} + \\mu_{A} + \\mu_{B} = 1$ 且 $\\mu_{M}, \\mu_{A}, \\mu_{B} \\in [0,1]$。\n    *   编译器打包算法：顺序、贪婪。\n    *   放置规则：如果指令的类别槽位为空，则将其放入当前指令包。\n    *   终止规则 1（冲突）：如果指令的类别槽位已被占用，则当前指令包关闭并发行。新的指令包以这条冲突的指令开始。\n    *   终止规则 2（满包）：如果所有三个槽位都被填满，则指令包关闭并发行。\n    *   假设：无数据或控制依赖。指令类别在概率上独立。\n    *   目标：推导 $U$（每个指令包中已用槽位的期望数量）和 $W$（每个指令包中浪费槽位的期望数量）的表达式。\n\n*   **步骤 2：使用提取的已知条件进行验证**\n    *   **科学依据：** 这是一个在计算机体系结构性能分析中定义明确的练习，使用了一个 VLIW/EPIC 处理器的标准简化模型。使用概率论来建模指令流是一种常见且有效的方法。\n    *   **适定性：** 问题为打包过程提供了一套完整的规则和一个完整的概率模型。待计算的量（期望值）定义明确，可以导出一个唯一的解。\n    *   **客观性：** 问题陈述使用了来自计算机体系结构和概率论的精确、客观的术语。\n    *   **结论：** 该问题没有科学缺陷、歧义或矛盾。这是一个有效且可解的问题。\n\n*   **步骤 3：判定与行动**\n    *   **判定：** 问题有效。\n    *   **行动：** 开始求解。\n\n**2. 解题推导**\n\n问题要求解每个 VLIW 指令包中已用槽位的期望数量 $U$ 和浪费槽位的期望数量 $W$。每个指令包的固定宽度为 $3$ 个槽位。因此，对于任何给定的指令包，已用槽位数加上浪费槽位数总是等于 $3$。根据期望的线性性质，这个关系对它们的期望值也成立：$U + W = 3$。我们的主要目标是推导出 $U$。\n\n设随机变量 $N$ 表示一个已完成指令包中已用槽位（指令）的数量。根据问题规则，$N$ 的取值范围为 $\\{1, 2, 3\\}$。已用槽位的期望数量为 $U = E[N]$。\n\n对于非负整数值随机变量的期望，有一个很有用的恒等式：$E[N] = \\sum_{k=1}^{\\infty} P(N \\ge k)$。由于指令包的最大大小为 $3$，这个和可以截断为：\n$$U = E[N] = P(N \\ge 1) + P(N \\ge 2) + P(N \\ge 3)$$\n\n我们现在将根据贪婪打包过程计算这些概率。设 $T_i$ 表示程序顺序流中第 $i$ 条指令的类别（类型）。这些类型是独立同分布的，其概率为 $P(T_i=M) = \\mu_M$，$P(T_i=A) = \\mu_A$ 和 $P(T_i=B) = \\mu_B$。\n\n*   **计算 $P(N \\ge 1)$：**\n    打包过程从取第一条可用指令并将其放入一个空指令包开始。这总是可能的。因此，每个指令包至少包含一条指令。\n    $$P(N \\ge 1) = 1$$\n\n*   **计算 $P(N \\ge 2)$：**\n    一个指令包将包含至少两条指令，当且仅当指令流中的第二条指令 $T_2$ 与第一条指令 $T_1$ 不冲突。如果它们的类别相同，就会发生冲突。因此，我们需要 $T_2 \\neq T_1$。\n    $$P(N \\ge 2) = P(T_2 \\neq T_1) = 1 - P(T_2 = T_1)$$\n    事件 $T_2 = T_1$ 可以根据具体类别进行划分。利用全概率公式以及 $T_1$ 和 $T_2$ 的独立性：\n    $$P(T_2 = T_1) = P(T_1=M, T_2=M) + P(T_1=A, T_2=A) + P(T_1=B, T_2=B)$$\n    $$P(T_2 = T_1) = P(T_1=M)P(T_2=M) + P(T_1=A)P(T_2=A) + P(T_1=B)P(T_2=B)$$\n    $$P(T_2 = T_1) = \\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2}$$\n    因此，至少有两条指令的概率是：\n    $$P(N \\ge 2) = 1 - (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2})$$\n\n*   **计算 $P(N \\ge 3)$：**\n    一个指令包将包含至少三条指令，当且仅当头两条指令的类别不同 ($T_2 \\neq T_1$)，且第三条指令的类别与前两条都不同 ($T_3 \\notin \\{T_1, T_2\\}$)。如果满足此条件，第三条指令被放入，指令包已满（包含 M、A、B 每类各一条指令）。由于满包会立即关闭，所以 $N \\ge 3$ 的条件与 $N=3$ 的条件相同。\n    事件 $N=3$ 发生，如果指令类型序列 $(T_1, T_2, T_3)$ 是 $(M, A, B)$ 的一个排列。共有 $3! = 6$ 种这样的排列。由于独立性，一种特定排列（例如 $(M, A, B)$）的概率是 $\\mu_{M}\\mu_{A}\\mu_{B}$。对所有 $6$ 种排列求和：\n    $$P(N \\ge 3) = P(N=3) = \\mu_{M}\\mu_{A}\\mu_{B} + \\mu_{M}\\mu_{B}\\mu_{A} + \\mu_{A}\\mu_{M}\\mu_{B} + \\mu_{A}\\mu_{B}\\mu_{M} + \\mu_{B}\\mu_{M}\\mu_{A} + \\mu_{B}\\mu_{A}\\mu_{M}$$\n    $$P(N \\ge 3) = 6\\mu_{M}\\mu_{A}\\mu_{B}$$\n\n*   **计算 $U = E[N]$：**\n    现在我们可以将这些概率相加，以求得已用槽位的期望数量。\n    $$U = P(N \\ge 1) + P(N \\ge 2) + P(N \\ge 3)$$\n    $$U = 1 + \\left(1 - (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2})\\right) + 6\\mu_{M}\\mu_{A}\\mu_{B}$$\n    合并各项，得到 $U$ 的最终表达式：\n    $$U = 2 - (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2}) + 6\\mu_{M}\\mu_{A}\\mu_{B}$$\n\n*   **计算 $W$：**\n    浪费槽位的期望数量 $W$ 等于总槽位数 $3$ 减去已用槽位的期望数量。\n    $$W = 3 - U$$\n    $$W = 3 - \\left(2 - (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2}) + 6\\mu_{M}\\mu_{A}\\mu_{B}\\right)$$\n    $$W = 3 - 2 + (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2}) - 6\\mu_{M}\\mu_{A}\\mu_{B}$$\n    $$W = 1 + \\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2} - 6\\mu_{M}\\mu_{A}\\mu_{B}$$\n\n推导出的 $U$ 和 $W$ 的表达式即为所求的、以 $\\mu_{M}$、$\\mu_{A}$ 和 $\\mu_{B}$ 为变量的闭式解析函数。",
            "answer": "$$\\boxed{\\begin{pmatrix} 2 - (\\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2}) + 6\\mu_{M}\\mu_{A}\\mu_{B}  1 + \\mu_{M}^{2} + \\mu_{A}^{2} + \\mu_{B}^{2} - 6\\mu_{M}\\mu_{A}\\mu_{B} \\end{pmatrix}}$$"
        },
        {
            "introduction": "EPIC架构通过广泛使用谓词执行（predication）和推测执行（speculation）来发掘指令级并行性。然而，这些强大功能的交互带来了微妙的挑战。这个思想实验探讨了一个关键的边缘案例：当一个被谓词保护的推测性加载指令遇到可能导致异常（如页错误）的情况时会发生什么。通过分析这个问题，您将理解为何需要像“延迟异常”（deferred exceptions）这样的复杂机制，以确保即使在积极的乱序推测执行下，架构的正确性也能得到保障。",
            "id": "3640849",
            "problem": "考虑显式并行指令计算（EPIC）中谓词执行的基础语义：一条谓词化指令由一个布尔谓词 $p \\in \\{0,1\\}$ 守护，架构约定要求当 $p=1$ 时，该指令对其架构状态产生通常的效果；而当 $p=0$ 时，该指令不产生任何类型的架构效果，包括禁止引发本应发生的同步异常（例如页面错误）。同时，回顾传统冯·诺依曼机模型中内存异常的基本规则：引用无效或未映射地址的加载指令会在使用点引发一个同步异常，并阻止后续的架构状态更新提交。\n\n一个 EPIC 微架构可以并行地发出谓词化指令以利用静态指令级并行性，这可能在 $p$ 的最终值已知之前发生，前提是它能维护架构的谓词执行约定。维护此约定的一种常见机制是延迟异常：一个推测性加载会产生一个携带延迟异常标签的“毒化”值（例如，Intel Itanium 家族中的“非事物”（Not a Thing, NaT）位），只有当程序的控制逻辑在一个为真的谓词下需要该值时（通过显式检查指令验证），异常才会在稍后被引发。如果没有这种延迟机制，机器可能会在无效访问时立即引发异常，即使该指令的谓词为假。\n\n设计以下实验，以明确谓词执行与数据依赖加载之间的交互作用。假设内存系统具有以下属性：\n- 所有严格小于 $4096$ 的虚拟地址都是无效的，如果被正常加载指令解引用，则会引发页面错误。\n- 内存内容满足 $\\text{mem}[8192] = 12288$ 和 $\\text{mem}[12288] = 7$。\n\n考虑一个静态调度的 EPIC 包，其中包含 2 条谓词化加载指令且没有分支：\n- 加载 $L_1$：如果 $p$ 为真，则计算 $r_1 \\leftarrow \\text{mem}[r_2]$。\n- 加载 $L_2$：如果 $p$ 为真，则计算 $r_3 \\leftarrow \\text{mem}[r_1]$。\n包中的所有其他指令都是独立的且无副作用。微架构在同一个周期内并行地发出 $L_1$ 和 $L_2$，此时 $p$ 尚未为提交而最终解析。该指令包在两种测试条件下执行：\n- 测试条件 $\\mathsf{T\\_A}$：在发出时，$p=1$ 且 $r_2=8192$。\n- 测试条件 $\\mathsf{T\\_B}$：在发出时，$p=0$ 且 $r_2=0$。\n\n在两种架构策略下分析该实验：\n- 策略 $\\mathsf{ND}$ (无延迟): 所有加载都是正常的，任何异常在内存系统检测到无效访问时立即引发。\n- 策略 $\\mathsf{DE}$ (延迟异常): 加载 $L_1$ 和 $L_2$ 是推测性的，如果它们的地址会导致错误，每个加载都会产生一个带有延迟异常标签的“毒化”值；异常仅在稍后由一个在 $p=1$ 条件下执行的显式检查引发，并且“毒化”状态会通过依赖性使用传播。\n\n以下哪些陈述正确地描述了实验的结果？\n\nA. 在策略 $\\mathsf{ND}$ 和测试条件 $\\mathsf{T\\_B}$ 下，即使 $p=0$，机器也可能因 $L_1$ 而引发同步异常，这违反了架构的谓词执行约定。\n\nB. 在策略 $\\mathsf{DE}$ 下，测试条件 $\\mathsf{T\\_B}$ 不会引发异常，因为当 $p=0$ 时，来自 $L_1$ 的“毒化”值（以及任何传播到 $L_2$ 的“毒化”状态）在架构上从未被需要；而测试条件 $\\mathsf{T\\_A}$ 产生 $r_3=7$。\n\nC. 从 $L_1$ 到 $L_2$ 的数据依赖使得延迟异常不足以应对；在测试条件 $\\mathsf{T\\_B}$ 下，$L_2$ 总会引发异常，因为地址计算与谓词 $p$ 无关。\n\nD. 一个正确推测性地发出谓词化加载的 EPIC 实现必须确保谓词求值先于地址转换；因此，在所有情况下，即使没有延迟异常，当 $p=0$ 时也不会引发异常。",
            "solution": "问题陈述是一个定义明确的计算机体系结构思想实验，具体涉及显式并行指令计算（EPIC）这一主题。所有提供的信息都具有科学依据、内部一致，并且足以进行严谨的分析。诸如谓词执行、延迟异常、推测执行和页面错误等术语均按照其在该领域的标准含义使用。因此，该问题是有效的。\n\n我们将针对架构策略和测试条件的每种组合，分析实验的结果。该指令包由两个数据依赖的加载指令组成：\n- $L_1$：如果 $p$ 为真，则计算 $r_1 \\leftarrow \\text{mem}[r_2]$。\n- $L_2$：如果 $p$ 为真，则计算 $r_3 \\leftarrow \\text{mem}[r_1]$。\n\n指令 $L_1$ 和 $L_2$ 在谓词 $p$ 解析之前，于同一个周期内并行发出。这意味着推测执行。从 $L_1$ 到 $L_2$ 的数据依赖意味着 $L_2$ 的内存访问执行必须等待 $L_1$ 的结果。我们假设存在一个从 $L_1$ 的执行阶段到 $L_2$ 的地址计算阶段的标准前向路径。\n\n内存系统具有以下已定义的属性：\n- 任何地址 $A  4096$ 都是无效的，并会导致页面错误。\n- $\\text{mem}[8192] = 12288$。\n- $\\text{mem}[12288] = 7$。\n\n### 策略 $\\mathsf{ND}$ (无延迟) 的分析\n\n在此策略下，任何异常在内存系统检测到时立即引发。\n\n**测试条件 $\\mathsf{T\\_A}$：** $p=1$， $r_2=8192$。\n1.  $L_1$被推测执行。它将其地址计算为 $r_2$ 的值，即 $8192$。\n2.  地址 $8192$ 是有效的（即 $\\ge 4096$）。内存系统读取 $\\text{mem}[8192]$，其值为 $12288$。\n3.  $L_2$被推测执行。它需要 $L_1$ 的结果来计算其地址。值 $12288$ 从 $L_1$ 前向传递过来。\n4.  $L_2$ 将其地址计算为 $12288$。这是一个有效的地址。内存系统读取 $\\text{mem}[12288]$，其值为 $7$。\n5.  谓词 $p$ 解析为 $1$。两条指令都在正确的路径上。\n6.  结果被提交到架构状态：$r_1$ 更新为 $12288$，$r_3$ 更新为 $7$。没有异常发生。\n\n**测试条件 $\\mathsf{T\\_B}$：** $p=0$， $r_2=0$。\n1.  $L_1$被推测执行。它将其地址计算为 $r_2$ 的值，即 $0$。\n2.  地址 $0$ 是无效的（即 $ 4096$）。\n3.  在策略 $\\mathsf{ND}$ 下，内存系统立即引发一个同步异常（页面错误）。\n4.  这个异常发生在 $L_1$ 的推测执行期间，在谓词 $p$ 被解析并用于取消该指令之前。机器停机或将控制权转移给异常处理程序。\n5.  谓词执行的架构约定规定，对于 $p=0$ 的情况，指令必须没有架构效果，这包括不引发异常。通过在一个本应被取消的指令上产生错误，微架构违反了架构约定。\n\n### 策略 $\\mathsf{DE}$ (延迟异常) 的分析\n\n在此策略下，推测执行期间的无效内存访问不会立即引发异常。相反，它会产生一个“毒化”值（例如，在结果寄存器上设置一个“非事物”（Not-a-Thing, NaT）位）。这种“毒化”状态会通过依赖指令传播。只有当一条指令试图在一个为真的谓词下使用该“毒化”值时，异常才会被引发。\n\n**测试条件 $\\mathsf{T\\_A}$：** $p=1$， $r_2=8192$。\n执行过程与 $\\mathsf{ND}$ 情况相同。\n1.  $L_1$ 访问有效地址 $8192$ 并读取值 $12288$。没有生成“毒化”状态。\n2.  $L_2$ 访问有效地址 $12288$ 并读取值 $7$。没有生成“毒化”状态。\n3.  谓词 $p$ 为 $1$。结果没有被“毒化”，因此任何对延迟异常的检查都会通过。结果 $r_1 \\leftarrow 12288$ 和 $r_3 \\leftarrow 7$ 被提交。$r_3$ 中的最终值为 $7$。\n\n**测试条件 $\\mathsf{T\\_B}$：** $p=0$， $r_2=0$。\n1.  $L_1$被推测执行。它将其地址计算为 $0$。\n2.  地址 $0$ 是无效的。微架构不会产生错误，而是为目标寄存器 $r_1$ 生成一个“毒化”值。\n3.  $L_2$被推测执行。它需要 $L_1$ 的结果作为其地址。策略规定“毒化”状态会传播。当 $L_2$ 试图使用 $r_1$ 的“毒化”值时，它自己的结果（目标为 $r_3$）也被标记为“毒化”。$L_2$ 的内存访问可能被完全抑制。\n4.  谓词 $p$ 解析为 $0$。\n5.  对于 $p=0$ 的架构约定要求谓词化指令无效。$r_1$ 和 $r_3$ 的“毒化”结果被丢弃。架构寄存器不被更新。\n6.  延迟异常永远不会被引发，因为“毒化”值从未在一个为真的谓词下被“架构上需要”。引发异常的条件（在 $p=1$ 下的显式检查）未被满足。因此，没有异常发生。\n\n### 选项评估\n\n**A. 在策略 $\\mathsf{ND}$ 和测试条件 $\\mathsf{T\\_B}$ 下，即使 $p=0$，机器也可能因 $L_1$ 而引发同步异常，这违反了架构的谓词执行约定。**\n我们对策略 $\\mathsf{ND}$ 在条件 $\\mathsf{T\\_B}$ 下的分析表明，$L_1$ 试图访问无效地址 $0$。由于异常不被延迟，页面错误会立即引发。这是在错误的谓词（$p=0$）能够使指令无效之前，推测性地发生的。这直接违反了 EPIC 架构约定，该约定要求谓词为假的指令不能有任何架构副作用。\n**结论：正确。**\n\n**B. 在策略 $\\mathsf{DE}$ 下，测试条件 $\\mathsf{T\\_B}$ 不会引发异常，因为当 $p=0$ 时，来自 $L_1$ 的“毒化”值（以及任何传播到 $L_2$ 的“毒化”状态）在架构上从未被需要；而测试条件 $\\mathsf{T\\_A}$ 产生 $r_3=7$。**\n这个陈述有两部分。\n1.  对于 $\\mathsf{DE}$ 和 $\\mathsf{T\\_B}$ ($p=0$, $r_2=0$)：我们的分析表明，$L_1$ 会生成一个“毒化”值并传播到 $L_2$。因为 $p=0$，谓词化指令被置为无效，其结果（包括“毒化”标签）被丢弃，延迟异常永远不会被触发。所以，没有异常被引发。这部分是正确的。\n2.  对于 $\\mathsf{DE}$ 和 $\\mathsf{T\\_A}$ ($p=1$, $r_2=8192$)：我们的分析表明，$L_1$ 加载 $\\text{mem}[8192]=12288$，然后 $L_2$ 加载 $\\text{mem}[12288]=7$。由于 $p=1$，结果 $r_3=7$ 被提交。这部分也是正确的。\n由于陈述的两个部分都为真，所以整个陈述是正确的。\n**结论：正确。**\n\n**C. 从 $L_1$ 到 $L_2$ 的数据依赖使得延迟异常不足以应对；在测试条件 $\\mathsf{T\\_B}$ 下，$L_2$ 总会引发异常，因为地址计算与谓词 $p$ 无关。**\n该陈述声称延迟异常机制是不充分的。我们对策略 $\\mathsf{DE}$ 在条件 $\\mathsf{T\\_B}$ 下的分析证明了并非如此。“毒化”生成和传播的机制，结合最终对谓词的检查，正确地处理了这种情况。异常*不会*被引发，因为 $p=0$。地址计算与谓词无关这个前提是推测执行之所以有风险的原因，但这恰恰是延迟异常旨在解决的问题。因此，异常总会被引发的结论是错误的。\n**结论：错误。**\n\n**D. 一个正确推测性地发出谓词化加载的 EPIC 实现必须确保谓词求值先于地址转换；因此，在所有情况下，即使没有延迟异常，当 $p=0$ 时也不会引发异常。**\n该陈述提出了一种特定的、保守的实现策略，并将其作为正确性的强制要求（“必须确保”）。该策略涉及在内存访问之前解析谓词，这确实可以防止在条件 $\\mathsf{T\\_B}$ 下的错误。然而，这样做会引入一个控制依赖，可能严重限制指令级并行性，从而破坏了 EPIC 理念的一个关键目标。问题将延迟异常描述为一种“常见机制”，用于在*允许*推测性加载在谓词已知之前发出的同时，维护架构约定。延迟异常机制作为一种解决方案的存在证明了选项 D 中提出的策略并不是构建正确实现的*唯一*方法。因此，“必须确保”的说法是错误的。\n**结论：错误。**",
            "answer": "$$\\boxed{AB}$$"
        }
    ]
}