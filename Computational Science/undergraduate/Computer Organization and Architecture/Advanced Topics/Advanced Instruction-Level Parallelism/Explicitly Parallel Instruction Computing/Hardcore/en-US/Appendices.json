{
    "hands_on_practices": [
        {
            "introduction": "The core task of a compiler for an Explicitly Parallel Instruction Computing (EPIC) architecture is a complex puzzle: scheduling instructions into fixed-width bundles. This exercise puts you in the role of the compiler, challenging you to manually schedule a sequence of instructions while respecting both data dependencies and the rigid structural constraints imposed by a limited set of hardware templates. Successfully solving this puzzle will give you a concrete understanding of the trade-offs between instruction-level parallelism and resource limitations that define the EPIC paradigm. ",
            "id": "3640835",
            "problem": "An Explicitly Parallel Instruction Computing (EPIC) processor issues fixed-width bundles of exactly $3$ instructions per cycle, using templates that constrain which functional unit types can appear together. A bundle template specifies the three slot types in order, and only the following templates are available:\n- $\\mathsf{MMI}$,\n- $\\mathsf{MII}$,\n- $\\mathsf{MIF}$,\n- $\\mathsf{FII}$,\n- $\\mathsf{MIB}$.\n\nHere $\\mathsf{M}$ denotes a memory operation (load or store), $\\mathsf{I}$ denotes an integer arithmetic or compare, $\\mathsf{F}$ denotes a floating-point operation, and $\\mathsf{B}$ denotes a branch. If a slot type in a chosen template cannot be filled by a ready instruction of that type, the slot must be occupied by a no-operation of that type, denoted $\\mathsf{NOP}$, which still consumes the slot.\n\nAll instructions within a bundle are assumed to be in the same stop group; therefore, any read-after-write dependency forces the consumer instruction to be scheduled in a strictly later bundle than its producer. Reordering across the original program order is permitted as long as data and control dependencies are preserved.\n\nConsider the following straight-line code fragment with $8$ instructions, their types, and dependencies:\n- $\\text{L}_{1}$: $\\mathsf{M}$ load $r_{1} \\leftarrow [a]$.\n- $\\text{L}_{2}$: $\\mathsf{M}$ load $r_{2} \\leftarrow [b]$.\n- $\\text{A}_{1}$: $\\mathsf{I}$ add $r_{3} \\leftarrow r_{1} + r_{5}$, depends on $\\text{L}_{1}$.\n- $\\text{A}_{2}$: $\\mathsf{I}$ add $r_{4} \\leftarrow r_{2} + r_{6}$, depends on $\\text{L}_{2}$.\n- $\\text{S}_{1}$: $\\mathsf{M}$ store $[c] \\leftarrow r_{3}$, depends on $\\text{A}_{1}$.\n- $\\text{F}_{1}$: $\\mathsf{F}$ multiply $f_{1} \\leftarrow f_{2} \\times f_{3}$, independent of all others.\n- $\\text{C}_{1}$: $\\mathsf{I}$ compare $p_{1} \\leftarrow r_{4}, r_{7}$, depends on $\\text{A}_{2}$.\n- $\\text{B}_{1}$: $\\mathsf{B}$ branch on $p_{1}$, depends on $\\text{C}_{1}$.\n\nTask:\n- Taking into account the template set $\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$, the $3$-slot bundle width, and the no-intra-bundle dependency rule, determine the minimal number of bundles needed to schedule all $8$ instructions while preserving semantics. You may reorder instructions as needed, but each bundle must use one of the allowed templates, inserting type-appropriate $\\mathsf{NOP}$s where necessary.\n- In your reasoning, explicitly demonstrate how template limitations prevent perfectly packing intuitive triples such as two loads with a floating-point operation, and propose a valid bundle-by-bundle instruction ordering that attains the minimum.\n\nReport only the minimal number of bundles as your final answer. No rounding is required.",
            "solution": "The problem asks for the minimum number of bundles required to schedule a given sequence of $8$ instructions on an Explicitly Parallel Instruction Computing (EPIC) processor with specific architectural constraints.\n\nFirst, we must rigorously validate the problem statement.\nThe problem provides a complete set of givens: an EPIC processor model with $3$-slot bundles, a fixed set of five bundle templates ($\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$), a list of $8$ instructions with their types ($\\mathsf{M}, \\mathsf{I}, \\mathsf{F}, \\mathsf{B}$), and the data dependencies between them. The scheduling rule regarding read-after-write (RAW) dependencies (no-intra-bundle dependency) is clearly stated. The problem is scientifically grounded in the principles of computer architecture and compiler optimization, presents a well-posed objective, and is free of ambiguity or contradiction. Thus, the problem is valid.\n\nTo solve the problem, we first analyze the dependencies to determine the theoretical minimum number of bundles. The dependencies can be represented as a directed acyclic graph (DAG):\n- $\\text{L}_{1} \\rightarrow \\text{A}_{1} \\rightarrow \\text{S}_{1}$\n- $\\text{L}_{2} \\rightarrow \\text{A}_{2} \\rightarrow \\text{C}_{1} \\rightarrow \\text{B}_{1}$\n- $\\text{F}_{1}$ (independent)\n\nThe instructions and their types are:\n- $\\text{L}_{1}$: $\\mathsf{M}$\n- $\\text{L}_{2}$: $\\mathsf{M}$\n- $\\text{A}_{1}$: $\\mathsf{I}$\n- $\\text{A}_{2}$: $\\mathsf{I}$\n- $\\text{S}_{1}$: $\\mathsf{M}$\n- $\\text{F}_{1}$: $\\mathsf{F}$\n- $\\text{C}_{1}$: $\\mathsf{I}$\n- $\\text{B}_{1}$: $\\mathsf{B}$\n\nThe \"no intra-bundle dependency\" rule states that if instruction $\\text{J}$ depends on instruction $\\text{I}$, $\\text{J}$ must be scheduled in a bundle strictly later than the bundle containing $\\text{I}$. The length of the longest path in the dependency graph, known as the critical path, therefore establishes a lower bound on the number of bundles required.\n\nIn this case, the longest dependency chain is $\\text{L}_{2} \\rightarrow \\text{A}_{2} \\rightarrow \\text{C}_{1} \\rightarrow \\text{B}_{1}$. This path has a length of $4$ (it contains $4$ instructions). This means that at least $4$ separate bundles are required to schedule these four instructions alone: one for $\\text{L}_{2}$, a subsequent one for $\\text{A}_{2}$, a third for $\\text{C}_{1}$, and a fourth for $\\text{B}_{1}$. Therefore, the minimum number of bundles is at least $4$. The theoretical minimum based on instruction count, $\\lceil 8/3 \\rceil = 3$, is superseded by this dependency constraint.\n\nOur task is now to determine if a schedule with exactly $4$ bundles is achievable given the available templates: $\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$. We will attempt to construct such a schedule.\n\n**Bundle 1:**\nThe set of instructions ready to be scheduled (those with no unsatisfied dependencies) are $\\text{L}_{1}(\\mathsf{M})$, $\\text{L}_{2}(\\mathsf{M})$, and $\\text{F}_{1}(\\mathsf{F})$. An optimal heuristic is to schedule instructions from the longest dependency chains as early as possible. Here, both $\\text{L}_{1}$ and $\\text{L}_{2}$ start dependency chains.\n\nThe problem asks to demonstrate how template limitations constrain scheduling. An intuitive approach would be to schedule the three ready instructions $\\{\\text{L}_{1}, \\text{L}_{2}, \\text{F}_{1}\\}$ together. This would require a bundle template of type $\\mathsf{MMF}$ (or its permutations). However, inspecting the available templates, $\\{\\mathsf{MMI}, \\mathsf{MII}, \\mathsf{MIF}, \\mathsf{FII}, \\mathsf{MIB}\\}$, reveals that no such template exists. The template set cannot accommodate two memory operations and one floating-point operation in a single bundle. This is a key constraint.\n\nTo maximize parallel execution in subsequent cycles, we should execute both loads, $\\text{L}_{1}$ and $\\text{L}_{2}$, as early as possible. This makes their dependents, $\\text{A}_{1}$ and $\\text{A}_{2}$, ready sooner. The $\\mathsf{MMI}$ template allows scheduling two memory operations. The third slot, for an $\\mathsf{I}$-type instruction, cannot be filled as no $\\mathsf{I}$-type instruction is ready. Thus, we must use a no-operation instruction, $\\text{NOP}_{\\mathsf{I}}$.\n- **Bundle 1:** $\\{\\text{L}_{1}(\\mathsf{M}), \\text{L}_{2}(\\mathsf{M}), \\text{NOP}_{\\mathsf{I}}\\}$ using template $\\mathsf{MMI}$.\n\n**Bundle 2:**\nAfter Bundle 1, instructions $\\text{L}_{1}$ and $\\text{L}_{2}$ are completed. The new set of ready instructions is:\n- $\\text{A}_{1}(\\mathsf{I})$, which depends on $\\text{L}_{1}$.\n- $\\text{A}_{2}(\\mathsf{I})$, which depends on $\\text{L}_{2}$.\n- $\\text{F}_{1}(\\mathsf{F})$, which was ready from the start.\nWe have one $\\mathsf{F}$-type and two $\\mathsf{I}$-type ready instructions. The template $\\mathsf{FII}$ is a perfect match for this set.\n- **Bundle 2:** $\\{\\text{F}_{1}(\\mathsf{F}), \\text{A}_{1}(\\mathsf{I}), \\text{A}_{2}(\\mathsf{I})\\}$ using template $\\mathsf{FII}$. The order within the bundle does not matter as there are no dependencies among them.\n\n**Bundle 3:**\nAfter Bundle 2, instructions $\\text{A}_{1}$, $\\text{A}_{2}$, and $\\text{F}_{1}$ are completed. The new set of ready instructions is:\n- $\\text{S}_{1}(\\mathsf{M})$, which depends on $\\text{A}_{1}$.\n- $\\text{C}_{1}(\\mathsf{I})$, which depends on $\\text{A}_{2}$.\nWe have one $\\mathsf{M}$-type and one $\\mathsf{I}$-type instruction ready. The instruction $\\text{B}_{1}$ is not yet ready, as it depends on $\\text{C}_{1}$. We must choose a template that can accommodate $\\text{S}_{1}$ and $\\text{C}_{1}$. Several templates could work with a $\\text{NOP}$, for example $\\mathsf{MII}$ or $\\mathsf{MIF}$. Let's use $\\mathsf{MII}$.\n- **Bundle 3:** $\\{\\text{S}_{1}(\\mathsf{M}), \\text{C}_{1}(\\mathsf{I}), \\text{NOP}_{\\mathsf{I}}\\}$ using template $\\mathsf{MII}$.\n\n**Bundle 4:**\nAfter Bundle 3, instructions $\\text{S}_{1}$ and $\\text{C}_{1}$ are completed. Only one instruction remains:\n- $\\text{B}_{1}(\\mathsf{B})$, which depends on $\\text{C}_{1}$ (now completed).\nThe only template that supports a branch ($\\mathsf{B}$) instruction is $\\mathsf{MIB}$. The other two slots must be filled with NOPs as there are no other ready instructions.\n- **Bundle 4:** $\\{\\text{NOP}_{\\mathsf{M}}, \\text{NOP}_{\\mathsf{I}}, \\text{B}_{1}(\\mathsf{B})\\}$ using template $\\mathsf{MIB}$.\n\nAll $8$ instructions have been scheduled in $4$ bundles.\nThe final schedule is:\n1.  $\\{\\text{L}_{1}, \\text{L}_{2}, \\text{NOP}_{\\mathsf{I}}\\}$\n2.  $\\{\\text{F}_{1}, \\text{A}_{1}, \\text{A}_{2}\\}$\n3.  $\\{\\text{S}_{1}, \\text{C}_{1}, \\text{NOP}_{\\mathsf{I}}\\}$\n4.  $\\{\\text{NOP}_{\\mathsf{M}}, \\text{NOP}_{\\mathsf{I}}, \\text{B}_{1}\\}$\n\nSince we established a theoretical minimum of $4$ bundles due to the critical path length, and we have successfully constructed a valid $4$-bundle schedule, we can conclude that the minimal number of bundles is $4$.",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "EPIC architectures derive much of their power from advanced features like predication, which allows instructions to be conditionally executed without costly branches. However, when combined with speculative execution, this powerful tool can create subtle but critical correctness issues. This thought experiment guides you through a scenario where a speculatively executed, predicated-false instruction could erroneously crash the program, revealing precisely why microarchitectural mechanisms like deferred exceptions are not just an optimization, but a fundamental requirement for building a correct EPIC processor. ",
            "id": "3640849",
            "problem": "Consider the foundational semantics of predication in Explicitly Parallel Instruction Computing (EPIC): a predicated instruction is guarded by a Boolean predicate $p \\in \\{0,1\\}$, and the architectural contract requires that when $p=1$ the instruction has its usual effect on architectural state, while when $p=0$ the instruction has no architectural effect of any kind, including the prohibition of raising synchronous exceptions (such as page faults) that would otherwise occur. Also recall the fundamental rule of memory exceptions in a conventional von Neumann machine model: a load that references an invalid or unmapped address raises a synchronous exception at the point of use and prevents subsequent architectural state updates from committing.\n\nAn EPIC microarchitecture may issue predicated instructions in parallel to exploit static instruction-level parallelism, potentially before the final value of $p$ is known, provided it preserves the architectural predication contract. A common mechanism to preserve this contract is deferred exceptions: a speculative load produces a poison value that carries a deferred-exception tag (for example, a Not a Thing (NaT) bit in the Intel Itanium family), and the exception is only raised later if and when the program’s control logically demands the value under a true predicate, as verified by an explicit check instruction. Without such deferral, the machine may raise an exception immediately on an invalid access, even if the instruction is predicated false.\n\nDesign the following experiment to make the interaction between predication and data-dependent loads explicit. Assume the memory system has the following properties:\n- All virtual addresses strictly less than $4096$ are invalid and raise a page fault if dereferenced by a normal load.\n- The memory contents satisfy $\\text{mem}[8192] = 12288$ and $\\text{mem}[12288] = 7$.\n\nConsider a statically scheduled EPIC bundle that contains $2$ predicated loads and no branches:\n- Load $L_1$: if $p$ then compute $r_1 \\leftarrow \\text{mem}[r_2]$.\n- Load $L_2$: if $p$ then compute $r_3 \\leftarrow \\text{mem}[r_1]$.\nAll other instructions in the bundle are independent and side-effect free. The microarchitecture issues $L_1$ and $L_2$ in parallel in the same cycle, before $p$ is finally resolved for commit. The bundle is executed under two test conditions:\n- Test condition $\\mathsf{T\\_A}$: $p=1$ and $r_2=8192$ at issue time.\n- Test condition $\\mathsf{T\\_B}$: $p=0$ and $r_2=0$ at issue time.\n\nAnalyze the experiment under two architectural policies:\n- Policy $\\mathsf{ND}$ (No Deferral): all loads are normal, and any exception is raised immediately when the memory system detects an invalid access.\n- Policy $\\mathsf{DE}$ (Deferred Exceptions): loads $L_1$ and $L_2$ are speculative, each producing a poison value with a deferred-exception tag if their address would fault; the exception is only raised later by an explicit check that executes under $p=1$, and poison propagates through dependent uses.\n\nWhich of the following statements correctly characterize the outcomes of the experiment?\n\nA. Under policy $\\mathsf{ND}$ in test condition $\\mathsf{T\\_B}$, the machine can raise a synchronous exception due to $L_1$ even though $p=0$, violating the architectural predication contract.\n\nB. Under policy $\\mathsf{DE}$, test condition $\\mathsf{T\\_B}$ does not raise an exception because the poison value from $L_1$ (and any propagated poison to $L_2$) is never architecturally demanded when $p=0$, while test condition $\\mathsf{T\\_A}$ produces $r_3=7$.\n\nC. The data dependency from $L_1$ to $L_2$ makes deferred exceptions insufficient; an exception will always be raised by $L_2$ in test condition $\\mathsf{T\\_B}$ because address computation is independent of the predicate $p$.\n\nD. A correct EPIC implementation that speculatively issues predicated loads must ensure predicate evaluation precedes address translation; thus, in all cases, no exceptions can be raised for $p=0$ even without deferred exceptions.",
            "solution": "The problem statement is a well-defined thought experiment in computer architecture, specifically on the topic of Explicitly Parallel Instruction Computing (EPIC). All provided information is scientifically grounded, internally consistent, and sufficient for a rigorous analysis. The terms such as predication, deferred exceptions, speculative execution, and page faults are used in accordance with their standard meanings in the field. The problem is therefore valid.\n\nWe will analyze the outcomes of the experiment for each combination of architectural policy and test condition. The bundle consists of two data-dependent loads:\n- $L_1$: if $p$ then compute $r_1 \\leftarrow \\text{mem}[r_2]$.\n- $L_2$: if $p$ then compute $r_3 \\leftarrow \\text{mem}[r_1]$.\n\nThe instructions $L_1$ and $L_2$ are issued in parallel in the same cycle, before the predicate $p$ is resolved. This implies speculative execution. The data dependency from $L_1$ to $L_2$ means the execution of the memory access for $L_2$ must wait for the result of $L_1$. We assume a standard forwarding path from $L_1$'s execution stage to $L_2$'s address-calculation stage.\n\nThe memory system has the following defined properties:\n- Any address $A < 4096$ is invalid and causes a page fault.\n- $\\text{mem}[8192] = 12288$.\n- $\\text{mem}[12288] = 7$.\n\n### Analysis of Policy $\\mathsf{ND}$ (No Deferral)\n\nUnder this policy, any exception is raised immediately upon detection by the memory system.\n\n**Test Condition $\\mathsf{T\\_A}$:** $p=1$, $r_2=8192$.\n1.  $L_1$ is speculatively executed. It computes its address as the value of $r_2$, which is $8192$.\n2.  The address $8192$ is valid (i.e., $\\ge 4096$). The memory system reads $\\text{mem}[8192]$, which is $12288$.\n3.  $L_2$ is speculatively executed. It requires the result of $L_1$ to compute its address. The value $12288$ is forwarded from $L_1$.\n4.  $L_2$ computes its address as $12288$. This is a valid address. The memory system reads $\\text{mem}[12288]$, which is $7$.\n5.  The predicate $p$ is resolved to $1$. Both instructions are on the correct path.\n6.  The results are committed to the architectural state: $r_1$ is updated to $12288$ and $r_3$ is updated to $7$. No exception occurs.\n\n**Test Condition $\\mathsf{T\\_B}$:** $p=0$, $r_2=0$.\n1.  $L_1$ is speculatively executed. It computes its address as the value of $r_2$, which is $0$.\n2.  The address $0$ is invalid (i.e., $< 4096$).\n3.  Under policy $\\mathsf{ND}$, the memory system immediately raises a synchronous exception (a page fault).\n4.  This exception occurs during the speculative execution of $L_1$, before the predicate $p$ is resolved and used to squash the instruction. The machine halts or transfers control to an exception handler.\n5.  The architectural contract for predication states that for $p=0$, the instruction must have no architectural effect, which includes not raising exceptions. By faulting on an instruction that should have been nullified, the microarchitecture violates the architectural contract.\n\n### Analysis of Policy $\\mathsf{DE}$ (Deferred Exceptions)\n\nUnder this policy, an invalid memory access during speculative execution does not raise an immediate exception. Instead, it produces a \"poison\" value (e.g., a Not-a-Thing or NaT bit is set on the result register). This poison propagates through dependent instructions. The exception is only raised if an instruction attempts to use the poisoned value under a true predicate.\n\n**Test Condition $\\mathsf{T\\_A}$:** $p=1$, $r_2=8192$.\nThe execution proceeds identically to the $\\mathsf{ND}$ case.\n1.  $L_1$ accesses the valid address $8192$ and reads the value $12288$. No poison is generated.\n2.  $L_2$ accesses the valid address $12288$ and reads the value $7$. No poison is generated.\n3.  The predicate $p$ is $1$. The results are not poison, so any checks for deferred exceptions pass. The results $r_1 \\leftarrow 12288$ and $r_3 \\leftarrow 7$ are committed. The final value in $r_3$ is $7$.\n\n**Test Condition $\\mathsf{T\\_B}$:** $p=0$, $r_2=0$.\n1.  $L_1$ is speculatively executed. It computes its address as $0$.\n2.  The address $0$ is invalid. Instead of faulting, the microarchitecture generates a poison value for the destination register $r_1$.\n3.  $L_2$ is speculatively executed. It needs the result of $L_1$ for its address. The policy states that poison propagates. When $L_2$ attempts to use the poisoned value of $r_1$, its own result, destined for $r_3$, is also marked as poison. The memory access for $L_2$ may be suppressed entirely.\n4.  The predicate $p$ is resolved to $0$.\n5.  The architectural contract for $p=0$ dictates that the predicated instructions have no effect. The poisoned results for $r_1$ and $r_3$ are discarded. The architectural registers are not updated.\n6.  The deferred exception is never raised because the poison values are never \"architecturally demanded\" under a true predicate. The condition for raising the exception (an explicit check under $p=1$) is not met. Thus, no exception occurs.\n\n### Evaluation of Options\n\n**A. Under policy $\\mathsf{ND}$ in test condition $\\mathsf{T\\_B}$, the machine can raise a synchronous exception due to $L_1$ even though $p=0$, violating the architectural predication contract.**\nOur analysis of policy $\\mathsf{ND}$ for condition $\\mathsf{T\\_B}$ shows that $L_1$ attempts to access the invalid address $0$. Because exceptions are not deferred, a page fault is raised immediately. This happens speculatively, before the false predicate ($p=0$) could nullify the instruction. This is a direct violation of the EPIC architectural contract, which requires no architectural side-effects for instructions with a false predicate.\n**Verdict: Correct.**\n\n**B. Under policy $\\mathsf{DE}$, test condition $\\mathsf{T\\_B}$ does not raise an exception because the poison value from $L_1$ (and any propagated poison to $L_2$) is never architecturally demanded when $p=0$, while test condition $\\mathsf{T\\_A}$ produces $r_3=7$.**\nThis statement has two parts.\n1.  For $\\mathsf{DE}$ and $\\mathsf{T\\_B}$ ($p=0$, $r_2=0$): Our analysis shows that a poison value is generated by $L_1$ and propagated to $L_2$. Because $p=0$, the predicated instructions are nullified, their results (including the poison tags) are discarded, and the deferred exception is never triggered. So, no exception is raised. This part is correct.\n2.  For $\\mathsf{DE}$ and $\\mathsf{T\\_A}$ ($p=1$, $r_2=8192$): Our analysis shows that $L_1$ loads $\\text{mem}[8192]=12288$, and $L_2$ then loads $\\text{mem}[12288]=7$. Since $p=1$, the result $r_3=7$ is committed. This part is also correct.\nSince both parts of the statement are true, the entire statement is correct.\n**Verdict: Correct.**\n\n**C. The data dependency from $L_1$ to $L_2$ makes deferred exceptions insufficient; an exception will always be raised by $L_2$ in test condition $\\mathsf{T\\_B}$ because address computation is independent of the predicate $p$.**\nThis statement claims the deferred exception mechanism is insufficient. Our analysis of policy $\\mathsf{DE}$ in condition $\\mathsf{T\\_B}$ proves otherwise. The mechanism of poison generation and propagation, combined with the final check against the predicate, correctly handles the situation. An exception is *not* raised because $p=0$. The premise that address computation is independent of the predicate is why speculation is risky, but it is precisely the problem that deferred exceptions are designed to solve. Therefore, the conclusion that an exception will always be raised is false.\n**Verdict: Incorrect.**\n\n**D. A correct EPIC implementation that speculatively issues predicated loads must ensure predicate evaluation precedes address translation; thus, in all cases, no exceptions can be raised for $p=0$ even without deferred exceptions.**\nThis statement proposes a specific, conservative implementation strategy as a mandatory requirement for correctness (\"must ensure\"). This strategy involves resolving the predicate before the memory access, which would indeed prevent the fault in condition $\\mathsf{T\\_B}$. However, doing so would introduce a control dependency that could severely limit instruction-level parallelism, undermining a key goal of the EPIC philosophy. The problem describes deferred exceptions as a \"common mechanism\" to preserve the architectural contract *while* allowing speculative loads to issue before the predicate is known. The existence of the deferred exception mechanism as a solution proves that the strategy proposed in option D is not the *only* way to build a correct implementation. Therefore, the \"must ensure\" claim is false.\n**Verdict: Incorrect.**",
            "answer": "A, B"
        },
        {
            "introduction": "While manual scheduling helps build intuition, real-world compilers need a formal, automatable method to find the best possible schedule among countless possibilities. This practice introduces you to Integer Linear Programming (ILP), a powerful mathematical technique for modeling and solving such optimization problems. By formulating the instruction scheduling task with its resource and dependency constraints as an ILP, you will learn how the intuitive puzzle of packing instructions can be transformed into a rigorous framework capable of guaranteeing an optimal solution. ",
            "id": "3640874",
            "problem": "Consider an explicitly parallel instruction computing (EPIC) processor that issues fixed-size bundles each cycle, subject to functional unit limits. The compiler must schedule instructions into bundles so that resource limits are respected and data dependences with latency are honored. Formulate this scheduling task as an Integer Linear Programming (ILP) model in which binary decision variables represent the placement of each instruction into a cycle, and then solve a tiny instance to determine the minimal number of cycles (bundles) required.\n\nFundamental base assumptions to use:\n- EPIC bundles explicitly indicate parallel issue; a bundle is a set of instructions issued in the same cycle, provided functional unit limits are not exceeded.\n- Data dependences enforce that a consumer instruction may issue only after its producer’s result becomes available; availability is captured by fixed latencies in cycles.\n- Integer Linear Programming (ILP) represents discrete decisions with linear constraints and integral variables.\n\nThe tiny instance is a straight-line code fragment with six instructions. Each instruction has a type and latency to define resource usage and when results become available. The processor has resource limits of at most $2$ arithmetic logic unit (ALU) instructions and at most $1$ memory (MEM) instruction per cycle; branch resources are not used here. Cycles are discretized and numbered $1,2,\\dots,H$ with horizon $H=6$. The instructions are:\n\n- Instruction $1$ ($\\text{L1}$): MEM load of register $r_1$, producing $r_1$. Type MEM. Result latency $2$ cycles.\n- Instruction $2$ ($\\text{A1}$): ALU add of register $r_2 \\leftarrow r_1 + c$, consuming $r_1$. Type ALU. Result latency $1$ cycle. Dependence: $1 \\rightarrow 2$.\n- Instruction $3$ ($\\text{L2}$): MEM load of register $r_3$, producing $r_3$. Type MEM. Result latency $2$ cycles.\n- Instruction $4$ ($\\text{M1}$): ALU multiply $r_4 \\leftarrow r_2 \\times r_3$, consuming $r_2$ and $r_3$. Type ALU. Result latency $1$ cycle. Dependences: $2 \\rightarrow 4$ and $3 \\rightarrow 4$.\n- Instruction $5$ ($\\text{S1}$): MEM store $[C] \\leftarrow r_4$, consuming $r_4$. Type MEM. Result latency does not further constrain scheduling, but the operand must be available. Dependence: $4 \\rightarrow 5$.\n- Instruction $6$ ($\\text{A2}$): ALU add $r_5 \\leftarrow r_6 + r_7$, independent. Type ALU. Result latency $1$ cycle. No dependences.\n\nLet binary variables $x_{i,t} \\in \\{0,1\\}$ indicate whether instruction $i \\in \\{1,\\dots,6\\}$ is scheduled in cycle $t \\in \\{1,\\dots,6\\}$. Let integer variables $s_i$ denote the scheduled cycle of instruction $i$, defined by $s_i = \\sum_{t=1}^{6} t \\, x_{i,t}$. Let integer variable $S$ be the makespan, defined to be the maximum scheduled cycle across all instructions.\n\nTask:\n1. Formulate the ILP with constraints that (a) each instruction is scheduled exactly once, (b) resource limits per cycle are respected for ALU and MEM types, (c) data dependences with latencies are enforced so consumers issue only after producers’ results are available, and (d) the makespan $S$ bounds all $s_i$. Use the above horizon $H=6$.\n2. Solve the instance to find the minimal makespan $S$, i.e., the smallest number of cycles required to schedule all six instructions under the given constraints. Provide the minimal $S$ as a single number. No rounding is required, and no units should be included in the final answer box.",
            "solution": "The problem statement has been validated and is deemed sound. It is a well-posed, scientifically grounded problem in computer architecture, specifically in the area of instruction-level parallelism and compiler optimization. All necessary data and constraints are provided, and the objective is clearly defined. We may proceed with the formulation and solution.\n\nThe task is to formulate an Integer Linear Programming (ILP) model for an instruction scheduling problem and solve a given instance to find the minimal makespan.\n\nFirst, we define the sets and parameters based on the problem description.\nLet the set of all instructions be $I = \\{1, 2, 3, 4, 5, 6\\}$.\nLet the set of scheduling cycles (the horizon) be $T = \\{1, 2, 3, 4, 5, 6\\}$.\nThe instructions are categorized by type into two sets:\nSet of ALU instructions: $I_{ALU} = \\{2, 4, 6\\}$.\nSet of MEM instructions: $I_{MEM} = \\{1, 3, 5\\}$.\n\nThe latencies for the producer instructions are given as:\n$L_1 = 2$ cycles for instruction $1$.\n$L_2 = 1$ cycle for instruction $2$.\n$L_3 = 2$ cycles for instruction $3$.\n$L_4 = 1$ cycle for instruction $4$.\n\nThe binary decision variable $x_{i,t} \\in \\{0, 1\\}$ is $1$ if instruction $i$ is scheduled in cycle $t$, and $0$ otherwise.\nThe scheduled cycle for instruction $i$ is $s_i = \\sum_{t \\in T} t \\cdot x_{i,t}$.\nThe makespan is $S$.\n\nThe objective is to minimize the total number of cycles used, which is the makespan $S$.\nObjective Function: Minimize $S$.\n\nThe ILP model is subject to the following constraints:\n\n1.  **Assignment Constraints**: Each instruction must be scheduled in exactly one cycle.\n    $$ \\sum_{t=1}^{6} x_{i,t} = 1 \\quad \\forall i \\in I $$\n\n2.  **Resource Constraints**: The number of instructions of each type scheduled in any cycle must not exceed the functional unit limits.\n    -   At most $2$ ALU instructions per cycle:\n        $$ \\sum_{i \\in I_{ALU}} x_{i,t} \\le 2 \\quad \\forall t \\in T $$\n        Explicitly: $x_{2,t} + x_{4,t} + x_{6,t} \\le 2$ for $t=1, \\dots, 6$.\n    -   At most $1$ MEM instruction per cycle:\n        $$ \\sum_{i \\in I_{MEM}} x_{i,t} \\le 1 \\quad \\forall t \\in T $$\n        Explicitly: $x_{1,t} + x_{3,t} + x_{5,t} \\le 1$ for $t=1, \\dots, 6$.\n\n3.  **Data Dependence Constraints**: A consumer instruction $j$ can only be scheduled after the result of a producer instruction $i$ is available. If instruction $i$ is scheduled at cycle $s_i$ and has latency $L_i$, its result is available at the start of cycle $s_i + L_i$. Thus, instruction $j$ must satisfy $s_j \\ge s_i + L_i$.\n    -   Dependence $1 \\rightarrow 2$ (latency $L_1 = 2$):\n        $$ \\sum_{t=1}^{6} t \\cdot x_{2,t} \\ge \\left(\\sum_{t=1}^{6} t \\cdot x_{1,t}\\right) + 2 $$\n    -   Dependence $2 \\rightarrow 4$ (latency $L_2 = 1$):\n        $$ \\sum_{t=1}^{6} t \\cdot x_{4,t} \\ge \\left(\\sum_{t=1}^{6} t \\cdot x_{2,t}\\right) + 1 $$\n    -   Dependence $3 \\rightarrow 4$ (latency $L_3 = 2$):\n        $$ \\sum_{t=1}^{6} t \\cdot x_{4,t} \\ge \\left(\\sum_{t=1}^{6} t \\cdot x_{3,t}\\right) + 2 $$\n    -   Dependence $4 \\rightarrow 5$ (latency $L_4 = 1$):\n        $$ \\sum_{t=1}^{6} t \\cdot x_{5,t} \\ge \\left(\\sum_{t=1}^{6} t \\cdot x_{4,t}\\right) + 1 $$\n\n4.  **Makespan Constraint**: The makespan $S$ must be greater than or equal to the scheduled cycle of every instruction.\n    $$ S \\ge \\sum_{t=1}^{6} t \\cdot x_{i,t} \\quad \\forall i \\in I $$\n\n5.  **Variable Domains**:\n    $$ x_{i,t} \\in \\{0, 1\\} \\quad \\forall i \\in I, \\forall t \\in T $$\n    $$ S \\in \\mathbb{Z}^+ $$\n\nThis completes the ILP formulation. Now, we solve the instance to find the minimal makespan $S$. We can determine a lower bound for $S$ by analyzing the critical path of the dependence graph.\n\nThe dependencies define the following chains:\n-   $1 \\rightarrow 2 \\rightarrow 4 \\rightarrow 5$\n-   $3 \\rightarrow 4 \\rightarrow 5$\n\nLet $s_i$ be the cycle in which instruction $i$ is scheduled. The dependence constraints imply:\n$s_2 \\ge s_1 + L_1 = s_1 + 2$\n$s_4 \\ge s_2 + L_2 = s_2 + 1$\n$s_4 \\ge s_3 + L_3 = s_3 + 2$\n$s_5 \\ge s_4 + L_4 = s_4 + 1$\n\nCombining these, we can establish a lower bound on $s_5$:\n$s_5 \\ge s_4 + 1 \\ge (s_2 + 1) + 1 = s_2 + 2$. Using $s_2 \\ge s_1 + 2$, we get $s_5 \\ge (s_1 + 2) + 2 = s_1 + 4$.\nAlso, $s_5 \\ge s_4 + 1 \\ge (s_3 + 2) + 1 = s_3 + 3$.\nTherefore, $s_5$ must satisfy $s_5 \\ge \\max(s_1 + 4, s_3 + 3)$.\n\nInstructions $1$ and $3$ are both of type MEM. The processor has only one MEM unit, so they cannot be scheduled in the same cycle ($s_1 \\ne s_3$). The earliest possible cycle is $1$.\nLet us consider two cases for scheduling $s_1$ and $s_3$:\n-   Case A: Instruction $1$ is scheduled before instruction $3$. The earliest possible schedule is $s_1=1$ and $s_3=2$.\n    The lower bound on $s_5$ becomes $s_5 \\ge \\max(1 + 4, 2 + 3) = \\max(5, 5) = 5$.\n-   Case B: Instruction $3$ is scheduled before instruction $1$. The earliest possible schedule is $s_3=1$ and $s_1=2$.\n    The lower bound on $s_5$ becomes $s_5 \\ge \\max(2 + 4, 1 + 3) = \\max(6, 4) = 6$.\n\nThe minimum lower bound for $s_5$ across both cases is $5$. The makespan $S$ is the maximum of all $s_i$, so $S \\ge s_5$. This implies that the minimal makespan must be at least $5$. $S_{min} \\ge 5$.\n\nNow, we must show that a makespan of $S=5$ is achievable by constructing a valid schedule. We follow a list scheduling approach, prioritizing instructions on the critical path.\n-   **Cycle 1**: Instructions ready to be scheduled are $\\{1, 3, 6\\}$. Instruction $1$ is on the longest critical path. We schedule it. We can also schedule instruction $6$ as it is independent and an ALU instruction.\n    -   Bundle 1: $\\{1 (\\text{MEM}), 6 (\\text{ALU})\\}$. Resources: $1$ MEM, $1$ ALU. OK.\n    -   $s_1=1, s_6=1$.\n-   **Cycle 2**: The only remaining ready instruction is $3$.\n    -   Bundle 2: $\\{3 (\\text{MEM})\\}$. Resources: $1$ MEM, $0$ ALU. OK.\n    -   $s_3=2$.\n-   **Cycle 3**: Instruction $2$ becomes ready (needs result from $1$, scheduled at $t=1$ with $L_1=2$, so ready at $t \\ge 1+2=3$).\n    -   Bundle 3: $\\{2 (\\text{ALU})\\}$. Resources: $0$ MEM, $1$ ALU. OK.\n    -   $s_2=3$.\n-   **Cycle 4**: Instruction $4$ becomes ready. It needs results from $2$ (scheduled at $t=3$ with $L_2=1$, ready at $t \\ge 3+1=4$) and $3$ (scheduled at $t=2$ with $L_3=2$, ready at $t \\ge 2+2=4$).\n    -   Bundle 4: $\\{4 (\\text{ALU})\\}$. Resources: $0$ MEM, $1$ ALU. OK.\n    -   $s_4=4$.\n-   **Cycle 5**: Instruction $5$ becomes ready (needs result from $4$, scheduled at $t=4$ with $L_4=1$, ready at $t \\ge 4+1=5$).\n    -   Bundle 5: $\\{5 (\\text{MEM})\\}$. Resources: $1$ MEM, $0$ ALU. OK.\n    -   $s_5=5$.\n\nAll $6$ instructions have been scheduled. The schedule is:\n$s_1 = 1, s_2 = 3, s_3 = 2, s_4 = 4, s_5 = 5, s_6 = 1$.\nThe maximum schedule time is $\\max(1, 3, 2, 4, 5, 1) = 5$.\nThis schedule is valid as it respects all dependence and resource constraints. The makespan is $S=5$.\n\nSince we have established a lower bound of $5$ for the makespan and have constructed a valid schedule with a makespan of $5$, we conclude that the minimal makespan is $5$.",
            "answer": "$$\\boxed{5}$$"
        }
    ]
}