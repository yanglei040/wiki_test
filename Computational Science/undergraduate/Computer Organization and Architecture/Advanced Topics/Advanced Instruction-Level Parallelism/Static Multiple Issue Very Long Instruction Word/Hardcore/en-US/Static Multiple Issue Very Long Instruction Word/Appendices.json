{
    "hands_on_practices": [
        {
            "introduction": "The core task of a VLIW compiler is to solve a complex, multi-dimensional packing problem: filling wide instruction bundles with operations that can execute in parallel. This exercise provides a concrete model of a VLIW processor with typed functional units and varying instruction latencies, forcing you to confront the two primary constraints in static scheduling: data dependencies and resource availability. By manually scheduling a sequence of code and contrasting it with a naive approach, you will gain a practical understanding of why intelligent scheduling is critical and how structural and data hazards dictate the limits of performance .",
            "id": "3681276",
            "problem": "Consider a statically scheduled Very Long Instruction Word (VLIW) processor with one bundle issued per cycle. The bundle has four typed slots: two integer arithmetic logic unit slots $S_{\\text{ALU},0}$ and $S_{\\text{ALU},1}$, one multiply slot $S_{\\text{MUL}}$, and one memory slot $S_{\\text{MEM}}$. Each instruction must be placed in a bundle and targets exactly one slot that matches its type. Assume the following widely accepted base facts and constraints:\n- Static multiple issue schedules must respect true data dependencies: if an instruction with latency $L$ produces a value used by its consumer, and it is issued at cycle $c$, then its consumer may be issued no earlier than cycle $c + L$.\n- Functional unit occupancy constraints must be respected: when an instruction is issued into a slot $s$ with occupancy $O_s$, that slot cannot issue another instruction for $O_s$ consecutive cycles counted from the cycle of issue. This includes multi-cycle operations whose occupancy extends over multiple cycles.\n- Integer addition has latency $L_{\\text{ADD}} = 1$ and occupies its ALU slot for $O_{\\text{ALU}} = 1$ cycle.\n- Multiply has latency $L_{\\text{MUL}} = 3$ and occupies $S_{\\text{MUL}}$ for $O_{\\text{MUL}} = L_{\\text{MUL}}$ cycles.\n- Load has latency $L_{\\text{LD}} = 2$ and occupies $S_{\\text{MEM}}$ for $O_{\\text{MEM}} = 1$ cycle.\n- Store has latency $L_{\\text{ST}} = 1$ and occupies $S_{\\text{MEM}}$ for $O_{\\text{MEM}} = 1$ cycle.\n\nThe program to be scheduled is the following sequence (useful registers are distinct unless a dependency is stated):\n- $I_{1}$: $\\text{LD } r_{1} \\leftarrow [r_{A}]$.\n- $I_{2}$: $\\text{LD } r_{2} \\leftarrow [r_{B}]$.\n- $I_{3}$: $\\text{MUL } r_{3} \\leftarrow r_{1} \\times r_{2}$, depends on $I_{1}$ and $I_{2}$.\n- $I_{4}$: $\\text{ADD } r_{4} \\leftarrow r_{3} + r_{C}$, depends on $I_{3}$.\n- $I_{5}$: $\\text{MUL } r_{5} \\leftarrow r_{4} \\times r_{D}$, depends on $I_{4}$.\n- $I_{6}$: $\\text{ADD } r_{6} \\leftarrow r_{5} + r_{E}$, depends on $I_{5}$.\n- $I_{7}$: $\\text{MUL } r_{7} \\leftarrow r_{6} \\times r_{F}$, depends on $I_{6}$.\n- $I_{8}$: $\\text{ADD } r_{8} \\leftarrow r_{7} + r_{G}$, depends on $I_{7}$.\n- $I_{9}$: $\\text{ST } [r_{H}] \\leftarrow r_{8}$, depends on $I_{8}$.\n- $I_{10}$: $\\text{ADD } r_{10} \\leftarrow r_{11} + r_{12}$, no dependencies.\n- $I_{11}$: $\\text{ADD } r_{13} \\leftarrow r_{14} + r_{15}$, no dependencies.\n- $I_{12}$: $\\text{ADD } r_{16} \\leftarrow r_{17} + r_{18}$, no dependencies.\n- $I_{13}$: $\\text{ADD } r_{19} \\leftarrow r_{20} + r_{21}$, no dependencies.\n\nTask:\n- First, design a conflict-free static schedule that respects both data-dependence latencies and slot occupancy constraints described above. You may assume one bundle is issued per cycle, and you may place independent $\\text{ADD}$ instructions opportunistically to fill available $S_{\\text{ALU},0}$ and $S_{\\text{ALU},1}$ slots without violating any constraints.\n- Second, consider a naive bundling policy that ignores all latencies and occupancy constraints and simply takes the next up to $4$ instructions in program order each cycle, mapping them by type into the matching slots ($\\text{LD}/\\text{ST} \\rightarrow S_{\\text{MEM}}$, $\\text{MUL} \\rightarrow S_{\\text{MUL}}$, $\\text{ADD} \\rightarrow S_{\\text{ALU},0}$ or $S_{\\text{ALU},1}$). Define a bundle conflict to occur whenever, in a given cycle, this naive policy attempts to assign an instruction to a slot that is unavailable in that cycle due to a prior instruction’s occupancy of that same slot (including simultaneous over-subscription of $S_{\\text{MEM}}$ or $S_{\\text{ALU},k}$ within the same cycle or multi-cycle occupancy of $S_{\\text{MUL}}$ across cycles). Count the total number of bundle conflicts that would be produced by this naive policy for the entire program sequence.\n\nProvide only the total number of bundle conflicts as your final answer. No rounding is needed.",
            "solution": "The problem asks for the total number of bundle conflicts produced by a naive bundling policy for a given sequence of instructions on a VLIW processor. A bundle conflict is defined as an attempt by the naive policy to assign an instruction to a slot that is unavailable, either due to a concurrent assignment within the same cycle (over-subscription) or due to the multi-cycle occupancy of a slot from a previous cycle.\n\nThe VLIW processor has four slots per bundle: two integer ALU slots ($S_{\\text{ALU},0}$, $S_{\\text{ALU},1}$), one multiply slot ($S_{\\text{MUL}}$), and one memory slot ($S_{\\text{MEM}}$). The naive policy forms bundles by taking up to four instructions in program order per cycle and mapping them to the appropriately typed slots. For ALU instructions, the policy will fill $S_{\\text{ALU},0}$ first, then $S_{\\text{ALU},1}$.\n\nWe will analyze the scheduling process cycle by cycle, tracking the occupancy of each slot and counting the conflicts as they occur. Let $F_s$ be the first cycle in which slot $s$ is free. Initially, at cycle $C=1$, all slots are available, so $F_s = 1$ for all slots $s$.\n\nThe instruction sequence is:\n- $I_1$: LD (MEM)\n- $I_2$: LD (MEM)\n- $I_3$: MUL (MUL)\n- $I_4$: ADD (ALU)\n- $I_5$: MUL (MUL)\n- $I_6$: ADD (ALU)\n- $I_7$: MUL (MUL)\n- $I_8$: ADD (ALU)\n- $I_9$: ST (MEM)\n- $I_{10}$: ADD (ALU)\n- $I_{11}$: ADD (ALU)\n- $I_{12}$: ADD (ALU)\n- $I_{13}$: ADD (ALU)\n\n**Cycle $1$**\n\nThe first bundle consists of instructions $I_1, I_2, I_3, I_4$.\n- Initial slot availability at $C=1$:\n  - $F_{\\text{ALU},0} = 1$\n  - $F_{\\text{ALU},1} = 1$\n  - $F_{\\text{MUL}} = 1$\n  - $F_{\\text{MEM}} = 1$\n\n- Naive assignment attempts:\n  - $I_1$ (LD) targets $S_{\\text{MEM}}$. The slot is available ($F_{\\text{MEM}} \\le 1$).\n  - $I_2$ (LD) targets $S_{\\text{MEM}}$. The slot is unavailable due to the simultaneous assignment of $I_1$. This is a resource over-subscription. This constitutes **$1$ conflict**.\n  - $I_3$ (MUL) targets $S_{\\text{MUL}}$. The slot is available ($F_{\\text{MUL}} \\le 1$).\n  - $I_4$ (ADD) targets $S_{\\text{ALU},0}$. The slot is available ($F_{\\text{ALU},0} \\le 1$).\n\n- Total conflicts in Cycle $1$: $1$.\n\n- Update slot occupancy for the next cycle, assuming instructions that did not conflict are issued.\n  - $I_1$ issues in $S_{\\text{MEM}}$ ($O_{\\text{MEM}}=1$). New $F_{\\text{MEM}} = 1 + 1 = 2$.\n  - $I_3$ issues in $S_{\\text{MUL}}$ ($O_{\\text{MUL}}=3$). New $F_{\\text{MUL}} = 1 + 3 = 4$.\n  - $I_4$ issues in $S_{\\text{ALU},0}$ ($O_{\\text{ALU}}=1$). New $F_{\\text{ALU},0} = 1 + 1 = 2$.\n  - $S_{\\text{ALU},1}$ remains unused. $F_{\\text{ALU},1} = 1$.\n\n**Cycle $2$**\n\nThe next bundle consists of instructions $I_5, I_6, I_7, I_8$.\n- Slot availability at $C=2$:\n  - $F_{\\text{ALU},0} = 2$ (Available)\n  - $F_{\\text{ALU},1} = 1$ (Available)\n  - $F_{\\text{MUL}} = 4$ (Unavailable, busy by $I_3$)\n  - $F_{\\text{MEM}} = 2$ (Available)\n\n- Naive assignment attempts:\n  - $I_5$ (MUL) targets $S_{\\text{MUL}}$. The slot is unavailable because $F_{\\text{MUL}} = 4 > 2$. This constitutes **$1$ conflict**.\n  - $I_6$ (ADD) targets $S_{\\text{ALU},0}$. The slot is available ($F_{\\text{ALU},0} \\le 2$).\n  - $I_7$ (MUL) targets $S_{\\text{MUL}}$. The slot is unavailable because $F_{\\text{MUL}} = 4 > 2$. This is a distinct attempt to use an unavailable slot. This constitutes another **$1$ conflict**.\n  - $I_8$ (ADD) targets $S_{\\text{ALU},1}$ (second ADD in the bundle). The slot is available ($F_{\\text{ALU},1} \\le 2$).\n\n- Total conflicts in Cycle $2$: $2$.\n\n- Update slot occupancy:\n  - $I_6$ issues in $S_{\\text{ALU},0}$ ($O_{\\text{ALU}}=1$). New $F_{\\text{ALU},0} = 2 + 1 = 3$.\n  - $I_8$ issues in $S_{\\text{ALU},1}$ ($O_{\\text{ALU}}=1$). New $F_{\\text{ALU},1} = 2 + 1 = 3$.\n  - $S_{\\text{MUL}}$ remains busy from $I_3$. $F_{\\text{MUL}}$ is still $4$.\n\n**Cycle $3$**\n\nThe next bundle consists of instructions $I_9, I_{10}, I_{11}, I_{12}$.\n- Slot availability at $C=3$:\n  - $F_{\\text{ALU},0} = 3$ (Available)\n  - $F_{\\text{ALU},1} = 3$ (Available)\n  - $F_{\\text{MUL}} = 4$ (Unavailable)\n  - $F_{\\text{MEM}} = 2$ (Available)\n\n- Naive assignment attempts:\n  - $I_9$ (ST) targets $S_{\\text{MEM}}$. The slot is available ($F_{\\text{MEM}} \\le 3$).\n  - $I_{10}$ (ADD) targets $S_{\\text{ALU},0}$. The slot is available ($F_{\\text{ALU},0} \\le 3$).\n  - $I_{11}$ (ADD) targets $S_{\\text{ALU},1}$. The slot is available ($F_{\\text{ALU},1} \\le 3$).\n  - $I_{12}$ (ADD) is the third ALU-type instruction. The naive policy attempts to map it to an ALU slot. However, $S_{\\text{ALU},0}$ and $S_{\\text{ALU},1}$ are already targeted by $I_{10}$ and $I_{11}$ in this same cycle. This is an over-subscription of ALU slots. This constitutes **$1$ conflict**.\n\n- Total conflicts in Cycle $3$: $1$.\n\n- Update slot occupancy:\n  - $I_9$ issues in $S_{\\text{MEM}}$ ($O_{\\text{MEM}}=1$). New $F_{\\text{MEM}} = 3 + 1 = 4$.\n  - $I_{10}$ issues in $S_{\\text{ALU},0}$ ($O_{\\text{ALU}}=1$). New $F_{\\text{ALU},0} = 3 + 1 = 4$.\n  - $I_{11}$ issues in $S_{\\text{ALU},1}$ ($O_{\\text{ALU}}=1$). New $F_{\\text{ALU},1} = 3 + 1 = 4$.\n  - $S_{\\text{MUL}}$ remains busy. $F_{\\text{MUL}}$ is still $4$.\n\n**Cycle $4$**\n\nThe final bundle consists of the last instruction, $I_{13}$.\n- Slot availability at $C=4$:\n  - $F_{\\text{ALU},0} = 4$ (Available)\n  - $F_{\\text{ALU},1} = 4$ (Available)\n  - $F_{\\text{MUL}} = 4$ (Available)\n  - $F_{\\text{MEM}} = 4$ (Available)\n\n- Naive assignment attempts:\n  - $I_{13}$ (ADD) targets $S_{\\text{ALU},0}$. The slot is available ($F_{\\text{ALU},0} \\le 4$). No conflict.\n\n- Total conflicts in Cycle $4$: $0$.\n\n**Total Conflicts**\n\nSumming the conflicts from each cycle:\nTotal Conflicts = (Conflicts in Cycle $1$) + (Conflicts in Cycle $2$) + (Conflicts in Cycle $3$) + (Conflicts in Cycle $4$)\nTotal Conflicts = $1 + 2 + 1 + 0 = 4$.\n\nThe naive bundling policy would result in a total of $4$ bundle conflicts.",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "Achieving high throughput on VLIW architectures hinges on effectively parallelizing loops, a task accomplished through a technique called software pipelining or modulo scheduling. This practice guides you through the process of optimizing a loop kernel, starting with the identification of resource and recurrence constraints to determine the minimum initiation interval ($II$). You will then perform a standard optimization—loop-invariant code motion—and reschedule the loop to see how this impacts performance and the subsequent demand for registers, a critical resource in highly parallel code .",
            "id": "3681186",
            "problem": "A statically scheduled Very Long Instruction Word (VLIW) processor has fully pipelined functional units with the following per-cycle availability and latencies: one memory load/store unit per cycle (latency to produce a register result is $3$ cycles), one integer multiplier per cycle (latency $2$ cycles), and two integer adders per cycle (latency $1$ cycle). Consider the loop below, where all arrays are non-aliasing, memory is single-ported only through the single load/store unit, and all operations are independent except as shown by data dependences. The program variable $acc$ is initialized before the loop and accumulates across iterations. The array element $K[0]$ is read in every iteration, even though it is loop-invariant.\n\nFor iteration index $i \\in \\{0,1,\\dots,N-1\\}$, the loop body is:\n- $t_A \\leftarrow \\text{load } A[i]$\n- $t_B \\leftarrow \\text{load } B[i]$\n- $k \\leftarrow \\text{load } K[0]$\n- $s_1 \\leftarrow t_A + k$\n- $p \\leftarrow s_1 \\times t_B$\n- $acc \\leftarrow p + acc$\n\nAssume there are no other instructions in the loop, and ignore prologue/epilogue effects; analyze the steady-state modulo-scheduled kernel only. You are to perform two transformations: first, perform loop-invariant code motion to hoist the load of $K[0]$ out of the loop, keeping its value in a non-rotating scalar register thereafter; second, reschedule the loop using modulo scheduling to minimize the initiation interval (II) subject to the given resource and dependence constraints. Treat the per-iteration temporaries and the loop-carried accumulator as allocated from a rotating register file of size $R$, and treat the invariant $k$ after hoisting as a non-rotating scalar that does not consume rotating registers.\n\nStarting from core definitions of resource-constrained and recurrence-constrained initiation intervals, and the notion of value lifetimes within a modulo schedule, do the following:\n- Determine the minimal achievable initiation interval before the transformation and after hoisting and rescheduling.\n- For each of the two schedules, construct a feasible modulo schedule (slot assignments modulo the II with integer stage offsets) that respects latencies and resources, and from it determine the per-value lifetime in cycles from producer issue to last consumer issue within the steady-state kernel.\n- Using the lifetimes and the chosen II, determine the number of simultaneously live instances required for each temporary value in the rotating register file; the total rotating-register demand is the sum over values of the ceiling of the lifetime divided by the II.\n- Report the reduction in the initiation interval due to hoisting and rescheduling, and the number of unused rotating registers in the final (after-transformation) kernel as a function of $R$.\n\nExpress your final answer as a row matrix with two entries: the initiation-interval reduction and the number of unused rotating registers in the final kernel, in terms of $R$. No rounding is required.",
            "solution": "We begin from two core, widely accepted definitions used in modulo scheduling for Very Long Instruction Word architectures:\n\n1. The resource-constrained initiation interval, denoted $II_{Res}$, is bounded below by the maximum, over each functional unit class, of the per-iteration demand divided by the per-cycle capacity, rounded up to the next integer.\n\n2. The recurrence-constrained initiation interval, denoted $II_{Rec}$, is bounded below by the maximum, over all loop-carried dependence cycles, of the total latency along the cycle divided by the distance (in iterations), rounded up to the next integer.\n\nThe achievable initiation interval is thus bounded below by $II \\ge \\max\\{II_{Res}, II_{Rec}\\}$, and for a fully pipelined issue with integer capacities, we target $II$ equal to that bound by constructing a feasible modulo schedule.\n\nStep 1: Baseline per-iteration resource demands and $II$ before hoisting. In the given loop body per iteration, we have:\n- Memory load/store unit: $3$ loads ($t_A$, $t_B$, $k$), capacity $1$ per cycle, so the memory contribution to $II_{Res}$ is $\\lceil 3/1 \\rceil = 3$.\n- Integer multiplier: $1$ multiply ($p \\leftarrow s_1 \\times t_B$), capacity $1$ per cycle, contribution $\\lceil 1/1 \\rceil = 1$.\n- Integer adders: $2$ adds ($s_1 \\leftarrow t_A + k$ and $acc \\leftarrow p + acc$), capacity $2$ per cycle, contribution $\\lceil 2/2 \\rceil = 1$.\n\nThus $II_{Res, \\text{before}} = \\max\\{3, 1, 1\\} = 3$.\n\nFor loop-carried recurrences, the only explicit recurrence is the accumulator: $acc$ flows from iteration $i-1$ into the addition in iteration $i$. The recurrence cycle comprises the addition that produces $acc$ with latency $1$ cycle and a distance of $1$ iteration, hence $II_{Rec} = \\lceil 1/1 \\rceil = 1$. There are no memory-carried dependences by assumption of non-aliasing and per-iteration independent array elements.\n\nTherefore, before hoisting, $II_{\\text{before}} = \\max\\{II_{Res}, II_{Rec}\\} = \\max\\{3, 1\\} = 3$.\n\nStep 2: Feasible modulo schedule before hoisting and steady-state lifetimes. We choose a modulo schedule with slots modulo $II=3$ labeled $0,1,2$, and assign stage offsets (multiples of $II$) to satisfy latencies and resource constraints. Let the issue times for iteration $i$ be absolute time $T = \\text{slot} + 3 \\times \\text{stage} + 3i$. One feasible assignment is:\n- $t_A \\leftarrow \\text{load } A[i]$: slot $0$, stage $0$; $T = 0 + 0 + 3i$.\n- $t_B \\leftarrow \\text{load } B[i]$: slot $1$, stage $0$; $T = 1 + 0 + 3i$.\n- $k \\leftarrow \\text{load } K[0]$: slot $2$, stage $0$; $T = 2 + 0 + 3i$.\n- $s_1 \\leftarrow t_A + k$: slot $2$, stage $1$; $T = 2 + 3 + 3i = 5 + 3i$. The operands are ready no earlier than $3 + 3i$ (from $t_A$ with latency $3$) and $5 + 3i$ (from $k$), so issuing at $5 + 3i$ is valid. Two adders per cycle allow two adds in slot $2$.\n- $p \\leftarrow s_1 \\times t_B$: slot $0$, stage $2$; $T = 0 + 6 + 3i = 6 + 3i$, respecting that $s_1$ is issued at $5 + 3i$ with latency $1$ (ready at $6 + 3i$) and $t_B$ is ready at $1 + 3 + 3i = 4 + 3i$.\n- $acc \\leftarrow p + acc$: slot $2$, stage $2$; $T = 2 + 6 + 3i = 8 + 3i$, respecting that $p$ is issued at $6 + 3i$ with latency $2$ (ready at $8 + 3i$). The recurrence to the next iteration’s $acc$ consumes this value at $8 + 3 (i+1) = 11 + 3i$, which is at least one cycle after production considering the $1$-cycle latency and $3$-cycle separation between iterations in the kernel.\n\nThis assignment satisfies per-slot capacities: slot $0$ has one load and one multiply, slot $1$ has one load, slot $2$ has two adds and one load, which is permissible because there are two adders and one memory unit, and the multiply is not in slot $2$.\n\nFrom these issue times, compute per-value lifetimes as the time from producer issue to consumer issue in the steady-state kernel:\n- $t_A$: produced at $0 + 3i$, used by $s_1$ at $5 + 3i$; lifetime $\\ell_{t_A} = (5 + 3i) - (0 + 3i) = 5$ cycles.\n- $t_B$: produced at $1 + 3i$, used by multiply at $6 + 3i$; lifetime $\\ell_{t_B} = 5$ cycles.\n- $k$ (before hoisting): produced at $2 + 3i$, used by $s_1$ at $5 + 3i$; lifetime $\\ell_{k} = 3$ cycles.\n- $s_1$: produced at $5 + 3i$, used by multiply at $6 + 3i$; lifetime $\\ell_{s_1} = 1$ cycle.\n- $p$: produced at $6 + 3i$, used by $acc$ at $8 + 3i$; lifetime $\\ell_{p} = 2$ cycles.\n- $acc$ recurrence instance: produced at $8 + 3 (i-1)$, used at $8 + 3i$; lifetime $\\ell_{acc} = 3$ cycles.\n\nThe number of simultaneously live instances for each value in the rotating register file equals the number of overlapping instances across iterations, which is given by $\\left\\lceil \\frac{\\ell}{II} \\right\\rceil$ for lifetime $\\ell$ under the modulo schedule. With $II=3$:\n- $t_A$: $\\left\\lceil \\frac{5}{3} \\right\\rceil = 2$.\n- $t_B$: $\\left\\lceil \\frac{5}{3} \\right\\rceil = 2$.\n- $k$: $\\left\\lceil \\frac{3}{3} \\right\\rceil = 1$.\n- $s_1$: $\\left\\lceil \\frac{1}{3} \\right\\rceil = 1$.\n- $p$: $\\left\\lceil \\frac{2}{3} \\right\\rceil = 1$.\n- $acc$: $\\left\\lceil \\frac{3}{3} \\right\\rceil = 1$.\n\nThus the total rotating-register demand before hoisting is $2 + 2 + 1 + 1 + 1 + 1 = 8$ registers.\n\nStep 3: After hoisting $k$ and rescheduling, recompute $II$ and lifetimes. Hoisting removes the invariant load from the loop. Per-iteration demands become:\n- Memory load/store unit: $2$ loads ($t_A$, $t_B$) per iteration, capacity $1$, contributing $\\lceil 2/1 \\rceil = 2$.\n- Integer multiplier: $1$ per iteration, contributing $\\lceil 1/1 \\rceil = 1$.\n- Integer adders: $2$ per iteration, contributing $\\lceil 2/2 \\rceil = 1$.\n\nTherefore $II_{Res, \\text{after}} = \\max\\{2, 1, 1\\} = 2$. The recurrence on $acc$ is unchanged, $II_{Rec} = 1$. Hence the minimal initiation interval after hoisting is $II_{\\text{after}} = \\max\\{2, 1\\} = 2$.\n\nConstruct a feasible modulo schedule with slots modulo $2$ labeled $0,1$, and absolute issue time $T = \\text{slot} + 2 \\times \\text{stage} + 2i$ for iteration $i$:\n- $t_A \\leftarrow \\text{load } A[i]$: slot $0$, stage $0$; $T = 0 + 0 + 2i = 0 + 2i$.\n- $t_B \\leftarrow \\text{load } B[i]$: slot $1$, stage $0$; $T = 1 + 0 + 2i = 1 + 2i$.\n- $s_1 \\leftarrow t_A + k$: slot $1$, stage $1$; $T = 1 + 2 + 2i = 3 + 2i$, respecting that $t_A$ is issued at $0 + 2i$ with latency $3$ (ready at $3 + 2i$), and $k$ is available as a non-rotating scalar with no in-kernel producing latency.\n- $p \\leftarrow s_1 \\times t_B$: slot $0$, stage $2$; $T = 0 + 4 + 2i = 4 + 2i$, respecting that $s_1$ is issued at $3 + 2i$ with latency $1$ (ready at $4 + 2i$) and $t_B$ is ready at $1 + 3 + 2i = 4 + 2i$.\n- $acc \\leftarrow p + acc$: slot $0$, stage $3$; $T = 0 + 6 + 2i = 6 + 2i$, respecting that $p$ is issued at $4 + 2i$ with latency $2$ (ready at $6 + 2i$). The recurrence to iteration $i+1$ consumes at $6 + 2 (i+1) = 8 + 2i$, safely after production considering the $1$-cycle latency and $2$-cycle separation per iteration.\n\nPer-slot capacities are respected: slot $0$ has one load, one multiply, and one add; slot $1$ has one load and one add; the capacities match the one memory unit, one multiplier, and two adders per cycle.\n\nCompute lifetimes after hoisting from producer issue to consumer issue:\n- $t_A$: produced at $0 + 2i$, used by $s_1$ at $3 + 2i$; lifetime $\\ell'_{t_A} = 3$ cycles.\n- $t_B$: produced at $1 + 2i$, used by multiply at $4 + 2i$; lifetime $\\ell'_{t_B} = 3$ cycles.\n- $s_1$: produced at $3 + 2i$, used by multiply at $4 + 2i$; lifetime $\\ell'_{s_1} = 1$ cycle.\n- $p$: produced at $4 + 2i$, used by $acc$ at $6 + 2i$; lifetime $\\ell'_{p} = 2$ cycles.\n- $acc$ recurrence instance: produced at $6 + 2 (i-1) = 4 + 2i$, used at $6 + 2i$; lifetime $\\ell'_{acc} = 2$ cycles.\n\nThe invariant $k$ no longer consumes a rotating register because it is hoisted and stored in a non-rotating scalar register.\n\nWith $II=2$, the number of simultaneously live instances per value equals $\\left\\lceil \\frac{\\ell'}{2} \\right\\rceil$:\n- $t_A$: $\\left\\lceil \\frac{3}{2} \\right\\rceil = 2$.\n- $t_B$: $\\left\\lceil \\frac{3}{2} \\right\\rceil = 2$.\n- $s_1$: $\\left\\lceil \\frac{1}{2} \\right\\rceil = 1$.\n- $p$: $\\left\\lceil \\frac{2}{2} \\right\\rceil = 1$.\n- $acc$: $\\left\\lceil \\frac{2}{2} \\right\\rceil = 1$.\n\nThus the total rotating-register demand after hoisting is $2 + 2 + 1 + 1 + 1 = 7$ registers.\n\nStep 4: Requested quantities. The reduction in initiation interval equals $II_{\\text{before}} - II_{\\text{after}} = 3 - 2 = 1$. For a rotating register file of size $R$, the number of unused rotating registers in the final kernel equals $R - 7$.\n\nTherefore, the requested pair is the row matrix with entries $1$ and $R - 7$.",
            "answer": "$$\\boxed{\\begin{pmatrix}1 & R-7\\end{pmatrix}}$$"
        },
        {
            "introduction": "A key challenge for statically scheduled architectures is handling events with unpredictable latency, such as memory cache misses. While a compiler must assume fixed latencies to create a schedule, real-world performance is dictated by how the system responds when those assumptions are violated. This exercise explores this tension by asking you to quantify the performance impact of a variable-latency memory load using expected value analysis, a fundamental tool for performance modeling that connects architectural behavior with probabilistic outcomes .",
            "id": "3681193",
            "problem": "A Very Long Instruction Word (VLIW) processor is a statically scheduled, multiple-issue architecture in which the compiler decides the issue grouping of operations into a fixed-width instruction word. In such machines, a memory load with variable latency can create pipeline bubbles when its latency exceeds the number of independent instructions scheduled to cover it. Consider a $4$-wide VLIW processor and a loop body that contains a single critical memory load whose result is used by a dependent arithmetic chain. The compiler schedules $A=6$ cycles of independent work after the load before the first dependent instruction, and inserts $C_{g}=2$ cycles of guard operations to enforce control/speculation checks associated with the load; these guard cycles occupy issue cycles that cannot be overlapped with useful work and are therefore counted as waste. The load has hit latency $L_{\\text{hit}}=4$ cycles, and on a hit no stall occurs because $L_{\\text{hit}} \\leq A$. On a miss, the latency $L_{\\text{miss}}$ is a random variable that takes the value $20$ cycles with probability $q=0.65$ (representing a level-two cache service) and $60$ cycles with probability $1-q=0.35$ (representing main memory service). The probability that the load misses is $p_{m}=0.16$, independently across iterations.\n\nDefine the cycle waste per iteration as the sum of the always-incurred guard cycles and any residual stall cycles that arise when the load latency exceeds the $A$ cycles of independent work. Under these assumptions and using the base facts of static scheduling and latency-driven dependence timing in VLIW pipelines, compute the expected cycle waste per iteration. Express your final answer in cycles and round your answer to four significant figures.",
            "solution": "The problem requires the calculation of the expected cycle waste per iteration in a statically scheduled a Very Long Instruction Word (VLIW) processor. The first step is to validate the problem statement.\n\n**Step 1: Extract Givens**\n- VLIW processor issue width: $4$\n- Independent work cycles scheduled to hide load latency: $A=6$ cycles\n- Guard operation cycles per iteration: $C_g=2$ cycles\n- Load hit latency: $L_{\\text{hit}}=4$ cycles\n- Load miss probability: $p_{m}=0.16$\n- Load miss latency, Level-2 cache service: $L_{\\text{miss,1}}=20$ cycles\n- Conditional probability of L2 cache service, given a miss: $q=0.65$\n- Load miss latency, main memory service: $L_{\\text{miss,2}}=60$ cycles\n- Conditional probability of main memory service, given a miss: $1-q=0.35$\n- Definition of cycle waste per iteration: $W = C_g + S$, where $S$ is the number of residual stall cycles.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, belonging to the field of computer organization and architecture, specifically performance analysis of instruction-level parallelism. All concepts used—VLIW architecture, static scheduling, memory hierarchy latency, pipeline stalls, and expected value—are standard and well-defined. The problem is objective, presenting data and definitions without subjective language. The setup is self-contained, providing all necessary parameters for the calculation. The given values are consistent; for example, the statement that a load hit ($L_{\\text{hit}}=4$) causes no stall is consistent with the amount of scheduled independent work ($A=6$), since $4 \\le 6$. The probabilistic model for memory latency is well-posed; the conditional probabilities for miss service sum to $1$ ($0.65 + 0.35 = 1$), and the overall event space (hit vs. miss) is complete. The problem is formally structured to have a unique, meaningful solution. Thus, it passes all validity checks.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A formal solution will be derived.\n\nThe expected cycle waste per iteration, $E[W]$, is the quantity of interest. The problem defines the total waste $W$ in a single iteration as the sum of the constant guard cycle overhead $C_g$ and the variable residual stall cycles $S$.\n$$W = C_g + S$$\nUsing the linearity of the expectation operator, the expected total waste is:\n$$E[W] = E[C_g + S] = E[C_g] + E[S]$$\nSince $C_g$ is a constant with the value $2$, its expected value is $E[C_g] = 2$. The problem thus reduces to finding the expected number of stall cycles, $E[S]$.\n$$E[W] = 2 + E[S]$$\nStall cycles are incurred when the memory load latency, $L$, is not fully hidden by the $A$ cycles of independent work scheduled by the compiler. The number of stall cycles $S$ is the latency that exceeds $A$.\n$$S = \\max(0, L - A)$$\nGiven $A=6$, the formula for stall cycles is:\n$$S = \\max(0, L - 6)$$\nThe latency $L$ is a random variable, so we must compute the expected value of $S$ by considering all possible latency outcomes and their respective probabilities. The possible outcomes for the load are a cache hit or a cache miss, where a miss can be serviced by either the Level-2 cache or main memory.\n\n1.  **Outcome 1: Cache Hit**\n    The probability of a cache hit is $p_{\\text{hit}} = 1 - p_m$.\n    $$p_{\\text{hit}} = 1 - 0.16 = 0.84$$\n    The latency in this case is $L_{\\text{hit}} = 4$ cycles. The number of stall cycles, $S_{\\text{hit}}$, is:\n    $$S_{\\text{hit}} = \\max(0, L_{\\text{hit}} - A) = \\max(0, 4 - 6) = 0$$\n\n2.  **Outcome 2: Cache Miss, serviced by L2 Cache**\n    This is a compound event. The probability of a miss is $p_m$, and the conditional probability of L2 service is $q$. The joint probability is $P(\\text{miss, L2}) = p_m \\times q$.\n    $$P(\\text{miss, L2}) = 0.16 \\times 0.65 = 0.104$$\n    The latency is $L_{\\text{miss,1}} = 20$ cycles. The number of stall cycles, $S_{\\text{miss,1}}$, is:\n    $$S_{\\text{miss,1}} = \\max(0, L_{\\text{miss,1}} - A) = \\max(0, 20 - 6) = 14$$\n\n3.  **Outcome 3: Cache Miss, serviced by Main Memory**\n    The probability of a miss is $p_m$, and the conditional probability of main memory service is $1-q$. The joint probability is $P(\\text{miss, MM}) = p_m \\times (1-q)$.\n    $$P(\\text{miss, MM}) = 0.16 \\times 0.35 = 0.056$$\n    The latency is $L_{\\text{miss,2}} = 60$ cycles. The number of stall cycles, $S_{\\text{miss,2}}$, is:\n    $$S_{\\text{miss,2}} = \\max(0, L_{\\text{miss,2}} - A) = \\max(0, 60 - 6) = 54$$\n\nThe expected number of stall cycles, $E[S]$, is the sum of the stall cycles for each outcome, weighted by the probability of that outcome.\n$$E[S] = (S_{\\text{hit}} \\times p_{\\text{hit}}) + (S_{\\text{miss,1}} \\times P(\\text{miss, L2})) + (S_{\\text{miss,2}} \\times P(\\text{miss, MM}))$$\nSubstituting the calculated values:\n$$E[S] = (0 \\times 0.84) + (14 \\times 0.104) + (54 \\times 0.056)$$\n$$E[S] = 0 + 1.456 + 3.024$$\n$$E[S] = 4.48$$\nNow, we can compute the total expected cycle waste per iteration, $E[W]$.\n$$E[W] = C_g + E[S] = 2 + 4.48 = 6.48$$\nThe problem requires the answer to be expressed to four significant figures.\n$$E[W] = 6.480$$",
            "answer": "$$\\boxed{6.480}$$"
        }
    ]
}