{
    "hands_on_practices": [
        {
            "introduction": "To truly understand memory disambiguation, we must go beyond abstract concepts and calculate the real-world performance impact. This first practice provides a concrete scenario where a single load instruction requires data from multiple sources: partially from the store queue and partially from the L1 cache, all while spanning a virtual page boundary. By calculating the total latency, you will trace the intricate interplay between store-to-load forwarding, cache access, and the virtual memory system's TLB, revealing how these components collectively determine execution time .",
            "id": "3657275",
            "problem": "A superscalar, out-of-order core implements memory disambiguation with a store queue for a single hardware thread. Virtual memory uses a page size of $P$ bytes, with $P = 4096$. A load of width $w$ bytes at virtual address $A$ spans a page boundary exactly when $A \\bmod P > P - w$. Consider one dynamic instance of a load with $w = 16$ and $A \\bmod P = 4092$, so that the load spans from $A$ to $A + w - 1$ across two consecutive virtual pages, which we denote page $p$ and page $p + 1$. By definition, the bytes accessed on page $p$ are offsets $4092, 4093, 4094, 4095$, and on page $p+1$ are offsets $0, 1, \\dots, 11$.\n\nThere are four older stores in the store queue with known virtual addresses and sizes, all from the same thread and in the following program order from oldest to youngest: $S_3$, $S_1$, $S_4$, $S_2$. Their virtual address offsets and lengths relative to the pages touched by the load are:\n- $S_3$: page $p$, address offset $4088$, length $4$ bytes,\n- $S_1$: page $p$, address offset $4094$, length $2$ bytes,\n- $S_4$: page $p+1$, address offset $0$, length $4$ bytes,\n- $S_2$: page $p+1$, address offset $8$, length $8$ bytes.\n\nThe memory disambiguation and data supply rules are as follows:\n- For each byte of the load that is covered by one or more older stores, the value is forwarded from the youngest covering older store on that byte. If a load must forward from $k$ distinct older stores in total, merging these forwarded slices incurs an additional $k$ cycles of delay.\n- For each page from which the load must fetch any bytes from the Level-1 data cache (L1), the access latency is $L_c = 4$ cycles and is paid once per such page. If all bytes for a page are forwarded from the store queue, the Level-1 data cache (L1) access on that page is suppressed and incurs no latency.\n- Translation Lookaside Buffer (TLB) behavior: the data-side Translation Lookaside Buffer (TLB) has a single lookup port and must provide a translation for a page before the Level-1 data cache (L1) can be accessed for that page. A TLB hit for a page takes $t_h = 1$ cycle; a TLB miss for a page takes $t_m = 13$ cycles (this is the total time to produce the translation for that page). If a page is fully satisfied by store forwarding, its TLB lookup is deferred to retirement and does not contribute to the execution latency of this load.\n- Lookups for the two pages, if both required by the execution of this load, are serialized through the single TLB port and their latencies add. Level-1 data cache (L1) access latencies for the two pages, if both required, also add. The merge delay for forwarded bytes adds after the TLB and Level-1 data cache (L1) latencies. Assume no overlap in time between these components for this problem.\n\nAssume the following events for this dynamic instance:\n- Page $p$’s TLB lookup is a hit.\n- Page $p+1$’s TLB lookup is a miss.\n- Any required Level-1 data cache (L1) accesses hit in the cache.\n\nStarting from the fundamental definitions of range intersection for memory disambiguation and the given execution rules, determine the total execution latency in cycles for this load, including TLB, Level-1 data cache (L1), and store-forwarding merge costs dictated by the partial overlap on the two pages. Report a single real-valued number equal to the total cycles. Do not include units in your final boxed answer.",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in the principles of computer architecture, specifically out-of-order execution and memory disambiguation. The problem is well-posed, providing a self-contained and consistent set of rules and data that allows for the derivation of a unique, meaningful solution. All terms are clearly defined, and the premises are factually sound within the established model of the hypothetical processor.\n\nThe task is to compute the total execution latency for a specific load instruction. This latency is the sum of three components as defined by the problem: the Translation Lookaside Buffer (TLB) latency, the Level-1 (L1) data cache access latency, and the store-forwarding merge delay. We will analyze the memory accesses on each of the two affected virtual pages to determine the contribution to each latency component.\n\nFirst, we establish the address ranges for the load and the stores.\nThe page size is $P = 4096$ bytes.\nThe load has a width $w = 16$ bytes, starting at a virtual address $A$ such that $A \\bmod P = 4092$.\nThe load accesses bytes from address $A$ to $A + w - 1 = A + 15$.\nThis access spans two pages, which we denote as $p$ and $p+1$.\n- On page $p$, the load accesses bytes at offsets $[4092, 4095]$. This is a total of $4$ bytes.\n- On page $p+1$, the load accesses bytes at offsets $[0, 11]$. This is a total of $12$ bytes.\nThe total number of bytes is $4 + 12 = 16$, consistent with the load width $w$.\n\nThe four older stores in program order (oldest to youngest) are $S_3, S_1, S_4, S_2$. Their address ranges are:\n- $S_3$: page $p$, offset $4088$, length $4$. Range of offsets: $[4088, 4091]$.\n- $S_1$: page $p$, offset $4094$, length $2$. Range of offsets: $[4094, 4095]$.\n- $S_4$: page $p+1$, offset $0$, length $4$. Range of offsets: $[0, 3]$.\n- $S_2$: page $p+1$, offset $8$, length $8$. Range of offsets: $[8, 15]$.\n\nNow, we analyze the data sourcing for each page.\n\n**Analysis for Page $p$**\nThe load requires bytes at offsets $[4092, 4095]$ from page $p$. We check for overlaps with older stores on this page.\n- Store $S_3$ occupies offsets $[4088, 4091]$. The intersection with the load's range $[4092, 4095]$ is empty: $[4092, 4095] \\cap [4088, 4091] = \\emptyset$.\n- Store $S_1$ occupies offsets $[4094, 4095]$. The intersection with the load's range is $[4092, 4095] \\cap [4094, 4095] = [4094, 4095]$.\nBased on the store-forwarding rule, the values for bytes at offsets $4094$ and $4095$ will be forwarded from store $S_1$.\nThe bytes at offsets $4092$ and $4093$ are not covered by any older store in the store queue. Therefore, these bytes must be fetched from the memory hierarchy, specifically the L1 data cache.\nSince not all bytes for page $p$ are fully satisfied by store forwarding, an L1 cache access and a preceding TLB lookup for page $p$ are necessary.\n\n**Analysis for Page $p+1$**\nThe load requires bytes at offsets $[0, 11]$ from page $p+1$. We check for overlaps with older stores on this page.\n- Store $S_4$ occupies offsets $[0, 3]$. The intersection with the load's range is $[0, 11] \\cap [0, 3] = [0, 3]$.\n- Store $S_2$ occupies offsets $[8, 15]$. The intersection with the load's range is $[0, 11] \\cap [8, 15] = [8, 11]$.\nThe program order is $S_4$ followed by $S_2$ (i.e., $S_2$ is younger). The affected byte ranges $[0, 3]$ and $[8, 11]$ are disjoint, so there is no conflict where a byte is covered by multiple stores.\n- Bytes at offsets $[0, 3]$ will be forwarded from store $S_4$.\n- Bytes at offsets $[8, 11]$ will be forwarded from store $S_2$.\nThe bytes at offsets $[4, 7]$ are not covered by any older store. These bytes must be fetched from the L1 data cache.\nSince not all bytes for page $p+1$ are fully satisfied by store forwarding, an L1 cache access and a preceding TLB lookup for page $p+1$ are also necessary.\n\nWith this analysis, we can calculate the total latency.\n\n**1. Total TLB Latency**\nA TLB lookup is required for both page $p$ and page $p+1$. The lookups are serialized.\n- The lookup for page $p$ is a hit, taking $t_h = 1$ cycle.\n- The lookup for page $p+1$ is a miss, taking $t_m = 13$ cycles.\nTotal TLB Latency = $t_h + t_m = 1 + 13 = 14$ cycles.\n\n**2. Total L1 Data Cache Latency**\nAn L1 cache access is required for both page $p$ and page $p+1$. The problem states these accesses hit in the cache and their latencies add.\n- The access for page $p$ incurs a latency of $L_c = 4$ cycles.\n- The access for page $p+1$ incurs a latency of $L_c = 4$ cycles.\nTotal L1 Cache Latency = $L_c + L_c = 4 + 4 = 8$ cycles.\n\n**3. Store-Forwarding Merge Delay**\nThe merge delay is $k$ cycles, where $k$ is the total number of distinct older stores from which the load forwards data.\n- From page $p$, data is forwarded from store $S_1$.\n- From page $p+1$, data is forwarded from stores $S_4$ and $S_2$.\nThe set of distinct forwarding stores is $\\{S_1, S_2, S_4\\}$.\nThe number of distinct stores is $k = 3$.\nStore-Forwarding Merge Delay = $k = 3$ cycles.\n\n**4. Total Execution Latency**\nThe total latency is the sum of the non-overlapped components.\nTotal Latency = (Total TLB Latency) + (Total L1 Cache Latency) + (Store-Forwarding Merge Delay)\nTotal Latency = $14 + 8 + 3 = 25$ cycles.\n\nThe total execution latency for this load is $25$ cycles.",
            "answer": "$$\\boxed{25}$$"
        },
        {
            "introduction": "Speculative execution is a powerful technique, but it comes with the risk of misprediction. This exercise explores the consequences of such a failure in memory disambiguation, focusing on the recovery process. You will analyze a snapshot of a Load-Store Queue (LSQ) at the exact moment a memory ordering violation is detected and apply a specific hardware recovery policy. This practice demonstrates how a single incorrect speculation can trigger a \"replay\" of multiple subsequent instructions, highlighting the significant performance penalty associated with misprediction and the importance of accurate dependence predictors .",
            "id": "3664944",
            "problem": "A superscalar out-of-order core enforces in-order retirement and implements a Load-Store Queue (LSQ) to maintain memory ordering between loads and stores. The LSQ depth is $D=16$. The machine permits speculative memory disambiguation: younger loads may issue even when there exist older stores with unresolved addresses. The core uses store-to-load forwarding from the store buffer when a load’s effective address matches an older store’s address. On a misprediction of memory dependence (for example, a younger load is allowed to issue despite an older unresolved store actually aliasing it), the core employs a global load replay policy: when the violating older store’s address resolves and a conflict is detected, all loads younger than that store that have already executed their memory accesses are squashed and reissued.\n\nConsider the following program-order sequence of memory operations currently resident in the Load-Store Queue (LSQ) at the instant an older store resolves its address and a conflict is detected. Indices increase with program order; index $0$ is the oldest entry and index $13$ is the youngest entry. The LSQ occupancy is thus $14$, which is within the depth $D=16$. Each operation is annotated with its type and its effective address symbol. At the instant of detection, every listed load has already executed its memory access.\n\nIndex $0$: $S_{0}$ writes $A$ (address of $S_{0}$ is resolved when inserted).  \nIndex $1$: $L_{1}$ reads $A$ (executed; forwarded correctly from $S_{0}$).  \nIndex $2$: $L_{2}$ reads $B$ (executed; no alias with $S_{0}$).  \nIndex $3$: $S_{1}$ writes an initially unresolved address that later resolves to $A$ (this is the violating store).  \nIndex $4$: $L_{3}$ reads $A$ (issued speculatively; memory dependence predictor claimed “no alias” with $S_{1}$; forwarded from $S_{0}$, which is incorrect because $S_{1}$ is older and should supply the value).  \nIndex $5$: $L_{4}$ reads $C$ (executed).  \nIndex $6$: $S_{2}$ writes $D$.  \nIndex $7$: $L_{5}$ reads $E$ (executed).  \nIndex $8$: $L_{6}$ reads $F$ (executed).  \nIndex $9$: $S_{3}$ writes $G$.  \nIndex $10$: $L_{7}$ reads $H$ (executed).  \nIndex $11$: $L_{8}$ reads $I$ (executed).  \nIndex $12$: $S_{4}$ writes $J$.  \nIndex $13$: $L_{9}$ reads $K$ (executed).\n\nDefine the replay window $W_{r}$ to be the count of younger loads that must be squashed and reissued when the misprediction is detected for $S_{1}$ at index $3$. Compute $W_{r}$ using the provided LSQ depth $D$ and the program-order memory sequence. Express your answer as an exact integer with no units.",
            "solution": "The problem will first be validated for scientific soundness, self-consistency, and clarity.\n\n### Step 1: Extract Givens\n- **Core Architecture**: Superscalar, out-of-order execution, in-order retirement.\n- **Load-Store Queue (LSQ)**: Depth $D=16$.\n- **Memory Disambiguation**: Speculative; younger loads may issue before older stores with unresolved addresses resolve.\n- **Forwarding**: Store-to-load forwarding is implemented.\n- **Misprediction Recovery Policy**: A global load replay policy is used. Upon detection of a memory dependence misprediction (i.e., a younger load incorrectly executed before an older, aliasing store's address was known), the core squashes and reissues **all loads younger than the violating store** that have already executed their memory accesses.\n- **Violating Store**: $S_{1}$ at index $3$. It initially had an unresolved address, which has now resolved to address $A$, revealing a conflict with the speculatively executed load $L_3$.\n- **LSQ State**: A sequence of $14$ memory operations (indices $0$ to $13$) is present in the LSQ.\n- **Execution Status**: At the moment the misprediction is detected, every listed load has already executed its memory access.\n- **Memory Operations Sequence**:\n    - Index $0$: Store $S_{0}$ to address $A$.\n    - Index $1$: Load $L_{1}$ from address $A$.\n    - Index $2$: Load $L_{2}$ from address $B$.\n    - Index $3$: Store $S_{1}$ to address $A$ (this is the violating store).\n    - Index $4$: Load $L_{3}$ from address $A$.\n    - Index $5$: Load $L_{4}$ from address $C$.\n    - Index $6$: Store $S_{2}$ to address $D$.\n    - Index $7$: Load $L_{5}$ from address $E$.\n    - Index $8$: Load $L_{6}$ from address $F$.\n    - Index $9$: Store $S_{3}$ to address $G$.\n    - Index $10$: Load $L_{7}$ from address $H$.\n    - Index $11$: Load $L_{8}$ from address $I$.\n    - Index $12$: Store $S_{4}$ to address $J$.\n    - Index $13$: Load $L_{9}$ from address $K$.\n- **Objective**: Compute the replay window, $W_{r}$, defined as the count of younger loads that must be squashed and reissued.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is valid.\n- **Scientifically Grounded**: The scenario described is a standard and fundamental problem in the design of high-performance, out-of-order microprocessors. Concepts such as the Load-Store Queue (LSQ), speculative memory disambiguation, store-to-load forwarding, and memory ordering violation detection and recovery are central topics in computer architecture. The \"global load replay\" policy is a valid, albeit simple, hardware implementation strategy for recovery.\n- **Well-Posed**: The problem is clearly defined. It specifies the exact recovery policy to be applied and provides the complete state of the relevant portion of the LSQ at the moment of misprediction detection. The question asks for a single, computable integer value, $W_{r}$, based on these precise conditions.\n- **Objective**: The problem is stated using precise, technical terminology from the field of computer architecture, with no subjective or ambiguous language.\n\nThe problem requires a direct application of the stated rules to the given data set. It is self-contained, consistent, and scientifically sound.\n\n### Step 3: Proceed to Solution\nThe problem is valid and a solution will be provided.\n\nThe core of the problem lies in the strict application of the specified memory dependence misprediction recovery policy. The policy is explicitly defined as a **global load replay**. It states: \"...when the violating older store’s address resolves and a conflict is detected, all loads younger than that store that have already executed their memory accesses are squashed and reissued.\"\n\nLet us dissect this policy and apply it to the provided LSQ state.\n\n1.  **Identify the Violating Store**: The problem identifies the store operation at index $3$, denoted as $S_{1}$, as the \"violating store\". This instruction serves as the reference point in program order.\n\n2.  **Identify Younger Instructions**: The policy concerns \"all loads younger than that store\". In the context of the LSQ, which maintains program order, \"younger\" instructions are those with a higher index. Therefore, we must consider all instructions with an index greater than $3$. These are the instructions from index $4$ to index $13$.\n\n3.  **Filter for Loads**: The policy specifically applies to \"loads\" only. We must enumerate all the `Load` operations within the identified window of younger instructions (indices $4$ through $13$).\n    - Index $4$: $L_{3}$ (Load)\n    - Index $5$: $L_{4}$ (Load)\n    - Index $6$: $S_{2}$ (Store) - Excluded\n    - Index $7$: $L_{5}$ (Load)\n    - Index $8$: $L_{6}$ (Load)\n    - Index $9$: $S_{3}$ (Store) - Excluded\n    - Index $10$: $L_{7}$ (Load)\n    - Index $11$: $L_{8}$ (Load)\n    - Index $12$: $S_{4}$ (Store) - Excluded\n    - Index $13$: $L_{9}$ (Load)\n\n4.  **Confirm Execution Status**: The policy applies to loads that \"have already executed their memory accesses\". The problem statement explicitly confirms this condition: \"At the instant of detection, every listed load has already executed its memory access.\" Therefore, all the loads identified in the previous step satisfy this condition and must be squashed.\n\n5.  **Compute the Replay Window $W_{r}$**: The replay window $W_{r}$ is the total count of loads that must be squashed and reissued. Based on the enumeration in step 3, these loads are $L_{3}$, $L_{4}$, $L_{5}$, $L_{6}$, $L_{7}$, $L_{8}$, and $L_{9}$.\n\nCounting these loads gives:\n$$W_{r} = 7$$\n\nThe load $L_{3}$ is the specific instruction whose speculative execution was incorrect (it was forwarded a value from $S_{0}$ when it should have received the new value from $S_{1}$). However, the \"global\" nature of the replay policy means that the recovery action is not limited to just $L_{3}$. All other loads that are younger in program order than the violating store $S_{1}$ are also caught in the replay, regardless of whether they themselves had a data dependency on $S_{1}$. The loads $L_{1}$ and $L_{2}$ are older than $S_{1}$ and are therefore unaffected. The LSQ depth $D=16$ is extraneous information, as the occupancy and state are fully specified.",
            "answer": "$$\\boxed{7}$$"
        },
        {
            "introduction": "Moving from individual instances to a more general understanding, this final practice challenges you to think like a processor architect by modeling performance analytically. Instead of tracing a single load, you will derive a mathematical expression for the expected number of stall cycles for a given pattern of loads and stores. By quantifying the \"overlap density\" and expected stalls based on architectural parameters, this exercise bridges the gap between the low-level mechanics of aliasing and the high-level performance analysis needed to design more efficient processors .",
            "id": "3657255",
            "problem": "Consider an out-of-order execution core with a store buffer that enforces memory disambiguation for loads relative to older stores. A program fragment performs stores to consecutive byte addresses $A+i$ for integer offsets $i \\in \\{0,1,\\dots,k\\}$, followed (in program order) by loads from consecutive byte addresses $A+j$ for integer offsets $j \\in \\{k/2,k/2+1,\\dots,3k/2\\}$. Assume $k$ is a positive even integer so that all bounds are integers. The base address $A$ is shared and known for the fragment.\n\nFundamental definitions:\n- A load and store are said to alias if they target the same byte address, that is, their effective addresses are equal.\n- Conservative memory disambiguation requires that a younger load not issue before the addresses of all possibly aliasing older stores are known; if a younger load is predicted independent of older stores but the unique older store to the same address has not yet computed its address by the time the load reaches the issue stage, the load stalls until the store’s address becomes known.\n- Let $r \\in [0,1]$ denote the probability that, when a given load reaches the issue stage, the unique older store to the same address (if it exists in the fragment) has already resolved its address. Let $c > 0$ denote the stall penalty in cycles incurred by a load if it must wait for that unique older store’s address. Assume independence across loads for the resolution event.\n\nDefine the overlap density $D(k)$ as the fraction of the loads in the fragment whose addresses alias with at least one store in the fragment, that is, using sets $S=\\{A+i \\mid i \\in \\{0,1,\\dots,k\\}\\}$ and $L=\\{A+j \\mid j \\in \\{k/2,k/2+1,\\dots,3k/2\\}\\}$, define $D(k)=\\frac{|S \\cap L|}{|L|}$.\n\nDefine the expected total stall cycles $E(k,r,c)$ for the loads in the fragment under the conservative memory disambiguation policy described above. Assume there is at most one store to any given address in $S$.\n\nCompute $D(k)$ and $E(k,r,c)$ in closed form. Express $E(k,r,c)$ in cycles. Provide both results as analytic expressions. No rounding is required.",
            "solution": "The problem is scientifically sound, well-posed, and requires the derivation of two quantities, the overlap density $D(k)$ and the expected total stall cycles $E(k,r,c)$, based on a set of clearly defined architectural rules and program behavior.\n\n### Part 1: Calculation of Overlap Density $D(k)$\n\nThe overlap density $D(k)$ is defined as the fraction of loads that alias with at least one store. The formula is given as $D(k)=\\frac{|S \\cap L|}{|L|}$, where $S$ and $L$ are the sets of addresses accessed by the stores and loads, respectively.\n\n1.  **Characterize the address sets**:\n    The store addresses are given by the set $S = \\{A+i \\mid i \\in \\{0, 1, \\dots, k\\}\\}$.\n    The load addresses are given by the set $L = \\{A+j \\mid j \\in \\{k/2, k/2+1, \\dots, 3k/2\\}\\}$.\n    Since the base address $A$ is common, we can analyze the intersection based on the integer offset sets. Let $I_S = \\{0, 1, \\dots, k\\}$ and $I_L = \\{k/2, k/2+1, \\dots, 3k/2\\}$. The intersection of address sets $S \\cap L$ corresponds to addresses $A+x$ where $x \\in I_S \\cap I_L$.\n\n2.  **Calculate the size of the load set, $|L|$**:\n    The number of elements in the set $L$ (or equivalently, $I_L$) is the number of integers in the range $[k/2, 3k/2]$.\n    $|L| = |I_L| = \\left(\\frac{3k}{2} - \\frac{k}{2}\\right) + 1 = k + 1$.\n\n3.  **Calculate the size of the intersection, $|S \\cap L|$**:\n    We need to find the number of elements in the intersection of the integer sets $I_S = [0, k]$ and $I_L = [k/2, 3k/2]$.\n    The intersection is the range $[\\max(0, k/2), \\min(k, 3k/2)]$.\n    Since $k$ is a positive even integer, $k/2 \\ge 0$. Also, $k \\le 3k/2$.\n    So, the intersection is the range $[k/2, k]$.\n    The number of integers in this range is $|S \\cap L| = |I_S \\cap I_L| = \\left(k - \\frac{k}{2}\\right) + 1 = \\frac{k}{2} + 1$.\n    We can write this as $\\frac{k+2}{2}$.\n\n4.  **Compute $D(k)$**:\n    Substituting the sizes into the definition of $D(k)$:\n    $D(k) = \\frac{|S \\cap L|}{|L|} = \\frac{k/2 + 1}{k+1} = \\frac{(k+2)/2}{k+1} = \\frac{k+2}{2(k+1)}$.\n\n### Part 2: Calculation of Expected Total Stall Cycles $E(k,r,c)$\n\nThe expected total stall cycles $E(k,r,c)$ is the sum of the expected stall cycles for all loads in the fragment.\n\n1.  **Identify conditions for a stall**:\n    A load incurs a stall of $c$ cycles if and only if two conditions are met:\n    a. The load's address aliases with an older store's address.\n    b. The address of that unique older store has not yet resolved (this occurs with probability $1-r$).\n\n2.  **Calculate expected stall for a single load**:\n    - For a load that does *not* alias with a store, the stall probability is $0$.\n    - For a load that *does* alias with a store, the stall probability is $1-r$. The expected stall for this load is $c \\times (1-r)$.\n\n3.  **Calculate total expected stall**:\n    The total expected stall is the sum of the expected stalls over all loads. Since the resolution events are independent, we can multiply the number of aliasing loads by the expected stall per aliasing load.\n    - Number of aliasing loads = $|S \\cap L| = \\frac{k}{2} + 1$.\n    - Expected stall per aliasing load = $c(1-r)$.\n\n    Therefore, the total expected stall cycles for the entire fragment is:\n    $E(k,r,c) = (\\text{Number of aliasing loads}) \\times (\\text{Expected stall per aliasing load})$\n    $E(k,r,c) = \\left(\\frac{k}{2} + 1\\right) \\times c(1-r) = \\frac{c(1-r)(k+2)}{2}$.\n\n### Final Results\n- The overlap density is $D(k) = \\frac{k+2}{2(k+1)}$.\n- The expected total stall cycles is $E(k,r,c) = \\frac{c(1-r)(k+2)}{2}$ cycles.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{k+2}{2(k+1)} & \\frac{c(1-r)(k+2)}{2}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}