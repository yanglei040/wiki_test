{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp the intricacies of memory disambiguation, it is essential to trace a memory operation through the processor's pipeline. This first practice problem simulates the execution of a single, complex load instruction that spans a page boundary, a scenario that stresses the system's capabilities. By calculating the total execution latency, you will see firsthand how an out-of-order core combines data from multiple sources—forwarding from the store queue and fetching from the L1 cache—while also accounting for the delays introduced by virtual memory translation via the TLB. ",
            "id": "3657275",
            "problem": "A superscalar, out-of-order core implements memory disambiguation with a store queue for a single hardware thread. Virtual memory uses a page size of $P$ bytes, with $P = 4096$. A load of width $w$ bytes at virtual address $A$ spans a page boundary exactly when $A \\pmod{P} > P - w$. Consider one dynamic instance of a load with $w = 16$ and $A \\pmod{P} = 4092$, so that the load spans from $A$ to $A + w - 1$ across two consecutive virtual pages, which we denote page $p$ and page $p + 1$. By definition, the bytes accessed on page $p$ are offsets $4092, 4093, 4094, 4095$, and on page $p+1$ are offsets $0, 1, \\dots, 11$.\n\nThere are four older stores in the store queue with known virtual addresses and sizes, all from the same thread and in the following program order from oldest to youngest: $S_3$, $S_1$, $S_4$, $S_2$. Their virtual address offsets and lengths relative to the pages touched by the load are:\n- $S_3$: page $p$, address offset $4088$, length $4$ bytes,\n- $S_1$: page $p$, address offset $4094$, length $2$ bytes,\n- $S_4$: page $p+1$, address offset $0$, length $4$ bytes,\n- $S_2$: page $p+1$, address offset $8$, length $8$ bytes.\n\nThe memory disambiguation and data supply rules are as follows:\n- For each byte of the load that is covered by one or more older stores, the value is forwarded from the youngest covering older store on that byte. If a load must forward from $k$ distinct older stores in total, merging these forwarded slices incurs an additional $k$ cycles of delay.\n- For each page from which the load must fetch any bytes from the Level-1 data cache (L1), the access latency is $L_c = 4$ cycles and is paid once per such page. If all bytes for a page are forwarded from the store queue, the Level-1 data cache (L1) access on that page is suppressed and incurs no latency.\n- Translation Lookaside Buffer (TLB) behavior: the data-side Translation Lookaside Buffer (TLB) has a single lookup port and must provide a translation for a page before the Level-1 data cache (L1) can be accessed for that page. A TLB hit for a page takes $t_h = 1$ cycle; a TLB miss for a page takes $t_m = 13$ cycles (this is the total time to produce the translation for that page). If a page is fully satisfied by store forwarding, its TLB lookup is deferred to retirement and does not contribute to the execution latency of this load.\n- Lookups for the two pages, if both required by the execution of this load, are serialized through the single TLB port and their latencies add. Level-1 data cache (L1) access latencies for the two pages, if both required, also add. The merge delay for forwarded bytes adds after the TLB and Level-1 data cache (L1) latencies. Assume no overlap in time between these components for this problem.\n\nAssume the following events for this dynamic instance:\n- Page $p$’s TLB lookup is a hit.\n- Page $p+1$’s TLB lookup is a miss.\n- Any required Level-1 data cache (L1) accesses hit in the cache.\n\nStarting from the fundamental definitions of range intersection for memory disambiguation and the given execution rules, determine the total execution latency in cycles for this load, including TLB, Level-1 data cache (L1), and store-forwarding merge costs dictated by the partial overlap on the two pages. Report a single real-valued number equal to the total cycles. Do not include units in your final boxed answer.",
            "solution": "The task is to compute the total execution latency for a specific load instruction. This latency is the sum of three components as defined by the problem: the Translation Lookaside Buffer (TLB) latency, the Level-1 (L1) data cache access latency, and the store-forwarding merge delay. We will analyze the memory accesses on each of the two affected virtual pages to determine the contribution to each latency component.\n\nFirst, we establish the address ranges for the load and the stores.\nThe page size is $P = 4096$ bytes.\nThe load has a width $w = 16$ bytes, starting at a virtual address $A$ such that $A \\pmod P = 4092$.\nThe load accesses bytes from address $A$ to $A + w - 1 = A + 15$.\nThis access spans two pages, which we denote as $p$ and $p+1$.\n- On page $p$, the load accesses bytes at offsets $[4092, 4095]$. This is a total of $4$ bytes.\n- On page $p+1$, the load accesses bytes at offsets $[0, 11]$. This is a total of $12$ bytes.\nThe total number of bytes is $4 + 12 = 16$, consistent with the load width $w$.\n\nThe four older stores in program order (oldest to youngest) are $S_3, S_1, S_4, S_2$. Their address ranges are:\n- $S_3$: page $p$, offset $4088$, length $4$. Range of offsets: $[4088, 4091]$.\n- $S_1$: page $p$, offset $4094$, length $2$. Range of offsets: $[4094, 4095]$.\n- $S_4$: page $p+1$, offset $0$, length $4$. Range of offsets: $[0, 3]$.\n- $S_2$: page $p+1$, offset $8$, length $8$. Range of offsets: $[8, 15]$.\n\nNow, we analyze the data sourcing for each page.\n\n**Analysis for Page $p$**\nThe load requires bytes at offsets $[4092, 4095]$ from page $p$. We check for overlaps with older stores on this page.\n- Store $S_3$ occupies offsets $[4088, 4091]$. The intersection with the load's range $[4092, 4095]$ is empty: $[4092, 4095] \\cap [4088, 4091] = \\emptyset$.\n- Store $S_1$ occupies offsets $[4094, 4095]$. The intersection with the load's range is $[4092, 4095] \\cap [4094, 4095] = [4094, 4095]$.\nBased on the store-forwarding rule, the values for bytes at offsets $4094$ and $4095$ will be forwarded from store $S_1$.\nThe bytes at offsets $4092$ and $4093$ are not covered by any older store in the store queue. Therefore, these bytes must be fetched from the memory hierarchy, specifically the L1 data cache.\nSince not all bytes for page $p$ are fully satisfied by store forwarding, an L1 cache access and a preceding TLB lookup for page $p$ are necessary.\n\n**Analysis for Page $p+1$**\nThe load requires bytes at offsets $[0, 11]$ from page $p+1$. We check for overlaps with older stores on this page.\n- Store $S_4$ occupies offsets $[0, 3]$. The intersection with the load's range is $[0, 11] \\cap [0, 3] = [0, 3]$.\n- Store $S_2$ occupies offsets $[8, 15]$. The intersection with the load's range is $[0, 11] \\cap [8, 15] = [8, 11]$.\nThe program order is $S_4$ followed by $S_2$ (i.e., $S_2$ is younger). The affected byte ranges $[0, 3]$ and $[8, 11]$ are disjoint, so there is no conflict where a byte is covered by multiple stores.\n- Bytes at offsets $[0, 3]$ will be forwarded from store $S_4$.\n- Bytes at offsets $[8, 11]$ will be forwarded from store $S_2$.\nThe bytes at offsets $[4, 7]$ are not covered by any older store. These bytes must be fetched from the L1 data cache.\nSince not all bytes for page $p+1$ are fully satisfied by store forwarding, an L1 cache access and a preceding TLB lookup for page $p+1$ are also necessary.\n\nWith this analysis, we can calculate the total latency.\n\n**1. Total TLB Latency**\nA TLB lookup is required for both page $p$ and page $p+1$. The lookups are serialized.\n- The lookup for page $p$ is a hit, taking $t_h = 1$ cycle.\n- The lookup for page $p+1$ is a miss, taking $t_m = 13$ cycles.\nTotal TLB Latency = $t_h + t_m = 1 + 13 = 14$ cycles.\n\n**2. Total L1 Data Cache Latency**\nAn L1 cache access is required for both page $p$ and page $p+1$. The problem states these accesses hit in the cache and their latencies add.\n- The access for page $p$ incurs a latency of $L_c = 4$ cycles.\n- The access for page $p+1$ incurs a latency of $L_c = 4$ cycles.\nTotal L1 Cache Latency = $L_c + L_c = 4 + 4 = 8$ cycles.\n\n**3. Store-Forwarding Merge Delay**\nThe merge delay is $k$ cycles, where $k$ is the total number of distinct older stores from which the load forwards data.\n- From page $p$, data is forwarded from store $S_1$.\n- From page $p+1$, data is forwarded from stores $S_4$ and $S_2$.\nThe set of distinct forwarding stores is $\\{S_1, S_2, S_4\\}$.\nThe number of distinct stores is $k = 3$.\nStore-Forwarding Merge Delay = $k = 3$ cycles.\n\n**4. Total Execution Latency**\nThe total latency is the sum of the non-overlapped components.\nTotal Latency = (Total TLB Latency) + (Total L1 Cache Latency) + (Store-Forwarding Merge Delay)\nTotal Latency = $14 + 8 + 3 = 25$ cycles.\n\nThe total execution latency for this load is $25$ cycles.",
            "answer": "$$\\boxed{25}$$"
        },
        {
            "introduction": "High-performance processors rely on speculative execution, often issuing loads before the addresses of all older stores are known. While this boosts performance, it risks error if a dependence is mispredicted. This next exercise explores the consequences of such a memory ordering violation. You are given a snapshot of the Load-Store Queue (LSQ) at the moment a misprediction is detected and are asked to apply a specific \"global load replay\" recovery policy, highlighting the performance cost of squashing and reissuing instructions. ",
            "id": "3664944",
            "problem": "A superscalar out-of-order core enforces in-order retirement and implements a Load-Store Queue (LSQ) to maintain memory ordering between loads and stores. The LSQ depth is $D=16$. The machine permits speculative memory disambiguation: younger loads may issue even when there exist older stores with unresolved addresses. The core uses store-to-load forwarding from the store buffer when a load’s effective address matches an older store’s address. On a misprediction of memory dependence (for example, a younger load is allowed to issue despite an older unresolved store actually aliasing it), the core employs a global load replay policy: when the violating older store’s address resolves and a conflict is detected, all loads younger than that store that have already executed their memory accesses are squashed and reissued.\n\nConsider the following program-order sequence of memory operations currently resident in the Load-Store Queue (LSQ) at the instant an older store resolves its address and a conflict is detected. Indices increase with program order; index $0$ is the oldest entry and index $13$ is the youngest entry. The LSQ occupancy is thus $14$, which is within the depth $D=16$. Each operation is annotated with its type and its effective address symbol. At the instant of detection, every listed load has already executed its memory access.\n\nIndex $0$: $S_{0}$ writes $A$ (address of $S_{0}$ is resolved when inserted).  \nIndex $1$: $L_{1}$ reads $A$ (executed; forwarded correctly from $S_{0}$).  \nIndex $2$: $L_{2}$ reads $B$ (executed; no alias with $S_{0}$).  \nIndex $3$: $S_{1}$ writes an initially unresolved address that later resolves to $A$ (this is the violating store).  \nIndex $4$: $L_{3}$ reads $A$ (issued speculatively; memory dependence predictor claimed “no alias” with $S_{1}$; forwarded from $S_{0}$, which is incorrect because $S_{1}$ is older and should supply the value).  \nIndex $5$: $L_{4}$ reads $C$ (executed).  \nIndex $6$: $S_{2}$ writes $D$.  \nIndex $7$: $L_{5}$ reads $E$ (executed).  \nIndex $8$: $L_{6}$ reads $F$ (executed).  \nIndex $9$: $S_{3}$ writes $G$.  \nIndex $10$: $L_{7}$ reads $H$ (executed).  \nIndex $11$: $L_{8}$ reads $I$ (executed).  \nIndex $12$: $S_{4}$ writes $J$.  \nIndex $13$: $L_{9}$ reads $K$ (executed).\n\nDefine the replay window $W_{r}$ to be the count of younger loads that must be squashed and reissued when the misprediction is detected for $S_{1}$ at index $3$. Compute $W_{r}$ using the provided LSQ depth $D$ and the program-order memory sequence. Express your answer as an exact integer with no units.",
            "solution": "The problem requires a direct application of the specified \"global load replay\" recovery policy. The policy states: \"...when the violating older store’s address resolves and a conflict is detected, all loads younger than that store that have already executed their memory accesses are squashed and reissued.\"\n\nWe apply this policy to the provided LSQ state.\n\n1.  **Identify the Violating Store:** The problem identifies the store operation at index 3, denoted $S_{1}$, as the \"violating store\". This instruction serves as the reference point in program order.\n\n2.  **Identify Younger Instructions:** The policy concerns \"all loads younger than that store\". \"Younger\" instructions are those with a higher index in the program-ordered LSQ. We must consider all instructions with an index greater than 3, i.e., from index 4 to index 13.\n\n3.  **Filter for Loads and Check Execution Status:** The policy specifically applies to \"loads\" that \"have already executed their memory accesses.\" The problem states this condition is met for all listed loads. We enumerate the loads within the window of younger instructions (indices 4 through 13):\n    - Index 4: $L_{3}$ (Load)\n    - Index 5: $L_{4}$ (Load)\n    - Index 7: $L_{5}$ (Load)\n    - Index 8: $L_{6}$ (Load)\n    - Index 10: $L_{7}$ (Load)\n    - Index 11: $L_{8}$ (Load)\n    - Index 13: $L_{9}$ (Load)\n    The stores at indices 6, 9, and 12 are not subject to this policy.\n\n4.  **Compute the Replay Window $W_{r}$:** The replay window $W_r$ is the total count of loads that must be squashed and reissued. Counting the loads identified in the previous step gives a total of 7.\n\n$$W_{r} = 7$$\n\nThe loads $L_1$ and $L_2$ are older than the violating store $S_1$ and are therefore unaffected. The \"global\" nature of the policy means that all loads younger than $S_1$ are replayed, including those that did not themselves have a data dependency on $S_1$. The LSQ depth $D=16$ is extraneous information.",
            "answer": "$$\\boxed{7}$$"
        },
        {
            "introduction": "The sophisticated prediction and recovery mechanisms we have discussed are not abstract concepts; they must be implemented in physical hardware. This final practice bridges the gap between the algorithmic side of memory disambiguation and its concrete implementation cost. You will analyze the design of a memory dependence predictor and calculate its total storage requirement in bits, from the tags and valid bits to the history information. This exercise illuminates the crucial trade-offs that processor architects face between adding performance-enhancing features and the real-world cost in silicon area. ",
            "id": "3657211",
            "problem": "A microarchitecture uses out-of-order (OoO) execution with a memory dependence predictor that performs memory disambiguation for loads and stores. When a load, denoted by $L$, is observed to have violated with an older store, denoted by $S$, at a program-order distance $d$ (measured as the count of older in-flight stores between $S$ and $L$ at the time $L$ issued), the predictor updates the correlation state for $L$ so that on a future execution it will conservatively treat $L$ as dependent on all older stores within distance $d$. To correlate dependence behavior across dynamic contexts, for each static load program counter (PC), the predictor maintains a per-load circular history of the last $H$ observed violating distances, and predicts the next dependent distance as the maximum over that window. To support this behavior in hardware, the predictor must store the $H$ distances themselves.\n\nThe predictor is implemented as a direct-mapped table with $E$ entries, addressed by the lower bits of the load PC $PC_L$. Each entry contains: a valid bit, a tag consisting of the higher-order PC bits not used to index the table, a $c$-bit saturating confidence counter, and $H$ most-recent violation distances for that load. The machine has a store queue (SQ) of capacity $Q$ entries; therefore any violating distance $d$ lies in the set $\\{1,\\dots,Q\\}$. To allow representing the case that no violation has been observed yet in a history position, the design encodes distances with an extra code, so the distance field must encode $Q+1$ distinct values. The address width is $A$ bits.\n\nAssume the following concrete parameters: $A = 48$, $E = 512$, $Q = 56$, and $c = 2$. The tag stores the higher-order $A - \\log_{2}(E)$ bits of $PC_L$ and there is no replacement metadata beyond the valid bit because the table is direct-mapped. Derive an exact closed-form expression, in bits, for the total storage required by the entire predictor table as a function of the history length $H$. Express your final answer as a single closed-form expression in $H$ with no units. No rounding is required.",
            "solution": "To find the total storage of the predictor table, $S_{total}$, we first calculate the size of a single entry, $S_{entry}$, and then multiply it by the total number of entries, $E$.\n\nThe size of a single entry is the sum of its components:\n$$S_{entry} = S_{valid} + S_{tag} + S_{confidence} + S_{distances}$$\nWe calculate the size of each component in bits using the given parameters: $A = 48$, $E = 512$, $Q = 56$, and $c = 2$.\n\n1.  **Size of the valid bit ($S_{valid}$):** Each entry has one valid bit.\n    $$S_{valid} = 1 \\text{ bit}$$\n\n2.  **Size of the tag ($S_{tag}$):** The table has $E = 512$ entries, so $\\log_2(512) = 9$ bits of the PC are used for indexing. The remaining bits form the tag.\n    $$S_{tag} = A - \\log_2(E) = 48 - 9 = 39 \\text{ bits}$$\n\n3.  **Size of the confidence counter ($S_{confidence}$):** The counter is $c$ bits wide.\n    $$S_{confidence} = c = 2 \\text{ bits}$$\n\n4.  **Size of the distance history ($S_{distances}$):** This field stores $H$ distances. First, we find the bits needed for a single distance, $S_{dist\\_field}$. The field must encode $Q+1 = 57$ distinct values (distances 1 to 56, plus a code for no violation). The number of bits required is $\\lceil\\log_2(N)\\rceil$.\n    $$S_{dist\\_field} = \\lceil \\log_2(Q+1) \\rceil = \\lceil \\log_2(57) \\rceil$$\n    Since $2^5 = 32$ and $2^6 = 64$, we need 6 bits to represent 57 values.\n    $$S_{dist\\_field} = 6 \\text{ bits}$$\n    The total storage for $H$ distances in one entry is:\n    $$S_{distances} = H \\times S_{dist\\_field} = 6H \\text{ bits}$$\n\nSumming these components gives the size of a single entry:\n$$S_{entry} = 1 + 39 + 2 + 6H = 42 + 6H \\text{ bits}$$\n\nFinally, the total storage capacity of the entire predictor table, $S_{total}(H)$, is the number of entries $E$ multiplied by the size of a single entry:\n$$S_{total}(H) = E \\times S_{entry} = 512 \\times (42 + 6H)$$\nExpanding this expression gives the final closed-form equation:\n$$S_{total}(H) = 512 \\times 42 + 512 \\times 6H = 21504 + 3072H$$\nThis is the total storage of the predictor table in bits.",
            "answer": "$$\n\\boxed{21504 + 3072H}\n$$"
        }
    ]
}