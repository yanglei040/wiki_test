{
    "hands_on_practices": [
        {
            "introduction": "While it seems intuitive that adding more processor cores should increase computational throughput, this is not always the case in systems with shared resources. This exercise explores a counter-intuitive scenario where adding cores can actually degrade performance due to contention on a single spinlock. You will develop a mathematical model that captures how busy-waiting threads interfere with the lock holder, allowing you to calculate the precise point at which adding more cores becomes detrimental . This practice is fundamental to understanding the scalability limitations of centralized locking mechanisms.",
            "id": "3684316",
            "problem": "A workload executes on a symmetric multiprocessor with $n$ identical Central Processing Unit (CPU) cores. Each request consists of a non-critical computation of duration $u$ and a critical section protected by a single spinlock of duration $c$ when the lock holder runs without disturbance. All cores continuously have work; the lock is hot (every request acquires it once). Under busy waiting, each of the $n-1$ spinning cores repeatedly polls the lock variable, generating cache coherence traffic that interferes with the lock holder. Empirically, assume this interference adds an extra delay of $\\alpha(n-1)$ to each critical section execution on the lock holder. Ignore all other overheads and context switches, and assume a long run so that initial transients are negligible.\n\nStarting from first principles and definitions, model the total completion time for $m$ requests executed on $n$ cores and derive the steady-state throughput $X(n)$, measured in requests per second, as a function of $n$, $u$, $c$, and $\\alpha$. Then, compute $\\frac{dX}{dn}$ and determine the threshold number of cores $n^{\\star}$ at which $\\frac{dX}{dn} = 0$, so that for $n  n^{\\star}$ additional cores strictly decrease throughput due to spinlock contention.\n\nUse the parameter values $u = 8\\,\\text{ms}$, $c = 0.5\\,\\text{ms}$, and $\\alpha = 0.1\\,\\text{ms}$. Provide the numerical value of $n^{\\star}$, rounded to four significant figures. Express the final answer as a pure number with no units.",
            "solution": "The user wants me to first validate the problem statement and then, if it is valid, provide a reasoned solution.\n\n### Step 1: Extract Givens\n-   Number of CPU cores: $n$\n-   Duration of non-critical computation per request: $u$\n-   Duration of critical section per request (undisturbed): $c$\n-   Interference delay factor per spinning core: $\\alpha$\n-   Total number of requests: $m$\n-   System specifics: Symmetric multiprocessor, single spinlock, hot lock (all cores continuously have work), busy waiting.\n-   Interference model: The delay added to the critical section is $\\alpha(n-1)$.\n-   Assumptions: Ignore other overheads and context switches; analysis is for steady-state (long run).\n-   Goals:\n    1.  Model the total completion time for $m$ requests.\n    2.  Derive the steady-state throughput $X(n)$.\n    3.  Compute the derivative $\\frac{dX}{dn}$.\n    4.  Find the threshold number of cores $n^{\\star}$ where $\\frac{dX}{dn} = 0$.\n-   Parameter values for numerical calculation: $u = 8\\,\\text{ms}$, $c = 0.5\\,\\text{ms}$, $\\alpha = 0.1\\,\\text{ms}$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded:** The problem describes a standard performance modeling scenario for lock contention in parallel systems. The model of spinner interference causing a slowdown for the lock holder is a well-established concept in computer architecture related to cache coherence protocols. The linear model for this overhead is a common and valid simplification. The problem is scientifically sound.\n2.  **Well-Posed:** The problem provides all necessary parameters and a clear objective. The goal is to build a model, analyze it using calculus, and find an optimal value, which is a well-defined mathematical task. A unique solution is expected.\n3.  **Objective:** The problem is stated in precise, technical language (\"critical section,\" \"spinlock,\" \"throughput\"). There is no subjective or ambiguous terminology.\n4.  **Flaw Check:** The problem does not violate any scientific principles, is not metaphorical, is self-contained, is not physically infeasible (the parameters are reasonable), and is not ill-posed or trivial.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n### Solution Derivation\nThe problem requires modeling the performance of a multiprocessor system limited by a single spinlock. We will first model the total time required to complete $m$ requests and then derive the throughput $X(n)$.\n\nLet $T_m(n)$ be the total time to complete $m$ requests on $n$ cores. The execution of these requests involves two types of work: non-critical computation of duration $u$ and critical section execution of base duration $c$.\n\nThe total amount of non-critical work for $m$ requests is $m \\times u$. This work is parallelizable. With $n$ cores, and assuming perfect parallelization, the time spent on this portion of the workload is $\\frac{m u}{n}$.\n\nThe critical sections must be executed serially, as only one core can hold the lock at a time. There are $m$ such critical sections. The problem states that due to contention from the $n-1$ spinning cores, the execution time of a single critical section is increased. The effective duration of one critical section, $c_{eff}$, is the base time $c$ plus the interference delay:\n$$c_{eff}(n) = c + \\alpha(n-1)$$\nSince the $m$ critical sections are serialized, the total time spent executing them is the sum of their individual durations. Assuming the system is in a steady state where the lock is passed from one core to another without idle time (a \"hot lock\"), this total time is:\n$$T_{serial} = m \\times c_{eff}(n) = m(c + \\alpha(n-1))$$\nA common and effective model for the total completion time $T_m(n)$ combines the time for the parallelized portion and the serialized portion:\n$$T_m(n) = \\frac{m u}{n} + m(c + \\alpha(n-1))$$\nThis model represents the workload as having a perfectly parallel part and a strictly serial part, which is a good approximation for this type of system.\n\nThe steady-state throughput, $X(n)$, is defined as the number of requests completed per unit time. Therefore:\n$$X(n) = \\frac{m}{T_m(n)} = \\frac{m}{\\frac{m u}{n} + m(c + \\alpha(n-1))}$$\nWe can cancel the factor $m$:\n$$X(n) = \\frac{1}{\\frac{u}{n} + c + \\alpha(n-1)}$$\nTo find the number of cores $n^{\\star}$ that maximizes the throughput, we need to find the value of $n$ for which the derivative of $X(n)$ with respect to $n$ is zero. Let's treat $n$ as a continuous variable for this optimization.\nWe can write $X(n)$ as:\n$$X(n) = \\left( u n^{-1} + c + \\alpha n - \\alpha \\right)^{-1}$$\nLet the denominator be $D(n) = u n^{-1} + (c-\\alpha) + \\alpha n$. Then $X(n) = [D(n)]^{-1}$. Using the chain rule for differentiation:\n$$\\frac{dX}{dn} = -[D(n)]^{-2} \\cdot \\frac{dD}{dn}$$\nFirst, we find the derivative of the denominator, $D(n)$:\n$$\\frac{dD}{dn} = \\frac{d}{dn} \\left( u n^{-1} + c - \\alpha + \\alpha n \\right) = -u n^{-2} + \\alpha$$\nSubstituting this back into the expression for $\\frac{dX}{dn}$:\n$$\\frac{dX}{dn} = - \\frac{-u n^{-2} + \\alpha}{\\left( \\frac{u}{n} + c + \\alpha(n-1) \\right)^2} = \\frac{u n^{-2} - \\alpha}{\\left( \\frac{u}{n} + c + \\alpha(n-1) \\right)^2}$$\nTo find the threshold $n^{\\star}$, we set $\\frac{dX}{dn} = 0$. Since the denominator is a squared term and represents a sum of durations, it is strictly positive for $n \\ge 1$. Thus, we only need to set the numerator to zero:\n$$u (n^{\\star})^{-2} - \\alpha = 0$$\n$$\\frac{u}{(n^{\\star})^2} = \\alpha$$\n$$(n^{\\star})^2 = \\frac{u}{\\alpha}$$\nSince $n$ must be positive, we take the positive square root:\n$$n^{\\star} = \\sqrt{\\frac{u}{\\alpha}}$$\nThis value of $n^{\\star}$ represents the point of maximum throughput. For $n  n^{\\star}$, the numerator $u n^{-2} - \\alpha$ is positive, so $\\frac{dX}{dn}  0$ and throughput increases with $n$. For $n  n^{\\star}$, the numerator is negative, so $\\frac{dX}{dn}  0$ and adding more cores strictly decreases throughput due to overwhelming contention.\n\nNow, we substitute the given numerical values: $u = 8\\,\\text{ms}$ and $\\alpha = 0.1\\,\\text{ms}$.\n$$n^{\\star} = \\sqrt{\\frac{8}{0.1}} = \\sqrt{80}$$\nTo obtain the numerical answer, we calculate the value of $\\sqrt{80}$:\n$$n^{\\star} = \\sqrt{16 \\times 5} = 4\\sqrt{5} \\approx 4 \\times 2.2360679... \\approx 8.9442719...$$\nThe problem asks for the value rounded to four significant figures.\n$$n^{\\star} \\approx 8.944$$",
            "answer": "$$\\boxed{8.944}$$"
        },
        {
            "introduction": "Having seen how pure busy-waiting can limit system scalability, a natural next step is to explore better implementation strategies. This practice introduces a common and effective alternative: a hybrid lock that combines a short period of spinning with thread parking (a lightweight form of blocking). By defining and calculating a \"spin efficiency\" metric, you will quantitatively compare the performance of a naive spinlock against this improved design under various contention levels . This exercise provides valuable, hands-on insight into the practical engineering trade-offs involved in designing efficient concurrency primitives.",
            "id": "3684245",
            "problem": "You are given a synthetic yet scientifically sound model of a concurrent system in which multiple threads contend for a spinlock protecting a critical section. The goal is to formalize and compute the \"spin efficiency\" defined as the ratio of useful work cycles to total cycles consumed by all threads. You must implement a program that computes the spin efficiency before and after a lock redesign that reduces busy waiting by bounding spin time and then parking threads.\n\nFundamental base and definitions to use:\n- A spinlock is a mutual exclusion mechanism in which a thread repeatedly checks a lock until it becomes available; this busy waiting consumes Central Processing Unit (CPU) cycles.\n- A critical section is a region of code that must be executed under mutual exclusion; each entry performs useful work that consumes CPU cycles.\n- Useful work cycles are the cycles that directly contribute to the completion of critical section work.\n- Busy waiting cycles are the cycles consumed by threads while actively spinning on the lock when they cannot enter the critical section.\n- Lock overhead cycles are the cycles consumed by acquire and release operations of the lock itself (excluding busy waiting).\n- Spin efficiency is defined as the ratio of useful work cycles to total cycles across all threads: $E = \\dfrac{\\text{useful work cycles}}{\\text{total cycles}}$.\n\nSystem model and parameters:\n- Let $M$ be the number of threads contending for the lock.\n- Let $A$ be the number of critical section entries (acquisitions) per thread.\n- Let $W$ be the number of cycles of useful work performed per critical section entry.\n- Let $C_{\\ell}$ be the number of cycles of lock overhead per critical section entry (acquire $+$ release).\n- Before redesign (pure busy-wait spinlock): when one thread holds the lock for $W$ cycles, each of the other $M-1$ threads spins continuously for the duration of those $W$ cycles.\n- After redesign (bounded spinning with park): each waiting thread spins for at most $S_{\\max}$ cycles per wait. If the lock has not been acquired after $S_{\\max}$ cycles and contention exists, the thread parks (does not consume CPU cycles while parked). When a lock is released under contention and $W  S_{\\max}$, exactly one parked thread is woken to acquire the lock next, incurring a wake-up cost $R$ cycles. Assume that the first acquisition does not require a wake-up; all subsequent acquisitions under the condition $W  S_{\\max}$ and $M1$ require one wake-up.\n\nAssumptions for computation:\n- All threads perform their $A$ acquisitions, and acquisitions are serialized by the lock.\n- The total number of acquisitions is $M \\cdot A$.\n- Lock overhead applies equally before and after redesign: $C_{\\ell}$ cycles per acquisition.\n- Parking consumes zero CPU cycles for the purpose of this metric.\n- The system is otherwise idealized (no I/O, no preemption costs, no cache or memory hierarchy modeling beyond the costs stated).\n\nYour task is to compute, for each test case, the spin efficiency before redesign and after redesign. To do so, start from the given base definitions and reason to the total cycles in each design, aggregating across all threads. Do not assume any unstated optimizations or costs.\n\nOutput requirements:\n- Each answer must be a floating-point number representing the spin efficiency as a decimal.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets: $[$$e_{1,\\text{before}}$$,$$e_{1,\\text{after}}$$,$$e_{2,\\text{before}}$$,$$e_{2,\\text{after}}$$,$$e_{3,\\text{before}}$$,$$e_{3,\\text{after}}$$,$$e_{4,\\text{before}}$$,$$e_{4,\\text{after}}$$]$, where $e_{i,\\cdot}$ denotes the spin efficiency for test case $i$. Print each decimal value rounded to exactly $6$ digits after the decimal point.\n\nTest suite:\n- Case $1$: $M=8$, $A=500$, $W=100$, $C_{\\ell}=5$, $S_{\\max}=20$, $R=200$.\n- Case $2$ (boundary, no contention): $M=1$, $A=1000$, $W=100$, $C_{\\ell}=5$, $S_{\\max}=20$, $R=200$.\n- Case $3$ (bounded spinning exceeds work, redesign equals baseline): $M=32$, $A=200$, $W=10$, $C_{\\ell}=5$, $S_{\\max}=50$, $R=200$.\n- Case $4$ (heavy contention with small spin bound): $M=16$, $A=50$, $W=1000$, $C_{\\ell}=5$, $S_{\\max}=10$, $R=200$.\n\nYour program must compute the two efficiencies for each case under the stated model and produce the single-line output in the exact format described.",
            "solution": "The problem will be validated by first extracting the given information and then assessing its scientific grounding, consistency, and structure.\n\n### Step 1: Extract Givens\n\n- **Definitions**:\n    - **Spinlock**: A mutual exclusion mechanism where a thread repeatedly checks a lock, consuming CPU cycles (busy waiting).\n    - **Critical section**: A code region requiring mutual exclusion, performing useful work that consumes CPU cycles.\n    - **Useful work cycles**: Cycles contributing directly to critical section work completion.\n    - **Busy waiting cycles**: Cycles consumed by threads spinning on a lock.\n    - **Lock overhead cycles**: Cycles for acquire and release operations, excluding busy waiting.\n    - **Spin efficiency ($E$)**: $E = \\dfrac{\\text{useful work cycles}}{\\text{total cycles}}$.\n\n- **Parameters**:\n    - $M$: Number of threads.\n    - $A$: Number of critical section acquisitions per thread.\n    - $W$: Cycles of useful work per critical section entry.\n    - $C_{\\ell}$: Cycles of lock overhead per critical section entry.\n    - $S_{\\max}$: Maximum spin cycles per wait in the redesigned lock.\n    - $R$: Wake-up cost in cycles for a parked thread.\n\n- **System Model (Before Redesign)**:\n    - A pure busy-wait spinlock.\n    - When one thread holds the lock for $W$ cycles, the other $M-1$ threads spin for $W$ cycles.\n\n- **System Model (After Redesign)**:\n    - A bounded-spin lock.\n    - Waiting threads spin for at most $S_{\\max}$ cycles.\n    - If the lock is not acquired after $S_{\\max}$ cycles under contention, the thread parks (consumes zero cycles).\n    - When a lock is released under contention, and if $W  S_{\\max}$, exactly one parked thread is woken up, costing $R$ cycles.\n    - The first acquisition has no wake-up cost. All subsequent acquisitions under the conditions $W  S_{\\max}$ and $M  1$ incur a wake-up cost.\n\n- **Assumptions**:\n    - Total acquisitions = $M \\cdot A$.\n    - Acquisitions are serialized.\n    - $C_{\\ell}$ is constant for both designs.\n    - Parking consumes zero CPU cycles.\n    - The system is idealized (no other costs like I/O or preemption).\n\n- **Test Suite**:\n    - Case 1: $M=8, A=500, W=100, C_{\\ell}=5, S_{\\max}=20, R=200$.\n    - Case 2: $M=1, A=1000, W=100, C_{\\ell}=5, S_{\\max}=20, R=200$.\n    - Case 3: $M=32, A=200, W=10, C_{\\ell}=5, S_{\\max}=50, R=200$.\n    - Case 4: $M=16, A=50, W=1000, C_{\\ell}=5, S_{\\max}=10, R=200$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem establishes a simplified but coherent and scientifically grounded model of a common computer science scenario (spinlock contention).\n- **Scientifically Grounded**: The model is based on fundamental concepts in operating systems and concurrent programming, such as spinlocks, critical sections, and busy waiting. The notion of modeling performance by counting CPU cycles is a standard technique in systems analysis. It does not violate any scientific principles.\n- **Well-Posed**: The parameters and rules are clearly defined, leading to a unique, computable solution for each test case.\n- **Objective**: The language is precise and quantitative. There are no subjective or ambiguous terms.\n- **Self-Contained and Consistent**: All necessary parameters, definitions, and assumptions for solving the problem are provided. There are no internal contradictions.\n- **Relevant**: The problem is directly related to the specified topic of spinlocks and busy waiting in operating systems.\n\nThe problem is not flawed; it is a valid, well-structured exercise in applying first principles to model system performance.\n\n### Step 3: Verdict and Action\n\nThe problem is **valid**. A solution will be derived and presented.\n\n### Derivation of Spin Efficiency Formulas\n\nThe spin efficiency $E$ is defined as the ratio of total useful work cycles to total cycles consumed across all threads. Let $N_{total} = M \\cdot A$ be the total number of acquisitions.\n\n**1. Total Useful Work Cycles**\n\nThe useful work is the work done within the critical section. Each of the $N_{total}$ acquisitions performs $W$ cycles of useful work.\n$$\n\\text{Cycles}_{\\text{useful}} = N_{\\text{total}} \\cdot W = (M \\cdot A) \\cdot W\n$$\nThis quantity serves as the numerator for the efficiency calculation in all scenarios.\n\n**2. Efficiency Before Redesign (Pure Busy-Wait)**\n\nIn this model, for each acquisition, one thread executes the critical section while the other $M-1$ threads busy-wait.\n- **Work and Overhead Cycles**: The thread acquiring the lock spends $W$ cycles on useful work and $C_{\\ell}$ cycles on lock overhead for each acquisition. Over all acquisitions, this is $N_{total} \\cdot (W + C_{\\ell})$.\n- **Busy-Waiting Cycles**: For each acquisition, the remaining $M-1$ threads spin for the duration of the critical section work, $W$. The total busy-wait cycles are $N_{total} \\cdot (M-1) \\cdot W$.\n- **Total Cycles**: The total cycles consumed is the sum of cycles from all threads for all activities.\n$$\n\\text{Cycles}_{\\text{total, before}} = N_{\\text{total}} \\cdot (W + C_{\\ell}) + N_{\\text{total}} \\cdot (M-1) \\cdot W\n$$\nSimplifying this expression:\n$$\n\\text{Cycles}_{\\text{total, before}} = N_{\\text{total}} \\cdot (W + C_{\\ell} + MW - W) = N_{\\text{total}} \\cdot (C_{\\ell} + M \\cdot W)\n$$\n- **Spin Efficiency (Before)**:\n$$\nE_{\\text{before}} = \\frac{\\text{Cycles}_{\\text{useful}}}{\\text{Cycles}_{\\text{total, before}}} = \\frac{N_{\\text{total}} \\cdot W}{N_{\\text{total}} \\cdot (C_{\\ell} + M \\cdot W)} = \\frac{W}{C_{\\ell} + M \\cdot W}\n$$\nThis formula is valid for $M  1$. If $M=1$, there is no contention, so the busy-wait term $(M-1) \\cdot W$ is zero. The formula correctly simplifies to $E = \\frac{W}{C_{\\ell} + W}$.\n\n**3. Efficiency After Redesign (Bounded Spinning with Park)**\n\nThe behavior of the redesigned lock depends on whether the useful work duration $W$ exceeds the maximum spin time $S_{\\max}$. We must handle two main cases, plus the special case of no contention ($M=1$).\n\n- **Case A: No Contention ($M=1$)**\nWith only one thread, there is no spinning or parking. The total cycles are simply the sum of useful work and lock overhead for all $A$ acquisitions.\n$$\n\\text{Cycles}_{\\text{total, after}} = A \\cdot (W + C_{\\ell})\n$$\nThe useful cycles are $A \\cdot W$.\n$$\nE_{\\text{after}} = \\frac{A \\cdot W}{A \\cdot (W + C_{\\ell})} = \\frac{W}{W + C_{\\ell}}\n$$\nThis is identical to the \"before\" case when $M=1$.\n\n- **Case B: Contention ($M1$) and $W \\le S_{\\max}$**\nIf the critical section work time is less than or equal to the maximum spin time, a waiting thread will spin for the entire duration ($W$ cycles) until the lock is released. It never reaches the $S_{\\max}$ limit to park. This scenario is functionally identical to the pure busy-wait model.\n$$\nE_{\\text{after}} = E_{\\text{before}} = \\frac{W}{C_{\\ell} + M \\cdot W} \\quad (\\text{if } W \\le S_{\\max} \\text{ and } M1)\n$$\n\n- **Case C: Contention ($M1$) and $W  S_{\\max}$**\nThis is the most complex case. Waiting threads spin for $S_{\\max}$ cycles and then park. Subsequent acquisitions (after the first) incur a wake-up cost $R$. We sum all cycle costs over the total $N_{total}$ acquisitions.\n- **Useful Work Cycles**: $\\text{Cycles}_{\\text{useful}} = N_{total} \\cdot W$.\n- **Lock Overhead Cycles**: $\\text{Cycles}_{\\text{overhead}} = N_{total} \\cdot C_{\\ell}$.\n- **Busy-Waiting Cycles**: For each of the $N_{total}$ acquisitions, the $M-1$ waiting threads now spin for only $S_{\\max}$ cycles.\n$$\n\\text{Cycles}_{\\text{wait}} = N_{total} \\cdot (M-1) \\cdot S_{\\max}\n$$\n- **Wake-up Cycles**: A wake-up cost $R$ is incurred for each acquisition except the first. There are $N_{total} - 1$ such events.\n$$\n\\text{Cycles}_{\\text{wakeup}} = (N_{total} - 1) \\cdot R\n$$\n- **Total Cycles**: The sum of all components.\n$$\n\\text{Cycles}_{\\text{total, after}} = \\text{Cycles}_{\\text{useful}} + \\text{Cycles}_{\\text{overhead}} + \\text{Cycles}_{\\text{wait}} + \\text{Cycles}_{\\text{wakeup}}\n$$\n$$\n\\text{Cycles}_{\\text{total, after}} = (N_{total} \\cdot W) + (N_{total} \\cdot C_{\\ell}) + (N_{total} \\cdot (M-1) \\cdot S_{\\max}) + ((N_{total} - 1) \\cdot R)\n$$\n- **Spin Efficiency (After, Case C)**:\n$$\nE_{\\text{after}} = \\frac{N_{total} \\cdot W}{(N_{total} \\cdot W) + (N_{total} \\cdot C_{\\ell}) + (N_{total} \\cdot (M-1) \\cdot S_{\\max}) + ((N_{total} - 1) \\cdot R)}\n$$\nThis formula encapsulates the benefits of the redesigned lock: the busy-wait term now scales with $S_{\\max}$ instead of the larger $W$, at the cost of an added wake-up term $R$.\n\n### Summary of Calculation Logic\n\nFor each test case with parameters $(M, A, W, C_{\\ell}, S_{\\max}, R)$:\n\n1.  **Calculate $E_{\\text{before}}$**:\n    $$\n    E_{\\text{before}} = \\frac{W}{C_{\\ell} + M \\cdot W}\n    $$\n\n2.  **Calculate $E_{\\text{after}}$**:\n    - If $M = 1$:\n      $$\n      E_{\\text{after}} = \\frac{W}{W + C_{\\ell}}\n      $$\n    - If $M  1$ and $W \\le S_{\\max}$:\n      $$\n      E_{\\text{after}} = \\frac{W}{C_{\\ell} + M \\cdot W}\n      $$\n    - If $M  1$ and $W  S_{\\max}$:\n      - Let $N_{total} = M \\cdot A$.\n      - Let $\\text{Numerator} = N_{total} \\cdot W$.\n      - Let $\\text{Denominator} = (N_{total} \\cdot W) + (N_{total} \\cdot C_{\\ell}) + (N_{total} \\cdot (M-1) \\cdot S_{\\max}) + ((N_{total} - 1) \\cdot R)$.\n      $$\n      E_{\\text{after}} = \\frac{\\text{Numerator}}{\\text{Denominator}}\n      $$\nThese formulas will be implemented to compute the results for the given test suite. Note that for computation, it is crucial to use data types (e.g., 64-bit integers) that can accommodate potentially large intermediate values for total cycle counts to avoid overflow before performing the final division.",
            "answer": "[0.124224,0.308736,0.952381,0.952381,0.030211,0.030211,0.062461,0.301323]"
        },
        {
            "introduction": "Performance is critical, but a high-performance lock is useless if it is not correct. This exercise shifts our focus from performance to the logical correctness and robustness of a spinlock implementation. You will analyze a common and subtle bug—the \"double unlock\"—to understand why a lock must not only manage its state (locked or unlocked) but also strictly enforce ownership . This practice will help you appreciate the importance of invariants and assertions in building safe and reliable mutual exclusion primitives that are resilient to incorrect usage.",
            "id": "3684301",
            "problem": "A non-recursive spinlock is implemented using atomic Compare-And-Swap (CAS) semantics: on acquire, a thread repeatedly performs an atomic operation that attempts to change a shared lock word from $\\text{Unlocked}$ to $\\text{Locked}$, spinning (busy waiting) while the operation fails, and on release, it writes back $\\text{Unlocked}$ with appropriate ordering so that critical-section stores become visible before the unlock. Consider a system with $n \\geq 2$ threads running on $m \\geq 1$ Central Processing Units (CPUs), where the lock protects a shared data structure. The core correctness requirement for any mutual exclusion mechanism is the safety property: at most one thread is in the critical section at any time. A fundamental additional requirement for a non-recursive spinlock is that only the thread that successfully acquired the lock may release it.\n\nDefine a minimal lock-state machine with states $S = \\{\\text{Unlocked}, \\text{Locked}\\}$. The allowed transitions are:\n- $\\text{Unlocked} \\rightarrow \\text{Locked}$ by a unique acquiring thread $T_i$,\n- $\\text{Locked} \\rightarrow \\text{Unlocked}$ by the same thread $T_i$.\n\nAn illegal transition occurs if either the precondition for the transition is not met (for example, attempting $\\text{Locked} \\rightarrow \\text{Unlocked}$ when the current state is $\\text{Unlocked}$), or the identity constraint is violated (for example, a thread $T_j \\neq T_i$ attempts to unlock when $T_i$ is the owner).\n\nSuppose there is a subtle bug in client code: a thread $T_1$ calls unlock twice in a row without an intervening lock, i.e., its intended sequence is $\\text{lock}(T_1)$, critical section, $\\text{unlock}(T_1)$, but due to a bug it executes $\\text{unlock}(T_1)$ again. Because of concurrency, it is possible that between the first and second unlock calls, some other thread $T_2$ acquires the lock, so that at the time of the second unlock by $T_1$, the state may be $\\text{Locked}$ and the owner may be $T_2$.\n\nYou are tasked with instrumenting the spinlock with invariants and assertions that will detect any illegal transition, including this double release scenario, as early as possible and without flagging valid interleavings. You may augment the lock with the following metadata, updated atomically where appropriate:\n- an owner identifier $o \\in \\{\\text{null}\\} \\cup \\{\\text{thread identifiers}\\}$,\n- a per-thread hold count $h_i \\in \\{0,1\\}$ (because the lock is non-recursive),\n- per-thread acquisition and release counters $a_i$ and $r_i$.\n\nWhich option specifies a set of invariants and assertions that will necessarily detect the second (buggy) unlock by $T_1$ under all interleavings, while not firing during any legal acquire or release?\n\nA. Assert only the state precondition on unlock: before any unlock, check $s = \\text{Locked}$. On acquire, assert $s = \\text{Unlocked}$ before attempting CAS. Do not track ownership or per-thread counts.\n\nB. Maintain and check the following invariants and assertions:\n- Precondition for acquire by $T_i$: assert $s = \\text{Unlocked}$; on successful CAS, set $s := \\text{Locked}$, $o := T_i$, increment $a_i$, and set $h_i := 1$.\n- Precondition for unlock by $T_i$: assert $s = \\text{Locked}$, $o = T_i$, and $h_i = 1$; then set $s := \\text{Unlocked}$, $o := \\text{null}$, $h_i := 0$, and increment $r_i$.\n- Global consistency: for all threads $i$, assert $r_i \\leq a_i$, and assert $\\sum_i h_i \\in \\{0,1\\}$.\nThese conditions reject any unlock when the current thread is not the owner or when the lock is not held, and prevent double release by the same thread.\n\nC. Maintain only global counters and a state-consistency check: define $A := \\sum_i a_i$ and $R := \\sum_i r_i$, assert $R \\leq A$ at all times, and assert that transitions alternate between $\\text{Unlocked}$ and $\\text{Locked}$ in the global timeline. Do not track $o$ or $h_i$.\n\nD. On unlock, assert that a store-load ordering barrier executes before writing $s := \\text{Unlocked}$, and on acquire, assert that a load-store ordering barrier executes after observing $s = \\text{Locked}$. Do not track $o$, $h_i$, or $(a_i, r_i)$, and do not assert state preconditions.\n\nSelect the best option.",
            "solution": "## Problem Validation\n\n### Step 1: Extract Givens\n\n- **Lock Implementation**: A non-recursive spinlock is implemented using atomic Compare-And-Swap (CAS).\n- **Acquire Operation**: A thread repeatedly performs an atomic operation attempting to change a shared lock word from $\\text{Unlocked}$ to $\\text{Locked}$, spinning while the operation fails.\n- **Release Operation**: The lock owner writes back $\\text{Unlocked}$ with appropriate memory ordering.\n- **System Parameters**: $n \\geq 2$ threads, $m \\geq 1$ CPUs.\n- **Correctness Requirements**:\n    1.  **Mutual Exclusion (Safety)**: At most one thread is in the critical section at any time.\n    2.  **Ownership on Release**: Only the thread that successfully acquired the lock may release it.\n- **Lock State Machine**:\n    - States $S = \\{\\text{Unlocked}, \\text{Locked}\\}$.\n    - Allowed transition $\\text{Unlocked} \\rightarrow \\text{Locked}$ by an acquiring thread $T_i$.\n    - Allowed transition $\\text{Locked} \\rightarrow \\text{Unlocked}$ by the same thread $T_i$.\n- **Bug Scenario**: A thread $T_1$ executes `unlock` twice in a row. Between the two `unlock` calls by $T_1$, another thread $T_2$ may acquire the lock. The specific interleaving to consider is: `lock(T_1)`, first `unlock(T_1)`, `lock(T_2)`, second (buggy) `unlock(T_1)`.\n- **Task**: Instrument the spinlock to detect any illegal transition, specifically the double release, under all interleavings, without flagging valid operations.\n- **Instrumentation Metadata Available**:\n    - Owner identifier $o \\in \\{\\text{null}\\} \\cup \\{\\text{thread identifiers}\\}$.\n    - Per-thread hold count $h_i \\in \\{0, 1\\}$ (for a non-recursive lock).\n    - Per-thread acquisition and release counters $a_i$ and $r_i$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement is evaluated against the validation criteria:\n\n1.  **Scientifically Grounded**: The problem is rooted in fundamental concepts of concurrent programming and operating systems, including spinlocks, atomic operations (CAS), mutual exclusion, and race conditions. The described bug (double-release) and the instrumentation techniques (tracking ownership, counters) are standard and realistic topics in this field.\n2.  **Well-Posed**: The problem asks for a specific set of invariants and assertions to detect a well-defined erroneous behavior (a double-unlock) under concurrent execution. The goal is clear and formally specifiable.\n3.  **Objective**: The language used is technical, precise, and free of subjective or ambiguous terminology. The scenario and requirements are stated objectively.\n4.  **Incomplete or Contradictory Setup**: The problem is self-contained. It provides the lock's behavior, the exact bug to detect, the possible interleaving, and the tools available for instrumentation. There are no contradictions.\n5.  **Unrealistic or Infeasible**: The scenario is a common and plausible programming error in low-level concurrency. The system model ($n$ threads, $m$ CPUs) is standard.\n6.  **Ill-Posed or Poorly Structured**: The problem is well-structured, building from general principles to a specific scenario and a clear question. It admits a unique, best solution among the options.\n7.  **Pseudo-Profound, Trivial, or Tautological**: The problem is not trivial. It requires a careful analysis of state changes under concurrency and understanding which information is necessary to maintain and check to ensure logical correctness, distinguishing it from other aspects like memory visibility.\n8.  **Outside Scientific Verifiability**: The proposed solutions (the options) are all verifiable through logical analysis of the state transitions.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is a well-defined, scientifically sound problem in computer science. The solution process will now proceed.\n\n## Solution Derivation\n\nThe core task is to devise a set of checks that can detect a specific illegal operation: a thread $T_1$ attempting to release a lock that it does not currently own. This situation arises in the given scenario:\n1.  Thread $T_1$ acquires the lock. The lock state is now $(\\text{state}=\\text{Locked}, \\text{owner}=T_1)$.\n2.  $T_1$ correctly releases the lock. The lock state becomes $(\\text{state}=\\text{Unlocked}, \\text{owner}=\\text{null})$.\n3.  Thread $T_2$ acquires the lock. The state becomes $(\\text{state}=\\text{Locked}, \\text{owner}=T_2)$.\n4.  $T_1$ erroneously attempts to release the lock again. At this point, the lock is in state $\\text{Locked}$, but its owner is $T_2$.\n\nAn illegal release by $T_1$ would violate mutual exclusion by prematurely unlocking the lock while $T_2$ is in its critical section. The instrumentation must therefore catch this attempt at step 4. A successful detection mechanism must, at the point of an `unlock` call by a thread $T_i$, be able to verify that $T_i$ is indeed the current, legitimate owner of the lock. This requires tracking lock ownership.\n\n### Option-by-Option Analysis\n\n**A. Assert only the state precondition on unlock: before any unlock, check $s = \\text{Locked}$. On acquire, assert $s = \\text{Unlocked}$ before attempting CAS. Do not track ownership or per-thread counts.**\n\nLet's trace the buggy scenario with these assertions:\n1.  `lock(T_1)`: $T_1$ finds $s=\\text{Unlocked}$ and its CAS succeeds, setting $s:=\\text{Locked}$.\n2.  `unlock(T_1)`: $T_1$ asserts $s=\\text{Locked}$. This is true. The assertion passes. $T_1$ sets $s:=\\text{Unlocked}$.\n3.  `lock(T_2)`: $T_2$ finds $s=\\text{Unlocked}$ and its CAS succeeds, setting $s:=\\text{Locked}$.\n4.  `unlock(T_1)` (buggy call): $T_1$ asserts $s=\\text{Locked}$. The lock state is indeed $\\text{Locked}$ (because $T_2$ holds it). The assertion **passes**, and $T_1$ proceeds to incorrectly set $s:=\\text{Unlocked}$, breaking the lock.\n\nThis set of assertions fails to detect the bug. The fundamental flaw is the lack of ownership tracking. Knowing the lock is `Locked` is insufficient; one must know *who* locked it.\n\n**Verdict for A: Incorrect.**\n\n**B. Maintain and check the following invariants and assertions: ...**\nThis option proposes a comprehensive set of metadata: state $s$, owner $o$, per-thread hold count $h_i$, and acquisition/release counters $a_i, r_i$. The key assertions are on the `unlock` path.\n\nLet's re-trace the scenario with these checks for `unlock` by thread $T_i$: `assert s = Locked, o = T_i, and h_i = 1`.\n\n1.  `lock(T_1)`: After successful CAS, the state is updated: $s:=\\text{Locked}$, $o:=T_1$, $a_1$ increments, $h_1:=1$.\n2.  `unlock(T_1)`: $T_1$ checks the preconditions.\n    - `assert s = Locked`: True.\n    - `assert o = T_1`: True.\n    - `assert h_1 = 1`: True.\n    All assertions pass. The state is updated: $s:=\\text{Unlocked}$, $o:=\\text{null}$, $h_1:=0$, $r_1$ increments.\n3.  `lock(T_2)`: After successful CAS, the state is updated: $s:=\\text{Locked}$, $o:=T_2$, $a_2$ increments, $h_2:=1$. Note that $h_1$ remains $0$.\n4.  `unlock(T_1)` (buggy call): $T_1$ checks the preconditions.\n    - `assert s = Locked`: True. The lock is held by $T_2$.\n    - `assert o = T_1`: **False.** The current owner $o$ is $T_2$. The assertion fails.\n    - `assert h_1 = 1`: **False.** The hold count for $T_1$, $h_1$, was set to $0$ during its valid unlock in step 2. The assertion fails.\n\nSince at least one assertion necessarily fails, the illegal unlock attempt is detected, preventing the violation of mutual exclusion. The set of checks is sufficient to catch the bug under all interleavings. The global consistency checks ($r_i \\leq a_i$ and $\\sum_i h_i \\in \\{0, 1\\}$) provide additional correctness guarantees, though the per-operation preconditions are sufficient for this specific bug.\n\n**Verdict for B: Correct.**\n\n**C. Maintain only global counters and a state-consistency check: define $A := \\sum_i a_i$ and $R := \\sum_i r_i$, assert $R \\leq A$ at all times, and assert that transitions alternate between $\\text{Unlocked}$ and $\\text{Locked}$ in the global timeline. Do not track $o$ or $h_i$.**\n\nThis approach uses aggregate counters, discarding per-thread information. Let's trace the scenario:\n1.  `lock(T_1)`: $a_1$ becomes $1$. $A=1, R=0$. $s: \\text{Unlocked} \\rightarrow \\text{Locked}$.\n2.  `unlock(T_1)`: $r_1$ becomes $1$. $A=1, R=1$. Check $R \\leq A$ passes. $s: \\text{Locked} \\rightarrow \\text{Unlocked}$.\n3.  `lock(T_2)`: $a_2$ becomes $1$. $A=2, R=1$. Check $R \\leq A$ passes. $s: \\text{Unlocked} \\rightarrow \\text{Locked}$.\n4.  `unlock(T_1)` (buggy): $r_1$ becomes $2$. $A=2, R=2$. Check $R \\leq A$ passes. $s: \\text{Locked} \\rightarrow \\text{Unlocked}$.\n\nThe invariant $R \\leq A$ is not violated. The global sequence of states is $\\text{Unlocked} \\rightarrow \\text{Locked} \\rightarrow \\text{Unlocked} \\rightarrow \\text{Locked} \\rightarrow \\text{Unlocked}$, which is a valid alternating sequence. This method is too coarse-grained to detect that the wrong thread is performing the unlock. It can detect if more unlocks than locks happen globally, but not an ownership violation.\n\n**Verdict for C: Incorrect.**\n\n**D. On unlock, assert that a store-load ordering barrier executes before writing $s := \\text{Unlocked}$, and on acquire, assert that a load-store ordering barrier executes after observing $s = \\text{Locked}$. Do not track $o$, $h_i$, or $(a_i, r_i)$, and do not assert state preconditions.**\n\nThis option focuses on memory ordering, which is a different aspect of lock implementation correctness. Memory barriers ensure that memory operations (reads and writes) performed by different threads on different CPUs appear in a consistent order. Specifically, the unlock barrier ensures that all writes from within the critical section are visible to other threads before the lock is released. The acquire barrier ensures that no reads or writes from the new critical section are reordered to occur before the lock is acquired.\n\nThese barriers are crucial for the correctness of the code *protected by* the lock, but they do not validate the logical sequence of lock/unlock operations themselves. The bug in question is a logical error (a protocol violation), not a memory visibility error. Asserting the presence of barriers does nothing to prevent a thread from calling `unlock` when it is not the owner. An implementation with the buggy client code would have these barriers, and thus the assertions would pass, while the logical flaw remains undetected.\n\n**Verdict for D: Incorrect.**",
            "answer": "$$\\boxed{B}$$"
        }
    ]
}