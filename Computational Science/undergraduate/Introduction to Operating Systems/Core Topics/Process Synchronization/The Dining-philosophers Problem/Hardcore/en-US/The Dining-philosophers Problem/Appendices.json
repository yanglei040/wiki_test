{
    "hands_on_practices": [
        {
            "introduction": "Theory provides the blueprint for avoiding deadlock, but true understanding comes from implementation. This exercise challenges you to build a concurrent simulation of the Dining Philosophers problem using one of the most effective deadlock-prevention techniques: resource hierarchy. By translating the principle of breaking the circular wait condition into working code with mutex locks, you will gain practical experience with fundamental synchronization primitives and solidify your grasp of deadlock avoidance. ",
            "id": "3661790",
            "problem": "You are asked to design, implement, and verify a concurrent simulation of the Dining Philosophers problem using mutex locks, with a deadlock-avoidance strategy based on resource hierarchy. Begin from the following fundamental base: the Coffman deadlock conditions state that a system can deadlock only if all of the following four conditions hold simultaneously: mutual exclusion, hold-and-wait, no preemption, and circular wait. In classical Dining Philosophers with forks modeled as mutually exclusive resources, mutual exclusion, hold-and-wait, and no preemption typically hold by design. Therefore, preventing circular wait is sufficient to ensure deadlock freedom. A well-tested method to prevent circular wait is to impose a strict total order on resources and require that threads acquire resources only in ascending order with respect to this order.\n\nDesign a program that creates $n$ philosopher threads arranged on a ring, indexed $0$ to $n-1$, where philosopher $i$ needs fork $i$ and fork $(i+1) \\bmod n$ to eat. Model each fork as a mutex lock. Implement resource hierarchy by imposing a strict total order on forks according to their indices, and require that each philosopher acquires the fork with the lower index first, followed by the fork with the higher index. In the boundary case where both forks coincide (which happens when $n=1$ because $(0+1) \\bmod 1 = 0$), the philosopher must acquire the single fork exactly once before eating.\n\nEach philosopher must perform exactly $k$ eat cycles. In one eat cycle, the philosopher must:\n- Acquire the required forks respecting the resource hierarchy,\n- Perform a constant-time critical section representing eating,\n- Release any held forks.\n\nAfter all philosopher threads terminate, verify that every philosopher completed exactly $k$ eat cycles. The program must produce a boolean for each test case: output $1$ if every philosopher ate exactly $k$ times and the program terminated, and $0$ otherwise.\n\nTest Suite:\nRun the simulation for the following parameter sets $(n, k)$ to cover a typical case, boundary conditions, and a larger stress case:\n- $(n, k) = (5, 100)$,\n- $(n, k) = (1, 100)$,\n- $(n, k) = (2, 100)$,\n- $(n, k) = (13, 50)$,\n- $(n, k) = (7, 0)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,\\dots,result_m]$). For the above test suite, print $[b_1,b_2,b_3,b_4,b_5]$ where each $b_i$ is $1$ or $0$ as defined earlier. No units are required for the output since the values are dimensionless booleans represented as integers.",
            "solution": "The present problem requires the design and implementation of a concurrent simulation for the Dining Philosophers problem. The solution must prevent deadlock by employing a resource hierarchy strategy, as specified. The system consists of $n$ philosophers and $n$ forks, modeled as threads and mutex locks, respectively. Each philosopher must complete $k$ cycles of thinking, acquiring forks, eating, and releasing forks.\n\n### Principle-Based Design\n\nThe solution is grounded in the principles of concurrent programming and deadlock theory. The Coffman conditions stipulate that deadlock can only occur if mutual exclusion, hold-and-wait, no preemption, and circular wait are all present. Our design inherently includes the first three:\n1.  **Mutual Exclusion**: Each fork is a mutex (`mtx_t`), which by definition can only be held by one thread at a time.\n2.  **Hold-and-Wait**: A philosopher acquires one fork and then holds it while waiting to acquire the second.\n3.  **No Preemption**: A philosopher cannot be forced to release a fork; they release it voluntarily after eating.\n\nTherefore, to prevent deadlock, we must eliminate the fourth condition: **Circular Wait**.\n\n### Deadlock Avoidance via Resource Hierarchy\n\nThe specified deadlock avoidance strategy is a resource hierarchy. This is a standard technique that imposes a global total ordering on all resources. Threads are then required to acquire resources in a sequence consistent with this ordering.\n\n1.  **Resource Modeling**: The $n$ forks are indexed from $0$ to $n-1$. This index serves as the basis for our total order. A fork with a lower index must be acquired before a fork with a higher index.\n\n2.  **Acquisition Logic**:\n    -   Each philosopher $i$ (for $i \\in \\{0, 1, ..., n-1\\}$) is situated between fork $i$ and fork $(i+1) \\bmod n$.\n    -   Let the two required forks for philosopher $i$ be $f_a = i$ and $f_b = (i+1) \\bmod n$.\n    -   The acquisition protocol is as follows:\n        -   Identify the fork with the lower index, `first_fork = min(f_a, f_b)`.\n        -   Identify the fork with the higher index, `second_fork = max(f_a, f_b)`.\n        -   The philosopher must first lock the mutex corresponding to `first_fork`.\n        -   Only then may the philosopher attempt to lock the mutex for `second_fork`.\n\n3.  **Breaking the Cycle**: This protocol breaks the circular wait condition. A classic deadlock scenario involves every philosopher picking up their left fork and waiting for their right fork, forming a circular dependency chain. With resource hierarchy, this chain is broken at philosopher $n-1$, who needs forks $n-1$ and $0$. Instead of acquiring fork $n-1$ and waiting for fork $0$, the protocol forces philosopher $n-1$ to acquire fork $0$ first. Since philosopher $0$ also acquires fork $0$ as their first fork, these two philosophers will contend for fork $0$, serializing their execution and preventing the deadlock cycle.\n\n### Implementation Details\n\nThe implementation is a C program utilizing the `threads.h` library.\n\n1.  **Main Loop**: The `main` function iterates through the specified test suite of $(n, k)$ parameters. For each test case, it orchestrates the simulation.\n\n2.  **Simulation Setup**: For each simulation run with parameters $n$ and $k$:\n    -   An array of $n$ mutexes (`mtx_t`) is allocated and initialized to represent the forks.\n    -   An array of $n$ counters (`int`) is allocated to track the number of times each philosopher has eaten.\n    -   $n$ philosopher threads (`thrd_t`) are created. Each thread is passed its unique ID ($0$ to $n-1$), the total number of philosophers $n$, the target number of eat cycles $k$, a pointer to its personal eat counter, and a pointer to the array of fork mutexes.\n\n3.  **Philosopher Thread Logic (`philosopher_routine`)**:\n    -   The core logic resides in this thread function. It executes a loop $k$ times.\n    -   In each iteration, it implements the fork acquisition, eating, and release cycle.\n    -   The fork indices are calculated, and the `min`/`max` logic is applied to determine the acquisition order.\n    -   A special check, `if (first_fork_idx != second_fork_idx)`, is crucial. It correctly handles the boundary case $n=1$, where both required forks are the same (fork $0$). This prevents the undefined behavior of attempting to lock an already-held non-recursive mutex.\n    -   After successfully acquiring the necessary forks, the \"eating\" phase is a conceptual critical section. The thread then releases the forks in the reverse order of acquisition.\n    -   Once the loop of $k$ cycles completes, the thread records its completion by setting its eat counter to $k$.\n\n4.  **Verification**: After creating all threads, the main thread waits for all of them to complete using `thrd_join`. Once all philosophers have finished, the main thread verifies the outcome. It iterates through the eat counters. If every counter equals $k$, the simulation for that test case is successful, and the result is $1$. Otherwise, it is $0$.\n\n5.  **Cleanup**: All mutexes are destroyed, and all dynamically allocated memory is freed to prevent resource leaks.\n\nThe final program collates the boolean results from each test case and prints them in the specified format $[b_1,b_2,...,b_m]$. The solution is robust and correctly implements the prescribed deadlock-avoidance mechanism for all given test cases, including boundary conditions such as $n=1$ and $k=0$.",
            "answer": "```c\n// The complete and compilable C program goes here.\n// Headers must adhere to the specified restrictions.\n#include stdio.h\n#include stdlib.h\n#include string.h\n#include math.h\n#include complex.h\n#include threads.h\n#include stdatomic.h\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    int n; // Number of philosophers\n    int k; // Number of eat cycles\n} TestCase;\n\n// Data passed to each philosopher thread.\ntypedef struct {\n    int id;\n    int num_philosophers;\n    int eat_cycles_k;\n    int* eat_count;\n    mtx_t* forks;\n} PhilosopherArgs;\n\n// The function executed by each philosopher thread.\nint philosopher_routine(void* arg) {\n    PhilosopherArgs* data = (PhilosopherArgs*)arg;\n    int id = data-id;\n    int n = data-num_philosophers;\n    int k = data-eat_cycles_k;\n    mtx_t* forks = data-forks;\n\n    if (k == 0) {\n        *(data-eat_count) = 0;\n        return thrd_success;\n    }\n\n    // Determine fork indices\n    int left_fork = id;\n    int right_fork = (id + 1) % n;\n\n    // Apply resource hierarchy: always acquire lower-indexed fork first\n    int first_fork_idx, second_fork_idx;\n    if (left_fork  right_fork) {\n        first_fork_idx = left_fork;\n        second_fork_idx = right_fork;\n    } else {\n        first_fork_idx = right_fork;\n        second_fork_idx = left_fork;\n    }\n\n    for (int i = 0; i  k; ++i) {\n        // Acquire forks\n        mtx_lock(forks[first_fork_idx]);\n        // Handle n=1 case where right_fork == left_fork.\n        // Don't try to lock the same mutex twice.\n        if (first_fork_idx != second_fork_idx) {\n            mtx_lock(forks[second_fork_idx]);\n        }\n\n        // --- Critical Section: \"Eating\" ---\n        // This block represents the philosopher eating.\n        // No actual work/delay is needed for this simulation.\n\n        // Release forks in reverse order\n        if (first_fork_idx != second_fork_idx) {\n            mtx_unlock(forks[second_fork_idx]);\n        }\n        mtx_unlock(forks[first_fork_idx]);\n    }\n\n    *(data-eat_count) = k;\n    return thrd_success;\n}\n\n// Runs one full simulation for a given (n, k) and returns 1 on success, 0 on failure.\nint run_simulation(int n, int k) {\n    if (n = 0) {\n        return (n == 0) ? 1 : 0; // Vacuously true for n=0, false for n0.\n    }\n\n    mtx_t* forks = malloc((size_t)n * sizeof(mtx_t));\n    thrd_t* threads = malloc((size_t)n * sizeof(thrd_t));\n    int* eat_counts = calloc((size_t)n, sizeof(int));\n    PhilosopherArgs* p_args = malloc((size_t)n * sizeof(PhilosopherArgs));\n\n    if (!forks || !threads || !eat_counts || !p_args) {\n        free(forks);\n        free(threads);\n        free(eat_counts);\n        free(p_args);\n        return 0; // Memory allocation failure\n    }\n\n    for (int i = 0; i  n; ++i) {\n        if (mtx_init(forks[i], mtx_plain) != thrd_success) {\n            for (int j = 0; j  i; ++j) mtx_destroy(forks[j]);\n            free(forks);\n            free(threads);\n            free(eat_counts);\n            free(p_args);\n            return 0; // Mutex initialization failure\n        }\n    }\n\n    for (int i = 0; i  n; ++i) {\n        p_args[i] = (PhilosopherArgs){.id = i,\n                                      .num_philosophers = n,\n                                      .eat_cycles_k = k,\n                                      .eat_count = eat_counts[i],\n                                      .forks = forks};\n        if (thrd_create(threads[i], philosopher_routine, p_args[i]) != thrd_success) {\n            // In a real-world scenario, would need to gracefully stop already\n            // created threads. For this problem, we treat it as a fatal error.\n            // In practice, this failure is highly unlikely here.\n            for (int j = 0; j  n; ++j) mtx_destroy(forks[j]);\n            free(forks);\n            free(threads);\n            free(eat_counts);\n            free(p_args);\n            return 0;\n        }\n    }\n\n    for (int i = 0; i  n; ++i) {\n        thrd_join(threads[i], NULL);\n    }\n\n    // Verification\n    int success = 1;\n    for (int i = 0; i  n; ++i) {\n        if (eat_counts[i] != k) {\n            success = 0;\n            break;\n        }\n    }\n\n    // Cleanup\n    for (int i = 0; i  n; ++i) {\n        mtx_destroy(forks[i]);\n    }\n    free(forks);\n    free(threads);\n    free(eat_counts);\n    free(p_args);\n\n    return success;\n}\n\nint main(void) {\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        {5, 100}, {1, 100}, {2, 100}, {13, 50}, {7, 0}};\n\n    // Calculate the number of test cases.\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    int results[num_cases];\n\n    // Calculate the result for each test case.\n    for (int i = 0; i  num_cases; ++i) {\n        results[i] = run_simulation(test_cases[i].n, test_cases[i].k);\n    }\n\n    // Print the results in the EXACT REQUIRED format before the final return statement.\n    printf(\"[\");\n    for (int i = 0; i  num_cases; ++i) {\n        printf(\"%d\", results[i]);\n        if (i  num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\\n\");\n\n    return EXIT_SUCCESS;\n}\n```"
        },
        {
            "introduction": "While preventing deadlocks is often the primary goal, in some complex systems it is more practical to detect them and recover. This practice shifts our focus from prevention to detection, using a formal structure called a Wait-For Graph (WFG). You are tasked with developing and implementing an efficient online algorithm to spot a cycle—the definitive sign of deadlock in this system—the moment it forms, a task that requires blending data structures and concurrent reasoning. ",
            "id": "3687542",
            "problem": "Consider the classical Dining Philosophers system with $N$ philosophers labeled $0,1,\\dots,N-1$ seated on a ring and $N$ forks, where fork $i$ is shared by philosophers $i$ and $(i+1) \\bmod N$. Each fork is a single-instance resource. Model resource acquisition as an online sequence of events: whenever philosopher $u$ attempts to acquire a fork held by neighbor philosopher $v$ and must wait, create a directed edge $u \\to v$ in the Wait-For Graph (WFG). The WFG is a directed graph whose vertices are the philosophers and whose edges represent wait dependencies between philosophers. In a single-instance resource setting, cycle existence in the WFG is both necessary and sufficient for deadlock among the set of vertices in the cycle.\n\nYour tasks are as follows:\n- Starting from the core definitions of deadlock and the Wait-For Graph (WFG), formally derive an online cycle-detection algorithm for the WFG that runs with amortized $\\mathcal{O}(1)$ time per fork acquisition event. You must justify why its amortized complexity is plausible, and under what structural properties of the Dining Philosophers problem the algorithm is correct.\n- Implement this algorithm as a complete, runnable program that processes a fixed test suite of event sequences described below. The program must identify, for each test case, the earliest acquisition event index (counted $1$-based) at which a directed cycle first appears in the WFG. If no cycle appears after processing all events in a test case, the result for that test case must be $-1$.\n\nThe online event model for each test case is as follows: an event is an ordered pair $(u,v)$ where $u$ is the philosopher who attempts to acquire a fork and waits because neighbor $v$ currently holds it. When processing the event $(u,v)$, add the directed edge $u \\to v$ to the WFG if $u$ does not already have an outgoing edge (a philosopher can be waiting for at most one fork at any time). Immediately after adding the edge, determine if there is any directed cycle in the WFG.\n\nThe test suite consists of five test cases that cover general behavior and edge cases:\n- Test case $1$: $N=5$, events $\\big[(0,1),(1,2),(2,3),(3,4),(4,0)\\big]$. This models the classical deadlock formation when each philosopher holds one fork and waits for the next. A cycle should form at the $5$-th event.\n- Test case $2$: $N=2$, events $\\big[(0,1),(1,0)\\big]$. A cycle forms at the $2$-nd event.\n- Test case $3$: $N=5$, events $\\big[(0,1),(2,3),(4,0)\\big]$. No cycle forms; the answer should be $-1$.\n- Test case $4$: $N=3$, events $\\big[(0,1),(1,2),(2,0)\\big]$. A cycle forms at the $3$-rd event.\n- Test case $5$: $N=4$, events $\\big[\\,\\big]$ (empty sequence). No cycle forms; the answer should be $-1$.\n\nFinal output specification:\n- Your program must produce a single line of output containing the results for the five test cases as a comma-separated list enclosed in square brackets, in the exact order listed above. For example, a valid output line would look like $\\big[5,2,-1,3,-1\\big]$ for the case where cycles are detected at the $5$-th and $2$-nd and $3$-rd events for the first, second, and fourth test cases, respectively, and none for the third and fifth.\n\nNo physical units or angle units are involved; results are integers. The memory usage of your implementation must be $\\mathcal{O}(N)$ for each test case, and the per-event processing time must be amortized $\\mathcal{O}(1)$ under the assumptions you justify in your derivation.",
            "solution": "The problem requires the derivation and implementation of an online cycle-detection algorithm for a Wait-For Graph (WFG) generated by a Dining Philosophers system. The algorithm must have an amortized time complexity of $\\mathcal{O}(1)$ per event and a memory complexity of $\\mathcal{O}(N)$.\n\nTo begin, we analyze the structural properties of the WFG as defined in the problem statement. The graph's vertices are the $N$ philosophers. A directed edge $u \\to v$ is created when philosopher $u$ starts waiting for a fork held by philosopher $v$. A critical constraint is provided: \"a philosopher can be waiting for at most one fork at any time\". This translates to a fundamental graph-theoretic property: the out-degree of any vertex $u$, denoted $\\text{deg}^+(u)$, is at most $1$.\n$$ \\forall u \\in V, \\quad \\text{deg}^+(u) \\le 1 $$\nA directed graph with this property is known as a functional graph. Each connected component of a functional graph consists of a set of directed trees whose roots point into a single directed cycle, or a single directed path which can be viewed as a tree whose root has no outgoing edge within the component.\n\nThe problem specifies an online process where an edge $u \\to v$ is added only if philosopher $u$ was not previously waiting. This means that just before adding the edge $u \\to v$, the out-degree of $u$ must have been $0$, i.e., $\\text{deg}^+(u) = 0$. In our path-based structural view, a vertex with an out-degree of $0$ is a \"tail\" of a path.\n\nAn edge addition $u \\to v$ can create a cycle if and only if there was already a directed path from $v$ to $u$ in the graph *before* the edge was added. Let such a path be $v \\to w_1 \\to \\dots \\to w_k \\to u$. Adding the edge $u \\to v$ closes this path into the cycle $u \\to v \\to w_1 \\to \\dots \\to w_k \\to u$. The task of cycle detection is therefore equivalent to answering the reachability query: \"Is $u$ reachable from $v$?\"\n\nA naive approach to answer this query would be to perform a graph traversal (like Depth-First Search or Breadth-First Search) starting from $v$. Since the out-degree of any vertex is at most $1$, the path from $v$ is unique. We can simply follow the successor pointers: $v, \\text{successor}[v], \\text{successor}[\\text{successor}[v]], \\dots$ until we either find $u$ or reach the end of the path (a vertex with no successor). In the worst case, this traversal could visit up to $N-1$ other vertices, leading to an $\\mathcal{O}(N)$ time complexity per event, which does not meet the requirement.\n\nTo achieve amortized $\\mathcal{O}(1)$ complexity, we need a more efficient way to manage path information. This can be achieved using a data structure analogous to a Disjoint Set Union (DSU) or Union-Find structure. Each distinct path in the WFG can be considered a \"set\" of vertices. The key idea is to associate a unique representative with each set. A canonical choice for the representative of a path is its tail (the vertex with out-degree $0$).\n\nLet's formalize this DSU-based approach.\n1.  **Data Structures**: We use an array, `path_tail[N]`, where `path_tail[i]` stores the representative (the tail) of the path containing philosopher $i$. Initially, each philosopher is in their own path of length zero, so we initialize `path_tail[i] = i` for all $i \\in \\{0, \\dots, N-1\\}$. We also use a `successor[N]` array to represent the WFG edges, initialized to a sentinel value (e.g., $-1$).\n\n2.  **`find_tail(i)` Operation**: This function finds the tail of the path containing philosopher $i$. It is analogous to the `find` operation in a DSU. To achieve the desired amortized complexity, we use path compression. When we find the tail for a philosopher `i`, we update `path_tail[i]` to point directly to it.\n    ```\n    function find_tail(i):\n        if path_tail[i] == i:\n            return i\n        // Path compression:\n        path_tail[i] = find_tail(path_tail[i])\n        return path_tail[i]\n    ```\n\n3.  **`union(u, v)` Operation**: This is analogous to the `union` operation. When we add an edge $u \\to v$, we are effectively merging the path that ends at $u$ with the path that contains $v$. The tail of the newly formed path is the tail of the original path containing $v$. Let $t_u = \\text{find\\_tail}(u)$ and $t_v = \\text{find\\_tail}(v)$. The union operation sets the representative of $t_u$'s set to be $t_v$. That is, `path_tail[t_u] = t_v`.\n\n4.  **Online Algorithm for Event $(u, v)$**:\n    *   An event $(u, v)$ means philosopher $u$ starts waiting for a resource held by $v$. As per the problem, $u$ was not waiting before, so $\\text{deg}^+(u)=0$. This implies that $u$ is the tail of its current path. Therefore, before the event, `find_tail(u)` must return $u$.\n    *   **Cycle Detection**: A cycle is formed if $v$ is part of a path that already terminates at $u$. This is true if and only if the tail of the path containing $v$ is $u$. So, we compute $t_v = \\text{find\\_tail}(v)$ and check if $t_v == u$. If they are equal, adding the edge $u \\to v$ will form a cycle.\n    *   **Update (if no cycle)**: If $t_v \\neq u$, no cycle is formed. We update the data structures to reflect the new edge:\n        a.  Set `successor[u] = v`.\n        b.  Perform the union operation: the path ending in $u$ is now joined to the path of $v$. The new tail for $u$'s path is the tail of $v$'s path. Since $u$ was its own representative (`find_tail(u) == u`), this union is simply `path_tail[u] = find_tail(v)`.\n\n**Amortized Complexity Justification**: The `find_tail` operation uses path compression. A sequence of $M$ `find_tail` and `union` operations on a set of $N$ elements takes $\\mathcal{O}(M \\cdot \\alpha(N))$ time, where $\\alpha(N)$ is the extremely slow-growing inverse Ackermann function. For any practical value of $N$, $\\alpha(N)$ is a small constant (less than $5$). Thus, the amortized time complexity per event, which involves one `find_tail` and one `union` (pointer update), is effectively $\\mathcal{O}(1)$. The memory required is for the `successor` and `path_tail` arrays, both of size $N$, leading to an overall memory complexity of $\\mathcal{O}(N)$.\n\n**Correctness Under Structural Properties**: The algorithm's correctness hinges on two properties from the problem statement:\n1.  $\\text{deg}^+(w) \\le 1$ for any philosopher $w$, ensuring the WFG is a functional graph (a collection of paths and cycles).\n2.  An edge $u \\to v$ is added only when $\\text{deg}^+(u)=0$, meaning $u$ is a tail node.\n\nThese two properties guarantee that our cycle-detection condition (`find_tail(v) == u`) is both necessary and sufficient. If the condition holds, there is a path $v \\to \\dots \\to u$, and adding $u \\to v$ completes a cycle. If the condition does not hold, $u$ and $v$ are on disjoint paths, and joining them creates a single, longer path, not a cycle.\n\nThe implementation will follow this DSU-based logic to process the given test suite.",
            "answer": "```c\n#include stdio.h\n#include stdlib.h\n#include string.h\n// #include math.h // Not used\n// #include complex.h // Not used\n// #include threads.h // Not used\n// #include stdatomic.h // Not used\n\n// An event where philosopher u waits for v.\ntypedef struct {\n    int u;\n    int v;\n} Event;\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    int N;             // Number of philosophers\n    const Event* events; // Sequence of wait-for events\n    int num_events;    // Number of events in the sequence\n} TestCase;\n\n/**\n * @brief Finds the representative (tail of the path) for a given philosopher.\n *\n * This function implements the \"find\" operation of a Disjoint Set Union (DSU)\n * data structure with path compression. It recursively finds the final tail of\n * the path and updates the path_tail array along the way to flatten the structure,\n * achieving amortized O(1) complexity.\n *\n * @param i The philosopher for whom to find the path tail.\n * @param path_tail The DSU array where path_tail[j] is the next node in the path to the representative.\n * @return The tail of the path containing philosopher i.\n */\nint find_tail(int i, int path_tail[]) {\n    if (path_tail[i] == i) {\n        return i;\n    }\n    // Path compression\n    path_tail[i] = find_tail(path_tail[i], path_tail);\n    return path_tail[i];\n}\n\nint main(void) {\n    // Define the event sequences for the test cases.\n    const Event events1[] = {{0, 1}, {1, 2}, {2, 3}, {3, 4}, {4, 0}};\n    const Event events2[] = {{0, 1}, {1, 0}};\n    const Event events3[] = {{0, 1}, {2, 3}, {4, 0}};\n    const Event events4[] = {{0, 1}, {1, 2}, {2, 0}};\n    const Event events5[] = {};\n\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        {5, events1, sizeof(events1) / sizeof(events1[0])},\n        {2, events2, sizeof(events2) / sizeof(events2[0])},\n        {5, events3, sizeof(events3) / sizeof(events3[0])},\n        {3, events4, sizeof(events4) / sizeof(events4[0])},\n        {4, events5, sizeof(events5) / sizeof(events5[0])},\n    };\n\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    int results[num_cases];\n\n    // Calculate the result for each test case.\n    for (int i = 0; i  num_cases; ++i) {\n        int N = test_cases[i].N;\n        const Event* events = test_cases[i].events;\n        int num_events = test_cases[i].num_events;\n\n        // The path_tail array serves as the parent array for the DSU data structure.\n        // path_tail[j] stores the representative for the path containing philosopher j.\n        // Initially, each philosopher is the tail of their own path.\n        int* path_tail = (int*)malloc(N * sizeof(int));\n        if (path_tail == NULL) { return EXIT_FAILURE; }\n\n        for (int j = 0; j  N; ++j) {\n            path_tail[j] = j;\n        }\n\n        int first_cycle_event = -1; // Default to -1 (no cycle).\n\n        for (int j = 0; j  num_events; ++j) {\n            int u = events[j].u;\n            int v = events[j].v;\n\n            // Before adding edge u - v, u has out-degree 0.\n            // Thus, u is the tail of its path, so find_tail(u) would be u.\n            // A cycle is formed if the tail of v's path is already u.\n            int tail_v = find_tail(v, path_tail);\n\n            if (tail_v == u) {\n                first_cycle_event = j + 1; // 1-based event index\n                break; // Cycle found, no need to process further events for this test case.\n            }\n\n            // No cycle formed. Update the structure.\n            // This is the \"union\" operation. We merge the path ending at u\n            // with the path containing v. The representative of u's path now\n            // becomes the representative of v's path.\n            // Since u is its own representative before this union, this simplifies to:\n            path_tail[u] = tail_v;\n        }\n\n        results[i] = first_cycle_event;\n        free(path_tail);\n    }\n\n    // Print the results in the EXACT REQUIRED format.\n    printf(\"[\");\n    for (int i = 0; i  num_cases; ++i) {\n        printf(\"%d\", results[i]);\n        if (i  num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\\n\");\n\n    return EXIT_SUCCESS;\n}\n```"
        },
        {
            "introduction": "With multiple correct, deadlock-free solutions, how do we choose the \"best\" one? This final practice moves beyond correctness to the crucial engineering domain of evaluation, challenging you to think like a systems researcher. You must design a scientifically rigorous experiment to compare different algorithms based on concrete metrics like throughput ($\\lambda$), wait time ($W$), and fairness ($J$). This exercise highlights the critical importance of sound methodology—from handling statistical variance and initialization bias to defining metrics precisely—to produce meaningful and defensible conclusions. ",
            "id": "3687546",
            "problem": "Consider a system implementing the Dining Philosophers problem with $N$ philosophers arranged around a table, each philosopher having a fork to the left and right. Philosophers alternate between thinking and eating. A philosopher becomes hungry, requests the two adjacent forks, and starts eating only after acquiring both forks. Think times and eat times are independent and identically distributed across philosophers and cycles with exponential distributions having means $\\tau_{\\text{think}}$ and $\\tau_{\\text{eat}}$ seconds, respectively. You must compare three algorithms as $N$ grows over the set $\\{5, 10, 20, 40\\}$:\n\n- Algorithm $\\mathrm{S}$ (symmetric naive): Each philosopher first acquires the left fork, then the right fork. This algorithm is susceptible to deadlock.\n- Algorithm $\\mathrm{R}$ (resource hierarchy): Impose a total order on forks; every philosopher acquires the lower-numbered fork first, then the higher-numbered fork. This algorithm prevents deadlock by eliminating circular wait.\n- Algorithm $\\mathrm{W}$ (waiter): A centralized waiter grants permission to a philosopher only if both adjacent forks are available, otherwise the request waits. This algorithm prevents deadlock without unnecessarily limiting concurrency beyond fork availability.\n\nYou will use performance counters to define and estimate three metrics over long runs in steady state:\n\n- System throughput $\\lambda$: the long-run rate of completed eating cycles (across all philosophers) per unit time.\n- Average wait $W$: the expected time from a philosopher’s first request for forks at the start of a hungry episode to the start of eating.\n- Jain’s fairness index $J$: computed over per-philosopher throughputs $x_i$ and defined by $J = \\dfrac{\\left(\\sum_{i=1}^{N} x_i\\right)^2}{N \\sum_{i=1}^{N} x_i^2}$.\n\nAssume the following foundational principles from concurrency and performance analysis: mutual exclusion must hold on forks; liveness (progress) and bounded waiting are desired properties; steady-state averages are well-defined when the system is ergodic; unbiased estimation requires removal of transients and sufficient samples per philosopher; deadlock is a terminal condition for Algorithm $\\mathrm{S}$ that halts progress.\n\nWhich option below is the most scientifically sound experimental plan and correct metric computation method to compare Algorithms $\\mathrm{S}$, $\\mathrm{R}$, and $\\mathrm{W}$ as $N$ grows, yielding unbiased estimates and valid cross-$N$ comparisons?\n\nA. For each $N$ and algorithm, run a single simulation of fixed duration $T$ with no warm-up, record the total number of fork acquisitions as throughput $\\lambda = \\dfrac{\\text{acquisitions}}{T}$, compute $W$ as the average time between acquiring the first fork and acquiring the second, and compute fairness $J$ over per-philosopher average waits using $x_i = W_i$. If Algorithm $\\mathrm{S}$ deadlocks, set $\\lambda = 0$, $W = +\\infty$, and $J = 0$.\n\nB. For each $N$ and algorithm, run until each philosopher has completed a fixed number $M$ of eating cycles, then stop. Compute $\\lambda = \\dfrac{N M}{T_{\\text{stop}}}$ where $T_{\\text{stop}}$ is the elapsed time, define $W$ as the average time between the end of thinking and the start of eating, and compute $J$ as $J = \\dfrac{\\sum_{i=1}^{N} x_i^2}{\\left(\\sum_{i=1}^{N} x_i\\right)^2}$ on per-philosopher completions $x_i = M$. If Algorithm $\\mathrm{S}$ deadlocks before all philosophers reach $M$, immediately restart the run with a new random seed, discarding the deadlocked run.\n\nC. For each $N$ and algorithm, perform one long run with no replication, use a brief warm-up $T_w$ independent of $N$, compute $\\lambda$ as the sum of successful first-fork grabs per unit time, compute $W$ from the time between issuing a request and acquiring the first fork, and compute fairness $J$ from per-philosopher first-fork grab rates $x_i$. If Algorithm $\\mathrm{S}$ deadlocks, ignore it and continue measuring other philosophers.\n\nD. For each $N$ and algorithm, perform $R$ independent replications with different random seeds. In each replication, apply a warm-up period $T_w$ that scales with $N$ (for example, $T_w = c \\cdot N \\cdot \\max\\{\\tau_{\\text{think}}, \\tau_{\\text{eat}}\\}$ for a fixed constant $c$) to reduce transients, then measure over a window $T_m$ that also scales with $N$ to maintain roughly constant expected samples per philosopher (for example, $T_m = c' \\cdot N \\cdot \\tau_{\\text{eat}}$ for fixed $c'$). Compute $\\lambda = \\dfrac{C}{T_m}$, where $C$ is the total number of completed eating cycles during measurement, compute per-philosopher throughputs $x_i = \\dfrac{C_i}{T_m}$, compute $J = \\dfrac{\\left(\\sum_{i=1}^{N} x_i\\right)^2}{N \\sum_{i=1}^{N} x_i^2}$, and compute $W$ as the average time from the instant a philosopher issues the fork request to the instant eating begins. Detect deadlock in Algorithm $\\mathrm{S}$; if deadlock occurs during the measurement window, record the deadlock incidence and $\\lambda \\to 0$, and exclude that replication from $W$ and $J$ (which are undefined when no eating occurs), while still including deadlock incidence as a separate liveness metric. Aggregate estimates over the $R$ replications with confidence intervals for each $N$ and algorithm, and compare trends as $N$ grows.",
            "solution": "The task is to identify the most scientifically sound experimental plan for comparing three different algorithms for the Dining Philosophers problem. The comparison involves measuring system throughput ($\\lambda$), average wait time ($W$), and fairness ($J$) as the number of philosophers ($N$) increases. A sound experimental plan for a stochastic simulation must address several key aspects: eliminating initialization bias, ensuring statistical validity through replication, defining and measuring metrics correctly, handling specific failure modes like deadlock, and ensuring fair comparisons across different system scales.\n\n### Validation of the Problem Statement\n\nFirst, the problem statement itself is subjected to validation.\n\n**Step 1: Extract Givens**\n- System: Dining Philosophers problem with $N$ philosophers, where $N \\in \\{5, 10, 20, 40\\}$.\n- Processes: Philosophers alternate between thinking and eating.\n- Resources: $N$ forks, with each philosopher requiring two adjacent forks to eat.\n- Stochasticity: Think and eat times are i.i.d. exponential random variables with means $\\tau_{\\text{think}}$ and $\\tau_{\\text{eat}}$, respectively.\n- Algorithms:\n    - S (symmetric naive): Left fork then right fork; prone to deadlock.\n    - R (resource hierarchy): Forks are ordered; acquire lower-numbered fork first; deadlock-free.\n    - W (waiter): Centralized waiter grants atomic access to both forks; deadlock-free.\n- Metrics:\n    - Throughput $\\lambda$: Long-run rate of completed eating cycles per unit time.\n    - Average Wait $W$: Expected time from first fork request to start of eating.\n    - Jain's Fairness Index $J$: $J = \\dfrac{\\left(\\sum_{i=1}^{N} x_i\\right)^2}{N \\sum_{i=1}^{N} x_i^2}$, based on per-philosopher throughputs $x_i$.\n- Foundational Principles: Mutual exclusion, desire for liveness and bounded waiting, assumption of ergodicity for steady-state analysis, requirement for unbiased estimation via transient removal and sufficient sampling, and treatment of deadlock as a terminal state.\n- Question: Identify the most scientifically sound experimental plan and metric computation method.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem statement is scientifically sound.\n- **Scientifically Grounded**: The Dining Philosophers problem is a canonical problem in concurrent programming and operating systems. The algorithms presented (naive, resource hierarchy, waiter/monitor) are standard examples. The performance metrics ($\\lambda, W, J$) are standard in performance evaluation. The use of stochastic simulation with exponential distributions is a well-established methodology in queueing theory and system modeling.\n- **Well-Posed**: The question asks to evaluate and select the best methodology from a set of choices. This is a clear, well-defined task. The objective—to obtain unbiased estimates and enable valid cross-$N$ comparisons—is explicit.\n- **Objective**: The language is precise and technical, free of subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. I will proceed with the analysis of the provided options.\n\n### Option-by-Option Analysis\n\nThe evaluation of each option is based on established principles of performance evaluation for stochastic systems.\n\n**A. For each $N$ and algorithm, run a single simulation of fixed duration $T$ with no warm-up, record the total number of fork acquisitions as throughput $\\lambda = \\dfrac{\\text{acquisitions}}{T}$, compute $W$ as the average time between acquiring the first fork and acquiring the second, and compute fairness $J$ over per-philosopher average waits using $x_i = W_i$. If Algorithm $\\mathrm{S}$ deadlocks, set $\\lambda = 0$, $W = +\\infty$, and $J = 0$.**\n\n- **Warm-up**: The absence of a warm-up period (\"no warm-up\") is a critical flaw. The initial state of the simulation (e.g., all philosophers thinking) is not representative of the steady-state behavior. Measurements taken from the start will be biased.\n- **Replication**: Using a \"single simulation\" provides only one sample point from a stochastic process. It is impossible to estimate statistical uncertainty (e.g., confidence intervals) or to determine if observed differences are significant or due to chance.\n- **Throughput $\\lambda$**: The metric is misidentified as being based on \"fork acquisitions\". The problem defines $\\lambda$ in terms of \"completed eating cycles\". These are not equivalent; a philosopher can acquire one fork but fail to complete a cycle.\n- **Wait Time $W$**: The proposed measurement of $W$, \"time between acquiring the first fork and acquiring the second\", is incorrect. The problem defines $W$ as the total time from the *initial request* to the *start of eating*. This option omits the wait for the first fork.\n- **Fairness $J$**: The proposal to compute $J$ over \"per-philosopher average waits\" contradicts the problem's definition, which explicitly states it should be computed over \"per-philosopher throughputs $x_i$\".\n\n**Verdict**: **Incorrect**. This option is riddled with fundamental errors in experimental methodology and metric definition.\n\n**B. For each $N$ and algorithm, run until each philosopher has completed a fixed number $M$ of eating cycles, then stop. Compute $\\lambda = \\dfrac{N M}{T_{\\text{stop}}}$ where $T_{\\text{stop}}$ is the elapsed time, define $W$ as the average time between the end of thinking and the start of eating, and compute $J$ as $J = \\dfrac{\\sum_{i=1}^{N} x_i^2}{\\left(\\sum_{i=1}^{N} x_i\\right)^2}$ on per-philosopher completions $x_i = M$. If Algorithm $\\mathrm{S}$ deadlocks before all philosophers reach $M$, immediately restart the run with a new random seed, discarding the deadlocked run.**\n\n- **Deadlock Handling**: The instruction to \"discard...the deadlocked run\" introduces severe survivorship bias. Deadlock is a key characteristic of Algorithm S. By discarding runs where it occurs, the evaluation would be limited to only the non-deadlocking (and thus unrepresentative) sample paths, leading to a grossly inaccurate and overly optimistic assessment of Algorithm S's performance and liveness.\n- **Fairness $J$**: The formula for $J$ is inverted. The correct formula for Jain's index is given in the problem statement. Furthermore, defining the inputs as $x_i = M$ is nonsensical. If every philosopher completes $M$ cycles, every $x_i$ would be identical, and $J$ would misleadingly compute to $1$ (perfect fairness) regardless of the actual time taken. Fairness should be computed on rates (throughputs), not total counts in this scenario.\n- **Warm-up/Replication**: The plan lacks an explicit warm-up phase and a systematic replication strategy for all conditions (it only mentions re-running for deadlocks).\n\n**Verdict**: **Incorrect**. The mishandling of deadlock is a fatal flaw, and the calculation of the fairness index is mathematically and conceptually wrong.\n\n**C. For each $N$ and algorithm, perform one long run with no replication, use a brief warm-up $T_w$ independent of $N$, compute $\\lambda$ as the sum of successful first-fork grabs per unit time, compute $W$ from the time between issuing a request and acquiring the first fork, and compute fairness $J$ from per-philosopher first-fork grab rates $x_i$. If Algorithm $\\mathrm{S}$ deadlocks, ignore it and continue measuring other philosophers.**\n\n- **Replication**: \"one long run with no replication\" is statistically poor practice, as noted for option A.\n- **Warm-up Scalability**: A warm-up time $T_w$ that is \"independent of $N$\" is a poor design choice. The time required for a system to reach steady state (mixing time) typically increases with the system size $N$. A $T_w$ adequate for $N=5$ would likely be insufficient for $N=40$.\n- **Metric Definitions**: The definitions for $\\lambda$, $W$, and the basis for $J$ are all incorrect. They are based on \"first-fork grabs\" rather than completed eating cycles. This fails to measure actual progress or total waiting time as defined.\n- **Deadlock Handling**: The instruction to \"ignore it and continue measuring other philosophers\" reveals a misunderstanding of deadlock. In the specified system, a deadlock involving a cycle of philosophers will prevent their neighbors from ever acquiring two forks, potentially halting the entire system. It is not possible to \"ignore\" a deadlock; it is an absorbing state for the involved philosophers and has cascading effects on others.\n\n**Verdict**: **Incorrect**. This option demonstrates multiple conceptual misunderstandings of the system dynamics, performance metrics, and proper experimental scaling.\n\n**D. For each $N$ and algorithm, perform $R$ independent replications with different random seeds. In each replication, apply a warm-up period $T_w$ that scales with $N$ (for example, $T_w = c \\cdot N \\cdot \\max\\{\\tau_{\\text{think}}, \\tau_{\\text{eat}}\\}$ for a fixed constant $c$) to reduce transients, then measure over a window $T_m$ that also scales with $N$ to maintain roughly constant expected samples per philosopher (for example, $T_m = c' \\cdot N \\cdot \\tau_{\\text{eat}}$ for fixed $c'$). Compute $\\lambda = \\dfrac{C}{T_m}$, where $C$ is the total number of completed eating cycles during measurement, compute per-philosopher throughputs $x_i = \\dfrac{C_i}{T_m}$, compute $J = \\dfrac{\\left(\\sum_{i=1}^{N} x_i\\right)^2}{N \\sum_{i=1}^{N} x_i^2}$, and compute $W$ as the average time from the instant a philosopher issues the fork request to the instant eating begins. Detect deadlock in Algorithm $\\mathrm{S}$; if deadlock occurs during the measurement window, record the deadlock incidence and $\\lambda \\to 0$, and exclude that replication from $W$ and $J$ (which are undefined when no eating occurs), while still including deadlock incidence as a separate liveness metric. Aggregate estimates over the $R$ replications with confidence intervals for each $N$ and algorithm, and compare trends as $N$ grows.**\n\n- **Replication and Warm-up**: The plan correctly calls for independent replications to ensure statistical validity and for a warm-up period to remove initialization bias.\n- **Scalability**: Crucially, it specifies that both the warm-up ($T_w$) and measurement ($T_m$) periods should scale with $N$. This is essential for a fair comparison across different system sizes, ensuring that the system has reached steady state and that a comparable number of samples per entity are collected in each configuration.\n- **Metric Definitions**: The computations for throughput ($\\lambda$), per-philosopher throughput ($x_i$), Jain's fairness index ($J$), and average wait time ($W$) are all precise and perfectly match the definitions provided in the problem statement.\n- **Deadlock Handling**: The handling of deadlock is exemplary. It is treated as an important, measurable outcome (\"record deadlock incidence\"). The consequences for that specific run ($\\lambda \\to 0$, exclusion from $W$ and $J$ statistics) are logically sound, as these metrics become ill-defined. This approach provides a complete and honest characterization of Algorithm S's behavior, separating its liveness properties (deadlock) from its performance properties in non-deadlocking cases.\n- **Analysis**: The final step of aggregating results and computing confidence intervals represents a complete and rigorous scientific methodology.\n\n**Verdict**: **Correct**. This option describes a comprehensive, methodologically rigorous, and scientifically sound experimental plan that adheres to all best practices for simulation-based performance analysis.",
            "answer": "$$\\boxed{D}$$"
        }
    ]
}