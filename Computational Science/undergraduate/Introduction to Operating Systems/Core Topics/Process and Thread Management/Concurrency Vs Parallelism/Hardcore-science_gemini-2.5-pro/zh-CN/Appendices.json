{
    "hands_on_practices": [
        {
            "introduction": "并发系统并不总能通过增加处理器核心来获得理想的性能提升。这个练习将通过应用阿姆达尔定律（Amdahl's Law）来揭示并行计算的根本限制。通过为一个假设的服务器工作负载计算可并行的比例，你将亲手量化一个小的串行部分（如一个临界区）如何显著限制多核处理器所能带来的整体加速效果，从而加深对并发和并行之间差异的理解 。",
            "id": "3626997",
            "problem": "一个服务器应用程序在操作系统（OS）调度器的管理下，运行在一个多核中央处理器（CPU）上。该应用程序会生成 $N$ 个工作线程来处理客户端请求。每个请求都包含两个阶段：一个不访问任何共享状态的本地计算阶段，以及一个更新由互斥锁保护的共享日志的临界区。由于该锁一次只允许一个线程执行临界区，因此即使存在许多可运行的线程，临界区本质上也是串行的。假设操作系统调度器在 $N$ 个线程之间产生大量的交错，因此并发度（交错）很高，但临界区占据了请求处理时间的主导部分。\n\n假设在单核上测量到的每个请求的时间如下：本地计算阶段耗时 $c = 3$ 毫秒，临界区耗时 $s = 7$ 毫秒。假设本地计算阶段在 $M$ 个相同核心上具有理想的并行扩展性，除了临界区本身的串行化之外没有其他同步开销，并且临界区不会因核心数量增加而受益。\n\n从加速比 $S(M)$ 是 $T(1)/T(M)$ 的比率、可并行化部分 $p$ 是单核执行时间中可以在多个核心上并发运行的工作部分、以及串行部分 $1 - p$ 不会随着核心增多而加速这些基本定义出发，推导出 $S(M)$ 关于 $p$ 和 $M$ 的表达式。然后，根据 $c$ 和 $s$ 计算此工作负载的可并行化部分 $p$，并评估当 $M \\in \\{1, 2, 8\\}$ 时的加速比。将您的最终答案表示为一个行矩阵，其中包含对应于 $M = 1$、$M = 2$ 和 $M = 8$ 的三个加速比。最终数值中不要包含任何单位。",
            "solution": "该问题要求推导被称为阿姆达尔定律（Amdahl's Law）的加速比公式，并将其应用于多核处理器上的特定工作负载。\n\n首先，我们进行问题验证。\n\n**第1步：提取已知条件**\n- 应用程序生成 $N$ 个工作线程。\n- 每个请求都有一个本地计算阶段和一个临界区阶段。\n- 临界区受互斥锁保护，使其本质上是串行的。\n- 单核上每个请求的本地计算时间：$c = 3$ 毫秒。\n- 单核上每个请求的临界区时间：$s = 7$ 毫秒。\n- 假设本地计算阶段在 $M$ 个核心上具有理想的并行扩展性。\n- 临界区不会因核心数量增加而受益。\n- 除了串行化之外，没有其他同步开销。\n- 加速比定义：$S(M) = T(1)/T(M)$，其中 $T(M)$ 是在 $M$ 个核心上的执行时间。\n- 单核执行时间的可并行化部分：$p$。\n- 单核执行时间的串行部分：$1-p$。\n- 任务：推导 $S(M)$ 关于 $p$ 和 $M$ 的表达式。\n- 任务：根据 $c$ 和 $s$ 计算 $p$。\n- 任务：评估当 $M \\in \\{1, 2, 8\\}$ 时的 $S(M)$。\n\n**第2步：使用提取的已知条件进行验证**\n- **科学性**：该问题是阿姆达尔定律（Amdahl's Law）的经典应用，这是并行计算中的一个基本原则，用于预测使用多个处理器时的理论加速比。所有概念（临界区、可并行化部分、加速比）在计算机科学和操作系统中都是标准概念。\n- **适定性**：该问题提供了推导公式和计算所需值的所有必要定义和数据（$c$、$s$）。目标陈述清晰。存在唯一解。\n- **客观性**：问题以精确的技术语言陈述，没有主观或含糊的术语。\n\n该问题是有效的，因为它是科学合理的、适定的和客观的。我们可以继续进行求解。\n\n**加速比 $S(M)$ 的推导**\n\n设 $T(1)$ 是任务在单个处理器核心上的总执行时间。这个总时间可以分为一个无法并行的串行部分和一个可并行的部分。\n\n串行部分所占比例为 $1-p$。因此，在串行部分上花费的时间是 $(1-p)T(1)$。无论核心数 $M$ 为多少，这个时间都是恒定的。\n\n可并行化部分所占比例为 $p$。在单核上，可并行化部分花费的时间是 $pT(1)$。在理想的并行扩展情况下，这项工作可以分布在 $M$ 个核心上，将这部分的时间减少到 $\\frac{pT(1)}{M}$。\n\n在 $M$ 个核心上的总执行时间 $T(M)$ 是串行部分时间和并行化部分时间之和：\n$$T(M) = (1-p)T(1) + \\frac{pT(1)}{M}$$\n我们可以提出公因子 $T(1)$：\n$$T(M) = T(1) \\left( (1-p) + \\frac{p}{M} \\right)$$\n加速比 $S(M)$ 定义为单核执行时间与多核执行时间之比：\n$$S(M) = \\frac{T(1)}{T(M)}$$\n代入 $T(M)$ 的表达式：\n$$S(M) = \\frac{T(1)}{T(1) \\left( (1-p) + \\frac{p}{M} \\right)}$$\n$$S(M) = \\frac{1}{(1-p) + \\frac{p}{M}}$$\n这就是以可并行化部分 $p$ 和处理器数量 $M$ 表示的加速比通用表达式，即阿姆达尔定律（Amdahl's Law）。\n\n**可并行化部分 $p$ 的计算**\n\n对于给定的工作负载，单个请求在单核上的总执行时间 $T(1)$ 是本地计算时间 $c$ 和临界区时间 $s$ 的总和。\n$$T(1) = c + s$$\n本地计算是可以并行运行的工作部分。因此，其持续时间 $c$ 对应于单核执行时间的可并行化部分。临界区本质上是串行的，因此其持续时间 $s$ 对应于串行部分。\n\n可并行化部分 $p$ 是可并行化时间与总时间的比率：\n$$p = \\frac{c}{c+s}$$\n代入给定值 $c=3$ 和 $s=7$：\n$$p = \\frac{3}{3+7} = \\frac{3}{10} = 0.3$$\n串行部分为 $1-p = 1 - 0.3 = 0.7$。这对应于 $\\frac{s}{c+s} = \\frac{7}{10} = 0.7$，是一致的。\n\n**评估 $M \\in \\{1, 2, 8\\}$ 时的加速比**\n\n现在我们使用推导出的加速比公式，并代入 $p=0.3$：\n$$S(M) = \\frac{1}{(1-0.3) + \\frac{0.3}{M}} = \\frac{1}{0.7 + \\frac{0.3}{M}}$$\n\n情况1：$M=1$\n$$S(1) = \\frac{1}{0.7 + \\frac{0.3}{1}} = \\frac{1}{0.7 + 0.3} = \\frac{1}{1} = 1$$\n这是预期的基线加速比。\n\n情况2：$M=2$\n$$S(2) = \\frac{1}{0.7 + \\frac{0.3}{2}} = \\frac{1}{0.7 + 0.15} = \\frac{1}{0.85}$$\n为了将其表示为精确分数：\n$$S(2) = \\frac{1}{\\frac{85}{100}} = \\frac{100}{85} = \\frac{20}{17}$$\n\n情况3：$M=8$\n$$S(8) = \\frac{1}{0.7 + \\frac{0.3}{8}}$$\n为了将其表示为精确分数，我们将分母转换为共同的基数：\n$$0.7 = \\frac{7}{10} = \\frac{56}{80}$$\n$$\\frac{0.3}{8} = \\frac{\\frac{3}{10}}{8} = \\frac{3}{80}$$\n所以，分母是：\n$$\\frac{56}{80} + \\frac{3}{80} = \\frac{59}{80}$$\n因此，加速比是：\n$$S(8) = \\frac{1}{\\frac{59}{80}} = \\frac{80}{59}$$\n\n计算出的三个加速比值分别为 $S(1)=1$，$S(2)=\\frac{20}{17}$ 和 $S(8)=\\frac{80}{59}$。",
            "answer": "$$\\boxed{\\begin{pmatrix} 1  \\frac{20}{17}  \\frac{80}{59} \\end{pmatrix}}$$"
        },
        {
            "introduction": "在构建高性能网络服务器时，选择正确的并发模型至关重要。本练习将带你进入一个实际的系统设计权衡场景，比较“每个连接一个线程”模型和异步I/O模型在处理大量连接时的性能表现。你将运用利特尔定律（Little's Law），一个强大的性能分析工具，来量化不同并发策略的开销，并理解这些开销如何与系统可用的并行能力（即CPU核心数）相互作用，最终影响服务的延迟 。",
            "id": "3627006",
            "problem": "一个网络服务器维护着 $10\\,000$ 个长时间存活的传输控制协议 (TCP) 连接，并且在任何给定时间，每个连接处理一个未完成的请求。该服务器运行在一台拥有 $4$ 个相同核心的对称多处理机器上。每个请求在用户空间中需要 $0.9 \\times 10^{-3}$ 秒的基本中央处理器 (CPU) 工作量。考虑了两种实现设计：\n\n- 每连接一线程：每个请求由其自己的线程处理。并发开销包括上下文切换和调度器簿记。每次上下文切换的成本为 $5 \\times 10^{-6}$ 秒，由于输入/输出 (I/O) 的阻塞和解除阻塞，平均每个请求有 $12$ 次上下文切换。调度器簿记为每个请求增加固定的 $60 \\times 10^{-6}$ 秒。\n- 异步I/O：请求由单个事件循环使用非阻塞I/O处理。并发开销包括事件循环的轮询/分发工作。每个请求有 $8$ 次事件循环轮询/分发操作，每次操作成本为 $3 \\times 10^{-6}$ 秒，此外每个请求还有固定的 $15 \\times 10^{-6}$ 秒用于分发簿记。\n\n假设系统在饱和状态下是CPU受限的，并忽略所有非CPU瓶颈。令 $L$ 表示系统中未完成的请求数量，$\\lambda$ 表示系统范围的请求完成率（吞吐量），$W$ 表示请求在系统中花费的平均时间（延迟）。使用利特尔法则 (Little’s Law)，$L = \\lambda W$，结合由4个核心施加的并行度上限，推导出在饱和状态下，每连接一线程模型的系统平均时间与异步I/O模型的系统平均时间之比，即 $\\frac{W_{\\text{thread}}}{W_{\\text{async}}}$。\n\n将最终的比率四舍五入到四位有效数字。将答案表示为一个无单位的纯数字。",
            "solution": "首先对问题进行验证，以确保其在科学上是合理的、良定的和客观的。\n\n### 步骤1：提取已知条件\n- TCP连接数：$N_{\\text{conn}} = 10\\,000$\n- 每个连接的未完成请求数：$1$\n- 相同CPU核心数：$N_{\\text{cores}} = 4$\n- 每个请求的基本CPU工作量：$T_{\\text{base}} = 0.9 \\times 10^{-3} \\text{ s}$\n- **每连接一线程模型：**\n  - 每次上下文切换的成本：$T_{\\text{cs}} = 5 \\times 10^{-6} \\text{ s}$\n  - 每个请求的平均上下文切换次数：$N_{\\text{cs}} = 12$\n  - 每个请求的调度器簿记成本：$T_{\\text{sched}} = 60 \\times 10^{-6} \\text{ s}$\n- **异步I/O模型：**\n  - 每个请求的事件循环操作次数：$N_{\\text{poll}} = 8$\n  - 每次事件循环操作的成本：$T_{\\text{poll}} = 3 \\times 10^{-6} \\text{ s}$\n  - 每个请求的分发簿记成本：$T_{\\text{dispatch}} = 15 \\times 10^{-6} \\text{ s}$\n- **系统状态与法则：**\n  - 系统在饱和状态下是CPU受限的。\n  - 未完成请求的总数：$L$\n  - 系统范围的请求完成率（吞吐量）：$\\lambda$\n  - 请求在系统中花费的平均时间（延迟）：$W$\n  - 利特尔法则 (Little's Law)：$L = \\lambda W$\n- **目标：**\n  - 计算比率 $\\frac{W_{\\text{thread}}}{W_{\\text{async}}}$ 并四舍五入到四位有效数字。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题是计算机科学领域一个标准的性能分析问题，特别是在操作系统和网络服务器的背景下。\n- **科学合理性：** 该问题使用了已建立的概念，如并发模型（线程与异步I/O）、上下文切换开销、CPU受限系统和利特尔法则 (Little's Law)。所提供的CPU时间和开销值是合理的。该模型是对真实世界性能权衡的一个简化但有效的表示。\n- **良定性：** 该问题为两种模型计算每个请求的总CPU工作量提供了所有必要信息。CPU受限饱和系统的假设允许确定最大吞吐量。利特尔法则 (Little's Law) 提供了求得延迟的必要关系。目标明确，且可获得唯一解。\n- **客观性：** 该问题使用精确、定量和无偏见的语言进行陈述。\n\n该问题没有违反任何无效性标准。它是完整的、一致的且可形式化的。\n\n### 步骤3：结论与行动\n该问题是有效的。将提供解答。\n\n问题的核心是确定每个模型的平均延迟 $W$。延迟取决于系统中的请求总数 $L$ 和系统的吞吐量 $\\lambda$，正如利特尔法则 (Little's Law) $L = \\lambda W$ 所描述的那样。\n\n首先，我们确定未完成请求的总数 $L$。系统维护 $N_{\\text{conn}} = 10\\,000$ 个连接，每个连接有一个未完成的请求。因此，系统中任何时候的请求总数是恒定的：\n$$L = N_{\\text{conn}} \\times 1 = 10\\,000$$\n\n接下来，我们计算每种模型处理单个请求所需的总CPU服务时间。这个服务时间，用 $S$ 表示，是基本CPU工作量和所有与并发相关的开销的总和。\n\n对于每连接一线程模型，服务时间 $S_{\\text{thread}}$ 是基本工作量、总上下文切换成本和调度器簿记成本的总和。\n$$S_{\\text{thread}} = T_{\\text{base}} + N_{\\text{cs}} \\times T_{\\text{cs}} + T_{\\text{sched}}$$\n代入给定值：\n$$S_{\\text{thread}} = (0.9 \\times 10^{-3}) + (12 \\times 5 \\times 10^{-6}) + (60 \\times 10^{-6})$$\n为了方便相加，我们将所有项用具有相同指数的秒来表示：\n$$S_{\\text{thread}} = (900 \\times 10^{-6}) + (60 \\times 10^{-6}) + (60 \\times 10^{-6})$$\n$$S_{\\text{thread}} = (900 + 60 + 60) \\times 10^{-6} = 1020 \\times 10^{-6} \\text{ s} = 1.02 \\times 10^{-3} \\text{ s}$$\n\n对于异步I/O模型，服务时间 $S_{\\text{async}}$ 是基本工作量、事件循环轮询总成本和分发簿记成本的总和。\n$$S_{\\text{async}} = T_{\\text{base}} + N_{\\text{poll}} \\times T_{\\text{poll}} + T_{\\text{dispatch}}$$\n代入给定值：\n$$S_{\\text{async}} = (0.9 \\times 10^{-3}) + (8 \\times 3 \\times 10^{-6}) + (15 \\times 10^{-6})$$\n再次，将所有项以一种通用形式表示：\n$$S_{\\text{async}} = (900 \\times 10^{-6}) + (24 \\times 10^{-6}) + (15 \\times 10^{-6})$$\n$$S_{\\text{async}} = (900 + 24 + 15) \\times 10^{-6} = 939 \\times 10^{-6} \\text{ s} = 0.939 \\times 10^{-3} \\text{ s}$$\n\n问题陈述系统在饱和状态下是CPU受限的。这意味着 $N_{\\text{cores}} = 4$ 个CPU是唯一的瓶颈，并且被完全利用（100%）。系统的总处理能力是每秒真实时间 $N_{\\text{cores}}$ 个CPU秒。系统范围内的最大吞吐量 $\\lambda$ 是这个总能力除以每个请求的CPU服务时间 $S$。\n$$\\lambda = \\frac{N_{\\text{cores}}}{S}$$\n\n现在我们可以使用利特尔法则 (Little's Law) $L = \\lambda W$ 来求平均延迟 $W$：\n$$W = \\frac{L}{\\lambda} = \\frac{L}{N_{\\text{cores}} / S} = \\frac{L \\cdot S}{N_{\\text{cores}}}$$\n\n我们可以将两种模型的延迟写为：\n$$W_{\\text{thread}} = \\frac{L \\cdot S_{\\text{thread}}}{N_{\\text{cores}}}$$\n$$W_{\\text{async}} = \\frac{L \\cdot S_{\\text{async}}}{N_{\\text{cores}}}$$\n\n问题要求的是比率 $\\frac{W_{\\text{thread}}}{W_{\\text{async}}}$。\n$$\\frac{W_{\\text{thread}}}{W_{\\text{async}}} = \\frac{\\frac{L \\cdot S_{\\text{thread}}}{N_{\\text{cores}}}}{\\frac{L \\cdot S_{\\text{async}}}{N_{\\text{cores}}}}$$\n由于 $L$ 和 $N_{\\text{cores}}$ 在两种情况下都相同，它们可以相互抵消，将该比率简化为服务时间的比率：\n$$\\frac{W_{\\text{thread}}}{W_{\\text{async}}} = \\frac{S_{\\text{thread}}}{S_{\\text{async}}}$$\n\n代入计算出的服务时间：\n$$\\frac{W_{\\text{thread}}}{W_{\\text{async}}} = \\frac{1020 \\times 10^{-6}}{939 \\times 10^{-6}} = \\frac{1020}{939}$$\n进行除法运算：\n$$\\frac{1020}{939} \\approx 1.08626198...$$\n\n问题要求将最终答案四舍五入到四位有效数字。前四位有效数字是 $1.086$。第五位数字是 $2$，小于 $5$，所以我们向下舍入（即截断）。\n$$\\frac{W_{\\text{thread}}}{W_{\\text{async}}} \\approx 1.086$$",
            "answer": "$$\\boxed{1.086}$$"
        },
        {
            "introduction": "为I/O密集型应用设置线程池大小是一个经典的系统设计问题，它完美地体现了并发与并行的核心区别。这个练习将指导你推导出一个确定线程池大小的通用法则，该法则需要同时满足两个目标：一是利用并发来“隐藏”I/O延迟，二是充分利用可用的CPU核心实现并行处理。通过解决这个问题，你将学会如何平衡硬件利用率（并行性）和服务等级目标（并发性），从而做出更明智的系统配置决策 。",
            "id": "3627021",
            "problem": "一台服务器使用一个固定大小的线程池来处理独立的客户端请求。每个请求在中央处理器（CPU）上的计算阶段和阻塞式输入/输出（I/O）等待之间交替进行。设 $C$ 表示每个请求的平均 CPU 计算时间，$W$ 表示每个请求的平均阻塞等待时间，其中 $C, W > 0$。我们将每个线程建模为在计算（在核心上忙碌）和等待（因 I/O 而阻塞）之间循环。该机器有 $M$ 个相同的 CPU 核心可用于执行准备好计算的线程。请求以平均速率 $\\lambda$（请求/秒）到达。系统操作员的目标是稳态平均响应时间不超过 $R^\\star$ 秒。线程池的大小为 $k$ 个线程。\n\n从第一性原理出发，提出一个选择 $k$ 的规则，该规则能同时满足：\n- 覆盖 I/O 延迟的并发性要求（以便有足够的在途请求来实现目标平均响应时间），以及\n- 由 $M$ 个核心施加的并行性限制（以便计算吞吐量不会受限，核心也不会因阻塞而空闲）。\n\n选择唯一的最佳选项。\n\nA. 选择 $k = \\lceil M \\rceil$。\n\nB. 选择 $k = \\left\\lceil M \\cdot \\left(1 + \\frac{W}{C}\\right) \\right\\rceil$。\n\nC. 选择 $k = \\left\\lceil \\max\\!\\left( M \\cdot \\left(1 + \\frac{W}{C}\\right),\\, \\lambda \\cdot R^\\star \\right) \\right\\rceil$。\n\nD. 选择 $k = \\left\\lceil \\lambda \\cdot (C + W) \\right\\rceil$。\n\nE. 选择 $k = \\left\\lceil \\frac{M}{1 + \\frac{W}{C}} \\right\\rceil$。",
            "solution": "用户希望我解决一个关于线程池大小设置的问题。\n\n### 步骤 1：验证问题陈述\n\n我将根据指示首先验证问题陈述。\n\n#### 提取已知条件\n- 一台服务器使用一个大小为 $k$ 的固定大小线程池。\n- 该服务器处理独立的客户端请求。\n- 每个请求在计算阶段（CPU）和阻塞式输入/输出（I/O）等待之间交替进行。\n- $C$：每个请求的平均 CPU 计算时间，其中 $C > 0$。\n- $W$：每个请求的平均阻塞 I/O 等待时间，其中 $W > 0$。\n- 系统有 $M$ 个相同的 CPU 核心。\n- $\\lambda$：请求的平均到达率（请求/秒）。\n- $R^\\star$：目标稳态平均响应时间（秒）。\n\n#### 使用提取的已知条件进行验证\n问题要求提出一个选择线程池大小 $k$ 的规则，以满足两个要求：\n1.  一个覆盖 I/O 延迟并满足响应时间目标的并发性要求。\n2.  一个有效利用 $M$ 个 CPU 核心的并行性限制。\n\n该问题陈述具有科学依据，表述清晰且客观。它描述了计算机系统性能建模中的一个经典且基本的问题。参数（$C$、$W$、$M$、$\\lambda$、$R^\\star$）是排队论和系统分析中使用的标准度量。该模型使用 CPU 和 I/O 时间的平均值，这是一阶分析中常见且有效的简化方法。该问题没有歧义、矛盾或基于错误的前提。它要求从第一性原理推导出一个调整大小的启发式方法，这是一项标准的工程任务。\n\n#### 结论\n问题陈述是**有效的**。我将继续进行推导和求解。\n\n### 步骤 2：从第一性原理推导\n\n问题要求确定一个线程池大小 $k$ 的规则，该规则能同时解决两个不同的约束：一个与硬件利用率（并行性）相关，另一个与服务水平目标（并发性）相关。\n\n**1. 并行性限制：饱和 CPU 核心**\n\n第一个目标是选择一个 $k$，使得 $M$ 个 CPU 核心保持忙碌，而不会因为线程阻塞在 I/O 上而空闲。\n- 让我们考虑单个线程。在一个完整的请求处理周期中，它花费 $C$ 个时间单位处于可运行状态（计算中或准备计算），花费 $W$ 个时间单位处于阻塞状态（等待 I/O）。\n- 一个周期的总时间是 $C+W$。\n- 一个线程处于可运行状态（即需要 CPU 核心）的时间比例是 $f_{cpu} = \\frac{C}{C+W}$。\n- 一个线程因 I/O 而阻塞的时间比例是 $f_{io} = \\frac{W}{C+W}$。\n\n对于一个大小为 $k$ 的线程池，在任何给定时间处于可运行状态的平均线程数是 $k \\cdot f_{cpu} = k \\cdot \\frac{C}{C+W}$。\n为了完全饱和所有 $M$ 个核心，我们需要可运行的线程数至少等于核心数 $M$。理想的目标是可运行的线程数恰好为 $M$。\n$$\nk \\cdot \\frac{C}{C+W} = M\n$$\n求解 $k$ 可得出保持 CPU 饱和所需的线程数：\n$$\nk_{cpu} = M \\cdot \\frac{C+W}{C} = M \\cdot \\left(1 + \\frac{W}{C}\\right)\n$$\n这个公式通常被称为基于利用率的规模调整规则，它提供了所需线程的数量，以确保平均有 $M$ 个线程准备好运行，从而使 $M$ 个核心得到充分利用。如果线程数少于这个值，那么只要有超过 $k-M$ 个线程被阻塞，核心就会出现空闲。这个公式抓住了并行性的限制。\n\n**2. 并发性要求：满足响应时间目标**\n\n第二个目标是拥有足够的线程来处理进入的工作负载，并实现平均响应时间小于或等于 $R^\\star$。\n- 这可以使用 Little's Law 进行分析，这是排队论中的一个基本定理，它指出在一个稳定系统中，客户的长期平均数量 $L$ 等于长期平均有效到达率 $\\lambda$ 乘以客户在系统中花费的平均时间 $R$。\n$$\nL = \\lambda \\cdot R\n$$\n- 在我们的情境中，“客户”是客户端请求。“系统”是服务器。请求在系统中花费的时间是其响应时间。\n- 系统必须支持 $\\lambda$ 的到达率，并旨在达到 $R^\\star$ 的平均响应时间。\n- 应用 Little's Law，为满足此目标，系统中的平均并发请求数为：\n$$\nL^\\star = \\lambda \\cdot R^\\star\n$$\n- 每个“在途”（由服务器处理）的请求都需要线程池中的一个线程。因此，为了支持平均 $L^\\star$ 个并发请求，线程池必须至少有那么多线程。\n$$\nk_{latency} \\ge \\lambda \\cdot R^\\star\n$$\n这个公式抓住了由服务水平目标驱动的并发性要求。\n\n**3. 结合两个要求**\n\n问题要求一个能同时满足*两个*要求的单一规则。线程池必须足够大，以满足两个约束中更严格的那一个。\n- 它必须足够大以保持 CPU 忙碌：$k \\ge M \\cdot \\left(1 + \\frac{W}{C}\\right)$。\n- 它必须足够大以支持延迟目标所需的并发性：$k \\ge \\lambda \\cdot R^\\star$。\n\n为了同时满足这两个条件，$k$ 必须大于或等于这两个所需值的最大值：\n$$\nk \\ge \\max\\left( M \\cdot \\left(1 + \\frac{W}{C}\\right),\\, \\lambda \\cdot R^\\star \\right)\n$$\n因为线程池大小 $k$ 必须是整数，所以满足此条件的最小整数值是该表达式的向上取整。\n$$\nk = \\left\\lceil \\max\\left( M \\cdot \\left(1 + \\frac{W}{C}\\right),\\, \\lambda \\cdot R^\\star \\right) \\right\\rceil\n$$\n这个复合规则确保系统配置既能处理硬件级别的并行性目标，又能处理应用级别的并发性目标。\n\n### 步骤 3：逐项分析选项\n\n现在，我将根据推导出的原理评估每个选项。\n\n**A. 选择 $k = \\lceil M \\rceil$。**\n由于 $M$（核心数）是整数，这可以简化为 $k=M$。此规则将线程数设置为与可用核心数相等。这仅对于纯 CPU 密集型的工作负载（即 $W=0$）是合适的策略。对于给定的问题，其中请求有阻塞 I/O 等待（$W > 0$），如果所有 $M$ 个线程同时在 I/O 上阻塞，CPU 核心将变为空闲。这未能满足保持核心忙碌的要求。因此，此选项不充分。\n**结论：不正确。**\n\n**B. 选择 $k = \\left\\lceil M \\cdot \\left(1 + \\frac{W}{C}\\right) \\right\\rceil$。**\n这个公式与我们为保持 $M$ 个核心饱和而推导出的 $k_{cpu}$ 完全对应。它正确地解决了并行性限制。然而，它完全忽略了关于到达率 $\\lambda$ 和目标响应时间 $R^\\star$ 的第二个要求。如果满足服务目标所需的并发水平 $\\lambda \\cdot R^\\star$ 远大于 $M \\cdot (1 + W/C)$，这个规则将导致线程池过小，使得请求被拒绝或在分配到线程前排队时间过长，从而无法满足响应时间目标。因为它只满足了两个要求中的一个，所以它是不完整的。\n**结论：不正确。**\n\n**C. 选择 $k = \\left\\lceil \\max\\!\\left( M \\cdot \\left(1 + \\frac{W}{C}\\right),\\, \\lambda \\cdot R^\\star \\right) \\right\\rceil$。**\n这个公式结合了我们从第一性原理推导出的两个下限。项 $M \\cdot (1 + W/C)$ 确保线程池足够大以保持硬件被充分利用。项 $\\lambda \\cdot R^\\star$ 确保线程池足够大以支持满足性能目标所需的并发请求数。通过取这两项的最大值，该规则保证了所选的线程池大小 $k$ 足以同时满足以硬件为中心的要求和以服务水平为中心的要求。这个规则稳健地同时抓住了问题的两个方面。\n**结论：正确。**\n\n**D. 选择 $k = \\left\\lceil \\lambda \\cdot (C + W) \\right\\rceil$。**\n项 $C+W$ 表示一个请求的理想总服务时间，不包括任何排队延迟。表达式 $\\lambda \\cdot (C+W)$ 是 Little's Law 的一个应用，用于计算当响应时间恰好等于服务时间时系统中的请求数。这是系统提供负载的定义。虽然这个值与所需的并发性有关，但它完全忽略了核心数 $M$，未能解决并行性限制。此外，它假设目标响应时间 $R^\\star$ 等于理想服务时间 $C+W$，而通常情况并非如此，因为 $R^\\star$ 通常必须考虑排队延迟。\n**结论：不正确。**\n\n**E. 选择 $k = \\left\\lceil \\frac{M}{1 + \\frac{W}{C}} \\right\\rceil$。**\n这个公式可以重写为 $k = \\lceil M \\cdot \\frac{C}{C+W} \\rceil$。由于 $C, W > 0$，分数 $\\frac{C}{C+W}$ 总是小于 1。因此，此规则会建议线程池大小 $k \\le M$。如果线程数少于核心数，就不可能完全利用所有 $M$ 个核心。这直接与饱和 CPU 的目标相矛盾，并且在概念上与处理 I/O 密集型任务的正确逻辑相反。\n**结论：不正确。**",
            "answer": "$$\\boxed{C}$$"
        }
    ]
}