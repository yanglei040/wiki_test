{
    "hands_on_practices": [
        {
            "introduction": "To build a solid understanding of message queues, we begin with the fundamentals of a single-queue system. This first practice challenges you to create a discrete-event simulator to model the interaction between a message producer and a consumer. By simulating deterministic arrival and service rates, you will gain direct insight into crucial behaviors like queue growth, the role of a finite buffer, and how backpressure mechanisms prevent system overload .",
            "id": "3658645",
            "problem": "You are to design and implement a discrete-event simulator of a single-message-queue system with one producer and one consumer, suitable for analyzing backpressure behavior. The system models a First-In-First-Out (FIFO) message queue with finite capacity and a blocking-send backpressure policy. The producer generates messages at a constant rate $\\,\\lambda\\,$ messages per second, and the consumer processes messages at a constant rate $\\,\\mu\\,$ messages per second. The consumer starts after a fixed delay. All interarrival and service times are deterministic and equal to $\\,1/\\lambda\\,$ and $\\,1/\\mu\\,$ respectively. The queue has an integer capacity $\\,C\\,$ and a backpressure threshold $\\,B\\,$. The producer is blocked during backpressure, meaning that if the queue occupancy $\\,q(t)\\,$ becomes greater than or equal to $\\,B\\,$, the producer stops generating messages until $\\,q(t)\\,$ drops strictly below $\\,B\\,$. When the queue is full (queue occupancy equals $\\,C\\,$) and the producer is not blocked by backpressure, arrivals are dropped and counted but do not enter the queue. The consumer behaves as a work-conserving server: if the consumer has started and the queue is non-empty, it continuously processes messages, producing a completion every $\\,1/\\mu\\,$ seconds, and immediately starts the next service if the queue remains non-empty.\n\nFundamental base and definitions that must be used:\n- A message queue is an abstract data type supporting enqueue and dequeue operations. Occupancy $\\,q(t)\\,$ evolves by $\\,q(t)\\to q(t)+1\\,$ at an arrival that is not dropped and $\\,q(t)\\to q(t)-1\\,$ at a service completion, with $\\,q(t)\\in\\{0,1,\\dots,C\\}\\,$.\n- Deterministic interarrival and service times are $\\,\\Delta t_{\\text{arr}}=1/\\lambda\\,$ and $\\,\\Delta t_{\\text{svc}}=1/\\mu\\,$, respectively.\n- Backpressure policy is: producer blocked when $\\,q(t)\\ge B\\,$ and producer resumes when $\\,q(t)B\\,$.\n- The consumer starts at time $\\,t_{\\text{delay}}\\,$ and does nothing before that. After starting, if $\\,q(t)0\\,$ and the consumer is idle, it immediately begins service and schedules a completion $\\,\\Delta t_{\\text{svc}}\\,$ later.\n- Stability indicator is defined as $\\,\\mathbf{1}_{\\{\\lambda\\mu\\}}\\,$, which equals $\\,1\\,$ if $\\,\\lambda\\mu\\,$ and equals $\\,0\\,$ otherwise.\n\nYour program must:\n- Implement the above system as a discrete-event simulator with exact event scheduling, no randomization, and deterministic tie-breaking. If an arrival and a service completion are scheduled for the same time, process the service completion first; if a consumer-start event coincides with other events, process the service completion first, then the consumer-start, then the arrival.\n- Track and report the following metrics for each test case over a finite horizon $\\,T_{\\text{end}}\\,$ seconds:\n  1. Peak queue occupancy (integer).\n  2. Time of the first backpressure trigger in seconds (float), defined as the first time $\\,t\\,$ such that $\\,q(t)\\,$ transitions from $\\,q(t)B\\,$ to $\\,q(t)\\ge B\\,$. If no backpressure ever triggers, output $-1.000$.\n  3. Total number of backpressure triggers (integer), counting each distinct transition from $\\,q(t)B\\,$ to $\\,q(t)\\ge B\\,$.\n  4. Total backpressure duration in seconds (float), defined as the sum of all intervals during which $\\,q(t)\\ge B\\,$ over $\\,t\\in[0,T_{\\text{end}}]$.\n  5. Total number of dropped arrivals due to full capacity (integer).\n  6. Final queue occupancy at $\\,t=T_{\\text{end}}\\,$ (integer).\n  7. Stability indicator $\\,\\mathbf{1}_{\\{\\lambda\\mu\\}}\\,$ (integer $\\,0\\,$ or $\\,1\\,$).\n\nScientific realism requirements:\n- All times must be expressed in seconds. All float outputs must be rounded to exactly $\\,3\\,$ decimal places. Integers must be printed without decimal places.\n- Do not use random number generation. Use deterministic scheduling computed from $\\,\\lambda\\,$, $\\,\\mu\\,$, $\\,B\\,$, $\\,C\\,$, $\\,t_{\\text{delay}}\\,$, and $\\,T_{\\text{end}}\\,$.\n- The event loop must terminate at $\\,t=T_{\\text{end}}\\,$ and, if backpressure is active at termination, must add the remaining backpressure duration up to $\\,T_{\\text{end}}\\,$.\n\nTest suite:\nSimulate the following four parameter sets, which together exercise typical behavior, boundary conditions, and edge cases:\n- Test $\\,1\\,$ (stable, delayed consumer, no backpressure): $\\,\\lambda=2.0\\,$, $\\,\\mu=5.0\\,$, $\\,C=50\\,$, $\\,B=20\\,$, $\\,t_{\\text{delay}}=3.0\\,$, $\\,T_{\\text{end}}=20.0\\,$.\n- Test $\\,2\\,$ (borderline $\\,\\lambda=\\mu\\,$, backpressure toggling at low threshold): $\\,\\lambda=5.0\\,$, $\\,\\mu=5.0\\,$, $\\,C=10\\,$, $\\,B=1\\,$, $\\,t_{\\text{delay}}=0.0\\,$, $\\,T_{\\text{end}}=5.0\\,$.\n- Test $\\,3\\,$ (overload $\\,\\lambda\\mu\\,$, delayed consumer, backpressure cycles): $\\,\\lambda=7.0\\,$, $\\,\\mu=3.0\\,$, $\\,C=40\\,$, $\\,B=15\\,$, $\\,t_{\\text{delay}}=5.0\\,$, $\\,T_{\\text{end}}=30.0\\,$.\n- Test $\\,4\\,$ (no backpressure due to threshold above capacity, drops occur): $\\,\\lambda=10.0\\,$, $\\,\\mu=2.0\\,$, $\\,C=30\\,$, $\\,B=100\\,$, $\\,t_{\\text{delay}}=0.0\\,$, $\\,T_{\\text{end}}=10.0\\,$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of lists, one per test case, with no spaces, enclosed in square brackets. Each inner list must have the $\\,7\\,$ metrics in order: $[$peak,firstBackpressureTimeSeconds,triggers,totalBackpressureDurationSeconds,drops,finalOccupancy,stabilityIndicator$]$.\n- Example formatting shape (values shown schematically): $[[p_1,t_1,n_1,d_1,x_1,q_1,s_1],[p_2,t_2,n_2,d_2,x_2,q_2,s_2],[p_3,t_3,n_3,d_3,x_3,q_3,s_3],[p_4,t_4,n_4,d_4,x_4,q_4,s_4]]$.\n- All float values must be printed with exactly $\\,3\\,$ decimal places, and all integers printed as integers. Time values are in seconds.",
            "solution": "The user requests a deterministic, discrete-event simulation of a single-producer, single-consumer message queue system with a finite capacity and a backpressure mechanism. The problem is well-defined, scientifically grounded in queueing theory, and provides all necessary parameters and rules, including tie-breaking, for a unique solution to exist. The validation concludes that the problem is **valid**.\n\nThe solution will be implemented as a C program that simulates the system for several test cases. The core of the program is a discrete-event simulator. The state of the system is defined by a set of variables: the current simulation time `t`, the queue occupancy `q(t)`, and boolean flags for the state of the producer (blocked/unblocked) and consumer (active/inactive, busy/idle).\n\nThe simulation progresses by advancing time to the next scheduled event. There are three types of events:\n1.  **Arrival**: A message is generated by the producer.\n2.  **Service Completion**: A message is processed by the consumer.\n3.  **Consumer Start**: The consumer becomes operational after a specified delay.\n\nThe simulation loop proceeds as follows:\n1.  Initialize the system state at time `t=0` with an empty queue (`q(0) = 0`). The first `ARRIVAL` event is scheduled at `t = 1/\\lambda`, and the `CONSUMER_START` event is scheduled at `t = t_{\\text{delay}}`. The `SERVICE_COMPLETION` event is not scheduled initially (`t = \\infty`).\n2.  Identify the minimum time of the next scheduled event (`t_{next}`).\n3.  If `t_{next}` is beyond the simulation horizon `T_{\\text{end}}`, the main loop terminates. Before termination, a final check is performed to account for any ongoing backpressure duration up to `T_{\\text{end}}`.\n4.  Advance the simulation time `t` to `t_{next}`.\n5.  Process all events scheduled at `t_{next}` according to the specified tie-breaking priority: `SERVICE_COMPLETION`  `CONSUMER_START`  `ARRIVAL`.\n\nThe logic for handling each event is as follows:\n\n**SERVICE_COMPLETION Event**: The queue occupancy `q(t)` is decremented. If `q(t)` drops below the backpressure threshold `B`, the producer is unblocked, the duration of the just-ended backpressure interval is recorded, and a new `ARRIVAL` event is scheduled. The consumer, now idle, immediately starts processing the next message if the queue is not empty (work-conserving policy), scheduling a new `SERVICE_COMPLETION` event `1/\\mu` seconds later.\n\n**CONSUMER_START Event**: The consumer becomes active. If the queue is non-empty, the consumer immediately starts processing the first message and schedules a `SERVICE_COMPLETION` event.\n\n**ARRIVAL Event**: If the producer is not blocked, an arrival occurs. If the queue is at full capacity `C`, the message is dropped. Otherwise, `q(t)` is incremented. If `q(t)` reaches or exceeds the backpressure threshold `B`, the producer becomes blocked, and metrics for backpressure (trigger time, count, start of interval) are updated. The next `ARRIVAL` event is scheduled `1/\\lambda` seconds later only if the producer is not blocked.\n\nThroughout the simulation, the following metrics are tracked:\n- **Peak Queue Occupancy**: The maximum value of `q(t)` observed.\n- **Backpressure Metrics**: The time of the first trigger, the total number of triggers (transitions from `q  B` to `q \\ge B`), and the total duration for which `q \\ge B`.\n- **Dropped Arrivals**: A counter for arrivals that occur when the queue is full (`q=C`) and the producer is not under backpressure.\n- **Final State**: The value of `q(T_{\\text{end}})` and the pre-calculated stability indicator `\\mathbf{1}_{\\{\\lambda\\mu\\}}`.\n\nThe implementation will use `double` precision for time and `int` for counters and occupancies. The logic is carefully structured to handle event scheduling and tie-breaking as specified, ensuring deterministic and correct results for the provided test cases.",
            "answer": "```c\n// The complete and compilable C program for the message queue simulation.\n#include stdio.h\n#include stdlib.h\n#include string.h\n#include math.h\n// #include complex.h // Not used\n// #include threads.h // Not used\n// #include stdatomic.h // Not used\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    double lambda;\n    double mu;\n    int C;\n    int B;\n    double t_delay;\n    double T_end;\n} TestCase;\n\n// A struct to hold the results for a single test case.\ntypedef struct {\n    int peak_occupancy;\n    double first_backpressure_time;\n    int total_backpressure_triggers;\n    double total_backpressure_duration;\n    int total_dropped_arrivals;\n    int final_occupancy;\n    int stability_indicator;\n} Result;\n\n// Function to run the discrete-event simulation for one test case.\nvoid run_simulation(const TestCase* params, Result* results) {\n    // System parameters\n    double lambda = params-lambda;\n    double mu = params-mu;\n    int C = params-C;\n    int B = params-B;\n    double t_delay = params-t_delay;\n    double T_end = params-T_end;\n\n    double inv_lambda = 1.0 / lambda;\n    double inv_mu = 1.0 / mu;\n\n    // State variables\n    double currentTime = 0.0;\n    int queueOccupancy = 0;\n    int isProducerBlocked = 0; // boolean 0/1\n    int isConsumerActive = 0;  // boolean 0/1\n    int isConsumerBusy = 0;    // boolean 0/1\n\n    // Event times\n    double nextArrivalTime = inv_lambda;\n    double nextServiceCompletionTime = INFINITY;\n    double consumerStartTime = (t_delay  0.0 || T_end == 0.0) ? t_delay : INFINITY;\n    if (t_delay == 0.0) {\n        isConsumerActive = 1;\n    }\n\n    // Initialize metrics\n    results-peak_occupancy = 0;\n    results-first_backpressure_time = -1.0;\n    results-total_backpressure_triggers = 0;\n    results-total_backpressure_duration = 0.0;\n    results-total_dropped_arrivals = 0;\n    double lastBackpressureStartTime = 0.0;\n    results-stability_indicator = (lambda  mu) ? 1 : 0;\n\n    while (1) {\n        double min_time = nextArrivalTime;\n        if (nextServiceCompletionTime  min_time) {\n            min_time = nextServiceCompletionTime;\n        }\n        if (consumerStartTime  min_time) {\n            min_time = consumerStartTime;\n        }\n\n        if (min_time  T_end) {\n            // If simulation ends while backpressure is active, add the remaining duration.\n            if (isProducerBlocked) {\n                results-total_backpressure_duration += T_end - lastBackpressureStartTime;\n            }\n            break;\n        }\n\n        currentTime = min_time;\n\n        // Process events at currentTime according to specified priority:\n        // 1. Service Completion\n        // 2. Consumer Start\n        // 3. Arrival\n        \n        // Process Service Completion\n        if (currentTime == nextServiceCompletionTime) {\n            queueOccupancy--;\n            \n            if (isProducerBlocked  queueOccupancy  B) {\n                isProducerBlocked = 0;\n                results-total_backpressure_duration += currentTime - lastBackpressureStartTime;\n                nextArrivalTime = currentTime + inv_lambda;\n            }\n\n            isConsumerBusy = 0;\n            if (isConsumerActive  queueOccupancy  0) {\n                isConsumerBusy = 1;\n                nextServiceCompletionTime = currentTime + inv_mu;\n            } else {\n                nextServiceCompletionTime = INFINITY;\n            }\n        }\n\n        // Process Consumer Start\n        if (currentTime == consumerStartTime) {\n            isConsumerActive = 1;\n            consumerStartTime = INFINITY;\n            if (!isConsumerBusy  queueOccupancy  0) {\n                isConsumerBusy = 1;\n                nextServiceCompletionTime = currentTime + inv_mu;\n            }\n        }\n\n        // Process Arrival\n        if (currentTime == nextArrivalTime) {\n            // An arrival event implies the producer was not blocked when it was scheduled.\n            // Check for drops only if not backpressure-blocked (which is always true here).\n            if (queueOccupancy == C) {\n                results-total_dropped_arrivals++;\n            } else {\n                queueOccupancy++;\n                if (queueOccupancy  results-peak_occupancy) {\n                    results-peak_occupancy = queueOccupancy;\n                }\n            }\n\n            if (!isProducerBlocked  queueOccupancy = B) {\n                isProducerBlocked = 1;\n                results-total_backpressure_triggers++;\n                if (results-first_backpressure_time  0.0) {\n                    results-first_backpressure_time = currentTime;\n                }\n                lastBackpressureStartTime = currentTime;\n            }\n\n            if (isProducerBlocked) {\n                nextArrivalTime = INFINITY;\n            } else {\n                nextArrivalTime = currentTime + inv_lambda;\n            }\n\n            // Check if idle consumer should start working on the new arrival.\n            if (isConsumerActive  !isConsumerBusy  queueOccupancy  0) {\n                isConsumerBusy = 1;\n                nextServiceCompletionTime = currentTime + inv_mu;\n            }\n        }\n    }\n\n    results-final_occupancy = queueOccupancy;\n}\n\nint main(void) {\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        {2.0, 5.0, 50, 20, 3.0, 20.0},\n        {5.0, 5.0, 10, 1, 0.0, 5.0},\n        {7.0, 3.0, 40, 15, 5.0, 30.0},\n        {10.0, 2.0, 30, 100, 0.0, 10.0}\n    };\n\n    // Calculate the number of test cases.\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    Result results[num_cases];\n\n    // Calculate the result for each test case.\n    for (int i = 0; i  num_cases; ++i) {\n        run_simulation(test_cases[i], results[i]);\n    }\n\n    // Print the results in the EXACT REQUIRED format before the final return statement.\n    printf(\"[\");\n    for (int i = 0; i  num_cases; ++i) {\n        printf(\"[%d,%.3f,%d,%.3f,%d,%d,%d]\",\n               results[i].peak_occupancy,\n               results[i].first_backpressure_time,\n               results[i].total_backpressure_triggers,\n               results[i].total_backpressure_duration,\n               results[i].total_dropped_arrivals,\n               results[i].final_occupancy,\n               results[i].stability_indicator\n        );\n        if (i  num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n\n    return EXIT_SUCCESS;\n}\n```"
        },
        {
            "introduction": "Real-world systems often face message reordering, where data packets arrive out of sequence. This next exercise moves beyond simple First-In-First-Out (FIFO) processing to tackle this common challenge by implementing a reassembly queue. You will design the logic to buffer future messages and deliver a perfectly ordered stream to the consumer, a mechanism at the heart of protocols like TCP that ensure reliable data transfer .",
            "id": "3658594",
            "problem": "You are given the foundational semantics of a message reassembly queue in an operating system. Each enqueued message carries a sequence number $seq \\in \\mathbb{N}$ and must be delivered to the consumer in strictly increasing order starting from an initial expected sequence number $s_0 \\in \\mathbb{N}$. The following contract governs processing at discrete arrival steps indexed by $t \\in \\mathbb{N}$ with the current next expected sequence number denoted $n_t$ and the buffer content set $S_t \\subset \\mathbb{N}$ containing out-of-order messages:\n- If an arrival has $seq_t  n_t$, the message is stale and is discarded.\n- If an arrival has $seq_t = n_t$, the message is delivered immediately, $n_t$ is incremented by $1$, and delivery continues greedily: while $n_t \\in S_t$, deliver $n_t$, remove it from $S_t$, and increment $n_t$ by $1$. This produces a contiguous in-order reassembly flush.\n- If an arrival has $seq_t  n_t$, it is buffered into $S_t$ if not already present (duplicates are ignored).\nDefine buffer occupancy $B_t$ as the cardinality of $S_t$ after all actions for step $t$ complete, and define the peak buffer occupancy over a finite sequence of arrivals as $$B_{\\max} = \\max_{t} B_t.$$\n\nYour task is to implement an out-of-order dequeue with reassembly based on $seq$ and to compute $B_{\\max}$ for each test case. The implementation must obey the above semantics, maintain a sorted buffer of unique $seq$ values for efficient detection of contiguous flushes, and produce the list of delivered $seq$ values in order for each test case.\n\nFundamental base for reasoning and algorithm design:\n- A message queue must enforce the invariant that delivered sequence numbers form a strictly increasing sequence starting at $s_0$.\n- Duplicates and stale messages are ignored in order to preserve correctness under reordering.\n- Buffer occupancy counts only stored out-of-order messages strictly greater than the current expected value $n_t$.\n\nTest suite:\n- Case $1$ (happy path): $s_0 = 0$, arrivals $[\\,0,1,2,3,4,5,6,7,8,9\\,]$.\n- Case $2$ (maximal local reordering window): $s_0 = 0$, arrivals $[\\,9,8,7,6,5,4,3,2,1,0\\,]$.\n- Case $3$ (duplicates and sparse reordering): $s_0 = 0$, arrivals $[\\,0,2,2,1,4,3,5\\,]$.\n- Case $4$ (gap then flush): $s_0 = 0$, arrivals $[\\,3,4,5,6,7,0,1,2\\,]$.\n- Case $5$ (stale after progress and duplicates): $s_0 = 0$, arrivals $[\\,0,1,2,1,1,3,5,4,4,6\\,]$.\n\nFor each test case, compute:\n- The delivered sequence list $L$ as a list of integers in strictly increasing order beginning at $s_0$ as far as permitted by arrivals.\n- The peak buffer occupancy $B_{\\max}$ over the processing of the case.\n\nFinal output format:\n- Your program should produce a single line of output containing a list of per-test-case results, where each result is itself a two-element list $[\\,L, B_{\\max}\\,]$. Each $L$ must be printed as a bracket-enclosed comma-separated list of integers, and $B_{\\max}$ as an integer. The overall output must be a single bracket-enclosed comma-separated list of these per-test-case results, for example: $[[[0,1,2],1],[[0,1],0]]$.\n\nNo physical units apply. Angles and percentages do not apply. The program must be self-contained, non-interactive, and must implement the above semantics faithfully. The single-line output must exactly aggregate the results in the specified format, with no additional text.",
            "solution": "The problem statement is valid. It is scientifically grounded in computer science principles concerning data stream processing and buffer management, is well-posed with a clear, deterministic set of rules, and is expressed in objective, formal language. The problem is a classic exercise in implementing a reassembly queue, a fundamental component in systems that handle ordered data over unreliable or reordering channels, such as TCP in networking.\n\nThe core of the problem is to process a sequence of incoming messages, each identified by a sequence number $seq$, and deliver them to a consumer in a strictly increasing order, starting from a given initial sequence number $s_0$. The system must maintain its state, which consists of the next expected sequence number, $n_t$, and a buffer of out-of-order messages, $S_t$.\n\nLet's formalize the state and transitions. The system state at any step $t$ is described by the tuple $(n_t, S_t)$, where $n_t \\in \\mathbb{N}$ is the next sequence number expected by the consumer, and $S_t \\subset \\{ k \\in \\mathbb{N} \\mid k  n_t \\}$ is a set of sequence numbers that have arrived out of order and are being held in a buffer. The buffer occupancy is $B_t = |S_t|$. The initial state is $(n_0, S_{-1}) = (s_0, \\emptyset)$.\n\nFor each message arriving at step $t$ with sequence number $seq_t$, we update the state $(n_t, S_{t-1})$ to $(n_{t+1}, S_t)$ based on the following rules:\n\n1.  **Stale Message**: If $seq_t  n_t$, the message is considered old and has likely been delivered already (or its predecessor was lost and the window has advanced). It is discarded. The state does not change: $(n_{t+1}, S_t) = (n_t, S_{t-1})$.\n\n2.  **Expected Message**: If $seq_t = n_t$, the message is the one the consumer is waiting for. It is delivered immediately. This advances the expected sequence number to $n_t + 1$. This advance may unblock a contiguous sequence of messages already in the buffer. A greedy flush is performed:\n    -   The system delivers $seq_t$.\n    -   A temporary expected number is set, $n'_{t} = n_t + 1$.\n    -   The system checks if $n'_{t}$ is present in the buffer $S_{t-1}$. As long as the next expected number is found in the buffer, it is delivered, removed from the buffer, and the expected number is incremented.\n    -   This process is formalized by a loop: let $S'_{t} = S_{t-1}$. While $n'_{t} \\in S'_{t}$, deliver $n'_{t}$, update $S'_{t} \\leftarrow S'_{t} \\setminus \\{n'_{t}\\}$, and update $n'_{t} \\leftarrow n'_{t} + 1$.\n    -   The state transition is finalized: $(n_{t+1}, S_t) = (n'_{t}, S'_{t})$.\n\n3.  **Out-of-Order Message**: If $seq_t  n_t$, the message has arrived before its predecessors. It must be stored for future delivery. It is added to the buffer if it is not already present (duplicate out-of-order messages are discarded). The next expected sequence number remains unchanged.\n    -   The state transition is: $(n_{t+1}, S_t) = (n_t, S_{t-1} \\cup \\{seq_t\\})$.\n\nThe buffer occupancy $B_t$ is the cardinality of $S_t$ after the operations for step $t$ are complete. The peak buffer occupancy $B_{\\max}$ is the maximum value of $B_t$ observed over the entire sequence of arrivals.\n\nTo implement this, a key choice is the data structure for the buffer $S_t$. The problem specifies that the buffer should be kept sorted to allow for efficient detection of contiguous flushes. A sorted dynamic array is a suitable choice. With a sorted buffer, checking for the presence of $n_t$ (the `while $n_t \\in S_t$` condition) becomes a simple check of the first element of the array.\n\nThe algorithm for each test case is as follows:\n1.  Initialize $n_t = s_0$, $S_t = \\emptyset$, the delivered list $L = \\emptyset$, and $B_{\\max} = 0$.\n2.  For each arriving sequence number $seq_t$ in the input list:\n    a. Apply the three rules above to update $n_t$, $S_t$, and $L$.\n    b. After processing the arrival and any resulting greedy flush, calculate the current buffer size, $|S_t|$.\n    c. Update $B_{\\max} = \\max(B_{\\max}, |S_t|)$.\n3.  After processing all arrivals, the final $L$ and $B_{\\max}$ are the results for the test case.\n\nThe use of a sorted array for the buffer implies the following operations:\n-   **Insertion**: To add a value $seq_t  n_t$, a search is performed to find the correct sorted position. To prevent duplicates, if the value already exists, the insertion is skipped. Otherwise, elements are shifted to make space, and the new value is inserted.\n-   **Flush**: During a greedy flush, the condition \"is $n_t \\in S_t$?\" is efficiently checked by comparing $n_t$ with the first element of the sorted buffer. If they match, the element is delivered, and removed from the buffer by shifting all subsequent elements one position to the left.",
            "answer": "```c\n#include stdio.h\n#include stdlib.h\n#include string.h\n#include math.h\n\n// A dynamic integer vector for storing buffer and delivered list.\ntypedef struct {\n    int* data;\n    size_t size;\n    size_t capacity;\n} IntVector;\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    int s0;\n    const int* arrivals;\n    size_t num_arrivals;\n} TestCase;\n\n// A struct to hold the results of a single test case.\ntypedef struct {\n    IntVector delivered_list;\n    int peak_occupancy;\n} TestCaseResult;\n\n// Initializes a vector with an initial capacity.\nvoid init_vector(IntVector* v, size_t initial_capacity) {\n    v-size = 0;\n    v-capacity = initial_capacity;\n    if (initial_capacity  0) {\n        v-data = (int*)malloc(initial_capacity * sizeof(int));\n        if (v-data == NULL) {\n            perror(\"Failed to allocate vector\");\n            exit(EXIT_FAILURE);\n        }\n    } else {\n        v-data = NULL;\n    }\n}\n\n// Frees the memory used by a vector.\nvoid free_vector(IntVector* v) {\n    free(v-data);\n    v-data = NULL;\n    v-size = 0;\n    v-capacity = 0;\n}\n\n// Appends a value to a vector, resizing if necessary.\nvoid add_to_vector(IntVector* v, int value) {\n    if (v-size == v-capacity) {\n        v-capacity = (v-capacity == 0) ? 8 : v-capacity * 2;\n        v-data = (int*)realloc(v-data, v-capacity * sizeof(int));\n        if (v-data == NULL) {\n            perror(\"Failed to reallocate vector\");\n            exit(EXIT_FAILURE);\n        }\n    }\n    v-data[v-size++] = value;\n}\n\n// Inserts a value into a sorted vector, maintaining order and uniqueness.\nvoid insert_sorted_unique(IntVector* buffer, int seq) {\n    size_t i = 0;\n    while (i  buffer-size  buffer-data[i]  seq) {\n        i++;\n    }\n\n    if (i  buffer-size  buffer-data[i] == seq) {\n        return; // Duplicate, do nothing.\n    }\n\n    if (buffer-size == buffer-capacity) {\n        buffer-capacity = (buffer-capacity == 0) ? 8 : buffer-capacity * 2;\n        buffer-data = (int*)realloc(buffer-data, buffer-capacity * sizeof(int));\n        if (buffer-data == NULL) {\n            perror(\"Failed to reallocate buffer\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    if (i  buffer-size) {\n        memmove(buffer-data[i + 1], buffer-data[i], (buffer-size - i) * sizeof(int));\n    }\n\n    buffer-data[i] = seq;\n    buffer-size++;\n}\n\n// Removes the first element from a vector.\nvoid remove_front(IntVector* buffer) {\n    if (buffer-size == 0) return;\n    memmove(buffer-data[0], buffer-data[1], (buffer-size - 1) * sizeof(int));\n    buffer-size--;\n}\n\nTestCaseResult process_queue(const TestCase* test_case) {\n    int next_expected = test_case-s0;\n    int peak_occupancy = 0;\n    \n    IntVector buffer;\n    init_vector(buffer, 8);\n    \n    IntVector delivered_list;\n    init_vector(delivered_list, 16);\n\n    for (size_t t = 0; t  test_case-num_arrivals; ++t) {\n        int current_seq = test_case-arrivals[t];\n\n        if (current_seq  next_expected) {\n            // Stale message, discard.\n        } else if (current_seq == next_expected) {\n            // In-order message.\n            add_to_vector(delivered_list, current_seq);\n            next_expected++;\n\n            // Greedy flush from buffer.\n            while (buffer.size  0  buffer.data[0] == next_expected) {\n                add_to_vector(delivered_list, buffer.data[0]);\n                remove_front(buffer);\n                next_expected++;\n            }\n        } else { // current_seq  next_expected\n            // Out-of-order message.\n            insert_sorted_unique(buffer, current_seq);\n        }\n        \n        // Update peak buffer occupancy for this step.\n        if ((int)buffer.size  peak_occupancy) {\n            peak_occupancy = (int)buffer.size;\n        }\n    }\n\n    TestCaseResult result = {delivered_list, peak_occupancy};\n    free_vector(buffer); // Free intermediary buffer\n    return result;\n}\n\nint main(void) {\n    const int arrivals1[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n    const int arrivals2[] = {9, 8, 7, 6, 5, 4, 3, 2, 1, 0};\n    const int arrivals3[] = {0, 2, 2, 1, 4, 3, 5};\n    const int arrivals4[] = {3, 4, 5, 6, 7, 0, 1, 2};\n    const int arrivals5[] = {0, 1, 2, 1, 1, 3, 5, 4, 4, 6};\n\n    TestCase test_cases[] = {\n        {0, arrivals1, sizeof(arrivals1) / sizeof(arrivals1[0])},\n        {0, arrivals2, sizeof(arrivals2) / sizeof(arrivals2[0])},\n        {0, arrivals3, sizeof(arrivals3) / sizeof(arrivals3[0])},\n        {0, arrivals4, sizeof(arrivals4) / sizeof(arrivals4[0])},\n        {0, arrivals5, sizeof(arrivals5) / sizeof(arrivals5[0])}\n    };\n    \n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    TestCaseResult results[num_cases];\n\n    for (int i = 0; i  num_cases; ++i) {\n        results[i] = process_queue(test_cases[i]);\n    }\n\n    printf(\"[\");\n    for (int i = 0; i  num_cases; ++i) {\n        if (i  0) {\n            printf(\",\");\n        }\n        printf(\"[[\");\n        for (size_t j = 0; j  results[i].delivered_list.size; ++j) {\n            if (j  0) {\n                printf(\",\");\n            }\n            printf(\"%d\", results[i].delivered_list.data[j]);\n        }\n        printf(\"],%d]\", results[i].peak_occupancy);\n        free_vector(results[i].delivered_list);\n    }\n    printf(\"]\\n\");\n\n    return EXIT_SUCCESS;\n}\n```"
        },
        {
            "introduction": "When multiple producers compete for a shared resource, ensuring fairness is paramount to prevent any single source from monopolizing bandwidth. This advanced practice introduces Deficit Round Robin (DRR), a powerful scheduling algorithm that provides fair access even when message sizes vary greatly. By implementing DRR and analyzing its performance against an ideal fairness model, you will explore a sophisticated solution to a classic resource allocation problem in operating systems and networking .",
            "id": "3658595",
            "problem": "Consider a system with multiple producers, each maintaining a First-In-First-Out (FIFO) message queue whose elements are byte-sized messages of varying lengths. The system schedules transmissions using Deficit Round Robin (DRR), formally defined as follows. Each producer $i$ is assigned a fixed deficit quantum $d_i$ (in bytes per round). In each round, the scheduler visits producers in a fixed cyclic order. When visiting producer $i$, if its queue is non-empty, the scheduler increases its deficit counter $D_i$ by $d_i$, then transmits as many messages from the head of its queue as possible, constrained by $D_i$, subtracting the size of each transmitted message from $D_i$. If the queue is empty, the scheduler sets $D_i \\leftarrow 0$ and moves on. The scheduler repeats rounds until all queues are empty.\n\nThe fundamental base for fairness is the proportional share principle: for a set of backlogged producers $S$ (producers with non-empty queues) with weights $w_i$, an ideal work-conserving scheduler allocates service such that each producer $i \\in S$ obtains a fraction $w_i / \\sum_{k \\in S} w_k$ of the service over any interval where the set $S$ remains constant. In DRR, the weight is $w_i = d_i$.\n\nDefine the actual bytes transmitted for producer $i$ over the entire execution as $B_i$. Define an expected-byte functional $E_i$ via the following construction. Index each individual message transmission event by $e = 1, 2, \\dots, E$ in chronological order. Let the size of event $e$ be $x_e$ bytes, transmitted from some producer $j_e$, and let $S_e$ be the set of backlogged producers immediately before event $e$. The ideal proportional allocation implies that the expected contribution to producer $i$ for event $e$ is\n$$\n\\Delta E_{i,e} = \\begin{cases}\nx_e \\cdot \\dfrac{d_i}{\\sum_{k \\in S_e} d_k},  \\text{if } i \\in S_e, \\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nDefine $E_i = \\sum_{e=1}^{E} \\Delta E_{i,e}$ and the total bytes transmitted $X = \\sum_{e=1}^{E} x_e$. The normalized fairness error per producer is\n$$\n\\varepsilon_i = \\begin{cases}\n\\dfrac{\\lvert B_i - E_i \\rvert}{X},  \\text{if } X  0, \\\\\n0,  \\text{if } X = 0,\n\\end{cases}\n$$\nand the per-case summary metric is\n$$\n\\varepsilon_{\\max} = \\max_{i} \\varepsilon_i.\n$$\n\nImplement Deficit Round Robin with per-producer deficit $d_i$, compute $B_i$ and $E_i$ as defined above by integrating expectations over actual transmission events, and report $\\varepsilon_{\\max}$ for each test case. All message sizes and deficit quanta are measured in bytes. No angles or physical units other than bytes are involved, and all reported values must be dimensionless decimal fractions. Your program must be self-contained, require no input, and produce exactly one line of output in the specified format.\n\nTest Suite:\n- Case $1$ (happy path, heterogeneous sizes, persistent backlogs):\n  - Producers: $3$.\n  - Deficits: $\\{700, 500, 300\\}$.\n  - Messages:\n    - Producer $0$: $\\{400, 800, 700, 300\\}$.\n    - Producer $1$: $\\{500, 500, 1000\\}$.\n    - Producer $2$: $\\{300, 900, 600\\}$.\n- Case $2$ (boundary condition with many small messages versus a large message, equal weights):\n  - Producers: $2$.\n  - Deficits: $\\{500, 500\\}$.\n  - Messages:\n    - Producer $0$: $\\{100, 100, 100, 100, 100, 100, 100, 100, 100, 100\\}$.\n    - Producer $1$: $\\{1000, 100, 100, 100\\}$.\n- Case $3$ (edge case with an empty queue and a producer with large messages):\n  - Producers: $3$.\n  - Deficits: $\\{500, 300, 700\\}$.\n  - Messages:\n    - Producer $0$: $\\{\\}$ (empty).\n    - Producer $1$: $\\{2000, 2000\\}$.\n    - Producer $2$: $\\{100, 100, 100, 100, 100, 100, 100, 100, 100, 100\\}$.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each entry corresponds to $\\varepsilon_{\\max}$ for one test case in the order above, expressed as a decimal fraction rounded to six digits after the decimal point. For example, the output should look like $\\left[\\varepsilon_{\\max}^{(1)}, \\varepsilon_{\\max}^{(2)}, \\varepsilon_{\\max}^{(3)}\\right]$ rendered as a single ASCII line such as $[0.012345,0.000678,0.091000]$.",
            "solution": "The design begins from the proportional fairness principle under work-conserving scheduling. The foundational statement is that when a set $S$ of producers is backlogged, an ideal scheduler allocates service so that producer $i \\in S$ receives a fraction $w_i / \\sum_{k \\in S} w_k$ of the service over any interval with fixed $S$. In Deficit Round Robin (DRR), the designer intends to approximate this principle using discrete rounds and per-producer deficit quanta $d_i$.\n\nAlgorithmic specification of DRR:\n- Maintain per-producer deficit counters $D_i$, initialized to $0$.\n- Visit producers in cyclic order. When visiting producer $i$, if its queue is non-empty:\n  - Add $d_i$ to $D_i$.\n  - While the head-of-line message has size $h_i \\le D_i$, transmit it, subtract $h_i$ from $D_i$, and advance the queue head. If the next head-of-line message exceeds $D_i$, stop and move to the next producer.\n- If the queue is empty when visiting producer $i$, set $D_i \\leftarrow 0$ and move on.\nBecause each $D_i$ increases by $d_i$ per round while the producer remains in the cycle, large messages will eventually be serviced once $D_i$ accumulates sufficiently, which guarantees eventual termination for finite workloads.\n\nFairness measurement:\n- Let actual bytes served to producer $i$ be $B_i$, the sum of sizes of all messages transmitted from $i$.\n- To compare to the proportional fairness principle without assuming continuous-time rates, we integrate the ideal allocation over discrete transmission events. Index each transmission event $e$ by its message size $x_e$ and define $S_e$ as the set of producers with non-empty queues immediately prior to event $e$. The ideal proportional allocation grants producer $i \\in S_e$ a share $x_e \\cdot d_i / \\sum_{k \\in S_e} d_k$, and grants $0$ if $i \\notin S_e$. Summing over events yields $E_i = \\sum_e \\Delta E_{i,e}$, and the total bytes $X = \\sum_e x_e$.\n- The normalized fairness error $\\varepsilon_i = \\lvert B_i - E_i \\rvert / X$ compares actual service to the integrated ideal expectation. Reporting the worst-case error $\\varepsilon_{\\max} = \\max_i \\varepsilon_i$ per test case summarizes the deviation concisely.\n\nPrinciple-based justification:\n- The proportional share principle assumes the weight $w_i$ reflects desired relative service. Under DRR, $w_i = d_i$. When $S_e$ changes over time because some queues empty, the ideal share adapts to the instantaneous set $S_e$ rather than penalizing idle producers. Integrating over events with $S_e$ yields $E_i$ consistent with the base principle at each instant of service.\n- DRR is work-conserving: in each step, if any producer has a head-of-line message whose size does not exceed its current deficit, the scheduler transmits it. If not, deficits accumulate over rounds until a transmission becomes possible. Because the workload is finite and $d_i  0$ for each producer that ever has work, deficits ensure eventual transmission and termination.\n\nAlgorithmic steps realized in code:\n- Represent each test case by arrays: deficits $d_i$ and per-producer message lists with sizes in bytes.\n- Initialize arrays for per-producer indices, deficits $D_i$, actual bytes $B_i$, and expected bytes $E_i$; compute total bytes $X$.\n- Main loop continues until all messages are transmitted. In each round, visit producers consecutively:\n  - If producer $i$ is empty, set $D_i \\leftarrow 0$.\n  - Otherwise, add $d_i$ to $D_i$, and while the head message size $h_i \\le D_i$:\n    - Compute the backlog set $S_e$ as the set of producers with non-empty queues; compute $\\sum_{k \\in S_e} d_k$.\n    - Update $E_k \\leftarrow E_k + x_e \\cdot d_k / \\sum_{k \\in S_e} d_k$ for all $k \\in S_e$.\n    - Update $B_i \\leftarrow B_i + x_e$, $D_i \\leftarrow D_i - x_e$, and advance producer $i$'s head index.\n- After completion, compute $\\varepsilon_i$ for each producer by $\\varepsilon_i = \\lvert B_i - E_i \\rvert / X$ if $X  0$, else $\\varepsilon_i = 0$, and report $\\varepsilon_{\\max} = \\max_i \\varepsilon_i$.\n\nTest suite coverage:\n- Case $1$ exercises heterogeneous message sizes and heterogeneous weights, producing sustained backlogs across producers for much of the run, which tests proportionality under varying head-of-line constraints.\n- Case $2$ applies equal weights but contrasts many small messages against one large message plus smaller ones, testing DRRâ€™s ability to converge fairness across granular and bursty workloads.\n- Case $3$ includes an empty producer and a producer with large messages and a relatively high weight, testing correct deficit reset on emptiness and fairness computation with changing backlog sets.\n\nOutput:\n- The program prints the list $\\left[\\varepsilon_{\\max}^{(1)}, \\varepsilon_{\\max}^{(2)}, \\varepsilon_{\\max}^{(3)}\\right]$ as a single ASCII line, with each value rounded to six digits after the decimal point, meeting the quantifiable answer specification and format requirements.",
            "answer": "```c\n// The complete and compilable C program goes here.\n// Headers must adhere to the specified restrictions.\n#include stdio.h\n#include stdlib.h\n#include string.h\n#include math.h\n// #include complex.h\n// #include threads.h\n// #include stdatomic.h\n\ntypedef struct {\n    int num_producers;\n    const int *deficits;    // d_i per producer\n    const int **messages;   // array of pointers to per-producer message arrays\n    const int *msg_counts;  // number of messages per producer\n} TestCase;\n\n// Helper to compute epsilon_max for one test case using DRR and proportional expectation integration\nstatic double run_drr_epsilon_max(const TestCase *tc) {\n    int P = tc-num_producers;\n    const int *d = tc-deficits;\n    const int **msgs = tc-messages;\n    const int *counts = tc-msg_counts;\n\n    // Per-producer state\n    int *idx = (int *)calloc(P, sizeof(int));        // head index in message list\n    int *acc = (int *)calloc(P, sizeof(int));        // accumulated deficit D_i\n    double *B = (double *)calloc(P, sizeof(double)); // actual bytes served\n    double *E = (double *)calloc(P, sizeof(double)); // expected bytes\n\n    // Compute total bytes X and total remaining messages\n    double total_bytes = 0.0;\n    int total_remaining_msgs = 0;\n    for (int i = 0; i  P; ++i) {\n        total_remaining_msgs += counts[i];\n        for (int m = 0; m  counts[i]; ++m) {\n            total_bytes += (double)msgs[i][m];\n        }\n    }\n\n    // DRR main loop: iterate rounds until all messages are transmitted\n    while (total_remaining_msgs  0) {\n        for (int i = 0; i  P; ++i) {\n            if (total_remaining_msgs == 0) {\n                break;\n            }\n            // If producer i is empty, reset its deficit and skip\n            if (idx[i] = counts[i]) {\n                acc[i] = 0;\n                continue;\n            }\n\n            // Add quantum d_i\n            acc[i] += d[i];\n\n            // Transmit as many messages as allowed by current deficit\n            while (idx[i]  counts[i]) {\n                int msize = msgs[i][idx[i]];\n                if (msize = acc[i]) {\n                    // Compute backlog set S_e and sum of deficits over S_e\n                    int sum_d_backlog = 0;\n                    for (int k = 0; k  P; ++k) {\n                        if (idx[k]  counts[k]) {\n                            sum_d_backlog += d[k];\n                        }\n                    }\n                    // Safety: if no backlog, break (should not occur if msize = acc[i])\n                    if (sum_d_backlog = 0) {\n                        break;\n                    }\n                    // Update expected bytes E_k for all k in backlog set proportionally to d_k\n                    for (int k = 0; k  P; ++k) {\n                        if (idx[k]  counts[k]) {\n                            E[k] += ((double)msize) * ((double)d[k]) / (double)sum_d_backlog;\n                        }\n                    }\n                    // Perform actual transmission from producer i\n                    B[i] += (double)msize;\n                    acc[i] -= msize;\n                    idx[i] += 1;\n                    total_remaining_msgs -= 1;\n                } else {\n                    // Head-of-line message too large for current deficit; move to next producer\n                    break;\n                }\n            }\n        }\n    }\n\n    // Compute normalized fairness errors and epsilon_max\n    double emax = 0.0;\n    if (total_bytes = 0.0) {\n        emax = 0.0;\n    } else {\n        for (int i = 0; i  P; ++i) {\n            double err = fabs(B[i] - E[i]) / total_bytes;\n            if (err  emax) {\n                emax = err;\n            }\n        }\n    }\n\n    free(idx);\n    free(acc);\n    free(B);\n    free(E);\n    return emax;\n}\n\nint main(void) {\n    // Define Test Case 1\n    static const int deficits1[] = {700, 500, 300};\n    static const int msgs10[] = {400, 800, 700, 300};\n    static const int msgs11[] = {500, 500, 1000};\n    static const int msgs12[] = {300, 900, 600};\n    static const int *messages1[] = {msgs10, msgs11, msgs12};\n    static const int counts1[] = {4, 3, 3};\n    TestCase tc1 = {\n        .num_producers = 3,\n        .deficits = deficits1,\n        .messages = messages1,\n        .msg_counts = counts1\n    };\n\n    // Define Test Case 2\n    static const int deficits2[] = {500, 500};\n    static const int msgs20[] = {100,100,100,100,100,100,100,100,100,100};\n    static const int msgs21[] = {1000,100,100,100};\n    static const int *messages2[] = {msgs20, msgs21};\n    static const int counts2[] = {10, 4};\n    TestCase tc2 = {\n        .num_producers = 2,\n        .deficits = deficits2,\n        .messages = messages2,\n        .msg_counts = counts2\n    };\n\n    // Define Test Case 3\n    static const int deficits3[] = {500, 300, 700};\n    static const int msgs30[] = {}; // empty\n    static const int msgs31[] = {2000, 2000};\n    static const int msgs32[] = {100,100,100,100,100,100,100,100,100,100};\n    static const int *messages3[] = {msgs30, msgs31, msgs32};\n    static const int counts3[] = {0, 2, 10};\n    TestCase tc3 = {\n        .num_producers = 3,\n        .deficits = deficits3,\n        .messages = messages3,\n        .msg_counts = counts3\n    };\n\n    // Run DRR fairness evaluation for each test case\n    double results[3];\n    results[0] = run_drr_epsilon_max(tc1);\n    results[1] = run_drr_epsilon_max(tc2);\n    results[2] = run_drr_epsilon_max(tc3);\n\n    // Print the results in the EXACT REQUIRED format\n    printf(\"[%.6f,%.6f,%.6f]\\n\", results[0], results[1], results[2]);\n\n    return EXIT_SUCCESS;\n}\n```"
        }
    ]
}