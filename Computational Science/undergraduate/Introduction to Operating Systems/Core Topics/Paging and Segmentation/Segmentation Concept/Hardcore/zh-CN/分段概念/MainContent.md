## 引言
在[操作系统](@entry_id:752937)的世界里，内存管理是决定系统性能、稳定性和安全性的基石。如何在有限的物理内存中为多个并发执行的进程提供一个既独立又高效的运行环境，是[操作系统](@entry_id:752937)设计者面临的核心挑战之一。[内存分段](@entry_id:751882)（Segmentation）机制，作为一种经典的[内存虚拟化](@entry_id:751887)技术，为这一问题提供了优雅且强大的解决方案。它不仅仅是将内存分割为块，更是为程序提供了一个与其逻辑结构（如代码、数据、堆栈）相匹配的、结构化的视图，从而极大地简化了[内存保护](@entry_id:751877)、共享与动态管理。

然而，纯粹的分段模型也面临着[内存碎片](@entry_id:635227)等固有挑战，这促使它在现代计算体系中不断演化。本文旨在系统性地剖析分段机制的来龙去脉。我们首先将在“原理与机制”一章中，深入其核心的[地址转换](@entry_id:746280)过程、[硬件保护](@entry_id:750157)特性以及[性能优化](@entry_id:753341)手段。接着，在“应用与跨学科关联”一章，我们将把视野拓宽至真实世界的应用场景，考察分段如何在系统软件、[虚拟化](@entry_id:756508)技术中发挥作用，甚至其核心思想如何与生物学、物理学等领域产生共鸣。最后，通过一系列“动手实践”练习，您将有机会亲手模拟分段的关键操作，将理论知识转化为实践能力。让我们从分段最基本的原理开始，揭示它如何构建起现代计算机的内存世界。

## 原理与机制

在本章中，我们将深入探讨[内存分段](@entry_id:751882)的核心原理与硬件机制。分段不仅是一种[内存虚拟化](@entry_id:751887)技术，更是一种强大的内存组织与保护模型。我们将从其基本的[地址转换](@entry_id:746280)过程出发，逐步剖析其在[性能优化](@entry_id:753341)、进程结构化、内存共享、动态增长及安全保护等方面的具体实现，并最终探讨其在现代计算体系结构中的演化与地位。

### [逻辑地址](@entry_id:751440)到物理地址的转换

在分段系统中，内存不再被视为一个单一、连续的字节数组，而是被组织成一组逻辑上独立的单元，即**段 (segment)**。每个段都可以有不同的大小，并用于存放程序的不同组成部分，如代码、数据或堆栈。因此，处理器不再使用单一的线性地址，而是使用一个二维的**[逻辑地址](@entry_id:751440) (logical address)**，其形式通常为一个地址对 $(i, o)$，其中 $i$ 是**段索引 (segment index)** 或**段选择子 (segment selector)**，用于唯一标识一个段；$o$ 是**段内偏移 (offset)**，表示目标内存在该段起始位置之后的字节距离。

这种[逻辑地址](@entry_id:751440)必须由处理器的**[内存管理单元](@entry_id:751868) (Memory Management Unit, MMU)** 转换为物理内存中的**物理地址 (physical address)**。这个转换过程依赖于[操作系统](@entry_id:752937)为每个进程维护的一个核心数据结构——**[段表](@entry_id:754634) (segment table)**。[段表](@entry_id:754634)中的每一个条目被称为**[段描述符](@entry_id:754633) (segment descriptor)**，它详细定义了一个段的属性。对于[地址转换](@entry_id:746280)而言，每个[段描述符](@entry_id:754633) $i$ 至少包含两个关键信息：

1.  **基地址 (base address)** $b_i$：该段在物理内存中的起始地址。
2.  **界限 (limit)** $l_i$：该段的长度，以字节为单位。

当MMU接收到一个[逻辑地址](@entry_id:751440) $(i, o)$ 时，它会执行一个两步过程：

首先是**保护检查 (protection check)**。这是分段机制最核心的安全特性。MMU必须验证偏移量 $o$ 是否在该段的合法范围之内。由于偏移量是从0开始的，所以有效的偏移量必须满足条件 $0 \le o  l_i$。如果偏移量 $o$ 大于或等于段的界限 $l_i$，即 $o \ge l_i$，这意味着进程试图访问其分配范围之外的内存。这种违规行为会立即触发一个由硬件产生的同步陷阱（或称异常），从而中断当前指令的执行。

如果保护检查通过，MMU才进行第二步，即**[地址计算](@entry_id:746276) (address calculation)**。最终的物理地址 $p$ 通过将段的基地址与偏移量相加得到：
$$ p = b_i + o $$

这个计算结果 $p$ 就是内存总线上使用的最终物理地址。

当发生越界访问（即 $o \ge l_i$）时，硬件陷阱会强制将控制权从用户进程转移到[操作系统内核](@entry_id:752950)的预定陷阱处理程序。这一事件在许多系统中被称为**[段错误](@entry_id:754628) (segmentation fault)**。[操作系统](@entry_id:752937)处理程序接管后，会执行一系列标准操作来响应这个错误 。它会首先分析陷阱帧（由硬件保存的上下文信息），确定错误的类型（如段界限违规）、出错的进程标识符（[PID](@entry_id:174286)）、导致错误的指令地址（PC）以及违规访问的[逻辑地址](@entry_id:751440) $(i, o)$。[操作系统](@entry_id:752937)通常会将这些详细信息记录在内核日志中，以供调试和审计。随后，它会向出错的用户进程发送一个信号（在类UNIX系统中为 `SIGSEGV`）。如果该进程没有安装自定义的信号处理程序，[操作系统](@entry_id:752937)的默认行为通常是终止该进程，从而防止潜在的内存破坏或安全漏洞。

### 硬件加速：段后备缓冲器

上述[地址转换](@entry_id:746280)机制虽然逻辑清晰，却隐藏着一个严重的性能问题。[段表](@entry_id:754634)本身存储在主存中，而主存的访问速度远低于CPU的执行速度。如果每次内存访问（无论是取指令还是读写数据）都需要先从主存中读取相应的[段描述符](@entry_id:754633)，那么[地址转换](@entry_id:746280)的开销将是巨大的，会导致系统性能急剧下降。

幸运的是，程序的内存访问行为通常表现出良好的**局部性原理 (principle of locality)**，即在一段时间内，程序会集中访问少数几个段。为了利用这一特性，现代处理器集成了一个专门的高速缓存，用于存放最近使用过的[段描述符](@entry_id:754633)。这个缓存被称为**段后备缓冲器 (Segment Lookaside Buffer, SLB)**，它在概念上是**转换后备缓冲器 (Translation Lookaside Buffer, TLB)** 的一种形式 。

当需要转换[逻辑地址](@entry_id:751440) $(i, o)$ 时，MMU首先在SLB中查找段索引 $i$。
- **SLB命中 (Hit)**：如果找到了匹配的条目，MMU就可以立即从中获取基地址 $b_i$ 和界限 $l_i$，而无需访问主存。为了进一步提升速度，硬件可以将保护检查 ($o  l_i$) 和[地址计算](@entry_id:746276) ($b_i + o$) 并行执行。只有在检查通过后，计算出的物理地址才会被最终采纳。由于高命中率，SLB极大地降低了[地址转换](@entry_id:746280)的平均延迟。
- **SLB未命中 (Miss)**：如果在SLB中未找到段 $i$ 的描述符，硬件或[操作系统](@entry_id:752937)辅助代码才会去访问内存中的[段表](@entry_id:754634)，获取 $(b_i, l_i)$。获取后，该描述符会被加载到SLB中，以备后续访问使用，然后重新开始转换过程。

在多进程环境中，当[操作系统](@entry_id:752937)进行[上下文切换](@entry_id:747797)时，必须确保新的进程不会使用前一个进程的[地址映射](@entry_id:170087)。这可以通过两种方式实现：一是清空SLB；二是在SLB的每个条目中增加一个**地址空间标识符 (Address Space Identifier, ASID)** 标签，这样不同进程的缓存条目就可以共存而不会混淆。SLB的设计是实现高效[虚拟内存](@entry_id:177532)的关键，它将逻辑上优雅但看似缓慢的分段机制转变为一种在实践中可行的技术。

### 进程地址空间的逻辑结构

分段最显著的优点之一是它为程序员和[操作系统](@entry_id:752937)提供了一个与程序逻辑结构相匹配的内存视图。一个进程的地址空间可以被自然地划分为多个有意义的段，例如：
- **代码段 (Code Segment)**：存放可执行指令，通常被设置为只读和可执行。
- **数据段 (Data Segment)**：存放初始化的全局变量和静态变量，通常是可读写的。
- **堆段 (Heap Segment)**：用于动态[内存分配](@entry_id:634722)（例如，通过 `malloc` 或 `new`），可读写。
- **栈段 (Stack Segment)**：用于存放[函数调用](@entry_id:753765)的返回地址、参数和局部变量，可读写。

这种结构化方法为内存共享、保护和动态管理提供了极大的灵活性。

#### 段的共享与隔离

分段机制使得在进程间安全地共享内存变得简单而高效。一个典型的应用场景是共享代码库 。当多个进程运行同一个程序时，它们的**代码段**是完全相同的。[操作系统](@entry_id:752937)可以只在物理内存中加载一份该程序的代码，然后让所有相关进程的[段表](@entry_id:754634)中对应的代码[段描述符](@entry_id:754633)都指向这同一个物理内存区域。为了保证代码的完整性，这个共享段的权限会被设置为只读（Read）和可执行（Execute），任何向该段写入的尝试都会被硬件阻止。

与此同时，每个进程的**数据段**必须是私有的。[操作系统](@entry_id:752937)通过为每个进程的数据段分配**不同**的物理内存区域来实现**隔离 (isolation)**。因此，进程 $P_1$ 的数据[段描述符](@entry_id:754633)指向物理地址 $[b_{d1}, b_{d1} + L_d)$，而进程 $P_2$ 的数据[段描述符](@entry_id:754633)指向完全不相关的物理地址 $[b_{d2}, b_{d2} + L_d)$。这样，即使它们执行相同的代码，对全局变量的修改也只会影响各自的私有数据副本。

为了管理共享段的生命周期，[操作系统](@entry_id:752937)通常会使用**引用计数 (reference counting)**。每当一个新进程映射该共享段时，其引用计数加一；当进程退出或卸载该段时，计数减一。只有当引用计数降为零时，[操作系统](@entry_id:752937)才会回收该物理内存。此外，如果[操作系统](@entry_id:752937)需要修改共享段的映射（例如，因内存整理而移动其物理位置），它必须确保所有正在使用该段的进程都能看到更新。由于MMU会缓存[段描述符](@entry_id:754633)，[操作系统](@entry_id:752937)在更新[段表](@entry_id:754634)后，必须强制使所有处理器上相关的缓存条目（如TLB/SLB条目）失效，这一过程称为**[TLB击落](@entry_id:756023) (TLB shootdown)**，以保证[地址转换](@entry_id:746280)的一致性。

#### 动态增长：[堆与栈](@entry_id:636580)的管理

进程的内存需求在运行时是动态变化的，尤其是堆和栈。一种经典且高效的[虚拟地址空间](@entry_id:756510)布局策略是将堆和栈放置在地址空间的两端，并让它们相向生长  。
- **堆 (Heap)** 通常从低地址端开始，向上（向高地址方向）增长。
- **栈 (Stack)** 通常从高地址端开始，向下（向低地址方向）增长。

这种布局使得两者可以共享它们之间的整个空闲区域，只要它们的边界不发生碰撞，就可以最大限度地利用[虚拟地址空间](@entry_id:756510)。

为防止堆和栈相互侵犯，必须确保堆的顶端始终低于栈的底端。让我们来精确定义这个非重叠条件。假设一个向上生长的堆段，其基地址为 $b_{\text{heap}}$，长度为 $l_{\text{heap}}$。它占用的地址范围是 $[b_{\text{heap}}, b_{\text{heap}} + l_{\text{heap}} - 1]$。对于一个向下生长的栈，其“基地址” $b_{\text{stack}}$ 通常指其固定的最高地址边界，其长度为 $l_{\text{stack}}$。它占用的地址范围是 $[b_{\text{stack}} - l_{\text{stack}}, b_{\text{stack}} - 1]$。为了安全，[操作系统](@entry_id:752937)还会在两个段的生长方向上设置**保护区 (guard region)**，即一小块无效的地址空间。设堆的保护区大小为 $g_{\text{heap}}$，栈的保护区大小为 $g_{\text{stack}}$。

堆及其保护区占据的最高地址为 $b_{\text{heap}} + l_{\text{heap}} + g_{\text{heap}} - 1$。
栈及其保护区占据的最低地址为 $b_{\text{stack}} - l_{\text{stack}} - g_{\text{stack}}$。

非重叠的严格条件是，堆区域的最高地址必须小于栈区域的最低地址：
$$ b_{\text{heap}} + l_{\text{heap}} + g_{\text{heap}} - 1  b_{\text{stack}} - l_{\text{stack}} - g_{\text{stack}} $$
由于地址是离散的，这等价于：
$$ b_{\text{heap}} + l_{\text{heap}} + g_{\text{heap}} \le b_{\text{stack}} - l_{\text{stack}} - g_{\text{stack}} $$

从这个不等式，我们可以解出在给定栈状态下，堆的最大允许长度 $l_{\text{heap}}^{\max}$ ：
$$ l_{\text{heap}}^{\max} = b_{\text{stack}} - b_{\text{heap}} - l_{\text{stack}} - g_{\text{heap}} - g_{\text{stack}} $$

[操作系统](@entry_id:752937)采用不同的策略来管理这两种段的增长 。堆的增长通常由程序通过显式的系统调用（如 `brk`）来请求。当[操作系统](@entry_id:752937)收到请求时，它会检查新的堆顶是否会与栈的保护区发生冲突。如果安全，它就更新堆段的界限；否则，拒绝请求。栈的增长通常是自动的。当程序执行（如深度递归）导致[栈指针](@entry_id:755333)超出当前栈的边界并进入下方的保护区时，会触发一个硬件陷阱。[操作系统](@entry_id:752937)捕获这个陷阱，并将其解释为扩展栈的请求。如果检查后发现仍有足够的空间，[操作系统](@entry_id:752937)就会调整栈的界限，使新的栈区域变为有效，然后恢复程序执行。这种按需扩展的方式对应用程序是透明的。

### 分段保护机制

除了通过界限检查防止越界访问，分段机制通常还包含一套复杂而精细的权限控制系统，尤其是在像Intel x86这样的体系结构中。这种保护机制基于**特权级 (privilege levels)** 或**环 (rings)** 的概念，旨在隔离不同信任级别的软件组件，最典型的应用是隔离用户应用程序和操作系统内核。

#### 特权级与[访问控制](@entry_id:746212)

特权级通常被组织成多个同心环，其中环0（Ring 0）拥有最高特权（通常为内核保留），而环3（Ring 3）拥有最低特权（通常用于用户应用程序）。为了实施保护，硬件会跟踪以下几个关键的[特权级别](@entry_id:753757)：

- **当前特权级 (Current Privilege Level, CPL)**：当前正在执行的代码的特权级，通常由代码段选择子中的特定位决定。
- **描述符特权级 (Descriptor Privilege Level, DPL)**：存储在[段描述符](@entry_id:754633)中，代表访问该段所**需要**的最低特权。
- **请求特权级 (Requested Privilege Level, RPL)**：存储在段选择子中，允许高特权级的代码在访问段时，临时模拟一个较低的特权级，以防止某些类型的安全攻击（如特洛伊木马）。

当代码试图访问一个数据段时，硬件会进行权限检查。对于数据访问，有效的特权级（EPL）是CPL和RPL中权限较低（即数值较大）的一个，即 $EPL = \max(CPL, RPL)$。只有当访问者的有效特权级高于或等于段的特权级时（数值上即 $EPL \le DPL_{\text{data}}$），访问才被允许。此外，[段描述符](@entry_id:754633)中还包含独立的读（R）、写（W）、执行（X）权限位，即使特权级检查通过，尝试写入一个 $W=0$ 的段（如代码段）也会失败 。

从低特权级到高特权级的控制转移（例如，用户程序发起系统调用进入内核）受到严格管制。用户代码不能直接跳转到内核代码段。这种转移必须通过一个受控的接口——**[调用门](@entry_id:747096) (call gate)** 来进行。[调用门](@entry_id:747096)本身也是一种描述符，它有自己的DPL，并指向目标内核代码段。当用户进程（如CPL=3）通过[调用门](@entry_id:747096)发起调用时，硬件会检查调用者的CPL是否满足[调用门](@entry_id:747096)的DPL要求。如果检查通过，CPU会自动切换到内核的栈，并将CPL提升到目标代码段的DPL（如0），然后才开始执行内核代码。这个过程确保了用户程序只能通过预定义的、安全的入口点进入内核，而不能任意篡改或执行内核代码。

#### 实例研究：x86[保护模式](@entry_id:753820)

为了更具体地理解这些机制，让我们看一个x86[保护模式](@entry_id:753820)下的例子 。在x86中，一个16位的段选择子被解码为三个部分：13位的**索引**，1位的**表指示符 (Table Indicator, TI)**，以及2位的**RPL**。TI位决定了是在**全局描述符表 (Global Descriptor Table, GDT)** 中查找描述符（$TI=0$），还是在进程私有的**局部描述符表 (Local Descriptor Table, LDT)** 中查找（$TI=1$）。

假设一个$CPL=3$的用户进程，其寄存器状态如下：
- $CS = 0x0043 \implies (\text{索引}=8, TI=0, RPL=3)$，指向GDT中DPL=3的代码段。
- $DS = 0x0029 \implies (\text{索引}=5, TI=0, RPL=1)$，指向GDT中DPL=3的数据段。
- $SS = 0x0033 \implies (\text{索引}=6, TI=0, RPL=3)$，指向GDT中DPL=3的栈段。
- $FS = 0x0017 \implies (\text{索引}=2, TI=1, RPL=3)$，指向LDT中DPL=3的数据段。

当处理器执行指令时：
1.  **取指令**：地址由 $(CS, EIP)$ 给出。处理器使用CS选择子的索引8在GDT中找到代码[段描述符](@entry_id:754633)，获取基地址 $b_{cs}$，最终的线性地址是 $b_{cs} + EIP$。
2.  **数据访问**：如 `MOV [ECX]`，默认使用DS段。处理器用DS选择子的索引5在GDT中找到数据[段描述符](@entry_id:754633)，获取基地址 $b_{ds}$，线性地址为 $b_{ds} + ECX$。
3.  **栈访问**：如 `MOV [EBP + 8]`，由于使用了基址指针EBP，默认使用SS段。处理器用SS选择子的索引6在GDT中找到栈[段描述符](@entry_id:754633)，获取基地址 $b_{ss}$，线性地址为 $b_{ss} + (EBP + 8)$。
4.  **段重载**：如 `MOV fs:[0xC]`，前缀 `fs:` 强制使用FS段。处理器用FS选择子的索引2在LDT中找到描述符，获取基地址 $b_{fs}$，线性地址为 $b_{fs} + 0xC$。

在每一步中，硬件都会进行界限和特权级检查，确保访问的合法性。这个例子展示了分段机制如何将程序的逻辑视图（通过CS, DS, SS等段寄存器）映射到内存的线性地址空间，同时集成了复杂的保护策略。

### 分段的局限性与演化

尽管分段在逻辑结构和保护方面表现出色，但纯粹的分段方案存在一个固有的严重问题，这促使其在现代系统中不断演化。

#### [内存碎片](@entry_id:635227)问题

分段机制的主要缺点是**[外部碎片](@entry_id:634663) (external fragmentation)** 。由于段的大小是可变的，当段被创建、销毁和换出内存时，物理内存中会散布着许多大小不一的空闲块（“孔洞”）。随着时间的推移，这些孔洞可能会变得非常小且不连续。最终可能出现这样一种情况：总的可用内存足够大，可以容纳一个新的段，但没有任何一个单独的连续空闲块足够大来分配给它。这些无法利用的空闲[空间总和](@entry_id:154701)就是[外部碎片](@entry_id:634663)。

例如，假设内存中有 $(8000, 6000, 12000, 5000, 7000)$ 字节的空闲块，我们需要按顺序分配大小为 $(5000, 9000, 7000, 3000, 11000)$ 字节的段。使用**首次适应 (first-fit)** 策略，前四个段可以成功分配，但最后一个11000字节的段将无法分配，因为此时最大的单个空闲块只有6000字节。然而，此时内存中剩余的空闲[空间总和](@entry_id:154701)（即[外部碎片](@entry_id:634663)）可能高达14000字节。这种内存浪费是分段方案的一个严重缺陷。

与此相对，分页（paging）方案虽然避免了[外部碎片](@entry_id:634663)（因为所有分配单元大小固定），但会产生**[内部碎片](@entry_id:637905) (internal fragmentation)**。由于一个进程的内存需求很少是页大小的整数倍，其最后一个页总会有部分空间被浪费。例如，对于一个5000字节的段，如果页大小为4096字节，则需要分配2个页面（8192字节），从而浪费 $8192 - 5000 = 3192$ 字节。

#### 混合模型：段页式[内存管理](@entry_id:636637)

为了集两家之长——既保留分段的逻辑优势，又克服其[外部碎片](@entry_id:634663)问题——像Intel x86这样的体系结构引入了**段页式 (segmented paging)** 混合模型 。

在这个模型中，[地址转换](@entry_id:746280)分为两个阶段：
1.  **分段单元**首先将[逻辑地址](@entry_id:751440) $(i, o)$ 转换为一个**线性地址 (linear address)**。这个过程与纯分段类似，但[段描述符](@entry_id:754633)中的“基地址”不再指向物理内存，而是指向该段的**页表 (page table)** 的基地址。界限检查 $o  L_i$ 依然在此阶段进行。
2.  **[分页](@entry_id:753087)单元**接着将这个线性地址（现在被视为一个普通的虚拟地址）转换为最终的物理地址。

举个例子，假设页大小为1024字节，要转换[逻辑地址](@entry_id:751440) $(i=3, o=2321)$。段3的界限 $L_3=5000$ 字节。
1.  **分段检查**：$2321  5000$，检查通过。
2.  **线性地址分解**：分页单元将段内偏移 $o=2321$ 分解为页号 $p$ 和页内偏移 $d$。
    $$ p = \lfloor \frac{2321}{1024} \rfloor = 2 $$
    $$ d = 2321 \pmod{1024} = 273 $$
3.  **页表查询**：分页单元查找段3的页表（其位置由[段描述符](@entry_id:754633)提供），找到第 $p=2$ 个条目，获取其对应的物理页框号 $f$。假设查表得 $f=8$。
4.  **物理[地址计算](@entry_id:746276)**：最终物理地址为 $(f \times \text{页大小}) + d = (8 \times 1024) + 273 = 8465$。

在这种模式下，一个逻辑段可以由分散在物理内存各处的多个页框组成，从而完美解决了[外部碎片](@entry_id:634663)问题。

#### 现代应用：[平坦模](@entry_id:153965)型与特殊用途段

在现代64位[操作系统](@entry_id:752937)（如Windows x64, Linux）中，段页式模型进一步演化，形成了一种**近乎平坦 (near-flat)** 的[内存模型](@entry_id:751871) 。在x86-64的“长模式”下，分段的作用被大大削弱。

[操作系统](@entry_id:752937)通常会将代码段（CS）、数据段（DS）、栈段（SS）的基地址都设置为0，并将它们的界限设置为一个非常大的值（实际上，在64位模式下，对这些段的基址和界限检查在很大程度上被硬件忽略了）。这样一来，分段单元的[地址转换](@entry_id:746280)就变成了一个[恒等映射](@entry_id:634191)：
$$ \text{线性地址} = \text{基地址} + \text{偏移量} = 0 + o = o $$

在这种配置下，[逻辑地址](@entry_id:751440)中的偏移量直接等同于线性地址。所有的虚拟化、隔离和保护任务都完全交给了功能更强大、更灵活的**[分页](@entry_id:753087)机制**。用户空间和内核空间的隔离是通过[页表项](@entry_id:753081)中的**用户/超级用户 (User/Supervisor)** 权限位，结合CPU当前的特权级（CPL）来实现的。

那么，分段是否已经彻底过时了呢？并非如此。即使在[平坦模](@entry_id:153965)型中，分段依然在一些特殊场景中扮演着不可或缺的角色。最突出的例子是 `FS` 和 `GS` 段寄存器的使用。[操作系统](@entry_id:752937)并不会将它们的基地址设为0，而是利用它们来指向一些特殊的数据结构。例如，内核可以为每个运行中的线程设置不同的 `GS` 基地址，使其指向各自的**[线程局部存储](@entry_id:755944) (Thread-Local Storage, TLS)** 块。这样，线程代码就可以通过 `gs:[offset]` 这样的地址形式，高效地、与硬件无关地访问自己的私有数据。同样，`FS` 或 `GS` 也常被用来指向存放当前CPU信息的结构。这种巧妙的应用，展示了分段作为一种提供额外基址寄存器的机制，在现代[高性能计算](@entry_id:169980)中仍然具有生命力。