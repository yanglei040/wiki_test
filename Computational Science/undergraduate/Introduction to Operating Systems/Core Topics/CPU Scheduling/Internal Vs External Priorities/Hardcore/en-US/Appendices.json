{
    "hands_on_practices": [
        {
            "introduction": "Effective resource management requires balancing policy goals with physical realities. This exercise explores a common scenario in memory bandwidth allocation, where an operating system must honor administrator-defined external priorities while respecting the actual memory demand exhibited by each workload. By working through this calculation, you will gain hands-on experience in applying a hybrid scheduling policy that translates high-level weights into concrete resource caps, a fundamental skill in performance tuning and system administration .",
            "id": "3649910",
            "problem": "A multiprogrammed Operating System (OS) multiplexes a shared memory bus of finite peak throughput across concurrent workloads. The administrator supplies external priorities as nonnegative weights that express relative importance, while the OS also observes internal priorities through demand estimates computed from hardware performance counters. Consider the following policy for enforcing memory-bandwidth throttling under a global peak memory bandwidth budget: given external weights and internal demand estimates, the OS assigns each workload a bandwidth cap proportional to its external weight but not exceeding its internal demand. Specifically, for workload index $i \\in \\{1,2,3,4\\}$, the cap is $C_i(\\alpha) = \\min\\{\\alpha\\,w_i, D_i\\}$ for some scaling factor $\\alpha \\ge 0$, and the OS chooses $\\alpha$ so that the total assigned bandwidth exactly equals the global budget $B_{\\max}$, that is $\\sum_{i=1}^{4} C_i(\\alpha) = B_{\\max}$.\n\nAssume $4$ workloads with external weights $w_1 = 3$, $w_2 = 1$, $w_3 = 4$, and $w_4 = 2$. The internal demand estimate $D_i$ for each workload is derived from a Last-Level Cache (LLC) miss counter as follows: if a workload exhibits $m_i$ LLC misses per second and each LLC miss fetches exactly one cache line of size $c$ bytes from main memory, then the workload’s instantaneous memory-bandwidth demand is $D_i = m_i \\, c$ bytes per second. Take the cache line size to be $c = 64$ bytes and define $1$ gigabyte (GB) to be $10^9$ bytes. The observed LLC-miss rates are $m_1 = 150 \\times 10^6$ misses per second, $m_2 = 50 \\times 10^6$ misses per second, $m_3 = 500 \\times 10^6$ misses per second, and $m_4 = 200 \\times 10^6$ misses per second. The global memory bandwidth budget is $B_{\\max} = 35$ GB/s.\n\nUnder the above policy, determine the final bandwidth cap for workload $4$. Express your answer in GB/s and round your answer to four significant figures.",
            "solution": "The problem requires the determination of the memory bandwidth cap for workload $4$, denoted as $C_4$, under a specific resource allocation policy. The policy is defined for $N=4$ workloads, indexed by $i \\in \\{1, 2, 3, 4\\}$.\n\nFirst, we must formalize the problem by calculating the internal demand estimate, $D_i$, for each workload. The demand is given by the product of the Last-Level Cache (LLC) miss rate, $m_i$, and the cache line size, $c$. The provided values are:\n- Cache line size, $c = 64$ bytes.\n- Miss rate for workload 1, $m_1 = 150 \\times 10^6$ misses/s.\n- Miss rate for workload 2, $m_2 = 50 \\times 10^6$ misses/s.\n- Miss rate for workload 3, $m_3 = 500 \\times 10^6$ misses/s.\n- Miss rate for workload 4, $m_4 = 200 \\times 10^6$ misses/s.\n\nThe demand $D_i = m_i c$ for each workload is calculated as follows, converting the units from bytes/s to gigabytes/s (GB/s), where $1 \\text{ GB} = 10^9$ bytes:\n- $D_1 = (150 \\times 10^6 \\text{ s}^{-1}) \\times (64 \\text{ bytes}) = 9600 \\times 10^6 \\text{ bytes/s} = 9.6 \\text{ GB/s}$.\n- $D_2 = (50 \\times 10^6 \\text{ s}^{-1}) \\times (64 \\text{ bytes}) = 3200 \\times 10^6 \\text{ bytes/s} = 3.2 \\text{ GB/s}$.\n- $D_3 = (500 \\times 10^6 \\text{ s}^{-1}) \\times (64 \\text{ bytes}) = 32000 \\times 10^6 \\text{ bytes/s} = 32.0 \\text{ GB/s}$.\n- $D_4 = (200 \\times 10^6 \\text{ s}^{-1}) \\times (64 \\text{ bytes}) = 12800 \\times 10^6 \\text{ bytes/s} = 12.8 \\text{ GB/s}$.\n\nThe bandwidth cap for each workload, $C_i(\\alpha)$, is given by the formula $C_i(\\alpha) = \\min\\{\\alpha\\,w_i, D_i\\}$, where $w_i$ are the external weights and $\\alpha$ is a scaling factor. The given weights are $w_1 = 3$, $w_2 = 1$, $w_3 = 4$, and $w_4 = 2$.\n\nThe scaling factor $\\alpha$ must be chosen such that the sum of the individual caps equals the global memory bandwidth budget, $B_{\\max} = 35$ GB/s. This gives the governing equation:\n$$ \\sum_{i=1}^{4} C_i(\\alpha) = B_{\\max} $$\n$$ \\min\\{\\alpha w_1, D_1\\} + \\min\\{\\alpha w_2, D_2\\} + \\min\\{\\alpha w_3, D_3\\} + \\min\\{\\alpha w_4, D_4\\} = B_{\\max} $$\nSubstituting the known values for $w_i$, $D_i$, and $B_{\\max}$:\n$$ \\min\\{3\\alpha, 9.6\\} + \\min\\{\\alpha, 3.2\\} + \\min\\{4\\alpha, 32.0\\} + \\min\\{2\\alpha, 12.8\\} = 35 $$\nLet $f(\\alpha)$ be the total allocated bandwidth. The function $f(\\alpha)$ is continuous, monotonically increasing, and piecewise linear. The points where the function's linear segments change are the critical values of $\\alpha$ where a workload's allocation becomes demand-limited, i.e., when $\\alpha w_i = D_i$. Let's denote these critical values as $\\alpha_i^* = D_i/w_i$.\n- $\\alpha_1^* = \\frac{D_1}{w_1} = \\frac{9.6}{3} = 3.2$.\n- $\\alpha_2^* = \\frac{D_2}{w_2} = \\frac{3.2}{1} = 3.2$.\n- $\\alpha_3^* = \\frac{D_3}{w_3} = \\frac{32.0}{4} = 8.0$.\n- $\\alpha_4^* = \\frac{D_4}{w_4} = \\frac{12.8}{2} = 6.4$.\n\nWe can solve for $\\alpha$ by examining the total allocation in the intervals defined by these ordered critical values ($3.2, 6.4, 8.0$).\n\nCase 1: $0 \\le \\alpha < 3.2$.\nIn this interval, $\\alpha w_i < D_i$ for all $i$. Thus, $C_i(\\alpha) = \\alpha w_i$ for all $i$.\nThe equation becomes $\\sum_{i=1}^{4} \\alpha w_i = B_{\\max}$, which simplifies to $\\alpha \\sum_{i=1}^{4} w_i = B_{\\max}$.\nThe sum of weights is $\\sum w_i = 3 + 1 + 4 + 2 = 10$.\nSo, $\\alpha(10) = 35$, which gives $\\alpha = 3.5$.\nThis value $\\alpha = 3.5$ is outside the assumed interval $[0, 3.2)$. Therefore, the solution for $\\alpha$ must be larger than $3.2$. This indicates that at least one workload is demand-limited. Let's evaluate the total bandwidth at the boundary $\\alpha = 3.2$:\n$f(3.2) = \\min\\{3(3.2), 9.6\\} + \\min\\{1(3.2), 3.2\\} + \\min\\{4(3.2), 32.0\\} + \\min\\{2(3.2), 12.8\\}$\n$f(3.2) = \\min\\{9.6, 9.6\\} + \\min\\{3.2, 3.2\\} + \\min\\{12.8, 32.0\\} + \\min\\{6.4, 12.8\\}$\n$f(3.2) = 9.6 + 3.2 + 12.8 + 6.4 = 32.0$ GB/s.\nSince $f(3.2) = 32.0 < B_{\\max} = 35$, the correct value of $\\alpha$ must be greater than $3.2$.\n\nCase 2: $3.2 \\le \\alpha < 6.4$.\nIn this interval, workloads $1$ and $2$ are demand-limited because $\\alpha \\ge \\alpha_1^* = 3.2$ and $\\alpha \\ge \\alpha_2^* = 3.2$. Their caps are fixed at their demands: $C_1(\\alpha) = D_1 = 9.6$ and $C_2(\\alpha) = D_2 = 3.2$.\nWorkloads $3$ and $4$ are still weight-proportional because $\\alpha < \\alpha_3^* = 8.0$ and $\\alpha < \\alpha_4^* = 6.4$. Their caps are $C_3(\\alpha) = 4\\alpha$ and $C_4(\\alpha) = 2\\alpha$.\nThe governing equation becomes:\n$$ D_1 + D_2 + \\alpha w_3 + \\alpha w_4 = B_{\\max} $$\n$$ 9.6 + 3.2 + 4\\alpha + 2\\alpha = 35 $$\n$$ 12.8 + 6\\alpha = 35 $$\n$$ 6\\alpha = 35 - 12.8 $$\n$$ 6\\alpha = 22.2 $$\n$$ \\alpha = \\frac{22.2}{6} = 3.7 $$\nThis value $\\alpha = 3.7$ lies within the interval $[3.2, 6.4)$, confirming our assumption. This is the correct scaling factor.\n\nNow we can determine the final bandwidth cap for workload $4$, $C_4$.\nUsing the determined value $\\alpha=3.7$:\n$$ C_4 = C_4(3.7) = \\min\\{2\\alpha, D_4\\} = \\min\\{2(3.7), 12.8\\} $$\n$$ C_4 = \\min\\{7.4, 12.8\\} = 7.4 $$\nThe bandwidth cap for workload $4$ is $7.4$ GB/s.\n\nAs a final check, let's calculate all caps and their sum:\n$C_1 = \\min\\{3(3.7), 9.6\\} = \\min\\{11.1, 9.6\\} = 9.6$ GB/s.\n$C_2 = \\min\\{1(3.7), 3.2\\} = \\min\\{3.7, 3.2\\} = 3.2$ GB/s.\n$C_3 = \\min\\{4(3.7), 32.0\\} = \\min\\{14.8, 32.0\\} = 14.8$ GB/s.\n$C_4 = 7.4$ GB/s.\nTotal bandwidth $= C_1 + C_2 + C_3 + C_4 = 9.6 + 3.2 + 14.8 + 7.4 = 12.8 + 14.8 + 7.4 = 27.6 + 7.4 = 35.0$ GB/s.\nThe sum matches the budget $B_{\\max} = 35$ GB/s.\n\nThe problem asks for the answer to be expressed in GB/s and rounded to four significant figures. The calculated value is exactly $7.4$. To express this with four significant figures, we write it as $7.400$.",
            "answer": "$$ \\boxed{7.400} $$"
        },
        {
            "introduction": "Operating systems often face difficult decisions, especially under extreme resource pressure like an Out-Of-Memory (OOM) condition. This practice challenges you to step into the role of a system designer and create a rational model for choosing the \"least harmful\" action: swapping a process to disk or terminating it entirely. You will learn to quantify abstract concepts like \"process importance\" and \"system disruption\" by combining external priority coefficients with internal metrics like memory footprint and page fault rates, providing a structured approach to a complex problem .",
            "id": "3649860",
            "problem": "An operating system using demand paging must avert an impending Out-Of-Memory (OOM) condition by taking exactly one action on a single process: either swap it out fully to disk or terminate it. The choice must balance external priority (policy-level importance) against internal memory behavior (resident set size and page fault activity). The system designer proposes a risk-weighted harm model grounded in first principles:\n\n- External policy importance is captured by an external priority coefficient $w_i$ for process $i$, where larger $w_i$ means the process is more protected from termination.\n- Internal memory footprint is measured by resident set size (RSS) $r_i$ in $\\text{MiB}$.\n- Internal memory pressure is reflected by page fault rate $\\phi_i$ in faults per second.\n- Swapping a process out consists of writing its resident set to disk; with sustained disk throughput $b$ in $\\text{MiB/s}$, swapping process $i$ takes time $t^{\\text{swap}}_i$ equal to its resident set divided by throughput.\n- A page fault uses disk Input/Output (I/O) to bring the missing page into Random Access Memory (RAM); the average service time per fault is $\\tau$ seconds.\n- The harm of swapping a process out is the sum of two components incurred during the swap time only: a stall cost proportional to swap time and a thrashing cost equal to the cumulative page fault service time of that process during the swap.\n- The harm of killing a process scales with its external priority coefficient.\n\nAssume the following system parameters and process metrics:\n- Disk throughput $b = 250\\ \\text{MiB/s}$.\n- Average page fault service time $\\tau = 0.008\\ \\text{s}$.\n- Swap stall penalty rate $\\lambda = 2\\ \\text{harm units/s}$.\n- Thrashing penalty rate $\\mu = 1\\ \\text{harm unit/s}$.\n- Base kill penalty $u = 100\\ \\text{harm units}$.\n\nThree processes are candidates, with identifiers $i \\in \\{1,2,3\\}$:\n- Process $1$: external priority coefficient $w_1 = 1.9$, resident set size $r_1 = 2300\\ \\text{MiB}$, page fault rate $\\phi_1 = 120\\ \\text{s}^{-1}$.\n- Process $2$: external priority coefficient $w_2 = 0.6$, resident set size $r_2 = 1500\\ \\text{MiB}$, page fault rate $\\phi_2 = 40\\ \\text{s}^{-1}$.\n- Process $3$: external priority coefficient $w_3 = 0.3$, resident set size $r_3 = 3400\\ \\text{MiB}$, page fault rate $\\phi_3 = 80\\ \\text{s}^{-1}$.\n\nUsing only the fundamental definitions above, derive the expected harm for the optimal swap choice $H_{\\text{swap}}^{\\star}$ and the expected harm for the optimal kill choice $H_{\\text{kill}}^{\\star}$, then compute the difference\n$$\\Delta = H_{\\text{swap}}^{\\star} - H_{\\text{kill}}^{\\star}.$$\nRound your final numeric value for $\\Delta$ to four significant figures. Express the final result as a pure number (harm units are implicit and must not be written in the answer).",
            "solution": "The problem requires the calculation of harm associated with two possible actions—swapping or terminating a process—to mitigate an Out-Of-Memory condition. The optimal choice for each action is the one that minimizes the associated harm. We must first formalize the harm models based on the provided definitions.\n\nFirst, we define the harm incurred by swapping out process $i$, denoted as $H_i^{\\text{swap}}$. The problem states this harm is the sum of a stall cost and a thrashing cost, both incurred during the time it takes to swap the process.\n\nThe swap time for process $i$, $t^{\\text{swap}}_i$, is the time required to write its resident set size $r_i$ to disk at a sustained throughput $b$.\n$$t^{\\text{swap}}_i = \\frac{r_i}{b}$$\n\nThe stall cost is defined as being proportional to the swap time, with a penalty rate $\\lambda$. The harm from the stall is therefore:\n$$H_{i, \\text{stall}} = \\lambda t^{\\text{swap}}_i$$\n\nThe thrashing cost is described in a slightly ambiguous manner. It is stated to be \"equal to the cumulative page fault service time,\" while a \"thrashing penalty rate\" $\\mu$ is also provided. To ensure dimensional consistency, we must construct a formula in units of harm. The \"cumulative page fault service time\" for process $i$ during its swap period is the total time the disk would be busy servicing that process's page faults. This is calculated by finding the number of faults during the swap, $N_i = \\phi_i t^{\\text{swap}}_i$, and multiplying by the average service time per fault, $\\tau$. Thus, the total service time is $T_{i, \\text{faults}} = (\\phi_i t^{\\text{swap}}_i) \\tau$. This quantity has units of time. The thrashing penalty rate $\\mu$ is given in harm units per second. Multiplying this rate by the total service time $T_{i, \\text{faults}}$ yields a quantity with units of harm: $\\mu \\cdot T_{i, \\text{faults}}$. This is the only interpretation that is both dimensionally consistent and utilizes all given parameters.\n$$H_{i, \\text{thrash}} = \\mu \\cdot T_{i, \\text{faults}} = \\mu (\\phi_i t^{\\text{swap}}_i \\tau)$$\n\nThe total harm for swapping process $i$ is the sum of these two components:\n$$H_i^{\\text{swap}} = H_{i, \\text{stall}} + H_{i, \\text{thrash}} = \\lambda t^{\\text{swap}}_i + \\mu \\phi_i t^{\\text{swap}}_i \\tau$$\nFactoring out $t^{\\text{swap}}_i$ and substituting its expression gives:\n$$H_i^{\\text{swap}} = (\\lambda + \\mu \\phi_i \\tau) t^{\\text{swap}}_i = (\\lambda + \\mu \\phi_i \\tau) \\frac{r_i}{b}$$\n\nNext, we define the harm of killing process $i$, denoted as $H_i^{\\text{kill}}$. The problem states this harm \"scales with its external priority coefficient $w_i$\" and that \"larger $w_i$ means the process is more protected from termination.\" This implies that the harm of killing a process is a monotonically increasing function of $w_i$. Given the \"base kill penalty\" $u$, the most direct and logical formulation is a direct proportionality:\n$$H_i^{\\text{kill}} = u \\cdot w_i$$\n\nThe problem provides the following system parameters:\n- Disk throughput $b = 250 \\text{ MiB/s}$.\n- Average page fault service time $\\tau = 0.008 \\text{ s}$.\n- Swap stall penalty rate $\\lambda = 2 \\text{ harm units/s}$.\n- Thrashing penalty rate $\\mu = 1 \\text{ harm unit/s}$.\n- Base kill penalty $u = 100 \\text{ harm units}$.\n\nThe metrics for the three candidate processes are:\n- Process $1$: $w_1 = 1.9$, $r_1 = 2300 \\text{ MiB}$, $\\phi_1 = 120 \\text{ s}^{-1}$.\n- Process $2$: $w_2 = 0.6$, $r_2 = 1500 \\text{ MiB}$, $\\phi_2 = 40 \\text{ s}^{-1}$.\n- Process $3$: $w_3 = 0.3$, $r_3 = 3400 \\text{ MiB}$, $\\phi_3 = 80 \\text{ s}^{-1}$.\n\nWe now calculate the swap harm for each process using the derived formula $H_i^{\\text{swap}} = \\frac{r_i}{b}(\\lambda + \\mu \\phi_i \\tau)$:\n$$H_1^{\\text{swap}} = \\frac{2300}{250} (2 + 1 \\cdot 120 \\cdot 0.008) = 9.2 (2 + 0.96) = 9.2(2.96) = 27.232$$\n$$H_2^{\\text{swap}} = \\frac{1500}{250} (2 + 1 \\cdot 40 \\cdot 0.008) = 6 (2 + 0.32) = 6(2.32) = 13.92$$\n$$H_3^{\\text{swap}} = \\frac{3400}{250} (2 + 1 \\cdot 80 \\cdot 0.008) = 13.6 (2 + 0.64) = 13.6(2.64) = 35.904$$\n\nThe optimal swap choice is the one with the minimum harm. The expected harm for the optimal swap choice, $H_{\\text{swap}}^{\\star}$, is therefore the minimum of these values:\n$$H_{\\text{swap}}^{\\star} = \\min\\{H_1^{\\text{swap}}, H_2^{\\text{swap}}, H_3^{\\text{swap}}\\} = \\min\\{27.232, 13.92, 35.904\\} = 13.92$$\n\nNext, we calculate the kill harm for each process using the formula $H_i^{\\text{kill}} = u \\cdot w_i$:\n$$H_1^{\\text{kill}} = 100 \\cdot 1.9 = 190$$\n$$H_2^{\\text{kill}} = 100 \\cdot 0.6 = 60$$\n$$H_3^{\\text{kill}} = 100 \\cdot 0.3 = 30$$\n\nThe optimal kill choice is the one with the minimum harm. The expected harm for the optimal kill choice, $H_{\\text{kill}}^{\\star}$, is the minimum of these values:\n$$H_{\\text{kill}}^{\\star} = \\min\\{H_1^{\\text{kill}}, H_2^{\\text{kill}}, H_3^{\\text{kill}}\\} = \\min\\{190, 60, 30\\} = 30$$\n\nFinally, we compute the difference $\\Delta$:\n$$\\Delta = H_{\\text{swap}}^{\\star} - H_{\\text{kill}}^{\\star} = 13.92 - 30 = -16.08$$\n\nThe problem asks to round the final numeric value for $\\Delta$ to four significant figures. The calculated value $-16.08$ already has four significant figures ($1$, $6$, $0$, $8$), so no further rounding is necessary.",
            "answer": "$$\\boxed{-16.08}$$"
        },
        {
            "introduction": "To truly understand scheduling, one must see it in action. This comprehensive practice guides you through implementing a discrete-time simulator for a Multi-Level Feedback Queue (MLFQ), a classic scheduler that elegantly combines external and internal priorities. You will configure the scheduler to use external priority bands to determine a job's initial placement, while promotions and demotions will be governed by internal dynamics like CPU usage and waiting time. Building this simulator provides an unparalleled, hands-on understanding of how scheduling policies impact system stability and throughput over time .",
            "id": "3649868",
            "problem": "You will implement a discrete-time simulator for a single-processor multi-level feedback queue scheduler with both external and internal priorities, and use it to study stability and throughput under adversarial arrivals. The simulator must follow the fundamental definitions of a multi-level feedback queue and treat external priority as an admission policy, while internal priority emerges from run-time behavior such as accumulated waiting and consumed time quanta.\n\nDefinitions and assumptions to use as the base of your derivation and program:\n- A multi-level feedback queue (MLFQ) has $L$ distinct ready-queues, indexed by $0,1,\\dots,L-1$, where index $0$ denotes the highest priority queue. Each level $k$ has a time quantum $q_k$ in time units. The processor executes in discrete time units and selects a job from the highest non-empty queue, following First-Come First-Served within that queue.\n- External priority $P_{ext}$ is a job attribute determined at arrival that maps the job to its initial queue level. It does not change during the lifetime of the job unless promoted or demoted by internal policies.\n- Internal priority $P_{int}$ is not an explicit number maintained by the scheduler; rather, it is reflected by per-job internal state, such as its waiting time in ready-queues and its consumption of time quanta, which determines demotion and promotion.\n- Demotion occurs when a job consumes exactly its time quantum at its current level without completing; it moves to the next lower-priority level.\n- Promotion occurs via aging to prevent starvation: a job that has been waiting in a ready-queue without running for $W_{promote}$ consecutive time units is promoted one level up, unless it is already at the highest level.\n- Jobs have arrival time $a_i$, service demand $s_i$ in time units, and external band $b_i$. A job’s initial queue level is determined solely by its external band at arrival; subsequent promotions and demotions reflect internal priority dynamics.\n- Throughput is defined as $X = \\frac{C}{T_{max}}$, where $C$ is the total number of jobs completed within the simulation horizon $T_{max}$. Express $X$ in jobs per time unit as a real number.\n- Stability is assessed by the evolution of the total ready-queue backlog. Let $Q(t)$ denote the total number of jobs waiting in all ready-queues at time $t$ (excluding any job that is currently running). Declare the system stable ($S=1$) for a given test case if $\\max_{0 \\le t < T_{max}} Q(t) \\le Q_{max}$ and $Q(T_{max}-1) \\le Q_{end}$; declare unstable ($S=0$) otherwise.\n\nScheduling semantics to implement:\n- Time progresses in integer steps $t = 0,1,2,\\dots,T_{max}-1$.\n- At the beginning of each time unit, all jobs with $a_i = t$ arrive and are enqueued into their initial queue level determined by $P_{ext}$ bands.\n- At each time unit, apply promotions before running the processor: any job in a ready-queue with accumulated waiting time $\\ge W_{promote}$ is promoted by one level and its waiting time is reset to $0$.\n- Preemption policy: at the beginning of a time unit, if a job is currently running and there is any job in a higher-priority ready-queue, preempt the running job immediately and return it to the front of its current queue to preserve its remaining time slice.\n- Execution: the processor runs for one time unit per step. A running job’s remaining service demand $s_i$ and its remaining time slice are each decremented by $1$ during that time unit. If $s_i$ reaches $0$, the job completes and leaves the system; if the time slice reaches $0$ and $s_i>0$, the job is demoted one level (unless already at the lowest level), its new time slice is set to the quantum of the new level, and it is enqueued at the tail of that level.\n- Waiting time accounting: every job in a ready-queue that does not run in the current time unit increases its waiting time by $1$; a job that runs sets its waiting time to $0$.\n\nSystem parameters for all test cases:\n- Number of levels $L = 3$.\n- Time quanta vector $\\mathbf{q} = [q_0,q_1,q_2] = [1,2,4]$ time units.\n- External bands set $\\{0,1,2\\}$, where lower band indices are higher external priority, and the initial queue level equals the band index.\n- Promotion threshold $W_{promote} = 3$ time units.\n\nAdversarial arrivals and test suite:\nImplement three test cases covering a general case, a bursty adversarial case, and a boundary load case. For each case, specify $T_{max}$, the arrival times $a_i$, service demands $s_i$, bands $b_i$, and stability thresholds $Q_{max}$ and $Q_{end}$.\n\n- Test Case $1$ (general “happy path”):\n    - $T_{max} = 50$.\n    - Jobs: $10$ jobs with $(a_i,s_i,b_i)$ equal to\n      $(0,4,0)$, $(3,4,1)$, $(6,4,2)$, $(9,4,0)$, $(12,4,1)$, $(15,4,2)$, $(18,4,0)$, $(21,4,1)$, $(24,4,2)$, $(27,4,0)$.\n    - Stability thresholds: $Q_{max} = 10$, $Q_{end} = 2$.\n\n- Test Case $2$ (adversarial bursts):\n    - $T_{max} = 60$.\n    - Jobs: for $t \\in \\{0,5,10,15,20,25,30,35,40,45,50,55\\}$, $3$ jobs arrive with $(a_i,s_i,b_i) = (t,1,0)$; additionally, two low-priority long jobs arrive with $(a_i,s_i,b_i) = (0,20,2)$ and $(30,20,2)$. The total number of jobs is $36 + 2 = 38$.\n    - Stability thresholds: $Q_{max} = 25$, $Q_{end} = 5$.\n\n- Test Case $3$ (boundary load with continuous high-priority arrivals):\n    - $T_{max} = 40$.\n    - Jobs: for each $t \\in \\{0,1,2,\\dots,39\\}$, one job arrives with $(a_i,s_i,b_i) = (t,1,1)$; additionally, one low-priority long job arrives at $t=0$ with $(a_i,s_i,b_i) = (0,40,2)$. The total number of jobs is $40 + 1 = 41$.\n    - Stability thresholds: $Q_{max} = 30$, $Q_{end} = 10$.\n\nRequired outputs:\n- For each test case, compute throughput $X$ (as a floating-point number of jobs per time unit) and stability $S$ (as an integer $0$ or $1$).\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must be ordered as $[X_1,S_1,X_2,S_2,X_3,S_3]$, where subscripts denote the test case index.\n\nThere are no physical units beyond time units, so no conversion is required. All numeric results must be returned in the specified list as primitive types (floats and integers), with no additional text. Ensure your simulation is self-contained, deterministic, and adheres strictly to the scheduling semantics described above.",
            "solution": "The user-provided problem statement has been analyzed and validated. It describes a discrete-time simulation of a Multi-Level Feedback Queue (MLFQ) scheduler. All parameters, rules, and test cases are specified in a self-contained, scientifically grounded, and objective manner. The problem is well-posed and suitable for a computational solution.\n\n### Principle of Operation\n\nThe core of the solution is a discrete-time simulation that meticulously implements the specified MLFQ scheduling algorithm. The simulation progresses in time units from $t=0$ to $t=T_{max}-1$. The state of the system is maintained through a set of data structures representing the jobs, the multi-level ready queues, and the processor status.\n\n#### Data Structures\n1.  **Job**: A structure, `Job`, holds the state of each process, including its unique ID, arrival time $a_i$, total service demand $s_i$, remaining service time, current queue level $k$, time consumed in its current quantum, and accumulated waiting time.\n2.  **Ready Queues**: An array of $L=3$ queues, where each queue is implemented as a linked list to efficiently support First-Come-First-Served (FCFS) operations: adding jobs to the tail (enqueue), removing jobs from the head (dequeue), and for preempted jobs, re-inserting at the head.\n\n#### Simulation Loop per Time Unit $t$\n\nAt each time step $t$, the simulation executes the following sequence of events in a deterministic order, as specified by the problem:\n\n1.  **Arrivals**: Jobs with an arrival time $a_i=t$ are instantiated and enqueued at the tail of the ready queue corresponding to their external priority band $b_i$. Their wait time is initialized to $0$.\n\n2.  **Promotions (Aging)**: To prevent starvation, all jobs currently in the ready queues (levels $k=1, 2$) are checked. If a job's accumulated consecutive waiting time has reached the threshold $W_{promote}=3$, it is promoted. This involves moving it from its current queue $k$ to the tail of the next higher-priority queue, $k-1$. Its waiting time is reset to $0$. This process is performed by iterating from the lowest-priority queue upwards to ensure promotions are handled consistently within the same time step.\n\n3.  **Preemption and Job Selection**:\n    a. The scheduler first identifies the highest-priority non-empty ready queue. The job at the head of this queue is the candidate to run next.\n    b. If a job was already running from the previous time step, its priority level is compared to that of the new candidate. If the candidate is in a strictly higher-priority queue (a smaller queue index $k$), the currently running job is preempted.\n    c. A preempted job is returned to the *front* of its original ready queue to ensure it runs again before any other job at its level. The processor is then considered idle for the purpose of selecting a new job.\n    d. If the processor is idle (either initially, after a job completion, or after a preemption), the candidate from the highest-priority non-empty queue is dequeued and becomes the new `running_job`. Its time-in-quantum counter is reset.\n\n4.  **Wait Time Update and Statistics**: For all jobs that remain in any ready queue (i.e., those not selected to run), their waiting time counter is incremented by $1$. The total number of jobs in all ready queues, $Q(t)$, is recorded after job selection to update the `max_q_len` and, at the final step, to set `final_q_len`.\n\n5.  **Execution**:\n    a. If a job is running, its remaining service demand and its time-in-quantum-used counter are both decremented by $1$. Its waiting time is reset to $0$.\n    b. **Completion**: If a job's remaining service becomes $0$, it is marked as completed. The total count of completed jobs, $C$, is incremented, and the processor becomes idle.\n    c. **Demotion**: If the job does not complete but has exhausted its time quantum for its current level (i.e., `time_in_quantum_used` == $q_k$), it is demoted. It is moved to the tail of the next lower-priority queue (or the same queue if already at the lowest level, $L-1$). The processor becomes idle.\n\n#### Final Metrics\nAfter the simulation completes at $t=T_{max}-1$, the final metrics are calculated for each test case:\n- **Throughput ($X$)**: $X = C / T_{max}$.\n- **Stability ($S$)**: The system is stable ($S=1$) if the maximum observed queue length $\\max_{0 \\le t < T_{max}} Q(t)$ does not exceed the threshold $Q_{max}$ AND the final queue length $Q(T_{max}-1)$ does not exceed $Q_{end}$. Otherwise, it is unstable ($S=0$).\n\nThis rigorous, step-by-step implementation ensures that all the specified semantics, including the interplay between external priority at arrival and internal priority dynamics (aging, quantum consumption), are correctly modeled to derive the required performance metrics.",
            "answer": "```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\n#define L 3\n#define W_PROMOTE 3\n\n// System parameters as defined in the problem\nconst int QUANTA[L] = {1, 2, 4};\n\n// Structure to represent a job\ntypedef struct {\n    int id;\n    int arrival_time;\n    int service_demand;\n    int remaining_service;\n    int band;\n\n    // Dynamic state\n    int current_level;\n    int time_in_quantum_used;\n    int wait_time;\n} Job;\n\n// Node for the queue linked list\ntypedef struct Node {\n    Job* job;\n    struct Node* next;\n} Node;\n\n// Queue structure\ntypedef struct {\n    Node* head;\n    Node* tail;\n    int size;\n} Queue;\n\n// --- Queue Helper Functions ---\n\nvoid init_queue(Queue* q) {\n    q->head = NULL;\n    q->tail = NULL;\n    q->size = 0;\n}\n\nvoid enqueue_tail(Queue* q, Job* job) {\n    Node* new_node = (Node*)malloc(sizeof(Node));\n    if (!new_node) {\n        perror(\"Failed to allocate memory for queue node\");\n        exit(EXIT_FAILURE);\n    }\n    new_node->job = job;\n    new_node->next = NULL;\n    if (q->tail) {\n        q->tail->next = new_node;\n    } else {\n        q->head = new_node;\n    }\n    q->tail = new_node;\n    q->size++;\n}\n\nvoid enqueue_head(Queue* q, Job* job) {\n    Node* new_node = (Node*)malloc(sizeof(Node));\n    if (!new_node) {\n        perror(\"Failed to allocate memory for queue node\");\n        exit(EXIT_FAILURE);\n    }\n    new_node->job = job;\n    new_node->next = q->head;\n    q->head = new_node;\n    if (!q->tail) {\n        q->tail = new_node;\n    }\n    q->size++;\n}\n\nJob* dequeue_head(Queue* q) {\n    if (!q->head) {\n        return NULL;\n    }\n    Node* old_head = q->head;\n    Job* job = old_head->job;\n    q->head = old_head->next;\n    if (!q->head) {\n        q->tail = NULL;\n    }\n    q->size--;\n    free(old_head);\n    return job;\n}\n\n// --- Simulation Logic ---\n\ntypedef struct {\n    double X;\n    int S;\n} SimResult;\n\ntypedef struct {\n    int T_max;\n    int Q_max;\n    int Q_end;\n    Job* job_defs;\n    int num_jobs;\n} TestCase;\n\nSimResult run_simulation(TestCase tc) {\n    Queue ready_queues[L];\n    for (int i = 0; i < L; ++i) {\n        init_queue(&ready_queues[i]);\n    }\n\n    Job* all_jobs = (Job*)malloc(tc.num_jobs * sizeof(Job));\n    if(!all_jobs) {\n        perror(\"Failed to allocate all_jobs\");\n        exit(EXIT_FAILURE);\n    }\n    memcpy(all_jobs, tc.job_defs, tc.num_jobs * sizeof(Job));\n\n    Job* running_job = NULL;\n    int completed_jobs_count = 0;\n    int max_q_len = 0;\n    int final_q_len = 0;\n\n    for (int t = 0; t < tc.T_max; ++t) {\n        // 1. Handle Arrivals\n        for (int i = 0; i < tc.num_jobs; ++i) {\n            if (all_jobs[i].arrival_time == t) {\n                Job* new_job = &all_jobs[i];\n                new_job->current_level = new_job->band;\n                new_job->wait_time = 0;\n                new_job->time_in_quantum_used = 0;\n                enqueue_tail(&ready_queues[new_job->current_level], new_job);\n            }\n        }\n\n        // 2. Handle Promotions (Aging)\n        for (int k = L - 1; k > 0; --k) {\n            Node* current = ready_queues[k].head;\n            Node* prev = NULL;\n            while (current != NULL) {\n                Node* next = current->next;\n                if (current->job->wait_time >= W_PROMOTE) {\n                    Job* promoted_job = current->job;\n                    \n                    if (prev) {\n                        prev->next = next;\n                    } else {\n                        ready_queues[k].head = next;\n                    }\n                    if (current == ready_queues[k].tail) {\n                        ready_queues[k].tail = prev;\n                    }\n                    ready_queues[k].size--;\n                    free(current);\n                    \n                    promoted_job->current_level = k - 1;\n                    promoted_job->wait_time = 0;\n                    enqueue_tail(&ready_queues[k - 1], promoted_job);\n                } else {\n                    prev = current;\n                }\n                current = next;\n            }\n        }\n\n        // 3. Preemption Check\n        int best_waiter_level = -1;\n        for (int k = 0; k < L; ++k) {\n            if (ready_queues[k].size > 0) {\n                best_waiter_level = k;\n                break;\n            }\n        }\n\n        if (running_job != NULL) {\n            if (best_waiter_level != -1 && best_waiter_level < running_job->current_level) {\n                // Preempt\n                enqueue_head(&ready_queues[running_job->current_level], running_job);\n                running_job = NULL;\n            }\n        }\n        \n        // 4. Select Job to Run\n        if (running_job == NULL) {\n            for (int k = 0; k < L; ++k) {\n                if (ready_queues[k].size > 0) {\n                    running_job = dequeue_head(&ready_queues[k]);\n                    running_job->time_in_quantum_used = 0; // Reset for new slice\n                    break;\n                }\n            }\n        }\n\n        // 5. Update Wait Times & Collect Queue Stats\n        int current_q_len = 0;\n        for (int k = 0; k < L; ++k) {\n            current_q_len += ready_queues[k].size;\n            Node* n = ready_queues[k].head;\n            while(n != NULL) {\n                n->job->wait_time++;\n                n = n->next;\n            }\n        }\n        if (current_q_len > max_q_len) {\n            max_q_len = current_q_len;\n        }\n        if (t == tc.T_max - 1) {\n            final_q_len = current_q_len;\n        }\n\n        // 6. Execute one time step\n        if (running_job != NULL) {\n            running_job->wait_time = 0;\n            running_job->remaining_service--;\n            running_job->time_in_quantum_used++;\n\n            if (running_job->remaining_service == 0) {\n                completed_jobs_count++;\n                running_job = NULL; \n            } else if (running_job->time_in_quantum_used == QUANTA[running_job->current_level]) {\n                int next_level = (running_job->current_level < L - 1) ? (running_job->current_level + 1) : (L - 1);\n                running_job->current_level = next_level;\n                enqueue_tail(&ready_queues[next_level], running_job);\n                running_job = NULL;\n            }\n        }\n    }\n\n    // Clean up any remaining jobs in queues\n    for (int k = 0; k < L; ++k) {\n        while (ready_queues[k].size > 0) {\n            dequeue_head(&ready_queues[k]);\n        }\n    }\n    free(all_jobs);\n\n    SimResult result;\n    result.X = (double)completed_jobs_count / tc.T_max;\n    result.S = (max_q_len <= tc.Q_max && final_q_len <= tc.Q_end) ? 1 : 0;\n    \n    return result;\n}\n\nint main(void) {\n    // Test Case 1 jobs: 10 jobs, regular arrivals\n    Job jobs1[] = {\n        {1, 0, 4, 4, 0}, {2, 3, 4, 4, 1}, {3, 6, 4, 4, 2}, {4, 9, 4, 4, 0}, {5, 12, 4, 4, 1},\n        {6, 15, 4, 4, 2}, {7, 18, 4, 4, 0}, {8, 21, 4, 4, 1}, {9, 24, 4, 4, 2}, {10, 27, 4, 4, 0}\n    };\n\n    // Test Case 2 jobs: 36 bursty jobs + 2 long jobs\n    Job jobs2[38];\n    int job_idx = 0;\n    for (int t = 0; t <= 55; t += 5) {\n        for (int i = 0; i < 3; ++i) {\n            jobs2[job_idx] = (Job){job_idx + 1, t, 1, 1, 0};\n            job_idx++;\n        }\n    }\n    jobs2[job_idx] = (Job){job_idx + 1, 0, 20, 20, 2}; job_idx++;\n    jobs2[job_idx] = (Job){job_idx + 1, 30, 20, 20, 2}; job_idx++;\n\n    // Test Case 3 jobs: 40 continuous jobs + 1 long job\n    Job jobs3[41];\n    job_idx = 0;\n    for (int t = 0; t < 40; ++t) {\n        jobs3[job_idx] = (Job){job_idx + 1, t, 1, 1, 1};\n        job_idx++;\n    }\n    jobs3[job_idx] = (Job){job_idx + 1, 0, 40, 40, 2}; job_idx++;\n    \n    TestCase test_cases[] = {\n        {50, 10, 2, jobs1, sizeof(jobs1) / sizeof(jobs1[0])},\n        {60, 25, 5, jobs2, sizeof(jobs2) / sizeof(jobs2[0])},\n        {40, 30, 10, jobs3, sizeof(jobs3) / sizeof(jobs3[0])}\n    };\n\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    SimResult results[num_cases];\n\n    for (int i = 0; i < num_cases; ++i) {\n        results[i] = run_simulation(test_cases[i]);\n    }\n\n    printf(\"[%.6f,%d,%.6f,%d,%.6f,%d]\\n\",\n           results[0].X, results[0].S,\n           results[1].X, results[1].S,\n           results[2].X, results[2].S);\n\n    return EXIT_SUCCESS;\n}\n```"
        }
    ]
}