## 引言
在现代计算中，为每个程序提供一个私有的、看似无限的内存空间，是[操作系统](@entry_id:752937)实现效率与隔离的关键。然而，物理内存是有限的，如何在有限的资源上构建这一宏伟的虚拟抽象？答案的核心便是**请求调页（Demand Paging）**——一种精妙的“惰性”策略，它彻底改变了[操作系统](@entry_id:752937)的内存管理方式。相较于在程序启动时就加载所有代码和数据的“预先加载”策略，请求调页仅在程序的某个部分被实际访问时，才将其从磁盘加载到内存。这种“即用即付”的哲学不仅能戏剧性地缩短程序启动时间，更是让运行远超物理内存大小的应用程序成为可能。

本文旨在全面而深入地剖析请求调页机制。我们将从其根本动机和性能优势出发，揭示其背后的工作原理。读者将跟随本文的脚步，穿越三个核心章节，构建一个从理论到实践的完整知识体系：

*   在**第一章：原理与机制**中，我们将解构一个“页面错误”从发生到处理完毕的完整生命周期，探讨决定系统性能的[有效访问时间](@entry_id:748802)，并深入比较FIFO、LRU、Clock等经典页面替换算法的设计与优劣。
*   在**第二章：应用与跨学科连接**中，我们将视野扩展到[操作系统](@entry_id:752937)之外，探索请求调页如何支撑起[写时复制](@entry_id:636568)（Copy-on-Write）、[内存映射](@entry_id:175224)文件等关键技术，并分析其与数据库、[垃圾回收](@entry_id:637325)、NUMA硬件乃至机器学习等领域的深刻交互。
*   最后，在**第三章：动手实践**中，您将通过解决具体问题来巩固所学知识，亲手计算性能指标，模拟算法行为，并应用理论来优化实际代码，从而将抽象概念转化为切实的工程能力。

现在，让我们首先深入其核心，探究请求调页的底层原理与精妙机制。

## 原理与机制

在上一章中，我们介绍了[虚拟内存](@entry_id:177532)的基本概念，即为每个进程提供一个私有的、连续的、巨大的地址空间。现在，我们将深入探讨实现这一抽象的关键技术——**请求调页（Demand Paging）**。请求调页是一种惰性加载策略：系统只在真正需要时（即访问时）才将程序的页面从二级存储加载到物理内存中。这种方法是现代[操作系统内存管理](@entry_id:752942)的核心，它不仅能显著加快程序启动速度，还能支持比物理内存更大的地址空间。

### 请求调页的核心动机与性能优势

为什么不直接在程序启动时将整个程序加载到内存中呢？这种“预先加载”（Eager Loading）的策略看起来简单直接，但在许多现实场景中效率低下。核心原因在于**局部性原理（Principle of Locality）**，它包含两个方面：**[时间局部性](@entry_id:755846)**（最近访问过的内存位置很可能在不久的将来再次被访问）和**空间局部性**（如果一个内存位置被访问，其附近的内存位置也很可能在不久的将来被访问）。

程序在执行的任何给定阶段，通常只会访问其地址空间的一小部分，即所谓的**工作集（Working Set）**。例如，处理用户输入的代码、错误处理例程或不常用的功能，在程序的大部分运行时间内可能都不会被触及。请求调页正是利用了这一特性。

我们可以通过一个量化模型来理解其性能优势。假设一个存储设备的读操作性能由两个参数决定：每次操作的固定延迟$L$（如[寻道时间](@entry_id:754621)和[旋转延迟](@entry_id:754428)）和持续的[数据传输](@entry_id:276754)[吞吐量](@entry_id:271802)$B$。读取大小为$S$的数据块所需的时间可以建模为$T_{IO} = L + \frac{S}{B}$。

现在，考虑一个大小为$X$兆字节的应用程序。
*   **预先加载策略**：[操作系统](@entry_id:752937)在程序启动前，通过一次连续的大规模读操作将整个应用程序加载到内存。总的I/O时间为$T_{eager} = L + \frac{X}{B}$。
*   **请求调页策略**：[操作系统](@entry_id:752937)在启动时只建立[内存映射](@entry_id:175224)，而不实际加载任何页面。假设在启动后的第一秒内，程序只访问了$t$个不同的页面，每个页面的大小为$p$兆字节。由于每次页面访问都是独立的，并且假设它们都会导致缺页（在冷启动时），系统需要执行$t$次独立的读操作。总的I/O时间为$T_{demand} = t \times (L + \frac{p}{B})$。

启动时间改善因子$R$可以定义为两种策略的I/O时间之比：
$$ R = \frac{T_{eager}}{T_{demand}} = \frac{L + \frac{X}{B}}{t \left( L + \frac{p}{B} \right)} = \frac{LB + X}{t(LB + p)} $$

这个公式清晰地表明，当初始访问的页面数$t$远小于总页面数($X/p$)时，$R$的值会远大于1，意味着请求调页能带来显著的启动性能提升。例如，一个大型应用程序可能包含数千个页面，但在启动时仅需加载几十个页面来显示主界面和初始化核心服务。请求调页将加载其余页面的成本分摊到了程序的整个生命周期中，仅在需要时才产生开销。

### 页面错误处理：一个完整的生命周期

请求调页的“魔法”是通过一个名为**页面错误（Page Fault）**或**缺页中断**的硬件异常机制实现的。当一个进程试图访问一个在逻辑上属于它，但当前尚未被加载到物理内存的页面时，就会发生页面错误。这并非一个真正的“错误”，而是一个通知[操作系统](@entry_id:752937)介入的信号。让我们通过一个典型的场景，详细剖析从CPU发出访问请求到该请求最终成功完成的全过程。

假设一个32位系统，页面大小为$4$ KiB ($0x1000$ 字节)，CPU尝试从虚拟地址$0x00403ABC$读取数据。

1.  **CPU与MMU**：CPU将虚拟地址$0x00403ABC$发送给**[内存管理单元](@entry_id:751868)（MMU）**。MMU负责将虚拟地址翻译成物理地址。它首先将该地址拆分为两部分：高位的**虚拟页号（Virtual Page Number, VPN）**和低位的**页内偏移（Page Offset）**。对于32位地址和4 KiB页面，低12位是偏移量，高20位是VPN。因此，$VPN = 0x00403$，$Offset = 0xABC$。

2.  **TLB查询**：MMU首先查询其高速缓存——**转译后备缓冲区（Translation Lookaside Buffer, TLB）**。TLB存储了最近使用过的VPN到**物理帧号（Physical Frame Number, PFN）**的映射。在这个场景中，我们假设TLB是空的，因此发生**TLB未命中（TLB Miss）**。

3.  **[页表遍历](@entry_id:753086)与页面错误**：TLB未命中后，硬件（或在某些架构中是软件）会自动遍历位于主存中的**[页表](@entry_id:753080)（Page Table）**。MMU使用VPN $0x00403$ 作为索引，在[页表](@entry_id:753080)中找到对应的**[页表项](@entry_id:753081)（Page Table Entry, [PTE](@entry_id:753081)）**。此时，MMU检查PTE中的一个关键比特——**存在/有效位（Present/Valid Bit）**。由于该页面尚未被加载，此位为$0$。当MMU发现存在位为$0$时，它无法完成地址翻译，于是触发一个硬件异常，即**页面错误**，并将控制权转移给操作系统内核。

4.  **[操作系统](@entry_id:752937)页面错误处理程序**：内核的页面错误处理程序接管控制。
    *   **合法性验证**：[操作系统](@entry_id:752937)首先检查这次访问是否合法。它会查看[PTE](@entry_id:753081)中的**保护位（Protection Bits）**（如读、写、执行权限），并与引发错误的访问类型（本例中是读操作）进行比较。如果访问违反了权限（例如，试图写入一个只读页面），[操作系统](@entry_id:752937)将终止该进程，并报告一个“[段错误](@entry_id:754628)（Segmentation Fault）”。在这个例子中，[PTE](@entry_id:753081)允许读操作，因此这是一个合法的页面错误。
    *   **帧分配**：[操作系统](@entry_id:752937)需要在物理内存中找到一个空闲的物理帧来存放即将加载的页面。假设它找到了一个空闲帧，其PFN为$0x000001A2$。如果没有空闲帧，[操作系统](@entry_id:752937)必须运行**页面替换算法**来选择一个“牺牲”帧（我们稍后会详细讨论）。
    *   **磁盘I/O**：[操作系统](@entry_id:752937)根据[PTE](@entry_id:753081)中记录的页面在**后备存储（Backing Store）**（如磁盘上的交换文件或可执行文件）上的位置，调度一次磁盘读操作，将页面内容加载到刚刚分配的物理帧$0x000001A2$中。这是一个耗时操作，在此期间，引发错误的进程通常会被置于**阻塞状态**，[操作系统](@entry_id:752937)会调度其他就绪进程运行。
    *   **[页表](@entry_id:753080)更新**：当磁盘I/O完成后，磁盘控制器会产生一个中断，通知[操作系统](@entry_id:752937)数据已准备好。[操作系统内核](@entry_id:752950)再次被激活，并更新导致错误的PTE：
        *   将**存在位**设置为$1$。
        *   将**PFN字段**设置为$0x000001A2$。
        *   **保护位**保持不变。
        *   **[脏位](@entry_id:748480)（Dirty Bit）**保持为$0$。该位用于标记页面在内存中是否被修改过。从磁盘加载页面时，内存中的副本与磁盘上的完全一致，因此是“干净”的。
        *   **访问位（Accessed/Reference Bit）**此时通常不会被[操作系统](@entry_id:752937)修改。

5.  **指令重试与成功访问**：[操作系统](@entry_id:752937)执行一条特殊的“从中断返回”指令，将控制权交还给用户进程。[程序计数器](@entry_id:753801)被恢复到导致错误的指令处，因此该指令会被**重新执行**。
    *   CPU再次发出对虚拟地址$0x00403ABC$的读请求。
    *   MMU再次进行地址翻译。此时可能会再次发生TLB未命中。
    *   硬件再次遍历[页表](@entry_id:753080)，但这次它发现PTE的存在位是$1$，并且PFN字段为$0x000001A2$。翻译成功！
    *   MMU计算出物理地址：$PA = (PFN \ll 12) + Offset = (0x000001A2 \ll 12) + 0xABC = 0x001A2ABC$。
    *   在允许内存访问的同时，硬件（MMU）会自动将[PTE](@entry_id:753081)中的**访问位**设置为$1$，以记录该页面已被访问。
    *   CPU从物理地址$0x001A2ABC$成功读取数据。硬件还会将这个新的翻译（$VPN=0x00403 \rightarrow PFN=0x000001A2$）缓存到TLB中，以加速未来的访问。

至此，一个完整的页面错误处理周期结束，进程仿佛什么都没发生一样继续执行。这个复杂的、由硬件和软件协同完成的过程，对应用程序是完全透明的。

### 性能分析：[有效访问时间](@entry_id:748802)

请求调页虽然功能强大，但其性能代价是高昂的。一次页面错误可能比一次正常的内存访问慢上百万倍（纳秒 vs. 毫秒）。因此，系统的整体性能极度依赖于页面错误的发生频率。我们可以使用**[有效访问时间](@entry_id:748802)（Effective Access Time, EAT）**来量化这一性能。

EAT是单次内存访问的期望时间。设$p$为**[缺页率](@entry_id:753068)（Page-fault Rate）**，即每次内存访问导致页面错误的概率。设$t_m$为一次内存命中的时间（即页面在物理内存中），$t_{fault}$为一次页面错误的服务时间。最简单的EAT模型是：
$$ EAT = (1 - p) \cdot t_m + p \cdot t_{fault} $$
由于$t_{fault} \gg t_m$，即使$p$很小，其对EAT的影响也可能非常显著。

为了得到更精确的模型，我们必须考虑TLB的影响。一次内存访问的完[整流](@entry_id:197363)程有三种可能的结果 ：

1.  **TLB命中**：这是最理想的情况。地址翻译瞬间完成，只需一次内存访问来获取数据。时间成本为$m$（假设TLB查找时间可忽略）。
2.  **TLB未命中，但页面在内存中**：MMU必须访问页表（第一次内存访问）来获取[PTE](@entry_id:753081)，然后才能访问目标数据（第二次内存访问）。时间成本为$2m$。
3.  **页面错误**：无论是否命中TLB，[PTE](@entry_id:753081)的存在位都为0。这会导致一次服务时间为$s$的[缺页中断](@entry_id:753072)。服务完成后，指令重试。由于[操作系统](@entry_id:752937)在加载页面后通常会更新TLB或确保[PTE](@entry_id:753081)是最新的，重试的访问可以视为一次TLB命中，额外花费时间$m$。总时间成本为$s + m$。

设$h$为在**没有发生页面错误**的情况下TLB的命中率，$p$仍然是总的[缺页率](@entry_id:753068)。我们可以构建一个更精确的EAT公式：
$$ EAT = p \cdot (s + m) + (1 - p) \cdot [\text{非缺页访问的期望时间}] $$
对于非缺页访问（概率为$1-p$），其时间取决于TLB是命中还是未命中：
$$ \text{非缺页访问的期望时间} = h \cdot m + (1 - h) \cdot (2m) = m(2 - h) $$
将此代入EAT公式，我们得到：
$$ EAT = p(s + m) + (1-p)m(2-h) $$
这个公式是理解虚拟内存性能的基石。它告诉我们，要获得良好的性能，必须同时努力实现极低的[缺页率](@entry_id:753068)$p$和极高的TLB命中率$h$。

### 策略选择 I：页面替换算法

当发生页面错误且没有空闲物理帧时，[操作系统](@entry_id:752937)必须选择一个当前驻留在内存中的页面进行**驱逐（Evict）**，以便为新页面腾出空间。选择哪个页面被驱逐的策略，就是**页面替换算法（Page Replacement Algorithm）**。一个好的算法应该驱逐将来最不可能被访问的页面，从而最小化未来的页面错误次数。

#### 理论最优与现实的差距

理论上存在一个完美的算法，称为**Belady[最优算法](@entry_id:752993)（OPT或MIN）**。它的策略是：驱逐在未来最长时间内不会被访问的页面。这个算法无法在真实系统中实现，因为它需要预知未来。然而，它可以作为评估其他实用算法性能的黄金标准或基准。通过在相同的页面引用序列上比较一个实用算法（如LRU）和一个[最优算法](@entry_id:752993)（OPT）的[缺页](@entry_id:753072)次数，我们可以量化该实用算法的性能差距 。

#### 经典算法与[Belady异常](@entry_id:746751)

*   **先进先出（First-In, First-Out, FIFO）**：这是最简单的替换算法。它维护一个所有驻留页面的队列，每次都驱逐最早进入内存的页面。FIFO实现简单，但性能通常不佳，因为它可能会驱逐一个仍然被频繁使用的“老”页面。
    更糟糕的是，FIFO算法存在一种反直觉的现象，称为**[Belady异常](@entry_id:746751)（Belady's Anomaly）**：在某些页面引用序列下，为进程分配更多的物理帧反而会导致更多的页面错误。
    例如，对于引用序列$\langle 0, 1, 2, 3, 0, 1, 4, 0, 1, 2, 3, 4 \rangle$，使用3个帧会产生9次[缺页](@entry_id:753072)，而使用4个帧反而会产生10次缺页 。这种现象的存在使得FIFO在现代[操作系统](@entry_id:752937)中很少被直接使用。

*   **[最近最少使用](@entry_id:751225)（Least Recently Used, LRU）**：[LRU算法](@entry_id:751540)基于局部性原理，认为如果一个页面在过去很长一段时间内都未被使用，那么它在将来也很可能不会被使用。因此，LRU驱逐最长时间未被访问的页面。LRU的性能通常远好于FIFO，并且非常接近OPT。
    至关重要的是，[LRU算法](@entry_id:751540)**不受[Belady异常](@entry_id:746751)的影响**。这是因为它具有**栈属性（Stack Property）**。一个具有栈属性的算法保证，对于任何引用序列，在拥有$k$个帧时内存中的页面集合，总是拥有$k+1$个帧时内存中页面集合的一个[子集](@entry_id:261956)。这意味着，在$k$个帧时发生的任何一次命中，在$k+1$个帧时也必然会命中。因此，增加帧数绝不会增加缺页次数。

#### LRU的实用近似：Clock算法

纯粹的[LRU算法](@entry_id:751540)实现起来代价高昂，因为它需要在每次内存访问时记录访问时间或更新一个[链表](@entry_id:635687)。因此，大多数[操作系统](@entry_id:752937)采用一种称为**Clock算法**（或**[二次机会算法](@entry_id:754595)**）的[LRU近似算法](@entry_id:751541)。

Clock算法将所有物理帧组织成一个[环形缓冲区](@entry_id:634142)，并用一个“指针”或“时钟指针”指向其中一个帧。每个帧都与一个**访问位（Reference Bit）**相关联（这通常就是[PTE](@entry_id:753081)中的访问位）。当需要替换页面时，算法从指针当前位置开始扫描：
1.  如果当前帧的访问位为$1$，说明该页面最近被使用过。算法会给它“第二次机会”，将其访问位清零，然后将指针移动到下一个帧。
2.  如果当前帧的访问位为$0$，说明该页面在最近一轮扫描中未被使用。算法选择这个帧作为牺牲品，将其驱逐。

这个过程有效地模拟了LRU：一个频繁被访问的页面会不断地将其访问位设置为1，从而在时钟指针扫过时幸存下来；而一个长时间未被访问的页面，其访问位最终会被清零，并在下一轮扫描中成为被驱逐的候选者。

此外，Clock算法还可以与**[脏位](@entry_id:748480)（Dirty Bit）**结合，以降低驱逐成本。驱逐一个“干净”的页面（[脏位](@entry_id:748480)为0）的成本很低，因为其内存副本与后备存储中的副本一致，可以直接丢弃。但驱逐一个“脏”的页面（[脏位](@entry_id:748480)为1）则必须先将其内容**写回（Write-back）**到磁盘，这会产生额外的I/O开销。增强的Clock算法在寻找牺牲品时，会优先选择访问位为0且[脏位](@entry_id:748480)为0的“干净”页面，其次才是访问位为0但[脏位](@entry_id:748480)为1的“脏”页面。这可以通过多轮扫描或更复杂的位组合来实现。

通过模拟Clock算法，我们可以精确计算在给定引用序列下的**页面调入（Page-ins）**、**页面调出（Page-outs）**和**[写回](@entry_id:756770)（Write-backs）**的次数，从而深入理解其运作机制 。

### 策略选择 II：系统级调优与约束

除了选择核心的替换算法，[操作系统](@entry_id:752937)还必须在更宏观的层面进行策略设计和调优，以应对复杂的现实世界负载和硬件约束。

#### 页面大小的选择

页面大小是[虚拟内存](@entry_id:177532)系统的一个基本设计参数，它深刻影响着系统性能，并且需要在多个相互冲突的因素之间进行权衡 ：

*   **[内部碎片](@entry_id:637905)（Internal Fragmentation）**：内存按页分配。如果一个程序只使用了页面的一小部分，剩余部分就被浪费了，这就是[内部碎片](@entry_id:637905)。页面越大，潜在的浪费就越多。对于空间局部性差的负载（如稀疏的随机访问），小页面更优，因为它们可以最小化为获取少量数据而加载的无用数据量。

*   **[页表](@entry_id:753080)大小**：页面越小，要覆盖相同的地址空间就需要越多的页面，从而导致页表变得非常庞大，占用更多内存。

*   **I/O效率**：对于具有良好空间局部性的负载（如顺序文件扫描或大型矩阵计算），[大页面](@entry_id:750413)更有效。由于磁盘I/O的延迟开销（$L$）是固定的，通过单次I/O传输更多的数据（更大的页面），可以摊薄每次I/O的延迟成本，提高整体I/O吞吐量。

*   **TLB覆盖范围（TLB Reach）**：TLB的条目数是有限的。TLB覆盖范围定义为“TLB条目数 $\times$ 页面大小”，表示TLB能够一次性映射的总内存大小。对于[工作集](@entry_id:756753)很大且访问模式随机的负载，如果[工作集](@entry_id:756753)能够完全被TLB覆盖，那么地址翻译的开销将大大降低。在这种情况下，[大页面](@entry_id:750413)（甚至是“[巨页](@entry_id:750413)”，如2 MiB或1 GiB）能显著增加TLB覆盖范围，从而提升性能。

因此，没有“一刀切”的最佳页面大小。
*   对于**顺序扫描**负载（Workload S），性能瓶颈在于总I/O时间，[大页面](@entry_id:750413)（如 **2 MiB**）通过减少I/O操作次数来最小化总延迟成本，是最佳选择。
*   对于**稀疏随机采样**负载（Workload R），性能瓶颈在于[内部碎片](@entry_id:637905)和单次缺页的高昂代价，小页面（如 **4 KiB**）通过减少数据浪费和单次[缺页](@entry_id:753072)的传输时间，是最佳选择。
*   对于**热点集随机访问**负载（Workload H），当热点集可以放入内存后，性能瓶颈转为地址翻译效率。此时，能够使TLB覆盖整个热点集的[大页面](@entry_id:750413)（如 **2 MiB**）是最佳选择。

#### [抖动](@entry_id:200248)：性能的悬崖

当系统分配给一个或多个进程的物理帧数不足以容纳其[工作集](@entry_id:756753)时，就会发生一种灾难性的性能崩溃，称为**[抖动](@entry_id:200248)（Thrashing）**。进程会不断地发生页面错误，换入一个页面后，很快又需要另一个刚刚被换出的页面。系统的大部分时间都花在了磁盘I/O上，而不是执行有用的计算，导致[CPU利用率](@entry_id:748026)急剧下降，系统[吞吐量](@entry_id:271802)趋近于零。

为了防止和控制[抖动](@entry_id:200248)，[操作系统](@entry_id:752937)需要一种机制来监控每个进程的内存行为，并动态调整其帧分配。一种有效的方法是**[缺页率](@entry_id:753068)监控（Page Fault Frequency, PFF）**。
[操作系统](@entry_id:752937)可以为每个进程设定一个[缺页率](@entry_id:753068)的上限（$f_{upper}$）和下限（$f_{lower}$）。
*   如果一个进程的[缺页率](@entry_id:753068)超过了$f_{upper}$，说明它可能需要更多的帧。[操作系统](@entry_id:752937)会尝试为其分配更多的物理帧。
*   如果一个进程的[缺页率](@entry_id:753068)低于$f_{lower}$，说明它拥有的帧可能超出了其实际需要。[操作系统](@entry_id:752937)可以从该进程回收一些帧，分配给其他更需要的进程。

通过将可接受的EAT范围（例如，$\[E_{min}, E_{max}\]$）转换成对应的PFF阈值（$[f_{lower}, f_{upper}]$），并根据进程[缺页率](@entry_id:753068)对帧数分配的局部敏感性（$\frac{df}{dF}$），[操作系统](@entry_id:752937)可以计算出需要增加或减少的帧数，从而将进程的性能维持在目标区间内，避免[抖动](@entry_id:200248)的发生 。

#### 高级驱逐策略与现实约束

*   **异构页面的处理**：在现代系统中，并非所有页面都生而平等。一个关键的区别在于**匿名页面（Anonymous Pages）**和**文件后备页面（File-backed Pages）**。匿名页面是进程的堆、栈等没有静态文件作为后备存储的内存区域，它们的唯一后备是[交换空间](@entry_id:755701)。文件后备页面则对应于[内存映射](@entry_id:175224)文件。
    在驱逐决策中，这种区别至关重要。驱逐一个干净的文件后备页面几乎没有成本，因为它总能从原始文件中重新读回。而驱逐一个匿名页面（总是被视为脏页）则必须将其写入[交换空间](@entry_id:755701)，成本高昂。更重要的是，不同类型页面的重引用概率也不同。通过计算每种驱逐决策的**期望总成本**（立即I/O成本 + 未来[缺页](@entry_id:753072)的期望成本），[操作系统](@entry_id:752937)可以制定更智能的策略。通常，优先驱逐干净的文件后备页面是成本最低的选择 。
    为了配合这种策略，[操作系统](@entry_id:752937)还会采用**后台写回（Background Writeback）**和**[写回](@entry_id:756770)限流（Writeback Throttling）**机制。当系统中脏页比例达到某个阈值（如5%）时，[内核线程](@entry_id:751009)会开始在后台将脏页[写回](@entry_id:756770)磁盘，将其“清洗”干净，以便未来可以低成本地驱逐。当脏页比例接近一个更高的硬限制（如10%）时，系统甚至会减慢或阻塞产生脏页的进程，以防止I/O系统被淹没，从而维持系统的稳定性。

*   **固定页面（Pinned Pages）**：最后，并非所有物理帧都可用于页面替换。某些页面必须被**固定（Pin）**在物理内存中，绝不能被换出。这主要出于两个原因：
    1.  **直接内存访问（Direct Memory Access, DMA）**：像网卡、磁盘控制器这样的I/O设备可以直接读写物理内存，而无需CPU介入。DMA操作的是物理地址，如果[操作系统](@entry_id:752937)在其操作期间移动或换出了DMA缓冲区对应的页面，将会导致[数据损坏](@entry_id:269966)或系统崩溃。因此，用于DMA的页面必须被固定。
    2.  **`mlock`系统调用**：实时应用程序或对延迟敏感的关键应用，可以通过`mlock()`系统调用请求[操作系统](@entry_id:752937)将其部分或全部地址空间锁定在内存中，以避免因页面错误引起不可预测的延迟。
    固定的页面（包括内核自身占用的页面）有效地减少了可用于请求调页的物理帧池。当一个系统中有大量页面被固定时，留给其他普通进程的可用内存会减少，导致内存压力增大，[缺页率](@entry_id:753068)上升，从而影响整体系统性能。在进行容量规划和性能分析时，必须将这部分不可回收的内存考虑在内 。

总之，请求调页是一个复杂而精妙的系统，它通过硬件与软件的紧密协作，在性能、资源利用和功能之间取得了微妙的平衡。理解其核心机制、性能权衡以及各种策略选择，是掌握现代[操作系统](@entry_id:752937)设计的关键一步。