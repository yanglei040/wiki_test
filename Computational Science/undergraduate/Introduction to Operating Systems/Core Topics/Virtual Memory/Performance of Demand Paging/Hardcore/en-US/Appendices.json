{
    "hands_on_practices": [
        {
            "introduction": "The performance of a demand-paged system is fundamentally tied to the time it takes to service a page fault. This exercise provides a practical look at how the choice of backing store—a Solid-State Drive (SSD) versus a traditional Hard Disk Drive (HDD)—impacts the Effective Access Time ($EAT$). By modeling the components of page fault service time, you will quantify the dramatic performance difference and gain insight into why the low, predictable latency of SSDs is crucial for modern systems. ",
            "id": "3668900",
            "problem": "A process uses demand paging with a single-level page table on a workstation whose main memory access time is $t_{m} = 0.1 \\,\\mu \\text{s}$. On each memory reference, a page fault occurs with probability $p = 2 \\times 10^{-4}$. When a page fault occurs, the operating system traps into the kernel, updates page tables, schedules a read of the missing page, and resumes the process. The processor overhead outside of input/output for this handling is $t_{\\text{os}} = 25 \\,\\mu \\text{s}$.\n\nThe backing store is either a Solid-State Drive (SSD) or a Hard Disk Drive (HDD). For each page fault, the storage service time comprises a fixed controller latency plus a sequential transfer of the page. Model the storage latency as a random variable $L$ with mean $\\mathbb{E}[L]$ and variance $\\operatorname{Var}(L)$; the page transfer time is given by $t_{x} = S / B$ where $S$ is the page size and $B$ is the sustained read bandwidth. The page size is $S = 4096 \\text{ bytes}$. Assume for the SSD that $\\mathbb{E}[L_{\\text{SSD}}] = 100 \\,\\mu \\text{s}$ and $\\operatorname{Var}(L_{\\text{SSD}}) = (20 \\,\\mu \\text{s})^{2}$ with sustained bandwidth $B_{\\text{SSD}} = 500 \\times 10^{6} \\text{ bytes/s}$. Assume for the HDD that $\\mathbb{E}[L_{\\text{HDD}}] = 6000 \\,\\mu \\text{s}$ and $\\operatorname{Var}(L_{\\text{HDD}}) = (3000 \\,\\mu \\text{s})^{2}$ with sustained bandwidth $B_{\\text{HDD}} = 150 \\times 10^{6} \\text{ bytes/s}$.\n\nUsing only the definition of expected value for a Bernoulli mixture of outcomes (no-fault versus page-fault) and the above parameters, derive an expression for the Effective Access Time (EAT) under SSD and under HDD. Then compute the difference $\\Delta EAT = EAT_{\\text{HDD}} - EAT_{\\text{SSD}}$ as a single real number. Finally, justify qualitatively from first principles of variance and tail probabilities why the SSD backing store reduces both the variance of access times and the tail latency of page faults relative to the HDD.\n\nExpress the final numerical value of $\\Delta EAT$ in $\\mu \\text{s}$ and round your answer to four significant figures.",
            "solution": "The problem asks for the derivation of an expression for the Effective Access Time (EAT), the calculation of the difference in EAT between using a Hard Disk Drive (HDD) and a Solid-State Drive (SSD) as a backing store, and a qualitative justification for the performance benefits of SSDs regarding access time variance and tail latency.\n\nFirst, we establish the model for Effective Access Time. A memory reference results in one of two outcomes: a successful access if the page is in main memory (an event with probability $1-p$), or a page fault if it is not (an event with probability $p$). The EAT is the expected value of the access time over this Bernoulli distribution of outcomes.\n\nLet $T_{hit}$ be the time for a memory access when the page is present in memory, and let $T_{fault}$ be the time to service a page fault. The problem specifies the main memory access time as $t_m$. In the absence of further information about a Translation Lookaside Buffer (TLB) or multi-level page tables, we define the non-fault access time $T_{hit}$ as $t_m$. The EAT is then given by:\n$$EAT = (1-p) \\cdot T_{hit} + p \\cdot \\mathbb{E}[T_{fault}]$$\nHere, $\\mathbb{E}[T_{fault}]$ is the expected page fault service time.\n\nThe page fault service time, $T_{fault}$, consists of several components as described: operating system overhead ($t_{os}$), storage device latency ($L$), and page transfer time ($t_x$).\n$$T_{fault} = t_{os} + L + t_x$$\nThe latency $L$ is a random variable, while $t_{os}$ and $t_x$ are constants for a given device. The expected page fault service time is found by applying the linearity of expectation:\n$$\\mathbb{E}[T_{fault}] = \\mathbb{E}[t_{os} + L + t_x] = t_{os} + \\mathbb{E}[L] + t_x$$\n\nThe page transfer time $t_x$ is determined by the page size $S$ and the device's sustained read bandwidth $B$, where $t_x = S/B$. We calculate this for both the SSD and the HDD.\n\nFor the SSD:\n$S = 4096 \\text{ bytes}$\n$B_{\\text{SSD}} = 500 \\times 10^{6} \\text{ bytes/s}$\n$$t_{x, \\text{SSD}} = \\frac{S}{B_{\\text{SSD}}} = \\frac{4096}{500 \\times 10^{6}} \\text{ s} = 8.192 \\times 10^{-6} \\text{ s} = 8.192 \\,\\mu\\text{s}$$\n\nFor the HDD:\n$S = 4096 \\text{ bytes}$\n$B_{\\text{HDD}} = 150 \\times 10^{6} \\text{ bytes/s}$\n$$t_{x, \\text{HDD}} = \\frac{S}{B_{\\text{HDD}}} = \\frac{4096}{150 \\times 10^{6}} \\text{ s} \\approx 27.3067 \\times 10^{-6} \\text{ s} = 27.3067 \\,\\mu\\text{s}$$\n\nNow, we can write the full expression for the expected page fault service time for each device, using the given parameters: $t_{os} = 25 \\,\\mu\\text{s}$, $\\mathbb{E}[L_{\\text{SSD}}] = 100 \\,\\mu\\text{s}$, and $\\mathbb{E}[L_{\\text{HDD}}] = 6000 \\,\\mu\\text{s}$.\n\nExpected page fault time for SSD:\n$$\\mathbb{E}[T_{\\text{fault, SSD}}] = t_{os} + \\mathbb{E}[L_{\\text{SSD}}] + t_{x, \\text{SSD}} = 25 \\,\\mu\\text{s} + 100 \\,\\mu\\text{s} + 8.192 \\,\\mu\\text{s} = 133.192 \\,\\mu\\text{s}$$\n\nExpected page fault time for HDD:\n$$\\mathbb{E}[T_{\\text{fault, HDD}}] = t_{os} + \\mathbb{E}[L_{\\text{HDD}}] + t_{x, \\text{HDD}} \\approx 25 \\,\\mu\\text{s} + 6000 \\,\\mu\\text{s} + 27.3067 \\,\\mu\\text{s} = 6052.3067 \\,\\mu\\text{s}$$\n\nThe Effective Access Times for each configuration are:\n$$EAT_{\\text{SSD}} = (1-p)t_m + p \\cdot \\mathbb{E}[T_{\\text{fault, SSD}}]$$\n$$EAT_{\\text{HDD}} = (1-p)t_m + p \\cdot \\mathbb{E}[T_{\\text{fault, HDD}}]$$\n\nWe are asked to compute the difference $\\Delta EAT = EAT_{\\text{HDD}} - EAT_{\\text{SSD}}$.\n$$\\Delta EAT = \\left( (1-p)t_m + p \\cdot \\mathbb{E}[T_{\\text{fault, HDD}}] \\right) - \\left( (1-p)t_m + p \\cdot \\mathbb{E}[T_{\\text{fault, SSD}}] \\right)$$\nThe term $(1-p)t_m$ cancels, simplifying the expression to:\n$$\\Delta EAT = p \\left( \\mathbb{E}[T_{\\text{fault, HDD}}] - \\mathbb{E}[T_{\\text{fault, SSD}}] \\right)$$\nSubstituting the calculated values:\n$$\\Delta EAT = (2 \\times 10^{-4}) \\left( 6052.3067 \\,\\mu\\text{s} - 133.192 \\,\\mu\\text{s} \\right)$$\n$$\\Delta EAT = (2 \\times 10^{-4}) \\left( 5919.1147 \\,\\mu\\text{s} \\right)$$\n$$\\Delta EAT \\approx 1.1838229 \\,\\mu\\text{s}$$\nRounding to four significant figures gives $1.184 \\,\\mu\\text{s}$.\n\nFinally, we provide a qualitative justification for why the SSD reduces both the variance of access times and the tail latency of page faults relative to the HDD.\n\n1.  **Variance of Access Times**: The random component in the page fault service time $T_{fault} = t_{os} + L + t_x$ is the storage latency $L$, as both $t_{os}$ and $t_x$ are deterministic constants. The variance of the page fault service time is therefore equal to the variance of the latency: $\\operatorname{Var}(T_{fault}) = \\operatorname{Var}(t_{os} + L + t_x) = \\operatorname{Var}(L)$. The problem provides these variances:\n    $$\\operatorname{Var}(L_{\\text{SSD}}) = (20 \\,\\mu\\text{s})^2 = 400 \\,(\\mu\\text{s})^2$$\n    $$\\operatorname{Var}(L_{\\text{HDD}}) = (3000 \\,\\mu\\text{s})^2 = 9 \\times 10^6 \\,(\\mu\\text{s})^2$$\n    The standard deviations are $\\sigma_{\\text{SSD}} = 20 \\,\\mu\\text{s}$ and $\\sigma_{\\text{HDD}} = 3000 \\,\\mu\\text{s}$. The variance (and standard deviation) of the HDD latency is orders of magnitude larger than that of the SSD. This is a direct consequence of their physical nature. HDD latency is dominated by mechanical operations: the seek time to move the read/write head to the correct track and the rotational latency to wait for the desired sector to spin under the head. These times are highly variable, depending on the initial and final positions of the head and disk. In contrast, SSD latency is purely electronic, involving addressing and accessing flash memory cells, which is a far more deterministic and consistent process. This fundamental difference in operation is why $\\operatorname{Var}(L_{\\text{HDD}}) \\gg \\operatorname{Var}(L_{\\text{SSD}})$, and thus the variance of the page fault service time is much lower with an SSD.\n\n2.  **Tail Latency**: Tail latency refers to the probability of observing very long service times, often characterized by high percentiles (e.g., $99$th or $99.9$th) of the service time distribution. A random variable with a larger variance will have a wider probability distribution, meaning its values are more spread out from the mean. A distribution with a larger variance and/or a larger mean will generally have a \"heavier\" or \"longer\" tail, indicating a non-trivial probability of observing outcomes far from the mean. The HDD's latency distribution has both a much larger mean ($\\mathbb{E}[L_{\\text{HDD}}] = 6000 \\,\\mu\\text{s}$ vs. $\\mathbb{E}[L_{\\text{SSD}}] = 100 \\,\\mu\\text{s}$) and a vastly larger variance. Consequently, the probability of experiencing a page fault service time significantly longer than the average (i.e., a tail latency event) is substantially higher for the HDD. For an SSD, the low mean and minuscule variance mean its latency distribution is tightly concentrated, making extremely long delays highly improbable. Therefore, the SSD provides not only faster average performance but also more predictable performance with a much lower incidence of worst-case latency spikes.",
            "answer": "$$\\boxed{1.184}$$"
        },
        {
            "introduction": "Beyond optimizing hardware, we can improve performance by making the operating system's policies smarter. This practice explores the trade-offs of page prefetching, a common technique where the OS fetches pages it predicts will be needed soon. While this may reduce the overall number of faults, it increases the I/O cost for each fault that does occur. You will use the $EAT$ model to determine the precise \"break-even\" point where the benefits of prefetching exactly offset its costs, a core skill in system tuning. ",
            "id": "3633506",
            "problem": "A virtual memory system uses demand paging on a program whose per-reference page-fault probability without any prefetching is $p$. The processor’s memory-reference service time on a hit is $t_m$. On a page fault with on-demand paging, the operating system performs fault handling with software overhead $H$, then performs a single Input/Output (I/O) to bring the faulting page: the storage device has average seek plus rotational latency $L$ and a sustained transfer rate of $R$, and the page size is $S$. Assume the I/O completes in one contiguous operation so that the service time per fault under on-demand paging is $H + L + \\frac{S}{R}$.\n\nNow consider a prefetch policy: whenever a fault occurs, the system also prefetches $m$ additional pages in the same I/O, incurring no additional latency beyond $L$ but incurring additional transfer time $\\frac{mS}{R}$ on each fault. This policy reduces the steady-state page-fault probability to an unknown $p'$ (per reference), but does not change $t_m$ or $H$.\n\nUsing only the definition of expected memory access time (EMAT), where the time per reference is the expected value over the hit and fault cases, determine the break-even $p'$ such that prefetching neither helps nor hurts the EMAT relative to on-demand paging. Then evaluate this break-even $p'$ numerically for the following parameters and express your final answer as a decimal, rounded to four significant figures:\n\n- Baseline page-fault probability: $p = 3.0 \\times 10^{-5}$.\n- Memory hit time: $t_m = 8.0 \\times 10^{-8}$ s.\n- Operating system software overhead per fault: $H = 4.0 \\times 10^{-4}$ s.\n- Device average latency: $L = 5.6 \\times 10^{-3}$ s.\n- Sustained transfer rate: $R = 250$ mebibytes per second (MiB/s).\n- Page size: $S = 8$ kibibytes (KiB).\n- Prefetch depth: $m = 12$ additional pages per fault.\n\nUse the fact that $1$ MiB $= 2^{20}$ bytes and $1$ KiB $= 2^{10}$ bytes. Do not use a percentage sign; report the probability as a pure decimal.",
            "solution": "We begin from the definition of expected memory access time (expected value over hits and faults). Let the per-reference page-fault probability be $p$ and the hit probability be $1 - p$. If the hit time is $t_m$ and the page-fault service time is $T_{\\text{fault}}$, then the expected memory access time (EMAT) is\n$$\n\\text{EMAT} = (1 - p)\\, t_m + p\\, T_{\\text{fault}}.\n$$\nUnder on-demand paging, the page-fault service time is the sum of the operating system overhead $H$, the device average latency $L$, and the transfer time for one page $\\frac{S}{R}$:\n$$\nT_{\\text{on}} = H + L + \\frac{S}{R}.\n$$\nUnder the prefetch policy, we fetch the faulting page plus $m$ additional pages in the same I/O. There is no extra latency beyond $L$, but there is extra transfer time $\\frac{mS}{R}$. Hence, the page-fault service time with prefetch is\n$$\nT_{\\text{pre}} = H + L + \\frac{(m+1)S}{R} = \\left(H + L + \\frac{S}{R}\\right) + \\frac{mS}{R} = T_{\\text{on}} + k,\n$$\nwhere we define the extra I/O cost per fault due to prefetch as\n$$\nk = \\frac{mS}{R}.\n$$\nLet the new per-reference page-fault probability under prefetch be $p'$. The EMATs for the two policies are\n$$\n\\text{EMAT}_{\\text{on}} = (1 - p)\\, t_m + p\\, T_{\\text{on}}, \\qquad \\text{EMAT}_{\\text{pre}} = (1 - p')\\, t_m + p'\\, T_{\\text{pre}}.\n$$\nThe break-even condition requires equality:\n$$\n(1 - p)\\, t_m + p\\, T_{\\text{on}} = (1 - p')\\, t_m + p'\\, T_{\\text{pre}}.\n$$\nRearrange to solve for $p'$:\n\n$$\nt_m - p t_m + p T_{\\text{on}} = t_m - p' t_m + p' T_{\\text{pre}}\n$$\n\n\n$$\n- p t_m + p T_{\\text{on}} = - p' t_m + p' T_{\\text{pre}}\n$$\n\n\n$$\np' (T_{\\text{pre}} - t_m) = p (T_{\\text{on}} - t_m)\n$$\n\n\n$$\np' = p \\, \\frac{T_{\\text{on}} - t_m}{T_{\\text{pre}} - t_m} = p \\, \\frac{T_{\\text{on}} - t_m}{(T_{\\text{on}} + k) - t_m}.\n$$\n\nThis expression shows the required reduction in page-fault probability to exactly offset the extra I/O cost $k$ introduced by prefetch.\n\nWe now evaluate numerically. First compute the per-page transfer time $\\frac{S}{R}$ and then $k$, $T_{\\text{on}}$, and $T_{\\text{pre}}$.\n\n- Convert units. With $R = 250$ MiB/s and $S = 8$ KiB,\n  - $1$ MiB $= 2^{20}$ bytes and $1$ KiB $= 2^{10}$ bytes.\n  - $R = 250 \\times 2^{20} = 250 \\times 1{,}048{,}576 = 262{,}144{,}000$ bytes/s.\n  - $S = 8 \\times 2^{10} = 8192$ bytes.\nThus,\n$$\n\\frac{S}{R} = \\frac{8192}{262{,}144{,}000} = \\frac{1}{32{,}000} = 3.125 \\times 10^{-5} \\text{ s}.\n$$\n\n- The extra transfer time for $m = 12$ additional pages is\n$$\nk = \\frac{mS}{R} = 12 \\times 3.125 \\times 10^{-5} = 3.75 \\times 10^{-4} \\text{ s}.\n$$\n\n- The on-demand page-fault service time is\n$$\nT_{\\text{on}} = H + L + \\frac{S}{R} = (4.0 \\times 10^{-4}) + (5.6 \\times 10^{-3}) + (3.125 \\times 10^{-5}) = 6.03125 \\times 10^{-3} \\text{ s}.\n$$\n\n- The prefetch page-fault service time is\n$$\nT_{\\text{pre}} = T_{\\text{on}} + k = (6.03125 \\times 10^{-3}) + (3.75 \\times 10^{-4}) = 6.40625 \\times 10^{-3} \\text{ s}.\n$$\n\n- The hit time is $t_m = 8.0 \\times 10^{-8}$ s, so\n$$\nT_{\\text{on}} - t_m = 6.03125 \\times 10^{-3} - 8.0 \\times 10^{-8} = 6.03117 \\times 10^{-3} \\text{ s},\n$$\n$$\nT_{\\text{pre}} - t_m = 6.40625 \\times 10^{-3} - 8.0 \\times 10^{-8} = 6.40617 \\times 10^{-3} \\text{ s}.\n$$\n\nTherefore,\n$$\np'_{\\text{break}} = p \\, \\frac{T_{\\text{on}} - t_m}{T_{\\text{pre}} - t_m} = \\left(3.0 \\times 10^{-5}\\right) \\times \\frac{6.03117 \\times 10^{-3}}{6.40617 \\times 10^{-3}}.\n$$\nCompute the value:\n$$\np'_{\\text{break}} \\approx \\left(3.0 \\times 10^{-5}\\right) \\times 0.941461 = 2.82438 \\times 10^{-5}.\n$$\n\nRounded to four significant figures as requested:\n$$\np'_{\\text{break}} = 2.824 \\times 10^{-5}.\n$$\nThis is the minimum post-prefetch page-fault probability (as a decimal) that makes prefetching break even with on-demand paging for the given device bandwidth, latency, and prefetch depth.",
            "answer": "$$\\boxed{2.824 \\times 10^{-5}}$$"
        },
        {
            "introduction": "The heart of a demand paging system is its page replacement algorithm. This advanced exercise moves beyond probabilistic models to analyze the concrete behavior of FIFO, LRU, and Clock algorithms on a given memory reference trace. You will use the concept of reuse distance to formally analyze LRU's performance and see firsthand how algorithm design impacts fault counts, including the potential for counter-intuitive results like Belady's Anomaly. ",
            "id": "3668817",
            "problem": "A virtual memory system uses demand paging with a fully associative main memory of $M$ page frames and a single process whose reference stream exhibits distinct locality phases. Consider the following reference trace $\\mathcal{S}$ composed by concatenating two phases $\\mathcal{A}$ and $\\mathcal{B}$ twice:\n$$\n\\mathcal{A} = [\\,1,\\,2,\\,1,\\,2,\\,1,\\,2,\\,3,\\,1,\\,2,\\,1,\\,2,\\,3\\,], \\quad\n\\mathcal{B} = [\\,1,\\,2,\\,3,\\,4,\\,1,\\,2,\\,5,\\,1,\\,2,\\,3,\\,4,\\,5\\,],\n$$\nso that\n$$\n\\mathcal{S} = \\mathcal{A} \\,\\Vert\\, \\mathcal{B} \\,\\Vert\\, \\mathcal{A} \\,\\Vert\\, \\mathcal{B},\n$$\nwith $\\Vert$ denoting concatenation. The total length of $\\mathcal{S}$ is $48$ references. The page replacement algorithms to be compared are First-In First-Out (FIFO), Least Recently Used (LRU), and the Second-Chance (Clock) algorithm. Assume a single-level uniform memory access, negligible translation lookaside buffer effects, and that all page frames are initially empty with all reference bits clear before processing the first reference of $\\mathcal{S}$.\n\nYou will use the concept of reuse (stack) distance to reason about the performance of demand paging. For a reference to a page at time $t$, define its reuse distance $K$ as the number of distinct pages referenced strictly between its previous reference and time $t$; for the first reference to a page (no previous reference), let $K = \\infty$. Let $D(k)$ denote the empirical distribution of $K$ measured over the entire trace $\\mathcal{S}$, that is, for each $k \\in \\{1,2,3,\\dots\\}$ and $k=\\infty$, $D(k)$ is the fraction of references in $\\mathcal{S}$ whose reuse distance equals $k$.\n\nTasks:\n- Using only the core definitions of demand paging, reuse distance, and the qualitative stack property of LRU (that the set of pages in memory under LRU with $M$ frames is always a superset of that with $M-1$ frames on the same trace), compute the empirical distribution $D(k)$ for the given $\\mathcal{S}$.\n- From first principles, derive how to compute the expected number of page faults for LRU from $D(k)$ and the frame count $M$, and evaluate this for $M=3$ on $\\mathcal{S}$.\n- By direct reasoning from the algorithm definitions, determine the total number of page faults incurred by FIFO and by Second-Chance (Clock) when $M=3$ on $\\mathcal{S}$, and compare qualitatively to the LRU result you derived from $D(k)$.\n- Focusing on the single phase $\\mathcal{B}$ (the $12$-reference subsequence) under a cold start (empty frames at the start of $\\mathcal{B}$), discuss the risk of Belady’s anomaly for FIFO by comparing FIFO’s total page faults when $M=3$ versus when $M=4$ on that subsequence, and explain the root cause of any anomaly observed in terms of the lack of the stack property.\n\nProvide as your final answer only the expected total number of LRU page faults for $M=3$ over the entire $48$-reference trace $\\mathcal{S}$, as a single integer with no units. Do not include intermediate results in the final answer box.",
            "solution": "We begin from core definitions. A page fault occurs when the referenced page is not present in the set of $M$ page frames. The reuse distance $K$ for a reference is the number of distinct pages referenced strictly between its previous occurrence and the current time; for a first reference to a page, $K=\\infty$. For Least Recently Used (LRU), a reference is a hit precisely when the number of distinct pages used since the last reference to that page is strictly less than the number of frames $M$, because LRU maintains in memory the $M$ most recently used distinct pages. Therefore, under LRU with $M$ frames, a reference faults if and only if $K \\ge M$ (including $K=\\infty$). This yields, for a trace of length $N$, that the LRU fault count equals\n$$\nN \\cdot \\Big( D(\\infty) \\;+\\; \\sum_{k=M}^{\\infty} D(k) \\Big),\n$$\nwhen $D(k)$ is the empirical reuse distance distribution.\n\nStep $1$: Compute the empirical $D(k)$ for $\\mathcal{S}$.\n\nWe scan $\\mathcal{S}$ once, and for each reference, compute $K$ as the number of distinct pages encountered since the previous reference to the same page, or $K=\\infty$ if none. Tallying over the entire $48$ references yields the following counts:\n- $5$ references with $K=\\infty$,\n- $12$ references with $K=1$,\n- $16$ references with $K=2$,\n- $4$ references with $K=3$,\n- $11$ references with $K=4$,\nand $0$ for all other finite $k$.\nThese counts sum to $48$, as required. Thus,\n$$\nD(\\infty) \\;=\\; \\frac{5}{48},\\quad D(1)\\;=\\;\\frac{12}{48},\\quad D(2)\\;=\\;\\frac{16}{48},\\quad D(3)\\;=\\;\\frac{4}{48},\\quad D(4)\\;=\\;\\frac{11}{48},\n$$\nwith $D(k)=0$ for all $k \\ge 5$.\n\nStep $2$: Derive and evaluate the LRU expected fault count for $M=3$.\n\nBy the LRU stack property and the definition of reuse distance, a reference faults under LRU with $M=3$ if $K \\in \\{\\infty\\} \\cup \\{3,4,5,\\dots\\}$. Using the empirical $D(k)$ above with $N=48$,\n$$\n\\text{Faults}_{\\text{LRU},\\,M=3}\n\\;=\\;\n48 \\cdot \\Big( D(\\infty) + \\sum_{k=3}^{\\infty} D(k) \\Big)\n\\;=\\;\n48 \\cdot \\Big( \\frac{5}{48} + \\frac{4}{48} + \\frac{11}{48} \\Big)\n\\;=\\;\n48 \\cdot \\frac{20}{48}\n\\;=\\;\n20.\n$$\nEquivalently, counting directly: $5$ first-touch references plus $4$ references with $K=3$ plus $11$ with $K=4$ produce $20$ LRU faults.\n\nStep $3$: Compare FIFO and Second-Chance (Clock) for $M=3$ by direct algorithmic reasoning.\n\nWe now simulate FIFO and Clock from their definitions. For First-In First-Out (FIFO), maintain a queue of loaded frames in arrival order; on a miss with a full memory, evict the oldest frame (the head of the queue). For Second-Chance (Clock), maintain a circular list of frames with a reference bit per frame; on a hit, set that page’s bit to $1$; on a miss, advance the hand, clearing any encountered bit that is $1$ to $0$ and continuing, until a frame with bit $0$ is found; evict that frame, install the new page there with bit $1$, and advance the hand by one position.\n\nCarrying out a step-by-step simulation across the $48$-reference trace $\\mathcal{S}$ with $M=3$ (frames initially empty and, for Clock, all reference bits initially $0$ and the hand at the first frame) yields the following total page fault counts:\n- $\\text{Faults}_{\\text{FIFO},\\,M=3} = 18$,\n- $\\text{Faults}_{\\text{Clock},\\,M=3} = 18$,\nwhich are both lower than or equal to, or higher than, the LRU count depending on the trace; here, the empirical LRU count is $20$. This illustrates that, although LRU has the stack property and tends to minimize faults among stack algorithms for a given $M$ on typical locality-rich traces, FIFO and Clock are not stack algorithms; in particular, FIFO may sometimes incur fewer or more faults than LRU on a given finite trace.\n\nStep $4$: Discuss Belady’s anomaly risk for FIFO on phase $\\mathcal{B}$.\n\nBelady’s anomaly refers to the possibility that, under FIFO, increasing the number of page frames can increase the number of page faults. Consider the single phase $\\mathcal{B} = [\\,1,\\,2,\\,3,\\,4,\\,1,\\,2,\\,5,\\,1,\\,2,\\,3,\\,4,\\,5\\,]$ under a cold start (empty frames at the start of $\\mathcal{B}$). A direct FIFO simulation shows:\n- With $M=3$, the total FIFO faults over $\\mathcal{B}$ are $9$.\n- With $M=4$, the total FIFO faults over $\\mathcal{B}$ are $10$.\nThus, increasing frames from $3$ to $4$ increases FIFO faults from $9$ to $10$, an instance of Belady’s anomaly. The root cause is that FIFO lacks the stack property: the set of pages in memory with $M=4$ at a given time is not necessarily a superset of the set with $M=3$ on the same reference string, so additional capacity can perturb eviction order in a way that leads to extra misses.\n\nConclusion and required numeric result.\n\nFrom the measured $D(k)$ and the LRU stack property, the expected total number of LRU page faults on $\\mathcal{S}$ for $M=3$ equals $20$.",
            "answer": "$$\\boxed{20}$$"
        }
    ]
}