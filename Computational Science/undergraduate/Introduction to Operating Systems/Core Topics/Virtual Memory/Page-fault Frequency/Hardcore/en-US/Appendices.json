{
    "hands_on_practices": [
        {
            "introduction": "Managing a fixed memory budget is a fundamental challenge in operating systems. This exercise  models a process with distinct memory regions—a stack and a heap—each with a unique access pattern and corresponding page-fault behavior. By determining the optimal allocation of frames between these regions, you will practice using optimization principles to minimize the total Page-Fault Frequency, a core skill in performance tuning.",
            "id": "3667671",
            "problem": "A single process divides its memory accesses between a call-stack region and a heap region. Let the fraction of all references that go to the stack be $r_{s}$ and to the heap be $r_{h}=1-r_{s}$. Page-Fault Frequency (PFF) is defined as the number of page-faults per memory reference, measured over a sufficiently long observation window so that ergodic averages coincide with expected values. Assume that each region’s per-reference miss probability under the Least Recently Used (LRU) policy can be empirically modeled as a strictly decreasing, convex function of the number of page frames allocated to that region. Specifically, for the stack and heap, the miss probabilities are\n$$m_{s}(f_{s})=\\exp(-a_{s} f_{s}), \\quad m_{h}(f_{h})=\\exp(-a_{h} f_{h}),$$\nwhere $f_{s}$ and $f_{h}$ are the frames allocated to the stack and heap, respectively, and $a_{s}0$, $a_{h}0$ are region-specific parameters capturing locality strength. The process is subject to a fixed total frame budget $F$, so that $f_{s}+f_{h}=F$ with $f_{s}\\ge 0$ and $f_{h}\\ge 0$.\n\nYou are given $r_{s}=0.4$, hence $r_{h}=0.6$, as well as $a_{s}=0.35$, $a_{h}=0.15$, and a total frame budget $F=30$.\n\nTasks:\n- Using only the definition of Page-Fault Frequency (PFF) as expected faults per reference and the given miss-probability models, derive symbolic expressions for $PFF_{stack}(f_{s})$, $PFF_{heap}(f_{h})$, and the total PFF as a function of $f_{s}$ only, given the constraint $f_{h}=F-f_{s}$.\n- From first principles, explain how a policy that “prioritizes the region with higher PFF” translates into a per-frame allocation decision rule in terms of the marginal reduction in total PFF when one more frame is assigned to either region.\n- Compute the value of the stack allocation $f_{s}^{\\star}$ that minimizes the total PFF subject to $f_{s}+f_{h}=F$, using the given numerical parameters. Round your answer to three significant figures and express it in frames.",
            "solution": "The problem as stated is scientifically grounded, well-posed, objective, and internally consistent. It presents a standard optimization problem within the context of operating system resource management, based on a simplified but valid empirical model of program locality. All necessary parameters and definitions are provided, allowing for a unique and meaningful solution. Therefore, the problem is deemed valid.\n\nThe solution proceeds by addressing the three tasks outlined in the problem statement.\n\nFirst, we derive the symbolic expressions for the Page-Fault Frequency (PFF) components. PFF is defined as the expected number of page faults per memory reference. The total PFF is the sum of contributions from the stack and heap regions.\n\nThe contribution of the stack to the total PFF, denoted $PFF_{stack}$, is the probability that a randomly chosen memory reference is to the stack AND it causes a page fault. This is the product of the fraction of references to the stack, $r_{s}$, and the miss probability for the stack, $m_{s}(f_{s})$.\n$$PFF_{stack}(f_{s}) = r_{s} m_{s}(f_{s}) = r_{s} \\exp(-a_{s} f_{s})$$\nSimilarly, the contribution of the heap to the total PFF, denoted $PFF_{heap}$, is the product of the fraction of references to the heap, $r_{h}$, and the miss probability for the heap, $m_{h}(f_{h})$.\n$$PFF_{heap}(f_{h}) = r_{h} m_{h}(f_{h}) = r_{h} \\exp(-a_{h} f_{h})$$\nThe total PFF for the process is the sum of these two contributions:\n$$PFF(f_{s}, f_{h}) = PFF_{stack}(f_{s}) + PFF_{heap}(f_{h}) = r_{s} \\exp(-a_{s} f_{s}) + r_{h} \\exp(-a_{h} f_{h})$$\nUsing the constraint that the total number of frames is fixed at $F$, we have $f_{s} + f_{h} = F$, which implies $f_{h} = F - f_{s}$. Substituting this into the expression for the total PFF yields the total PFF as a function of $f_{s}$ only:\n$$PFF(f_{s}) = r_{s} \\exp(-a_{s} f_{s}) + r_{h} \\exp(-a_{h} (F - f_{s}))$$\n\nSecond, we explain the allocation decision rule. A naive policy that \"prioritizes the region with higher PFF\" would mean allocating a frame to the stack if $PFF_{stack}(f_s)  PFF_{heap}(f_h)$, and to the heap otherwise. However, this policy is not optimal. The optimal resource allocation policy aims to achieve the greatest possible improvement (i.e., reduction) in the overall objective function, which is the total PFF.\n\nThe correct decision rule is based on the marginal reduction in total PFF obtained by allocating one additional frame to a region. For a continuous approximation of frame allocation, this is captured by the partial derivative of the total PFF with respect to the number of frames allocated to each region. The marginal reduction in total PFF from adding a frame to the stack is $-\\frac{\\partial PFF}{\\partial f_{s}}$, and for the heap it is $-\\frac{\\partial PFF}{\\partial f_{h}}$.\n\nLet's compute these marginal reductions from their respective contributions to the total PFF:\nThe marginal reduction for the stack is:\n$$R_{s}(f_{s}) = -\\frac{d}{d f_{s}} (PFF_{stack}(f_{s})) = -\\frac{d}{d f_{s}} [r_{s} \\exp(-a_{s} f_{s})] = a_{s} r_{s} \\exp(-a_{s} f_{s})$$\nThe marginal reduction for the heap is:\n$$R_{h}(f_{h}) = -\\frac{d}{d f_{h}} (PFF_{heap}(f_{h})) = -\\frac{d}{d f_{h}} [r_{h} \\exp(-a_{h} f_{h})] = a_{h} r_{h} \\exp(-a_{h} f_{h})$$\nThe decision rule is to allocate the next frame to the region with the higher marginal reduction. The optimal static allocation is achieved when the marginal reductions are equalized: $R_{s}(f_{s}^{\\star}) = R_{h}(f_{h}^{\\star})$. This condition ensures that no frame could be reallocated from one region to another to achieve a greater reduction in total PFF.\n\nThird, we compute the optimal stack allocation $f_{s}^{\\star}$ that minimizes the total PFF. To find the minimum of $PFF(f_s)$, we set its first derivative with respect to $f_s$ to zero.\n$$PFF(f_{s}) = r_{s} \\exp(-a_{s} f_{s}) + r_{h} \\exp(-a_{h} (F - f_{s}))$$\n$$\\frac{d PFF(f_{s})}{d f_{s}} = -a_{s} r_{s} \\exp(-a_{s} f_{s}) + a_{h} r_{h} \\exp(-a_{h} (F - f_{s}))$$\nSetting the derivative to zero:\n$$-a_{s} r_{s} \\exp(-a_{s} f_{s}^{\\star}) + a_{h} r_{h} \\exp(-a_{h} (F - f_{s}^{\\star})) = 0$$\n$$a_{s} r_{s} \\exp(-a_{s} f_{s}^{\\star}) = a_{h} r_{h} \\exp(-a_{h} (F - f_{s}^{\\star}))$$\nThis equation is identical to the equilibrium condition where the marginal reductions are equal. To solve for $f_{s}^{\\star}$, we take the natural logarithm of both sides:\n$$\\ln(a_{s} r_{s}) - a_{s} f_{s}^{\\star} = \\ln(a_{h} r_{h}) - a_{h} (F - f_{s}^{\\star})$$\n$$\\ln(a_{s} r_{s}) - a_{s} f_{s}^{\\star} = \\ln(a_{h} r_{h}) - a_{h} F + a_{h} f_{s}^{\\star}$$\nRearranging the terms to isolate $f_{s}^{\\star}$:\n$$a_{h} F + \\ln(a_{s} r_{s}) - \\ln(a_{h} r_{h}) = (a_{s} + a_{h}) f_{s}^{\\star}$$\n$$f_{s}^{\\star} = \\frac{a_{h} F + \\ln\\left(\\frac{a_{s} r_{s}}{a_{h} r_{h}}\\right)}{a_{s} + a_{h}}$$\nNow, we substitute the given numerical values: $r_{s}=0.4$, $r_{h}=0.6$, $a_{s}=0.35$, $a_{h}=0.15$, and $F=30$.\nThe denominator is $a_{s} + a_{h} = 0.35 + 0.15 = 0.5$.\nThe numerator terms are:\n$a_{h} F = 0.15 \\times 30 = 4.5$.\nThe argument of the logarithm is $\\frac{a_{s} r_{s}}{a_{h} r_{h}} = \\frac{0.35 \\times 0.4}{0.15 \\times 0.6} = \\frac{0.14}{0.09} = \\frac{14}{9}$.\nSo, $\\ln\\left(\\frac{14}{9}\\right) \\approx 0.44183$.\nSubstituting these values into the expression for $f_s^{\\star}$:\n$$f_{s}^{\\star} = \\frac{4.5 + \\ln\\left(\\frac{14}{9}\\right)}{0.5} \\approx \\frac{4.5 + 0.44183}{0.5} = \\frac{4.94183}{0.5} \\approx 9.88366$$\nThe second derivative of $PFF(f_s)$ is $a_{s}^2 r_{s} \\exp(-a_{s} f_{s}) + a_{h}^2 r_{h} \\exp(-a_{h} (F - f_{s}))$, which is strictly positive for all $f_s$, confirming that this critical point is a global minimum.\nRounding the result to three significant figures, we get $9.88$. This value is within the valid range $[0, 30]$.",
            "answer": "$$\\boxed{9.88}$$"
        },
        {
            "introduction": "The choice of a page replacement algorithm can have a profound impact on performance, particularly when memory is scarce. This problem  challenges you to analyze a classic \"thrashing\" scenario, where a process cyclically accesses more pages than there are available frames. By comparing the resulting Page-Fault Frequency for LRU, CLOCK, and Random Replacement, you will gain a concrete understanding of how different policy behaviors lead to dramatically different outcomes under stress.",
            "id": "3667744",
            "problem": "A single process repeatedly accesses a loop of $K$ distinct virtual pages in a fixed cyclic order, one reference per page per cycle, with uniform revisit frequency among the $K$ pages. The process is allocated $f$ physical page frames, with $f  K$. There is no prefetching, and the initial contents of memory are empty; consider the long-run steady state after any transient warm-up has passed. The operating system may use one of three page-replacement policies: Least Recently Used (LRU), the Clock page replacement algorithm (CLOCK), or Random Replacement (RR). Define Page-Fault Frequency (PFF) as the long-run average number of page faults per memory reference: $PFF = \\lim_{N \\to \\infty} \\frac{F(N)}{N}$, where $F(N)$ counts page faults in the first $N$ references.\n\nFrom the basic definitions of these replacement policies and the described workload, reason about the steady-state $PFF$ under each policy when $f  K$. Then, for the specific case $K = 10$ and $f = 4$, select the option that best predicts the steady-state $PFF$ ordering across policies and provides a correct numerical prediction for RR.\n\nA. Under LRU and CLOCK, $PFF$ approaches $1$ per reference in steady state; under RR, $PFF$ is strictly less than $1$ and is approximately $0.90$ when $K = 10$ and $f = 4$.\n\nB. Under LRU and CLOCK, $PFF$ approaches $1$ per reference in steady state; under RR, $PFF$ is approximately $1 - \\frac{f}{K} = 0.60$ when $K = 10$ and $f = 4$.\n\nC. Under LRU, CLOCK, and RR, $PFF$ approaches $1$ per reference whenever $f  K$.\n\nD. Under LRU, $PFF$ is strictly less than under CLOCK, and both are strictly less than under RR, because LRU exploits recency to avoid thrashing when $f  K$.",
            "solution": "This problem analyzes the steady-state performance of three page replacement policies (LRU, CLOCK, and Random) under a pathological workload: a cyclic scan of $K$ pages with only $f$ available frames, where $f  K$.\n\n1.  **Least Recently Used (LRU) Policy**: LRU evicts the page that has not been accessed for the longest time. In a cyclic pattern of $P_1, P_2, \\dots, P_K, P_1, \\dots$, by the time page $P_i$ is referenced, the $f$ pages in memory are $\\{P_{i-1}, P_{i-2}, \\dots, P_{i-f}\\}$ (indices taken modulo $K$). Since $f  K$, the requested page $P_i$ is never one of these. This means every single memory access results in a page fault. This is the classic thrashing scenario for LRU. Therefore, the Page-Fault Frequency ($PFF_{LRU}$) is 1.\n\n2.  **Clock (CLOCK) Policy**: CLOCK is a hardware-efficient approximation of LRU. It maintains a reference bit for each page. For this deterministic, cyclic workload, CLOCK's behavior devolves to that of LRU. To find a victim page, the algorithm must scan all $f$ frames, clearing their reference bits (as they have all been recently used). After a full circle, it evicts the page it first encountered, which is the oldest page. Just like LRU, it always evicts a page that will be needed soon, and the page being requested is never in memory. Thus, the Page-Fault Frequency ($PFF_{CLOCK}$) is also 1.\n\n3.  **Random Replacement (RR) Policy**: RR evicts a page chosen uniformly at random from the $f$ resident pages. This randomness prevents the pathological lock-step behavior seen in LRU and CLOCK. A page fault occurs if the requested page is not in memory. We can model this using survival analysis. A reference to a page is a *hit* only if it has survived in memory since its last access, which was $K-1$ references ago. The probability of a specific page being evicted at any fault is $1/f$. The fault rate is the PFF itself. So, the probability that a given page is evicted at any single memory reference step is $P(\\text{eviction}) = PFF \\times \\frac{1}{f}$. The probability it survives one step is $1 - \\frac{PFF}{f}$. The probability it survives $K-1$ steps is $(1 - \\frac{PFF}{f})^{K-1}$. This survival probability must equal the hit rate, which is $1 - PFF$. This gives the equation:\n    $$1 - PFF = \\left(1 - \\frac{PFF}{f}\\right)^{K-1}$$\n    For the case $K = 10$ and $f = 4$, we get:\n    $$1 - PFF = \\left(1 - \\frac{PFF}{4}\\right)^{9}$$\n    We can test the value $PFF \\approx 0.90$ from Option A.\n    LHS = $1 - 0.90 = 0.10$.\n    RHS = $(1 - 0.90/4)^9 = (1 - 0.225)^9 = (0.775)^9 \\approx 0.1008$.\n    Since the left-hand side is approximately equal to the right-hand side, $PFF_{RR} \\approx 0.90$ is the correct prediction. This is strictly less than 1.\n\n**Conclusion:**\nThe analysis shows $PFF_{LRU} = 1$, $PFF_{CLOCK} = 1$, and $PFF_{RR} \\approx 0.90$. Option A correctly states that PFF for LRU and CLOCK is 1, while for RR it is strictly less than 1 and approximately 0.90. Options B, C, and D make incorrect claims about the PFF values or their relative ordering.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Translating theoretical knowledge into practical skill requires learning to interpret real-world performance data. This exercise  simulates the process of analyzing measurements from a tool like Linux `perf` to diagnose a multithreaded application's behavior. By calculating and correlating Page-Fault Frequency with system call rates, you will learn to identify and distinguish between I/O-bound, CPU-bound, and memory-thrashing phases, a crucial skill in performance engineering.",
            "id": "3667759",
            "problem": "A multi-threaded workload is instrumented using the Linux performance analysis tool (perf) to study Page-Fault Frequency (PFF). Page-Fault Frequency (PFF) is defined operationally in this lab as the rate of page faults experienced by a thread over a fixed wall-clock interval. A page fault occurs when a thread references a virtual memory page that is not currently mapped to a usable physical frame; this includes both minor faults (page already in memory but not mapped into the process address space) and major faults (page not in memory and must be fetched from disk). System call (syscall) rate is used as a proxy to identify Input/Output (I/O)-bound phases, because threads performing I/O typically invoke many syscalls (for example, read and write). Central Processing Unit (CPU)-bound behavior is characterized by sustained computation with few syscalls. The experiment samples per-thread counters in three non-overlapping phases with known wall-clock durations.\n\nThe workload has two threads, $T_1$ and $T_2$. For each phase, perf reports the following per-thread counts for page faults (minor plus major combined) and syscalls:\n\nPhase $\\mathrm{A}$ spans $0$ to $10$ seconds, duration $10$ seconds.\n- $T_1$: page faults $2000$, syscalls $80$.\n- $T_2$: page faults $100$, syscalls $60$.\n\nPhase $\\mathrm{B}$ spans $10$ to $30$ seconds, duration $20$ seconds.\n- $T_1$: page faults $150$, syscalls $5000$.\n- $T_2$: page faults $2500$, syscalls $200$.\n\nPhase $\\mathrm{C}$ spans $30$ to $45$ seconds, duration $15$ seconds.\n- $T_1$: page faults $20$, syscalls $40$.\n- $T_2$: page faults $30$, syscalls $35$.\n\nBased on the fundamental definitions above and the reported per-thread counts over known durations, which option best describes a correct interpretation of the phase behavior and the appropriate measurement approach to compute per-thread Page-Fault Frequency (PFF) and correlate it with syscall rate to distinguish I/O-bound versus CPU-bound phases?\n\nA. Compute per-thread PFF in each phase as total page faults (minor plus major) divided by the phase duration, and compute per-thread syscall rate similarly. Then, for $T_1$, Phase $\\mathrm{A}$ exhibits high PFF with low syscall rate (consistent with memory thrashing during CPU-heavy work), Phase $\\mathrm{B}$ exhibits low PFF with very high syscall rate (consistent with I/O-bound behavior), and Phase $\\mathrm{C}$ exhibits low PFF with low syscall rate (consistent with CPU-bound compute with a resident working set). For $T_2$, Phase $\\mathrm{A}$ exhibits low PFF with low syscall rate (CPU-bound with a small working set), Phase $\\mathrm{B}$ exhibits very high PFF with modest syscall rate (consistent with memory thrashing), and Phase $\\mathrm{C}$ exhibits low PFF with low syscall rate (CPU-bound).\n\nB. Any phase with a high syscall rate must also have a high PFF, because syscalls trigger page faults; therefore both $T_1$ and $T_2$ are I/O-bound in Phase $\\mathrm{B}$, and PFF cannot distinguish CPU-bound versus I/O-bound phases.\n\nC. To compute PFF correctly, only major page faults should be counted, because minor page faults do not reflect memory residency; therefore phases with many minor faults should be treated as having zero PFF, and classification should rely on major faults alone.\n\nD. Per-thread PFF should be computed by aggregating system-wide page faults and dividing by the process CPU time (not wall-clock time), because wall-clock time includes I/O wait and hence underestimates true frequency; using system-wide counters will still reveal per-thread phase behavior after normalization.\n\nChoose the single best option.",
            "solution": "The derivation begins from core definitions. A page fault is an event triggered when a thread references a virtual memory page that is not currently mapped to a usable physical frame. The rate (frequency) of a discrete event over a fixed interval is defined as the total count divided by the interval length in time; thus, operationally in this lab, Page-Fault Frequency (PFF) is computed as per-thread page-fault count divided by the wall-clock duration of the measurement window. System call (syscall) rate is computed similarly as per-thread syscall count divided by the wall-clock duration. These definitions follow standard frequency concepts: if $N$ events occur uniformly over time interval $\\Delta t$, the event frequency is $N / \\Delta t$. In operating systems, I/O-bound phases typically present high syscall rates (invocations such as `read`, `write`, `open`), while CPU-bound phases present low syscall rates and sustained computation. Memory thrashing is characterized by a very high PFF (frequent page faults) indicating that the working set size exceeds available physical frames or mapping capacity, while a low PFF indicates a resident, stable working set.\n\nCompute per-thread PFF and syscall rate for each phase:\n\nFor $T_1$:\n- Phase $\\mathrm{A}$ duration $10$ seconds. PFF $= 2000 / 10 = 200$ faults/second. Syscall rate $= 80 / 10 = 8$ syscalls/second. Interpretation: very high PFF, low syscall rate. This is consistent with CPU-heavy memory-thrashing behavior (the thread is computing and causing many page faults, rather than issuing many I/O syscalls).\n- Phase $\\mathrm{B}$ duration $20$ seconds. PFF $= 150 / 20 = 7.5$ faults/second. Syscall rate $= 5000 / 20 = 250$ syscalls/second. Interpretation: low PFF, extremely high syscall rate. This is consistent with I/O-bound behavior (many syscalls) with a relatively stable working set (low PFF).\n- Phase $\\mathrm{C}$ duration $15$ seconds. PFF $= 20 / 15 \\approx 1.33$ faults/second. Syscall rate $= 40 / 15 \\approx 2.67$ syscalls/second. Interpretation: low PFF and low syscall rate. This is consistent with CPU-bound compute with a resident working set.\n\nFor $T_2$:\n- Phase $\\mathrm{A}$ duration $10$ seconds. PFF $= 100 / 10 = 10$ faults/second. Syscall rate $= 60 / 10 = 6$ syscalls/second. Interpretation: low PFF and low syscall rate. This is consistent with CPU-bound behavior with a small working set.\n- Phase $\\mathrm{B}$ duration $20$ seconds. PFF $= 2500 / 20 = 125$ faults/second. Syscall rate $= 200 / 20 = 10$ syscalls/second. Interpretation: very high PFF with modest syscall rate. This is consistent with memory thrashing during CPU-heavy work, not I/O-bound behavior.\n- Phase $\\mathrm{C}$ duration $15$ seconds. PFF $= 30 / 15 = 2$ faults/second. Syscall rate $= 35 / 15 \\approx 2.33$ syscalls/second. Interpretation: low PFF and low syscall rate. This is consistent with CPU-bound behavior.\n\nFrom these computations, the correct classification and measurement method is to compute per-thread PFF and syscall rate using per-thread counts divided by wall-clock interval durations and then interpret high syscall rate as I/O-bound if PFF is low, and interpret high PFF with low syscall rate as memory-thrashing CPU-heavy behavior. This matches Option A exactly.\n\nEvaluate each option:\n\nA. Option A describes computing per-thread PFF as total page faults (minor plus major) divided by phase duration and computing per-thread syscall rate similarly. It then provides interpretations that exactly match the computed rates: $T_1$ Phase $\\mathrm{A}$ high PFF with low syscall rate (memory thrashing), Phase $\\mathrm{B}$ low PFF with very high syscall rate (I/O-bound), Phase $\\mathrm{C}$ low PFF with low syscall rate (CPU-bound), and $T_2$ Phase $\\mathrm{A}$ low PFF with low syscall rate (CPU-bound), Phase $\\mathrm{B}$ very high PFF with modest syscall rate (memory thrashing), Phase $\\mathrm{C}$ low PFF with low syscall rate (CPU-bound). Verdict — Correct.\n\nB. Option B asserts that any phase with a high syscall rate must also have a high PFF because syscalls trigger page faults. This is a misconception. Syscalls often do not cause page faults directly; many syscalls operate on already resident data or involve kernel work that does not fault user pages. Our data show a counterexample: $T_1$ Phase $\\mathrm{B}$ has extremely high syscall rate ($250$ per second) but low PFF ($7.5$ per second). Furthermore, PFF clearly distinguishes memory-thrashing CPU-heavy phases (e.g., $T_1$ Phase $\\mathrm{A}$ and $T_2$ Phase $\\mathrm{B}$) from I/O-bound phases (e.g., $T_1$ Phase $\\mathrm{B}$). Verdict — Incorrect.\n\nC. Option C claims that only major faults should be counted for PFF because minor faults do not reflect memory residency and proposes treating phases with many minor faults as having zero PFF. This is incorrect in the context of the lab’s definition and operational goal. Minor faults indicate that a page was not mapped in the process address space at the time of access; they are evidence of memory management events that affect locality and mapping, and they contribute to the effective fault frequency experienced by a thread. Excluding minor faults will distort the observed PFF signature and can obscure thrashing that manifests as frequent minor faults (for example, copy-on-write faults or page table population). Verdict — Incorrect.\n\nD. Option D proposes computing per-thread PFF by aggregating system-wide page faults and dividing by process CPU time rather than wall-clock time and claims that system-wide counters will still reveal per-thread behavior. This is flawed for two reasons. First, per-thread PFF must be computed from per-thread counts to preserve attribution; system-wide aggregation mixes events from unrelated threads and processes, destroying per-thread resolution. Second, frequency is defined per unit time; using CPU time excludes I/O wait and other scheduler-induced delays that are part of the behavior we aim to classify. Normalizing by CPU time will inflate apparent rates in I/O-bound phases and confound the interpretation. Verdict — Incorrect.\n\nTherefore, Option A is the single best choice.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}