{
    "hands_on_practices": [
        {
            "introduction": "Before data can be transmitted across a network, it must be encoded into a byte stream through a process called serialization. This exercise explores the performance trade-off between human-readable formats like JSON and compact binary formats like Protocol Buffers. By modeling the CPU cost, you will develop the essential skill of analyzing how data representation impacts overall system throughput, a critical consideration in designing high-performance microservices. ",
            "id": "3636323",
            "problem": "A microservice in a distributed key–value store cluster must serialize and deserialize incoming Remote Procedure Call (RPC) payloads, each containing $n$ scalar fields with simple types. Two alternative encodings are under consideration: JavaScript Object Notation (JSON) and Protocol Buffers (Protobuf). The service runs on a single dedicated core of a Central Processing Unit (CPU) with clock frequency $3.2\\,\\text{GHz}$. Assume the workload is steady-state, the system is CPU-bound (that is, network and storage are not the bottlenecks), and there is no concurrent overlap between computation and I/O for serialization.\n\nModel the CPU work per message as the total number of CPU cycles to serialize and deserialize the payload. Assume the total cycles per message are affine in $n$:\n- For JavaScript Object Notation (JSON): $C_{\\mathrm{J}}(n) = \\alpha_{\\mathrm{J}} + \\gamma_{\\mathrm{J}}\\,n$.\n- For Protocol Buffers (Protobuf): $C_{\\mathrm{P}}(n) = \\alpha_{\\mathrm{P}} + \\gamma_{\\mathrm{P}}\\,n$.\n\nHere, $\\alpha_{\\mathrm{J}}$ and $\\alpha_{\\mathrm{P}}$ are fixed per-message cycle costs (schema handling, allocation overheads, etc.), and $\\gamma_{\\mathrm{J}}$ and $\\gamma_{\\mathrm{P}}$ are per-field cycle costs reflecting encoding and decoding work. Suppose measurements on the target platform yield\n$\\alpha_{\\mathrm{J}} = 1.2 \\times 10^{5}$, $\\gamma_{\\mathrm{J}} = 1.6 \\times 10^{4}$, $\\alpha_{\\mathrm{P}} = 1.8 \\times 10^{5}$, and $\\gamma_{\\mathrm{P}} = 3.2 \\times 10^{3}$, all in units of CPU cycles.\n\nUsing only first principles about throughput as completed work per unit time and the interpretation of a CPU clock rate as available cycles per unit time, derive the per-core steady-state throughputs in messages per second for the two encodings as functions of $n$, and then determine the break-even field count $n^{\\ast}$ at which the two throughputs are equal. Provide your final $n^{\\ast}$ as an exact simplified fraction; no rounding is required. Do not include any units in your final answer.",
            "solution": "The problem asks for the break-even field count $n^{\\ast}$ at which the throughput of a microservice is the same for two different serialization formats: JSON and Protobuf. The solution is based on the fundamental relationship between CPU frequency, computational cost per message, and throughput.\n\n1.  **Define Throughput**\n    Throughput, in messages per second, is the total number of available CPU cycles per second divided by the number of CPU cycles required to process a single message. Let $f$ be the CPU clock frequency ($3.2 \\times 10^9$ cycles/second) and $C(n)$ be the cost in cycles for a message with $n$ fields. The throughput $T(n)$ is:\n    $$T(n) = \\frac{f}{C(n)}$$\n\n2.  **Formulate Throughput for Each Encoding**\n    Using the given affine cost models, the throughput for JSON is:\n    $$T_{\\mathrm{J}}(n) = \\frac{f}{C_{\\mathrm{J}}(n)} = \\frac{f}{\\alpha_{\\mathrm{J}} + \\gamma_{\\mathrm{J}}\\,n}$$\n    And the throughput for Protobuf is:\n    $$T_{\\mathrm{P}}(n) = \\frac{f}{C_{\\mathrm{P}}(n)} = \\frac{f}{\\alpha_{\\mathrm{P}} + \\gamma_{\\mathrm{P}}\\,n}$$\n\n3.  **Find the Break-Even Point**\n    The break-even point $n^{\\ast}$ is the value of $n$ where the throughputs are equal: $T_{\\mathrm{J}}(n^{\\ast}) = T_{\\mathrm{P}}(n^{\\ast})$.\n    $$\\frac{f}{\\alpha_{\\mathrm{J}} + \\gamma_{\\mathrm{J}}\\,n^{\\ast}} = \\frac{f}{\\alpha_{\\mathrm{P}} + \\gamma_{\\mathrm{P}}\\,n^{\\ast}}$$\n    Since the CPU frequency $f$ is a positive constant, this equality holds if and only if the denominators are equal. This means the break-even point occurs when the CPU cost per message is the same for both formats.\n    $$\\alpha_{\\mathrm{J}} + \\gamma_{\\mathrm{J}}\\,n^{\\ast} = \\alpha_{\\mathrm{P}} + \\gamma_{\\mathrm{P}}\\,n^{\\ast}$$\n\n4.  **Solve for $n^{\\ast}$**\n    We rearrange the equation to solve for $n^{\\ast}$:\n    $$\\gamma_{\\mathrm{J}}\\,n^{\\ast} - \\gamma_{\\mathrm{P}}\\,n^{\\ast} = \\alpha_{\\mathrm{P}} - \\alpha_{\\mathrm{J}}$$\n    $$(\\gamma_{\\mathrm{J}} - \\gamma_{\\mathrm{P}})\\,n^{\\ast} = \\alpha_{\\mathrm{P}} - \\alpha_{\\mathrm{J}}$$\n    $$n^{\\ast} = \\frac{\\alpha_{\\mathrm{P}} - \\alpha_{\\mathrm{J}}}{\\gamma_{\\mathrm{J}} - \\gamma_{\\mathrm{P}}}$$\n    This symbolic result shows that the break-even point depends only on the fixed and per-field costs, not on the absolute CPU speed.\n\n5.  **Substitute Numerical Values and Calculate**\n    We substitute the given values:\n    - $\\alpha_{\\mathrm{J}} = 1.2 \\times 10^{5}$ cycles\n    - $\\gamma_{\\mathrm{J}} = 1.6 \\times 10^{4}$ cycles/field\n    - $\\alpha_{\\mathrm{P}} = 1.8 \\times 10^{5}$ cycles\n    - $\\gamma_{\\mathrm{P}} = 3.2 \\times 10^{3}$ cycles/field\n\n    $$n^{\\ast} = \\frac{(1.8 \\times 10^{5}) - (1.2 \\times 10^{5})}{(1.6 \\times 10^{4}) - (3.2 \\times 10^{3})}$$\n    $$n^{\\ast} = \\frac{0.6 \\times 10^{5}}{16 \\times 10^{3} - 3.2 \\times 10^{3}} = \\frac{6 \\times 10^{4}}{12.8 \\times 10^{3}}$$\n    $$n^{\\ast} = \\frac{60}{12.8} = \\frac{600}{128}$$\n\n6.  **Simplify to an Exact Fraction**\n    We simplify the fraction $\\frac{600}{128}$ by dividing the numerator and denominator by their greatest common divisor.\n    - Divide by 4: $\\frac{600 \\div 4}{128 \\div 4} = \\frac{150}{32}$\n    - Divide by 2: $\\frac{150 \\div 2}{32 \\div 2} = \\frac{75}{16}$\n    The numerator $75 = 3 \\times 5^2$ and the denominator $16 = 2^4$ share no common factors, so this is the simplest form.",
            "answer": "$$\n\\boxed{\\frac{75}{16}}\n$$"
        },
        {
            "introduction": "Communication in distributed systems relies on Remote Procedure Calls (RPCs), but network latency is inherently variable and packet loss is a reality. This practice introduces a foundational technique for building reliable services: adaptive timeouts. You will apply an Exponentially Weighted Moving Average (EWMA) to estimate network Round-Trip Time ($RTT$) and its variance, a method famously used in TCP.  This allows you to calculate a timeout value that intelligently balances the need for quick failure detection against the cost of unnecessary retransmissions.",
            "id": "3636314",
            "problem": "A service in a distributed cluster uses Remote Procedure Call (RPC) to coordinate tasks. The system retransmits a request if the response does not arrive before a timeout. To avoid both unnecessary retries and excessive waiting, the system sets the timeout adaptively based on the current estimate of the network Round-Trip Time (RTT). The system estimates the RTT mean and variability using the Exponentially Weighted Moving Average (EWMA), and models instantaneous RTT as the sum of many independent delay components arising from queueing, serialization, and propagation. By the Central Limit Theorem, the instantaneous RTT is modeled as approximately normally distributed.\n\nAt discrete time $t$, let the observed RTT sample be $r_t$. The EWMA mean estimate $\\hat{r}_t$ is defined by the core recursive smoothing rule\n$$\n\\hat{r}_t = (1-\\alpha)\\,\\hat{r}_{t-1} + \\alpha\\, r_t,\n$$\nwhere $\\alpha \\in (0,1)$ is the smoothing parameter. To estimate dispersion, define the EWMA of squared deviations $v_t$ by\n$$\nv_t = (1-\\alpha)\\,v_{t-1} + \\alpha\\,\\big(r_t - \\hat{r}_{t-1}\\big)^{2},\n$$\nand take the estimated standard deviation to be $\\hat{\\sigma}_t = \\sqrt{v_t}$.\n\nSuppose at time $t=0$ the system has initial mean estimate $\\hat{r}_0 = 18\\,\\mathrm{ms}$ and initial variance estimate $v_0 = 9\\,\\mathrm{ms}^{2}$, and uses smoothing parameter $\\alpha = 0.3$. Over the next four RPCs, it observes RTT samples\n$$\nr_1 = 21\\,\\mathrm{ms},\\quad r_2 = 15\\,\\mathrm{ms},\\quad r_3 = 24\\,\\mathrm{ms},\\quad r_4 = 18\\,\\mathrm{ms}.\n$$\n\nThe cluster operator requires that, under the normal model with parameters given by the current EWMA estimates, the probability that a single RTT sample exceeds the timeout due solely to random variation (a “false timeout”) must be $\\beta = 0.01$ per attempt. The timeout is set to the smallest value that satisfies this requirement for the current time $t=4$.\n\nUsing only these foundations, compute the numerical value of the timeout at $t=4$. Express your final answer in milliseconds and round your result to four significant figures.",
            "solution": "The problem requires the calculation of an adaptive timeout for a Remote Procedure Call (RPC) based on statistical estimates of the network's Round-Trip Time (RTT). The problem is well-posed, scientifically grounded, and contains all necessary information for a unique solution. We will proceed by first iteratively computing the Exponentially Weighted Moving Average (EWMA) for the mean and variance of the RTT, and then using these estimates to determine the timeout value that satisfies the specified false timeout probability.\n\nThe given initial conditions at time $t=0$ are:\n- Initial mean estimate: $\\hat{r}_0 = 18\\,\\mathrm{ms}$\n- Initial variance estimate: $v_0 = 9\\,\\mathrm{ms}^{2}$\n- Smoothing parameter: $\\alpha = 0.3$\n\nThe recursive rules for updating the estimates at time $t$ are:\n- Mean estimate: $\\hat{r}_t = (1-\\alpha)\\,\\hat{r}_{t-1} + \\alpha\\, r_t$\n- Variance estimate: $v_t = (1-\\alpha)\\,v_{t-1} + \\alpha\\,\\big(r_t - \\hat{r}_{t-1}\\big)^{2}$\n- Standard deviation estimate: $\\hat{\\sigma}_t = \\sqrt{v_t}$\n\nThe observed RTT samples are $r_1 = 21\\,\\mathrm{ms}$, $r_2 = 15\\,\\mathrm{ms}$, $r_3 = 24\\,\\mathrm{ms}$, and $r_4 = 18\\,\\mathrm{ms}$. We compute the estimates for $t=1, 2, 3, 4$. For clarity, we note that $1-\\alpha = 1 - 0.3 = 0.7$. All units of time are in milliseconds ($\\mathrm{ms}$) and variance in $\\mathrm{ms}^2$.\n\n**Step 1: Compute estimates for $t=1$**\nUsing the sample $r_1 = 21$:\n$$\n\\hat{r}_1 = (1-\\alpha)\\hat{r}_0 + \\alpha r_1 = (0.7)(18) + (0.3)(21) = 12.6 + 6.3 = 18.9\n$$\n$$\nv_1 = (1-\\alpha)v_0 + \\alpha(r_1 - \\hat{r}_0)^2 = (0.7)(9) + (0.3)(21 - 18)^2 = 6.3 + 0.3(3^2) = 6.3 + 2.7 = 9.0\n$$\n\n**Step 2: Compute estimates for $t=2$**\nUsing the sample $r_2 = 15$ and the estimates from $t=1$:\n$$\n\\hat{r}_2 = (1-\\alpha)\\hat{r}_1 + \\alpha r_2 = (0.7)(18.9) + (0.3)(15) = 13.23 + 4.5 = 17.73\n$$\n$$\nv_2 = (1-\\alpha)v_1 + \\alpha(r_2 - \\hat{r}_1)^2 = (0.7)(9.0) + (0.3)(15 - 18.9)^2 = 6.3 + 0.3(-3.9)^2 = 6.3 + 0.3(15.21) = 6.3 + 4.563 = 10.863\n$$\n\n**Step 3: Compute estimates for $t=3$**\nUsing the sample $r_3 = 24$ and the estimates from $t=2$:\n$$\n\\hat{r}_3 = (1-\\alpha)\\hat{r}_2 + \\alpha r_3 = (0.7)(17.73) + (0.3)(24) = 12.411 + 7.2 = 19.611\n$$\n$$\nv_3 = (1-\\alpha)v_2 + \\alpha(r_3 - \\hat{r}_2)^2 = (0.7)(10.863) + (0.3)(24 - 17.73)^2 = 7.6041 + 0.3(6.27)^2 = 7.6041 + 0.3(39.3129) \\approx 7.6041 + 11.7939 = 19.398\n$$\nFor higher precision, we retain more figures: $v_3 = 7.6041 + 11.79387 = 19.39797$.\n\n**Step 4: Compute estimates for $t=4$**\nUsing the sample $r_4 = 18$ and the estimates from $t=3$:\n$$\n\\hat{r}_4 = (1-\\alpha)\\hat{r}_3 + \\alpha r_4 = (0.7)(19.611) + (0.3)(18) = 13.7277 + 5.4 = 19.1277\n$$\n$$\nv_4 = (1-\\alpha)v_3 + \\alpha(r_4 - \\hat{r}_3)^2 = (0.7)(19.39797) + (0.3)(18 - 19.611)^2 = 13.578579 + 0.3(-1.611)^2 = 13.578579 + 0.3(2.595321) \\approx 13.578579 + 0.778596 = 14.357175\n$$\nAt time $t=4$, the final estimated mean and variance are:\n$$\n\\hat{r}_4 = 19.1277\\,\\mathrm{ms}\n$$\n$$\nv_4 = 14.357175\\,\\mathrm{ms}^2\n$$\nThe corresponding standard deviation is:\n$$\n\\hat{\\sigma}_4 = \\sqrt{v_4} = \\sqrt{14.357175} \\approx 3.789086\\,\\mathrm{ms}\n$$\n\n**Step 5: Compute the Timeout**\nThe instantaneous RTT, let's call the random variable $R$, is modeled as a normal distribution with the parameters estimated at $t=4$. Thus, $R \\sim \\mathcal{N}(\\mu, \\sigma^2)$ where $\\mu = \\hat{r}_4$ and $\\sigma = \\hat{\\sigma}_4$.\nThe timeout, $T_o$, must be set such that the probability of a false timeout is $\\beta = 0.01$. This means the probability that an observed RTT $R$ exceeds $T_o$ is $0.01$:\n$$\nP(R > T_o) = \\beta = 0.01\n$$\nTo find $T_o$, we standardize the variable $R$. Let $Z = \\frac{R-\\mu}{\\sigma}$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0, 1)$.\n$$\nP\\left(\\frac{R-\\mu}{\\sigma} > \\frac{T_o-\\mu}{\\sigma}\\right) = P\\left(Z > \\frac{T_o-\\mu}{\\sigma}\\right) = 0.01\n$$\nWe need to find the critical value $z_{0.01}$ from the standard normal distribution such that $P(Z > z_{0.01}) = 0.01$. This value corresponds to the $99^{th}$ percentile of the distribution, as $P(Z \\le z_{0.01}) = 1 - 0.01 = 0.99$. Consulting a standard normal distribution table or using a computational tool, we find:\n$$\nz_{0.01} \\approx 2.3263\n$$\nThe timeout $T_o$ is determined by the equation:\n$$\n\\frac{T_o - \\mu}{\\sigma} = z_{0.01}\n$$\n$$\nT_o = \\mu + z_{0.01} \\sigma = \\hat{r}_4 + z_{0.01} \\hat{\\sigma}_4\n$$\nSubstituting the calculated values for $\\hat{r}_4$ and $\\hat{\\sigma}_4$:\n$$\nT_o = 19.1277 + (2.3263) \\times (\\sqrt{14.357175})\n$$\n$$\nT_o \\approx 19.1277 + (2.3263) \\times (3.789086)\n$$\n$$\nT_o \\approx 19.1277 + 8.8150\n$$\n$$\nT_o \\approx 27.9427\\,\\mathrm{ms}\n$$\nThe problem requires the result to be rounded to four significant figures. The value $27.9427$ rounded to four significant figures is $27.94$.",
            "answer": "$$\\boxed{27.94}$$"
        },
        {
            "introduction": "How can a large, dynamic cluster of nodes efficiently share information and converge on a consistent state? Gossip (or anti-entropy) protocols provide a robust and scalable answer. This exercise moves from point-to-point communication to system-wide behavior, asking you to analyze the network bandwidth consumed by such a protocol. Using first principles of probability, you will calculate the expected communication overhead, gaining a deeper understanding of the costs associated with achieving eventual consistency in large-scale systems. ",
            "id": "3636305",
            "problem": "Consider a cluster of $N$ nodes running a gossip anti-entropy protocol. Time is divided into periods of length $P$ seconds. In every period, each node independently initiates exactly one anti-entropy session with a peer chosen uniformly at random from the other $N-1$ nodes (self-selection is disallowed). Each anti-entropy session consists of a bidirectional exchange of a digest of size $g$ bytes: each participant sends exactly one digest of size $g$ bytes and receives exactly one digest of size $g$ bytes from its peer. Assume negligible headers and control traffic beyond the digest payloads, no retries, and that two nodes choosing each other in the same period results in two distinct sessions. Assume sessions complete within the same period in which they are initiated and that initiations across nodes are independent.\n\nUsing only fundamental definitions of bandwidth as bytes per unit time and the linearity of expectation for independent Bernoulli trials, derive from first principles the expected steady-state:\n\n- per-node aggregate bandwidth (sum of transmitted and received bytes per second), and\n- cluster-wide network throughput (total bytes transmitted over network links per second, counting each digest once as it traverses the network),\n\nexpressed in terms of $N$, $g$, and $P$. Express your answers in bytes per second. Provide the final results as a single row vector with the first entry being the per-node aggregate bandwidth and the second entry being the cluster-wide throughput. No numerical substitution is required; express your final answer symbolically.",
            "solution": "The objective is to compute expected bandwidths based on the rate at which bytes are transferred due to the protocol behavior.\n\nBandwidth is defined as bytes per unit time. Therefore, if an entity transfers an expected number of bytes $B_{\\text{period}}$ in each period of length $P$, its expected bandwidth is $B_{\\text{period}}/P$.\n\nWe analyze two quantities:\n\n1. Expected per-node aggregate bandwidth, which sums bytes transmitted and received by a single node.\n2. Expected cluster-wide throughput, which sums bytes transmitted over the network links (counting each digest once) across all nodes.\n\nWe start with per-node analysis. In each period, each node initiates exactly one session. In addition, other nodes may initiate sessions targeting this node.\n\nLet us fix a node and denote by $X$ the random variable equal to the number of incoming sessions (initiated by other nodes that target this node) in one period. For each other node (there are $N-1$ such nodes), define indicator random variables $I_{i}$ for $i \\in \\{1,2,\\ldots,N-1\\}$, where $I_{i} = 1$ if that node chooses our fixed node as its peer, and $I_{i} = 0$ otherwise. Because each node chooses uniformly from $N-1$ possible peers and choices are independent,\n$$\n\\Pr(I_{i} = 1) = \\frac{1}{N-1}.\n$$\nThus, $X = \\sum_{i=1}^{N-1} I_{i}$ and by linearity of expectation,\n$$\n\\mathbb{E}[X] = \\sum_{i=1}^{N-1} \\mathbb{E}[I_{i}] = \\sum_{i=1}^{N-1} \\frac{1}{N-1} = 1.\n$$\nTherefore, in expectation, a node receives $1$ incoming session per period in addition to the $1$ session it initiates, so it participates in an expected total of $1 + 1 = 2$ sessions per period.\n\nEach session is bidirectional: the node sends a digest of size $g$ bytes and receives a digest of size $g$ bytes. Therefore, the aggregate bytes accounted to the node per session (transmit plus receive) is $2g$. With an expected $2$ sessions per period, the expected per-node aggregate bytes per period is\n$$\nB_{\\text{node, period}} = 2 \\times 2g = 4g.\n$$\nDividing by the period length $P$ to obtain a rate gives the expected per-node aggregate bandwidth:\n$$\nB_{\\text{node}} = \\frac{4g}{P}.\n$$\n\nNext, we compute the cluster-wide network throughput, counting each digest once as it traverses the network. There are exactly $N$ initiated sessions per period because each node initiates one session. Each session produces two digest transmissions over the network, one in each direction, for a total of $2g$ bytes transmitted per session. Therefore, the expected total bytes transmitted over the network in one period is\n$$\nB_{\\text{cluster, period}} = N \\times 2g = 2gN.\n$$\nDividing by $P$ yields the cluster-wide throughput:\n$$\nB_{\\text{cluster}} = \\frac{2gN}{P}.\n$$\n\nCollecting the two expressions, the per-node aggregate bandwidth is $\\frac{4g}{P}$ and the cluster-wide throughput is $\\frac{2gN}{P}$, both in bytes per second.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{4g}{P} & \\frac{2gN}{P}\\end{pmatrix}}$$"
        }
    ]
}