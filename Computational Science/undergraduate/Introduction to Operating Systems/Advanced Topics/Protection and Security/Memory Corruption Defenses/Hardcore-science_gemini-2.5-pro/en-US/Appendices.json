{
    "hands_on_practices": [
        {
            "introduction": "Address Space Layout Randomization (ASLR) is a cornerstone of modern security, but how much protection does it actually provide? This exercise guides you through a quantitative analysis of ASLR's effectiveness against brute-force attacks. By modeling the attack as a series of probabilistic trials, you will derive the expected time to compromise a system, directly linking the number of entropy bits ($b$) to a tangible measure of security .",
            "id": "3657054",
            "problem": "An operating system employs Address Space Layout Randomization (ASLR), which randomizes a critical code pointer’s base address uniformly over a pool of $2^{b}$ distinct possibilities on every process restart. An attacker attempts a brute-force overwrite: each guess independently targets one candidate address; if the guess is incorrect, the process crashes and is automatically restarted by the system. Due to crash handling and restart overhead, the observed steady-state attempt rate is $\\lambda$ attempts per second, and attempts are independent with identical success probability per guess. Assume the selection among $2^{b}$ addresses is uniform and independent across restarts, and that guesses are independent of the randomization.\n\nStarting from the core definitions of independent Bernoulli trials and the geometric distribution, derive an expression for the expected wall-clock time to the first successful overwrite as a function of $b$ and $\\lambda$. Then, for $b=16$ and $b=32$, compute the ratio $R$ of the expected time at $b=32$ to that at $b=16$. Provide the exact value of $R$ as a unitless number. In addition, explain in words how $\\lambda$ influences practicality, but do not use any numerical values in your explanation. Only the ratio $R$ should be reported as the final answer, and it must be unitless and exact.",
            "solution": "The problem statement is critically validated before proceeding to a solution.\n\n### Step 1: Extract Givens\n- The number of distinct possibilities for the critical code pointer's base address is $2^b$.\n- The randomization is uniform over these $2^b$ possibilities on every process restart.\n- An attacker attempts a brute-force overwrite.\n- Each guess independently targets one candidate address.\n- An incorrect guess leads to a process crash and automatic restart.\n- The steady-state attempt rate is $\\lambda$ attempts per second.\n- Attempts are independent with identical success probability per guess.\n- The selection of the address is uniform and independent across restarts.\n- Guesses are independent of the randomization.\n- The first task is to derive an expression for the expected wall-clock time to the first successful overwrite as a function of $b$ and $\\lambda$, starting from core definitions.\n- The second task is to compute the ratio $R$ of the expected time at $b=32$ to that at $b=16$.\n- The final answer must be the exact, unitless value of $R$.\n- An explanation of how $\\lambda$ influences practicality, without numerical values, is also required.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the established criteria.\n- **Scientifically Grounded**: The problem is well-grounded in the principles of computer security and probability theory. Address Space Layout Randomization (ASLR) is a standard defense mechanism in modern operating systems. The modeling of a brute-force attack as a sequence of independent trials is a standard and valid approach in security analysis. The concepts of uniform probability distributions, Bernoulli trials, and the geometric distribution are fundamental to mathematics and statistics.\n- **Well-Posed**: The problem provides all necessary information to derive the requested expression and compute the ratio. The parameters $b$ and $\\lambda$ are defined, and the probabilistic model is specified. A unique and stable solution can be determined.\n- **Objective**: The problem is stated using precise, objective language common in scientific and engineering disciplines. It is free from subjective or opinion-based statements.\n\nThe problem exhibits none of the invalidating flaws. It is not scientifically unsound, is directly formalizable, is complete, is scientifically plausible, is well-posed, and is a non-trivial application of core principles.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n### Derivation of Expected Time\n\nLet $N$ be the random variable representing the number of attempts required to achieve the first successful overwrite. The problem states that the base address is chosen uniformly from a set of $2^b$ distinct possibilities. An attacker makes a single, independent guess. The probability of success for any individual attempt, denoted by $p$, is therefore:\n$$p = \\frac{1}{2^b}$$\nEach guess is an independent trial, as the address is re-randomized upon every failure and subsequent restart. This scenario describes a sequence of independent Bernoulli trials, each with a success probability of $p$. The number of trials $N$ needed to obtain the first success follows a geometric distribution.\n\nThe probability mass function for the geometric distribution is given by $P(N=k) = (1-p)^{k-1}p$ for $k = 1, 2, 3, \\dots$. The expected value of a geometrically distributed random variable is the reciprocal of the success probability. Therefore, the expected number of attempts to the first success, $E[N]$, is:\n$$E[N] = \\frac{1}{p}$$\nSubstituting the expression for $p$:\n$$E[N] = \\frac{1}{1/2^b} = 2^b$$\nThis gives the expected number of attempts (or equivalently, crashes) before a success.\n\nThe problem asks for the expected *wall-clock time* to the first success, which we denote as $E[T]$. We are given that the steady-state attempt rate is $\\lambda$ attempts per second. This rate incorporates all overhead, including crash handling and process restart. The average time elapsed per attempt is the reciprocal of this rate, i.e., $\\frac{1}{\\lambda}$ seconds per attempt.\n\nThe total wall-clock time $T$ is the product of the number of attempts $N$ and the time per attempt. By the linearity of expectation, the expected total time is the expected number of attempts multiplied by the average time per attempt.\n$$E[T] = E[N] \\times (\\text{Time per attempt})$$\n$$E[T] = 2^b \\times \\frac{1}{\\lambda} = \\frac{2^b}{\\lambda}$$\nThis is the expression for the expected wall-clock time to the first successful overwrite as a function of $b$ and $\\lambda$.\n\n### Calculation of the Ratio $R$\n\nThe problem requires calculating the ratio $R$ of the expected time for an entropy of $b=32$ bits to the expected time for an entropy of $b=16$ bits. Let $E[T_{32}]$ denote the expected time when $b=32$, and $E[T_{16}]$ denote the expected time when $b=16$.\n\nUsing the derived formula for $E[T]$:\n$$E[T_{32}] = \\frac{2^{32}}{\\lambda}$$\n$$E[T_{16}] = \\frac{2^{16}}{\\lambda}$$\nThe ratio $R$ is defined as:\n$$R = \\frac{E[T_{32}]}{E[T_{16}]}$$\nSubstituting the expressions:\n$$R = \\frac{2^{32}/\\lambda}{2^{16}/\\lambda} = \\frac{2^{32}}{2^{16}}$$\nUsing the property of exponents, $x^a / x^c = x^{a-c}$:\n$$R = 2^{32-16} = 2^{16}$$\nNow, we compute the exact numerical value of $2^{16}$:\n$$2^{16} = (2^8)^2 = 256^2 = 65536$$\nAlternatively, $2^{16} = 2^6 \\times 2^{10} = 64 \\times 1024 = 65536$.\n\nThe ratio $R$ is exactly $65536$.\n\n### Influence of $\\lambda$ on Practicality\n\nThe expected time to a successful attack, $E[T] = \\frac{2^b}{\\lambda}$, is inversely proportional to the attempt rate $\\lambda$. The parameter $\\lambda$ quantifies the practical speed at which an attacker can execute guesses, accounting for all system-level overheads like process creation, crash detection, and logging. A higher value of $\\lambda$ implies a more efficient attack, where the time between consecutive attempts is short. This reduces the overall expected time to compromise, making the brute-force attack more feasible within a given timeframe. Conversely, a lower value of $\\lambda$ signifies significant overhead per attempt, which lengthens the interval between guesses. This increases the total expected time to success, thereby making the attack less practical and bolstering the effective security provided by the ASLR mechanism. Thus, system performance in handling crashes is a critical factor in determining the practical security of ASLR against brute-force attacks.",
            "answer": "$$\\boxed{65536}$$"
        },
        {
            "introduction": "Stack canaries are a powerful defense, but their design involves subtle trade-offs. This practice explores a common engineering decision: modifying canaries to avoid problematic byte values, such as null terminators, to prevent bugs in string handling functions. You will use the principles of information theory to quantify the resulting loss in entropy and calculate how this design choice affects the probability of an attack succeeding by pure chance .",
            "id": "3657006",
            "problem": "A system deploys a stack canary to detect memory corruption. In the unconstrained design, the canary is $m$ independent bytes uniformly random over the set of all $256$ byte values, yielding full $8m$ bits of entropy. To reduce interactions with text-handling bugs, an engineer proposes to encode the canary so that every canary byte avoids the two byte values $0x00$ and $0x0A$. You are asked to formalize this design and quantify its security properties.\n\nAdopt the following model grounded in standard probability and information theory. Each canary byte is produced by rejection sampling from an ideal source of independent, uniform $8$-bit values: draw a byte uniformly from $\\{0,1,\\dots,255\\}$ and, if it equals $0x00$ or $0x0A$, discard and redraw until it falls in the allowed alphabet of size $256-2=254$. This yields $m$ independent, uniformly distributed symbols over an alphabet of size $254$. Use the Shannon entropy definition $H(X) = - \\sum_{x} \\Pr[X=x] \\log_{2} \\Pr[X=x]$, with independence implying additivity of entropies for product distributions.\n\nAssume $m=8$. Let $\\Delta b$ denote the entropy loss in bits compared to the unconstrained $8$-byte canary. Next, consider an accidental overwrite that writes $m$ bytes independently, each byte uniformly random over all $256$ values, into the canary’s memory region. The overwrite is invisible if, after the write, the canary check still matches the originally stored canary exactly. Let $p$ denote the probability of such accidental overwrite invisibility under this model.\n\nCompute $\\Delta b$ and $p$ for $m=8$, and present the numerical values rounded to four significant figures. Express the entropy loss in bits; express the probability as a decimal (not a percentage). Provide your final answer as two entries in a single row, in the order $\\Delta b$, then $p$.",
            "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded in probability and information theory, well-posed with sufficient information for a unique solution, and formally objective. We may proceed with the solution.\n\nThe problem asks for two quantities: the entropy loss $\\Delta b$ in the constrained canary design and the probability $p$ of an accidental overwrite going undetected. We are given the canary size is $m=8$ bytes.\n\nFirst, we compute the entropy loss $\\Delta b$.\nThe entropy of a random variable $X$ is given by the Shannon formula $H(X) = - \\sum_{x} \\Pr[X=x] \\log_{2} \\Pr[X=x]$. For a variable uniformly distributed over a set of size $N$, the probability of any single outcome is $\\frac{1}{N}$, so the entropy simplifies to $H = - \\sum_{i=1}^{N} \\frac{1}{N} \\log_{2}\\left(\\frac{1}{N}\\right) = -N \\left(\\frac{1}{N}\\right) (-\\log_{2} N) = \\log_{2} N$.\n\nThe unconstrained canary consists of $m$ independent bytes, each uniformly chosen from an alphabet of size $N_{unc} = 256$. The total entropy, $H_{unc}$, is the sum of the entropies of the individual bytes due to their independence:\n$$H_{unc} = m \\times \\log_{2}(256)$$\nSince $\\log_{2}(256) = \\log_{2}(2^{8}) = 8$, the entropy is:\n$$H_{unc} = 8m \\text{ bits}$$\n\nThe constrained canary also consists of $m$ independent bytes, but each is uniformly chosen from an alphabet of allowed values. The problem states that two byte values, $0x00$ and $0x0A$, are forbidden. This leaves an alphabet of size $N_{con} = 256 - 2 = 254$. The total entropy of the constrained canary, $H_{con}$, is:\n$$H_{con} = m \\times \\log_{2}(254)$$\n\nThe entropy loss, $\\Delta b$, is the difference between the entropy of the unconstrained and constrained designs:\n$$\\Delta b = H_{unc} - H_{con} = 8m - m \\log_{2}(254)$$\nFactoring out $m$ and using the properties of logarithms:\n$$\\Delta b = m (8 - \\log_{2}(254)) = m (\\log_{2}(256) - \\log_{2}(254)) = m \\log_{2}\\left(\\frac{256}{254}\\right)$$\nSubstituting the given value $m=8$:\n$$\\Delta b = 8 \\log_{2}\\left(\\frac{256}{254}\\right) = 8 \\log_{2}\\left(\\frac{128}{127}\\right)$$\nTo compute the numerical value, we use the change of base formula, $\\log_{2}(x) = \\frac{\\ln(x)}{\\ln(2)}$:\n$$\\Delta b = 8 \\frac{\\ln(256/254)}{\\ln(2)} \\approx 8 \\frac{\\ln(1.007874)}{\\ln(2)} \\approx 8 \\frac{0.0078431}{0.693147} \\approx 8 \\times 0.011315 \\approx 0.09052016$$\nRounding to four significant figures, the entropy loss is $\\Delta b \\approx 0.09052$ bits.\n\nNext, we compute the probability $p$ that an accidental overwrite is invisible.\nLet $C = (C_1, C_2, \\dots, C_m)$ be the random vector representing the originally stored canary. Each component $C_i$ is an independent random variable uniformly distributed over the set of allowed bytes, $\\mathcal{A}$, where $|\\mathcal{A}| = 254$. So, for any byte value $k \\in \\mathcal{A}$, $\\Pr[C_i=k] = \\frac{1}{254}$.\n\nLet $W = (W_1, W_2, \\dots, W_m)$ be the random vector representing the bytes written by the overwrite. Each component $W_i$ is an independent random variable uniformly distributed over the set of all possible byte values, $\\mathcal{B}$, where $|\\mathcal{B}| = 256$. So, for any byte value $k \\in \\mathcal{B}$, $\\Pr[W_i=k] = \\frac{1}{256}$.\n\nThe overwrite is invisible if the written canary $W$ is identical to the original canary $C$. We need to compute $p = \\Pr[W=C]$. The vectors $C$ and $W$ are independent. Due to the independence of the individual bytes within each vector, the probability of a full match is the product of the probabilities of matching for each byte:\n$$p = \\Pr[W_1 = C_1, W_2 = C_2, \\dots, W_m = C_m] = \\prod_{i=1}^{m} \\Pr[W_i = C_i]$$\nLet's compute the probability of a single-byte match, $\\Pr[W_i = C_i]$. We can find this by summing over all possible matching values. A match can only occur if the value is in the allowed set $\\mathcal{A}$.\n$$\\Pr[W_i = C_i] = \\sum_{k \\in \\mathcal{A}} \\Pr[W_i = k \\text{ and } C_i = k]$$\nSince $W_i$ and $C_i$ are independent:\n$$\\Pr[W_i = C_i] = \\sum_{k \\in \\mathcal{A}} \\Pr[W_i = k] \\Pr[C_i = k]$$\nSubstituting the probabilities:\n$$\\Pr[W_i = C_i] = \\sum_{k \\in \\mathcal{A}} \\left(\\frac{1}{256}\\right) \\left(\\frac{1}{254}\\right)$$\nThe term inside the summation is constant for all $k \\in \\mathcal{A}$. The size of the set $\\mathcal{A}$ is $254$.\n$$\\Pr[W_i = C_i] = |\\mathcal{A}| \\times \\left(\\frac{1}{256} \\times \\frac{1}{254}\\right) = 254 \\times \\frac{1}{256 \\times 254} = \\frac{1}{256}$$\nThe probability of a single-byte match is $\\frac{1}{256}$. Thus, the probability of an $m$-byte match is:\n$$p = \\left(\\frac{1}{256}\\right)^m$$\nSubstituting $m=8$:\n$$p = \\left(\\frac{1}{256}\\right)^8 = (256)^{-8} = (2^8)^{-8} = 2^{-64}$$\nThe numerical value is:\n$$p = \\frac{1}{18,446,744,073,709,551,616} \\approx 5.42101086 \\times 10^{-20}$$\nRounding to four significant figures, the probability is $p \\approx 5.421 \\times 10^{-20}$.\n\nWe have computed both required values.\n$\\Delta b \\approx 0.09052$.\n$p \\approx 5.421 \\times 10^{-20}$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 0.09052 & 5.421 \\times 10^{-20} \\end{pmatrix}}$$"
        },
        {
            "introduction": "The security guarantees of ASLR are not absolute; they depend critically on how the operating system manages processes. This problem confronts a nuanced scenario: how does ASLR's protection differ in a server that `fork()`s child processes versus one that uses `execve()` for each new task? By analyzing the attacker's probability of success in each model, you will gain a deeper appreciation for how high-level application architecture can have profound security implications at the system level .",
            "id": "3656980",
            "problem": "A network service on a $64$-bit operating system is protected by Address Space Layout Randomization (ASLR). The operating system picks the heap base uniformly at random from a discrete set of $M$ equally likely candidate base addresses each time a process image is created by the execve system call. A child created by the fork system call inherits the exact address space, including the heap base, of its parent. Consider an attacker who attempts a heap-based buffer overflow that succeeds only if the attacker’s single guessed heap base matches the actual heap base for that attempt.\n\nAssume the following scenario. A persistent parent process is started once via execve and then handles each client connection by forking a child; if a child crashes, the parent remains alive and forks a new child on the next connection. Thus, across attempts within the lifetime of the parent, the heap base does not change unless the parent itself is restarted via execve. Alternatively, consider a design where each connection is handled by launching a fresh process with execve, which re-randomizes the heap base on every attempt.\n\nThe attacker performs $k$ sequential attempts against the service on the same machine. In each attempt, the attacker makes exactly one guess of the heap base. The attacker can choose the strategy for selecting guesses. Let $S$ denote the random variable equal to the number of successful exploits over the $k$ attempts. Assume $k \\le M$ and that the attacker knows $M$ but not the actual heap base.\n\nWhich of the following statements are correct? Select all that apply.\n\nA. In the fork-without-exec scenario (same heap base across attempts), the optimal strategy is to try distinct heap-base guesses without replacement. The probability of at least $1$ success is $k/M$, and the expected number of successes is $E[S] = k/M$.\n\nB. In the execve-per-attempt scenario (independent heap base each attempt), if the attacker guesses uniformly from the $M$ candidates each time, the probability of at least $1$ success is $1 - (1 - 1/M)^{k}$, and the expected number of successes is $E[S] = k/M$.\n\nC. For $k \\ge 2$ and $M \\ge 2$, re-randomizing the heap base on every attempt via execve strictly increases the probability of at least $1$ success compared to the fork-without-exec scenario.\n\nD. In the fork-without-exec scenario, repeating the same heap-base guess on every attempt maximizes the probability of at least $1$ success across $k$ attempts.",
            "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded, well-posed, objective, and internally consistent, presenting a formalizable problem in the domain of operating systems security.\n\nThe problem asks us to evaluate four statements regarding the success probability of a heap-based buffer overflow attack under two different process management scenarios, both protected by Address Space Layout Randomization (ASLR).\n\nLet $M$ be the number of possible heap base addresses, from which the OS chooses one uniformly at random. Let $k$ be the number of attack attempts, where $k \\le M$. The attacker makes one guess per attempt. A success occurs if the guess matches the actual heap base. Let $S$ be the random variable for the total number of successes in $k$ attempts.\n\nFirst, we establish a key property. Let $I_i$ be the indicator random variable for a successful exploit on attempt $i$, for $i \\in \\{1, 2, ..., k\\}$. Thus, $S = \\sum_{i=1}^{k} I_i$. By the linearity of expectation, the expected number of successes is $E[S] = E[\\sum_{i=1}^{k} I_i] = \\sum_{i=1}^{k} E[I_i]$. For any single attempt $i$, the OS chooses a heap base $H_i$ uniformly at random from $M$ possibilities. The attacker makes a guess $g_i$. The probability of success for this attempt is $P(I_i=1) = P(g_i = H_i)$. Since $H_i$ is uniformly random, this probability is $1/M$, regardless of the attacker's choice of $g_i$ (as long as $g_i$ is a valid address candidate).\nIn the `fork`-without-`exec` scenario, the heap base is fixed, so $H_1=H_2=...=H_k=H$. The expectation for a single attempt is still $E[I_i] = P(g_i=H) = 1/M$.\nIn the `execve`-per-attempt scenario, the heap base is re-randomized, so $H_i$ are independent and identically distributed. The expectation is $E[I_i] = P(g_i=H_i) = 1/M$.\nTherefore, in both scenarios, $E[S] = \\sum_{i=1}^{k} (1/M) = k/M$. This holds for any guessing strategy.\n\nNow we analyze each option.\n\n### Option A Analysis\n\nThis option considers the **`fork`-without-`exec` scenario**, where the heap base is fixed for all $k$ attempts. Let the fixed, unknown heap base be $H$.\n\nThe statement is: \"In the fork-without-exec scenario (same heap base across attempts), the optimal strategy is to try distinct heap-base guesses without replacement. The probability of at least $1$ success is $k/M$, and the expected number of successes is $E[S] = k/M$.\"\n\n1.  **Optimal Strategy**: The attacker's goal in such a scenario is typically to achieve at least one successful exploit. The probability of at least one success is $P(S \\ge 1)$. The target address $H$ is fixed. If the attacker guesses an address $g$ and it fails ($g \\ne H$), re-using that same guess $g$ in a future attempt is pointless, as it is guaranteed to fail again. To maximize the chance of finding $H$, the attacker must explore as many unique unknown locations as possible. Therefore, the optimal strategy to maximize $P(S \\ge 1)$ is to choose $k$ distinct guesses, $\\{g_1, g_2, ..., g_k\\}$. This is effectively sampling without replacement from the set of possible addresses.\n\n2.  **Probability of at least 1 success**: With the optimal strategy of $k$ distinct guesses, the attacker succeeds if the true address $H$ is one of the $k$ addresses they guessed. Since $H$ was chosen uniformly at random from $M$ possibilities, the probability that it falls within the attacker's set of $k$ guesses is:\n    $$ P(S \\ge 1) = \\frac{k}{M} $$\n\n3.  **Expected Number of Successes**: As derived earlier, using the linearity of expectation, $E[S] = k/M$. This holds regardless of the strategy, so it is also true for the optimal strategy.\n\nAll parts of the statement in Option A are correct. The strategy is optimal for maximizing the probability of success, and the stated probability and expected value are correct for that strategy (and the expectation is correct for any strategy).\n\n**Verdict: Correct**\n\n### Option B Analysis\n\nThis option considers the **`execve`-per-attempt scenario**, where the heap base is re-randomized independently for each of the $k$ attempts.\n\nThe statement is: \"In the execve-per-attempt scenario (independent heap base each attempt), if the attacker guesses uniformly from the $M$ candidates each time, the probability of at least $1$ success is $1 - (1 - 1/M)^{k}$, and the expected number of successes is $E[S] = k/M$.\"\n\n1.  **Probabilistic Model**: Each of the $k$ attempts is an independent Bernoulli trial. For each attempt, the probability of success is $p = 1/M$, and the probability of failure is $q = 1 - p = 1 - 1/M$. The total number of successes $S$ follows a binomial distribution $S \\sim B(k, 1/M)$. The phrase \"if the attacker guesses uniformly from the $M$ candidates each time\" describes one possible strategy. However, the success probability $p=1/M$ on any given trial is independent of the attacker's guessing strategy, as the OS's choice is what is random. The correctness of the calculations does not depend on this specific strategy, but the statement is not made false by its inclusion.\n\n2.  **Probability of at least 1 success**: The probability of at least one success is $P(S \\ge 1) = 1 - P(S=0)$. The probability of zero successes is the probability of failing all $k$ independent attempts, which is $q^k$.\n    $$ P(S \\ge 1) = 1 - \\left(1 - \\frac{1}{M}\\right)^k $$\n    This part of the statement is correct.\n\n3.  **Expected Number of Successes**: For a binomial distribution $B(n, p)$, the expected value is $np$. Here, $n=k$ and $p=1/M$.\n    $$ E[S] = k \\cdot \\frac{1}{M} = \\frac{k}{M} $$\n    As shown in the initial analysis, this result is general. This part of the statement is also correct.\n\nAll parts of the statement in Option B are correct.\n\n**Verdict: Correct**\n\n### Option C Analysis\n\nThis option compares the probability of success in the two scenarios.\n\nThe statement is: \"For $k \\ge 2$ and $M \\ge 2$, re-randomizing the heap base on every attempt via execve strictly increases the probability of at least $1$ success compared to the fork-without-exec scenario.\"\n\nLet $P_{\\text{fork}}$ be the probability of at least $1$ success in the `fork` scenario and $P_{\\text{exec}}$ be the probability in the `execve` scenario. For the `fork` scenario, we assume the attacker uses the optimal strategy, yielding the maximum possible success probability.\n-   From A, $P_{\\text{fork}} = k/M$.\n-   From B, $P_{\\text{exec}} = 1 - (1 - 1/M)^k$.\n\nThe statement claims that $P_{\\text{exec}} > P_{\\text{fork}}$ for $k \\ge 2, M \\ge 2$.\nWe use Bernoulli's inequality, which states that for any real number $x > -1$ and integer $n \\ge 0$, $(1+x)^n \\ge 1+nx$. The inequality becomes strict, $(1+x)^n > 1+nx$, if $n \\ge 2$ and $x \\ne 0$.\n\nLet $x = -1/M$ and $n=k$. Since $M \\ge 2$, we have $x \\in [-1/2, 0)$, so $x > -1$ and $x \\ne 0$. Since $k \\ge 2$, the strict form of the inequality applies:\n$$ \\left(1 - \\frac{1}{M}\\right)^k > 1 - \\frac{k}{M} $$\nNow, we rearrange this inequality to compare $P_{\\text{exec}}$ and $P_{\\text{fork}}$:\n$$ -\\left(1 - \\frac{1}{M}\\right)^k  -\\left(1 - \\frac{k}{M}\\right) = \\frac{k}{M} - 1 $$\n$$ 1 - \\left(1 - \\frac{1}{M}\\right)^k  \\frac{k}{M} $$\nThis shows that $P_{\\text{exec}}  P_{\\text{fork}}$.\n\nTherefore, re-randomizing on every attempt strictly *decreases* the attacker's probability of achieving at least one success, compared to the `fork` scenario where the attacker can use an optimal search strategy. Intuitively, the `fork` scenario allows the attacker to perform a search without replacement, which is more efficient than the search with replacement that the `execve` scenario effectively forces.\n\n**Verdict: Incorrect**\n\n### Option D Analysis\n\nThis option proposes a specific strategy for the **`fork`-without-`exec` scenario**.\n\nThe statement is: \"In the fork-without-exec scenario, repeating the same heap-base guess on every attempt maximizes the probability of at least $1$ success across $k$ attempts.\"\n\nLet's analyze this strategy. The attacker chooses a single address, say $g_0$, and guesses it for all $k$ attempts. The heap base $H$ is fixed. A success occurs if and only if $g_0 = H$. The probability of this single event is:\n$$ P(S \\ge 1) = P(g_0 = H) = \\frac{1}{M} $$\nThis strategy results in a success probability of $1/M$.\n\nAs established in the analysis for Option A, the optimal strategy is to try $k$ distinct guesses, which yields a success probability of $k/M$. For the conditions of the problem, we have $k \\ge 1$. If $k=1$, the strategies are identical. If $k>1$, then $k/M > 1/M$. Since the problem is interesting for $k \\ge 2$ (as in option C), it's clear that repeating the guess is not optimal. It yields a lower probability of success than the distinct-guess strategy.\n\nTherefore, the statement that this strategy *maximizes* the probability is false.\n\n**Verdict: Incorrect**",
            "answer": "$$\\boxed{AB}$$"
        }
    ]
}