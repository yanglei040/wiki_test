{
    "hands_on_practices": [
        {
            "introduction": "Effective intrusion detection is fundamentally about managing and mitigating risk. In professional security engineering, it's not enough to simply detect an intrusion; we must also be able to articulate the value of our detection systems in concrete terms, such as the financial loss they help prevent. This exercise grounds this idea by modeling a security breach using core concepts from probability theory, allowing you to quantify the tangible benefit of a timely detection. By working through this scenario, you will learn to connect abstract system-level events to a quantitative risk assessment, a crucial skill for justifying security measures and making informed decisions. ",
            "id": "3650719",
            "problem": "A Linux operating system uses mount flags to mitigate classes of attacks at the filesystem boundary. The flags $noexec$, $nodev$, and $nosuid$ respectively prevent execution of binaries from a mount, creation or use of device files on a mount, and honoring set-user-identifier bits on a mount. An Intrusion Detection System (IDS) monitors the kernelâ€™s mount events; if an attacker removes these flags on a monitored mount, the IDS eventually detects and reverts the mount configuration. Assume the following model grounded in core definitions from probability and operating systems:\n\n- For each of the three attack vectors corresponding to the three flags, attacker attempts arrive as a Poisson process with constant rate $\\lambda_i$ attempts per hour when the mount is in a compromised state (flags removed).\n- Conditioned on an attempt, the probability of a successful compromise depends on whether the protective flag is present. With the flag present, the success probability is $\\alpha_i$. With the flag removed, the success probability is $\\beta_i$, where $\\beta_i > \\alpha_i$.\n- Each successful compromise on vector $i$ produces an expected monetary loss of $L_i$ dollars, independent across attempts and vectors.\n- The IDS detection-and-revert time $T$ after the flag-removal event is exponentially distributed with parameter $\\mu$ per hour due to memoryless polling and independent alerting delays.\n\nAssume the three vectors are independent, arrivals are independent of detection, and stationarity holds during the short detection window.\n\nA single mount event removes all three flags simultaneously on a critical mount, and remains in that state until the IDS reverts it. Quantify the expected additional monetary loss incurred during this window due to the flag removal, compared to the counterfactual where the flags had remained in place for the same duration. Use the following parameters:\n\n- For the $noexec$-related vector: $\\lambda_1 = 0.03$ per hour, $\\alpha_1 = 0.05$, $\\beta_1 = 0.60$, $L_1 = 3000$ dollars.\n- For the $nodev$-related vector: $\\lambda_2 = 0.004$ per hour, $\\alpha_2 = 0.02$, $\\beta_2 = 0.40$, $L_2 = 12000$ dollars.\n- For the $nosuid$-related vector: $\\lambda_3 = 0.015$ per hour, $\\alpha_3 = 0.01$, $\\beta_3 = 0.50$, $L_3 = 8000$ dollars.\n- IDS detection parameter: $\\mu = 0.5$ per hour.\n\nExpress the final result in dollars, and round your answer to $4$ significant figures.",
            "solution": "The problem asks for the expected additional monetary loss incurred during a window of vulnerability. This window begins when protective mount flags are removed and ends when an Intrusion Detection System (IDS) detects the change and reverts it. The duration of this window, $T$, is a random variable following an exponential distribution with rate parameter $\\mu$.\n\nLet $\\Delta L_{\\text{total}}$ be the total additional monetary loss. The problem states there are three independent attack vectors, indexed by $i \\in \\{1, 2, 3\\}$. By the linearity of expectation, the total expected additional loss is the sum of the expected additional losses for each vector:\n$$E[\\Delta L_{\\text{total}}] = \\sum_{i=1}^{3} E[\\Delta L_i]$$\nwhere $E[\\Delta L_i]$ is the expected additional loss for attack vector $i$.\n\nLet us analyze a single attack vector $i$.\nThe arrival of attack attempts is modeled as a Poisson process with rate $\\lambda_i$. A key property of a Poisson process is that if events are selected independently with a constant probability $p$, the resulting process of selected events is also a Poisson process with a rate of $\\lambda_i p$. This is known as Poisson thinning.\n\nIn our case, the events are successful compromises.\nWhen the protective flag is present, the probability of success is $\\alpha_i$. The rate of successful compromises is $\\lambda_i^{\\alpha} = \\lambda_i \\alpha_i$.\nWhen the protective flag is removed, the probability of success is $\\beta_i$. The rate of successful compromises is $\\lambda_i^{\\beta} = \\lambda_i \\beta_i$.\n\nThe loss is incurred over a random time interval $[0, T]$, where the probability density function of $T$ is $f_T(t) = \\mu \\exp(-\\mu t)$ for $t \\ge 0$. The expected duration of this interval is $E[T] = \\frac{1}{\\mu}$.\n\nThe additional loss for vector $i$, $\\Delta L_i$, is the difference between the loss that occurs with flags removed and the loss that would have occurred with flags present, over the same random duration $T$. Let $N_i^{\\beta}(t)$ and $N_i^{\\alpha}(t)$ be the number of successful compromises over a time interval $t$ with flags removed and present, respectively. These are random variables following Poisson distributions with parameters $\\lambda_i \\beta_i t$ and $\\lambda_i \\alpha_i t$. The associated losses are $L_i N_i^{\\beta}(T)$ and $L_i N_i^{\\alpha}(T)$.\n\nThe expected additional loss is:\n$$E[\\Delta L_i] = E[L_i N_i^{\\beta}(T) - L_i N_i^{\\alpha}(T)] = L_i \\left( E[N_i^{\\beta}(T)] - E[N_i^{\\alpha}(T)] \\right)$$\nTo find the expectation of $N(T)$, where $N(t)$ is a Poisson process with rate $\\lambda'$ and $T$ is an independent random variable, we use the Law of Total Expectation (also known as the tower property), $E[X] = E_Y[E[X|Y]]$.\n$$E[N(T)] = E_T[E[N(T)|T=t]]$$\nFor a fixed duration $t$, the expected number of events for a Poisson process with rate $\\lambda'$ is $E[N(t)] = \\lambda' t$.\n$$E[N(T)] = E_T[\\lambda' T] = \\lambda' E[T]$$\nSince $T$ is exponentially distributed with parameter $\\mu$, its expectation is $E[T] = \\frac{1}{\\mu}$.\nTherefore, the expected number of events over the random interval is:\n$$E[N(T)] = \\frac{\\lambda'}{\\mu}$$\nApplying this result to our two scenarios:\n$$E[N_i^{\\beta}(T)] = \\frac{\\lambda_i \\beta_i}{\\mu}$$\n$$E[N_i^{\\alpha}(T)] = \\frac{\\lambda_i \\alpha_i}{\\mu}$$\nSubstituting these back into the expression for the expected additional loss for vector $i$:\n$$E[\\Delta L_i] = L_i \\left( \\frac{\\lambda_i \\beta_i}{\\mu} - \\frac{\\lambda_i \\alpha_i}{\\mu} \\right) = \\frac{L_i \\lambda_i (\\beta_i - \\alpha_i)}{\\mu}$$\nThe total expected additional loss is the sum over all three vectors:\n$$E[\\Delta L_{\\text{total}}] = \\sum_{i=1}^{3} \\frac{L_i \\lambda_i (\\beta_i - \\alpha_i)}{\\mu} = \\frac{1}{\\mu} \\sum_{i=1}^{3} L_i \\lambda_i (\\beta_i - \\alpha_i)$$\nNow, we substitute the given parameters.\nThe IDS detection parameter is $\\mu = 0.5$ per hour.\n\nFor vector $i=1$ ($noexec$):\n$\\lambda_1 = 0.03$ per hour, $\\alpha_1 = 0.05$, $\\beta_1 = 0.60$, $L_1 = 3000$ dollars.\nTerm $1$: $L_1 \\lambda_1 (\\beta_1 - \\alpha_1) = 3000 \\times 0.03 \\times (0.60 - 0.05) = 3000 \\times 0.03 \\times 0.55 = 49.5$.\n\nFor vector $i=2$ ($nodev$):\n$\\lambda_2 = 0.004$ per hour, $\\alpha_2 = 0.02$, $\\beta_2 = 0.40$, $L_2 = 12000$ dollars.\nTerm $2$: $L_2 \\lambda_2 (\\beta_2 - \\alpha_2) = 12000 \\times 0.004 \\times (0.40 - 0.02) = 12000 \\times 0.004 \\times 0.38 = 18.24$.\n\nFor vector $i=3$ ($nosuid$):\n$\\lambda_3 = 0.015$ per hour, $\\alpha_3 = 0.01$, $\\beta_3 = 0.50$, $L_3 = 8000$ dollars.\nTerm $3$: $L_3 \\lambda_3 (\\beta_3 - \\alpha_3) = 8000 \\times 0.015 \\times (0.50 - 0.01) = 8000 \\times 0.015 \\times 0.49 = 58.8$.\n\nThe sum of these terms is:\n$$\\sum_{i=1}^{3} L_i \\lambda_i (\\beta_i - \\alpha_i) = 49.5 + 18.24 + 58.8 = 126.54$$\nFinally, we compute the total expected additional loss:\n$$E[\\Delta L_{\\text{total}}] = \\frac{1}{0.5} \\times 126.54 = 2 \\times 126.54 = 253.08$$\nThe problem requires the answer to be rounded to $4$ significant figures. The number $253.08$ rounded to four significant figures is $253.1$.\nThe expected additional loss, in dollars, is $253.1$.",
            "answer": "$$\\boxed{253.1}$$"
        },
        {
            "introduction": "One of the most powerful paradigms in intrusion detection is building a model of \"normal\" system behavior and then flagging any significant deviations, a technique known as anomaly detection. This approach is powerful because it doesn't require prior knowledge of specific attack signatures. This practice places you in the role of a security engineer using modern operating system features like control groups (cgroups) to establish a behavioral baseline for a running service. You will use fundamental statistical tools to decide when a deviation is significant enough to warrant an alert, while carefully tuning your system to manage the rate of false alarms. ",
            "id": "3650732",
            "problem": "An operating systems team uses Linux control groups (cgroups) to monitor the resource usage of a single network-facing service. At a fixed sampling interval of $\\Delta = 5\\,\\text{s}$, the system records two per-sample metrics for that service: Central Processing Unit (CPU) utilization fraction and Input/Output (I/O) throughput in $\\text{MB}/\\text{s}$. A sliding window of recent samples of length $W$ (with $W$ sufficiently large for stable estimation) is maintained to compute the empirical mean $\\hat{\\mu}$ and empirical standard deviation $\\hat{\\sigma}$ of each metric. At each sample time $t$, the system computes standardized scores (so-called $z$-scores) for CPU and I/O as $z_{\\text{cpu},t} = (x_{\\text{cpu},t} - \\hat{\\mu}_{\\text{cpu}})/\\hat{\\sigma}_{\\text{cpu}}$ and $z_{\\text{io},t} = (x_{\\text{io},t} - \\hat{\\mu}_{\\text{io}})/\\hat{\\sigma}_{\\text{io}}$. The anomaly policy declares an alert if either metric exhibits a sustained deviation beyond $3$ standard deviations, meaning that for at least $K$ consecutive samples, either $|z_{\\text{cpu},t}| > 3$ or $|z_{\\text{io},t}| > 3$ holds at each of those $K$ samples.\n\nAssume the following for benign (non-attack) operation:\n- The standardized scores for each metric are independent and identically distributed across time and are well modeled by a standard normal distribution $\\mathcal{N}(0,1)$ due to the sufficiently large window size $W$.\n- The CPU and I/O standardized scores are independent of each other at a given sample time.\n- Overlap effects between consecutive runs can be neglected for rare events, so that the probability that a run of $K$ consecutive threshold exceedances begins at any given sample is well approximated by the $K$th power of the single-sample exceedance probability.\n\nUsing only these assumptions, design the sustained-deviation length $K$ so that the expected number of false alerts over a benign monitoring period of $30$ days is at most $0.5$. Express your final answer as the smallest integer $K$ that achieves this target. Your answer must be a single integer (no units).",
            "solution": "The user wants me to determine the smallest integer value for the sustained-deviation length, denoted as $K$, for an anomaly detection system. The design constraint is that the expected number of false alerts during a $30$-day monitoring period must not exceed $0.5$.\n\n### Step 1: Problem Validation\nI will first validate the problem statement.\n\n**Givens Extracted from the Problem Statement:**\n-   Sampling interval: $\\Delta = 5\\,\\text{s}$.\n-   Metrics: CPU utilization and I/O throughput.\n-   Standardized scores (z-scores) are computed at each sample time $t$: $z_{\\text{cpu},t}$ and $z_{\\text{io},t}$.\n-   Alert condition: A sustained deviation for at least $K$ consecutive samples, where for each sample in the sequence, $|z_{\\text{cpu},t}| > 3$ or $|z_{\\text{io},t}| > 3$.\n-   Assumptions for benign (non-attack) operation:\n    1.  The standardized scores for each metric, $z_{\\text{cpu},t}$ and $z_{\\text{io},t}$, are independent and identically distributed (i.i.d.) over time.\n    2.  Both are well-modeled by a standard normal distribution, $\\mathcal{N}(0,1)$.\n    3.  $z_{\\text{cpu},t}$ and $z_{\\text{io},t}$ are independent of each other at any given time $t$.\n    4.  The probability of a run of $K$ consecutive exceedances starting at a sample is approximated by the $K$-th power of the single-sample exceedance probability.\n-   Target constraint: The expected number of false alerts over a benign monitoring period of $30$ days is at most $0.5$.\n-   Objective: Find the smallest integer $K$ that satisfies this constraint.\n\n**Validation against Criteria:**\n1.  **Scientific or Factual Unsoundness**: The problem is grounded in standard statistical modeling (normal distribution, z-scores, probability of independent events) applied to a realistic computer science problem (resource monitoring for anomaly detection). The assumptions, such as the data following a normal distribution and events being i.i.d., are common and explicitly stated simplifying assumptions for such models. There are no violations of scientific principles.\n2.  **Non-Formalizable or Irrelevant**: The problem is well-defined mathematically and is relevant to the topic of operating systems, specifically in the context of performance monitoring and intrusion detection, which are advanced subjects in that field.\n3.  **Incomplete or Contradictory Setup**: The problem provides all necessary data and constraints to arrive at a unique solution. The assumptions are internally consistent.\n4.  **Unrealistic or Infeasible**: The scenario is a simplified but plausible model of a real-world system. All values are within realistic bounds.\n5.  **Ill-Posed or Poorly Structured**: The problem is well-posed. A unique, stable, and meaningful integer solution for $K$ exists.\n6.  **Pseudo-Profound, Trivial, or Tautological**: The problem requires a multi-step quantitative analysis involving probability theory and logarithms. It is not trivial.\n7.  **Outside Scientific Verifiability**: The problem is a mathematical exercise based on a given model and can be solved and verified according to the rules of mathematics and probability.\n\n**Verdict:** The problem is **valid**. I will proceed to the solution.\n\n### Step 2: Solution Derivation\nThe objective is to find the smallest integer $K$ that ensures the expected number of false alerts in a $30$-day period is no more than $0.5$.\n\nFirst, let's calculate the total number of samples, $N$, in the monitoring period.\nThe monitoring period is $T = 30$ days. The sampling interval is $\\Delta = 5 \\text{ s}$.\nWe convert the period $T$ to seconds:\n$$ T = 30 \\text{ days} \\times 24 \\frac{\\text{hours}}{\\text{day}} \\times 60 \\frac{\\text{minutes}}{\\text{hour}} \\times 60 \\frac{\\text{seconds}}{\\text{minute}} = 2,592,000 \\text{ s} $$\nThe total number of samples is:\n$$ N = \\frac{T}{\\Delta} = \\frac{2,592,000 \\text{ s}}{5 \\text{ s}} = 518,400 $$\n\nNext, we determine the probability of a single sample being flagged as anomalous. Let this probability be $p$. An alert is triggered at a single sample time $t$ if $|z_{\\text{cpu},t}| > 3$ or $|z_{\\text{io},t}| > 3$.\nLet $A_{\\text{cpu}}$ be the event $|z_{\\text{cpu},t}| > 3$ and $A_{\\text{io}}$ be the event $|z_{\\text{io},t}| > 3$. The single-sample anomaly event is $A = A_{\\text{cpu}} \\cup A_{\\text{io}}$.\nThe probability $p$ is given by the principle of inclusion-exclusion:\n$$ p = P(A_{\\text{cpu}} \\cup A_{\\text{io}}) = P(A_{\\text{cpu}}) + P(A_{\\text{io}}) - P(A_{\\text{cpu}} \\cap A_{\\text{io}}) $$\nAccording to the problem's assumptions, $z_{\\text{cpu},t}$ and $z_{\\text{io},t}$ are independent. Therefore, the events $A_{\\text{cpu}}$ and $A_{\\text{io}}$ are independent, which means $P(A_{\\text{cpu}} \\cap A_{\\text{io}}) = P(A_{\\text{cpu}}) P(A_{\\text{io}})$.\n\nLet $p_{\\text{metric}}$ be the probability that a single metric's standardized score exceeds the threshold of $3$. Since both scores are modeled by a standard normal distribution, $Z \\sim \\mathcal{N}(0,1)$, we have:\n$$ p_{\\text{metric}} = P(|Z| > 3) $$\nThis probability can be calculated from the cumulative distribution function (CDF) of the standard normal distribution, $\\Phi(z)$.\n$$ p_{\\text{metric}} = P(Z > 3) + P(Z < -3) $$\nBy symmetry of the normal distribution, $P(Z < -3) = P(Z > 3) = 1 - \\Phi(3)$.\n$$ p_{\\text{metric}} = 2(1 - \\Phi(3)) $$\nUsing the well-known \"68-95-99.7 rule\" for normal distributions, the probability of a value falling within $3$ standard deviations of the mean is approximately $0.9973$. Thus, the probability of falling outside this range is:\n$$ p_{\\text{metric}} \\approx 1 - 0.9973 = 0.0027 $$\nUsing this value, we have $P(A_{\\text{cpu}}) = P(A_{\\text{io}}) = p_{\\text{metric}} \\approx 0.0027$.\nNow we can compute $p$:\n$$ p = 2p_{\\text{metric}} - p_{\\text{metric}}^2 \\approx 2(0.0027) - (0.0027)^2 = 0.0054 - 0.00000729 = 0.00539271 $$\n\nAn alert is declared if a sample is anomalous for $K$ consecutive times. Based on the problem assumption, the probability of an alert sequence of length $K$ beginning at any given sample is $p^K$.\nThe expected number of false alerts, $E[\\text{alerts}]$, over the entire period is the number of samples $N$ multiplied by the probability of an alert sequence starting at any sample. We neglect end effects (i.e., we assume there are $N$ potential start times for a sequence of length $K$), which is a reasonable approximation for large $N$.\n$$ E[\\text{alerts}] = N \\times p^K $$\nThe problem requires this expectation to be at most $0.5$:\n$$ N p^K \\le 0.5 $$\nWe need to solve for the smallest integer $K$ that satisfies this inequality.\n$$ 518,400 \\times (0.00539271)^K \\le 0.5 $$\nLet's isolate the term with $K$:\n$$ (0.00539271)^K \\le \\frac{0.5}{518,400} = \\frac{1}{1,036,800} $$\nTo solve for $K$, we take the natural logarithm of both sides.\n$$ \\ln\\left((0.00539271)^K\\right) \\le \\ln\\left(\\frac{1}{1,036,800}\\right) $$\n$$ K \\ln(0.00539271) \\le -\\ln(1,036,800) $$\nSince $0.00539271 < 1$, its natural logarithm is negative. When we divide by this negative number, we must reverse the inequality sign.\n$$ K \\ge \\frac{-\\ln(1,036,800)}{\\ln(0.00539271)} $$\nNow, we compute the values of the logarithms:\n$$ \\ln(1,036,800) \\approx 13.8516 $$\n$$ \\ln(0.00539271) \\approx -5.2233 $$\nSubstituting these values back into the inequality for $K$:\n$$ K \\ge \\frac{-13.8516}{-5.2233} \\approx 2.6517 $$\nSince $K$ must be an integer, the smallest integer value for $K$ that satisfies this condition is $3$.\n\nTo verify, let's check the expected number of alerts for $K=2$ and $K=3$.\nFor $K=2$:\n$$ E[\\text{alerts}] = 518,400 \\times (0.00539271)^2 \\approx 518,400 \\times (2.9081 \\times 10^{-5}) \\approx 15.07 $$\nThis value is greater than $0.5$.\nFor $K=3$:\n$$ E[\\text{alerts}] = 518,400 \\times (0.00539271)^3 \\approx 518,400 \\times (1.5684 \\times 10^{-7}) \\approx 0.0813 $$\nThis value is less than $0.5$.\nThus, the smallest integer $K$ that meets the required design constraint is $3$.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "An alternative to detecting anomalous behavior is to precisely define what constitutes \"approved\" configuration and flag any deviation from this specification. This whitelist-based approach is highly effective for ensuring system integrity and detecting unauthorized persistence mechanisms. This exercise demonstrates how this concept can be formalized by translating complex system configurations, like `systemd` unit files, into a structured feature space. You will apply the Hamming distance, a foundational metric from information theory, to quantify the difference between an observed configuration and a set of trusted templates, providing a clear and automatable method for integrity checking. ",
            "id": "3650781",
            "problem": "An operating system configuration monitoring pipeline for an Intrusion Detection System (IDS) uses a whitelist baseline to detect stealthy persistence in Linux System Manager (systemd) unit files. Each unit is mapped to a binary feature vector of length $12$, where position $i$ indicates the presence ($1$) or absence ($0$) of a specific directive condition. The monitored features are fixed and applied uniformly to all units:\n- $f_{1}$: The `ExecStart` command invokes a shell interpreter.\n- $f_{2}$: The `ExecStartPre` directive is present.\n- $f_{3}$: The `ExecStartPost` directive is present.\n- $f_{4}$: The `Type` directive is set to `simple`.\n- $f_{5}$: The `Restart` directive is set to `always`.\n- $f_{6}$: The `RestartSec` directive is specified.\n- $f_{7}$: The `RemainAfterExit` directive is specified.\n- $f_{8}$: The `WantedBy` directive includes `multi-user.target`.\n- $f_{9}$: The `StandardOutput` directive is set to `null`.\n- $f_{10}$: At least one `Environment` key-value is defined.\n- $f_{11}$: A `ConditionPathExists` directive is present.\n- $f_{12}$: The `User` directive is specified and is non-root.\n\nThe whitelist contains three approved templates, each represented as a binary vector in the fixed feature order $\\left(f_{1}, f_{2}, \\dots, f_{12}\\right)$:\n$$\\mathbf{t}_{1} = (0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1)$$\n$$\\mathbf{t}_{2} = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1)$$\n$$\\mathbf{t}_{3} = (0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0)$$\n\nA newly observed unit is mapped to the feature vector:\n$$\\mathbf{x} = (1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0).$$\n\nTreat the distance between two units as the count of positions at which their corresponding binary feature entries differ. Compute the minimal distance between $\\mathbf{x}$ and the whitelist set $\\{\\mathbf{t}_{1}, \\mathbf{t}_{2}, \\mathbf{t}_{3}\\}$. Provide your final answer as a single number. No rounding is required.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the context of computer science and operating systems security, using standard mathematical formalisms (binary vectors, distance metrics). The problem is well-posed, self-contained, and provides all necessary data and definitions for a unique solution.\n\nThe problem requires computing the minimal distance between a given feature vector $\\mathbf{x}$ and a set of whitelist template vectors $\\{\\mathbf{t}_{1}, \\mathbf{t}_{2}, \\mathbf{t}_{3}\\}$. All vectors are elements of the vector space $\\{0, 1\\}^{12}$. The distance metric is defined as \"the count of positions at which their corresponding binary feature entries differ.\" This is formally known as the Hamming distance.\n\nFor two binary vectors $\\mathbf{a} = (a_{1}, a_{2}, \\dots, a_{n})$ and $\\mathbf{b} = (b_{1}, b_{2}, \\dots, b_{n})$ of length $n$, the Hamming distance $d_{H}(\\mathbf{a}, \\mathbf{b})$ is given by the sum of the element-wise differences (which, for binary digits, is equivalent to the number of non-zero elements in the vector resulting from the bitwise XOR operation):\n$$d_{H}(\\mathbf{a}, \\mathbf{b}) = \\sum_{i=1}^{n} |a_{i} - b_{i}|$$\nIn this problem, the length of the vectors is $n=12$.\n\nThe given vectors are:\nThe observed unit vector:\n$$\\mathbf{x} = (1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0)$$\nThe whitelist template vectors:\n$$\\mathbf{t}_{1} = (0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1)$$\n$$\\mathbf{t}_{2} = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1)$$\n$$\\mathbf{t}_{3} = (0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0)$$\n\nWe must compute the Hamming distance from $\\mathbf{x}$ to each template vector $\\mathbf{t}_{i}$ and then find the minimum of these distances.\n\n1.  **Compute the distance between $\\mathbf{x}$ and $\\mathbf{t}_{1}$:**\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{1}) = \\sum_{i=1}^{12} |x_{i} - t_{1,i}|$\n    The differing positions are $i=1, 3, 5, 7, 9, 11, 12$.\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{1}) = |1-0| + |0-0| + |1-0| + |1-1| + |1-0| + |1-1| + |1-0| + |1-1| + |1-0| + |1-1| + |1-0| + |0-1|$\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{1}) = 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1 + 1 = 7$\n\n2.  **Compute the distance between $\\mathbf{x}$ and $\\mathbf{t}_{2}$:**\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{2}) = \\sum_{i=1}^{12} |x_{i} - t_{2,i}|$\n    The differing positions are $i=1, 3, 4, 5, 6, 8, 9, 10, 12$.\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{2}) = |1-0| + |0-0| + |1-0| + |1-0| + |1-0| + |1-0| + |1-1| + |1-0| + |1-0| + |1-0| + |1-1| + |0-1|$\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{2}) = 1 + 0 + 1 + 1 + 1 + 1 + 0 + 1 + 1 + 1 + 0 + 1 = 9$\n\n3.  **Compute the distance between $\\mathbf{x}$ and $\\mathbf{t}_{3}$:**\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{3}) = \\sum_{i=1}^{12} |x_{i} - t_{3,i}|$\n    The differing positions are $i=1, 2, 4, 7, 9, 11$.\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{3}) = |1-0| + |0-1| + |1-1| + |1-0| + |1-1| + |1-1| + |1-0| + |1-1| + |1-0| + |1-1| + |1-0| + |0-0|$\n    $d_{H}(\\mathbf{x}, \\mathbf{t}_{3}) = 1 + 1 + 0 + 1 + 0 + 0 + 1 + 0 + 1 + 0 + 1 + 0 = 6$\n\nThe set of computed distances is $\\{7, 9, 6\\}$. The minimal distance is the minimum value in this set.\nMinimal distance $= \\min\\{d_{H}(\\mathbf{x}, \\mathbf{t}_{1}), d_{H}(\\mathbf{x}, \\mathbf{t}_{2}), d_{H}(\\mathbf{x}, \\mathbf{t}_{3})\\}$\nMinimal distance $= \\min\\{7, 9, 6\\} = 6$\n\nThis minimal distance of $6$ indicates that the observed unit $\\mathbf{x}$ is \"closest\" to the whitelist template $\\mathbf{t}_{3}$, differing in $6$ feature conditions. In the context of an IDS, this distance would be compared against a threshold to determine if an alert should be generated.",
            "answer": "$$\\boxed{6}$$"
        }
    ]
}