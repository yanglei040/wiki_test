{
    "hands_on_practices": [
        {
            "introduction": "One of the foundational decisions in a distributed operating system is whether to execute a process locally or migrate it to a more powerful remote node. This exercise models that fundamental trade-off, balancing the fixed, one-time cost of moving a process against the potential long-term gain of faster execution. By deriving a simple decision rule, you will develop a quantitative intuition for the cost-benefit analysis that underpins many dynamic resource management strategies, such as load balancing .",
            "id": "3644955",
            "problem": "A Distributed Operating System (DOS) can migrate a compute-bound process from a local node to a remote node to reduce completion time. Let the process have a job size $x$ measured in local central processing unit (CPU) seconds, meaning that if it executes entirely on the local node, it would require $x$ seconds of CPU time at the local processor. The remote node offers a speed ratio $\\rho$ relative to the local node, meaning the remote processor sustains $\\rho$ times the execution rate of the local processor, with $\\rho  1$. The act of migrating the process to the remote node incurs a one-time network and setup cost $C_{n}$ measured in seconds, which includes state transfer and remote dispatch overheads. Assume there is no overlap between computation and communication, the amount of computation is invariant under migration, and there are no queueing delays at either node.\n\nUsing only the foundational facts that execution time equals work divided by speed and that independent overheads add to completion time, derive a decision rule that guarantees a net completion time reduction by migration. Express your answer as the threshold job size $x^{*}$ in seconds, in closed form as a symbolic expression in terms of $\\rho$ and $C_{n}$, such that migration strictly reduces completion time if and only if $x  x^{*}$. Provide your final answer exactly; do not approximate. Express the threshold in seconds.",
            "solution": "The problem requires the derivation of a decision rule for process migration in a distributed system. The rule should determine the threshold job size, denoted as $x^*$, above which migrating a process to a remote node strictly reduces its completion time. The derivation will be based on the fundamental principles and variables provided.\n\nFirst, let us formalize the completion times for the two possible execution scenarios: local execution and remote execution.\n\nLet $T_{local}$ be the total completion time if the process executes entirely on the local node. The problem defines the job size $x$ as the CPU time in seconds required for the process on the local node. Therefore, the completion time for local execution is:\n$$T_{local} = x$$\n\nNext, let $T_{remote}$ be the total completion time if the process is migrated to the remote node. This duration comprises two distinct, non-overlapping parts: the migration overhead and the remote computation time.\n\nThe migration cost is a fixed, one-time overhead given as $C_{n}$ seconds.\n\nThe computation time on the remote node depends on the job's work content and the remote processor's speed. Let $W$ represent the total computational work of the process. Since the process requires $x$ seconds on the local processor, we can express the work as $W = S_{local} \\cdot x$, where $S_{local}$ is the execution speed (e.g., instructions per second) of the local processor. The remote processor is faster by a factor of $\\rho$, so its speed is $S_{remote} = \\rho \\cdot S_{local}$. The execution time on the remote node is the work divided by the remote speed:\n$$T_{compute\\_remote} = \\frac{W}{S_{remote}} = \\frac{S_{local} \\cdot x}{\\rho \\cdot S_{local}} = \\frac{x}{\\rho}$$\nThe problem states that there is no overlap between computation and communication. Thus, the total completion time for the remote scenario is the sum of the migration overhead and the remote computation time:\n$$T_{remote} = C_{n} + T_{compute\\_remote} = C_{n} + \\frac{x}{\\rho}$$\n\nMigration is advantageous if and only if the completion time is strictly reduced. This can be expressed with the following inequality:\n$$T_{remote}  T_{local}$$\nSubstituting the derived expressions for $T_{remote}$ and $T_{local}$:\n$$C_{n} + \\frac{x}{\\rho}  x$$\nTo find the threshold job size $x^*$, we must solve this inequality for $x$. We begin by isolating the terms involving $x$:\n$$C_{n}  x - \\frac{x}{\\rho}$$\nFactoring out $x$ from the right-hand side gives:\n$$C_{n}  x \\left(1 - \\frac{1}{\\rho}\\right)$$\nTo simplify the term in the parenthesis, we find a common denominator:\n$$C_{n}  x \\left(\\frac{\\rho - 1}{\\rho}\\right)$$\nThe problem states that the remote node is faster, meaning $\\rho  1$. This implies that the term $\\rho - 1$ is positive. Since $\\rho$ is also positive, the fraction $\\frac{\\rho-1}{\\rho}$ is a positive quantity. Therefore, we can multiply both sides of the inequality by its reciprocal, $\\frac{\\rho}{\\rho-1}$, without altering the direction of the inequality sign:\n$$C_{n} \\cdot \\frac{\\rho}{\\rho - 1}  x$$\nThis inequality can be rewritten as:\n$$x  C_{n} \\frac{\\rho}{\\rho - 1}$$\nThis expression defines the condition under which migration is beneficial. The problem asks for the threshold job size $x^*$ such that migration is strictly advantageous if and only if $x  x^*$. By comparing our result with this condition, we can identify the expression for $x^*$:\n$$x^* = C_{n} \\frac{\\rho}{\\rho - 1}$$\nThis is the closed-form symbolic expression for the threshold job size. If the job size $x$ is greater than this value, the time saved by the faster remote processor outweighs the fixed cost of migration.",
            "answer": "$$\\boxed{C_{n} \\frac{\\rho}{\\rho - 1}}$$"
        },
        {
            "introduction": "A primary motivation for building distributed systems is to achieve high availability through replication. This practice moves beyond the qualitative idea that 'more replicas are better' and asks you to quantify this relationship precisely using basic probability. You will derive the exact availability of a service and, more importantly, analyze the marginal gain of adding each new replica, revealing the crucial engineering principle of diminishing returns .",
            "id": "3645021",
            "problem": "A distributed operating system (DOS) deploys a stateless, read-mostly service as $k$ identical replicas across independent nodes. In a fixed mission window, each node is unavailable with probability $p \\in (0,1)$, independently of all others. The service is considered available if at least $1$ replica is available in the window. Assume no correlated failures and ignore network partitions and request routing latency.\n\nStarting only from the axioms of probability and the definition of independence, do the following:\n\n1. Derive the exact availability $A(k)$ of the service as a function of $k$ and $p$.\n2. Using your expression for $A(k)$, derive the marginal availability gain $\\Delta(k)$ obtained by adding the $k$-th replica, defined as $\\Delta(k) = A(k) - A(k-1)$ for $k \\ge 1$ with the convention that $A(0)=0$. Then, determine the ratio $\\rho(k) = \\frac{\\Delta(k+1)}{\\Delta(k)}$ for $k \\ge 1$ and interpret what this implies about diminishing returns as $k$ increases.\n3. For a concrete system with $p = 0.02$, determine the smallest integer $k$ such that the incremental gain from adding the $k$-th replica falls below a target threshold $\\varepsilon = 1.0 \\times 10^{-6}$, that is, $\\Delta(k)  \\varepsilon$.\n\nReport your final answer as the integer value of $k$ for the parameters $p = 0.02$ and $\\varepsilon = 1.0 \\times 10^{-6}$. No rounding is required beyond the exact integer.",
            "solution": "The problem statement has been analyzed and is deemed valid. It is scientifically grounded in fundamental probability theory, is well-posed with a clear objective and sufficient data, and is expressed in objective, formal language. We may therefore proceed with the solution.\n\nThe solution is divided into three parts as requested by the problem statement.\n\n### Part 1: Derivation of Service Availability $A(k)$\n\nLet $U_i$ be the event that the $i$-th replica is unavailable during the mission window, for $i \\in \\{1, 2, \\dots, k\\}$. The problem states that the probability of this event is $p$.\n$$P(U_i) = p$$\nThe probability that the $i$-th replica is available, which we denote by the complementary event $U_i^c$, is therefore:\n$$P(U_i^c) = 1 - p$$\nThe service is defined as available if at least one replica is available. It is more straightforward to calculate the probability of the complementary event: the service being unavailable. The service is unavailable if and only if all $k$ replicas are unavailable. This corresponds to the intersection of the events $U_1, U_2, \\dots, U_k$.\n$$P(\\text{Service Unavailable}) = P(U_1 \\cap U_2 \\cap \\dots \\cap U_k)$$\nThe problem specifies that the nodes are independent. Therefore, the events $U_i$ are mutually independent. The probability of their intersection is the product of their individual probabilities:\n$$P(\\text{Service Unavailable}) = \\prod_{i=1}^{k} P(U_i) = \\prod_{i=1}^{k} p = p^k$$\nThe availability of the service, $A(k)$, is the probability that the service is available. This is $1$ minus the probability that it is unavailable.\n$$A(k) = 1 - P(\\text{Service Unavailable})$$\nSubstituting the derived expression gives the exact availability as a function of $k$ and $p$:\n$$A(k) = 1 - p^k$$\n\n### Part 2: Derivation of Marginal Gain $\\Delta(k)$ and Ratio $\\rho(k)$\n\nThe marginal availability gain $\\Delta(k)$ is defined as $\\Delta(k) = A(k) - A(k-1)$ for $k \\ge 1$, with the convention that $A(0) = 0$.\nUsing the expression for $A(k)$:\n$$A(k) = 1 - p^k$$\n$$A(k-1) = 1 - p^{k-1}$$\nSubstituting these into the definition of $\\Delta(k)$:\n$$\\Delta(k) = (1 - p^k) - (1 - p^{k-1}) = 1 - p^k - 1 + p^{k-1} = p^{k-1} - p^k$$\nFactoring out the term $p^{k-1}$:\n$$\\Delta(k) = p^{k-1}(1-p)$$\nThis expression represents the incremental probability of service availability gained by adding the $k$-th replica. It is precisely the probability that the first $k-1$ replicas fail (an event with probability $p^{k-1}$) AND the $k$-th replica is available (an event with probability $1-p$).\n\nNext, we determine the ratio $\\rho(k) = \\frac{\\Delta(k+1)}{\\Delta(k)}$ for $k \\ge 1$.\nFirst, we find the expression for $\\Delta(k+1)$ by substituting $k+1$ for $k$ in the formula for $\\Delta(k)$:\n$$\\Delta(k+1) = p^{(k+1)-1}(1-p) = p^k(1-p)$$\nNow, we form the ratio:\n$$\\rho(k) = \\frac{\\Delta(k+1)}{\\Delta(k)} = \\frac{p^k(1-p)}{p^{k-1}(1-p)}$$\nSince $p \\in (0,1)$, the term $1-p$ is non-zero and can be canceled. We are left with:\n$$\\rho(k) = \\frac{p^k}{p^{k-1}} = p^{k-(k-1)} = p^1 = p$$\nThe ratio $\\rho(k)$ is constant and equal to $p$. Since $p \\in (0,1)$, this implies that the marginal gain from adding a replica is always a fixed fraction $p$ of the marginal gain from the previous replica. This represents a geometric reduction in the marginal gain, which is a classic example of the principle of diminishing returns. Each subsequent replica adds progressively less to the system's overall availability.\n\n### Part 3: Determination of the Minimum Number of Replicas $k$\n\nWe are asked to find the smallest integer $k$ such that the incremental gain $\\Delta(k)$ falls below a threshold $\\varepsilon$. The condition is:\n$$\\Delta(k)  \\varepsilon$$\nSubstituting the expression for $\\Delta(k)$ and the given values $p = 0.02$ and $\\varepsilon = 1.0 \\times 10^{-6}$:\n$$p^{k-1}(1-p)  \\varepsilon$$\n$$(0.02)^{k-1}(1 - 0.02)  1.0 \\times 10^{-6}$$\n$$(0.02)^{k-1}(0.98)  10^{-6}$$\nTo solve for $k$, we first isolate the term containing the exponent:\n$$(0.02)^{k-1}  \\frac{10^{-6}}{0.98}$$\nWe now take the natural logarithm ($\\ln$) of both sides. Since the natural logarithm is a strictly increasing function, the direction of the inequality is preserved.\n$$\\ln\\left((0.02)^{k-1}\\right)  \\ln\\left(\\frac{10^{-6}}{0.98}\\right)$$\nUsing the logarithm property $\\ln(a^b) = b\\ln(a)$:\n$$(k-1)\\ln(0.02)  \\ln(10^{-6}) - \\ln(0.98)$$\nTo isolate $(k-1)$, we must divide by $\\ln(0.02)$. It is critical to note that since $0.02  1$, the value of $\\ln(0.02)$ is negative. Dividing an inequality by a negative number reverses the direction of the inequality sign.\n$$k-1  \\frac{\\ln(10^{-6}) - \\ln(0.98)}{\\ln(0.02)}$$\nNow, we can solve for $k$:\n$$k  1 + \\frac{\\ln(10^{-6}) - \\ln(0.98)}{\\ln(0.02)}$$\nLet's evaluate the expression on the right-hand side:\n$$k  1 + \\frac{-6\\ln(10) - \\ln(0.98)}{\\ln(0.02)}$$\nUsing computational values, $\\ln(10) \\approx 2.302585$, $\\ln(0.98) \\approx -0.0202027$, and $\\ln(0.02) \\approx -3.912023$.\n$$k  1 + \\frac{-6(2.302585) - (-0.0202027)}{-3.912023}$$\n$$k  1 + \\frac{-13.815510 + 0.0202027}{-3.912023}$$\n$$k  1 + \\frac{-13.7953073}{-3.912023} \\approx 1 + 3.52638$$\n$$k  4.52638$$\nSince $k$ must be an integer, the smallest integer value of $k$ that satisfies this inequality is $5$.\nTo verify, for $k=5$, the gain is $\\Delta(5) = (0.02)^{4}(0.98) = (1.6 \\times 10^{-7})(0.98) = 1.568 \\times 10^{-7}$, which is less than $\\varepsilon = 1.0 \\times 10^{-6}$.\nFor $k=4$, the gain is $\\Delta(4) = (0.02)^{3}(0.98) = (8.0 \\times 10^{-6})(0.98) = 7.84 \\times 10^{-6}$, which is not less than $\\varepsilon$.\nThus, the smallest integer is indeed $k=5$.",
            "answer": "$$\\boxed{5}$$"
        },
        {
            "introduction": "Achieving high performance in a distributed system requires vigilance against subtle overheads that can arise from the system's own coherence mechanisms. This problem explores 'false sharing,' a classic performance pitfall in distributed shared memory systems where logically independent data shares a physical coherence unit, like a memory page. By calculating the resulting message traffic, you will gain a deeper appreciation for how application data layout must align with the underlying system architecture to avoid severe performance degradation .",
            "id": "3644993",
            "problem": "A parallel program runs on a Distributed Shared Memory (DSM) system implementing invalidate-based coherence at the page granularity. The system has page size $P = 4096$ bytes. There are $N = 8$ nodes, each running one thread. Each thread performs $r = 5.0 \\times 10^{5}$ write operations per second to elements of a large shared array. The array is page-aligned. Due to independent thread placement of elements within pages, there is a false-sharing probability $\\phi = 0.12$ that any given write targets a page that is concurrently cached by other nodes without true data dependence. When such a false-sharing event occurs, the invalidate protocol sends one invalidation and one acknowledgment per remote sharer of that page. The average number of remote sharers for a falsely-shared page is $\\bar{s} = 3$.\n\nStarting from first principles about expectations and message counting in an invalidate-based coherence protocol, derive an expression for and compute the expected rate of coherence messages per second attributable to false sharing under these conditions. Express your final numerical answer in messages per second.\n\nThen, based on the page-level nature of DSM coherence and the given page size $P$, propose a concrete data layout transformation that would reduce $\\phi$ by preventing false sharing, and explain qualitatively why it is effective in a DSM system. You may assume that only one thread needs to write a given subset of array elements and that it is possible to align and partition data on page boundaries to isolate writers.\n\nProvide as your final answer only the expected coherence message rate before any layout changes, in messages per second. No rounding is required, and no units should be included inside the final box.",
            "solution": "The problem statement is evaluated for validity prior to attempting a solution.\n\nThe givens are:\n- Page size: $P = 4096$ bytes\n- Number of nodes/threads: $N = 8$\n- Write rate per thread: $r = 5.0 \\times 10^{5}$ writes/second\n- False-sharing probability: $\\phi = 0.12$\n- Average number of remote sharers for a falsely-shared page: $\\bar{s} = 3$\n- Coherence protocol: Invalidate-based\n- Messages per false-sharing event per remote sharer: $1$ invalidation and $1$ acknowledgment.\n\nThe problem is scientifically grounded in the principles of parallel computer architecture and distributed operating systems, specifically concerning cache coherence in Distributed Shared Memory (DSM) systems. The concept of false sharing at page granularity is a well-understood performance issue. The problem is well-posed, providing all necessary parameters ($N$, $r$, $\\phi$, $\\bar{s}$, and protocol message counts) for a unique quantitative solution. The language is objective and precise. The provided data are numerically consistent and plausible for a high-performance distributed system. No scientific flaws, contradictions, or ambiguities are present. Therefore, the problem is deemed valid.\n\nThe solution is approached in two parts as requested by the problem statement.\n\nPart 1: Calculation of the expected coherence message rate.\nThe total rate of coherence messages due to false sharing can be derived from first principles by considering the contributions of all threads in the system.\n\nFirst, we determine the total number of write operations occurring per second across the entire system. With $N$ threads each performing $r$ writes per second, the total system write rate, $R_{write}$, is:\n$$R_{write} = N \\times r$$\n\nNext, we determine the rate at which these writes cause false-sharing events. A false-sharing event is triggered by a write operation with a probability $\\phi$. Thus, the expected rate of false-sharing events, $R_{event}$, is the total write rate multiplied by this probability:\n$$R_{event} = R_{write} \\times \\phi = (N \\times r) \\times \\phi$$\n\nFor each false-sharing event, the invalidate-based coherence protocol generates messages. A write to a falsely-shared page requires sending invalidations to all other nodes that have a cached copy of that page (the remote sharers). The problem states that for a given false-sharing event, there is an average of $\\bar{s}$ remote sharers. The protocol requires sending one invalidation to each remote sharer and receiving one acknowledgment back from each. Therefore, the number of messages generated per remote sharer is $1 + 1 = 2$.\nThe total number of messages per false-sharing event, $M_{event}$, is the number of messages per sharer multiplied by the average number of sharers:\n$$M_{event} = 2 \\times \\bar{s}$$\n\nFinally, the total expected rate of coherence messages per second, $R_{msg}$, is the product of the rate of false-sharing events and the number of messages generated per event.\n$$R_{msg} = R_{event} \\times M_{event} = (N \\times r \\times \\phi) \\times (2 \\times \\bar{s})$$\n\nSubstituting the given numerical values:\n- $N = 8$\n- $r = 5.0 \\times 10^{5} \\text{ s}^{-1}$\n- $\\phi = 0.12$\n- $\\bar{s} = 3$\n\nWe calculate the rate:\n$$R_{msg} = 8 \\times (5.0 \\times 10^{5}) \\times 0.12 \\times (2 \\times 3)$$\n$$R_{msg} = 8 \\times (5.0 \\times 10^{5}) \\times 0.12 \\times 6$$\n$$R_{msg} = 40.0 \\times 10^{5} \\times 0.12 \\times 6$$\n$$R_{msg} = (4.0 \\times 10^{6}) \\times 0.72$$\n$$R_{msg} = 2.88 \\times 10^{6} \\text{ messages/second}$$\n\nPart 2: Data layout transformation to reduce false sharing.\nThe root cause of false sharing in a page-based DSM system is that multiple, independent data items, accessed by different threads, happen to be co-located on the same memory page. The coherence protocol operates at the page granularity of $P=4096$ bytes, meaning it cannot distinguish between writes to different bytes within the same page. A write to any part of the page by one thread will cause the system to treat the entire page as modified, triggering invalidations to other threads that have a cached copy, even if those threads are accessing completely different data elements within that page.\n\nA concrete data layout transformation to prevent this is **data padding and alignment**. The strategy is to ensure that the disjoint subsets of the shared array that are exclusively written to by different threads are allocated on physically distinct memory pages.\n\nThe transformation is implemented as follows:\nAssuming each of the $N$ threads has a workload that involves writing to a specific, non-overlapping partition of the shared array, we must modify the memory allocation of the array. Instead of allocating the partitions contiguously, each partition should be explicitly aligned to a page boundary. This means the starting address of each thread's writable partition must be a multiple of the page size, $P = 4096$.\n\nFor example, if thread $0$ writes to `data_partition_0` and thread $1$ writes to `data_partition_1`, we ensure that the memory address of the start of `data_partition_1` is at least $P$ bytes after the start of `data_partition_0`, and is itself aligned on a $P$-byte boundary. If the size of `data_partition_0` is not an integer multiple of $P$, unused memory, or \"padding,\" must be inserted after it to force `data_partition_1` to start on the next page boundary.\n\nThis transformation is effective because it physically isolates the write targets of different threads onto separate pages. When thread $i$ writes to its data partition, it modifies a page that contains only its own data. No other thread $j$ (where $j \\neq i$) will have a reason to cache this page for its own writes. Consequently, a write by thread $i$ will not trigger an invalidation for a page needed by thread $j$. This directly attacks the premise of false sharing by ensuring that a single coherence block (a page) does not contain data being independently modified by multiple writers. This layout change reduces the false-sharing probability $\\phi$ toward $0$, at the cost of increased memory consumption due to the padding.",
            "answer": "$$\\boxed{2.88 \\times 10^{6}}$$"
        }
    ]
}