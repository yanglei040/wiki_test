{
    "hands_on_practices": [
        {
            "introduction": "Remote Procedure Calls operate over networks that are inherently unreliable, meaning requests or replies can be lost, forcing clients to retry. This exercise challenges you to analyze common filesystem operations from first principles to determine which are \"idempotent\"—safe to retry—and which are not . Mastering this concept is fundamental to designing robust and predictable distributed systems that can gracefully handle network failures.",
            "id": "3677029",
            "problem": "A client communicates with a remote file service using Remote Procedure Call (RPC), defined formally as a determination procedure that maps a request and current server state to a new state and a reply. Let the server maintain a state space denoted by $S$ and define an RPC execution as a function $F$ where $F(S, x) = (S', r)$, with $x$ the operation request, $S'$ the new state, and $r$ the reply. The network realizes at-least-once delivery semantics due to retries: if the client does not receive a reply within a timeout, it re-sends the same request, and the server may execute the same request multiple times. An operation $x$ is said to be idempotent with respect to both state and observable reply if for any state $S$,\n$$F(S, x) = (S', r) \\quad \\text{and} \\quad F(S', x) = (S', r),$$\nmeaning that re-execution does not change the resulting state or the reply relative to a single execution.\n\nConsider a Portable Operating System Interface (POSIX)-like file service offering the following operations on a path $P$ or a file $F$:\n$\\mathsf{read}(F, o, n)$ which returns $n$ bytes from offset $o$, $\\mathsf{writeAt}(F, o, B)$ which writes the byte sequence $B$ at offset $o$, $\\mathsf{append}(F, B)$ which appends $B$ to the end of $F$, $\\mathsf{create}(P)$ which creates a new empty file at $P$ and returns success if $P$ did not exist, $\\mathsf{delete}(P)$ which removes the file at $P$, $\\mathsf{chmod}(P, m)$ which sets the mode bits to $m$ (absolute assignment), and $\\mathsf{rename}(A, B)$ which atomically moves the path $A$ to $B$.\n\nAssume:\n- The server executes each operation atomically and immediately persists the effect before replying.\n- There is a single client issuing these operations, and the only source of duplicate executions is network-level retry of the same request; there are no concurrent writes by other clients in between retries.\n- When an operation is retried, the client re-sends an identical request message.\n\nFrom the foundational definition of idempotency above and standard POSIX-like semantics, classify which operations are naturally idempotent under at-least-once semantics and which ones are non-idempotent because retries change user-visible semantics (state and replies). For the non-idempotent ones, propose wrapper strategies that make them safe under retries without requiring global transactions, such as incorporating client-generated idempotency keys and conditional preconditions that the server can verify to produce the same effect and reply for re-executions of the same logical request.\n\nWhich option correctly classifies idempotent versus non-idempotent operations and proposes wrappers that achieve idempotent behavior under retries while respecting typical file system invariants?\n\nA. Classify $\\mathsf{read}(F, o, n)$, $\\mathsf{writeAt}(F, o, B)$, and $\\mathsf{chmod}(P, m)$ as idempotent; classify $\\mathsf{append}(F, B)$, $\\mathsf{create}(P)$, $\\mathsf{delete}(P)$, and $\\mathsf{rename}(A, B)$ as non-idempotent because retries can change replies even when state does not change. Make non-idempotent operations safe using request-scoped idempotency keys $k$: for $\\mathsf{append}$ use $\\mathsf{appendToken}(F, k, B)$ that writes $B$ exactly once, records the chosen offset, and returns the same offset on retries of the same $k$; for $\\mathsf{create}$ use $\\mathsf{createToken}(P, k)$ that either creates and records $\\langle P, k \\rangle$ or, if $P$ already exists due to the same $k$, returns success, and if $P$ exists due to a different cause returns “already exists”; for $\\mathsf{delete}$ use $\\mathsf{deleteToken}(P, k)$ that deletes and records $\\langle P, k \\rangle$, returning the same success on a retry of $k$ and “not found” if $P$ is absent and was not removed by $k$; for $\\mathsf{rename}$ use $\\mathsf{renameToken}(A, B, k, i, v)$ that conditionally renames only if $A$ currently refers to inode $i$ at version $v$, records $\\langle A \\to B, k \\rangle$, and returns the same success or error on retried $k$.\n\nB. Classify $\\mathsf{append}(F, B)$ as idempotent because appending the same $B$ twice yields two copies of $B$ which is “acceptable,” classify $\\mathsf{writeAt}(F, o, B)$ as non-idempotent because writing twice “overwrites different bytes,” and make all operations safe by client-side retry counters $c$ without server support, assuming the server will drop duplicates if $c$ increases.\n\nC. Classify $\\mathsf{rename}(A, B)$ as idempotent because moving a path twice does not “move it again,” classify $\\mathsf{delete}(P)$ as idempotent because removing an already absent file has no state effect, and make $\\mathsf{create}(P)$ safe by renaming a temporary file to $P$ without any idempotency key, assuming that retries of the rename always return success.\n\nD. Classify $\\mathsf{read}(F, o, n)$ as non-idempotent because the file may change between retries, classify $\\mathsf{writeAt}(F, o, B)$ and $\\mathsf{append}(F, B)$ as idempotent, and make non-idempotent operations safe by introducing client-side sleeps before retry so that the server “stabilizes,” without any server-side deduplication or conditional checks.\n\nSelect the single best option.",
            "solution": "Begin from first principles. An RPC operation $x$ is idempotent if $F(F(S, x)_1, x) = F(S, x)$, where $F(S, x) = (S', r)$ and $F(S', x) = (S', r)$; here the subscript $1$ selects the state component. In words, applying $x$ twice produces the same state and reply as applying it once. Under at-least-once semantics, the same logical request $x$ may execute multiple times, so idempotency is determined by whether repeats of the identical request alter either the final state or the reply relative to a single execution.\n\nAssumptions constrain variability: a single client, atomic operations, and identical retries mean that any change between repeated executions is due to the operation itself, not concurrent interference.\n\nAnalyze each operation:\n\n- $\\mathsf{read}(F, o, n)$: Under the assumptions, the file content does not change between retries because no other client writes and the same client is only retrying due to a lost reply. Therefore the state remains unchanged and the reply, the byte sequence returned, is the same on re-execution. Thus $\\mathsf{read}$ is idempotent.\n\n- $\\mathsf{writeAt}(F, o, B)$: Writing the same bytes $B$ at the same offset $o$ twice yields the same final state as writing once: the file bytes in the range are equal to $B$ after the first write, and the second write writes $B$ again at the same positions, leaving the file unchanged. Replies in POSIX-like semantics for a successful write indicate the count of bytes written; with atomicity and persistence, duplicate execution returns the same success. Thus $\\mathsf{writeAt}$ is idempotent under the stated conditions.\n\n- $\\mathsf{chmod}(P, m)$ with absolute assignment: Setting the mode bits to $m$ twice results in the same mode $m$; because the assignment is absolute (not a toggle or arithmetic update), the reply indicating success is the same on a retry. Thus $\\mathsf{chmod}$ is idempotent.\n\n- $\\mathsf{append}(F, B)$: Appending $B$ to the end of a file changes file length by $\\lvert B \\rvert$. Re-executing the same append will further increase length by $\\lvert B \\rvert$ again, and the content will contain two copies of $B$. The reply typically includes the number of bytes appended or the new end offset; this reply would differ between the first and second execution. Therefore $\\mathsf{append}$ is not idempotent.\n\n- $\\mathsf{create}(P)$: Creating a file at $P$ once changes the state from “absent” to “present.” A second execution over the same path $P$ yields a different reply: standard semantics return “already exists” error; even if the state remains “present,” the reply changes. Therefore, relative to the definition incorporating reply semantics, $\\mathsf{create}$ is not idempotent.\n\n- $\\mathsf{delete}(P)$: Removing a file once changes the state from “present” to “absent.” A second execution on an absent file produces a different reply, “not found,” although the state remains “absent.” Given the definition includes reply, $\\mathsf{delete}$ is not idempotent.\n\n- $\\mathsf{rename}(A, B)$: Moving a path from $A$ to $B$ once causes $A$ to become absent and $B$ to become present (pointing to the moved inode). A second execution over the same arguments typically fails because $A$ no longer exists, producing a different reply; therefore $\\mathsf{rename}$ is not idempotent.\n\nFor non-idempotent operations, wrappers can provide idempotent semantics by binding a logical request to an idempotency key $k$ and making the server return the same effect and reply on re-execution of the same logical request. Principles for such wrappers include:\n\n- Deduplication via a per-client key: the server stores a mapping from $(\\text{client}, k)$ to the outcome $(S', r)$ for operations that completed, ensuring that a duplicate request with the same $(\\text{client}, k)$ returns the stored reply $r$ and does not re-apply the state change.\n\n- Conditional preconditions: the server checks that the state satisfies the same preconditions the client saw when issuing the request (for example, the source inode and version for a rename). If the preconditions fail, the same error is returned; if the preconditions hold and the operation was completed under $k$, the same success is returned.\n\nApply those to each non-idempotent operation:\n\n- $\\mathsf{append}(F, B)$: Use $\\mathsf{appendToken}(F, k, B)$ that records $k$ in a per-file ledger when appending $B$, along with the chosen offset $o$ and a hash of $B$ to detect mismatch. On retry with the same $k$, the server returns the previously recorded $o$ and does not append again, thereby ensuring $F(F(S, x)_1, x) = F(S, x)$ for $x = \\mathsf{appendToken}(F, k, B)$.\n\n- $\\mathsf{create}(P)$: Use $\\mathsf{createToken}(P, k)$ that creates the file and records $\\langle P, k \\rangle$ upon success. If a retry arrives with the same $k$, the server detects the existing record and returns success again. If the path $P$ exists but was not created under $k$, the server returns the “already exists” error, preserving invariants.\n\n- $\\mathsf{delete}(P)$: Use $\\mathsf{deleteToken}(P, k)$ that deletes and records $\\langle P, k \\rangle$. On retry under the same $k$, the server returns success even if $P$ is already absent, because the same logical deletion completed earlier under $k$. If $P$ is absent and there is no record for $k$, the server returns “not found,” preserving correctness relative to a different logical request.\n\n- $\\mathsf{rename}(A, B)$: Use $\\mathsf{renameToken}(A, B, k, i, v)$ where the client includes the source inode $i$ and version $v$ observed before issuing the rename. The server performs the rename only if $A$ refers to inode $i$ at version $v$, then records $\\langle A \\to B, k \\rangle$. A retry with the same $k$ returns the same success; if $A$ no longer matches $i, v$ and there is no record for $k$, the server returns the same error as the first attempt would, avoiding unintended extra moves.\n\nEvaluate each option:\n\nA. This option classifies $\\mathsf{read}$, $\\mathsf{writeAt}$, and $\\mathsf{chmod}$ as idempotent and the rest as non-idempotent under retries because replies change even if state may not. This matches the analysis above. The proposed wrappers use idempotency keys $k$ and conditional checks to ensure that a duplicate execution yields the same reply without re-applying the state change. Each wrapper respects common file system invariants: $\\mathsf{appendToken}$ does not duplicate content on retries, $\\mathsf{createToken}$ distinguishes between files created by the same logical request versus pre-existing files, $\\mathsf{deleteToken}$ preserves “not found” for different logical requests while making the same logical deletion idempotent, and $\\mathsf{renameToken}$ uses preconditions ($i, v$) to avoid unintended extra moves and returns the same outcome under retries. Verdict — Correct.\n\nB. This option incorrectly declares $\\mathsf{append}$ idempotent on the basis that duplicating content is “acceptable.” By the formal definition, appending twice produces different state and reply than appending once, so it is non-idempotent. It also incorrectly claims $\\mathsf{writeAt}$ is non-idempotent under the stated assumptions; writing the same $B$ at the same $o$ twice yields the same state and reply. Furthermore, relying only on client-side retry counters $c$ without server-side deduplication cannot guarantee that the server will suppress duplicates, especially across reconnections or stateless servers. Verdict — Incorrect.\n\nC. This option mistakenly classifies $\\mathsf{rename}$ as idempotent, arguing that moving “does not move it again,” but retries produce different replies because the source no longer exists, violating the idempotency condition. It also treats $\\mathsf{delete}$ as idempotent, which fails when the second execution returns “not found.” The proposed $\\mathsf{create}$ wrapper relying solely on renaming a temporary file to $P$ without an idempotency key does not ensure that a retried rename returns the same reply; if the first rename succeeded and the second executes, the source temporary path may be missing and the reply would differ. Verdict — Incorrect.\n\nD. This option incorrectly classifies $\\mathsf{read}$ as non-idempotent under the given assumptions; with no intervening writes, a retried read returns the same data and reply. It misclassifies $\\mathsf{append}$ as idempotent. The suggested “sleep before retry” does not provide any server-side mechanism to ensure duplicate suppression or reply consistency, so it fails to achieve idempotent behavior under retries. Verdict — Incorrect.\n\nTherefore, the correct option is A.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "A successful distributed service must evolve over time to add new features or introduce breaking changes, all without disrupting its existing user base. This practice asks you to evaluate different strategies for versioning an RPC interface, a critical aspect of long-term system design and maintenance . By considering factors like backward compatibility and feature negotiation, you will learn to build flexible protocols that can adapt to future requirements.",
            "id": "3677065",
            "problem": "A Remote Procedure Call (RPC) is a mechanism by which a client in one address space invokes a procedure provided by a server in another address space, typically across process or machine boundaries. At the operating system level, RPC depends on a stable contract between client and server describing procedure identifiers, parameter and result encodings, and error semantics. Assume the following foundational facts:\n- A wire protocol that uses a self-describing encoding (for example, Type-Length-Value (TLV)) can safely carry fields unknown to an implementation, because unknown field types can be skipped using the length and type metadata. As a consequence, adding optional fields is forward-compatible: an older client can parse messages by ignoring unknown fields as long as previously defined fields and semantics remain unchanged.\n- Backward compatibility means that a server upgrade does not force existing clients to change to continue functioning: previously valid procedure calls and responses remain valid and correctly interpreted. Forward compatibility means that newer clients can interoperate with older servers by making calls limited to the older server’s contract.\n\nConsider a distributed service that must evolve over time. The service has a baseline set of procedures and several optional features (for example, compression, tracing, and streaming). The environment includes deployed clients that cannot be upgraded instantly. The design goals are:\n- Backward compatibility: a new server should not break existing clients.\n- Feature negotiation: clients and servers should enable optional features only when both sides support them.\n- Controlled breaking changes: when absolutely necessary, changes that would break compatibility must be isolated so that old clients still work without being forced to change immediately.\n\nSuppose a client supports a major version $M_c = 1$ with a minor range $[m_{c,\\min}, m_{c,\\max}] = [1, 3]$ and a feature set $F_c = \\{\\text{gzip}, \\text{streaming}\\}$. A server supports major versions $M \\in \\{1, 2\\}$, with minor ranges $[1, 5]$ for $M = 1$ and $[0, 2]$ for $M = 2$, and a feature set $F_s = \\{\\text{gzip}, \\text{streaming}, \\text{tracing}\\}$. The wire encoding is TLV-like, so unknown fields can be ignored. No mandatory feature is required for the baseline procedures. The service must select a compatible interface and feature set such that:\n- The chosen version preserves the ability of the client to parse and act on responses and the server to parse requests.\n- Optional features are enabled only if both sides support them; unsupported features remain disabled without causing errors in baseline calls.\n- Adding a new optional field or procedure in a minor evolution should not force old clients to change, and an introduced breaking change must not silently corrupt calls, but should be isolated via versioning so old clients continue to work.\n\nWhich of the following RPC interface versioning schemes achieves these goals in general?\n\nA. Use two-level semantic versioning for the service contract $(M, m)$ where $M$ is a major version indicating backward-incompatible changes, and $m$ is a minor version indicating backward-compatible additions. At connection setup, the client sends its supported major versions as a finite set $V_c \\subset \\mathbb{N}$ and, for each $M \\in V_c$, a minor interval $[m_{c,\\min}(M), m_{c,\\max}(M)]$, together with a capability bitmap for features $F_c \\subseteq \\mathcal{F}$. The server replies with a selected $(M^*, m^*)$ such that $M^* \\in V_c \\cap V_s$ and $m^*$ lies in the intersection of the client and server minor intervals for $M^*$, choosing the highest such $m^*$; and a negotiated feature set $F^* = F_c \\cap F_s$. The wire protocol guarantees that unknown optional fields are ignored and that procedure identifiers and existing field semantics are not changed within a fixed $M$. Servers may support multiple $M$ concurrently to avoid breaking old clients; breaking changes require incrementing $M$.\n\nB. Use a single monotonically increasing global version number $v \\in \\mathbb{N}$ with no explicit minor level or feature negotiation. The server always speaks the latest $v$, and clients must upgrade to match. Optional features are implied by $v$ and cannot be independently toggled. The wire protocol allows changing field meanings in newer $v$ to simplify evolution.\n\nC. Eliminate explicit version numbers and rely exclusively on feature negotiation via a capability bitmap $F \\subseteq \\mathcal{F}$. The presence or absence of features defines the contract. The server enables any feature the client advertises, and silently changes field semantics when new features are present. There is no baseline version; incompatible field changes are handled by adding new features and removing old ones.\n\nD. Assign per-procedure version numbers $v_p \\in \\mathbb{N}$ for each procedure $p$ independent of a service-wide version. At connection, the server advertises a map of $\\{p \\mapsto v_{s,p,\\max}\\}$, and the client chooses any $\\{p \\mapsto v_{c,p}\\}$ it prefers up to the server’s maximum. Features are embedded inside procedure versions, not negotiated separately. The wire encoding does not guarantee safe skipping of unknown fields; older clients must parse exact schemas per $p$, and fields may be repurposed within a given $v_p$ to reduce duplication.\n\nSelect the single best option that satisfies backward compatibility, feature negotiation, and controlled breaking changes, without breaking old clients when adding new optional functionality.",
            "solution": "The problem statement is a valid exercise in distributed systems design, specifically protocol versioning and evolution. The premises are scientifically grounded in established computer science principles, and the goals—backward compatibility, feature negotiation, and controlled breaking changes—are well-defined and objective. The problem is self-contained and well-posed, asking for an evaluation of different strategies against these clear criteria.\n\nThe core requirements for a robust RPC evolution strategy, as defined in the problem, are:\n1.  **Backward Compatibility**: A newly deployed server must not break existing, older clients. This is critical in environments where client upgrades are not instantaneous. The problem implies this is achieved by ensuring that additions are optional and a self-describing wire protocol (like Type-Length-Value, TLV) allows old clients to ignore new fields they do not understand.\n2.  **Feature Negotiation**: Optional capabilities (e.g., compression) must be explicitly negotiated, so they are enabled only when both the client and server support them. This prevents errors from attempting to use unsupported features.\n3.  **Controlled Breaking Changes**: Incompatible API changes (e.g., changing a field's meaning, removing a procedure) must be possible, but must be managed in a way that isolates their impact. Older clients must be able to continue functioning with the old API contract, which implies a server may need to support multiple incompatible API versions simultaneously.\n\nBased on these principles, we will evaluate each proposed versioning scheme. The example scenario provides a concrete case: a client supporting version $M_c = 1$, minor range $[1, 3]$, and features $F_c = \\{\\text{gzip}, \\text{streaming}\\}$ should be able to successfully connect to a server supporting major versions $\\{1, 2\\}$, with respective minor ranges $[1, 5]$ and $[0, 2]$, and features $F_s = \\{\\text{gzip}, \\text{streaming}, \\text{tracing}\\}$. A successful negotiation would select major version $M^* = 1$, a compatible minor version (e.g., the maximum common version $m^*=3$), and the intersection of features $F^* = \\{\\text{gzip}, \\text{streaming}\\}$.\n\n### Option-by-Option Analysis\n\n**A. Use two-level semantic versioning for the service contract $(M, m)$...**\n\nThis scheme proposes a two-level versioning system, $(M, m)$, where $M$ denotes a major version for backward-incompatible changes and $m$ denotes a minor version for backward-compatible additions. The negotiation protocol is explicitly defined:\n- The client sends its supported major versions $V_c$ and corresponding minor version ranges.\n- The client sends its supported feature set $F_c$.\n- The server responds with a selected version $(M^*, m^*)$ that is mutually supported, typically the highest available, and a negotiated feature set $F^* = F_c \\cap F_s$.\n- It relies on a wire protocol where unknown optional fields are ignored, and procedure/field semantics are stable within a major version $M$.\n- Breaking changes are managed by incrementing $M$, and servers can support multiple major versions concurrently.\n\nLet's evaluate this against the goals:\n- **Backward Compatibility**: This is perfectly achieved. An old client supporting $M=1$ can talk to a new server that has evolved to a higher minor version within $M=1$ (e.g., client at $1.3$ talks to server at $1.5$). The server, knowing the client's maximum minor version is $3$, will restrict its responses to the $1.3$ contract. Since minor changes are only additive and the wire protocol ignores unknown additions, the client will not break.\n- **Feature Negotiation**: This is explicitly and robustly handled by exchanging feature sets ($F_c$, $F_s$) and computing their intersection ($F^*$). This is a clean, orthogonal mechanism.\n- **Controlled Breaking Changes**: This is the explicit purpose of the major version $M$. A breaking change requires incrementing $M$ to, say, $M=2$. The server can offer both $M=1$ and $M=2$ interfaces simultaneously. Old clients will negotiate $M=1$ and continue to function, while new clients can use the $M=2$ interface. This perfectly isolates the breaking change.\n\nThis scheme is a textbook example of a robust protocol evolution strategy.\n\n**Verdict: Correct**\n\n**B. Use a single monotonically increasing global version number $v \\in \\mathbb{N}$...**\n\nThis scheme proposes a single global version number $v$. The server always uses the latest version, and clients are forced to upgrade. Features are not negotiated but are tied to the version $v$. The wire protocol allows changing field meanings.\n\nLet's evaluate this against the goals:\n- **Backward Compatibility**: This scheme explicitly violates backward compatibility. It's a \"lock-step\" model that requires all clients to upgrade, which is contrary to the problem's stated goal that \"existing clients\" should not be broken by a \"server upgrade\" and that they \"cannot be upgraded instantly.\"\n- **Feature Negotiation**: This is explicitly disallowed. Features are inflexibly tied to the global version $v$.\n- **Controlled Breaking Changes**: Changes are not controlled; they are forced upon all clients. The ability to \"change field meanings\" is extremely dangerous and a well-known anti-pattern that can lead to silent data corruption, which a robust system must prevent.\n\nThis scheme is brittle and unsuitable for the described environment.\n\n**Verdict: Incorrect**\n\n**C. Eliminate explicit version numbers and rely exclusively on feature negotiation...**\n\nThis scheme abandons version numbers in favor of a set of features $F$. The contract is defined by the collection of features. It allows the server to \"silently change field semantics when new features are present.\"\n\nLet's evaluate this against the goals:\n- **Backward Compatibility**: This is severely compromised. Relying solely on feature sets creates combinatorial complexity. The rule \"silently changes field semantics when new features are present\" is a critical flaw. A client advertising features $\\{f_1, f_2\\}$ could connect to a server supporting $\\{f_1, f_2, f_3\\}$. If the presence of $f_3$ alters the semantics of messages related to $f_1$, the client will misinterpret data, leading to silent corruption. This is a catastrophic failure mode. A stable baseline contract, guaranteed by versioning, is necessary to prevent such ambiguities.\n- **Feature Negotiation**: While it centers on feature negotiation, the lack of a versioned baseline makes it unsafe. Without versions, there is no way to reason about the compatibility of the *combination* of features.\n- **Controlled Breaking Changes**: This model offers poor control. A \"breaking change\" is modeled as adding a new feature and removing an old one. An old client, unaware of this protocol evolution, might attempt a call that is no longer valid, leading to an unexpected error or, worse, undefined behavior. This fails to \"isolate\" the change.\n\nThis scheme is-defined and encourages practices that lead to non-determinism and silent errors.\n\n**Verdict: Incorrect**\n\n**D. Assign per-procedure version numbers $v_p \\in \\mathbb{N}$ for each procedure $p$...**\n\nThis scheme proposes fine-grained versioning at the level of individual procedures. Features are embedded within these procedure versions. Critically, it states the wire encoding \"does not guarantee safe skipping of unknown fields\" and allows fields to be \"repurposed.\"\n\nLet's evaluate this against the goals:\n- **Backward Compatibility**: This is undermined by the protocol assumptions. If an old client cannot safely skip unknown fields, then any additive change by the server to a procedure's response could break the client. This violates the premise of easy backward-compatible evolution. Allowing fields to be \"repurposed\" is a serious anti-pattern, identical to the flaw in option B, which can cause silent data corruption.\n- **Feature Negotiation**: This is not handled orthogonally. Embedding features (like compression) inside procedure versions is poor design. A cross-cutting concern like compression should be negotiated once for the connection, not on a per-procedure basis, which would lead to redundancy and complexity.\n- **Controlled Breaking Changes**: While per-procedure versioning seems to offer isolation, it creates a maintenance nightmare. A change to a shared data structure would necessitate a coordinated version bump across all procedures that use it. The overall service \"contract\" becomes a complex matrix of procedure versions, which is far harder to manage than a single service-level version.\n\nThis scheme is overly complex, fragile, and its specified wire protocol is fundamentally unsafe for evolutionary design.\n\n**Verdict: Incorrect**\n\nIn conclusion, Option A is the only one that presents a comprehensive, safe, and scalable strategy that meets all the design goals laid out in the problem statement. It aligns with best practices for evolving distributed systems.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "The theoretical elegance of RPCs must confront the complex realities of modern operating systems. This problem explores a classic and dangerous interaction between multi-threaded RPC clients and the POSIX `fork()` system call . By reasoning about shared file descriptors and inconsistent memory states, you will develop a crucial understanding of the pitfalls that arise when process creation and network programming intersect, and learn the safe patterns required for building correct systems software.",
            "id": "3677100",
            "problem": "A process in a Portable Operating System Interface (POSIX) compliant operating system uses a Remote Procedure Call (RPC) client library to communicate with a server over Transmission Control Protocol (TCP). The library maintains $N$ persistent connections, a background heartbeat thread, and per-connection mutex-protected send queues. At time $t_0$, the process is multi-threaded: the main thread is executing application logic, a heartbeat thread is periodically sending health checks, and worker threads are issuing RPCs concurrently. At some moment $t_1 > t_0$, the main thread calls the system call $fork()$. Immediately after the call returns, the child process attempts to reuse the inherited RPC client object for further RPCs, while the parent continues running and using the same library.\n\nFrom first principles, use the following foundational base to reason about what is and is not safe after $fork()$ in a multi-threaded process:\n- By definition, $fork()$ creates a child process that is an almost-exact copy of the parent’s address space at the instant of the call, but only the calling thread is present in the child; other threads from the parent do not exist in the child.\n- By well-tested operating system facts, open file descriptors (FDs) are duplicated such that both parent and child refer to the same underlying open file description in the kernel; for sockets, this means the same TCP connection state is shared. The reference count for the open file description is incremented; kernel-side state such as sequence numbers, send buffers, and protocol control blocks are shared.\n- In a multi-threaded process, immediately after $fork()$ and before any $exec()$, only functions classified as asynchronous-signal-safe are guaranteed to be safe to call; functions that acquire user-space locks or allocate memory are not guaranteed safe.\n- The close-on-exec flag (FD\\_CLOEXEC) causes the kernel to close an FD on $exec()$, not on $fork()$.\n- The POSIX function $pthread\\_atfork$ registers three handlers: a prepare handler called in the parent before $fork()$, a parent handler called in the parent after $fork()$, and a child handler called in the child after $fork()$; these can be used to coordinate lock states across $fork()$.\n\nAssume the RPC library uses non-async-signal-safe operations internally (for example, it uses $malloc$, mutexes, and background threads), and the TCP-based RPC protocol relies on application-level message framing atop a stream with no inherent message boundaries.\n\nWhich of the following recommendations or claims are correct under these constraints? Select all that apply.\n\nA. In a multi-threaded parent, it is safe to perform RPC operations in the child immediately after $fork()$ as long as the child does not touch shared memory not owned by the calling thread.\n\nB. A safe pattern is: in the child, either call $exec()$ immediately (doing no RPC), or, if the child must perform RPC without $exec()$, first close all inherited RPC-related FDs and reinitialize a fresh RPC client state before issuing any RPC calls.\n\nC. Marking the RPC sockets with FD\\_CLOEXEC ensures they are closed in the child at $fork()$, preventing any risk from inherited connections.\n\nD. Sharing an established TCP connection between parent and child is safe because each process has independent sequence number spaces on the socket, so writes from the two processes cannot interleave in a way that breaks the RPC protocol.\n\nE. Using $pthread\\_atfork$ to quiesce the library before $fork()$ (for example, stopping background threads and acquiring all mutexes), and then resetting internal locks and rebuilding RPC client state in the child before any RPC use, is a safe mitigation strategy.\n\nF. When launching new helper processes from an RPC-using, multi-threaded parent, replacing $fork()+exec()$ with $posix\\_spawn()$ avoids post-$fork()$ hazards and is recommended as a safer approach.\n\nChoose the correct option(s).",
            "solution": "The problem statement describes a classic and critical issue in POSIX systems programming: the interaction between multi-threading and the `$fork()$` system call. We must validate the problem setup before proceeding to a solution.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem statement provides the following definitions, conditions, and assumptions, which constitute a \"foundational base\":\n*   A process uses a Remote Procedure Call (RPC) client library over Transmission Control Protocol (TCP).\n*   The library maintains `$N$` persistent connections, a background heartbeat thread, and per-connection mutex-protected send queues.\n*   At time `$t_0$`, the process is multi-threaded (main thread, heartbeat thread, worker threads).\n*   At time `$t_1 > t_0$`, the main thread calls `$fork()$`.\n*   The child process attempts to reuse the inherited RPC client object. The parent process also continues running and using the library.\n*   `$fork()$` creates a copy of the parent's address space but only replicates the calling thread in the child.\n*   Open file descriptors (FDs) are duplicated, pointing to the same underlying kernel open file description (e.g., a shared TCP connection state, including sequence numbers and buffers).\n*   In a multi-threaded process, only async-signal-safe functions are safe to call in the child after `$fork()` and before `$exec()$`. Functions using user-space locks (like mutexes) or memory allocation (`$malloc()$`) are not safe.\n*   The `FD_CLOEXEC` flag causes an FD to be closed on `$exec()$`, not on `$fork()$`.\n*   The `$pthread\\_atfork()$` function registers handlers to manage state (e.g., locks) across a `$fork()` call.\n*   The RPC library is assumed to use non-async-signal-safe operations.\n*   The RPC protocol uses application-level message framing over a TCP stream.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem statement is evaluated against the validation criteria:\n\n*   **Scientifically Grounded**: The premises are firmly based on the well-documented behavior of the POSIX `$fork()$` system call in the context of multi-threading and I/O. The described hazards—deadlocks from inherited mutexes and data corruption from shared file descriptors—are real, well-known problems in systems programming. The description of TCP connection sharing and async-signal safety is accurate.\n*   **Well-Posed**: The problem is clearly structured. It presents a scenario and asks for an evaluation of proposed solutions and claims based on a specified set of first principles. A definite set of correct and incorrect statements can be derived.\n*   **Objective**: The language is precise and technical. It avoids subjectivity and relies on standard operating system terminology and concepts (`$fork()$`, `$exec()$`, mutex, file descriptor).\n\nThe problem does not exhibit any invalidating flaws. It is not scientifically unsound, non-formalizable, incomplete, unrealistic, ill-posed, or trivial. It is a standard, albeit complex, computer science problem.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. We may proceed to the solution.\n\n### Derivation of Solution\n\nThe core of the problem lies in two distinct hazards that arise when `$fork()` is called in a multi-threaded process that manages resources like mutexes and network connections.\n\n1.  **Internal State Inconsistency (Mutex Deadlock)**: The RPC library uses mutexes. If a thread other than the one calling `$fork()` holds a mutex at the moment of the call, the child process inherits the memory state where that mutex is locked. However, the thread that held the lock does not exist in the child. Therefore, the child process's single thread has no way to release the lock. Any attempt by the child to acquire this same mutex will result in an irrecoverable deadlock. The problem states the library uses \"per-connection mutex-protected send queues,\" making this a near-certainty in a concurrent application.\n\n2.  **External Resource Contention (Shared TCP Connection)**: The problem correctly states that `$fork()` duplicates file descriptors such that they point to the same underlying kernel object. For a TCP socket, this means both the parent and child processes are now writing to and reading from the *same* TCP stream. The kernel will serialize access to its send/receive buffers, but from the perspective of the application-level RPC protocol, this is disastrous. An RPC message sent by the parent might be interleaved with an RPC message from the child. The server would receive a garbled stream of data that violates the message framing, leading to communication failure and protocol errors. The claim is that the protocol relies on \"application-level message framing,\" which is acutely vulnerable to such interleaving.\n\nA safe use of the RPC library in the child process must mitigate both of these hazards. The child must either not use the library at all (and typically call `$exec()$`), or it must completely reset its state to a clean, known-good configuration, independent of the parent.\n\n### Option-by-Option Analysis\n\n**A. In a multi-threaded parent, it is safe to perform RPC operations in the child immediately after $fork()$ as long as the child does not touch shared memory not owned by the calling thread.**\n\nThis statement is fundamentally incorrect. The primary danger is not related to \"shared memory\" in the sense of `$shmget()$`, but to the state of the process's *entire duplicated address space*. The child inherits a copy of the mutexes. If any mutex was locked by another thread in the parent, the child will deadlock when it tries to use the RPC library. Furthermore, the RPC operations would use the inherited socket FDs, leading to the TCP stream corruption described above. The condition \"as long as the child does not touch shared memory not owned by the calling thread\" is ill-defined and does not address the actual risks.\n\n**Verdict: Incorrect.**\n\n**B. A safe pattern is: in the child, either call $exec()$ immediately (doing no RPC), or, if the child must perform RPC without $exec()$, first close all inherited RPC-related FDs and reinitialize a fresh RPC client state before issuing any RPC calls.**\n\nThis recommendation describes two valid patterns.\n1.  `$fork()` followed immediately by `$exec()`: This is the canonical safe way to create a new process. The `$exec()` call replaces the child's problematic memory image (including any locked mutexes) with a fresh one from an executable file. This completely avoids the internal state inconsistency problem.\n2.  Child performs RPC without `$exec()`: The prescribed actions are to (i) close inherited FDs and (ii) reinitialize the RPC client. Closing the FDs correctly severs the connection to the shared kernel TCP state, preventing stream corruption. Reinitializing the client from scratch (e.g., calling its `$init()` function) would create new, unlocked mutexes, allocate fresh memory, and establish new, independent network connections. This avoids both the inherited locked-mutex problem and the shared-connection problem. This is the correct \"manual cleanup\" procedure.\n\n**Verdict: Correct.**\n\n**C. Marking the RPC sockets with FD_CLOEXEC ensures they are closed in the child at $fork()$, preventing any risk from inherited connections.**\n\nThis statement is factually wrong. As explicitly stated in the problem's foundational base, \"The close-on-exec flag (FD_CLOEXEC) causes the kernel to close an FD on `$exec()$`, not on `$fork()`.\" Therefore, setting this flag has no effect on the child process immediately after `$fork()` returns. The file descriptors remain open and shared with the parent, and the risk of stream corruption persists.\n\n**Verdict: Incorrect.**\n\n**D. Sharing an established TCP connection between parent and child is safe because each process has independent sequence number spaces on the socket, so writes from the two processes cannot interleave in a way that breaks the RPC protocol.**\n\nThis claim is directly contradicted by the provided foundational base, which correctly states that parent and child \"refer to the same underlying open file description in the kernel; for sockets, this means the same TCP connection state is shared... kernel-side state such as sequence numbers, send buffers, and protocol control blocks are shared.\" There is only one TCP connection and one set of sequence numbers. Writes from both processes are sent over this single connection. The non-deterministic interleaving of these writes will corrupt the application-level message stream.\n\n**Verdict: Incorrect.**\n\n**E. Using $pthread\\_atfork$ to quiesce the library before $fork()$ (for example, stopping background threads and acquiring all mutexes), and then resetting internal locks and rebuilding RPC client state in the child before any RPC use, is a safe mitigation strategy.**\n\nThis describes the canonical, library-centric solution to the `$fork()` safety problem. The `$pthread\\_atfork()` mechanism is designed for precisely this purpose.\n*   The `prepare` handler, called in the parent before `$fork()$`, acquires all necessary locks. This ensures the process enters `$fork()` in a known state.\n*   The `parent` handler, called in the parent after `$fork()` returns, releases the locks, allowing the parent to resume normal operation.\n*   The `child` handler, called in the child after `$fork()` returns, inherits the locks acquired by the `prepare` handler. Since the child is single-threaded, its main thread is the one that \"holds\" these locks, so it can safely release them. The handler would then proceed to re-establish a valid state for the child, which might involve restarting background threads (which were not inherited) and cleaning up other state. This is a robust and correct mitigation strategy.\n\n**Verdict: Correct.**\n\n**F. When launching new helper processes from an RPC-using, multi-threaded parent, replacing $fork()+exec()$ with $posix\\_spawn()$ avoids post-$fork()$ hazards and is recommended as a safer approach.**\n\nThe `$posix\\_spawn()` function family was introduced to the POSIX standard to provide a more efficient and safer way to create processes, especially from multi-threaded callers. Unlike `$fork()`, which creates a vulnerable window where arbitrary code can run in the child before `$exec()$`, `$posix\\_spawn()` is designed as a higher-level abstraction that combines process creation and program execution. Implementations are free to use mechanisms like `$vfork()` to avoid duplicating the entire parent address space. By mapping directly from the parent to the new executable image, it bypasses the execution of any intermediate code in the child that could trigger deadlocks or use inconsistent data. Thus, it effectively prevents the post-`$fork()` hazards associated with using a non-fork-safe library.\n\n**Verdict: Correct.**",
            "answer": "$$\\boxed{BEF}$$"
        }
    ]
}