{
    "hands_on_practices": [
        {
            "introduction": "Virtualizing a CPU relies on the principle of 'trap-and-emulate', a fundamental mechanism for handling sensitive instructions. This practice challenges you to implement a minimal Virtual Machine Monitor (VMM) that intercepts and emulates a privileged I/O instruction, directly demonstrating how a hypervisor can maintain control while providing equivalent functionality to the guest OS. By building this core component from scratch, you will gain a practical understanding of the architectural support that makes virtualization possible .",
            "id": "3689650",
            "problem": "You are to implement, in a single self-contained program, a minimal virtual machine monitor that emulates one privileged instruction following the trap-and-emulate model of virtualization. The goal is to demonstrate equivalence of guest-visible semantics whether the instruction is executed in privileged mode or trapped and emulated by the Virtual Machine Monitor (VMM). The program must run the given test suite and output the correctness of each test as a list of booleans in a single line.\n\nStart from the following fundamental base and definitions:\n- A computer architecture defines privileged instructions whose execution semantics are only permitted in kernel mode. When such an instruction is executed in user mode, hardware causes a trap to the operating system. Under virtualization, the Virtual Machine Monitor (VMM) must intercept these traps and emulate the instruction semantics on a virtual device state so that the guest experiences behavior indistinguishable from running on bare hardware. This is the trap-and-emulate principle.\n- Let the current privilege level be denoted by $\\mathrm{CPL}$, where $\\mathrm{CPL} = 0$ indicates kernel mode and $\\mathrm{CPL} \\neq 0$ indicates user mode.\n- Define a single device called the Virtual Counter Device with a $32$-bit state $D \\in \\{0, 1, \\ldots, 2^{32} - 1\\}$. Its only hardware-visible operation is a privileged instruction $\\mathrm{IOWRITE}(p, v)$ that writes a value $v$ to a port $p$ with the following behavior:\n  1. If $p = p_c$, where $p_c$ is the device’s valid port number, the device updates its state according to $$D \\leftarrow (D + (v \\bmod 2^{32})) \\bmod 2^{32}.$$\n  2. If $p \\neq p_c$, the device raises a device-exception visible to the guest. Let the guest-visible exception flag be $E \\in \\{0,1\\}$, initially $0$. On invalid port, set $$E \\leftarrow 1$$ and leave $D$ unchanged.\n- Under virtualization:\n  - If $\\mathrm{CPL} = 0$, the privileged instruction executes directly (conceptually “native”), but your emulator must still apply the same semantics to the virtual device state.\n  - If $\\mathrm{CPL} \\neq 0$, the instruction traps to the VMM, which must emulate the exact same semantics on the virtual device state $(D, E)$.\n\nImplement the minimal VMM and guest execution model for the single privileged instruction $\\mathrm{IOWRITE}(p, v)$ over a $32$-bit counter state. Use $p_c = 16$ as the valid port number. The initial guest-visible exception flag is $E = 0$ for each test case.\n\nYour program must:\n- Represent guest state $(D, E, \\mathrm{CPL})$.\n- Execute the privileged instruction $\\mathrm{IOWRITE}(p, v)$ by either direct semantics when $\\mathrm{CPL} = 0$ or trap-and-emulate when $\\mathrm{CPL} \\neq 0$, ensuring identical guest-visible results.\n- Use $32$-bit modular arithmetic for the counter: $(x \\bmod 2^{32})$ and addition modulo $2^{32}$.\n\nTest Suite and Expected Answers:\nFor each test, you are given initial values and the instruction parameters. Compute the final $(D, E)$ and compare to the expected values. For each test, output a boolean result as an integer $1$ if both $D$ and $E$ match the expected values, otherwise output $0$.\n\nLet $p_c = 16$. The tests are:\n\n- Test $1$ (happy path, user mode):\n  - Inputs: $D_0 = 100$, $p = 16$, $v = 10$, $\\mathrm{CPL} = 3$.\n  - Expected: $D_f = 110$, $E_f = 0$.\n\n- Test $2$ (kernel mode, wrap-around near upper bound):\n  - Inputs: $D_0 = 0$, $p = 16$, $v = 2^{32} - 50$, $\\mathrm{CPL} = 0$.\n  - Expected: $D_f = (0 + ((2^{32} - 50) \\bmod 2^{32})) \\bmod 2^{32} = 2^{32} - 50$, $E_f = 0$.\n\n- Test $3$ (boundary input $v = 0$, user mode):\n  - Inputs: $D_0 = 500$, $p = 16$, $v = 0$, $\\mathrm{CPL} = 3$.\n  - Expected: $D_f = 500$, $E_f = 0$.\n\n- Test $4$ (invalid port, user mode):\n  - Inputs: $D_0 = 777$, $p = 99$, $v = 12345$, $\\mathrm{CPL} = 3$.\n  - Expected: $D_f = 777$, $E_f = 1$.\n\n- Test $5$ (value larger than $2^{32}$, reduction then add, user mode):\n  - Inputs: $D_0 = 42$, $p = 16$, $v = 2^{33} + 5$, $\\mathrm{CPL} = 3$.\n  - Expected: Since $(2^{33} + 5) \\bmod 2^{32} = 5$, we have $D_f = (42 + 5) \\bmod 2^{32} = 47$, $E_f = 0$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[1,0,1,1,1]\"), in the exact order of the test suite above. No other output is permitted.",
            "solution": "The solution demonstrates the principle of trap-and-emulate by implementing a function, `execute_iowrite`, that deterministically applies the semantics of the privileged instruction $\\mathrm{IOWRITE}(p, v)$ to a virtual device state. The core idea is that this function's logic is identical regardless of the Current Privilege Level (CPL), ensuring semantic equivalence between native execution and VMM emulation.\n\nThe implementation models the guest-visible state using a `GuestState` struct containing the 32-bit counter `D`, the exception flag `E`, and the CPL. To correctly handle the modular arithmetic and potentially large input values, specific C data types are chosen:\n- `D` is represented by `unsigned int`, assumed to be 32 bits. The C standard guarantees that arithmetic on unsigned integers is performed modulo $2^N$, which naturally implements the required addition modulo $2^{32}$.\n- The instruction parameter `v` is represented by `unsigned long long` (a 64-bit type) to accommodate values larger than $2^{32}$ (as in Test 5) without overflow before the modular reduction.\n\nThe `execute_iowrite` function encapsulates the instruction's logic:\n1. It compares the given port `p` against the valid port number `pc = 16`.\n2. If the port is valid (`p == pc`), it updates the counter. The operation $D \\leftarrow (D + (v \\bmod 2^{32})) \\bmod 2^{32}$ is achieved by first casting the 64-bit `v` to a 32-bit `uint32_t` (performing $v \\bmod 2^{32}$) and then adding the result to the `unsigned int D`.\n3. If the port is invalid (`p != pc`), it sets the exception flag `E` to 1, leaving `D` unchanged.\n\nThe `main` function acts as a test harness. It iterates through the provided test suite, initializes the guest state for each test, calls `execute_iowrite` to simulate the instruction, and compares the final state $(D, E)$ against the expected outcome. The result of each comparison (1 for match, 0 for mismatch) is stored and printed in the specified comma-separated format.",
            "answer": "```c\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n// #include <complex.h>\n// #include <threads.h>\n// #include <stdatomic.h>\n\n// Assuming 'unsigned int' is 32 bits, a standard on modern 32/64-bit systems.\n// This is necessary as <stdint.h> is not a permitted header.\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n\n// Represents the guest-visible state. The CPL is part of the state\n// but does not affect the emulation logic itself, illustrating the core principle.\ntypedef struct {\n    uint32_t D; // 32-bit virtual device counter state\n    int E;      // Guest-visible exception flag\n    int CPL;    // Current Privilege Level\n} GuestState;\n\n// Represents the parameters for the IOWRITE privileged instruction.\ntypedef struct {\n    int p;      // Port number for the I/O write\n    uint64_t v; // Value to write (64-bit to handle inputs > 2^32)\n} Instruction;\n\n// Bundles initial state, instruction, and expected final state for a single test.\ntypedef struct {\n    GuestState initial_state;\n    Instruction instruction;\n    GuestState expected_final_state;\n} TestCase;\n\n// Emulates the semantics of the IOWRITE(p, v) privileged instruction.\n// This function implements the behavior of the virtual device, which must be\n// identical whether the instruction is executed \"natively\" (CPL=0) or\n// trapped-and-emulated by the VMM (CPL!=0).\nvoid execute_iowrite(GuestState* current_state, const Instruction* instr) {\n    const int pc = 16; // The valid port number for the Virtual Counter Device.\n\n    if (instr->p == pc) {\n        // Valid port: update the device state D.\n        // The rule is D <- (D + (v mod 2^32)) mod 2^32.\n\n        // 1. Calculate (v mod 2^32): Casting the 64-bit 'v' to a 32-bit unsigned\n        //    integer correctly performs the modulo 2^32 operation.\n        uint32_t value_to_add = (uint32_t)(instr->v);\n\n        // 2. Calculate (D + result) mod 2^32: C's standard unsigned integer\n        //    arithmetic naturally handles addition modulo 2^32.\n        current_state->D += value_to_add;\n    } else {\n        // Invalid port: raise a device exception.\n        // The state D is unchanged, and the exception flag E is set.\n        current_state->E = 1;\n    }\n}\n\nint main(void) {\n    // Define the test suite from the problem statement.\n    // Note on values:\n    // Test 2: v = 2^32 - 50 = 4294967296 - 50 = 4294967246\n    // Test 5: v = 2^33 + 5 = 8589934592 + 5 = 8589934597\n    TestCase test_cases[] = {\n        // Test 1: Happy path, user mode.\n        {{100, 0, 3}, {16, 10}, {110, 0, 3}},\n        // Test 2: Kernel mode, wrap-around near upper bound.\n        {{0, 0, 0}, {16, 4294967246ULL}, {4294967246U, 0, 0}},\n        // Test 3: Boundary input v = 0, user mode.\n        {{500, 0, 3}, {16, 0}, {500, 0, 3}},\n        // Test 4: Invalid port, user mode.\n        {{777, 0, 3}, {99, 12345}, {777, 1, 3}},\n        // Test 5: Value larger than 2^32, user mode.\n        {{42, 0, 3}, {16, 8589934597ULL}, {47, 0, 3}}\n    };\n\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    int results[num_cases];\n\n    // Process each test case.\n    for (int i = 0; i < num_cases; ++i) {\n        // Create a copy of the initial state to work on.\n        GuestState current_state = test_cases[i].initial_state;\n        \n        // Execute the emulated instruction.\n        execute_iowrite(&current_state, &test_cases[i].instruction);\n        \n        // Check if the resulting state matches the expected state.\n        if (current_state.D == test_cases[i].expected_final_state.D &&\n            current_state.E == test_cases[i].expected_final_state.E) {\n            results[i] = 1; // Success\n        } else {\n            results[i] = 0; // Failure\n        }\n    }\n\n    // Print the results in the exact required format.\n    // The output is a single line with no trailing newline character.\n    printf(\"[\");\n    for (int i = 0; i < num_cases; ++i) {\n        printf(\"%d\", results[i]);\n        if (i < num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n\n    return EXIT_SUCCESS;\n}\n```"
        },
        {
            "introduction": "While virtualization provides powerful abstraction, it comes with performance overheads, particularly in memory management. This exercise guides you through a quantitative analysis of nested page fault latency, a common cost in systems using hardware-assisted memory virtualization like Intel's Extended Page Tables (EPT). By modeling the expected delay from its constituent parts—including VM exits, Translation Lookaside Buffer (TLB) management, and potential disk I/O—you will learn to reason about and calculate the performance impact of virtualization on memory-intensive applications .",
            "id": "3689656",
            "problem": "A Virtual Machine (VM) running on a host uses two-dimensional paging via Extended Page Tables (EPT). In this setting, a nested page fault occurs when a memory access from a guest process triggers both guest-level handling and a second-level translation event handled by the Virtual Machine Monitor (VMM). Consider a memory-intensive application with a fault rate of $\\lambda$ faults per second. The following experimentally characterized latencies for each nested page fault are available, measured under steady-state load on a modern multicore system:\n\n- Virtual Machine exit overhead per fault: $t_{\\text{exit}} = 0.7 \\,\\mu\\text{s}$.\n- Virtual Machine entry overhead per fault: $t_{\\text{entry}} = 0.7 \\,\\mu\\text{s}$.\n- EPT page table update in the VMM: $t_{\\text{ept\\_update}} = 1.5 \\,\\mu\\text{s}$.\n- Translation Lookaside Buffer (TLB) shootdown and refill cost: $t_{\\text{tlb}} = 3.5 \\,\\mu\\text{s}$.\n- Additional page-walk time due to second-level translation: $t_{\\text{walk\\_extra}} = 0.8 \\,\\mu\\text{s}$.\n- Guest minor fault handler time (allocation and mapping without disk): $t_{\\text{guest\\_minor}} = 9.0 \\,\\mu\\text{s}$.\n\nWhen the guest fault is major, a disk-backed page-in is required. In virtualization, this disk service path induces an additional device virtualization overhead. Empirically:\n\n- Probability the nested fault is a guest major fault: $p = 0.012$.\n- Average disk service time per major fault (including host scheduling): $t_{\\text{disk}} = 4.0 \\,\\text{ms}$.\n- Additional I/O virtualization overhead for a major fault (device emulation and VM scheduling): $t_{\\text{virt\\_io}} = 0.300 \\,\\text{ms}$.\n\nAssume the nested page fault latency $L$ is the expected time per fault obtained from first principles by decomposing the common costs that occur for every nested fault and the conditional major-fault costs weighted by their probability. The total added delay per second $\\Delta$ induced by nested page faults for the application is given by the product of the fault rate and the expected latency per fault.\n\nUsing only these definitions and facts, derive $L$ from first principles and then compute $\\Delta = \\lambda L$ for a fault rate of $\\lambda = 1200 \\,\\text{faults}/\\text{s}$. Express the final numerical value of $\\Delta$ in $\\text{s}/\\text{s}$ and round your answer to four significant figures.",
            "solution": "The goal is to calculate the total added delay per second, $\\Delta$, caused by nested page faults. This is given by the formula $\\Delta = \\lambda L$, where $\\lambda$ is the fault rate and $L$ is the expected latency per fault. The derivation proceeds by first principles to find $L$.\n\nThe expected latency $L$ is the weighted average of the latency for a minor fault, $L_{\\text{minor}}$, and a major fault, $L_{\\text{major}}$, where a major fault occurs with probability $p$. Using the law of total expectation:\n$$\nL = (1-p) L_{\\text{minor}} + p L_{\\text{major}}\n$$\nA major fault includes all the steps of a minor fault plus the time for disk I/O ($t_{\\text{disk}}$) and I/O virtualization ($t_{\\text{virt\\_io}}$). So, $L_{\\text{major}} = L_{\\text{minor}} + t_{\\text{disk}} + t_{\\text{virt\\_io}}$. Substituting this into the equation for $L$ and simplifying gives:\n$$\nL = (1-p)L_{\\text{minor}} + p(L_{\\text{minor}} + t_{\\text{disk}} + t_{\\text{virt\\_io}})\n$$\n$$\nL = L_{\\text{minor}} + p(t_{\\text{disk}} + t_{\\text{virt\\_io}})\n$$\nThe latency of a minor fault, $L_{\\text{minor}}$, is the sum of all non-disk-related overheads:\n$$\nL_{\\text{minor}} = t_{\\text{exit}} + t_{\\text{entry}} + t_{\\text{ept\\_update}} + t_{\\text{tlb}} + t_{\\text{walk\\_extra}} + t_{\\text{guest\\_minor}}\n$$\nSubstituting the given values (after converting all units to seconds):\n$L_{\\text{minor}} = (0.7 + 0.7 + 1.5 + 3.5 + 0.8 + 9.0) \\times 10^{-6}\\,\\text{s} = 16.2 \\times 10^{-6}\\,\\text{s}$\n\nThe additional expected latency from major faults is:\n$$\np(t_{\\text{disk}} + t_{\\text{virt\\_io}}) = 0.012 \\times (4.0 \\times 10^{-3} + 0.300 \\times 10^{-3})\\,\\text{s} = 0.012 \\times 4.3 \\times 10^{-3}\\,\\text{s} = 0.0516 \\times 10^{-3}\\,\\text{s} = 51.6 \\times 10^{-6}\\,\\text{s}\n$$\nNow, we compute the total expected latency $L$:\n$$\nL = L_{\\text{minor}} + p(t_{\\text{disk}} + t_{\\text{virt\\_io}}) = 16.2 \\times 10^{-6}\\,\\text{s} + 51.6 \\times 10^{-6}\\,\\text{s} = 67.8 \\times 10^{-6}\\,\\text{s}\n$$\nFinally, we calculate the total added delay per second, $\\Delta$, using the given fault rate $\\lambda = 1200 \\,\\text{faults}/\\text{s}$:\n$$\n\\Delta = \\lambda L = (1200 \\,\\text{s}^{-1}) \\times (67.8 \\times 10^{-6}\\,\\text{s}) = 0.08136\n$$\nThe result is a dimensionless value representing the fraction of each second spent on fault handling. The value $0.08136$ has four significant figures as required.",
            "answer": "$$\n\\boxed{0.08136}\n$$"
        },
        {
            "introduction": "In multi-tenant cloud environments, providing predictable performance requires strict resource management, especially for I/O. This problem explores how to enforce a Service Level Agreement (SLA) for storage I/O using the token bucket algorithm, a classic traffic shaping technique. Your task is to derive the necessary configuration that guarantees a VM its specified I/O rate and burst capacity, even when competing with other VMs, teaching you how to formally reason about system behavior to provide quality-of-service guarantees .",
            "id": "3689722",
            "problem": "A hypervisor manages per-tenant storage Input/Output (I/O) for multiple Virtual Machines (VMs) by enforcing per-VM quotas. Each VM is assigned a Service Level Agreement (SLA) defined by a sustained I/O rate $r$ (in bytes per second) and an instantaneous burst allowance $b$ (in bytes). The hypervisor uses a per-VM token-bucket gate in front of a work-conserving round-robin I/O scheduler. The token-bucket gate permits a VM to dispatch I/O only when sufficient tokens are available; tokens accumulate at a fixed rate up to a finite bucket depth. The round-robin scheduler selects among backlogged VMs in fixed-length quanta of $\\Delta$ seconds per active VM. The storage device provides a constant service rate $C$ (in bytes per second). Admission control ensures feasibility: the sum of reserved rates across all concurrently active VMs does not exceed $C$.\n\nAssume the following.\n- The token accrual is continuous in time at the configured rate, up to the configured bucket depth.\n- There are $M$ active VMs that can be simultaneously backlogged, and the round-robin scheduler cycles through them in quanta of length $\\Delta$ seconds, so a backlogged VM can experience a worst-case deferral before being scheduled again.\n- The disk is work-conserving and delivers at least the aggregate admitted rate when backlogged.\n- The SLA to be enforced for a designated VM is the standard token-bucket service envelope: in any time window of length $T \\ge 0$, the VM should be able to obtain service up to $b + r T$, provided it has that much demand, even under mixed workloads where other VMs may be backlogged.\n\nPropose a scheme that uses a per-VM token bucket in conjunction with the round-robin scheduler to enforce the SLA. Then, starting from the formal definition of token-bucket regulation and the worst-case service deferral of round-robin scheduling, derive the minimum bucket depth $B_{\\min}$ (in bytes) that must be configured for the designated VM so that, despite scheduler-induced service deferral under mixed workloads with up to $M$ active VMs, the VM still satisfies the SLA envelope $b + r T$ for all $T \\ge 0$. Express $B_{\\min}$ as a closed-form symbolic function of $b$, $r$, $M$, and $\\Delta$.\n\nYour final answer must be a single closed-form expression. No numerical evaluation is required, and no rounding is needed. State the expression only; do not include units inside the final answer.",
            "solution": "The problem requires the derivation of the minimum token-bucket depth, denoted as $B_{\\min}$, for a designated Virtual Machine (VM) to ensure its Service Level Agreement (SLA) is met, despite potential service delays induced by a round-robin scheduler.\n\nFirst, we establish the scheme for enforcing the SLA. The hypervisor's per-VM token-bucket gate for the designated VM will be configured with a token accrual rate equal to the sustained I/O rate specified in the SLA, which is $r$ bytes/second. The depth of this token bucket is the parameter $B_{\\min}$ that we must determine.\n\nThe analysis proceeds by considering the worst-case scenario for the designated VM. The SLA guarantees that in any time window of length $T \\ge 0$, the VM should be able to obtain service for up to $b + r T$ bytes, provided it has sufficient demand. This can be interpreted as the VM having a service \"credit\" comprising a fixed (burst) component $b$ and a time-variable component that grows at rate $r$.\n\nThe worst-case service deferral occurs when our designated VM becomes backlogged (i.e., has I/O to dispatch) at the exact moment that $M-1$ other VMs also become backlogged. The work-conserving round-robin scheduler will serve each of these other VMs for its quantum of $\\Delta$ seconds before servicing our designated VM. Therefore, the maximum time our VM might have to wait for a service opportunity, despite being backlogged and having tokens to spend, is:\n$$T_{\\text{defer}} = (M-1)\\Delta$$\nThis period represents a \"service blackout\" from the perspective of the designated VM.\n\nDuring this service deferral period of length $T_{\\text{defer}}$, the VM is unable to have its I/O requests serviced by the disk. However, according to its SLA, its entitlement to service continues to accumulate. The SLA allows for an initial instantaneous burst of $b$ bytes. Over the deferral period $T_{\\text{defer}}$, the VM accrues an additional service entitlement of $r \\times T_{\\text{defer}}$ bytes.\n\nTo satisfy the SLA, the hypervisor's internal mechanisms must be able to buffer this total service entitlement, so that it can be dispatched to the storage device as soon as the scheduler makes the resource available. At the end of the worst-case deferral period, at time $T_{\\text{defer}}$, the total amount of data that the VM is entitled to have sent is the sum of its initial burst allowance and the allowance accrued during the wait:\n$$D_{\\text{entitled}} = b + r T_{\\text{defer}} = b + r(M-1)\\Delta$$\n\nThe per-VM token bucket is the mechanism that allows the VM to accumulate and \"stage\" its I/O requests ahead of their execution by the scheduler. The depth of this bucket determines the maximum amount of burst traffic the VM can submit to the scheduler's queue. To ensure that the VM never loses a service opportunity it is entitled to (which would happen if the token bucket overflowed), the bucket's depth must be large enough to accommodate the maximum possible service entitlement that could accumulate before being consumed.\n\nThis maximum accumulation corresponds to the worst-case scenario described above. Therefore, the minimum required depth of the token bucket, $B_{\\min}$, must be equal to the total service entitlement, $D_{\\text{entitled}}$, that can accumulate during the maximum service blackout period.\n$$B_{\\min} = b + r(M-1)\\Delta$$\n\nThis configuration ensures that even if the VM experiences the maximum possible scheduling delay of $(M-1)\\Delta$, its token bucket is sufficiently deep to store both its intrinsic burst allowance $b$ and the additional service credits $r(M-1)\\Delta$ that accrue during the delay. When the scheduler eventually serves the VM, this entire accumulated burst can be dispatched, thus satisfying the SLA requirement.",
            "answer": "$$\\boxed{b + r(M-1)\\Delta}$$"
        }
    ]
}