{
    "hands_on_practices": [
        {
            "introduction": "The foundation of hardware-assisted memory virtualization lies in the two-stage address translation process. Understanding this mechanism is crucial for grasping how a hypervisor provides memory isolation and management. This first exercise provides a concrete, step-by-step walkthrough of this entire pipeline, from a guest linear address to a final host physical address, navigating through both guest and host paging structures . By manually performing the translation and checking permissions, you will gain a deep, bit-level appreciation for how nested paging works in practice.",
            "id": "3657979",
            "problem": "A $32$-bit guest runs in supervisor mode with Physical Address Extension (PAE) enabled and No-Execute (NX) support active. The guest attempts a single-byte write to the guest linear address $0x\\mathrm{E5412345}$. The hypervisor uses Intel Extended Page Tables (EPT) for nested paging. Assume standard PAE semantics for index extraction and permissions, and standard EPT semantics for index extraction and permissions, including support for mixed page sizes.\n\nGuest paging structures (PAE):\n- The Page-Directory-Pointer Table Entry (PDPTE) at index $3$ is present and points to a Page Directory whose Page-Directory Entries (PDEs) are valid. You may assume that the PDPTE’s permissions do not further restrict supervisor writes beyond those implied by the PDE described below.\n- In the referenced Page Directory, the Page-Directory Entry at index $0x\\mathrm{12A}$ is marked present with Read/Write enabled and User/Supervisor indicating supervisor-only access, and has the Page Size bit set (it maps a $2\\,\\text{MiB}$ page). The No-Execute bit in this PDE is clear. This PDE maps a guest physical $2\\,\\text{MiB}$ frame whose base guest physical address is $0x\\mathrm{01A00000}$.\n\nEPT structures:\n- The EPT Page-Map Level $4$ (PML4) entry at index $0$ is readable/writable/executable and points to a valid EPT Page-Directory-Pointer Table (PDPT).\n- The EPT PDPT entry at index $0$ is readable/writable/executable and points to a valid EPT Page Directory (PD).\n- The EPT PD entry at index $13$ is readable/writable/executable, is not a large-page entry, and points to a valid EPT Page Table (PT).\n- The EPT Page-Table Entry (PTE) at index $18$ is readable and writable (executable is cleared) and maps a $4\\,\\text{KiB}$ host physical frame whose base host physical address is $0x\\mathrm{00000000008F3000}$.\n\nAssume that all unspecified entries along the guest and EPT walks are present and properly aligned, and that no other processor state (such as caching controls) affects permission checks for this access.\n\nTask:\n- Using definitions of PAE address translation and EPT address translation, derive the final host physical address corresponding to the guest’s write access. Explicitly verify at each step that the permissions permit a supervisor-mode write. If any permission would deny the access, you must terminate the derivation at that point; otherwise, compute the final address.\n- Express the final address as a single unsigned integer in hexadecimal with a $0x$ prefix. Do not round.",
            "solution": "The problem requires performing a two-stage memory address translation for a write access initiated by a guest operating system. The first stage translates the guest linear address to a guest physical address using the guest's paging structures (PAE). The second stage translates the resulting guest physical address to a host physical address using the hypervisor's Extended Page Tables (EPT). At each step of both translations, we must verify that the access permissions allow a supervisor-mode write.\n\n**Stage 1: Guest Linear Address to Guest Physical Address (GPA) Translation**\n\nThe guest is a $32$-bit system with Physical Address Extension (PAE) enabled. A $32$-bit linear address is translated using a three-level page table structure. The guest linear address to be translated is $LA_g = 0x\\mathrm{E5412345}$.\n\nUnder PAE, the $32$-bit linear address is partitioned as follows:\n- Bits $31-30$: Index into the Page-Directory-Pointer Table (PDPTE), $2$ bits.\n- Bits $29-21$: Index into the Page Directory (PD), $9$ bits.\n- Bits $20-0$: Offset within the page, $21$ bits (for a $2\\,\\text{MiB}$ page).\n\nWe parse the guest linear address $LA_g = 0x\\mathrm{E5412345}$:\n1.  **PDPTE Index**: The index is given by the top $2$ bits of the address.\n    $$ \\text{Index}_{\\text{PDPTE}} = \\frac{0x\\mathrm{E5412345}}{2^{30}} = \\lfloor \\frac{3846280005}{1073741824} \\rfloor = 3 $$\n    The problem states that the PDPTE at index $3$ is present and its permissions do not restrict a supervisor write. The access is therefore permitted at this level.\n\n2.  **Page Directory (PD) Index**: The index is given by bits $29-21$ of the address.\n    $$ \\text{Index}_{\\text{PD}} = \\left\\lfloor \\frac{0x\\mathrm{E5412345}}{2^{21}} \\right\\rfloor \\pmod{2^9} = \\left( \\frac{0x\\mathrm{E5412345}}{0x\\mathrm{200000}} \\right) \\& 0x\\mathrm{1FF} $$\n    $0x\\mathrm{E5412345} \\gg 21 = 0x\\mathrm{72A}$. The PD index is $0x\\mathrm{72A} \\& 0x\\mathrm{1FF} = 0x\\mathrm{12A}$.\n    The problem states that the Page-Directory Entry (PDE) at index $0x\\mathrm{12A}$ is present.\n\n3.  **Permission Check and Page Size Determination**:\n    The problem specifies the attributes of the PDE at index $0x\\mathrm{12A}$:\n    - **Present**: The entry is valid.\n    - **Read/Write (R/W)**: Enabled, allowing write accesses.\n    - **User/Supervisor (U/S)**: Set for supervisor-only access. The guest access is in supervisor mode, so this is permitted.\n    - **No-Execute (NX)**: Clear. This is irrelevant for a write access but poses no restriction.\n    - **Page Size (PS)**: Set. This indicates that the PDE maps a large page of size $2\\,\\text{MiB}$.\n\n    The access is a supervisor-mode write, which is fully permitted by this PDE. Since the PS bit is set, this is the final step of the guest address translation.\n\n4.  **Guest Physical Address (GPA) Calculation**:\n    For a $2\\,\\text{MiB}$ large page, the guest physical address is the sum of the base physical address from the PDE and the offset from the linear address.\n    - The base guest physical address from the PDE is given as $0x\\mathrm{01A00000}$.\n    - The offset is the lower $21$ bits of the linear address:\n      $$ \\text{Offset}_g = LA_g \\pmod{2^{21}} = 0x\\mathrm{E5412345} \\& 0x\\mathrm{1FFFFF} = 0x\\mathrm{12345} $$\n    - The resulting guest physical address is:\n      $$ \\text{GPA} = 0x\\mathrm{01A00000} + 0x\\mathrm{12345} = 0x\\mathrm{01A12345} $$\n\n**Stage 2: Guest Physical Address (GPA) to Host Physical Address (HPA) Translation**\n\nThe hypervisor uses Intel Extended Page Tables (EPT) to translate the GPA to a host physical address (HPA). This involves a four-level page walk using the GPA, $0x\\mathrm{01A12345}$. The EPT structure partitions a physical address into four $9$-bit indices and a $12$-bit offset.\n\nThe GPA, $0x\\mathrm{01A12345}$, is parsed as follows for the EPT walk:\n- Bits $47-39$: Index into the EPT Page-Map Level $4$ Table (PML4T).\n- Bits $38-30$: Index into the EPT Page-Directory-Pointer Table (PDPT).\n- Bits $29-21$: Index into the EPT Page Directory (PD).\n- Bits $20-12$: Index into the EPT Page Table (PT).\n- Bits $11-0$: Offset within the $4\\,\\text{KiB}$ page.\n\n1.  **EPT PML4 Index**: Since the GPA $0x\\mathrm{01A12345}$ is a $32$-bit address, its bits from $32$ to $47$ are all $0$.\n    $$ \\text{Index}_{\\text{PML4}} = \\left\\lfloor \\frac{0x\\mathrm{01A12345}}{2^{39}} \\right\\rfloor \\pmod{2^9} = 0 $$\n    The EPT PML4 entry at index $0$ is given as readable, writable, and executable. A write is permitted.\n\n2.  **EPT PDPT Index**: Bits $38-30$ of the GPA are also $0$.\n    $$ \\text{Index}_{\\text{PDPT}} = \\left\\lfloor \\frac{0x\\mathrm{01A12345}}{2^{30}} \\right\\rfloor \\pmod{2^9} = 0 $$\n    The EPT PDPT entry at index $0$ is given as readable, writable, and executable. A write is permitted.\n\n3.  **EPT PD Index**:\n    $$ \\text{Index}_{\\text{PD}} = \\left\\lfloor \\frac{0x\\mathrm{01A12345}}{2^{21}} \\right\\rfloor \\pmod{2^9} = (0x\\mathrm{01A12345} \\gg 21) \\& 0x\\mathrm{1FF} = 0xD = 13 $$\n    The EPT PD entry at index $13$ is given as readable, writable, and executable, and is not a large-page entry. A write is permitted, and the walk continues to the next level.\n\n4.  **EPT PT Index**:\n    $$ \\text{Index}_{\\text{PT}} = \\left\\lfloor \\frac{0x\\mathrm{01A12345}}{2^{12}} \\right\\rfloor \\pmod{2^9} = (0x\\mathrm{01A12345} \\gg 12) \\& 0x\\mathrm{1FF} = 0x\\mathrm{1A12} \\& 0x\\mathrm{1FF} = 0x\\mathrm{12} = 18 $$\n    The EPT Page-Table Entry (PTE) at index $18$ is the final entry in the EPT walk. It is given as readable and writable, which permits the guest's write access. The executable bit being cleared is not a restriction for a data write. This PTE maps a $4\\,\\text{KiB}$ host physical frame.\n\n5.  **Host Physical Address (HPA) Calculation**:\n    The HPA is the sum of the base host physical address from the EPT PTE and the offset from the GPA.\n    - The base host physical address from the PTE is given as $0x\\mathrm{00000000008F3000}$.\n    - The offset is the lower $12$ bits of the GPA:\n      $$ \\text{Offset}_h = \\text{GPA} \\pmod{2^{12}} = 0x\\mathrm{01A12345} \\& 0x\\mathrm{FFF} = 0x\\mathrm{345} $$\n    - The resulting host physical address is:\n      $$ \\text{HPA} = 0x\\mathrm{8F3000} + 0x\\mathrm{345} = 0x\\mathrm{8F3345} $$\n\nAll permission checks during both the guest-level and EPT-level translations have passed for a supervisor-mode write. The final host physical address is derived successfully.",
            "answer": "$$\\boxed{0x\\mathrm{8F3345}}$$"
        },
        {
            "introduction": "Beyond simple isolation, nested paging enables powerful and efficient hypervisor features. One of the most important is the ability to rapidly clone virtual machines using a technique called copy-on-write (COW). This practice moves from the raw mechanism of translation to a key application, exploring how a hypervisor can manipulate EPT permissions to share memory between a parent and child VM until a write occurs . This exercise demonstrates the elegant interplay between hardware capabilities and high-level system policies.",
            "id": "3657999",
            "problem": "A virtual machine manager (hypervisor) on an x86 platform that supports Intel Extended Page Tables (EPT) uses copy-on-write to implement fast virtual machine cloning. In this setting, the Central Processing Unit (CPU) performs two-stage address translation: a guest virtual address is translated to a guest physical address using the guest page tables, and then the guest physical address is translated to a host physical address using EPT. Hardware permission checks for writes are enforced by the intersection of permissions along this translation pipeline: a write is allowed only if all relevant permissions allow it; otherwise, a fault is raised to the appropriate handler.\n\nConsider a single virtual machine fork operation that clones a parent virtual machine to produce a child virtual machine. The hypervisor implements copy-on-write at the level of EPT leaf entries to initially share $S$ distinct host page frames between the two virtual machines. Each of these $S$ pages is currently mapped in the parent with an EPT leaf entry that grants read and write permissions. To establish copy-on-write sharing at fork time, the hypervisor must ensure that subsequent writes by either the parent or the child to any of these shared pages will be intercepted so that a private copy can be created.\n\nAssume the following operational model for the fork:\n- For each of the $S$ shared pages, the hypervisor modifies the parent’s existing EPT leaf entry to deny writes while continuing to allow reads.\n- For each of the $S$ shared pages, the hypervisor installs a corresponding EPT leaf entry in the child’s EPT that maps to the same host physical page as the parent and also denies writes while allowing reads.\n- Upper-level EPT structures (non-leaf levels) for both parent and child are already allocated or reused without modification for the address ranges covering these $S$ pages. Translation Lookaside Buffer (TLB) shootdowns, accessed or dirty bit side effects, and any later updates upon actual write faults are not counted here.\n\nUnder these conditions, compute the total number of EPT leaf-entry updates the hypervisor must perform during this single fork, expressed as a function of the shared page count $S$. Provide your answer as a closed-form analytic expression in terms of $S$. No rounding is required, and no units are needed.",
            "solution": "The objective is to compute the total number of Extended Page Table (EPT) leaf-entry updates required for a single virtual machine fork operation, as a function of the number of shared pages, $S$.\n\nThe problem specifies the following actions are performed by the hypervisor during the fork to establish COW sharing for $S$ pages:\n\n1.  **Updates for the Parent Virtual Machine:**\n    The problem states: \"For each of the $S$ shared pages, the hypervisor modifies the parent’s existing EPT leaf entry to deny writes while continuing to allow reads.\"\n    An EPT leaf entry is a data structure in memory that defines the mapping and permissions for a page. Modifying an existing entry, for example, by clearing the write-permission bit, constitutes an update to that memory location. Since this operation is performed for each of the $S$ shared pages, the number of EPT leaf-entry updates for the parent virtual machine is exactly $S$. Let us denote this count as $N_{parent}$.\n    $$N_{parent} = S$$\n\n2.  **Updates for the Child Virtual Machine:**\n    The problem states: \"For each of the $S$ shared pages, the hypervisor installs a corresponding EPT leaf entry in the child’s EPT that maps to the same host physical page as the parent and also denies writes while allowing reads.\"\n    The child virtual machine begins with its own, separate EPT structure. \"Installing\" a new EPT leaf entry means the hypervisor must create and write this entry into the appropriate leaf-level EPT page for the child. This act of writing the new entry's data is an update to the EPT structure. This operation is also performed for each of the $S$ shared pages. Therefore, the number of EPT leaf-entry updates for the child virtual machine is also $S$. Let us denote this count as $N_{child}$.\n    $$N_{child} = S$$\n\nThe problem explicitly asks for the *total* number of EPT leaf-entry updates. This total, which we can call $N_{total}$, is the sum of the updates performed for the parent's EPT and the updates performed for the child's EPT.\n\n$$N_{total} = N_{parent} + N_{child}$$\n\nSubstituting the values derived from the problem description:\n\n$$N_{total} = S + S$$\n$$N_{total} = 2S$$\n\nThe problem specifies that modifications to upper-level EPT structures, TLB shootdowns, and subsequent updates upon write faults are to be excluded from this count. The calculation above strictly adheres to these constraints, counting only the EPT leaf-entry updates performed at the moment of the fork operation.\n\nThus, the total number of EPT leaf-entry updates is twice the number of shared pages.",
            "answer": "$$\\boxed{2S}$$"
        },
        {
            "introduction": "While nested paging is powerful, managing page tables at scale introduces significant performance considerations, especially in modern multi-core systems. Every modification to an EPT entry may require invalidating cached translations in the Translation Lookaside Buffers (TLBs) across all cores—an expensive operation known as a TLB shootdown. This final exercise delves into system performance by modeling the cost of this process and challenging you to quantify the speedup gained from a critical optimization technique: batching updates to amortize the cost of shootdowns . This helps build an intuition for the performance engineering required in real-world hypervisor development.",
            "id": "3657962",
            "problem": "You are designing the update path in a hypervisor that uses Extended Page Tables (EPT) for nested paging on an $x86$ machine with $C$ physical cores. By definition of virtual memory correctness, any change to page tables must not leave stale cached translations in any Translation Lookaside Buffer (TLB), so after EPT entry changes, a TLB shootdown must invalidate those stale entries on all cores that may have cached them. A standard mechanism to achieve this is to send Inter-Processor Interrupts (IPIs) to participating cores and perform an EPT-context invalidation. Consider two strategies for applying $N$ EPT entry updates: a naive strategy and a batched strategy. The naive strategy applies each EPT update and immediately performs a global shootdown before proceeding to the next update. The batched strategy defers shootdowns by grouping updates into fixed-size batches of size $B$, performing a single global shootdown per batch, while ensuring that no virtual Central Processing Unit (CPU) executes with stale translations in-between (for example, by pausing vCPUs mapped to the EPT or holding a write lock on the EPT so no vCPU can run until the batch completes). Your batching algorithm must preserve the invariant that no stale EPT translation is used after an update; use memory ordering so that all EPT writes become visible before issuing the shootdown.\n\nAssume the following cost model for elapsed time on the updating thread:\n- Each EPT entry update takes $t_u = 0.12\\,\\mu\\text{s}$.\n- Per-batch bookkeeping/marking in the batched strategy adds $t_m = 0.03\\,\\mu\\text{s}$ per updated entry.\n- The wall-clock cost to complete one global TLB shootdown is\n$$t_s = (C-1)\\,t_{\\text{send}} + t_{\\text{ack}} + t_b,$$\nwhere $t_{\\text{send}} = 0.20\\,\\mu\\text{s}$ is the sender’s per-target IPI issue time, $t_{\\text{ack}} = 2.0\\,\\mu\\text{s}$ is the time for the slowest receiver to handle the IPI and acknowledge, and $t_b = 1.0\\,\\mu\\text{s}$ is a barrier/synchronization overhead.\n- Parameters: $C = 8$, $N = 4096$, $B = 128$.\n\nDefine speedup as $S = T_{\\text{naive}}/T_{\\text{batched}}$, where $T_{\\text{naive}}$ and $T_{\\text{batched}}$ are the elapsed times of the naive and batched strategies under the model above. Taking care to respect the TLB/EPT correctness invariants in your batching design and deriving from the fundamental requirement that updated page tables must be made visible to all cores before stale translations can be used, determine $S$.\n\nWhich option is closest to the correct value of $S$?\n\nA. $S \\approx 24.5$\n\nB. $S \\approx 29.3$\n\nC. $S \\approx 15.7$\n\nD. $S \\approx 128$",
            "solution": "The objective is to compute the speedup, $S$, defined as the ratio of the total time taken by the naive strategy, $T_{\\text{naive}}$, to the total time taken by the batched strategy, $T_{\\text{batched}}$.\n$$S = \\frac{T_{\\text{naive}}}{T_{\\text{batched}}}$$\nWe will calculate $T_{\\text{naive}}$ and $T_{\\text{batched}}$ based on the provided cost model and parameters.\n\nFirst, we calculate the cost of a single global TLB shootdown, $t_s$. The formula is given as:\n$$t_s = (C-1)\\,t_{\\text{send}} + t_{\\text{ack}} + t_b$$\nThe given parameter values are:\n- Number of physical cores, $C = 8$\n- IPI issue time per target, $t_{\\text{send}} = 0.20\\,\\mu\\text{s}$\n- Slowest receiver acknowledgment time, $t_{\\text{ack}} = 2.0\\,\\mu\\text{s}$\n- Barrier/synchronization overhead, $t_b = 1.0\\,\\mu\\text{s}$\n\nSubstituting these values into the equation for $t_s$:\n$$t_s = (8-1) \\times 0.20\\,\\mu\\text{s} + 2.0\\,\\mu\\text{s} + 1.0\\,\\mu\\text{s}$$\n$$t_s = 7 \\times 0.20\\,\\mu\\text{s} + 3.0\\,\\mu\\text{s}$$\n$$t_s = 1.4\\,\\mu\\text{s} + 3.0\\,\\mu\\text{s} = 4.4\\,\\mu\\text{s}$$\n\nNext, we calculate the total time for the naive strategy, $T_{\\text{naive}}$.\nIn the naive strategy, each of the $N$ EPT entry updates is followed immediately by a global TLB shootdown. The cost of one such cycle is the sum of the update cost, $t_u$, and the shootdown cost, $t_s$. This cycle is repeated $N$ times.\nThe given parameters are:\n- Number of EPT updates, $N = 4096$\n- EPT entry update time, $t_u = 0.12\\,\\mu\\text{s}$\n\nThe total time is:\n$$T_{\\text{naive}} = N \\times (t_u + t_s)$$\n$$T_{\\text{naive}} = 4096 \\times (0.12\\,\\mu\\text{s} + 4.4\\,\\mu\\text{s})$$\n$$T_{\\text{naive}} = 4096 \\times 4.52\\,\\mu\\text{s} = 18513.92\\,\\mu\\text{s}$$\n\nNow, we calculate the total time for the batched strategy, $T_{\\text{batched}}$.\nIn the batched strategy, the $N$ updates are grouped into batches of size $B = 128$. The number of batches is therefore:\n$$\\text{Number of batches} = \\frac{N}{B} = \\frac{4096}{128} = 32$$\nFor each batch, the process is as follows:\n1.  Perform $B$ updates. The total time for these updates is $B \\times t_u$.\n2.  Perform per-entry bookkeeping/marking for each of the $B$ updates. The problem states this adds a cost of $t_m = 0.03\\,\\mu\\text{s}$ per updated entry. So, the total marking cost for one batch is $B \\times t_m$.\n3.  Perform a single global TLB shootdown, which costs $t_s$.\n\nThe total time for one batch is the sum of these costs: $B \\times t_u + B \\times t_m + t_s$.\nThe total time for the batched strategy, $T_{\\text{batched}}$, is the cost per batch multiplied by the number of batches:\n$$T_{\\text{batched}} = \\left(\\frac{N}{B}\\right) \\times \\left(B \\cdot t_u + B \\cdot t_m + t_s\\right)$$\nThis can be algebraically simplified to group costs by type:\n$$T_{\\text{batched}} = N \\cdot t_u + N \\cdot t_m + \\left(\\frac{N}{B}\\right) \\cdot t_s$$\n$$T_{\\text{batched}} = N(t_u + t_m) + \\left(\\frac{N}{B}\\right)t_s$$\nSubstituting the given values:\n- $N = 4096$\n- $B = 128$\n- $t_u = 0.12\\,\\mu\\text{s}$\n- $t_m = 0.03\\,\\mu\\text{s}$\n- $t_s = 4.4\\,\\mu\\text{s}$\n\n$$T_{\\text{batched}} = 4096 \\times (0.12\\,\\mu\\text{s} + 0.03\\,\\mu\\text{s}) + \\left(\\frac{4096}{128}\\right) \\times 4.4\\,\\mu\\text{s}$$\n$$T_{\\text{batched}} = 4096 \\times (0.15\\,\\mu\\text{s}) + 32 \\times 4.4\\,\\mu\\text{s}$$\n$$T_{\\text{batched}} = 614.4\\,\\mu\\text{s} + 140.8\\,\\mu\\text{s}$$\n$$T_{\\text{batched}} = 755.2\\,\\mu\\text{s}$$\n\nFinally, we calculate the speedup, $S$:\n$$S = \\frac{T_{\\text{naive}}}{T_{\\text{batched}}} = \\frac{18513.92\\,\\mu\\text{s}}{755.2\\,\\mu\\text{s}}$$\n$$S \\approx 24.51515...$$\n\nThe calculated speedup is approximately $24.5$. We now evaluate the given options.\n\nA. $S \\approx 24.5$\nThis option matches our calculated value of $S \\approx 24.515$.\nVerdict: **Correct**\n\nB. $S \\approx 29.3$\nThis value is significantly different from our calculated result.\nVerdict: **Incorrect**\n\nC. $S \\approx 15.7$\nThis value is significantly different from our calculated result.\nVerdict: **Incorrect**\n\nD. $S \\approx 128$\nThis value is equal to the batch size $B$. It represents the factor by which the number of expensive shootdown operations is reduced ($N$ shootdowns in the naive case vs. $N/B$ shootdowns in the batched case, a reduction factor of $B$). However, speedup depends on the total time, which also includes the costs of updates ($t_u$) and marking ($t_m$). The total speedup will be less than the reduction factor of the most dominant cost component, because other costs (which are not reduced by the same factor) dilute the overall benefit.\nVerdict: **Incorrect**",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}