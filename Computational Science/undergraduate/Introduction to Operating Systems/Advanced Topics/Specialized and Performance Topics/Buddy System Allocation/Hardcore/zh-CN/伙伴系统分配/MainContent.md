## 引言
动态内存管理是现代[操作系统](@entry_id:752937)的心脏，它负责在运行时按需为进程和内核分配和回收内存资源。在这项复杂任务中，如何平衡分配速度、内存利用率和碎片化程度，是一个永恒的挑战。[伙伴系统](@entry_id:637828)（Buddy System）作为一种经典且高效的动态[内存分配策略](@entry_id:751844)，通过其优雅的、基于2的幂次方的分治思想，为这一问题提供了强有力的解决方案。它不仅是许多主流[操作系统](@entry_id:752937)（如Linux）物理[内存管理](@entry_id:636637)的基石，其设计哲学也影响了计算机科学的多个领域。

本文旨在全面而深入地剖析[伙伴系统](@entry_id:637828)。我们将不仅仅停留在理论层面，而是要揭示它在真实系统中的运作方式和面临的挑战。通过本文的学习，读者将理解为何一个看似简单的算法能够在复杂的现代计算环境中持续发挥核心作用。

我们将分三个章节展开探讨：
- **原理与机制**：本章将深入[伙伴系统](@entry_id:637828)的内部，从其核心的二分拆分与合并思想出发，揭示其背后精妙的[地址算术](@entry_id:746274)，并详细分析其在内、外碎片方面的性能权衡。
- **应用与跨学科连接**：本章将视野扩展到实际应用，展示[伙伴系统](@entry_id:637828)如何在[操作系统内核](@entry_id:752950)、线程管理、[NUMA架构](@entry_id:752764)、大页支持以及虚拟化中扮演关键角色，并探索其思想在存储、网络和安[全等](@entry_id:273198)领域的延伸。
- **动手实践**：通过一系列精心设计的编程问题，本章将引导读者在具体场景中应用所学知识，解决由硬件限制、对齐要求和工作负载模式引发的实际问题，从而巩固对[伙伴系统](@entry_id:637828)动态行为的理解。

让我们从[伙伴系统](@entry_id:637828)的核心原理开始，一探其究竟。

## 原理与机制

在上一章中，我们介绍了[伙伴系统](@entry_id:637828)（Buddy System）作为一种经典动态[内存分配策略](@entry_id:751844)的背景和基本目标。本章将深入探讨其核心工作原理与内部机制。我们将从其基础的二分拆分与合并思想出发，揭示其高效运转背后的[地址算术](@entry_id:746274)奥秘，分析其性能特征与固有的设计权衡，并最终讨论在真实[操作系统](@entry_id:752937)环境中实现[伙伴系统](@entry_id:637828)时必须面对的各种实际问题。

### 核心思想：二分拆分与合并

[伙伴系统](@entry_id:637828)的根本哲学在于，它将整个可管理的内存区域视为一个巨大的、大小为 $2$ 的幂次方的块。所有内存的分配和释放都围绕着两种基本操作展开：**拆分（Splitting）** 和 **合并（Coalescing）**。

当系统收到一个[内存分配](@entry_id:634722)请求时，例如需要大小为 $s$ 字节的空间，分配器首先会将请求的大小向上取整到一个 $2$ 的幂次方，我们称之为 $2^k$。这个大小既要能容纳请求的 $s$ 字节，又不能小于系统设定的最小块大小。接着，分配器会寻找一个大小恰好为 $2^k$ 的空闲块。如果找不到，它会寻找一个更大的空闲块，例如大小为 $2^{k+1}$ 的块，并将其**二分**成两个大小相等、地址相邻的“伙伴”块，每个的大小均为 $2^k$。其中一个伙伴块被用于满足当前请求（或继续向下拆分），而另一个则被加入到相应大小的空闲块列表中。这个拆分过程会递归地进行，直到产生一个大小合适、可以被分配的块为止。

与分配过程相反，当一个已分配的内存块被释放时，系统会尝试执行**合并**操作。分配器会检查这个刚刚被释放的块，其大小为 $2^k$，并找到它在诞生时配对的那个“伙伴”块。如果这个伙伴块当前也处于空闲状态，系统就会立即将这两个伙伴块合并成它们共同的“父块”，大小为 $2^{k+1}$。这个合并过程同样是递归的：新合并的父块会继续检查它自己的伙伴是否空闲，如此循环，直到遇到一个已被占用的伙伴或者达到了内存管理区域的边界为止。

这种持续的、及时的合并策略是[伙伴系统](@entry_id:637828)的一个关键特征。它确保了空闲内存会尽可能地聚合成更大的连续块，这一特性被称为**最大化合并**（Maximal Coalescence）。

### 伙伴机制：[地址算术](@entry_id:746274)的奥秘

“伙伴”这一概念是算法的核心，而高效地识别一个块的伙伴则是其实现的关键。[伙伴系统](@entry_id:637828)的精妙之处在于，它利用了二进制地址的结构特性，使得伙伴的查找成为一个极快的[位运算](@entry_id:172125)操作。

为了理解这一点，我们首先需要将内存地址[相对化](@entry_id:274907)。假设一个[内存管理](@entry_id:636637)区域的起始绝对地址为 $R$，总大小为 $2^M$ 字节。对于区域内任意一个绝对地址为 $a$ 的块，我们可以计算出其**相对地址** $a' = a - R$。[伙伴系统](@entry_id:637828)的所有对齐和配对规则都是基于这个相对地址空间来定义的。一个“$k$ 阶”（order-$k$）块，其大小为 $2^k$ 字节，它的相对地址 $a'$ 必须是 $2^k$ 的整数倍。这在二进制表示上意味着 $a'$ 的最低 $k$ 位必须全部为 $0$。

在拆分一个 $k+1$ 阶块时，其相对地址为 $p'$（$p'$ 的最低 $k+1$ 位为 $0$），它会产生两个 $k$ 阶的伙伴块。第一个伙伴块的相对地址仍然是 $p'$，第二个伙伴块的相对地址则是 $p' + 2^k$。观察它们的二进制表示，由于 $p'$ 的第 $k$ 位为 $0$，这两个地址仅在第 $k$ 位上不同（一个为 $0$，一个为 $1$），而所有其他位都完全相同。

基于这一观察，我们可以得出一个普适的伙伴查找公式。对于一个相对地址为 $a'$ 的 $k$ 阶块，其伙伴的相对地址 $b'$ 可以通过对 $a'$ 的第 $k$ 位进行翻转得到。这个操作等价于[位运算](@entry_id:172125)中的**异或（XOR）**：

$b' = a' \oplus 2^k$

这里的 $\oplus$ 表示[按位异或](@entry_id:269594)操作。$2^k$ 这个数在二[进制](@entry_id:634389)下只有第 $k$ 位为 $1$。因此，与 $2^k$ 进行异或，正好可以翻转第 $k$ 位而保持其他位不变 。

当内存区域的基地址 $R$ 不为零时，我们只需将绝对[地址转换](@entry_id:746280)为相对地址，执行[异或](@entry_id:172120)运算，再转换回绝对地址即可。给定一个绝对地址为 $a$ 的 $k$ 阶块，其伙伴的绝对地址 $b$ 计算公式为 ：

$b = ((a - R) \oplus 2^k) + R$

这个公式构成了[伙伴系统](@entry_id:637828)实现的基础。在调试或验证一个伙伴关系时，一个鲁棒的检查方法是，对于两个疑似伙伴的 $k$ 阶块，它们的相对地址 $i$ 和 $j$ 不仅要满足 $i \oplus j = 2^k$（或者等价的 $i \oplus j = 1 \ll k$），还必须各自都是 $2^k$ 的倍数，以确保它们是对齐正确的 $k$ 阶块 。

### 动态行为：一个完整的演练

为了将上述抽象规则具体化，让我们通过一个完整的操作序列来追踪[伙伴分配器](@entry_id:747005)的状态演变 。假设我们管理一个大小为 $2^{20}$ 字节（$1\,\mathrm{MiB}$）的内存池，最小块大小为 $2^8$ 字节，每个分配请求还需要额外 $32$ 字节的[元数据](@entry_id:275500)开销。

1.  **初始状态**：整个内存池是一个单一的、20阶（$2^{20}$ 字节）的空闲块，地址为 $0$。

2.  **分配 X (180,000 字节)**：请求大小加上[元数据](@entry_id:275500)为 $180,032$ 字节。向上取整到 $2$ 的幂次方，得到 $2^{18}$ 字节（$256\,\mathrm{KiB}$）。为此，系统将20阶块拆分为一个19阶的伙伴对，保留高地址的伙伴（地址 $2^{19}$）在19阶空闲列表中，并继续拆分低地址的伙伴。这个过程持续到产生一个18阶块。最终，地址为 $0$ 的18阶块被分配给 X，地址为 $2^{18}$ 的18阶块和地址为 $2^{19}$ 的19阶块成为空闲块。

3.  **分配 Y (200,000 字节)**：需要 $200,032$ 字节，同样向上取整为 $2^{18}$ 字节。此时，恰好有一个18阶的空闲块（地址 $2^{18}$），系统直接将其分配给 Y。

4.  **释放 Y**：地址为 $2^{18}$ 的18阶块被释放。系统检查其伙伴，即地址为 $2^{18} \oplus 2^{18} = 0$ 的块。由于该块正被 X 占用，合并无法进行。该释放的块被简单地加入18阶空闲列表。

5.  **释放 X**：地址为 $0$ 的18阶块被释放。系统检查其伙伴，即地址为 $0 \oplus 2^{18} = 2^{18}$ 的块。由于 Y 刚刚被释放，这个伙伴块现在是空闲的。于是，**第一次合并发生**：这两个18阶块合并成一个19阶块，地址为 $\min(0, 2^{18}) = 0$。

6.  **递归合并**：新生成的19阶空闲块（地址 $0$）会继续检查它自己的伙伴，即地址为 $0 \oplus 2^{19} = 2^{19}$ 的块。如果在后续操作中，所有占据地址空间 $[2^{19}, 2^{20}-1)$ 的分配都被释放，使得这个高地址的19阶伙伴块也变为空闲，那么它们将进一步合并，最终还原为最初的那个20阶的完整内存块。

这个例子生动地展示了[伙伴系统](@entry_id:637828)的动态特性：分配时通过拆分产生碎片，释放时通过合并消除碎片。一个关键的释放操作，如果其伙伴恰好空闲，就可能触发一连串的“级联合并”，迅速恢复大块的连续内存。

### 性能特征与权衡

[伙伴系统](@entry_id:637828)以其简洁的机制和高效的合并策略著称，但它也带来了独特的性能权衡，主要体现在[内部碎片](@entry_id:637905)和[外部碎片](@entry_id:634663)两个方面。

#### 内碎片问题

**内碎片（Internal Fragmentation）** 是指在一个已分配的内存块中，由于分配大小必须向上取整到预设的块规格（在[伙伴系统](@entry_id:637828)中是 $2$ 的幂次方），导致部分空间被分配出去但并未被应用程序实际请求或使用的部分。对于一个大小为 $s$ 的请求，如果分配器提供了一个大小为 $B$ 的块，那么内碎片就是 $B - s$。

[伙伴系统](@entry_id:637828)的内碎片问题是其最显著的缺点之一。由于块大小只能是 $2$ 的幂次方，这个“阶梯”可能很陡峭。例如，一个请求大小为 $65$ 字节（$2^6+1$）的请求，将被分配一个 $128$ 字节（$2^7$）的块，造成 $128 - 65 = 63$ 字节的浪费，浪费率接近 $50\%$。

我们可以精确地量化这个浪费。对于一个大小为 $B=2^k$ 的块，它用于满足大小为 $s$ 的请求，其中 $2^{k-1}  s \leq 2^k$。内碎片为 $B-s$，其范围是 $0 \leq B-s  B - 2^{k-1} = B/2$。这意味着，对于任何单次分配，内碎片的量严格小于所分配块大小的一半 。

为了评估最坏情况，我们可以构建一个“对抗性”的请求序列来最大化总内碎片 。为了在消耗给定大小的内存块时产生最多的碎片，我们应该请求尽可能小的数据量。例如，对于一个大小为 $2^k$ 的块，最坏的请求是 $s = 2^{k-1}+1$ 字节。分析表明，最能有效制造碎片的策略是反复请求系统能分配的最小块。如果最小块大小是 $2^{k_{\min}}$，那么反复请求 $1$ 字节将导致每次分配都产生 $2^{k_{\min}}-1$ 字节的内碎片。在一个总容量为 $2^{20}$ 字节、最小块为 $16$ 字节（$k_{\min}=4$）的系统中，一个由 $n$ 个1字节请求组成的序列将产生总计 $n \times (16-1) = 15n$ 字节的内碎片。

#### 外碎片问题

**外碎片（External Fragmentation）** 是指空闲内存总量足以满足一个请求，但由于这些空闲内存不连续，而是被分割成许多小块，导致没有一个单独的块足够大，从而使请求失败。

[伙伴系统](@entry_id:637828)通过其“最大化合并”[不变性](@entry_id:140168)，在很大程度上缓解了外碎片问题。由于任何一对相邻的空闲伙伴都会被立即合并，系统中绝不会存在“本可以合并但未合并”的空闲块。从这个意义上说，[伙伴系统](@entry_id:637828)**没有可避免的外碎片** 。

然而，这并不意味着[伙伴系统](@entry_id:637828)完全消除了外碎片。[合并操作](@entry_id:636132)有严格的限制：只有互为伙伴的块才能合并。如果两个空闲块在地址上相邻，但不是伙伴关系，它们就无法合并。考虑这样一个场景：在一个 $1024\,\mathrm{B}$ 的内存区域中，系统先后分配了四个 $200\,\mathrm{B}$ 的请求（每个都向上取整为 $256\,\mathrm{B}$）。此时内存被 A, B, C, D 四个 $256\,\mathrm{B}$ 的块占满。然后，我们释放块 A 和块 C。现在，系统中有两个空闲的 $256\,\mathrm{B}$ 块，总空闲内存为 $512\,\mathrm{B}$。但A和C不是伙伴（A的伙伴是B，C的伙伴是D），因此它们不能合并。此时如果有一个 $300\,\mathrm{B}$ 的请求（向上取整为 $512\,\mathrm{B}$），尽管总空闲内存足够，分配请求仍会失败，因为系统中最大的连续空闲块只有 $256\,\mathrm{B}$。这个例子清晰地表明，外碎片在[伙伴系统](@entry_id:637828)中依然存在，只是其形式受到了伙伴关系的严格约束 。

#### 分配策略的影响

当需要拆分一个大块来满足小请求时，如果存在多个不同大小的空闲块可供选择，分配器应如何决策？这是一个重要的策略问题 。

*   **最近优先（Closest-Order-First）**：选择能够满足请求的、大小最接近的空闲块进行拆分。如果存在大小完全匹配的空闲块，则直接使用，不进行拆分。
*   **最大优先（Highest-Order-First）**：总是选择当前系统中最大的空闲块进行拆分，即使存在更小但同样合适的块。

直觉上，最大优先策略似乎很浪费。实践也证明了这一点。假设系统初始有一个10阶的空闲块和三个6阶的空闲块。当连续收到三个6阶块的请求时，“最近优先”策略会直接使用已有的三个6阶块，从而完整地保留了那个10阶的大块。而“最大优先”策略则会固执地三次拆分那个10阶的大块，导致其被“蚕食”，不复存在。当后续有一个10阶块的请求到来时，只有采用“最近优先”策略的系统能够满足。因此，**“最近优先”策略通过优先使用小块来保护大块的完整性，是更可取的设计**，它有助于为未来可能的大内存请求保留可能性。

### 实现细节与现实考量

将理论上的伙伴算法转化为一个健壮的[操作系统](@entry_id:752937)组件，需要考虑几个关键的实现问题。

#### 元[数据管理](@entry_id:635035)

分配器需要跟踪每个内存块的状态（空闲或已分配）以及它的大小。存储这些[元数据](@entry_id:275500)有两种主流方法 ：

1.  **中心化[位图](@entry_id:746847)（Centralized Bitmaps）**：为每个块大小的“阶”都维护一个[位图](@entry_id:746847)。在 $k$ 阶的[位图](@entry_id:746847)中，每一位对应一个潜在的 $k$ 阶块。这种方法的优点是元数据开销是固定的，与[内存分配](@entry_id:634722)的碎片化程度无关。其总空间开销是所有阶的潜在块数量之和。对于一个从 $k_{\min}$ 到 $k_{\max}$ 阶的系统，总位数约为 $2^{k_{\max}-k_{\min}+1}$。

2.  **块内头部（Per-Block Headers）**：在每个**已分配**的块的起始位置嵌入一个小的头部结构，用于存储其大小和状态。这种方法的优点是只有已分配的块才产生开销。但它的缺点是，在最坏情况下，当整个内存被分割成最小的块时，元数据的总开销会达到最大，即（最小块的数量 $\times$ 头部大小）。头部大小本身也需要足够容纳块的阶数信息（需要 $\lceil\log_2(\text{阶数})\rceil$ 位）。

比较这两种方法，当内存被高度碎片化时，块内头部的空间开销可能远大于[位图](@entry_id:746847)。而[位图](@entry_id:746847)法则提供了一种可预测且通常更紧凑的[元数据](@entry_id:275500)方案。

#### 处理非连续物理内存

真实的物理内存很少是单一、完美的连续区域。硬件设备、BIOS保留区等常常会在物理地址空间中留下“空洞”。[伙伴系统](@entry_id:637828)必须适应这种非连续性 。

一个直接的想法是在整个物理地址空间上运行一个全局[伙伴系统](@entry_id:637828)，并将空洞标记为“永久占用”。然而，这种方法行不通，因为[伙伴系统](@entry_id:637828)的[合并操作](@entry_id:636132)依赖于严格的物理地址邻接性。一个空洞会成为不可逾越的障碍，阻止位于其两侧的、本应是伙伴的块进行合并。例如，位于 $[0, 64\text{MiB})$ 的块和位于 $[96\text{MiB}, 160\text{MiB})$ 的块，即使在全局[地址计算](@entry_id:746276)上可能是伙伴，但它们之间隔着一个 $32\text{MiB}$ 的空洞，无法合并成一个物理上连续的块。

正确的适应方法是**为每个连续的物理内存区域（或称为“区域(Zone)”）实例化一个独立的[伙伴分配器](@entry_id:747005)**。例如，如果系统有三个可用的物理内存区域 `Zone 0`、`Zone 1` 和 `Zone 2`，那么就应该有三个独立的[伙伴系统](@entry_id:637828)实例，每个实例只在自己的区域内进行拆分和合并。这样自然就尊重了物理上的不连续性，并保证了所有分配出的块都是物理连续的。

#### 与高层机制的交互

[伙伴分配器](@entry_id:747005)是[操作系统内存管理](@entry_id:752942)体系中的一环，其能力有其边界。理解这些边界对于系统设计至关重要。

[伙伴系统](@entry_id:637828)的合并规则是刚性的。要将整个内存区域（例如一个 $2^K$ 大小的块）恢复为空闲状态，**必须释放掉该区域内的每一个被分配的子块**。哪怕只有一个最小的块被占用，向上合并的链条就会在某一层中断，导致无法形成完整的 $2^K$ 大小的块 。

在某些情况下，这种刚性会成为一个严重的问题 。考虑一个场景：一个 $1\text{MiB}$ 的内存区域，在地址 $0$ 的位置有一个大小为 $4\text{KiB}$ 的**被钉住（pinned）**的页。这个页由于被用于DMA操作等原因不能被移动。此时，即使该页之外的所有内存都已释放，[伙伴系统](@entry_id:637828)也无法将低半区的 $512\text{KiB}$ 空间合并成一个完整的块，因为地址 $0$ 的块被占用了。因此，仅靠[伙伴系统](@entry_id:637828)的合并机制，能得到的最大连续空闲块可能远小于实际的空闲内存总量。

这时，就需要更高层次的机制介入，例如**内存规整（Memory Compaction）**。[操作系统](@entry_id:752937)可以启动一个进程，将所有“可移动”的内存页复制到别处，并更新对应的[页表](@entry_id:753080)，从而将小的空闲块“挤”到一起，形成一个大的连续空闲区域。在上述例子中，通过内存规整，系统可以将其他所有已分配的可移动页都挪到那块被钉住的页旁边，从而释放出一大块连续的内存。这个例子说明，[伙伴系统](@entry_id:637828)擅长快速的分配和合并，但面对由不可移动对象造成的碎片化时，就需要与内存规整这类更强大但开销也更大的机制协同工作。