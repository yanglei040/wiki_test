{
    "hands_on_practices": [
        {
            "introduction": "Understanding false sharing begins with a simple question: when do two different memory addresses land in the same cache line? This exercise challenges you to move from intuition to a precise mathematical rule. By deriving an indicator based on memory offsets and the cache line size $B$, you'll develop a foundational tool for analyzing data structure layouts and identifying potential performance hotspots during code reviews .",
            "id": "3641010",
            "problem": "In a byte-addressable shared-memory system, the memory hierarchy uses a data cache that organizes main memory into fixed-size cache lines of size $B$ bytes. Two concurrent writes by different threads to distinct addresses that reside in the same cache line can cause false sharing. By definition, memory addresses that fall within the same half-open interval $[kB,(k+1)B)$ for some integer $k$ are contained in the same cache line.\n\nConsider a structure allocated at a base address $A$ that is $B$-aligned (i.e., $A$ is a multiple of $B$). For code review purposes, you want a predicate that flags a pair of fields as risky if their starting byte offsets from $A$ map to the same cache line. Assume each field is strictly contained within a single cache line (no field straddles two cache lines), and you are given $B=64$ bytes and six struct fields with starting byte offsets $o_1=0$, $o_2=40$, $o_3=64$, $o_4=68$, $o_5=120$, $o_6=160$ relative to $A$.\n\nStarting from the fundamental definition above (addresses in the same interval $[kB,(k+1)B)$ share a cache line), derive an analytic indicator $S(o_i,o_j,B)$ that returns $1$ if a pair of starting offsets $o_i$ and $o_j$ share a cache line and returns $0$ otherwise. Then, using this indicator, determine the total number of unordered distinct pairs among the six fields that would be flagged as risky by this predicate. Express your final answer as a single integer.",
            "solution": "The problem requires us to first derive an analytic predicate, which we will call an indicator function $S(o_i, o_j, B)$, to determine if two fields within a structure fall into the same cache line. Subsequently, we must use this indicator to count the number of such \"risky\" pairs among a given set of field offsets.\n\nFirst, we formalize the condition for two memory addresses to be in the same cache line. According to the problem statement, a cache line of size $B$ bytes corresponds to a half-open interval of memory addresses $[kB, (k+1)B)$ for some non-negative integer $k$. An address, let's call it $addr$, falls into the cache line indexed by $k$ if $kB \\le addr < (k+1)B$. Dividing by $B$ gives $k \\le \\frac{addr}{B} < k+1$. This is the definition of the floor function, so the cache line index $k$ for a given address $addr$ is $k = \\lfloor \\frac{addr}{B} \\rfloor$. Consequently, two distinct addresses, $addr_i$ and $addr_j$, reside in the same cache line if and only if they have the same cache line index:\n$$\n\\left\\lfloor \\frac{addr_i}{B} \\right\\rfloor = \\left\\lfloor \\frac{addr_j}{B} \\right\\rfloor\n$$\n\nThe problem considers fields within a structure allocated at a base address $A$. A field with a starting byte offset $o_i$ relative to $A$ has an absolute memory address of $addr_i = A + o_i$. Therefore, two fields with starting offsets $o_i$ and $o_j$ share a cache line if:\n$$\n\\left\\lfloor \\frac{A+o_i}{B} \\right\\rfloor = \\left\\lfloor \\frac{A+o_j}{B} \\right\\rfloor\n$$\n\nA crucial piece of information is that the base address $A$ is $B$-aligned. This means $A$ is a multiple of $B$, so we can write $A = mB$ for some integer $m$. Substituting this into our condition yields:\n$$\n\\left\\lfloor \\frac{mB+o_i}{B} \\right\\rfloor = \\left\\lfloor \\frac{mB+o_j}{B} \\right\\rfloor\n$$\n$$\n\\left\\lfloor m + \\frac{o_i}{B} \\right\\rfloor = \\left\\lfloor m + \\frac{o_j}{B} \\right\\rfloor\n$$\nUsing the property of the floor function that $\\lfloor x+n \\rfloor = \\lfloor x \\rfloor + n$ for any integer $n$, we can simplify the equation:\n$$\nm + \\left\\lfloor \\frac{o_i}{B} \\right\\rfloor = m + \\left\\lfloor \\frac{o_j}{B} \\right\\rfloor\n$$\n$$\n\\left\\lfloor \\frac{o_i}{B} \\right\\rfloor = \\left\\lfloor \\frac{o_j}{B} \\right\\rfloor\n$$\nThis simplified condition shows that for a $B$-aligned structure, whether two fields share a cache line depends only on their offsets $o_i, o_j$ and the cache line size $B$, not on the base address $A$.\n\nWe can now define the analytic indicator $S(o_i, o_j, B)$, which returns $1$ if the fields share a cache line and $0$ otherwise. Based on our derived condition, the function is:\n$$\nS(o_i, o_j, B) =\n\\begin{cases}\n1 & \\text{if } \\left\\lfloor \\frac{o_i}{B} \\right\\rfloor = \\left\\lfloor \\frac{o_j}{B} \\right\\rfloor \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\n\nNext, we apply this indicator to the given data. The cache line size is $B = 64$ bytes. The six field offsets are $o_1=0$, $o_2=40$, $o_3=64$, $o_4=68$, $o_5=120$, and $o_6=160$. We compute the cache line index $k_i = \\lfloor \\frac{o_i}{64} \\rfloor$ for each offset:\n\\begin{itemize}\n    \\item $k_1 = \\lfloor \\frac{0}{64} \\rfloor = \\lfloor 0 \\rfloor = 0$\n    \\item $k_2 = \\lfloor \\frac{40}{64} \\rfloor = \\lfloor 0.625 \\rfloor = 0$\n    \\item $k_3 = \\lfloor \\frac{64}{64} \\rfloor = \\lfloor 1 \\rfloor = 1$\n    \\item $k_4 = \\lfloor \\frac{68}{64} \\rfloor = \\lfloor 1.0625 \\rfloor = 1$\n    \\item $k_5 = \\lfloor \\frac{120}{64} \\rfloor = \\lfloor 1.875 \\rfloor = 1$\n    \\item $k_6 = \\lfloor \\frac{160}{64} \\rfloor = \\lfloor 2.5 \\rfloor = 2$\n\\end{itemize}\n\nWe now have the cache line index for each field: $\\{k_1, k_2, k_3, k_4, k_5, k_6\\} = \\{0, 0, 1, 1, 1, 2\\}$. Two fields constitute a risky pair if they have the same cache line index. To count the number of unordered distinct pairs, we can group the fields by their cache line index:\n\\begin{itemize}\n    \\item Cache line $k=0$: Fields with offsets $\\{o_1, o_2\\}$. There are $N_0 = 2$ fields in this group.\n    \\item Cache line $k=1$: Fields with offsets $\\{o_3, o_4, o_5\\}$. There are $N_1 = 3$ fields in this group.\n    \\item Cache line $k=2$: Field with offset $\\{o_6\\}$. There are $N_2 = 1$ field in this group.\n\\end{itemize}\n\nThe number of unordered pairs within a group of size $N$ is given by the binomial coefficient $\\binom{N}{2} = \\frac{N(N-1)}{2}$. We calculate this for each group:\n\\begin{itemize}\n    \\item Number of risky pairs in the $k=0$ group: $\\binom{N_0}{2} = \\binom{2}{2} = \\frac{2(1)}{2} = 1$. This pair corresponds to $(o_1, o_2)$.\n    \\item Number of risky pairs in the $k=1$ group: $\\binom{N_1}{2} = \\binom{3}{2} = \\frac{3(2)}{2} = 3$. These pairs correspond to $(o_3, o_4)$, $(o_3, o_5)$, and $(o_4, o_5)$.\n    \\item Number of risky pairs in the $k=2$ group: $\\binom{N_2}{2} = \\binom{1}{2} = \\frac{1(0)}{2} = 0$.\n\\end{itemize}\nThe total number of risky pairs is the sum of the pairs from all groups:\n$$\n\\text{Total risky pairs} = \\binom{2}{2} + \\binom{3}{2} + \\binom{1}{2} = 1 + 3 + 0 = 4\n$$\nTherefore, there are $4$ unordered distinct pairs of fields among the six given that would be flagged as risky.",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "Atomic operations provide powerful guarantees about memory ordering and indivisibility, but do they operate at the same granularity as the underlying hardware? This exercise explores the crucial distinction between logical atomicity and physical cache coherence, a common point of confusion for programmers . By analyzing a scenario involving an array of atomic flags, you will discover why false sharing can persist despite the use of atomics and learn to reason correctly about the interaction between software constructs and hardware behavior.",
            "id": "3641047",
            "problem": "Consider a shared-memory multiprocessor system where each Central Processing Unit (CPU) core has a private write-back cache and the system maintains coherence via a line-based protocol such as Modified, Exclusive, Shared, Invalid (MESI). The cache line size is $B$ bytes. A program spawns $p$ threads on different CPU cores. The threads operate on a shared array $A$ of atomic Boolean flags, where each element $A[i]$ is an atomic object of size $1$ byte and is stored contiguously in memory starting at an address aligned to $B$ bytes. Each thread $t$ repeatedly toggles a unique flag $A[i_t]$ using an atomic read-modify-write operation with sequential consistency semantics, and never accesses any other elements. The indices $i_t$ are distinct and, for concreteness, equal to $i_t = t$ for $t \\in \\{0,1,\\dots,p-1\\}$ with $p \\ge 2$.\n\nUse only the following foundational facts as the basis for your reasoning:\n- Caches transfer and track data at the granularity of cache lines; coherence protocols maintain a single-writer or multiple-reader discipline per cache line by invalidating or updating other caches’ copies when a write occurs.\n- An atomic operation provides indivisibility and specified ordering semantics with respect to other atomic operations, but does not alter the physical granularity at which cache coherence operates.\n- False sharing occurs when multiple threads access different variables that reside in the same cache line, and at least one thread writes, causing coherence traffic and performance degradation despite the absence of true data dependencies.\n\nSelect all statements that are correct in this setting.\n\nA. Using atomic operations on $A[i]$ eliminates false sharing because arbitration by the coherence protocol serializes access and prevents any extra invalidations when different threads write different $A[i]$.\n\nB. False sharing can still occur because coherence is enforced at cache-line granularity, so different threads toggling different $A[i]$ that reside in the same cache line will trigger invalidations and line transfers.\n\nC. Padding each $A[i]$ so that it occupies exactly $B$ bytes and aligning each $A[i]$ on a $B$-byte boundary ensures that no two distinct $A[i]$ share a cache line, thereby reducing false sharing at the cost of increased memory usage.\n\nD. Switching to acquire loads and relaxed stores (instead of sequential consistency) removes cache line invalidations on writes and therefore prevents false sharing.\n\nE. With cache line size $B$ and $1$-byte atomics stored contiguously starting at a $B$-byte-aligned base, up to $B$ consecutive elements $A[0],A[1],\\dots,A[B-1]$ reside within the same cache line; thus if $p \\le B$ and threads access $A[0],A[1],\\dots,A[p-1]$, they will all contend on the same cache line.\n\nF. Replacing atomic flags with non-atomic plain bytes while padding each element to $B$ bytes would eliminate false sharing, but would necessarily introduce a data race and undefined behavior even if each thread is the sole accessor of its own element.\n\nG. Aligning only the base of the array $A$ to $B$ bytes, while storing $1$-byte elements contiguously with no per-element padding, is sufficient to eliminate false sharing whenever each thread uses a unique index.",
            "solution": "The problem asks us to evaluate statements about false sharing in a scenario with an array of atomic flags. The core issue is the mismatch between the logical unit of operation (a 1-byte atomic flag) and the physical unit of cache coherence (a cache line of size $B$ bytes).\n\nThe setup is a canonical example of false sharing:\n- A shared array $A$ of 1-byte atomic flags is stored contiguously.\n- The base address of $A$ is aligned to a $B$-byte boundary.\n- $p$ threads on different cores each modify a unique flag $A[t]$.\n- Because the flags are 1-byte and contiguous, and the array starts on a cache line boundary, the first $B$ flags ($A[0]$ to $A[B-1]$) will all reside in the same physical cache line.\n- When a thread writes to its flag, the hardware's cache coherence protocol must give that thread's core exclusive ownership of the *entire cache line*. If other cores have a copy of this line, their copy must be invalidated. This \"ping-ponging\" of the cache line between cores, caused by writes to logically independent data within that line, is the essence of false sharing. Atomic operations ensure logical correctness but do not change this underlying physical behavior.\n\nWith this understanding, let's analyze each statement:\n\nA. Using atomic operations on $A[i]$ eliminates false sharing because arbitration by the coherence protocol serializes access and prevents any extra invalidations when different threads write different $A[i]$.\nAnalysis: This is incorrect. Atomic operations provide logical guarantees (indivisibility, ordering) but operate on top of the hardware's cache coherence mechanism. They do not change the fact that coherence is managed at the cache-line level. A write to any byte in a cache line requires the writing core to gain exclusive ownership of the entire line, which necessitates invalidating copies in other cores. These invalidations are not \"extra\"; they are fundamental to how MESI-like protocols work and are the direct cause of false sharing.\nVerdict: **Incorrect**.\n\nB. False sharing can still occur because coherence is enforced at cache-line granularity, so different threads toggling different $A[i]$ that reside in the same cache line will trigger invalidations and line transfers.\nAnalysis: This statement is a perfect description of the problem. Because multiple flags $A[i]$ share a cache line, a write to one flag by one thread will cause the coherence protocol to invalidate that line in the caches of other threads that might need to access their own flags within the same line. This leads to cache line transfers and performance degradation, which is precisely what false sharing is.\nVerdict: **Correct**.\n\nC. Padding each $A[i]$ so that it occupies exactly $B$ bytes and aligning each $A[i]$ on a $B$-byte boundary ensures that no two distinct $A[i]$ share a cache line, thereby reducing false sharing at the cost of increased memory usage.\nAnalysis: This is the standard and correct software solution to false sharing. By ensuring each logically independent piece of data ($A[i]$) resides in its own exclusive cache line, writes from different threads to different data elements will no longer interfere at the hardware level. This eliminates the false sharing phenomenon. The obvious trade-off is a significant increase in the memory footprint of the data structure.\nVerdict: **Correct**.\n\nD. Switching to acquire loads and relaxed stores (instead of sequential consistency) removes cache line invalidations on writes and therefore prevents false sharing.\nAnalysis: This is incorrect. Memory consistency models (like acquire-release or relaxed) dictate the ordering guarantees of memory operations as seen by other threads. They do not alter the physical mechanism of cache coherence. A `relaxed` store is still a write operation that modifies memory. If this write targets a shared cache line, the coherence protocol must still ensure the writing core has exclusive access, which involves invalidations. Weaker memory models might hide some latency by allowing more reordering, but they do not eliminate the fundamental coherence traffic that constitutes false sharing.\nVerdict: **Incorrect**.\n\nE. With cache line size $B$ and 1-byte atomics stored contiguously starting at a $B$-byte-aligned base, up to $B$ consecutive elements $A[0],A[1],\\dots,A[B-1]$ reside within the same cache line; thus if $p \\le B$ and threads access $A[0],A[1],\\dots,A[p-1]$, they will all contend on the same cache line.\nAnalysis: This is a direct and correct deduction from the problem setup. Since the array starts on a $B$-byte boundary and each element is 1 byte, the elements from index 0 to $B-1$ will occupy the first cache line. If the number of threads $p$ is less than or equal to $B$, and they access the first $p$ elements, then all $p$ threads will be performing write operations to the same cache line, creating a classic \"hotspot\" for false sharing.\nVerdict: **Correct**.\n\nF. Replacing atomic flags with non-atomic plain bytes while padding each element to $B$ bytes would eliminate false sharing, but would necessarily introduce a data race and undefined behavior even if each thread is the sole accessor of its own element.\nAnalysis: The first part is correct: padding would eliminate false sharing. The second part is incorrect. A data race occurs when two or more threads concurrently access the *same* memory location without synchronization, and at least one access is a write. In this scenario, each thread $t$ accesses only its own unique element $A[t]$. Since no two threads access the same memory location, there is no data race by definition. The behavior is well-defined.\nVerdict: **Incorrect**.\n\nG. Aligning only the base of the array $A$ to $B$ bytes, while storing 1-byte elements contiguously with no per-element padding, is sufficient to eliminate false sharing whenever each thread uses a unique index.\nAnalysis: This statement is incorrect. This describes the exact setup that *causes* false sharing, not the one that eliminates it. Aligning the base of the array ensures that the contention starts at the beginning of a cache line, but the contiguous storage of small elements is what groups them into a shared line, creating the problem.\nVerdict: **Incorrect**.",
            "answer": "B, C, E"
        },
        {
            "introduction": "In performance engineering, solutions are rarely free. Fixing one bottleneck can sometimes introduce costs elsewhere, such as increased memory consumption. The standard solution to false sharing—padding data structures—is a perfect example of this trade-off . This practice places you in a realistic scenario where you must weigh a substantial throughput gain against its memory cost, teaching you to quantify the efficiency of an optimization and make informed engineering decisions.",
            "id": "3640979",
            "problem": "A multicore system executes a microbenchmark in an introductory operating systems course investigating false sharing and cache alignment. Each of $T$ worker threads maintains its own array of $N$ structures that contain frequently updated counters. Without padding, each structure has size $s$ bytes. To mitigate false sharing, each structure is padded to $B$ bytes, where $B$ equals the processor cache line size. Padding reduces coherence traffic by ensuring that frequently written structures do not share a cache line across threads.\n\nAssume the following measured and known quantities:\n- Number of threads: $T = 8$.\n- Elements per thread: $N = 2 \\times 10^{6}$.\n- Unpadded structure size: $s = 24$ bytes.\n- Padded structure size equal to cache line size: $B = 64$ bytes.\n- Baseline throughput without padding: $X = 1.2 \\times 10^{8}$ operations per second (ops/sec).\n- Throughput with padding: $Y = 4.2 \\times 10^{8}$ ops/sec.\n\nStarting from first principles, use the definition that the total additional memory consumption due to padding across all threads is the difference between padded and unpadded total sizes, and that one mebibyte (MiB) equals $2^{20}$ bytes. Compute the ratio of throughput gain per mebibyte of extra memory consumed, defined as the throughput gain in ops/sec divided by the additional memory in MiB. Express your final answer in ops/sec per MiB and round your answer to four significant figures.",
            "solution": "The phenomenon of false sharing arises when multiple threads write to distinct variables that reside on the same cache line, causing frequent invalidations in the cache coherence protocol and reducing throughput. Padding each structure to the cache line size ensures that structures written by different threads are separated into distinct cache lines, reducing coherence traffic and potentially increasing throughput. We compare the throughput gain to the memory overhead incurred by padding.\n\nWe proceed from the definitions:\n\n1. The total memory used by all arrays without padding is\n$$\nM_{\\text{unpadded}} = T \\times N \\times s.\n$$\n\n2. The total memory used with padding to $B$ bytes is\n$$\nM_{\\text{padded}} = T \\times N \\times B.\n$$\n\n3. The additional memory consumption due to padding (the memory waste) is\n$$\nW_{\\text{bytes}} = M_{\\text{padded}} - M_{\\text{unpadded}} = T \\times N \\times (B - s).\n$$\n\n4. Convert this additional memory from bytes to mebibytes using $1 \\text{ MiB} = 2^{20}$ bytes:\n$$\nW_{\\text{MiB}} = \\frac{W_{\\text{bytes}}}{2^{20}}.\n$$\n\n5. The throughput gain due to padding is\n$$\nG = Y - X.\n$$\n\n6. The desired ratio of throughput gain per mebibyte of extra memory is\n$$\nR = \\frac{G}{W_{\\text{MiB}}}.\n$$\n\nNow substitute the given values:\n\n- $T = 8$,\n- $N = 2 \\times 10^{6}$,\n- $s = 24$,\n- $B = 64$,\n- $X = 1.2 \\times 10^{8}$,\n- $Y = 4.2 \\times 10^{8}$,\n- $2^{20} = 1{,}048{,}576$.\n\nCompute the additional memory in bytes:\n$$\nW_{\\text{bytes}} = 8 \\times \\left(2 \\times 10^{6}\\right) \\times (64 - 24) = 8 \\times 2 \\times 10^{6} \\times 40 = 640 \\times 10^{6}.\n$$\n\nConvert to mebibytes:\n$$\nW_{\\text{MiB}} = \\frac{640 \\times 10^{6}}{1{,}048{,}576} = \\frac{640{,}000{,}000}{1{,}048{,}576}.\n$$\nIt is helpful to keep this as an exact fraction for accuracy.\n\nCompute the throughput gain:\n$$\nG = 4.2 \\times 10^{8} - 1.2 \\times 10^{8} = 3.0 \\times 10^{8}.\n$$\n\nForm the ratio:\n$$\nR = \\frac{3.0 \\times 10^{8}}{ \\frac{640{,}000{,}000}{1{,}048{,}576} } = 3.0 \\times 10^{8} \\times \\frac{1{,}048{,}576}{640{,}000{,}000}.\n$$\n\nSimplify the scalar factor:\n$$\n\\frac{3.0 \\times 10^{8}}{640{,}000{,}000} = \\frac{300{,}000{,}000}{640{,}000{,}000} = \\frac{3}{6.4} = 0.46875.\n$$\n\nTherefore,\n$$\nR = 0.46875 \\times 1{,}048{,}576 = 491{,}520.\n$$\n\nRound to four significant figures:\n$$\nR \\approx 4.915 \\times 10^{5}.\n$$\n\nThe ratio represents the throughput gain in ops/sec per MiB of extra memory consumed due to padding.",
            "answer": "$$\\boxed{4.915 \\times 10^{5}}$$"
        }
    ]
}