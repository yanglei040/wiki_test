{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp the severity of priority inversion, it is essential to move from theory to calculation. This first exercise places you in the classic priority inversion scenario: a high-priority task is blocked on a mutex held by a low-priority task, while a series of medium-priority tasks are free to run. Your goal is to derive a model that quantifies the total delay, revealing how the problem can become unbounded as the number of interfering tasks grows . This practice forms the foundation for understanding why this issue is so critical in real-time systems.",
            "id": "3671212",
            "problem": "A uniprocessor scheduler uses fixed-priority preemptive scheduling with round-robin time slicing among tasks at the same priority. The Central Processing Unit (CPU) incurs a constant context switch overhead of duration $\\delta$ each time it dispatches a ready task to run. A single high-priority task $H$ attempts to acquire a mutex that is currently held by a low-priority task $L$. There is no priority inheritance mechanism: task $L$ keeps its low priority. At the instant $H$ blocks on the mutex, exactly $m$ medium-priority tasks $\\{M_{1}, M_{2}, \\ldots, M_{m}\\}$ are ready. Each medium-priority task, when scheduled, runs for exactly one time quantum of duration $q$ and then blocks on input/output for a time long enough that it does not become ready again during this episode. No other tasks arrive during the episode. Define the inversion delay $D_{\\text{inv}}$ for this experimental run as the elapsed time starting when $H$ blocks on the mutex and ending immediately after the last medium-priority task finishes its one quantum and blocks (that is, just before the dispatcher would run $L$ next). For this experiment design, you will vary $q$, $\\delta$, and $m$ across runs.\n\nUsing only the core definitions of fixed-priority preemptive scheduling, a time quantum, and context switch overhead, derive an analytic expression for $D_{\\text{inv}}$ as a function of $q$, $\\delta$, and $m$ for one run in the setting described. Then evaluate your expression for the specific parameter values $q = 3.7$ milliseconds, $\\delta = 0.23$ milliseconds, and $m = 19$. Round your numerical answer to four significant figures. Express the final delay in milliseconds. Provide only a single number as your final result.",
            "solution": "The problem presents a scenario involving task scheduling on a uniprocessor system and asks for the derivation and calculation of a specific metric termed \"inversion delay\".\n\n### Step 1: Problem Validation\n\nFirst, a critical validation of the problem statement is performed.\n\n**Extraction of Givens:**\n- **Scheduler Policy:** Fixed-priority preemptive scheduling. For tasks at the same priority level, round-robin time slicing is used.\n- **System:** Uniprocessor.\n- **Context Switch Overhead:** A constant duration $\\delta$ is incurred for each dispatch of a ready task.\n- **Task Set and State:**\n    - A high-priority task, $H$.\n    - A low-priority task, $L$, which holds a mutex.\n    - $m$ medium-priority tasks, $\\{M_{1}, M_{2}, \\ldots, M_{m}\\}$.\n    - The initial state begins at the instant task $H$ attempts to acquire the mutex held by $L$ and blocks. At this same instant, all $m$ medium-priority tasks are in the ready state.\n- **Task Behavior:**\n    - Each medium-priority task $M_i$, when scheduled, runs for exactly one time quantum of duration $q$.\n    - After running for its quantum, each $M_i$ blocks on an input/output operation and does not become ready again within the period of interest.\n- **Priority Inheritance:** Explicitly stated as not being implemented. Task $L$ retains its low priority.\n- **Definition of Inversion Delay, $D_{\\text{inv}}$:** The elapsed time from the moment $H$ blocks on the mutex until the moment the last of the $m$ medium-priority tasks finishes its quantum and blocks.\n- **Parameters for Evaluation:** $q = 3.7$ milliseconds, $\\delta = 0.23$ milliseconds, and $m = 19$.\n\n**Validation against Criteria:**\n- **Scientific Grounding:** The problem is firmly rooted in the fundamental principles of operating systems, specifically task scheduling, concurrency control (mutexes), and the well-documented phenomenon of priority inversion. All terms used ($q$, $\\delta$, preemption, priority) are standard in the field. The scenario is a classic example used to illustrate scheduling behavior.\n- **Well-Posedness:** The problem is well-posed. The initial conditions are precisely specified, the behavior of all relevant tasks is deterministic, and the quantity to be calculated, $D_{\\text{inv}}$, is defined with a clear start and end point. This structure ensures that a unique and meaningful solution can be derived.\n- **Objectivity:** The language is formal, precise, and free of any subjective or ambiguous terminology.\n\n**Verdict:** The problem statement is valid, being scientifically sound, well-posed, objective, and internally consistent. I will proceed with the derivation of the solution.\n\n### Step 2: Derivation of the Analytic Expression\n\nThe problem asks for the inversion delay, $D_{\\text{inv}}$, experienced by the high-priority task $H$. This delay is caused by the execution of the $m$ medium-priority tasks that preempt the low-priority task $L$, which holds the mutex needed by $H$.\n\nLet us define the start of our time measurement, $t=0$, as the instant that task $H$ blocks on the mutex.\nAt $t=0$, the set of ready tasks includes the low-priority task $L$ and the $m$ medium-priority tasks $\\{M_1, M_2, \\ldots, M_m\\}$. Task $H$ is now in the blocked state.\n\nAccording to the fixed-priority preemptive scheduling policy, the scheduler must always run a ready task from the highest-priority non-empty queue. Since the medium-priority tasks have a higher priority than task $L$, the scheduler will ignore $L$ and proceed to execute the medium-priority tasks.\n\nThe $m$ medium-priority tasks are all at the same priority level and are scheduled using a round-robin policy. This means they will be executed sequentially. Since their behavior is identical, the specific order of execution ($M_1, M_2, \\ldots$ or any other permutation) does not affect the total time elapsed. Let us assume they are scheduled in the order of their indices.\n\n1.  **Execution of Task $M_1$**: The scheduler selects $M_1$ to run. Before $M_1$ can execute, the system must perform a context switch to dispatch it. This incurs an overhead of $\\delta$. After the context switch, $M_1$ runs for its prescribed time quantum, $q$. The total time consumed for the system to process $M_1$ is the sum of the context switch time and the execution time: $t_1 = \\delta + q$. Upon completion of its quantum, $M_1$ blocks and is removed from the ready queue.\n\n2.  **Execution of Task $M_2$**: With $M_1$ blocked, the scheduler is invoked again. The highest-priority ready tasks are now $\\{M_2, \\ldots, M_m\\}$. The scheduler selects $M_2$. Again, a context switch of duration $\\delta$ is required, followed by execution for a quantum $q$. The time elapsed for this step is $t_2 = \\delta + q$.\n\nThis process repeats for all $m$ medium-priority tasks. Each task $M_i$ in the set requires a context switch of $\\delta$ and runs for a quantum of $q$ before blocking. The time contribution of each task $M_i$ is therefore $(\\delta + q)$.\n\nThe total inversion delay, $D_{\\text{inv}}$, is defined as the time until the last medium-priority task, $M_m$, finishes its quantum and blocks. This is the sum of the time contributions from all $m$ medium-priority tasks.\n\n$$D_{\\text{inv}} = \\sum_{i=1}^{m} (\\text{context switch for } M_i + \\text{run time of } M_i)$$\n$$D_{\\text{inv}} = \\sum_{i=1}^{m} (\\delta + q)$$\n\nSince $\\delta$ and $q$ are constants for all $m$ tasks, the summation simplifies to:\n$$D_{\\text{inv}} = m(q + \\delta)$$\nThis is the analytic expression for the inversion delay as a function of $m$, $q$, and $\\delta$.\n\n### Step 3: Numerical Evaluation\n\nThe problem provides the following specific values for the parameters:\n- $q = 3.7$ milliseconds\n- $\\delta = 0.23$ milliseconds\n- $m = 19$\n\nSubstituting these values into the derived expression:\n$$D_{\\text{inv}} = 19 \\times (3.7 + 0.23)$$\nFirst, calculate the sum inside the parentheses:\n$$q + \\delta = 3.7 + 0.23 = 3.93 \\text{ ms}$$\nNow, multiply by the number of medium-priority tasks, $m$:\n$$D_{\\text{inv}} = 19 \\times 3.93$$\n$$D_{\\text{inv}} = 74.67 \\text{ ms}$$\n\nThe problem requires the numerical answer to be rounded to four significant figures. The calculated value, $74.67$, already contains exactly four significant figures ($7$, $4$, $6$, and $7$). Therefore, no further rounding is needed. The final numerical result for the inversion delay is $74.67$ milliseconds.",
            "answer": "$$\\boxed{74.67}$$"
        },
        {
            "introduction": "Priority inversion is not solely caused by mutexes; it can also arise from the need for atomicity in critical kernel operations, often implemented using non-preemptive code sections. In this practice, we explore how a high-priority task can be blocked by a lower-priority task executing a non-preemptible piece of code. By analyzing the worst-case scenario, you will discover a fundamental principle of blocking analysis and learn to distinguish relevant information from distractors .",
            "id": "3671216",
            "problem": "In a fixed-priority, preemptive scheduler within an operating system, preemption is disabled inside explicit non-preemptive sections to ensure atomicity of certain kernel or user-level critical operations. Consider three periodic tasks with strictly ordered priorities $p_H > p_M > p_L$, where $H$ denotes the high-priority task, $M$ the medium-priority task, and $L$ the low-priority task. A job of task $H$ arrives at time $t=0$. The scheduler obeys the following fundamental rules: a ready job of higher priority preempts a lower-priority job immediately, except when the lower-priority job is inside a non-preemptive section; context switches occur instantaneously outside non-preemptive sections; and non-preemptive sections have a system-wide enforced upper bound $\\tau$.\n\nAssume the operating system enforces a maximum non-preemptive section length of $\\tau = 3.100\\ \\mathrm{ms}$. In the workload under consideration, the low-priority task $L$ occasionally enters a non-preemptive section of length $2.847\\ \\mathrm{ms}$, and the medium-priority task $M$ occasionally enters a non-preemptive section of length $1.802\\ \\mathrm{ms}$. Suppose a job of $H$ arrives at $t=0$ in the worst case with respect to blocking, and that $L$ has just entered its non-preemptive section at $t=0$. After $L$ leaves its non-preemptive section, $M$ may be ready to run. There are no other tasks in the system.\n\nStarting from the core definitions of preemption and non-preemptive sections, and without assuming any specialized protocol beyond the stated scheduler behavior, derive the maximum priority inversion delay $B$ that the job of $H$ can suffer due solely to non-preemptive sections of lower-priority tasks, and compute its numerical value for the given parameters $p_H$, $p_M$, $p_L$, and $\\tau$. Express your final answer in milliseconds and round to four significant figures.",
            "solution": "The problem asks for the maximum priority inversion delay, $B$, that a high-priority task $H$ can experience due to the non-preemptive sections of lower-priority tasks in a fixed-priority, preemptive scheduling system.\n\nFirst, we must establish the fundamental principles governing the scenario.\n1.  **Fixed-Priority Preemptive Scheduling**: In a set of ready tasks, the scheduler will always execute the one with the highest priority. If a task with a higher priority than the currently running task becomes ready, the higher-priority task will immediately preempt the running task.\n2.  **Non-Preemptive Section**: This is an exception to the preemption rule. If a task is executing within a non-preemptive section, it cannot be preempted by any other task, regardless of priority, until it exits the section.\n3.  **Priority Inversion**: This phenomenon occurs when a high-priority task is ready to run but is forced to wait for a lower-priority task to complete some activity. In this problem, the cause of priority inversion is explicitly limited to non-preemptive sections. The duration of this waiting is the priority inversion delay, also known as blocking time.\n\nLet the three tasks be $H$, $M$, and $L$, with priorities $p_H > p_M > p_L$. A job of task $H$ arrives at time $t=0$ and becomes ready to run.\n\nFor task $H$ to be blocked, it must become ready while a lower-priority task ($M$ or $L$) is already running inside a non-preemptive section. If a lower-priority task were running but not in a non-preemptive section, $H$ would preempt it instantly, and no blocking would occur.\n\nThe maximum blocking time for task $H$ will occur under a specific worst-case sequence of events:\n1.  A lower-priority task (say, task $i$, where $p_i < p_H$) enters its non-preemptive section of duration $C_{i,np}$.\n2.  An infinitesimal time $\\epsilon > 0$ after task $i$ enters its section, the high-priority task $H$ becomes ready to run.\n3.  Because task $i$ is in a non-preemptive section, the scheduler cannot preempt it in favor of $H$. Task $H$ is now blocked.\n4.  Task $H$ must wait for task $i$ to complete its entire non-preemptive section. The duration of this wait is $C_{i,np}$.\n5.  Once task $i$ exits its non-preemptive section, the scheduler is invoked. The set of ready tasks includes $H$, $i$, and potentially other tasks that became ready during the blocking interval. In our problem, the prompt states that task $M$ may be ready at this point.\n6.  The scheduler must choose the highest-priority task from the ready queue. Since $p_H$ is the highest priority ($p_H > p_M > p_L$), task $H$ is guaranteed to be selected for execution.\n\nThis analysis reveals a critical point: a high-priority task can be blocked by at most one non-preemptive section of a single lower-priority task. Once the blocking section is finished, $H$ will run, preventing any other lower-priority task (like $M$) from being scheduled and subsequently entering its own non-preemptive section to cause further blocking. The statement \"After $L$ leaves its non-preemptive section, $M$ may be ready to run\" is included to test this understanding; even if $M$ is ready, it cannot run because $H$ has higher priority and is also ready.\n\nTherefore, the maximum priority inversion delay, $B$, that task $H$ can suffer is the duration of the longest non-preemptive section among all tasks with a priority lower than $p_H$.\n\nThe tasks with priority lower than $p_H$ are $M$ and $L$. The problem provides the lengths of their respective non-preemptive sections:\n- Length of task $L$'s non-preemptive section, $C_{L,np} = 2.847\\ \\mathrm{ms}$.\n- Length of task $M$'s non-preemptive section, $C_{M,np} = 1.802\\ \\mathrm{ms}$.\n\nThe maximum delay $B$ is the maximum of these values:\n$$\nB = \\max(C_{L,np}, C_{M,np})\n$$\nSubstituting the given values:\n$$\nB = \\max(2.847\\ \\mathrm{ms}, 1.802\\ \\mathrm{ms})\n$$\n$$\nB = 2.847\\ \\mathrm{ms}\n$$\nThe problem also provides a system-wide maximum non-preemptive section length, $\\tau = 3.100\\ \\mathrm{ms}$. This value acts as an upper bound for any non-preemptive section in the system. The given section lengths for tasks $L$ and $M$ ($2.847\\ \\mathrm{ms}$ and $1.802\\ \\mathrm{ms}$) are both less than $\\tau$, which confirms the consistency of the problem statement. However, the maximum blocking for this specific workload is determined by the actual characteristics of the tasks involved, not the theoretical system-wide limit.\n\nThe prompt specifies a scenario where \"L has just entered its non-preemptive section at t=0\". Since task $L$ has the longer of the two non-preemptive sections, this specific scenario indeed corresponds to the worst-case blocking for task $H$.\n\nThe final value for the maximum priority inversion delay is $2.847\\ \\mathrm{ms}$. The problem asks for the answer to be rounded to four significant figures. The number $2.847$ already has four significant figures, so no rounding is necessary.",
            "answer": "$$\\boxed{2.847}$$"
        },
        {
            "introduction": "The full cost of priority inversion often hides in the subtle interactions between software and hardware. This final practice delves into one such effect: cache thrashing. You will model and calculate how a preempting medium-priority task not only consumes CPU time but also degrades the performance of the low-priority task by evicting its data from the cache. This exercise demonstrates that the total inversion delay is more than just the sum of execution times, connecting high-level scheduling concepts to the concrete realities of microarchitectural performance .",
            "id": "3671221",
            "problem": "Consider a single-core system with fixed-priority preemptive scheduling and three threads: a high-priority thread $T_{H}$, a medium-priority thread $T_{M}$, and a low-priority thread $T_{L}$. The low-priority thread $T_{L}$ holds a mutual exclusion (mutex) lock that $T_{H}$ needs to enter its critical section. There is no priority inheritance. While $T_{L}$ holds the lock, the scheduler allows $T_{M}$ to preempt $T_{L}$ whenever $T_{M}$ is runnable, for a fixed time slice of duration $\\Delta$. The Central Processing Unit (CPU) frequency is $f$ cycles per second.\n\nAssume the following working-set and cache interaction model. Each time $T_{M}$ runs, it touches $e$ cache lines that map to the same sets as those currently relevant to $T_{L}$’s critical section, evicting them from the shared cache. When $T_{L}$ resumes after each preemption, it will incur exactly one extra cache miss for each of those $e$ lines as it reloads them, with a miss penalty of $p$ cycles per miss. This pattern repeats for $k$ preemptions before $T_{L}$ finally releases the lock.\n\nParameters:\n- CPU frequency $f = 2.5 \\times 10^{9}$ cycles per second.\n- Miss penalty $p = 200$ cycles per miss.\n- Evicted lines per preemption $e = 128$.\n- Number of preemptions $k = 75$.\n- Medium-priority time slice per preemption $\\Delta = 1$ millisecond.\n\nStarting from the definitions that time due to a cost in cycles is cycles divided by cycles-per-second, and that priority inversion is the extra waiting incurred by a higher-priority thread due to lower-priority thread lock holding and interference by medium-priority activity, derive from first principles:\n\n1. The added delay $M$ experienced by $T_{L}$ due solely to the extra cache misses caused by $T_{M}$’s evictions (express $M$ in milliseconds).\n2. The resultant priority inversion $D$ as the additional waiting time imposed on $T_{H}$ beyond the baseline case without $T_{M}$, taken as the sum of $T_{M}$’s scheduled run time while $T_{L}$ holds the lock and the cache-miss-induced delay $M$ (express $D$ in milliseconds).\n\nProvide exact values; no rounding is required. Express your final answer in milliseconds.",
            "solution": "We begin from two core facts:\n- A time cost in cycles converts to seconds by dividing by the CPU frequency, hence if a computation incurs $C$ cycles, the time in seconds is $C/f$.\n- Priority inversion, in this setting without priority inheritance, is the extra waiting imposed on the high-priority thread $T_{H}$ because the low-priority thread $T_{L}$ holds a lock, while the medium-priority thread $T_{M}$ preempts $T_{L}$ and also degrades $T_{L}$’s progress via cache thrashing.\n\nDefine the added delay $M$ due solely to cache thrashing. Each preemption by $T_{M}$ evicts $e$ cache lines relevant to $T_{L}$. Under the stated model, when $T_{L}$ resumes after a preemption, it will reload exactly those $e$ lines, incurring one extra miss per line. Let the per-miss penalty be $p$ cycles. Over $k$ preemptions, the total number of extra misses is $k \\cdot e$, and the total extra cycles incurred are\n$$\nC_{\\text{miss}} = k \\cdot e \\cdot p.\n$$\nConverting cycles to seconds using the CPU frequency $f$ yields\n$$\nt_{\\text{miss}} = \\frac{C_{\\text{miss}}}{f} = \\frac{k \\cdot e \\cdot p}{f}.\n$$\nTo express in milliseconds, multiply by $10^{3}$:\n$$\nM = 10^{3} \\cdot \\frac{k \\cdot e \\cdot p}{f} \\quad \\text{milliseconds}.\n$$\nSubstitute the given values $k = 75$, $e = 128$, $p = 200$, and $f = 2.5 \\times 10^{9}$:\nFirst compute cycles:\n$$\nC_{\\text{miss}} = 75 \\cdot 128 \\cdot 200 = 75 \\cdot 25{,}600 = 1{,}920{,}000 \\ \\text{cycles}.\n$$\nConvert to seconds:\n$$\nt_{\\text{miss}} = \\frac{1{,}920{,}000}{2.5 \\times 10^{9}} = 0.000768 \\ \\text{seconds}.\n$$\nConvert to milliseconds:\n$$\nM = 10^{3} \\cdot 0.000768 = 0.768 \\ \\text{milliseconds}.\n$$\n\nNext, define the resultant priority inversion $D$. In the absence of $T_{M}$, the baseline waiting of $T_{H}$ while $T_{L}$ holds the lock would not include $T_{M}$’s CPU time nor the cache-thrashing overhead. With $T_{M}$ present, the extra waiting attributable to $T_{M}$ is the sum of:\n- The scheduled run time of $T_{M}$ during each of the $k$ preemptions, which is $k \\cdot \\Delta$.\n- The added delay $M$ that $T_{L}$ experiences from cache misses, which directly extends the lock hold time and therefore $T_{H}$’s wait.\n\nTherefore,\n$$\nD = k \\cdot \\Delta + M.\n$$\nUsing $k = 75$ and $\\Delta = 1 \\ \\text{millisecond}$ gives\n$$\nk \\cdot \\Delta = 75 \\cdot 1 = 75 \\ \\text{milliseconds}.\n$$\nThus,\n$$\nD = 75 + 0.768 = 75.768 \\ \\text{milliseconds}.\n$$\n\nWe have derived $M$ and $D$ from first principles: extra misses per preemption induce an added cycle cost converted by $f$, and the total inversion combines scheduler-induced delay and cache-induced delay. Both values are expressed in milliseconds as required.",
            "answer": "$$\\boxed{\\begin{pmatrix}0.768 & 75.768\\end{pmatrix}}$$"
        }
    ]
}