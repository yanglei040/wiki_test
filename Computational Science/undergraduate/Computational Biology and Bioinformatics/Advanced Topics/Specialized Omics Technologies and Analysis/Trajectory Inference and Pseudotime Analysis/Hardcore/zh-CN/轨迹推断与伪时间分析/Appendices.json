{
    "hands_on_practices": [
        {
            "introduction": "在分析细胞分化等生物学过程时，一个关键的初始步骤是确定轨迹的“根”或起始点，这通常对应于最未分化的细胞状态。本练习将指导你应用信息论中的一个核心概念——香农熵 (Shannon entropy)，来量化多能性标志基因的表达集中度，从而以一种符合生物学直觉的方式，通过编程自动识别出最可能的根细胞 。这个方法为你提供了一个将抽象生物学问题转化为精确计算任务的范例。",
            "id": "2437518",
            "problem": "给定一个有限的单细胞集合，每个细胞都测量了多个基因，并指定了一个作为多能性标记的基因子集。对于每个细胞，通过一个加性的非负伪计数来归一化其非负的标记基因表达向量，从而定义一个在标记基因集上的概率分布。该分布的香农熵量化了该细胞内多能性标记基因表达的集中程度。将根细胞集定义为最小化此香农熵的细胞子集，平局时优先选择总标记基因表达量较大者，其次是细胞索引较小者。您的任务是编写一个完整程序，精确实现此定义，并为多个测试用例返回所选的一个或多个索引。\n\n形式上，假设有 $N$ 个细胞和 $G$ 个基因。令 $X \\in \\mathbb{R}_{\\ge 0}^{N \\times G}$ 为非负表达矩阵，其中条目 $x_{i,g}$ 表示细胞 $i \\in \\{0,\\dots,N-1\\}$ 中基因 $g \\in \\{0,\\dots,G-1\\}$ 的表达量。令 $M \\subseteq \\{0,\\dots,G-1\\}$ 为多能性标记基因索引的非空集合，且 $|M| = K \\ge 1$。对于一个给定的非负伪计数 $\\alpha \\in \\mathbb{R}_{\\ge 0}$，为每个细胞 $i$ 定义标记基因向量 $v_i \\in \\mathbb{R}_{\\ge 0}^{K}$，其分量为 $v_{i,g} = x_{i,g}$（对于 $g \\in M$），平滑后的标记基因向量 $w_i$ 的分量为 $w_{i,g} = v_{i,g} + \\alpha$，归一化常数 $s_i = \\sum_{g \\in M} w_{i,g}$。如果 $s_i > 0$，则定义分布 $p_i$ 的分量为 $p_{i,g} = \\dfrac{w_{i,g}}{s_i}$。如果 $s_i = 0$，则将 $p_i$ 定义为 $M$ 上的均匀分布，即对于所有 $g \\in M$，$p_{i,g} = \\dfrac{1}{K}$。定义细胞 $i$ 的香农熵（使用自然对数）为\n$$\nH_i = - \\sum_{g \\in M} p_{i,g} \\log p_{i,g},\n$$\n遵循通常的约定，即对于任何 $q \\in [0,1]$，当 $q = 0$ 时，$q \\log q = 0$。同时，定义不含伪计数的总标记基因表达量为\n$$\nS_i = \\sum_{g \\in M} v_{i,g} = \\sum_{g \\in M} x_{i,g}.\n$$\n给定一个目标根细胞数量 $r \\in \\{1,2,\\dots,N\\}$，将所选的根细胞集 $R$ 定义为 $\\{0,\\dots,N-1\\}$ 的一个大小为 $r$ 的子集，该子集满足以下字典序最小化规则：按 $H_i$ 递增排序所有细胞，若出现平局则按 $S_i$ 递减排序，若仍有平局则按索引 $i$ 递增排序。在此排序下取前 $r$ 个细胞构成 $R$。对于一个给定的测试用例，当 $r=1$ 时输出为 $\\{0,\\dots,N-1\\}$ 中的单个整数索引；当 $r>1$ 时输出为严格按数值递增排序的索引列表。\n\n您的程序必须为以下测试套件精确实现这些定义。在所有情况下，索引都是从零开始的。\n\n- 测试用例 1 (带平滑的通用情况)：\n  - $X = \\begin{bmatrix}\n  10  10  0 \\\\\n  20  0  0 \\\\\n  0  20  0 \\\\\n  5  5  10\n  \\end{bmatrix}$，\n  - $M = \\{0,1\\}$，\n  - $\\alpha = 1$，\n  - $r = 1$。\n- 测试用例 2 (熵值出现明确平局，由更大的总标记基因表达量解决)：\n  - $X = \\begin{bmatrix}\n  8  2 \\\\\n  16  4 \\\\\n  5  5\n  \\end{bmatrix}$，\n  - $M = \\{0,1\\}$，\n  - $\\alpha = 0$，\n  - $r = 1$。\n- 测试用例 3 (细胞中全零标记基因向量的边界情况，通过平滑处理)：\n  - $X = \\begin{bmatrix}\n  0  0 \\\\\n  0  10 \\\\\n  0  1\n  \\end{bmatrix}$，\n  - $M = \\{0,1\\}$，\n  - $\\alpha = 1$，\n  - $r = 1$。\n- 测试用例 4 (请求多个根细胞)：\n  - $X = \\begin{bmatrix}\n  10  0  0 \\\\\n  0  10  0 \\\\\n  3  3  3 \\\\\n  6  4  0 \\\\\n  9  1  0\n  \\end{bmatrix}$，\n  - $M = \\{0,1,2\\}$，\n  - $\\alpha = 1$，\n  - $r = 2$。\n\n您的程序应生成单行输出，其中包含按顺序汇总的四个测试用例的结果，形式为方括号内以逗号分隔的列表。每个元素必须是整数（当 $r=1$ 时）或按递增顺序排列的整数列表（当 $r>1$ 时）。例如，输出可能看起来像\n$[a,b,c,[d,e]]$\n其中 $a$、$b$、$c$ 是整数，而 $[d,e]$ 是一个整数列表。不应打印任何额外文本。",
            "solution": "该问题提出了一个定义明确的计算任务，其基础是生物信息学领域，特别是用于在单细胞数据集中识别根细胞。其定义在数学上是精确的，每个测试用例的参数都已完全指定，并且所需的选择标准是明确无误的。因此，该问题是有效的，并且可以直接通过算法求解。\n\n目标是从总共 $N$ 个细胞中识别出 $r$ 个根细胞的集合。选择基于字典序排序，其中在一个预定义的多能性标记基因集合上具有最集中表达谱的细胞被优先选择。这种集中程度通过香农熵 $H_i$ 来量化，该熵值源自从细胞的标记基因表达水平推导出的概率分布。\n\n执行过程如下：对于每个细胞 $i \\in \\{0, \\dots, N-1\\}$，我们计算两个用于排序的指标：香农熵 $H_i$ 和总标记基因表达量 $S_i$。\n\n首先，我们为每个细胞 $i$ 计算香农熵 $H_i$：\n1.  从表达矩阵 $X \\in \\mathbb{R}_{\\ge 0}^{N \\times G}$ 中，我们为细胞 $i$ 提取标记基因表达向量 $v_i \\in \\mathbb{R}_{\\ge 0}^{K}$。其分量为 $v_{i,g} = x_{i,g}$，其中基因索引 $g$ 属于标记基因集 $M$，$K = |M|$。\n2.  将一个非负伪计数 $\\alpha \\ge 0$ 加到 $v_i$ 的每个分量上，形成一个平滑向量 $w_i$，其分量为 $w_{i,g} = v_{i,g} + \\alpha$。当 $\\alpha > 0$ 时，此步骤可确保没有概率为零，从而避免对数问题，并处理细胞对所有标记基因表达量均为零的情况。\n3.  对向量 $w_i$ 进行归一化以创建一个概率分布 $p_i$。归一化常数为 $s_i = \\sum_{g \\in M} w_{i,g}$。\n4.  如果 $s_i > 0$，概率分布 $p_i$ 的分量为 $p_{i,g} = \\dfrac{w_{i,g}}{s_i}$。在 $s_i = 0$ 的特殊情况下（这只可能在 $\\alpha=0$ 且对于 $g \\in M$ 的所有相关标记基因表达 $x_{i,g}$ 均为零时发生），分布 $p_i$ 被定义为均匀分布，即对于所有 $g \\in M$，$p_{i,g} = \\dfrac{1}{K}$。\n5.  然后使用指定的自然对数计算该分布的香农熵：\n    $$\n    H_i = - \\sum_{g \\in M} p_{i,g} \\log p_{i,g}\n    $$\n    遵循 $q=0$ 时 $q \\log q = 0$ 的约定。较低的 $H_i$ 值表示标记基因的表达谱更集中、更不均匀。\n\n其次，我们为每个细胞 $i$ 计算总标记基因表达量 $S_i$。这是原始、未平滑的标记基因表达值的简单总和：\n$$\nS_i = \\sum_{g \\in M} x_{i,g}\n$$\n该指标用作主要的平局决胜规则。\n\n在为所有细胞计算出 $H_i$ 和 $S_i$ 后，我们建立一个唯一的细胞排序。排序是基于每个细胞 $i$ 的一组标准元组按字典序进行的：\n1.  主要标准：按香农熵 $H_i$ 升序。\n2.  次要标准（平局决胜）：按总标记基因表达量 $S_i$ 降序。\n3.  第三标准（最终平局决胜）：按细胞索引 $i$ 升序。\n\n这个排序过程可以通过对所有 $i \\in \\{0, \\dots, N-1\\}$ 的元组列表 $(H_i, -S_i, i)$ 进行排序来实现。\n\n最后，从这个唯一排序的列表中选择前 $r$ 个细胞，形成根细胞集 $R$。给定测试用例的输出是对应于这些选定细胞的索引（当 $r=1$ 时）或索引列表（当 $r>1$ 时）。如果 $r>1$，最终输出中的索引必须以严格的数值递增顺序呈现。\n\n该实现使用 Python 编写，利用 `numpy` 库进行高效的数组操作，并使用 `scipy.stats.entropy` 来稳健地计算香non熵。该算法为每个提供的测试用例精确地遵循了上述步骤。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import entropy\n\ndef find_roots(X_raw, M, alpha, r):\n    \"\"\"\n    Identifies root cells based on Shannon entropy and total marker expression.\n\n    Args:\n        X_raw (list of lists): The N x G gene expression matrix.\n        M (set): The set of marker gene indices.\n        alpha (float): The nonnegative pseudocount.\n        r (int): The number of root cells to select.\n\n    Returns:\n        int or list of int: The index or list of indices of the root cells.\n    \"\"\"\n    X = np.array(X_raw, dtype=float)\n    marker_indices = sorted(list(M))\n    num_cells = X.shape[0]\n    K = len(marker_indices)\n\n    cell_metrics = []\n\n    for i in range(num_cells):\n        # Extract marker vector v_i and calculate total marker expression S_i\n        v_i = X[i, marker_indices]\n        S_i = np.sum(v_i)\n\n        # Calculate smoothed marker vector w_i and normalization constant s_i\n        w_i = v_i + alpha\n        s_i = np.sum(w_i)\n\n        # Define probability distribution p_i\n        if s_i > 0:\n            p_i = w_i / s_i\n        else:\n            # This case occurs iff alpha=0 and all relevant x_i,g are 0.\n            # Define p_i as the uniform distribution on M.\n            p_i = np.full(K, 1.0 / K)\n\n        # Calculate Shannon entropy H_i using natural logarithm\n        H_i = entropy(p_i, base=np.e)\n\n        # Store metrics for lexicographical sorting: (H_i, -S_i, i)\n        # We use -S_i because the tie-breaker is in descending order of S_i.\n        cell_metrics.append((H_i, -S_i, i))\n\n    # Sort cells based on the specified criteria\n    cell_metrics.sort()\n\n    # Select the top r cell indices\n    root_indices = [metric[2] for metric in cell_metrics[:r]]\n\n    # Format the output as per the problem description\n    if r == 1:\n        return root_indices[0]\n    else:\n        # Return indices in strictly increasing numerical order\n        return sorted(root_indices)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"X\": [[10, 10, 0], [20, 0, 0], [0, 20, 0], [5, 5, 10]],\n            \"M\": {0, 1}, \"alpha\": 1, \"r\": 1\n        },\n        {\n            \"X\": [[8, 2], [16, 4], [5, 5]],\n            \"M\": {0, 1}, \"alpha\": 0, \"r\": 1\n        },\n        {\n            \"X\": [[0, 0], [0, 10], [0, 1]],\n            \"M\": {0, 1}, \"alpha\": 1, \"r\": 1\n        },\n        {\n            \"X\": [[10, 0, 0], [0, 10, 0], [3, 3, 3], [6, 4, 0], [9, 1, 0]],\n            \"M\": {0, 1, 2}, \"alpha\": 1, \"r\": 2\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = find_roots(case[\"X\"], case[\"M\"], case[\"alpha\"], case[\"r\"])\n        results.append(result)\n\n    # Helper function to format results into the required string format\n    def format_result(res):\n        if isinstance(res, list):\n            # Format list as '[d,e]' without spaces\n            return f\"[{','.join(map(str, res))}]\"\n        else:\n            return str(res)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(format_result, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "伪时间为细胞进行了排序，但它本身并未直接揭示生物过程的“速度”。细胞是通过某些阶段快速过渡，还是在其他阶段缓慢分化？本练习通过一个假设场景，引入了“分化速度”的定义，即细胞在伪时间轴上的密度 。通过这个计算，你将理解细胞在某个伪时间点 $\\tau$ 的累积速率如何直接与该点的细胞概率密度相关联，从而将抽象的统计模型与动态的生物学解释联系起来。",
            "id": "2437529",
            "problem": "一项单细胞RNA测序 (scRNA-seq) 研究使用轨迹推断为$N$个细胞中的每一个分配一个伪时间 $\\tau \\in [0,1]$。在一个特定的细胞谱系中，伪时间分配的分布可以很好地用一个形状参数为 $\\alpha = 2$ 和 $\\beta = 3$ 的贝塔分布来近似，其在 $[0,1]$ 上的概率密度函数为 $f(\\tau) = 12\\,\\tau\\,(1-\\tau)^{2}$。总共有 $N=800$ 个细胞。将伪时间 $\\tau$ 处的“分化速度”定义为预期累积细胞计数相对于伪时间的变化率，即 $\\frac{d}{d\\tau}\\big(\\text{伪时间} \\le \\tau \\text{的预期细胞数}\\big)$。计算在 $\\tau = 0.25$ 处的这个速度。请将您的答案表示为每个单位伪时间的精确细胞数，无需四舍五入。",
            "solution": "在继续之前，对问题陈述进行验证。\n\n步骤1：提取已知条件。\n- 细胞总数：$N = 800$。\n- 伪时间变量：$\\tau \\in [0, 1]$。\n- 伪时间分配分布的概率密度函数 (PDF) 服从形状参数为 $\\alpha = 2$ 和 $\\beta = 3$ 的贝塔分布。\n- PDF 的具体形式为 $f(\\tau) = 12\\tau(1-\\tau)^{2}$，其中 $\\tau \\in [0, 1]$。\n- “分化速度”被定义为预期累积细胞计数相对于伪时间的变化率：$\\frac{d}{d\\tau}\\big(\\text{伪时间} \\le \\tau \\text{的预期细胞数}\\big)$。\n- 任务是计算在特定伪时间 $\\tau = 0.25$ 处的这个速度。\n\n步骤2：使用提取的已知条件进行验证。\n该问题具有科学依据，提法明确且客观。它涉及轨迹推断，这是计算生物学中的一个标准课题。使用贝塔分布来模拟区间 $[0, 1]$ 上的变量是合适的。所提供的PDF，$f(\\tau) = 12\\tau(1-\\tau)^{2}$，对于参数为 $\\alpha=2$ 和 $\\beta=3$ 的贝塔分布是正确归一化的，因为贝塔函数 $B(\\alpha, \\beta)$ 是 $B(2, 3) = \\frac{\\Gamma(2)\\Gamma(3)}{\\Gamma(2+3)} = \\frac{1!2!}{4!} = \\frac{2}{24} = \\frac{1}{12}$，并且贝塔PDF的一般形式是 $\\frac{\\tau^{\\alpha-1}(1-\\tau)^{\\beta-1}}{B(\\alpha, \\beta)}$。所有定义都清晰且可数学形式化。不存在矛盾或信息缺失。\n\n步骤3：结论与行动。\n问题有效。将构建一个解决方案。\n\n解答过程如下。设 $T$ 是表示随机选择细胞的伪时间的随机变量。$T$ 的概率密度函数由 $f(\\tau) = 12\\tau(1-\\tau)^{2}$ 给出，其中 $\\tau \\in [0, 1]$。\n\n累积分布函数 (CDF)，记为 $F(\\tau)$，给出了一个细胞的伪时间小于或等于 $\\tau$ 的概率。它由PDF的积分定义：\n$$F(\\tau) = P(T \\le \\tau) = \\int_{0}^{\\tau} f(t) \\, dt$$\n对于总共 $N$ 个细胞，伪时间小于或等于 $\\tau$ 的预期细胞数，我们记为 $E(\\tau)$，是细胞总数乘以这个概率：\n$$E(\\tau) = N \\cdot F(\\tau) = N \\int_{0}^{\\tau} f(t) \\, dt$$\n问题将“分化速度”（我们称之为 $S(\\tau)$）定义为该预期累积细胞计数相对于伪时间的变化率。这是 $E(\\tau)$ 相对于 $\\tau$ 的导数：\n$$S(\\tau) = \\frac{d}{d\\tau} E(\\tau) = \\frac{d}{d\\tau} \\left( N \\int_{0}^{\\tau} f(t) \\, dt \\right)$$\n由于 $N$ 是一个常数，它可以移到导数符号的外面：\n$$S(\\tau) = N \\frac{d}{d\\tau} \\left( \\int_{0}^{\\tau} f(t) \\, dt \\right)$$\n根据微积分基本定理，一个积分对其上限的导数是该上限处的被积函数的值。因此：\n$$\\frac{d}{d\\tau} \\left( \\int_{0}^{\\tau} f(t) \\, dt \\right) = f(\\tau)$$\n将此代回 $S(\\tau)$ 的表达式，我们得到一个简单的关系：\n$$S(\\tau) = N f(\\tau)$$\n这个结果是合乎逻辑的：细胞在某个伪时间点累积的速率与该点的细胞密度成正比。\n\n我们需要计算在 $\\tau = 0.25$ 处的这个速度。我们有 $N = 800$ 和 $f(\\tau) = 12\\tau(1-\\tau)^{2}$。我们代入 $\\tau = 0.25$，这相当于 $\\frac{1}{4}$。\n\n首先，计算 PDF $f(\\tau)$ 在 $\\tau = \\frac{1}{4}$ 处的值：\n$$f\\left(\\frac{1}{4}\\right) = 12 \\left(\\frac{1}{4}\\right) \\left(1 - \\frac{1}{4}\\right)^{2}$$\n$$f\\left(\\frac{1}{4}\\right) = 12 \\left(\\frac{1}{4}\\right) \\left(\\frac{3}{4}\\right)^{2}$$\n$$f\\left(\\frac{1}{4}\\right) = 3 \\left(\\frac{9}{16}\\right)$$\n$$f\\left(\\frac{1}{4}\\right) = \\frac{27}{16}$$\n现在，我们使用 $S(\\frac{1}{4}) = N f(\\frac{1}{4})$ 来计算在这一点上的速度 $S(\\tau)$：\n$$S\\left(\\frac{1}{4}\\right) = 800 \\times \\frac{27}{16}$$\n为了简化计算，我们将 $800$ 除以 $16$：\n$$\\frac{800}{16} = \\frac{100 \\times 8}{16} = \\frac{100}{2} = 50$$\n最后，我们将这个结果乘以 $27$：\n$$S\\left(\\frac{1}{4}\\right) = 50 \\times 27 = 1350$$\n在 $\\tau = 0.25$ 处的分化速度是 $1350$ 细胞/单位伪时间。",
            "answer": "$$\\boxed{1350}$$"
        },
        {
            "introduction": "生物过程并非总是线性的；细胞常常在关键节点上做出命运选择，形成分叉结构。轨迹推断中的一个核心任务是确定数据是支持简单的线性路径，还是更复杂的F分叉结构。本练习要求你构建一个模型选择框架，用赤池信息准则 (Akaike Information Criterion, AIC) 或贝叶斯信息准则 (Bayesian Information Criterion, BIC) 来客观地判断数据集更符合线性模型还是分叉模型 。这是一个高级实践，它让你掌握如何通过惩罚模型复杂性来进行严谨的科学推断，从而确定最能解释数据的轨迹拓扑结构。",
            "id": "2437495",
            "problem": "给定平面上的一个有限点集，这些点代表从单细胞数据中获得的、嵌入到低维空间中的细胞。您将比较两个嵌套的轨迹模型，这两个模型将每个细胞映射到一个一维的伪时间，同时假设在垂直于轨迹的方向上存在各向同性的高斯噪声。两个候选模型是：一个线性轨迹模型和一个带单分叉（两条直线分支共享一个连接点）的分支轨迹模型。您的任务是实现一个程序，该程序为测试套件中的每个数据集根据赤池信息准则（AIC）或贝叶斯信息准则（BIC）判断哪个模型更优，并为每个数据集返回一个整数标志。最终输出必须是包含所有数据集对应整数列表的单行文本。\n\n基本建模假设和定义：\n- 设数据集为点 $\\{x_i\\}_{i=1}^n \\subset \\mathbb{R}^2$，其中 $x_i = (x_{i1}, x_{i2})^\\top$。假设每个细胞位于一条一维轨迹附近，且在垂直于轨迹的方向上存在各向同性的高斯噪声。\n- 对于线性模型 $\\mathcal{M}_{\\text{lin}}$，轨迹是一条直线：一个点 $m \\in \\mathbb{R}^2$ 和一个单位方向 $d \\in \\mathbb{R}^2$, $\\|d\\|_2 = 1$。$x_i$ 的伪时间是标量 $t_i = d^\\top (x_i - m)$。正交残差为 $r_i = (x_i - m) - t_i d$，残差平方和为 $RSS_{\\text{lin}} = \\sum_{i=1}^n \\|r_i\\|_2^2$。\n- 对于分支模型 $\\mathcal{M}_{\\text{br}}$，轨迹是共享一个公共连接点 $m \\in \\mathbb{R}^2$ 的两条直线的并集，有两条单位方向 $d_1, d_2 \\in \\mathbb{R}^2$，对 $j \\in \\{1,2\\}$ 有 $\\|d_j\\|_2 = 1$。每个细胞被分配到产生较小正交距离的分支。对于最小化垂直距离的分配 $a_i \\in \\{1,2\\}$，伪时间为 $t_i^{(a_i)} = d_{a_i}^\\top (x_i - m)$，正交残差为 $r_i^{(a_i)} = (x_i - m) - t_i^{(a_i)} d_{a_i}$。残差平方和为 $RSS_{\\text{br}} = \\sum_{i=1}^n \\min\\{\\|(x_i - m) - (d_1^\\top (x_i - m)) d_1\\|_2^2,\\|(x_i - m) - (d_2^\\top (x_i - m)) d_2\\|_2^2\\}$。\n- 高斯噪声模型和对数似然：假设正交偏差是独立同分布的，其一维高斯噪声为 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$，因此方差的最大似然估计量为 $\\widehat{\\sigma}^2 = RSS/n$。任一模型下的最大化对数似然为\n$$\n\\log L_{\\max} = -\\frac{n}{2}\\left[ \\log(2\\pi \\widehat{\\sigma}^2) + 1 \\right].\n$$\n为避免当 $RSS = 0$ 时出现退化的似然，请实现一个严格为正的下限 $\\epsilon$，并使用 $\\widehat{\\sigma}^2 = \\max\\{RSS/n, \\epsilon\\}$，其中 $\\epsilon = 10^{-12}$。\n- 模型选择准则定义为\n$$\n\\text{AIC} = 2k - 2 \\log L_{\\max}, \\quad \\text{BIC} = k \\log n - 2 \\log L_{\\max},\n$$\n其中 $k$ 是估计的自由参数数量。参数计数如下，包括方差参数：\n  - 对于 $\\mathcal{M}_{\\text{lin}}$：$k_{\\text{lin}} = 4$ 个参数，包括 $m$（$2$ 个实数自由度）、直线方向 $d$（$1$ 个角度自由度，因为 $\\|d\\|_2=1$）和方差 $\\sigma^2$（$1$ 个）。\n  - 对于 $\\mathcal{M}_{\\text{br}}$：$k_{\\text{br}} = 5$ 个参数，包括 $m$（$2$ 个）、两个分支方向 $d_1, d_2$（每个贡献 $1$ 个角度自由度，共 $2$ 个）和方差 $\\sigma^2$（$1$ 个）。离散的分支分配不计为参数。\n\n算法要求：\n- 拟合 $\\mathcal{M}_{\\text{lin}}$：将 $m$ 估计为样本均值 $m = \\frac{1}{n}\\sum_{i=1}^n x_i$。将 $d$ 估计为中心化数据矩阵的第一主成分方向。通过对到拟合直线的垂直距离的平方求和来计算 $RSS_{\\text{lin}}$。\n- 拟合 $\\mathcal{M}_{\\text{br}}$：将连接点固定在相同的样本均值 $m$ 处。对于那些满足 $\\|x_i - m\\|_2 > 0$ 的点 $i$，通过对单位向量 $u_i = \\frac{x_i - m}{\\|x_i - m\\|_2}$ 进行迭代方向聚类过程来估计方向 $d_1, d_2$。\n  - 初始化：使用中心化数据的前两个主方向作为初始单位方向。\n  - 迭代：在以下两个步骤之间交替进行固定次数的少量迭代：将每个 $u_i$ 分配给最大化 $|u_i^\\top d_j|$ 的方向 $d_j$（这反映了线的双向性），以及将每个 $d_j$ 更新为已分配 $u_i$ 的归一化带符号总和，即 $d_j \\leftarrow \\frac{\\sum_{i \\in S_j} \\operatorname{sign}(u_i^\\top d_j) u_i}{\\left\\|\\sum_{i \\in S_j} \\operatorname{sign}(u_i^\\top d_j) u_i\\right\\|_2}$。如果在一次迭代中集合 $S_j$ 为空，则保留前一个 $d_j$。\n  - 通过对各点到两条直线（穿过 $m$，方向为 $d_1$ 和 $d_2$）中较近一条的垂直距离的平方求和来计算 $RSS_{\\text{br}}$。\n- 根据每个测试用例的指定计算 $\\log L_{\\max}$、AIC 或 BIC，并选择准则值较小的模型。如果两者相等（在 $10^{-9}$ 的数值公差范围内），则选择更简单的线性模型 $\\mathcal{M}_{\\text{lin}}$。\n\n角度单位：所有角度必须以弧度为单位解释。\n\n测试套件（不允许随机性；按规定生成确切的点）：\n- 用例 1（线性，准则 BIC）：\n  - 单线数据集：$m = (0,0)$，方向角度 $\\theta = \\pi/6$，伪时间 $t \\in \\{-2,-1,0,1,2\\}$。点为对每个 $t$ 的 $x(t) = m + t(\\cos\\theta, \\sin\\theta)$。\n  - 使用 BIC 进行选择。\n- 用例 2（分支，准则 AIC）：\n  - 双分支数据集：$m = (0,0)$，分支方向角度 $\\theta_1 = \\pi/6$ 和 $\\theta_2 = -\\pi/6$，每个分支上的伪时间 $t \\in \\{-1, 1\\}$。点是 $\\{ m + t(\\cos\\theta_1, \\sin\\theta_1) : t \\in \\{-1,1\\} \\}$ 和 $\\{ m + t(\\cos\\theta_2, \\sin\\theta_2) : t \\in \\{-1,1\\} \\}$ 的并集。\n  - 使用 AIC 进行选择。\n- 用例 3（不平衡弱分支，准则 BIC）：\n  - 双分支数据集：真实连接点 $m_{\\text{true}} = (0,0)$，分支方向角度 $\\theta_1 = 0$ 和 $\\theta_2 = \\pi/12$，分支 1 上的伪时间 $t_1 \\in \\{0,1,2,3\\}$，分支 2 上的伪时间 $t_2 \\in \\{0.5\\}$。点是 $\\{ m_{\\text{true}} + t(\\cos\\theta_1, \\sin\\theta_1) : t \\in \\{0,1,2,3\\} \\}$ 和 $\\{ m_{\\text{true}} + t(\\cos\\theta_2, \\sin\\theta_2) : t \\in \\{0.5\\} \\}$ 的并集。\n  - 使用 BIC 进行选择。\n- 用例 4（微小边界情况，准则 AIC）：\n  - 一条线上的两个点：$x_1 = (0,0)$, $x_2 = (1,0)$。\n  - 使用 AIC 进行选择。\n\n答案规格和最终输出格式：\n- 对于每个用例，如果分支模型 $\\mathcal{M}_{\\text{br}}$ 被指定的信息准则所偏好，则输出整数 $1$；如果线性模型 $\\mathcal{M}_{\\text{lin}}$ 被偏好（包括相等的情况），则输出 $0$。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，“[0,1,0,0]”）。",
            "solution": "该问题陈述在科学上是合理的，它提出了一个基于统计模型选择的明确计算任务，用于区分线性与分支轨迹。该问题是良态的，定义了所有必要的数学概念和算法步骤，包括模型几何、参数计数、似然函数以及参数估计的具体程序。\n\n### 解决方案\n\n解决方案旨在严格遵循问题中定义的算法和统计框架。核心任务是为给定的二维点集拟合一个线性模型和一个分支模型，然后使用指定的信息准则（AIC或BIC）来比较这两个模型。\n\n**1. 模型拟合与残差平方和（RSS）计算**\n\n对于给定的数据集 $X \\in \\mathbb{R}^{n \\times 2}$，两个模型的连接点 $m$ 都被估计为样本均值 $m = \\frac{1}{n} \\sum_{i=1}^n x_i$。令 $B = X - m^\\top$ 为中心化数据矩阵。\n\n**线性模型 ($\\mathcal{M}_{\\text{lin}}$):**\n- **方向估计**：方向向量 $d$ 是中心化数据 $B$ 的第一主成分方向。这通过对 $B$ 进行奇异值分解（SVD）得到，$d$ 对应于最大奇异值所关联的右奇异向量。\n- **RSS计算**：对于每个中心化的点 $b_i = x_i - m$，其到由 $d$ 定义的直线上的投影长度的平方是 $(d^\\top b_i)^2$。该点到直线的正交距离的平方是 $\\|b_i\\|^2 - (d^\\top b_i)^2$。因此，总的残差平方和为：\n  $$\n  RSS_{\\text{lin}} = \\sum_{i=1}^n \\left( \\|b_i\\|^2 - (d^\\top b_i)^2 \\right)\n  $$\n\n**分支模型 ($\\mathcal{M}_{\\text{br}}$):**\n- **方向估计**：方向 $d_1$ 和 $d_2$ 通过一个迭代算法找到。\n    - **初始化**：初始方向 $d_1$ 和 $d_2$ 设为 $B$ 的前两个主成分方向。\n    - **迭代**：该算法对这些方向进行优化。首先，计算所有非零中心化点的单位向量 $u_i = b_i / \\|b_i\\|_2$。然后，在固定的迭代次数内（例如10次）交替执行以下步骤：\n        1. **分配**：每个 $u_i$ 根据其与哪个方向 $d_j$ 的投影绝对值 $|u_i^\\top d_j|$ 更大，被分配到聚类 $S_j$。\n        2. **更新**：每个方向 $d_j$ 被更新为其聚类中所有向量的归一化加权平均值，权重为与旧方向的投影符号。新方向为：\n           $$\n           d_j^{\\text{new}} \\leftarrow \\frac{\\sum_{u_i \\in S_j} \\operatorname{sign}(u_i^\\top d_j^{\\text{old}}) u_i}{\\left\\|\\sum_{u_i \\in S_j} \\operatorname{sign}(u_i^\\top d_j^{\\text{old}}) u_i\\right\\|_2}\n           $$\n- **RSS计算**：迭代完成后，使用最终的方向 $d_1$ 和 $d_2$ 计算 $RSS_{\\text{br}}$。对于每个点，取其到两条直线的正交距离平方中的较小值并求和：\n  $$\n  RSS_{\\text{br}} = \\sum_{i=1}^n \\min\\left( \\|b_i\\|^2 - (d_1^\\top b_i)^2, \\|b_i\\|^2 - (d_2^\\top b_i)^2 \\right)\n  $$\n\n**2. 模型选择**\n\n对于每个模型 $\\mathcal{M} \\in \\{\\mathcal{M}_{\\text{lin}}, \\mathcal{M}_{\\text{br}}\\}$，其最大化对数似然根据以下步骤计算：\n1.  估计噪声方差：$\\widehat{\\sigma}^2 = \\max(RSS/n, \\epsilon)$，其中 $\\epsilon = 10^{-12}$。\n2.  计算对数似然：\n    $$\n    \\log L_{\\max} = -\\frac{n}{2}\\left( \\log(2\\pi \\widehat{\\sigma}^2) + 1 \\right)\n    $$\n然后，使用问题中定义的参数数量 $k$（线性模型 $k_{\\text{lin}}=4$，分支模型 $k_{\\text{br}}=5$）计算相应的信息准则：\n$$\n\\text{AIC} = 2k - 2 \\log L_{\\max}\n$$\n$$\n\\text{BIC} = k \\log n - 2 \\log L_{\\max}\n$$\n最后，比较两个模型的信息准则值。如果分支模型的准则值严格小于线性模型的准则值（考虑数值公差 $10^{-9}$），则选择分支模型（输出1）。否则，选择线性模型（输出0）。这种结构化的方法确保了实现将忠实地执行指定的任务。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the model selection analysis on all test cases.\n    \"\"\"\n    epsilon = 1e-12\n    num_iterations_branching = 10\n    tie_tolerance = 1e-9\n    \n    # --- Helper Functions ---\n    \n    def fit_linear_model(X):\n        \"\"\"Fits the linear model M_lin.\"\"\"\n        n, _ = X.shape\n        if n  2:\n            return np.zeros(2), np.array([1.0, 0.0]), 0.0\n\n        m = np.mean(X, axis=0)\n        B = X - m\n        \n        # SVD on centered data to get principal components\n        # Vh contains the principal directions as rows\n        try:\n            _, _, Vh = np.linalg.svd(B, full_matrices=False)\n            d = Vh[0, :]\n        except np.linalg.LinAlgError:\n            d = np.array([1.0, 0.0]) # Fallback for singular matrix\n            \n        # Calculate RSS using the efficient formula: sum(||b_i||^2 - (d.b_i)^2)\n        squared_norms = np.sum(B**2, axis=1)\n        projections_sq = (B @ d)**2\n        rss = np.sum(squared_norms - projections_sq)\n        \n        return m, d, rss.clip(min=0)\n\n    def fit_branching_model(X):\n        \"\"\"Fits the branching model M_br.\"\"\"\n        n, _ = X.shape\n        if n  2:\n            return np.zeros(2), np.array([1., 0.]), np.array([0., 1.]), 0.0\n\n        m = np.mean(X, axis=0)\n        B = X - m\n        \n        # Initialize directions with the first two PCs\n        try:\n            _, _, Vh = np.linalg.svd(B, full_matrices=False)\n            d1 = Vh[0, :]\n            d2 = Vh[1, :] if Vh.shape[0] > 1 else np.array([-d1[1], d1[0]])\n        except np.linalg.LinAlgError:\n            d1 = np.array([1.0, 0.0])\n            d2 = np.array([0.0, 1.0])\n\n        # Get unit vectors for points not at the mean\n        norms = np.linalg.norm(B, axis=1)\n        valid_indices = norms > epsilon\n        u_vectors = B[valid_indices] / norms[valid_indices, np.newaxis]\n\n        if u_vectors.shape[0] > 0:\n            # Iterative refinement of directions\n            for _ in range(num_iterations_branching):\n                d1_old, d2_old = d1, d2\n                \n                # Assignment step\n                proj1 = np.abs(u_vectors @ d1)\n                proj2 = np.abs(u_vectors @ d2)\n                \n                assign_to_1 = proj1 >= proj2\n                S1_vectors = u_vectors[assign_to_1]\n                S2_vectors = u_vectors[~assign_to_1]\n\n                # Update step for d1\n                if S1_vectors.shape[0] > 0:\n                    signs1 = np.sign(S1_vectors @ d1_old)\n                    sum_vec1 = np.sum(S1_vectors * signs1[:, np.newaxis], axis=0)\n                    norm1 = np.linalg.norm(sum_vec1)\n                    if norm1 > epsilon:\n                        d1 = sum_vec1 / norm1\n\n                # Update step for d2\n                if S2_vectors.shape[0] > 0:\n                    signs2 = np.sign(S2_vectors @ d2_old)\n                    sum_vec2 = np.sum(S2_vectors * signs2[:, np.newaxis], axis=0)\n                    norm2 = np.linalg.norm(sum_vec2)\n                    if norm2 > epsilon:\n                        d2 = sum_vec2 / norm2\n\n        # Calculate RSS for the branching model\n        squared_norms = np.sum(B**2, axis=1)\n        proj_d1_sq = (B @ d1)**2\n        proj_d2_sq = (B @ d2)**2\n        \n        rss_per_point_1 = squared_norms - proj_d1_sq\n        rss_per_point_2 = squared_norms - proj_d2_sq\n        \n        # Negative rss values can occur from float precision errors, clip at 0\n        rss_br = np.sum(np.minimum(rss_per_point_1, rss_per_point_2).clip(min=0))\n\n        return m, d1, d2, rss_br\n\n    def calculate_criterion(rss, k, n, criterion_type):\n        \"\"\"Calculates AIC or BIC.\"\"\"\n        if n == 0:\n            return float('inf')\n        \n        sigma_sq_hat = max(rss / n, epsilon)\n        log_L_max = - (n / 2) * (np.log(2 * np.pi * sigma_sq_hat) + 1)\n        \n        if criterion_type.upper() == 'AIC':\n            return 2 * k - 2 * log_L_max\n        elif criterion_type.upper() == 'BIC':\n            if n = 1: return float('inf') # log(n) undefined or 0\n            return k * np.log(n) - 2 * log_L_max\n        else:\n            raise ValueError(\"Unknown criterion type\")\n\n    # --- Test Cases ---\n    \n    test_cases_defs = [\n        {\n            \"id\": 1,\n            \"criterion\": \"BIC\",\n            \"points_func\": lambda: np.array([t * np.array([np.cos(np.pi/6), np.sin(np.pi/6)]) for t in [-2, -1, 0, 1, 2]])\n        },\n        {\n            \"id\": 2,\n            \"criterion\": \"AIC\",\n            \"points_func\": lambda: np.vstack([\n                np.array([t * np.array([np.cos(np.pi/6), np.sin(np.pi/6)]) for t in [-1, 1]]),\n                np.array([t * np.array([np.cos(-np.pi/6), np.sin(-np.pi/6)]) for t in [-1, 1]])\n            ])\n        },\n        {\n            \"id\": 3,\n            \"criterion\": \"BIC\",\n            \"points_func\": lambda: np.vstack([\n                np.array([t * np.array([np.cos(0), np.sin(0)]) for t in [0, 1, 2, 3]]),\n                np.array([0.5 * np.array([np.cos(np.pi/12), np.sin(np.pi/12)])])\n            ])\n        },\n        {\n            \"id\": 4,\n            \"criterion\": \"AIC\",\n            \"points_func\": lambda: np.array([[0., 0.], [1., 0.]])\n        }\n    ]\n\n    results = []\n    for case_def in test_cases_defs:\n        X = case_def[\"points_func\"]()\n        criterion_type = case_def[\"criterion\"]\n        n = X.shape[0]\n\n        # Linear Model\n        k_lin = 4\n        _, _, rss_lin = fit_linear_model(X)\n        crit_lin = calculate_criterion(rss_lin, k_lin, n, criterion_type)\n\n        # Branching Model\n        k_br = 5\n        _, _, _, rss_br = fit_branching_model(X)\n        crit_br = calculate_criterion(rss_br, k_br, n, criterion_type)\n\n        # Decision\n        if crit_br  crit_lin - tie_tolerance:\n            results.append(1)\n        else:\n            results.append(0)\n            \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}