{
    "hands_on_practices": [
        {
            "introduction": "本练习将指导你实现一个核心的统计分析流程，该流程类似于著名的 DESeq2 方法，用于识别在特定条件下至关重要的基因 。通过从头构建此流程，你将深入理解对高通量测序实验数据进行标准化、离散度估计和统计建模的原理，这些都是分析工作的基本技能。",
            "id": "2371981",
            "problem": "您的任务是，从基本原理出发，实现一个完整的差异分析流程，用于比较两个混合型“成簇规律间隔短回文重复序列”（CRISPR）扰动筛选实验。此流程需仿照序列计数数据差异表达分析（DESeq2）的精神。目标是识别出“条件特异性必需基因”，此处定义为在经过适当的归一化和统计建模后，其向导 RNA 丰度在一个条件下显著低于另一条件的基因。\n\n请从以下基础理论和经过充分检验的事实出发：\n- 来自混合型筛选的计数数据为非负整数，并且相对于泊松模型表现出过度离散。一个广泛使用的模型是负二项（NB）分布，其方差函数为 $V(\\mu) = \\mu + \\alpha \\mu^{2}$，其中 $\\mu$ 是均值，$\\alpha \\ge 0$ 是离散度。\n- 带有对数连接函数的广义线性模型（GLMs）是建模跨条件计数的标准方法。对于样本 $j$，其尺度因子为 $s_{j}$，设计矩阵 $X$ 包含一个截距和一个二元条件指示变量 $x_{j} \\in \\{0,1\\}$，则对于基因 $g$ 的模型为 $\\log \\mu_{gj} = \\log s_{j} + \\beta_{g0} + \\beta_{g1} x_{j}$。\n- 比率中位数法提供了稳健的文库大小归一化。对于每个样本 $j$，尺度因子 $s_{j}$ 是所有基因的 $k_{gj}/G_{g}$ 比率的中位数，其中 $k_{gj}$ 是原始计数，$G_{g}$ 是 $k_{g\\cdot}$ 在所有样本间的几何平均数，该计算仅限于在所有样本中计数均为严格正值的基因。\n- 使用来自 Fisher 信息的方差并通过渐近正态近似的 Wald 检验，提供了一种检验系数是否等于零的方法。\n- Benjamini–Hochberg (BH) 程序可以控制假发现率（FDR）。\n\n您必须实现以下步骤：\n1) 通过比率中位数法进行尺度因子归一化：\n   - 对于每个基因 $g$，仅当对所有 $j \\in \\{1,\\dots,m\\}$ 都有 $k_{gj} > 0$ 时，计算几何平均数 $G_{g} = \\exp\\left( \\frac{1}{m} \\sum_{j=1}^{m} \\log k_{gj} \\right)$；否则在此步骤中排除基因 $g$。\n   - 对于每个样本 $j$，计算所有具有有效 $G_{g}$ 的基因 $g$ 的比率 $r_{gj} = k_{gj} / G_{g}$，并将 $s_{j}$ 设为 $\\{ r_{gj} \\}$ 的中位数。\n   - 中心化尺度因子，使得 $\\exp\\left( \\frac{1}{m} \\sum_{j=1}^{m} \\log s_{j} \\right) = 1$。\n2) 通过矩量法估计共同离散度：\n   - 对于每个基因 $g$，计算归一化计数 $y_{gj} = k_{gj} / s_{j}$ 及其在所有 $m$ 个样本中的均值 $\\bar{y}_{g}$ 和样本方差 $S^{2}_{g}$。\n   - 对于 $\\bar{y}_{g} > 0$ 的基因，定义单基因离散度估计 $\\hat{\\alpha}_{g} = \\max\\left(0,\\; \\frac{S^{2}_{g} - \\bar{y}_{g}}{\\bar{y}_{g}^{2}} \\right)$。\n   - 将所有 $\\bar{y}_{g} > 0$ 的基因的 $\\{ \\hat{\\alpha}_{g} \\}$ 的中位数定义为单一的共同离散度 $\\hat{\\alpha}$。\n3) 对于每个基因 $g$，使用 Fisher 评分法（迭代重加权最小二乘法）拟合一个负二项广义线性模型，该模型使用对数连接函数、偏移量 $\\log s_{j}$、共同离散度 $\\hat{\\alpha}$ 以及包含截距和条件指示变量 $x_{j} \\in \\{0,1\\}$ 的设计矩阵：\n   - 初始化 $\\beta_{g0}$ 和 $\\beta_{g1}$（例如，$\\beta_{g1}=0$，$\\beta_{g0}$ 为平均归一化计数的对数值）。\n   - 在每次迭代中，计算线性预测变量 $\\eta_{gj} = \\log s_{j} + \\beta_{g0} + \\beta_{g1} x_{j}$、均值 $\\mu_{gj} = \\exp(\\eta_{gj})$、权重 $w_{gj} = \\frac{\\mu_{gj}}{1 + \\hat{\\alpha}\\mu_{gj}}$ 以及工作响应变量 $z_{gj} = \\eta_{gj} + \\frac{k_{gj} - \\mu_{gj}}{\\mu_{gj}}$。\n   - 更新 $\\beta_{g} = (\\mathbf{X}^{\\top} \\mathbf{W} \\mathbf{X})^{-1} \\mathbf{X}^{\\top} \\mathbf{W} \\mathbf{z}$ 直至收敛或达到固定的迭代次数上限，其中 $\\mathbf{W}$ 是对角线上为 $w_{gj}$ 的对角矩阵。\n4) 对于基因 $g$，在收敛后，从 $(\\mathbf{X}^{\\top} \\mathbf{W} \\mathbf{X})$ 的逆矩阵中提取估计的系数 $\\hat{\\beta}_{g1}$ 及其标准误 $\\operatorname{se}(\\hat{\\beta}_{g1})$。构建 Wald 统计量 $Z_{g} = \\hat{\\beta}_{g1} / \\operatorname{se}(\\hat{\\beta}_{g1})$，并使用标准正态分布计算双侧 $p$ 值。\n5) 对所有基因应用 Benjamini–Hochberg 程序以获得校正后的 $q$ 值。\n6) 如果一个基因同时满足以下两个标准，则将其定义为“相对于条件0，在条件1中是条件特异性必需的”：\n   - 校正后的 $q$ 值小于 $\\alpha_{\\mathrm{FDR}}$。\n   - 估计的 log$_{2}$ 倍数变化 $\\widehat{\\mathrm{LFC}}_{g} = \\hat{\\beta}_{g1} / \\log 2$ 小于或等于 $- \\tau$，其中 $\\tau$ 是用户指定的非负阈值。\n\n在所有样本中计数均为零的基因，或 $\\bar{y}_{g} = 0$ 的基因，应从测试中排除。\n\n您的程序必须实现上述流程，并在以下测试套件上运行。对于每个测试用例，输入包括一个原始计数矩阵（基因为行，样本为列），以及一个长度等于样本数的二元条件分配向量。请使用 $\\alpha_{\\mathrm{FDR}} = 0.1$ 和 $\\tau = 1.0$，并报告被判定为相对于条件0在条件1中是条件特异性必需的基因的从零开始的索引。\n\n测试套件：\n- 案例1（平衡的重复样本，明显的差异性耗竭）：\n  - 计数矩阵 $K$，包含6个基因和6个样本（前3个样本为条件0，后3个样本为条件1）：\n    - 基因0: $[100, 90, 110, 120, 80, 100]$\n    - 基因1: $[50, 45, 55, 60, 40, 50]$\n    - 基因2: $[30, 27, 33, 9, 6, 8]$\n    - 基因3: $[20, 18, 22, 24, 16, 20]$\n    - 基因4: $[10, 9, 11, 3, 2, 3]$\n    - 基因5: $[60, 54, 66, 72, 48, 60]$\n  - 条件向量 $x = [0, 0, 0, 1, 1, 1]$。\n- 案例2（严重的文库大小不平衡，单个差异基因）：\n  - 计数矩阵 $K$，包含5个基因和4个样本（前2个样本为条件0，后2个样本为条件1）：\n    - 基因0: $[160, 40, 120, 56]$\n    - 基因1: $[80, 20, 12, 6]$\n    - 基因2: $[40, 10, 30, 14]$\n    - 基因3: $[30, 7, 23, 10]$\n    - 基因4: $[10, 3, 8, 4]$\n  - 条件向量 $x = [0, 0, 1, 1]$。\n- 案例3（带有零的稀疏计数，一个强差异基因）：\n  - 计数矩阵 $K$，包含6个基因和4个样本（前2个样本为条件0，后2个样本为条件1）：\n    - 基因0: $[2, 1, 2, 1]$\n    - 基因1: $[0, 0, 0, 0]$\n    - 基因2: $[3, 2, 3, 2]$\n    - 基因3: $[1, 0, 1, 0]$\n    - 基因4: $[4, 4, 4, 4]$\n    - 基因5: $[6, 5, 1, 1]$\n  - 条件向量 $x = [0, 0, 1, 1]$。\n\n要求与输出：\n- 精确按照描述实现完整的流程。\n- 对于每个案例，返回满足显著性和效应大小标准的、从零开始的基因索引的排序列表。\n- 您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表（例如，`[result_1,result_2,result_3]`），其中每个 `result_i` 是一个整数列表，表示案例 `i` 中被判定的基因的索引。对于提供的测试套件，程序应输出一行，如 `[[i_1,i_2], [j_1], [k_1]]`，包含发现的索引。",
            "solution": "该问题是在计算生物学领域中一个定义明确且科学上合理的任务。它要求实现一个标准的统计流程，用于从计数数据中识别差异丰度特征，特别是在 CRISPR 筛选的背景下。该方法论是像 DESeq2 这类成熟算法的简化变体，它建立在广义线性模型和成熟统计实践的坚实基础上。该问题是有效的，可以通过遵循概述的步骤来构建一个严谨的解决方案。\n\n分析从基本原理开始，如下所示。\n\n**1. 统计基础：负二项模型**\n来自混合型 CRISPR 筛选的原始数据是计数 $k_{gj}$，代表样本 $j$ 中向导 RNA $g$ 的测序读取数。这类数据是非负整数，并且总是表现出过度离散，即方差大于均值。因此，方差等于均值的泊松分布是不够的。我们采用负二项（NB）分布，它增加了一个离散度参数 $\\alpha$ 来对这种额外的方差进行建模。方差-均值关系由下式给出：\n$$V(\\mu_{g}) = \\mu_{g} + \\alpha \\mu_{g}^{2}$$\n其中 $\\mu_{g}$ 是向导 $g$ 的平均丰度，$\\alpha \\ge 0$ 是离散度参数。当 $\\alpha=0$ 时，NB 分布简化为泊松分布。\n\n**2. 文库大小的归一化**\n不同样本的测序深度不同，导致总读取数（文库大小）存在系统性差异。为了使计数在样本间具有可比性，我们必须进行归一化。问题指定了比率中位数法，该方法对于大部分差异丰度基因具有稳健性。\n\n首先，对于在所有 $m$ 个样本中计数 $k_{gj} > 0$ 的基因子集，我们通过计算每个基因 $g$ 的计数几何平均数来构建一个伪参考样本：\n$$G_{g} = \\left( \\prod_{j=1}^{m} k_{gj} \\right)^{1/m} = \\exp\\left( \\frac{1}{m} \\sum_{j=1}^{m} \\log k_{gj} \\right)$$\n其次，对于每个样本 $j$，我们计算其计数 $k_{gj}$ 与参考子集中所有基因的伪参考值 $G_{g}$ 的比率。样本 $j$ 的尺度因子 $s_{j}$ 是这些比率的中位数：\n$$s_{j} = \\underset{g}{\\text{median}} \\left\\{ \\frac{k_{gj}}{G_{g}} \\right\\}$$\n最后，将这些尺度因子中心化，使其几何平均数为1，以确保归一化不会改变计数数据的整体尺度。这可以通过将每个 $s_j$ 除以所有尺度因子的几何平均数来实现。\n\n**3. 共同离散度的估计**\n离散度参数 $\\alpha$ 必须从数据中估计。虽然可以进行单基因离散度估计，但在重复样本数较少时它是不稳定的。一个常见的做法是估计一个在所有基因间共享的、单一的全局离散度值 $\\hat{\\alpha}$。这是一种汇集信息的稳健方法。这里使用矩量法。\n\n对于每个基因 $g$，归一化计数计算为 $y_{gj} = k_{gj} / s_{j}$。我们计算这些归一化计数在所有样本中的均值 $\\bar{y}_{g}$ 和样本方差 $S^{2}_{g}$。根据NB方差函数，我们有 $S_g^2 \\approx \\bar{y}_g + \\alpha_g \\bar{y}_g^2$。重新整理得到单基因离散度估计：\n$$\\hat{\\alpha}_{g} = \\frac{S^{2}_{g} - \\bar{y}_{g}}{\\bar{y}_{g}^{2}}$$\n为确保非负性，我们取 $\\max(0, \\hat{\\alpha}_{g})$。最终的共同离散度 $\\hat{\\alpha}$ 是这些单基因估计值的中位数，仅在 $\\bar{y}_{g} > 0$ 的基因上计算。中位数提供了对具有极端方差的离群基因的稳健性。\n\n**4. 广义线性模型 (GLM) 拟合**\n为了建模实验条件对基因丰度的影响，我们为每个基因的计数拟合一个负二项 GLM。该模型通过一个对数连接函数将期望计数 $\\mu_{gj}$ 与实验变量关联起来：\n$$\\log(\\mu_{gj}) = \\log(s_{j}) + \\beta_{g0} + \\beta_{g1} x_{j}$$\n此处，$\\log(s_j)$ 是一个偏移项，用以解释文库大小归一化。$\\mathbf{X}$ 是设计矩阵，其中一列为1代表截距，另一列为二元条件指示变量 $x_j \\in \\{0, 1\\}$。系数 $\\beta_{g0}$ 和 $\\beta_{g1}$ 分别代表对数基线丰度和条件间的对数倍数变化。\n\n我们使用迭代重加权最小二乘法（IRLS）来估计系数 $\\beta_g = [\\beta_{g0}, \\beta_{g1}]^T$，对于此 GLM，这等同于 Fisher 评分法。迭代更新公式为：\n$$\\beta_g^{(t+1)} = (\\mathbf{X}^{\\top} \\mathbf{W}^{(t)} \\mathbf{X})^{-1} \\mathbf{X}^{\\top} \\mathbf{W}^{(t)} \\mathbf{z}^{(t)}$$\n其中，在第 $t$ 次迭代时：\n- $\\eta_{gj} = \\log(s_j) + \\beta_{g0}^{(t)} + \\beta_{g1}^{(t)} x_{j}$ 是线性预测变量。\n- $\\mu_{gj} = \\exp(\\eta_{gj})$ 是估计的均值。\n- $w_{gj} = \\frac{\\mu_{gj}}{1 + \\hat{\\alpha}\\mu_{gj}}$ 是权重矩阵 $\\mathbf{W}$ 的对角元素。\n- $z_{gj} = \\eta_{gj} + \\frac{k_{gj} - \\mu_{gj}}{\\mu_{gj}}$ 是工作响应变量。\n迭代过程持续进行，直到 $\\beta_g$ 的变化小于一个容忍阈值或达到最大迭代次数。\n\n**5. 假设检验与多重检验校正**\n我们的主要兴趣是条件是否具有显著影响，即 $\\beta_{g1} \\neq 0$ 是否成立。为此我们使用 Wald 检验。检验统计量为：\n$$Z_{g} = \\frac{\\hat{\\beta}_{g1}}{\\operatorname{se}(\\hat{\\beta}_{g1})}$$\n其中 $\\hat{\\beta}_{g1}$ 是从收敛的 IRLS 得到的系数估计值，其标准误 $\\operatorname{se}(\\hat{\\beta}_{g1})$ 来自估计量的渐近协方差矩阵，由 $\\widehat{\\text{Cov}}(\\hat{\\beta}_g) = (\\mathbf{X}^{\\top} \\mathbf{W}_{\\text{final}} \\mathbf{X})^{-1}$ 给出。具体来说，$\\operatorname{se}(\\hat{\\beta}_{g1})$ 是此矩阵中对应于 $\\beta_{g1}$ 的对角元素的平方根。在零假设 $H_0: \\beta_{g1} = 0$下，统计量 $Z_g$ 服从标准正态分布。这使得可以计算双侧 $p$ 值。\n\n由于我们同时对数千个基因进行此检验，我们面临多重检验问题。为了控制假发现的比例，我们使用 Benjamini-Hochberg (BH) 程序来调整 $p$ 值，从而得到 $q$ 值（FDR 校正后的 $p$ 值）。\n\n**6. 条件特异性必需基因的鉴定**\n一个基因被鉴定为“相对于条件0，在条件1中是条件特异性必需的”，如果它满足两个标准：\n1.  **统计显著性**：校正后的 $q$ 值必须低于指定阈值，$q_g \\le \\alpha_{\\mathrm{FDR}}$（例如 $0.1$）。\n2.  **效应大小**：该基因在条件1中必须是耗竭的。我们使用以2为底的对数倍数变化来量化这一点，$\\widehat{\\mathrm{LFC}}_{g} = \\hat{\\beta}_{g1} / \\log 2$。标准是 $\\widehat{\\mathrm{LFC}}_{g} \\le -\\tau$，其中 $\\tau$ 是一个非负的幅度阈值（例如 $1.0$，对应于丰度至少减半）。\n\n在所有样本中计数均为零或无法可靠拟合模型的基因将从分析中排除。最终输出是满足这两个标准的基因索引的排序列表。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the differential analysis pipeline on all test cases.\n    \"\"\"\n\n    class DifferentialAnalysis:\n        \"\"\"\n        Implements the complete differential analysis pipeline for CRISPR screen count data.\n        \"\"\"\n        \n        def __init__(self, counts, conditions, alpha_fdr, tau):\n            self.raw_counts = np.asarray(counts, dtype=float)\n            self.conditions = np.asarray(conditions, dtype=float)\n            self.alpha_fdr = alpha_fdr\n            self.tau_lfc = tau\n            self.num_genes, self.num_samples = self.raw_counts.shape\n            self.log2 = np.log(2)\n            self.irls_iterations = 25\n            self.irls_tol = 1e-6\n\n        def run(self):\n            \"\"\"\n            Executes the full analysis pipeline.\n            \"\"\"\n            # Step 0: Filter genes that are untestable from the start\n            genes_with_counts = self.raw_counts.sum(axis=1) > 0\n            if not np.any(genes_with_counts):\n                return []\n\n            # Step 1: Size-factor normalization\n            size_factors = self._calculate_size_factors()\n            if size_factors is None: # Happens if no genes for geo mean calc\n                return []\n            \n            normalized_counts = self.raw_counts / size_factors\n            mean_normalized_counts = np.mean(normalized_counts, axis=1)\n            \n            # Further filter genes where mean normalized count is zero\n            testable_genes_mask = (genes_with_counts)  (mean_normalized_counts  0)\n            testable_gene_indices = np.where(testable_genes_mask)[0]\n            if len(testable_gene_indices) == 0:\n                return []\n\n            # Step 2: Common dispersion estimation\n            common_dispersion = self._estimate_common_dispersion(size_factors, testable_genes_mask)\n\n            # Step 3  4: Per-gene GLM fit and Wald test\n            design_matrix = np.vstack([np.ones(self.num_samples), self.conditions]).T\n            \n            p_values = []\n            betas = []\n            final_testable_indices = []\n\n            for i in testable_gene_indices:\n                counts_g = self.raw_counts[i, :]\n                try:\n                    beta, cov_matrix = self._fit_nb_glm(counts_g, design_matrix, size_factors, common_dispersion)\n                    \n                    beta1 = beta[1]\n                    se_beta1 = np.sqrt(cov_matrix[1, 1])\n                    \n                    if np.isinf(se_beta1) or se_beta1  1e-8:\n                        p_val = 1.0\n                    else:\n                        wald_stat = beta1 / se_beta1\n                        p_val = 2 * (1 - norm.cdf(np.abs(wald_stat)))\n                    \n                    p_values.append(p_val)\n                    betas.append(beta1)\n                    final_testable_indices.append(i)\n                except (np.linalg.LinAlgError, ValueError):\n                    continue\n\n            # Step 5: Benjamini-Hochberg FDR correction\n            if not p_values:\n                return []\n            q_values = self._benjamini_hochberg(p_values)\n\n            # Step 6: Identify condition-specific essential genes\n            significant_genes = []\n            for gene_idx, beta1, q_val in zip(final_testable_indices, betas, q_values):\n                lfc = beta1 / self.log2\n                if q_val  self.alpha_fdr and lfc = -self.tau_lfc:\n                    significant_genes.append(gene_idx)\n            \n            return sorted(significant_genes)\n\n        def _calculate_size_factors(self):\n            genes_for_geo_mean_mask = np.all(self.raw_counts  0, axis=1)\n            \n            if not np.any(genes_for_geo_mean_mask):\n                return np.ones(self.num_samples) # Fallback if no gene is viable\n\n            counts_subset = self.raw_counts[genes_for_geo_mean_mask, :]\n            geo_means = np.exp(np.mean(np.log(counts_subset), axis=1))\n            \n            ratios = counts_subset / geo_means[:, np.newaxis]\n            size_factors_uncentered = np.median(ratios, axis=0)\n            \n            if np.any(size_factors_uncentered = 0): # Avoid log(0) or log(-)\n                return size_factors_uncentered / np.mean(size_factors_uncentered)\n\n            geo_mean_sf = np.exp(np.mean(np.log(size_factors_uncentered)))\n            size_factors = size_factors_uncentered / geo_mean_sf\n            return size_factors\n\n        def _estimate_common_dispersion(self, size_factors, valid_genes_mask):\n            counts_subset = self.raw_counts[valid_genes_mask, :]\n            if counts_subset.shape[0] == 0:\n                return 0.0\n\n            normalized_counts = counts_subset / size_factors\n            mean_y = np.mean(normalized_counts, axis=1)\n            var_y = np.var(normalized_counts, axis=1, ddof=1)\n            \n            mean_y_sq = mean_y**2\n            # Add a small epsilon to avoid division by zero\n            mean_y_sq[mean_y_sq == 0] = 1e-8\n\n            dispersions_g = (var_y - mean_y) / mean_y_sq\n            dispersions_g[dispersions_g  0] = 0\n            \n            return np.median(dispersions_g)\n\n        def _fit_nb_glm(self, counts_g, X, s, alpha):\n            mean_norm_count = np.mean(counts_g / s)\n            if mean_norm_count = 0:\n                raise ValueError(\"Mean normalized count is zero or negative.\")\n            \n            beta = np.array([np.log(mean_norm_count), 0.0])\n\n            for _ in range(self.irls_iterations):\n                beta_old = beta.copy()\n                \n                eta = X @ beta + np.log(s)\n                mu = np.exp(eta)\n                \n                weights = mu / (1.0 + alpha * mu)\n                if np.sum(weights)  1e-8:\n                    raise np.linalg.LinAlgError(\"All weights are near zero.\")\n                \n                W = np.diag(weights)\n                z = eta + (counts_g - mu) / mu\n                \n                XT_W_X = X.T @ W @ X\n                XT_W_X_inv = np.linalg.inv(XT_W_X)\n                beta = XT_W_X_inv @ X.T @ W @ z\n                \n                if np.sum(np.abs(beta - beta_old)) / (np.sum(np.abs(beta_old)) + 1e-8)  self.irls_tol:\n                    break\n            \n            # Recalculate final covariance matrix with converged beta\n            eta = X @ beta + np.log(s)\n            mu = np.exp(eta)\n            weights = mu / (1.0 + alpha * mu)\n            W = np.diag(weights)\n            XT_W_X = X.T @ W @ X\n            cov_matrix = np.linalg.inv(XT_W_X)\n            \n            return beta, cov_matrix\n\n        def _benjamini_hochberg(self, p_values):\n            p_values = np.asarray(p_values)\n            num_tests = len(p_values)\n            \n            sorted_indices = np.argsort(p_values)\n            sorted_p_values = p_values[sorted_indices]\n            \n            ranks = np.arange(1, num_tests + 1)\n            q_values_sorted = sorted_p_values * num_tests / ranks\n            \n            q_values_sorted = np.minimum.accumulate(q_values_sorted[::-1])[::-1]\n            \n            q_values = np.empty_like(p_values)\n            q_values[sorted_indices] = q_values_sorted\n            return q_values\n\n    # Test suite from the problem statement\n    test_cases = [\n        # Case 1\n        (\n            [[100, 90, 110, 120, 80, 100], [50, 45, 55, 60, 40, 50], [30, 27, 33, 9, 6, 8],\n             [20, 18, 22, 24, 16, 20], [10, 9, 11, 3, 2, 3], [60, 54, 66, 72, 48, 60]],\n            [0, 0, 0, 1, 1, 1]\n        ),\n        # Case 2\n        (\n            [[160, 40, 120, 56], [80, 20, 12, 6], [40, 10, 30, 14],\n             [30, 7, 23, 10], [10, 3, 8, 4]],\n            [0, 0, 1, 1]\n        ),\n        # Case 3\n        (\n            [[2, 1, 2, 1], [0, 0, 0, 0], [3, 2, 3, 2], [1, 0, 1, 0],\n             [4, 4, 4, 4], [6, 5, 1, 1]],\n            [0, 0, 1, 1]\n        )\n    ]\n    \n    alpha_fdr = 0.1\n    tau = 1.0\n    all_results = []\n\n    for counts, conditions in test_cases:\n        analyzer = DifferentialAnalysis(counts, conditions, alpha_fdr, tau)\n        result = analyzer.run()\n        all_results.append(result)\n\n    # Format the final output exactly as required, handling spaces in list string representation.\n    # The default str() includes spaces, which is consistent with the problem's example format: [[i_1, i_2], [j_1], [k_1]]\n    output_str = ','.join(map(str, all_results))\n    print(f\"[{output_str}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "理想的CRISPR实验假设向导RNA只影响其预定靶点，但脱靶效应是一个现实问题。本练习介绍了一种计算方法，通过在产生意外相似表型的向导RNA中寻找共同的序列基序（motif），并应用基本的富集统计检验，来识别潜在的脱靶效应 。",
            "id": "2372025",
            "problem": "您将获得一个玩具数据集，该数据集代表一项基于成簇规律间隔短回文重复序列 (CRISPR) 的扰动筛选。该数据集由引导序列以及与每个引导序列相关的实值表型组成。目标是定义并实现一个决策程序，以检测表现出意外相似表型的引导序列之间是否存在共享的序列基序。该程序必须纯粹用数学术语定义如下。\n\n设有 $N$ 个引导序列，索引为 $i \\in \\{1,\\dots,N\\}$。每个引导序列具有：\n- 一个核苷酸序列 $s_i$，其字母表为 $\\{ \\text{A}, \\text{C}, \\text{G}, \\text{T} \\}$。\n- 一个实值表型 $y_i \\in \\mathbb{R}$。\n\n给定一个相似性阈值 $\\tau  0$ 和一个邻居度阈值 $t \\in \\mathbb{Z}_{\\ge 0}$，定义意外相似引导序列的集合\n$$\nS \\;=\\; \\left\\{ i \\in \\{1,\\dots,N\\} \\;:\\; \\left|\\left\\{ j \\in \\{1,\\dots,N\\}\\setminus\\{i\\} \\;:\\; |y_i - y_j| \\le \\tau \\right\\}\\right| \\;\\ge\\; t \\right\\}。\n$$\n令 $n_S = |S|$。对于一个基序长度 $k \\in \\mathbb{Z}_{\\ge 1}$，一个 $k$-mer 基序 $m$ 是 $\\{\\text{A},\\text{C},\\text{G},\\text{T}\\}$ 字母表上任意长度为 $k$ 的字符串。如果 $m$ 作为连续子串出现在 $s_i$ 中（出现位置可以重叠），则称引导序列 $i$ 包含基序 $m$。对于一个基序 $m$，定义指示符\n$$\nI_i(m) \\;=\\; \\begin{cases}\n1  \\text{如果 $m$ 是 $s_i$ 的子串，}\\\\\n0  \\text{否则。}\n\\end{cases}\n$$\n定义\n$$\nK(m) \\;=\\; \\sum_{i=1}^{N} I_i(m), \\qquad x(m) \\;=\\; \\sum_{i \\in S} I_i(m)。\n$$\n将 $x(m)$ 理解为集合 $S$ 中包含 $m$ 的引导序列数量，将 $K(m)$ 理解为所有引导序列中包含 $m$ 的总数量。考虑一个零模型，其中集合 $S$ 中的 $n_S$ 个引导序列是从 $N$ 个引导序列中均匀无放回抽取的。在此零模型下，$X \\sim \\text{Hypergeometric}(N, K(m), n_S)$ 是一个大小为 $n_S$ 的随机子集中包含该基序的引导序列数量。定义单边富集 $p$-值为\n$$\np(m) \\;=\\; \\mathbb{P}\\left[ X \\ge x(m) \\right] \\;=\\; \\sum_{r = x(m)}^{\\min\\{K(m),\\, n_S\\}} \\frac{\\binom{K(m)}{r} \\binom{N - K(m)}{n_S - r}}{\\binom{N}{n_S}}。\n$$\n令 $M$ 为一个非空有限的允许基序长度集合。令 $\\mathcal{C}$ 为候选基序集合，定义为\n$$\n\\mathcal{C} \\;=\\; \\bigcup_{k \\in M} \\left\\{ m \\in \\{\\text{A},\\text{C},\\text{G},\\text{T}\\}^k \\;:\\; K(m) \\ge 1 \\right\\}。\n$$\n选择一个唯一的“最佳”基序\n$$\nm^\\star \\;\\in\\; \\operatorname*{arg\\,min}_{m \\in \\mathcal{C}} \\; p(m),\n$$\n并遵循以下确定性平局决胜规则：如果多个基序达到相同的最小 $p(m)$ 值（在标准实数比较的精度内），则根据排序 $\\text{A}  \\text{C}  \\text{G}  \\text{T}$ 和标准字符串字典序比较，选择字典序最小的基序。\n\n使用数字映射 $\\text{A}\\mapsto 0$, $\\text{C}\\mapsto 1$, $\\text{G}\\mapsto 2$, $\\text{T}\\mapsto 3$，将任意基序 $m = m_1 m_2 \\dots m_k$ 映射到一个4进制整数排名，如下所示：\n$$\n\\mathrm{rank}(m) \\;=\\; \\sum_{\\ell=1}^{k} d(m_\\ell)\\, 4^{k-\\ell},\n$$\n其中 $d(\\text{A})=0$, $d(\\text{C})=1$, $d(\\text{G})=2$, $d(\\text{T})=3$。\n\n给定一个显著性水平 $\\alpha \\in (0,1)$，为每个测试用例报告一个三元组：\n$$\n\\left[ \\;\\mathrm{rank}(m^\\star),\\; \\text{round}\\!\\left(p(m^\\star),\\, 6\\right),\\; \\mathbf{1}\\{ p(m^\\star)  \\alpha \\} \\; \\right],\n$$\n其中 $\\text{round}(\\cdot,6)$ 表示四舍五入到6位小数，$\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n\n您的程序必须生成单行输出，其中包含所有测试用例的结果。结果应为一个逗号分隔的列表，并用方括号括起来，每个测试用例的结果表示为上述的三元素列表。\n\n测试套件规范。请使用以下三个测试用例，每个测试用例由元组 $\\left( \\{s_i\\}_{i=1}^{N}, \\{y_i\\}_{i=1}^{N}, \\tau, t, M, \\alpha \\right)$ 定义：\n\n- 测试用例 A (正常路径):\n  - $N = 8$。\n  - 序列 $\\{s_i\\}$:\n    - $s_1 = \\text{ACGTAAACGT}$,\n    - $s_2 = \\text{TTTTCGTAAG}$,\n    - $s_3 = \\text{GGGGCGTCCC}$,\n    - $s_4 = \\text{AACGTTTTTT}$,\n    - $s_5 = \\text{AAAATTTTGG}$,\n    - $s_6 = \\text{CCCCCAAAAA}$,\n    - $s_7 = \\text{GACGTGAAAA}$,\n    - $s_8 = \\text{TAAAAAACGT}$。\n  - 表型 $\\{y_i\\}$ (无物理单位): $[\\,1.02,\\;0.98,\\;1.05,\\;1.00,\\;2.00,\\;2.10,\\;0.97,\\;1.01\\,]$。\n  - 阈值: $\\tau = 0.08$, $t = 3$。\n  - 允许的基序长度: $M = \\{3,4\\}$。\n  - 显著性水平: $\\alpha = 0.05$。\n\n- 测试用例 B (平局决胜):\n  - $N = 4$。\n  - 序列 $\\{s_i\\}$:\n    - $s_1 = \\text{AAACCCGGGT}$,\n    - $s_2 = \\text{AAACCCGGGA}$,\n    - $s_3 = \\text{TTTGGGCCCA}$,\n    - $s_4 = \\text{TTTGGGCCCT}$。\n  - 表型 $\\{y_i\\}$ (无物理单位): $[\\,0.50,\\;0.49,\\;1.50,\\;1.60\\,]$。\n  - 阈值: $\\tau = 0.02$, $t = 1$。\n  - 允许的基序长度: $M = \\{3\\}$。\n  - 显著性水平: $\\alpha = 0.05$。\n\n- 测试用例 C (S为空的边界情况):\n  - $N = 4$。\n  - 序列 $\\{s_i\\}$:\n    - $s_1 = \\text{AGTCAGTCAG}$,\n    - $s_2 = \\text{CAGTCAGTCA}$,\n    - $s_3 = \\text{GTCAGTCAGT}$,\n    - $s_4 = \\text{TCAGTCAGTC}$。\n  - 表型 $\\{y_i\\}$ (无物理单位): $[\\,0.00,\\;1.00,\\;2.00,\\;3.00\\,]$。\n  - 阈值: $\\tau = 0.05$, $t = 1$。\n  - 允许的基序长度: $M = \\{4\\}$。\n  - 显著性水平: $\\alpha = 0.05$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每一项是对应测试用例的列表 $[\\,\\mathrm{rank}(m^\\star),\\; \\text{round}(p(m^\\star),6),\\; \\mathbf{1}\\{ p(m^\\star)  \\alpha \\}\\,]$，顺序为A、B、C。",
            "solution": "该问题要求实现一个确定性程序，用于从CRISPR扰动筛选的引导RNA特定子集中，识别出在统计上富集的序列基序。该问题在计算上定义明确，科学上基于生物信息学和统计学原理，并且所有术语和程序都经过了精确的数学规定。我的验证证实了该问题是有效的，并且每个测试用例都有唯一的解。现在我将详细说明解决过程。\n\n对于每个测试用例，整个过程可以分解为五个主要步骤：\n1.  识别“意外相似引导序列”的集合，记为 $S$。\n2.  基于提供的序列和允许的基序长度 $M$，生成所有候选基序的集合 $\\mathcal{C}$。\n3.  对于每个候选基序 $m \\in \\mathcal{C}$，使用超几何分布计算其富集 $p$-值 $p(m)$。\n4.  通过找到最小化 $p(m)$ 的基序来确定“最佳”基序 $m^\\star$，并应用指定的字典序平局决胜规则。\n5.  计算最终输出三元组：$[\\mathrm{rank}(m^\\star), \\mathrm{round}(p(m^\\star), 6), \\mathbf{1}\\{p(m^\\star)  \\alpha\\}]$。\n\n让我们以所需的数学严谨性剖析每个步骤。\n\n步骤1：确定集合 $S$\n集合 $S$ 由所有至少有 $t$ 个“邻居”的引导序列 $i$ 组成，其中邻居 $j$ 是指其表型 $y_j$ 与 $y_i$ “接近”的另一个引导序列。形式上，对于每个引导序列 $i \\in \\{1, \\dots, N\\}$，我们计算其邻域的大小，$c_i = |\\left\\{ j \\in \\{1,\\dots,N\\}\\setminus\\{i\\} \\;:\\; |y_i - y_j| \\le \\tau \\right\\}\\right|$。然后将集合 $S$ 定义为 $S = \\{i : c_i \\ge t\\}$。该集合的大小为 $n_S = |S|$。这是对所提供定义的直接实现。\n\n步骤2：生成候选基序集合 $\\mathcal{C}$\n候选基序集合 $\\mathcal{C}$ 是所有出现在至少一个引导序列 $\\{s_i\\}_{i=1}^N$ 中、且长度在集合 $M$ 中指定的唯一子串的集合。要构建此集合，我们遍历每个允许的长度 $k \\in M$。对于每个 $k$，我们遍历所有引导序列 $s_i$。然后我们从每个 $s_i$ 中提取所有长度为 $k$ 的子串，并将它们添加到一个主集合数据结构中以确保唯一性。然后将生成的集合 $\\mathcal{C}$ 按字典序排序。此排序对于正确且高效地实现为选择 $m^\\star$ 而规定的平局决胜规则至关重要。\n\n步骤3：计算富集 $p$-值\n对于每个基序 $m \\in \\mathcal{C}$，我们必须首先计算两个量：\n-   $K(m)$: 数据集中包含基序 $m$ 作为子串的引导序列总数。这通过遍历所有 $N$ 个序列并检查 $m$ 是否存在来计算。\n-   $x(m)$: 集合 $S$ 中包含基序 $m$ 的引导序列数量。这通过遍历由 $S$ 索引的引导序列并检查 $m$ 是否存在来计算。\n\n基序 $m$ 在集合 $S$ 中富集的统计显著性由一个源自超几何分布的 $p$-值来量化。零假设是，集合 $S$ 中的 $n_S$ 个引导序列是从 $N$ 个引导序列的总群体中无放回随机抽取的样本。随机变量 $X$ 表示在此类随机样本中包含基序 $m$ 的引导序列数量。$X$ 服从超几何分布，$X \\sim \\text{Hypergeometric}(N, K(m), n_S)$，其参数为：\n-   总体大小：$N$ (引导序列总数)\n-   总体中成功的数量：$K(m)$ (包含基序 $m$ 的引导序列总数)\n-   样本大小：$n_S$ (集合 $S$ 的大小)\n\n单边 $p$-值是在样本中观察到至少 $x(m)$ 次成功的概率，由 $p(m) = \\mathbb{P}[X \\ge x(m)]$ 给出。这可以使用超几何分布的生存函数 (SF) 来计算，生存函数通常定义为 $\\text{sf}(q) = \\mathbb{P}[X  q]$。因此，我们有 $p(m) = \\mathbb{P}[X \\ge x(m)] = \\text{sf}(x(m)-1)$。在计算上，这可以由 Python 中像 `scipy.stats` 这样的科学计算库中可用的函数可靠地处理。\n\n一个重要的边界情况，如测试用例C所示，是当集合 $S$ 为空时，即 $n_S=0$。在这种情况下，我们抽取一个大小为0的样本。观察到的成功次数 $x(m)$ 必须为0。根据定义，在大小为0的样本中观察到至少0次成功的概率为1。因此，对于任何基序 $m$，如果 $n_S=0$，那么 $p(m)=1$。\n\n步骤4：选择最佳基序 $m^\\star$\n最佳基序 $m^\\star$ 是 $\\mathcal{C}$ 中所有基序里具有最小 $p$-值的那个。问题指定了一个严格的平局决胜规则：如果多个基序产生相同的最小 $p$-值，则选择字典序最小的那个。通过遍历步骤2中按字典序排序的基序列表，遇到的第一个达到最小 $p$-值的基序保证是正确的 $m^\\star$。我们维护一个变量来记录迄今为止找到的最小 $p$-值 $p_{min}$ 和对应的基序 $m^\\star$。每当找到一个 $p$-值严格小于当前 $p_{min}$ 的基序时，我们就更新这些变量。\n\n步骤5：计算最终输出并格式化\n一旦确定了 $m^\\star$ 及其关联的 $p$-值 $p(m^\\star)$，就可以构建最终结果。\n-   $m^\\star = m_1 m_2 \\dots m_k$ 的排名被计算为一个4进制整数。使用提供的映射 $d(\\text{A})=0, d(\\text{C})=1, d(\\text{G})=2, d(\\text{T})=3$，排名由公式 $\\mathrm{rank}(m^\\star) = \\sum_{\\ell=1}^{k} d(m_\\ell) 4^{k-\\ell}$ 给出。这可以使用霍纳法 (Horner's method) 高效实现。\n-   $p$-值 $p(m^\\star)$ 四舍五入到6位小数。\n-   计算显著性指示符 $\\mathbf{1}\\{ p(m^\\star)  \\alpha \\}$，如果条件为真则其值为1，否则为0。\n\n这三个值构成了该测试用例的最终输出列表。然后，所有测试用例的结果会按规定汇总到单个列表中。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import hypergeom\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n\n    test_cases = [\n        # Test case A (happy path)\n        (\n            [ # sequences {s_i}\n                \"ACGTAAACGT\", \"TTTTCGTAAG\", \"GGGGCGTCCC\", \"AACGTTTTTT\",\n                \"AAAATTTTGG\", \"CCCCCAAAAA\", \"GACGTGAAAA\", \"TAAAAAACGT\"\n            ],\n            [1.02, 0.98, 1.05, 1.00, 2.00, 2.10, 0.97, 1.01], # phenotypes {y_i}\n            0.08, # tau\n            3,    # t\n            {3, 4}, # M\n            0.05  # alpha\n        ),\n        # Test case B (tie-breaking)\n        (\n            [ # sequences {s_i}\n                \"AAACCCGGGT\", \"AAACCCGGGA\", \"TTTGGGCCCA\", \"TTTGGGCCCT\"\n            ],\n            [0.50, 0.49, 1.50, 1.60], # phenotypes {y_i}\n            0.02, # tau\n            1,    # t\n            {3},  # M\n            0.05  # alpha\n        ),\n        # Test case C (edge case with empty S)\n        (\n            [ # sequences {s_i}\n                \"AGTCAGTCAG\", \"CAGTCAGTCA\", \"GTCAGTCAGT\", \"TCAGTCAGTC\"\n            ],\n            [0.00, 1.00, 2.00, 3.00], # phenotypes {y_i}\n            0.05, # tau\n            1,    # t\n            {4},  # M\n            0.05  # alpha\n        )\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(*case)\n        # Format the result list into a string representation for the final output.\n        # Ensure floating point numbers are represented correctly.\n        formatted_result = f\"[{result[0]}, {result[1]:.6f}, {result[2]}]\" if isinstance(result[1], float) else f\"[{result[0]}, {result[1]}, {result[2]}]\"\n        # round() can return int if result is .0. str() prints 1.0 which is fine. The above is overkill.\n        # The problem states round(), so float output is adequate. Let's use simpler formatting.\n        results.append(str(result).replace(\" \", \"\"))\n\n\n    print(f\"[{','.join(results)}]\")\n\ndef rank_motif(motif: str) - int:\n    \"\"\"\n    Maps a motif to its base-4 integer rank.\n    \"\"\"\n    d_map = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n    rank = 0\n    for char in motif:\n        rank = rank * 4 + d_map[char]\n    return rank\n\ndef process_case(sequences: list[str], phenotypes: list[float], tau: float, t: int, M: set[int], alpha: float):\n    \"\"\"\n    Processes a single test case according to the problem specification.\n    \"\"\"\n    N = len(sequences)\n\n    # Step 1: Determine the set S of unexpectedly similar guides\n    S = set()\n    for i in range(N):\n        neighbor_count = 0\n        for j in range(N):\n            if i == j:\n                continue\n            if abs(phenotypes[i] - phenotypes[j]) = tau:\n                neighbor_count += 1\n        if neighbor_count = t:\n            S.add(i)\n    nS = len(S)\n\n    # Step 2: Generate the set of candidate motifs C\n    candidate_motifs = set()\n    for k in M:\n        if k = 0:\n            continue\n        for seq in sequences:\n            if len(seq) = k:\n                for i in range(len(seq) - k + 1):\n                    candidate_motifs.add(seq[i:i+k])\n    \n    # Sort for deterministic tie-breaking\n    sorted_motifs = sorted(list(candidate_motifs))\n\n    if not sorted_motifs:\n        # This case suggests the problem setup is ill-posed (no motifs of specified lengths exist).\n        # A robust implementation might return an error or default.\n        return [None, None, None]\n\n    best_motif = \"\"\n    min_p_value = float('inf')\n\n    # Step 3  4: For each motif, calculate p-value and find the best motif\n    for m in sorted_motifs:\n        K_m = sum(1 for s in sequences if m in s)\n        x_m = sum(1 for i in S if m in sequences[i])\n\n        # Calculate the one-sided enrichment p-value using the hypergeometric survival function.\n        # P[X = x_m] is computed as sf(x_m-1).\n        # M_pop - N (total guides)\n        # n_success - K_m (guides with motif)\n        # N_sample - nS (guides in S)\n        p_val = hypergeom.sf(x_m - 1, N, K_m, nS)\n\n        if p_val  min_p_value:\n            min_p_value = p_val\n            best_motif = m\n            # Because the motifs are pre-sorted lexicographically, the first time we\n            # find a minimum p-value, we are guaranteed to satisfy the tie-breaking rule.\n\n    # Step 5: Calculate the final result triple\n    m_star_rank = rank_motif(best_motif)\n    p_m_star_rounded = round(min_p_value, 6)\n    is_significant = 1 if min_p_value  alpha else 0\n\n    return [m_star_rank, p_m_star_rounded, is_significant]\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "我们如何知道哪种分析算法最适合某个特定的生物学问题？本练习将让你扮演方法开发者的角色，任务是构建一个仿真场景，以比较不同的“命中基因”（hit-calling）识别算法在处理一个具有功能相反的亚型基因的复杂情况下的表现 。这项实践突出了仿真在理解不同分析方法优缺点方面的强大作用。",
            "id": "2372047",
            "problem": "您的任务是构建一个完全指定的模拟，用于分析基于成簇规律间隔短回文重复序列 (CRISPR) 的混合扰动筛选，以评估当单个基因具有两个功能相反的亚型并被不同的指导核糖核酸 (gRNA) 靶向时，两种不同的命中基因识别算法的表现。您必须实现一个程序，该程序遵循下面的数学规范，运行一组指定的测试用例，并输出一个单行整数列表，该列表编码了两种算法在每个测试用例上的相对正确性。\n\n考虑一个包含 $G$ 个基因和每个基因 $K$ 个指导序列的混合筛选。有一个特殊的基因，表示为 $g^\\star$，它有两个功能相反的亚型。每个指导序列在筛选前（时间 $0$）和筛选后（时间 $1$）进行测序。对于基因 $j$ 中的每个指导序列 $i$，其筛选前计数 $X_{0,ji}$ 和筛选后计数 $X_{1,ji}$ 是来自负二项分布的独立抽样，该分布被设定为具有指定的均值和一个共同的离散参数。所有随机抽样都必须通过使用每个测试用例提供的种子来为随机数生成器设定种子，从而确定性地执行。\n\n定义以下参数，除非另有说明，否则这些参数在所有测试用例中都是固定的：\n\n- 基因总数 $G = 200$。\n- 每个基因的指导序列数 $K = 6$。\n- 特殊基因索引 $g^\\star = 0$（零基索引）。\n- 每个指导序列的基线筛选前平均计数 $\\mu_0 = 500$。\n- 共同的负二项分布离散（大小参数）$r = 50$。\n- 算法 M 的单侧显著性水平 $\\alpha = 0.05$。\n- 算法 B 的贝叶斯因子阈值 $T = 10$。\n- 算法 B 的备择效应均值大小参数 $\\beta = 0.6$。\n- 所有对数运算必须使用自然对数。\n\n负二项分布的参数化和抽样：对于期望的均值 $\\mu$ 和离散（大小）参数 $r$，令 $p = \\frac{r}{r+\\mu}$。那么一次抽样 $Y \\sim \\mathrm{NB}(r,p)$ 的均值为 $\\mu$，方差为 $\\mu + \\frac{\\mu^2}{r}$。所有计数抽样均使用此参数化方法。\n\n真实的指导序列水平效应：令 $\\ell_{ji}$ 表示基因 $j$ 中指导序列 $i$ 的真实对数倍数变化。\n\n- 对于所有基因 $j \\ne g^\\star$ 及其所有指导序列，设置 $\\ell_{ji} = 0$。\n- 对于特殊基因 $g^\\star$，有三类指导序列：\n  1. 靶向亚型A的指导序列，真实效应为 $+\\mu$（富集）。\n  2. 靶向亚型B的指导序列，真实效应为 $-\\mu$（耗尽）。\n  3. 共享外显子指导序列，真实效应为 $0$。\n  分配给这三类的 $K$ 个指导序列的比例分别为 $p_A$、$p_B$ 和 $p_S$，且 $p_A + p_B + p_S = 1$。要将比例转换为总和为 $K$ 的整数 $(K_A, K_B, K_S)$，首先计算 $(\\lfloor p_A K \\rfloor, \\lfloor p_B K \\rfloor, \\lfloor p_S K \\rfloor)$ 和小数部分 $(\\{p_A K\\}, \\{p_B K\\}, \\{p_S K\\})$。令 $R = K - (\\lfloor p_A K \\rfloor + \\lfloor p_B K \\rfloor + \\lfloor p_S K \\rfloor)$。通过将其小数部分按降序排列，将剩余的 $R$ 个指导序列分配给相应类别，每个类别 $+1$；若小数部分相同，则按A、B、S的固定顺序处理。将前 $K_A$ 个指导序列分配给 $+\\mu$，接下来的 $K_B$ 个指导序列分配给 $-\\mu$，剩余的 $K_S$ 个指导序列分配给 $0$。\n\n计数生成和观测效应：对于基因 $j$ 中的每个指导序列 $i$，进行抽样\n- $X_{0,ji} \\sim \\mathrm{NB}(r, \\frac{r}{r+\\mu_0})$，\n- $X_{1,ji} \\sim \\mathrm{NB}(r, \\frac{r}{r+\\mu_0 \\exp(\\ell_{ji})})$。\n定义观测到的指导序列水平的对数倍数变化\n$$\nL_{ji} = \\log\\left(\\frac{X_{1,ji} + 1}{X_{0,ji} + 1}\\right).\n$$\n\n根据所有指导序列水平的 $L_{ji}$ 值，通过中位数绝对偏差定义一个稳健的尺度估计 $\\hat{\\sigma}$：令 $m = \\mathrm{median}(\\{L_{ji}\\})$ 且 $\\mathrm{MAD} = \\mathrm{median}(|L_{ji} - m|)$。设置 $\\hat{\\sigma} = 1.4826 \\cdot \\mathrm{MAD}$。如果 $\\hat{\\sigma} = 0$，则用 $\\{L_{ji}\\}$ 的样本标准差替换；如果该值也为 $0$，则替换为一个小的常数 $10^{-8}$。\n\n算法 M（带有Bonferroni校正的方向特异性秩-最小值p值）：\n1. 对于每个指导序列 $L_{ji}$，定义标准化值 $Z_{ji} = \\frac{L_{ji}}{\\hat{\\sigma}}$。\n2. 令 $\\Phi(\\cdot)$ 表示标准正态累积分布函数。将耗尽和富集的单侧p值分别定义为 $p^-_{ji} = \\Phi(Z_{ji})$ 和 $p^+_{ji} = 1 - \\Phi(Z_{ji})$。\n3. 对于每个基因 $j$，定义经Bonferroni校正的基因水平值 $P^-_j = \\min\\{1, K \\cdot \\min_i p^-_{ji}\\}$ 和 $P^+_j = \\min\\{1, K \\cdot \\min_i p^+_{ji}\\}$。\n4. 定义 $P_j = \\min(P^-_j, P^+_j)$ 和预测方向 $\\mathrm{dir}_M(j) = +1$（如果 $P^+_j  P^-_j$），否则 $\\mathrm{dir}_M(j) = -1$。如果 $P^+_j = P^-_j$，通过设置 $\\mathrm{dir}_M(j) = +1$ 来打破平局。\n5. 如果 $P_j \\le \\alpha$，算法 M 将基因 $j$ 判定为命中基因；否则，不判定为命中基因。\n\n算法 B（使用固定备择假设的高斯似然比的双边贝叶斯因子）：\n1. 设 $L_{ji}$ 的零分布为 $\\mathcal{N}(0, \\tau^2)$，其中 $\\tau = \\hat{\\sigma}$。\n2. 定义两个备择分布：耗尽 $\\mathcal{N}(-\\beta, \\tau^2)$ 和富集 $\\mathcal{N}(+\\beta, \\tau^2)$。\n3. 对每个基因 $j$，计算对数贝叶斯因子\n$$\n\\log \\mathrm{BF}^-(j) = \\sum_{i=1}^K \\left[ \\log \\phi(L_{ji}; -\\beta, \\tau) - \\log \\phi(L_{ji}; 0, \\tau) \\right],\n$$\n$$\n\\log \\mathrm{BF}^+(j) = \\sum_{i=1}^K \\left[ \\log \\phi(L_{ji}; +\\beta, \\tau) - \\log \\phi(L_{ji}; 0, \\tau) \\right],\n$$\n其中 $\\phi(x; \\mu, \\tau)$ 是均值为 $\\mu$、标准差为 $\\tau$ 的高斯概率密度函数。令 $\\log \\mathrm{BF}_{\\max}(j) = \\max(\\log \\mathrm{BF}^-(j), \\log \\mathrm{BF}^+(j))$。预测方向为 $\\mathrm{dir}_B(j) = +1$（如果 $\\log \\mathrm{BF}^+(j)  \\log \\mathrm{BF}^-(j)$），否则为 $\\mathrm{dir}_B(j) = -1$。如果相等，则通过设置 $\\mathrm{dir}_B(j) = +1$ 来打破平局。\n4. 如果 $\\log \\mathrm{BF}_{\\max}(j) \\ge \\log T$，算法 B 将基因 $j$ 判定为命中基因；否则，不判定为命中基因。\n\n特殊基因 $g^\\star$ 的真实方向仅由设计比例决定：定义 $L^\\star = +1$（如果 $p_A  p_B$），$L^\\star = -1$（如果 $p_B  p_A$），以及 $L^\\star = 0$（如果 $p_A = p_B$）。一个算法对 $g^\\star$ 的判定是否正确如下确定：如果 $L^\\star \\in \\{+1, -1\\}$，算法当且仅当判定其为命中基因且其预测方向等于 $L^\\star$ 时为正确；如果 $L^\\star = 0$，算法当且仅当不判定其为命中基因时为正确。\n\n对于每个测试用例，计算算法 M 和 B 在特殊基因 $g^\\star$ 上的两个正确性指标 $C_M$ 和 $C_B$（每个指标为 $0$ 或 $1$）。将它们映射为单个整数结果 $R = 2 \\cdot C_M + C_B$，其取值范围为 $\\{0,1,2,3\\}$，分别对应于两者都不正确、仅算法 B 正确、仅算法 M 正确或两者都正确。\n\n测试套件：对于每个用例，您将获得一个元组 $(\\mathrm{seed}, \\mu, p_A, p_B, p_S)$，其中 $p_A + p_B + p_S = 1$。使用以下四个测试用例：\n1. $(42, 0.8, 0.8, 0.2, 0.0)$，\n2. $(43, 0.8, 0.25, 0.75, 0.0)$，\n3. $(44, 0.8, 0.5, 0.5, 0.0)$，\n4. $(45, 1.0, 0.1, 0.1, 0.8)$。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来（例如 $[r_1,r_2,r_3,r_4]$），其中每个 $r_i$ 是对应测试用例的整数 $R$，顺序与上面列出的一致。不应打印任何其他文本。不涉及物理单位或角度，任何分数在输入参数中必须表示为小数。所有计算都必须按规定执行，并且在给定种子的情况下是可复现的。",
            "solution": "该问题要求构建并执行一个详细的模拟，该模拟针对基于成簇规律间隔短回文重复序列 (CRISPR) 的混合扰动筛选。其目标是在一个特定场景下评估两种不同命中基因识别算法（指定为算法M和算法B）的性能。该场景涉及一个特殊基因 $g^\\star$，它拥有两个具有拮抗生物学效应（富集和耗尽）的亚型。该问题被判定为有效，因为它在计算生物学和生物信息学原理上具有科学依据，在数学和算法上是适定的，并为模拟提供了完整而明确的规范。\n\n模拟过程的结构如下。我们首先定义筛选的参数和数据生成的统计模型。然后我们描述两种分析算法的实现。最后，我们建立评估每种算法对特殊基因 $g^\\star$ 分类正确性的标准。\n\n**1. 模拟框架**\n\n模拟的筛选包含 $G = 200$ 个基因，每个基因由 $K = 6$ 个指导RNA (gRNA) 靶向。一个索引为 $g^\\star = 0$ 的特定基因被建模为具有两个效应相反的亚型。对于基因 $j$ 中的每个指导序列 $i$，我们模拟来自筛选前文库 ($T_0$) 和筛选后文库 ($T_1$) 的读数计数。这些计数表示为 $X_{0,ji}$ 和 $X_{1,ji}$，是从负二项分布 $\\mathrm{NB}(r, p)$ 中生成的，这是对高通量测序产生的过度离散计数数据进行建模的标准选择。该分布由其离散（大小）参数 $r = 50$ 和一个概率参数 $p$ 来参数化。对于期望的平均计数 $\\mu$，概率设置为 $p = \\frac{r}{r+\\mu}$。筛选前文库中一个指导序列的基线平均计数为 $\\mu_0 = 500$。\n\n一个指导序列的真实生物学效应由其对数倍数变化 $\\ell_{ji}$ 表示。对于所有靶向非特殊基因 ($j \\ne g^\\star$) 的指导序列，其效应为空，即 $\\ell_{ji} = 0$。对于特殊基因 $g^\\star$，指导序列被分为三类：\n- $K_A$ 个靶向亚型A的指导序列，真实效应为 $+\\mu$（富集）。\n- $K_B$ 个靶向亚型B的指导序列，真实效应为 $-\\mu$（耗尽）。\n- $K_S$ 个靶向共享区域的指导序列，真实效应为 $0$。\n\n计数 $K_A$、$K_B$ 和 $K_S$ 由指定的比例 $(p_A, p_B, p_S)$ 决定，满足 $p_A + p_B + p_S = 1$。整数计数通过首先对每个类别的 $p \\cdot K$ 取底，然后将剩余的 $R = K - (\\lfloor p_A K \\rfloor + \\lfloor p_B K \\rfloor + \\lfloor p_S K \\rfloor)$ 个指导序列逐一分配给小数部分最大的类别（按A、B、S的顺序打破平局）来确定性地计算。\n\n在定义了真实效应 $\\ell_{ji}$ 后，筛选后计数的均值为 $\\mu_0 \\exp(\\ell_{ji})$。因此，计数生成如下：\n$$\nX_{0,ji} \\sim \\mathrm{NB}\\left(r, \\frac{r}{r+\\mu_0}\\right)\n$$\n$$\nX_{1,ji} \\sim \\mathrm{NB}\\left(r, \\frac{r}{r+\\mu_0 \\exp(\\ell_{ji})}\\right)\n$$\n所有随机抽样都是使用每个用例的种子为随机数生成器设定种子来确定性地执行的。根据这些计数，计算观测到的指导序列水平的对数倍数变化 $L_{ji}$，其中加入一个伪计数 $1$ 来处理零计数：\n$$\nL_{ji} = \\log\\left(\\frac{X_{1,ji} + 1}{X_{0,ji} + 1}\\right)\n$$\n其中 $\\log$ 表示自然对数。\n\n使用中位数绝对偏差 (MAD) 从所有观测到的 $L_{ji}$ 值集合中计算出零假设下对数倍数变化的标准差的稳健估计 $\\hat{\\sigma}$：$\\hat{\\sigma} = 1.4826 \\cdot \\mathrm{median}(|L_{ji} - \\mathrm{median}(\\{L\\cdot\\})|)$。如果 $\\hat{\\sigma}$ 为零，则使用指定的备用方法。\n\n**2. 命中基因识别算法**\n\n将两种算法应用于数据以识别命中基因。\n\n**算法 M (改进的秩-最小值P值):**\n该算法基于识别每个基因的最极端的单个指导序列效应，并应用Bonferroni校正。\n1. 对每个指导序列，计算一个标准化的Z-score：$Z_{ji} = L_{ji} / \\hat{\\sigma}$。\n2. 使用标准正态累积分布函数 $\\Phi(\\cdot)$ 计算耗尽和富集的单侧p值：\n   $$ p^-_{ji} = \\Phi(Z_{ji}) \\quad \\text{和} \\quad p^+_{ji} = 1 - \\Phi(Z_{ji}) $$\n3. 通过取每个方向上最小的指导序列水平p值并对 $K$ 个指导序列应用Bonferroni校正，来获得基因水平的p值：\n   $$ P^-_j = \\min\\left(1, K \\cdot \\min_i p^-_{ji}\\right) \\quad \\text{和} \\quad P^+_j = \\min\\left(1, K \\cdot \\min_i p^+_{ji}\\right) $$\n4. 最终的基因p值为 $P_j = \\min(P^-_j, P^+_j)$。预测方向 $\\mathrm{dir}_M(j)$ 在 $P^+_j  P^-_j$ 时为 $+1$，否则为 $-1$（平局打破规则为 $+1$）。\n5. 如果 $P_j \\le \\alpha$，其中显著性水平为 $\\alpha = 0.05$，则判定一个基因为命中基因。\n\n**算法 B (基于贝叶斯因子):**\n该算法使用贝叶斯框架，将一个零假设与两个具有固定效应量的备择假设进行比较。\n1. 对于一个非命中基因，假定其观测到的对数倍数变化 $L_{ji}$ 服从零分布 $\\mathcal{N}(0, \\hat{\\sigma}^2)$。\n2. 定义两个备择分布：耗尽效应的 $\\mathcal{N}(-\\beta, \\hat{\\sigma}^2)$ 和富集效应的 $\\mathcal{N}(+\\beta, \\hat{\\sigma}^2)$，固定效应大小为 $\\beta = 0.6$。\n3. 对于每个基因 $j$，计算对数贝叶斯因子以比较备择假设与零假设。对于单个指导序列 $L_{ji}$，正向备择假设与零假设的对数似然比简化为 $\\frac{L_{ji}\\beta}{\\hat{\\sigma}^2} - \\frac{\\beta^2}{2\\hat{\\sigma}^2}$。对基因 $j$ 的所有指导序列求和：\n   $$ \\log \\mathrm{BF}^+(j) = \\sum_{i=1}^K \\left( \\frac{L_{ji}\\beta}{\\hat{\\sigma}^2} - \\frac{\\beta^2}{2\\hat{\\sigma}^2} \\right) = \\frac{\\beta}{\\hat{\\sigma}^2} \\sum_{i=1}^K L_{ji} - \\frac{K\\beta^2}{2\\hat{\\sigma}^2} $$\n   同样，对于负向备择假设：\n   $$ \\log \\mathrm{BF}^-(j) = \\sum_{i=1}^K \\left( -\\frac{L_{ji}\\beta}{\\hat{\\sigma}^2} - \\frac{\\beta^2}{2\\hat{\\sigma}^2} \\right) = -\\frac{\\beta}{\\hat{\\sigma}^2} \\sum_{i=1}^K L_{ji} - \\frac{K\\beta^2}{2\\hat{\\sigma}^2} $$\n4. 最大对数贝叶斯因子为 $\\log \\mathrm{BF}_{\\max}(j) = \\max(\\log \\mathrm{BF}^-(j), \\log \\mathrm{BF}^+(j))$。预测方向 $\\mathrm{dir}_B(j)$ 在 $\\log \\mathrm{BF}^+(j)  \\log \\mathrm{BF}^-(j)$ 时为 $+1$，否则为 $-1$（平局打破规则为 $+1$）。\n5. 如果证据足够强，即 $\\log \\mathrm{BF}_{\\max}(j) \\ge \\log T$（其中贝叶斯因子阈值为 $T = 10$），则判定一个基因为命中基因。\n\n**3. 评估与输出**\n\n每种算法的性能仅在特殊基因 $g^\\star$ 上进行评估。该基因的真实方向 $L^\\star$ 由输入设计定义：如果 $p_A  p_B$ 则 $L^\\star = +1$，如果 $p_B  p_A$ 则 $L^\\star = -1$，如果 $p_A = p_B$ 则 $L^\\star = 0$。\n- 如果 $L^\\star \\in \\{+1, -1\\}$，一个算法当且仅当它将 $g^\\star$ 判定为命中基因且其预测方向与 $L^\\star$ 匹配时，才被认为是正确的。\n- 如果 $L^\\star = 0$，一个算法当且仅当它不将 $g^\\star$ 判定为命中基因时，才被认为是正确的。\n\n对于每个测试用例，我们分别为算法M和B计算二进制正确性指标 $C_M$ 和 $C_B$。这些指标被组合成一个单一的整数结果 $R = 2 \\cdot C_M + C_B$，该结果唯一地编码了两种算法的结果。程序将为每个提供的测试用例执行模拟，并输出这些整数结果的列表。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import nbinom, norm\n\ndef solve():\n    \"\"\"\n    Runs the full CRISPR screen simulation and analysis for a suite of test cases.\n    \"\"\"\n\n    # --- Fixed Parameters ---\n    G = 200  # Total number of genes\n    K = 6  # Guides per gene\n    g_star_idx = 0  # Special gene index\n    mu_0 = 500.0  # Baseline pre-selection mean count\n    r = 50.0  # Common Negative Binomial dispersion (size)\n    alpha = 0.05  # Significance level for Algorithm M\n    T = 10.0  # Bayes factor threshold for Algorithm B\n    beta = 0.6  # Alternative effect size for Algorithm B\n\n    # --- Test Cases (seed, mu, p_A, p_B, p_S) ---\n    test_cases = [\n        (42, 0.8, 0.8, 0.2, 0.0),\n        (43, 0.8, 0.25, 0.75, 0.0),\n        (44, 0.8, 0.5, 0.5, 0.0),\n        (45, 1.0, 0.1, 0.1, 0.8),\n    ]\n\n    results = []\n\n    for seed, mu_effect, p_A, p_B, p_S in test_cases:\n        rng = np.random.default_rng(seed)\n\n        # --- 1. Determine Guide Counts for Special Gene ---\n        fractions = {'A': p_A, 'B': p_B, 'S': p_S}\n        base_counts = {cat: int(frac * K) for cat, frac in fractions.items()}\n        remainders = {cat: frac * K - base_counts[cat] for cat, frac in fractions.items()}\n        \n        # Sort categories by remainder descending, with tie-break A, B, S\n        sorted_cats = sorted(fractions.keys(), key=lambda c: (-remainders[c], ['A', 'B', 'S'].index(c)))\n        \n        R_rem = K - sum(base_counts.values())\n        final_counts = base_counts.copy()\n        for i in range(R_rem):\n            final_counts[sorted_cats[i]] += 1\n        \n        K_A, K_B, K_S = final_counts['A'], final_counts['B'], final_counts['S']\n\n        # --- 2. Generate True Log Fold Changes (l_ji) ---\n        l_ji = np.zeros((G, K))\n        effects = np.concatenate([\n            np.full(K_A, mu_effect),\n            np.full(K_B, -mu_effect),\n            np.full(K_S, 0.0)\n        ])\n        l_ji[g_star_idx, :] = effects\n\n        # --- 3. Generate Counts and Observed LFCs ---\n        p0 = r / (r + mu_0)\n        X0 = nbinom.rvs(n=r, p=p0, size=(G, K), random_state=rng)\n        \n        mu1 = mu_0 * np.exp(l_ji)\n        p1 = r / (r + mu1)\n        X1 = nbinom.rvs(n=r, p=p1, size=(G, K), random_state=rng)\n\n        L_ji = np.log((X1 + 1) / (X0 + 1))\n\n        # --- 4. Estimate Robust Scale (sigma_hat) ---\n        median_lfc = np.median(L_ji)\n        mad = np.median(np.abs(L_ji - median_lfc))\n        sigma_hat = 1.4826 * mad\n        if sigma_hat == 0.0:\n            sigma_hat = np.std(L_ji)\n            if sigma_hat == 0.0:\n                sigma_hat = 1e-8\n\n        # --- 5. Run Algorithms on Special Gene g* ---\n        L_star = L_ji[g_star_idx, :]\n        \n        # --- Algorithm M ---\n        Z_star = L_star / sigma_hat\n        p_minus_guides = norm.cdf(Z_star)\n        p_plus_guides = 1.0 - p_minus_guides\n        \n        P_minus_star = min(1.0, K * np.min(p_minus_guides))\n        P_plus_star = min(1.0, K * np.min(p_plus_guides))\n        \n        P_star_M = min(P_minus_star, P_plus_star)\n        \n        # Tie-break: dir=+1 if P+ = P-\n        dir_M = 1 if P_plus_star = P_minus_star else -1\n        hit_M = P_star_M = alpha\n\n        # --- Algorithm B ---\n        sum_L_star = np.sum(L_star)\n        log_BF_plus = (beta / sigma_hat**2) * sum_L_star - (K * beta**2) / (2 * sigma_hat**2)\n        log_BF_minus = (-beta / sigma_hat**2) * sum_L_star - (K * beta**2) / (2 * sigma_hat**2)\n        \n        log_BF_max = max(log_BF_plus, log_BF_minus)\n\n        # Tie-break: dir=+1 if BF+ >= BF-\n        dir_B = 1 if log_BF_plus = log_BF_minus else -1\n        hit_B = log_BF_max = np.log(T)\n\n        # --- 6. Evaluate Correctness ---\n        if p_A  p_B:\n            L_star_truth = 1\n        elif p_B  p_A:\n            L_star_truth = -1\n        else:\n            L_star_truth = 0\n\n        C_M = 0\n        if L_star_truth in [1, -1]:\n            if hit_M and dir_M == L_star_truth:\n                C_M = 1\n        elif L_star_truth == 0:\n            if not hit_M:\n                C_M = 1\n\n        C_B = 0\n        if L_star_truth in [1, -1]:\n            if hit_B and dir_B == L_star_truth:\n                C_B = 1\n        elif L_star_truth == 0:\n            if not hit_B:\n                C_B = 1\n        \n        # --- 7. Compute Final Result ---\n        R = 2 * C_M + C_B\n        results.append(R)\n\n    # --- Print Final Output ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}