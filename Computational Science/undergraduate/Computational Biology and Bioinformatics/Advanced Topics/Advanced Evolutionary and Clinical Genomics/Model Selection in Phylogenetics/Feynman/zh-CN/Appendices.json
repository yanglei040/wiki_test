{
    "hands_on_practices": [
        {
            "introduction": "这个练习是您实践技能的基石。我们将把赤池信息准则（AIC）和贝叶斯信息准则（BIC）应用于一组常见的嵌套替换模型，这些模型在系统发育学中被广泛使用。 这个练习将帮助您掌握计算模型参数这一关键技能，并直接观察模型拟合度（通过对数似然值衡量）与复杂性（通过参数数量衡量）之间的权衡，这是所有模型选择中的核心主题。",
            "id": "2734801",
            "problem": "一个长度为 $5000$ 个位点的核苷酸序列比对，在一个关联 $12$ 个分类单元的固定的、完全解析的无根拓扑结构上进行了分析。对于一个包含 $m$ 个分类单元的无根二叉系统发育，存在 $2m - 3$ 个分支，每个分支都有一个独立的分支长度参数。在五个时间同质、时间可逆的替换模型下获得的最大对数似然值（自然对数）如下所示，所有值都是在相同的拓扑结构和序列比对上估计的：\n\n- JC69： $\\ln \\hat{L}_{\\mathrm{JC69}} = -7423.6$\n- HKY： $\\ln \\hat{L}_{\\mathrm{HKY}} = -7089.2$\n- GTR： $\\ln \\hat{L}_{\\mathrm{GTR}} = -7012.8$\n- GTR+G（四个离散伽马类别，单个形状参数）：$\\ln \\hat{L}_{\\mathrm{GTR+G}} = -6844.5$\n- GTR+G+I（伽马分布同上，外加一个恒定不变位点的比例）：$\\ln \\hat{L}_{\\mathrm{GTR+G+I}} = -6839.7$\n\n假设核苷酸模型采用标准参数化：JC69 模型具有相等的碱基频率和相等的可交换性，除了分支长度外，不增加额外的自由替换过程参数；HKY 模型增加了一个转换/颠换率比值参数 $\\kappa$ 和三个独立的碱基频率参数；GTR 模型有五个独立的可交换性参数和三个独立的碱基频率参数；$+G$ 扩展增加了一个伽马形状参数 $\\alpha$；$+I$ 扩展增加了一个恒定不变位点比例的参数。离散伽马类别的数量是固定的，不增加参数。\n\n使用赤池信息准则 (Akaike Information Criterion, AIC) 和贝叶斯信息准则 (Bayesian Information Criterion, BIC) 的标准定义，每个准则都在最大化对数似然值与一个惩罚项之间进行权衡，该惩罚项随自由参数数量的增加而增加，对于 BIC，还随样本量（此处为序列比对的位点数）的增加而增加。请完成以下任务：\n\n1. 确定每个模型的自由参数总数 $k$，包括所有分支长度和模型特定参数。\n2. 计算每个模型的 AIC 和 BIC 值。\n3. 根据 AIC 和 BIC 确定最优模型（即各自准则值最小的模型）。\n4. 作为最终数值答案，报告 AIC 最优模型的赤池权重（基于 AIC 的归一化相对似然），以小数形式表示。将最终数值答案四舍五入到四位有效数字。",
            "solution": "该问题要求使用赤池信息准则 (AIC) 和贝叶斯信息准则 (BIC) 对五个嵌套的核苷酸替换模型进行比较分析。目标是识别出最佳拟合模型，并通过其赤池权重来量化其支持度。\n\n首先，我们必须定义这两个准则。AIC 由以下公式给出：\n$$\nAIC = 2k - 2\\ln \\hat{L}\n$$\n其中 $k$ 是模型中的自由参数数量，$\\ln \\hat{L}$ 是最大化的自然对数似然值。BIC 由以下公式给出：\n$$\nBIC = k \\ln(n) - 2\\ln \\hat{L}\n$$\n其中 $n$ 是样本量，在此情境中是核苷酸序列比对中的位点数，给定为 $n = 5000$。\n\n第一步是正确确定五个模型中每一个的自由参数总数 $k$。参数总数是分支长度参数数量与替换过程参数数量之和。\n对于一个包含 $m$ 个分类单元的无根二叉系统发育树，其分支数量为 $2m - 3$。在这里，$m = 12$ 个分类单元，所以分支数量为 $2(12) - 3 = 21$。每个分支都有一个长度参数，因此所有模型都共有 $k_{branches} = 21$ 个参数。\n\n我们现在按描述确定每个模型的替换过程参数数量 ($k_{subst}$)：\n- **JC69**：该模型假设碱基频率相等，替换率单一。它没有用于替换过程的自由参数。因此，$k_{subst, \\mathrm{JC69}} = 0$。\n- **HKY**：该模型引入了一个转换/颠换率比值参数 ($\\kappa$)，并允许不相等的碱基频率。由于四个碱基频率之和必须为 $1$，因此有 $3$ 个自由的频率参数。因此，$k_{subst, \\mathrm{HKY}} = 1 + 3 = 4$。\n- **GTR**：这是通用时间可逆模型。它有 $6$ 个可交换性参数，但它们是相对的，所以只有 $5$ 个是自由的。它还有 $3$ 个自由的碱基频率参数。因此，$k_{subst, \\mathrm{GTR}} = 5 + 3 = 8$。\n- **GTR+G**：该模型增加了一个用于描述跨位点变异率的伽马分布的参数，即形状参数 $\\alpha$。因此，$k_{subst, \\mathrm{GTR+G}} = k_{subst, \\mathrm{GTR}} + 1 = 8 + 1 = 9$。\n- **GTR+G+I**：该模型增加了一个恒定不变位点比例的参数 $p_{inv}$。因此，$k_{subst, \\mathrm{GTR+G+I}} = k_{subst, \\mathrm{GTR+G}} + 1 = 9 + 1 = 10$。\n\n每个模型的总参数数量 ($k$) 为：\n- $k_{\\mathrm{JC69}} = 21 + 0 = 21$\n- $k_{\\mathrm{HKY}} = 21 + 4 = 25$\n- $k_{\\mathrm{GTR}} = 21 + 8 = 29$\n- $k_{\\mathrm{GTR+G}} = 21 + 9 = 30$\n- $k_{\\mathrm{GTR+G+I}} = 21 + 10 = 31$\n\n利用 $k$、$\\ln \\hat{L}$ 和 $n=5000$ 的值，我们可以计算每个模型的 AIC 和 BIC。\n\n1. **JC69**：$k = 21$，$\\ln \\hat{L} = -7423.6$\n   $AIC_{\\mathrm{JC69}} = 2(21) - 2(-7423.6) = 42 + 14847.2 = 14889.2$\n   $BIC_{\\mathrm{JC69}} = 21\\ln(5000) - 2(-7423.6) \\approx 21(8.5172) + 14847.2 = 178.8612 + 14847.2 = 15026.0612$\n\n2. **HKY**：$k = 25$，$\\ln \\hat{L} = -7089.2$\n   $AIC_{\\mathrm{HKY}} = 2(25) - 2(-7089.2) = 50 + 14178.4 = 14228.4$\n   $BIC_{\\mathrm{HKY}} = 25\\ln(5000) - 2(-7089.2) \\approx 25(8.5172) + 14178.4 = 212.9300 + 14178.4 = 14391.3300$\n\n3. **GTR**：$k = 29$，$\\ln \\hat{L} = -7012.8$\n   $AIC_{\\mathrm{GTR}} = 2(29) - 2(-7012.8) = 58 + 14025.6 = 14083.6$\n   $BIC_{\\mathrm{GTR}} = 29\\ln(5000) - 2(-7012.8) \\approx 29(8.5172) + 14025.6 = 246.9988 + 14025.6 = 14272.5988$\n\n4. **GTR+G**：$k = 30$，$\\ln \\hat{L} = -6844.5$\n   $AIC_{\\mathrm{GTR+G}} = 2(30) - 2(-6844.5) = 60 + 13689.0 = 13749.0$\n   $BIC_{\\mathrm{GTR+G}} = 30\\ln(5000) - 2(-6844.5) \\approx 30(8.5172) + 13689.0 = 255.5160 + 13689.0 = 13944.5160$\n\n5. **GTR+G+I**：$k = 31$，$\\ln \\hat{L} = -6839.7$\n   $AIC_{\\mathrm{GTR+G+I}} = 2(31) - 2(-6839.7) = 62 + 13679.4 = 13741.4$\n   $BIC_{\\mathrm{GTR+G+I}} = 31\\ln(5000) - 2(-6839.7) \\approx 31(8.5172) + 13679.4 = 264.0332 + 13679.4 = 13943.4332$\n\n最优模型是信息准则得分最小的模型。\n- 对于 AIC，最小值为 $AIC_{min} = 13741.4$，对应于 **GTR+G+I** 模型。\n- 对于 BIC，最小值为 $BIC_{min} \\approx 13943.43$，同样对应于 **GTR+G+I** 模型。\n\n最后，我们必须计算 AIC 下最优模型（即 GTR+G+I）的赤池权重。模型 $i$ 的赤池权重 ($w_i$) 是衡量其在一组候选模型中相对支持度的指标。其计算公式为：\n$$\nw_i = \\frac{\\exp(-\\frac{1}{2}\\Delta_i)}{\\sum_{j=1}^{R} \\exp(-\\frac{1}{2}\\Delta_j)}\n$$\n其中 $\\Delta_i = AIC_i - AIC_{min}$，$R=5$ 是模型的数量。\n\n首先，我们计算每个模型相对于 $AIC_{min} = AIC_{\\mathrm{GTR+G+I}} = 13741.4$ 的 $\\Delta_i$ 值。\n- $\\Delta_{\\mathrm{JC69}} = 14889.2 - 13741.4 = 1147.8$\n- $\\Delta_{\\mathrm{HKY}} = 14228.4 - 13741.4 = 487.0$\n- $\\Delta_{\\mathrm{GTR}} = 14083.6 - 13741.4 = 342.2$\n- $\\Delta_{\\mathrm{GTR+G}} = 13749.0 - 13741.4 = 7.6$\n- $\\Delta_{\\mathrm{GTR+G+I}} = 13741.4 - 13741.4 = 0$\n\n接下来，我们计算最优模型 (GTR+G+I) 的赤池权重的分子：\n$\\exp(-\\frac{1}{2}\\Delta_{\\mathrm{GTR+G+I}}) = \\exp(-\\frac{1}{2} \\times 0) = \\exp(0) = 1$。\n\n现在，我们计算分母，即所有模型相对似然之和：\n$\\sum_{j=1}^{5} \\exp(-\\frac{1}{2}\\Delta_j) = \\exp(-\\frac{1147.8}{2}) + \\exp(-\\frac{487.0}{2}) + \\exp(-\\frac{342.2}{2}) + \\exp(-\\frac{7.6}{2}) + \\exp(-\\frac{0}{2})$\n$\\sum_{j} \\exp(-\\frac{1}{2}\\Delta_j) = \\exp(-573.9) + \\exp(-243.5) + \\exp(-171.1) + \\exp(-3.8) + \\exp(0)$\n前三项小到可以忽略不计，在数值上可以忽略。我们计算：\n$\\exp(-3.8) \\approx 0.0223708$\n$\\exp(0) = 1$\n因此，总和约等于 $0 + 0 + 0 + 0.0223708 + 1 = 1.0223708$。\n\nGTR+G+I 模型的赤池权重为：\n$w_{\\mathrm{GTR+G+I}} = \\frac{1}{1.0223708} \\approx 0.978119$\n\n四舍五入到四位有效数字，AIC 最优模型的赤池权重为 $0.9781$。这表明，在给定数据和候选模型集的情况下，GTR+G+I 模型在 Kullback-Leibler 意义下是最佳模型的概率约为 $97.81\\%$。",
            "answer": "$$\\boxed{0.9781}$$"
        },
        {
            "introduction": "在掌握了基础知识之后，接下来的练习将引入一个重要的改进：小样本校正的赤池信息准则（AICc）。您将通过一个精心设计的思想实验，探索一个 AIC 和 AICc 对模型偏好得出不同结论的场景。 这个练习旨在揭示当数据集大小 $n$ 相对于模型参数数量 $k$ 不大时，为什么 AICc 的校正至关重要，从而加深您对惩罚项作用以及选择合适统计工具重要性的理解。",
            "id": "2734863",
            "problem": "一个包含来自 $10$ 个分类单元的 $n=800$ 个比对核苷酸位点的系统发育基因组学数据集，在最大似然法下用两种时间可逆替换模型进行分析。这两种模型参数化方式不同，但共享相同的固定拓扑结构和支长优化程序。模型 $\\mathcal{M}_{1}$ 有 $k_{1}=20$ 个自由参数，其最大化对数似然值为 $\\ln \\hat{L}_{1}=-11234.5$。模型 $\\mathcal{M}_{2}$ 有 $k_{2}=40$ 个自由参数，其最大化对数似然值为 $\\ln \\hat{L}_{2}=-11213.5$。利用最大似然原理以及赤池信息准则 (AIC) 和小样本校正的赤池信息准则 (AICc) 的标准定义，完成以下任务：\n\n1) 计算 $\\mathcal{M}_{1}$ 和 $\\mathcal{M}_{2}$ 的 AIC 和 AICc。\n\n2) 判断在 AIC 和 AICc 标准下分别哪个模型更优，并通过推导在给定 $(n,k_{1},k_{2})$ 的情况下，更复杂的模型 $\\mathcal{M}_{2}$ 要成为更优模型所需的对数似然值改进阈值 $\\Delta \\ln \\hat{L}=\\ln \\hat{L}_{2}-\\ln \\hat{L}_{1}$，来解释这两种标准下排序的差异。\n\n3) 最后，报告单一数值 $\\Delta=\\mathrm{AICc}_{2}-\\mathrm{AICc}_{1}$，四舍五入到四位有效数字。最终报告的数字不应包含单位。",
            "solution": "此问题要求使用信息论准则对两个系统发育模型进行定量比较。我将首先验证问题陈述的有效性。\n\n给定的数据是：\n- 样本量（位点数），$n = 800$。\n- 模型 $\\mathcal{M}_{1}$ 的自由参数数量，$k_{1} = 20$。\n- 模型 $\\mathcal{M}_{1}$ 的最大化对数似然值，$\\ln \\hat{L}_{1} = -11234.5$。\n- 模型 $\\mathcal{M}_{2}$ 的自由参数数量，$k_{2} = 40$。\n- 模型 $\\mathcal{M}_{2}$ 的最大化对数似然值，$\\ln \\hat{L}_{2} = -11213.5$。\n分类单元数量 $10$ 是背景信息，在 AIC 和 AICc 的标准定义中不使用，这两个定义依赖于样本量 $n$ 和参数数量 $k$。\n\n该问题具有科学依据，使用了系统发育学中模型选择的标准方法（AIC, AICc）。问题是适定的，为计算提供了所有必要的数值。整个设定是完整、一致且无歧义的。因此，该问题是有效的，可以进行求解。\n\n赤池信息准则 (Akaike Information Criterion, AIC) 定义为：\n$$ \\mathrm{AIC} = 2k - 2 \\ln \\hat{L} $$\n其中 $k$ 是模型中可估计参数的数量，$\\ln \\hat{L}$ 是对数似然函数的最大化值。\n\n小样本校正的赤池信息准则 (AICc)，在比率 $\\frac{n}{k}$ 较小（通常小于 $40$）时推荐使用，其定义为：\n$$ \\mathrm{AICc} = \\mathrm{AIC} + \\frac{2k(k+1)}{n-k-1} = 2k - 2 \\ln \\hat{L} + \\frac{2k(k+1)}{n-k-1} $$\n\n**1) AIC 和 AICc 的计算**\n\n对于模型 $\\mathcal{M}_{1}$，我们有 $k_{1} = 20$，$\\ln \\hat{L}_{1} = -11234.5$ 和 $n=800$。\nAIC 值为：\n$$ \\mathrm{AIC}_{1} = 2k_{1} - 2 \\ln \\hat{L}_{1} = 2(20) - 2(-11234.5) = 40 + 22469 = 22509 $$\nAICc 值为：\n$$ \\mathrm{AICc}_{1} = \\mathrm{AIC}_{1} + \\frac{2k_{1}(k_{1}+1)}{n-k_{1}-1} = 22509 + \\frac{2(20)(20+1)}{800-20-1} = 22509 + \\frac{840}{779} \\approx 22509 + 1.0783 = 22510.0783 $$\n\n对于模型 $\\mathcal{M}_{2}$，我们有 $k_{2} = 40$，$\\ln \\hat{L}_{2} = -11213.5$ 和 $n=800$。\nAIC 值为：\n$$ \\mathrm{AIC}_{2} = 2k_{2} - 2 \\ln \\hat{L}_{2} = 2(40) - 2(-11213.5) = 80 + 22427 = 22507 $$\nAICc 值为：\n$$ \\mathrm{AICc}_{2} = \\mathrm{AIC}_{2} + \\frac{2k_{2}(k_{2}+1)}{n-k_{2}-1} = 22507 + \\frac{2(40)(40+1)}{800-40-1} = 22507 + \\frac{3280}{759} \\approx 22507 + 4.3215 = 22511.3215 $$\n\n**2) 模型偏好与阈值推导**\n\nAIC 或 AICc 值较低的模型更优。\n- 根据 AIC：$\\mathrm{AIC}_{2} = 22507 < \\mathrm{AIC}_{1} = 22509$。因此，更复杂的模型 $\\mathcal{M}_{2}$ 更优。\n- 根据 AICc：$\\mathrm{AICc}_{1} \\approx 22510.08 < \\mathrm{AICc}_{2} \\approx 22511.32$。因此，更简单的模型 $\\mathcal{M}_{1}$ 更优。\n\n这种差异的产生是因为 AICc 对额外参数的惩罚比 AIC 更大，并且这种惩罚随着 $k$ 的增加而非线性地增长。$\\mathcal{M}_{2}$ 的校正项明显大于 $\\mathcal{M}_{1}$ 的校正项，这导致了偏好的逆转。\n\n现在，我们推导 $\\mathcal{M}_{2}$ 成为更优模型所需的对数似然值改进阈值 $\\Delta \\ln \\hat{L} = \\ln \\hat{L}_{2} - \\ln \\hat{L}_{1}$。\n\n对于 AIC，如果 $\\mathrm{AIC}_{2} < \\mathrm{AIC}_{1}$，则 $\\mathcal{M}_{2}$ 更优：\n$$ 2k_{2} - 2 \\ln \\hat{L}_{2} < 2k_{1} - 2 \\ln \\hat{L}_{1} $$\n$$ 2(\\ln \\hat{L}_{1} - \\ln \\hat{L}_{2}) < 2(k_{1} - k_{2}) $$\n$$ \\ln \\hat{L}_{2} - \\ln \\hat{L}_{1} > k_{2} - k_{1} $$\n给定 $k_{1}=20$ 和 $k_{2}=40$，阈值是：\n$$ \\Delta \\ln \\hat{L} > 40 - 20 = 20 $$\n观测到的改进量是 $\\ln \\hat{L}_{2} - \\ln \\hat{L}_{1} = -11213.5 - (-11234.5) = 21$。由于 $21 > 20$，根据 AIC，$\\mathcal{M}_{2}$ 确实更优。\n\n对于 AICc，如果 $\\mathrm{AICc}_{2} < \\mathrm{AICc}_{1}$，则 $\\mathcal{M}_{2}$ 更优：\n$$ \\mathrm{AIC}_{2} + \\frac{2k_{2}(k_{2}+1)}{n-k_{2}-1} < \\mathrm{AIC}_{1} + \\frac{2k_{1}(k_{1}+1)}{n-k_{1}-1} $$\n$$ (2k_{2} - 2 \\ln \\hat{L}_{2}) + \\frac{2k_{2}(k_{2}+1)}{n-k_{2}-1} < (2k_{1} - 2 \\ln \\hat{L}_{1}) + \\frac{2k_{1}(k_{1}+1)}{n-k_{1}-1} $$\n整理公式以求解 $\\Delta \\ln \\hat{L} = \\ln \\hat{L}_{2} - \\ln \\hat{L}_{1}$：\n$$ 2(\\ln \\hat{L}_{1} - \\ln \\hat{L}_{2}) < 2(k_{1}-k_{2}) + \\frac{2k_{1}(k_{1}+1)}{n-k_{1}-1} - \\frac{2k_{2}(k_{2}+1)}{n-k_{2}-1} $$\n$$ \\Delta \\ln \\hat{L} > (k_{2}-k_{1}) + \\frac{1}{2} \\left[ \\frac{2k_{2}(k_{2}+1)}{n-k_{2}-1} - \\frac{2k_{1}(k_{1}+1)}{n-k_{1}-1} \\right] $$\n$$ \\Delta \\ln \\hat{L} > (k_{2}-k_{1}) + \\frac{k_{2}(k_{2}+1)}{n-k_{2}-1} - \\frac{k_{1}(k_{1}+1)}{n-k_{1}-1} $$\n代入给定值：\n$$ \\Delta \\ln \\hat{L} > (40-20) + \\frac{40(41)}{800-40-1} - \\frac{20(21)}{800-20-1} $$\n$$ \\Delta \\ln \\hat{L} > 20 + \\frac{1640}{759} - \\frac{420}{779} $$\n$$ \\Delta \\ln \\hat{L} > 20 + 2.160737... - 0.539152... $$\n$$ \\Delta \\ln \\hat{L} > 20 + 1.621585... = 21.621585... $$\n观测到的改进量 $\\Delta \\ln \\hat{L} = 21$ 小于约 $21.62$ 的阈值。因此，根据 AICc，拟合度的提升不足以证明增加 $20$ 个参数是合理的，所以 $\\mathcal{M}_{1}$ 更优。\n\n**3) 计算 $\\Delta = \\mathrm{AICc}_{2} - \\mathrm{AICc}_{1}$**\n\n题目要求我们计算单一数值 $\\Delta = \\mathrm{AICc}_{2} - \\mathrm{AICc}_{1}$。\n$$ \\Delta = \\mathrm{AICc}_{2} - \\mathrm{AICc}_{1} = (22511.32147...) - (22510.07830...) = 1.24317... $$\n或者，这可以通过符号计算得出：\n$$ \\Delta = (2k_{2} - 2\\ln \\hat{L}_{2} + \\frac{2k_{2}(k_{2}+1)}{n-k_{2}-1}) - (2k_{1} - 2\\ln \\hat{L}_{1} + \\frac{2k_{1}(k_{1}+1)}{n-k_{1}-1}) $$\n$$ \\Delta = 2(k_{2}-k_{1}) - 2(\\ln \\hat{L}_{2} - \\ln \\hat{L}_{1}) + 2 \\left( \\frac{k_{2}(k_{2}+1)}{n-k_{2}-1} - \\frac{k_{1}(k_{1}+1)}{n-k_{1}-1} \\right) $$\n$$ \\Delta = 2(20) - 2(21) + 2 \\left( \\frac{1640}{759} - \\frac{420}{779} \\right) $$\n$$ \\Delta = 40 - 42 + 2(2.160737... - 0.539152...) $$\n$$ \\Delta = -2 + 2(1.621585...) = -2 + 3.24317... = 1.24317... $$\n四舍五入到四位有效数字，结果是 $1.243$。",
            "answer": "$$ \\boxed{1.243} $$"
        },
        {
            "introduction": "我们最后一个也是最高阶的练习将带您深入了解系统发育分析软件的内部工作原理。您将直接从几个经典替换模型（如 JC69、K80 和 F81）的数学定义出发，从零开始实现它们的似然函数。 通过亲手编写数值优化和 AIC 计算程序，您将对这些进化模型如何运作以及如何在统计学上进行比较，获得一种深刻且根本的理解，从而揭开自动化软件背后过程的神秘面纱。",
            "id": "2406832",
            "problem": "您需要从第一性原理出发，在一个简化的系统发育背景中，为核苷酸替换模型实现一个赤池信息准则 (AIC) 模型选择程序。任务是计算三种经典连续时间替换模型的最大对数似然，然后计算它们的 AIC 值，以便为每个测试用例选择最佳模型。这些模型是：Jukes-Cantor 1969 (JC69)、Kimura 2-参数 (K80) 和 Felsenstein 1981 (F81)。您将假设一个固定的有根星状系统发育树，其具有 $4$ 个叶节点和相同的分支长度。字母表为脱氧核糖核酸 (DNA) 的核苷酸 $\\{A,C,G,T\\}$。位点似然使用标准的连续时间马尔可夫链 (CTMC) 框架和针对星状拓扑特化的 Felsenstein 剪枝算法进行计算。最终程序必须为下面给出的测试套件生成结果。\n\n基本依据与假设：\n- 作用于 $\\{A,C,G,T\\}$ 上的连续时间马尔可夫链 (CTMC)，具有同质、时间可逆的动态特性。\n- 各位点沿着一个拥有 $4$ 个悬垂分支的有根星状树独立同分布地演化，每个分支的长度为 $t$（在给定的测试中，所有分支的 $t$ 值相同）。\n- 对于每个模型，沿着长度为 $t$ 的分支的转移概率由模型约束下的速率矩阵 $\\mathbf{Q}$ 的矩阵指数给出，且期望替换速率被归一化为每个单位时间 $1$ 次替换。平稳分布为 $\\boldsymbol{\\pi}$。\n- 根部分布等于平稳分布 $\\boldsymbol{\\pi}$。\n- 对每个模型的自由参数执行最大似然估计 (MLE)，同时在测试用例中保持分支长度 $t$ 固定。\n\n您必须实现：\n- 使用在星状树上的标准剪枝递归计算根部的位点似然。对于在叶节点上观测到核苷酸为 $(x_1,x_2,x_3,x_4)$ 的单个位点，其转移矩阵为 $\\mathbf{P}(t)$（元素为 $P_{ij}(t)$），根部先验概率为 $\\pi_i$，则位点似然为\n$$\n\\mathcal{L}_{\\text{site}} \\;=\\; \\sum_{i \\in \\{A,C,G,T\\}} \\pi_i \\prod_{\\ell=1}^{4} P_{i,\\,x_\\ell}(t).\n$$\n- 整个序列比对的对数似然是所有位点的 $\\log \\mathcal{L}_{\\text{site}}$ 之和。\n- 模型设定，速率归一化至单位期望速率：\n  - JC69：所有非对角线瞬时速率相等；平稳频率 $\\boldsymbol{\\pi}=(\\tfrac{1}{4},\\tfrac{1}{4},\\tfrac{1}{4},\\tfrac{1}{4})$；当 $t$ 固定时没有自由参数。\n  - K80：转换与颠换两个速率类别，转换/颠换速率比 $\\kappa$ 作为唯一的自由参数；平稳频率固定为各 $\\tfrac{1}{4}$；通过适当缩放瞬时速率，将期望速率归一化为 $1$。\n  - F81：非对角线速率与目标碱基频率成正比；自由参数是平稳频率 $\\boldsymbol{\\pi}=(\\pi_A,\\pi_C,\\pi_G,\\pi_T)$，需满足 $\\sum \\pi_i=1$ 和 $\\pi_i>0$ 的约束；通过一个全局标量将期望速率归一化为 $1$，使得 $-\\sum_i \\pi_i Q_{ii}=1$。\n- 对于每个模型，给定观测到的序列比对和分支长度 $t$，计算其自由参数下的最大对数似然 $\\ell_{\\max}$。然后使用赤池信息准则 (AIC) 的定义计算 AIC：对于一个有 $k$ 个自由参数的模型，\n$$\n\\mathrm{AIC} \\;=\\; 2k \\;-\\; 2 \\,\\ell_{\\max}.\n$$\n- 在此问题中，当 $t$ 在每个测试用例中固定时，参数数量 $k$ 为：JC69 有 $k=0$，K80 有 $k=1$（$\\kappa$ 参数），F81 有 $k=3$（因为 $\\sum \\pi_i=1$，所以有三个独立的平稳频率）。\n\n算法要求：\n- 实现跨位点数值稳定的对数似然累加。在需要时，对根状态求和使用 log-sum-exp 稳定化方法。\n- 对于 K80，对参数 $\\kappa > 0$ 执行一维数值优化。\n- 对于 F81，对 $\\boldsymbol{\\pi}$ 执行约束优化，您可以通过转换为无约束参数（例如，通过对 4 个分量使用 softmax 并固定一个参考值）并优化这些无约束参数来实现。\n\n需要推导和实现的精确模型要素：\n- JC69 的转移概率应从其期望速率为 $1$ 的 $\\mathbf{Q}$ 矩阵推导得出，从而得到仅含 $t$ 的 $P_{ii}(t)$ 和 $P_{ij}(t)$。\n- K80 的转移概率应在期望速率为 $1$ 的归一化条件下推导，其转换与颠换概率取决于 $\\kappa$ 和 $t$。\n- F81 的转移概率应从其具有平稳频率 $\\boldsymbol{\\pi}$ 和一个全局标量 $\\mu$ 的 $\\mathbf{Q}$ 矩阵推导得出，该标量 $\\mu$ 的选择需确保期望速率为 $1$。在 F81 模型下，\n$$\nQ_{ij} \\;=\\; \\mu\\, \\pi_j \\quad (i \\neq j), \\qquad Q_{ii} \\;=\\; - \\mu \\,(1-\\pi_i), \\qquad \\mu \\;=\\; \\frac{1}{1-\\sum_{i} \\pi_i^2}.\n$$\n然后\n$$\n\\mathbf{P}(t) \\;=\\; \\boldsymbol{\\Pi} \\;+\\; e^{-\\mu t}\\,(\\mathbf{I}-\\boldsymbol{\\Pi}), \\quad \\text{其中 } \\boldsymbol{\\Pi} \\text{ 的每一行都等于 } \\boldsymbol{\\pi}.\n$$\n\n测试套件：\n实现您的程序以评估以下 $4$ 个测试用例。在每个案例中，星状树有 $4$ 个叶节点，按顺序标记为分类单元 $1$ 至 $4$，并具有固定的分支长度 $t$（所有 $4$ 个悬垂分支的 $t$ 值相同）。每个序列比对都以 $4$ 个等长的 $\\{A,C,G,T\\}$ 序列形式给出，每个分类单元一个，按列对齐。\n\n- 案例 $1$（平衡的组成，混合的变化；预期简约法不会支持转换偏好；中等分支长度）：\n  - 分支长度 $t = 0.5$。\n  - 长度为 $16$ 的序列按列指定；对于分类单元 $\\{1,2,3,4\\}$，这 $16$ 个位点列是：\n    $[AAAA, CCCC, GGGG, TTTT, AAGG, GGAA, CCTT, TTCC, AACC, CCAA, GGTT, TTGG, ACTG, AGCT, ATAT, CGCG]$。\n- 案例 $2$（强转换偏好，总体组成平衡；中等分支长度）：\n  - 分支长度 $t = 0.5$。\n  - 长度为 $24$ 的序列指定为 $4$ 个区块：\n    - 不变区块：$[AAAA, CCCC, GGGG, TTTT]$，\n    - A/G 转换区块重复 $5$ 次：$[AAGG, GGAA]$ 重复 $5$ 次，\n    - C/T 转换区块重复 $5$ 次：$[CCTT, TTCC]$ 重复 $5$ 次。\n- 案例 $3$（强碱基组成偏斜，偏向 $A$；中等分支长度；长序列比对，因此频率拟合很重要）：\n  - 分支长度 $t = 0.5$。\n  - 长度为 $60$ 的序列通过连接区块定义：\n    - 分类单元 $1$ 和 $2$：$45$ 个 $A$，然后 $5$ 个 $G$，然后 $10$ 个 $A$。\n    - 分类单元 $3$ 和 $4$：$40$ 个 $A$，然后 $5$ 个 $G$，然后 $5$ 个 $A$，然后 $5$ 个 $C$，然后 $5$ 个 $T$。\n- 案例 $4$（近零分支长度边界；所有分类单元序列相同；由模型惩罚项主导）：\n  - 分支长度 $t = 0.001$。\n  - 所有 $4$ 个分类单元都具有相同的长度为 $12$ 的序列：字符串 $ACGTACGTACGT$。\n\n单位与数值约定：\n- 没有物理单位；分支长度 $t$ 是无量纲的，以每个位点的期望替换数计量，因为根据构造，期望速率为 $1$。\n- 不涉及角度。\n- 概率应以小数处理；不要使用百分比。\n\n最终输出格式：\n- 对于每个测试用例，计算 JC69、K80 和 F81 的 AIC，并选择 AIC 最小的模型。将模型编码为整数：JC69 $\\to$ 0, K80 $\\to$ 1, F81 $\\to$ 2。\n- 您的程序应生成单行输出，其中包含一个逗号分隔的整数列表，并用方括号括起来，例如，对于四个案例按顺序的结果为 $[0,1,2,0]$。\n\n您的程序必须是一个完整的、可运行的程序，不读取任何输入，并严格按照指定格式写入一行输出。程序必须如上所述从头实现似然和优化算法，并且不得调用任何外部系统发育学软件。",
            "solution": "用户提供了一个在计算系统发育学领域中定义明确且科学上合理的问题。该问题是有效的，因为它基于分子进化的既定原理，在数学和算法上是适定的，并且以客观明确的方式呈现。它要求为三种经典的核苷酸替换模型——Jukes-Cantor $1969$ (JC69)、Kimura $1980$ (K80) 和 Felsenstein $1981$ (F81)——实现一个使用赤池信息准则 (AIC) 的标准模型选择程序。所有必要的组成部分，包括数据、系统发育树结构、数学公式和评估标准，都已提供。\n\n解决方案将遵循系统的、第一性原理的方法来构建。首先，将建立在连续时间马尔可夫链框架下进行似然计算的核心机制。然后，将为三种模型中的每一种开发具体的实现，接着进行数值优化以找到具有自由参数的模型的最大对数似然（$\\ell_{\\max}$）。最后，将计算每个模型的 AIC 值，并用它来为每个测试用例选择最拟合的模型。\n\n对于给定的模型，数据的似然是逐个位点计算，然后进行组合。系统发育树是一个有根的星状拓扑，有四个叶节点和相同的分支长度 $t$。根部被假定处于替换过程的平稳分布 $\\boldsymbol{\\pi}$ 中。对于在叶节点上观测到核苷酸为 $(x_1, x_2, x_3, x_4)$ 的单个位点，位点似然由 Felsenstein 的剪枝算法给出，对于此拓扑，该算法简化为：\n$$\n\\mathcal{L}_{\\text{site}} = \\sum_{i \\in \\{A,C,G,T\\}} \\pi_i \\prod_{\\ell=1}^{4} P_{i,x_\\ell}(t)\n$$\n其中 $\\pi_i$ 是祖先核苷酸 $i$ 的平稳频率，而 $P_{i,x_\\ell}(t)$ 是沿着长度为 $t$ 的分支从核苷酸 $i$ 转移到 $x_\\ell$ 的概率。一个序列比对的总对数似然是单个位点对数似然的总和：$\\ell = \\sum_{\\text{sites}} \\log(\\mathcal{L}_{\\text{site}})$。为了处理数值下溢并保持精度，此计算使用 log-sum-exp 变换来执行：\n$$\n\\log(\\mathcal{L}_{\\text{site}}) = \\mathrm{logsumexp}_{i} \\left( \\log(\\pi_i) + \\sum_{\\ell=1}^4 \\log(P_{i,x_\\ell}(t)) \\right)\n$$\n问题规定，对于每个模型，瞬时速率矩阵 $\\mathbf{Q}$ 都被缩放，以使每个位点每个单位时间的期望替换数为 $1$。这由条件 $-\\sum_i \\pi_i Q_{ii} = 1$ 表示。\n\n三种模型的实现如下：\n\n1.  **Jukes-Cantor 1969 (JC69)**：这是最简单的模型。它假设碱基频率相等（$\\pi_A=\\pi_C=\\pi_G=\\pi_T=1/4$）并且所有替换类型只有单一速率。速率归一化条件 $3\\alpha=1$（其中 $\\alpha$ 是非对角线速率）意味着速率矩阵的特征值导致以下对于长度为 $t$ 的分支的转移概率：\n    $$\n    \\begin{aligned}\n    P_{ii}(t) &= \\frac{1}{4} + \\frac{3}{4}e^{-\\frac{4}{3}t} \\\\\n    P_{ij}(t) &= \\frac{1}{4} - \\frac{1}{4}e^{-\\frac{4}{3}t} \\quad (i \\neq j)\n    \\end{aligned}\n    $$\n    由于每个测试用例的分支长度 $t$ 是固定的，JC69 模型没有自由参数。因此，参数计数为 $k=0$。\n\n2.  **Kimura 1980 (K80)**：该模型区分了转换（嘌呤-嘌呤或嘧啶-嘧啶的改变，速率为 $\\alpha$）和颠换（嘌呤-嘧啶的改变，速率为 $\\beta$）。碱基频率假定相等（$\\pi_i=1/4$）。唯一的自由参数是转换/颠换速率比，$\\kappa = \\alpha/\\beta$。在我们的参数化下，速率归一化条件要求 $(\\alpha + 2\\beta) = 1$，得出 $\\alpha = \\kappa / (\\kappa+2)$ 和 $\\beta = 1/(\\kappa+2)$。转移概率为：\n    $$\n    \\begin{aligned}\n    P_{ii}(t) &= \\frac{1}{4} + \\frac{1}{4}e^{-4\\beta t} + \\frac{1}{2}e^{-2(\\alpha+\\beta)t} \\\\\n    P_{ij}(t, \\text{transition}) &= \\frac{1}{4} + \\frac{1}{4}e^{-4\\beta t} - \\frac{1}{2}e^{-2(\\alpha+\\beta)t} \\\\\n    P_{ij}(t, \\text{transversion}) &= \\frac{1}{4} - \\frac{1}{4}e^{-4\\beta t}\n    \\end{aligned}\n    $$\n    通过对单一参数 $\\kappa > 0$ 进行数值优化来找到最大对数似然。参数计数为 $k=1$。\n\n3.  **Felsenstein 1981 (F81)**：该模型允许不相等的碱基频率 $\\boldsymbol{\\pi} = (\\pi_A, \\pi_C, \\pi_G, \\pi_T)$，这些频率被视为受约束 $\\sum_i \\pi_i = 1$ 的自由参数。替换速率取决于目标碱基的频率。模型的速率矩阵 $\\mathbf{Q}$ 和转移矩阵 $\\mathbf{P}(t)$ 在问题陈述中给出，通过因子 $\\mu = 1 / (1 - \\sum_i \\pi_i^2)$ 实现速率归一化。得到的转移概率为：\n    $$\n    \\begin{aligned}\n    P_{ii}(t) &= \\pi_i + (1 - \\pi_i)e^{-\\mu t} \\\\\n    P_{ij}(t) &= \\pi_j(1 - e^{-\\mu t}) \\quad (i \\neq j)\n    \\end{aligned}\n    $$\n    由于 $\\sum_i \\pi_i = 1$，存在 $3$ 个独立的频率。因此，参数计数为 $k=3$。通过对这三个参数进行优化来找到最大对数似然。这个约束优化问题通过使用 softmax 变换对单纯形进行重参数化来解决，从而能够使用无约束优化算法。\n\n对于每个模型和测试用例，确定最大对数似然 $\\ell_{\\max}$。然后计算赤池信息准则：\n$$\n\\mathrm{AIC} = 2k - 2\\ell_{\\max}\n$$\nAIC 值最低的模型被选为数据的最佳拟合模型。整个过程被封装在一个 Python 程序中，使用 `numpy` 和 `scipy` 库进行数值计算和优化。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize, minimize_scalar\nfrom scipy.special import logsumexp\nfrom collections import Counter\n\n# Define a mapping from nucleotides to indices for matrix operations.\nNUC_MAP = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n\ndef process_alignment_cols(cols):\n    \"\"\"\n    Processes a list of alignment column strings into a Counter of site patterns.\n    Each pattern is a tuple of nucleotide indices.\n    \"\"\"\n    site_patterns = [\"\".join(sorted(col)) + \":\" + col for col in cols]\n    \n    counts = Counter()\n    for col_str in cols:\n        indices = tuple(NUC_MAP[nuc] for nuc in col_str)\n        counts[indices] += 1\n    return counts\n\ndef calculate_log_likelihood(site_counts, P, pi):\n    \"\"\"\n    Calculates the total log-likelihood for an alignment given site pattern counts,\n    a transition probability matrix P, and stationary frequencies pi.\n    This implementation is numerically stable, using the log-sum-exp trick.\n    \"\"\"\n    total_log_L = 0.0\n    \n    # Pre-calculate logs to avoid repeated computations inside the loop\n    # Add a small epsilon to prevent log(0) if any probability is exactly zero.\n    log_P = np.log(P + 1e-300)\n    log_pi = np.log(pi + 1e-300)\n\n    for site_indices, count in site_counts.items():\n        # For each ancestral state i, calculate log(P(path | ancestor=i))\n        # This is sum_{leaves l} log(P_{i, x_l})\n        sum_log_probs_over_leaves = (log_P[:, site_indices[0]] +\n                                     log_P[:, site_indices[1]] +\n                                     log_P[:, site_indices[2]] +\n                                     log_P[:, site_indices[3]])\n\n        # Combine with root probability log(pi_i)\n        terms = log_pi + sum_log_probs_over_leaves\n        \n        # Sum over all possible ancestral states i in log-space\n        site_log_L = logsumexp(terms)\n        \n        total_log_L += count * site_log_L\n    \n    return total_log_L\n\n# --- Model-specific implementations ---\n\ndef get_aic_jc69(t, site_counts):\n    \"\"\"Computes AIC for the JC69 model.\"\"\"\n    k = 0\n    pi = np.array([0.25, 0.25, 0.25, 0.25])\n    \n    p_diag = 0.25 + 0.75 * np.exp(-4.0/3.0 * t)\n    p_offdiag = 0.25 - 0.25 * np.exp(-4.0/3.0 * t)\n    \n    P = np.full((4, 4), p_offdiag)\n    np.fill_diagonal(P, p_diag)\n\n    log_L = calculate_log_likelihood(site_counts, P, pi)\n    aic = 2 * k - 2 * log_L\n    return aic\n\ndef get_aic_k80(t, site_counts):\n    \"\"\"Computes AIC for the K80 model via optimization.\"\"\"\n    k = 1\n    pi = np.array([0.25, 0.25, 0.25, 0.25])\n    \n    is_transition_matrix = np.array([\n        [0, 0, 1, 0],  # A -> G\n        [0, 0, 0, 1],  # C -> T\n        [1, 0, 0, 0],  # G -> A\n        [0, 1, 0, 0],  # T -> C\n    ])\n\n    def objective_fn(kappa):\n        if kappa <= 0:\n            return np.inf\n\n        beta = 1.0 / (kappa + 2.0)\n        alpha = kappa * beta\n        \n        e1 = np.exp(-4.0 * beta * t)\n        e2 = np.exp(-2.0 * (alpha + beta) * t)\n\n        p_identity = 0.25 + 0.25 * e1 + 0.5 * e2\n        p_transition = 0.25 + 0.25 * e1 - 0.5 * e2\n        p_transversion = 0.25 - 0.25 * e1\n\n        P = np.full((4, 4), p_transversion)\n        P[is_transition_matrix == 1] = p_transition\n        np.fill_diagonal(P, p_identity)\n        \n        log_L = calculate_log_likelihood(site_counts, P, pi)\n        return -log_L # Return negative log-likelihood for minimization\n\n    # Optimize over kappa > 0\n    res = minimize_scalar(objective_fn, bounds=(1e-9, 100), method='bounded')\n    max_log_L = -res.fun\n    \n    aic = 2 * k - 2 * max_log_L\n    return aic\n\ndef get_aic_f81(t, site_counts):\n    \"\"\"Computes AIC for the F81 model via optimization.\"\"\"\n    k = 3\n    \n    def objective_fn(params):\n        # Softmax transformation from 3 unconstrained params to a 4-dim probability vector pi\n        # Fix one parameter to 0 for identifiability.\n        unconstrained_params = np.concatenate(([0], params))\n        exp_params = np.exp(unconstrained_params)\n        pi = exp_params / np.sum(exp_params)\n        \n        if np.any(pi < 1e-9): # Avoid extreme frequencies\n            return np.inf\n\n        mu = 1.0 / (1.0 - np.sum(pi**2))\n        \n        exp_mut = np.exp(-mu * t)\n        \n        # Build P matrix\n        p_offdiag_term = 1.0 - exp_mut\n        P = np.outer(np.ones(4), pi) * p_offdiag_term\n        np.fill_diagonal(P, pi + (1 - pi) * exp_mut)\n\n        log_L = calculate_log_likelihood(site_counts, P, pi)\n        return -log_L\n\n    # Initial guess corresponds to uniform frequencies\n    initial_params = np.array([0.0, 0.0, 0.0])\n    res = minimize(objective_fn, initial_params, method='L-BFGS-B')\n    max_log_L = -res.fun\n    \n    aic = 2 * k - 2 * max_log_L\n    return aic\n\ndef solve():\n    \"\"\"Main function to run the analysis for all test cases.\"\"\"\n    \n    # Test Case 1\n    case1_t = 0.5\n    case1_cols = \"AAAA,CCCC,GGGG,TTTT,AAGG,GGAA,CCTT,TTCC,AACC,CCAA,GGTT,TTGG,ACTG,AGCT,ATAT,CGCG\".split(',')\n    \n    # Test Case 2\n    case2_t = 0.5\n    case2_cols = (['AAAA', 'CCCC', 'GGGG', 'TTTT'] + \n                  ['AAGG', 'GGAA'] * 5 + \n                  ['CCTT', 'TTCC'] * 5)\n\n    # Test Case 3\n    case3_t = 0.5\n    s1 = 'A'*45 + 'G'*5 + 'A'*10\n    s2 = 'A'*45 + 'G'*5 + 'A'*10\n    s3 = 'A'*40 + 'G'*5 + 'A'*5 + 'C'*5 + 'T'*5\n    s4 = 'A'*40 + 'G'*5 + 'A'*5 + 'C'*5 + 'T'*5\n    case3_cols = [''.join(site) for site in zip(s1, s2, s3, s4)]\n\n    # Test Case 4\n    case4_t = 0.001\n    s_ident = 'ACGTACGTACGT'\n    case4_cols = [''.join(site) for site in zip(s_ident, s_ident, s_ident, s_ident)]\n\n    test_cases = [\n        (case1_t, case1_cols),\n        (case2_t, case2_cols),\n        (case3_t, case3_cols),\n        (case4_t, case4_cols),\n    ]\n\n    results = []\n    \n    model_mapping = {0: 'JC69', 1: 'K80', 2: 'F81'}\n    model_funcs = [get_aic_jc69, get_aic_k80, get_aic_f81]\n    \n    for i, (t, cols) in enumerate(test_cases):\n        site_counts = process_alignment_cols(cols)\n        \n        aic_values = []\n        for func in model_funcs:\n            aic_values.append(func(t, site_counts))\n        \n        best_model_idx = np.argmin(aic_values)\n        results.append(best_model_idx)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}