{
    "hands_on_practices": [
        {
            "introduction": "第一个练习是连接生物学规则与马尔可夫链数学形式的桥梁。你将为一个假设的、在嘌呤和嘧啶之间严格交替的DNA序列构建转移矩阵，这是一种常见的结构基序。通过计算其熵率（entropy rate），你将亲身体验如何量化序列模型的可预测性和信息含量。",
            "id": "2402072",
            "problem": "一个基于核苷酸字母表 $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 的脱氧核糖核酸(DNA)序列被建模为一个一阶马尔可夫链，该模型具有以下生物学约束：序列在嘌呤 $\\{\\mathrm{A},\\mathrm{G}\\}$ 和嘧啶 $\\{\\mathrm{C},\\mathrm{T}\\}$ 之间完美交替。每当当前核苷酸是嘌呤时，下一个核苷酸从嘧啶中均匀随机选择；每当当前核苷酸是嘧啶时，下一个核苷酸从嘌呤中均匀随机选择。不遵守这种交替规则的转移概率为 $0$。假设初始分布等于该链唯一的平稳分布。\n\n使用有序状态空间 $(\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T})$，写出编码这些规则的转移矩阵 $P$。然后，使用平稳一阶马尔可夫链的香农熵率定义，用自然对数确定此过程的熵率 $H$。以奈特为单位表示最终答案。最终答案必须是单一的闭式表达式，无需四舍五入。",
            "solution": "设状态空间为 $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$，其有序索引为 $(\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T})$。生物学约束规定，从任何一个嘌呤（状态 $\\mathrm{A}$ 或 $\\mathrm{G}$）出发，下一个状态必须是均匀选择的一个嘧啶（状态 $\\mathrm{C}$ 或 $\\mathrm{T}$）；从任何一个嘧啶（状态 $\\mathrm{C}$ 或 $\\mathrm{T}$）出发，下一个状态必须是均匀选择的一个嘌呤（状态 $\\mathrm{A}$ 或 $\\mathrm{G}$）。因此，对于任何嘌呤状态 $i \\in \\{\\mathrm{A},\\mathrm{G}\\}$ 和嘧啶状态 $j \\in \\{\\mathrm{C},\\mathrm{T}\\}$，转移概率为 $P_{ij}=\\frac{1}{2}$；而如果 $i$ 和 $j$ 同为嘌呤或同为嘧啶，则 $P_{ij}=0$。在排序 $(\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T})$ 下，将其写成矩阵 $P$ 形式，我们得到\n$$\nP \\;=\\;\n\\begin{pmatrix}\n0 & \\tfrac{1}{2} & 0 & \\tfrac{1}{2} \\\\\n\\tfrac{1}{2} & 0 & \\tfrac{1}{2} & 0 \\\\\n0 & \\tfrac{1}{2} & 0 & \\tfrac{1}{2} \\\\\n\\tfrac{1}{2} & 0 & \\tfrac{1}{2} & 0\n\\end{pmatrix}.\n$$\n我们验证每一行的和都为 $1$，因此 $P$ 是一个有效的转移矩阵。\n\n接下来，我们确定平稳分布 $\\pi$。根据嘌呤之间、嘧啶之间以及转移结构的对称性，平稳分布是均匀的：$\\pi_{\\mathrm{A}}=\\pi_{\\mathrm{C}}=\\pi_{\\mathrm{G}}=\\pi_{\\mathrm{T}}=\\frac{1}{4}$。通过直接乘法可以验证 $\\pi P=\\pi$。\n\n对于一个具有平稳分布 $\\pi$ 和转移概率 $P$ 的平稳一阶马尔可夫链，其香农熵率（以奈特为单位）定义为\n$$\nH \\;=\\; -\\sum_{i} \\pi_{i} \\sum_{j} P_{ij} \\ln P_{ij}.\n$$\n在当前链中，每一行 $i$ 恰好有两个非零的转移概率，且均等于 $\\tfrac{1}{2}$。因此，对于任何状态 $i$，\n$$\n\\sum_{j} P_{ij} \\ln P_{ij} \\;=\\; \\tfrac{1}{2}\\ln\\!\\big(\\tfrac{1}{2}\\big) \\;+\\; \\tfrac{1}{2}\\ln\\!\\big(\\tfrac{1}{2}\\big)\n\\;=\\; \\ln\\!\\big(\\tfrac{1}{2}\\big).\n$$\n代入熵率公式，\n$$\nH \\;=\\; -\\sum_{i} \\pi_{i}\\,\\ln\\!\\big(\\tfrac{1}{2}\\big)\n\\;=\\; -\\ln\\!\\big(\\tfrac{1}{2}\\big)\\,\\sum_{i}\\pi_{i}\n\\;=\\; -\\ln\\!\\big(\\tfrac{1}{2}\\big)\n\\;=\\; \\ln 2.\n$$\n因此，这个嘌呤-嘧啶交替的马尔可夫链的熵率是 $\\ln 2$ 奈特。",
            "answer": "$$\\boxed{\\ln 2}$$"
        },
        {
            "introduction": "从真实数据建模常常会遇到挑战，特别是当数据稀疏或重复时。这个思想实验探讨了当你在一个完美的串联重复序列上训练马尔可夫模型时会发生什么，这种情况放大了最大似然估计（Maximum Likelihood Estimation, MLE）的问题。通过分析伪计数（pseudocounts）的影响，你将理解一种构建更稳健、更具泛化能力的序列模型的关键技术。",
            "id": "2402066",
            "problem": "考虑一个基于字母表 $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 的脱氧核糖核酸（DNA）序列。您在一个由基序 $\\mathrm{CAG}$ 重复 $n$ 次（其中 $n \\ge 2$ 为整数）拼接而成的单一线性训练字符串 $s = (\\mathrm{CAG})^n$ 上训练一个一阶马尔可夫链。您从左到右计算相邻对 $(x_i,x_{i+1})$，并且在字符串末尾不进行环绕。您通过最大似然估计（MLE）来估算转移概率，即对于每个前驱符号 $x$，转移矩阵的行是通过对跟随 $x$ 的后继符号 $y$ 的观测计数进行归一化得到的，以使该行中的概率总和为 $1$。在第二种情况下，您应用强度为 $\\alpha>0$ 的对称狄利克雷伪计数，方法是在对每行进行重新归一化以使其总和为 $1$ 之前，为每个固定的前驱 $x$，将 $\\alpha$ 加到每个可能的转移 $x\\to y$ 的计数上。\n\n哪种说法最能描述这种设定下，在有和没有伪计数的情况下估算出的转移概率？\n\nA. 在对 $s=(\\mathrm{CAG})^n$ 进行最大似然估计时，唯一观测到的转移是 $\\mathrm{C}\\to\\mathrm{A}$、$\\mathrm{A}\\to\\mathrm{G}$ 和 $\\mathrm{G}\\to\\mathrm{C}$，它们在各自的行中（对于至少有一个观测到的前驱的行）被估计的概率均为 $1$，而这些行中所有其他转移概率均为 $0$；$\\mathrm{T}$ 的行是不可估计的，因为 $\\mathrm{T}$ 从未作为前驱出现。在使用强度为 $\\alpha>0$ 的对称狄利克雷伪计数时，每一行都变得有明确定义且概率严格为正，并且对于每个前驱 $x$ 和后继 $y$，平滑后的估计形式为 $(N_{xy}+\\alpha)/(N_x+4\\alpha)$，其中 $N_{xy}$ 是 $x \\to y$ 的观测计数，$N_x$ 是 $x$ 被观测为有后继的总次数。当 $n$ 很大时，三个观测到的循环转移概率接近于 $1$，但对于任何有限的 $n$ 都严格小于 $1$，并且所有之前未观测到的转移概率都变得很小但不为零；当 $n\\to\\infty$ 时，对于 $\\mathrm{C}\\to\\mathrm{A}$、$\\mathrm{A}\\to\\mathrm{G}$ 和 $\\mathrm{G}\\to\\mathrm{C}$ 的平滑估计收敛到 $1$。\n\nB. 在对 $s=(\\mathrm{CAG})^n$ 进行最大似然估计时，平稳分布在 $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 上是均匀的，因为每个核苷酸出现的频率相等，而与转移结构无关，并且伪计数只影响平稳分布，而转移概率保持不变。\n\nC. 伪计数只将零转移概率替换为小的正值，但不会改变任何已经等于 $1$ 的转移概率；因此，在平滑处理后，$\\mathrm{C}\\to\\mathrm{A}$、$\\mathrm{A}\\to\\mathrm{G}$ 和 $\\mathrm{G}\\to\\mathrm{C}$ 的概率仍然恰好为 $1$。\n\nD. 在对 $s=(\\mathrm{CAG})^n$ 进行最大似然估计时，状态 $\\mathrm{C}$、$\\mathrm{A}$ 和 $\\mathrm{G}$ 是吸收态，因为它们只转移到自身，并且伪计数通过强制转移矩阵在所有 $16$ 种可能的转移上均匀分布来移除这些吸收态。",
            "solution": "该问题陈述已经过验证，具有科学依据，问题提出得当且客观。它呈现了一个训练一阶马尔可夫链的标准理论练习，这是计算生物学中的一个基本课题。所有术语都有明确的定义，前提条件也是一致的。我们可以开始解题。\n\n问题要求分析从 DNA 序列 $s = (\\mathrm{CAG})^n$（其中 $n \\ge 2$ 为整数）在两种不同的估计方案下估算出的转移概率：最大似然估计（MLE）和带有对称狄利克雷伪计数的 MLE。字母表为 $\\mathcal{A} = \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$。\n\n首先，我们分析训练字符串 $s$ 的结构以确定转移计数。该字符串是 $s = \\mathrm{CAGCAG...CAG}$，是基序 $\\mathrm{CAG}$ 重复 $n$ 次的拼接。字符串的长度为 $3n$。我们计算相邻对 $(x_i, x_{i+1})$，其中 $i = 1, \\dots, 3n-1$。\n\n设 $N_{xy}$ 是核苷酸 $x$ 后面跟着核苷酸 $y$ 的次数。设 $N_x = \\sum_{y \\in \\mathcal{A}} N_{xy}$ 是 $x$ 作为前驱出现的总次数。\n\n对于序列 $s = (\\mathrm{CAG})^n$：\n- 转移 $\\mathrm{C}\\to\\mathrm{A}$ 发生在 $\\mathrm{C}$ 位于位置 $3k-2$ 时（$k=1, \\dots, n$）。这涵盖了所有 $\\mathrm{C}$ 作为前驱的情况。因此，$N_C = n$ 且 $N_{CA} = n$。所有其他计数 $N_{Cy}$ 均为 $0$。\n- 转移 $\\mathrm{A}\\to\\mathrm{G}$ 发生在 $\\mathrm{A}$ 位于位置 $3k-1$ 时（$k=1, \\dots, n$）。这涵盖了所有 $\\mathrm{A}$ 作为前驱的情况。因此，$N_A = n$ 且 $N_{AG} = n$。所有其他计数 $N_{Ay}$ 均为 $0$。\n- 转移 $\\mathrm{G}\\to\\mathrm{C}$ 发生在 $\\mathrm{G}$ 位于位置 $3k$ 时（$k=1, \\dots, n-1$）。最后一个位于位置 $3n$ 的 $\\mathrm{G}$ 在字符串的末尾，不是一个前驱。这涵盖了所有 $\\mathrm{G}$ 作为前驱的情况。因此，$N_G = n-1$ 且 $N_{GC} = n-1$。所有其他计数 $N_{Gy}$ 均为 $0$。条件 $n \\ge 2$ 保证了 $N_G \\ge 1$。\n- 核苷酸 $\\mathrm{T}$ 从未在序列中出现，所以对于所有 $y \\in \\mathcal{A}$，有 $N_T=0$ 和 $N_{Ty}=0$。\n\n**情况1：最大似然估计 (MLE)**\n\n转移概率 $P(y|x)$ 的MLE由计数比率给出：$P(y|x) = \\frac{N_{xy}}{N_x}$。\n\n- **行 C (从 C):** $N_C=n$。\n  $P(\\mathrm{A}|\\mathrm{C}) = \\frac{N_{CA}}{N_C} = \\frac{n}{n} = 1$。\n  $P(\\mathrm{C}|\\mathrm{C}) = P(\\mathrm{G}|\\mathrm{C}) = P(\\mathrm{T}|\\mathrm{C}) = 0$。\n- **行 A (从 A):** $N_A=n$。\n  $P(\\mathrm{G}|\\mathrm{A}) = \\frac{N_{AG}}{N_A} = \\frac{n}{n} = 1$。\n  $P(\\mathrm{A}|\\mathrm{A}) = P(\\mathrm{C}|\\mathrm{A}) = P(\\mathrm{T}|\\mathrm{A}) = 0$。\n- **行 G (从 G):** $N_G=n-1$。由于 $n \\ge 2$，所以 $N_G \\ge 1$。\n  $P(\\mathrm{C}|\\mathrm{G}) = \\frac{N_{GC}}{N_G} = \\frac{n-1}{n-1} = 1$。\n  $P(\\mathrm{A}|\\mathrm{G}) = P(\\mathrm{G}|\\mathrm{G}) = P(\\mathrm{T}|\\mathrm{G}) = 0$。\n- **行 T (从 T):** $N_T=0$。分母为零，所以从 $\\mathrm{T}$ 开始的转移概率无法从数据中估计。\n\n因此，MLE转移矩阵 $P_{MLE}$ 是（用`u`表示未定义）：\n$$\nP_{MLE} = \\begin{pmatrix}\n  P(A|A) & P(C|A) & P(G|A) & P(T|A) \\\\\n  P(A|C) & P(C|C) & P(G|C) & P(T|C) \\\\\n  P(A|G) & P(C|G) & P(G|G) & P(T|G) \\\\\n  P(A|T) & P(C|T) & P(G|T) & P(T|T)\n \\end{pmatrix}\n =\n \\begin{pmatrix}\n  0 & 0 & 1 & 0 \\\\\n  1 & 0 & 0 & 0 \\\\\n  0 & 1 & 0 & 0 \\\\\n  u & u & u & u\n \\end{pmatrix}\n$$\n（假设行序为 A, C, G, T）。\n\n**情况2：对称狄利克雷伪计数**\n\n对于强度为 $\\alpha > 0$ 的对称狄利克雷先验，我们将一个伪计数 $\\alpha$ 加到每个转移计数 $N_{xy}$ 上。平滑后的概率 $P_{\\alpha}(y|x)$ 是：\n$$ P_{\\alpha}(y|x) = \\frac{N_{xy} + \\alpha}{N_x + k\\alpha} $$\n其中 $k$ 是字母表的大小，即 $k=4$。\n\n- **行 C (从 C):** $N_C=n$。\n  $P_{\\alpha}(\\mathrm{A}|\\mathrm{C}) = \\frac{N_{CA}+\\alpha}{N_C+4\\alpha} = \\frac{n+\\alpha}{n+4\\alpha}$。\n  $P_{\\alpha}(\\mathrm{C}|\\mathrm{C}) = P_{\\alpha}(\\mathrm{G}|\\mathrm{C}) = P_{\\alpha}(\\mathrm{T}|\\mathrm{C}) = \\frac{0+\\alpha}{n+4\\alpha} = \\frac{\\alpha}{n+4\\alpha}$。\n- **行 A (从 A):** $N_A=n$。\n  $P_{\\alpha}(\\mathrm{G}|\\mathrm{A}) = \\frac{N_{AG}+\\alpha}{N_A+4\\alpha} = \\frac{n+\\alpha}{n+4\\alpha}$。\n  $P_{\\alpha}(\\mathrm{A}|\\mathrm{A}) = P_{\\alpha}(\\mathrm{C}|\\mathrm{A}) = P_{\\alpha}(\\mathrm{T}|\\mathrm{A}) = \\frac{\\alpha}{n+4\\alpha}$。\n- **行 G (从 G):** $N_G=n-1$。\n  $P_{\\alpha}(\\mathrm{C}|\\mathrm{G}) = \\frac{N_{GC}+\\alpha}{N_G+4\\alpha} = \\frac{n-1+\\alpha}{n-1+4\\alpha}$。\n  $P_{\\alpha}(\\mathrm{A}|\\mathrm{G}) = P_{\\alpha}(\\mathrm{G}|\\mathrm{G}) = P_{\\alpha}(\\mathrm{T}|\\mathrm{G}) = \\frac{\\alpha}{n-1+4\\alpha}$。\n- **行 T (从 T):** $N_T=0$。\n  $P_{\\alpha}(y|\\mathrm{T}) = \\frac{N_{Ty}+\\alpha}{N_T+4\\alpha} = \\frac{0+\\alpha}{0+4\\alpha} = \\frac{1}{4}$ 对于所有 $y \\in \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$。\n\n使用伪计数后，每个转移概率都严格为正。对于观测到的转移 $\\mathrm{C}\\to\\mathrm{A}$、$\\mathrm{A}\\to\\mathrm{G}$ 和 $\\mathrm{G}\\to\\mathrm{C}$，其概率对于任何有限的 $n$ 和 $\\alpha > 0$ 都严格小于 $1$。例如，$\\frac{n+\\alpha}{n+4\\alpha} = 1 - \\frac{3\\alpha}{n+4\\alpha} < 1$。当 $n \\to \\infty$ 时，这些概率趋近于 $1$。例如，$\\lim_{n \\to \\infty} \\frac{n+\\alpha}{n+4\\alpha} = \\lim_{n \\to \\infty} \\frac{1+\\alpha/n}{1+4\\alpha/n} = 1$。\n\n现在，我们来评估给出的选项。\n\n**选项 A:**\n- *\"在对 $s=(\\mathrm{CAG})^n$ 进行最大似然估计时，唯一观测到的转移是 $\\mathrm{C}\\to\\mathrm{A}$、$\\mathrm{A}\\to\\mathrm{G}$ 和 $\\mathrm{G}\\to\\mathrm{C}$，它们在各自的行中（对于至少有一个观测到的前驱的行）被估计的概率均为 $1$，而这些行中所有其他转移概率均为 $0$。\"* 这是正确的，如上所述。\n- *\"$\\mathrm{T}$ 的行是不可估计的，因为 $\\mathrm{T}$ 从未作为前驱出现。\"* 这是正确的。\n- *\"在使用强度为 $\\alpha>0$ 的对称狄利克雷伪计数时，每一行都变得有明确定义且概率严格为正，...\"* 这是正确的。分母变为 $N_x+4\\alpha > 0$，分子变为 $N_{xy}+\\alpha > 0$。\n- *\"...对于每个前驱 $x$ 和后继 $y$，平滑后的估计形式为 $(N_{xy}+\\alpha)/(N_x+4\\alpha)$，其中 $N_{xy}$ 是 $x \\to y$ 的观测计数，$N_x$ 是 $x$ 被观测为有后继的总次数。\"* 这是此类平滑处理的正确公式。\n- *\"当 $n$ 很大时，三个观测到的循环转移概率接近于 $1$，但对于任何有限的 $n$ 都严格小于 $1$，并且所有之前未观测到的转移概率都变得很小但不为零。\"* 这是正确的。\n- *\"当 $n\\to\\infty$ 时，对于 $\\mathrm{C}\\to\\mathrm{A}$、$\\mathrm{A}\\to\\mathrm{G}$ 和 $\\mathrm{G}\\to\\mathrm{C}$ 的平滑估计收敛到 $1$。\"* 这也是正确的。\n结论：**正确**。\n\n**选项 B:**\n- *\"在对 $s=(\\mathrm{CAG})^n$ 进行最大似然估计时，平稳分布在 $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$ 上是均匀的，因为每个核苷酸出现的频率相等，...\"* 这是不正确的。核苷酸 $\\mathrm{T}$ 根本没有出现，所以频率相等的前提是错误的。此外，平稳分布是由转移矩阵推导出来的，而不是直接由碱基组成得出，并且在这种情况下，该链不是不可约的，这使得在所有四个状态上讨论唯一的平稳分布变得复杂。在连通类 $\\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}\\}$ 中，平稳分布将是 $(\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3})$，但对于 $\\mathrm{T}$ 将是 $0$。\n- *\"...并且伪计数只影响平稳分布，而转移概率保持不变。\"* 这从根本上是错误的。伪计数的全部目的就是改变转移概率以避免零概率事件。\n结论：**不正确**。\n\n**选项 C:**\n- *\"伪计数只将零转移概率替换为小的正值，但不会改变任何已经等于 $1$ 的转移概率。\"* 这是不正确的。如推导所示，一个等于 $1$ 的概率（例如，$P(\\mathrm{A}|\\mathrm{C})=1$）被更改为 $P_\\alpha(\\mathrm{A}|\\mathrm{C}) = \\frac{n+\\alpha}{n+4\\alpha}$，这个值严格小于 $1$。平滑处理会影响给定行中的所有概率估计，而不仅仅是值为零的那些。\n- *\"...因此，在平滑处理后，$\\mathrm{C}\\to\\mathrm{A}$、$\\mathrm{A}\\to\\mathrm{G}$ 和 $\\mathrm{G}\\to\\mathrm{C}$ 的概率仍然恰好为 $1$。\"* 这是基于错误前提的错误结论。\n结论：**不正确**。\n\n**选项 D:**\n- *\"在对 $s=(\\mathrm{CAG})^n$ 进行最大似然估计时，状态 $\\mathrm{C}$、$\\mathrm{A}$ 和 $\\mathrm{G}$ 是吸收态，因为它们只转移到自身，...\"* 这是不正确的。一个吸收态 $x$ 的条件是 $P(x|x)=1$。在这里，我们有 $P(\\mathrm{C}|\\mathrm{C})=0$、$P(\\mathrm{A}|\\mathrm{A})=0$ 和 $P(\\mathrm{G}|\\mathrm{G})=0$。这些状态形成一个确定性循环，它们不是吸收态。\n- *\"...并且伪计数通过强制转移矩阵在所有 $16$ 种可能的转移上均匀分布来移除这些吸收态。\"* 这是不正确的。虽然伪计数确保所有转移都是可能的（从而移除了任何可能存在的吸收态），但它们不会导致一个均匀矩阵。平滑后的概率在很大程度上取决于原始的非零计数。只有 T 的行，由于没有观测计数，才会变成均匀分布。\n结论：**不正确**。\n\n总之，选项 A 对两种估计方法的结果提供了完整而准确的描述。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "序列建模中的一个根本问题是如何选择合适的模型复杂度，特别是马尔可夫链的阶数 $k$。这个编程练习让你扮演一名计算生物学家，任务是使用贝叶斯信息准则（Bayesian Information Criterion, BIC）根据经验做出这一决策。通过实现这个模型选择过程，你将学会如何在模型拟合度和复杂度之间进行权衡，这是统计建模中的一项核心技能。",
            "id": "2402020",
            "problem": "给定一个由字母表 $\\{A,C,G,T\\}$ 构成的脱氧核糖核酸（DNA）序列和一个整数上限 $k_{\\max}$。对于每个满足 $0 \\le k \\le k_{\\max}$ 的整数模型阶数 $k$，我们考虑一个该序列的 $k$ 阶马尔可夫模型。设序列为 $x_1,x_2,\\dots,x_n$，其长度为 $n$。对于每个 $k$，定义条件似然\n$$\nL_k(x_{1:n}) \\;=\\; \\prod_{t=k+1}^{n} P\\!\\left(x_t \\,\\middle|\\, x_{t-k},x_{t-k+1},\\dots,x_{t-1}\\right),\n$$\n并定义对数似然\n$$\n\\ell_k(x_{1:n}) \\;=\\; \\sum_{t=k+1}^{n} \\log P\\!\\left(x_t \\,\\middle|\\, x_{t-k},x_{t-k+1},\\dots,x_{t-1}\\right),\n$$\n其中 $\\log$ 表示自然对数。对于每个 $k$，使用最大似然估计（MLE）来估计条件转移概率：对于每个出现在 $\\{x_{t-k},\\dots,x_{t-1}\\}$（对于某个 $t \\in \\{k+1,\\dots,n\\}$）中的长度为 $k$ 的上下文 $s \\in \\{A,C,G,T\\}^k$，以及对于每个符号 $a \\in \\{A,C,G,T\\}$，\n$$\n\\widehat{P}(a \\mid s) \\;=\\; \\frac{N(s,a)}{N(s,\\ast)},\n$$\n其中 $N(s,a)$ 是满足 $(x_{t-k},\\dots,x_{t-1})=s$ 且 $x_t=a$ 的索引 $t \\in \\{k+1,\\dots,n\\}$ 的数量，而 $N(s,\\ast)=\\sum_{b \\in \\{A,C,G,T\\}} N(s,b)$。如果一个上下文 $s$ 未被观测到（即 $N(s,\\ast)=0$），那么它对下面定义的似然和参数计数都没有贡献。\n\n定义阶数 $k$ 的贝叶斯信息准则（BIC）为\n$$\n\\mathrm{BIC}(k) \\;=\\; -2\\,\\ell_k(x_{1:n}) \\;+\\; p_k \\,\\log T_k,\n$$\n其中 $T_k = n-k$ 是有效样本量（条件预测事件的数量），而 $p_k$ 是拟合模型中的自由参数数量，此处取为\n$$\np_k \\;=\\; \\left(\\#\\text{ of distinct observed length-}k\\text{ contexts } s \\text{ with } N(s,\\ast)>0\\right)\\times(4-1).\n$$\n对于 $k=0$ 的情况，如果 $n \\ge 1$，则将上下文解释为空字符串，视为一个单一的已观测上下文，并取 $T_0 = n$。在所有情况下，均使用自然对数。\n\n你的任务是，对于每个测试用例，确定能够最小化 $\\mathrm{BIC}(k)$ 的最优阶数 $k^\\star \\in \\{0,1,\\dots,k_{\\max}\\}$。如果出现平局（多个 $k$ 达到相同的最小值），则选择其中最小的 $k$。\n\n你编写的程序必须直接根据上述定义从第一性原理出发进行实现。不需要外部输入；程序必须在内部评估以下测试集，每个测试用例由一个DNA序列 $x_{1:n}$ 和一个整数 $k_{\\max}$ 指定，并满足约束 $0 \\le k_{\\max} \\le n-1$，以确保对于所有考虑的 $k$，都有 $T_k \\ge 1$。\n\n测试集：\n- 测试用例 $1$：sequence = \"ATATATATATAT\", $k_{\\max} = 3$。\n- 测试用例 $2$：sequence = \"AC\", $k_{\\max} = 1$。\n- 测试用例 $3$：sequence = \"ATATATAA\", $k_{\\max} = 2$。\n- 测试用例 $4$：sequence = \"GATTACA\", $k_{\\max} = 0$。\n- 测试用例 $5$：sequence = \"ACGTA\", $k_{\\max} = 4$。\n- 测试用例 $6$：sequence = \"AAAAAAA\", $k_{\\max} = 4$。\n\n你的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的整数列表形式的结果（例如，如果有三个测试用例，则为“[0,1,2]”）。此问题要求的输出是形如\n“[k1,k2,k3,k4,k5,k6]”\n的单行文本，其中每个 $k_i$ 是上述定义的测试用例 $i$ 的最优阶数。此问题不涉及任何物理单位；所有输出均为纯整数。",
            "solution": "该问题提出了一个为给定脱氧核糖核酸（DNA）序列的马尔可夫链模型进行模型阶数选择的任务。这是统计推断和计算生物学中的一个标准问题。问题陈述的有效性得到了确认，因为它科学地基于已建立的统计理论，问题设定良好，提供了所有必要的信息和约束，并且其表述是客观的。所有的定义，包括对数似然 $\\ell_k$、转移概率的最大似然估计（MLE）、自由参数数量 $p_k$、有效样本量 $T_k$ 以及贝叶斯信息准则（BIC），都是标准的且内部一致。\n\n核心原理是应用贝叶斯信息准则（BIC）来为序列 $x_{1:n}$ 的马尔可夫模型选择最优阶数 $k$。阶数为 $k$ 的模型的 BIC 定义为：\n$$\n\\mathrm{BIC}(k) = -2\\,\\ell_k(x_{1:n}) + p_k \\,\\log T_k\n$$\n该准则通过平衡模型对数据的拟合优度与其复杂性，体现了简约性原则，即奥卡姆剃刀定律。\n- 项 $-2\\,\\ell_k(x_{1:n})$ 度量了拟合的不足。其中 $\\ell_k(x_{1:n})$ 是在给定模型下序列的条件对数似然。更高的对数似然表示更好的拟合，从而使该项的值更小。\n- 项 $p_k \\,\\log T_k$ 是对模型复杂度的惩罚。$p_k$ 是模型中的自由参数数量，$T_k = n-k$ 是 $k$ 阶模型的有效样本量。一个更复杂的模型（更大的 $p_k$）会受到更重的惩罚，尤其是在样本量 $T_k$ 较小时。\n\n我们的目标是找到能够最小化 $\\mathrm{BIC}(k)$ 的阶数 $k^\\star \\in \\{0, 1, \\dots, k_{\\max}\\}$。为了实现这一目标，我们将实现一个算法，该算法遍历从 $0$ 到 $k_{\\max}$ 的每个可能的阶数 $k$，为每个 $k$ 计算 $\\mathrm{BIC}(k)$，然后找出产生最小 BIC 值的 $k$。\n\n对于给定的序列 $x_{1:n}$ 和阶数 $k$，$\\mathrm{BIC}(k)$ 的计算过程如下：\n\n首先，我们确定自由参数的数量 $p_k$。问题指定\n$$\np_k = (\\#\\text{ of distinct observed length-}k\\text{ contexts } s \\text{ with } N(s,\\ast)>0)\\times(4-1)\n$$\n对于每个不同的已观测上下文（长度为 $k$ 的前缀），都有 $4$ 个来自字母表 $\\{A,C,G,T\\}$ 的可能后续符号。这 $4$ 个结果的概率之和必须为 $1$，这为该上下文留下了 $4-1=3$ 个自由参数需要估计。因此，$p_k$ 是序列中作为后续符号的上下文出现的、长度为 $k$ 的唯一子串数量的 $3$ 倍。\n对于 $k=0$ 的特殊情况，上下文是空字符串。如果序列非空（$n \\ge 1$），这个单一上下文总是被观测到。因此，$p_0 = 1 \\times 3 = 3$。\n\n其次，我们计算条件对数似然 $\\ell_k$。公式为：\n$$\n\\ell_k(x_{1:n}) = \\sum_{t=k+1}^{n} \\log \\widehat{P}(x_t \\mid x_{t-k}, \\dots, x_{t-1})\n$$\n概率 $\\widehat{P}(a \\mid s)$ 使用最大似然估计法（MLE）进行估计，在本例中这对应于经验频率：\n$$\n\\widehat{P}(a \\mid s) = \\frac{N(s,a)}{N(s,\\ast)}\n$$\n其中 $N(s,a)$ 是子串 $sa$ 在序列中（在适当位置）出现的次数，$N(s,\\ast)$ 是上下文 $s$ 的总计数。通过对相同项进行分组，可以更高效地计算对数似然和：\n$$\n\\ell_k(x_{1:n}) = \\sum_{s,a} N(s,a) \\log \\left( \\frac{N(s,a)}{N(s,\\ast)} \\right)\n$$\n其中求和遍及所有已观测到的上下文-符号对 $(s,a)$。这需要计算所有相关的长度为 $k$ 的子串（上下文）和长度为 $k+1$ 的子串（转移）。\n\n对于 $k=0$ 的情况，模型假设符号是独立同分布的。一个符号 $a$ 的概率是它在序列中的总频率，$\\widehat{P}(a) = N(a)/n$。对数似然为：\n$$\n\\ell_0(x_{1:n}) = \\sum_{a \\in \\{A,C,G,T\\}} N(a) \\log \\left( \\frac{N(a)}{n} \\right)\n$$\n\n最后，在计算出 $\\ell_k$ 和 $p_k$，并已知 $T_k = n-k$ 后，我们就可以计算 $\\mathrm{BIC}(k)$。请注意，这里的对数是自然对数，即 $\\log(\\cdot) = \\ln(\\cdot)$。如果 $T_k=1$，则 $\\log T_k = 0$，惩罚项消失。问题的约束条件（$0 \\le k_{\\max} \\le n-1$）确保了对于所有考虑的 $k$，都有 $T_k \\ge 1$。\n\n总体算法如下：\n1. 对于每个测试用例（序列 `x`，`k_max`）：\n2. 初始化一个空列表来存储 BIC 值。\n3. 对于从 $0$ 到 $k_{\\max}$ 的每个整数 $k$：\n    a. 如果 $k=0$：计算符号频率 $\\{N(a)\\}$。计算 $\\ell_0$ 和 $p_0=3$。计算 $\\mathrm{BIC}(0) = -2\\ell_0 + p_0 \\log n$。\n    b. 如果 $k>0$：\n        i. 遍历序列从索引 $k$ 到 $n-1$，以识别所有 $n-k$ 个转移事件。\n        ii. 统计所有唯一的长度为 $k$ 的上下文的出现次数 $N(s,\\ast)$，以及所有唯一的长度为 $(k+1)$ 的转移序列的出现次数 $N(s,a)$。\n        iii. 根据唯一上下文的数量计算 $p_k$。\n        iv. 使用计数来计算 $\\ell_k$。\n        v. 计算 $\\mathrm{BIC}(k) = -2\\ell_k + p_k \\log(n-k)$。\n    c. 存储计算出的 $\\mathrm{BIC}(k)$。\n4. 找到 BIC 分数列表中与最小值对应的索引 $k^\\star$。问题陈述要求在出现平局时选择最小的 $k$，通过找到最小值的首次出现位置可以自然地处理这种情况。\n5. 收集所有测试用例的最优 $k^\\star$ 值，并将其格式化为最终结果。",
            "answer": "```python\nimport numpy as np\n\ndef calculate_bic_k(seq: str, k: int) -> float:\n    \"\"\"\n    Calculates the Bayesian Information Criterion (BIC) for a k-th order Markov model.\n\n    Args:\n        seq: The DNA sequence.\n        k: The order of the Markov model.\n\n    Returns:\n        The BIC value for the model.\n    \"\"\"\n    n = len(seq)\n    \n    if k == 0:\n        # --- Handle 0-th order model ---\n        T_k = n\n        if T_k < 1:\n            return float('inf')\n\n        # Count symbol frequencies\n        counts = {}\n        for char in seq:\n            counts[char] = counts.get(char, 0) + 1\n        \n        # Calculate log-likelihood ell_0\n        log_likelihood = 0.0\n        for char_count in counts.values():\n            if char_count > 0:\n                prob = char_count / n\n                log_likelihood += char_count * np.log(prob)\n        \n        # Number of free parameters p_0\n        # One context (empty string) means 4-1=3 free parameters.\n        p_k = 3\n        \n    else: # k > 0\n        # --- Handle k-th order model (k > 0) ---\n        T_k = n - k\n        if T_k < 1:\n            return float('inf')\n\n        # Count contexts (k-mers) and transitions (k+1)-mers\n        context_counts = {}\n        transition_counts = {}\n        \n        for i in range(k, n):\n            context = seq[i-k:i]\n            symbol = seq[i]\n            \n            context_counts[context] = context_counts.get(context, 0) + 1\n            \n            transition_key = (context, symbol)\n            transition_counts[transition_key] = transition_counts.get(transition_key, 0) + 1\n\n        if not context_counts:\n            # This case occurs if n <= k, which is prevented by the problem's\n            # constraint k_max <= n-1. Still, as a safeguard:\n            return 0.0 if T_k <= 1 else float('inf')\n\n        # Calculate log-likelihood ell_k\n        log_likelihood = 0.0\n        for (context, _), trans_count in transition_counts.items():\n            ctx_count = context_counts[context]\n            # Probability P(symbol | context) = N(context, symbol) / N(context, *)\n            prob = trans_count / ctx_count\n            # Summand is N(s,a) * log(P(a|s))\n            log_likelihood += trans_count * np.log(prob)\n        \n        # Number of free parameters p_k\n        num_distinct_contexts = len(context_counts)\n        p_k = num_distinct_contexts * (4 - 1)\n\n    # Calculate BIC penalty term: p_k * log(T_k)\n    # The term is 0 if T_k=1, as log(1)=0.\n    penalty_term = 0.0\n    if T_k > 1:\n        penalty_term = p_k * np.log(T_k)\n        \n    bic = -2 * log_likelihood + penalty_term\n    return bic\n\ndef find_optimal_k(seq: str, k_max: int) -> int:\n    \"\"\"\n    Finds the optimal Markov model order k that minimizes the BIC.\n\n    Args:\n        seq: The DNA sequence.\n        k_max: The maximum order to test.\n\n    Returns:\n        The optimal order k*.\n    \"\"\"\n    bic_values = []\n    for k in range(k_max + 1):\n        bic_k = calculate_bic_k(seq, k)\n        bic_values.append(bic_k)\n    \n    # Find the index of the minimum BIC value.\n    # np.argmin() correctly breaks ties by returning the first index.\n    min_bic = float('inf')\n    optimal_k = -1\n\n    for k, bic in enumerate(bic_values):\n        if bic < min_bic:\n            min_bic = bic\n            optimal_k = k\n            \n    return optimal_k\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given suite of test cases.\n    \"\"\"\n    test_cases = [\n        {\"sequence\": \"ATATATATATAT\", \"k_max\": 3},\n        {\"sequence\": \"AC\", \"k_max\": 1},\n        {\"sequence\": \"ATATATAA\", \"k_max\": 2},\n        {\"sequence\": \"GATTACA\", \"k_max\": 0},\n        {\"sequence\": \"ACGTA\", \"k_max\": 4},\n        {\"sequence\": \"AAAAAAA\", \"k_max\": 4},\n    ]\n\n    results = []\n    for case in test_cases:\n        seq = case[\"sequence\"]\n        k_max = case[\"k_max\"]\n        \n        # Ensure constraint k_max <= n-1 is met, as per problem.\n        n = len(seq)\n        if not (0 <= k_max <= n - 1):\n            raise ValueError(f\"Invalid k_max={k_max} for sequence length n={n}\")\n            \n        optimal_k = find_optimal_k(seq, k_max)\n        results.append(optimal_k)\n\n    # Print the final result in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}