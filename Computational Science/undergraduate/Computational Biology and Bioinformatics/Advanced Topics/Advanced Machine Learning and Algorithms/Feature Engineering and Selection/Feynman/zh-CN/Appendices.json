{
    "hands_on_practices": [
        {
            "introduction": "生物信息学中的一个基本任务是从原始序列数据中提取有意义的生物学特征。本练习将引导你实现一个衡量基因密码子使用频率与宿主生物平均使用频率之间差异的特征 。通过计算和比较概率分布，你将掌握将序列信息转化为定量指标的核心技能，这对于研究基因演化和功能至关重要。",
            "id": "2389797",
            "problem": "给定一个偏差特征的形式化定义，该特征量化了一个基因的密码子使用与其宿主生物平均密码子使用的差异程度。设密码子字母表为脱氧核糖核酸 (DNA) 字母表 $\\{ \\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T} \\}$ 上所有 $64$ 种可能的三联体集合，并设终止密码子集合为 $C_{\\mathrm{stop}}=\\{\\mathrm{TAA},\\mathrm{TAG},\\mathrm{TGA}\\}$。将有义密码子集合定义为 $C = \\{\\text{所有DNA三联体}\\} \\setminus C_{\\mathrm{stop}}$，其中包含 $61$ 个密码子。对于任何长度是 $3$ 的倍数的DNA序列，其密码子化是指从左到右将其分解为不重叠的三联体 $(c_1,c_2,\\dots,c_n)$，其中 $n$ 是密码子的数量。\n\n对于任何密码子化的序列 $S$（测试套件中不含终止密码子），其在 $C$ 上的经验密码子使用分布 $p_S$ 定义为\n$$\np_S(c) = \\frac{\\#\\{i \\in \\{1,\\dots,n\\}: c_i = c\\}}{n} \\quad \\text{对每个 } c \\in C,\n$$\n其中 $n$ 是 $S$ 中密码子的总数，$\\#\\{\\cdot\\}$ 表示计数。对于一个宿主编码序列的多重集 $H=\\{H_1,H_2,\\dots,H_m\\}$，通过汇总所有宿主序列的计数并按密码子总数进行归一化，定义宿主的混合平均密码子使用分布 $q_H$ 为\n$$\nq_H(c) = \\frac{\\sum_{j=1}^{m} \\#\\{i: (H_j)_i = c\\}}{\\sum_{j=1}^{m} n_j} \\quad \\text{对每个 } c \\in C,\n$$\n其中 $n_j$ 是 $H_j$ 中的密码子数量。需要为一个基因序列 $G$ 计算的偏差特征是其密码子使用与宿主混合使用之间的 $\\ell_1$ 距离，\n$$\nD(G,H) = \\sum_{c \\in C} \\left| p_G(c) - q_H(c) \\right|.\n$$\n\n测试套件中的所有序列都是长度为 $3$ 的倍数的大写DNA字符串，且不含终止密码子。密码子化必须使用从位置 $1$ 开始的阅读框，并采用不重叠的三联体。使用上文定义的有义密码子集合 $C$。您的程序必须完全按照定义计算 $D(G,H)$，并且必须输出四舍五入到 $6$ 位小数的结果。\n\n测试套件：\n- 宿主编码集 $H$ 由以下三个序列组成：\n  - $H_1 = \\text{ATGGCTGCTGGTGGCATGGCCGCTGGT}$,\n  - $H_2 = \\text{GCTGGTGCTGGCATGGCTGCCGGT}$,\n  - $H_3 = \\text{ATGGCTGGTGCTGCTGGC}$.\n- 四个待评估的候选基因序列 $G$，与同一宿主 $H$ 进行比较：\n  1. $G_1 = \\text{ATGGCTGCTGGTGGCATGGCCGCTGGTGCTGGTGCTGGCATGGCTGCCGGTATGGCTGGTGCTGCTGGC}$,\n  2. $G_2 = \\text{TTTTTCTTATTGAAAAAGAACAATCAACAC}$,\n  3. $G_3 = \\text{ATGGCTGGTGCTAAGGCTTACGGCGCCTTT}$,\n  4. $G_4 = \\text{ATG}$.\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含四个结果 $[D(G_1,H),D(G_2,H),D(G_3,H),D(G_4,H)]$，形式为一个以逗号分隔的十进制数列表，四舍五入到 $6$ 位小数，并用方括号括起来，不含空格。例如，格式必须与 $[\\dots]$ 完全一样。\n- 不涉及任何物理单位或角度单位。所有值都是无量纲的实数。\n\n覆盖说明：\n- 测试套件包括一个通用案例、一个精确匹配案例、一个不相交支持集的边界案例以及一个最小长度基因案例。答案必须是四舍五入到 $6$ 位小数的十进制数。",
            "solution": "我们详细审查了问题陈述，并确认其有效。该问题在生物信息学领域具有科学依据，特别是关于密码子使用偏好性。所提供的密码子使用分布和偏差特征（$\\ell_1$ 距离）的定义在数学上是精确的，并且是该领域的标准定义。所有必要的数据和约束都已提供，构成了一个定义明确、具有唯一可计算解的问题。该问题是客观的、无歧义的，其计算任务是可行的。因此，我将着手提供一个完整的解决方案。\n\n求解方法包括三个主要步骤：\n1.  建立有义密码子的规范表示。\n2.  计算宿主的混合平均密码子使用分布，记为 $q_H$。\n3.  对每个候选基因序列 $G$，计算其经验密码子使用分布 $p_G$，然后计算偏差特征 $D(G,H) = \\sum_{c \\in C} |p_G(c) - q_H(c)|$。\n\n首先，我们定义有义密码子的集合 $C$。这是所有 $4^3 = 64$ 种可能的DNA三联体中，排除了三个标准终止密码子（$\\mathrm{TAA}$、$\\mathrm{TAG}$ 和 $\\mathrm{TGA}$）后的集合。这剩下 $|C| = 61$ 个有义密码子。为了计算方便，我们建立一个包含这 $61$ 个密码子的固定有序列表，以及一个从每个密码子字符串到唯一索引的映射。这使我们能够将密码子使用分布表示为 $\\mathbb{R}^{61}$ 中的向量。\n\n其次，我们计算宿主生物的分布 $q_H$。问题将其定义为混合平均使用。计算方法是首先将所有宿主序列 $\\{H_1, H_2, \\dots, H_m\\}$ 连接成一个大的序列。然后，我们在这个混合序列中统计 $61$ 个有义密码子中每一个的出现次数。通过将这些计数除以混合序列中的密码子总数进行归一化，得到分布 $q_H$。\n给定的宿主集为 $H = \\{H_1, H_2, H_3\\}$，其中：\n$H_1 = \\text{ATGGCTGCTGGTGGCATGGCCGCTGGT}$ (长度 $27$, $n_1 = 9$ 个密码子)\n$H_2 = \\text{GCTGGTGCTGGCATGGCTGCCGGT}$ (长度 $24$, $n_2 = 8$ 个密码子)\n$H_3 = \\text{ATGGCTGGTGCTGCTGGC}$ (长度 $18$, $n_3 = 6$ 个密码子)\n\n宿主池中的密码子总数为 $N_H = n_1 + n_2 + n_3 = 9 + 8 + 6 = 23$。\n混合密码子计数通过对每个序列的计数求和确定：\n- 计数(ATG) = $4$\n- 计数(GCT) = $9$\n- 计数(GGT) = $5$\n- 计数(GGC) = $3$\n- 计数(GCC) = $2$\n所有其他密码子的计数为 $0$。\n宿主分布 $q_H$ 是一个向量，其中每个密码子 $c$ 的分量是 $q_H(c) = \\text{计数}(c) / N_H$。例如，$q_H(\\text{ATG}) = 4/23$。\n\n第三，对每个候选基因 $G_k$（$k=1,2,3,4$），我们计算其经验密码子使用分布 $p_{G_k}$。这包括对基因序列进行密码子化，统计每个有义密码子的出现次数，并按该基因的密码子总数 $n_{G_k}$ 进行归一化。\n\n最后，偏差特征 $D(G_k, H)$ 是两个概率分布向量 $p_{G_k}$ 和 $q_H$ 之间的 $\\ell_1$ 距离。\n$D(G_k, H) = \\| p_{G_k} - q_H \\|_1 = \\sum_{i=1}^{61} |(p_{G_k})_i - (q_H)_i|$。\n\n让我们将此方法应用于四个测试案例。\n\n**案例 1: $G_1$**\n$G_1$ 是 $H_1, H_2, H_3$的串联。因此，其密码子组成与混合的宿主组成完全相同。密码子数量为 $n_{G_1} = 23$。因此，分布 $p_{G_1}$ 与 $q_H$ 相同。\n$D(G_1, H) = \\sum_{c \\in C} |q_H(c) - q_H(c)| = 0$。\n\n**案例 2: $G_2 = \\text{TTTTTCTTATTGAAAAAGAACAATCAACAC}$**\n该基因有 $n_{G_2} = 10$ 个密码子：{TTT, TTC, TTA, TTG, AAA, AAG, AAC, AAT, CAA, CAC}，每个出现一次。因此，对于这 10 个密码子中的每一个 $c$，$p_{G_2}(c) = 1/10$。$G_2$ 中的密码子集合与宿主池 $H$ 中存在的密码子集合不相交。当两个概率分布的支持集不相交时，它们的 $\\ell_1$ 距离为最大值。\n$D(G_2, H) = \\sum_{c \\in \\text{codons}(G_2)} |p_{G_2}(c) - 0| + \\sum_{c \\in \\text{codons}(H)} |0 - q_H(c)| = \\sum p_{G_2}(c) + \\sum q_H(c) = 1 + 1 = 2$。\n\n**案例 3: $G_3 = \\text{ATGGCTGGTGCTAAGGCTTACGGCGCCTTT}$**\n该基因有 $n_{G_3} = 10$ 个密码子。密码子计数为：ATG(1), GCT(3), GGT(1), AAG(1), TAC(1), GGC(1), GCC(1), TTT(1)。通过将这些计数除以 10，可以得到分布 $p_{G_3}$。然后我们计算 $\\sum_{c \\in C} |p_{G_3}(c) - q_H(c)|$。\n非零项来自存在于 $G_3$ 或 $H$ 中的密码子。\n- $|p_{G_3}(\\text{ATG}) - q_H(\\text{ATG})| = |1/10 - 4/23| = |23/230 - 40/230| = 17/230$\n- $|p_{G_3}(\\text{GCT}) - q_H(\\text{GCT})| = |3/10 - 9/23| = |69/230 - 90/230| = 21/230$\n- $|p_{G_3}(\\text{GGT}) - q_H(\\text{GGT})| = |1/10 - 5/23| = |23/230 - 50/230| = 27/230$\n- $|p_{G_3}(\\text{GGC}) - q_H(\\text{GGC})| = |1/10 - 3/23| = |23/230 - 30/230| = 7/230$\n- $|p_{G_3}(\\text{GCC}) - q_H(\\text{GCC})| = |1/10 - 2/23| = |23/230 - 20/230| = 3/230$\n仅存在于 $G_3$ 中的密码子的项：\n- $|p_{G_3}(\\text{AAG}) - 0| = 1/10 = 23/230$\n- $|p_{G_3}(\\text{TAC}) - 0| = 1/10 = 23/230$\n- $|p_{G_3}(\\text{TTT}) - 0| = 1/10 = 23/230$\n总和为 $(17+21+27+7+3+23+23+23)/230 = 144/230 = 72/115 \\approx 0.626087$。\n\n**案例 4: $G_4 = \\text{ATG}$**\n该基因有 $n_{G_4} = 1$ 个密码子，即 ATG。其分布为 $p_{G_4}(\\text{ATG}) = 1$，对所有其他密码子 $p_{G_4}(c) = 0$。\n距离为 $D(G_4, H) = |p_{G_4}(\\text{ATG}) - q_H(\\text{ATG})| + \\sum_{c \\neq \\text{ATG}} |0 - q_H(c)|$。\n这等于 $|1 - 4/23| + (\\sum_{c \\in C} q_H(c) - q_H(\\text{ATG})) = 19/23 + (1 - 4/23) = 19/23 + 19/23 = 38/23 \\approx 1.652174$。\n\n实现将以编程方式对所有 $61$ 个密码子执行这些计算，以确保正确性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the codon usage deviation feature for a set of genes against a host.\n    \"\"\"\n    # Define test cases as per the problem statement.\n    host_sequences = [\n        \"ATGGCTGCTGGTGGCATGGCCGCTGGT\",\n        \"GCTGGTGCTGGCATGGCTGCCGGT\",\n        \"ATGGCTGGTGCTGCTGGC\",\n    ]\n    gene_sequences = [\n        \"ATGGCTGCTGGTGGCATGGCCGCTGGTGCTGGTGCTGGCATGGCTGCCGGTATGGCTGGTGCTGCTGGC\",\n        \"TTTTTCTTATTGAAAAAGAACAATCAACAC\",\n        \"ATGGCTGGTGCTAAGGCTTACGGCGCCTTT\",\n        \"ATG\",\n    ]\n\n    # Step 1: Establish a canonical representation of sense codons.\n    bases = ['A', 'C', 'G', 'T']\n    all_codons = [b1 + b2 + b3 for b1 in bases for b2 in bases for b3 in bases]\n    stop_codons = {\"TAA\", \"TAG\", \"TGA\"}\n    sense_codons = sorted([c for c in all_codons if c not in stop_codons])\n    codon_to_idx = {codon: i for i, codon in enumerate(sense_codons)}\n    num_sense_codons = len(sense_codons)\n\n    def get_codon_distribution(sequence: str) -> np.ndarray:\n        \"\"\"\n        Calculates the empirical codon usage distribution for a given DNA sequence.\n        \n        Args:\n            sequence: A DNA sequence string with length divisible by 3.\n\n        Returns:\n            A numpy array representing the probability distribution over sense codons.\n        \"\"\"\n        counts = np.zeros(num_sense_codons, dtype=np.float64)\n        num_codons = len(sequence) // 3\n\n        if num_codons == 0:\n            return counts\n\n        for i in range(0, len(sequence), 3):\n            codon = sequence[i:i+3]\n            if codon in codon_to_idx:\n                counts[codon_to_idx[codon]] += 1\n        \n        return counts / num_codons\n\n    # Step 2: Compute the host's pooled average codon usage distribution q_H.\n    pooled_host_sequence = \"\".join(host_sequences)\n    q_H = get_codon_distribution(pooled_host_sequence)\n\n    results = []\n    # Step 3: For each gene, compute its distribution p_G and the deviation D(G, H).\n    for gene_seq in gene_sequences:\n        # Calculate p_G for the current gene.\n        p_G = get_codon_distribution(gene_seq)\n        \n        # Calculate the L1 distance (deviation feature).\n        # D(G,H) = sum |p_G(c) - q_H(c)|\n        deviation = np.sum(np.abs(p_G - q_H))\n        \n        results.append(deviation)\n\n    # Format the final output as a comma-separated list of decimals rounded to 6 places.\n    # The format \"{:.6f}\" handles rounding and ensures 6 decimal places are shown.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在表观遗传学研究中，特征工程通常涉及根据基因组坐标整合信号。本练习挑战你从DNA甲基化数据中，根据“CpG岛岸”（CpG island shores）这一复杂的生物学定义，构建一个区域性特征 。通过这个实践，你将学会如何精确地处理基因组区间逻辑、聚合多个数据点，并将抽象的生物学概念转化为可计算的特征，这是处理现代基因组学数据的必备技能。",
            "id": "2389842",
            "problem": "给定合成的脱氧核糖核酸 (DNA) 甲基化微阵列数据，其中包括探针的基因组坐标和每个样本的甲基化值（称为 beta 值）。任务是为每个样本构建一个特征：该特征是在胞嘧啶-磷酸-鸟嘌呤 (CpG) 岛岸 (CpG island shores) 中所有探针的 beta 值的平均值。CpG 岛岸被定义为在每个 CpG 岛两侧，由指定窗口宽度确定的侧翼区域，但不包括任何位于 CpG 岛内部的碱基对。您的解决方案必须是一个完整的可运行程序，用于计算多个测试用例的此特征，并额外评估一个基于跨样本方差的简单特征选择标准。\n\n从以下基本原则开始：\n- CpG 岛由一个染色体上的闭合基因组区间表示，具有整数碱基对坐标。对于一个起始坐标为 $s$、结束坐标为 $e$（含）的岛，其左岸是闭区间 $[s - w, s - 1]$，右岸是闭区间 $[e + 1, e + w]$，其中 $w$ 是以碱基对为单位的非负整数窗口宽度。所有区间都必须被裁剪到染色体域 $[1, L]$ 内，其中 $L$ 是以碱基对为单位的染色体长度。\n- 所有岛的岸区并集，是指位于至少一个此类左岸或右岸中的碱基对位置的集合，其中排除了任何位于 CpG 岛内部的位置。\n- 位于基因组位置 $x$ 的探针属于岸区并集，当且仅当 $x$ 位于至少一个左岸或右岸区间内（裁剪到 $[1, L]$ 后），并且 $x$ 不包含在任何 CpG 岛区间内。\n- 对于给定的样本 $i$，构建的特征值是其位置落在岸区并集中的所有探针的 beta 值的算术平均值，计算时忽略缺失值。如果某个样本没有探针参与计算，则该特征值为未定义，并应表示为一个非数值 (not-a-number) 量。\n- 跨样本总体方差定义为 $\\sigma^{2} = \\frac{1}{n} \\sum_{i=1}^{n} \\left(m_{i} - \\bar{m}\\right)^{2}$，其中 $m_{i}$ 是样本 $i$ 的构建特征值，$\\bar{m}$ 是所有具有已定义值的 $m_{i}$ 的平均值，$n$ 是用于计算 $\\bar{m}$ 的具有已定义值的样本数量。缺失的特征值应从方差计算中排除。如果没有样本具有已定义的特征值，则方差为未定义，并应表示为一个非数值量。测试用例的特征选择决策是返回一个布尔值，指示是否满足 $\\sigma^{2} \\ge \\tau$，$\\tau$ 是一个给定的非负阈值。\n\n所有坐标均为整数，并以碱基对（bp）为单位。Beta 值是 $[0, 1]$ 范围内的实数或非数值。不涉及角度。所有输出必须是小数，而不是百分比。\n\n您的程序必须：\n- 对于每个测试用例，根据给定的 CpG 岛、染色体长度 $L$ 和窗口宽度 $w$ 构建岸区并集。\n- 选择基因组位置位于岸区并集中的探针，并为每个样本计算构建的特征 $m_{i}$，计算方法是对所选探针的值求平均，并忽略缺失值。\n- 计算已定义的 $m_{i}$ 值的跨样本总体方差 $\\sigma^{2}$，并与提供的阈值 $\\tau$ 进行比较，以产生一个布尔决策。\n- 将每个 $m_{i}$ 和 $\\sigma^{2}$ 四舍五入到 $6$ 位小数进行输出。如果任何 $m_{i}$ 或 $\\sigma^{2}$ 未定义，则将其输出为非数值。\n\n输入通过以下您的程序必须嵌入的测试套件进行硬编码。对于每个测试用例，数据包括：\n- 染色体长度 $L$（以碱基对为单位）。\n- 窗口宽度 $w$（以碱基对为单位）。\n- CpG 岛区间列表 $[(s_{1}, e_{1}), (s_{2}, e_{2}), \\dots]$，其中 $s_{k} \\le e_{k}$，端点包含在内。\n- 探针列表，形式为成对的 $(x, [\\beta_{1}, \\beta_{2}, \\dots, \\beta_{S}])$，其中 $x$ 是探针位置，$\\beta_{i}$ 是样本 $i$ 的 beta 值（可能为非数值）。\n- 非负方差阈值 $\\tau$。\n\n测试套件：\n- 测试用例 1 (正常路径):\n  - $L = 10000$, $w = 2000$。\n  - 岛屿: $[(4000, 4500)]$。\n  - 探针:\n    - $(1500, [0.1, 0.2, 0.15])$\n    - $(2500, [0.8, 0.7, 0.9])$\n    - $(4000, [0.9, 0.95, 0.85])$\n    - $(4501, [0.3, 0.4, 0.35])$\n    - $(4600, [0.6, 0.5, 0.55])$\n    - $(7000, [0.2, 0.2, 0.2])$\n  - $\\tau = 0.001$。\n- 测试用例 2 (边界裁剪和缺失值):\n  - $L = 5000$, $w = 2000$。\n  - 岛屿: $[(100, 300)]$。\n  - 探针:\n    - $(1, [0.5, 0.6, 0.7])$\n    - $(99, [0.4, \\text{NaN}, 0.6])$\n    - $(100, [0.9, 0.8, 0.7])$\n    - $(200, [0.2, 0.2, 0.2])$\n    - $(301, [0.3, 0.3, 0.3])$\n    - $(2299, [0.2, 0.2, \\text{NaN}])$\n    - $(2300, [0.1, \\text{NaN}, 0.1])$\n    - $(2301, [0.0, 0.0, 0.0])$\n  - $\\tau = 0.002$。\n- 测试用例 3 (相邻岛屿的重叠岸区，不包括岛内碱基):\n  - $L = 20000$, $w = 3000$。\n  - 岛屿: $[(5000, 5200), (8000, 8200)]$。\n  - 探针:\n    - $(2100, [0.2, 0.4, 0.6])$\n    - $(5100, [0.9, 0.9, 0.9])$\n    - $(6000, [0.5, 0.7, 0.9])$\n    - $(8100, [0.1, 0.2, 0.3])$\n    - $(9000, [0.4, 0.4, 0.4])$\n    - $(15000, [0.0, 0.0, 0.0])$\n    - $(11200, [0.8, 0.6, 0.4])$\n    - $(8201, [0.3, \\text{NaN}, 0.3])$\n  - $\\tau = 0.001$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个无逗号、由方括号括起来的三个测试用例结果的列表。每个测试用例结果本身就是一个列表，结构为 $[m_{1}, m_{2}, \\dots, m_{S}, \\sigma^{2}, \\text{pass}]$，其中 $m_{i}$ 是四舍五入到 $6$ 位小数的每个样本的构建特征值，$\\sigma^{2}$ 是四舍五入到 $6$ 位小数的跨样本总体方差，$\\text{pass}$ 是一个布尔值，表示是否满足 $\\sigma^{2} \\ge \\tau$。输出中不得包含任何空格。例如，包含三个测试用例结果的列表应如下所示：[[\\dots],[\\dots],[\\dots]]，其中不含任何空格。",
            "solution": "所提出的问题是计算生物学领域中一个明确定义的练习，特别是在基因组数据的特征工程方面。任务要求从合成的 DNA 甲基化微阵列数据中为每个样本计算一个特征，然后执行一个简单的基于方差的特征选择步骤。该问题具有科学依据、逻辑一致，并为获得唯一解提供了所有必要信息。因此，该问题被认为是有效的。\n\n解决方案通过对每个测试用例按顺序、分步实现指定逻辑来展开。\n\n首先，我们必须精确地识别出感兴趣的基因组区域，即 CpG 岛岸。一个 CpG 岛被给定为一个闭区间 $[s, e]$。岛岸被定义为在该岛两侧宽度为 $w$ 的区域，具体为区间 $[s - w, s - 1]$ 和 $[e + 1, e + w]$。这些区间必须被裁剪到有效的染色体域，即 $[1, L]$，其中 $L$ 是染色体长度。因此，对于一个岛 $[s, e]$，其左岸是 $[\\max(1, s - w), s - 1]$，右岸是 $[e + 1, \\min(L, e + w)]$。\n\n问题的核心在于定义用于特征计算的探针位置集合。一个位于基因组坐标 $x$ 的探针被选中，当且仅当满足两个条件：\n1. 位置 $x$ 必须落在所有 CpG 岛派生的所有岸区区域的并集内。这意味着 $x$ 必须至少在一个左岸或右岸区间内。\n2. 位置 $x$ 绝不能落在任何 CpG 岛区间 $[s_k, e_k]$ 内。\n\n为了高效地实现这一逻辑，我们可以使用覆盖整个染色体长度 $L$ 的布尔掩码。让我们定义两个长度为 $L+1$ 的布尔数组（对坐标使用 1-based 索引）：`is_island` 和 `is_shore`。\n- `is_island` 数组初始化为 false。对于每个岛 $[s_k, e_k]$，我们将索引从 $s_k$ 到 $e_k$（含）的元素设置为 true。\n- `is_shore` 数组也初始化为 false。对于每个岛 $[s_k, e_k]$，我们计算其裁剪后的左岸和右岸区间，并将 `is_shore` 中的相应元素设置为 true。\n\n然后，如果 `is_shore`$[x]$ 为 true 且 `is_island`$[x]$ 为 false，则选择位置 $x$ 处的探针。这种方法通过正确应用排除原则，可以正确处理复杂情况，例如相邻岛的岸区相互重叠或甚至与其他岛重叠。\n\n一旦识别出相关探针的集合，我们便为每个样本构建特征。设 $S$ 为样本数量。所选探针的 beta 值形成一个值矩阵，其中行对应探针，列对应样本。对于每个样本 $i \\in \\{1, \\dots, S\\}$，特征值 $m_i$ 计算为来自所有选定探针（用集合 $P_{\\text{sel}}$ 表示）的 beta 值 $(\\beta)$ 的算术平均值。在此计算中必须忽略任何表示为非数值 (NaN) 的缺失值。\n$$\nm_i = \\frac{1}{|P'_{\\text{sel}, i}|} \\sum_{p \\in P'_{\\text{sel}, i}} \\beta_{p,i}\n$$\n其中 $P'_{\\text{sel}, i}$ 是选定探针的子集，在该子集中样本 $i$ 的 beta 值不为 NaN。如果对于给定样本 $i$，所有选定探针的 beta 值均为 NaN，或者根本没有探针被选中（$P_{\\text{sel}}$ 为空），则集合 $P'_{\\text{sel}, i}$ 为空，特征值 $m_i$ 定义为 NaN。\n\n最后一步是使用基于方差的选择标准来评估此构建特征的效用。我们计算特征值 $m_i$ 在所有 $m_i$ 不为 NaN 的样本中的总体方差 $\\sigma^2$。设非 NaN 特征值的集合为 $M' = \\{m_i | m_i \\text{ is not NaN}\\}$，并设 $n = |M'|$ 为此类值的数量。这些值的平均值为 $\\bar{m} = \\frac{1}{n} \\sum_{m_i \\in M'} m_i$。那么总体方差为：\n$$\n\\sigma^2 = \\frac{1}{n} \\sum_{m_i \\in M'} (m_i - \\bar{m})^2\n$$\n如果 $n=0$（所有 $m_i$ 均为 NaN），则 $\\sigma^2$ 也为 NaN。如果此方差达到或超过给定的阈值 $\\tau$，则选择该特征：\n$$\n\\text{pass} = (\\sigma^2 \\ge \\tau)\n$$\n如果 $\\sigma^2$ 是 NaN，此比较的评估结果为 false。\n\n所有计算出的 $m_i$ 和 $\\sigma^2$ 值都按要求四舍五入到 6 位小数。该过程独立应用于问题陈述中提供的每个测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the feature engineering and selection problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (happy path)\n        {\n            \"L\": 10000, \"w\": 2000,\n            \"islands\": [(4000, 4500)],\n            \"probes\": [\n                (1500, [0.1, 0.2, 0.15]),\n                (2500, [0.8, 0.7, 0.9]),\n                (4000, [0.9, 0.95, 0.85]),\n                (4501, [0.3, 0.4, 0.35]),\n                (4600, [0.6, 0.5, 0.55]),\n                (7000, [0.2, 0.2, 0.2]),\n            ],\n            \"tau\": 0.001\n        },\n        # Test case 2 (boundary clipping and missing values)\n        {\n            \"L\": 5000, \"w\": 2000,\n            \"islands\": [(100, 300)],\n            \"probes\": [\n                (1, [0.5, 0.6, 0.7]),\n                (99, [0.4, np.nan, 0.6]),\n                (100, [0.9, 0.8, 0.7]),\n                (200, [0.2, 0.2, 0.2]),\n                (301, [0.3, 0.3, 0.3]),\n                (2299, [0.2, 0.2, np.nan]),\n                (2300, [0.1, np.nan, 0.1]),\n                (2301, [0.0, 0.0, 0.0]),\n            ],\n            \"tau\": 0.002\n        },\n        # Test case 3 (overlapping shores from adjacent islands)\n        {\n            \"L\": 20000, \"w\": 3000,\n            \"islands\": [(5000, 5200), (8000, 8200)],\n            \"probes\": [\n                (2100, [0.2, 0.4, 0.6]),\n                (5100, [0.9, 0.9, 0.9]),\n                (6000, [0.5, 0.7, 0.9]),\n                (8100, [0.1, 0.2, 0.3]),\n                (9000, [0.4, 0.4, 0.4]),\n                (15000, [0.0, 0.0, 0.0]),\n                (11200, [0.8, 0.6, 0.4]),\n                (8201, [0.3, np.nan, 0.3]),\n            ],\n            \"tau\": 0.001\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        L = case[\"L\"]\n        w = case[\"w\"]\n        islands = case[\"islands\"]\n        probes = case[\"probes\"]\n        tau = case[\"tau\"]\n\n        # Step 1: Identify shore and island regions using boolean masks\n        is_island = np.zeros(L + 1, dtype=bool)\n        is_shore = np.zeros(L + 1, dtype=bool)\n\n        for s, e in islands:\n            is_island[s : e + 1] = True\n            \n            # Left shore\n            left_shore_start = max(1, s - w)\n            left_shore_end = s - 1\n            if left_shore_start <= left_shore_end:\n                is_shore[left_shore_start : left_shore_end + 1] = True\n            \n            # Right shore\n            right_shore_start = e + 1\n            right_shore_end = min(L, e + w)\n            if right_shore_start <= right_shore_end:\n                is_shore[right_shore_start : right_shore_end + 1] = True\n\n        # Step 2: Select probes that are in shores but not in islands\n        selected_betas = []\n        for pos, beta_values in probes:\n            if 1 <= pos <= L and is_shore[pos] and not is_island[pos]:\n                selected_betas.append(beta_values)\n        \n        num_samples = len(probes[0][1]) if probes else 0\n        \n        # Step 3: Compute engineered feature m_i for each sample\n        m_features = []\n        if not selected_betas:\n            m_features = [np.nan] * num_samples\n        else:\n            selected_betas_matrix = np.array(selected_betas)\n            for i in range(num_samples):\n                sample_betas = selected_betas_matrix[:, i]\n                # np.nanmean handles empty arrays (after NaN removal) by returning nan\n                mean_val = np.nanmean(sample_betas)\n                m_features.append(mean_val)\n\n        # Step 4: Compute variance and perform feature selection\n        m_features_valid = [m for m in m_features if not np.isnan(m)]\n        \n        if len(m_features_valid) > 0:\n            # np.var computes population variance by default (ddof=0)\n            variance = np.var(m_features_valid)\n        else:\n            variance = np.nan\n\n        pass_criterion = False\n        if not np.isnan(variance):\n            pass_criterion = variance >= tau\n            \n        # Step 5: Format results\n        rounded_m = [round(m, 6) if not np.isnan(m) else m for m in m_features]\n        rounded_var = round(variance, 6) if not np.isnan(variance) else variance\n\n        case_result = rounded_m + [rounded_var, pass_criterion]\n        all_results.append(case_result)\n\n    # Final print statement in the exact required format\n    # Custom formatter to handle nan, bool, and float\n    def format_item(item):\n        if isinstance(item, bool):\n            return str(item)\n        if isinstance(item, float) and np.isnan(item):\n            return 'nan'\n        if isinstance(item, float):\n            return f\"{item:.6f}\"\n        return str(item)\n\n    result_str = \"[\"\n    for i, case_res in enumerate(all_results):\n        result_str += \"[\"\n        result_str += \",\".join([format_item(item) for item in case_res])\n        result_str += \"]\"\n        if i < len(all_results) - 1:\n            result_str += \",\"\n    result_str += \"]\"\n    \n    # Another way to achieve the same result without spaces\n    # import json\n    # print(json.dumps(all_results, separators=(',', ':')).replace('NaN', 'nan'))\n\n    print(result_str)\n\nsolve()\n```"
        },
        {
            "introduction": "特征工程的内涵远不止于简单的数据变换，它还可以与统计建模深度融合。在这个高级练习中，你将探索一个精妙的概念：将统计模型的参数本身作为一个特征 。具体来说，你将通过拟合一个逻辑回归模型来量化两个单核苷酸多态性（SNP）之间的上位性相互作用，并将交互项的系数 $\\beta_3$ 作为最终的工程化特征，这为理解复杂的遗传效应提供了有力的分析工具。",
            "id": "2389799",
            "problem": "为您提供了多个个体的二元表型数据和代表两个单核苷酸多态性（SNPs）的两个基因型特征，表示为 $S_1$ 和 $S_2$。对于个体索引 $i \\in \\{1,2,\\ldots,n\\}$，其表型为 $y_i \\in \\{0,1\\}$，基因型为 $S_{1,i} \\in \\{0,1,2\\}$ 和 $S_{2,i} \\in \\{0,1,2\\}$。考虑一个逻辑回归模型，其中 $y_i=1$ 的对数几率是一个截距项、 $S_{1,i}$ 和 $S_{2,i}$ 的主效应及其交互作用的线性函数：\n$$\n\\log\\left(\\frac{\\mathbb{P}(y_i=1 \\mid S_{1,i},S_{2,i})}{\\mathbb{P}(y_i=0 \\mid S_{1,i},S_{2,i})}\\right) \\;=\\; \\beta_0 \\;+\\; \\beta_1 S_{1,i} \\;+\\; \\beta_2 S_{2,i} \\;+\\; \\beta_3 \\left(S_{1,i} \\cdot S_{2,i}\\right).\n$$\n构建的交互作用特征被定义为通过拟合上述模型获得的系数 $\\beta_3$ 的最大似然估计。如果交互作用列 $\\left(S_{1,i}\\cdot S_{2,i}\\right)_{i=1}^n$ 恒等于零（因此不携带任何信息），则按照惯例将构建的交互作用特征定义为 $0$。\n\n您的任务是为以下每个测试用例计算构建的交互作用特征。对于每个案例，您必须将给定数据视为用于拟合上述模型的完整数据集，不含额外的协变量。所有计算均无单位。您的程序应输出一行，其中包含所有测试用例的结果，形式为方括号括起来的逗号分隔列表，每个值四舍五入到小数点后恰好 $6$ 位。\n\n测试套件\n\n- 案例A（所有基因型组合均衡出现）：\n  数据集包含 $n=20$ 个个体，以有序三元组 $(S_1,S_2,y)$ 的形式指定。样本为：\n  $$(0,0,0),(0,0,0),(0,0,0),(0,0,0),(0,0,1),$$\n  $$(1,0,0),(1,0,0),(1,0,1),(1,0,0),(1,0,1),$$\n  $$(0,1,0),(0,1,1),(0,1,0),(0,1,0),(0,1,1),$$\n  $$(1,1,1),(1,1,1),(1,1,0),(1,1,1),(1,1,1).$$\n  对于此案例，计算 $\\hat{\\beta}_3$ 的拟合值。\n\n- 案例B（近似可加的主效应和最小的交互作用）：\n  数据集包含 $n=40$ 个个体，根据 $(S_1,S_2)$ 分为四个大小相等的组。对于 $(S_1,S_2)=(0,0)$，有 $10$ 个个体，其中 $3$ 个 $y=1$，$7$ 个 $y=0$；对于 $(S_1,S_2)=(1,0)$，有 $10$ 个个体，其中 $5$ 个 $y=1$，$5$ 个 $y=0$；对于 $(S_1,S_2)=(0,1)$，有 $10$ 个个体，其中 $5$ 个 $y=1$，$5$ 个 $y=0$；对于 $(S_1,S_2)=(1,1)$，有 $10$ 个个体，其中 $7$ 个 $y=1$，$3$ 个 $y=0$。具体来说，样本为：\n  $$(0,0,1),(0,0,1),(0,0,1),(0,0,0),(0,0,0),(0,0,0),(0,0,0),(0,0,0),(0,0,0),(0,0,0),$$\n  $$(1,0,1),(1,0,1),(1,0,1),(1,0,1),(1,0,1),(1,0,0),(1,0,0),(1,0,0),(1,0,0),(1,0,0),$$\n  $$(0,1,1),(0,1,1),(0,1,1),(0,1,1),(0,1,1),(0,1,0),(0,1,0),(0,1,0),(0,1,0),(0,1,0),$$\n  $$(1,1,1),(1,1,1),(1,1,1),(1,1,1),(1,1,1),(1,1,1),(1,1,1),(1,1,0),(1,1,0),(1,1,0).$$\n  对于此案例，计算 $\\hat{\\beta}_3$ 的拟合值。\n\n- 案例C（退化的交互作用列）：\n  数据集包含 $n=8$ 个个体，其 $S_2$ 恒等于零。样本为：\n  $$(0,0,0),(1,0,1),(0,0,0),(2,0,1),(1,0,0),(2,0,1),(0,0,1),(1,0,0).$$\n  对于此案例，根据所述惯例，返回 $0$ 作为构建的交互作用特征。\n\n最终输出格式\n\n您的程序应生成单行输出，其中包含三个构建的交互作用特征，形式为方括号括起来的逗号分隔列表，每个值四舍五入到小数点后恰好 $6$ 位，例如：$[\\hat{\\beta}_3^{(A)},\\hat{\\beta}_3^{(B)},\\hat{\\beta}_3^{(C)}]$。",
            "solution": "对问题陈述进行严格验证。\n\n步骤1：提取已知条件\n- **模型**：使用logit链接函数的逻辑回归，用于二元表型 $y_i \\in \\{0, 1\\}$ 和两个单核苷酸多态性 (SNP) 特征 $S_{1,i}, S_{2,i} \\in \\{0, 1, 2\\}$。模型指定为：\n$$ \\log\\left(\\frac{\\mathbb{P}(y_i=1 \\mid S_{1,i},S_{2,i})}{\\mathbb{P}(y_i=0 \\mid S_{1,i},S_{2,i})}\\right) = \\beta_0 + \\beta_1 S_{1,i} + \\beta_2 S_{2,i} + \\beta_3 (S_{1,i} \\cdot S_{2,i}) $$\n- **构建特征的定义**：该特征是交互作用系数的最大似然估计 (MLE)，$\\hat{\\beta}_3$。\n- **特殊条件**：如果交互作用列 $(S_{1,i} \\cdot S_{2,i})_{i=1}^n$ 恒等于零，则构建的特征定义为 $0$。\n- **数据集**：\n    - **案例A**：$n=20$ 个样本，以 $(S_1, S_2, y)$ 三元组形式提供。\n    - **案例B**：$n=40$ 个样本，为四个 $(S_1,S_2)$ 组合 $(0,0), (1,0), (0,1), (1,1)$ 中的每一个提供了计数，也提供了显式样本。\n    - **案例C**：$n=8$ 个样本，其 $S_2$ 恒等于零。\n- **任务**：为每个案例计算 $\\hat{\\beta}_3$。\n\n步骤2：使用提取的已知条件进行验证\n根据所需标准对问题进行评估：\n- **科学依据充分**：该问题基于逻辑回归，这是一种基础统计方法，并应用于 SNP 数据分析，这是计算生物学和生物信息学中的标准实践。该模型在科学上是合理的。\n- **问题定义明确**：该问题要求计算广义线性模型中参数的最大似然估计。对于案例A和案例B中提供的数据集，数据不是完全可分的（即，对于具有多个样本的预测变量组合，同时存在 $y=0$ 和 $y=1$ 两种结果），这确保了唯一且有限的最大似然估计的存在。对于案例C，问题陈述为处理因退化设计矩阵而产生的不可识别性问题提供了明确的规则，使得所有案例中的问题都定义明确。\n- **客观性**：问题使用精确的数学语言阐述，术语定义清晰，数据客观。\n\n该问题不存在科学上不合理、模糊或矛盾等缺陷。解决问题所需的所有数据和条件均已提供。\n\n步骤3：结论与行动\n该问题有效。将推导并实施解决方案。\n\n问题的核心是为指定的逻辑回归模型的参数 $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1, \\beta_2, \\beta_3]^T$ 找到最大似然估计。\n\n$y_i=1$ 的概率由 sigmoid 函数 $\\sigma(\\eta_i)$ 给出：\n$$ p_i = \\mathbb{P}(y_i=1 \\mid \\mathbf{x}_i, \\boldsymbol{\\beta}) = \\sigma(\\eta_i) = \\frac{1}{1 + e^{-\\eta_i}} $$\n其中 $\\eta_i = \\mathbf{x}_i^T \\boldsymbol{\\beta}$ 是线性预测器。第 $i$ 个体的设计向量是 $\\mathbf{x}_i = [1, S_{1,i}, S_{2,i}, S_{1,i} \\cdot S_{2,i}]^T$。\n\n假设独立，观测数据的似然函数是每个观测的伯努利概率的乘积：\n$$ L(\\boldsymbol{\\beta}) = \\prod_{i=1}^n p_i^{y_i} (1-p_i)^{1-y_i} $$\n最大化似然函数等同于最大化对数似然函数 $\\ell(\\boldsymbol{\\beta}) = \\log L(\\boldsymbol{\\beta})$：\n$$ \\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right] $$\n通过代入 $p_i = e^{\\eta_i} / (1+e^{\\eta_i})$ 和 $1-p_i = 1 / (1+e^{\\eta_i})$，对数似然函数简化为：\n$$ \\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left[ y_i \\eta_i - \\log(1 + e^{\\eta_i}) \\right] = \\sum_{i=1}^n \\left[ y_i (\\mathbf{x}_i^T \\boldsymbol{\\beta}) - \\log(1 + e^{\\mathbf{x}_i^T \\boldsymbol{\\beta}}) \\right] $$\n最大化 $\\ell(\\boldsymbol{\\beta})$ 的 $\\boldsymbol{\\beta}$ 没有闭式解。必须通过数值方法找到解。逻辑回归模型的对数似然函数是全局凹的，这保证了如果数据不是完全可分的，则存在唯一的最大值。我们可以通过最小化负对数似然函数来找到这个最大值, 负对数似然函数是一个凸函数。一个标准且高效的方法是拟牛顿算法，如BFGS (Broyden–Fletcher–Goldfarb–Shanno)，我们将使用 `scipy.optimize.minimize` 来实现。这需要目标函数的梯度。\n\n要最小化的目标函数是 $f(\\boldsymbol{\\beta}) = -\\ell(\\boldsymbol{\\beta})$。它的梯度是负的对数似然梯度，为：\n$$ \\nabla f(\\boldsymbol{\\beta}) = -\\frac{\\partial \\ell(\\boldsymbol{\\beta})}{\\partial \\boldsymbol{\\beta}} = -\\sum_{i=1}^n (y_i - p_i) \\mathbf{x}_i = \\sum_{i=1}^n (p_i - y_i) \\mathbf{x}_i = \\mathbf{X}^T (\\mathbf{p} - \\mathbf{y}) $$\n其中 $\\mathbf{X}$ 是 $n \\times 4$ 的设计矩阵，$\\mathbf{y}$ 是结果向量，$\\mathbf{p}$ 是概率向量。\n\n对于每个案例，我们按以下步骤进行：\n\n**案例 A**：\n数据集包含 $n=20$ 个个体样本。我们直接从给定数据构建 $20 \\times 4$ 的设计矩阵 $\\mathbf{X}$ 和 $20 \\times 1$ 的响应向量 $\\mathbf{y}$。$\\mathbf{X}$ 的四列对应于截距项 (1)、$S_1$、$S_2$ 和交互作用乘积 $S_1 \\cdot S_2$。然后，我们使用 $\\boldsymbol{\\beta} = \\mathbf{0}$ 作为初始猜测值，数值最小化负对数似然函数，以找到 MLE 向量 $\\hat{\\boldsymbol{\\beta}}$。所需的特征是该向量的第四个分量 $\\hat{\\beta}_3$。\n\n**案例 B**：\n数据集包含 $n=40$ 个样本，根据 $(S_1, S_2)$ 的值聚合成四个组。这种结构允许对数似然函数有计算上更高效的公式。设 $j$ 为四个唯一组的索引，$N_j$ 为 $j$ 组中的个体数，$k_j$ 为该组中取值为正例 ($y=1$) 的数量。唯一的设计向量是 $\\mathbf{x}_j$。对数似然函数为：\n$$ \\ell(\\boldsymbol{\\beta}) = \\sum_{j=1}^4 \\left[ k_j (\\mathbf{x}_j^T \\boldsymbol{\\beta}) - N_j \\log(1 + e^{\\mathbf{x}_j^T \\boldsymbol{\\beta}}) \\right] $$\n梯度也同样进行聚合：\n$$ \\nabla f(\\boldsymbol{\\beta}) = \\sum_{j=1}^4 (N_j p_j - k_j) \\mathbf{x}_j $$\n我们构建唯一设计向量的 $4 \\times 4$ 矩阵，以及对应的 $N_j$ 和 $k_j$ 向量。然后像案例 A 一样进行优化，找到 $\\hat{\\boldsymbol{\\beta}}$，并提取 $\\hat{\\beta}_3$。\n\n**案例 C**：\n数据集对所有 $i=1, \\dots, 8$ 都有 $S_{2,i} = 0$。因此，交互作用项 $S_{1,i} \\cdot S_{2,i}$ 对所有个体也都是 $0$。设计矩阵中对应于交互作用系数 $\\beta_3$ 的列是一个零向量。这会产生一个不可识别性问题，因为 $\\beta_3$ 的任何值都会产生相同的似然值。问题为这种情况提供了明确的惯例：构建的交互作用特征定义为 $0$。因此，对于此案例，根据定义 $\\hat{\\beta}_3 = 0$，无需进行计算。\n\n实现将使用 `scipy.optimize.minimize` 的 'BFGS' 方法，为提高效率和准确性，同时提供目标函数（负对数似然）及其雅可比矩阵（梯度）。为确保在计算 $\\log(1+e^{\\eta})$ 和 sigmoid 函数时的数值稳定性，将使用 `scipy.special` 模块中的函数（`logsumexp` 和 `expit`）。",
            "answer": "```python\nimport numpy as np\nimport scipy.optimize\n\ndef solve():\n    \"\"\"\n    Solves the logistic regression problem for three test cases and computes the\n    engineered interaction feature (MLE of beta_3) for each.\n    \"\"\"\n\n    # --- Case A ---\n    data_A = [\n        (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 1),\n        (1, 0, 0), (1, 0, 0), (1, 0, 1), (1, 0, 0), (1, 0, 1),\n        (0, 1, 0), (0, 1, 1), (0, 1, 0), (0, 1, 0), (0, 1, 1),\n        (1, 1, 1), (1, 1, 1), (1, 1, 0), (1, 1, 1), (1, 1, 1),\n    ]\n    S1_A = np.array([d[0] for d in data_A])\n    S2_A = np.array([d[1] for d in data_A])\n    y_A = np.array([d[2] for d in data_A])\n    X_A = np.c_[np.ones(len(S1_A)), S1_A, S2_A, S1_A * S2_A]\n    \n    beta_A = _fit_logistic_regression(X_A, y_A)\n    beta3_A = beta_A[3]\n\n    # --- Case B ---\n    # The data can be aggregated for efficiency\n    # (S1, S2): {N: total count, k: count with y=1}\n    data_B_grouped = {\n        (0, 0): {'N': 10, 'k': 3},\n        (1, 0): {'N': 10, 'k': 5},\n        (0, 1): {'N': 10, 'k': 5},\n        (1, 1): {'N': 10, 'k': 7},\n    }\n    X_unique_B = []\n    N_B, k_B = [], []\n    for (s1, s2), counts in data_B_grouped.items():\n        X_unique_B.append([1, s1, s2, s1 * s2])\n        N_B.append(counts['N'])\n        k_B.append(counts['k'])\n    \n    X_B_agg = np.array(X_unique_B)\n    N_B_agg = np.array(N_B)\n    k_B_agg = np.array(k_B)\n\n    beta_B = _fit_logistic_regression(X_B_agg, k_B_agg, N=N_B_agg, grouped=True)\n    beta3_B = beta_B[3]\n\n    # --- Case C ---\n    # For this case, S2 is always 0. The interaction term S1*S2 is always 0.\n    # The problem statement defines the engineered feature to be 0 in this scenario.\n    beta3_C = 0.0\n\n    results = [beta3_A, beta3_B, beta3_C]\n    \n    # Format the output as specified\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\n\ndef _fit_logistic_regression(X, y, N=None, grouped=False):\n    \"\"\"\n    Fits a logistic regression model and returns the estimated coefficients.\n    Can handle both individual and grouped data.\n    \"\"\"\n    from scipy.special import expit\n\n    num_features = X.shape[1]\n    beta_initial = np.zeros(num_features)\n\n    if grouped:\n        # For grouped data\n        def objective(beta, X_grp, k_grp, N_grp):\n            eta = X_grp @ beta\n            # Numerically stable calculation of log(1 + exp(eta))\n            log_1_plus_exp_eta = np.logaddexp(0, eta)\n            neg_log_likelihood = -np.sum(k_grp * eta - N_grp * log_1_plus_exp_eta)\n            return neg_log_likelihood\n\n        def jacobian(beta, X_grp, k_grp, N_grp):\n            eta = X_grp @ beta\n            p = expit(eta)\n            grad = X_grp.T @ (N_grp * p - k_grp)\n            return grad\n        \n        args = (X, y, N)\n\n    else:\n        # For individual data\n        def objective(beta, X_ind, y_ind):\n            eta = X_ind @ beta\n            log_1_plus_exp_eta = np.logaddexp(0, eta)\n            neg_log_likelihood = -np.sum(y_ind * eta - log_1_plus_exp_eta)\n            return neg_log_likelihood\n\n        def jacobian(beta, X_ind, y_ind):\n            eta = X_ind @ beta\n            p = expit(eta)\n            grad = X_ind.T @ (p - y_ind)\n            return grad\n        \n        args = (X, y)\n\n    result = scipy.optimize.minimize(\n        fun=objective,\n        x0=beta_initial,\n        args=args,\n        method='BFGS',\n        jac=jacobian\n    )\n\n    if not result.success:\n        raise RuntimeError(f\"Optimization failed: {result.message}\")\n\n    return result.x\n\nsolve()\n\n```"
        }
    ]
}