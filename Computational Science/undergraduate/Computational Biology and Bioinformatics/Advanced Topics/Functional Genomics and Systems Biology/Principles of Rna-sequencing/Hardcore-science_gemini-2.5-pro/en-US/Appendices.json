{
    "hands_on_practices": [
        {
            "introduction": "RNA-seq data is inherently compositional, meaning it measures the relative proportion of transcripts rather than their absolute counts. This foundational exercise demonstrates a critical pitfall of this property: how a dramatic change in one gene can create the illusion of change in all others under simple total-count normalization . By working through this calculation, you will gain an essential intuition for why robust normalization is not just a technical step, but a prerequisite for valid biological conclusions.",
            "id": "2417849",
            "problem": "An experimenter performs RNA sequencing (RNA-seq) on two conditions, $A$ and $B$, using the same number of cells per sample and no external controls or spike-ins. Each library is sequenced to exactly $100000$ mapped reads. The assay produces read counts that are, in expectation, proportional to the fraction of transcript molecules contributed by each gene in the library. The experimenter applies a standard total-count scaling normalization (counts per million, CPM), which divides each gene’s count by the sample’s total mapped reads, thereby comparing relative abundances.\n\nConsider a gene set consisting of one gene $X$ and $990$ other genes. The true absolute transcript molecules per cell are as follows:\n\n- In condition $A$: gene $X$ has $1000$ molecules; each of the other $990$ genes has $100$ molecules.\n- In condition $B$: gene $X$ is strongly over-expressed with $50000$ molecules; each of the other $990$ genes remains at $100$ molecules.\n\nAssume that the sequencing process samples reads proportionally to these underlying transcript fractions, and ignore sampling variance. The experimenter computes log base-$2$ fold-changes using CPM-normalized values between $B$ and $A$.\n\nWhich option best describes the apparent log base-$2$ fold-change for any one of the unchanged other genes (not $X$) under this normalization and why?\n\nA. Approximately $-0.58$ for most other genes, because the single highly abundant gene $X$ in condition $B$ reduces the relative fractions of all unchanged genes, making them appear down-regulated under total-count normalization.\n\nB. Approximately $0$ for most other genes, because total-count normalization fully removes composition effects due to over-expression of a single gene.\n\nC. Approximately $+0.58$ for most other genes, because the large increase in total RNA content in condition $B$ raises all normalized counts.\n\nD. It depends on sequencing depth; increasing reads from $100000$ to $200000$ would drive the apparent log base-$2$ fold-change for most other genes toward $0$ under total-count normalization.",
            "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Experiment: RNA-sequencing on two conditions, $A$ and $B$.\n- Replicates: The problem describes two samples, one for each condition. The number of cells per sample is identical.\n- Controls: No external controls or spike-ins are used.\n- Sequencing Depth: Each library is sequenced to exactly $100000$ mapped reads.\n- Assay Principle: Read counts are, in expectation, proportional to the fraction of transcript molecules for each gene.\n- Normalization: Total-count scaling (counts per million, CPM), defined as dividing each gene's count by the sample's total mapped reads and scaling.\n- Gene Set: One gene, $X$, and $990$ other genes.\n- True Absolute Abundances (molecules per cell):\n    - Condition $A$: Gene $X$ has $1000$ molecules. Each of the $990$ other genes has $100$ molecules.\n    - Condition $B$: Gene $X$ has $50000$ molecules. Each of the $990$ other genes has $100$ molecules.\n- Assumptions:\n    1.  Sequencing samples reads proportionally to the underlying transcript fractions.\n    2.  Sampling variance is to be ignored.\n- Question: Compute the apparent log base-$2$ fold-change for any one of the unchanged genes when comparing condition $B$ to condition $A$, using CPM-normalized values.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem describes a classic and fundamental issue in the analysis of compositional data, which is characteristic of RNA-seq experiments. The concept of a highly expressed gene skewing the relative abundance of other genes under total-count normalization is a well-established artifact in bioinformatics. The principles are scientifically sound.\n- **Well-Posed**: The problem is well-posed. It provides all necessary numerical data and a clear, unambiguous question that allows for a unique solution through direct calculation.\n- **Objective**: The problem is stated in precise, objective language without subjective claims or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. It is a standard, albeit simplified, model for illustrating the pitfalls of naive normalization methods in transcriptomics. I will proceed with the derivation of the solution.\n\n**Derivation**\n\nThe core a priori assumption of the RNA-seq assay as described is that the number of reads mapped to a gene is proportional to the total number of its transcripts in the sample. Since we ignore sampling variance, we treat this proportionality as an exact relationship. Let us denote an arbitrary gene from the set of $990$ unchanged genes as gene $Y$.\n\n1.  **Calculate Total Transcript Molecules per Cell for Each Condition:**\n    The total number of molecules per cell serves as the denominator for calculating the molecular fraction of each gene.\n    -   In condition $A$, the total number of molecules, $T_A$, is:\n        $$T_A = (\\text{molecules of } X) + (990 \\times \\text{molecules of other genes}) = 1000 + (990 \\times 100) = 1000 + 99000 = 100000 \\text{ molecules}$$\n    -   In condition $B$, the total number of molecules, $T_B$, is:\n        $$T_B = (\\text{molecules of } X) + (990 \\times \\text{molecules of other genes}) = 50000 + (990 \\times 100) = 50000 + 99000 = 149000 \\text{ molecules}$$\n\n2.  **Calculate Expected Read Counts for Gene $Y$ in Each Condition:**\n    The expected read count for a gene is the total number of mapped reads in the library multiplied by the gene's molecular fraction.\n    -   In condition $A$, the molecular fraction of gene $Y$ is $f_{Y,A} = \\frac{100}{T_A} = \\frac{100}{100000}$. The expected read count for gene $Y$, $C_{Y,A}$, is:\n        $$C_{Y,A} = (\\text{Total Reads}) \\times f_{Y,A} = 100000 \\times \\frac{100}{100000} = 100\n        $$\n    -   In condition $B$, the molecular fraction of gene $Y$ is $f_{Y,B} = \\frac{100}{T_B} = \\frac{100}{149000}$. The expected read count for gene $Y$, $C_{Y,B}$, is:\n        $$C_{Y,B} = (\\text{Total Reads}) \\times f_{Y,B} = 100000 \\times \\frac{100}{149000} \\approx 67.114\n        $$\n\n3.  **Calculate CPM-Normalized Values and the Fold-Change:**\n    The CPM normalization formula is $CPM = \\frac{\\text{Gene Count}}{\\text{Total Mapped Reads}} \\times 10^6$. We are asked to compute the fold-change of these CPM values for gene $Y$ between condition $B$ and $A$.\n\n    -   $CPM_{Y,A} = \\frac{C_{Y,A}}{\\text{Total Reads}_A} \\times 10^6 = \\frac{100}{100000} \\times 10^6 = 1000$\n    -   $CPM_{Y,B} = \\frac{C_{Y,B}}{\\text{Total Reads}_B} \\times 10^6 = \\frac{100000 \\times \\frac{100}{149000}}{100000} \\times 10^6 = \\frac{100}{149000} \\times 10^6 \\approx 671.14$\n\n    The fold-change ($FC$) of the normalized values is the ratio $\\frac{CPM_{Y,B}}{CPM_{Y,A}}$.\n    $$FC = \\frac{CPM_{Y,B}}{CPM_{Y,A}} = \\frac{\\frac{100}{149000} \\times 10^6}{\\frac{100}{100000} \\times 10^6} = \\frac{100000}{149000} \\approx 0.67114$$\n    Note that the scaling factor $10^6$ and the identical total mapped reads cancel, so the fold change of CPM values is equivalent to the ratio of the raw counts, which in turn is equivalent to the ratio of the underlying molecular fractions.\n\n4.  **Calculate the Log Base-2 Fold-Change:**\n    The question asks for the log base-$2$ fold-change.\n    $$\\log_2(FC) = \\log_2\\left(\\frac{100000}{149000}\\right) \\approx \\log_2(0.67114)$$\n    $$\\log_2(FC) \\approx -0.5753$$\n    This value is approximately $-0.58$.\n\n**Option-by-Option Analysis**\n\n-   **A. Approximately $-0.58$ for most other genes, because the single highly abundant gene $X$ in condition $B$ reduces the relative fractions of all unchanged genes, making them appear down-regulated under total-count normalization.**\n    -   The calculated value, $\\approx -0.5753$, matches the stated value of approximately $-0.58$.\n    -   The reasoning provided is precisely correct. The massive increase in transcripts from gene $X$ in condition $B$ inflates the denominator ($T_B$) used to calculate relative abundance. Consequently, the relative fraction of reads for all other genes, whose absolute molecule counts are unchanged, must decrease. Total-count normalization perpetuates this distortion, leading to the artificial conclusion that these genes are down-regulated.\n    -   **Verdict: Correct.**\n\n-   **B. Approximately $0$ for most other genes, because total-count normalization fully removes composition effects due to over-expression of a single gene.**\n    -   The calculation shows a non-zero value.\n    -   The reasoning is fundamentally incorrect. Total-count normalization (like CPM) is the method that *introduces* this compositional artifact into the final reported values. It does not remove such effects; it is sensitive to them. Methods that are robust to this artifact, such as TMM or RLE, are based on the assumption that most genes are *not* differentially expressed, an assumption that total-count normalization does not use.\n    -   **Verdict: Incorrect.**\n\n-   **C. Approximately $+0.58$ for most other genes, because the large increase in total RNA content in condition $B$ raises all normalized counts.**\n    -   The sign is incorrect. The calculation yields a negative log fold-change, indicating apparent down-regulation.\n    -   The reasoning is flawed. While the total RNA content increases in condition $B$, normalized counts are *fractions* of the total. When the denominator (total RNA content) increases and a gene's numerator (its own RNA content) stays constant, the resulting fraction *decreases*.\n    -   **Verdict: Incorrect.**\n\n-   **D. It depends on sequencing depth; increasing reads from $100000$ to $200000$ would drive the apparent log base-$2$ fold-change for most other genes toward $0$ under total-count normalization.**\n    -   The apparent log fold-change is determined by the ratio of the *relative molecular fractions*, not the absolute number of reads. As shown in the derivation, the total sequencing depth is a scaling factor that cancels out completely when calculating the fold change between CPM-normalized values, provided the depth is the same for both samples being compared. If we were to change the depth from $100000$ to $200000$ for both samples, the CPM values would remain unchanged, and therefore the fold-change would also be unchanged. The problem is one of composition, not sequencing depth.\n    -   **Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Before drawing biological conclusions, it is vital to ensure your data's integrity through rigorous quality control (QC). This practice challenges you to design a robust QC metric to verify that the recorded sex of a sample matches its genetic expression profile, a common check for sample swaps or contamination . The exercise requires you to evaluate different strategies and converge on a solution that properly accounts for library size, gene length, and mapping ambiguity, highlighting the principles of good metric design in bioinformatics.",
            "id": "2417798",
            "problem": "You are evaluating human bulk Ribonucleic Acid sequencing (RNA-seq) libraries for sample identity. Metadata provides a stated biological sex (male or female) for each sample. You wish to design a single sample-level quality control statistic that flags potential contamination or mislabeling by exploiting expression of sex-specific genes, particularly those on chromosome Y, while being robust to variable sequencing depth, gene length, and mapping ambiguity. You may assume you have, for each sample, gene-level read counts $c_g$, effective transcript lengths $L_g$, total mapped fragments $N$, and standard ways to compute normalizations such as Transcripts Per Million (TPM). You also have a curated set $Y$ of male-specific, high-mappability Y-linked marker genes that exclude pseudoautosomal and paralogous regions, and knowledge of the X inactive specific transcript (XIST), a gene expressed in females but typically silenced in males. Let $\\delta$ denote a small positive pseudocount.\n\nWhich of the following defines the most appropriate metric to detect sex discordance or contamination, given the stated constraints?\n\nA. Declare a sample contaminated if the absolute number of reads mapping anywhere on chromosome Y exceeds $100$.\n\nB. Compute the sex-discordance score\n$$\nS \\;=\\; \\log_2\\!\\left(\\frac{\\sum_{g\\in Y} \\mathrm{TPM}^{\\mathrm{uniq}}_g + \\delta}{\\mathrm{TPM}_{\\mathrm{XIST}} + \\delta}\\right),\n$$\nwhere $\\mathrm{TPM}^{\\mathrm{uniq}}_g$ is computed from uniquely mapping fragments and effective lengths for genes $g\\in Y$. Flag a female-labeled sample if $S$ is above a chosen threshold and a male-labeled sample if $S$ is below that threshold.\n\nC. Use the chromosome-level ratio\n$$\nR \\;=\\; \\frac{\\text{total reads mapped to chromosome Y}}{\\text{total reads mapped to chromosome X}},\n$$\nand declare discordance if $R$ exceeds a fixed cutoff for female-labeled samples or falls below it for male-labeled samples.\n\nD. Use the mitochondrial read fraction\n$$\nM \\;=\\; \\frac{\\text{reads mapped to mitochondrial genome}}{N},\n$$\nand declare contamination if $M$ is unusually high compared to the cohort median.\n\nE. Compute the proportion\n$$\nP \\;=\\; \\frac{1}{|Y|}\\sum_{g\\in Y}\\mathbf{1}\\{c_g \\geq 1\\},\n$$\nand declare contamination if $P$ exceeds a fixed threshold in a female-labeled sample.",
            "solution": "The problem requires the formulation of a robust quality control metric for detecting sex discordance (mislabeling) or cross-sex contamination in human bulk RNA-seq samples. The core requirements for such a metric are that it must exploit sex-specific gene expression, be robust to variations in sequencing depth and gene length, and account for mapping ambiguity.\n\nLet us establish the principles for a valid metric based on the provided information.\n1.  **Biological Basis**: The fundamental biological difference is the chromosome complement: males are XY, females are XX. An effective metric must leverage this. The problem provides a curated set of male-specific Y-linked genes, $Y$, and the X-inactive specific transcript, `XIST`, which is highly expressed in females to mediate X-inactivation but is typically silent in males. A powerful metric would contrast the expression of Y-linked markers with `XIST` expression.\n2.  **Robustness to Sequencing Depth**: The total number of reads per sample, $N$, can vary significantly. Any metric based on raw read counts, $c_g$, will be heavily biased by this variation. Therefore, normalization for library size is essential.\n3.  **Robustness to Gene Length**: The number of reads mapping to a gene is proportional to its length, $L_g$. A metric that sums read counts over genes without accounting for their lengths will be biased. Normalization for gene length is required for inter-gene comparisons.\n4.  **Robustness to Mapping Ambiguity**: Reads originating from repetitive sequences or genes with close paralogs (e.g., on other chromosomes) can be misplaced by alignment algorithms. This is particularly problematic for chromosome Y, which shares pseudoautosomal regions (PARs) with chromosome X. The problem correctly suggests using a curated set $Y$ of `high-mappability` non-PAR genes and, as an additional measure, one could filter for uniquely mapping reads.\n\nA metric that satisfies these points would likely involve Transcripts Per Million (TPM), as TPM normalization is defined as:\n$$\n\\mathrm{TPM}_g = \\left( \\frac{c_g / L_g}{\\sum_{k} (c_k / L_k)} \\right) \\times 10^6\n$$\nwhere $k$ iterates over all genes. This formula explicitly normalizes for both gene length $L_g$ (in the term $c_g / L_g$) and sequencing depth (in the denominator, which is proportional to total library size).\n\nUsing these principles, we will now evaluate each option.\n\n**A. Declare a sample contaminated if the absolute number of reads mapping anywhere on chromosome Y exceeds $100$.**\nThis metric is based on a fixed threshold of an absolute read count.\n- It is not robust to sequencing depth. A very deeply sequenced female sample may accumulate more than $100$ spurious reads due to background noise or mapping errors, leading to a false positive. Conversely, a shallowly sequenced male sample might yield fewer than $100$ reads, leading to a false negative.\n- It is not robust to mapping ambiguity. By considering reads \"anywhere on chromosome Y\", it includes pseudoautosomal regions and other ambiguous loci, which are known to attract reads even in female samples. It fails to utilize the provided high-mappability gene set $Y$.\n- The threshold of $100$ is arbitrary and not generalizable across different experiments or sequencing technologies.\nTherefore, this approach is fundamentally flawed.\n**Verdict: Incorrect.**\n\n**B. Compute the sex-discordance score $$S \\;=\\; \\log_2\\!\\left(\\frac{\\sum_{g\\in Y} \\mathrm{TPM}^{\\mathrm{uniq}}_g + \\delta}{\\mathrm{TPM}_{\\mathrm{XIST}} + \\delta}\\right)$$, where $\\mathrm{TPM}^{\\mathrm{uniq}}_g$ is computed from uniquely mapping fragments and effective lengths for genes $g\\in Y$. Flag a female-labeled sample if $S$ is above a chosen threshold and a male-labeled sample if $S$ is below that threshold.**\nThis metric constructs a ratio of a male expression signature to a female expression signature.\n- It correctly leverages sex-specific markers: the numerator captures expression from curated Y-linked genes ($g \\in Y$), while the denominator captures expression of `XIST`.\n- It is robust to sequencing depth and gene length because it uses TPM, a normalization method designed specifically for this purpose.\n- It is robust to mapping ambiguity in two ways: it uses the curated high-mappability gene set $Y$, and it specifies that TPM should be computed from `uniquely mapping fragments` ($\\mathrm{TPM}^{\\mathrm{uniq}}$).\n- The use of a log-transform is statistically sound, as it helps to create a more symmetric distribution of scores. The pseudocount $\\delta$ prevents division by zero. The resulting score $S$ provides a continuous measure, allowing for empirical thresholding that is more robust than an arbitrary count cutoff. High $S$ indicates a male-like profile (high Y expression, low `XIST`), and low $S$ indicates a female-like profile (low Y expression, high `XIST`). This is the correct interpretation.\nThis metric meets all the stated requirements for a robust and scientifically sound statistic.\n**Verdict: Correct.**\n\n**C. Use the chromosome-level ratio $$R \\;=\\; \\frac{\\text{total reads mapped to chromosome Y}}{\\text{total reads mapped to chromosome X}}$$, and declare discordance if $R$ exceeds a fixed cutoff for female-labeled samples or falls below it for male-labeled samples.**\nThis metric uses a ratio of raw read counts aggregated at the chromosome level.\n- It is not robust to the vast differences in gene content and expression patterns on the X chromosome. The denominator, `total reads mapped to chromosome X`, is a function of the a large number of genes, many of which are unrelated to sex determination and whose expression can vary dramatically due to biological state, making the ratio $R$ unstable and noisy.\n- It fails to normalize for gene length.\n- By using \"total reads mapped\", it fails to account for mapping ambiguity from PARs and other homologous regions.\n- This approach is less specific and sensitive than a gene-set based approach like B.\n**Verdict: Incorrect.**\n\n**D. Use the mitochondrial read fraction $$M \\;=\\; \\frac{\\text{reads mapped to mitochondrial genome}}{N}$$, and declare contamination if $M$ is unusually high compared to the cohort median.**\nThis metric measures the proportion of mitochondrial reads.\n- While a high mitochondrial read fraction is a valid and important QC metric, it typically indicates issues with cell viability (e.g., apoptosis) or RNA quality, not sample identity with respect to sex.\n- This metric does not use sex-specific gene expression at all. It provides no information to distinguish a male sample from a female sample.\n- Therefore, it is completely inappropriate for the stated task of detecting sex discordance.\n**Verdict: Incorrect.**\n\n**E. Compute the proportion $$P \\;=\\; \\frac{1}{|Y|}\\sum_{g\\in Y}\\mathbf{1}\\{c_g \\geq 1\\}$$, and declare contamination if $P$ exceeds a fixed threshold in a female-labeled sample.**\nThis metric calculates the fraction of genes in the set $Y$ that are detected with at least one read.\n- The condition $c_g \\geq 1$ is highly sensitive to sequencing depth. A shallowly sequenced male sample might fail to detect some Y-linked genes, while a deeply sequenced female sample might detect spurious reads for several Y-linked genes. This violates the robustness-to-depth requirement.\n- It discards all quantitative expression information by binarizing the counts. A gene with one read is treated identically to a gene with thousands of reads, which is a major loss of information and statistical power.\n- The metric is less powerful and robust than one based on a properly normalized expression measure like TPM.\n**Verdict: Incorrect.**\n\nIn summary, Option B is the only one that proposes a metric satisfying all the critical requirements for a robust, sensitive, and specific sex-check statistic in RNA-seq analysis. It is well-designed from both a biological and a bioinformatic perspective.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Large-scale sequencing projects often involve processing samples in different groups, or 'batches', which can introduce systematic, non-biological variation that obscures true biological signals. This hands-on exercise guides you through implementing a powerful statistical method to computationally correct for these batch effects using a linear model . This practice will solidify your understanding of how to model and remove unwanted sources of variation, a fundamental skill for analyzing complex, real-world genomic datasets.",
            "id": "2417834",
            "problem": "You are given the task of formalizing and implementing a principled approach to remove batch effects from Ribonucleic Acid sequencing (RNA-seq) data using a linear model. Consider a count matrix with genes indexed by $g \\in \\{1,\\dots,G\\}$ and samples indexed by $i \\in \\{1,\\dots,N\\}$. Let $c_{g,i} \\in \\mathbb{N}_0$ be the observed raw read count for gene $g$ in sample $i$. Each sample has two binary covariates: a biological condition indicator $z_i \\in \\{0,1\\}$ and a batch indicator $b_i \\in \\{0,1\\}$. The goal is to model batch effects as an additive term in a linear model for transformed expression and then computationally remove the batch contribution.\n\nDefine the following from first principles.\n\n1. Size-factor normalization. For each sample $i$, let the library size be $L_i = \\sum_{g=1}^G c_{g,i}$. Define the size factor $s_i$ by\n$$\ns_i = \\frac{L_i}{\\frac{1}{N}\\sum_{j=1}^N L_j}.\n$$\n2. Log-transformed normalized expression. For a fixed pseudo-count $c_0 > 0$, define\n$$\ny_{g,i} = \\log_2\\Big(\\frac{c_{g,i}}{s_i} + c_0\\Big).\n$$\nUse $c_0 = 1.0$.\n\n3. Linear model per gene. For each gene $g$, model $y_{g,i}$ across samples $i$ using ordinary least squares with the design matrix having three columns: an intercept, the condition indicator, and the batch indicator. That is, for each $g$,\n$$\ny_{g,i} = \\beta_{g,0} + \\beta_{g,\\text{cond}}\\; z_i + \\beta_{g,\\text{batch}}\\; b_i + \\varepsilon_{g,i},\n$$\nwhere $\\varepsilon_{g,i}$ are zero-mean residuals. Estimate $(\\beta_{g,0}, \\beta_{g,\\text{cond}}, \\beta_{g,\\text{batch}})$ by minimizing the sum of squared residuals over samples $i \\in \\{1,\\dots,N\\}$.\n\n4. Batch-effect removal. For each gene $g$ and sample $i$, define the batch-corrected expression\n$$\n\\tilde{y}_{g,i} = y_{g,i} - \\beta_{g,\\text{batch}}\\; b_i.\n$$\n\n5. Evaluation statistic. For each gene $g$ and for each condition level $z \\in \\{0,1\\}$ for which both batches have at least one sample with that condition (that is, there exists at least one $i$ with $z_i = z$ and $b_i = 0$, and at least one $i$ with $z_i = z$ and $b_i = 1$), compute\n$$\nd_{g}(z) = \\Big(\\text{mean of } \\tilde{y}_{g,i} \\text{ over } i \\text{ with } z_i = z,\\, b_i = 1\\Big) - \\Big(\\text{mean of } \\tilde{y}_{g,i} \\text{ over } i \\text{ with } z_i = z,\\, b_i = 0\\Big).\n$$\nFor each gene $g$, define\n$$\nD_g = \\max_{z \\in \\{0,1\\} \\text{ valid}} \\left| d_{g}(z) \\right|,\n$$\nwhere the maximum is taken over condition levels $z$ that are valid as described above. If no condition level is valid for gene $g$, define $D_g = 0$.\n\nFor each test case below, compute the evaluation statistic\n$$\nR = \\max_{g \\in \\{1,\\dots,G\\}} D_g,\n$$\nand report $R$ rounded to six digits after the decimal point.\n\nTest suite. Implement the above definitions exactly for the following three independent test cases. In each case, $G$ is the number of genes (rows), $N$ is the number of samples (columns), the count matrix is $C = (c_{g,i})$, the condition vector is $(z_1,\\dots,z_N)$, and the batch vector is $(b_1,\\dots,b_N)$.\n\n- Test case $1$:\n  - $G = 3$, $N = 4$.\n  - Counts $C$ (rows $g=1,2,3$; columns $i=1,2,3,4$):\n    $$\n    \\begin{bmatrix}\n    100 & 150 & 160 & 240 \\\\\n    80 & 160 & 128 & 256 \\\\\n    40 & 40 & 64 & 64\n    \\end{bmatrix}\n    $$\n  - Condition vector $(z_1,z_2,z_3,z_4) = (0,1,0,1)$.\n  - Batch vector $(b_1,b_2,b_3,b_4) = (0,0,1,1)$.\n\n- Test case $2$:\n  - $G = 3$, $N = 4$.\n  - Counts $C$:\n    $$\n    \\begin{bmatrix}\n    60 & 90 & 90 & 120 \\\\\n    30 & 30 & 30 & 60 \\\\\n    10 & 20 & 20 & 20\n    \\end{bmatrix}\n    $$\n  - Condition vector $(z_1,z_2,z_3,z_4) = (0,1,1,0)$.\n  - Batch vector $(b_1,b_2,b_3,b_4) = (0,0,0,1)$.\n\n- Test case $3$:\n  - $G = 5$, $N = 4$.\n  - Counts $C$:\n    $$\n    \\begin{bmatrix}\n    200 & 300 & 260 & 390 \\\\\n    500 & 750 & 500 & 750 \\\\\n    0 & 0 & 5 & 8 \\\\\n    1000 & 1500 & 1000 & 1500 \\\\\n    0 & 0 & 0 & 0\n    \\end{bmatrix}\n    $$\n  - Condition vector $(z_1,z_2,z_3,z_4) = (0,0,1,1)$.\n  - Batch vector $(b_1,b_2,b_3,b_4) = (0,1,0,1)$.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list of the three rounded values $R$ for the test cases, enclosed in square brackets. For example, an acceptable output format is\n$$\n[\\text{result}_1,\\text{result}_2,\\text{result}_3].\n$$\nAll numeric outputs must be floats rounded to exactly six digits after the decimal point. No other text should be printed.",
            "solution": "The problem requires the formalization and implementation of a computational procedure to remove batch effects from RNA-sequencing (RNA-seq) count data. The methodology is based on a linear model applied to log-transformed, normalized expression values. The efficacy of the batch correction is then evaluated using a defined statistical metric. The entire procedure will be executed step-by-step as specified.\n\nThe fundamental principle is to model the observed gene expression as a linear combination of effects: a baseline expression level (intercept), an effect due to the biological condition of interest, and an undesirable effect due to the experimental batch. By estimating the magnitude of the batch effect using ordinary least squares (OLS), we can then arithmetically subtract this component from the data, yielding batch-corrected expression values.\n\nThe computational steps are as follows:\n\nFirst, we address the technical artifact of varying sequencing depth across samples. This is accomplished through size-factor normalization. For each sample $i$, the library size $L_i$ is calculated as the total sum of read counts across all genes $G$: $L_i = \\sum_{g=1}^G c_{g,i}$. The size factor for sample $i$, denoted $s_i$, is the ratio of its library size to the average library size across all $N$ samples:\n$$\ns_i = \\frac{L_i}{\\frac{1}{N}\\sum_{j=1}^N L_j}\n$$\nNormalizing the raw count $c_{g,i}$ by its corresponding sample's size factor $s_i$ adjusts the counts to a common scale.\n\nSecond, the normalized counts are transformed to a logarithmic scale. This transformation serves two purposes: it stabilizes the variance, as the variance of RNA-seq data often depends on the mean, and it converts the multiplicative relationships inherent in count data into an additive framework suitable for linear modeling. A pseudo-count, $c_0 = 1.0$, is added to prevent taking the logarithm of zero and to moderate the variance of low-expression genes. The log-transformed expression $y_{g,i}$ is defined as:\n$$\ny_{g,i} = \\log_2\\Big(\\frac{c_{g,i}}{s_i} + c_0\\Big)\n$$\n\nThird, for each gene $g$, a linear model is fitted to the log-transformed expression values $y_{g,i}$ across all samples $i=1, \\dots, N$. The model regresses $y_{g,i}$ on the provided covariates: an intercept term, the binary condition indicator $z_i$, and the binary batch indicator $b_i$. The model is:\n$$\ny_{g,i} = \\beta_{g,0} + \\beta_{g,\\text{cond}}\\; z_i + \\beta_{g,\\text{batch}}\\; b_i + \\varepsilon_{g,i}\n$$\nIn matrix notation for a single gene $g$, this is $Y_g = X\\beta_g + \\varepsilon_g$, where $Y_g$ is the $N \\times 1$ vector of expression values for gene $g$, $X$ is the $N \\times 3$ design matrix with columns for the intercept (all ones), the condition vector $(z_1, \\dots, z_N)^T$, and the batch vector $(b_1, \\dots, b_N)^T$. The coefficient vector $\\beta_g = (\\beta_{g,0}, \\beta_{g,\\text{cond}}, \\beta_{g,\\text{batch}})^T$ is estimated using ordinary least squares (OLS), which minimizes the sum of squared residuals $\\sum_i \\varepsilon_{g,i}^2$. The OLS estimate is given by $\\hat{\\beta}_g = (X^T X)^{-1} X^T Y_g$, provided the design matrix $X$ has full column rank. We are specifically interested in $\\hat{\\beta}_{g,\\text{batch}}$, the estimated batch effect for gene $g$.\n\nFourth, the batch effect is removed. For each gene $g$ and sample $i$, the batch-corrected expression value $\\tilde{y}_{g,i}$ is computed by subtracting the estimated batch component from the original log-transformed value:\n$$\n\\tilde{y}_{g,i} = y_{g,i} - \\hat{\\beta}_{g,\\text{batch}}\\; b_i\n$$\nThis correction is only applied to samples belonging to batch $b_i=1$, effectively adjusting their expression levels to match the baseline of batch $b_i=0$.\n\nFifth, the success of the correction is evaluated. For each gene $g$, we measure the residual mean difference in expression between batches, stratified by the biological condition. For a given condition level $z \\in \\{0,1\\}$, if there are samples from both batches ($b_i=0$ and $b_i=1$) with that condition, we compute:\n$$\nd_{g}(z) = \\Big(\\text{mean}_{i: z_i=z, b_i=1} \\tilde{y}_{g,i}\\Big) - \\Big(\\text{mean}_{i: z_i=z, b_i=0} \\tilde{y}_{g,i}\\Big)\n$$\nAn effective correction should result in $d_g(z) \\approx 0$. The statistic $D_g$ captures the worst-case residual batch effect for gene $g$ across valid condition levels:\n$$\nD_g = \\max_{z \\in \\{0,1\\} \\text{ valid}} \\left| d_{g}(z) \\right|\n$$\nIf no condition level is valid for comparison, $D_g$ is defined as $0$.\n\nFinally, the overall evaluation statistic $R$ for a given dataset is the maximum of these gene-wise statistics, representing the largest residual batch effect present in the data after correction:\n$$\nR = \\max_{g \\in \\{1,\\dots,G\\}} D_g\n$$\n\nThis entire sequence of calculations is implemented to solve for $R$ for each of the provided test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_case(C, z, b):\n    \"\"\"\n    Solves a single test case for batch effect removal and evaluation.\n\n    Args:\n        C (np.ndarray): Count matrix (G x N).\n        z (np.ndarray): Condition vector (N,).\n        b (np.ndarray): Batch vector (N,).\n\n    Returns:\n        float: The evaluation statistic R, rounded to 6 decimal places.\n    \"\"\"\n    G, N = C.shape\n    C = C.astype(np.float64)\n    z = z.astype(np.float64)\n    b = b.astype(np.float64)\n    c0 = 1.0\n\n    # Step 1: Size-factor normalization\n    L = C.sum(axis=0)\n    L_mean = L.mean()\n    s = L / L_mean\n\n    # Step 2: Log-transformed normalized expression\n    # Use np.divide and np.newaxis for broadcasting s across rows of C\n    y = np.log2(np.divide(C, s[np.newaxis, :]) + c0)\n\n    # Step 3: Linear model per gene\n    # Construct the design matrix X\n    X = np.vstack([np.ones(N), z, b]).T\n\n    # Check for collinearity. If not full rank, OLS is ill-defined.\n    # The problem statement guarantees full-rank designs for the test cases.\n    # if np.linalg.matrix_rank(X) < X.shape[1]:\n    #     raise ValueError(\"Design matrix is not full column rank.\")\n\n    # Fit the model for each gene to get beta_batch\n    beta_batch_g = np.zeros(G)\n    for g in range(G):\n        # np.linalg.lstsq returns a tuple; the first element is the solution vector\n        beta_hat, _, _, _ = np.linalg.lstsq(X, y[g, :], rcond=None)\n        beta_batch_g[g] = beta_hat[2]\n\n    # Step 4: Batch-effect removal\n    # Subtract beta_batch * b_i from each y_gi\n    # This can be done with broadcasting\n    y_tilde = y - beta_batch_g[:, np.newaxis] * b[np.newaxis, :]\n\n    # Step 5: Evaluation statistic\n    D_g = np.zeros(G)\n    for g in range(G):\n        d_g_z_abs = []\n        \n        # Check condition z=0\n        z0_indices = np.where(z == 0)[0]\n        z0_b0_indices = np.where((z == 0) & (b == 0))[0]\n        z0_b1_indices = np.where((z == 0) & (b == 1))[0]\n        if len(z0_b0_indices) > 0 and len(z0_b1_indices) > 0:\n            mean_b1_z0 = np.mean(y_tilde[g, z0_b1_indices])\n            mean_b0_z0 = np.mean(y_tilde[g, z0_b0_indices])\n            d_g_0 = mean_b1_z0 - mean_b0_z0\n            d_g_z_abs.append(np.abs(d_g_0))\n            \n        # Check condition z=1\n        z1_indices = np.where(z == 1)[0]\n        z1_b0_indices = np.where((z == 1) & (b == 0))[0]\n        z1_b1_indices = np.where((z == 1) & (b == 1))[0]\n        if len(z1_b0_indices) > 0 and len(z1_b1_indices) > 0:\n            mean_b1_z1 = np.mean(y_tilde[g, z1_b1_indices])\n            mean_b0_z1 = np.mean(y_tilde[g, z1_b0_indices])\n            d_g_1 = mean_b1_z1 - mean_b0_z1\n            d_g_z_abs.append(np.abs(d_g_1))\n\n        if len(d_g_z_abs) > 0:\n            D_g[g] = np.max(d_g_z_abs)\n        else:\n            D_g[g] = 0.0\n\n    # Final result R\n    R = np.max(D_g) if len(D_g) > 0 else 0.0\n    \n    return round(R, 6)\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run them, and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {\n            \"C\": np.array([\n                [100, 150, 160, 240],\n                [80, 160, 128, 256],\n                [40, 40, 64, 64]\n            ]),\n            \"z\": np.array([0, 1, 0, 1]),\n            \"b\": np.array([0, 0, 1, 1])\n        },\n        # Test case 2\n        {\n            \"C\": np.array([\n                [60, 90, 90, 120],\n                [30, 30, 30, 60],\n                [10, 20, 20, 20]\n            ]),\n            \"z\": np.array([0, 1, 1, 0]),\n            \"b\": np.array([0, 0, 0, 1])\n        },\n        # Test case 3\n        {\n            \"C\": np.array([\n                [200, 300, 260, 390],\n                [500, 750, 500, 750],\n                [0, 0, 5, 8],\n                [1000, 1500, 1000, 1500],\n                [0, 0, 0, 0]\n            ]),\n            \"z\": np.array([0, 0, 1, 1]),\n            \"b\": np.array([0, 1, 0, 1])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(case[\"C\"], case[\"z\"], case[\"b\"])\n        results.append(f\"{result:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}