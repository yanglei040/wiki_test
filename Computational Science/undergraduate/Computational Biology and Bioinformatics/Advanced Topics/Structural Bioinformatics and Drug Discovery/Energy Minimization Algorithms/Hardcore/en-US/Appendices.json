{
    "hands_on_practices": [
        {
            "introduction": "Gradient-based methods are the workhorses of energy minimization, used to find the nearest local energy minimum from a given starting structure. However, not all gradient methods are created equal. This practice  challenges you to implement and compare two classic algorithms, Steepest Descent and Conjugate Gradient, to discover firsthand how the curvature of the energy landscape dramatically impacts their performance and why choosing the right algorithm is crucial for efficient minimization.",
            "id": "2388054",
            "problem": "You are tasked with designing and implementing a program that, for a family of strictly convex quadratic molecular mechanics energy models, compares the iteration counts of two classical energy minimization methods—Steepest Descent (SD) and Conjugate Gradient (CG)—when minimizing the energy from a prescribed initial configuration. The energy to be minimized is the quadratic approximation $$E(\\mathbf{x})=\\tfrac{1}{2}\\,\\mathbf{x}^{\\mathsf{T}}\\mathbf{H}\\,\\mathbf{x},$$ where $\\mathbf{x}\\in\\mathbb{R}^{n}$ are Cartesian displacements from a reference conformation and $\\mathbf{H}\\in\\mathbb{R}^{n\\times n}$ is a symmetric positive definite matrix (the Hessian). The gradient is $\\nabla E(\\mathbf{x})=\\mathbf{H}\\,\\mathbf{x}$. The convergence rate comparison between the methods must be quantified by the number of iterations required to satisfy a specified stopping criterion.\n\nDefinitions and requirements:\n- Let the stopping criterion be the first iteration index $k$ such that the Euclidean norm of the gradient satisfies $$\\lVert\\nabla E(\\mathbf{x}_{k})\\rVert_{2}\\leq \\tau\\,\\lVert\\nabla E(\\mathbf{x}_{0})\\rVert_{2},$$ with tolerance $\\tau=10^{-8}$ and initial state $\\mathbf{x}_{0}$ defined below.\n- An iteration is defined as one update of $\\mathbf{x}$ along the current search direction with exact line minimization along that direction. For both Steepest Descent and Conjugate Gradient, the step length at iteration $k$ is the unique minimizer $\\alpha_{k}$ of the univariate function $E(\\mathbf{x}_{k}+\\alpha\\,\\mathbf{p}_{k})$ with respect to $\\alpha\\in\\mathbb{R}$, where $\\mathbf{p}_{k}$ is the method-dependent search direction at iteration $k$.\n- For Steepest Descent, the search direction at each iteration is $\\mathbf{p}_{k}=-\\nabla E(\\mathbf{x}_{k})$.\n- For Conjugate Gradient, the search directions are mutually $\\mathbf{H}$-conjugate.\n\nTest suite (four test cases):\nFor each test case, the Hessian is diagonal, $\\mathbf{H}=\\operatorname{diag}(\\lambda_{1},\\dots,\\lambda_{n})$, with entries following a geometric progression that sets the condition number $\\kappa$:\n$$\\lambda_{i}=\\exp\\!\\Big(\\ln(\\kappa)\\cdot\\frac{i-1}{n-1}\\Big),\\quad i\\in\\{1,\\dots,n\\},$$\nso that $\\lambda_{1}=1$ and $\\lambda_{n}=\\kappa$. The initial state is componentwise\n$$x_{0,i}=\\sin(i),\\quad i\\in\\{1,\\dots,n\\},$$\nwith the sine function evaluated in radians. The stopping tolerance is $\\tau=10^{-8}$ for all cases. The specific test cases are:\n- Case $1$ (helix-like, highly anisotropic curvature): $n=60$, $\\kappa=1000$.\n- Case $2$ (globular-like, moderately anisotropic curvature): $n=60$, $\\kappa=10$.\n- Case $3$ (boundary case, already minimized): $n=60$, $\\kappa=50$, and $\\mathbf{x}_{0}=\\mathbf{0}$.\n- Case $4$ (small well-conditioned instance): $n=5$, $\\kappa=50$.\n\nFor each test case, your program must compute:\n- the integer iteration count for Steepest Descent, denoted $I_{\\mathrm{SD}}$;\n- the integer iteration count for Conjugate Gradient, denoted $I_{\\mathrm{CG}}$; and\n- the integer difference $D=I_{\\mathrm{SD}}-I_{\\mathrm{CG}}$.\n\nIf the stopping criterion is satisfied at the initial state, the corresponding iteration count must be $0$. For Conjugate Gradient, you must not exceed $n$ iterations. For Steepest Descent, you must not exceed a safety cap of $100000$ iterations; if the stopping criterion is not met by that cap (which should not occur with the parameters above), return the cap as the iteration count.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as\n$$[I_{\\mathrm{SD}}^{(1)},\\,I_{\\mathrm{CG}}^{(1)},\\,D^{(1)},\\,I_{\\mathrm{SD}}^{(2)},\\,I_{\\mathrm{CG}}^{(2)},\\,D^{(2)},\\,I_{\\mathrm{SD}}^{(3)},\\,I_{\\mathrm{CG}}^{(3)},\\,D^{(3)},\\,I_{\\mathrm{SD}}^{(4)},\\,I_{\\mathrm{CG}}^{(4)},\\,D^{(4)}],$$\nwhere the superscript $(j)$ refers to test case $j\\in\\{1,2,3,4\\}$. No other text must be printed.",
            "solution": "The problem statement is subjected to validation and is found to be scientifically grounded, well-posed, and objective. It presents a standard numerical optimization task: minimizing a strictly convex quadratic function using two classical iterative methods, Steepest Descent (SD) and Conjugate Gradient (CG). All parameters, definitions, and conditions are specified with sufficient precision to permit a unique and meaningful solution. The problem is therefore valid.\n\nThe mathematical problem is to find the minimum of the quadratic energy function $E(\\mathbf{x}): \\mathbb{R}^n \\to \\mathbb{R}$, defined as:\n$$\nE(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^{\\mathsf{T}}\\mathbf{H}\\,\\mathbf{x}\n$$\nwhere $\\mathbf{x} \\in \\mathbb{R}^n$ represents the Cartesian displacements and $\\mathbf{H} \\in \\mathbb{R}^{n \\times n}$ is a symmetric positive definite (SPD) Hessian matrix. The positive definite nature of $\\mathbf{H}$ ensures that $E(\\mathbf{x})$ is strictly convex and has a unique global minimum at $\\mathbf{x} = \\mathbf{0}$. The gradient of the energy function, which is required for the optimization algorithms, is given by:\n$$\n\\nabla E(\\mathbf{x}) = \\mathbf{g}(\\mathbf{x}) = \\mathbf{H}\\mathbf{x}\n$$\nBoth optimization methods start from an initial point $\\mathbf{x}_0$ and generate a sequence of points $\\{\\mathbf{x}_k\\}$ that iteratively approach the minimum. The update rule is of the general form $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$, where $\\mathbf{p}_k$ is a search direction and $\\alpha_k$ is the step length. The problem specifies an exact line search, meaning $\\alpha_k$ is chosen to minimize $E(\\mathbf{x}_k + \\alpha \\mathbf{p}_k)$ with respect to $\\alpha$. For the given quadratic energy function, this optimal step length has an analytical solution:\n$$\n\\alpha_k = \\underset{\\alpha \\in \\mathbb{R}}{\\arg\\min}\\, E(\\mathbf{x}_k + \\alpha \\mathbf{p}_k) = -\\frac{\\mathbf{g}_k^{\\mathsf{T}}\\mathbf{p}_k}{\\mathbf{p}_k^{\\mathsf{T}}\\mathbf{H}\\mathbf{p}_k}\n$$\nwhere $\\mathbf{g}_k = \\nabla E(\\mathbf{x}_k)$.\n\nThe Steepest Descent (SD) method employs the negative gradient as its search direction at each step:\n$$\n\\mathbf{p}_k = -\\mathbf{g}_k\n$$\nSubstituting this into the formula for $\\alpha_k$ yields the specific step length for SD:\n$$\n\\alpha_k^{\\mathrm{SD}} = -\\frac{\\mathbf{g}_k^{\\mathsf{T}}(-\\mathbf{g}_k)}{(-\\mathbf{g}_k)^{\\mathsf{T}}\\mathbf{H}(-\\mathbf{g}_k)} = \\frac{\\mathbf{g}_k^{\\mathsf{T}}\\mathbf{g}_k}{\\mathbf{g}_k^{\\mathsf{T}}\\mathbf{H}\\mathbf{g}_k}\n$$\nThe SD algorithm proceeds by iteratively updating the position $\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k^{\\mathrm{SD}}\\mathbf{g}_k$. Its convergence rate is known to degrade significantly as the condition number $\\kappa(\\mathbf{H})$ of the Hessian increases, leading to a characteristic zigzagging path toward the minimum.\n\nThe Conjugate Gradient (CG) method improves upon SD by choosing search directions that are $\\mathbf{H}$-conjugate (i.e., $\\mathbf{p}_i^{\\mathsf{T}}\\mathbf{H}\\mathbf{p}_j = 0$ for $i \\neq j$). This prevents repeated minimization along the same directions. The search direction is updated at each iteration:\n$$\n\\mathbf{p}_k = -\\mathbf{g}_k + \\beta_k \\mathbf{p}_{k-1}\n$$\nwith $\\mathbf{p}_0 = -\\mathbf{g}_0$. A common choice for $\\beta_k$, known as the Fletcher-Reeves formula, is:\n$$\n\\beta_k = \\frac{\\mathbf{g}_k^{\\mathsf{T}}\\mathbf{g}_k}{\\mathbf{g}_{k-1}^{\\mathsf{T}}\\mathbf{g}_{k-1}}\n$$\nThis choice is equivalent to others, such as Polak-Ribière, for strictly convex quadratic functions with exact line search. A key property of exact line search is that the new gradient $\\mathbf{g}_k$ is orthogonal to the previous search direction $\\mathbf{p}_{k-1}$, so $\\mathbf{g}_k^{\\mathsf{T}}\\mathbf{p}_{k-1} = 0$. Using this, the numerator of the step length formula for CG simplifies:\n$$\n\\mathbf{g}_k^{\\mathsf{T}}\\mathbf{p}_k = \\mathbf{g}_k^{\\mathsf{T}}(-\\mathbf{g}_k + \\beta_k \\mathbf{p}_{k-1}) = -\\mathbf{g}_k^{\\mathsf{T}}\\mathbf{g}_k\n$$\nThus, the step length for CG can be calculated as:\n$$\n\\alpha_k^{\\mathrm{CG}} = \\frac{\\mathbf{g}_k^{\\mathsf{T}}\\mathbf{g}_k}{\\mathbf{p}_k^{\\mathsf{T}}\\mathbf{H}\\mathbf{p}_k}\n$$\nThe CG method has the remarkable property that, in exact arithmetic, it is guaranteed to find the exact minimum of a quadratic function in at most $n$ iterations.\n\nThe stopping criterion for both methods is when the Euclidean norm of the gradient falls below a relative tolerance:\n$$\n\\lVert\\mathbf{g}_k\\rVert_2 \\leq \\tau \\lVert\\mathbf{g}_0\\rVert_2\n$$\nwhere $\\mathbf{g}_k = \\nabla E(\\mathbf{x}_k)$ and $\\tau=10^{-8}$. An iteration is counted as one update from $\\mathbf{x}_k$ to $\\mathbf{x}_{k+1}$. If the condition is met at $\\mathbf{x}_0$, the iteration count is $0$.\n\nThe test cases specify a diagonal Hessian $\\mathbf{H} = \\operatorname{diag}(\\lambda_1, \\dots, \\lambda_n)$, which greatly simplifies matrix-vector products $\\mathbf{H}\\mathbf{v}$ to element-wise products. The eigenvalues $\\lambda_i$ are constructed to fix the condition number $\\kappa = \\lambda_n/\\lambda_1 = \\kappa/1 = \\kappa$. The implementation will leverage this diagonal structure for efficiency. The case $\\mathbf{x}_0 = \\mathbf{0}$ is handled as a base case, resulting in $0$ iterations as the system is already at the minimum. The provided program implements these two algorithms, applies them to the specified test cases, and computes the required iteration counts $I_{\\mathrm{SD}}$, $I_{\\mathrm{CG}}$, and their difference $D$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef steepest_descent(h_diag, x0, tau, max_iter):\n    \"\"\"\n    Minimizes a quadratic form using the Steepest Descent method.\n    \"\"\"\n    x = x0.copy()\n    g = h_diag * x\n    g0_norm = np.linalg.norm(g)\n\n    # If already at the minimum, iterations = 0.\n    if g0_norm == 0:\n        return 0\n\n    threshold = tau * g0_norm\n\n    for i in range(1, max_iter + 1):\n        g_dot_g = np.dot(g, g)\n        \n        # Calculate alpha_k = (g_k^T * g_k) / (g_k^T * H * g_k)\n        # H is diagonal, so g_k^T * H * g_k = g_k^T * (h_diag * g_k)\n        g_H_g = np.dot(g, h_diag * g)\n        \n        # Avoid division by zero if gradient is effectively zero\n        if g_H_g == 0:\n            return i - 1\n\n        alpha = g_dot_g / g_H_g\n        \n        # Update position: x_{k+1} = x_k - alpha_k * g_k\n        x -= alpha * g\n        \n        # Update gradient for next iteration\n        g = h_diag * x\n        \n        if np.linalg.norm(g) = threshold:\n            return i\n            \n    return max_iter\n\ndef conjugate_gradient(h_diag, x0, tau, n):\n    \"\"\"\n    Minimizes a quadratic form using the Conjugate Gradient method.\n    \"\"\"\n    x = x0.copy()\n    g = h_diag * x\n    g0_norm = np.linalg.norm(g)\n    \n    # If already at the minimum, iterations = 0.\n    if g0_norm == 0:\n        return 0\n\n    threshold = tau * g0_norm\n    \n    p = -g\n    g_sq_norm = np.dot(g, g)\n\n    # CG is guaranteed to converge in at most n iterations for quadratics in exact arithmetic.\n    for i in range(1, n + 1):\n        # Calculate p_k^T * H * p_k\n        p_H_p = np.dot(p, h_diag * p)\n        \n        # Avoid division by zero\n        if p_H_p == 0:\n            # This can happen if p becomes zero, meaning we have likely converged\n            return i - 1\n\n        # alpha_k = (g_k^T * g_k) / (p_k^T * H * p_k)\n        alpha = g_sq_norm / p_H_p\n        \n        # Update position: x_{k+1} = x_k + alpha_k * p_k\n        x += alpha * p\n        \n        # Efficient gradient update: g_{k+1} = g_k + alpha_k * H * p_k\n        g += alpha * (h_diag * p)\n\n        if np.linalg.norm(g) = threshold:\n            return i\n\n        g_new_sq_norm = np.dot(g, g)\n        beta = g_new_sq_norm / g_sq_norm\n        \n        # Update search direction: p_{k+1} = -g_{k+1} + beta_{k+1} * p_k\n        p = -g + beta * p\n        g_sq_norm = g_new_sq_norm\n        \n    return n\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases and prints the results.\n    \"\"\"\n    test_cases = [\n        # (n, kappa)\n        (60, 1000.0),  # Case 1\n        (60, 10.0),    # Case 2\n        (60, 50.0),    # Case 3\n        (5, 50.0),     # Case 4\n    ]\n\n    tau = 1e-8\n    sd_max_iter = 100000\n    \n    results = []\n\n    for i, (n, kappa) in enumerate(test_cases):\n        # Construct Hessian diagonal entries\n        if n == 1:\n            # Special case to avoid division by zero in the formula for lambda_i\n            h_diag = np.array([kappa])\n        else:\n            indices = np.arange(n, dtype=float)\n            h_diag = np.exp(np.log(kappa) * indices / (n - 1))\n        \n        # Construct initial state x0\n        # Case 3 has a special x0\n        if i == 2:  # 0-indexed case 3\n            x0 = np.zeros(n)\n        else:\n            # i from 1 to n for sin(i)\n            indices_for_sin = np.arange(1, n + 1)\n            x0 = np.sin(indices_for_sin)\n\n        # Run both algorithms\n        i_sd = steepest_descent(h_diag, x0, tau, sd_max_iter)\n        i_cg = conjugate_gradient(h_diag, x0, tau, n)\n        \n        difference = i_sd - i_cg\n        \n        results.extend([i_sd, i_cg, difference])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While gradient methods are excellent for finding the *nearest* minimum, they often get trapped in local energy wells on a complex landscape. To explore the broader conformational space and seek out global energy minima, we can turn to stochastic methods. This exercise  guides you through implementing a Metropolis Monte Carlo simulation, a powerful algorithm that uses random moves and a physics-based acceptance probability to model the folding of a polymer chain and escape from high-energy traps.",
            "id": "2388039",
            "problem": "Consider a hydrophobic polymer chain of length $N=5$ embedded on a two-dimensional square lattice of side length $L$ with periodic boundary conditions (a torus). The polymer consists of $N$ indistinguishable monomers occupying $N$ distinct lattice sites, with the connectivity constraint that consecutive monomers are at unit lattice distance (Manhattan distance $1$) and the chain is self-avoiding (no two monomers occupy the same site). All monomers are hydrophobic, and the interaction energy is defined as follows. For a conformation with monomer coordinates $\\{\\mathbf{r}_i\\}_{i=0}^{N-1}$, where each $\\mathbf{r}_i$ is a lattice site represented by integer coordinates $(x_i,y_i)$ with $x_i \\in \\{0,1,\\dots,L-1\\}$ and $y_i \\in \\{0,1,\\dots,L-1\\}$, define the number of non-bonded nearest-neighbor contacts $C$ as the cardinality of unordered pairs $\\{i,j\\}$ such that $|i-j|1$ and the toroidal lattice distance between $\\mathbf{r}_i$ and $\\mathbf{r}_j$ is exactly $1$. The toroidal lattice distance between two sites $(x,y)$ and $(x',y')$ is computed by taking the minimal wrapped coordinate differences $\\Delta x = \\min\\{|x-x'|, L - |x-x'|\\}$ and $\\Delta y = \\min\\{|y-y'|, L - |y-y'|\\}$, and defining the sites to be nearest neighbors when either $(\\Delta x=1,\\Delta y=0)$ or $(\\Delta x=0,\\Delta y=1)$. The energy is given by\n$$\nE(\\{\\mathbf{r}_i\\}) = -\\varepsilon \\, C,\n$$\nwith $\\varepsilon0$ a fixed energy scale. Throughout, use $\\varepsilon=1$ and Boltzmann constant $k_{\\mathrm{B}}=1$, so energy and temperature are in dimensionless units.\n\nFor each test case, the initial conformation is specified deterministically as the straight horizontal chain occupying the sites\n$$\n\\mathbf{r}_i = (i \\bmod L,\\, 0), \\quad i \\in \\{0,1,2,3,4\\},\n$$\nwhich satisfies the connectivity and self-avoidance constraints for all $L \\ge 5$. Time evolution proceeds via discrete attempts to alter the conformation while preserving connectivity and self-avoidance. At each attempt, a single local move is proposed that modifies the position of either one end monomer or a single interior monomer, subject to preserving unit bond lengths to its immediate neighbors along the chain. If the proposed conformation violates self-avoidance, it is rejected. Otherwise, the change in energy $\\Delta E$ is computed and the move is accepted with probability\n$$\np_{\\mathrm{acc}} = \n\\begin{cases}\n1,  \\text{if } \\Delta E \\le 0,\\\\\n\\exp(-\\Delta E/T),  \\text{if } \\Delta E > 0,\n\\end{cases}\n$$\nwhere $T$ is the temperature for that test case. If $T=0$, interpret the acceptance rule as accepting only moves with $\\Delta E \\le 0$. Across all visited conformations, including the initial conformation, keep track of the minimum energy encountered. After a specified number of attempts $M$, report the minimum energy found in units of $\\varepsilon$ as an integer.\n\nAssume the following concrete local moves at each attempt. With equal probability, choose one of two move families:\n- End move: choose one end monomer, i.e., index $0$ or $N-1$, with equal probability. Let its only bonded neighbor be monomer $1$ or $N-2$, respectively. Propose to move the chosen end monomer to one of the vacant lattice sites that are nearest neighbors (in the toroidal sense) of its bonded neighbor, chosen uniformly at random among the available sites. If no such site exists, the attempt is a rejection.\n- Corner flip: choose uniformly at random an interior monomer with index $i \\in \\{1,2,3\\}$. If the vectors from $\\mathbf{r}_i$ to its bonded neighbors $\\mathbf{r}_{i-1}$ and $\\mathbf{r}_{i+1}$ are orthogonal unit lattice vectors on the torus (that is, one is $(\\pm 1, 0)$ and the other $(0,\\pm 1)$ in minimal wrapped coordinates), propose to move monomer $i$ to the unique other lattice site that is a nearest neighbor of both $\\mathbf{r}_{i-1}$ and $\\mathbf{r}_{i+1}$, namely $\\mathbf{r}'_i = \\mathbf{r}_i + (\\mathbf{r}_{i-1} - \\mathbf{r}_i) + (\\mathbf{r}_{i+1} - \\mathbf{r}_i)$ computed with minimal wrapped displacements and then reduced modulo $L$ into $\\{0,1,\\dots,L-1\\}^2$. If that site is occupied by another monomer, the attempt is a rejection.\n\nImplement the above precisely defined dynamics and tracking of the minimum energy. For each test case below, run exactly $M$ independent move attempts starting from the specified initial conformation and using the specified pseudorandom seed to initialize a pseudorandom number generator, so that the sequence of proposed moves is deterministic for the test. The required output for all test cases is a single line containing the list of minimum energies found, in the specified order of test cases, as a comma-separated list enclosed in square brackets.\n\nUse the following test suite, each test case given as a tuple $(L,M,T,\\text{seed})$ with all values written in the same order:\n- Test A (general exploration): $(L,M,T,\\text{seed}) = (\\,6,\\,100000,\\,0.8,\\,20231102\\,)$.\n- Test B (boundary condition with no moves): $(L,M,T,\\text{seed}) = (\\,5,\\,0,\\,0.5,\\,1\\,)$.\n- Test C (high-temperature exploration): $(L,M,T,\\text{seed}) = (\\,6,\\,30000,\\,5.0,\\,777\\,)$.\n- Test D (low-temperature limited exploration): $(L,M,T,\\text{seed}) = (\\,6,\\,5000,\\,0.2,\\,424242\\,)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[\\text{result}_A,\\text{result}_B,\\text{result}_C,\\text{result}_D]$. Report energies in units of $\\varepsilon$ as integers.",
            "solution": "The problem requires the implementation of a Metropolis Monte Carlo simulation for a self-avoiding polymer chain on a two-dimensional toroidal lattice. The objective is to find the minimum energy encountered during a fixed number of simulation steps for several test cases. The problem is well-defined, scientifically sound, and computationally feasible. It is a standard problem in computational statistical physics, often used to model polymer folding.\n\nThe system state is a single polymer chain composed of $N=5$ monomers. The conformation is described by the set of monomer coordinates $\\{\\mathbf{r}_i\\}_{i=0}^{N-1}$, where each $\\mathbf{r}_i=(x_i, y_i)$ is a site on a square lattice of size $L \\times L$ with periodic boundary conditions. The coordinates are integers, $x_i, y_i \\in \\{0, 1, \\dots, L-1\\}$. The chain must satisfy two constraints: connectivity, meaning consecutive monomers $\\mathbf{r}_i$ and $\\mathbf{r}_{i+1}$ are nearest neighbors on the lattice, and self-avoidance, meaning $\\mathbf{r}_i \\neq \\mathbf{r}_j$ for $i \\neq j$.\n\nThe energy of a given conformation is defined by the number of favorable contacts between non-bonded monomers. Specifically, $E = -\\varepsilon C$, where $\\varepsilon=1$ is the energy unit and $C$ is the number of non-bonded, nearest-neighbor contacts. A pair of monomers $\\{i,j\\}$ forms a non-bonded contact if their sequence separation is greater than one, i.e., $|i-j|  1$, and their spatial distance on the toroidal lattice is exactly one. The toroidal Manhattan distance between two sites $\\mathbf{r}=(x,y)$ and $\\mathbf{r}'=(x',y')$ is given by $\\min(|x-x'|, L - |x-x'|) + \\min(|y-y'|, L-|y-y'|)$.\n\nThe simulation proceeds via the Metropolis-Hastings algorithm. Starting from a specified initial conformation, a sequence of $M$ move attempts is performed. At each attempt, a new conformation is proposed by applying a local move to the current conformation. The move is accepted or rejected based on the change in energy, $\\Delta E$, and the system temperature, $T$. The acceptance probability is given by $p_{\\mathrm{acc}} = \\min\\{1, \\exp(-\\Delta E/T)\\}$. For the special case of $T=0$, only moves that do not increase the energy ($\\Delta E \\le 0$) are accepted. Throughout the simulation, the minimum energy encountered is tracked.\n\nThe local move set is precisely defined and consists of two types of moves, chosen with equal probability at each attempt:\n1.  **End Move**: One of the two end monomers (index $0$ or $N-1$) is chosen. A new position is proposed for it, selected uniformly at random from the vacant nearest-neighbor sites of its bonded neighbor on the chain. If no such vacant sites exist, the move attempt is rejected.\n2.  **Corner Flip**: An interior monomer $i \\in \\{1, \\dots, N-2\\}$ is chosen. If its bonded neighbors, $\\mathbf{r}_{i-1}$ and $\\mathbf{r}_{i+1}$, form a $90$-degree angle around it (i.e., the minimal displacement vectors $\\mathbf{r}_{i-1}-\\mathbf{r}_i$ and $\\mathbf{r}_{i+1}-\\mathbf{r}_i$ are orthogonal unit vectors), a move to the fourth corner of the resulting $2 \\times 2$ square is proposed. The new position is $\\mathbf{r}'_i = \\mathbf{r}_{i-1} + \\mathbf{r}_{i+1} - \\mathbf{r}_i$, with all coordinates taken modulo $L$. If this target site is already occupied by another monomer, the move attempt is rejected.\n\nThe implementation will follow these specifications directly. For each test case, a simulation is initialized with the given parameters $(L, M, T, \\text{seed})$. The initial conformation is a straight horizontal chain, $\\mathbf{r}_i = (i,0)$ for $i \\in \\{0, \\dots, 4\\}$. A Mersenne Twister pseudorandom number generator, seeded with the specified value, ensures the deterministic evolution of the system for each run. The energy of a conformation is calculated by iterating through all non-bonded pairs. For efficiency, during the simulation, the change in energy $\\Delta E$ is calculated locally by considering only the contacts of the single monomer that is moved. The program will execute the simulation for each test case and report the minimum energy found, formatted as specified. For the test case with $M=0$, no moves are attempted, and the reported minimum energy is simply the energy of the initial conformation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the polymer folding problem by running Monte Carlo simulations\n    for a given set of test cases.\n    \"\"\"\n\n    class PolymerSimulation:\n        \"\"\"\n        A class to encapsulate the state and methods for a single\n        polymer Monte Carlo simulation.\n        \"\"\"\n        def __init__(self, L, M, T, seed):\n            self.L = L\n            self.N = 5\n            self.M = M\n            self.T = T\n            self.rng = np.random.default_rng(seed)\n            \n            # Initial conformation: r_i = (i mod L, 0)\n            self.positions = np.array([[i % self.L, 0] for i in range(self.N)], dtype=np.int32)\n            \n            self.energy = self._calculate_total_energy()\n            self.min_energy = self.energy\n\n        def _get_toroidal_displacement(self, p1, p2):\n            \"\"\"Returns the minimal displacement vector from p2 to p1 on the torus.\"\"\"\n            disp = p1 - p2\n            if disp[0]  self.L / 2:\n                disp[0] -= self.L\n            elif disp[0]  -self.L / 2:\n                disp[0] += self.L\n            \n            if disp[1]  self.L / 2:\n                disp[1] -= self.L\n            elif disp[1]  -self.L / 2:\n                disp[1] += self.L\n            return disp\n\n        def _toroidal_manhattan_dist(self, p1, p2):\n            \"\"\"Calculates the Manhattan distance on the torus.\"\"\"\n            disp = np.abs(p1 - p2)\n            dx = min(disp[0], self.L - disp[0])\n            dy = min(disp[1], self.L - disp[1])\n            return dx + dy\n\n        def _calculate_total_energy(self):\n            \"\"\"Calculates the total energy of the current conformation.\"\"\"\n            contacts = 0\n            for i in range(self.N):\n                for j in range(i + 2, self.N):  # |i-j|  1\n                    if self._toroidal_manhattan_dist(self.positions[i], self.positions[j]) == 1:\n                        contacts += 1\n            return -contacts\n\n        def _calculate_energy_change(self, moved_idx, new_pos):\n            \"\"\"Calculates the energy change resulting from moving a single monomer.\"\"\"\n            old_pos = self.positions[moved_idx]\n            old_contacts = 0\n            new_contacts = 0\n            \n            for i in range(self.N):\n                if i == moved_idx or abs(i - moved_idx) = 1:\n                    continue\n                \n                p_other = self.positions[i]\n                if self._toroidal_manhattan_dist(old_pos, p_other) == 1:\n                    old_contacts += 1\n                if self._toroidal_manhattan_dist(new_pos, p_other) == 1:\n                    new_contacts += 1\n\n            delta_C = new_contacts - old_contacts\n            # Energy E = -eps * C with eps=1\n            return -delta_C\n\n        def run(self):\n            \"\"\"Runs the Monte Carlo simulation for M steps.\"\"\"\n            if self.M == 0:\n                return self.min_energy\n\n            for _ in range(self.M):\n                current_occupied = {tuple(p) for p in self.positions}\n                proposal = None\n\n                # Choose move family: End move or Corner flip\n                if self.rng.random()  0.5:\n                    # Propose an End Move\n                    moved_idx = 0 if self.rng.random()  0.5 else self.N - 1\n                    neighbor_idx = 1 if moved_idx == 0 else self.N - 2\n                    neighbor_pos = self.positions[neighbor_idx]\n                    \n                    available_sites = []\n                    for move in [[1, 0], [-1, 0], [0, 1], [0, -1]]:\n                        site = (neighbor_pos + move) % self.L\n                        if tuple(site) not in current_occupied:\n                            available_sites.append(site)\n                    \n                    if available_sites:\n                        new_pos_coord = self.rng.choice(available_sites, axis=0)\n                        proposal = (moved_idx, new_pos_coord)\n                else:\n                    # Propose a Corner Flip\n                    moved_idx = self.rng.choice([1, 2, 3])\n                    pos_i = self.positions[moved_idx]\n                    pos_prev = self.positions[moved_idx - 1]\n                    pos_next = self.positions[moved_idx + 1]\n                    \n                    disp_prev = self._get_toroidal_displacement(pos_prev, pos_i)\n                    disp_next = self._get_toroidal_displacement(pos_next, pos_i)\n                    \n                    is_corner = (np.sum(np.abs(disp_prev)) == 1 and\n                                 np.sum(np.abs(disp_next)) == 1 and\n                                 np.dot(disp_prev, disp_next) == 0)\n                    \n                    if is_corner:\n                        new_pos = (pos_i + disp_prev + disp_next) % self.L\n                        if tuple(new_pos) not in current_occupied:\n                            proposal = (moved_idx, new_pos)\n\n                if proposal is None:\n                    continue # Attempt rejected\n\n                moved_idx, new_pos = proposal\n                \n                delta_E = self._calculate_energy_change(moved_idx, new_pos)\n                \n                accept = False\n                if self.T == 0:\n                    if delta_E = 0:\n                        accept = True\n                else:\n                    if delta_E = 0 or self.rng.random()  np.exp(-delta_E / self.T):\n                        accept = True\n                \n                if accept:\n                    self.positions[moved_idx] = new_pos\n                    self.energy += delta_E\n                    self.min_energy = min(self.min_energy, self.energy)\n            \n            return self.min_energy\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (L, M, T, seed)\n        (6, 100000, 0.8, 20231102),\n        (5, 0, 0.5, 1),\n        (6, 30000, 5.0, 777),\n        (6, 5000, 0.2, 424242),\n    ]\n\n    results = []\n    for L, M, T, seed in test_cases:\n        sim = PolymerSimulation(L, M, T, seed)\n        min_e = sim.run()\n        results.append(int(min_e))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "For certain classes of problems, we can do better than just searching the energy landscape—we can find the provably optimal solution with an efficient algorithm. This is possible when the problem exhibits \"optimal substructure,\" allowing the use of dynamic programming. In this practice , you will implement a dynamic programming algorithm to find the minimum free energy structure of an RNA molecule, modeling the real-life process of co-transcriptional folding and mastering a technique central to sequence analysis.",
            "id": "2388076",
            "problem": "You are asked to design and implement a program that models co-transcriptional Ribonucleic Acid (RNA) folding under a simplified energy model by sequentially adding nucleotides one at a time and re-minimizing the structure at each step. The central computational task is an energy minimization over RNA secondary structures, framed in purely mathematical terms and solved by an algorithm designed from first principles.\n\nThe fundamental base you must rely on consists of: (i) canonical base pairing rules for RNA, (ii) the principle of optimality that underpins Dynamic Programming (DP), and (iii) the additivity of free energies over independent structural components in simplified secondary structure models. Your program should implement these principles without importing any problem-specific formulas that are not derived from these bases.\n\nConsider an RNA primary sequence $S = (S_1, S_2, \\dots, S_L)$ of length $L$, where each $S_i \\in \\{\\text{A}, \\text{U}, \\text{G}, \\text{C}\\}$. A secondary structure is a set of index pairs $X \\subset \\{(i,j) \\mid 1 \\le i  j \\le L\\}$ subject to the following constraints:\n- Each index appears in at most one pair.\n- The structure is non-crossing: for any $(i,j) \\in X$ and $(k,\\ell) \\in X$ with $i  k$, if $k  j$ then $\\ell  j$.\n- Only canonical pairs are allowed: $(\\text{A}, \\text{U})$, $(\\text{U}, \\text{A})$, $(\\text{G}, \\text{C})$, $(\\text{C}, \\text{G})$.\n- A minimum hairpin loop length constraint $h \\in \\mathbb{Z}_{\\ge 0}$ is enforced: a pair $(i,j)$ is forbidden if $j - i - 1  h$.\n\nThe energy of a secondary structure $X$ under the simplified model is defined as\n$$\nE(X) \\;=\\; \\sum_{(i,j) \\in X} e_p \\;+\\; \\sum_{\\substack{(i,j) \\in X \\\\ (i+1,j-1) \\in X}} e_s,\n$$\nwhere $e_p \\in \\mathbb{R}$ is the per-pair energy and $e_s \\in \\mathbb{R}$ is the stacking energy added once for each adjacent stacked pair $(i,j)$ and $(i+1,j-1)$. We adopt the convention that $e_p  0$ and $e_s \\le 0$, and unpaired nucleotides contribute $0$ energy.\n\nFor each prefix length $t \\in \\{1,2,\\dots,L\\}$, define the minimum free energy (MFE) over all valid structures on indices $\\{1,\\dots,t\\}$ as\n$$\nM(t) \\;=\\; \\min\\{\\, E(X) \\mid X \\text{ is a valid structure on } \\{1,\\dots,t\\}\\,\\}.\n$$\nCo-transcriptional folding is modeled by computing the sequence $\\big(M(1), M(2), \\dots, M(L)\\big)$, where at each step $t$ a newly appended nucleotide is allowed to form or break pairs so as to minimize energy subject to the constraints above.\n\nYour task is to:\n- Derive, from the principle of optimality and the constraints above, an algorithmic scheme that computes $M(t)$ for all $t \\in \\{1,\\dots,L\\}$.\n- Implement a correct and efficient program that, for each test case below, outputs the list $\\big(M(1), M(2), \\dots, M(L)\\big)$ with all values rounded to one decimal place.\n\nTest suite. For each test case, you are given a sequence $S$, a per-pair energy $e_p$, a stacking energy $e_s$, and a minimum hairpin loop length $h$. For all cases, use only canonical pairs as defined above.\n- Test case $1$: $S=\\text{\"GCGC\"}$, $e_p=-1.0$, $e_s=-0.5$, $h=0$.\n- Test case $2$: $S=\\text{\"AUGC\"}$, $e_p=-1.0$, $e_s=-0.5$, $h=3$.\n- Test case $3$: $S=\\text{\"AUAU\"}$, $e_p=-1.0$, $e_s=-0.2$, $h=0$.\n- Test case $4$: $S=\\text{\"AAAAAA\"}$, $e_p=-1.0$, $e_s=-0.5$, $h=0$.\n- Test case $5$: $S=\\text{\"GCGC\"}$, $e_p=-1.0$, $e_s=-0.5$, $h=1$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of lists, with no spaces, enclosed in square brackets. Each inner list must contain the $L$ rounded values $M(1),\\dots,M(L)$ for that test case, in order. For example, the format must look like $[\\,[m_{1,1},\\dots,m_{1,L_1}],[m_{2,1},\\dots,m_{2,L_2}],\\dots\\,]$ and must be printed exactly like \"[[...],[...],...]\". Round every energy value to one decimal place. No physical units or angle units are involved in this problem.",
            "solution": "The problem presented is a valid, well-posed scientific question grounded in the principles of computational biology and is solvable through rigorous algorithmic design. It requires the derivation and implementation of a dynamic programming (DP) algorithm to model the co-transcriptional folding of an RNA sequence under a simplified energy model.\n\nThe core task is to compute the minimum free energy (MFE) for all prefixes of a given RNA sequence $S$. Let $S_{i \\dots j}$ denote the subsequence from index $i$ to $j$. The MFE for a prefix of length $t$, $S_{1 \\dots t}$, is denoted as $M(t)$. This value corresponds to the MFE of the entire subsequence $S_{1 \\dots t}$, which we can find by solving the general problem of finding the MFE for any subsequence $S_{i \\dots j}$.\n\nThe principle of optimality states that an optimal solution to a problem contains optimal solutions to its subproblems. This is the foundation of dynamic programming. A non-crossing RNA secondary structure can be decomposed into smaller, independent substructures, which allows for a DP-based solution. The provided energy function, $E(X) = \\sum_{(i,j) \\in X} e_p + \\sum_{\\text{stacks}} e_s$, is local and additive, satisfying the requirements for DP.\n\nWe define two coupled DP tables:\n$1$. $W(i, j)$: The minimum free energy for any valid secondary structure on the subsequence $S_{i \\dots j}$.\n$2$. $V(i, j)$: The minimum free energy for any valid secondary structure on the subsequence $S_{i \\dots j}$, with the explicit constraint that the endpoints $i$ and $j$ form a base pair.\n\nThe values in these tables are computed for subsequences of increasing length. The final desired quantity, $M(t)$, is given by $W(1, t)$ for the prefix $S_{1 \\dots t}$.\n\nThe recurrence relations are derived by considering all possible structural states of the nucleotides at the boundaries of a subsequence $S_{i \\dots j}$.\n\n**Recurrence for $W(i, j)$**\n\nTo compute $W(i, j)$, we consider two mutually exclusive cases for the nucleotide at index $j$:\n$1$. **$j$ is unpaired**: In this case, nucleotide $S_j$ does not contribute to the energy. The MFE of the subsequence $S_{i \\dots j}$ is identical to the MFE of the subsequence $S_{i \\dots j-1}$. The energy is thus $W(i, j-1)$.\n$2$. **$j$ is paired with $k$**: Nucleotide $S_j$ forms a pair with a nucleotide $S_k$ where $i \\le k  j$. Due to the non-crossing constraint, the pair $(k, j)$ divides the subsequence $S_{i \\dots j}$ into two independent regions: the external region $S_{i \\dots k-1}$ and the region enclosed by the pair, $S_{k+1 \\dots j-1}$. The total energy is the sum of the MFE of the external region, $W(i, k-1)$, and the MFE of the structure closed by the pair $(k,j)$, which is precisely $V(k, j)$. We must minimize over all possible partners $k$.\n\nCombining these cases, we get the recurrence for $W(i, j)$:\n$$\nW(i, j) = \\min \\left( W(i, j-1), \\quad \\min_{i \\le k  j, \\text{ valid pair } (k,j)} \\left\\{ W(i, k-1) + V(k, j) \\right\\} \\right)\n$$\nA pair $(k,j)$ is valid if $S_k$ and $S_j$ are canonical complements and the loop length constraint $j-k-1 \\ge h$ is met. The base cases are $W(i, i-1) = 0$ (for empty subsequences) and $W(i, i) = 0$.\n\n**Recurrence for $V(i, j)$**\n\nTo compute $V(i, j)$, we assume the pair $(i, j)$ is formed. If $(i, j)$ is not a valid pair (not canonical or $j-i-1  h$), then $V(i, j) = \\infty$. Otherwise, the total energy is the sum of the energy of the pair $(i,j)$ itself and the MFE of the internal region $S_{i+1 \\dots j-1}$. The pair $(i,j)$ contributes $e_p$. The structure of the internal region can be one of the following:\n$1$. **Hairpin loop**: The internal region $S_{i+1 \\dots j-1}$ is entirely unpaired. Its energy contribution is $0$.\n$2$. **Stacked pair**: The pair $(i, j)$ is stacked on an adjacent pair $(i+1, j-1)$. This structure is a pair $(i,j)$ enclosing a smaller substructure that is itself closed by the pair $(i+1, j-1)$. The energy contribution is the stacking energy $e_s$ plus the MFE of the structure closed by $(i+1, j-1)$, which is $V(i+1, j-1)$.\n$3$. **Multiloop**: The internal region $S_{i+1 \\dots j-1}$ decomposes into two or more independent substructures. For a simple bifurcation, the region splits at some index $k$ ($i+1 \\le k  j-1$) into two independent subproblems on $S_{i+1 \\dots k}$ and $S_{k+1 \\dots j-1}$. The MFE is the sum $W(i+1, k) + W(k+1, j-1)$. We minimize over all possible split points $k$.\n\nThus, the recurrence for $V(i, j)$ is:\n$$\nV(i, j) = e_p + \\min \\left( E_{\\text{hairpin}}, E_{\\text{stack}}, E_{\\text{multi}} \\right)\n$$\nwhere:\n- $E_{\\text{hairpin}} = 0$\n- $E_{\\text{stack}} = e_s + V(i+1, j-1)$\n- $E_{\\text{multi}} = \\min_{i+1 \\le k  j-1} \\{W(i+1, k) + W(k+1, j-1)\\}$\n\nThese recurrences define a complete DP algorithm. To model co-transcriptional folding, we apply this algorithm iteratively. For each prefix length $t = 1, \\dots, L$, we solve for the MFE of the sequence $S_{1 \\dots t}$, which is $W(1, t)$. This involves computing the DP tables $W$ and $V$ for all subsequences within $S_{1 \\dots t}$. The result for each test case is the sequence of these MFE values, $(M(1), M(2), \\dots, M(L))$. The provided solution implements this by re-calculating the MFE from scratch for each prefix length. Given the small sequence lengths in the test suite, this $O(L^4)$ approach is computationally feasible and correct.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Global constant for infinity\nINF = np.inf\n\ndef get_canonical_pairs():\n    \"\"\"Returns a set of canonical RNA base pairs.\"\"\"\n    return {('A', 'U'), ('U', 'A'), ('G', 'C'), ('C', 'G')}\n\ndef compute_mfe_for_prefix(S_prefix, ep, es, h, canonical_pairs):\n    \"\"\"\n    Computes the Minimum Free Energy (MFE) for a given RNA sequence prefix.\n\n    This function implements a dynamic programming algorithm based on the Zuker-Stankiewicz\n    model, simplified according to the problem statement.\n    \"\"\"\n    N = len(S_prefix)\n    if N == 0:\n        return 0.0\n\n    # W[i][j]: MFE for any valid structure on subsequence S[i...j]\n    W = np.full((N, N), 0.0)\n    # V[i][j]: MFE for a structure on S[i...j] that is CLOSED by pair (i,j)\n    V = np.full((N, N), INF)\n\n    # d is the length of the subsequence minus 1.\n    for d in range(1, N):\n        for i in range(N - d):\n            j = i + d\n\n            # --- Calculate V[i][j] ---\n            if (S_prefix[i], S_prefix[j]) in canonical_pairs and (j - i - 1 >= h):\n                # Hairpin loop: region i+1...j-1 is unpaired.\n                e_hairpin = 0.0\n\n                # Stacked pair: pair (i,j) stacks on (i+1,j-1)\n                e_stack = es + V[i+1][j-1] if d > 1 else INF\n\n                # Multiloop (bifurcation): internal region i+1...j-1 splits\n                e_multi = INF\n                for k in range(i + 1, j - 1):\n                    e_multi = min(e_multi, W[i+1][k] + W[k+1][j-1])\n                \n                V[i][j] = ep + min(e_hairpin, e_stack, e_multi)\n\n            # --- Calculate W[i][j] ---\n            # Case 1: j is unpaired\n            e_unpaired = W[i][j-1]\n\n            # Case 2: j is paired with some k  j\n            e_paired = INF\n            for k in range(i, j):\n                # The pair (k,j) must satisfy the min loop length\n                if V[k][j] != INF:\n                    energy_prefix = W[i][k-1] if k > i else 0.0\n                    e_paired = min(e_paired, energy_prefix + V[k][j])\n            \n            W[i][j] = min(e_unpaired, e_paired)\n    \n    return W[0][N-1] if N > 0 else 0.0\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and print final results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\"S\": \"GCGC\", \"ep\": -1.0, \"es\": -0.5, \"h\": 0},\n        {\"S\": \"AUGC\", \"ep\": -1.0, \"es\": -0.5, \"h\": 3},\n        {\"S\": \"AUAU\", \"ep\": -1.0, \"es\": -0.2, \"h\": 0},\n        {\"S\": \"AAAAAA\", \"ep\": -1.0, \"es\": -0.5, \"h\": 0},\n        {\"S\": \"GCGC\", \"ep\": -1.0, \"es\": -0.5, \"h\": 1},\n    ]\n\n    canonical_pairs = get_canonical_pairs()\n    all_results = []\n\n    for case in test_cases:\n        S, ep, es, h = case[\"S\"], case[\"ep\"], case[\"es\"], case[\"h\"]\n        L = len(S)\n        m_sequence = []\n        for t in range(1, L + 1):\n            prefix = S[:t]\n            mfe = compute_mfe_for_prefix(prefix, ep, es, h, canonical_pairs)\n            m_sequence.append(round(mfe, 1))\n        all_results.append(m_sequence)\n\n    # Format the final output according to problem specifications.\n    # The output is a comma-separated list of lists, with no spaces.\n    inner_lists_str = [f\"[{','.join(map(str, sublist))}]\" for sublist in all_results]\n    print(f\"[{','.join(inner_lists_str)}]\")\n\nsolve()\n```"
        }
    ]
}