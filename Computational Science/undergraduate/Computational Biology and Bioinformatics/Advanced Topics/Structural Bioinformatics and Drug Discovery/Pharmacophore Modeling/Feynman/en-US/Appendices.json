{
    "hands_on_practices": [
        {
            "introduction": "The first step in many drug discovery projects is to understand the target protein's binding site. This practice guides you through creating a receptor-guided pharmacophore, a map of interaction 'hotspots' derived directly from the receptor's structure. By implementing a simplified physical model for electrostatics, steric repulsion, and hydrophobicity, you will learn how to computationally probe a binding site to identify the most energetically favorable locations for key chemical features, a fundamental technique in structure-based drug design .",
            "id": "2440150",
            "problem": "You are given three-dimensional receptor binding site descriptions consisting of atoms with positions (in Angstroms), element types, and partial charges (dimensionless). Your task is to construct a receptor-guided pharmacophore by identifying spatial hotspots for three probe types: hydrogen-bond donor (D), hydrogen-bond acceptor (A), and hydrophobe (H). A receptor-guided pharmacophore feature is defined here as a local energy minimum for a virtual probe interacting with the receptor, subject to physically motivated interactions. You must implement a grid-based evaluation and return, for each probe type, a small, diversified set of local minima representing key interaction points. All final reported coordinates must be expressed in Angstroms, rounded to three decimals.\n\nFoundational bases and assumptions to use:\n- Electrostatic interaction is governed by Coulomb’s law: the interaction between charges depends on the product of charges and inverse powers of separation. In a heterogeneous medium, a distance-dependent dielectric is a common approximation. Use a distance-dependent dielectric proportional to separation to obtain an inverse-square dependence of electrostatic energy on separation.\n- Short-range steric exclusion is captured by the repulsive part of a van der Waals (vdW) interaction. Approximate this repulsion by a purely repulsive inverse-twelfth power of separation.\n- The hydrophobic effect can be approximated by a spatially decaying occupancy preference around nonpolar carbons. Model this as a spherically symmetric Gaussian well centered on carbon atoms for a hydrophobic probe.\n\nFrom these bases, construct an interaction energy for a probe of type $T \\in \\{\\mathrm{D}, \\mathrm{A}, \\mathrm{H}\\}$ at position $\\mathbf{x}$ relative to receptor atoms indexed by $i$ at positions $\\mathbf{r}_i$ with charges $q_i$:\n- Let $r_i(\\mathbf{x}) = \\max\\{ \\lVert \\mathbf{x} - \\mathbf{r}_i \\rVert_2, r_{\\mathrm{soft}} \\}$ for numerical stability at short range.\n- Electrostatic term: $E_{\\mathrm{elec}}(\\mathbf{x}) = \\sum_i \\dfrac{q_T \\, q_i}{r_i(\\mathbf{x})^2}$ where $q_T$ is the probe’s effective charge: $q_{\\mathrm{D}} = +0.4$, $q_{\\mathrm{A}} = -0.4$, $q_{\\mathrm{H}} = 0.0$ (dimensionless).\n- Steric repulsion term: $E_{\\mathrm{rep}}(\\mathbf{x}) = \\sum_i \\dfrac{k_{\\mathrm{rep}}}{r_i(\\mathbf{x})^{12}}$ with $k_{\\mathrm{rep}} = 0.01$.\n- Hydrophobic term (only for the hydrophobe probe $T = \\mathrm{H}$ and only from carbon atoms): $E_{\\mathrm{hyd}}(\\mathbf{x}) = - \\sum_{i \\in \\mathrm{carbons}} k_{\\mathrm{hyd}} \\, \\exp\\!\\left(-\\dfrac{r_i(\\mathbf{x})^2}{\\sigma^2}\\right)$ with $k_{\\mathrm{hyd}} = 0.3$ and $\\sigma = 2.0$.\n- Total energy for probe $T$: $E_T(\\mathbf{x}) = E_{\\mathrm{elec}}(\\mathbf{x}) + E_{\\mathrm{rep}}(\\mathbf{x}) + 1_{T=\\mathrm{H}} \\, E_{\\mathrm{hyd}}(\\mathbf{x})$.\n\nNumerical parameters and units:\n- Set $r_{\\mathrm{soft}} = 0.5$ Angstroms.\n- All energies are in arbitrary energy units (A.U.). You must not convert units.\n- Grid spacing is $\\Delta = 1.0$ Angstrom.\n\nLocal minima definition and selection:\n- Evaluate $E_T(\\mathbf{x})$ on a three-dimensional grid covering an axis-aligned bounding box defined per test case.\n- A grid point is a local minimum if its value is strictly less than the values at all of its adjacent neighbors in the $3 \\times 3 \\times 3$ cube excluding itself (that is, the $26$ immediate neighbors in three dimensions; for boundary points, compare only to in-bounds neighbors).\n- For each probe type $T$, rank all local minima by energy (ascending).\n- Diversify by spatial clustering: traverse ranked minima (best to worst) and keep a candidate only if it is at least $r_{\\mathrm{cluster}} = 1.0$ Angstrom away (Euclidean distance) from every previously accepted minimum for the same $T$.\n- Keep up to $K = 3$ minima per probe type per test case, subject to an energy cutoff $E_T(\\mathbf{x}) < E_{\\mathrm{cut},T}$ with $E_{\\mathrm{cut},\\mathrm{D}} = -0.03$, $E_{\\mathrm{cut},\\mathrm{A}} = -0.03$, $E_{\\mathrm{cut},\\mathrm{H}} = -0.08$ (A.U.).\n- Report the coordinates of the kept minima for each probe type.\n\nTest suite (three cases). In each case, coordinates are in Angstroms, charges are dimensionless:\n- Case 1:\n  - Receptor atoms:\n    - Oxygen ($\\mathrm{O}$): position $(0.0, 0.0, 0.0)$, $q = -0.5$.\n    - Nitrogen ($\\mathrm{N}$): position $(3.0, 0.0, 0.0)$, $q = +0.3$.\n    - Carbon ($\\mathrm{C}$): position $(0.0, 3.0, 0.0)$, $q = 0.0$.\n    - Carbon ($\\mathrm{C}$): position $(0.0, -3.0, 0.0)$, $q = 0.0$.\n  - Grid bounding box: center $(0.0, 0.0, 0.0)$, half-extent $4.0$ in each axis, spacing $\\Delta = 1.0$.\n- Case 2:\n  - Receptor atoms:\n    - Oxygen ($\\mathrm{O}$): position $(-2.0, -2.0, 0.0)$, $q = -0.4$.\n    - Oxygen ($\\mathrm{O}$): position $(2.0, 2.0, 0.0)$, $q = -0.4$.\n    - Nitrogen ($\\mathrm{N}$): position $(-2.0, 2.0, 0.0)$, $q = +0.3$.\n    - Carbon ($\\mathrm{C}$): position $(0.0, 0.0, 2.0)$, $q = 0.0$.\n  - Grid bounding box: center $(0.0, 0.0, 0.0)$, half-extent $3.0$ in each axis, spacing $\\Delta = 1.0$.\n- Case 3:\n  - Receptor atoms:\n    - Carbon ($\\mathrm{C}$): position $(-1.5, 0.0, 0.0)$, $q = 0.0$.\n    - Carbon ($\\mathrm{C}$): position $(1.5, 0.0, 0.0)$, $q = 0.0$.\n    - Carbon ($\\mathrm{C}$): position $(0.0, 2.0, 0.0)$, $q = 0.0$.\n  - Grid bounding box: center $(0.0, 0.0, 0.0)$, half-extent $3.0$ in each axis, spacing $\\Delta = 1.0$.\n\nProgram requirements:\n- Implement the energy model as described above from the foundational bases, evaluate on the specified grids, detect and select local minima as defined, and apply clustering and cutoffs.\n- For each test case, produce an ordered list of three lists $[\\mathrm{D}, \\mathrm{A}, \\mathrm{H}]$, where each of the three is a list of three-dimensional points $[x, y, z]$ (in Angstroms) corresponding to the selected minima for that probe type, rounded to three decimals.\n- Your program should produce a single line of output containing the results for all three test cases as a comma-separated list enclosed in square brackets. Concretely: a list of length three, where each element is itself the $[\\mathrm{D}, \\mathrm{A}, \\mathrm{H}]$ triple for a test case. Each coordinate must be rounded to three decimals and expressed in Angstroms. Example of required shape (not actual values): \n  - $[[[\\cdot,\\cdot,\\cdot],\\ldots],[[\\cdot,\\cdot,\\cdot],\\ldots],[[\\cdot,\\cdot,\\cdot],\\ldots]], \\ldots$ for the three cases.\n- The final output must be a single line with no extra text. All reported coordinates must be rounded to three decimals (Angstroms).",
            "solution": "The problem statement has been subjected to rigorous validation and is found to be scientifically sound and computationally well-posed. It presents a clearly defined task in computational drug design, specifically the generation of a receptor-guided pharmacophore. The physical model, while simplified, is based on established principles of molecular mechanics. All necessary parameters and algorithmic steps are provided, rendering the problem unambiguous and solvable. We proceed to the solution.\n\nThe core of the problem is to identify energetically favorable positions for three types of chemical probes—a hydrogen-bond donor ($D$), a hydrogen-bond acceptor ($A$), and a hydrophobic group ($H$)—within the binding site of a receptor. These favorable positions, or \"hotspots,\" are defined as local minima on a potential energy surface. The solution is constructed through a multi-step computational procedure.\n\n### 1. Potential Energy Functions\n\nThe interaction between a virtual probe of type $T \\in \\{D, A, H\\}$ at position $\\mathbf{x}$ and the receptor atoms is modeled by a potential energy function $E_T(\\mathbf{x})$. This function is a sum of electrostatic, steric repulsion, and, for the hydrophobic probe, hydrophobic interaction terms. Let the receptor consist of atoms indexed by $i$ at positions $\\mathbf{r}_i$ with partial charges $q_i$. The distance between the probe and atom $i$ is given by $d_i(\\mathbf{x}) = \\lVert \\mathbf{x} - \\mathbf{r}_i \\rVert_2$. To prevent numerical instability at vanishing separations, a softened distance, $r_i(\\mathbf{x})$, is used:\n$$\nr_i(\\mathbf{x}) = \\max \\{ d_i(\\mathbf{x}), r_{\\mathrm{soft}} \\}\n$$\nwhere the softening parameter is $r_{\\mathrm{soft}} = 0.5$ Angstroms.\n\nThe total energy $E_T(\\mathbf{x})$ is defined as:\n$$\nE_T(\\mathbf{x}) = E_{\\mathrm{elec}}(\\mathbf{x}) + E_{\\mathrm{rep}}(\\mathbf{x}) + \\delta_{TH} \\, E_{\\mathrm{hyd}}(\\mathbf{x})\n$$\nwhere $\\delta_{TH}$ is the Kronecker delta, equal to $1$ if the probe type $T$ is $H$ and $0$ otherwise.\n\n**1.1. Electrostatic Energy ($E_{\\mathrm{elec}}$)**\nThis term models the Coulombic interaction. The problem specifies a distance-dependent dielectric, leading to an inverse-square dependence of energy on separation. The probe has an effective charge $q_T$.\n$$\nE_{\\mathrm{elec}}(\\mathbf{x}) = \\sum_i \\frac{q_T \\, q_i}{r_i(\\mathbf{x})^2}\n$$\nThe probe charges are defined as $q_D = +0.4$, $q_A = -0.4$, and $q_H = 0.0$.\n\n**1.2. Steric Repulsion Energy ($E_{\\mathrm{rep}}$)**\nThis term models the strong, short-range repulsion between electron clouds, a consequence of the Pauli exclusion principle. It is approximated by an inverse-twelfth power law, a standard component of Lennard-Jones potentials.\n$$\nE_{\\mathrm{rep}}(\\mathbf{x}) = \\sum_i \\frac{k_{\\mathrm{rep}}}{r_i(\\mathbf{x})^{12}}\n$$\nThe repulsion strength constant is given as $k_{\\mathrm{rep}} = 0.01$.\n\n**1.3. Hydrophobic Energy ($E_{\\mathrm{hyd}}$)**\nThis term is specific to the hydrophobic probe ($T=H$) and models the tendency of nonpolar groups to cluster together to minimize disruption of the hydrogen-bonding network of a solvent (an effect implicitly modeled here). The interaction is attractive and is modeled as a sum of Gaussian wells centered on the receptor's nonpolar carbon atoms.\n$$\nE_{\\mathrm{hyd}}(\\mathbf{x}) = - \\sum_{i \\in \\text{carbons}} k_{\\mathrm{hyd}} \\exp\\left(-\\frac{r_i(\\mathbf{x})^2}{\\sigma^2}\\right)\n$$\nThe parameters for this potential are the strength $k_{\\mathrm{hyd}} = 0.3$ and the spatial extent $\\sigma = 2.0$ Angstroms.\n\n### 2. Grid-Based Evaluation\n\nThe continuous potential energy surface is discretized for computational analysis. For each test case, a three-dimensional grid of points is generated within a specified axis-aligned bounding box. The grid spacing is uniform, with $\\Delta = 1.0$ Angstrom. For each probe type $T$, the energy $E_T(\\mathbf{x})$ is computed at every grid point $\\mathbf{x}$, resulting in a three-dimensional array of energy values, which we denote as the energy grid.\n\n### 3. Identification of Local Minima\n\nA grid point is identified as a local minimum if its energy value is strictly less than the energy values of all its immediate neighbors. For a point in the interior of the grid, there are $3^3 - 1 = 26$ such neighbors. For points on the boundaries, faces, or corners of the grid, comparisons are made only with neighbors that lie within the grid. The algorithm iterates through every point on the energy grid and performs these comparisons to compile a list of all local minima, storing their grid coordinates and corresponding energy values.\n\n### 4. Selection and Diversification of Minima\n\nThe raw set of local minima must be filtered to yield a small, diverse set of the most significant interaction hotspots. This is accomplished through a sequential four-step process for each probe type.\n\n**4.1. Energy Cutoff:** Minima that are not sufficiently favorable are discarded. A candidate minimum at position $\\mathbf{x}$ is kept only if its energy $E_T(\\mathbf{x})$ is below a type-specific threshold:\n$$\nE_T(\\mathbf{x}) < E_{\\mathrm{cut},T}\n$$\nThe cutoffs are given as $E_{\\mathrm{cut},D} = -0.03$, $E_{\\mathrm{cut},A} = -0.03$, and $E_{\\mathrm{cut},H} = -0.08$ (in arbitrary energy units).\n\n**4.2. Ranking:** The surviving minima are sorted in ascending order of their energy values, from most favorable to least favorable.\n\n**4.3. Spatial Clustering:** To ensure a diverse set of pharmacophore features, a spatial clustering procedure is applied. The algorithm iterates through the ranked list of minima. The first minimum (the one with the lowest energy) is always accepted. A subsequent minimum is accepted only if its position is at least a distance of $r_{\\mathrm{cluster}} = 1.0$ Angstrom away from all previously accepted minima for that same probe type. This prevents the selection of multiple redundant minima from the same pocket or interaction region.\n\n**4.4. Final Selection:** The process continues until a maximum of $K=3$ diverse, low-energy minima are accepted for each probe type. The final output for each probe type is the list of coordinates of these selected minima. If fewer than $K$ minima satisfy all criteria, the list will be correspondingly shorter. The coordinates are reported in Angstroms, rounded to three decimal places.\n\nThis entire procedure is systematically applied to each test case provided in the problem statement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the pharmacophore generation for all test cases.\n    \"\"\"\n    \n    # Define physical and numerical parameters\n    PROBE_CHARGES = {'D': 0.4, 'A': -0.4, 'H': 0.0}\n    K_REP = 0.01\n    K_HYD = 0.3\n    SIGMA_HYD = 2.0\n    R_SOFT = 0.5\n    R_CLUSTER = 1.0\n    K_MAX_MINIMA = 3\n    ENERGY_CUTOFFS = {'D': -0.03, 'A': -0.03, 'H': -0.08}\n    PROBE_TYPES = ['D', 'A', 'H']\n\n    # Define the test cases from the problem statement.\n    # Each case: {atoms: [(pos, charge, type)], grid: (center, half_extent, spacing)}\n    test_cases = [\n        {\n            \"atoms\": [\n                (np.array([0.0, 0.0, 0.0]), -0.5, 'O'),\n                (np.array([3.0, 0.0, 0.0]), 0.3, 'N'),\n                (np.array([0.0, 3.0, 0.0]), 0.0, 'C'),\n                (np.array([0.0, -3.0, 0.0]), 0.0, 'C'),\n            ],\n            \"grid\": {\"center\": np.array([0.0, 0.0, 0.0]), \"half_extent\": 4.0, \"spacing\": 1.0},\n        },\n        {\n            \"atoms\": [\n                (np.array([-2.0, -2.0, 0.0]), -0.4, 'O'),\n                (np.array([2.0, 2.0, 0.0]), -0.4, 'O'),\n                (np.array([-2.0, 2.0, 0.0]), 0.3, 'N'),\n                (np.array([0.0, 0.0, 2.0]), 0.0, 'C'),\n            ],\n            \"grid\": {\"center\": np.array([0.0, 0.0, 0.0]), \"half_extent\": 3.0, \"spacing\": 1.0},\n        },\n        {\n            \"atoms\": [\n                (np.array([-1.5, 0.0, 0.0]), 0.0, 'C'),\n                (np.array([1.5, 0.0, 0.0]), 0.0, 'C'),\n                (np.array([0.0, 2.0, 0.0]), 0.0, 'C'),\n            ],\n            \"grid\": {\"center\": np.array([0.0, 0.0, 0.0]), \"half_extent\": 3.0, \"spacing\": 1.0},\n        },\n    ]\n\n    def calculate_energy(probe_pos, probe_type, atoms):\n        \"\"\"Calculates the interaction energy for a probe at a given position.\"\"\"\n        probe_charge = PROBE_CHARGES[probe_type]\n        e_elec, e_rep, e_hyd = 0.0, 0.0, 0.0\n\n        for atom_pos, atom_charge, atom_type in atoms:\n            dist = np.linalg.norm(probe_pos - atom_pos)\n            r = max(dist, R_SOFT)\n            \n            # Electrostatic term\n            e_elec += (probe_charge * atom_charge) / (r ** 2)\n            \n            # Repulsion term\n            e_rep += K_REP / (r ** 12)\n            \n            # Hydrophobic term\n            if probe_type == 'H' and atom_type == 'C':\n                e_hyd -= K_HYD * np.exp(-(r ** 2) / (SIGMA_HYD ** 2))\n                \n        return e_elec + e_rep + e_hyd\n\n    def solve_case(case):\n        \"\"\"Solves a single test case.\"\"\"\n        atoms = case[\"atoms\"]\n        center = case[\"grid\"][\"center\"]\n        half_extent = case[\"grid\"][\"half_extent\"]\n        spacing = case[\"grid\"][\"spacing\"]\n\n        # Generate grid coordinates\n        axis_coords = np.arange(center[0] - half_extent, center[0] + half_extent + spacing / 2, spacing)\n        grid_x, grid_y, grid_z = np.meshgrid(axis_coords, axis_coords, axis_coords, indexing='ij')\n        grid_shape = grid_x.shape\n        grid_points = np.stack([grid_x, grid_y, grid_z], axis=-1)\n\n        case_results = []\n        for probe_type in PROBE_TYPES:\n            # Calculate energy on the grid\n            energy_grid = np.zeros(grid_shape)\n            for i in range(grid_shape[0]):\n                for j in range(grid_shape[1]):\n                    for k in range(grid_shape[2]):\n                        probe_pos = grid_points[i, j, k]\n                        energy_grid[i, j, k] = calculate_energy(probe_pos, probe_type, atoms)\n\n            # Find local minima\n            local_minima = []\n            for i in range(grid_shape[0]):\n                for j in range(grid_shape[1]):\n                    for k in range(grid_shape[2]):\n                        val = energy_grid[i, j, k]\n                        is_min = True\n                        for di in [-1, 0, 1]:\n                            for dj in [-1, 0, 1]:\n                                for dk in [-1, 0, 1]:\n                                    if di == 0 and dj == 0 and dk == 0:\n                                        continue\n                                    ni, nj, nk = i + di, j + dj, k + dk\n                                    if 0 = ni  grid_shape[0] and 0 = nj  grid_shape[1] and 0 = nk  grid_shape[2]:\n                                        if energy_grid[ni, nj, nk] = val:\n                                            is_min = False\n                                            break\n                                if not is_min: break\n                            if not is_min: break\n                        if is_min:\n                            local_minima.append({\n                                'coord': grid_points[i, j, k],\n                                'energy': val\n                            })\n            \n            # Filter, sort, and diversify minima\n            # 1. Energy cutoff\n            filtered_minima = [m for m in local_minima if m['energy']  ENERGY_CUTOFFS[probe_type]]\n            \n            # 2. Sort by energy\n            sorted_minima = sorted(filtered_minima, key=lambda m: m['energy'])\n            \n            # 3. Diversify by clustering and limit to K\n            accepted_minima_coords = []\n            for minimum in sorted_minima:\n                if len(accepted_minima_coords) >= K_MAX_MINIMA:\n                    break\n                \n                is_distant_enough = True\n                for accepted_coord in accepted_minima_coords:\n                    if np.linalg.norm(minimum['coord'] - accepted_coord)  R_CLUSTER:\n                        is_distant_enough = False\n                        break\n                \n                if is_distant_enough:\n                    accepted_minima_coords.append(minimum['coord'])\n\n            case_results.append(accepted_minima_coords)\n\n        return case_results\n\n    # Process all test cases\n    all_results = [solve_case(case) for case in test_cases]\n\n    # Format the final output string\n    def format_point(p):\n        return f\"[{p[0]:.3f},{p[1]:.3f},{p[2]:.3f}]\"\n\n    def format_point_list(pl):\n        return f\"[{','.join(format_point(p) for p in pl)}]\"\n\n    def format_case_result(cr):\n        # cr is [D_points, A_points, H_points]\n        return f\"[{format_point_list(cr[0])},{format_point_list(cr[1])},{format_point_list(cr[2])}]\"\n\n    final_output_str = f\"[{','.join(format_case_result(r) for r in all_results)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "When a protein's structure is unknown, we can infer its binding requirements by studying the molecules that bind to it. This exercise focuses on a core task in ligand-based design: merging the pharmacophores of two different ligands to build a single, more general consensus model . You will implement an iterative alignment algorithm, using the powerful Kabsch method for rigid-body superposition, to discover the common geometric arrangement of features shared by active compounds.",
            "id": "2414196",
            "problem": "You are given two ligand-based pharmacophores, each represented as a finite set of features. Each feature is a tuple consisting of a categorical feature type and a three-dimensional coordinate with an associated tolerance radius. Formally, a ligand-based pharmacophore is a set $F = \\{(t_i, \\mathbf{x}_i, r_i)\\}_{i=1}^{n}$ where $t_i$ is a categorical feature type drawn from a fixed finite vocabulary (e.g., hydrogen bond acceptor, hydrogen bond donor, hydrophobic, aromatic ring, positive ionizable, negative ionizable), $\\mathbf{x}_i \\in \\mathbb{R}^3$ is a point in three-dimensional space, and $r_i \\in \\mathbb{R}_{0}$ is a tolerance radius (all lengths are in angstroms). We assume a rigid body alignment between two pharmacophores is a transformation of the form $\\mathbf{x} \\mapsto R \\mathbf{x} + \\mathbf{t}$ with $R \\in \\mathbb{R}^{3 \\times 3}$ an orthogonal matrix with $\\det(R) = 1$ and $\\mathbf{t} \\in \\mathbb{R}^3$. Two features $(t_i, \\mathbf{x}_i, r_i)$ and $(t_j, \\mathbf{y}_j, s_j)$ are considered a match if and only if $t_i = t_j$ and $\\|\\mathbf{x}_i - \\mathbf{y}_j\\|_2 \\le r_i + s_j + \\varepsilon$, where $\\varepsilon \\ge 0$ is a global slack parameter. A consensus pharmacophore is formed from matched pairs by creating one consensus feature per matched pair. In this problem you are only required to output the number of matched pairs (that is, the number of consensus features) produced by your algorithm.\n\nStarting from the following fundamental bases:\n- The Euclidean norm in $\\mathbb{R}^3$, namely $\\|\\mathbf{x}\\|_2 = \\sqrt{x_1^2 + x_2^2 + x_3^2}$.\n- The definition of rigid body transformations $R \\in \\mathrm{SO}(3)$ with translation $\\mathbf{t} \\in \\mathbb{R}^3$.\n- The least-squares optimal rigid alignment between two paired point sets can be found by minimizing the sum of squared residuals and solved via singular value decomposition of the covariance matrix (the Kabsch procedure), derived from the method of orthogonal Procrustes.\n- A one-to-one matching across two sets is a selection of disjoint pairs; a greedy selection by increasing distance among edges that satisfy a threshold yields a maximal matching with respect to that constraint.\n\nDesign and implement an algorithm that merges two input pharmacophores into a consensus by:\n- Computing an initial rigid alignment as follows: compute the set of feature types shared by both pharmacophores. If there are at least $2$ shared types, for each shared type aggregate the centroid of that type in each pharmacophore and compute the least-squares optimal rigid transform that aligns the per-type centroids. Otherwise, use the identity transform initially.\n- Iteratively refining the alignment: given a current transform, transform the second pharmacophore and build the set of all potential matches between features of equal type that satisfy the threshold $\\|\\mathbf{x}_i - \\mathbf{y}_j\\|_2 \\le r_i + s_j + \\varepsilon$. Select a one-to-one set of matches greedily by increasing distance (ties are broken deterministically by type and indices). Recompute the optimal rigid transform using the Kabsch procedure on the coordinates of the matched pairs (using pre-transform coordinates from the second pharmacophore), and iterate until the matched set ceases to change or a fixed small iteration cap is reached.\n- Output, for each test case, the number of matched pairs produced by the final iteration. No physical unit is required in the output because it is a count.\n\nTest suite. Each test case is a triple $(P, Q, \\varepsilon)$ where $P$ and $Q$ are pharmacophores given as lists of features of the form $(\\text{type}, \\mathbf{x}, r)$, with $\\mathbf{x}$ a three-dimensional point in angstroms and $r$ a radius in angstroms. Use the following five test cases:\n\n- Test case $1$ (happy path; multiple shared types and a rigid transform with small noise, expect multiple matches):\n  - $P_1 = [(\\text{HBA}, \\left(0, 0, 0\\right), 0.6), (\\text{HBD}, \\left(2, 0, 0\\right), 0.6), (\\text{HYD}, \\left(0, 2, 0\\right), 0.6)]$\n  - $Q_1 = [(\\text{HBA}, \\left(5.02, -3.01, 1.0\\right), 0.6), (\\text{HBD}, \\left(4.97, -1.0, 1.01\\right), 0.6), (\\text{HYD}, \\left(3.01, -2.98, 0.98\\right), 0.6)]$\n  - $\\varepsilon_1 = 0.2$\n- Test case $2$ (partial overlap; some types absent in one pharmacophore, expect some but not all matches):\n  - $P_2 = [(\\text{HBA}, \\left(0, 0, 0\\right), 0.5), (\\text{HBD}, \\left(2, 0, 0\\right), 0.5), (\\text{HYD}, \\left(0, 2, 0\\right), 0.7), (\\text{ARO}, \\left(1, 1, 0\\right), 0.8)]$\n  - $Q_2 = [(\\text{HBA}, \\left(1.01, 0.98, 0\\right), 0.5), (\\text{HBD}, \\left(-1.0, 1.03, 0\\right), 0.5)]$\n  - $\\varepsilon_2 = 0.2$\n- Test case $3$ (no shared types; expect no matches):\n  - $P_3 = [(\\text{HBA}, \\left(0, 0, 0\\right), 0.5), (\\text{HBD}, \\left(1, 0, 0\\right), 0.5)]$\n  - $Q_3 = [(\\text{HYD}, \\left(10, 10, 0\\right), 0.5), (\\text{ARO}, \\left(11, 10, 0\\right), 0.5)]$\n  - $\\varepsilon_3 = 0.2$\n- Test case $4$ (boundary condition; one shared type with exact threshold distance, inclusive inequality must count as a match):\n  - $P_4 = [(\\text{HBA}, \\left(0, 0, 0\\right), 0.5)]$\n  - $Q_4 = [(\\text{HBA}, \\left(1.0, 0, 0\\right), 0.4)]$\n  - $\\varepsilon_4 = 0.1$\n- Test case $5$ (one-to-one constraint; more features of a type in one pharmacophore than the other; greedy selection should choose the closest and leave others unmatched):\n  - $P_5 = [(\\text{HYD}, \\left(0, 0, 0\\right), 0.5), (\\text{HYD}, \\left(0.6, 0, 0\\right), 0.5)]$\n  - $Q_5 = [(\\text{HYD}, \\left(0.2, 0, 0\\right), 0.5)]$\n  - $\\varepsilon_5 = 0.1$\n\nYour program must implement the algorithm described above and compute, for each test case, the number of matched pairs found by the final iteration. Your program should produce a single line of output containing the five results as a comma-separated list enclosed in square brackets (e.g., $[a, b, c, d, e]$). The final answers for each test case are required to be integers. No other text should be printed.",
            "solution": "The provided problem statement is valid. It is scientifically grounded in the principles of computational structural biology and bioinformatics, specifically in the area of pharmacophore modeling. The problem is well-posed, providing a clear, deterministic algorithm for aligning and merging two pharmacophores. The language is objective and unambiguous. The given data and required transformations are physically and mathematically sound.\n\nThe task is to design and implement an algorithm that computes the number of matched features between two pharmacophores, $P$ and $Q$. A pharmacophore is defined as a set of features $F = \\{(t_i, \\mathbf{x}_i, r_i)\\}_{i=1}^{n}$, where $t_i$ is a feature type, $\\mathbf{x}_i \\in \\mathbb{R}^3$ is its spatial coordinate, and $r_i$ is a tolerance radius. The algorithm involves iterative refinement of a rigid-body alignment, which consists of a rotation $R \\in \\mathrm{SO}(3)$ and a translation $\\mathbf{t} \\in \\mathbb{R}^3$, applied to the second pharmacophore $Q$.\n\nThe methodological design is predicated on several core principles:\n\n1.  **Principle of Superposition and Alignment**: The fundamental assumption is that two pharmacophores representing ligands that bind to the same target should be superimposable in three-dimensional space. The optimal superposition is found by a rigid-body transformation $\\mathbf{y} \\mapsto R\\mathbf{y} + \\mathbf{t}$ that minimizes the distance between corresponding features. The problem specifies using the Kabsch algorithm, which provides an analytical solution for the least-squares optimal rigid transformation between two sets of paired points. Given two sets of $N$ corresponding points, represented by $3 \\times N$ matrices $P_{pts}$ and $Q_{pts}$, the algorithm first centers the points by subtracting their respective centroids, $\\mathbf{p}_c$ and $\\mathbf{q}_c$:\n    $$P'_{pts} = P_{pts} - \\mathbf{p}_c$$\n    $$Q'_{pts} = Q_{pts} - \\mathbf{q}_c$$\n    The covariance matrix $H$ is computed as $H = Q'_{pts} (P'_{pts})^T$. A singular value decomposition (SVD) of $H$ is performed, $H = U\\Sigma V^T$. The optimal rotation matrix is then $R = VU^T$. A special correction is applied if $\\det(R) = -1$ to ensure $R$ is a pure rotation. The translation vector is subsequently found as $\\mathbf{t} = \\mathbf{p}_c - R\\mathbf{q}_c$.\n\n2.  **Principle of Feature Conservation**: A meaningful alignment must respect the chemical nature of the features. Therefore, a feature $(t_i, \\mathbf{x}_i, r_i)$ from pharmacophore $P$ can only be matched with a feature $(t_j, \\mathbf{y}_j, s_j)$ from pharmacophore $Q$ if they are of the same type, i.e., $t_i = t_j$.\n\n3.  **Principle of Iterative Refinement**: The optimal alignment depends on knowing the correct correspondence between features, but establishing correspondence requires a good alignment. This chicken-and-egg problem is resolved through an iterative procedure:\n    a.  An initial alignment is computed based on a coarse-grained correspondence: the centroids of shared feature types. If fewer than two feature types are shared, an identity transformation is used as a starting point.\n    b.  Given a current alignment $(R, \\mathbf{t})$, the coordinates of pharmacophore $Q$ are transformed.\n    c.  A new set of one-to-one feature matches is established between $P$ and the transformed $Q$. This is done by first identifying all potential pairs that satisfy both the type identity condition ($t_i = t_j$) and a distance threshold, $\\|\\mathbf{x}_i - (R\\mathbf{y}_j + \\mathbf{t})\\|_2 \\le r_i + s_j + \\varepsilon$, where $\\varepsilon$ is a global slack parameter. From these potential pairs, a one-to-one matching is greedily selected by prioritizing pairs with the smallest distance.\n    d.  A new, improved alignment $(R', \\mathbf{t}')$ is computed using the Kabsch algorithm on the original coordinates of the newly matched feature pairs.\n    e.  This process is repeated until the set of matched pairs no longer changes between iterations, indicating convergence, or until a fixed iteration limit is reached.\n\n4.  **Principle of Parsimony (Greedy Choice)**: Finding the globally optimal one-to-one matching is a complex assignment problem. The algorithm employs a greedy heuristic, which is computationally efficient and effective in practice. By sorting all potential matches by increasing distance and selecting them in order while respecting the one-to-one constraint, the algorithm prioritizes the closest, most confident pairings. This deterministic procedure, with specified tie-breaking rules, ensures a unique solution.\n\nThe final output is the cardinality of the matched set upon convergence, representing the size of the consensus pharmacophore. The implementation will precisely follow these steps to solve the provided test cases.",
            "answer": "```python\nimport numpy as np\nfrom collections import namedtuple\n\n# Use a namedtuple for features for clarity.\nFeature = namedtuple('Feature', ['type', 'coord', 'radius'])\n# Mapping for feature types to ensure deterministic sorting for tie-breaking.\nTYPE_MAP = {'HBA': 0, 'HBD': 1, 'HYD': 2, 'ARO': 3, 'PI': 4, 'NI': 5}\n# Maximum number of iterations for the refinement loop.\nMAX_ITERATIONS = 20\n\ndef kabsch_algorithm(P, Q):\n    \"\"\"\n    Computes the optimal rigid transformation (rotation R, translation t)\n    to align point set Q to point set P using the Kabsch algorithm.\n    Points are represented as column vectors.\n    :param P: A 3xN numpy array of N points in the reference set.\n    :param Q: A 3xN numpy array of N points in the mobile set.\n    :return: A tuple (R, t) where R is a 3x3 rotation matrix and t is a 3x1\n             translation vector. The transformation is: p_new = R @ p_old + t.\n    \"\"\"\n    if P.shape[1] == 0:\n        return np.identity(3), np.zeros((3, 1))\n\n    # 1. Center the point sets\n    p_cen = np.mean(P, axis=1, keepdims=True)\n    q_cen = np.mean(Q, axis=1, keepdims=True)\n    P_centered = P - p_cen\n    Q_centered = Q - q_cen\n\n    # 2. Compute covariance matrix\n    H = Q_centered @ P_centered.T\n\n    # 3. SVD\n    U, _, Vt = np.linalg.svd(H)\n\n    # 4. Compute rotation matrix\n    R = Vt.T @ U.T\n\n    # 5. Handle reflection case\n    if np.linalg.det(R)  0:\n        Vt[2, :] *= -1\n        R = Vt.T @ U.T\n\n    # 6. Compute translation vector\n    t = p_cen - R @ q_cen\n    \n    return R, t\n\ndef solve_pharmacophore_alignment(p_pharma, q_pharma, epsilon):\n    \"\"\"\n    Merges two pharmacophores and returns the number of matched features.\n    \"\"\"\n    # 1. Initial Alignment\n    p_types = {feat.type: [] for feat in p_pharma}\n    q_types = {feat.type: [] for feat in q_pharma}\n    for feat in p_pharma:\n        p_types[feat.type].append(feat.coord)\n    for feat in q_pharma:\n        q_types[feat.type].append(feat.coord)\n    \n    shared_types = sorted(list(set(p_types.keys())  set(q_types.keys())))\n    \n    R = np.identity(3)\n    t = np.zeros((3, 1))\n\n    if len(shared_types) >= 2:\n        p_centroids = np.array([np.mean(p_types[stype], axis=0) for stype in shared_types]).T\n        q_centroids = np.array([np.mean(q_types[stype], axis=0) for stype in shared_types]).T\n        R, t = kabsch_algorithm(p_centroids, q_centroids)\n\n    # 2. Iterative Refinement\n    last_matched_indices = None\n    \n    for _ in range(MAX_ITERATIONS):\n        q_pharma_transformed = []\n        for feat in q_pharma:\n            coord_col = feat.coord.reshape(3, 1)\n            new_coord = (R @ coord_col + t).reshape(3)\n            q_pharma_transformed.append(Feature(feat.type, new_coord, feat.radius))\n            \n        potential_matches = []\n        for p_idx, p_feat in enumerate(p_pharma):\n            for q_idx, q_feat_trans in enumerate(q_pharma_transformed):\n                if p_feat.type == q_feat_trans.type:\n                    dist = np.linalg.norm(p_feat.coord - q_feat_trans.coord)\n                    threshold = p_feat.radius + q_feat_trans.radius + epsilon\n                    if dist = threshold:\n                        potential_matches.append((dist, TYPE_MAP[p_feat.type], p_idx, q_idx))\n        \n        potential_matches.sort()\n        \n        current_matched_indices = []\n        used_p, used_q = set(), set()\n        for _, _, p_idx, q_idx in potential_matches:\n            if p_idx not in used_p and q_idx not in used_q:\n                current_matched_indices.append((p_idx, q_idx))\n                used_p.add(p_idx)\n                used_q.add(q_idx)\n        \n        current_matched_indices.sort()\n        \n        if current_matched_indices == last_matched_indices:\n            break\n        \n        last_matched_indices = current_matched_indices\n        \n        if not current_matched_indices:\n            R, t = np.identity(3), np.zeros((3, 1))\n            continue\n            \n        p_matched_coords = np.array([p_pharma[p_idx].coord for p_idx, _ in current_matched_indices]).T\n        q_matched_coords = np.array([q_pharma[q_idx].coord for _, q_idx in current_matched_indices]).T\n        \n        R, t = kabsch_algorithm(p_matched_coords, q_matched_coords)\n        \n    return len(last_matched_indices) if last_matched_indices is not None else 0\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        ([('HBA', (0, 0, 0), 0.6), ('HBD', (2, 0, 0), 0.6), ('HYD', (0, 2, 0), 0.6)],\n         [('HBA', (5.02, -3.01, 1.0), 0.6), ('HBD', (4.97, -1.0, 1.01), 0.6), ('HYD', (3.01, -2.98, 0.98), 0.6)],\n         0.2),\n        # Test case 2\n        ([('HBA', (0, 0, 0), 0.5), ('HBD', (2, 0, 0), 0.5), ('HYD', (0, 2, 0), 0.7), ('ARO', (1, 1, 0), 0.8)],\n         [('HBA', (1.01, 0.98, 0), 0.5), ('HBD', (-1.0, 1.03, 0), 0.5)],\n         0.2),\n        # Test case 3\n        ([('HBA', (0, 0, 0), 0.5), ('HBD', (1, 0, 0), 0.5)],\n         [('HYD', (10, 10, 0), 0.5), ('ARO', (11, 10, 0), 0.5)],\n         0.2),\n        # Test case 4\n        ([('HBA', (0, 0, 0), 0.5)],\n         [('HBA', (1.0, 0, 0), 0.4)],\n         0.1),\n        # Test case 5\n        ([('HYD', (0, 0, 0), 0.5), ('HYD', (0.6, 0, 0), 0.5)],\n         [('HYD', (0.2, 0, 0), 0.5)],\n         0.1)\n    ]\n\n    results = []\n    for p_raw, q_raw, epsilon in test_cases:\n        p_pharma = [Feature(t, np.array(x), r) for t, x, r in p_raw]\n        q_pharma = [Feature(t, np.array(x), r) for t, x, r in q_raw]\n        num_matches = solve_pharmacophore_alignment(p_pharma, q_pharma, epsilon)\n        results.append(num_matches)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "A pharmacophore model becomes truly powerful when it can quantitatively distinguish active molecules from inactive ones. This practice introduces a rigorous Bayesian statistical method to automatically weight the importance of each feature in your model . By calculating a weight, $w_{j}$, based on a feature's observed frequency in active and inactive compounds, you will learn how to transform a simple geometric hypothesis into a data-driven, predictive scoring function.",
            "id": "2414221",
            "problem": "A pharmacophore model for small molecules is represented by a fixed set of binary features indexed by $j \\in \\{1,\\dots,d\\}$, where each feature encodes the presence or absence of a pharmacophoric element (for example, a hydrogen bond donor at a location) in a ligand. A dataset contains ligands labeled as active or inactive. For each feature $j$, let $x_{j} \\in \\{0,1\\}$ denote whether the feature is present in a ligand, and let $y \\in \\{0,1\\}$ denote the class label, where $y=1$ indicates active and $y=0$ indicates inactive. Assume the following probabilistic model: conditional on $y=c \\in \\{0,1\\}$ and for each feature $j$, $x_{j} \\mid y=c \\sim \\mathrm{Bernoulli}(\\theta^{(c)}_{j})$, where the parameters $\\theta^{(c)}_{j}$ are unknown and independent across $j$ and $c$. Assume independent Beta priors $\\theta^{(c)}_{j} \\sim \\mathrm{Beta}(\\alpha,\\beta)$ with fixed hyperparameters $\\alpha0$ and $\\beta0$ shared across all $j$ and $c$. For each feature $j$, the training data for class $c$ are summarized by $N^{(c)}$ total ligands and $n^{(c)}_{j}$ ligands in which $x_{j}=1$.\n\nDefine the importance weight of feature $j$ to be\n$$\nw_{j} \\equiv \\log\\left(\\frac{\\mathrm{odds}\\!\\left(\\mathbb{E}[\\theta^{(1)}_{j} \\mid \\text{data}]\\right)}{\\mathrm{odds}\\!\\left(\\mathbb{E}[\\theta^{(0)}_{j} \\mid \\text{data}]\\right)}\\right),\n$$\nwhere for any $p \\in (0,1)$, $\\mathrm{odds}(p) \\equiv \\dfrac{p}{1-p}$, and $\\mathbb{E}[\\theta^{(c)}_{j} \\mid \\text{data}]$ denotes the posterior mean of $\\theta^{(c)}_{j}$ under the model and prior above given the summarized counts. All logarithms are natural logarithms. The output for a test case is the list $[w_{1},\\dots,w_{d}]$ in the order of features.\n\nCompute $[w_{1},\\dots,w_{d}]$ for each of the following test cases. For each case, you are given the number of actives $N^{(1)}$, the number of inactives $N^{(0)}$, the active counts vector $[n^{(1)}_{1},\\dots,n^{(1)}_{d}]$, the inactive counts vector $[n^{(0)}_{1},\\dots,n^{(0)}_{d}]$, and the shared Beta prior hyperparameters $(\\alpha,\\beta)$.\n\nTest Suite:\n- Case $1$: $N^{(1)}=10$, $N^{(0)}=12$, $[n^{(1)}_{j}]_{j=1}^{4} = [6,2,8,0]$, $[n^{(0)}_{j}]_{j=1}^{4} = [1,5,6,0]$, $(\\alpha,\\beta)=(0.5,0.5)$.\n- Case $2$: $N^{(1)}=3$, $N^{(0)}=20$, $[n^{(1)}_{j}]_{j=1}^{3} = [0,3,0]$, $[n^{(0)}_{j}]_{j=1}^{3} = [10,0,1]$, $(\\alpha,\\beta)=(0.5,0.5)$.\n- Case $3$: $N^{(1)}=50$, $N^{(0)}=50$, $[n^{(1)}_{j}]_{j=1}^{4} = [25,50,0,1]$, $[n^{(0)}_{j}]_{j=1}^{4} = [25,50,0,2]$, $(\\alpha,\\beta)=(1.0,1.0)$.\n- Case $4$: $N^{(1)}=1$, $N^{(0)}=1$, $[n^{(1)}_{j}]_{j=1}^{2} = [1,0]$, $[n^{(0)}_{j}]_{j=1}^{2} = [0,1]$, $(\\alpha,\\beta)=(2.0,3.0)$.\n\nAnswer specification:\n- For each test case, compute the vector $[w_{1},\\dots,w_{d}]$ in natural logarithm units as defined above.\n- Return each $w_{j}$ rounded to $6$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the bracketed, comma-separated list for a test case. For example, the overall structure must be $[[r_{1,1},\\dots,r_{1,d_{1}}],[r_{2,1},\\dots,r_{2,d_{2}}],\\dots]$ with no spaces, where $r_{k,\\ell}$ denotes the rounded value for feature $\\ell$ in case $k$.",
            "solution": "The problem statement has been validated and is deemed acceptable. It presents a standard, well-posed problem in Bayesian statistical modeling applied to computational biology, specifically in the context of pharmacophore analysis. All necessary information is provided, the premises are scientifically sound, and there are no contradictions or ambiguities. We may proceed with the solution.\n\nThe problem requires the computation of a feature importance weight, $w_{j}$, defined as the log-odds ratio of posterior mean probabilities for a feature being present in active versus inactive molecules. The model is a Naive Bayes classifier with Bernoulli-distributed features and Beta-distributed priors on the Bernoulli parameters.\n\nLet us begin by formalizing the Bayesian inference for a single parameter $\\theta^{(c)}_{j}$, which is the probability of feature $j$ being present ($x_j=1$) in a ligand of class $c \\in \\{0, 1\\}$.\n\nThe prior distribution for the parameter $\\theta^{(c)}_{j}$ is given as a Beta distribution with hyperparameters $\\alpha$ and $\\beta$:\n$$\n\\theta^{(c)}_{j} \\sim \\mathrm{Beta}(\\alpha, \\beta)\n$$\nThe probability density function (PDF) is proportional to:\n$$\np(\\theta^{(c)}_{j}) \\propto (\\theta^{(c)}_{j})^{\\alpha-1} (1 - \\theta^{(c)}_{j})^{\\beta-1}\n$$\n\nThe data for feature $j$ and class $c$ consists of $N^{(c)}$ ligands, among which $n^{(c)}_{j}$ have the feature present ($x_j=1$) and $N^{(c)} - n^{(c)}_{j}$ have the feature absent ($x_j=0$). Assuming the ligands are independent and identically distributed, the likelihood of observing $n^{(c)}_{j}$ successes in $N^{(c)}$ trials follows a binomial distribution. The likelihood function for $\\theta^{(c)}_{j}$ is:\n$$\nL(\\text{data} \\mid \\theta^{(c)}_{j}) = P(n^{(c)}_{j} \\mid N^{(c)}, \\theta^{(c)}_{j}) \\propto (\\theta^{(c)}_{j})^{n^{(c)}_{j}} (1 - \\theta^{(c)}_{j})^{N^{(c)} - n^{(c)}_{j}}\n$$\n\nAccording to Bayes' theorem, the posterior distribution of $\\theta^{(c)}_{j}$ is proportional to the product of the prior and the likelihood:\n$$\np(\\theta^{(c)}_{j} \\mid \\text{data}) \\propto p(\\theta^{(c)}_{j}) \\cdot L(\\text{data} \\mid \\theta^{(c)}_{j})\n$$\n$$\np(\\theta^{(c)}_{j} \\mid \\text{data}) \\propto \\left((\\theta^{(c)}_{j})^{\\alpha-1} (1 - \\theta^{(c)}_{j})^{\\beta-1}\\right) \\cdot \\left((\\theta^{(c)}_{j})^{n^{(c)}_{j}} (1 - \\theta^{(c)}_{j})^{N^{(c)} - n^{(c)}_{j}}\\right)\n$$\nCombining terms, we get:\n$$\np(\\theta^{(c)}_{j} \\mid \\text{data}) \\propto (\\theta^{(c)}_{j})^{n^{(c)}_{j} + \\alpha - 1} (1 - \\theta^{(c)}_{j})^{N^{(c)} - n^{(c)}_{j} + \\beta - 1}\n$$\nThis expression is the kernel of a Beta distribution. This demonstrates the conjugacy of the Beta prior with the Bernoulli/Binomial likelihood. The posterior distribution is therefore:\n$$\n\\theta^{(c)}_{j} \\mid \\text{data} \\sim \\mathrm{Beta}(\\alpha', \\beta')\n$$\nwhere the posterior hyperparameters $\\alpha'$ and $\\beta'$ are:\n$$\n\\alpha' = n^{(c)}_{j} + \\alpha\n$$\n$$\n\\beta' = N^{(c)} - n^{(c)}_{j} + \\beta\n$$\n\nThe problem requires the posterior mean, $\\mathbb{E}[\\theta^{(c)}_{j} \\mid \\text{data}]$. For a random variable $X \\sim \\mathrm{Beta}(a,b)$, its expectation is $\\mathbb{E}[X] = \\frac{a}{a+b}$. Applying this to our posterior distribution, we find the posterior mean of $\\theta^{(c)}_{j}$:\n$$\n\\hat{\\theta}^{(c)}_{j} \\equiv \\mathbb{E}[\\theta^{(c)}_{j} \\mid \\text{data}] = \\frac{\\alpha'}{\\alpha' + \\beta'} = \\frac{n^{(c)}_{j} + \\alpha}{(n^{(c)}_{j} + \\alpha) + (N^{(c)} - n^{(c)}_{j} + \\beta)} = \\frac{n^{(c)}_{j} + \\alpha}{N^{(c)} + \\alpha + \\beta}\n$$\n\nNext, we compute the odds of this posterior mean probability. The odds function is defined as $\\mathrm{odds}(p) = \\frac{p}{1-p}$.\nFor $\\hat{\\theta}^{(c)}_{j}$, we have:\n$$\n1 - \\hat{\\theta}^{(c)}_{j} = 1 - \\frac{n^{(c)}_{j} + \\alpha}{N^{(c)} + \\alpha + \\beta} = \\frac{(N^{(c)} + \\alpha + \\beta) - (n^{(c)}_{j} + \\alpha)}{N^{(c)} + \\alpha + \\beta} = \\frac{N^{(c)} - n^{(c)}_{j} + \\beta}{N^{(c)} + \\alpha + \\beta}\n$$\nTherefore, the odds are:\n$$\n\\mathrm{odds}(\\hat{\\theta}^{(c)}_{j}) = \\frac{\\hat{\\theta}^{(c)}_{j}}{1 - \\hat{\\theta}^{(c)}_{j}} = \\frac{\\frac{n^{(c)}_{j} + \\alpha}{N^{(c)} + \\alpha + \\beta}}{\\frac{N^{(c)} - n^{(c)}_{j} + \\beta}{N^{(c)} + \\alpha + \\beta}} = \\frac{n^{(c)}_{j} + \\alpha}{N^{(c)} - n^{(c)}_{j} + \\beta}\n$$\n\nFinally, we substitute this expression into the definition of the importance weight $w_{j}$:\n$$\nw_{j} = \\log\\left(\\frac{\\mathrm{odds}(\\hat{\\theta}^{(1)}_{j})}{\\mathrm{odds}(\\hat{\\theta}^{(0)}_{j})}\\right) = \\log\\left( \\frac{\\frac{n^{(1)}_{j} + \\alpha}{N^{(1)} - n^{(1)}_{j} + \\beta}}{\\frac{n^{(0)}_{j} + \\alpha}{N^{(0)} - n^{(0)}_{j} + \\beta}} \\right)\n$$\nUsing the property of logarithms, $\\log(\\frac{A}{B}) = \\log(A) - \\log(B)$, this can be written as:\n$$\nw_{j} = \\log\\left(\\frac{n^{(1)}_{j} + \\alpha}{N^{(1)} - n^{(1)}_{j} + \\beta}\\right) - \\log\\left(\\frac{n^{(0)}_{j} + \\alpha}{N^{(0)} - n^{(0)}_{j} + \\beta}\\right)\n$$\nThis is the final, operational formula for computing the weight of each feature $j$. This formula is now applied to each of the provided test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the pharmacophore feature weighting problem for the given test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'N1': 10, 'N0': 12, 'n1': np.array([6, 2, 8, 0]), 'n0': np.array([1, 5, 6, 0]), 'alpha': 0.5, 'beta': 0.5},\n        {'N1': 3, 'N0': 20, 'n1': np.array([0, 3, 0]), 'n0': np.array([10, 0, 1]), 'alpha': 0.5, 'beta': 0.5},\n        {'N1': 50, 'N0': 50, 'n1': np.array([25, 50, 0, 1]), 'n0': np.array([25, 50, 0, 2]), 'alpha': 1.0, 'beta': 1.0},\n        {'N1': 1, 'N0': 1, 'n1': np.array([1, 0]), 'n0': np.array([0, 1]), 'alpha': 2.0, 'beta': 3.0}\n    ]\n\n    # A helper function to compute weights for a single case.\n    def compute_weights(N1, N0, n1_vec, n0_vec, alpha, beta):\n        \"\"\"\n        Computes the importance weights w_j for a single test case.\n        \n        The formula for w_j is:\n        w_j = log(odds(E[theta_j^1|data])) - log(odds(E[theta_j^0|data]))\n            = log((n1_j + alpha) / (N1 - n1_j + beta)) - log((n0_j + alpha) / (N0 - n0_j + beta))\n        \n        Args:\n            N1 (int): Number of active ligands.\n            N0 (int): Number of inactive ligands.\n            n1_vec (np.ndarray): Counts of feature presence for active ligands.\n            n0_vec (np.ndarray): Counts of feature presence for inactive ligands.\n            alpha (float): Beta prior hyperparameter.\n            beta (float): Beta prior hyperparameter.\n        \n        Returns:\n            np.ndarray: An array of computed weights w_j.\n        \"\"\"\n        # Posterior odds for the active class (c=1)\n        odds1 = (n1_vec + alpha) / (N1 - n1_vec + beta)\n        \n        # Posterior odds for the inactive class (c=0)\n        odds0 = (n0_vec + alpha) / (N0 - n0_vec + beta)\n        \n        # Compute the log-odds ratio, which is the feature weight w_j\n        weights = np.log(odds1) - np.log(odds0)\n        \n        return weights\n\n    all_results_str = []\n    for case in test_cases:\n        # Extract parameters for the current case\n        N1 = case['N1']\n        N0 = case['N0']\n        n1_vec = case['n1']\n        n0_vec = case['n0']\n        alpha = case['alpha']\n        beta = case['beta']\n\n        # Calculate the weights for the current case\n        weights = compute_weights(N1, N0, n1_vec, n0_vec, alpha, beta)\n        \n        # Format the results for the current case to 6 decimal places\n        case_result_str = f\"[{','.join([f'{w:.6f}' for w in weights])}]\"\n        \n        all_results_str.append(case_result_str)\n\n    # Combine all case results into the final specified format\n    final_output = f\"[{','.join(all_results_str)}]\"\n    \n    # Print the final result string\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}