{
    "hands_on_practices": [
        {
            "introduction": "Before an end-to-end model generates a final 3D structure, it often first predicts a \"distogram\"—a matrix representing the probable distance between every pair of amino acids. A fundamental test of this intermediate output is to check for geometric self-consistency. This hands-on practice challenges you to implement a powerful quality control metric based on the triangle inequality, a core axiom of Euclidean geometry, to evaluate the physical plausibility of a predicted distogram . By quantifying violations, you can assess the local quality of a prediction even without a known ground-truth structure.",
            "id": "2387757",
            "problem": "You are given the task of formalizing a per-residue local quality metric for predicted protein residue-residue distances (a \"distogram\" approximation) by quantifying violations of the triangle inequality, a fundamental property of Euclidean distances in three-dimensional space. In a metric space such as Euclidean $\\mathbb{R}^3$, the distance function $d(\\cdot,\\cdot)$ between any three points $i$, $j$, and $k$ must satisfy the triangle inequality $d(i,k) \\le d(i,j) + d(j,k)$. For protein structures, using distances between $\\alpha$-carbon atoms, this inequality must hold exactly for the true structure. However, predicted distograms may exhibit local inconsistencies where $d(i,k)  d(i,j) + d(j,k)$ for some triplets, providing a basis for a local quality metric of the prediction around residue $j$.\n\nStarting from the triangle inequality in Euclidean space as the foundational base and the notion that predicted distograms approximate true metric distances but may violate metric axioms, design and implement an algorithm to compute, for each residue index $j$, a local violation score defined as the average magnitude by which the triangle inequality is violated when $j$ serves as the intermediate node between all unordered pairs $(i,k)$ with $i \\ne j$, $k \\ne j$, and $i  k$. More precisely, for each triple $(i,j,k)$ with $ik$ and both distinct from $j$, compute the positive violation magnitude, defined as the positive part of $d(i,k) - \\left(d(i,j) + d(j,k)\\right)$ (that is, use $0$ whenever the expression is negative or zero), and average these values over all such unordered pairs with $j$ fixed. This average is the per-residue local violation score for $j$. The score has units of Angstroms (Å). A lower score indicates higher local consistency.\n\nYour program must:\n- Assume that for each test case, the input is a symmetric distance matrix $D \\in \\mathbb{R}^{n \\times n}$ with $D_{ii} = 0$ for all $i$, entries in Angstroms, and indices $i,j,k$ $0$-indexed.\n- For each residue index $j \\in \\{0,\\dots,n-1\\}$, compute the average positive violation magnitude over all unordered pairs $(i,k)$ with $ik$, $i \\ne j$, $k \\ne j$. The average is taken over exactly $\\binom{n-1}{2}$ pairs for each $j$. If there are no such pairs (which does not occur in the provided tests), define the score as $0$.\n- Report, for each test case, the vector of per-residue scores $V = [V_0,\\dots,V_{n-1}]$, with each entry rounded to $6$ decimal places. The unit is Angstroms. All angles, if any, are irrelevant here. Do not express anything as a percentage.\n\nTest suite:\nProvide solutions for the following four distance matrices (all in Angstroms, symmetric, and with zero diagonal):\n\n- Test case $1$ ($n=4$), matrix $D^{(1)}$:\n  - Row $0$: [$0$, $1.0$, $3.0$, $1.41421356237$]\n  - Row $1$: [$1.0$, $0$, $1.2$, $1.0$]\n  - Row $2$: [$3.0$, $1.2$, $0$, $1.562049935$]\n  - Row $3$: [$1.41421356237$, $1.0$, $1.562049935$, $0$]\n\n- Test case $2$ ($n=4$), matrix $D^{(2)}$ constructed from points on a line:\n  - Row $0$: [$0$, $1$, $3$, $6$]\n  - Row $1$: [$1$, $0$, $2$, $5$]\n  - Row $2$: [$3$, $2$, $0$, $3$]\n  - Row $3$: [$6$, $5$, $3$, $0$]\n\n- Test case $3$ ($n=3$), matrix $D^{(3)}$ with a clear violation for the middle residue:\n  - Row $0$: [$0$, $1$, $3$]\n  - Row $1$: [$1$, $0$, $1$]\n  - Row $2$: [$3$, $1$, $0$]\n\n- Test case $4$ ($n=5$), matrix $D^{(4)}$ derived from a planar geometry with two inflated distances to induce multiple local violations:\n  - Row $0$: [$0$, $1.0$, $2.0$, $1.414213562373$, $5.0$]\n  - Row $1$: [$1.0$, $0$, $1.0$, $1.0$, $2.2360679775$]\n  - Row $2$: [$2.0$, $1.0$, $0$, $3.0$, $2.0$]\n  - Row $3$: [$1.414213562373$, $1.0$, $3.0$, $0$, $1.414213562373$]\n  - Row $4$: [$5.0$, $2.2360679775$, $2.0$, $1.414213562373$, $0$]\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a list of the rounded per-residue scores for one test case. For example, print a string like $[[v_{0}^{(1)},\\dots,v_{n_1-1}^{(1)}],[v_{0}^{(2)},\\dots],\\dots]$, with each $v$ rounded to $6$ decimals. Units are Angstroms, but the unit label must not appear in the printed line.",
            "solution": "The problem statement presented is valid. It is scientifically grounded, well-posed, and objective. The task is to formalize and compute a per-residue local quality score for a predicted protein residue-residue distance matrix, known as a distogram. The basis for this metric is the triangle inequality, a fundamental axiom of any metric space, which includes the three-dimensional Euclidean space ($\\mathbb{R}^3$) where protein structures reside. A predicted distogram may not be perfectly embeddable in $\\mathbb{R}^3$, leading to violations of this inequality. Quantifying these violations provides a direct measure of local geometric inconsistency in the predicted structure.\n\nThe problem is formalized as follows. Let the set of residue indices be $\\mathcal{R} = \\{0, 1, \\dots, n-1\\}$, where $n$ is the number of residues. The input is a symmetric distance matrix $D$ of size $n \\times n$, where the element $D_{ij}$ represents the predicted distance $d(i,j)$ between residues $i$ and $j$. By definition, $D_{ii} = 0$ and $D_{ij} = D_{ji}$ for all $i, j \\in \\mathcal{R}$.\n\nThe triangle inequality for any three points $i, j, k$ states that the distance between two points is no greater than the sum of the distances from each of those two points to a third point. For any triplet of residues, this can be expressed in three ways:\n$$ d(i,k) \\le d(i,j) + d(j,k) $$\n$$ d(i,j) \\le d(i,k) + d(k,j) $$\n$$ d(j,k) \\le d(j,i) + d(i,k) $$\nThe problem defines a local quality score for a specific residue $j$ by considering it as the intermediate point in the inequality. A violation occurs if the direct distance $d(i,k)$ is greater than the path through $j$, i.e., $d(i,k)  d(i,j) + d(j,k)$.\n\nThe magnitude of a single violation for the triplet $(i,j,k)$ with $j$ as the intermediate residue is defined as the positive part of the difference:\n$$ v_{ijk} = \\max\\left(0, D_{ik} - (D_{ij} + D_{jk})\\right) $$\nThis value is non-zero only when the triangle inequality is violated.\n\nThe per-residue local violation score for a residue $j$, which we denote as $V_j$, is defined as the average of these violation magnitudes over all possible choices for the outer pair $(i,k)$. For a fixed $j$, the other residues form a set $\\mathcal{R}_j = \\mathcal{R} \\setminus \\{j\\}$, which has a size of $n-1$. The number of unique unordered pairs $\\{i,k\\}$ that can be formed from this set is given by the binomial coefficient $\\binom{n-1}{2}$. The score $V_j$ is therefore:\n$$ V_j = \\frac{1}{\\binom{n-1}{2}} \\sum_{\\{i,k\\} \\subset \\mathcal{R}_j, ik} v_{ijk} $$\nIf $n-1  2$ (i.e., $n  3$), the number of pairs is $0$, and the score $V_j$ is defined as $0$.\n\nThe algorithm to compute the vector of scores $V = [V_0, V_1, \\dots, V_{n-1}]$ is as follows:\n1. For each residue index $j$ from $0$ to $n-1$:\n    a. If $n  3$, set $V_j = 0$ and continue. The number of pairs to average over, $N_{pairs} = \\frac{(n-1)(n-2)}{2}$, is zero.\n    b. Otherwise, initialize a sum for the total violation, $\\Sigma_j = 0$.\n    c. Identify the set of indices other than $j$, $\\mathcal{R}_j = \\{m \\in \\mathcal{R} \\mid m \\ne j\\}$.\n    d. Iterate through all unique, unordered pairs $\\{i, k\\}$ from $\\mathcal{R}_j$. A systematic way to achieve this is to iterate with an outer loop for $i$ over $\\mathcal{R}_j$ and an inner loop for $k$ over $\\mathcal{R}_j$ such that $k  i$.\n    e. For each such pair $\\{i,k\\}$, calculate the violation magnitude $v_{ijk} = \\max(0, D_{ik} - (D_{ij} + D_{jk}))$.\n    f. Add this value to the sum: $\\Sigma_j = \\Sigma_j + v_{ijk}$.\n    g. After iterating through all $\\binom{n-1}{2}$ pairs, compute the average score: $V_j = \\Sigma_j / N_{pairs}$.\n2. Collect the scores $\\{V_0, V_1, \\dots, V_{n-1}\\}$ to form the final result vector.\n\nThis procedure is implemented for each test case provided. The use of NumPy arrays for the distance matrices facilitates clean and efficient access to the distance values $D_{ij}$. The results for each test case are calculated, rounded to $6$ decimal places, and presented in the specified format.",
            "answer": "```python\nimport numpy as np\n\ndef compute_violation_scores(dist_matrix: np.ndarray) - list[float]:\n    \"\"\"\n    Computes the per-residue local violation score for a given distance matrix.\n\n    Args:\n        dist_matrix: A symmetric n x n numpy array representing the distance matrix.\n\n    Returns:\n        A list of per-residue violation scores, rounded to 6 decimal places.\n    \"\"\"\n    D = np.array(dist_matrix, dtype=np.float64)\n    n = D.shape[0]\n    \n    if n  3:\n        # If n  3, no triangles can be formed. The number of pairs is 0.\n        # The problem defines the score as 0 in this case.\n        return [0.0] * n\n\n    scores = np.zeros(n, dtype=np.float64)\n    num_pairs = (n - 1) * (n - 2) // 2\n\n    # Iterate over each residue j, which will serve as the intermediate point.\n    for j in range(n):\n        total_violation = 0.0\n        \n        # Create a list of indices excluding j.\n        other_indices = [idx for idx in range(n) if idx != j]\n        \n        # Iterate over all unique pairs (i, k) from the remaining indices.\n        for idx_i in range(len(other_indices)):\n            for idx_k in range(idx_i + 1, len(other_indices)):\n                i = other_indices[idx_i]\n                k = other_indices[idx_k]\n                \n                # Retrieve distances for the triplet (i, j, k).\n                # D_ik is the direct distance.\n                # D_ij + D_jk is the path length through the intermediate residue j.\n                d_ik = D[i, k]\n                d_ij = D[i, j]\n                d_jk = D[k, j] # Using D[k,j] since matrix is symmetric.\n                \n                # Calculate the violation of the triangle inequality: d(i,k) = d(i,j) + d(j,k)\n                violation = d_ik - (d_ij + d_jk)\n                \n                # Accumulate only positive violations.\n                if violation  0:\n                    total_violation += violation\n        \n        # The score for residue j is the average violation over all pairs (i, k).\n        scores[j] = total_violation / num_pairs\n        \n    return list(scores)\n\ndef solve():\n    \"\"\"\n    Solves the problem for all given test cases and prints the result.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        [\n            [0, 1.0, 3.0, 1.41421356237],\n            [1.0, 0, 1.2, 1.0],\n            [3.0, 1.2, 0, 1.562049935],\n            [1.41421356237, 1.0, 1.562049935, 0]\n        ],\n        # Test case 2\n        [\n            [0, 1, 3, 6],\n            [1, 0, 2, 5],\n            [3, 2, 0, 3],\n            [6, 5, 3, 0]\n        ],\n        # Test case 3\n        [\n            [0, 1, 3],\n            [1, 0, 1],\n            [3, 1, 0]\n        ],\n        # Test case 4\n        [\n            [0, 1.0, 2.0, 1.414213562373, 5.0],\n            [1.0, 0, 1.0, 1.0, 2.2360679775],\n            [2.0, 1.0, 0, 3.0, 2.0],\n            [1.414213562373, 1.0, 3.0, 0, 1.414213562373],\n            [5.0, 2.2360679775, 2.0, 1.414213562373, 0]\n        ]\n    ]\n\n    results = []\n    for D_matrix in test_cases:\n        result_vector = compute_violation_scores(D_matrix)\n        results.append(result_vector)\n\n    # Format the final output string as a list of lists without spaces.\n    formatted_vectors = []\n    for vec in results:\n        # Round each score to 6 decimal places.\n        rounded_vec = [round(v, 6) for v in vec]\n        # Format as a string \"[v1,v2,...]\"\n        str_vec = f\"[{','.join(f'{v:.6f}' for v in rounded_vec)}]\"\n        formatted_vectors.append(str_vec)\n    \n    # Final output format: [[...],[...],...]\n    print(f\"[{','.join(formatted_vectors)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Modern protein structure predictors can incorporate information from experimentally determined structures of related proteins, known as templates. However, this template data can be noisy or incomplete. This exercise explores the crucial concept of model robustness by asking you to quantify how sensitive a simplified, template-based scoring function is to noise in the input atomic coordinates . You will derive and implement an exact formula for the expected shift in the model's score, providing a hands-on understanding of how to mathematically analyze a model's stability against imperfect data.",
            "id": "2387810",
            "problem": "An end-to-end protein structure prediction system may incorporate a template-dependent scoring module that aggregates pairwise geometric cues from a provided template structure. Consider a simplified surrogate of such a module that maps a template with $N$ residues to a scalar score $F(X)$ based on the coordinates $X = (x_1,\\dots,x_N)$, where each $x_i \\in \\mathbb{R}^3$ is given in Angstroms (Angstrom is the unit of length used throughout). For a fixed parameter $\\gamma  0$ with units $\\text{Angstrom}^{-2}$, define\n- If $N  2$, set $F(X) = 0$ by convention.\n- If $N \\ge 2$, let $M = \\frac{N(N-1)}{2}$ be the number of unordered residue pairs and define\n$$\nF(X) = \\frac{1}{M} \\sum_{1 \\le i  j \\le N} \\exp\\!\\big(-\\gamma \\, \\lVert x_i - x_j \\rVert^2\\big).\n$$\n\nAssume the template coordinates are perturbed by additive, independent and identically distributed (i.i.d.) Gaussian noise per residue:\n$$\nx_i' = x_i + \\varepsilon_i, \\quad \\text{with } \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2 I_3),\n$$\nwhere $I_3$ is the $3 \\times 3$ identity matrix and $\\sigma \\ge 0$ is the noise standard deviation in Angstroms. Define the model’s sensitivity to coordinate noise at level $\\sigma$ by the absolute shift in the expected score,\n$$\nS(\\sigma; X, \\gamma) = \\left| \\mathbb{E}\\left[F(X')\\right] - F(X) \\right|.\n$$\n\nYour program must compute $S(\\sigma; X, \\gamma)$ exactly for each provided test case using the definitions above. All coordinates must be treated in Angstroms, $\\sigma$ is in Angstroms, $\\gamma$ is in $\\text{Angstrom}^{-2}$, and $S(\\sigma; X, \\gamma)$ is dimensionless. Report each result as a floating-point number rounded to exactly six decimal places.\n\nTest suite of parameter values:\n- Case $1$: $N=3$, coordinates $x_1=(0,0,0)$, $x_2=(3.8,0,0)$, $x_3=(7.6,0,0)$, $\\gamma=0.5$, $\\sigma=0.0$.\n- Case $2$: $N=3$, coordinates $x_1=(0,0,0)$, $x_2=(3.8,0,0)$, $x_3=(7.6,0,0)$, $\\gamma=0.5$, $\\sigma=0.5$.\n- Case $3$: $N=4$, coordinates $x_1=(0,0,0)$, $x_2=(0,3.8,0)$, $x_3=(3.8,0,0)$, $x_4=(3.8,3.8,0)$, $\\gamma=0.3$, $\\sigma=1.0$.\n- Case $4$: $N=2$, coordinates $x_1=(0,0,0)$, $x_2=(3.8,0,0)$, $\\gamma=1.0$, $\\sigma=2.0$.\n- Case $5$: $N=1$, coordinates $x_1=(0,0,0)$, $\\gamma=0.5$, $\\sigma=1.0$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3,r_4,r_5]$), where $r_k$ is the value of $S(\\sigma; X, \\gamma)$ for Case $k$, rounded to exactly six decimal places.",
            "solution": "The problem requires the determination of the model's sensitivity to coordinate noise, $S(\\sigma; X, \\gamma)$, defined as the absolute difference between the expected score of a noise-perturbed structure, $\\mathbb{E}\\left[F(X')\\right]$, and the score of the original unperturbed structure, $F(X)$. The definition is given as:\n$$\nS(\\sigma; X, \\gamma) = \\left| \\mathbb{E}\\left[F(X')\\right] - F(X) \\right|\n$$\nThe coordinates are perturbed by additive i.i.d. Gaussian noise, $x_i' = x_i + \\varepsilon_i$, where each noise vector $\\varepsilon_i$ is distributed according to $\\mathcal{N}(0, \\sigma^2 I_3)$.\n\nFirst, we analyze the trivial cases. For a system with $N  2$ residues, the score function is defined as $F(X) = 0$. The perturbed structure $X'$ also has $N  2$ residues, so $F(X') = 0$ by the same definition. The expectation is thus $\\mathbb{E}[F(X')] = \\mathbb{E}[0] = 0$. Consequently, for $N  2$, the sensitivity is $S(\\sigma; X, \\gamma) = |0 - 0| = 0$. This addresses Case 5 ($N=1$).\n\nFor the main case where $N \\ge 2$, the score function is:\n$$\nF(X) = \\frac{1}{M} \\sum_{1 \\le i  j \\le N} \\exp\\!\\big(-\\gamma \\, \\lVert x_i - x_j \\rVert^2\\big), \\quad M = \\frac{N(N-1)}{2}\n$$\nThe score for the perturbed structure $X'$ is:\n$$\nF(X') = \\frac{1}{M} \\sum_{1 \\le i  j \\le N} \\exp\\!\\big(-\\gamma \\, \\lVert x_i' - x_j' \\rVert^2\\big)\n$$\nTo calculate the sensitivity, we must compute the expected value of $F(X')$. By leveraging the linearity of expectation, we can write:\n$$\n\\mathbb{E}\\left[F(X')\\right] = \\frac{1}{M} \\sum_{1 \\le i  j \\le N} \\mathbb{E}\\left[ \\exp\\!\\big(-\\gamma \\, \\lVert x_i' - x_j' \\rVert^2\\big) \\right]\n$$\nThis reduces the problem to computing the expectation of a single exponential term for each residue pair $(i, j)$.\n\nLet $d_{ij} = x_i - x_j$ be the vector difference for the original coordinates. The corresponding vector for the perturbed coordinates is $d_{ij}' = x_i' - x_j'$, which can be expressed as:\n$$\nd_{ij}' = (x_i + \\varepsilon_i) - (x_j + \\varepsilon_j) = (x_i - x_j) + (\\varepsilon_i - \\varepsilon_j) = d_{ij} + \\varepsilon_{ij}\n$$\nwhere $\\varepsilon_{ij} = \\varepsilon_i - \\varepsilon_j$. For $i \\ne j$, the noise vectors $\\varepsilon_i$ and $\\varepsilon_j$ are independent and identically distributed as $\\mathcal{N}(0, \\sigma^2 I_3)$. The difference vector $\\varepsilon_{ij}$ is therefore also a Gaussian random vector. Its mean is $\\mathbb{E}[\\varepsilon_{ij}] = \\mathbb{E}[\\varepsilon_i] - \\mathbb{E}[\\varepsilon_j] = 0 - 0 = 0$. Its covariance matrix, due to independence, is $\\text{Cov}(\\varepsilon_{ij}) = \\text{Cov}(\\varepsilon_i) + \\text{Cov}(\\varepsilon_j) = \\sigma^2 I_3 + \\sigma^2 I_3 = 2\\sigma^2 I_3$. Therefore, $\\varepsilon_{ij} \\sim \\mathcal{N}(0, 2\\sigma^2 I_3)$.\nThis means the perturbed difference vector $d_{ij}'$ follows a multivariate normal distribution with mean $d_{ij}$ and covariance matrix $2\\sigma^2 I_3$, i.e., $d_{ij}' \\sim \\mathcal{N}(d_{ij}, 2\\sigma^2 I_3)$.\n\nWe must compute $\\mathbb{E}\\left[ \\exp(-\\gamma \\lVert d_{ij}' \\rVert^2) \\right]$. Let $v = d_{ij}'$. The components of $v$, denoted $v_k$ for $k \\in \\{1, 2, 3\\}$, are independent, with each component following a one-dimensional normal distribution $v_k \\sim \\mathcal{N}(\\mu_k, \\tau^2)$, where $\\mu_k$ is the $k$-th component of $d_{ij}$ and the variance is $\\tau^2 = 2\\sigma^2$. The expectation factorizes over the three independent Cartesian components:\n$$\n\\mathbb{E}\\left[ \\exp(-\\gamma \\lVert v \\rVert^2) \\right] = \\mathbb{E}\\left[ \\exp(-\\gamma(v_1^2 + v_2^2 + v_3^2)) \\right] = \\prod_{k=1}^3 \\mathbb{E}\\left[ \\exp(-\\gamma v_k^2) \\right]\n$$\nFor a single component $Z \\sim \\mathcal{N}(\\mu, \\tau^2)$, the expectation is found by integrating against the probability density function:\n$$\n\\mathbb{E}\\left[ \\exp(-\\gamma Z^2) \\right] = \\int_{-\\infty}^{\\infty} \\exp(-\\gamma z^2) \\frac{1}{\\sqrt{2\\pi\\tau^2}} \\exp\\left(-\\frac{(z-\\mu)^2}{2\\tau^2}\\right) dz\n$$\nThis is a standard integral whose evaluation by completing the square in the exponent yields:\n$$\n\\mathbb{E}\\left[ \\exp(-\\gamma Z^2) \\right] = \\frac{1}{\\sqrt{1+2\\gamma\\tau^2}} \\exp\\left( -\\frac{\\gamma \\mu^2}{1+2\\gamma\\tau^2} \\right)\n$$\nWe apply this result to each of the three dimensions and multiply them. Let $\\mu_k$ be the components of $d_{ij}$.\n$$\n\\mathbb{E}\\left[ \\exp(-\\gamma \\lVert d_{ij}' \\rVert^2) \\right] = \\prod_{k=1}^3 \\left[ \\frac{1}{\\sqrt{1+2\\gamma\\tau^2}} \\exp\\left( -\\frac{\\gamma \\mu_k^2}{1+2\\gamma\\tau^2} \\right) \\right]\n= \\frac{1}{(1+2\\gamma\\tau^2)^{3/2}} \\exp\\left( -\\frac{\\gamma \\sum_{k=1}^3 \\mu_k^2}{1+2\\gamma\\tau^2} \\right)\n$$\nSubstituting $\\sum \\mu_k^2 = \\lVert d_{ij} \\rVert^2 = \\lVert x_i - x_j \\rVert^2$ and $\\tau^2 = 2\\sigma^2$, we obtain the expectation for a single pairwise term:\n$$\n\\mathbb{E}\\left[ \\exp(-\\gamma \\lVert x_i' - x_j' \\rVert^2) \\right] = \\frac{1}{(1+4\\gamma\\sigma^2)^{3/2}} \\exp\\left( -\\frac{\\gamma \\lVert x_i - x_j \\rVert^2}{1+4\\gamma\\sigma^2} \\right)\n$$\nSumming over all pairs and dividing by $M$, we get the full expression for $\\mathbb{E}[F(X')]$:\n$$\n\\mathbb{E}[F(X')] = \\frac{1}{M} \\sum_{1 \\le i  j \\le N} \\frac{1}{(1+4\\gamma\\sigma^2)^{3/2}} \\exp\\left( -\\frac{\\gamma \\lVert x_i - x_j \\rVert^2}{1+4\\gamma\\sigma^2} \\right)\n$$\nThe sensitivity $S(\\sigma; X, \\gamma)$ is therefore:\n$$\nS(\\sigma; X, \\gamma) = \\left| \\frac{1}{M} \\sum_{1 \\le i  j \\le N} \\left[ \\frac{\\exp\\left( -\\frac{\\gamma \\lVert x_i - x_j \\rVert^2}{1+4\\gamma\\sigma^2} \\right)}{(1+4\\gamma\\sigma^2)^{3/2}} - \\exp(-\\gamma \\lVert x_i - x_j \\rVert^2) \\right] \\right|\n$$\nIf $\\sigma = 0$, the denominator $1+4\\gamma\\sigma^2$ becomes $1$ and the prefactor $(1+4\\gamma\\sigma^2)^{-3/2}$ is also $1$. The expression inside the summation becomes zero for each term, correctly yielding $S(0; X, \\gamma) = 0$. This applies to Case 1.\n\nThe provided Python code implements this final formula to compute the sensitivity for each test case by iterating over all unique residue pairs, calculating the contribution of each pair to the total sensitivity, and averaging appropriately.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the sensitivity of a simplified protein score to Gaussian noise\n    for a suite of test cases.\n    \"\"\"\n\n    def compute_sensitivity(coords, gamma, sigma):\n        \"\"\"\n        Calculates S(sigma; X, gamma) for a given set of coordinates, gamma, and sigma.\n        \n        Args:\n            coords (list of tuples): A list of 3D coordinates for N residues.\n            gamma (float): The decay parameter in Angstrom^-2.\n            sigma (float): The standard deviation of the Gaussian noise in Angstroms.\n            \n        Returns:\n            float: The computed sensitivity, a dimensionless quantity.\n        \"\"\"\n        X = np.array(coords, dtype=np.float64)\n        N = X.shape[0]\n\n        # By definition, if N  2, the score F(X) is 0. The perturbed score F(X')\n        # is also 0. Thus, the sensitivity is 0.\n        if N  2:\n            return 0.0\n\n        # If sigma is 0, there is no perturbation, so E[F(X')] = F(X),\n        # and the sensitivity is 0. This also handles the trivial case numerically.\n        if sigma == 0.0:\n            return 0.0\n        \n        M = N * (N - 1) / 2.0\n        \n        sum_of_differences = 0.0\n        \n        # Pre-compute constants derived from the analytical solution\n        # for the expectation E[F(X')].\n        four_gamma_sigma_sq = 4.0 * gamma * sigma**2\n        scaling_factor = 1.0 + four_gamma_sigma_sq\n        prefactor = scaling_factor**(-1.5)\n        \n        # Iterate over all unique pairs of residues (i, j) with i  j\n        for i in range(N):\n            for j in range(i + 1, N):\n                # Calculate the squared Euclidean distance between residues i and j\n                d_sq = np.sum((X[i] - X[j])**2)\n                \n                # The term contributed by pair (i,j) to the original score F(X)\n                term_fx = np.exp(-gamma * d_sq)\n                \n                # The expected value of the term for the perturbed score E[F(X')]\n                term_efx_prime = prefactor * np.exp(-gamma * d_sq / scaling_factor)\n                \n                # Accumulate the difference between the expected and original terms\n                sum_of_differences += (term_efx_prime - term_fx)\n\n        # The total sensitivity is the absolute value of the average difference\n        sensitivity = abs(sum_of_differences / M)\n        return sensitivity\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: N=3, gamma=0.5, sigma=0.0\n        {\"coords\": [(0.0, 0.0, 0.0), (3.8, 0.0, 0.0), (7.6, 0.0, 0.0)], \"gamma\": 0.5, \"sigma\": 0.0},\n        # Case 2: N=3, gamma=0.5, sigma=0.5\n        {\"coords\": [(0.0, 0.0, 0.0), (3.8, 0.0, 0.0), (7.6, 0.0, 0.0)], \"gamma\": 0.5, \"sigma\": 0.5},\n        # Case 3: N=4, gamma=0.3, sigma=1.0\n        {\"coords\": [(0.0, 0.0, 0.0), (0.0, 3.8, 0.0), (3.8, 0.0, 0.0), (3.8, 3.8, 0.0)], \"gamma\": 0.3, \"sigma\": 1.0},\n        # Case 4: N=2, gamma=1.0, sigma=2.0\n        {\"coords\": [(0.0, 0.0, 0.0), (3.8, 0.0, 0.0)], \"gamma\": 1.0, \"sigma\": 2.0},\n        # Case 5: N=1, gamma=0.5, sigma=1.0\n        {\"coords\": [(0.0, 0.0, 0.0)], \"gamma\": 0.5, \"sigma\": 1.0},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_sensitivity(case[\"coords\"], case[\"gamma\"], case[\"sigma\"])\n        # Format the result to exactly six decimal places as a string\n        results.append(f\"{result:.6f}\")\n\n    # Print the final output as a single comma-separated list in brackets\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The ultimate output of a structure prediction model is a set of 3D coordinates, and its accuracy is typically measured by comparing it to an experimental structure. The gold-standard metric for this comparison is the Root-Mean-Square Deviation (RMSD), which requires optimally superimposing the two structures. This final practice guides you through the implementation of the famous Kabsch algorithm to calculate RMSD, applying it to the fascinating biological edge case of metamorphic proteins, which naturally adopt more than one stable fold . Mastering this practice will equip you with one of the most essential skills in computational structural biology.",
            "id": "2387752",
            "problem": "You are given a formal evaluation task for an end-to-end protein structure prediction model on metamorphic proteins. A metamorphic protein can adopt two distinct stable folds. For a given predicted three-dimensional coordinate set $\\mathbf{P} \\in \\mathbb{R}^{N \\times 3}$ (one row per residue, interpreted as the alpha carbon coordinates) and two native folds $\\mathbf{A} \\in \\mathbb{R}^{N \\times 3}$ and $\\mathbf{B} \\in \\mathbb{R}^{N \\times 3}$ of the same sequence, define the root-mean-square deviation (RMSD) between $\\mathbf{P}$ and a native $\\mathbf{X} \\in \\{\\mathbf{A}, \\mathbf{B}\\}$ as the minimum over all proper rigid-body transformations of $\\mathbf{P}$:\n$$\n\\operatorname{RMSD}^{\\star}(\\mathbf{P}, \\mathbf{X}) \\triangleq \\min_{\\mathbf{R},\\,\\mathbf{t}} \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} \\left\\| \\mathbf{R}\\,\\mathbf{p}_i + \\mathbf{t} - \\mathbf{x}_i \\right\\|_2^2}\n$$\nsubject to $\\mathbf{R} \\in \\mathrm{SO}(3)$ (the special orthogonal group of rotations in three dimensions, i.e., $\\mathbf{R}^{\\top}\\mathbf{R} = \\mathbf{I}$ and $\\det(\\mathbf{R}) = 1$) and $\\mathbf{t} \\in \\mathbb{R}^3$. Here, $\\mathbf{p}_i$ and $\\mathbf{x}_i$ denote the $i$-th row of $\\mathbf{P}$ and $\\mathbf{X}$, respectively. Define the metamorphic evaluation score as\n$$\ns(\\mathbf{P}; \\mathbf{A}, \\mathbf{B}) \\triangleq \\min\\left( \\operatorname{RMSD}^{\\star}(\\mathbf{P}, \\mathbf{A}), \\operatorname{RMSD}^{\\star}(\\mathbf{P}, \\mathbf{B}) \\right).\n$$\nLet the acceptance threshold be $\\tau = 1.0$ Angstrom (Å). A prediction is considered correct for a metamorphic protein if $s(\\mathbf{P}; \\mathbf{A}, \\mathbf{B}) \\le \\tau$. All RMSD values must be expressed in Å, rounded to three decimals in the final output.\n\nTest suite. For each test case $k \\in \\{1,2,3\\}$, you are given a sequence length $N_k$ and two native folds $\\mathbf{A}^{(k)}$ and $\\mathbf{B}^{(k)}$. You must evaluate a specified predicted structure $\\mathbf{P}^{(k)}$ against both $\\mathbf{A}^{(k)}$ and $\\mathbf{B}^{(k)}$ as defined above. Angles appearing below are specified in radians.\n\n- Test case $1$ (happy path; prediction matches the first fold up to a rigid-body transform):\n  - $N_1 = 5$.\n  - $\\mathbf{A}^{(1)}$ has rows\n    $$\n    (0,0,0),\\ (3.8,0,0),\\ (7.6,0,0),\\ (11.4,0,0),\\ (15.2,0,0).\n    $$\n  - Define $\\delta \\triangleq \\frac{3.8}{\\sqrt{2}}$. $\\mathbf{B}^{(1)}$ has rows\n    $$\n    (0,0,0),\\ (\\delta,\\delta,0),\\ (2\\delta,0,0),\\ (3\\delta,\\delta,0),\\ (4\\delta,0,0).\n    $$\n  - Let $\\theta = \\pi/6$ and $\\mathbf{t}^{(1)} = (1.1,-2.3,0.5)$. Let $\\mathbf{R}_z(\\theta)$ denote the rotation about the $z$-axis by $\\theta$, with matrix\n    $$\n    \\mathbf{R}_z(\\theta) = \\begin{bmatrix}\n    \\cos\\theta  -\\sin\\theta  0\\\\\n    \\sin\\theta  \\cos\\theta  0\\\\\n    0  0  1\n    \\end{bmatrix}.\n    $$\n    The prediction is\n    $$\n    \\mathbf{P}^{(1)} = \\mathbf{A}^{(1)} \\mathbf{R}_z(\\theta)^{\\top} + \\mathbf{1}\\, (\\mathbf{t}^{(1)})^{\\top},\n    $$\n    where $\\mathbf{1} \\in \\mathbb{R}^{N_1 \\times 1}$ is the all-ones column vector, and addition is row-wise.\n\n- Test case $2$ (prediction matches the second fold up to a rigid-body transform):\n  - $N_2 = 6$.\n  - $\\mathbf{A}^{(2)}$ has rows\n    $$\n    (0,0,0),\\ (0,3.8,0),\\ (0,7.6,0),\\ (0,11.4,0),\\ (0,15.2,0),\\ (0,19.0,0).\n    $$\n  - $\\mathbf{B}^{(2)}$ has rows\n    $$\n    (0,0,0),\\ (3.8,0,0),\\ (7.6,0,0),\\ (7.6,3.8,0),\\ (7.6,7.6,0),\\ (7.6,11.4,0).\n    $$\n  - Let $\\phi = -\\pi/3$ and $\\mathbf{t}^{(2)} = (0.2,-0.5,1.0)$. The prediction is\n    $$\n    \\mathbf{P}^{(2)} = \\mathbf{B}^{(2)} \\mathbf{R}_z(\\phi)^{\\top} + \\mathbf{1}\\, (\\mathbf{t}^{(2)})^{\\top}.\n    $$\n\n- Test case $3$ (edge case; a mirror-image prediction that cannot be matched by a proper rotation):\n  - $N_3 = 5$.\n  - Construct $\\mathbf{A}^{(3)}$ by cumulative sums of the following step vectors of length $3.8$:\n    $$\n    \\mathbf{s}_1 = \\left(3.8\\cos\\left(\\frac{\\pi}{3}\\right),\\ 3.8\\sin\\left(\\frac{\\pi}{3}\\right),\\ 0\\right),\n    $$\n    $$\n    \\mathbf{s}_2 = \\left(\\sqrt{3.8^2-1.0^2}\\cos\\left(-\\frac{\\pi}{3}\\right),\\ \\sqrt{3.8^2-1.0^2}\\sin\\left(-\\frac{\\pi}{3}\\right),\\ 1.0\\right),\n    $$\n    $$\n    \\mathbf{s}_3 = \\left(\\sqrt{3.8^2-0.7^2}\\cos\\left(\\frac{\\pi}{9}\\right),\\ \\sqrt{3.8^2-0.7^2}\\sin\\left(\\frac{\\pi}{9}\\right),\\ -0.7\\right),\n    $$\n    $$\n    \\mathbf{s}_4 = \\left(\\sqrt{3.8^2-0.9^2}\\cos\\left(-\\frac{13\\pi}{18}\\right),\\ \\sqrt{3.8^2-0.9^2}\\sin\\left(-\\frac{13\\pi}{18}\\right),\\ 0.9\\right).\n    $$\n    Let the first row be $(0,0,0)$ and each subsequent row be the sum of $(0,0,0)$ with the first $j$ step vectors for $j \\in \\{1,2,3,4\\}$. Thus $\\mathbf{A}^{(3)}$ has $5$ rows.\n  - Let $\\mathbf{B}^{(3)}$ be the same as $\\mathbf{B}^{(1)}$ from test case $1$ (reuse $\\delta$).\n  - Define the reflection matrix\n    $$\n    \\mathbf{F} = \\mathrm{diag}(-1,\\,1,\\,1),\n    $$\n    which mirrors $x \\mapsto -x$ across the $yz$-plane. The prediction is\n    $$\n    \\mathbf{P}^{(3)} = \\mathbf{A}^{(3)} \\mathbf{F}^{\\top}.\n    $$\n\nFor each test case $k$, compute\n- $r_A^{(k)} = \\operatorname{RMSD}^{\\star}(\\mathbf{P}^{(k)}, \\mathbf{A}^{(k)})$,\n- $r_B^{(k)} = \\operatorname{RMSD}^{\\star}(\\mathbf{P}^{(k)}, \\mathbf{B}^{(k)})$,\n- $r^{(k)} = \\min(r_A^{(k)}, r_B^{(k)})$,\n- $m^{(k)} = 1$ if $r_A^{(k)} \\le r_B^{(k)}$, else $m^{(k)} = 2$,\n- $c^{(k)} = \\text{True}$ if $r^{(k)} \\le \\tau$, else $c^{(k)} = \\text{False}$.\n\nRequired final output format. Your program should produce a single line of output containing the results for the three test cases as a comma-separated list of triples, with no spaces, enclosed in square brackets. Each triple must be of the form $[r^{(k)},m^{(k)},c^{(k)}]$, where $r^{(k)}$ is the minimal RMSD in Å rounded to three decimals, $m^{(k)}$ is the integer fold index $1$ or $2$, and $c^{(k)}$ is a boolean. For example, the output must look like\n$$\n\\big[ [\\cdot,\\cdot,\\cdot], [\\cdot,\\cdot,\\cdot], [\\cdot,\\cdot,\\cdot] \\big]\n$$\nbut with the actual computed values, no extra spaces, and numeric values formatted as specified.",
            "solution": "The problem statement has been validated and is determined to be a well-posed, scientifically grounded task in computational structural biology. It provides all necessary definitions and data for a unique and verifiable solution. The problem requires the implementation of a standard algorithm for calculating the Root-Mean-Square Deviation (RMSD) between two sets of $3$D coordinates, and its application to evaluate a protein structure prediction against two possible native folds of a metamorphic protein.\n\nThe core of the problem is the computation of $\\operatorname{RMSD}^{\\star}(\\mathbf{P}, \\mathbf{X})$, defined as the minimum RMSD over all possible rigid-body transformations of the predicted structure $\\mathbf{P}$. A rigid-body transformation consists of a rotation $\\mathbf{R}$ and a translation $\\mathbf{t}$. The minimization problem is given by:\n$$\n\\operatorname{RMSD}^{\\star}(\\mathbf{P}, \\mathbf{X}) = \\min_{\\mathbf{R} \\in \\mathrm{SO}(3), \\mathbf{t} \\in \\mathbb{R}^3} \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} \\left\\| (\\mathbf{R}\\,\\mathbf{p}_i + \\mathbf{t}) - \\mathbf{x}_i \\right\\|_2^2}\n$$\nThis is a classic problem in structural alignment, and its solution is found using the Kabsch algorithm, or a numerically equivalent method based on Singular Value Decomposition (SVD). The procedure involves the following steps:\n\n1.  **Centering the Coordinates**: The optimal translation $\\mathbf{t}$ can be shown to superimpose the centroid of the rotated set $\\mathbf{R}\\mathbf{P}$ onto the centroid of the reference set $\\mathbf{X}$. The first step is therefore to translate both coordinate sets so that their centroids are at the origin. Let $\\mathbf{P}$ and $\\mathbf{X}$ be the $N \\times 3$ matrices of coordinates. The centroids are calculated as:\n    $$\n    \\bar{\\mathbf{p}} = \\frac{1}{N}\\sum_{i=1}^{N} \\mathbf{p}_i, \\quad \\bar{\\mathbf{x}} = \\frac{1}{N}\\sum_{i=1}^{N} \\mathbf{x}_i\n    $$\n    The centered coordinate matrices, $\\mathbf{P}'$ and $\\mathbf{X}'$, are then obtained by subtracting the respective centroids from each point:\n    $$\n    \\mathbf{p}'_i = \\mathbf{p}_i - \\bar{\\mathbf{p}}, \\quad \\mathbf{x}'_i = \\mathbf{x}_i - \\bar{\\mathbf{x}}\n    $$\n    After centering, the problem reduces to finding the optimal rotation $\\mathbf{R}$ that minimizes the distance between the transformed points of $\\mathbf{P}'$ and the points of $\\mathbf{X}'$.\n\n2.  **Covariance Matrix**: The optimal rotation is found by considering the covariance matrix of the centered coordinates. For point sets represented as $N \\times 3$ matrices (where each row is a point), the $3 \\times 3$ covariance matrix $\\mathbf{H}$ is computed as:\n    $$\n    \\mathbf{H} = (\\mathbf{P}')^{\\top} \\mathbf{X}'\n    $$\n\n3.  **Singular Value Decomposition (SVD)**: We perform an SVD on the covariance matrix $\\mathbf{H}$:\n    $$\n    \\mathbf{H} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^{\\top}\n    $$\n    Here, $\\mathbf{U}$ and $\\mathbf{V}$ are $3 \\times 3$ orthogonal matrices, and $\\mathbf{\\Sigma}$ is a $3 \\times 3$ diagonal matrix of singular values.\n\n4.  **Optimal Rotation Matrix**: The optimal rotation matrix $\\mathbf{R}$ that maximizes the overlap (and thus minimizes the RMSD) is given by:\n    $$\n    \\mathbf{R} = \\mathbf{V} \\mathbf{U}^{\\top}\n    $$\n\n5.  **Reflection Handling**: The problem specifies that the rotation $\\mathbf{R}$ must be a proper rotation, i.e., it must belong to the special orthogonal group $\\mathrm{SO}(3)$, which requires that its determinant is $+1$. The matrix $\\mathbf{R}$ computed above may have a determinant of $-1$. This occurs if one coordinate set is a mirror image (enantiomer) of the other. To ensure a proper rotation, we check the determinant:\n    $$\n    d = \\det(\\mathbf{R}) = \\det(\\mathbf{V} \\mathbf{U}^{\\top})\n    $$\n    If $d = -1$, the optimal transformation is a reflection. To find the best *proper* rotation, we must correct $\\mathbf{R}$. The standard method is to invert the component of rotation corresponding to the smallest singular value. This is achieved by flipping the sign of the last column of $\\mathbf{V}$ before computing $\\mathbf{R}$:\n    $$\n    \\text{If } \\det(\\mathbf{V} \\mathbf{U}^{\\top}) = -1, \\text{ set } \\mathbf{R} = \\mathbf{V} \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  -1 \\end{pmatrix} \\mathbf{U}^{\\top}\n    $$\n    This correction guarantees that $\\det(\\mathbf{R}) = +1$ and gives the optimal solution within $\\mathrm{SO}(3)$. This check is critical for Test Case $3$, where the predicted structure is an explicit reflection of a native fold.\n\n6.  **RMSD Calculation**: With the optimal proper rotation $\\mathbf{R}$ found, the coordinates of $\\mathbf{P}'$ are rotated, and the RMSD is computed using the centered coordinates:\n    $$\n    \\operatorname{RMSD}^{\\star}(\\mathbf{P}, \\mathbf{X}) = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} \\left\\| \\mathbf{p}'_i \\mathbf{R} - \\mathbf{x}'_i \\right\\|_2^2}\n    $$\n    Note that for row vectors $\\mathbf{p}'_i$, the rotation is applied as $\\mathbf{p}'_i \\mathbf{R}$.\n\nFor each test case $k \\in \\{1,2,3\\}$, this procedure is applied twice: first to compute $r_A^{(k)} = \\operatorname{RMSD}^{\\star}(\\mathbf{P}^{(k)}, \\mathbf{A}^{(k)})$ and second to compute $r_B^{(k)} = \\operatorname{RMSD}^{\\star}(\\mathbf{P}^{(k)}, \\mathbf{B}^{(k)})$. The metamorphic score $r^{(k)}$, the matching fold index $m^{(k)}$, and the correctness flag $c^{(k)}$ are then determined based on these two RMSD values and the acceptance threshold $\\tau = 1.0$.\n\nFor Test Cases $1$ and $2$, the predicted structure $\\mathbf{P}^{(k)}$ is constructed by applying a proper rigid-body transformation to one of the native folds ($\\mathbf{A}^{(1)}$ and $\\mathbf{B}^{(2)}$, respectively). Therefore, the calculated RMSD against that specific fold is expected to be numerically zero, and the metamorphic score $r^{(k)}$ will be $0.000$.\n\nFor Test Case $3$, $\\mathbf{P}^{(3)}$ is a reflection of $\\mathbf{A}^{(3)}$. The RMSD calculation for $\\operatorname{RMSD}^{\\star}(\\mathbf{P}^{(3)}, \\mathbf{A}^{(3)})$ will trigger the reflection-handling step, resulting in a non-zero RMSD, as a proper rotation cannot perfectly superimpose a structure onto its mirror image. The final score will depend on which of the two non-zero RMSD values, $r_A^{(3)}$ or $r_B^{(3)}$, is smaller.",
            "answer": "```python\nimport numpy as np\n\ndef calculate_rmsd(P, X):\n    \"\"\"\n    Calculates the Root-Mean-Square Deviation (RMSD) between two sets of\n    3D coordinates P and X, minimized over rigid-body transformations.\n\n    This function implements the Kabsch algorithm.\n\n    Args:\n        P (np.ndarray): An N x 3 matrix of coordinates to be aligned.\n        X (np.ndarray): An N x 3 matrix of reference coordinates.\n\n    Returns:\n        float: The RMSD value in the same units as the input coordinates.\n    \"\"\"\n    # Number of points\n    N = P.shape[0]\n\n    # 1. Center the coordinate sets\n    centroid_P = np.mean(P, axis=0)\n    centroid_X = np.mean(X, axis=0)\n    P_centered = P - centroid_P\n    X_centered = X - centroid_X\n\n    # 2. Compute the covariance matrix H = P_centered.T @ X_centered\n    H = P_centered.T @ X_centered\n\n    # 3. Singular Value Decomposition\n    U, S, Vt = np.linalg.svd(H)\n\n    # 4. Compute the optimal rotation matrix R\n    R = Vt.T @ U.T\n\n    # 5. Handle reflection case (det(R) = -1)\n    if np.linalg.det(R)  0:\n        # Flip the sign of the column of V corresponding to the smallest singular value\n        Vt_corrected = Vt.copy()\n        Vt_corrected[2, :] *= -1\n        R = Vt_corrected.T @ U.T\n\n    # 6. Apply rotation to P_centered\n    # For row vectors, the transformation is P @ R\n    P_rotated = P_centered @ R\n\n    # 7. Calculate RMSD\n    diff = P_rotated - X_centered\n    rmsd = np.sqrt(np.sum(diff**2) / N)\n\n    return rmsd\n\ndef solve():\n    \"\"\"\n    Solves the problem by evaluating predicted structures against native folds\n    for three test cases.\n    \"\"\"\n    tau = 1.0\n    results = []\n\n    # --- Test Case 1 ---\n    N1 = 5\n    A1 = np.array([[3.8 * i, 0, 0] for i in range(N1)], dtype=float)\n\n    delta = 3.8 / np.sqrt(2)\n    B1 = np.array([\n        [0.0, 0.0, 0.0],\n        [delta, delta, 0.0],\n        [2 * delta, 0.0, 0.0],\n        [3 * delta, delta, 0.0],\n        [4 * delta, 0.0, 0.0]\n    ], dtype=float)\n    \n    theta = np.pi / 6\n    t1 = np.array([1.1, -2.3, 0.5])\n    Rz1_T = np.array([\n        [np.cos(theta), np.sin(theta), 0],\n        [-np.sin(theta), np.cos(theta), 0],\n        [0, 0, 1]\n    ])\n    P1 = A1 @ Rz1_T + t1\n\n    rA1 = calculate_rmsd(P1, A1)\n    rB1 = calculate_rmsd(P1, B1)\n    \n    if rA1 = rB1:\n        r1, m1 = rA1, 1\n    else:\n        r1, m1 = rB1, 2\n    c1 = r1 = tau\n    results.append(f\"[{r1:.3f},{m1},{'True' if c1 else 'False'}]\")\n\n    # --- Test Case 2 ---\n    N2 = 6\n    A2 = np.array([[0, 3.8 * i, 0] for i in range(N2)], dtype=float)\n    B2 = np.array([\n        [0.0, 0.0, 0.0],\n        [3.8, 0.0, 0.0],\n        [7.6, 0.0, 0.0],\n        [7.6, 3.8, 0.0],\n        [7.6, 7.6, 0.0],\n        [7.6, 11.4, 0.0]\n    ], dtype=float)\n    \n    phi = -np.pi / 3\n    t2 = np.array([0.2, -0.5, 1.0])\n    Rz2_T = np.array([\n        [np.cos(phi), np.sin(phi), 0],\n        [-np.sin(phi), np.cos(phi), 0],\n        [0, 0, 1]\n    ])\n    P2 = B2 @ Rz2_T + t2\n    \n    rA2 = calculate_rmsd(P2, A2)\n    rB2 = calculate_rmsd(P2, B2)\n\n    if rA2 = rB2:\n        r2, m2 = rA2, 1\n    else:\n        r2, m2 = rB2, 2\n    c2 = r2 = tau\n    results.append(f\"[{r2:.3f},{m2},{'True' if c2 else 'False'}]\")\n\n    # --- Test Case 3 ---\n    N3 = 5\n    s_vecs = []\n    # s1\n    s_vecs.append(np.array([3.8 * np.cos(np.pi/3), 3.8 * np.sin(np.pi/3), 0.0]))\n    # s2\n    len_s2 = np.sqrt(3.8**2 - 1.0**2)\n    s_vecs.append(np.array([len_s2 * np.cos(-np.pi/3), len_s2 * np.sin(-np.pi/3), 1.0]))\n    # s3\n    len_s3 = np.sqrt(3.8**2 - 0.7**2)\n    s_vecs.append(np.array([len_s3 * np.cos(np.pi/9), len_s3 * np.sin(np.pi/9), -0.7]))\n    # s4\n    len_s4 = np.sqrt(3.8**2 - 0.9**2)\n    s_vecs.append(np.array([len_s4 * np.cos(-13*np.pi/18), len_s4 * np.sin(-13*np.pi/18), 0.9]))\n    \n    A3_coords = [np.zeros(3)]\n    for i in range(len(s_vecs)):\n        A3_coords.append(np.sum(s_vecs[:i+1], axis=0))\n    A3 = np.array(A3_coords)\n    \n    B3 = B1  # Re-use B1\n    \n    F = np.diag([-1., 1., 1.])\n    P3 = A3 @ F\n    \n    rA3 = calculate_rmsd(P3, A3)\n    rB3 = calculate_rmsd(P3, B3)\n\n    if rA3 = rB3:\n        r3, m3 = rA3, 1\n    else:\n        r3, m3 = rB3, 2\n    c3 = r3 = tau\n    results.append(f\"[{r3:.3f},{m3},{'True' if c3 else 'False'}]\")\n    \n    # Final print statement\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}