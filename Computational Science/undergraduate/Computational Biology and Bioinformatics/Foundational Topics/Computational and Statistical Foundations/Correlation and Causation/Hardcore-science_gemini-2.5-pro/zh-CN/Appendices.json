{
    "hands_on_practices": [
        {
            "introduction": "在生物信息学分析中，直接汇总来自不同来源的数据是一种常见做法，但这其中暗藏风险。一个未被观察到的“混杂变量”可能会扭曲我们对事物之间关系的认知。本练习通过一个经典的统计学现象——辛普森悖论，直观地展示了这种风险。通过亲手计算一个假设性药物试验中的恢复率，您将体会到忽略一个关键变量（如疾病严重程度）会如何导致对因果关系的完全错误判断 。",
            "id": "2383010",
            "problem": "一位计算生物学家正在审核一个经过整理的临床数据集的结果，该数据集评估了一种新的抗菌药物。患者根据疾病严重程度被分为两个层次：轻度和重度。对于每个层次和治疗组（药物组对对照组），报告了康复患者数和总患者数如下：轻度层，药物组：$20$人中有$18$人康复；轻度层，对照组：$200$人中有$160$人康复；重度层，药物组：$800$人中有$240$人康复；重度层，对照组：$20$人中有$4$人康复。将任何组的康复率定义为该组中康复人数与总患者数的比率。将一个治疗组的合并康复率定义为两个层次的总康复人数与两个层次的总患者数的比率。将合并风险差定义为药物组的合并康复率减去对照组的合并康复率。当忽略分层标签并将各组内的所有患者合并时，计算合并风险差。以小数形式表示您的答案，并四舍五入到四位有效数字。",
            "solution": "所述问题是有效的。它具有科学依据，提法明确，并包含得出唯一解所需的所有信息。我们将着手进行分析。\n\n目标是计算药物组和对照组之间的合并风险差，这需要将指定层次的数据进行汇总。我们获得了轻度和重度两个层次在药物组和对照组的数据。\n\n让我们系统地定义变量。设 $R$ 表示康复患者数，$N$ 表示总患者数。我们使用下标来表示治疗组（D 代表药物组，C 代表对照组）和层次（m 代表轻度，s 代表重度）。\n\n给定的数据是：\n-   轻度层，药物组：$R_{D,m} = 18$, $N_{D,m} = 20$。\n-   轻度层，对照组：$R_{C,m} = 160$, $N_{C,m} = 200$。\n-   重度层，药物组：$R_{D,s} = 240$, $N_{D,s} = 800$。\n-   重度层，对照组：$R_{C,s} = 4$, $N_{C,s} = 20$。\n\n任何特定组内的康复率 $r$ 定义为康复人数与总患者数的比率，$r = \\frac{R}{N}$。尽管问题要求的是合并结果，但我们首先计算每个层次内的康复率作为初步分析。\n\n对于轻度层：\n-   药物组康复率：$r_{D,m} = \\frac{R_{D,m}}{N_{D,m}} = \\frac{18}{20} = 0.9$。\n-   对照组康复率：$r_{C,m} = \\frac{R_{C,m}}{N_{C,m}} = \\frac{160}{200} = 0.8$。\n轻度层的风险差为 $r_{D,m} - r_{C,m} = 0.9 - 0.8 = 0.1$。\n\n对于重度层：\n-   药物组康复率：$r_{D,s} = \\frac{R_{D,s}}{N_{D,s}} = \\frac{240}{800} = 0.3$。\n-   对照组康复率：$r_{C,s} = \\frac{R_{C,s}}{N_{C,s}} = \\frac{4}{20} = 0.2$。\n重度层的风险差为 $r_{D,s} - r_{C,s} = 0.3 - 0.2 = 0.1$。\n\n观察到在两个层次中，药物组的康复率都高出 $0.1$ 或 $10$ 个百分点。一个朴素的解释是该药物是有益的。\n\n现在，我们进行主要任务：计算合并风险差。这涉及到忽略分层标签，并对每个治疗组的数据进行汇总。\n\n首先，计算合并药物组的总康复人数和总患者数。\n-   药物组总康复人数：$R_D = R_{D,m} + R_{D,s} = 18 + 240 = 258$。\n-   药物组总患者数：$N_D = N_{D,m} + N_{D,s} = 20 + 800 = 820$。\n\n因此，药物组的合并康复率 $RR_D$ 为：\n$$RR_D = \\frac{R_D}{N_D} = \\frac{258}{820}$$\n\n接下来，计算合并对照组的总康复人数和总患者数。\n-   对照组总康复人数：$R_C = R_{C,m} + R_{C,s} = 160 + 4 = 164$。\n-   对照组总患者数：$N_C = N_{C,m} + N_{C,s} = 200 + 20 = 220$。\n\n对照组的合并康复率 $RR_C$ 为：\n$$RR_C = \\frac{R_C}{N_C} = \\frac{164}{220}$$\n\n合并风险差 $\\Delta_{RD}$ 定义为药物组的合并康复率与对照组的合并康复率之差。\n$$\\Delta_{RD} = RR_D - RR_C = \\frac{258}{820} - \\frac{164}{220}$$\n\n现在我们对这个表达式进行数值计算。\n$$RR_D = \\frac{258}{820} \\approx 0.3146341...$$\n$$RR_C = \\frac{164}{220} = \\frac{41}{55} \\approx 0.7454545...$$\n\n将这些值代入合并风险差的表达式中：\n$$\\Delta_{RD} \\approx 0.3146341 - 0.7454545 = -0.4308204...$$\n\n问题要求答案四舍五入到四位有效数字。第一位有效数字是 $4$。我们必须保留接下来的三位数字：$3$、 $0$ 和 $8$。第四位有效数字（$8$）之后的数字是 $2$。由于 $2  5$，我们不对最后一位进行向上舍入。\n因此，四舍五入到四位有效数字的合并风险差为 $-0.4308$。\n\n这个结果展示了一个典型的Simpson悖论案例。混淆变量是疾病的严重程度。当在每个层次内进行分析时，该药物似乎是有效的，但当数据合并时，结论却反转了，表明该药物是有害的。这是因为治疗分配严重偏斜：大多数服用药物的患者属于重度类别（无论治疗如何，其康复率都较低），而大多数在对照组中的患者属于轻度类别（无论治疗如何，其康复率都较高）。不加批判地合并数据会导致错误的结论。任何严谨的分析都必须考虑此类混淆因素。",
            "answer": "$$\n\\boxed{-0.4308}\n$$"
        },
        {
            "introduction": "认识到混杂效应的危害后，我们自然会问：如何从数学上严格区分相关性与因果性？本练习引入了贝叶斯网络作为一种强大的工具，来模拟变量间的概率性因果关系。您将学习并计算“观察”概率（$P(C=1 \\mid S=1)$）与“干预”概率（$P(C=1 \\mid do(S=1))$）之间的区别，从而精确量化由共同原因（例如，一个同时影响吸烟行为和癌症风险的基因）所引入的混杂偏倚 。",
            "id": "2382934",
            "problem": "给定一个离散贝叶斯网络，其中包含三个二元随机变量，用于模拟某人群中遗传和行为对疾病风险的影响：胆碱能受体烟碱α5亚基基因（CHRNA5）上单个核苷酸多态性的基因型、吸烟状况和肺癌结果。设 $G \\in \\{0,1\\}$ 表示 CHRNA5 风险等位基因的基因型指示符，其中 $G=1$ 表示存在至少一个风险等位基因。设 $S \\in \\{0,1\\}$ 表示吸烟状况，其中 $S=1$ 表示当前吸烟者。设 $C \\in \\{0,1\\}$ 表示肺癌，其中 $C=1$ 表示患有该疾病。有向无环图 (DAG) 的结构为 $G \\to S$、$S \\to C$，以及可选的 $G \\to C$。联合分布可分解为 $P(G,S,C) = P(G) P(S \\mid G) P(C \\mid S,G)$。\n\n每个测试用例的参数由以下概率给出：\n- $P(G=1) = p_g$，\n- $P(S=1 \\mid G=0) = s_0$，$P(S=1 \\mid G=1) = s_1$，\n- $P(C=1 \\mid S=s, G=g) = c_{sg}$，其中 $(s,g) \\in \\{0,1\\} \\times \\{0,1\\}$。\n\n干预使用 do 算子定义。在干预 $do(S=1)$ 下，变量 $S$ 被外生地设置为 $1$，这会移除所有指向 $S$ 的箭头，并将 $S$ 的条件分布替换为在 $1$ 处的点质量，同时保持所有其他条件分布不变。\n\n对于下面的每个测试用例，计算以下标量值：\n- 差值 $\\Delta = P(C=1 \\mid S=1) - P(C=1 \\mid do(S=1))$。\n\n您的程序必须根据上述定义和概率定律，从第一性原理出发为每个测试用例计算 $\\Delta$，不得使用任何外部数据。将每个 $\\Delta$ 表示为四舍五入到六位小数的十进制数（不要使用百分号）。\n\n测试套件（每个用例由 $(p_g, s_0, s_1, c_{00}, c_{10}, c_{01}, c_{11})$ 指定）：\n1. 案例 A（存在对吸烟的遗传效应和对肺癌的直接遗传效应，吸烟导致肺癌）：$(p_g, s_0, s_1, c_{00}, c_{10}, c_{01}, c_{11}) = (0.3, 0.2, 0.6, 0.01, 0.05, 0.02, 0.12)$。\n2. 案例 B（存在对吸烟的遗传效应，但不存在对肺癌的直接遗传效应，吸烟导致肺癌）：$(p_g, s_0, s_1, c_{00}, c_{10}, c_{01}, c_{11}) = (0.3, 0.2, 0.6, 0.01, 0.05, 0.01, 0.05)$。\n3. 案例 C（存在对吸烟的遗传效应和对肺癌的直接遗传效应，但吸烟对肺癌没有因果效应）：$(p_g, s_0, s_1, c_{00}, c_{10}, c_{01}, c_{11}) = (0.3, 0.2, 0.6, 0.01, 0.01, 0.05, 0.05)$。\n4. 案例 D（不存在对吸烟的遗传效应，但存在对肺癌的遗传和吸烟效应）：$(p_g, s_0, s_1, c_{00}, c_{10}, c_{01}, c_{11}) = (0.3, 0.4, 0.4, 0.01, 0.05, 0.02, 0.12)$。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果按上述测试用例的顺序列出，例如 $[\\Delta_A,\\Delta_B,\\Delta_C,\\Delta_D]$。",
            "solution": "该问题要求计算给定贝叶斯网络中的量 $\\Delta = P(C=1 \\mid S=1) - P(C=1 \\mid do(S=1))$。这个量代表了在给定吸烟条件下的肺癌观测条件概率与强制吸烟干预下的肺癌因果概率之间的差异。这个差异正是由基因 $G$ 引入的混杂偏倚，该基因是吸烟 $S$ 和肺癌 $C$ 的一个潜在共同原因。\n\n分析分三步进行：首先，推导观测项 $P(C=1 \\mid S=1)$ 的表达式；其次，推导干预项 $P(C=1 \\mid do(S=1))$ 的表达式；第三，将它们结合起来求出 $\\Delta$ 并应用于给定的测试用例。\n\n联合概率分布由分解式 $P(G,S,C) = P(G) P(S \\mid G) P(C \\mid S,G)$ 给出。参数定义为 $P(G=1) = p_g$、$P(S=1 \\mid G=0) = s_0$、$P(S=1 \\mid G=1) = s_1$ 和 $P(C=1 \\mid S=s, G=g) = c_{sg}$。\n\n1.  观测项 $P(C=1 \\mid S=1)$ 的推导：\n    根据条件概率的定义，\n    $$ P(C=1 \\mid S=1) = \\frac{P(C=1, S=1)}{P(S=1)} $$\n    分母 $P(S=1)$ 通过使用全概率定律对变量 $G$ 进行边缘化得到：\n    $$ P(S=1) = \\sum_{g \\in \\{0,1\\}} P(S=1, G=g) = \\sum_{g \\in \\{0,1\\}} P(S=1 \\mid G=g) P(G=g) $$\n    $$ P(S=1) = P(S=1 \\mid G=0)P(G=0) + P(S=1 \\mid G=1)P(G=1) $$\n    代入给定参数，其中 $P(G=0) = 1 - p_g$：\n    $$ P(S=1) = s_0 (1 - p_g) + s_1 p_g $$\n    分子 $P(C=1, S=1)$ 也通过对 $G$ 进行边缘化得到：\n    $$ P(C=1, S=1) = \\sum_{g \\in \\{0,1\\}} P(C=1, S=1, G=g) $$\n    根据网络结构使用链式法则：\n    $$ P(C=1, S=1) = P(C=1 \\mid S=1, G=0)P(S=1 \\mid G=0)P(G=0) + P(C=1 \\mid S=1, G=1)P(S=1 \\mid G=1)P(G=1) $$\n    代入给定参数：\n    $$ P(C=1, S=1) = c_{10} s_0 (1 - p_g) + c_{11} s_1 p_g $$\n    结合分子和分母，得到观测概率：\n    $$ P(C=1 \\mid S=1) = \\frac{c_{10} s_0 (1 - p_g) + c_{11} s_1 p_g}{s_0 (1 - p_g) + s_1 p_g} $$\n\n2.  干预项 $P(C=1 \\mid do(S=1))$ 的推导：\n    干预 $do(S=1)$ 修改系统，将整个群体的 $S$ 值设置为 $1$。这对应于在图中移除所有指向节点 $S$ 的边（在本例中为边 $G \\to S$）并将 $S$ 设置为 $1$。在这个修改后的图中，剩余变量 $G$ 和 $C$ 的联合分布，记作 $P_{do(S=1)}$，变为 $P_{do(S=1)}(G, C) = P(G) P(C \\mid S=1, G)$。\n    所求概率是这个新分布中 $C=1$ 的边缘概率：\n    $$ P(C=1 \\mid do(S=1)) = \\sum_{g \\in \\{0,1\\}} P_{do(S=1)}(C=1, G=g) $$\n    $$ P(C=1 \\mid do(S=1)) = \\sum_{g \\in \\{0,1\\}} P(C=1 \\mid S=1, G=g)P(G=g) $$\n    这就是 $S$ 对 $C$ 因果效应的后门调整公式，其中 $G$ 是混杂变量。\n    代入参数：\n    $$ P(C=1 \\mid do(S=1)) = P(C=1 \\mid S=1, G=0)P(G=0) + P(C=1 \\mid S=1, G=1)P(G=1) $$\n    $$ P(C=1 \\mid do(S=1)) = c_{10}(1 - p_g) + c_{11} p_g $$\n\n3.  $\\Delta$ 的计算：\n    $\\Delta$ 的最终表达式是两个推导项之差：\n    $$ \\Delta = \\frac{c_{10} s_0 (1 - p_g) + c_{11} s_1 p_g}{s_0 (1 - p_g) + s_1 p_g} - \\left( c_{10}(1 - p_g) + c_{11} p_g \\right) $$\n    这个表达式可以通过代数运算来简化。设分母为 $D = s_0 (1 - p_g) + s_1 p_g$。将两项通分并化简分子后，我们得到一个更具洞察力的形式：\n    $$ \\Delta = \\frac{p_g(1-p_g)(s_1 - s_0)(c_{11} - c_{10})}{s_0 (1 - p_g) + s_1 p_g} $$\n    这个简化公式表明，混杂偏倚 $\\Delta$ 非零当且仅当：\n    a) 该基因具有多态性（$0  p_g  1$）。\n    b) 该基因影响吸烟行为（$s_1 \\neq s_0$），从而产生了路径 $G \\to S$。\n    c) 对于吸烟者，该基因对不同等位基因的肺癌风险影响不同（$c_{11} \\neq c_{10}$），这表明存在一条 $G \\to C$ 路径或交互作用。这意味着 $G$ 是 $S$ 和 $C$ 的共同原因。\n\n将此公式应用于每个测试用例：\n\n案例 A: $(p_g, s_0, s_1, c_{10}, c_{11}) = (0.3, 0.2, 0.6, 0.05, 0.12)$\n$$ \\Delta_A = \\frac{0.3 \\times (1-0.3) \\times (0.6 - 0.2) \\times (0.12 - 0.05)}{(1-0.3) \\times 0.2 + 0.3 \\times 0.6} = \\frac{0.3 \\times 0.7 \\times 0.4 \\times 0.07}{0.7 \\times 0.2 + 0.3 \\times 0.6} = \\frac{0.00588}{0.32} = 0.018375 $$\n\n案例 B: $(p_g, s_0, s_1, c_{10}, c_{11}) = (0.3, 0.2, 0.6, 0.05, 0.05)$\n这里，$c_{11} - c_{10} = 0.05 - 0.05 = 0$。分子变为 $0$。\n$$ \\Delta_B = 0 $$\n这是预料之中的。对于 $s=0$ 和 $s=1$ 两种情况，$c_{s0}=c_{s1}$ 的条件意味着没有直接的因果路径 $G \\to C$。因此，$G$ 不是 $S \\to C$ 关系中的混杂因素。\n\n案例 C: $(p_g, s_0, s_1, c_{10}, c_{11}) = (0.3, 0.2, 0.6, 0.01, 0.05)$\n$$ \\Delta_C = \\frac{0.3 \\times (1-0.3) \\times (0.6 - 0.2) \\times (0.05 - 0.01)}{(1-0.3) \\times 0.2 + 0.3 \\times 0.6} = \\frac{0.3 \\times 0.7 \\times 0.4 \\times 0.04}{0.32} = \\frac{0.00336}{0.32} = 0.0105 $$\n在这种情况下，由于 $G$ 的混杂作用，吸烟与癌症之间存在关联，即使吸烟本身对癌症没有因果效应（因为 $c_{0g}=c_{1g}$）。\n\n案例 D: $(p_g, s_0, s_1, c_{10}, c_{11}) = (0.3, 0.4, 0.4, 0.05, 0.12)$\n这里，$s_1 - s_0 = 0.4 - 0.4 = 0$。分子变为 $0$。\n$$ \\Delta_D = 0 $$\n这也是预料之中的。条件 $s_0 = s_1$ 表示基因 $G$ 对吸烟行为没有影响，从而切断了 $G \\to S$ 路径。没有这条路径，$G$ 就不能成为共同原因，因此也不能成为混杂因素。\n\n结果四舍五入到六位小数后为：$\\Delta_A=0.018375$，$\\Delta_B=0.000000$，$\\Delta_C=0.010500$ 和 $\\Delta_D=0.000000$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of calculating the difference between associational and\n    causal probabilities in a given Bayesian network.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (p_g, s_0, s_1, c_00, c_10, c_01, c_11)\n    test_cases = [\n        (0.3, 0.2, 0.6, 0.01, 0.05, 0.02, 0.12),  # Case A\n        (0.3, 0.2, 0.6, 0.01, 0.05, 0.01, 0.05),  # Case B\n        (0.3, 0.2, 0.6, 0.01, 0.01, 0.05, 0.05),  # Case C\n        (0.3, 0.4, 0.4, 0.01, 0.05, 0.02, 0.12),  # Case D\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Unpack parameters for the current test case.\n        # Notation from problem statement:\n        # pg: P(G=1)\n        # s0: P(S=1 | G=0)\n        # s1: P(S=1 | G=1)\n        # c10: P(C=1 | S=1, G=0)\n        # c11: P(C=1 | S=1, G=1)\n        # c00 and c01 are not needed for this specific calculation.\n        pg, s0, s1, c00, c10, c01, c11 = case\n\n        # The quantity to compute is Delta = P(C=1|S=1) - P(C=1|do(S=1)).\n        # This difference represents the confounding bias.\n        # A simplified formula derived from first principles is used:\n        # Delta = (pg * (1-pg) * (s1-s0) * (c11-c10)) / P(S=1)\n        # where P(S=1) = (1-pg)*s0 + pg*s1.\n        \n        # Calculate the denominator, P(S=1).\n        prob_s1 = (1.0 - pg) * s0 + pg * s1\n\n        # The problem statement implies P(S=1) will not be zero for any test case,\n        # which would make the observational probability P(C=1|S=1) undefined.\n        # For the given cases, P(S=1) is always positive.\n        if prob_s1 == 0.0:\n            # If P(S=1) is 0, the subpopulation of smokers is empty.\n            # The confounding bias is taken to be 0 in this edge case.\n            delta = 0.0\n        else:\n            # Calculate the numerator of the simplified formula.\n            # This represents the covariance between the genetic effect on smoking\n            # and the genetic effect on cancer risk among a population of smokers.\n            numerator = pg * (1.0 - pg) * (s1 - s0) * (c11 - c10)\n            \n            # Calculate Delta, the confounding bias.\n            delta = numerator / prob_s1\n        \n        # Format the result to six decimal places as required.\n        results.append(f\"{delta:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们已经了解了混杂问题及其形式化描述，但在许多生物信息学研究中，进行主动干预（即执行 $do(X)$ 操作）是不现实的。那么，我们如何才能从观测数据中推断因果关系呢？本练习介绍了一种强大的统计策略——孟德尔随机化（Mendelian Randomization），它利用基因变异作为“自然实验”中的工具变量。通过模拟和编码，您将亲身体验标准回归方法（OLS）如何因混杂因素而产生偏倚，以及工具变量法（IV）如何在满足特定假设时成功地估计出真实的因果效应 。",
            "id": "2382981",
            "problem": "给定一个数学上指定的线性结构因果模型，该模型用于一个简化的转录调控场景，其灵感来自孟德尔随机化（MR；Mendelian Randomization）。这些变量是：一个遗传工具变量 $Z$（处于哈代-温伯格平衡中的单个核苷酸多态性的等位基因剂量），一个转录因子表达量 $X$，一个靶基因表达量 $Y$，以及一个同时影响 $X$ 和 $Y$ 的未观测混杂因素 $U$。对于个体 $i \\in \\{1,\\dots,n\\}$，数据生成过程如下：\n$$\nZ_i \\sim \\text{Binomial}(2,p), \\quad U_i \\sim \\mathcal{N}(0,1), \\quad \\varepsilon^X_i \\sim \\mathcal{N}(0,\\sigma_X^2), \\quad \\varepsilon^Y_i \\sim \\mathcal{N}(0,\\sigma_Y^2),\n$$\n在个体 $i$ 之间相互独立，并且\n$$\nX_i \\;=\\; \\alpha Z_i \\;+\\; \\delta U_i \\;+\\; \\varepsilon^X_i, \\qquad\nY_i \\;=\\; \\beta X_i \\;+\\; \\kappa U_i \\;+\\; \\gamma Z_i \\;+\\; \\varepsilon^Y_i.\n$$\n所有截距均为零。我们感兴趣的因果假设是 $X$ 对 $Y$ 具有因果效应，该效应由结构参数 $\\beta$ 编码。参数 $\\gamma$ 编码了 $Z$ 对 $Y$ 可能存在的、不由 $X$ 介导的直接效应（违反了工具变量的排他性限制）。参数 $\\delta$ 和 $\\kappa$ 编码了未观测到的混杂。\n\n你的任务是，对于下面测试套件中的每一组参数，从该模型生成一个大小为 $n$ 的样本，并从该样本中计算以下量值：\n- 在上述模型中，当使用 $Z$ 作为 $X$ 的工具变量时，$Y$ 的线性结构方程中 $X$ 的识别系数 $\\widehat{\\beta}_{\\mathrm{IV}}$。该系数通过将 $Y$ 的回归量投影到工具变量的列空间，并求解相应的正规方程获得。\n- 用于检验上述识别系数的原假设 $H_0:\\beta=0$ 的双边 $p$ 值，使用同方差线性模型、学生t分布以及自由度 $n-k$（其中 $k=2$ 是结构方程中的系数数量，即截距和斜率）。\n- 用于检验“$X$ 在工具变量空间上的线性投影中 $Z$ 的系数为零”这一原假设的第一阶段 $F$ 统计量。使用针对带截距的单个工具变量的标准 $F$ 统计量，自由度为 $\\left(1, n-2\\right)$。\n- 对带有截距的 $Y$ 对 $X$ 的回归所得到的普通最小二乘法系数 $\\widehat{\\beta}_{\\mathrm{OLS}}$。\n\n所有量值都必须从样本中计算得出，并以实数形式表示。不涉及任何物理单位。当需要显著性水平时，使用小数 $\\alpha=0.05$。随机抽样必须是可复现的：对于每个测试用例，请使用以所提供的整数种子 $s$ 初始化的伪随机数生成器。\n\n测试套件（四个用例）：\n- 用例 A（有效工具变量，非零因果效应）：$n=5000$, $p=0.3$, $\\alpha=0.8$, $\\beta=1.2$, $\\delta=1.0$, $\\kappa=1.0$, $\\gamma=0.0$, $\\sigma_X=1.0$, $\\sigma_Y=1.0$, $s=2021$。\n- 用例 B（有效工具变量，零因果效应）：$n=5000$, $p=0.3$, $\\alpha=0.8$, $\\beta=0.0$, $\\delta=1.0$, $\\kappa=1.0$, $\\gamma=0.0$, $\\sigma_X=1.0$, $\\sigma_Y=1.0$, $s=2022$。\n- 用例 C（通过直接效应导致的无效工具变量）：$n=5000$, $p=0.3$, $\\alpha=0.8$, $\\beta=1.0$, $\\delta=1.0$, $\\kappa=1.0$, $\\gamma=0.6$, $\\sigma_X=1.0$, $\\sigma_Y=1.0$, $s=2023$。\n- 用例 D（弱工具变量）：$n=5000$, $p=0.3$, $\\alpha=0.05$, $\\beta=1.0$, $\\delta=1.0$, $\\kappa=1.0$, $\\gamma=0.0$, $\\sigma_X=1.0$, $\\sigma_Y=1.0$, $s=2024$。\n\n最终输出格式：\n- 对于每个测试用例，返回列表 $\\left[\\widehat{\\beta}_{\\mathrm{IV}},\\, p\\text{-value}_{\\mathrm{IV}},\\, F_{\\text{first-stage}},\\, \\widehat{\\beta}_{\\mathrm{OLS}}\\right]$，其中每个条目都四舍五入到恰好 $4$ 位小数。\n- 你的程序应该生成单行输出，其中包含四个用例的结果，形式为由这些列表组成的、以逗号分隔的列表，并用方括号括起来（例如，$\\left[\\left[a,b,c,d\\right],\\left[\\dots\\right],\\left[\\dots\\right],\\left[\\dots\\right]\\right]$），所有数字都按指定要求进行四舍五入。",
            "solution": "该问题具有科学依据，定义明确，并且所有变量和过程都以足够的数学精度进行了定义。它描述了一项基于线性结构因果模型（因果推断中的一种标准工具）的模拟研究，旨在评估普通最小二乘法（OLS）和工具变量（IV）估计量在与孟德尔随机化相关的不同场景下的性能。该问题是有效的。\n\n任务是根据指定的模型为四组不同的参数集生成数据，并为每组数据计算四个统计量：IV 估计值 $\\widehat{\\beta}_{\\mathrm{IV}}$、其对应的 $p$ 值、第一阶段的 $F$ 统计量以及 OLS 估计值 $\\widehat{\\beta}_{\\mathrm{OLS}}$。\n\n解决方案分五个阶段进行：\n1. 数据生成：对于每个测试用例，我们根据指定的分布和结构方程生成一个大小为 $n$ 的样本。\n2. OLS 估计：我们通过对 $Y$ 关于 $X$ 和一个截距进行回归来计算 OLS 估计值 $\\widehat{\\beta}_{\\mathrm{OLS}}$。\n3. IV 估计：我们使用两阶段最小二乘法 (2SLS) 程序计算 IV 估计值 $\\widehat{\\beta}_{\\mathrm{IV}}$。\n4. IV 推断：我们计算 $\\widehat{\\beta}_{\\mathrm{IV}}$ 的标准误，以找出用于检验原假设 $H_0: \\beta=0$ 的 $t$ 统计量和相应的 $p$ 值。\n5. 第一阶段诊断：我们计算第一阶段回归的 $F$ 统计量，以评估工具变量的强度。\n\n令长度为 $n$ 的向量 $\\mathbf{y}$、$\\mathbf{x}$、$\\mathbf{z}$ 分别代表抽样数据 $\\{Y_i\\}_{i=1}^n$、$\\{X_i\\}_{i=1}^n$ 和 $\\{Z_i\\}_{i=1}^n$。令 $\\mathbf{1}$ 为长度为 $n$ 的全1向量。\n\n**1. 数据生成**\n对于每个个体 $i \\in \\{1, \\dots, n\\}$，我们按规定生成变量：\n- 遗传工具变量：$Z_i \\sim \\text{Binomial}(2,p)$\n- 未观测到的混杂因素：$U_i \\sim \\mathcal{N}(0,1)$\n- 误差项：$\\varepsilon^X_i \\sim \\mathcal{N}(0,\\sigma_X^2)$ 和 $\\varepsilon^Y_i \\sim \\mathcal{N}(0,\\sigma_Y^2)$\n利用这些，我们构建可观测变量 $X_i$ 和 $Y_i$：\n$$\nX_i \\;=\\; \\alpha Z_i \\;+\\; \\delta U_i \\;+\\; \\varepsilon^X_i\n$$\n$$\nY_i \\;=\\; \\beta X_i \\;+\\; \\kappa U_i \\;+\\; \\gamma Z_i \\;+\\; \\varepsilon^Y_i\n$$\n用种子 $s$ 初始化的伪随机数生成器确保了每个用例的可复现性。\n\n**2. 普通最小二乘法 (OLS) 估计**\nOLS 模型包含一个截距：$Y_i = b_0 + b_1 X_i + e_i$。其矩阵形式为 $\\mathbf{y} = \\mathbf{X}_{\\text{OLS}} \\mathbf{b} + \\mathbf{e}$，其中 $\\mathbf{X}_{\\text{OLS}} = [\\mathbf{1}, \\mathbf{x}]$ 是 $n \\times 2$ 的设计矩阵。\n$\\mathbf{b} = [b_0, b_1]'$ 的 OLS 估计量由正规方程的解给出：\n$$\n\\widehat{\\mathbf{b}}_{\\mathrm{OLS}} = (\\mathbf{X}_{\\text{OLS}}' \\mathbf{X}_{\\text{OLS}})^{-1} \\mathbf{X}_{\\text{OLS}}' \\mathbf{y}\n$$\n所需的量是斜率系数 $\\widehat{\\beta}_{\\mathrm{OLS}} = \\widehat{b}_1$。\n\n**3. 工具变量 (IV) 估计**\nIV 估计使用两阶段最小二乘法 (2SLS) 执行。\n$Y$ 的结构方程是 $Y_i = \\beta_0 + \\beta_1 X_i + \\eta_i$。内生回归量 $X$ 的工具变量是 $Z$。我们在所有回归中都包含一个截距。\n回归量矩阵是 $\\mathbf{X}_{\\text{reg}} = [\\mathbf{1}, \\mathbf{x}]$，工具变量矩阵是 $\\mathbf{Z}_{\\text{inst}} = [\\mathbf{1}, \\mathbf{z}]$。\n\n第一阶段：将回归量投影到由工具变量张成的空间上。投影矩阵是 $\\mathbf{P_Z} = \\mathbf{Z}_{\\text{inst}} (\\mathbf{Z}_{\\text{inst}}' \\mathbf{Z}_{\\text{inst}})^{-1} \\mathbf{Z}_{\\text{inst}}'$。投影后的回归量是 $\\widehat{\\mathbf{X}}_{\\text{reg}} = \\mathbf{P_Z} \\mathbf{X}_{\\text{reg}}$。\n\n第二阶段：2SLS 估计量 $\\widehat{\\mathbf{\\beta}}_{\\mathrm{IV}} = [\\widehat{\\beta}_0, \\widehat{\\beta}_1]'$ 是通过将 $\\mathbf{y}$ 对 $\\widehat{\\mathbf{X}}_{\\text{reg}}$ 回归得到的。然而，一个更直接和标准的公式是：\n$$\n\\widehat{\\mathbf{\\beta}}_{\\mathrm{IV}} = (\\mathbf{X}_{\\text{reg}}' \\mathbf{P_Z} \\mathbf{X}_{\\text{reg}})^{-1} \\mathbf{X}_{\\text{reg}}' \\mathbf{P_Z} \\mathbf{y}\n$$\n因果效应的估计值是斜率系数，我们将其记为 $\\widehat{\\beta}_{\\mathrm{IV}}$（这里略微滥用了符号，它实际上是向量中的 $\\widehat{\\beta}_1$）。\n\n**4. $\\widehat{\\beta}_{\\mathrm{IV}}$ 的 P 值**\n为了检验原假设 $H_0: \\beta=0$，我们计算一个 $t$ 统计量。\n首先，我们使用估计出的系数和原始回归量计算残差：\n$$\n\\mathbf{e}_{\\mathrm{IV}} = \\mathbf{y} - \\mathbf{X}_{\\text{reg}} \\widehat{\\mathbf{\\beta}}_{\\mathrm{IV}}\n$$\n在同方差性假设下，回归误差的估计方差是：\n$$\n\\widehat{\\sigma}^2_{\\mathrm{IV}} = \\frac{\\mathbf{e}_{\\mathrm{IV}}' \\mathbf{e}_{\\mathrm{IV}}}{n-k}\n$$\n其中 $k=2$ 是参数的数量（截距和斜率）。估计量的方差-协方差矩阵是：\n$$\n\\widehat{\\text{Var}}(\\widehat{\\mathbf{\\beta}}_{\\mathrm{IV}}) = \\widehat{\\sigma}^2_{\\mathrm{IV}} (\\mathbf{X}_{\\text{reg}}' \\mathbf{P_Z} \\mathbf{X}_{\\text{reg}})^{-1}\n$$\n斜率系数的标准误 $SE(\\widehat{\\beta}_{\\mathrm{IV}})$ 是该矩阵第二个对角元素的平方根。$t$ 统计量是：\n$$\nt = \\frac{\\widehat{\\beta}_{\\mathrm{IV}}}{SE(\\widehat{\\beta}_{\\mathrm{IV}})}\n$$\n双边 $p$ 值使用自由度为 $n-k = n-2$ 的学生t分布计算：\n$$\np\\text{-value}_{\\mathrm{IV}} = 2 \\cdot P(T_{n-2} > |t|)\n$$\n\n**5. 第一阶段 F 统计量**\n第一阶段的回归是 $X_i = \\pi_0 + \\pi_1 Z_i + \\nu_i$。我们需要检验原假设 $H_0: \\pi_1 = 0$。\n$F$ 统计量将完整模型（包含 $Z_i$）与受限模型（仅包含截距）进行比较。\n令 $RSS_1$ 为完整第一阶段回归（$X$ 对 $\\mathbf{1}$ 和 $\\mathbf{z}$ 回归）的残差平方和。令 $TSS$ 为 $X$ 的总平方和，即 $X$ 仅对截距回归的残差平方和。对于带一个工具变量和一个截距的情况，$F$ 统计量的公式是：\n$$\nF_{\\text{first-stage}} = \\frac{(TSS - RSS_1) / (2-1)}{RSS_1 / (n-2)} = \\frac{TSS - RSS_1}{RSS_1 / (n-2)}\n$$\n在原假设下，该统计量服从自由度为 $(1, n-2)$ 的 $F$ 分布。\n\n这五个步骤将为四个测试用例中的每一个实施。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Solves the problem by iterating through test cases, simulating data,\n    and calculating the required statistical quantities.\n    \"\"\"\n    test_cases = [\n        # Case A (valid instrument, nonzero causal effect)\n        {'n': 5000, 'p': 0.3, 'alpha': 0.8, 'beta': 1.2, 'delta': 1.0, 'kappa': 1.0, 'gamma': 0.0, 'sigma_X': 1.0, 'sigma_Y': 1.0, 's': 2021},\n        # Case B (valid instrument, null causal effect)\n        {'n': 5000, 'p': 0.3, 'alpha': 0.8, 'beta': 0.0, 'delta': 1.0, 'kappa': 1.0, 'gamma': 0.0, 'sigma_X': 1.0, 'sigma_Y': 1.0, 's': 2022},\n        # Case C (invalid instrument via direct effect)\n        {'n': 5000, 'p': 0.3, 'alpha': 0.8, 'beta': 1.0, 'delta': 1.0, 'kappa': 1.0, 'gamma': 0.6, 'sigma_X': 1.0, 'sigma_Y': 1.0, 's': 2023},\n        # Case D (weak instrument)\n        {'n': 5000, 'p': 0.3, 'alpha': 0.05, 'beta': 1.0, 'delta': 1.0, 'kappa': 1.0, 'gamma': 0.0, 'sigma_X': 1.0, 'sigma_Y': 1.0, 's': 2024},\n    ]\n\n    results = []\n    for params in test_cases:\n        n = params['n']\n        p = params['p']\n        alpha = params['alpha']\n        beta = params['beta']\n        delta = params['delta']\n        kappa = params['kappa']\n        gamma = params['gamma']\n        sigma_X = params['sigma_X']\n        sigma_Y = params['sigma_Y']\n        s = params['s']\n\n        # 1. Data Generation\n        rng = np.random.default_rng(s)\n        Z = rng.binomial(2, p, size=n)\n        U = rng.normal(0, 1, size=n)\n        eps_X = rng.normal(0, sigma_X, size=n)\n        eps_Y = rng.normal(0, sigma_Y, size=n)\n        \n        X = alpha * Z + delta * U + eps_X\n        Y = beta * X + kappa * U + gamma * Z + eps_Y\n\n        # Prepare matrices for regressions\n        ones = np.ones(n)\n        \n        # OLS matrices\n        X_ols_mat = np.vstack([ones, X]).T\n        \n        # IV/2SLS matrices\n        X_reg_mat = np.vstack([ones, X]).T  # Regressors for 2nd stage\n        Z_inst_mat = np.vstack([ones, Z]).T # Instruments for 1st stage\n\n        # 2. OLS Estimation\n        try:\n            b_ols_hat_vec = np.linalg.solve(X_ols_mat.T @ X_ols_mat, X_ols_mat.T @ Y)\n            beta_ols_hat = b_ols_hat_vec[1]\n        except np.linalg.LinAlgError:\n            beta_ols_hat = np.nan\n\n        # 3. IV Estimation (2SLS)\n        try:\n            # Projection matrix P_Z\n            ZtZ_inv = np.linalg.inv(Z_inst_mat.T @ Z_inst_mat)\n            P_Z = Z_inst_mat @ ZtZ_inv @ Z_inst_mat.T\n            \n            # 2SLS estimator\n            X_reg_T_P_Z = X_reg_mat.T @ P_Z\n            beta_iv_vec = np.linalg.solve(X_reg_T_P_Z @ X_reg_mat, X_reg_T_P_Z @ Y)\n            beta_iv_hat = beta_iv_vec[1]\n\n            # 4. IV p-value calculation\n            k = 2  # Number of parameters in 2nd stage (intercept, slope)\n            df = n - k\n            residuals_iv = Y - X_reg_mat @ beta_iv_vec\n            sigma2_hat_iv = np.sum(residuals_iv**2) / df\n            \n            var_cov_beta_iv = sigma2_hat_iv * np.linalg.inv(X_reg_T_P_Z @ X_reg_mat)\n            se_beta_iv_hat = np.sqrt(var_cov_beta_iv[1, 1])\n            \n            t_stat_iv = beta_iv_hat / se_beta_iv_hat\n            p_value_iv = 2 * t.sf(np.abs(t_stat_iv), df=df)\n\n        except np.linalg.LinAlgError:\n            beta_iv_hat = np.nan\n            p_value_iv = np.nan\n\n        # 5. First-stage F-statistic\n        try:\n            # Full model: X ~ 1 + Z\n            _, rss1, _, _ = np.linalg.lstsq(Z_inst_mat, X, rcond=None)\n            \n            # Restricted model: X ~ 1\n            X_mean = np.mean(X)\n            tss = np.sum((X - X_mean)**2)\n            \n            df_num = 1\n            df_den = n - 2\n            \n            f_stat = ((tss - rss1[0]) / df_num) / (rss1[0] / df_den)\n        except (np.linalg.LinAlgError, IndexError):\n            f_stat = np.nan\n\n        # Store results for the current case\n        results.append([beta_iv_hat, p_value_iv, f_stat, beta_ols_hat])\n\n    # Final print statement in the exact required format.\n    formatted_results = [\n        f\"[{r[0]:.4f},{r[1]:.4f},{r[2]:.4f},{r[3]:.4f}]\" for r in results\n    ]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}