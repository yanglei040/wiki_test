{
    "hands_on_practices": [
        {
            "introduction": "在生物学研究中，我们经常需要判断两个分类变量之间是否存在关联，例如某种细菌种类是否与特定的抗生素耐药性相关。卡方检验 (Chi-squared test) 是解决此类问题的基本工具，它通过比较观测频数和零假设下的期望频数来量化变量之间的关联强度。通过这个练习，你将亲手计算卡方统计量，从而掌握假设检验的核心逻辑，并为分析真实的生物学分类数据打下坚实的基础。",
            "id": "2398945",
            "problem": "一家医院的微生物实验室正在监测从血流感染中分离出的细菌菌株的抗生素耐药性。对于一种目标抗生素，分离株根据细菌种类和药敏试验的表型结果（耐药或敏感）进行分类。在一个月内，记录了以下计数：\n- Escherichia coli：$40$ 例耐药，$60$ 例敏感。\n- Staphylococcus aureus：$25$ 例耐药，$75$ 例敏感。\n- Pseudomonas aeruginosa：$35$ 例耐药，$15$ 例敏感。\n\n将这些数据视为一个大小为 $N$ 的随机样本，该样本来自于分类变量“菌种”和“耐药状态”的联合分布。在耐药状态与菌种无关的原假设下，使用数据所隐含的 $3 \\times 2$ 列联表，确定用于独立性检验的 Pearson 卡方检验统计量。\n\n仅提供检验统计量的值。将您的答案四舍五入至四位有效数字。",
            "solution": "问题陈述已经过评估，被认为是有效的。它具有科学依据，提法明确，客观，并为获得唯一解提供了所有必要信息。这是统计假设检验在计算生物学中的一个标准应用。我们现在开始求解。\n\n本题要求计算用于列联表独立性检验的 Pearson 卡方检验统计量，记为 $\\chi^2$。数据涉及三种细菌菌株的抗生素耐药性。\n\n首先，我们必须将所提供的计数整理成一个观测频率列联表，记为 $O_{ij}$。令行 $i$ 代表细菌种类，列 $j$ 代表耐药状态（耐药，敏感）。\n\n观测频率如下：\n- *Escherichia coli*：$O_{11} = 40$ 例耐药，$O_{12} = 60$ 例敏感。\n- *Staphylococcus aureus*：$O_{21} = 25$ 例耐药，$O_{22} = 75$ 例敏感。\n- *Pseudomonas aeruginosa*：$O_{31} = 35$ 例耐药，$O_{32} = 15$ 例敏感。\n\n我们构建 $3 \\times 2$ 列联表，并计算行总计 ($R_i$)、列总计 ($C_j$) 和总计 ($N$)。\n\n观测频率 $O_{ij}$ 表如下：\n$$\n\\begin{array}{c|cc|c}\n\\text{菌种}  \\text{耐药}  \\text{敏感}  \\text{行总计 } (R_i) \\\\\n\\hline\n\\text{E. coli}  40  60  100 \\\\\n\\text{S. aureus}  25  75  100 \\\\\n\\text{P. aeruginosa}  35  15  50 \\\\\n\\hline\n\\text{列总计 } (C_j)  100  150  250\n\\end{array}\n$$\n行总计为 $R_1 = 40 + 60 = 100$，$R_2 = 25 + 75 = 100$ 和 $R_3 = 35 + 15 = 50$。\n列总计为 $C_1 = 40 + 25 + 35 = 100$ 和 $C_2 = 60 + 75 + 15 = 150$。\n总计为 $N = 100 + 100 + 50 = 250$。\n\n原假设 $H_0$ 指出，耐药状态与细菌种类无关。在此假设下，每个单元格的期望频率 $E_{ij}$ 使用以下公式计算：\n$$ E_{ij} = \\frac{R_i \\times C_j}{N} $$\n\n我们现在计算每个单元格的期望频率：\n- $E_{11} = \\frac{R_1 \\times C_1}{N} = \\frac{100 \\times 100}{250} = \\frac{10000}{250} = 40$\n- $E_{12} = \\frac{R_1 \\times C_2}{N} = \\frac{100 \\times 150}{250} = \\frac{15000}{250} = 60$\n- $E_{21} = \\frac{R_2 \\times C_1}{N} = \\frac{100 \\times 100}{250} = \\frac{10000}{250} = 40$\n- $E_{22} = \\frac{R_2 \\times C_2}{N} = \\frac{100 \\times 150}{250} = \\frac{15000}{250} = 60$\n- $E_{31} = \\frac{R_3 \\times C_1}{N} = \\frac{50 \\times 100}{250} = \\frac{5000}{250} = 20$\n- $E_{32} = \\frac{R_3 \\times C_2}{N} = \\frac{50 \\times 150}{250} = \\frac{7500}{250} = 30$\n\nPearson 卡方检验统计量的计算方法是，将观测频率与期望频率之差的平方除以期望频率，然后对表中所有单元格求和：\n$$ \\chi^2 = \\sum_{i=1}^{r} \\sum_{j=1}^{c} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}} $$\n其中 $r=3$ 是行数，$c=2$ 是列数。\n\n我们计算每个单元格对 $\\chi^2$ 统计量的贡献：\n- 单元格(1,1)：$\\frac{(40 - 40)^2}{40} = \\frac{0}{40} = 0$\n- 单元格(1,2)：$\\frac{(60 - 60)^2}{60} = \\frac{0}{60} = 0$\n- 单元格(2,1)：$\\frac{(25 - 40)^2}{40} = \\frac{(-15)^2}{40} = \\frac{225}{40} = 5.625$\n- 单元格(2,2)：$\\frac{(75 - 60)^2}{60} = \\frac{(15)^2}{60} = \\frac{225}{60} = 3.75$\n- 单元格(3,1)：$\\frac{(35 - 20)^2}{20} = \\frac{(15)^2}{20} = \\frac{225}{20} = 11.25$\n- 单元格(3,2)：$\\frac{(15 - 30)^2}{30} = \\frac{(-15)^2}{30} = \\frac{225}{30} = 7.5$\n\n总 $\\chi^2$ 统计量是这些值的总和：\n$$ \\chi^2 = 0 + 0 + 5.625 + 3.75 + 11.25 + 7.5 = 28.125 $$\n\n题目要求答案四舍五入至四位有效数字。数值 $28.125$ 四舍五入到四位有效数字是 $28.13$。",
            "answer": "$$\n\\boxed{28.13}\n$$"
        },
        {
            "introduction": "在分析像RNA测序这样的高通量数据时，我们经常会遇到异常值（outliers），这些极端值可能会严重影响像$t$检验这类依赖数据正态性假设的参数检验结果。这个实践将通过一个编程练习，让你直观地看到单个异常值如何扭曲$t$检验的$p$值，而基于秩次的非参数检验（如Wilcoxon秩和检验）却能保持稳健。掌握这种对比，对于在真实的生物数据分析中选择正确的统计工具至关重要。",
            "id": "2398972",
            "problem": "构建一个程序，该程序针对在核糖核酸测序 (RNA-seq) 中跨两种生物学条件测量的一个固定基因，计算双样本 Welch $t$ 检验和 Wilcoxon 秩和检验（也称 Mann-Whitney U 检验）的双侧 p 值，并在一组指定的测试套件中汇总结果。假设每种条件都为该基因产生独立的重复计数，并将提供的计数视为观测值。两种检验的原假设均为两种条件具有相同的集中趋势，表述为 $H_0$：两种条件分别从具有相同均值（Welch $t$ 检验）或相同连续分布（Wilcoxon 秩和检验）的总体中抽样。不对计数进行任何转换。所有检验都必须是双侧的。\n\n您的程序必须处理以下测试套件，其中每一项都指定了条件 $A$ 和条件 $B$ 的计数：\n\n- 测试用例 $1$（基线，无离群值，分布可比）：\n  - 条件 $A$：$\\left(43, 50, 39, 61, 55, 47\\right)$\n  - 条件 $B$：$\\left(45, 52, 41, 58, 53, 49\\right)$\n\n- 测试用例 $2$（条件 $B$ 中有单个极端高值离群值）：\n  - 条件 $A$：$\\left(43, 50, 39, 61, 55, 47\\right)$\n  - 条件 $B$：$\\left(45, 52, 41, 58, 53, 1000\\right)$\n\n- 测试用例 $3$（小样本量，且条件 $B$ 中有单个极端高值离群值）：\n  - 条件 $A$：$\\left(20, 22, 25\\right)$\n  - 条件 $B$：$\\left(19, 21, 400\\right)$\n\n- 测试用例 $4$（位置偏移，且条件 $B$ 中有单个极端低值离群值）：\n  - 条件 $A$：$\\left(15, 16, 18, 20, 19, 17\\right)$\n  - 条件 $B$：$\\left(28, 30, 27, 29, 31, 0\\right)$\n\n对于每个测试用例 $i \\in \\{1,2,3,4\\}$，计算：\n- $p_{t,i}$：比较条件 $A$ 和条件 $B$ 的双样本 Welch $t$ 检验的双侧 p 值。\n- $p_{w,i}$：比较条件 $A$ 和条件 $B$ 的 Wilcoxon 秩和检验的双侧 p 值。\n\n您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须包含 $8$ 个浮点数，按 $\\left[p_{t,1}, p_{w,1}, p_{t,2}, p_{w,2}, p_{t,3}, p_{w,3}, p_{t,4}, p_{w,4}\\right]$ 的顺序排列，每个数字四舍五入到 $6$ 位小数。不应打印任何附加文本。所有数字都是无量纲的，并且必须以小数形式表示（例如，$0.012345$），而不是百分比。",
            "solution": "该问题要求对来自两种条件的 RNA 测序计数数据应用两种不同的统计假设检验——即 Welch 双样本 $t$ 检验和 Wilcoxon 秩和检验，并计算其 p 值。目标是比较参数检验与非参数检验的性能，尤其是在存在离群值的情况下，这种情况在生物数据集中很常见。在进行计算求解之前，我们必须为每个检验建立理论基础。\n\n**1. Welch 双样本 $t$ 检验**\n\nWelch $t$ 检验是一种统计工具，用于比较两个独立样本（此处表示为条件 $A$ 和条件 $B$）的均值。它是 Student $t$ 检验的一种变体，在两个样本方差不相等（即所谓的 Behrens-Fisher 问题）时被认为更可靠。原假设 $H_0$ 假定总体均值相等，即 $H_0: \\mu_A = \\mu_B$。\n\n检验统计量 $t$ 的计算方法为样本均值之差除以差值的标准误：\n$$\nt = \\frac{\\bar{x}_A - \\bar{x}_B}{\\sqrt{\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}}}\n$$\n其中：\n- $\\bar{x}_A$ 和 $\\bar{x}_B$ 分别是条件 $A$ 和条件 $B$ 的样本均值。\n- $s_A^2$ 和 $s_B^2$ 是无偏样本方差。\n- $n_A$ 和 $n_B$ 是样本量。\n\n与 Student $t$ 检验不同，Welch 检验的自由度 $\\nu$ 并非简单的 $n_A + n_B - 2$。它需要使用 Welch-Satterthwaite 方程进行近似计算：\n$$\n\\nu \\approx \\frac{\\left( \\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B} \\right)^2}{\\frac{(s_A^2/n_A)^2}{n_A - 1} + \\frac{(s_B^2/n_B)^2}{n_B - 1}}\n$$\n然后，根据具有 $\\nu$ 自由度的 Student $t$ 分布确定 p 值。对于双侧检验，p 值为 $2 \\cdot P(T_\\nu  |t|)$，其中 $T_\\nu$ 是一个服从 $t$ 分布的随机变量。\n\n$t$ 检验的一个关键假设是两个样本中的数据都近似服从正态分布。当数据严重偏离正态性时，例如出现偏斜或重尾分布，该检验的性能会下降。至关重要的是，样本均值 $(\\bar{x})$ 和方差 $(s^2)$ 对极端值（离群值）高度敏感，这些值会对 $t$ 统计量产生不成比例的影响，从而导致错误的结论。\n\n**2. Wilcoxon 秩和（Mann-Whitney U）检验**\n\nWilcoxon 秩和检验是 $t$ 检验的一种非参数替代方法。它不对数据的特定分布做任何假设，因此更为稳健。该检验的原假设是，对于从两个总体中随机选取的值 $X$ 和 $Y$，$X$ 大于 $Y$ 的概率等于 $Y$ 大于 $X$ 的概率。更一般地说，它检验的是两个样本是否从具有相同分布的总体中抽取。\n\n其步骤如下：\n1. 将所有 $n_A + n_B$ 个观测值合并到一个列表中并排序。如果存在结（相同值），则为它们分配本应分配的秩的平均值。\n2. 计算其中一个样本（例如样本 $A$）的秩之和，记为 $R_A$。\n3. 检验统计量 $U$ 基于此秩和计算。对于样本 $A$，统计量 $U_A$ 为：\n   $$\n   U_A = R_A - \\frac{n_A(n_A + 1)}{2}\n   $$\n   检验统计量 $U$ 通常取 $U = \\min(U_A, U_B)$，其中 $U_B$ 的计算方法与样本 $B$ 类似。\n4. p 值是根据原假设下 $U$ 统计量的已知分布确定的。对于小样本量，使用精确分布。对于大样本，则采用带连续性校正的正态近似。\n\n由于 Wilcoxon 检验是基于秩而不是原始数据值进行操作，其统计量不受离群值大小的影响，只受其序数位置的影响。一个极端值仅被视为最高（或最低）的秩，其具体的数值不会进一步影响检验统计量。这一特性赋予了该检验对离群值的强大稳健性。\n\n**3. 测试用例的应用与解释**\n\n所提供的测试用例旨在突出这两种检验的不同敏感性。\n- **测试用例 1**: 分布相似且无离群值。预计两种检验都会产生较高的 p 值，表明没有显著差异。\n- **测试用例 2 和 3**: 在条件 $B$ 中引入了一个极端高值离群值。预计 $t$ 检验的 p 值将受到显著影响，因为该离群值会同时抬高条件 $B$ 的均值和方差。相比之下，Wilcoxon 检验应相对不受影响，从而能更稳定地评估集中趋势的偏移。\n- **测试用例 4**: 在条件 $B$ 中引入了一个极端低值离群值，而其其余成员的值相较于条件 $A$ 有所升高。这个离群值会拉低条件 $B$ 的均值，可能掩盖 $t$ 检验本应检测到的真实位置偏移。然而，秩和检验更能检测出两个样本主体之间一致的秩差异。\n\n计算实现将使用 `scipy.stats` 库，具体而言，使用带参数 `equal_var=False` 的 `ttest_ind` 函数执行 Welch $t$ 检验，以及带参数 `alternative='two-sided'` 的 `mannwhitneyu` 函数执行 Wilcoxon 秩和检验。将为每个测试用例系统地计算结果，并按要求进行格式化。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import ttest_ind, mannwhitneyu\n\ndef solve():\n    \"\"\"\n    Computes and prints p-values for Welch's t-test and Wilcoxon rank-sum test\n    for a suite of RNA-seq count data test cases.\n    \"\"\"\n\n    # Define the test suite as specified in the problem statement.\n    test_cases = [\n        # Test case 1: baseline, no outlier, comparable distributions\n        (np.array([43, 50, 39, 61, 55, 47]), np.array([45, 52, 41, 58, 53, 49])),\n        # Test case 2: single extreme high outlier in condition B\n        (np.array([43, 50, 39, 61, 55, 47]), np.array([45, 52, 41, 58, 53, 1000])),\n        # Test case 3: small sample size with a single extreme high outlier in condition B\n        (np.array([20, 22, 25]), np.array([19, 21, 400])),\n        # Test case 4: location shift with a single extreme low outlier in condition B\n        (np.array([15, 16, 18, 20, 19, 17]), np.array([28, 30, 27, 29, 31, 0])),\n    ]\n\n    results = []\n    for cond_a, cond_b in test_cases:\n        # Perform Welch's two-sample t-test.\n        # The `equal_var=False` argument specifies that we should perform Welch's t-test,\n        # which does not assume equal population variance.\n        # The test is two-sided by default.\n        t_stat, p_t = ttest_ind(cond_a, cond_b, equal_var=False)\n        results.append(p_t)\n\n        # Perform the Wilcoxon rank-sum test (Mann-Whitney U test).\n        # We explicitly specify a two-sided test.\n        # The 'auto' method for p-value calculation is used by default,\n        # which chooses between an exact test and a normal approximation\n        # based on sample size and presence of ties.\n        u_stat, p_w = mannwhitneyu(cond_a, cond_b, alternative='two-sided')\n        results.append(p_w)\n\n    # Format the results as a comma-separated list of floating-point numbers\n    # rounded to 6 decimal places, enclosed in square brackets.\n    formatted_results = [f\"{p:.6f}\" for p in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "许多前沿的计算生物学问题所使用的检验统计量（例如，两个个体间最长共享DNA片段的长度）其零分布非常复杂，无法用现成的数学公式描述。在这种情况下，计算机模拟便成为我们最强大的工具。这个练习将指导你通过蒙特卡洛模拟方法，为复杂的检验统计量生成经验零分布并估算$p$值，让你掌握一种不依赖于“教科书”分布的、极为灵活且应用广泛的假设检验技术。",
            "id": "2398987",
            "problem": "您正在研究两个个体是否在某条染色体上共享异常长的状态相同（identical-by-state）片段。检验统计量是等位基因匹配的最长连续标记块的长度（以碱基对为单位），该长度通过计算标记块末端标记和起始标记的物理位置之差来衡量。在两个个体不相关的零假设下，每个标记匹配被建模为一个独立的伯努利试验，其具有给定的单位标记匹配概率。由于对于实际的标记布局和异构的匹配概率，最长连续片段长度的零分布在分析上是难解的，因此您将通过蒙特卡罗模拟来近似它。\n\n您的任务是实现一个程序，该程序针对多个测试用例，使用模拟的零数据来估计观测到的最长匹配片段长度的蒙特卡罗 p 值。请遵循以下科学原理和定义作为您设计的基础：\n\n- 令 $M_i \\in \\{0,1\\}$ 表示标记 $i$ 处的匹配指示符，其中 $M_i = 1$ 表示匹配，$M_i = 0$ 表示不匹配。在无亲缘关系的零假设 $\\mathcal{H}_0$ 下，假设 $\\{M_i\\}_{i=0}^{n-1}$ 是独立的伯努利随机变量，其匹配概率可以是一个共同的概率 $p$，也可以是每个标记各自的概率 $p_i$。\n- 令 $x_i$ 表示标记 $i$ 的物理位置（以碱基对为单位），且 $x_0  x_1  \\dots  x_{n-1}$ 严格递增。\n- 将检验统计量 $T(M, x)$ 定义为在所有 $M_i = 1$ 的连续运行（run）中，片段长度的最大值。片段长度由 $x_{j} - x_{i}$ 计算得出，其中运行从索引 $i$ 开始，到索引 $j \\ge i$ 结束。根据定义，长度为一个标记的运行，其片段长度为 0 碱基对。\n- 给定一个观测统计量 $T_{\\text{obs}}$，使用来自零模型的 $B$ 次独立模拟，通过蒙特卡罗方法来近似零 p 值。在每次模拟 $b \\in \\{1,\\dots,B\\}$ 中，从伯努利模型生成一个独立序列 $M^{(b)}$，计算 $T^{(b)} = T(M^{(b)}, x)$，并估计\n$$\n\\widehat{p} \\;=\\; \\frac{1 + \\sum_{b=1}^{B} \\mathbf{1}\\{T^{(b)} \\ge T_{\\text{obs}}\\}}{B+1}\n$$,\n这是标准的蒙特卡罗 p 值，带有 $+1$ 连续性校正以避免零估计。根据大数强定律，在 $\\mathcal{H}_0$ 下，当 $B \\to \\infty$ 时，$\\widehat{p}$ 几乎必然收敛于真实的 p 值。\n\n实现要求：\n\n- 使用固定的伪随机数生成器种子 $20231011$ 以确保可复现性。\n- 对于每个测试用例，模拟 $B$ 个零复制，按上述方式计算 $\\widehat{p}$，并报告结果。\n- 所有模拟的标记匹配在其给定概率下必须是独立的。如果提供的是标量 $p$，则对所有 $i$ 使用 $M_i \\sim \\text{Bernoulli}(p)$。如果提供的是向量 $(p_0,\\dots,p_{n-1})$，则独立地使用 $M_i \\sim \\text{Bernoulli}(p_i)$。\n- 统计量必须使用提供的 $x_i$ 位置以碱基对为单位进行计算。输出中不进行单位转换；输出为 p 值，必须是无量纲的小数（不带百分号）。\n\n测试套件：\n\n实现您的程序来计算以下四种情况的 $\\widehat{p}$。在每种情况下，索引为 $i \\in \\{0,1,\\dots,n-1\\}$。\n\n- 情况 1（正常路径，长数组，中等匹配概率）：\n  - $n = 1000$。\n  - 位置：$x_i = 10000 \\cdot i$（以碱基对为单位）。\n  - 匹配概率：标量 $p = 0.25$。\n  - 观测统计量：$T_{\\text{obs}} = 180000$（以碱基对为单位）。\n  - 模拟次数：$B = 5000$。\n\n- 情况 2（不规则间距，较高匹配概率）：\n  - $n = 200$。\n  - 位置：$x_i = 1000 \\cdot i + 5000 \\cdot \\left\\lfloor \\dfrac{i}{50} \\right\\rfloor$（以碱基对为单位），在索引 50、100 和 150 处引入了额外的间隙。\n  - 匹配概率：标量 $p = 0.5$。\n  - 观测统计量：$T_{\\text{obs}} = 100000$（以碱基对为单位）。\n  - 模拟次数：$B = 5000$。\n\n- 情况 3（小数组，稀疏匹配，边界观测统计量）：\n  - $n = 50$。\n  - 位置：$x_i = 20000 \\cdot i$（以碱基对为单位）。\n  - 匹配概率：标量 $p = 0.1$。\n  - 观测统计量：$T_{\\text{obs}} = 0$（以碱基对为单位）。\n  - 模拟次数：$B = 5000$。\n\n- 情况 4（位置相关的大间隙，异构的单位标记概率）：\n  - $n = 300$。\n  - 位置：$x_i = 500 \\cdot i + 20000 \\cdot \\left\\lfloor \\dfrac{i}{75} \\right\\rfloor$（以碱基对为单位），在索引 75、150 和 225 处引入了更大的间隙。\n  - 匹配概率：单位标记概率 $p_i = 0.05 + 0.45 \\cdot \\dfrac{i}{n-1}$，对于 $i=0,\\dots,n-1$。\n  - 观测统计量：$T_{\\text{obs}} = 50000$（以碱基对为单位）。\n  - 模拟次数：$B = 5000$。\n\n最终输出规范：\n\n- 您的程序应生成单行输出，其中包含按情况 1 到 4 顺序排列的四个蒙特卡罗 p 值，格式为一个用方括号括起来的逗号分隔列表，每个值四舍五入到 6 位小数（例如，$[0.123456,0.000200,1.000000,0.042314]$）。",
            "solution": "我们将共享基因组片段的假设检验表述如下。零假设 $\\mathcal{H}_0$ 假定两个个体不相关，因此沿着一个标记面板的匹配指示符表现为独立的伯努利随机变量，其具有给定的单位标记匹配概率。令 $M_i \\in \\{0,1\\}$ 表示标记 $i$ 处的匹配指示符，并令有序的物理位置为 $x_0  x_1  \\dots  x_{n-1}$（以碱基对为单位）。一个连续的匹配块（或运行）是一个最大的索引区间 $[i,j]$，其中对于所有 $k \\in \\{i,i+1,\\dots,j\\}$ 都有 $M_k = 1$，并且满足 $i=0$ 或 $M_{i-1}=0$，以及 $j=n-1$ 或 $M_{j+1}=0$。\n\n将检验统计量 $T(M,x)$ 定义为所有此类运行中片段长度（以碱基对为单位）的最大值，计算方式为 $x_j - x_i$。长度为一个标记的运行产生的片段长度为 0，因为在相邻的不同标记之间没有跨度。将观测统计量 $T_{\\text{obs}}$ 与 $T(M,x)$ 的零分布进行比较。\n\n挑战在于，对于实际的 $x$ 和异构概率，最大运行长度的精确零分布没有封闭形式的解。因此，我们基于以下原则，通过蒙特卡罗模拟来近似它：\n\n- 在 $\\mathcal{H}_0$ 下，模拟的 $M^{(b)}$ 与零数据生成过程具有相同的分布。因此，$T^{(b)}$ 是来自 $T$ 的零分布的独立同分布样本。\n- 指示变量 $\\mathbf{1}\\{T^{(b)} \\ge T_{\\text{obs}}\\}$ 是独立的伯努利变量，其均值等于 $T_{\\text{obs}}$ 处的真实零分布尾部概率。它们的和 $C$ 除以 $B$ 即可估计此均值。$+1$ 校正产生了一个保守的有限样本估计量，当 $B \\to \\infty$ 时，该估计量会收敛到真实的 p 值。\n- 该实现通过计算以碱基对为单位的 $x$ 的差值来尊重单位；报告的 p 值是无量纲的，并以小数表示。\n\n所提供测试套件中的边界情况：\n\n- 情况 3 使用 $T_{\\text{obs}} = 0$，这确保了 $C = B$，因此 $\\widehat{p} = \\dfrac{1+B}{B+1} = 1$（精确值）。\n- 情况 1 和 2 探测了极端尾部，其观测片段相对于零假设下的典型行为要长得多；而情况 4 引入了 $p_i$ 的异构性和与位置相关的大间隙，从而检验了通用的模拟逻辑。\n\n最终程序完全按照定义构建指定的位置数组和概率，将种子设置为 $20231011$，对每个案例用 $B=5000$ 运行模拟，计算四个 $\\widehat{p}$ 值，将每个值四舍五入到 6 位小数，并以要求的列表格式打印单行结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef longest_segment_bp(matches: np.ndarray, positions: np.ndarray) - int:\n    \"\"\"\n    Compute the longest contiguous run of True values in 'matches',\n    measured in base pairs as positions[end] - positions[start].\n    A run of length 1 has length 0.\n    \"\"\"\n    n = matches.size\n    max_len = 0\n    i = 0\n    # Ensure boolean array\n    m = matches.astype(bool, copy=False)\n    while i  n:\n        if m[i]:\n            start = i\n            # advance until the run ends\n            while i + 1  n and m[i + 1]:\n                i += 1\n            end = i\n            seg_len = int(positions[end] - positions[start])\n            if seg_len  max_len:\n                max_len = seg_len\n        i += 1\n    return max_len\n\ndef monte_carlo_pvalue(positions, probs, T_obs, B, rng) - float:\n    \"\"\"\n    Estimate Monte Carlo p-value: (1 + count[T_sim = T_obs]) / (B + 1)\n    positions: 1D array of increasing integers (base pairs)\n    probs: scalar in [0,1] or 1D array of per-marker probabilities in [0,1]\n    T_obs: observed longest segment length (base pairs)\n    B: number of simulations\n    rng: numpy Generator for reproducibility\n    \"\"\"\n    positions = np.asarray(positions, dtype=np.int64)\n    n = positions.size\n\n    count_ge = 0\n    # Prepare probability vector\n    if np.isscalar(probs):\n        p_vec = float(probs)\n        for _ in range(B):\n            matches = rng.random(n)  p_vec\n            T_sim = longest_segment_bp(matches, positions)\n            if T_sim = T_obs:\n                count_ge += 1\n    else:\n        p_arr = np.asarray(probs, dtype=float)\n        assert p_arr.shape == (n,), \"Per-marker probability vector must match number of positions.\"\n        for _ in range(B):\n            matches = rng.random(n)  p_arr\n            T_sim = longest_segment_bp(matches, positions)\n            if T_sim = T_obs:\n                count_ge += 1\n\n    pval = (1.0 + count_ge) / (B + 1.0)\n    return pval\n\ndef solve():\n    # Fixed random seed as specified\n    rng = np.random.default_rng(20231011)\n\n    # Test Case 1\n    n1 = 1000\n    positions1 = 10000 * np.arange(n1, dtype=np.int64)\n    p1 = 0.25\n    T_obs1 = 180000  # base pairs\n    B1 = 5000\n\n    # Test Case 2: irregular spacing with extra gaps at indices 50, 100, 150\n    n2 = 200\n    idx2 = np.arange(n2, dtype=np.int64)\n    positions2 = 1000 * idx2 + 5000 * (idx2 // 50)\n    p2 = 0.5\n    T_obs2 = 100000  # base pairs\n    B2 = 5000\n\n    # Test Case 3: small array, sparse matches, boundary observed value\n    n3 = 50\n    positions3 = 20000 * np.arange(n3, dtype=np.int64)\n    p3 = 0.1\n    T_obs3 = 0  # base pairs\n    B3 = 5000\n\n    # Test Case 4: large gaps at 75, 150, 225; heterogeneous probabilities\n    n4 = 300\n    idx4 = np.arange(n4, dtype=np.int64)\n    positions4 = 500 * idx4 + 20000 * (idx4 // 75)\n    p4 = 0.05 + 0.45 * (idx4.astype(float) / (n4 - 1))\n    T_obs4 = 50000  # base pairs\n    B4 = 5000\n\n    test_cases = [\n        (positions1, p1, T_obs1, B1),\n        (positions2, p2, T_obs2, B2),\n        (positions3, p3, T_obs3, B3),\n        (positions4, p4, T_obs4, B4),\n    ]\n\n    results = []\n    for positions, probs, T_obs, B in test_cases:\n        pval = monte_carlo_pvalue(positions, probs, T_obs, B, rng)\n        results.append(pval)\n\n    # Final print statement in the exact required format, rounded to 6 decimals.\n    formatted = \"[\" + \",\".join(f\"{r:.6f}\" for r in results) + \"]\"\n    print(formatted)\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}