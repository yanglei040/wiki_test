{
    "hands_on_practices": [
        {
            "introduction": "Bayesian inference is exceptionally powerful for interpreting diagnostic tests, a common task in bioinformatics. This exercise explores a classic scenario: a computational tool flags a protein as potentially \"prion-like\". By using the classifier's known accuracy and the base rate of prion proteins, you will apply Bayes' theorem to find the actual probability that a flagged protein is a true prion. This practice  is fundamental for learning how to correctly weigh new evidence against prior knowledge, a core skill in avoiding common statistical fallacies.",
            "id": "2400337",
            "problem": "A bioinformatics pipeline screens a large eukaryotic proteome to identify prion-like proteins. For each protein, a binary classifier outputs either \"flag\" or \"no flag.\" Let $\\text{prion}$ denote the event that a protein is truly prion-like by ground truth, and let $\\text{flag}$ denote the event that the classifier flags the protein. The classifier's true positive rate (TPR) is $0.80$, meaning $P(\\text{flag}\\mid \\text{prion})=0.80$. The classifier's false positive rate (FPR) is $0.10$, meaning $P(\\text{flag}\\mid \\neg \\text{prion})=0.10$. The base rate (prevalence) of prion-like proteins in this proteome is $P(\\text{prion})=0.01$. A randomly selected protein is flagged by the classifier.\n\nWhat is the posterior probability $P(\\text{prion}\\mid \\text{flag})$? Provide your answer as an exact fraction.",
            "solution": "The problem requires the calculation of a posterior probability, $P(\\text{prion}\\mid \\text{flag})$, which is the probability that a protein is truly prion-like given that it has been flagged by a classifier. This is a standard application of Bayes' theorem. The problem is well-posed and provides all necessary information for a direct calculation.\n\nLet us define the events as follows:\n- $\\text{prion}$: The event that a randomly selected protein is truly prion-like.\n- $\\neg \\text{prion}$: The event that a randomly selected protein is not prion-like.\n- $\\text{flag}$: The event that the classifier flags the protein.\n\nFrom the problem statement, we are given the following probabilities:\n- The prior probability (prevalence) of a protein being prion-like: $P(\\text{prion}) = 0.01$.\n- The conditional probability of a flag given that the protein is prion-like (True Positive Rate): $P(\\text{flag}\\mid \\text{prion}) = 0.80$.\n- The conditional probability of a flag given that the protein is not prion-like (False Positive Rate): $P(\\text{flag}\\mid \\neg \\text{prion}) = 0.10$.\n\nBayes' theorem states:\n$$\nP(\\text{prion}\\mid \\text{flag}) = \\frac{P(\\text{flag}\\mid \\text{prion}) P(\\text{prion})}{P(\\text{flag})}\n$$\nThe denominator, $P(\\text{flag})$, is the marginal probability of a protein being flagged. This probability is calculated using the law of total probability, summing over the complete and disjoint set of events $\\{\\text{prion}, \\neg \\text{prion}\\}$:\n$$\nP(\\text{flag}) = P(\\text{flag}\\mid \\text{prion}) P(\\text{prion}) + P(\\text{flag}\\mid \\neg \\text{prion}) P(\\neg \\text{prion})\n$$\nFirst, we must determine the probability of a protein not being prion-like, $P(\\neg \\text{prion})$. Since this is the complement of the event $\\text{prion}$, its probability is:\n$$\nP(\\neg \\text{prion}) = 1 - P(\\text{prion}) = 1 - 0.01 = 0.99\n$$\nNow, we can substitute the known values into the expression for $P(\\text{flag})$:\n$$\nP(\\text{flag}) = (0.80)(0.01) + (0.10)(0.99)\n$$\n$$\nP(\\text{flag}) = 0.008 + 0.099 = 0.107\n$$\nWith the value of $P(\\text{flag})$ computed, we can now return to Bayes' theorem to find the posterior probability $P(\\text{prion}\\mid \\text{flag})$. The numerator is the product of the likelihood and the prior:\n$$\nP(\\text{flag}\\mid \\text{prion}) P(\\text{prion}) = (0.80)(0.01) = 0.008\n$$\nTherefore, the posterior probability is:\n$$\nP(\\text{prion}\\mid \\text{flag}) = \\frac{0.008}{0.107}\n$$\nThe problem requires the answer to be an exact fraction. We convert the decimal values to their fractional equivalents to simplify the expression:\n$$\nP(\\text{prion}\\mid \\text{flag}) = \\frac{\\frac{8}{1000}}{\\frac{107}{1000}}\n$$\nThis simplifies to:\n$$\nP(\\text{prion}\\mid \\text{flag}) = \\frac{8}{107}\n$$\nThe number $107$ is a prime number, and it does not divide $8$. Thus, the fraction $\\frac{8}{107}$ is in its simplest form. This is the exact posterior probability that a protein is prion-like, given that it was flagged by the classifier.",
            "answer": "$$\\boxed{\\frac{8}{107}}$$"
        },
        {
            "introduction": "One of the central tasks in science is estimating the value of an unknown parameter. This problem  puts you in the role of a medical statistician evaluating a new surgical procedure with an unknown success rate, $p$. Starting from a position of maximum uncertainty (a uniform prior), you will use the results of the first clinical trials to update your belief about $p$ and calculate a new central estimate. This exercise elegantly demonstrates the process of Bayesian learning: combining a prior state of knowledge with observed data to form a more informed posterior belief.",
            "id": "1923968",
            "problem": "A new, high-risk surgical procedure is being developed for a condition that was previously considered untreatable. The true probability of success for this procedure, denoted by $p$, is unknown. Before conducting any clinical trials, medical researchers hold no preconceived bias about this probability, and thus consider every possible value of $p$ in the interval $[0, 1]$ to be equally likely.\n\nThe procedure is then attempted on $n$ different patients. In every one of these $n$ independent trials, the procedure fails to achieve a successful outcome.\n\nBased on this observed data of zero successes in $n$ trials, an updated belief about the success probability $p$ is formed. A medical statistician decides to summarize this updated belief by calculating a central value, $p_{med}$. This value is defined such that, given the observed data, it is equally probable for the true success rate $p$ to be less than or equal to $p_{med}$ as it is for it to be greater than $p_{med}$.\n\nFind a closed-form analytic expression for $p_{med}$ in terms of $n$.",
            "solution": "Let $p$ denote the success probability. The prior belief is uniform on $[0,1]$, which is the $\\operatorname{Beta}(1,1)$ prior with density $\\pi(p)=1$ for $p\\in[0,1]$.\n\nWe observe $n$ independent Bernoulli trials with $k=0$ successes. The likelihood is\n$$\nL(p\\mid \\text{data}) \\propto p^{k}(1-p)^{n-k}=(1-p)^{n}.\n$$\nBy Bayesâ€™ theorem, the posterior is proportional to prior times likelihood:\n$$\n\\pi(p\\mid \\text{data}) \\propto \\pi(p)L(p\\mid \\text{data}) \\propto (1-p)^{n}, \\quad 0\\leq p\\leq 1.\n$$\nThis is a $\\operatorname{Beta}(1,n+1)$ distribution. Normalizing explicitly,\n$$\n\\int_{0}^{1} (1-p)^{n}\\,dp=\\frac{1}{n+1},\n$$\nso the posterior density is\n$$\nf(p\\mid \\text{data})=(n+1)(1-p)^{n}, \\quad 0\\leq p\\leq 1.\n$$\nThe posterior cumulative distribution function is\n$$\nF(p)=\\int_{0}^{p} (n+1)(1-t)^{n}\\,dt.\n$$\nCompute the integral via $u=1-t$, $du=-dt$:\n$$\nF(p)=(n+1)\\int_{0}^{p} (1-t)^{n}\\,dt=(n+1)\\int_{1-p}^{1} u^{n}\\,du\n= (n+1)\\left[\\frac{u^{n+1}}{n+1}\\right]_{1-p}^{1}\n=1-(1-p)^{n+1}.\n$$\nThe posterior median $p_{med}$ satisfies $F(p_{med})=\\frac{1}{2}$, hence\n$$\n1-(1-p_{med})^{n+1}=\\frac{1}{2}\n\\;\\;\\Longrightarrow\\;\\;\n(1-p_{med})^{n+1}=\\frac{1}{2}.\n$$\nTaking the $(n+1)$-th root gives\n$$\n1-p_{med}=2^{-\\frac{1}{n+1}},\n$$\nso\n$$\np_{med}=1-2^{-\\frac{1}{n+1}}.\n$$\nThis expression is valid for all $n\\geq 0$ and, in particular, for $n\\geq 1$ as in the problem context.",
            "answer": "$$\\boxed{1-2^{-\\frac{1}{n+1}}}$$"
        },
        {
            "introduction": "After estimating parameters, the next logical step in many scientific analyses is to compare them. This problem  takes you into the world of differential gene expression, a cornerstone of modern biology. Given the posterior distributions for the expression levels of two genes, $\\mu_A$ and $\\mu_B$, your task is to calculate the probability that one is more expressed than the other. This practice illustrates a profound advantage of Bayesian methods: they provide full probability distributions for parameters, enabling us to directly answer nuanced comparative questions like $P(\\mu_A > \\mu_B \\mid \\text{data})$.",
            "id": "2400372",
            "problem": "A study of differential gene expression compares the true mean log-expression levels of two genes, gene A and gene B, across biological replicates. Let the true mean log-expression of gene A be denoted by $\\mu_A$ and that of gene B by $\\mu_B$. After a Bayesian analysis using conjugate priors and a Gaussian likelihood, the posterior distributions for these parameters are obtained as independent normal distributions: $P(\\mu_A \\mid \\text{data}) \\sim \\mathcal{N}(10, 1)$ and $P(\\mu_B \\mid \\text{data}) \\sim \\mathcal{N}(8, 1)$, where the first parameter is the mean and the second parameter is the variance. Assume that $\\mu_A$ and $\\mu_B$ are independent under the posterior.\n\nCompute the posterior probability that gene A is more expressed than gene B, that is, compute $P(\\mu_A > \\mu_B \\mid \\text{data})$. Round your answer to $4$ significant figures.",
            "solution": "The problem as stated is valid. It is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. We will proceed with the calculation.\n\nThe problem requires the computation of the posterior probability that the true mean log-expression of gene A, denoted $\\mu_A$, is greater than that of gene B, denoted $\\mu_B$. This probability is written as $P(\\mu_A > \\mu_B \\mid \\text{data})$.\n\nThe givens are the posterior distributions for $\\mu_A$ and $\\mu_B$:\n1.  The posterior distribution of $\\mu_A$ is a normal distribution with mean $10$ and variance $1$. We write this as $\\mu_A \\mid \\text{data} \\sim \\mathcal{N}(\\mu_{A,p}, \\sigma^2_{A,p})$, where $\\mu_{A,p} = 10$ and $\\sigma^2_{A,p} = 1$.\n2.  The posterior distribution of $\\mu_B$ is a normal distribution with mean $8$ and variance $1$. We write this as $\\mu_B \\mid \\text{data} \\sim \\mathcal{N}(\\mu_{B,p}, \\sigma^2_{B,p})$, where $\\mu_{B,p} = 8$ and $\\sigma^2_{B,p} = 1$.\n3.  The random variables $\\mu_A$ and $\\mu_B$ are independent under their posterior distributions.\n\nTo compute $P(\\mu_A > \\mu_B \\mid \\text{data})$, we can reformulate the inequality as $\\mu_A - \\mu_B > 0$. Let us define a new random variable $D = \\mu_A - \\mu_B$. The problem is now to compute $P(D > 0 \\mid \\text{data})$.\n\nA fundamental property of normal distributions states that a linear combination of independent normal random variables is also a normal random variable. Specifically, for independent random variables $X \\sim \\mathcal{N}(\\mu_X, \\sigma^2_X)$ and $Y \\sim \\mathcal{N}(\\mu_Y, \\sigma^2_Y)$, the variable $W = aX + bY$ is distributed as $W \\sim \\mathcal{N}(a\\mu_X + b\\mu_Y, a^2\\sigma^2_X + b^2\\sigma^2_Y)$.\n\nIn our case, $D = \\mu_A - \\mu_B$, which corresponds to setting $a=1$ and $b=-1$. The distribution of $D$ is therefore normal. We calculate its mean and variance.\n\nThe mean of $D$ is the difference of the means of $\\mu_A$ and $\\mu_B$:\n$$E[D] = E[\\mu_A] - E[\\mu_B] = \\mu_{A,p} - \\mu_{B,p} = 10 - 8 = 2$$\n\nThe variance of $D$ is the sum of the variances of $\\mu_A$ and $\\mu_B$, because they are independent:\n$$\\text{Var}(D) = \\text{Var}(\\mu_A - \\mu_B) = \\text{Var}(\\mu_A) + (-1)^2 \\text{Var}(\\mu_B) = \\sigma^2_{A,p} + \\sigma^2_{B,p} = 1 + 1 = 2$$\n\nThus, the distribution of the difference $D$ is $D \\mid \\text{data} \\sim \\mathcal{N}(2, 2)$. The mean is $E[D] = \\mu_D = 2$ and the variance is $\\text{Var}(D) = \\sigma^2_D = 2$. The standard deviation is $\\sigma_D = \\sqrt{2}$.\n\nWe must now compute $P(D > 0)$. To do this, we standardize the random variable $D$ to a standard normal variable $Z \\sim \\mathcal{N}(0, 1)$ using the transformation $Z = \\frac{D - \\mu_D}{\\sigma_D}$.\n$$P(D > 0) = P\\left(\\frac{D - \\mu_D}{\\sigma_D} > \\frac{0 - \\mu_D}{\\sigma_D}\\right)$$\nSubstituting the values for $\\mu_D$ and $\\sigma_D$:\n$$P(D > 0) = P\\left(Z > \\frac{0 - 2}{\\sqrt{2}}\\right) = P(Z > -\\sqrt{2})$$\nDue to the symmetry of the standard normal distribution, the probability $P(Z > -z)$ is equal to $P(Z  z)$. Therefore:\n$$P(Z > -\\sqrt{2}) = P(Z  \\sqrt{2})$$\nThis probability is the value of the cumulative distribution function (CDF) of the standard normal distribution, denoted $\\Phi(z)$, evaluated at $z = \\sqrt{2}$.\n$$P(\\mu_A > \\mu_B \\mid \\text{data}) = \\Phi(\\sqrt{2})$$\nThe numerical value of $\\sqrt{2}$ is approximately $1.41421356...$. Using a standard normal probability table or a computational tool, we find the value of $\\Phi(\\sqrt{2})$.\n$$\\Phi(\\sqrt{2}) \\approx \\Phi(1.4142) \\approx 0.92135039...$$\nThe problem requires the answer to be rounded to $4$ significant figures. The first four significant figures are $9$, $2$, $1$, and $3$. The fifth significant digit is $5$, which requires rounding up the fourth digit.\n$$0.92135... \\approx 0.9214$$\nThus, the posterior probability that gene A is more expressed than gene B is approximately $0.9214$.",
            "answer": "$$\\boxed{0.9214}$$"
        }
    ]
}