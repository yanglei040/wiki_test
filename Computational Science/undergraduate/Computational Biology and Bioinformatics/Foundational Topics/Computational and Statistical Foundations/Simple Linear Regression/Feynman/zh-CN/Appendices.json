{
    "hands_on_practices": [
        {
            "introduction": "简单线性回归是分析生物学数据中变量关系的基本工具。本练习将通过一个生物技术领域的经典问题——估算生物质得率系数（biomass yield coefficient）——来让你亲手实践线性回归。你将对几组代表不同实验情景的数据进行建模，这不仅能帮助你掌握如何拟合模型和解释斜率的生物学意义，还能让你直观地感受真实世界数据（包含噪声）与理想数据之间的差异。",
            "id": "2429490",
            "problem": "一系列独立的分批培养实验研究了最终生物量如何依赖于初始供应的葡萄糖。对于每次实验，在葡萄糖被完全消耗后，测量了初始葡萄糖浓度 $S_0$（单位为 $\\mathrm{g/L}$）和最终生物量浓度 $X_f$（单位为克干重/升，$\\mathrm{gDW/L}$）。假设存在加性扰动的线性关系，模型为 $X_f = \\beta_0 + \\beta_1 S_0 + \\varepsilon$，其中 $\\varepsilon$ 是一个零均值扰动。斜率 $\\beta_1$ 等于生物量产率系数 $Y_{X/S}$（单位为 $\\mathrm{gDW/g}$），截距 $\\beta_0$ 代表了不能归因于所供应葡萄糖的预先存在的生物量。\n\n对于下面的每个数据集，请确定能使观测值 $X_f$ 与模型预测值 $\\beta_0 + \\beta_1 S_0$ 之间的残差平方和最小化的直线的斜率参数 $\\beta_1$。以 $\\mathrm{gDW/g}$ 为单位表示每个斜率，并将每个结果四舍五入到小数点后恰好六位。不要输出单位，只输出数字。\n\n测试套件（每个数据集以一组数对 $(S_0, X_f)$ 的形式给出，其中 $S_0$ 的单位是 $\\mathrm{g/L}$，$X_f$ 的单位是 $\\mathrm{gDW/L}$）：\n- 数据集 A（一般情况）：\n$$\\{(0, 0.07), (2, 1.04), (4, 2.05), (6, 3.06), (8, 4.03)\\}$$\n- 数据集 B（零截距的无噪声比例关系）：\n$$\\{(0, 0.00), (1, 0.45), (2, 0.90), (3, 1.35), (4, 1.80)\\}$$\n- 数据集 C（输入范围窄且有小测量噪声）：\n$$\\{(1.9, 1.068), (2.0, 1.116), (2.1, 1.177), (2.2, 1.229), (2.3, 1.285)\\}$$\n- 数据集 D（具有两个不同点的最小样本量的边界情况）：\n$$\\{(5.0, 2.50), (10.0, 4.90)\\}$$\n\n您的程序应生成单行输出，其中包含分别为数据集 A、B、C 和 D 计算出的斜率，形式为一个用方括号括起来、不含空格的逗号分隔列表，例如 $[a,b,c,d]$，其中 $a$、$b$、$c$ 和 $d$ 是格式化为小数点后六位的计算斜率。",
            "solution": "问题陈述已经过严格验证，被认为是科学上合理、适定、客观且自洽的。它提出了数据分析中的一项标准任务，即简单线性回归，并将其应用于计算生物学中的一个真实场景。所需数据均已提供，且目标明确无误。因此，将提供一个完整的解决方案。\n\n该问题要求确定形式为 $X_f = \\beta_0 + \\beta_1 S_0 + \\varepsilon$ 的简单线性回归模型的斜率参数 $\\beta_1$。这需要对四个独立的数据集进行计算。指定的方法是最小化残差平方和，即普通最小二乘法（OLS）的原理。\n\n设自变量为 $x_i = S_{0,i}$，因变量为 $y_i = X_{f,i}$，共有一组 $n$ 个观测值。线性模型为 $\\hat{y}_i = \\beta_0 + \\beta_1 x_i$，其中 $\\hat{y}_i$ 是 $y_i$ 的预测值。目标是找到使残差平方和 (SSE) 最小化的参数 $\\beta_0$ 和 $\\beta_1$：\n$$SSE(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^{n} (y_i - (\\beta_0 + \\beta_1 x_i))^2$$\n为找到该函数的最小值，我们必须计算其关于 $\\beta_0$ 和 $\\beta_1$ 的偏导数，并令它们为零。这将得到正规方程。\n\n关于 $\\beta_0$ 的偏导数为：\n$$\\frac{\\partial SSE}{\\partial \\beta_0} = \\sum_{i=1}^{n} 2(y_i - \\beta_0 - \\beta_1 x_i)(-1) = -2 \\left( \\sum_{i=1}^{n} y_i - n\\beta_0 - \\beta_1 \\sum_{i=1}^{n} x_i \\right) = 0$$\n这可以简化为第一个正规方程：\n$$n\\beta_0 + \\beta_1 \\sum_{i=1}^{n} x_i = \\sum_{i=1}^{n} y_i$$\n\n关于 $\\beta_1$ 的偏导数为：\n$$\\frac{\\partial SSE}{\\partial \\beta_1} = \\sum_{i=1}^{n} 2(y_i - \\beta_0 - \\beta_1 x_i)(-x_i) = -2 \\left( \\sum_{i=1}^{n} x_i y_i - \\beta_0 \\sum_{i=1}^{n} x_i - \\beta_1 \\sum_{i=1}^{n} x_i^2 \\right) = 0$$\n这可以简化为第二个正规方程：\n$$\\beta_0 \\sum_{i=1}^{n} x_i + \\beta_1 \\sum_{i=1}^{n} x_i^2 = \\sum_{i=1}^{n} x_i y_i$$\n\n现在我们得到了一个包含两个未知数 $\\beta_0$ 和 $\\beta_1$ 的二元线性方程组。问题特别要求的是斜率 $\\beta_1$。我们可以解这个方程组来求得 $\\beta_1$。从第一个正规方程，我们用样本均值 $\\bar{x} = \\frac{1}{n}\\sum x_i$ 和 $\\bar{y} = \\frac{1}{n}\\sum y_i$ 来表示 $\\beta_0$：\n$$\\beta_0 = \\frac{1}{n} \\left( \\sum_{i=1}^{n} y_i - \\beta_1 \\sum_{i=1}^{n} x_i \\right) = \\bar{y} - \\beta_1 \\bar{x}$$\n将这个关于 $\\beta_0$ 的表达式代入第二个正规方程，得到：\n$$(\\bar{y} - \\beta_1 \\bar{x}) \\sum_{i=1}^{n} x_i + \\beta_1 \\sum_{i=1}^{n} x_i^2 = \\sum_{i=1}^{n} x_i y_i$$\n解出 $\\beta_1$：\n$$\\beta_1 \\left( \\sum_{i=1}^{n} x_i^2 - \\bar{x} \\sum_{i=1}^{n} x_i \\right) = \\sum_{i=1}^{n} x_i y_i - \\bar{y} \\sum_{i=1}^{n} x_i$$\n$$\\beta_1 = \\frac{\\sum_{i=1}^{n} x_i y_i - \\bar{y} \\sum_{i=1}^{n} x_i}{\\sum_{i=1}^{n} x_i^2 - \\bar{x} \\sum_{i=1}^{n} x_i} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}$$\n由此推导出的一个常用计算公式是：\n$$\\beta_1 = \\frac{n \\sum_{i=1}^{n} x_i y_i - (\\sum_{i=1}^{n} x_i)(\\sum_{i=1}^{n} y_i)}{n \\sum_{i=1}^{n} x_i^2 - (\\sum_{i=1}^{n} x_i)^2}$$\n该公式将被应用于每个数据集。\n\n**数据集 A：**\n$x = \\{0, 2, 4, 6, 8\\}$, $y = \\{0.07, 1.04, 2.05, 3.06, 4.03\\}$。这里，$n=5$。\n$\\sum x_i = 20$, $\\sum y_i = 10.25$, $\\sum x_i^2 = 120$, $\\sum x_i y_i = 60.88$。\n$$\\beta_1 = \\frac{5(60.88) - (20)(10.25)}{5(120) - (20)^2} = \\frac{304.4 - 205}{600 - 400} = \\frac{99.4}{200} = 0.497$$\n\n**数据集 B：**\n$x = \\{0, 1, 2, 3, 4\\}$, $y = \\{0.00, 0.45, 0.90, 1.35, 1.80\\}$。这里，$n=5$。\n$\\sum x_i = 10$, $\\sum y_i = 4.5$, $\\sum x_i^2 = 30$, $\\sum x_i y_i = 13.5$。\n$$\\beta_1 = \\frac{5(13.5) - (10)(4.5)}{5(30) - (10)^2} = \\frac{67.5 - 45}{150 - 100} = \\frac{22.5}{50} = 0.45$$\n\n**数据集 C：**\n$x = \\{1.9, 2.0, 2.1, 2.2, 2.3\\}$, $y = \\{1.068, 1.116, 1.177, 1.229, 1.285\\}$。这里，$n=5$。\n$\\sum x_i = 10.5$, $\\sum y_i = 5.875$, $\\sum x_i^2 = 22.15$, $\\sum x_i y_i = 12.3922$。\n$$\\beta_1 = \\frac{5(12.3922) - (10.5)(5.875)}{5(22.15) - (10.5)^2} = \\frac{61.961 - 61.6875}{110.75 - 110.25} = \\frac{0.2735}{0.5} = 0.547$$\n\n**数据集 D：**\n$x = \\{5.0, 10.0\\}$, $y = \\{2.50, 4.90\\}$。这里，$n=2$。\n对于两个点，OLS 斜率就是连接它们的直线的斜率：\n$$\\beta_1 = \\frac{y_2 - y_1}{x_2 - x_1} = \\frac{4.90 - 2.50}{10.0 - 5.0} = \\frac{2.4}{5.0} = 0.48$$\n使用通用公式：\n$\\sum x_i = 15.0$, $\\sum y_i = 7.40$, $\\sum x_i^2 = 125.0$, $\\sum x_i y_i = 61.5$。\n$$\\beta_1 = \\frac{2(61.5) - (15.0)(7.40)}{2(125.0) - (15.0)^2} = \\frac{123 - 111}{250 - 225} = \\frac{12}{25} = 0.48$$\n\n为数据集 A、B、C 和 D 计算出的斜率分别是 $0.497$、$0.45$、$0.547$ 和 $0.48$。这些值必须格式化为六位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import linregress\n\ndef solve():\n    \"\"\"\n    Calculates the slope of a simple linear regression for several datasets\n    representing biomass yield experiments.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple of two lists: (S0 values, Xf values).\n    test_cases = [\n        # Dataset A (general case)\n        ([0, 2, 4, 6, 8], [0.07, 1.04, 2.05, 3.06, 4.03]),\n        # Dataset B (noise-free proportional relationship with zero intercept)\n        ([0, 1, 2, 3, 4], [0.00, 0.45, 0.90, 1.35, 1.80]),\n        # Dataset C (narrow input range with small measurement noise)\n        ([1.9, 2.0, 2.1, 2.2, 2.3], [1.068, 1.116, 1.177, 1.229, 1.285]),\n        # Dataset D (boundary case with the minimal sample size of two distinct points)\n        ([5.0, 10.0], [2.50, 4.90]),\n    ]\n\n    results = []\n    for s0_values, xf_values in test_cases:\n        # The problem asks to find the slope parameter (beta_1) of the line\n        # that minimizes the sum of squared residuals. This is precisely what\n        # scipy.stats.linregress calculates.\n        \n        # Convert lists to numpy arrays for the regression function.\n        x = np.array(s0_values)\n        y = np.array(xf_values)\n        \n        # Perform the linear regression.\n        # The result object contains 'slope', 'intercept', 'rvalue', 'pvalue', 'stderr'.\n        # We only need the slope.\n        regression_result = linregress(x, y)\n        slope = regression_result.slope\n        \n        # Format the result to exactly six digits after the decimal point.\n        formatted_slope = f\"{slope:.6f}\"\n        results.append(formatted_slope)\n\n    # Final print statement in the exact required format: [a,b,c,d]\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在数据分析中，一个看似微不足道的数据点有时可能对整个模型的结论产生决定性的影响。本练习将通过一个具体的计算任务，向你展示“影响力点”（influential points）的概念。你将看到，仅仅在数据集中增加一个点，就可能使回归斜率的$p$值发生巨大变化，甚至跨过$0.05$这一传统的统计显著性门槛，从而体会到数据可视化和诊断检查在回归分析中的重要性。",
            "id": "2429452",
            "problem": "您正在一项药物基因组学分析中，对信使核糖核酸（mRNA）表达与下游定量响应之间的线性关联进行建模。请考虑以下简化的、完全指定的场景，该场景分离出普通最小二乘法线性回归的数学原理，同时在计算生物学和生物信息学领域保持科学上的现实性。\n\n背景与数据生成：\n- 预测变量 $x$ 代表经过 $\\log_2$ 变换的基因表达（单位为 $\\log_2(\\text{TPM})$，无量纲）。基础样本包含 $n = 10$ 个细胞系，其预测变量值为\n  $$\n  x = (-4.5,-3.5,-2.5,-1.5,-0.5,0.5,1.5,2.5,3.5,4.5).\n  $$\n- 响应变量 $y$ 代表标准化的蛋白质丰度 $z$-分数（无量纲，因此可以为负值）。为确保一个可控、可复现的信噪比，以产生一个临界关联，定义\n  $$\n  z_i = x_i^2 - \\overline{x^2}, \\quad \\text{其中} \\quad \\overline{x^2} = \\frac{1}{n}\\sum_{i=1}^n x_i^2,\n  $$\n  并构建基础响应为\n  $$\n  y_i = x_i + \\beta z_i \\quad \\text{其中} \\quad \\beta = 0.5175.\n  $$\n  该构造产生了一个线性趋势 $y \\approx x$，并带有结构化的正交噪声（因为 $\\sum_{i=1}^n x_i z_i = 0$），在经典的'正态误差模型'下，其产生的斜率具有临界显著性。\n\n统计模型与推断目标：\n- 假设采用标准的带截距项的简单线性回归模型，\n  $$\n  y_i = \\alpha + \\beta_1 x_i + \\varepsilon_i,\n  $$\n  其中误差 $\\varepsilon_i$ 是独立同分布的高斯随机变量，均值为 $0$，方差为 $\\sigma^2$（同方差正态误差）。在该模型下，普通最小二乘法斜率估计量 $\\widehat{\\beta}_1$ 具有一个 Student's $t$ 统计量，其双侧 $p$ 值可量化反对原假设 $H_0:\\beta_1=0$ 的证据。\n\n任务：\n- 根据第一性原理实现带截距项的普通最小二乘法拟合，为每个指定的数据集计算在同方差正态误差模型下斜率的双侧 $p$ 值。您必须使用残差方差估计和 $(n-2)$ 的自由度来推导 $t$ 统计量，然后通过 Student's $t$ 分布的累积分布函数计算双侧 $p$ 值。\n\n测试套件：\n为以下三个数据集计算并报告斜率的双侧 $p$ 值：\n1. 基础数据集 ($n=10$): 预测变量 $x$ 如上所述；响应变量 $y$ 由 $y_i = x_i + \\beta z_i$ 定义，其中 $\\beta = 0.5175$，$z_i = x_i^2 - \\overline{x^2}$。\n2. 基础数据集加一个与趋势一致的影响点 ($n=11$): 将数据点 $(x_{\\text{new}}, y_{\\text{new}}) = (6.0, 6.0)$ 添加到基础数据集中。这模拟了一个与假设的生物学关系相符的高杠杆率样本。\n3. 基础数据集加一个与趋势相反的影响点 ($n=11$): 将数据点 $(x_{\\text{new}}, y_{\\text{new}}) = (6.0, -6.0)$ 添加到基础数据集中。这模拟了一个与假设的生物学关系相矛盾的高杠杆率样本。\n\n需展示的科学目标：\n- 具体展示添加一个影响数据点如何能将双侧斜率 $p$ 值从一个接近 $0.06$ 的临界值变为一个接近 $0.04$ 的值（跨越传统的 $0.05$ 阈值），以及一个相悖的影响点如何能使 $p$ 值朝相反方向移动。\n\n答案格式：\n- 对于每个数据集，输出斜率的双侧 $p$ 值，结果为保留两位小数的十进制数（无单位）。\n- 您的程序应生成单行输出，其中包含三个结果，以逗号分隔并用方括号括起（例如 $[0.06,0.04,0.23]$）。",
            "solution": "问题陈述已经过验证，被认为是有效的。它具有科学依据，定义明确，客观，并包含了使用普通最小二乘法线性回归的既定原则推导唯一、有意义解所需的所有信息。所提供的背景和数据生成方案尽管是合成的，但其构造旨在展示一个与计算生物学和生物信息学相关的、具体且可验证的统计现象。\n\n任务是为三个不同数据集，计算简单线性回归模型中斜率系数的双侧 $p$ 值。该分析将从第一性原理出发，并与经典的“正态误差模型”保持一致。\n\n简单线性回归模型由下式给出：\n$$\ny_i = \\alpha + \\beta_1 x_i + \\varepsilon_i\n$$\n其中 $y_i$ 是响应变量，$x_i$ 是预测变量，$\\alpha$ 是截距，$\\beta_1$ 是斜率，$\\varepsilon_i$ 是来自均值为 $0$、方差为 $\\sigma^2$ 的正态分布的独立同分布随机误差，即 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。\n\n普通最小二乘法（OLS）旨在最小化残差平方和（SSE），$\\text{SSE} = \\sum_{i=1}^n (y_i - (\\widehat{\\alpha} + \\widehat{\\beta}_1 x_i))^2$。斜率 $\\widehat{\\beta}_1$ 和截距 $\\widehat{\\alpha}$ 的 OLS 估计量由下式给出：\n$$\n\\widehat{\\beta}_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\n$$\n$$\n\\widehat{\\alpha} = \\bar{y} - \\widehat{\\beta}_1 \\bar{x}\n$$\n其中 $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$ 和 $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^n y_i$ 是样本均值。\n\n为了对斜率进行假设检验，我们必须首先估计误差的方差 $\\sigma^2$。$\\sigma^2$ 的无偏估计量是均方误差（或残差方差）$\\widehat{\\sigma}^2$，由残差 $e_i = y_i - (\\widehat{\\alpha} + \\widehat{\\beta}_1 x_i)$ 计算得出：\n$$\n\\widehat{\\sigma}^2 = \\frac{\\sum_{i=1}^n e_i^2}{n-2} = \\frac{\\text{SSE}}{n-2}\n$$\n分母 $n-2$ 表示自由度，因为数据中估计了两个参数（$\\alpha$ 和 $\\beta_1$）。\n\n斜率估计量的标准误 $\\text{SE}(\\widehat{\\beta}_1)$ 量化了其抽样变异性：\n$$\n\\text{SE}(\\widehat{\\beta}_1) = \\sqrt{\\frac{\\widehat{\\sigma}^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2}}\n$$\n\n主要任务是检验原假设 $H_0: \\beta_1 = 0$ 与备择假设 $H_a: \\beta_1 \\neq 0$。这通过使用一个 $t$ 统计量来完成，在原假设下，该统计量服从自由度为 $n-2$ 的 Student's $t$ 分布。$t$ 统计量计算如下：\n$$\nt = \\frac{\\widehat{\\beta}_1 - 0}{\\text{SE}(\\widehat{\\beta}_1)} = \\frac{\\widehat{\\beta}_1}{\\text{SE}(\\widehat{\\beta}_1)}\n$$\n\n双侧 $p$ 值是在假设原假设为真的情况下，观测到至少与计算出的检验统计量一样极端的统计量的概率。它由下式给出：\n$$\np = 2 \\times P(T_{n-2} \\ge |t|)\n$$\n其中 $T_{n-2}$ 是一个服从自由度为 $n-2$ 的 Student's $t$ 分布的随机变量。该概率可以使用 $t$ 分布的累积分布函数（CDF）$F_{n-2}$ 计算：\n$$\np = 2 \\times (1 - F_{n-2}(|t|))\n$$\n\n每个数据集的计算步骤如下：\n1.  对于一组给定的 $n$ 个数据点 $(x_i, y_i)$，计算样本均值 $\\bar{x}$ 和 $\\bar{y}$。\n2.  计算 OLS 斜率估计量 $\\widehat{\\beta}_1$ 和截距估计量 $\\widehat{\\alpha}$。\n3.  确定拟合值 $\\widehat{y}_i = \\widehat{\\alpha} + \\widehat{\\beta}_1 x_i$ 和残差 $e_i = y_i - \\widehat{y}_i$。\n4.  计算残差平方和 $\\text{SSE} = \\sum_{i=1}^n e_i^2$ 和残差方差 $\\widehat{\\sigma}^2 = \\text{SSE} / (n-2)$。\n5.  计算斜率的标准误 $\\text{SE}(\\widehat{\\beta}_1)$。\n6.  计算斜率的 $t$ 统计量。\n7.  使用自由度为 $n-2$ 的 Student's $t$ 分布确定双侧 $p$ 值。\n\n该程序将应用于指定的三个数据集。\n\n数据集1（基础数据集）：\n-   $n = 10$.\n-   预测变量 $x = (-4.5, -3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3.5, 4.5)$.\n-   响应变量 $y_i = x_i + \\beta z_i$，其中 $\\beta = 0.5175$，$z_i = x_i^2 - \\overline{x^2}$。\n\n数据集2（与趋势一致的影响点）：\n-   $n = 11$.\n-   数据由基础数据集加上点 $(x_{\\text{new}}, y_{\\text{new}}) = (6.0, 6.0)$ 组成。\n\n数据集3（与趋势相反的影响点）：\n-   $n = 11$.\n-   数据由基础数据集加上点 $(x_{\\text{new}}, y_{\\text{new}}) = (6.0, -6.0)$ 组成。\n\n实现将使用数值库来稳健地执行这些计算并推导出所需的 $p$ 值。最终结果将展示统计显著性对高杠杆率数据点的敏感性，这是数据分析中的一个关键概念。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Solves the simple linear regression problem for three specified datasets.\n    \"\"\"\n\n    def calculate_p_value(x: np.ndarray, y: np.ndarray) -> float:\n        \"\"\"\n        Calculates the two-sided p-value for the slope of a simple linear regression\n        from first principles.\n        \n        Args:\n            x: A numpy array of predictor values.\n            y: A numpy array of response values.\n            \n        Returns:\n            The two-sided p-value for the OLS slope coefficient.\n        \"\"\"\n        # 1. Get sample size n\n        n = len(x)\n        if n <= 2:\n            return np.nan # p-value is undefined for n <= 2\n\n        # 2. Calculate sample means\n        x_bar = np.mean(x)\n        y_bar = np.mean(y)\n\n        # 3. Calculate OLS slope estimate (beta_1_hat)\n        # Numerator: sum of products of deviations\n        sp_xy = np.sum((x - x_bar) * (y - y_bar))\n        # Denominator: sum of squared deviations for x\n        ss_x = np.sum((x - x_bar)**2)\n        \n        beta_1_hat = sp_xy / ss_x\n        \n        # 4. Calculate OLS intercept estimate (alpha_hat)\n        alpha_hat = y_bar - beta_1_hat * x_bar\n        \n        # 5. Calculate fitted values and residuals\n        y_hat = alpha_hat + beta_1_hat * x\n        residuals = y - y_hat\n        \n        # 6. Calculate Residual Sum of Squares (SSE) and degrees of freedom\n        sse = np.sum(residuals**2)\n        df = n - 2\n        \n        # 7. Calculate residual variance (sigma_hat_squared)\n        sigma2_hat = sse / df\n        \n        # 8. Calculate standard error of the slope\n        se_beta_1 = np.sqrt(sigma2_hat / ss_x)\n        \n        # 9. Calculate the t-statistic\n        if se_beta_1 == 0:\n            return 0.0 if beta_1_hat != 0 else 1.0\n        t_stat = beta_1_hat / se_beta_1\n        \n        # 10. Calculate the two-sided p-value\n        # Using survival function (1 - CDF) for better precision in the tail\n        p_value = 2 * t.sf(np.abs(t_stat), df)\n        \n        return p_value\n\n    # --- Define base data as per the problem ---\n    x_base = np.array([-4.5, -3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3.5, 4.5])\n    n_base = len(x_base)\n    beta_gen = 0.5175\n    \n    # Generate the base response y\n    x_sq_bar = np.mean(x_base**2)\n    z = x_base**2 - x_sq_bar\n    y_base = x_base + beta_gen * z\n\n    # --- Define the three test cases ---\n    test_cases = [\n        # Case 1: Base dataset\n        (x_base, y_base),\n        # Case 2: Base dataset + aligned influential point\n        (np.append(x_base, 6.0), np.append(y_base, 6.0)),\n        # Case 3: Base dataset + opposing influential point\n        (np.append(x_base, 6.0), np.append(y_base, -6.0))\n    ]\n\n    results = []\n    for x_data, y_data in test_cases:\n        p_val = calculate_p_value(x_data, y_data)\n        # Format to two decimal places as a string\n        results.append(f\"{p_val:.2f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "经典的线性回归依赖于关于数据分布的较强假设（如正态性和同方差性）来计算置信区间。然而，自助法（Bootstrapping）作为一种强大的、计算密集型的现代方法，提供了一种无需这些强假设的稳健替代方案。在本练习中，你将亲手实现非参数自助法，来估计基因的GC含量与表达水平之间关系的斜率的不确定性，从而掌握一种在现代生物信息学中广泛应用的核心重采样技术。",
            "id": "2429424",
            "problem": "给定您多个独立的成对观测数据集，这些数据集代表了来自单一生物体的不同蛋白质编码基因的鸟嘌呤-胞嘧啶含量（GC含量）和标准化基因表达水平。对于每个数据集，考虑简单线性回归模型 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$，其中 $x_i$ 表示GC含量（以区间 $[0,1]$ 内的分数表示），$y_i$ 表示以2为底的对数TPM（每百万转录本）标度上的标准化表达水平，$\\beta_0$ 是截距，$\\beta_1$ 是斜率，$\\varepsilon_i$ 是观测值 $i$ 的一个未观测到的残差。斜率 $\\beta_1$ 定义为在该模型下最小化残差平方和的普通最小二乘系数。\n\n您的任务是使用成对观测值的非参数自举重采样方法，为每个数据集的斜率 $\\beta_1$ 构建置信水平为 $0.95$ 的双侧置信区间。对于每个数据集，将观测对 $\\{(x_i,y_i)\\}_{i=1}^n$ 视为定义了一个经验分布，该分布在每个观测对上赋予 $1/n$ 的概率质量，从这些观测对中有放回地抽取 $B$ 个大小为 $n$ 的自举样本，计算每个自举样本的斜率估计值，然后报告自举斜率分布的百分位数区间，其下端点位于概率 $0.025$ 处，上端点位于概率 $0.975$ 处。为确保每个数据集的可复现性，请使用提供的伪随机种子。\n\n测试套件（四个不同的数据集）。在每种情况下，$x$ 表示GC含量（分数），$y$ 表示以2为底的对数TPM。对于每种情况，报告 $\\beta_1$ 的 $0.95$ 置信区间的两个端点。\n\n- 情况1（普遍递增关联）：\n  - $x$: $0.34, 0.36, 0.40, 0.41, 0.43, 0.45, 0.48, 0.50, 0.52, 0.55, 0.57, 0.60$\n  - $y$: $4.10, 4.00, 4.30, 4.50, 4.60, 4.90, 5.00, 5.30, 5.40, 5.80, 6.00, 6.20$\n  - 置信水平: $0.95$；自举复制次数: $B=8000$；种子: $13579$。\n\n- 情况2（近零关联）：\n  - $x$: $0.31, 0.33, 0.35, 0.38, 0.40, 0.42, 0.44, 0.47, 0.49, 0.51, 0.53, 0.56$\n  - $y$: $5.10, 4.95, 5.05, 5.00, 5.02, 4.98, 5.01, 5.04, 4.96, 5.03, 4.97, 5.00$\n  - 置信水平: $0.95$；自举复制次数: $B=8000$；种子: $24680$。\n\n- 情况3（普遍递减关联）：\n  - $x$: $0.30, 0.34, 0.37, 0.39, 0.41, 0.44, 0.46, 0.49, 0.51, 0.54, 0.58, 0.61$\n  - $y$: $7.00, 6.80, 6.60, 6.50, 6.30, 6.10, 6.00, 5.90, 5.70, 5.50, 5.30, 5.20$\n  - 置信水平: $0.95$；自举复制次数: $B=8000$；种子: $11235$。\n\n- 情况4（较小样本，递增关联）：\n  - $x$: $0.32, 0.36, 0.40, 0.45, 0.50, 0.54, 0.58, 0.62$\n  - $y$: $3.80, 3.95, 4.10, 4.30, 4.45, 4.60, 4.80, 4.95$\n  - 置信水平: $0.95$；自举复制次数: $B=8000$；种子: $98765$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素对应上述顺序的一个测试用例，并且本身是一个包含置信区间下端点和上端点的双元素列表。每个数值端点必须使用标准四舍五入到小数点后六位。例如，一个有效的输出形状是 $[[\\ell_1,u_1],[\\ell_2,u_2],[\\ell_3,u_3],[\\ell_4,u_4]]$，其中 $\\ell_k$ 和 $u_k$ 分别表示情况 $k$ 的下端点和上端点。",
            "solution": "在尝试任何解决方案之前，我们对问题陈述进行了严格的验证。\n\n**步骤1：提取已知条件**\n- **模型**：形式为 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ 的简单线性回归。\n- **自变量 ($x_i$)**：鸟嘌呤-胞嘧啶含量（GC含量），一个在 $[0,1]$ 区间内的分数。\n- **因变量 ($y_i$)**：标准化的基因表达水平，在以2为底的对数TPM（每百万转录本）标度上。\n- **目标参数**：斜率系数 $\\beta_1$，使用普通最小二乘法（OLS）估计。\n- **任务**：对于四个独立的成对观测数据集中的每一个，为 $\\beta_1$ 构建一个置信水平为 $0.95$ 的双侧置信区间。\n- **方法**：成对观测值 $\\{(x_i, y_i)\\}$ 的非参数自举重采样。置信区间将是百分位数区间。\n- **步骤**：\n    1. 对于每个包含 $n$ 对观测值的数据集，有放回地抽取 $B$ 个大小为 $n$ 的自举样本。\n    2. 为每个自举样本计算OLS斜率估计值 $\\hat{\\beta}_1^*$。\n    3. 从得到的自举斜率分布的分位数构建置信区间。下端点是 $0.025$ 分位数，上端点是 $0.975$ 分位数。\n- **特定情况参数**：\n    - **情况1**：提供了数据数组 $x$ 和 $y$。$B=8000$ 次自举复制。用于伪随机数生成的种子是 $13579$。\n    - **情况2**：提供了数据数组 $x$ 和 $y$。$B=8000$ 次自举复制。种子是 $24680$。\n    - **情况3**：提供了数据数组 $x$ 和 $y$。$B=8000$ 次自举复制。种子是 $11235$。\n    - **情况4**：提供了数据数组 $x$ 和 $y$。$B=8000$ 次自举复制。种子是 $98765$。\n- **输出格式**：包含一个双元素列表的列表的单行，`[[\\ell_1,u_1],[\\ell_2,u_2],[\\ell_3,u_3],[\\ell_4,u_4]]`，其中 $\\ell_k$ 和 $u_k$ 是情况 $k$ 的下端点和上端点，四舍五入到六位小数。\n\n**步骤2：验证**\n- **科学依据**：该问题具有充分的科学依据。研究GC含量等基因组特征与基因表达之间的关系是计算生物学和生物信息学中的一个基本课题。简单线性回归和非参数自举是用于此类分析的标准、稳健的统计方法。该问题不含伪科学内容。\n- **良置性**：该问题是良置的。它清晰地定义了输入（数据、参数）、统计流程（OLS、百分位数自举）和所需的输出格式。提供种子确保了解决方案的唯一性和可复现性。\n- **客观性**：问题以精确、客观和定量的术语陈述。没有主观或模糊的陈述。\n- **完整性与一致性**：问题是自包含的。每种情况所需的所有数据、模型和参数（样本大小 $n$、复制次数 $B$、置信水平 $1-\\alpha$ 以及随机种子）都已明确提供。不存在内部矛盾。\n\n**步骤3：结论**\n该问题被判定为**有效**。它是一项应用于现实生物学背景的标准统计任务，定义严谨，并包含了求解所需的所有信息。因此，我们可以继续进行。\n\n**求解方法**\n\n目标是为简单线性回归模型的斜率参数 $\\beta_1$ 构建一个 $95\\%$ 的置信区间。指定的方法是非参数自举，该方法对误差项 $\\varepsilon_i$ 的分布没有做出强假设。\n\n我们感兴趣的统计量是斜率的普通最小二乘（OLS）估计值 $\\hat{\\beta}_1$。对于一个包含 $n$ 对观测值 $\\{(x_i, y_i)\\}_{i=1}^n$ 的样本，最小化残差平方和 $\\sum_{i=1}^n (y_i - (\\hat{\\beta}_0 + \\hat{\\beta}_1 x_i))^2$ 的OLS估计量 $\\hat{\\beta}_1$ 由以下公式给出：\n$$\n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} = \\frac{\\text{Cov}(x, y)}{\\text{Var}(x)}\n$$\n其中 $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$ 和 $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$ 分别是自变量和因变量的样本均值。\n\n解决方案的核心是非参数自举算法，我们将其应用于下面四个案例中的每一个：\n1. 原始的 $n$ 对观测值数据集 $D = \\{(x_1, y_1), \\dots, (x_n, y_n)\\}$ 被视为经验分布函数，其中每一对被选中的概率为 $1/n$。\n2. 使用指定的种子初始化一个伪随机数生成器，以确保可复现性。\n3. 总共生成 $B=8000$ 个自举样本。每个自举样本 $D^*_j$（其中 $j \\in \\{1, \\dots, B\\}$）是通过从原始数据集 $D$ 中有放回地抽取 $n$ 对观测值而创建的。\n4. 对于每个自举样本 $D^*_j$，使用来自 $D^*_j$ 的数据和上述公式计算 OLS 斜率估计值，记为 $\\hat{\\beta}_{1,j}^*$。\n5. 此过程产生 $B$ 个自举斜率估计值的集合 $\\{\\hat{\\beta}_{1,1}^*, \\hat{\\beta}_{1,2}^*, \\dots, \\hat{\\beta}_{1,B}^*\\}$。这个集合可作为估计量 $\\hat{\\beta}_1$ 的抽样分布的经验近似。\n\n为了构建置信区间，我们使用百分位数法。对于 $1-\\alpha = 0.95$ 的置信水平，我们有 $\\alpha=0.05$。置信区间的下界和上界由排序后的自举斜率分布的 $\\alpha/2 = 0.025$ 和 $1-\\alpha/2 = 0.975$ 分位数确定。\n- 设排序后的自举斜率列表为 $\\hat{\\beta}_{1,(1)}^* \\leq \\hat{\\beta}_{1,(2)}^* \\leq \\dots \\leq \\hat{\\beta}_{1,(B)}^*$。\n- 下端点 $\\ell$ 是此排序列表中位置为 $B \\times (\\alpha/2)$ 的值。\n- 上端点 $u$ 是此排序列表中位置为 $B \\times (1-\\alpha/2)$ 的值。\n\n实现将使用 Python 的 `numpy` 库来完成。对于每种情况，我们将：\n- 定义数据数组 $x$ 和 $y$。\n- 使用给定的种子实例化一个随机数生成器。\n- 循环 $B=8000$ 次。在每次迭代中，生成自举索引，选择相应的观测对以形成自举样本，并计算斜率 $\\hat{\\beta}_1^*$。\n- 循环结束后，将使用 `numpy.quantile` 高效地计算 8000 个斜率估计值集合的 $0.025$ 和 $0.975$ 分位数。\n- 所得端点将按要求四舍五入到小数点后六位。最终输出将格式化为表示列表之列表的单个字符串。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes 95% bootstrap confidence intervals for the slope of a simple linear regression model\n    for four different bioinformatics datasets.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"x\": np.array([0.34, 0.36, 0.40, 0.41, 0.43, 0.45, 0.48, 0.50, 0.52, 0.55, 0.57, 0.60]),\n            \"y\": np.array([4.10, 4.00, 4.30, 4.50, 4.60, 4.90, 5.00, 5.30, 5.40, 5.80, 6.00, 6.20]),\n            \"B\": 8000,\n            \"seed\": 13579\n        },\n        {\n            \"x\": np.array([0.31, 0.33, 0.35, 0.38, 0.40, 0.42, 0.44, 0.47, 0.49, 0.51, 0.53, 0.56]),\n            \"y\": np.array([5.10, 4.95, 5.05, 5.00, 5.02, 4.98, 5.01, 5.04, 4.96, 5.03, 4.97, 5.00]),\n            \"B\": 8000,\n            \"seed\": 24680\n        },\n        {\n            \"x\": np.array([0.30, 0.34, 0.37, 0.39, 0.41, 0.44, 0.46, 0.49, 0.51, 0.54, 0.58, 0.61]),\n            \"y\": np.array([7.00, 6.80, 6.60, 6.50, 6.30, 6.10, 6.00, 5.90, 5.70, 5.50, 5.30, 5.20]),\n            \"B\": 8000,\n            \"seed\": 11235\n        },\n        {\n            \"x\": np.array([0.32, 0.36, 0.40, 0.45, 0.50, 0.54, 0.58, 0.62]),\n            \"y\": np.array([3.80, 3.95, 4.10, 4.30, 4.45, 4.60, 4.80, 4.95]),\n            \"B\": 8000,\n            \"seed\": 98765\n        }\n    ]\n\n    all_results = []\n    confidence_level = 0.95\n    alpha = 1.0 - confidence_level\n    lower_quantile = alpha / 2.0\n    upper_quantile = 1.0 - lower_quantile\n\n    def calculate_slope(x, y):\n        \"\"\"Calculates the OLS slope coefficient.\"\"\"\n        x_mean = np.mean(x)\n        y_mean = np.mean(y)\n        numerator = np.sum((x - x_mean) * (y - y_mean))\n        denominator = np.sum((x - x_mean)**2)\n        # Denominator is non-zero for the given datasets and their bootstrap samples\n        # as x values are not all identical.\n        return numerator / denominator\n\n    for case in test_cases:\n        x_data = case[\"x\"]\n        y_data = case[\"y\"]\n        n = len(x_data)\n        B = case[\"B\"]\n        seed = case[\"seed\"]\n\n        rng = np.random.default_rng(seed)\n        \n        bootstrap_slopes = np.empty(B)\n\n        for i in range(B):\n            indices = rng.choice(n, size=n, replace=True)\n            x_boot = x_data[indices]\n            y_boot = y_data[indices]\n            \n            # The case where all x_boot values are identical is highly improbable\n            # and does not occur with the given seeds and data. We proceed without\n            # an explicit check for denominator == 0 for efficiency.\n            bootstrap_slopes[i] = calculate_slope(x_boot, y_boot)\n        \n        ci_lower = np.quantile(bootstrap_slopes, lower_quantile)\n        ci_upper = np.quantile(bootstrap_slopes, upper_quantile)\n\n        rounded_result = [round(ci_lower, 6), round(ci_upper, 6)]\n        all_results.append(rounded_result)\n\n    # Format the output string exactly as specified.\n    # `map(str, all_results)` produces strings like '[1.23, 4.56]',\n    # which are then joined by commas.\n    print(f\"[{','.join(map(str, all_results))}]\".replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}