{
    "hands_on_practices": [
        {
            "introduction": "A foundational challenge in computational biology is the sheer scale of modern datasets, which often requires performing thousands or millions of hypothesis tests simultaneously. This exercise provides a crucial, hands-on calculation to demonstrate how the probability of encountering at least one false positive result—the Family-Wise Error Rate (FWER)—inflates dramatically as the number of tests increases. Understanding this principle is the first step toward appreciating the need for multiple testing correction, a non-negotiable step in genomic and other high-throughput analyses .",
            "id": "2430505",
            "problem": "In a computational biology validation study of a transcription factor binding site predictor, a researcher uses Chromatin Immunoprecipitation followed by sequencing (ChIP-seq) negative control regions to estimate the behavior of the statistical testing pipeline under the absence of true signal. Suppose the researcher performs hypothesis tests on $m = 20$ independent negative control regions, where each test is conducted at a per-test significance level $\\alpha = 0.05$. Assume that all $m$ null hypotheses are true and that the tests are mutually independent. What is the probability that at least one of these tests is declared significant purely by chance? Express your answer as a decimal fraction and round your answer to $4$ significant figures.",
            "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Number of independent hypothesis tests: $m = 20$.\n- The tests are performed on negative control regions, meaning all null hypotheses are assumed to be true.\n- The per-test significance level (Type I error rate for a single test): $\\alpha = 0.05$.\n- The tests are mutually independent.\n- The quantity to be calculated is the probability that at least one of these tests is declared significant.\n- The final answer must be a decimal fraction rounded to $4$ significant figures.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded. It addresses the concept of the Family-Wise Error Rate (FWER), a fundamental topic in multiple hypothesis testing, which is a critical area in bioinformatics and computational biology. The scenario described—assessing statistical properties using negative controls—is a standard and valid methodology. The problem is well-posed, providing all necessary parameters ($m$, $\\alpha$) and assumptions (independence, truth of null hypotheses) to arrive at a unique, meaningful solution. There are no internal contradictions, ambiguities, or reliance on non-scientific premises. The problem is a direct application of probability theory to a realistic scientific context.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A solution will be formulated.\n\n**Solution Formulation**\nThe problem asks for the probability of observing at least one statistically significant result when conducting $m$ independent hypothesis tests, given that all null hypotheses are true. This is a classic problem in multiple comparisons.\n\nLet $H_{0,i}$ be the null hypothesis for the $i$-th test, where $i$ ranges from $1$ to $m$. We are given that all $H_{0,i}$ are true.\nThe significance level, $\\alpha$, is the probability of committing a Type I error for a single test. A Type I error occurs when a true null hypothesis is incorrectly rejected. Therefore, for any single test $i$, the probability of declaring the result significant (i.e., rejecting $H_{0,i}$) is given by:\n$$P(\\text{test } i \\text{ is significant}) = \\alpha$$\n\nWe are given $\\alpha = 0.05$.\n\nThe complementary event is that a single test is *not* declared significant. The probability of this event is:\n$$P(\\text{test } i \\text{ is not significant}) = 1 - \\alpha$$\n\nThe problem states that all $m = 20$ tests are mutually independent. We want to find the probability that *at least one* test is significant. Let $A$ be the event that at least one of the $m$ tests is significant. It is computationally simpler to first calculate the probability of the complementary event, $A^c$, which is the event that *none* of the tests are significant.\n\nSince the tests are independent, the probability that all $m$ tests are not significant is the product of their individual probabilities:\n$$P(A^c) = P(\\text{test 1 is not significant} \\cap \\text{test 2 is not significant} \\cap \\dots \\cap \\text{test } m \\text{ is not significant})$$\n$$P(A^c) = \\prod_{i=1}^{m} P(\\text{test } i \\text{ is not significant})$$\n$$P(A^c) = (1 - \\alpha)^m$$\n\nThe probability of the event $A$ (at least one significant test) is then given by the complement rule:\n$$P(A) = 1 - P(A^c)$$\n$$P(A) = 1 - (1 - \\alpha)^m$$\n\nThis quantity is known as the Family-Wise Error Rate (FWER) under the complete null hypothesis.\n\nNow, we substitute the given values into this formula:\n- Number of tests, $m = 20$.\n- Significance level, $\\alpha = 0.05$.\n\n$$P(A) = 1 - (1 - 0.05)^{20}$$\n$$P(A) = 1 - (0.95)^{20}$$\n\nTo obtain the numerical value, we calculate $(0.95)^{20}$:\n$$(0.95)^{20} \\approx 0.358485922$$\n\nNow, we find the final probability:\n$$P(A) \\approx 1 - 0.358485922$$\n$$P(A) \\approx 0.641514078$$\n\nThe problem requires the answer to be rounded to $4$ significant figures. The first four significant figures are $6$, $4$, $1$, and $5$. The fifth digit is $1$, which is less than $5$, so we round down.\nThe final result is $0.6415$.\nThis result demonstrates a critical concept: even with a small per-test error rate of $5\\%$, the probability of making at least one false discovery inflates rapidly as the number of tests increases. For $20$ tests, there is a greater than $64\\%$ chance of at least one false positive result.",
            "answer": "$$\\boxed{0.6415}$$"
        },
        {
            "introduction": "While a single study may not have enough statistical power to detect a subtle biological effect, consistent signals across independent experiments can provide strong cumulative evidence. This practice moves beyond interpreting a single $p$-value to the important task of meta-analysis, where results are formally synthesized. By working through the logic of combining $p$-values from separate cohorts, you will learn how to rigorously assess whether repeated, individually non-significant findings can collectively achieve statistical significance .",
            "id": "2430501",
            "problem": "A biomarker is evaluated for differential expression between two phenotypic groups in two independent RNA sequencing (RNA-seq) cohorts. Each cohort performs a valid test of the same null hypothesis that the true mean expression difference is zero, producing independent p-values $p_1$ and $p_2$. The observed values are $p_1 = 0.1$ and $p_2 = 0.1$. The study’s pre-registered meta-analysis plan specifies a combining rule that rejects for sufficiently small values of the product of the p-values: define the test statistic $T = p_1 p_2$, and define the combined p-value as $\\Pr\\!\\left(U_1 U_2 \\leq T \\mid H_0\\right)$, where under the null hypothesis $H_0$ the p-values $U_1$ and $U_2$ are independent and identically distributed as $\\mathrm{Uniform}(0,1)$.\n\nCompute the exact combined p-value for the observed data. Round your answer to four significant figures. Do not include any units in your response.",
            "solution": "Under the null hypothesis $H_0$, the p-values $U_1$ and $U_2$ are independent and identically distributed as $\\mathrm{Uniform}(0,1)$. The combined p-value defined by the product rule is the tail probability\n$$\n\\Pr\\!\\left(U_1 U_2 \\leq t\\right),\n$$\nevaluated at the observed $t = p_1 p_2$. To obtain this from first principles, compute the cumulative distribution function of $T = U_1 U_2$ for $t \\in (0,1)$ using the joint density of $(U_1,U_2)$, which is $1$ on the unit square:\n$$\nF_T(t) \\equiv \\Pr\\!\\left(U_1 U_2 \\leq t\\right) = \\iint_{\\{(u_1,u_2)\\in(0,1)^2: u_1 u_2 \\leq t\\}} 1 \\,\\mathrm{d}u_2\\,\\mathrm{d}u_1.\n$$\nFor a fixed $u_1 \\in (0,1)$, the condition $u_1 u_2 \\leq t$ is equivalent to $u_2 \\leq t/u_1$. When $u_1 \\in (0,t)$, $t/u_1 \\geq 1$, so the inner integral over $u_2$ spans the full interval $(0,1)$; when $u_1 \\in [t,1)$, the inner integral spans $(0, t/u_1)$. Thus,\n$$\nF_T(t) = \\int_{0}^{t} \\left(\\int_{0}^{1} 1 \\,\\mathrm{d}u_2\\right) \\mathrm{d}u_1 + \\int_{t}^{1} \\left(\\int_{0}^{t/u_1} 1 \\,\\mathrm{d}u_2\\right) \\mathrm{d}u_1\n= \\int_{0}^{t} 1 \\,\\mathrm{d}u_1 + \\int_{t}^{1} \\frac{t}{u_1} \\,\\mathrm{d}u_1.\n$$\nEvaluating these integrals yields\n$$\nF_T(t) = t + t \\int_{t}^{1} \\frac{1}{u_1} \\,\\mathrm{d}u_1 = t + t\\left[\\ln(1) - \\ln(t)\\right] = t - t \\ln(t),\n$$\nfor $t \\in (0,1)$. For the observed data, $p_1 = 0.1$ and $p_2 = 0.1$, so $t = p_1 p_2 = 0.01$. Therefore, the combined p-value is\n$$\nF_T(0.01) = 0.01 - 0.01 \\ln(0.01) = 0.01 \\left(1 - \\ln(0.01)\\right).\n$$\nUsing the natural logarithm, $\\ln(0.01) = -\\ln(100) = -2 \\ln(10) \\approx -4.605170186$, hence\n$$\nF_T(0.01) \\approx 0.01 \\left(1 + 4.605170186\\right) = 0.01 \\times 5.605170186 = 0.05605170186.\n$$\nRounding to four significant figures gives $0.05605$.\n\nThis exact combined p-value, being greater than $0.05$, would not be considered statistically significant at a commonly used significance level $\\alpha = 0.05$, but the requested output is the numerical p-value itself.",
            "answer": "$$\\boxed{0.05605}$$"
        },
        {
            "introduction": "In bioinformatics, we often use complex models or metrics, like the Area Under the Curve (AUC) for a classifier, for which a simple, off-the-shelf formula to calculate a $p$-value does not exist. This coding exercise introduces permutation testing, an elegant and powerful computational method for empirically determining the statistical significance of any observed statistic. By implementing a permutation test from scratch, you will gain a deep, practical understanding of how to build a null distribution and assess the performance of a model when standard assumptions do not hold .",
            "id": "2430559",
            "problem": "You are given a binary classification setting from computational biology and bioinformatics in which a model assigns a real-valued risk score to each patient for a survival endpoint. Let there be $n$ patients indexed by $i \\in \\{1,\\dots,n\\}$, with model scores $s_i \\in \\mathbb{R}$ and binary labels $y_i \\in \\{0,1\\}$, where $y_i = 1$ denotes the event of interest (for example, non-survival) and $y_i = 0$ denotes the absence of the event (for example, survival). The Area Under the Receiver Operating Characteristic Curve (AUC) is defined from first principles as\n$$\n\\mathrm{AUC}(s,y) \\;=\\; \\frac{1}{n_1 n_0} \\sum_{i: y_i=1} \\sum_{j: y_j=0} \\left( \\mathbf{1}\\{s_i  s_j\\} \\;+\\; \\tfrac{1}{2}\\,\\mathbf{1}\\{s_i = s_j\\} \\right),\n$$\nwhere $n_1 = \\sum_{i=1}^n \\mathbf{1}\\{y_i=1\\}$ and $n_0 = \\sum_{i=1}^n \\mathbf{1}\\{y_i=0\\}$, and $\\mathbf{1}\\{\\cdot\\}$ is the indicator function. If $n_1 = 0$ or $n_0 = 0$, define $\\mathrm{AUC}(s,y) = 0.5$ by convention.\n\nTo assess statistical significance of the observed $\\mathrm{AUC}(s,y)$, consider a label-permutation test under the null hypothesis that labels are exchangeable given the scores. Formally, let $\\mathcal{Y}$ be the set of all labelings $y' \\in \\{0,1\\}^n$ with exactly $n_1$ ones and $n_0$ zeros, and let the permutation null distribution be uniform over $\\mathcal{Y}$. The one-sided right-tail $p$-value for testing whether $\\mathrm{AUC}(s,y)$ exceeds what is expected by chance is\n$$\np \\;=\\; \\frac{1}{|\\mathcal{Y}|} \\sum_{y' \\in \\mathcal{Y}} \\mathbf{1}\\big\\{\\mathrm{AUC}(s,y') \\;\\ge\\; \\mathrm{AUC}(s,y)\\big\\}.\n$$\nIn the degenerate boundary case $n_1 = 0$ or $n_0 = 0$, define the $p$-value to be $1.0$.\n\nYour task is to write a complete program that, for each of the test cases below, computes the exact permutation $p$-value as defined above. The program must implement the definitions as stated, without assuming any approximation. For ties in scores across classes, use the $\\tfrac{1}{2}$ convention given in the AUC definition.\n\nTest suite (each case specifies $(s,y)$ as arrays in the given order):\n- Case $1$ (balanced moderate performance with $\\mathrm{AUC}$ equal to $0.6$ by construction): \n  - $s = [$ $0.6$, $0.2$, $0.5$, $0.1$, $0.45$, $0.5$, $0.5$ $]$\n  - $y = [$ $1$, $0$, $0$, $1$, $1$, $1$, $1$ $]$\n- Case $2$ (near-perfect separation):\n  - $s = [$ $0.9$, $0.8$, $0.7$, $0.2$, $0.1$ $]$\n  - $y = [$ $1$, $1$, $1$, $0$, $0$ $]$\n- Case $3$ (degenerate boundary where all labels are identical):\n  - $s = [$ $0.3$, $0.1$, $0.9$, $0.7$ $]$\n  - $y = [$ $1$, $1$, $1$, $1$ $]$\n- Case $4$ (interleaved ties yielding $\\mathrm{AUC}$ equal to $0.5$):\n  - $s = [$ $0.1$, $0.1$, $0.2$, $0.2$, $0.3$, $0.3$ $]$\n  - $y = [$ $1$, $0$, $1$, $0$, $1$, $0$ $]$\n\nFinal output specification:\n- For each case, output the $p$-value as a real number in decimal form rounded to exactly $6$ digits after the decimal point.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the cases above, for example: $[$ $p_1$, $p_2$, $p_3$, $p_4$ $]$.",
            "solution": "The problem statement has been subjected to validation and is determined to be valid. It is scientifically sound, well-posed, unambiguous, and internally consistent. The problem is rooted in the established statistical practice of using permutation tests to assess the significance of a model performance metric, in this case, the Area Under the Receiver Operating Characteristic Curve (AUC). All terms are defined with mathematical precision, and the test cases provided are computationally feasible. We may therefore proceed with the derivation of the solution.\n\nThe task is to compute an exact one-sided permutation $p$-value for an observed AUC. This requires a direct implementation of the provided definitions without approximation. The algorithm consists of two principal steps: the calculation of the AUC for a given set of scores and labels, and the enumeration of the permutation space to determine the $p$-value.\n\nFirst, we define the procedure for calculating $\\mathrm{AUC}(s,y)$. Given a vector of scores $s \\in \\mathbb{R}^n$ and a vector of binary labels $y \\in \\{0,1\\}^n$, we count the number of positive labels, $n_1 = \\sum_{i=1}^n \\mathbf{1}\\{y_i=1\\}$, and negative labels, $n_0 = \\sum_{i=1}^n \\mathbf{1}\\{y_i=0\\}$. Per the problem statement, if either $n_1=0$ or $n_0=0$, the AUC is defined by convention as $0.5$. Otherwise, the AUC is computed using the formula:\n$$\n\\mathrm{AUC}(s,y) \\;=\\; \\frac{1}{n_1 n_0} \\sum_{i: y_i=1} \\sum_{j: y_j=0} \\left( \\mathbf{1}\\{s_i  s_j\\} \\;+\\; \\tfrac{1}{2}\\,\\mathbf{1}\\{s_i = s_j\\} \\right)\n$$\nThis calculation involves iterating through all pairs of positively- and negatively-labeled samples, comparing their scores, and summing the results according to the indicator function $\\mathbf{1}\\{\\cdot\\}$, which accounts for ties with a value of $\\tfrac{1}{2}$. The final sum is normalized by the total number of pairs, $n_1 n_0$.\n\nSecond, we address the computation of the $p$-value. For a given test case $(s,y)$, we first compute the observed AUC, denoted $\\mathrm{AUC}_{\\text{obs}} = \\mathrm{AUC}(s,y)$. The null hypothesis of the permutation test posits that the labels are exchangeable with respect to the scores. The set of all possible label assignments under this null hypothesis, $\\mathcal{Y}$, consists of all binary vectors of length $n$ that have the same counts of positive and negative labels as the original vector $y$, i.e., $n_1$ and $n_0$ respectively. The size of this permutation space is given by the binomial coefficient $|\\mathcal{Y}| = \\binom{n}{n_1}$.\n\nTo compute the exact $p$-value, we must enumerate every unique permutation $y' \\in \\mathcal{Y}$. For each $y'$, we calculate its corresponding $\\mathrm{AUC}(s, y')$. The one-sided right-tail $p$-value is the proportion of these permutations for which the AUC is greater than or equal to the observed AUC:\n$$\np \\;=\\; \\frac{1}{|\\mathcal{Y}|} \\sum_{y' \\in \\mathcal{Y}} \\mathbf{1}\\big\\{\\mathrm{AUC}(s,y') \\;\\ge\\; \\mathrm{AUC}_{\\text{obs}}\\big\\}\n$$\nIn the degenerate case where $n_1=0$ or $n_0=0$, the $p$-value is defined to be $1.0$.\n\nThis procedure is applied to each test case:\n- For Case $1$ ($n=7$, $n_1=5$), we compute $\\mathrm{AUC}_{\\text{obs}}$ and then iterate through all $|\\mathcal{Y}| = \\binom{7}{5} = 21$ label permutations to find the $p$-value.\n- For Case $2$ ($n=5$, $n_1=3$), we have $|\\mathcal{Y}| = \\binom{5}{3} = 10$. The observed data shows perfect separation, so $\\mathrm{AUC}_{\\text{obs}} = 1.0$. The $p$-value is the fraction of permutations that also achieve an AUC of $1.0$. Since all scores are unique, perfect separation is only possible if the three highest scores are assigned the positive label. There is only one such assignment. Thus, the $p$-value is $1/10 = 0.1$.\n- For Case $3$ ($n=4$, $n_1=4. n_0=0$), this is a degenerate boundary case. By definition, the $p$-value is $1.0$.\n- For Case $4$ ($n=6$, $n_1=3$), we have $|\\mathcal{Y}| = \\binom{6}{3} = 20$. The observed data yields $\\mathrm{AUC}_{\\text{obs}}=0.5$ due to the symmetric distribution of scores between the two classes. The $p$-value is the fraction of permutations where $\\mathrm{AUC} \\ge 0.5$. Due to the symmetry of the AUC statistic ($\\mathrm{AUC}(y') + \\mathrm{AUC}(1-y')=1$) when $n_1=n_0$, the distribution of AUC values under the null is symmetric around $0.5$. The number of cases where $\\mathrm{AUC}  0.5$ must equal the number where $\\mathrm{AUC}  0.5$. An analytical count reveals that $8$ permutations yield $\\mathrm{AUC}=0.5$, leaving $12$ permutations for which the AUC is not $0.5$. By symmetry, $6$ must be greater than $0.5$. The total count of permutations with $\\mathrm{AUC} \\ge 0.5$ is $8+6=14$. The $p$-value is therefore $14/20 = 0.7$.\n\nThe implementation will programmatically perform this exhaustive enumeration for each case, ensuring adherence to the exact definitions provided.",
            "answer": "```python\nimport numpy as np\nfrom itertools import combinations\nfrom scipy.special import comb\n\ndef solve():\n    \"\"\"\n    Computes exact permutation p-values for the AUC statistic for a suite of test cases.\n    \"\"\"\n\n    def calculate_auc(scores: np.ndarray, labels: np.ndarray) - float:\n        \"\"\"\n        Calculates the Area Under the ROC Curve (AUC) based on the provided formula.\n        \"\"\"\n        n1 = np.sum(labels == 1)\n        n0 = np.sum(labels == 0)\n\n        if n1 == 0 or n0 == 0:\n            return 0.5\n        \n        pos_scores = scores[labels == 1]\n        neg_scores = scores[labels == 0]\n        \n        auc_sum = 0.0\n        for s_i in pos_scores:\n            for s_j in neg_scores:\n                if s_i  s_j:\n                    auc_sum += 1.0\n                elif s_i == s_j:\n                    auc_sum += 0.5\n        \n        return auc_sum / (n1 * n0)\n\n    def compute_exact_p_value(s: np.ndarray, y: np.ndarray) - float:\n        \"\"\"\n        Computes the exact permutation p-value for the observed AUC.\n        \"\"\"\n        n = len(s)\n        n1 = int(np.sum(y))\n        n0 = n - n1\n\n        if n1 == 0 or n0 == 0:\n            return 1.0\n\n        auc_observed = calculate_auc(s, y)\n        \n        indices = np.arange(n)\n        # Generate all combinations of indices for the positive class\n        pos_label_indices_iter = combinations(indices, n1)\n        \n        num_permutations = comb(n, n1, exact=True)\n        count_ge_observed = 0\n\n        for pos_indices in pos_label_indices_iter:\n            y_perm = np.zeros(n, dtype=int)\n            y_perm[list(pos_indices)] = 1\n            \n            auc_permuted = calculate_auc(s, y_perm)\n            \n            # Using a small tolerance for floating point comparison is good practice,\n            # but for this problem's small denominators, direct comparison is exact.\n            if auc_permuted = auc_observed:\n                count_ge_observed += 1\n                \n        return count_ge_observed / num_permutations\n\n    test_cases = [\n        # Case 1: balanced moderate performance\n        (np.array([0.6, 0.2, 0.5, 0.1, 0.45, 0.5, 0.5]), \n         np.array([1, 0, 0, 1, 1, 1, 1])),\n        # Case 2: near-perfect separation\n        (np.array([0.9, 0.8, 0.7, 0.2, 0.1]), \n         np.array([1, 1, 1, 0, 0])),\n        # Case 3: degenerate boundary case\n        (np.array([0.3, 0.1, 0.9, 0.7]), \n         np.array([1, 1, 1, 1])),\n        # Case 4: interleaved ties\n        (np.array([0.1, 0.1, 0.2, 0.2, 0.3, 0.3]), \n         np.array([1, 0, 1, 0, 1, 0]))\n    ]\n    \n    results = []\n    for s, y in test_cases:\n        p_value = compute_exact_p_value(s, y)\n        results.append(f\"{p_value:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}