{
    "hands_on_practices": [
        {
            "introduction": "This practice provides a concrete introduction to the information-theoretic cost of sequence masking. Before we build complex filters, it is essential to understand that replacing a nucleotide with a generic 'N' is not a neutral act; it is a quantifiable loss of information. This exercise will guide you through calculating this loss in bits using the concept of self-information, connecting the abstract principles of information theory to the practical task of sequence analysis .",
            "id": "2390141",
            "problem": "You are given deoxyribonucleic acid sequences in which soft-masked regions are denoted by lowercase letters and unmasked positions by uppercase letters, using only the alphabet {A, C, G, T} in either case. A hard-masked version of a sequence is obtained by replacing every lowercase character with the uppercase letter N, and leaving every uppercase character A, C, G, or T unchanged. Let the background distribution over the nucleotides A, C, G, T be specified by probabilities $p_A, p_C, p_G, p_T$, with $p_A + p_C + p_G + p_T = 1$ and each $p_X \\in (0,1)$.\n\nFor a sequence $s$ of length $n$, define the self-information of a symbol $x \\in \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$ under the given background distribution as $I(x) = -\\log_2 p_x$. Define the total information of the original sequence as\n$$\nI(s) = \\sum_{i=1}^{n} I\\big(x_i\\big),\n$$\nwhere $x_i$ is the uppercase version of the character at position $i$ in $s$. Define the information loss in bits incurred by converting $s$ to its hard-masked version as\n$$\nL(s) = \\sum_{i \\in \\mathcal{M}} I\\big(x_i\\big),\n$$\nwhere $\\mathcal{M}$ is the set of indices where $s$ has lowercase letters (the positions that become N in the hard-masked sequence). In other words, each soft-masked position contributes the lost self-information of its actual nucleotide identity under the given background model. The unit for $I(\\cdot)$, $I(s)$, and $L(s)$ is bits.\n\nYour task is to write a complete program that, for each test case below, converts the provided soft-masked sequence to a hard-masked sequence (by replacing lowercase a, c, g, t with N) and computes the information loss $L(s)$, expressed in bits, rounded to exactly $6$ decimal places.\n\nTest suite:\n1. Sequence: \"ACgtACgt\", Background probabilities: $(p_A, p_C, p_G, p_T) = (0.25, 0.25, 0.25, 0.25)$.\n2. Sequence: \"aCgTaCgT\", Background probabilities: $(p_A, p_C, p_G, p_T) = (0.10, 0.20, 0.30, 0.40)$.\n3. Sequence: \"acgt\", Background probabilities: $(p_A, p_C, p_G, p_T) = (0.25, 0.25, 0.25, 0.25)$.\n4. Sequence: \"ACGTACGT\", Background probabilities: $(p_A, p_C, p_G, p_T) = (0.25, 0.25, 0.25, 0.25)$.\n5. Sequence: \"aaCCggTT\", Background probabilities: $(p_A, p_C, p_G, p_T) = (0.70, 0.10, 0.10, 0.10)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test cases. Each element of the list must be a floating-point number equal to $L(s)$ in bits, rounded to exactly $6$ decimal places. For example: \"[x1,x2,x3,x4,x5]\".",
            "solution": "The problem statement has been subjected to rigorous validation.\n\nThe givens are:\n1.  A set of DNA sequences containing uppercase (`A`, `C`, `G`, `T`) and lowercase (`a`, `c`, `g`, `t`) characters. Lowercase letters denote soft-masked regions.\n2.  A procedure for hard-masking, where lowercase letters are replaced by `N`.\n3.  A background probability distribution `$(p_A, p_C, p_G, p_T)$` for each sequence, where `$p_X \\in (0,1)$` and `$\\sum p_X = 1$`.\n4.  The definition of self-information for a nucleotide `$x \\in \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$` is `$I(x) = -\\log_2 p_x$`.\n5.  The definition of information loss `$L(s)$` upon hard-masking is the sum of self-information of the nucleotides in the soft-masked regions: `$L(s) = \\sum_{i \\in \\mathcal{M}} I(x_i)$`, where `$\\mathcal{M}$` is the set of indices of lowercase characters and `$x_i$` is the uppercase equivalent of the character at index `$i$`.\n6.  A test suite of five cases, each with a sequence and a probability distribution.\n7.  A requirement to compute `$L(s)$` for each case, rounded to six decimal places, and to conceptually perform the hard-masking conversion.\n\nThe problem is validated against the required criteria:\n1.  **Scientifically Grounded**: The problem is based on standard, well-established concepts in bioinformatics and information theory. Sequence masking is a common technique for handling repetitive or low-complexity regions. The application of self-information to quantify the loss of data upon masking is a valid and direct use of information-theoretic principles. The problem is scientifically sound.\n2.  **Well-Posed**: The problem is specified with mathematical precision. All necessary inputs (sequences, probabilities) are provided. The definitions are unambiguous, and the required calculations are clearly described. A unique solution exists for each test case and can be determined algorithmically. The problem is well-posed.\n3.  **Objective**: The problem is stated in formal, quantitative terms, free of any subjectivity or opinion. The problem is objective.\n\nConclusion: The problem is valid. A complete and reasoned solution will be provided.\n\nThe task is to compute the information loss that occurs when a soft-masked DNA sequence is converted to a hard-masked representation. This loss is quantified using the principles of information theory.\n\nA soft-masked sequence uses lowercase letters to signify regions of low complexity or repeats. While the nucleotide identity is known, it is flagged as being less reliable or less significant for certain analyses. Hard-masking is a more severe data-reduction step where these nucleotides are replaced by a generic symbol `N`, completely obscuring their original identity. The information loss is the amount of information, measured in bits, that is discarded in this process.\n\nThe fundamental quantity is the self-information, or surprisal, of a nucleotide `$x$`, given by `$I(x) = -\\log_2 p_x$`. This measures the information content of observing nucleotide `$x$` under a background model where `$x$` occurs with probability `$p_x$`. A rare nucleotide (low `$p_x$`) has high self-information, while a common one (high `$p_x$`) has low self-information.\n\nThe total information loss for a sequence `$s$`, denoted `$L(s)$`, is the sum of the self-information of all nucleotides that are soft-masked. Let `$s = s_1s_2...s_n$` be the sequence of length `$n$`. Let `$\\mathcal{M}$` be the set of indices `$i$` such that `$s_i$` is a lowercase letter. Let `$x_i$` be the uppercase version of `$s_i$`. The information loss is precisely:\n$$\nL(s) = \\sum_{i \\in \\mathcal{M}} I(x_i) = \\sum_{i \\in \\mathcal{M}} (-\\log_2 p_{x_i})\n$$\n\nThe algorithm to solve the problem is as follows:\n1.  For each given test case, consisting of a sequence `$s$` and a probability map `$\\{p_A, p_C, p_G, p_T\\}$`.\n2.  Initialize a variable, `total_loss`, to `$0.0$`.\n3.  Iterate through each character `$c$` in the sequence `$s$`.\n4.  Check if `$c$` is a lowercase letter.\n5.  If it is, convert `$c$` to its uppercase equivalent, `$x$`. Find the corresponding probability `$p_x$` from the given distribution.\n6.  Calculate the self-information `$- \\log_2 p_x$` and add it to `total_loss`.\n7.  After iterating through the entire sequence, the final value of `total_loss` is the information loss `$L(s)$`.\n8.  This value must be formatted to six decimal places.\n\nAs an illustrative example, let us consider Test Case 2:\n- Sequence `$s = \\text{\"aCgTaCgT\"}$`.\n- Background probabilities: `$p_A = 0.10, p_C = 0.20, p_G = 0.30, p_T = 0.40$`.\n\nThe soft-masked positions contain the characters `a`, `g`, `a`, `g`. The corresponding uppercase nucleotides are `A`, `G`, `A`, `G`. The information loss is the sum of the self-information of these four nucleotides.\n$$\nL(s) = I(\\text{A}) + I(\\text{G}) + I(\\text{A}) + I(\\text{G}) = 2 \\cdot I(\\text{A}) + 2 \\cdot I(\\text{G})\n$$\nUsing the provided probabilities:\n$$\nI(\\text{A}) = -\\log_2(p_A) = -\\log_2(0.10)\n$$\n$$\nI(\\text{G}) = -\\log_2(p_G) = -\\log_2(0.30)\n$$\nThe total loss is:\n$$\nL(s) = 2 \\cdot (-\\log_2(0.10)) + 2 \\cdot (-\\log_2(0.30))\n$$\nUsing the base change formula `$\\log_2(x) = \\frac{\\ln(x)}{\\ln(2)}$`:\n$$\n-\\log_2(0.10) \\approx -(-3.321928) \\approx 3.321928 \\text{ bits}\n$$\n$$\n-\\log_2(0.30) \\approx -(-1.736966) \\approx 1.736966 \\text{ bits}\n$$\nSo, the total information loss is:\n$$\nL(s) \\approx 2 \\cdot (3.321928) + 2 \\cdot (1.736966) = 6.643856 + 3.473932 = 10.117788 \\text{ bits}\n$$\nRounded to six decimal places, the result is `$10.117788$`. The corresponding hard-masked sequence would be `\"NCGNCNGT\"`, but only the numerical loss value is required for the final output. The procedure is repeated for all test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the information loss problem for a suite of test cases.\n    For each case, it computes the information loss incurred when converting a\n    soft-masked DNA sequence to a hard-masked one.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (sequence, probability_dict)\n    test_cases = [\n        (\n            \"ACgtACgt\",\n            {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n        ),\n        (\n            \"aCgTaCgT\",\n            {'A': 0.10, 'C': 0.20, 'G': 0.30, 'T': 0.40}\n        ),\n        (\n            \"acgt\",\n            {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n        ),\n        (\n            \"ACGTACGT\",\n            {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n        ),\n        (\n            \"aaCCggTT\",\n            {'A': 0.70, 'C': 0.10, 'G': 0.10, 'T': 0.10}\n        ),\n    ]\n\n    results = []\n    for seq, probs in test_cases:\n        information_loss = 0.0\n        \n        # This part conceptually builds the hard-masked sequence,\n        # but is not strictly needed for the final output value.\n        # hard_masked_seq_list = []\n\n        # Iterate through each character of the sequence.\n        for char in seq:\n            # Check if the character is lowercase (soft-masked).\n            if 'a' <= char <= 'z':\n                # This is a soft-masked position.\n                nucleotide = char.upper()\n                \n                # Get the background probability of this nucleotide.\n                p = probs[nucleotide]\n                \n                # Calculate self-information I(x) = -log2(p) and add to total loss.\n                if p > 0:\n                    information_loss -= np.log2(p)\n\n                # For hard-masking, this position becomes 'N'.\n                # hard_masked_seq_list.append('N')\n            # else:\n                # Unmasked characters remain unchanged.\n                # hard_masked_seq_list.append(char)\n        \n        # The hard-masked sequence would be: \"\".join(hard_masked_seq_list)\n        \n        results.append(f\"{information_loss:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Building on the concept of information content, we now move to a practical application: constructing an algorithm to detect low-complexity regions (LCRs) from scratch. This exercise challenges you to implement a simplified version of the classic SEG algorithm, which uses Shannon entropy in a sliding window to identify compositionally biased regions in protein sequences. You will learn the importance of the trigger-and-extend strategy, a common design pattern in bioinformatics for achieving robust detection of sequence features .",
            "id": "2390180",
            "problem": "You will implement a simplified, self-contained variant of the SEG (Segment) algorithm for detecting low-complexity regions in protein sequences. The implementation must rely on base principles: local compositional variability measured by Shannon information and sliding-window analysis. Your program will use fixed parameters for amino acid alphabet size and window length, together with a two-threshold trigger-extension mechanism. The program must run as-is and print the results for a provided test suite.\n\nFundamental base and definitions:\n- Consider a protein sequence as a string $S$ over the standard amino acid alphabet $\\mathcal{A}$ with size $A = 20$. Let $|S| = L$ denote the length of the sequence.\n- For a fixed window length $W$, define the set of valid window start indices $s \\in \\{0, 1, \\dots, L - W\\}$. The window at start $s$ covers the residues with indices $\\{s, s+1, \\dots, s+W-1\\}$.\n- For each window, let $c_i(s)$ be the count of amino acid $i \\in \\{1,\\dots,A\\}$ in the window at start $s$. Define the empirical frequencies $p_i(s) = c_i(s)/W$. The Shannon entropy of the window is\n$$\nH(s) = -\\sum_{i=1}^{A} p_i(s)\\,\\log_2 p_i(s),\n$$\nwith the convention that $0\\log_2 0 = 0$. This $H(s)$ is bounded by $0 \\le H(s) \\le \\log_2 W$, and decreases as the window composition becomes more uniform or repetitive.\n- The simplified SEG logic uses two thresholds $\\tau_1$ (trigger) and $\\tau_2$ (extension) with $\\tau_1 \\le \\tau_2$. A window index $s$ is a trigger if $H(s) \\le \\tau_1$. A maximal contiguous block of window indices $[a,b]$ is extendable if $H(s) \\le \\tau_2$ for all $s \\in [a,b]$. A low-complexity region is formed by any maximal block $[a,b]$ that contains at least one trigger index $t \\in [a,b]$ (so $H(t) \\le \\tau_1$) and that cannot be extended further to the left or right without violating $H \\le \\tau_2$.\n- Mapping windows to residues: any contiguous block of windows $[a,b]$ maps to a single contiguous residue interval $[r_{\\min}, r_{\\max}] = [a, b+W-1]$. The set of masked residue indices is the union of these intervals over all qualifying blocks. Overlapping residue intervals must be merged into single intervals before enumerating indices.\n\nAlgorithmic task:\n- Input is implicit: your code must use the fixed amino acid alphabet $\\mathcal{A}$ of standard $20$ amino acids, compute $H(s)$ using base-$2$ logarithm, and apply the two-threshold trigger-extension scheme as defined above.\n- Edge cases: if $L < W$, there are no valid windows, so the masked set is empty. If no $H(s)$ falls below $\\tau_1$, no region is reported even if some $H(s) \\le \\tau_2$.\n- Output for each test case is the sorted list of masked residue indices (zero-based) after merging overlapping intervals and taking the union across all qualifying blocks. If no residues are masked, output the empty list.\n\nTest suite:\nUse the following fixed test cases, each defined by $(S, W, \\tau_1, \\tau_2)$:\n- Test case $1$: $S =$ \"ACDEFGHIKLMAAAAAAAAAAACDEFGHIKLM\", $W = 12$, $\\tau_1 = 1.8$, $\\tau_2 = 2.2$.\n- Test case $2$: $S =$ \"ACDEFGHIKLMNPQRSTVWY\", $W = 12$, $\\tau_1 = 1.8$, $\\tau_2 = 2.2$.\n- Test case $3$: $S =$ \"AAAAACCCCC\", $W = 12$, $\\tau_1 = 1.8$, $\\tau_2 = 2.2$.\n- Test case $4$: $S =$ \"AAAAAAAAAAAACDEFGHIKLMN\", $W = 12$, $\\tau_1 = 1.8$, $\\tau_2 = 2.2$.\n- Test case $5$: $S =$ \"ACDEFGHIKLMKKKKKKKKKKCDEFGHIKLMAAAAAAAA\", $W = 12$, $\\tau_1 = 1.8$, $\\tau_2 = 2.2$.\n\nRequirements and constraints:\n- Use only the standard amino acid alphabet $\\mathcal{A}$ of size $A=20$ when counting $c_i(s)$; ignore any character not in $\\mathcal{A}$ for counting, but sequences provided use only standard amino acids.\n- Use base-$2$ logarithms for $H(s)$, and compute with real arithmetic.\n- When constructing low-complexity regions, identify maximal contiguous window blocks $[a,b]$ that satisfy $H(s) \\le \\tau_2$ and contain at least one trigger $t$ with $H(t) \\le \\tau_1$. Each such block maps to a residue interval $[a, b+W-1]$. Merge overlapping residue intervals and output the union as a sorted list of indices.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself the bracketed, comma-separated list of masked zero-based indices for the corresponding test case, with no spaces anywhere. For example, if two test cases produced masked indices $[0,1]$ and $[]$, the single line would be \"[[0,1],[]]\".",
            "solution": "We begin from the base principle that local sequence complexity is captured by Shannon entropy, a well-tested measure of uncertainty in Information Theory. For a discrete distribution $(p_1,\\dots,p_A)$ over an alphabet of size $A$, Shannon entropy is defined as\n$$\nH = -\\sum_{i=1}^{A} p_i \\log_2 p_i,\n$$\nwith the convention $0\\log_2 0 = 0$. In a biological sequence window, $p_i$ is the empirical fraction of residue type $i$ observed in the window. Repetitive or compositionally biased windows have lower $H$, while compositionally diverse windows approach higher $H$ up to $\\log_2 W$ if at most $W$ distinct symbols appear uniformly in a window of length $W$.\n\nSEG’s essential mechanism is a two-threshold decision to stabilize region detection: a lower trigger threshold $\\tau_1$ begins masking when a window’s complexity $H(s)$ is sufficiently low, while a higher extension threshold $\\tau_2$ allows the region to expand through moderately low-complexity windows without frequently toggling on and off. This hysteresis-like design prevents fragmented detection when local fluctuations occur around a single threshold.\n\nAlgorithmic derivation:\n1. Represent the sequence $S$ over the standard amino acid alphabet $\\mathcal{A}$ with $A = 20$. Let $|S| = L$.\n2. Fix a window length $W$. Valid window starts are $s \\in \\{0,1,\\dots,L-W\\}$. For each $s$, compute counts $c_i(s)$ for $i \\in \\{1,\\dots,A\\}$ across indices $\\{s,\\dots,s+W-1\\}$. Define $p_i(s) = c_i(s)/W$.\n3. Compute per-window entropy using\n$$\nH(s) = -\\sum_{i=1}^{A} p_i(s)\\log_2 p_i(s).\n$$\nOnly terms with $p_i(s) > 0$ contribute.\n4. Identify all maximal contiguous blocks $[a,b]$ of window indices such that $H(s) \\le \\tau_2$ for all $s \\in [a,b]$ and such that there exists at least one trigger index $t \\in [a,b]$ with $H(t) \\le \\tau_1$. Maximality means we cannot extend $[a,b]$ to $[a-1,b]$ or $[a,b+1]$ without violating $H \\le \\tau_2$ or going out of range.\n5. Map each block $[a,b]$ of windows to the corresponding residue interval $[r_{\\min}, r_{\\max}] = [a, b + W - 1]$. This follows because the union over windows $\\{[s, s+W-1] : s \\in [a,b]\\}$ is precisely the interval from the smallest start $a$ to the largest end $b+W-1$. Formally, for any $x \\in [a, b+W-1]$, there exists $s \\in [a,b]$ such that $x \\in [s, s+W-1]$, establishing equality of sets.\n6. Merge overlapping or adjacent residue intervals across all qualifying blocks to form their union. Enumerate the resulting set as a sorted list of zero-based indices to obtain the mask for the sequence.\n7. Edge case: if $L < W$, then there are no valid windows and the result is the empty set.\n\nWhy the thresholds are appropriate:\n- For $W = 12$, the maximum possible entropy is bounded by $\\log_2 W \\approx 3.585$. Choosing $\\tau_1 = 1.8$ and $\\tau_2 = 2.2$ positions the trigger well below typical high-complexity windows, while the extension threshold allows some tolerance to moderate variability. Windows dominated by one or two residues will have $H(s)$ comfortably below $\\tau_1$, ensuring reliable triggers. Windows comprising many distinct residues will have $H(s)$ above $\\tau_2$, preventing false extensions.\n\nComputational considerations:\n- A naive per-window counting is $\\mathcal{O}(A W)$ per window, yielding $\\mathcal{O}(A W (L-W+1))$ across the sequence. For the small test cases provided, this is efficient and clear. Optimizations via sliding updates are possible but not required.\n- Interval merging can be realized in $\\mathcal{O}(K \\log K)$ where $K$ is the number of intervals, which is small here.\n\nApplying to the test suite:\n- Test case $1$ contains an internal run of many $A$ residues; windows spanning this run have low $H(s)$ and satisfy $H(s) \\le \\tau_1$, triggering masking and extension until $H(s) > \\tau_2$ at the flanks, producing a contiguous masked segment in the interior.\n- Test case $2$ distributes distinct amino acids broadly; entropy in windows approaches $\\log_2 12$, exceeding $\\tau_2$, so no windows satisfy the trigger and the result is empty.\n- Test case $3$ has $L < W$, so no windows exist and the result is empty.\n- Test case $4$ places a low-complexity region at the start; the earliest windows have very low $H(s)$ and trigger masking, then extension halts as $H(s)$ increases.\n- Test case $5$ contains two separated low-complexity segments (a run of $K$ residues and a run of $A$ residues), yielding two masked intervals after merging windows within each segment.\n\nThe final program computes $H(s)$ for each window, identifies blocks via the two-threshold mechanism, maps to residue intervals, merges overlaps, and prints the list of masked indices for each test case. The output is a single line representing the nested lists for all test cases without spaces, as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\nfrom typing import List, Tuple\n\nAA_ALPHABET = \"ACDEFGHIKLMNPQRSTVWY\"\nAA_INDEX = {aa: i for i, aa in enumerate(AA_ALPHABET)}\nA = 20  # size of amino acid alphabet\n\ndef shannon_entropy_window(window: str, W: int) -> float:\n    # Count only standard amino acids\n    counts = [0] * A\n    for ch in window:\n        idx = AA_INDEX.get(ch, None)\n        if idx is not None:\n            counts[idx] += 1\n    H = 0.0\n    for c in counts:\n        if c > 0:\n            p = c / W\n            H -= p * math.log2(p)\n    return H\n\ndef compute_window_entropies(S: str, W: int) -> List[float]:\n    L = len(S)\n    if L < W:\n        return []\n    Hs = []\n    for s in range(L - W + 1):\n        win = S[s:s+W]\n        Hs.append(shannon_entropy_window(win, W))\n    return Hs\n\ndef find_blocks(Hs: List[float], tau1: float, tau2: float) -> List[Tuple[int, int]]:\n    blocks = []\n    n = len(Hs)\n    s = 0\n    while s < n:\n        if Hs[s] <= tau2:\n            a = s\n            has_trigger = (Hs[s] <= tau1)\n            s += 1\n            while s < n and Hs[s] <= tau2:\n                if Hs[s] <= tau1:\n                    has_trigger = True\n                s += 1\n            b = s - 1\n            if has_trigger:\n                blocks.append((a, b))\n        else:\n            s += 1\n    return blocks\n\ndef merge_intervals(intervals: List[Tuple[int, int]]) -> List[Tuple[int, int]]:\n    if not intervals:\n        return []\n    intervals.sort()\n    merged = [intervals[0]]\n    for start, end in intervals[1:]:\n        last_start, last_end = merged[-1]\n        if start <= last_end + 1:\n            merged[-1] = (last_start, max(last_end, end))\n        else:\n            merged.append((start, end))\n    return merged\n\ndef blocks_to_residue_intervals(blocks: List[Tuple[int, int]], W: int) -> List[Tuple[int, int]]:\n    # Each window-block [a,b] maps to residue interval [a, b+W-1]\n    res_intervals = [(a, b + W - 1) for (a, b) in blocks]\n    return merge_intervals(res_intervals)\n\ndef intervals_to_indices(intervals: List[Tuple[int, int]]) -> List[int]:\n    indices = []\n    for a, b in intervals:\n        indices.extend(range(a, b + 1))\n    return indices\n\ndef seg_mask_indices(S: str, W: int, tau1: float, tau2: float) -> List[int]:\n    L = len(S)\n    if L < W:\n        return []\n    Hs = compute_window_entropies(S, W)\n    blocks = find_blocks(Hs, tau1, tau2)\n    residue_intervals = blocks_to_residue_intervals(blocks, W)\n    indices = intervals_to_indices(residue_intervals)\n    return indices\n\ndef serialize_no_spaces(obj) -> str:\n    # Serialize lists of ints (possibly nested) with no spaces\n    if isinstance(obj, list):\n        return \"[\" + \",\".join(serialize_no_spaces(x) for x in obj) + \"]\"\n    elif isinstance(obj, bool):\n        return \"true\" if obj else \"false\"\n    elif isinstance(obj, (int, float)):\n        # For floats, ensure a consistent representation (not used here)\n        return str(obj)\n    else:\n        # Fallback for other simple types\n        return str(obj)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Each case: (S, W, tau1, tau2)\n        (\"ACDEFGHIKLMAAAAAAAAAAACDEFGHIKLM\", 12, 1.8, 2.2),\n        (\"ACDEFGHIKLMNPQRSTVWY\", 12, 1.8, 2.2),\n        (\"AAAAACCCCC\", 12, 1.8, 2.2),\n        (\"AAAAAAAAAAAACDEFGHIKLMN\", 12, 1.8, 2.2),\n        (\"ACDEFGHIKLMKKKKKKKKKKCDEFGHIKLMAAAAAAAA\", 12, 1.8, 2.2),\n    ]\n\n    results = []\n    for S, W, tau1, tau2 in test_cases:\n        masked = seg_mask_indices(S, W, tau1, tau2)\n        results.append(masked)\n\n    # Final print statement in the exact required format (no spaces).\n    print(serialize_no_spaces(results))\n\nsolve()\n```"
        },
        {
            "introduction": "An algorithm is only as good as our understanding of its behavior. In this final practice, you will take on the role of an algorithm developer and create a benchmark to test the LCR filter you have conceptualized. You will write a program to generate synthetic DNA sequences with tunable complexity, from perfectly random to highly repetitive, and measure how a filter responds . This exercise provides invaluable insight into algorithm validation, a critical skill for any computational biologist.",
            "id": "2390167",
            "problem": "You are asked to formalize and implement a principled generator of synthetic Deoxyribonucleic Acid (DNA) sequences with a tunable complexity level, and to quantify how a simple low-complexity region (LCR) filter responds to the generated sequences. The purpose is to create a reproducible benchmark for filtering low-complexity regions in computational biology and bioinformatics. Your program must generate sequences using a probabilistic model tied to a parameter that controls repetitiveness and then evaluate the sequences with a sliding-window Shannon entropy filter.\n\nBase definitions and requirements:\n- Consider the nucleotide alphabet $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$. A DNA sequence is a string over this alphabet of length $L$.\n- The Low-Complexity Region (LCR) filter will be based on Shannon entropy. For any window with empirical base frequencies $\\{p_{\\mathrm{A}},p_{\\mathrm{C}},p_{\\mathrm{G}},p_{\\mathrm{T}}\\}$, define the Shannon entropy $H$ in bits as\n$$\nH \\equiv - \\sum_{b \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}} p_b \\log_2 p_b,\n$$\nwith the convention that terms with $p_b=0$ contribute $0$ to the sum. The maximum per-window entropy for a uniform distribution over $4$ nucleotides is $2$ bits.\n- A position is considered masked if there exists at least one window covering that position with entropy $H < \\tau$, where $\\tau$ is a user-specified entropy threshold (in bits). The fraction of masked positions is defined as the number of masked indices divided by $L$ and must be reported as a decimal in $[0,1]$.\n- Windows are extracted as follows. If $L \\ge w$, slide a window of length $w$ with stride $1$ from the start to the end, producing $(L-w+1)$ windows. If $L < w$, define a single window consisting of the entire sequence (of length $L$). The average per-window entropy is the arithmetic mean of $H$ across all evaluated windows in this manner.\n\nSequence generator with tunable complexity:\n- Let $\\lambda \\in [0,1]$ parameterize the repetitiveness. The generator is a mixture of a deterministic repeating-motif source and a uniform independent and identically distributed (i.i.d.) source, blended at the per-position level.\n- Fix an integer motif length $m \\ge 1$. First, sample a motif $M$ of length $m$ by drawing each nucleotide independently and uniformly from $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$. Then, for each position $i \\in \\{0,1,\\dots,L-1\\}$:\n    - With probability $\\lambda$, emit $M[i \\bmod m]$.\n    - With probability $(1-\\lambda)$, emit an i.i.d. uniform nucleotide from $\\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}$.\n- Intuition: $\\lambda = 0$ yields a maximally random i.i.d. uniform sequence, and $\\lambda = 1$ yields an almost perfectly repetitive sequence determined by $M$ (aside from the initial sampling of $M$).\n- To ensure reproducibility, all random draws (motif sampling and i.i.d. emissions) must be performed with a fixed pseudorandom number generator seed set to $s=12345$ at the beginning of the program, and the generator must not be reseeded between test cases.\n\nWhat you must implement:\n- Implement the generator described above.\n- Implement the sliding-window Shannon entropy computation and the masking rule as defined above.\n- For each test case, generate the sequence and compute:\n    1. The average per-window Shannon entropy (in bits).\n    2. The fraction of masked positions (decimal in $[0,1]$).\n- Round both quantities to $4$ decimal places.\n\nTest suite:\nYour program must run the following test cases in order. Each case is a tuple $(L,\\lambda,m,w,\\tau)$:\n- Case $1$: $(500, 0.0, 3, 50, 1.5)$\n- Case $2$: $(500, 1.0, 2, 50, 1.5)$\n- Case $3$: $(500, 0.5, 3, 50, 1.5)$\n- Case $4$: $(257, 0.8, 7, 25, 1.2)$\n- Case $5$: $(120, 0.3, 1, 10, 1.8)$\n- Case $6$: $(1, 1.0, 1, 1, 0.1)$\n\nFinal output format:\n- Your program should produce a single line of output containing a list of length $6$. Each element is a list of the form $[E,F]$, where $E$ is the average per-window entropy (rounded to $4$ decimals) and $F$ is the fraction of masked positions (rounded to $4$ decimals) for the corresponding test case.\n- The output must be exactly one line in the format:\n\"[ [E1,F1],[E2,F2],...,[E6,F6] ]\"\n- Values must be rounded to $4$ decimal places. Fractions must be decimals in $[0,1]$.\n\nScientific grounding and constraints:\n- Use the definition of Shannon entropy and empirical base frequencies as stated. This is a standard, well-tested measure that connects to complexity in sequences.\n- Use the described mixture generator to realize a tunable complexity spectrum grounded in probability theory and information theory.\n- Ensure all computations are numerically stable and logically consistent with the definitions above.",
            "solution": "The problem presented is a well-posed exercise in computational sequence analysis. It is scientifically grounded, free of contradiction, and all terms are clearly defined. We shall proceed with its formal solution. The objective is to construct a synthetic data generator for Deoxyribonucleic Acid (DNA) sequences with tunable complexity and to measure the response of a standard low-complexity region (LCR) filter.\n\nFirst, we address the sequence generation procedure. A DNA sequence is a string of length $L$ over the alphabet $\\mathcal{A} = \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$. The generator is a probabilistic mixture model controlled by a parameter $\\lambda \\in [0, 1]$. This parameter dictates the probability of drawing a nucleotide from a periodic, deterministic source versus an independent and identically distributed (i.i.d.) uniform random source.\n\nThe algorithm for generating a sequence is as follows:\n$1$. A fixed integer seed, $s = 12345$, is used to initialize a pseudorandom number generator (RNG). This ensures reproducibility.\n$2$. A motif sequence, $M$, of a given integer length $m \\ge 1$ is generated. Each of the $m$ nucleotides in $M$ is sampled independently and uniformly from $\\mathcal{A}$.\n$3$. The final sequence $S$ of length $L$ is constructed position by position. For each index $i \\in \\{0, 1, \\dots, L-1\\}$:\n    a. A random variate $u$ is drawn from the uniform distribution on $[0, 1)$.\n    b. If $u < \\lambda$, the nucleotide at position $i$ of the sequence, $S[i]$, is assigned the value from the motif: $S[i] \\leftarrow M[i \\bmod m]$. This is the deterministic component.\n    c. If $u \\ge \\lambda$, the nucleotide $S[i]$ is assigned a new value sampled independently and uniformly from $\\mathcal{A}$. This is the i.i.d. random component.\n\nA value of $\\lambda = 0$ results in a purely i.i.d. sequence, exhibiting maximal complexity. Conversely, $\\lambda = 1$ generates a sequence that is a perfect repetition of the motif $M$, representing minimal complexity. Values of $\\lambda$ between $0$ and $1$ interpolate between these two extremes.\n\nNext, we formalize the method for LCR analysis using Shannon entropy. For any subsequence (a window), we first compute the empirical frequencies of the four nucleotides. Let a window of length $W_{\\text{len}}$ contain $n_b$ occurrences of base $b \\in \\mathcal{A}$. The empirical probability, or frequency, is $p_b = n_b / W_{\\text{len}}$. The Shannon entropy $H$ of this window, measured in bits, is given by the formula:\n$$\nH = - \\sum_{b \\in \\{\\mathrm{A},\\mathrm{C},\\mathrm{G},\\mathrm{T}\\}} p_b \\log_2 p_b\n$$\nBy convention, any term where $p_b = 0$ evaluates to $0$, since $\\lim_{p \\to 0^+} p \\log_2 p = 0$. The maximum possible entropy for this alphabet is $H_{\\text{max}} = \\log_2(4) = 2$ bits, corresponding to a uniform distribution where $p_b = 1/4$ for all $b$. Low entropy values, approaching $0$, indicate a lack of diversity, i.e., low complexity.\n\nThe analysis of the full sequence $S$ proceeds via a sliding window approach. A window is a subsequence of length $w$.\n- If the sequence length $L$ is greater than or equal to the window length $w$ ($L \\ge w$), we slide a window with a stride of $1$. This produces a set of $N_{\\text{win}} = L - w + 1$ overlapping windows. The $j$-th window, for $j \\in \\{0, 1, \\dots, L-w\\}$, corresponds to the subsequence $S[j \\dots j+w-1]$.\n- If $L < w$, the analysis is performed on a single window comprising the entire sequence $S$. In this case, $N_{\\text{win}} = 1$.\n\nFor each of the $N_{\\text{win}}$ windows, we compute its Shannon entropy $H_j$. Two metrics are then derived:\n$1$. The average per-window Shannon entropy, $\\bar{H}$, is the arithmetic mean of the individual window entropies:\n$$\n\\bar{H} = \\frac{1}{N_{\\text{win}}} \\sum_{j=0}^{N_{\\text{win}}-1} H_j\n$$\n$2$. The fraction of masked positions, $F$. A position $i$ in the sequence $S$ is defined as \"masked\" if it is part of at least one window whose entropy $H_j$ is below a specified threshold $\\tau$. Let $W_j$ be the set of indices covered by the $j$-th window. A position $i$ is masked if there exists a $j$ such that $i \\in W_j$ and $H_j < \\tau$. The fraction $F$ is the total count of unique masked positions divided by the total sequence length $L$.\n\nTo implement this, we create a boolean array, `is_masked`, of length $L$, initialized to `False`. For each window $j$ starting at index $j_{start}$ of length $w'$, if its entropy $H_j < \\tau$, we set `is_masked` from index $j_{start}$ to $j_{start} + w' - 1$ to `True`. The final fraction is the sum of this boolean array divided by $L$.\n\nThe implementation will process each test case $(L, \\lambda, m, w, \\tau)$ by first generating the sequence according to the probabilistic model, then calculating the window entropies, and finally computing $\\bar{H}$ and $F$. All random operations will use the single, persistent RNG instance initialized with the specified seed $s=12345$. The final numerical results for $\\bar{H}$ and $F$ must be rounded to $4$ decimal places.\n\nThis entire procedure is algorithmically explicit and computationally feasible, providing a correct and reproducible solution to the problem as stated.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import entropy as shannon_entropy\n\ndef solve():\n    \"\"\"\n    Generates synthetic DNA sequences with tunable complexity and analyzes them\n    with a Shannon entropy-based low-complexity region (LCR) filter.\n    \"\"\"\n    # Initialize the pseudorandom number generator with a fixed seed for reproducibility.\n    # This RNG instance will be used for all random operations across all test cases.\n    RNG = np.random.default_rng(seed=12345)\n    \n    # Define the DNA nucleotide alphabet.\n    ALPHABET = np.array(['A', 'C', 'G', 'T'])\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (L, lambda, m, w, tau)\n    test_cases = [\n        (500, 0.0, 3, 50, 1.5),\n        (500, 1.0, 2, 50, 1.5),\n        (500, 0.5, 3, 50, 1.5),\n        (257, 0.8, 7, 25, 1.2),\n        (120, 0.3, 1, 10, 1.8),\n        (1, 1.0, 1, 1, 0.1),\n    ]\n\n    final_results = []\n    \n    for L, lambda_param, m, w, tau in test_cases:\n        # 1. Sequence Generation\n        \n        # Generate the random motif M of length m.\n        motif = RNG.choice(ALPHABET, size=m)\n\n        # Generate the sequence of length L using the mixture model.\n        sequence = np.empty(L, dtype='<U1')\n        random_draws = RNG.random(size=L)\n        random_bases = RNG.choice(ALPHABET, size=L)\n        for i in range(L):\n            if random_draws[i] < lambda_param:\n                sequence[i] = motif[i % m]\n            else:\n                sequence[i] = random_bases[i]\n        \n        # 2. LCR Analysis: Windowing and Entropy Calculation\n\n        # Extract windows from the sequence.\n        windows = []\n        if L >= w:\n            num_windows = L - w + 1\n            for i in range(num_windows):\n                windows.append(sequence[i:i+w])\n        else:  # L < w\n            num_windows = 1\n            windows.append(sequence)\n\n        # Calculate Shannon entropy for each window.\n        window_entropies = []\n        for win in windows:\n            if len(win) == 0:\n                # This case should not occur with L >= 1.\n                H = 0.0\n            else:\n                # Count base occurrences and compute frequencies.\n                _, counts = np.unique(win, return_counts=True)\n                # scipy.stats.entropy requires a probability distribution.\n                # If a window contains only a subset of ALPHABET, we need to map counts correctly.\n                base_counts = {base: 0 for base in ALPHABET}\n                win_bases, win_counts = np.unique(win, return_counts=True)\n                for base, count in zip(win_bases, win_counts):\n                    base_counts[base] = count\n                \n                probs = np.array(list(base_counts.values())) / len(win)\n                H = shannon_entropy(probs, base=2)\n            \n            window_entropies.append(H)\n        \n        # Calculate the average per-window entropy.\n        avg_entropy = np.mean(window_entropies) if window_entropies else 0.0\n\n        # 3. Masking based on Entropy Threshold\n\n        # Initialize a boolean array to track masked positions.\n        masked_positions = np.zeros(L, dtype=bool)\n        \n        # Determine which sequence positions are masked.\n        if L >= w:\n            window_indices = range(L - w + 1)\n            window_length = w\n        else:\n            window_indices = [0]\n            window_length = L\n\n        for i, H in zip(window_indices, window_entropies):\n            if H < tau:\n                masked_positions[i : i + window_length] = True\n        \n        # Calculate the fraction of masked positions.\n        masked_fraction = np.sum(masked_positions) / L if L > 0 else 0.0\n\n        # Append rounded results for the current test case.\n        rounded_avg_entropy = round(avg_entropy, 4)\n        rounded_masked_fraction = round(masked_fraction, 4)\n        final_results.append([rounded_avg_entropy, rounded_masked_fraction])\n\n    # 4. Final Output Formatting\n    # Construct the output string exactly as specified.\n    result_str = \",\".join([f\"[{E},{F}]\" for E, F in final_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```"
        }
    ]
}