{
    "hands_on_practices": [
        {
            "introduction": "Before diving into the complex statistical aspects of FASTA, it is crucial to understand its foundational computational costs. The algorithm's speed relies on a rapid lookup strategy to find identical short words, or $k$-tuples, which often involves a direct-address table. This exercise tasks you with calculating the memory footprint of this core data structure, providing a tangible understanding of how the choice of word size, $k$, imposes a fundamental hardware constraint on the search . Mastering this calculation reveals the critical trade-off between the specificity of a larger $k$ and its exponentially increasing demand on system memory.",
            "id": "2435282",
            "problem": "In the Fast-All (FASTA) algorithm for database searching, the query indexing step constructs a direct-address lookup table that maps each possible contiguous word of length $k$ (a $k$-tuple) over a finite alphabet of size $A$ to a fixed-size record. Assume the following model for the lookup table: it is a fully allocated array with one entry for every possible $k$-tuple, and each entry stores exactly $b$ bytes (e.g., a pointer or offset), with no compression, pooling, or lazy allocation. The table is constructed identically regardless of the query content.\n\nUsing only these assumptions and basic counting principles, determine the expected total memory usage of the lookup table, expressed as a closed-form function of $A$, $k$, and $b$. Express your final answer in bytes. No rounding is required, and the final result must be a single analytic expression.",
            "solution": "The problem statement is evaluated and found to be valid. It is scientifically grounded, well-posed, and objective. It describes a simplified but valid model of a direct-address lookup table, a fundamental data structure in computer science, as applied in the context of the FASTA algorithm. All parameters required for the solution—the alphabet size $A$, the word length $k$, and the memory size per entry $b$—are explicitly provided. The problem is a straightforward application of basic counting principles.\n\nThe objective is to determine the total memory usage of the lookup table. The total memory $M$ required for a fully allocated array-like data structure is given by the product of the total number of entries, $N$, and the memory required for each entry, which is given as $b$ bytes.\n\n$$M = N \\times b$$\n\nThe problem states that the memory per entry is a fixed size of $b$ bytes.\n\nThe core of the problem is to determine $N$, the total number of entries in the lookup table. The problem specifies that the table has \"one entry for every possible $k$-tuple\" that can be formed from an alphabet of size $A$. A $k$-tuple is a contiguous word of length $k$.\n\nWe can determine the number of unique $k$-tuples using a fundamental counting principle, the rule of product. A word of length $k$ consists of $k$ positions. For each position, there are $A$ possible characters that can be chosen from the alphabet. Since the choice for each position is independent of the choices for all other positions, the total number of unique words is the product of the number of choices for each of the $k$ positions.\n\n$$N = \\underbrace{A \\times A \\times \\dots \\times A}_{k \\text{ times}}$$\n\nThis product is equivalent to $A$ raised to the power of $k$.\n\n$$N = A^{k}$$\n\nThe problem statement asks for the *expected* total memory usage. However, the model provided is deterministic. The table is \"fully allocated\" and its construction is \"identically regardless of the query content\". This means the size of the table is fixed and does not depend on any random variable or the specific input query sequence. Therefore, the expected memory usage is simply its actual, calculated memory usage.\n\nSubstituting the expression for the number of entries $N$ into the equation for total memory $M$, we obtain the final expression.\n\n$$M = A^{k} \\times b$$\n\nThe units are in bytes, as specified by the definition of $b$. The final expression for the total memory usage of the lookup table is a closed-form function of the given parameters $A$, $k$, and $b$.",
            "answer": "$$\\boxed{b A^{k}}$$"
        },
        {
            "introduction": "A key challenge in any database search is distinguishing a true, biologically significant match from a purely random one. FASTA's power comes not just from finding alignments, but from assessing their statistical likelihood. This practice guides you through the process of building a probabilistic model to determine the chance of finding at least one identical $k$-tuple between two random sequences . By working through this derivation, you will develop a firsthand appreciation for the statistical principles that underpin the entire field of sequence similarity searching and quantify the \"noise\" that heuristic algorithms like FASTA are designed to overcome.",
            "id": "2435300",
            "problem": "A word-based database search algorithm identifies initial \"hits\" as exact matches of length-$k$ words ($k$-tuples) between a query and a database sequence. Consider a query sequence of length $m$ and a single contiguous database sequence of length $N$. Assume an alphabet $\\mathcal{A}$ of size $s$ with letters drawn independently and identically distributed (i.i.d.) according to probabilities $\\{p_1, p_2, \\ldots, p_s\\}$, where $\\sum_{j=1}^{s} p_j = 1$. A $k$-tuple match is defined as two length-$k$ substrings, one from the query and one from the database, that are identical letter-by-letter.\n\nAssume:\n- $m \\ge k$ and $N \\ge k$.\n- All letters in both sequences are i.i.d. with the given composition.\n- Outcomes for distinct pairs of $k$-tuples (one from the query and one from the database) are mutually independent.\n\nUnder these assumptions, model the probability that there exists at least one exact $k$-tuple match between the query and the database anywhere along their lengths. Provide your final result as a single closed-form analytic expression in terms of $m$, $N$, $k$, and $\\{p_j\\}_{j=1}^{s}$. Do not simplify numerically.",
            "solution": "The problem statement presented is subjected to validation.\n\n**Step 1: Extract Givens**\n- Query sequence length: $m$\n- Database sequence length: $N$\n- Word length for matching: $k$\n- Alphabet size: $s$\n- Probability distribution for letters: $\\{p_1, p_2, \\ldots, p_s\\}$, where $\\sum_{j=1}^{s} p_j = 1$.\n- Constraints: $m \\ge k$ and $N \\ge k$.\n- Assumption 1: All letters in both sequences are independent and identically distributed (i.i.d.).\n- Assumption 2: Outcomes for distinct pairs of $k$-tuples (one from the query, one from the database) are mutually independent.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is assessed against the required criteria.\n- **Scientifically Grounded:** The problem uses a simplified probabilistic model (i.i.d. sequences) common in introductory bioinformatics for analyzing algorithm performance. While biological sequences exhibit more complex statistical properties, this Bernoulli-like model is a standard theoretical starting point. It is scientifically sound within this modeling context.\n- **Well-Posed:** The problem provides all necessary parameters ($m, N, k, \\{p_j\\}$) and clear conditions to derive a unique mathematical expression for the requested probability.\n- **Objective:** The language is formal and unambiguous.\n- **Flaw Analysis:** The problem does not violate any of the specified flaw conditions. The assumption of mutual independence of outcomes for all $k$-tuple pairs is a strong simplification and deviates from the reality of overlapping $k$-tuples, which create dependencies. However, it is an explicit instruction for the model, not a flaw in the problem statement itself. The problem is thus internally consistent and solvable as stated.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be derived based on the provided framework.\n\nThe objective is to compute the probability of at least one exact $k$-tuple match. It is more direct to first calculate the probability of the complementary event—that there are zero matches—and subtract this from $1$.\n\nLet $E$ be the event of at least one match. We seek $P(E) = 1 - P(E^c)$, where $E^c$ is the event of no matches.\n\nFirst, we determine the probability of a match between a single, arbitrarily chosen $k$-tuple from the query and a single, arbitrarily chosen $k$-tuple from the database. Let this probability be denoted by $p_{match}$.\n\nA match between two $k$-tuples requires that all $k$ pairs of corresponding characters are identical. Due to the i.i.d. assumption for letters, we can first compute the probability, $P_{iden}$, that a single character from the query is identical to a single character from the database. This occurs if both characters are the first letter of the alphabet, or both are the second, and so on.\nGiven the letter probabilities $\\{p_j\\}$, and the independence of the two sequences, this is:\n$$P_{iden} = \\sum_{j=1}^{s} P(\\text{query char is } j \\text{ and db char is } j) = \\sum_{j=1}^{s} P(\\text{query char is } j) \\times P(\\text{db char is } j)$$\n$$P_{iden} = \\sum_{j=1}^{s} p_j \\cdot p_j = \\sum_{j=1}^{s} p_j^2$$\n\nSince the letters within each $k$-tuple are also i.i.d., the probability that two $k$-tuples are identical is the product of the probabilities that each of the $k$ positions match independently.\n$$p_{match} = (P_{iden})^k = \\left(\\sum_{j=1}^{s} p_j^2\\right)^k$$\n\nNext, we must count the total number of such comparisons.\nThe query sequence of length $m$ has $(m-k+1)$ possible starting positions for a $k$-tuple.\nThe database sequence of length $N$ has $(N-k+1)$ possible starting positions for a $k$-tuple.\nThus, the total number of distinct pairs of ($k$-tuple from query, $k$-tuple from database) is:\n$$C = (m-k+1)(N-k+1)$$\n\nThe problem states that the outcomes for these $C$ distinct pairs are mutually independent. This allows us to model the entire search as a series of $C$ independent Bernoulli trials. Each trial is a comparison of a single pair of $k$-tuples, with a 'success' (match) probability of $p_{match}$.\n\nThe event $E^c$ (no matches) corresponds to experiencing $C$ consecutive 'failures'. The probability of a single failure (no match for a given pair) is $(1 - p_{match})$. Due to independence, the probability of all $C$ trials resulting in failure is:\n$$P(E^c) = (1 - p_{match})^C = \\left(1 - \\left(\\sum_{j=1}^{s} p_j^2\\right)^k\\right)^{(m-k+1)(N-k+1)}$$\n\nFinally, the probability of at least one match, $P(E)$, is found by the complement rule:\n$$P(E) = 1 - P(E^c) = 1 - \\left(1 - \\left(\\sum_{j=1}^{s} p_j^2\\right)^k\\right)^{(m-k+1)(N-k+1)}$$\n\nThis is the final analytical expression derived under the stated assumptions.",
            "answer": "$$\n\\boxed{1 - \\left(1 - \\left(\\sum_{j=1}^{s} p_j^2\\right)^k\\right)^{(m-k+1)(N-k+1)}}\n$$"
        },
        {
            "introduction": "To truly understand an algorithm, there is no substitute for building a working model of it. This practice moves from static calculations to a dynamic simulation of FASTA's core logic, challenging you to implement its initial stages in code . You will translate abstract concepts—such as seeding diagonals, calculating an initial score ($init1$), applying a threshold, and preparing for alignment joining—into a functional program. This hands-on coding exercise provides a concrete, operational understanding of how parameter tuning directly impacts the trade-off between sensitivity (keeping true homologous regions) and computational efficiency (filtering out noise).",
            "id": "2435286",
            "problem": "Construct a complete, runnable program that models the trade-off in the Fast Alignment Search Tool (FASTA) between the initial diagonal score (denoted as $init1$) threshold and the number of diagonals that must be stored and joined, under an idealized but mathematically precise setup described below. All computations are purely symbolic and combinatorial; no physical units are involved.\n\nDefinitions and setup:\n\n- Let the nucleotide alphabet be $\\Sigma=\\{\\text{A},\\text{C},\\text{G},\\text{T}\\}$. A sequence is a finite string over $\\Sigma$.\n- Let the query sequence be $Q$ of length $L_Q$, with zero-based indices $i\\in\\{0,1,\\dots,L_Q-1\\}$. Let the subject (database) sequence be $S$ of length $L_S$, with zero-based indices $j\\in\\{0,1,\\dots,L_S-1\\}$.\n- Fix a word length $k\\in\\mathbb{Z}_{\\ge 1}$. A $k$-mer is any contiguous substring of length $k$. For any $i\\in\\{0,1,\\dots,L_Q-k\\}$ and $j\\in\\{0,1,\\dots,L_S-k\\}$, a seed occurs at the pair $(i,j)$ if and only if the $k$-mers are exactly equal, i.e., $Q[i:i+k]=S[j:j+k]$.\n- Define the diagonal offset $d=i-j$. For a fixed diagonal $d\\in\\mathbb{Z}$, let $M_d=\\{i\\in\\{0,1,\\dots,L_Q-k\\}\\mid \\exists j \\text{ with } j=i-d \\text{ and } 0\\le j\\le L_S-k \\text{ such that } Q[i:i+k]=S[j:j+k]\\}$ be the set of query indices participating in seeds on diagonal $d$. Let $|M_d|$ denote its cardinality.\n- Fix a seed reward $s_m\\in\\mathbb{Z}_{\\ge 1}$. Define the initial diagonal score as $init1(d)=s_m\\cdot |M_d|$.\n- Given a threshold $\\tau\\in\\mathbb{Z}_{\\ge 0}$, the retained (stored) diagonal set is $D_{\\tau}=\\{d\\in\\mathbb{Z}\\mid init1(d)\\ge \\tau\\}$, and the number of stored diagonals is $|D_{\\tau}|$.\n- Fix a proximity parameter $\\delta\\in\\mathbb{Z}_{\\ge 0}$. For each retained diagonal $d\\in D_{\\tau}$, sort the elements of $M_d$ increasingly as $i_1<i_2<\\dots<i_{t_d}$. Define the number of join operations contributed by diagonal $d$ as $J_d=\\left|\\{\\ell\\in\\{1,2,\\dots,t_d-1\\}\\mid i_{\\ell+1}-i_\\ell\\le \\delta\\}\\right|$. The total number of joins is $J=\\sum_{d\\in D_{\\tau}}J_d$.\n- For each test case, you are given a set of true homologous diagonals $D^\\star\\subset\\mathbb{Z}$ that encode where known homologous regions align. Define the boolean $B$ to be $\\text{True}$ if and only if $D^\\star\\subseteq D_{\\tau}$, and $\\text{False}$ otherwise.\n\nYour program must, for each test case, compute and return the triple $[|D_{\\tau}|,J,B]$.\n\nTest suite:\n\nUse the following three test cases. In all cases, indices are zero-based, and the diagonal offset is $d=i-j$.\n\n- Test case $1$ (representative case):\n  - $Q=$ \"ACGTGACCTGATCGTACGTA\" (so $L_Q=20$).\n  - $S=$ \"TTTTACGTGACCTGATCGTACGTACCCC\" (so $L_S=28$).\n  - $k=4$, $s_m=1$, $\\tau=8$, $\\delta=5$.\n  - True homologous diagonal set $D^\\star=\\{-4\\}$.\n- Test case $2$ (high threshold boundary where nothing is retained):\n  - Same $Q$ and $S$ as in test case $1$.\n  - $k=4$, $s_m=1$, $\\tau=18$, $\\delta=5$.\n  - $D^\\star=\\{-4\\}$.\n- Test case $3$ (multiple homologous blocks on distinct diagonals):\n  - Let $A_{block}=$ \"ACGTCGATGCTAGTCA\" and $B_{block}=$ \"TGACCTGATCGTAGCA\".\n  - $Q=$ $A_{block}$ + \"GGGG\" + $B_{block}$ (so $L_Q=36$).\n  - $S=$ \"TT\" + $A_{block}$ + \"TTTTTT\" + $B_{block}$ + \"CC\" (so $L_S=42$).\n  - $k=4$, $s_m=1$, $\\tau=10$, $\\delta=5$.\n  - The block $A_{block}$ aligns at offset $d=-2$, and block $B_{block}$ aligns at offset $d=-4$, so $D^\\star=\\{-2,-4\\}$.\n\nRequired final output format:\n\n- Your program must process the three test cases in the order listed above and produce a single line of output containing the list of results, one per test case, where each result is the list $[|D_{\\tau}|,J,B]$ for that test. The line must be a single string representation of the outer list with comma-separated inner lists, for example, \"[[a,b,True],[c,d,False],[e,f,True]]\" with actual computed integers and booleans in place of $a,b,c,d,e,f$.",
            "solution": "The problem statement is a valid, well-posed, and scientifically grounded formulation of a simplified model of the FASTA algorithm's initial stages. It provides a clear, objective, and complete set of definitions and parameters to compute the trade-off between sensitivity (retaining true homologous diagonals) and computational cost (number of stored diagonals and join operations). All terms are rigorously defined, and the data for the test cases are self-contained and consistent. I will therefore proceed with a full solution.\n\nThe solution is constructed by implementing a computational procedure that strictly follows the definitions provided in the problem statement. The algorithm is executed for each test case to compute the required triple $[|D_{\\tau}|, J, B]$. The process is divided into four main logical steps.\n\nFirst, we must identify all seed matches between the query sequence $Q$ of length $L_Q$ and the subject sequence $S$ of length $L_S$. A seed is a perfect match between a $k$-mer from $Q$ and a $k$-mer from $S$. To do this efficiently, we first build a lookup table (a hash map or dictionary) that maps each unique $k$-mer present in the subject sequence $S$ to a list of its starting indices $j$. We then iterate through the query sequence $Q$, extracting each $k$-mer starting at index $i \\in \\{0, 1, \\dots, L_Q - k\\}$. For each query $k$-mer, we use the lookup table to find all matching $k$-mers in $S$. For each match found between a query $k$-mer starting at $i$ and a subject $k$-mer starting at $j$, we calculate the diagonal offset $d = i - j$. We populate a primary data structure, a map where keys are diagonal offsets $d$ and values are lists of the query indices $i$ that contribute seeds to that diagonal. This structure represents the collection of sets $\\{M_d\\}_{d\\in\\mathbb{Z}}$.\n\nSecond, with the `diagonal_matches` map constructed, we compute the initial score for each diagonal and filter them based on the threshold $\\tau$. For each diagonal $d$ that has at least one seed, its score is given by $init1(d) = s_m \\cdot |M_d|$, where $|M_d|$ is the number of seeds on that diagonal and $s_m$ is the seed reward. We then form the retained diagonal set, $D_{\\tau} = \\{d \\in \\mathbb{Z} \\mid init1(d) \\ge \\tau\\}$. The first component of our output is the cardinality of this set, $|D_{\\tau}|$.\n\nThird, we calculate the total number of join operations, $J$. This calculation is performed only on the diagonals retained in the set $D_{\\tau}$. For each such diagonal $d \\in D_{\\tau}$, we retrieve the list of its contributing query indices, $M_d$. This list must be sorted in ascending order to analyze proximity: $i_1 < i_2 < \\dots < i_{t_d}$, where $t_d = |M_d|$. The number of joins for this single diagonal, $J_d$, is the count of adjacent index pairs $(i_\\ell, i_{\\ell+1})$ whose difference is within the proximity parameter $\\delta$, i.e., $i_{\\ell+1} - i_\\ell \\le \\delta$. The total number of joins, $J$, is the summation of these counts over all retained diagonals: $J = \\sum_{d \\in D_{\\tau}} J_d$. This is the second component of our output.\n\nFourth, we perform a validation check against the known homologous regions. The problem provides a set of true homologous diagonals, $D^\\star$. We must determine if our filtering procedure a successfully retained all these essential diagonals. This is formalized by checking if $D^\\star$ is a subset of our computed retained set $D_{\\tau}$. A boolean variable, $B$, is set to True if $D^\\star \\subseteq D_{\\tau}$, and False otherwise. This boolean is the third and final component of our output triple.\n\nBy executing these four steps for each of the provided test cases, we can generate the required output list $[|D_{\\tau}|, J, B]$ for each case and format them as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import defaultdict\n\ndef solve():\n    \"\"\"\n    Main function to solve the FASTA trade-off problem for all test cases.\n    \"\"\"\n\n    def compute_fasta_metrics(Q, S, k, s_m, tau, delta, D_star):\n        \"\"\"\n        Computes the required metrics for a single FASTA test case.\n\n        Args:\n            Q (str): The query sequence.\n            S (str): The subject sequence.\n            k (int): The k-mer length.\n            s_m (int): The seed reward.\n            tau (int): The initial diagonal score threshold.\n            delta (int): The proximity parameter for joining.\n            D_star (list): The list of true homologous diagonals.\n\n        Returns:\n            list: A list containing [|D_tau|, J, B].\n        \"\"\"\n        L_Q = len(Q)\n        L_S = len(S)\n\n        # Step 1: Find all seeds and populate diagonal_matches.\n        # Create a lookup table for k-mer positions in the subject sequence S.\n        kmer_positions_s = defaultdict(list)\n        if L_S >= k:\n            for j in range(L_S - k + 1):\n                kmer = S[j : j + k]\n                kmer_positions_s[kmer].append(j)\n\n        # Find matches by iterating through k-mers in the query sequence Q.\n        diagonal_matches = defaultdict(list)\n        if L_Q >= k:\n            for i in range(L_Q - k + 1):\n                kmer = Q[i : i + k]\n                if kmer in kmer_positions_s:\n                    for j in kmer_positions_s[kmer]:\n                        d = i - j\n                        diagonal_matches[d].append(i)\n\n        # Step 2: Compute initial scores and filter diagonals.\n        D_tau = set()\n        retained_matches = {}\n        for d, M_d in diagonal_matches.items():\n            init1_score = s_m * len(M_d)\n            if init1_score >= tau:\n                D_tau.add(d)\n                retained_matches[d] = M_d\n        \n        num_stored_diagonals = len(D_tau)\n\n        # Step 3: Calculate total number of joins (J).\n        total_joins = 0\n        for d in D_tau:\n            M_d = retained_matches[d]\n            M_d.sort()  # Ensure indices are sorted for proximity check.\n            \n            joins_d = 0\n            if len(M_d) > 1:\n                for idx in range(len(M_d) - 1):\n                    if M_d[idx + 1] - M_d[idx] <= delta:\n                        joins_d += 1\n            total_joins += joins_d\n\n        # Step 4: Check for homologous diagonals.\n        D_star_set = set(D_star)\n        B = D_star_set.issubset(D_tau)\n\n        return [num_stored_diagonals, total_joins, B]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"Q\": \"ACGTGACCTGATCGTACGTA\",\n            \"S\": \"TTTTACGTGACCTGATCGTACGTACCCC\",\n            \"k\": 4, \"s_m\": 1, \"tau\": 8, \"delta\": 5,\n            \"D_star\": [-4]\n        },\n        {\n            \"Q\": \"ACGTGACCTGATCGTACGTA\",\n            \"S\": \"TTTTACGTGACCTGATCGTACGTACCCC\",\n            \"k\": 4, \"s_m\": 1, \"tau\": 18, \"delta\": 5,\n            \"D_star\": [-4]\n        },\n        {\n            \"A_block\": \"ACGTCGATGCTAGTCA\",\n            \"B_block\": \"TGACCTGATCGTAGCA\",\n            \"Q\": \"ACGTCGATGCTAGTCA\" + \"GGGG\" + \"TGACCTGATCGTAGCA\",\n            \"S\": \"TT\" + \"ACGTCGATGCTAGTCA\" + \"TTTTTT\" + \"TGACCTGATCGTAGCA\" + \"CC\",\n            \"k\": 4, \"s_m\": 1, \"tau\": 10, \"delta\": 5,\n            \"D_star\": [-2, -4]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Special handling for TC3 variable names\n        if \"A_block\" in case:\n             case_to_run = {k: v for k, v in case.items() if k not in [\"A_block\", \"B_block\"]}\n        else:\n            case_to_run = case\n\n        result = compute_fasta_metrics(\n            case_to_run[\"Q\"], case_to_run[\"S\"], case_to_run[\"k\"], case_to_run[\"s_m\"], \n            case_to_run[\"tau\"], case_to_run[\"delta\"], case_to_run[\"D_star\"]\n        )\n        results.append(result)\n\n    # Convert results to a string representation for the final output.\n    # The boolean True/False needs to be capitalized as per Python's str() behavior.\n    result_str = \"[\" + \",\".join(map(str, results)) + \"]\"\n    \n    # Final print statement in the exact required format.\n    print(result_str.replace(\"'\", \"\"))\n\n# Corrected call to main function\ndef main():\n    solve()\n\nif __name__ == \"__main__\":\n    # In a real environment, you'd call main()\n    # For this structure, solve() is called directly.\n    # But let's create a main() for good practice and call it.\n    \n    # The provided code had an issue with calling solve. Let's fix it.\n    # The `solve` function is defined and then called. The test case data structure has to be handled properly.\n    \n    # Reworking the solution to be self-contained and correct.\n    test_cases = [\n        {\n            \"Q\": \"ACGTGACCTGATCGTACGTA\",\n            \"S\": \"TTTTACGTGACCTGATCGTACGTACCCC\",\n            \"k\": 4, \"s_m\": 1, \"tau\": 8, \"delta\": 5,\n            \"D_star\": [-4]\n        },\n        {\n            \"Q\": \"ACGTGACCTGATCGTACGTA\",\n            \"S\": \"TTTTACGTGACCTGATCGTACGTACCCC\",\n            \"k\": 4, \"s_m\": 1, \"tau\": 18, \"delta\": 5,\n            \"D_star\": [-4]\n        },\n        {\n            \"Q\": \"ACGTCGATGCTAGTCAGGGGTTGACCTGATCGTAGCA\",\n            \"S\": \"TTACGTCGATGCTAGTCATTTTTTTGACCTGATCGTAGCACC\",\n            \"k\": 4, \"s_m\": 1, \"tau\": 10, \"delta\": 5,\n            \"D_star\": [-2, -4]\n        }\n    ]\n    \n    results = []\n    for case in test_cases:\n        result = compute_fasta_metrics(\n            case[\"Q\"], case[\"S\"], case[\"k\"], case[\"s_m\"], \n            case[\"tau\"], case[\"delta\"], case[\"D_star\"]\n        )\n        results.append(result)\n\n    result_str = str(results).replace(\" \", \"\")\n    print(result_str)\n\nmain()\n```"
        }
    ]
}