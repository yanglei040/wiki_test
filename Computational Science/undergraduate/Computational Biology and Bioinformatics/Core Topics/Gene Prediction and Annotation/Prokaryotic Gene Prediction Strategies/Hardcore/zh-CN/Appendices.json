{
    "hands_on_practices": [
        {
            "introduction": "开放阅读框（Open Reading Frames, ORFs）是基因预测中最基本的信号。然而，仅仅寻找长的ORF是不够的，因为在随机DNA序列中也可能偶然出现。这个练习将指导你基于第一性原理，建立一个概率模型来计算随机基因组中假阳性ORF的期望数量，从而深刻理解为何我们需要更复杂的基因预测策略。",
            "id": "2419180",
            "problem": "给定一个应用于原核生物脱氧核糖核酸（DNA）序列的开放阅读框（ORF）预测的形式化模型。假设一个基因组是基于字母表 $\\{A,C,G,T\\}$ 生成的独立同分布序列，其碱基概率 $p_A$、$p_C$、$p_G$ 和 $p_T$ 的总和为 $1$。在选定的链和阅读框上，开放阅读框（ORF）定义如下：从与阅读框对齐的位置开始，如果三联体是标准起始密码子 $\\{ATG,TTG,GTG\\}$ 之一，则翻译在同一阅读框内逐个密码子进行，直到遇到集合 $\\{TAA,TAG,TGA\\}$ 中的第一个框内终止密码子。ORF 是从起始密码子开始到第一个框内终止密码子之前（不包括终止密码子）的序列。ORF 长度（以密码子为单位）定义为从起始密码子（含）到终止密码子（不含）之间的密码子数量。\n\n一个预测的 ORF 是指任何长度至少达到指定最小长度 $L_{\\min}$（如上文定义的以密码子为单位）的 ORF。一个标准的 ORF 查找器会扫描指定数量的阅读框（$F \\in \\{3,6\\}$）中的所有密码子对齐位置，其中 $F=3$ 表示三个正向阅读框，$F=6$ 表示三个正向阅读框和三个反向互补阅读框。在每个阅读框中，它会独立于其他阅读框评估所有可能的密码子对齐的起始位置。\n\n在这种情况下，将假阳性率（FPR）定义为在一个不含真实基因的基因组中（因此报告的每个 ORF 都是伪的），每兆碱基（即每 $1000000$ 个核苷酸）预测 ORF 的期望数量。在由 $(p_A,p_T,p_G,p_C)$ 指定的独立同分布碱基模型下，您必须从第一性原理出发，精确计算此期望值，并假设基因组非常长，以至于边界效应可以忽略不计。为转换为每兆碱基的数量，使用长度为 $N=1000000$ 个核苷酸的基因组，并且每个阅读框只计算完整的密码子起始位点，即每个阅读框使用 $\\left\\lfloor N/3 \\right\\rfloor$ 个密码子对齐的起始位置。\n\n您的任务是编写一个完整的程序，对于以下参数集的测试套件，计算出每种情况下每兆碱基的伪预测 ORF 的期望数量，并以实数形式返回。每个测试用例指定为 $(p_A,p_T,p_G,p_C,L_{\\min},F)$:\n\n- 测试用例 1：$(0.45,\\,0.40,\\,0.10,\\,0.05,\\,100,\\,6)$。\n- 测试用例 2：$(0.49,\\,0.41,\\,0.06,\\,0.04,\\,50,\\,6)$。\n- 测试用例 3：$(0.40,\\,0.40,\\,0.10,\\,0.10,\\,75,\\,6)$。\n- 测试用例 4：$(0.25,\\,0.25,\\,0.25,\\,0.25,\\,50,\\,6)$。\n- 测试用例 5：$(0.50,\\,0.35,\\,0.10,\\,0.05,\\,30,\\,3)$。\n- 测试用例 6：$(0.50,\\,0.35,\\,0.10,\\,0.05,\\,300,\\,6)$。\n\n要求和约定：\n\n- 在每个测试用例中，碱基概率必须满足 $p_A+p_T+p_G+p_C=1$；所有给定的用例都已满足此条件。\n- 起始密码子集合精确为 $\\{ATG,TTG,GTG\\}$，终止密码子集合精确为 $\\{TAA,TAG,TGA\\}$。\n- 报告每个测试用例中每 $1000000$ 个核苷酸的伪预测 ORF 的期望数量，结果为实数。\n- 最终输出格式：您的程序应生成一行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[x_1,x_2,\\dots,x_6]$），顺序与上述测试用例相同。输出行中不允许有额外的文本或空格。",
            "solution": "问题陈述已经过验证，被认为是有效的。这是一个定义明确、有科学依据的计算生物学问题，需要应用概率论的第一性原理。\n\n目标是计算随机脱氧核糖核酸（DNA）每兆碱基中伪预测开放阅读框（ORF）的期望数量。这个量被定义为假阳性率（FPR）。基因组模型是一个来自字母表 $\\{A, C, G, T\\}$ 的独立同分布（IID）核苷酸序列，其概率由给定的 $p_A$、$p_C$、$p_G$ 和 $p_T$ 决定。\n\n设 $E[N_{\\text{ORF}}]$ 为长度为 $N = 1000000$ 个核苷酸的序列中预测 ORF 的期望数量。一个预测的 ORF 是指长度至少为 $L_{\\min}$ 个密码子的 ORF。ORF 的搜索在 $F$ 个阅读框中进行。\n\n根据期望的线性性，预测 ORF 的总期望数量是在每个可能位置上找到一个预测 ORF 的期望之和。由于序列的独立同分布特性，在任何给定的密码子对齐位置开始一个预测 ORF 的概率是恒定的。\n\n待测试的密码子对齐位置总数是阅读框数 $F$ 与每个阅读框中起始位置数的乘积。对于长度为 $N$ 的序列，单个阅读框中有 $\\lfloor N/3 \\rfloor$ 个不重叠的密码子位置。\n测试位点的数量是 $F \\times \\lfloor N/3 \\rfloor$。\n给定 $N = 1000000$，每个阅读框的位置数为 $\\lfloor 1000000/3 \\rfloor = 333333$。\n\n因此，总期望为：\n$$ E[N_{\\text{ORF}}] = F \\times \\left\\lfloor \\frac{N}{3} \\right\\rfloor \\times P(\\text{predicted ORF}) $$\n其中 $P(\\text{predicted ORF})$ 是在任意一个密码子对齐位置开始一个预测 ORF 的概率。\n\n要在一个给定位置开始一个预测 ORF，必须独立满足两个条件：\n1. 该位置的密码子必须是一个起始密码子。\n2. 由此产生的 ORF 的长度必须至少为 $L_{\\min}$ 个密码子。\n\n让我们计算这些事件的概率。\n起始密码子集合是 $\\mathcal{S} = \\{ATG, TTG, GTG\\}$。起始密码子的概率 $P(\\text{start})$ 是每个起始密码子概率的总和，根据碱基概率 $p_A, p_T, p_G, p_C$ 计算得出：\n$$ P(\\text{start}) = P(ATG) + P(TTG) + P(GTG) $$\n$$ P(\\text{start}) = (p_A \\cdot p_T \\cdot p_G) + (p_T \\cdot p_T \\cdot p_G) + (p_G \\cdot p_T \\cdot p_G) $$\n\n终止密码子集合是 $\\mathcal{T} = \\{TAA, TAG, TGA\\}$。一个随机密码子是终止密码子的概率 $P(\\text{stop})$ 为：\n$$ P(\\text{stop}) = P(TAA) + P(TAG) + P(TGA) $$\n$$ P(\\text{stop}) = (p_T \\cdot p_A \\cdot p_A) + (p_T \\cdot p_A \\cdot p_G) + (p_T \\cdot p_G \\cdot p_A) $$\n一个随机密码子不是终止密码子的概率是 $P(\\text{non-stop}) = 1 - P(\\text{stop})$。\n\nORF 定义为从起始密码子开始到第一个框内终止密码子（不包括）的序列。ORF 的长度是它包含的密码子数量。一个 ORF 的长度要至少为 $L_{\\min}$，意味着起始密码子之后的第一个 $L_{\\min}-1$ 个密码子都必须是非终止密码子。\n起始位置之后的密码子序列是一系列独立的试验。一个 ORF 长度至少为 $L_{\\min}$ 的概率，是 $L_{\\min}-1$ 个密码子序列中不包含终止密码子的概率。\n$$ P(\\text{length} \\ge L_{\\min}) = (P(\\text{non-stop}))^{L_{\\min}-1} = (1 - P(\\text{stop}))^{L_{\\min}-1} $$\n\n在特定位点开始一个预测 ORF 的概率是起始密码子概率与后续 ORF 足够长的概率的乘积：\n$$ P(\\text{predicted ORF}) = P(\\text{start}) \\times P(\\text{length} \\ge L_{\\min}) $$\n$$ P(\\text{predicted ORF}) = P(\\text{start}) \\times (1 - P(\\text{stop}))^{L_{\\min}-1} $$\n\n最后，我们将其代入预测 ORF 总期望数量的表达式中：\n$$ E[N_{\\text{ORF}}] = F \\times \\left\\lfloor \\frac{N}{3} \\right\\rfloor \\times P(\\text{start}) \\times (1 - P(\\text{stop}))^{L_{\\min}-1} $$\n\n代入明确的概率公式和 $N=1000000$ 的值：\n$$ E[N_{\\text{ORF}}] = F \\times 333333 \\times (p_A p_T p_G + p_T^2 p_G + p_G p_T p_G) \\times (1 - (p_T p_A^2 + p_T p_A p_G + p_T p_G p_A))^{L_{\\min}-1} $$\n\n对每个给定的测试用例实施此公式以计算所需的值。",
            "answer": "```python\nimport math\n\ndef solve():\n    \"\"\"\n    Computes the expected number of spurious predicted ORFs per megabase.\n    \"\"\"\n    test_cases = [\n        # (p_A, p_T, p_G, p_C, L_min, F)\n        (0.45, 0.40, 0.10, 0.05, 100, 6),\n        (0.49, 0.41, 0.06, 0.04, 50, 6),\n        (0.40, 0.40, 0.10, 0.10, 75, 6),\n        (0.25, 0.25, 0.25, 0.25, 50, 6),\n        (0.50, 0.35, 0.10, 0.05, 30, 3),\n        (0.50, 0.35, 0.10, 0.05, 300, 6),\n    ]\n\n    results = []\n    \n    # Genome length for calculation (per megabase)\n    N = 1000000\n    \n    # Number of codon-aligned start positions per frame\n    num_positions_per_frame = N // 3\n\n    for case in test_cases:\n        p_A, p_T, p_G, p_C, L_min, F = case\n\n        # Calculate the probability of encountering a start codon {ATG, TTG, GTG}\n        # P(start) = P(ATG) + P(TTG) + P(GTG) = pA*pT*pG + pT*pT*pG + pG*pT*pG\n        p_start = (p_A * p_T * p_G) + (p_T * p_T * p_G) + (p_G * p_T * p_G)\n\n        # Calculate the probability of encountering a stop codon {TAA, TAG, TGA}\n        # P(stop) = P(TAA) + P(TAG) + P(TGA) = pT*pA*pA + pT*pA*pG + pT*pG*pA\n        p_stop = (p_T * p_A * p_A) + (p_T * p_A * p_G) + (p_T * p_G * p_A)\n\n        # The probability of a codon not being a stop codon\n        p_non_stop = 1.0 - p_stop\n\n        # An ORF is predicted if its length is >= L_min. This means the first L_min-1\n        # codons after the start codon must be non-stop codons.\n        # The probability of this event for an ORF is P(non_stop)^(L_min - 1).\n        if L_min > 1:\n            prob_long_enough = p_non_stop ** (L_min - 1)\n        else: # L_min=1 means any start codon is a predicted ORF of sufficient length.\n            prob_long_enough = 1.0\n\n        # The probability of a predicted ORF at a single codon-aligned site\n        # is P(start) * P(length >= L_min).\n        prob_predicted_orf_at_site = p_start * prob_long_enough\n\n        # The total number of sites to check is F * num_positions_per_frame.\n        total_sites = F * num_positions_per_frame\n\n        # By linearity of expectation, the total expected number is num_sites * probability_per_site.\n        expected_orfs = total_sites * prob_predicted_orf_at_site\n        results.append(expected_orfs)\n\n    # Format the final output as a comma-separated list in brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "在认识到简单ORF扫描的局限性后，下一步是利用编码区和非编码区之间固有的统计学差异。本练习将对比两种核心方法：一种是基于特定基序的确定性扫描器，另一种是更强大的概率工具——隐马尔可夫模型（Hidden Markov Model, HMM）。通过实现和评估这两种模型，你将亲身体会如何利用序列的统计特性来更精确地识别基因边界。",
            "id": "2419168",
            "problem": "您的任务是实现并评估两种不同的序列标注模型，用于识别原核生物脱氧核糖核酸 (DNA) 序列中的基因边界。每个序列是基于字母表 $\\{A,C,G,T\\}$ 的字符串。在此，一个基因被定义为正向链上的一个连续编码片段，它起始于集合 $\\{ATG,GTG,TTG\\}$ 中的一个起始密码子，并终止于其后的第一个、来自集合 $\\{TAA,TAG,TGA\\}$ 的终止密码子。起始边界索引定义为起始密码子第一个碱基的从零开始的索引，终止边界索引定义为终止密码子最后一个碱基的从零开始的索引。本问题中所有索引均为从零开始计数。\n\n使用两种模型来预测基因边界，具体如下。\n\n1) 模型 A（概率性双状态一阶模型）：\n\n- 状态：基因间区 ($I$) 和编码区 ($C$)。\n- 初始状态概率：$\\pi_I = 0.8$, $\\pi_C = 0.2$。\n- 状态转移概率：$P(I \\to I) = 0.98$, $P(I \\to C) = 0.02$, $P(C \\to C) = 0.98$, $P(C \\to I) = 0.02$。\n- 在 $\\{A,C,G,T\\}$ 上的发射概率：\n  - 对于 $I$：$P(A|I) = 0.3$, $P(C|I) = 0.2$, $P(G|I) = 0.2$, $P(T|I) = 0.3$。\n  - 对于 $C$：$P(A|C) = 0.2$, $P(C|C) = 0.3$, $P(G|C) = 0.3$, $P(T|C) = 0.2$。\n- 给定一个长度为 $L$ 的序列 $s$，最可能的状态路径 $z_{1:L}$ 是在上述参数下使联合概率最大化的路径。预测的起始边界是路径在位置 $t$ 从 $I$ 转换到 $C$ 的索引 $t$；预测的终止边界是路径在位置 $t$ 从 $C$ 转换到 $I$ 的索引 $t-1$。如果最可能的路径在位置 $L-1$ 以 $C$ 结尾，则预测在索引 $L-1$ 处有一个终止边界。如果它在位置 $0$ 以 $C$ 开始，则预测在索引 $0$ 处有一个起始边界。\n\n2) 模型 B（确定性循环基序驱动的边界检测器）：\n\n- 设 $S = \\{ATG,GTG,TTG\\}$ 为起始密码子集合， $P = \\{TAA,TAG,TGA\\}$ 为终止密码子集合。\n- 为序列 $s$ 定义指示函数：\n  - $m_s(t) = 1$ 如果 $s[t:t+3] \\in S$，否则 $m_s(t) = 0$。此定义适用于 $t \\in \\{0,1,\\ldots,L-3\\}$，对于 $t>L-3$，$m_s(t)=0$。\n  - $m_p(t) = 1$ 如果 $t \\ge 2$ 且 $s[t-2:t+1] \\in P$，否则 $m_p(t) = 0$。\n- 初始化一个二进制的基因内状态 $y_{-1} = 0$。对于 $t$ 从 $0$ 到 $L-1$：\n  - 如果 $y_{t-1} = 0$ 且 $m_s(t) = 1$，则在索引 $t$ 处记录一个起始边界，并设置 $y_t = 1$。\n  - 否则，如果 $y_{t-1} = 1$ 且 $m_p(t) = 1$，则在索引 $t$ 处记录一个终止边界，并设置 $y_t = 0$。\n  - 否则，设置 $y_t = y_{t-1}$。\n- 模型 B 的预测边界集是所有记录的起始和终止索引的集合。\n\n评估指标：\n\n- 对于一个给定序列，设 $B_{\\text{true}}$ 为真实边界索引的集合， $B_{\\text{pred}}$ 为模型预测的边界索引集合。定义真阳性 $TP = |B_{\\text{true}} \\cap B_{\\text{pred}}|$，假阳性 $FP = |B_{\\text{pred}} \\setminus B_{\\text{true}}|$，以及假阴性 $FN = |B_{\\text{true}} \\setminus B_{\\text{pred}}|$。定义精确率 $p = \\frac{TP}{TP+FP}$（当 $TP+FP > 0$ 时），召回率 $r = \\frac{TP}{TP+FN}$（当 $TP+FN > 0$ 时）。F1 分数是 $F1 = \\frac{2pr}{p+r}$（当 $p+r>0$ 时）。特殊情况：如果 $|B_{\\text{true}}| = 0$ 且 $|B_{\\text{pred}}| = 0$，则定义 $F1 = 1$。\n- 对于下面的每个测试用例，计算模型 A 和模型 B 的 F1 分数。将每个 F1 分数表示为四舍五入到三位小数的十进制数。\n\n测试套件：\n\n- 测试用例 1：序列 $s_1 = $ \"AAAGGAGGCCATGAAACCCGGGTTTTAATTT\"。真实的起始边界索引是 $10$（在索引 $10$–$12$ 处的 \"ATG\" 中的 \"A\"），真实的终止边界索引是 $27$（在索引 $25$–$27$ 处的 \"TAA\" 中的最后一个 \"A\"）。因此，$B_{\\text{true},1} = \\{10, 27\\}$。\n- 测试用例 2：序列 $s_2 = $ \"ATGCCCGGGCCCTAGAAAA\"。真实的起始边界索引是 $0$（在索引 $0$–$2$ 处的 \"ATG\" 中的 \"A\"），真实的终止边界索引是 $14$（在索引 $12$–$14$ 处的 \"TAG\" 中的 \"G\"）。因此，$B_{\\text{true},2} = \\{0, 14\\}$。\n- 测试用例 3：序列 $s_3 = $ \"ACACACACACACACACGGCGGCCGCGGCCG\"。在 $s_3$ 中没有来自上述集合的起始或终止密码子，所以 $B_{\\text{true},3} = \\emptyset$。\n\n要求的最终输出格式：\n\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。按顺序为每个测试用例输出一个双元素列表 $[F1_{\\text{A}}, F1_{\\text{B}}]$，其中 $F1_{\\text{A}}$ 是模型 A 的 F1 分数，$F1_{\\text{B}}$ 是模型 B 的 F1 分数，两者都四舍五入到三位小数。例如，总输出必须采用 \"[[a1,b1],[a2,b2],[a3,b3]]\" 的形式，其中每个 $a_i$ 和 $b_i$ 都是四舍五入到三位小数的十进制数。",
            "solution": "所提出的问题是计算生物学领域一个明确定义的练习，特别是在原核生物基因预测方面。它要求实现并评估两种不同的模型来识别基因边界。经过严格的验证过程，该问题被认为是具有科学依据、定义明确且客观的。所有必要的参数、定义和测试用例都已提供，并且没有内部矛盾或逻辑缺陷。评估指标 F1 分数是标准的，其计算（包括指定的边界情况和未定义场景的标准解释）是可行的。因此，该问题是有效的，并将提供一个完整的解决方案。\n\n该解决方案包含两个主要部分：实现预测模型（模型 A 和模型 B），然后使用 F1 分数对照提供的真实数据评估其预测结果。\n\n**模型 A：概率性双状态一阶模型**\n\n该模型是一个隐马尔可夫模型 (HMM)，具有两个状态：基因间区 ($I$) 和编码区 ($C$)。其目标是为给定的 DNA 序列找到最可能的状态序列，并由此推断出基因边界。维特比 (Viterbi) 算法是完成此项任务的标准方法。\n\n该 HMM 由以下参数定义：\n- **状态：** $\\mathcal{S} = \\{I, C\\}$。为方便计算，我们将它们映射到索引 $\\{0, 1\\}$。\n- **观测值（字母表）：** $\\mathcal{O} = \\{A, C, G, T\\}$，映射到索引 $\\{0, 1, 2, 3\\}$。\n- **初始状态概率 ($\\boldsymbol{\\pi}$):** 模型以某一给定状态开始的概率。\n    $$ \\pi_I = P(z_0=I) = 0.8 $$\n    $$ \\pi_C = P(z_0=C) = 0.2 $$\n- **转移概率 ($\\mathbf{A}$):** 从一个状态转移到另一个状态的概率。\n    $$ A = \\begin{pmatrix} P(I|I)  P(C|I) \\\\ P(I|C)  P(C|C) \\end{pmatrix} = \\begin{pmatrix} 0.98  0.02 \\\\ 0.02  0.98 \\end{pmatrix} $$\n- **发射概率 ($\\mathbf{B}$):** 在某一给定状态下观测到特定核苷酸的概率。\n    $$ P(\\text{obs}|I) = \\{P(A|I)=0.3, P(C|I)=0.2, P(G|I)=0.2, P(T|I)=0.3\\} $$\n    $$ P(\\text{obs}|C) = \\{P(A|C)=0.2, P(C|C)=0.3, P(G|C)=0.3, P(T|C)=0.2\\} $$\n\n为避免长序列导致数值下溢，维特比 (Viterbi) 算法在对数空间中实现。设输入序列为 $s$，长度为 $L$，索引从 $0$ 到 $L-1$。\n\n1.  **初始化 ($t=0$):** 对于每个状态 $k \\in \\{I, C\\}$，分数 $\\delta_0(k)$ 是以状态 $k$ 开始并发射第一个观测值 $s_0$ 的对数概率。\n    $$ \\delta_0(k) = \\log(\\pi_k) + \\log(B_k(s_0)) $$\n    初始化一个回溯指针表 $\\psi$：$\\psi_0(k) = 0$。\n\n2.  **递归 ($t=1, \\dots, L-1$):** 对于每个状态 $j \\in \\{I, C\\}$，我们找到在时间 $t$ 结束于状态 $j$ 的最可能路径。\n    $$ \\delta_t(j) = \\max_{i \\in \\{I, C\\}} (\\delta_{t-1}(i) + \\log(A_{ij})) + \\log(B_j(s_t)) $$\n    回溯指针存储使概率最大化的状态 $i$：\n    $$ \\psi_t(j) = \\arg\\max_{i \\in \\{I, C\\}} (\\delta_{t-1}(i) + \\log(A_{ij})) $$\n\n3.  **终止与回溯：** 最可能的最终状态是 $z_{L-1} = \\arg\\max_{k \\in \\{I, C\\}} (\\delta_{L-1}(k))$。路径的其余部分 $z_{L-2}, \\dots, z_0$ 通过回溯指针找到：$z_{t-1} = \\psi_t(z_t)$。\n\n4.  **边界预测：** 根据问题规则扫描得到的维特比 (Viterbi) 路径 $z_0, \\dots, z_{L-1}$ 以识别边界：\n    -   如果 $z_0 = C$，则在索引 $0$ 处预测一个起始边界。\n    -   对于 $t \\in \\{1, \\dots, L-1\\}$，如果 $z_{t-1}=I$ 且 $z_t=C$，则在索引 $t$ 处预测一个起始边界。\n    -   对于 $t \\in \\{1, \\dots, L-1\\}$，如果 $z_{t-1}=C$ 且 $z_t=I$，则在索引 $t-1$ 处预测一个终止边界。\n    -   如果路径以 $z_{L-1}=C$ 结尾，则在索引 $L-1$ 处预测一个终止边界。\n\n**模型 B：确定性循环基序驱动的边界检测器**\n\n该模型是一个简单的有限状态自动机，它扫描序列以寻找起始和终止密码子。其行为是完全确定性的。\n\n-   **状态：** 一个二进制变量 $y_t \\in \\{0, 1\\}$，其中 $y_t=0$ 表示在步骤 $t$ 处于基因间区域，$y_t=1$ 表示处于基因内区域。初始状态为 $y_{-1}=0$。\n-   **密码子集合：** 起始密码子 $S = \\{ATG, GTG, TTG\\}$ 和终止密码子 $P = \\{TAA, TAG, TGA\\}$。\n-   **逻辑：** 模型从索引 $t=0$ 遍历到 $L-1$。在每个位置 $t$，它根据以下规则更新其状态：\n    1.  如果当前状态是基因间区 ($y_{t-1}=0$) 并且一个来自 $S$ 的起始密码子在索引 $t$ 开始 (即 $s[t:t+3] \\in S$)，则在索引 $t$ 处记录一个起始边界，并将状态转换为基因内 ($y_t=1$)。\n    2.  如果当前状态是基因内 ($y_{t-1}=1$) 并且一个来自 $P$ 的终止密码子在索引 $t$ 结束 (即 $s[t-2:t+1] \\in P$)，则在索引 $t$ 处记录一个终止边界，并将状态转换为基因间区 ($y_t=0$)。\n    3.  否则，状态保持不变 ($y_t = y_{t-1}$)。\n-   所有记录的起始和终止索引的集合构成了预测的边界 $B_{\\text{pred}}$。这种自动机结构确保它能找到不重叠、交替出现的起始和终止位点。\n\n**评估指标：F1 分数**\n\n对于每个模型，将其预测的边界集合 $B_{\\text{pred}}$ 与真实的边界集合 $B_{\\text{true}}$ 进行比较。性能通过 F1 分数量化。\n\n-   **计数：**\n    -   真阳性 ($TP$): $|B_{\\text{true}} \\cap B_{\\text{pred}}|$\n    -   假阳性 ($FP$): $|B_{\\text{pred}} \\setminus B_{\\text{true}}|$\n    -   假阴性 ($FN$): $|B_{\\text{true}} \\setminus B_{\\text{pred}}|$\n-   **指标：**\n    -   精确率 ($p$): $p = \\frac{TP}{TP+FP}$ 如果 $TP+FP > 0$，否则 $p=0$。\n    -   召回率 ($r$): $r = \\frac{TP}{TP+FN}$ 如果 $TP+FN > 0$，否则 $r=0$。\n-   **F1 分数：**\n    -   主要公式为 $F1 = \\frac{2pr}{p+r}$ 如果 $p+r > 0$，否则 $F1=0$。\n    -   定义了一个特殊情况：如果 $|B_{\\text{true}}| = 0$ 且 $|B_{\\text{pred}}| = 0$，则 $F1 = 1$。\n\n所提供的 Python 代码实现了这些模型和评估指标，以解决给定的测试用例。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the gene prediction models on test cases and print the results.\n    \"\"\"\n\n    def model_a_predict(s: str) -> set:\n        \"\"\"\n        Predicts gene boundaries using the probabilistic two-state first-order model (Model A).\n        This is an HMM, and the most probable state path is found using the Viterbi algorithm.\n        \"\"\"\n        L = len(s)\n        if L == 0:\n            return set()\n\n        # Model Parameters\n        # States: 0=Intergenic (I), 1=Coding (C)\n        # Observations: 0=A, 1=C, 2=G, 3=T\n        char_to_int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n        obs = np.array([char_to_int[c] for c in s], dtype=int)\n        \n        num_states = 2\n        pi = np.array([0.8, 0.2])\n        A = np.array([[0.98, 0.02], [0.02, 0.98]])\n        B = np.array([[0.3, 0.2, 0.2, 0.3], [0.2, 0.3, 0.3, 0.2]])\n\n        # Use log probabilities for numerical stability\n        log_pi = np.log(pi)\n        log_A = np.log(A)\n        log_B = np.log(B)\n\n        # Viterbi algorithm\n        delta = np.zeros((L, num_states))\n        psi = np.zeros((L, num_states), dtype=int)\n\n        # Initialization step\n        delta[0, :] = log_pi + log_B[:, obs[0]]\n\n        # Recursion step\n        for t in range(1, L):\n            for j in range(num_states):\n                trans_prob = delta[t - 1, :] + log_A[:, j]\n                max_prob_idx = np.argmax(trans_prob)\n                max_prob = trans_prob[max_prob_idx]\n                delta[t, j] = max_prob + log_B[j, obs[t]]\n                psi[t, j] = max_prob_idx\n\n        # Backtracking to find the most probable path\n        path = np.zeros(L, dtype=int)\n        path[L - 1] = np.argmax(delta[L - 1, :])\n        for t in range(L - 2, -1, -1):\n            path[t] = psi[t + 1, path[t + 1]]\n\n        # Boundary extraction from the path\n        B_pred = set()\n        # Rule: If path begins in C, start boundary at 0\n        if path[0] == 1:\n            B_pred.add(0)\n        \n        # Rule: Transitions between states\n        for t in range(1, L):\n            if path[t-1] == 0 and path[t] == 1:  # I -> C transition\n                B_pred.add(t)\n            elif path[t-1] == 1 and path[t] == 0:  # C -> I transition\n                B_pred.add(t-1)\n        \n        # Rule: If path ends in C, stop boundary at L-1\n        if path[L - 1] == 1:\n            B_pred.add(L - 1)\n            \n        return B_pred\n\n    def model_b_predict(s: str) -> set:\n        \"\"\"\n        Predicts gene boundaries using the deterministic recurrent motif-driven detector (Model B).\n        \"\"\"\n        L = len(s)\n        if L == 0:\n            return set()\n        \n        start_codons = {\"ATG\", \"GTG\", \"TTG\"}\n        stop_codons = {\"TAA\", \"TAG\", \"TGA\"}\n        \n        B_pred = set()\n        # y=0: intergenic state, y=1: coding state\n        y = 0 \n        \n        for t in range(L):\n            if y == 0:\n                # Look for a start codon\n                if t + 3 <= L and s[t:t+3] in start_codons:\n                    B_pred.add(t)\n                    y = 1\n            else: # y == 1\n                # Look for a stop codon\n                if t >= 2 and s[t-2:t+1] in stop_codons:\n                    B_pred.add(t)\n                    y = 0\n        return B_pred\n\n    def calculate_f1(B_true: set, B_pred: set) -> float:\n        \"\"\"\n        Calculates the F1-score given true and predicted boundary sets.\n        \"\"\"\n        if not B_true and not B_pred:\n            return 1.0\n\n        tp = len(B_true.intersection(B_pred))\n        fp = len(B_pred.difference(B_true))\n        fn = len(B_true.difference(B_pred))\n\n        # Handle division by zero for precision and recall\n        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n        \n        # Handle division by zero for F1-score\n        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n        \n        return f1\n\n    # Test suite from the problem statement\n    test_cases = [\n        (\"AAAGGAGGCCATGAAACCCGGGTTTTAATTT\", {10, 27}),\n        (\"ATGCCCGGGCCCTAGAAAA\", {0, 14}),\n        (\"ACACACACACACACACGGCGGCCGCGGCCG\", set())\n    ]\n\n    results = []\n    for s, B_true in test_cases:\n        # Model A\n        B_pred_a = model_a_predict(s)\n        f1_a = calculate_f1(B_true, B_pred_a)\n        \n        # Model B\n        B_pred_b = model_b_predict(s)\n        f1_b = calculate_f1(B_true, B_pred_b)\n        \n        results.append([f\"{f1_a:.3f}\", f\"{f1_b:.3f}\"])\n\n    # Format the final output string as specified\n    final_output = \"[\" + \",\".join([f\"[{a},{b}]\" for a, b in results]) + \"]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "现代基因预测流程的强大之处在于其整合多种证据来源的能力，而不仅仅依赖单一信号。最后的这个练习将向你展示如何构建一个朴素贝叶斯分类器，将来自HMM、序列组成、核糖体结合位点等多种特征融合成一个统一的后验概率。为每个预测基因计算一个可信度分数，是筛选最可靠候选基因以供下游分析的关键一步。",
            "id": "2419184",
            "problem": "给定一个概率模型，用以为一个由隐马尔可夫模型 (HMM) 预测的基因指定其作为原核生物基因组中真实蛋白质编码基因的后验概率。对于每个预测的基因，你会观察到一个由五个分量组成的特征向量：一个HMM对数优势评分 $s$、一个编码六聚体对数似然比 $h$、一个核糖体结合位点基序得分 $r$、该基因的鸟嘌呤-胞嘧啶 (GC) 含量 $x \\in (0,1)$，以及起始密码子类别 $c \\in \\{\\text{ATG},\\text{GTG},\\text{TTG},\\text{OTHER}\\}$。设潜类别变量为 $G \\in \\{T,F\\}$，其中 $T$ 表示真实的蛋白质编码基因，$F$ 表示错误的预测。假设在给定 $G$ 的条件下，各特征是条件独立的。\n\n设先验概率为 $P(G=T) = p_0$ 和 $P(G=F) = 1 - p_0$，其中 $p_0 = 0.7$。给定 $G$ 的条件下特征的条件分布规定如下。\n\n- 对于HMM对数优势评分 $s$：\n  - $s \\mid G=T \\sim \\mathcal{N}(\\mu_s^T,\\ (\\sigma_s^T)^2)$，其中 $\\mu_s^T = 5$ 且 $\\sigma_s^T = 2$。\n  - $s \\mid G=F \\sim \\mathcal{N}(\\mu_s^F,\\ (\\sigma_s^F)^2)$，其中 $\\mu_s^F = 0$ 且 $\\sigma_s^F = 2$。\n\n- 对于编码六聚体对数似然比 $h$：\n  - $h \\mid G=T \\sim \\mathcal{N}(\\mu_h^T,\\ (\\sigma_h^T)^2)$，其中 $\\mu_h^T = 2$ 且 $\\sigma_h^T = 1.5$。\n  - $h \\mid G=F \\sim \\mathcal{N}(\\mu_h^F,\\ (\\sigma_h^F)^2)$，其中 $\\mu_h^F = -1$ 且 $\\sigma_h^F = 1.5$。\n\n- 对于核糖体结合位点基序得分 $r$：\n  - $r \\mid G=T \\sim \\mathcal{N}(\\mu_r^T,\\ (\\sigma_r^T)^2)$，其中 $\\mu_r^T = 3$ 且 $\\sigma_r^T = 1$。\n  - $r \\mid G=F \\sim \\mathcal{N}(\\mu_r^F,\\ (\\sigma_r^F)^2)$，其中 $\\mu_r^F = 0$ 且 $\\sigma_r^F = 1.5$。\n\n- 对于GC含量 $x$：\n  - $x \\mid G=T \\sim \\mathrm{Beta}(\\alpha_T,\\ \\beta_T)$，其中 $\\alpha_T = 55$ 且 $\\beta_T = 45$。\n  - $x \\mid G=F \\sim \\mathrm{Beta}(\\alpha_F,\\ \\beta_F)$，其中 $\\alpha_F = 35$ 且 $\\beta_F = 65$。\n\n- 对于起始密码子类别 $c$ (分类变量)：\n  - $P(c=\\text{ATG} \\mid G=T)=0.83$, $P(c=\\text{GTG} \\mid G=T)=0.12$, $P(c=\\text{TTG} \\mid G=T)=0.04$, $P(c=\\text{OTHER} \\mid G=T)=0.01$。\n  - $P(c=\\text{ATG} \\mid G=F)=0.25$, $P(c=\\text{GTG} \\mid G=F)=0.25$, $P(c=\\text{TTG} \\mid G=F)=0.25$, $P(c=\\text{OTHER} \\mid G=F)=0.25$。\n\n使用以下的密度函数和质量函数。\n\n- 对于正态分布， $X \\sim \\mathcal{N}(\\mu,\\ \\sigma^2)$ 的概率密度函数是\n  $$ f_{\\mathcal{N}}(x \\mid \\mu,\\ \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\exp\\!\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right). $$\n\n- 对于贝塔分布， $X \\sim \\mathrm{Beta}(\\alpha,\\ \\beta)$ 的概率密度函数是\n  $$ f_{\\mathrm{Beta}}(x \\mid \\alpha,\\ \\beta) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\ \\beta)}, \\quad \\text{for } x \\in (0,1), $$\n  其中 $B(\\alpha,\\ \\beta) = \\dfrac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$ 且 $\\Gamma(\\cdot)$ 是伽马函数。\n\n- 对于分类变量，其概率质量函数为 $P(c=k \\mid G)=q_k$，其中 $q_k$ 是类别 $k$ 的指定概率。\n\n对于一个观察到的特征向量 $e=(s,h,r,x,c)$，定义类条件似然\n$$ \\ell_T(e) = f_{\\mathcal{N}}(s \\mid \\mu_s^T,\\ \\sigma_s^T) \\cdot f_{\\mathcal{N}}(h \\mid \\mu_h^T,\\ \\sigma_h^T) \\cdot f_{\\mathcal{N}}(r \\mid \\mu_r^T,\\ \\sigma_r^T) \\cdot f_{\\mathrm{Beta}}(x \\mid \\alpha_T,\\ \\beta_T) \\cdot P(c \\mid G=T), $$\n$$ \\ell_F(e) = f_{\\mathcal{N}}(s \\mid \\mu_s^F,\\ \\sigma_s^F) \\cdot f_{\\mathcal{N}}(h \\mid \\mu_h^F,\\ \\sigma_h^F) \\cdot f_{\\mathcal{N}}(r \\mid \\mu_r^F,\\ \\sigma_r^F) \\cdot f_{\\mathrm{Beta}}(x \\mid \\alpha_F,\\ \\beta_F) \\cdot P(c \\mid G=F). $$\n\n使用贝叶斯定理，给定 $e$ 时基因是真实的后验概率为\n$$ P(G=T \\mid e) = \\frac{p_0 \\cdot \\ell_T(e)}{p_0 \\cdot \\ell_T(e) + (1-p_0) \\cdot \\ell_F(e)}. $$\n\n你的任务是编写一个程序，对下面列出的每个测试用例，使用上述模型和定义计算 $P(G=T \\mid e)$。\n\n按所述顺序评估的观测特征向量 $(s,h,r,x,c)$ 测试集：\n- 案例 Alpha: $(6.0,\\,2.5,\\,3.2,\\,0.56,\\,\\text{ATG})$。\n- 案例 Beta: $(3.0,\\,1.0,\\,2.0,\\,0.50,\\,\\text{GTG})$。\n- 案例 Gamma: $(1.0,\\,0.0,\\,0.5,\\,0.45,\\,\\text{TTG})$。\n- 案例 Delta: $(-1.0,\\,-1.5,\\,-0.5,\\,0.20,\\,\\text{OTHER})$。\n- 案例 Epsilon: $(12.0,\\,6.0,\\,6.0,\\,0.58,\\,\\text{ATG})$。\n- 案例 Zeta: $(-5.0,\\,-4.0,\\,-3.0,\\,0.10,\\,\\text{OTHER})$。\n\n最终输出格式：你的程序应生成单行输出，其中包含按上述确切顺序排列的各案例的后验概率，形式为一个由方括号括起来的逗号分隔的十进制数列表，每个值四舍五入到六位小数（例如，[$0.123456$,$0.654321$,$0.500000$,$0.000001$,$0.999999$,$0.250000$])。不应打印任何额外文本。",
            "solution": "该问题要求在给定一组观测特征的情况下，计算一个预测基因为真实蛋白质编码基因的后验概率。这是贝叶斯推断的一个经典应用，具体来说是使用朴素贝葉斯分类器。该模型假设在给定类别标签 $G \\in \\{T, F\\}$（其中 $T$ 表示真实基因，$F$ 表示错误预测）的条件下，特征是条件独立的。\n\n解决方案的核心是贝叶斯定理的应用。在给定证据（特征向量 $e=(s,h,r,x,c)$）的情况下，一个基因为真（$G=T$）的后验概率由下式给出：\n$$ P(G=T \\mid e) = \\frac{P(e \\mid G=T) P(G=T)}{P(e)} $$\n先验概率 $P(G=T)$ 已给出，为 $p_0 = 0.7$。项 $P(e \\mid G=T)$ 是在基因为真的情况下观测到证据 $e$ 的类条件似然。分母 $P(e)$ 是证据的总概率，可以使用全概率定律展开：\n$$ P(e) = P(e \\mid G=T)P(G=T) + P(e \\mid G=F)P(G=F) $$\n将此代入贝叶斯公式，并使用问题陈述中的记法 $\\ell_G(e) = P(e \\mid G)$ 表示似然以及 $P(G=F) = 1-p_0$，我们得到问题陈述中提供的表达式：\n$$ P(G=T \\mid e) = \\frac{p_0 \\cdot \\ell_T(e)}{p_0 \\cdot \\ell_T(e) + (1-p_0) \\cdot \\ell_F(e)} $$\n由于条件独立性假设，类条件似然 $\\ell_G(e)$ 是每个特征的单个概率密度或质量函数的乘积：\n$$ \\ell_G(e) = P(s \\mid G) \\cdot P(h \\mid G) \\cdot P(r \\mid G) \\cdot P(x \\mid G) \\cdot P(c \\mid G) $$\n每个特征的分布都已指定：连续特征 $s, h, r$ 服从正态分布 ($\\mathcal{N}$)，特征 $x$ 服从贝塔分布 ($\\mathrm{Beta}$)，离散特征 $c$ 服从分类分布。\n\n通过乘以概率密度直接计算似然 $\\ell_T(e)$ 和 $\\ell_F(e)$ 可能会导致数值下溢，因为这些值可能非常小。一种标准且稳健的技术是在对数空间中执行计算。对数似然 $L_G(e) = \\ln(\\ell_G(e))$ 是各个对数概率的总和：\n$$ L_G(e) = \\ln(P(s \\mid G)) + \\ln(P(h \\mid G)) + \\ln(P(r \\mid G)) + \\ln(P(x \\mid G)) + \\ln(P(c \\mid G)) $$\n正态分布 $\\mathcal{N}(\\mu, \\sigma^2)$ 的对数概率密度为：\n$$ \\ln(f_{\\mathcal{N}}(z \\mid \\mu, \\sigma)) = -\\ln(\\sigma) - \\frac{1}{2}\\ln(2\\pi) - \\frac{(z-\\mu)^2}{2\\sigma^2} $$\n贝塔分布 $\\mathrm{Beta}(\\alpha, \\beta)$ 的对数概率密度为：\n$$ \\ln(f_{\\mathrm{Beta}}(z \\mid \\alpha, \\beta)) = (\\alpha-1)\\ln(z) + (\\beta-1)\\ln(1-z) - \\ln(B(\\alpha, \\beta)) $$\n其中 $\\ln(B(\\alpha, \\beta)) = \\ln(\\Gamma(\\alpha)) + \\ln(\\Gamma(\\beta)) - \\ln(\\Gamma(\\alpha+\\beta))$。最好使用像 `scipy.stats.norm.logpdf`、`scipy.stats.beta.logpdf` 和 `scipy.special.gammaln` 这样的专用函数来执行这些计算，以保持数值精度。分类变量的对数概率就是其给定概率质量的对数。\n\n为了使用对数似然计算后验概率，我们可以对公式进行代数变换：\n$$ P(G=T \\mid e) = \\frac{p_0 \\ell_T(e)}{p_0 \\ell_T(e) + (1-p_0) \\ell_F(e)} = \\frac{1}{1 + \\frac{(1-p_0) \\ell_F(e)}{p_0 \\ell_T(e)}} $$\n分母中的比率项可以使用对数量之差的指数来表示：\n$$ \\frac{(1-p_0) \\ell_F(e)}{p_0 \\ell_T(e)} = \\exp\\left( \\ln\\left( \\frac{(1-p_0) \\ell_F(e)}{p_0 \\ell_T(e)} \\right) \\right) = \\exp\\left( (\\ln(1-p_0) + L_F(e)) - (\\ln(p_0) + L_T(e)) \\right) $$\n这个变换后的表达式涉及一个 logistic (sigmoid) 函数，该函数在数值上是稳定的，可以减轻溢出或下溢的风险。\n\n计算过程如下：\n对于每个测试用例向量 $e = (s, h, r, x, c)$：\n1.  通过对每个观测特征值的对数概率求和，计算对数似然 $L_T(e)$，使用“真”类（$G=T$）的一组参数。\n2.  类似地，使用“假”类（$G=F$）的参数计算对数似然 $L_F(e)$。\n3.  计算先验几率的对数，$\\ln(1-p_0) - \\ln(p_0)$。\n4.  组合这些项以找到后验优势比的对数：$Z = (\\ln(1-p_0) + L_F(e)) - (\\ln(p_0) + L_T(e))$。\n5.  计算最终的后验概率为 $P(G=T \\mid e) = \\frac{1}{1 + \\exp(Z)}$。\n6.  收集所有测试用例的结果，并格式化为六位小数，以逗号分隔的列表形式呈现。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, beta\n\ndef solve():\n    \"\"\"\n    Computes the posterior probability that a predicted gene is a true\n    protein-coding gene based on a Naive Bayes model.\n    \"\"\"\n    # Define the model parameters for true (T) and false (F) gene classes.\n    # The parameters are for features: s, h, r, x, c.\n    params = {\n        'T': {\n            's': {'mu': 5.0, 'sigma': 2.0},\n            'h': {'mu': 2.0, 'sigma': 1.5},\n            'r': {'mu': 3.0, 'sigma': 1.0},\n            'x': {'alpha': 55.0, 'beta': 45.0},\n            'c': {'ATG': 0.83, 'GTG': 0.12, 'TTG': 0.04, 'OTHER': 0.01}\n        },\n        'F': {\n            's': {'mu': 0.0, 'sigma': 2.0},\n            'h': {'mu': -1.0, 'sigma': 1.5},\n            'r': {'mu': 0.0, 'sigma': 1.5},\n            'x': {'alpha': 35.0, 'beta': 65.0},\n            'c': {'ATG': 0.25, 'GTG': 0.25, 'TTG': 0.25, 'OTHER': 0.25}\n        }\n    }\n    \n    # Prior probability of being a true gene.\n    prior_p0 = 0.7\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (s, h, r, x, c)\n        (6.0, 2.5, 3.2, 0.56, 'ATG'),     # Case Alpha\n        (3.0, 1.0, 2.0, 0.50, 'GTG'),     # Case Beta\n        (1.0, 0.0, 0.5, 0.45, 'TTG'),     # Case Gamma\n        (-1.0, -1.5, -0.5, 0.20, 'OTHER'), # Case Delta\n        (12.0, 6.0, 6.0, 0.58, 'ATG'),    # Case Epsilon\n        (-5.0, -4.0, -3.0, 0.10, 'OTHER')  # Case Zeta\n    ]\n\n    results = []\n    \n    # Pre-compute log of priors for efficiency.\n    log_p0 = np.log(prior_p0)\n    log_1_minus_p0 = np.log(1.0 - prior_p0)\n\n    for s_obs, h_obs, r_obs, x_obs, c_obs in test_cases:\n        # Calculate log-likelihood for the \"True\" class (G=T).\n        # This is the sum of the log-probabilities of each feature given G=T.\n        log_L_T = (\n            norm.logpdf(s_obs, loc=params['T']['s']['mu'], scale=params['T']['s']['sigma']) +\n            norm.logpdf(h_obs, loc=params['T']['h']['mu'], scale=params['T']['h']['sigma']) +\n            norm.logpdf(r_obs, loc=params['T']['r']['mu'], scale=params['T']['r']['sigma']) +\n            beta.logpdf(x_obs, a=params['T']['x']['alpha'], b=params['T']['x']['beta']) +\n            np.log(params['T']['c'][c_obs])\n        )\n\n        # Calculate log-likelihood for the \"False\" class (G=F).\n        # This is the sum of the log-probabilities of each feature given G=F.\n        log_L_F = (\n            norm.logpdf(s_obs, loc=params['F']['s']['mu'], scale=params['F']['s']['sigma']) +\n            norm.logpdf(h_obs, loc=params['F']['h']['mu'], scale=params['F']['h']['sigma']) +\n            norm.logpdf(r_obs, loc=params['F']['r']['mu'], scale=params['F']['r']['sigma']) +\n            beta.logpdf(x_obs, a=params['F']['x']['alpha'], b=params['F']['x']['beta']) +\n            np.log(params['F']['c'][c_obs])\n        )\n\n        # Calculate the posterior probability P(G=T|e) using a numerically stable\n        # formula based on log-likelihoods.\n        # P(T|e) = 1 / (1 + exp(log( (1-p0)l_F / (p0 * l_T) )))\n        # log_ratio = log(1-p0) + log_L_F - (log(p0) + log_L_T)\n        \n        log_joint_T = log_p0 + log_L_T\n        log_joint_F = log_1_minus_p0 + log_L_F\n        \n        # This term is log( P(e, F) / P(e, T) )\n        log_odds_ratio = log_joint_F - log_joint_T\n        \n        posterior_T = 1.0 / (1.0 + np.exp(log_odds_ratio))\n        \n        results.append(posterior_T)\n\n    # Format the final output as a comma-separated list of values rounded to\n    # six decimal places, enclosed in square brackets.\n    formatted_results = [f'{r:.6f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}