{
    "hands_on_practices": [
        {
            "introduction": "The strict molecular clock hypothesis makes a strong, testable prediction about the geometry of a phylogenetic tree. If evolutionary rates are constant across all lineages, then the total evolutionary distance from the common ancestor (the root) to every present-day descendant (the tips) should be identical. This practice  challenges you to translate this theoretical concept into a computational reality by writing a script to determine if a tree is 'ultrametric'—the technical term for this geometric property. Mastering this skill provides a fundamental tool for the initial validation of the strict clock assumption on any given phylogenetic tree.",
            "id": "2435884",
            "problem": "You are given the task of validating the strict Molecular Clock Hypothesis on rooted phylogenetic trees represented in Newick format with branch lengths. Under a strict molecular clock, if all taxa are sampled contemporaneously, the expected number of substitutions per site accumulated from the root to any tip is equal. This is because the instantaneous substitution rate per site, denoted by $r$, is assumed constant through time and across lineages, and branch lengths in such trees represent expected substitutions per site, which are proportional to elapsed time. Therefore, in a rooted tree whose extant tips are contemporaneous, every root-to-tip path length should be equal, up to numerical tolerance.\n\nFundamental base:\n- Under a time-homogeneous Poisson process of substitutions at a constant rate $r$ per site, the expected number of substitutions in an interval of length $t$ is $rt$. In a rooted tree with contemporaneous tips, the elapsed time from the root to each tip is the same, say $T$, so the expected total substitutions along a root-to-tip path is $rT$. Since branch lengths encode expected substitutions per site, the sum of branch lengths along any root-to-tip path should be equal across all tips for a strict molecular clock tree.\n\nDefinitions for this task:\n- A rooted, weighted tree in Newick format defines a set of leaves (tips) with labels, and each edge carries a nonnegative length equal to the expected substitutions per site for that edge.\n- For each leaf $i$, let $L_i$ be the total root-to-tip length, defined as the sum of branch lengths along the unique path from the root to that leaf.\n- Given a nonnegative tolerance $\\epsilon$, the tree is declared ultrametric if $\\max_i L_i - \\min_i L_i \\le \\epsilon$.\n- If the tree is not ultrametric, define the median root-to-tip length $\\tilde{L}$ as the median of $\\{L_i\\}$. The most non-clock-like lineage is the tip whose absolute deviation $|L_i - \\tilde{L}|$ is maximized. In case of a tie, choose the lineage whose label is lexicographically smallest.\n- To make the output machine-checkable without strings, define an index map for leaves as follows: list all leaf labels, sort them lexicographically in ascending order, and assign indices $0,1,2,\\dots$ in that order. Report the index of the most non-clock-like lineage. If the tree is ultrametric, report $-1$ as the lineage index and $0.0$ as the deviation.\n\nYour program must:\n- Parse a rooted Newick tree string with branch lengths into an internal representation. The input strings will be syntactically valid Newick and will always be rooted. You must correctly handle polytomies (nodes with degree greater than $2$), leaves, and internal nodes, each optionally with labels. All branch lengths are nonnegative real numbers, and all leaves have labels.\n- Compute all root-to-tip lengths $\\{L_i\\}$.\n- Decide ultrametricity using the tolerance $\\epsilon$.\n- If not ultrametric, identify the most non-clock-like lineage as defined above and compute its maximum absolute deviation $d^\\star = \\max_i |L_i - \\tilde{L}|$.\n- For each test case, output a triplet `[u,k,d]`, where `u` is a boolean indicating ultrametricity, `k` is the integer lineage index as defined above, and `d` is the float $d^\\star$. If `u` is true, output `k=-1` and `d=0.0`. Round `d` to $6$ decimal places using standard rounding.\n\nAngle units are not applicable. The branch length unit is expected substitutions per site. Output is unitless numerical data as specified above.\n\nTest suite:\nUse the following test cases, each specified as a tuple $(\\text{Newick}, \\epsilon)$.\n- Case $1$ (strictly ultrametric, balanced binary):\n  - Newick: $((A:0.1,B:0.1):0.2,C:0.3);$\n  - $\\epsilon = 10^{-9}$\n- Case $2$ (non-ultrametric, one lineage longer):\n  - Newick: $((A:0.1,B:0.2):0.2,C:0.3);$\n  - $\\epsilon = 10^{-6}$\n- Case $3$ (near ultrametric within tolerance):\n  - Newick: $((A:0.1,B:0.1):0.2,C:0.3000004);$\n  - $\\epsilon = 5\\times 10^{-7}$\n- Case $4$ (single-tip rooted tree):\n  - Newick: $(A:0.5);$\n  - $\\epsilon = 10^{-9}$\n- Case $5$ (rooted polytomy, one slightly longer tip):\n  - Newick: $(A:0.2,B:0.2,C:0.21,D:0.2);$\n  - $\\epsilon = 0.005$\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case result in the order above. Each test case result must itself be a list of the form `[u,k,d]` as specified. For example, an output with two hypothetical cases would look like `[[\\text{True},-1,0.0],[\\text{False},1,0.123456]]`.",
            "solution": "The problem is well-posed, scientifically grounded, and objective. It presents a clear computational task based on the molecular clock hypothesis, a fundamental concept in evolutionary biology. All terms, such as Newick format, root-to-tip length, and ultrametricity, are precisely defined. The inputs, expected outputs, and evaluation criteria, including tie-breaking rules, are specified without ambiguity. The problem is therefore valid and a solution can be constructed.\n\nThe solution is implemented by following a sequence of logical steps:\n1.  **Tree Parsing**: The Newick-formatted string, representing a rooted phylogenetic tree, must be parsed into an appropriate in-memory data structure. A recursive descent parsing strategy is employed. The tree is represented using a `Node` class, where each instance stores its name (if any), the length of the branch leading to it, and references to its parent and children. The parser first splits the children of the root and then recursively calls a function to parse each child's subtree string. This handles nested structures and polytomies correctly.\n\n2.  **Root-to-Tip Length Calculation**: Once the tree is parsed, the root-to-tip distance $L_i$ for each leaf $i$ is calculated. This is achieved by a depth-first traversal starting from the root of the tree. The function `_get_root_to_tip_lengths` recursively traverses the tree, accumulating the sum of branch lengths along each path. When a leaf is reached, its name and total path length are stored. The result is a collection of pairs $(name_i, L_i)$ for all leaves in the tree.\n\n3.  **Ultrametricity Test**: The molecular clock hypothesis implies that in a perfectly clock-like tree with contemporaneous tips, all root-to-tip paths should have equal length. This property is known as ultrametricity. To test this, we compute the difference between the maximum and minimum root-to-tip lengths, $\\max_i L_i - \\min_i L_i$. If this difference is less than or equal to the given tolerance $\\epsilon$, the tree is considered ultrametric. In this case, the result is recorded as ultrametric ($u=\\text{True}$), with a lineage index $k=-1$ and deviation $d=0.0$ as per the problem specification.\n\n4.  **Non-ultrametric Analysis**: If the tree fails the ultrametricity test ($\\max_i L_i - \\min_i L_i > \\epsilon$), it is declared non-ultrametric ($u=\\text{False}$). According to the problem definition, we must identify the most non-clock-like lineage. This involves the following steps:\n    a.  Calculate the median root-to-tip length, $\\tilde{L}$, from the set of all $\\{L_i\\}$. The `numpy.median` function is used for this calculation, which correctly handles both odd and even numbers of elements.\n    b.  For each leaf $i$, compute the absolute deviation of its path length from the median: $|L_i - \\tilde{L}|$.\n    c.  The maximum of these deviations, $d^\\star = \\max_i |L_i - \\tilde{L}|$, is identified. This value, rounded to $6$ decimal places using Python's built-in `round()` function, corresponds to the output value $d$.\n    d.  Identify the lineage(s) corresponding to this maximum deviation. If there is a tie (multiple lineages exhibit the same maximum deviation), the problem specifies a tie-breaking rule: select the lineage whose label is lexicographically smallest.\n    e.  Finally, the index $k$ of this identified lineage must be determined. An index map is created by sorting all leaf labels lexicographically and assigning indices $0, 1, 2, \\dots$. The index of the chosen lineage's label in this sorted list is the value $k$.\n\n5.  **Output Generation**: For each test case, a triplet $[u,k,d]$ is generated. These triplets are collected into a list. The final output is a single string representing a list of these result-triplets, formatted exactly as specified, e.g., `[[True,-1,0.0],[False,1,0.100000]]`.",
            "answer": "```python\nimport numpy as np\n\nclass Node:\n    \"\"\"Represents a node in a phylogenetic tree.\"\"\"\n    def __init__(self, name=\"\", length=0.0):\n        self.name = name\n        self.length = length  # Branch length from parent to this node\n        self.parent = None\n        self.children = []\n\n    def add_child(self, child):\n        self.children.append(child)\n        child.parent = self\n\ndef _split_newick_children(s: str) -> list[str]:\n    \"\"\"Splits a Newick string section into its top-level children.\"\"\"\n    if not s:\n        return []\n    children = []\n    paren_level = 0\n    start = 0\n    for i, char in enumerate(s):\n        if char == '(':\n            paren_level += 1\n        elif char == ')':\n            paren_level -= 1\n        elif char == ',' and paren_level == 0:\n            children.append(s[start:i])\n            start = i + 1\n    children.append(s[start:])\n    return children\n\ndef _parse_newick_string(s: str) -> Node:\n    \"\"\"Recursively parses a Newick string component into a Node object.\"\"\"\n    s = s.strip()\n    \n    # Check for internal node syntax (e.g., (...)label:length)\n    if s.startswith('(') and s.endswith(')'):\n        # This is a special case of a whole subtree being passed without label/length\n        content = s[1:-1]\n        node = Node()\n        children_strings = _split_newick_children(content)\n        for child_s in children_strings:\n            child_node = _parse_newick_string(child_s)\n            node.add_child(child_node)\n        return node\n    \n    label_part = \"\"\n    length_part = \"\"\n    content = \"\"\n\n    last_paren = s.rfind(')')\n    if last_paren != -1: # Internal node\n        content = s[1:last_paren]\n        label_len_part = s[last_paren+1:]\n        if ':' in label_len_part:\n            label_part, length_part = label_len_part.split(':', 1)\n        else:\n            label_part = label_len_part\n    else: # Leaf node\n        if ':' in s:\n            label_part, length_part = s.split(':', 1)\n        else:\n            label_part = s\n    \n    name = label_part.strip()\n    length = float(length_part) if length_part else 0.0\n    \n    node = Node(name=name, length=length)\n\n    if last_paren != -1: # If internal, parse its children\n        children_strings = _split_newick_children(content)\n        for child_s in children_strings:\n            child_node = _parse_newick_string(child_s)\n            node.add_child(child_node)\n            \n    return node\n\ndef parse_newick(newick_str: str) -> Node:\n    \"\"\"Parses a full Newick string into a tree of Node objects.\"\"\"\n    if newick_str.endswith(';'):\n        newick_str = newick_str[:-1]\n    \n    root = _parse_newick_string(newick_str)\n    return root\n\ndef _get_root_to_tip_lengths(node: Node, current_length: float, lengths: dict):\n    \"\"\"Recursively traverses the tree to calculate all root-to-tip lengths.\"\"\"\n    path_len = current_length + node.length\n\n    if not node.children:  # It's a leaf\n        if node.name:\n            lengths[node.name] = path_len\n        return\n\n    for child in node.children:\n        _get_root_to_tip_lengths(child, path_len, lengths)\n\ndef process_tree(newick_str: str, epsilon: float) -> list:\n    \"\"\"Processes a single tree to check for ultrametricity and non-clock-like lineages.\"\"\"\n    root = parse_newick(newick_str)\n    \n    leaf_lengths = {}\n    _get_root_to_tip_lengths(root, 0.0, leaf_lengths)\n    \n    if not leaf_lengths:\n        return [True, -1, 0.0]\n\n    lengths = list(leaf_lengths.values())\n    max_len = max(lengths)\n    min_len = min(lengths)\n\n    if max_len - min_len <= epsilon:\n        return [True, -1, 0.0]\n    else: # Not ultrametric\n        u = False\n        median_l = np.median(lengths)\n        \n        deviations = {name: abs(length - median_l) for name, length in leaf_lengths.items()}\n        \n        max_deviation = -1.0\n        for dev in deviations.values():\n            if dev > max_deviation:\n                max_deviation = dev\n        \n        # Tie-breaking: find all candidates with max deviation, then choose lexicographically smallest name\n        candidates = []\n        # Use a small tolerance for floating point comparison\n        for name, dev in deviations.items():\n            if abs(dev - max_deviation) < 1e-12:\n                candidates.append(name)\n        \n        chosen_lineage = sorted(candidates)[0]\n        \n        sorted_labels = sorted(leaf_lengths.keys())\n        k = sorted_labels.index(chosen_lineage)\n        \n        d = round(max_deviation, 6)\n        \n        return [u, k, d]\n\n\ndef solve():\n    \"\"\"Main function to run the test suite and format the output.\"\"\"\n    test_cases = [\n        (\"((A:0.1,B:0.1):0.2,C:0.3);\", 1e-9),\n        (\"((A:0.1,B:0.2):0.2,C:0.3);\", 1e-6),\n        (\"((A:0.1,B:0.1):0.2,C:0.3000004);\", 5e-7),\n        (\"(A:0.5);\", 1e-9),\n        (\"(A:0.2,B:0.2,C:0.21,D:0.2);\", 0.005)\n    ]\n\n    results = []\n    for newick_str, epsilon in test_cases:\n        result = process_tree(newick_str, epsilon)\n        results.append(result)\n\n    formatted_results = []\n    for res in results:\n        u, k, d = res\n        # Manual formatting to match problem example (no spaces, Python bool literals)\n        formatted_results.append(f\"[{u},{k},{d}]\")\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While checking for perfect ultrametricity is a useful first step, real biological data is inherently noisy. We need a statistical framework to determine if observed differences in root-to-tip distances are significant or just due to random chance. The relative rate test is a classic and powerful method for this purpose, allowing you to formally compare the evolutionary rates of two closely related lineages against a more distant outgroup. This exercise  guides you through implementing a modern version of this test using paralinear distances, which cleverly corrects for confounding factors like differing nucleotide compositions, providing a robust tool for hypothesis testing in molecular evolution.",
            "id": "2435873",
            "problem": "You are given a triplet of taxa denoted $A$, $B$, and an outgroup $O$, together with aligned site-pattern counts summarized as two joint contingency tables for each test case: a $4 \\times 4$ matrix $C_{AO}$ for the pair $(A,O)$ and a $4 \\times 4$ matrix $C_{BO}$ for the pair $(B,O)$. The rows correspond to the nucleotides $\\{A,C,G,T\\}$ for the first taxon in the pair, and the columns correspond to the nucleotides $\\{A,C,G,T\\}$ for the second taxon. Each entry is a nonnegative integer count. Assume sites evolve independently under an arbitrary time-homogeneous, stationary but otherwise unrestricted continuous-time Markov substitution process on nucleotides (the general Markov model). Let $\\epsilon>0$ denote a fixed pseudocount to be added to each cell before forming probabilities to avoid undefined logarithms for zero cells. Let $\\alpha \\in (0,1)$ denote a significance level, $B \\in \\mathbb{N}$ a bootstrap replicate count, and $s \\in \\mathbb{N}$ a random seed.\n\nDefine the empirical joint probability matrix for a pair $(X,O)$ as\n$$\n\\hat{P}_{XO} \\;=\\; \\frac{C_{XO} + \\epsilon \\mathbf{1}_{4 \\times 4}}{\\sum_{i=1}^{4}\\sum_{j=1}^{4}\\left(C_{XO}[i,j] + \\epsilon\\right)},\n$$\nwhere $\\mathbf{1}_{4 \\times 4}$ is the $4 \\times 4$ matrix of ones. Define the marginal frequency vectors\n$$\n\\hat{p}_X(i) \\;=\\; \\sum_{j=1}^{4} \\hat{P}_{XO}[i,j], \\quad \\hat{p}_O(j) \\;=\\; \\sum_{i=1}^{4} \\hat{P}_{XO}[i,j].\n$$\nDefine the paralinear (log-determinant) path length between $X$ and $O$ by\n$$\nd_{\\mathrm{PL}}(X,O) \\;=\\; -\\ln \\det\\!\\left(\\hat{P}_{XO}\\right) \\;+\\; \\frac{1}{2}\\,\\ln\\!\\left(\\prod_{i=1}^{4} \\hat{p}_X(i)\\right) \\;+\\; \\frac{1}{2}\\,\\ln\\!\\left(\\prod_{j=1}^{4} \\hat{p}_O(j)\\right).\n$$\nThe null hypothesis of a strict molecular clock for the ingroup pair $(A,B)$ relative to $O$ is $H_0: d_{\\mathrm{PL}}(A,O) = d_{\\mathrm{PL}}(B,O)$. Consider the test statistic\n$$\n\\Delta \\;=\\; d_{\\mathrm{PL}}(A,O) - d_{\\mathrm{PL}}(B,O).\n$$\n\nEstimate the sampling variability of $\\Delta$ by nonparametric bootstrap over sites as follows: for each pair $(X,O)$ with observed counts $C_{XO}$ and total sites $n_{XO}=\\sum_{i,j}C_{XO}[i,j]$, form the empirical site-pattern distribution\n$$\n\\tilde{P}_{XO} \\;=\\; \\frac{C_{XO}}{n_{XO}}.\n$$\nFor $b=1,\\dots,B$, independently draw bootstrap replicate counts $\\widetilde{C}_{XO}^{(b)} \\sim \\mathrm{Multinomial}\\!\\left(n_{XO}, \\mathrm{vec}\\!\\left(\\tilde{P}_{XO}\\right)\\right)$ for $(A,O)$ and $(B,O)$, where $\\mathrm{vec}$ denotes vectorization into $16$ categories. For each bootstrap replicate, compute $\\Delta^{(b)}$ by replacing $C_{XO}$ with $\\widetilde{C}_{XO}^{(b)}$ in the definition of $d_{\\mathrm{PL}}$ (including the same $\\epsilon$ pseudocount), and estimate the bootstrap standard deviation\n$$\n\\hat{\\sigma} \\;=\\; \\sqrt{\\frac{1}{B-1}\\sum_{b=1}^{B} \\left(\\Delta^{(b)} - \\overline{\\Delta}\\right)^2}, \\quad \\overline{\\Delta} \\;=\\; \\frac{1}{B}\\sum_{b=1}^{B}\\Delta^{(b)}.\n$$\nUse the large-sample normal approximation to form the standardized statistic $Z = \\Delta / \\hat{\\sigma}$ and reject $H_0$ at level $\\alpha$ if $|Z| \\ge z_{1-\\alpha/2}$, where $z_{1-\\alpha/2}$ is the $(1-\\alpha/2)$-quantile of the standard normal distribution. Angles are not involved. No physical units are involved.\n\nYour task is to implement a program that, for each of the following test cases, returns a boolean indicating whether $H_0$ is rejected ($\\mathrm{True}$) or not rejected ($\\mathrm{False}$). The program must use natural logarithms and the exact definitions above. The bootstrap must use the given $B$ and random seed $s$ for reproducibility. The final output must be a single line containing the results for all cases as a comma-separated list enclosed in square brackets; each entry must be either $\\mathrm{True}$ or $\\mathrm{False}$.\n\nTest Suite:\n\n- Case $1$ (balanced, clock-like):\n  - $C_{AO} = \\begin{bmatrix}\n  220 & 10 & 10 & 10\\\\\n  10 & 220 & 10 & 10\\\\\n  10 & 10 & 220 & 10\\\\\n  10 & 10 & 10 & 220\n  \\end{bmatrix}$,\n    $C_{BO} = \\begin{bmatrix}\n  220 & 10 & 10 & 10\\\\\n  10 & 220 & 10 & 10\\\\\n  10 & 10 & 220 & 10\\\\\n  10 & 10 & 10 & 220\n  \\end{bmatrix}$,\n    $\\epsilon = 0.5$, $B = 2000$, $\\alpha = 0.05$, $s = 7$.\n\n- Case $2$ (rate-accelerated $A$):\n  - $C_{AO} = \\begin{bmatrix}\n  150 & 20 & 20 & 20\\\\\n  20 & 150 & 20 & 20\\\\\n  20 & 20 & 150 & 20\\\\\n  20 & 20 & 20 & 150\n  \\end{bmatrix}$,\n    $C_{BO} = \\begin{bmatrix}\n  240 & 5 & 5 & 5\\\\\n  5 & 240 & 5 & 5\\\\\n  5 & 5 & 240 & 5\\\\\n  5 & 5 & 5 & 240\n  \\end{bmatrix}$,\n    $\\epsilon = 0.5$, $B = 2000$, $\\alpha = 0.05$, $s = 13$.\n\n- Case $3$ (boundary: nearly identical to outgroup):\n  - $C_{AO} = \\begin{bmatrix}\n  250 & 0 & 0 & 0\\\\\n  0 & 250 & 0 & 0\\\\\n  0 & 0 & 250 & 0\\\\\n  0 & 0 & 0 & 250\n  \\end{bmatrix}$,\n    $C_{BO} = \\begin{bmatrix}\n  250 & 0 & 0 & 0\\\\\n  0 & 250 & 0 & 0\\\\\n  0 & 0 & 250 & 0\\\\\n  0 & 0 & 0 & 250\n  \\end{bmatrix}$,\n    $\\epsilon = 0.5$, $B = 2000$, $\\alpha = 0.05$, $s = 17$.\n\n- Case $4$ (small-sample, compositionally biased, clock-like):\n  - $C_{AO} = \\begin{bmatrix}\n  35 & 3 & 1 & 1\\\\\n  1 & 7 & 1 & 1\\\\\n  1 & 1 & 4 & 0\\\\\n  1 & 0 & 0 & 3\n  \\end{bmatrix}$,\n    $C_{BO} = \\begin{bmatrix}\n  3 & 0 & 1 & 1\\\\\n  0 & 3 & 1 & 1\\\\\n  1 & 1 & 20 & 3\\\\\n  1 & 1 & 3 & 20\n  \\end{bmatrix}$,\n    $\\epsilon = 0.5$, $B = 2000$, $\\alpha = 0.05$, $s = 19$.\n\nFinal output format: Your program should produce a single line of output containing the four boolean results, as a comma-separated list enclosed in square brackets, in the order of the cases above, for example $[\\mathrm{False},\\mathrm{True},\\mathrm{False},\\mathrm{False}]$.",
            "solution": "The problem is subjected to validation and is found to be scientifically sound, well-posed, and objective. It presents a standard statistical procedure from computational biology for testing the molecular clock hypothesis using log-determinant distances. All necessary data, parameters, and definitions are provided, forming a complete and non-contradictory specification. We therefore proceed with the solution.\n\nThe fundamental task is to implement a hypothesis test for the null hypothesis $H_0: d_{\\mathrm{PL}}(A,O) = d_{\\mathrm{PL}}(B,O)$, where $d_{\\mathrm{PL}}$ is the paralinear distance, a measure of evolutionary divergence that is robust to compositional biases in nucleotide sequences. The test compares the evolutionary distance from taxon $A$ to the outgroup $O$ with the distance from taxon $B$ to the same outgroup $O$. A significant difference between these distances is evidence against a constant rate of evolution (a strict molecular clock) in the lineages leading to $A$ and $B$.\n\nThe procedure is as follows:\n\nFirst, for a given pair of taxa, which we denote generically as $(X,O)$, with an observed joint count matrix $C_{XO}$ of dimension $4 \\times 4$, we compute the paralinear distance. A small positive pseudocount, $\\epsilon$, is added to each cell of $C_{XO}$. This practice, known as additive smoothing, ensures that all subsequent probabilistic quantities are well-defined by preventing zero probabilities, which would lead to undefined logarithms. The resulting matrix is then normalized to form the empirical joint probability matrix $\\hat{P}_{XO}$:\n$$\n\\hat{P}_{XO} \\;=\\; \\frac{C_{XO} + \\epsilon \\mathbf{1}_{4 \\times 4}}{N_{XO}},\n$$\nwhere $\\mathbf{1}_{4 \\times 4}$ is the $4 \\times 4$ matrix of ones and $N_{XO} = \\sum_{i=1}^{4}\\sum_{j=1}^{4}\\left(C_{XO}[i,j] + \\epsilon\\right)$ is the normalization constant. From $\\hat{P}_{XO}$, we derive the marginal nucleotide frequency vectors for taxon $X$ and the outgroup $O$:\n$$\n\\hat{p}_X(i) \\;=\\; \\sum_{j=1}^{4} \\hat{P}_{XO}[i,j] \\quad \\text{and} \\quad \\hat{p}_O(j) \\;=\\; \\sum_{i=1}^{4} \\hat{P}_{XO}[i,j].\n$$\nThe paralinear distance, also known as the log-determinant distance, is then calculated using the formula:\n$$\nd_{\\mathrm{PL}}(X,O) \\;=\\; -\\ln \\det(\\hat{P}_{XO}) \\;+\\; \\frac{1}{2}\\sum_{i=1}^{4}\\ln(\\hat{p}_X(i)) \\;+\\; \\frac{1}{2}\\sum_{j=1}^{4}\\ln(\\hat{p}_O(j)).\n$$\nThis formulation, using a sum of logarithms, is numerically more stable than computing the logarithm of a product of small numbers, as specified in the problem statement, but is mathematically equivalent.\n\nThe test statistic for the clock hypothesis is the difference between the two distances to the outgroup:\n$$\n\\Delta \\;=\\; d_{\\mathrm{PL}}(A,O) - d_{\\mathrm{PL}}(B,O).\n$$\nA value of $\\Delta$ close to zero is consistent with the molecular clock hypothesis, implying that the lineages for $A$ and $B$ have accumulated substitutions at a similar rate since their divergence.\n\nTo assess the statistical significance of the observed value of $\\Delta$, we must estimate its sampling variance. The problem specifies a nonparametric bootstrap approach. This statistical technique involves resampling from the observed data to simulate new datasets. For each pair $(X,O)$, we first determine the total number of aligned sites, $n_{XO} = \\sum_{i,j} C_{XO}[i,j]$, and the empirical distribution of the $16$ possible site patterns (nucleotide pairs), $\\tilde{P}_{XO} = C_{XO} / n_{XO}$. For each of the $B$ bootstrap replicates, we generate a new count matrix $\\widetilde{C}_{XO}^{(b)}$ by drawing $n_{XO}$ samples from a multinomial distribution with parameters $(n_{XO}, \\mathrm{vec}(\\tilde{P}_{XO}))$. This process simulates the re-sampling of columns (sites) with replacement from the original sequence alignment. This is done independently for the $(A,O)$ and $(B,O)$ pairs.\n\nFor each bootstrap replicate $b$, where $b$ ranges from $1$ to $B$, we compute a bootstrap version of the test statistic, $\\Delta^{(b)}$, by applying the entire distance calculation procedure described above to the bootstrap count matrices $\\widetilde{C}_{AO}^{(b)}$ and $\\widetilde{C}_{BO}^{(b)}$. The same pseudocount $\\epsilon$ is used in these calculations.\n\nThe collection of $B$ bootstrap statistics, $\\{\\Delta^{(b)}\\}_{b=1}^{B}$, forms an empirical sampling distribution for $\\Delta$. From this distribution, we calculate the sample standard deviation, which serves as our estimate for the standard error of $\\Delta$:\n$$\n\\hat{\\sigma} \\;=\\; \\sqrt{\\frac{1}{B-1}\\sum_{b=1}^{B} \\left(\\Delta^{(b)} - \\overline{\\Delta}\\right)^2},\n$$\nwhere $\\overline{\\Delta}$ is the arithmetic mean of the bootstrap statistics.\n\nFinally, assuming that $\\Delta$ is approximately normally distributed for large sample sizes (a consequence of the Central Limit Theorem), we construct a standardized test statistic $Z = \\Delta / \\hat{\\sigma}$. This $Z$-score measures how many standard errors the observed $\\Delta$ is from zero. The null hypothesis $H_0$ is rejected at a significance level $\\alpha$ if the absolute value of the observed $Z$-score meets or exceeds the critical value $z_{1-\\alpha/2}$, which is the $(1-\\alpha/2)$-quantile of the standard normal distribution. That is, we reject $H_0$ if $|Z| \\ge z_{1-\\alpha/2}$.\n\nThe algorithm is implemented in Python, utilizing the `numpy` library for numerical linear algebra and statistical computations, and the `scipy.stats` module to obtain the required quantile of the standard normal distribution. For each test case, the random number generator is initialized with the specified seed $s$ to ensure full reproducibility of the bootstrap procedure.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef calculate_dpl(C, epsilon):\n    \"\"\"\n    Calculates the paralinear (log-determinant) distance for a given count matrix.\n    \n    Args:\n        C (np.ndarray): A 4x4 matrix of site-pattern counts.\n        epsilon (float): A positive pseudocount.\n        \n    Returns:\n        float: The paralinear distance d_PL(X,O).\n    \"\"\"\n    C = np.asarray(C, dtype=np.float64)\n    \n    # Add pseudocount and normalize to get the empirical joint probability matrix\n    total_sum = C.sum() + epsilon * C.size\n    P_hat = (C + epsilon) / total_sum\n    \n    # Use slogdet for numerical stability. The determinant of P_hat should be positive.\n    sign, log_det_P = np.linalg.slogdet(P_hat)\n    if sign <= 0:\n        # This is not expected with a positive pseudocount on diagonally-dominant-like matrices.\n        # It would indicate a serious numerical issue or an invalid matrix.\n        # Returning infinity would lead to rejection if this path is taken.\n        return np.inf\n\n    # Calculate marginal frequency vectors\n    p_X = P_hat.sum(axis=1)\n    p_O = P_hat.sum(axis=0)\n    \n    # Calculate sum of logs of marginals\n    log_prod_pX = np.log(p_X).sum()\n    log_prod_pO = np.log(p_O).sum()\n    \n    # Calculate paralinear distance as per the formula\n    d_pl = -log_det_P + 0.5 * log_prod_pX + 0.5 * log_prod_pO\n    \n    return d_pl\n\ndef perform_clock_test(C_AO, C_BO, epsilon, B, alpha, s):\n    \"\"\"\n    Performs the molecular clock test for a triplet of taxa (A, B, O).\n\n    Args:\n        C_AO (np.ndarray): Count matrix for pair (A, O).\n        C_BO (np.ndarray): Count matrix for pair (B, O).\n        epsilon (float): Pseudocount.\n        B (int): Number of bootstrap replicates.\n        alpha (float): Significance level.\n        s (int): Random seed.\n        \n    Returns:\n        bool: True if the null hypothesis is rejected, False otherwise.\n    \"\"\"\n    # Initialize a random number generator with the specified seed for reproducibility\n    rng = np.random.default_rng(s)\n\n    C_AO = np.asarray(C_AO, dtype=np.float64)\n    C_BO = np.asarray(C_BO, dtype=np.float64)\n\n    # Calculate the observed test statistic Delta\n    d_pl_AO_obs = calculate_dpl(C_AO, epsilon)\n    d_pl_BO_obs = calculate_dpl(C_BO, epsilon)\n    delta_obs = d_pl_AO_obs - d_pl_BO_obs\n\n    # Prepare for nonparametric bootstrap\n    n_AO = int(C_AO.sum())\n    p_tilde_AO = C_AO.flatten() / n_AO if n_AO > 0 else np.full(16, 1/16)\n    \n    n_BO = int(C_BO.sum())\n    p_tilde_BO = C_BO.flatten() / n_BO if n_BO > 0 else np.full(16, 1/16)\n\n    # Perform bootstrap resampling\n    delta_bootstraps = np.zeros(B)\n    for b in range(B):\n        # Generate bootstrap replicate counts for AO and BO\n        C_boot_AO_flat = rng.multinomial(n_AO, p_tilde_AO)\n        C_boot_AO = C_boot_AO_flat.reshape((4, 4))\n        \n        C_boot_BO_flat = rng.multinomial(n_BO, p_tilde_BO)\n        C_boot_BO = C_boot_BO_flat.reshape((4, 4))\n        \n        # Compute d_PL for the bootstrap replicate\n        d_pl_AO_boot = calculate_dpl(C_boot_AO, epsilon)\n        d_pl_BO_boot = calculate_dpl(C_boot_BO, epsilon)\n        \n        delta_bootstraps[b] = d_pl_AO_boot - d_pl_BO_boot\n\n    # Calculate the bootstrap standard deviation of Delta\n    sigma_hat = np.std(delta_bootstraps, ddof=1)\n    \n    # Handle the case where standard deviation is effectively zero\n    if sigma_hat < 1e-12:\n        return np.abs(delta_obs) > 1e-12\n\n    # Calculate the standardized Z-statistic\n    Z = delta_obs / sigma_hat\n    \n    # Find the critical value from the standard normal distribution\n    z_crit = norm.ppf(1.0 - alpha / 2.0)\n    \n    # Reject H0 if |Z| is greater than or equal to the critical value\n    rejection = np.abs(Z) >= z_crit\n    \n    return bool(rejection)\n\ndef solve():\n    \"\"\"\n    Defines the test cases and runs the clock test for each, printing the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"C_AO\": np.array([\n                [220, 10, 10, 10], [10, 220, 10, 10], \n                [10, 10, 220, 10], [10, 10, 10, 220]\n            ]),\n            \"C_BO\": np.array([\n                [220, 10, 10, 10], [10, 220, 10, 10], \n                [10, 10, 220, 10], [10, 10, 10, 220]\n            ]),\n            \"epsilon\": 0.5, \"B\": 2000, \"alpha\": 0.05, \"s\": 7\n        },\n        {\n            \"C_AO\": np.array([\n                [150, 20, 20, 20], [20, 150, 20, 20], \n                [20, 20, 150, 20], [20, 20, 20, 150]\n            ]),\n            \"C_BO\": np.array([\n                [240, 5, 5, 5], [5, 240, 5, 5], \n                [5, 5, 240, 5], [5, 5, 5, 240]\n            ]),\n            \"epsilon\": 0.5, \"B\": 2000, \"alpha\": 0.05, \"s\": 13\n        },\n        {\n            \"C_AO\": np.array([\n                [250, 0, 0, 0], [0, 250, 0, 0], \n                [0, 0, 250, 0], [0, 0, 0, 250]\n            ]),\n            \"C_BO\": np.array([\n                [250, 0, 0, 0], [0, 250, 0, 0], \n                [0, 0, 250, 0], [0, 0, 0, 250]\n            ]),\n            \"epsilon\": 0.5, \"B\": 2000, \"alpha\": 0.05, \"s\": 17\n        },\n        {\n            \"C_AO\": np.array([\n                [35, 3, 1, 1], [1, 7, 1, 1], \n                [1, 1, 4, 0], [1, 0, 0, 3]\n            ]),\n            \"C_BO\": np.array([\n                [3, 0, 1, 1], [0, 3, 1, 1], \n                [1, 1, 20, 3], [1, 1, 3, 20]\n            ]),\n            \"epsilon\": 0.5, \"B\": 2000, \"alpha\": 0.05, \"s\": 19\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = perform_clock_test(\n            case[\"C_AO\"], case[\"C_BO\"], case[\"epsilon\"], \n            case[\"B\"], case[\"alpha\"], case[\"s\"]\n        )\n        results.append(result)\n\n    # Format and print the final output as a single line\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "What happens if we assume a strict molecular clock when, in fact, different lineages have evolved at different speeds? This is not just a theoretical question; it has profound implications for the accuracy of molecular dating. This thought experiment  delves into the consequences of such model misspecification. By reasoning through a hypothetical scenario, you will discover how ignoring rate heterogeneity can lead to predictable and systematic biases—either over- or underestimation—in your calculated divergence times, highlighting the critical importance of selecting an appropriate evolutionary model.",
            "id": "2435879",
            "problem": "You are analyzing a rooted phylogeny under the molecular clock hypothesis in computational biology and bioinformatics. The true evolutionary process is a relaxed clock with branch-specific substitution rates. The tree has a root that splits into two large monophyletic clades. Within clade F, lineages evolve at a constant rate $r_{F}$, and within clade S, lineages evolve at a constant rate $r_{S}$, with $r_{F} > r_{S}$. The expected number of substitutions per site accumulated along a lineage equals the product of the per-lineage substitution rate and elapsed time, and root-to-tip genetic distances measured in substitutions per site reflect this product. Let the true age of the root be $t_{\\mathrm{root}}$. Assume you have abundant sequence data so that estimated genetic distances closely approximate their expectations.\n\nYou have exactly one hard calibration: in analysis I, you fix the age of the crown (Most Recent Common Ancestor (MRCA)) of clade F to its true value, and in analysis II, you instead fix the age of the crown (MRCA) of clade S to its true value. All other node ages are unconstrained by calibrations. However, in both analyses you fit a strict molecular clock model that enforces a single substitution rate $r_{\\mathrm{strict}}$ across the entire tree.\n\nWhich of the following statements best describes the direction of bias in the estimated root age under the strict clock relative to $t_{\\mathrm{root}}$ in these two calibration placements, and why?\n\nA. The root age will be overestimated in both analyses, because enforcing a single rate forces the model to increase times to accommodate slower-evolving lineages.\n\nB. The root age will be underestimated in both analyses, because enforcing a single rate forces the model to decrease times to accommodate faster-evolving lineages.\n\nC. The root age will be overestimated when the calibration is in clade S and underestimated when the calibration is in clade F, because a single rate forces time to absorb lineage rate differences via the relationship between genetic distance, rate, and time.\n\nD. There is no systematic bias with sufficient data; a single calibration is sufficient to identify the root age under a strict clock regardless of true rate variation.",
            "solution": "The problem statement must first be subjected to rigorous validation.\n\n**Step 1: Extract Givens**\n-   The evolutionary process is a relaxed molecular clock.\n-   The phylogeny has a root splitting into two monophyletic clades: clade F and clade S.\n-   Lineages within clade F evolve at a constant rate $r_{F}$.\n-   Lineages within clade S evolve at a constant rate $r_{S}$.\n-   The rates are unequal: $r_{F} > r_{S}$.\n-   The expected number of substitutions per site (genetic distance, $d$) is the product of substitution rate ($r$) and time ($t$): $d = r \\cdot t$.\n-   The true age of the root is $t_{\\mathrm{root}}$.\n-   Sequence data are abundant, so estimated genetic distances are assumed to be equal to their true expected values.\n-   Two analyses are performed, both using a misspecified strict molecular clock model with a single rate $r_{\\mathrm{strict}}$.\n-   Analysis I: The age of the Most Recent Common Ancestor (MRCA) of clade F is fixed to its true value via a hard calibration.\n-   Analysis II: The age of the Most Recent Common Ancestor (MRCA) of clade S is fixed to its true value via a hard calibration.\n-   The question asks for the direction of bias in the estimated root age, $t_{\\mathrm{root, est}}$, relative to the true root age, $t_{\\mathrm{root}}$, in both analyses.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is firmly grounded in the principles of molecular phylogenetics and computational biology. It describes a common and well-understood issue: the effect of model misspecification (fitting a strict clock to data generated by a relaxed clock) on parameter estimation, specifically node ages.\n-   **Well-Posed:** The problem is clearly defined. The relationship between distance, rate, and time is explicitly given. The conditions for the two separate analyses are unambiguous. The question asks for a specific, derivable outcome (the direction of bias).\n-   **Objective:** The problem is stated using precise, objective terminology from the field. It is free from subjective or speculative claims.\n\n**Step 3: Verdict and Action**\nThe problem statement is scientifically sound, well-posed, objective, and self-contained. It is therefore **valid**. I will proceed with the solution.\n\nThe fundamental relationship governing this system is that genetic distance, $d$, is the product of the substitution rate, $r$, and time, $t$:\n$$d = r \\cdot t$$\nThe problem states that due to abundant data, the estimated genetic distances accurately reflect the true expected distances generated by the relaxed clock process. The strict clock model, however, is misspecified and forces a single rate, $r_{\\mathrm{strict}}$, for the entire tree. Consequently, to explain the \"correct\" genetic distances, the model must adjust its time estimates, $t_{\\mathrm{est}}$. This relationship can be expressed as:\n$$t_{\\mathrm{est}} = \\frac{d}{r_{\\mathrm{strict}}}$$\nAny bias in $t_{\\mathrm{est}}$ arises because $r_{\\mathrm{strict}}$ does not match the true, lineage-specific rate, $r_{\\mathrm{true}}$.\n\nLet us analyze the two scenarios.\n\n**Analysis I: Calibration on Clade F (the fast-evolving clade)**\n\nIn this analysis, the age of the MRCA of clade F is fixed to its true value, let us call it $t_{F}$. A hard calibration forces the model to reconcile the genetic distances within clade F with this fixed time. Consider a lineage from the MRCA of clade F to any tip within that clade. The true time elapsed is $t_{F}$, and the true rate is $r_{F}$. Thus, the genetic distance is $d_{F, \\mathrm{internal}} = r_{F} \\cdot t_{F}$.\n\nThe strict clock model, with its single rate $r_{\\mathrm{strict, I}}$, must explain this distance over the fixed time $t_{F}$. Therefore:\n$$r_{\\mathrm{strict, I}} \\cdot t_{F} = d_{F, \\mathrm{internal}} = r_{F} \\cdot t_{F}$$\nThis forces the estimated rate for this analysis to be:\n$$r_{\\mathrm{strict, I}} = r_{F}$$\nThe model adopts the fast rate from the calibrated clade and applies it across the entire tree. Now, we evaluate the root age. The true root-to-tip distance for a lineage in the slow-evolving clade S is given by:\n$$d_{\\mathrm{S, root-tip}} = r_{S} \\cdot t_{\\mathrm{root}}$$\nThe strict clock model uses its estimated rate, $r_{\\mathrm{strict, I}}$, to infer the root age from this distance:\n$$t_{\\mathrm{root, est, I}} = \\frac{d_{\\mathrm{S, root-tip}}}{r_{\\mathrm{strict, I}}} = \\frac{r_{S} \\cdot t_{\\mathrm{root}}}{r_{F}}$$\nGiven that $r_{F} > r_{S}$, the ratio $r_{S} / r_{F} < 1$. It follows that:\n$$t_{\\mathrm{root, est, I}} < t_{\\mathrm{root}}$$\nIn Analysis I, the root age is **underestimated**.\n\n**Analysis II: Calibration on Clade S (the slow-evolving clade)**\n\nIn this analysis, the age of the MRCA of clade S is fixed to its true value, $t_{S}$. By the same logic as before, the strict clock model is forced to adopt the rate of this calibrated clade. The true genetic distance from the MRCA of S to a tip is $d_{S, \\mathrm{internal}} = r_{S} \\cdot t_{S}$. The model must satisfy:\n$$r_{\\mathrm{strict, II}} \\cdot t_{S} = d_{S, \\mathrm{internal}} = r_{S} \\cdot t_{S}$$\nThis leads to an estimated rate for this analysis:\n$$r_{\\mathrm{strict, II}} = r_{S}$$\nThe model adopts the slow rate and applies it across the entire tree. Now, we evaluate the root age by considering a lineage in the fast-evolving clade F. The true root-to-tip distance for this lineage is:\n$$d_{\\mathrm{F, root-tip}} = r_{F} \\cdot t_{\\mathrm{root}}$$\nThe strict clock model uses its estimated rate, $r_{\\mathrm{strict, II}}$, to infer the root age from this distance:\n$$t_{\\mathrm{root, est, II}} = \\frac{d_{\\mathrm{F, root-tip}}}{r_{\\mathrm{strict, II}}} = \\frac{r_{F} \\cdot t_{\\mathrm{root}}}{r_{S}}$$\nGiven that $r_{F} > r_{S}$, the ratio $r_{F} / r_{S} > 1$. It follows that:\n$$t_{\\mathrm{root, est, II}} > t_{\\mathrm{root}}$$\nIn Analysis II, the root age is **overestimated**.\n\nNow, we evaluate the provided options.\n\n**A. The root age will be overestimated in both analyses, because enforcing a single rate forces the model to increase times to accommodate slower-evolving lineages.**\nThis statement is **Incorrect**. As derived, when the calibration is on the fast clade F, the root age is underestimated, not overestimated. The reasoning provided is also flawed; it only considers one side of the misspecification effect.\n\n**B. The root age will be underestimated in both analyses, because enforcing a single rate forces the model to decrease times to accommodate faster-evolving lineages.**\nThis statement is **Incorrect**. As derived, when the calibration is on the slow clade S, the root age is overestimated, not underestimated. Again, the reasoning is one-sided and does not capture the full dynamic.\n\n**C. The root age will be overestimated when the calibration is in clade S and underestimated when the calibration is in clade F, because a single rate forces time to absorb lineage rate differences via the relationship between genetic distance, rate, and time.**\nThis statement is **Correct**. My derivation confirms both parts of the conclusion.\n1.  Calibration in clade S (slow rate $r_S$) leads to $t_{\\mathrm{root, est, II}} > t_{\\mathrm{root}}$ (overestimation).\n2.  Calibration in clade F (fast rate $r_F$) leads to $t_{\\mathrm{root, est, I}} < t_{\\mathrm{root}}$ (underestimation).\nThe provided reasoning is also correct and concise. The model misspecification creates a tension between the fixed genetic distances ($d$) and the enforced single rate ($r_{\\mathrm{strict}}$). To satisfy the equation $d = r_{\\mathrm{strict}} \\cdot t_{\\mathrm{est}}$, the estimated time ($t_{\\mathrm{est}}$) must compensate for the error in $r_{\\mathrm{strict}}$.\n\n**D. There is no systematic bias with sufficient data; a single calibration is sufficient to identify the root age under a strict clock regardless of true rate variation.**\nThis statement is **Incorrect**. This is a fundamentally false assertion about statistical modeling. Sufficient data ensures that the input (genetic distances) is accurate, but it does not and cannot correct for a misspecified underlying model (strict clock vs. relaxed clock). As demonstrated, the choice of where to place the single calibration in the presence of rate heterogeneity introduces a predictable, systematic bias in the age estimates for uncalibrated nodes.",
            "answer": "$$\\boxed{C}$$"
        }
    ]
}