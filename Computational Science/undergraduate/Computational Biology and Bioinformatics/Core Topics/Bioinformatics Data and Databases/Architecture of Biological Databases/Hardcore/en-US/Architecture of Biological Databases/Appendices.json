{
    "hands_on_practices": [
        {
            "introduction": "Biological data is constantly being revised and updated. To ensure the reproducibility of scientific analyses and prevent data pipelines from breaking, a systematic approach to versioning is essential. This exercise introduces Semantic Versioning (SemVer), a framework borrowed from software engineering, and challenges you to apply its rigorous principles to the complex world of gene annotations. By deciding what constitutes a MAJOR, MINOR, or PATCH change, you will gain a critical understanding of data dependencies and the importance of stable identifiers in bioinformatics .",
            "id": "2373018",
            "problem": "You are designing versioning for gene annotation records in a curated secondary biological database that builds upon a primary archive. A primary database stores submitted raw sequences and minimally processed feature annotations, while a secondary database consolidates, cross-references, and refines annotations across sources, aiming to provide stable identifiers and consistent models. The curation team wants to adopt Semantic Versioning (SemVer), where a record’s version is written as $M.m.p$ and the labels MAJOR, MINOR, and PATCH must be mapped to specific classes of changes in the gene annotation. Consider that downstream users depend on stable gene identifiers and coding sequences for pipelines such as variant effect prediction, protein functional analysis, and cross-database mapping.\n\nWhich of the following policies most appropriately maps MAJOR, MINOR, and PATCH to changes in a gene annotation record in a secondary database, in a way that adheres to the SemVer principle that MAJOR corresponds to backward-incompatible changes, MINOR to backward-compatible additions, and PATCH to backward-compatible fixes?\n\nA. MAJOR when the gene identifier changes, the gene is split or merged, gene boundaries shift in a way that alters the coding sequence, the reference assembly or coordinate system remapping invalidates prior coordinates, or the gene type changes in a way that alters interpretability; MINOR when new transcript isoforms or cross-references are added without changing existing transcript identifiers or coding sequences; PATCH when only metadata are corrected, such as description text, synonyms, publication links, or evidence codes, without changing any sequences, coordinates, or identifiers.\n\nB. MAJOR when functional description text or preferred gene symbol changes; MINOR when coding sequence or protein sequence changes but the gene identifier remains the same; PATCH when new transcript isoforms are added or removed.\n\nC. MAJOR only when the database schema or file format for the entire repository changes; MINOR when any feature coordinate changes, including small shifts in untranslated regions, but coding sequence remains identical; PATCH when metadata are corrected and when new cross-references or ontology annotations are added.\n\nD. MAJOR when new cross-references are added to external resources; MINOR when gene boundaries move or transcript models are retired; PATCH when the reference coding sequence is corrected to fix an erroneous amino acid, since it is a small change to the protein but keeps the identifier stable.",
            "solution": "The problem statement requires the formulation of a versioning policy for gene annotation records within a curated secondary biological database, using the principles of Semantic Versioning (SemVer). The core task is to map the version increments—MAJOR, MINOR, and PATCH—to specific types of changes in a gene annotation record.\n\nFirst, let us formalize the principles of Semantic Versioning, or SemVer, for a version identifier of the form $M.m.p$:\n1.  **MAJOR version ($M$)**: Incremented for backward-incompatible changes. A user of a previous version cannot necessarily switch to the new version without modifications to their dependent code or analysis pipeline. The \"API\" has been broken.\n2.  **MINOR version ($m$)**: Incremented for adding new functionality in a backward-compatible manner. Existing functionality remains, and users can safely upgrade.\n3.  **PATCH version ($p$)**: Incremented for making backward-compatible bug fixes. These are corrections that do not add new features or break existing ones.\n\nThe problem states that this system is to be applied to a gene annotation record in a secondary database. Downstream users rely on stable gene identifiers and coding sequences (CDS). Therefore, the \"API\" of a gene annotation record is constituted by its stable identifier, its genomic coordinates, its defined features (exons, CDS), and the sequences derived from these features (e.g., transcript and protein sequences). A \"backward-incompatible\" change is one that would break or invalidate analyses that depend on these core data elements.\n\nBased on these first principles, we can proceed to validate the problem statement.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   **System**: Versioning for gene annotation records.\n-   **Database Type**: Curated secondary biological database, building upon a primary archive.\n-   **Database Function**: Consolidates, cross-references, refines annotations; provides stable identifiers and consistent models.\n-   **Versioning Scheme**: Semantic Versioning (SemVer), format $M.m.p$.\n-   **SemVer Definitions**:\n    -   MAJOR: Backward-incompatible changes.\n    -   MINOR: Backward-compatible additions.\n    -   PATCH: Backward-compatible fixes.\n-   **User Dependencies**: Stable gene identifiers and coding sequences.\n-   **User Applications**: Variant effect prediction, protein functional analysis, cross-database mapping.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically and logically sound.\n-   **Scientifically Grounded**: The distinction between primary (e.g., GenBank/ENA) and secondary curated databases (e.g., RefSeq, Ensembl/GENCODE) is a fundamental concept in bioinformatics. The challenges of versioning annotations and maintaining stability for downstream users are real and critical issues in the field. Semantic Versioning is a widely accepted standard in software engineering, and its application to data versioning is a logical extension.\n-   **Well-Posed**: The problem is well-defined. It provides the versioning framework (SemVer), the data context (gene annotations), and the criteria for what constitutes a breaking change (dependencies of downstream users). The task is to find the most appropriate mapping among the given options, which is a solvable and unambiguous question.\n-   **Objective**: The question is objective, based on the formal definitions of SemVer and the concrete requirements of bioinformatics pipelines.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. It is a well-posed problem in computational biology that requires a rigorous application of established principles. We will now proceed with the solution by evaluating each option.\n\n### Option-by-Option Analysis\n\n**Option A:**\n-   **MAJOR**: `when the gene identifier changes, the gene is split or merged, gene boundaries shift in a way that alters the coding sequence, the reference assembly or coordinate system remapping invalidates prior coordinates, or the gene type changes in a way that alters interpretability`\n    -   A change in the gene identifier is the most definitive backward-incompatible change, as it breaks any direct lookup.\n    -   Splitting or merging genes fundamentally alters the gene model, invalidating all prior assumptions about that locus.\n    -   A change to the coding sequence (CDS) is also a critical breaking change. Pipelines for variant effect prediction or protein analysis depend on the exact reference CDS; altering it makes previous analyses invalid.\n    -   Remapping to a new assembly or coordinate system makes all previous coordinates obsolete.\n    -   Changing a gene type (e.g., from `protein_coding` to `pseudogene`) is a major re-interpretation that breaks assumptions for any analysis focused on protein function.\n    -   This mapping correctly identifies changes that are backward-incompatible for the specified downstream applications. This aligns with the purpose of a MAJOR version increment.\n-   **MINOR**: `when new transcript isoforms or cross-references are added without changing existing transcript identifiers or coding sequences`\n    -   Adding new isoforms or new cross-references enriches the record with new information without invalidating or altering the existing, stable data. A user interested in a pre-existing transcript can still find it unchanged. This is the definition of a backward-compatible addition of functionality. This aligns with the MINOR version increment.\n-   **PATCH**: `when only metadata are corrected, such as description text, synonyms, publication links, or evidence codes, without changing any sequences, coordinates, or identifiers`\n    -   Correcting typos in a description, updating a URL, or refining an evidence code are all fixes that improve the quality of the record but do not affect the core structural or sequence data upon which computational pipelines depend. These are backward-compatible fixes. This aligns with the PATCH version increment.\n\n**Verdict for A**: This option correctly and precisely maps the principles of SemVer to the context of gene annotation versioning. **Correct**.\n\n**Option B:**\n-   **MAJOR**: `when functional description text or preferred gene symbol changes`\n    -   Changing a text description is a minor correction, not a MAJOR breaking change. A gene symbol change can be disruptive but is often handled via synonym lists; it is not as severe as a CDS change, especially if a stable primary ID is maintained. This is a poor mapping for a MAJOR change.\n-   **MINOR**: `when coding sequence or protein sequence changes but the gene identifier remains the same`\n    -   This is a catastrophic misinterpretation of backward compatibility. A change to the coding sequence is a fundamental, breaking change that invalidates most downstream analyses. To label this as a MINOR, backward-compatible change is scientifically dangerous and defeats the purpose of versioning.\n-   **PATCH**: `new transcript isoforms are added or removed`\n    -   Adding a new isoform is a feature addition (MINOR). *Removing* an isoform is a breaking change (MAJOR). Classifying these actions, especially removal, as a mere PATCH is incorrect.\n\n**Verdict for B**: This policy is fundamentally flawed and misrepresents the impact of critical data changes. **Incorrect**.\n\n**Option C:**\n-   **MAJOR**: `only when the database schema or file format for the entire repository changes`\n    -   This confuses the versioning of an individual data record with the versioning of the entire database system. A record can undergo a breaking change (e.g., CDS update) independently of the global database schema. This policy is far too restrictive and fails to capture record-level breaking changes.\n-   **MINOR**: `when any feature coordinate changes, including small shifts in untranslated regions, but coding sequence remains identical`\n    -   This is a plausible definition for a MINOR or PATCH change, but the policy as a whole is flawed.\n-   **PATCH**: `when metadata are corrected and when new cross-references or ontology annotations are added`\n    -   This conflates two distinct types of changes. Metadata correction is a PATCH. Adding new features like cross-references or annotations is a MINOR change. Lumping them together is imprecise.\n\n**Verdict for C**: This policy misapplies the scope of versioning and conflates PATCH and MINOR changes. **Incorrect**.\n\n**Option D:**\n-   **MAJOR**: `when new cross-references are added to external resources`\n    -   Adding a cross-reference is a non-breaking feature addition. This should be a MINOR change. Assigning it to MAJOR is a complete misunderstanding of SemVer.\n-   **MINOR**: `when gene boundaries move or transcript models are retired`\n    -   Retiring a transcript model is a backward-incompatible change, as any analysis relying on it will fail. This must be a MAJOR change. Moving gene boundaries can also be a MAJOR change if it alters the CDS.\n-   **PATCH**: `when the reference coding sequence is corrected to fix an erroneous amino acid, since it is a small change to the protein but keeps the identifier stable`\n    -   As with option B, this is a dangerous and incorrect classification. A correction to the CDS that changes the resulting protein sequence is a backward-incompatible change, regardless of how \"small\" it seems. It is a bug fix, but a breaking one, thus necessitating a MAJOR version increment.\n\n**Verdict for D**: This policy demonstrates a fundamental lack of understanding of SemVer principles, incorrectly classifying the severity of every type of change. **Incorrect**.\n\nIn conclusion, only option A presents a logically consistent, scientifically sound, and pragmatically useful application of Semantic Versioning to gene annotation records, correctly prioritizing the stability of identifiers and sequences that are critical for downstream bioinformatics research.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "The utility of a biological database hinges not only on the data it holds but also on the integrity of its connections to other resources. Broken or circular cross-references can silently undermine the validity of large-scale computational analyses. This practice guides you through the process of designing a quantitative metric—an \"integrity score\"—to formally assess the quality of links between primary and secondary databases. By translating abstract concepts like data quality into a concrete mathematical formula, you will practice a core skill in bioinformatics: creating objective and tunable models to monitor and maintain the health of a database ecosystem .",
            "id": "2373026",
            "problem": "A primary biological database stores raw molecular entries, while a secondary biological database stores derived and curated information, and the two are interconnected by cross-references. Consider a primary database $\\mathcal{P}$ and a secondary database $\\mathcal{S}$. A cross-reference is a directed link from an entry in $\\mathcal{P}$ to an entry in $\\mathcal{S}$. Define the following quantities:\n- $L$: total number of recorded $\\mathcal{P} \\to \\mathcal{S}$ links,\n- $B$: number of broken $\\mathcal{P} \\to \\mathcal{S}$ links, meaning the target accession in $\\mathcal{S}$ does not resolve to an existing entry,\n- $V$: number of valid $\\mathcal{P} \\to \\mathcal{S}$ links, with $V=L-B$,\n- $K$: among the $V$ valid links, the number of links that are part of a circular two-step reference $p \\to s \\to p$, where $p \\in \\mathcal{P}$, $s \\in \\mathcal{S}$, and the back-link from $s$ points to the same $p$ that referenced $s$.\n\nYou are tasked with defining an integrity score $S_{\\mathrm{integrity}}$ that quantifies the quality of cross-references from $\\mathcal{P}$ to $\\mathcal{S}$, subject to the following requirements:\n1. $S_{\\mathrm{integrity}}=1$ if $B=0$ and $K=0$.\n2. The penalty from broken links depends only on the fraction $B/L$ and is linear in this fraction.\n3. The penalty from circular references depends only on the fraction $K/V$ and is linear in this fraction.\n4. The two penalties are additive, so that $S_{\\mathrm{integrity}}=1 - a\\,(B/L) - b\\,(K/V)$ for some constants $a$ and $b$.\n5. Calibration condition A: for a dataset with exactly one half of the links broken and no circular references, the score is $S_{\\mathrm{integrity}}=0.70$.\n6. Calibration condition B: for a dataset with no broken links and exactly one quarter of the valid links forming circular two-step references, the score is $S_{\\mathrm{integrity}}=0.85$.\n\nFor a real dataset with $L=1240$, $B=160$, and $K=210$, compute $S_{\\mathrm{integrity}}$ implied by the above requirements. Report a pure number rounded to four significant figures.",
            "solution": "We begin from the stated requirements. The score must take the form\n$$\nS_{\\mathrm{integrity}} \\;=\\; 1 \\;-\\; a\\,\\frac{B}{L} \\;-\\; b\\,\\frac{K}{V},\n$$\nwhere $V=L-B$. The constants $a$ and $b$ are determined by the calibration conditions.\n\nUsing calibration condition A, where exactly half the links are broken and there are no circular references, we have $B/L = \\frac{1}{2}$ and $K/V=0$, giving\n$$\n0.70 \\;=\\; 1 \\;-\\; a \\cdot \\frac{1}{2} \\;-\\; b \\cdot 0 \\;=\\; 1 \\;-\\; \\frac{a}{2}.\n$$\nSolving for $a$,\n$$\n\\frac{a}{2} \\;=\\; 1 - 0.70 \\;=\\; 0.30 \\;\\;\\Rightarrow\\;\\; a \\;=\\; 0.60.\n$$\n\nUsing calibration condition B, where there are no broken links and one quarter of valid links are circular, we have $B/L=0$ and $K/V=\\frac{1}{4}$, giving\n$$\n0.85 \\;=\\; 1 \\;-\\; a \\cdot 0 \\;-\\; b \\cdot \\frac{1}{4} \\;=\\; 1 \\;-\\; \\frac{b}{4}.\n$$\nSolving for $b$,\n$$\n\\frac{b}{4} \\;=\\; 1 - 0.85 \\;=\\; 0.15 \\;\\;\\Rightarrow\\;\\; b \\;=\\; 0.60.\n$$\n\nThus the score becomes\n$$\nS_{\\mathrm{integrity}} \\;=\\; 1 \\;-\\; 0.60\\,\\frac{B}{L} \\;-\\; 0.60\\,\\frac{K}{V}.\n$$\n\nFor the given dataset, we compute $V$:\n$$\nV \\;=\\; L - B \\;=\\; 1240 - 160 \\;=\\; 1080.\n$$\nNext, compute the fractions:\n$$\n\\frac{B}{L} \\;=\\; \\frac{160}{1240} \\;=\\; \\frac{16}{124} \\;=\\; \\frac{4}{31} \\;\\approx\\; 0.1290322581,\n$$\n$$\n\\frac{K}{V} \\;=\\; \\frac{210}{1080} \\;=\\; \\frac{21}{108} \\;=\\; \\frac{7}{36} \\;\\approx\\; 0.1944444444.\n$$\nCompute the penalties:\n$$\n0.60 \\cdot \\frac{B}{L} \\;\\approx\\; 0.60 \\cdot 0.1290322581 \\;=\\; 0.07741935486,\n$$\n$$\n0.60 \\cdot \\frac{K}{V} \\;\\approx\\; 0.60 \\cdot 0.1944444444 \\;=\\; 0.1166666667.\n$$\nSum of penalties:\n$$\n0.07741935486 + 0.1166666667 \\;=\\; 0.1940860216.\n$$\nTherefore,\n$$\nS_{\\mathrm{integrity}} \\;=\\; 1 - 0.1940860216 \\;=\\; 0.8059139784.\n$$\n\nRounded to four significant figures, the result is $0.8059$.",
            "answer": "$$\\boxed{0.8059}$$"
        },
        {
            "introduction": "Many biological systems, from metabolic pathways to ecological food webs, are fundamentally networks of interconnected entities. Representing and querying these relationships as a graph is a cornerstone of computational biology. This problem challenges you to model a food web as a directed graph and implement an algorithm to find all organisms at a specific trophic distance from primary producers. This task provides direct, hands-on experience with graph traversal algorithms, demonstrating how abstract data structures and query logic are used to answer concrete biological questions .",
            "id": "2373039",
            "problem": "You are given a conceptual architecture for an ecological biological database with two layers: a primary database and a secondary database. The primary database (PD) stores direct trophic interactions as directed edges in a directed graph, and the secondary database (SD) stores derived annotations such as trophic distances from primary producers. A primary producer is an organism that consumes no other organisms. The goal is to formalize a query over the secondary database: find all organisms that are exactly three trophic steps away from any primary producer, where “trophic step” is defined as one directed predation link following the direction from resource (prey) to consumer (predator).\n\nFormally, let the food web be represented as a directed graph $G=(V,E)$, where $V$ is a finite set of organism identifiers and $E \\subseteq V \\times V$ is a set of ordered pairs $(u,v)$ meaning that organism $u$ is directly consumed by organism $v$. Let $S \\subseteq V$ be the set of identified primary producers. For $s \\in S$ and $v \\in V$, define $d(s,v)$ to be the length, in number of directed edges, of a shortest directed path from $s$ to $v$ if such a path exists; otherwise $d(s,v)$ is undefined. For a producer set $S$, define the trophic distance of a node $v$ from producers as\n$$\n\\delta_S(v) = \\min_{s \\in S} d(s,v),\n$$\nwhenever at least one $d(s,v)$ is defined. The desired query result is the set\n$$\nD_3(S)=\\{\\, v \\in V \\mid \\delta_S(v)=3 \\,\\}.\n$$\n\nYour task is to write a complete program that, for each of the following independent test cases, computes and returns the sorted list of organism identifiers in $D_3(S)$.\n\nInterpretation and requirements:\n- Each test case provides a directed edge list $E$ and a set $S$ of primary producers.\n- The directed edges are oriented from resource to consumer. A single predator may have multiple resources, and cycles may exist.\n- For each test case, compute the set $D_3(S)$ consisting of all nodes whose shortest directed distance from the producer set $S$ equals $3$, and output the node identifiers sorted in increasing order.\n- If $D_3(S)$ is empty, output an empty list for that test case.\n- All organism identifiers are positive integers, and you must output integers, not strings.\n\nTest suite:\n- Test case $1$:\n  - $E_1 = \\{(1,2),(1,3),(2,4),(3,4),(4,5),(5,6),(2,7)\\}$\n  - $S_1 = \\{1\\}$\n- Test case $2$:\n  - $E_2 = \\{(1,2),(2,3),(3,4),(8,9),(9,10),(10,11),(2,5),(5,6),(6,4)\\}$\n  - $S_2 = \\{1,8\\}$\n- Test case $3$:\n  - $E_3 = \\{(1,2),(2,3),(3,2),(3,4),(4,5),(5,3)\\}$\n  - $S_3 = \\{1\\}$\n- Test case $4$:\n  - $E_4 = \\{(1,2),(2,1)\\}$\n  - $S_4 = \\{1\\}$\n- Test case $5$:\n  - $E_5 = \\{(1,2)\\}$\n  - $S_5 = \\{10\\}$\n\nFinal output format:\n- Your program should produce a single line of output containing the results for all five test cases as a comma-separated list enclosed in square brackets. Each element of this outer list must be the inner sorted list (in increasing order) of integers for the corresponding test case. For example, an output with three test cases could look like $[[1,4],[3],[]]$.",
            "solution": "We formalize the architecture of primary and secondary biological databases for an ecological food web as follows. The primary database (PD) holds the raw entity-relationship data: organisms as nodes and direct trophic interactions as directed edges from resource to consumer. This is naturally modeled as a directed graph $G=(V,E)$ with $E \\subseteq V \\times V$. The secondary database (SD) derives annotations from PD, such as trophic distances from primary producers. Conceptually, SD stores the function $\\delta_S: V \\to \\mathbb{N}$ defined by $\\delta_S(v)=\\min_{s \\in S} d(s,v)$, where $d(s,v)$ is the length of a shortest directed path from $s$ to $v$ in $G$. The query “organisms exactly three trophic levels away from a primary producer” is formalized as retrieving $D_3(S)=\\{ v \\in V \\mid \\delta_S(v)=3\\}$ from SD.\n\nFrom first principles in graph theory, in a directed, unweighted graph, the shortest path length in edge count from a source set $S$ to all reachable nodes is obtained by performing a breadth-first search (BFS) initiated with the entire set $S$ at distance $0$. BFS explores layers in nondecreasing order of path length, and the first time a node is discovered establishes its shortest-path distance. Therefore, to compute $D_3(S)$, it suffices to:\n- Initialize distances $\\text{dist}(s)=0$ for all $s \\in S$ and $\\text{dist}(v)$ undefined otherwise.\n- Traverse the graph in layers by increasing distance using a queue, propagating from a node $u$ to all out-neighbors $v$ and setting $\\text{dist}(v)=\\text{dist}(u)+1$ when not yet assigned.\n- Stop exploring beyond distance $3$, because nodes with shortest distance greater than $3$ cannot contribute to $D_3(S)$.\n- Collect all nodes with $\\text{dist}(v)=3$.\n\nBecause PD provides edges $(u,v)$ oriented from resource to consumer, successive applications of edges correspond exactly to successive trophic steps. BFS naturally handles cycles and multiple producers by the property that the first time a node is assigned a distance is via a shortest directed path from the nearest producer in $S$; subsequent longer alternative paths are ignored.\n\nWe now compute the expected outcomes for the provided test suite by analyzing directed reachability and path lengths.\n\n- Test case $1$:\n  - $E_1 = \\{(1,2),(1,3),(2,4),(3,4),(4,5),(5,6),(2,7)\\}$, $S_1=\\{1\\}$.\n  - From $1$, nodes at distance $1$ are $\\{2,3\\}$. At distance $2$, $\\{4,7\\}$. At distance $3$, only $\\{5\\}$ (via $1 \\to 2 \\to 4 \\to 5$ or $1 \\to 3 \\to 4 \\to 5$). Therefore $D_3(S_1)=[5]$ in increasing order.\n\n- Test case $2$:\n  - $E_2 = \\{(1,2),(2,3),(3,4),(8,9),(9,10),(10,11),(2,5),(5,6),(6,4)\\}$, $S_2=\\{1,8\\}$.\n  - From $1$: distance $1$ is $\\{2\\}$, distance $2$ is $\\{3,5\\}$, distance $3$ is $\\{4,6\\}$. From $8$: distance $1$ is $\\{9\\}$, distance $2$ is $\\{10\\}$, distance $3$ is $\\{11\\}$. Union at exactly distance $3$ from either producer yields $\\{4,6,11\\}$, so $D_3(S_2)=[4,6,11]$.\n\n- Test case $3$:\n  - $E_3 = \\{(1,2),(2,3),(3,2),(3,4),(4,5),(5,3)\\}$, $S_3=\\{1\\}$.\n  - There is a cycle among $\\{2,3,5\\}$ but shortest distances from $1$ are: $\\text{dist}(2)=1$, $\\text{dist}(3)=2$, $\\text{dist}(4)=3$, $\\text{dist}(5)=4$. Hence $D_3(S_3)=[4]$.\n\n- Test case $4$:\n  - $E_4 = \\{(1,2),(2,1)\\}$, $S_4=\\{1\\}$.\n  - $\\text{dist}(2)=1$, $\\text{dist}(1)=0$. No node has shortest distance $3$, since revisiting the cycle would not change the shortest distances. Therefore $D_3(S_4)=[\\,]$ (empty list).\n\n- Test case $5$:\n  - $E_5 = \\{(1,2)\\}$, $S_5=\\{10\\}$.\n  - Node $10$ has no outgoing edges in the given graph. No nodes are reachable from $10$, so $D_3(S_5)=[\\,]$.\n\nAlgorithmically, for each test case, build an adjacency list for $G$, run a BFS from all sources in $S$ simultaneously, assign shortest distances up to $3$, and collect nodes with distance exactly $3$, sorted in increasing order. The final output is the outer list aggregating the five inner lists, printed on a single line as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\n\ndef nodes_at_exact_distance_three(edges, producers):\n    # Build adjacency list from edges (u -> v)\n    adj = {}\n    nodes = set()\n    for u, v in edges:\n        nodes.add(u)\n        nodes.add(v)\n        if u not in adj:\n            adj[u] = []\n        adj[u].append(v)\n    # Ensure producers appear in adjacency even if they have no outgoing edges\n    for s in producers:\n        if s not in adj:\n            adj[s] = []\n        nodes.add(s)\n\n    # Multi-source BFS up to depth 3\n    from collections import deque\n    dist = {}\n    q = deque()\n\n    # Initialize queue with all producers at distance 0\n    for s in producers:\n        if s not in dist:\n            dist[s] = 0\n            q.append(s)\n\n    # BFS\n    while q:\n        u = q.popleft()\n        du = dist[u]\n        if du == 3:\n            # Do not expand further from nodes already at depth 3\n            continue\n        for v in adj.get(u, []):\n            if v not in dist:\n                dist[v] = du + 1\n                # Only enqueue if we have not exceeded depth 3\n                if dist[v] <= 3:\n                    q.append(v)\n\n    # Collect nodes at exact distance 3\n    result = sorted([v for v, d in dist.items() if d == 3])\n    return result\n\ndef format_list_of_lists_no_spaces(lol):\n    # Formats e.g., [[5],[4,6,11],[4],[],[]] without spaces\n    inner = []\n    for lst in lol:\n        inner.append(\"[\" + \",\".join(str(x) for x in lst) + \"]\")\n    return \"[\" + \",\".join(inner) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        {\n            \"edges\": [(1,2),(1,3),(2,4),(3,4),(4,5),(5,6),(2,7)],\n            \"producers\": [1],\n        },\n        # Test case 2\n        {\n            \"edges\": [(1,2),(2,3),(3,4),(8,9),(9,10),(10,11),(2,5),(5,6),(6,4)],\n            \"producers\": [1,8],\n        },\n        # Test case 3\n        {\n            \"edges\": [(1,2),(2,3),(3,2),(3,4),(4,5),(5,3)],\n            \"producers\": [1],\n        },\n        # Test case 4\n        {\n            \"edges\": [(1,2),(2,1)],\n            \"producers\": [1],\n        },\n        # Test case 5\n        {\n            \"edges\": [(1,2)],\n            \"producers\": [10],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        edges = case[\"edges\"]\n        producers = case[\"producers\"]\n        result = nodes_at_exact_distance_three(edges, producers)\n        results.append(result)\n\n    # Final print statement in the exact required format (no spaces).\n    print(format_list_of_lists_no_spaces(results))\n\nsolve()\n```"
        }
    ]
}