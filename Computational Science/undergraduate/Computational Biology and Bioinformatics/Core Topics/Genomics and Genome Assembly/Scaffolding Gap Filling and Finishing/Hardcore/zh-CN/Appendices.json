{
    "hands_on_practices": [
        {
            "introduction": "基因组搭建（scaffolding）的核心是确定不同重叠群（contigs）之间的正确顺序和方向。然而，用于推断这些连接的实验证据，如双末端测序（mate-pairs）、光学图谱（optical mapping）或Hi-C，本身可能包含噪声甚至相互矛盾。本练习将引导你使用一个强大的贝叶斯框架，以定量方式整合来自多种独立数据源的证据，从而计算出一个潜在连接的后验正确率。通过这种方式，你将学会如何从不完美的数据中做出稳健的推断，这是现代生物信息学的一项核心技能 。",
            "id": "2427655",
            "problem": "给定一个形式概率模型，用于评估基于基因组组装中常用的多种独立实验证据类型（双末端测序文库、光学图谱和高通量染色体构象捕获(Hi-C)）所提出的两个重叠群之间的支架连接是否正确。设二元事件 $L \\in \\{0,1\\}$ 表示所提出的连接是正确的 ($L=1$) 还是不正确的 ($L=0$)。对于集合 $\\mathcal{D} = \\{\\text{MP}, \\text{OM}, \\text{HC}\\}$ 中的每种数据类型 $d$，记录一个观测值 $x_d \\in \\{+1,-1,0\\}$，其中 $+1$ 表示支持性证据（与连接一致），$-1$ 表示矛盾性证据（与连接不一致），$0$ 表示缺失或无信息量的证据。假设在给定 $L$ 的条件下，各个观测是条件独立的。\n\n对于每种数据类型 $d \\in \\mathcal{D}$，给定条件概率 $P(x_d=+1 \\mid L=1)$ 和 $P(x_d=+1 \\mid L=0)$ 作为模型参数。当 $x_d=-1$ 时，使用 $P(x_d=-1 \\mid L=1)=1-P(x_d=+1 \\mid L=1)$ 和 $P(x_d=-1 \\mid L=0)=1-P(x_d=+1 \\mid L=0)$。当 $x_d=0$ 时，该观测不应改变后验概率。\n\n你的任务是从第一性原理出发，计算后验概率 $P(L=1 \\mid \\mathbf{x})$，其中 $\\mathbf{x}=(x_{\\text{MP}},x_{\\text{OM}},x_{\\text{HC}})$，指定了先验概率 $P(L=1)=p_0$，且条件独立性意味着\n$$\nP(\\mathbf{x}\\mid L=\\ell) \\;=\\; \\prod_{d\\in\\mathcal{D}} P(x_d\\mid L=\\ell), \\quad \\ell\\in\\{0,1\\}.\n$$\n使用贝叶斯法则：\n$$\nP(L=1\\mid \\mathbf{x}) \\;=\\; \\frac{p_0 \\cdot \\prod_{d\\in\\mathcal{D}} P(x_d\\mid L=1)}{p_0 \\cdot \\prod_{d\\in\\mathcal{D}} P(x_d\\mid L=1) + (1-p_0) \\cdot \\prod_{d\\in\\mathcal{D}} P(x_d\\mid L=0)}.\n$$\n\n所有概率必须按 $[0,1]$ 区间内的小数处理。\n\n对于所有测试用例，使用以下固定的模型参数：\n- 双末端测序 (MP)：$P(x_{\\text{MP}}=+1 \\mid L=1)=0.9$，$P(x_{\\text{MP}}=+1 \\mid L=0)=0.1$。\n- 光学图谱 (OM)：$P(x_{\\text{OM}}=+1 \\mid L=1)=0.95$，$P(x_{\\text{OM}}=+1 \\mid L=0)=0.05$。\n- 高通量染色体构象捕获 (Hi-C) (HC)：$P(x_{\\text{HC}}=+1 \\mid L=1)=0.85$，$P(x_{\\text{HC}}=+1 \\mid L=0)=0.2$。\n\n实现一个程序，计算每个测试用例的 $P(L=1\\mid \\mathbf{x})$，并将每个结果四舍五入到 $6$ 位小数：\n- 情况 1：$p_0=0.5$, $x_{\\text{MP}}=+1$, $x_{\\text{OM}}=+1$, $x_{\\text{HC}}=+1$。\n- 情况 2：$p_0=0.5$, $x_{\\text{MP}}=+1$, $x_{\\text{OM}}=-1$, $x_{\\text{HC}}=+1$。\n- 情况 3：$p_0=0.01$, $x_{\\text{MP}}=+1$, $x_{\\text{OM}}=+1$, $x_{\\text{HC}}=+1$。\n- 情况 4：$p_0=0.9$, $x_{\\text{MP}}=-1$, $x_{\\text{OM}}=-1$, $x_{\\text{HC}}=-1$。\n- 情况 5：$p_0=0.2$, $x_{\\text{MP}}=+1$, $x_{\\text{OM}}=0$, $x_{\\text{HC}}=-1$。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个值都四舍五入到 $6$ 位小数（例如 $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5]$）。不涉及物理单位，也不涉及角度。",
            "solution": "所呈现的问题在科学上是合理的，在计算上是适定的。它要求将概率论的基本原理，特别是贝叶斯法则，应用于一个生物信息学问题。我们将从第一性原理出发推导解答。\n\n目标是计算在给定观测向量 $\\mathbf{x} = (x_{\\text{MP}}, x_{\\text{OM}}, x_{\\text{HC}})$ 的条件下，一个支架连接是正确的（$L=1$）的后验概率 $P(L=1 \\mid \\mathbf{x})$。一个正确连接的先验概率给定为 $P(L=1) = p_0$。\n\n根据贝叶斯法则，后验概率由下式给出：\n$$\nP(L=1 \\mid \\mathbf{x}) = \\frac{P(\\mathbf{x} \\mid L=1) P(L=1)}{P(\\mathbf{x})}\n$$\n分母中的项 $P(\\mathbf{x})$ 是证据的边缘概率，使用全概率定律计算：\n$$\nP(\\mathbf{x}) = P(\\mathbf{x} \\mid L=1) P(L=1) + P(\\mathbf{x} \\mid L=0) P(L=0)\n$$\n鉴于 $P(L=0) = 1 - P(L=1) = 1 - p_0$，我们得到问题陈述中提供的公式：\n$$\nP(L=1\\mid \\mathbf{x}) = \\frac{p_0 \\cdot P(\\mathbf{x}\\mid L=1)}{p_0 \\cdot P(\\mathbf{x}\\mid L=1) + (1-p_0) \\cdot P(\\mathbf{x}\\mid L=0)}\n$$\n问题指出，在给定连接的真实状态 $L$ 的条件下，观测是条件独立的。因此，对于 $\\ell \\in \\{0, 1\\}$，似然函数 $P(\\mathbf{x}\\mid L=\\ell)$ 是各个条件概率的乘积：\n$$\nP(\\mathbf{x}\\mid L=\\ell) = \\prod_{d\\in\\mathcal{D}} P(x_d\\mid L=\\ell)\n$$\n其中 $\\mathcal{D} = \\{\\text{MP}, \\text{OM}, \\text{HC}\\}$。\n\n对于每种数据类型 $d \\in \\mathcal{D}$ 和观测 $x_d \\in \\{+1, -1, 0\\}$，条件概率定义如下。支持性证据（$x_d=+1$）的参数已给出：\n- 双末端测序 (MP)：$P(x_{\\text{MP}}=+1 \\mid L=1) = 0.9$，$P(x_{\\text{MP}}=+1 \\mid L=0) = 0.1$。\n- 光学图谱 (OM)：$P(x_{\\text{OM}}=+1 \\mid L=1) = 0.95$，$P(x_{\\text{OM}}=+1 \\mid L=0) = 0.05$。\n- Hi-C (HC)：$P(x_{\\text{HC}}=+1 \\mid L=1) = 0.85$，$P(x_{\\text{HC}}=+1 \\mid L=0) = 0.2$。\n\n对于矛盾性证据（$x_d=-1$），概率推导如下：\n$$\nP(x_d = -1 \\mid L=\\ell) = 1 - P(x_d = +1 \\mid L=\\ell)\n$$\n这得出：\n- MP：$P(x_{\\text{MP}}=-1 \\mid L=1) = 0.1$，$P(x_{\\text{MP}}=-1 \\mid L=0) = 0.9$。\n- OM：$P(x_{\\text{OM}}=-1 \\mid L=1) = 0.05$，$P(x_{\\text{OM}}=-1 \\mid L=0) = 0.95$。\n- HC：$P(x_{\\text{HC}}=-1 \\mid L=1) = 0.15$，$P(x_{\\text{HC}}=-1 \\mid L=0) = 0.8$。\n\n对于缺失证据（$x_d=0$），该观测必须不改变后验分布。这通过将此观测的似然比设置为 $1$ 来实现。在我们的计算中，这等同于对 $\\ell=1$ 和 $\\ell=0$ 都设置 $P(x_d=0 \\mid L=\\ell) = 1$，从而有效地将该项从乘积中移除。\n\n我们现在为每个测试用例计算后验概率。\n\n**情况 1：** $p_0=0.5$, $\\mathbf{x}=(x_{\\text{MP}}=+1, x_{\\text{OM}}=+1, x_{\\text{HC}}=+1)$。\n- $L=1$ 时的似然：$P(\\mathbf{x} \\mid L=1) = 0.9 \\times 0.95 \\times 0.85 = 0.72675$。\n- $L=0$ 时的似然：$P(\\mathbf{x} \\mid L=0) = 0.1 \\times 0.05 \\times 0.2 = 0.001$。\n- 后验概率：$P(L=1 \\mid \\mathbf{x}) = \\frac{0.5 \\times 0.72675}{0.5 \\times 0.72675 + (1-0.5) \\times 0.001} = \\frac{0.363375}{0.363375 + 0.0005} = \\frac{0.363375}{0.363875} \\approx 0.998626$。\n\n**情况 2：** $p_0=0.5$, $\\mathbf{x}=(x_{\\text{MP}}=+1, x_{\\text{OM}}=-1, x_{\\text{HC}}=+1)$。\n- $L=1$ 时的似然：$P(\\mathbf{x} \\mid L=1) = 0.9 \\times (1-0.95) \\times 0.85 = 0.9 \\times 0.05 \\times 0.85 = 0.03825$。\n- $L=0$ 时的似然：$P(\\mathbf{x} \\mid L=0) = 0.1 \\times (1-0.05) \\times 0.2 = 0.1 \\times 0.95 \\times 0.2 = 0.019$。\n- 后验概率：$P(L=1 \\mid \\mathbf{x}) = \\frac{0.5 \\times 0.03825}{0.5 \\times 0.03825 + (1-0.5) \\times 0.019} = \\frac{0.019125}{0.019125 + 0.0095} = \\frac{0.019125}{0.028625} \\approx 0.668122$。\n\n**情况 3：** $p_0=0.01$, $\\mathbf{x}=(x_{\\text{MP}}=+1, x_{\\text{OM}}=+1, x_{\\text{HC}}=+1)$。\n- 似然与情况 1 相同：$P(\\mathbf{x} \\mid L=1) = 0.72675$, $P(\\mathbf{x} \\mid L=0) = 0.001$。\n- 后验概率：$P(L=1 \\mid \\mathbf{x}) = \\frac{0.01 \\times 0.72675}{0.01 \\times 0.72675 + (1-0.01) \\times 0.001} = \\frac{0.0072675}{0.0072675 + 0.00099} = \\frac{0.0072675}{0.0082575} \\approx 0.880115$。\n\n**情况 4：** $p_0=0.9$, $\\mathbf{x}=(x_{\\text{MP}}=-1, x_{\\text{OM}}=-1, x_{\\text{HC}}=-1)$。\n- $L=1$ 时的似然：$P(\\mathbf{x} \\mid L=1) = (1-0.9) \\times (1-0.95) \\times (1-0.85) = 0.1 \\times 0.05 \\times 0.15 = 0.00075$。\n- $L=0$ 时的似然：$P(\\mathbf{x} \\mid L=0) = (1-0.1) \\times (1-0.05) \\times (1-0.2) = 0.9 \\times 0.95 \\times 0.8 = 0.684$。\n- 后验概率：$P(L=1 \\mid \\mathbf{x}) = \\frac{0.9 \\times 0.00075}{0.9 \\times 0.00075 + (1-0.9) \\times 0.684} = \\frac{0.000675}{0.000675 + 0.0684} = \\frac{0.000675}{0.069075} \\approx 0.009772$。\n\n**情况 5：** $p_0=0.2$, $\\mathbf{x}=(x_{\\text{MP}}=+1, x_{\\text{OM}}=0, x_{\\text{HC}}=-1)$。\n- $L=1$ 时的似然：$P(\\mathbf{x} \\mid L=1) = 0.9 \\times 1 \\times (1-0.85) = 0.9 \\times 0.15 = 0.135$。\n- $L=0$ 时的似然：$P(\\mathbf{x} \\mid L=0) = 0.1 \\times 1 \\times (1-0.2) = 0.1 \\times 0.8 = 0.08$。\n- 后验概率：$P(L=1 \\mid \\mathbf{x}) = \\frac{0.2 \\times 0.135}{0.2 \\times 0.135 + (1-0.2) \\times 0.08} = \\frac{0.027}{0.027 + 0.064} = \\frac{0.027}{0.091} \\approx 0.296703$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the posterior probability for scaffold link correctness\n    based on a Bayesian model with multiple evidence types.\n    \"\"\"\n\n    # Fixed model parameters\n    # For each data type d, we store (P(x_d=+1|L=1), P(x_d=+1|L=0))\n    model_params = {\n        \"MP\": (0.9, 0.1),\n        \"OM\": (0.95, 0.05),\n        \"HC\": (0.85, 0.2)\n    }\n\n    # Test cases from the problem statement\n    # Each case is a tuple: (p0, (x_mp, x_om, x_hc))\n    test_cases = [\n        (0.5, (1, 1, 1)),   # Case 1\n        (0.5, (1, -1, 1)),  # Case 2\n        (0.01, (1, 1, 1)),  # Case 3\n        (0.9, (-1, -1, -1)),# Case 4\n        (0.2, (1, 0, -1))   # Case 5\n    ]\n    \n    data_types = [\"MP\", \"OM\", \"HC\"]\n    results = []\n\n    for case in test_cases:\n        p0, observations = case\n        \n        # Initialize likelihoods for L=1 and L=0\n        lik_L1 = 1.0\n        lik_L0 = 1.0\n\n        for i, obs in enumerate(observations):\n            data_type = data_types[i]\n            p_plus_1_given_L1, p_plus_1_given_L0 = model_params[data_type]\n            \n            if obs == 1:\n                # Supportive evidence\n                lik_L1 *= p_plus_1_given_L1\n                lik_L0 *= p_plus_1_given_L0\n            elif obs == -1:\n                # Contradictory evidence\n                # P(x_d=-1|L) = 1 - P(x_d=+1|L)\n                lik_L1 *= (1.0 - p_plus_1_given_L1)\n                lik_L0 *= (1.0 - p_plus_1_given_L0)\n            elif obs == 0:\n                # Missing or uninformative evidence\n                # Likelihood ratio is 1, so we multiply by 1 (i.e., do nothing)\n                pass\n\n        # Calculate numerator and denominator of Bayes' rule\n        numerator = p0 * lik_L1\n        denominator = numerator + (1.0 - p0) * lik_L0\n        \n        if denominator == 0:\n            # This case is not expected with the given parameters but is good practice\n            posterior = 0.0\n        else:\n            posterior = numerator / denominator\n        \n        results.append(posterior)\n\n    # Format the results as a comma-separated string, rounded to 6 decimal places\n    output_str = f\"[{','.join([f'{r:.6f}' for r in results])}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "搭建（scaffolding）完成后，我们得到了一个有序且定向的重叠群（contigs）框架，但它们之间仍然存在着序列未知的空隙（gaps）。填补这些空隙是获得完整基因组序列的关键一步。本练习将让你亲手实现一个解决空隙填充问题的经典算法：利用那些未成功比对到任何现有重叠群的测序读长（reads）来构建一个德布鲁因图（de Bruijn graph）。通过将空隙填充问题建模为在这个加权图上寻找一条最高置信度的路径，你将深入理解图论在基因组组装中的巧妙应用 。",
            "id": "2427629",
            "problem": "给定一个在核苷酸字母表上的有限未映射测序读长集合，以及一个由$k$阶de Bruijn图中的起始节点和终止节点定义的目标缺口。将填补该缺口的路径的置信度建模为沿该路径的平滑转移概率的乘积。形式上，令$\\Sigma=\\{A,C,G,T\\}$，并根据给定的读长构建de Bruijn图$G_k$如下。对于每个读长$r$及其中的每个长度为$k$的连续子串（表示为$x_1 x_2 \\dots x_k$），从节点$u = x_1 x_2 \\dots x_{k-1}$向节点$v = x_2 x_3 \\dots x_k$添加一条有向边。计数$c(u \\to v)$是这个$k$-mer在所有读长中出现的次数。对于给定的平滑参数$\\alpha > 0$，定义出度$d(u)$为从$u$出发的不同出边的数量，并定义从$u$到$v$的平滑转移概率为\n$$\nP(u \\to v) = \\frac{c(u \\to v) + \\alpha}{\\sum_{v'} c(u \\to v') + \\alpha \\cdot d(u)} \\quad \\text{其中 } v' \\text{ 是所有观测到的出邻接点}。\n$$\n一条路径$u_0 \\to u_1 \\to \\dots \\to u_m$的置信度为\n$$\n\\mathrm{Conf} = \\prod_{i=0}^{m-1} P(u_i \\to u_{i+1})。\n$$\n设起始节点为$s$，终止节点为$t$，两者均为长度为$k-1$的字符串。设最大允许边数为$L \\in \\mathbb{N}$。将缺口填补的最优置信度定义为所有从$s$到$t$且最多使用$L$条边的有向路径的$\\mathrm{Conf}$的最大值；如果$m=0$且$s=t$，则定义$\\mathrm{Conf}=1$。如果不存在这样的路径（当$s \\ne t$时，$m \\ge 1$），则定义最优置信度为$0$。\n\n对于每个指定的测试用例，你的程序必须计算最优置信度的自然对数（以$e$为底），即\n$$\n\\log \\mathrm{Conf}^* = \\max_{\\substack{s \\to t \\text{ 路径} \\\\ m \\le L}} \\sum_{i=0}^{m-1} \\log P(u_i \\to u_{i+1}),\n$$\n并遵循以下约定：如果不存在路径且$s \\ne t$，输出$-\\infty$；如果$s=t$且$L \\ge 0$，则允许空路径，此时$\\log \\mathrm{Conf}^* = 0$。所有对数都必须是自然对数。要求的数值输出必须四舍五入到$6$位小数（如果为有限值）。不涉及物理单位。不使用角度。不使用百分比。\n\n测试套件。对于每个测试用例，参数为$(\\text{reads}, k, \\alpha, s, t, L)$，其中reads是$\\Sigma$上的一个有限字符串列表。\n\n- 测试用例 $1$（顺利路径，唯一链）：\n  - reads $= [\\text{ATG}, \\text{TGA}, \\text{TGA}, \\text{GAC}]$\n  - $k = 3$\n  - $\\alpha = 0.5$\n  - $s = \\text{AT}$\n  - $t = \\text{AC}$\n  - $L = 3$\n\n- 测试用例 $2$（具有不等支持度的分支）：\n  - reads $= [\\text{ATG}, \\text{ATG}, \\text{ATA}, \\text{TGA}, \\text{TGC}, \\text{GCA}]$\n  - $k = 3$\n  - $\\alpha = 0.5$\n  - $s = \\text{AT}$\n  - $t = \\text{GA}$\n  - $L = 2$\n\n- 测试用例 $3$（不存在路径）：\n  - reads $= [\\text{AAA}, \\text{AAT}, \\text{ATC}]$\n  - $k = 3$\n  - $\\alpha = 0.5$\n  - $s = \\text{GG}$\n  - $t = \\text{TT}$\n  - $L = 5$\n\n- 测试用例 $4$（边界条件 $L=0$ 且 $s=t$）：\n  - reads $= [\\text{AAA}, \\text{AAT}, \\text{ATC}]$\n  - $k = 3$\n  - $\\alpha = 0.5$\n  - $s = \\text{AT}$\n  - $t = \\text{AT}$\n  - $L = 0$\n\n最终输出格式。你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果顺序与测试用例相同。每个条目必须是该测试用例的$\\log \\mathrm{Conf}^*$的浮点数值，如果为有限值则四舍五入到$6$位小数，如果不存在路径则为$-\\infty$。例如，一个包含四个结果的输出必须类似于$[\\text{r}_1,\\text{r}_2,\\text{r}_3,\\text{r}_4]$。",
            "solution": "所呈现的问题是一个在加权有向图上的明确定义的优化练习。它为一个计算基因组学中的常见问题——填补基因组草图组装中的缺口——建立了一个简化但概念上有效的模型。该置信度模型基于de Bruijn图中的平滑转移概率，在统计上是合理的。目标是在路径长度受限的情况下，找到两个指定节点之间置信度最高的路径。这等价于在边权重定义为转移概率的对数时，寻找最长路径。该问题不包含任何逻辑矛盾、科学谬误或歧义。因此，我们将着手其形式化解决方案。\n\n问题的核心是找到具有最大累积对数概率的路径。设图为$G = (V, E)$，其中$V$是从读长中导出的$(k-1)$-mers集合，如果对应于从$u$到$v$的转换的$k$-mer被观察到，则存在一条边$(u, v) \\in E$。一条边$(u, v)$的权重由$w(u, v) = \\log P(u \\to v)$给出。问题就变成了寻找：\n$$\n\\log \\mathrm{Conf}^* = \\max_{\\substack{\\pi = u_0 \\to \\dots \\to u_m \\\\ u_0 = s, u_m = t \\\\ m \\le L}} \\sum_{i=0}^{m-1} w(u_i, u_{i+1})\n$$\n\n这是最长路径问题的一个变体，受边数的约束。这类问题可以通过动态规划正确解决。一个类似于Bellman-Ford算法的方法是合适的。\n\n解决方案通过以下步骤构建：\n\n1.  **De Bruijn图的构建**\n    首先，我们必须从输入读长中构建de Bruijn图。图的节点是长度为$k-1$的唯一子串（称为$(k-1)$-mers）。如果读长中存在一个$k$-mer，其前$k-1$个字符构成节点$u$，后$k-1$个字符构成节点$v$，则存在一条从$u$到$v$的边。我们处理所有读长，找出所有构成的$k$-mers及其频率。设$c(u \\to v)$为对应于从节点$u$到节点$v$转换的$k$-mer的计数。这些计数可以存储在例如哈希映射的数据结构中，将节点对$(u, v)$映射到其计数。\n\n2.  **边权重的计算**\n    在图结构和边计数确定后，我们计算每条边的权重。对于每个至少是一条边源头的节点$u$，我们计算两个量：\n    - 出度$d(u)$，即从$u$一步可达的不同节点$v'$的数量。\n    - 总出向计数$\\sum_{v'} c(u \\to v')$，即对$u$的所有观测到的邻居$v'$求和。\n\n    然后根据所提供的公式为每条边$(u, v)$计算平滑转移概率$P(u \\to v)$：\n    $$\n    P(u \\to v) = \\frac{c(u \\to v) + \\alpha}{\\sum_{v'} c(u \\to v') + \\alpha \\cdot d(u)}\n    $$\n    边$(u, v)$的权重是该概率的自然对数，$w(u, v) = \\log P(u \\to v)$。由于$P(u \\to v)$可能小于$1$，其对数将为非正数。这保证了图中没有正权重环，从而简化了最长路径问题。\n\n3.  **用于最长路径的动态规划**\n    我们定义一个动态规划状态$D(l, v)$，表示从起始节点$s$到任意节点$v$使用*恰好*$l$条边的路径的最大对数置信度。\n    状态空间由路径长度$l \\in [0, L]$和节点$v \\in V$索引。我们可以将每个节点的字符串表示映射到一个唯一的整数索引，以便在基于数组的实现中高效访问。\n\n    DP公式如下：\n    - **基础情况：** 对于长度为$l=0$的路径，唯一可以“到达”的节点是起始节点$s$本身（通过一条空路径）。\n      $$ D(0, v) = \\begin{cases} 0  \\text{if } v = s \\\\ -\\infty  \\text{if } v \\neq s \\end{cases} $$\n    - **递推关系：** 对于从$1$到$L$的$l$，我们通过考虑所有入边$(u, v)$来更新到达每个节点$v$的对数置信度。\n      $$\n      D(l, v) = \\max_{u \\text{ 使得 } (u,v) \\in E} \\{ D(l-1, u) + w(u, v) \\}\n      $$\n      如果没有长度为$l-1$的路径到达$v$的任何前驱节点$u$，或者如果$v$没有前驱节点，则$D(l, v)$保持为$-\\infty$。\n\n4.  **最终答案提取**\n    在填充DP表直到$l=L$后，从$s$到目标节点$t$使用*至多*$L$条边的路径的最优对数置信度是在节点$t$的所有可能路径长度条目中找到的最大值。\n    $$\n    \\max_{0 \\le l \\le L} D(l, t)\n    $$\n    我们必须遵守特定的问题约定：\n    - 如果$s = t$，允许零长度路径，其对数置信度为$0$。因此，答案必须至少为$0$。最终结果是$\\max(0, \\max_{1 \\le l \\le L} D(l, t))$。\n    - 如果在$L$条边内不存在从$s$到$t$的路径（即，对于$l \\geq 1$的所有$D(l, t)$都保持为$-\\infty$），且$s \\neq t$，则结果为$-\\infty$。\n    - 如果$s$或$t$不存在于从读长构建的图中，则不可能存在路径。如果$s=t$，结果为$0$，否则为$-\\infty$。\n\n这样就完成了算法的逻辑设计。实现将系统地遵循这些步骤。",
            "answer": "```python\nimport numpy as np\nfrom collections import defaultdict\n\ndef format_result(val):\n    \"\"\"Formats a number for the final output string.\"\"\"\n    if val == float('-inf'):\n        return '-inf'\n    return f\"{val:.6f}\"\n\ndef calculate_best_log_confidence(reads, k, alpha, s, t, L):\n    \"\"\"\n    Computes the optimal log confidence for a gap fill.\n    \"\"\"\n    # Step 1: Graph Construction\n    kmer_counts = defaultdict(int)\n    for read in reads:\n        if len(read) >= k:\n            for i in range(len(read) - k + 1):\n                kmer = read[i:i+k]\n                kmer_counts[kmer] += 1\n\n    # Adjacency list representation: graph[u] = {v1: count, v2: count}\n    graph = defaultdict(lambda: defaultdict(int))\n    nodes = set()\n    if k  2: # Nodes must have length k-1 >= 1\n        return 0.0 if s == t else float('-inf')\n\n    for kmer, count in kmer_counts.items():\n        u, v = kmer[:-1], kmer[1:]\n        graph[u][v] += count\n        nodes.add(u)\n        nodes.add(v)\n    \n    if not nodes:\n        return 0.0 if s == t else float('-inf')\n\n    node_list = sorted(list(nodes))\n    node_to_idx = {node: i for i, node in enumerate(node_list)}\n    num_nodes = len(node_list)\n\n    # Step 2: Edge Weight Calculation\n    weights = {}\n    for u, neighbors in graph.items():\n        if not neighbors:\n            continue\n        d_u = len(neighbors)\n        sum_c_u = sum(neighbors.values())\n        denominator = sum_c_u + alpha * d_u\n        for v, c_uv in neighbors.items():\n            numerator = c_uv + alpha\n            prob = numerator / denominator\n            weights[(u, v)] = np.log(prob)\n\n    # Step 3: Dynamic Programming\n    dp = np.full((L + 1, num_nodes), float('-inf'))\n\n    if s in node_to_idx:\n        s_idx = node_to_idx[s]\n        dp[0][s_idx] = 0.0\n\n    for l in range(1, L + 1):\n        for u_str, u_neighbors in graph.items():\n            if u_str not in node_to_idx: continue\n            u_idx = node_to_idx[u_str]\n            if dp[l-1][u_idx] == float('-inf'):\n                continue\n            for v_str in u_neighbors:\n                if v_str not in node_to_idx: continue\n                v_idx = node_to_idx[v_str]\n                weight = weights[(u_str, v_str)]\n                new_log_conf = dp[l-1][u_idx] + weight\n                dp[l][v_idx] = max(dp[l][v_idx], new_log_conf)\n\n    # Step 4: Final Answer Extraction\n    if t not in node_to_idx:\n        return 0.0 if s == t else float('-inf')\n        \n    t_idx = node_to_idx[t]\n    \n    # max log-confidence over paths of length 1 to L\n    max_log_conf = np.max(dp[1:, t_idx]) if L > 0 else float('-inf')\n\n    if s == t:\n        # A path of length 0 (log-conf 0) is also an option.\n        return max(0.0, max_log_conf)\n    else:\n        return max_log_conf\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (happy path, unique chain)\n        {'reads': ['ATG', 'TGA', 'TGA', 'GAC'], 'k': 3, 'alpha': 0.5, 's': 'AT', 't': 'AC', 'L': 3},\n        # Test case 2 (branching with unequal support)\n        {'reads': ['ATG', 'ATG', 'ATA', 'TGA', 'TGC', 'GCA'], 'k': 3, 'alpha': 0.5, 's': 'AT', 't': 'GA', 'L': 2},\n        # Test case 3 (no path exists)\n        {'reads': ['AAA', 'AAT', 'ATC'], 'k': 3, 'alpha': 0.5, 's': 'GG', 't': 'TT', 'L': 5},\n        # Test case 4 (boundary condition L=0 and s=t)\n        {'reads': ['AAA', 'AAT', 'ATC'], 'k': 3, 'alpha': 0.5, 's': 'AT', 't': 'AT', 'L': 0},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_best_log_confidence(\n            case['reads'], case['k'], case['alpha'], case['s'], case['t'], case['L']\n        )\n        results.append(result)\n\n    formatted_results = [format_result(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个“完成”的基因组组装序列并非绝对完美，最后的“精加工”（finishing）阶段需要仔细检查并修正其中可能存在的错误，尤其是结构性错配（structural mis-assemblies）。这些错误往往会在测序读长比对数据中留下独特的统计信号，例如在错误的连接点附近出现异常高比例的“软剪切”（soft-clipped）读长。本练习将向你展示如何将这个生物学问题转化为一个统计假设检验框架，通过识别这些统计异常来自动化地扫描整个基因组，并定位潜在的组装错误，这是保证组装质量的关键步骤 。",
            "id": "2427648",
            "problem": "给定一个已完成基因组组装中，读段（read）到组装（assembly）比对的简化抽象模型。对于由整数 $i \\in \\{0,1,\\dots,L-1\\}$ 索引的每个组装位置，提供两个非负整数：$n_i$，即与位置 $i$ 重叠的读段总数；以及 $c_i$，即为了比对而在位置 $i$ 处需要进行软剪切（soft-clip）的读段数量。假设，在正确组装的区域中，单个读段在特定位置需要软剪切的概率是独立的，为 $p_0$。因此，在正确性的零假设模型下，$C_i \\sim \\mathrm{Binomial}(n_i,p_0)$。对于显著性水平为 $\\alpha$ 的单边检验，如果零假设下的上尾概率，\n$$\n\\mathbb{P}\\left(X \\ge c_i \\mid X \\sim \\mathrm{Binomial}(n_i,p_0)\\right),\n$$\n严格小于 $\\alpha$，则位置 $i$ 被称为“异常”（abnormal）。一个“检出区域”（detected region）被定义为异常位置组成的最大连续区间 $[a,b]$（使用基于 0 的索引，包含端点），并且只报告长度至少为 $L_{\\min}$（即 $b-a+1 \\ge L_{\\min}$）的区间。\n\n您的任务是编写一个完整的程序，根据上述定义，为下面提供的每个测试用例确定并输出检出的区间 $[a,b]$ 列表。程序必须独立处理每个测试用例。所有区间端点都表示为整数，不带物理单位。不涉及角度。所有概率都必须作为 $[0,1]$ 区间内的实数处理。\n\n测试套件（每个测试用例包含 $(\\{n_i\\},\\{c_i\\},p_0,\\alpha,L_{\\min})$）：\n- 测试用例 1：\n  - $\\{n_i\\}_{i=0}^{19} = [100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100,100]$\n  - $\\{c_i\\}_{i=0}^{19} = [2,2,2,2,2,2,2,2,15,15,15,2,2,2,2,2,2,2,2,2]$\n  - $p_0 = 0.02$，$\\alpha = 10^{-6}$，$L_{\\min} = 2$\n- 测试用例 2：\n  - $\\{n_i\\}_{i=0}^{6} = [20,20,100,100,100,100,100]$\n  - $\\{c_i\\}_{i=0}^{6} = [8,8,2,2,2,2,2]$\n  - $p_0 = 0.02$，$\\alpha = 10^{-6}$，$L_{\\min} = 2$\n- 测试用例 3：\n  - $\\{n_i\\}_{i=0}^{7} = [5,5,5,5,5,100,100,100]$\n  - $\\{c_i\\}_{i=0}^{7} = [2,0,2,0,2,4,4,4]$\n  - $p_0 = 0.02$，$\\alpha = 10^{-3}$，$L_{\\min} = 2$\n\n最终输出格式：您的程序应生成单行输出，其中包含一个由方括号括起的逗号分隔列表。列表中的每个元素对应一个测试用例，每个测试用例由一个检出区间的列表表示，每个区间以双元素列表 $[a,b]$ 的形式编写（使用基于 0 的索引和包含端点）。例如，整体格式为 $[R_1,R_2,R_3]$，其中每个 $R_j$ 是一个列表，如 $[[a_1,b_1],[a_2,b_2],\\dots]$。例如，如果三个测试用例产生的结果分别是区间 $[[8,10]]$、 $[[0,1]]$ 和 $[]$，则程序必须打印单行 $[[[8,10]],[[0,1]],[]]$。",
            "solution": "在尝试任何解决方案之前，问题陈述都经过强制性验证过程。\n\n### 第 1 步：提取已知条件\n从问题陈述中逐字提取已知条件：\n- 组装包含 $L$ 个位置，由 $i \\in \\{0, 1, \\dots, L-1\\}$ 索引。\n- 对于每个位置 $i$，给定两个非负整数：\n    - $n_i$：与位置 $i$ 重叠的读段总数。\n    - $c_i$：在位置 $i$ 被软剪切的读段数量。\n- 正确组装区域的零假设模型假定，软剪切读段的计数 $C_i$ 服从二项分布：$C_i \\sim \\mathrm{Binomial}(n_i, p_0)$，其中 $p_0$ 是单个读段需要软剪切的概率。\n- 如果零假设模型下的上尾概率严格小于显著性水平 $\\alpha$，则位置 $i$ 被指定为“异常”（abnormal）：\n$$\n\\mathbb{P}\\left(X \\ge c_i \\mid X \\sim \\mathrm{Binomial}(n_i, p_0)\\right)  \\alpha\n$$\n- 一个“检出区域”是异常位置组成的最大连续区间 $[a, b]$，采用基于 0 的包含性索引。\n- 只报告长度至少为 $L_{\\min}$（即 $b - a + 1 \\ge L_{\\min}$）的检出区域。\n- 提供了三个测试用例，每个用例由一个元组 $(\\{n_i\\}, \\{c_i\\}, p_0, \\alpha, L_{\\min})$ 定义。\n\n### 第 2 步：使用提取的已知条件进行验证\n根据有效性标准对问题进行评估：\n\n- **科学依据充分：** 该问题牢固地植根于计算生物学和统计遗传学。在零假设下使用二项分布对读段计数数据进行建模，是识别序列比对中异常情况的标准且可靠的做法。此类统计检验是基因组组装质量控制和结构变异检测的基础。该问题在科学上是有效的。\n- **问题定义明确：** 该问题没有歧义，并提供了一个清晰的确定性算法。每个测试用例的所有必要参数（$n_i$、$c_i$、$p_0$、$\\alpha$、$L_{\\min}$）都已指定。“异常位置”和“检出区域”的定义是精确的数学和逻辑构造。每个测试用例都存在唯一解。\n- **客观性：** 问题以客观、形式化的语言表述。没有主观陈述、观点或含糊之处。\n\n### 第 3 步：结论与行动\n该问题是**有效的**。它是一个定义明确的计算任务，基于可靠的科学和统计原理。可以构建一个严谨的解决方案。\n\n### 解决方案推导\n\n对于每个测试用例，解决方案都遵循一个基于统计假设检验的多步骤过程。目标是识别出基因组中观测到的软剪切读段数量异常高的区域，这表明其偏离了正确组装的零假设模型。\n\n对于由参数 $(\\{n_i\\}_{i=0}^{L-1}, \\{c_i\\}_{i=0}^{L-1}, p_0, \\alpha, L_{\\min})$ 表征的每个测试用例：\n\n**1. 识别异常位置**\n\n对于从 $0$ 到 $L-1$ 的每个位置 $i$，我们执行单边假设检验。零假设 $H_0$ 是该位置组装正确，软剪切读段的数量是一个随机变量 $X \\sim \\mathrm{Binomial}(n_i, p_0)$。备择假设 $H_1$ 是软剪切读段的数量显著高于在 $H_0$ 下的预期。\n\n我们计算 p 值，即假设 $H_0$ 为真时，观测到至少与观测计数 $c_i$ 一样极端的结果的概率。这对应于二项分布的上尾概率，或称生存函数（SF）：\n$$\nP_i = \\mathbb{P}(X \\ge c_i) = \\sum_{k=c_i}^{n_i} \\binom{n_i}{k} p_0^k (1 - p_0)^{n_i-k}\n$$\n如果位置 $i$ 的 p 值 $P_i$ 严格小于预定的显著性水平 $\\alpha$，则该位置被分类为“异常”。此过程应用于所有位置，从而产生一个布尔向量，指示哪些位置是异常的。\n\n**2. 分组成连续区域**\n\n下一步是识别所有异常位置组成的最大连续区间。我们遍历异常位置的布尔向量，并将连续的 `True` 值分组。例如，如果位置 $i, i+1, \\dots, j$ 都是异常的，但 $i-1$ 和 $j+1$ 不是（或超出边界），那么 $[i, j]$ 就构成一个最大连续区域。\n\n**3. 按最小长度筛选**\n\n最后，对每个识别出的区域 $[a, b]$ 进行长度筛选。区间的长度计算为 $b - a + 1$。只有长度大于或等于指定的最小长度 $L_{\\min}$ 的区域才会被保留并报告为检出区域。\n\n这个完整的算法独立地应用于问题陈述中提供的每个测试用例。使用具有稳健统计函数实现的计算库（如 `scipy.stats`）对于准确计算二项分布的生存函数至关重要，特别是对于较大的 $n_i$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import binom\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases as specified.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1:\n        (\n            np.array([100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100], dtype=np.int64),\n            np.array([2, 2, 2, 2, 2, 2, 2, 2, 15, 15, 15, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=np.int64),\n            0.02,\n            1e-6,\n            2\n        ),\n        # Test Case 2:\n        (\n            np.array([20, 20, 100, 100, 100, 100, 100], dtype=np.int64),\n            np.array([8, 8, 2, 2, 2, 2, 2], dtype=np.int64),\n            0.02,\n            1e-6,\n            2\n        ),\n        # Test Case 3:\n        (\n            np.array([5, 5, 5, 5, 5, 100, 100, 100], dtype=np.int64),\n            np.array([2, 0, 2, 0, 2, 4, 4, 4], dtype=np.int64),\n            0.02,\n            1e-3,\n            2\n        ),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        n_i, c_i, p_0, alpha, L_min = case\n        \n        # Step 1: Identify abnormal positions\n        # Calculate P(X >= c_i) for each position.\n        # This is the survival function P(X > k) where k = c_i - 1.\n        # For c_i = 0, sf(-1) is 1.0, which is correct.\n        p_values = binom.sf(c_i - 1, n_i, p_0)\n        is_abnormal = p_values  alpha\n        \n        # Step 2: Group into contiguous regions\n        candidate_regions = []\n        in_region = False\n        start_index = -1\n        \n        for i, abnormal_flag in enumerate(is_abnormal):\n            if abnormal_flag and not in_region:\n                # Start of a new potential region\n                in_region = True\n                start_index = i\n            elif not abnormal_flag and in_region:\n                # End of the current region\n                in_region = False\n                end_index = i - 1\n                candidate_regions.append([start_index, end_index])\n        \n        # Handle the case where the sequence ends with an abnormal region\n        if in_region:\n            candidate_regions.append([start_index, len(is_abnormal) - 1])\n            \n        # Step 3: Filter regions by minimum length\n        detected_regions = []\n        for region in candidate_regions:\n            start, end = region\n            length = end - start + 1\n            if length >= L_min:\n                detected_regions.append(region)\n                \n        all_results.append(detected_regions)\n\n    # Convert results to the required string format\n    # Example: [[[8,10]],[[0,1]],[]]\n    result_str = str(all_results).replace(\" \", \"\")\n    print(result_str)\n\nsolve()\n```"
        }
    ]
}