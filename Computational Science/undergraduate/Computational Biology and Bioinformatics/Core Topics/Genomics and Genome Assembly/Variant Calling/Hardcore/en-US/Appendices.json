{
    "hands_on_practices": [
        {
            "introduction": "The journey to discovering a genetic variant begins with sequence alignment, the process of mapping short sequencing reads to a reference genome. This fundamental exercise delves into how alignment algorithms score potential variants, specifically insertions and deletions (indels). By calculating an alignment score using the affine gap penalty model, you will gain insight into the quantitative logic that underpins the identification of these important structural variations from raw sequencing data .",
            "id": "2439464",
            "problem": "A single-end read has been aligned to a reference genome, and the alignment can be summarized in the Concise Idiosyncratic Gapped Alignment Report (CIGAR) notation using the operations $M$ (alignment match or mismatch consuming one read and one reference base), $I$ (insertion relative to the reference consuming read bases but not reference bases), and $D$ (deletion relative to the reference consuming reference bases but not read bases). The alignment consists of exactly three consecutive segments in this order: a contiguous insertion of length $5$ relative to the reference, followed by $10$ aligned matches to the reference, followed by a contiguous deletion of length $3$ relative to the reference. There are no other operations and no soft or hard clipping.\n\nAssume an affine gap scoring scheme is used for computing an alignment score, where each aligned match contributes $+m$ points per base, and each contiguous gap of length $\\ell \\ge 1$ (either an insertion or a deletion) incurs a penalty of $g_o + (\\ell - 1) g_e$ that is subtracted from the total score. Let $m = 2$, $g_o = 3$, and $g_e = 1$.\n\nWhat is the total alignment score for this alignment under these assumptions? Report your answer as a single integer with no units.",
            "solution": "The problem statement is submitted for validation.\n\nFirst, we extract the given information verbatim.\n- The alignment consists of three consecutive segments: an insertion of length $5$, followed by $10$ matches, followed by a deletion of length $3$.\n- The scoring scheme is an affine gap model.\n- Score for an aligned match per base: $+m$.\n- Penalty for a contiguous gap of length $\\ell \\ge 1$: $g_o + (\\ell - 1) g_e$. This penalty is subtracted from the score.\n- Parameter values: $m = 2$, $g_o = 3$, $g_e = 1$.\n\nNext, we validate the problem based on these givens.\nThe problem is scientifically grounded. The CIGAR notation, alignment concepts (match, insertion, deletion), and the affine gap penalty model are fundamental and standard components of sequence alignment algorithms in bioinformatics. The problem is a direct and practical application of these principles.\nThe problem is well-posed. It provides all necessary parameters and a complete description of the alignment structure, which allows for the calculation of a single, unambiguous numerical score. There are no contradictions or missing pieces of information. The language is precise and objective.\n\nThe verdict is that the problem is valid. We shall proceed with the solution.\n\nThe total alignment score, which we denote as $S$, is the sum of the scores from the constituent parts of the alignment. The alignment has three parts:\n1. A series of $N_M = 10$ aligned matches.\n2. A contiguous insertion of length $\\ell_I = 5$.\n3. A contiguous deletion of length $\\ell_D = 3$.\n\nThe total score $S$ is calculated by summing the positive contributions from matches and subtracting the penalties from the gaps (insertion and deletion).\nThe total score from the matches, $S_M$, is the number of matches multiplied by the score per match:\n$$S_M = N_M \\times m$$\n\nThe penalty for a gap is given by the affine gap penalty function $P(\\ell) = g_o + (\\ell - 1) g_e$, where $\\ell$ is the length of the gap.\nThe penalty for the insertion of length $\\ell_I = 5$, denoted $P_I$, is:\n$$P_I = g_o + (\\ell_I - 1) g_e$$\n\nThe penalty for the deletion of length $\\ell_D = 3$, denoted $P_D$, is:\n$$P_D = g_o + (\\ell_D - 1) g_e$$\n\nThe total alignment score $S$ is therefore:\n$$S = S_M - P_I - P_D$$\n\nNow, we substitute the given values into these expressions. The parameters are:\n- Number of matches, $N_M = 10$.\n- Score per match, $m = 2$.\n- Length of insertion, $\\ell_I = 5$.\n- Length of deletion, $\\ell_D = 3$.\n- Gap opening penalty, $g_o = 3$.\n- Gap extension penalty, $g_e = 1$.\n\nFirst, we calculate the score from the matches:\n$$S_M = 10 \\times 2 = 20$$\n\nNext, we calculate the penalty for the insertion:\n$$P_I = 3 + (5 - 1) \\times 1 = 3 + (4 \\times 1) = 3 + 4 = 7$$\nThis penalty of $7$ is subtracted from the total score.\n\nThen, we calculate the penalty for the deletion:\n$$P_D = 3 + (3 - 1) \\times 1 = 3 + (2 \\times 1) = 3 + 2 = 5$$\nThis penalty of $5$ is also subtracted from the total score.\n\nFinally, we compute the total alignment score $S$:\n$$S = S_M - P_I - P_D = 20 - 7 - 5 = 8$$\n\nThe total score for the described alignment is $8$.",
            "answer": "$$\\boxed{8}$$"
        },
        {
            "introduction": "After alignment, a variant caller assesses the evidence for a variant at each position. This practice explores the statistical heart of modern variant calling, moving beyond simple allele counts to a more nuanced, likelihood-based approach. By evaluating different genetic scenarios, you will learn how to interpret allele balance in the context of sequencing errors and copy number variations, a key skill for distinguishing true variants from artifacts .",
            "id": "2439432",
            "problem": "A whole-genome short-read sequencing experiment on a germline sample reports a candidate single nucleotide polymorphism (SNP) at a locus with total depth $n = 50$ and $k = 45$ reads supporting the alternate allele, giving an allele balance $AB = k/n = 0.9$. Assume per-base sequencing error rate $\\epsilon = 0.01$, unbiased mapping, and independent reads. Let the expected fraction of reads supporting the alternate allele be determined by the underlying allele copy proportions and sequencing error: if there are $a$ copies of the alternate allele and $r$ copies of the reference allele at this locus due to a copy number variation (CNV), then the true alternate-allele proportion is $p = a/(a+r)$, and a read supports the alternate base with probability $p_{\\mathrm{eff}} = p(1-\\epsilon) + (1-p)\\epsilon$. The sample is germline, and at this locus the total copy number is known to be in $\\{1,2,3,4\\}$.\n\nWhich interpretation is most consistent with the observed allele balance $AB = 0.9$ under these assumptions?\n\nA. A true homozygous alternate variant in a diploid region (no CNV), i.e., $a = 2$, $r = 0$.\n\nB. A heterozygous variant in a region with total copy number $3$, with $a = 2$ and $r = 1$.\n\nC. A heterozygous variant in a region with total copy number $4$, with $a = 3$ and $r = 1$.\n\nD. No true variant is present; the $k = 45$ alternate reads arise entirely from random sequencing errors at rate $\\epsilon = 0.01$.\n\nSelect the single best choice.",
            "solution": "The problem statement has been validated and found to be scientifically sound, well-posed, objective, and self-contained. The data provided are realistic and sufficient for a rigorous analysis. We shall now proceed to the solution.\n\nThe task is to determine which of the four proposed scenarios is most consistent with the experimental observation of $k=45$ reads supporting an alternate allele out of a total sequencing depth of $n=50$. The observed allele balance is therefore $AB = k/n = 45/50 = 0.9$. Consistency is to be evaluated in a statistical sense, meaning we must find the scenario under which the observed data are most probable, i.e., have the highest likelihood.\n\nThe number of reads supporting the alternate allele, $k$, can be modeled as a random variable following a binomial distribution, $k \\sim \\mathrm{Binomial}(n, p_{\\mathrm{eff}})$, where $p_{\\mathrm{eff}}$ is the effective probability that a single read supports the alternate allele. The likelihood of observing $k$ alternate reads in a sample of $n$ reads is given by the binomial probability mass function:\n$$L(p_{\\mathrm{eff}} | k, n) = P(k | n, p_{\\mathrm{eff}}) = \\binom{n}{k} (p_{\\mathrm{eff}})^k (1-p_{\\mathrm{eff}})^{n-k}$$\nSince the term $\\binom{n}{k} = \\binom{50}{45}$ is a constant for all scenarios, we only need to compare the values of $(p_{\\mathrm{eff}})^k (1-p_{\\mathrm{eff}})^{n-k}$ for each option. For numerical stability and convenience, it is often simpler to compare the log-likelihoods. The term to be maximized is proportional to the log-likelihood:\n$$\\ln(L) \\propto k \\ln(p_{\\mathrm{eff}}) + (n-k) \\ln(1 - p_{\\mathrm{eff}})$$\nSubstituting the observed values $k=45$ and $n=50$, we evaluate the expression:\n$$45 \\ln(p_{\\mathrm{eff}}) + 5 \\ln(1 - p_{\\mathrm{eff}})$$\nThe value of $p_{\\mathrm{eff}}$ depends on the true underlying allele proportion, $p = a/(a+r)$, and the sequencing error rate, $\\epsilon = 0.01$, according to the given formula:\n$$p_{\\mathrm{eff}} = p(1-\\epsilon) + (1-p)\\epsilon$$\nWe will now calculate $p_{\\mathrm{eff}}$ and the corresponding log-likelihood term for each of the four options.\n\n**Option A: A true homozygous alternate variant in a diploid region (no CNV), i.e., $a = 2$, $r = 0$.**\nIn this scenario, the true alternate-allele proportion is $p = a/(a+r) = 2/(2+0) = 1$.\nThe effective probability of observing an alternate allele is:\n$$p_{\\mathrm{eff,A}} = 1(1-0.01) + (1-1)(0.01) = 1(0.99) + 0(0.01) = 0.99$$\nThe log-likelihood term is:\n$$\\ln(L_A) \\propto 45 \\ln(0.99) + 5 \\ln(1-0.99) = 45 \\ln(0.99) + 5 \\ln(0.01)$$\n$$\\ln(L_A) \\propto 45(-0.01005) + 5(-4.60517) = -0.45225 - 23.02585 = -23.4781$$\nThe observed allele balance of $0.9$ deviates from the expected $0.99$. The five observed reference-supporting reads are highly improbable if the probability of sequencing a reference allele is only $1-p_{\\mathrm{eff,A}} = 0.01$.\n\n**Option B: A heterozygous variant in a region with total copy number $3$, with $a = 2$ and $r = 1$.**\nHere, the true alternate-allele proportion is $p = a/(a+r) = 2/(2+1) = 2/3$.\nThe effective probability of observing an alternate allele is:\n$$p_{\\mathrm{eff,B}} = \\frac{2}{3}(1-0.01) + \\left(1-\\frac{2}{3}\\right)(0.01) = \\frac{2}{3}(0.99) + \\frac{1}{3}(0.01) = \\frac{1.98 + 0.01}{3} = \\frac{1.99}{3} \\approx 0.6633$$\nThe log-likelihood term is:\n$$\\ln(L_B) \\propto 45 \\ln\\left(\\frac{1.99}{3}\\right) + 5 \\ln\\left(1-\\frac{1.99}{3}\\right) = 45 \\ln\\left(\\frac{1.99}{3}\\right) + 5 \\ln\\left(\\frac{1.01}{3}\\right)$$\n$$\\ln(L_B) \\propto 45(-0.41050) + 5(-1.08864) = -18.4725 - 5.4432 = -23.9157$$\nThis log-likelihood is lower (more negative) than that of Option A, indicating it is even less consistent with the data.\n\n**Option C: A heterozygous variant in a region with total copy number $4$, with $a = 3$ and $r = 1$.**\nThe true alternate-allele proportion is $p = a/(a+r) = 3/(3+1) = 3/4 = 0.75$.\nThe effective probability of observing an alternate allele is:\n$$p_{\\mathrm{eff,C}} = \\frac{3}{4}(1-0.01) + \\left(1-\\frac{3}{4}\\right)(0.01) = 0.75(0.99) + 0.25(0.01) = 0.7425 + 0.0025 = 0.745$$\nThe log-likelihood term is:\n$$\\ln(L_C) \\propto 45 \\ln(0.745) + 5 \\ln(1-0.745) = 45 \\ln(0.745) + 5 \\ln(0.255)$$\n$$\\ln(L_C) \\propto 45(-0.29440) + 5(-1.36649) = -13.2480 - 6.83245 = -20.08045$$\nThis log-likelihood value is the highest (least negative) among all options considered so far. A superficial analysis might favor Option A because its expected allele balance ($0.99$) is arithmetically closer to the observed $0.9$ than Option C's ($0.745$). However, this is incorrect. The binomial likelihood function, $L(p) \\propto p^{45}(1-p)^5$, is highly asymmetric around its maximum at $p=0.9$. The penalty for deviation is much more severe for $p>0.9$ due to the $(1-p)^5$ term. Observing $5$ reads of a type expected with probability $0.01$ (Option A) is far less likely than observing $45$ reads of a type expected with probability $0.745$ (Option C).\n\n**Option D: No true variant is present.**\nThis implies a homozygous reference genotype. Assuming a diploid region ($a=0, r=2$), the true alternate-allele proportion is $p = 0/(0+2) = 0$.\nThe effective probability of observing an alternate allele is due entirely to sequencing error:\n$$p_{\\mathrm{eff,D}} = 0(1-0.01) + (1-0)(0.01) = 0.01$$\nThe log-likelihood term is:\n$$\\ln(L_D) \\propto 45 \\ln(0.01) + 5 \\ln(0.99)$$\n$$\\ln(L_D) \\propto 45(-4.60517) + 5(-0.01005) = -207.23265 - 0.05025 = -207.2829$$\nThis log-likelihood is extremely low, indicating that observing $45$ alternate reads when they are expected only from error is virtually impossible. This is the least plausible scenario by a very large margin.\n\n**Conclusion:**\nComparing the log-likelihood terms for all options:\n- Option A: $-23.4781$\n- Option B: $-23.9157$\n- Option C: $-20.08045$\n- Option D: $-207.2829$\n\nThe highest log-likelihood corresponds to Option C. Therefore, the interpretation most consistent with the observed data is a heterozygous variant in a region with total copy number $4$, having three copies of the alternate allele and one copy of the reference allele.\n\n**Option-by-Option Verdict:**\n- A: **Incorrect**. While the expected allele balance of $0.99$ seems close to the observation of $0.9$, the likelihood of observing $5$ reference reads is extremely low under this model, making it less plausible than Option C.\n- B: **Incorrect**. The expected allele balance of approximately $0.663$ is far from the observation, and the corresponding likelihood is lower than for options A and C.\n- C: **Correct**. This scenario maximizes the likelihood of the observed data among the given choices. The statistical evidence strongly supports this interpretation over the others.\n- D: **Incorrect**. The observation of $45$ alternate reads cannot be plausibly explained by random sequencing error alone. The likelihood for this scenario is vanishingly small.",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "A raw list of variant calls is rarely perfect; it must be filtered to remove false positives. However, filtering is a double-edged sword that can also remove true variants if applied naively. This exercise examines a critical edge case for the widely-used QualByDepth ($QD$) metric, demonstrating why understanding the assumptions and limitations of quality scores is essential for building a robust and accurate variant calling pipeline .",
            "id": "2439414",
            "problem": "A laboratory uses a hard-filtering rule that removes any called variant with a QualByDepth (QD) annotation below a fixed threshold. QualByDepth (QD) is defined as the variant confidence on the Phred scale divided by the unfiltered depth of coverage at the locus, i.e., $QD = QUAL / DP$, where $QUAL$ is the Phred-scaled variant confidence and $DP$ is the unfiltered depth of coverage. The Phred scale is defined by $Q = -10 \\log_{10} p$, where $p$ is the error probability of the call. The lab sets a hard filter to remove variants with $QD < 2.0$.\n\nConsider the following four scenarios. In each scenario, assume the variant caller and aligner were properly configured and that read base qualities and mapping qualities are typical for modern short-read sequencing. Which option best exemplifies an edge case in which filtering on low $QD$ would remove a true positive variant?\n\nA. Targeted amplicon sequencing of a known germline heterozygous Single Nucleotide Polymorphism (SNP). The locus is captured extremely deeply, with unfiltered depth $DP = 4000$. The variant caller down-samples internally to limit evidence for genotype likelihoods, yielding a variant confidence $QUAL = 350$ based on an effective subset of reads. The allele balance among non-duplicated, high-quality reads is consistent with a heterozygote, and orthogonal validation confirms the SNP is real.\n\nB. Whole-genome sequencing at typical coverage of approximately $30\\times$. A germline heterozygous SNP has unfiltered depth $DP = 30$, variant confidence $QUAL = 200$, and an alternate allele fraction near $0.5$. Independent validation confirms the SNP is real.\n\nC. Whole-exome sequencing with modest coverage variability. A germline heterozygous insertion/deletion (indel) call is supported by unfiltered depth $DP = 8$, with variant confidence $QUAL = 30$ and balanced allele counts across both strands. Independent long-read sequencing confirms the indel is real.\n\nD. A short homopolymer run in a low-complexity region shows an apparent indel with unfiltered depth $DP = 120$ but variant confidence $QUAL = 20$. The signal appears in many unrelated samples processed across different batches, suggesting a recurrent sequencing or alignment artifact rather than a true biological variant.",
            "solution": "The problem requires the identification of a specific scenario from a set of four options that best exemplifies an edge case where a true positive variant is erroneously filtered out by a low QualByDepth (QD) threshold. The filtering criterion is defined as removing any variant where $QD < 2.0$. The QualByDepth metric itself is defined as the ratio of the Phred-scaled variant confidence ($QUAL$) to the unfiltered depth of coverage ($DP$), such that $QD = QUAL / DP$. A true positive is a variant that is biologically real and has been correctly identified by the variant caller. The task is therefore to find the option describing a confirmed true variant for which the calculated $QD$ value falls below the $2.0$ threshold, leading to its incorrect removal.\n\nLet us analyze each scenario methodically.\n\nFirst, we establish the filtering rule: A variant is removed if $QD < 2.0$.\n\nOption A: Targeted amplicon sequencing of a known germline heterozygous Single Nucleotide Polymorphism (SNP).\n- Givens: The unfiltered depth is $DP = 4000$. The variant confidence, limited by internal down-sampling, is $QUAL = 350$. The variant is confirmed as a true positive (\"orthogonal validation confirms the SNP is real\").\n- Calculation of $QD$:\n$$QD = \\frac{QUAL}{DP} = \\frac{350}{4000} = \\frac{35}{400} = \\frac{7}{80} = 0.0875$$\n- Evaluation: The calculated $QD$ value is $0.0875$. Since $0.0875 < 2.0$, this variant would be removed by the hard filter. The problem explicitly states this is a true positive variant. This scenario represents a classic failure mode for the $QD$ metric. In regions of extremely high coverage, such as those produced by amplicon sequencing, the denominator $DP$ becomes very large. Even if the absolute variant confidence $QUAL$ is extremely high (a $QUAL$ of $350$ corresponds to a vanishingly small error probability of $10^{-35}$), the $QD$ ratio can be artificially suppressed. Variant callers often down-sample reads in such high-depth regions to maintain computational tractability, which can cap the maximum achievable $QUAL$ score. The combination of a capped $QUAL$ and an extremely large $DP$ leads to a low $QD$ value, causing the erroneous rejection of a high-confidence, true positive call. This situation precisely matches the description of a problematic edge case for $QD$ filtering.\n- Verdict: **Correct**. This option perfectly exemplifies an edge case where a low $QD$-based filter removes a true positive variant.\n\nOption B: Whole-genome sequencing at typical coverage.\n- Givens: The unfiltered depth is $DP = 30$. The variant confidence is $QUAL = 200$. The variant is a confirmed true positive SNP.\n- Calculation of $QD$:\n$$QD = \\frac{QUAL}{DP} = \\frac{200}{30} \\approx 6.67$$\n- Evaluation: The calculated $QD$ value is approximately $6.67$. Since $6.67 > 2.0$, this variant would *not* be removed by the filter. This scenario describes a high-quality true positive variant that is correctly passed by the filter. It does not illustrate a failure of the filter.\n- Verdict: **Incorrect**.\n\nOption C: Whole-exome sequencing with modest coverage.\n- Givens: The unfiltered depth is $DP = 8$. The variant confidence is $QUAL = 30$. The variant is a confirmed true positive indel.\n- Calculation of $QD$:\n$$QD = \\frac{QUAL}{DP} = \\frac{30}{8} = 3.75$$\n- Evaluation: The calculated $QD$ value is $3.75$. Since $3.75 > 2.0$, this variant would *not* be removed by the filter. While the depth is low, the confidence is sufficiently high relative to the depth to produce a good $QD$ score. This is an example of a true positive call that correctly passes the filter.\n- Verdict: **Incorrect**.\n\nOption D: An apparent indel in a low-complexity region.\n- Givens: The unfiltered depth is $DP = 120$. The variant confidence is $QUAL = 20$. The problem text states that the signal is a \"recurrent sequencing or alignment artifact rather than a true biological variant\". This means it is a false positive.\n- The primary goal is to find an example of a *true positive* being filtered. Since this scenario describes a likely *false positive*, it cannot be the correct answer, irrespective of the $QD$ value.\n- For completeness, we calculate the $QD$:\n$$QD = \\frac{QUAL}{DP} = \\frac{20}{120} = \\frac{1}{6} \\approx 0.167$$\n- Evaluation: The calculated $QD$ is approximately $0.167$. Since $0.167 < 2.0$, the variant would be filtered. However, since the variant is described as an artifact (a false positive), its removal represents a *success* of the filtering strategy, not a failure. The low $QUAL$ score of $20$ relative to the substantial depth of $120$ is exactly the type of low-quality signal that the $QD$ metric is designed to detect and filter out.\n- Verdict: **Incorrect**.\n\nConclusion: Only scenario A describes a situation where a confirmed true positive variant is filtered out by the $QD < 2.0$ rule. This occurs due to an artifact of the $QD$ calculation in an edge case of extremely high sequencing depth, which is a known limitation of this particular filtering metric.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}