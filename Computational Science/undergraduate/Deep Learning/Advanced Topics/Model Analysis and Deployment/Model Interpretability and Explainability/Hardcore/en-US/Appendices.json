{
    "hands_on_practices": [
        {
            "introduction": "Many interpretability methods aim to assign importance scores to input features. This practice explores the relationship between two intuitive approaches: perturbation-based attribution (occlusion) and gradient-based attribution (Gradient $\\times$ Input). While they may seem similar, their equivalence hinges on the model's underlying mathematical structure. This exercise challenges you to derive the precise conditions under which these methods agree and to quantify their discrepancy in the presence of nonlinear feature interactions , providing a foundational understanding of why different explanation methods can produce different results.",
            "id": "3153229",
            "problem": "Consider a predictive model $f: \\mathbb{R}^{d} \\to \\mathbb{R}$ and a zero-baseline occlusion ablation procedure which, for an input $x \\in \\mathbb{R}^{d}$ and feature index $j \\in \\{1,\\dots,d\\}$, defines the occlusion attribution for feature $j$ as $A_{\\mathrm{occ},j}(x) \\triangleq f(x) - f\\big(x^{(j \\leftarrow 0)}\\big)$, where $x^{(j \\leftarrow 0)}$ is the vector obtained from $x$ by setting its $j$-th coordinate to $0$ and keeping all other coordinates unchanged. The Gradient times Input attribution is defined as $A_{\\mathrm{gxi},j}(x) \\triangleq x_{j} \\,\\frac{\\partial f}{\\partial x_{j}}(x)$.\n\n1) Using only the linearity of differentiation and the definition of affine linear functions, derive the necessary and sufficient conditions under which $A_{\\mathrm{occ},j}(x) = A_{\\mathrm{gxi},j}(x)$ for every input $x \\in \\mathbb{R}^{d}$ and every feature index $j \\in \\{1,\\dots,d\\}$.\n\n2) Now consider the specific nonlinear model in $d=3$ defined by\n$$\nf(x) \\;=\\; w^{\\top}x \\;+\\; b \\;+\\; \\gamma\\, x_{1} x_{2} \\;+\\; \\delta\\, x_{2}^{2},\n$$\nwith parameters $w = (1,-2,3)$, $b = 0$, $\\gamma = \\tfrac{1}{2}$, $\\delta = -1$, and the input $x = (2,-1,4)$. For feature $j=2$, compute the occlusion attribution $A_{\\mathrm{occ},2}(x)$ and the Gradient times Input attribution $A_{\\mathrm{gxi},2}(x)$, and then define the discrepancy\n$$\nD \\;\\triangleq\\; A_{\\mathrm{occ},2}(x) \\;-\\; A_{\\mathrm{gxi},2}(x).\n$$\nReport $D$ as your final answer. No rounding is required, and the answer is unitless.",
            "solution": "This problem consists of two parts. The first part requires deriving the necessary and sufficient conditions for the equality of occlusion attribution and Gradient-times-Input attribution. The second part involves a direct computation of these quantities and their difference for a specific nonlinear model.\n\n### Part 1: Derivation of Necessary and Sufficient Conditions\n\nWe are given two attribution methods for a function $f: \\mathbb{R}^{d} \\to \\mathbb{R}$:\n1.  The zero-baseline occlusion attribution: $A_{\\mathrm{occ},j}(x) \\triangleq f(x) - f\\big(x^{(j \\leftarrow 0)}\\big)$.\n2.  The Gradient-times-Input attribution: $A_{\\mathrm{gxi},j}(x) \\triangleq x_{j} \\,\\frac{\\partial f}{\\partial x_{j}}(x)$.\n\nThe problem asks for the necessary and sufficient conditions on $f$ such that $A_{\\mathrm{occ},j}(x) = A_{\\mathrm{gxi},j}(x)$ for every input $x \\in \\mathbb{R}^{d}$ and every feature index $j \\in \\{1,\\dots,d\\}$. The condition is thus:\n$$\nf(x) - f\\big(x^{(j \\leftarrow 0)}\\big) = x_{j} \\frac{\\partial f}{\\partial x_{j}}(x) \\quad \\forall x \\in \\mathbb{R}^d, \\forall j \\in \\{1, \\dots, d\\}\n$$\n\nLet us analyze this condition for a single, arbitrary feature $j$. To isolate the dependence on the variable $x_j$, we fix all other coordinates $x_k$ for $k \\neq j$. We define a single-variable function $g: \\mathbb{R} \\to \\mathbb{R}$ as follows:\n$$\ng(t) \\triangleq f(x_1, \\dots, x_{j-1}, t, x_{j+1}, \\dots, x_d)\n$$\nThe partial derivative of $f$ with respect to $x_j$ is the ordinary derivative of $g$ with respect to its argument: $\\frac{\\partial f}{\\partial x_{j}}(x) = g'(x_j)$. The vector $x^{(j \\leftarrow 0)}$ corresponds to setting the argument of $g$ to $0$, so $f(x^{(j \\leftarrow 0)}) = g(0)$. With this notation, the required condition for the specific feature $j$ and input $x$ becomes an equation for $g$ evaluated at $t=x_j$:\n$$\ng(x_j) - g(0) = x_j g'(x_j)\n$$\nSince this must hold for any $x \\in \\mathbb{R}^d$, it must hold for any value of $x_j$. Let's replace $x_j$ with a generic variable $t$. The function $g(t)$ must satisfy the identity:\n$$\ng(t) - g(0) = t g'(t) \\quad \\forall t \\in \\mathbb{R}\n$$\nWe can rearrange this into a first-order ordinary differential equation for $g(t)$. Let's define a new function $H(t) \\triangleq g(t) - t g'(t)$. The condition is equivalent to stating that $H(t) = g(0)$ for all $t$. Since $g(0)$ is a constant with respect to $t$, the function $H(t)$ must be constant. Consequently, its derivative with respect to $t$ must be zero for all $t$.\n$$\nH'(t) = \\frac{d}{dt} \\left( g(t) - t g'(t) \\right) = 0\n$$\nUsing the linearity of differentiation and the product rule, we find:\n$$\ng'(t) - \\left( \\frac{d}{dt}(t) \\cdot g'(t) + t \\cdot \\frac{d}{dt}(g'(t)) \\right) = 0\n$$\n$$\ng'(t) - (1 \\cdot g'(t) + t \\cdot g''(t)) = 0\n$$\n$$\n-t g''(t) = 0\n$$\nFor this equation to hold for all $t \\in \\mathbb{R}$, we must have $g''(t) = 0$ for all $t \\ne 0$. If we assume $f$ is a twice continuously differentiable function ($C^2$), then $g''(t)$ is continuous, which implies $g''(t)=0$ for all $t \\in \\mathbb{R}$.\n\nThe condition $g''(t) = 0$ means that the second derivative of $g$ is zero. Integrating twice with respect to $t$ yields:\n$g'(t) = c_1$\n$g(t) = c_1 t + c_2$\nwhere $c_1$ and $c_2$ are constants of integration. This is the definition of an affine linear function. The constants $c_1$ and $c_2$ can depend on the other coordinates $x_k$ ($k \\ne j$) that were held fixed.\nIn terms of $f$, the condition $g''(t)=0$ is $\\frac{\\partial^2 f}{\\partial x_j^2} = 0$. This must hold for all $j \\in \\{1, \\dots, d\\}$.\n\nThis implies that for each $j$, the partial derivative $\\frac{\\partial f}{\\partial x_j}$ is independent of $x_j$. Let's write this as:\n$$\n\\frac{\\partial f}{\\partial x_j}(x) = \\phi_j(x_1, \\dots, x_{j-1}, x_{j+1}, \\dots, x_d)\n$$\nThis must hold for every $j \\in \\{1, \\dots, d\\}$. Now, we use the equality of mixed partial derivatives (Clairaut's theorem), assuming $f \\in C^2$. For any two distinct indices $j, k$:\n$$\n\\frac{\\partial^2 f}{\\partial x_k \\partial x_j} = \\frac{\\partial^2 f}{\\partial x_j \\partial x_k}\n$$\n$$\n\\frac{\\partial}{\\partial x_k} \\left( \\frac{\\partial f}{\\partial x_j} \\right) = \\frac{\\partial \\phi_j}{\\partial x_k}\n$$\n$$\n\\frac{\\partial}{\\partial x_j} \\left( \\frac{\\partial f}{\\partial x_k} \\right) = \\frac{\\partial \\phi_k}{\\partial x_j}\n$$\nSince $\\phi_j$ is independent of $x_j$ and $\\phi_k$ is independent of $x_k$, $\\frac{\\partial \\phi_j}{\\partial x_k}$ is independent of $x_j$, and $\\frac{\\partial \\phi_k}{\\partial x_j}$ is independent of $x_k$.\n\nThe result $\\frac{\\partial^2 f}{\\partial x_j^2}=0$ for all $j$, along with the equality of mixed partials, forces all second-order partial derivatives to be zero. Consider $\\frac{\\partial^2 f}{\\partial x_j \\partial x_k}$ for $j \\neq k$. Since $\\frac{\\partial f}{\\partial x_j}$ is independent of $x_j$, we can write $f(x) = x_j \\phi_j(x_{-j}) + \\psi_j(x_{-j})$. Then $\\frac{\\partial f}{\\partial x_k} = x_j \\frac{\\partial \\phi_j}{\\partial x_k} + \\frac{\\partial \\psi_j}{\\partial x_k}$. We also know $\\frac{\\partial f}{\\partial x_k} = \\phi_k(x_{-k})$ which is independent of $x_j$. For this to hold, the coefficient of $x_j$ must be zero, i.e., $\\frac{\\partial \\phi_j}{\\partial x_k}=0$. This means $\\phi_j$ is independent of $x_k$ for all $k \\ne j$. Thus, $\\phi_j$ must be a constant, say $w_j$.\n\nSo, we have established that $\\frac{\\partial f}{\\partial x_j} = w_j$ for all $j$, where each $w_j$ is a constant. This means the gradient of $f$ is a constant vector $w = (w_1, \\dots, w_d)^\\top$.\nIf $\\nabla f(x) = w$, we can integrate to find the form of $f(x)$. Integrating $\\frac{\\partial f}{\\partial x_1} = w_1$ gives $f(x) = w_1 x_1 + h_1(x_2, \\dots, x_d)$. Differentiating this with respect to $x_2$ gives $\\frac{\\partial f}{\\partial x_2} = \\frac{\\partial h_1}{\\partial x_2}$. Since we know $\\frac{\\partial f}{\\partial x_2} = w_2$, we have $\\frac{\\partial h_1}{\\partial x_2} = w_2$. Integrating this gives $h_1(x_2, \\dots, x_d) = w_2 x_2 + h_2(x_3, \\dots, x_d)$. Continuing this process inductively, we arrive at:\n$$\nf(x) = w_1 x_1 + w_2 x_2 + \\dots + w_d x_d + b\n$$\nwhere $b$ is a constant of integration. This can be written as $f(x) = w^\\top x + b$. This is the general form of an affine linear function. This is the necessary condition.\n\nTo show sufficiency, let's assume $f(x) = w^\\top x + b = \\sum_{k=1}^d w_k x_k + b$.\nThe occlusion attribution is:\n$A_{\\mathrm{occ},j}(x) = f(x) - f(x^{(j \\leftarrow 0)}) = \\left( \\sum_{k=1}^d w_k x_k + b \\right) - \\left( \\sum_{k \\ne j} w_k x_k + w_j \\cdot 0 + b \\right) = w_j x_j$.\nThe Gradient-times-Input attribution is:\n$A_{\\mathrm{gxi},j}(x) = x_j \\frac{\\partial f}{\\partial x_j}(x)$.\nThe partial derivative is $\\frac{\\partial f}{\\partial x_j} = \\frac{\\partial}{\\partial x_j} \\left( \\sum_{k=1}^d w_k x_k + b \\right) = w_j$.\nTherefore, $A_{\\mathrm{gxi},j}(x) = x_j \\cdot w_j$.\nSince both attributions equal $w_j x_j$, the equality holds.\n\nThus, the necessary and sufficient condition is that the function $f$ must be an affine linear function of its input $x$.\n\n### Part 2: Computation for a Specific Model\n\nWe are given the model $f(x) \\;=\\; w^{\\top}x \\;+\\; b \\;+\\; \\gamma\\, x_{1} x_{2} \\;+\\; \\delta\\, x_{2}^{2}$ with parameters $w = (1,-2,3)^\\top$, $b = 0$, $\\gamma = \\frac{1}{2}$, and $\\delta = -1$.\nThe specific function is:\n$$\nf(x_1, x_2, x_3) = (1 \\cdot x_1 - 2 \\cdot x_2 + 3 \\cdot x_3) + 0 + \\frac{1}{2} x_1 x_2 - 1 \\cdot x_2^2\n$$\n$$\nf(x_1, x_2, x_3) = x_1 - 2x_2 + 3x_3 + \\frac{1}{2} x_1 x_2 - x_2^2\n$$\nThis function is not affine linear due to the terms $\\frac{1}{2} x_1 x_2$ and $-x_2^2$. Therefore, based on Part 1, we do not expect the two attributions to be equal in general.\n\nThe input is $x = (2, -1, 4)$ and the feature is $j=2$. We need to compute $D = A_{\\mathrm{occ},2}(x) - A_{\\mathrm{gxi},2}(x)$.\n\nFirst, we compute the occlusion attribution $A_{\\mathrm{occ},2}(x) = f(x) - f(x^{(2 \\leftarrow 0)})$.\nThe original input is $x = (2, -1, 4)$.\nThe occluded input is $x^{(2 \\leftarrow 0)} = (2, 0, 4)$.\n\n$f(2, -1, 4) = (2) - 2(-1) + 3(4) + \\frac{1}{2}(2)(-1) - (-1)^2$\n$f(2, -1, 4) = 2 + 2 + 12 - 1 - 1 = 14$.\n\n$f(2, 0, 4) = (2) - 2(0) + 3(4) + \\frac{1}{2}(2)(0) - (0)^2$\n$f(2, 0, 4) = 2 - 0 + 12 + 0 - 0 = 14$.\n\n$A_{\\mathrm{occ},2}(x) = 14 - 14 = 0$.\n\nNext, we compute the Gradient-times-Input attribution $A_{\\mathrm{gxi},2}(x) = x_2 \\frac{\\partial f}{\\partial x_2}(x)$.\nFirst, we find the partial derivative of $f$ with respect to $x_2$:\n$$\n\\frac{\\partial f}{\\partial x_2} = \\frac{\\partial}{\\partial x_2} \\left( x_1 - 2x_2 + 3x_3 + \\frac{1}{2} x_1 x_2 - x_2^2 \\right) = -2 + \\frac{1}{2}x_1 - 2x_2\n$$\nNow, we evaluate this partial derivative at the input $x=(2,-1,4)$:\n$$\n\\frac{\\partial f}{\\partial x_2}(2, -1, 4) = -2 + \\frac{1}{2}(2) - 2(-1) = -2 + 1 + 2 = 1\n$$\nNow we can compute $A_{\\mathrm{gxi},2}(x)$:\n$$\nA_{\\mathrm{gxi},2}(x) = x_2 \\cdot \\frac{\\partial f}{\\partial x_2}(x) = (-1) \\cdot (1) = -1\n$$\nFinally, we compute the discrepancy $D$:\n$$\nD = A_{\\mathrm{occ},2}(x) - A_{\\mathrm{gxi},2}(x) = 0 - (-1) = 1\n$$",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Building on the insight that model structure affects attributions, we now compare two widely-used, sophisticated methods: SHapley Additive exPlanations (SHAP) and Integrated Gradients (IG). These methods are designed to handle complex models, but they do so based on different principles—SHAP from cooperative game theory and IG from path integration. This exercise uses a carefully constructed logical function with a known feature interaction to create a clear test case . By calculating and comparing the attributions from both methods, you will gain hands-on experience with how they distribute credit among interacting features and satisfy their respective \"completeness\" properties.",
            "id": "3153200",
            "problem": "You are given a binary classification dataset where features are independent and identically distributed Bernoulli random variables and the label is generated by a logical rule. Specifically, let $(X_1, X_2, X_3)$ be independent with $X_i \\sim \\mathrm{Bernoulli}(1/2)$ for $i \\in \\{1,2,3\\}$, and let the label be $Y = \\mathbb{1}[(X_1 \\land X_2) \\lor X_3]$. Consider the differentiable surrogate model $f:\\mathbb{R}^3 \\to \\mathbb{R}$ defined by $f(x_1,x_2,x_3) = x_1 x_2 + x_3 - x_1 x_2 x_3$, which coincides with the logical rule on $\\{0,1\\}^3$.\n \nYour goal is to compare attributions from SHapley Additive exPlanations (SHAP) and Integrated Gradients (IG) at the input $x^{\\star} = (1,1,1)$ using the following settings.\n \n- For SHAP, use the interventional value function $v(S) = \\mathbb{E}[f(X) \\mid X_S = x^{\\star}_S]$ under the independent background distribution of $(X_1,X_2,X_3)$, and define the Shapley value for feature $i$ by\n  $$\\phi_i = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!\\,(|N|-|S|-1)!}{|N|!}\\,\\big(v(S \\cup \\{i\\}) - v(S)\\big),$$\n  where $N = \\{1,2,3\\}$.\n- For IG, use the baseline $x' = (0,0,0)$ and the straight-line path from $x'$ to $x^{\\star}$, with the attribution for feature $i$ defined by\n  $$\\mathrm{IG}_i(x^{\\star}) = (x^{\\star}_i - x'_i) \\int_{0}^{1} \\frac{\\partial f(x' + \\alpha (x^{\\star} - x'))}{\\partial x_i} \\, d\\alpha.$$\n \nTasks:\n1. Starting from the definitions above, compute the Shapley values $\\phi_1$, $\\phi_2$, and $\\phi_3$ at $x^{\\star}$, and briefly explain how the terms reflect distribution of interaction credit between $X_1$ and $X_2$ and the dominance of $X_3$.\n2. Compute the Integrated Gradients attributions $\\mathrm{IG}_1(x^{\\star})$, $\\mathrm{IG}_2(x^{\\star})$, and $\\mathrm{IG}_3(x^{\\star})$ using the given baseline and path, and show that their sum equals $f(x^{\\star}) - f(x')$.\n3. Use your results to illustrate non-additivity across methods by showing that the sum of SHAP attributions equals $f(x^{\\star}) - \\mathbb{E}[f(X)]$ while the sum of IG attributions equals $f(x^{\\star}) - f(x')$. Then, compute the ratio\n   $$R \\equiv \\frac{\\mathrm{IG}_3(x^{\\star})}{\\phi_3}.$$\n \nProvide your final answer as a single reduced fraction. No rounding is required and no units are needed.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and complete. All necessary definitions, variables, and conditions are provided to compute the required quantities. The problem is a standard exercise in applying the definitions of SHAP and Integrated Gradients, two established methods in machine learning interpretability.\n\nThe solution proceeds by following the three tasks outlined in the problem.\n\nLet the feature vector be $x = (x_1, x_2, x_3)$. The surrogate model is given by $f(x_1, x_2, x_3) = x_1 x_2 + x_3 - x_1 x_2 x_3$. The features $X_i$ are independent Bernoulli random variables with parameter $p=1/2$, so $\\mathbb{E}[X_i] = 1/2$ for $i \\in \\{1,2,3\\}$. The input for attribution is $x^{\\star} = (1,1,1)$.\n\n### Task 1: Computation of SHAP values\n\nThe Shapley value for feature $i$ is given by\n$$\n\\phi_i = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!\\,(|N|-|S|-1)!}{|N|!}\\,\\big(v(S \\cup \\{i\\}) - v(S)\\big)\n$$\nwhere $N = \\{1,2,3\\}$ and the value function is $v(S) = \\mathbb{E}[f(X) \\mid X_S = x^{\\star}_S]$. Given $x^{\\star}=(1,1,1)$, this means we fix the components in $S$ to $1$ and take the expectation over the remaining components, which follow the background distribution $X_i \\sim \\mathrm{Bernoulli}(1/2)$.\n\nFirst, we compute the value function $v(S)$ for all $S \\subseteq N$:\n- $S=\\emptyset$: $v(\\emptyset) = \\mathbb{E}[f(X_1,X_2,X_3)] = \\mathbb{E}[X_1 X_2 + X_3 - X_1 X_2 X_3]$. By independence of $X_i$:\n  $v(\\emptyset) = \\mathbb{E}[X_1]\\mathbb{E}[X_2] + \\mathbb{E}[X_3] - \\mathbb{E}[X_1]\\mathbb{E}[X_2]\\mathbb{E}[X_3] = (\\frac{1}{2})(\\frac{1}{2}) + \\frac{1}{2} - (\\frac{1}{2})(\\frac{1}{2})(\\frac{1}{2}) = \\frac{1}{4} + \\frac{1}{2} - \\frac{1}{8} = \\frac{5}{8}$.\n- $S=\\{1\\}$: $v(\\{1\\}) = \\mathbb{E}[f(1,X_2,X_3)] = \\mathbb{E}[X_2 + X_3 - X_2 X_3] = \\mathbb{E}[X_2] + \\mathbb{E}[X_3] - \\mathbb{E}[X_2]\\mathbb{E}[X_3] = \\frac{1}{2} + \\frac{1}{2} - (\\frac{1}{2})(\\frac{1}{2}) = 1 - \\frac{1}{4} = \\frac{3}{4}$.\n- $S=\\{2\\}$: By symmetry with feature $1$, $v(\\{2\\}) = \\mathbb{E}[f(X_1,1,X_3)] = \\frac{3}{4}$.\n- $S=\\{3\\}$: $v(\\{3\\}) = \\mathbb{E}[f(X_1,X_2,1)] = \\mathbb{E}[X_1 X_2 + 1 - X_1 X_2] = \\mathbb{E}[1] = 1$.\n- $S=\\{1,2\\}$: $v(\\{1,2\\}) = \\mathbb{E}[f(1,1,X_3)] = \\mathbb{E}[1 + X_3 - X_3] = \\mathbb{E}[1] = 1$.\n- $S=\\{1,3\\}$: $v(\\{1,3\\}) = \\mathbb{E}[f(1,X_2,1)] = \\mathbb{E}[X_2 + 1 - X_2] = \\mathbb{E}[1] = 1$.\n- $S=\\{2,3\\}$: $v(\\{2,3\\}) = \\mathbb{E}[f(X_1,1,1)] = \\mathbb{E}[X_1 + 1 - X_1] = \\mathbb{E}[1] = 1$.\n- $S=\\{1,2,3\\}$: $v(\\{1,2,3\\}) = f(1,1,1) = 1 \\cdot 1 + 1 - 1 \\cdot 1 \\cdot 1 = 1$.\n\nNow we compute the Shapley values. For $|N|=3$, the weights are $\\frac{0!2!}{3!} = \\frac{2}{6} = \\frac{1}{3}$ for $|S|=0$, $\\frac{1!1!}{3!} = \\frac{1}{6}$ for $|S|=1$, and $\\frac{2!0!}{3!} = \\frac{1}{3}$ for $|S|=2$.\n\nFor $\\phi_3$:\n$$\n\\phi_3 = \\frac{1}{3}\\big(v(\\{3\\}) - v(\\emptyset)\\big) + \\frac{1}{6}\\big(v(\\{1,3\\}) - v(\\{1\\})\\big) + \\frac{1}{6}\\big(v(\\{2,3\\}) - v(\\{2\\})\\big) + \\frac{1}{3}\\big(v(\\{1,2,3\\}) - v(\\{1,2\\})\\big)\n$$\n$$\n\\phi_3 = \\frac{1}{3}\\left(1 - \\frac{5}{8}\\right) + \\frac{1}{6}\\left(1 - \\frac{3}{4}\\right) + \\frac{1}{6}\\left(1 - \\frac{3}{4}\\right) + \\frac{1}{3}\\left(1 - 1\\right)\n$$\n$$\n\\phi_3 = \\frac{1}{3}\\left(\\frac{3}{8}\\right) + \\frac{1}{6}\\left(\\frac{1}{4}\\right) + \\frac{1}{6}\\left(\\frac{1}{4}\\right) + 0 = \\frac{3}{24} + \\frac{1}{24} + \\frac{1}{24} = \\frac{5}{24}\n$$\n\nFor $\\phi_1$:\n$$\n\\phi_1 = \\frac{1}{3}\\big(v(\\{1\\}) - v(\\emptyset)\\big) + \\frac{1}{6}\\big(v(\\{1,2\\}) - v(\\{2\\})\\big) + \\frac{1}{6}\\big(v(\\{1,3\\}) - v(\\{3\\})\\big) + \\frac{1}{3}\\big(v(\\{1,2,3\\}) - v(\\{2,3\\})\\big)\n$$\n$$\n\\phi_1 = \\frac{1}{3}\\left(\\frac{3}{4} - \\frac{5}{8}\\right) + \\frac{1}{6}\\left(1 - \\frac{3}{4}\\right) + \\frac{1}{6}\\left(1 - 1\\right) + \\frac{1}{3}\\left(1 - 1\\right)\n$$\n$$\n\\phi_1 = \\frac{1}{3}\\left(\\frac{1}{8}\\right) + \\frac{1}{6}\\left(\\frac{1}{4}\\right) + 0 + 0 = \\frac{1}{24} + \\frac{1}{24} = \\frac{2}{24} = \\frac{1}{12}\n$$\nBy symmetry of the model $f$ with respect to $x_1$ and $x_2$, we have $\\phi_2 = \\phi_1 = 1/12$.\n\nThe attributions are $\\phi_1 = 1/12$, $\\phi_2 = 1/12$, and $\\phi_3 = 5/24$. Feature $X_3$ receives the highest attribution ($\\phi_3 = 10/48$) compared to $X_1$ and $X_2$ ($\\phi_1=\\phi_2=4/48$). This reflects its dominant role; setting $X_3=1$ guarantees an output of $1$, regardless of $X_1$ and $X_2$. Features $X_1$ and $X_2$ receive smaller, equal attributions, reflecting their symmetric and interactive nature—they must both be $1$ to affect the output, and only when $X_3=0$. SHAP fairly distributes the credit for the interaction between $X_1$ and $X_2$.\n\n### Task 2: Computation of Integrated Gradients (IG) attributions\n\nThe IG attribution for feature $i$ is defined as:\n$$\n\\mathrm{IG}_i(x^{\\star}) = (x^{\\star}_i - x'_i) \\int_{0}^{1} \\frac{\\partial f(x' + \\alpha (x^{\\star} - x'))}{\\partial x_i} \\, d\\alpha\n$$\nHere, $x^{\\star}=(1,1,1)$ and the baseline is $x'=(0,0,0)$. The path is $x(\\alpha) = x' + \\alpha(x^{\\star}-x') = (0,0,0) + \\alpha(1,1,1) = (\\alpha, \\alpha, \\alpha)$. Also, $x^{\\star}_i - x'_i = 1-0=1$ for all $i$.\nThe partial derivatives of $f(x_1,x_2,x_3) = x_1 x_2 + x_3 - x_1 x_2 x_3$ are:\n- $\\frac{\\partial f}{\\partial x_1} = x_2 - x_2 x_3 = x_2(1-x_3)$\n- $\\frac{\\partial f}{\\partial x_2} = x_1 - x_1 x_3 = x_1(1-x_3)$\n- $\\frac{\\partial f}{\\partial x_3} = 1 - x_1 x_2$\n\nWe evaluate these derivatives along the path $x(\\alpha)=(\\alpha,\\alpha,\\alpha)$:\n- $\\frac{\\partial f(x(\\alpha))}{\\partial x_1} = \\alpha(1-\\alpha) = \\alpha - \\alpha^2$\n- $\\frac{\\partial f(x(\\alpha))}{\\partial x_2} = \\alpha(1-\\alpha) = \\alpha - \\alpha^2$\n- $\\frac{\\partial f(x(\\alpha))}{\\partial x_3} = 1 - \\alpha \\cdot \\alpha = 1 - \\alpha^2$\n\nNow we compute the integrals:\n- $\\mathrm{IG}_1(x^{\\star}) = \\int_{0}^{1} (\\alpha - \\alpha^2) \\, d\\alpha = \\left[\\frac{\\alpha^2}{2} - \\frac{\\alpha^3}{3}\\right]_0^1 = \\frac{1}{2} - \\frac{1}{3} = \\frac{1}{6}$.\n- $\\mathrm{IG}_2(x^{\\star}) = \\int_{0}^{1} (\\alpha - \\alpha^2) \\, d\\alpha = \\frac{1}{6}$.\n- $\\mathrm{IG}_3(x^{\\star}) = \\int_{0}^{1} (1 - \\alpha^2) \\, d\\alpha = \\left[\\alpha - \\frac{\\alpha^3}{3}\\right]_0^1 = 1 - \\frac{1}{3} = \\frac{2}{3}$.\n\nThe sum of IG attributions is:\n$$\n\\sum_{i=1}^3 \\mathrm{IG}_i(x^{\\star}) = \\frac{1}{6} + \\frac{1}{6} + \\frac{2}{3} = \\frac{2}{6} + \\frac{4}{6} = \\frac{6}{6} = 1\n$$\nWe must verify this equals $f(x^{\\star}) - f(x')$.\n- $f(x^{\\star}) = f(1,1,1) = 1(1) + 1 - 1(1)(1) = 1$.\n- $f(x') = f(0,0,0) = 0(0) + 0 - 0(0)(0) = 0$.\nSo, $f(x^{\\star}) - f(x') = 1 - 0 = 1$. The sum is correct, confirming the completeness property for IG.\n\n### Task 3: Comparison and Ratio Calculation\n\nWe compare the sums of attributions for the two methods.\nFor SHAP, the sum of attributions is:\n$$\n\\sum_{i=1}^3 \\phi_i = \\phi_1 + \\phi_2 + \\phi_3 = \\frac{1}{12} + \\frac{1}{12} + \\frac{5}{24} = \\frac{2}{24} + \\frac{2}{24} + \\frac{5}{24} = \\frac{9}{24} = \\frac{3}{8}\n$$\nThis sum equals $f(x^{\\star}) - \\mathbb{E}[f(X)]$, as required by the efficiency property of Shapley values:\n$f(x^{\\star}) - \\mathbb{E}[f(X)] = 1 - v(\\emptyset) = 1 - \\frac{5}{8} = \\frac{3}{8}$.\n\nFor IG, the sum of attributions is $\\sum_{i=1}^3 \\mathrm{IG}_i(x^{\\star}) = 1$, which equals $f(x^{\\star}) - f(x') = 1-0=1$.\n\nThe sums are different ($\\frac{3}{8} \\ne 1$), illustrating that the total attribution score depends on the method and its choice of baseline (expected value for SHAP, a specific point $x'$ for IG). This is a known difference between the two methods, often described as non-additivity across methods.\n\nFinally, we compute the ratio $R$:\n$$\nR = \\frac{\\mathrm{IG}_3(x^{\\star})}{\\phi_3} = \\frac{2/3}{5/24} = \\frac{2}{3} \\cdot \\frac{24}{5} = \\frac{2 \\cdot 8}{5} = \\frac{16}{5}\n$$\nThe ratio is not $1$, which highlights that even for a single feature, the attribution scores from different methods can differ significantly, not just in their sum but in their individual values.",
            "answer": "$$\\boxed{\\frac{16}{5}}$$"
        },
        {
            "introduction": "An explanation is only useful if it is \"faithful\"—that is, if it accurately reflects the model's true reasoning process. However, a model might learn to use spurious correlations or \"shortcuts\" in the data, and a simple gradient-based saliency map may fail to reveal this behavior, especially in the presence of function saturation. This hands-on coding challenge guides you through constructing a scenario where two models achieve identical accuracy, but one relies on a shortcut . You will then implement and apply deletion and insertion curves, powerful techniques for evaluating the faithfulness of an explanation by measuring how the model's prediction changes as you iteratively remove or add features according to their attributed importance.",
            "id": "3153222",
            "problem": "You must write a complete, runnable program that constructs two differentiable binary classifiers over images and can evaluate the faithfulness of their gradient-based saliency using deletion and insertion curves. The program must rely only on well-defined mathematical operations and definitions. No user input is required, and all computations must be deterministic.\n\nThe fundamental basis for the derivation must use: the definition of gradient-based saliency as the input gradient $\\nabla_{x} f(x)$, the chain rule for derivatives, and standard derivatives of the logistic sigmoid and the hyperbolic tangent. The logistic sigmoid is $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ with derivative $\\sigma'(z) = \\sigma(z)\\,(1-\\sigma(z))$. The hyperbolic tangent is $\\tanh(u) = \\frac{e^{u} - e^{-u}}{e^{u} + e^{-u}}$ with derivative $\\frac{d}{du}\\tanh(u) = \\operatorname{sech}^{2}(u)$, where $\\operatorname{sech}(u) = \\frac{1}{\\cosh(u)}$.\n\nTask specification:\n\n- Input representation:\n  - Consider grayscale images $x \\in \\mathbb{R}^{H \\times W}$ with $H = W = 16$.\n  - Define a signal region $S = \\{(i,j) : 0 \\le i < 4,\\ 0 \\le j < 4\\}$ and a shortcut region $C = \\{(i,j) : 0 \\le i < 4,\\ 12 \\le j < 16\\}$. Let $|S| = |C| = 16$.\n  - For an image $x$, define $\\mathrm{mean}_{S}(x)$ as the arithmetic mean of pixels in $S$, and $\\mathrm{mean}_{C}(x)$ as the arithmetic mean of pixels in $C$.\n\n- Models:\n  - Model $\\mathrm{A}$ (linear-logistic):\n    - Logit: $z_{\\mathrm{A}}(x) = a_{S}\\,\\mathrm{mean}_{S}(x) + a_{C}\\,\\mathrm{mean}_{C}(x)$ with $a_{S} = 4.0$ and $a_{C} = 0.2$.\n    - Probability: $f_{\\mathrm{A}}(x) = \\sigma(z_{\\mathrm{A}}(x))$.\n  - Model $\\mathrm{B}$ (saturated-shortcut):\n    - Logit: $z_{\\mathrm{B}}(x) = b_{S}\\,\\mathrm{mean}_{S}(x) + b_{C}\\,\\tanh(\\alpha\\,\\mathrm{mean}_{C}(x))$ with $b_{S} = 1.5$, $b_{C} = 3.0$, and $\\alpha = 5.0$.\n    - Probability: $f_{\\mathrm{B}}(x) = \\sigma(z_{\\mathrm{B}}(x))$.\n\n- Saliency definition:\n  - For each model, the saliency map is the absolute gradient magnitude $s(x) = |\\nabla_{x} f(x)|$ computed via the chain rule under the above definitions.\n\n- Deletion and insertion curves:\n  - Let $N = H \\cdot W$ be the number of pixels.\n  - For a fixed attribution $s(x)$, define an ordering $\\pi$ of pixels by sorting indices in descending order of saliency scores.\n  - Deletion curve: starting at the original $x^{(0)} = x$, for step $t \\in \\{0,1,\\dots,T\\}$ with $T = 20$, form $x^{(t)}$ by setting to zero the top $k_{t} = \\left\\lfloor \\frac{t}{T} \\cdot N \\right\\rfloor$ pixels according to $\\pi$ while leaving other pixels as in $x$. Record $y^{(t)} = f(x^{(t)})$ where $f$ is the model’s probability. The deletion Area Under the Curve (AUC) is the trapezoidal integral of $y^{(t)}$ versus the fraction $\\frac{t}{T}$, normalized to $[0,1]$ by the unit interval on the horizontal axis and probability range $[0,1]$ on the vertical axis.\n  - Insertion curve: starting at the zero image $\\tilde{x}^{(0)} = 0$, for step $t \\in \\{0,1,\\dots,T\\}$, form $\\tilde{x}^{(t)}$ by setting the top $k_{t}$ pixels according to $\\pi$ to the original values from $x$ and leaving the rest zero. Record $\\tilde{y}^{(t)} = f(\\tilde{x}^{(t)})$. The insertion AUC is defined analogously via the trapezoidal rule.\n\n- Faithfulness score and decision rule:\n  - For each model on each test image, define a faithfulness score $F = \\mathrm{AUC}_{\\mathrm{ins}} - \\mathrm{AUC}_{\\mathrm{del}}$.\n  - For each test case, decide which model’s saliency is more faithful by comparing scores: the larger $F$ indicates greater faithfulness.\n\nDataset construction:\n\n- Use three deterministic test images parameterized by $\\mu_{S} \\in \\{2.0, 0.8, 0.2\\}$ and a fixed correlation factor $\\rho = 0.8$.\n- For each test image:\n  - Set all pixels in $S$ to $\\mu_{S}$.\n  - Set all pixels in $C$ to $\\mu_{C} = \\rho \\cdot \\mu_{S}$.\n  - Set all other pixels to $0$.\n  - The intended ground-truth label is $y=1$, but the program must solely evaluate the models’ probabilities and derived saliency metrics.\n- Note: With the above parameters, both models achieve identical accuracy on these cases (each predicts class $1$), yet they rely on different mechanisms: Model $\\mathrm{A}$ emphasizes the signal region $S$ while Model $\\mathrm{B}$ relies on a saturated shortcut through $C$. Gradients $\\nabla_{x} f_{\\mathrm{A}}(x)$ and $\\nabla_{x} f_{\\mathrm{B}}(x)$ can appear similar due to saturation suppressing gradients in $C$ for Model $\\mathrm{B}$.\n\nProgram requirements:\n\n- Implement both models and their gradients exactly as specified.\n- For each test image, compute the faithfulness scores for Model $\\mathrm{A}$ and Model $\\mathrm{B}$ using their own saliency rankings, then output which model is more faithful.\n- Final output format: Your program should produce a single line of output containing the decisions for the three test cases as a comma-separated list of integers enclosed in square brackets, where $0$ denotes Model $\\mathrm{A}$ is more faithful and $1$ denotes Model $\\mathrm{B}$ is more faithful. For example, an output like $[0,1,0]$ is acceptable.\n\nTest suite:\n\n- The three test cases are the three values of $\\mu_{S}$ in the set $\\{2.0, 0.8, 0.2\\}$ with fixed $\\rho = 0.8$.\n- The expected outputs are integers, one per test case, determined by the algorithm described above.\n- Coverage:\n  - A strong-signal case $\\mu_{S} = 2.0$.\n  - A moderate-signal case $\\mu_{S} = 0.8$.\n  - A near-boundary case $\\mu_{S} = 0.2$.\n\nYour program must follow the exact output format: a single line with a list of three integers like $[r_{1},r_{2},r_{3}]$ and no extra text. All numeric constants described above must be used exactly as specified.",
            "solution": "We start from core definitions in differentiable models, gradients, and attribution faithfulness.\n\nDefinitions and derivatives. The logistic sigmoid is $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ with derivative $\\sigma'(z) = \\sigma(z)\\,(1-\\sigma(z))$. The hyperbolic tangent is $\\tanh(u) = \\frac{e^{u}-e^{-u}}{e^{u}+e^{-u}}$ with derivative $\\frac{d}{du}\\tanh(u) = \\operatorname{sech}^{2}(u)$, where $\\operatorname{sech}(u) = \\frac{1}{\\cosh(u)}$. The chain rule will be used to combine these derivatives for composite functions.\n\nImage geometry and means. Let $H=W=16$, and let $S$ and $C$ be disjoint $4\\times 4$ regions, each with cardinality $|S|=|C|=16$. For an image $x \\in \\mathbb{R}^{H \\times W}$, define the means $\\mathrm{mean}_{S}(x) = \\frac{1}{|S|} \\sum_{(i,j)\\in S} x_{ij}$ and $\\mathrm{mean}_{C}(x) = \\frac{1}{|C|} \\sum_{(i,j)\\in C} x_{ij}$.\n\nModels. We define two models with probabilities $f_{\\mathrm{A}}(x) = \\sigma(z_{\\mathrm{A}}(x))$ and $f_{\\mathrm{B}}(x) = \\sigma(z_{\\mathrm{B}}(x))$ where\n- $z_{\\mathrm{A}}(x) = a_{S}\\,\\mathrm{mean}_{S}(x) + a_{C}\\,\\mathrm{mean}_{C}(x)$ with $a_{S}=4.0$ and $a_{C}=0.2$,\n- $z_{\\mathrm{B}}(x) = b_{S}\\,\\mathrm{mean}_{S}(x) + b_{C}\\,\\tanh(\\alpha\\,\\mathrm{mean}_{C}(x))$ with $b_{S}=1.5$, $b_{C}=3.0$, and $\\alpha=5.0$.\n\nGradients as saliency. The saliency map is $s(x) = |\\nabla_{x} f(x)|$. Using the chain rule,\n$\\nabla_{x} f(x) = \\sigma'(z(x)) \\cdot \\nabla_{x} z(x)$.\n\nFor Model $\\mathrm{A}$, $z_{\\mathrm{A}}(x)$ is linear in the means. The gradient of $\\mathrm{mean}_{S}(x)$ with respect to any pixel in $S$ is $\\frac{1}{|S|}$ and zero outside $S$. Similarly for $C$. Therefore,\n- For $(i,j)\\in S$: $\\frac{\\partial z_{\\mathrm{A}}}{\\partial x_{ij}} = \\frac{a_{S}}{|S|}$,\n- For $(i,j)\\in C$: $\\frac{\\partial z_{\\mathrm{A}}}{\\partial x_{ij}} = \\frac{a_{C}}{|C|}$,\n- Elsewhere: $\\frac{\\partial z_{\\mathrm{A}}}{\\partial x_{ij}} = 0$.\nThus the gradient is\n$\\frac{\\partial f_{\\mathrm{A}}}{\\partial x_{ij}} = \\sigma'(z_{\\mathrm{A}}(x)) \\cdot \\frac{\\partial z_{\\mathrm{A}}}{\\partial x_{ij}}$,\nwith the above piecewise constants per region.\n\nFor Model $\\mathrm{B}$, we again apply the chain rule, but the shortcut path uses $\\tanh(\\cdot)$. Let $m_{C}(x) = \\mathrm{mean}_{C}(x)$. Then\n$\\frac{\\partial z_{\\mathrm{B}}}{\\partial x_{ij}} =\n\\begin{cases}\n\\frac{b_{S}}{|S|}, & (i,j)\\in S,\\\\\nb_{C}\\cdot \\frac{d}{du}\\tanh(\\alpha u)\\big|_{u=m_{C}(x)} \\cdot \\frac{\\partial m_{C}}{\\partial x_{ij}}, & (i,j)\\in C,\\\\\n0, & \\text{otherwise}.\n\\end{cases}$\nWe have $\\frac{d}{du}\\tanh(\\alpha u) = \\alpha\\,\\operatorname{sech}^{2}(\\alpha u)$ and $\\frac{\\partial m_{C}}{\\partial x_{ij}} = \\frac{1}{|C|}$ for $(i,j)\\in C$. Therefore,\n- For $(i,j)\\in S$: $\\frac{\\partial z_{\\mathrm{B}}}{\\partial x_{ij}} = \\frac{b_{S}}{|S|}$,\n- For $(i,j)\\in C$: $\\frac{\\partial z_{\\mathrm{B}}}{\\partial x_{ij}} = \\frac{b_{C}\\,\\alpha}{|C|}\\,\\operatorname{sech}^{2}(\\alpha\\,m_{C}(x))$,\n- Elsewhere: $0$.\nHence $\\frac{\\partial f_{\\mathrm{B}}}{\\partial x_{ij}} = \\sigma'(z_{\\mathrm{B}}(x)) \\cdot \\frac{\\partial z_{\\mathrm{B}}}{\\partial x_{ij}}$.\n\nInterpretation. For positive inputs where $m_{C}(x) > 0$ and $\\alpha$ is large, $\\operatorname{sech}^{2}(\\alpha\\,m_{C}(x))$ becomes very small, saturating the shortcut path in Model $\\mathrm{B}$. This leads to small gradients in region $C$ despite a large logit contribution from $C$. Therefore, $\\nabla_{x} f_{\\mathrm{B}}(x)$ appears similar to $\\nabla_{x} f_{\\mathrm{A}}(x)$ by emphasizing region $S$; however, the underlying causal reliance differs: Model $\\mathrm{B}$ relies on $C$ through a saturated nonlinearity, whereas Model $\\mathrm{A}$ relies primarily on $S$ due to $a_{S} \\gg a_{C}$.\n\nDeletion and insertion curves. To quantify faithfulness, we evaluate how fast the model output $f(x)$ changes when perturbing features in the order suggested by the saliency map $s(x)$. For deletion, we progressively set top-salient pixels to zero and integrate the probability curve over $\\frac{t}{T}$ for $t=0,\\dots,T$ with $T=20$ via the trapezoidal rule. A smaller deletion Area Under the Curve (AUC) indicates that removing top-ranked features quickly reduces the model’s confidence, aligning with faithful attribution. For insertion, we start from the zero image and progressively insert top-salient pixels; a larger insertion AUC indicates faster recovery of the model’s confidence when adding important features. A combined faithfulness score $F = \\mathrm{AUC}_{\\mathrm{ins}} - \\mathrm{AUC}_{\\mathrm{del}}$ summarizes both effects; larger $F$ means more faithful saliency.\n\nDataset construction and identical accuracy. We construct three deterministic test images with $\\mu_{S} \\in \\{2.0, 0.8, 0.2\\}$ and $\\mu_{C} = \\rho\\,\\mu_{S}$ with $\\rho=0.8$. All pixels in $S$ are set to $\\mu_{S}$, all pixels in $C$ to $\\mu_{C}$, and the rest to $0$. For these images, both models predict probabilities above $0.5$ (class $1$), hence identical accuracy on this test suite, yet their reliance differs: Model $\\mathrm{A}$ is driven by $S$ while Model $\\mathrm{B}$ is driven by a saturated function of $C$.\n\nExpected diagnostic outcome. Because Model $\\mathrm{B}$’s gradient underestimates the shortcut contribution in $C$ (due to saturation), its gradient-based saliency will rank pixels in $S$ too highly relative to their true causal influence on the model’s output. Thus, deletion along the gradient ranking will not reduce $f_{\\mathrm{B}}(x)$ as quickly, and insertion will not recover it as effectively, yielding a smaller $F$. Model $\\mathrm{A}$, whose gradient aligns with its reliance on $S$, will exhibit a lower deletion AUC and higher insertion AUC, giving a larger $F$. Therefore, for each test case, we expect the decision to favor Model $\\mathrm{A}$ as more faithful, encoded as the integer $0$.\n\nAlgorithmic steps implemented by the program:\n- Construct the three images from $\\mu_{S} \\in \\{2.0, 0.8, 0.2\\}$ and $\\rho=0.8$.\n- Implement $f_{\\mathrm{A}}$, $f_{\\mathrm{B}}$ and their gradients via the chain rule.\n- For each image and model:\n  - Compute saliency $s(x) = |\\nabla_{x} f(x)|$.\n  - Build deletion and insertion curves over $T=20$ steps using the saliency ranking and baseline zero.\n  - Compute $\\mathrm{AUC}_{\\mathrm{del}}$ and $\\mathrm{AUC}_{\\mathrm{ins}}$ with the trapezoidal rule on $\\frac{t}{T}$.\n  - Compute $F = \\mathrm{AUC}_{\\mathrm{ins}} - \\mathrm{AUC}_{\\mathrm{del}}$.\n- Per test case, output $0$ if $F_{\\mathrm{A}} \\ge F_{\\mathrm{B}}$ and $1$ otherwise.\n- The final line must be a single list $[r_{1},r_{2},r_{3}]$.\n\nThis procedure operationalizes model interpretability and explainability: gradient similarity alone can be misleading due to saturation, while deletion/insertion curves provide a principled, effect-based diagnostic of saliency faithfulness.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Sigmoid and its derivative\ndef sigmoid(z: np.ndarray) -> np.ndarray:\n    return 1.0 / (1.0 + np.exp(-z))\n\ndef dsigmoid(z: np.ndarray) -> np.ndarray:\n    s = sigmoid(z)\n    return s * (1.0 - s)\n\n# Tanh and sech^2 utilities\ndef tanh(u: np.ndarray) -> np.ndarray:\n    return np.tanh(u)\n\ndef sech2(u: np.ndarray) -> np.ndarray:\n    # sech(u) = 1/cosh(u); sech^2(u) = 1 / cosh(u)^2\n    return 1.0 / (np.cosh(u) ** 2)\n\n# Image geometry and regions\nH, W = 16, 16\n# Define S: rows 0..3, cols 0..3\nS_rows = slice(0, 4)\nS_cols = slice(0, 4)\n# Define C: rows 0..3, cols 12..15\nC_rows = slice(0, 4)\nC_cols = slice(12, 16)\nS_size = (S_rows.stop - S_rows.start) * (S_cols.stop - S_cols.start)\nC_size = (C_rows.stop - C_rows.start) * (C_cols.stop - C_cols.start)\n\n# Model parameters\na_S, a_C = 4.0, 0.2\nb_S, b_C, alpha = 1.5, 3.0, 5.0\n\ndef mean_region(img: np.ndarray, rows: slice, cols: slice) -> float:\n    region = img[rows, cols]\n    return float(np.mean(region))\n\ndef modelA_logit(img: np.ndarray) -> float:\n    mS = mean_region(img, S_rows, S_cols)\n    mC = mean_region(img, C_rows, C_cols)\n    return a_S * mS + a_C * mC\n\ndef modelA_prob(img: np.ndarray) -> float:\n    return float(sigmoid(modelA_logit(img)))\n\ndef modelA_grad(img: np.ndarray) -> np.ndarray:\n    # Gradient of f_A wrt pixels: dsigmoid(z_A) * dz_A/dx\n    zA = modelA_logit(img)\n    g = dsigmoid(zA)\n    grad = np.zeros_like(img, dtype=float)\n    grad[S_rows, S_cols] = g * (a_S / S_size)\n    grad[C_rows, C_cols] = g * (a_C / C_size)\n    return grad\n\ndef modelB_logit(img: np.ndarray) -> float:\n    mS = mean_region(img, S_rows, S_cols)\n    mC = mean_region(img, C_rows, C_cols)\n    return b_S * mS + b_C * tanh(alpha * mC)\n\ndef modelB_prob(img: np.ndarray) -> float:\n    return float(sigmoid(modelB_logit(img)))\n\ndef modelB_grad(img: np.ndarray) -> np.ndarray:\n    # Gradient of f_B wrt pixels: dsigmoid(z_B) * dz_B/dx\n    mC = mean_region(img, C_rows, C_cols)\n    zB = modelB_logit(img)\n    g = dsigmoid(zB)\n    grad = np.zeros_like(img, dtype=float)\n    # S contribution\n    grad[S_rows, S_cols] = g * (b_S / S_size)\n    # C contribution with tanh chain rule: b_C * alpha * sech^2(alpha * mC) / |C|\n    grad[C_rows, C_cols] = g * (b_C * alpha * float(sech2(alpha * mC)) / C_size)\n    return grad\n\ndef deletion_insertion_auc(img: np.ndarray, prob_fn, grad_fn, T: int = 20) -> tuple[float, float]:\n    # Compute saliency from gradient magnitude\n    grad = grad_fn(img)\n    sal = np.abs(grad).reshape(-1)  # flatten\n    order = np.argsort(-sal)  # descending saliency\n\n    N = img.size\n    # Deletion: start from original, progressively zero-out top-k pixels\n    del_probs = []\n    del_img = img.copy().reshape(-1)\n    for t in range(T + 1):\n        # Record\n        del_probs.append(prob_fn(del_img.reshape(img.shape)))\n        # Next step: zero next batch\n        if t < T:\n            k_next = int(np.floor((t + 1) * N / T))\n            k_curr = int(np.floor(t * N / T))\n            idx = order[k_curr:k_next]\n            del_img[idx] = 0.0\n    del_probs = np.array(del_probs, dtype=float)\n    del_auc = auc_trapezoid(del_probs)\n\n    # Insertion: start from zeros, progressively insert top-k original pixels\n    ins_probs = []\n    ins_img = np.zeros_like(img).reshape(-1)\n    x_flat = img.reshape(-1)\n    for t in range(T + 1):\n        ins_probs.append(prob_fn(ins_img.reshape(img.shape)))\n        if t < T:\n            k_next = int(np.floor((t + 1) * N / T))\n            k_curr = int(np.floor(t * N / T))\n            idx = order[k_curr:k_next]\n            ins_img[idx] = x_flat[idx]\n    ins_probs = np.array(ins_probs, dtype=float)\n    ins_auc = auc_trapezoid(ins_probs)\n\n    return del_auc, ins_auc\n\ndef build_image(mu_S: float, rho: float = 0.8) -> np.ndarray:\n    mu_C = rho * mu_S\n    img = np.zeros((H, W), dtype=float)\n    img[S_rows, S_cols] = mu_S\n    img[C_rows, C_cols] = mu_C\n    return img\n\ndef solve():\n    # Define the test cases from the problem statement: mu_S values\n    mu_S_values = [2.0, 0.8, 0.2]\n    rho = 0.8\n\n    results = []\n    for mu_S in mu_S_values:\n        img = build_image(mu_S, rho=rho)\n\n        # Compute AUCs for model A\n        delA, insA = deletion_insertion_auc(img, modelA_prob, modelA_grad, T=20)\n        scoreA = insA - delA\n\n        # Compute AUCs for model B\n        delB, insB = deletion_insertion_auc(img, modelB_prob, modelB_grad, T=20)\n        scoreB = insB - delB\n\n        # Decide which model is more faithful: 0 for A if scoreA >= scoreB, else 1 for B\n        result = 0 if scoreA >= scoreB else 1\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}