{
    "hands_on_practices": [
        {
            "introduction": "要掌握任何深度学习层，理解其对张量维度的影响是第一步。本练习将挑战你从转置卷积与标准卷积的基本关系出发，推导出其输出尺寸的精确公式，为在网络架构中使用它打下坚实的数学基础。",
            "id": "3196147",
            "problem": "考虑一个用于卷积神经网络（CNN）中上采样的一维转置卷积（也称为分数步长卷积）。设该转置卷积的输入长度为 $n$，使用大小为 $k$ 的卷积核、步长为 $s$、填充为 $p$、输出填充为 $op$。步长 $s$ 决定了卷积核作用位置的间隔，填充 $p$ 表示在前向传播中概念上添加到信号两端的零元素的数量，而输出填充 $op$ 是一个满足 $0 \\leq op  s$ 的整数，它通过将输出长度增加 $op$ 来从上采样输出的 $s$ 种可能的空间对齐方式中选择一种。\n\n作为一个基本依据，使用标准（前向）一维卷积的输出长度 $m$ 的成熟公式，其输入长度为 $L$，卷积核大小为 $k$，步长为 $s$，填充为 $p$：\n$$\nm \\;=\\; \\left\\lfloor \\frac{L + 2p - k}{s} \\right\\rfloor + 1,\n$$\n以及转置卷积实现的是与该前向卷积相对应的线性算子的转置这一事实。\n\n请基于这些原理，不借助任何预先记下的目标公式，推导出一个用 $n$、$k$、$s$、$p$ 和 $op$ 表示的转置卷积精确输出长度的闭式表达式。在推导过程中，请说明在什么条件下可以消去前向公式中的向下取整运算，从而得到一个精确的等式，并解释 $op$ 在确定最终长度中的作用。\n\n最后，对于 $n=7$、$k=3$、$s=2$、$p=1$ 和 $op=1$ 的情况，对推导出的表达式进行数值计算。无需四舍五入；报告精确的整数输出长度。最终答案必须是单个数字。",
            "solution": "该问题要求从第一性原理出发，推导一维转置卷积的输出长度。出发点是标准前向卷积的输出长度公式，以及转置卷积对应于前向卷积线性算子的转置这一事实。\n\n设标准前向卷积是一个由矩阵 $C$ 表示的线性算子。该算子将一个长度为 $L$ 的输入向量映射到一个长度为 $m$ 的输出向量。题目给出了 $m$ 的计算公式如下：\n$$m = \\left\\lfloor \\frac{L + 2p - k}{s} \\right\\rfloor + 1$$\n其中 $k$ 是卷积核大小，$s$ 是步长，$p$ 是填充。\n\n转置卷积执行的是转置操作，我们可以用 $C^T$ 表示。该算子将一个大小为 $m$ 的输入映射到一个大小为 $L$ 的输出。题目规定，对于我们的转置卷积，其输入长度为 $n$。这意味着我们必须将 $n$ 与前向卷积的输出大小关联起来，即 $m=n$。我们的目标是求出转置卷积的输出长度，记为 $L_{out}$。这个长度对应于前向卷积的输入大小 $L$。\n\n通过将 $m=n$ 和 $L=L_{out}$ 代入前向卷积公式，我们建立了支配维度的基本关系：\n$$n = \\left\\lfloor \\frac{L_{out} + 2p - k}{s} \\right\\rfloor + 1$$\n\n我们的任务是解这个关于 $L_{out}$ 的方程。首先，我们分离出向下取整函数：\n$$n - 1 = \\left\\lfloor \\frac{L_{out} + 2p - k}{s} \\right\\rfloor$$\n向下取整函数的定义是，对于任意实数 $x$ 和整数 $z$，等式 $z = \\lfloor x \\rfloor$ 等价于不等式 $z \\leq x  z + 1$。应用这个性质，我们得到：\n$$n - 1 \\leq \\frac{L_{out} + 2p - k}{s}  (n - 1) + 1$$\n$$n - 1 \\leq \\frac{L_{out} + 2p - k}{s}  n$$\n由于步长 $s$ 是一个正整数，我们可以用 $s$ 乘以整个不等式，且不等号的方向不变：\n$$s(n - 1) \\leq L_{out} + 2p - k  sn$$\n最后，我们通过在不等式的所有部分加上 $(k - 2p)$ 来分离出 $L_{out}$：\n$$s(n - 1) + k - 2p \\leq L_{out}  sn + k - 2p$$\n这个不等式表明 $L_{out}$ 没有唯一的解。相反，$L_{out}$ 可以取一系列可能的整数值。这种模糊性的产生是因为前向卷积是一个多对一的映射；由于步长和向下取整函数的性质，多个输入长度 $L$ 可以产生相同的输出长度 $m$。此范围内 $L_{out}$ 的可能整数值的数量为 $(sn + k - 2p) - (s(n - 1) + k - 2p) = s$。\n\n题目引入了输出填充 $op$，它是一个满足 $0 \\leq op  s$ 的整数。它的作用是通过从 $s$ 个可能的选项中选择一个特定的输出长度来解决这种模糊性。题目指出 $op$ 会增加输出长度。一个标准的惯例是定义一个基础输出长度（可能的最小值），并将 $op$ 作为偏移量加上。从我们推导的不等式中，$L_{out}$ 的最小可能整数值为：\n$$L_{min} = s(n - 1) + k - 2p$$\n最终的输出长度 $L_{out}$ 是通过将输出填充 $op$ 加到这个最小长度上确定的：\n$$L_{out} = L_{min} + op = s(n - 1) + k - 2p + op$$\n对于任何有效的参数集 $n, k, s, p$ 和 $op$，该公式为转置卷积提供了一个确定的输出长度。\n\n题目还问到在什么条件下可以消除前向公式中的向下取整操作。表达式 $m = \\lfloor \\frac{L + 2p - k}{s} \\rfloor + 1$ 能够简化为一个不含向下取整函数的精确等式，当且仅当其参数是一个整数。这个条件是：\n$$\\frac{L + 2p - k}{s} \\in \\mathbb{Z}$$\n这等价于说 $(L + 2p - k)$ 可以被步长 $s$ 整除，用数学方式表示为：\n$$(L + 2p - k) \\pmod s = 0$$\n当这个条件成立时，$L$ 和 $m$ 之间的关系变成一对一。我们可以直接解出 $L$：\n$$m = \\frac{L + 2p - k}{s} + 1 \\implies s(m-1) = L + 2p - k \\implies L = s(m-1) + k - 2p$$\n将此与我们为 $L_{out}$ 推导的公式（其中 $L=L_{out}$，$m=n$）进行比较，我们看到这对应于输出填充 $op=0$ 的情况。因此，$op$ 的作用是处理前向传播中输入和输出大小之间的关系不是一对一的一般情况，允许用户为转置操作选择 $s$ 个可能的输出大小之一。\n\n最后，我们对给定数值情况计算推导出的表达式：$n=7$，$k=3$，$s=2$，$p=1$ 和 $op=1$。\n将这些值代入 $L_{out}$ 的公式中：\n$$L_{out} = s(n - 1) + k - 2p + op$$\n$$L_{out} = 2(7 - 1) + 3 - 2(1) + 1$$\n$$L_{out} = 2(6) + 3 - 2 + 1$$\n$$L_{out} = 12 + 3 - 2 + 1$$\n$$L_{out} = 15 - 2 + 1$$\n$$L_{out} = 13 + 1$$\n$$L_{out} = 14$$\n得到的输出长度是 $14$。",
            "answer": "$$\\boxed{14}$$"
        },
        {
            "introduction": "在实际的模型设计中，选择合适的工具需要权衡各种利弊。本练习将对转置卷积与其他流行的上采样技术进行定量比较，分析它们的计算复杂度、参数数量和内存占用，这对于构建高效且可扩展的模型至关重要。",
            "id": "3196153",
            "problem": "考虑一个二维深度神经网络层中的三种上采样策略，该层将一个空间尺寸为 $H_{\\text{in}} \\times W_{\\text{in}}$、通道数为 $C_{\\text{in}}$ 的输入张量映射到一个空间尺寸为 $H_{\\text{out}} \\times W_{\\text{out}}$、通道数为 $C_{\\text{out}}$ 的输出张量，其中步幅 $s$ 满足 $H_{\\text{out}} = s H_{\\text{in}}$ 和 $W_{\\text{out}} = s W_{\\text{in}}$。这三种策略是：(i) 转置卷积，其核心尺寸为 $k \\times k$，步幅为 $s$，参数张量的形状为 $C_{\\text{out}} \\times C_{\\text{in}} \\times k \\times k$；(ii) 像素重排（也称为子像素卷积），它首先在低分辨率尺度上应用标准卷积以产生 $C_{\\text{out}} s^{2}$ 个通道，然后通过像素重排重新排列成高分辨率输出；(iii) 最近邻上采样（因子为 $s$），然后是在高分辨率尺度上应用一个核心尺寸为 $k \\times k$ 的标准卷积，将 $C_{\\text{in}}$ 映射到 $C_{\\text{out}}$。\n\n从离散卷积的定义（即跨输入通道和空间偏移的加权邻域乘积之和）出发，并使用一个乘加运算计为 $2$ 次浮点运算（FLOPs）的约定，其中浮点运算次数（FLOPs）是执行的浮点乘法和加法总数，推导出每种策略的总前向传播 FLOPs 和参数数量的符号表达式，这些表达式应为 $H_{\\text{out}}$、$W_{\\text{out}}$、$C_{\\text{in}}$、$C_{\\text{out}}$、$k$ 和 $s$ 的函数。此外，将峰值中间激活元素数量（不包括给定的输入和最终输出张量）定义为该策略特有的任何中间张量中物化的最大元素数量，并为每种策略推导出这些数量的表达式。\n\n然后，对 $C_{\\text{in}} = 64$，$C_{\\text{out}} = 64$，$s = 2$ 和 $k = 3$ 的情况，评估这些表达式。将 FLOPs 表示为 $H_{\\text{out}}$ 和 $W_{\\text{out}}$ 的函数，并将峰值中间激活元素数量也表示为 $H_{\\text{out}}$ 和 $W_{\\text{out}}$ 的函数。不需要四舍五入。\n\n将你的最终答案以一个包含 $9$ 个条目的单行矩阵形式给出，顺序如下：$\\big[$ 转置卷积的 FLOPs，转置卷积的参数数量，转置卷积的峰值中间元素数量，像素重排的 FLOPs，像素重排的参数数量，像素重排的峰值中间元素数量，最近邻加卷积的 FLOPs，最近邻加卷积的参数数量，最近邻加卷积的峰值中间元素数量 $\\big]$。",
            "solution": "问题陈述在深度学习领域内是一个有效、适定且有科学依据的问题。它要求对三种标准的上采样技术进行定量比较。所有给定条件都清晰且一致。我们将开始推导。\n\n基本操作是二维离散卷积。对于一个将形状为 $C_{\\text{in}} \\times H_{\\text{in}} \\times W_{\\text{in}}$ 的输入张量映射到形状为 $C_{\\text{out}} \\times H_{\\text{out}} \\times W_{\\text{out}}$ 的输出张量（核心尺寸为 $k \\times k$）的标准卷积，其浮点运算次数（FLOPs）计算如下。对于 $H_{\\text{out}} \\times W_{\\text{out}}$ 空间网格中的每个输出像素以及 $C_{\\text{out}}$ 个输出通道中的每一个，计算都涉及到对 $k \\times k$ 邻域和所有 $C_{\\text{in}}$ 个输入通道的求和。这包括 $C_{\\text{in}} \\times k \\times k$ 次乘法和同样数量的加法。将一次乘加运算定义为 $2$ FLOPs，总 FLOPs 为：\n$$\n\\text{FLOPs} \\approx 2 \\times H_{\\text{out}} \\times W_{\\text{out}} \\times C_{\\text{out}} \\times C_{\\text{in}} \\times k \\times k\n$$\n我们基于此原理分析这三种上采样策略中的每一种。输入空间尺寸为 $H_{\\text{in}} \\times W_{\\text{in}}$，输出为 $H_{\\text{out}} \\times W_{\\text{out}}$，且 $H_{\\text{out}} = s H_{\\text{in}}$ 和 $W_{\\text{out}} = s W_{\\text{in}}$。\n\n### 策略 (i)：转置卷积\n\n步幅为 $s$ 的转置卷积（也称为反卷积或分数步幅卷积）将一个低分辨率输入网格映射到一个高分辨率输出网格。其计算成本由乘加运算的数量定义，这些运算发生在输入网格的每个像素上。\n\n- **FLOPs**：乘加运算是相对于尺寸为 $H_{\\text{in}} \\times W_{\\text{in}}$ 的输入张量执行的。对于 $H_{\\text{in}} \\times W_{\\text{in}}$ 个输入像素中的每一个，以及 $C_{\\text{in}}$ 个输入通道和 $C_{\\text{out}}$ 个输出通道中的每一个，都会应用核心权重。这等效于一个产生尺寸为 $H_{\\text{in}} \\times W_{\\text{in}}$ 的输出的标准卷积。\n$$\n\\text{FLOPs}_{\\text{TC}} = 2 \\times H_{\\text{in}} \\times W_{\\text{in}} \\times C_{\\text{out}} \\times C_{\\text{in}} \\times k^2\n$$\n代入 $H_{\\text{in}} = H_{\\text{out}}/s$ 和 $W_{\\text{in}} = W_{\\text{out}}/s$，我们得到：\n$$\n\\text{FLOPs}_{\\text{TC}} = 2 \\times \\frac{H_{\\text{out}}}{s} \\times \\frac{W_{\\text{out}}}{s} \\times C_{\\text{out}} \\times C_{\\text{in}} \\times k^2 = \\frac{2 H_{\\text{out}} W_{\\text{out}} C_{\\text{in}} C_{\\text{out}} k^2}{s^2}\n$$\n\n- **参数**：问题陈述参数张量的形状为 $C_{\\text{out}} \\times C_{\\text{in}} \\times k \\times k$。参数（权重）的总数是这些维度的乘积。偏置没有被提及，因此不包括在内。\n$$\n\\text{Params}_{\\text{TC}} = C_{\\text{in}} C_{\\text{out}} k^2\n$$\n\n- **峰值中间激活元素数量**：转置卷积的一种常见实现方式是，通过在输入元素之间插入 $s-1$ 行和列的零来对输入张量进行上采样，然后应用标准卷积。中间张量就是这个零插值的张量。一个空间尺寸为 $H_{\\text{in}} \\times W_{\\text{in}}$ 的输入会变成一个尺寸为 $((H_{\\text{in}}-1)s + 1) \\times ((W_{\\text{in}}-1)s + 1)$、通道数为 $C_{\\text{in}}$ 的中间张量。\n$$\n\\text{Interm}_{\\text{TC}} = C_{\\text{in}} \\times ((H_{\\text{in}}-1)s + 1) \\times ((W_{\\text{in}}-1)s + 1)\n$$\n用输出维度表示：\n$$\n\\text{Interm}_{\\text{TC}} = C_{\\text{in}} \\times \\left(\\left(\\frac{H_{\\text{out}}}{s}-1\\right)s + 1\\right) \\times \\left(\\left(\\frac{W_{\\text{out}}}{s}-1\\right)s + 1\\right) = C_{\\text{in}} (H_{\\text{out}} - s + 1)(W_{\\text{out}} - s + 1)\n$$\n\n### 策略 (ii)：像素重排\n\n该策略包括一个在低分辨率下的标准卷积，随后进行深度到空间的重排。\n\n- **FLOPs**：第一步是在 $H_{\\text{in}} \\times W_{\\text{in}}$ 输入上进行标准卷积，将 $C_{\\text{in}}$ 个通道映射到 $C_{\\text{out}} s^2$ 个通道。为了公平比较，假设核心尺寸为 $k \\times k$。第二步（像素重排）是重新排列操作，其 FLOPs 为零。\n$$\n\\text{FLOPs}_{\\text{PS}} = 2 \\times H_{\\text{in}} \\times W_{\\text{in}} \\times (C_{\\text{out}}s^2) \\times C_{\\text{in}} \\times k^2\n$$\n代入 $H_{\\text{in}}$ 和 $W_{\\text{in}}$：\n$$\n\\text{FLOPs}_{\\text{PS}} = 2 \\times \\frac{H_{\\text{out}}}{s} \\times \\frac{W_{\\text{out}}}{s} \\times C_{\\text{out}}s^2 \\times C_{\\text{in}} \\times k^2 = 2 H_{\\text{out}} W_{\\text{out}} C_{\\text{in}} C_{\\text{out}} k^2\n$$\n\n- **参数**：参数属于初始卷积，其输入通道为 $C_{\\text{in}}$，输出通道为 $C_{\\text{out}}s^2$，核心尺寸为 $k \\times k$。\n$$\n\\text{Params}_{\\text{PS}} = C_{\\text{in}} (C_{\\text{out}}s^2) k^2 = C_{\\text{in}} C_{\\text{out}} s^2 k^2\n$$\n\n- **峰值中间激活元素数量**：中间张量是像素重排之前、低分辨率卷积的输出。其形状为 $(C_{\\text{out}}s^2) \\times H_{\\text{in}} \\times W_{\\text{in}}$。\n$$\n\\text{Interm}_{\\text{PS}} = (C_{\\text{out}}s^2) \\times H_{\\text{in}} \\times W_{\\text{in}} = C_{\\text{out}}s^2 \\times \\frac{H_{\\text{out}}}{s} \\times \\frac{W_{\\text{out}}}{s} = C_{\\text{out}} H_{\\text{out}} W_{\\text{out}}\n$$\n\n### 策略 (iii)：最近邻上采样 + 卷积\n\n该策略首先扩展空间分辨率，然后应用一个卷积。\n\n- **FLOPs**：第一步，最近邻上采样，不涉及浮点算术。所有的 FLOPs 都来自随后在高分辨率尺度上进行的标准卷积。该卷积使用一个 $k \\times k$ 的核心，将形状为 $C_{\\text{in}} \\times H_{\\text{out}} \\times W_{\\text{out}}$ 的上采样张量映射到形状为 $C_{\\text{out}} \\times H_{\\text{out}} \\times W_{\\text{out}}$ 的输出张量。\n$$\n\\text{FLOPs}_{\\text{Up+C}} = 2 \\times H_{\\text{out}} \\times W_{\\text{out}} \\times C_{\\text{out}} \\times C_{\\text{in}} \\times k^2\n$$\n\n- **参数**：参数是高分辨率卷积的参数。\n$$\n\\text{Params}_{\\text{Up+C}} = C_{\\text{in}} C_{\\text{out}} k^2\n$$\n\n- **峰值中间激活元素数量**：中间张量是最近邻上采样步骤的输出，其形状为 $C_{\\text{in}} \\times H_{\\text{out}} \\times W_{\\text{out}}$。\n$$\n\\text{Interm}_{\\text{Up+C}} = C_{\\text{in}} H_{\\text{out}} W_{\\text{out}}\n$$\n\n### 数值评估\n我们现在代入给定值：$C_{\\text{in}} = 64$，$C_{\\text{out}} = 64$，$s = 2$ 和 $k = 3$。\n\n**对于转置卷积 (i)：**\n- $\\text{FLOPs}_{\\text{TC}} = \\frac{2 H_{\\text{out}} W_{\\text{out}} (64)(64) (3^2)}{2^2} = \\frac{2 \\times 4096 \\times 9}{4} H_{\\text{out}} W_{\\text{out}} = 18432 H_{\\text{out}} W_{\\text{out}}$.\n- $\\text{Params}_{\\text{TC}} = (64)(64)(3^2) = 4096 \\times 9 = 36864$.\n- $\\text{Interm}_{\\text{TC}} = 64 (H_{\\text{out}} - 2 + 1)(W_{\\text{out}} - 2 + 1) = 64(H_{\\text{out}} - 1)(W_{\\text{out}} - 1)$.\n\n**对于像素重排 (ii)：**\n- $\\text{FLOPs}_{\\text{PS}} = 2 H_{\\text{out}} W_{\\text{out}} (64)(64) (3^2) = 2 \\times 4096 \\times 9 H_{\\text{out}} W_{\\text{out}} = 73728 H_{\\text{out}} W_{\\text{out}}$.\n- $\\text{Params}_{\\text{PS}} = (64)(64)(2^2)(3^2) = 4096 \\times 4 \\times 9 = 147456$.\n- $\\text{Interm}_{\\text{PS}} = 64 H_{\\text{out}} W_{\\text{out}}$.\n\n**对于上采样 + 卷积 (iii)：**\n- $\\text{FLOPs}_{\\text{Up+C}} = 2 H_{\\text{out}} W_{\\text{out}} (64)(64) (3^2) = 73728 H_{\\text{out}} W_{\\text{out}}$.\n- $\\text{Params}_{\\text{Up+C}} = (64)(64)(3^2) = 4096 \\times 9 = 36864$.\n- $\\text{Interm}_{\\text{Up+C}} = 64 H_{\\text{out}} W_{\\text{out}}$.\n\n最终答案是一个行矩阵，按指定顺序包含这九个结果。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 18432 H_{\\text{out}} W_{\\text{out}}  36864  64(H_{\\text{out}} - 1)(W_{\\text{out}} - 1)  73728 H_{\\text{out}} W_{\\text{out}}  147456  64 H_{\\text{out}} W_{\\text{out}}  73728 H_{\\text{out}} W_{\\text{out}}  36864  64 H_{\\text{out}} W_{\\text{out}} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "转置卷积功能强大，但也因有时会产生棋盘伪影而闻名，这些伪影会降低生成图像的质量。这个动手编程挑战让你通过重建一个图案来将这些伪影可视化，并探索如何利用一个微妙而强大的概念——核相位调整——来有效减轻它们。",
            "id": "3196158",
            "problem": "您面临一个纯粹的数学和计算挑战，该挑战关于在对二进制棋盘格图案进行上采样时使用二维转置卷积。目标是从离散卷积和线性算子的第一性原理出发进行推理，以构建一个正确的二维转置卷积实现，严格定义核相位的概念，并定量地展示相位调整如何能减少在从低分辨率棋盘格重建高分辨率棋盘格时的棋盘格伪影（鬼影网格）。\n\n从以下基础知识开始：\n- 一维信号 $x[n]$ 与核 $h[m]$ 的离散卷积定义为 $y[n] = \\sum_{m \\in \\mathbb{Z}} x[m] \\, h[n-m]$。根据线性性质，其对于 $x[i,j]$ 和 $h[u,v]$ 的二维模拟为 $y[p,q] = \\sum_{i,j} x[i,j] \\, h[p-i, q-j]$。\n- 步长为 $s$ 的步进卷积可以看作是先应用卷积，然后对输出索引每 $s$ 个采样一次。该线性算子的转置对应于首先在样本之间插入 $s-1$ 个零（因子为 $s$ 的上采样），然后再与一个翻转的核进行卷积。这将得出一个具体、可实现的转置卷积表达式。\n- 对于一个大小为 $H \\times W$ 的输入，使用步长为 $s$、大小为 $k \\times k$ 的有限核进行二维转置卷积，其产生的输出自然的、未裁剪的尺寸为 $(H-1)\\cdot s + k$ × $(W-1)\\cdot s + k$。\n\n任务：\n1. 从上述基础出发，为一个具有整数步长 $s$、大小为 $k \\times k$ 的有限核 $K$ 以及核相位参数 $\\phi = (\\phi_y,\\phi_x)$（其中 $\\phi_y \\in \\{0,1,\\dots,s-1\\}$ 且 $\\phi_x \\in \\{0,1,\\dots,s-1\\}$）的二维转置卷积推导出一个显式的求和公式。核相位决定了核的哪个整数抽头与每个上采样后的格点对齐。将此推导实现为一个正确的数值程序。\n2. 构建一个低分辨率二进制棋盘格 $X \\in \\{0,1\\}^{H \\times W}$，其定义为 $X[i,j] = ((i + j) \\bmod 2)$，使用实值算术。通过在两个维度上进行因子为 $s$ 的最近邻复制来构建目标高分辨率图像 $Y_{\\text{target}}$，即每个像素被扩展为一个 $s \\times s$ 的恒定块。\n3. 对于给定的步长 $s$ 和核大小 $k$，定义一个大小为 $k \\times k$ 的可分离、对称、归一化的核 $K$，作为一维二项式权重 $b[r] = \\binom{k-1}{r} / 2^{\\,k-1}$ (其中 $r \\in \\{0,1,\\dots,k-1\\}$) 的外积，因此 $K[u,v] = b[u]\\cdot b[v]$。这个核是一个离散三角（帐篷）核，通常用于近似双线性插值。\n4. 使用推导出的求和公式实现二维转置卷积。在输出域之外使用零填充。对于网格 $\\{0,1,\\dots,s-1\\} \\times \\{0,1,\\dots,s-1\\}$ 中的每个相位 $\\phi$，计算形状为 $((H-1)\\cdot s + k) \\times ((W-1)\\cdot s + k)$ 的未裁剪输出 $Y_{\\phi}$，然后将其中心裁剪至确切的目标形状 $sH \\times sW$，形成 $\\widehat{Y}_{\\phi}$。中心裁剪的定义是，沿每个轴在顶部和左侧移除 $\\lfloor (k-s)/2 \\rfloor$ 个像素，在底部和右侧移除 $\\lceil (k-s)/2 \\rceil$ 个像素，以匹配 $sH \\times sW$ 的尺寸（等价地，裁剪一个大小为 $sH \\times sW$ 的居中窗口）。\n5. 通过重建输出和目标之间的均方误差（MSE, Mean Squared Error）来量化鬼影网格，其定义为\n   $$ \\operatorname{MSE}(A,B) = \\frac{1}{N} \\sum_{n=1}^{N} \\left( A_n - B_n \\right)^2 $$,\n   其中 $N = sH \\cdot sW$，且 $A$ 和 $B$ 是大小为 $N$ 的展平数组。\n6. 对于每个测试用例，定义改进比\n   $$ r = \\frac{\\min_{\\phi} \\operatorname{MSE}(\\widehat{Y}_{\\phi}, Y_{\\text{target}})}{\\max_{\\phi} \\operatorname{MSE}(\\widehat{Y}_{\\phi}, Y_{\\text{target}})} $$。\n   $r  1$ 的值表示相对于最差相位，相位调整减少了鬼影网格。\n7. 您的程序必须为每个测试用例计算 $r$，并生成一行输出，其中包含用方括号括起来的逗号分隔的结果列表，每个 $r$ 值都四舍五入到恰好 $6$ 位小数。例如，打印为 $[0.123456,0.654321,1.000000]$。\n\n测试套件：\n- 案例 1 (一般情况，$k \\neq s$)：$H = 5$，$W = 6$，$s = 2$，$k = 3$。\n- 案例 2 (边界情况，$k = s$)：$H = 5$，$W = 6$，$s = 2$，$k = 2$。\n- 案例 3 (边缘情况，$k \\neq s$ 且步长较大)：$H = 5$，$W = 6$，$s = 3$，$k = 4$。\n\n所有量都是无单位的。您的最终输出必须是上述确切格式的一行。不允许用户输入，也不得使用文件或网络访问。程序必须是完整的，并能按规定运行。唯一接受的输出类型是列表中的浮点数。在打印前将每个 $r$ 四舍五入到 $6$ 位小数。",
            "solution": "该问题要求推导带相位的二维转置卷积，实现该算法以上采样二进制棋盘格图案，并分析核相位如何影响棋盘格伪影。解决方案首先为该操作建立一个正式的数学模型，然后描述其数值实现和在具体测试用例中的应用。\n\n### 步骤 1：带相位转置卷积公式的推导\n\n步长为 $s$ 的二维卷积是一个线性算子。其转置，即转置卷积，也是一个线性算子。理解转置卷积的一种构造性方法是将其视为一个操作，该操作将输入网格中的每个点映射到输出网格中一个经过缩放和平移的核副本。\n\n设输入为大小为 $H \\times W$ 的离散二维信号 $X[i,j]$。设卷积核为大小为 $k \\times k$ 的 $K[u,v]$。对于步长为 $s$ 的转置卷积操作，实际上是将核 $K$ 的一个副本（按输入值 $X[i,j]$ 缩放）放置在输出网格中与输入坐标 $(i,j)$ 对应的位置。在没有任何相位偏移的情况下，核副本的左上角 $(0,0)$ 与输出网格中的上采样坐标 $(is, js)$ 对齐。\n\n问题引入了一个核相位参数 $\\phi = (\\phi_y, \\phi_x)$，其中 $\\phi_y, \\phi_x \\in \\{0, 1, \\dots, s-1\\}$。该相位决定了核的哪个抽头 $(\\phi_y, \\phi_x)$ 与上采样后的格点 $(is, js)$ 对齐。如果核的抽头 $(\\phi_y, \\phi_x)$ 被放置在 $(is, js)$ 处，那么核的原点（抽头 $(0,0)$）被有效地移动到位置 $(is - \\phi_y, js - \\phi_x)$。\n\n因此，单个输入像素 $X[i,j]$ 对输出像素 $Y[p,q]$ 的贡献非零，当且仅当 $(p,q)$ 落在移位后核的覆盖区域内。落在 $(p,q)$ 上的特定核抽头是 $(u,v)$，其中：\n$p = (is - \\phi_y) + u \\implies u = p - is + \\phi_y$\n$q = (js - \\phi_x) + v \\implies v = q - js + \\phi_x$\n\n一个输出像素 $Y_{\\phi}[p,q]$ 的总值是所有输入像素贡献的总和。这导出了带相位的二维转置卷积的显式求和公式：\n$$\nY_{\\phi}[p,q] = \\sum_{i=0}^{H-1} \\sum_{j=0}^{W-1} X[i,j] \\cdot K[p - is + \\phi_y, q - js + \\phi_x]\n$$\n这个公式对所有输出坐标 $(p,q)$ 都有效。核 $K$ 在其有限支撑域（即不在 $[0, k-1] \\times [0, k-1]$ 范围内的索引）之外被定义为零。这个公式为数值实现提供了直接的基础。\n\n### 步骤 2：算法设计与实现\n\n解决方案的结构是按照指定的任务来解决每个测试用例。\n\n**输入、目标和核的生成（任务 2 和 3）：**\n首先，对于给定的测试用例 $(H, W, s, k)$，构造必要的组件。\n- 低分辨率输入 $X$ 是一个 $H \\times W$ 的矩阵，由二进制棋盘格图案 $X[i,j] = ((i+j) \\pmod 2)$ 定义。\n- 高分辨率目标 $Y_{\\text{target}}$ 是一个 $sH \\times sW$ 的矩阵，通过对 $X$ 进行最近邻复制上采样生成。这等同于将 $X$ 的每个像素扩展为一个恒定的 $s \\times s$ 块，使用克罗内克积可以高效地实现。\n- $k \\times k$ 的核 $K$ 被构造为一个一维二项式滤波器向量 $b$ 的外积。$b$ 的元素由 $b[r] = \\binom{k-1}{r} / 2^{k-1}$ 给出，其中 $r \\in \\{0, \\dots, k-1\\}$。得到的核 $K[u,v] = b[u]b[v]$ 是对称的，其元素之和为 1。\n\n**转置卷积和裁剪（任务 4）：**\n直接实现推导出的求和公式。一个大小为所需未裁剪尺寸 $((H-1)s+k) \\times ((W-1)s+k)$ 的输出网格 $Y_{\\phi}$ 被初始化为零。每个像素 $Y_{\\phi}[p,q]$ 的值是通过遍历所有输入像素 $X[i,j]$ 并根据公式对其贡献求和来计算的。对网格 $\\{0, \\dots, s-1\\} \\times \\{0, \\dots, s-1\\}$ 中的每个可能的相位 $\\phi$ 重复此过程。\n\n计算完未裁剪的输出 $Y_{\\phi}$ 后，将其中心裁剪至目标尺寸 $sH \\times sW$。沿每个轴需要移除的像素总数为 $k-s$。通过从开始（顶部/左侧）修剪 $\\lfloor (k-s)/2 \\rfloor$ 个像素，从末尾（底部/右侧）修剪 $\\lceil (k-s)/2 \\rceil$ 个像素来完成。这样便产生了最终的重建图像 $\\widehat{Y}_{\\phi}$。\n\n**误差量化和改进比（任务 5 和 6）：**\n棋盘格伪影表现为输出中不希望出现的高频网格图案，其产生原因是核响应的重叠不均匀。这些伪影的严重程度通过重建图像 $\\widehat{Y}_{\\phi}$ 与理想的最近邻目标 $Y_{\\text{target}}$ 之间的均方误差（MSE）来量化：\n$$\n\\operatorname{MSE}(\\widehat{Y}_{\\phi}, Y_{\\text{target}}) = \\frac{1}{sH \\cdot sW} \\sum_{p=0}^{sH-1} \\sum_{q=0}^{sW-1} \\left( \\widehat{Y}_{\\phi}[p,q] - Y_{\\text{target}}[p,q] \\right)^2\n$$\n对于每个测试用例，为所有可能的相位 $\\phi$ 计算 MSE。找出最小和最大的 MSE 值。最终的改进比 $r$ 计算如下：\n$$\nr = \\frac{\\min_{\\phi} \\operatorname{MSE}(\\widehat{Y}_{\\phi}, Y_{\\text{target}})}{\\max_{\\phi} \\operatorname{MSE}(\\widehat{Y}_{\\phi}, Y_{\\text{target}})}\n$$\n该比率衡量了相位调整的有效性。$r  1$ 的值表明，与最差情况的相位相比，选择最优的核相位可以显著减少重建误差。如果最大 MSE 为零（所有相位下都能完美重建），则该比率取 1。为每个测试用例计算出的 $r$ 值在最终输出时四舍五入到六位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import comb\n\ndef transposed_conv(X, K, s, phi):\n    \"\"\"\n    Computes the 2D transposed convolution using the derived summation formula.\n\n    Args:\n        X (np.ndarray): Input matrix of shape (H, W).\n        K (np.ndarray): Kernel matrix of shape (k, k).\n        s (int): The stride.\n        phi (tuple): The phase (phi_y, phi_x).\n\n    Returns:\n        np.ndarray: The uncropped output matrix.\n    \"\"\"\n    H, W = X.shape\n    k, _ = K.shape\n    phi_y, phi_x = phi\n    \n    out_H = (H - 1) * s + k\n    out_W = (W - 1) * s + k\n    Y = np.zeros((out_H, out_W), dtype=float)\n\n    # This direct implementation of the derived formula is clear and sufficient\n    # for the problem's constraints.\n    for p in range(out_H):\n        for q in range(out_W):\n            val = 0.0\n            for i in range(H):\n                for j in range(W):\n                    u = p - i * s + phi_y\n                    v = q - j * s + phi_x\n                    if 0 = u  k and 0 = v  k:\n                        val += X[i, j] * K[u, v]\n            Y[p, q] = val\n            \n    return Y\n\ndef compute_improvement_ratio(H, W, s, k):\n    \"\"\"\n    Computes the improvement ratio 'r' for a single test case.\n    \"\"\"\n    # Task 3: Construct the separable, symmetric, normalized kernel K\n    b = np.array([comb(k - 1, r, exact=False) for r in range(k)], dtype=float) / (2**(k - 1))\n    K = np.outer(b, b)\n\n    # Task 2: Construct the low-resolution chessboard X and high-resolution target Y_target\n    I, J = np.ogrid[:H, :W]\n    X = ((I + J) % 2).astype(float)\n    Y_target = np.kron(X, np.ones((s, s)))\n    \n    target_H, target_W = Y_target.shape\n\n    # Task 4: Define center-cropping parameters\n    pad_amount = k - s\n    crop_y_start = int(np.floor(pad_amount / 2))\n    crop_x_start = int(np.floor(pad_amount / 2))\n\n    mses = []\n    # Iterate over all possible phases\n    for phi_y in range(s):\n        for phi_x in range(s):\n            # Task 4 (Part 1): Compute the uncropped transposed convolution output\n            Y_phi = transposed_conv(X, K, s, (phi_y, phi_x))\n\n            # Task 4 (Part 2): Center-crop the output to the target shape\n            Y_hat_phi = Y_phi[crop_y_start : crop_y_start + target_H, crop_x_start : crop_x_start + target_W]\n\n            # Task 5: Quantify ghost grids by Mean Squared Error (MSE)\n            mse = np.mean((Y_hat_phi - Y_target)**2)\n            mses.append(mse)\n\n    # Task 6: Compute the improvement ratio r\n    min_mse = np.min(mses)\n    max_mse = np.max(mses)\n\n    if max_mse == 0:\n        return 1.0\n    else:\n        return min_mse / max_mse\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (5, 6, 2, 3),  # Case 1\n        (5, 6, 2, 2),  # Case 2\n        (5, 6, 3, 4),  # Case 3\n    ]\n\n    results = []\n    for H, W, s, k in test_cases:\n        r = compute_improvement_ratio(H, W, s, k)\n        # Round to 6 decimal places and format to ensure 6 places are shown\n        results.append(f\"{round(r, 6):.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}