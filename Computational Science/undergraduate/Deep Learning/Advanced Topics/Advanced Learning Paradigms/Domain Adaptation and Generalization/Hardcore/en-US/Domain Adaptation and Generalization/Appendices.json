{
    "hands_on_practices": [
        {
            "introduction": "The choice of a loss function is a fundamental decision in training any machine learning model, yet its impact extends beyond simple optimization. Different loss functions shape the decision boundary and the model's confidence in distinct ways, which can profoundly affect how well the model generalizes when faced with a domain shift. This practice provides a hands-on experiment to explore this relationship, allowing you to empirically measure how training with cross-entropy, label-smoothing, or a margin-based loss impacts transfer performance across various types of distribution shifts .",
            "id": "3117573",
            "problem": "You will implement and compare three empirical risk minimization procedures under a controlled source-to-target distribution shift for binary classification. Your goal is to operationalize how the choice of loss function during training on a source distribution affects the transfer performance on a target distribution. You must produce a complete program that trains a linear classifier on source data using three different losses, evaluates on target data with a standardized metric, and outputs a final decision per test case indicating whether a smoother loss improves transfer.\n\nBase principles and definitions:\n- Empirical Risk Minimization (ERM): Given data sampled from a source distribution $\\mathcal{S}$, a hypothesis class $\\mathcal{H}$, and a loss $\\ell$, ERM fits parameters $\\theta$ by minimizing the empirical risk $\\hat{R}_{\\mathcal{S}}(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n} \\ell(f_{\\theta}(x_i), y_i)$.\n- Domain adaptation setup: There is a source distribution $\\mathcal{S}$ and a target distribution $\\mathcal{T}$ over the same input-output space. The model is trained on $\\mathcal{S}$ and evaluated on $\\mathcal{T}$.\n- Model: A linear classifier $f_{\\theta}(x) = \\sigma(w^{\\top} x + b)$ with parameters $\\theta = (w,b)$, where $\\sigma(z) = \\frac{1}{1+\\exp(-z)}$ is the logistic sigmoid.\n- Training losses to compare:\n  1. Cross-entropy (CE): $\\ell_{\\mathrm{CE}}(p,y) = -\\left(y \\log p + (1-y)\\log(1-p)\\right)$ for $y \\in \\{0,1\\}$ and $p \\in (0,1)$.\n  2. Label-smoothing cross-entropy (LS-CE): Replace the hard target $y \\in \\{0,1\\}$ with a smoothed target $t \\in (0,1)$ where $t = (1-\\varepsilon)$ when $y=1$ and $t = \\varepsilon$ when $y=0$, for a given smoothing parameter $\\varepsilon \\in [0,1/2)$. Then use $\\ell_{\\mathrm{CE}}(p,t)$.\n  3. Margin logistic loss (M-Logit): For labels $\\tilde{y} \\in \\{-1,+1\\}$ and score $z = w^{\\top}x + b$, $\\ell_{\\mathrm{M}}(z,\\tilde{y}) = \\log\\left(1 + \\exp\\left(m - \\tilde{y}\\,z\\right)\\right)$ where $m \\ge 0$ is the margin parameter.\n\nAll three training objectives include $\\ell_2$-regularization with coefficient $\\lambda > 0$ applied to $w$ only. Optimization is performed by batch gradient descent for a fixed number of epochs and a fixed learning rate.\n\nEvaluation metric:\n- To compare transfer performance across losses in a common space, evaluate on target data using the standard cross-entropy with the true labels $y \\in \\{0,1\\}$ and the model’s predicted probability $p = \\sigma(w^{\\top}x + b)$. The target risk estimate is $\\hat{R}_{\\mathcal{T}}(\\theta) = \\frac{1}{n_{\\mathcal{T}}}\\sum_{j=1}^{n_{\\mathcal{T}}} -\\left(y_j \\log p_j + (1-y_j)\\log(1-p_j)\\right)$.\n\nData generation:\n- Inputs are in $\\mathbb{R}^d$ with $d=2$. Both source $\\mathcal{S}$ and target $\\mathcal{T}$ are binary class-conditional Gaussian mixtures with isotropic covariance $\\sigma^2 I$ but possibly different class priors and class means. For a dataset with $n$ samples, draw class labels according to the class prior, then draw $x \\mid y=c$ from $\\mathcal{N}(\\mu_c, \\sigma^2 I)$ for $c \\in \\{0,1\\}$.\n- For each test case, you will be given:\n  - Source class means $\\mu^{\\mathcal{S}}_0 \\in \\mathbb{R}^2$ and $\\mu^{\\mathcal{S}}_1 \\in \\mathbb{R}^2$,\n  - Target class means $\\mu^{\\mathcal{T}}_0 \\in \\mathbb{R}^2$ and $\\mu^{\\mathcal{T}}_1 \\in \\mathbb{R}^2$,\n  - Source and target class priors $\\pi^{\\mathcal{S}} \\in (0,1)$ and $\\pi^{\\mathcal{T}} \\in (0,1)$ for class $1$ (class $0$ has prior $1-\\pi$),\n  - Standard deviation $\\sigma > 0$ (shared across classes and domains),\n  - Training size $n_{\\mathcal{S}}$ and evaluation size $n_{\\mathcal{T}}$,\n  - Optimization hyperparameters: learning rate $\\alpha > 0$, epochs $E \\in \\mathbb{N}$, regularization $\\lambda > 0$,\n  - Label smoothing parameter $\\varepsilon \\in [0,1/2)$ and margin parameter $m \\ge 0$.\n\nDecision rule per test case:\n- Let $\\hat{R}^{\\mathrm{CE}}_{\\mathcal{T}}$, $\\hat{R}^{\\mathrm{LS}}_{\\mathcal{T}}$, and $\\hat{R}^{\\mathrm{M}}_{\\mathcal{T}}$ denote the target evaluation risks for the model trained with cross-entropy, label-smoothing cross-entropy, and margin logistic loss respectively. Define a tolerance $\\tau = 10^{-3}$.\n- Output the boolean value `LS_is_better` for the test case, which is `True` if $\\hat{R}^{\\mathrm{LS}}_{\\mathcal{T}} \\le \\min\\{\\hat{R}^{\\mathrm{CE}}_{\\mathcal{T}}, \\hat{R}^{\\mathrm{M}}_{\\mathcal{T}}\\} - \\tau$, and `False` otherwise.\n\nTest suite:\nUse the following four test cases, each specified as an ordered tuple of parameters. Each test case row lists:\n$(\\mu^{\\mathcal{S}}_0, \\mu^{\\mathcal{S}}_1, \\mu^{\\mathcal{T}}_0, \\mu^{\\mathcal{T}}_1, \\pi^{\\mathcal{S}}, \\pi^{\\mathcal{T}}, \\sigma, n_{\\mathcal{S}}, n_{\\mathcal{T}}, \\alpha, E, \\lambda, \\varepsilon, m)$, where all vectors are in $\\mathbb{R}^2$ and all scalars are real numbers in appropriate domains.\n\n- Case $1$ (mild covariate shift, small sample):\n  - $( (-1.0, 0.0), (1.0, 0.0), (-0.6, 0.0), (1.4, 0.0), 0.5, 0.5, 0.5, 200, 5000, 0.1, 400, 10^{-2}, 0.1, 0.6 )$\n- Case $2$ (no shift, large sample):\n  - $( (-1.0, 0.0), (1.0, 0.0), (-1.0, 0.0), (1.0, 0.0), 0.5, 0.5, 0.5, 4000, 5000, 0.1, 400, 10^{-2}, 0.1, 0.6 )$\n- Case $3$ (strong covariate shift, medium sample):\n  - $( (-1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (2.0, 0.0), 0.5, 0.5, 0.6, 1000, 5000, 0.1, 400, 10^{-2}, 0.1, 0.6 )$\n- Case $4$ (label shift, no covariate shift):\n  - $( (-1.0, 0.0), (1.0, 0.0), (-1.0, 0.0), (1.0, 0.0), 0.5, 0.8, 0.5, 1000, 5000, 0.1, 400, 10^{-2}, 0.1, 0.6 )$\n\nImplementation requirements:\n- Use a single linear model class $f_{\\theta}(x) = \\sigma(w^{\\top} x + b)$ with shared initialization $(w,b)=(0,0)$ for each training run.\n- Train three separate models per test case: CE, LS-CE, and M-Logit, each with the specified hyperparameters and $\\ell_2$-regularization on $w$.\n- For evaluation on $\\mathcal{T}$, always compute the standard cross-entropy with true labels and the model’s predicted probability $p = \\sigma(w^{\\top} x + b)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of boolean values enclosed in square brackets (e.g., \"[True,False,True,False]\"), where the $k$-th boolean corresponds to Case $k$ above.",
            "solution": "The objective is to implement and compare three empirical risk minimization (ERM) procedures for a binary classification task under a specified source-to-target distribution shift. We will train a linear classifier on a source distribution $\\mathcal{S}$ using three distinct loss functions and evaluate their generalization performance on a target distribution $\\mathcal{T}$ using a common metric.\n\n### 1. Model and Data Generation\nThe model is a linear classifier parameterized by weights $w \\in \\mathbb{R}^d$ and a bias $b \\in \\mathbb{R}$, where $d=2$ for this problem. The parameters are denoted collectively as $\\theta = (w,b)$. The classifier predicts the probability of class $1$ for an input $x \\in \\mathbb{R}^d$ as:\n$$f_{\\theta}(x) = p = \\sigma(w^{\\top} x + b)$$\nwhere $\\sigma(z) = \\frac{1}{1+\\exp(-z)}$ is the logistic sigmoid function.\n\nThe data for both source and target domains are generated from two-component Gaussian mixture models. For a given domain (either $\\mathcal{S}$ or $\\mathcal{T}$) with class priors $\\pi_0$ and $\\pi_1$ (where $\\pi_0 + \\pi_1 = 1$), a data point $(x,y)$ is generated by first sampling a class label $y \\in \\{0,1\\}$ from a Bernoulli distribution with parameter $\\pi_1$. Then, the feature vector $x$ is sampled from a class-conditional Gaussian distribution:\n$$x \\mid y=c \\sim \\mathcal{N}(\\mu_c, \\sigma^2 I)$$\nfor $c \\in \\{0,1\\}$, where $\\mu_c$ is the class mean and $\\sigma^2 I$ is the isotropic covariance matrix, with $I$ being the $d \\times d$ identity matrix.\n\n### 2. Training via Empirical Risk Minimization\nThe model parameters $\\theta$ are learned by minimizing a regularized empirical risk on the source data $\\{(x_i, y_i)\\}_{i=1}^{n_{\\mathcal{S}}}$. The general form of the objective function is:\n$$L(\\theta) = \\frac{1}{n_{\\mathcal{S}}} \\sum_{i=1}^{n_{\\mathcal{S}}} \\ell(f_{\\theta}(x_i), y_i) + \\lambda \\|w\\|_2^2$$\nwhere $\\ell$ is the chosen loss function and $\\lambda > 0$ is the coefficient for $\\ell_2$ regularization, which is applied only to the weights $w$. Optimization is performed using batch gradient descent for a fixed number of epochs $E$ with a learning rate $\\alpha$.\n\nThe parameter update rules are:\n$$w \\leftarrow w - \\alpha \\nabla_w L(\\theta)$$\n$$b \\leftarrow b - \\alpha \\nabla_b L(\\theta)$$\nThe gradients are computed over the entire source dataset:\n$$\\nabla_w L(\\theta) = \\left( \\frac{1}{n_{\\mathcal{S}}} \\sum_{i=1}^{n_{\\mathcal{S}}} \\frac{\\partial \\ell_i}{\\partial z_i} x_i^{\\top} \\right) + 2\\lambda w$$\n$$\\nabla_b L(\\theta) = \\frac{1}{n_{\\mathcal{S}}} \\sum_{i=1}^{n_{\\mathcal{S}}} \\frac{\\partial \\ell_i}{\\partial z_i}$$\nwhere $z_i = w^{\\top}x_i + b$ is the logit for sample $i$, and $\\ell_i$ is the loss for that sample. The crucial component is the gradient of the per-sample loss with respect to the logit, $\\frac{\\partial \\ell_i}{\\partial z_i}$, which varies for each of the three loss functions.\n\n### 3. Loss Functions and Gradients\n\n#### 3.1. Cross-Entropy Loss (CE)\nThe standard cross-entropy loss for binary classification with labels $y \\in \\{0,1\\}$ is:\n$$\\ell_{\\mathrm{CE}}(p,y) = -\\left(y \\log p + (1-y)\\log(1-p)\\right)$$\nwhere $p = \\sigma(z)$. The gradient of this loss with respect to the logit $z$ is:\n$$\\frac{\\partial \\ell_{\\mathrm{CE}}}{\\partial z} = p - y$$\n\n#### 3.2. Label-Smoothing Cross-Entropy Loss (LS-CE)\nThis loss is a variant of cross-entropy where the hard labels $y \\in \\{0,1\\}$ are replaced by \"soft\" or smoothed target probabilities $t$. For a smoothing parameter $\\varepsilon \\in [0, 1/2)$, the target $t$ is defined as:\n$$t = y(1-\\varepsilon) + (1-y)\\varepsilon$$\nThe loss function is $\\ell_{\\mathrm{CE}}(p,t)$. The gradient with respect to the logit $z$ is analogous to the standard CE case:\n$$\\frac{\\partial \\ell_{\\mathrm{LS}}}{\\partial z} = p - t$$\n\n#### 3.3. Margin Logistic Loss (M-Logit)\nThis loss is defined using labels $\\tilde{y} \\in \\{-1,+1\\}$, which correspond to $y \\in \\{0,1\\}$ via the mapping $\\tilde{y} = 2y-1$. Given a margin parameter $m \\ge 0$, the loss is:\n$$\\ell_{\\mathrm{M}}(z, \\tilde{y}) = \\log\\left(1 + \\exp\\left(m - \\tilde{y}z\\right)\\right)$$\nThis loss encourages the score $\\tilde{y}z$ to be greater than the margin $m$. The gradient with respect to the logit $z$ is:\n$$\\frac{\\partial \\ell_{\\mathrm{M}}}{\\partial z} = \\frac{\\partial}{\\partial z} \\log\\left(1 + \\exp\\left(m - \\tilde{y}z\\right)\\right) = \\frac{\\exp(m-\\tilde{y}z)}{1+\\exp(m-\\tilde{y}z)} \\cdot (-\\tilde{y}) = -\\tilde{y} \\, \\sigma(m - \\tilde{y}z)$$\n\n### 4. Evaluation and Decision\nAfter training three separate models (one for each loss function) on the source data $\\mathcal{S}$, their performance is evaluated on the target data $\\mathcal{T} = \\{(x_j, y_j)\\}_{j=1}^{n_{\\mathcal{T}}}$. The evaluation metric is the standard, un-smoothed cross-entropy risk for all models, ensuring a fair comparison. The target risk for a model with parameters $\\theta$ is:\n$$\\hat{R}_{\\mathcal{T}}(\\theta) = \\frac{1}{n_{\\mathcal{T}}} \\sum_{j=1}^{n_{\\mathcal{T}}} -\\left(y_j \\log p_j + (1-y_j)\\log(1-p_j)\\right)$$\nwhere $p_j = \\sigma(w^{\\top}x_j + b)$. For numerical stability, this can be computed as $\\frac{1}{n_{\\mathcal{T}}} \\sum_j \\left( \\log(1+e^{z_j}) - y_j z_j \\right)$.\n\nFor each test case, we compute the target risks $\\hat{R}^{\\mathrm{CE}}_{\\mathcal{T}}$, $\\hat{R}^{\\mathrm{LS}}_{\\mathcal{T}}$, and $\\hat{R}^{\\mathrm{M}}_{\\mathcal{T}}$. The final decision is based on a tolerance $\\tau = 10^{-3}$. The boolean output `LS_is_better` is `True` if and only if:\n$$\\hat{R}^{\\mathrm{LS}}_{\\mathcal{T}} \\le \\min\\{\\hat{R}^{\\mathrm{CE}}_{\\mathcal{T}}, \\hat{R}^{\\mathrm{M}}_{\\mathcal{T}}\\} - \\tau$$\n\n### 5. Implementation Summary\nThe solution involves a main loop over the provided test cases. For each case:\n1.  Set a deterministic random seed for reproducibility.\n2.  Generate source and target datasets according to the specified parameters.\n3.  For each of the three loss functions ('CE', 'LS', 'M'), train a linear model from initialization $(w,b)=(0,0)$ using batch gradient descent.\n4.  Evaluate each of the three trained models on the target dataset to obtain their respective target risks.\n5.  Apply the decision rule to determine if the label-smoothing approach provided a sufficiently better result than the other two.\nThe results from all test cases are collected and printed in the specified format.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import expit # Numerically stable sigmoid function\n\ndef generate_data(means, prior_1, sigma, n_samples, seed):\n    \"\"\"\n    Generates data from a 2-component Gaussian mixture model.\n    \"\"\"\n    d = len(means[0])\n    cov = sigma**2 * np.eye(d)\n    \n    rng = np.random.default_rng(seed)\n    \n    # Generate labels from a Bernoulli distribution\n    labels = rng.random(n_samples) < prior_1\n    y = labels.astype(int)\n    \n    n_class1 = np.sum(y)\n    n_class0 = n_samples - n_class1\n    \n    X = np.zeros((n_samples, d))\n    if n_class0 > 0:\n        X[y == 0] = rng.multivariate_normal(means[0], cov, n_class0)\n    if n_class1 > 0:\n        X[y == 1] = rng.multivariate_normal(means[1], cov, n_class1)\n        \n    return X, y\n\ndef train_model(X, y, loss_type, hparams):\n    \"\"\"\n    Trains a linear classifier using batch gradient descent.\n    \"\"\"\n    n_samples, d = X.shape\n    alpha = hparams['alpha']\n    epochs = hparams['epochs']\n    reg_lambda = hparams['lambda']\n    ls_eps = hparams.get('eps', 0.1)\n    margin_m = hparams.get('m', 0.6)\n\n    w = np.zeros(d)\n    b = 0.0\n\n    for _ in range(epochs):\n        z = X @ w + b\n        \n        if loss_type == 'ce':\n            p = expit(z)\n            grad_z = p - y\n        elif loss_type == 'ls':\n            p = expit(z)\n            t = y * (1 - ls_eps) + (1 - y) * ls_eps\n            grad_z = p - t\n        elif loss_type == 'm':\n            y_tilde = 2 * y - 1\n            arg = margin_m - y_tilde * z\n            # Note: expit(x) is sigmoid(x)\n            grad_z = -y_tilde * expit(arg)\n        else:\n            raise ValueError(\"Unknown loss type\")\n            \n        grad_w = (X.T @ grad_z) / n_samples + 2 * reg_lambda * w\n        grad_b = np.mean(grad_z)\n        \n        w -= alpha * grad_w\n        b -= alpha * grad_b\n        \n    return w, b\n\ndef evaluate_risk(X, y, w, b):\n    \"\"\"\n    Evaluates the standard cross-entropy risk on a dataset.\n    Uses a numerically stable implementation: log(1+exp(z)) - y*z\n    \"\"\"\n    z = X @ w + b\n    # np.logaddexp(0, z) computes log(1 + exp(z)) stably\n    losses = np.logaddexp(0, z) - y * z\n    return np.mean(losses)\n\ndef solve():\n    \"\"\"\n    Main solver function to run the experiment for all test cases.\n    \"\"\"\n    # Each case: (mu_s0, mu_s1, mu_t0, mu_t1, pi_s, pi_t, sigma, n_s, n_t, alpha, E, lambda, eps, m)\n    test_cases = [\n        # Case 1 (mild covariate shift, small sample)\n        ((-1.0, 0.0), (1.0, 0.0), (-0.6, 0.0), (1.4, 0.0), 0.5, 0.5, 0.5, 200, 5000, 0.1, 400, 10**-2, 0.1, 0.6),\n        # Case 2 (no shift, large sample)\n        ((-1.0, 0.0), (1.0, 0.0), (-1.0, 0.0), (1.0, 0.0), 0.5, 0.5, 0.5, 4000, 5000, 0.1, 400, 10**-2, 0.1, 0.6),\n        # Case 3 (strong covariate shift, medium sample)\n        ((-1.0, 0.0), (1.0, 0.0), (0.0, 0.0), (2.0, 0.0), 0.5, 0.5, 0.6, 1000, 5000, 0.1, 400, 10**-2, 0.1, 0.6),\n        # Case 4 (label shift, no covariate shift)\n        ((-1.0, 0.0), (1.0, 0.0), (-1.0, 0.0), (1.0, 0.0), 0.5, 0.8, 0.5, 1000, 5000, 0.1, 400, 10**-2, 0.1, 0.6),\n    ]\n\n    results = []\n    \n    for i, case in enumerate(test_cases):\n        mu_s0, mu_s1, mu_t0, mu_t1, pi_s, pi_t, sigma, n_s, n_t, alpha, E, reg_lambda, eps, m = case\n\n        # Convert means to numpy arrays\n        mu_s = (np.array(mu_s0), np.array(mu_s1))\n        mu_t = (np.array(mu_t0), np.array(mu_t1))\n\n        hparams = {\n            'alpha': alpha, 'epochs': E, 'lambda': reg_lambda,\n            'eps': eps, 'm': m\n        }\n        \n        # Use a deterministic seed for each case to ensure reproducibility.\n        # Use derived seeds for data generation to ensure source/target are different.\n        case_seed = 42 + i\n        \n        # Generate data\n        X_s, y_s = generate_data(mu_s, pi_s, sigma, n_s, seed=case_seed)\n        X_t, y_t = generate_data(mu_t, pi_t, sigma, n_t, seed=case_seed + 100) # Different seed for target\n        \n        # Train models\n        w_ce, b_ce = train_model(X_s, y_s, 'ce', hparams)\n        w_ls, b_ls = train_model(X_s, y_s, 'ls', hparams)\n        w_m, b_m = train_model(X_s, y_s, 'm', hparams)\n        \n        # Evaluate models\n        risk_ce = evaluate_risk(X_t, y_t, w_ce, b_ce)\n        risk_ls = evaluate_risk(X_t, y_t, w_ls, b_ls)\n        risk_m = evaluate_risk(X_t, y_t, w_m, b_m)\n        \n        # Apply decision rule\n        tau = 1e-3\n        is_better = risk_ls <= min(risk_ce, risk_m) - tau\n        results.append(is_better)\n        \n    # Format output as specified\n    formatted_results = [str(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "A crucial aspect of building robust and reliable machine learning systems is enabling them to recognize their own limitations. When a model encounters data that is fundamentally different from its training distribution—so-called out-of-distribution (OOD) data—its predictions can become arbitrary and untrustworthy. This practice guides you through building a \"selective classifier\" that can identify OOD samples and choose to abstain from making a prediction, a critical safety feature for real-world deployment . You will implement a density-based approach using Kernel Density Estimation (KDE) to distinguish familiar, in-distribution data from novel, OOD inputs.",
            "id": "3117588",
            "problem": "Consider a binary classification problem under domain adaptation and generalization, with a source domain $S$ and a target domain $T$. The input space is $\\mathbb{R}^2$, and the label space is $\\{0,1\\}$. The source domain $S$ generates independently and identically distributed (i.i.d.) pairs $(x,y)$ with the following structure. The marginal distribution over $x$ is uniform over the union of two axis-aligned rectangles, and the conditional label distribution assigns one rectangle to label $0$ and the other to label $1$. Specifically, define the rectangles\n$$R_0 = \\{x \\in \\mathbb{R}^2 : x_1 \\in [-3,-1],\\ x_2 \\in [-1,1]\\},$$\n$$R_1 = \\{x \\in \\mathbb{R}^2 : x_1 \\in [1,3],\\ x_2 \\in [-1,1]\\},$$\nand the source marginal support $\\operatorname{supp}(P_S^X) = R_0 \\cup R_1$. A simple base classifier $g$ uses the sign of the first coordinate, defined by $g(x) = \\mathbb{I}\\{x_1 > 0\\}$, where $\\mathbb{I}\\{\\cdot\\}$ denotes the indicator function.\n\nThe target domain $T$ introduces an out-of-support shift that includes inputs outside $\\operatorname{supp}(P_S^X)$. Concretely, let an out-of-distribution (OOD) rectangle\n$$R_o = \\{x \\in \\mathbb{R}^2 : x_1 \\in [-1,1],\\ x_2 \\in [3,5]\\}$$\ngenerate OOD inputs without labels. The target marginal $P_T^X$ is a mixture that draws $x$ i.i.d. by first choosing with probability $\\pi_o$ to sample uniformly from $R_o$ (OOD) and with probability $1-\\pi_o$ to sample uniformly from $R_0 \\cup R_1$ (in-support). If $x$ is drawn from $R_0$ then $y=0$, and if $x$ is drawn from $R_1$ then $y=1$.\n\nYou must implement an abstaining selective classifier for $T$ that detects OOD points and abstains on them while maintaining high precision on in-support target examples. The abstention mechanism should be based on a nonparametric estimate of the source marginal density $p_S^X$. Use a smooth isotropic Gaussian window function with bandwidth $h>0$ to construct a kernel density estimator (KDE) $\\hat{p}_S(x)$ from source samples. Define a detection threshold $\\tau>0$ and abstain on any $x$ with $\\hat{p}_S(x) < \\tau$. Predictions are only made on non-abstained points using the base classifier $g(x)$.\n\nStarting from core definitions of probability distributions, support, and i.i.d. sampling, implement the full pipeline:\n- Sample $n_S$ source points from $S$ and $n_T$ target points from $T$ according to the specified rectangles and mixture.\n- Estimate $\\hat{p}_S(x)$ using the isotropic Gaussian window with bandwidth $h$ and the source samples.\n- Apply the threshold-based abstention rule using $\\tau$ and classify with $g(x)$ when not abstaining.\n- Compute the following metrics for the target set:\n    1. In-support precision: among target points $x \\in \\operatorname{supp}(P_S^X)$ on which the method did not abstain, the fraction of correct predictions $\\in [0,1]$ expressed as a float. If the denominator is $0$, return $0$.\n    2. OOD abstention rate: among target points $x \\in R_o$, the fraction that were abstained $\\in [0,1]$ expressed as a float. If there are no OOD points, return $0$.\n    3. Meets criteria: a boolean indicating whether both the in-support precision is at least $0.95$ and the OOD abstention rate is at least $0.9$.\n\nYour program must be a complete, runnable implementation that uses the following test suite of parameter values, designed to test a happy path, a boundary condition with too-loose detection, and a boundary condition with too-strict detection:\n- Test case $1$: seed $0$, $n_S=400$, $n_T=300$, $h=0.3$, $\\tau=0.015$, $\\pi_o=0.3$.\n- Test case $2$: seed $1$, $n_S=400$, $n_T=300$, $h=0.3$, $\\tau=0.0$, $\\pi_o=0.3$.\n- Test case $3$: seed $2$, $n_S=400$, $n_T=300$, $h=0.3$, $\\tau=0.05$, $\\pi_o=0.3$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case is represented by a sub-list $[p,a,b]$ with no spaces, $p$ and $a$ rounded to $4$ decimal places, and $b$ being either $True$ or $False$. For example, the final output format should be like $[[0.9732,0.9458,True],[0.8123,0.1021,False],[0.0000,1.0000,False]]$. No physical units, angles, or percentage signs are involved in this problem; all numeric answers are dimensionless floats or booleans as specified.",
            "solution": "The user's request is to solve a problem in the domain of machine learning, specifically concerning domain adaptation and out-of-distribution (OOD) detection. A critical analysis of the problem statement is required before proceeding with a solution.\n\n### Step 1: Problem Validation\n\nFirst, I will extract the givens and validate the problem statement according to the specified criteria.\n\n#### Givens Extraction:\n- **Domains and Spaces**: A source domain $S$ and a target domain $T$. Input space is $\\mathbb{R}^2$, label space is $\\{0,1\\}$.\n- **Source Domain $S$**:\n    - Data $(x,y)$ are i.i.d.\n    - Input support is $\\operatorname{supp}(P_S^X) = R_0 \\cup R_1$, where:\n        - $R_0 = \\{x \\in \\mathbb{R}^2 : x_1 \\in [-3,-1],\\ x_2 \\in [-1,1]\\}$\n        - $R_1 = \\{x \\in \\mathbb{R}^2 : x_1 \\in [1,3],\\ x_2 \\in [-1,1]\\}$\n    - Marginal distribution $P_S^X$ is uniform over $R_0 \\cup R_1$.\n    - Labeling function: $y=0$ for $x \\in R_0$, and $y=1$ for $x \\in R_1$.\n- **Base Classifier**: $g(x) = \\mathbb{I}\\{x_1 > 0\\}$, where $\\mathbb{I}\\{\\cdot\\}$ is the indicator function.\n- **Target Domain $T$**:\n    - Introduces an OOD rectangle $R_o = \\{x \\in \\mathbb{R}^2 : x_1 \\in [-1,1],\\ x_2 \\in [3,5]\\}$.\n    - Target marginal $P_T^X$ is a mixture model: with probability $\\pi_o$, sample uniformly from $R_o$; with probability $1-\\pi_o$, sample uniformly from $R_0 \\cup R_1$.\n    - In-support labels are the same as in the source domain. OOD points from $R_o$ are unlabeled.\n- **Abstaining Selective Classifier**:\n    - Abstention is based on a Kernel Density Estimate (KDE) of the source marginal, $\\hat{p}_S(x)$.\n    - The KDE uses an isotropic Gaussian window function with bandwidth $h > 0$.\n    - The rule is to abstain on a point $x$ if $\\hat{p}_S(x) < \\tau$, where $\\tau > 0$ is a threshold.\n    - If not abstained, prediction is made using the base classifier $g(x)$.\n- **Tasks**:\n    1. Sample $n_S$ source points and $n_T$ target points.\n    2. Construct the KDE $\\hat{p}_S(x)$ from the source samples.\n    3. Apply the selective classifier to the target samples.\n    4. Compute three metrics for the target set:\n        - **In-support precision**: Fraction of correct predictions among non-abstained target points from $\\operatorname{supp}(P_S^X)$. Return $0.0$ if the denominator is zero.\n        - **OOD abstention rate**: Fraction of abstained points among target points from $R_o$. Return $0.0$ if no OOD points exist.\n        - **Meets criteria**: Boolean flag, `True` if in-support precision $\\ge 0.95$ and OOD abstention rate $\\ge 0.9$.\n- **Test Cases**:\n    - 1: `seed=0, n_S=400, n_T=300, h=0.3, tau=0.015, pi_o=0.3`\n    - 2: `seed=1, n_S=400, n_T=300, h=0.3, tau=0.0, pi_o=0.3`\n    - 3: `seed=2, n_S=400, n_T=300, h=0.3, tau=0.05, pi_o=0.3`\n- **Output Format**: A single line `[[p1,a1,b1],[p2,a2,b2],...]` with floats rounded to $4$ decimal places and no spaces in sub-lists.\n\n#### Validation Verdict:\nThe problem is **valid**.\n- It is **scientifically grounded** in standard statistical machine learning principles (KDE, mixture models, classification metrics).\n- It is **well-posed**, with all parameters, distributions, and objectives defined unambiguously. The provision of random seeds ensures reproducibility. Specific instructions for edge cases (e.g., zero denominators) are provided.\n- It is **objective**, using formal mathematical language entirely.\n- The setup is a canonical, albeit simplified, representation of an OOD detection problem, making it a relevant and non-trivial challenge that requires careful implementation. It is free of any of the invalidity flags.\n\n### Step 2: Solution Design and Implementation\n\nI will now proceed with a reasoned, step-by-step implementation.\n\n#### Principle-Based Design\nThe solution revolves around the core concept of density-based OOD detection. The principle is that data points from the source distribution's support should exhibit high density under a model of that distribution, while OOD points, being far from this support, should exhibit low density. A KDE is a classic non-parametric method to estimate a probability density function from a finite sample.\n\n1.  **Data Generation**: The first step is to simulate the data generation process for both source and target domains according to the specified uniform distributions over the defined rectangles.\n    - For the source data, $n_S$ points are drawn uniformly from $R_0 \\cup R_1$. Since the areas of $R_0$ ($2 \\times 2 = 4$) and $R_1$ ($2 \\times 2 = 4$) are equal, sampling uniformly from their union is equivalent to first choosing one of the rectangles with probability $0.5$ and then sampling uniformly from within it.\n    - For the target data, a mixture model is used. For each of the $n_T$ points, a Bernoulli trial with success probability $\\pi_o$ determines if the point is OOD (from $R_o$) or in-support (from $R_0 \\cup R_1$).\n\n2.  **Kernel Density Estimation**: The source marginal density $p_S^X(x)$ is estimated using the $n_S$ source points. The formula for a multivariate Gaussian KDE is:\n    $$ \\hat{p}_S(x) = \\frac{1}{n_S} \\sum_{i=1}^{n_S} K_h(x - x_{S,i}) $$\n    where $x_{S,i}$ are the source samples and $K_h$ is the scaled kernel function. For an isotropic Gaussian kernel in $d=2$ dimensions with bandwidth $h$, the function is:\n    $$ K_h(u) = \\frac{1}{2\\pi h^2} \\exp\\left(-\\frac{\\|u\\|^2}{2h^2}\\right) $$\n    This formula will be implemented to calculate the density estimate $\\hat{p}_S(x_T)$ for each target point $x_T$. Vectorized computation using `numpy` is crucial for efficiency, avoiding explicit loops over samples. The squared Euclidean distance matrix between all target and source points, $\\|x_T - x_{S,i}\\|^2$, can be calculated efficiently via broadcasting.\n\n3.  **Selective Classification and Evaluation**: With the density estimates for all target points, the selective classification is performed.\n    - For each target point $x_T$, if $\\hat{p}_S(x_T) < \\tau$, the classifier abstains.\n    - Otherwise, it predicts the label using the base classifier $g(x_T) = \\mathbb{I}\\{x_{T,1} > 0\\}$.\n    - An important observation is that the base classifier $g(x)$ is a perfect classifier for any in-support data point. For any $x \\in R_0$, its first coordinate $x_1 < 0$, so $g(x)=0$, which is the correct label. For any $x \\in R_1$, $x_1 > 0$, so $g(x)=1$, which is also correct. This simplifies the calculation of in-support precision: if a point is in-support and not abstained, its prediction is guaranteed to be correct. Therefore, the in-support precision will be $1.0$ unless all in-support points are abstained, in which case it is $0.0$ per instructions.\n\n4.  **Metric Calculation**: The metrics are computed based on the outcomes of the selective classification on the target set.\n    - **OOD abstention rate**: We identify all target points originating from $R_o$ and calculate the fraction on which the classifier abstained.\n    - **In-support precision**: We identify all target points originating from $R_0 \\cup R_1$ and then filter for those that were not abstained. The precision is the fraction of correct predictions on this subset, which, due to the perfect base classifier, is $1.0$ if the subset is non-empty, and $0.0$ otherwise.\n    - **Meets criteria**: A simple boolean check against the thresholds of $0.95$ for precision and $0.9$ for OOD abstention rate.\n\nThe process is repeated for each test case, with the random seed reset each time to ensure deterministic and reproducible results. The final output is formatted into the specified string format.",
            "answer": "```python\nimport numpy as np\n\n# This script implements a selective classifier for out-of-distribution detection.\n# It adheres to the Python 3.12 environment with numpy 1.23.5.\n# No other libraries like scipy are used, ensuring a first-principles implementation.\n\n# Define rectangle boundaries as constants for clarity and correctness.\nR0_X_RANGE = [-3.0, -1.0]\nR0_Y_RANGE = [-1.0, 1.0]\nR1_X_RANGE = [1.0, 3.0]\nR1_Y_RANGE = [-1.0, 1.0]\nRO_X_RANGE = [-1.0, 1.0]\nRO_Y_RANGE = [3.0, 5.0]\n\ndef sample_from_rectangle(n_samples: int, x_range: list, y_range: list) -> np.ndarray:\n    \"\"\"Samples n_samples uniformly from a given axis-aligned rectangle.\"\"\"\n    if n_samples == 0:\n        return np.empty((0, 2))\n    x1 = np.random.uniform(x_range[0], x_range[1], n_samples)\n    x2 = np.random.uniform(y_range[0], y_range[1], n_samples)\n    return np.stack((x1, x2), axis=1)\n\ndef generate_source_data(n_S: int) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Generates n_S source data points from the uniform distribution over R0 U R1.\n    Since Area(R0) = Area(R1), we sample from each with 0.5 probability.\n    \"\"\"\n    from_R0_mask = np.random.rand(n_S) < 0.5\n    n_R0 = np.sum(from_R0_mask)\n    n_R1 = n_S - n_R0\n\n    points_R0 = sample_from_rectangle(n_R0, R0_X_RANGE, R0_Y_RANGE)\n    labels_R0 = np.zeros(n_R0, dtype=int)\n\n    points_R1 = sample_from_rectangle(n_R1, R1_X_RANGE, R1_Y_RANGE)\n    labels_R1 = np.ones(n_R1, dtype=int)\n\n    source_points = np.concatenate((points_R0, points_R1), axis=0)\n    source_labels = np.concatenate((labels_R0, labels_R1), axis=0)\n\n    # Shuffle to ensure the returned data is i.i.d.\n    p = np.random.permutation(n_S)\n    return source_points[p], source_labels[p]\n\ndef generate_target_data(n_T: int, pi_o: float) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Generates n_T target data points from the specified mixture distribution.\"\"\"\n    is_ood_mask = np.random.rand(n_T) < pi_o\n    n_ood = np.sum(is_ood_mask)\n    n_insupport = n_T - n_ood\n\n    points_ood = sample_from_rectangle(n_ood, RO_X_RANGE, RO_Y_RANGE)\n    points_insupport, labels_insupport = generate_source_data(n_insupport)\n    \n    target_points = np.zeros((n_T, 2))\n    target_labels = np.full(n_T, -1, dtype=int)  # -1 for OOD points\n    \n    target_points[is_ood_mask] = points_ood\n    target_points[~is_ood_mask] = points_insupport\n    target_labels[~is_ood_mask] = labels_insupport\n\n    return target_points, target_labels, is_ood_mask\n\ndef kde_gauss(x_eval: np.ndarray, x_source: np.ndarray, h: float) -> np.ndarray:\n    \"\"\"\n    Computes Gaussian Kernel Density Estimates for evaluation points.\n    Formula for 2D: p_hat(x) = (1 / (n_S * 2*pi*h^2)) * sum_i exp(-||x-x_i||^2 / (2h^2))\n    \"\"\"\n    n_S = x_source.shape[0]\n    \n    # Efficiently compute squared Euclidean distances using broadcasting\n    # dist_sq[j, i] = ||x_eval_j - x_source_i||^2\n    dist_sq = np.sum(x_eval**2, axis=1)[:, np.newaxis] + np.sum(x_source**2, axis=1) - 2 * np.dot(x_eval, x_source.T)\n    \n    # Apply the exponential part of the Gaussian kernel\n    kernel_vals = np.exp(-dist_sq / (2 * h**2))\n    \n    # Final normalization and averaging over source points\n    norm_const = 1 / (2 * np.pi * h**2)\n    density_estimates = norm_const * np.mean(kernel_vals, axis=1)\n    \n    return density_estimates\n\ndef solve():\n    \"\"\"Main function to run test cases and print results.\"\"\"\n    test_cases = [\n        {'seed': 0, 'n_S': 400, 'n_T': 300, 'h': 0.3, 'tau': 0.015, 'pi_o': 0.3},\n        {'seed': 1, 'n_S': 400, 'n_T': 300, 'h': 0.3, 'tau': 0.0, 'pi_o': 0.3},\n        {'seed': 2, 'n_S': 400, 'n_T': 300, 'h': 0.3, 'tau': 0.05, 'pi_o': 0.3},\n    ]\n\n    results = []\n    for params in test_cases:\n        np.random.seed(params['seed'])\n        \n        # 1. Generate data\n        source_points, _ = generate_source_data(params['n_S'])\n        target_points, _, target_is_ood_mask = generate_target_data(\n            params['n_T'], params['pi_o']\n        )\n        \n        # 2. Estimate density for target points\n        density_estimates = kde_gauss(target_points, source_points, params['h'])\n\n        # 3. Apply abstention rule\n        abstained_mask = density_estimates < params['tau']\n\n        # 4. Compute metrics\n        \n        # OOD abstention rate\n        ood_indices = np.where(target_is_ood_mask)[0]\n        if len(ood_indices) == 0:\n            ood_abstention_rate = 0.0\n        else:\n            num_abstained_ood = np.sum(abstained_mask[ood_indices])\n            ood_abstention_rate = num_abstained_ood / len(ood_indices)\n            \n        # In-support precision\n        insupport_indices = np.where(~target_is_ood_mask)[0]\n        non_abstained_insupport_mask = ~abstained_mask[insupport_indices]\n        num_non_abstained_insupport = np.sum(non_abstained_insupport_mask)\n        \n        if num_non_abstained_insupport == 0:\n            insupport_precision = 0.0\n        else:\n            # The base classifier g(x) = I{x_1 > 0} is perfect for in-support data.\n            # Thus, any non-abstained in-support point is classified correctly.\n            insupport_precision = 1.0\n\n        # Meets criteria\n        meets_criteria = (insupport_precision >= 0.95) and (ood_abstention_rate >= 0.9)\n        \n        results.append([insupport_precision, ood_abstention_rate, meets_criteria])\n\n    # Format output string exactly as specified in the problem statement\n    result_strings = []\n    for p, a, b in results:\n        # Python's default str(bool) is 'True' or 'False' which is the required format.\n        result_strings.append(f\"[{p:.4f},{a:.4f},{b}]\")\n        \n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Rather than passively hoping a model generalizes, many state-of-the-art domain adaptation techniques actively work to minimize the discrepancy between source and target domains. This advanced exercise delves into two powerful frameworks for performing such feature-level alignment: Optimal Transport (OT) and Maximum Mean Discrepancy (MMD). You will implement alignment strategies based on OT, which seeks a minimal-cost \"transport plan\" to morph the source distribution into the target, and compare it to an MMD-based method that minimizes a statistical distance between the distributions' mean embeddings . This practice offers a deep, practical understanding of the algorithms that power modern domain adaptation.",
            "id": "3117509",
            "problem": "You are given a binary classification domain adaptation task framed in terms of feature alignment between a source domain and a target domain using Optimal Transport (OT) and Maximum Mean Discrepancy (MMD). Both domains are represented by finite samples with labels in the source domain and labels in the target domain for evaluation only. The feature extractor is the identity map, so the features are identical to the input vectors. The goal is to implement entropically regularized OT with uniform marginals, construct a barycentric alignment from the resulting transport plan, fine-tune a classifier on aligned source features, and compare its target-domain accuracy to a classifier fine-tuned using an MMD-based alignment under a linear kernel. The final output should aggregate accuracy improvements of OT over MMD across multiple test cases.\n\nFundamental base and definitions to use:\n- The task is set in the context of domain adaptation. A source domain provides labeled samples, while a target domain provides unlabeled samples for alignment and labeled samples for evaluation.\n- The identity feature extractor is denoted by $f_{\\theta}(x) = x$. The parameter vector $\\theta$ is not explicitly optimized in this task.\n- The Optimal Transport alignment solves the following entropically regularized transportation problem: given source features $\\{z_{i}^{S}\\}_{i=1}^{n_{S}}$, target features $\\{z_{j}^{T}\\}_{j=1}^{n_{T}}$, uniform marginals $a \\in \\mathbb{R}^{n_{S}}$ and $b \\in \\mathbb{R}^{n_{T}}$ with $a_{i} = \\frac{1}{n_{S}}$ and $b_{j} = \\frac{1}{n_{T}}$, and the cost matrix $C \\in \\mathbb{R}^{n_{S} \\times n_{T}}$ defined by $C_{ij} = \\lVert z_{i}^{S} - z_{j}^{T} \\rVert_{2}^{2}$, find a transport plan $\\pi \\in \\mathbb{R}^{n_{S} \\times n_{T}}$ that minimizes the regularized objective subject to marginal constraints:\n$$\n\\min_{\\pi} \\sum_{i=1}^{n_{S}} \\sum_{j=1}^{n_{T}} \\pi_{ij} \\lVert z_{i}^{S} - z_{j}^{T} \\rVert_{2}^{2} + \\varepsilon \\sum_{i=1}^{n_{S}} \\sum_{j=1}^{n_{T}} \\pi_{ij} \\log \\pi_{ij}\n$$\nsubject to $\\sum_{j=1}^{n_{T}} \\pi_{ij} = a_{i}$ and $\\sum_{i=1}^{n_{S}} \\pi_{ij} = b_{j}$. The entropic regularization parameter is $\\varepsilon > 0$.\n- Use the Sinkhorn-Knopp iterative scaling method (no explicit formulas are provided here; you must derive and implement the procedure) to solve the entropically regularized problem and obtain the transport plan $\\pi$ that satisfies the marginal constraints.\n- Construct a barycentric alignment of the source features with respect to the target features using the transport plan. Specifically, produce aligned source features $\\{z_{i}^{S,\\mathrm{OT}}\\}_{i=1}^{n_{S}}$ by forming the barycentric combinations of target features weighted by the transport plan and the source marginal.\n- Fine-tune a binary classifier on the aligned source features using the source labels. The classifier must be implemented as logistic regression trained via gradient descent on the cross-entropy loss.\n- Maximum Mean Discrepancy (MMD) is a discrepancy measure between distributions based on kernel mean embeddings. Use the linear kernel $k(x,y) = x^{\\top}y$. Under this kernel, derive and implement the alignment transformation on source features that minimizes the empirical MMD between aligned source features and target features. Fine-tune the same logistic regression classifier on the MMD-aligned source features using the source labels.\n- Evaluate both classifiers on the original target features using the true target labels. Compute the accuracy for the OT-aligned classifier and the MMD-aligned classifier. Report, for each test case, the accuracy improvement computed as the scalar $A_{\\mathrm{OT}} - A_{\\mathrm{MMD}}$, where $A_{\\mathrm{OT}}$ and $A_{\\mathrm{MMD}}$ are the target-domain accuracies achieved by the respective methods.\n\nData generation protocol (all angles are specified in radians):\n- Generate source data for two classes with equal sample sizes (binary labels). Let $d = 2$. The class-conditional source means are $\\mu_{0}^{S} = [-2, 0]$ and $\\mu_{1}^{S} = [2, 0]$. For source samples, draw independent Gaussian noise with zero mean and covariance $\\sigma_{S}^{2} I_{2}$, where $I_{2}$ is the $2 \\times 2$ identity matrix. The source labels are known.\n- Generate target data by applying a rotation and translation to the source class means to produce target class means. Let the rotation angle be $\\alpha$ and the translation vector be $t = [t_{x}, t_{y}]$. The target class means are $\\mu_{c}^{T} = R(\\alpha) \\mu_{c}^{S} + t$, for $c \\in \\{0,1\\}$, where $R(\\alpha)$ is the $2 \\times 2$ rotation matrix for angle $\\alpha$ in radians. Draw independent Gaussian noise with zero mean and covariance $\\sigma_{T}^{2} I_{2}$ around each target class mean. The target labels are used only for evaluation.\n\nImplementation requirements:\n- Use $f_{\\theta}(x) = x$.\n- Use uniform marginals $a_{i} = \\frac{1}{n_{S}}$ and $b_{j} = \\frac{1}{n_{T}}$.\n- Use the Sinkhorn-Knopp method to solve the entropically regularized OT problem for the given $\\varepsilon$.\n- Construct the barycentric alignment of the source features using the transport plan and the target features.\n- Train logistic regression via gradient descent with a fixed number of epochs and learning rate as specified in the test suite. Use cross-entropy loss and predict by thresholding the logistic function at $0.5$.\n- For the MMD-based alignment with a linear kernel, derive the alignment that minimizes empirical MMD between aligned source features and target features. Implement this alignment and then fine-tune logistic regression on the aligned source features.\n- Evaluate accuracies on the target domain and compute the accuracy improvement $A_{\\mathrm{OT}} - A_{\\mathrm{MMD}}$ for each case.\n\nTest suite:\n- All random sampling must use the specified seed for reproducibility. Use independent seeds per test case: seed $= 10 + \\text{case\\_index}$, where case index is $0,1,2,3$ for the four cases.\n- Provide four test cases with parameters $(n_{S}, n_{T}, \\sigma_{S}, \\sigma_{T}, \\alpha, t_{x}, t_{y}, \\varepsilon, \\text{epochs}, \\text{learning\\_rate})$:\n    1. Case $0$ (happy path): $(n_{S}, n_{T}) = (60, 60)$, $\\sigma_{S} = 0.4$, $\\sigma_{T} = 0.4$, $\\alpha = 0.5$, $t_{x} = 1.0$, $t_{y} = 0.5$, $\\varepsilon = 0.2$, epochs $= 200$, learning rate $= 0.1$.\n    2. Case $1$ (no shift boundary condition): $(n_{S}, n_{T}) = (60, 60)$, $\\sigma_{S} = 0.4$, $\\sigma_{T} = 0.4$, $\\alpha = 0.0$, $t_{x} = 0.0$, $t_{y} = 0.0$, $\\varepsilon = 0.2$, epochs $= 200$, learning rate $= 0.1$.\n    3. Case $2$ (hard shift): $(n_{S}, n_{T}) = (80, 80)$, $\\sigma_{S} = 0.4$, $\\sigma_{T} = 0.6$, $\\alpha = 1.0$, $t_{x} = 2.0$, $t_{y} = -1.0$, $\\varepsilon = 0.3$, epochs $= 250$, learning rate $= 0.08$.\n    4. Case $3$ (small sample size edge case): $(n_{S}, n_{T}) = (12, 12)$, $\\sigma_{S} = 0.5$, $\\sigma_{T} = 0.5$, $\\alpha = 0.8$, $t_{x} = 1.5$, $t_{y} = 1.5$, $\\varepsilon = 0.25$, epochs $= 300$, learning rate $= 0.12$.\n\nAnswer type and final output format:\n- For each test case, compute the float $A_{\\mathrm{OT}} - A_{\\mathrm{MMD}}$, where $A_{\\mathrm{OT}}$ and $A_{\\mathrm{MMD}}$ are target-domain accuracies expressed as fractions in $[0,1]$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each float formatted to four decimal places in the order of the test cases (for example, $[0.1234,0.0000,-0.0567,0.0321]$).",
            "solution": "The problem requires a comparative analysis of two domain adaptation techniques, one based on Optimal Transport (OT) and the other on Maximum Mean Discrepancy (MMD), for a binary classification task. The objective is to align a labeled source domain distribution with an unlabeled target domain distribution in a feature space, which, in this case, is the input space itself as the feature extractor is the identity map, $f_{\\theta}(x) = x$. We will implement both alignment methods, train a logistic regression classifier on the aligned source data, evaluate its performance on the target domain, and compute the accuracy improvement of the OT-based method over the MMD-based method.\n\nFirst, we define the data generation process. The source data consists of $n_S$ samples from two balanced classes in a $d=2$ dimensional space. The class-conditional distributions are Gaussian. The means are $\\mu_{0}^{S} = [-2, 0]^{\\top}$ and $\\mu_{1}^{S} = [2, 0]^{\\top}$. Samples are generated as $z_i^S \\sim \\mathcal{N}(\\mu_{y_i^S}^S, \\sigma_S^2 I_2)$, where $y_i^S \\in \\{0, 1\\}$ are the source labels and $I_2$ is the $2 \\times 2$ identity matrix. The target domain data consists of $n_T$ samples generated by applying a rotation and a translation to the source class means. The target class means are $\\mu_{c}^{T} = R(\\alpha) \\mu_{c}^{S} + t$ for $c \\in \\{0,1\\}$, where $R(\\alpha)$ is the rotation matrix for an angle $\\alpha$, and $t = [t_x, t_y]^\\top$ is a translation vector. Target samples are generated as $z_j^T \\sim \\mathcal{N}(\\mu_{y_j^T}^T, \\sigma_T^2 I_2)$, where $y_j^T$ are the target labels, used only for evaluation.\n\nThe core of the first alignment method is Entropically Regularized Optimal Transport. We aim to find a transport plan $\\pi \\in \\mathbb{R}^{n_S \\times n_T}$ that minimizes the regularized transport cost. The cost between a source feature $z_i^S$ and a target feature $z_j^T$ is the squared Euclidean distance, $C_{ij} = \\lVert z_i^S - z_j^T \\rVert_2^2$. The optimization problem is:\n$$\n\\min_{\\pi} \\sum_{i=1}^{n_{S}} \\sum_{j=1}^{n_{T}} \\pi_{ij} C_{ij} - \\varepsilon H(\\pi)\n$$\nwhere $H(\\pi) = -\\sum_{ij} \\pi_{ij} \\log \\pi_{ij}$ is the entropy of the plan, and $\\varepsilon > 0$ is the regularization strength. The minimization is subject to marginal constraints $\\pi \\mathbf{1}_{n_T} = a$ and $\\pi^\\top \\mathbf{1}_{n_S} = b$, where $\\mathbf{1}_k$ is a vector of ones of size $k$. The marginals are uniform, with $a_i = 1/n_S$ and $b_j = 1/n_T$.\n\nThis problem is solved efficiently using the Sinkhorn-Knopp algorithm. The solution $\\pi$ can be expressed as $\\pi = \\text{diag}(u) K \\text{diag}(v)$, where $K_{ij} = e^{-C_{ij}/\\varepsilon}$ and $u, v$ are scaling vectors. The algorithm iteratively updates $u$ and $v$ to satisfy the marginal constraints:\n$$\nu \\leftarrow a \\oslash (K v) \\quad \\text{and} \\quad v \\leftarrow b \\oslash (K^\\top u)\n$$\nwhere $\\oslash$ denotes element-wise division. Starting with an initial guess for $v$ (e.g., $v = \\mathbf{1}_{n_T}$), these updates are repeated until convergence.\n\nOnce the optimal transport plan $\\pi$ is found, we perform a barycentric alignment of the source features. The aligned source feature $z_i^{S,\\mathrm{OT}}$ is the expectation of the target features to which $z_i^S$ is mapped, weighted by the conditional transport probabilities. The conditional probability that $z_i^S$ maps to $z_j^T$ is $p(j|i) = \\pi_{ij} / a_i = n_S \\pi_{ij}$. Thus, the aligned feature is:\n$$\nz_i^{S,\\mathrm{OT}} = \\sum_{j=1}^{n_T} p(j|i) z_j^T = n_S \\sum_{j=1}^{n_T} \\pi_{ij} z_j^T\n$$\nIn matrix notation, this is $Z_{S,\\mathrm{OT}} = (n_S \\pi) Z_T$, where $Z_T$ is the matrix of target features.\n\nThe second alignment method is based on minimizing the Maximum Mean Discrepancy (MMD) with a linear kernel $k(x,y) = x^\\top y$. The squared empirical MMD between a set of transformed source features $\\{\\mathcal{T}(z_i^S)\\}_{i=1}^{n_S}$ and target features $\\{z_j^T\\}_{j=1}^{n_T}$ is:\n$$\n\\text{MMD}^2 = \\left\\lVert \\frac{1}{n_S} \\sum_{i=1}^{n_S} \\phi(\\mathcal{T}(z_i^S)) - \\frac{1}{n_T} \\sum_{j=1}^{n_T} \\phi(z_j^T) \\right\\rVert_{\\mathcal{H}}^2\n$$\nFor the linear kernel, the feature map $\\phi$ is the identity, $\\phi(x) = x$. We choose a simple alignment transformation class: a global translation, $\\mathcal{T}(z) = z + v$. The objective is to find the vector $v$ that minimizes:\n$$\n\\min_v \\left\\lVert \\frac{1}{n_S} \\sum_{i=1}^{n_S} (z_i^S + v) - \\frac{1}{n_T} \\sum_{j=1}^{n_T} z_j^T \\right\\rVert_2^2 = \\min_v \\left\\lVert (\\bar{z}^S + v) - \\bar{z}^T \\right\\rVert_2^2\n$$\nwhere $\\bar{z}^S$ and $\\bar{z}^T$ are the empirical means of the source and target features, respectively. This expression is minimized when $v = \\bar{z}^T - \\bar{z}^S$. The MMD-based alignment is therefore a mean-matching transformation:\n$$\nz_i^{S,\\mathrm{MMD}} = z_i^S + (\\bar{z}^T - \\bar{z}^S)\n$$\nThis aligns the centroid of the source distribution with the centroid of the target distribution.\n\nAfter aligning the source features using both OT ($Z_{S,\\mathrm{OT}}$) and MMD ($Z_{S,\\mathrm{MMD}}$), we train two separate binary logistic regression classifiers. The model predicts the probability of class $1$ as $\\hat{y} = \\sigma(z^\\top w + b)$, where $\\sigma(s) = 1/(1+e^{-s})$ is the sigmoid function, $w \\in \\mathbb{R}^2$ are the weights, and $b \\in \\mathbb{R}$ is the bias. The classifiers are trained by minimizing the binary cross-entropy loss function using gradient descent for a fixed number of epochs and a given learning rate. The gradient of the loss $L$ for a dataset of size $N$ with features $X$ and labels $Y$ is:\n$$\n\\nabla_w L = \\frac{1}{N} X^\\top (\\hat{Y} - Y), \\quad \\nabla_b L = \\frac{1}{N} \\sum_{i=1}^N (\\hat{y}_i - y_i)\n$$\nThe weights and bias are updated as $w \\leftarrow w - \\eta \\nabla_w L$ and $b \\leftarrow b - \\eta \\nabla_b L$, where $\\eta$ is the learning rate.\n\nFinally, we evaluate the performance of both classifiers. The classifier trained on $Z_{S,\\mathrm{OT}}$ and the classifier trained on $Z_{S,\\mathrm{MMD}}$ are both tested on the original, unaligned target features $Z_T$ with their true labels $Y_T$. A prediction is classified as $1$ if the output probability is greater than $0.5$, and $0$ otherwise. The accuracy is the fraction of correctly classified target samples. The final result for each test case is the difference in accuracies: $A_{\\mathrm{OT}} - A_{\\mathrm{MMD}}$.",
            "answer": "```python\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef generate_data(n_s, n_t, sigma_s, sigma_t, alpha, t_x, t_y, seed):\n    \"\"\"Generates source and target domain data.\"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # Source domain data\n    mu_s0 = np.array([-2.0, 0.0])\n    mu_s1 = np.array([2.0, 0.0])\n    \n    n_s_half = n_s // 2\n    z_s0 = rng.multivariate_normal(mu_s0, sigma_s**2 * np.eye(2), size=n_s_half)\n    z_s1 = rng.multivariate_normal(mu_s1, sigma_s**2 * np.eye(2), size=n_s - n_s_half)\n    \n    Z_s = np.vstack((z_s0, z_s1))\n    Y_s = np.hstack((np.zeros(n_s_half), np.ones(n_s - n_s_half)))\n\n    # Target domain data\n    R = np.array([[np.cos(alpha), -np.sin(alpha)], [np.sin(alpha), np.cos(alpha)]])\n    t = np.array([t_x, t_y])\n    \n    mu_t0 = R @ mu_s0 + t\n    mu_t1 = R @ mu_s1 + t\n    \n    n_t_half = n_t // 2\n    z_t0 = rng.multivariate_normal(mu_t0, sigma_t**2 * np.eye(2), size=n_t_half)\n    z_t1 = rng.multivariate_normal(mu_t1, sigma_t**2 * np.eye(2), size=n_t - n_t_half)\n    \n    Z_t = np.vstack((z_t0, z_t1))\n    Y_t = np.hstack((np.zeros(n_t_half), np.ones(n_t - n_t_half)))\n    \n    return Z_s, Y_s, Z_t, Y_t\n\ndef sinkhorn_knopp(C, epsilon, n_s, n_t, num_iter=100):\n    \"\"\"Solves entropically regularized OT using Sinkhorn-Knopp.\"\"\"\n    a = np.full(n_s, 1.0 / n_s)\n    b = np.full(n_t, 1.0 / n_t)\n    \n    K = np.exp(-C / epsilon)\n    v = np.ones(n_t)\n    \n    for _ in range(num_iter):\n        u = a / (K @ v)\n        v = b / (K.T @ u)\n        \n    pi = np.diag(u) @ K @ np.diag(v)\n    return pi\n\ndef ot_align(Z_s, Z_t, epsilon):\n    \"\"\"Aligns source features to target features using Optimal Transport.\"\"\"\n    n_s = Z_s.shape[0]\n    n_t = Z_t.shape[0]\n    \n    C = cdist(Z_s, Z_t, 'sqeuclidean')\n    pi = sinkhorn_knopp(C, epsilon, n_s, n_t)\n    \n    Z_s_ot = (n_s * pi) @ Z_t\n    return Z_s_ot\n\ndef mmd_align(Z_s, Z_t):\n    \"\"\"Aligns source features to target features by matching means (linear MMD).\"\"\"\n    mean_s = np.mean(Z_s, axis=0)\n    mean_t = np.mean(Z_t, axis=0)\n    \n    translation = mean_t - mean_s\n    Z_s_mmd = Z_s + translation\n    return Z_s_mmd\n\ndef train_logistic_regression(X, y, epochs, lr):\n    \"\"\"Trains a logistic regression classifier using gradient descent.\"\"\"\n    n_samples, n_features = X.shape\n    w = np.zeros(n_features)\n    b = 0.0\n    \n    y = y.reshape(-1, 1)\n\n    for _ in range(epochs):\n        linear_model = (X @ w + b).reshape(-1, 1)\n        y_pred = 1 / (1 + np.exp(-linear_model))\n        \n        dw = (1 / n_samples) * (X.T @ (y_pred - y))\n        db = (1 / n_samples) * np.sum(y_pred - y)\n        \n        w -= lr * dw.flatten()\n        b -= lr * db\n\n    return w, b\n\ndef predict_and_evaluate(X, y, w, b):\n    \"\"\"Makes predictions and computes accuracy.\"\"\"\n    linear_model = (X @ w + b).reshape(-1, 1)\n    y_pred_prob = 1 / (1 + np.exp(-linear_model))\n    y_pred_class = (y_pred_prob > 0.5).astype(int)\n    \n    accuracy = np.mean(y_pred_class.flatten() == y.flatten())\n    return accuracy\n\ndef solve():\n    test_cases = [\n        (60, 60, 0.4, 0.4, 0.5, 1.0, 0.5, 0.2, 200, 0.1),\n        (60, 60, 0.4, 0.4, 0.0, 0.0, 0.0, 0.2, 200, 0.1),\n        (80, 80, 0.4, 0.6, 1.0, 2.0, -1.0, 0.3, 250, 0.08),\n        (12, 12, 0.5, 0.5, 0.8, 1.5, 1.5, 0.25, 300, 0.12),\n    ]\n\n    results = []\n    for i, params in enumerate(test_cases):\n        n_s, n_t, sigma_s, sigma_t, alpha, t_x, t_y, epsilon, epochs, lr = params\n        seed = 10 + i\n        \n        Z_s, Y_s, Z_t, Y_t = generate_data(n_s, n_t, sigma_s, sigma_t, alpha, t_x, t_y, seed)\n        \n        # OT path\n        Z_s_ot = ot_align(Z_s, Z_t, epsilon)\n        w_ot, b_ot = train_logistic_regression(Z_s_ot, Y_s, epochs, lr)\n        acc_ot = predict_and_evaluate(Z_t, Y_t, w_ot, b_ot)\n        \n        # MMD path\n        Z_s_mmd = mmd_align(Z_s, Z_t)\n        w_mmd, b_mmd = train_logistic_regression(Z_s_mmd, Y_s, epochs, lr)\n        acc_mmd = predict_and_evaluate(Z_t, Y_t, w_mmd, b_mmd)\n        \n        accuracy_improvement = acc_ot - acc_mmd\n        results.append(accuracy_improvement)\n\n    print(f\"[{','.join(f'{r:.4f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}