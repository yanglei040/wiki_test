{
    "hands_on_practices": [
        {
            "introduction": "我们可以从动力系统的视角来理解残差网络的核心创新。一个非常深的网络可以看作是信号随“时间”（即网络深度）演变的一系列变换。本练习将残差块简化为线性变换，以便从解析上研究其稳定性，揭示跳跃连接如何防止困扰早期深度网络的“信号爆炸”问题。通过推导稳定性条件，您将对为何残差网络可以构建得如此之深获得根本性的理解。",
            "id": "3169711",
            "problem": "考虑深度神经网络中使用的带有跳跃连接的残差块，其层更新由 $x_{l+1} = x_{l} + h F(x_{l})$ 给出，其中步长 $h > 0$，层索引 $l \\in \\mathbb{N}$。假设残差函数是线性的，$F(x) = A x$，其中 $A \\in \\mathbb{C}^{n \\times n}$ 是一个正规矩阵（即 $A^{*}A = AA^{*}$），因此 $A$ 是酉可对角化的。用 $\\|\\cdot\\|_{2}$ 表示 $\\mathbb{C}^{n}$ 上的欧几里得范数以及矩阵上的相关诱导算子范数。为了防止在重复应用残差块时出现范数爆炸，我们要求单步映射 $B(h) \\equiv I + h A$ 在欧几里得范数下是非扩张的，即 $\\|B(h)\\|_{2} \\leq 1$。\n\n仅从正规矩阵的谱定理、诱导算子范数的定义以及矩阵多项式的特征值是该多项式在矩阵特征值处的取值这一性质出发，推导出一个关于 $h$ 和 $A$ 的特征值 $\\{\\lambda_{i}\\}_{i=1}^{n}$ 的条件，以保证 $\\|I + h A\\|_{2} \\leq 1$。将此条件表示为复平面中 $h \\lambda$ 的一个稳定域，写成一个包含 $\\operatorname{Re}(\\lambda)$ 和 $|\\lambda|$ 的显式不等式。\n\n然后，考虑一个具体的正规矩阵 $A$，其谱为 $\\{-2,\\,-0.5 + i,\\,-0.5 - i,\\,-0.2\\}$。确定上确界步长 $h^{\\star} > 0$，使得对于所有 $0 \\leq h \\leq h^{\\star}$，$\\|I + h A\\|_{2} \\leq 1$ 都成立。将最终答案表示为一个实数。不需要四舍五入。",
            "solution": "问题要求分两部分：首先，为一个带有线性残差函数的残差块推导稳定性条件；其次，将此条件应用于一个具体案例，以找到最大允许步长。\n\n第一部分：稳定性条件的推导\n\n我们已知层更新规则 $x_{l+1} = (I + hA)x_l$，其中 $A$ 是一个正规矩阵。防止范数爆炸的条件是映射 $B(h) = I + hA$ 是非扩张的，即 $\\|I + hA\\|_2 \\leq 1$。\n\n我们首先确定矩阵 $B(h) = I + hA$ 的2-范数。\n问题陈述 $A \\in \\mathbb{C}^{n \\times n}$ 是一个正规矩阵，意味着 $A^*A = AA^*$。对于任何实数步长 $h$，矩阵 $B(h)$ 也是正规的，因为：\n$$ (I + hA)^*(I + hA) = (I^* + \\overline{h}A^*)(I + hA) = (I + hA^*)(I + hA) = I + hA + hA^* + h^2 A^*A $$\n$$ (I + hA)(I + hA)^* = (I + hA)(I^* + \\overline{h}A^*) = (I + hA)(I + hA^*) = I + hA^* + hA + h^2 AA^* $$\n由于 $A^*A = AA^*$，我们有 $(I + hA)^*(I + hA) =\n (I + hA)(I + hA)^*$，所以 $I + hA$ 是正规的。\n\n根据谱定理，一个正规矩阵是酉可对角化的。由此得出的一个关键性质是，正规矩阵的诱导2-范数等于其谱半径（其特征值的最大绝对值）。\n设 $\\{\\lambda_i\\}_{i=1}^n$ 是 $A$ 的特征值。问题陈述，矩阵多项式的特征值是该多项式在矩阵特征值处的取值。矩阵 $B(h) = I + hA$ 可以看作是在 $A$ 处对多项式 $p(z) = 1 + hz$ 求值。因此，$B(h)$ 的特征值是 $\\{1 + h\\lambda_i\\}_{i=1}^n$。\n\n于是 $B(h)$ 的2-范数为：\n$$ \\|I + hA\\|_2 = \\rho(I + hA) = \\max_{i \\in \\{1, \\dots, n\\}} |1 + h\\lambda_i| $$\n因此，非扩张条件 $\\|I + hA\\|_2 \\leq 1$ 要求对于 $A$ 的每个特征值 $\\lambda_i$，以下不等式成立：\n$$ |1 + h\\lambda_i| \\leq 1 $$\n这是基本条件。让我们进一步分析它。令 $z_i = h\\lambda_i$，条件是对于每个 $i$，复数 $z_i$ 必须位于由 $|1+z| \\leq 1$ 定义的稳定域内。几何上，这是一个在复平面中以 $(-1, 0)$ 为中心、半径为 1 的闭圆盘。\n\n为了推导包含 $\\operatorname{Re}(\\lambda)$ 和 $|\\lambda|$ 的显式不等式，我们将 $|1 + h\\lambda| \\leq 1$ 两边平方：\n$$ |1 + h\\lambda|^2 \\leq 1^2 $$\n设 $\\lambda = \\operatorname{Re}(\\lambda) + i\\operatorname{Im}(\\lambda)$。项 $h\\lambda = h\\operatorname{Re}(\\lambda) + ih\\operatorname{Im}(\\lambda)$。\n模的平方是：\n$$ (1 + h\\operatorname{Re}(\\lambda))^2 + (h\\operatorname{Im}(\\lambda))^2 \\leq 1 $$\n展开左侧得到：\n$$ 1 + 2h\\operatorname{Re}(\\lambda) + h^2(\\operatorname{Re}(\\lambda))^2 + h^2(\\operatorname{Im}(\\lambda))^2 \\leq 1 $$\n合并含有 $h^2$ 的项：\n$$ 1 + 2h\\operatorname{Re}(\\lambda) + h^2((\\operatorname{Re}(\\lambda))^2 + (\\operatorname{Im}(\\lambda))^2) \\leq 1 $$\n认识到 $(\\operatorname{Re}(\\lambda))^2 + (\\operatorname{Im}(\\lambda))^2 = |\\lambda|^2$，我们有：\n$$ 1 + 2h\\operatorname{Re}(\\lambda) + h^2|\\lambda|^2 \\leq 1 $$\n两边减 1 得：\n$$ 2h\\operatorname{Re}(\\lambda) + h^2|\\lambda|^2 \\leq 0 $$\n由于步长 $h$ 给定为正 ($h > 0$)，我们可以用 $h$ 除以不等式而不改变其方向：\n$$ 2\\operatorname{Re}(\\lambda) + h|\\lambda|^2 \\leq 0 $$\n这就是 $h$ 和矩阵 $A$ 的每个特征值 $\\lambda$ 必须满足的条件。\n\n第二部分：上确界步长 $h^{\\star}$ 的计算\n\n我们给定一个矩阵 $A$，其谱（特征值集合）为 $\\{-2, -0.5 + i, -0.5 - i, -0.2\\}$。我们必须找到上确界 $h^{\\star} > 0$，使得对于所有 $h \\in [0, h^{\\star}]$ 以及谱中的所有特征值 $\\lambda$，条件 $2\\operatorname{Re}(\\lambda) + h|\\lambda|^2 \\leq 0$ 都得到满足。\n\n对于一个非零特征值 $\\lambda$，我们可以重排不等式以找到 $h$ 的一个上界：\n$$ h|\\lambda|^2 \\leq -2\\operatorname{Re}(\\lambda) $$\n要存在一个正解 $h > 0$，我们必须有 $-2\\operatorname{Re}(\\lambda) > 0$，这意味着 $\\operatorname{Re}(\\lambda)  0$。我们对所有给定的特征值进行检查：\n\\begin{itemize}\n    \\item $\\operatorname{Re}(-2) = -2  0$\n    \\item $\\operatorname{Re}(-0.5+i) = -0.5  0$\n    \\item $\\operatorname{Re}(-0.5-i) = -0.5  0$\n    \\item $\\operatorname{Re}(-0.2) = -0.2  0$\n\\end{itemize}\n由于所有特征值都有负实部，一个正的步长 $h$ 是可能的。\n如果 $|\\lambda|^2 \\neq 0$，$h$ 的不等式为：\n$$ h \\leq \\frac{-2\\operatorname{Re}(\\lambda)}{|\\lambda|^2} $$\n这个不等式必须对每个特征值都成立。因此，$h$ 必须小于或等于所有特征值对应的这些上界中的最小值。上确界 $h^{\\star}$ 就是这个最小值。\n$$ h^{\\star} = \\min_{\\lambda \\in \\text{spectrum}} \\left( \\frac{-2\\operatorname{Re}(\\lambda)}{|\\lambda|^2} \\right) $$\n让我们为每个特征值计算这个值：\n\n1.  对于 $\\lambda_1 = -2$：\n    $\\operatorname{Re}(\\lambda_1) = -2$ 且 $|\\lambda_1|^2 = (-2)^2 = 4$。\n    $h$ 的界限是 $h \\leq \\frac{-2(-2)}{4} = \\frac{4}{4} = 1$。\n\n2.  对于 $\\lambda_2 = -0.5 + i$：\n    $\\operatorname{Re}(\\lambda_2) = -0.5$ 且 $|\\lambda_2|^2 = (-0.5)^2 + 1^2 = 0.25 + 1 = 1.25$。\n    $h$ 的界限是 $h \\leq \\frac{-2(-0.5)}{1.25} = \\frac{1}{1.25} = \\frac{1}{5/4} = \\frac{4}{5} = 0.8$。\n\n3.  对于 $\\lambda_3 = -0.5 - i$：\n    $\\operatorname{Re}(\\lambda_3) = -0.5$ 且 $|\\lambda_3|^2 = (-0.5)^2 + (-1)^2 = 0.25 + 1 = 1.25$。\n    $h$ 的界限是 $h \\leq \\frac{-2(-0.5)}{1.25} = \\frac{1}{1.25} = 0.8$。\n\n4.  对于 $\\lambda_4 = -0.2$：\n    $\\operatorname{Re}(\\lambda_4) = -0.2$ 且 $|\\lambda_4|^2 = (-0.2)^2 = 0.04$。\n    $h$ 的界限是 $h \\leq \\frac{-2(-0.2)}{0.04} = \\frac{0.4}{0.04} = 10$。\n\n$h$ 的上界集合是 $\\{1, 0.8, 0.8, 10\\}$。为了同时满足所有特征值的条件，$h$ 必须小于或等于这些界的最小值。\n$$ h^{\\star} = \\min\\{1, 0.8, 10\\} = 0.8 $$\n因此，使得系统对于所有 $h \\in [0, h^{\\star}]$ 保持非扩张的上确界步长是 $0.8$。",
            "answer": "$$\\boxed{0.8}$$"
        },
        {
            "introduction": "在实际的网络中，残差块并非独立存在；它们需要与批量归一化（Batch Normalization, BN）等其他组件协同工作。本练习模拟了一个常见问题：恒等路径与残差路径的统计分布不匹配，这可能会干扰信息的顺畅流动。您将为跳跃连接推导一个仿射对齐变换，以标准化模块的输出，亲身体验如何通过精细的工程设计，让不同的深度学习组件高效地协同工作。",
            "id": "3169660",
            "problem": "考虑一个深度神经网络中的预激活残差块的单个通道。该块将一个恒等跳跃连接路径添加到一个残差路径上。残差路径包括带有可学习仿射参数的批归一化 (BN) 和一个逐点非线性。对于给定的一个小批量和通道，假设以下每个样本的统计量都得到了精确估计：\n- 恒等路径上的输入是一个随机变量 $x$，其均值为 $\\mu_{x}$，方差为 $\\sigma_{x}^{2}$。\n- 残差路径的输出（经过批归一化及其学习到的仿射变换和非线性之后），记为 $r$，其均值为 $\\mu_{r}$，方差为 $\\sigma_{r}^{2}$。\n\n为进行此分析，假设 $x$ 和 $r$ 是相互独立的。如果不对跳跃连接应用对齐，则块输出为 $y = x + r$。由于 $x$ 和 $r$ 可能有不同的均值和方差，其和 $y$ 可能会相对于通常为了稳定训练而偏好的归一化状态，经历均值和方差的漂移。\n\n为了减少这种不匹配，假设我们在恒等跳跃连接路径上插入一个仿射对齐 $s = a x + b$，其中 $a \\in \\mathbb{R}$ 且 $b \\in \\mathbb{R}$，并形成输出 $y' = r + s$。你的任务是：\n- 仅使用期望的线性性质和独立随机变量和的方差性质，推导出 $\\mathbb{E}[y']$ 和 $\\operatorname{Var}(y')$，用 $a$、$b$、$\\mu_{x}$、$\\sigma_{x}^{2}$、$\\mu_{r}$ 和 $\\sigma_{r}^{2}$ 表示。\n- 施加对齐目标，使求和后的输出满足 $\\mathbb{E}[y'] = 0$ 和 $\\operatorname{Var}(y') = 1$。\n- 在约束条件 $a \\ge 0$（以保持恒等映射的方向）下，针对以下统计数据，求解满足对齐目标的唯一 $(a,b)$：\n  $\\mu_{x} = 1.5$，$\\sigma_{x}^{2} = 1.0$，$\\mu_{r} = 0.25$，$\\sigma_{r}^{2} = 0.75$。\n- 将 $a$ 和 $b$ 都四舍五入到四位有效数字，并将这对数值以行向量的形式报告。\n\n将你的最终答案以单行矩阵 $\\begin{pmatrix} a  b \\end{pmatrix}$ 的形式给出，不要包含单位。",
            "solution": "该问题要求推导残差块中跳跃连接的仿射对齐参数 $a$ 和 $b$，使得该块的输出均值为 $0$，方差为 $1$。\n\n首先，我们验证问题陈述的有效性。\n**第 1 步：提取给定条件**\n- 块输出为 $y' = r + s$，其中 $s = ax + b$。\n- 恒等路径上的输入是一个随机变量 $x$，其均值为 $\\mathbb{E}[x] = \\mu_{x}$，方差为 $\\operatorname{Var}(x) = \\sigma_{x}^{2}$。\n- 残差路径的输出是一个随机变量 $r$，其均值为 $\\mathbb{E}[r] = \\mu_{r}$，方差为 $\\operatorname{Var}(r) = \\sigma_{r}^{2}$。\n- 假设 $x$ 和 $r$ 相互独立。\n- 对齐目标是 $\\mathbb{E}[y'] = 0$ 且 $\\operatorname{Var}(y') = 1$。\n- 施加了约束条件：$a \\ge 0$。\n- 具体的统计数值为：$\\mu_{x} = 1.5$，$\\sigma_{x}^{2} = 1.0$，$\\mu_{r} = 0.25$，$\\sigma_{r}^{2} = 0.75$。\n\n**第 2 步：使用提取的给定条件进行验证**\n该问题具有科学依据，它使用概率论的标准原理对深度学习中的一个常见场景进行建模。这是一个适定的问题，因为它提供了一套完整且一致的条件来确定参数 $a$ 和 $b$ 的唯一解。所提供的量在量纲上是一致的且是合理的。该问题不违反任何无效性标准。\n\n**第 3 步：结论与行动**\n该问题是有效的。我们继续进行求解。\n\n块的输出由残差路径输出 $r$ 和对齐后的跳跃连接输出 $s = ax + b$ 的和给出。\n$$y' = r + s = r + (ax + b)$$\n我们必须首先推导输出的均值 $\\mathbb{E}[y']$ 和方差 $\\operatorname{Var}(y')$ 的表达式。\n\n**均值 $\\mathbb{E}[y']$ 的推导**\n根据期望算子的线性性质，我们有：\n$$\\mathbb{E}[y'] = \\mathbb{E}[r + ax + b]$$\n$$\\mathbb{E}[y'] = \\mathbb{E}[r] + \\mathbb{E}[ax] + \\mathbb{E}[b]$$\n由于 $a$ 和 $b$ 是常数，$\\mathbb{E}[ax] = a\\mathbb{E}[x]$ 且 $\\mathbb{E}[b] = b$。\n$$\\mathbb{E}[y'] = \\mathbb{E}[r] + a\\mathbb{E}[x] + b$$\n代入给定的符号均值：\n$$\\mathbb{E}[y'] = \\mu_{r} + a\\mu_{x} + b$$\n\n**方差 $\\operatorname{Var}(y')$ 的推导**\n$y'$ 的方差由下式给出：\n$$\\operatorname{Var}(y') = \\operatorname{Var}(r + ax + b)$$\n加上一个常数 $b$ 不会改变方差，所以 $\\operatorname{Var}(r + ax + b) = \\operatorname{Var}(r + ax)$。\n$$\\operatorname{Var}(y') = \\operatorname{Var}(r + ax)$$\n问题陈述中说明随机变量 $x$ 和 $r$ 是相互独立的。因此，$ax$ 和 $r$ 也是相互独立的。对于相互独立的随机变量，其和的方差等于方差的和：\n$$\\operatorname{Var}(y') = \\operatorname{Var}(r) + \\operatorname{Var}(ax)$$\n使用性质 $\\operatorname{Var}(cX) = c^2\\operatorname{Var}(X)$，其中 $c$ 是一个常数，我们得到 $\\operatorname{Var}(ax) = a^2\\operatorname{Var}(x)$。\n$$\\operatorname{Var}(y') = \\operatorname{Var}(r) + a^2\\operatorname{Var}(x)$$\n代入给定的符号方差：\n$$\\operatorname{Var}(y') = \\sigma_{r}^{2} + a^2\\sigma_{x}^{2}$$\n\n**求解 $a$ 和 $b$**\n现在我们应用对齐目标：$\\mathbb{E}[y'] = 0$ 和 $\\operatorname{Var}(y') = 1$。这产生了一个包含两个方程的方程组：\n$$(1) \\quad \\mu_{r} + a\\mu_{x} + b = 0$$\n$$(2) \\quad \\sigma_{r}^{2} + a^2\\sigma_{x}^{2} = 1$$\n\n我们从方程 $(2)$ 中求解 $a$：\n$$a^2\\sigma_{x}^{2} = 1 - \\sigma_{r}^{2}$$\n$$a^2 = \\frac{1 - \\sigma_{r}^{2}}{\\sigma_{x}^{2}}$$\n$$a = \\pm \\sqrt{\\frac{1 - \\sigma_{r}^{2}}{\\sigma_{x}^{2}}}$$\n问题包含了约束条件 $a \\ge 0$，这是一个常见的选择，用以保持恒等映射的方向。因此，我们取正根：\n$$a = \\sqrt{\\frac{1 - \\sigma_{r}^{2}}{\\sigma_{x}^{2}}}$$\n\n接着，我们从方程 $(1)$ 中求解 $b$：\n$$b = -(\\mu_{r} + a\\mu_{x})$$\n\n现在我们代入给定的数值：$\\mu_{x} = 1.5$，$\\sigma_{x}^{2} = 1.0$，$\\mu_{r} = 0.25$ 和 $\\sigma_{r}^{2} = 0.75$。\n首先，我们计算 $a$：\n$$a = \\sqrt{\\frac{1 - 0.75}{1.0}} = \\sqrt{\\frac{0.25}{1.0}} = \\sqrt{0.25} = 0.5$$\n值 $a = 0.5$ 满足条件 $a \\ge 0$。\n\n接下来，我们使用已确定的 $a$ 值来计算 $b$：\n$$b = -(0.25 + (0.5)(1.5))$$\n$$b = -(0.25 + 0.75)$$\n$$b = -1.0$$\n\n问题要求将 $a$ 和 $b$ 都四舍五入到四位有效数字。\n- 对于 $a = 0.5$，四位有效数字为 $0.5000$。\n- 对于 $b = -1.0$，四位有效数字为 $-1.000$。\n\n解是数对 $(a, b) = (0.5000, -1.000)$，我们将其以行向量的形式报告。",
            "answer": "$$\\boxed{\\begin{pmatrix} 0.5000  -1.000 \\end{pmatrix}}$$"
        }
    ]
}