{
    "hands_on_practices": [
        {
            "introduction": "One of the fundamental breakthroughs of ResNet was to reframe the optimization problem, making it easier to train very deep networks. Instead of learning a complex underlying mapping, residual blocks are optimized to learn a correction, or residual, to an identity mapping. This exercise  delves into the theoretical underpinnings of this idea by analyzing the training dynamics of a simplified linear ResNet, allowing you to derive how an identity-like initialization leads to more stable and faster initial learning.",
            "id": "3169939",
            "problem": "Consider a one-dimensional Residual Network (ResNet) defined as follows. A Residual Network (ResNet) with $L$ residual blocks applies the transformation $x \\mapsto x + W_{l} x$ at block $l$, so in one dimension each block parameter is a scalar $w_{l} \\in \\mathbb{R}$ and the full network applies $x \\mapsto \\left(\\prod_{l=1}^{L} (1 + w_{l})\\right) x$. Suppose we tie the block parameters so that $w_{l} = w$ for all $l \\in \\{1, \\dots, L\\}$, giving a network output $y = (1 + w)^{L} x$. Let the target mapping be $y^{\\star} = a x$ for a fixed scalar $a > 0$, and assume the input $x$ is a zero-mean random variable with variance $\\mathbb{E}[x^{2}] = 1$. Consider the quadratic loss $\\mathcal{L}(w) = \\frac{1}{2} \\mathbb{E}\\!\\left[\\left(y - y^{\\star}\\right)^{2}\\right]$. Training is performed by gradient descent with a constant step size $\\eta > 0$.\n\nStarting from the fundamental definition of gradient descent and the chain rule, derive a local linearized expression for the one-step contraction factor $r(w)$ of the scalar error $e(w) = (1 + w)^{L} - a$ under a single gradient descent step at a current parameter $w$, defined by the approximation $e^{+} \\approx r(w)\\, e$, where $e^{+}$ is the error after one update and $e$ is the error before the update. Then, compare identity initialization $w = 0$ to a small random initialization $w = \\delta$ with $|\\delta| \\ll 1$ by deriving the closed-form expression for the ratio $R = \\frac{r(\\delta)}{r(0)}$ in terms of $L$, $\\eta$, and $\\delta$.\n\nYour final answer must be this single analytic expression for $R$. No numerical rounding is required.",
            "solution": "The problem asks for the derivation of a ratio $R = \\frac{r(\\delta)}{r(0)}$, where $r(w)$ is the local linearized contraction factor for the error in a simplified one-dimensional Residual Network trained with gradient descent.\n\nFirst, we formalize the loss function $\\mathcal{L}(w)$. The network output is $y = (1 + w)^{L} x$ and the target is $y^{\\star} = a x$. The loss is given by:\n$$\n\\mathcal{L}(w) = \\frac{1}{2} \\mathbb{E}\\!\\left[\\left(y - y^{\\star}\\right)^{2}\\right] = \\frac{1}{2} \\mathbb{E}\\!\\left[\\left((1 + w)^{L} x - a x\\right)^{2}\\right]\n$$\nWe can factor out the term involving $x$:\n$$\n\\mathcal{L}(w) = \\frac{1}{2} \\mathbb{E}\\!\\left[\\left((1 + w)^{L} - a\\right)^{2} x^{2}\\right]\n$$\nSince the term $\\left((1 + w)^{L} - a\\right)^{2}$ is a constant with respect to the expectation over the random variable $x$, we can move it outside the expectation:\n$$\n\\mathcal{L}(w) = \\frac{1}{2} \\left((1 + w)^{L} - a\\right)^{2} \\mathbb{E}[x^{2}]\n$$\nThe problem states that the input $x$ is a zero-mean random variable with variance $\\mathbb{E}[x^{2}] = 1$. Substituting this into the equation for the loss gives:\n$$\n\\mathcal{L}(w) = \\frac{1}{2} \\left((1 + w)^{L} - a\\right)^{2}\n$$\nThe problem also defines the scalar error as $e(w) = (1 + w)^{L} - a$. Therefore, the loss function can be expressed compactly in terms of the error:\n$$\n\\mathcal{L}(w) = \\frac{1}{2} e(w)^{2}\n$$\nNext, we perform training using gradient descent. The update rule for the parameter $w$ is $w^{+} = w - \\eta \\frac{d\\mathcal{L}}{dw}$, where $w^{+}$ is the parameter value after one update step and $\\eta > 0$ is the learning rate. We need to compute the gradient of the loss function with respect to $w$. Using the chain rule:\n$$\n\\frac{d\\mathcal{L}}{dw} = \\frac{d\\mathcal{L}}{de} \\frac{de}{dw}\n$$\nThe derivatives are:\n$$\n\\frac{d\\mathcal{L}}{de} = \\frac{d}{de} \\left(\\frac{1}{2} e^{2}\\right) = e(w)\n$$\n$$\n\\frac{de}{dw} = \\frac{d}{dw} \\left((1 + w)^{L} - a\\right) = L(1 + w)^{L-1}\n$$\nCombining these results, the gradient is:\n$$\n\\frac{d\\mathcal{L}}{dw} = e(w) L (1 + w)^{L-1}\n$$\nNow we can write the gradient descent update for $w$:\n$$\nw^{+} = w - \\eta \\, e(w) \\, L (1 + w)^{L-1}\n$$\nThe problem requires us to find the linearized one-step dynamics of the error, $e^{+} \\approx r(w) e(w)$, where $e^{+} = e(w^{+})$. We can find this by linearizing $e(w^{+})$ around the current value $w$ using a first-order Taylor expansion:\n$$\ne^{+} = e(w^{+}) \\approx e(w) + (w^{+} - w) \\frac{de}{dw}(w)\n$$\nThe change in $w$ is $\\Delta w = w^{+} - w = -\\eta \\frac{d\\mathcal{L}}{dw}$. Substituting this and the expression for $\\frac{de}{dw}$ into the Taylor expansion gives:\n$$\ne^{+} \\approx e(w) + \\left(-\\eta \\frac{d\\mathcal{L}}{dw}\\right) \\left(L(1 + w)^{L-1}\\right)\n$$\nNow, we substitute the full expression for the gradient $\\frac{d\\mathcal{L}}{dw} = e(w) L (1+w)^{L-1}$:\n$$\ne^{+} \\approx e(w) - \\eta \\left(e(w) L (1+w)^{L-1}\\right) \\left(L(1 + w)^{L-1}\\right)\n$$\nSimplifying this expression:\n$$\ne^{+} \\approx e(w) - \\eta \\, e(w) \\, L^{2} (1+w)^{2(L-1)}\n$$\nFactoring out the current error $e(w)$:\n$$\ne^{+} \\approx e(w) \\left[ 1 - \\eta L^{2} (1+w)^{2(L-1)} \\right]\n$$\nBy comparing this to the given form $e^{+} \\approx r(w) e(w)$, we can identify the local contraction factor $r(w)$:\n$$\nr(w) = 1 - \\eta L^{2} (1+w)^{2(L-1)}\n$$\nThe final step is to compute the ratio $R = \\frac{r(\\delta)}{r(0)}$. First, we evaluate $r(w)$ at the identity initialization $w=0$:\n$$\nr(0) = 1 - \\eta L^{2} (1+0)^{2(L-1)} = 1 - \\eta L^{2} (1) = 1 - \\eta L^{2}\n$$\nNext, we evaluate $r(w)$ at the small random initialization $w=\\delta$:\n$$\nr(\\delta) = 1 - \\eta L^{2} (1+\\delta)^{2(L-1)}\n$$\nFinally, we form the ratio $R$:\n$$\nR = \\frac{r(\\delta)}{r(0)} = \\frac{1 - \\eta L^{2} (1+\\delta)^{2(L-1)}}{1 - \\eta L^{2}}\n$$\nThis is the required closed-form expression for the ratio $R$ in terms of $L$, $\\eta$, and $\\delta$.",
            "answer": "$$\\boxed{\\frac{1 - \\eta L^{2} (1+\\delta)^{2(L-1)}}{1 - \\eta L^{2}}}$$"
        },
        {
            "introduction": "To build intuition, it is often powerful to construct a scenario where a concept's utility becomes crystal clear. This coding practice  does exactly that for residual connections by guiding you to build a synthetic classification task where the input data is already a good-but-imperfect predictor. You will programmatically demonstrate and quantify how a simple residual function can learn the necessary corrections, turning a mediocre classifier into a perfect one and providing tangible evidence for the 'learning a correction' hypothesis.",
            "id": "3169949",
            "problem": "Consider a binary classification task constructed to emulate a single residual block in a Residual Network (ResNet), where the residual block computes a mapping of the form $H(\\mathbf{x}) = I(\\mathbf{x}) + F(\\mathbf{x})$, and the identity mapping $I(\\mathbf{x})$ is an existing input representation while $F(\\mathbf{x})$ is a learned correction. Use the following foundational base: the classification decision is made by thresholding a scalar logit at $0$, and classification accuracy is the fraction of correct predictions over all samples. The ground-truth decision boundary is defined by the sign of a linear function with additive noise. Your task is to formalize the situation where inputs are near the decision boundary, making residual corrections decisive, and to quantify the improvement in accuracy from adding the residual $F$ over the identity baseline $I$.\n\nDataset and decision definitions:\n- Let $\\mathbf{x} = (x_1, x_2) \\in \\mathbb{R}^2$ be the input. For a dataset of size $N$, sample $x_1 \\sim \\mathrm{Uniform}(-\\delta, \\delta)$ and $x_2 \\sim \\mathrm{Uniform}(-1, 1)$ independently, with $\\delta > 0$ small so that inputs are near the decision boundary defined by $x_1 = 0$.\n- Let $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ be independent additive noise.\n- The ground-truth label is defined as $y = \\mathbb{I}\\{x_1 + \\alpha\\, x_2 + \\varepsilon \\ge 0\\}$, where $\\alpha \\in \\mathbb{R}$ controls the strength of the residual component tied to $x_2$, and $\\mathbb{I}\\{\\cdot\\}$ denotes the indicator function returning $1$ when the condition is true and $0$ otherwise.\n- The identity-baseline classifier uses the logit $I(\\mathbf{x}) = x_1$ and predicts $\\hat{y}_I = \\mathbb{I}\\{I(\\mathbf{x}) \\ge 0\\}$.\n- The residualized classifier uses the logit $H(\\mathbf{x}) = I(\\mathbf{x}) + F(\\mathbf{x})$ with $F(\\mathbf{x}) = \\alpha\\, x_2$ and predicts $\\hat{y}_R = \\mathbb{I}\\{H(\\mathbf{x}) \\ge 0\\}$.\n\nFor each dataset, compute the identity-baseline accuracy\n$$\\mathrm{Acc}_I = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{I}\\{\\hat{y}_I^{(i)} = y^{(i)}\\},$$\nthe residualized accuracy\n$$\\mathrm{Acc}_R = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{I}\\{\\hat{y}_R^{(i)} = y^{(i)}\\},$$\nand the accuracy improvement\n$$\\Delta \\mathrm{Acc} = \\mathrm{Acc}_R - \\mathrm{Acc}_I.$$\n\nYour program must deterministically generate the datasets using a pseudorandom number generator with the specified seed and produce the accuracy improvement $\\Delta \\mathrm{Acc}$ for each of the following test cases:\n- Test case $1$: $(N, \\delta, \\alpha, \\sigma, \\text{seed}) = (5000, 0.05, 0.5, 0.0, 42)$.\n- Test case $2$: $(N, \\delta, \\alpha, \\sigma, \\text{seed}) = (5000, 0.05, 0.0, 0.0, 123)$.\n- Test case $3$: $(N, \\delta, \\alpha, \\sigma, \\text{seed}) = (5000, 10^{-6}, 0.5, 0.0, 7)$.\n- Test case $4$: $(N, \\delta, \\alpha, \\sigma, \\text{seed}) = (5000, 0.5, 0.5, 0.0, 99)$.\n- Test case $5$: $(N, \\delta, \\alpha, \\sigma, \\text{seed}) = (5000, 0.05, 0.5, 0.3, 2023)$.\n\nDesign for coverage:\n- The first case is a typical near-boundary scenario where residual corrections should help.\n- The second case sets $\\alpha = 0$, so residuals add no information, serving as a baseline edge case.\n- The third case makes inputs extremely close to the decision boundary by setting $\\delta = 10^{-6}$.\n- The fourth case relaxes the near-boundary condition by increasing $\\delta$, testing reduced reliance on residual corrections.\n- The fifth case introduces noise with $\\sigma > 0$, testing robustness when labels are corrupted.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each entry being the computed $\\Delta \\mathrm{Acc}$ for the respective test case, rounded to $6$ decimal places (for example, $[0.123456,0.000000,0.250000,0.050000,0.010000]$). No other text should be printed.",
            "solution": "The problem requires us to quantify the performance improvement gained by a single residual connection in a simplified binary classification setting. The scenario is designed to model a ResNet block where an identity mapping $I(\\mathbf{x})$ is augmented by a residual function $F(\\mathbf{x})$ to form a new mapping $H(\\mathbf{x}) = I(\\mathbf{x}) + F(\\mathbf{x})$. We will simulate this process, calculate the classification accuracy for both the baseline (identity-only) and the residualized model, and then determine the accuracy improvement $\\Delta \\mathrm{Acc}$. The entire process is to be executed deterministically for several test cases by using a seeded pseudorandom number generator.\n\nThe solution proceeds through the following steps for each test case, defined by the parameters $(N, \\delta, \\alpha, \\sigma, \\text{seed})$.\n\n1.  **Dataset Generation**: First, we generate a dataset of $N$ samples. Each sample consists of an input vector $\\mathbf{x}^{(i)} = (x_1^{(i)}, x_2^{(i)})$ and a corresponding ground-truth label $y^{(i)}$.\n    -   A pseudorandom number generator is initialized with the specified `seed` to ensure deterministic and reproducible results.\n    -   The input components are sampled from independent uniform distributions: $x_1^{(i)} \\sim \\mathrm{Uniform}(-\\delta, \\delta)$ and $x_2^{(i)} \\sim \\mathrm{Uniform}(-1, 1)$ for $i=1, \\dots, N$. The parameter $\\delta$ controls the proximity of the inputs to the decision boundary $x_1 = 0$.\n    -   An independent additive noise term $\\varepsilon^{(i)}$ is sampled from a normal distribution $\\mathcal{N}(0, \\sigma^2)$. The parameter $\\sigma$ is the standard deviation of the noise.\n    -   The ground-truth label $y^{(i)}$ is determined by the sign of a noisy linear combination of the inputs. It is defined using the indicator function $\\mathbb{I}\\{\\cdot\\}$ as:\n        $$y^{(i)} = \\mathbb{I}\\{x_1^{(i)} + \\alpha\\, x_2^{(i)} + \\varepsilon^{(i)} \\ge 0\\}$$\n        This function yields $1$ if the condition is true, and $0$ otherwise.\n\n2.  **Model Predictions**: We define two classifiers and generate their predictions for each sample in the dataset.\n    -   The **identity-baseline classifier** uses only the $x_1$ component of the input. Its logit is $I(\\mathbf{x}) = x_1$, and its prediction $\\hat{y}_I$ is based on the sign of this logit:\n        $$\\hat{y}_I^{(i)} = \\mathbb{I}\\{I(\\mathbf{x}^{(i)}) \\ge 0\\} = \\mathbb{I}\\{x_1^{(i)} \\ge 0\\}$$\n    -   The **residualized classifier** incorporates the contribution from $x_2$ as a residual correction. Its logit is $H(\\mathbf{x}) = I(\\mathbf{x}) + F(\\mathbf{x})$, where the identity mapping is $I(\\mathbf{x}) = x_1$ and the residual function is $F(\\mathbf{x}) = \\alpha\\, x_2$. The prediction $\\hat{y}_R$ is:\n        $$\\hat{y}_R^{(i)} = \\mathbb{I}\\{H(\\mathbf{x}^{(i)}) \\ge 0\\} = \\mathbb{I}\\{x_1^{(i)} + \\alpha\\, x_2^{(i)} \\ge 0\\}$$\n        This model effectively attempts to learn the true decision boundary, but without access to the noise term $\\varepsilon$.\n\n3.  **Performance Evaluation**: We compute the accuracy for each classifier and the resulting improvement.\n    -   The accuracy of a classifier is the fraction of correctly classified samples. The identity-baseline accuracy, $\\mathrm{Acc}_I$, is calculated as:\n        $$\\mathrm{Acc}_I = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{I}\\{\\hat{y}_I^{(i)} = y^{(i)}\\}$$\n    -   Similarly, the residualized accuracy, $\\mathrm{Acc}_R$, is:\n        $$\\mathrm{Acc}_R = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{I}\\{\\hat{y}_R^{(i)} = y^{(i)}\\}$$\n    -   The final metric of interest is the accuracy improvement, $\\Delta \\mathrm{Acc}$, defined as the difference between the two accuracies:\n        $$\\Delta \\mathrm{Acc} = \\mathrm{Acc}_R - \\mathrm{Acc}_I$$\n        A positive value for $\\Delta \\mathrm{Acc}$ indicates that the residual connection provides a tangible benefit for classification performance under the given conditions.\n\nFor a noise-free case where $\\sigma = 0$, the ground-truth label is $y^{(i)} = \\mathbb{I}\\{x_1^{(i)} + \\alpha x_2^{(i)} \\ge 0\\}$. The prediction of the residualized classifier, $\\hat{y}_R^{(i)}$, is identical to the ground-truth label $y^{(i)}$. Consequently, in such cases, $\\mathrm{Acc}_R$ will be exactly $1$. Any deviation from this in the simulation would be due to floating-point precision, but is expected to be negligible. The accuracy improvement then becomes $\\Delta \\mathrm{Acc} = 1 - \\mathrm{Acc}_I$.\n\nThe provided test cases explore the model's behavior under different regimes:\n-   **Case 1 ($\\alpha=0.5$, $\\delta=0.05$, $\\sigma=0.0$):** A standard scenario where the residual term contains useful information, inputs are near the identity boundary, and there is no label noise. We expect a significant positive $\\Delta \\mathrm{Acc}$.\n-   **Case 2 ($\\alpha=0.0$, $\\delta=0.05$, $\\sigma=0.0$):** Here, the residual term $F(\\mathbf{x}) = 0 \\cdot x_2 = 0$. Both classifiers become identical, so we must have $\\mathrm{Acc}_I = \\mathrm{Acc}_R$, leading to $\\Delta \\mathrm{Acc} = 0$.\n-   **Case 3 ($\\alpha=0.5$, $\\delta=10^{-6}$, $\\sigma=0.0$):** With an extremely small $\\delta$, inputs are clustered very tightly around the $x_1=0$ boundary. The identity classifier's performance is expected to approach that of a random guess (accuracy of $0.5$), making the residual term critically important. $\\Delta \\mathrm{Acc}$ should be close to $0.5$.\n-   **Case 4 ($\\alpha=0.5$, $\\delta=0.5$, $\\sigma=0.0$):** With a larger $\\delta$, a greater proportion of inputs are far from the $x_1=0$ boundary. For these points, the sign of $x_1$ is a better predictor of the sign of $x_1 + \\alpha x_2$, thus improving $\\mathrm{Acc}_I$ and reducing the *relative* improvement $\\Delta \\mathrm{Acc}$.\n-   **Case 5 ($\\alpha=0.5$, $\\delta=0.05$, $\\sigma=0.3$):** The introduction of significant label noise ($\\sigma > 0$) makes the problem fundamentally stochastic. The true labels can flip sign relative to the noiseless boundary. Both accuracies are expected to drop, but the residual classifier, being better aligned with the underlying data structure, should maintain an advantage, resulting in a positive $\\Delta \\mathrm{Acc}$.\n\nThe following program implements this entire procedure to calculate $\\Delta \\mathrm{Acc}$ for each test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the accuracy improvement from a residual connection in a simplified\n    binary classification task for a set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (N, delta, alpha, sigma, seed)\n    test_cases = [\n        (5000, 0.05, 0.5, 0.0, 42),\n        (5000, 0.05, 0.0, 0.0, 123),\n        (5000, 1e-6, 0.5, 0.0, 7),\n        (5000, 0.5, 0.5, 0.0, 99),\n        (5000, 0.05, 0.5, 0.3, 2023),\n    ]\n\n    results = []\n    for N, delta, alpha, sigma, seed in test_cases:\n        # 1. Dataset Generation\n        # Initialize a pseudorandom number generator with the specified seed for reproducibility.\n        rng = np.random.default_rng(seed)\n\n        # Sample x1 and x2 from their respective uniform distributions.\n        x1 = rng.uniform(-delta, delta, size=N)\n        x2 = rng.uniform(-1, 1, size=N)\n\n        # Sample additive noise from a normal distribution. scale=sigma (std dev).\n        epsilon = rng.normal(loc=0.0, scale=sigma, size=N)\n\n        # Determine ground-truth labels.\n        # y = I{x1 + alpha*x2 + epsilon >= 0}\n        ground_truth_logit = x1 + alpha * x2 + epsilon\n        y_true = (ground_truth_logit >= 0).astype(int)\n\n        # 2. Model Predictions\n        # Identity-baseline classifier prediction.\n        # y_hat_I = I{x1 >= 0}\n        y_pred_I = (x1 >= 0).astype(int)\n\n        # Residualized classifier prediction.\n        # y_hat_R = I{x1 + alpha*x2 >= 0}\n        y_pred_R = (x1 + alpha * x2 >= 0).astype(int)\n\n        # 3. Performance Evaluation\n        # Calculate accuracy for the identity-baseline classifier.\n        acc_I = np.mean(y_pred_I == y_true)\n\n        # Calculate accuracy for the residualized classifier.\n        acc_R = np.mean(y_pred_R == y_true)\n\n        # Calculate the accuracy improvement.\n        delta_acc = acc_R - acc_I\n        \n        results.append(delta_acc)\n\n    # Format results to 6 decimal places and print in the specified format.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once a model is trained, how can we peek inside to understand its behavior? This advanced practice  introduces a powerful diagnostic technique to quantify a residual block's dependence on its identity shortcut versus its learned residual branch. By strategically injecting noise and measuring the impact on performance, you will derive and compute a 'Shortcut Reliance Index' (SRI), offering a principled way to analyze the function that the block has learned.",
            "id": "3169993",
            "problem": "You are given a single residual block from a Residual Network (ResNet). The block maps an input vector $x \\in \\mathbb{R}^d$ to an output vector $y \\in \\mathbb{R}^d$ by the rule $y = f(x; B) + x$, where $f(\\cdot; B)$ is the residual transformation parameterized by a matrix $B \\in \\mathbb{R}^{d \\times d}$. For this problem, assume a linear residual branch $f(x; B) = B x$. Consider a supervised prediction task with targets $t \\in \\mathbb{R}^d$, and define the loss as the Mean Squared Error (MSE), namely $L = \\mathbb{E}\\left[\\lVert y - t \\rVert_2^2 \\right]$, where the expectation is with respect to the data distribution. You will design a diagnostic to quantify how much the block relies on the identity shortcut relative to the residual branch by measuring sensitivity of the loss to small additive perturbations.\n\nDiagnostic definition to be implemented:\n1) For a fixed noise scale $\\epsilon > 0$, define a skip-only perturbation that adds zero-mean Gaussian noise to the shortcut path at the adder: the perturbed output is $y_{\\text{skip}}(\\epsilon) = Bx + \\left( x + \\epsilon z \\right)$, where $z \\sim \\mathcal{N}(0, I_d)$ and $I_d$ is the $d \\times d$ identity matrix. Define the skip-perturbation performance drop as $\\Delta L_{\\text{skip}}(\\epsilon) = \\mathbb{E}\\left[\\lVert y_{\\text{skip}}(\\epsilon) - t \\rVert_2^2\\right] - \\mathbb{E}\\left[\\lVert (Bx + x) - t \\rVert_2^2 \\right]$.\n2) For the same $\\epsilon$, define an input-perturbation that adds the same type of noise to the block input before branching: the perturbed output is $y_{\\text{in}}(\\epsilon) = B(x + \\epsilon z) + (x + \\epsilon z)$. Define the input-perturbation performance drop as $\\Delta L_{\\text{in}}(\\epsilon) = \\mathbb{E}\\left[\\lVert y_{\\text{in}}(\\epsilon) - t \\rVert_2^2\\right] - \\mathbb{E}\\left[\\lVert (Bx + x) - t \\rVert_2^2 \\right]$.\n3) Define the Shortcut Reliance Index (SRI) for small $\\epsilon$ as the ratio $SRI = \\dfrac{\\Delta L_{\\text{skip}}(\\epsilon)}{\\Delta L_{\\text{in}}(\\epsilon)}$. This ratio isolates the relative sensitivity of the loss to skip-only noise versus input noise and is to be computed exactly for the linear residual block.\n\nFrom first principles and using only the definitions above along with standard properties of Gaussian random variables, derive a computationally efficient expression to evaluate $SRI$ for any given $B$ and $d$, without performing stochastic simulation. Then implement a program that evaluates $SRI$ on the following test suite. For each case, use the specified parameters:\n- Test case $1$: $d = 3$, $B = 0.5 \\, I_d$, $\\epsilon = 0.1$.\n- Test case $2$: $d = 3$, $B = 0 \\, I_d$, $\\epsilon = 0.1$.\n- Test case $3$: $d = 3$, $B = \\mathrm{diag}(1, -0.5, 0)$, $\\epsilon = 0.1$.\n- Test case $4$: $d = 3$, $B = 4 \\, I_d$, $\\epsilon = 0.1$.\n- Test case $5$: $d = 3$, $B = -0.9 \\, I_d$, $\\epsilon = 0.1$.\n\nYour program must output a single line containing the computed $SRI$ for each test case, as a comma-separated list enclosed in square brackets, in the order of the cases $1$ through $5$ (for example, $[a,b,c,d,e]$). All outputs must be real-valued numbers. No physical units are involved in this problem.",
            "solution": "The problem requires the derivation of the Shortcut Reliance Index (SRI) for a linear residual block and its evaluation for a set of given parameters. The SRI is defined as the ratio of the loss increase due to a skip-path-only noise injection to the loss increase from a block-input noise injection. We shall derive this quantity from first principles.\n\nLet the block's input be $x \\in \\mathbb{R}^d$, the target be $t \\in \\mathbb{R}^d$, and the linear residual branch be defined by the matrix $B \\in \\mathbb{R}^{d \\times d}$. The output of the block is $y = Bx + x = (B+I_d)x$, where $I_d$ is the $d \\times d$ identity matrix. The loss function is the Mean Squared Error, $L = \\mathbb{E}\\left[\\lVert y - t \\rVert_2^2 \\right]$, where the expectation is over the data distribution of $(x, t)$ and any injected noise. The unperturbed loss is $L_0 = \\mathbb{E}_{x,t}\\left[\\lVert (B+I_d)x - t \\rVert_2^2 \\right]$. Let's define the error vector for a given data sample as $e = (B+I_d)x - t$. Then $L_0 = \\mathbb{E}_{x,t}[\\lVert e \\rVert_2^2]$.\n\nFirst, we analyze the skip-only perturbation. The perturbed output is given by $y_{\\text{skip}}(\\epsilon) = Bx + (x + \\epsilon z) = (B+I_d)x + \\epsilon z$, where $z \\sim \\mathcal{N}(0, I_d)$ is a vector of i.i.d. standard Gaussian random variables, independent of $x$ and $t$. The noise scale is $\\epsilon > 0$.\n\nThe loss with skip-path perturbation is $L_{\\text{skip}}(\\epsilon) = \\mathbb{E}_{x,t,z}\\left[\\lVert y_{\\text{skip}}(\\epsilon) - t \\rVert_2^2\\right]$. We can write this as:\n$$ L_{\\text{skip}}(\\epsilon) = \\mathbb{E}_{x,t,z}\\left[\\lVert ((B+I_d)x - t) + \\epsilon z \\rVert_2^2\\right] = \\mathbb{E}_{x,t,z}\\left[\\lVert e + \\epsilon z \\rVert_2^2\\right] $$\nExpanding the squared L2-norm, which is the inner product of the vector with itself:\n$$ \\lVert e + \\epsilon z \\rVert_2^2 = (e + \\epsilon z)^T (e + \\epsilon z) = e^T e + 2\\epsilon e^T z + \\epsilon^2 z^T z = \\lVert e \\rVert_2^2 + 2\\epsilon e^T z + \\epsilon^2 \\lVert z \\rVert_2^2 $$\nBy linearity of expectation, we have:\n$$ L_{\\text{skip}}(\\epsilon) = \\mathbb{E}_{x,t,z}[\\lVert e \\rVert_2^2] + 2\\epsilon \\mathbb{E}_{x,t,z}[e^T z] + \\epsilon^2 \\mathbb{E}_{x,t,z}[\\lVert z \\rVert_2^2] $$\nWe evaluate each term:\n1.  $\\mathbb{E}_{x,t,z}[\\lVert e \\rVert_2^2] = \\mathbb{E}_{x,t}[\\lVert e \\rVert_2^2] = L_0$, as $e$ is not a function of $z$.\n2.  $\\mathbb{E}_{x,t,z}[e^T z] = \\mathbb{E}_{x,t}[\\mathbb{E}_z[e^T z | x,t]]$. Since $e$ is constant with respect to $z$, this becomes $\\mathbb{E}_{x,t}[e^T \\mathbb{E}_z[z]]$. As $z \\sim \\mathcal{N}(0, I_d)$, $\\mathbb{E}_z[z] = 0$. Thus, this term is $0$.\n3.  $\\mathbb{E}_{x,t,z}[\\lVert z \\rVert_2^2] = \\mathbb{E}_z[\\lVert z \\rVert_2^2] = \\mathbb{E}_z[\\sum_{i=1}^d z_i^2] = \\sum_{i=1}^d \\mathbb{E}_z[z_i^2]$. For a standard normal variable $z_i$, $\\mathbb{E}[z_i] = 0$ and $\\mathrm{Var}(z_i) = 1$. Since $\\mathrm{Var}(z_i) = \\mathbb{E}[z_i^2] - (\\mathbb{E}[z_i])^2$, we have $\\mathbb{E}[z_i^2] = 1$. Therefore, $\\mathbb{E}_z[\\lVert z \\rVert_2^2] = \\sum_{i=1}^d 1 = d$.\n\nSubstituting these results, we get $L_{\\text{skip}}(\\epsilon) = L_0 + \\epsilon^2 d$.\nThe skip-perturbation performance drop is defined as $\\Delta L_{\\text{skip}}(\\epsilon) = L_{\\text{skip}}(\\epsilon) - L_0$, which simplifies to:\n$$ \\Delta L_{\\text{skip}}(\\epsilon) = \\epsilon^2 d $$\n\nNext, we analyze the input perturbation. The perturbed output is $y_{\\text{in}}(\\epsilon) = B(x+\\epsilon z) + (x+\\epsilon z) = (B+I_d)(x+\\epsilon z) = (B+I_d)x + \\epsilon(B+I_d)z$.\nThe loss with input perturbation is $L_{\\text{in}}(\\epsilon) = \\mathbb{E}_{x,t,z}\\left[\\lVert y_{\\text{in}}(\\epsilon) - t \\rVert_2^2\\right]$:\n$$ L_{\\text{in}}(\\epsilon) = \\mathbb{E}_{x,t,z}\\left[\\lVert ((B+I_d)x - t) + \\epsilon(B+I_d)z \\rVert_2^2\\right] = \\mathbb{E}_{x,t,z}\\left[\\lVert e + \\epsilon(B+I_d)z \\rVert_2^2\\right] $$\nExpanding the squared norm:\n$$ \\lVert e + \\epsilon(B+I_d)z \\rVert_2^2 = \\lVert e \\rVert_2^2 + 2\\epsilon e^T(B+I_d)z + \\epsilon^2 z^T(B+I_d)^T(B+I_d)z $$\nTaking the expectation:\n$$ L_{\\text{in}}(\\epsilon) = \\mathbb{E}_{x,t,z}[\\lVert e \\rVert_2^2] + 2\\epsilon \\mathbb{E}_{x,t,z}[e^T(B+I_d)z] + \\epsilon^2 \\mathbb{E}_{x,t,z}[z^T(B+I_d)^T(B+I_d)z] $$\nWe evaluate the terms:\n1.  The first term is $L_0$.\n2.  The cross term is $\\mathbb{E}_{x,t,z}[e^T(B+I_d)z] = \\mathbb{E}_{x,t}[e^T(B+I_d)\\mathbb{E}_z[z]] = 0$.\n3.  The third term involves a quadratic form in the Gaussian vector $z$. Let $M = (B+I_d)^T(B+I_d)$. The expectation is $\\mathbb{E}_{x,t,z}[z^T M z] = \\mathbb{E}_z[z^T M z]$. For a random vector $z$ with mean $\\mu=0$ and covariance $\\Sigma=I_d$, we have $\\mathbb{E}_z[z^T M z] = \\mathrm{Tr}(M\\Sigma) + \\mu^T M \\mu = \\mathrm{Tr}(M I_d) + 0 = \\mathrm{Tr}(M)$.\nSo, $\\mathbb{E}_z[z^T(B+I_d)^T(B+I_d)z] = \\mathrm{Tr}((B+I_d)^T(B+I_d))$.\n\nSubstituting back, we find $L_{\\text{in}}(\\epsilon) = L_0 + \\epsilon^2 \\mathrm{Tr}((B+I_d)^T(B+I_d))$.\nThe input-perturbation performance drop is $\\Delta L_{\\text{in}}(\\epsilon) = L_{\\text{in}}(\\epsilon) - L_0$:\n$$ \\Delta L_{\\text{in}}(\\epsilon) = \\epsilon^2 \\mathrm{Tr}\\left((B+I_d)^T(B+I_d)\\right) $$\nThe term $\\mathrm{Tr}((B+I_d)^T(B+I_d))$ is equivalent to the squared Frobenius norm of the matrix $B+I_d$, denoted $\\lVert B+I_d \\rVert_F^2$.\n\nFinally, the Shortcut Reliance Index (SRI) is the ratio of these two quantities:\n$$ SRI = \\frac{\\Delta L_{\\text{skip}}(\\epsilon)}{\\Delta L_{\\text{in}}(\\epsilon)} = \\frac{\\epsilon^2 d}{\\epsilon^2 \\mathrm{Tr}\\left((B+I_d)^T(B+I_d)\\right)} $$\nThe $\\epsilon^2$ terms cancel, yielding an expression independent of the noise scale $\\epsilon$ and the data distribution. The final expression is:\n$$ SRI = \\frac{d}{\\mathrm{Tr}\\left((B+I_d)^T(B+I_d)\\right)} = \\frac{d}{\\lVert B+I_d \\rVert_F^2} $$\nThis expression is computationally efficient as it only requires matrix addition and the computation of the squared Frobenius norm, which is a sum of the squares of the matrix elements, an operation of complexity $O(d^2)$. We will now implement this formula to evaluate the specified test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Shortcut Reliance Index (SRI) for several test cases\n    of a linear residual block.\n    \"\"\"\n    \n    # Test cases are defined as tuples of (dimension, B_matrix).\n    #\n    # Test case 1: d = 3, B = 0.5 * I_d\n    # Test case 2: d = 3, B = 0 * I_d\n    # Test case 3: d = 3, B = diag(1, -0.5, 0)\n    # Test case 4: d = 3, B = 4 * I_d\n    # Test case 5: d = 3, B = -0.9 * I_d\n    \n    test_cases = [\n        (3, 0.5 * np.identity(3)),\n        (3, 0.0 * np.identity(3)),\n        (3, np.diag([1.0, -0.5, 0.0])),\n        (3, 4.0 * np.identity(3)),\n        (3, -0.9 * np.identity(3))\n    ]\n\n    results = []\n    for d, B in test_cases:\n        # The derived formula for SRI is:\n        # SRI = d / Tr((B + I)^T * (B + I))\n        # The denominator is the squared Frobenius norm of the matrix (B + I).\n        \n        # Construct the identity matrix of dimension d.\n        I = np.identity(d)\n        \n        # Compute the matrix B + I.\n        B_plus_I = B + I\n        \n        # The squared Frobenius norm ||A||_F^2 is the sum of the squares of all elements.\n        # This is computationally more efficient than matrix multiplication followed by trace.\n        # np.sum(np.square(A)) computes this directly.\n        denominator = np.sum(np.square(B_plus_I))\n        \n        # According to the problem setup, the denominator will not be zero for the\n        # given test cases. If it were, SRI would be infinite, signifying that\n        # the block is perfectly robust to input noise but not skip-path noise.\n        if denominator == 0:\n            sri = float('inf')\n        else:\n            sri = d / denominator\n            \n        results.append(sri)\n\n    # The final print statement must match the specified format: [a,b,c,d,e]\n    # We use map(str, ...) and ','.join(...) to format the list of floats.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}