{
    "hands_on_practices": [
        {
            "introduction": "理想情况下，卷积操作具有平移等变性，但这一理想特性在处理有限长度的信号时常常受到实际实现方式的挑战，其中最关键的就是边界填充策略。本练习  将带你从最基础的一维卷积入手，深入探究两种不同填充方式对平移等变性的影响。你将通过编程实现并量化比较循环填充（circular padding）和零填充（zero padding）下的等变性误差 $\\varepsilon_{\\mathrm{circ}}$ 和 $\\varepsilon_{0}$，从而直观地理解边界效应是如何破坏完美的等变性，以及为何特定类型的填充（如循环填充）能够在特定条件下（如周期信号）保持这一特性。",
            "id": "3196029",
            "problem": "你的任务是评估卷积神经网络 (CNN) 中使用的一维离散互相关的平移等变性。请严格处理周期信号，并形式化定义两种填充方案：循环填充和零填充。你的工作是实现这两种方案，并量化当输入被循环移位时产生的等变性误差。评估应纯粹是数学和算法上的，不借助任何外部文件或用户输入。\n\n使用的基本定义：\n- 令输入信号为 $x \\in \\mathbb{R}^N$，其索引为 $n \\in \\{0,1,\\dots,N-1\\}$；核为 $w \\in \\mathbb{R}^M$，其中 $M$ 为奇数。令 $c = \\frac{M-1}{2}$ 表示核中心索引。\n- 定义整数移位 $s$ 的循环移位算子 $T_s$ 如下\n$$\n\\left(T_s x\\right)[n] = x\\left[(n - s) \\bmod N\\right].\n$$\n- 定义一维循环填充互相关（输出长度为 $N$）如下\n$$\n\\left(\\mathrm{Corr}_{\\mathrm{circ}}(x,w)\\right)[n] = \\sum_{m=0}^{M-1} w[m]\\; x\\left[(n + m - c) \\bmod N\\right].\n$$\n- 定义一维零填充互相关（输出长度为 $N$）如下\n$$\n\\left(\\mathrm{Corr}_{0}(x,w)\\right)[n] = \\sum_{m=0}^{M-1} w[m]\\; x\\left[n + m - c\\right]\\mathbf{1}\\left(0 \\le n + m - c \\le N-1\\right),\n$$\n其中 $\\mathbf{1}(\\cdot)$ 是指示函数，因此在 $\\{0,1,\\dots,N-1\\}$ 范围之外的值被视为 $0$。\n\n任务：\n- 对于每个给定的测试用例，计算两个非负实数：\n    - 循环填充下与平移等变性的最大绝对偏差，\n    $$\n    \\varepsilon_{\\mathrm{circ}} = \\max_{0 \\le n \\le N-1} \\left| \\left(\\mathrm{Corr}_{\\mathrm{circ}}(T_s x, w)\\right)[n] - \\left(T_s\\,\\mathrm{Corr}_{\\mathrm{circ}}(x,w)\\right)[n] \\right|.\n    $$\n    - 零填充下与平移等变性的最大绝对偏差，\n    $$\n    \\varepsilon_{0} = \\max_{0 \\le n \\le N-1} \\left| \\left(\\mathrm{Corr}_{0}(T_s x, w)\\right)[n] - \\left(T_s\\,\\mathrm{Corr}_{0}(x,w)\\right)[n] \\right|.\n    $$\n- 使用上述定义的模索引实现循环移位算子 $T_s$。\n- 使用环绕索引实现 $\\mathrm{Corr}_{\\mathrm{circ}}$，并使用上述指示函数实现 $\\mathrm{Corr}_{0}$。\n- 使用浮点运算。不涉及物理单位。提及角度只是作为周期信号的一个启发性例子；所有计算都是纯数值的。\n\n测试套件：\n为以下六组参数 $(x,w,s)$ 提供结果，每组都有指定的 $N$ 和奇数 $M$：\n- 情况 1：$N = 8$，$x = [0,1,2,3,4,5,6,7]$，$w = [1,0,-1]$，$s = 2$。\n- 情况 2：$N = 8$，$x[n] = \\sin\\left(2\\pi n / 8\\right)$，对于 $n \\in \\{0,1,2,3,4,5,6,7\\}$，$w = [1,2,3,2,1]/9$，$s = 3$。\n- 情况 3：$N = 5$，$x = [1,0,0,0,0]$，$w = [-1,0,2]$，$s = 4$。\n- 情况 4：$N = 7$，$x = [0.2,-0.1,0.5,-0.3,0.7,-0.2,0.0]$，$w = [0.25,0.5,0.25]$，$s = 0$。\n- 情况 5：$N = 9$，$x[n] = \\cos\\left(2\\pi n / 9\\right)$，对于 $n \\in \\{0,1,2,3,4,5,6,7,8\\}$，$w = [1,-1,0,1,-1]$，$s = 4$。\n- 情况 6：$N = 8$，$x = [1,-1,1,-1,1,-1,1,-1]$，$w = [2,-1,0,1,-2,1,0]$，$s = 1$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表。\n- 该列表必须按顺序包含12个浮点值\n$$\n[\\varepsilon_{\\mathrm{circ}}^{(1)}, \\varepsilon_{0}^{(1)}, \\varepsilon_{\\mathrm{circ}}^{(2)}, \\varepsilon_{0}^{(2)}, \\dots, \\varepsilon_{\\mathrm{circ}}^{(6)}, \\varepsilon_{0}^{(6)}],\n$$\n其中上标表示情况编号。将每个值表示为十进制数。例如，一个语法正确的行看起来会像 $[0.0,0.5,0.0,1.25,\\dots]$。",
            "solution": "该问题要求评估一维离散互相关在两种不同填充方案（循环填充和零填充）下的平移等变性。平移等变性是信号处理和卷积神经网络 ($CNNs$) 中的一个基本概念。如果在一个算子 $F$ 应用之前或之后应用一个变换 $T$ 会得到相同的结果，即对于任何输入 $x$ 都有 $F(T(x)) = T(F(x))$，则称该算子 $F$ 对变换 $T$ 是等变的。在此情境下，算子 $F$ 是互相关（$\\mathrm{Corr}_{\\mathrm{circ}}$ 或 $\\mathrm{Corr}_{0}$），变换 $T$ 是循环移位算子 $T_s$。我们将分析每种填充方案对此属性的遵循情况，然后提出一个算法来计算指定的偏差度量 $\\varepsilon_{\\mathrm{circ}}$ 和 $\\varepsilon_{0}$。\n\n首先，让我们形式化要比较的量。对于给定的填充方案，我们计算移位后输入的相关性输出，记为 $y'_{\\mathrm{pad}} = \\mathrm{Corr}_{\\mathrm{pad}}(T_s x, w)$。我们还计算原始输入的相关性输出，$y_{\\mathrm{pad}} = \\mathrm{Corr}_{\\mathrm{pad}}(x, w)$，然后移位这个输出，得到 $T_s y_{\\mathrm{pad}}$。等变性误差是这两个结果信号之间逐元素的最大绝对差。\n\n**循环填充与等变性分析**\n\n如定义所示，循环互相关算子相对于循环移位算子 $T_s$ 是完全等变的。我们可以用数学方法证明这一点。令 $y_{\\mathrm{circ}} = \\mathrm{Corr}_{\\mathrm{circ}}(x, w)$。我们旨在证明 $\\mathrm{Corr}_{\\mathrm{circ}}(T_s x, w) = T_s y_{\\mathrm{circ}}$。\n\n让我们展开左侧（LHS）在任意索引 $n \\in \\{0, 1, \\dots, N-1\\}$ 处的值：\n$$\n\\text{LHS}[n] = \\left(\\mathrm{Corr}_{\\mathrm{circ}}(T_s x, w)\\right)[n] = \\sum_{m=0}^{M-1} w[m]\\; (T_s x)\\left[(n + m - c) \\bmod N\\right]\n$$\n根据移位算子的定义，$(T_s x)[k] = x[(k - s) \\bmod N]$。代入 $k = (n + m - c) \\bmod N$：\n$$\n\\text{LHS}[n] = \\sum_{m=0}^{M-1} w[m]\\; x\\left[\\left( ((n + m - c) \\bmod N) - s \\right) \\bmod N\\right]\n$$\n使用模运算的性质 $((a \\bmod N) - b) \\bmod N = (a-b) \\bmod N$，我们可以简化索引：\n$$\n\\text{LHS}[n] = \\sum_{m=0}^{M-1} w[m]\\; x\\left[(n - s + m - c) \\bmod N\\right]\n$$\n现在我们来考察右侧（RHS），$T_s y_{\\mathrm{circ}}$。\n$$\n\\text{RHS}[n] = (T_s y_{\\mathrm{circ}})[n] = y_{\\mathrm{circ}}[(n-s) \\bmod N]\n$$\n根据 $y_{\\mathrm{circ}} = \\mathrm{Corr}_{\\mathrm{circ}}(x, w)$ 的定义，我们有：\n$$\n\\text{RHS}[n] = \\left(\\mathrm{Corr}_{\\mathrm{circ}}(x, w)\\right)[(n-s) \\bmod N] = \\sum_{m=0}^{M-1} w[m]\\; x\\left[(((n-s)\\bmod N) + m - c) \\bmod N\\right]\n$$\n再次使用模运算的性质，这可简化为：\n$$\n\\text{RHS}[n] = \\sum_{m=0}^{M-1} w[m]\\; x\\left[(n - s + m - c) \\bmod N\\right]\n$$\n由于对于所有 $n \\in \\{0, 1, \\dots, N-1\\}$ 都有 $\\text{LHS}[n] = \\text{RHS}[n]$，等式 $\\mathrm{Corr}_{\\mathrm{circ}}(T_s x, w) = T_s \\mathrm{Corr}_{\\mathrm{circ}}(x, w)$ 成立。因此，等变性误差的理论值为 $\\varepsilon_{\\mathrm{circ}} = 0$。数值计算产生的任何非零结果都可归因于浮点精度误差。一个例外是 $s=0$ 的情况，此时移位是单位操作，使得任何算子的等变性都是平凡的。\n\n**零填充与非等变性分析**\n\n相反，零填充互相关通常对于循环移位不是等变的。问题的核心在于移位算子 $T_s$ 的循环性质与零填充相关性 $\\mathrm{Corr}_{0}$ 的非循环、有界性质之间的不兼容性。算子 $T_s$ 将信号一端的值环绕到另一端。然而，算子 $\\mathrm{Corr}_{0}$ 将信号边界视为绝对边界，在域 $\\{0, 1, \\dots, N-1\\}$ 之外用零填充。\n\n让我们来分析零填充情况下等变性方程的两侧。\n左侧是：\n$$\n\\text{LHS}[n] = (\\mathrm{Corr}_{0}(T_s x, w))[n] = \\sum_{m=0}^{M-1} w[m]\\; (T_s x)[n + m - c]\\; \\mathbf{1}(0 \\le n + m - c \\le N-1)\n$$\n代入 $(T_s x)[k] = x[(k-s) \\bmod N]$：\n$$\n\\text{LHS}[n] = \\sum_{m=0}^{M-1} w[m]\\; x[((n + m - c) - s) \\bmod N]\\; \\mathbf{1}(0 \\le n + m - c \\le N-1)\n$$\n右侧是：\n$$\n\\text{RHS}[n] = (T_s \\mathrm{Corr}_{0}(x,w))[n] = (\\mathrm{Corr}_{0}(x,w))[(n-s) \\bmod N]\n$$\n令 $n' = (n-s) \\bmod N$。那么：\n$$\n\\text{RHS}[n] = \\sum_{m=0}^{M-1} w[m]\\; x[n' + m - c]\\; \\mathbf{1}(0 \\le n' + m - c \\le N-1)\n$$\n$\\text{LHS}[n]$ 和 $\\mathrm{RHS}[n]$ 的表达式不等价。LHS 将指示函数应用于索引 $k = n + m - c$，然后使用环绕后的值 $x[(k-s) \\bmod N]$。RHS 使用移位后的输出索引 $n'$，并将指示函数应用于基于 $n'$ 的索引，使用未环绕的值 $x[n' + m - c]$。这种差异在边界处最为明显。例如，当 RHS 计算中靠近边缘的核支撑集会读取 $[0, N-1]$ 之外的值（从而得到零）时，LHS 中对应的核可能会读取一个由 $T_s$ 环绕过来的非零值。这导致了非零的等变性误差，$\\varepsilon_{0} > 0$，除非是平凡情况（如 $s=0$）。\n\n**算法流程**\n\n对每个测试用例 $(x, w, s)$ 的验证将按以下步骤进行：\n1. 确定信号长度 $N = \\mathrm{len}(x)$ 和核长度 $M = \\mathrm{len}(w)$。计算核中心索引 $c = (M-1)/2$。\n2. 根据定义 $(T_s x)[n] = x[(n - s) \\bmod N]$ 实现循环移位算子 $T_s$。\n3. 通过对核进行求和并对输入信号索引使用模运算 $(n+m-c)\\bmod N$ 来实现循环互相关 $\\mathrm{Corr}_{\\mathrm{circ}}(x, w)$。\n4. 通过对核进行求和并使用指示函数（或条件逻辑）来实现零填充互相关 $\\mathrm{Corr}_0(x, w)$：如果 $0 \\le k \\le N-1$，则使用 $x[k]$（其中 $k = n+m-c$），否则使用 0。\n5. 对于循环情况：\n    a. 计算移位后的输入信号：$x' = T_s x$。\n    b. 计算移位后输入的相关性：$y'_{\\mathrm{circ}} = \\mathrm{Corr}_{\\mathrm{circ}}(x', w)$。\n    c. 计算原始输入的相关性：$y_{\\mathrm{circ}} = \\mathrm{Corr}_{\\mathrm{circ}}(x, w)$。\n    d. 移位结果输出：$y_{\\mathrm{circ\\_shifted}} = T_s y_{\\mathrm{circ}}$。\n    e. 计算误差：$\\varepsilon_{\\mathrm{circ}} = \\max |y'_{\\mathrm{circ}} - y_{\\mathrm{circ\\_shifted}}|$。\n6. 对于零填充情况：\n    a. 计算移位后的输入信号：$x' = T_s x$。\n    b. 计算移位后输入的相关性：$y'_{0} = \\mathrm{Corr}_{0}(x', w)$。\n    c. 计算原始输入的相关性：$y_{0} = \\mathrm{Corr}_{0}(x, w)$。\n    d. 移位结果输出：$y_{0\\_\\mathrm{shifted}} = T_s y_{0}$。\n    e. 计算误差：$\\varepsilon_{0} = \\max |y'_{0} - y_{0\\_\\mathrm{shifted}}|$。\n7. 该测试用例的最终结果是数值对 $(\\varepsilon_{\\mathrm{circ}}, \\varepsilon_{0})$。对所有指定的测试用例重复此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n#\n# Helper functions for the specified operations\n#\n\ndef circular_shift(x: np.ndarray, s: int) -> np.ndarray:\n    \"\"\"Implements the circular shift operator T_s.\n    (T_s x)[n] = x[(n - s) mod N]\n    This corresponds to a right shift by s.\n    \"\"\"\n    return np.roll(x, s)\n\ndef corr_circ(x: np.ndarray, w: np.ndarray) -> np.ndarray:\n    \"\"\"Implements 1D circularly padded cross-correlation.\n    (Corr_circ(x,w))[n] = sum_{m=0}^{M-1} w[m] x[(n + m - c) mod N]\n    \"\"\"\n    N = len(x)\n    M = len(w)\n    c = (M - 1) // 2\n    y = np.zeros(N, dtype=float)\n    for n in range(N):\n        val = 0.0\n        for m in range(M):\n            idx = (n + m - c) % N\n            val += w[m] * x[idx]\n        y[n] = val\n    return y\n\ndef corr_zero(x: np.ndarray, w: np.ndarray) -> np.ndarray:\n    \"\"\"Implements 1D zero-padded cross-correlation.\n    (Corr_0(x,w))[n] = sum_{m=0}^{M-1} w[m] x[n + m - c] * 1(0 = n+m-c  N)\n    \"\"\"\n    N = len(x)\n    M = len(w)\n    c = (M - 1) // 2\n    y = np.zeros(N, dtype=float)\n    for n in range(N):\n        val = 0.0\n        for m in range(M):\n            idx = n + m - c\n            if 0 = idx  N:\n                val += w[m] * x[idx]\n        y[n] = val\n    return y\n\ndef calculate_equivariance_error(x, w, s):\n    \"\"\"\n    Calculates the equivariance errors ε_circ and ε_0 for a given\n    input signal x, kernel w, and shift s.\n    \"\"\"\n    # Circular Padding Case\n    x_shifted = circular_shift(x, s)\n    y_corr_of_shifted = corr_circ(x_shifted, w)\n    \n    y = corr_circ(x, w)\n    y_shifted_of_corr = circular_shift(y, s)\n    \n    eps_circ = np.max(np.abs(y_corr_of_shifted - y_shifted_of_corr))\n\n    # Zero Padding Case\n    # x_shifted is the same\n    y_corr_of_shifted_zero = corr_zero(x_shifted, w)\n\n    y_zero = corr_zero(x, w)\n    y_shifted_of_corr_zero = circular_shift(y_zero, s)\n    \n    eps_zero = np.max(np.abs(y_corr_of_shifted_zero - y_shifted_of_corr_zero))\n    \n    return eps_circ, eps_zero\n\ndef solve():\n    \"\"\"\n    Defines the test cases, computes the equivariance errors for each,\n    and prints the results in the specified format.\n    \"\"\"\n    \n    # Define test cases\n    case1 = (np.array([0,1,2,3,4,5,6,7], dtype=float), np.array([1,0,-1], dtype=float), 2)\n    \n    N2 = 8\n    n2 = np.arange(N2)\n    x2 = np.sin(2 * np.pi * n2 / N2)\n    w2 = np.array([1,2,3,2,1], dtype=float) / 9.0\n    case2 = (x2, w2, 3)\n\n    case3 = (np.array([1,0,0,0,0], dtype=float), np.array([-1,0,2], dtype=float), 4)\n\n    case4 = (np.array([0.2,-0.1,0.5,-0.3,0.7,-0.2,0.0], dtype=float), np.array([0.25,0.5,0.25], dtype=float), 0)\n\n    N5 = 9\n    n5 = np.arange(N5)\n    x5 = np.cos(2 * np.pi * n5 / N5)\n    w5 = np.array([1,-1,0,1,-1], dtype=float)\n    case5 = (x5, w5, 4)\n\n    case6 = (np.array([1,-1,1,-1,1,-1,1,-1], dtype=float), np.array([2,-1,0,1,-2,1,0], dtype=float), 1)\n\n    test_cases = [case1, case2, case3, case4, case5, case6]\n    \n    results = []\n    for x, w, s in test_cases:\n        eps_circ, eps_zero = calculate_equivariance_error(x, w, s)\n        results.append(eps_circ)\n        results.append(eps_zero)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在卷积神经网络中，除了卷积层的填充策略，非线性的下采样操作（如下采样）是破坏平移等变性的另一个主要因素，其中最大池化（max pooling）尤为典型。最大池化的输出对输入特征相对于池化网格的精确位置高度敏感，微小的输入平移可能导致输出发生剧烈且非线性的变化。本练习  设计了一个巧妙的实验，通过在棋盘格输入上系统地改变“相位”，来量化这种由特征与池化网格对齐方式引起的等变性破坏。你将学习并计算一个名为“交换子模长”（commutator magnitude）$M(x; \\Delta u,\\Delta v)$ 的指标，它是一个用以衡量这种非线性效应的强大数学工具。",
            "id": "3196094",
            "problem": "您的任务是使用合成棋盘格输入，量化由卷积神经网络 (CNN) 流水线中的最大池化所引起的平移等变性破坏。该评估必须通过计算一个对易子幅度来完成，该幅度比较了在流水线之前应用空间位移与在流水线之后应用相应的下采样位移之间的差异。该流水线由循环卷积、修正线性单元 (ReLU) 和非重叠最大池化组成。您需要系统地改变棋盘格输入相对于池化网格的相位，并对对易子幅度进行聚合。\n\n定义与设置：\n- 设输入为大小为 $N \\times N$ 的方形图像，具有周期性边界条件（循环包裹）。\n- 将图像 $x$ 上的循环平移算子 $T_{(\\Delta u,\\Delta v)}$ 定义为\n$$\n(T_{(\\Delta u,\\Delta v)} x)[u,v] \\;=\\; x[(u-\\Delta u) \\bmod N,\\; (v-\\Delta v) \\bmod N].\n$$\n- 将核为 $K$ 的循环卷积算子 $C_K$ 定义为\n$$\n(C_K x)[u,v] \\;=\\; \\sum_{m}\\sum_{n} K[m,n]\\; x[(u-m) \\bmod N,\\; (v-n) \\bmod N].\n$$\n- 将逐点的修正线性单元 (ReLU) $\\phi$ 定义为\n$$\n\\phi(z) \\;=\\; \\max(0,z).\n$$\n- 将在 $N \\times N$ 输入（假设 $N$ 可被 $s$ 整除）上，窗口大小为 $s \\times s$、步幅为 $s$ 的非重叠最大池化定义为算子 $P_s$，其产生大小为 $(N/s) \\times (N/s)$ 的输出：\n$$\n(P_s x)[i,j] \\;=\\; \\max_{0 \\le a  s,\\; 0 \\le b  s} \\; x[i s + a,\\; j s + b],\n$$\n其中索引按常规数组方式计算，并依赖于 $N$ 可被 $s$ 整除这一事实（每个池化窗口内无需边界包裹）。\n- 将作用于大小为 $(N/s)\\times(N/s)$ 的池化输出的下采样位移算子 $U_{(\\delta_u,\\delta_v)}$ 定义为\n$$\n(U_{(\\delta_u,\\delta_v)} y)[i,j] \\;=\\; y[(i-\\delta_u) \\bmod (N/s), \\; (j-\\delta_v) \\bmod (N/s)].\n$$\n- 将复合 CNN 算子 $F$ 定义为\n$$\nF \\;=\\; P_s \\circ \\phi \\circ C_K.\n$$\n- 对于任意输入 $x$ 和整数输入空间位移 $(\\Delta u,\\Delta v)$，将相应的输出空间位移定义为\n$$\n(\\delta_u,\\delta_v) \\;=\\; \\left(\\left\\lfloor \\frac{\\Delta u}{s} \\right\\rfloor, \\; \\left\\lfloor \\frac{\\Delta v}{s} \\right\\rfloor \\right).\n$$\n- 将对易子幅度（归一化）定义为\n$$\nM(x; \\Delta u,\\Delta v) \\;=\\; \\frac{\\left\\| F\\left(T_{(\\Delta u,\\Delta v)} x\\right) \\;-\\; U_{(\\delta_u,\\delta_v)}\\left(F(x)\\right) \\right\\|_2}{\\left\\| F(x) \\right\\|_2 + \\varepsilon},\n$$\n其中 $\\|\\cdot\\|_2$ 是池化输出上的欧几里得范数，$\\varepsilon$ 是一个用于避免除以零的小的正数常量。\n\n输入生成与相位扫描：\n- 使用周期为 $2$ 的二元棋盘格图案：\n$$\nB[u,v] \\;=\\; \\mathbf{1}\\left\\{ \\left((u+v) \\bmod 2\\right) = 0 \\right\\},\n$$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n- 将相对于池化网格的相位偏移输入定义为\n$$\nB_{p,q}[u,v] \\;=\\; B[(u+p) \\bmod N,\\; (v+q) \\bmod N],\n$$\n对于所有整数相位 $p \\in \\{0,1,\\dots,s-1\\}$ 和 $q \\in \\{0,1,\\dots,s-1\\}$。\n\n核：\n- 使用一个固定的 $3 \\times 3$ 水平方向 Sobel 核，\n$$\nK \\;=\\; \\begin{bmatrix}\n-1  0  1 \\\\\n-2  0  2 \\\\\n-1  0  1\n\\end{bmatrix}.\n$$\n\n任务：\n1. 实现如上定义的 $T_{(\\Delta u,\\Delta v)}$、$C_K$（带循环边界条件）、$\\phi$、$P_s$ 和 $U_{(\\delta_u,\\delta_v)}$。\n2. 对于下面的每个测试用例，生成所有 $s \\times s$ 个相位偏移的输入 $B_{p,q}$，为每个 $(p,q)$ 计算 $M(B_{p,q}; \\Delta u,\\Delta v)$，并通过计算以下值进行聚合：\n   - 所有相位的平均值，\n   - 所有相位的最大值。\n3. 为保证数值稳定性，在 $M$ 的定义中使用 $\\varepsilon = 10^{-12}$。\n4. 将每个聚合后的浮点数四舍五入到 $6$ 位小数。\n\n测试套件：\n- 所有用例均使用上述 Sobel 核 $K$。对于每个用例，$N$ 是输入大小，$s$ 是池化步幅/窗口，$(\\Delta u,\\Delta v)$ 是输入空间位移。\n  1. 用例 A: $N=24$, $s=2$, $(\\Delta u,\\Delta v) = (1,0)$。\n  2. 用例 B: $N=24$, $s=2$, $(\\Delta u,\\Delta v) = (2,0)$。\n  3. 用例 C: $N=24$, $s=3$, $(\\Delta u,\\Delta v) = (1,1)$。\n  4. 用例 D: $N=24$, $s=3$, $(\\Delta u,\\Delta v) = (3,0)$。\n  5. 用例 E: $N=24$, $s=3$, $(\\Delta u,\\Delta v) = (0,0)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果是一个双元素列表 $[\\text{mean}, \\text{max}]$，并按上述用例的顺序排列。例如，输出必须如下所示：\n$$\n\\big[ [m_A, M_A], [m_B, M_B], [m_C, M_C], [m_D, M_D], [m_E, M_E] \\big],\n$$\n其中每个浮点数都四舍五入到 $6$ 位小数。",
            "solution": "### 原理与方法\n\n这个问题的核心是量化一个简单的CNN流水线在多大程度上不具备平移等变性。如果对输入进行平移会得到一个相应平移的输出，那么算子 $F$ 就被称为是平移等变的。形式上，对于一个平移算子 $T_\\Delta$，必须存在一个相应的输出空间平移算子 $U_\\delta$，使得对于任何输入 $x$，都有 $F(T_\\Delta x) = U_\\delta(F(x))$。如果此等式不成立，等变性就被破坏了。\n\n非等变性的程度可以通过流水线算子 $F$ 和平移算子 $T$ 之间的对易子幅度来衡量。对易子 $[F, U]$ 定义为 $F \\circ T - U \\circ F$。如果这些算子完全交换（即系统是完全等变的），则将此对易子应用于输入 $x$ 的结果将为零。一个非零的结果标志着等变性的破坏。问题中定义了这个对易子的归一化幅度：\n$$\nM(x; \\Delta u,\\Delta v) = \\frac{\\left\\| F\\left(T_{(\\Delta u,\\Delta v)} x\\right) - U_{(\\delta_u,\\delta_v)}\\left(F(x)\\right) \\right\\|_2}{\\left\\| F(x) \\right\\|_2 + \\varepsilon}\n$$\n在这里，$F(T_{(\\Delta u,\\Delta v)} x)$ 表示“先平移后处理”的路径，而 $U_{(\\delta_u,\\delta_v)}(F(x))$ 表示“先处理后平移”的路径。这两条路径之间的差异就是等变性的破坏程度。\n\nCNN流水线 $F = P_s \\circ \\phi \\circ C_K$ 由三个阶段组成：\n1.  **循环卷积 ($C_K$)**：此操作是完全平移等变的。对平移后的信号进行卷积与对卷积后的信号进行平移是相同的。\n2.  **ReLU ($\\phi$)**：此逐点激活函数也是完全平移等变的。在平移之前或之后应用它会产生相同的结果。\n3.  **最大池化 ($P_s$)**：这是等变性破坏的来源。最大池化仅对那些是其步幅 $s$ 整数倍的平移是等变的。对于任何其他平移值（“子步幅”平移），输出会以一种非线性的方式改变，这种改变无法通过对未平移输出的简单平移来描述。这些算子的复合导致流水线 $F$ 在通常情况下不是平移等变的。\n\n输入信号是一个合成的棋盘格图案。通过系统地改变其相对于固定池化网格的相位 $(p, q)$，我们可以评估在所有可能的输入对齐方式下的等变性破坏。这一点至关重要，因为破坏的幅度高度依赖于信号的高频分量如何与池化窗口的边界对齐。对所有相位的对易子幅度求平均，为给定输入平移 $(\\Delta u, \\Delta v)$ 提供了一个关于流水线缺乏等变性的鲁棒聚合度量。\n\n### 算法实现\n\n对于每个测试用例，该解决方案通过以下步骤实现：\n\n1.  **定义算子**：为每个指定的数学算子创建函数：\n    *   `circular_translate` ($T$ 和 $U$)：使用 `numpy.roll` 实现，它在给定轴上执行所需的循环平移。\n    *   `circular_convolve` ($C_K$)：使用 `scipy.signal.convolve2d` 实现，并设置 `mode='same'` 和 `boundary='wrap'` 以匹配循环卷积的定义。\n    *   `relu` ($\\phi$)：使用 `numpy.maximum` 实现，它执行逐元素操作 $\\max(0,z)$。\n    *   `max_pool` ($P_s$)：通过将 $N \\times N$ 输入数组重塑为 $(N/s, s, N/s, s)$ 的块，然后取每个 $s \\times s$ 块内的最大值来实现。\n\n2.  **定义CNN流水线 ($F$)**：一个 `cnn_pipeline` 函数按指定顺序复合上述算子：$F(x) = P_s(\\phi(C_K(x)))$。\n\n3.  **相位扫描与对易子计算**：\n    *   生成一个大小为 $N \\times N$ 的基础棋盘格图案 $B$。\n    *   一个嵌套循环遍历所有可能的输入相位 $p, q \\in \\{0, 1, \\dots, s-1\\}$。\n    *   在每次迭代中，通过对基础棋盘格应用 `circular_translate` 来创建相位偏移的输入 $x = B_{p,q}$。\n    *   计算两条路径：\n        *   路径 1 (先平移后处理): `F_Tx = cnn_pipeline(circular_translate(x, du, dv), ...)`\n        *   路径 2 (先处理后平移): `Fx = cnn_pipeline(x, ...)`, `delta_u = du // s`, `delta_v = dv // s`, `U_Fx = downsampled_shift(Fx, delta_u, delta_v)`\n    *   使用 `numpy.linalg.norm` 计算差值 `F_Tx - U_Fx` 和基线 `Fx` 的L2范数。\n    *   根据公式计算对易子幅度 $M$，使用提供的 $\\varepsilon = 10^{-12}$。存储所有相位的计算幅度。\n\n4.  **聚合与输出**：\n    *   在遍历完一个给定测试用例的所有相位后，使用 `numpy.mean` 和 `numpy.max` 计算收集到的对易子幅度的平均值和最大值。\n    *   将这两个聚合值格式化为6位小数并存储。\n    *   最后，将所有测试用例的结果格式化为指定的字符串格式 `[[mean_A, max_A], [mean_B, max_B], ...]` 并打印到标准输出。\n\n这个设计将问题的数学公式直接转化为一个可验证的数值实验。一个健全性检查是，当输入位移 $(\\Delta u, \\Delta v)$ 是池化步幅 $s$ 的整数倍或为零时，对易子幅度应为0.0，这证实了在此背景下对等变性的理论理解。",
            "answer": "```python\nimport numpy as np\nfrom scipy.signal import convolve2d\n\ndef solve():\n    \"\"\"\n    Computes the mean and maximum commutator magnitudes to quantify translation\n    equivariance breaks in a simple CNN pipeline for a suite of test cases.\n    \"\"\"\n\n    def circular_translate(x: np.ndarray, du: int, dv: int) -> np.ndarray:\n        \"\"\"\n        Applies a circular translation T_{(\\Delta u, \\Delta v)} to an image x.\n        (T_(\\Delta u,\\Delta v) x)[u,v] = x[(u-\\Delta u) mod N, (v-\\Delta v) mod N]\n        \"\"\"\n        return np.roll(x, shift=(du, dv), axis=(0, 1))\n\n    def circular_convolve(x: np.ndarray, K: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Applies circular convolution C_K with kernel K to an image x.\n        \"\"\"\n        return convolve2d(x, K, mode='same', boundary='wrap')\n\n    def relu(x: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Applies the pointwise Rectified Linear Unit (ReLU) function.\n        \"\"\"\n        return np.maximum(0, x)\n\n    def max_pool(x: np.ndarray, s: int) -> np.ndarray:\n        \"\"\"\n        Applies non-overlapping max pooling P_s with window size s x s.\n        \"\"\"\n        N = x.shape[0]\n        N_out = N // s\n        reshaped = x.reshape(N_out, s, N_out, s)\n        # Swap axes to group pooling windows together: (N_out, N_out, s, s)\n        pooled = reshaped.swapaxes(1, 2)\n        return pooled.max(axis=(2, 3))\n\n    def downsampled_shift(y: np.ndarray, du: int, dv: int) -> np.ndarray:\n        \"\"\"\n        Applies a circular translation U_{(\\delta_u, \\delta_v)} on a pooled output.\n        \"\"\"\n        return np.roll(y, shift=(du, dv), axis=(0, 1))\n\n    def cnn_pipeline(x: np.ndarray, K: np.ndarray, s: int) -> np.ndarray:\n        \"\"\"\n        Computes the full pipeline F = P_s o phi o C_K.\n        \"\"\"\n        convolved = circular_convolve(x, K)\n        activated = relu(convolved)\n        pooled = max_pool(activated, s)\n        return pooled\n\n    def generate_checkerboard(N: int) -> np.ndarray:\n        \"\"\"\n        Generates a binary checkerboard pattern of size N x N.\n        \"\"\"\n        u, v = np.meshgrid(np.arange(N), np.arange(N), indexing='ij')\n        board = ((u + v) % 2) == 0\n        return board.astype(float)\n\n    test_cases = [\n        # (N, s, (du, dv))\n        (24, 2, (1, 0)),  # Case A\n        (24, 2, (2, 0)),  # Case B\n        (24, 3, (1, 1)),  # Case C\n        (24, 3, (3, 0)),  # Case D\n        (24, 3, (0, 0)),  # Case E\n    ]\n    \n    K = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=float)\n    epsilon = 1e-12\n    \n    final_results = []\n    \n    for case_params in test_cases:\n        N, s, (du, dv) = case_params\n        \n        commutator_magnitudes = []\n        base_board = generate_checkerboard(N)\n        \n        for p in range(s):\n            for q in range(s):\n                # 1. Generate phase-shifted input x = B_{p,q}\n                x = circular_translate(base_board, p, q)\n                \n                # 2. Compute \"shift-then-process\" path: F(T(x))\n                shifted_x = circular_translate(x, du, dv)\n                F_Tx = cnn_pipeline(shifted_x, K, s)\n                \n                # 3. Compute \"process-then-shift\" path: U(F(x))\n                Fx = cnn_pipeline(x, K, s)\n                delta_u = du // s\n                delta_v = dv // s\n                U_Fx = downsampled_shift(Fx, delta_u, delta_v)\n                \n                # 4. Calculate the commutator magnitude M(x; du, dv)\n                norm_diff = np.linalg.norm(F_Tx - U_Fx)\n                norm_Fx = np.linalg.norm(Fx)\n                \n                M = norm_diff / (norm_Fx + epsilon)\n                commutator_magnitudes.append(M)\n        \n        # 5. Aggregate results (mean and max) for the test case\n        mean_M = np.mean(commutator_magnitudes)\n        max_M = np.max(commutator_magnitudes)\n        \n        final_results.append([mean_M, max_M])\n        \n    # 6. Format and print the final output\n    formatted_pairs = []\n    for mean_val, max_val in final_results:\n        formatted_pairs.append(f\"[{mean_val:.6f}, {max_val:.6f}]\")\n    \n    print(f\"[{', '.join(formatted_pairs)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在真实的CNN架构中，多种因素（如填充、卷积步幅和池化）共同作用，决定了网络整体的平移等变性程度。为了评估和比较不同设计的优劣，我们需要一个超越单个组件分析的整体性度量。这个综合性练习  将指导你构建并实现一个“等变性鲁棒性”指标 $\\text{ER}(A)$，将前面学到的知识融会贯通。你将通过对一系列不同平移量 $\\boldsymbol{\\delta}$ 所产生的等变性误差 $E_A(\\boldsymbol{\\delta})$进行平均，从而为整个网络架构的鲁棒性给出一个量化分数。这项实践使你能够定量比较不同架构选择（如步幅为1 vs 步幅为2，或使用最大池化）的影响，从而在网络设计中就如何保持关键的等变性做出更明智的决策。",
            "id": "3196087",
            "problem": "要求您形式化并实现一个用于量化卷积神经网络（CNNs）中平移等变性鲁棒性的指标，该指标通过在一组平移上聚合等变性误差来计算。您的实现必须是一个完整的、可运行的程序，为多种架构选择计算该指标，并输出单行报告。\n\n起点：使用二维信号上的离散卷积、离散平移算子以及“单位步幅且无边界效应的卷积具有平移等变性”这一概念的基本定义。明确地说，对于一个离散二维信号 $x[\\cdot,\\cdot]$、一个滤波器 $h[\\cdot,\\cdot]$ 以及一个具有位移 $\\boldsymbol{\\delta} = (\\delta_x,\\delta_y)$（以像素为单位）的离散平移算子 $T_{\\boldsymbol{\\delta}}$，经典的线性时不变系统理论断言，在没有边界和子采样的情况下，卷积与平移是可交换的。然而，在具有特定填充、步幅和池化的有限图像中，边界效应和子采样会破坏精确的等变性。目标是形式化一个误差 $E(\\boldsymbol{\\delta})$，用于衡量给定架构偏离等变性的程度，然后在一组位移上对该误差进行积分，从而为每个架构获得一个单一的鲁棒性数值。\n\n您的程序必须执行以下操作。\n\n1) 将大小为 $16 \\times 16$ 的离散输入图像 $x[n,m]$ 定义为\n$$\nx[n,m] = \\sin\\!\\left(\\tfrac{2\\pi n}{16}\\right) + 0.5 \\cos\\!\\left(\\tfrac{2\\pi m}{16}\\right) + 0.1 n + 0.05 m,\n$$\n适用于所有整数索引 $n \\in \\{0,1,\\dots,15\\}$ 和 $m \\in \\{0,1,\\dots,15\\}$。角度以弧度为单位。\n\n2) 使用以下 $3 \\times 3$ 卷积核（互相关形式，不翻转）：\n$$\nh = \\frac{1}{8}\\begin{bmatrix}\n1  0  -1 \\\\\n2  0  -2 \\\\\n1  0  -1\n\\end{bmatrix}.\n$$\n\n3) 实现一个单层CNN块，包括：\n- 一次二维互相关，其整数步幅为 $s \\in \\mathbb{N}$，填充策略为 $\\{\\text{same},\\text{valid}\\}$，其中“same”表示对于大小为 $k$ 的卷积核，在每侧进行 $\\lfloor k/2 \\rfloor$ 的零填充，“valid”表示不进行填充，\n- 一个逐点修正线性单元（ReLU），\n- 一个可选的 $2 \\times 2$ 池化层，步幅为 $2$，使用最大池化或平均池化，或者不进行池化。当存在池化层时，在ReLU之后应用它。\n\n4) 将 $x$ 上的离散循环平移算子 $T_{\\boldsymbol{\\delta}}$ 定义为沿列循环平移 $\\delta_x$ 像素，沿行循环平移 $\\delta_y$ 像素（对信号大小取模）。在对齐以进行比较时，对输入和输出都应用循环平移。\n\n5) 对于给定的架构 $A$，定义其前向映射 $F_A(\\cdot)$。令有效下采样因子为\n$$\nS_{\\text{eff}} = s \\times S_{\\text{pool}},\n$$\n其中 $s$ 是卷积步幅，$S_{\\text{pool}} \\in \\{1,2\\}$ 是池化步幅（当不使用池化时 $S_{\\text{pool}} = 1$，对于 $2\\times 2$ 池化则为 $S_{\\text{pool}} = 2$）。对于下面测试套件中的每个位移 $\\boldsymbol{\\delta} = (\\delta_x,\\delta_y)$，定义输出网格对齐位移\n$$\n\\boldsymbol{\\delta}_{\\text{out}} = \\left(\\left\\lfloor \\frac{\\delta_x}{S_{\\text{eff}}} \\right\\rfloor, \\left\\lfloor \\frac{\\delta_y}{S_{\\text{eff}}} \\right\\rfloor\\right).\n$$\n\n6) 对于架构 $A$，将其等变性误差 $E_A(\\boldsymbol{\\delta})$ 定义为移位后输入的输出与未移位输入的经适当移位的输出之间的归一化差异，\n$$\nE_A(\\boldsymbol{\\delta}) = \\frac{\\left\\| F_A\\!\\left(T_{\\boldsymbol{\\delta}} x\\right) - T_{\\boldsymbol{\\delta}_{\\text{out}}} \\left(F_A(x)\\right) \\right\\|_F}{\\left\\| F_A(x) \\right\\|_F + 10^{-12}},\n$$\n其中 $\\|\\cdot\\|_F$ 是弗罗贝尼乌斯范数。这种归一化使得 $E_A(\\boldsymbol{\\delta})$ 无量纲。\n\n7) 将架构 $A$ 的等变性鲁棒性指标定义为 $E_A(\\boldsymbol{\\delta})$ 在以下位移集合上的均匀平均值（一个在离散集上近似积分的黎曼和）：\n$$\n\\Delta = \\{ (0,0), (1,0), (0,1), (1,1), (2,0), (0,2), (3,1), (1,3) \\}.\n$$\n明确地，\n$$\n\\text{ER}(A) = \\frac{1}{|\\Delta|} \\sum_{\\boldsymbol{\\delta} \\in \\Delta} E_A(\\boldsymbol{\\delta}).\n$$\n\n8) 为以下四种架构中的每一种计算 $\\text{ER}(A)$。每个架构被指定为一个元组 $(s, \\text{padding}, \\text{pool})$，其中 $s$ 是卷积步幅，$\\text{padding} \\in \\{\\text{same},\\text{valid}\\}$，$\\text{pool} \\in \\{\\text{none},\\text{max},\\text{avg}\\}$：\n- $A_1 = (1, \\text{same}, \\text{none})$，\n- $A_2 = (2, \\text{same}, \\text{none})$，\n- $A_3 = (1, \\text{valid}, \\text{none})$，\n- $A_4 = (1, \\text{same}, \\text{max})$，使用 $2 \\times 2$ 最大池化，步幅为 $2$。\n\n9) 您的程序应生成单行输出，其中包含四个值 $[\\text{ER}(A_1), \\text{ER}(A_2), \\text{ER}(A_3), \\text{ER}(A_4)]$，以逗号分隔的列表形式，并用方括号括起来。每个值必须是四舍五入到六位小数的浮点数。例如，输出行应如下所示\n$$\n[\\alpha_1,\\alpha_2,\\alpha_3,\\alpha_4],\n$$\n其中每个 $\\alpha_i$ 是一个在小数点后恰好有六位数字的十进制字符串。\n\n此问题无需外部输入，且不涉及物理单位；所有量均为无量纲。测试套件是上面指定的固定架构集 $A_1$–$A_4$ 和位移集 $\\Delta$。您的实现必须是自包含且确定性的。",
            "solution": "该问题要求我们实现一个“等变性鲁棒性”指标 $\\text{ER}(A)$，以量化和比较不同CNN架构 $A$ 对平移操作的响应。这个指标的核心思想是测量网络输出在输入平移时偏离“理想”等变行为的程度，并在多个不同平移上取平均，从而得到一个单一、稳健的分数。\n\n### 原理分析\n\n一个理想的平移等变系统 $F$ 满足 $F(T_{\\boldsymbol{\\delta}}x) = T'_{\\boldsymbol{\\delta}}(F(x))$，其中 $T$ 和 $T'$ 是输入和输出空间上的平移算子。然而，在实际的CNN中，由于以下几个因素，这种完美的等变性会被打破：\n1.  **填充（Padding）**：'same'填充在图像边界引入零值，当特征平移到边界时，其计算方式会发生改变。'valid'填充则直接裁剪边界，导致输出尺寸减小，并且完全丢失了边界信息，从根本上改变了信号的结构。\n2.  **步幅（Stride）**：大于1的步幅 $s$ 会进行下采样。一个1像素的输入平移可能不会在输出网格上产生任何变化，或者可能导致特征跳到下一个网格点，从而破坏了平滑的等变响应。\n3.  **池化（Pooling）**：像最大池化这样的非线性下采样操作对特征在池化窗口内的精确位置非常敏感，微小的输入平移可能导致输出值发生剧烈变化。\n\n本问题中的等变性误差 $E_A(\\boldsymbol{\\delta})$ 正是用来量化这种偏差。它计算了“先平移输入再通过网络” ($F_A(T_{\\boldsymbol{\\delta}} x)$) 和“先通过网络再平移输出” ($T_{\\boldsymbol{\\delta}_{\\text{out}}} (F_A(x))$) 这两条路径结果之间的差异。\n\n*   **输出平移对齐**：注意到输出的平移量 $\\boldsymbol{\\delta}_{\\text{out}}$ 是通过输入平移量 $\\boldsymbol{\\delta}$ 除以有效下采样因子 $S_{\\text{eff}}$ 并取整得到的。这是至关重要的，因为它正确地将输入空间中的像素级平移映射到了下采样后的输出特征图空间中的网格级平移。\n*   **归一化**：通过除以原始输出的范数 $\\|F_A(x)\\|_F$，误差 $E_A(\\boldsymbol{\\delta})$ 变成了一个相对值，使得不同架构（可能产生不同幅度的输出）之间的比较更加公平。\n\n### 算法流程\n\n为了计算每个架构 $A$ 的 $\\text{ER}(A)$，我们遵循以下步骤：\n1.  **初始化**：生成指定的 $16 \\times 16$ 输入信号 $x$ 和卷积核 $h$。定义平移集合 $\\Delta$。\n2.  **为每个架构循环**：对于给定的架构 $A = (s, \\text{padding}, \\text{pool})$：\n    a.  **计算基准输出**：计算一次原始输入的前向传播结果 $F_A(x)$ 及其弗罗贝尼乌斯范数 $\\|F_A(x)\\|_F$。此范数在后续的所有误差计算中作为分母。\n    b.  **计算有效下采样因子** $S_{\\text{eff}}$。\n    c.  **为每个平移循环**：初始化一个累积误差 `total_error = 0`。对于平移集合 $\\Delta$ 中的每一个位移 $\\boldsymbol{\\delta}$：\n        i.  **路径1（先平移）**：对输入 $x$ 应用循环平移 $T_{\\boldsymbol{\\delta}}$ 得到 $x'$，然后计算其前向传播结果 $F_A(x')$。\n        ii. **路径2（后平移）**：根据 $\\boldsymbol{\\delta}$ 和 $S_{\\text{eff}}$ 计算输出平移量 $\\boldsymbol{\\delta}_{\\text{out}}$。然后对基准输出 $F_A(x)$ 应用循环平移 $T_{\\boldsymbol{\\delta}_{\\text{out}}}$。\n        iii. **计算误差**：计算两条路径结果之差的弗罗贝尼乌斯范数，并除以基准范数 $\\|F_A(x)\\|_F$，得到 $E_A(\\boldsymbol{\\delta})$。\n        iv. **累积误差**：将 $E_A(\\boldsymbol{\\delta})$ 加到 `total_error`。\n    d.  **计算平均误差**：将 `total_error` 除以平移集合的大小 $|\\Delta|$，得到最终的鲁棒性指标 $\\text{ER}(A)$。\n3.  **收集并输出**：收集所有架构的 $\\text{ER}(A)$ 值，并按指定格式输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes a translation equivariance robustness metric for several CNN architectures.\n    \"\"\"\n\n    # 1. Define input signal and kernel as per the problem statement.\n    def generate_input_image():\n        \"\"\"Generates the 16x16 input image x[n,m].\"\"\"\n        N = 16\n        n, m = np.mgrid[0:N, 0:N]\n        x = np.sin(2 * np.pi * n / N) + 0.5 * np.cos(2 * np.pi * m / N) + 0.1 * n + 0.05 * m\n        return x\n\n    def get_kernel():\n        \"\"\"Returns the 3x3 convolution kernel h.\"\"\"\n        h = np.array([\n            [1, 0, -1],\n            [2, 0, -2],\n            [1, 0, -1]\n        ]) / 8.0\n        return h\n\n    # 2. Implement the fundamental operators.\n    def circular_translate(image, delta):\n        \"\"\"\n        Applies a circular translation T_delta to an image.\n        delta = (delta_x, delta_y), where delta_x is column shift and delta_y is row shift.\n        \"\"\"\n        delta_x, delta_y = delta\n        # np.roll shifts along axes: axis 0 is rows (y), axis 1 is columns (x).\n        return np.roll(image, shift=(delta_y, delta_x), axis=(0, 1))\n\n    def convolve2d(image, kernel, stride, padding):\n        \"\"\"\n        Performs 2D cross-correlation with specified stride and padding.\n        \"\"\"\n        k_h, k_w = kernel.shape\n        img_h, img_w = image.shape\n\n        if padding == 'same':\n            pad_h = k_h // 2\n            pad_w = k_w // 2\n            padded_image = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant')\n        elif padding == 'valid':\n            padded_image = image\n        else:\n            raise ValueError(\"Unsupported padding type\")\n\n        padded_h, padded_w = padded_image.shape\n        \n        out_h = (padded_h - k_h) // stride + 1\n        out_w = (padded_w - k_w) // stride + 1\n        output = np.zeros((out_h, out_w))\n\n        for y in range(out_h):\n            for x in range(out_w):\n                y_start, x_start = y * stride, x * stride\n                patch = padded_image[y_start:y_start + k_h, x_start:x_start + k_w]\n                output[y, x] = np.sum(patch * kernel)\n        \n        return output\n\n    def pool2d(feature_map, pool_type):\n        \"\"\"\n        Performs 2x2 pooling with stride 2.\n        \"\"\"\n        pool_size, pool_stride = 2, 2\n        in_h, in_w = feature_map.shape\n        out_h = (in_h - pool_size) // pool_stride + 1\n        out_w = (in_w - pool_size) // pool_stride + 1\n        output = np.zeros((out_h, out_w))\n\n        op = np.max if pool_type == 'max' else np.mean\n\n        for y in range(out_h):\n            for x in range(out_w):\n                y_start, x_start = y * pool_stride, x * pool_stride\n                patch = feature_map[y_start:y_start + pool_size, x_start:x_start + pool_size]\n                output[y, x] = op(patch)\n        \n        return output\n\n    # 3. Define the forward pass for a given architecture.\n    def forward_pass(image, kernel, architecture):\n        \"\"\"\n        Computes the forward pass F_A(image) for a given architecture.\n        architecture = (stride, padding, pool_type)\n        \"\"\"\n        s, padding, pool_type = architecture\n        \n        # Convolution\n        y = convolve2d(image, kernel, s, padding)\n        \n        # ReLU\n        y = np.maximum(0, y)\n        \n        # Optional Pooling\n        if pool_type != 'none':\n            y = pool2d(y, pool_type)\n            \n        return y\n\n    # 4. Implement the full equivariance robustness metric ER(A).\n    def compute_equivariance_robustness(architecture, x, h, delta_set):\n        \"\"\"\n        Computes the ER(A) metric for a given architecture.\n        \"\"\"\n        # Calculate F_A(x) and its norm once\n        Fx = forward_pass(x, h, architecture)\n        norm_Fx = np.linalg.norm(Fx, 'fro') + 1e-12\n        \n        # Determine effective downsampling factor S_eff\n        s, _, pool_type = architecture\n        S_pool = 2 if pool_type != 'none' else 1\n        S_eff = s * S_pool\n        \n        total_error = 0.0\n        for delta in delta_set:\n            delta_x, delta_y = delta\n            \n            # Apply shift to input: T_delta(x)\n            x_shifted = circular_translate(x, (delta_x, delta_y))\n            \n            # Compute network output for shifted input: F_A(T_delta(x))\n            F_Tx = forward_pass(x_shifted, h, architecture)\n            \n            # Compute required output shift: delta_out\n            delta_out_x = delta_x // S_eff\n            delta_out_y = delta_y // S_eff\n            \n            # Apply shift to original output: T_{delta_out}(F_A(x))\n            T_Fx = circular_translate(Fx, (delta_out_x, delta_out_y))\n            \n            # Ensure dimensions match before subtraction\n            if F_Tx.shape != T_Fx.shape:\n                raise ValueError(f\"Shape mismatch: {F_Tx.shape} vs {T_Fx.shape}\")\n\n            # Compute the error for this shift E_A(delta)\n            error_norm = np.linalg.norm(F_Tx - T_Fx, 'fro')\n            E_A_delta = error_norm / norm_Fx\n            total_error += E_A_delta\n            \n        # Average the error over all shifts\n        ER_A = total_error / len(delta_set)\n        return ER_A\n\n    # Main execution block\n    # Define constants and test cases\n    x = generate_input_image()\n    h = get_kernel()\n    \n    delta_set = [(0, 0), (1, 0), (0, 1), (1, 1), (2, 0), (0, 2), (3, 1), (1, 3)]\n    \n    architectures = [\n        (1, 'same', 'none'),  # A1\n        (2, 'same', 'none'),  # A2\n        (1, 'valid', 'none'), # A3\n        (1, 'same', 'max')    # A4\n    ]\n    \n    # Calculate results for each architecture\n    results = []\n    for arch in architectures:\n        er_metric = compute_equivariance_robustness(arch, x, h, delta_set)\n        results.append(er_metric)\n\n    # Format and print the final output\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}