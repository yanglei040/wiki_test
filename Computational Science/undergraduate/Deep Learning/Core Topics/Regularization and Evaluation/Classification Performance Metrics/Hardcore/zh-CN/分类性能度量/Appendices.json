{
    "hands_on_practices": [
        {
            "introduction": "模型的性能不仅取决于其内在的判别能力，还与它所应用的数据环境息息相关。一个在验证集上表现优异的模型，部署到真实世界后可能会因为类别分布（即正类别的比例）的变化而性能下降。这个练习  将引导你从第一性原理出发，推导精确率和召回率如何受类别分布变化的影响，并学习如何重新调整决策阈值以在新环境下最大化 $F_1$ 分数，这是部署稳健分类系统的关键一步。",
            "id": "3105734",
            "problem": "一个用于深度学习管道的二元分类器会输出一个非负分数 $s$，分数越高表示属于正类的可能性越大。在验证集上，分类器的决策阈值 $\\tau$ 被选择用来最大化F1分数（F1），F1分数定义为精确率和召回率的调和平均数。部署后，类别流行度发生了变化。仅从混淆矩阵和标准分类指标的基本定义出发，推导当分数阈值固定时，精确率和召回率如何依赖于类别流行度，然后在新的流行度下重新调整阈值以最大化F1分数。\n\n假设分数 $s$ 遵循以下科学上合理的模型：\n- 正类的条件分数分布是率为 $\\lambda_{1}$ 的指数分布，即 $s \\mid y=1 \\sim \\text{Exp}(\\lambda_{1})$。\n- 负类的条件分数分布是率为 $\\lambda_{0}$ 的指数分布，即 $s \\mid y=0 \\sim \\text{Exp}(\\lambda_{0})$。\n\n决策规则规定，当且仅当 $s \\geq \\tau$ 时预测 $y=1$，否则预测 $y=0$。设验证集流行度为 $\\pi_{\\text{val}}$，部署集流行度为 $\\pi_{\\text{dep}}$。仅使用真阳性率、假阳性率、精确率、召回率和F1分数的核心定义来推导所需的表达式。\n\n具体地，使用参数 $\\lambda_{1}=1$，$\\lambda_{0}=2$，$\\pi_{\\text{val}}=0.4$ 和 $\\pi_{\\text{dep}}=0.2$ 进行计算：\n- 首先，仅使用定义，推导真阳性率和假阳性率作为 $\\tau$ 的函数的表达式。\n- 然后，推导精确率和召回率作为 $\\tau$ 和流行度 $\\pi$ 的函数的表达式。\n- 定性地解释，当流行度从 $\\pi_{\\text{val}}$ 变为 $\\pi_{\\text{dep}}$ 时，精确率和召回率中哪一个会改变，并说明原因。\n- 确定在 $\\pi_{\\text{val}}$ 下最大化F1分数的验证阈值 $\\tau_{\\text{val}}$。\n- 最后，计算在 $\\pi_{\\text{dep}}$ 下最大化F1分数的部署阈值 $\\tau_{\\text{dep}}$。\n\n将您的部署阈值 $\\tau_{\\text{dep}}$ 的最终数值答案四舍五入到四位有效数字。只提供 $\\tau_{\\text{dep}}$ 的数值作为您的最终答案。",
            "solution": "所述问题具有科学依据、提法恰当、客观且内部一致。这是一个应用于分类器评估的统计决策理论中的标准问题，使用了通用的定义和一个合理的、可形式化的分类器分数模型。所有必要的参数都已提供。因此，该问题是有效的，并将推导出一个解。\n\n解答按要求分为五个部分进行。\n\n首先，我们推导真阳性率（TPR）和假阳性率（FPR）作为决策阈值 $\\tau$ 的函数的表达式。根据定义，TPR，也称为召回率（Recall）或灵敏度（Sensitivity），是正类实例被正确分类为正类的概率。FPR是负类实例被错误分类为正类的概率。决策规则规定，如果一个样本的分数 $s$ 大于或等于阈值 $\\tau$，则将其分类为正类（$\\hat{y}=1$）。\n\n给定真实类别 $y$，TPR和FPR为：\n$$TPR(\\tau) = P(\\hat{y}=1 | y=1) = P(s \\geq \\tau | y=1)$$\n$$FPR(\\tau) = P(\\hat{y}=1 | y=0) = P(s \\geq \\tau | y=0)$$\n条件分数分布被给定为指数分布。对于一个随机变量 $X \\sim \\text{Exp}(\\lambda)$，其概率密度函数为 $f(x) = \\lambda e^{-\\lambda x}$（对于 $x \\geq 0$），其生存函数为 $P(X \\geq x) = e^{-\\lambda x}$。\n对于正类，$s \\mid y=1 \\sim \\text{Exp}(\\lambda_1)$。因此，TPR为：\n$$TPR(\\tau) = \\exp(-\\lambda_1 \\tau)$$\n对于负类，$s \\mid y=0 \\sim \\text{Exp}(\\lambda_0)$。因此，FPR为：\n$$FPR(\\tau) = \\exp(-\\lambda_0 \\tau)$$\n\n第二，我们推导精确率（PREC）和召回率（REC）作为 $\\tau$ 和类别流行度 $\\pi = P(y=1)$ 的函数的表达式。\n根据定义，召回率与真阳性率相同：\n$$REC(\\tau) = TPR(\\tau) = \\exp(-\\lambda_1 \\tau)$$\n精确率，或称阳性预测值（PPV），是在一个样本被分类为正类的条件下，该样本确实是正类的概率。使用贝叶斯定理：\n$$PREC(\\tau, \\pi) = P(y=1 | \\hat{y}=1) = \\frac{P(\\hat{y}=1 | y=1)P(y=1)}{P(\\hat{y}=1)}$$\n分子是 $TPR(\\tau) \\cdot \\pi$。分母可以使用全概率定律展开：\n$$P(\\hat{y}=1) = P(\\hat{y}=1 | y=1)P(y=1) + P(\\hat{y}=1 | y=0)P(y=0)$$\n$$P(\\hat{y}=1) = TPR(\\tau) \\cdot \\pi + FPR(\\tau) \\cdot (1-\\pi)$$\n将这些代入精确率的表达式中，得到：\n$$PREC(\\tau, \\pi) = \\frac{TPR(\\tau) \\cdot \\pi}{TPR(\\tau) \\cdot \\pi + FPR(\\tau) \\cdot (1-\\pi)}$$\n代入TPR和FPR的指数形式，我们得到最终的表达式：\n$$REC(\\tau) = \\exp(-\\lambda_1 \\tau)$$\n$$PREC(\\tau, \\pi) = \\frac{\\pi \\exp(-\\lambda_1 \\tau)}{\\pi \\exp(-\\lambda_1 \\tau) + (1-\\pi) \\exp(-\\lambda_0 \\tau)}$$\n\n第三，我们解释改变流行度的影响。\n召回率的表达式 $REC(\\tau) = \\exp(-\\lambda_1 \\tau)$ 不依赖于流行度 $\\pi$。召回率是衡量分类器在真实标签为正的条件下识别所有正类实例的能力。这个属性是分类器在正类上性能的内在属性，不受总体中正类实例比例的影响。\n相反，精确率的表达式清楚地显示了对 $\\pi$ 的依赖性。精确率衡量的是在所有正类预测中正确预测的比例。正类预测的集合由真阳性（来自正类）和假阳性（来自负类）组成。流行度 $\\pi$ 的变化改变了可用的正样本和负样本数量之间的平衡。如果 $\\pi$ 减小（如此处从 $\\pi_{\\text{val}}=0.4$ 降至 $\\pi_{\\text{dep}}=0.2$），负类将变得更加主导。对于固定的FPR，这会导致假阳性的绝对数量增加，从而稀释了预测为正类的集合，并因此降低了精确率。\n\n第四，我们确定最大化F1分数的最佳阈值 $\\tau$。F1分数是精确率和召回率的调和平均数：\n$$F1 = 2 \\frac{PREC \\cdot REC}{PREC + REC}$$\n最大化F1分数等同于最小化其倒数 $\\frac{1}{F1}$：\n$$\\frac{1}{F1} = \\frac{1}{2}\\left(\\frac{1}{PREC} + \\frac{1}{REC}\\right)$$\n我们定义一个函数 $f(\\tau) = \\frac{2}{F1(\\tau, \\pi)}$，并希望将其最小化。\n$$\\frac{1}{REC(\\tau)} = \\frac{1}{\\exp(-\\lambda_1 \\tau)} = \\exp(\\lambda_1 \\tau)$$\n$$\\frac{1}{PREC(\\tau, \\pi)} = \\frac{\\pi \\exp(-\\lambda_1 \\tau) + (1-\\pi) \\exp(-\\lambda_0 \\tau)}{\\pi \\exp(-\\lambda_1 \\tau)} = 1 + \\frac{1-\\pi}{\\pi} \\frac{\\exp(-\\lambda_0 \\tau)}{\\exp(-\\lambda_1 \\tau)} = 1 + \\frac{1-\\pi}{\\pi} \\exp((\\lambda_1 - \\lambda_0)\\tau)$$\n所以，要最小化的函数是：\n$$f(\\tau) = \\exp(\\lambda_1 \\tau) + 1 + \\frac{1-\\pi}{\\pi} \\exp((\\lambda_1 - \\lambda_0)\\tau)$$\n为了找到最小值，我们计算关于 $\\tau$ 的导数并将其设为零：\n$$\\frac{df}{d\\tau} = \\lambda_1 \\exp(\\lambda_1 \\tau) + \\frac{1-\\pi}{\\pi}(\\lambda_1 - \\lambda_0) \\exp((\\lambda_1 - \\lambda_0)\\tau) = 0$$\n$$\\lambda_1 \\exp(\\lambda_1 \\tau) = -\\frac{1-\\pi}{\\pi}(\\lambda_1 - \\lambda_0) \\exp((\\lambda_1 - \\lambda_0)\\tau)$$\n$$\\lambda_1 \\exp(\\lambda_1 \\tau) = \\frac{1-\\pi}{\\pi}(\\lambda_0 - \\lambda_1) \\exp(\\lambda_1 \\tau)\\exp(-\\lambda_0 \\tau)$$\n因为 $\\tau \\geq 0$，我们知道 $\\exp(\\lambda_1 \\tau) > 0$，所以可以除以它：\n$$\\lambda_1 = \\frac{1-\\pi}{\\pi}(\\lambda_0 - \\lambda_1) \\exp(-\\lambda_0 \\tau)$$\n现在，我们求解 $\\tau$：\n$$\\exp(-\\lambda_0 \\tau) = \\frac{\\pi \\lambda_1}{(1-\\pi)(\\lambda_0 - \\lambda_1)}$$\n$$-\\lambda_0 \\tau = \\ln\\left(\\frac{\\pi \\lambda_1}{(1-\\pi)(\\lambda_0 - \\lambda_1)}\\right)$$\n$$\\tau = -\\frac{1}{\\lambda_0} \\ln\\left(\\frac{\\pi \\lambda_1}{(1-\\pi)(\\lambda_0 - \\lambda_1)}\\right) = \\frac{1}{\\lambda_0} \\ln\\left(\\frac{(1-\\pi)(\\lambda_0 - \\lambda_1)}{\\pi \\lambda_1}\\right)$$\n这是最大化F1分数的阈值 $\\tau$ 的通用表达式。验证阈值 $\\tau_{\\text{val}}$ 是通过代入 $\\pi = \\pi_{\\text{val}} = 0.4$，$\\lambda_1 = 1$ 和 $\\lambda_0 = 2$ 得到的：\n$$\\tau_{\\text{val}} = \\frac{1}{2} \\ln\\left(\\frac{(1-0.4)(2-1)}{0.4 \\cdot 1}\\right) = \\frac{1}{2} \\ln\\left(\\frac{0.6}{0.4}\\right) = \\frac{1}{2} \\ln(1.5)$$\n\n最后，我们将部署流行度 $\\pi = \\pi_{\\text{dep}} = 0.2$ 代入 $\\tau$ 的通用表达式中，计算部署阈值 $\\tau_{\\text{dep}}$：\n$$\\tau_{\\text{dep}} = \\frac{1}{2} \\ln\\left(\\frac{(1-0.2)(2-1)}{0.2 \\cdot 1}\\right)$$\n$$\\tau_{\\text{dep}} = \\frac{1}{2} \\ln\\left(\\frac{0.8}{0.2}\\right) = \\frac{1}{2} \\ln(4)$$\n因为 $\\ln(4) = \\ln(2^2) = 2\\ln(2)$，表达式简化为：\n$$\\tau_{\\text{dep}} = \\frac{1}{2} (2\\ln(2)) = \\ln(2)$$\n其数值为 $\\tau_{\\text{dep}} \\approx 0.693147...$。四舍五入到四位有效数字得到 $0.6931$。",
            "answer": "$$\\boxed{0.6931}$$"
        },
        {
            "introduction": "早停（Early Stopping）是防止模型过拟合的重要正则化技术，但其效果好坏严重依赖于我们选择监控的验证指标。在处理类别不平衡的数据时，这个选择尤其关键。本练习  将通过一个模拟的训练过程，清晰地揭示为何在不平衡场景下，以准确率（Accuracy）为导向可能选出对少数类性能较差的模型，而 $F_1$ 分数则能引导我们获得更均衡、更实用的分类器。",
            "id": "3105763",
            "problem": "给定一个具有类别不平衡的二元分类验证场景和两种早停策略。目标是使用基于类别的条件正确率构建一个跨周期的确定性验证轨迹，从第一性原理推导性能指标，并针对每个测试用例判断，在验证集 $\\text{Accuracy}$ 上停止是否比在验证集 $\\text{F1}$ 上停止产生更差的少数类 $\\text{Recall}$。\n\n使用的基本定义：\n- 一个二元分类器在数据集上会产生真正例 (TP)、假正例 (FP)、真负例 (TN) 和假负例 (FN) 的计数；这些是定义性能指标的基础。\n- 需要从这些计数推导和实现的性能指标是：$\\text{Accuracy}$、$\\text{Precision}$、$\\text{Recall}$ 和 $\\text{F1}$-score (通常表示为 $\\text{F1}$)。\n\n验证轨迹生成：\n- 设验证样本总数为 $N$。\n- 设少数类（正类）的比例为 $r$，因此多数类（负类）的比例为 $1 - r$。\n- 轨迹跨越 $T$ 个周期，由 $t \\in \\{1,2,\\ldots,T\\}$ 索引。\n- 对于每个周期 $t$，定义两个基于类别的条件正确率：\n  - 负类的正确率 $p_n(t)$。\n  - 正类的正确率 $p_p(t)$。\n- 轨迹由带截断的线性趋势生成：\n  - $p_n(t)$ 遵循递减的线性趋势：从 $p_{n,0}$ 开始，每个周期步长以非负速率 $\\delta_n$ 变化，即 $p_n(t) = \\mathrm{clip}\\big(p_{n,0} - \\delta_n \\cdot (t - 1), 0, 1\\big)$。\n  - $p_p(t)$ 遵循递增的线性趋势：从 $p_{p,0}$ 开始，每个周期步长以非负速率 $\\delta_p$ 变化，即 $p_p(t) = \\mathrm{clip}\\big(p_{p,0} + \\delta_p \\cdot (t - 1), 0, 1\\big)$。\n- 此处 $\\mathrm{clip}(x,0,1)$ 表示将 $x$ 限制在区间 $[0,1]$ 内。\n\n计算要求：\n- 对于每个周期 $t$，将 $\\{p_n(t), p_p(t)\\}$ 分别视为负类和正类被正确分类的概率，并从第一性原理出发，以 $N_+ = r N$ 和 $N_- = (1 - r) N$ 作为期望的正负样本数，推导期望的混淆矩阵计数 $\\{TP(t), FP(t), TN(t), FN(t)\\}$。\n- 仅使用这些定义，推导并实现每个周期 $t$ 的 $\\text{Accuracy}(t)$、$\\text{Precision}(t)$、$\\text{Recall}(t)$ 和 $\\text{F1}(t)$，结果以 $[0,1]$ 区间内的小数表示。\n- 定义两种早停策略：\n  - 策略 $\\mathcal{A}$：在使验证集 $\\text{Accuracy}(t)$ 最大化的周期 $t$ 停止。\n  - 策略 $\\mathcal{F}$：在使验证集 $\\text{F1}(t)$ 最大化的周期 $t$ 停止。\n- 如果跨周期的最大值出现平局，则选择最早的周期（最小的 $t$）。\n- 对于每种策略，报告所选周期的少数类 $\\text{Recall}$，并进行比较。\n\n输出规范：\n- 对于每个测试用例，输出一个布尔值，指示策略 $\\mathcal{A}$ 下的少数类 $\\text{Recall}$ 是否严格低于策略 $\\mathcal{F}$ 下的少数类 $\\text{Recall}$。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 $[result_1,result_2,\\ldots]$）。每个 $result_i$ 必须是布尔值。\n\n所有指标必须以 $[0,1]$ 区间内的小数表示；请勿使用百分比。\n\n测试套件：\n使用以下四组参数集来实例化 $(N, r, T, p_{n,0}, \\delta_n, p_{p,0}, \\delta_p)$。\n\n- 案例 1 (理想路径，强不平衡和发散趋势):\n  - $N = 10000$, $r = 0.05$, $T = 12$, $p_{n,0} = 0.995$, $\\delta_n = 0.01$, $p_{p,0} = 0.20$, $\\delta_p = 0.06$。\n- 案例 2 (类别平衡):\n  - $N = 10000$, $r = 0.50$, $T = 12$, $p_{n,0} = 0.995$, $\\delta_n = 0.01$, $p_{p,0} = 0.20$, $\\delta_p = 0.06$。\n- 案例 3 (轻度不平衡，较缓和的趋势):\n  - $N = 10000$, $r = 0.20$, $T = 12$, $p_{n,0} = 0.99$, $\\delta_n = 0.005$, $p_{p,0} = 0.30$, $\\delta_p = 0.03$。\n- 案例 4 (边界情况，性能恒定):\n  - $N = 10000$, $r = 0.10$, $T = 12$, $p_{n,0} = 0.99$, $\\delta_n = 0.0$, $p_{p,0} = 0.10$, $\\delta_p = 0.0$。\n\n您的任务：\n- 实现上述的轨迹生成器和指标计算。\n- 对于每个案例，确定 $\\mathcal{A}$ 和 $\\mathcal{F}$ 的早停周期，提取相应的少数类 $\\text{Recall}$ 值，并以布尔值的形式输出 $\\text{Recall}_{\\mathcal{A}} < \\text{Recall}_{\\mathcal{F}}$ 是否成立。\n- 以以上描述的精确单行格式生成最终输出。",
            "solution": "该问题要求分析二元分类器的两种早停策略，这两种策略分别基于验证集的 Accuracy 和 F1-score。我们需要确定在 Accuracy 上停止是否比在 F1-score 上停止导致更差的少数类 Recall。该分析在一个由基于类别的条件正确率生成的确定性验证轨迹上进行。\n\n首先，我们通过按规定从第一性原理推导必要的指标来建立理论基础。\n\n设 $N$ 为验证集中的样本总数。\n设 $r$ 为少数类（正类）的比例。\n正样本的数量为 $N_+ = rN$。\n负样本的数量为 $N_- = (1 - r)N$。\n\n验证轨迹跨越 $T$ 个周期，由 $t \\in \\{1, 2, ..., T\\}$ 索引。对于每个周期 $t$，我们被赋予每个类别的正确分类概率：\n- $p_p(t)$：正确分类一个正样本的概率。\n- $p_n(t)$：正确分类一个负样本的概率。\n\n这些概率根据以下截断线性函数随周期演变：\n$$p_p(t) = \\mathrm{clip}(p_{p,0} + \\delta_p \\cdot (t - 1), 0, 1)$$\n$$p_n(t) = \\mathrm{clip}(p_{n,0} - \\delta_n \\cdot (t - 1), 0, 1)$$\n其中 $p_{p,0}$ 和 $p_{n,0}$ 是初始概率，$\\delta_p \\ge 0$ 和 $\\delta_n \\ge 0$ 是变化率。$\\mathrm{clip}(x, a, b)$ 函数将 $x$ 约束在区间 $[a, b]$ 内。\n\n根据这些概率，我们可以推导出每个周期 $t$ 混淆矩阵各组成部分的期望计数：\n- 真正例 ($TP(t)$)：一个正样本被正确分类。\n  $$TP(t) = N_+ \\cdot p_p(t) = rN \\cdot p_p(t)$$\n- 假负例 ($FN(t)$)：一个正样本被错误分类。其概率为 $1 - p_p(t)$。\n  $$FN(t) = N_+ \\cdot (1 - p_p(t)) = rN \\cdot (1 - p_p(t))$$\n- 真负例 ($TN(t)$)：一个负样本被正确分类。\n  $$TN(t) = N_- \\cdot p_n(t) = (1 - r)N \\cdot p_n(t)$$\n- 假正例 ($FP(t)$)：一个负样本被错误分类。其概率为 $1 - p_n(t)$。\n  $$FP(t) = N_- \\cdot (1 - p_n(t)) = (1 - r)N \\cdot (1 - p_n(t))$$\n\n所有组成部分的总和为 $TP(t) + FN(t) + TN(t) + FP(t) = N_+ + N_- = N$，与预期相符。\n\n接下来，我们使用这些期望计数来推导每个周期 $t$ 的性能指标。\n1.  **Accuracy**：正确分类样本的比例。\n    $$\\text{Accuracy}(t) = \\frac{TP(t) + TN(t)}{N} = \\frac{rN \\cdot p_p(t) + (1-r)N \\cdot p_n(t)}{N} = r \\cdot p_p(t) + (1-r) \\cdot p_n(t)$$\n    这表明 $\\text{Accuracy}$ 是各类别正确率的加权平均，权重与类别占比相对应。\n\n2.  **Recall (Sensitivity or True Positive Rate)**：被正确识别的实际正样本的比例。这就是少数类的 $\\text{Recall}$。\n    $$\\text{Recall}(t) = \\frac{TP(t)}{TP(t) + FN(t)} = \\frac{TP(t)}{N_+} = \\frac{rN \\cdot p_p(t)}{rN} = p_p(t)$$\n    这是一个关键结果：周期 $t$ 的少数类 $\\text{Recall}$ 就是正类的正确率 $p_p(t)$。\n\n3.  **Precision (Positive Predictive Value)**：正确预测为正类的比例。\n    $$\\text{Precision}(t) = \\frac{TP(t)}{TP(t) + FP(t)} = \\frac{rN \\cdot p_p(t)}{rN \\cdot p_p(t) + (1-r)N \\cdot (1-p_n(t))}$$\n    如果分母 $TP(t) + FP(t)$ 为 $0$，$\\text{Precision}$ 按惯例定义为 $0$。\n\n4.  **F1-Score**：$\\text{Precision}$ 和 $\\text{Recall}$ 的调和平均值。\n    $$\\text{F1}(t) = 2 \\cdot \\frac{\\text{Precision}(t) \\cdot \\text{Recall}(t)}{\\text{Precision}(t) + \\text{Recall}(t)}$$\n    如果 $\\text{Precision}$ 和 $\\text{Recall}$ 均为 $0$，则 F1-score 也为 $0$。\n\n问题定义了两种早停策略：\n- 策略 $\\mathcal{A}$：在周期 $t_\\mathcal{A} = \\arg\\max_{t} \\text{Accuracy}(t)$ 停止。\n- 策略 $\\mathcal{F}$：在周期 $t_\\mathcal{F} = \\arg\\max_{t} \\text{F1}(t)$ 停止。\n如果最大值出现平局，则选择最早的周期（最小的 $t$）。\n\n我们必须确定策略 $\\mathcal{A}$ 下的少数类 $\\text{Recall}$ 是否严格低于策略 $\\mathcal{F}$ 下的。条件如下：\n$$\\text{Recall}(t_\\mathcal{A}) < \\text{Recall}(t_\\mathcal{F})$$\n使用我们推导出的 $\\text{Recall}$ 公式，这等价于：\n$$p_p(t_\\mathcal{A}) < p_p(t_\\mathcal{F})$$\n函数 $p_p(t)$ 被定义为 $t$ 的单调非递减函数（因为 $\\delta_p \\ge 0$）。因此，当且仅当 $t_1 < t_2$ 时，$p_p(t_1) < p_p(t_2)$，前提是 $p_p(t)$ 尚未在其最大值 $1$ 处被截断。如果它已被截断，则可能存在 $t_1 < t_2$ 但 $p_p(t_1) = p_p(t_2) = 1$ 的情况。然而，严格不等式 $p_p(t_\\mathcal{A}) < p_p(t_\\mathcal{F})$ 仅在 $t_\\mathcal{A} < t_\\mathcal{F}$ 时才能成立。如果 $t_\\mathcal{A} \\ge t_\\mathcal{F}$，那么 $p_p(t_\\mathcal{A}) \\ge p_p(t_\\mathcal{F})$。因此，问题简化为确定是否 $t_\\mathcal{A} < t_\\mathcal{F}$。\n\n解决每个测试用例的算法如下：\n1.  对于给定的参数 $(N, r, T, p_{n,0}, \\delta_n, p_{p,0}, \\delta_p)$，初始化数组以存储 $t=1, \\dots, T$ 期间的 $\\text{Accuracy}(t)$ 和 $\\text{F1}(t)$ 的值。\n2.  对 $t$ 从 $1$ 到 $T$ 进行循环：\n    a. 使用提供的截断线性公式计算 $p_n(t)$ 和 $p_p(t)$。\n    b. 计算混淆矩阵的各组成部分 $TP(t)$、$FP(t)$、$TN(t)$、$FN(t)$。\n    c. 计算 $\\text{Accuracy}(t)$、$\\text{Recall}(t)$ 和 $\\text{Precision}(t)$，并处理潜在的除零错误。\n    d. 计算 $\\text{F1}(t)$。\n    e. 将 $\\text{Accuracy}(t)$ 和 $\\text{F1}(t)$ 存储在它们各自的数组中。\n3.  找到使 $\\text{Accuracy}(t)$ 数组最大化的周期 $t_\\mathcal{A}$。第一个最大值元素的索引对应于最早周期规则。\n4.  找到使 $\\text{F1}(t)$ 数组最大化的周期 $t_\\mathcal{F}$，同样使用第一个最大值的索引。\n5.  评估布尔条件 $t_\\mathcal{A} < t_\\mathcal{F}$。\n6.  对所有测试用例重复此过程，并收集布尔结果。\n此过程将被实现以生成最终答案。",
            "answer": "[True,False,True,False]"
        },
        {
            "introduction": "面对类别悬殊的数据集，一个常见的处理策略是“过采样”（Oversampling），即在训练中增加少数类样本的数量。这一操作能够有效提升模型对少数类的“召回率”，但它也可能带来副作用，比如因过分关注少数类特征而导致“误报”增多，从而损害“精确率”。这个练习  建立了一个模型来量化这种权衡，你的任务是找到最佳的过采样率，以在召回率的提升和精确率的潜在损失之间达到最佳平衡，从而最大化综合性能指标 $F_1$ 分数。",
            "id": "3105759",
            "problem": "给定一个基于原理的模型，该模型描述了对二元分类器中的正训练样本进行过采样如何影响验证集性能。在此模型中，使用过采样率 $r \\in \\{1,2,\\dots,R_{\\max}\\}$ 训练一个二元分类器，即将每个正训练样本复制 $r$ 次。在一个大小为 $N$、正类比例为 $\\pi$ 的固定验证集上，当 $r = 1$ 时，分类器表现出基准真正率 (TPR) $t_0$ 和基准假正率 (FPR) $f_0$。由于灵敏度增加，假设过采样会提高 TPR，但由于对类正特征的过拟合，它也会提高 FPR。为捕捉这些效应，假设验证集上的 TPR 和 FPR 作为 $r$ 的函数如下：\n$$\nt(r) = t_0 + (1 - t_0)\\left(1 - e^{-a(r - 1)}\\right), \\quad f(r) = f_0 + b(1 - f_0)\\left(1 - e^{-c(r - 1)}\\right),\n$$\n其中 $a > 0$ 控制灵敏度的增长，$b \\in (0,1]$ 界定假正率增长的上限，而 $c > 0$ 控制假正率随过采样增加的速度。\n\n设验证集混淆矩阵的计数由真正例 (TP)、假正例 (FP)、假负例 (FN) 和真负例 (TN) 表示。使用将这些计数与比率和类别比例相关联的基本定义，为每个 $r$ 推导出验证集上的准确率 (Accuracy)、精确率 (Precision)、召回率 (Recall) 和 F1 分数 (F1)，其中准确率是正确分类的验证实例的比例，精确率是预测为正例中真正为正例的比例，召回率是实际正例中被正确检测出的比例，F1 分数是精确率和召回率的调和平均值。然后，对每个测试用例，确定在离散集合 $\\{1,2,\\dots,R_{\\max}\\}$ 上使验证集 F1 分数最大化的过采样率 $r^\\star$。如果出现平局，选择达到最大 F1 分数的最小 $r$。\n\n所有比率和分数都必须视为 $[0,1]$ 区间内的小数。不涉及物理单位或角度。您的程序必须实现上述定义和模型来计算所需的量。\n\n测试套件：\n- 用例 1：$N = 1000$, $\\pi = 0.1$, $t_0 = 0.5$, $f_0 = 0.05$, $a = 0.9$, $b = 0.6$, $c = 0.7$, $R_{\\max} = 10$。\n- 用例 2：$N = 800$, $\\pi = 0.5$, $t_0 = 0.6$, $f_0 = 0.1$, $a = 0.7$, $b = 0.9$, $c = 1.0$, $R_{\\max} = 10$。\n- 用例 3：$N = 1200$, $\\pi = 0.02$, $t_0 = 0.3$, $f_0 = 0.01$, $a = 1.2$, $b = 0.4$, $c = 0.8$, $R_{\\max} = 12$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含每个测试用例的最优过采样率，格式为用逗号分隔并用方括号括起来的列表（例如，$[r_1,r_2,r_3]$）。每个 $r_i$ 必须是其用例指定范围 $\\{1,2,\\dots,R_{\\max}\\}$ 内的整数。",
            "solution": "该问题是有效的，因为它在科学上基于分类性能评估的原则，在数学上是适定的，具有明确的目标，并提供了一套完整且一致的信息。\n\n目标是从离散集合 $\\{1, 2, \\dots, R_{\\max}\\}$ 中找到使验证集上 F1 分数最大化的最优过采样率 $r^\\star$。为实现此目标，我们必须首先将 F1 分数推导为过采样率 $r$ 的函数。这需要用给定的参数和函数来表示基本的混淆矩阵计数——真正例 ($TP$)、假正例 ($FP$)、假负例 ($FN$) 和真负例 ($TN$)。\n\n设 $N$ 为验证集的总大小，$\\pi$ 为正实例的比例。实际正实例的数量为 $P = N \\pi$，实际负实例的数量为 $N_{\\text{neg}} = N(1-\\pi)$。\n\n真正率 $t(r)$ 定义为被正确分类的实际正例的比例。这也称为召回率。因此，$\\text{Recall}(r) = t(r)$。真正例的数量是 $r$ 的函数：\n$$\nTP(r) = P \\cdot t(r) = N \\pi t(r)\n$$\n假正率 $f(r)$ 定义为被错误分类的实际负例的比例。假正例的数量为：\n$$\nFP(r) = N_{\\text{neg}} \\cdot f(r) = N(1-\\pi)f(r)\n$$\n剩余的混淆矩阵计数可以从这些推导出来。假负例的数量是未被识别为正例的实际正例的数量：\n$$\nFN(r) = P - TP(r) = N \\pi - N \\pi t(r) = N \\pi (1 - t(r))\n$$\n真负例的数量是正确识别为负例的实际负例的数量：\n$$\nTN(r) = N_{\\text{neg}} - FP(r) = N(1-\\pi) - N(1-\\pi)f(r) = N(1-\\pi)(1 - f(r))\n$$\n\n有了这些计数，我们就可以定义所需的性能指标。\n准确率是总正确预测的比例：\n$$\n\\text{Accuracy}(r) = \\frac{TP(r) + TN(r)}{N} = \\frac{N \\pi t(r) + N(1-\\pi)(1 - f(r))}{N} = \\pi t(r) + (1-\\pi)(1 - f(r))\n$$\n精确率是预测为正例中实际为正例的比例：\n$$\n\\text{Precision}(r) = \\frac{TP(r)}{TP(r) + FP(r)} = \\frac{N \\pi t(r)}{N \\pi t(r) + N(1-\\pi)f(r)} = \\frac{\\pi t(r)}{\\pi t(r) + (1-\\pi)f(r)}\n$$\n请注意，为使精确率有意义，分母 $TP(r) + FP(r)$ 必须非零。如果分母为零（即没有做出正向预测），我们可以将精确率定义为 $0$。\n\nF1 分数是精确率和召回率的调和平均值。一个常见且代数上方便的形式是：\n$$\nF1(r) = \\frac{2 \\cdot TP(r)}{2 \\cdot TP(r) + FP(r) + FN(r)}\n$$\n代入 $TP(r)$、$FP(r)$ 和 $FN(r)$ 的表达式：\n$$\nF1(r) = \\frac{2 N \\pi t(r)}{2 N \\pi t(r) + N(1-\\pi)f(r) + N \\pi (1 - t(r))}\n$$\n验证集总大小 $N$ 从分子和分母中约去，表达式简化为：\n$$\nF1(r) = \\frac{2 \\pi t(r)}{2 \\pi t(r) + (1-\\pi)f(r) + \\pi (1 - t(r))} = \\frac{2 \\pi t(r)}{\\pi t(r) + (1-\\pi)f(r) + \\pi}\n$$\n$$\nF1(r) = \\frac{2 \\pi t(r)}{\\pi(1+t(r)) + (1-\\pi)f(r)}\n$$\n真正率 $t(r)$ 和假正率 $f(r)$ 的函数如下：\n$$\nt(r) = t_0 + (1 - t_0)\\left(1 - e^{-a(r - 1)}\\right)\n$$\n$$\nf(r) = f_0 + b(1 - f_0)\\left(1 - e^{-c(r - 1)}\\right)\n$$\n\n寻找最优过采样率 $r^\\star$ 的总体算法如下：\n对于每个测试用例，我们遍历从 $1$ 到 $R_{\\max}$ 的每个整数值 $r$。在每次迭代中，我们：\n$1$. 使用为特定用例提供的公式和参数计算 $t(r)$ 和 $f(r)$ 的值。\n$2$. 将这些值代入推导出的 $F1(r)$ 表达式中以计算 F1 分数。\n$3$. 跟踪到目前为止找到的最大 F1 分数以及对应的 $r$ 值。如果当前的 F1 分数大于先前找到的最大值，我们更新最大值并将当前的 $r$ 设置为新的最优率 $r^\\star$。\n$4$. 根据问题的平局决胜规则，如果计算出的 F1 分数等于当前最大值，我们不更新 $r^\\star$。这确保了选择达到最大 F1 分数的最小 $r$。\n\n对每个提供的测试用例都执行此过程。",
            "answer": "[3,2,4]"
        }
    ]
}