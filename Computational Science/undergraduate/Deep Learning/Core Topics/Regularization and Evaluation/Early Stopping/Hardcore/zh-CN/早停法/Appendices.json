{
    "hands_on_practices": [
        {
            "introduction": "理论知识需要通过实践来巩固。本节将通过一系列动手实践，加深你对早停法及其变体的理解。第一个练习将探讨早停法最核心的目标：通过防止过拟合来提升模型的泛化能力。你将通过编码实现一个模拟实验，直接比较早停法与检查点平均法（Checkpoint Averaging）在减小泛化差距方面的表现，从而直观地理解它们作为正则化技术的工作原理和效果差异。",
            "id": "3119093",
            "problem": "要求您在一个受控的深度学习模拟中实现并分析两种模型选择策略，该模拟使用一维线性回归代理模型来模拟训练动态和泛化行为。比较指标是跨随机种子的期望泛化差距，定义为在选定模型参数下，测试损失与训练损失之差的期望值。您的程序必须是一个完整、可运行的程序。\n\n基本基础与设置：\n- 考虑一个数据生成过程，其中输入 $x$ 从标准正态分布 $x \\sim \\mathcal{N}(0,1)$ 中独立采样，输出 $y$ 由 $y = \\theta^\\ast x + \\epsilon$ 生成，其中噪声 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$ 与 $x$ 无关。参数 $\\theta^\\ast$ 是真实的数据生成系数。\n- 训练过程是使用批量梯度下降 (GD) 的经验风险最小化 (ERM)，以最小化均方误差 (MSE) 损失。对于一个参数 $\\theta$ 和数据集 $\\{(x_i, y_i)\\}_{i=1}^n$，经验损失为 $L(\\theta) = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\theta x_i)^2$。关于 $\\theta$ 的梯度是 $\\nabla_\\theta L(\\theta) = \\frac{2}{n}\\sum_{i=1}^n x_i(\\theta x_i - y_i)$。\n- 在周期 $t$ 的 GD 更新规则是 $\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta L(\\theta_t)$，其中 $\\eta$ 是学习率，初始化为 $\\theta_0 = 0$。\n- 定义参数 $\\theta$ 处的泛化差距为 $G(\\theta) = L_{test}(\\theta) - L_{train}(\\theta)$，其中 $L_{train}$ 和 $L_{test}$ 分别是在训练集和测试集上计算的经验 MSE。\n- 跨种子的期望是通过对由一系列随机种子控制的数据集和噪声的独立抽取进行平均。对于一个选择规则，它为每个种子 $s$ 产生一个参数 $\\theta_{sel}^{(s)}$，期望泛化差距为 $\\mathbb{E}_s\\big[G(\\theta_{sel}^{(s)})\\big]$，通过对给定种子的算术平均值来近似。\n\n待比较的模型选择策略：\n1. 早停法 (ES)：使用一个独立的验证集来监控每个周期的验证损失 $L_{val}(\\theta_t)$。维持迄今为止看到的最佳验证损失及其对应的周期。如果验证损失在 $p$ 个连续周期内没有严格改善（即“耐心值”），则停止选择，并选择在停止前遇到的最佳周期所对应的参数。形式上，扫描周期 $t=0,1,\\dots$；每当 $L_{val}(\\theta_t)  \\min_{u \\le t-1} L_{val}(\\theta_u)$ 时，记录 $t$ 为新的最佳周期，并重置一个记录未改善周期的计数器。否则，增加该计数器；如果它超过 $p$，则终止并选择最后记录的最佳周期。计算所选参数 $\\theta_{ES}$ 的泛化差距 $G(\\theta_{ES})$。\n2. 检查点平均法 (CA)：训练固定的总共 $E$ 个周期。设最后 $k$ 个参数为 $\\theta_{E-k+1}, \\dots, \\theta_E$。定义平均化后的参数为 $\\bar{\\theta} = \\frac{1}{k}\\sum_{u=E-k+1}^E \\theta_u$。计算泛化差距 $G(\\bar{\\theta})$。\n\n每个种子 $s$ 的模拟协议：\n- 使用种子 $s$，根据给定的 $n_{train}$、$n_{val}$ 和 $n_{test}$ 生成独立的训练、验证和测试数据集。\n- 使用训练集执行 $E$ 个周期的批量 GD，存储每个周期 $t$ 的 $\\theta_t$。\n- 为每个周期 $t$ 计算 $L_{train}(\\theta_t)$、$L_{val}(\\theta_t)$ 和 $L_{test}(\\theta_t)$。\n- 应用 ES 选择 $\\theta_{ES}$ 并计算 $G(\\theta_{ES})$。\n- 应用 CA 计算 $\\bar{\\theta}$ 并计算 $G(\\bar{\\theta})$。\n- 在案例中的所有种子上重复此过程，并计算 $G(\\theta_{ES})$ 的均值和 $G(\\bar{\\theta})$ 的均值。\n\n测试套件：\n为以下参数集实现上述模拟。在所有情况下，损失是无量纲的，最终输出必须是浮点数。将最终输出四舍五入到 $6$ 位小数。\n\n- 案例 1 (理想情况)：\n  - 真实参数 $\\theta^\\ast = 1.5$\n  - 训练集大小 $n_{train} = 50$\n  - 验证集大小 $n_{val} = 100$\n  - 测试集大小 $n_{test} = 10000$\n  - 学习率 $\\eta = 0.05$\n  - 总周期数 $E = 120$\n  - 耐心值 $p = 5$\n  - 平均窗口 $k = 10$\n  - 噪声标准差 $\\sigma_\\epsilon = 0.5$\n  - 种子：从 $0$ 到 $19$ 的整数（含）\n- 案例 2 (边界情况：最小耐心值，无平均)：\n  - 真实参数 $\\theta^\\ast = 1.5$\n  - 训练集大小 $n_{train} = 50$\n  - 验证集大小 $n_{val} = 100$\n  - 测试集大小 $n_{test} = 10000$\n  - 学习率 $\\eta = 0.05$\n  - 总周期数 $E = 120$\n  - 耐心值 $p = 0$\n  - 平均窗口 $k = 1$\n  - 噪声标准差 $\\sigma_\\epsilon = 0.5$\n  - 种子：从 $20$ 到 $39$ 的整数（含）\n- 案例 3 (边界情况：平均所有检查点，低噪声，更大数据集)：\n  - 真实参数 $\\theta^\\ast = 1.5$\n  - 训练集大小 $n_{train} = 400$\n  - 验证集大小 $n_{val} = 400$\n  - 测试集大小 $n_{test} = 10000$\n  - 学习率 $\\eta = 0.02$\n  - 总周期数 $E = 200$\n  - 耐心值 $p = 10$\n  - 平均窗口 $k = 200$\n  - 噪声标准差 $\\sigma_\\epsilon = 0.1$\n  - 种子：从 $40$ 到 $59$ 的整数（含）\n- 案例 4 (边缘情况：高噪声，小数据集，不同真实参数)：\n  - 真实参数 $\\theta^\\ast = -0.8$\n  - 训练集大小 $n_{train} = 20$\n  - 验证集大小 $n_{val} = 40$\n  - 测试集大小 $n_{test} = 10000$\n  - 学习率 $\\eta = 0.03$\n  - 总周期数 $E = 150$\n  - 耐心值 $p = 3$\n  - 平均窗口 $k = 20$\n  - 噪声标准差 $\\sigma_\\epsilon = 1.2$\n  - 种子：从 $60$ 到 $79$ 的整数（含）\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个案例，其本身是一个双元素列表，分别包含早停法和检查点平均法的期望泛化差距，两个值都四舍五入到 $6$ 位小数。例如，格式必须类似于 $\\big[ [g_{ES}^{(1)}, g_{CA}^{(1)}], [g_{ES}^{(2)}, g_{CA}^{(2)}], [g_{ES}^{(3)}, g_{CA}^{(3)}], [g_{ES}^{(4)}, g_{CA}^{(4)}] \\big]$。",
            "solution": "问题陈述是有效的。它提出了一个定义明确、有科学依据且客观的模拟任务，与机器学习领域相关。该任务涉及在一个受控的一维线性回归设置中，比较两种常见的模型选择策略：早停法 (ES) 和检查点平均法 (CA)。所有参数、流程和定义都清晰明确、无矛盾地给出，从而能够得出一个唯一且有意义的数值解。\n\n解决方案首先阐述理论框架，然后详细说明算法实现。\n\n### 理论框架\n\n1.  **数据生成与模型：** 问题设置在一个简单线性模型的背景下。数据生成过程由 $y = \\theta^\\ast x + \\epsilon$ 定义，其中输入 $x$ 从标准正态分布 $x \\sim \\mathcal{N}(0,1)$ 中抽取，噪声项 $\\epsilon$ 也服从正态分布 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$。目标是使用模型 $\\hat{y} = \\theta x$ 来估计真实参数 $\\theta^\\ast$。\n\n2.  **优化：** 参数 $\\theta$ 通过在训练集 $\\{(x_i, y_i)\\}_{i=1}^{n_{train}}$ 上最小化均方误差 (MSE) 来优化。经验损失函数为 $L_{train}(\\theta) = \\frac{1}{n_{train}}\\sum_{i=1}^{n_{train}} (y_i - \\theta x_i)^2$。优化方法是批量梯度下降 (GD)，它根据以下规则迭代更新参数：\n    $$\n    \\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta L_{train}(\\theta_t)\n    $$\n    其中 $\\theta_0 = 0$ 是初始化值，$\\eta$ 是学习率，$t$ 是周期索引。损失的梯度为：\n    $$\n    \\nabla_\\theta L_{train}(\\theta) = \\frac{2}{n_{train}}\\sum_{i=1}^{n_{train}} x_i(\\theta x_i - y_i)\n    $$\n    对于给定的训练集，这个过程会生成一个确定性的参数轨迹 $\\{\\theta_0, \\theta_1, \\dots, \\theta_E\\}$。模拟中的随机性源于为每个指定随机种子采样数据集的过程。\n\n3.  **泛化差距：** 评估的核心指标是泛化差距，定义为模型在未见过的测试数据上的性能与其在训练数据上的性能之差：\n    $$\n    G(\\theta) = L_{test}(\\theta) - L_{train}(\\theta)\n    $$\n    一个大的正差距是过拟合的标志，即模型学习了训练集的特质，而这些特质无法泛化到更广泛的数据分布中。最终的比较指标是期望泛化差距 $\\mathbb{E}_s[G(\\theta_{sel})]$，通过在多个独立模拟（种子）上对差距进行平均来近似。\n\n4.  **模型选择策略：**\n    *   **早停法 (ES)：** 该技术通过防止模型训练时间过长而导致过拟合，起到一种正则化的作用。它通过监控一个独立验证集上的损失 $L_{val}(\\theta_t)$ 来工作。当验证损失在指定的周期数（即耐心值 $p$）内未能表现出严格改善时，训练实际上就停止了。所选择的参数不是训练停止时的那个，而是在此过程中观察到的产生最佳（最小）验证损失的那个周期所对应的参数。该策略直接旨在选择一个具有良好泛化性能的模型，并以验证集作为其代理。\n    *   **检查点平均法 (CA)：** 此方法涉及训练固定的周期数 ($E$)，然后对最后 $k$ 个周期的参数进行平均。平均化后的参数是 $\\bar{\\theta} = \\frac{1}{k}\\sum_{u=E-k+1}^E \\theta_u$。这种方法背后的直觉（与 Polyak-Ruppert 平均法相关）是，在优化轨迹的一部分上对参数进行平均，可以得到一个更稳定的解，该解位于损失景观中一个更宽、更平坦的区域，这通常与更好的泛化能力相关。\n\n### 算法实现\n\n解决方案由一个程序实现，该程序为四个指定的案例中的每一个执行模拟。\n\n1.  **主循环：** 程序遍历每个参数案例。对于每个案例，它运行一系列模拟，每个指定的种子范围内的一个种子对应一次模拟。\n\n2.  **单一种子模拟：** 对于给定的种子 $s$：\n    a.  **数据生成：** 使用 $s$ 为一个新的随机数生成器设定种子。根据过程 $x \\sim \\mathcal{N}(0,1)$ 和 $y = \\theta^\\ast x + \\epsilon$（其中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$），生成大小分别为 $n_{train}$、$n_{val}$ 和 $n_{test}$ 的独立训练、验证和测试数据集。\n    b.  **梯度下降：** 从 $\\theta_0=0$ 开始，运行 GD 算法 $E$ 个周期。所有中间参数 $\\theta_0, \\theta_1, \\dots, \\theta_E$ 都被存储起来。梯度计算为提高效率而进行了向量化。\n    c.  **损失评估：** 对于每个存储的参数 $\\theta_t$，在训练、验证和测试集上计算 MSE，从而得到轨迹 $L_{train}(\\theta_t)$、$L_{val}(\\theta_t)$ 和 $L_{test}(\\theta_t)$。\n    d.  **早停法选择：** 从 $t=0$到 $E$ 扫描存储的验证损失 $L_{val}(\\theta_t)$。跟踪对应于迄今为止观察到的最小验证损失的周期 $t_{best}$。对于每个没有产生新的严格更低验证损失的周期，耐心计数器会增加；在有改善时则重置。如果计数器超过了耐心参数 $p$，扫描终止。选择的参数是 $\\theta_{ES} = \\theta_{t_{best}}$。然后计算泛化差距 $G(\\theta_{ES})$。\n    e.  **检查点平均法选择：** 通过对训练轨迹的最后 $k$ 个参数 $\\{\\theta_{E-k+1}, \\dots, \\theta_E\\}$ 进行平均来计算参数 $\\bar{\\theta}$。然后计算泛化差距 $G(\\bar{\\theta})$。\n\n3.  **平均与输出：** 在完成一个案例中所有种子的模拟后，为 ES 和 CA 收集的泛化差距分别取平均值。这两个平均值构成了该案例的结果。最终的程序输出将所有四个案例的结果整理成指定的列表的列表格式，每个数值都四舍五入到六位小数。",
            "answer": "```python\nimport numpy as np\n\ndef mse(theta, x, y):\n    \"\"\"\n    Calculates the Mean Squared Error for a 1D linear model.\n    \"\"\"\n    if y.size == 0:\n        return 0.0\n    return np.mean((y - theta * x)**2)\n\ndef run_simulation_for_case(params):\n    \"\"\"\n    Runs the full simulation for one set of parameters.\n    \"\"\"\n    theta_star, n_train, n_val, n_test, eta, E, p, k, sigma_eps, seeds = params\n\n    es_gaps = []\n    ca_gaps = []\n\n    for seed in seeds:\n        rng = np.random.default_rng(seed)\n        \n        # 1. Data Generation\n        x_train = rng.standard_normal(n_train)\n        eps_train = rng.standard_normal(n_train) * sigma_eps\n        y_train = theta_star * x_train + eps_train\n        \n        x_val = rng.standard_normal(n_val)\n        eps_val = rng.standard_normal(n_val) * sigma_eps\n        y_val = theta_star * x_val + eps_val\n\n        x_test = rng.standard_normal(n_test)\n        eps_test = rng.standard_normal(n_test) * sigma_eps\n        y_test = theta_star * x_test + eps_test\n\n        # 2. Training (Batch Gradient Descent)\n        thetas = np.zeros(E + 1)\n        theta_t = 0.0\n        \n        mean_x_sq_train = np.mean(x_train**2)\n        mean_xy_train = np.mean(x_train * y_train)\n\n        for t in range(E):\n            grad = 2 * (theta_t * mean_x_sq_train - mean_xy_train)\n            theta_t = theta_t - eta * grad\n            thetas[t + 1] = theta_t\n\n        # 3. Loss Calculation\n        train_losses = np.array([mse(th, x_train, y_train) for th in thetas])\n        val_losses = np.array([mse(th, x_val, y_val) for th in thetas])\n        test_losses = np.array([mse(th, x_test, y_test) for th in thetas])\n\n        # 4. Early Stopping (ES)\n        best_val_loss = float('inf')\n        best_epoch = 0\n        patience_counter = 0\n\n        for t in range(E + 1):\n             current_val_loss = val_losses[t]\n             if current_val_loss  best_val_loss:\n                 best_val_loss = current_val_loss\n                 best_epoch = t\n                 patience_counter = 0\n             else:\n                 patience_counter += 1\n            \n             if patience_counter > p:\n                 break\n        \n        theta_es = thetas[best_epoch]\n        es_gap = test_losses[best_epoch] - train_losses[best_epoch]\n        es_gaps.append(es_gap)\n\n        # 5. Checkpoint Averaging (CA)\n        theta_ca_list = thetas[E - k + 1 : E + 1]\n        theta_ca = np.mean(theta_ca_list)\n        ca_gap = mse(theta_ca, x_test, y_test) - mse(theta_ca, x_train, y_train)\n        ca_gaps.append(ca_gap)\n\n    return [round(np.mean(es_gaps), 6), round(np.mean(ca_gaps), 6)]\n\ndef solve():\n    \"\"\"\n    Defines the test cases and formats the final output.\n    \"\"\"\n    case1 = (1.5, 50, 100, 10000, 0.05, 120, 5, 10, 0.5, range(0, 20))\n    case2 = (1.5, 50, 100, 10000, 0.05, 120, 0, 1, 0.5, range(20, 40))\n    case3 = (1.5, 400, 400, 10000, 0.02, 200, 10, 200, 0.1, range(40, 60))\n    case4 = (-0.8, 20, 40, 10000, 0.03, 150, 3, 20, 1.2, range(60, 80))\n    \n    test_cases = [case1, case2, case3, case4]\n\n    results = []\n    for case in test_cases:\n        result = run_simulation_for_case(case)\n        results.append(result)\n        \n    final_output_str = str(results).replace(\" \", \"\")\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "标准的早停法依赖于验证损失的原始值，但在实践中，验证损失曲线往往充满噪声，这可能导致过早或不稳定的停止决策。为了解决这个问题，我们可以引入更稳健的统计方法。本练习将指导你应用一种经典的统计过程控制技术——累积和（CUSUM）变化点检测，来分析验证损失的变化趋势，从而更精确地识别模型性能从“持续改进”到“停滞或恶化”的转折点。",
            "id": "3119056",
            "problem": "你的任务是使用累积和 (CUSUM) 变化点检测方法，对验证损失残差实现一个基于特定原理的早停机制。你必须从核心统计定义中推导出该检测器，然后将其实现为一个完整的、可运行的程序，该程序处理一个固定的测试套件，并以指定格式输出结果。背景如下。\n\n给定一个验证损失序列 $\\{L_{\\text{val}}(t)\\}_{t=1}^{T}$，通过一阶差分 $r_t = L_{\\text{val}}(t) - L_{\\text{val}}(t-1)$ 定义残差，其中 $t \\in \\{2,\\dots,T\\}$。将 $r_t$ 解释为验证损失在逐个 epoch 间的变化。假设在初始的“受控”状态（当模型真正在改进时），残差是独立同分布的，其均值为 $\\mu_0  0$。对应于真正改进结束的状态转变，被建模为在某个未知时间，残差均值增加至某个 $\\mu_1 > \\mu_0$，这会导致验证损失的改进减小或恶化。你需要构建一个单边上累积和 (CUSUM) 检测器来识别这种向上漂移并触发早停。\n\n检测器应基于以下源于标准序贯变化检测的规范：\n- 使用前 $W$ 个残差估计受控均值 $\\mu_0$：$\\mu_0 = \\frac{1}{W}\\sum_{t=2}^{W+1} r_t$，其中 $W$ 是一个给定的整数窗口大小，满足 $W \\ge 1$ 和 $W+1 \\le T$。\n- 对残差时间 $t \\in \\{W+2,\\dots,T\\}$，递归地定义单边上累积和统计量 $\\{S_t\\}$：$S_{W+1} = 0$ 且 $S_t = \\max\\{0, S_{t-1} + r_t - \\mu_0 - k\\}$，其中 $k > 0$ 是一个给定的参考值，用于设定对向上漂移的敏感度。\n- 将停止时间 $\\tau$ 定义为在原始验证损失时间尺度上，统计量首次越过阈值的最小 epoch 索引，即 $\\tau = \\min\\{t \\in \\{W+2,\\dots,T\\} : S_t \\ge h\\}$，其中 $h > 0$ 是一个给定的阈值。如果不存在这样的时间，则设 $\\tau = -1$。\n- 当触发停止时，返回整数 epoch 索引 $\\tau$。如果没有触发，则返回 $-1$。\n\n重要索引约定：残差时间 $t$ 对应于 epoch $t$ 时的验证损失，因为 $r_t$ 使用了 $L_{\\text{val}}(t)$ 和 $L_{\\text{val}}(t-1)$。因此，当在残差时间 $t$ 触发警报时，要返回的停止 epoch 正是 $t$。\n\n你的程序必须为下面的测试套件实现这个检测器，无需任何用户输入。对于每个测试用例，都给定了验证损失序列以及参数 $W$、$k$ 和 $h$。对于每个案例，输出停止 epoch $\\tau$（整数），如果未发生检测则输出 $-1$。你的程序应生成单行输出，其中包含一个用方括号括起来的、逗号分隔的结果列表。\n\n测试套件：\n- 案例 A（从改善明显转为恶化）：\n  - 序列长度 $T = 20$。验证损失 $[1.00, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50, 0.45, 0.465, 0.480, 0.495, 0.510, 0.525, 0.540, 0.555, 0.570]$。\n  - 参数：$W = 6$，$k = 0.02$，$h = 0.10$。\n- 案例 B（持续改善，无漂移）：\n  - 序列长度 $T = 15$。验证损失 $[1.00, 0.97, 0.94, 0.91, 0.88, 0.85, 0.82, 0.79, 0.76, 0.73, 0.70, 0.67, 0.64, 0.61, 0.58]$。\n  - 参数：$W = 6$，$k = 0.02$，$h = 0.10$。\n- 案例 C（含噪声的平台期，精确达到阈值）：\n  - 序列长度 $T = 11$。验证损失 $[1.00, 0.96, 0.92, 0.88, 0.84, 0.80, 0.76, 0.72, 0.71, 0.70, 0.69]$。\n  - 参数：$W = 5$，$k = 0.01$，$h = 0.06$。\n- 案例 D（基线窗口内出现早期异常，随后持续改善）：\n  - 序列长度 $T = 15$。验证损失 $[1.00, 0.95, 0.90, 0.85, 0.80, 0.82, 0.84, 0.79, 0.74, 0.69, 0.64, 0.59, 0.54, 0.49, 0.44]$。\n  - 参数：$W = 6$，$k = 0.02$，$h = 0.10$。\n\n要求：\n- 精确实现上述检测器。\n- 对于每个案例，计算首次出现 $S_t \\ge h$ 时的整数 epoch 索引 $\\tau$，如果从未出现则为 $-1$。\n- 最终输出格式：单行输出，包含按顺序排列的四个结果的列表，格式为 $[\\tau_A,\\tau_B,\\tau_C,\\tau_D]$，无多余空格或文本。",
            "solution": "所提出的问题是有效的，因为它在科学上基于成熟的累积和 (CUSUM) 变化点检测统计理论，其定义和数据完整且一致，问题良构，并且可以通过计算进行验证。因此，我们可以着手解决。\n\n核心任务是实现一个单边上 CUSUM 检测器，用以识别模型在训练期间验证损失改善情况的退化。这种退化被建模为验证损失逐 epoch 变化的均值的向上漂移。\n\n设验证损失序列为 $\\{L_{\\text{val}}(t)\\}_{t=1}^{T}$，其中 $t$ 是 epoch 编号，$T$ 是总 epoch 数。逐 epoch 的变化，或称残差，定义为 $r_t = L_{\\text{val}}(t) - L_{\\text{val}}(t-1)$，其中 $t \\in \\{2, \\dots, T\\}$。\n\n在训练的初始“受控”阶段，模型正在改进，这意味着验证损失持续下降。我们通过假设残差 $r_t$ 是从一个均值为负（$\\mu_0  0$）的分布中采样来对此建模。过拟合或有效学习的停止，其特征是该分布发生转变，残差的均值增加到一个值 $\\mu_1 > \\mu_0$。这对应于损失下降速率变慢、进入平台期或损失增加。CUSUM 检测器就是为检测这种特定转变而设计的。\n\n算法规定如下：\n$1$. **残差计算**：首先，我们根据给定的验证损失序列 $\\{L_{\\text{val}}(t)\\}_{t=1}^{T}$ 计算出残差序列 $\\{r_t\\}_{t=2}^{T}$。\n\n$2$. **基线估计**：受控均值 $\\mu_0$ 是根据训练的初始窗口估计的。使用前 $W$ 个残差，我们计算样本均值：\n$$\n\\mu_0 = \\frac{1}{W}\\sum_{t=2}^{W+1} r_t\n$$\n这为逐 epoch 的改善建立了基线期望。参数 $W$ 必须满足 $W \\ge 1$ 和 $W+1 \\le T$。\n\n$3$. **CUSUM 统计量更新**：单边上 CUSUM 统计量 $S_t$ 被设计用来累积向上偏离基线均值 $\\mu_0$ 的证据。它是为 epochs $t \\in \\{W+2, \\dots, T\\}$ 递归计算的，初始条件为 $S_{W+1} = 0$。更新规则是：\n$$\nS_t = \\max\\{0, S_{t-1} + r_t - \\mu_0 - k\\}\n$$\n在这里，$r_t - \\mu_0$ 项代表当前残差与预期基线的偏离。参数 $k > 0$ 是一个参考值，或称“松弛量”，它允许微小的波动。只有当偏离 $r_t - \\mu_0$ 超过这个松弛量 $k$ 时，统计量 $S_t$ 才会增加。$\\max\\{0, \\cdot\\}$ 操作确保 CUSUM 统计量不会累积“负证据”（即优于预期的改善时期），并且如果朝向漂移的趋势消失，它会重置为 $0$。\n\n$4$. **停止条件**：在累积证据 $S_t$ 首次越过预定义阈值 $h > 0$ 的第一个 epoch $t$ 处，触发警报并停止训练。因此，停止时间 $\\tau$ 定义为：\n$$\n\\tau = \\min\\{t \\in \\{W+2, \\dots, T\\} : S_t \\ge h\\}\n$$\n如果 CUSUM 统计量直到最后一个 epoch $T$ 都未越过阈值 $h$，则不触发停止，我们设 $\\tau = -1$。报告的停止时间 $\\tau$ 对应于原始验证损失序列中的 epoch 索引。\n\n我们来逐步计算**案例 A**：\n- **给定**：验证损失 $\\{L_{\\text{val}}(t)\\}_{t=1}^{20}$ 为 $[1.00, 0.95, \\dots, 0.570]$。参数为 $T=20$, $W=6$, $k=0.02$, $h=0.10$。\n- **步骤 1（残差）**：我们计算 $t \\in \\{2, \\dots, 20\\}$ 的 $r_t$。\n从 $r_2$ 到 $r_{12}$ 的所有残差都是 $-0.05$。从 $r_{13}$ 开始，残差变为正值：$r_{13} = 0.465 - 0.45 = 0.015$，$r_{14} = 0.480 - 0.465 = 0.015$，以此类推。\n- **步骤 2（基线）**：我们使用前 $W=6$ 个残差（$r_2, \\dots, r_7$）来估计 $\\mu_0$。\n$$\n\\mu_0 = \\frac{1}{6} \\sum_{t=2}^{7} r_t = \\frac{1}{6} (r_2 + \\dots + r_7) = \\frac{1}{6} (6 \\times -0.05) = -0.05\n$$\n- **步骤 3 和 4（CUSUM 迭代与停止）**：我们初始化 $S_{W+1} = S_7 = 0$，并从 $t=W+2 = 8$ 迭代到 $T=20$。我们使用 $k=0.02$。\n- 对于 $t=8, \\dots, 12$：$r_t = -0.05$。更新项为 $r_t - \\mu_0 - k = -0.05 - (-0.05) - 0.02 = -0.02$。因此，$S_t = \\max\\{0, S_{t-1} - 0.02\\}$。因为 $S_7=0$，所以 $S_8=\\max\\{0, -0.02\\}=0$，并且随后 $S_9=S_{10}=S_{11}=S_{12}=0$。\n- 对于 $t=13$：$r_{13} = 0.015$。更新项为 $r_{13} - \\mu_0 - k = 0.015 - (-0.05) - 0.02 = 0.045$。\n$$S_{13} = \\max\\{0, S_{12} + 0.045\\} = \\max\\{0, 0 + 0.045\\} = 0.045$$\n该值小于 $h=0.10$。\n- 对于 $t=14$：$r_{14} = 0.015$。更新项仍为 $0.045$。\n$$S_{14} = \\max\\{0, S_{13} + 0.045\\} = \\max\\{0, 0.045 + 0.045\\} = 0.09$$\n该值小于 $h=0.10$。\n- 对于 $t=15$：$r_{15} = 0.015$。更新项仍为 $0.045$。\n$$S_{15} = \\max\\{0, S_{14} + 0.045\\} = \\max\\{0, 0.09 + 0.045\\} = 0.135$$\n此时，$S_{15} = 0.135 \\ge h = 0.10$。满足停止条件。\n- **结果**：停止时间为 $\\tau = 15$。\n\n将此相同过程应用于其他测试用例，我们得到：\n- **案例 B**：$\\mu_0 = -0.03$。对于所有后续的 epoch，$r_t = -0.03$。CUSUM 更新项 $r_t - \\mu_0 - k = -0.03 - (-0.03) - 0.02 = -0.02$ 始终为负，因此 $S_t$ 保持为 $0$。未触发停止。$\\tau = -1$。\n- **案例 C**：$\\mu_0 = -0.04$。随着残差从 $-0.04$ 变为 $-0.01$，CUSUM 统计量逐渐增加。在 $t=11$ 时，$S_{11}$ 精确达到 $0.06$，由于 $S_{11} \\ge h = 0.06$，触发停止。$\\tau = 11$。\n- **案例 D**：基线窗口包含异常的正残差，导致一个没那么负的 $\\mu_0 \\approx -0.0267$。随后的残差均为 $-0.05$。CUSUM 更新项 $r_t - \\mu_0 - k \\approx -0.05 - (-0.0267) - 0.02 = -0.0433$ 始终为负。因此，$S_t$ 保持为 $0$。未触发停止。$\\tau = -1$。\n\n测试套件的最终结果是 $[15, -1, 11, -1]$。",
            "answer": "```python\nimport numpy as np\n\ndef cusum_early_stopping(losses, W, k, h):\n    \"\"\"\n    Implements a CUSUM-based early stopping detector.\n\n    Args:\n        losses (list or np.ndarray): Sequence of validation losses, 1-indexed by epoch.\n        W (int): Window size for estimating the in-control mean.\n        k (float): Reference value (slack) for the CUSUM statistic.\n        h (float): Threshold for triggering the stop.\n\n    Returns:\n        int: The stopping epoch tau, or -1 if no stop is triggered.\n    \"\"\"\n    losses = np.array(losses, dtype=float)\n    T = len(losses)\n\n    # Problem constraints on W\n    if not (W >= 1 and W + 1 = T):\n        # This case should not occur with the given test suite\n        # but is good practice for a general function.\n        raise ValueError(\"W must satisfy 1 = W and W+1 = T.\")\n\n    # Step 1: Compute residuals r_t for t=2,...,T\n    # r_t = L(t) - L(t-1)\n    # The array `residuals` is 0-indexed, where residuals[i] corresponds to r_{i+2}.\n    # e.g., residuals[0] = losses[1] - losses[0] = r_2\n    residuals = np.diff(losses)\n\n    # Step 2: Estimate in-control mean mu_0 from the first W residuals\n    # These are r_2, ..., r_{W+1}, which correspond to residuals[0], ..., residuals[W-1]\n    mu_0 = np.mean(residuals[0:W])\n\n    # Step 3  4: CUSUM iteration and stopping check\n    # Initialize S_{W+1} = 0.\n    s_current = 0.0\n    \n    # Iterate for epochs t from W+2 to T.\n    # This corresponds to residual indices from W to T-2.\n    # The epoch t equals residual_index + 2.\n    for t_idx in range(W, T - 1):\n        r_t = residuals[t_idx]\n        \n        # Update CUSUM statistic: S_t = max(0, S_{t-1} + r_t - mu_0 - k)\n        s_current = max(0.0, s_current + r_t - mu_0 - k)\n        \n        # Check against threshold h\n        if s_current >= h:\n            # Stopping epoch tau is t = t_idx + 2\n            return t_idx + 2\n            \n    # If the loop completes without stopping\n    return -1\n\ndef solve():\n    \"\"\"\n    Runs the CUSUM detector on the provided test suite and prints the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"id\": \"A\",\n            \"losses\": [1.00, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50, 0.45, 0.465, 0.480, 0.495, 0.510, 0.525, 0.540, 0.555, 0.570],\n            \"W\": 6,\n            \"k\": 0.02,\n            \"h\": 0.10\n        },\n        {\n            \"id\": \"B\",\n            \"losses\": [1.00, 0.97, 0.94, 0.91, 0.88, 0.85, 0.82, 0.79, 0.76, 0.73, 0.70, 0.67, 0.64, 0.61, 0.58],\n            \"W\": 6,\n            \"k\": 0.02,\n            \"h\": 0.10\n        },\n        {\n            \"id\": \"C\",\n            \"losses\": [1.00, 0.96, 0.92, 0.88, 0.84, 0.80, 0.76, 0.72, 0.71, 0.70, 0.69],\n            \"W\": 5,\n            \"k\": 0.01,\n            \"h\": 0.06\n        },\n        {\n            \"id\": \"D\",\n            \"losses\": [1.00, 0.95, 0.90, 0.85, 0.80, 0.82, 0.84, 0.79, 0.74, 0.69, 0.64, 0.59, 0.54, 0.49, 0.44],\n            \"W\": 6,\n            \"k\": 0.02,\n            \"h\": 0.10\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        tau = cusum_early_stopping(case[\"losses\"], case[\"W\"], case[\"k\"], case[\"h\"])\n        results.append(tau)\n\n    # Print results in the required format: [tau_A,tau_B,tau_C,tau_D]\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the solver\nsolve()\n```"
        },
        {
            "introduction": "早停法的理念不仅限于监控验证损失。在更广阔的视野下，它是指在模型开始学习数据中“有害”模式之前停止训练。一个典型的例子是在存在标签噪声的数据集上训练。本练习将带你探索一个前沿应用：通过监控训练集上每个样本损失值的分布动态，来检测模型开始“记忆”错误标签的精确时刻。你将实现一个基于损失直方图分位数的检测规则，这是一种不依赖验证集，而是直接从训练动态中寻找早停信号的先进策略。",
            "id": "3119110",
            "problem": "您将获得一个程式化的设置，用于研究在有标签噪声的情况下，深度学习中的早停（early stopping）问题。其基础是经验风险最小化（ERM），即训练一个参数为 $\\theta$ 的模型来最小化经验风险 $\\frac{1}{n}\\sum_{i=1}^{n}\\ell(y_i, f_\\theta(x_i))$，其中在训练轮次 $t$ 时，单个样本的损失为非负的 $\\ell_i(t)$。在比率为 $\\rho \\in [0,1]$ 的对称标签噪声下，一部分比例为 $\\rho$ 的标签被均匀随机地损坏，而剩下比例为 $1-\\rho$ 的标签是干净的。一个广泛观察到的现象是，在训练过程中，干净样本的损失会较早下降，而噪声样本最初保持高损失，直到模型开始记忆噪声时，其损失才开始下降。这导致单个样本损失的直方图出现一种特征性演变：高损失尾部起初保持稳定，当记忆开始时便开始收缩。早停旨在模型拟合噪声尾部之前选择一个轮次。\n\n您必须实现一个程序，该程序在给定一个合成但科学上可信的单个样本损失 $\\ell_i(t)$ 生成器和一个基于直方图的检测规则的情况下，为多个测试用例输出检测到的早停轮次。检测规则必须使用损失分布的分位数来指定，作为右尾直方图质量的稳定代理指标。\n\n合成损失生成器。对于每个测试用例，您会获得：\n- 训练样本数量 $n$，\n- 对称标签噪声率 $\\rho$，\n- 总训练轮次数 $T$，\n- 随机种子 $s$，\n- 干净样本衰减率 $\\alpha > 0$，\n- 记忆后噪声样本衰减率 $\\beta > 0$，\n- 记忆开始轮次 $t_m \\in \\{0,1,\\dots,T-1\\}$，\n- 用于模拟随机性的高斯噪声标准差 $\\sigma > 0$，\n- 以及下面定义的检测超参数。\n\n为保证可复现性，您必须从一个用给定种子 $s$ 初始化的伪随机数生成器中获取所有随机性。以概率 $\\rho$ 将单个样本的身份生成为噪声样本，以概率 $1-\\rho$ 生成为干净样本，各样本之间独立。对于每个样本 $j \\in \\{1,\\dots,n\\}$，从 $\\mathrm{Uniform}(0,1)$ 分布中抽取一次难度 $d_j$，并在所有轮次中重复使用。定义以下基准值：\n- 干净样本基准值 $b^{\\mathrm{clean}}_j = 1.6 + 0.4 d_j$，\n- 干净样本下限值 $f^{\\mathrm{clean}}_j = 0.05 + 0.05 d_j$，\n- 噪声样本基准值 $b^{\\mathrm{noisy}}_j = 2.2 + 0.4 d_j$，\n- 噪声样本下限值 $f^{\\mathrm{noisy}}_j = 0.02 + 0.01 d_j$。\n\n对于每个轮次 $t \\in \\{0,1,\\dots,T-1\\}$ 和样本 $j$，独立地对 $j$ 和 $t$ 定义噪声项 $\\varepsilon_{j,t} \\sim \\mathcal{N}(0,\\sigma^2)$，然后如下定义单个样本的损失 $\\ell_j(t)$：\n- 如果 $j$ 是干净样本：\n$$\n\\ell_j(t) = f^{\\mathrm{clean}}_j + \\bigl(b^{\\mathrm{clean}}_j - f^{\\mathrm{clean}}_j\\bigr)\\exp(-\\alpha t) + \\varepsilon_{j,t}.\n$$\n- 如果 $j$ 是噪声样本：\n$$\n\\ell_j(t) =\n\\begin{cases}\nb^{\\mathrm{noisy}}_j + \\varepsilon_{j,t},  \\text{如果 } t  t_m,\\\\\nf^{\\mathrm{noisy}}_j + \\bigl(b^{\\mathrm{noisy}}_j - f^{\\mathrm{noisy}}_j\\bigr)\\exp\\bigl(-\\beta (t - t_m)\\bigr) + \\varepsilon_{j,t},  \\text{如果 } t \\ge t_m.\n\\end{cases}\n$$\n最后，将损失在零处进行裁剪，即 $\\ell_j(t) \\leftarrow \\max\\{\\ell_j(t), 0\\}$。\n\n基于损失直方图动态的检测规则。设 $q_p(t)$ 表示在轮次 $t$ 时 $\\{\\ell_1(t),\\dots,\\ell_n(t)\\}$ 的经验 $p$-分位数，其中固定的 $p \\in (0,1)$ 强调右尾（例如，$p=0.9$）。定义一个窗口长度为 $w \\in \\mathbb{N}$ 的移动平均平滑器：\n$$\n\\widehat{q}_p(t) = \\frac{1}{w}\\sum_{k=0}^{w-1} q_p(t-k), \\quad \\text{定义于 } t \\ge w-1.\n$$\n定义离散斜率\n$$\ns(t) = \\widehat{q}_p(t) - \\widehat{q}_p(t-1), \\quad \\text{定义于 } t \\ge w.\n$$\n给定一个负斜率阈值 $\\gamma > 0$、一个要求的连续轮次数 $s_{\\mathrm{consec}} \\in \\mathbb{N}$ 和一个预热期 $t_{\\mathrm{warm}} \\in \\mathbb{N}$，检测满足 $t^\\star \\ge \\max\\{w, t_{\\mathrm{warm}}\\}$ 并且对于所有 $t \\in \\{t^\\star, t^\\star + 1, \\dots, t^\\star + s_{\\mathrm{consec}} - 1\\}$ 都有\n$$\ns(t) \\le -\\gamma\n$$\n成立的最早轮次 $t^\\star$。\n如果存在这样的轮次，则输出 $t^\\star$；否则输出 $T$。\n\n您的程序必须完全按照定义实现上述生成器和检测规则，并使用提供的测试套件。本问题不涉及物理单位，也不涉及角度。所有比例必须以小数表示（例如，百分之三十写作 $0.3$）。所有测试用例的最终输出必须是单行文本，包含一个由方括号括起来的、逗号分隔的检测到的轮次列表。\n\n测试套件。请实现您的程序，按以下顺序在下列参数集上运行：\n\n- A案例（理想情况，中等噪声，记忆开始点清晰）：\n    - $n = 4000$，$\\rho = 0.3$， $T = 60$， $s = 42$， $\\alpha = 0.12$， $\\beta = 0.25$， $t_m = 25$， $\\sigma = 0.03$， $p = 0.9$， $w = 3$， $\\gamma = 0.04$， $s_{\\mathrm{consec}} = 2$， $t_{\\mathrm{warm}} = 5$。\n\n- B案例（边界情况：无标签噪声，使用足够严格的阈值时不应触发检测）：\n    - $n = 4000$，$\\rho = 0.0$， $T = 60$， $s = 123$， $\\alpha = 0.12$， $\\beta = 0.25$， $t_m = 25$， $\\sigma = 0.03$， $p = 0.9$， $w = 3$， $\\gamma = 0.2$， $s_{\\mathrm{consec}} = 2$， $t_{\\mathrm{warm}} = 5$。\n\n- C案例（高噪声，记忆开始点较晚）：\n    - $n = 4000$，$\\rho = 0.6$， $T = 70$， $s = 7$， $\\alpha = 0.12$， $\\beta = 0.20$， $t_m = 40$， $\\sigma = 0.03$， $p = 0.9$， $w = 3$， $\\gamma = 0.03$， $s_{\\mathrm{consec}} = 2$， $t_{\\mathrm{warm}} = 5$。\n\n- D案例（边缘情况：小数据集且记忆非常缓慢，可能不触发检测）：\n    - $n = 300$，$\\rho = 0.4$， $T = 50$， $s = 999$， $\\alpha = 0.08$， $\\beta = 0.05$， $t_m = 30$， $\\sigma = 0.04$， $p = 0.9$， $w = 4$， $\\gamma = 0.03$， $s_{\\mathrm{consec}} = 3$， $t_{\\mathrm{warm}} = 5$。\n\n要求的最终输出格式。您的程序应生成单行输出，其中包含一个由方括号括起来的、逗号分隔的结果列表（例如，“[result_A,result_B,result_C,result_D]”），其中每个结果是对应案例定义的整数轮次索引。",
            "solution": "用户提供了一个问题，要求在深度学习背景下实现一个用于早停的模拟和检测算法。该问题具有科学依据，定义明确，并提供了所有必要的参数和定义。因此，该问题被视为有效，并将开发一个完整的解决方案。\n\n解决方案分为两个主要概念部分：在一系列轮次中生成合成的单个样本训练损失，以及对这些损失应用特定的检测规则以确定最佳的早停轮次。\n\n### 第1部分：合成单个样本损失的生成\n\n第一步是生成单个样本损失矩阵，记为 $\\ell_j(t)$，表示样本 $j$ 在轮次 $t$ 的损失。该过程的维度由样本数量 $n$ 和总轮次数 $T$ 定义。\n\n1.  **初始化与随机性**：为保证可复现性，所有随机元素均源自一个用给定种子 $s$ 初始化的伪随机数生成器。\n\n2.  **样本身份与难度**：$n$ 个样本中的每一个都被分为“干净”或“噪声”两类。一个样本被指定为噪声样本的概率为 $\\rho$，干净样本的概率为 $1-\\rho$。此分配对每个样本独立进行。同时，为每个样本 $j$ 分配一个静态的“难度”参数 $d_j$，该参数从均匀分布 $\\mathrm{Uniform}(0, 1)$ 中抽取。此难度参数在整个训练过程中调节该特定样本的损失特性。\n\n3.  **损失特性**：根据样本的身份（干净或噪声）及其难度 $d_j$，定义了四个关键值：\n    -   干净样本基准损失：$b^{\\mathrm{clean}}_j = 1.6 + 0.4 d_j$\n    -   干净样本下限损失：$f^{\\mathrm{clean}}_j = 0.05 + 0.05 d_j$\n    -   噪声样本基准损失：$b^{\\mathrm{noisy}}_j = 2.2 + 0.4 d_j$\n    -   噪声样本下限损失：$f^{\\mathrm{noisy}}_j = 0.02 + 0.01 d_j$\n    “基准”值代表初始的高损失，而“下限”值代表经过大量训练后可达到的最小损失。\n\n4.  **损失演变动态**：对每个样本 $j \\in \\{1, \\dots, n\\}$ 和轮次 $t \\in \\{0, \\dots, T-1\\}$，单个样本损失 $\\ell_j(t)$ 的建模如下。\n    -   对于一个**干净**样本，损失从其基准值向其下限值指数衰减，由衰减率 $\\alpha$ 控制：\n        $$\n        \\ell_j(t) = f^{\\mathrm{clean}}_j + \\bigl(b^{\\mathrm{clean}}_j - f^{\\mathrm{clean}}_j\\bigr)\\exp(-\\alpha t) + \\varepsilon_{j,t}\n        $$\n    -   对于一个**噪声**样本，其行为根据记忆开始轮次 $t_m$ 分岔。在此轮次之前，模型未能拟合不正确的标签，损失保持较高水平。在此轮次之后，模型开始“记忆”噪声标签，导致损失下降。这由衰减率 $\\beta$ 控制：\n        $$\n        \\ell_j(t) =\n        \\begin{cases}\n        b^{\\mathrm{noisy}}_j + \\varepsilon_{j,t},  \\text{如果 } t  t_m, \\\\\n        f^{\\mathrm{noisy}}_j + \\bigl(b^{\\mathrm{noisy}}_j - f^{\\mathrm{noisy}}_j\\bigr)\\exp\\bigl(-\\beta (t - t_m)\\bigr) + \\varepsilon_{j,t},  \\text{如果 } t \\ge t_m.\n        \\end{cases}\n        $$\n    在两种情况下，$\\varepsilon_{j,t}$ 是一个从零均值高斯分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽取的随机噪声项，为每个样本和轮次独立添加，以模拟训练的随机性。最后，由于损失值必须为非负，计算出的损失在零处被裁剪：$\\ell_j(t) \\leftarrow \\max\\{\\ell_j(t), 0\\}$。\n\n### 第2部分：基于直方图的早停检测\n\n该过程的第二部分是分析生成的损失矩阵，以识别最佳停止轮次 $t^\\star$。要检测的现象是记忆的开始，表现为噪声样本损失的突然下降。这种下降导致损失分布直方图的右尾收缩。\n\n1.  **分位数作为代理指标**：通过在每个轮次 $t$ 计算损失集合 $\\{\\ell_1(t), \\dots, \\ell_n(t)\\}$ 的经验 $p$-分位数 $q_p(t)$ 来追踪损失分布的右尾。接近 1 的 $p$ 值（例如，$p=0.9$）确保该指标对高损失样本敏感，这些样本在记忆开始前主要为噪声样本。\n\n2.  **平滑处理**：为减轻随机噪声 $\\varepsilon_{j,t}$ 的影响并获得更稳定的信号，使用窗口大小为 $w$ 的移动平均对原始分位数序列 $q_p(t)$ 进行平滑处理。平滑后的分位数 $\\widehat{q}_p(t)$ 定义于轮次 $t \\ge w-1$：\n    $$\n    \\widehat{q}_p(t) = \\frac{1}{w}\\sum_{k=0}^{w-1} q_p(t-k)\n    $$\n\n3.  **斜率计算**：记忆的开始以平滑分位数的急剧下降为标志。这通过计算平滑分位数序列的离散斜率（或一阶差分）来检测。斜率 $s(t)$ 定义于轮次 $t \\ge w$：\n    $$\n    s(t) = \\widehat{q}_p(t) - \\widehat{q}_p(t-1)\n    $$\n\n4.  **检测规则**：早停轮次 $t^\\star$ 是基于一个持续性条件来识别的。它是满足两个标准的最早轮次 $t^\\star$：\n    -   它必须发生在“预热”期之后，即 $t^\\star \\ge \\max\\{w, t_{\\mathrm{warm}}\\}$。预热期 $t_{\\mathrm{warm}}$ 防止因初始训练瞬态而过早停止。条件 $t^\\star \\ge w$ 是必要的，因为斜率 $s(t)$ 最早从 $t=w$ 开始定义。\n    -   斜率必须在一段持续时间内显著为负。具体来说，从 $t^\\star$ 开始的 $s_{\\mathrm{consec}}$ 个连续轮次中，斜率 $s(t)$ 必须小于或等于一个负阈值 $-\\gamma$（其中 $\\gamma > 0$）。也就是说，对于所有 $t \\in \\{t^\\star, t^\\star + 1, \\dots, t^\\star + s_{\\mathrm{consec}} - 1\\}$，必须满足 $s(t) \\le -\\gamma$。\n\n如果找到了满足这些条件的轮次 $t^\\star$，则将其作为结果返回。如果搜索完成仍未找到这样的轮次，算法将返回总轮次数 $T$，表示未触发早停。\n\n整个程序被实现并应用于问题陈述中指定的每个测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(n, rho, T, s_seed, alpha, beta, t_m, sigma, p, w, gamma, s_consec, t_warm):\n    \"\"\"\n    Runs the simulation and detection algorithm for a single test case.\n    \"\"\"\n    # 1. Initialize random number generator for reproducibility.\n    rng = np.random.default_rng(s_seed)\n\n    # 2. Generate per-example identities and difficulties.\n    is_noisy = rng.choice([True, False], size=n, p=[rho, 1 - rho])\n    d = rng.uniform(0, 1, size=n)\n\n    # 3. Define base and floor values for losses.\n    b_clean = 1.6 + 0.4 * d\n    f_clean = 0.05 + 0.05 * d\n    b_noisy = 2.2 + 0.4 * d\n    f_noisy = 0.02 + 0.01 * d\n\n    # 4. Generate the T x n matrix of per-example losses over all epochs.\n    losses = np.zeros((T, n))\n    # Pre-generate all Gaussian noise for efficiency.\n    gaussian_noise = rng.normal(0, sigma, size=(T, n))\n\n    for t in range(T):\n        # Calculate base losses for clean examples at epoch t\n        loss_clean_t = f_clean + (b_clean - f_clean) * np.exp(-alpha * t)\n\n        # Calculate base losses for noisy examples at epoch t\n        if t  t_m:\n            loss_noisy_t = b_noisy\n        else:\n            loss_noisy_t = f_noisy + (b_noisy - f_noisy) * np.exp(-beta * (t - t_m))\n\n        # Combine based on whether an example is noisy or clean\n        epoch_losses = np.where(is_noisy, loss_noisy_t, loss_clean_t)\n        \n        # Add stochastic noise\n        epoch_losses += gaussian_noise[t, :]\n        \n        # Clip losses at zero\n        losses[t, :] = np.maximum(epoch_losses, 0)\n\n    # 5. Calculate the p-quantile of the loss distribution for each epoch.\n    if losses.shape[1] == 0:  # Handle edge case of n=0\n        q_p = np.zeros(T)\n    else:\n        q_p = np.quantile(losses, p, axis=1)\n\n    # 6. Compute the smoothed quantiles using a moving average.\n    q_p_hat = np.zeros_like(q_p)\n    # The moving average is defined for t >= w-1.\n    for t in range(w - 1, T):\n        q_p_hat[t] = np.mean(q_p[t - w + 1 : t + 1])\n\n    # 7. Compute the discrete slope of the smoothed quantiles.\n    slopes = np.zeros_like(q_p)\n    # The slope is defined for t >= w.\n    for t in range(w, T):\n        slopes[t] = q_p_hat[t] - q_p_hat[t - 1]\n\n    # 8. Search for the early stopping epoch t_star.\n    t_star = T\n    t_search_start = max(w, t_warm)\n\n    # The latest possible start of a valid sequence is T - s_consec.\n    # The loop should go up to and including this value.\n    for t_candidate in range(t_search_start, T - s_consec + 1):\n        # Check if the slope is below the threshold for s_consec consecutive epochs.\n        sub_slopes = slopes[t_candidate : t_candidate + s_consec]\n        if np.all(sub_slopes = -gamma):\n            t_star = t_candidate\n            break  # Found the earliest such epoch\n    \n    return t_star\n\n\ndef solve():\n    \"\"\"\n    Defines the test suite and runs the simulation for each case.\n    \"\"\"\n    test_cases = [\n        # Case A (happy path, moderate noise, clear memorization onset)\n        {\"n\": 4000, \"rho\": 0.3, \"T\": 60, \"s_seed\": 42, \"alpha\": 0.12, \"beta\": 0.25, \n         \"t_m\": 25, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.04, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case B (boundary: no label noise)\n        {\"n\": 4000, \"rho\": 0.0, \"T\": 60, \"s_seed\": 123, \"alpha\": 0.12, \"beta\": 0.25, \n         \"t_m\": 25, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.2, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case C (high noise, later memorization onset)\n        {\"n\": 4000, \"rho\": 0.6, \"T\": 70, \"s_seed\": 7, \"alpha\": 0.12, \"beta\": 0.20, \n         \"t_m\": 40, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.03, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case D (edge: small dataset and very slow memorization)\n        {\"n\": 300, \"rho\": 0.4, \"T\": 50, \"s_seed\": 999, \"alpha\": 0.08, \"beta\": 0.05, \n         \"t_m\": 30, \"sigma\": 0.04, \"p\": 0.9, \"w\": 4, \"gamma\": 0.03, \n         \"s_consec\": 3, \"t_warm\": 5},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_simulation(**params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}