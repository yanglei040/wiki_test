{
    "hands_on_practices": [
        {
            "introduction": "在机器学习中，我们的目标是训练出具有良好泛化能力的模型。本练习将通过一个受控的模拟实验，帮助你直观地理解两种常见的模型选择策略：早停（Early Stopping）和检查点平均（Checkpoint Averaging）。你将通过比较它们在控制过拟合（通过泛化差距 $L_{\\text{test}} - L_{\\text{train}}$ 来衡量）方面的表现，来深入探究早停作为一种隐式正则化方法的核心优势。",
            "id": "3119093",
            "problem": "要求您在一个受控的深度学习模拟中实现并分析两种模型选择策略，该模拟使用一维线性回归代理模型来模仿训练动态和泛化行为。比较指标是跨随机种子的期望泛化差距，定义为在选定模型参数下，测试损失与训练损失之差的期望值。您的程序必须是一个完整、可运行的程序。\n\n基本基础和设置：\n- 考虑一个数据生成过程，其中输入 $x$ 从标准正态分布 $x \\sim \\mathcal{N}(0,1)$ 中独立采样，输出 $y$ 由 $y = \\theta^\\ast x + \\epsilon$ 生成，其中噪声 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$ 与 $x$ 无关。参数 $\\theta^\\ast$ 是真实的数据生成系数。\n- 训练过程是使用批量梯度下降 (GD) 进行经验风险最小化 (ERM)，以最小化均方误差 (MSE) 损失。对于一个参数 $\\theta$ 和数据集 $\\{(x_i, y_i)\\}_{i=1}^n$，经验损失为 $L(\\theta) = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\theta x_i)^2$。关于 $\\theta$ 的梯度是 $\\nabla_\\theta L(\\theta) = \\frac{2}{n}\\sum_{i=1}^n x_i(\\theta x_i - y_i)$。\n- 在第 $t$ 轮次 (epoch) 的 GD 更新规则是 $\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta L(\\theta_t)$，其中 $\\eta$ 是学习率，初始化为 $\\theta_0 = 0$。\n- 定义参数 $\\theta$ 的泛化差距为 $G(\\theta) = L_{\\text{test}}(\\theta) - L_{\\text{train}}(\\theta)$，其中 $L_{\\text{train}}$ 和 $L_{\\text{test}}$ 分别是在训练集和测试集上计算的经验 MSE。\n- 跨种子的期望是通过对由随机种子列表控制的数据集和噪声的独立抽取进行平均。对于一个为每个种子 $s$ 产生参数 $\\theta_{sel}^{(s)}$ 的选择规则，期望泛化差距为 $\\mathbb{E}_s\\big[G(\\theta_{sel}^{(s)})\\big]$，通过对给定种子的算术平均值来近似。\n\n需要比较的模型选择策略：\n1. 早停 (Early Stopping, ES)：使用一个独立的验证集来监控每个轮次的验证损失 $L_{val}(\\theta_t)$。维持迄今为止看到的最佳验证损失及其对应的轮次。如果验证损失在 $p$ 个连续轮次（即耐心值）内没有严格改善，则停止选择，并选择在停止前遇到的最佳轮次所对应的参数。形式上，扫描轮次 $t=0,1,\\dots$；每当 $L_{val}(\\theta_t)  \\min_{u \\le t-1} L_{val}(\\theta_u)$ 时，记录 $t$ 为新的最佳轮次，并重置一个未改善轮次的计数器。否则，增加该计数器；如果它超过 $p$，则终止并选择最后记录的最佳轮次。计算所选参数 $\\theta_{ES}$ 的泛化差距 $G(\\theta_{ES})$。\n2. 检查点平均 (Checkpoint Averaging, CA)：训练固定的总共 $E$ 个轮次。设最后 $k$ 个参数为 $\\theta_{E-k+1}, \\dots, \\theta_E$。定义平均化参数为 $\\bar{\\theta} = \\frac{1}{k}\\sum_{u=E-k+1}^E \\theta_u$。计算泛化差距 $G(\\bar{\\theta})$。\n\n每个种子 $s$ 的模拟协议：\n- 使用种子 $s$，根据给定的 $n_{train}$、$n_{val}$ 和 $n_{test}$ 生成独立的训练、验证和测试数据集。\n- 使用训练集执行批量 GD，共 $E$ 个轮次，存储每个轮次 $t$ 的 $\\theta_t$。\n- 计算每个轮次 $t$ 的 $L_{\\text{train}}(\\theta_t)$、$L_{\\text{val}}(\\theta_t)$ 和 $L_{\\text{test}}(\\theta_t)$。\n- 应用 ES 选择 $\\theta_{ES}$ 并计算 $G(\\theta_{ES})$。\n- 应用 CA 计算 $\\bar{\\theta}$ 并计算 $G(\\bar{\\theta})$。\n- 对该案例中的所有种子重复此过程，并计算 $G(\\theta_{ES})$ 的均值和 $G(\\bar{\\theta})$ 的均值。\n\n测试套件：\n为以下参数集实现上述模拟。在所有情况下，损失是无量纲的，最终输出必须是浮点数。将最终输出四舍五入到 $6$ 位小数。\n\n- 案例 1（正常路径）：\n  - 真实参数 $\\theta^\\ast = 1.5$\n  - 训练集大小 $n_{train} = 50$\n  - 验证集大小 $n_{val} = 100$\n  - 测试集大小 $n_{test} = 10000$\n  - 学习率 $\\eta = 0.05$\n  - 总轮次 $E = 120$\n  - 耐心 $p = 5$\n  - 平均窗口 $k = 10$\n  - 噪声标准差 $\\sigma_\\epsilon = 0.5$\n  - 种子：从 $0$到 $19$ 的整数（含）\n- 案例 2（边界：最小耐心，无平均）：\n  - 真实参数 $\\theta^\\ast = 1.5$\n  - 训练集大小 $n_{train} = 50$\n  - 验证集大小 $n_{val} = 100$\n  - 测试集大小 $n_{test} = 10000$\n  - 学习率 $\\eta = 0.05$\n  - 总轮次 $E = 120$\n  - 耐心 $p = 0$\n  - 平均窗口 $k = 1$\n  - 噪声标准差 $\\sigma_\\epsilon = 0.5$\n  - 种子：从 $20$ 到 $39$ 的整数（含）\n- 案例 3（边界：平均所有检查点，低噪声，更大数据）：\n  - 真实参数 $\\theta^\\ast = 1.5$\n  - 训练集大小 $n_{train} = 400$\n  - 验证集大小 $n_{val} = 400$\n  - 测试集大小 $n_{test} = 10000$\n  - 学习率 $\\eta = 0.02$\n  - 总轮次 $E = 200$\n  - 耐心 $p = 10$\n  - 平均窗口 $k = 200$\n  - 噪声标准差 $\\sigma_\\epsilon = 0.1$\n  - 种子：从 $40$ 到 $59$ 的整数（含）\n- 案例 4（边缘：高噪声，小数据，不同真实参数）：\n  - 真实参数 $\\theta^\\ast = -0.8$\n  - 训练集大小 $n_{train} = 20$\n  - 验证集大小 $n_{val} = 40$\n  - 测试集大小 $n_{test} = 10000$\n  - 学习率 $\\eta = 0.03$\n  - 总轮次 $E = 150$\n  - 耐心 $p = 3$\n  - 平均窗口 $k = 20$\n  - 噪声标准差 $\\sigma_\\epsilon = 1.2$\n  - 种子：从 $60$ 到 $79$ 的整数（含）\n\n要求的最终输出格式：\n- 您的程序应生成一行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，每个元素对应一个案例，其本身是一个包含早停和检查点平均的期望泛化差距的双元素列表，两个值都四舍五入到 $6$ 位小数。例如，其形状必须类似于 $\\big[ [g_{ES}^{(1)}, g_{CA}^{(1)}], [g_{ES}^{(2)}, g_{CA}^{(2)}], [g_{ES}^{(3)}, g_{CA}^{(3)}], [g_{ES}^{(4)}, g_{CA}^{(4)}] \\big]$。",
            "solution": "问题陈述是有效的。它提出了一个适定、有科学依据且客观的模拟任务，与机器学习领域相关。该任务涉及在一个受控的一维线性回归设置中，比较两种常见的模型选择策略：早停 (ES) 和检查点平均 (CA)。所有参数、过程和定义都清晰无矛盾地给出，从而能够得出一个唯一且有意义的数值解。\n\n该解决方案首先阐述理论框架，然后详细说明算法实现。\n\n### 理论框架\n\n1.  **数据生成与模型：** 问题设定在一个简单的线性模型背景下。数据生成过程由 $y = \\theta^\\ast x + \\epsilon$ 定义，其中输入 $x$ 从标准正态分布 $x \\sim \\mathcal{N}(0,1)$ 中抽取，噪声项 $\\epsilon$ 也服从正态分布 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$。目标是使用模型 $\\hat{y} = \\theta x$ 来估计真实参数 $\\theta^\\ast$。\n\n2.  **优化：** 参数 $\\theta$ 通过在训练集 $\\{(x_i, y_i)\\}_{i=1}^{n_{train}}$ 上最小化均方误差 (MSE) 来优化。经验损失函数为 $L_{\\text{train}}(\\theta) = \\frac{1}{n_{\\text{train}}}\\sum_{i=1}^{n_{\\text{train}}} (y_i - \\theta x_i)^2$。优化方法是批量梯度下降 (GD)，它根据以下规则迭代更新参数：\n    $$\n    \\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta L_{\\text{train}}(\\theta_t)\n    $$\n    其中初始化为 $\\theta_0 = 0$，$\\eta$ 是学习率，$t$ 是轮次索引。损失的梯度为：\n    $$\n    \\nabla_\\theta L_{\\text{train}}(\\theta) = \\frac{2}{n_{\\text{train}}}\\sum_{i=1}^{n_{\\text{train}}} x_i(\\theta x_i - y_i)\n    $$\n    对于给定的训练集，此过程会生成一个确定的参数轨迹 $\\{\\theta_0, \\theta_1, \\dots, \\theta_E\\}$。模拟中的随机性源于为每个指定的随机种子采样数据集。\n\n3.  **泛化差距：** 评估的核心指标是泛化差距，定义为模型在未见过的测试数据上的性能与其在训练数据上的性能之差：\n    $$\n    G(\\theta) = L_{\\text{test}}(\\theta) - L_{\\text{train}}(\\theta)\n    $$\n    大的正差距是过拟合的标志，即模型学习到了训练集的特质，而这些特质无法泛化到更广泛的数据分布中。最终的比较指标是期望泛化差距 $\\mathbb{E}_s[G(\\theta_{sel})]$，通过对多个独立模拟（种子）的差距进行平均来近似。\n\n4.  **模型选择策略：**\n    *   **早停 (ES)：** 这种技术通过防止模型训练时间过长而导致过拟合，起到一种正则化的作用。它的工作原理是监控一个独立的验证集上的损失 $L_{val}(\\theta_t)$。当验证损失在指定的轮次数（称为耐心，$p$）内未能严格改善时，训练实际上就停止了。所选择的参数不是训练停止时的参数，而是在此过程中观察到的产生最佳（最小）验证损失的那个轮次的参数。该策略直接旨在选择一个具有良好泛化性能的模型，这种性能由验证集作为代理来衡量。\n    *   **检查点平均 (CA)：** 此方法涉及训练固定的轮次数 ($E$)，然后对最后 $k$ 个轮次的参数进行平均。平均化参数为 $\\bar{\\theta} = \\frac{1}{k}\\sum_{u=E-k+1}^E \\theta_u$。这种方法背后的直觉（与 Polyak-Ruppert 平均有关）是，对优化轨迹上一部分参数进行平均，可以得到一个更稳定的解，该解位于损失景观中一个更宽、更平坦的区域，这通常与更好的泛化性能相关。\n\n### 算法实现\n\n该解决方案通过一个程序实现，该程序为四个指定案例中的每一个执行模拟。\n\n1.  **主循环：** 程序遍历每个参数案例。对于每个案例，它运行一系列模拟，每个指定范围内的种子对应一个模拟。\n\n2.  **单一种子模拟：** 对于给定的种子 $s$：\n    a.  **数据生成：** 使用 $s$ 为新的随机数生成器设定种子。根据过程 $x \\sim \\mathcal{N}(0,1)$ 和 $y = \\theta^\\ast x + \\epsilon$（其中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$），生成大小为 $n_{train}$、$n_{val}$ 和 $n_{test}$ 的独立训练、验证和测试数据集。\n    b.  **梯度下降：** 从 $\\theta_0=0$ 开始，运行 GD 算法 $E$ 个轮次。存储所有中间参数 $\\theta_0, \\theta_1, \\dots, \\theta_E$。梯度计算被向量化以提高效率。\n    c.  **损失评估：** 对每个存储的参数 $\\theta_t$，在训练、验证和测试集上计算 MSE，从而得到轨迹 $L_{\\text{train}}(\\theta_t)$、$L_{\\text{val}}(\\theta_t)$ 和 $L_{\\text{test}}(\\theta_t)$。\n    d.  **早停选择：** 从 $t=0$ 到 $E$ 扫描存储的验证损失 $L_{val}(\\theta_t)$。跟踪对应于迄今为止所见的最小验证损失的轮次 $t_{best}$。对于每个未能产生新的严格更低验证损失的轮次，耐心计数器会增加；一旦有改善，计数器就会重置。如果计数器超过耐心参数 $p$，则扫描终止。选择的参数是 $\\theta_{ES} = \\theta_{t_{best}}$。然后计算泛化差距 $G(\\theta_{ES})$。\n    e.  **检查点平均选择：** 通过对训练轨迹的最后 $k$ 个参数 $\\{\\theta_{E-k+1}, \\dots, \\theta_E\\}$ 进行平均来计算参数 $\\bar{\\theta}$。然后计算泛化差距 $G(\\bar{\\theta})$。\n\n3.  **平均与输出：** 在完成一个案例中所有种子的模拟后，分别为 ES 和 CA 收集到的泛化差距计算平均值。这两个平均值构成了该案例的结果。最终的程序输出将所有四个案例的结果整理成指定的列表的列表格式，每个数值都四舍五入到六位小数。",
            "answer": "```python\nimport numpy as np\n\ndef mse(theta, x, y):\n    \"\"\"\n    Calculates the Mean Squared Error for a 1D linear model.\n    \"\"\"\n    if y.size == 0:\n        return 0.0\n    return np.mean((y - theta * x)**2)\n\ndef run_simulation_for_case(params):\n    \"\"\"\n    Runs the full simulation for one set of parameters.\n    \"\"\"\n    theta_star, n_train, n_val, n_test, eta, E, p, k, sigma_eps, seeds = params\n\n    es_gaps = []\n    ca_gaps = []\n\n    for seed in seeds:\n        rng = np.random.default_rng(seed)\n        \n        # 1. Data Generation\n        x_train = rng.standard_normal(n_train)\n        eps_train = rng.standard_normal(n_train) * sigma_eps\n        y_train = theta_star * x_train + eps_train\n        \n        x_val = rng.standard_normal(n_val)\n        eps_val = rng.standard_normal(n_val) * sigma_eps\n        y_val = theta_star * x_val + eps_val\n\n        x_test = rng.standard_normal(n_test)\n        eps_test = rng.standard_normal(n_test) * sigma_eps\n        y_test = theta_star * x_test + eps_test\n\n        # 2. Training (Batch Gradient Descent)\n        thetas = np.zeros(E + 1)\n        theta_t = 0.0\n        \n        mean_x_sq_train = np.mean(x_train**2)\n        mean_xy_train = np.mean(x_train * y_train)\n\n        for t in range(E):\n            grad = 2 * (theta_t * mean_x_sq_train - mean_xy_train)\n            theta_t = theta_t - eta * grad\n            thetas[t + 1] = theta_t\n\n        # 3. Loss Calculation\n        train_losses = np.array([mse(th, x_train, y_train) for th in thetas])\n        val_losses = np.array([mse(th, x_val, y_val) for th in thetas])\n        test_losses = np.array([mse(th, x_test, y_test) for th in thetas])\n\n        # 4. Early Stopping (ES)\n        best_val_loss = float('inf')\n        best_epoch = 0\n        patience_counter = 0\n\n        for t in range(E + 1):\n             current_val_loss = val_losses[t]\n             if current_val_loss  best_val_loss:\n                 best_val_loss = current_val_loss\n                 best_epoch = t\n                 patience_counter = 0\n             else:\n                 patience_counter += 1\n            \n             if patience_counter > p:\n                 break\n        \n        theta_es = thetas[best_epoch]\n        es_gap = test_losses[best_epoch] - train_losses[best_epoch]\n        es_gaps.append(es_gap)\n\n        # 5. Checkpoint Averaging (CA)\n        theta_ca_list = thetas[E - k + 1 : E + 1]\n        theta_ca = np.mean(theta_ca_list)\n        ca_gap = mse(theta_ca, x_test, y_test) - mse(theta_ca, x_train, y_train)\n        ca_gaps.append(ca_gap)\n\n    return [round(np.mean(es_gaps), 6), round(np.mean(ca_gaps), 6)]\n\ndef solve():\n    \"\"\"\n    Defines the test cases and formats the final output.\n    \"\"\"\n    case1 = (1.5, 50, 100, 10000, 0.05, 120, 5, 10, 0.5, range(0, 20))\n    case2 = (1.5, 50, 100, 10000, 0.05, 120, 0, 1, 0.5, range(20, 40))\n    case3 = (1.5, 400, 400, 10000, 0.02, 200, 10, 200, 0.1, range(40, 60))\n    case4 = (-0.8, 20, 40, 10000, 0.03, 150, 3, 20, 1.2, range(60, 80))\n    \n    test_cases = [case1, case2, case3, case4]\n\n    results = []\n    for case in test_cases:\n        result = run_simulation_for_case(case)\n        results.append(result)\n        \n    final_output_str = str(results).replace(\" \", \"\")\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "标准的早停策略对验证集损失的随机波动很敏感，尤其是在验证集较小的情况下，这可能导致过早停止训练。本练习旨在解决这一问题，引导你实现一种更稳健的、基于统计显著性的早停规则。通过区分真实的性能提升和随机噪声，你将学会如何构建一个更可靠的停止准则，以避免因偶然的验证损失抖动而做出错误的决策。",
            "id": "3119052",
            "problem": "给定一个训练场景，其中模型使用大量的输入增强进行训练，但早停必须基于一个大小为 $m$ 的未经增强的验证子集。由于验证子集很小，经验验证风险估计会表现出采样噪声。您的任务是设计并实现一个有原则的、能感知方差的早停规则，该规则仅使用未经增强的验证测量值来决定何时停止以及选择哪个周期，同时完全忽略增强后的训练损失来进行停止决策。\n\n从以下基本原理出发：\n- 经验风险最小化：在周期 $t$ 的未经增强的验证损失是 $m$ 个独立同分布的单样本损失的经验均值，它是真实风险的无偏估计量。\n- 对于 $m$ 个方差为 $\\sigma^2$ 的独立同分布变量的样本均值，其方差为 $\\sigma^2 / m$。\n- 根据中心极限定理，每个周期的经验均值近似服从以真实风险为中心、标准误差为 $\\sqrt{\\sigma^2 / m}$ 的正态分布。\n\n基于这些原则，推导出一个停止规则，以防止在表观上的改进与噪声相当时错误地判断为取得了进展。然后在您的程序中实现以下考虑显著性的耐心规则：\n- 定义一个决策阈值 $\\tau = c \\cdot \\sqrt{\\sigma^2 / m}$，其中 $c$ 是一个用户选择的正常数。\n- 维护两个跟踪量：至今为止观察到的原始最佳验证均值（即迄今为止的最小值），以及记录到统计显著改进的最后一个周期。\n- 在每个周期 $t$，如果当前未经增强的验证均值低于之前的原始最佳值，则更新原始最佳值。另外，如果当前未经增强的验证均值比上一次显著改进时的值至少低 $\\tau$，则记录一次统计显著的改进。\n- 在第一个满足 $t - t_{\\text{last-significant}} \\ge P$ 的周期 $t$ 停止，其中 $P$ 是一个非负整数耐心参数。当满足此停止条件时，所选周期是截至并包括周期 $t$ 所观察到的原始最佳验证均值的周期索引。如果该条件从未触发，则选择所有周期中具有原始最佳验证均值的周期。\n- 在您的输出中，周期索引必须是从 $1$ 开始的。\n\n您的程序必须严格实现此规则，并为以下测试套件生成答案。在每个测试用例中，您将获得：\n- 每个周期的未经增强的验证均值序列 $y_1, y_2, \\dots, y_T$（用于早停）。\n- 每个周期的增强训练均值序列 $a_1, a_2, \\dots, a_T$（仅供参考；不要用于停止决策）。\n- 子集大小 $m$、单样本方差 $\\sigma^2$、决策参数 $c$ 和耐心值 $P$。\n\n测试套件：\n- Case A:\n  - 未经增强的验证序列 $[1.00, 0.90, 0.82, 0.79, 0.78, 0.775, 0.774, 0.776, 0.780, 0.785, 0.790, 0.800]$。\n  - 增强后的训练序列 $[1.50, 1.30, 1.15, 1.05, 0.98, 0.94, 0.91, 0.89, 0.87, 0.86, 0.85, 0.84]$。\n  - 参数: $m = 25$, $\\sigma^2 = 0.0001$, $c = 1.96$, $P = 2$。\n- Case B:\n  - 未经增强的验证序列 $[1.00, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94, 0.93, 0.92, 0.91]$。\n  - 增强后的训练序列 $[1.40, 1.30, 1.20, 1.10, 1.05, 1.00, 0.96, 0.93, 0.91, 0.90]$。\n  - 参数: $m = 20$, $\\sigma^2 = 1\\times10^{-6}$, $c = 1.96$, $P = 3$。\n- Case C:\n  - 未经增强的验证序列 $[0.90, 0.85, 0.83, 0.835, 0.84, 0.845, 0.86, 0.87, 0.875, 0.88]$。\n  - 增强后的训练序列 $[1.20, 1.10, 1.02, 0.98, 0.95, 0.93, 0.92, 0.91, 0.905, 0.90]$。\n  - 参数: $m = 5$, $\\sigma^2 = 0.01$, $c = 1.96$, $P = 2$。\n- Case D:\n  - 未经增强的验证序列 $[1.20, 1.00, 0.95, 0.951, 0.96, 0.97]$。\n  - 增强后的训练序列 $[1.60, 1.45, 1.35, 1.28, 1.22, 1.18]$。\n  - 参数: $m = 10$, $\\sigma^2 = 0.0001$, $c = 1.96$, $P = 1$。\n\n重要的实现和输出要求：\n- 您的程序必须严格按照上述描述实现考虑显著性的耐心规则，仅使用未经增强的验证序列 $[y_t]$ 和参数 $m$、$\\sigma^2$、$c$ 和 $P$。\n- 周期索引必须是从 $1$ 开始的。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，顺序为 Case A、Case B、Case C、Case D。每个元素必须是所选的周期索引（一个整数）。例如，输出格式为 $[\\text{A},\\text{B},\\text{C},\\text{D}]$，其中每个符号被计算出的整数替换。",
            "solution": "用户提出了一个关于为机器学习模型训练设计原则性早停规则的问题，特别是在验证损失测量值受显著采样噪声影响的情况下。核心任务是开发一个“考虑显著性的耐心规则”，以避免因随机波动而过早停止，并根据统计上显著的改进来正确识别最佳模型检查点。\n\n该问题的表述基于统计学习理论的既定原则，并且是自洽的、适定的和科学上合理的。它提供了清晰的算法规范和一组用于验证的测试用例。因此，该问题是有效的，可以构建一个分步解决方案。\n\n所提规则的基础在于经验验证风险的统计特性。设模型在周期 $t$ 的真实但未知的风险（期望损失）为 $R_t$。我们测量到的量是经验风险，或称验证均值，$y_t$，它是在一个大小为 $m$ 的小验证集上计算的。这个经验风险是真实风险的无偏估计量，即 $E[y_t] = R_t$。根据中心极限定理，对于足够大的 $m$，$y_t$ 的分布可以近似为一个以真实风险 $R_t$ 为中心的正态分布：\n$$\ny_t \\approx \\mathcal{N}(R_t, \\frac{\\sigma^2}{m})\n$$\n其中 $\\sigma^2$ 是单样本损失的方差，假定为已知且恒定。该抽样分布的标准差，称为均值标准误差，为 $SE = \\sqrt{\\sigma^2 / m}$。\n\n从一个周期到另一个周期观察到的验证损失下降，$y_t  y_{t'}$，并不能保证真实风险的下降，$R_t  R_{t'}$。观察到的变化可能完全是由于随机采样噪声。为了防止这种情况，我们仅当观察到的下降相对于预期噪声水平较大时，才宣布改进是“统计上显著的”。我们通过定义一个决策阈值 $\\tau$ 作为标准误差的倍数来将其形式化：\n$$\n\\tau = c \\cdot SE = c \\cdot \\sqrt{\\frac{\\sigma^2}{m}}\n$$\n这里，$c$ 是一个控制测试严格性的正常数。一个典型的选择 $c = 1.96$，其动机是正态分布的性质，其中大约 $95\\%$ 的值位于均值的 $1.96$ 个标准差范围内。因此，如果真实风险实际上没有下降，那么偶然观察到大于 $\\tau$ 的下降是不太可能的。\n\n该问题详细说明了一个基于此原则的完整“考虑显著性的耐心”算法。它在周期 $t=1, 2, \\dots, T$ 中跟踪几个量：\n\n1.  $y^*$：到目前为止观察到的最小（“原始最佳”）验证均值。\n2.  $e^*$：达到 $y^*$ 时的基于 $1$ 的周期索引。\n3.  $t_{\\text{sig}}$：记录的最后一次统计显著改进的基于 $1$ 的周期索引。\n4.  $y_{\\text{sig}}$：在周期 $t_{\\text{sig}}$ 观察到的验证均值 $y_t$。\n\n算法流程如下：\n\n**初始化 (在周期 $t=1$):**\n- 设 $y_1$ 为第一个周期的验证均值。\n- 设置 $y^* \\leftarrow y_1$。\n- 设置 $e^* \\leftarrow 1$。\n- 设置 $t_{\\text{sig}} \\leftarrow 1$。\n- 设置 $y_{\\text{sig}} \\leftarrow y_1$。\n\n**迭代 (对于周期 $t = 2, 3, \\dots, T$):**\n对于每个具有验证均值 $y_t$ 的新周期 $t$：\n1.  **更新原始最佳值:** 如果 $y_t  y^*$，则更新 $y^* \\leftarrow y_t$ 和 $e^* \\leftarrow t$。\n2.  **检查显著改进:** 将当前验证均值 $y_t$ 与上一次显著改进时的值 $y_{\\text{sig}}$ 进行比较。如果满足条件 $y_t \\le y_{\\text{sig}} - \\tau$，则认为改进是显著的。然后我们更新未来比较的参考点：$t_{\\text{sig}} \\leftarrow t$ 和 $y_{\\text{sig}} \\leftarrow y_t$。\n3.  **检查停止条件:** 在上述更新之后，检查自上次显著改进以来的周期数是否超过了耐心限度 $P$。如果 $t - t_{\\text{sig}} \\ge P$，则条件满足。\n    - 如果条件满足，训练过程停止。选择的周期是到此为止记录的最佳性能周期，即 $e^*$ 的当前值。\n    - 如果条件不满足，过程继续到下一个周期。\n\n**最终选择 (如果从未满足停止条件):**\n- 如果长度为 $T$ 的训练序列完成而从未触发停止条件，则选择的周期是具有整体最佳原始验证均值的周期，即 $e^*$ 的最终值。\n\n现在将此算法应用于所提供的测试用例。\n\n**Case A:**\n参数: $m = 25$, $\\sigma^2 = 0.0001$, $c = 1.96$, $P = 2$。\n验证序列: $y = [1.00, 0.90, 0.82, 0.79, 0.78, 0.775, 0.774, 0.776, \\dots]$。\n阈值: $\\tau = 1.96 \\cdot \\sqrt{0.0001 / 25} = 1.96 \\cdot 0.002 = 0.00392$。\n- $t=1$: $y^*=1.00$, $e^*=1$, $t_{\\text{sig}}=1$, $y_{\\text{sig}}=1.00$。\n- $t=2, \\dots, 6$: 每个周期都显示出足够大的下降，足以被认为是显著的。因此，$t_{\\text{sig}}$ 在每一步都被更新，最终变为 $6$。在 $t=6$ 时，$e^*=6$。\n- $t=7$: $y_7=0.774$。这是一个新的原始最佳值，因此 $e^* \\leftarrow 7$。然而，$y_7=0.774$ 不小于或等于 $y_{\\text{sig}}-\\tau = 0.775 - 0.00392 = 0.77108$。没有显著改进。$t_{\\text{sig}}$ 保持为 $6$。耐心计数器：$t-t_{\\text{sig}} = 7-6=1  2$。\n- $t=8$: $y_8=0.776$。不是新的原始最佳值。不是显著改进。耐心计数器：$t-t_{\\text{sig}} = 8-6=2 \\ge 2$。满足停止条件。选择的周期是此时 $e^*$ 的值，即 $7$。\n\n**Case B:**\n参数: $m = 20$, $\\sigma^2 = 1 \\times 10^{-6}$, $c = 1.96$, $P = 3$。\n验证序列: $y = [1.00, 0.99, 0.98, \\dots, 0.91]$。\n阈值: $\\tau = 1.96 \\cdot \\sqrt{10^{-6} / 20} \\approx 0.000438$。\n验证损失每一步都减少 $0.01$。由于 $0.01 > \\tau$，每个周期都构成了显著的改进。因此，$t_{\\text{sig}}$ 在每个周期都被更新为 $t$。条件 $t - t_{\\text{sig}} \\ge P$（即 $t-t \\ge 3$）永远不会满足。过程运行至完成。选择的周期是整个序列中损失最小的那个，即 $y_{10}=0.91$ 对应的周期。选择的周期是 $10$。\n\n**Case C:**\n参数: $m = 5$, $\\sigma^2 = 0.01$, $c = 1.96$, $P = 2$。\n验证序列: $y = [0.90, 0.85, 0.83, 0.835, \\dots]$。\n阈值: $\\tau = 1.96 \\cdot \\sqrt{0.01 / 5} \\approx 0.08765$。\n- $t=1$: $y^*=0.90$, $e^*=1$, $t_{\\text{sig}}=1$, $y_{\\text{sig}}=0.90$。\n- $t=2$: $y_2=0.85$。这是一个新的原始最佳值 ($e^* \\leftarrow 2$)。然而，$y_2=0.85$ 不小于或等于 $y_{\\text{sig}}-\\tau = 0.90 - 0.08765 = 0.81235$。没有显著改进。$t_{\\text{sig}}$ 保持为 $1$。耐心计数器：$t-t_{\\text{sig}} = 2-1=1  2$。\n- $t=3$: $y_3=0.83$。这是一个新的原始最佳值 ($e^* \\leftarrow 3$)。它相对于 $y_1$ 也不是一个显著的改进。$t_{\\text{sig}}$ 保持为 $1$。耐心计数器：$t-t_{\\text{sig}} = 3-1=2 \\ge 2$。满足停止条件。选择的周期是 $e^*$ 的当前值，即 $3$。\n\n**Case D:**\n参数: $m = 10$, $\\sigma^2 = 0.0001$, $c = 1.96$, $P = 1$。\n验证序列: $y = [1.20, 1.00, 0.95, 0.951, \\dots]$。\n阈值: $\\tau = 1.96 \\cdot \\sqrt{0.0001 / 10} \\approx 0.0062$。\n- $t=1$: $y^*=1.20$, $e^*=1$, $t_{\\text{sig}}=1$, $y_{\\text{sig}}=1.20$。\n- $t=2$: $y_2=1.00$。新的原始最佳值 ($e^* \\leftarrow 2$)。$y_2=1.00 \\le 1.20 - 0.0062$，所以这是一个显著的改进。更新 $t_{\\text{sig}} \\leftarrow 2$, $y_{\\text{sig}} \\leftarrow 1.00$。耐心计数器：$t-t_{\\text{sig}}=0  1$。\n- $t=3$: $y_3=0.95$。新的原始最佳值 ($e^* \\leftarrow 3$)。$y_3=0.95 \\le 1.00 - 0.0062$，所以这是一个显著的改进。更新 $t_{\\text{sig}} \\leftarrow 3$, $y_{\\text{sig}} \\leftarrow 0.95$。耐心计数器：$t-t_{\\text{sig}}=0  1$。\n- $t=4$: $y_4=0.951$。不是新的原始最佳值。不是显著改进。耐心计数器：$t-t_{\\text{sig}} = 4-3=1 \\ge 1$。满足停止条件。选择的周期是 $e^*$ 的当前值，即 $3$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef significance_aware_patience_stopping(\n    val_means: list[float], m: int, sigma_sq: float, c: float, p: int\n) -> int:\n    \"\"\"\n    Implements the significance-aware patience early stopping rule.\n\n    Args:\n        val_means: A sequence of unaugmented validation means per epoch.\n        m: The size of the validation subset.\n        sigma_sq: The per-example variance of the loss.\n        c: The user-chosen positive decision parameter.\n        p: The non-negative integer patience parameter.\n\n    Returns:\n        The 1-based index of the selected epoch.\n    \"\"\"\n    if not val_means:\n        # According to the problem setup, sequences are non-empty.\n        # This is a defensive check.\n        return 0\n\n    num_epochs = len(val_means)\n    \n    # Calculate the decision threshold tau\n    tau = c * np.sqrt(sigma_sq / m)\n\n    # Initialize tracked quantities\n    # All epoch indices are 1-based as per the problem description.\n    raw_best_val_mean = val_means[0]\n    epoch_of_raw_best = 1\n    t_last_significant = 1\n    val_at_last_significant = val_means[0]\n\n    for t_idx, current_val_mean in enumerate(val_means):\n        # Epochs are 1-based\n        current_epoch = t_idx + 1\n\n        # The loop starts at epoch 1 (t_idx=0). Initialization is effectively\n        # handled before the first iteration's logic would change anything.\n        if current_epoch == 1:\n            continue\n\n        # 1. Update Raw Best\n        if current_val_mean  raw_best_val_mean:\n            raw_best_val_mean = current_val_mean\n            epoch_of_raw_best = current_epoch\n\n        # 2. Check for Significant Improvement\n        if current_val_mean = val_at_last_significant - tau:\n            val_at_last_significant = current_val_mean\n            t_last_significant = current_epoch\n\n        # 3. Check Stopping Condition\n        if current_epoch - t_last_significant >= p:\n            # Stop condition is met. The selected epoch is the best raw\n            # epoch found up to and including this point.\n            return epoch_of_raw_best\n\n    # If the loop completes without stopping, select the overall best raw epoch.\n    return epoch_of_raw_best\n\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the early stopping problem.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"val_means\": [1.00, 0.90, 0.82, 0.79, 0.78, 0.775, 0.774, 0.776, 0.780, 0.785, 0.790, 0.800],\n            \"m\": 25,\n            \"sigma_sq\": 0.0001,\n            \"c\": 1.96,\n            \"p\": 2,\n        },\n        {\n            \"val_means\": [1.00, 0.99, 0.98, 0.97, 0.96, 0.95, 0.94, 0.93, 0.92, 0.91],\n            \"m\": 20,\n            \"sigma_sq\": 1e-6,\n            \"c\": 1.96,\n            \"p\": 3,\n        },\n        {\n            \"val_means\": [0.90, 0.85, 0.83, 0.835, 0.84, 0.845, 0.86, 0.87, 0.875, 0.88],\n            \"m\": 5,\n            \"sigma_sq\": 0.01,\n            \"c\": 1.96,\n            \"p\": 2,\n        },\n        {\n            \"val_means\": [1.20, 1.00, 0.95, 0.951, 0.96, 0.97],\n            \"m\": 10,\n            \"sigma_sq\": 0.0001,\n            \"c\": 1.96,\n            \"p\": 1,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        selected_epoch = significance_aware_patience_stopping(\n            val_means=case[\"val_means\"],\n            m=case[\"m\"],\n            sigma_sq=case[\"sigma_sq\"],\n            c=case[\"c\"],\n            p=case[\"p\"]\n        )\n        results.append(selected_epoch)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在处理含有标签噪声的数据集时，深度学习模型的一个典型行为是先学习干净样本，然后开始“记忆”错误的标签，这是一种需要避免的过拟合。本练习将带你超越仅仅观察平均验证损失的传统方法，转而分析整个训练损失分布的动态变化。你将学习如何通过监测损失分布的“尾部”，来精确捕捉模型开始记忆噪声的时刻，从而实现更智能的早停。",
            "id": "3119110",
            "problem": "给定一个用于研究深度学习中在标签噪声下早停问题的程式化设定。其基础是经验风险最小化（ERM），即训练一个带参数 $\\theta$ 的模型，以最小化经验风险 $\\frac{1}{n}\\sum_{i=1}^{n}\\ell(y_i, f_\\theta(x_i))$，其中 $\\ell_i(t)$ 是在训练轮次 $t$ 的非负逐样本损失。在比率为 $\\rho \\in [0,1]$ 的对称标签噪声下，有比例为 $\\rho$ 的标签被均匀随机地损坏，而剩余比例为 $1-\\rho$ 的标签是干净的。一个普遍观察到的现象是，在训练过程中，干净样本的损失会较早下降，而噪声样本最初保持高损失，直到模型开始记忆噪声后，其损失才开始下降。这导致逐样本损失的直方图出现一种特征性的演变：高损失尾部起初保持稳定，当记忆开始时，它便开始收缩。早停的目标是在模型拟合噪声尾部之前选择一个训练轮次。\n\n你必须实现一个程序，该程序在给定一个合成的但科学上合理的逐样本损失 $\\ell_i(t)$ 生成器和一个基于直方图的检测规则的情况下，为多个测试用例输出检测到的早停轮次。该检测规则必须使用损失分布的分位数作为直方图右尾质量的稳定代理指标来指定。\n\n合成损失生成器。对于每个测试用例，给定以下参数：\n- 训练样本数 $n$，\n- 对称标签噪声比率 $\\rho$，\n- 总训练轮次数 $T$，\n- 随机种子 $s$，\n- 干净样本衰减率 $\\alpha  0$，\n- 记忆后噪声样本衰减率 $\\beta  0$，\n- 记忆开始轮次 $t_m \\in \\{0,1,\\dots,T-1\\}$，\n- 用于建模随机性的高斯噪声标准差 $\\sigma  0$，\n- 以及下文定义的检测超参数。\n\n为保证可复现性，你必须从一个用给定种子 $s$ 初始化的伪随机数生成器中获取所有随机数。以概率 $\\rho$ 将样本身份生成为噪声样本，以概率 $1-\\rho$ 生成为干净样本，各样本之间独立。对于每个样本 $j \\in \\{1,\\dots,n\\}$，从 $\\mathrm{Uniform}(0,1)$ 分布中抽取一次难度值 $d_j$，并在所有轮次中重复使用。定义以下基础值：\n- 干净样本基础值 $b^{\\mathrm{clean}}_j = 1.6 + 0.4 d_j$，\n- 干净样本下限值 $f^{\\mathrm{clean}}_j = 0.05 + 0.05 d_j$，\n- 噪声样本基础值 $b^{\\mathrm{noisy}}_j = 2.2 + 0.4 d_j$，\n- 噪声样本下限值 $f^{\\mathrm{noisy}}_j = 0.02 + 0.01 d_j$。\n\n对于每个轮次 $t \\in \\{0,1,\\dots,T-1\\}$ 和样本 $j$，独立地定义噪声项 $\\varepsilon_{j,t} \\sim \\mathcal{N}(0,\\sigma^2)$，然后如下定义逐样本损失 $\\ell_j(t)$：\n- 如果 $j$ 是干净样本：\n$$\n\\ell_j(t) = f^{\\mathrm{clean}}_j + \\bigl(b^{\\mathrm{clean}}_j - f^{\\mathrm{clean}}_j\\bigr)\\exp(-\\alpha t) + \\varepsilon_{j,t}.\n$$\n- 如果 $j$ 是噪声样本：\n$$\n\\ell_j(t) =\n\\begin{cases}\nb^{\\mathrm{noisy}}_j + \\varepsilon_{j,t},  \\text{if } t  t_m, \\\\\nf^{\\mathrm{noisy}}_j + \\bigl(b^{\\mathrm{noisy}}_j - f^{\\mathrm{noisy}}_j\\bigr)\\exp\\bigl(-\\beta (t - t_m)\\bigr) + \\varepsilon_{j,t},  \\text{if } t \\ge t_m.\n\\end{cases}\n$$\n最后，将损失在零处进行裁剪，即 $\\ell_j(t) \\leftarrow \\max\\{\\ell_j(t), 0\\}$。\n\n基于损失直方图动态的检测规则。令 $q_p(t)$ 表示在轮次 $t$ 时集合 $\\{\\ell_1(t),\\dots,\\ell_n(t)\\}$ 的经验 $p$-分位数，其中固定的 $p \\in (0,1)$ 用于强调右尾（例如，$p=0.9$）。定义一个窗口长度为 $w \\in \\mathbb{N}$ 的移动平均平滑器：\n$$\n\\widehat{q}_p(t) = \\frac{1}{w}\\sum_{k=0}^{w-1} q_p(t-k), \\quad \\text{defined for } t \\ge w-1.\n$$\n定义离散斜率\n$$\ns(t) = \\widehat{q}_p(t) - \\widehat{q}_p(t-1), \\quad \\text{defined for } t \\ge w.\n$$\n给定一个负斜率阈值 $\\gamma  0$、一个所需的连续轮次数 $s_{\\mathrm{consec}} \\in \\mathbb{N}$ 和一个预热期 $t_{\\mathrm{warm}} \\in \\mathbb{N}$，检测满足 $t^\\star \\ge \\max\\{w, t_{\\mathrm{warm}}\\}$ 和以下条件的最早轮次 $t^\\star$：\n$$\ns(t) \\le -\\gamma \\quad \\text{for all } t \\in \\{t^\\star, t^\\star + 1, \\dots, t^\\star + s_{\\mathrm{consec}} - 1\\}.\n$$\n如果存在这样的轮次，则输出 $t^\\star$；否则输出 $T$。\n\n你的程序必须完全按照上述定义实现生成器和检测规则，并使用提供的测试套件。此问题不涉及物理单位。也不涉及角度。所有比例必须表示为小数（例如，百分之三十应写作 $0.3$）。所有测试用例的最终输出必须是单行文本，其中包含一个由方括号括起来的、逗号分隔的检测到的轮次列表。\n\n测试套件。实现你的程序，使其按以下顺序在以下参数集上运行：\n\n- 情况 A（理想路径，中等噪声，记忆开始点清晰）：\n    - $n = 4000$, $\\rho = 0.3$, $T = 60$, $s = 42$, $\\alpha = 0.12$, $\\beta = 0.25$, $t_m = 25$, $\\sigma = 0.03$, $p = 0.9$, $w = 3$, $\\gamma = 0.04$, $s_{\\mathrm{consec}} = 2$, $t_{\\mathrm{warm}} = 5$。\n\n- 情况 B（边界情况：无标签噪声，使用足够严格的阈值时不应触发检测）：\n    - $n = 4000$, $\\rho = 0.0$, $T = 60$, $s = 123$, $\\alpha = 0.12$, $\\beta = 0.25$, $t_m = 25$, $\\sigma = 0.03$, $p = 0.9$, $w = 3$, $\\gamma = 0.2$, $s_{\\mathrm{consec}} = 2$, $t_{\\mathrm{warm}} = 5$。\n\n- 情况 C（高噪声，记忆开始点较晚）：\n    - $n = 4000$, $\\rho = 0.6$, $T = 70$, $s = 7$, $\\alpha = 0.12$, $\\beta = 0.20$, $t_m = 40$, $\\sigma = 0.03$, $p = 0.9$, $w = 3$, $\\gamma = 0.03$, $s_{\\mathrm{consec}} = 2$, $t_{\\mathrm{warm}} = 5$。\n\n- 情况 D（边缘情况：小数据集且记忆非常缓慢，可能不会触发检测）：\n    - $n = 300$, $\\rho = 0.4$, $T = 50$, $s = 999$, $\\alpha = 0.08$, $\\beta = 0.05$, $t_m = 30$, $\\sigma = 0.04$, $p = 0.9$, $w = 4$, $\\gamma = 0.03$, $s_{\\mathrm{consec}} = 3$, $t_{\\mathrm{warm}} = 5$。\n\n要求的最终输出格式。你的程序应生成单行输出，其中包含一个由方括号括起来的、逗号分隔的结果列表（例如，“[result_A,result_B,result_C,result_D]”），其中每个结果是对应情况的整数轮次索引，如上所定义。",
            "solution": "用户提供了一个问题，要求在深度学习背景下为早停实现一个模拟和检测算法。该问题具有科学依据，定义明确（良构），并且提供了所有必要的参数和定义。因此，该问题被认为是有效的，并将开发一个完整的解决方案。\n\n该解决方案分为两个主要概念部分：在一系列训练轮次中生成合成的逐样本训练损失，以及对这些损失应用特定的检测规则以确定最佳早停轮次。\n\n### 第1部分：合成逐样本损失生成\n\n第一步是生成逐样本损失矩阵，记为样本 $j$ 在轮次 $t$ 的损失 $\\ell_j(t)$。该过程的维度由样本数量 $n$ 和总轮次数 $T$ 定义。\n\n1.  **初始化和随机性**：为保证可复现性，所有随机元素均源自一个用给定种子 $s$ 初始化的伪随机数生成器。\n\n2.  **样本身份和难度**：$n$ 个样本中的每一个都被分类为“干净”或“噪声”。一个样本被指定为噪声样本的概率为 $\\rho$，被指定为干净样本的概率为 $1-\\rho$。此分配对每个样本独立进行。同时，为每个样本 $j$ 分配一个静态的“难度”参数 $d_j$，该参数从均匀分布 $\\mathrm{Uniform}(0, 1)$ 中抽取。此难度参数在整个训练过程中调节该特定样本的损失特性。\n\n3.  **损失特性**：根据样本的身份（干净或噪声）及其难度 $d_j$，定义了四个关键值：\n    -   干净样本基础损失：$b^{\\mathrm{clean}}_j = 1.6 + 0.4 d_j$\n    -   干净样本下限损失：$f^{\\mathrm{clean}}_j = 0.05 + 0.05 d_j$\n    -   噪声样本基础损失：$b^{\\mathrm{noisy}}_j = 2.2 + 0.4 d_j$\n    -   噪声样本下限损失：$f^{\\mathrm{noisy}}_j = 0.02 + 0.01 d_j$\n    “基础”值代表初始的高损失，而“下限”值代表在大量训练后可达到的最小损失。\n\n4.  **损失演变动态**：对于每个样本 $j \\in \\{1, \\dots, n\\}$ 和轮次 $t \\in \\{0, \\dots, T-1\\}$，逐样本损失 $\\ell_j(t)$ 的建模如下。\n    -   对于**干净**样本，损失从其基础值向其下限值指数衰减，由衰减率 $\\alpha$ 控制：\n        $$\n        \\ell_j(t) = f^{\\mathrm{clean}}_j + \\bigl(b^{\\mathrm{clean}}_j - f^{\\mathrm{clean}}_j\\bigr)\\exp(-\\alpha t) + \\varepsilon_{j,t}\n        $$\n    -   对于**噪声**样本，其行为根据记忆开始轮次 $t_m$ 发生分化。在此轮次之前，模型未能拟合不正确的标签，损失保持较高水平。在此轮次之后，模型开始“记忆”噪声标签，导致损失下降。这由衰减率 $\\beta$ 控制：\n        $$\n        \\ell_j(t) =\n        \\begin{cases}\n        b^{\\mathrm{noisy}}_j + \\varepsilon_{j,t},  \\text{if } t  t_m, \\\\\n        f^{\\mathrm{noisy}}_j + \\bigl(b^{\\mathrm{noisy}}_j - f^{\\mathrm{noisy}}_j\\bigr)\\exp\\bigl(-\\beta (t - t_m)\\bigr) + \\varepsilon_{j,t},  \\text{if } t \\ge t_m.\n        \\end{cases}\n        $$\n    在两种情况下，$\\varepsilon_{j,t}$ 是一个从零均值高斯分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽取的随机噪声项，为每个样本和轮次独立添加，以模拟训练的随机性。最后，由于损失值必须为非负，计算出的损失在零处被裁剪：$\\ell_j(t) \\leftarrow \\max\\{\\ell_j(t), 0\\}$。\n\n### 第2部分：基于直方图的早停检测\n\n该过程的第二部分是分析生成的损失矩阵，以识别最佳停止轮次 $t^\\star$。要检测的现象是记忆的开始，这表现为噪声样本损失的突然下降。这种下降导致损失分布直方图的右尾收缩。\n\n1.  **分位数作为代理指标**：通过在每个轮次 $t$ 计算损失集合 $\\{\\ell_1(t), \\dots, \\ell_n(t)\\}$ 的经验 $p$-分位数 $q_p(t)$ 来追踪损失分布的右尾。接近 1 的 $p$ 值（例如，$p=0.9$）确保该指标对高损失样本敏感，这些样本在记忆开始前主要是噪声样本。\n\n2.  **平滑**：为了减轻随机噪声 $\\varepsilon_{j,t}$ 的影响并获得更稳定的信号，使用窗口大小为 $w$ 的移动平均对原始分位数序列 $q_p(t)$ 进行平滑。平滑后的分位数 $\\widehat{q}_p(t)$ 定义于轮次 $t \\ge w-1$：\n    $$\n    \\widehat{q}_p(t) = \\frac{1}{w}\\sum_{k=0}^{w-1} q_p(t-k)\n    $$\n\n3.  **斜率计算**：记忆的开始以平滑后分位数的急剧下降为标志。通过计算平滑后分位数序列的离散斜率（或一阶差分）来检测这一点。斜率 $s(t)$ 定义于轮次 $t \\ge w$：\n    $$\n    s(t) = \\widehat{q}_p(t) - \\widehat{q}_p(t-1)\n    $$\n\n4.  **检测规则**：早停轮次 $t^\\star$ 是基于一个持续性条件来识别的。它是满足以下两个标准的最早轮次 $t^\\star$：\n    -   它必须发生在“预热”期之后，即 $t^\\star \\ge \\max\\{w, t_{\\mathrm{warm}}\\}$。预热期 $t_{\\mathrm{warm}}$ 防止因初始训练瞬态而导致的过早停止。条件 $t^\\star \\ge w$ 是必要的，因为斜率 $s(t)$ 最早定义于 $t=w$。\n    -   斜率必须在一个持续的时间段内显著为负。具体来说，从 $t^\\star$ 开始的 $s_{\\mathrm{consec}}$ 个连续轮次内，斜率 $s(t)$ 必须小于或等于一个负阈值 $-\\gamma$（其中 $\\gamma  0$）。也就是说，对于所有 $t \\in \\{t^\\star, t^\\star + 1, \\dots, t^\\star + s_{\\mathrm{consec}} - 1\\}$，必须满足 $s(t) \\le -\\gamma$。\n\n如果找到了满足这些条件的轮次 $t^\\star$，则将其作为结果返回。如果搜索完成仍未找到这样的轮次，则算法返回总轮次数 $T$，表示早停未被触发。\n\n整个过程被实现并应用于问题陈述中指定的每个测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(n, rho, T, s_seed, alpha, beta, t_m, sigma, p, w, gamma, s_consec, t_warm):\n    \"\"\"\n    Runs the simulation and detection algorithm for a single test case.\n    \"\"\"\n    # 1. Initialize random number generator for reproducibility.\n    rng = np.random.default_rng(s_seed)\n\n    # 2. Generate per-example identities and difficulties.\n    is_noisy = rng.choice([True, False], size=n, p=[rho, 1 - rho])\n    d = rng.uniform(0, 1, size=n)\n\n    # 3. Define base and floor values for losses.\n    b_clean = 1.6 + 0.4 * d\n    f_clean = 0.05 + 0.05 * d\n    b_noisy = 2.2 + 0.4 * d\n    f_noisy = 0.02 + 0.01 * d\n\n    # 4. Generate the T x n matrix of per-example losses over all epochs.\n    losses = np.zeros((T, n))\n    # Pre-generate all Gaussian noise for efficiency.\n    gaussian_noise = rng.normal(0, sigma, size=(T, n))\n\n    for t in range(T):\n        # Calculate base losses for clean examples at epoch t\n        loss_clean_t = f_clean + (b_clean - f_clean) * np.exp(-alpha * t)\n\n        # Calculate base losses for noisy examples at epoch t\n        if t  t_m:\n            loss_noisy_t = b_noisy\n        else:\n            loss_noisy_t = f_noisy + (b_noisy - f_noisy) * np.exp(-beta * (t - t_m))\n\n        # Combine based on whether an example is noisy or clean\n        epoch_losses = np.where(is_noisy, loss_noisy_t, loss_clean_t)\n        \n        # Add stochastic noise\n        epoch_losses += gaussian_noise[t, :]\n        \n        # Clip losses at zero\n        losses[t, :] = np.maximum(epoch_losses, 0)\n\n    # 5. Calculate the p-quantile of the loss distribution for each epoch.\n    if losses.shape[1] == 0:  # Handle edge case of n=0\n        q_p = np.zeros(T)\n    else:\n        q_p = np.quantile(losses, p, axis=1)\n\n    # 6. Compute the smoothed quantiles using a moving average.\n    q_p_hat = np.zeros_like(q_p)\n    # The moving average is defined for t >= w-1.\n    for t in range(w - 1, T):\n        q_p_hat[t] = np.mean(q_p[t - w + 1 : t + 1])\n\n    # 7. Compute the discrete slope of the smoothed quantiles.\n    slopes = np.zeros_like(q_p)\n    # The slope is defined for t >= w.\n    for t in range(w, T):\n        slopes[t] = q_p_hat[t] - q_p_hat[t - 1]\n\n    # 8. Search for the early stopping epoch t_star.\n    t_star = T\n    t_search_start = max(w, t_warm)\n\n    # The latest possible start of a valid sequence is T - s_consec.\n    # The loop should go up to and including this value.\n    for t_candidate in range(t_search_start, T - s_consec + 1):\n        # Check if the slope is below the threshold for s_consec consecutive epochs.\n        sub_slopes = slopes[t_candidate : t_candidate + s_consec]\n        if np.all(sub_slopes = -gamma):\n            t_star = t_candidate\n            break  # Found the earliest such epoch\n    \n    return t_star\n\n\ndef solve():\n    \"\"\"\n    Defines the test suite and runs the simulation for each case.\n    \"\"\"\n    test_cases = [\n        # Case A (happy path, moderate noise, clear memorization onset)\n        {\"n\": 4000, \"rho\": 0.3, \"T\": 60, \"s_seed\": 42, \"alpha\": 0.12, \"beta\": 0.25, \n         \"t_m\": 25, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.04, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case B (boundary: no label noise)\n        {\"n\": 4000, \"rho\": 0.0, \"T\": 60, \"s_seed\": 123, \"alpha\": 0.12, \"beta\": 0.25, \n         \"t_m\": 25, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.2, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case C (high noise, later memorization onset)\n        {\"n\": 4000, \"rho\": 0.6, \"T\": 70, \"s_seed\": 7, \"alpha\": 0.12, \"beta\": 0.20, \n         \"t_m\": 40, \"sigma\": 0.03, \"p\": 0.9, \"w\": 3, \"gamma\": 0.03, \n         \"s_consec\": 2, \"t_warm\": 5},\n\n        # Case D (edge: small dataset and very slow memorization)\n        {\"n\": 300, \"rho\": 0.4, \"T\": 50, \"s_seed\": 999, \"alpha\": 0.08, \"beta\": 0.05, \n         \"t_m\": 30, \"sigma\": 0.04, \"p\": 0.9, \"w\": 4, \"gamma\": 0.03, \n         \"s_consec\": 3, \"t_warm\": 5},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_simulation(**params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}