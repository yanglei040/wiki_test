{
    "hands_on_practices": [
        {
            "introduction": "The Cutout augmentation is a powerful yet simple regularization technique that works by masking random regions of an input image. While its default implementation uses random placement, we can ask if a more intelligent strategy could yield better results. This practice  challenges you to explore a saliency-aware placement strategy, connecting the concept of augmentation to model interpretability through gradients. By quantifying the difference in regularization strength between random and guided masking, you will gain a deeper appreciation for how model-centric information can enhance data-centric techniques.",
            "id": "3111355",
            "problem": "You are asked to write a complete, runnable program that quantifies how the placement of CutOut masks relative to salient regions affects the increase in training loss, which we use as a proxy for regularization strength, for a simple linear model on images. The problem is framed in purely mathematical terms, suitable for implementation in any modern programming language.\n\nConsider a single-image binary regression model with a linear predictor. Let an image be represented as a two-dimensional array of real numbers $x \\in \\mathbb{R}^{H \\times W}$, and let the model weights be $w \\in \\mathbb{R}^{H \\times W}$. Define the prediction as $y = \\langle w, x \\rangle = \\sum_{i=1}^{H}\\sum_{j=1}^{W} w_{ij}\\,x_{ij}$ and the mean squared error (MSE) loss as $L(x; w, t) = (y - t)^2$, where $t \\in \\mathbb{R}$ is the target. A CutOut mask of size $h \\times w$ zeroes out a contiguous rectangular region of the input. Let $m \\in \\{0,1\\}^{H \\times W}$ be a binary mask with a single $h \\times w$ rectangle of ones set to zero and all other entries equal to one, and denote the masked input as $x' = m \\odot x$, where $\\odot$ is the Hadamard (elementwise) product. The masked loss is $L(x'; w, t) = \\big(\\langle w, x' \\rangle - t\\big)^2$.\n\nDefine the saliency map as the absolute value of the gradient of the loss with respect to the input evaluated at the unmasked input, that is $s = \\left| \\nabla_x L(x; w, t) \\right|$. For the MSE loss with a linear model, this simplifies to $s_{ij} = 2\\,\\big| \\langle w, x \\rangle - t \\big|\\,|w_{ij}|$. Therefore, a saliency-aware CutOut placement of size $h \\times w$ is chosen to maximize the sum of $s_{ij}$ over the masked region, which is equivalent to maximizing the sum of $|w_{ij}|$ over the rectangle, because the factor $2\\,\\big| \\langle w, x \\rangle - t \\big|$ is constant across $(i,j)$.\n\nWe measure regularization strength as the increase in loss due to masking. Specifically, define the unmasked loss $L_0 = L(x; w, t)$, the expected masked loss under uniformly random placement of the CutOut $h \\times w$ window (over all valid top-left positions) as $\\mathbb{E}_{\\text{rand}}[L]$, and the masked loss under the saliency-aware placement as $L_{\\text{sal}}$. Define the random-masking increase as $\\Delta_{\\text{rand}} = \\mathbb{E}_{\\text{rand}}[L] - L_0$, and the saliency-aware increase as $\\Delta_{\\text{sal}} = L_{\\text{sal}} - L_0$. Also define the gain and the ratio as $G = \\Delta_{\\text{sal}} - \\Delta_{\\text{rand}}$ and $R = \\Delta_{\\text{sal}} / \\Delta_{\\text{rand}}$ (if the denominator is zero, treat $R$ as positive infinity).\n\nYou must compute these quantities exactly (without Monte Carlo approximation) by enumerating all valid top-left placements for the random case and by selecting the saliency-aware placement defined above. To ensure universal reproducibility, inputs $x$ and $w$ must be generated by a fixed linear congruential generator (LCG) with modulus $m = 2^{32}$, multiplier $a = 1664525$, increment $c = 1013904223$, and seed $s \\in \\{0,1,\\dots,2^{32}-1\\}$. The generator evolves as $u_{k+1} = (a\\,u_k + c) \\bmod m$, and each pseudo-random real value in $[0,1)$ is $r_k = u_k / m$. To construct an $H \\times W$ array from a seed $s$, generate $H \\cdot W$ values $r_k$ in row-major order and map each to $v_k = 2\\,r_k - 1 \\in [-1,1)$.\n\nFor each test case, you are given $H$, $W$, $h$, $w$, seeds $s_x$ for $x$, $s_w$ for $w$, and target $t$. Construct $x$ and $w$ as described above. Compute $L_0$, $\\Delta_{\\text{rand}}$, $\\Delta_{\\text{sal}}$, $G$, and $R$ exactly. The CutOut placements are the set of all top-left indices $(i,j)$ with $i \\in \\{0,1,\\dots,H-h\\}$ and $j \\in \\{0,1,\\dots,W-w\\}$.\n\nImportant mathematical details to use:\n- Empirical Risk Minimization (ERM) and definition of MSE: $L(x; w, t) = (\\langle w, x \\rangle - t)^2$.\n- Saliency by gradient magnitude: $s = \\left| \\nabla_x L \\right|$.\n- Linear model prediction: $\\langle w, x \\rangle = \\sum_{i,j} w_{ij} x_{ij}$.\n- Masked prediction under a rectangle that zeroes a region $R$: $\\langle w, x' \\rangle = \\langle w, x \\rangle - \\sum_{(i,j)\\in R} w_{ij} x_{ij}$.\n- Saliency-aware selection: choose the rectangle maximizing $\\sum_{(i,j)\\in R} |w_{ij}|$.\n\nAngles are not involved. There are no physical units. You must express the final results as real numbers rounded to exactly $6$ decimal places.\n\nTest suite:\nCompute the outputs for the following five test cases:\n1. $H = 8$, $W = 8$, $h = 3$, $w = 3$, $s_x = 12345$, $s_w = 54321$, $t = 1.0$.\n2. $H = 8$, $W = 8$, $h = 1$, $w = 1$, $s_x = 1$, $s_w = 2$, $t = 1.0$.\n3. $H = 8$, $W = 8$, $h = 7$, $w = 7$, $s_x = 987654321$, $s_w = 123456789$, $t = -1.0$.\n4. $H = 6$, $W = 10$, $h = 2$, $w = 5$, $s_x = 555$, $s_w = 777$, $t = 1.0$.\n5. $H = 5$, $W = 5$, $h = 5$, $w = 5$, $s_x = 42$, $s_w = 43$, $t = -1.0$.\n\nRequired final output format:\nYour program should produce a single line of output containing a list of length $5$, where each element is a list corresponding to one test case. For each test case, output a list of four floats: $[\\Delta_{\\text{rand}}, \\Delta_{\\text{sal}}, G, R]$, each rounded to exactly $6$ decimal places. The final output must be a single line of the form\n$[[d_{1r}, d_{1s}, g_1, r_1],[d_{2r}, d_{2s}, g_2, r_2],[d_{3r}, d_{3s}, g_3, r_3],[d_{4r}, d_{4s}, g_4, r_4],[d_{5r}, d_{5s}, g_5, r_5]]$\nwith no spaces added beyond those necessary to separate list elements. If $\\Delta_{\\text{rand}} = 0$, define $R = +\\infty$ for that case before rounding and printing.\n\nYour program must implement the LCG and data generation exactly as specified, compute the exact averages by enumerating all valid placements, and follow the rounding rule. No user input is required. The output must match the specified format exactly.",
            "solution": "The problem requires us to quantify the effect of different placement strategies for the CutOut data augmentation technique on a simple linear regression model. We will measure this effect by the increase in the mean squared error (MSE) loss, which serves as a proxy for the regularization strength imparted by the augmentation.\n\n### 1. Model and Loss Function\nLet the input image be a matrix $x \\in \\mathbb{R}^{H \\times W}$ and the model weights be a corresponding matrix $w \\in \\mathbb{R}^{H \\times W}$. The model is linear, with the prediction $y$ given by the Frobenius inner product:\n$$\ny = \\langle w, x \\rangle = \\sum_{i=1}^{H}\\sum_{j=1}^{W} w_{ij}\\,x_{ij}\n$$\nGiven a scalar target value $t \\in \\mathbb{R}$, the loss is the Mean Squared Error (MSE):\n$$\nL(x; w, t) = (\\langle w, x \\rangle - t)^2\n$$\n\n### 2. CutOut Augmentation\nCutOut is a data augmentation method that masks a contiguous rectangular region of the input image by setting its pixel values to zero. A CutOut mask of size $h \\times w$ can be represented by a binary matrix $m \\in \\{0,1\\}^{H \\times W}$, where the entries corresponding to the cutout rectangle are $0$ and all other entries are $1$.\nThe augmented input, $x'$, is obtained by the Hadamard (elementwise) product:\n$$\nx' = m \\odot x\n$$\nLet a specific cutout rectangle be denoted by $R$. The prediction on the masked input, $y'$, is:\n$$\ny' = \\langle w, x' \\rangle = \\sum_{(i,j) \\notin R} w_{ij}x_{ij} = \\sum_{i,j} w_{ij}x_{ij} - \\sum_{(i,j) \\in R} w_{ij}x_{ij}\n$$\nLet's define the original prediction as $y_0 = \\langle w, x \\rangle$ and the change in prediction due to the mask as $\\delta_R = \\sum_{(i,j) \\in R} w_{ij}x_{ij}$. Then, the masked prediction is $y' = y_0 - \\delta_R$. The corresponding loss is:\n$$\nL(x'; w, t) = (y' - t)^2 = (y_0 - \\delta_R - t)^2\n$$\n\n### 3. Placement Strategies and Evaluation Metrics\nWe are asked to compare two placement strategies for the CutOut mask: uniformly random and saliency-aware.\n\n**Unmasked Baseline:** The baseline loss without any augmentation is $L_0 = (y_0 - t)^2$.\n\n**Uniformly Random Placement:**\nThis strategy involves choosing the top-left corner of the $h \\times w$ cutout window uniformly at random from all possible valid positions. The set of valid top-left positions is $\\{(i,j) \\mid 0 \\le i \\le H-h, 0 \\le j \\le W-w\\}$. Let the total number of such positions be $N_p = (H-h+1)(W-w+1)$.\nThe expected loss under random placement, $\\mathbb{E}_{\\text{rand}}[L]$, is the average loss over all possible placements:\n$$\n\\mathbb{E}_{\\text{rand}}[L] = \\frac{1}{N_p} \\sum_{\\text{all valid } R} (y_0 - \\delta_R - t)^2\n$$\nThe increase in loss due to random masking is $\\Delta_{\\text{rand}} = \\mathbb{E}_{\\text{rand}}[L] - L_0$.\n\n**Saliency-Aware Placement:**\nThis strategy places the cutout mask over the region deemed most \"important\" or \"salient\". The saliency map is defined as the magnitude of the gradient of the loss with respect to the input: $s = \\left| \\nabla_x L \\right|$.\n$$\n\\frac{\\partial L}{\\partial x_{ij}} = \\frac{\\partial}{\\partial x_{ij}} (\\langle w, x \\rangle - t)^2 = 2(\\langle w, x \\rangle - t) \\frac{\\partial}{\\partial x_{ij}} (\\sum_{k,l} w_{kl}x_{kl}) = 2(y_0 - t)w_{ij}\n$$\nThus, the saliency map is $s_{ij} = |\\frac{\\partial L}{\\partial x_{ij}}| = 2|y_0 - t||w_{ij}|$.\nTo maximize the total saliency within the cutout region, we must find the rectangle $R^*$ that maximizes $\\sum_{(i,j) \\in R^*} s_{ij}$. Since the term $2|y_0 - t|$ is a constant positive scalar for a given unmasked input, this is equivalent to finding the region $R^*$ that maximizes the sum of absolute weight magnitudes:\n$$\nR^* = \\arg\\max_{R} \\sum_{(i,j) \\in R} |w_{ij}|\n$$\nThe loss under this saliency-aware placement is $L_{\\text{sal}} = (y_0 - \\delta_{R^*} - t)^2$.\nThe increase in loss is $\\Delta_{\\text{sal}} = L_{\\text{sal}} - L_0$.\n\n**Comparative Metrics:**\nFinally, we compute two metrics to compare the strategies:\n1.  The gain: $G = \\Delta_{\\text{sal}} - \\Delta_{\\text{rand}}$\n2.  The ratio: $R = \\Delta_{\\text{sal}} / \\Delta_{\\text{rand}}$ (defined as $+\\infty$ if $\\Delta_{\\text{rand}}=0$)\n\n### 4. Computational Algorithm\nA direct implementation of the summations over all sliding windows would be inefficient. We can significantly optimize the computation using summed-area tables, also known as integral images.\n\n**Data Generation:** The input arrays $x$ and $w$ are generated using a specific Linear Congruential Generator (LCG): $u_{k+1} = (a u_k + c) \\pmod m$, with $m = 2^{32}$, $a = 1664525$, and $c = 1013904223$. The initial state $u_0$ is the given seed $s$. Each pseudo-random integer $u_k$ is converted to a real number $r_k = u_k/m \\in [0,1)$, which is then mapped to $v_k = 2r_k - 1 \\in [-1,1)$. These values populate the arrays in row-major order.\n\n**Efficient Summation using Integral Images:**\nAn integral image $I_A$ of an array $A$ is an array where $I_A(i,j)$ stores the sum of all elements in $A$ in the rectangle from the origin $(0,0)$ to $(i,j)$. This allows the sum over any arbitrary rectangle to be computed in $O(1)$ time using four lookups. We will pre-compute two integral images:\n1.  $I_{w \\odot x}$ for the array of elementwise products $w_{ij}x_{ij}$. This is used to rapidly calculate $\\delta_R$ for any region $R$.\n2.  $I_{|w|}$ for the array of absolute weights $|w_{ij}|$. This is used to find the saliency-aware region $R^*$ by quickly calculating $\\sum_{(i,j) \\in R} |w_{ij}|$ for all candidate regions.\n\n**Step-by-Step Calculation:**\n1.  For each test case, generate the matrices $x$ and $w$ of size $H \\times W$ using the specified LCG and seeds.\n2.  Calculate the unmasked prediction $y_0 = \\sum_{i,j} w_{ij}x_{ij}$ and the unmasked loss $L_0 = (y_0 - t)^2$.\n3.  Compute the integral images $I_{w \\odot x}$ and $I_{|w|}$.\n4.  Initialize a variable for total loss, `total_loss_sum = 0`, and variables to track the best saliency placement, `max_sal_sum = -1` and `best_placement = None`.\n5.  Iterate through all $N_p$ valid top-left positions $(i,j)$ for the $h \\times w$ window. For each position:\n    a. Use $I_{|w|}$ to find the sum of absolute weights in the current window. If this sum is greater than `max_sal_sum`, update `max_sal_sum` and store the current position in `best_placement`.\n    b. Use $I_{w \\odot x}$ to find the sum $\\delta_{ij}$ for the current window.\n    c. Calculate the masked loss $L_{ij} = (y_0 - \\delta_{ij} - t)^2$.\n    d. Add $L_{ij}$ to `total_loss_sum`.\n6.  After the loop, calculate the expected random loss $\\mathbb{E}_{\\text{rand}}[L] = \\text{total_loss_sum} / N_p$. Then compute $\\Delta_{\\text{rand}} = \\mathbb{E}_{\\text{rand}}[L] - L_0$.\n7.  Using the stored `best_placement`, use $I_{w \\odot x}$ to find the corresponding $\\delta_{R^*}$.\n8.  Calculate the saliency-aware loss $L_{\\text{sal}} = (y_0 - \\delta_{R^*} - t)^2$. Then compute $\\Delta_{\\text{sal}} = L_{\\text{sal}} - L_0$.\n9.  Calculate the final metrics $G = \\Delta_{\\text{sal}} - \\Delta_{\\text{rand}}$ and $R = \\Delta_{\\text{sal}} / \\Delta_{\\text{rand}}$. Handle the case where $\\Delta_{\\text{rand}}$ is zero (or numerically close to it).\n10. Round the four resulting metrics ($\\Delta_{\\text{rand}}$, $\\Delta_{\\text{sal}}$, $G$, $R$) to $6$ decimal places and store them.\nThis procedure ensures an exact calculation as required, without resorting to Monte Carlo approximation, while remaining computationally efficient.",
            "answer": "```python\nimport numpy as np\n# No other libraries are imported, as scipy is not strictly needed.\n# numpy provides sufficient functionality for this problem.\n\n# LCG parameters from the problem description.\nLCG_M = 2**32\nLCG_A = 1664525\nLCG_C = 1013904223\n\ndef generate_array(seed, H, W):\n    \"\"\"\n    Generates an HxW numpy array using the specified LCG.\n    Values are mapped to the range [-1, 1).\n    \"\"\"\n    n_values = H * W\n    u = seed\n    values = []\n    for _ in range(n_values):\n        u = (LCG_A * u + LCG_C) & (LCG_M - 1)\n        # Convert to float in [0, 1) then to [-1, 1)\n        v = 2 * (u / LCG_M) - 1\n        values.append(v)\n    \n    return np.array(values, dtype=np.float64).reshape((H, W))\n\ndef integral_image(arr):\n    \"\"\"\n    Computes the summed-area table (integral image) of a 2D array.\n    \"\"\"\n    S = np.zeros((arr.shape[0] + 1, arr.shape[1] + 1), dtype=np.float64)\n    S[1:, 1:] = np.cumsum(np.cumsum(arr, axis=0), axis=1)\n    return S\n\ndef sum_rect(integral_img, r, c, h, w):\n    \"\"\"\n    Calculates the sum over a rectangle using the integral image.\n    r, c are 0-indexed top-left corner coordinates.\n    \"\"\"\n    r1, c1 = r, c\n    r2, c2 = r + h, c + w\n    # The integral_img is 1-padded, so coordinates map directly.\n    return integral_img[r2, c2] - integral_img[r1, c2] - integral_img[r2, c1] + integral_img[r1, c1]\n\ndef compute_metrics(H, W, h, w_mask, s_x, s_w, t):\n    \"\"\"\n    Computes all required metrics for a single test case.\n    \"\"\"\n    # 1. Generate data\n    x = generate_array(s_x, H, W)\n    weights = generate_array(s_w, H, W)\n\n    # 2. Calculate unmasked baseline\n    y0 = np.sum(weights * x)\n    L0 = (y0 - t)**2\n\n    # 3. Pre-compute for efficient summation\n    integral_wx = integral_image(weights * x)\n    integral_abs_w = integral_image(np.abs(weights))\n    \n    num_placements = (H - h + 1) * (W - w_mask + 1)\n    \n    total_masked_loss = 0.0\n    \n    max_sal_sum = -1.0\n    best_placement_ij = (0, 0)\n    \n    # 4. Iterate over all possible placements\n    for i in range(H - h + 1):\n        for j in range(W - w_mask + 1):\n            # Saliency-aware placement search\n            current_sal_sum = sum_rect(integral_abs_w, i, j, h, w_mask)\n            if current_sal_sum > max_sal_sum:\n                max_sal_sum = current_sal_sum\n                best_placement_ij = (i, j)\n\n            # Random placement calculation\n            delta_ij = sum_rect(integral_wx, i, j, h, w_mask)\n            loss_ij = (y0 - delta_ij - t)**2\n            total_masked_loss += loss_ij\n            \n    # 5. Calculate random masking metrics\n    E_rand_L = total_masked_loss / num_placements\n    delta_rand = E_rand_L - L0\n\n    # 6. Calculate saliency-aware masking metrics\n    i_star, j_star = best_placement_ij\n    delta_sal = sum_rect(integral_wx, i_star, j_star, h, w_mask)\n    L_sal = (y0 - delta_sal - t)**2\n    delta_sal_val = L_sal - L0\n    \n    # 7. Calculate final comparative metrics\n    G = delta_sal_val - delta_rand\n    \n    if abs(delta_rand) < 1e-12: # Treat as zero\n        R = np.inf\n    else:\n        R = delta_sal_val / delta_rand\n\n    return [delta_rand, delta_sal_val, G, R]\n    \ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        # (H, W, h, w_mask, s_x, s_w, t)\n        (8, 8, 3, 3, 12345, 54321, 1.0),\n        (8, 8, 1, 1, 1, 2, 1.0),\n        (8, 8, 7, 7, 987654321, 123456789, -1.0),\n        (6, 10, 2, 5, 555, 777, 1.0),\n        (5, 5, 5, 5, 42, 43, -1.0),\n    ]\n\n    all_results = []\n    \n    def format_float(val):\n        \"\"\"Formats floats to .6f, handles infinity.\"\"\"\n        if val == np.inf:\n            return 'inf'\n        return f'{val:.6f}'\n\n    for case in test_cases:\n        H, W, h, w_mask, s_x, s_w, t = case\n        result = compute_metrics(H, W, h, w_mask, s_x, s_w, t)\n        all_results.append(result)\n\n    # Format the output string as per problem specification.\n    # e.g., [[d1,d2,g1,r1],[d3,d4,g2,r2]]\n    result_strings = []\n    for res in all_results:\n        formatted_res = [format_float(v) for v in res]\n        result_strings.append(f\"[{','.join(formatted_res)}]\")\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Mixing augmentations like CutMix, which combine patches and labels from different images, have become a staple for achieving state-of-the-art performance. However, their effectiveness relies on the assumption that local image regions are semantically meaningful and interchangeable. This exercise  prompts you to critically examine this assumption by designing a synthetic dataset where class identity is defined exclusively by global spatial arrangement. You will implement and train a model to investigate how an augmentation like CutMix can disrupt the learning of these crucial long-range dependencies, highlighting the importance of aligning your augmentation strategy with the underlying structure of your data.",
            "id": "3151909",
            "problem": "You must write a complete, runnable program that constructs a synthetic image dataset in which class identity is determined by global spatial arrangement, trains a multinomial logistic regression model under different augmentation configurations, and evaluates whether the augmentations disrupt the model’s ability to learn global context. Base your approach on empirical risk minimization with cross-entropy under the softmax model and on formal definitions of the augmentations. The dataset and learning problem must be purely mathematical and logically defined without any dependence on external files. Your program must implement all steps from scratch using linear algebra operations.\n\nDataset design: Create grayscale images of size $H \\times W$ with intensity values in $[0,1]$. There are exactly two classes, encoded with one-hot vectors in $\\{[1,0],[0,1]\\}$. Each image is partitioned into four equal quadrants. Let $c_{\\mathrm{lo}} \\in (0,1)$ and $c_{\\mathrm{hi}} \\in (0,1)$ with $c_{\\mathrm{lo}} < c_{\\mathrm{hi}}$. Define the class-conditional generation rule as follows:\n- For class $0$: the top-left and bottom-right quadrants are filled with $c_{\\mathrm{hi}}$, and the top-right and bottom-left quadrants are filled with $c_{\\mathrm{lo}}$.\n- For class $1$: the top-left and bottom-right quadrants are filled with $c_{\\mathrm{lo}}$, and the top-right and bottom-left quadrants are filled with $c_{\\mathrm{hi}}$.\nAfter this deterministic construction, add independent Gaussian noise $\\mathcal{N}(0,\\sigma^{2})$ to each pixel and clip to $[0,1]$. This construction ensures the classes are distinguished only by the global arrangement of quadrants, not by local textures.\n\nModel and learning objective: Use multinomial logistic regression (softmax regression) with two classes. For an input vector $x \\in \\mathbb{R}^{D}$ with $D = H \\cdot W$, model the class probabilities as\n$$\np_{\\theta}(y=k \\mid x) = \\frac{\\exp(w_{k}^{\\top} x + b_{k})}{\\sum_{j=0}^{1} \\exp(w_{j}^{\\top} x + b_{j})}, \\quad k \\in \\{0,1\\},\n$$\nwith parameters $\\theta = \\{W,b\\}$, where $W \\in \\mathbb{R}^{D \\times 2}$ and $b \\in \\mathbb{R}^{2}$. Train by minimizing the empirical risk under cross-entropy with possibly soft targets:\n$$\n\\mathcal{L}(\\theta) = -\\frac{1}{N}\\sum_{i=1}^{N} \\sum_{k=0}^{1} y_{i,k} \\log p_{\\theta}(y=k \\mid x_{i}),\n$$\nwhere $y_{i} \\in [0,1]^{2}$ is one-hot for unaugmented examples and can be a convex combination for CutMix as specified below. Optimize $\\mathcal{L}$ with mini-batch gradient descent.\n\nAugmentations to implement:\n- Cutout: Given an image $x \\in [0,1]^{H \\times W}$ and a square mask of side length $s = \\lfloor \\sqrt{f} \\cdot H \\rfloor$ for fraction $f \\in (0,1)$, choose a uniformly random top-left location that keeps the square inside bounds and fill the masked region with a constant value $m \\in [0,1]$ (use the dataset mean intensity), leaving the label unchanged.\n- CutMix: Given two images $x_{a}, x_{b}$ with labels $y_{a}, y_{b}$, sample $\\lambda \\sim \\operatorname{Beta}(\\alpha,\\alpha)$ for $\\alpha>0$. Compute a rectangular region whose area fraction is $(1-\\lambda)$ by setting its side lengths proportional to $\\sqrt{1-\\lambda}$ and placing it at a uniformly random location. Replace that region in $x_{a}$ with the corresponding patch from $x_{b}$ to obtain $\\tilde{x}$, and use the mixed label $\\tilde{y} = \\lambda y_{a} + (1-\\lambda) y_{b}$. As a boundary case, allow full replacement with $\\lambda = 0$, which corresponds to using the entire $x_{b}$ and label $y_{b}$.\n\nTraining and evaluation protocol: Flatten images to vectors in $\\mathbb{R}^{D}$, train the model for a fixed number of epochs with a fixed learning rate and batch size, and then report the test accuracy defined as the fraction of correctly predicted class indices on a held-out test set. Use a fixed random seed to ensure deterministic behavior.\n\nTest suite: Your program must run the following four configurations and return the test accuracy for each, in the listed order.\n- Case $1$ (happy path): no augmentation.\n- Case $2$ (coverage variant): Cutout with fraction $f = 0.50$ and fill value equal to the mean intensity $m$ of the dataset.\n- Case $3$ (augmentation under study): CutMix with $\\alpha = 1.0$ in the Beta distribution $\\operatorname{Beta}(\\alpha,\\alpha)$.\n- Case $4$ (boundary condition): CutMix with full replacement, i.e., deterministically set $\\lambda = 0$ so the pasted rectangle is the entire image.\n\nFixed hyperparameters and data specifications to use in all cases:\n- Image height $H = 16$ and width $W = 16$.\n- Low and high intensities $c_{\\mathrm{lo}} = 0.20$ and $c_{\\mathrm{hi}} = 0.80$.\n- Noise standard deviation $\\sigma = 0.05$.\n- Training set size $N_{\\mathrm{train}} = 400$ and test set size $N_{\\mathrm{test}} = 200$.\n- Batch size $B = 64$, number of epochs $E = 60$, learning rate $\\eta = 0.1$.\n- Random seed $s_{0} = 42$.\n- Use one-hot encoding for the two labels and soft convex combinations only when CutMix applies.\n\nRequired final output format: Your program should produce a single line of output containing the results as a comma-separated list of floating-point accuracies in $[0,1]$, ordered as $[a_{1},a_{2},a_{3},a_{4}]$ corresponding to Cases $1$ through $4$, enclosed in square brackets and with no extra whitespace or text (for example, $[0.9750,0.9600,0.9100,0.5200]$). No units are involved in this problem, and any fractional quantities must be expressed as decimals in the program output.",
            "solution": "The objective is to investigate the impact of spatial data augmentations—specifically Cutout and CutMix—on the performance of a multinomial logistic regression model. The learning task is designed such that class identity is determined exclusively by the global spatial arrangement of features, not by local content. We will implement the entire experimental pipeline from first principles, including dataset generation, model training via gradient descent, and the augmentation algorithms, to evaluate four distinct training configurations.\n\nFirst, we formally define the synthetic dataset. Images are of size $H \\times W$, where $H=16$ and $W=16$. There are two classes, $k \\in \\{0, 1\\}$. The image canvas is partitioned into four equal $8 \\times 8$ quadrants. For an image of class $k=0$, the top-left and bottom-right quadrants are filled with a high intensity value $c_{\\mathrm{hi}}=0.80$, while the top-right and bottom-left quadrants are filled with a low intensity value $c_{\\mathrm{lo}}=0.20$. For class $k=1$, this assignment is inverted. Following this deterministic construction, we add independent and identically distributed Gaussian noise, drawn from $\\mathcal{N}(0, \\sigma^2)$ with $\\sigma=0.05$, to each pixel. The final pixel intensities are clipped to the range $[0, 1]$. This procedure generates a dataset where the core distinguishing feature is a global \"checkerboard\" pattern of intensity. Training and test sets of sizes $N_{\\mathrm{train}}=400$ and $N_{\\mathrm{test}}=200$ are generated, with balanced classes. The random seed for all stochastic processes is fixed at $s_0=42$ to ensure reproducibility.\n\nThe model employed is multinomial logistic regression, also known as softmax regression. An input image is first flattened into a vector $x \\in \\mathbb{R}^{D}$, where the dimensionality $D = H \\cdot W = 256$. The model parameters are a weight matrix $W \\in \\mathbb{R}^{D \\times 2}$ and a bias vector $b \\in \\mathbb{R}^{2}$. For a given input $x$, the model computes scores $z_k = w_k^\\top x + b_k$ for each class $k$. These scores are transformed into probabilities using the softmax function:\n$$\np_{\\theta}(y=k \\mid x) = \\frac{\\exp(z_k)}{\\sum_{j=0}^{1} \\exp(z_j)}\n$$\nwhere $\\theta = \\{W, b\\}$.\n\nThe model parameters are learned by minimizing the empirical risk, specifically the average cross-entropy loss over the training dataset. For a training set of $N$ samples $\\{(x_i, y_i)\\}_{i=1}^N$, where $y_i$ is the label vector, the loss function is:\n$$\n\\mathcal{L}(\\theta) = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{k=0}^{1} y_{i,k} \\log p_{\\theta}(y=k \\mid x_{i})\n$$\nThe label vector $y_i$ is a one-hot encoding for standard classification (e.g., $[1, 0]$ for class $0$). For samples created by CutMix, $y_i$ becomes a \"soft\" label representing a convex combination of the original one-hot labels.\n\nOptimization is performed using mini-batch gradient descent. For a mini-batch of size $B$, the gradients of the loss with respect to the parameters are:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial W} = \\frac{1}{B} X_{\\text{batch}}^\\top (P - Y_{\\text{batch}})\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial b} = \\frac{1}{B} \\sum_{i=1}^{B} (p_i - y_i)\n$$\nwhere $X_{\\text{batch}} \\in \\mathbb{R}^{B \\times D}$ is the matrix of input vectors, $Y_{\\text{batch}} \\in \\mathbb{R}^{B \\times 2}$ is the matrix of label vectors, and $P \\in \\mathbb{R}^{B \\times 2}$ is the matrix of predicted probabilities. The parameters are updated iteratively for $E=60$ epochs using a learning rate of $\\eta=0.1$:\n$$\nW \\leftarrow W - \\eta \\frac{\\partial \\mathcal{L}}{\\partial W}\n$$\n$$\nb \\leftarrow b - \\eta \\frac{\\partial \\mathcal{L}}{\\partial b}\n$$\n\nWe implement and evaluate two data augmentation techniques:\n\n1.  **Cutout**: For each image in a batch, a square region is selected and its pixels are replaced with a constant value. The side length of the square is $s = \\lfloor \\sqrt{f} \\cdot H \\rfloor$, where the fraction $f=0.50$, yielding $s = \\lfloor \\sqrt{0.50} \\cdot 16 \\rfloor = 11$. The top-left corner of the square is chosen uniformly at random such that the square remains within the image boundaries. The fill value is the mean intensity of the training dataset. The class label of the image remains unchanged. This augmentation occludes a significant portion of the image, potentially disrupting the global pattern.\n\n2.  **CutMix**: This technique combines pairs of training examples. For a pair of images $(x_a, x_b)$ with labels $(y_a, y_b)$, a mixing a coefficient $\\lambda$ is sampled from a Beta distribution, $\\lambda \\sim \\operatorname{Beta}(\\alpha, \\alpha)$ with $\\alpha=1.0$ (which is equivalent to a uniform distribution $\\mathcal{U}[0,1]$). A rectangular patch is cut from $x_b$ and pasted onto $x_a$. The area of this patch is $(1-\\lambda)$ times the total image area, with side lengths proportional to $\\sqrt{1-\\lambda}$. The location of the patch is chosen uniformly at random. The resulting synthetic image $\\tilde{x}$ is assigned a soft label $\\tilde{y} = \\lambda y_a + (1-\\lambda) y_b$. This forces the model to learn from fragmented patterns and associate them with proportionally mixed labels.\n\nWe will execute four test cases to assess the impact of these augmentations:\n- **Case 1**: No augmentation, serving as a baseline.\n- **Case 2**: Training with Cutout ($f=0.50$).\n- **Case 3**: Training with CutMix ($\\alpha=1.0$).\n- **Case 4**: A boundary condition of CutMix where $\\lambda$ is deterministically set to $0$. This results in replacing a training sample $(x_a, y_a)$ with another randomly chosen sample from the same batch, $(x_b, y_b)$.\n\nFor each case, we train a model from scratch on the same training data and report its final accuracy on the same held-out test set. This controlled comparison will illuminate how these augmentations interact with a learning problem that depends critically on global context.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the four test cases and print the results.\n    \"\"\"\n    \n    # --- Fixed Hyperparameters and Data Specifications ---\n    H, W = 16, 16\n    c_lo, c_hi = 0.20, 0.80\n    sigma = 0.05\n    N_train, N_test = 400, 200\n    B = 64\n    E = 60\n    eta = 0.1\n    s0 = 42\n    \n    # --- Case-specific parameters ---\n    case_params = [\n        {'aug': 'none'},\n        {'aug': 'cutout', 'f': 0.50},\n        {'aug': 'cutmix', 'alpha': 1.0},\n        {'aug': 'cutmix_lambda_0'},\n    ]\n\n    results = []\n    for params in case_params:\n        # Each case must be fully deterministic and reproducible\n        accuracy = train_and_evaluate(\n            H=H, W=W, c_lo=c_lo, c_hi=c_hi, sigma=sigma,\n            N_train=N_train, N_test=N_test, B=B, E=E, eta=eta,\n            seed=s0, aug_params=params\n        )\n        results.append(f\"{accuracy:.4f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef train_and_evaluate(H, W, c_lo, c_hi, sigma, N_train, N_test, B, E, eta, seed, aug_params):\n    \"\"\"\n    Generates data, trains a model under a specific augmentation, and evaluates it.\n    \"\"\"\n    \n    # --- Seeding for reproducibility ---\n    rng = np.random.default_rng(seed)\n\n    # --- Helper Functions ---\n    def softmax(z):\n        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n\n    def cross_entropy_loss(y_true, y_pred):\n        # Clip y_pred to avoid log(0)\n        y_pred = np.clip(y_pred, 1e-12, 1. - 1e-12)\n        return -np.sum(y_true * np.log(y_pred)) / y_true.shape[0]\n        \n    # --- Dataset Generation ---\n    def generate_dataset(N, H, W, c_lo, c_hi, sigma, rng_gen):\n        n_per_class = N // 2\n        X = np.zeros((N, H, W), dtype=np.float32)\n        Y = np.zeros((N, 2), dtype=np.float32)\n        \n        h_half, w_half = H // 2, W // 2\n        \n        # Class 0\n        for i in range(n_per_class):\n            img = np.full((H, W), c_lo, dtype=np.float32)\n            img[:h_half, :w_half] = c_hi\n            img[h_half:, w_half:] = c_hi\n            X[i] = img\n            Y[i] = [1, 0]\n            \n        # Class 1\n        for i in range(n_per_class, N):\n            img = np.full((H, W), c_hi, dtype=np.float32)\n            img[:h_half, :w_half] = c_lo\n            img[h_half:, w_half:] = c_lo\n            X[i] = img\n            Y[i] = [0, 1]\n\n        # Add noise and clip\n        X += rng_gen.normal(0, sigma, X.shape)\n        X = np.clip(X, 0.0, 1.0)\n        \n        # Shuffle dataset\n        indices = np.arange(N)\n        rng_gen.shuffle(indices)\n        X, Y = X[indices], Y[indices]\n        \n        return X, Y\n\n    X_train, Y_train = generate_dataset(N_train, H, W, c_lo, c_hi, sigma, rng)\n    X_test, Y_test = generate_dataset(N_test, H, W, c_lo, c_hi, sigma, rng)\n\n    # --- Model Initialization ---\n    D = H * W\n    K = 2 \n    # Use the same RNG for reproducible weight initialization\n    w_rng = np.random.default_rng(seed)\n    W_mat = w_rng.normal(0, 0.01, (D, K))\n    b_vec = np.zeros((1, K))\n\n    # --- Augmentation setup ---\n    aug = aug_params['aug']\n    \n    # Calculate dataset mean for Cutout\n    mean_intensity = 0.0\n    if aug == 'cutout':\n        mean_intensity = np.mean(X_train)\n\n    # --- Training Loop ---\n    for epoch in range(E):\n        indices = np.arange(N_train)\n        rng.shuffle(indices)\n        X_train_shuffled, Y_train_shuffled = X_train[indices], Y_train[indices]\n\n        for i in range(0, N_train, B):\n            X_batch_orig = X_train_shuffled[i:i+B]\n            Y_batch_orig = Y_train_shuffled[i:i+B]\n            \n            actual_B = X_batch_orig.shape[0]\n            if actual_B == 0: continue\n\n            # Apply augmentations\n            X_batch_aug, Y_batch_aug = X_batch_orig.copy(), Y_batch_orig.copy()\n\n            if aug == 'cutout':\n                f = aug_params['f']\n                s = int(np.floor(np.sqrt(f) * H))\n                for j in range(actual_B):\n                    y1 = rng.integers(0, H - s + 1)\n                    x1 = rng.integers(0, W - s + 1)\n                    X_batch_aug[j, y1:y1+s, x1:x1+s] = mean_intensity\n            \n            elif aug == 'cutmix':\n                alpha = aug_params['alpha']\n                for j in range(actual_B):\n                    lam = rng.beta(alpha, alpha)\n                    rand_index = rng.integers(actual_B)\n                    \n                    xa, ya = X_batch_aug[j], Y_batch_aug[j]\n                    xb, yb = X_batch_aug[rand_index], Y_batch_aug[rand_index]\n                    \n                    ratio = np.sqrt(1. - lam)\n                    patch_h = int(H * ratio)\n                    patch_w = int(W * ratio)\n\n                    if patch_h > 0 and patch_w > 0:\n                        cy = rng.integers(H - patch_h + 1)\n                        cx = rng.integers(W - patch_w + 1)\n                        xa[cy:cy+patch_h, cx:cx+patch_w] = xb[cy:cy+patch_h, cx:cx+patch_w]\n\n                    X_batch_aug[j] = xa\n                    Y_batch_aug[j] = lam * ya + (1. - lam) * yb\n\n            elif aug == 'cutmix_lambda_0':\n                # Deterministic lambda = 0\n                for j in range(actual_B):\n                    rand_index = rng.integers(actual_B)\n                    # Complete replacement of image and label\n                    X_batch_aug[j] = X_batch_orig[rand_index]\n                    Y_batch_aug[j] = Y_batch_orig[rand_index]\n\n            # Flatten images\n            X_batch_flat = X_batch_aug.reshape(actual_B, D)\n\n            # Forward pass\n            scores = X_batch_flat @ W_mat + b_vec\n            probs = softmax(scores)\n\n            # Backward pass (gradient calculation)\n            grad_scores = (probs - Y_batch_aug) / actual_B\n            grad_W = X_batch_flat.T @ grad_scores\n            grad_b = np.sum(grad_scores, axis=0, keepdims=True)\n\n            # Update parameters\n            W_mat -= eta * grad_W\n            b_vec -= eta * grad_b\n\n    # --- Evaluation ---\n    X_test_flat = X_test.reshape(N_test, D)\n    test_scores = X_test_flat @ W_mat + b_vec\n    test_probs = softmax(test_scores)\n    \n    predictions = np.argmax(test_probs, axis=1)\n    ground_truth = np.argmax(Y_test, axis=1)\n    \n    accuracy = np.mean(predictions == ground_truth)\n    return accuracy\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "Typically, data augmentation is applied with a fixed policy and strength throughout the entire training process. But should the intensity of augmentation remain constant as the model learns and potentially begins to overfit? This advanced practice  introduces the concept of adaptive augmentation, where the transformation strength is dynamically adjusted based on the model's training state. You will implement a simple yet effective controller that modulates augmentation based on the norm of the model's gradients, providing hands-on experience with the sophisticated, dynamic strategies that are at the forefront of modern augmentation research.",
            "id": "3111262",
            "problem": "You will implement a complete, deterministic program that constructs an adaptive image data augmentation pipeline for a toy image. The augmentation strength must be adapted based on the evolution of the gradient norm sequence, with stronger transforms when the gradient norms are small to mitigate overfitting. The design must start from the foundational principle of empirical risk minimization and gradient-based optimization, and must employ only fundamental statistical operations and deterministic transforms. All trigonometric operations must use radian measure.\n\nBegin from the following base in supervised learning. For a model with parameters $\\theta$ trained by minimizing empirical risk, the instantaneous mini-batch loss is $\\ell(\\theta)$ and the gradient is $\\nabla_{\\theta} \\ell(\\theta)$. The scalar signal available to your augmentation controller is the gradient norm $g_t = \\lVert \\nabla_{\\theta} \\ell(\\theta_t) \\rVert_2$ observed at discrete steps $t = 1, 2, \\dots$. Overfitting is associated with vanishingly small $g_t$ that persist without concomitant generalization improvement, which motivates stronger data augmentation when $g_t$ is small relative to its recent typical scale.\n\nYour tasks are as follows.\n\n1) Define an adaptive augmentation strength $s_t \\in (0, 1)$ at each step $t$ from the observed sequence $\\{g_1, \\dots, g_t\\}$ using only online statistics. Use an Exponential Moving Average (EMA) to track the first and second moments of $g_t$ with smoothing parameter $\\beta$ and initialize with the first observation to avoid cold-start bias. Use the following update equations for the moment estimates:\n$$\nm_t = (1 - \\beta) m_{t-1} + \\beta g_t, \\quad v_t = (1 - \\beta) v_{t-1} + \\beta g_t^2,\n$$\nwith $m_1 = g_1$ and $v_1 = g_1^2$. To avoid circularity when computing the standardized deviation for $t \\ge 2$, use the previous step statistics to form\n$$\nz_t = \\frac{g_t - m_{t-1}}{\\sqrt{\\max(v_{t-1} - m_{t-1}^2, \\varepsilon)}},\n$$\nwhere $\\varepsilon$ is a small positive constant. Map this standardized deviation to an intensity component via a logistic function\n$$\ns^{(1)}_t = \\frac{1}{1 + \\exp(\\gamma z_t)},\n$$\nwhere $\\gamma > 0$ controls steepness. To guard against globally small gradients where variance collapses, define an absolute-scale component\n$$\ns^{(2)}_t = \\frac{1}{1 + \\left(\\frac{g_t}{\\tau_0}\\right)^k},\n$$\nwith threshold $\\tau_0 > 0$ and exponent $k \\ge 1$. Combine the two components into the final strength\n$$\ns_t = \\frac{1}{2} s^{(1)}_t + \\frac{1}{2} s^{(2)}_t.\n$$\nUse $\\beta = 0.2$, $\\gamma = 1.5$, $\\varepsilon = 10^{-8}$, $\\tau_0 = 0.05$, and $k = 2$. The value $s_t$ you report for each test should be computed at the final time index $t$ of the provided sequence.\n\n2) Define a deterministic toy grayscale image and deterministic augmentation transforms controlled by $s_t$. Let the image be a grid $I \\in [0,1]^{8 \\times 8}$ with entries\n$$\nI_{ij} = \\frac{i + j}{14}, \\quad i,j \\in \\{0,1,\\dots,7\\},\n$$\nso that $I$ is a smooth ramp. Define a deterministic, zero-mean spatial pattern\n$$\nN_{ij} = \\sin\\!\\left(\\frac{2\\pi (i + j)}{8}\\right),\n$$\nwith the sine argument in radians. Given $s_t$, compute the following transforms:\n- Brightness scaling factor $B = 1 + 0.3 s_t$.\n- Additive pattern amplitude $\\sigma = 0.1 s_t$ applied to $N$.\n- Compose the intermediate image\n$$\nJ = \\operatorname{clip}(B \\cdot I + \\sigma \\cdot N, 0, 1),\n$$\nwhere $\\operatorname{clip}$ saturates values to the interval $[0,1]$.\n- Apply a center cutout whose side length in pixels is $L = \\left\\lfloor 0.5 s_t \\cdot 8 \\right\\rfloor$. If $L = 0$, do nothing. Otherwise, replace the centered square of side $L$ in $J$ by the global mean of $J$ to obtain the augmented image $A$.\n\nQuantify the augmentation effect via the mean squared distortion\n$$\nD = \\frac{1}{64} \\sum_{i=0}^{7} \\sum_{j=0}^{7} \\left(A_{ij} - I_{ij}\\right)^2.\n$$\n\n3) Implement the above as a single, self-contained program using the specified runtime. The program must compute the augmentation strength $s_t$ (at the final step $t$) and the distortion $D$ for each of the following five gradient-norm sequences, which constitute the test suite:\n- Case 1 (decreasing): $[1.0, 0.8, 0.6, 0.5, 0.4]$.\n- Case 2 (increasing): $[0.2, 0.3, 0.4, 0.6, 0.9]$.\n- Case 3 (constant small): $[0.05, 0.05, 0.05, 0.05, 0.05]$.\n- Case 4 (alternating): $[0.9, 0.1, 0.9, 0.1, 0.9]$.\n- Case 5 (near zero): $[0.0, 0.0, 0.0, 0.0, 0.0]$.\n\nFor each case, output two floats: first the final augmentation strength $s_t$, then the distortion $D$. Your program should produce a single line of output containing all results as a comma-separated list enclosed in square brackets, in the order of the cases above, with each float rounded to six decimal places, i.e.,\n$[s_1, D_1, s_2, D_2, s_3, D_3, s_4, D_4, s_5, D_5]$.",
            "solution": "The problem is assessed as valid. It presents a self-contained, scientifically grounded, and computationally well-defined task in the domain of deep learning and computer vision. The objective is to implement a deterministic, adaptive data augmentation pipeline whose strength is controlled by the statistics of a gradient norm sequence. The ambiguity in the definition of the standardized deviation $z_t$ at the initial step $t=1$ is resolved by adopting the standard convention of setting $z_1=0$, as no prior statistical history exists. All other definitions, constants, and procedures are specified with sufficient precision to permit a unique solution.\n\nThe solution is implemented by following the three main tasks described in the problem statement. The process is broken down into the calculation of the augmentation strength, the application of transformations to a toy image, and the final computation of distortion.\n\n### 1. Adaptive Augmentation Strength Calculation ($s_t$)\n\nThe core of the adaptive mechanism is the augmentation strength $s_t \\in (0, 1)$, which is dynamically computed at each step $t$ based on the history of observed gradient norms $\\{g_1, g_2, \\dots, g_t\\}$. The procedure for a given sequence of gradient norms is as follows:\n\n- **Initialization**: At step $t=1$, the Exponential Moving Average (EMA) moments are initialized directly from the first observation: $m_1 = g_1$ and $v_1 = g_1^2$.\n- **Recursive Update**: For subsequent steps $t \\ge 2$, the first moment $m_t$ (mean) and second moment $v_t$ (mean of squares) of the gradient norm sequence are updated using the EMA formulas with a smoothing parameter $\\beta = 0.2$:\n$$\nm_t = (1 - \\beta) m_{t-1} + \\beta g_t\n$$\n$$\nv_t = (1 - \\beta) v_{t-1} + \\beta g_t^2\n$$\n- **Standardized Deviation ($z_t$)**: The current gradient norm $g_t$ is standardized relative to the statistics of the previous step, $m_{t-1}$ and $v_{t-1}$. This produces a measure of how unusual the current gradient norm is. For $t=1$, we set $z_1=0$. For $t \\ge 2$, the formula is:\n$$\nz_t = \\frac{g_t - m_{t-1}}{\\sqrt{\\max(v_{t-1} - m_{t-1}^2, \\varepsilon)}}\n$$\nwhere $\\varepsilon = 10^{-8}$ is a small constant ensuring the denominator, which approximates the standard deviation, is non-zero.\n- **Strength Components**: The strength $s_t$ is a combination of two components.\n    1.  $s^{(1)}_t$ is based on the standardized deviation $z_t$. It maps large negative $z_t$ (i.e., $g_t$ much smaller than its recent average) to a high strength. A logistic function with steepness $\\gamma = 1.5$ is used:\n        $$\n        s^{(1)}_t = \\frac{1}{1 + \\exp(\\gamma z_t)}\n        $$\n    2.  $s^{(2)}_t$ is based on the absolute magnitude of $g_t$. It ensures high augmentation strength when the gradient norm is small in an absolute sense, regardless of its recent history. This guards against scenarios where all gradients are small and the variance collapses. It is defined with a threshold $\\tau_0 = 0.05$ and an exponent $k=2$:\n        $$\n        s^{(2)}_t = \\frac{1}{1 + \\left(\\frac{g_t}{\\tau_0}\\right)^k}\n        $$\n- **Final Strength**: The two components are averaged to produce the final strength for step $t$:\n$$\ns_t = \\frac{1}{2} s^{(1)}_t + \\frac{1}{2} s^{(2)}_t\n$$\nFor each test case, this calculation is carried out for the entire gradient norm sequence, and the value of $s_t$ from the final step is used for the subsequent image augmentation.\n\n### 2. Image Augmentation Pipeline\n\nA deterministic toy image and a set of transformations are defined to demonstrate the effect of the calculated strength $s_t$.\n\n- **Base Image ($I$)**: A grayscale image $I$ of size $8 \\times 8$ is generated, with pixel values forming a linear ramp. The value at position $(i,j)$ for $i,j \\in \\{0, 1, \\dots, 7\\}$ is:\n$$\nI_{ij} = \\frac{i + j}{14}\n$$\nThis ensures pixel values are in the range $[0,1]$.\n- **Noise Pattern ($N$)**: A deterministic, zero-mean spatial pattern $N$ of size $8 \\times 8$ is created using a sine function, with the argument in radians:\n$$\nN_{ij} = \\sin\\!\\left(\\frac{2\\pi (i + j)}{8}\\right)\n$$\n- **Transformations**: The final augmentation strength $s_t$ controls a series of transformations applied to the base image $I$:\n    1.  **Brightness and Contrast**: An intermediate image $J$ is formed by applying a brightness scaling and adding the noise pattern. The brightness factor is $B = 1 + 0.3 s_t$ and the noise amplitude is $\\sigma = 0.1 s_t$. The resulting image is clipped to the $[0,1]$ range:\n        $$\n        J = \\operatorname{clip}(B \\cdot I + \\sigma \\cdot N, 0, 1)\n        $$\n    2.  **Center Cutout**: A square region at the center of the image $J$ is replaced by the global mean of $J$. The side length of this square is $L = \\lfloor 0.5 s_t \\cdot 8 \\rfloor = \\lfloor 4 s_t \\rfloor$ pixels. If $L=0$, no cutout is performed. For the $8 \\times 8$ grid, a centered square of side $L$ starts at indices $(\\lfloor \\frac{8-L}{2} \\rfloor, \\lfloor \\frac{8-L}{2} \\rfloor)$. The result of this operation is the final augmented image $A$.\n\n### 3. Distortion Metric ($D$)\n\nTo quantify the magnitude of the applied augmentation, the mean squared distortion $D$ between the augmented image $A$ and the original image $I$ is calculated. This is defined as the average of the squared differences of pixel values over the entire $8 \\times 8 = 64$ pixel grid:\n$$\nD = \\frac{1}{64} \\sum_{i=0}^{7} \\sum_{j=0}^{7} \\left(A_{ij} - I_{ij}\\right)^2\n$$\n\nThe provided program implements this full pipeline, computing the final strength $s_t$ and the corresponding distortion $D$ for each of the five specified gradient-norm sequences.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the adaptive augmentation simulation for all test cases.\n    \"\"\"\n    \n    # Define the problem parameters.\n    BETA = 0.2\n    GAMMA = 1.5\n    EPSILON = 1e-8\n    TAU0 = 0.05\n    K_EXP = 2\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        [1.0, 0.8, 0.6, 0.5, 0.4],       # Case 1 (decreasing)\n        [0.2, 0.3, 0.4, 0.6, 0.9],       # Case 2 (increasing)\n        [0.05, 0.05, 0.05, 0.05, 0.05], # Case 3 (constant small)\n        [0.9, 0.1, 0.9, 0.1, 0.9],       # Case 4 (alternating)\n        [0.0, 0.0, 0.0, 0.0, 0.0],       # Case 5 (near zero)\n    ]\n\n    # --- Helper function to process one case ---\n    def process_case(g_sequence):\n        # Part 1: Compute final augmentation strength s_t\n        m_prev, v_prev = 0.0, 0.0\n        s_t = 0.0\n        \n        for t, g_t in enumerate(g_sequence):\n            # t is 0-indexed, so simulation step is t+1\n            if t == 0:  # Step t=1\n                m_t = g_t\n                v_t = g_t**2\n                # As per standard convention for the first step where no\n                # prior statistics exist, z_1 is taken as 0.\n                z_t = 0.0\n            else:  # Step t>=2\n                # Standardized deviation z_t uses statistics from step t-1\n                var_prev = v_prev - m_prev**2\n                std_dev_prev = np.sqrt(max(var_prev, EPSILON))\n                z_t = (g_t - m_prev) / std_dev_prev\n                \n                # Update EMA moments for current step t\n                m_t = (1.0 - BETA) * m_prev + BETA * g_t\n                v_t = (1.0 - BETA) * v_prev + BETA * g_t**2\n            \n            # Calculate strength components for step t\n            s1_t = 1.0 / (1.0 + np.exp(GAMMA * z_t))\n            s2_t = 1.0 / (1.0 + (g_t / TAU0)**K_EXP)\n            \n            # Final combined strength for step t\n            s_t = 0.5 * s1_t + 0.5 * s2_t\n            \n            # Store current moments for the next iteration\n            m_prev, v_prev = m_t, v_t\n        \n        final_s = s_t\n    \n        # Part 2: Image Augmentation\n        img_size = 8\n        \n        # Create original image I\n        i_coords, j_coords = np.indices((img_size, img_size))\n        # Denominator is 2 * (img_size - 1) = 14\n        I = (i_coords + j_coords) / (2.0 * (img_size - 1))\n\n        # Create noise pattern N\n        N_pattern = np.sin(2.0 * np.pi * (i_coords + j_coords) / img_size)\n\n        # Augmentation parameters from final strength\n        B = 1.0 + 0.3 * final_s\n        sigma = 0.1 * final_s\n\n        # Intermediate image J\n        J = np.clip(B * I + sigma * N_pattern, 0.0, 1.0)\n\n        # Cutout logic\n        # L = floor(0.5 * s_t * 8) = floor(4 * s_t)\n        L = int(np.floor(4.0 * final_s))\n        A = J.copy()  # Start with J, then apply cutout\n        \n        if L > 0:\n            mean_J = np.mean(J)\n            start_idx = (img_size - L) // 2\n            A[start_idx:start_idx + L, start_idx:start_idx + L] = mean_J\n\n        # Part 3: Distortion\n        D = np.mean((A - I)**2)\n        \n        return final_s, D\n\n    # --- Main loop to gather results ---\n    results = []\n    for case_sequence in test_cases:\n        s, d = process_case(case_sequence)\n        results.extend([s, d])\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}