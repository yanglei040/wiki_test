{
    "hands_on_practices": [
        {
            "introduction": "在设计复杂的学习率策略之前，首先必须具备从训练曲线中识别预热（warmup）是否配置不当的能力。这项练习将引导你通过一个简化的模拟环境，学习如何诊断学习率预热问题。你将实现具体的诊断规则，以识别“预热不足”（under-warmup）导致的初期训练不稳定，以及“预热过度”（over-warmup）导致的收敛过慢，从而为后续设计更优的预热策略打下直观基础。",
            "id": "3115472",
            "problem": "您将实现并使用一个简单的、确定性的训练动态模拟器，利用学习曲线来诊断学习率预热（warmup）。设定为在一个严格凸二次函数上进行一维梯度下降，学习率先经过线性增加的预热，然后保持恒定。您的程序必须模拟多个周期的训练损失，对学习曲线的早期部分应用基于原则的诊断，并将每种情况分类为预热不足、预热过度或可接受的预热。\n\n基本原理：\n- 考虑损失函数 $L(x) = \\frac{1}{2} a x^{2}$，其曲率 $a \\gt 0$。梯度为 $\\nabla L(x) = a x$。使用学习率 $\\eta_{t}$ 的梯度下降将参数更新为 $x_{t+1} = x_{t} - \\eta_{t} \\nabla L(x_{t})$。\n- 具有预热长度 $w$ 和最大学习率 $\\eta_{\\max}$ 的线性预热学习率方案由下式给出：\n  - $\\eta_{t} = \\eta_{\\max} \\cdot \\min\\!\\left(\\frac{t}{w}, 1\\right)$，对于整数周期 $t \\in \\{1, 2, \\dots, T\\}$。\n- 观测到的训练损失被确定性地建模为 $y_{t} = L(x_{t}) + \\sigma \\sin\\!\\left( \\frac{2 \\pi t}{P} \\right)$，其中 $\\sigma \\ge 0$ 且周期参数 $P \\ge 1$。对于 $t = 0$，定义 $y_{0} = L(x_{0})$。\n\n需要从基本原理实现的诊断方法：\n- 早期周期的稳定性：定义一个长度为 $K = \\min(5, T)$ 的早期窗口。通过检查是否存在某个 $t \\in \\{1, \\dots, K\\}$ 使得 $y_{t} \\gt (1 + \\tau) \\, y_{t-1}$ 来检测初始发散，其中阈值 $\\tau = 0.1$。\n- 进展延迟：将在周期 $K$ 时达到的总损失减少的比例量化为\n  $$f_{\\text{early}} = \\frac{y_{0} - y_{K}}{\\max(y_{0} - y_{T}, \\varepsilon)},$$\n  其中 $\\varepsilon = 10^{-12}$。如果 $f_{\\text{early}} \\lt \\rho$（其中 $\\rho = 0.2$），则判断为进展延迟。\n- 分类规则，按此顺序应用：\n  - 如果在早期窗口内检测到初始发散，则分类为预热不足并输出 $-1$。\n  - 否则，如果检测到进展延迟，则分类为预热过度并输出 $1$。\n  - 否则，分类为可接受的预热并输出 $0$。\n\n模拟细节：\n- 用 $x_{0}$ 初始化，并计算 $y_{0} = L(x_{0})$。\n- 对于每个周期 $t = 1, 2, \\dots, T$：\n  - 计算 $\\eta_{t} = \\eta_{\\max} \\cdot \\min\\!\\left(\\frac{t}{w}, 1\\right)$。\n  - 更新 $x_{t} = x_{t-1} - \\eta_{t} a x_{t-1}$。\n  - 计算 $y_{t} = \\frac{1}{2} a x_{t}^{2} + \\sigma \\sin\\!\\left( \\frac{2 \\pi t}{P} \\right)$。\n\n测试套件：\n为以下参数集提供输出。每个案例是一个元组 $(a, \\eta_{\\max}, w, T, x_{0}, \\sigma, P)$：\n- 案例 A（预期通过极短的预热来探测初始发散）：$(10.0, 0.25, 1, 40, 1.0, 0.0, 7)$。\n- 案例 B（预期在安全的最大学习率和较短的预热下为可接受的预热）：$(10.0, 0.15, 3, 40, 1.0, 0.0, 7)$。\n- 案例 C（预期在非常长的预热下出现进展延迟）：$(10.0, 0.18, 300, 500, 1.0, 0.0, 7)$。\n- 案例 D（预热后处于经典步长稳定性极限边缘的边界稳定性）：$(10.0, 0.20, 5, 40, 1.0, 0.0, 7)$。\n- 案例 E（预期在预热结束时因最大学习率过高而出现初始发散）：$(12.0, 0.25, 5, 50, 1.0, 0.0, 7)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为上述测试套件的结果，并按顺序排列。每个条目必须是 $\\{-1, 0, 1\\}$ 中的一个整数，代表该案例的分类，因此输出必须类似于 $[r_{A}, r_{B}, r_{C}, r_{D}, r_{E}]$。\n\n注意：\n- 本问题中不涉及物理单位。\n- 根据参数 $\\frac{2 \\pi t}{P}$ 的构造，正弦项中的角度以弧度为单位。\n- 百分比必须以小数表示，所有阈值 $\\tau$、$\\rho$ 和 $\\varepsilon$ 均以数值形式提供。",
            "solution": "问题陈述已经过验证，并被确定是合理的。它在科学上基于数值优化的原理，特别是凸二次函数上的梯度下降。该问题是适定的，所有参数、方程和诊断标准都有明确无误的定义。整个设置是自洽且内部一致的，可以得出一个唯一且有意义的解。\n\n任务是模拟一维参数 $x$ 在梯度下降下的训练动态，并对学习率预热方案的行为进行分类。该过程涉及几个相互关联的组成部分：优化的数学模型、学习率方案、训练损失的模拟以及一套诊断规则。\n\n首先，我们建立核心优化模型。损失函数是一个简单的凸二次函数，$L(x) = \\frac{1}{2} a x^2$，其中 $a > 0$ 是曲率。该损失函数关于参数 $x$ 的梯度是 $\\nabla L(x) = a x$。梯度下降更新规则在每个周期 $t$ 根据方程 $x_{t} = x_{t-1} - \\eta_{t} \\nabla L(x_{t-1})$ 修改参数 $x$，其中 $\\eta_t$ 是周期 $t$ 的学习率。代入梯度，具体的更新规则是：\n$$x_{t} = x_{t-1} - \\eta_{t} a x_{t-1} = x_{t-1}(1 - \\eta_{t} a)$$\n此更新在周期 $t = 1, 2, \\dots, T$ 执行。\n\n学习率 $\\eta_t$ 遵循线性预热方案。对于总共 $w$ 个周期的预热时长和目标最大学习率 $\\eta_{\\max}$，周期 $t$ 的学习率由下式给出：\n$$\\eta_{t} = \\eta_{\\max} \\cdot \\min\\left(\\frac{t}{w}, 1\\right)$$\n这意味着对于 $t \\le w$，$\\eta_t$ 从 $\\eta_1 = \\eta_{\\max}/w$ 线性增加到 $\\eta_w = \\eta_{\\max}$。对于所有后续周期 $t > w$，学习率保持恒定在 $\\eta_t = \\eta_{\\max}$。\n\n模拟必须跟踪每个周期的训练损失。问题定义了一个观测损失 $y_t$，它由真实损失 $L(x_t)$ 和一个确定性的正弦噪声项组成。初始损失为 $y_0 = L(x_0)$。对于后续周期 $t \\in \\{1, 2, \\dots, T\\}$，观测损失为：\n$$y_t = L(x_t) + \\sigma \\sin\\left(\\frac{2 \\pi t}{P}\\right) = \\frac{1}{2} a x_t^2 + \\sigma \\sin\\left(\\frac{2 \\pi t}{P}\\right)$$\n模拟过程如下：\n1. 初始化参数 $x_0$ 并计算初始损失 $y_0 = \\frac{1}{2} a x_0^2$。将所有损失值 $y_t$ 存储在一个数组中。\n2. 对于从 $1$ 到 $T$ 的每个周期 $t$：\n   a. 使用预热方案计算学习率 $\\eta_t$。\n   b. 使用梯度下降规则更新参数以得到 $x_t$。\n   c. 计算观测损失 $y_t$ 并存储它。\n\n模拟完成后，我们对生成的学习曲线 $\\{y_t\\}_{t=0}^T$ 应用一系列诊断测试。\n\n第一个诊断是针对**早期周期的稳定性**。该测试检查初始发散，这是学习率过于激进（即预热不足）的常见症状。我们定义一个 $K = \\min(5, T)$ 个周期的早期窗口。如果损失在该窗口内的任何点上增加了超过相对阈值 $\\tau = 0.1$，则检测到初始发散。也就是说，如果存在任何 $t \\in \\{1, \\dots, K\\}$ 使得：\n$$y_t > (1 + \\tau) y_{t-1}$$\n如果满足此条件，则将预热分类为`预热不足`（`-1`）。\n\n如果没有发现初始发散，第二个诊断是针对**进展延迟**。该测试检查学习率是否过于保守（即预热过度），这会导致模型在开始时学习得太慢。我们量化在 $K$ 个周期的早期窗口内发生的总损失减少的比例：\n$$f_{\\text{early}} = \\frac{y_0 - y_K}{\\max(y_0 - y_T, \\varepsilon)}$$\n这里，$\\varepsilon = 10^{-12}$ 是一个很小的常数，用于防止在周期 $0$ 到 $T$ 损失没有减少时出现除以零的情况。如果这个比例低于阈值 $\\rho = 0.2$，我们判定为进展延迟。然后将预热分类为`预热过度`（`1`）。\n\n最终的分类遵循严格的顺序。\n1. 如果检测到初始发散，结果为 $-1$。\n2. 否则，如果检测到进展延迟，结果为 $1$。\n3. 否则，预热被认为是`可接受的`，结果为 $0$。\n\n此过程将应用于提供的每个测试案例。该实现将系统地执行模拟并应用定义的诊断方法，为每组参数生成最终分类。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates training dynamics to diagnose learning rate warmup for several test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case A: (a, eta_max, w, T, x0, sigma, P)\n        (10.0, 0.25, 1, 40, 1.0, 0.0, 7),\n        # Case B:\n        (10.0, 0.15, 3, 40, 1.0, 0.0, 7),\n        # Case C:\n        (10.0, 0.18, 300, 500, 1.0, 0.0, 7),\n        # Case D:\n        (10.0, 0.20, 5, 40, 1.0, 0.0, 7),\n        # Case E:\n        (12.0, 0.25, 5, 50, 1.0, 0.0, 7),\n    ]\n\n    results = []\n\n    # Diagnostic thresholds and constants\n    tau = 0.1\n    rho = 0.2\n    epsilon = 1e-12\n\n    for case in test_cases:\n        a, eta_max, w, T, x0, sigma, P = case\n\n        # --- Simulation ---\n        # Initialize arrays for parameter and loss history\n        x_history = np.zeros(T + 1)\n        y_history = np.zeros(T + 1)\n\n        # Initial conditions\n        x_history[0] = x0\n        y_history[0] = 0.5 * a * x_history[0]**2\n\n        # Run the simulation loop for T epochs\n        for t in range(1, T + 1):\n            # Calculate learning rate with linear warmup\n            eta_t = eta_max * min(t / w, 1.0)\n            \n            # Update parameter using gradient descent\n            x_prev = x_history[t-1]\n            x_curr = x_prev * (1 - eta_t * a)\n            x_history[t] = x_curr\n            \n            # Calculate observed loss\n            true_loss = 0.5 * a * x_curr**2\n            noise = sigma * np.sin(2 * np.pi * t / P) if sigma > 0 else 0.0\n            y_history[t] = true_loss + noise\n\n        # --- Diagnostics ---\n        K = min(5, T)\n        y0 = y_history[0]\n        yK = y_history[K]\n        yT = y_history[T]\n\n        # 1. Check for early-epoch stability (under-warmup)\n        initial_divergence = False\n        for t in range(1, K + 1):\n            if y_history[t] > (1 + tau) * y_history[t-1]:\n                initial_divergence = True\n                break\n\n        # 2. Check for delayed progress (over-warmup)\n        # This is only checked if no divergence was found.\n        delayed_progress = False\n        if not initial_divergence:\n            denominator = max(y0 - yT, epsilon)\n            f_early = (y0 - yK) / denominator\n            if f_early < rho:\n                delayed_progress = True\n        \n        # 3. Apply classification rule\n        if initial_divergence:\n            results.append(-1)  # Under-warmup\n        elif delayed_progress:\n            results.append(1)   # Over-warmup\n        else:\n            results.append(0)   # Acceptable warmup\n\n    # Print results in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "掌握了诊断方法后，我们自然会思考如何设计更好的预热策略。除了线性预热，还存在余弦预热等多种形式。这项练习将让你在固定的“学习预算”（即预热期间学习率的累积总和）下，比较不同形状的预热方案对优化结果的影响。通过这个实践，你将深刻理解到，预热策略的形状，而不仅仅是其长度或峰值，对最终训练效果同样至关重要。",
            "id": "3143278",
            "problem": "考虑将确定性梯度下降应用于一维二次目标函数 $f(x) = \\frac{1}{2}\\lambda x^2$，其中曲率参数 $\\lambda > 0$。更新规则为 $x_{k+1} = x_k - \\eta_k \\nabla f(x_k)$，其中 $k = 0, 1, \\dots, T_w - 1$，$\\eta_k \\ge 0$ 是第 $k$ 步的学习率，$T_w$ 是预热长度（预热期间的梯度下降步数）。梯度为 $\\nabla f(x) = \\lambda x$。预热策略是一个序列 $\\{\\eta_k\\}_{k=1}^{T_w}$，该序列是单调不减的，并满足 $\\eta_{T_w} = \\eta_0$，其中 $\\eta_0$ 是预热结束时的基础学习率。\n\n基本原理：\n- 将梯度下降更新 $x_{k+1} = x_k - \\eta_k \\nabla f(x_k)$ 应用于二次函数 $f(x) = \\frac{1}{2}\\lambda x^2$，可得 $x_{k+1} = (1 - \\lambda \\eta_k) x_k$。\n- 累积预热“预算”约束为离散和 $\\sum_{k=1}^{T_w} \\eta_k$ 等于一个固定常数 $A > 0$。这个离散和是连续积分 $\\int_0^{T_w} \\eta(t)\\,dt$ 的黎曼和近似，并且在离散设置中将精确执行为 $\\sum_{k=1}^{T_w} \\eta_k = A$。\n\n待分析的预热策略族：\n- 线性预热：随步数索引成比例增加，在第 $T_w$ 步从 $0$ 增长到 $\\eta_0$。\n- 余弦预热：根据 $1 - \\cos(\\cdot)$ 函数，在第 $T_w$ 步从 $0$ 增长到 $\\eta_0$。角度必须以弧度为单位。\n- 指数预热：对于给定的 $\\alpha > 0$，根据 $1 - e^{-\\alpha k}$ 增长，并进行归一化，以使策略在第 $T_w$ 步达到 $\\eta_0$。\n\n对于每个策略族，必须选择基础学习率 $\\eta_0$（作为 $T_w$ 和策略形状参数的函数），以使离散和 $\\sum_{k=1}^{T_w} \\eta_k$ 等于固定值 $A$。然后，从 $x_0$ 开始运行梯度下降 $T_w$ 步，并记录最终的目标函数值 $f(x_{T_w})$。因此，该分析比较了保持相同预热预算 $A$ 的不同 $(T_w, \\eta_0)$ 对的结果（最终目标值）。\n\n你的任务是实现一个程序，为以下测试套件计算 $f(x_{T_w})$。所有角度量均以弧度为单位。所有输出均为实数（浮点数）。\n\n测试套件（每个案例列出策略族、预热长度 $T_w$、预算 $A$、曲率 $\\lambda$、初始值 $x_0$ 以及任何额外的策略参数）：\n\n1. 线性预热，参数为 $T_w = 10$，$A = 3.0$，$\\lambda = 0.1$，$x_0 = 1.0$。\n2. 余弦预热，参数为 $T_w = 1$，$A = 0.5$，$\\lambda = 0.5$，$x_0 = 1.0$。\n3. 指数预热，参数为 $T_w = 100$，$A = 20.0$，$\\lambda = 0.05$，$x_0 = 1.0$，指数率 $\\alpha = 0.07$。\n\n计算中使用的策略定义：\n- 线性：$\\eta_k = \\eta_0 \\frac{k}{T_w}$，其中 $k = 1, \\dots, T_w$。\n- 余弦：$\\eta_k = \\frac{\\eta_0}{2}\\left(1 - \\cos\\left(\\frac{\\pi k}{T_w}\\right)\\right)$，其中 $k = 1, \\dots, T_w$，角度以弧度为单位。\n- 指数（归一化以在 $T_w$ 步达到 $\\eta_0$）：$\\eta_k = \\eta_0 \\frac{1 - e^{-\\alpha k}}{1 - e^{-\\alpha T_w}}$，其中 $k = 1, \\dots, T_w$。\n\n所有情况下需强制执行的约束：$\\sum_{k=1}^{T_w} \\eta_k = A$。\n\n每个案例的计算目标：\n- 计算 $x_{T_w} = x_0 \\prod_{k=1}^{T_w} \\left(1 - \\lambda \\eta_k\\right)$。\n- 计算 $f(x_{T_w}) = \\frac{1}{2}\\lambda x_{T_w}^2$。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[result1,result2,result3]$）。列表中的条目必须是按上述顺序列出的测试套件的 $f(x_{T_w})$ 值，每个值都表示为浮点数。",
            "solution": "该问题被评估为有效。它在科学上基于数值优化的原理，对于每个测试用例都是适定的且具有唯一解，并使用客观和精确的数学语言进行表述。尽管梯度下降步骤的索引存在一个微小的歧义（通用规则使用 $k=0, \\dots, T_w-1$ 而具体策略定义使用 $k=1, \\dots, T_w$），但这通过计算目标 $x_{T_w} = x_0 \\prod_{k=1}^{T_w} \\left(1 - \\lambda \\eta_k\\right)$ 的明确表述，以及在所有策略定义和约束中对 $k=1, \\dots, T_w$ 索引的一致使用而得到了明确的解决。解决方案将严格遵守这个明确的表述。\n\n任务是计算在使用学习率预热策略应用 $T_w$ 步梯度下降后，最终的目标函数值 $f(x_{T_w})$。目标函数是 $f(x) = \\frac{1}{2}\\lambda x^2$。梯度是 $\\nabla f(x) = \\lambda x$。\n\n梯度下降一步后的状态更新规则是 $x_{k+1} = x_k - \\eta_k \\nabla f(x_k) = x_k - \\eta_k (\\lambda x_k) = (1 - \\lambda \\eta_k) x_k$。根据问题的明确定义，我们使用一个学习率序列 $\\{\\eta_k\\}_{k=1}^{T_w}$。从初始值 $x_0$ 开始应用此更新规则 $T_w$ 步，得到最终状态 $x_{T_w}$：\n$$\nx_{T_w} = x_0 \\prod_{k=1}^{T_w} (1 - \\lambda \\eta_k)\n$$\n在这个最终状态下，目标函数的值为：\n$$\nf(x_{T_w}) = \\frac{1}{2} \\lambda x_{T_w}^2 = \\frac{1}{2} \\lambda \\left( x_0 \\prod_{k=1}^{T_w} (1 - \\lambda \\eta_k) \\right)^2\n$$\n\n一个关键步骤是为每个案例确定完整的学习率策略 $\\{\\eta_k\\}_{k=1}^{T_w}$。这些策略是根据基础学习率 $\\eta_0$ 定义的，$\\eta_0$ 是第 $T_w$ 步的最终学习率。$\\eta_0$ 的值由“预热预算”约束确定：\n$$\n\\sum_{k=1}^{T_w} \\eta_k = A\n$$\n其中 $A$ 是一个给定的常数。对于每个策略族，$\\eta_k$ 是 $\\eta_0$ 的函数。让我们写成 $\\eta_k = \\eta_0 \\cdot g_k$，其中 $g_k$ 是策略的形状。约束变为：\n$$\n\\sum_{k=1}^{T_w} \\eta_0 g_k = \\eta_0 \\sum_{k=1}^{T_w} g_k = A\n$$\n令 $S = \\sum_{k=1}^{T_w} g_k$。那么 $\\eta_0 = A/S$。我们现在为每个策略族推导和因子 $S$ 的表达式。\n\n线性预热：\n策略定义为 $\\eta_k = \\eta_0 \\frac{k}{T_w}$，其中 $k=1, \\dots, T_w$。形状函数是 $g_k = k/T_w$。\n和因子 $S_{lin}$ 是：\n$$\nS_{lin} = \\sum_{k=1}^{T_w} \\frac{k}{T_w} = \\frac{1}{T_w} \\sum_{k=1}^{T_w} k = \\frac{1}{T_w} \\frac{T_w(T_w+1)}{2} = \\frac{T_w+1}{2}\n$$\n\n余弦预热：\n策略是 $\\eta_k = \\frac{\\eta_0}{2}\\left(1 - \\cos\\left(\\frac{\\pi k}{T_w}\\right)\\right)$，其中 $k=1, \\dots, T_w$。形状函数是 $g_k = \\frac{1}{2}\\left(1 - \\cos\\left(\\frac{\\pi k}{T_w}\\right)\\right)$。\n和因子 $S_{cos}$ 是：\n$$\nS_{cos} = \\sum_{k=1}^{T_w} \\frac{1}{2}\\left(1 - \\cos\\left(\\frac{\\pi k}{T_w}\\right)\\right) = \\frac{1}{2} \\left( \\sum_{k=1}^{T_w} 1 - \\sum_{k=1}^{T_w} \\cos\\left(\\frac{\\pi k}{T_w}\\right) \\right) = \\frac{1}{2} \\left( T_w - \\sum_{k=1}^{T_w} \\cos\\left(\\frac{\\pi k}{T_w}\\right) \\right)\n$$\n使用恒等式 $\\sum_{k=1}^{N} \\cos(k\\theta) = -1$（其中 $\\theta=\\pi/N$ 且 $N \\ge 1$ 为整数），我们有 $\\sum_{k=1}^{T_w} \\cos\\left(\\frac{\\pi k}{T_w}\\right) = -1$。\n因此，和因子是：\n$$\nS_{cos} = \\frac{1}{2} (T_w - (-1)) = \\frac{T_w+1}{2}\n$$\n有趣的是，这与线性策略的和因子相同。\n\n指数预热：\n策略是 $\\eta_k = \\eta_0 \\frac{1 - e^{-\\alpha k}}{1 - e^{-\\alpha T_w}}$，其中 $k=1, \\dots, T_w$。形状函数是 $g_k = \\frac{1 - e^{-\\alpha k}}{1 - e^{-\\alpha T_w}}$。\n和因子 $S_{exp}$ 是：\n$$\nS_{exp} = \\sum_{k=1}^{T_w} \\frac{1 - e^{-\\alpha k}}{1 - e^{-\\alpha T_w}} = \\frac{1}{1 - e^{-\\alpha T_w}} \\sum_{k=1}^{T_w} (1 - e^{-\\alpha k}) = \\frac{1}{1 - e^{-\\alpha T_w}} \\left( T_w - \\sum_{k=1}^{T_w} (e^{-\\alpha})^k \\right)\n$$\n第二个和是几何级数。令 $r=e^{-\\alpha}$。该和为 $\\sum_{k=1}^{T_w} r^k = r \\frac{1-r^{T_w}}{1-r}$。代回得：\n$$\nS_{exp} = \\frac{1}{1 - e^{-\\alpha T_w}} \\left( T_w - e^{-\\alpha} \\frac{1 - e^{-\\alpha T_w}}{1 - e^{-\\alpha}} \\right)\n$$\n\n每个测试用例的整体算法如下：\n1.  识别策略类型及其参数（$T_w, A, \\lambda, x_0, \\alpha$）。\n2.  计算相应的和因子 $S$。\n3.  计算基础学习率 $\\eta_0 = A/S$。\n4.  使用给定策略族的公式生成完整的学习率策略 $\\{\\eta_k\\}_{k=1}^{T_w}$。\n5.  计算最终状态 $x_{T_w} = x_0 \\prod_{k=1}^{T_w} (1 - \\lambda \\eta_k)$。\n6.  计算最终目标值 $f(x_{T_w}) = \\frac{1}{2} \\lambda x_{T_w}^2$。\n\n对问题陈述中指定的每个测试用例实施此过程。\n\n例如，对于测试用例 2（余弦预热，$T_w=1, A=0.5, \\lambda=0.5, x_0=1.0$）：\n1.  $S_{cos} = \\frac{1+1}{2} = 1$。\n2.  $\\eta_0 = A/S_{cos} = 0.5/1 = 0.5$。\n3.  该策略只有一个步骤，$k=1$。$\\eta_1 = \\frac{\\eta_0}{2}(1-\\cos(\\pi \\cdot 1/1)) = \\frac{0.5}{2}(1 - (-1)) = 0.5$。\n4.  $x_1 = x_0(1-\\lambda \\eta_1) = 1.0(1 - 0.5 \\cdot 0.5) = 0.75$。\n5.  $f(x_1) = \\frac{1}{2}\\lambda x_1^2 = \\frac{1}{2}(0.5)(0.75)^2 = 0.25 \\cdot 0.5625 = 0.140625$。\n\n其他案例需要数值计算，这由所提供的程序执行。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_linear(Tw, A, lmbda, x0):\n    \"\"\"\n    Computes f(x_Tw) for a linear warmup schedule.\n    \"\"\"\n    # Sum factor S_lin = (Tw + 1) / 2\n    S_lin = (Tw + 1.0) / 2.0\n    \n    # Base learning rate eta0\n    eta0 = A / S_lin\n    \n    # Learning rate schedule eta_k = eta0 * k / Tw\n    ks = np.arange(1, Tw + 1)\n    etas = eta0 * ks / Tw\n    \n    # Compute the product term for x_Tw\n    product_term = np.prod(1.0 - lmbda * etas)\n    \n    # Compute x_Tw\n    x_Tw = x0 * product_term\n    \n    # Compute f(x_Tw)\n    f_x_Tw = 0.5 * lmbda * x_Tw**2\n    \n    return f_x_Tw\n\ndef calculate_cosine(Tw, A, lmbda, x0):\n    \"\"\"\n    Computes f(x_Tw) for a cosine warmup schedule.\n    \"\"\"\n    # Sum factor S_cos = (Tw + 1) / 2\n    S_cos = (Tw + 1.0) / 2.0\n        \n    # Base learning rate eta0\n    eta0 = A / S_cos\n    \n    # Learning rate schedule eta_k = (eta0 / 2) * (1 - cos(pi*k/Tw))\n    ks = np.arange(1, Tw + 1)\n    etas = (eta0 / 2.0) * (1.0 - np.cos(np.pi * ks / Tw))\n    \n    # Compute the product term for x_Tw\n    product_term = np.prod(1.0 - lmbda * etas)\n    \n    # Compute x_Tw\n    x_Tw = x0 * product_term\n    \n    # Compute f(x_Tw)\n    f_x_Tw = 0.5 * lmbda * x_Tw**2\n    \n    return f_x_Tw\n\ndef calculate_exponential(Tw, A, lmbda, x0, alpha):\n    \"\"\"\n    Computes f(x_Tw) for an exponential warmup schedule.\n    \"\"\"\n    # Sum factor S_exp\n    exp_a = np.exp(-alpha)\n    exp_aTw = np.exp(-alpha * Tw)\n    \n    # Sum of geometric series part\n    # sum_{k=1}^{Tw} (e^{-alpha})^k\n    # This must handle the case where the ratio is 1 (alpha=0), but alpha > 0 is a premise.\n    sum_geom_series = exp_a * (1.0 - exp_aTw) / (1.0 - exp_a)\n    \n    # S_exp = (1 / (1-exp(-a*Tw))) * (Tw - sum_geom_series)\n    sum_term_in_S = Tw - sum_geom_series\n    S_exp = sum_term_in_S / (1.0 - exp_aTw)\n    \n    # Base learning rate eta0\n    eta0 = A / S_exp\n    \n    # Learning rate schedule eta_k = eta0 * (1 - exp(-alpha*k)) / (1 - exp(-alpha*Tw))\n    ks = np.arange(1, Tw + 1)\n    numerator = 1.0 - np.exp(-alpha * ks)\n    denominator = 1.0 - exp_aTw\n    etas = eta0 * numerator / denominator\n    \n    # Compute the product term for x_Tw\n    product_term = np.prod(1.0 - lmbda * etas)\n    \n    # Compute x_Tw\n    x_Tw = x0 * product_term\n    \n    # Compute f(x_Tw)\n    f_x_Tw = 0.5 * lmbda * x_Tw**2\n    \n    return f_x_Tw\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'type': 'linear', 'Tw': 10, 'A': 3.0, 'lambda': 0.1, 'x0': 1.0},\n        {'type': 'cosine', 'Tw': 1, 'A': 0.5, 'lambda': 0.5, 'x0': 1.0},\n        {'type': 'exponential', 'Tw': 100, 'A': 20.0, 'lambda': 0.05, 'x0': 1.0, 'alpha': 0.07}\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'linear':\n            result = calculate_linear(case['Tw'], case['A'], case['lambda'], case['x0'])\n        elif case['type'] == 'cosine':\n            result = calculate_cosine(case['Tw'], case['A'], case['lambda'], case['x0'])\n        elif case['type'] == 'exponential':\n            result = calculate_exponential(case['Tw'], case['A'], case['lambda'], case['x0'], case['alpha'])\n        else:\n            raise ValueError(f\"Unknown schedule type: {case['type']}\")\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "固定长度和形状的预热策略虽然简单，但在复杂的训练任务中可能并非最优。作为本章的最后一项实践，我们将探索一种更高级的自适应预热方法。这项练习将指导你构建一个能够“感知”训练动态的智能预热调度器，它只有在梯度范数 $\\lVert g_t \\rVert_2$ 显示出训练趋于稳定时才提升学习率。这种数据驱动的方法可以使预热过程更加稳健和高效。",
            "id": "3143236",
            "problem": "您将获得一个非负实数序列，表示随机梯度下降（SGD）中损失函数在每次迭代时的梯度范数。设参数向量表示为 $\\theta_t \\in \\mathbb{R}^d$，损失为 $L(\\theta)$，梯度为 $g_t = \\nabla_{\\theta} L(\\theta_t)$，学习率为 $\\eta(t)$。核心 SGD 更新规则是基本的基础：$$\\theta_{t+1} = \\theta_t - \\eta(t)\\,g_t.$$ 目标是构建并应用一个自适应预热方案，该方案仅在当前梯度范数 $\\lVert \\nabla L(\\theta_t) \\rVert_2$ 低于其近期历史记录的指定经验百分位数时才增加 $\\eta(t)$。该自适应预热方案必须遵循以下原则和定义：\n\n1. 初始化和单调性约束：从一个最小学习率 $\\eta_{\\min}$ 开始，并允许 $\\eta(t)$ 随时间非递减，其上限为目标学习率 $\\eta_{\\text{target}}$。\n2. 百分位数阈值法：在迭代 $t \\ge 2$ 时，定义大小为 $n_t = \\min(W, t-1)$ 的历史窗口 $H_t = \\left\\{ \\lVert g_j \\rVert_2 \\mid j \\in \\{\\max(1, t-W), \\dots, t-1\\} \\right\\}$。对于一个选定的百分位数 $p \\in [0,100]$，通过对排序后的历史记录进行线性插值来定义经验百分位数阈值 $q_p(H_t)$。如果 $H_t$ 升序排序后为 $x_{(1)} \\le x_{(2)} \\le \\dots \\le x_{(n_t)}$，则设置 $$\\text{pos} = \\frac{p}{100}\\,(n_t - 1), \\quad \\ell = \\lfloor \\text{pos} \\rfloor, \\quad u = \\lceil \\text{pos} \\rceil,$$ 且 $$q_p(H_t) = \n\\begin{cases}\nx_{(\\ell+1)}  \\text{if } \\ell = u, \\\\\nx_{(\\ell+1)} + (x_{(u+1)} - x_{(\\ell+1)})\\,(\\text{pos} - \\ell)  \\text{if } \\ell  u.\n\\end{cases}$$\n对于 $n_t = 1$，将 $q_p(H_t)$ 解释为 $x_{(1)}$。\n3. 自适应预热规则：对于 $t = 1$，设置 $\\eta(1) = \\eta_{\\min}$。对于 $t \\ge 2$，计算当前梯度范数 $g_t^{\\text{norm}} = \\lVert g_t \\rVert_2$ 和阈值 $q_p(H_t)$。仅当 $g_t^{\\text{norm}}  q_p(H_t)$ 时，将学习率乘以一个因子 $(1+\\alpha)$ 来增加，但绝不能超过 $\\eta_{\\text{target}}$。形式上，\n$$\\eta(t) = \n\\begin{cases}\n\\min\\left(\\eta(t-1)\\,(1+\\alpha),\\,\\eta_{\\text{target}}\\right)  \\text{if } g_t^{\\text{norm}}  q_p(H_t), \\\\\n\\eta(t-1)  \\text{otherwise.}\n\\end{cases}$$\n一旦 $\\eta(t)$ 达到 $\\eta_{\\text{target}}$，它此后将一直保持在 $\\eta_{\\text{target}}$。\n\n您的任务是实现一个程序，该程序为每个测试用例将其梯度范数序列应用上述自适应预热方案，并返回两个输出：最后一次迭代后的最终学习率值 $\\eta(T)$，以及执行的实际增加总次数（即满足 $\\eta(t)  \\eta(t-1)$ 的迭代次数 $t$）。\n\n所有量都是无量纲的，并表示为实数。不涉及物理单位。百分位数必须以 $[0,100]$ 区间内的数字形式提供，且不得使用百分号。\n\n测试套件：\n- 用例 1（普遍递减的梯度范数）：\n  - 梯度范数：$[5.0,\\,4.5,\\,4.0,\\,3.5,\\,3.0,\\,2.6,\\,2.3,\\,2.1,\\,1.9,\\,1.8]$\n  - 窗口大小：$W=3$\n  - 百分位数：$p=40.0$\n  - 乘性增加参数：$\\alpha=0.5$\n  - 最小学习率：$\\eta_{\\min}=0.001$\n  - 目标学习率：$\\eta_{\\text{target}}=0.01$\n- 用例 2（测试相等边界的近似恒定范数）：\n  - 梯度范数：$[3.0,\\,3.0,\\,3.0,\\,3.0,\\,3.0,\\,3.0,\\,3.0,\\,3.0]$\n  - 窗口大小：$W=4$\n  - 百分位数：$p=50.0$\n  - 乘性增加参数：$\\alpha=0.5$\n  - 最小学习率：$\\eta_{\\min}=0.001$\n  - 目标学习率：$\\eta_{\\text{target}}=0.005$\n- 用例 3（测试短窗口和平局的零值和小值）：\n  - 梯度范数：$[1.0,\\,0.0,\\,0.0,\\,0.05,\\,0.0,\\,0.0]$\n  - 窗口大小：$W=2$\n  - 百分位数：$p=50.0$\n  - 乘性增加参数：$\\alpha=0.8$\n  - 最小学习率：$\\eta_{\\min}=0.0001$\n  - 目标学习率：$\\eta_{\\text{target}}=0.002$\n- 用例 4（测试较大窗口和触及上限的振荡范数）：\n  - 梯度范数：$[5.0,\\,10.0,\\,6.0,\\,4.0,\\,9.0,\\,3.0,\\,8.0,\\,2.0,\\,7.0,\\,1.0]$\n  - 窗口大小：$W=5$\n  - 百分位数：$p=60.0$\n  - 乘性增加参数：$\\alpha=0.5$\n  - 最小学习率：$\\eta_{\\min}=0.0005$\n  - 目标学习率：$\\eta_{\\text{target}}=0.002$\n\n输出规范：\n- 对于每个测试用例，生成一个列表 $[\\eta(T),\\,\\text{count}]$，其中 $\\eta(T)$ 是最后一次迭代后的最终学习率，$\\text{count}$ 是在此过程中实际增加的总次数。\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，格式为方括号括起来的逗号分隔列表，形式为 $[[\\eta_1(T),\\text{count}_1],[\\eta_2(T),\\text{count}_2],[\\eta_3(T),\\text{count}_3],[\\eta_4(T),\\text{count}_4]]$，不含任何附加文本。",
            "solution": "问题陈述是有效的。它在深度学习优化这一成熟领域有科学依据，特别是关于学习率调度。该问题提法明确，为确定性算法提供了一套完整且无歧义的规则和参数。所有术语都定义清晰，测试套件中提供的数据对于计算模拟来说是一致且切合实际的。\n\n任务是为给定的梯度范数序列实现一个自适应学习率预热方案。该方案根据一组预定义规则确定每次迭代 $t$ 的学习率 $\\eta(t)$。每个测试用例的主要输出包括最后一次迭代 $T$ 后的最终学习率 $\\eta(T)$，以及学习率增加的总次数。\n\n算法流程如下：\n\n1.  **状态变量与初始化**：核心状态变量是学习率 $\\eta(t)$ 和一个用于记录增加次数的计数器。在初始迭代 $t=1$ 时，学习率被设置为指定的最小值 $\\eta(1) = \\eta_{\\min}$，增加计数器初始化为 $0$。\n\n2.  **迭代更新**：对于从 $2$ 到 $T$ 的每次后续迭代 $t$（其中 $T$ 是总迭代次数，即梯度范数序列的长度），学习率 $\\eta(t)$ 是根据 $\\eta(t-1)$、当前梯度范数 $\\lVert g_t \\rVert_2$ 以及从近期历史记录中计算出的基于百分位数的阈值来确定的。\n\n3.  **历史记录与阈值计算**：在给定的迭代 $t \\ge 2$ 时，定义一个历史窗口 $H_t$，它是最近 $n_t = \\min(W, t-1)$ 个梯度范数的集合，其中 $W$ 是最大窗口大小。形式上，$H_t = \\{ \\lVert g_j \\rVert_2 \\mid j \\in \\{\\max(1, t-W), \\dots, t-1\\} \\}$。然后，计算一个阈值 $q_p(H_t)$，作为 $H_t$ 中值的第 $p$ 个经验百分位数。问题为此计算指定了线性插值方法：\n    设 $H_t$ 中排序后的值为 $x_{(1)} \\le x_{(2)} \\le \\dots \\le x_{(n_t)}$。百分位数的位置计算为 $\\text{pos} = \\frac{p}{100}(n_t - 1)$。设 $\\ell = \\lfloor \\text{pos} \\rfloor$ 和 $u = \\lceil \\text{pos} \\rceil$，则阈值为：\n    $$q_p(H_t) = \n    \\begin{cases}\n    x_{(\\ell+1)}  \\text{if } \\ell = u \\\\\n    x_{(\\ell+1)} + (x_{(u+1)} - x_{(\\ell+1)})\\,(\\text{pos} - \\ell)  \\text{if } \\ell  u\n    \\end{cases}$$\n    对于历史记录只包含一个值的特殊情况（$n_t=1$），阈值就是该值本身，$q_p(H_t) = x_{(1)}$。此计算等同于 `numpy` 等数值库中的标准百分位数计算。\n\n4.  **学习率更新规则**：自适应方案的核心是 $\\eta(t)$ 的更新规则：\n    $$\\eta(t) = \n    \\begin{cases}\n    \\min\\left(\\eta(t-1)\\cdot(1+\\alpha), \\eta_{\\text{target}}\\right)  \\text{if } \\lVert g_t \\rVert_2  q_p(H_t) \\\\\n    \\eta(t-1)  \\text{otherwise}\n    \\end{cases}$$\n    此处，$\\alpha$ 是乘性增加因子，$\\eta_{\\text{target}}$ 是最大允许学习率。仅当当前梯度范数严格小于历史百分位数阈值时，才会执行增加操作。如果一次更新导致 $\\eta(t)  \\eta(t-1)$，则增加计数器加一。\n\n5.  **饱和**：一个关键约束是学习率非递减且上限为 $\\eta_{\\text{target}}$。一旦学习率达到 $\\eta_{\\text{target}}$，它将在所有后续迭代中保持该值，并且更新逻辑实际上被绕过。\n\n实现将为每个测试用例的整个梯度范数序列逐步模拟此过程。然后收集最终的学习率值和总增加次数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the adaptive learning rate warmup problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1 (general decreasing gradient norms):\n        {\n            \"grad_norms\": [5.0, 4.5, 4.0, 3.5, 3.0, 2.6, 2.3, 2.1, 1.9, 1.8],\n            \"W\": 3,\n            \"p\": 40.0,\n            \"alpha\": 0.5,\n            \"eta_min\": 0.001,\n            \"eta_target\": 0.01\n        },\n        # Case 2 (near-constant norms testing equality boundary):\n        {\n            \"grad_norms\": [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0],\n            \"W\": 4,\n            \"p\": 50.0,\n            \"alpha\": 0.5,\n            \"eta_min\": 0.001,\n            \"eta_target\": 0.005\n        },\n        # Case 3 (zeros and small values testing short windows and ties):\n        {\n            \"grad_norms\": [1.0, 0.0, 0.0, 0.05, 0.0, 0.0],\n            \"W\": 2,\n            \"p\": 50.0,\n            \"alpha\": 0.8,\n            \"eta_min\": 0.0001,\n            \"eta_target\": 0.002\n        },\n        # Case 4 (oscillatory norms testing larger window and hitting the cap):\n        {\n            \"grad_norms\": [5.0, 10.0, 6.0, 4.0, 9.0, 3.0, 8.0, 2.0, 7.0, 1.0],\n            \"W\": 5,\n            \"p\": 60.0,\n            \"alpha\": 0.5,\n            \"eta_min\": 0.0005,\n            \"eta_target\": 0.002\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_schedule(case)\n        results.append(result)\n\n    # Format the output as specified: [[eta1,count1],[eta2,count2],...]\n    inner_strings = [f'[{r[0]},{r[1]}]' for r in results]\n    output_string = f\"[{','.join(inner_strings)}]\"\n    print(output_string)\n\ndef run_schedule(params):\n    \"\"\"\n    Applies the adaptive warmup schedule for a single test case.\n\n    Args:\n        params (dict): A dictionary containing all parameters for the case.\n\n    Returns:\n        list: A list containing the final learning rate and the total increase count.\n    \"\"\"\n    grad_norms = params[\"grad_norms\"]\n    W = params[\"W\"]\n    p = params[\"p\"]\n    alpha = params[\"alpha\"]\n    eta_min = params[\"eta_min\"]\n    eta_target = params[\"eta_target\"]\n\n    current_eta = eta_min\n    increase_count = 0\n    T = len(grad_norms)\n\n    # Iterations are 1-based in the problem, t = 1, ..., T.\n    # Python indices are 0-based, i = 0, ..., T-1.\n    # The loop for updates starts at t=2, so index i=1.\n    for i in range(1, T):\n        # If LR has reached target, it stays there.\n        if current_eta == eta_target:\n            continue\n\n        # Current gradient norm (at time t = i + 1)\n        current_g_norm = grad_norms[i]\n\n        # History window H_t for t = i + 1\n        # History consists of norms from j=max(1, t-W) to t-1.\n        # In 0-based indices, this is a slice from max(0, i-W) to i-1.\n        history_start_idx = max(0, i - W)\n        history = grad_norms[history_start_idx:i]\n\n        # Calculate percentile threshold q_p(H_t)\n        # The problem defines linear interpolation, which is the default for\n        # np.percentile in the specified version.\n        # It also handles the n=1 case correctly.\n        if not history:\n            # This case occurs only if i=0, but loop starts at i=1.\n            # As a safeguard, use a threshold that prevents updates.\n            q_p_threshold = float('inf')\n        else:\n            q_p_threshold = np.percentile(history, p, interpolation='linear')\n        \n        # Apply the adaptive warmup rule\n        if current_g_norm  q_p_threshold:\n            prev_eta = current_eta\n            current_eta = min(current_eta * (1 + alpha), eta_target)\n            if current_eta  prev_eta:\n                increase_count += 1\n    \n    return [current_eta, increase_count]\n\nsolve()\n```"
        }
    ]
}