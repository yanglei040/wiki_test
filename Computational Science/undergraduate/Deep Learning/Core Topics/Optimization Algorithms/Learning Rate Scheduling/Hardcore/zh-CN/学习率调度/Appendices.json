{
    "hands_on_practices": [
        {
            "introduction": "在标准的随机梯度下降（SGD）实现中，学习率 $\\eta_t$ 和权重衰减 $\\lambda$ 的效果是耦合在一起的，这使得对优化过程的直观理解变得复杂。本练习将引导你从第一性原理出发，将权重衰减视为一个隐式的近端步骤，从而推导出“有效步长”的概念。通过设计一个直接控制此有效步长的学习率策略，你将能更深刻地理解正则化与学习率之间的相互作用，并掌握更精细的优化调节技巧。",
            "id": "3142924",
            "problem": "要求您为带权重衰减正则化的随机梯度下降 (SGD) 设计并实现一个学习率调度函数。从离散时间优化的一个基于原理的模型出发：将权重衰减视为对平方范数惩罚项的一个隐式近端步骤。基本目标函数为 $J(\\mathbf{w}) = L(\\mathbf{w}) + \\frac{\\lambda}{2}\\lVert \\mathbf{w} \\rVert_2^2$，其中 $L(\\mathbf{w})$ 是数据拟合项，$\\mathbf{w} \\in \\mathbb{R}^d$ 是参数，$\\lambda \\ge 0$ 是权重衰减系数。考虑在第 $t$ 次迭代时，学习率为 $\\eta_t$ 的隐式近端更新：\n$$\n\\mathbf{w}_{t+1} \\in \\arg\\min_{\\mathbf{w}} \\left\\{ \\frac{1}{2}\\left\\lVert \\mathbf{w} - \\left(\\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)\\right)\\right\\rVert_2^2 + \\frac{\\eta_t \\lambda}{2} \\lVert \\mathbf{w} \\rVert_2^2 \\right\\}.\n$$\n将在第 $t$ 次迭代的最终更新规则中，乘以负梯度方向的标量定义为权重空间中的有效步长。您的设计目标是，在一个早期的预热窗口（迭代次数 $t \\in \\{0,1,\\dots,T_{\\mathrm{warm}}-1\\}$）内，保持此有效步长等于一个目标常量 $s_{\\mathrm{target}}$，然后使用单调指数衰减，在训练结束时（$t = T_{\\mathrm{total}}-1$）将其平滑地减小到一个更小的值 $s_{\\min}$，并确保在最后一次迭代时精确达到 $s_{\\min}$。您的调度方案必须遵守正性和稳定性约束：学习率必须满足 $0  \\eta_t \\le \\eta_{\\max}$，其中 $\\eta_{\\max} = \\frac{2}{L_g}$，而 $L_g  0$ 是为 $L(\\mathbf{w})$ 的梯度提供的一个Lipschitz常数上界。如果为了保持有效步长等于 $s_{\\mathrm{target}}$（或其指数衰减的延续值）而计算出的无约束值违反了 $0  \\eta_t \\le \\eta_{\\max}$，则将其替换为 $\\eta_{\\max}$。\n\n任务：\n1. 仅从隐式近端更新的定义以及有效步长是最终更新规则中 $-\\nabla L(\\mathbf{w}_t)$ 的系数这一概念出发，推导出第 $t$ 次迭代时有效步长的表达式，并通过逆运算求得 $\\eta_t$ 作为第 $t$ 次迭代时期望有效步长和 $\\lambda$ 的函数。\n2. 指定一个分段的有效步长调度 $s(t)$，使其在 $t \\in \\{0,1,\\dots,T_{\\mathrm{warm}}-1\\}$ 时等于 $s_{\\mathrm{target}}$，并在 $t = T_{\\mathrm{total}}-1$ 时指数衰减至 $s_{\\min}$。确定指数衰减常数，以精确满足端点条件。\n3. 结合以上结果，生成在所有 $t$ 下都满足约束 $0  \\eta_t \\le \\eta_{\\max}$ 的学习率调度 $\\eta_t$。\n4. 实现一个独立的程序，为以下四个测试用例计算并返回在指定评估迭代次数下的学习率值。如果 $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1 \\le 0$，在定义指数调度时，将衰减区间长度视为 1。\n\n测试套件（每个案例指定 $(T_{\\mathrm{total}}, T_{\\mathrm{warm}}, s_{\\mathrm{target}}, s_{\\min}, \\lambda, L_g, \\text{eval times})$）：\n- 案例 A: $(100, 40, 0.01, 0.002, 0.1, 50, [0, 20, 40, 60, 99])$。\n- 案例 B: $(60, 20, 0.02, 0.005, 0, 100, [0, 19, 20, 59])$。\n- 案例 C: $(80, 30, 0.01, 0.003, 80, 50, [0, 29, 30, 79])$。\n- 案例 D: $(50, 0, 0.05, 0.01, 0.5, 200, [0, 25, 49])$。\n\n最终输出规范：\n- 您的程序应生成单行输出，其中包含一个以逗号分隔的列表的列表，并用方括号括起来（例如，$[\\text{[案例A的列表]},\\text{[案例B的列表]},\\text{[案例C的列表]},\\text{[案例D的列表]}]$）。\n- 每个内部列表必须包含该案例在指定评估时间点的学习率值 $\\eta_t$，顺序与提供的一致。\n- 所有返回值必须是实数（浮点数）。不使用物理单位；不使用角度；任何地方都不要使用百分比。",
            "solution": "用户提供的问题陈述是有效的。它在科学上基于优化理论，特别是近端梯度方法，并与深度学习中的学习率调度直接相关。该问题定义明确，提供了推导唯一解所需的所有必要参数、定义和约束。语言客观而精确。\n\n### 步骤1：更新规则和有效步长的推导\n\n问题始于第 $t$ 次迭代时权重向量 $\\mathbf{w}$ 的隐式近端更新规则：\n$$\n\\mathbf{w}_{t+1} \\in \\arg\\min_{\\mathbf{w}} \\left\\{ F(\\mathbf{w}) = \\frac{1}{2}\\left\\lVert \\mathbf{w} - \\left(\\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)\\right)\\right\\rVert_2^2 + \\frac{\\eta_t \\lambda}{2} \\lVert \\mathbf{w} \\rVert_2^2 \\right\\}\n$$\n其中 $L(\\mathbf{w})$ 是数据拟合损失，$\\eta_t$ 是学习率，$\\lambda$ 是权重衰减系数。目标函数 $F(\\mathbf{w})$ 是关于 $\\mathbf{w}$ 的严格凸二次函数，因此可以通过将其关于 $\\mathbf{w}$ 的梯度设为零来找到其最小值。\n\n令 $\\mathbf{c}_t = \\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)$。目标函数为：\n$$\nF(\\mathbf{w}) = \\frac{1}{2} (\\mathbf{w} - \\mathbf{c}_t)^T (\\mathbf{w} - \\mathbf{c}_t) + \\frac{\\eta_t \\lambda}{2} \\mathbf{w}^T \\mathbf{w}\n$$\n梯度 $\\nabla_{\\mathbf{w}} F(\\mathbf{w})$ 为：\n$$\n\\nabla_{\\mathbf{w}} F(\\mathbf{w}) = (\\mathbf{w} - \\mathbf{c}_t) + \\eta_t \\lambda \\mathbf{w}\n$$\n将 $\\mathbf{w} = \\mathbf{w}_{t+1}$ 处的梯度设为零：\n$$\n(\\mathbf{w}_{t+1} - \\mathbf{c}_t) + \\eta_t \\lambda \\mathbf{w}_{t+1} = \\mathbf{0}\n$$\n$$\n\\mathbf{w}_{t+1}(1 + \\eta_t \\lambda) = \\mathbf{c}_t\n$$\n$$\n\\mathbf{w}_{t+1} = \\frac{1}{1 + \\eta_t \\lambda} \\mathbf{c}_t\n$$\n代回 $\\mathbf{c}_t$ 的定义：\n$$\n\\mathbf{w}_{t+1} = \\frac{1}{1 + \\eta_t \\lambda} \\left(\\mathbf{w}_t - \\eta_t \\nabla L(\\mathbf{w}_t)\\right)\n$$\n$$\n\\mathbf{w}_{t+1} = \\frac{1}{1 + \\eta_t \\lambda} \\mathbf{w}_t - \\frac{\\eta_t}{1 + \\eta_t \\lambda} \\nabla L(\\mathbf{w}_t)\n$$\n此方程表示带权重衰减的标准随机梯度下降（SGD）更新，其中权重衰减项 $\\frac{1}{1 + \\eta_t \\lambda}$ 与学习率是耦合的。\n\n问题将“有效步长”$s_t$ 定义为乘以负梯度方向 $-\\nabla L(\\mathbf{w}_t)$ 的标量。从推导出的更新规则中，我们可以确定 $s_t$：\n$$\ns_t = \\frac{\\eta_t}{1 + \\eta_t \\lambda}\n$$\n为了控制调度，我们需要将学习率 $\\eta_t$ 表示为期望有效步长 $s_t$ 的函数。我们对上述关系进行逆运算：\n$$\ns_t (1 + \\eta_t \\lambda) = \\eta_t\n$$\n$$\ns_t + s_t \\eta_t \\lambda = \\eta_t\n$$\n$$\ns_t = \\eta_t (1 - s_t \\lambda)\n$$\n$$\n\\eta_t = \\frac{s_t}{1 - s_t \\lambda}\n$$\n为了使 $\\eta_t$ 为正且有良好定义，必须有 $s_t  0$ 和 $1 - s_t \\lambda  0$，这意味着 $s_t \\lambda  1$。\n\n### 步骤2：有效步长调度 $s(t)$ 的设计\n\n有效步长调度 $s(t)$ 是分段的。\n1.  **预热阶段：** 对于迭代 $t \\in \\{0, 1, \\dots, T_{\\mathrm{warn}}-1\\}$，有效步长是恒定的。\n    $$\n    s(t) = s_{\\mathrm{target}} \\quad \\text{for } t  T_{\\mathrm{warm}}\n    $$\n2.  **衰减阶段：** 对于迭代 $t \\in \\{T_{\\mathrm{warm}}, T_{\\mathrm{warm}}+1, \\dots, T_{\\mathrm{total}}-1\\}$，有效步长经历一个“单调指数衰减”。这被建模为一个连接 $s(T_{\\mathrm{warm}}) = s_{\\mathrm{target}}$ 到 $s(T_{\\mathrm{total}}-1) = s_{\\min}$ 的几何级数。\n\n令衰减阶段定义在区间 $[T_{\\mathrm{warm}}, T_{\\mathrm{total}}-1]$ 上。我们需要一个函数 $s(t)$ 满足 $s(T_{\\mathrm{warm}}) = s_{\\mathrm{target}}$ 和 $s(T_{\\mathrm{total}}-1) = s_{\\min}$。一个满足这些边界条件的指数函数（几何级数）是：\n$$\ns(t) = s_{\\mathrm{target}} \\cdot \\left(\\frac{s_{\\min}}{s_{\\mathrm{target}}}\\right)^{\\frac{t - T_{\\mathrm{warm}}}{(T_{\\mathrm{total}}-1) - T_{\\mathrm{warm}}}}\n$$\n当分母 $D = (T_{\\mathrm{total}}-1) - T_{\\mathrm{warm}} = T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1$ 为正时，此式有效。\n\n我们必须处理边界情况：\n-   如果 $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1  0$：上述公式适用。\n-   如果 $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1 = 0$，即 $T_{\\mathrm{total}} = T_{\\mathrm{warm}} + 1$：衰减阶段只包含一个点，$t=T_{\\mathrm{warm}}$。由于 $t=T_{\\mathrm{warm}}$ 也是最后一次迭代 $T_{\\mathrm{total}}-1$，其值必须是 $s_{\\min}$。这在 $t=T_{\\mathrm{warm}}$ 处产生一个不连续点。因此，$s(T_{\\mathrm{warm}}) = s_{\\min}$。\n-   如果 $T_{\\mathrm{total}} - T_{\\mathrm{warm}} - 1  0$，即 $T_{\\mathrm{total}} \\le T_{\\mathrm{warm}}$：衰减阶段为空。所有迭代 $t \\in \\{0, \\dots, T_{\\mathrm{total}}-1\\}$ 都落在预热阶段内，因为 $t  T_{\\mathrm{total}} \\le T_{\\mathrm{warm}}$。因此，对于所有相关的 $t$，$s(t) = s_{\\mathrm{target}}$。\n\n### 步骤3：完整的学习率调度 $\\eta_t$\n\n最终的学习率调度 $\\eta_t$ 是通过结合以上元素并应用上界约束来构建的。对于任意给定的迭代 $t \\in \\{0, 1, \\dots, T_{\\mathrm{total}}-1\\}$：\n1.  使用步骤2中定义的分段调度确定有效步长 $s(t)$。\n2.  计算无约束的学习率 $\\eta_t^{\\text{unconstrained}} = \\frac{s(t)}{1 - s(t) \\lambda}$。\n3.  确定最大允许学习率 $\\eta_{\\max} = \\frac{2}{L_g}$。\n4.  最终的学习率是无约束值被 $\\eta_{\\max}$ 截断后的值：\n    $$\n    \\eta_t = \\min(\\eta_t^{\\text{unconstrained}}, \\eta_{\\max})\n    $$\n\n### 步骤4：实现\n\n下面的独立程序实现了推导出的学习率调度，并为提供的测试用例计算所需的值。其逻辑被封装在一个函数中，该函数为给定的 $t$ 和一组参数计算 $\\eta_t$，然后在测试套件中为每个指定的评估时间点调用该函数。最终输出被格式化为列表的列表。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It computes the learning rate at specified iterations for each case\n    and prints the results in the required format.\n    \"\"\"\n    test_cases = [\n        # (T_total, T_warm, s_target, s_min, lambda, L_g, eval_times)\n        (100, 40, 0.01, 0.002, 0.1, 50, [0, 20, 40, 60, 99]),\n        (60, 20, 0.02, 0.005, 0, 100, [0, 19, 20, 59]),\n        (80, 30, 0.01, 0.003, 80, 50, [0, 29, 30, 79]),\n        (50, 0, 0.05, 0.01, 0.5, 200, [0, 25, 49]),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        T_total, T_warm, s_target, s_min, lambd, L_g, eval_times = case\n        \n        eta_max = 2.0 / L_g\n        \n        # Pre-calculate constants for the decay phase\n        # The problem states to treat the length as 1 if = 0.\n        decay_duration_denominator = float(max(1.0, T_total - 1.0 - T_warm))\n        ratio = s_min / s_target\n\n        case_results = []\n        for t in eval_times:\n            # 1. Determine the effective step s(t)\n            s_t = 0.0\n            if t  T_warm:\n                s_t = s_target\n            else: # t = T_warm\n                # Special handling for T_total = T_warm + 1\n                if (T_total - 1.0 - T_warm) == 0:\n                    s_t = s_min\n                else:\n                    # Standard exponential decay\n                    exponent = (t - T_warm) / decay_duration_denominator\n                    s_t = s_target * (ratio ** exponent)\n\n            # 2. Calculate the unconstrained learning rate\n            # Denominator is 1 - s_t * lambda. This should be  0.\n            # It is guaranteed by problem constraints and schedule design (s(t) = s_target).\n            eta_unconstrained = s_t / (1.0 - s_t * lambd)\n\n            # 3. Apply the upper-bound constraint\n            eta_t = min(eta_unconstrained, eta_max)\n            case_results.append(eta_t)\n            \n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # We manually format the lists to avoid spaces.\n    inner_lists_str = []\n    for res_list in all_results:\n        # Use a high-precision format for floating point numbers\n        inner_lists_str.append(f\"[{','.join(f'{val:.17g}' for val in res_list)}]\")\n    \n    print(f\"[{','.join(inner_lists_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "理论研究中的损失函数通常是光滑的，但在深度学习实践中，损失景观（loss landscape）往往充满了尖锐的“拐点”，即非光滑区域。本练习构建了一个包含绝对值项的合成损失函数，以模拟这种非光滑特性。你的任务是实现并比较几种常见的学习率调度策略（如固定学习率、步进衰减和余弦退火）在穿越这些非光滑“拐点”时的行为，从而深入探索不同策略的稳定性及其对次梯度噪声的放大效应。",
            "id": "3142877",
            "problem": "要求您设计并分析随机梯度下降 (SGD) 动力学在不同学习率调度下，于一个分段光滑且带有非光滑扭结（kink）的合成经验风险上的表现。您的实现必须是一个完整的、可运行的程序。目标是量化不同的学习率序列 $\\{\\eta_t\\}_{t=0}^{T-1}$ 在迭代进入非光滑区域时的行为，并估计一个由数据驱动的、单位学习率下的次梯度噪声放大度量。\n\n基本原理与设置：\n- 带有分段光滑绝对值项的经验风险：对于标量参数 $w \\in \\mathbb{R}$，定义\n$$\nL(w) = \\frac{1}{n} \\sum_{i=1}^{n} \\left| a_i w - b_i \\right| + \\frac{\\lambda}{2} w^2,\n$$\n其中 $n$ 是数据点数量，$(a_i,b_i)$ 是固定标量，$\\lambda  0$ 是一个 $\\ell_2$ 正则化权重。每当 $a_i w - b_i = 0$ 时，绝对值项会引入非光滑的扭结。\n- 使用次梯度的随机梯度下降 (SGD) 更新规则：初始化 $w_0 \\in \\mathbb{R}$，并在每个步骤 $t \\in \\{0,1,\\dots,T-1\\}$，从 $\\{1,\\dots,n\\}$ 中均匀采样一个索引 $I_t$ 并更新\n$$\nw_{t+1} = w_t - \\eta_t \\, g_t,\n$$\n其中随机次梯度为\n$$\ng_t = a_{I_t} \\cdot \\operatorname{sign}(a_{I_t} w_t - b_{I_t}) + \\lambda w_t,\n$$\n并约定 $\\operatorname{sign}(0)=0$。步骤 $t$ 的学习率为 $\\eta_t  0$。\n- 非光滑区域检测：定义残差向量 $r(w) \\in \\mathbb{R}^n$，其分量为 $r_i(w) = a_i w - b_i$。对于一个容差 $\\varepsilon  0$，如果 $\\min_{1 \\le i \\le n} |r_i(w_t)| \\le \\varepsilon$，我们称迭代 $w_t$ 处于非光滑区域中。\n\n合成数据集与固定常量：\n- 使用 $n = 8$ 个数据点，其值为\n$$\na = [0.5,\\, 1.0,\\, 1.5,\\, 0.8,\\, 1.2,\\, 0.3,\\, 2.0,\\, 0.7], \\quad\nb = [0.6,\\, 1.2,\\, 1.8,\\, 0.9,\\, 1.5,\\, 0.2,\\, 2.3,\\, 0.85].\n$$\n- 使用 $\\lambda = 0.01$。\n- 使用总步数 $T = 4000$。\n- 使用非光滑容差 $\\varepsilon = 0.01$。\n- 初始化 $w_0 = 0$。\n- 使用一个固定的伪随机数生成器种子，其值为 $20231105$，用于索引采样。在每一步，从 $\\{1,\\dots,n\\}$ 中均匀采样单个索引。\n\n待测试的调度（测试套件）：\n对于每个调度，运行上述从 $t=0$ 到 $t=T-1$ 的 SGD 过程，在每一步应用该调度的 $\\eta_t$。\n\n- 调度 A (恒定小值)：对于所有 $t$，$\\eta_t = 0.05$。\n- 调度 B (步进衰减)：\n  - 对于 $0 \\le t  1200$，$\\eta_t = 0.08$。\n  - 对于 $1200 \\le t  2500$，$\\eta_t = 0.02$。\n  - 对于 $2500 \\le t  4000$，$\\eta_t = 0.005$。\n- 调度 C (不带重启的余弦退火)：使用 $\\eta_{\\max} = 0.08$，$\\eta_{\\min} = 0.002$ 和 $T = 4000$，定义\n$$\n\\eta_t = \\eta_{\\min} + \\frac{1}{2}\\left(\\eta_{\\max}-\\eta_{\\min}\\right)\\left(1 + \\cos\\left(\\pi \\frac{t}{T-1}\\right)\\right),\n$$\n对于 $t \\in \\{0,\\dots,T-1\\}$。\n- 调度 D (逆时衰减)：使用 $\\eta_0 = 0.12$ 和 $\\gamma = 0.0015$，\n$$\n\\eta_t = \\frac{\\eta_0}{1 + \\gamma t}.\n$$\n- 调度 E (恒定大值)：对于所有 $t$，$\\eta_t = 0.2$。\n\n噪声放大度量：\n- 令 $\\Delta w_t = w_{t+1} - w_t$。在步数集合 $K = \\{ t \\in \\{0,\\dots,T-1\\} : \\min_i |a_i w_t - b_i| \\le \\varepsilon \\}$ 内，通过零截距最小二乘法估计一个经学习率归一化的放大斜率：\n$$\n\\hat{s} = \\underset{s \\in \\mathbb{R}}{\\arg\\min} \\sum_{t \\in K} \\left( |\\Delta w_t| - s \\, \\eta_t \\right)^2.\n$$\n证明其最小化子为\n$$\n\\hat{s} = \\frac{\\sum_{t \\in K} \\eta_t \\, |\\Delta w_t|}{\\sum_{t \\in K} \\eta_t^2},\n$$\n并为每个调度计算此值。如果 $K$ 为空，则定义 $\\hat{s} = 0$。\n\n每个调度所需的输出：\n- 运行 $T$ 步后，计算：\n  1. 最终经验风险 $L(w_T)$。\n  2. 如上定义的放大斜率 $\\hat{s}$。\n  3. 处于非光滑区域内的步数的整数计数 $|K|$。\n\n最终输出格式：\n- 您的程序必须生成单行输出，包含从调度 A 到 E 的结果的串联，每个调度贡献一个三元组 $[L(w_T), \\hat{s}, |K|]$，并按 A、B、C、D、E 的顺序扁平化为一个列表。\n- 浮点数表示为四舍五入到六位小数，整数不带小数点。\n- 最终输出必须是单行、用方括号括起来的逗号分隔列表。例如，包含两个调度的输出可能看起来像 $[0.123456,0.654321,42,0.234567,0.345678,7]$。\n\n角度单位与物理单位：\n- 此问题不涉及任何物理单位或角度。\n\n您的实现必须是最终答案部分中指定的完整、可运行的程序。不需要外部输入。所有随机性必须遵循指定的种子。输出必须精确反映此处提供的定义，包括浮点值的舍入规则。",
            "solution": "用户提供了一个在机器学习数值优化领域中明确定义的计算问题。任务是模拟随机梯度下降 (SGD) 在一个分段光滑损失函数上的行为，并分析迭代在五种不同学习率调度下的表现。分析的重点是量化当迭代接近目标函数中的非光滑“扭结”时学习率的影响。\n\n该问题是有效的，因为它在非光滑优化理论中有科学依据，所有必要的参数和条件都已明确指定，并且是客观和可形式化的。我们将着手提供一个完整的解决方案。\n\n该解决方案包括三个主要部分：\n1.  噪声放大度量 $\\hat{s}$ 的数学推导。\n2.  为每个学习率调度模拟 SGD 过程的算法流程描述。\n3.  计算所需的输出度量：最终损失 $L(w_T)$、放大斜率 $\\hat{s}$ 以及非光滑区域中的步数计数 $|K|$。\n\n### 放大斜率 $\\hat{s}$ 的推导\n\n问题将放大斜率 $\\hat{s}$ 定义为一个零截距最小二乘问题的解。目标是找到 $s \\in \\mathbb{R}$ 的值，该值最小化权重更新的幅度 $|\\Delta w_t|$ 与学习率的线性模型 $s \\eta_t$ 之间的平方误差总和，适用于非光滑区域集合 $K$ 中的所有步骤 $t$。要最小化的目标函数是：\n$$\nJ(s) = \\sum_{t \\in K} \\left( |\\Delta w_t| - s \\eta_t \\right)^2\n$$\n为了找到最小化子 $\\hat{s}$，我们计算 $J(s)$ 相对于 $s$ 的导数，并将其设为零。\n$$\n\\frac{dJ}{ds} = \\frac{d}{ds} \\sum_{t \\in K} \\left( |\\Delta w_t|^2 - 2s\\eta_t|\\Delta w_t| + s^2\\eta_t^2 \\right)\n$$\n由于求和与微分算子是线性的，我们可以交换它们的顺序。项 $|\\Delta w_t|$ 和 $\\eta_t$ 相对于 $s$ 是常数。\n$$\n\\frac{dJ}{ds} = \\sum_{t \\in K} \\frac{d}{ds} \\left( |\\Delta w_t|^2 - 2s\\eta_t|\\Delta w_t| + s^2\\eta_t^2 \\right) = \\sum_{t \\in K} \\left( -2\\eta_t|\\Delta w_t| + 2s\\eta_t^2 \\right)\n$$\n将导数设为零，得到最优值 $\\hat{s}$：\n$$\n\\sum_{t \\in K} \\left( -2\\eta_t|\\Delta w_t| + 2\\hat{s}\\eta_t^2 \\right) = 0\n$$\n$$\n2\\hat{s} \\sum_{t \\in K} \\eta_t^2 = 2 \\sum_{t \\in K} \\eta_t|\\Delta w_t|\n$$\n假设集合 $K$ 非空（否则，总和为零，$\\hat{s}$ 定义为 $0$），我们知道 $\\sum_{t \\in K} \\eta_t^2  0$，因为 $\\eta_t  0$。因此，我们可以解出 $\\hat{s}$：\n$$\n\\hat{s} = \\frac{\\sum_{t \\in K} \\eta_t |\\Delta w_t|}{\\sum_{t \\in K} \\eta_t^2}\n$$\n这证实了问题陈述中给出的公式。二阶导数 $\\frac{d^2J}{ds^2} = \\sum_{t \\in K} 2\\eta_t^2$ 为正，确认了 $\\hat{s}$ 确实是一个最小化子。\n\n### 算法流程\n\n对于五个学习率调度（A、B、C、D、E）中的每一个，我们执行以下模拟：\n\n1.  **初始化**：\n    *   设置模型参数 $w = w_0 = 0$。\n    *   使用固定种子 $20231105$ 初始化一个伪随机数生成器。这对于确保五个调度模拟中的随机采样索引序列 $\\{I_t\\}_{t=0}^{T-1}$ 完全相同至关重要，从而实现公平比较。\n    *   初始化一个空列表 `k_data`，用于存储落入非光滑区域的步骤 $t$ 的 $(\\eta_t, |\\Delta w_t|)$ 对。\n\n2.  **SGD 迭代**：模拟运行 $T=4000$ 步，从 $t=0$ 到 $t=3999$。在每一步 $t$ 中：\n    *   **学习率**：根据当前调度的公式计算学习率 $\\eta_t$。\n    *   **非光滑区域检查**：计算残差向量 $r(w_t)$，其分量为 $r_i(w_t) = a_i w_t - b_i$。如果 $\\min_{1 \\le i \\le n} |r_i(w_t)| \\le \\varepsilon = 0.01$，则迭代 $w_t$ 处于非光滑区域中。\n    *   **随机次梯度**：从 $\\{1, \\dots, 8\\}$ 中均匀采样一个索引 $I_t$。然后按如下方式计算随机次梯度 $g_t$：\n        $$\n        g_t = a_{I_t} \\cdot \\operatorname{sign}(a_{I_t} w_t - b_{I_t}) + \\lambda w_t\n        $$\n        其中 $\\lambda=0.01$，我们使用约定 $\\operatorname{sign}(0)=0$。\n    *   **参数更新**：根据 SGD 规则更新权重：$w_{t+1} = w_t - \\eta_t g_t$。我们将变化量定义为 $\\Delta w_t = w_{t+1} - w_t = -\\eta_t g_t$。\n    *   **数据收集**：如果 $w_t$ 满足非光滑区域条件，则将对 $(\\eta_t, |\\Delta w_t|)$ 附加到 `k_data` 列表中。\n\n3.  **模拟后分析**：完成所有 $T$ 步后，我们得到最终权重 $w_T$。然后计算所需的度量：\n    *   **最终经验风险 $L(w_T)$**：使用以下公式计算：\n        $$\n        L(w_T) = \\frac{1}{n} \\sum_{i=1}^{n} |a_i w_T - b_i| + \\frac{\\lambda}{2} w_T^2\n        $$\n    *   **放大斜率 $\\hat{s}$**：使用收集到的 `k_data` 列表。如果列表为空（即集合 $K$ 为空），则 $\\hat{s}=0$。否则，使用推导出的公式计算 $\\hat{s}$。\n    *   **非光滑区域计数 $|K|$**：这只是 `k_data` 列表中的条目数。\n\n对五个调度中的每一个都重复此完整过程。将得到的三元组 $[L(w_T), \\hat{s}, |K|]$ 收集起来，并格式化为单个扁平列表作为最终输出。浮点值四舍五入到六位小数，整数按原样呈现。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the SGD simulations and produce the final output.\n    \"\"\"\n    \n    # --- Synthetic dataset and fixed constants ---\n    A = np.array([0.5, 1.0, 1.5, 0.8, 1.2, 0.3, 2.0, 0.7])\n    B = np.array([0.6, 1.2, 1.8, 0.9, 1.5, 0.2, 2.3, 0.85])\n    LAMBDA = 0.01\n    T = 4000\n    EPSILON = 0.01\n    W0 = 0.0\n    SEED = 20231105\n    N = len(A)\n\n    def get_lr(schedule_name, t, T_total):\n        \"\"\"Calculates the learning rate for a given step and schedule.\"\"\"\n        if schedule_name == 'A':\n            return 0.05\n        elif schedule_name == 'B':\n            if t  1200:\n                return 0.08\n            elif t  2500:\n                return 0.02\n            else:\n                return 0.005\n        elif schedule_name == 'C':\n            eta_max = 0.08\n            eta_min = 0.002\n            return eta_min + 0.5 * (eta_max - eta_min) * (1 + np.cos(np.pi * t / (T_total - 1)))\n        elif schedule_name == 'D':\n            eta0 = 0.12\n            gamma = 0.0015\n            return eta0 / (1 + gamma * t)\n        elif schedule_name == 'E':\n            return 0.2\n        else:\n            raise ValueError(f\"Unknown schedule: {schedule_name}\")\n\n    def run_sgd_simulation(schedule_name):\n        \"\"\"Runs one full SGD simulation for a given learning rate schedule.\"\"\"\n        \n        # Initialize RNG with fixed seed for reproducibility across schedules\n        rng = np.random.default_rng(SEED)\n\n        w = W0\n        k_data = []  # Stores (eta_t, delta_w_t) for t in K\n\n        for t in range(T):\n            # 1. Get learning rate\n            eta_t = get_lr(schedule_name, t, T)\n\n            # 2. Check for nonsmooth region\n            residuals = A * w - B\n            min_abs_residual = np.min(np.abs(residuals))\n            is_in_k = min_abs_residual = EPSILON\n\n            # 3. Sample index and compute stochastic subgradient\n            i_t = rng.integers(0, N)\n            residual_t = A[i_t] * w - B[i_t]\n            # np.sign(0.0) returns 0.0, matching the sign(0)=0 convention.\n            sign_term = np.sign(residual_t)\n            g_t = A[i_t] * sign_term + LAMBDA * w\n            \n            # 4. Compute weight update\n            delta_w_t = -eta_t * g_t\n            w_next = w + delta_w_t\n\n            # 5. Store data for hat_s if in nonsmooth region\n            if is_in_k:\n                k_data.append((eta_t, delta_w_t))\n\n            # 6. Update w for the next iteration\n            w = w_next\n        \n        w_T = w\n        \n        # --- Post-simulation analysis ---\n        \n        # 1. Final empirical risk L(w_T)\n        final_loss = np.mean(np.abs(A * w_T - B)) + (LAMBDA / 2.0) * w_T**2\n        \n        # 2. Amplification slope hat_s\n        if not k_data:\n            hat_s = 0.0\n        else:\n            k_etas = np.array([item[0] for item in k_data])\n            k_delta_ws_abs = np.abs(np.array([item[1] for item in k_data]))\n            \n            numerator = np.sum(k_etas * k_delta_ws_abs)\n            denominator = np.sum(k_etas**2)\n            \n            hat_s = numerator / denominator if denominator  0 else 0.0\n\n        # 3. Count |K|\n        k_count = len(k_data)\n        \n        return final_loss, hat_s, k_count\n\n    schedules_to_test = ['A', 'B', 'C', 'D', 'E']\n    all_results = []\n    \n    for schedule in schedules_to_test:\n        l_wT, s_hat, k_size = run_sgd_simulation(schedule)\n        all_results.append(f\"{l_wT:.6f}\")\n        all_results.append(f\"{s_hat:.6f}\")\n        all_results.append(str(k_size))\n        \n    # --- Final Output Formatting ---\n    print(f\"[{','.join(all_results)}]\")\n\n# Execute the main function\nsolve()\n```"
        },
        {
            "introduction": "预定义的学习率策略是一种“开环”控制，它无法根据模型的实际训练表现进行调整。一种更强大的方法是“闭环”控制，即让学习率调度器根据实时的验证反馈动态调整。本练习将引导你从零开始构建一个响应式的自适应调度器，它通过监测验证损失的移动平均值（moving averages）和“耐心”（patience）等指标来决定何时降低学习率，这不仅能让你理解常见库中 `ReduceLROnPlateau` 等工具的内部逻辑，还能让你学会如何评估这类策略的潜在风险，例如“假阳性”触发。",
            "id": "3142901",
            "problem": "您的任务是设计并测试一种学习率（LR）调度策略。该策略由早停（ES）式检测器触发，并通过验证集移动平均（MA）交叉进行验证，同时需要量化其假阳性率。目标是从基本原理出发实现检测器逻辑，并将其应用于合成的、但科学上合理的验证损失序列。当有证据表明训练出现停滞或恶化时，该调度策略应在冷却阶段降低学习率。您的程序必须为一小组测试用例输出一份简明的摘要。\n\n需要使用和构建的基本原理：\n- 基于梯度的学习使用形式为 $x_{t+1} = x_t - \\eta_t g_t$ 的更新，其中 $x_t$ 是在周期 $t$ 的参数向量，$g_t$ 是梯度估计，$\\eta_t \\gt 0$ 是在周期 $t$ 的学习率（LR）。该调度策略控制 $\\eta_t$。\n- 早停（ES）监控一个验证标准，以检测在某个耐心窗口内是否缺乏改善。检测器是一个由可观测的验证统计数据驱动的逻辑谓词。\n- 移动平均（MA）可作为降噪统计量。验证序列 $(y_t)$ 在时间 $t$、窗口大小为 $w$ 的简单移动平均（SMA）是最后 $w$ 个可用值的均值（如果可用值少于 $w$ 个，则使用较短的窗口），即\n$$\n\\operatorname{SMA}_w(t) = \\frac{1}{m}\\sum_{i=t-m+1}^{t} y_i,\\quad m=\\min(w, t+1).\n$$\n\n需要实现的调度策略定义：\n- 设初始学习率为 $\\eta_0 \\gt 0$。每当调度器触发时，将当前学习率乘以一个衰减因子 $\\gamma$（其中 $0 \\lt \\gamma \\lt 1$），并进入一个持续 $c$ 个周期的冷却阶段。在冷却期间，不允许新的触发。冷却结束后，学习率保持其最近一次衰减后的值。\n- 维护两个简单移动平均：一个窗口为 $w_s$ 的短期 SMA 和一个窗口为 $w_\\ell$ 的长期 SMA，其中 $w_s \\lt w_\\ell$。将它们表示为 $S_t = \\operatorname{SMA}_{w_s}(t)$ 和 $L_t = \\operatorname{SMA}_{w_\\ell}(t)$。\n- 维护至今观测到的最佳平滑值，$B_t = \\min_{0 \\le i \\le t} S_i$。如果在时间 $t$ 发生改善，即 $S_t \\lt B_{t-1} - \\varepsilon$（其中 $\\varepsilon \\ge 0$ 是一个容忍度），则更新 $B_t = S_t$ 并将周期 $t$ 记录为最近改善时间。\n- 定义在时间 $t$ 的早停（ES）条件成立，如果过去 $p$ 个周期内没有发生改善，即 $t - \\text{last\\_improve} \\ge p$。\n- 定义在时间 $t$ 的交叉确认条件成立，如果 $(S_i - L_i) \\ge \\delta$ 对于最近至少 $k$ 个连续周期（包括 $t$）都为真，其中 $\\delta \\ge 0$ 且整数 $k \\ge 1$。\n- 触发规则：在非冷却期间，如果在时间 $t$ 同时满足 ES 条件和交叉确认条件，则从周期 $t$ 开始触发一次冷却，设置 $\\eta \\leftarrow \\gamma \\eta$，并在冷却结束前阻止新的触发。\n\n假阳性定义：\n- 如果在接下来的 $q$ 个周期 $(t_0+1,\\dots,\\min(T-1, t_0+q))$ 内，存在一个新的最佳原始验证损失，该值比截至 $t_0$ 观测到的最佳原始验证损失至少低 $\\varepsilon$，则周期 $t_0$ 的触发被视为假阳性。形式上，设 $y_t$ 为原始验证损失，$b_{\\text{raw}}(t_0) = \\min_{0 \\le i \\le t_0} y_i$。如果满足以下条件，则该触发为假阳性：\n$$\n\\min_{t_0+1 \\le j \\le \\min(T-1, t_0+q)} y_j \\le b_{\\text{raw}}(t_0) - \\varepsilon.\n$$\n\n验证损失生成器：\n- 对于长度为 $T$ 的序列，为周期 $t \\in \\{0,1,\\dots,T-1\\}$ 定义原始验证损失\n$$\ny_t = a + b \\exp\\left(-\\frac{t}{\\tau}\\right) + u \\cdot \\frac{\\max(0, t - t_u)}{T} + \\epsilon_t,\n$$\n其中 $\\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$。使用一个带有指定整数种子的伪随机数生成器（PRNG）以保证可复现性。包含 $u$ 的项在 $t_u$ 之后引入一个平缓的上升漂移，以模拟过拟合。\n\n任务：\n- 根据规范实现由合成验证损失驱动的调度器和检测器。使用从 $t=0$ 开始的周期索引。如上所述，在序列开始部分使用可用样本计算简单移动平均。当在周期 $t$ 发生触发时，将该周期作为长度为 $c$ 的冷却期的第一个周期。\n- 对于下方的每个测试用例，计算：\n    1. 冷却触发的总次数（一个整数）。\n    2. 假阳性的数量（一个整数）。\n    3. 最终学习率（一个浮点数），从 $\\eta_0$ 开始，每次触发都乘以 $\\gamma$。\n\n测试套件：\n- 所有用例均使用初始学习率 $\\eta_0 = 0.1$。\n\n- 用例 A（带有轻微过拟合尾部的理想路径）：\n    - 序列参数：$T = 60$, $a = 0.2$, $b = 0.9$, $\\tau = 16$, $\\sigma = 0.008$, $u = 0.12$, $t_u = 45$, 种子 $= 0$。\n    - 调度策略参数：$\\gamma = 0.5$, $c = 5$, $p = 5$, $w_s = 3$, $w_\\ell = 9$, $k = 2$, $\\delta = 0.002$, $\\varepsilon = 0.0005$, $q = 4$。\n\n- 用例 B（持续改善，无漂移）：\n    - 序列参数：$T = 40$, $a = 0.1$, $b = 0.8$, $\\tau = 30$, $\\sigma = 0.005$, $u = 0.0$, $t_u = 100$, 种子 $= 1$。\n    - 调度策略参数：$\\gamma = 0.5$, $c = 6$, $p = 7$, $w_s = 2$, $w_\\ell = 8$, $k = 3$, $\\delta = 0.001$, $\\varepsilon = 0.0005$, $q = 5$。\n\n- 用例 C（用于探测假阳性的嘈杂平坦区域）：\n    - 序列参数：$T = 50$, $a = 0.5$, $b = 0.0$, $\\tau = 1$, $\\sigma = 0.02$, $u = 0.0$, $t_u = 0$, 种子 $= 2$。\n    - 调度策略参数：$\\gamma = 0.5$, $c = 4$, $p = 3$, $w_s = 1$, $w_\\ell = 6$, $k = 1$, $\\delta = 0.0$, $\\varepsilon = 0.0025$, $q = 5$。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表。将所有用例的结果汇总到一个列表的列表中，每个内部列表对应一个用例，按 A、B、C 的顺序排列。每个内部列表的形式必须是 $[\\text{冷却次数},\\text{假阳性数},\\text{最终学习率}]$。最终的字符串不能包含空格。例如，一个有效的输出形式是 \"[[1,0,0.05],[0,0,0.1],[3,2,0.0125]]\"。",
            "solution": "用户要求设计并实现一种基于早停（ES）原则和移动平均（MA）交叉的学习率（LR）调度策略。任务涉及在合成的验证损失数据上模拟调度器的行为，并量化其性能，特别是学习率降低的次数和假阳性率。\n\n该解决方案是从基本原理出发，作为在一系列周期 $t \\in \\{0, 1, \\dots, T-1\\}$ 上的离散时间模拟而开发的。\n\n**1. 合成验证损失的生成**\n\n对于每个测试用例，都会生成一个总共 $T$ 个周期的原始验证损失序列，表示为 $y_t$。用于生成此数据的函数是：\n$$\ny_t = a + b \\exp\\left(-\\frac{t}{\\tau}\\right) + u \\cdot \\frac{\\max(0, t - t_u)}{T} + \\epsilon_t\n$$\n这个模型在科学上是合理的，可以用来表示模型训练期间的验证损失曲线：\n- 常数项 $a$ 代表不可约减的误差或渐近损失值。\n- 项 $b \\exp(-t/\\tau)$ 模拟了学习的初始阶段，其中损失以时间常数 $\\tau$呈指数级下降。\n- 项 $u \\cdot \\frac{\\max(0, t - t_u)}{T}$ 模拟了在周期 $t_u$ 之后过拟合的开始，引入了一个线性的损失上升漂移，其幅度由因子 $u$ 缩放。\n- 项 $\\epsilon_t$ 是一个随机噪声分量，从正态分布 $\\mathcal{N}(0, \\sigma^2)$ 中采样，它代表了小批量梯度下降和验证过程中固有的随机性。\n\n通过为每个用例的伪随机数生成器（PRNG）使用特定的整数种子来确保可复现性。整个序列 $\\{y_t\\}_{t=0}^{T-1}$ 在主调度器模拟开始前预先生成。\n\n**2. 调度器设计与状态演化**\n\n调度器的逻辑在每个周期 $t$ 执行。其行为由一组内部状态变量和预定义规则决定。\n\n- **状态变量**：\n    - $\\eta_t$：周期 $t$ 的学习率，初始化为 $\\eta_0$。\n    - 冷却期：一个表示调度器是否暂时不活动的状态。我们跟踪 `cooldown_until`，即冷却期结束后调度器再次变为活动状态的第一个周期。\n    - $B_t$：至今观测到的最佳（最低）平滑验证损失。它被初始化为 $B_{-1} = \\infty$。\n    - `last_improve_epoch`：平滑损失上一次发生显著改善的周期 $t$。\n    - 交叉连续计数器：跟踪交叉条件已连续满足的周期数。\n\n- **移动平均（SMA）**：在每个周期 $t$，计算原始损失 $y_t$ 的两个简单移动平均以平滑噪声：\n    - 短期 SMA：$S_t = \\operatorname{SMA}_{w_s}(t) = \\frac{1}{\\min(w_s, t+1)}\\sum_{i=t-\\min(w_s, t+1)+1}^{t} y_i$\n    - 长期 SMA：$L_t = \\operatorname{SMA}_{w_\\ell}(t) = \\frac{1}{\\min(w_\\ell, t+1)}\\sum_{i=t-\\min(w_\\ell, t+1)+1}^{t} y_i$\n    其中 $w_s  w_\\ell$ 是各自的窗口大小。短期 SMA $S_t$ 对近期变化更敏感，而长期 SMA $L_t$ 反映了更广泛的趋势。\n\n- **模拟循环（周期 $t = 0, \\dots, T-1$）**：\n    1.  **计算 SMA**：根据历史原始损失数据 $\\{y_i\\}_{i=0}^{t}$ 计算 $S_t$ 和 $L_t$。\n    2.  **检查改善**：如果当前短期 SMA $S_t$ 比至今的最佳值 $B_{t-1}$ 有显著改善，则记录一次改善。条件为 $S_t  B_{t-1} - \\varepsilon$，其中 $\\varepsilon \\ge 0$ 是一个最小改善阈值。如果满足此条件，则更新状态：$B_t = S_t$ 并且 `last_improve_epoch` 设置为 $t$。否则，$B_t = B_{t-1}$。在 $t=0$ 时，假定有一次改善，因此 $B_0=S_0$ 并且 `last_improve_epoch` 设置为 $0$。\n    3.  **检查触发**：只有当调度器不处于冷却期（即 $t \\ge \\text{cooldown\\_until}$）时，才会发生学习率降低的触发。触发需要同时满足两个条件：\n        -   **早停（ES）条件**：在指定的周期数内没有观察到显著改善。如果 $t - \\text{last\\_improve\\_epoch} \\ge p$ 则为真，其中 $p$ 是耐心参数。\n        -   **交叉确认条件**：短期 SMA 持续高于长期 SMA，表明学习趋势可能发生逆转（即损失开始增加）。如果条件 $(S_i - L_i) \\ge \\delta$ 在过去 $k$ 个连续周期（从 $t-k+1$ 到 $t$）都成立，则为真，其中 $\\delta \\ge 0$ 是一个容忍度，$k \\ge 1$ 是确认长度。\n    4.  **触发动作**：如果两个条件都满足，则在周期 $t$ 发生一个触发事件。学习率乘以一个衰减因子 $\\gamma$（即 $\\eta \\leftarrow \\gamma \\cdot \\eta$），并启动一个为期 $c$ 个周期的新冷却期。这可以防止在周期 $t+c$ 之前发生进一步的触发。触发的周期被记录下来以供后续分析。\n\n**3. 假阳性分析**\n\n在所有 $T$ 个周期的模拟完成后，执行事后分析以识别记录的触发中的假阳性。如果在调度器决定降低学习率后，模型本可以在一个短的 $q$ 个周期的前瞻窗口内实现一个新的最佳原始验证损失，那么在周期 $t_0$ 的触发就被定义为假阳性。\n\n形式上，对于每个触发周期 $t_0$，我们计算：\n- 截至触发时的最佳原始损失：$b_{\\text{raw}}(t_0) = \\min_{0 \\le i \\le t_0} y_i$。\n- 随后 $q$ 个周期内的最小原始损失：$\\min_{t_0+1 \\le j \\le \\min(T-1, t_0+q)} y_j$。\n\n如果满足以下条件，在 $t_0$ 的触发被计为假阳性：\n$$\n\\min_{t_0+1 \\le j \\le \\min(T-1, t_0+q)} y_j \\le b_{\\text{raw}}(t_0) - \\varepsilon\n$$\n这个条件意味着，在学习率降低后不久，就发现了一个新的、至少比之前好 $\\varepsilon$ 的原始损失，这表明降低学习率的决定可能为时过早。\n\n最终的实现将这整个逻辑封装到一个函数中，为每个提供的测试用例执行该函数，并汇总结果——总触发次数、假阳性数量和最终学习率。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the simulation.\n    \"\"\"\n\n    def run_case(T, a, b, tau, sigma, u, t_u, seed,\n                 eta_0, gamma, c, p, w_s, w_ell, k, delta, epsilon, q):\n        \"\"\"\n        Runs a single simulation case for the LR scheduler.\n\n        Returns:\n            A list containing [num_triggers, num_false_positives, final_lr].\n        \"\"\"\n        # 1. Generate the full raw validation loss sequence\n        rng = np.random.default_rng(seed)\n        epochs = np.arange(T)\n        noise = rng.normal(0, sigma, T)\n        drift = u * np.maximum(0, epochs - t_u) / T\n        y_raw = a + b * np.exp(-epochs / tau) + drift + noise\n\n        # 2. Initialize scheduler state variables\n        lr = eta_0\n        cooldown_until = 0\n        trigger_epochs = []\n        \n        best_smooth_loss = np.inf\n        last_improve_epoch = 0\n        consecutive_crossover_count = 0\n        \n        # Store SMA values for crossover check\n        S_hist = []\n        L_hist = []\n        \n        # 3. Main simulation loop over epochs\n        for t in range(T):\n            # Compute Short-term and Long-term Simple Moving Averages (SMAs)\n            m_s = min(w_s, t + 1)\n            S_t = np.mean(y_raw[t - m_s + 1 : t + 1])\n\n            m_ell = min(w_ell, t + 1)\n            L_t = np.mean(y_raw[t - m_ell + 1 : t + 1])\n            \n            S_hist.append(S_t)\n            L_hist.append(L_t)\n\n            # Check for improvement in smoothed loss\n            if t == 0:\n                best_smooth_loss = S_t\n                last_improve_epoch = 0\n            else:\n                if S_t  best_smooth_loss - epsilon:\n                    best_smooth_loss = S_t\n                    last_improve_epoch = t\n\n            # Check for trigger conditions if not in cooldown\n            if t = cooldown_until:\n                # Early Stopping condition: patience exceeded\n                es_holds = (t - last_improve_epoch) = p\n\n                # Crossover confirmation condition\n                crossover_holds = False\n                if t + 1 = k:\n                    crossover_true_for_k_steps = True\n                    for i in range(k):\n                        if not ((S_hist[t-i] - L_hist[t-i]) = delta):\n                            crossover_true_for_k_steps = False\n                            break\n                    if crossover_true_for_k_steps:\n                        crossover_holds = True\n\n                # If both conditions hold, trigger LR reduction\n                if es_holds and crossover_holds:\n                    lr *= gamma\n                    cooldown_until = t + c\n                    trigger_epochs.append(t)\n        \n        num_triggers = len(trigger_epochs)\n\n        # 4. Post-hoc analysis for false positives\n        num_false_positives = 0\n        for t0 in trigger_epochs:\n            best_raw_loss_at_trigger = np.min(y_raw[:t0 + 1])\n            \n            j_start = t0 + 1\n            j_end_inclusive = min(T - 1, t0 + q)\n            \n            # Check if lookahead window is valid\n            if j_start  j_end_inclusive:\n                continue\n                \n            future_losses = y_raw[j_start : j_end_inclusive + 1]\n            min_future_loss = np.min(future_losses)\n\n            if min_future_loss = best_raw_loss_at_trigger - epsilon:\n                num_false_positives += 1\n\n        return [num_triggers, num_false_positives, lr]\n\n    # Define the test suite as specified in the problem\n    test_cases = [\n        # Case A: Happy path with mild overfitting tail\n        dict(\n            T=60, a=0.2, b=0.9, tau=16, sigma=0.008, u=0.12, t_u=45, seed=0,\n            eta_0=0.1, gamma=0.5, c=5, p=5, w_s=3, w_ell=9, k=2, delta=0.002,\n            epsilon=0.0005, q=4\n        ),\n        # Case B: Continued improvement, no drift\n        dict(\n            T=40, a=0.1, b=0.8, tau=30, sigma=0.005, u=0.0, t_u=100, seed=1,\n            eta_0=0.1, gamma=0.5, c=6, p=7, w_s=2, w_ell=8, k=3, delta=0.001,\n            epsilon=0.0005, q=5\n        ),\n        # Case C: Noisy flat region to probe false positives\n        dict(\n            T=50, a=0.5, b=0.0, tau=1, sigma=0.02, u=0.0, t_u=0, seed=2,\n            eta_0=0.1, gamma=0.5, c=4, p=3, w_s=1, w_ell=6, k=1, delta=0.0,\n            epsilon=0.0025, q=5\n        ),\n    ]\n\n    # Run all test cases and collect results\n    results = [run_case(**case) for case in test_cases]\n\n    # Format the final output string as required\n    # A bit complex to get the exact float representation as the example\n    # We will format it manually.\n    results_str = []\n    for case_res in results:\n        # [1,0,0.05]\n        lr_val_str = f\"{case_res[2]:.17g}\".rstrip('0').rstrip('.')\n        if lr_val_str == \"0.1\": lr_val_str = \"0.1\" # handle this case\n        if lr_val_str == \"0.05\": lr_val_str = \"0.05\"\n        if \"e\" not in lr_val_str and \".\" not in lr_val_str:\n            lr_val_str += \".0\"\n        \n        results_str.append(f\"[{case_res[0]},{case_res[1]},{case_res[2]}]\")\n\n\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}