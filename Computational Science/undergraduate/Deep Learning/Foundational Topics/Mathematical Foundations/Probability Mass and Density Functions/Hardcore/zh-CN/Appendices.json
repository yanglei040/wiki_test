{
    "hands_on_practices": [
        {
            "introduction": "在深度学习中，概率质量函数（PMF）是定义分类模型输出和损失函数的核心。这个实践将深入探讨两种基础的PMF——伯努利分布和分类分布——如何影响模型训练。通过从第一性原理推导并计算负对数似然损失的梯度和曲率，你将亲手揭示模型在处理不平衡数据时，不同PMF选择对其学习动态的具体影响。",
            "id": "3166266",
            "problem": "您将比较深度学习中用于分类任务的两种输出头，并量化在标签不平衡的情况下，概率质量函数 (PMF) 的形状如何影响负对数似然及其导数。这两种头是：用于二元分类的伯努利头 (Bernoulli head) 和用于多类分类的分类头 (Categorical head)。比较应从梯度相对于 logits 的大小以及损失曲面曲率概念的角度进行。计算必须从概率质量函数 (PMF)、负对数似然 (NLL) 的基本定义以及通过标准链接函数从 logits 到概率的映射开始。\n\n需要使用的基本定义是：\n- 对于由概率 $p \\in (0,1)$ 参数化的二元标签 $y \\in \\{0, 1\\}$，其伯努利 PMF 为 $P(Y=y \\mid p) = p^{y} (1-p)^{1-y}$。logit $z \\in \\mathbb{R}$ 通过 logistic 函数 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ 映射到 $p$。\n- 对于由概率向量 $\\mathbf{q} \\in \\Delta^{K-1}$ (概率单纯形) 参数化的 one-hot 标签 $\\mathbf{y} \\in \\{0,1\\}^{K}$（其中恰好有一个 $1$ 和 $K-1$ 个零），其分类 PMF 为 $P(\\mathbf{Y}=\\mathbf{y} \\mid \\mathbf{q}) = \\prod_{i=1}^{K} q_{i}^{y_{i}}$。logits $\\mathbf{z} \\in \\mathbb{R}^{K}$ 通过 softmax 函数 $q_{i}(\\mathbf{z}) = \\frac{e^{z_{i}}}{\\sum_{j=1}^{K} e^{z_{j}}}$ 映射到 $\\mathbf{q}$。\n\n将负对数似然 (NLL) 损失函数定义为在这些链接函数下 PMF 的负对数。对于伯努利头，将损失表示为 $\\mathcal{L}_{\\mathrm{B}}(z; y)$；对于分类头，将损失表示为 $\\mathcal{L}_{\\mathrm{C}}(\\mathbf{z}; \\mathbf{y})$。\n\n任务：\n1. 对于伯努利头，计算：\n   - 相对于标量 logit $z$ 的梯度，并报告其大小 $\\lVert \\nabla_{z} \\mathcal{L}_{\\mathrm{B}}(z; y) \\rVert_{2}$。\n   - 定义为二阶导数 $\\frac{d^{2}\\mathcal{L}_{\\mathrm{B}}(z; y)}{dz^{2}}$ 的曲率。\n   这两个量都必须从 PMF、NLL 定义和链式法则推导并实现，不使用任何未经这些基本定义证明的快捷公式。\n\n2. 对于分类头，计算：\n   - 相对于 logits 向量 $\\mathbf{z}$ 的梯度向量，并报告其欧几里得范数 $\\lVert \\nabla_{\\mathbf{z}} \\mathcal{L}_{\\mathrm{C}}(\\mathbf{z}; \\mathbf{y}) \\rVert_{2}$。\n   - 定义为 Hessian 矩阵 $\\nabla^{2}_{\\mathbf{z}} \\mathcal{L}_{\\mathrm{C}}(\\mathbf{z}; \\mathbf{y})$ 最大特征值的曲率大小。\n   这两个量都必须从 PMF、NLL 定义、链式法则以及 softmax 雅可比矩阵推导并实现，不使用任何未经这些基本定义证明的快捷公式。\n\n在这里，不平衡标签被定义为预测强烈偏向多数类，而观察到的标签属于少数类的情况。您将量化 PMF 的形式（伯努利与分类）在此类条件下如何改变梯度大小和适当的曲率度量。\n\n测试套件：\n在分类头中对类别标签使用从零开始的索引。实现以下六个测试用例。\n\n- 伯努利头 (二元):\n  1. 用例 B1 (罕见正例，中等置信度的负例预测): $y = 1$, $z = -2.197224577$ (对应 $p \\approx 0.1$)。\n  2. 用例 B2 (罕见正例，极高置信度的负例预测): $y = 1$, $z = -6.907755278$ (对应 $p \\approx 0.001$)。\n  3. 用例 B3 (多数负例，高置信度的正例预测): $y = 0$, $z = 2.197224577$ (对应 $p \\approx 0.9$)。\n\n- 分类头 (多类):\n  4. 用例 C1 (罕见类别索引 $3$ 对抗多数偏向的 logits): $K = 5$, $y = 3$, $\\mathbf{z} = [2.0, 1.0, 0.5, -1.0, -2.0]$。\n  5. 用例 C2 (罕见类别索引 $2$，极端多数偏向): $K = 3$, $y = 2$, $\\mathbf{z} = [5.0, 0.0, -2.5]$。\n  6. 用例 C3 (平衡预测，均匀 logits): $K = 4$, $y = 1$, $\\mathbf{z} = [0.0, 0.0, 0.0, 0.0]$。\n\n答案规格：\n- 对每个测试用例，输出两个浮点数：首先是梯度大小，其次是曲率大小（如上定义）。\n- 最终程序输出必须是单行文本，包含按顺序排列的所有 $12$ 个浮点数，聚合为方括号内的逗号分隔列表，遵循六个测试用例的顺序：B1, B2, B3, C1, C2, C3。即，输出格式必须严格为 \"[g_B1,c_B1,g_B2,c_B2,g_B3,c_B3,g_C1,c_C1,g_C2,c_C2,g_C3,c_C3]\"。\n- 此问题不涉及物理单位。角度不适用。\n\n您的程序必须完整且可按规定运行，不接受外部输入，并直接从定义计算这些量。在适当情况下确保数值稳定性。",
            "solution": "用户要求对伯努利分布和分类分布的负对数似然 (NLL) 损失函数及其导数进行详细分析，这两种分布通常在深度学习模型中用作分类任务的输出头。该分析将从第一性原理出发，从概率质量函数 (PMF) 和将实值 logits 映射到概率的链接函数 (logistic 和 softmax) 开始。\n\n### 1. 用于二元分类的伯努利头\n\n对于二元分类问题，标签为 $y \\in \\{0, 1\\}$。模型预测标签为 $1$ 的概率 $p \\in (0,1)$。\n\n**1.1. 损失函数推导**\n伯努利 PMF 由下式给出：\n$$P(Y=y \\mid p) = p^{y} (1-p)^{1-y}$$\nNLL 损失 $\\mathcal{L}_{\\mathrm{B}}$ 是 PMF 的负对数：\n$$\\mathcal{L}_{\\mathrm{B}}(p; y) = -\\log(p^{y} (1-p)^{1-y}) = -[y \\log(p) + (1-y)\\log(1-p)]$$\n概率 $p$ 是通过 logistic (sigmoid) 函数 $\\sigma(z)$ 从标量 logit $z \\in \\mathbb{R}$ 获得的：\n$$p = \\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n将此代入损失函数得到 $\\mathcal{L}_{\\mathrm{B}}(z; y)$。\n\n**1.2. 梯度计算**\n为求损失相对于 logit $z$ 的梯度，我们使用链式法则：$\\frac{d\\mathcal{L}_{\\mathrm{B}}}{dz} = \\frac{d\\mathcal{L}_{\\mathrm{B}}}{dp} \\frac{dp}{dz}$。\n\n首先，我们求损失相对于概率 $p$ 的导数：\n$$\\frac{d\\mathcal{L}_{\\mathrm{B}}}{dp} = -\\left[ \\frac{y}{p} - \\frac{1-y}{1-p} \\right] = \\frac{1-y}{1-p} - \\frac{y}{p} = \\frac{p(1-y) - y(1-p)}{p(1-p)} = \\frac{p - py - y + py}{p(1-p)} = \\frac{p-y}{p(1-p)}$$\n接下来，我们求 logistic 函数相对于 $z$ 的导数：\n$$\\frac{dp}{dz} = \\frac{d}{dz} (1 + e^{-z})^{-1} = -1(1 + e^{-z})^{-2}(-e^{-z}) = \\frac{e^{-z}}{(1+e^{-z})^2} = \\frac{1}{1+e^{-z}}\\frac{e^{-z}}{1+e^{-z}} = \\sigma(z)(1-\\sigma(z)) = p(1-p)$$\n结合这些结果，得到梯度：\n$$\\frac{d\\mathcal{L}_{\\mathrm{B}}}{dz} = \\left( \\frac{p-y}{p(1-p)} \\right) \\cdot (p(1-p)) = p - y = \\sigma(z) - y$$\n梯度是一个标量，因此其欧几里得范数是其绝对值：\n$$\\lVert \\nabla_{z} \\mathcal{L}_{\\mathrm{B}}(z; y) \\rVert_{2} = |\\sigma(z) - y|$$\n\n**1.3. 曲率计算**\n伯努利情况下的曲率定义为损失相对于 logit $z$ 的二阶导数：\n$$\\frac{d^{2}\\mathcal{L}_{\\mathrm{B}}}{dz^{2}} = \\frac{d}{dz} \\left( \\frac{d\\mathcal{L}_{\\mathrm{B}}}{dz} \\right) = \\frac{d}{dz}(\\sigma(z) - y) = \\frac{d}{dz}\\sigma(z)$$\n使用我们之前求出的 logistic 函数的导数：\n$$\\frac{d^{2}\\mathcal{L}_{\\mathrm{B}}}{dz^{2}} = \\sigma(z)(1-\\sigma(z)) = p(1-p)$$\n\n### 2. 用于多类分类的分类头\n\n对于有 $K$ 个类的多类分类问题，标签由一个 one-hot 向量 $\\mathbf{y} \\in \\{0, 1\\}^K$ 表示，其中只有一个分量是 $1$。模型预测一个概率向量 $\\mathbf{q} \\in \\Delta^{K-1}$ (概率单纯形)。\n\n**2.1. 损失函数推导**\n分类 PMF 由下式给出：\n$$P(\\mathbf{Y}=\\mathbf{y} \\mid \\mathbf{q}) = \\prod_{i=1}^{K} q_{i}^{y_{i}}$$\nNLL 损失 $\\mathcal{L}_{\\mathrm{C}}$ 是 PMF 的负对数：\n$$\\mathcal{L}_{\\mathrm{C}}(\\mathbf{q}; \\mathbf{y}) = -\\log\\left(\\prod_{i=1}^{K} q_{i}^{y_{i}}\\right) = -\\sum_{i=1}^{K} y_i \\log(q_i)$$\n由于 $\\mathbf{y}$ 是 one-hot 向量，如果真实类别是 $c$，则 $y_c = 1$ 且对于 $i \\neq c$ 有 $y_i=0$。损失简化为标准的交叉熵损失：\n$$\\mathcal{L}_{\\mathrm{C}} = -\\log(q_c)$$\n概率向量 $\\mathbf{q}$ 是通过 softmax 函数从 logit 向量 $\\mathbf{z} \\in \\mathbb{R}^K$ 获得的：\n$$q_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$$\n\n**2.2. 梯度计算**\n为求损失相对于 logit 向量 $\\mathbf{z}$ 的梯度，我们计算每个分量 $k$ 的偏导数 $\\frac{\\partial \\mathcal{L}_{\\mathrm{C}}}{\\partial z_k}$。\n$$\\frac{\\partial \\mathcal{L}_{\\mathrm{C}}}{\\partial z_k} = \\sum_{i=1}^{K} \\frac{\\partial \\mathcal{L}_{\\mathrm{C}}}{\\partial q_i} \\frac{\\partial q_i}{\\partial z_k}$$\n损失相对于 $q_i$ 的导数是 $\\frac{\\partial \\mathcal{L}_{\\mathrm{C}}}{\\partial q_i} = -\\frac{y_i}{q_i}$。\nsoftmax 函数的偏导数构成了雅可比矩阵 $J_{ik} = \\frac{\\partial q_i}{\\partial z_k}$，其为：\n$$\\frac{\\partial q_i}{\\partial z_k} = \\begin{cases} q_i(1-q_i)  \\text{if } i=k \\\\ -q_i q_k  \\text{if } i \\neq k \\end{cases} \\quad \\text{或简写为, } \\quad \\frac{\\partial q_i}{\\partial z_k} = q_i(\\delta_{ik} - q_k)$$\n其中 $\\delta_{ik}$ 是克罗内克δ函数。\n结合这些，我们得到：\n$$\\frac{\\partial \\mathcal{L}_{\\mathrm{C}}}{\\partial z_k} = \\sum_{i=1}^{K} \\left(-\\frac{y_i}{q_i}\\right) (q_i(\\delta_{ik} - q_k)) = -\\sum_{i=1}^{K} y_i(\\delta_{ik} - q_k) = - (y_k - q_k \\sum_{i=1}^{K} y_i)$$\n由于 $\\mathbf{y}$ 是一个 one-hot 向量，$\\sum_{i=1}^{K} y_i = 1$。因此，偏导数简化为：\n$$\\frac{\\partial \\mathcal{L}_{\\mathrm{C}}}{\\partial z_k} = q_k - y_k$$\n因此，梯度向量为 $\\nabla_{\\mathbf{z}} \\mathcal{L}_{\\mathrm{C}}(\\mathbf{z}; \\mathbf{y}) = \\mathbf{q} - \\mathbf{y}$。其欧几里得范数为：\n$$\\lVert \\nabla_{\\mathbf{z}} \\mathcal{L}_{\\mathrm{C}}(\\mathbf{z}; \\mathbf{y}) \\rVert_{2} = \\lVert \\mathbf{q} - \\mathbf{y} \\rVert_{2} = \\sqrt{\\sum_{i=1}^{K} (q_i - y_i)^2}$$\n\n**2.3. 曲率计算**\n分类情况下的曲率定义为 Hessian 矩阵 $\\mathbf{H} = \\nabla^{2}_{\\mathbf{z}} \\mathcal{L}_{\\mathrm{C}}(\\mathbf{z}; \\mathbf{y})$ 的最大特征值。Hessian 矩阵的元素 $H_{k\\ell}$ 为：\n$$H_{k\\ell} = \\frac{\\partial}{\\partial z_\\ell} \\left( \\frac{\\partial \\mathcal{L}_{\\mathrm{C}}}{\\partial z_k} \\right) = \\frac{\\partial}{\\partial z_\\ell} (q_k - y_k) = \\frac{\\partial q_k}{\\partial z_\\ell}$$\n这正是前面推导出的 softmax 函数的雅可比矩阵。所以，Hessian 矩阵是：\n$$\\mathbf{H} = \\begin{pmatrix} q_1(1-q_1)  -q_1 q_2  \\dots \\\\ -q_2 q_1  q_2(1-q_2)  \\dots \\\\ \\vdots  \\vdots  \\ddots \\end{pmatrix} \\quad \\text{或简写为, } \\quad \\mathbf{H} = \\text{diag}(\\mathbf{q}) - \\mathbf{q}\\mathbf{q}^T$$\n该矩阵是分类分布的协方差矩阵。它是一个实对称半正定矩阵。曲率是其最大特征值 $\\lambda_{\\max}(\\mathbf{H})$。这将通过数值方法计算。\n\n### 3. 用于实现的公式总结\n\n-   **伯努利头:**\n    -   $p = 1 / (1 + e^{-z})$\n    -   梯度大小: $|p - y|$\n    -   曲率: $p(1-p)$\n\n-   **分类头:**\n    -   稳定的 softmax: $z'_i = z_i - \\max(\\mathbf{z})$，然后 $q_i = e^{z'_i} / \\sum_j e^{z'_j}$\n    -   one-hot 标签: $\\mathbf{y}$ 来自索引 $y_{idx}$\n    -   梯度大小: $\\sqrt{\\sum_{i=1}^{K} (q_i - y_i)^2}$\n    -   Hessian 矩阵: $\\mathbf{H} = \\text{diag}(\\mathbf{q}) - \\mathbf{q}\\mathbf{q}^T$\n    -   曲率: $\\lambda_{\\max}(\\mathbf{H})$",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes gradient magnitude and curvature for Bernoulli and Categorical NLL loss\n    functions based on specified test cases.\n    \"\"\"\n\n    # --- Helper Functions ---\n\n    def bernoulli_analysis(y, z):\n        \"\"\"\n        Computes gradient magnitude and curvature for the Bernoulli NLL loss.\n        \n        Args:\n            y (int): The true label (0 or 1).\n            z (float): The logit.\n            \n        Returns:\n            A tuple (gradient_magnitude, curvature).\n        \"\"\"\n        # Calculate probability p = sigma(z)\n        p = 1.0 / (1.0 + np.exp(-z))\n        \n        # Gradient of NLL w.r.t. z is p - y\n        grad_scalar = p - y\n        \n        # Gradient magnitude is the absolute value of the scalar gradient\n        grad_magnitude = np.abs(grad_scalar)\n        \n        # Curvature (second derivative) is p * (1 - p)\n        curvature = p * (1.0 - p)\n        \n        return grad_magnitude, curvature\n\n    def categorical_analysis(y_idx, z_vec):\n        \"\"\"\n        Computes gradient magnitude and curvature for the Categorical NLL loss.\n        \n        Args:\n            y_idx (int): The index of the true class.\n            z_vec (np.ndarray): The vector of logits.\n            \n        Returns:\n            A tuple (gradient_magnitude, curvature).\n        \"\"\"\n        K = len(z_vec)\n        \n        # 1. Compute probability vector q using a stable softmax\n        z_shifted = z_vec - np.max(z_vec)\n        exps = np.exp(z_shifted)\n        q = exps / np.sum(exps)\n        \n        # 2. Create one-hot label vector y\n        y_vec = np.zeros(K)\n        y_vec[y_idx] = 1.0\n        \n        # 3. Compute gradient vector and its magnitude\n        # Gradient of NLL w.r.t. z is q - y\n        grad_vec = q - y_vec\n        grad_magnitude = np.linalg.norm(grad_vec)\n        \n        # 4. Construct the Hessian matrix H = diag(q) - q*q^T\n        # hessian = np.diag(q) - np.outer(q, q)\n        # Using a numerically stable way to compute eigenvalues of I-uu^T style matrices is not needed here\n        # standard computation is fine given the problem constraints and numpy's robustness.\n        q_diag = np.diag(q)\n        q_outer = np.outer(q, q)\n        hessian = q_diag - q_outer\n\n\n        # 5. Compute eigenvalues of the Hessian\n        # The Hessian is real and symmetric, use eigh for efficiency and stability.\n        # eigh returns eigenvalues in ascending order.\n        eigenvalues = np.linalg.eigh(hessian)[0]\n        \n        # 6. Curvature is the largest eigenvalue\n        curvature = eigenvalues[-1]\n        \n        return grad_magnitude, curvature\n\n    # --- Test Cases ---\n    \n    test_cases = [\n        # Type, (parameters...)\n        ('B', (1, -2.197224577)),     # Case B1\n        ('B', (1, -6.907755278)),     # Case B2\n        ('B', (0, 2.197224577)),      # Case B3\n        ('C', (3, np.array([2.0, 1.0, 0.5, -1.0, -2.0]))), # Case C1\n        ('C', (2, np.array([5.0, 0.0, -2.5]))),          # Case C2\n        ('C', (1, np.array([0.0, 0.0, 0.0, 0.0]))),       # Case C3\n    ]\n\n    results = []\n    for case_type, params in test_cases:\n        if case_type == 'B':\n            y, z = params\n            grad_mag, curv = bernoulli_analysis(y, z)\n        elif case_type == 'C':\n            y_idx, z_vec = params\n            grad_mag, curv = categorical_analysis(y_idx, z_vec)\n        \n        results.extend([grad_mag, curv])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{x:.7f}' for x in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个分类模型输出的概率质量函数（PMF）不仅要预测正确，其给出的“置信度”也应是可靠的。这个实践将引导你实现一个关键的评估指标——期望校准误差（ECE），来衡量模型预测置信度与实际准确率之间的一致性。通过在过自信和欠自信等典型场景下计算ECE，你将学会如何诊断和量化模型的校准水平。",
            "id": "3166196",
            "problem": "给定一个多类分类场景，其中模型为每个输入生成一个预测的类别概率向量，该向量各分量之和为 $1$。此类向量构成一个概率质量函数 (PMF)。在深度学习中，从 logits (未归一化分数) 构建 PMF 的一种标准方法是通过 softmax 函数：给定 logits $\\mathbf{z} \\in \\mathbb{R}^K$，PMF 定义为 $p_i = \\exp(z_i) / \\sum_{j=1}^K \\exp(z_j)$，其中 $i \\in \\{1,\\dots,K\\}$。\n\n目标是计算预期校准误差 (Expected Calibration Error, ECE)，该误差用于衡量预测置信度与观测准确率之间的差异。请基于基本原理，仅使用以下基础定义：\n- 一个关于 $K$ 个类别的 PMF 是一个函数 $p: \\{1,\\dots,K\\} \\to [0,1]$，满足 $\\sum_{i=1}^K p(i) = 1$。\n- 对于每个预测 $\\mathbf{p}$，将预测类别定义为最大分量的索引，将置信度定义为最大概率值。对于给定的真实标签，如果预测类别与真实标签相等，则将正确性定义为 $1$，否则为 $0$。\n- 期望值是某个量在其概率分布下的平均值。期望值的基于直方图的近似方法将定义域划分为多个区间（bin），计算每个区间内的平均值，并按区间的相对频率加权聚合这些平均值。\n\n定义以下过程，使用 $B$ 个等宽区间在 $[0,1]$ 上近似计算 ECE：\n- 对于每个带有 PMF $\\mathbf{p}^{(n)}$ 的样本 $n \\in \\{1,\\dots,N\\}$，令置信度为 $c^{(n)} = \\max_i p^{(n)}_i$，预测类别为 $\\hat{y}^{(n)} = \\arg\\max_i p^{(n)}_i$。给定真实标签 $y^{(n)}$，定义指示符 $a^{(n)} = 1$（如果 $\\hat{y}^{(n)} = y^{(n)}$）和 $a^{(n)} = 0$（否则）。\n- 将 $[0,1]$ 划分为 $B$ 个等宽区间。根据规则 $b^{(n)} = \\min\\{\\lfloor B \\cdot c^{(n)} \\rfloor, B-1\\}$ 将每个 $c^{(n)}$ 分配到一个区间，这实现的区间为 $[0, 1/B), [1/B, 2/B), \\dots, [(B-1)/B, 1]$。\n- 对于每个区间 $b \\in \\{0,\\dots,B-1\\}$，仅考虑那些 $b^{(n)} = b$ 的样本 $n$。如果一个区间没有样本，则其贡献为零。对于非空区间，计算其经验准确率（区间内 $a^{(n)}$ 的平均值）和经验置信度（区间内 $c^{(n)}$ 的平均值）。ECE 是区间准确率与区间置信度之间绝对偏差的加权聚合，权重等于落入每个区间的样本比例。\n\n你的任务是：实现一个程序，为以下每个测试用例计算 ECE。对于每个用例，你会得到一组 PMF（作为行）、一个真实标签向量以及区间数量 $B$。将标签视为从零开始的类别索引。使用上面陈述的精确分箱规则，并跳过空区间（即，没有样本的区间贡献为 $0$）。你的程序应生成单行输出，其中包含 ECE 值，四舍五入到六位小数，格式为用方括号括起来的逗号分隔列表。\n\n测试套件：\n- 案例 A（在两个置信度水平上完美校准，$K=5$ 类）：\n  - 样本数 $N = 50$，区间数 $B = 10$。\n  - 通过堆叠 $25$ 个 $[0.2, 0.2, 0.2, 0.2, 0.2]$ 的副本，后跟 $25$ 个 $[0.8, 0.05, 0.05, 0.05, 0.05]$ 的副本，来构建 PMF 矩阵。\n  - 长度为 $50$ 的真实标签向量：\n    - 索引 $0$到$4$：标签 $0$。\n    - 索引 $5$到$24$：标签 $1$。\n    - 索引 $25$到$44$：标签 $0$。\n    - 索引 $45$到$49$：标签 $1$。\n- 案例 B（过度自信的预测，$K=3$ 类）：\n  - 样本数 $N = 20$，区间数 $B = 10$。\n  - PMF 矩阵包含 $20$ 个 $[0.9, 0.05, 0.05]$ 的副本。\n  - 长度为 $20$ 的真实标签向量：\n    - 索引 $0$到$9$：标签 $0$。\n    - 索引 $10$到$19$：标签 $1$。\n- 案例 C（置信度不足的预测，$K=3$ 类）：\n  - 样本数 $N = 20$，区间数 $B = 10$。\n  - PMF 矩阵包含 $20$ 个 $[0.4, 0.3, 0.3]$ 的副本。\n  - 长度为 $20$ 的真实标签向量：\n    - 索引 $0$到$15$：标签 $0$。\n    - 索引 $16$到$19$：标签 $1$。\n- 案例 D（区间覆盖稀疏，测试空区间处理，$K=4$ 类）：\n  - 样本数 $N = 4$，区间数 $B = 20$。\n  - PMF 矩阵（每行为一个样本）：\n    - 行 $1$：$[0.51, 0.49, 0.0, 0.0]$。\n    - 行 $2$：$[0.99, 0.01, 0.0, 0.0]$。\n    - 行 $3$：$[0.0, 0.34, 0.33, 0.33]$。\n    - 行 $4$：$[0.0, 0.26, 0.25, 0.49]$。\n  - 长度为 $4$ 的真实标签向量：$[0, 1, 1, 2]$。\n- 案例 E（边界情况，置信度为 $1$ 的确定性 PMF，$K=3$ 类）：\n  - 样本数 $N = 4$，区间数 $B = 15$。\n  - PMF 矩阵：\n    - 行 $1$：$[1.0, 0.0, 0.0]$。\n    - 行 $2$：$[1.0, 0.0, 0.0]$。\n    - 行 $3$：$[0.0, 1.0, 0.0]$。\n    - 行 $4$：$[0.0, 1.0, 0.0]$。\n  - 长度为 $4$ 的真实标签向量：$[0, 1, 1, 2]$。\n\n最终输出格式：\n- 你的程序应生成单行输出，按顺序包含案例 A 到 E 的 ECE 值，四舍五入到六位小数，格式与 Python 风格的列表完全一致，不含空格：例如，$[x_A, x_B, x_C, x_D, x_E]$，其中每个 $x_\\cdot$ 是一个四舍五入到六位小数的浮点数。",
            "solution": "该问题要求计算预期校准误差 (Expected Calibration Error, ECE)，这是一种用于评估概率分类器校准度的度量指标。该过程基于直方图分箱方法。解决方案是根据所提供的基本原理和定义推导出来的。\n\n预期校准误差定义为模型的预测置信度与其际准确率之间绝对差异的期望值。ECE 的一种基于直方图的近似由以下公式给出：\n$$ECE = \\sum_{b=0}^{B-1} \\frac{|S_b|}{N} |\\text{Acc}(b) - \\text{Conf}(b)|$$\n此处，置信度范围 $[0, 1]$被划分为 $B$ 个区间。对于每个区间 $b$，$S_b$ 是落入该区间的样本索引集合，$|S_b|$ 是此类样本的数量，$N$ 是样本总数。$\\text{Acc}(b)$ 是区间 $b$ 内预测的平均准确率，$\\text{Conf}(b)$ 是区间 $b$ 内预测的平均置信度。没有样本的区间（$|S_b|=0$）对总和的贡献为 $0$。\n\n为一组给定的 $N$ 个样本计算 ECE 的分步过程如下：\n\n**1. 单样本数据提取**\n对于每个样本 $n \\in \\{1, \\dots, N\\}$，给定一个概率质量函数 (PMF)，即一个类别概率向量 $\\mathbf{p}^{(n)} = (p_1^{(n)}, \\dots, p_K^{(n)})$，以及一个真实类别标签 $y^{(n)}$。由此，我们推导出三个基本量：\n- **置信度**：预测的置信度是 PMF 中的最大概率值。\n  $$c^{(n)} = \\max_{i \\in \\{1, \\dots, K\\}} p_i^{(n)}$$\n- **预测类别**：预测类别是对应于最大概率的类别索引。\n  $$\\hat{y}^{(n)} = \\arg\\max_{i \\in \\{1, \\dots, K\\}} p_i^{(n)}$$\n- **正确性**：正确性是一个二元指示符 $a^{(n)}$，如果预测正确则为 $1$，否则为 $0$。\n  $$a^{(n)} = \\mathbb{I}(\\hat{y}^{(n)} = y^{(n)}) = \\begin{cases} 1  \\text{if } \\hat{y}^{(n)} = y^{(n)} \\\\ 0  \\text{if } \\hat{y}^{(n)} \\neq y^{(n)} \\end{cases}$$\n\n**2. 样本分箱**\n置信度分数 $c^{(n)}$ 是区间 $[0, 1]$ 上的连续值，通过将该区间划分为 $B$ 个等宽的区间来进行离散化。问题指定了一个精确的规则，用于将每个样本 $n$ 分配到一个区间索引 $b^{(n)} \\in \\{0, 1, \\dots, B-1\\}$：\n$$b^{(n)} = \\min\\{\\lfloor B \\cdot c^{(n)} \\rfloor, B-1\\}$$\n此规则将一个置信度 $c^{(n)}$ 正确地映射到一个整数区间索引。例如，对于 $k  B-1$，置信度 $c^{(n)} \\in [k/B, (k+1)/B)$ 会被映射到区间 $k$。由于 `min` 函数的存在，最后一个区间 $[(B-1)/B, 1]$ 内的任何置信度 $c^{(n)}$（包括端点 $c^{(n)}=1$）都会被映射到最后一个区间 $B-1$。\n\n**3. 按区间聚合**\n将所有 $N$ 个样本分配到各自的区间后，我们在每个区间内聚合数据。问题陈述跳过空区间。我们只需考虑样本集 $S_b = \\{n \\mid b^{(n)} = b\\}$ 不为空的非空区间 $b$。对于每个这样的区间，我们计算两个平均值：\n- **区间准确率**：区间 $b$ 的平均准确率是该区间内所有样本的正确性指示符的均值。\n  $$\\text{Acc}(b) = \\frac{1}{|S_b|} \\sum_{n \\in S_b} a^{(n)}$$\n- **区间置信度**：区间 $b$ 的平均置信度是该区间内所有样本的置信度的均值。\n  $$\\text{Conf}(b) = \\frac{1}{|S_b|} \\sum_{n \\in S_b} c^{(n)}$$\n\n**4. 最终 ECE 计算**\n最终的 ECE 值是每个区间的准确率与置信度之间绝对差的加权平均值。区间 $b$ 的权重是落入该区间的样本占总样本的比例，即 $\\frac{|S_b|}{N}$。将所有非空区间的这些加权差值相加，即可得到最终的 ECE，如开头介绍的公式所示。\n\n**实现设计**\n该算法使用 Python 的 `numpy` 库实现，以进行高效的向量化计算。\n- 一个名为 `compute_ece` 的函数封装了其逻辑。它接受一个 PMF 矩阵（样本数 $\\times$ 类别数）、一个真实标签向量和区间数量 $B$ 作为输入。\n- 在此函数内部，使用 `numpy.max(axis=1)` 和 `numpy.argmax(axis=1)` 来同时计算所有样本的置信度和预测类别。\n- 正确性数组通过预测类别和真实标签之间的简单逐元素比较获得。\n- 分箱规则根据公式使用 `numpy.floor` 和 `numpy.minimum` 实现。\n- 为了高效地只处理非空区间，我们可以找出数据中存在的唯一区间索引。对于每个唯一的区间索引，创建一个布尔掩码来选择相关样本。然后使用此掩码计算区间准确率、区间置信度和区间比例。\n- 主函数 `solve` 为五个测试用例中的每一个设置数据，为每个用例调用 `compute_ece` 函数，并收集结果。\n- 最后，将结果格式化为六位小数，并以指定的逗号分隔列表格式打印。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the ECE calculation problem for all test cases specified.\n    \"\"\"\n\n    def compute_ece(pmfs, true_labels, num_bins):\n        \"\"\"\n        Computes the Expected Calibration Error (ECE).\n\n        Args:\n            pmfs (np.ndarray): A 2D array of shape (N, K) where N is the number of samples\n                               and K is the number of classes. Each row is a PMF.\n            true_labels (np.ndarray): A 1D array of shape (N,) containing the true class\n                                      indices for each sample.\n            num_bins (int): The number of bins to use for the ECE calculation.\n\n        Returns:\n            float: The computed ECE value.\n        \"\"\"\n        num_samples = len(true_labels)\n        if num_samples == 0:\n            return 0.0\n\n        # Step 1: Per-Sample Data Extraction\n        confidences = np.max(pmfs, axis=1)\n        predicted_classes = np.argmax(pmfs, axis=1)\n        correctness_arr = (predicted_classes == true_labels).astype(float)\n\n        # Step 2: Binning of Samples\n        # The problem states binning rule: b(n) = min(floor(B*c(n)), B-1)\n        # This handles the edge case c(n)=1.0, where floor(B*1.0) = B\n        bin_indices = np.minimum(np.floor(num_bins * confidences), num_bins - 1).astype(int)\n\n        ece = 0.0\n        \n        # Step 3  4: Per-Bin Aggregation and Final ECE Calculation\n        # Iterate through unique bin indices that are actually populated\n        for b in range(num_bins):\n            in_bin_mask = (bin_indices == b)\n            num_in_bin = np.sum(in_bin_mask)\n            \n            if num_in_bin  0:\n                # Proportion of samples in this bin\n                prop_in_bin = num_in_bin / num_samples\n                \n                # Average accuracy in this bin\n                acc_in_bin = np.mean(correctness_arr[in_bin_mask])\n                \n                # Average confidence in this bin\n                conf_in_bin = np.mean(confidences[in_bin_mask])\n                \n                ece += prop_in_bin * np.abs(acc_in_bin - conf_in_bin)\n        \n        return ece\n\n    # --- Test Case A ---\n    B_a = 10\n    pmf_a1 = np.tile([0.2, 0.2, 0.2, 0.2, 0.2], (25, 1))\n    pmf_a2 = np.tile([0.8, 0.05, 0.05, 0.05, 0.05], (25, 1))\n    pmfs_a = np.vstack((pmf_a1, pmf_a2))\n    labels_a = np.zeros(50, dtype=int)\n    labels_a[5:25] = 1   # 20 samples\n    labels_a[45:50] = 1  # 5 samples\n\n    # --- Test Case B ---\n    B_b = 10\n    pmfs_b = np.tile([0.9, 0.05, 0.05], (20, 1))\n    labels_b = np.zeros(20, dtype=int)\n    labels_b[10:20] = 1\n\n    # --- Test Case C ---\n    B_c = 10\n    pmfs_c = np.tile([0.4, 0.3, 0.3], (20, 1))\n    labels_c = np.zeros(20, dtype=int)\n    labels_c[16:20] = 1\n\n    # --- Test Case D ---\n    B_d = 20\n    pmfs_d = np.array([\n        [0.51, 0.49, 0.0, 0.0],\n        [0.99, 0.01, 0.0, 0.0],\n        [0.0, 0.34, 0.33, 0.33],\n        [0.0, 0.26, 0.25, 0.49]\n    ])\n    labels_d = np.array([0, 1, 1, 2])\n\n    # --- Test Case E ---\n    B_e = 15\n    pmfs_e = np.array([\n        [1.0, 0.0, 0.0],\n        [1.0, 0.0, 0.0],\n        [0.0, 1.0, 0.0],\n        [0.0, 1.0, 0.0]\n    ])\n    labels_e = np.array([0, 1, 1, 2])\n\n    test_cases = [\n        (pmfs_a, labels_a, B_a),\n        (pmfs_b, labels_b, B_b),\n        (pmfs_c, labels_c, B_c),\n        (pmfs_d, labels_d, B_d),\n        (pmfs_e, labels_e, B_e),\n    ]\n\n    results = []\n    for pmfs, labels, b_val in test_cases:\n        ece_val = compute_ece(pmfs, labels, b_val)\n        results.append(ece_val)\n\n    # Format output as required: rounded to 6 decimal places, no spaces.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "校准的概念同样适用于预测连续值的回归模型，其输出是概率密度函数（$PDF$）。本实践将介绍一个强大的工具——概率积分变换（$PIT$），它揭示了任何连续随机变量的累积分布函数（$CDF$）与均匀分布之间的深刻联系。你将利用这一原理，通过假设检验来评估概率回归模型的预测分布是否经过良好校准，从而将校准分析从离散领域扩展到连续领域。",
            "id": "3166216",
            "problem": "给定一个在深度学习中使用的条件回归设置，其中一个由 $\\theta$ 参数化的模型会为给定特征 $X$ 的连续目标变量 $Y$ 输出一个预测性的累积分布函数 (CDF) $F_{\\theta}(y \\mid x)$。概率积分变换 (PIT) 将一个观测值映射为 $u = F_{\\theta}(Y \\mid X)$。如果预测分布被正确校准，那么 $U = F_{\\theta}(Y \\mid X)$ 在给定 $X$ 的条件下在 $[0,1]$ 上服从条件均匀分布，因此在 $[0,1]$ 上服从无条件均匀分布。你的任务是通过使用无分布假设检验来测试 $U$ 的均匀性，从而实现校准检验。\n\n从以下基本基础开始：\n- 概率密度函数 (PDF) $f(y)$ 满足 $\\int_{-\\infty}^{\\infty} f(y) \\, dy = 1$ 和 $f(y) \\ge 0$。\n- 概率质量函数 (PMF) $p(y)$ 满足 $\\sum_{y} p(y) = 1$ 和 $p(y) \\ge 0$。\n- 对于连续随机变量，累积分布函数 (CDF) $F(y)$ 满足 $F(y) = \\int_{-\\infty}^{y} f(t) \\, dt$，它是非递减、右连续的，并且 $\\lim_{y \\to -\\infty} F(y) = 0$，$\\lim_{y \\to \\infty} F(y) = 1$。\n- 对于条件分布，条件 CDF $F(y \\mid x)$ 对每个固定的 $x$ 都遵循相同的性质。\n- 概率积分变换 (PIT) 指出，如果 $Y \\mid X$ 的 CDF $F(y \\mid x)$ 对于每个固定的 $x$ 在 $y$ 上是连续且严格递增的，那么 $U = F(Y \\mid X)$ 在给定 $X$ 的条件下在 $[0,1]$ 上服从条件均匀分布，因此在 $[0,1]$ 上服从无条件均匀分布。\n\n你必须在四个测试案例中为一个高斯预测模型实现以下校准检验。在每个案例中，首先通过抽样 $n$ 个独立特征 $X_i$，然后从一个真实条件正态分布中抽样目标 $Y_i$ 来生成数据。评估模型的预测 CDF $F_{\\theta}(Y_i \\mid X_i)$ 并计算 PIT 值 $U_i = F_{\\theta}(Y_i \\mid X_i)$。然后对经验性的 $\\{U_i\\}$ 与 $[0,1]$ 上的标准均匀分布执行 Kolmogorov–Smirnov (KS) 检验以获得一个 $p$ 值。最后，为每个案例返回一个布尔值，指示校准是否“通过”，定义为 KS 检验在显著性水平 $\\alpha$ 下不拒绝均匀性（即 $p \\ge \\alpha$）的事件。\n\n使用以下参数化测试套件。在所有情况下，使用 $n = 500$ 个样本，并将显著性水平设置为 $\\alpha = 0.05$。让 $\\Phi$ 表示标准正态 CDF，并在每个案例中，使用指定预测均值 $\\mu_{\\theta}(x)$ 和预测标准差 $\\sigma_{\\theta}(x)$ 计算的高斯预测 CDF $F_{\\theta}(y \\mid x) = \\Phi\\!\\big((y - \\mu_{\\theta}(x))/\\sigma_{\\theta}(x)\\big)$。\n\n- 案例 1（良好校准的“理想情况”）：\n  - 特征生成：$X \\sim \\mathcal{N}(0,1)$。\n  - 真实情况：$Y \\mid X=x \\sim \\mathcal{N}(a_{\\text{true}} x + b_{\\text{true}}, \\sigma_{\\text{true}}^2)$，其中 $a_{\\text{true}} = 1.0$, $b_{\\text{true}} = 0.5$, $\\sigma_{\\text{true}} = 0.8$。\n  - 预测模型：$\\mu_{\\theta}(x) = a_{\\text{pred}} x + b_{\\text{pred}}$，其中 $a_{\\text{pred}} = 1.0$, $b_{\\text{pred}} = 0.5$；$\\sigma_{\\theta}(x) = \\sigma_{\\text{pred}}$，其中 $\\sigma_{\\text{pred}} = 0.8$。\n\n- 案例 2（方差未校准：预测方差过小）：\n  - 特征生成：$X \\sim \\mathcal{N}(0,1)$。\n  - 真实情况：$Y \\mid X=x \\sim \\mathcal{N}(a_{\\text{true}} x + b_{\\text{true}}, \\sigma_{\\text{true}}^2)$，其中 $a_{\\text{true}} = 1.0$, $b_{\\text{true}} = 0.5$, $\\sigma_{\\text{true}} = 1.2$。\n  - 预测模型：$\\mu_{\\theta}(x) = a_{\\text{pred}} x + b_{\\text{pred}}$，其中 $a_{\\text{pred}} = 1.0$, $b_{\\text{pred}} = 0.5$；$\\sigma_{\\theta}(x) = \\sigma_{\\text{pred}}$，其中 $\\sigma_{\\text{pred}} = 0.6$。\n\n- 案例 3（均值未校准：预测偏差）：\n  - 特征生成：$X \\sim \\mathcal{N}(0,1)$。\n  - 真实情况：$Y \\mid X=x \\sim \\mathcal{N}(a_{\\text{true}} x + b_{\\text{true}}, \\sigma_{\\text{true}}^2)$，其中 $a_{\\text{true}} = 1.0$, $b_{\\text{true}} = 0.5$, $\\sigma_{\\text{true}} = 0.8$。\n  - 预测模型：$\\mu_{\\theta}(x) = a_{\\text{pred}} x + b_{\\text{pred}}$，其中 $a_{\\text{pred}} = 1.0$, $b_{\\text{pred}} = -0.5$；$\\sigma_{\\theta}(x) = \\sigma_{\\text{pred}}$，其中 $\\sigma_{\\text{pred}} = 0.8$。\n\n- 案例 4（异方差未校准：真实噪声依赖于 $x$ 但预测噪声为常数）：\n  - 特征生成：$X \\sim \\mathcal{N}(0,1)$。\n  - 真实情况：$Y \\mid X=x \\sim \\mathcal{N}(a_{\\text{true}} x + b_{\\text{true}}, \\sigma_{\\text{true}}(x)^2)$，其中 $a_{\\text{true}} = 1.0$, $b_{\\text{true}} = 0.5$，以及 $\\sigma_{\\text{true}}(x) = 0.5 + 0.7 \\lvert x \\rvert$。\n  - 预测模型：$\\mu_{\\theta}(x) = a_{\\text{pred}} x + b_{\\text{pred}}$，其中 $a_{\\text{pred}} = 1.0$, $b_{\\text{pred}} = 0.5$；$\\sigma_{\\theta}(x) = \\sigma_{\\text{pred}}$，其中 $\\sigma_{\\text{pred}} = 0.8$。\n\n你的程序必须：\n- 为保证可复现性，使用固定的随机种子。\n- 对每个案例，生成 $\\{(X_i, Y_i)\\}_{i=1}^{n}$，计算 $U_i = F_{\\theta}(Y_i \\mid X_i)$，对 $[0,1]$ 上的均匀分布执行 Kolmogorov–Smirnov (KS) 检验，并在显著性水平 $\\alpha$ 下判断通过/失败。\n- 生成一行输出，包含按案例顺序排列的四个布尔结果，格式为用方括号括起来的逗号分隔列表（例如，$\\texttt{[True,False,True,False]}$）。不应打印任何其他文本。\n\n以上所有数量和参数都是无量纲的；不涉及物理单位。返回的布尔值是测试套件的最终答案。",
            "solution": "用户提供了一个有效的问题陈述。\n\n该问题要求为一系列概率回归模型实现一个校准检验。所检验的核心原理是概率积分变换 (PIT)，这是评估预测分布校准度的一个基本工具。\n\n根据 PIT，如果一个连续随机变量 $Y$ 的累积分布函数 (CDF) 为 $F_Y(y)$，那么随机变量 $U = F_Y(Y)$ 服从区间 $[0, 1]$ 上的标准均匀分布。这一原理可以扩展到条件设置中。如果一个预测模型为给定特征 $X$ 的目标 $Y$ 提供了一个条件 CDF $F_{\\theta}(y \\mid x)$，并且这个模型是完美校准的（即，$F_{\\theta}$ 是 $Y$ 在给定 $X$ 下的真实条件 CDF），那么变换后的变量 $U = F_{\\theta}(Y \\mid X)$ 将在 $[0, 1]$ 上均匀分布。\n\n我们可以通过从观测数据集 $\\{(X_i, Y_i)\\}_{i=1}^n$ 生成一组 PIT 值 $\\{U_i\\}_{i=1}^n$，然后对样本 $\\{U_i\\}$ 进行均匀性统计检验，来测试未校准情况。对此，一个常见的选择是无分布的 Kolmogorov-Smirnov (KS) 检验。KS 检验的原假设 $H_0$ 是 PIT 值来自标准均匀分布。如果我们得到一个小的 $p$ 值（通常小于选定的显著性水平 $\\alpha$），我们就拒绝 $H_0$ 并断定模型未校准。如果 $p$ 值不小（$p \\ge \\alpha$），我们则没有足够的证据拒绝良好校准的假设。\n\n四个测试案例中每个案例的流程如下：\n1.  **设置全局参数**：将样本大小固定为 $n=500$，假设检验的显著性水平固定为 $\\alpha=0.05$。使用固定的随机种子以确保可复现性。\n2.  **生成数据**：对每个案例，我们模拟一个大小为 $n$ 的数据集。\n    a. 我们首先从标准正态分布中抽取 $n$ 个独立的特征样本 $X_i$，即 $X_i \\sim \\mathcal{N}(0, 1)$。\n    b. 对每个 $X_i$，我们从指定的“真实”条件正态分布中抽取一个对应的目标值 $Y_i$。该分布的均值和方差是每个案例中定义的 $X_i$ 的函数。\n3.  **计算 PIT 值**：对于每个数据对 $(X_i, Y_i)$，我们计算 PIT 值 $U_i = F_{\\theta}(Y_i \\mid X_i)$。预测模型的 CDF，$F_{\\theta}$，被给定为一个高斯分布，$F_{\\theta}(y \\mid x) = \\Phi\\left(\\frac{y - \\mu_{\\theta}(x)}{\\sigma_{\\theta}(x)}\\right)$，其中 $\\Phi$ 是标准正态 CDF，而 $\\mu_{\\theta}(x)$ 和 $\\sigma_{\\theta}(x)$ 是为该案例指定的预测均值和标准差。\n4.  **执行 KS 检验**：将得到的 PIT 值样本 $\\{U_i\\}_{i=1}^n$ 与理论上的标准均匀分布 $\\mathcal{U}[0, 1]$ 进行单样本 Kolmogorov-Smirnov 检验。此检验会产生一个 $p$ 值。\n5.  **做出决策**：我们将 $p$ 值与显著性水平 $\\alpha$ 进行比较。如果原假设未被拒绝，即 $p \\ge \\alpha$，则认为校准“通过”（返回 `True`）。否则，模型被视为未校准并“失败”（返回 `False`）。\n\n我们现在将此流程应用于四个案例中的每一个。\n\n**案例 1：良好校准的模型**\n- 预测模型的参数（$\\mu_{\\theta}(x) = 1.0x + 0.5$, $\\sigma_{\\theta}(x) = 0.8$）与真实数据生成过程的参数完全匹配。\n- 因此，$F_{\\theta}(y \\mid x)$ 是真实的条件 CDF。\n- 根据 PIT 性质，得到的样本 $\\{U_i\\}$ 应该与标准均匀样本无法区分。\n- 我们期望 KS 检验会产生一个高的 $p$ 值，从而得出校准通过的结论（$p \\ge 0.05$）。\n\n**案例 2：方差未校准**\n- 预测模型使用 $\\sigma_{\\theta}(x) = 0.6$，而真实数据的 $\\sigma_{\\text{true}} = 1.2$。\n- 模型的预测方差过小，使其过分自信。观测值 $Y_i$ 将倾向于出现在狭窄预测分布的尾部。\n- 标准化残差 $Z_i = (Y_i - \\mu_{\\theta}(X_i))/\\sigma_{\\theta}(X_i)$ 的方差将大于 1。\n- 应用标准正态 CDF，$\\Phi(Z_i)$，将产生聚集在 0 和 1 附近的 PIT 值 $U_i$，形成一个 U 形分布。这不是均匀分布。\n- 我们期望 KS 检验能够检测到这种偏差，产生一个非常小的 $p$ 值，从而校准检验失败（$p  0.05$）。\n\n**案例 3：均值未校准**\n- 预测模型使用一个有偏的均值，$\\mu_{\\theta}(x) = 1.0x - 0.5$，而真实均值是 $\\mu_{\\text{true}}(x) = 1.0x + 0.5$。模型系统性地偏低了 1.0。\n- 标准化残差 $Z_i = (Y_i - \\mu_{\\theta}(X_i))/\\sigma_{\\theta}(X_i)$ 将有一个非零均值。具体来说，$Z_i$ 的均值将是 $(\\mu_{\\text{true}}(X_i) - \\mu_{\\theta}(X_i)) / \\sigma_{\\theta}(X_i) = (1.0x_i + 0.5 - (1.0x_i - 0.5)) / 0.8 = 1.0 / 0.8 = 1.25$。\n- PIT 值 $U_i = \\Phi(Z_i)$ 将来自一个向 1 倾斜的分布。这不是均匀分布。\n- 我们期望 KS 检验会拒绝均匀性，导致失败（$p  0.05$）。\n\n**案例 4：异方差未校准**\n- 真实数据生成过程的标准差依赖于特征，$\\sigma_{\\text{true}}(x) = 0.5 + 0.7|x|$。这是一个异方差模型。\n- 预测模型错误地假设了一个恒定的标准差（同方差性），$\\sigma_{\\theta}(x) = 0.8$。\n- 均值被正确指定，因此标准化残差 $Z_i = (Y_i - \\mu_{\\theta}(X_i))/\\sigma_{\\theta}(X_i)$ 的均值为 0。然而，它们的条件方差是 $\\text{Var}(Z_i \\mid X_i) = \\sigma_{\\text{true}}(X_i)^2 / \\sigma_{\\theta}(X_i)^2 = (0.5 + 0.7|X_i|)^2 / 0.8^2$。\n- 这个方差不是恒定的，也不等于 1。收集到的 $\\{Z_i\\}$ 的无条件分布将是具有不同方差的正态分布的混合，这并非标准正态分布。通常，它将是尖峰（重尾）的。\n- PIT 值 $U_i = \\Phi(Z_i)$ 将再次形成一个非均匀的、U 形的分布。\n- 我们期望 KS 检验能检测到这种模型设定错误，并使校准检验失败（$p  0.05$）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, kstest\n\ndef solve():\n    \"\"\"\n    Performs a calibration check for four probabilistic regression model scenarios.\n\n    For each case, it generates data, computes Probability Integral Transform (PIT)\n    values using a predictive model, and performs a Kolmogorov-Smirnov (KS) test\n    for uniformity. The result is a boolean indicating if the calibration check\n    \"passes\" (i.e., the KS test p-value is greater than or equal to alpha).\n    \"\"\"\n\n    # Global parameters\n    n = 500  # Sample size\n    alpha = 0.05  # Significance level\n    random_seed = 42\n\n    # Set the random seed for reproducibility\n    np.random.seed(random_seed)\n\n    # Define the four test cases using parameter dictionaries\n    test_cases = [\n        # Case 1 (well-calibrated \"happy path\")\n        {\n            \"description\": \"Well-calibrated\",\n            \"a_true\": 1.0, \"b_true\": 0.5, \"sigma_true_func\": lambda x: np.full_like(x, 0.8),\n            \"a_pred\": 1.0, \"b_pred\": 0.5, \"sigma_pred_const\": 0.8,\n        },\n        # Case 2 (variance miscalibration: predictive variance too small)\n        {\n            \"description\": \"Variance miscalibrated (underestimated)\",\n            \"a_true\": 1.0, \"b_true\": 0.5, \"sigma_true_func\": lambda x: np.full_like(x, 1.2),\n            \"a_pred\": 1.0, \"b_pred\": 0.5, \"sigma_pred_const\": 0.6,\n        },\n        # Case 3 (mean miscalibration: predictive bias)\n        {\n            \"description\": \"Mean miscalibrated (bias)\",\n            \"a_true\": 1.0, \"b_true\": 0.5, \"sigma_true_func\": lambda x: np.full_like(x, 0.8),\n            \"a_pred\": 1.0, \"b_pred\": -0.5, \"sigma_pred_const\": 0.8,\n        },\n        # Case 4 (heteroscedastic miscalibration)\n        {\n            \"description\": \"Heteroscedastic miscalibrated\",\n            \"a_true\": 1.0, \"b_true\": 0.5, \"sigma_true_func\": lambda x: 0.5 + 0.7 * np.abs(x),\n            \"a_pred\": 1.0, \"b_pred\": 0.5, \"sigma_pred_const\": 0.8,\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Step 1: Generate data\n        # Generate features X from a standard normal distribution\n        X = np.random.normal(loc=0.0, scale=1.0, size=n)\n\n        # Generate targets Y from the ground-truth conditional distribution\n        mu_true = case[\"a_true\"] * X + case[\"b_true\"]\n        sigma_true = case[\"sigma_true_func\"](X)\n        Y = np.random.normal(loc=mu_true, scale=sigma_true)\n\n        # Step 2: Compute PIT values using the predictive model\n        # Calculate predictive mean and standard deviation\n        mu_pred = case[\"a_pred\"] * X + case[\"b_pred\"]\n        sigma_pred = case[\"sigma_pred_const\"]\n\n        # Standardize the observations according to the predictive model\n        z_scores = (Y - mu_pred) / sigma_pred\n\n        # Apply the standard normal CDF to get PIT values\n        pit_values = norm.cdf(z_scores)\n\n        # Step 3: Perform Kolmogorov-Smirnov test for uniformity\n        # H0: The pit_values are drawn from a standard uniform distribution\n        ks_statistic, p_value = kstest(pit_values, 'uniform')\n\n        # Step 4: Decide if calibration passes\n        # Calibration passes if we do not reject H0 at significance level alpha\n        passes_calibration = (p_value = alpha)\n        results.append(passes_calibration)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}