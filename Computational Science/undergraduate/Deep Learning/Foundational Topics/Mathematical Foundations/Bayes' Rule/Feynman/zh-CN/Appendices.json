{
    "hands_on_practices": [
        {
            "introduction": "本练习将带你回到贝叶斯规则的核心：根据新证据更新我们的信念。我们将探讨一个关于数字内存设备读取错误的假设场景，其中我们有一个关于存储位的先验知识，然后我们观察到一个不确定的结果（“擦除”）。通过这个练习，你将实践如何运用贝叶斯公式，结合先验概率和似然函数，来精确计算后验概率，从而牢固掌握基本计算流程。",
            "id": "1603705",
            "problem": "一个数字存储设备以二进制比特序列的形式存储数据。设源比特（由随机变量 $X$ 表示）为 $0$ 或 $1$。通过对数据模式的广泛分析，已知一个比特为 $0$ 的先验概率是 $P(X=0) = \\alpha$。\n\n从设备中读取一个比特时，接收到的符号（由 $Y$ 表示）可能出现三种结果之一：该比特被正确读取为 $0$，正确读取为 $1$，或者读取操作失败，导致一个“擦除”符号，我们记为 '?'。该设备的设计使得它从不翻转比特；存储的 $0$ 永远不会被读取为 $1$，存储的 $1$ 也永远不会被读取为 $0$。\n\n然而，读取操作的可靠性取决于存储的值。当存储的比特为 $0$ 时发生擦除的概率是 $P(Y='?'|X=0) = p_0$。当存储的比特为 $1$ 时发生擦除的概率是 $P(Y='?'|X=1) = p_1$。\n\n假设从设备中读取一个比特，结果是一个擦除符号 '?'。确定设备中最初存储的比特是 $0$ 的后验概率。请用 $\\alpha$、$p_0$ 和 $p_1$ 给出一个单一的封闭形式解析表达式作为你的答案。",
            "solution": "我们被要求计算在接收到的符号是擦除的情况下，存储的比特是 $0$ 的后验概率。这可以写作 $P(X=0 | Y='?')$。\n\n为了解决这个问题，我们应用贝叶斯定理，其表述如下：\n$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n\n在我们的问题背景下，设事件 $A$ 为 $X=0$（存储的比特是 0），事件 $B$ 为 $Y='?'$（观察到擦除）。将这些代入贝叶斯定理，我们得到：\n$$ P(X=0 | Y='?') = \\frac{P(Y='?' | X=0) \\cdot P(X=0)}{P(Y='?')} $$\n\n问题提供了以下值：\n- $P(X=0) = \\alpha$\n- $P(Y='?' | X=0) = p_0$\n\n我们唯一需要计算的项是观察到擦除的总概率，即 $P(Y='?')$。我们可以使用全概率公式来计算它，对 $X$ 的所有可能输入求和：\n$$ P(Y='?') = P(Y='?' | X=0) \\cdot P(X=0) + P(Y='?' | X=1) \\cdot P(X=1) $$\n\n我们已知 $P(X=0) = \\alpha$，这意味着存储的比特为 $1$ 的概率是 $P(X=1) = 1 - P(X=0) = 1 - \\alpha$。我们还已知条件概率 $P(Y='?' | X=1) = p_1$。\n\n现在，我们可以将所有已知概率代入 $P(Y='?')$ 的表达式中：\n$$ P(Y='?') = (p_0) \\cdot (\\alpha) + (p_1) \\cdot (1 - \\alpha) $$\n$$ P(Y='?') = \\alpha p_0 + p_1(1-\\alpha) $$\n\n有了 $P(Y='?')$ 的表达式，我们现在可以使用贝叶斯定理完成目标后验概率的计算：\n$$ P(X=0 | Y='?') = \\frac{P(Y='?' | X=0) \\cdot P(X=0)}{P(Y='?')} $$\n$$ P(X=0 | Y='?') = \\frac{p_0 \\cdot \\alpha}{\\alpha p_0 + p_1(1-\\alpha)} $$\n\n这就是在观察到擦除的情况下，存储的比特是 $0$ 的后验概率的最终表达式。",
            "answer": "$$\\boxed{\\frac{\\alpha p_0}{\\alpha p_0 + p_1(1-\\alpha)}}$$"
        },
        {
            "introduction": "在掌握了基本计算后，让我们来看一个贝叶斯规则在现实世界中至关重要的应用：医学诊断测试。这个练习将揭示一个深刻且往往有违直觉的现象，即基础概率（或称“患病率”）如何极大地影响一个诊断测试的预测价值。通过分析在不同患病率环境下同一测试的表现，你将深刻理解“基础概率谬误”的成因及其在数据解读中的重要性。",
            "id": "2523977",
            "problem": "一家医院的实验室正在评估一种新的聚合酶链式反应 (PCR) 检测方法，用于筛查耐碳青霉烯类肠杆菌科细菌 (CRE)。该检测方法具有经验证实的灵敏度和特异度，并假设这些值在不同环境中保持不变。感染控制团队计划在两种截然不同的环境中使用同一种检测方法：一个低患病率的社区筛查项目，以及一个高患病率的疫情病房。您的目标是仅使用核心定义和贝叶斯定理，判断哪些陈述必然为真，并借此解释为何阳性预测值和阴性预测值并非检测方法的内在属性。\n\n使用的基础概念：\n- 灵敏度是 $P(T^{+}\\mid D)$。\n- 特异度是 $P(T^{-}\\mid \\bar D)$。\n- 患病率是 $P(D)$，记为 $\\pi$。\n- 阳性预测值 (PPV) 是 $P(D\\mid T^{+})$。\n- 阴性预测值 (NPV) 是 $P(\\bar D\\mid T^{-})$。\n- 贝叶斯定理将 $P(D\\mid T^{+})$ 与 $P(T^{+}\\mid D)$、$P(D)$ 和 $P(T^{+})$ 联系起来。\n\n假设以下经验证实的检验特性在两种环境中都相同：灵敏度 $Se = 0.90$，特异度 $Sp = 0.995$。社区项目筛查的是无症状人群，其患病率 $\\pi = 0.0005$（即 $0.05\\%$）。疫情病房筛查的是高风险人群，其患病率 $\\pi = 0.20$（即 $20\\%$）。\n\n下列哪些陈述是正确的？\n\nA. 因为灵敏度和特异度是检测方法的内在属性，在不同环境中不会改变，所以当特异度很高时，阳性预测值等于灵敏度，因此 PPV 与患病率无关。\n\nB. 使用贝叶斯定理，并将检验前概率设为患病率 $\\pi$，则阳性预测值满足 $PPV = \\dfrac{Se\\cdot \\pi}{Se\\cdot \\pi + (1-Sp)\\cdot (1-\\pi)}$，阴性预测值满足 $NPV = \\dfrac{Sp\\cdot (1-\\pi)}{Sp\\cdot (1-\\pi) + (1-Se)\\cdot \\pi}$，这使得 PPV 和 NPV 都是 $\\pi$ 的显式函数。\n\nC. 当 $Se=0.90$ 和 $Sp=0.995$ 时，在患病率 $\\pi=0.0005$ 的社区项目中，$PPV \\approx 0.083$（约 $8.3\\%$），而在患病率 $\\pi=0.20$ 的疫情病房中，$PPV \\approx 0.978$（约 $97.8\\%$）；这种差异完全由不同的患病率引起。\n\nD. 随着患病率趋近于 $0$，阴性预测值趋近于灵敏度，因为阴性结果主要由 $Se$ 决定的真阴性所主导。\n\nE. 在保持 $Se$ 和 $Sp$ 不变的情况下，当 $\\pi \\to 0$ 时，有 $PPV \\to 0$ 和 $NPV \\to 1$；当 $\\pi \\to 1$ 时，有 $PPV \\to 1$ 和 $NPV \\to 0$；因此 PPV 和 NPV 并非检测方法的内在属性。\n\nF. 因为（阳性和阴性）似然比（likelihood ratio, LR）是检测方法的内在属性，所以 PPV 和 NPV 都是内在的，且与患病率无关。\n\nG. 筛查中的基率谬误源于将 $P(T^{+}\\mid D)$ 与 $P(D\\mid T^{+})$ 相混淆；在极低的 $\\pi$ 值下，即使有很高的 $Sp$ 和 $Se$，也可能得出较低的 PPV，因为来自庞大非患病群体的假阳性数量超过了真阳性数量。",
            "solution": "题干的陈述在科学上是合理且严谨的。它提供了清晰的定义和所有评估这些论断所需的数据。它描述了一个临床微生物学中的真实场景，其核心在于正确应用概率论，特别是贝叶斯定理，于诊断检验中。因此，我们着手进行推导和分析。\n\n令 $D$ 表示受试者患有该疾病（是 CRE 携带者）的事件，$\\bar D$ 表示受试者未患该疾病的事件。令 $T^{+}$ 表示检验结果为阳性的事件， $T^{-}$ 表示检验结果为阴性的事件。\n\n提供的定义如下：\n- 灵敏度：$Se = P(T^{+} \\mid D)$\n- 特异度：$Sp = P(T^{-} \\mid \\bar D)$\n- 患病率：$\\pi = P(D)$\n- 阳性预测值 (PPV)：$P(D \\mid T^{+})$\n- 阴性预测值 (NPV)：$P(\\bar D \\mid T^{-})$\n\n题目要求根据这些定义、贝叶斯定理以及给定的数值：$Se = 0.90$、$Sp = 0.995$ 和两个患病率值 $\\pi_1 = 0.0005$ 及 $\\pi_2 = 0.20$，来判断哪些陈述是正确的。\n\n我们的首要任务是推导出 PPV 和 NPV 作为 $Se$、$Sp$ 和 $\\pi$ 的显式表达式。\n\n**阳性预测值 (PPV) 的推导**\n根据定义，$PPV = P(D \\mid T^{+})$。使用贝叶斯定理：\n$$PPV = \\frac{P(T^{+} \\mid D) P(D)}{P(T^{+})}$$\n阳性检验的总概率 $P(T^{+})$ 由全概率定律给出：\n$$P(T^{+}) = P(T^{+} \\mid D) P(D) + P(T^{+} \\mid \\bar D) P(\\bar D)$$\n我们代入给定的定义和关系：$P(T^{+} \\mid D) = Se$，$P(D) = \\pi$，$P(\\bar D) = 1 - \\pi$，以及 $P(T^{+} \\mid \\bar D) = 1 - P(T^{-} \\mid \\bar D) = 1 - Sp$。\n$$P(T^{+}) = Se \\cdot \\pi + (1 - Sp)(1 - \\pi)$$\n将此代入 PPV 的贝叶斯定理表达式，我们得到：\n$$PPV = \\frac{Se \\cdot \\pi}{Se \\cdot \\pi + (1 - Sp)(1 - \\pi)}$$\n\n**阴性预测值 (NPV) 的推导**\n根据定义，$NPV = P(\\bar D \\mid T^{-})$。使用贝叶斯定理：\n$$NPV = \\frac{P(T^{-} \\mid \\bar D) P(\\bar D)}{P(T^{-})}$$\n阴性检验的总概率 $P(T^{-})$ 为：\n$$P(T^{-}) = P(T^{-} \\mid \\bar D) P(\\bar D) + P(T^{-} \\mid D) P(D)$$\n我们代入给定的定义和关系：$P(T^{-} \\mid \\bar D) = Sp$，$P(\\bar D) = 1 - \\pi$，$P(D) = \\pi$，以及 $P(T^{-} \\mid D) = 1 - P(T^{+} \\mid D) = 1 - Se$。\n$$P(T^{-}) = Sp \\cdot (1 - \\pi) + (1 - Se) \\cdot \\pi$$\n将此代入 NPV 的贝叶斯定理表达式，我们得到：\n$$NPV = \\frac{Sp \\cdot (1 - \\pi)}{Sp \\cdot (1 - \\pi) + (1 - Se) \\cdot \\pi}$$\n\n这些推导证实了 PPV 和 NPV 都是患病率 $\\pi$ 的显式函数。现在我们来评估每个陈述。\n\n**A. 因为灵敏度和特异度是检测方法的内在属性，在不同环境中不会改变，所以当特异度很高时，阳性预测值等于灵敏度，因此 PPV 与患病率无关。**\n这个陈述有根本性的错误。PPV，$P(D \\mid T^{+})$，和灵敏度，$P(T^{+} \\mid D)$，是不同事件的概率。将它们混为一谈是一种被称为基率谬误的逻辑错误。推导出的 PPV 公式清楚地显示了它对患病率 $\\pi$ 的依赖性。声称 $PPV$ 等于 $Se$ 是错误的。例如，如果我们假设一个完美的检验，其中 $Se=1$ 且 $Sp=1$，公式会给出 $PPV = \\frac{1 \\cdot \\pi}{1 \\cdot \\pi + 0 \\cdot (1-\\pi)} = 1$，这不一定等于 $Se$。整个陈述都是不正确的。\n**结论：错误。**\n\n**B. 使用贝叶斯定理，并将检验前概率设为患病率 $\\pi$，则阳性预测值满足 $PPV = \\dfrac{Se\\cdot \\pi}{Se\\cdot \\pi + (1-Sp)\\cdot (1-\\pi)}$，阴性预测值满足 $NPV = \\dfrac{Sp\\cdot (1-\\pi)}{Sp\\cdot (1-\\pi) + (1-Se)\\cdot \\pi}$，这使得 PPV 和 NPV 都是 $\\pi$ 的显式函数。**\n这个陈述中给出的公式与我们使用贝叶斯定理从第一性原理推导出的公式完全相同。其结论，即 PPV 和 NPV 都是 $\\pi$ 的显式函数，是这些公式的直接结果。这个陈述是对数学关系的正确表述。\n**结论：正确。**\n\n**C. 当 $Se=0.90$ 和 $Sp=0.995$ 时，在患病率 $\\pi=0.0005$ 的社区项目中，$PPV \\approx 0.083$（约 $8.3\\%$），而在患病率 $\\pi=0.20$ 的疫情病房中，$PPV \\approx 0.978$（约 $97.8\\%$）；这种差异完全由不同的患病率引起。**\n我们必须使用推导出的 PPV 公式和给定的数据进行计算。\n对于患病率 $\\pi_1 = 0.0005$ 的社区项目：\n$$PPV_1 = \\frac{0.90 \\cdot 0.0005}{0.90 \\cdot 0.0005 + (1 - 0.995)(1 - 0.0005)} = \\frac{0.00045}{0.00045 + (0.005)(0.9995)} = \\frac{0.00045}{0.00045 + 0.0049975} = \\frac{0.00045}{0.0054475} \\approx 0.082606...$$\n这个值约等于 $0.083$，即 $8.3\\%$。计算是正确的。\n对于患病率 $\\pi_2 = 0.20$ 的疫情病房：\n$$PPV_2 = \\frac{0.90 \\cdot 0.20}{0.90 \\cdot 0.20 + (1 - 0.995)(1 - 0.20)} = \\frac{0.18}{0.18 + (0.005)(0.80)} = \\frac{0.18}{0.18 + 0.004} = \\frac{0.18}{0.184} \\approx 0.97826...$$\n这个值约等于 $0.978$，即 $97.8\\%$。计算也是正确的。\n由于 $Se$ 和 $Sp$ 保持不变，PPV 的巨大差异确实完全是由患病率 $\\pi$ 的变化引起的。该陈述是正确的。\n**结论：正确。**\n\n**D. 随着患病率趋近于 $0$，阴性预测值趋近于灵敏度，因为阴性结果主要由 $Se$ 决定的真阴性所主导。**\n我们分析当 $\\pi \\to 0$ 时 NPV 的极限：\n$$\\lim_{\\pi \\to 0} NPV = \\lim_{\\pi \\to 0} \\frac{Sp \\cdot (1 - \\pi)}{Sp \\cdot (1 - \\pi) + (1 - Se) \\cdot \\pi} = \\frac{Sp \\cdot (1 - 0)}{Sp \\cdot (1 - 0) + (1 - Se) \\cdot 0} = \\frac{Sp}{Sp} = 1$$\nNPV 趋近于 $1$（或 $100\\%$），而不是灵敏度 ($Se$)。此外，其理由也是不正确的：真阴性与特异度（$Sp$，通过 $P(T^{-} \\mid \\bar D)$）相关，而不是灵敏度（$Se$，通过 $P(T^{+} \\mid D)$）。该陈述的论点和论据都是错误的。\n**结论：错误。**\n\n**E. 在保持 $Se$ 和 $Sp$ 不变的情况下，当 $\\pi \\to 0$ 时，有 $PPV \\to 0$ 和 $NPV \\to 1$；当 $\\pi \\to 1$ 时，有 $PPV \\to 1$ 和 $NPV \\to 0$；因此 PPV 和 NPV 并非检测方法的内在属性。**\n我们评估所述的极限。\n当 $\\pi \\to 0$ 时：\n$$ \\lim_{\\pi \\to 0} PPV = \\lim_{\\pi \\to 0} \\frac{Se \\cdot \\pi}{Se \\cdot \\pi + (1 - Sp)(1 - \\pi)} = \\frac{Se \\cdot 0}{Se \\cdot 0 + (1 - Sp) \\cdot 1} = 0 $$\n$$ \\lim_{\\pi \\to 0} NPV = \\lim_{\\pi \\to 0} \\frac{Sp \\cdot (1 - \\pi)}{Sp \\cdot (1 - \\pi) + (1 - Se) \\cdot \\pi} = \\frac{Sp \\cdot 1}{Sp \\cdot 1 + (1 - Se) \\cdot 0} = 1 $$\n当 $\\pi \\to 1$ 时：\n$$ \\lim_{\\pi \\to 1} PPV = \\lim_{\\pi \\to 1} \\frac{Se \\cdot \\pi}{Se \\cdot \\pi + (1 - Sp)(1 - \\pi)} = \\frac{Se \\cdot 1}{Se \\cdot 1 + (1 - Sp) \\cdot 0} = 1 $$\n$$ \\lim_{\\pi \\to 1} NPV = \\lim_{\\pi \\to 1} \\frac{Sp \\cdot (1 - \\pi)}{Sp \\cdot (1 - \\pi) + (1 - Se) \\cdot \\pi} = \\frac{Sp \\cdot 0}{Sp \\cdot 0 + (1 - Se) \\cdot 1} = 0 $$\n所有四个极限都陈述正确（假设是一个不完美的检验，其中 $Se  1$ 且 $Sp  1$）。由于 PPV 和 NPV 随患病率 $\\pi$ 发生巨大变化，它们不是检验本身的内在属性，而是应用于特定人群时检验的属性。该结论直接源于此分析。\n**结论：正确。**\n\n**F. 因为（阳性和阴性）似然比（likelihood ratio, LR）是检测方法的内在属性，所以 PPV 和 NPV 都是内在的，且与患病率无关。**\n似然比的定义为 $LR^{+} = \\frac{Se}{1-Sp}$ 和 $LR^{-} = \\frac{1-Se}{Sp}$。由于 $Se$ 和 $Sp$ 是内在属性，所以 $LR^{+}$ 和 $LR^{-}$ 也是。然而，预测值和似然比之间的关系涉及到检验前的患病比数 $\\frac{\\pi}{1-\\pi}$。具体来说，检验后比数等于检验前比数乘以似然比。对于 PPV：\n$$\\frac{PPV}{1-PPV} = \\frac{\\pi}{1-\\pi} \\cdot LR^{+}$$\n该方程表明 PPV 是内在属性 $LR^{+}$ 和外在因素患病率 $\\pi$ 的函数。认为内在的似然比意味着内在的预测值是一个不合逻辑的推论，并且可以证明是错误的。\n**结论：错误。**\n\n**G. 筛查中的基率谬误源于将 $P(T^{+}\\mid D)$ 与 $P(D\\mid T^{+})$ 相混淆；在极低的 $\\pi$ 值下，即使有很高的 $Sp$ 和 $Se$，也可能得出较低的 PPV，因为来自庞大非患病群体的假阳性数量超过了真阳性数量。**\n该陈述为此背景下的基率谬误提供了正确的定义：将灵敏度与 PPV 相混淆。然后，它为这一现象提供了清晰且正确的机理学解释。真阳性的数量与 $\\pi \\cdot Se$ 成正比，而假阳性的数量与 $(1-\\pi)(1-Sp)$ 成正比。当 $\\pi$ 非常低时，非患病人群 $(1-\\pi)$ 非常庞大。因此，即使是很小的假阳性率 $(1-Sp)$ 也可能产生大量的假阳性，其数量相对于甚至超过真阳性的数量。我们在 C 部分对低患病率环境的计算从数值上证实了这一点：在每百万被筛查者中，预计有 $5447.5$ 个阳性检测结果，其中 $4997.5$ 个是假阳性，只有 $450$ 个是真阳性。该陈述完全正确。\n**结论：正确。**",
            "answer": "$$\\boxed{BCEG}$$"
        },
        {
            "introduction": "最后，我们将贝叶斯规则与机器学习的核心概念联系起来。本练习探讨了在线性判别分析（LDA）这一经典生成模型中，先验概率的选择如何直接且量化地影响模型的决策边界。通过推导决策边界的偏移量，你将具体地看到贝叶斯原理是如何成为构建和理解统计模型的基石，并体会到在模型设计中审慎选择先验的必要性。",
            "id": "3139733",
            "problem": "考虑一个线性判别分析 (LDA) 生成模型下的二元分类问题，其特征是一维的。假设类条件密度是具有公共方差的高斯分布：对于类别标签 $Y \\in \\{0,1\\}$ 和特征 $x \\in \\mathbb{R}$，\n$$\np(x \\mid Y=k) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma}\\,\\exp\\!\\left(-\\frac{(x - \\mu_{k})^{2}}{2\\sigma^{2}}\\right), \\quad k \\in \\{0,1\\},\n$$\n其中 $\\mu_{0} \\neq \\mu_{1}$ 且 $\\sigma^{2}  0$。设真实先验概率为 $\\pi_{0}$ 和 $\\pi_{1}$，并假设在训练中您估计的先验概率 $\\hat{\\pi}_{0}$ 和 $\\hat{\\pi}_{1}$ 是设定错误的。分类通过贝叶斯决策规则执行：如果对数后验几率 $\\ln\\!\\big(P(Y=1 \\mid x)/P(Y=0 \\mid x)\\big)$ 为非负，则将 $x$ 划分到类别 1，否则划分到类别 0。在实践中，对数后验几率是使用估计的先验概率 $\\hat{\\pi}_{k}$ 计算的。\n\n从贝叶斯定理和上述高斯似然出发，推导一个闭式解析表达式，表示用估计的先验概率 $\\hat{\\pi}_{k}$ 替换真实先验概率 $\\pi_{k}$ 所导致的实线上决策边界位置的偏移。将您的最终答案表示为以下变量的函数：\n$$\n\\Delta \\equiv \\ln\\!\\left(\\frac{\\hat{\\pi}_{1}}{\\hat{\\pi}_{0}}\\right) - \\ln\\!\\left(\\frac{\\pi_{1}}{\\pi_{0}}\\right), \\quad \\sigma^{2}, \\quad \\mu_{0}, \\quad \\mu_{1}.\n$$\n您的答案必须是表示带符号偏移（新边界减去真实边界）的单个闭式表达式。最终答案中不要提供推导或中间步骤。不需要进行四舍五入。",
            "solution": "该问题在统计学习理论的框架内提法恰当且有科学依据。推导决策边界偏移所需的所有必要参数和条件均已提供。我将开始进行解答。\n\n目标是找到决策边界的偏移，定义为 $x_{\\text{new}} - x_{\\text{true}}$，其中 $x_{\\text{true}}$ 是用真实先验 $\\pi_k$ 计算的边界，而 $x_{\\text{new}}$ 是用估计的先验 $\\hat{\\pi}_k$ 计算的边界。\n\n贝叶斯决策规则在对数后验几率为非负时将特征 $x$ 划分到类别 1。决策边界是使对数后验几率恰好为零的点 $x$。\n$$\n\\ln\\left(\\frac{P(Y=1 \\mid x)}{P(Y=0 \\mid x)}\\right) = 0\n$$\n使用贝叶斯定理，$P(Y=k \\mid x) = \\frac{p(x \\mid Y=k)P(Y=k)}{p(x)}$，我们可以用类条件似然 $p(x \\mid Y=k)$ 和先验概率 $\\pi_k = P(Y=k)$ 来表示对数后验几率。\n$$\n\\ln\\left(\\frac{p(x \\mid Y=1)\\pi_1}{p(x \\mid Y=0)\\pi_0}\\right) = \\ln\\left(\\frac{p(x \\mid Y=1)}{p(x \\mid Y=0)}\\right) + \\ln\\left(\\frac{\\pi_1}{\\pi_0}\\right) = 0\n$$\n问题指定类条件密度是具有公共方差 $\\sigma^2$ 的高斯分布：\n$$\np(x \\mid Y=k) = \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(x - \\mu_{k})^{2}}{2\\sigma^{2}}\\right)\n$$\n每个类别的对数似然为：\n$$\n\\ln(p(x \\mid Y=k)) = -\\ln(\\sqrt{2\\pi}\\sigma) - \\frac{(x - \\mu_{k})^{2}}{2\\sigma^{2}}\n$$\n因此，对数似然比为：\n$$\n\\ln\\left(\\frac{p(x \\mid Y=1)}{p(x \\mid Y=0)}\\right) = \\ln(p(x \\mid Y=1)) - \\ln(p(x \\mid Y=0))\n$$\n$$\n= \\left(-\\ln(\\sqrt{2\\pi}\\sigma) - \\frac{(x - \\mu_{1})^{2}}{2\\sigma^{2}}\\right) - \\left(-\\ln(\\sqrt{2\\pi}\\sigma) - \\frac{(x - \\mu_{0})^{2}}{2\\sigma^{2}}\\right)\n$$\n$$\n= \\frac{(x - \\mu_{0})^{2}}{2\\sigma^{2}} - \\frac{(x - \\mu_{1})^{2}}{2\\sigma^{2}}\n$$\n展开平方项：\n$$\n= \\frac{1}{2\\sigma^{2}} \\left[ (x^2 - 2x\\mu_0 + \\mu_0^2) - (x^2 - 2x\\mu_1 + \\mu_1^2) \\right]\n$$\n$$\n= \\frac{1}{2\\sigma^{2}} \\left[ 2x(\\mu_1 - \\mu_0) + \\mu_0^2 - \\mu_1^2 \\right]\n$$\n这个表达式是 LDA 特有的线性判别函数。决策边界 $x_b$ 是通过将对数似然比与对数先验几率之和设为零来找到的：\n$$\n\\frac{1}{2\\sigma^{2}} \\left[ 2x_b(\\mu_1 - \\mu_0) + \\mu_0^2 - \\mu_1^2 \\right] + \\ln\\left(\\frac{\\pi_1}{\\pi_0}\\right) = 0\n$$\n现在，我们求解通用决策边界 $x_b$：\n$$\n2x_b(\\mu_1 - \\mu_0) + \\mu_0^2 - \\mu_1^2 = -2\\sigma^2 \\ln\\left(\\frac{\\pi_1}{\\pi_0}\\right)\n$$\n$$\n2x_b(\\mu_1 - \\mu_0) = \\mu_1^2 - \\mu_0^2 - 2\\sigma^2 \\ln\\left(\\frac{\\pi_1}{\\pi_0}\\right)\n$$\n$$\n2x_b(\\mu_1 - \\mu_0) = (\\mu_1 - \\mu_0)(\\mu_1 + \\mu_0) - 2\\sigma^2 \\ln\\left(\\frac{\\pi_1}{\\pi_0}\\right)\n$$\n由于给定 $\\mu_0 \\neq \\mu_1$，我们可以除以 $2(\\mu_1 - \\mu_0)$：\n$$\nx_b = \\frac{\\mu_1 + \\mu_0}{2} - \\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{\\pi_1}{\\pi_0}\\right)\n$$\n这是决策边界的一般形式。\n\n首先，我们使用真实先验 $\\pi_0$ 和 $\\pi_1$ 来找到真实决策边界 $x_{\\text{true}}$：\n$$\nx_{\\text{true}} = \\frac{\\mu_1 + \\mu_0}{2} - \\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{\\pi_1}{\\pi_0}\\right)\n$$\n接下来，我们找到由使用设定错误的先验 $\\hat{\\pi}_0$ 和 $\\hat{\\pi}_1$ 产生的新决策边界 $x_{\\text{new}}$：\n$$\nx_{\\text{new}} = \\frac{\\mu_1 + \\mu_0}{2} - \\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{\\hat{\\pi}_1}{\\hat{\\pi}_0}\\right)\n$$\n决策边界位置的偏移是差值 $x_{\\text{new}} - x_{\\text{true}}$：\n$$\n\\text{Shift} = \\left(\\frac{\\mu_1 + \\mu_0}{2} - \\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{\\hat{\\pi}_1}{\\hat{\\pi}_0}\\right)\\right) - \\left(\\frac{\\mu_1 + \\mu_0}{2} - \\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{\\pi_1}{\\pi_0}\\right)\\right)\n$$\n项 $\\frac{\\mu_1 + \\mu_0}{2}$ 被消掉了：\n$$\n\\text{Shift} = -\\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{\\hat{\\pi}_1}{\\hat{\\pi}_0}\\right) + \\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{\\pi_1}{\\pi_0}\\right)\n$$\n提出公因子 $-\\frac{\\sigma^2}{\\mu_1 - \\mu_0}$：\n$$\n\\text{Shift} = -\\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\left[ \\ln\\left(\\frac{\\hat{\\pi}_1}{\\hat{\\pi}_0}\\right) - \\ln\\left(\\frac{\\pi_1}{\\pi_0}\\right) \\right]\n$$\n问题将量 $\\Delta$ 定义为：\n$$\n\\Delta \\equiv \\ln\\left(\\frac{\\hat{\\pi}_{1}}{\\hat{\\pi}_{0}}\\right) - \\ln\\left(\\frac{\\pi_{1}}{\\pi_{0}}\\right)\n$$\n将此定义代入我们的偏移表达式，即可得到最终答案：\n$$\n\\text{Shift} = -\\frac{\\sigma^2 \\Delta}{\\mu_1 - \\mu_0}\n$$\n这就是决策边界偏移量的闭式解析表达式，表示为指定的量 $\\Delta$、$\\sigma^2$、$\\mu_0$ 和 $\\mu_1$ 的函数。",
            "answer": "$$\n\\boxed{-\\frac{\\sigma^2 \\Delta}{\\mu_1 - \\mu_0}}\n$$"
        }
    ]
}