{
    "hands_on_practices": [
        {
            "introduction": "The training of deep neural networks relies on stochastic gradient descent (SGD) and its variants, where gradients are computed on small batches of data. This process is inherently noisy. This hands-on practice  allows you to move beyond viewing this noise as a mere nuisance and instead analyze it as a structured statistical process. By deriving and computing the covariance between gradients of different layers in a simple network, you will gain fundamental insights into how learning dynamics can be correlated, leading to either cooperative (aligned) or conflicting (misaligned) updates across the model.",
            "id": "3123312",
            "problem": "Consider a scalar two-layer linear network used in deep learning with input $x \\in \\mathbb{R}$, parameters $a \\in \\mathbb{R}$ and $b \\in \\mathbb{R}$, and output $\\hat{y} = b a x$. The training label is generated by the random linear model $y = \\theta x + \\varepsilon$, where $x \\sim \\mathcal{N}(0, \\sigma_x^2)$ and $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon}^2)$ are independent zero-mean Gaussian random variables. The loss per sample is the Mean Squared Error (MSE) $L = \\frac{1}{2}(\\hat{y} - y)^2$. For a single random sample, define the stochastic gradients $g^{(1)} = \\frac{\\partial L}{\\partial a}$ and $g^{(2)} = \\frac{\\partial L}{\\partial b}$. These gradients are random variables due to the randomness in $x$ and $\\varepsilon$.\n\nYour tasks are:\n1. Starting strictly from the fundamental definitions of expectation $\\mathbb{E}$, variance $\\operatorname{Var}$, and covariance $\\operatorname{Cov}$, together with the independence of $x$ and $\\varepsilon$, derive closed-form symbolic expressions for $\\mathbb{E}[g^{(1)}]$, $\\mathbb{E}[g^{(2)}]$, $\\operatorname{Var}(g^{(1)})$, $\\operatorname{Var}(g^{(2)})$, and $\\operatorname{Cov}(g^{(1)}, g^{(2)})$ in terms of $a$, $b$, $\\theta$, $\\sigma_x^2$, and $\\sigma_{\\varepsilon}^2$. Then derive the correlation coefficient $\\rho = \\frac{\\operatorname{Cov}(g^{(1)}, g^{(2)})}{\\sqrt{\\operatorname{Var}(g^{(1)}) \\operatorname{Var}(g^{(2)})}}$.\n2. Implement a program that uses these derived formulas to compute, for each provided test case, the numerical values of $\\operatorname{Cov}(g^{(1)}, g^{(2)})$, $\\operatorname{Var}(g^{(1)})$, $\\operatorname{Var}(g^{(2)})$, and $\\rho$. Additionally, classify alignment versus conflict of gradient noise across layers via the sign of covariance: output $+1$ if $\\operatorname{Cov}(g^{(1)}, g^{(2)}) > 0$ (alignment), $-1$ if $\\operatorname{Cov}(g^{(1)}, g^{(2)})  0$ (conflict), and $0$ if $\\operatorname{Cov}(g^{(1)}, g^{(2)}) = 0$ (neutral). When either $\\operatorname{Var}(g^{(1)}) = 0$ or $\\operatorname{Var}(g^{(2)}) = 0$, define $\\rho$ by convention to be $0$.\n\nUse only the given model and probabilistic assumptions. Do not introduce any additional shortcuts or formulas in the derivation beyond well-tested facts about independent zero-mean Gaussian random variables. Express all mathematical expressions using LaTeX. No physical units or angle units are involved. Results should be numerical floats or integers.\n\nTest suite (each case is a tuple $(a, b, \\theta, \\sigma_x^2, \\sigma_{\\varepsilon}^2)$):\n- Case $1$: $(1.0, 2.0, 1.2, 1.0, 0.5)$\n- Case $2$: $(1.0, -2.0, 1.2, 1.0, 0.5)$\n- Case $3$: $(0.0, 1.5, 0.8, 1.0, 0.3)$\n- Case $4$: $(1.0, 1.5, 1.5, 1.0, 0.0)$\n- Case $5$: $(-0.5, -0.25, 0.1, 2.0, 5.0)$\n- Case $6$: $(0.3, 0.6, 0.1, 0.01, 1.0)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with no spaces, where each test case result is the list $[\\operatorname{Cov}(g^{(1)}, g^{(2)}), \\operatorname{Var}(g^{(1)}), \\operatorname{Var}(g^{(2)}), \\rho, \\text{sign}]$. For example, the output must look like $[[c_{1},v_{1}^{(1)},v_{1}^{(2)},\\rho_{1},s_{1}],[c_{2},v_{2}^{(1)},v_{2}^{(2)},\\rho_{2},s_{2}],\\dots]$, where each $c_i$, $v_i^{(1)}$, $v_i^{(2)}$, and $\\rho_i$ are floats and each $s_i$ is an integer in $\\{-1, 0, 1\\}$.",
            "solution": "The problem is valid as it is scientifically grounded in probability theory and calculus, is well-posed with a unique and meaningful solution, and is expressed in objective, formal language. It is a standard theoretical exercise in analyzing the statistics of stochastic gradients in a simplified neural network model.\n\nWe begin by formally deriving the required statistical quantities.\n\n**1. Problem Setup and Gradient Derivation**\n\nThe model output is $\\hat{y} = b a x$, and the target label is generated by $y = \\theta x + \\varepsilon$. The loss for a single sample is the Mean Squared Error (MSE):\n$$L = \\frac{1}{2}(\\hat{y} - y)^2 = \\frac{1}{2}(bax - (\\theta x + \\varepsilon))^2$$\nWe can rewrite the term inside the square as:\n$$\\hat{y} - y = (ab - \\theta)x - \\varepsilon$$\nThe stochastic gradients with respect to the parameters $a$ and $b$ are the partial derivatives of the loss $L$.\n\nThe gradient with respect to $a$, denoted $g^{(1)}$, is:\n$$g^{(1)} = \\frac{\\partial L}{\\partial a} = \\frac{\\partial}{\\partial a} \\left[ \\frac{1}{2}((ab - \\theta)x - \\varepsilon)^2 \\right]$$\nUsing the chain rule:\n$$g^{(1)} = ((ab - \\theta)x - \\varepsilon) \\cdot \\frac{\\partial}{\\partial a}((ab - \\theta)x - \\varepsilon) = ((ab - \\theta)x - \\varepsilon) \\cdot (bx)$$\n$$g^{(1)} = (ab - \\theta)bx^2 - b\\varepsilon x$$\n\nThe gradient with respect to $b$, denoted $g^{(2)}$, is:\n$$g^{(2)} = \\frac{\\partial L}{\\partial b} = \\frac{\\partial}{\\partial b} \\left[ \\frac{1}{2}((ab - \\theta)x - \\varepsilon)^2 \\right]$$\nUsing the chain rule:\n$$g^{(2)} = ((ab - \\theta)x - \\varepsilon) \\cdot \\frac{\\partial}{\\partial b}((ab - \\theta)x - \\varepsilon) = ((ab - \\theta)x - \\varepsilon) \\cdot (ax)$$\n$$g^{(2)} = (ab - \\theta)ax^2 - a\\varepsilon x$$\n\n**2. Properties of Random Variables**\n\nThe random variables are $x \\sim \\mathcal{N}(0, \\sigma_x^2)$ and $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon}^2)$, and they are independent. We will use the following standard moments of zero-mean Gaussian distributions:\n- $\\mathbb{E}[x] = 0$, $\\mathbb{E}[\\varepsilon] = 0$\n- $\\mathbb{E}[x^2] = \\operatorname{Var}(x) + (\\mathbb{E}[x])^2 = \\sigma_x^2$\n- $\\mathbb{E}[\\varepsilon^2] = \\operatorname{Var}(\\varepsilon) + (\\mathbb{E}[\\varepsilon])^2 = \\sigma_{\\varepsilon}^2$\n- $\\mathbb{E}[x^3] = 0$ (all odd moments are zero)\n- $\\mathbb{E}[x^4] = 3(\\sigma_x^2)^2 = 3\\sigma_x^4$\n\nDue to independence, the expectation of a product of functions of $x$ and $\\varepsilon$ is the product of their individual expectations. For example, $\\mathbb{E}[x^k \\varepsilon^m] = \\mathbb{E}[x^k]\\mathbb{E}[\\varepsilon^m]$.\n- $\\mathbb{E}[x\\varepsilon] = \\mathbb{E}[x]\\mathbb{E}[\\varepsilon] = 0 \\cdot 0 = 0$\n- $\\mathbb{E}[x^2\\varepsilon^2] = \\mathbb{E}[x^2]\\mathbb{E}[\\varepsilon^2] = \\sigma_x^2 \\sigma_{\\varepsilon}^2$\n- $\\mathbb{E}[x^3\\varepsilon] = \\mathbb{E}[x^3]\\mathbb{E}[\\varepsilon] = 0 \\cdot 0 = 0$\n\n**3. Derivation of Expectations**\n\nUsing the linearity of the expectation operator $\\mathbb{E}$:\n$$\\mathbb{E}[g^{(1)}] = \\mathbb{E}[(ab - \\theta)bx^2 - b\\varepsilon x] = (ab - \\theta)b\\mathbb{E}[x^2] - b\\mathbb{E}[\\varepsilon x]$$\nSubstituting the moments:\n$$\\mathbb{E}[g^{(1)}] = (ab - \\theta)b\\sigma_x^2 - b(0) = (ab - \\theta)b\\sigma_x^2$$\n\nSimilarly for $g^{(2)}$:\n$$\\mathbb{E}[g^{(2)}] = \\mathbb{E}[(ab - \\theta)ax^2 - a\\varepsilon x] = (ab - \\theta)a\\mathbb{E}[x^2] - a\\mathbb{E}[\\varepsilon x]$$\n$$\\mathbb{E}[g^{(2)}] = (ab - \\theta)a\\sigma_x^2 - a(0) = (ab - \\theta)a\\sigma_x^2$$\nThese are the expected gradients, which represent the gradients of the expected loss $\\mathbb{E}[L]$.\n\n**4. Derivation of Variances and Covariance**\n\nWe use the fundamental definitions $\\operatorname{Var}(Z) = \\mathbb{E}[Z^2] - (\\mathbb{E}[Z])^2$ and $\\operatorname{Cov}(Z_1, Z_2) = \\mathbb{E}[Z_1 Z_2] - \\mathbb{E}[Z_1]\\mathbb{E}[Z_2]$.\n\nFirst, we compute the second moments of the gradients.\nFor $g^{(1)}$:\n$$(g^{(1)})^2 = ((ab - \\theta)bx^2 - b\\varepsilon x)^2 = (ab - \\theta)^2 b^2 x^4 - 2(ab - \\theta)b^2 \\varepsilon x^3 + b^2 \\varepsilon^2 x^2$$\nTaking the expectation:\n$$\\mathbb{E}[(g^{(1)})^2] = (ab - \\theta)^2 b^2 \\mathbb{E}[x^4] - 2(ab - \\theta)b^2 \\mathbb{E}[\\varepsilon x^3] + b^2 \\mathbb{E}[\\varepsilon^2 x^2]$$\nSubstituting the higher-order moments:\n$$\\mathbb{E}[(g^{(1)})^2] = (ab - \\theta)^2 b^2 (3\\sigma_x^4) - 2(ab - \\theta)b^2 (0) + b^2 (\\sigma_{\\varepsilon}^2 \\sigma_x^2)$$\n$$\\mathbb{E}[(g^{(1)})^2] = 3(ab - \\theta)^2 b^2 \\sigma_x^4 + b^2 \\sigma_{\\varepsilon}^2 \\sigma_x^2$$\nNow, we calculate the variance of $g^{(1)}$:\n$$\\operatorname{Var}(g^{(1)}) = \\mathbb{E}[(g^{(1)})^2] - (\\mathbb{E}[g^{(1)}])^2$$\n$$(\\mathbb{E}[g^{(1)}])^2 = ((ab - \\theta)b\\sigma_x^2)^2 = (ab - \\theta)^2 b^2 \\sigma_x^4$$\n$$\\operatorname{Var}(g^{(1)}) = (3(ab - \\theta)^2 b^2 \\sigma_x^4 + b^2 \\sigma_{\\varepsilon}^2 \\sigma_x^2) - (ab - \\theta)^2 b^2 \\sigma_x^4$$\n$$\\operatorname{Var}(g^{(1)}) = 2(ab - \\theta)^2 b^2 \\sigma_x^4 + b^2 \\sigma_{\\varepsilon}^2 \\sigma_x^2$$\n\nBy symmetry, the expression for $\\operatorname{Var}(g^{(2)})$ is identical with $a$ replacing the outer $b$:\n$$\\operatorname{Var}(g^{(2)}) = 2(ab - \\theta)^2 a^2 \\sigma_x^4 + a^2 \\sigma_{\\varepsilon}^2 \\sigma_x^2$$\n\nNext, for the covariance, we compute $\\mathbb{E}[g^{(1)} g^{(2)}]$:\n$$g^{(1)}g^{(2)} = ((ab - \\theta)bx^2 - b\\varepsilon x)((ab - \\theta)ax^2 - a\\varepsilon x)$$\n$$g^{(1)}g^{(2)} = (ab - \\theta)^2 ab x^4 - 2(ab - \\theta)ab \\varepsilon x^3 + ab \\varepsilon^2 x^2$$\nTaking the expectation:\n$$\\mathbb{E}[g^{(1)}g^{(2)}] = (ab - \\theta)^2 ab \\mathbb{E}[x^4] - 2(ab - \\theta)ab \\mathbb{E}[\\varepsilon x^3] + ab \\mathbb{E}[\\varepsilon^2 x^2]$$\n$$\\mathbb{E}[g^{(1)}g^{(2)}] = (ab - \\theta)^2 ab (3\\sigma_x^4) + ab (\\sigma_{\\varepsilon}^2 \\sigma_x^2) = 3(ab - \\theta)^2 ab \\sigma_x^4 + ab \\sigma_{\\varepsilon}^2 \\sigma_x^2$$\nNow, we compute the covariance:\n$$\\operatorname{Cov}(g^{(1)}, g^{(2)}) = \\mathbb{E}[g^{(1)}g^{(2)}] - \\mathbb{E}[g^{(1)}]\\mathbb{E}[g^{(2)}]$$\n$$\\mathbb{E}[g^{(1)}]\\mathbb{E}[g^{(2)}] = ((ab - \\theta)b\\sigma_x^2)((ab - \\theta)a\\sigma_x^2) = (ab - \\theta)^2 ab \\sigma_x^4$$\n$$\\operatorname{Cov}(g^{(1)}, g^{(2)}) = (3(ab - \\theta)^2 ab \\sigma_x^4 + ab \\sigma_{\\varepsilon}^2 \\sigma_x^2) - ((ab - \\theta)^2 ab \\sigma_x^4)$$\n$$\\operatorname{Cov}(g^{(1)}, g^{(2)}) = 2(ab - \\theta)^2 ab \\sigma_x^4 + ab \\sigma_{\\varepsilon}^2 \\sigma_x^2$$\n\n**5. Correlation Coefficient**\n\nLet's factor the expressions. Let $V_Z = 2(ab - \\theta)^2 \\sigma_x^4 + \\sigma_{\\varepsilon}^2 \\sigma_x^2$. This term is non-negative.\n- $\\operatorname{Var}(g^{(1)}) = b^2 V_Z$\n- $\\operatorname{Var}(g^{(2)}) = a^2 V_Z$\n- $\\operatorname{Cov}(g^{(1)}, g^{(2)}) = ab V_Z$\n\nThe correlation coefficient $\\rho$ is defined as:\n$$\\rho = \\frac{\\operatorname{Cov}(g^{(1)}, g^{(2)})}{\\sqrt{\\operatorname{Var}(g^{(1)}) \\operatorname{Var}(g^{(2)})}}$$\nSubstituting our expressions:\n$$\\rho = \\frac{ab V_Z}{\\sqrt{(b^2 V_Z) \\cdot (a^2 V_Z)}} = \\frac{ab V_Z}{\\sqrt{a^2 b^2 V_Z^2}} = \\frac{ab V_Z}{|ab| V_Z}$$\nIf $V_Z \\neq 0$ and $a,b \\neq 0$, this simplifies to:\n$$\\rho = \\frac{ab}{|ab|} = \\operatorname{sign}(ab)$$\nwhere $\\operatorname{sign}(z)$ is $1$ if $z0$, $-1$ if $z0$, and $0$ if $z=0$. So, if $a$ and $b$ have the same sign, $\\rho=1$. If they have opposite signs, $\\rho=-1$.\n\nPer the problem statement, if either variance is zero, $\\rho$ is defined as $0$.\n$\\operatorname{Var}(g^{(1)}) = 0$ if $b=0$ or $V_Z=0$.\n$\\operatorname{Var}(g^{(2)}) = 0$ if $a=0$ or $V_Z=0$.\nSo, $\\rho=0$ if $a=0$, or $b=0$, or $V_Z=0$.\nNote that $V_Z = 0$ if and only if $\\sigma_x^2=0$, or both $\\sigma_{\\varepsilon}^2=0$ and $ab=\\theta$.\nIn all cases where one of the variances is zero, our expressions correctly give $\\operatorname{Cov}(g^{(1)}, g^{(2)})=0$, so the convention is consistent. Our general expression for $\\rho$ as $\\operatorname{sign}(ab)$ is valid when the variances are non-zero, and consistent with the $\\rho=0$ convention when $a=0$ or $b=0$.\n\n**6. Final Formulas for Implementation**\n\nLet $\\Delta = ab - \\theta$.\nLet $\\sigma_x^2$ be `sx2` and $\\sigma_{\\varepsilon}^2$ be `se2`.\nThe common factor is $V_Z = 2\\Delta^2 (\\text{sx2})^2 + \\text{se2} \\cdot \\text{sx2}$.\n- $\\operatorname{Cov}(g^{(1)}, g^{(2)}) = ab V_Z$\n- $\\operatorname{Var}(g^{(1)}) = b^2 V_Z$\n- $\\operatorname{Var}(g^{(2)}) = a^2 V_Z$\n- $\\rho$: if $\\operatorname{Var}(g^{(1)})=0$ or $\\operatorname{Var}(g^{(2)})=0$, $\\rho=0$. Otherwise, $\\rho = \\frac{\\operatorname{Cov}(g^{(1)}, g^{(2)})}{\\sqrt{\\operatorname{Var}(g^{(1)}) \\operatorname{Var}(g^{(2)})}}$.\n- sign: $\\operatorname{sign}(\\operatorname{Cov}(g^{(1)}, g^{(2)}))$, which will be $+1, -1$, or $0$.\n\nThese formulas are implemented to compute the numerical results for the given test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of calculating gradient statistics for a two-layer linear network.\n    \"\"\"\n    # Test suite: each case is a tuple (a, b, theta, sigma_x^2, sigma_epsilon^2)\n    test_cases = [\n        (1.0, 2.0, 1.2, 1.0, 0.5),    # Case 1\n        (1.0, -2.0, 1.2, 1.0, 0.5),   # Case 2\n        (0.0, 1.5, 0.8, 1.0, 0.3),    # Case 3\n        (1.0, 1.5, 1.5, 1.0, 0.0),    # Case 4\n        (-0.5, -0.25, 0.1, 2.0, 5.0), # Case 5\n        (0.3, 0.6, 0.1, 0.01, 1.0),   # Case 6\n    ]\n\n    results = []\n    for case in test_cases:\n        a, b, theta, sx2, se2 = case\n\n        # Let delta = ab - theta\n        delta = a * b - theta\n\n        # Common factor term V_Z = 2 * delta^2 * (sx2)^2 + se2 * sx2\n        # where V_Z = Var(((ab-theta)x - epsilon)x)\n        common_term_vz = 2 * (delta**2) * (sx2**2) + se2 * sx2\n        \n        # Cov(g1, g2) = ab * V_Z\n        cov_g1_g2 = a * b * common_term_vz\n        \n        # Var(g1) = b^2 * V_Z\n        var_g1 = b**2 * common_term_vz\n        \n        # Var(g2) = a^2 * V_Z\n        var_g2 = a**2 * common_term_vz\n\n        # Correlation coefficient rho\n        # By convention, rho = 0 if either variance is 0.\n        if var_g1 == 0 or var_g2 == 0:\n            rho = 0.0\n        else:\n            rho = cov_g1_g2 / np.sqrt(var_g1 * var_g2)\n\n        # Sign of covariance for alignment classification\n        # np.sign returns -1, 0, or 1 as a float. Convert to int.\n        sign = int(np.sign(cov_g1_g2))\n        \n        results.append([cov_g1_g2, var_g1, var_g2, rho, sign])\n\n    # Format the output string to be a list of lists with no spaces.\n    # e.g., [[c1,v11,v12,r1,s1],[c2,v21,v22,r2,s2],...]\n    result_strings = []\n    for res in results:\n        # Format each inner list to a string without spaces.\n        inner_string = \",\".join(map(str, res))\n        result_strings.append(f\"[{inner_string}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A standard deep learning model provides a point estimate prediction but offers no information about its confidence. For critical applications, knowing what the model *doesn't* know is as important as its prediction. This exercise  introduces Monte Carlo dropout, a widely used and computationally efficient technique for estimating model uncertainty. You will learn to treat a neural network's output as a random variable and use the fundamental tools of expectation and variance to compute a predictive mean and a measure of the model's confidence, known as epistemic uncertainty.",
            "id": "3123387",
            "problem": "You are given a single-hidden-layer feedforward neural network with Rectified Linear Unit (ReLU) activation and hidden-layer dropout. The network maps a two-dimensional input vector $x \\in \\mathbb{R}^2$ to a scalar output. The network parameters are fixed and known. You must use Monte Carlo dropout to approximate the predictive mean $\\mathbb{E}[f(x)]$ and predictive variance $\\operatorname{Var}[f(x)]$ of the network output $f(x)$ under the randomness induced by dropout, and then relate how epistemic uncertainty changes with the dropout rate $p$ by inspecting the variance values across test cases.\n\nFundamental base for deriving the algorithm:\n- The expectation of a real-valued random variable $Z$ is $\\mathbb{E}[Z]$.\n- The variance of a real-valued random variable $Z$ is $\\operatorname{Var}(Z) = \\mathbb{E}\\left[(Z - \\mathbb{E}[Z])^2\\right]$.\n- Monte Carlo estimation uses independent samples $Z_1, Z_2, \\dots, Z_T$ to approximate $\\mathbb{E}[Z]$ by the sample mean and $\\operatorname{Var}(Z)$ by the sample variance.\n\nNetwork definition:\n- Hidden layer of size $H=3$ with parameters\n$$\n\\mathbf{W}_1 =\n\\begin{bmatrix}\n1.0  -0.5 \\\\\n0.3  0.8 \\\\\n-0.7  0.2\n\\end{bmatrix}, \\quad\n\\mathbf{b}_1 =\n\\begin{bmatrix}\n0.1 \\\\\n-0.2 \\\\\n0.0\n\\end{bmatrix}.\n$$\n- Output layer parameters\n$$\n\\mathbf{W}_2 =\n\\begin{bmatrix}\n0.5 \\\\\n-1.0 \\\\\n0.3\n\\end{bmatrix}, \\quad\nb_2 = 0.05.\n$$\n- ReLU activation is defined as $\\operatorname{ReLU}(z) = \\max(z, 0)$ applied elementwise.\n- Hidden-layer dropout with rate $p \\in [0,1)$ is applied to the post-activation hidden vector $h = \\operatorname{ReLU}(\\mathbf{W}_1 x + \\mathbf{b}_1)$. Using inverted dropout, the dropped hidden vector is\n$$\n\\tilde{h} = \\begin{cases}\nh,  \\text{if } p = 0, \\\\\n\\frac{m \\odot h}{1-p},  \\text{if } p  0,\n\\end{cases}\n$$\nwhere $m \\in \\{0,1\\}^H$ is a random mask with independent entries $m_i \\sim \\operatorname{Bernoulli}(1-p)$, and $\\odot$ denotes elementwise multiplication. The network output is\n$$\nf(x) = \\mathbf{W}_2^\\top \\tilde{h} + b_2.\n$$\n\nMonte Carlo dropout setup:\n- For a given input $x$, dropout rate $p$, and number of Monte Carlo samples $T \\in \\mathbb{N}$, generate $T$ independent samples of $f(x)$ by independently drawing masks $m$ and computing $f(x)$.\n- Approximate $\\mathbb{E}[f(x)]$ by the sample mean of the $T$ outputs.\n- Approximate $\\operatorname{Var}[f(x)]$ by the sample variance of the $T$ outputs.\n\nTask:\n- Implement a program that performs the above Monte Carlo procedure for the specified test suite.\n- Your program must not train the network; it must use the fixed parameters given above.\n- Your outputs must be floats. No physical units are involved in this problem.\n\nTest suite:\nCompute the predictive mean and variance for the following $(x, p, T)$ triplets. Each $x$ is given as a two-dimensional vector. Use the exact numeric values shown.\n\n1. $x = \\begin{bmatrix} 0.5 \\\\ -1.0 \\end{bmatrix}$, $p = 0.0$, $T = 100$.\n2. $x = \\begin{bmatrix} 0.5 \\\\ -1.0 \\end{bmatrix}$, $p = 0.2$, $T = 1000$.\n3. $x = \\begin{bmatrix} 2.0 \\\\ 1.0 \\end{bmatrix}$, $p = 0.5$, $T = 1000$.\n4. $x = \\begin{bmatrix} 2.0 \\\\ 1.0 \\end{bmatrix}$, $p = 0.9$, $T = 2000$.\n5. $x = \\begin{bmatrix} -1.5 \\\\ 0.3 \\end{bmatrix}$, $p = 0.5$, $T = 25$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- Each test caseâ€™s result must itself be a list of two floats in the order $[\\text{mean}, \\text{variance}]$ corresponding to $\\mathbb{E}[f(x)]$ and $\\operatorname{Var}[f(x)]$ for that case.\n- For example, a valid output format for $K$ test cases is\n$$\n\\text{[}[m_1,v_1],[m_2,v_2],\\dots,[m_K,v_K]\\text{]}.\n$$\n\nDesign for coverage:\n- Case $1$ is a boundary condition with $p = 0.0$ (no dropout), which should exhibit zero variance.\n- Cases $2$ and $3$ are general cases with moderate dropout.\n- Case $4$ probes a high dropout regime $p = 0.9$ to illustrate increased epistemic uncertainty.\n- Case $5$ uses a small number of samples $T = 25$ to illustrate sampling variability in the Monte Carlo estimates.\n\nYour implementation must be deterministic across runs by using a fixed random seed for the Monte Carlo sampling.",
            "solution": "We begin from core definitions in probability theory. For a real-valued random variable $Z$, the expectation is $\\mathbb{E}[Z]$, and the variance is $\\operatorname{Var}(Z) = \\mathbb{E}\\left[(Z - \\mathbb{E}[Z])^2\\right]$. When the exact distribution of $Z$ is not tractable, Monte Carlo methods approximate these quantities using independent samples. Given independent samples $Z_1, Z_2, \\dots, Z_T$, the sample mean $\\hat{\\mu}$ and sample variance $\\hat{\\sigma}^2$ provide consistent estimators:\n$$\n\\hat{\\mu} = \\frac{1}{T} \\sum_{t=1}^T Z_t, \\quad\n\\hat{\\sigma}^2 = \\frac{1}{T-1} \\sum_{t=1}^T (Z_t - \\hat{\\mu})^2.\n$$\nThe unbiased sample variance uses the denominator $T-1$ and converges to $\\operatorname{Var}(Z)$ as $T \\to \\infty$.\n\nIn deep learning, dropout practices introduce stochasticity by randomly zeroing hidden units during training. Monte Carlo dropout applies this same randomness at inference time to approximate Bayesian predictions, attributing variability in outputs to epistemic uncertainty (uncertainty in the model due to limited data or parameter uncertainty). Inverted dropout rescales kept activations by $\\frac{1}{1-p}$ so that the expected activation remains unchanged. Specifically, for a hidden activation vector $h = \\operatorname{ReLU}(\\mathbf{W}_1 x + \\mathbf{b}_1)$ and a mask $m \\in \\{0,1\\}^H$ with independent entries $m_i \\sim \\operatorname{Bernoulli}(1-p)$, the dropped hidden vector is\n$$\n\\tilde{h} = \\frac{m \\odot h}{1-p} \\quad \\text{for } p  0, \\quad \\tilde{h} = h \\quad \\text{for } p = 0.\n$$\nThe scalar output is then\n$$\nf(x) = \\mathbf{W}_2^\\top \\tilde{h} + b_2.\n$$\nUnder dropout, $f(x)$ becomes a random variable due to the randomness in $m$. We estimate $\\mathbb{E}[f(x)]$ and $\\operatorname{Var}[f(x)]$ by sampling $T$ independent masks $m^{(1)}, \\dots, m^{(T)}$ and computing the outputs $f^{(t)}(x)$, forming the sample mean and sample variance.\n\nAlgorithmic steps:\n1. Fix the network parameters $\\mathbf{W}_1$, $\\mathbf{b}_1$, $\\mathbf{W}_2$, $b_2$ as specified.\n2. For each test case $(x, p, T)$:\n   - Compute the deterministic hidden activation $h = \\operatorname{ReLU}(\\mathbf{W}_1 x + \\mathbf{b}_1)$.\n   - If $p = 0$, then $\\tilde{h} = h$ for all samples, so $f(x)$ is deterministic; $\\operatorname{Var}[f(x)] = 0$.\n   - If $p  0$, repeat for $t = 1, \\dots, T$:\n     - Sample a mask $m^{(t)} \\in \\{0,1\\}^H$ with independent $m_i^{(t)} \\sim \\operatorname{Bernoulli}(1-p)$.\n     - Form $\\tilde{h}^{(t)} = \\frac{m^{(t)} \\odot h}{1-p}$.\n     - Compute $f^{(t)}(x) = \\mathbf{W}_2^\\top \\tilde{h}^{(t)} + b_2$.\n   - Estimate $\\mathbb{E}[f(x)]$ by $\\hat{\\mu} = \\frac{1}{T} \\sum_{t=1}^T f^{(t)}(x)$ and $\\operatorname{Var}[f(x)]$ by the unbiased sample variance $\\hat{\\sigma}^2 = \\frac{1}{T-1} \\sum_{t=1}^T (f^{(t)}(x) - \\hat{\\mu})^2$ (for $T \\geq 2$; for $p=0$, all samples are identical and variance is $0$).\n3. Aggregate the results for all test cases into a single list in the specified output format.\n\nRelation of epistemic uncertainty to the dropout rate $p$:\n- Epistemic uncertainty reflects model uncertainty. Dropout stochastically removes hidden units. As $p$ increases, the probability of zeroing units increases, which induces higher variability across different network realizations sampled via masks.\n- With inverted dropout, kept activations are scaled by $\\frac{1}{1-p}$. For large $p$ (close to $1$), this factor amplifies the contributions of the few active units when they are kept, while most samples set them to zero. This mixture (rare large contributions versus frequent zeros) increases the variance of $f(x)$.\n- Therefore, all else equal, the predictive variance $\\operatorname{Var}[f(x)]$ generally increases with $p$, illustrating greater epistemic uncertainty.\n\nTest suite coverage justification:\n- Case $1$ ($p=0$) yields zero variance since $m_i \\equiv 1$ and no randomness is present.\n- Cases $2$ and $3$ are typical Monte Carlo dropout estimates with moderate $p$ and large $T$, providing accurate estimates of $\\mathbb{E}[f(x)]$ and $\\operatorname{Var}[f(x)]$.\n- Case $4$ uses a high dropout rate $p=0.9$ and larger $T$ to stably estimate the increased variance due to strong dropout.\n- Case $5$ demonstrates the effect of small sample size $T=25$ on the estimates, emphasizing sampling variability.\n\nThe program will implement these steps using a fixed random seed to ensure deterministic results across runs and will print a single line with the list of $[\\text{mean}, \\text{variance}]$ for each test case in order.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef relu(x):\n    return np.maximum(x, 0.0)\n\ndef mc_dropout_predict(x, p, T, rng, W1, b1, W2, b2):\n    \"\"\"\n    Perform Monte Carlo dropout predictions for a single input x.\n    Returns an array of T scalar outputs.\n    \"\"\"\n    # Compute deterministic hidden activation h = ReLU(W1 x + b1)\n    a = W1 @ x + b1\n    h = relu(a)\n\n    # If p == 0, output is deterministic; replicate the same value T times\n    if p == 0.0:\n        y = float(W2 @ h + b2)\n        return np.full(T, y, dtype=float)\n\n    keep_prob = 1.0 - p\n    scale = 1.0 / keep_prob\n\n    # Sample T masks and compute outputs\n    outputs = np.empty(T, dtype=float)\n    for t in range(T):\n        # Bernoulli(keep_prob) for each hidden unit\n        m = rng.binomial(1, keep_prob, size=h.shape)\n        h_drop = (m * h) * scale\n        y = float(W2 @ h_drop + b2)\n        outputs[t] = y\n    return outputs\n\ndef solve():\n    # Fixed random seed for determinism\n    rng = np.random.default_rng(42)\n\n    # Define fixed network parameters\n    W1 = np.array([[1.0, -0.5],\n                   [0.3,  0.8],\n                   [-0.7, 0.2]], dtype=float)\n    b1 = np.array([0.1, -0.2, 0.0], dtype=float)\n    W2 = np.array([0.5, -1.0, 0.3], dtype=float)\n    b2 = 0.05\n\n    # Define the test cases from the problem statement.\n    # Each test case is (x, p, T)\n    test_cases = [\n        (np.array([0.5, -1.0], dtype=float), 0.0, 100),\n        (np.array([0.5, -1.0], dtype=float), 0.2, 1000),\n        (np.array([2.0,  1.0], dtype=float), 0.5, 1000),\n        (np.array([2.0,  1.0], dtype=float), 0.9, 2000),\n        (np.array([-1.5, 0.3], dtype=float), 0.5, 25),\n    ]\n\n    results = []\n    for x, p, T in test_cases:\n        outputs = mc_dropout_predict(x, p, T, rng, W1, b1, W2, b2)\n        mean = float(np.mean(outputs))\n        # Unbiased sample variance; for T=1, set variance to 0.0 to avoid NaN\n        var = float(np.var(outputs, ddof=1)) if T > 1 else 0.0\n        # Round for stable presentation while keeping numeric type\n        mean_rounded = round(mean, 6)\n        var_rounded = round(var, 6)\n        results.append([mean_rounded, var_rounded])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(str(res) for res in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "In the later stages of training, the feature representations learned by deep classifiers often exhibit a remarkable geometric structure, a phenomenon termed \"neural collapse\". This structure is not an accident but an emergent property of the optimization process. This practice  provides a direct, hands-on simulation to explore this advanced concept. By calculating the within-class covariance $\\widehat{\\mathbf{S}}_w$ and between-class covariance $\\widehat{\\mathbf{S}}_b$, you will quantify how features of the same class collapse to a single point while their class means become maximally separated, offering a glimpse into the geometry of deep representations.",
            "id": "3123405",
            "problem": "You are tasked with designing and implementing a program that quantifies the phenomenon commonly observed in supervised deep learning representations known as neural collapse. The focus is on tracking the shrinkage of within-class covariance and the growth of between-class covariance of class means, and on measuring the degree of collapse using ratio metrics that approach a constant under specific scaling of parameters. Your program must compute these quantities from first principles using only definitions of expectation, variance, and covariance.\n\nConsider a random vector $\\mathbf{X} \\in \\mathbb{R}^D$ and a discrete class label $Y \\in \\{1,\\dots,C\\}$. For each class $c \\in \\{1,\\dots,C\\}$, you will simulate data according to a class-conditional model with isotropic Gaussian noise and class-dependent means as follows.\n\nData generation procedure:\n- For given integers $C$ (number of classes), $D$ (dimension), and $n$ (samples per class), along with a real standard deviation $\\sigma \\ge 0$ and a real mean scale $\\gamma  0$, construct class means $\\boldsymbol{\\mu}_1,\\dots,\\boldsymbol{\\mu}_C \\in \\mathbb{R}^D$ by:\n  1. Sampling $C$ i.i.d. standard normal vectors in $\\mathbb{R}^D$, assembling them as the columns of a matrix, and centering the columns by subtracting their column average so they have zero average across classes.\n  2. Normalizing each centered column to unit Euclidean norm and scaling it to have Euclidean norm $\\gamma$ so that $\\|\\boldsymbol{\\mu}_c\\|_2 = \\gamma$ for all $c$.\n- For each class $c$, independently sample $n$ observations according to the model\n  $$ \\mathbf{X} \\mid Y=c = \\boldsymbol{\\mu}_c + \\boldsymbol{\\varepsilon}, \\quad \\text{where } \\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I}_D). $$\n\nEmpirical estimation tasks:\n- Compute the empirical class mean for each class $c$:\n  $$ \\widehat{\\boldsymbol{\\mu}}_c = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_{c,i}, $$\n  where $\\mathbf{x}_{c,i}$ are the sampled observations for class $c$.\n- Compute the empirical within-class covariance for each class $c$ using the empirical expectation operator with denominator $n$:\n  $$ \\widehat{\\mathbf{\\Sigma}}_{w,c} = \\frac{1}{n} \\sum_{i=1}^n \\left(\\mathbf{x}_{c,i} - \\widehat{\\boldsymbol{\\mu}}_c\\right)\\left(\\mathbf{x}_{c,i} - \\widehat{\\boldsymbol{\\mu}}_c\\right)^\\top. $$\n- Compute the overall empirical within-class covariance as the average across classes:\n  $$ \\widehat{\\mathbf{S}}_w = \\frac{1}{C} \\sum_{c=1}^C \\widehat{\\mathbf{\\Sigma}}_{w,c}. $$\n- Compute the empirical mean of class means:\n  $$ \\widehat{\\boldsymbol{\\mu}} = \\frac{1}{C} \\sum_{c=1}^C \\widehat{\\boldsymbol{\\mu}}_c. $$\n- Compute the empirical between-class covariance of class means:\n  $$ \\widehat{\\mathbf{S}}_b = \\frac{1}{C} \\sum_{c=1}^C \\left(\\widehat{\\boldsymbol{\\mu}}_c - \\widehat{\\boldsymbol{\\mu}}\\right)\\left(\\widehat{\\boldsymbol{\\mu}}_c - \\widehat{\\boldsymbol{\\mu}}\\right)^\\top. $$\n\nCollapse ratio metrics:\n- Compute the following two scalar metrics:\n  1. The trace ratio\n     $$ r_{\\mathrm{trace}} = \\frac{\\operatorname{tr}\\left(\\widehat{\\mathbf{S}}_b\\right)}{\\operatorname{tr}\\left(\\widehat{\\mathbf{S}}_w\\right)}. $$\n  2. The Frobenius norm ratio\n     $$ r_{\\mathrm{fro}} = \\frac{\\left\\|\\widehat{\\mathbf{S}}_b\\right\\|_F}{\\left\\|\\widehat{\\mathbf{S}}_w\\right\\|_F}, $$\n     where $\\|\\mathbf{A}\\|_F = \\sqrt{\\sum_{i,j} a_{ij}^2}$ denotes the Frobenius norm.\n\nCorner cases:\n- If $\\operatorname{tr}\\left(\\widehat{\\mathbf{S}}_w\\right) = 0$ or $\\left\\|\\widehat{\\mathbf{S}}_w\\right\\|_F = 0$, define the corresponding ratio as $+\\infty$.\n\nYour program must implement the data generation and estimation precisely as described, using the specified seeds to ensure reproducibility. It must process a test suite of parameter values, compute the two ratios for each case, and produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result must be a two-element list in the exact order $[r_{\\mathrm{trace}}, r_{\\mathrm{fro}}]$. The final output format must therefore look like\n$$ [[r_{\\mathrm{trace}}^{(1)}, r_{\\mathrm{fro}}^{(1)}],[r_{\\mathrm{trace}}^{(2)}, r_{\\mathrm{fro}}^{(2)}],\\dots]. $$\n\nTest suite:\n- Case $1$ (happy path): seed $0$, $C=5$, $D=10$, $n=200$, $\\sigma=1.0$, $\\gamma=2.0$.\n- Case $2$ (constant-ratio scaling): seed $0$, $C=5$, $D=10$, $n=200$, $\\sigma=2.0$, $\\gamma=4.0$.\n- Case $3$ (high noise, low separation): seed $1$, $C=5$, $D=10$, $n=200$, $\\sigma=3.0$, $\\gamma=1.0$.\n- Case $4$ (low noise, high separation): seed $2$, $C=5$, $D=10$, $n=200$, $\\sigma=0.1$, $\\gamma=3.0$.\n- Case $5$ (edge case, zero within-class variance): seed $3$, $C=3$, $D=4$, $n=50$, $\\sigma=0.0$, $\\gamma=1.5$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element of the list is itself a two-element list containing the values $[r_{\\mathrm{trace}}, r_{\\mathrm{fro}}]$ for the corresponding test case, in the same order as the test suite.",
            "solution": "The problem is valid. It is scientifically grounded in the statistical modeling of deep learning representations, well-posed with a complete and consistent set of definitions and parameters, and objective in its formulation. We will proceed with a solution.\n\nThe objective is to simulate and quantify the phenomenon of neural collapse, which describes a specific geometric configuration of feature representations in the final layer of a supervised deep network during training. This phenomenon is characterized by the following properties:\n1. The variability of features within a single class collapses, meaning the within-class covariance matrices shrink.\n2. The empirical means of features for different classes become maximally separated and equidistant, forming a simplex equiangular tight frame. This leads to a structured and large between-class covariance.\n\nThe problem provides a simplified generative model to study this. We will implement this model and compute two key ratios that measure the degree of collapse: the ratio of the trace and the Frobenius norm of the between-class and within-class covariance matrices.\n\nThe solution is structured as follows:\n1.  **Data Generation**: For each test case, we first generate the class-prototype vectors and then sample the data points for each class.\n2.  **Empirical Covariance Estimation**: Using the generated data, we compute the empirical within-class and between-class covariance matrices based on their fundamental definitions.\n3.  **Metric Calculation**: We compute the trace and Frobenius norm ratios from the estimated covariance matrices.\n\n### 1. Data Generation\n\nThe process begins by constructing the true class means $\\boldsymbol{\\mu}_c \\in \\mathbb{R}^D$ for $c \\in \\{1,\\ldots,C\\}$. These are idealized feature representations for each class.\n- First, we sample $C$ vectors from a $D$-dimensional standard normal distribution, $\\mathbf{v}_c \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}_D)$. These vectors are arranged as columns of a matrix $\\mathbf{V} \\in \\mathbb{R}^{D \\times C}$.\n- The grand mean of these vectors, $\\bar{\\mathbf{v}} = \\frac{1}{C} \\sum_{c=1}^C \\mathbf{v}_c$, is subtracted from each vector to ensure that the resulting set of means is centered: $\\mathbf{v}'_c = \\mathbf{v}_c - \\bar{\\mathbf{v}}$. This guarantees that $\\sum_{c=1}^C \\mathbf{v}'_c = \\mathbf{0}$.\n- Each centered vector $\\mathbf{v}'_c$ is normalized to have a Euclidean norm of $\\gamma$. This is done by first normalizing to unit length and then scaling:\n  $$ \\boldsymbol{\\mu}_c = \\gamma \\frac{\\mathbf{v}'_c}{\\|\\mathbf{v}'_c\\|_2} $$\n  This ensures that $\\|\\boldsymbol{\\mu}_c\\|_2 = \\gamma$ for all classes $c$.\n\nWith the true class means established, we simulate $n$ data points for each class. Each data point $\\mathbf{x}_{c,i}$ is sampled from a class-conditional Gaussian distribution:\n$$ \\mathbf{x}_{c,i} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_c, \\sigma^2 \\mathbf{I}_D) $$\nThis is equivalent to adding isotropic Gaussian noise $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I}_D)$ to the true class mean: $\\mathbf{x}_{c,i} = \\boldsymbol{\\mu}_c + \\boldsymbol{\\varepsilon}_{c,i}$.\n\n### 2. Empirical Covariance Estimation\n\nFrom the generated data samples $\\{\\mathbf{x}_{c,i}\\}_{i=1}^n$ for each class $c$, we compute empirical estimates of various statistical quantities.\n\n- **Empirical Class Means**: The mean vector for each class is estimated by averaging its samples:\n  $$ \\widehat{\\boldsymbol{\\mu}}_c = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_{c,i} $$\n\n- **Within-Class Covariance**: The covariance of features within each class, $\\widehat{\\mathbf{\\Sigma}}_{w,c}$, measures the scatter of data points around their empirical class mean $\\widehat{\\boldsymbol{\\mu}}_c$. It is computed using the formula for sample covariance with a denominator of $n$:\n  $$ \\widehat{\\mathbf{\\Sigma}}_{w,c} = \\frac{1}{n} \\sum_{i=1}^n \\left(\\mathbf{x}_{c,i} - \\widehat{\\boldsymbol{\\mu}}_c\\right)\\left(\\mathbf{x}_{c,i} - \\widehat{\\boldsymbol{\\mu}}_c\\right)^\\top $$\n  The overall within-class covariance, $\\widehat{\\mathbf{S}}_w$, is the average of these individual covariance matrices over all classes:\n  $$ \\widehat{\\mathbf{S}}_w = \\frac{1}{C} \\sum_{c=1}^C \\widehat{\\mathbf{\\Sigma}}_{w,c} $$\n\n- **Between-Class Covariance**: This metric, $\\widehat{\\mathbf{S}}_b$, quantifies the scatter of the *empirical class means* $\\widehat{\\boldsymbol{\\mu}}_c$ around their own grand mean, $\\widehat{\\boldsymbol{\\mu}} = \\frac{1}{C} \\sum_{c=1}^C \\widehat{\\boldsymbol{\\mu}}_c$. The formula is:\n  $$ \\widehat{\\mathbf{S}}_b = \\frac{1}{C} \\sum_{c=1}^C \\left(\\widehat{\\boldsymbol{\\mu}}_c - \\widehat{\\boldsymbol{\\mu}}\\right)\\left(\\widehat{\\boldsymbol{\\mu}}_c - \\widehat{\\boldsymbol{\\mu}}\\right)^\\top $$\n\n### 3. Collapse Ratio Metrics\n\nThe degree of neural collapse is quantified by comparing the \"size\" of the between-class covariance to the within-class covariance. We use two scalar measures for the size of these matrices: the trace and the Frobenius norm.\n\n- **Trace Ratio**: The trace of a square matrix is the sum of its diagonal elements, $\\operatorname{tr}(\\mathbf{A}) = \\sum_i A_{ii}$. For a covariance matrix, the trace represents the total variance, i.e., the sum of the variances along each dimension. The trace ratio is:\n  $$ r_{\\mathrm{trace}} = \\frac{\\operatorname{tr}\\left(\\widehat{\\mathbf{S}}_b\\right)}{\\operatorname{tr}\\left(\\widehat{\\mathbf{S}}_w\\right)} $$\n  A large value indicates that the separation between class means is large relative to the spread of data within each class.\n\n- **Frobenius Norm Ratio**: The Frobenius norm of a matrix $\\mathbf{A}$ is the square root of the sum of the squares of its elements, $\\|\\mathbf{A}\\|_F = \\sqrt{\\sum_{i,j} a_{ij}^2}$. It provides an alternative measure of the overall magnitude of the matrix. The Frobenius norm ratio is:\n  $$ r_{\\mathrm{fro}} = \\frac{\\left\\|\\widehat{\\mathbf{S}}_b\\right\\|_F}{\\left\\|\\widehat{\\mathbf{S}}_w\\right\\|_F} $$\n\n- **Corner Case**: If the within-class noise standard deviation $\\sigma$ is $0$, all samples for a class are identical to the class mean, $\\mathbf{x}_{c,i} = \\boldsymbol{\\mu}_c$. Consequently, the empirical class mean is also the true mean, $\\widehat{\\boldsymbol{\\mu}}_c = \\boldsymbol{\\mu}_c$. The within-class deviations $(\\mathbf{x}_{c,i} - \\widehat{\\boldsymbol{\\mu}}_c)$ are all zero, making the within-class covariance matrix $\\widehat{\\mathbf{S}}_w$ the zero matrix. In this case, both its trace and Frobenius norm are $0$. As specified, the ratios $r_{\\mathrm{trace}}$ and $r_{\\mathrm{fro}}$ are defined to be $+\\infty$.\n\nThe implementation will systematically execute these steps for each parameter set provided in the test suite, ensuring reproducibility by setting the specified random seed for each run.",
            "answer": "```python\nimport numpy as np\n# scipy is not strictly needed as numpy provides all necessary functionalities.\n# from scipy import linalg # For example, though np.linalg is used here.\n\ndef solve():\n    \"\"\"\n    Simulates neural collapse phenomena and computes collapse ratio metrics.\n    \"\"\"\n    \n    # Test suite: (seed, C, D, n, sigma, gamma)\n    test_cases = [\n        (0, 5, 10, 200, 1.0, 2.0),\n        (0, 5, 10, 200, 2.0, 4.0),\n        (1, 5, 10, 200, 3.0, 1.0),\n        (2, 5, 10, 200, 0.1, 3.0),\n        (3, 3, 4, 50, 0.0, 1.5),\n    ]\n\n    results = []\n\n    for case in test_cases:\n        seed, C, D, n, sigma, gamma = case\n        np.random.seed(seed)\n\n        # === 1. Data Generation ===\n        \n        # --- Generate true class means mu_c ---\n        # Sample C i.i.d. standard normal vectors\n        mu_raw = np.random.randn(D, C)\n        \n        # Center the columns by subtracting their mean vector\n        mu_mean = mu_raw.mean(axis=1, keepdims=True)\n        mu_centered = mu_raw - mu_mean\n        \n        # Normalize each column to unit norm\n        norms = np.linalg.norm(mu_centered, axis=0, keepdims=True)\n        # Avoid division by zero, though highly unlikely with continuous distributions\n        norms[norms == 0] = 1.0  \n        mu_unit_norm = mu_centered / norms\n        \n        # Scale to have norm gamma\n        mus = mu_unit_norm * gamma  # Shape (D, C)\n\n        # --- Sample data points for each class ---\n        data_by_class = []\n        for c in range(C):\n            mu_c = mus[:, c].reshape(1, D)  # Shape (1, D) for broadcasting\n            # Generate isotropic Gaussian noise\n            epsilon = np.random.randn(n, D) * sigma\n            # Generate class data\n            X_c = mu_c + epsilon  # Shape (n, D)\n            data_by_class.append(X_c)\n\n        # === 2. Empirical Covariance Estimation ===\n        \n        # --- Compute empirical class means hat_mu_c ---\n        hat_mus = np.array([X_c.mean(axis=0) for X_c in data_by_class]) # Shape (C, D)\n        \n        # --- Compute overall within-class covariance S_w ---\n        # List to store individual within-class covariance matrices\n        hat_Sigma_w_c_list = []\n        for c in range(C):\n            X_c = data_by_class[c]\n            hat_mu_c = hat_mus[c]\n            # Deviations from the class mean\n            diffs = X_c - hat_mu_c # Shape (n, D)\n            # Covariance for class c, using denominator n\n            hat_Sigma_w_c = (diffs.T @ diffs) / n # Shape (D, D)\n            hat_Sigma_w_c_list.append(hat_Sigma_w_c)\n        \n        # Average across classes to get S_w\n        hat_S_w = np.mean(np.array(hat_Sigma_w_c_list), axis=0) # Shape (D, D)\n\n        # --- Compute between-class covariance S_b ---\n        # Mean of empirical class means\n        hat_mu = hat_mus.mean(axis=0) # Shape (D,)\n        \n        # Deviations of class means from the grand mean\n        diffs_b = hat_mus - hat_mu # Shape (C, D)\n        \n        # Covariance of class means, using denominator C\n        hat_S_b = (diffs_b.T @ diffs_b) / C # Shape (D, D)\n        \n        # === 3. Metric Calculation ===\n        \n        tr_S_w = np.trace(hat_S_w)\n        tr_S_b = np.trace(hat_S_b)\n        \n        fro_S_w = np.linalg.norm(hat_S_w, 'fro')\n        fro_S_b = np.linalg.norm(hat_S_b, 'fro')\n\n        # Calculate ratios with division-by-zero handling\n        # If sigma is 0, S_w will be a zero matrix, tr_S_w and fro_S_w will be 0.\n        r_trace = tr_S_b / tr_S_w if tr_S_w != 0 else np.inf\n        r_fro = fro_S_b / fro_S_w if fro_S_w != 0 else np.inf\n        \n        results.append([r_trace, r_fro])\n\n    # Format output as a string representation of a list of lists.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}