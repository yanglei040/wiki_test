## 引言
在机器学习的世界里，我们的终极目标是构建一个能够对前所未见的数据做出精准预测的模型。理论上，这需要最小化模型的“[期望风险](@entry_id:634700)”——即在所有可能数据上的平均损失。然而，由于我们无法获知真实的数据[分布](@entry_id:182848)，这一目标在实践中是无法直接实现的。这便是[经验风险](@entry_id:633993)最小化（Empirical Risk Minimization, ERM）原则登场的舞台。ERM提出了一种务实且强大的替代方案：利用我们拥有的训练数据集，最小化模型在该数据集上的平均损失（即“[经验风险](@entry_id:633993)”），并以此作为我们追求良好泛化性能的代理目标。这个看似简单的原则构成了从线性回归到[深度神经网络](@entry_id:636170)等无数学习算法的理论核心。

本文将带领读者系统性地探索[经验风险](@entry_id:633993)最小化的世界。首先，在“原理与机制”一章中，我们将深入其核心定义，剖析其与[期望风险](@entry_id:634700)之间的关键差异，并探讨由此产生的过拟合问题以及如何通过[结构风险最小化](@entry_id:637483)、代理损失和[泛化理论](@entry_id:635655)等机制来应对这些挑战。接着，在“应用与跨学科连接”一章，我们将展示ERM框架如何灵活地扩展和应用于解决计算机视觉、自然语言处理、[联邦学习](@entry_id:637118)乃至强化学习等领域的复杂现实问题，如[分布偏移](@entry_id:638064)和数据偏见。最后，“动手实践”部分将提供具体的编码练习，帮助读者将理论知识转化为实践技能，加深对ERM内在权衡的理解。通过这三章的学习，您将构建起对[经验风险](@entry_id:633993)最小化从理论基础到前沿应用的全面认识。

## 原理与机制

在机器学习领域，我们的核心目标是训练一个模型，使其在面对未曾见过的新数据时能够做出准确的预测。这一目标被形式化为最小化模型的**[期望风险](@entry_id:634700)**（Expected Risk）。然而，[期望风险](@entry_id:634700)是根据真实的数据生成[分布](@entry_id:182848)计算的，而这个[分布](@entry_id:182848)在实践中是未知的。因此，我们不得不转向一个可行的替代方案：利用我们拥有的训练数据来近似这个目标。**[经验风险](@entry_id:633993)最小化**（Empirical Risk Minimization, ERM）原则正是基于这一思想的核心框架。本章将深入探讨ERM的基本原理、其内在的挑战，以及为克服这些挑战而发展出的一系列关键机制与理论。

### [经验风险](@entry_id:633993)最小化：核心原则

让我们从形式化的定义开始。假设一个输入空间 $\mathcal{X}$ 和一个输出空间 $\mathcal{Y}$，以及一个[联合概率分布](@entry_id:171550) $p(x, y)$，其中 $x \in \mathcal{X}$，$y \in \mathcal{Y}$。给定一个从[假设空间](@entry_id:635539) $\mathcal{F}$ 中选择的函数 $f: \mathcal{X} \to \mathcal{Y}$ 和一个非负的**损失函数** $L(f(x), y)$，用于量化预测 $f(x)$ 与真实标签 $y$ 之间的差异，我们定义**[期望风险](@entry_id:634700)** $R(f)$ 为：

$$
R(f) = \mathbb{E}_{(x,y) \sim p(x,y)}[L(f(x), y)] = \int L(f(x), y) \, d p(x, y)
$$

$R(f)$ 代表了模型 $f$ 在所有可能数据上的平均损失，是衡量[模型泛化](@entry_id:174365)能力的终极标准。然而，由于 $p(x,y)$ 未知，我们无法直接计算或最小化 $R(f)$。

幸运的是，我们通常拥有一个从 $p(x,y)$ 中[独立同分布](@entry_id:169067)（i.i.d.）采样得到的训练数据集 $S = \{(x_i, y_i)\}_{i=1}^{n}$。这个数据集为我们提供了一个关于真实[分布](@entry_id:182848)的经验性近似。我们可以定义**[经验风险](@entry_id:633993)**（Empirical Risk） $\hat{R}_n(f)$ 为模型在训练集 $S$ 上的平均损失：

$$
\hat{R}_n(f) = \frac{1}{n} \sum_{i=1}^{n} L(f(x_i), y_i)
$$

**[经验风险](@entry_id:633993)最小化 (ERM)** 原则非常直观：它主张我们应该选择[假设空间](@entry_id:635539) $\mathcal{F}$ 中能够使[经验风险](@entry_id:633993)最小化的那个函数 $\hat{f}_n$。

$$
\hat{f}_n = \arg\min_{f \in \mathcal{F}} \hat{R}_n(f)
$$

这个原则构成了监督学习中绝大多数算法的基石。从[线性回归](@entry_id:142318)到[支持向量机](@entry_id:172128)，再到[深度神经网络](@entry_id:636170)的训练，其本质都是在某个[假设空间](@entry_id:635539)内，根据特定的[损失函数](@entry_id:634569)，执行[经验风险](@entry_id:633993)最小化的过程。ERM的吸[引力](@entry_id:175476)在于其简洁性与实用性：它将一个不可解的、关于未知[分布](@entry_id:182848)的[优化问题](@entry_id:266749)，转化为了一个在有限数据集上可以具体执行的[优化问题](@entry_id:266749)。

### 经验与期望的鸿沟：过拟合的风险

ERM原则虽然强大，但其核心假设——即[经验风险](@entry_id:633993) $\hat{R}_n(f)$ 是[期望风险](@entry_id:634700) $R(f)$ 的一个良好代理——并非总是成立。最小化[经验风险](@entry_id:633993)与最小化[期望风险](@entry_id:634700)之间存在的鸿沟，是理解机器学习复杂性的关键，也是**[过拟合](@entry_id:139093)**（Overfitting）现象的根源。

当一个模型的容量（即其复杂性或表达能力）相对于训练数据的数量过大时，ERM可能会导致灾难性的后果。模型可能会“记住”训练数据中的每一个细节，包括其中的噪声，从而在[训练集](@entry_id:636396)上取得极低的[经验风险](@entry_id:633993)，但在新数据上表现糟糕，即具有很高的[期望风险](@entry_id:634700)。

一个极端的例子可以清晰地揭示这个问题 ``。考虑一个二[分类问题](@entry_id:637153)，其中标签 $Y \in \{0, 1\}$ 是纯粹的随机噪声，与输入 $X$ 无关（例如，无论 $X$ 为何， $Y$ 以 $0.5$ 的概率取 $0$ 或 $1$）。假设我们使用的函数类别 $\mathcal{F}$ 具有很高的复杂度，其[VC维](@entry_id:636849)度（Vapnik-Chervonenkis dimension）为 $d$。如果我们采集的样本量 $n$ 小于或等于 $d$（$n \le d$），那么该函数类别有足够的能力“打散”（shatter）这 $n$ 个点。这意味着，对于训练样本中任意一种标签组合 $\{Y_1, \dots, Y_n\}$，我们几乎总能（以概率1）在 $\mathcal{F}$ 中找到一个函数 $\hat{f}_n$ 完美地拟合这些数据，即 $\hat{f}_n(X_i) = Y_i$ 对所有 $i$ 成立。

在这种情况下，ERM找到的解 $\hat{f}_n$ 将完美地插值训练数据，其[经验风险](@entry_id:633993)（使用[0-1损失](@entry_id:173640)）为 $\hat{R}_n(\hat{f}_n) = 0$。然而，这个模型学到的完全是训练样本的随机性，而没有学到任何关于真实数据[分布](@entry_id:182848)的有用信息。当这个模型面对一个新数据点 $(X, Y)$ 时，由于 $Y$ 与 $X$ 无关，$\hat{f}_n(X)$ 的预测结果与真实标签 $Y$ 匹配的概率将是 $0.5$。因此，该模型的[期望风险](@entry_id:634700) $R(\hat{f}_n)$ 是 $0.5$，相当于随机猜测。这个例子生动地说明，在[模型容量](@entry_id:634375)过高时，ERM会因过度拟合训练数据而彻底失败，[经验风险](@entry_id:633993)与[期望风险](@entry_id:634700)之间出现了巨大的鸿沟。

### 构建实用的ERM：[损失函数](@entry_id:634569)与优化

上述挑战表明，简单地应用ERM原则是不够的。为了使其在实践中有效，我们必须仔细设计其两个关键组成部分：损失函数 $L$ 和最小化[经验风险](@entry_id:633993)的优化过程。

#### 理想与现实：代理[损失函数](@entry_id:634569)

在[分类问题](@entry_id:637153)中，我们最关心的通常是分类的正确与否。这自然地导向了**[0-1损失函数](@entry_id:173640)**：$L_{0-1}(\hat{y}, y) = \mathbf{1}\{\hat{y} \neq y\}$，如果预测错误，损失为1，否则为0。最小化基于[0-1损失](@entry_id:173640)的[经验风险](@entry_id:633993)，等价于最大化模型在[训练集](@entry_id:636396)上的准确率。

然而，直接最小化0-1[经验风险](@entry_id:633993)在计算上是极其困难的。[0-1损失函数](@entry_id:173640)是一个不连续、非凸的阶跃函数，其梯度在几乎所有地方都为零。这使得[基于梯度的优化](@entry_id:169228)方法（如[梯度下降](@entry_id:145942)）无法使用。事实上，可以证明，对于像[线性分类器](@entry_id:637554)这样相对简单的模型类，找到最小化0-1[经验风险](@entry_id:633993)的解也是一个**N[P-难](@entry_id:265298)**问题 ``。

为了克服这个计算障碍，[学习理论](@entry_id:634752)转向使用**代理损失函数**（Surrogate Loss Functions）。这些函数是[0-1损失](@entry_id:173640)的连续、通常是凸的近似。通过最小化代理损失，我们希望能够间接地最小化我们真正关心的[0-1损失](@entry_id:173640)。常见的代理损失包括：

*   **Hinge损失**：$L_{\text{hinge}}(z) = \max(0, 1-z)$，用于支持向量机（SVM）。
*   **Logistic损失**（或称[对数损失](@entry_id:637769)、[交叉熵损失](@entry_id:141524)）：$L_{\text{log}}(z) = \log(1 + \exp(-z))$，用于逻辑回归和[神经网](@entry_id:276355)络。

这些函数是凸的，使得相应的[经验风险](@entry_id:633993)最小化问题成为一个**凸[优化问题](@entry_id:266749)**，可以通过梯度下降等方法在[多项式时间](@entry_id:263297)内高效求解 ``。

一个好的代理[损失函数](@entry_id:634569)应该具有**分类校准**（Classification-Calibrated）的性质 ``。这意味着，如果一个模型在代理损失下达到了最优，那么它所产生的分类决策（例如通过[符号函数](@entry_id:167507) $\text{sign}(f(x))$）也应该在[0-1损失](@entry_id:173640)下是最优的。一个被广泛研究的、确保分类校准的充分条件是，代理损失函数 $\phi(z)$ 在 $z=0$ 处可微且其导数小于零，即 $\phi'(0)  0$。Hinge损失（在[广义导数](@entry_id:265109)意义下）和Logistic损失都满足这个条件，这为它们作为[0-1损失](@entry_id:173640)的有效替代品提供了理论保证。

#### [损失函数](@entry_id:634569)的稳健性

损失函数的选择不仅影响优化的可行性，还深刻影响模型对数据中异常值（outliers）的敏感度。**稳健性**（Robustness）是指模型性能在面对数据[分布](@entry_id:182848)的微小扰动（如异[常点](@entry_id:164624)的存在）时保持稳定的能力。

让我们通过一个简单的回归问题来考察不同损失函数对异常值的反应 ``。假设我们的模型是一个常数预测器 $f(x)=w$，目标是根据一组数据点 $\{y_1, \dots, y_n\}$ 来确定最佳的 $w$。

*   **[平方误差损失](@entry_id:178358)**（$L_2$ 损失）：$L_2(r) = \frac{1}{2}r^2$。最小化[经验风险](@entry_id:633993) $\frac{1}{n}\sum_i \frac{1}{2}(w-y_i)^2$ 的解是数据的**样本均值** $w_{L_2}^* = \frac{1}{n}\sum_i y_i$。均值对异常值非常敏感。一个远离中心的点可以极大地改变均值的位置。例如，对于数据集 $\{0, 0, 10\}$，均值为 $\frac{10}{3}$，这个结果被异[常点](@entry_id:164624) $10$ 显著地“拉”了过去。

*   **[绝对误差损失](@entry_id:170764)**（$L_1$ 损失）：$L_1(r) = |r|$。最小化[经验风险](@entry_id:633993) $\frac{1}{n}\sum_i |w-y_i|$ 的解是数据的**样本[中位数](@entry_id:264877)**。中位数对异常值具有很强的稳健性。只要数据集中的一半数据保持不变，无论异[常点](@entry_id:164624)的值变得多大，[中位数](@entry_id:264877)都不会改变。对于数据集 $\{0, 0, 10\}$，[中位数](@entry_id:264877)是 $0$，完全不受异[常点](@entry_id:164624) $10$ 的大小影响。

*   **Huber损失**：$L_\delta(r)$。这是一个结合了$L_2$和$L_1$损失优点的混合损失。当误差 $|r|$ 小于某个阈值 $\delta$ 时，它表现为平方损失；当误差大于 $\delta$ 时，它转变为线性损失。
    $$
    L_{\delta}(r) = \begin{cases} \frac{1}{2}r^{2}   \text{if } |r| \le \delta \\ \delta(|r| - \frac{1}{2}\delta)   \text{if } |r| > \delta \end{cases}
    $$
    Huber损失在误差较小的区域像$L_2$损失一样平滑可微，易于优化；而在误差较大的区域像$L_1$损失一样呈[线性增长](@entry_id:157553)，从而限制了异常值的影响。它通过参数 $\delta$ 在对异常值的敏感性（类似$L_2$）和稳健性（类似$L_1$）之间提供了一个平滑的权衡 ``。

因此，[损失函数](@entry_id:634569)的选择是一个关键的设计决策，它反映了我们对优化效率和模型对数据噪声的稳健性的综合考量。

### 控制[模型复杂度](@entry_id:145563)：从ERM到[结构风险最小化](@entry_id:637483)

我们已经看到，当[模型复杂度](@entry_id:145563)过高时，单纯的ERM会导致过拟合。这引出了一个核心问题：我们应该如何选择一个复杂度恰到好处的[假设空间](@entry_id:635539) $\mathcal{F}$？**[结构风险最小化](@entry_id:637483)**（Structural Risk Minimization, SRM）为这个问题提供了一个系统性的答案 ``。

SRM的思想不是在单个、巨大的[假设空间](@entry_id:635539)里进行搜索，而是将[假设空间](@entry_id:635539)组织成一个嵌套的结构序列：

$$
\mathcal{H}_1 \subset \mathcal{H}_2 \subset \mathcal{H}_3 \subset \dots \subset \mathcal{H}_m
$$

其中，每个假设类的复杂度（例如，由其[VC维](@entry_id:636849)度衡量）随着索引的增加而严格递增。对于每个类别 $\mathcal{H}_k$，我们都可以通过ERM找到其内部的最优函数 $\hat{f}_k$ 及其对应的最小[经验风险](@entry_id:633993) $\hat{R}_n(\mathcal{H}_k)$。由于类别是嵌套的，[经验风险](@entry_id:633993)必然随着类别复杂度的增加而单调不增：$\hat{R}_n(\mathcal{H}_1) \ge \hat{R}_n(\mathcal{H}_2) \ge \dots$。

然而，SRM并不选择[经验风险](@entry_id:633993)最低的那个类别（即最复杂的类别 $\mathcal{H}_m$）。相反，它试图平衡**[经验风险](@entry_id:633993)**和**[模型复杂度](@entry_id:145563)**。SRM选择的类别 $k^*$ 是最小化一个“惩罚化”风险的类别，该风险由[经验风险](@entry_id:633993)和-一个依赖于类别复杂度的**容量惩罚项**（Capacity Penalty）$\Omega(\mathcal{H}_k, n)$ 组成：

$$
k^* = \arg\min_{k} \left( \hat{R}_n(\mathcal{H}_k) + \Omega(\mathcal{H}_k, n, \delta) \right)
$$

容量惩罚项 $\Omega$ 是类别复杂度（如[VC维](@entry_id:636849)度）的增函数，是样本量 $n$ 的减函数。这意味着，更复杂的类别会受到更重的惩罚。

SRM的决策过程体现了经典的**偏见-[方差](@entry_id:200758)权衡**。选择过于简单的类别（如 $\mathcal{H}_1$）会导致高偏见（模型无法拟[合数](@entry_id:263553)据，$\hat{R}_n$ 很大）但低[方差](@entry_id:200758)（惩罚项 $\Omega$ 很小）。选择过于复杂的类别（如 $\mathcal{H}_m$）则导致低偏见（$\hat{R}_n$ 可能为0）但高[方差](@entry_id:200758)（惩罚项 $\Omega$ 很大），这正是[过拟合](@entry_id:139093)的特征。SRM的目标是找到这个权衡的最佳点。例如，即使类别 $\mathcal{H}_4$ 达到了零[经验风险](@entry_id:633993)，但如果从 $\mathcal{H}_3$ 到 $\mathcal{H}_4$ 的复杂度增加所带来的惩罚项增量，超过了[经验风险](@entry_id:633993)的减小量（$0.05$），SRM仍然会理智地选择更简单的类别 $\mathcal{H}_3$，从而有效避免过拟合 ``。

然而，SRM的有效性依赖于惩罚项 $\Omega$ 的紧密程度。如果理论上的[泛化界](@entry_id:637175)过于宽松或悲观，会导致惩罚项过大，使得SRM过度偏爱简单的模型，从而可能导致**[欠拟合](@entry_id:634904)**（Underfitting） ``。在实践中，像[交叉验证](@entry_id:164650)这样的数据驱动方法，常被用作选择[模型复杂度](@entry_id:145563)的替代或补充方案。

### 惩罚项的理论基础：量化[泛化误差](@entry_id:637724)

SRM中至关重要的容量惩罚项并非凭空产生，它源于[统计学习理论](@entry_id:274291)对**[泛化误差](@entry_id:637724)**（Generalization Error）——即[期望风险](@entry_id:634700)与[经验风险](@entry_id:633993)之差 $R(f) - \hat{R}_n(f)$——的深刻分析。理论的目标是为这个差值提供一个高概率的[上界](@entry_id:274738)，即**[泛化界](@entry_id:637175)**（Generalization Bound）。

一个典型的[泛化界](@entry_id:637175)形式如下：以至少 $1-\delta$ 的概率，对于[假设空间](@entry_id:635539) $\mathcal{F}$ 中的所有函数 $f$，同时成立：

$$
R(f) \le \hat{R}_n(f) + \text{Complexity}(\mathcal{F}, n, \delta)
$$

这里的 $\text{Complexity}(\mathcal{F}, n, \delta)$ 就是SRM中容量惩罚项 $\Omega$ 的理论原型。它量化了由于在有限样本上最小化[经验风险](@entry_id:633993)而非[期望风险](@entry_id:634700)所带来的不确定性。这个复杂度项取决于三个因素：[假设空间](@entry_id:635539) $\mathcal{F}$ 的内在复杂性、样本量 $n$ 和我们期望界成立的置信度 $1-\delta$。

衡量类别复杂度的经典工具包括：
*   **[VC维](@entry_id:636849)度**：一个[组合数学](@entry_id:144343)概念，衡量一个函数类能够“打散”的点的最大数量。它是[分布](@entry_id:182848)无关的，但可能比较粗略。
*   **Rademacher复杂度**：一个更精细的、与数据[分布](@entry_id:182848)相关的复杂度度量 ``。它衡量的是一个函数类能够拟合随机噪声的能力。给定一个样本 $S$，**经验Rademacher复杂度** $\hat{\mathfrak{R}}_S(\mathcal{F})$ 定义为：
    $$
    \hat{\mathfrak{R}}_S(\mathcal{F}) = \mathbb{E}_{\sigma} \left[ \sup_{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^n \sigma_i f(x_i) \right]
    $$
    其中 $\sigma_i$ 是独立的、取值为 $\{-1, +1\}$ 的[随机变量](@entry_id:195330)。通过一系列精巧的数学推导（包括对称化技术和McDiarmid不等式等[集中不等式](@entry_id:273366)），可以证明[泛化误差](@entry_id:637724)与Rademacher复杂度紧密相关。一个基于Rademacher复杂度的典型[泛化界](@entry_id:637175)形如 ``：
    $$
    R(f) \le \hat{R}_n(f) + 2 \mathfrak{R}_n(\mathcal{F}) + C(n, \delta)
    $$
    其中 $\mathfrak{R}_n(\mathcal{F})$ 是期望Rademacher复杂度（即 $\hat{\mathfrak{R}}_S(\mathcal{F})$ 在所有样本 $S$ 上的期望），$C(n, \delta)$ 是一个只依赖于 $n$ 和 $\delta$ 的[置信度](@entry_id:267904)项（例如 $\sqrt{\frac{\ln(1/\delta)}{2n}}$）。

这些理论界为SRM的惩罚项提供了坚实的基础，并清晰地表明，为了获得良好的泛化能力（小的 $R(f)$），我们必须在拟合训练数据（小的 $\hat{R}_n(f)$）和控制[模型复杂度](@entry_id:145563)（小的复杂度项）之间进行权衡。

### ERM框架的扩展：应对真实世界的数据挑战

ERM不仅是一个理论原则，更是一个极具适应性的实践框架。通过对ERM公式中的组件进行修改，我们可以使其适应各种复杂的、非理想化的数据场景。

#### 样本[选择偏差](@entry_id:172119)的校正

标准的ERM假设训练样本是真实数据[分布](@entry_id:182848)的无偏代表。然而，在现实世界中，数据收集过程可能存在系统性的**样本[选择偏差](@entry_id:172119)**（Sample Selection Bias），即某些类型的样本比其他类型更容易被观察到和收集 ``。例如，在医学诊断中，病情更严重的患者可能更倾向于去医院，导致医院收集的数据中重症患者比例偏高。

如果每个样本 $(x,y)$ 被包含在[训练集](@entry_id:636396)中的概率 $q(x)$ 是已知的，并且这个概率依赖于特征 $x$ 而不恒定，那么在观测到的样本上计算的朴素[经验风险](@entry_id:633993) $\hat{R}_{\text{naive}}(f)$ 将是[期望风险](@entry_id:634700) $R(f)$ 的一个有偏估计。它会不成比例地放大那些易于被观测的样本的损失。

为了纠正这种偏差，我们可以使用**逆[倾向得分](@entry_id:635864)加权**（Inverse Propensity Scoring, IPS）来构建一个无偏的[风险估计](@entry_id:754371)器。其核心思想是为每个观测到的样本赋予一个权重，该权重等于其被观测到的概率的倒数。修正后的无偏[经验风险](@entry_id:633993)估计器为：

$$
\hat{R}_{\text{unbiased}}(f) = \frac{1}{n} \sum_{i=1}^{m} \frac{L(f(x^{(i)}), y^{(i)})}{q(x^{(i)})}
$$

其中 $n$ 是从真实[分布](@entry_id:182848)中最初抽取的总样本数（包括被选中和未被选中的），$m$ 是最终被选中的样本数，求和只针对这 $m$ 个观测到的样本。通过给那些不易被观测的样本（$q(x)$ 小）赋予更高的权重，这个估计器可以有效地重构出原始无偏[分布](@entry_id:182848)下的[期望风险](@entry_id:634700) ``。在ERM框架下最小化这个加权的[经验风险](@entry_id:633993)，可以得到一个在原始、无偏[分布](@entry_id:182848)上表现更好的模型。

#### [类别不平衡](@entry_id:636658)的处理

另一个常见的数据挑战是**[类别不平衡](@entry_id:636658)**（Class Imbalance），即不同类别的样本数量差异巨大。例如，在欺诈检测中，绝大多数交易是正常的，只有极少数是欺诈性的。在这种情况下，标准的ERM会倾向于一个总是预测多数类的模型，因为它可以在不学习任何有用模式的情况下获得很高的准确率（很低的[经验风险](@entry_id:633993)）。

为了解决这个问题，我们可以引入**[类别加权](@entry_id:635159)**（Class Weighting）的ERM ``。我们为每个类别 $y$ 分配一个权重 $\omega_y$，并在计算[经验风险](@entry_id:633993)时对每个样本的损失进行加权：

$$
\hat{R}_w(f) = \frac{1}{n}\sum_{i=1}^{n} \omega_{y_i} L(f(x_i),y_i)
$$

一种常见的策略是设置权重与类别频率成反比，例如，$\omega_1 \propto 1/n_1$ 和 $\omega_0 \propto 1/n_0$，其中 $n_1$ 和 $n_0$ 分别是正负类别的样本数。这相当于在训练中“放大”了少数类样本的重要性，迫使模型更加关注它们。

[类别加权](@entry_id:635159)不仅改变了模型的训练目标，也影响了最优的决策策略。对于一个能输出校准概率分数 $s(x) \approx \mathbb{P}(y=1|x)$ 的模型，在标准的0-1风险下，最优决策阈值是 $0.5$。但在加权风险下，最优阈值会移动。可以证明，最优阈值 $\tau^*$ 变为 ``：

$$
\tau^* = \frac{\omega_0}{\omega_0 + \omega_1}
$$

特别地，如果使用与类别频率成反比的权重，最优阈值恰好等于正类的经验流行率 $\hat{\pi} = n_1/n$。对于一个稀有类别（$\hat{\pi}$ 很小），这意味着最优阈值会变得很低，从而提高模型的**召回率**（Recall），即找出更多正类的能力，但这通常会以牺牲**[精确率](@entry_id:190064)**（Precision）为代价。

### 现代前沿：稳健与[隐式正则化](@entry_id:187599)

ERM原则在[深度学习](@entry_id:142022)时代依然充满活力，并被扩展以应对新的挑战，如模型对微小扰动的稳健性。

#### 稳健ERM：对抗性训练

[深度神经网络](@entry_id:636170)虽然强大，但被发现对输入端的微小、精心设计的扰动（称为**[对抗性扰动](@entry_id:746324)**）异常敏感。**对抗性训练**（Adversarial Training）是一种旨在提升模型稳健性的主流技术，它可以被看作是**稳健ERM**（Robust ERM）的一种形式 ``。

在稳健ERM中，我们最小化的不是每个样本点的损失，而是该点周围一个邻域内（由范数球 $\|\delta\| \le \epsilon$ 定义）的**最坏情况损失**。其目标函数——**对抗性[经验风险](@entry_id:633993)**——可以写成一个min-max形式：

$$
\hat{R}_{\text{adv}}(f) = \frac{1}{n}\sum_{i=1}^n \left[ \max_{\|\delta\| \le \epsilon} L\big(f(x_i+\delta),y_i\big) \right]
$$

这个目标函数要求模型不仅要在原始训练点上表现良好，还要在其周围的整个“扰动球”内都表现良好。解决这个min-max问题在计算上极具挑战性。内部的“max”问题（寻找最差的扰动 $\delta$）通常是一个非凹的最大化问题，难以精确求解。

在实践中，内部最大化通常通过迭代[优化算法](@entry_id:147840)来近似，例如**[投影梯度下降](@entry_id:637587)**（Projected Gradient Descent, PGD）。PGD通过在[损失函数](@entry_id:634569)上进行多步梯度上升来寻找一个近似的最差扰动。需要注意的是，任何此类近似算法找到的扰动所产生的损失，都只是真实最坏情况损失的一个**下界** ``。另一种策略是，用一个易于最大化的**上界代理**（upper-bounding surrogate）来替换内部的[损失函数](@entry_id:634569)，从而将复杂的min-max问题转化为一个更易于处理的最小化问题 ``。

#### [数据增强](@entry_id:266029)中的[隐式正则化](@entry_id:187599)：Mixup

[数据增强](@entry_id:266029)是现代[深度学习训练](@entry_id:636899)流程中不可或缺的一环。其中一种名为 **Mixup** 的技术，通过对成对的训练样本进行线性插值来创造新的合成样本，展现了一种新颖的正则化机制 ``。

具体来说，Mixup从[训练集](@entry_id:636396)中随机抽取两个样本 $(x_i, y_i)$ 和 $(x_j, y_j)$，并根据一个从Beta[分布](@entry_id:182848)中采样的系数 $\lambda \in [0, 1]$ 来创建新的训练样本：

$$
\tilde{x} = \lambda x_i + (1-\lambda) x_j
$$
$$
\tilde{y} = \lambda y_i + (1-\lambda) y_j
$$

然后，模型在这些合成样本上最小化[经验风险](@entry_id:633993)。表面上看，这只是在扩充数据集，但其背后蕴含着深刻的正则化原理。Mixup训练的[目标函数](@entry_id:267263)可以表示为：

$$
\hat{R}_{\text{mix}}(f)=\mathbb{E}_{i,j,\lambda}\big[\ell\big(f(\lambda x_i+(1-\lambda)x_j),\,\lambda y_i+(1-\lambda)y_j\big)\big]
$$

最小化这个期望损失，实际上是在鼓励模型 $f$ 的行为在任意两个训练点之间的线性路径上保持“平滑”。如果模型在点 $x_i$ 和 $x_j$ 之间表现出剧烈的[非线性](@entry_id:637147)行为（即函数有很大的曲率），那么 $f(\lambda x_i+(1-\lambda)x_j)$ 会显著偏离 $f(x_i)$ 和 $f(x_j)$ 的[线性插值](@entry_id:137092)，导致更高的损失。因此，Mixup隐式地惩罚了模型函数在训练样本连线上的[二阶导数](@entry_id:144508)，促使函数表现得更像一个线性函数。这种鼓励[函数空间](@entry_id:143478)线性的正则化效应，被证明能有效提升模型的泛化能力和对[对抗性扰动](@entry_id:746324)的稳健性。

### 更广阔的视角：判别方法与生成方法

最后，将ERM置于[统计建模](@entry_id:272466)的更广阔图景中是很有裨益的。ERM是一种典型的**判别方法**（Discriminative Approach）：它直接学习一个从输入 $x$ 到输出 $y$ 的映射或[决策边界](@entry_id:146073)，而不关心数据本身的生成过程 $p(x,y)$。

与此相对的是**生成方法**（Generative Approach），它试图学习数据的联合分布 $p(x,y)$ 或条件分布 $p(y|x)$。例如，通过**[最大似然估计](@entry_id:142509)**（Maximum Likelihood Estimation, MLE）来拟合一个参数化的[条件概率](@entry_id:151013)模型 $p_\theta(y|x)$ ``。

这两种方法之间存在深刻的联系与区别：

*   **等价性**：在某些情况下，两者是等价的。例如，对于二[分类问题](@entry_id:637153)，如果使用**[负对数似然](@entry_id:637801)损失**（即[交叉熵损失](@entry_id:141524)），那么基于ERM的判别式训练等价于对[条件概率](@entry_id:151013)模型 $p_\theta(y=1|x)$ 进行[最大似然估计](@entry_id:142509) ``。

*   **稳健性与效率**：当[生成模型](@entry_id:177561)的假设（例如，假设类别条件分布是高斯分布）与真实数据不符时（即**[模型设定错误](@entry_id:170325)**），直接关注决策边界的判别方法通常表现更稳健、更准确。因为它将模型的全部“精力”都用在了划分数据上，而生成模型则“浪费”了部分能力去拟合一个错误的完整数据[分布](@entry_id:182848) ``。

*   **数据效率与[归纳偏置](@entry_id:137419)**：在小样本、高维度的情况下，如果[生成模型](@entry_id:177561)的假设是正确的，它通常比灵活的[判别模型](@entry_id:635697)表现更好。这是因为[生成模型](@entry_id:177561)的参数化结构提供了一种强烈的**[归纳偏置](@entry_id:137419)**（Inductive Bias），可以显著降低模型的[方差](@entry_id:200758)，从而在数据稀疏时获得更好的泛化性能 ``。

*   **决策灵活性**：能够输出校准概率的[生成模型](@entry_id:177561)（或经过校准的[判别模型](@entry_id:635697)）在实际决策中更具优势。例如，在代价敏感的[分类任务](@entry_id:635433)中，不同类型的错误（假阳性与假阴性）具有不同的代价。一个概率模型可以让我们通过简单地调整决策阈值来适应变化的代价，而一个只输出硬标签的分类器则需要为每种代价组合重新训练 ``。

总之，[经验风险](@entry_id:633993)最小化不仅是机器学习中的一个基础性计算原则，更是一个内涵丰富、不断演化的理论框架。从其最初的朴素形式，到通过代理损失、[结构风险最小化](@entry_id:637483)、[泛化理论](@entry_id:635655)、鲁棒性扩展和[自适应加权](@entry_id:638030)等机制的不断完善，ERM为我们提供了一套强大的工具，用以应对从理论到实践的各种挑战，并持续推动着学习算法的前沿发展。