{
    "hands_on_practices": [
        {
            "introduction": "本练习将带你回到经典的模型选择问题中，探索多项式回归中的“偏差-方差权衡”。你将通过分析不同复杂度的模型（多项式阶数 $d$）的训练误差和验证误差，来理解模型容量是如何影响泛化能力的。这个实践的核心是学习如何量化并识别出那个在欠拟合与过拟合之间达到最佳平衡的模型，这对应着经典“U形”测试误差曲线的谷底。",
            "id": "3107026",
            "problem": "您将获得对同一数据集拟合的 $d$ 阶多项式回归模型的观测值。对于每个测试用例，您将获得一组阶数 $d \\in \\mathbb{N}$ 对应的经验训练均方误差 (MSE) $E_{\\text{train}}(d)$ 和经验交叉验证均方误差 $E_{\\text{val}}(d)$。您的任务是通过对泛化差距 $g(d)$ 与 $d$ 进行回归来预测过拟合风险，并分类出能最小化预期泛化误差估计值的最优阶数。\n\n基本依据和定义：\n- 复杂度为 $d$ 时的泛化误差可以表示为 $E_{\\text{gen}}(d) = E_{\\text{train}}(d) + g(d)$，其中 $g(d)$ 是由 $g(d) = E_{\\text{test}}(d) - E_{\\text{train}}(d)$ 定义的泛化差距。在实践中，$E_{\\text{test}}(d)$ 是未知的，交叉验证被用作一个经过充分检验的代理，因此我们将差距估计为 $g(d) \\approx E_{\\text{val}}(d) - E_{\\text{train}}(d)$。\n- 过拟合风险随模型复杂度增加而增加，这反映为 $g(d)$ 作为 $d$ 的函数的正斜率。\n\n算法要求：\n- 对于每个测试用例，在每个观测到的阶数 $d_k$ 处计算 $g(d_k) = E_{\\text{val}}(d_k) - E_{\\text{train}}(d_k)$。\n- 使用普通最小二乘法 (Ordinary Least Squares (OLS)) 将直线 $g(d) \\approx a + b\\,d$ 拟合到观测对 $\\{(d_k, g(d_k))\\}$。\n- 在每个观测到的阶数处，构建估计的预期泛化误差为 $\\widehat{E}_{\\text{gen}}(d_k) = E_{\\text{train}}(d_k) + \\widehat{a} + \\widehat{b}\\,d_k$。\n- 将最优阶数 $\\widehat{d}^{\\star}$ 分类为所提供集合中能最小化 $\\widehat{E}_{\\text{gen}}(d_k)$ 的整数阶数。如果在数值容差范围内有多个阶数达到相同的最小值，则选择其中最小的阶数（偏好更低的复杂度）。\n- 每个测试用例报告两个量：差距对阶数回归的估计斜率 $\\widehat{b}$（四舍五入到4位小数）和分类出的最优阶数 $\\widehat{d}^{\\star}$（作为整数）。\n\n测试套件：\n- 测试用例 1：$d = [1,2,3,4,5]$, $E_{\\text{train}} = [9.0,6.0,4.5,4.0,3.8]$, $E_{\\text{val}} = [10.0,7.0,5.0,5.2,6.0]$。\n- 测试用例 2：$d = [1,2,3,4]$, $E_{\\text{train}} = [5.0,4.2,3.6,3.3]$, $E_{\\text{val}} = [5.0,4.2,3.6,3.3]$。\n- 测试用例 3：$d = [1,2,3,4,5,6]$, $E_{\\text{train}} = [12.0,8.0,6.0,5.2,5.0,4.9]$, $E_{\\text{val}} = [11.5,7.3,5.1,4.1,3.7,3.4]$。\n- 测试用例 4：$d = [1,10]$, $E_{\\text{train}} = [5.0,0.1]$, $E_{\\text{val}} = [5.1,6.0]$。\n- 测试用例 5：$d = [2,3,4]$, $E_{\\text{train}} = [8.0,6.0,5.0]$, $E_{\\text{val}} = [8.7,6.6,5.4]$。\n\n输出规格：\n- 对于每个测试用例，输出一个双元素列表 $[\\widehat{b}, \\widehat{d}^{\\star}]$，其中 $\\widehat{b}$ 是四舍五入到4位小数的斜率，$\\widehat{d}^{\\star}$ 是一个整数。\n- 您的程序应生成单行输出，其中包含一个列表，该列表按顺序汇总了每个测试用例的输出，且不含空格。每个元素本身必须是如前所述的双元素列表。最终打印输出必须只有一行。\n\n不涉及物理单位。所有角度（如有）在此均不相关。不需要百分比。\n\n您的程序必须是一个完整、可运行的程序，该程序在内部定义上述测试用例，并生成指定的单行输出。",
            "solution": "### 步骤 1：提取已知信息\n- **模型**：阶数为 $d \\in \\mathbb{N}$ 的多项式回归模型。\n- **每个测试用例的数据**：一组阶数 $d_k$，对应的训练均方误差 (MSE) $E_{\\text{train}}(d_k)$ 和交叉验证均方误差 $E_{\\text{val}}(d_k)$。\n- **定义**：\n    - 泛化误差：$E_{\\text{gen}}(d) = E_{\\text{train}}(d) + g(d)$。\n    - 泛化差距：$g(d) = E_{\\text{test}}(d) - E_{\\text{train}}(d)$。\n    - 经验泛化差距估计：$g(d) \\approx E_{\\text{val}}(d) - E_{\\text{train}}(d)$。\n- **算法要求**：\n    1.  计算每个阶数的经验差距：$g(d_k) = E_{\\text{val}}(d_k) - E_{\\text{train}}(d_k)$。\n    2.  使用普通最小二乘法 (OLS) 将直线 $g(d) \\approx a + b\\,d$ 拟合到数据点 $\\{(d_k, g(d_k))\\}$，以找到估计的截距 $\\widehat{a}$ 和斜率 $\\widehat{b}$。\n    3.  估计每个阶数下的预期泛化误差：$\\widehat{E}_{\\text{gen}}(d_k) = E_{\\text{train}}(d_k) + \\widehat{a} + \\widehat{b}\\,d_k$。\n    4.  将最优阶数 $\\widehat{d}^{\\star}$ 分类为所提供集合中能最小化 $\\widehat{E}_{\\text{gen}}(d_k)$ 的整数阶数。平局决胜规则是，如果多个阶数产生相同的最小值，则选择最小的阶数。\n    5.  报告四舍五入到4位小数的斜率 $\\widehat{b}$ 和整数最优阶数 $\\widehat{d}^{\\star}$。\n- **测试套件**：\n    - **测试用例 1**：$d = [1,2,3,4,5]$, $E_{\\text{train}} = [9.0,6.0,4.5,4.0,3.8]$, $E_{\\text{val}} = [10.0,7.0,5.0,5.2,6.0]$。\n    - **测试用例 2**：$d = [1,2,3,4]$, $E_{\\text{train}} = [5.0,4.2,3.6,3.3]$, $E_{\\text{val}} = [5.0,4.2,3.6,3.3]$。\n    - **测试用例 3**：$d = [1,2,3,4,5,6]$, $E_{\\text{train}} = [12.0,8.0,6.0,5.2,5.0,4.9]$, $E_{\\text{val}} = [11.5,7.3,5.1,4.1,3.7,3.4]$。\n    - **测试用例 4**：$d = [1,10]$, $E_{\\text{train}} = [5.0,0.1]$, $E_{\\text{val}} = [5.1,6.0]$。\n    - **测试用例 5**：$d = [2,3,4]$, $E_{\\text{train}} = [8.0,6.0,5.0]$, $E_{\\text{val}} = [8.7,6.6,5.4]$。\n- **输出规格**：对于每个测试用例，输出一个双元素列表 $[\\widehat{b}, \\widehat{d}^{\\star}]$，最终输出字符串为一个单行列表，不含空格。\n\n### 步骤 2：使用提取的已知信息进行验证\n根据验证标准对问题陈述进行评估。\n- **科学依据**：该问题基于统计学习理论的基本概念，包括偏差-方差权衡、过拟合、训练误差、验证误差和泛化误差。使用普通最小二乘法来建模模型复杂度和泛化差距之间的关系是一种标准且可靠的分析技术。\n- **良构性**：该问题是良构的。对于每个测试用例，用于 OLS 回归的不同数据点的数量至少为2，这确保了线性参数的唯一解。寻找最优阶数是在一个有限集上进行最小化，保证有解。平局决胜规则确保了解的唯一性。\n- **客观性**：该问题使用精确的数学定义和清晰、明确的算法过程进行陈述。输入是数值型的，所需的输出是明确定义的。\n- **缺陷检查清单**：该问题未违反任何指定的缺陷。它在科学上可靠、可形式化、完整、现实且良构。它需要进行非平凡的计算和推理。\n\n### 步骤 3：结论与行动\n该问题是有效的。将提供一个完整的解决方案。\n\n该问题要求分析模型性能与复杂度（具体指多项式回归模型的阶数 $d$）的函数关系。分析的核心在于理解和建模泛化差距 $g(d)$，它代表了模型在未见过数据上的性能（由验证误差 $E_{\\text{val}}$ 近似）与其在训练数据上的性能（$E_{\\text{train}}$）之间的差异。随着复杂度增加，差距不断增大是过拟合的一个标志。\n\n指定算法旨在创建一个平滑的泛化误差估计，以便做出比简单选择验证误差最低的模型更稳健的模型选择决策。验证误差本身可能含有噪声，对泛化差距的趋势进行建模有助于滤除这种噪声。\n\n每个测试用例的步骤如下：\n\n1.  **计算经验泛化差距**：对于每个给定的多项式阶数 $d_k$，我们使用提供的训练误差和验证误差计算经验泛化差距 $g(d_k)$：\n    $$g(d_k) = E_{\\text{val}}(d_k) - E_{\\text{train}}(d_k)$$\n\n2.  **通过 OLS 建模泛化差距**：我们假设模型复杂度 $d$ 和泛化差距 $g(d)$ 之间存在线性关系。我们使用普通最小二乘法 (OLS) 将一条直线 $\\widehat{g}(d) = \\widehat{a} + \\widehat{b}d$ 拟合到观测点集 $\\{(d_k, g(d_k))\\}$。选择斜率 $\\widehat{b}$ 和截距 $\\widehat{a}$ 以最小化平方差之和 $\\sum_k (g(d_k) - (\\widehat{a} + \\widehat{b}d_k))^2$。对于一组 $n$ 个点，OLS 估计量由以下公式给出：\n    $$ \\widehat{b} = \\frac{\\sum_{k=1}^{n} (d_k - \\bar{d})(g_k - \\bar{g})}{\\sum_{k=1}^{n} (d_k - \\bar{d})^2} $$\n    $$ \\widehat{a} = \\bar{g} - \\widehat{b}\\bar{d} $$\n    其中 $\\bar{d} = \\frac{1}{n}\\sum_k d_k$ 和 $\\bar{g} = \\frac{1}{n}\\sum_k g(d_k)$ 是样本均值。斜率 $\\widehat{b}$ 可作为过拟合风险的直接度量；正的 $\\widehat{b}$ 表示训练性能和验证性能之间的差距随着模型复杂度的增加而扩大。\n\n3.  **估计泛化误差**：使用差距的线性模型，我们构建了真实泛化误差的平滑估计 $\\widehat{E}_{\\text{gen}}(d_k)$：\n    $$ \\widehat{E}_{\\text{gen}}(d_k) = E_{\\text{train}}(d_k) + \\widehat{g}(d_k) = E_{\\text{train}}(d_k) + \\widehat{a} + \\widehat{b}d_k $$\n    该估计结合了直接观测到的训练误差（反映了模型对数据的拟合程度）和对泛化惩罚项的正则化估计（考虑了复杂度）。\n\n4.  **确定最优阶数**：最优阶数 $\\widehat{d}^{\\star}$ 从给定的集合 $\\{d_k\\}$ 中选择，该阶数能最小化我们的估计泛化误差 $\\widehat{E}_{\\text{gen}}(d_k)$。\n    $$ \\widehat{d}^{\\star} = \\underset{d_k}{\\arg\\min} \\{ \\widehat{E}_{\\text{gen}}(d_k) \\} $$\n    问题规定，如果出现平局，应选择达到最小误差的阶数中最小的那个。这反映了简约原则（奥卡姆剃刀）：在所有其他条件相同的情况下，偏好更简单的模型。\n\n最后，对于每个测试用例，我们报告计算出的斜率 $\\widehat{b}$（过拟合风险的度量）和确定的最优阶数 $\\widehat{d}^{\\star}$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the model selection problem for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        {'d': [1, 2, 3, 4, 5], \n         'E_train': [9.0, 6.0, 4.5, 4.0, 3.8], \n         'E_val': [10.0, 7.0, 5.0, 5.2, 6.0]},\n        # Test case 2\n        {'d': [1, 2, 3, 4], \n         'E_train': [5.0, 4.2, 3.6, 3.3], \n         'E_val': [5.0, 4.2, 3.6, 3.3]},\n        # Test case 3\n        {'d': [1, 2, 3, 4, 5, 6], \n         'E_train': [12.0, 8.0, 6.0, 5.2, 5.0, 4.9], \n         'E_val': [11.5, 7.3, 5.1, 4.1, 3.7, 3.4]},\n        # Test case 4\n        {'d': [1, 10], \n         'E_train': [5.0, 0.1], \n         'E_val': [5.1, 6.0]},\n        # Test case 5\n        {'d': [2, 3, 4], \n         'E_train': [8.0, 6.0, 5.0], \n         'E_val': [8.7, 6.6, 5.4]},\n    ]\n\n    results_as_strings = []\n    \n    for case in test_cases:\n        # Extract and convert data to numpy arrays for vectorized operations\n        d = np.array(case['d'], dtype=float)\n        E_train = np.array(case['E_train'], dtype=float)\n        E_val = np.array(case['E_val'], dtype=float)\n        \n        # Step 1: Compute the empirical generalization gap\n        g = E_val - E_train\n        \n        # Step 2: Fit a straight line g(d) = a + b*d using OLS.\n        # np.polyfit with degree 1 returns the coefficients [b, a] for slope and intercept.\n        b_hat, a_hat = np.polyfit(d, g, 1)\n        \n        # Step 3: Form the estimated expected generalization error\n        # E_gen_hat(d) = E_train(d) + (a_hat + b_hat*d)\n        E_gen_hat = E_train + a_hat + b_hat * d\n        \n        # Step 4: Classify the optimal degree d_star\n        # np.argmin finds the index of the first occurrence of the minimum value.\n        # Since the input degrees 'd' are sorted, this satisfies the tie-breaking rule\n        # of choosing the smallest degree.\n        min_error_index = np.argmin(E_gen_hat)\n        d_star = int(d[min_error_index])\n        \n        # Format the result for this case as a string \"[b,d_star]\" with no spaces\n        # and b rounded to 4 decimal places.\n        case_result_str = f\"[{b_hat:.4f},{d_star}]\"\n        results_as_strings.append(case_result_str)\n\n    # Final print statement in the exact required format.\n    # The output is a single list containing the results for all test cases.\n    print(f\"[{','.join(results_as_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了经典理论后，我们将探索一个颠覆传统观念的现代深度学习现象：双峰下降（double descent）。传统观点认为，当模型容量超过某个点后，测试误差会持续上升，但实践表明，在高度过参数化的模型中，测试误差在越过“插值阈值”后会再次下降。本练习将通过一个线性自编码器，让你亲手模拟并观察这一奇特的“先降后升再降”的测试误差曲线，直观感受模型容量与泛化之间更复杂的关系。",
            "id": "3183618",
            "problem": "您将通过改变瓶颈层大小，实现一个仿真来研究线性自编码器中的双峰现象。目标是将训练重构误差和测试时泛化能力与模型容量如何跨越插值阈值并趋近于单位映射联系起来。使用一个纯粹的数学框架，该框架基于经验风险最小化（ERM）、主成分分析（PCA）和正交投影的性质，并设计一个程序，为多个测试用例生成可量化的输出。\n\n考虑一个权重绑定的线性自编码器，其中输入是向量 $x \\in \\mathbb{R}^d$，编码器为 $z = W^\\top x$（其中 $W \\in \\mathbb{R}^{d \\times m}$），解码器重构输出为 $\\hat{x} = W z = W W^\\top x$。设训练数据矩阵为 $X_{\\text{train}} \\in \\mathbb{R}^{n \\times d}$，测试数据矩阵为 $X_{\\text{test}} \\in \\mathbb{R}^{n_{\\text{test}} \\times d}$。通过其经验均值 $\\mu_{\\text{train}} \\in \\mathbb{R}^d$ 对训练数据进行中心化，并使用相同的 $\\mu_{\\text{train}}$ 对测试数据进行中心化，以评估固定估计器的泛化能力。对于给定的瓶颈层大小 $m$（$1 \\le m \\le d$），定义重构矩阵 $P_m = W_m W_m^\\top$，其中 $W_m$ 具有标准正交的列，这些列张成 $\\mathbb{R}^d$ 的一个 $m$ 维子空间。在瓶颈层大小为 $m$ 时的训练重构误差为\n$$\nE_{\\text{train}}(m) = \\frac{1}{n} \\sum_{i=1}^n \\left\\| x_i - P_m x_i \\right\\|_2^2,\n$$\n测试重构误差为\n$$\nE_{\\text{test}}(m) = \\frac{1}{n_{\\text{test}}} \\sum_{j=1}^{n_{\\text{test}}} \\left\\| x^{\\text{test}}_j - P_m x^{\\text{test}}_j \\right\\|_2^2,\n$$\n其中所有的 $x_i$ 和 $x^{\\text{test}}_j$ 都已通过 $\\mu_{\\text{train}}$ 中心化。\n\n基本和建模假设：\n- 经验风险最小化（ERM）：估计器在 $W$ 的列为标准正交的约束下，最小化平均训练重构误差 $E_{\\text{train}}(m)$。\n- 主成分分析（PCA）：对于具有平方误差和绑定权重的线性自编码器，其 ERM 解得到的 $W_m$ 的列是中心化训练矩阵的前 $m$ 个右奇异向量（等价于经验协方差矩阵的前 $m$ 个特征向量），因此 $P_m$ 是到该 $m$ 维子空间上的正交投影算子。\n- 正交投影：对于任何 $m$，$P_m$ 是一个秩为 $m$ 的幂等对称矩阵，且 $\\left\\| x - P_m x \\right\\|_2^2$ 是 $x$ 到由 $W_m$ 张成的子空间的平方距离。\n\n容量跨越与单位映射：\n- 插值阈值：设 $r = \\operatorname{rank}(X_{\\text{train}})$。当 $m \\ge r$ 时，存在使 $E_{\\text{train}}(m) = 0$ 的解，因为投影算子可以张成训练数据子空间。满足此条件的最小 $m$ 记为 $m_{\\text{interp}}$。\n- 单位映射：当 $m = d$ 且 $W_d$ 有 $d$ 个标准正交列时，$P_d = I_d$，这使得 $E_{\\text{train}}(d) = 0$ 和 $E_{\\text{test}}(d) = 0$，从而将容量与单位映射联系起来。\n\n双峰现象研究：\n- 随着 $m$ 从 $1$ 增加到 $d$，测试误差 $E_{\\text{test}}(m)$ 可能会表现出初始下降（增加了与信号对齐的方向），然后在 $m \\approx r$ 附近上升（对训练子空间过拟合），随后当 $m \\to d$ 时再次下降（趋近于单位映射）。这种形状被称为双峰现象。\n\n实现要求：\n- 通过从 $\\mathbb{R}^d$ 上的零均值多元正态分布 $\\mathcal{N}(0, \\Sigma)$ 中独立采样来构建 $X_{\\text{train}}$ 和 $X_{\\text{test}}$，其中 $\\Sigma$ 是通过选择一个随机标准正交基并在对角线上放置指定的特征值来构建的。设 $Q \\in \\mathbb{R}^{d \\times d}$ 为标准正交矩阵，并设置 $\\Sigma = Q \\operatorname{diag}(\\lambda_1,\\ldots,\\lambda_d) Q^\\top$，其中用户指定的 $\\lambda_i$ 值反映了少数较大的“信号”方差和较小的“噪声”方差。\n- 使用训练均值 $\\mu_{\\text{train}}$ 对 $X_{\\text{train}}$ 和 $X_{\\text{test}}$ 进行中心化。\n- 计算中心化训练矩阵的奇异值分解（SVD），以获得由右奇异向量构成的标准正交基 $V \\in \\mathbb{R}^{d \\times d}$。对于每个 $m$，将 $W_m$ 设置为 $V$ 的前 $m$ 列，并计算 $P_m = W_m W_m^\\top$。\n- 对于每个 $m \\in \\{1, 2, \\ldots, d\\}$，计算 $E_{\\text{train}}(m)$ 和 $E_{\\text{test}}(m)$。\n- 令 $m_{\\text{peak}}$ 为最大化 $E_{\\text{test}}(m)$ 的索引 $m$（若有多个，则取最小的 $m$）。\n- 令 $m_{\\text{interp}}$ 为满足 $E_{\\text{train}}(m) \\le \\tau$ 的最小 $m$，容差为 $\\tau = 10^{-12}$。\n- 定义一个布尔值 $b_{\\text{dd}}$，用于指示是否观察到双峰现象，使用以下标准：\n    - 令 $k = m_{\\text{peak}}$，并考虑峰值前后的序列。设 $E_{\\text{pre}} = \\{E_{\\text{test}}(1), \\ldots, E_{\\text{test}}(k-1)\\}$ 和 $E_{\\text{post}} = \\{E_{\\text{test}}(k+1), \\ldots, E_{\\text{test}}(d)\\}$（空序列意味着 $b_{\\text{dd}} = \\text{False}$）。\n    - 如果 $\\min(E_{\\text{pre}})  E_{\\text{test}}(k)$ 和 $\\min(E_{\\text{post}})  E_{\\text{test}}(k)$ 同时成立，并且 $E_{\\text{pre}}$ 中至少存在一次严格下降，且 $E_{\\text{post}}$ 中至少有一个值严格小于 $E_{\\text{test}}(k)$，则声明存在双峰现象。\n- 对于每个测试用例，输出列表 $[m_{\\text{peak}}, \\text{round}(E_{\\text{test}}(m_{\\text{peak}}), 6), m_{\\text{interp}}, b_{\\text{dd}}]$。\n\n测试套件：\n对于每个用例，参数为 $(d, n, n_{\\text{test}}, s, \\sigma_{\\text{signal}}^2, \\sigma_{\\text{noise}}^2, \\text{seed})$，其中 $d$ 是维度，$n$ 是训练样本数，$n_{\\text{test}}$ 是测试样本数，$s$ 是信号维度数，$\\sigma_{\\text{signal}}^2$ 是信号方差，$\\sigma_{\\text{noise}}^2$ 是噪声方差，$\\text{seed}$ 用于设置随机数生成器。通过将前 $s$ 个特征值设置为 $\\sigma_{\\text{signal}}^2$，其余 $d - s$ 个设置为 $\\sigma_{\\text{noise}}^2$ 来构造特征值。\n- 用例 1：$(d, n, n_{\\text{test}}, s, \\sigma_{\\text{signal}}^2, \\sigma_{\\text{noise}}^2, \\text{seed}) = (\\,60,\\,40,\\,2000,\\,12,\\,5.0,\\,0.5,\\,1\\,)$。\n- 用例 2：$(\\,60,\\,58,\\,2000,\\,12,\\,4.0,\\,0.6,\\,2\\,)$。\n- 用例 3：$(\\,30,\\,15,\\,3000,\\,0,\\,0.0,\\,1.0,\\,3\\,)$。\n- 用例 4：$(\\,20,\\,5,\\,5000,\\,8,\\,3.0,\\,0.3,\\,4\\,)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，其本身也是一个形式为 $[m_{\\text{peak}}, \\text{round}(E_{\\text{test}}(m_{\\text{peak}}), 6), m_{\\text{interp}}, b_{\\text{dd}}]$ 的列表。浮点数必须四舍五入到 6 位小数。例如，输出应类似于 $[[1,0.123456,1,True],[\\ldots],[\\ldots],[\\ldots]]$。",
            "solution": "用户的请求是验证并解决一个计算问题，该问题涉及在线性自编码器中模拟双峰现象。\n\n### 问题验证\n\n**步骤1：提取已知信息**\n\n-   **模型**：线性自编码器，输入为 $x \\in \\mathbb{R}^d$，编码器为 $z = W^\\top x$，解码器为 $\\hat{x} = W W^\\top x$，其中 $W \\in \\mathbb{R}^{d \\times m}$ 的列是标准正交的。重构矩阵为 $P_m = W W^\\top$。\n-   **数据**：训练集 $X_{\\text{train}} \\in \\mathbb{R}^{n \\times d}$，测试集 $X_{\\text{test}} \\in \\mathbb{R}^{n_{\\text{test}} \\times d}$。数据从 $\\mathcal{N}(0, \\Sigma)$ 采样。\n-   **协方差**：$\\Sigma = Q \\operatorname{diag}(\\lambda_1, \\ldots, \\lambda_d) Q^\\top$，其中 $Q$ 是一个随机标准正交矩阵。前 $s$ 个特征值 $\\{\\lambda_i\\}$ 为 $\\sigma_{\\text{signal}}^2$，其余 $d-s$ 个为 $\\sigma_{\\text{noise}}^2$。\n-   **中心化**：训练集 $X_{\\text{train}}$ 和测试集 $X_{\\text{test}}$ 都使用训练数据的经验均值 $\\mu_{\\text{train}}$ 进行中心化。\n-   **优化**：模型参数 $W_m$ 通过最小化训练重构误差（经验风险最小化）来选择，这等价于主成分分析（PCA）。$W_m$ 的列是中心化训练矩阵的前 $m$ 个右奇异向量。\n-   **误差度量**：\n    -   训练误差：$E_{\\text{train}}(m) = \\frac{1}{n} \\sum_{i=1}^n \\left\\| x_i - P_m x_i \\right\\|_2^2$\n    -   测试误差：$E_{\\text{test}}(m) = \\frac{1}{n_{\\text{test}}} \\sum_{j=1}^{n_{\\text{test}}} \\left\\| x^{\\text{test}}_j - P_m x^{\\text{test}}_j \\right\\|_2^2$\n-   **待计算的量**：\n    -   $m_{\\text{peak}}$：使 $E_{\\text{test}}(m)$ 最大化的最小瓶颈大小 $m$。\n    -   $m_{\\text{interp}}$：使 $E_{\\text{train}}(m) \\le \\tau$（$\\tau = 10^{-12}$）成立的最小 $m$。\n    -   $b_{\\text{dd}}$：一个布尔值，根据 $E_{\\text{test}}(m)$ 曲线在 $m_{\\text{peak}}$ 周围的形状指示是否观察到双峰现象。\n-   **测试用例**：提供了四组特定的参数 $(d, n, n_{\\text{test}}, s, \\sigma_{\\text{signal}}^2, \\sigma_{\\text{noise}}^2, \\text{seed})$。\n\n**步骤2：使用提取的已知信息进行验证**\n\n根据验证标准对问题进行评估：\n\n-   **科学性**：该问题基于成熟的原理。线性自编码器的ERM与PCA等价是机器学习中的一个标准结论，其根源在于Eckart-Young-Mirsky定理。通过改变模型容量（$m$）来模拟双峰现象是当代研究中用于理解过参数化模型泛化能力的一种标准技术。数据生成过程是创建结构化合成数据的常规方法。\n-   **适定性**：问题定义清晰，没有歧义。所有参数、数据生成和分析的方法（SVD），以及输出指标（$m_{\\text{peak}}$、$m_{\\text{interp}}$、$b_{\\text{dd}}$）的定义都得到了精确说明。这确保了在给定随机种子的情况下，可以为每个测试用例计算出唯一且稳定的解。\n-   **客观性**：语言正式且客观。分析标准是定量的，没有主观解释的余地。\n-   **完整性和一致性**：问题提供了所有必要的信息（超参数、种子、容差），并且不包含内部矛盾。\n-   **可行性**：指定的维度（$d \\le 60, n \\le 58$）在计算上是可行的，使得所需的SVD和矩阵运算在标准硬件上是可行的。\n\n**步骤3：结论与行动**\n\n问题**有效**。这是一个适定、科学合理且计算上可行的任务，直接解决了现代机器学习理论中的一个相关课题。将按要求进行求解。\n\n### 解法\n\n将遵循问题陈述中概述的理论原理和计算步骤来实现该仿真。分析的核心是将由瓶颈维度 $m$ 控制的模型容量与其在训练和测试数据上的性能联系起来。\n\n1.  **理论框架**：问题指定了一个权重绑定的线性自编码器，其中解码器权重矩阵是编码器权重矩阵的转置。重构由 $\\hat{x} = W_m W_m^\\top x$ 给出。矩阵 $P_m = W_m W_m^\\top$ 是一个到由 $W_m$ 的列张成的 $m$ 维子空间上的正交投影算子。经验风险最小化（ERM）原则要求我们选择 $W_m$ 来最小化平均训练重构误差 $E_{\\text{train}}(m)$。对于平方 $\\ell_2$ 范数损失，此优化问题等价于主成分分析（PCA）。最优子空间是由中心化训练数据的前 $m$ 个主成分张成的子空间。这些成分是中心化训练数据矩阵 $X_c = X_{\\text{train}} - \\mu_{\\text{train}}$ 的右奇异向量。\n\n2.  **仿真算法**：\n    -   **数据生成**：对于每个测试用例，我们首先使用给定的种子建立一个随机数生成器。我们构建 $d \\times d$ 的协方差矩阵 $\\Sigma = Q \\operatorname{diag}(\\lambda_1, \\ldots, \\lambda_d) Q^\\top$。设置特征值 $\\lambda_i$ 以在“信号”和“噪声”维度之间创建区别，并使用 `scipy.stats` 中的例程生成一个随机标准正交矩阵 $Q$。然后我们从多元正态分布 $\\mathcal{N}(0, \\Sigma)$ 中采样 $n$ 个训练向量和 $n_{\\text{test}}$ 个测试向量。\n    -   **数据中心化**：通过减去其经验均值 $\\mu_{\\text{train}} = \\frac{1}{n} \\sum_{i=1}^n x_i$ 来对训练数据进行中心化，得到 $X_c$。关键是，测试数据也使用相同的 $\\mu_{\\text{train}}$ 进行中心化，以评估学习到的模型对来自同一分布的未见数据的泛化能力。\n    -   **主成分基**：我们计算中心化训练矩阵的奇异值分解（SVD）：$X_c = U S V^\\top$。$V$ 的列（或 $V^\\top$ 的行）构成了训练数据的主成分标准正交基，按 $S$ 中相应的奇异值排序。\n    -   **误差曲线计算**：我们从 $1$ 到 $d$ 遍历模型容量 $m$。在每一步中：\n        -   投影算子 $P_m$ 由前 $m$ 个主成分向量构成：$W_m = V_{:, 1:m}$，$P_m = W_m W_m^\\top$。\n        -   测试重构误差 $E_{\\text{test}}(m)$ 直接使用其定义计算。这可以高效地计算为 $E_{\\text{test}}(m) = \\frac{1}{n_{\\text{test}}} \\|X_{test, c} (I_d - P_m)\\|_F^2$，其中 $\\|\\cdot\\|_F$ 是弗罗贝尼乌斯范数。\n        -   训练重构误差 $E_{\\text{train}}(m)$ 的计算可以更高效。根据SVD和PCA的性质，使用前 $m$ 个主成分在训练集上的总重构误差是剩余奇异值的平方和。即，$E_{\\text{train}}(m) = \\frac{1}{n} \\sum_{k=m+1}^{\\text{rank}} s_k^2$，其中 $s_k$ 是 $X_c$ 的奇异值。\n\n3.  **分析与指标提取**：在计算完 $m=1, \\ldots, d$ 的完整误差曲线 $E_{\\text{train}}(m)$ 和 $E_{\\text{test}}(m)$ 后：\n    -   $m_{\\text{peak}}$ 被确定为最大化测试误差曲线 $E_{\\text{test}}$ 的最小 $m$。这一点通常标志着过拟合的开始，此时模型容量刚好足以拟合训练数据，但捕获了损害泛化能力的伪相关性。\n    -   $m_{\\text{interp}}$ 是通过定位第一个使训练误差 $E_{\\text{train}}(m)$ 降至数值容差 $\\tau = 10^{-12}$ 以下的 $m$ 来找到的。这标志着插值阈值，此时模型容量足以完美记忆训练数据（$m \\ge \\operatorname{rank}(X_c)$）。\n    -   $b_{\\text{dd}}$ 由一个特定标准确定，该标准检查峰值（$m_{\\text{peak}}$）前是否存在特有的“U形”以及随后的测试误差下降，这构成了“第二次下降”。当模型容量接近 $d$ 并且投影算子 $P_m$ 接近单位矩阵时，会发生第二次下降，单位矩阵能在任何数据上轻松实现零误差。\n\n这一全面的过程允许在一个受控且有理论基础的线性模型中，对双峰现象进行定量研究。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import ortho_group\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        (60, 40, 2000, 12, 5.0, 0.5, 1),\n        (60, 58, 2000, 12, 4.0, 0.6, 2),\n        (30, 15, 3000, 0, 0.0, 1.0, 3),\n        (20, 5, 5000, 8, 3.0, 0.3, 4),\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_simulation(*params)\n        results.append(result)\n\n    # Format the final output string as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(d, n, n_test, s, sigma_signal_sq, sigma_noise_sq, seed):\n    \"\"\"\n    Runs the double descent simulation for a single set of parameters.\n\n    Args:\n        d (int): Dimensionality of the data space.\n        n (int): Number of training samples.\n        n_test (int): Number of test samples.\n        s (int): Number of signal dimensions.\n        sigma_signal_sq (float): Signal variance.\n        sigma_noise_sq (float): Noise variance.\n        seed (int): Random seed.\n\n    Returns:\n        list: A list containing [m_peak, E_test_at_peak, m_interp, b_dd].\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Construct the covariance matrix Sigma\n    lambdas = np.array([sigma_signal_sq] * s + [sigma_noise_sq] * (d - s))\n    Q = ortho_group.rvs(dim=d, random_state=rng)\n    Sigma = Q @ np.diag(lambdas) @ Q.T\n\n    # 2. Generate training and test data\n    mean = np.zeros(d)\n    X_train = rng.multivariate_normal(mean=mean, cov=Sigma, size=n)\n    X_test = rng.multivariate_normal(mean=mean, cov=Sigma, size=n_test)\n\n    # 3. Center data using the training mean\n    mu_train = np.mean(X_train, axis=0)\n    X_train_centered = X_train - mu_train\n    X_test_centered = X_test - mu_train\n\n    # 4. Compute SVD of the centered training data\n    # U, S, Vt where V are the right singular vectors (principal components)\n    U, S_vals, Vt = np.linalg.svd(X_train_centered, full_matrices=False)\n    V = Vt.T\n\n    E_train_curve = []\n    E_test_curve = []\n\n    # Pad singular values array with zeros up to dimension d if necessary\n    S_sq_full = np.zeros(d)\n    S_sq_full[:len(S_vals)] = S_vals**2\n\n    # 5. Iterate over bottleneck size m from 1 to d\n    for m in range(1, d + 1):\n        # Efficiently compute training error using singular values\n        # E_train(m) = (1/n) * sum_{k=m to rank-1} s_k^2\n        train_error = np.sum(S_sq_full[m:]) / n\n        E_train_curve.append(train_error)\n\n        # Compute test error via projection\n        W_m = V[:, :m]\n        P_m = W_m @ W_m.T\n        I = np.identity(d)\n        \n        # Error matrix for test set: X_test_c - X_test_c @ P_m = X_test_c @ (I - P_m)\n        error_matrix_test = X_test_centered @ (I - P_m)\n        # Sum of squared L2 norms is the squared Frobenius norm\n        test_error = np.sum(error_matrix_test**2) / n_test\n        E_test_curve.append(test_error)\n\n    # 6. Calculate the required metrics\n    E_test_curve = np.array(E_test_curve)\n    E_train_curve = np.array(E_train_curve)\n\n    # m_peak: smallest m that maximizes test error\n    m_peak = np.argmax(E_test_curve) + 1\n    e_test_at_peak = E_test_curve[m_peak - 1]\n\n    # m_interp: smallest m where training error is effectively zero\n    tau = 1e-12\n    interp_indices = np.where(E_train_curve = tau)[0]\n    # The problem setup guarantees interpolation happens\n    m_interp = interp_indices[0] + 1 if len(interp_indices) > 0 else d + 1\n\n    # b_dd: boolean for double descent\n    k = m_peak\n    E_pre = E_test_curve[:k-1]\n    E_post = E_test_curve[k:] # from index k to the end\n\n    b_dd = False\n    # Check for empty sequences before proceeding\n    if E_pre.size > 0 and E_post.size > 0:\n        cond1 = np.min(E_pre)  e_test_at_peak\n        cond2 = np.min(E_post)  e_test_at_peak\n        \n        # \"at least one strict decrease somewhere in E_pre\"\n        # Implemented as not being monotonically non-decreasing\n        # Or more directly, there is at least one adjacent pair with a decrease\n        # This correctly handles sequences of length 1 (returns False)\n        cond3 = any(E_pre[i] > E_pre[i+1] for i in range(len(E_pre)-1))\n\n        if cond1 and cond2 and cond3:\n            b_dd = True\n            \n    return [m_peak, round(e_test_at_peak, 6), m_interp, b_dd]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "既然我们观察到了“双峰下降”现象，一个自然的问题是：为什么更复杂的模型有时反而能更好地泛化？本练习旨在通过“间隔”（margin）和“损失景观平坦度”（loss landscape flatness）这两个概念来探寻其背后的机理。你将通过一个精心设计的对比实验，验证一个更宽（参数更多）的网络如何能够找到一个具有更大间隔和更平坦损失最小值的解，从而获得比窄网络更强的泛化能力，即使两者在功能上是等价的。",
            "id": "3152424",
            "problem": "您将置身于一个深度学习中的受控比较场景，以探究在何种情况下，更宽的模型能够比更窄的模型具有更好的泛化能力，即便两者都达到了相同的训练误差。该场景考虑二元分类问题，通过从经验风险最小化（ERM）的基本原则和基于稳定性的泛化理论中推导出的经验边距和损失平坦度指标，来评估两个参数化模型族。\n\n此问题的基本原理：\n- 经验风险最小化（ERM）定义了在训练集 $\\{(x_i,y_i)\\}_{i=1}^n$（标签 $y_i \\in \\{-1,+1\\}$）和模型得分函数 $f_\\theta(x)$ 下的经验损失为\n$$\n\\widehat{L}(\\theta) \\;=\\; \\frac{1}{n} \\sum_{i=1}^n \\ell\\big(y_i f_\\theta(x_i)\\big),\n$$\n其中逻辑斯谛损失（logistic loss）由下式给出\n$$\n\\ell(t) \\;=\\; \\log\\!\\big(1 + e^{-t}\\big).\n$$\n- 分类器 $f_\\theta$ 在训练集上的经验边距定义为\n$$\n\\gamma(\\theta) \\;=\\; \\min_{i \\in \\{1,\\dots,n\\}} y_i f_\\theta(x_i).\n$$\n- 一个平坦度的代理指标（锐度）通过在参数受到微小的乘性扰动 $\\theta \\mapsto \\theta'$ 下，经验损失的期望增量来捕捉，其数值上定义为\n$$\n\\Delta(\\theta;\\alpha) \\;=\\; \\mathbb{E}\\big[\\,\\widehat{L}(\\theta') - \\widehat{L}(\\theta)\\,\\big],\n$$\n其中每个参数 $\\theta_k$ 被独立地扰动为 $\\theta_k' \\;=\\; \\theta_k \\cdot (1 + \\alpha z_k)$，其中 $z_k \\sim \\mathcal{N}(0,1)$ 且噪声尺度 $\\alpha$ 很小。\n\n任务：\n实现两个分类器，在一个固定的训练集上评估它们的经验边距和平坦度，以及在一个人造测试分布上的泛化性能。\n- 模型 $\\mathsf{A}$（窄）：一个在 $\\mathbb{R}^2$ 中的线性分类器，其单位范数权重向量为\n$$\nw_{\\mathsf{A}} \\;=\\; \\begin{bmatrix} \\cos(\\theta) \\\\ \\sin(\\theta) \\end{bmatrix},\n$$\n得分为 $f_{\\mathsf{A}}(x) = w_{\\mathsf{A}}^\\top x$。角度 $\\theta$ 以弧度为单位提供。\n- 模型 $\\mathsf{B}$（宽）：一个具有 $2m$ 个隐藏单元的双层修正线性单元（ReLU）网络，它实现得分\n$$\nf_{\\mathsf{B}}(x) \\;=\\; \\sum_{j=1}^{m} \\frac{1}{m}\\,\\max\\!\\big(0,\\,u^\\top x\\big) \\;+\\; \\sum_{j=1}^{m} \\left(-\\frac{1}{m}\\right)\\,\\max\\!\\big(0,\\,-u^\\top x\\big),\n$$\n其中 $u = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ 且 $\\max(0,\\cdot)$ 是 ReLU 激活函数。请注意，$f_{\\mathsf{B}}(x)$ 精确等于 $u^\\top x$，但由于在 $m$ 个配对中进行了复制，其参数化更宽。\n\n训练集：\n使用包含四个点的确定性训练集\n$$\nX_{\\text{train}} = \\Big\\{ (1,\\,r),\\; (1,\\,-r),\\; (-1,\\,r),\\; (-1,\\,-r) \\Big\\},\n$$\n对于第一个坐标 $x_1 = 1$ 的点，标签为 $y=+1$；对于第一个坐标 $x_1 = -1$ 的点，标签为 $y=-1$。标量 $r0$ 已提供。\n\n测试分布：\n通过从正类分布 $\\mathcal{N}\\!\\left(\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix},\\,\\sigma^2 I\\right)$ 中采样 $N/2$ 个标签为 $+1$ 的点，并从负类分布 $\\mathcal{N}\\!\\left(\\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix},\\,\\sigma^2 I\\right)$ 中采样 $N/2$ 个标签为 $-1$ 的点，来生成一个大小为 $N$ 的平衡测试集。这里 $\\sigma0$，$I$ 是 $2\\times 2$ 的单位矩阵。角度单位是弧度。测试误差必须表示为 $[0,1]$ 区间内的一个小数。\n\n每个测试用例需要计算的指标：\n- 两个模型在训练集上的经验边距，$\\gamma_{\\mathsf{A}}$ 和 $\\gamma_{\\mathsf{B}}$。\n- 两个模型在噪声尺度 $\\alpha$ 下的平坦度代理指标，定义为在所有参数的乘性高斯扰动下，经验逻辑斯谛损失的平均增量，$\\Delta_{\\mathsf{A}}(\\alpha)$ 和 $\\Delta_{\\mathsf{B}}(\\alpha)$。\n- 两个模型在生成的测试集上的测试误差，$e_{\\mathsf{A}}$ 和 $e_{\\mathsf{B}}$，计算为被错误分类的测试样本的比例。\n\n决策逻辑：\n对于每个测试用例，输出三个布尔值，指示更宽的模型是否展现出期望的属性：\n- $b_1$: $\\gamma_{\\mathsf{B}} > \\gamma_{\\mathsf{A}}$，\n- $b_2$: $\\Delta_{\\mathsf{B}}(\\alpha)  \\Delta_{\\mathsf{A}}(\\alpha)$，\n- $b_3$: $e_{\\mathsf{B}}  e_{\\mathsf{A}}$。\n\n测试套件：\n在以下参数集上运行您的程序，以涵盖不同方面：\n- 情况1（理想情况）：$\\theta = 0.3$, $m = 50$, $r = 0.2$, $\\sigma = 0.4$, $\\alpha = 0.05$, $N = 5000$。\n- 情况2（小离散度的边界条件）：$\\theta = 0.6$, $m = 100$, $r = 0.1$, $\\sigma = 0.15$, $\\alpha = 0.05$, $N = 5000$。\n- 情况3（中等宽度和较大离散度的边缘情况）：$\\theta = 0.4$, $m = 10$, $r = 0.25$, $\\sigma = 0.5$, $\\alpha = 0.05$, $N = 5000$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例对应一个由三个布尔值组成的列表 $[b_1,b_2,b_3]$。例如，一个有效的输出格式是\n$$\n[[True,False,True],[True,True,True],[False,True,False]]\n$$\n不应打印任何额外文本。",
            "solution": "用户提供的问题是有效的。它在科学上基于统计学习理论和深度学习的原理，特别是关于模型容量、泛化以及过参数化的作用。该问题是适定的（well-posed），所有必要的参数和定义都已提供，以得出一个唯一的、有意义的解决方案。它提出了一个受控的、可形式化的实验，用以检验一个关于模型宽度、损失景观的几何形状（平坦度）和泛化性能（测试误差）之间关系的特定假设，这也是现代深度学习研究的核心课题。\n\n解决方案的步骤是实现指定的两个模型，为每个模型计算所需的指标，然后执行所要求的比较。\n\n**1. 模型和指标定义**\n\n该问题为数据 $x \\in \\mathbb{R}^2$ 和标签 $y \\in \\{-1, +1\\}$ 的二元分类任务定义了两个模型。\n\n- **模型 $\\mathsf{A}$（窄）** 是一个线性分类器，其得分函数为 $f_{\\mathsf{A}}(x) = w_{\\mathsf{A}}^\\top x$。其权重向量 $w_{\\mathsf{A}} = [\\cos(\\theta), \\sin(\\theta)]^\\top$ 由单个标量角度 $\\theta$ 参数化。\n\n- **模型 $\\mathsf{B}$（宽）** 是一个双层 ReLU 网络。其得分函数由下式给出\n$$\nf_{\\mathsf{B}}(x) \\;=\\; \\sum_{j=1}^{m} \\frac{1}{m}\\,\\max\\!\\big(0,\\,u^\\top x\\big) \\;+\\; \\sum_{j=1}^{m} \\left(-\\frac{1}{m}\\right)\\,\\max\\!\\big(0,\\,-u^\\top x\\big),\n$$\n其中 $u = [1, 0]^\\top$。使用恒等式 $\\max(0, z) - \\max(0, -z) = z$，该函数可简化为一个精确的线性函数：\n$$\nf_{\\mathsf{B}}(x) = \\frac{m}{m} \\max(0, u^\\top x) - \\frac{m}{m} \\max(0, -u^\\top x) = u^\\top x = x_1.\n$$\n尽管其函数形式简单，但其参数化涉及第二层中的 $2m$ 个权重：$m$ 个值为 $1/m$ 的权重和 $m$ 个值为 $-1/m$ 的权重。这 $2m$ 个权重是用于计算平坦度时受扰动的参数。\n\n训练集是固定的，包含 $n=4$ 个点：$X_{\\text{train}} = \\{ (1, r), (1, -r), (-1, r), (-1, -r) \\}$，对应的标签为 $Y_{\\text{train}} = \\{+1, +1, -1, -1\\}$。\n\n计算三个指标：\n- **经验边距 ($\\gamma$)**：在正确分类的训练点上的最小得分，$\\gamma(\\theta) = \\min_{i} y_i f_\\theta(x_i)$。\n- **平坦度代理指标 ($\\Delta$)**：在参数的乘性扰动下，逻辑斯谛损失的期望增量，$\\Delta(\\theta;\\alpha) = \\mathbb{E}[\\,\\widehat{L}(\\theta') - \\widehat{L}(\\theta)\\,]$，其中 $\\theta_k' = \\theta_k(1+\\alpha z_k)$ 且 $z_k \\sim \\mathcal{N}(0,1)$。逻辑斯谛损失为 $\\ell(t) = \\log(1+e^{-t})$。\n- **测试误差 ($e$)**：在一个大型的人工生成的测试集上的错分率。\n\n**2. 模型 $\\mathsf{A}$ 指标的计算**\n\n- **经验边距 $\\gamma_{\\mathsf{A}}$**：\n模型 $\\mathsf{A}$ 在训练集上的得分是 $y_i f_{\\mathsf{A}}(x_i)$。对于这四个点，它们是：\n$y_1 f_{\\mathsf{A}}(x_1) = 1 \\cdot (\\cos\\theta + r\\sin\\theta)$\n$y_2 f_{\\mathsf{A}}(x_2) = 1 \\cdot (\\cos\\theta - r\\sin\\theta)$\n$y_3 f_{\\mathsf{A}}(x_3) = -1 \\cdot (-\\cos\\theta + r\\sin\\theta) = \\cos\\theta - r\\sin\\theta$\n$y_4 f_{\\mathsf{A}}(x_4) = -1 \\cdot (-\\cos\\theta - r\\sin\\theta) = \\cos\\theta + r\\sin\\theta$\n由于测试用例参数确保 $\\theta  0$ 和 $r0$，我们有 $\\sin\\theta  0$。边距是这些值中的最小值：\n$\\gamma_{\\mathsf{A}} = \\min(\\cos\\theta + r\\sin\\theta, \\cos\\theta - r\\sin\\theta) = \\cos\\theta - r\\sin\\theta$。\n\n- **平坦度代理指标 $\\Delta_{\\mathsf{A}}(\\alpha)$**：\n模型 $\\mathsf{A}$ 的参数是 $\\theta$。经验损失为 $\\widehat{L}_{\\mathsf{A}}(\\phi) = \\frac{1}{2}[\\ell(\\cos\\phi + r\\sin\\phi) + \\ell(\\cos\\phi - r\\sin\\phi)]$。平坦度通过蒙特卡洛平均来估计。我们生成 $K$ 个样本 $z_k \\sim \\mathcal{N}(0,1)$，计算扰动后的参数 $\\theta_k' = \\theta(1+\\alpha z_k)$，然后平均由此产生的损失变化：\n$\\Delta_{\\mathsf{A}}(\\alpha) \\approx \\frac{1}{K} \\sum_{k=1}^K \\widehat{L}_{\\mathsf{A}}(\\theta_k') - \\widehat{L}_{\\mathsf{A}}(\\theta)$。\n\n- **测试误差 $e_{\\mathsf{A}}$**：\n测试误差通过按照问题规范生成一个大小为 $N$ 的测试集，并计算 $\\text{sign}(f_{\\mathsf{A}}(x)) \\neq y$ 的样本所占的比例来得出。\n\n**3. 模型 $\\mathsf{B}$ 指标的计算**\n\n- **经验边距 $\\gamma_{\\mathsf{B}}$**：\n得分函数是 $f_{\\mathsf{B}}(x) = x_1$。对于四个训练点，乘积 $y_i f_{\\mathsf{B}}(x_i)$ 分别是：\n$y_1 f_{\\mathsf{B}}(x_1) = 1 \\cdot 1 = 1$\n$y_2 f_{\\mathsf{B}}(x_2) = 1 \\cdot 1 = 1$\n$y_3 f_{\\mathsf{B}}(x_3) = -1 \\cdot (-1) = 1$\n$y_4 f_{\\mathsf{B}}(x_4) = -1 \\cdot (-1) = 1$\n因此边距是恒定的：$\\gamma_{\\mathsf{B}} = 1$。\n\n- **平坦度代理指标 $\\Delta_{\\mathsf{B}}(\\alpha)$**：\n参数是 $2m$ 个第二层权重。设 $v_j$ 为这些权重。在一个训练点 $x_i$ 上，扰动模型的得分取决于扰动权重的总和。对于 $x_{i,1}=1$ 的训练点，得分为 $S_1 = \\sum_{j=1}^m \\frac{1}{m}(1+\\alpha z_j) = 1 + \\frac{\\alpha}{m}\\sum_{j=1}^m z_j$。对于 $x_{i,1}=-1$ 的点，得分为 $-S_2$，其中 $S_2 = 1 + \\frac{\\alpha}{m}\\sum_{j=m+1}^{2m} z_j$。根据中心极限定理，对于较大的 $m$，$S_1, S_2$ 近似服从正态分布。精确地说，作为缩放正态变量的和，$S_1 \\sim \\mathcal{N}(1, \\alpha^2/m)$ 和 $S_2 \\sim \\mathcal{N}(1, \\alpha^2/m)$。\n扰动模型的损失变为 $\\frac{1}{2}[\\ell(S_1) + \\ell(S_2)]$。未扰动的损失是 $\\ell(1)$。平坦度是：\n$\\Delta_{\\mathsf{B}}(\\alpha) = \\mathbb{E}_{S_1, S_2}\\left[ \\frac{1}{2}(\\ell(S_1) + \\ell(S_2)) \\right] - \\ell(1) = \\mathbb{E}_{S \\sim \\mathcal{N}(1, \\alpha^2/m)}[\\ell(S)] - \\ell(1)$。\n这个期望可以通过从 $S$ 的分布中直接采样，利用蒙特卡洛模拟来高效计算。有效扰动的方差与宽度 $m$ 成反比，这表明更宽的模型更平坦。\n\n- **测试误差 $e_{\\mathsf{B}}$**：\n测试误差在相同的生成测试集上计算。决策规则是 $\\text{sign}(x_1)$。这对应于指定测试分布的贝叶斯最优分类器，该分布的中心分别在 $[1,0]^\\top$ 和 $[-1,0]^\\top$，使其成为理想的基准。\n\n**4. 实现与决策逻辑**\n\n该解决方案使用 `numpy` 库在 Python 中实现。对于每个案例，单个随机数生成器用于蒙特卡洛估计和测试集生成，以确保一致性。使用大量的蒙特卡洛样本（$K=20000$）以确保平坦度指标的估计稳定。对于三个测试用例中的每一个，我们计算 $(\\gamma_{\\mathsf{A}}, \\Delta_{\\mathsf{A}}, e_{\\mathsf{A}})$ 和 $(\\gamma_{\\mathsf{B}}, \\Delta_{\\mathsf{B}}, e_{\\mathsf{B}})$，然后评估三个布尔条件：\n- $b_1: \\gamma_{\\mathsf{B}} > \\gamma_{\\mathsf{A}}$（宽模型的边距是否更大？）\n- $b_2: \\Delta_{\\mathsf{B}}(\\alpha)  \\Delta_{\\mathsf{A}}(\\alpha)$（宽模型的损失景观是否更平坦？）\n- $b_3: e_{\\mathsf{B}}  e_{\\mathsf{A}}$（宽模型的泛化能力是否更好？）\n\n根据推导，我们预期 $b_1$ 为 `True`，因为 $\\gamma_{\\mathsf{A}}  1 = \\gamma_{\\mathsf{B}}$；$b_2$ 为 `True`，因为模型 $\\mathsf{B}$ 的扰动方差因其宽度 $m$ 而减小；$b_3$ 为 `True`，因为模型 $\\mathsf{B}$ 实现了测试数据的最优分类器，而模型 $\\mathsf{A}$ 的分类器由于 $\\theta \\neq 0$ 而略有偏差。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating and comparing metrics for two classifier models\n    across three different test cases, as specified in the problem description.\n    \"\"\"\n\n    # --- Static Configurations ---\n    # Number of Monte Carlo samples for flatness calculation\n    K_SAMPLES = 20000\n\n    # --- Helper Functions ---\n    def logistic_loss(t):\n        \"\"\"Computes the logistic loss log(1 + exp(-t)) in a numerically stable way.\"\"\"\n        return np.logaddexp(0, -t)\n\n    def get_training_set(r):\n        \"\"\"Returns the fixed training set points and labels.\"\"\"\n        X_train = np.array([\n            [1.0, r], [1.0, -r], [-1.0, r], [-1.0, -r]\n        ])\n        y_train = np.array([1.0, 1.0, -1.0, -1.0])\n        return X_train, y_train\n\n    def generate_test_set(N, sigma, rng):\n        \"\"\"Generates a balanced test set of size N.\"\"\"\n        n_half = N // 2\n        cov = np.eye(2) * (sigma ** 2)\n\n        mean_pos = np.array([1.0, 0.0])\n        X_pos = rng.multivariate_normal(mean_pos, cov, n_half)\n        y_pos = np.ones(n_half)\n\n        mean_neg = np.array([-1.0, 0.0])\n        X_neg = rng.multivariate_normal(mean_neg, cov, n_half)\n        y_neg = -np.ones(n_half)\n\n        X_test = np.vstack((X_pos, X_neg))\n        y_test = np.concatenate((y_pos, y_neg))\n        return X_test, y_test\n\n    def calculate_model_A_metrics(theta, r, alpha, X_test, y_test, rng):\n        \"\"\"Calculates margin, flatness, and test error for Model A.\"\"\"\n        # 1. Empirical Margin (gamma_A)\n        gamma_A = np.cos(theta) - r * np.sin(theta)\n\n        # 2. Flatness Surrogate (Delta_A)\n        def empirical_loss_A(phi):\n            t1 = np.cos(phi) + r * np.sin(phi)\n            t2 = np.cos(phi) - r * np.sin(phi)\n            return 0.5 * (logistic_loss(t1) + logistic_loss(t2))\n\n        base_loss_A = empirical_loss_A(theta)\n        \n        z_samples = rng.standard_normal(K_SAMPLES)\n        perturbed_thetas = theta * (1.0 + alpha * z_samples)\n        \n        perturbed_losses = np.array([empirical_loss_A(p_t) for p_t in perturbed_thetas])\n        delta_A = np.mean(perturbed_losses) - base_loss_A\n\n        # 3. Test Error (e_A)\n        w_A = np.array([np.cos(theta), np.sin(theta)])\n        scores_A = X_test @ w_A\n        predictions_A = np.sign(scores_A)\n        predictions_A[predictions_A == 0] = 1.0  # Break ties\n        e_A = np.mean(predictions_A != y_test)\n\n        return gamma_A, delta_A, e_A\n\n    def calculate_model_B_metrics(m, alpha, X_test, y_test, rng):\n        \"\"\"Calculates margin, flatness, and test error for Model B.\"\"\"\n        # 1. Empirical Margin (gamma_B)\n        # For Model B, f(x) = x_1. For all training points, y_i * f(x_i) = 1.\n        gamma_B = 1.0\n\n        # 2. Flatness Surrogate (Delta_B)\n        base_loss_B = logistic_loss(1.0)\n        \n        zeta_samples = rng.standard_normal(K_SAMPLES)\n        S_samples = 1.0 + (alpha / np.sqrt(m)) * zeta_samples\n        \n        perturbed_losses = logistic_loss(S_samples)\n        delta_B = np.mean(perturbed_losses) - base_loss_B\n\n        # 3. Test Error (e_B)\n        scores_B = X_test[:, 0]\n        predictions_B = np.sign(scores_B)\n        predictions_B[predictions_B == 0] = 1.0  # Break ties\n        e_B = np.mean(predictions_B != y_test)\n\n        return gamma_B, delta_B, e_B\n\n    # --- Main Execution Logic ---\n    test_cases = [\n        # Case 1: theta=0.3, m=50, r=0.2, sigma=0.4, alpha=0.05, N=5000\n        (0.3, 50, 0.2, 0.4, 0.05, 5000),\n        # Case 2: theta=0.6, m=100, r=0.1, sigma=0.15, alpha=0.05, N=5000\n        (0.6, 100, 0.1, 0.15, 0.05, 5000),\n        # Case 3: theta=0.4, m=10, r=0.25, sigma=0.5, alpha=0.05, N=5000\n        (0.4, 10, 0.25, 0.5, 0.05, 5000),\n    ]\n\n    results = []\n    # Use a single random number generator for all random processes.\n    # No seed is specified, so results may vary slightly on different runs,\n    # but the conclusions should be stable due to large N and K.\n    rng = np.random.default_rng()\n\n    for case in test_cases:\n        theta, m, r, sigma, alpha, N = case\n\n        # Generate a single test set to be used by both models for this case\n        X_test, y_test = generate_test_set(N, sigma, rng)\n\n        # Calculate metrics for both models\n        gamma_A, delta_A, e_A = calculate_model_A_metrics(theta, r, alpha, X_test, y_test, rng)\n        gamma_B, delta_B, e_B = calculate_model_B_metrics(m, alpha, X_test, y_test, rng)\n        \n        # Perform the comparisons to get the boolean results\n        b1 = gamma_B > gamma_A\n        b2 = delta_B  delta_A\n        b3 = e_B  e_A\n        \n        results.append([bool(b1), bool(b2), bool(b3)])\n\n    # Format the final output string exactly as required\n    print(f\"[{','.join(map(str, results))}]\".replace(\" \", \"\"))\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}