## 引言
[监督式学习](@entry_id:161081)分类是现代人工智能的基石，它赋予了机器从带标签数据中学习并做出预测的能力，应用遍及从科学发现到日常科技的方方面面。然而，从一个在干净、平衡的数据集上表现良好的原型模型，到一个能够在充满不确定性、数据偏差和未知输入的真实世界中可靠工作的系统，其间存在着巨大的鸿沟。本文旨在跨越这一鸿沟，系统性地探讨构建稳健、公平且可信的分类模型的先进原理与实践。

本文将引导读者踏上一段从理论深化到实践应用的旅程。在**“原理与机制”**一章中，我们将超越基础定义，深入剖析分类决策的核心，探讨如何通过[成本敏感学习](@entry_id:634187)做出最优选择，并掌握处理[类别不平衡](@entry_id:636658)、[分布](@entry_id:182848)变化以及开放集识别等现实挑战的关键技术。随后的**“应用与跨学科连接”**一章将展示这些原理如何在计算生物学、自然语言处理等前沿领域中大放异彩，并揭示其与[表示学习](@entry_id:634436)、[小样本学习](@entry_id:636112)和[模型可解释性](@entry_id:171372)的深刻联系。最后，在**“动手实践”**部分，你将有机会亲手实现和解决真实场景中的复杂问题，例如在[分布](@entry_id:182848)变化下校准决策阈值，以及对模型进行后门攻击与防御，从而将理论知识转化为坚实的工程能力。

## 原理与机制

在介绍性章节之后，我们现在深入探讨监督式[分类任务](@entry_id:635433)的核心原理与机制。本章旨在构建一个坚实的理论框架，从基本定义出发，逐步过渡到解决现实世界挑战的先进技术。我们将探讨分类决策的制定方式、模型如何从数据中学习，以及如何确保模型在面对[分布](@entry_id:182848)变化和未知输入时的稳健性。

### 监督式分类的本质

监督学习的核心任务是学习一个从输入到输出的映射函数。在[分类问题](@entry_id:637153)中，这个输出是一个离散的类别标签。

#### [分类与回归](@entry_id:637626)的区分

首先，我们必须明确**分类 (classification)** 与 **回归 (regression)** 之间的根本区别。尽管两者都属于监督学习的范畴，因为它们都从带有标签的数据中学习，但它们预测的目标类型截然不同。

- **分类** 的目标是预测一个数据点属于预定义类别集合中的哪一个。这些类别是离散且无序的。例如，一个模型可能需要将一张图片分类为“猫”、“狗”或“鸟”。
- **回归** 的目标是预测一个连续的数值。例如，一个模型可能需要根据房屋的特征（如面积、位置）预测其价格。

让我们通过一个[材料科学](@entry_id:152226)的例子来具体说明这一点。假设一个研究团队拥有一个包含多种化合物及其对应**[带隙](@entry_id:191975)能量 ($E_g$)** 的数据集。[带隙](@entry_id:191975)是一个连续的物理量。该团队有两个目标：

1.  **目标1：** 将假想的化合物分为三类：“金属” ($E_g \lt 0.1$ eV)、“[半导体](@entry_id:141536)” ($0.1 \le E_g \le 4.0$ eV) 或“绝缘体” ($E_g \gt 4.0$ eV)。由于目标输出是一个来自有限、[离散集](@entry_id:146023)合的标签，这是一个**[分类任务](@entry_id:635433)**。模型学习一个函数 $f: \mathbb{R}^{d} \to \{\text{金属}, \text{半导体}, \text{绝缘体}\}$，其中 $\mathbb{R}^{d}$ 是描述化合物的特征空间。

2.  **目标2：** 预测一个假想化合物的具体[带隙](@entry_id:191975)能量值 $E_g$。由于目标输出是一个连续的实数，这是一个**回归任务**。模型学习一个函数 $f: \mathbb{R}^{d} \to \mathbb{R}$。

这个例子清晰地展示了任务目标（预测离散类别还是连续数值）如何决定了我们所面临的机器学习问题的类型。

#### 规范的[监督式学习](@entry_id:161081)工作流

要成功构建一个分类器，遵循一个系统化的工作流程至关重要。这个流程确保了模型的开发是严谨的，并且其性能评估是可靠和无偏的。一个典型的[监督式学习](@entry_id:161081)工作流包括以下步骤：

1.  **构建带标签的数据集：** 收集数据，并为每个数据点（输入特征 $\mathbf{x}_i$）关联一个正确的类别标签 $y_i$。这个数据集通常表示为 $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^{n}$。例如，在利用质谱数据识别细菌种类的任务中，特征 $\mathbf{x}_i$ 是质谱向量，标签 $y_i$ 是通过黄金标准方法（如[全基因组测序](@entry_id:169777)）确定的物种身份。

2.  **数据集划分：** 将整个数据集 $\mathcal{D}$ 分割成几个互不相交的[子集](@entry_id:261956)：
    *   **[训练集](@entry_id:636396) (Training Set)：** 用于训练模型，即调整模型的内部参数。
    *   **[验证集](@entry_id:636445) (Validation Set)：** 用于调整模型的**超参数**（例如，[学习率](@entry_id:140210)、[网络结构](@entry_id:265673)、正则化强度）。模型在训练过程中不会直接从验证集“学习”参数，但验证集的性能指导我们选择最佳的超参数配置。
    *   **测试集 (Test Set)：** 完全独立于训练和验证过程。它只在模型最终确定后使用一次，以提供模型在全新、未见过数据上**泛化性能**的无偏估计。

3.  **模型训练：** 在训练集上，通过优化算法（如[梯度下降](@entry_id:145942)）调整模型参数，以最小化一个**[损失函数](@entry_id:634569) (loss function)**。损失函数衡量模型预测与真实标签之间的差距。这个使用标签指导[参数优化](@entry_id:151785)的过程正是“监督”一词的由来。

4.  **模型评估：** 在测试集上评估最终模型的性能，使用适当的[分类指标](@entry_id:637806)（如准确率、[精确率](@entry_id:190064)、召回率或[F1分数](@entry_id:196735)）。

这个工作流与**[无监督学习](@entry_id:160566) (unsupervised learning)** 形成鲜明对比。无监督方法，如 K-均值[聚类](@entry_id:266727) (k-means clustering) 或主成分分析 (Principal Component Analysis, PCA)，在没有标签 $y_i$ 的情况下处理数据，旨在发现数据内在的结构或模式。标签仅在事后用于解释或评估这些模式，而不会指导模型的学习过程。

### 决策核心：从概率到预测

现代分类器，特别是[深度神经网络](@entry_id:636170)，通常被设计为输出每个类别的概率（或可以轻松转换为概率的分数，如 **logits**）。给定一个输入 $\mathbf{x}$，模型会为每个类别 $j$ 计算一个[后验概率](@entry_id:153467) $p(y=j|\mathbf{x})$。最直接的决策规则是选择概率最高的类别，即**最大后验 (maximum a posteriori, MAP)** 决策：

$$
\hat{y} = \arg\max_{j} p(y=j|\mathbf{x})
$$

在许多情况下，这是一个合理的选择。然而，当不同类型的错误分类导致不同成本时，这个简单的规则可能不再是最优的。

#### [成本敏感分类](@entry_id:635260)

在现实世界的应用中，将A类错分为B类的代价未必等于将B类错分为A类的代价。例如，在[医学诊断](@entry_id:169766)中，将一个病人（正类）误诊为健康（假阴性，False Negative）的后果，通常比将一个健康人误诊为病人（假阳性，False Positive）的后果严重得多。

为了在这种**非对称错误成本**的情况下做出最优决策，我们需要引入决策理论的框架。我们可以定义一个**[成本矩阵](@entry_id:634848) (cost matrix)** $C$，其中 $C_{ij}$ 表示真实类别为 $i$ 但模型预测为 $j$ 时产生的成本。通常，正确分类的成本为零，即 $C_{ii} = 0$。

对于给定的输入 $\mathbf{x}$，如果我们选择预测类别 $j$，其**[条件期望](@entry_id:159140)风险 (conditional expected risk)** $R(j|\mathbf{x})$ 是所有可能真实类别 $i$ 的成本 $C_{ij}$ 以其后验概率 $p(y=i|\mathbf{x})$ 为权重的加权和：

$$
R(j|\mathbf{x}) = \mathbb{E}[C_{Yj} | X=\mathbf{x}] = \sum_{i=1}^{K} C_{ij} \, p(y=i|\mathbf{x})
$$

**贝叶斯最优决策规则 (Bayes-optimal decision rule)** 指示我们选择能够[最小化条件](@entry_id:203120)[期望风险](@entry_id:634700)的类别：

$$
\hat{y}^{\star}(x) = \arg\min_{j} R(j|\mathbf{x}) = \arg\min_{j} \sum_{i=1}^{K} C_{ij} \, p(y=i|\mathbf{x})
$$

让我们将这个通用规则应用于一个[二元分类](@entry_id:142257)问题，类别为 $\{0, 1\}$。[成本矩阵](@entry_id:634848)为 $C_{00}=C_{11}=0$, $C_{10} > 0$（假阴性成本），以及 $C_{01} > 0$（[假阳性](@entry_id:197064)成本）。

- 预测类别 1 的风险：$R(1|\mathbf{x}) = C_{01} p(y=0|\mathbf{x}) + C_{11} p(y=1|\mathbf{x}) = C_{01} (1 - p(y=1|\mathbf{x}))$
- 预测类别 0 的风险：$R(0|\mathbf{x}) = C_{10} p(y=1|\mathbf{x}) + C_{00} p(y=0|\mathbf{x}) = C_{10} p(y=1|\mathbf{x})$

最优决策是当 $R(1|\mathbf{x}) \le R(0|\mathbf{x})$ 时预测类别 1。即：

$$
C_{01} (1 - p(y=1|\mathbf{x})) \le C_{10} p(y=1|\mathbf{x})
$$

解这个不等式，我们得到：

$$
p(y=1|\mathbf{x}) \ge \frac{C_{01}}{C_{01} + C_{10}}
$$

这个结果非常重要。它表明，在存在非对称成本时，最优决策不再是简单地将后验概率与 $0.5$ 比较，而是与一个由成本决定的**新阈值 $t^{\star} = \frac{C_{01}}{C_{01} + C_{10}}$** 进行比较。例如，如果假阴性的成本 $C_{10}$ 远大于假阳性的成本 $C_{01}$，则阈值 $t^{\star}$ 会很低，这意味着模型只需要对样本属于正类有较低的[置信度](@entry_id:267904)就应该预测为正类，以避免代价高昂的假阴性错误。这种调整决策阈值的技术被称为**阈值移动 (threshold moving)**。

### 学习分类器：[损失函数](@entry_id:634569)的角色

我们已经看到，做出明智的分类决策依赖于准确的后验概率 $p(y=j|\mathbf{x})$。那么，模型是如何学习来估计这些概率的呢？答案是通过最小化一个精心设计的**损失函数 (loss function)**。

#### [交叉熵损失](@entry_id:141524)

对于[分类任务](@entry_id:635433)，最常用和最基础的损失函数是**[交叉熵损失](@entry_id:141524) (cross-entropy loss)**。对于一个样本 $(\mathbf{x}, y)$，其中 $y$ 是真实类别，$\hat{p}_j = p_{\theta}(y=j|\mathbf{x})$ 是模型（参数为 $\theta$）预测的类别 $j$ 的概率，多类别[交叉熵损失](@entry_id:141524)定义为：

$$
L(\theta) = -\sum_{j=1}^{K} \mathbb{I}(y=j) \log(\hat{p}_j) = -\log(\hat{p}_y)
$$

其中 $\mathbb{I}(\cdot)$ 是[指示函数](@entry_id:186820)。这个[损失函数](@entry_id:634569)鼓励模型为真实类别赋予尽可能高的概率。在训练过程中，模型通过[梯度下降](@entry_id:145942)等[优化算法](@entry_id:147840)调整其参数 $\theta$，以最小化在整个训练集上的平均[交叉熵损失](@entry_id:141524)。

[交叉熵损失](@entry_id:141524)的计算效率很高。对于一个包含 $n$ 个样本的数据集，计算总损失和梯度的复杂度是 $O(n)$，即与样本数量成[线性关系](@entry_id:267880)。

#### 应对[类别不平衡](@entry_id:636658)

然而，标准的[交叉熵损失](@entry_id:141524)在处理**[类别不平衡](@entry_id:636658) (class imbalance)** 的数据集时会遇到问题。[类别不平衡](@entry_id:636658)是指不同类别的样本数量差异巨大。在这种情况下，如果一个模型简单地最小化平均损失，它会倾向于优先学习多数类，因为它们对总损失的贡献更大，而可能会忽视或放弃学习少数类。

为了解决这个问题，研究人员提出了多种策略。

**1. 损失重加权 (Loss Re-weighting)**

一个直观的方法是为不同类别的损失赋予不同的权重。具体来说，我们可以为少数类的样本赋予更高的权重，为多数类的样本赋予较低的权重。

- **逆频率加权 (Inverse-Frequency Weighting)：** 最简单的加权策略是让类别 $c$ 的权重 $w_c$ 与其样本数 $n_c$ 成反比，即 $w_c \propto 1/n_c$。这直接补偿了样本数量的差异。

- **基于有效样本数的类别平衡损失 (Class-Balanced Loss based on Effective Number of Samples)：** 这是一个更精细的加权方案。其核心思想是，随着一个类别样本数量的增加，新样本带来的边际效益是递减的。一个拥有海量样本的类别中，许多样本可能是冗余的。我们可以用一个**有效样本数 ($E_n$)** 来建模这种递减效应，它被定义为一个几何级数之和：
  $$
  E_n = \sum_{k=0}^{n-1} \beta^{k} = \frac{1 - \beta^{n}}{1 - \beta}
  $$
  其中 $n$ 是实际样本数，$\beta \in [0, 1)$ 是一个超参数，控制着样本间的重叠程度。当 $\beta \to 1$ 时，$E_n \to n$，模型退化为逆频率加权；当 $\beta \to 0$ 时，$E_n \to 1$，所有样本权重相同，无重加权。类别平衡损失的权重与有效样本数成反比，即 $w_c \propto 1/E_{n_c}$。这种方法通过一个超参数 $\beta$ 提供了在不加权和逆频率加权之间的平滑过渡。

**2. 优化排序指标**

另一种方法是改变优化的目标。与其直接优化预测概率的准确性（如[交叉熵](@entry_id:269529)），我们可以转而优化一个与类别排序相关的指标，如**[ROC曲线](@entry_id:182055)下面积 (Area Under the Receiver Operating Characteristic Curve, AUC)**。AUC衡量的是模型将随机选择的正样本排在随机选择的负样本前面的概率，因此它对[类别不平衡](@entry_id:636658)不敏感。

直接优化不可微的AUC是困难的，但我们可以优化其可微的代理损失 (surrogate loss)。一个常见的代理是**成对排序损失 (pairwise ranking loss)**。其思想是，对于训练集中的每一对正样本（来自类别 $\mathcal{P}$）和负样本（来自类别 $\mathcal{N}$），我们都希望正样本的得分 $f_{\theta}(x_i)$ 高于负样本的得分 $f_{\theta}(x_j)$。一个典型的[损失函数](@entry_id:634569)是：

$$
L_{\mathrm{AUC}}(\theta) = \frac{1}{n_{+} n_{-}} \sum_{i \in \mathcal{P}} \sum_{j \in \mathcal{N}} \max(0, 1 - (f_{\theta}(x_i) - f_{\theta}(x_j)))
$$

其中 $n_+$ 和 $n_-$ 分别是正负样本的数量。这种损失直接惩罚了错误的排序。然而，一个朴素的实现需要遍历所有 $n_+ \times n_-$ 个样本对，其计算复杂度为 $O(n_+ n_-)$，在数据量大时是不可行的。幸运的是，可以通过**小批量采样 (mini-batch sampling)** 的方式来高效地估计其梯度，使得在大规模数据集上进行训练成为可能。

### 面对[分布](@entry_id:182848)变化的稳健性

监督学习的一个核心假设是，测试数据的[分布](@entry_id:182848)与训练数据的[分布](@entry_id:182848)相同。然而，在现实世界中，这个假设经常被违背。这种训练和测试[分布](@entry_id:182848)之间的不一致被称为**[分布](@entry_id:182848)变化 (distribution shift)**。一个稳健的分类器应该能够优雅地处理这种变化。

#### 类别先验变化：[长尾](@entry_id:274276)识别

一种常见的[分布](@entry_id:182848)变化是**类别[先验概率](@entry_id:275634) (class prior probability)** 的变化。考虑一个**[长尾分布](@entry_id:142737) (long-tailed distribution)** 的训练集，其中少数“头部”类别拥有大量样本，而大多数“尾部”类别样本稀少。一个标准分类器在训练时会隐式地学习到这些训练先验 $\pi_k = p(\text{class}=k)$。

问题在于，当模型部署到新环境中时，类别的相对频率可能会发生变化，即测试时的[先验概率](@entry_id:275634) $\pi'_k$ 与训练时不同。在这种情况下，原始的决策边界就不再是最优的了。

幸运的是，如果类别条件[似然](@entry_id:167119) $p(\mathbf{x}|y=k)$ 保持不变，我们可以对模型的输出进行校正。根据贝叶斯定理，后验概率可以表示为：

$$
p(y=k|\mathbf{x}) \propto p(\mathbf{x}|y=k) \pi_k
$$

模型的 logits $z_k(\mathbf{x})$ 近似于对数后验几率，其中包含了对数先验项：$z_k(\mathbf{x}) \approx \log p(\mathbf{x}|y=k) + \log \pi_k + \text{const}$。当先验从 $\pi_k$ 变为 $\pi'_k$ 时，为了得到新的最优决策，我们只需对原始 logits 进行一个简单的加法调整：

$$
z'_k(\mathbf{x}) = z_k(\mathbf{x}) - \log \pi_k + \log \pi'_k = z_k(\mathbf{x}) + \log\left(\frac{\pi'_k}{\pi_k}\right)
$$

这种技术被称为**对数调整 (logit adjustment)**。它允许模型在不重新训练的情况下适应变化的类别[分布](@entry_id:182848)，从而显著提高了在动态环境中的稳健性。

#### 数据退化：测量对扰动的敏感性

另一种[分布](@entry_id:182848)变化源于[数据质量](@entry_id:185007)的退化。例如，在自动驾驶中，摄像头拍摄的图像可能会因为雨、雾或运动模糊而变得不清晰。一个稳健的模型应该在这些扰动下依然能做出正确的预测。

我们可以通过一个程式化的模型来分析和量化模型对数据退化的**稳健性 (robustness)** 。假设一个分类器的**决策边界 (decision margin)** $m_0$（例如，正确类别的 logit 与最强竞争者 logit 的差值）在干净数据上服从某个[分布](@entry_id:182848)。当数据受到严重程度为 $s$ 的退化时，决策边界会发生衰减：

$$
m_s = m_0 - \Delta(s)
$$

其中 $\Delta(s)$ 是一个随严重程度 $s$ 单调增加的衰减项。分类正确的条件是 $m_s > 0$。因此，在严重程度为 $s$ 时的准确率 $\text{Acc}(s)$ 就是 $\mathbb{P}[m_0 > \Delta(s)]$。通过对不同严重程度 $s$ 计算准确率，我们可以得到一条准确率-严重性曲线。这条曲线的陡峭程度反映了模型的稳健性：曲线越平坦，模型越稳健。我们可以通[过拟合](@entry_id:139093)这条[曲线的斜率](@entry_id:178976)来得到一个定量的**敏感度指标 $\partial \text{Acc}/\partial s$**，用于比较不同模型的稳健性。

#### [子群](@entry_id:146164)体偏移：[算法公平性](@entry_id:143652)

[分布](@entry_id:182848)变化也与**[算法公平性](@entry_id:143652) (algorithmic fairness)** 密切相关。一个数据集可能由多个[子群](@entry_id:146164)体（例如，按种族、性别或地理位置划分的群体）组成，而这些[子群](@entry_id:146164)体的数据[分布](@entry_id:182848)可能存在差异。标准的**[经验风险最小化](@entry_id:633880) (Empirical Risk Minimization, ERM)** 算法旨在最小化在整个数据集上的平均损失。这可能会导致模型在多数群体上表现良好，但牺牲了在少数或非[典型群](@entry_id:203721)体上的性能。

为了解决这个问题，我们可以将公平性问题视为一个对最差[子群](@entry_id:146164)体性能的稳健性问题。**群体[分布](@entry_id:182848)[稳健优化](@entry_id:163807) (Group Distributionally Robust Optimization, Group DRO)** 正是为此而生。与最小化平均风险不同，Group DRO 的目标是最小化所有[子群](@entry_id:146164)体中的**最差群体风险 (worst-group risk)**：

$$
\min_{\theta} \max_{g \in \mathcal{G}} \mathbb{E}_{(\mathbf{x},y)\sim P_g} [ \ell(f_\theta(\mathbf{x}),y) ]
$$

其中 $\mathcal{G}$ 是[子群](@entry_id:146164)体的集合，$P_g$ 是群体 $g$ 的数据[分布](@entry_id:182848)。一个实用的 Group DRO 训练算法是，在每一步迭代中，首先找出当前损失最高的“最差”群体，然后仅使用该群体的数据来计算梯度并更新模型参数。这个过程迫使模型关注并改善其在表现最差的群体上的性能，从而获得更公平、更稳健的模型。

### 超越封闭世界：开放集识别

传统的[分类任务](@entry_id:635433)遵循一个**封闭世界假设 (closed-world assumption)**，即测试时遇到的所有类别都在训练时出现过。然而，在许多现实应用中，这个假设不成立。模型不可避免地会遇到来自训练期间未见过的**未知类别 (unknown classes)** 的输入。**开放集识别 (Open-Set Recognition)** 的目标就是让模型不仅能正确分类已知类别，还能识别并拒绝这些未知类别的输入。

#### 基于[置信度](@entry_id:267904)的拒绝

核心思想是利用分类器自身的**置信度 (confidence)** 来判断一个输入是“已知的”还是“未知的”。直觉上，当模型面对一个来自已知类别的输入时，它应该会以高置信度做出预测；而当面对一个未知输入时，它的预测[置信度](@entry_id:267904)应该会比较低。

**1. 最大 [Softmax](@entry_id:636766) 概率 (Maximum [Softmax](@entry_id:636766) Probability, MSP)**

最简单的置信度分数是**最大 [Softmax](@entry_id:636766) 概率 (MSP)**，即模型为所有类别分配的概率中的最大值：$m(\mathbf{x}) = \max_k p(y=k|\mathbf{x})$。我们可以设定一个阈值 $\tau$，如果一个输入的 MSP 低于这个阈值 ($m(\mathbf{x}) \le \tau$)，就将其拒绝为“未知”。

这个阈值 $\tau$ 需要被仔细校准。一个标准做法是在一个包含已知类别样本的验证集上进行校准，选择一个阈值使得特定比例（例如，$\alpha=0.05$）的已知样本被错误地拒绝。这被称为**假拒绝率 (False Rejection Rate, FRR)**。

**2. 增强置信度分离 (ODIN)**

单纯的 MSP 方法有时区分度不足。**ODIN (Out-of-Distribution detector with temperature scaling and input perturbation)** 等方法旨在拉大已知[分布](@entry_id:182848) (In-Distribution, ID) 和未知[分布](@entry_id:182848) (Out-of-Distribution, OOD) 样本置信度得分之间的差距。ODIN 主要使用两种技术：

- **温度缩放 (Temperature Scaling)：** 在计算 [Softmax](@entry_id:636766) 之前，将 logits 除以一个温度参数 $T > 1$。这会使[概率分布](@entry_id:146404)“软化”（更接近[均匀分布](@entry_id:194597)），从而降低所有样本的 MSP，但通常对 OOD 样本的影响更大。
- **输入/Logit 扰动：** 在计算 MSP 之前，对输入或 logits 添加一个微小的、精心设计的扰动。扰动的方向是沿着能最大化模型对预测类别[置信度](@entry_id:267904)的梯度方向。这会使得 ID 样本的 MSP 变得更高，而 OOD 样本的 MSP 变化不大或变小，从而增强了区分度。

#### 显式拒绝头

另一种更直接的方法是训练一个专门用于拒绝的模块，即**拒绝头 (rejection head)**。我们可以构建一个新的[二元分类](@entry_id:142257)任务：区分“已知”和“未知”样本。

1.  **[特征提取](@entry_id:164394)：** 对于任何输入 $\mathbf{x}$，我们不直接使用原始特征，而是从基础分类器的输出中提取更有信息的特征。例如，我们可以使用 MSP ($p_{\max}(\mathbf{x})$) 和决策边界（$p_{\max}(\mathbf{x})$ 与第二大概率之差）作为拒绝头的输入特征。

2.  **负样本合成：** 训练这个拒绝头需要“未知”类别的样本作为负例。由于我们没有真实的未知类别数据，可以通过**负样本合成 (negative synthesis)** 的方式来创建。例如，我们可以在特征空间中远离已知类别[分布](@entry_id:182848)的区域进行均匀采样，生成“伪未知”样本。

3.  **训练与评估：** 将已知类别的训练样本（正例）和合成的负样本（负例）结合起来，训练一个[二元分类](@entry_id:142257)器（如逻辑回归）作为拒绝头。在评估时，我们可以使用**开放集 F1 分数 (open-set F1-score)**，它综合了模型在拒绝真实未知样本（召回率）和避免错误拒绝已知样本（[精确率](@entry_id:190064)）两方面的能力。

这种方法将开放集识别问题转化为一个标准的监督学习问题，提供了一种系统性的解决方案。