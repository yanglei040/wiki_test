{
    "hands_on_practices": [
        {
            "introduction": "理解任何复杂系统的第一步是观察其基本构成。在金融市场中，限价订单是构成流动性“大厦”的砖石。本练习旨在探索一个关键的“风格化事实”：订单规模的分布。通过将观测数据拟合到一个截断的幂律分布模型，您将学习如何量化不同规模订单的出现频率，这对理解市场深度和流动性碎片化至关重要。",
            "id": "2408310",
            "problem": "您会获得一个加密货币限价订单簿中独立限价订单大小的观测样本，以基础资产单位表示（例如，币的数量）。假定在每种情况下，所有观测值都是独立同分布的，并且在指定区间内，订单大小遵循闭区间上的连续截断幂律分布。具体而言，对于参数 $x_{\\min} > 0$、$x_{\\max} > x_{\\min}$ 和指数 $\\alpha > 0$，其概率密度函数为\n$$\nf(x \\mid \\alpha, x_{\\min}, x_{\\max}) = C(\\alpha; x_{\\min}, x_{\\max}) \\, x^{-\\alpha}, \\quad x \\in [x_{\\min}, x_{\\max}],\n$$\n在该区间之外，$f(x \\mid \\alpha, x_{\\min}, x_{\\max}) = 0$，其中归一化常数 $C(\\alpha; x_{\\min}, x_{\\max})$ 满足\n$$\n\\int_{x_{\\min}}^{x_{\\max}} C(\\alpha; x_{\\min}, x_{\\max}) \\, x^{-\\alpha} \\, dx = 1.\n$$\n对于 $\\alpha \\neq 1$，该常数为\n$$\nC(\\alpha; x_{\\min}, x_{\\max}) = \\frac{1 - \\alpha}{x_{\\max}^{1 - \\alpha} - x_{\\min}^{1 - \\alpha}},\n$$\n对于 $\\alpha = 1$，它是相应的连续极限。\n\n任务：对于下方的每个测试用例，仅使用落在指定区间 $[x_{\\min}, x_{\\max}]$ 内的观测值，通过在截断幂律模型下最大化对数似然来估计指数 $\\alpha$。将每个用例估计出的 $\\alpha$ 作为一个纯数（无单位）报告。然后，从经济学角度解释该指数，说明大订单与小订单的相对频率；但是，您的程序输出应仅包含数值估计。\n\n所有订单大小均以基础资产单位（例如，币）表示。指数 $\\alpha$ 是无量纲的。您的程序的最终输出必须为单行，其中包含一个由逗号分隔的三个估计指数的列表，每个指数四舍五入到小数点后四位，并用方括号括起来（例如，$[\\alpha_1,\\alpha_2,\\alpha_3]$）。不应打印任何其他文本。\n\n测试套件（请精确使用这些样本和区间）：\n\n用例1（正常路径，中度截断）：\n- 区间：$[x_{\\min}, x_{\\max}] = [0.02, 5.0]$。\n- 观测到的订单大小：\n$[0.02, 0.02, 0.025, 0.03, 0.03, 0.035, 0.04, 0.045, 0.05, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.12, 0.15, 0.18, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.60, 0.70, 0.80, 0.90, 1.00, 1.10, 1.30, 1.50, 1.70, 2.00, 2.50, 3.00, 3.50, 4.00]$。\n\n用例2（更宽的截断，质量集中在下界附近，有少量大订单）：\n- 区间：$[x_{\\min}, x_{\\max}] = [0.01, 10.0]$。\n- 观测到的订单大小：\n$[0.01, 0.01, 0.012, 0.015, 0.02, 0.02, 0.025, 0.03, 0.035, 0.04, 0.05, 0.06, 0.08, 0.10, 0.13, 0.17, 0.22, 0.30, 0.40, 0.55, 0.75, 1.00, 1.40, 2.00, 3.00, 4.50, 6.00, 8.00, 9.50]$。\n\n用例3（边缘用例，拟合前需要在区间内进行筛选）：\n- 区间：$[x_{\\min}, x_{\\max}] = [0.05, 2.0]$。\n- 观测到的订单大小（请注意，某些值位于区间之外，在估计前必须丢弃）：\n$[0.03, 0.04, 0.05, 0.06, 0.07, 0.09, 0.12, 0.16, 0.21, 0.28, 0.37, 0.50, 0.68, 0.91, 1.20, 1.60, 2.00, 2.20, 3.00, 0.02, 1.90]$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[1.7321,2.0000,1.2345]$），每个条目是相应案例的估计指数 $\\alpha$，四舍五入到小数点后四位。不应产生任何其他输出。",
            "solution": "该问题要求根据一组观测到的订单大小，估计截断幂律分布的指数 $\\alpha$。估计将使用最大似然估计（MLE）方法进行。分析过程如下。\n\n首先，必须验证问题的陈述。该问题具有科学依据，因为幂律分布是经济物理学和金融学中用于描述订单大小等数量的标准模型。该问题是适定的，它提供了清晰的统计模型和数据，通过标准的估计程序可以得到唯一的解。所有术语都有定义，提供的数据与上下文一致。因此，该问题被认为是有效的，可以构建一个严谨的解决方案。\n\n对于 $x \\in [x_{\\min}, x_{\\max}]$，订单大小 $x$ 的概率密度函数（PDF）如下：\n$$\nf(x \\mid \\alpha, x_{\\min}, x_{\\max}) = C(\\alpha; x_{\\min}, x_{\\max}) \\, x^{-\\alpha}\n$$\n其中 $\\alpha > 0$ 是待估计的指数，$x_{\\min}$ 和 $x_{\\max}$ 是给定的截断边界。归一化常数 $C(\\alpha; x_{\\min}, x_{\\max})$（下文记作 $C(\\alpha)$）确保 PDF 在其支撑集上的积分为1。\n\n对于 $\\alpha \\neq 1$，该常数为：\n$$\nC(\\alpha) = \\frac{1 - \\alpha}{x_{\\max}^{1 - \\alpha} - x_{\\min}^{1 - \\alpha}}\n$$\n对于 $\\alpha = 1$ 的特殊情况，我们必须计算当 $\\alpha \\to 1$ 时 $C(\\alpha)$ 的极限。通过对关于 $\\delta = 1 - \\alpha$ 的表达式应用洛必达法则，我们得到：\n$$\nC(1) = \\lim_{\\alpha \\to 1} \\frac{1 - \\alpha}{x_{\\max}^{1 - \\alpha} - x_{\\min}^{1 - \\alpha}} = \\frac{1}{\\ln(x_{\\max}) - \\ln(x_{\\min})} = \\frac{1}{\\ln(x_{\\max}/x_{\\min})}\n$$\n\n给定一组落在区间 $[x_{\\min}, x_{\\max}]$ 内的 $N$ 个独立同分布的观测值 $\\{x_i\\}_{i=1}^N$，似然函数 $L(\\alpha)$ 是各个概率的乘积：\n$$\nL(\\alpha \\mid \\{x_i\\}) = \\prod_{i=1}^{N} f(x_i \\mid \\alpha) = \\prod_{i=1}^{N} C(\\alpha) x_i^{-\\alpha} = [C(\\alpha)]^N \\left( \\prod_{i=1}^{N} x_i \\right)^{-\\alpha}\n$$\n在计算上，处理对数似然函数 $\\mathcal{L}(\\alpha) = \\ln L(\\alpha)$ 更为方便：\n$$\n\\mathcal{L}(\\alpha) = N \\ln C(\\alpha) - \\alpha \\sum_{i=1}^{N} \\ln x_i\n$$\n为了找到最大似然估计 $\\hat{\\alpha}$，我们必须找到使 $\\mathcal{L}(\\alpha)$ 最大化的 $\\alpha$ 值。这可以通过求解 $\\frac{d\\mathcal{L}(\\alpha)}{d\\alpha} = 0$ 来实现。其导数为：\n$$\n\\frac{d\\mathcal{L}(\\alpha)}{d\\alpha} = N \\frac{d}{d\\alpha}(\\ln C(\\alpha)) - \\sum_{i=1}^{N} \\ln x_i = 0\n$$\n$\\ln C(\\alpha)$ 的导数不简单，得到的方程是超越方程，这意味着无法解析地求解 $\\alpha$。因此，需要采用数值方法。标准方法是使用数值优化算法来找到负对数似然函数 $-\\mathcal{L}(\\alpha)$ 的最小值。\n\n需要最小化的函数是：\n$$\n-\\mathcal{L}(\\alpha) = -N \\ln C(\\alpha) + \\alpha \\sum_{i=1}^{N} \\ln x_i\n$$\n对于所有 $\\alpha \\neq 1$ 都有效的 $\\ln C(\\alpha)$ 的数值稳定表达式是 $\\ln|1 - \\alpha| - \\ln|x_{\\max}^{1 - \\alpha} - x_{\\min}^{1 - \\alpha}|$。必须分段实现完整的目标函数，以处理 $\\alpha = 1$ 的单独情况。该算法将搜索使此函数最小化的 $\\alpha > 0$ 的值。\n\n对每个测试用例，步骤如下：\n$1$. 筛选提供的观测订单大小列表，只保留那些位于指定区间 $[x_{\\min}, x_{\\max}]$ 内的值 $x_i$。设此类有效观测值的数量为 $N$。\n$2$. 计算这些有效观测值的对数之和，即 $\\sum_{i=1}^{N} \\ln x_i$。\n$3$. 使用 $N$、$\\sum \\ln x_i$、$x_{\\min}$ 和 $x_{\\max}$ 的值，在合适的范围内（例如 $\\alpha > 0$）对负对数似然函数 $-\\mathcal{L}(\\alpha)$ 关于 $\\alpha$ 进行数值最小化。\n$4$. 使该函数最小化的 $\\alpha$ 值即为最大似然估计 $\\hat{\\alpha}$。\n\n在经济学上，指数 $\\alpha$ 量化了订单大小的分布。一个较大的 $\\alpha$ 值表示概率密度 $f(x) \\propto x^{-\\alpha}$ 随着 $x$ 的增加而迅速衰减。这意味着小额订单的频率远高于大额订单。一个较小的 $\\alpha$ 值对应于分布中“更重的尾部”，表明大额订单虽然频率仍低于小额订单，但其出现的相对概率更高。因此，$\\alpha$ 是衡量市场碎片化程度以及散户规模与机构规模流动性供给之间平衡的一个指标。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Solves for the MLE of the power-law exponent alpha for three test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"interval\": (0.02, 5.0),\n            \"observations\": [\n                0.02, 0.02, 0.025, 0.03, 0.03, 0.035, 0.04, 0.045, 0.05, 0.05, 0.06, 0.07, 0.08, 0.09,\n                0.10, 0.12, 0.15, 0.18, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.60, 0.70, 0.80,\n                0.90, 1.00, 1.10, 1.30, 1.50, 1.70, 2.00, 2.50, 3.00, 3.50, 4.00\n            ]\n        },\n        {\n            \"interval\": (0.01, 10.0),\n            \"observations\": [\n                0.01, 0.01, 0.012, 0.015, 0.02, 0.02, 0.025, 0.03, 0.035, 0.04, 0.05, 0.06, 0.08,\n                0.10, 0.13, 0.17, 0.22, 0.30, 0.40, 0.55, 0.75, 1.00, 1.40, 2.00, 3.00, 4.50,\n                6.00, 8.00, 9.50\n            ]\n        },\n        {\n            \"interval\": (0.05, 2.0),\n            \"observations\": [\n                0.03, 0.04, 0.05, 0.06, 0.07, 0.09, 0.12, 0.16, 0.21, 0.28, 0.37, 0.50, 0.68,\n                0.91, 1.20, 1.60, 2.00, 2.20, 3.00, 0.02, 1.90\n            ]\n        }\n    ]\n\n    results = []\n\n    def neg_log_likelihood(alpha, N, sum_log_x, x_min, x_max):\n        \"\"\"\n        Computes the negative log-likelihood for the truncated power-law distribution.\n        \"\"\"\n        if N == 0:\n            return np.inf\n\n        # Case for alpha = 1\n        if np.isclose(alpha, 1.0):\n            log_C = -np.log(np.log(x_max) - np.log(x_min))\n        # Case for alpha != 1\n        else:\n            one_minus_alpha = 1.0 - alpha\n            try:\n                # This formulation is numerically stable for alpha  1 and alpha > 1\n                log_C = np.log(np.abs(one_minus_alpha)) - np.log(np.abs(x_max**one_minus_alpha - x_min**one_minus_alpha))\n            except (ValueError, ZeroDivisionError):\n                return np.inf\n\n        log_L = N * log_C - alpha * sum_log_x\n        return -log_L\n\n    for case in test_cases:\n        x_min, x_max = case[\"interval\"]\n        obs = np.array(case[\"observations\"])\n\n        # 1. Filter data to be within the specified interval [x_min, x_max]\n        filtered_obs = obs[(obs >= x_min)  (obs = x_max)]\n        \n        N = len(filtered_obs)\n        if N == 0:\n            # Handle cases with no valid data, though not expected here.\n            results.append(np.nan)\n            continue\n            \n        # 2. Pre-compute sum of logarithms\n        sum_log_x = np.sum(np.log(filtered_obs))\n\n        # 3. Minimize the negative log-likelihood function\n        # The search for alpha > 0. Bounds avoid alpha=0 and very large values.\n        res = minimize_scalar(\n            neg_log_likelihood,\n            bounds=(1e-6, 10.0),\n            args=(N, sum_log_x, x_min, x_max),\n            method='bounded'\n        )\n\n        estimated_alpha = res.x\n        results.append(estimated_alpha)\n\n    # Format output to four decimal places\n    formatted_results = [f\"{r:.4f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了订单簿的静态结构之后，下一步是分析市场对交易行为的动态响应。本实践将引导您探索“市场冲击”——即交易对资产价格产生的影响。您将实现并检验一个经典的幂律模型，该模型对于预测交易成本、设计高效的交易执行算法以及管理大额头寸的风险至关重要。",
            "id": "2408364",
            "problem": "您正在研究限价订单簿（LOB）中市价订单的即时价格影响。我们将即时市场影响定义为执行一个规模为 $Q$ 的市价订单所引起的中价变化，记为 $I(Q)$。在一个静态LOB中，相对于当前中价的价格位移为 $u$ 时，单位价格位移的边际供给密度为连续函数 $s(u)$，则执行的量满足以下一致性条件：\n$$\nQ \\;=\\; \\int_{0}^{I(Q)} s(u)\\,du,\n$$\n而影响 $I(Q)$ 是消耗 $Q$ 单位流动性所需的价格位移。假设边际供给密度是 $u$ 的单调函数，并且LOB在所关注的时间范围内是局部平稳的。\n\n您需要提出了一个参数化的影响模型，并使用合成数据对其进行实证评估。该参数模型为非线性幂律法则：\n$$\nI(Q) \\;=\\; a\\,Q^{b},\n$$\n其中参数 $a0$ 且 $b0$。观测值受到乘性噪声的影响：观测到的影响 $I_{\\text{obs}}(Q)$ 满足：\n$$\nI_{\\text{obs}}(Q) \\;=\\; I(Q)\\,\\exp(\\varepsilon),\n$$\n其中 $\\varepsilon$ 是独立同分布的高斯噪声，均值为 $0$，方差为 $\\tau^{2}$。\n\n任务：\n- 对于下面测试套件中描述的每个数据集，按如下方式生成合成数据：从 $[Q_{\\min},Q_{\\max}]$ 上的对数均匀分布中抽取 $N$ 个独立的交易规模 $Q_{i}$（即 $\\log Q_{i}$ 在 $[\\log Q_{\\min},\\log Q_{\\max}]$ 上均匀分布），计算噪声 $\\varepsilon_{i}\\sim \\mathcal{N}(0,\\tau^{2})$，并设置 $I_{i,\\text{obs}}=a\\,Q_{i}^{b}\\,\\exp(\\varepsilon_{i})$。\n- 基于联合样本 $\\{(Q_{i},I_{i,\\text{obs}})\\}_{i=1}^{N}$ 以及上述噪声模型所依据的、有充分理由的统计学原理，设计并实现一个 $b$ 的估计器。您的估计器必须在 $Q_{i}$ 和 $I_{i,\\text{obs}}$ 严格为正时有良好定义，并且不应依赖外部数据。\n- 对于每个测试用例，仅输出您对该数据集的估计值 $\\hat{b}$。\n\n提供一个执行所有测试用例并打印 $\\hat{b}$ 估计值列表的程序。\n\n您可以使用的基础知识包括：\n- 即时市场影响 $I(Q)$ 的定义，即在LOB中执行数量 $Q$ 所需的价格位移。\n- 积分关系 $Q=\\int_{0}^{I(Q)} s(u)\\,du$，它将消耗的深度与订单规模等同起来。\n- 高斯分布的性质以及在正确指定的模型下的最大似然估计（MLE）原理。\n- 应用于变换后的线性模型时的普通最小二乘（OLS）回归的性质。\n\n测试套件规格：\n对于每个案例，您必须使用指定的随机种子以确保可复现性。在每个元组中，参数为 $(\\text{seed}, a, b, \\tau, N, Q_{\\min}, Q_{\\max})$。\n\n- 案例 A（凹性影响，低噪声，宽规模范围）：$(314159,\\, 0.5,\\, 0.6,\\, 0.05,\\, 2000,\\, 100,\\, 50000)$。\n- 案例 B（近线性影响，中等范围）：$(271828,\\, 1.2,\\, 1.0,\\, 0.05,\\, 1500,\\, 50,\\, 20000)$。\n- 案例 C（强凹性影响，较高噪声，非常宽的范围）：$(424242,\\, 0.8,\\, 0.3,\\, 0.10,\\, 3000,\\, 10,\\, 100000)$。\n- 案例 D（中度凹性影响，较强噪声，样本较少）：$(8675309,\\, 0.3,\\, 0.9,\\, 0.20,\\, 800,\\, 5,\\, 5000)$。\n\n以上所有符号和数字都是精确的，必须严格遵守。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含按 A、B、C、D 顺序排列的四个估计值，以逗号分隔，并用方括号括起来。例如，输出必须类似于\n$[\\hat{b}_{A},\\hat{b}_{B},\\hat{b}_{C},\\hat{b}_{D}]$，\n其中每个 $\\hat{b}$ 表示为浮点数。在打印输出中，将每个 $\\hat{b}$ 四舍五入到恰好 $6$ 位小数。\n\n不涉及物理单位或角度单位。不使用百分比。最终答案必须是浮点数。程序不得读取任何输入，并且必须完全自包含，并可使用指定的种子进行复现。",
            "solution": "问题陈述已经过严格验证，被认为是有效的。它在科学上基于成熟的市场微观结构理论，在数学上是适定的，并为任务提供了完整而明确的规范。因此，我们可以着手推导和实施解决方案。\n\n该问题要求在给定的非线性幂律市场影响模型中估计参数 $b$：\n$$\nI(Q) \\;=\\; a\\,Q^{b}\n$$\n观测值受到乘性的、对数正态分布的噪声的影响。对于一组规模为 $\\{Q_i\\}_{i=1}^{N}$ 的 $N$ 笔交易，观测到的影响 $\\{I_{i,\\text{obs}}\\}_{i=1}^{N}$ 由以下模型给出：\n$$\nI_{i,\\text{obs}} \\;=\\; a\\,Q_{i}^{b}\\,\\exp(\\varepsilon_{i})\n$$\n其中噪声项 $\\varepsilon_{i}$ 是从均值为 $0$、方差为 $\\tau^2$ 的高斯分布中独立同分布地抽取的，即 $\\varepsilon_{i} \\sim \\mathcal{N}(0, \\tau^2)$。\n\n为了估计这个非线性模型的参数，一种标准而有效的方法是通过对数变换将关系线性化。对观测方程两边取自然对数，得到：\n$$\n\\log(I_{i,\\text{obs}}) \\;=\\; \\log\\left(a\\,Q_{i}^{b}\\,\\exp(\\varepsilon_{i})\\right)\n$$\n利用对数的基本性质，特别是 $\\log(xyz) = \\log(x) + \\log(y) + \\log(z)$ 和 $\\log(x^k) = k\\log(x)$，我们可以展开右边：\n$$\n\\log(I_{i,\\text{obs}}) \\;=\\; \\log(a) + \\log(Q_{i}^{b}) + \\log(\\exp(\\varepsilon_{i}))\n$$\n这可以简化为一个线性方程：\n$$\n\\log(I_{i,\\text{obs}}) \\;=\\; \\log(a) + b\\,\\log(Q_{i}) + \\varepsilon_{i}\n$$\n为了将其形式化为一个标准的线性回归问题，我们引入以下变量变换：\n- 令 $y_i = \\log(I_{i,\\text{obs}})$ 为响应变量。\n- 令 $x_i = \\log(Q_i)$ 为预测变量。\n- 令 $\\beta_0 = \\log(a)$ 为截距项。\n- 令 $\\beta_1 = b$ 为斜率系数，这是我们感兴趣的参数。\n\n现在，该模型可以写成简单线性回归的规范形式：\n$$\ny_i \\;=\\; \\beta_0 + \\beta_1 x_i + \\varepsilon_i\n$$\n问题陈述指出，交易规模 $Q_i$ 和噪声项 $\\varepsilon_i$ 是独立生成的。因此，预测变量 $x_i = \\log(Q_i)$ 与误差项 $\\varepsilon_i$ 无关。误差 $\\varepsilon_i$ 是从零均值、恒定方差（$\\tau^2$）的正态分布中独立同分布抽取的。这些条件满足了经典线性回归模型的所有假设。\n\n在这些条件下，普通最小二乘（OLS）估计器是参数 $\\beta_0$ 和 $\\beta_1$ 的最佳线性无偏估计器（BLUE）。此外，由于误差项是正态分布的，OLS估计器与最大似然估计器（MLE）相同，后者具有很强的统计特性，包括一致性和渐近有效性。\n\nOLS方法通过最小化残差平方和（SSR）来找到参数估计值 $\\hat{\\beta}_0$ 和 $\\hat{\\beta}_1$：\n$$\n\\text{SSR} \\;=\\; \\sum_{i=1}^{N} (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)^2\n$$\n斜率系数 $\\hat{\\beta}_1$ 的著名闭式解为：\n$$\n\\hat{\\beta}_1 \\;=\\; \\frac{\\sum_{i=1}^{N}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{N}(x_i - \\bar{x})^2}\n$$\n其中 $\\bar{x} = \\frac{1}{N}\\sum_{i=1}^{N} x_i$ 和 $\\bar{y} = \\frac{1}{N}\\sum_{i=1}^{N} y_i$ 分别是预测变量和响应变量的样本均值。因此，我们对市场影响指数 $\\hat{b}$ 的估计就是这个估计出的斜率系数，即 $\\hat{b} = \\hat{\\beta}_1$。\n\n每个测试用例的算法流程如下：\n$1$. **数据生成**：\n    - 对于由 $(\\text{seed}, a, b, \\tau, N, Q_{\\min}, Q_{\\max})$ 指定的给定测试用例，使用指定的种子初始化伪随机数生成器以保证可复现性。\n    - 从区间 $[Q_{\\min}, Q_{\\max}]$ 上的对数均匀分布中生成 $N$ 个交易规模 $Q_i$。这等同于从均匀分布 $\\mathcal{U}(\\log(Q_{\\min}), \\log(Q_{\\max}))$ 中抽取 $\\log(Q_i)$。\n    - 从正态分布 $\\mathcal{N}(0, \\tau^2)$ 中生成 $N$ 个噪声项 $\\varepsilon_i$。\n    - 计算合成的观测影响 $I_{i,\\text{obs}} = a\\,Q_i^b \\exp(\\varepsilon_i)$。\n$2$. **模型估计**：\n    -通过取自然对数来转换生成的数据：$y_i = \\log(I_{i,\\text{obs}})$ 和 $x_i = \\log(Q_i)$。\n    - 构建线性系统 $\\mathbf{y} = X\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$，其中 $\\mathbf{y}$ 是 $y_i$ 值的向量，$\\boldsymbol{\\beta} = [\\beta_0, \\beta_1]^T$，而 $X$ 是一个 $N \\times 2$ 的设计矩阵，其第一列全为1，第二列是 $x_i$ 值的向量。\n    - 使用数值最小二乘法求解器求解系数向量 $\\hat{\\boldsymbol{\\beta}}$。该向量的第二个元素 $\\hat{\\beta}_1$ 提供了估计值 $\\hat{b}$。\n该方法在统计学上基础扎实，且在计算上具有鲁棒性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Generates synthetic market impact data and estimates the power-law exponent 'b'\n    for a series of test cases using Ordinary Least Squares on a log-transformed model.\n    \"\"\"\n\n    # Test cases: (seed, a, b, tau, N, Q_min, Q_max)\n    # The parameters correspond to: random seed, scale parameter 'a', exponent 'b',\n    # noise standard deviation 'tau', number of samples 'N', minimum trade size 'Q_min',\n    # and maximum trade size 'Q_max'.\n    test_cases = [\n        # Case A (concave impact, low noise, wide size range)\n        (314159, 0.5, 0.6, 0.05, 2000, 100, 50000),\n        # Case B (near-linear impact, moderate range)\n        (271828, 1.2, 1.0, 0.05, 1500, 50, 20000),\n        # Case C (strongly concave, higher noise, very wide range)\n        (424242, 0.8, 0.3, 0.10, 3000, 10, 100000),\n        # Case D (moderately concave, heavier noise, fewer samples)\n        (8675309, 0.3, 0.9, 0.20, 800, 5, 5000),\n    ]\n\n    results = []\n\n    for seed, a, b, tau, N, Q_min, Q_max in test_cases:\n        # Step 1: Generate synthetic data.\n        # Initialize a random number generator with the specified seed for reproducibility.\n        rng = np.random.default_rng(seed)\n\n        # Generate N trade sizes Q from a log-uniform distribution on [Q_min, Q_max].\n        # This is done by drawing from a uniform distribution in log-space.\n        log_Q = rng.uniform(np.log(Q_min), np.log(Q_max), N)\n        Q = np.exp(log_Q)\n\n        # Generate N i.i.d. Gaussian noise terms.\n        epsilon = rng.normal(loc=0.0, scale=tau, size=N)\n\n        # Compute the observed impact I_obs = a * Q^b * exp(epsilon).\n        I_obs = a * (Q ** b) * np.exp(epsilon)\n\n        # Step 2: Transform the data to linearize the model.\n        # log(I_obs) = log(a) + b*log(Q) + epsilon\n        log_I_obs = np.log(I_obs)\n\n        # Step 3: Perform Ordinary Least Squares (OLS) regression.\n        # We model log_I_obs = beta_0 + beta_1 * log_Q, where beta_1 is our estimate for b.\n        y = log_I_obs\n        x = log_Q\n\n        # Construct the design matrix X for the linear system y = X * beta.\n        # The first column is for the intercept (beta_0), the second for the slope (beta_1).\n        X = np.vstack([np.ones(N), x]).T\n\n        # Solve for the coefficient vector beta = [beta_0, beta_1] using a\n        # standard and numerically stable least-squares solver.\n        # beta[0] will be the estimate for log(a), and beta[1] for b.\n        beta, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n        \n        b_estimate = beta[1]\n        results.append(b_estimate)\n        \n    # Final print statement in the exact required format.\n    # The output must be a single line: a list of comma-separated values\n    # enclosed in square brackets, with each value rounded to 6 decimal places.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n# Execute the main function.\nsolve()\n```"
        },
        {
            "introduction": "在我们对市场结构和动态的理解基础上，现在我们转向一个更具挑战性的规范性问题：一个交易代理（agent）应如何以最优方式进行交易？本练习采用强化学习，一种强大的人工智能范式，来赋予一个代理发现自身交易策略的能力。通过构建一个模拟的市场环境并定义其状态、行动和奖励，您将观察一个代理如何学会在激进交易（市价单）的即时性与被动交易（限价单）的成本优势之间做出权衡。",
            "id": "2408335",
            "problem": "构建一个完全指定的、离散时间的市场微观结构模拟，其中单个买方代理与一个程式化的限价订单簿进行交互。该环境是一个有限马尔可夫决策过程，代理在其中决定是否以及在何处下单，订单簿则通过外部事件演变。目标是模拟学习动态，以最大化执行的预期折扣效用，同时考虑等待成本。所要求的输出是代理在三个指定状态下学习到的贪婪动作，以及在学习到的贪婪策略下，针对几个参数集的估计平均折扣回报。本说明中的所有数学实体均采用LaTeX格式。\n\n环境定义如下。\n\n1. 时间、回合与折扣：\n- 时间是离散的，由 $t \\in \\{0,1,2,\\dots\\}$ 索引，每回合的最大时间范围为 $T_{\\max} \\in \\mathbb{N}$。\n- 每个回合从 $t = 0$ 开始，并在代理的买单首次执行时或在 $t = T_{\\max}$ 时终止，以先发生者为准。\n- 折扣因子为 $\\gamma \\in (0,1)$。\n- 回合回报是折扣总和 $G = \\sum_{t=0}^{\\tau} \\gamma^t r_t$，其中 $\\tau$ 是该时间范围内的终止时间。\n\n2. 订单簿状态与约束：\n- 状态是一个三元组 $s_t = (h_t,q_t,p_t)$，其中：\n  - $h_t \\in \\{0,1\\}$ 表示代理当前是否在最优买价处有未成交的限价买单（$h_t=1$）或没有（$h_t=0$）。\n  - $q_t \\in \\{0,1,2,3\\}$ 是在最优买价处除代理自身订单外的未成交订单总数，上限为$3$。\n  - $p_t \\in \\{0,1,2,3\\}$ 是在最优买价队列中排在代理订单之前的订单数量（代理的队列位置，以排在前面的订单数量计），上限为$3$。如果 $h_t=0$，根据定义 $p_t$ 设为$0$。\n- 每个回合的初始状态为 $s_0 = (0,q_0,0)$，其中 $q_0 \\in \\{0,1,2,3\\}$ 由测试用例指定。\n\n3. 动作：\n- 在每个决策时间 $t$，代理选择一个动作 $a_t \\in \\mathcal{A} = \\{0,1,2,3\\}$，其编码如下：\n  - 0：等待（不执行任何操作），\n  - 1：在当前最优买价处下达一个限价买单（仅在 $h_t=0$ 时有效；否则其效果等同于等待），\n  - 2：下达一个市价买单，该订单立即以最优卖价成交并终止回合，\n  - 3：取消现有的限价订单（仅在 $h_t=1$ 时有效；否则其效果等同于等待）。\n- 动作有效性：\n  - 如果 $h_t=1$ 且 $a_t=1$，则视为动作 $0$（等待）。\n  - 如果 $h_t=0$ 且 $a_t=3$，则视为动作 $0$（等待）。\n\n4. 价格、价差与奖励：\n- 设半价差为 $s/2$，其中 $s \\in \\{1,2,\\dots\\}$ 为指定值。将参考价值归一化为 $0$。\n- 如果代理执行市价买单（动作 $2$），则即时奖励为 $-s/2$，该回合在此步骤终止。\n- 如果代理的限价买单在代理位于买单队列首位（$p_t=0$）时与到达的市价卖单成交，则即时奖励为 $+s/2$，该回合在此步骤终止。\n- 如果回合中的某一步骤未终止（无成交），该步骤的奖励为等待成本 $-w$，其中 $w0$ 为指定值。\n- 如果回合在没有成交的情况下达到时间上限 $T_{\\max}$，则计算截至 $T_{\\max}-1$（含）的累计奖励；在 $T_{\\max}$ 时，除了已应用的每步等待成本外，没有额外的终止奖励或惩罚。\n\n5. 外部订单簿事件与单步内的状态转移：\n- 在代理未选择动作 $2$ 的每个非终止步骤中，会发生一个外部事件 $e_t$，该事件按以下概率独立抽取：\n  - 市价卖单到达，概率为 $p_{\\mathrm{ms}}$，\n  - 在最优买价处的限价买单到达，概率为 $p_{\\mathrm{lb}}$，\n  - 在最优买价处的取消订单，概率为 $p_{\\mathrm{cb}}$，\n  且满足 $p_{\\mathrm{ms}} + p_{\\mathrm{lb}} + p_{\\mathrm{cb}} = 1$。\n- 给定所选动作和事件的状态转移：\n  - 如果 $a_t = 1$ 且 $h_t=0$：代理在最优买价处提交一个限价买单。下一个状态具有 $h_{t}^{+}=1$，$p_{t}^{+} = \\min\\{q_t,3\\}$，以及 $q_{t}^{+} = q_t$。\n  - 如果 $a_t = 3$ 且 $h_t=1$：代理取消订单。下一个状态具有 $h_{t}^{+}=0$，$p_{t}^{+}=0$，以及 $q_{t}^{+}=q_t$。\n  - 如果在动作生效后 $a_t \\in \\{0,1,3\\}$（即回合未因动作而终止），则发生一个外部事件并如下更新 $(h,q,p)$：\n    - 如果事件是市价卖单：\n      - 如果 $h=1$ 且 $p=0$：代理立即执行；回合在此步骤终止，奖励为 $+s/2$，且此步骤没有等待成本。\n      - 否则：如果 $q0$，则 $q \\leftarrow q-1$；如果此外 $h=1$ 且 $p0$，则 $p \\leftarrow p-1$。\n    - 如果事件是在最优买价处的取消订单：\n      - 如果 $q0$，则 $q \\leftarrow q-1$。\n      - 如果 $h=1$ 且 $p0$，则 $p \\leftarrow p-1$；如果 $p=0$，则保持为 $0$。\n    - 如果事件是在最优买价处的限价买单到达：\n      - $q \\leftarrow \\min\\{q+1,3\\}$；如果 $h=1$，则 $p$ 保持不变。\n  - 如果事件未导致终止性执行，则每步奖励为 $-w$。\n  - 如果 $a_t=2$，回合立即终止，奖励为 $-s/2$，且该步骤不发生外部事件。\n- 所有更新都遵守上限 $q \\in \\{0,1,2,3\\}$ 和 $p \\in \\{0,1,2,3\\}$，并且当 $h=1$ 时，始终满足 $p \\le q$。\n\n6. 学习动态：\n- 代理维护一个状态-动作价值函数 $Q(s,a)$，在训练开始时对所有的 $(s,a)$ 将其初始化为 $0$。\n- 对于每个访问过的转移 $(s_t,a_t,r_t,s_{t+1})$，代理更新\n  $$Q(s_t,a_t) \\leftarrow (1-\\alpha) Q(s_t,a_t) + \\alpha \\left[r_t + \\gamma \\max_{a' \\in \\mathcal{A}} Q(s_{t+1},a')\\right],$$\n  其中 $\\alpha \\in (0,1]$ 是学习率。\n- 在训练期间，代理使用 $\\varepsilon$-贪婪规则选择动作，参数为 $\\varepsilon \\in [0,1)$：以概率 $\\varepsilon$ 从 $\\mathcal{A}$ 中均匀随机选择一个动作；否则选择在当前状态下最大化 $Q(s,a)$ 的动作。$\\arg\\max$ 中的平局通过选择最小的动作索引来确定性地打破。\n- 训练后，在任何状态 $s$ 下学习到的贪婪策略 $\\pi(s) \\in \\mathcal{A}$ 是最大化 $Q(s,a)$ 的最小索引动作。\n\n7. 随机性控制：\n- 所有外部事件都使用一个由每个测试用例中指定的整数种子初始化的伪随机数生成器进行抽样。为了可复现性，请使用此种子进行训练。对于训练后的评估，请使用增加 $1$ 后的种子重新为伪随机数生成器设定种子。\n\n8. 评估状态与指标：\n- 设学习到的贪婪动作在以下三个状态下进行评估：\n  - $s^{(1)} = (0,q_0,0)$,\n  - $s^{(2)} = (1,1,0)$,\n  - $s^{(3)} = (1,3,3)$.\n- 此外，通过从 $s_0=(0,q_0,0)$ 开始，使用 $\\varepsilon=0$、折扣因子 $\\gamma$ 和时间上限 $T_{\\max}$，模拟 $N_{\\mathrm{eval}}$ 个独立的回合，来估计学习到的贪婪策略的平均折扣回报，并使用训练后的伪随机数种子。回合回报的样本均值必须报告为一个四舍五入到四位小数的浮点数。\n\n测试套件。对于下方的每个测试用例，参数以有序元组的形式给出\n$(s, w, \\gamma, \\alpha, \\varepsilon, T_{\\max}, E, N_{\\mathrm{eval}}, q_0, p_{\\mathrm{ms}}, p_{\\mathrm{lb}}, p_{\\mathrm{cb}}, \\text{seed})$，其含义如上文所定义。所有数字都明确给出：\n\n- 情况 A（一般情况）：\n  - $(2,\\, 0.02,\\, 0.95,\\, 0.20,\\, 0.10,\\, 50,\\, 4000,\\, 2000,\\, 2,\\, 0.50,\\, 0.30,\\, 0.20,\\, 7)$。\n- 情况 B（快速执行环境）：\n  - $(2,\\, 0.02,\\, 0.95,\\, 0.20,\\, 0.10,\\, 50,\\, 3000,\\, 2000,\\, 2,\\, 0.80,\\, 0.10,\\, 0.10,\\, 11)$。\n- 情况 C（高等待成本环境）：\n  - $(2,\\, 0.20,\\, 0.95,\\, 0.20,\\, 0.10,\\, 50,\\, 4000,\\, 2000,\\, 3,\\, 0.20,\\, 0.50,\\, 0.30,\\, 13)$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。对于每个测试用例，输出一个包含四个元素的列表，其中包含：\n- 在 $s^{(1)}$ 处学习到的贪婪动作，为 $\\{0,1,2,3\\}$ 中的整数，\n- 在 $s^{(2)}$ 处学习到的贪婪动作，为 $\\{0,1,2,3\\}$ 中的整数，\n- 在 $s^{(3)}$ 处学习到的贪婪动作，为 $\\{0,1,2,3\\}$ 中的整数，\n- 在学习到的贪婪策略下估计的平均折扣回报（四舍五入到四位小数）。\n\n因此，最终输出必须是以下形式：\n$[[a^{(1)}_A,a^{(2)}_A,a^{(3)}_A,\\bar{G}_A],[a^{(1)}_B,a^{(2)}_B,a^{(3)}_B,\\bar{G}_B],[a^{(1)}_C,a^{(2)}_C,a^{(3)}_C,\\bar{G}_C]]$，其中下标分别指代情况A、B和C。不应打印任何额外文本。",
            "solution": "用户提供了一个问题陈述，要求构建一个离散时间的市场微观结构模拟。该模拟涉及单个代理在一个程式化的限价订单簿环境中学习交易，该环境被建模为一个有限马尔可夫决策过程（MDP）。代理的目标是通过选择下单、取消或执行订单的最优动作来最大化执行的预期折扣效用。该问题定义明确、科学上合理且计算上可行。它属于计算经济学和金融学领域，特别是金融市场中的基于代理的建模和强化学习。所有参数、动态和评估指标都以足够的数学严谨性进行了规定，从而能够得到唯一的、可复现的解。因此，该问题被认为是有效的。\n\n解决方案将通过实现Q学习算法来为代理找到一个最优策略。实现将遵循以下步骤：\n\n1.  **状态和动作空间定义**：环境的状态是一个元组 $s_t = (h_t, q_t, p_t)$，其中 $h_t \\in \\{0, 1\\}$ 表示代理是否有活动限价单，$q_t \\in \\{0, 1, 2, 3\\}$ 是最优买价处的其他订单数量，而 $p_t \\in \\{0, 1, 2, 3\\}$ 是代理的队列位置。根据定义，如果 $h_t=0$ 则 $p_t=0$，如果 $h_t=1$ 则 $p_t \\le q_t$。这个有限状态空间包含 $14$ 个有效的非终止状态。将创建一个映射，为每个状态元组分配一个唯一的整数索引，以高效实现Q表。动作空间是 $\\mathcal{A} = \\{0, 1, 2, 3\\}$，分别代表等待、下限价单、下市价单和取消订单。\n\n2.  **环境动态模拟**：将实现一个函数来模拟MDP的一个步骤。此函数给定状态 $s_t$ 和动作 $a_t$，将计算即时奖励 $r_t$ 和下一个状态 $s_{t+1}$。其逻辑严格遵守问题规范：\n    *   **动作处理**：无效的动作（例如，已存在订单时再下单）被视为等待。市价单（动作 $2$）导致回合立即终止，奖励为 $r_t = -s/2$。\n    *   **状态转移**：对于非终止性动作，状态首先根据代理的动作（下达或取消订单）进行更新。然后，对一个外部事件进行抽样——市价卖单（$p_{\\mathrm{ms}}$）、限价买单（$p_{\\mathrm{lb}}$）或取消订单（$p_{\\mathrm{cb}}$）。\n    *   **执行与奖励**：如果当代理处于队列首位（$h_t=1, p_t=0$）时有市价卖单到达，则回合终止，奖励为 $r_t = +s/2$。任何非终止步骤都会产生等待成本，奖励为 $r_t = -w$。\n    *   **状态更新**：如果回合未终止，状态变量 $(h_t, q_t, p_t)$ 会根据外部事件进行更新，并遵守指定的上限和约束。\n\n3.  **Q学习实现**：代理的学习过程使用Q学习进行建模。一个Q表 $Q(s, a)$ 被初始化为零，并存储在状态 $s$ 下采取动作 $a$ 的估计价值。\n    *   **训练循环**：代理与环境交互指定的 $E$ 个回合。每个回合最多运行 $T_{\\max}$ 步。\n    *   **动作选择**：在训练期间，使用 $\\varepsilon$-贪婪策略选择动作。以概率 $\\varepsilon$ 选择一个随机动作以确保探索；否则，选择具有最高Q值的动作，$a = \\arg\\max_{a'} Q(s_t, a')$（利用）。平局通过选择最小的动作索引来打破。\n    *   **Q值更新**：在每次转移 $(s_t, a_t, r_t, s_{t+1})$ 之后，使用贝尔曼方程更新Q表：\n        $$Q(s_t, a_t) \\leftarrow (1-\\alpha) Q(s_t, a_t) + \\alpha \\left[r_t + \\gamma \\max_{a' \\in \\mathcal{A}} Q(s_{t+1}, a')\\right]$$\n        这里，$\\alpha$ 是学习率，$\\gamma$ 是折扣因子。如果 $s_{t+1}$ 是终止状态，则 $\\gamma \\max_{a' \\in \\mathcal{A}} Q(s_{t+1}, a')$ 项为零。\n\n4.  **策略评估**：训练完成后，对学习到的知识进行评估。\n    *   **贪婪策略**：从最终的Q表中提取一个确定性的贪婪策略 $\\pi(s)$：$\\pi(s) = \\arg\\max_{a' \\in \\mathcal{A}} Q(s, a')$，使用相同的平局打破规则。然后确定代理在三个指定状态下的学习动作：$s^{(1)} = (0, q_0, 0)$，$s^{(2)} = (1, 1, 0)$ 和 $s^{(3)} = (1, 3, 3)$。\n    *   **性能估计**：为了估计学习策略的性能，模拟 $N_{\\mathrm{eval}}$ 个新的回合。对于这些评估回合，代理严格遵循贪婪策略（$\\varepsilon=0$），并按规定重新设定随机数生成器的种子。计算每个回合的总折扣回报 $G = \\sum_{t=0}^{\\tau} \\gamma^t r_t$。最终的指标是这些回报的样本均值，四舍五入到四位小数。\n\n整个过程封装在一个Python脚本中。所有随机性都通过一个带种子的伪随机数生成器来控制，以确保可复现性。该脚本将针对三个测试用例中的每一个执行，结果将被格式化为问题陈述中指定的精确输出字符串。",
            "answer": "```python\nimport numpy as np\n\n# State-space mapping global variables\nSTATE_TO_IDX = {}\nIDX_TO_STATE = []\n\ndef build_state_space():\n    \"\"\"Builds the mapping between state tuples and integer indices.\"\"\"\n    if STATE_TO_IDX:\n        return\n    idx = 0\n    # States where the agent has no order (h=0)\n    for q in range(4):\n        state = (0, q, 0)\n        STATE_TO_IDX[state] = idx\n        IDX_TO_STATE.append(state)\n        idx += 1\n    # States where the agent has an order (h=1)\n    for q in range(4):\n        for p in range(q + 1):\n            state = (1, q, p)\n            STATE_TO_IDX[state] = idx\n            IDX_TO_STATE.append(state)\n            idx += 1\n\ndef step(state, action, rng, params):\n    \"\"\"\n    Simulates one step of the environment dynamics.\n    Returns (next_state, reward, done).\n    \"\"\"\n    s_val, w, gamma, _, _, T_max, _, _, q0, p_ms, p_lb, p_cb, _ = params\n    half_spread = s_val / 2.0\n    h, q, p = state\n\n    # Action validity checks\n    if h == 1 and action == 1:\n        action = 0  # Wait\n    if h == 0 and action == 3:\n        action = 0  # Wait\n\n    # Action 2: Market order\n    if action == 2:\n        return None, -half_spread, True\n\n    # Pre-event state update from agent's action\n    # For actions 0 (wait), 1 (limit), 3 (cancel)\n    \n    # Action 1: Place limit order\n    if action == 1:\n        if h == 0:\n            h = 1\n            p = q # Agent joins at the back of the queue of size q\n    # Action 3: Cancel limit order\n    elif action == 3:\n        if h == 1:\n            h = 0\n            p = 0\n\n    # Exogenous event simulation\n    # Check for immediate execution of limit order\n    event = rng.choice(['ms', 'lb', 'cb'], p=[p_ms, p_lb, p_cb])\n    \n    if event == 'ms':\n        if h == 1 and p == 0:\n            return None, half_spread, True  # Limit order execution\n        else:\n            if q > 0:\n                q -= 1\n                if h == 1 and p > 0:\n                    p -= 1\n    elif event == 'cb':\n        if q > 0:\n            q -= 1\n            if h == 1 and p > 0:\n                p -= 1\n    elif event == 'lb':\n        q = min(q + 1, 3)\n\n    return (h, q, p), -w, False\n\ndef run_case(params):\n    \"\"\"Runs the full simulation for one set of parameters.\"\"\"\n    s_val, w, gamma, alpha, epsilon, T_max, E, N_eval, q_0, p_ms, p_lb, p_cb, seed = params\n    \n    # Initialize Q-table and RNG for training\n    q_table = np.zeros((len(IDX_TO_STATE), 4))\n    rng = np.random.default_rng(seed)\n\n    # Q-learning training\n    for _ in range(E):\n        state = (0, q_0, 0)\n        \n        for t in range(T_max):\n            state_idx = STATE_TO_IDX[state]\n\n            # Epsilon-greedy action selection\n            if rng.random()  epsilon:\n                action = rng.integers(0, 4)\n            else:\n                action = np.argmax(q_table[state_idx, :])\n\n            next_state, reward, done = step(state, action, rng, params)\n\n            # Q-table update\n            if done:\n                target = reward\n                q_table[state_idx, action] = (1 - alpha) * q_table[state_idx, action] + alpha * target\n                break\n            else:\n                next_state_idx = STATE_TO_IDX[next_state]\n                max_next_q = np.max(q_table[next_state_idx, :])\n                target = reward + gamma * max_next_q\n                q_table[state_idx, action] = (1 - alpha) * q_table[state_idx, action] + alpha * target\n                state = next_state\n\n    # Evaluation phase\n    # 1. Get greedy actions for specified states\n    s1 = (0, q_0, 0)\n    s2 = (1, 1, 0)\n    s3 = (1, 3, 3)\n    \n    # Check if a state is valid before trying to get its index.\n    # (1,1,0) can be invalid if q_0 is 0. But for all test cases, q_0 >= 2\n    # (1,3,3) is always valid in the defined state space.\n    action_s1 = np.argmax(q_table[STATE_TO_IDX[s1], :])\n    action_s2 = np.argmax(q_table[STATE_TO_IDX[s2], :])\n    action_s3 = np.argmax(q_table[STATE_TO_IDX[s3], :])\n\n    # 2. Estimate average discounted return\n    eval_rng = np.random.default_rng(seed + 1)\n    episode_returns = []\n    \n    for _ in range(N_eval):\n        state = (0, q_0, 0)\n        discounted_return = 0.0\n        \n        for t in range(T_max):\n            state_idx = STATE_TO_IDX[state]\n            action = np.argmax(q_table[state_idx, :]) # Greedy policy\n            \n            next_state, reward, done = step(state, action, eval_rng, params)\n            \n            discounted_return += (gamma ** t) * reward\n            \n            if done:\n                break\n            \n            state = next_state\n        \n        episode_returns.append(discounted_return)\n\n    avg_return = np.mean(episode_returns)\n\n    return [int(action_s1), int(action_s2), int(action_s3), avg_return]\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    # Build the state space mappings\n    build_state_space()\n\n    # Test case parameters:\n    # (s, w, gamma, alpha, epsilon, T_max, E, N_eval, q_0, p_ms, p_lb, p_cb, seed)\n    test_cases = [\n        (2, 0.02, 0.95, 0.20, 0.10, 50, 4000, 2000, 2, 0.50, 0.30, 0.20, 7),\n        (2, 0.02, 0.95, 0.20, 0.10, 50, 3000, 2000, 2, 0.80, 0.10, 0.10, 11),\n        (2, 0.20, 0.95, 0.20, 0.10, 50, 4000, 2000, 3, 0.20, 0.50, 0.30, 13),\n    ]\n\n    all_results = []\n    for params in test_cases:\n        result = run_case(params)\n        all_results.append(result)\n\n    # Format the final output string\n    # e.g., [[1,0,3,-0.1234],[...],[...]]\n    outer_parts = []\n    for res in all_results:\n        a1, a2, a3, G_avg = res\n        # Format the average return to 4 decimal places\n        inner_str = f\"[{a1},{a2},{a3},{G_avg:.4f}]\"\n        outer_parts.append(inner_str)\n    \n    final_output = f\"[{','.join(outer_parts)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}