{
    "hands_on_practices": [
        {
            "introduction": "The first step in mastering multidimensional optimization is applying the core principles of calculus to a tangible problem. This exercise puts you in the role of a firm's decision-maker, tasked with allocating an advertising budget across different digital platforms to maximize profit . By working through this scenario, which uses a common logarithmic response model, you will practice using first-order conditions to find the optimal spending levels and translating abstract mathematical tools into concrete business strategy.",
            "id": "2445369",
            "problem": "A firm allocates advertising expenditures across three digital platforms: Google, Facebook, and Twitter. Let the expenditures be $x_G$, $x_F$, and $x_T$, each measured in dollars. The firm’s sales quantity function is given by\n$$\nQ(x_G, x_F, x_T) = d + \\beta_G \\ln\\!\\big(1 + \\alpha_G x_G\\big) + \\beta_F \\ln\\!\\big(1 + \\alpha_F x_F\\big) + \\beta_T \\ln\\!\\big(1 + \\alpha_T x_T\\big),\n$$\ndefined on the domain $x_G  -1/\\alpha_G$, $x_F  -1/\\alpha_F$, and $x_T  -1/\\alpha_T$ so that the logarithms are well-defined. The firm earns a constant per-unit margin $m$ dollars on each unit sold and incurs the advertising outlays as costs. The firm’s profit function is\n$$\n\\pi(x_G, x_F, x_T) = m \\, Q(x_G, x_F, x_T) - \\big(x_G + x_F + x_T\\big).\n$$\nAssume the parameters are $d = 2000$, $m = 50$, $\\beta_G = 100$, $\\beta_F = 120$, $\\beta_T = 80$, $\\alpha_G = 0.002$, $\\alpha_F = 0.0015$, and $\\alpha_T = 0.001$. Find the unique unconstrained global maximizer $\\big(x_G^{\\ast}, x_F^{\\ast}, x_T^{\\ast}\\big)$ of $\\pi(x_G, x_F, x_T)$ over its domain. Express your answer as exact values. Do not include units in your final answer.",
            "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Variables for advertising expenditures: $x_G$, $x_F$, $x_T$.\n- Sales quantity function: $Q(x_G, x_F, x_T) = d + \\beta_G \\ln(1 + \\alpha_G x_G) + \\beta_F \\ln(1 + \\alpha_F x_F) + \\beta_T \\ln(1 + \\alpha_T x_T)$.\n- Domain of definition: $x_G  -1/\\alpha_G$, $x_F  -1/\\alpha_F$, $x_T  -1/\\alpha_T$.\n- Profit function: $\\pi(x_G, x_F, x_T) = m \\, Q(x_G, x_F, x_T) - (x_G + x_F + x_T)$.\n- Parameters: $d = 2000$, $m = 50$, $\\beta_G = 100$, $\\beta_F = 120$, $\\beta_T = 80$, $\\alpha_G = 0.002$, $\\alpha_F = 0.0015$, $\\alpha_T = 0.001$.\n- Objective: Find the unique unconstrained global maximizer $(x_G^{\\ast}, x_F^{\\ast}, x_T^{\\ast})$ of the profit function.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem employs a logarithmic response model for advertising, a standard and empirically supported formulation in economics and marketing science. The profit function is correctly specified as total revenue (margin times quantity) minus total cost. The problem is scientifically grounded.\n- **Well-Posed**: The problem asks for the global maximizer of a function. Existence and uniqueness must be verified. The profit function is twice-differentiable on its domain. The analysis of its Hessian matrix will determine concavity. The Hessian of $\\pi$ is a diagonal matrix, because the advertising effects are separable. The diagonal elements are $\\frac{\\partial^2 \\pi}{\\partial x_i^2} = -m \\frac{\\beta_i \\alpha_i^2}{(1+\\alpha_i x_i)^2}$ for $i \\in \\{G, F, T\\}$. Since all parameters $m, \\beta_i, \\alpha_i$ are positive and the domain ensures $1+\\alpha_i x_i  0$, all diagonal entries of the Hessian are strictly negative. A diagonal matrix with strictly negative entries is negative definite. A function with a negative definite Hessian over a convex domain is strictly concave. A critical point of a strictly concave function is a unique global maximum. The problem is therefore well-posed.\n- **Objective and Self-Contained**: The problem is stated with clear, unambiguous language. All necessary parameters and functional forms are provided. It is self-contained and objective.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A solution will be derived.\n\nThe objective is to find the values of $x_G$, $x_F$, and $x_T$ that maximize the profit function $\\pi(x_G, x_F, x_T)$. The profit function is given by:\n$$\n\\pi(x_G, x_F, x_T) = m \\left( d + \\beta_G \\ln(1 + \\alpha_G x_G) + \\beta_F \\ln(1 + \\alpha_F x_F) + \\beta_T \\ln(1 + \\alpha_T x_T) \\right) - (x_G + x_F + x_T)\n$$\nTo find the unconstrained extremum of this function, we must apply the first-order necessary condition, which states that the gradient of the function must be the zero vector at the critical point $(x_G^{\\ast}, x_F^{\\ast}, x_T^{\\ast})$. That is, $\\nabla \\pi(x_G^{\\ast}, x_F^{\\ast}, x_T^{\\ast}) = \\mathbf{0}$. We compute the partial derivatives of $\\pi$ with respect to each variable:\n$$\n\\frac{\\partial \\pi}{\\partial x_G} = m \\frac{\\beta_G \\alpha_G}{1 + \\alpha_G x_G} - 1\n$$\n$$\n\\frac{\\partial \\pi}{\\partial x_F} = m \\frac{\\beta_F \\alpha_F}{1 + \\alpha_F x_F} - 1\n$$\n$$\n\\frac{\\partial \\pi}{\\partial x_T} = m \\frac{\\beta_T \\alpha_T}{1 + \\alpha_T x_T} - 1\n$$\nSetting these partial derivatives to zero, we obtain a system of three independent equations:\n$$\nm \\frac{\\beta_G \\alpha_G}{1 + \\alpha_G x_G^{\\ast}} - 1 = 0 \\implies 1 + \\alpha_G x_G^{\\ast} = m \\beta_G \\alpha_G \\implies x_G^{\\ast} = \\frac{m \\beta_G \\alpha_G - 1}{\\alpha_G}\n$$\n$$\nm \\frac{\\beta_F \\alpha_F}{1 + \\alpha_F x_F^{\\ast}} - 1 = 0 \\implies 1 + \\alpha_F x_F^{\\ast} = m \\beta_F \\alpha_F \\implies x_F^{\\ast} = \\frac{m \\beta_F \\alpha_F - 1}{\\alpha_F}\n$$\n$$\nm \\frac{\\beta_T \\alpha_T}{1 + \\alpha_T x_T^{\\ast}} - 1 = 0 \\implies 1 + \\alpha_T x_T^{\\ast} = m \\beta_T \\alpha_T \\implies x_T^{\\ast} = \\frac{m \\beta_T \\alpha_T - 1}{\\alpha_T}\n$$\nThis provides the unique critical point. To confirm this is a global maximum, we examine the second-order sufficient condition. We compute the Hessian matrix $H$ of the function $\\pi$. The second-order partial derivatives are:\n$$\n\\frac{\\partial^2 \\pi}{\\partial x_G^2} = -m \\frac{\\beta_G \\alpha_G^2}{(1 + \\alpha_G x_G)^2}\n$$\n$$\n\\frac{\\partial^2 \\pi}{\\partial x_F^2} = -m \\frac{\\beta_F \\alpha_F^2}{(1 + \\alpha_F x_F)^2}\n$$\n$$\n\\frac{\\partial^2 \\pi}{\\partial x_T^2} = -m \\frac{\\beta_T \\alpha_T^2}{(1 + \\alpha_T x_T)^2}\n$$\nAll mixed partial derivatives are zero, for example, $\\frac{\\partial^2 \\pi}{\\partial x_G \\partial x_F} = 0$. Thus, the Hessian matrix is a diagonal matrix:\n$$\nH = \\begin{pmatrix}\n-m \\frac{\\beta_G \\alpha_G^2}{(1 + \\alpha_G x_G)^2}  0  0 \\\\\n0  -m \\frac{\\beta_F \\alpha_F^2}{(1 + \\alpha_F x_F)^2}  0 \\\\\n0  0  -m \\frac{\\beta_T \\alpha_T^2}{(1 + \\alpha_T x_T)^2}\n\\end{pmatrix}\n$$\nGiven that all parameters ($m, \\beta_i, \\alpha_i$) are positive, and the domain of the function ensures that $1 + \\alpha_i x_i  0$, the squared term $(1 + \\alpha_i x_i)^2$ is always positive. Consequently, all three diagonal elements of the Hessian matrix are strictly negative for all points $(x_G, x_F, x_T)$ in the domain. A matrix with such properties is negative definite.\nA function whose Hessian is negative definite over its entire convex domain is strictly concave. Any critical point of a strictly concave function is its unique global maximum. Therefore, the critical point we found, $(x_G^{\\ast}, x_F^{\\ast}, x_T^{\\ast})$, is the unique global maximizer of the profit function $\\pi$.\n\nNow we substitute the provided numerical values into the expressions for $x_G^{\\ast}$, $x_F^{\\ast}$, and $x_T^{\\ast}$.\nThe parameters are: $m = 50$, $\\beta_G = 100$, $\\alpha_G = 0.002$, $\\beta_F = 120$, $\\alpha_F = 0.0015$, $\\beta_T = 80$, $\\alpha_T = 0.001$.\n\nFor $x_G^{\\ast}$:\n$$\nx_G^{\\ast} = \\frac{50 \\times 100 \\times 0.002 - 1}{0.002} = \\frac{10 - 1}{0.002} = \\frac{9}{0.002} = 4500\n$$\n\nFor $x_F^{\\ast}$:\n$$\nx_F^{\\ast} = \\frac{50 \\times 120 \\times 0.0015 - 1}{0.0015} = \\frac{9 - 1}{0.0015} = \\frac{8}{0.0015} = \\frac{8}{15/10000} = \\frac{80000}{15} = \\frac{16000}{3}\n$$\n\nFor $x_T^{\\ast}$:\n$$\nx_T^{\\ast} = \\frac{50 \\times 80 \\times 0.001 - 1}{0.001} = \\frac{4 - 1}{0.001} = \\frac{3}{0.001} = 3000\n$$\n\nThe optimal advertising expenditures are $(x_G^{\\ast}, x_F^{\\ast}, x_T^{\\ast}) = \\left(4500, \\frac{16000}{3}, 3000\\right)$. These values are positive and lie within the domain of the function, confirming a valid economic solution.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 4500  \\frac{16000}{3}  3000 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Beyond finding specific numerical answers, a deeper understanding comes from deriving general solutions that reveal the structure of an economic model. This practice explores the optimal strategy for a job seeker by maximizing a quadratic approximation of expected salary, a common modeling technique . Your task is to solve for the optimal efforts symbolically, which provides a powerful formula demonstrating how the solution depends on the underlying parameters of the model and reinforces your understanding of quadratic forms.",
            "id": "2445351",
            "problem": "A job seeker considers two application channels during a single week: a formal channel and an informal channel. Let $n_F$ denote the intensity of applications sent through the formal channel and $n_I$ denote the intensity of applications sent through the informal channel. Interpreting intensities as continuous proxies for application counts over a short horizon, and under independent and small-arrival-probability conditions, the weekly expected salary of the secured job can be approximated by a second-order expansion in $(n_F,n_I)$:\n$$\n\\mathbb{E}[S(n_F,n_I)] \\;=\\; \\beta_0 \\;+\\; \\beta_F \\, n_F \\;+\\; \\beta_I \\, n_I \\;-\\; \\frac{1}{2}\\Big( a_F \\, n_F^{2} \\;+\\; 2 a_{FI} \\, n_F n_I \\;+\\; a_I \\, n_I^{2} \\Big),\n$$\nwhere $\\beta_0$, $\\beta_F$, $\\beta_I$, $a_F$, $a_{FI}$, and $a_I$ are parameters. Assume $a_F  0$, $a_I  0$, and $a_F a_I - a_{FI}^{2}  0$, and that $\\beta_F  0$ and $\\beta_I  0$. These conditions ensure the approximation is strictly concave in $(n_F,n_I)$ and delivers a unique interior maximizer.\n\nDetermine the unconstrained optimizer $(n_F^{\\star}, n_I^{\\star})$ that maximizes $\\mathbb{E}[S(n_F,n_I)]$ with respect to $n_F$ and $n_I$. Express your final answer as a single closed-form analytic expression. No rounding is required.",
            "solution": "The problem requires finding the unconstrained optimizer for the expected weekly salary function, which is a quadratic function of two variables: application intensity through a formal channel, $n_F$, and an informal channel, $n_I$.\n\nFirst, a validation of the problem statement is in order.\n\nStep 1: Extract Givens.\nThe objective function to be maximized is:\n$$\n\\mathbb{E}[S(n_F,n_I)] = \\beta_0 + \\beta_F n_F + \\beta_I n_I - \\frac{1}{2}\\Big( a_F n_F^{2} + 2 a_{FI} n_F n_I + a_I n_I^{2} \\Big)\n$$\nThe variables of optimization are $n_F$ and $n_I$.\nThe parameters are $\\beta_0$, $\\beta_F$, $\\beta_I$, $a_F$, $a_{FI}$, and $a_I$.\nThe following conditions are given:\n$a_F  0$\n$a_I  0$\n$a_F a_I - a_{FI}^{2}  0$\n$\\beta_F  0$\n$\\beta_I  0$\n\nStep 2: Validate Using Extracted Givens.\nThe problem is scientifically and mathematically sound. It presents a standard unconstrained optimization problem for a quadratic function. The function represents a second-order Taylor approximation, a common and valid technique in many scientific fields, including computational economics. The problem is well-posed; the given conditions on the parameters $a_F$, $a_I$, and $a_{FI}$ are precisely the conditions required for the Hessian matrix of the quadratic part to be positive definite, which in turn makes the objective function strictly concave, guaranteeing a unique global maximum. The problem is stated objectively with precisely defined mathematical terms and constraints. It is self-contained and does not violate any fundamental principles.\n\nStep 3: Verdict and Action.\nThe problem is valid. A solution will be derived.\n\nLet the objective function be denoted by $J(n_F, n_I)$. To find the unconstrained maximum, we must apply the first-order necessary condition, which states that the gradient of the function must be the zero vector at the optimal point $(n_F^{\\star}, n_I^{\\star})$.\nThe gradient of $J(n_F, n_I)$ is the vector of its partial derivatives: $\\nabla J = \\begin{pmatrix} \\frac{\\partial J}{\\partial n_F}  \\frac{\\partial J}{\\partial n_I} \\end{pmatrix}^T$.\n\nWe calculate the partial derivatives:\n$$\n\\frac{\\partial J}{\\partial n_F} = \\frac{\\partial}{\\partial n_F} \\left( \\beta_0 + \\beta_F n_F + \\beta_I n_I - \\frac{1}{2} a_F n_F^{2} - a_{FI} n_F n_I - \\frac{1}{2} a_I n_I^{2} \\right) = \\beta_F - a_F n_F - a_{FI} n_I\n$$\n$$\n\\frac{\\partial J}{\\partial n_I} = \\frac{\\partial}{\\partial n_I} \\left( \\beta_0 + \\beta_F n_F + \\beta_I n_I - \\frac{1}{2} a_F n_F^{2} - a_{FI} n_F n_I - \\frac{1}{2} a_I n_I^{2} \\right) = \\beta_I - a_{FI} n_F - a_I n_I\n$$\n\nSetting these partial derivatives to zero yields a system of two linear equations for the two unknowns, $n_F$ and $n_I$:\n$$\na_F n_F + a_{FI} n_I = \\beta_F\n$$\n$$\na_{FI} n_F + a_I n_I = \\beta_I\n$$\n\nThis system can be expressed in matrix form as:\n$$\n\\begin{pmatrix} a_F  a_{FI} \\\\ a_{FI}  a_I \\end{pmatrix} \\begin{pmatrix} n_F \\\\ n_I \\end{pmatrix} = \\begin{pmatrix} \\beta_F \\\\ \\beta_I \\end{pmatrix}\n$$\n\nThe second-order sufficient condition for a maximum requires that the Hessian matrix of second partial derivatives, $H$, be negative definite at the critical point. Let us compute the Hessian:\n$$\nH = \\begin{pmatrix} \\frac{\\partial^2 J}{\\partial n_F^2}  \\frac{\\partial^2 J}{\\partial n_F \\partial n_I} \\\\ \\frac{\\partial^2 J}{\\partial n_I \\partial n_F}  \\frac{\\partial^2 J}{\\partial n_I^2} \\end{pmatrix} = \\begin{pmatrix} -a_F  -a_{FI} \\\\ -a_{FI}  -a_I \\end{pmatrix}\n$$\nA matrix is negative definite if its leading principal minors alternate in sign, starting with a negative sign.\nThe first principal minor is $H_1 = -a_F$. Since the problem states $a_F  0$, we have $H_1  0$.\nThe second principal minor is the determinant of $H$:\n$$\n\\det(H) = (-a_F)(-a_I) - (-a_{FI})^2 = a_F a_I - a_{FI}^2\n$$\nThe problem states $a_F a_I - a_{FI}^2  0$.\nSince the leading principal minors alternate in sign as required ($-, +$), the Hessian matrix is negative definite. This confirms that the solution to the first-order conditions corresponds to a strict local maximum. Because the function is globally concave, this is the unique global maximum.\n\nTo solve the system of linear equations for $(n_F^{\\star}, n_I^{\\star})$, we can use matrix inversion. Let the coefficient matrix be $A = \\begin{pmatrix} a_F  a_{FI} \\\\ a_{FI}  a_I \\end{pmatrix}$. The determinant is $\\det(A) = a_F a_I - a_{FI}^2$, which is given to be positive. The inverse of $A$ is:\n$$\nA^{-1} = \\frac{1}{a_F a_I - a_{FI}^2} \\begin{pmatrix} a_I  -a_{FI} \\\\ -a_{FI}  a_F \\end{pmatrix}\n$$\nThe solution vector is then found by pre-multiplying the constant vector by $A^{-1}$:\n$$\n\\begin{pmatrix} n_F^{\\star} \\\\ n_I^{\\star} \\end{pmatrix} = A^{-1} \\begin{pmatrix} \\beta_F \\\\ \\beta_I \\end{pmatrix} = \\frac{1}{a_F a_I - a_{FI}^2} \\begin{pmatrix} a_I  -a_{FI} \\\\ -a_{FI}  a_F \\end{pmatrix} \\begin{pmatrix} \\beta_F \\\\ \\beta_I \\end{pmatrix}\n$$\nPerforming the matrix-vector multiplication gives the expressions for the optimal intensities:\n$$\n\\begin{pmatrix} n_F^{\\star} \\\\ n_I^{\\star} \\end{pmatrix} = \\frac{1}{a_F a_I - a_{FI}^2} \\begin{pmatrix} a_I \\beta_F - a_{FI} \\beta_I \\\\ a_F \\beta_I - a_{FI} \\beta_F \\end{pmatrix}\n$$\nThus, the components of the optimizer are:\n$$\nn_F^{\\star} = \\frac{a_I \\beta_F - a_{FI} \\beta_I}{a_F a_I - a_{FI}^2}\n$$\n$$\nn_I^{\\star} = \\frac{a_F \\beta_I - a_{FI} \\beta_F}{a_F a_I - a_{FI}^2}\n$$\nThese expressions represent the unique optimal application intensities that maximize the expected salary.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{a_I \\beta_F - a_{FI} \\beta_I}{a_F a_I - a_{FI}^{2}}  \\frac{a_F \\beta_I - a_{FI} \\beta_F}{a_F a_I - a_{FI}^{2}} \\end{pmatrix}}$$"
        },
        {
            "introduction": "While analytical solutions are elegant, many real-world optimization problems are too complex to be solved by hand, which is where computational algorithms become essential. In this capstone practice, you will implement the gradient descent algorithm with a backtracking line search, a cornerstone of modern numerical optimization . By applying your code to diverse test cases from finance and econometrics, you will gain hands-on experience with the power and practical challenges of iterative methods, a core skill set for any computational economist.",
            "id": "2445371",
            "problem": "You are given smooth objective functions in multiple dimensions that arise in computational economics and finance. For each specified test case, construct an iterative unconstrained minimization method that generates a sequence $\\{\\mathbf{x}_k\\}_{k \\ge 0}$ according to $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{d}_k$ with descent direction $\\mathbf{d}_k = -\\nabla f(\\mathbf{x}_k)$. At each iteration $k$, the step length $\\alpha_k$ must be chosen from the geometric sequence $\\{\\alpha_0 \\rho^m: m \\in \\{0,1,2,\\dots\\}\\}$, with $\\alpha_0 \\in (0,\\infty)$ and $\\rho \\in (0,1)$ fixed and common to all test cases, to satisfy the Armijo sufficient decrease condition:\n$$\nf(\\mathbf{x}_k + \\alpha_k \\mathbf{d}_k) \\le f(\\mathbf{x}_k) + c\\,\\alpha_k \\nabla f(\\mathbf{x}_k)^\\top \\mathbf{d}_k,\n$$\nwith a fixed constant $c \\in (0,1)$ common to all test cases. Initialize from the given starting point, and terminate when $\\|\\nabla f(\\mathbf{x}_k)\\|_2 \\le \\varepsilon$ or when $k$ reaches a specified maximum number of iterations. All computations are over the real numbers. Angles are not used. No physical units are involved.\n\nUse the following fixed parameters for all test cases: $\\alpha_0 = 1$, $\\rho = \\tfrac{1}{2}$, $c = 10^{-4}$, $\\varepsilon = 10^{-8}$, and $\\text{max\\_iter} = 10000$.\n\nTest Suite (all matrices and vectors are written explicitly):\n\n- Test case $1$ (mean-variance quadratic in finance):\n  - Decision variable $\\mathbf{w} \\in \\mathbb{R}^2$.\n  - Objective\n    $$\n    f_1(\\mathbf{w}) = \\tfrac{1}{2}\\,\\mathbf{w}^\\top \\boldsymbol{\\Sigma}\\,\\mathbf{w} - \\boldsymbol{\\mu}^\\top \\mathbf{w},\n    \\quad\n    \\boldsymbol{\\Sigma} =\n    \\begin{bmatrix}\n    2  0.8 \\\\\n    0.8  1.5\n    \\end{bmatrix},\n    \\quad\n    \\boldsymbol{\\mu} =\n    \\begin{bmatrix}\n    0.5 \\\\\n    0.3\n    \\end{bmatrix}.\n    $$\n  - Initial condition $\\mathbf{w}_0 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$.\n\n- Test case $2$ (ill-conditioned quadratic):\n  - Decision variable $\\mathbf{x} \\in \\mathbb{R}^2$.\n  - Objective\n    $\n    f_2(\\mathbf{x}) = \\tfrac{1}{2}\\,\\mathbf{x}^\\top \\mathbf{H}\\,\\mathbf{x} - \\mathbf{b}^\\top \\mathbf{x},\n    \\quad\n    \\mathbf{H} =\n    \\begin{bmatrix}\n    1000  0 \\\\\n    0  1\n    \\end{bmatrix},\n    \\quad\n    \\mathbf{b} =\n    \\begin{bmatrix}\n    1 \\\\\n    1\n    \\end{bmatrix}.\n    $\n  - Initial condition $\\mathbf{x}_0 = \\begin{bmatrix} 10 \\\\ 10 \\end{bmatrix}$.\n\n- Test case $3$ (negative log-likelihood for binary choice with logistic link, not linearly separable):\n  - Parameter vector $\\boldsymbol{\\theta} \\in \\mathbb{R}^2$.\n  - Data matrix\n    $\n    \\mathbf{X} =\n    \\begin{bmatrix}\n    1  -2 \\\\\n    1  -1 \\\\\n    1  1 \\\\\n    1  2\n    \\end{bmatrix},\n    $\n    label vector\n    $\n    \\mathbf{y} =\n    \\begin{bmatrix}\n    -1 \\\\\n    1 \\\\\n    -1 \\\\\n    1\n    \\end{bmatrix}.\n    $\n  - Objective\n    $$\n    f_3(\\boldsymbol{\\theta}) = \\sum_{i=1}^{4} \\log\\!\\big(1 + \\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})\\big),\n    $$\n    where $\\mathbf{x}_i^\\top$ is the $i$-th row of $\\mathbf{X}$ and $y_i$ is the $i$-th entry of $\\mathbf{y}$.\n  - Initial condition $\\boldsymbol{\\theta}_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$.\n\nFor each test case, run the iterative minimization with the common parameters above and report the minimized objective value $f(\\mathbf{x}^\\star)$ at termination. Your program must not read any input. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases, with each entry rounded to six decimal places, for example, $[0.123456,1.234567,2.345678]$.",
            "solution": "The problem statement has been rigorously evaluated and is determined to be valid. It presents a clear, mathematically sound, and well-posed set of tasks in the field of unconstrained optimization. The objective functions are standard examples from computational economics and finance, and all required parameters and initial conditions are provided without ambiguity or contradiction. The specified algorithm, gradient descent with a backtracking line search based on the Armijo condition, is a fundamental and appropriate method for solving such problems. We shall now proceed with the formal derivation and solution.\n\nThe core of the problem is to implement the method of steepest descent for minimizing a smooth function $f: \\mathbb{R}^n \\to \\mathbb{R}$. This is an iterative algorithm that generates a sequence of points $\\{\\mathbf{x}_k\\}_{k \\ge 0}$ using the update rule:\n$$\n\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{d}_k\n$$\nThe direction $\\mathbf{d}_k$ is chosen as the negative gradient of the objective function at the current iterate $\\mathbf{x}_k$, which is the direction of steepest descent:\n$$\n\\mathbf{d}_k = -\\nabla f(\\mathbf{x}_k)\n$$\nThe step length $\\alpha_k  0$ is determined by a backtracking line search procedure to ensure sufficient decrease in the objective function value. Starting with an initial guess $\\alpha = \\alpha_0$, the step length is successively reduced by a factor $\\rho \\in (0,1)$ until the Armijo condition is satisfied:\n$$\nf(\\mathbf{x}_k + \\alpha \\mathbf{d}_k) \\le f(\\mathbf{x}_k) + c\\,\\alpha \\nabla f(\\mathbf{x}_k)^\\top \\mathbf{d}_k\n$$\nwhere $c \\in (0,1)$ is a small constant. The given parameters are fixed for all test cases as $\\alpha_0 = 1$, $\\rho = \\frac{1}{2}$, and $c = 10^{-4}$.\n\nThe algorithm terminates and reports the current point $\\mathbf{x}_k$ as the approximate minimizer $\\mathbf{x}^\\star$ when the Euclidean norm of the gradient is below a specified tolerance $\\varepsilon = 10^{-8}$, or when the number of iterations $k$ reaches the maximum limit $\\text{max\\_iter} = 10000$.\n\nWe now apply this general procedure to the three specified test cases.\n\n**Test Case 1: Mean-Variance Quadratic**\nThe objective function is a standard quadratic form from portfolio optimization:\n$$\nf_1(\\mathbf{w}) = \\tfrac{1}{2}\\,\\mathbf{w}^\\top \\boldsymbol{\\Sigma}\\,\\mathbf{w} - \\boldsymbol{\\mu}^\\top \\mathbf{w}\n$$\nwhere $\\mathbf{w} \\in \\mathbb{R}^2$, $\\boldsymbol{\\Sigma} = \\begin{bmatrix} 2  0.8 \\\\ 0.8  1.5 \\end{bmatrix}$, and $\\boldsymbol{\\mu} = \\begin{bmatrix} 0.5 \\\\ 0.3 \\end{bmatrix}$. The gradient of a general quadratic function $f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^\\top \\mathbf{A} \\mathbf{x} - \\mathbf{b}^\\top \\mathbf{x}$ for a symmetric matrix $\\mathbf{A}$ is $\\nabla f(\\mathbf{x}) = \\mathbf{A}\\mathbf{x} - \\mathbf{b}$. Therefore, the gradient for $f_1$ is:\n$$\n\\nabla f_1(\\mathbf{w}) = \\boldsymbol{\\Sigma}\\,\\mathbf{w} - \\boldsymbol{\\mu}\n$$\nThe Hessian of $f_1$ is $\\nabla^2 f_1(\\mathbf{w}) = \\boldsymbol{\\Sigma}$. The matrix $\\boldsymbol{\\Sigma}$ is symmetric and its eigenvalues are approximately $2.55$ and $0.95$, which are both positive. Thus, $\\boldsymbol{\\Sigma}$ is positive definite, which implies that $f_1$ is strictly convex and possesses a unique global minimum. The steepest descent algorithm is guaranteed to converge to this minimum. The algorithm is initialized from $\\mathbf{w}_0 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$.\n\n**Test Case 2: Ill-Conditioned Quadratic**\nThe objective function is another quadratic:\n$$\nf_2(\\mathbf{x}) = \\tfrac{1}{2}\\,\\mathbf{x}^\\top \\mathbf{H}\\,\\mathbf{x} - \\mathbf{b}^\\top \\mathbf{x}\n$$\nwith $\\mathbf{x} \\in \\mathbb{R}^2$, $\\mathbf{H} = \\begin{bmatrix} 1000  0 \\\\ 0  1 \\end{bmatrix}$, and $\\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$. The gradient is:\n$$\n\\nabla f_2(\\mathbf{x}) = \\mathbf{H}\\,\\mathbf{x} - \\mathbf{b}\n$$\nThe Hessian matrix $\\mathbf{H}$ is positive definite, as its eigenvalues are $1000$ and $1$. Consequently, $f_2$ is strictly convex with a unique minimum. The condition number of $\\mathbf{H}$ is the ratio of its largest to smallest eigenvalue, which is $1000/1 = 1000$. This high condition number implies that the level sets of $f_2$ are highly elongated ellipses, which typically slows down the convergence of the steepest descent method. The algorithm starts from $\\mathbf{x}_0 = \\begin{bmatrix} 10 \\\\ 10 \\end{bmatrix}$.\n\n**Test Case 3: Negative Log-Likelihood for Binary Choice**\nThe objective function is the negative log-likelihood for a logistic regression model:\n$$\nf_3(\\boldsymbol{\\theta}) = \\sum_{i=1}^{4} \\log\\!\\big(1 + \\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})\\big)\n$$\nwhere $\\boldsymbol{\\theta} \\in \\mathbb{R}^2$. To find the gradient, we differentiate with respect to a component $\\theta_j$ of $\\boldsymbol{\\theta}$:\n$$\n\\frac{\\partial f_3}{\\partial \\theta_j} = \\sum_{i=1}^{4} \\frac{1}{1 + \\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})} \\cdot \\frac{\\partial}{\\partial \\theta_j} \\left(1 + \\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})\\right)\n$$\n$$\n= \\sum_{i=1}^{4} \\frac{\\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})}{1 + \\exp(-y_i\\,\\mathbf{x}_i^\\top \\boldsymbol{\\theta})} \\cdot (-y_i x_{ij})\n$$\nLet $\\sigma(z) = \\frac{1}{1+e^{-z}}$ be the logistic sigmoid function. The expression $\\frac{\\exp(-z)}{1+\\exp(-z)}$ can be rewritten as $\\frac{1}{e^z+1} = \\sigma(-z)$.\nThus, the gradient vector $\\nabla f_3(\\boldsymbol{\\theta})$ has components:\n$$\n[\\nabla f_3(\\boldsymbol{\\theta})]_j = \\sum_{i=1}^{4} \\sigma(-y_i \\mathbf{x}_i^\\top \\boldsymbol{\\theta}) (-y_i x_{ij})\n$$\nThis can be written compactly in vector form. Let $\\mathbf{p}$ be a vector with elements $p_i = \\sigma(y_i \\mathbf{x}_i^\\top \\boldsymbol{\\theta})$. Using the identity $\\sigma(-z) = 1 - \\sigma(z)$, the gradient is:\n$$\n\\nabla f_3(\\boldsymbol{\\theta}) = \\sum_{i=1}^{4} (1-p_i) (-y_i \\mathbf{x}_i) = \\sum_{i=1}^{4} y_i(p_i-1) \\mathbf{x}_i = \\mathbf{X}^\\top (\\mathbf{y} \\odot (\\mathbf{p} - \\mathbf{1}))\n$$\nwhere $\\odot$ denotes element-wise multiplication and $\\mathbf{1}$ is a vector of ones. The Hessian of this function can be shown to be positive semi-definite. Since the data matrix $\\mathbf{X}$ has linearly independent columns (full column rank), the Hessian is in fact positive definite, ensuring $f_3$ is strictly convex with a unique minimizer. The algorithm is initialized from the origin, $\\boldsymbol{\\theta}_0 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$. For numerical stability, the computation of $\\log(1+e^z)$ is performed using a log-sum-exp pattern.\n\nThe algorithm is implemented in software following these derivations to compute the final objective values for each case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expit, logsumexp\n\ndef solve():\n    \"\"\"\n    Solves the unconstrained optimization problems defined in the test suite\n    using the gradient descent method with backtracking line search.\n    \"\"\"\n    \n    # Define common parameters for the optimization algorithm\n    alpha0 = 1.0\n    rho = 0.5\n    c = 1e-4\n    epsilon = 1e-8\n    max_iter = 10000\n\n    def gradient_descent(f, grad_f, x0):\n        \"\"\"\n        Generic implementation of gradient descent with backtracking line search.\n\n        Args:\n            f (callable): The objective function.\n            grad_f (callable): The gradient of the objective function.\n            x0 (np.ndarray): The initial starting point.\n\n        Returns:\n            float: The minimized objective function value at termination.\n        \"\"\"\n        x = np.copy(x0).astype(np.float64)\n        \n        for k in range(max_iter):\n            grad = grad_f(x)\n            grad_norm = np.linalg.norm(grad)\n\n            # Termination condition: norm of the gradient is small enough\n            if grad_norm = epsilon:\n                break\n            \n            d = -grad  # Steepest descent direction\n            \n            # Backtracking line search to find step length alpha\n            alpha = alpha0\n            fx = f(x)\n            grad_dot_d = np.dot(grad, d)\n            \n            # Armijo condition check\n            while f(x + alpha * d)  fx + c * alpha * grad_dot_d:\n                alpha = rho * alpha\n            \n            # Update the iterate\n            x = x + alpha * d\n            \n        return f(x)\n\n    results = []\n\n    # Test Case 1: Mean-variance quadratic\n    Sigma = np.array([[2.0, 0.8], [0.8, 1.5]])\n    mu = np.array([0.5, 0.3])\n    w0 = np.array([1.0, 1.0])\n    \n    def f1(w):\n        return 0.5 * w.T @ Sigma @ w - mu.T @ w\n    \n    def grad_f1(w):\n        return Sigma @ w - mu\n        \n    result1 = gradient_descent(f1, grad_f1, w0)\n    results.append(result1)\n\n    # Test Case 2: Ill-conditioned quadratic\n    H = np.array([[1000.0, 0.0], [0.0, 1.0]])\n    b = np.array([1.0, 1.0])\n    x0_2 = np.array([10.0, 10.0])\n\n    def f2(x):\n        return 0.5 * x.T @ H @ x - b.T @ x\n    \n    def grad_f2(x):\n        return H @ x - b\n        \n    result2 = gradient_descent(f2, grad_f2, x0_2)\n    results.append(result2)\n\n    # Test Case 3: Negative log-likelihood for binary choice\n    X = np.array([[1.0, -2.0], [1.0, -1.0], [1.0, 1.0], [1.0, 2.0]])\n    y = np.array([-1.0, 1.0, -1.0, 1.0])\n    theta0 = np.array([0.0, 0.0])\n\n    def f3(theta):\n        # log(1+exp(z)) is computed robustly as log(exp(0)+exp(z))\n        z = -y * (X @ theta)\n        return np.sum(logsumexp(np.vstack((np.zeros_like(z), z)), axis=0))\n\n    def grad_f3(theta):\n        # Gradient of sum_i log(1+exp(-y_i*x_i'theta)) is sum_i y_i(p_i-1)x_i\n        # where p_i = sigmoid(y_i*x_i'theta)\n        h = y * (X @ theta)\n        p = expit(h)  # Numerically stable sigmoid function\n        # Vectorized gradient calculation\n        return X.T @ (y * (p - 1.0))\n        \n    result3 = gradient_descent(f3, grad_f3, theta0)\n    results.append(result3)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}