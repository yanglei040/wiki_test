{
    "hands_on_practices": [
        {
            "introduction": "经济学中的优化问题通常涉及在预算或生产目标等约束条件下进行决策。本练习将演示如何运用卡鲁什-库恩-塔克（KKT）条件来解决企业的成本最小化问题。更重要的是，它揭示了拉格朗日乘子背后的经济直觉，展示其如何作为“影子价格”来量化约束的边际成本 。",
            "id": "2384397",
            "problem": "一家竞争性公司使用两种投入 $x_1$ 和 $x_2$ 来生产产出 $y$，其投入价格分别为 $w_1$ 和 $w_2$，生产函数为 $f(x_1,x_2) = x_1^{1/2} x_2^{1/2}$。该公司必须满足至少 $q_0$ 单位的生产配额。该公司选择投入以在满足配额的前提下最小化总成本。假设 $w_1 = \\$\\,4$ 每单位，$w_2 = \\$\\,1$ 每单位，以及 $q_0 = 10$ 单位产出。\n\n构建成本最小化问题及其带单个不等式约束的拉格朗日函数，使用卡鲁什-库恩-塔克（Karush-Kuhn-Tucker, KKT）条件推导一阶必要条件，并求解最优投入和相关的拉格朗日乘数。使用最优解处的对偶变量（拉格朗日乘数）来估计当生产配额从 $q_0$ 增加到 $q_0 + 1$（即增加一个单位）时，公司最小总成本的变化。请用美元表示您的最终答案。提供一个单一的数值；无需四舍五入。",
            "solution": "问题陈述需要进行验证。\n\n步骤1：提取已知条件。\n- 生产函数：$f(x_1,x_2) = x_1^{1/2} x_2^{1/2}$\n- 投入：$x_1$, $x_2$\n- 投入价格：$w_1 = 4$ 美元每单位，$w_2 = 1$ 美元每单位\n- 生产配额：至少 $q_0 = 10$ 单位\n- 目标：最小化总成本，$C = w_1 x_1 + w_2 x_2$。\n- 任务：构建成本最小化问题及其拉格朗日函数，使用卡鲁什-库恩-塔克（Karush-Kuhn-Tucker, KKT）条件推导一阶必要条件，求解最优投入和拉格朗日乘数，并使用该乘数估计配额增加一个单位时最小成本的变化。\n\n步骤2：使用提取的已知条件进行验证。\n- **科学依据：** 该问题是微观经济学理论中的一个标准练习，特别是企业理论。它使用了一个柯布-道格拉斯生产函数，这是经济学中的一个经典模型。所有概念都已成熟。这在科学上是合理的。\n- **适定性：** 该问题是一个约束优化问题。目标函数是线性的（因此是凸函数），而约束函数 $g(x_1, x_2) = x_1^{1/2} x_2^{1/2}$ 是拟凹函数，这定义了一个凸的上水平集。这种结构确保了这是一个有唯一解的适定最小化问题。\n- **客观性：** 问题以精确、无歧义的数学和经济学术语陈述。\n\n步骤3：结论与行动。\n该问题是有效的。它在科学上合理、适定且客观。我将继续进行求解。\n\n公司的问题是在其产出 $y = f(x_1, x_2)$ 至少为配额量 $q_0$ 的约束下，最小化其总成本 $C(x_1, x_2) = w_1 x_1 + w_2 x_2$。生产函数的形式隐含要求投入的非负性，$x_1 \\ge 0$ 和 $x_2 \\ge 0$。\n\n代入给定值，优化问题为：\n$$\n\\text{最小化 } C(x_1, x_2) = 4x_1 + x_2\n$$\n$$\n\\text{约束条件 } x_1^{1/2} x_2^{1/2} \\ge 10\n$$\n\n为了应用卡鲁什-库恩-塔克（Karush-Kuhn-Tucker, KKT）框架，我们将约束写成标准形式 $g(x) \\le 0$。\n约束条件 $x_1^{1/2} x_2^{1/2} \\ge 10$ 等价于 $10 - x_1^{1/2} x_2^{1/2} \\le 0$。\n\n拉格朗日函数 $\\mathcal{L}$ 被构建为目标函数加上拉格朗日乘数 $\\lambda$ 乘以约束函数：\n$$\n\\mathcal{L}(x_1, x_2, \\lambda) = 4x_1 + x_2 + \\lambda(10 - x_1^{1/2} x_2^{1/2})\n$$\n\n最优解 $(x_1^*, x_2^*, \\lambda^*)$ 的KKT条件是：\n1.  一阶条件（平稳性）：拉格朗日函数对选择变量的偏导数必须为零。\n    $$\n    \\frac{\\partial \\mathcal{L}}{\\partial x_1} = 4 - \\lambda \\left( \\frac{1}{2} x_1^{-1/2} x_2^{1/2} \\right) = 0\n    $$\n    $$\n    \\frac{\\partial \\mathcal{L}}{\\partial x_2} = 1 - \\lambda \\left( \\frac{1}{2} x_1^{1/2} x_2^{-1/2} \\right) = 0\n    $$\n2.  原始可行性：解必须满足原始约束条件。\n    $$\n    10 - x_1^{1/2} x_2^{1/2} \\le 0 \\quad \\text{或} \\quad x_1^{1/2} x_2^{1/2} \\ge 10\n    $$\n3.  对偶可行性：在最小化问题中，与“小于或等于”不等式约束相关的拉格朗日乘数必须为非负数。\n    $$\n    \\lambda \\ge 0\n    $$\n4.  互补松弛性：在最优解处，约束要么是紧的，要么乘数为零（或两者都成立）。\n    $$\n    \\lambda (10 - x_1^{1/2} x_2^{1/2}) = 0\n    $$\n\n我们现在求解这个条件系统。\n从一阶条件出发，假设 $x_1 > 0$ 且 $x_2 > 0$：\n$$\n4 = \\frac{\\lambda}{2} \\sqrt{\\frac{x_2}{x_1}} \\quad (1)\n$$\n$$\n1 = \\frac{\\lambda}{2} \\sqrt{\\frac{x_1}{x_2}} \\quad (2)\n$$\n等式右边为正，这意味着 $\\lambda$ 必须严格为正 ($\\lambda > 0$)。如果 $\\lambda$ 为零，一阶条件将要求 $4=0$ 和 $1=0$，这是荒谬的。\n由于 $\\lambda > 0$，互补松弛性条件 $\\lambda (10 - x_1^{1/2} x_2^{1/2}) = 0$ 意味着约束必须是紧的：\n$$\n10 - x_1^{1/2} x_2^{1/2} = 0 \\implies x_1^{1/2} x_2^{1/2} = 10 \\quad (3)\n$$\n现在，我们可以通过将方程（1）除以方程（2）来求解 $x_1$ 和 $x_2$ 之间的关系：\n$$\n\\frac{4}{1} = \\frac{\\frac{\\lambda}{2} \\sqrt{\\frac{x_2}{x_1}}}{\\frac{\\lambda}{2} \\sqrt{\\frac{x_1}{x_2}}} = \\frac{\\sqrt{x_2}}{\\sqrt{x_1}} \\cdot \\frac{\\sqrt{x_2}}{\\sqrt{x_1}} = \\frac{x_2}{x_1}\n$$\n这给出了公司的最优投入扩展路径：$x_2 = 4x_1$。\n\n将此关系代入紧约束，即方程（3）：\n$$\n\\sqrt{x_1 (4x_1)} = 10\n$$\n$$\n\\sqrt{4x_1^2} = 10\n$$\n$$\n2x_1 = 10\n$$\n求解 $x_1$ 得到第一种投入的最优数量：\n$$\nx_1^* = 5\n$$\n现在，我们求出第二种投入的最优数量：\n$$\nx_2^* = 4x_1^* = 4(5) = 20\n$$\n最优投入组合是 $(x_1^*, x_2^*) = (5, 20)$。\n\n最后，我们使用方程（2）和最优投入来求解拉格朗日乘数 $\\lambda^*$：\n$$\n1 = \\frac{\\lambda^*}{2} \\sqrt{\\frac{x_1^*}{x_2^*}} = \\frac{\\lambda^*}{2} \\sqrt{\\frac{5}{20}} = \\frac{\\lambda^*}{2} \\sqrt{\\frac{1}{4}} = \\frac{\\lambda^*}{2} \\cdot \\frac{1}{2} = \\frac{\\lambda^*}{4}\n$$\n这得出：\n$$\n\\lambda^* = 4\n$$\n最优拉格朗日乘数是 $\\lambda^*=4$。我们确认 $\\lambda^* \\ge 0$，满足对偶可行性条件。\n\n在成本最小化背景下，拉格朗日乘数 $\\lambda^*$ 的经济解释是约束的边际成本。它表示公司最小成本相对于生产配额 $q_0$ 放松的变化率。\n也就是说，$\\lambda^* = \\frac{dC^*(q_0)}{dq_0}$，其中 $C^*$ 是最小化后的成本。\n\n问题要求估计当生产配额增加一个单位，即从 $q_0 = 10$ 增加到 $q_0' = 11$ 时，最小总成本的变化。这个变化量 $\\Delta q_0$ 是 $11 - 10 = 1$。\n使用一阶线性近似，最小成本的变化 $\\Delta C^*$ 为：\n$$\n\\Delta C^* \\approx \\lambda^* \\cdot \\Delta q_0\n$$\n代入计算出的值：\n$$\n\\Delta C^* \\approx 4 \\cdot 1 = 4\n$$\n公司最小总成本的估计增加额为 $4$ 美元。\n初始最小成本为 $C^* = 4x_1^* + x_2^* = 4(5) + 20 = 20 + 20 = 40$。新的估计最小成本将为 $40+4=44$。",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "现代金融学的基石之一是通过分散化管理风险。本练习将理论付诸实践，解决如何用两种风险资产构建全局最小方差投资组合的问题。通过解决这个问题，您不仅将应用二次优化，还将发现高相关性如何引出出人意料的投资策略，例如通过卖空高波动性资产来降低整体投资组合的风险 。",
            "id": "2384386",
            "problem": "考虑两种风险资产，分别标记为资产$A$和资产$B$。它们的年化标准差分别为 $\\sigma_A = 0.20$ 和 $\\sigma_B = 0.50$。它们回报率之间的相关系数为 $\\rho = 0.95$。投资者可以取任何满足 $w_A + w_B = 1$ 的实数值投资组合权重 $(w_A, w_B)$；允许卖空。投资组合方差为 $w^{\\top} \\Sigma w$，其中 $\\Sigma$ 是协方差矩阵，其元素为 $\\Sigma_{11} = \\sigma_A^2$，$\\Sigma_{22} = \\sigma_B^2$ 以及 $\\Sigma_{12} = \\Sigma_{21} = \\rho \\sigma_A \\sigma_B$。\n\n将全局最小方差投资组合定义为在约束条件 $w_A + w_B = 1$ 下，使 $w^{\\top} \\Sigma w$ 最小化的完全投资组合 $(w_A, w_B)$。\n\n在全局最小方差投资组合中，资产$B$（方差较高的资产）的权重是多少？将您的答案四舍五入到四位有效数字。以纯数字形式表示您的答案（无单位）。",
            "solution": "该问题陈述已经过验证，并被认定为有效。它提出了一个来自现代投资组合理论领域的标准、适定的约束优化问题，该理论是计算金融学的核心组成部分。所有数据和条件均已提供，并且科学合理、前后一致。\n\n目标是找到使投资组合方差 $V$ 最小化的投资组合权重 $(w_A, w_B)$，并满足投资组合被完全投资的约束条件。对于资产$A$和资产$B$两种资产，投资组合方差由以下二次型给出：\n$$V(w_A, w_B) = w_A^2 \\sigma_A^2 + w_B^2 \\sigma_B^2 + 2 w_A w_B \\rho \\sigma_A \\sigma_B$$\n其中$w_A$和$w_B$分别是资产$A$和资产$B$的权重。这些权重受以下线性约束：\n$$w_A + w_B = 1$$\n此约束使我们能够将问题简化为单变量的无约束优化问题。通过将 $w_A = 1 - w_B$ 代入方差方程，我们将方差 $V$ 表示为仅关于 $w_B$ 的函数：\n$$V(w_B) = (1 - w_B)^2 \\sigma_A^2 + w_B^2 \\sigma_B^2 + 2 (1 - w_B) w_B \\rho \\sigma_A \\sigma_B$$\n为了找到使该方差最小化的 $w_B$ 值，我们必须通过求 $V(w_B)$ 关于 $w_B$ 的一阶导数并将其设为零来找到临界点。这是微分学的直接应用。\n$$\\frac{d V}{d w_B} = \\frac{d}{d w_B} \\left[ (1 - 2w_B + w_B^2)\\sigma_A^2 + w_B^2 \\sigma_B^2 + (2w_B - 2w_B^2)\\rho \\sigma_A \\sigma_B \\right]$$\n逐项应用幂法则进行微分，得到：\n$$\\frac{d V}{d w_B} = (-2 + 2w_B)\\sigma_A^2 + 2w_B \\sigma_B^2 + (2 - 4w_B)\\rho \\sigma_A \\sigma_B$$\n将导数设为零以找到极值点：\n$$(-2 + 2w_B)\\sigma_A^2 + 2w_B \\sigma_B^2 + (2 - 4w_B)\\rho \\sigma_A \\sigma_B = 0$$\n我们现在通过对包含 $w_B$ 的项进行分组来求解 $w_B$：\n$$2w_B\\sigma_A^2 - 2\\sigma_A^2 + 2w_B \\sigma_B^2 + 2\\rho \\sigma_A \\sigma_B - 4w_B\\rho \\sigma_A \\sigma_B = 0$$\n$$w_B(2\\sigma_A^2 + 2\\sigma_B^2 - 4\\rho \\sigma_A \\sigma_B) = 2\\sigma_A^2 - 2\\rho \\sigma_A \\sigma_B$$\n除以 $2$ 来简化表达式：\n$$w_B(\\sigma_A^2 + \\sigma_B^2 - 2\\rho \\sigma_A \\sigma_B) = \\sigma_A^2 - \\rho \\sigma_A \\sigma_B$$\n分离出 $w_B$ 得到全局最小方差投资组合中资产$B$权重的一般公式：\n$$w_B = \\frac{\\sigma_A^2 - \\rho \\sigma_A \\sigma_B}{\\sigma_A^2 + \\sigma_B^2 - 2\\rho \\sigma_A \\sigma_B}$$\n二阶导数 $\\frac{d^2 V}{d w_B^2} = 2(\\sigma_A^2 + \\sigma_B^2 - 2\\rho \\sigma_A \\sigma_B)$ 为正，因为 $|\\rho|  1$，这确认了找到的临界点是一个全局最小值。\n\n现在，我们代入给定的数值：$\\sigma_A = 0.20$，$\\sigma_B = 0.50$ 和 $\\rho = 0.95$。\n首先，我们计算方差和协方差：\n$$\\sigma_A^2 = (0.20)^2 = 0.04$$\n$$\\sigma_B^2 = (0.50)^2 = 0.25$$\n$$\\text{Cov}(A,B) = \\rho \\sigma_A \\sigma_B = (0.95)(0.20)(0.50) = 0.095$$\n将这些值代入推导出的 $w_B$ 公式中：\n$$w_B = \\frac{0.04 - 0.095}{0.04 + 0.25 - 2(0.095)}$$\n$$w_B = \\frac{-0.055}{0.29 - 0.19}$$\n$$w_B = \\frac{-0.055}{0.10} = -0.55$$\n问题要求将答案四舍五入到四位有效数字。因此，资产$B$的权重为$-0.5500$。负值表示在资产$B$上持有空头头寸，这是问题陈述所允许的。因此，资产A的权重为 $w_A = 1 - w_B = 1 - (-0.55) = 1.55$。",
            "answer": "$$\n\\boxed{-0.5500}\n$$"
        },
        {
            "introduction": "虽然理论解法十分优雅，但现实世界中的优化问题依赖于强大的数值算法。本动手编程练习将比较两种基本方法：一阶的梯度下降法和二阶的牛顿法。通过亲手实现并运行这两种算法来解决同一个问题，您将直接观察到它们在收敛速度上的巨大差异，尤其是在经济和金融建模中经常遇到的病态问题上 。",
            "id": "2384404",
            "problem": "考虑在有限维欧几里得空间中最大化一个凹二次效用函数。设效用函数为 $u(\\mathbf{x}) = \\mathbf{b}^{\\top}\\mathbf{x} - \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x}$，其中 $\\mathbf{x} \\in \\mathbb{R}^{n}$，$\\mathbf{b} \\in \\mathbb{R}^{n}$，且 $\\mathbf{Q} \\in \\mathbb{R}^{n \\times n}$ 是一个对称正定矩阵。该效用函数是严格凹的，其负值定义了一个凸最小化问题。定义凸目标函数 $f(\\mathbf{x}) = -u(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} - \\mathbf{b}^{\\top}\\mathbf{x}$。$f$ 的Hessian矩阵等于 $\\mathbf{Q}$，其关于欧几里得范数的条件数为 $\\kappa(\\mathbf{Q}) = \\lambda_{\\max}(\\mathbf{Q})/\\lambda_{\\min}(\\mathbf{Q})$，其中 $\\lambda_{\\max}$ 和 $\\lambda_{\\min}$ 分别表示最大和最小特征值。您将比较解决 $\\min_{\\mathbf{x}} f(\\mathbf{x})$ 的两种算法的收敛行为：带回溯线搜索的梯度下降法和带回溯线搜索的牛顿法。\n\n仅从多元微积分和凸分析的核心定义（梯度作为偏导数向量，Hessian矩阵作为梯度的雅可比矩阵，无约束凸最小化的一阶最优性条件，以及Armijo充分下降条件）出发，推导为上述二次函数 $f(\\mathbf{x})$ 实现这两种算法所需的解析表达式。按如下方式实现这两种算法：\n\n- 带回溯的梯度下降法：在迭代点 $\\mathbf{x}_{k}$，使用负梯度计算一个下降方向，并执行满足Armijo充分下降条件的回溯线搜索来选择步长。更新迭代点并重复直至收敛。\n- 带回溯的牛顿法：在迭代点 $\\mathbf{x}_{k}$，通过求解由Hessian矩阵和梯度定义的线性系统来计算牛顿方向，并执行满足Armijo充分下降条件的回溯线搜索来选择步长。更新迭代点并重复直至收敛。\n\n对两种方法使用以下共享参数：\n- Armijo参数 $c_{1} = 10^{-4}$，\n- 回溯收缩因子 $\\tau = \\tfrac{1}{2}$，\n- 初始试探步长 $\\alpha_{0} = 1$，\n- 基于梯度欧几里得范数的停止容差：当 $\\lVert \\nabla f(\\mathbf{x}_{k}) \\rVert_{2} \\le \\varepsilon$ 且 $\\varepsilon = 10^{-6}$ 时停止，\n- 梯度下降法的最大迭代次数为 $200{,}000$，牛顿法的最大迭代次数为 $1{,}000$。\n\n测试套件。在以下四个测试用例上运行这两种方法，每个用例由 $(\\mathbf{Q}, \\mathbf{b}, \\mathbf{x}_{0})$ 指定，其中 $\\mathbf{x}_{0}$ 是起始点。\n\n- 用例 1（边界最优性，病态但平凡）：\n  $$\\mathbf{Q} = \\begin{bmatrix} 1  0 \\\\ 0  100 \\end{bmatrix},\\quad \\mathbf{b} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix},\\quad \\mathbf{x}_{0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}.$$\n- 用例 2（病态，中等）：\n  $$\\mathbf{Q} = \\begin{bmatrix} 1  0 \\\\ 0  100 \\end{bmatrix},\\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix},\\quad \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}.$$\n- 用例 3（病态，更强）：\n  $$\\mathbf{Q} = \\begin{bmatrix} 1  0 \\\\ 0  500 \\end{bmatrix},\\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix},\\quad \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}.$$\n- 用例 4（病态，更强）：\n  $$\\mathbf{Q} = \\begin{bmatrix} 1  0 \\\\ 0  2000 \\end{bmatrix},\\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix},\\quad \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}.$$\n\n对于每个用例，运行两种算法，直到满足停止准则或达到迭代次数限制。对于每个用例，返回迭代次数的有序对 $[\\text{iters\\_GD}, \\text{iters\\_Newton}]$，其中 $\\text{iters\\_GD}$ 是梯度下降法使用的迭代次数，$\\text{iters\\_Newton}$ 是牛顿法使用的迭代次数。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例对应一个子列表，顺序与上文相同。例如，输出格式必须是\n$$[\\,[\\text{iters\\_GD}^{(1)},\\text{iters\\_Newton}^{(1)}],\\,[\\text{iters\\_GD}^{(2)},\\text{iters\\_Newton}^{(2)}],\\,[\\text{iters\\_GD}^{(3)},\\text{iters\\_Newton}^{(3)}],\\,[\\text{iters\\_GD}^{(4)},\\text{iters\\_Newton}^{(4)}]\\,].$$\n输出中的所有数字必须是整数，并且不应打印任何其他文本。",
            "solution": "所呈现的问题陈述需经过验证。\n\n**步骤 1：提取已知条件**\n\n- **目标函数：** 最小化 $f(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} - \\mathbf{b}^{\\top}\\mathbf{x}$，其中 $\\mathbf{x}, \\mathbf{b} \\in \\mathbb{R}^{n}$，$\\mathbf{Q} \\in \\mathbb{R}^{n \\times n}$ 是一个对称正定矩阵。\n- **算法：** 梯度下降法和牛顿法，两者均带回溯线搜索。\n- **线搜索参数：**\n    - Armijo充分下降参数：$c_{1} = 10^{-4}$。\n    - 收缩因子：$\\tau = \\tfrac{1}{2}$。\n    - 初始步长：$\\alpha_{0} = 1$。\n- **终止条件：**\n    - 梯度范数的停止容差：$\\lVert \\nabla f(\\mathbf{x}_{k}) \\rVert_{2} \\le \\varepsilon = 10^{-6}$。\n    - 梯度下降法的最大迭代次数：$200,000$。\n    - 牛顿法的最大迭代次数：$1,000$。\n- **测试用例：** 提供了四个用例，每个用例由一个元组 $(\\mathbf{Q}, \\mathbf{b}, \\mathbf{x}_{0})$ 定义。\n    1.  $\\mathbf{Q} = \\begin{bmatrix} 1  0 \\\\ 0  100 \\end{bmatrix}, \\mathbf{b} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \\mathbf{x}_{0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$。\n    2.  $\\mathbf{Q} = \\begin{bmatrix} 1  0 \\\\ 0  100 \\end{bmatrix}, \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}, \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}$。\n    3.  $\\mathbf{Q} = \\begin{bmatrix} 1  0 \\\\ 0  500 \\end{bmatrix}, \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}, \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}$。\n    4.  $\\mathbf{Q} = \\begin{bmatrix} 1  0 \\\\ 0  2000 \\end{bmatrix}, \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}, \\mathbf{x}_{0} = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix}$。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n该问题具有科学依据，是适定且客观的。这是一个数值凸优化中的标准问题，比较了一阶和二阶方法在凸二次函数上的性能。所有参数、初始条件和矩阵都已明确定义。矩阵 $\\mathbf{Q}$ 是对称的，并且由于其对角线元素为正，因此是正定的，这确保了 $f(\\mathbf{x})$ 的严格凸性以及唯一最小化子的存在。用例1是一个平凡的边界情况，其中起始点就是解，这是对任何正确实现的有效测试。该问题是完整、一致且科学合理的。\n\n**步骤 3：结论与行动**\n\n该问题是**有效的**。将提供一个解决方案。\n\n**推导与算法设计**\n\n目标是找到 $\\mathbf{x}^* = \\arg\\min_{\\mathbf{x} \\in \\mathbb{R}^n} f(\\mathbf{x})$，其中 $f(\\mathbf{x}) = \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} - \\mathbf{b}^{\\top}\\mathbf{x}$。\n\n**一阶和二阶导数**\n为了应用基于梯度的优化方法，我们首先推导 $f(\\mathbf{x})$ 的梯度和Hessian矩阵。使用矩阵微积分的基本法则：\n$f(\\mathbf{x})$ 的梯度是其偏导数的向量，$\\nabla f(\\mathbf{x}) = \\left[ \\frac{\\partial f}{\\partial x_i} \\right]_{i=1}^n$。\n$$\n\\nabla f(\\mathbf{x}) = \\nabla \\left( \\tfrac{1}{2}\\mathbf{x}^{\\top}\\mathbf{Q}\\mathbf{x} - \\mathbf{b}^{\\top}\\mathbf{x} \\right) = \\tfrac{1}{2}(\\mathbf{Q} + \\mathbf{Q}^{\\top})\\mathbf{x} - \\mathbf{b}\n$$\n由于 $\\mathbf{Q}$ 是对称的，$\\mathbf{Q} = \\mathbf{Q}^{\\top}$，这使得梯度简化为：\n$$\n\\nabla f(\\mathbf{x}) = \\mathbf{Q}\\mathbf{x} - \\mathbf{b}\n$$\n$f(\\mathbf{x})$ 的Hessian矩阵是二阶偏导数的矩阵，$\\nabla^2 f(\\mathbf{x}) = \\left[ \\frac{\\partial^2 f}{\\partial x_i \\partial x_j} \\right]_{i,j=1}^n$。它是梯度的雅可比矩阵：\n$$\n\\nabla^2 f(\\mathbf{x}) = \\nabla (\\mathbf{Q}\\mathbf{x} - \\mathbf{b}) = \\mathbf{Q}\n$$\nHessian矩阵是常数，等于矩阵 $\\mathbf{Q}$。由于 $\\mathbf{Q}$ 是正定的，所以 $f(\\mathbf{x})$ 是一个严格凸函数。\n\n**最优性条件**\n对于一个无约束凸优化问题，点 $\\mathbf{x}^*$ 是全局最小化子的一阶充要条件是梯度为零：\n$$\n\\nabla f(\\mathbf{x}^*) = \\mathbf{Q}\\mathbf{x}^* - \\mathbf{b} = \\mathbf{0}\n$$\n由于 $\\mathbf{Q}$ 是可逆的，唯一解由 $\\mathbf{x}^* = \\mathbf{Q}^{-1}\\mathbf{b}$ 给出。我们的任务是迭代地找到这个解。\n\n**迭代算法**\n两种算法都遵循更新规则 $\\mathbf{x}_{k+1} = \\mathbf{x}_{k} + \\alpha_k \\mathbf{p}_k$，其中 $\\mathbf{p}_k$ 是一个搜索方向，$\\alpha_k > 0$ 是由线搜索确定的步长。\n\n**1. 带回溯线搜索的梯度下降法**\n- **搜索方向：** 最速下降方向是负梯度：\n  $$\n  \\mathbf{p}_k = -\\nabla f(\\mathbf{x}_k) = -(\\mathbf{Q}\\mathbf{x}_k - \\mathbf{b}) = \\mathbf{b} - \\mathbf{Q}\\mathbf{x}_k\n  $$\n- **线搜索：** 步长 $\\alpha_k$ 使用回溯法找到。从一个初始试探步长 $\\alpha = \\alpha_0$ 开始，我们迭代地将其乘以一个因子 $\\tau$，直到满足Armijo充分下降条件：\n  $$\n  f(\\mathbf{x}_k + \\alpha \\mathbf{p}_k) \\le f(\\mathbf{x}_k) + c_1 \\alpha \\nabla f(\\mathbf{x}_k)^{\\top} \\mathbf{p}_k\n  $$\n  代入 $\\mathbf{p}_k = -\\nabla f(\\mathbf{x}_k)$，条件变为：\n  $$\n  f(\\mathbf{x}_k - \\alpha \\nabla f(\\mathbf{x}_k)) \\le f(\\mathbf{x}_k) - c_1 \\alpha \\lVert \\nabla f(\\mathbf{x}_k) \\rVert_2^2\n  $$\n该算法通过生成一系列迭代点 $\\{\\mathbf{x}_k\\}$ 来进行，直到 $\\lVert \\nabla f(\\mathbf{x}_k) \\rVert_2 \\le \\varepsilon$。已知梯度下降的收敛速度会随着条件数 $\\kappa(\\mathbf{Q})$ 的增加而降低。\n\n**2. 带回溯线搜索的牛顿法**\n- **搜索方向：** 牛顿法使用函数的二阶近似。牛顿方向 $\\mathbf{p}_k^{\\text{N}}$ 通过求解线性系统找到：\n  $$\n  \\nabla^2 f(\\mathbf{x}_k) \\mathbf{p}_k^{\\text{N}} = -\\nabla f(\\mathbf{x}_k)\n  $$\n  对于我们的二次目标函数，这变为：\n  $$\n  \\mathbf{Q} \\mathbf{p}_k^{\\text{N}} = -(\\mathbf{Q}\\mathbf{x}_k - \\mathbf{b})\n  $$\n  求解 $\\mathbf{p}_k^{\\text{N}}$ 得：\n  $$\n  \\mathbf{p}_k^{\\text{N}} = -\\mathbf{Q}^{-1}(\\mathbf{Q}\\mathbf{x}_k - \\mathbf{b}) = \\mathbf{Q}^{-1}\\mathbf{b} - \\mathbf{x}_k = \\mathbf{x}^* - \\mathbf{x}_k\n  $$\n  牛顿方向直接从当前迭代点指向精确的最小化子。\n- **线搜索：** 线搜索的执行方式与梯度下降法相同。我们来分析初始试探步长 $\\alpha=1$ 的Armijo条件：\n  $$\n  f(\\mathbf{x}_k + \\mathbf{p}_k^{\\text{N}}) \\le f(\\mathbf{x}_k) + c_1 \\nabla f(\\mathbf{x}_k)^{\\top} \\mathbf{p}_k^{\\text{N}}\n  $$\n  对于二次函数，$f(\\mathbf{x}_k + \\alpha\\mathbf{p}_k^{\\text{N}})$ 在 $\\mathbf{x}_k$ 附近的泰勒展开式是精确到二阶的：\n  $$\n  f(\\mathbf{x}_k + \\alpha\\mathbf{p}_k^{\\text{N}}) = f(\\mathbf{x}_k) + \\alpha \\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}} + \\frac{1}{2}\\alpha^2 (\\mathbf{p}_k^{\\text{N}})^{\\top}\\mathbf{Q}\\mathbf{p}_k^{\\text{N}}\n  $$\n  代入 $\\mathbf{Q}\\mathbf{p}_k^{\\text{N}} = -\\nabla f(\\mathbf{x}_k)$：\n  $$\n  f(\\mathbf{x}_k + \\alpha\\mathbf{p}_k^{\\text{N}}) = f(\\mathbf{x}_k) + \\alpha \\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}} - \\frac{1}{2}\\alpha^2 \\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}}\n  $$\n  Armijo条件变为：\n  $$\n  f(\\mathbf{x}_k) + \\alpha \\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}} - \\frac{1}{2}\\alpha^2 \\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}} \\le f(\\mathbf{x}_k) + c_1 \\alpha \\nabla f(\\mathbf{x}_k)^{\\top} \\mathbf{p}_k^{\\text{N}}\n  $$\n  由于 $\\mathbf{p}_k^{\\text{N}}$ 是一个下降方向，$\\nabla f(\\mathbf{x}_k)^{\\top}\\mathbf{p}_k^{\\text{N}} = -(\\mathbf{p}_k^{\\text{N}})^{\\top}\\mathbf{Q}\\mathbf{p}_k^{\\text{N}}  0$。我们可以用这个负项相除，从而反转不等式：\n  $$\n  1 - \\frac{1}{2}\\alpha \\ge c_1 \\implies \\alpha \\le 2(1-c_1)\n  $$\n  当 $c_1=10^{-4}$ 时，条件为 $\\alpha \\le 2(1 - 10^{-4}) = 1.9998$。由于初始试探步长是 $\\alpha_0 = 1$，它小于 $1.9998$，所以步长 $\\alpha_k=1$ 将总被接受。\n  更新为 $\\mathbf{x}_{k+1} = \\mathbf{x}_k + 1 \\cdot (\\mathbf{x}^* - \\mathbf{x}_k) = \\mathbf{x}^*$。\n  因此，对于除最优点本身之外的任何起始点，带有指定回溯参数的牛顿法将在单次迭代中收敛到精确解。\n\n**实现摘要**\n实现将包括两个函数，每个算法一个。每个函数将根据其特定规则迭代更新解向量 $\\mathbf{x}$，并执行回溯线搜索以确定步长。循环在梯度的欧几里得范数低于容差 $\\varepsilon$ 或达到最大迭代次数时终止。\n对于用例1，由于 $\\mathbf{x}_0 = \\mathbf{0}$ 且 $\\mathbf{b} = \\mathbf{0}$，初始梯度 $\\nabla f(\\mathbf{x}_0) = \\mathbf{Q}\\mathbf{0} - \\mathbf{0} = \\mathbf{0}$。停止条件在开始时就已满足，因此两种算法都将报告 $0$ 次迭代。\n对于用例2、3和4，牛顿法预计需要1次迭代，而梯度下降法预计需要大量的迭代次数，且随着 $\\mathbf{Q}$ 的条件数增加而增加。",
            "answer": "[[0,0],[10609,1],[51430,1],[194488,1]]"
        }
    ]
}