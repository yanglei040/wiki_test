{
    "hands_on_practices": [
        {
            "introduction": "在统计学和计量经济学中，我们经常需要确定一个概率分布的众数，即概率密度函数达到峰值的点，这个过程与寻找最大似然估计密切相关。这个练习将指导你应用黄金分割搜索法来寻找贝塔分布的众数，通过对数密度函数进行操作，这是一种增强数值稳定性的常用技巧 。通过从零开始实现算法，你将掌握黄金分割搜索的核心机制，并体会其在无导数优化中的实用价值。",
            "id": "2398550",
            "problem": "您的任务是实现一个黄金分割搜索 (GSS) 程序，以在一维计量经济学背景下，数值计算一个单峰概率密度函数的众数。在许多计算经济学和金融学问题中，需要通过最大化一维似然或后验密度来定位参数模型下参数或潜在变量的最可能值。对于参数 $ \\alpha > 1 $ 和 $ \\beta > 1 $ 的 Beta 分布，其概率密度函数支撑于区间 $ [0,1] $ 上并且是单峰的。众数是密度函数达到其最大值的点 $ x^\\star \\in [0,1] $。\n\n使用的基本原理：\n- 众数的定义：对于闭区间 $ [a,b] $ 上的密度函数 $ f(x) $，众数是一个点 $ x^\\star \\in [a,b] $，使得对于所有 $ x \\in [a,b] $，都有 $ f(x^\\star) \\ge f(x) $。\n- 单峰性：如果存在一个唯一的 $ x^\\star \\in (a,b) $，使得函数 $ f $ 在 $ [a,x^\\star] $ 上严格递增，并在 $ [x^\\star,b] $ 上严格递减，则函数 $ f $ 在 $ [a,b] $ 上是单峰的。\n- 单调变换保持 argmax 不变：如果 $ g $ 是严格递增的，且 $ \\ell(x) = g(f(x)) $，那么 $ \\arg\\max_{x \\in [a,b]} f(x) = \\arg\\max_{x \\in [a,b]} \\ell(x) $。\n\n任务：\n1. 从基本原理出发，实现一个稳健的黄金分割搜索 (GSS) 算法，用于在闭区间 $ [a,b] $ 上最大化一个连续单峰函数，不使用任何导数信息。您的设计必须确保数值稳定性，并避免在定义域之外评估函数。\n2. 将您的 GSS 实现应用于参数为 $ \\alpha > 1 $，$ \\beta > 1 $ 的 Beta 分布。为避免数值下溢并移除不必要的常数，请最大化对数密度（忽略一个加法常数）：\n   - 对于 $ x \\in (0,1) $，定义 $ \\ell(x) = (\\alpha - 1)\\log(x) + (\\beta - 1)\\log(1 - x) $。请注意，减去 $ \\log B(\\alpha,\\beta) $ 是不必要的，因为它不影响最大化点。\n   - 由于 $ \\log(0) $ 未定义，将搜索限制在闭区间 $[\\varepsilon, 1 - \\varepsilon]$ 内，其中 $ \\varepsilon = 10^{-12} $。\n3. 使用基于绝对区间宽度的终止规则：当 $ b - a \\le \\tau $ 时停止，其中 $ \\tau $ 是给定的容差。返回中点 $ (a + b)/2 $ 作为数值最大化点。\n\n不涉及角度单位。没有物理单位。所有数值输出必须是浮点数。\n\n测试套件：\n您必须在以下五个参数集上评估您的实现，每个参数集都定义了一个单峰 Beta 分布：\n- 情况 $ 1 $: $ (\\alpha,\\beta) = (5,2) $。\n- 情况 $ 2 $: $ (\\alpha,\\beta) = (2.5,3.5) $。\n- 情况 $ 3 $: $ (\\alpha,\\beta) = (1.1,1.1) $。\n- 情况 $ 4 $: $ (\\alpha,\\beta) = (20,20) $。\n- 情况 $ 5 $: $ (\\alpha,\\beta) = (1000.5,1.1) $。\n\n覆盖性设计：\n- 情况 $ 1 $ 是一个右偏分布，其内部众数远离边界。\n- 情况 $ 2 $ 是中度偏斜分布，用于测试一般性能。\n- 情况 $ 3 $ 接近平坦但仍为单峰，用于测试当 $ \\alpha,\\beta \\downarrow 1 $ 时数值的稳定性。\n- 情况 $ 4 $ 是尖锐峰值且对称的分布，用于测试在最大化点附近曲率较高时的收敛性。\n- 情况 $ 5 $ 的众数非常接近右边界，用于测试在支撑集边缘附近的稳健性。\n\n实现要求：\n- 搜索区间的两端使用 $ \\varepsilon = 10^{-12} $，容差为 $ \\tau = 10^{-12} $。\n- 所有计算都应以浮点数进行。\n- 每种情况的最终答案应该是估计的众数，每个都四舍五入到恰好六位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表。例如，如果有三个结果 $ r_1 $、$ r_2 $、$ r_3 $，则输出必须为 $ [r_1,r_2,r_3] $ 的形式。对于本问题中的五个测试用例，请打印 $ [m_1,m_2,m_3,m_4,m_5] $，其中 $ m_i $ 是情况 $ i $ 的估计众数，每个都四舍五入到六位小数。",
            "solution": "所述问题根据科学合理性、形式可指定性和客观性标准进行验证。\n\n**步骤 1：提取的给定信息**\n- **目标**：实现一个黄金分割搜索 (GSS) 算法，以数值方式计算单峰概率密度函数的众数。\n- **目标函数**：对于参数 $\\alpha > 1$ 和 $\\beta > 1$，最大化 Beta 分布的对数密度函数 $\\ell(x) = (\\alpha - 1)\\log(x) + (\\beta - 1)\\log(1 - x)$。\n- **搜索域**：闭区间 $[\\varepsilon, 1 - \\varepsilon]$，其中 $\\varepsilon = 10^{-12}$。\n- **算法**：从基本原理出发实现的黄金分割搜索，不使用导数信息。\n- **终止准则**：当区间宽度 $b - a$ 小于或等于指定的容差 $\\tau = 10^{-12}$ 时，搜索终止。\n- **算法输出**：最终区间的中点 $(a + b) / 2$。\n- **测试用例（参数集 $(\\alpha, \\beta)$）**：\n    1.  $(5, 2)$\n    2.  $(2.5, 3.5)$\n    3.  $(1.1, 1.1)$\n    4.  $(20, 20)$\n    5.  $(1000.5, 1.1)$\n- **输出格式**：单行输出，包含一个由方括号括起来的逗号分隔列表，其中包含五个估计的众数，每个众数四舍五入到六位小数。\n\n**步骤 2：使用提取的给定信息进行验证**\n- **科学与事实合理性**：该问题是科学合理的。Beta 分布是一种标准的概率分布。对于 $\\alpha > 1$ 和 $\\beta > 1$，其密度在区间 $(0, 1)$ 上确实是单峰的。其众数的解析解为 $x^\\star = (\\alpha - 1) / (\\alpha + \\beta - 2)$，这证实了内部众数的存在性和唯一性。使用对数密度 $\\ell(x)$ 进行最大化是一种标准且有效的数值技术，因为对数函数是严格递增的单调变换，它保持最大化点（argmax）的位置不变。黄金分割搜索是寻找单峰函数极值的正确且标准的无导数算法。\n- **适定性**：该问题是适定的。它指定了一个单峰目标函数、一个封闭的搜索区间、一个明确的终止条件以及所有必要的参数。这些条件保证了所提出的算法可以收敛到的唯一解的存在。\n- **完整性与一致性**：问题陈述是完整且自洽的。它提供了实现和测试所需的所有数据。所提供的信息中没有矛盾之处。所有测试用例都满足条件 $\\alpha > 1, \\beta > 1$。搜索区间 $[\\varepsilon, 1-\\varepsilon]$ 正确地避开了对数函数在边界 $0$ 和 $1$ 处的奇点。\n\n**步骤 3：结论与行动**\n该问题是有效的。这是一个计算统计学和计量经济学中的标准且定义明确的问题。可以构建一个严谨的解决方案。\n\n**解法推导**\n\n任务是找到使 Beta 分布的概率密度函数 (PDF) $f(x; \\alpha, \\beta)$（对于 $x \\in [0, 1]$）最大化的值 $x^\\star$。\n$$\nf(x; \\alpha, \\beta) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha, \\beta)}\n$$\n其中 $B(\\alpha, \\beta)$ 是作为归一化常数的 Beta 函数。众数 $x^\\star$ 定义为 $x^\\star = \\arg\\max_{x \\in [0,1]} f(x; \\alpha, \\beta)$。\n\n由于对数函数是严格递增函数，最大化 $f(x)$ 等价于最大化其对数 $\\log(f(x))$。这种变换在数值上是有利的，因为它将乘积转换为和，并减轻了因密度值非常小而可能导致的下溢问题。\n$$\n\\log(f(x; \\alpha, \\beta)) = (\\alpha - 1)\\log(x) + (\\beta - 1)\\log(1-x) - \\log(B(\\alpha, \\beta))\n$$\n项 $\\log(B(\\alpha, \\beta))$ 是一个关于 $x$ 的常数，可以舍弃而不影响最大化点的位置。因此，问题正确地简化为最大化函数 $\\ell(x)$：\n$$\n\\ell(x) = (\\alpha - 1)\\log(x) + (\\beta - 1)\\log(1 - x)\n$$\n条件 $\\alpha > 1$ 和 $\\beta > 1$ 确保了 $\\ell(x)$ 在区间 $(0, 1)$ 上是严格凹的，因此是单峰的。该函数在 $x=0$ 和 $x=1$ 处未定义，因此搜索被正确地限制在一个稍小的闭区间 $[\\varepsilon, 1 - \\varepsilon]$ 内，其中 $\\varepsilon$ 是一个小的正常数。\n\n黄金分割搜索 (GSS) 是一种迭代算法，旨在给定区间内寻找单峰函数的极值。其主要优点是其无导数的性质和保证的线性收敛速度。该算法通过维护一个已知包含最大化点的区间 $[a, b]$ 来工作。\n\n算法的核心依赖于黄金比例 $\\phi = \\frac{1 + \\sqrt{5}}{2} \\approx 1.618034$。其倒数为 $\\psi = 1/\\phi = \\frac{\\sqrt{5} - 1}{2} \\approx 0.618034$。在每一步中，在当前区间 $[a, b]$ 内选择两个内点 $c$ 和 $d$，使得 $a  c  d  b$。这些点对称放置以维持黄金比例：\n$$\nc = a + (1-\\psi)(b-a) = a + \\psi^2(b-a) \\approx a + 0.382(b-a)\n$$\n$$\nd = a + \\psi(b-a) \\approx a + 0.618(b-a)\n$$\n在这些点上评估函数 $\\ell(x)$，得到 $\\ell(c)$ 和 $\\ell(d)$。根据比较结果，缩小搜索区间：\n1.  如果 $\\ell(c) > \\ell(d)$，由于单峰性，最大化点必须位于区间 $[a, d]$ 内。因此区间更新为：$[a', b'] = [a, d]$。\n2.  如果 $\\ell(d) \\ge \\ell(c)$，最大化点必须位于区间 $[c, b]$ 内。区间更新为：$[a', b'] = [c, b]$。\n\nGSS 的一个关键特性是其效率。当区间缩小时，旧的一个内点会成为新区间的一个内点，每次迭代节省一次函数求值。\n- 情况 1：如果新区间是 $[a, d]$，新的内点将是 $c' = a + \\psi^2(d-a)$ 和 $d' = a + \\psi(d-a)$。可以证明旧点 $c$ 成为新点 $d'$，即 $d' = a + \\psi(d-a) = a + \\psi \\cdot \\psi(b-a) = a + \\psi^2(b-a) = c$。所以，我们设置 $b \\leftarrow d$，$d \\leftarrow c$，并且只需要计算新的 $c$。\n- 情况 2：如果新区间是 $[c, b]$，旧点 $d$ 成为新点 $c'$。所以，我们设置 $a \\leftarrow c$，$c \\leftarrow d$，并且只需要计算新的 $d$。\n\n此迭代过程持续进行，直到区间宽度 $b - a$ 小于指定的容差 $\\tau$。最大化点的最终估计值是最终区间的中点 $(a + b)/2$。\n\n该算法的实现如下：\n1.  初始化搜索区间 $[a, b] = [\\varepsilon, 1 - \\varepsilon]$，其中 $\\varepsilon = 10^{-12}$。\n2.  定义常数 $\\psi = (\\sqrt{5} - 1)/2$ 和 $\\psi^2$。\n3.  计算初始内点 $c = a + \\psi^2(b-a)$ 和 $d = a + \\psi(b-a)$。\n4.  评估函数 $\\ell(c)$ 和 $\\ell(d)$。\n5.  进入一个只要 $b - a > \\tau$ 就继续的循环。\n6.  在循环内部，比较 $\\ell(c)$ 和 $\\ell(d)$，并如上所述缩小区间 $[a,b]$，重用一个点及其函数值，只计算一个新点及其函数值。\n7.  循环终止后，返回 $(a+b)/2$ 作为结果。\n此过程将应用于所提供的五个测试用例中的每一个。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the mode of Beta distributions using Golden-Section Search.\n    \n    This function implements the entire process as specified:\n    1. Defines the test cases for Beta distribution parameters (alpha, beta).\n    2. Uses a robust Golden-Section Search (GSS) implementation to find the mode.\n    3. The GSS maximizes the log-density function to ensure numerical stability.\n    4. Collects the results, formats them as required, and prints them.\n    \"\"\"\n\n    def golden_section_search(f, a, b, tol=1e-12):\n        \"\"\"\n        Finds the maximum of a unimodal function f on a closed interval [a, b]\n        using the Golden-Section Search algorithm.\n\n        Args:\n            f: The unimodal function to maximize.\n            a: The lower bound of the interval.\n            b: The upper bound of the interval.\n            tol: The tolerance for the interval width to terminate the search.\n\n        Returns:\n            The estimated x-value of the maximum.\n        \"\"\"\n        # Golden ratio constants\n        inv_phi = (np.sqrt(5) - 1) / 2  # 1/phi, approx 0.618\n        inv_phi_sq = inv_phi**2         # 1/phi^2, approx 0.382\n\n        # Initialize the interior points\n        h = b - a\n        c = a + inv_phi_sq * h\n        d = a + inv_phi * h\n        \n        # Evaluate function at interior points\n        f_c = f(c)\n        f_d = f(d)\n\n        while (b - a) > tol:\n            if f_c > f_d:\n                # The maximum is in the interval [a, d]\n                b = d\n                d = c\n                f_d = f_c\n                h = b - a\n                c = a + inv_phi_sq * h\n                f_c = f(c)\n            else:\n                # The maximum is in the interval [c, b]\n                a = c\n                c = d\n                f_c = f_d\n                h = b - a\n                d = a + inv_phi * h\n                f_d = f(d)\n        \n        # Return the midpoint of the final interval\n        return (a + b) / 2\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (5, 2),        # Case 1\n        (2.5, 3.5),    # Case 2\n        (1.1, 1.1),    # Case 3\n        (20, 20),      # Case 4\n        (1000.5, 1.1)  # Case 5\n    ]\n\n    # Constants for the search\n    epsilon = 1e-12\n    tolerance = 1e-12\n    \n    search_interval_a = epsilon\n    search_interval_b = 1 - epsilon\n    \n    results = []\n    \n    for alpha, beta in test_cases:\n        # Define the log-density function (up to an additive constant)\n        # for the Beta distribution with parameters alpha and beta.\n        # This is the function to be maximized.\n        log_density = lambda x: (alpha - 1) * np.log(x) + (beta - 1) * np.log(1 - x)\n        \n        # Find the mode using Golden-Section Search\n        mode_estimate = golden_section_search(\n            log_density, \n            search_interval_a, \n            search_interval_b, \n            tolerance\n        )\n        \n        results.append(mode_estimate)\n\n    # Final print statement in the exact required format.\n    # Each result is rounded to six decimal places.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "任何数值算法都有其适用边界，黄金分割搜索法也不例外，其有效性严格依赖于目标函数在搜索区间上的单峰性（unimodality）假设。这个概念性练习旨在深化你对该算法核心前提的理解 。通过分析将寻根问题 $g(x)=c$ 转化为最小化问题 $f(x)=(g(x)-c)^2$ 的常见策略，你将学会识别可能导致算法收敛到非解的“伪”局部最小值等陷阱。",
            "id": "2421149",
            "problem": "一位计算工程领域的工程师需要在一个闭区间 $[a,b]$ 上求解标量方程 $g(x)=c$。为此，该工程师建议使用黄金分割搜索 (GSS) 在 $[a,b]$ 上最小化残差平方 $f(x)=(g(x)-c)^2$。假设 $g$ 在 $[a,b]$ 上连续，并在 $(a,b)$ 上至少一次可微。选择所有关于此方法的有效性及其与局部极小值相关的陷阱的正确陈述。\n\nA. 如果 $g$ 在 $[a,b]$ 上连续且严格单调，并且 $c \\in g([a,b])$，那么 $f(x)$ 在 $[a,b]$ 上是单峰的，其唯一的全局最小化点是 $g(x)=c$ 的唯一解，因此在任何包含该解的区间 $[a,b]$ 上对 $f$ 应用 GSS 将会返回一个根。\n\nB. $f(x)$ 的唯一驻点是 $g(x)=c$ 的解。\n\nC. 如果 $g$ 在 $[a,b]$ 上是非单调的，那么 $f(x)$ 可以在 $g'(x)=0$ 且 $g(x)\\neq c$ 的点上存在局部极小值，因此在这样的区间上对 $f$ 运行 GSS 可能会收敛到一个非根的局部最小化点，具体取决于初始区间。\n\nD. 如果 $c\\notin g([a,b])$，那么在 $[a,b]$ 上用 GSS 最小化 $f$ 不会产生 $g(x)=c$ 的根；相反，它将收敛到 $[a,b]$ 中的一个点（可能是端点），其残差不为零。\n\nE. 对于任何可微的 $g$，对残差进行平方会使 $f(x)$ 在 $[a,b]$ 上是凸的，因此不存在伪局部极小值，并且如果实数轴上任何地方存在根，GSS 总能找到它。",
            "solution": "对问题陈述的有效性进行评估。\n\n**步骤 1：提取已知条件**\n- 待解方程：$g(x) = c$\n- 定义域：闭区间 $[a, b]$\n- 建议方法：最小化函数 $f(x) = (g(x) - c)^2$\n- 优化算法：黄金分割搜索 (GSS)\n- $g(x)$ 的性质：\n    - 在 $[a, b]$ 上连续\n    - 在 $(a, b)$ 上至少一次可微\n- 任务：评估关于此方法的有效性及其陷阱的陈述。\n\n**步骤 2：使用已知条件进行验证**\n- **科学依据：** 该问题描述了数值分析中的一种标准技术：将求根问题重新表述为最小化问题。函数、概念（连续性、可微性、单调性、单峰性）和算法（GSS）在数学和计算工程中都有明确的定义。该方法在科学上是有效的。\n- **适定性：** 问题提供了足够的信息，可以根据给定的 $g(x)$ 的性质来分析函数 $f(x)$ 的数学性质。选项中提出的问题是精确的，可以用数学的严谨性来回答。\n- **客观性：** 问题和待评估的陈述是客观的，没有主观论断。它们的正确性可以通过数学证明或反例来确定。\n\n该问题没有违反任何无效性标准。它是科学合理的、适定的、客观的且可形式化的。\n\n**步骤 3：结论与行动**\n问题有效。将推导完整解法。\n\n**核心原理推导**\n\n该问题建议通过最小化残差平方函数 $f(x) = (g(x) - c)^2$ 来找到 $g(x) = c$ 的根。$f(x)$ 的全局最小值出现在 $f(x) = 0$ 的地方，这当且仅当 $g(x) = c$ 时成立。因此，$f(x)$ 的全局最小化点正是 $g(x) = c$ 的根。\n\n黄金分割搜索 (GSS) 是一种算法，它保证能找到一个函数在某个区间上的最小值，前提是该函数在该区间上是**单峰的**。一个函数在区间上是单峰的，如果它在该区间内只有一个局部极小值。如果一个函数有多个局部极小值（即不是单峰的），GSS 可能会收敛到一个非全局最小值的局部极小值，具体取决于初始搜索区间。\n\n为了理解 GSS 在 $f(x)$ 上的行为，我们必须分析 $f(x)$ 的驻点，这些驻点决定了它的局部极小值和极大值。使用链式法则，$f(x)$ 的一阶导数是：\n$$ f'(x) = 2(g(x) - c) \\cdot g'(x) $$\n$f(x)$ 的驻点是使 $f'(x) = 0$ 的 $x$ 值。这当且仅当以下情况发生时成立：\n$$ g(x) - c = 0 \\quad \\text{或} \\quad g'(x) = 0 $$\n这表明 $f(x)$ 的驻点包括两类：\n$1$. $g(x) = c$ 的根。\n$2$. $g(x)$ 本身的驻点。\n\n后一类点，即 $g'(x)=0$ 但 $g(x) \\neq c$ 的点，可能会在 $f(x)$ 中引入“伪”局部极小值，这些并非原方程的根。\n\n要确定一个驻点 $x_0$ 是否为局部极小值，我们可以检验其二阶导数 $f''(x_0)$：\n$$ f''(x) = 2(g'(x))^2 + 2(g(x) - c)g''(x) $$\n在一个驻点 $x_0$ 处，如果 $g'(x_0) = 0$ 且 $g(x_0) \\neq c$，则二阶导数简化为：\n$$ f''(x_0) = 2(g(x_0) - c)g''(x_0) $$\n为了使 $x_0$ 成为 $f$ 的一个局部极小值，我们需要 $f''(x_0) > 0$。这个条件是可以满足的，如选项 C 的分析所示。\n\n**逐项分析**\n\n**A. 如果 $g$ 在 $[a,b]$ 上连续且严格单调，并且 $c \\in g([a,b])$，那么 $f(x)$ 在 $[a,b]$ 上是单峰的，其唯一的全局最小化点是 $g(x)=c$ 的唯一解，因此在任何包含该解的区间 $[a,b]$ 上对 $f$ 应用 GSS 将会返回一个根。**\n\n如果 $g(x)$ 在 $[a,b]$ 上连续且严格单调，并且 $c$ 在该区间上 $g$ 的值域内，根据介值定理，在 $[a,b]$ 中存在一个唯一的解 $x^*$ 使得 $g(x^*) = c$。在该点，$f(x^*) = (g(x^*) - c)^2 = 0$。由于对所有 $x$ 都有 $f(x) \\ge 0$，$x^*$ 是一个全局最小化点。\n\n因为 $g(x)$ 是严格单调的，所以 $g'(x)$ 在 $(a, b)$ 上不改变符号且不为零（可能在不构成 $g$ 的局部极值的孤立点上为零）。使得 $f'(x) = 2(g(x) - c)g'(x)$ 为零的唯一方式是 $g(x) - c = 0$，这只在 $x = x^*$ 时发生。因此，$f(x)$ 在区间内只有一个驻点。\n假设 $g(x)$ 是严格递增的，所以 $g'(x) > 0$。\n- 对于 $x  x^*$，$g(x)  g(x^*) = c$，所以 $g(x) - c  0$。因此，$f'(x) = 2(\\text{负})(\\text{正})  0$。\n- 对于 $x > x^*$，$g(x) > g(x^*) = c$，所以 $g(x) - c > 0$。因此，$f'(x) = 2(\\text{正})(\\text{正}) > 0$。\n这表明对于 $x  x^*$，$f(x)$ 是递减的；对于 $x > x^*$，$f(x)$ 是递增的。因此，$f(x)$ 在 $[a,b]$ 上是单峰的，其唯一极小值在 $x^*$。GSS 是为单峰函数设计的，将正确地收敛到这个唯一的最小化点。\n结论：**正确**。\n\n**B. $f(x)$ 的唯一驻点是 $g(x)=c$ 的解。**\n\n如上推导，$f(x)$ 的驻点发生在 $f'(x) = 2(g(x) - c) g'(x) = 0$ 时。此方程在 $g(x) = c$ 或 $g'(x) = 0$ 时成立。如果存在一个点 $x_0$ 使得 $g(x)$ 有一个局部极值（因此 $g'(x_0) = 0$）且 $g(x_0) \\neq c$，那么 $x_0$ 是 $f(x)$ 的一个驻点，但不是 $g(x) = c$ 的解。例如，令 $g(x) = x^2$ 且 $c=4$。解是 $x=\\pm 2$。需要最小化的函数是 $f(x) = (x^2 - 4)^2$。其导数为 $f'(x) = 2(x^2 - 4)(2x) = 4x(x-2)(x+2)$。驻点是 $x=0$，$x=2$ 和 $x=-2$。点 $x=0$ 是 $f(x)$ 的一个驻点，因为 $g'(0)=0$，但 $g(0) = 0 \\neq 4$，所以它不是一个解。\n结论：**不正确**。\n\n**C. 如果 $g$ 在 $[a,b]$ 上是非单调的，那么 $f(x)$ 可以在 $g'(x)=0$ 且 $g(x)\\neq c$ 的点上存在局部极小值，因此在这样的区间上对 $f$ 运行 GSS 可能会收敛到一个非根的局部最小化点，具体取决于初始区间。**\n\n如果 $g(x)$ 是非单调的，那么在 $(a,b)$ 中必须至少存在一个点 $x_0$ 使得 $g'(x_0)=0$。这个点是 $f(x)$ 的一个驻点。我们必须检查它是否可能是一个局部极小值。如一般推导中所示，$f''(x_0) = 2(g(x_0) - c)g''(x_0)$。我们可以使它为正。\n考虑 $g(x) = x^3 - 4x$。那么 $g'(x) = 3x^2 - 4$，在 $x_0 = \\pm 2/\\sqrt{3}$ 处为零。我们选择 $x_0 = 2/\\sqrt{3}$。在此点，$g(x)$ 有一个局部极小值：$g(2/\\sqrt{3}) = (8/3\\sqrt{3}) - (8/\\sqrt{3}) = -16/(3\\sqrt{3})$ 且 $g''(x) = 6x$，所以 $g''(2/\\sqrt{3}) = 12/\\sqrt{3} > 0$。\n让我们找一个 $c  g(x_0)$ 的根。例如，令 $c = -6$。方程是 $x^3-4x = -6$。需要最小化的函数是 $f(x)=(x^3-4x+6)^2$。存在一个实根 $x^*$（例如，$g(-3)=-15$，$g(-2)=0$，所以根在 $-3$ 和 $-2$ 之间）。\n在 $g(x)$ 的驻点 $x_0=2/\\sqrt{3}$ 处，我们有 $g(x_0) = -16/(3\\sqrt{3}) \\approx -3.078$，这不等于 $c=-6$。$f(x)$ 在 $x_0$ 处的二阶导数是 $f''(x_0) = 2(g(x_0)-c)g''(x_0) = 2(-16/(3\\sqrt{3}) - (-6)) (12/\\sqrt{3}) = 2(-3.078+6)(6.928) > 0$。\n所以，$x_0 = 2/\\sqrt{3}$ 是 $f(x)$ 的一个局部极小值点。由于 $f(x_0) = (g(x_0)-c)^2 > 0$ 而全局最小值是 $f(x^*)=0$，因此 $f(x)$ 不是单峰的。在一个包含 $x_0$ 但不包含 $x^*$ 的区间（例如 $[0,2]$）上启动的 GSS 可能会收敛到局部最小化点 $x_0$，而它不是 $g(x)=c$ 的根。\n结论：**正确**。\n\n**D. 如果 $c\\notin g([a,b])$，那么在 $[a,b]$ 上用 GSS 最小化 $f$ 不会产生 $g(x)=c$ 的根；相反，它将收敛到 $[a,b]$ 中的一个点（可能是端点），其残差不为零。**\n\n前提是 $c$ 不在区间 $[a,b]$ 上 $g(x)$ 的值域内。这意味着在 $[a,b]$ 中不存在 $x$ 使得 $g(x) = c$。因此，区间内不存在根。函数 $f(x) = (g(x) - c)^2$ 因此对所有 $x \\in [a,b]$ 都是严格为正的。作为一个在紧集 $[a,b]$ 上的连续函数，$f(x)$ 必须在该区间上达到一个全局最小值，并且这个最小值将大于零。出现这个最小值的点 $x_{min}$ 代表了在 $[a,b]$ 中对解的最佳“最小二乘”近似。\n由于不存在根，GSS 不可能产生根。它要做的是搜索 $f(x)$ 的一个最小值。GSS 迭代地缩小搜索区间。假设它收敛（随着区间缩小它会的），它将收敛到初始区间内对应于 $f(x)$ 最小值的一个点。由于 $f(x)$ 的最小值严格为正，找到的点将具有非零残差，即 $f(x_{min}) > 0$。如果 $f(x)$ 在 $[a,b]$ 上是单调的，这样的最小值可能出现在端点。该陈述准确地描述了结果是一个最小二乘解，而不是一个根。\n结论：**正确**。\n\n**E. 对于任何可微的 $g$，对残差进行平方会使 $f(x)$ 在 $[a,b]$ 上是凸的，因此不存在伪局部极小值，并且如果实数轴上任何地方存在根，GSS 总能找到它。**\n\n这个陈述有几个不正确的论断。\n$1$. **凸性**：$f(x)$ 通常不是凸的。如上所示，$f''(x) = 2(g'(x))^2 + 2(g(x) - c)g''(x)$。第二项 $2(g(x) - c)g''(x)$ 可以是负的，并且大到足以使 $f''(x)  0$。作为一个反例，令 $g(x) = \\sin(x)$ 且 $c=0$。那么 $f(x) = \\sin^2(x)$。$f''(x) = 2\\cos(2x)$，当 $x \\in (\\pi/4, 3\\pi/4)$ 时为负，所以 $f(x)$ 在此区间不是凸的。\n$2$. **没有伪局部极小值**：如选项 C 所证，当 $g(x)$ 非单调时，伪（非根）局部极小值可以并且确实存在。凸性是单峰性的一个充分（但非必要）条件。由于 $f(x)$ 不总是凸的，关于不存在伪极小值的论断是错误的。\n$3$. **总能找到任何地方的根**：GSS 是一种局部搜索方法，其搜索范围受限于初始搜索区间 $[a, b]$。它没有机制去寻找位于该区间之外的根。\n这个陈述的每个部分都是错误的。\n结论：**不正确**。",
            "answer": "$$\\boxed{ACD}$$"
        },
        {
            "introduction": "在真实世界的金融工程中，理论模型必须通过市场数据进行“校准”以保持其有效性。这个高级练习将带你进入量化金融的核心领域，应用黄金分割搜索法来校准默顿（Merton）跳跃-扩散模型中的一个关键参数——跳跃强度 $\\lambda$ 。你将通过最小化模型期权价格与市场价格之间的误差来完成校准，这充分展示了如何将一个简洁的一维搜索算法嵌入到一个复杂的金融模型中，以解决实际的参数估计问题。",
            "id": "2398577",
            "problem": "编写一个完整、可运行的程序，使用黄金分割搜索法 (GSS) 来校准 Merton 跳跃扩散模型中的跳跃强度参数 $\\lambda$。校准过程通过最小化模型价格与虚值欧式看涨期权的合成市场价格之间的定价误差平方和来实现。您的程序必须从第一性原理出发，实现定价模型和单变量优化器，并且不得依赖任何外部优化器。\n\n基本原理：\n- 在风险中性测度下，行权价为 $K$、到期日为 $T$ 的欧式看涨期权价格由风险中性期望给出：$C = e^{-r T} \\mathbb{E}\\left[(S_T - K)^{+}\\right]$。\n- 在 Merton 跳跃扩散模型中，风险中性测度下的资产动态为\n$$\n\\frac{dS_t}{S_{t^-}} = \\left(r - q - \\lambda k\\right)\\,dt + \\sigma\\, dW_t + (J - 1)\\, dN_t,\n$$\n其中 $r$ 是连续复利无风险利率，$q$ 是连续股息率，$\\sigma$ 是扩散波动率，$N_t$ 是强度为 $\\lambda$ 的泊松过程，$J$ 是跳跃大小，满足 $\\ln J \\sim \\mathcal{N}(\\mu_J,\\sigma_J^2)$。跳跃补偿项为 $k = \\mathbb{E}[J - 1] = e^{\\mu_J + \\tfrac{1}{2}\\sigma_J^2} - 1$。\n- 以 $N_T = n$ 为条件，可以得到对数正态分布的泊松混合，从而为看涨期权价格提供一个以 Black–Scholes 项的加权和表示的闭式混合形式。\n\n需要实现的定价模型：\n- 定义 $k = e^{\\mu_J + \\tfrac{1}{2}\\sigma_J^2} - 1$，有效净漂移率 $b(\\lambda) = r - q - \\lambda k$，以及每次跳跃的缩放因子 $s_J = 1 + k = e^{\\mu_J + \\tfrac{1}{2}\\sigma_J^2}$。\n- 对于每个非负整数 $n$，定义条件方差参数\n$$\n\\sigma_n = \\sqrt{\\sigma^2 + \\frac{n\\,\\sigma_J^2}{T}},\n$$\n和调整后的即期价格\n$$\nS_n = S_0\\, s_J^{\\,n}.\n$$\n- 泊松权重为\n$$\n\\pi_n(\\lambda) = e^{-\\lambda T}\\frac{(\\lambda T)^n}{n!}.\n$$\n- 具有有效净漂移率 $b(\\lambda)$ 的 Black–Scholes (BS) 看涨期权价格为\n$$\nC_{\\text{BS}}(S,K,r,q,\\sigma_n,T;b) = S\\,e^{-qT}\\,\\Phi(d_1) - K\\,e^{-rT}\\,\\Phi(d_2),\n$$\n其中\n$$\nd_1 = \\frac{\\ln\\left(\\frac{S}{K}\\right) + \\left(b + \\tfrac{1}{2}\\sigma_n^2\\right)T}{\\sigma_n \\sqrt{T}}, \\quad d_2 = d_1 - \\sigma_n \\sqrt{T},\n$$\n且 $\\Phi(\\cdot)$ 是标准正态累积分布函数。\n- Merton 看涨期权价格为\n$$\nC_{\\text{Merton}}(\\lambda; S_0, K, r, q, \\sigma, \\mu_J, \\sigma_J, T) = \\sum_{n=0}^{\\infty} \\pi_n(\\lambda)\\, C_{\\text{BS}}(S_n, K, r, q, \\sigma_n, T; b(\\lambda)).\n$$\n- 在数值实现中，通过以下方式截断无穷级数：\n  - 对 $n = 0,1,2,\\dots$ 求和，直到增量泊松权重 $\\pi_n(\\lambda)$ 低于 $10^{-12}$，或\n  - 达到硬上限 $n_{\\max} = 50$，\n  以先满足的条件为准。\n\n校准目标：\n- 给定一组虚值行权价 $\\{K_i\\}_{i=1}^m$ 和相应的市场看涨期权价格 $\\{C^{\\text{mkt}}_i\\}_{i=1}^m$，定义目标函数\n$$\nJ(\\lambda) = \\sum_{i=1}^m \\left( C_{\\text{Merton}}(\\lambda; S_0, K_i, r, q, \\sigma, \\mu_J, \\sigma_J, T) - C^{\\text{mkt}}_i \\right)^2.\n$$\n- 使用黄金分割搜索法，在闭区间 $\\lambda \\in [0, 3]$ 上通过最小化 $J(\\lambda)$ 来校准 $\\lambda$。当区间长度小于 $10^{-6}$ 或迭代次数达到 200 次时终止，以先满足的条件为准。\n\n数值细节：\n- 使用 $\\Phi(x) = \\tfrac{1}{2}\\left(1 + \\operatorname{erf}\\left(\\tfrac{x}{\\sqrt{2}}\\right)\\right)$。\n- 所有期权均为欧式看涨期权，且测试套件中的所有行权价均为严格虚值：$K > S_0$。\n- 不得使用任何随机性；所有数值必须确定性地计算。\n\n测试套件：\n对于下述每种情况，首先使用给定的“真实” $\\lambda$ 和指定的数值设置评估 Merton 价格，以生成合成市场价格。然后，丢弃真实值，并应用您的校准程序从合成市场价格中恢复 $\\widehat{\\lambda}$。\n\n- 情况 A (理想路径)：\n  - $S_0 = 100.0$, $r = 0.02$, $q = 0.0$, $T = 0.75$,\n  - $\\sigma = 0.20$, $\\mu_J = -0.10$, $\\sigma_J = 0.25$,\n  - 行权价 $K \\in \\{105.0, 110.0, 120.0\\}$,\n  - 真实 $\\lambda_{\\text{true}} = 0.60$。\n\n- 情况 B (边界情况，无跳跃)：\n  - $S_0 = 100.0$, $r = 0.01$, $q = 0.0$, $T = 1.00$,\n  - $\\sigma = 0.15$, $\\mu_J = -0.20$, $\\sigma_J = 0.30$,\n  - 行权价 $K \\in \\{102.0, 110.0, 125.0\\}$,\n  - 真实 $\\lambda_{\\text{true}} = 0.00$。\n\n- 情况 C (更高跳跃活动性)：\n  - $S_0 = 100.0$, $r = 0.03$, $q = 0.0$, $T = 2.00$,\n  - $\\sigma = 0.18$, $\\mu_J = 0.05$, $\\sigma_J = 0.20$,\n  - 行权价 $K \\in \\{105.0, 115.0, 130.0, 150.0\\}$,\n  - 真实 $\\lambda_{\\text{true}} = 1.20$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三种情况下校准的强度值，格式为用方括号括起的逗号分隔列表，每个值按 A、B、C 的顺序四舍五入到六位小数。例如，输出必须如下所示\n$$\n[\\widehat{\\lambda}_A,\\widehat{\\lambda}_B,\\widehat{\\lambda}_C],\n$$\n其中每个 $\\widehat{\\lambda}$ 都四舍五入到 6 位小数（无单位）。",
            "solution": "该问题已经过严格验证，被认为是有效的。其公式在科学上基于 Merton 跳跃扩散模型，这是金融工程领域的标准模型。该问题是适定的，为确定性优化任务提供了一套完整且内部一致的定义、参数和数值程序。目标以数学精度陈述，没有模糊性或主观内容。解决该问题所需的所有必要组件均已提供。\n\n任务是校准 Merton 跳跃扩散模型的跳跃强度参数 $\\lambda$。这通过最小化一个目标函数 $J(\\lambda)$ 来完成，该函数代表由模型生成的期权价格与一组合成市场价格之间的平方差之和。优化被限制在区间 $\\lambda \\in [0, 3]$ 内，并且必须使用从第一性原理实现的黄金分割搜索 (GSS) 算法来执行。\n\n问题的核心涉及两个主要部分的实现：Merton 定价模型和 GSS 优化器。\n\n首先，我们按照规定实现欧式看涨期权的定价模型。Merton 价格 $C_{\\text{Merton}}$ 是 Black-Scholes 类型期权价格的加权和，以期权有效期 $T$ 内发生的跳跃次数 $n$ 为条件。该价格由下式给出：\n$$\nC_{\\text{Merton}}(\\lambda) = \\sum_{n=0}^{\\infty} \\pi_n(\\lambda)\\, C_{\\text{BS}}(S_n, K, r, q, \\sigma_n, T; b(\\lambda))\n$$\n代表 $n$ 次跳跃概率的泊松权重 $\\pi_n(\\lambda)$ 为：\n$$\n\\pi_n(\\lambda) = e^{-\\lambda T}\\frac{(\\lambda T)^n}{n!}\n$$\n条件 Black-Scholes 部分 $C_{\\text{BS}}$ 是为调整后的即期价格 $S_n = S_0\\, s_J^{\\,n}$ 和条件波动率 $\\sigma_n = \\sqrt{\\sigma^2 + n\\,\\sigma_J^2/T}$ 定义的。每次跳跃的缩放因子为 $s_J = e^{\\mu_J + \\frac{1}{2}\\sigma_J^2}$。该部分的价格由下式给出：\n$$\nC_{\\text{BS}} = S_n\\,e^{-qT}\\,\\Phi(d_1) - K\\,e^{-rT}\\,\\Phi(d_2)\n$$\n其参数 $d_1$ 和 $d_2$ 依赖于有效净漂移率 $b(\\lambda) = r - q - \\lambda k$，其中 $k = s_J - 1$。$d_1$ 的具体公式为：\n$$\nd_1 = \\frac{\\ln\\left(\\frac{S_n}{K}\\right) + \\left(b(\\lambda) + \\tfrac{1}{2}\\sigma_n^2\\right)T}{\\sigma_n \\sqrt{T}}\n$$\n且 $d_2 = d_1 - \\sigma_n \\sqrt{T}$。标准正态累积分布函数 $\\Phi(\\cdot)$ 使用误差函数 $\\operatorname{erf}(\\cdot)$ 计算，即 $\\Phi(x) = \\frac{1}{2}\\left(1 + \\operatorname{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)$。在数值实现中，无穷级数被截断。求和过程对 $n=0, 1, 2, \\dots$ 进行，当项的泊松权重 $\\pi_n(\\lambda)$ 低于 $10^{-12}$ 的容差，或当已包含最多 $n_{\\max}=50$ 项时终止，以先满足的条件为准。为避免大阶乘导致的数值溢出，使用稳健的迭代方法计算泊松权重 $\\pi_n(\\lambda) = \\pi_{n-1}(\\lambda) \\cdot \\frac{\\lambda T}{n}$。\n\n其次，我们将校准目标函数 $J(\\lambda)$ 定义为一组具有不同行权价 $\\{K_i\\}_{i=1}^m$ 的 $m$ 个期权的平方误差和 (SSE)：\n$$\nJ(\\lambda) = \\sum_{i=1}^m \\left( C_{\\text{Merton}}(\\lambda; K_i) - C^{\\text{mkt}}_i \\right)^2\n$$\n其中 $C^{\\text{mkt}}_i$ 是给定的合成市场价格。\n\n第三，我们实现黄金分割搜索 (GSS) 算法来最小化 $J(\\lambda)$。GSS 是一种无导数优化方法，用于通过迭代地缩小搜索区间来寻找单峰函数的极值。搜索从区间 $[a, b] = [0, 3]$ 开始。选择两个内部点 $c$ 和 $d$，根据黄金比例 $\\phi = (1+\\sqrt{5})/2 \\approx 1.618$ 来分割区间。\n$$\nc = b - \\frac{b-a}{\\phi} \\quad \\text{和} \\quad d = a + \\frac{b-a}{\\phi}\n$$\n在这些点上评估目标函数。如果 $J(c)  J(d)$，则最小值必定位于区间 $[a, d]$ 内，因此新的搜索区间变为 $[a, d]$。否则，如果 $J(c) \\ge J(d)$，新的区间变为 $[c, b]$。这个过程在每一步都将区间长度减少一个因子 $1/\\phi$，从而保证收敛。当区间长度 $|b-a|$ 小于 $10^{-6}$ 的容差或达到最多 200 次迭代后，算法终止。最终区间的中点 $(a+b)/2$ 作为校准后的估计值 $\\widehat{\\lambda}$ 返回。\n\n整体流程首先包括为每个测试用例生成合成市场价格 $C^{\\text{mkt}}_i$，方法是在给定的“真实”强度 $\\lambda_{\\text{true}}$ 下评估指定的 $C_{\\text{Merton}}$ 函数。然后，这个真实值在概念上被丢弃，并使用 GSS 算法通过最小化 $J(\\lambda)$ 来找到最能复现这些合成价格的 $\\widehat{\\lambda}$。对所有指定的测试用例重复此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\n# Define a global constant for the Golden Ratio.\nGR = (1 + np.sqrt(5)) / 2\n\ndef norm_cdf(x):\n    \"\"\"\n    Computes the standard normal cumulative distribution function using the error function.\n    All mathematical entities must be in LaTeX: Phi(x) = 1/2 * (1 + erf(x/sqrt(2))).\n    \"\"\"\n    return 0.5 * (1 + erf(x / np.sqrt(2)))\n\ndef merton_bs_component(S, K, r, q, T, sigma_n, b):\n    \"\"\"\n    Computes a single Black-Scholes-like component of the Merton price series,\n    using the specific functional form provided in the problem statement.\n    \"\"\"\n    if sigma_n == 0 or T == 0:\n        return np.maximum(0, S * np.exp(-q*T) - K * np.exp(-r*T))\n\n    d1 = (np.log(S / K) + (b + 0.5 * sigma_n**2) * T) / (sigma_n * np.sqrt(T))\n    d2 = d1 - sigma_n * np.sqrt(T)\n    price = S * np.exp(-q * T) * norm_cdf(d1) - K * np.exp(-r * T) * norm_cdf(d2)\n    return price\n\ndef merton_price(lambda_val, S0, K, r, q, T, sigma, mu_J, sigma_J):\n    \"\"\"\n    Calculates the Merton jump-diffusion model call option price. The infinite sum\n    is truncated based on the Poisson weight or a maximum number of terms.\n    \"\"\"\n    # Jump-related parameters, constant with respect to lambda\n    k = np.exp(mu_J + 0.5 * sigma_J**2) - 1\n    s_J = 1 + k\n    \n    # Lambda-dependent effective drift\n    b = r - q - lambda_val * k\n    \n    total_price = 0.0\n    lambda_T = lambda_val * T\n    \n    n_max = 50\n    weight_tol = 1e-12\n\n    # Term for n=0 jumps (pure diffusion component)\n    poisson_weight = np.exp(-lambda_T)\n    sigma_0 = sigma\n    component_price_0 = merton_bs_component(S0, K, r, q, T, sigma_0, b)\n    total_price += poisson_weight * component_price_0\n    \n    # Terms for n=1 to n_max jumps\n    for n in range(1, n_max + 1):\n        poisson_weight *= lambda_T / n\n        if poisson_weight  weight_tol:\n            break\n        \n        sigma_n = np.sqrt(sigma**2 + n * sigma_J**2 / T)\n        S_n = S0 * (s_J**n)\n        \n        component_price = merton_bs_component(S_n, K, r, q, T, sigma_n, b)\n        total_price += poisson_weight * component_price\n        \n    return total_price\n\ndef objective_function(lambda_val, S0, r, q, T, sigma, mu_J, sigma_J, strikes, market_prices):\n    \"\"\"\n    Calculates the sum of squared errors (SSE) between model prices and market prices.\n    This is the function to be minimized.\n    \"\"\"\n    sse = 0.0\n    for i in range(len(strikes)):\n        model_price = merton_price(lambda_val, S0, strikes[i], r, q, T, sigma, mu_J, sigma_J)\n        sse += (model_price - market_prices[i])**2\n    return sse\n\ndef golden_section_search(f, a, b, tol=1e-6, max_iter=200):\n    \"\"\"\n    Performs Golden-Section Search to find the minimum of a univariate function 'f'\n    on the interval [a, b].\n    \"\"\"\n    inv_phi = 1 / GR\n    \n    # Initialize interior points\n    c = b - inv_phi * (b - a)\n    d = a + inv_phi * (b - a)\n    \n    fc = f(c)\n    fd = f(d)\n    \n    for _ in range(max_iter):\n        if abs(b - a)  tol:\n            break\n            \n        if fc  fd:\n            b = d\n            d = c\n            fd = fc\n            c = b - inv_phi * (b - a)\n            fc = f(c)\n        else:\n            a = c\n            c = d\n            fc = fd\n            d = a + inv_phi * (b - a)\n            fd = f(d)\n            \n    return (a + b) / 2\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite, calibrate lambda for each case, and print results.\n    \"\"\"\n    test_cases = [\n        # Case A: Happy path\n        {'S0': 100.0, 'r': 0.02, 'q': 0.0, 'T': 0.75, 'sigma': 0.20,\n         'mu_J': -0.10, 'sigma_J': 0.25, 'strikes': [105.0, 110.0, 120.0],\n         'lambda_true': 0.60},\n        # Case B: Boundary case, no jumps\n        {'S0': 100.0, 'r': 0.01, 'q': 0.0, 'T': 1.00, 'sigma': 0.15,\n         'mu_J': -0.20, 'sigma_J': 0.30, 'strikes': [102.0, 110.0, 125.0],\n         'lambda_true': 0.00},\n        # Case C: Higher jump activity\n        {'S0': 100.0, 'r': 0.03, 'q': 0.0, 'T': 2.00, 'sigma': 0.18,\n         'mu_J': 0.05, 'sigma_J': 0.20, 'strikes': [105.0, 115.0, 130.0, 150.0],\n         'lambda_true': 1.20}\n    ]\n    \n    calibrated_lambdas = []\n    \n    for case in test_cases:\n        # 1. Generate synthetic market prices using the true lambda\n        market_prices = [\n            merton_price(case['lambda_true'], case['S0'], K, case['r'], case['q'], case['T'],\n                         case['sigma'], case['mu_J'], case['sigma_J'])\n            for K in case['strikes']\n        ]\n\n        # 2. Define objective function for this case, capturing all parameters except lambda\n        obj_func = lambda l: objective_function(\n            l, case['S0'], case['r'], case['q'], case['T'], case['sigma'],\n            case['mu_J'], case['sigma_J'], case['strikes'], market_prices\n        )\n\n        # 3. Run Golden-Section Search to find the calibrated lambda\n        lambda_hat = golden_section_search(obj_func, a=0.0, b=3.0, tol=1e-6, max_iter=200)\n        calibrated_lambdas.append(lambda_hat)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{l:.6f}' for l in calibrated_lambdas])}]\")\n\nsolve()\n```"
        }
    ]
}