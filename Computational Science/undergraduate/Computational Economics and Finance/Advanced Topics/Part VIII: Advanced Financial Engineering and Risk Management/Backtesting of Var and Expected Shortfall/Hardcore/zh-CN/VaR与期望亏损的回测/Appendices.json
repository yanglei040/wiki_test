{
    "hands_on_practices": [
        {
            "introduction": "风险价值（$VaR$）回测的一个基本检验是其无条件覆盖率，它只关心违约发生的频率。本练习旨在通过一个精心设计的思想实验，揭示这种方法的内在局限性。您将构建一个看似完美的$VaR$模型，其违约频率恰好符合预期，因此能够通过标准的Kupiec测试，但该模型系统性地低估了尾部风险的严重性，从而突显了期望损失（$ES$）在捕捉极端损失方面的重要性。",
            "id": "2374206",
            "problem": "你需要通过构建合成的损益（PL）数据和一个故意错误设定的 VaR 模型来展示使用风险价值（VaR）进行回测的局限性。这个模型需要满足无条件覆盖检验，同时隐藏了对于期望损失（ES）来说显而易见的极端尾部严重性。你必须实现一个完整的程序，从第一性原理出发产生确定性的输出。\n\n使用的基本定义：\n- 损失由序列 $\\{L_t\\}_{t=1}^T$ 表示，其中 $L_t \\ge 0$ 表示在时间 $t$ 的损失。\n- 在尾部概率水平 $\\alpha \\in (0,1)$ 下的风险价值（VaR）是满足 $\\mathbb{P}(L_t \\le v_\\alpha) \\ge 1 - \\alpha$ 的最小阈值 $v_\\alpha$。当一个模型提供一系列 $\\{v_t\\}_{t=1}^T$ 的单步向前 VaR 预测时，在时间 $t$ 的一次违例是事件 $L_t > v_t$。\n- 超额指标为 $I_t = \\mathbf{1}\\{L_t > v_t\\}$。在正确的无条件覆盖下，序列 $\\{I_t\\}$ 是一个成功概率为 $\\alpha$ 的独立同分布的伯努利过程。\n- 在水平 $\\alpha$ 下的期望损失（ES）是在损失超过 VaR 阈值的条件下，损失的条件期望：$\\mathrm{ES}_\\alpha = \\mathbb{E}[L_t \\mid L_t > v_\\alpha]$。\n- Kupiec 无条件覆盖似然比（LR）检验比较了在原假设违例概率 $\\alpha$ 下的伯努利似然与在最大似然估计 $\\hat{p}$ 下的似然。原假设是无条件违例率等于 $\\alpha$。LR 统计量渐近服从自由度为 1 的 $\\chi^2$ 分布，你必须据此计算一个 p 值，并确定在显著性水平 0.05 下，检验是否未能拒绝原假设。\n\n你的任务：\n1. 对于每个提供的测试案例，构建一个合成的损失序列 $\\{L_t\\}_{t=1}^T$ 和一个恒定的 VaR 预测序列 $\\{v_t\\}_{t=1}^T$，其中 $v_t \\equiv v$，使得：\n   - 恰好有 $x = \\alpha T$ 个时间点是违例，在这些违例时间点上 $L_t = 10 v$。\n   - 所有其他时间点都是非违例，其上 $L_t = 0.5 v$。\n   - 注意：所有数学实体，包括 $10$、$0.5$ 和 $x$，都必须在你的构建中作为约束被遵守。\n2. 根据构建的 $\\{L_t\\}$ 和 $\\{v_t\\}$，计算超额指标 $\\{I_t\\}$ 和每个案例的违例次数 $x = \\sum_{t=1}^T I_t$。\n3. 对每个案例，仅基于伯努利似然原理和自由度为 1 的渐近 $\\chi^2$ 分布，实现 Kupiec 无条件覆盖似然比检验。使用此检验计算 p 值和一个布尔值，该布尔值指示检验在显著性水平 0.05 下是否未能拒绝原假设。\n4. 计算每个案例的已实现期望损失比率，定义为当 $x \\ge 1$ 时，$M = \\left(\\frac{1}{x} \\sum_{t=1}^T I_t L_t\\right) / v$。在你的构造中，这个比率应该能揭示相对于模型 VaR 水平的系统性尾部严重性。\n5. 你的实现必须是确定性的，并且不得依赖任何外部随机性。\n\n测试套件：\n你必须在以下参数集 $(T,\\alpha,v)$ 上运行你的程序，其中 $T$ 是长度，$\\alpha$ 是小数形式的违例概率， $v$ 是恒定的 VaR 水平：\n- 案例 A: $(T,\\alpha,v) = (1000, 0.01, 1.0)$\n- 案例 B: $(T,\\alpha,v) = (250, 0.04, 2.0)$\n- 案例 C: $(T,\\alpha,v) = (200, 0.055, 0.5)$\n- 案例 D (小样本覆盖检验): $(T,\\alpha,v) = (20, 0.1, 3.0)$\n\n对于每个案例，按此确切顺序输出包含三个项目的列表：\n- 一个布尔值，指示 Kupiec 检验在显著性水平 0.05 下是否未能拒绝。\n- Kupiec 检验的 p 值，为浮点数。\n- 已实现的期望损失比率 $M$，为浮点数。\n\n最终输出格式：\n- 你的程序应生成单行输出，包含一个由各案例结果组成的列表，其中每个案例结果是按上述顺序排列的三元素列表。例如，最终的单行输出应如下所示：\n- $[\\,[\\text{True}, 1.0, 10.0], [\\text{True}, 0.9999, 10.0]\\,]$\n- 你的代码必须精确打印一行此列表，不含任何额外文本。\n\n重要实现说明：\n- 将违例视为 $L_t > v_t$，其中损失和 VaR 均为非负数。\n- 确保在提供的每个测试案例中，$x = \\alpha T$ 都是一个整数。不要随机化违例的位置；一个简单的确定性放置是可以接受的。\n- 对于 Kupiec 决策，使用 0.05 的显著性水平。\n- 角度和物理单位不适用。百分比必须表示为小数，给定的 $\\alpha$ 值已满足此要求。",
            "solution": "所述问题是有效的。它在科学上基于金融风险管理的原则，特别是风险模型的回测。所有定义和约束都定义良好、完整且一致，从而能够得到一个独特而有意义的解决方案。任务是构建一个特定场景，以说明与期望损失 ($ES$) 相比，风险价值 ($VaR$) 的一个已知局限性。\n\n目标是创建一个合成的损益 ($PL$) 历史，由损失序列 $\\{L_t\\}_{t=1}^T$ 表示，以及一个相应的单步向前 $VaR$ 预测序列 $\\{v_t\\}_{t=1}^T$。这种构建必须是故意错误设定的，以使 $VaR$ 模型通过标准回测——Kupiec 无条件覆盖检验——同时隐藏对尾部损失幅度的严重低估，而这是一个基于 $ES$ 的指标会暴露的缺陷。\n\n首先，我们处理每个给定测试案例（即参数三元组 $(T, \\alpha, v)$）的合成数据构建。$T$ 是时间周期的总数，$\\alpha$ 是目标违例概率，$v$ 是恒定的 $VaR$ 预测水平。\n\n问题规定了一个恒定的 $VaR$ 预测：\n$$ v_t = v \\quad \\forall t \\in \\{1, \\dots, T\\} $$\n\n在时间 $t$ 的一次违例或超额，被定义为事件 $L_t > v_t$。构造要求违例总数 $x$ 必须恰好为 $x = \\alpha T$。对于所提供的测试案例，这个乘积是一个整数。为确保确定性，我们可以将这 $x$ 次违例放在时间序列的开头，从 $t=1$ 到 $t=x$。\n\n损失值指定如下：\n- 对于违例周期（$t \\in \\{1, \\dots, x\\}$）：$L_t = 10v$。这满足违例条件 $L_t > v$，因为 $v$ 必须为正。\n- 对于非违例周期（$t \\in \\{x+1, \\dots, T\\}$）：$L_t = 0.5v$。这不构成违例，因为 $0.5v \\ngtr v$。\n\n因此，超额指标序列 $\\{I_t\\}_{t=1}^T$ 为：$t \\in \\{1, \\dots, x\\}$ 时 $I_t = 1$，$t \\in \\{x+1, \\dots, T\\}$ 时 $I_t = 0$。\n\n接下来，我们执行 Kupiec 无条件覆盖似然比 ($LR$) 检验。原假设 $H_0$ 是真实违例概率为 $p = \\alpha$。检验统计量基于在 $H_0$ 下观测数据的似然与在最大似然估计 $\\hat{p} = x/T$ 下的似然进行比较。$LR$ 统计量由下式给出：\n$$ LR_{uc} = 2 \\ln \\left( \\frac{L(\\hat{p})}{L(\\alpha)} \\right) = 2 \\ln \\left( \\frac{\\hat{p}^x (1 - \\hat{p})^{T-x}}{\\alpha^x (1-\\alpha)^{T-x}} \\right) $$\n该表达式可以重写为：\n$$ LR_{uc} = 2 \\left[ x \\ln\\left(\\frac{\\hat{p}}{\\alpha}\\right) + (T-x) \\ln\\left(\\frac{1-\\hat{p}}{1-\\alpha}\\right) \\right] $$\n通过我们的特定构造，违例次数为 $x = \\alpha T$。因此，经验违例率为 $\\hat{p} = x/T = (\\alpha T)/T = \\alpha$。将 $\\hat{p} = \\alpha$ 代入 $LR_{uc}$ 公式可得：\n$$ LR_{uc} = 2 \\left[ (\\alpha T) \\ln\\left(\\frac{\\alpha}{\\alpha}\\right) + (T-\\alpha T) \\ln\\left(\\frac{1-\\alpha}{1-\\alpha}\\right) \\right] = 2 \\left[ (\\alpha T) \\ln(1) + T(1-\\alpha) \\ln(1) \\right] = 0 $$\n$LR_{uc}$ 统计量因此恒等于零。该统计量渐近服从自由度为 1 的卡方分布 $\\chi^2(1)$。检验的 p 值是观测到至少与计算出的检验统计量一样极端的概率，即 $P(\\chi^2(1) \\ge LR_{uc})$。当 $LR_{uc}=0$ 时，p 值为：\n$$ p\\text{-value} = \\int_0^\\infty f(z; 1) dz = 1 $$\n其中 $f(z; 1)$ 是 $\\chi^2(1)$ 分布的概率密度函数。如果 p 值低于显著性水平（此处为 0.05），则拒绝原假设。由于 $1.0 > 0.05$，我们对所有测试案例都无条件地未能拒绝原假设。$VaR$ 模型完美地通过了覆盖检验。\n\n最后，我们使用已实现的期望损失比率 $M$ 来分析模型在尾部损失幅度方面的表现。它被定义为违例日的经验平均损失与 $VaR$ 水平的比率：\n$$ M = \\frac{\\frac{1}{x} \\sum_{t=1}^T I_t L_t}{v} $$\n总和 $\\sum_{t=1}^T I_t L_t$ 代表了所有 $x$ 个违例日的总损失。根据我们的构造，在这些天中的每一天，损失为 $L_t = 10v$。因此，总和为 $x \\cdot 10v$。违例日的平均损失是：\n$$ \\frac{1}{x} \\sum_{t=1}^T I_t L_t = \\frac{x \\cdot 10v}{x} = 10v $$\n这是经验的，或已实现的期望损失。比率 $M$ 接着是：\n$$ M = \\frac{10v}{v} = 10 $$\n这个在所有测试案例中都恒定的结果揭示了模型的关键缺陷。当发生违例时，由此产生的损失平均比 $VaR$ 阈值大 10 倍。一个简单的覆盖检验对这种系统性的、严重的尾部损失分布风险低估是无视的。这证明了像 $ES$ 这样的一致性风险度量的优越性，它不仅考虑了尾部损失的频率，还考虑了其严重性。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Solves the problem of demonstrating VaR backtesting limitations.\n    For each test case, it computes the Kupiec test result and the realized ES ratio.\n    \"\"\"\n    test_cases = [\n        # (T, alpha, v)\n        (1000, 0.01, 1.0),\n        (250, 0.04, 2.0),\n        (200, 0.055, 0.5),\n        (20, 0.1, 3.0),\n    ]\n\n    results = []\n    significance_level = 0.05\n\n    for T, alpha, v in test_cases:\n        # Per problem statement, x = alpha * T is an integer for all test cases.\n        # This setup is deterministic.\n        x = int(T * alpha)\n        \n        # 1. Kupiec Unconditional Coverage Test\n        # The null hypothesis is that the violation probability is alpha.\n        # The test statistic LR_uc = 2 * ln(L(p_hat) / L(alpha)).\n        # By construction, the observed violation rate p_hat = x / T = alpha.\n        # This forces the LR statistic to be 0 and the p-value to be 1.\n        # We implement the full formula for formal verification.\n\n        lr_stat = 0.0\n        if x == 0:\n            # log(p_hat) term is undefined, but limit of p_hat*log(p_hat) is 0.\n            # LR = 2* T * log(1/(1-alpha))\n            lr_stat = 2 * (T * np.log(1 / (1 - alpha)))\n        elif x == T:\n            # log(1-p_hat) term is undefined.\n            # LR = 2 * T * log(1/alpha)\n            lr_stat = 2 * (T * np.log(1 / alpha))\n        else:\n            p_hat = x / T\n            # Due to problem design, p_hat is exactly alpha.\n            # np.log(p_hat / alpha) will be np.log(1.0) = 0.\n            # The formula is robust to minor floating point inaccuracies if any existed.\n            term1 = x * np.log(p_hat / alpha)\n            term2 = (T - x) * np.log((1 - p_hat) / (1 - alpha))\n            lr_stat = 2 * (term1 + term2)\n\n        # p-value from chi-squared distribution with 1 degree of freedom\n        p_value = float(chi2.sf(lr_stat, df=1))\n\n        # Decision: Fail to reject H0 if p-value is not less than significance level\n        k_test_fails_to_reject = p_value >= significance_level\n\n        # 2. Realized Expected Shortfall Ratio (M)\n        # M = (average loss on violation days) / VaR\n        # Loss on violation days is L_t = 10 * v\n        # Average loss is therefore (x * 10 * v) / x = 10 * v\n        # M = (10 * v) / v = 10\n        es_ratio = 0.0\n        if x > 0:\n            # The calculation is analytically 10, as shown in the solution notes.\n            # Average loss conditional on violation = 10 * v\n            # Ratio M = (10 * v) / v\n            es_ratio = 10.0\n        # The problem statement defines M for x >= 1, so no else case is needed\n        # for the given test suite.\n\n        results.append([k_test_fails_to_reject, p_value, es_ratio])\n\n    # Final print statement must match the specified format exactly.\n    # The format from the template is f\"[{','.join(map(str, results))}]\"\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个可靠的风险模型不仅应准确预测违约的频率，还应确保这些违约事件在时间上是独立的，不存在可预测的聚集模式。本练习将引导您构建一个$VaR$违约序列，其总违约次数符合预期，但所有违约都集中在每周的同一天发生。通过应用Christoffersen的条件覆盖率测试，您将亲自验证为何仅满足无条件覆盖率是不够的，以及为何独立性检验对于识别风险模型中隐藏的系统性缺陷至关重要。",
            "id": "2374172",
            "problem": "您的任务是构建并评估一个风险价值（VaR）例外过程，该过程在指定的概率水平上具有正确的无条件覆盖率，但表现出系统性的时间选择性。考虑一个交易日历，它由一个重复的五天工作周组成，其中的日子用整数标记，星期一为第 $0$ 天，星期二为第 $1$ 天，星期三为第 $2$ 天，星期四为第 $3$ 天，星期五为第 $4$ 天。令 $T$ 表示交易总天数，由 $t \\in \\{0,1,\\ldots,T-1\\}$ 索引；令 $\\alpha \\in (0,1)$ 表示名义 VaR 例外概率水平。定义 VaR 例外指示序列 $\\{I_t\\}_{t=0}^{T-1}$ 为 $I_t \\in \\{0,1\\}$，其中 $I_t=1$ 表示第 $t$ 天是一个 VaR 例外，否则 $I_t=0$。待评估的模型必须同时满足以下两个属性：\n- 在 $T$ 天内的例外总数恰好等于 $\\alpha T$。\n- 所有例外只发生在星期一。\n\n假设第一个观测值的起始星期已知，表示为 $s \\in \\{0,1,2,3,4\\}$，其中 $s=0$ 对应星期一。时间 $t$ 对应的星期是 $(s+t) \\bmod 5$。模型应在样本中最早的几个星期一上放置恰好 $\\alpha T$ 个例外，对于那些星期一的索引，$I_t=1$，否则 $I_t=0$。您可以假设 $\\alpha T$ 是一个整数，并且样本中星期一的数量至少为 $\\alpha T$。\n\n令 $\\{I_t\\}$ 接受 Christoffersen 回测框架的检验，该框架包括：\n- 无条件覆盖假设，即例外概率等于 $\\alpha$。\n- 独立性假设，即例外在时间上是独立的。\n- 条件覆盖假设，即无条件覆盖和独立性联合成立。\n\n使用 Christoffersen 框架中定义的似然比统计量，并为每个检验报告：\n- 无条件覆盖的似然比统计量，记为 $LR_{\\mathrm{uc}}$。\n- 独立性的似然比统计量，记为 $LR_{\\mathrm{ind}}$。\n- 条件覆盖统计量 $LR_{\\mathrm{cc}} = LR_{\\mathrm{uc}} + LR_{\\mathrm{ind}}$。\n- 相应的 $p$ 值，根据自由度分别为 $1$（对于 $LR_{\\mathrm{uc}}$）、$1$（对于 $LR_{\\mathrm{ind}}$）和 $2$（对于 $LR_{\\mathrm{cc}}$）的卡方分布计算。\n- 每个原假设在显著性水平 $\\delta=0.05$ 下的二元拒绝决策，以布尔值表示。\n\n您的程序必须为以下参数三元组 $(T,\\alpha,s)$ 的测试套件实现此构建和分析：\n- 测试 $1$：$(T,\\alpha,s) = (500, 0.05, 0)$。\n- 测试 $2$：$(T,\\alpha,s) = (495, 0.20, 3)$。\n- 测试 $3$：$(T,\\alpha,s) = (100, 0.10, 1)$。\n- 测试 $4$：$(T,\\alpha,s) = (500, 0.01, 4)$。\n- 测试 $5$：$(T,\\alpha,s) = (250, 0.04, 2)$。\n\n对于每个测试，按以下顺序输出一个包含九个值的列表：\n$[LR_{\\mathrm{uc}}, p_{\\mathrm{uc}}, LR_{\\mathrm{ind}}, p_{\\mathrm{ind}}, LR_{\\mathrm{cc}}, p_{\\mathrm{cc}}, \\text{reject}_{\\mathrm{uc}}, \\text{reject}_{\\mathrm{ind}}, \\text{reject}_{\\mathrm{cc}}]$，其中 $p_{\\mathrm{uc}}$、$p_{\\mathrm{ind}}$ 和 $p_{\\mathrm{cc}}$ 是 $p$ 值，而 `reject_uc`、`reject_ind`、`reject_cc` 是表示在显著性水平 $\\delta=0.05$ 下是否拒绝的布尔值。\n\n最终输出格式：您的程序应生成单行输出，其中包含所有五个测试的结果，格式为一个由逗号分隔的九元素列表组成的列表，并用方括号括起来，例如 $[\\ldots]$。所有概率都必须表示为小数，而不是百分比符号。",
            "solution": "我们从第一性原理出发，对 VaR 例外指示序列和 Christoffersen 检验进行形式化。令 $T \\in \\mathbb{N}$ 为交易天数，$\\alpha \\in (0,1)$ 为名义例外概率。定义指示符 $I_t \\in \\{0,1\\}$（对于 $t \\in \\{0,1,\\ldots,T-1\\}$），其构建规则如下：\n- 计算对应于星期一的索引集合 $\\mathcal{M} = \\{t \\in \\{0,\\ldots,T-1\\} : (s+t) \\bmod 5 = 0\\}$，其中 $s \\in \\{0,1,2,3,4\\}$ 是第一个观测值对应的星期，0 代表星期一。\n- 令 $K = \\alpha T$。根据假设，$K$ 是一个整数且 $|\\mathcal{M}| \\ge K$。\n- 对 $\\mathcal{M}$ 中按 $t$ 升序排列的前 $K$ 个元素设置 $I_t = 1$，对所有其他索引设置 $I_t = 0$。这确保了所有例外都发生在星期一，并且例外总数等于 $\\alpha T$。\n\nChristoffersen 的无条件覆盖检验考虑假设\n$H_0^{\\mathrm{uc}}: \\mathbb{P}(I_t=1) = \\alpha$，\n该假设陈述了例外概率等于 $\\alpha$。令 $N_1 = \\sum_{t=0}^{T-1} I_t$ 且 $N_0 = T - N_1$。在 $H_0^{\\mathrm{uc}}$ 下，对于成功概率为 $\\alpha$ 的独立伯努利试验，其似然函数为\n$$\nL_0^{\\mathrm{uc}} = (1-\\alpha)^{N_0} \\alpha^{N_1}.\n$$\n无约束似然（在 $\\pi \\in [0,1]$ 上最大化）在 $\\hat{\\pi} = N_1/T$ 处取得，得到\n$$\nL_1^{\\mathrm{uc}} = (1-\\hat{\\pi})^{N_0} \\hat{\\pi}^{N_1}.\n$$\n似然比统计量为\n$$\nLR_{\\mathrm{uc}} = -2 \\left[ \\ln L_0^{\\mathrm{uc}} - \\ln L_1^{\\mathrm{uc}} \\right]\n= 2 \\left[ N_1 \\ln\\left(\\frac{N_1}{\\alpha T}\\right) + N_0 \\ln\\left(\\frac{N_0}{(1-\\alpha)T}\\right) \\right],\n$$\n约定形式为 $0 \\cdot \\ln(0)$ 的项被处理为 $0$。在 $H_0^{\\mathrm{uc}}$ 下，$LR_{\\mathrm{uc}}$ 渐近服从自由度为 $1$ 的卡方分布。\n\n独立性检验考虑序列 $\\{I_t\\}$ 中的一阶马尔可夫依赖性。定义在 $t=1,\\ldots,T-1$ 上的转移计数：\n- $N_{ij} = \\#\\{t \\in \\{1,\\ldots,T-1\\} : I_{t-1}=i, I_t=j\\}$ for $i,j \\in \\{0,1\\}$。\n令 $N_{0\\cdot} = N_{00} + N_{01}$ 且 $N_{1\\cdot} = N_{10} + N_{11}$。在无约束一阶马尔可夫备择假设下，最大似然估计量为\n$$\n\\hat{p}_{01} = \\frac{N_{01}}{N_{0\\cdot}} \\ \\text{ if } N_{0\\cdot}  0, \\quad\n\\hat{p}_{11} = \\frac{N_{11}}{N_{1\\cdot}} \\ \\text{ if } N_{1\\cdot}  0,\n$$\n如果分母为零，则进行自然的边界处理。无约束对数似然为\n$$\n\\ln L_1^{\\mathrm{ind}} = N_{00}\\ln(1-\\hat{p}_{01}) + N_{01}\\ln(\\hat{p}_{01}) + N_{10}\\ln(1-\\hat{p}_{11}) + N_{11}\\ln(\\hat{p}_{11}),\n$$\n其中任何系数为零的项都按零处理。在具有共同成功概率 $\\pi$ 的独立性原假设下，基于转移的最大似然估计量为\n$$\n\\hat{\\pi} = \\frac{N_{01} + N_{11}}{N_{00} + N_{01} + N_{10} + N_{11}} = \\frac{N_{01} + N_{11}}{T-1},\n$$\n且受约束的对数似然为\n$$\n\\ln L_0^{\\mathrm{ind}} = (N_{00}+N_{10})\\ln(1-\\hat{\\pi}) + (N_{01}+N_{11})\\ln(\\hat{\\pi}).\n$$\n独立性似然比统计量为\n$$\nLR_{\\mathrm{ind}} = -2\\left[\\ln L_0^{\\mathrm{ind}} - \\ln L_1^{\\mathrm{ind}}\\right],\n$$\n在独立性原假设下，该统计量渐近服从自由度为 $1$ 的卡方分布。\n\n条件覆盖统计量结合了这两个部分：\n$$\nLR_{\\mathrm{cc}} = LR_{\\mathrm{uc}} + LR_{\\mathrm{ind}},\n$$\n在联合原假设下，该统计量渐近服从自由度为 $2$ 的卡方分布。\n\n对于每个测试用例 $(T,\\alpha,s)$，我们按照规定构建 $\\{I_t\\}$，计算 $N_1$、$N_0$ 和转移计数 $N_{ij}$，然后使用具有适当自由度的卡方分布的生存函数来评估 $LR_{\\mathrm{uc}}$、$LR_{\\mathrm{ind}}$ 和 $LR_{\\mathrm{cc}}$ 及其 $p$ 值。通过将每个 $p$ 值与 $\\delta = 0.05$ 进行比较来做出拒绝决策。因为该构造强制要求 $N_1 = \\alpha T$ 精确成立，所以我们有 $\\hat{\\pi} = \\alpha$，因此对于所有测试用例，$LR_{\\mathrm{uc}} = 0$ 恒成立，这意味着在任何常规水平上都不会拒绝无条件覆盖假设。然而，将所有例外集中在星期一会引发相对于日历时间的序列依赖性，这可以通过独立性检验来检测，因为转移概率不同，特别是 $\\hat{p}_{11} = 0$（没有连续的例外）和 $\\hat{p}_{01}  0$，这会增加 $LR_{\\mathrm{ind}}$ 并通常导致拒绝独立性和条件覆盖假设，尤其是在 $T$ 和 $\\alpha T$ 增加时。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef build_monday_exception_series(T: int, alpha: float, start_day: int) - np.ndarray:\n    \"\"\"\n    Construct an exception indicator series I_t of length T such that:\n    - Exactly K = alpha*T exceptions occur (assumed integer),\n    - All exceptions occur on Mondays (weekday index 0),\n    - The first observation has weekday 'start_day' in {0,..,4}.\n    \"\"\"\n    K = int(round(alpha * T))\n    I = np.zeros(T, dtype=int)\n    monday_indices = [t for t in range(T) if ((start_day + t) % 5) == 0]\n    if K  len(monday_indices):\n        raise ValueError(\"Not enough Mondays to place all exceptions.\")\n    # Place exceptions on the earliest Mondays\n    for t in monday_indices[:K]:\n        I[t] = 1\n    return I\n\ndef safe_log(x: float) - float:\n    \"\"\"Natural log with handling for x in {0,1} when multiplied by zero counts later.\"\"\"\n    # We will never call log(0) multiplied by positive coefficient if model is set correctly\n    # But to be safe, cap x in (0,1) open interval with tiny epsilon\n    eps = 1e-16\n    if x == 0.0:\n        x = eps\n    elif x = 1.0:\n        x = 1.0 - eps\n    return np.log(x)\n\ndef lr_uc(I: np.ndarray, alpha: float) - float:\n    \"\"\"\n    Christoffersen's unconditional coverage LR statistic.\n    LR_uc = 2 * [ N1*ln(N1/(alpha*T)) + N0*ln(N0/((1-alpha)*T)) ] with 0*ln(0)=0.\n    \"\"\"\n    T = I.size\n    N1 = int(I.sum())\n    N0 = T - N1\n    # Handle 0*ln(0) - 0 via conditional terms\n    term1 = 0.0 if N1 == 0 else N1 * np.log(N1 / (alpha * T))\n    term0 = 0.0 if N0 == 0 else N0 * np.log(N0 / ((1.0 - alpha) * T))\n    LR = 2.0 * (term1 + term0)\n    # Numerical cleanup: LR cannot be negative\n    return float(max(LR, 0.0))\n\ndef lr_ind(I: np.ndarray) - float:\n    \"\"\"\n    Christoffersen's independence LR statistic based on 2x2 transition counts.\n    \"\"\"\n    # Compute transitions\n    I_prev = I[:-1]\n    I_curr = I[1:]\n    N00 = int(np.sum((I_prev == 0)  (I_curr == 0)))\n    N01 = int(np.sum((I_prev == 0)  (I_curr == 1)))\n    N10 = int(np.sum((I_prev == 1)  (I_curr == 0)))\n    N11 = int(np.sum((I_prev == 1)  (I_curr == 1)))\n\n    N0dot = N00 + N01\n    N1dot = N10 + N11\n    Ntrans = N0dot + N1dot  # equals len(I)-1\n\n    # Unrestricted MLEs with boundary handling\n    p01_hat = 0.0 if N0dot == 0 else N01 / N0dot\n    p11_hat = 0.0 if N1dot == 0 else N11 / N1dot\n\n    # Log-likelihood under alternative (Markov)\n    ll1 = 0.0\n    if N00  0:\n        ll1 += N00 * safe_log(1.0 - p01_hat)\n    if N01  0:\n        ll1 += N01 * safe_log(p01_hat)\n    if N10  0:\n        ll1 += N10 * safe_log(1.0 - p11_hat)\n    if N11  0:\n        ll1 += N11 * safe_log(p11_hat)\n\n    # Restricted MLE under independence\n    pi_hat = 0.0 if Ntrans == 0 else (N01 + N11) / Ntrans\n    ll0 = 0.0\n    if (N00 + N10)  0:\n        ll0 += (N00 + N10) * safe_log(1.0 - pi_hat)\n    if (N01 + N11)  0:\n        ll0 += (N01 + N11) * safe_log(pi_hat)\n\n    LR = -2.0 * (ll0 - ll1)\n    return float(max(LR, 0.0))\n\ndef analyze_case(T: int, alpha: float, start_day: int, sig: float = 0.05):\n    I = build_monday_exception_series(T, alpha, start_day)\n    LR_uc = lr_uc(I, alpha)\n    LR_ind = lr_ind(I)\n    LR_cc = LR_uc + LR_ind\n\n    # p-values from chi-square distributions\n    p_uc = chi2.sf(LR_uc, df=1)\n    p_ind = chi2.sf(LR_ind, df=1)\n    p_cc = chi2.sf(LR_cc, df=2)\n\n    reject_uc = p_uc  sig\n    reject_ind = p_ind  sig\n    reject_cc = p_cc  sig\n\n    return LR_uc, p_uc, LR_ind, p_ind, LR_cc, p_cc, reject_uc, reject_ind, reject_cc\n\ndef format_result(result_tuple):\n    # Format floats to 6 decimals, booleans as True/False\n    formatted = []\n    for i, v in enumerate(result_tuple):\n        if isinstance(v, float):\n            formatted.append(f\"{v:.6f}\")\n        elif isinstance(v, (np.floating,)):\n            formatted.append(f\"{float(v):.6f}\")\n        elif isinstance(v, (bool, np.bool_)):\n            formatted.append(\"True\" if bool(v) else \"False\")\n        else:\n            formatted.append(str(v))\n    return \"[\" + \",\".join(formatted) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is (T, alpha, start_day)\n    test_cases = [\n        (500, 0.05, 0),  # Test 1\n        (495, 0.20, 3),  # Test 2\n        (100, 0.10, 1),  # Test 3\n        (500, 0.01, 4),  # Test 4\n        (250, 0.04, 2),  # Test 5\n    ]\n\n    results = []\n    for case in test_cases:\n        T, alpha, start_day = case\n        result = analyze_case(T, alpha, start_day, sig=0.05)\n        results.append(format_result(result))\n\n    # Final print statement in the exact required format: a single line with a list of lists\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "在量化模型构建中，一个常见且隐蔽的错误是“前视偏差”（look-ahead bias），即在预测中无意使用了未来的信息。本练习旨在通过实践揭示这种偏差的欺骗性影响。您将对比一个遵循正确时间顺序的基准风险模型与一个包含“幽灵特征”（即包含了当日回报信息）的错误模型，通过计算各种回测指标，量化由前视偏差带来的虚假“优势”，从而深刻理解在模型开发中严格遵守数据时间顺序的至关重要性。",
            "id": "2374186",
            "problem": "您将实现并比较两种用于风险价值（VaR）和期望损失（ES）的滚动高斯风险模型，并量化包含“幽灵特征”（来自未来的信息）如何影响标准回测结果。所有计算都将在从指定的条件异方差过程生成的合成收益序列上执行。您的程序必须是独立自足的，产生确定性结果，并按下文规定输出一个浮点数列表。\n\n定义和假设：\n- 令 $\\alpha \\in (0,1)$ 表示VaR和期望损失的尾部概率水平。\n- 时间 $t$ 的向前一步收益为 $r_t$。负值代表损失。\n- 在条件均值为零、条件标准差为 $\\sigma_t$ 的高斯模型下，$\\alpha$-分位数（左尾）为 $q_\\alpha = \\Phi^{-1}(\\alpha)$，其中 $\\Phi^{-1}(\\cdot)$ 是标准正态分布的逆累积分布函数。条件VaR预测为 $\\widehat{\\text{VaR}}_t = q_\\alpha \\sigma_t$。\n- 期望损失是尾部的条件期望。对于一个标准正态随机变量 $Z$，其截断均值满足 $\\mathbb{E}[Z \\mid Z \\le q_\\alpha] = -\\varphi(q_\\alpha)/\\alpha$，其中 $\\varphi(\\cdot)$ 是标准正态概率密度函数。因此，ES预测为 $\\widehat{\\text{ES}}_t = -\\sigma_t \\, \\varphi(q_\\alpha)/\\alpha$。\n- VaR的回测使用超出指标 $I_t = \\mathbf{1}\\{r_t  \\widehat{\\text{VaR}}_t\\}$。在正确校准下的无条件覆盖意味着 $I_t$ 是独立同分布的伯努利变量，成功概率为 $\\alpha$。在长度为 $n$ 的回测样本中，令 $x = \\sum_{t=1}^n I_t$ 表示超出次数。无条件覆盖假设的似然比统计量等于\n$$\n\\text{LR}_{\\text{uc}} = 2\\left[ x \\ln\\left(\\frac{x/n}{\\alpha}\\right) + (n-x)\\ln\\left(\\frac{1 - x/n}{1-\\alpha}\\right)\\right],\n$$\n约定当 $x=0$ 时 $x \\ln(x/n)$ 为 $0$，当 $x=n$ 时 $(n-x)\\ln(1 - x/n)$ 为 $0$。在原假设下，$\\text{LR}_{\\text{uc}}$ 渐近服从自由度为 $1$ 的 $\\chi^2$ 分布。经验命中率为 $\\widehat{p} = x/n$。\n- 水平为 $\\alpha$ 的分位数的一个严格一致的评分函数是“检验损失” $\\ell_t^{Q} = \\left(\\alpha - I_t\\right)\\left(r_t - \\widehat{\\text{VaR}}_t\\right)$，其样本平均值 $\\overline{\\ell}^{Q}$ 对于校准良好的分位数预测应该很小。\n- 一个简单的ES回测诊断方法是将实现的尾部条件均值与超出日的平均ES预测进行比较。定义实现的短缺为 $\\overline{r}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} r_t$（仅当 $x \\ge 1$ 时有定义），以及对应的超出日的平均ES预测为 $\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} \\widehat{\\text{ES}}_t$。绝对ES偏差为 $|\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} - \\overline{r}_{\\text{tail}}|$。\n\n待比较的模型：\n- 基线模型（正确时间顺序）：在时间 $t$，使用长度为 $W$ 的滚动窗口，根据最近的 $W$ 个过去收益 $\\{r_{t-W},\\dots,r_{t-1}\\}$ 的样本标准差来估计 $\\sigma_t$。\n- 幽灵特征模型（前视偏差）：在时间 $t$，错误地使用一个包含当前收益的滚动窗口 $\\{r_{t-W+1},\\dots,r_t\\}$ 来估计 $\\sigma_t$。这使用了相对于决策点的未来信息，在真实的预测中是禁止的，但此处有意包含以量化其影响。\n\n数据生成过程：\n- 收益由一个条件均值为零的高斯广义自回归条件异方差（GARCH(1,1)）过程生成：\n$$\n\\sigma_t^2 = \\omega + \\alpha_G r_{t-1}^2 + \\beta_G \\sigma_{t-1}^2,\\quad r_t = \\sigma_t \\, z_t,\\quad z_t \\sim \\mathcal{N}(0,1),\n$$\n给定参数 $\\omega > 0$, $\\alpha_G \\ge 0$, 和 $\\beta_G \\ge 0$ 满足 $\\alpha_G + \\beta_G  1$ 以实现协方差平稳性。当 $\\alpha_G + \\beta_G  1$ 时，将 $\\sigma_0^2$ 初始化为无条件方差 $\\omega/(1 - \\alpha_G - \\beta_G)$，否则为了数值稳定性，将其初始化为 $\\omega$。\n\n为每个模型计算的回测指标：\n- 命中率绝对误差：$|\\widehat{p} - \\alpha|$。\n- 无条件覆盖似然比统计量：$\\text{LR}_{\\text{uc}}$。\n- 平均分位数检验损失：$\\overline{\\ell}^{Q}$。\n- 绝对ES偏差：$|\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} - \\overline{r}_{\\text{tail}}|$。\n\n必需的比较输出：\n对于下方的每个测试用例，按此顺序计算以下四个差值（基线减去幽灵）：\n$D_1 =$ 命中率绝对误差减少量 $= |\\widehat{p}_{\\text{base}} - \\alpha| - |\\widehat{p}_{\\text{ghost}} - \\alpha|$，\n$D_2 =$ 无条件覆盖似然比减少量 $= \\text{LR}_{\\text{uc, base}} - \\text{LR}_{\\text{uc, ghost}}$，\n$D_3 =$ 分位数检验损失减少量 $= \\overline{\\ell}^{Q}_{\\text{base}} - \\overline{\\ell}^{Q}_{\\text{ghost}}$，\n$D_4 =$ ES绝对偏差减少量 $= |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, base}} - \\overline{r}_{\\text{tail, base}}| - |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, ghost}} - \\overline{r}_{\\text{tail, ghost}}|$。\n\n任何 $D_j$ 的正值都表明，幽灵特征模型在该指标下表现得“更好”，但这将是虚假的，因为它非法地使用了未来信息。\n\n测试套件：\n实现下方的四个测试用例。对于每一个用例，使用提供的伪随机数生成器种子模拟收益以确保确定性，然后使用指定的滚动窗口长度 $W$ 和水平 $\\alpha$ 计算指标。所有的 $\\alpha$ 值都必须视为小数，而不是百分比。\n\n- 案例A（异方差，强持续性）：$T = 4000$，$\\omega = 10^{-6}$，$\\alpha_G = 0.05$，$\\beta_G = 0.94$，$W = 250$，$\\alpha = 0.01$，种子 $= 1729$。\n- 案例B（异方差，中等持续性，较短样本）：$T = 2000$，$\\omega = 10^{-6}$，$\\alpha_G = 0.15$，$\\beta_G = 0.80$，$W = 100$，$\\alpha = 0.05$，种子 $= 2718$。\n- 案例C（独立同分布高斯，边缘情况）：$T = 4000$，$\\omega = 10^{-4}$，$\\alpha_G = 0.00$，$\\beta_G = 0.00$，$W = 250$，$\\alpha = 0.01$，种子 $= 3141$。\n- 案例D（边界：小窗口）：$T = 1500$，$\\omega = 10^{-6}$，$\\alpha_G = 0.10$，$\\beta_G = 0.85$，$W = 30$，$\\alpha = 0.02$，种子 $= 1618$。\n\n最终输出格式：\n- 您的程序应产生单行输出，包含一个由方括号括起来的、包含16个浮点数的逗号分隔列表，顺序为 $[D_{1,A},D_{2,A},D_{3,A},D_{4,A},D_{1,B},D_{2,B},D_{3,B},D_{4,B},D_{1,C},D_{2,C},D_{3,C},D_{4,C},D_{1,D},D_{2,D},D_{3,D},D_{4,D}]$，其中下标表示测试用例。每个浮点数必须四舍五入到6位小数。不得打印任何其他文本。\n\n数值说明：\n- 滚动标准差应使用分母为 $(W-1)$ 的无偏样本方差。\n- 计算截断正态量时，使用 $q_\\alpha = \\Phi^{-1}(\\alpha)$ 和 $\\mathbb{E}[Z \\mid Z \\le q_\\alpha] = -\\varphi(q_\\alpha)/\\alpha$。\n- 无条件覆盖似然比 $\\text{LR}_{\\text{uc}}$ 使用上述针对 $x=0$ 或 $x=n$ 的约定，以避免未定义的对数。",
            "solution": "该问题陈述已经过严格验证，被认为是有效的。它在科学上基于金融计量经济学的原理，提法恰当且客观。它为比较两种风险模型的计算实验提供了一套完整且一致的要求。目标是量化前视偏差（“幽灵特征”）对风险价值（VaR）和期望损失（ES）的标准回测指标的影响。\n\n解决方案将分四个连续阶段进行开发：\n1. 从指定的GARCH(1,1)过程模拟金融收益数据。\n2. 实现两种滚动窗口波动率模型：一个正确设定的基线模型和一个有缺陷的幽灵特征模型。\n3. 计算VaR和ES预测，然后为每个模型计算四个不同的回测性能指标。\n4. 计算两种模型在这些指标上的差异，以量化从前视偏差中获得的虚假性能提升。\n\n**阶段1：数据生成过程**\n\n合成收益序列 $\\{r_t\\}$ 从一个高斯GARCH(1,1)过程生成。条件方差 $\\sigma_t^2$ 和收益 $r_t$ 由以下公式给出：\n$$\n\\sigma_t^2 = \\omega + \\alpha_G r_{t-1}^2 + \\beta_G \\sigma_{t-1}^2\n$$\n$$\nr_t = \\sigma_t z_t, \\quad \\text{其中} \\quad z_t \\sim \\mathcal{N}(0,1) \\quad \\text{i.i.d.}\n$$\n该过程在时间 $t=0$ 初始化。对于一个平稳过程，其中 $\\alpha_G + \\beta_G  1$，初始方差 $\\sigma_0^2$ 被设置为无条件方差 $\\sigma^2 = \\omega / (1 - \\alpha_G - \\beta_G)$。如果 $\\alpha_G + \\beta_G \\ge 1$，则将 $\\sigma_0^2$ 设置为 $\\omega$。\n对于每个测试用例，使用特定的伪随机数生成器种子生成一个包含 $T$ 个收益的序列 $\\{r_0, r_1, \\dots, r_{T-1}\\}$，以确保结果的确定性和可复现性。\n\n**阶段2：风险模型设定与预测**\n\n使用两种模型来预测向前一步的条件标准差 $\\sigma_t$。预测在从 $t=W$ 到 $t=T-1$ 的回测期间进行，其中 $W$ 是滚动窗口大小，总共 $n = T-W$ 个观测值。两种模型都使用滚动窗口中收益的无偏样本标准差（分母为 $W-1$）来估计 $\\sigma_t$。\n\n- **基线模型（正确时间顺序）：** 对时间 $t$ 的预测，表示为 $\\sigma_{t, \\text{base}}$，是使用在时间 $t-1$ 可获得的 $W$ 个最近*过去*收益计算的：\n$$ \\sigma_{t, \\text{base}} = \\text{StDev}(\\{r_{t-W}, r_{t-W+1}, \\dots, r_{t-1}\\}) $$\n- **幽灵特征模型（前视偏差）：** 对时间 $t$ 的预测，表示为 $\\sigma_{t, \\text{ghost}}$，是使用一个错误地包含了当前收益 $r_t$ 的窗口计算的：\n$$ \\sigma_{t, \\text{ghost}} = \\text{StDev}(\\{r_{t-W+1}, r_{t-W+2}, \\dots, r_t\\}) $$\n\n对于给定的尾部概率 $\\alpha$，模型 $m \\in \\{\\text{base, ghost}\\}$ 的VaR和ES预测为：\n$$ \\widehat{\\text{VaR}}_{t,m} = q_\\alpha \\sigma_{t,m}, \\quad \\text{其中} \\quad q_\\alpha = \\Phi^{-1}(\\alpha) $$\n$$ \\widehat{\\text{ES}}_{t,m} = -\\frac{\\varphi(q_\\alpha)}{\\alpha} \\sigma_{t,m} $$\n这里，$\\Phi^{-1}(\\cdot)$ 是标准正态分布的逆累积分布函数（分位数函数），$\\varphi(\\cdot)$ 是其概率密度函数。常数 $q_\\alpha$ 和用于ES的乘数会为提高效率而预先计算。\n\n**阶段3：回测指标**\n\n对于每个模型，我们使用四个指标在大小为 $n=T-W$ 的回测样本上评估其预测质量。当 $r_t  \\widehat{\\text{VaR}}_t$ 时，记录一次VaR超出，由 $I_t = \\mathbf{1}\\{r_t  \\widehat{\\text{VaR}}_t\\}$ 指示。总超出次数为 $x = \\sum_{i=1}^n I_t$。\n\n1.  **命中率绝对误差：** 衡量经验超出频率 $\\widehat{p} = x/n$ 与目标水平 $\\alpha$ 之间的偏差：\n$$ |\\widehat{p} - \\alpha| $$\n2.  **无条件覆盖似然比 ($\\text{LR}_{\\text{uc}}$)：** 检验假设 $\\mathbb{E}[I_t] = \\alpha$。该统计量为：\n$$ \\text{LR}_{\\text{uc}} = 2\\left[ x \\ln\\left(\\frac{x/n}{\\alpha}\\right) + (n-x)\\ln\\left(\\frac{1 - x/n}{1-\\alpha}\\right)\\right] $$\n为处理对数项，严格遵守针对 $x=0$ 或 $x=n$ 的指定约定。\n3.  **平均分位数检验损失 ($\\overline{\\ell}^{Q}$)：** 一种严格一致的分位数评分函数。值越低越好。\n$$ \\overline{\\ell}^{Q} = \\frac{1}{n}\\sum_{t=1}^{n} (\\alpha - I_t)(r_t - \\widehat{\\text{VaR}}_t) $$\n4.  **绝对ES偏差：** 衡量超出日的平均预测ES与同一天的平均实现收益之间的差异。\n$$ |\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} - \\overline{r}_{\\text{tail}}| $$\n其中 $\\overline{r}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} r_t$ 且 $\\overline{\\widehat{\\text{ES}}}_{\\text{tail}} = \\frac{1}{x}\\sum_{t: I_t=1} \\widehat{\\text{ES}}_t$。如果 $x=0$（没有超出），则偏差定义为 $0$，因为没有可评估的尾部事件。\n\n**阶段4：比较分析与最终输出**\n\n分析的核心是两种模型的直接比较。对于四个测试用例（A、B、C、D）中的每一个，我们为基线模型和幽灵特征模型计算这四个指标。最终所需的输出是这些指标的差异，计算方式为（基线指标）-（幽灵指标）：\n\n- $D_1 = |\\widehat{p}_{\\text{base}} - \\alpha| - |\\widehat{p}_{\\text{ghost}} - \\alpha|$\n- $D_2 = \\text{LR}_{\\text{uc, base}} - \\text{LR}_{\\text{uc, ghost}}$\n- $D_3 = \\overline{\\ell}^{Q}_{\\text{base}} - \\overline{\\ell}^{Q}_{\\text{ghost}}$\n- $D_4 = |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, base}} - \\overline{r}_{\\text{tail, base}}| - |\\overline{\\widehat{\\text{ES}}}_{\\text{tail, ghost}} - \\overline{r}_{\\text{tail, ghost}}|$\n\n任何 $D_j$ 的正值都表示幽灵特征模型由于使用了未来信息而在性能上获得了虚假的提升。该过程对所有四个测试用例执行，产生16个标量值，这些值被格式化为所需的单行输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Implements and compares two rolling Gaussian risk models (VaR and ES),\n    quantifying the effect of 'ghost features' (look-ahead bias) on backtesting outcomes.\n    \"\"\"\n\n    test_cases = [\n        # Case A (heteroskedastic, strong persistence)\n        {'T': 4000, 'omega': 1e-6, 'alpha_G': 0.05, 'beta_G': 0.94, 'W': 250, 'alpha': 0.01, 'seed': 1729},\n        # Case B (heteroskedastic, moderate persistence, shorter sample)\n        {'T': 2000, 'omega': 1e-6, 'alpha_G': 0.15, 'beta_G': 0.80, 'W': 100, 'alpha': 0.05, 'seed': 2718},\n        # Case C (independent and identically distributed Gaussian, edge case)\n        {'T': 4000, 'omega': 1e-4, 'alpha_G': 0.00, 'beta_G': 0.00, 'W': 250, 'alpha': 0.01, 'seed': 3141},\n        # Case D (boundary: small window)\n        {'T': 1500, 'omega': 1e-6, 'alpha_G': 0.10, 'beta_G': 0.85, 'W': 30, 'alpha': 0.02, 'seed': 1618},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        T, omega, alpha_G, beta_G, W, alpha, seed = case.values()\n        \n        # 1. Generate GARCH(1,1) return series\n        rng = np.random.default_rng(seed)\n        z = rng.normal(size=T)\n        \n        returns = np.zeros(T)\n        sigma2 = np.zeros(T)\n\n        if alpha_G + beta_G  1.0:\n            sigma2_uncond = omega / (1.0 - alpha_G - beta_G)\n        else:\n            sigma2_uncond = omega\n        \n        sigma2[0] = sigma2_uncond\n        returns[0] = np.sqrt(sigma2[0]) * z[0]\n\n        for t in range(1, T):\n            sigma2[t] = omega + alpha_G * returns[t-1]**2 + beta_G * sigma2[t-1]\n            returns[t] = np.sqrt(sigma2[t]) * z[t]\n        \n        # 2. Setup for backtesting\n        backtest_returns = returns[W:]\n        n_backtest = T - W\n        \n        q_alpha = norm.ppf(alpha)\n        es_multiplier = -norm.pdf(q_alpha) / alpha\n\n        # 3. Calculate metrics for both models\n        models = ['base', 'ghost']\n        metrics_all = {}\n\n        for model_type in models:\n            var_forecasts = np.zeros(n_backtest)\n            es_forecasts = np.zeros(n_backtest)\n            \n            for i in range(n_backtest):\n                t_current = W + i\n                if model_type == 'base':\n                    window = returns[t_current - W : t_current]\n                else: # ghost model\n                    window = returns[t_current - W + 1 : t_current + 1]\n                \n                sigma_t = np.std(window, ddof=1)\n                var_forecasts[i] = q_alpha * sigma_t\n                es_forecasts[i] = es_multiplier * sigma_t\n            \n            # --- Compute all 4 metrics ---\n            \n            # Exceedances\n            I = backtest_returns  var_forecasts\n            x = np.sum(I)\n            \n            # Metric 1: Hit-rate absolute error\n            p_hat = x / n_backtest\n            hit_rate_error = np.abs(p_hat - alpha)\n\n            # Metric 2: LR_uc\n            lr_uc = 0.0\n            if x > 0 and x  n_backtest :\n                term1 = x * np.log(p_hat / alpha)\n                term2 = (n_backtest - x) * np.log((1 - p_hat) / (1 - alpha))\n                lr_uc = 2 * (term1 + term2)\n            elif x == 0 and n_backtest > 0:\n                lr_uc = 2 * (n_backtest * np.log(1 / (1-alpha)))\n            elif x == n_backtest and n_backtest > 0:\n                 lr_uc = 2 * (n_backtest * np.log(1 / alpha))\n\n            # Metric 3: Average quantile check loss\n            avg_check_loss = np.mean((alpha - I) * (backtest_returns - var_forecasts))\n            \n            # Metric 4: Absolute ES bias\n            abs_es_bias = 0.0\n            if x > 0:\n                realized_shortfall = np.mean(backtest_returns[I])\n                mean_es_on_exceedance = np.mean(es_forecasts[I])\n                abs_es_bias = np.abs(mean_es_on_exceedance - realized_shortfall)\n                \n            metrics_all[model_type] = (hit_rate_error, lr_uc, avg_check_loss, abs_es_bias)\n\n        # 4. Compute differences (baseline - ghost)\n        base_metrics = metrics_all['base']\n        ghost_metrics = metrics_all['ghost']\n        diffs = [base_metrics[j] - ghost_metrics[j] for j in range(4)]\n        results.extend(diffs)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}