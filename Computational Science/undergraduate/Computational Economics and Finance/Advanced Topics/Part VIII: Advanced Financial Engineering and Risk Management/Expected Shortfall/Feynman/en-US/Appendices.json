{
    "hands_on_practices": [
        {
            "introduction": "We begin with a fundamental task in modern portfolio management: quantifying the tail risk of a simple portfolio. This exercise  will guide you through calculating the Expected Shortfall ($ES$) for a portfolio composed of two correlated risky assets and a risk-free asset. By understanding how the portfolio's $ES$ changes with the weights allocated to each asset, you develop a core competency in risk-aware asset allocation and build an intuition for how diversification impacts extreme losses, not just overall volatility.",
            "id": "2390659",
            "problem": "You are given a portfolio consisting of two correlated risky assets and a cash asset. Let the random vector of risky-asset returns be $R = (R_1, R_2)^\\top$, where $R$ is jointly normally distributed with mean vector $\\mu = (\\mu_1, \\mu_2)^\\top$ and covariance matrix\n$$\n\\Sigma = \\begin{pmatrix}\n\\sigma_1^2 & \\rho\\,\\sigma_1 \\sigma_2 \\\\\n\\rho\\,\\sigma_1 \\sigma_2 & \\sigma_2^2\n\\end{pmatrix}.\n$$\nLet $w_1$ and $w_2$ denote the portfolio weights on the two risky assets, and let the remaining weight be $w_0 = 1 - w_1 - w_2$ invested in a cash asset with zero return and zero variance. Assume $w_1 \\ge 0$, $w_2 \\ge 0$, and $w_1 + w_2 \\le 1$. Define the portfolio return as $R_p = w_1 R_1 + w_2 R_2 + w_0 \\cdot 0 = w_1 R_1 + w_2 R_2$, and the portfolio loss as $L = -R_p$. Let the Expected Shortfall (Conditional Value-at-Risk) at tail probability level $\\alpha \\in (0,1)$ be\n$$\n\\mathrm{ES}_\\alpha(L) = \\mathbb{E}\\!\\left[\\,L \\,\\middle|\\, L \\ge \\mathrm{VaR}_\\alpha(L)\\,\\right],\n$$\nwhere $\\mathrm{VaR}_\\alpha(L)$ is the Value-at-Risk at level $\\alpha$.\n\nParameters to use:\n- Risky-asset means: $\\mu_1 = 0.001$, $\\mu_2 = 0.0005$.\n- Risky-asset volatilities: $\\sigma_1 = 0.02$, $\\sigma_2 = 0.015$.\n- Correlation: $\\rho = 0.4$.\n- Tail probability level: $\\alpha = 0.975$.\n\nTasks:\n- For weights $(w_1,w_2)$ on a uniform grid over the square $[0,1]\\times[0,1]$ with step size $0.01$, compute $\\mathrm{ES}_\\alpha(L)$ for all feasible points satisfying $w_1 \\ge 0$, $w_2 \\ge 0$, and $w_1 + w_2 \\le 1$. This yields the numerical surface whose level sets form a $2$-dimensional contour representation of portfolio Expected Shortfall over the feasible weight triangle.\n- Do not output the grid. Instead, compute $\\mathrm{ES}_\\alpha(L)$ for the following test suite of specific weight pairs, expressed in the given order:\n  $$\n  (w_1,w_2) \\in \\{(0,0),\\ (1,0),\\ (0,1),\\ (0.3,0.2)\\}.\n  $$\n- All answers must be expressed as real numbers (floats). No physical units apply. The tail probability level is a decimal in $(0,1)$, not a percentage.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite, with each value rounded to $6$ decimal places (for example, $[x_1,x_2,x_3,x_4]$).\n\nThe input data are fully specified above; your program must not read any input and must not access external resources.",
            "solution": "The problem statement is subjected to validation before a solution is attempted.\n\nGivens are extracted verbatim:\n- A portfolio consists of two correlated risky assets and one cash asset.\n- The random vector of risky-asset returns is $R = (R_1, R_2)^\\top$.\n- $R$ is jointly normally distributed with mean vector $\\mu = (\\mu_1, \\mu_2)^\\top$ and covariance matrix $\\Sigma = \\begin{pmatrix} \\sigma_1^2 & \\rho\\,\\sigma_1 \\sigma_2 \\\\ \\rho\\,\\sigma_1 \\sigma_2 & \\sigma_2^2 \\end{pmatrix}$.\n- Portfolio weights on risky assets are $w_1$ and $w_2$.\n- Weight on cash asset is $w_0 = 1 - w_1 - w_2$, with zero return and zero variance.\n- Constraints are $w_1 \\ge 0$, $w_2 \\ge 0$, and $w_1 + w_2 \\le 1$.\n- Portfolio return is $R_p = w_1 R_1 + w_2 R_2$.\n- Portfolio loss is $L = -R_p$.\n- Expected Shortfall at tail probability level $\\alpha \\in (0,1)$ is $\\mathrm{ES}_\\alpha(L) = \\mathbb{E}\\!\\left[\\,L \\,\\middle|\\, L \\ge \\mathrm{VaR}_\\alpha(L)\\,\\right]$.\n- Value-at-Risk is $\\mathrm{VaR}_\\alpha(L)$.\n- Parameters: $\\mu_1 = 0.001$, $\\mu_2 = 0.0005$, $\\sigma_1 = 0.02$, $\\sigma_2 = 0.015$, $\\rho = 0.4$, $\\alpha = 0.975$.\n- Test cases for $(w_1,w_2)$ are $\\{(0,0),\\ (1,0),\\ (0,1),\\ (0.3,0.2)\\}$.\n\nValidation assessment:\nThe problem is scientifically grounded, well-posed, and objective. It is a standard problem in computational finance, based on established principles of portfolio theory and risk management. The mathematical setup, involving a linear combination of normally distributed random variables, is consistent and leads to a unique, well-defined solution. The provided parameters are numerically realistic. The term \"tail probability level $\\alpha$\" is slightly ambiguous. Standard convention in finance defines $\\mathrm{ES}_\\alpha$ and $\\mathrm{VaR}_\\alpha$ with $\\alpha$ as the confidence level (e.g., $0.95$, $0.99$), where the corresponding tail probability is $1-\\alpha$. Given the value $\\alpha=0.975$, we interpret $\\alpha$ as this confidence level, which is a standard interpretation rendering the problem unambiguous. Therefore, the problem is deemed **valid**.\n\nThe solution proceeds as follows.\n\nFirst, we determine the probability distribution of the portfolio loss, $L$. The portfolio return, $R_p$, is a linear combination of two jointly normally distributed random variables, $R_1$ and $R_2$. Let the weight vector be $w = (w_1, w_2)^\\top$. The portfolio return can be written as $R_p = w^\\top R$.\nBecause $R \\sim \\mathcal{N}(\\mu, \\Sigma)$, the portfolio return $R_p$ is also normally distributed.\nThe mean of the portfolio return, $\\mu_p$, is:\n$$ \\mu_p = \\mathbb{E}[R_p] = \\mathbb{E}[w^\\top R] = w^\\top \\mu = w_1 \\mu_1 + w_2 \\mu_2 $$\nThe variance of the portfolio return, $\\sigma_p^2$, is:\n$$ \\sigma_p^2 = \\mathrm{Var}(R_p) = \\mathrm{Var}(w^\\top R) = w^\\top \\Sigma w = w_1^2 \\sigma_1^2 + w_2^2 \\sigma_2^2 + 2 w_1 w_2 \\rho \\sigma_1 \\sigma_2 $$\nThus, $R_p \\sim \\mathcal{N}(\\mu_p, \\sigma_p^2)$.\n\nThe portfolio loss is defined as $L = -R_p$. As an affine transformation of a normal random variable, $L$ is also normally distributed.\nThe mean of the portfolio loss, $\\mu_L$, is:\n$$ \\mu_L = \\mathbb{E}[L] = \\mathbb{E}[-R_p] = -\\mu_p = -(w_1 \\mu_1 + w_2 \\mu_2) $$\nThe variance of the portfolio loss, $\\sigma_L^2$, is:\n$$ \\sigma_L^2 = \\mathrm{Var}(L) = \\mathrm{Var}(-R_p) = (-1)^2 \\mathrm{Var}(R_p) = \\sigma_p^2 $$\nThe standard deviation of the loss is $\\sigma_L = \\sigma_p$.\nSo, the loss distribution is $L \\sim \\mathcal{N}(\\mu_L, \\sigma_L^2)$.\n\nSecond, we formulate the Expected Shortfall, $\\mathrm{ES}_\\alpha(L)$, for this normal distribution. The definition provided is $\\mathrm{ES}_\\alpha(L) = \\mathbb{E}[L \\mid L \\ge \\mathrm{VaR}_\\alpha(L)]$.\nThe Value-at-Risk, $\\mathrm{VaR}_\\alpha(L)$, is the $\\alpha$-quantile of the loss distribution $L$. Let $z_\\alpha = \\Phi^{-1}(\\alpha)$ be the $\\alpha$-quantile of the standard normal distribution $\\mathcal{N}(0,1)$, where $\\Phi(\\cdot)$ is the standard normal cumulative distribution function (CDF).\nThen, $\\mathrm{VaR}_\\alpha(L)$ is found by standardizing $L$:\n$$ P(L \\le \\mathrm{VaR}_\\alpha(L)) = P\\left(\\frac{L - \\mu_L}{\\sigma_L} \\le \\frac{\\mathrm{VaR}_\\alpha(L) - \\mu_L}{\\sigma_L}\\right) = \\Phi\\left(\\frac{\\mathrm{VaR}_\\alpha(L) - \\mu_L}{\\sigma_L}\\right) = \\alpha $$\nThis implies $\\frac{\\mathrm{VaR}_\\alpha(L) - \\mu_L}{\\sigma_L} = z_\\alpha$, which gives:\n$$ \\mathrm{VaR}_\\alpha(L) = \\mu_L + \\sigma_L z_\\alpha $$\nNow, $\\mathrm{ES}_\\alpha(L)$ is the expected value of $L$ truncated from below at $c = \\mathrm{VaR}_\\alpha(L)$. For a general normal variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, the conditional expectation is given by:\n$$ \\mathbb{E}[X \\mid X \\ge c] = \\mu + \\sigma \\frac{\\phi((c-\\mu)/\\sigma)}{1 - \\Phi((c-\\mu)/\\sigma)} $$\nwhere $\\phi(\\cdot)$ is the standard normal probability density function (PDF).\nIn our case, $X=L$, $\\mu=\\mu_L$, $\\sigma=\\sigma_L$, and $c = \\mathrm{VaR}_\\alpha(L)$. The standardized cutoff is:\n$$ \\frac{c - \\mu_L}{\\sigma_L} = \\frac{(\\mu_L + \\sigma_L z_\\alpha) - \\mu_L}{\\sigma_L} = z_\\alpha $$\nSubstituting this into the conditional expectation formula yields the formula for Expected Shortfall:\n$$ \\mathrm{ES}_\\alpha(L) = \\mu_L + \\sigma_L \\frac{\\phi(z_\\alpha)}{1 - \\Phi(z_\\alpha)} $$\nSince $\\Phi(z_\\alpha) = \\alpha$ by definition, we obtain the final analytical expression:\n$$ \\mathrm{ES}_\\alpha(L) = \\mu_L + \\sigma_L \\frac{\\phi(z_\\alpha)}{1 - \\alpha} $$\n\nThird, we apply this formula to the given test cases using the specified parameters: $\\mu_1 = 0.001$, $\\mu_2 = 0.0005$, $\\sigma_1 = 0.02$, $\\sigma_2 = 0.015$, $\\rho = 0.4$, and $\\alpha = 0.975$.\nThe quantile $z_{0.975} = \\Phi^{-1}(0.975) \\approx 1.959964$. The denominator is $1 - \\alpha = 0.025$.\n\nCase 1: $(w_1, w_2) = (0, 0)$.\nThe portfolio holds only the cash asset.\n$\\mu_L = -(0 \\cdot \\mu_1 + 0 \\cdot \\mu_2) = 0$.\n$\\sigma_L^2 = 0$, so $\\sigma_L = 0$.\n$\\mathrm{ES}_{0.975}(L) = 0 + 0 \\cdot \\frac{\\phi(z_{0.975})}{0.025} = 0$.\n\nCase 2: $(w_1, w_2) = (1, 0)$.\nThe portfolio is fully invested in asset $1$.\n$\\mu_L = -(1 \\cdot 0.001 + 0 \\cdot 0.0005) = -0.001$.\n$\\sigma_L = \\sigma_1 = 0.02$.\n$\\mathrm{ES}_{0.975}(L) = -0.001 + 0.02 \\cdot \\frac{\\phi(z_{0.975})}{0.025} \\approx 0.045753$.\n\nCase 3: $(w_1, w_2) = (0, 1)$.\nThe portfolio is fully invested in asset $2$.\n$\\mu_L = -(0 \\cdot 0.001 + 1 \\cdot 0.0005) = -0.0005$.\n$\\sigma_L = \\sigma_2 = 0.015$.\n$\\mathrm{ES}_{0.975}(L) = -0.0005 + 0.015 \\cdot \\frac{\\phi(z_{0.975})}{0.025} \\approx 0.034565$.\n\nCase 4: $(w_1, w_2) = (0.3, 0.2)$.\n$\\mu_L = -(0.3 \\cdot 0.001 + 0.2 \\cdot 0.0005) = -(0.0003 + 0.0001) = -0.0004$.\n$\\sigma_L^2 = (0.3)^2(0.02)^2 + (0.2)^2(0.015)^2 + 2(0.3)(0.2)(0.4)(0.02)(0.015) = 0.0000594$.\n$\\sigma_L = \\sqrt{0.0000594} \\approx 0.00770714$.\n$\\mathrm{ES}_{0.975}(L) = -0.0004 + 0.00770714 \\cdot \\frac{\\phi(z_{0.975})}{0.025} \\approx 0.017597$.\n\nThese calculations are implemented in the provided program to produce the final numerical answer.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Calculates the Expected Shortfall (ES) for a two-asset portfolio for specific weight combinations.\n    \"\"\"\n    # Define the parameters given in the problem statement.\n    mu1 = 0.001\n    mu2 = 0.0005\n    sigma1 = 0.02\n    sigma2 = 0.015\n    rho = 0.4\n    alpha = 0.975\n\n    # Define the test suite of specific weight pairs.\n    test_cases = [\n        (0.0, 0.0),\n        (1.0, 0.0),\n        (0.0, 1.0),\n        (0.3, 0.2),\n    ]\n\n    # Pre-compute constants related to the standard normal distribution.\n    # z_alpha is the alpha-quantile of the standard normal distribution.\n    z_alpha = norm.ppf(alpha)\n    \n    # This is the term phi(z_alpha) / (1 - alpha) from the ES formula for a normal distribution.\n    pdf_over_tail = norm.pdf(z_alpha) / (1.0 - alpha)\n\n    results = []\n    for w1, w2 in test_cases:\n        # Calculate the mean of the portfolio loss (L = -R_p).\n        # mu_L = -E[R_p] = -(w1*mu1 + w2*mu2)\n        mu_L = -(w1 * mu1 + w2 * mu2)\n\n        # Calculate the variance of the portfolio return, which is equal to the variance of the loss.\n        # var_p = w1^2*sigma1^2 + w2^2*sigma2^2 + 2*w1*w2*rho*sigma1*sigma2\n        var_p = (w1 * sigma1)**2 + (w2 * sigma2)**2 + 2 * w1 * w2 * rho * sigma1 * sigma2\n        \n        # The standard deviation of the loss.\n        sigma_L = np.sqrt(var_p)\n\n        # Calculate Expected Shortfall (ES_alpha) using the derived formula for normal distributions:\n        # ES_alpha(L) = mu_L + sigma_L * (phi(z_alpha) / (1 - alpha))\n        es = mu_L + sigma_L * pdf_over_tail\n        results.append(es)\n\n    # Format the results to 6 decimal places as required.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Financial markets rarely conform to a single, static model; they often switch between different \"regimes,\" such as periods of high and low volatility. This exercise  challenges you to compute Expected Shortfall in this more realistic, dynamic setting using a Markov-switching model. You will learn to calculate the risk contributions from each regime and determine the overall portfolio $ES$ for the resulting mixture distribution, a crucial skill for managing risk in non-stationary environments.",
            "id": "2390701",
            "problem": "Consider a two-regime Markov-switching model for a single-period portfolio return. Let the latent regime at time $t$ be $S_t \\in \\{1,2\\}$. Conditional on $S_t = s$, the portfolio return $R_t$ is normally distributed with mean $\\mu_s$ and variance $\\sigma_s^2$, that is, $R_t \\mid (S_t = s) \\sim \\mathcal{N}(\\mu_s, \\sigma_s^2)$ for $s \\in \\{1,2\\}$. The regime process $\\{S_t\\}$ follows a two-state time-homogeneous Markov chain with transition matrix\n$$\nP \\;=\\; \\begin{bmatrix}\np_{11} & p_{12} \\\\\np_{21} & p_{22}\n\\end{bmatrix},\n$$\nwhere $p_{ij} = \\mathbb{P}(S_{t+1} = j \\mid S_t = i)$ and $p_{11} + p_{12} = 1$, $p_{21} + p_{22} = 1$. Define the loss as $L_t = -R_t$, and fix a tail probability level $q \\in (0,1)$, interpreted as the probability mass in the right tail of the loss distribution. The Value-at-Risk threshold $c_q$ is defined implicitly by $\\mathbb{P}(L_t \\ge c_q) = q$. The Expected Shortfall (Conditional Value-at-Risk) at tail probability $q$ is defined as\n$$\n\\mathrm{ES}(q) \\;=\\; \\mathbb{E}\\!\\left[\\,L_t \\,\\middle|\\, L_t \\ge c_q \\,\\right].\n$$\n\nFor each regime $s \\in \\{1,2\\}$, define the regime-conditional Expected Shortfall $\\mathrm{ES}_s(q)$ using the conditional loss distribution $L_t \\mid (S_t = s) \\sim \\mathcal{N}(-\\mu_s, \\sigma_s^2)$. Define the unconditional mixture Expected Shortfall $\\mathrm{ES}_{\\mathrm{mix}}(q)$ using the unconditional loss distribution obtained by mixing the two Gaussian components with stationary probabilities of the Markov chain. Let the stationary distribution be the vector $\\pi = (\\pi_1, \\pi_2)$ satisfying $\\pi = \\pi P$ and $\\pi_1 + \\pi_2 = 1$, with $\\pi_1 > 0$ and $\\pi_2 > 0$.\n\nIdentify the high-volatility regime as the one with the larger standard deviation $\\sigma_s$, and the low-volatility regime as the one with the smaller standard deviation. For each test case below, you must compute three quantities in this order: the Expected Shortfall in the high-volatility regime $\\mathrm{ES}_{\\text{high}}(q)$, the Expected Shortfall in the low-volatility regime $\\mathrm{ES}_{\\text{low}}(q)$, and the unconditional mixture Expected Shortfall $\\mathrm{ES}_{\\mathrm{mix}}(q)$. All outputs must be expressed in decimal return units (not in percentages), each rounded to exactly eight decimal places.\n\nTest suite. For each case, the tuple lists $(\\mu_1, \\sigma_1, \\mu_2, \\sigma_2, P, q)$ with\n$$\nP \\,=\\, \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{21} & p_{22} \\end{bmatrix}.\n$$\n- Case $1$: $(\\mu_1, \\sigma_1, \\mu_2, \\sigma_2) = (\\,0.0005,\\, 0.01,\\, -0.0005,\\, 0.03\\,)$, $P = \\begin{bmatrix} 0.95 & 0.05 \\\\ 0.10 & 0.90 \\end{bmatrix}$, $q = 0.01$.\n- Case $2$: $(\\mu_1, \\sigma_1, \\mu_2, \\sigma_2) = (\\,0.0,\\, 0.01,\\, 0.0,\\, 0.02\\,)$, $P = \\begin{bmatrix} 0.90 & 0.10 \\\\ 0.10 & 0.90 \\end{bmatrix}$, $q = 0.05$.\n- Case $3$: $(\\mu_1, \\sigma_1, \\mu_2, \\sigma_2) = (\\,0.0002,\\, 0.005,\\, -0.0002,\\, 0.05\\,)$, $P = \\begin{bmatrix} 0.995 & 0.005 \\\\ 0.005 & 0.995 \\end{bmatrix}$, $q = 0.02$.\n- Case $4$: $(\\mu_1, \\sigma_1, \\mu_2, \\sigma_2) = (\\,0.0001,\\, 0.001,\\, -0.0001,\\, 0.04\\,)$, $P = \\begin{bmatrix} 0.50 & 0.50 \\\\ 0.50 & 0.50 \\end{bmatrix}$, $q = 0.001$.\n\nYour program must:\n- For each case, determine which state is the high-volatility regime and which is the low-volatility regime by comparing $\\sigma_1$ and $\\sigma_2$.\n- Compute $\\mathrm{ES}_{\\text{high}}(q)$ and $\\mathrm{ES}_{\\text{low}}(q)$ from first principles using the regime-conditional normal loss distributions.\n- Compute $\\mathrm{ES}_{\\mathrm{mix}}(q)$ from first principles using the stationary distribution $\\pi$ of $P$ and the unconditional mixture of the two normal loss components.\n\nFinal output format. Your program should produce a single line of output containing a flat list of floating-point numbers, in the order\n$$\n\\big[\\, \\mathrm{ES}_{\\text{high}}^{(1)},\\, \\mathrm{ES}_{\\text{low}}^{(1)},\\, \\mathrm{ES}_{\\mathrm{mix}}^{(1)},\\, \\mathrm{ES}_{\\text{high}}^{(2)},\\, \\mathrm{ES}_{\\text{low}}^{(2)},\\, \\mathrm{ES}_{\\mathrm{mix}}^{(2)},\\, \\mathrm{ES}_{\\text{high}}^{(3)},\\, \\mathrm{ES}_{\\text{low}}^{(3)},\\, \\mathrm{ES}_{\\mathrm{mix}}^{(3)},\\, \\mathrm{ES}_{\\text{high}}^{(4)},\\, \\mathrm{ES}_{\\text{low}}^{(4)},\\, \\mathrm{ES}_{\\mathrm{mix}}^{(4)} \\,\\big],\n$$\nwith no spaces, where superscript $(i)$ refers to test case $i$. Each number must be rounded to exactly eight decimal places. The line must be printed as a comma-separated list enclosed in square brackets, for example, $[x_1,x_2,\\dots,x_{12}]$.",
            "solution": "The problem is subjected to rigorous validation.\n\n### Step 1: Extract Givens\n- **Model**: A two-regime Markov-switching model for a single-period portfolio return $R_t$.\n- **Latent Regime**: $S_t \\in \\{1,2\\}$, following a time-homogeneous Markov chain.\n- **Transition Matrix**: $P = \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{21} & p_{22} \\end{bmatrix}$, where $p_{ij} = \\mathbb{P}(S_{t+1} = j \\mid S_t = i)$.\n- **Conditional Return Distribution**: $R_t \\mid (S_t = s) \\sim \\mathcal{N}(\\mu_s, \\sigma_s^2)$.\n- **Loss Definition**: $L_t = -R_t$. Consequently, the conditional loss distribution is $L_t \\mid (S_t = s) \\sim \\mathcal{N}(-\\mu_s, \\sigma_s^2)$.\n- **Tail Probability**: A fixed level $q \\in (0,1)$.\n- **Value-at-Risk (VaR)**: $c_q$ defined by $\\mathbb{P}(L_t \\ge c_q) = q$.\n- **Expected Shortfall (ES)**: $\\mathrm{ES}(q) = \\mathbb{E}[L_t \\mid L_t \\ge c_q]$.\n- **Regime-Conditional ES**: $\\mathrm{ES}_s(q)$ is the ES for the loss distribution $L_t \\mid (S_t = s)$.\n- **Unconditional Mixture ES**: $\\mathrm{ES}_{\\mathrm{mix}}(q)$ is the ES for the unconditional loss distribution, which is a mixture of the two conditional distributions weighted by the stationary probabilities $\\pi = (\\pi_1, \\pi_2)$ of the Markov chain.\n- **Stationary Distribution**: $\\pi$ is the vector satisfying $\\pi = \\pi P$ and $\\pi_1 + \\pi_2 = 1$.\n- **Regime Identification**: High-volatility regime has the larger $\\sigma_s$, low-volatility has the smaller $\\sigma_s$.\n- **Task**: For four test cases, compute $\\mathrm{ES}_{\\text{high}}(q)$, $\\mathrm{ES}_{\\text{low}}(q)$, and $\\mathrm{ES}_{\\mathrm{mix}}(q)$.\n- **Test Cases**:\n    1. $(\\mu_1, \\sigma_1, \\mu_2, \\sigma_2) = (0.0005, 0.01, -0.0005, 0.03)$, $P = \\begin{bmatrix} 0.95 & 0.05 \\\\ 0.10 & 0.90 \\end{bmatrix}$, $q = 0.01$.\n    2. $(\\mu_1, \\sigma_1, \\mu_2, \\sigma_2) = (0.0, 0.01, 0.0, 0.02)$, $P = \\begin{bmatrix} 0.90 & 0.10 \\\\ 0.10 & 0.90 \\end{bmatrix}$, $q = 0.05$.\n    3. $(\\mu_1, \\sigma_1, \\mu_2, \\sigma_2) = (0.0002, 0.005, -0.0002, 0.05)$, $P = \\begin{bmatrix} 0.995 & 0.005 \\\\ 0.005 & 0.995 \\end{bmatrix}$, $q = 0.02$.\n    4. $(\\mu_1, \\sigma_1, \\mu_2, \\sigma_2) = (0.0001, 0.001, -0.0001, 0.04)$, $P = \\begin{bmatrix} 0.50 & 0.50 \\\\ 0.50 & 0.50 \\end{bmatrix}$, $q = 0.001$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is **scientifically grounded**, based on standard principles of financial econometrics and risk management. The Markov-switching model, Value-at-Risk, and Expected Shortfall are all canonical concepts. The problem is **well-posed**, providing all necessary parameters and unambiguous definitions for the quantities to be computed. The mathematical structure guarantees a unique and meaningful solution. The problem statement is **objective** and free from any subjective or speculative content. No flaws from the checklist are identified.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A reasoned solution follows.\n\n---\n\n### Solution Methodology\n\nThe problem requires the calculation of three types of Expected Shortfall (ES) for a loss process derived from a two-regime Markov-switching model. The core principles are laid out below.\n\n**1. Regime-Conditional Expected Shortfall**\n\nFor a random variable representing loss, $L$, that follows a normal distribution $L \\sim \\mathcal{N}(\\mu_L, \\sigma_L^2)$, the Expected Shortfall at a tail probability $q$ is given by the formula:\n$$\n\\mathrm{ES}(q) = \\mu_L + \\sigma_L \\frac{\\phi(\\Phi^{-1}(1-q))}{q}\n$$\nwhere $\\phi(\\cdot)$ is the standard normal probability density function (PDF) and $\\Phi(\\cdot)$ is the standard normal cumulative distribution function (CDF).\n\nIn this problem, the return in regime $s$ is $R_s \\sim \\mathcal{N}(\\mu_s, \\sigma_s^2)$. The loss is $L_s = -R_s$, so its distribution is $L_s \\sim \\mathcal{N}(-\\mu_s, \\sigma_s^2)$. The mean of the loss is $\\mu_{L,s} = -\\mu_s$ and its standard deviation is $\\sigma_{L,s} = \\sigma_s$. Substituting these into the general formula gives the regime-conditional ES:\n$$\n\\mathrm{ES}_s(q) = -\\mu_s + \\sigma_s \\frac{\\phi(z_q)}{q}\n$$\nwhere $z_q = \\Phi^{-1}(1-q)$ is the $(1-q)$-quantile of the standard normal distribution. We compute this quantity for the high-volatility ($\\mathrm{ES}_{\\text{high}}(q)$) and low-volatility ($\\mathrm{ES}_{\\text{low}}(q)$) regimes, which are identified by comparing the values of $\\sigma_1$ and $\\sigma_2$.\n\n**2. Unconditional Mixture Expected Shortfall**\n\nThe calculation of $\\mathrm{ES}_{\\mathrm{mix}}(q)$ is a multi-step process.\n\n**Step 2a: Stationary Distribution**\nThe unconditional distribution of the loss is a mixture of the two regime-conditional distributions, weighted by the stationary probabilities of the Markov chain. For a $2 \\times 2$ transition matrix $P = \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{21} & p_{22} \\end{bmatrix}$, the stationary probabilities $\\pi = (\\pi_1, \\pi_2)$ are found by solving the linear system $\\pi P = \\pi$ subject to $\\pi_1 + \\pi_2 = 1$. The solution is:\n$$\n\\pi_1 = \\frac{p_{21}}{p_{12} + p_{21}}, \\quad \\pi_2 = \\frac{p_{12}}{p_{12} + p_{21}}\n$$\nThis assumes the chain is irreducible, i.e., $p_{12} + p_{21} > 0$, which holds for all test cases.\n\n**Step 2b: Value-at-Risk of the Mixture**\nThe unconditional loss $L$ has a mixture CDF given by $F_L(c) = \\pi_1 F_1(c) + \\pi_2 F_2(c)$, where $F_s(c)$ is the CDF of the loss in regime $s$, $L_s \\sim \\mathcal{N}(-\\mu_s, \\sigma_s^2)$. Explicitly, $F_s(c) = \\Phi\\left(\\frac{c - (-\\mu_s)}{\\sigma_s}\\right) = \\Phi\\left(\\frac{c+\\mu_s}{\\sigma_s}\\right)$.\nThe Value-at-Risk, $c_q$, is defined by the condition $\\mathbb{P}(L \\ge c_q) = q$, which is equivalent to $F_L(c_q) = 1-q$. This gives the non-linear equation for $c_q$:\n$$\n\\pi_1 \\Phi\\left(\\frac{c_q+\\mu_1}{\\sigma_1}\\right) + \\pi_2 \\Phi\\left(\\frac{c_q+\\mu_2}{\\sigma_2}\\right) = 1-q\n$$\nThis equation must be solved numerically, for instance, using Brent's method.\n\n**Step 2c: Expected Shortfall of the Mixture**\nThe mixture ES is the conditional expectation $\\mathrm{ES}_{\\mathrm{mix}}(q) = \\mathbb{E}[L \\mid L \\ge c_q]$. It is calculated as:\n$$\n\\mathrm{ES}_{\\mathrm{mix}}(q) = \\frac{1}{q} \\int_{c_q}^{\\infty} c \\cdot f_L(c) \\, dc = \\frac{1}{q} \\left( \\pi_1 \\int_{c_q}^{\\infty} c \\cdot f_1(c) \\, dc + \\pi_2 \\int_{c_q}^{\\infty} c \\cdot f_2(c) \\, dc \\right)\n$$\nwhere $f_s(c)$ is the PDF of the loss distribution $L_s$. The integral $\\int_{c_q}^{\\infty} c \\cdot f_s(c) \\, dc$ is the first partial moment of the normal distribution $L_s$. For a normal variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, this partial moment is given by $\\mu \\cdot \\mathbb{P}(X > c_q) + \\sigma^2 \\cdot \\phi(c_q; \\mu, \\sigma)$. For our loss $L_s \\sim \\mathcal{N}(-\\mu_s, \\sigma_s^2)$, this becomes:\n$$\n\\int_{c_q}^{\\infty} c \\cdot f_s(c) \\, dc = (-\\mu_s)\\left(1 - \\Phi\\left(\\frac{c_q+\\mu_s}{\\sigma_s}\\right)\\right) + \\sigma_s \\phi\\left(\\frac{c_q+\\mu_s}{\\sigma_s}\\right)\n$$\nBy substituting this expression for each regime into the formula for $\\mathrm{ES}_{\\mathrm{mix}}(q)$, we obtain the final value.\n\nThe algorithm is implemented by following these precise mathematical steps for each test case provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.optimize import root_scalar\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: (mu1, sigma1, mu2, sigma2), [[p11, p12], [p21, p22]], q\n        ((0.0005, 0.01, -0.0005, 0.03), np.array([[0.95, 0.05], [0.10, 0.90]]), 0.01),\n        # Case 2\n        ((0.0, 0.01, 0.0, 0.02), np.array([[0.90, 0.10], [0.10, 0.90]]), 0.05),\n        # Case 3\n        ((0.0002, 0.005, -0.0002, 0.05), np.array([[0.995, 0.005], [0.005, 0.995]]), 0.02),\n        # Case 4\n        ((0.0001, 0.001, -0.0001, 0.04), np.array([[0.50, 0.50], [0.50, 0.50]]), 0.001),\n    ]\n\n    all_results = []\n    for params, P, q in test_cases:\n        mu1, sigma1, mu2, sigma2 = params\n        \n        # 1. Identify high/low volatility regimes.\n        if sigma1 > sigma2:\n            mu_high, sigma_high = mu1, sigma1\n            mu_low, sigma_low = mu2, sigma2\n        else:\n            mu_high, sigma_high = mu2, sigma2\n            mu_low, sigma_low = mu1, sigma1\n            \n        # 2. Calculate regime-conditional Expected Shortfall.\n        def es_normal(mu, sigma, q_level):\n            \"\"\"Calculates ES for a normal loss L ~ N(-mu, sigma^2).\"\"\"\n            z_q = norm.ppf(1 - q_level)\n            es = -mu + sigma * norm.pdf(z_q) / q_level\n            return es\n\n        es_high = es_normal(mu_high, sigma_high, q)\n        es_low = es_normal(mu_low, sigma_low, q)\n        \n        # 3. Calculate unconditional mixture Expected Shortfall.\n        \n        # 3a. Stationary probabilities\n        p12 = P[0, 1]\n        p21 = P[1, 0]\n        # Formula pi_1 = p21 / (p12 + p21), pi_2 = p12 / (p12 + p21)\n        # Handles reducible case where denominator is 0, though not present in tests.\n        if p12 + p21 > 0:\n            pi1 = p21 / (p12 + p21)\n            pi2 = 1.0 - pi1\n        else: # Reducible chain, assume initial state 1 if ambiguous. Here we assume non-reducible.\n            pi1 = 1.0\n            pi2 = 0.0\n            if P[0,0] != 1.0: # Check if state 2 is the absorbing one\n                pi1 = 0.0\n                pi2 = 1.0\n        \n        # 3b. Find VaR of the mixture (c_q) by finding the root.\n        # Loss L_s ~ N(-mu_s, sigma_s^2)\n        # CDF of L_s is F_s(c) = norm.cdf((c - (-mu_s)) / sigma_s) = norm.cdf((c + mu_s) / sigma_s)\n        # We need to solve F_L(c) = pi1*F1(c) + pi2*F2(c) = 1 - q\n        def mixture_cdf_minus_target(c, mu1, sigma1, mu2, sigma2, pi1, pi2, q_level):\n            cdf1 = norm.cdf((c + mu1) / sigma1)\n            cdf2 = norm.cdf((c + mu2) / sigma2)\n            return pi1 * cdf1 + pi2 * cdf2 - (1.0 - q_level)\n\n        # Bracket for root finding. A wide but safe range.\n        bracket_min = min(-mu1, -mu2) - 10 * max(sigma1, sigma2)\n        bracket_max = max(-mu1, -mu2) + 10 * max(sigma1, sigma2)\n        \n        sol = root_scalar(\n            mixture_cdf_minus_target, \n            args=(mu1, sigma1, mu2, sigma2, pi1, pi2, q),\n            bracket=[bracket_min, bracket_max],\n            method='brentq'\n        )\n        c_q = sol.root\n\n        # 3c. Calculate partial expectations and the mixture ES.\n        # Partial expectation for L_s: E[L_s | L_s > c_q] * P(L_s > c_q)\n        # This is integral from c_q to infinity of x * f_s(x) dx\n        def partial_expectation(c_threshold, mu, sigma):\n            mu_loss = -mu\n            z = (c_threshold - mu_loss) / sigma\n            # Formula: mu_L * (1 - CDF(z)) + sigma * PDF(z)\n            # This is equivalent to mu_L * P(L>c) + sigma^2 * f(c)\n            return mu_loss * (1 - norm.cdf(z)) + sigma * norm.pdf(z)\n\n        pe1 = partial_expectation(c_q, mu1, sigma1)\n        pe2 = partial_expectation(c_q, mu2, sigma2)\n        \n        es_mix = (pi1 * pe1 + pi2 * pe2) / q\n        \n        all_results.extend([es_high, es_low, es_mix])\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.8f}\" for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A crucial part of a risk manager's job is not just to forecast risk, but to validate whether their models are accurate. This practice  presents a fascinating paradox that highlights the shortcomings of Value-at-Risk ($VaR$) and the conceptual strength of Expected Shortfall ($ES$). Through a carefully designed simulation, you will demonstrate how a model can produce highly accurate $ES$ forecasts yet still fail a standard $VaR$ backtest, revealing the critical difference between measuring the frequency of losses and their expected magnitude.",
            "id": "2374170",
            "problem": "You are asked to build a complete, deterministic simulation that demonstrates that a model with very high-quality Expected Shortfall (ES) forecasts can nonetheless fail a standard Value-at-Risk (VaR) backtest for unconditional coverage. Your program must implement the definitions and logic from first principles, and must not rely on any external data or user input.\n\nDefinitions and requirements:\n- Let Value-at-Risk (VaR) at confidence level $c$ be defined as the upper quantile of the loss distribution at level $c$, so that if $L$ denotes loss, then $\\mathrm{VaR}_c$ is the unique value $v$ such that $\\mathbb{P}(L \\le v) = c$. Equivalently, with tail probability $\\alpha := 1 - c$, $\\mathrm{VaR}_c$ is the threshold $v$ such that $\\mathbb{P}(L > v) = \\alpha$.\n- Let Expected Shortfall (ES) at confidence level $c$ be defined as the conditional expectation of loss given that loss exceeds $\\mathrm{VaR}_c$, namely $\\mathrm{ES}_c := \\mathbb{E}[L \\mid L > \\mathrm{VaR}_c]$.\n- A “VaR backtest” for unconditional coverage is an assessment based on the sequence of exceedance indicators $I_t := \\mathbf{1}\\{L_t > v\\}$ under the null hypothesis that $\\mathbb{P}(I_t = 1) = \\alpha$ independently over time. The standard unconditional coverage test evaluates whether the observed number of exceedances $x := \\sum_{t=1}^T I_t$ is consistent with the null at a fixed significance level. Your task is to implement the unconditional coverage likelihood-ratio test, and to declare a “fail” if the null is rejected at significance level $0.05$, and “pass” otherwise.\n- To quantify ES forecast quality, compute the realized tail average $\\widehat{\\mathrm{ES}} := \\frac{1}{x} \\sum_{t: L_t > v} L_t$ when $x \\ge 1$, and compare it to the model’s ES forecast $e$. Define the relative error $\\varepsilon := \\lvert \\widehat{\\mathrm{ES}} - e \\rvert / e$. Declare ES “very high-quality” if $\\varepsilon \\le \\tau$ for a given tolerance $\\tau$.\n\nSimulation design to demonstrate the paradox:\n- The “model” will produce constant forecasts $(v, e)$ as if losses were standard normal. Specifically, take loss $Z$ drawn from a standard normal distribution and define $v$ to be the $c$-quantile of $Z$, and $e$ to be the conditional mean $e := \\mathbb{E}[Z \\mid Z > v]$. These $(v, e)$ are the model’s constant forecasts throughout the backtest horizon.\n- The true data-generating process (DGP) deliberately violates unconditional coverage for VaR while keeping the ES forecast nearly correct:\n  1. Fix a tail probability $\\alpha$ and confidence level $c := 1 - \\alpha$. Fix a tail inflation factor $r \\ge 1$ and sample size $T$. Set the number of exceedances deterministically to $x := \\text{round}(r \\cdot \\alpha \\cdot T)$ and the number of non-exceedances to $T - x$. This makes the exceedance frequency equal to $r \\cdot \\alpha$ up to rounding.\n  2. For the $x$ exceedance losses, draw from a Generalized Pareto Distribution (GPD) for the excess over threshold $v$ with shape parameter $\\xi \\in (0, 1)$ and scale parameter $\\beta$ chosen so that the conditional mean equals the model forecast $e$. If $W \\sim \\mathrm{GPD}(\\xi, \\beta)$ denotes the excess and $L := v + W$, then $\\mathbb{E}[L \\mid L > v] = v + \\beta/(1 - \\xi)$. Enforce $v + \\beta/(1 - \\xi) = e$ by setting $\\beta := (e - v)\\,(1 - \\xi)$.\n  3. For the $T - x$ non-exceedance losses, draw independently from a uniform distribution on $[0, v]$, which guarantees they do not exceed $v$.\n- This construction ensures that the realized exceedance probability is approximately $r \\cdot \\alpha$, which will trigger a failure of unconditional coverage when $r$ is sufficiently greater than $1$, yet the conditional mean of exceedances matches the model’s ES by construction, making ES very accurate.\n\nTesting and reporting:\n- Use a fixed random seed to ensure that the simulation is deterministic and reproducible. You must implement the unconditional coverage likelihood-ratio test at significance level $0.05$ using the exact Bernoulli likelihoods under the null and under the empirical exceedance rate, and compare to the chi-square critical value with one degree of freedom.\n- For ES quality, use the relative error threshold $\\tau$ as specified in each test case below. If there are no exceedances ($x = 0$), define $\\widehat{\\mathrm{ES}}$ arbitrarily and set ES quality to “not high-quality”; however, the provided test suite ensures $x \\ge 1$.\n\nTest suite:\n- Common parameters for all cases: tail probability $\\alpha = 0.01$, significance level for the VaR test $0.05$, GPD shape parameter $\\xi = 0.10$, and ES tolerance $\\tau = 0.05$. The model confidence level is $c = 1 - \\alpha = 0.99$.\n- Case $1$ (happy path): $T = 5000$, $r = 1.0$.\n- Case $2$ (paradox): $T = 5000$, $r = 2.0$.\n- Case $3$ (low-power edge): $T = 5000$, $r = 1.2$.\n\nRequired outputs:\n- For each case, compute two booleans: \n  1. VaR backtest failure (True if the unconditional coverage null is rejected at significance $0.05$, else False).\n  2. ES high-quality indicator (True if $\\varepsilon \\le \\tau$, else False).\n- Your program should produce a single line of output containing the six booleans in order of cases and metrics as a comma-separated list enclosed in square brackets, in the following order: $[\\text{VaRFail}_1,\\text{ESGood}_1,\\text{VaRFail}_2,\\text{ESGood}_2,\\text{VaRFail}_3,\\text{ESGood}_3]$. Example format only: $[\\text{True},\\text{False},\\dots]$.\n\nConstraints:\n- The program must be completely self-contained and deterministic.\n- All random sampling must be performed with a fixed seed of your choice, and the exceedance count must be set deterministically to $x := \\text{round}(r \\cdot \\alpha \\cdot T)$ as specified.",
            "solution": "The problem statement is valid. It is scientifically grounded in the principles of financial risk management, specifically the backtesting of Value-at-Risk (VaR) and Expected Shortfall (ES) models. The definitions provided for $\\mathrm{VaR}$, $\\mathrm{ES}$, the unconditional coverage test, and the Generalized Pareto Distribution (GPD) are standard and mathematically correct. The simulation design is a well-posed computational experiment intended to demonstrate a known, non-trivial phenomenon where a model can produce high-quality ES forecasts while failing a VaR backtest. The problem is self-contained, with all necessary parameters and procedures specified, and is free of contradictions or ambiguities.\n\nHere follows the reasoned solution.\n\nThe core task is to construct a deterministic simulation demonstrating that a model's forecasts for Value-at-Risk ($\\mathrm{VaR}$) and Expected Shortfall ($\\mathrm{ES}$) can receive conflicting evaluations in a backtest. Specifically, the simulation must show a scenario where the $\\mathrm{VaR}$ forecast is rejected, but the $\\mathrm{ES}$ forecast is deemed highly accurate.\n\nFirst, we establish the theoretical foundations for the model forecasts, the data-generating process (DGP), and the statistical tests.\n\n**1. Model Forecasts**\n\nThe \"model\" is defined to produce constant forecasts $(v, e)$ for $\\mathrm{VaR}$ and $\\mathrm{ES}$, respectively. These forecasts are derived under the assumption that the financial loss $L$ follows a standard normal distribution, $Z \\sim N(0, 1)$.\n\nThe confidence level is $c = 1 - \\alpha$, where $\\alpha = 0.01$. Thus, $c = 0.99$.\nThe $\\mathrm{VaR}$ forecast, $v$, is the $c$-quantile of the standard normal distribution:\n$$v = \\Phi^{-1}(c) = \\Phi^{-1}(0.99)$$\nwhere $\\Phi^{-1}$ is the quantile function (inverse CDF) of the standard normal distribution.\n\nThe $\\mathrm{ES}$ forecast, $e$, is the conditional expectation of the loss, given that the loss exceeds the $\\mathrm{VaR}$ threshold $v$:\n$$e = \\mathbb{E}[Z \\mid Z > v]$$\nFor a standard normal distribution, this has a well-known closed-form solution:\n$$e = \\frac{\\phi(v)}{1 - c} = \\frac{\\phi(v)}{\\alpha}$$\nwhere $\\phi$ is the probability density function (PDF) of the standard normal distribution. These values, $v$ and $e$, are constants throughout the simulation.\n\n**2. Data-Generating Process (DGP)**\n\nThe simulation's DGP is designed to diverge from the model's assumption in a controlled manner. It generates a time series of $T$ losses.\n\nThe number of $\\mathrm{VaR}$ exceedances, $x$, is deterministically set based on a tail inflation factor $r$:\n$$x = \\text{round}(r \\cdot \\alpha \\cdot T)$$\nThe number of non-exceedances is correspondingly $T-x$. This construction directly manipulates the empirical frequency of exceedances to be approximately $r \\cdot \\alpha$.\n\nThe losses themselves are generated from two distinct distributions:\n- **Exceedance Losses ($x$ samples):** Losses that exceed the model's $\\mathrm{VaR}$ forecast $v$ are of the form $L_t = v + W_t$, where $W_t$ is the excess loss over the threshold. $W_t$ is drawn from a Generalized Pareto Distribution, $W_t \\sim \\mathrm{GPD}(\\xi, \\beta)$. The problem specifies a shape parameter $\\xi = 0.10$. The scale parameter $\\beta$ is chosen to force the conditional mean of the exceedances to match the model's $\\mathrm{ES}$ forecast $e$. The mean of a $\\mathrm{GPD}(\\xi, \\beta)$ is $\\mathbb{E}[W_t] = \\beta / (1 - \\xi)$, for $\\xi  1$. Therefore, we enforce:\n$$\\mathbb{E}[L_t \\mid L_t > v] = v + \\mathbb{E}[W_t] = v + \\frac{\\beta}{1 - \\xi} = e$$\nSolving for the scale parameter $\\beta$ yields:\n$$\\beta = (e - v)(1 - \\xi)$$\nThis choice of $\\beta$ is central to the paradox: the distribution of tail losses is constructed to have a mean that precisely matches the model's (incorrectly derived) $\\mathrm{ES}$ forecast. To generate a random variate $W$ from this GPD, we use inverse transform sampling. The inverse CDF (quantile function) of the GPD is\n$$F^{-1}(u) = \\frac{\\beta}{\\xi}((1-u)^{-\\xi} - 1)$$\nfor a uniform random variable $u \\sim U(0,1)$.\n\n- **Non-Exceedance Losses ($T-x$ samples):** These losses are drawn from a uniform distribution on the interval $[0, v]$. This simple choice guarantees that these losses are always less than or equal to $v$ and thus never constitute a $\\mathrm{VaR}$ exceedance.\n\n**3. Backtesting Procedures**\n\nTwo separate tests are performed on the generated series of $T$ losses.\n\n- **VaR Backtest (Unconditional Coverage):** The unconditional coverage test, proposed by Kupiec, evaluates the null hypothesis $H_0$ that the probability of a $\\mathrm{VaR}$ exceedance on any given day is $\\alpha$, i.e., $p = \\alpha$. The test is based on the likelihood-ratio (LR) statistic. The likelihood function for observing $x$ exceedances in a sample of size $T$ is given by the binomial probability mass function $L(p; x, T) = p^x (1-p)^{T-x}$. The LR statistic compares the likelihood under the null hypothesis ($p=\\alpha$) with the likelihood under the alternative hypothesis, where $p$ is estimated by its maximum likelihood estimate, $\\hat{p} = x/T$. The statistic is:\n$$LR_{uc} = 2 \\ln\\left(\\frac{L(\\hat{p})}{L(\\alpha)}\\right) = 2 \\left[ \\ln(L(\\hat{p})) - \\ln(L(\\alpha)) \\right]$$\n$$LR_{uc} = 2 \\left[ x \\ln\\left(\\frac{x}{T}\\right) + (T-x) \\ln\\left(1 - \\frac{x}{T}\\right) - x \\ln(\\alpha) - (T-x) \\ln(1 - \\alpha) \\right]$$\nUnder $H_0$, this statistic is asymptotically distributed as a chi-square distribution with one degree of freedom, $\\chi^2_1$. The null hypothesis is rejected at a significance level of $0.05$ if $LR_{uc}$ exceeds the critical value $\\chi^2_{1, 0.95} \\approx 3.841$. A rejection implies the VaR model fails the backtest.\n\n- **ES Quality Assessment:** The quality of the ES forecast $e$ is assessed by comparing it to the realized average of the exceedance losses, $\\widehat{\\mathrm{ES}}$.\n$$\\widehat{\\mathrm{ES}} = \\frac{1}{x} \\sum_{t: L_t > v} L_t$$\nThe relative error $\\varepsilon$ is computed as:\n$$\\varepsilon = \\frac{\\lvert \\widehat{\\mathrm{ES}} - e \\rvert}{e}$$\nThe ES forecast is deemed \"high-quality\" if this error is within a given tolerance $\\tau = 0.05$, i.e., if $\\varepsilon \\le 0.05$.\n\n**4. Simulation Execution**\n\nThe simulation proceeds by executing the above steps for each of the three test cases. A fixed random seed is used to ensure deterministic and reproducible outcomes.\n\n- **Case 1 ($r=1.0$):** $$x = \\text{round}(1.0 \\cdot 0.01 \\cdot 5000) = 50$$ The empirical exceedance rate $\\hat{p} = 50/5000 = 0.01$, which is exactly $\\alpha$. The $LR_{uc}$ statistic is $0$, which is below the critical value. The $\\mathrm{VaR}$ test passes. The realized ES, $\\widehat{\\mathrm{ES}}$, will be close to the true mean $e$ due to the law of large numbers, likely resulting in a small error $\\varepsilon$ and a high-quality assessment.\n- **Case 2 ($r=2.0$):** $$x = \\text{round}(2.0 \\cdot 0.01 \\cdot 5000) = 100$$ The empirical rate is $\\hat{p} = 100/5000 = 0.02$, double the hypothesized $\\alpha$. This large discrepancy will lead to a large $LR_{uc}$ statistic, causing the $\\mathrm{VaR}$ test to fail. However, the DGP is still constructed such that the conditional mean of exceedances is $e$. Thus, $\\widehat{\\mathrm{ES}}$ is expected to be close to $e$, and the $\\mathrm{ES}$ forecast will be deemed high-quality. This is the central paradoxical result.\n- **Case 3 ($r=1.2$):** $$x = \\text{round}(1.2 \\cdot 0.01 \\cdot 5000) = 60$$ The empirical rate is $\\hat{p} = 60/5000 = 0.012$. The deviation from $\\alpha$ is small. The resulting $LR_{uc}$ statistic may not be large enough to exceed the critical value, demonstrating a low-power scenario where the $\\mathrm{VaR}$ test fails to detect the bias. The ES quality is expected to remain high.\n\nThe implementation will compute these outcomes and report the specified boolean values.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, chi2\n\ndef solve():\n    \"\"\"\n    Runs a deterministic simulation to demonstrate that a model with high-quality\n    Expected Shortfall (ES) forecasts can fail a standard Value-at-Risk (VaR)\n    backtest for unconditional coverage.\n    \"\"\"\n    # Use a fixed random seed for deterministic and reproducible results.\n    SEED = 42\n    rng = np.random.default_rng(SEED)\n\n    # --- Common parameters from the problem statement ---\n    alpha = 0.01            # Tail probability\n    var_test_sig_level = 0.05 # Significance level for the VaR LR test\n    xi = 0.10               # GPD shape parameter\n    tau = 0.05              # Relative error tolerance for ES quality\n    \n    # Confidence level for VaR and ES\n    c = 1 - alpha\n    \n    # --- Step 1: Calculate the model's constant forecasts (v, e) ---\n    # The model assumes losses are standard normal Z ~ N(0, 1).\n    # v is the c-quantile of the standard normal distribution.\n    v = norm.ppf(c)\n    # e is the expected value of Z given Z  v.\n    e = norm.pdf(v) / alpha\n    \n    # --- Pre-calculate the critical value for the LR test ---\n    # The LR statistic is asymptotically chi-square distributed with 1 df.\n    chi2_critical_value = chi2.ppf(1 - var_test_sig_level, df=1)\n\n    # --- Define the test cases ---\n    test_cases = [\n        # (T, r)\n        (5000, 1.0),  # Case 1: Happy path\n        (5000, 2.0),  # Case 2: Paradox\n        (5000, 1.2),  # Case 3: Low-power edge\n    ]\n\n    results = []\n    \n    # --- Step 2: Run simulation for each test case ---\n    for T, r in test_cases:\n        # --- a. Determine exceedance count deterministically ---\n        x = int(np.round(r * alpha * T))\n        T_minus_x = T - x\n\n        # Ensure x is within (0, T) to avoid log(0) issues in LR test.\n        # The test cases provided guarantee this.\n        assert 0  x  T, \"Number of exceedances must be between 0 and T.\"\n\n        # --- b. Generate simulated losses based on the true DGP ---\n        \n        # Exceedance losses: drawn from a GPD to match the model's ES 'e'\n        # The GPD scale parameter beta is chosen to match the conditional mean.\n        # E[L | L  v] = v + beta / (1 - xi) = e\n        beta = (e - v) * (1 - xi)\n        \n        # Generate GPD variates using inverse transform sampling (first principles)\n        # W = (beta / xi) * ((1 - U)^(-xi) - 1) for U ~ U(0,1)\n        u_samples_gpd = rng.uniform(size=x)\n        excess_losses = (beta / xi) * (np.power(1 - u_samples_gpd, -xi) - 1)\n        exceedance_losses = v + excess_losses\n        \n        # Non-exceedance losses: drawn from U[0, v]\n        # This is not strictly required for the tests but completes the DGP.\n        # non_exceedance_losses = rng.uniform(low=0.0, high=v, size=T_minus_x)\n\n        # --- c. Perform VaR unconditional coverage backtest ---\n        p_hat = x / T\n        \n        # Log-likelihood under the alternative hypothesis (p = p_hat)\n        log_L1 = x * np.log(p_hat) + T_minus_x * np.log(1 - p_hat)\n        # Log-likelihood under the null hypothesis (p = alpha)\n        log_L0 = x * np.log(alpha) + T_minus_x * np.log(1 - alpha)\n        \n        # Likelihood-ratio statistic\n        lr_uc_statistic = 2 * (log_L1 - log_L0)\n        \n        # VaR backtest fails if the statistic exceeds the critical value\n        var_fail = lr_uc_statistic  chi2_critical_value\n        results.append(var_fail)\n\n        # --- d. Evaluate ES forecast quality ---\n        # Realized tail average (sample mean of exceedance losses)\n        es_hat = np.mean(exceedance_losses)\n        \n        # Relative error of the ES forecast\n        epsilon = np.abs(es_hat - e) / e\n        \n        # ES forecast is high-quality if the relative error is within tolerance\n        es_good = epsilon = tau\n        results.append(es_good)\n        \n    # --- Final print statement in the exact required format ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}