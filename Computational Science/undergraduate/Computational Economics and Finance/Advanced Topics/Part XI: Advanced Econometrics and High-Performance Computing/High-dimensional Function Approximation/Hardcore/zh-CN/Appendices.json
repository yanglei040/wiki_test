{
    "hands_on_practices": [
        {
            "introduction": "这个首个练习是一个基础的起点。我们将实现一个稀疏网格插值器，来逼近一个复杂但平滑的五维函数。这项练习将帮助你掌握使用Clenshaw-Curtis节点的组合技术的核心机制，并观察随着我们提高插值水平，逼近误差是如何减小的，从而展示稀疏网格在处理合适问题时的威力。",
            "id": "2399817",
            "problem": "设 $d = 5$ 并考虑紧致超立方体域 $[0,1]^5$。定义光滑、高度非可加函数 $f : [0,1]^5 \\to \\mathbb{R}$ 如下\n$$\nf(x_1,x_2,x_3,x_4,x_5) \\;=\\; \\exp\\!\\big(0.5\\,x_1 x_2 + 0.25\\,x_3\\big)\\,\\cos\\!\\Big(\\pi\\big(x_1 x_3 + 2.0\\,x_2 x_4\\big)\\Big)\\;+\\;\\sin\\!\\Big(2\\pi\\big(x_4 x_5 + 0.1\\,x_1\\big)\\Big)\\;+\\;0.05\\,x_1 x_2 x_3 x_4 x_5,\n$$\n其中所有三角函数参数的单位均为弧度。\n\n您的任务是使用一个在 $[0,1]^5$ 上的五维稀疏网格插值，在三个近似水平 $\\ell \\in \\{1,2,3\\}$ 上逼近 $f$，并在一个固定的评估集上量化逼近质量。对于每个水平 $\\ell$，计算插值相对于 $f$ 在以下15个测试点上评估时的最大逐点绝对误差：\n$$\n\\begin{aligned}\n(\\,0.5,\\,0.5,\\,0.5,\\,0.5,\\,0.5\\,),\\quad (\\,0,\\,0,\\,0,\\,0,\\,0\\,),\\quad (\\,1,\\,1,\\,1,\\,1,\\,1\\,),\\quad (\\,0,\\,1,\\,0,\\,1,\\,0\\,),\\quad (\\,1,\\,0,\\,1,\\,0,\\,1\\,),\\\\\n(\\,0.25,\\,0.75,\\,0.33,\\,0.67,\\,0.5\\,),\\quad (\\,0.9,\\,0.1,\\,0.2,\\,0.8,\\,0.3\\,),\\quad (\\,0.1,\\,0.9,\\,0.8,\\,0.2,\\,0.7\\,),\\\\\n(\\,0.3,\\,0.3,\\,0.7,\\,0.7,\\,0.2\\,),\\quad (\\,0.6,\\,0.4,\\,0.2,\\,0.9,\\,0.1\\,),\\quad (\\,0.15,\\,0.85,\\,0.55,\\,0.45,\\,0.35\\,),\\\\\n(\\,0.8,\\,0.2,\\,0.6,\\,0.4,\\,0.5\\,),\\quad (\\,0.2,\\,0.8,\\,0.4,\\,0.6,\\,0.9\\,),\\quad (\\,0.05,\\,0.95,\\,0.25,\\,0.75,\\,0.35\\,),\\quad (\\,0.4,\\,0.4,\\,0.4,\\,0.4,\\,0.4\\,).\n\\end{aligned}\n$$\n\n测试套件包含三个水平 $\\ell \\in \\{1,2,3\\}$。对于每个 $\\ell$，所需的答案是一个等于上述测试集上最大绝对误差的实数。您的程序必须生成单行输出，其中包含这三个结果，形式为按 $\\ell = 1$、$\\ell = 2$、$\\ell = 3$ 顺序排列、用方括号括起来的逗号分隔列表，每个实数四舍五入到6位小数。例如，所需格式的输出为\n$$\n[\\;e_1,\\,e_2,\\,e_3\\;],\n$$\n其中 $e_\\ell$ 表示在水平 $\\ell$ 上的最大绝对误差，四舍五入到6位小数。\n\n程序没有外部输入，也不涉及物理单位。三角函数中的所有角度都以弧度为单位。最终输出必须是指定格式的精确一行。",
            "solution": "问题陈述经过验证，被认为是有效的。它在数值分析这一成熟领域，特别是在高维函数逼近方面，具有科学依据。该问题是适定的、客观的，并提供了构建唯一、可验证解所需的所有必要信息。任务是实现一种标准的数值算法，即稀疏网格插值法，并评估其性能。\n\n求解过程如下。任务的核心是使用稀疏网格插值（记为 $\\mathcal{A}_{\\ell,d}f$）来逼近一个给定的 $d=5$ 维函数 $f: [0,1]^5 \\to \\mathbb{R}$，其近似水平为 $\\ell \\in \\{1, 2, 3\\}$。然后通过计算在一个预定的15个测试点集上的最大绝对误差来评估该插值的准确性。\n\n稀疏网格插值是使用组合技术构建的，该技术结合了建立在各向异性网格上的多个张量积插值。这种方法通过明智地选择对逼近精度贡献最大的网格配置来缓解维度灾难。对于定义在 $d$ 维域上的函数 $f$，其水平为 $\\ell$ 的稀疏网格插值由以下公式给出：\n$$\n\\mathcal{A}_{\\ell,d}f(x) = \\sum_{q=0}^{\\min(\\ell, d-1)} (-1)^q \\binom{d-1}{q} \\sum_{|\\mathbf{i}|_1 = \\ell-q} \\mathcal{I}^{\\mathbf{i}}f(x)\n$$\n其中：\n- $\\mathbf{i} = (i_1, i_2, \\dots, i_d)$ 是一个非负整数的多重指标，表示每个维度中一维插值的水平。\n- $|\\mathbf{i}|_1 = i_1 + i_2 + \\dots + i_d$ 是水平之和。\n- $\\mathcal{I}^{\\mathbf{i}}f(x)$ 是由水平为 $i_1, \\dots, i_d$ 的一维插值构建的张量积插值。\n- $\\binom{n}{k}$ 是二项式系数。\n\n$\\mathcal{I}^{\\mathbf{i}}f(x)$ 的构建依赖于一维插值规则的选择。由于其优越的稳定性和准确性，我们使用基于 Clenshaw-Curtis 节点的拉格朗日插值。在区间 $[0,1]$ 上，水平为 $i \\ge 0$ 的一维 Clenshaw-Curtis 网格定义如下：\n- 对于水平 $i=0$：$m_0=1$ 个点，位于 $x_0=0.5$。\n- 对于水平 $i > 0$：$m_i=2^i+1$ 个点，由 $x_k = \\frac{1}{2}\\left(1 - \\cos\\left(\\frac{k\\pi}{m_i-1}\\right)\\right)$ 给出，其中 $k=0, 1, \\dots, m_i-1$。\n\n对于点 $x=(x_1, \\dots, x_d)$，其张量积插值 $\\mathcal{I}^{\\mathbf{i}}f(x)$ 计算如下：\n$$\n\\mathcal{I}^{\\mathbf{i}}f(x) = \\sum_{p \\in \\mathcal{G}_{\\mathbf{i}}} f(p) \\prod_{j=1}^{d} L_{i_j, p_j}(x_j)\n$$\n这里，$\\mathcal{G}_{\\mathbf{i}} = X_{i_1} \\times X_{i_2} \\times \\dots \\times X_{i_d}$ 是张量积网格，其中 $X_{i_j}$ 是水平为 $i_j$ 的一维节点集。$L_{i_j, p_j}(x_j)$ 项表示维度 $j$ 中节点 $p_j$ 的一维拉格朗日基多项式，在坐标 $x_j$ 处求值。\n\n计算算法的结构如下：\n1.  对于每个近似水平 $\\ell \\in \\{1, 2, 3\\}$，遍历所提供的15个测试点。\n2.  对于每个测试点 $x_{test}$，使用组合公式计算稀疏网格插值 $\\mathcal{A}_{\\ell,d}f(x_{test})$ 的值。这包括：\n    a.  遍历 $q$ 从 $0$ 到 $\\min(\\ell, d-1)$。\n    b.  生成所有满足 $|\\mathbf{i}|_1 = \\ell-q$ 的多重指标 $\\mathbf{i}$。\n    c.  对于每个多重指标 $\\mathbf{i}$，计算相应的张量积插值 $\\mathcal{I}^{\\mathbf{i}}f(x_{test})$ 的值。\n    d.  将这些值按组合系数 $(-1)^q \\binom{d-1}{q}$ 加权求和。\n3.  为优化性能，函数 $f$ 在网格点上的求值被缓存，因为许多张量积插值会使用相同的网格点。在适当的情况下，递归和中间计算也被记忆化。\n4.  对于每个测试点，计算绝对误差 $|\\,f(x_{test}) - \\mathcal{A}_{\\ell,d}f(x_{test})\\,|$。\n5.  在所有15个测试点上的这些绝对误差的最大值被记录为水平 $\\ell$ 的结果。\n6.  最终输出是 $\\ell=1, 2, 3$ 的这些最大误差的列表，按要求格式化为6位小数。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import comb\nfrom itertools import product\nfrom functools import lru_cache\n\n# The target function to be approximated, as defined in the problem.\ndef f_definition(x):\n    \"\"\"The function f, vectorized for efficient evaluation on NumPy arrays.\"\"\"\n    x1, x2, x3, x4, x5 = x\n    term1 = np.exp(0.5 * x1 * x2 + 0.25 * x3) * np.cos(np.pi * (x1 * x3 + 2.0 * x2 * x4))\n    term2 = np.sin(2 * np.pi * (x4 * x5 + 0.1 * x1))\n    term3 = 0.05 * x1 * x2 * x3 * x4 * x5\n    return term1 + term2 + term3\n\n# Caching for function evaluations. The key is a tuple representation of the point.\nfunc_eval_cache = {}\n\ndef f_cached(p_tuple):\n    \"\"\"A wrapper for f_definition that uses a cache to avoid re-computation.\"\"\"\n    if p_tuple not in func_eval_cache:\n        func_eval_cache[p_tuple] = f_definition(np.array(p_tuple))\n    return func_eval_cache[p_tuple]\n\n@lru_cache(maxsize=None)\ndef get_1d_nodes(level):\n    \"\"\"\n    Computes 1D Clenshaw-Curtis nodes on [0,1] for a given hierarchical level.\n    Level 0 corresponds to a single point at the domain center.\n    Level i > 0 corresponds to 2^i+1 points. The results are cached.\n    \"\"\"\n    if level == 0:\n        return (0.5,)  # Return as tuple for hashability\n    num_points = 2**level + 1\n    k = np.arange(num_points)\n    nodes = 0.5 * (1.0 - np.cos(k * np.pi / (num_points - 1)))\n    return tuple(nodes)\n\n@lru_cache(maxsize=None)\ndef generate_multi_indices(d, s):\n    \"\"\"\n    Generates all d-dimensional multi-indices i with |i|_1 = s.\n    The recursive generation is memoized for efficiency.\n    \"\"\"\n    if d == 1:\n        return [(s,)]\n    indices = []\n    for i in range(s + 1):\n        # Recursively find indices for the remaining dimensions and sum\n        sub_indices = generate_multi_indices(d - 1, s - i)\n        for sub in sub_indices:\n            indices.append((i,) + sub)\n    return indices\n\ndef get_1d_lagrange_basis_eval(t, nodes_tuple, k):\n    \"\"\"\n    Evaluates the k-th 1D Lagrange basis polynomial at point t.\n    The nodes are passed as a tuple to enable potential caching if this function were wrapped.\n    \"\"\"\n    nodes = np.array(nodes_tuple)\n    xk = nodes[k]\n\n    if np.isclose(t, xk):\n        return 1.0\n\n    numerator = 1.0\n    denominator = 1.0\n    for j, xj in enumerate(nodes):\n        if j != k:\n            numerator *= (t - xj)\n            denominator *= (xk - xj)\n    \n    # This prevents division by zero if t is close to another node,\n    # making the numerator near-zero.\n    if np.isclose(denominator, 0.0):\n        return 0.0\n        \n    return numerator / denominator\n\ndef solve():\n    \"\"\"\n    Main solver function to perform sparse grid interpolation and error calculation.\n    \"\"\"\n    D = 5\n    LEVELS = [1, 2, 3]\n    TEST_POINTS = np.array([\n        [0.5, 0.5, 0.5, 0.5, 0.5], [0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0],\n        [0.0, 1.0, 0.0, 1.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0],\n        [0.25, 0.75, 0.33, 0.67, 0.5], [0.9, 0.1, 0.2, 0.8, 0.3], [0.1, 0.9, 0.8, 0.2, 0.7],\n        [0.3, 0.3, 0.7, 0.7, 0.2], [0.6, 0.4, 0.2, 0.9, 0.1], [0.15, 0.85, 0.55, 0.45, 0.35],\n        [0.8, 0.2, 0.6, 0.4, 0.5], [0.2, 0.8, 0.4, 0.6, 0.9], [0.05, 0.95, 0.25, 0.75, 0.35],\n        [0.4, 0.4, 0.4, 0.4, 0.4]\n    ])\n\n    final_errors = []\n\n    for l_level in LEVELS:\n        max_level_error = 0.0\n        \n        # Cache for tensor product interpolation results, reset for each test point.\n        tensor_interp_cache = {}\n\n        def get_tensor_interp_val(x_test_tuple, mi_tuple):\n            \"\"\"Computes or retrieves from cache the tensor product interpolant value.\"\"\"\n            if mi_tuple in tensor_interp_cache:\n                return tensor_interp_cache[mi_tuple]\n\n            nodes_per_dim = [get_1d_nodes(mi) for mi in mi_tuple]\n            node_indices_ranges = [range(len(nodes)) for nodes in nodes_per_dim]\n            \n            total_sum = 0.0\n            for index_tuple in product(*node_indices_ranges):\n                \n                grid_point = tuple(nodes_per_dim[i][index_tuple[i]] for i in range(D))\n                func_val = f_cached(grid_point)\n                \n                basis_product = 1.0\n                for i in range(D):\n                    basis_val = get_1d_lagrange_basis_eval(x_test_tuple[i], nodes_per_dim[i], index_tuple[i])\n                    basis_product *= basis_val\n                \n                total_sum += func_val * basis_product\n            \n            tensor_interp_cache[mi_tuple] = total_sum\n            return total_sum\n\n        for x_test_point in TEST_POINTS:\n            x_test_tuple = tuple(x_test_point)\n            tensor_interp_cache.clear()\n            \n            interpolant_val = 0.0\n            for q in range(min(l_level, D - 1) + 1):\n                comb_coeff = ((-1)**q) * comb(D - 1, q, exact=True)\n                if comb_coeff == 0:\n                    continue\n                \n                s = l_level - q\n                multi_indices = generate_multi_indices(D, s)\n                \n                term_sum = 0.0\n                for mi_tuple in multi_indices:\n                    term_sum += get_tensor_interp_val(x_test_tuple, mi_tuple)\n                \n                interpolant_val += comb_coeff * term_sum\n\n            exact_val = f_definition(x_test_point)\n            error = abs(exact_val - interpolant_val)\n            if error > max_level_error:\n                max_level_error = error\n        \n        final_errors.append(f\"{max_level_error:.6f}\")\n\n    print(f\"[{','.join(final_errors)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在许多现实世界的经济模型中，并非所有状态变量都同等重要。本练习将介绍各向异性稀疏网格的概念，这是一种至关重要的优化方法，它将更多的计算资源分配给更重要的维度。通过为一个前两个维度占主导地位的10维函数构建各向异性网格，你将直接看到这种有针对性的方法如何能比各向同性网格带来更高效、更准确的逼近。",
            "id": "2432646",
            "problem": "您的任务是使用基于 Smolyak 构造的各向异性稀疏网格，来近似一个超立方体上的高维函数。定义域为单位超立方体 $[0,1]^{10}$。令 $d = 10$。对于每个维度 $i \\in \\{1,\\dots,d\\}$ 和每个层级 $\\ell_i \\in \\mathbb{N}$ (其中 $\\ell_i \\ge 1$)，定义一维嵌套二进网格\n$$\nX_{\\ell_i} = \\left\\{ \\frac{j}{2^{\\ell_i - 1}} \\,:\\, j = 0,1,\\dots,2^{\\ell_i - 1} \\right\\} \\subset [0,1].\n$$\n对于一个多重指标 $\\boldsymbol{\\ell} = (\\ell_1,\\dots,\\ell_d)$，定义全张量网格\n$$\nG_{\\boldsymbol{\\ell}} = X_{\\ell_1} \\times \\cdots \\times X_{\\ell_d}.\n$$\n令 $U_{\\boldsymbol{\\ell}}$ 为 $G_{\\boldsymbol{\\ell}}$ 上的 $d$ 变量多线性节点插值算子，它通过二进网格上的一维线性拉格朗日基函数的张量积来定义。\n\n令 $\\boldsymbol{\\alpha} = (\\alpha_1,\\dots,\\alpha_d)$ 为一个正整数各向异性权重向量，并令 $Q \\in \\mathbb{N}$ 且 $Q \\ge 0$。定义下闭索引集\n$$\n\\mathcal{I}(\\boldsymbol{\\alpha}, Q) = \\left\\{ \\boldsymbol{\\ell} \\in \\mathbb{N}^d \\,:\\, \\ell_i \\ge 1 \\text{ for all } i, \\ \\sum_{i=1}^d \\alpha_i (\\ell_i - 1) \\le Q \\right\\}.\n$$\n考虑全网格插值的线性组合\n$$\n\\mathcal{S}_{\\boldsymbol{\\alpha},Q} = \\sum_{\\boldsymbol{\\ell} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q)} c_{\\boldsymbol{\\ell}} \\, U_{\\boldsymbol{\\ell}},\n$$\n其系数 $\\{c_{\\boldsymbol{\\ell}}\\}$ 由插值一致性条件所刻画\n$$\n\\sum_{\\boldsymbol{k} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q), \\, \\boldsymbol{k} \\ge \\boldsymbol{\\ell}} c_{\\boldsymbol{k}} = 1 \\quad \\text{for every } \\boldsymbol{\\ell} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q),\n$$\n其中 $\\boldsymbol{k} \\ge \\boldsymbol{\\ell}$ 表示按分量定义的偏序，即对所有 $i$ 都有 $k_i \\ge \\ell_i$。此条件确保 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$ 在 $\\bigcup_{\\boldsymbol{\\ell} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q)} G_{\\boldsymbol{\\ell}}$ 中的每个节点上都对目标函数进行插值。\n\n您的程序必须在 $[0,1]^{10}$ 上实现 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$ 并在指定点上对其求值。使用以下两个目标函数，每个函数都针对 $\\boldsymbol{x} = (x_1,\\dots,x_{10}) \\in [0,1]^{10}$ 定义：\n- $f_1(\\boldsymbol{x}) = \\exp(x_1) + \\sin(2\\pi x_2) + 0.1 \\sum_{i=3}^{10} 0.5^{\\,i} \\, x_i^2$。\n- $f_2(\\boldsymbol{x}) = \\log(1 + 5 x_1) + \\sqrt{1 + x_2} + 0.01 \\sum_{i=3}^{10} x_i$。\n所有三角函数的参数都应解释为弧度。自然对数函数是 $\\log(\\cdot)$，主平方根是 $\\sqrt{\\cdot}$。\n\n使用以下求值点集 $\\mathcal{E} = \\{\\boldsymbol{y}^{(k)}\\}_{k=1}^{5} \\subset [0,1]^{10}$，其中每个 $\\boldsymbol{y}^{(k)}$ 都明确给出：\n- $\\boldsymbol{y}^{(1)} = (0.13,\\,0.77,\\,0.50,\\,0.20,\\,0.80,\\,0.33,\\,0.66,\\,0.10,\\,0.90,\\,0.42)$,\n- $\\boldsymbol{y}^{(2)} = (0.31,\\,0.62,\\,0.25,\\,0.75,\\,0.40,\\,0.60,\\,0.20,\\,0.80,\\,0.35,\\,0.65)$,\n- $\\boldsymbol{y}^{(3)} = (0.73,\\,0.27,\\,0.15,\\,0.85,\\,0.55,\\,0.45,\\,0.05,\\,0.95,\\,0.22,\\,0.78)$,\n- $\\boldsymbol{y}^{(4)} = (0.50,\\,0.50,\\,0.10,\\,0.90,\\,0.30,\\,0.70,\\,0.25,\\,0.75,\\,0.40,\\,0.60)$,\n- $\\boldsymbol{y}^{(5)} = (0.21,\\,0.84,\\,0.63,\\,0.37,\\,0.12,\\,0.88,\\,0.47,\\,0.53,\\,0.19,\\,0.81)$.\n\n定义偏重前两个维度的各向异性权重为\n$$\n\\boldsymbol{\\alpha}^{\\mathrm{aniso}} = (1,\\,1,\\,4,\\,4,\\,4,\\,4,\\,4,\\,4,\\,4,\\,4),\n$$\n以及各向同性权重为\n$$\n\\boldsymbol{\\alpha}^{\\mathrm{iso}} = (1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,1).\n$$\n\n测试套件。您的程序必须执行以下四个测试用例，并为每个用例报告一个标量结果：\n- 测试 $1$：使用 $\\boldsymbol{\\alpha} = \\boldsymbol{\\alpha}^{\\mathrm{aniso}}$ 和 $Q = 8$ 为 $f_1$ 构建 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$。计算在 $\\mathcal{E}$ 上的最大绝对误差，\n$$\n\\max_{\\boldsymbol{y} \\in \\mathcal{E}} \\left| \\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f_1](\\boldsymbol{y}) - f_1(\\boldsymbol{y}) \\right|.\n$$\n- 测试 $2$：使用 $\\boldsymbol{\\alpha} = \\boldsymbol{\\alpha}^{\\mathrm{iso}}$ 和 $Q = 3$ 为 $f_1$ 构建 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$。计算在 $\\mathcal{E}$ 上的最大绝对误差。\n- 测试 $3$：使用 $\\boldsymbol{\\alpha} = \\boldsymbol{\\alpha}^{\\mathrm{aniso}}$ 和 $Q = 6$ 为 $f_2$ 构建 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$。计算在 $\\mathcal{E}$ 上的最大绝对误差。\n- 测试 $4$：使用 $\\boldsymbol{\\alpha} = \\boldsymbol{\\alpha}^{\\mathrm{aniso}}$ 和 $Q = 8$ 为 $f_1$ 构建 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$。在单点 $\\boldsymbol{0} = (0,0,0,0,0,0,0,0,0,0)$ 上计算绝对误差，\n$$\n\\left| \\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f_1](\\boldsymbol{0}) - f_1(\\boldsymbol{0}) \\right|.\n$$\n\n最终输出格式。您的程序应生成单行输出，其中包含按顺序排列的四个结果，形式为用方括号括起来的逗号分隔列表，例如\n$$\n[{\\tt r1},{\\tt r2},{\\tt r3},{\\tt r4}],\n$$\n其中每个 ${\\tt rj}$ 是一个实数（一个浮点值）。",
            "solution": "用户提供了一个在数值分析领域中定义明确的问题，具体涉及使用各向异性稀疏网格近似高维函数。该问题具有科学依据，内部逻辑一致，并包含其求解所需的所有信息。因此，我将着手提供一个完整的解决方案。\n\n核心任务是在指定点 $\\boldsymbol{y} \\in [0,1]^{10}$ 上对稀疏网格插值 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f]$ 进行求值。该插值使用组合技术公式定义：\n$$\n\\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f](\\boldsymbol{y}) = \\sum_{\\boldsymbol{\\ell} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q)} c_{\\boldsymbol{\\ell}} \\, U_{\\boldsymbol{\\ell}}[f](\\boldsymbol{y})\n$$\n其中 $f$ 是目标函数，$\\boldsymbol{y}$ 是一个求值点，$\\mathcal{I}(\\boldsymbol{\\alpha}, Q)$ 是一个下闭多重指标集，$c_{\\boldsymbol{\\ell}}$ 是组合系数，$U_{\\boldsymbol{\\ell}}[f](\\boldsymbol{y})$ 是一个全张量积多线性插值的值。\n\n对每个测试用例，该解决方案通过一系列模块化步骤实现：\n1.  **生成索引集**：构造集合 $\\mathcal{I}(\\boldsymbol{\\alpha}, Q) = \\left\\{ \\boldsymbol{\\ell} \\in \\mathbb{N}^d \\,:\\, \\ell_i \\ge 1, \\ \\sum_{i=1}^d \\alpha_i (\\ell_i - 1) \\le Q \\right\\}$。为高效实现此过程，我们定义层级向量 $\\boldsymbol{k} = (\\ell_1-1, \\dots, \\ell_d-1)$，其中每个 $k_i \\ge 0$。条件变为 $\\sum_{i=1}^d \\alpha_i k_i \\le Q$。采用递归回溯算法来寻找所有满足此不等式的有效向量 $\\boldsymbol{k} \\in \\mathbb{N}_0^d$。相应的多重指标 $\\boldsymbol{\\ell} = \\boldsymbol{k} + \\mathbf{1}$ 构成了集合 $\\mathcal{I}(\\boldsymbol{\\alpha}, Q)$。该集合存储在哈希集合中以实现高效查找。\n\n2.  **计算组合系数**：系数 $c_{\\boldsymbol{\\ell}}$ 由确保算子具有插值性的一致性条件确定。对于一个下闭索引集 $\\mathcal{I}$，该条件意味着 $c_{\\boldsymbol{\\ell}}$ 存在一个由容斥原理给出的唯一解：\n    $$\n    c_{\\boldsymbol{\\ell}} = \\sum_{J \\subseteq \\{1, \\dots, d\\}} (-1)^{|J|} \\mathbb{I}(\\boldsymbol{\\ell} + \\mathbf{e}_J \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q))\n    $$\n    其中 $\\mathbf{e}_J = \\sum_{j \\in J} \\mathbf{e}_j$，$\\mathbf{e}_j$ 是第 $j$ 个标准基向量。$\\mathbb{I}(\\cdot)$ 是指示函数，当条件成立时为 $1$，否则为 $0$。对于每个 $\\boldsymbol{\\ell} \\in \\mathcal{I}$，我们遍历维度的所有 $2^d$ 个子集 $J$，检查相邻索引 $\\boldsymbol{\\ell}+\\mathbf{e}_J$ 是否在 $\\mathcal{I}$ 中，并对带符号的贡献求和。对于 $d=10$，每个系数需要进行 $2^{10} = 1024$ 次检查，这在计算上是可行的。\n\n3.  **全张量积插值的求值**：项 $U_{\\boldsymbol{\\ell}}[f](\\boldsymbol{y})$ 表示在点 $\\boldsymbol{y}$ 处对全张量网格 $G_{\\boldsymbol{\\ell}} = X_{\\ell_1} \\times \\cdots \\times X_{\\ell_d}$ 上的多线性插值进行求值。这一过程通过递归实现。$d$ 维插值的值通过在第一个维度上执行一维线性插值获得，其中所需的两个网格点上的值本身是通过在剩余变量上进行 $(d-1)$ 维插值计算的。这个过程在 $d$ 步后终止，需要在包围 $\\boldsymbol{y}$ 的 $G_{\\boldsymbol{\\ell}}$ 中的超矩形单元的 $2^d$ 个角点上进行函数求值。\n\n4.  **通过记忆化进行优化**：由于存在冗余计算，一个朴素的实现方式在计算上是不可行的。对不同的 $\\boldsymbol{\\ell}$ 求值 $U_{\\boldsymbol{\\ell}}[f](\\boldsymbol{y})$ 会重复需要在相同的网格点上计算 $f$ 的值。为消除这种冗余，所有的函数求值 $f(\\boldsymbol{x})$ 都在一个字典中进行记忆化（缓存）。当需要某个特定网格点 $\\boldsymbol{x}$ 上的 $f$ 值时，首先检查缓存，仅当该值未被计算过时才进行函数求值。\n\n5.  **组装与误差计算**：对于每个测试用例和每个求值点 $\\boldsymbol{y}$，通过对所有 $\\boldsymbol{\\ell} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q)$ 的贡献 $c_{\\boldsymbol{\\ell}} U_{\\boldsymbol{\\ell}}[f](\\boldsymbol{y})$ 求和来组装最终的近似值。然后计算绝对误差 $|\\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f](\\boldsymbol{y}) - f(\\boldsymbol{y})|$。按要求报告在求值点集 $\\mathcal{E}$ 上的最大误差。\n\n对于测试用例 4，求值点是 $\\boldsymbol{y} = \\boldsymbol{0} = (0,\\dots,0)$。点 $\\boldsymbol{0}$ 是每个网格 $G_{\\boldsymbol{\\ell}}$ 的成员，因为一维网格 $X_{\\ell_i}$ 总是包含 0。稀疏网格构造保证了在稀疏网格并集 $\\mathcal{H}_{\\boldsymbol{\\alpha},Q} = \\bigcup_{\\boldsymbol{\\ell} \\in \\mathcal{I}} G_{\\boldsymbol{\\ell}}$ 中的所有点上都具有插值性。由于 $\\boldsymbol{0} \\in \\mathcal{H}_{\\boldsymbol{\\alpha},Q}$，我们必然有 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f_1](\\boldsymbol{0}) = f_1(\\boldsymbol{0})$，这意味着绝对误差恰好为 $0$。这可以作为对实现正确性的一个解析性检验。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import combinations\nimport math\n\ndef solve():\n    \"\"\"\n    Implements and evaluates an anisotropic sparse grid interpolant.\n    \"\"\"\n    d = 10\n\n    # Define target functions\n    def f1(x_tuple):\n        x = np.array(x_tuple)\n        term1 = np.exp(x[0])\n        term2 = np.sin(2 * np.pi * x[1])\n        term3 = 0.1 * np.sum([0.5**(i + 3) * x[i + 2]**2 for i in range(8)])\n        return term1 + term2 + term3\n\n    def f2(x_tuple):\n        x = np.array(x_tuple)\n        term1 = np.log(1 + 5 * x[0])\n        term2 = np.sqrt(1 + x[1])\n        term3 = 0.01 * np.sum(x[2:])\n        return term1 + term2 + term3\n\n    # Define evaluation points\n    evaluation_set = [\n        (0.13, 0.77, 0.50, 0.20, 0.80, 0.33, 0.66, 0.10, 0.90, 0.42),\n        (0.31, 0.62, 0.25, 0.75, 0.40, 0.60, 0.20, 0.80, 0.35, 0.65),\n        (0.73, 0.27, 0.15, 0.85, 0.55, 0.45, 0.05, 0.95, 0.22, 0.78),\n        (0.50, 0.50, 0.10, 0.90, 0.30, 0.70, 0.25, 0.75, 0.40, 0.60),\n        (0.21, 0.84, 0.63, 0.37, 0.12, 0.88, 0.47, 0.53, 0.19, 0.81),\n    ]\n\n    # Define anisotropy weights\n    alpha_aniso = (1, 1, 4, 4, 4, 4, 4, 4, 4, 4)\n    alpha_iso = (1, 1, 1, 1, 1, 1, 1, 1, 1, 1)\n\n    # Define test cases\n    test_cases = [\n        {'f': f1, 'alpha': alpha_aniso, 'Q': 8, 'eval_points': evaluation_set},\n        {'f': f1, 'alpha': alpha_iso,   'Q': 3, 'eval_points': evaluation_set},\n        {'f': f2, 'alpha': alpha_aniso, 'Q': 6, 'eval_points': evaluation_set},\n        {'f': f1, 'alpha': alpha_aniso, 'Q': 8, 'eval_points': [tuple([0.0]*d)]},\n    ]\n\n    memo_indices = {}\n    memo_coeffs = {}\n\n    def generate_indices(alpha, Q):\n        indices = set()\n        k_levels = []\n\n        def find_k(dim_idx, current_sum):\n            if dim_idx == d:\n                indices.add(tuple(k + 1 for k in k_levels))\n                return\n\n            max_k = (Q - current_sum) // alpha[dim_idx]\n            for ki in range(max_k + 1):\n                k_levels.append(ki)\n                find_k(dim_idx + 1, current_sum + alpha[dim_idx] * ki)\n                k_levels.pop()\n        \n        find_k(0, 0)\n        return indices\n\n    def calculate_coeffs(index_set):\n        coeffs = {}\n        e_vectors = np.identity(d, dtype=int)\n        for l_tuple in index_set:\n            l_vec = np.array(l_tuple)\n            c_l = 0\n            for size in range(d + 1):\n                for J in combinations(range(d), size):\n                    l_prime_vec = l_vec.copy()\n                    for j_idx in J:\n                        l_prime_vec[j_idx] += 1\n                    \n                    if tuple(l_prime_vec) in index_set:\n                        c_l += (-1)**size\n            coeffs[l_tuple] = c_l\n        return coeffs\n    \n    def get_interpolant_evaluator(f_func, y_tuple, l_tuple, memo_f):\n        def recursive_eval(dim, partial_point):\n            if dim == d:\n                point = tuple(partial_point)\n                if point not in memo_f:\n                    memo_f[point] = f_func(point)\n                return memo_f[point]\n\n            k = l_tuple[dim]\n            y_i = y_tuple[dim]\n\n            if k == 1:\n                # Grid is {0, 1}\n                weight = y_i\n                if abs(weight)  1e-15: return recursive_eval(dim + 1, partial_point + [0.0])\n                if abs(weight - 1.0)  1e-15: return recursive_eval(dim + 1, partial_point + [1.0])\n                \n                val_left = recursive_eval(dim + 1, partial_point + [0.0])\n                val_right = recursive_eval(dim + 1, partial_point + [1.0])\n                return (1.0 - weight) * val_left + weight * val_right\n            \n            m = 1  (k - 1)  # 2**(k-1)\n            \n            if abs(y_i - 1.0)  1e-15:\n                return recursive_eval(dim + 1, partial_point + [1.0])\n\n            pos = y_i * m\n            j = int(pos)\n            weight = pos - j\n\n            left_coord = j / m\n            \n            if weight  1e-15:\n                return recursive_eval(dim + 1, partial_point + [left_coord])\n\n            right_coord = (j + 1) / m\n            \n            val_left = recursive_eval(dim + 1, partial_point + [left_coord])\n            val_right = recursive_eval(dim + 1, partial_point + [right_coord])\n            return (1.0 - weight) * val_left + weight * val_right\n\n        return recursive_eval(0, [])\n\n    results = []\n    for case in test_cases:\n        f_func = case['f']\n        alpha = case['alpha']\n        Q = case['Q']\n        eval_points = case['eval_points']\n        \n        case_key = (alpha, Q)\n        \n        if case_key in memo_indices:\n            index_set = memo_indices[case_key]\n        else:\n            index_set = generate_indices(alpha, Q)\n            memo_indices[case_key] = index_set\n\n        if case_key in memo_coeffs:\n            coeffs = memo_coeffs[case_key]\n        else:\n            coeffs = calculate_coeffs(index_set)\n            memo_coeffs[case_key] = coeffs\n        \n        memo_f = {}\n        max_abs_error = 0.0\n\n        for y_tuple in eval_points:\n            approx_val = 0.0\n            for l_tuple in index_set:\n                c_l = coeffs[l_tuple]\n                if abs(c_l)  1e-15:\n                    continue\n                \n                u_l_f_y = get_interpolant_evaluator(f_func, y_tuple, l_tuple, memo_f)\n                approx_val += c_l * u_l_f_y\n            \n            true_val = f_func(y_tuple)\n            abs_error = abs(approx_val - true_val)\n            \n            if abs_error > max_abs_error:\n                max_abs_error = abs_error\n        \n        results.append(max_abs_error)\n\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "理解一种方法的局限性与其了解其优势同样重要。这最后一个练习通过关注一个带有尖锐“扭结”或不可微性的函数，来挑战稀疏网格的普适性。你将比较一个基于全局多项式的Smolyak网格与一个局部逐片三线性插值器的性能，从而揭示为什么全局方法在处理非平滑特征时可能会遇到困难，并强调选择与函数底层结构相匹配的逼近方案的重要性。",
            "id": "2399802",
            "problem": "考虑坐标为 $(x,y,z)$ 的紧致域 $\\mathcal{D}=[-1,1]^3$。你的任务是构造一个特定的三维函数 $f:\\mathcal{D}\\to\\mathbb{R}$，该函数沿一个平面呈现一个不可微的扭折，使得对于一定范围的离散化参数，基于切比雪夫多项式并通过Smolyak稀疏网格组合的全局多项式插值，会比在均匀张量网格上的局部逐片三线性插值产生更大的均方根误差。完全从第一性原理出发：定义该函数，精确定义两种逼近算子，在固定的评估网格上对两者进行求值，并比较所得误差。\n\n使用以下数学定义。\n\n1) 函数类。对于一个固定的阈值参数 $\\tau\\in\\mathbb{R}$，定义\n$$\nf_\\tau(x,y,z)=\\max\\{0,\\; x+y+z-\\tau\\},\\quad (x,y,z)\\in[-1,1]^3.\n$$\n在下述每个测试用例中，选择并明确使用指定的特定成员 $f_{\\tau}$。\n\n2) 一维切比雪夫-洛巴托节点和重心权。对于正整数 $m\\ge 1$，定义节点\n$$\nx_j=\\cos\\left(\\frac{\\pi j}{m-1}\\right),\\quad j=0,1,\\dots,m-1,\n$$\n约定当 $m=1$ 时，单个节点为 $x_0=0$。相关的重心权 $\\lambda_j$ 为\n$$\n\\lambda_j = (-1)^j\\cdot \\delta_j,\\quad \\delta_j=\\begin{cases}\\tfrac{1}{2},  j\\in\\{0,m-1\\}\\ \\text{and}\\ m\\ge 2, \\\\[4pt] 1,  \\text{otherwise.}\\end{cases}\n$$\n当 $m=1$ 时，取 $\\lambda_0=1$。\n\n给定不同的节点 $(x_j)_{j=0}^{m-1}$、重心权 $(\\lambda_j)_{j=0}^{m-1}$ 和数据值 $(y_j)_{j=0}^{m-1}$，函数 $g$ 的一维重心插值多项式 $U_m[g]$ 是一个次数至多为 $m-1$ 的多项式，其逐点定义为\n$$\nU_m[g](x)=\n\\begin{cases}\ng(x_k),  \\text{if }x=x_k\\ \\text{for some }k,\\\\[6pt]\n\\dfrac{\\displaystyle \\sum_{j=0}^{m-1}\\dfrac{\\lambda_j}{x-x_j}g(x_j)}{\\displaystyle \\sum_{j=0}^{m-1}\\dfrac{\\lambda_j}{x-x_j}},  \\text{otherwise.}\n\\end{cases}\n$$\n\n3) $d=3$ 维中的Smolyak稀疏网格切比雪夫插值多项式。对于一维层级 $\\ell\\in\\mathbb{N}$，设\n$$\nm(\\ell)=\\begin{cases}\n1,  \\ell=1,\\\\\n2^{\\ell-1}+1,  \\ell\\ge 2,\n\\end{cases}\n$$\n并令 $U_{m(\\ell)}$ 为在基数为 $m(\\ell)$ 的切比雪夫-洛巴托节点上定义的上述一维插值多项式。对于总层级 $L\\in\\mathbb{N}$ 和 $d=3$，定义Smolyak指标集\n$$\n\\mathcal{I}_{L}=\\left\\{\\boldsymbol{\\ell}=(\\ell_1,\\ell_2,\\ell_3)\\in\\mathbb{N}^3:\\ \\ell_i\\ge 1,\\ \\ \\ell_1+\\ell_2+\\ell_3\\le L+2\\right\\}.\n$$\n对于 $\\boldsymbol{\\ell}\\in\\mathcal{I}_L$，定义组合系数\n$$\nw(\\boldsymbol{\\ell};L)=(-1)^{\\,L+2-(\\ell_1+\\ell_2+\\ell_3)}\\binom{2}{\\,L+2-(\\ell_1+\\ell_2+\\ell_3)\\,}.\n$$\nSmolyak插值多项式 $A_L[f]$ 是线性算子\n$$\nA_L[f](x,y,z)=\\sum_{\\boldsymbol{\\ell}\\in\\mathcal{I}_L} w(\\boldsymbol{\\ell};L)\\,\\big(U_{m(\\ell_1)}\\otimes U_{m(\\ell_2)}\\otimes U_{m(\\ell_3)}\\big)[f](x,y,z),\n$$\n其中 $\\otimes$ 表示沿每个坐标的一维插值多项式的张量积应用。\n\n4) 均匀张量网格和逐片三线性插值多项式。对于整数 $M\\ge 2$，在 $[-1,1]$ 上定义一个均匀网格，其节点为\n$$\n\\xi_j=-1+\\frac{2j}{M-1},\\quad j=0,1,\\dots,M-1.\n$$\n逐片三线性插值多项式 $T_M[f]$ 是在每个网格单元上为三线性函数，并在所有张量网格节点上与 $f$ 相匹配的唯一函数。\n\n5) 离散均方根误差 (RMSE)。对于整数 $E\\ge 2$，定义一个每轴有 $E$ 个节点的评估网格\n$$\n\\zeta_k=-1+\\frac{2k}{E-1},\\quad k=0,1,\\dots,E-1.\n$$\n给定 $\\mathcal{D}$ 上 $f$ 的一个逼近函数 $\\hat{f}$，定义离散均方根误差\n$$\n\\mathrm{RMSE}(\\hat{f},f)=\\left(\\frac{1}{E^3}\\sum_{i=0}^{E-1}\\sum_{j=0}^{E-1}\\sum_{k=0}^{E-1}\\big(\\hat{f}(\\zeta_i,\\zeta_j,\\zeta_k)-f(\\zeta_i,\\zeta_j,\\zeta_k)\\big)^2\\right)^{1/2}.\n$$\n\n实现一个完整的程序，对每个测试用例执行以下操作：构造指定的 $f_\\tau$，构造如上定义的 $A_L[f_\\tau]$ 和 $T_M[f_\\tau]$，在同一个评估网格上评估两个逼近函数和 $f_\\tau$，计算均方根误差，并报告标量差值\n$$\n\\Delta=\\mathrm{RMSE}\\big(A_L[f_\\tau],f_\\tau\\big)-\\mathrm{RMSE}\\big(T_M[f_\\tau],f_\\tau\\big).\n$$\n正的 $\\Delta$ 值表明，在Smolyak网格上的切比雪夫插值性能劣于逐片三线性插值。\n\n使用以下测试套件，该套件通过改变扭折位置和离散化层级来探查典型、边界邻近和较低层级的情况：\n\n- 测试用例1：$\\tau=0.0$, $L=4$, $M=25$, $E=31$。\n- 测试用例2：$\\tau=0.9$, $L=5$, $M=29$, $E=31$。\n- 测试用例3：$\\tau=-0.2$, $L=3$, $M=21$, $E=31$。\n\n最终输出格式。你的程序应生成单行输出，其中包含来自上述三个测试用例的数值结果 $\\Delta$，形式为用方括号括起来的逗号分隔列表，每个标量值四舍五入到六位小数（例如，$[\\delta_1,\\delta_2,\\delta_3]$）。",
            "solution": "问题陈述已经过严格验证，并被确定为有效。它在科学上基于数值分析和逼近理论的原理，问题设定良好，提供了所有必要的定义和参数，并以客观、正式的语言表述。该问题构成了一个计算数学中标准的、可验证的练习，旨在比较一种全局多项式逼近方法（Smolyak-Chebyshev）与一种局部逐片多项式方法（逐片三线性）在处理一个光滑度较低的函数时的效能。因此，我们将继续提供完整的解决方案。\n\n目标是计算在域 $\\mathcal{D}=[-1,1]^3$ 上，针对函数 $f_\\tau(x,y,z)=\\max\\{0,\\; x+y+z-\\tau\\}$ 的两种逼近方案之间的均方根误差之差 $\\Delta$。一个正的 $\\Delta$ 值表示Smolyak-Chebyshev方法的误差大于逐片三线性方法的误差。函数 $f_\\tau$ 在由 $x+y+z-\\tau=0$ 定义的平面上是连续但不可微的，在该处存在一个“扭折”。这种缺乏光滑性的特点是本题测试的核心。\n\n我们的步骤如下：\n1.  定义目标函数 $f_\\tau$ 和评估网格。\n2.  构造逐片三线性插值多项式 $T_M[f_\\tau]$ 并在网格上对其求值。\n3.  构造Smolyak稀疏网格插值多项式 $A_L[f_\\tau]$ 并在同一网格上对其求值。\n4.  计算两种逼近相对于真实函数的离散均方根误差 (RMSE)。\n5.  计算差值 $\\Delta = \\mathrm{RMSE}(A_L[f_\\tau]) - \\mathrm{RMSE}(T_M[f_\\tau])$。\n\n**1. 评估框架**\n\n对于每个测试用例，我们给定函数 $f_\\tau$ 的参数 $\\tau$、Smolyak网格的层级 $L$、三线性插值多项式的网格大小 $M$ 以及评估网格的分辨率 $E$。评估网格是 $\\mathcal{D}=[-1,1]^3$ 上的一个均匀张量积网格，每轴有 $E$ 个点，由节点 $\\zeta_k=-1+\\frac{2k}{E-1}$（$k=0, \\dots, E-1$）给出。所有的逼近函数和真实函数都将在此网格的 $E^3$ 个点上进行计算。\n\n**2. 逐片三线性插值多项式 $T_M[f_\\tau]$**\n\n此方法依赖于在均匀网格的每个单元内的局部逼近。\n首先，定义一个每轴有 $M$ 个节点的均匀张量网格：$\\xi_j=-1+\\frac{2j}{M-1}$（$j=0, \\dots, M-1$）。这将域 $\\mathcal{D}$ 划分为 $(M-1)^3$ 个立方单元。函数 $f_\\tau$ 在所有 $M^3$ 个网格节点上进行求值。\n\n为了在评估点 $(x,y,z)$ 处找到插值多项式 $T_M[f_\\tau]$ 的值，我们首先确定包含该点的单元 $[\\xi_{j_x}, \\xi_{j_x+1}] \\times [\\xi_{j_y}, \\xi_{j_y+1}] \\times [\\xi_{j_z}, \\xi_{j_z+1}]$。然后，使用该单元八个角点的已知函数值通过三线性插值计算出该值。这可以通过利用 `scipy.ndimage.map_coordinates` 函数来高效实现，该函数执行N维逐片线性插值。评估坐标 $(\\zeta_i, \\zeta_j, \\zeta_k)$ 在传递给该函数之前，会被映射到 $M$ 点网格的基于索引的坐标系中。\n\n**3. Smolyak稀疏网格插值多项式 $A_L[f_\\tau]$**\n\n对于足够光滑的函数，Smolyak构造提供了一种通过一维插值多项式的组合来构建高维插值多项式的方法，其维度扩展性优于完全张量积。维度 $d=3$ 和层级 $L$ 的算子是：\n$$\nA_L[f] = \\sum_{\\boldsymbol{\\ell}\\in\\mathcal{I}_L} w(\\boldsymbol{\\ell};L)\\,\\big(U_{m(\\ell_1)}\\otimes U_{m(\\ell_2)}\\otimes U_{m(\\ell_3)}\\big)[f]\n$$\n其中 $\\boldsymbol{\\ell}=(\\ell_1,\\ell_2,\\ell_3)$ 是一维层级的多重索引。其组成部分是：\n-   **指标集**：$\\mathcal{I}_{L}=\\left\\{\\boldsymbol{\\ell}\\in\\mathbb{N}^3:\\ \\ell_1+\\ell_2+\\ell_3\\le L+2\\right\\}$。\n-   **组合系数**：$w(\\boldsymbol{\\ell};L)=(-1)^{\\,L+2-|\\boldsymbol{\\ell}|_1}\\binom{2}{\\,L+2-|\\boldsymbol{\\ell}|_1\\,}$，其中 $|\\boldsymbol{\\ell}|_1=\\ell_1+\\ell_2+\\ell_3$。这些系数仅在 $L \\le |\\boldsymbol{\\ell}|_1 \\le L+2$ 时非零。\n-   **一维插值多项式**：$U_{m(\\ell)}$ 是在 $m(\\ell)$ 个切比雪夫-洛巴托节点上的重心多项式插值。节点数为 $m(1)=1$，当 $\\ell \\ge 2$ 时为 $m(\\ell)=2^{\\ell-1}+1$。\n\n$A_L[f_\\tau]$ 在评估网格上的求值过程如下：\n一个初始化为零的累加器网格用于存储最终的逼近值。我们遍历活动指标集（其中 $w(\\boldsymbol{\\ell};L) \\neq 0$）中的每个多重索引 $\\boldsymbol{\\ell}$。对于每个 $\\boldsymbol{\\ell}$：\na. 分别沿 $x$、$y$ 和 $z$ 轴，由 $m(\\ell_1)$、$m(\\ell_2)$ 和 $m(\\ell_3)$ 个切比雪夫-洛巴托节点构成一个稀疏张量积网格。\nb. 在该稀疏网格的所有节点上对真实函数 $f_\\tau$ 进行求值。\nc. 从这个稀疏网格到稠密的 $E \\times E \\times E$ 评估网格执行三维张量积重心插值。这是通过沿每个维度顺序应用一维重心插值公式来完成的。\nd. 将得到的插值结果乘以系数 $w(\\boldsymbol{\\ell};L)$ 并加到累加器网格中。\n\n由于其数值稳定性，一维重心插值公式对于切比雪夫点非常有效。对于一组节点 $(x_j)$、值 $(y_j)$ 和重心权 $(\\lambda_j)$，在点 $x$ 处的插值由 $\\left(\\sum_j \\frac{\\lambda_j y_j}{x-x_j}\\right) / \\left(\\sum_j \\frac{\\lambda_j}{x-x_j}\\right)$ 给出。\n\n**4. 误差计算与比较**\n\n在评估网格上计算出两种逼近 $A_L[f_\\tau]$ 和 $T_M[f_\\tau]$ 的值之后，计算它们各自的离散均方根误差：\n$$\n\\mathrm{RMSE}(\\hat{f},f)=\\left(\\frac{1}{E^3}\\sum_{i,j,k=0}^{E-1}\\big(\\hat{f}(\\zeta_i,\\zeta_j,\\zeta_k)-f_\\tau(\\zeta_i,\\zeta_j,\\zeta_k)\\big)^2\\right)^{1/2}\n$$\n每个测试用例的最终结果是差值 $\\Delta = \\mathrm{RMSE}(A_L[f_\\tau]) - \\mathrm{RMSE}(T_M[f_\\tau])$。函数 $f_\\tau$ 几乎处处是线性的，但其扭折违反了保证全局多项式方法快速收敛的光滑性假设。相比之下，逐片线性方法是局部的；其误差主要局限于被扭折穿过的单元。因此可以预见，对于给定的参数，$\\Delta$ 将为正值，这表明在这种情况下，局部的、低阶的方法更为优越。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import comb\nfrom scipy.ndimage import map_coordinates\n\ndef get_cheby_grid(m, cache):\n    \"\"\"\n    Computes or retrieves from cache the Chebyshev-Lobatto nodes and barycentric weights.\n    \"\"\"\n    if m in cache:\n        return cache[m]\n\n    if m == 1:\n        nodes = np.array([0.0])\n        weights = np.array([1.0])\n        cache[m] = (nodes, weights)\n        return nodes, weights\n\n    j = np.arange(m)\n    nodes = np.cos(np.pi * j / (m - 1))\n    \n    weights = (-1.0)**j\n    weights[0] *= 0.5\n    weights[-1] *= 0.5\n    \n    cache[m] = (nodes, weights)\n    return nodes, weights\n\ndef barycentric_interp1d(x_eval, x_nodes, y_nodes, bary_weights):\n    \"\"\"\n    Performs 1D barycentric interpolation on a vector of evaluation points.\n    \"\"\"\n    Ne = x_eval.shape[0]\n    Nm = x_nodes.shape[0]\n    \n    if Nm == 1:\n        return np.full(Ne, y_nodes[0])\n\n    interp_vals = np.zeros(Ne, dtype=np.float64)\n    exact_matches = np.zeros(Ne, dtype=bool)\n\n    # Handle cases where evaluation points are very close to nodes\n    for j in range(Nm):\n        matches = np.isclose(x_eval, x_nodes[j])\n        if np.any(matches):\n            interp_vals[matches] = y_nodes[j]\n            exact_matches |= matches\n\n    # Process points that are not nodes using the vectorized formula\n    non_match_indices = np.where(~exact_matches)[0]\n    if len(non_match_indices) > 0:\n        x_sub_eval = x_eval[non_match_indices]\n        \n        diff = x_sub_eval[:, None] - x_nodes[None, :]\n        temp = bary_weights[None, :] / diff\n        \n        numerator = np.sum(temp * y_nodes[None, :], axis=1)\n        denominator = np.sum(temp, axis=1)\n\n        # Avoid division by zero, although it is unlikely for non-node points\n        result = np.divide(numerator, denominator, \n                           out=np.zeros_like(numerator), \n                           where=denominator != 0)\n        \n        interp_vals[non_match_indices] = result\n\n    return interp_vals\n\ndef compute_smolyak_approx(f, L, eval_grid_1d, cache):\n    \"\"\"\n    Computes the Smolyak sparse grid approximation on the evaluation grid.\n    \"\"\"\n    E = len(eval_grid_1d)\n    approx_values = np.zeros((E, E, E), dtype=np.float64)\n\n    # Generate Smolyak index set and coefficients\n    indices_and_coeffs = []\n    max_level_sum = L + 2\n    for l1 in range(1, max_level_sum + 1):\n        for l2 in range(1, max_level_sum - l1 + 1):\n            for l3 in range(1, max_level_sum - l1 - l2 + 1):\n                level_sum = l1 + l2 + l3\n                k = max_level_sum - level_sum\n                if 0 = k = 2:\n                    w = ((-1)**k) * comb(2, k, exact=True)\n                    if w != 0:\n                        indices_and_coeffs.append(((l1, l2, l3), w))\n\n    m_func = lambda l: 1 if l == 1 else 2**(l - 1) + 1\n\n    for (l1, l2, l3), w in indices_and_coeffs:\n        m1, m2, m3 = m_func(l1), m_func(l2), m_func(l3)\n        \n        nodes1, weights1 = get_cheby_grid(m1, cache)\n        nodes2, weights2 = get_cheby_grid(m2, cache)\n        nodes3, weights3 = get_cheby_grid(m3, cache)\n\n        grid_x, grid_y, grid_z = np.meshgrid(nodes1, nodes2, nodes3, indexing='ij')\n        f_on_grid = f(grid_x, grid_y, grid_z)\n        \n        # Sequentially apply 1D interpolation\n        interp1 = np.zeros((E, m2, m3), dtype=np.float64)\n        for j in range(m2):\n            for k in range(m3):\n                interp1[:, j, k] = barycentric_interp1d(eval_grid_1d, nodes1, f_on_grid[:, j, k], weights1)\n\n        interp2 = np.zeros((E, E, m3), dtype=np.float64)\n        for i in range(E):\n            for k in range(m3):\n                interp2[i, :, k] = barycentric_interp1d(eval_grid_1d, nodes2, interp1[i, :, k], weights2)\n\n        tensor_prod_interp = np.zeros((E, E, E), dtype=np.float64)\n        for i in range(E):\n            for j in range(E):\n                tensor_prod_interp[i, j, :] = barycentric_interp1d(eval_grid_1d, nodes3, interp2[i, j, :], weights3)\n        \n        approx_values += w * tensor_prod_interp\n        \n    return approx_values\n\ndef compute_trilinear_approx(f, M, eval_xx, eval_yy, eval_zz):\n    \"\"\"\n    Computes the piecewise trilinear approximation on the evaluation grid.\n    \"\"\"\n    grid_nodes_1d = np.linspace(-1., 1., M)\n    grid_x, grid_y, grid_z = np.meshgrid(grid_nodes_1d, grid_nodes_1d, grid_nodes_1d, indexing='ij')\n    f_on_uniform_grid = f(grid_x, grid_y, grid_z)\n    \n    # Map physical coordinates of the evaluation grid to the index coordinates of the M-point grid\n    h = 2.0 / (M - 1)\n    coords_x = (eval_xx - (-1)) / h\n    coords_y = (eval_yy - (-1)) / h\n    coords_z = (eval_zz - (-1)) / h\n    \n    coords = np.stack([coords_x, coords_y, coords_z])\n    \n    # Use SciPy's map_coordinates for efficient N-D linear interpolation\n    approx_values = map_coordinates(f_on_uniform_grid, coords, order=1, mode='nearest')\n    \n    return approx_values\n\ndef solve():\n    \"\"\"\n    Main driver function to run test cases and compute the error difference.\n    \"\"\"\n    test_cases = [\n        (0.0, 4, 25, 31),\n        (0.9, 5, 29, 31),\n        (-0.2, 3, 21, 31),\n    ]\n\n    results = []\n    cheby_cache = {}\n\n    for i, (tau, L, M, E) in enumerate(test_cases):\n        f = lambda x, y, z: np.maximum(0., x + y + z - tau)\n        \n        eval_grid_1d = np.linspace(-1., 1., E)\n        eval_xx, eval_yy, eval_zz = np.meshgrid(eval_grid_1d, eval_grid_1d, eval_grid_1d, indexing='ij')\n        \n        f_true_values = f(eval_xx, eval_yy, eval_zz)\n\n        # Smolyak-Chebyshev approximation\n        A_L_values = compute_smolyak_approx(f, L, eval_grid_1d, cheby_cache)\n        rmse_A = np.sqrt(np.mean((A_L_values - f_true_values)**2))\n\n        # Piecewise trilinear approximation\n        T_M_values = compute_trilinear_approx(f, M, eval_xx, eval_yy, eval_zz)\n        rmse_T = np.sqrt(np.mean((T_M_values - f_true_values)**2))\n\n        delta = rmse_A - rmse_T\n        results.append(delta)\n\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}