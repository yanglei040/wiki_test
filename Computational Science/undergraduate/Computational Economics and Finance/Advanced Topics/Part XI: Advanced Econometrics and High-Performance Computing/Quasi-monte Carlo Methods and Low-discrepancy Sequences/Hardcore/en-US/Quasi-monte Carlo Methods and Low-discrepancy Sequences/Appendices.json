{
    "hands_on_practices": [
        {
            "introduction": "To begin our practical exploration, we will directly compare the performance of Quasi-Monte Carlo (QMC) with two other fundamental numerical integration techniques: standard Monte Carlo (MC) and a deterministic grid-based Riemann sum. This exercise is designed to provide a clear, empirical baseline for QMC's advantages. By approximating the integral of a simple periodic function, you will observe firsthand how the superior uniformity of a Sobol' sequence can lead to faster convergence than the probabilistic sampling of MC and avoid the resonance pitfalls of a regular grid .",
            "id": "2424669",
            "problem": "Consider the bivariate function $f:[0,1]^2 \\to \\mathbb{R}$ defined by $f(x,y)=\\cos(20\\pi x)+\\cos(20\\pi y)$, where the cosine function is evaluated in radians. The goal is to numerically approximate the integral\n$$I=\\int_0^1\\int_0^1 f(x,y)\\,dx\\,dy$$,\ncompare the absolute integration errors produced by three estimators, and report the results for a prescribed set of sample sizes.\n\nDefine the following three estimators of $I$ for a given sample size $N\\in\\mathbb{N}$:\n- Monte Carlo (MC, Monte Carlo): Draw $N$ independent samples $(X_i,Y_i)$ with $(X_i,Y_i)\\sim \\text{Uniform}([0,1]^2)$ and use the estimator\n$$\\widehat{I}_{\\text{MC},N}=\\frac{1}{N}\\sum_{i=1}^N f(X_i,Y_i).$$\n- Quasi-Monte Carlo (QMC, Quasi-Monte Carlo): Use the first $N$ points $(u_i,v_i)$ from a two-dimensional Sobol low-discrepancy sequence without scrambling on $[0,1]^2$, and use the estimator\n$$\\widehat{I}_{\\text{QMC},N}=\\frac{1}{N}\\sum_{i=1}^N f(u_i,v_i).$$\n- Two-dimensional Riemann sum on a uniform grid: Assume $N=n^2$ with $n\\in\\mathbb{N}$, and form the uniform $n\\times n$ grid of left-endpoint nodes\n$$\\Big\\{\\Big(\\frac{i}{n},\\frac{j}{n}\\Big): i=0,1,\\dots,n-1,\\; j=0,1,\\dots,n-1\\Big\\}.$$\nUse the estimator\n$$\\widehat{I}_{\\text{Grid},N}=\\frac{1}{n^2}\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1} f\\Big(\\frac{i}{n},\\frac{j}{n}\\Big).$$\n\nYour program must:\n- Use the exact value of $I$ implied by the definition of $f$ over $[0,1]^2$ for computing errors.\n- For MC, use a fixed pseudorandom seed $2025$ for reproducibility.\n- For QMC, use the two-dimensional Sobol sequence without scrambling, taking the first $N$ points in order, starting at index $0$.\n- For the grid-based Riemann sum, apply it only when $N$ is a perfect square.\n\nFor each $N$ in the test suite, compute the absolute errors\n$$E_{\\text{MC}}(N)=\\big|\\widehat{I}_{\\text{MC},N}-I\\big|,\\quad E_{\\text{QMC}}(N)=\\big|\\widehat{I}_{\\text{QMC},N}-I\\big|,\\quad E_{\\text{Grid}}(N)=\\big|\\widehat{I}_{\\text{Grid},N}-I\\big|.$$\n\nTest suite:\n- $N\\in\\{1,4,25,100,400\\}$, which corresponds to grid sizes $n\\in\\{1,2,5,10,20\\}$ for the grid estimator.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a list of lists. Each inner list corresponds to one $N$ in the order $N\\in[1,4,25,100,400]$ and contains the three errors in the fixed order $[E_{\\text{MC}}(N),E_{\\text{QMC}}(N),E_{\\text{Grid}}(N)]$.\n- Each floating-point number must be printed with exactly $8$ digits after the decimal point.\n- There must be no spaces anywhere in the printed line.\n- The output therefore has the form of a single Python-style list of lists on one line, with all entries formatted to $8$ decimal places.",
            "solution": "The problem as stated is scientifically grounded, well-posed, objective, and complete. It is a standard exercise in computational mathematics, comparing the performance of Monte Carlo, Quasi-Monte Carlo, and deterministic grid-based numerical integration methods. All provided information is sufficient and consistent for a unique solution. The problem is therefore valid.\n\nThe objective is to compute the absolute integration errors for three different numerical estimators of the integral $I = \\int_0^1\\int_0^1 f(x,y)\\,dx\\,dy$ for the function $f(x,y)=\\cos(20\\pi x)+\\cos(20\\pi y)$.\n\nFirst, we must determine the exact value of the integral $I$. By the linearity of integration, we can separate the integral:\n$$I = \\int_0^1\\int_0^1 \\left(\\cos(20\\pi x)+\\cos(20\\pi y)\\right)\\,dx\\,dy = \\int_0^1\\int_0^1 \\cos(20\\pi x)\\,dx\\,dy + \\int_0^1\\int_0^1 \\cos(20\\pi y)\\,dx\\,dy$$\nLet us evaluate the first term:\n$$ \\int_0^1\\int_0^1 \\cos(20\\pi x)\\,dx\\,dy = \\int_0^1 \\left[ \\frac{\\sin(20\\pi x)}{20\\pi} \\right]_{x=0}^{x=1} \\,dy = \\int_0^1 \\left( \\frac{\\sin(20\\pi \\cdot 1) - \\sin(20\\pi \\cdot 0)}{20\\pi} \\right) \\,dy $$\nSince $\\sin(20\\pi) = 0$ and $\\sin(0) = 0$, the inner integral evaluates to $0$. Thus, the entire first term is $\\int_0^1 0 \\,dy = 0$.\nBy symmetry, the second term is also zero:\n$$ \\int_0^1\\int_0^1 \\cos(20\\pi y)\\,dx\\,dy = \\int_0^1 \\cos(20\\pi y) \\left[ x \\right]_{x=0}^{x=1} \\,dy = \\int_0^1 \\cos(20\\pi y) \\,dy = \\left[ \\frac{\\sin(20\\pi y)}{20\\pi} \\right]_{y=0}^{y=1} = 0 $$\nTherefore, the exact value of the integral is $I = 0 + 0 = 0$. The absolute error of any estimator $\\widehat{I}$ is thus simply its absolute value, $E = |\\widehat{I} - I| = |\\widehat{I}|$.\n\nThe solution procedure involves implementing the three estimators for each sample size $N$ in the set $\\{1, 4, 25, 100, 400\\}$.\n\n1.  **Monte Carlo (MC) Estimator:** For each $N$, we generate $N$ independent random points $(X_i, Y_i)$ uniformly distributed in the unit square $[0,1]^2$. A pseudorandom number generator with a fixed seed of $2025$ is used to ensure reproducibility. The estimate is the sample mean of the function values at these points:\n    $$\\widehat{I}_{\\text{MC},N}=\\frac{1}{N}\\sum_{i=1}^N f(X_i,Y_i)$$\n\n2.  **Quasi-Monte Carlo (QMC) Estimator:** For each $N$, we use the first $N$ points $(u_i,v_i)$ of a two-dimensional Sobol low-discrepancy sequence. These points are generated deterministically and are designed to cover the unit square more evenly than pseudorandom points. To ensure we are using the \"first $N$ points\" for each test case, a single sequence of the maximum required length ($N=400$) is generated, and the appropriate prefix of this sequence is used for each $N$. The estimate is the sample mean:\n    $$\\widehat{I}_{\\text{QMC},N}=\\frac{1}{N}\\sum_{i=1}^N f(u_i,v_i)$$\n\n3.  **Grid-based Riemann Sum Estimator:** This method is applied for $N=n^2$ where $n \\in \\{1, 2, 5, 10, 20\\}$. A uniform $n \\times n$ grid of points $(\\frac{i}{n}, \\frac{j}{n})$ for $i,j \\in \\{0, 1, \\dots, n-1\\}$ is constructed. The estimate is the mean of the function values over this grid:\n    $$\\widehat{I}_{\\text{Grid},N}=\\frac{1}{n^2}\\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1} f\\Big(\\frac{i}{n},\\frac{j}{n}\\Big)$$\n    It is important to analyze the behavior of this estimator for the given function. The sum can be simplified:\n    $$\\widehat{I}_{\\text{Grid},N} = \\frac{1}{n^2} \\sum_{i=0}^{n-1}\\sum_{j=0}^{n-1} \\left( \\cos\\left(\\frac{20\\pi i}{n}\\right) + \\cos\\left(\\frac{20\\pi j}{n}\\right) \\right) = \\frac{2}{n}\\sum_{k=0}^{n-1} \\cos\\left(\\frac{20\\pi k}{n}\\right)$$\n    The term $20\\pi/n$ is a multiple of $2\\pi$ if $10/n$ is an integer. This holds for $n \\in \\{1, 2, 5, 10\\}$. For these values, every term $\\cos(2\\pi \\cdot (\\text{integer}) \\cdot k) = 1$. The sum is $n$, and the estimator becomes $\\widehat{I}_{\\text{Grid},N} = \\frac{2}{n} \\cdot n = 2$. The error is $|\\widehat{I}_{\\text{Grid},N}| = 2$.\n    For $n=20$, the argument is $\\cos(\\pi k)$, and the sum $\\sum_{k=0}^{19} \\cos(\\pi k) = 1-1+1-1+\\dots+1-1=0$. The estimator and its error are both $0$. This specific function choice highlights a resonance phenomenon where a uniform grid can perform very poorly or perfectly, depending on its alignment with the function's periodicity.\n\nThe program calculates these three estimates for each $N$, computes the absolute errors, and formats the results as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import qmc\n\ndef solve():\n    \"\"\"\n    Computes and compares absolute integration errors for MC, QMC, and Grid estimators.\n    \"\"\"\n    # The exact value of the integral is I=0.\n    I_exact = 0.0\n\n    # Define the bivariate function to be integrated.\n    def f(x, y):\n        \"\"\"\n        Calculates f(x,y) = cos(20*pi*x) + cos(20*pi*y).\n        x and y can be scalars or numpy arrays.\n        \"\"\"\n        return np.cos(20 * np.pi * x) + np.cos(20 * np.pi * y)\n\n    # Define the test suite for sample sizes N.\n    test_cases = [\n        (1, 1),\n        (4, 2),\n        (25, 5),\n        (100, 10),\n        (400, 20),\n    ]\n\n    seed = 2025\n    rng = np.random.default_rng(seed)\n\n    # Pre-generate all required Sobol points to ensure \"first N\" rule is followed.\n    max_N = test_cases[-1][0]\n    sobol_engine = qmc.Sobol(d=2, scramble=False)\n    all_qmc_points = sobol_engine.random(max_N)\n\n    results = []\n    for N, n in test_cases:\n        # --- 1. Monte Carlo (MC) Estimator ---\n        # Generate N fresh random points for each N.\n        mc_points = rng.random((N, 2))\n        f_values_mc = f(mc_points[:, 0], mc_points[:, 1])\n        I_hat_mc = np.mean(f_values_mc)\n        error_mc = np.abs(I_hat_mc - I_exact)\n\n        # --- 2. Quasi-Monte Carlo (QMC) Estimator ---\n        # Use the first N points from the pre-generated sequence.\n        qmc_points = all_qmc_points[:N]\n        f_values_qmc = f(qmc_points[:, 0], qmc_points[:, 1])\n        I_hat_qmc = np.mean(f_values_qmc)\n        error_qmc = np.abs(I_hat_qmc - I_exact)\n\n        # --- 3. Grid-based Riemann Sum Estimator ---\n        # Generate an n x n grid of left-endpoints.\n        grid_coords = np.arange(n) / n\n        x_grid, y_grid = np.meshgrid(grid_coords, grid_coords)\n        f_values_grid = f(x_grid, y_grid)\n        I_hat_grid = np.mean(f_values_grid)\n        error_grid = np.abs(I_hat_grid - I_exact)\n\n        results.append([error_mc, error_qmc, error_grid])\n\n    # Format the output string according to the specified rules:\n    # A list of lists, with each number formatted to 8 decimal places,\n    # and no spaces in the entire output string.\n    formatted_rows = [\n        f\"[{','.join([f'{err:.8f}' for err in row])}]\"\n        for row in results\n    ]\n    final_output = f\"[{','.join(formatted_rows)}]\"\n\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "While our first exercise showcased QMC's strengths, its performance is not universally superior and depends critically on the structure of the integrand. This next practice explores the concept of 'effective dimension' by applying an orthogonal rotation to the input variables of a function defined on a multivariate normal distribution. You will see that even though the true value of the integral is unchanged by rotation, the error of the QMC estimate can degrade significantly, revealing how QMC's advantage diminishes when a function is not well-aligned with the coordinate axes .",
            "id": "2424673",
            "problem": "You are given a simulation-based integration task that compares standard Monte Carlo and quasi-Monte Carlo methods in a setting relevant to computational economics and finance. Consider the expectation of an integrand under a multivariate standard normal distribution, and examine how an orthogonal rotation of variables changes the axis alignment of the integrand and can eliminate the typical advantage of quasi-Monte Carlo when the function is axis-aligned.\n\nLet $d \\in \\mathbb{N}$ be the dimension, let $\\boldsymbol{Z} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$ be a $d$-dimensional standard normal random vector, and let $\\mathbf{Q} \\in \\mathbb{R}^{d \\times d}$ be an orthogonal matrix satisfying $\\mathbf{Q}^\\top \\mathbf{Q} = \\mathbf{I}_d$. Define the integrand\n$$\nf_{\\lambda,\\mathbf{Q}}(\\boldsymbol{z}) = \\exp\\!\\left(\\lambda \\, (\\mathbf{Q}\\boldsymbol{z})_1\\right),\n$$\nwhere $(\\mathbf{Q}\\boldsymbol{z})_1$ denotes the first component of the rotated vector $\\mathbf{Q}\\boldsymbol{z}$ and $\\lambda \\in \\mathbb{R}$ is a fixed scalar. Because the multivariate normal distribution is invariant under orthogonal transformations, the integral of interest is\n$$\nI(\\lambda) = \\mathbb{E}\\!\\left[f_{\\lambda,\\mathbf{Q}}(\\boldsymbol{Z})\\right] = \\mathbb{E}\\!\\left[\\exp\\!\\left(\\lambda \\, (\\mathbf{Q}\\boldsymbol{Z})_1\\right)\\right] = \\exp\\!\\left(\\tfrac{1}{2}\\lambda^2\\right),\n$$\nwhich does not depend on $\\mathbf{Q}$.\n\nYour task is to write a complete, runnable program that empirically compares the absolute integration error of:\n- quasi-Monte Carlo using a Sobol low-discrepancy sequence mapped to independent standard normal coordinates via the inverse standard normal cumulative distribution function, and\n- standard Monte Carlo using independent pseudo-random standard normal draws,\n\nfor various orthogonal matrices $\\mathbf{Q}$ that rotate and mix coordinates. Use a fixed seed for standard Monte Carlo to ensure reproducibility. Use a scrambled Sobol sequence with a fixed seed to avoid boundary issues at $0$ and $1$ for the inverse standard normal mapping.\n\nFundamental definitions you may rely on include: the definition of expectation as an integral, the invariance of $\\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$ under orthogonal transformations, and the mapping of uniform random variables to normal random variables via the inverse cumulative distribution function. Do not assume any unproven shortcuts beyond these.\n\nImplementation requirements:\n- Generate $n$ sample points in $[0,1]^d$ using a Sobol sequence, scramble them with a fixed seed, and transform them coordinate-wise to $\\mathbb{R}^d$ via the inverse standard normal cumulative distribution function to obtain quasi-Monte Carlo samples. Independently, generate $n$ independent $d$-dimensional standard normal samples using a pseudo-random number generator with a fixed seed.\n- Apply the orthogonal transform $\\mathbf{Q}$ to each $d$-dimensional sample and evaluate $f_{\\lambda,\\mathbf{Q}}$.\n- Estimate $I(\\lambda)$ by the sample mean under each method and compute the absolute error relative to the exact value $\\exp\\!\\left(\\tfrac{1}{2}\\lambda^2\\right)$.\n- Report, for each test case, a ratio defined as\n$$\nr = \\frac{\\left|\\widehat{I}_{\\mathrm{QMC}} - I(\\lambda)\\right|}{\\max\\!\\left(\\left|\\widehat{I}_{\\mathrm{MC}} - I(\\lambda)\\right|, \\varepsilon\\right)},\n$$\nwith $\\varepsilon = 10^{-16}$ to avoid division by zero. Ratios $r  1$ indicate quasi-Monte Carlo outperforms standard Monte Carlo on that test; ratios $r > 1$ indicate the opposite. Angles, when present, must be interpreted in radians.\n\nOrthogonal matrices to be used:\n- For a planar rotation in the first two coordinates by angle $\\theta$, define $\\mathbf{Q}$ by embedding the $2 \\times 2$ rotation\n$$\n\\mathbf{R}(\\theta) = \\begin{pmatrix} \\cos\\theta  -\\sin\\theta\\\\ \\sin\\theta  \\cos\\theta \\end{pmatrix}\n$$\ninto the top-left block of $\\mathbf{Q}$ and setting the remaining diagonal entries to $1$ and off-diagonal entries to $0$.\n- For a Householder reflection that mixes all coordinates equally in the first output coordinate, take $\\boldsymbol{v} = \\tfrac{1}{\\sqrt{d}}(1,1,\\dots,1)^\\top \\in \\mathbb{R}^d$ and define\n$$\n\\mathbf{Q} = \\mathbf{I}_d - 2 \\,\\boldsymbol{u}\\boldsymbol{u}^\\top, \\quad \\boldsymbol{u} = \\frac{\\boldsymbol{e}_1 - \\boldsymbol{v}}{\\lVert \\boldsymbol{e}_1 - \\boldsymbol{v}\\rVert_2},\n$$\nwhere $\\boldsymbol{e}_1$ is the first standard basis vector. This choice ensures $(\\mathbf{Q}\\boldsymbol{z})_1 = \\boldsymbol{v}^\\top \\boldsymbol{z}$, so the integrand depends on an equal-weighted linear combination of all coordinates.\n\nFixed parameters:\n- Use $\\lambda = 0.5$.\n- Use standard Monte Carlo seed $42$.\n- Use Sobol scramble seed $7$.\n\nTest suite:\n- Case $1$: $d = 8$, $n = 4096$, planar rotation with $\\theta = 0$ (axis-aligned).\n- Case $2$: $d = 8$, $n = 4096$, planar rotation with $\\theta = \\pi/4$ (mixes two coordinates).\n- Case $3$: $d = 32$, $n = 4096$, Householder reflection with $\\boldsymbol{v} = \\tfrac{1}{\\sqrt{d}}(1,\\dots,1)^\\top$ (maximally mixes all coordinates in the first output).\n- Case $4$: $d = 8$, $n = 64$, planar rotation with $\\theta = 0$ (small sample size boundary).\n- Case $5$: $d = 8$, $n = 64$, planar rotation with $\\theta = \\pi/4$ (small sample size with mixing).\n\nRequired final output format:\n- Your program should produce a single line of output containing the ratios $r$ for the cases listed above as a comma-separated list enclosed in square brackets, in the same order as the test cases, each ratio rounded to $6$ decimal places (for example, $\\left[0.123456,0.654321\\right]$). No additional text should be printed.",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded, well-posed, and contains all necessary information for a unique, reproducible solution. The mathematical premises upon which it is built, specifically the analytical value of the integral and the properties of the specified orthogonal transformations, are correct. The task is a standard numerical experiment to compare the performance of quasi-Monte Carlo and standard Monte Carlo integration, a classical problem in computational mathematics and its applications to finance. We shall therefore proceed with the solution.\n\nThe objective is to compute the ratio of absolute errors between quasi-Monte Carlo (QMC) and standard Monte Carlo (MC) methods for estimating the expectation of a function under a multivariate standard normal distribution. The integral of interest is\n$$\nI(\\lambda) = \\mathbb{E}_{\\boldsymbol{Z} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)}\\!\\left[f_{\\lambda,\\mathbf{Q}}(\\boldsymbol{Z})\\right] = \\mathbb{E}\\!\\left[\\exp\\!\\left(\\lambda \\, (\\mathbf{Q}\\boldsymbol{Z})_1\\right)\\right]\n$$\nwhere $\\boldsymbol{Z}$ is a $d$-dimensional standard normal random vector, $\\mathbf{Q}$ is a $d \\times d$ orthogonal matrix, and $(\\mathbf{Q}\\boldsymbol{Z})_1$ is the first component of the transformed vector. As the multivariate standard normal distribution is invariant under orthogonal transformations, the vector $\\boldsymbol{Y} = \\mathbf{Q}\\boldsymbol{Z}$ is also distributed as $\\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$. Consequently, its first component $Y_1 = (\\mathbf{Q}\\boldsymbol{Z})_1$ is a standard normal random variable, $Y_1 \\sim \\mathcal{N}(0, 1)$. The expectation is thus the moment-generating function of a standard normal variable evaluated at $\\lambda$, which has the known closed-form solution:\n$$\nI(\\lambda) = \\mathbb{E}\\!\\left[\\exp(\\lambda Y_1)\\right] = \\exp\\!\\left(\\tfrac{1}{2}\\lambda^2\\right)\n$$\nThis value serves as the ground truth for calculating integration error. For the given parameter $\\lambda = 0.5$, the exact value is $I(0.5) = \\exp\\!\\left(\\tfrac{1}{2}(0.5)^2\\right) = \\exp(0.125)$.\n\nThe expectation is estimated numerically by approximating the integral with a sample mean over $n$ points:\n$$\n\\widehat{I} = \\frac{1}{n} \\sum_{i=1}^{n} \\exp\\!\\left(\\lambda \\, (\\mathbf{Q}\\boldsymbol{z}_i)_1\\right)\n$$\nThe efficacy of this approximation depends on the choice of the sample points $\\boldsymbol{z}_i$. We compare two methods for generating these points.\n\nFirst, the standard Monte Carlo (MC) method generates $n$ independent and identically distributed samples $\\boldsymbol{z}_i$ from the target distribution $\\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$ using a pseudo-random number generator. A fixed seed ensures reproducibility.\n\nSecond, the quasi-Monte Carlo (QMC) method aims to improve convergence by using deterministic, low-discrepancy sequences that cover the integration domain more uniformly than pseudo-random points. Here, we use a Sobol sequence to generate $n$ points in the $d$-dimensional unit hypercube, $[0,1]^d$. These points are scrambled using a fixed seed to improve their statistical properties. Each coordinate of these uniform points $u_{i,j}$ is then transformed to a standard normal coordinate $z_{i,j}$ via the inverse cumulative distribution function (CDF) of the standard normal distribution, also known as the probit function: $z_{i,j} = \\Phi^{-1}(u_{i,j})$.\n\nThe central part of this problem is to analyze the effect of the integrand's structure on QMC performance. The integrand $f_{\\lambda,\\mathbf{Q}}(\\boldsymbol{z})$ depends on $\\boldsymbol{z}$ only through the linear combination $(\\mathbf{Q}\\boldsymbol{z})_1 = \\sum_{j=1}^d Q_{1j} z_j$. The effectiveness of QMC is often highest when the most important dimensions of the function are aligned with the first few axes of the low-discrepancy sequence. By applying an orthogonal transformation $\\mathbf{Q}$, we change this alignment.\n\nWe consider two types of orthogonal matrices:\n1.  A planar rotation, which mixes the first two coordinates. When the rotation angle $\\theta=0$, $\\mathbf{Q}=\\mathbf{I}_d$ and the integrand becomes $\\exp(\\lambda z_1)$, depending only on the first coordinate. This is an ideal, \"axis-aligned\" case for QMC. As $\\theta$ increases to $\\pi/4$, the integrand becomes dependent on an equal mix of $z_1$ and $z_2$, which typically degrades QMC performance. The matrix is $\\mathbf{Q} = \\begin{pmatrix} \\mathbf{R}(\\theta)  \\mathbf{0} \\\\ \\mathbf{0}  \\mathbf{I}_{d-2} \\end{pmatrix}$, where $\\mathbf{R}(\\theta) = \\begin{pmatrix} \\cos\\theta  -\\sin\\theta \\\\ \\sin\\theta  \\cos\\theta \\end{pmatrix}$.\n\n2.  A Householder reflection designed to maximally mix all coordinates. The matrix is given by $\\mathbf{Q} = \\mathbf{I}_d - 2 \\boldsymbol{u}\\boldsymbol{u}^\\top$ with $\\boldsymbol{u} = \\frac{\\boldsymbol{e}_1 - \\boldsymbol{v}}{\\lVert \\boldsymbol{e}_1 - \\boldsymbol{v}\\rVert_2}$ for $\\boldsymbol{v} = \\frac{1}{\\sqrt{d}}(1, \\dots, 1)^\\top$. This transformation is constructed such that $\\mathbf{Q}$ maps $\\boldsymbol{e}_1$ to $\\boldsymbol{v}$. Since $\\mathbf{Q}$ is symmetric and orthogonal ($\\mathbf{Q}^\\top = \\mathbf{Q} = \\mathbf{Q}^{-1}$), it follows that $(\\mathbf{Q}\\boldsymbol{z})_1 = \\boldsymbol{e}_1^\\top \\mathbf{Q} \\boldsymbol{z} = (\\mathbf{Q}^\\top \\boldsymbol{e}_1)^\\top \\boldsymbol{z} = (\\mathbf{Q} \\boldsymbol{e}_1)^\\top \\boldsymbol{z} = \\boldsymbol{v}^\\top \\boldsymbol{z}$. The integrand becomes $\\exp\\!\\left(\\frac{\\lambda}{\\sqrt{d}}\\sum_{j=1}^d z_j\\right)$, depending equally on all $d$ coordinates. This represents a worst-case scenario for standard QMC, as the effective dimension is high.\n\nFor each test case defined by $(d, n, \\mathbf{Q})$, the computational procedure is as follows:\n1.  Set parameters: $\\lambda=0.5$, MC seed $42$, Sobol scramble seed $7$.\n2.  Construct the specified $d \\times d$ orthogonal matrix $\\mathbf{Q}$.\n3.  Generate $n$ standard normal samples $\\boldsymbol{Z}_{\\text{MC}}$ using the MC method.\n4.  Generate $n$ standard normal samples $\\boldsymbol{Z}_{\\text{QMC}}$ using the Sobol-based QMC method.\n5.  For each sample set, compute the rotated vectors $\\boldsymbol{Y} = (\\mathbf{Q}\\boldsymbol{Z}^\\top)^\\top$, which can be implemented as $\\boldsymbol{Z} @ \\mathbf{Q}^\\top$.\n6.  Extract the first component of the rotated vectors, $(\\boldsymbol{Y})_1$.\n7.  Evaluate the integrand for all samples and compute the sample means $\\widehat{I}_{\\text{MC}}$ and $\\widehat{I}_{\\text{QMC}}$.\n8.  Calculate the absolute errors: $E_{\\text{MC}} = |\\widehat{I}_{\\text{MC}} - I(\\lambda)|$ and $E_{\\text{QMC}} = |\\widehat{I}_{\\text{QMC}} - I(\\lambda)|$.\n9.  Compute the performance ratio $r = E_{\\text{QMC}} / \\max(E_{\\text{MC}}, \\varepsilon)$, with $\\varepsilon = 10^{-16}$.\n\nThe results from all test cases will be compiled and presented in the required format. The ratio $r$ quantifies the relative performance of QMC: $r  1$ indicates QMC is superior for that configuration, while $r > 1$ indicates MC is superior.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import qmc, norm\n\ndef solve():\n    \"\"\"\n    Compares the performance of quasi-Monte Carlo (QMC) and standard Monte Carlo (MC)\n    for integrating a function under a multivariate standard normal distribution,\n    subject to various orthogonal transformations.\n    \"\"\"\n\n    # --- Fixed Parameters ---\n    lambda_val = 0.5\n    mc_seed = 42\n    sobol_scramble_seed = 7\n    epsilon = 1e-16\n\n    # --- Analytical Solution ---\n    # The true value of the integral E[exp(lambda * (QZ)_1)]\n    I_true = np.exp(0.5 * lambda_val**2)\n\n    # --- Test Suite ---\n    test_cases = [\n        # Case 1: d=8, n=4096, planar rotation, theta=0 (axis-aligned)\n        {'d': 8, 'n': 4096, 'q_type': 'planar', 'theta': 0.0},\n        # Case 2: d=8, n=4096, planar rotation, theta=pi/4 (mixes 2 coords)\n        {'d': 8, 'n': 4096, 'q_type': 'planar', 'theta': np.pi / 4},\n        # Case 3: d=32, n=4096, Householder reflection (mixes all coords)\n        {'d': 32, 'n': 4096, 'q_type': 'householder', 'theta': None},\n        # Case 4: d=8, n=64, planar rotation, theta=0 (small sample)\n        {'d': 8, 'n': 64, 'q_type': 'planar', 'theta': 0.0},\n        # Case 5: d=8, n=64, planar rotation, theta=pi/4 (small sample with mixing)\n        {'d': 8, 'n': 64, 'q_type': 'planar', 'theta': np.pi / 4},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        d = case['d']\n        n = case['n']\n        q_type = case['q_type']\n        theta = case['theta']\n\n        # --- Construct Orthogonal Matrix Q ---\n        if q_type == 'planar':\n            Q = np.identity(d)\n            if d = 2:\n                c, s = np.cos(theta), np.sin(theta)\n                R = np.array([[c, -s], [s, c]])\n                Q[:2, :2] = R\n        elif q_type == 'householder':\n            v = np.ones(d) / np.sqrt(d)\n            e1 = np.zeros(d)\n            e1[0] = 1.0\n            u_vec = e1 - v\n            norm_u = np.linalg.norm(u_vec)\n            if norm_u  0:\n                u_vec /= norm_u\n            u_outer_u = np.outer(u_vec, u_vec)\n            Q = np.identity(d) - 2 * u_outer_u\n        else:\n            raise ValueError(f\"Unknown matrix type: {q_type}\")\n\n        # --- Generate Samples ---\n        # Standard Monte Carlo (MC) samples\n        rng_mc = np.random.default_rng(seed=mc_seed)\n        Z_mc = rng_mc.standard_normal(size=(n, d))\n\n        # Quasi-Monte Carlo (QMC) samples\n        sampler_qmc = qmc.Sobol(d=d, scramble=True, seed=sobol_scramble_seed)\n        U_qmc = sampler_qmc.random(n=n)\n        Z_qmc = norm.ppf(U_qmc)\n\n        # --- Define integrand function ---\n        def evaluate_integrand(Z, Q_matrix, lam):\n            # Q is (d, d), Z is (n, d). We want Q*z for each row z in Z.\n            # This is equivalent to (Q @ Z.T).T or Z @ Q.T\n            # Then we take the first component of each resulting vector.\n            Y1 = (Z @ Q_matrix.T)[:, 0]\n            return np.exp(lam * Y1)\n\n        # --- Estimate Integrals ---\n        f_vals_mc = evaluate_integrand(Z_mc, Q, lambda_val)\n        I_hat_mc = np.mean(f_vals_mc)\n\n        f_vals_qmc = evaluate_integrand(Z_qmc, Q, lambda_val)\n        I_hat_qmc = np.mean(f_vals_qmc)\n\n        # --- Compute Errors and Ratio ---\n        err_mc = np.abs(I_hat_mc - I_true)\n        err_qmc = np.abs(I_hat_qmc - I_true)\n\n        ratio = err_qmc / np.maximum(err_mc, epsilon)\n        results.append(ratio)\n\n    # --- Format and Print Final Output ---\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Our final practice tackles a common challenge in computational finance: integrating discontinuous functions, such as those found in digital option payoffs. Standard QMC can perform poorly on such problems due to the alignment of the fixed points with the discontinuity. Here, we introduce Randomized QMC (RQMC) via Owen scrambling, a powerful technique that enhances uniformity while restoring a probabilistic framework for error analysis. By comparing an unscrambled Sobol' sequence with its scrambled counterpart, you will empirically verify the significant performance gains that scrambling offers for this important class of problems .",
            "id": "2424700",
            "problem": "You must write a complete, runnable program that compares the performance of Owen-scrambled Sobol’ sequences and unscrambled Sobol’ sequences for estimating the integral of a discontinuous integrand central to computational economics and finance. Consider the integral\n$$\nI(d,\\tau) \\;=\\; \\int_{[0,1]^d} \\mathbf{1}\\!\\left\\{\\sum_{i=1}^{d} u_i \\ge \\tau \\right\\} \\, \\mathrm{d}\\boldsymbol{u},\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function, $d \\in \\mathbb{N}$ is the dimension, and $\\tau \\in \\mathbb{R}$ is a threshold. This integral represents the probability that the sum of $d$ independent Uniform$(0,1)$ random variables exceeds $\\tau$, which is a prototypical discontinuous payoff relevant to digital payoffs in asset pricing and risk measures in computational economics and finance. The exact value is\n$$\nI(d,\\tau) \\;=\\; 1 - F_{\\mathrm{IH}}(\\tau; d),\n$$\nwhere $F_{\\mathrm{IH}}(\\cdot; d)$ is the cumulative distribution function of the Irwin–Hall distribution with parameter $d$, given by\n$$\nF_{\\mathrm{IH}}(x; d) \\;=\\;\n\\begin{cases}\n0,  x \\le 0,\\\\[4pt]\n\\dfrac{1}{d!}\\displaystyle\\sum_{k=0}^{\\lfloor x \\rfloor} (-1)^k \\binom{d}{k} (x - k)^d,  0  x  d,\\\\[10pt]\n1,  x \\ge d.\n\\end{cases}\n$$\n\nFor a given $d$, $\\tau$, and sample size $N \\in \\mathbb{N}$, define the quasi-Monte Carlo estimator\n$$\n\\widehat{I}_N \\;=\\; \\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{1}\\!\\left\\{\\sum_{i=1}^{d} u_{n,i} \\ge \\tau \\right\\},\n$$\nwhere $\\{\\boldsymbol{u}_n\\}_{n=1}^{N} \\subset [0,1]^d$ are the first $N$ points of a Sobol’ low-discrepancy sequence. Let $m$ be the smallest integer such that $2^m \\ge N$. In all cases below, use the first $N$ points from a Sobol’ digital net of size $2^m$ in $d$ dimensions.\n\nYour program must, for each test case, compute:\n1. An unscrambled estimate using an unscrambled Sobol’ sequence to obtain $\\widehat{I}_N^{\\mathrm{uns}}$ and its absolute error\n$$\ne_{\\mathrm{uns}} \\;=\\; \\left| \\widehat{I}_N^{\\mathrm{uns}} - I(d,\\tau) \\right|.\n$$\n2. $R$ independent randomized estimates using Owen-scrambled Sobol’ sequences to obtain $\\widehat{I}_{N,r}^{\\mathrm{scr}}$ for $r \\in \\{1,\\dots,R\\}$, each with its own independent randomization, and record the absolute errors\n$$\ne_{\\mathrm{scr},r} \\;=\\; \\left| \\widehat{I}_{N,r}^{\\mathrm{scr}} - I(d,\\tau) \\right|.\n$$\nFor each test case, define the performance ratio\n$$\n\\rho \\;=\\; \\frac{e_{\\mathrm{uns}}}{\\operatorname{median}\\{ e_{\\mathrm{scr},1},\\dots,e_{\\mathrm{scr},R} \\}},\n$$\nso that $\\rho > 1$ numerically demonstrates that the Owen-scrambled estimator attains a smaller typical absolute error than the unscrambled estimator on this discontinuous integrand.\n\nUse the following test suite of parameter values, where $S$ is a base seed and $R$ is the number of independent Owen-scrambled replications. For the $r$-th scrambled replication, use seed $S + r - 1$. For each tuple $\\left(d,\\tau,N,R,S\\right)$ below, compute the corresponding $\\rho$:\n- Test case $1$: $\\left(d,\\tau,N,R,S\\right) = \\left(5,\\,2.5,\\,4093,\\,64,\\,13579\\right)$.\n- Test case $2$: $\\left(d,\\tau,N,R,S\\right) = \\left(10,\\,5.0,\\,16384,\\,32,\\,24680\\right)$.\n- Test case $3$: $\\left(d,\\tau,N,R,S\\right) = \\left(12,\\,9.0,\\,32767,\\,16,\\,112233\\right)$.\n\nYour program must:\n- Compute $I(d,\\tau)$ exactly using the Irwin–Hall cumulative distribution function $F_{\\mathrm{IH}}(\\tau; d)$ given above.\n- For each test case, use the first $N$ points from a Sobol’ digital net of size $2^m$ in $d$ dimensions for both unscrambled and independently Owen-scrambled sequences.\n- For each test case, produce the performance ratio $\\rho$ defined above.\n\nFinal output format:\n- Your program should produce a single line of output containing the three ratios for the test cases as a comma-separated list enclosed in square brackets, in the order of the test cases given above, with each ratio rounded to exactly $6$ digits after the decimal point. For example, an output of the form $\\left[\\rho_1,\\rho_2,\\rho_3\\right]$ must be printed as a single line like $[1.234000,0.987650,1.500000]$.",
            "solution": "The problem presented is a valid numerical experiment in the domain of quasi-Monte Carlo (QMC) methods, specifically applied to a problem characteristic of computational finance. It requires the comparison of standard Sobol’ sequences against Owen-scrambled Sobol’ sequences for integrating a discontinuous function. The problem is well-posed, scientifically grounded, and all parameters and definitions are provided with sufficient clarity to permit a unique, verifiable solution. We shall proceed with the derivation and implementation of the solution.\n\nThe core objective is to compute a performance ratio, $\\rho$, which quantifies the improvement afforded by Owen scrambling over an unscrambled sequence for a specific discontinuous integral. This ratio is defined as\n$$\n\\rho \\;=\\; \\frac{e_{\\mathrm{uns}}}{\\operatorname{median}\\{ e_{\\mathrm{scr},1},\\dots,e_{\\mathrm{scr},R} \\}},\n$$\nwhere $e_{\\mathrm{uns}}$ is the absolute error of the estimator using an unscrambled Sobol' sequence, and $\\{ e_{\\mathrm{scr},r} \\}_{r=1}^R$ is a set of absolute errors from $R$ independent replications using Owen-scrambled Sobol' sequences. A value of $\\rho > 1$ demonstrates superior performance of the scrambled sequence, as it achieves a smaller median error.\n\nThe step-by-step procedure is as follows:\n\n**Step 1: Computation of the Exact Integral Value**\n\nThe integral to be estimated is\n$$\nI(d,\\tau) \\;=\\; \\int_{[0,1]^d} \\mathbf{1}\\!\\left\\{\\sum_{i=1}^{d} u_i \\ge \\tau \\right\\} \\, \\mathrm{d}\\boldsymbol{u}.\n$$\nThis represents the probability $P(\\sum_{i=1}^d U_i \\ge \\tau)$ where $U_i \\sim \\text{Uniform}(0,1)$ are independent random variables. The sum $\\sum_{i=1}^d U_i$ follows the Irwin–Hall distribution with parameter $d$. The exact value of the integral is given by the survival function of this distribution:\n$$\nI(d,\\tau) \\;=\\; 1 - F_{\\mathrm{IH}}(\\tau; d),\n$$\nwhere $F_{\\mathrm{IH}}(x; d)$ is the cumulative distribution function (CDF) provided in the problem statement. To compute this, we must implement a function for $F_{\\mathrm{IH}}(x;d)$. For a given value $x = \\tau$ and parameter $d$, the function is defined piece-wise. The non-trivial case is for $0  x  d$:\n$$\nF_{\\mathrm{IH}}(x; d) \\;=\\; \\frac{1}{d!}\\sum_{k=0}^{\\lfloor x \\rfloor} (-1)^k \\binom{d}{k} (x - k)^d.\n$$\nThis sum involves factorials, binomial coefficients, and powers, all of which are standard mathematical functions. For instance, for the test case $(d, \\tau) = (5, 2.5)$, we find $I(5, 2.5) = 1 - F_{\\mathrm{IH}}(2.5; 5) = 1 - 0.5 = 0.5$, which follows from the symmetry of the Irwin-Hall distribution around its mean $d/2 = 2.5$. For the other cases, direct evaluation of the formula is required.\n\n**Step 2: Implementation of the Quasi-Monte Carlo Estimators**\n\nThe QMC estimator for $I(d,\\tau)$ using a point set $\\{\\boldsymbol{u}_n\\}_{n=1}^{N}$ is\n$$\n\\widehat{I}_N \\;=\\; \\frac{1}{N} \\sum_{n=1}^{N} f(\\boldsymbol{u}_n),\n$$\nwhere the integrand is the indicator function $f(\\boldsymbol{u}) = \\mathbf{1}\\{\\sum_{i=1}^{d} u_i \\ge \\tau\\}$. The computation involves summing the components of each point $\\boldsymbol{u}_n$, checking if the sum is greater than or equal to $\\tau$, and averaging the results of this binary check over all $N$ points.\n\nWe must compute two types of estimates:\n\n1.  **Unscrambled Estimate ($\\widehat{I}_N^{\\mathrm{uns}}$):** We generate the first $N$ points of a single $d$-dimensional Sobol' sequence without any scrambling. These points are used to compute the estimate $\\widehat{I}_N^{\\mathrm{uns}}$. The absolute error is then $e_{\\mathrm{uns}} = |\\widehat{I}_N^{\\mathrm{uns}} - I(d, \\tau)|$. A Sobol' sequence generator is configured with `scramble=False`.\n\n2.  **Scrambled Estimates ($\\widehat{I}_{N,r}^{\\mathrm{scr}}$):** We perform $R$ independent replications. For each replication $r \\in \\{1, \\dots, R\\}$, we generate a new set of $N$ points from a $d$-dimensional Sobol' sequence with Owen scrambling enabled. Crucially, each replication must be statistically independent. This is achieved by seeding the random number generator for the scrambling matrices differently for each replication. The problem specifies using a seed of $S + r - 1$ for the $r$-th replication. For each of these $R$ point sets, we compute an estimate $\\widehat{I}_{N,r}^{\\mathrm{scr}}$ and its corresponding absolute error $e_{\\mathrm{scr},r} = |\\widehat{I}_{N,r}^{\\mathrm{scr}} - I(d, \\tau)|$. This procedure yields a sample of $R$ errors $\\{e_{\\mathrm{scr},1}, \\dots, e_{\\mathrm{scr},R}\\}$.\n\n**Step 3: Calculation of the Performance Ratio**\n\nWith the unscrambled error $e_{\\mathrm{uns}}$ and the sample of $R$ scrambled errors $\\{e_{\\mathrm{scr},r}\\}$, we can assess the typical performance of the scrambled estimator. The median of the scrambled errors, $\\operatorname{median}\\{e_{\\mathrm{scr},r}\\}$, provides a robust measure of the central tendency of the error distribution for the randomized QMC method. The final performance ratio $\\rho$ is computed by dividing the single deterministic error of the unscrambled method by this median error.\n\n**Step 4: Algorithmic Procedure for a Single Test Case**\nFor each tuple $(d, \\tau, N, R, S)$:\n1.  Calculate the exact integral value $I_{\\mathrm{exact}} = 1 - F_{\\mathrm{IH}}(\\tau; d)$.\n2.  Generate an unscrambled Sobol' sequence of $N$ points in $d$ dimensions.\n3.  Compute the estimate $\\widehat{I}_N^{\\mathrm{uns}}$ and the error $e_{\\mathrm{uns}} = |\\widehat{I}_N^{\\mathrm{uns}} - I_{\\mathrm{exact}}|$.\n4.  Initialize an empty list for scrambled errors, `errors_scr`.\n5.  Loop $r$ from $1$ to $R$:\n    a.  Set the seed for randomization to $S + r - 1$.\n    b.  Generate an Owen-scrambled Sobol' sequence of $N$ points in $d$ dimensions.\n    c.  Compute the estimate $\\widehat{I}_{N,r}^{\\mathrm{scr}}$ and the error $e_{\\mathrm{scr},r} = |\\widehat{I}_{N,r}^{\\mathrm{scr}} - I_{\\mathrm{exact}}|$.\n    d.  Append $e_{\\mathrm{scr},r}$ to `errors_scr`.\n6.  Calculate the median of the scrambled errors: $m_e = \\operatorname{median}(\\text{errors\\_scr})$.\n7.  Calculate the performance ratio $\\rho = e_{\\mathrm{uns}} / m_e$.\n8.  Store the resulting $\\rho$, formatted to $6$ decimal places.\n\nThis entire process is repeated for all provided test cases. The final output is an ordered list of the computed ratios.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import qmc\nfrom scipy.special import comb\nimport math\n\ndef solve():\n    \"\"\"\n    Main solver function that executes the comparison for all test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (d, tau, N, R, S)\n        (5, 2.5, 4093, 64, 13579),\n        (10, 5.0, 16384, 32, 24680),\n        (12, 9.0, 32767, 16, 112233),\n    ]\n\n    results = []\n    \n    for d, tau, N, R, S in test_cases:\n        # Step 1: Compute the exact integral value using the Irwin-Hall CDF\n        exact_integral_value = 1.0 - irwin_hall_cdf(tau, d)\n\n        # Step 2.1: Compute the unscrambled QMC estimate and its error\n        # Initialize an unscrambled Sobol' sequence generator\n        sampler_unscrambled = qmc.Sobol(d=d, scramble=False)\n        points_unscrambled = sampler_unscrambled.random(n=N)\n        \n        # Compute the estimate\n        integrand_values = (np.sum(points_unscrambled, axis=1) = tau)\n        i_hat_unscrambled = np.mean(integrand_values)\n\n        # Compute the absolute error\n        e_unscrambled = np.abs(i_hat_unscrambled - exact_integral_value)\n\n        # Step 2.2: Compute R independent scrambled QMC estimates and their errors\n        scrambled_errors = []\n        for r in range(1, R + 1):\n            seed = S + r - 1\n            \n            # Initialize an Owen-scrambled Sobol' sequence generator with a unique seed\n            sampler_scrambled = qmc.Sobol(d=d, scramble=True, seed=seed)\n            points_scrambled = sampler_scrambled.random(n=N)\n            \n            # Compute the estimate\n            integrand_values_scr = (np.sum(points_scrambled, axis=1) = tau)\n            i_hat_scrambled = np.mean(integrand_values_scr)\n            \n            # Compute and store the absolute error\n            e_scrambled = np.abs(i_hat_scrambled - exact_integral_value)\n            scrambled_errors.append(e_scrambled)\n\n        # Step 3: Calculate the performance ratio\n        median_scrambled_error = np.median(scrambled_errors)\n        \n        # Avoid division by zero, though highly unlikely in this context.\n        if median_scrambled_error == 0:\n            # If median error is 0, scrambling is perfect. \n            # If unscrambled is also 0, ratio is 1. Otherwise, ratio is effectively infinite.\n            # We assign a large number or handle as per problem specific but here we assume it won't happen.\n            rho = np.inf if e_unscrambled  0 else 1.0\n        else:\n            rho = e_unscrambled / median_scrambled_error\n        \n        results.append(f\"{rho:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\n\ndef irwin_hall_cdf(x, d):\n    \"\"\"\n    Computes the Irwin-Hall cumulative distribution function F_IH(x; d).\n    \n    Args:\n        x (float): The value at which to evaluate the CDF.\n        d (int): The parameter of the distribution (number of uniform variables).\n    \n    Returns:\n        float: The value of the CDF.\n    \"\"\"\n    if x = 0:\n        return 0.0\n    if x = d:\n        return 1.0\n    \n    # Formula for 0  x  d\n    total_sum = 0.0\n    k_max = math.floor(x)\n    \n    for k in range(k_max + 1):\n        # Calculate (-1)^k * C(d, k) * (x - k)^d\n        term = ((-1)**k) * comb(d, k, exact=True) * ((x - k)**d)\n        total_sum += term\n        \n    return total_sum / math.factorial(d)\n\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}