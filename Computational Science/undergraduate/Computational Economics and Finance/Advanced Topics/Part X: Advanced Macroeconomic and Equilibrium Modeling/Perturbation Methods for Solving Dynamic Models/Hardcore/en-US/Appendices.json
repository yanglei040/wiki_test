{
    "hands_on_practices": [
        {
            "introduction": "Perturbation methods build a local approximation around a point of equilibrium, namely the model's steady state. This exercise provides a crucial hands-on lesson by demonstrating the pathological and economically nonsensical dynamics that arise from linearizing around an incorrect point . By observing these failures, you will gain a deeper appreciation for why correctly solving for the steady state is the essential first step of any perturbation analysis.",
            "id": "2418938",
            "problem": "Consider the standard one-sector Real Business Cycle (RBC) model with inelastic labor and logarithmic utility. Time is discrete. The representative household maximizes expected discounted utility subject to a resource constraint and firms operate a Cobb-Douglas technology. The structural environment is:\n- Preferences: $\\sum_{t=0}^{\\infty} \\beta^{t} \\log(c_{t})$ with discount factor $\\beta \\in (0,1)$.\n- Technology: $y_{t} = \\exp(z_{t}) k_{t}^{\\alpha}$ with capital share $\\alpha \\in (0,1)$.\n- Capital accumulation and resource feasibility: $c_{t} + k_{t+1} = (1-\\delta) k_{t} + y_{t}$ with depreciation rate $\\delta \\in (0,1)$.\n- Productivity shock: $z_{t+1} = \\rho z_{t} + \\sigma \\varepsilon_{t+1}$ with $|\\rho|1$, $\\sigma>0$, and $\\varepsilon_{t+1} \\sim \\mathcal{N}(0,1)$.\n\nThe fundamental equilibrium first-order conditions are:\n- Euler equation: $\\frac{1}{c_{t}} = \\beta \\, \\mathbb{E}_{t} \\left[ \\frac{1}{c_{t+1}} \\left( \\alpha \\exp(z_{t+1}) k_{t+1}^{\\alpha-1} + 1 - \\delta \\right) \\right]$.\n- Resource feasibility: $c_{t} + k_{t+1} - (1-\\delta)k_{t} - \\exp(z_{t}) k_{t}^{\\alpha} = 0$.\n\nLet the vector of predetermined endogenous variables be $x_{t} = k_{t}$, the vector of non-predetermined endogenous (jump) variables be $y_{t} = c_{t}$, and the vector of exogenous states be $z_{t}$ (scalar). Define the equilibrium residual vector $f(\\cdot)$ at time $t$ on the variables $(x_{t+1},y_{t+1},x_{t},y_{t},z_{t+1},z_{t})$ by stacking the Euler equation residual and the resource feasibility residual evaluated at those arguments.\n\nFirst-order perturbation around a steady state requires linearization of the equilibrium conditions around a point that satisfies the steady-state conditions. In this exercise, you are asked to implement a naive first-order perturbation that ignores the constant residual and linearizes around possibly incorrect “pseudo steady states” that do not satisfy the steady-state conditions. The goal is to illustrate the pathologies that can occur when the expansion point is incorrect, by computing the resulting impulse response functions (IRFs) and stability properties.\n\nTasks to implement:\n1. For a given expansion point $(\\bar{x},\\bar{y},\\bar{z}) = (\\bar{k},\\bar{c},0)$ and its “next-period” counterpart $(\\bar{x}^{+},\\bar{y}^{+},\\bar{z}^{+}) = (\\bar{k},\\bar{c},0)$, numerically compute the Jacobian blocks of $f$ using central finite differences:\n   - $f_{x^{+}} = \\frac{\\partial f}{\\partial x_{t+1}}(\\bar{\\cdot})$, $f_{y^{+}} = \\frac{\\partial f}{\\partial y_{t+1}}(\\bar{\\cdot})$, $f_{x} = \\frac{\\partial f}{\\partial x_{t}}(\\bar{\\cdot})$, $f_{y} = \\frac{\\partial f}{\\partial y_{t}}(\\bar{\\cdot})$, $f_{z} = \\frac{\\partial f}{\\partial z_{t}}(\\bar{\\cdot})$, $f_{z^{+}} = \\frac{\\partial f}{\\partial z_{t+1}}(\\bar{\\cdot})$.\n   Use a step size that scales with the magnitude of the variable being perturbed to avoid numerical underflow and ensure $y$ stays strictly positive in the perturbations.\n2. Form the linearized expectational system (in deviations from the expansion point) by combining the $z_{t+1}$ term via its conditional expectation:\n   - Let $F_{x^{+}} = f_{x^{+}}$, $F_{y^{+}} = f_{y^{+}}$, $F_{x} = f_{x}$, $F_{y} = f_{y}$, and $F_{z} = f_{z} + f_{z^{+}} \\rho$.\n   - The linearized equilibrium is $F_{x^{+}} x_{t+1} + F_{y^{+}} y_{t+1} + F_{x} x_{t} + F_{y} y_{t} + F_{z} z_{t} = 0$, where expectations apply to $y_{t+1}$ via the policy function.\n3. Assume linear policy functions for a naive first-order solution (ignoring any constant term induced by linearizing at a non-solution):\n   - $x_{t+1} = p \\, x_{t} + q \\, z_{t}$,\n   - $y_{t} = r \\, x_{t} + s \\, z_{t}$,\n   - and hence $\\mathbb{E}_{t} y_{t+1} = r \\, x_{t+1} + s \\, \\rho \\, z_{t}$.\n   Impose that the coefficients on $x_{t}$ and $z_{t}$ in the linearized system are identically zero in each equation to obtain two vector conditions. Solve for $(p,r)$ from the $x_{t}$-coefficient conditions and then for $(q,s)$ from the $z_{t}$-coefficient conditions. Use a robust numerical root finder for $(p,r)$ and a linear solver for $(q,s)$. If the solver fails to converge to a finite solution, treat the case as “no valid solution.”\n4. Using the obtained $(p,q,r,s)$, compute the impulse response functions (IRFs) of $(x_{t},y_{t})$ to a one-time initial exogenous state deviation of size $\\Delta z_{0} = \\sigma$ at $t=0$, with $x_{0}=0$, and $z_{t+1} = \\rho z_{t}$ for $t \\ge 0$ and no further shocks. That is, set $z_{0} = \\sigma$, then iterate:\n   - $y_{t} = r \\, x_{t} + s \\, z_{t}$,\n   - $x_{t+1} = p \\, x_{t} + q \\, z_{t}$,\n   - $z_{t+1} = \\rho \\, z_{t}$,\n   for $t = 0,1,\\dots,T-1$ over a finite horizon $T$.\n5. Diagnose “pathology” using the following quantitative metrics:\n   - Stability flag: set to $1$ if $|p|  1$ and to $0$ otherwise.\n   - Sign-consistency flag for the impact response of consumption: set to $1$ if $y_{0} \\ge 0$ when $\\Delta z_{0} > 0$, and $0$ otherwise.\n   - Divergence flag: compute the Euclidean norms $\\| (x_{t},y_{t}) \\|$ over the horizon; set to $1$ if either the solver failed, or $|p| \\ge 1$, or if the ratio $\\max_{t \\in \\{T-5,\\dots,T-1\\}} \\| (x_{t},y_{t}) \\| \\big/ \\max_{t \\in \\{0,\\dots,4\\}} \\| (x_{t},y_{t}) \\|$ exceeds $100$, and set to $0$ otherwise.\n\nParameter values:\n- $\\beta = 0.96$, $\\alpha = 0.36$, $\\delta = 0.08$, $\\rho = 0.90$, $\\sigma = 0.01$, $T = 40$.\n- The correct steady state (expansion point) satisfies $1 = \\beta \\left( \\alpha \\bar{k}^{\\alpha-1} + 1 - \\delta \\right)$, so $\\bar{k} = \\left( \\frac{\\alpha}{\\beta^{-1} - 1 + \\delta} \\right)^{\\frac{1}{1-\\alpha}}$, $\\bar{y} = \\bar{k}^{\\alpha}$, $\\bar{c} = \\bar{y} - \\delta \\bar{k}$, and $\\bar{z} = 0$.\n\nTest suite of expansion points (linearize “naively” around each, treating it as if it were a steady state):\n- Case A (correct expansion point): $(\\bar{k}, \\bar{c}, 0)$ computed from the above formulas.\n- Case B (incorrect but resource-consistent): $(\\tilde{k}, \\tilde{c}, 0)$ with $\\tilde{k} = 0.5 \\, \\bar{k}$ and $\\tilde{c} = \\tilde{k}^{\\alpha} - \\delta \\tilde{k}$.\n- Case C (incorrect and resource-inconsistent): $(\\hat{k}, \\hat{c}, 0)$ with $\\hat{k} = 5.0 \\, \\bar{k}$ and $\\hat{c} = 0.2 \\, \\bar{c}$.\n\nYour program must:\n- Numerically compute the Jacobians, solve for $(p,q,r,s)$ using the method described, simulate the IRFs for each case under the one-time initial deviation $\\Delta z_{0} = \\sigma$, and compute the three flags for each case in the order: stability flag, sign-consistency flag, divergence flag.\n- Produce a single line of output containing all results as a comma-separated list enclosed in square brackets, in the order: Case A flags followed by Case B flags followed by Case C flags. For example, the output format must be exactly like: $[a_{1},a_{2},a_{3},b_{1},b_{2},b_{3},c_{1},c_{2},c_{3}]$ where each $a_{i}$, $b_{i}$, $c_{i}$ is an integer $0$ or $1$.\n\nNo physical units or angle units are involved. Express all numeric outputs as integers $0$ or $1$ exactly, not as decimals.",
            "solution": "The problem requires an implementation and evaluation of a first-order perturbation method for a standard Real Business Cycle (RBC) model. The unique aspect of the problem is the directive to perform the linearization (perturbation) around points that are not necessarily the true deterministic steady state of the model. This is a pedagogical exercise to demonstrate the pathologies that arise from an incorrect expansion point, which is a common error in practical application. My response will present the systematic procedure to solve this problem, adhering to the specified numerical methods.\n\nFirst, the structural equations of the economic environment must be clearly defined. The representative household's problem under the given preferences, technology, and constraints yields two fundamental first-order conditions that must hold in equilibrium at all times $t$:\n1.  The Euler equation, which governs the intertemporal consumption-savings trade-off:\n    $$ \\frac{1}{c_{t}} = \\beta \\, \\mathbb{E}_{t} \\left[ \\frac{1}{c_{t+1}} \\left( \\alpha \\exp(z_{t+1}) k_{t+1}^{\\alpha-1} + 1 - \\delta \\right) \\right] $$\n2.  The resource constraint, ensuring market clearing:\n    $$ c_{t} + k_{t+1} = (1-\\delta) k_{t} + \\exp(z_{t}) k_{t}^{\\alpha} $$\n\nThese two equations form a system of nonlinear stochastic difference equations. To solve this system using perturbation, we first express them as a vector of residual functions, $f$, which must equal zero in equilibrium. Let the state vector be partitioned into predetermined variables $x_t = k_t$, non-predetermined (jump) variables $y_t = c_t$, and exogenous shocks $z_t$. The system can be written abstractly as:\n$$ \\mathbb{E}_t [f(x_{t+1}, y_{t+1}, x_t, y_t, z_{t+1}, z_t)] = 0 $$\nSpecifically, the two components of $f$ are:\n$$ f_1 = \\frac{1}{y_{t}} - \\beta \\frac{1}{y_{t+1}} \\left( \\alpha \\exp(z_{t+1}) x_{t+1}^{\\alpha-1} + 1 - \\delta \\right) $$\n$$ f_2 = y_{t} + x_{t+1} - (1-\\delta)x_{t} - \\exp(z_{t}) x_{t}^{\\alpha} $$\nNote that the expectation operator is handled at a later stage.\n\nA first-order perturbation approximates the solution by taking a first-order Taylor series expansion of this system around a specified expansion point, denoted $(\\bar{x}, \\bar{y}, \\bar{z})$. A crucial detail is that a correct application of perturbation theory requires this expansion point to be a steady state, i.e., a point where $f(\\bar{x}, \\bar{y}, \\bar{x}, \\bar{y}, \\bar{z}, \\bar{z}) = 0$ when $\\bar{z}=0$. The problem instructs us to proceed \"naively\" by ignoring the constant term that arises when this condition is not met. The linearized system is thus approximated as:\n$$ F_{x^{+}} \\hat{x}_{t+1} + F_{y^{+}} \\mathbb{E}_{t} \\hat{y}_{t+1} + F_{x} \\hat{x}_{t} + F_{y} \\hat{y}_{t} + F_{z^{+}} \\mathbb{E}_{t} \\hat{z}_{t+1} + F_{z} \\hat{z}_{t} = 0 $$\nwhere $\\hat{v} = v - \\bar{v}$ denotes a deviation from the expansion point, and the matrices $F_{v}$ are the Jacobians of $f$ with respect to variable $v$, evaluated at the expansion point. As per the problem, these Jacobians are computed numerically using a central finite difference scheme.\n\nThe autoregressive nature of the shock process, $z_{t+1} = \\rho z_t + \\sigma \\varepsilon_{t+1}$, implies $\\mathbb{E}_t[\\hat{z}_{t+1}] = \\rho \\hat{z}_t$. Substituting this collapses the shock terms into one:\n$$ F_{x^{+}} \\hat{x}_{t+1} + F_{y^{+}} \\mathbb{E}_{t} \\hat{y}_{t+1} + F_{x} \\hat{x}_{t} + F_{y} \\hat{y}_{t} + (F_{z} + F_{z^{+}}\\rho) \\hat{z}_{t} = 0 $$\n\nThe term $\\mathbb{E}_{t} \\hat{y}_{t+1}$ is endogenous and unknown. To solve the system, we assume a linear policy function for the deviations:\n$$ \\hat{x}_{t+1} = p \\hat{x}_{t} + q \\hat{z}_{t} $$\n$$ \\hat{y}_{t} = r \\hat{x}_{t} + s \\hat{z}_{t} $$\nThis implies a rule for the expectation of the future jump variable:\n$$ \\mathbb{E}_{t} \\hat{y}_{t+1} = \\mathbb{E}_{t} [r \\hat{x}_{t+1} + s \\hat{z}_{t+1}] = r \\hat{x}_{t+1} + s (\\rho \\hat{z}_t) = r(p \\hat{x}_{t} + q \\hat{z}_{t}) + s \\rho \\hat{z}_t $$\n\nSubstituting these policy rules into the linearized system and grouping terms by the independent state variables $\\hat{x}_t$ and $\\hat{z}_t$ gives two conditions, as the equation must hold for any state realization:\n1.  Coefficient on $\\hat{x}_t$: $F_{x^{+}}p + F_{y^{+}}rp + F_x + F_y r = 0$\n2.  Coefficient on $\\hat{z}_t$: $F_{x^{+}}q + F_{y^{+}}(rq + s\\rho) + F_y s + (F_z + F_{z^{+}}\\rho) = 0$\n\nThe first is a system of two equations, nonlinear in the two unknowns $(p,r)$ due to the product $rp$. It must be solved numerically, for instance, with a robust root-finding algorithm. The second is a linear system in $(q,s)$ that can be solved directly once $(p,r)$ are known.\n\nOnce the policy function coefficients $(p,q,r,s)$ are determined, we can assess the properties of the resulting \"solution\". Failure to find a finite, real solution with the numerical solver is the first indicator of pathology. If a solution is found, we evaluate it against three criteria:\n1.  **Stability**: A stable dynamic system requires that the endogenous state variable does not explode in response to a temporary shock. For this model, this corresponds to the condition $|p|  1$.\n2.  **Sign-Consistency**: Standard economic theory dictates that a positive productivity shock ($\\Delta z_0 > 0$) should lead to an increase in consumption, i.e., $y_0 \\ge 0$. The initial response is $\\hat{y}_0 = r \\hat{x}_0 + s \\hat{z}_0 = s \\sigma$. Given $\\sigma>0$, this reduces to checking if $s \\ge 0$.\n3.  **Divergence**: This is a composite flag. It is triggered if the solver fails, if the stability condition $|p| \\ge 1$ is met, or if the simulated impulse response functions (IRFs) show explosive behavior, quantitatively measured by comparing the norm of the state vector at the end of the simulation horizon to its norm at the beginning.\n\nThe implementation will apply this entire procedure to three distinct expansion points: the correct steady state (Case A), an incorrect but resource-consistent point (Case B), and an incorrect point violating all steady-state conditions (Case C). This will quantitatively demonstrate that only linearization around the true steady state yields a coherent dynamic system.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import root\n\ndef process_case(expansion_point, params):\n    \"\"\"\n    Computes Jacobians, solves for policy functions, and evaluates pathologies for a given expansion point.\n    \"\"\"\n    # Unpack parameters\n    beta, alpha, delta, rho, sigma, T = params\n    k_bar, c_bar, z_bar = expansion_point\n\n    # Ensure expansion point itself is valid for calculation (c0)\n    if c_bar = 0:\n        # Cannot proceed, mark as total failure\n        return 0, 0, 1\n\n    # 1. Define the residual functions for the two equilibrium conditions\n    def f_residuals(xp, yp, x, y, zp, z):\n        # xp=k_{t+1}, yp=c_{t+1}, x=k_t, y=c_t, zp=z_{t+1}, z=z_t\n        if yp = 0:\n            return np.array([1e12, 1e12]) # Return large penalty if consumption is non-positive\n        \n        # Euler equation residual\n        f1 = 1.0 / y - beta / yp * (alpha * np.exp(zp) * xp**(alpha - 1) + 1.0 - delta)\n        # Resource constraint residual\n        f2 = y + xp - (1.0 - delta) * x - np.exp(z) * x**alpha\n        return np.array([f1, f2])\n\n    # 2. Compute Jacobians numerically via central finite differences\n    def compute_jacobians(eval_point):\n        k_eval, c_eval, z_eval = eval_point\n        vars_base = [k_eval, c_eval, k_eval, c_eval, z_eval, z_eval]\n        jacobians = {}\n        var_names = ['xp', 'yp', 'x', 'y', 'zp', 'z']\n        \n        for i, name in enumerate(var_names):\n            # Scaled step size to handle variables of different magnitudes\n            h = 1e-6 * np.abs(vars_base[i]) + 1e-8\n            \n            vars_plus = list(vars_base)\n            vars_plus[i] += h\n            f_plus = f_residuals(*vars_plus)\n\n            vars_minus = list(vars_base)\n            vars_minus[i] -= h\n            f_minus = f_residuals(*vars_minus)\n            \n            jacobians[name] = (f_plus - f_minus) / (2.0 * h)\n            \n        return (jacobians['xp'], jacobians['yp'], jacobians['x'],\n                jacobians['y'], jacobians['zp'], jacobians['z'])\n\n    f_xp, f_yp, f_x, f_y, f_zp, f_z = compute_jacobians(expansion_point)\n\n    # 3. Solve for policy function coefficients (p, r, q, s)\n    p, q, r, s = None, None, None, None\n    solver_success = False\n    \n    # Define the nonlinear system for (p, r)\n    def pol_sys_pr(pr_vec):\n        p_val, r_val = pr_vec\n        # Eq1: Coefficient on x_t from Euler residual must be zero\n        eq1 = f_xp[0] * p_val + f_yp[0] * r_val * p_val + f_x[0] + f_y[0] * r_val\n        # Eq2: Coefficient on x_t from Resource residual must be zero\n        eq2 = f_xp[1] * p_val + f_yp[1] * r_val * p_val + f_x[1] + f_y[1] * r_val\n        return [eq1, eq2]\n    \n    # Solve for (p,r) using a numerical root finder\n    initial_guess_pr = [0.95, 0.5]\n    sol_pr = root(pol_sys_pr, initial_guess_pr, method='hybr', options={'xtol': 1e-9})\n    \n    if sol_pr.success and np.all(np.isfinite(sol_pr.x)):\n        p, r = sol_pr.x\n        \n        # Once (p,r) are found, solve the linear system for (q,s)\n        Fz_eff = f_z + f_zp * rho\n        \n        A = np.zeros((2, 2))\n        A[:, 0] = f_xp + f_yp * r      # Coefficient on q\n        A[:, 1] = f_y + f_yp * rho    # Coefficient on s\n        \n        b = -Fz_eff\n        \n        try:\n            # Check if matrix A is singular\n            if np.linalg.det(A) == 0:\n                solver_success = False\n            else:\n                q, s = np.linalg.solve(A, b)\n                if np.all(np.isfinite([q, s])):\n                    solver_success = True\n        except np.linalg.LinAlgError:\n            solver_success = False\n\n    # 4. Diagnose pathologies and compute flags\n    divergence_flag = 0\n    if not solver_success:\n        divergence_flag = 1\n        stability_flag = 0\n        sign_consistency_flag = 0\n        return stability_flag, sign_consistency_flag, divergence_flag\n\n    stability_flag = 1 if np.abs(p)  1.0 else 0\n    sign_consistency_flag = 1 if s = 0.0 else 0\n    \n    if np.abs(p) = 1.0:\n        divergence_flag = 1\n\n    # Simulate IRF to check for long-term divergence only if not already flagged\n    if divergence_flag == 0:\n        x_irf = np.zeros(T)\n        y_irf = np.zeros(T)\n        z_irf = np.zeros(T)\n        \n        z_irf[0] = sigma\n        # x_irf[0] is 0 by problem specification\n\n        for t in range(T - 1):\n            y_irf[t] = r * x_irf[t] + s * z_irf[t]\n            x_irf[t+1] = p * x_irf[t] + q * z_irf[t]\n            z_irf[t+1] = rho * z_irf[t]\n        y_irf[T-1] = r * x_irf[T-1] + s * z_irf[T-1]\n\n        norms = np.sqrt(x_irf**2 + y_irf**2)\n        \n        max_early = np.max(norms[0:5])\n        max_late = np.max(norms[T-5:T])\n        \n        # If initial impact is virtually zero, system is stable, so avoid division by zero\n        if max_early  1e-12:\n            if max_late / max_early  100.0:\n                divergence_flag = 1\n    \n    return stability_flag, sign_consistency_flag, divergence_flag\n\n\ndef solve():\n    # Structural parameters of the RBC model\n    beta = 0.96\n    alpha = 0.36\n    delta = 0.08\n    rho = 0.90\n    sigma = 0.01\n    T = 40\n    params = (beta, alpha, delta, rho, sigma, T)\n\n    # Calculate the correct steady state (for Case A and as a reference)\n    k_bar = (alpha / (1.0/beta - 1.0 + delta))**(1.0 / (1.0 - alpha))\n    c_bar = k_bar**alpha - delta * k_bar\n    z_bar = 0.0\n    \n    # Define the three test cases as expansion points (k, c, z)\n    test_cases = [\n        # Case A: Correct expansion point\n        (k_bar, c_bar, z_bar),\n        # Case B: Incorrect but resource-consistent point\n        (0.5 * k_bar, (0.5 * k_bar)**alpha - delta * (0.5 * k_bar), z_bar),\n        # Case C: Incorrect and resource-inconsistent point\n        (5.0 * k_bar, 0.2 * c_bar, z_bar)\n    ]\n\n    all_results = []\n    for expansion_point in test_cases:\n        flags = process_case(expansion_point, params)\n        all_results.extend(flags)\n        \n    # Format and print the final output as a single-line list\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A common practical question is whether to linearize a model in the levels of its variables (e.g., $k_t$) or their logarithms (e.g., $\\log(k_t)$). This practice explores the relationship between these two popular approaches, which can be a source of confusion for students . By implementing both methods, you will verify their equivalence at the first order of approximation, learning that the choice is often one of convenience rather than a source of difference in the solution's local accuracy.",
            "id": "2418943",
            "problem": "Consider the stochastic Solow growth model with Cobb-Douglas technology and exogenous productivity:\n- Capital evolves according to $k_{t+1} = s \\, a_t \\, k_t^{\\alpha} + (1-\\delta) k_t$, where $k_t  0$ is capital, $s \\in (0,1)$ is the savings rate, $\\alpha \\in (0,1)$ is the output elasticity of capital, and $\\delta \\in (0,1)$ is the depreciation rate.\n- Productivity satisfies $a_t = \\exp(z_t)$ with $\\log$-productivity following an autoregressive process $z_t = (1-\\rho)\\,\\bar z + \\rho\\, z_{t-1} + \\sigma \\varepsilon_t$, where $|\\rho|  1$, $\\sigma \\ge 0$, and $\\varepsilon_t$ is an independently and identically distributed (i.i.d.) innovation with mean $0$ and unit variance.\n- Let the deterministic steady state be $(\\bar k, \\bar z)$, where $\\bar a = \\exp(\\bar z)$ and $\\bar k$ solves $\\bar k = s \\bar a \\bar k^{\\alpha} + (1-\\delta)\\bar k$.\n\nYou are to compare impulse response functions for capital under two first-order perturbation approaches around the deterministic steady state:\n- Levels linearization: linearize in the variables $(k_t, z_t)$.\n- Log-linearization: linearize in $(\\log k_t, z_t)$ and report the capital response in levels using the first-order mapping $k_t \\approx \\bar k (1 + \\hat k_t)$, where $\\hat k_t = \\log(k_t) - \\log(\\bar k)$.\n\nDefine an impulse response to a one-standard-deviation productivity shock at date $t=0$ by setting $\\varepsilon_0 = 1$ and $\\varepsilon_t = 0$ for all $t \\ge 1$, with initial conditions $k_0 = \\bar k$ and $z_{-1} = \\bar z$. Construct the impulse responses for $k_t$ over a finite horizon $t=0,1,\\dots,H$ under both methods, keeping the approximation order fixed at first order. For each parameter set below, compute the maximum absolute difference, over $t=0,1,\\dots,H$, between the two capital responses in levels.\n\nTest suite (each line is one independent case, to be evaluated in the order listed):\n- Case A (happy path): $\\alpha = 0.35$, $\\delta = 0.08$, $s = 0.25$, $\\rho = 0.90$, $\\sigma = 0.01$, $\\bar z = 0$, $H = 20$.\n- Case B (low depreciation): $\\alpha = 0.33$, $\\delta = 0.01$, $s = 0.15$, $\\rho = 0.80$, $\\sigma = 0.02$, $\\bar z = 0$, $H = 30$.\n- Case C (no persistence): $\\alpha = 0.40$, $\\delta = 0.12$, $s = 0.30$, $\\rho = 0$, $\\sigma = 0.05$, $\\bar z = 0$, $H = 15$.\n- Case D (high persistence): $\\alpha = 0.30$, $\\delta = 0.05$, $s = 0.20$, $\\rho = 0.99$, $\\sigma = 0.005$, $\\bar z = 0$, $H = 40$.\n- Case E (zero shock size): $\\alpha = 0.33$, $\\delta = 0.10$, $s = 0.20$, $\\rho = 0.95$, $\\sigma = 0$, $\\bar z = 0$, $H = 20$.\n\nYour program must:\n- Compute $\\bar k$ from first principles given the model definition and parameters.\n- Construct first-order perturbation dynamics in levels and in logs.\n- For each case, simulate the impulse responses of $k_t$ under both methods over the stated horizon, and compute the maximum absolute difference across $t=0,1,\\dots,H$.\n- Output a single line containing a comma-separated list of these maxima, in the order A through E, enclosed in square brackets. Each value must be a floating-point number rounded to $12$ decimal places. For example, an output with three cases should look like $[x_1,x_2,x_3]$ with no spaces.\n\nNo physical units are involved. Angles do not appear. Percentages must not be used anywhere; all values are real numbers.",
            "solution": "The problem asks for a comparison of two first-order perturbation methods for solving the stochastic Solow growth model. The core of the analysis involves deriving the linearized dynamics for both methods, simulating the impulse response of capital to a productivity shock, and calculating the maximum absolute difference between the two resulting capital paths.\n\nFirst, we define the model equations:\n1.  Capital accumulation: $k_{t+1} = s \\, a_t \\, k_t^{\\alpha} + (1-\\delta) k_t$, where $a_t = \\exp(z_t)$.\n2.  Log-productivity process: $z_t = (1-\\rho)\\,\\bar z + \\rho\\, z_{t-1} + \\sigma \\varepsilon_t$.\n\nLet's establish the deterministic steady state $(\\bar k, \\bar z)$. At this state, there are no shocks ($\\varepsilon_t = 0$), so $z_t = \\bar z$ for all $t$. The capital stock is constant, $k_t = k_{t+1} = \\bar k$. The steady state is defined by the equation:\n$$\n\\bar k = s \\, \\exp(\\bar z) \\, \\bar k^{\\alpha} + (1-\\delta) \\bar k\n$$\nLetting $\\bar a = \\exp(\\bar z)$, we simplify:\n$$\n\\delta \\bar k = s \\bar a \\bar k^{\\alpha}\n$$\nSince $k_t > 0$, we know $\\bar k > 0$. We can divide by $\\bar k^{\\alpha}$:\n$$\n\\delta \\bar k^{1-\\alpha} = s \\bar a\n$$\nSolving for $\\bar k$ yields the steady-state capital stock:\n$$\n\\bar k = \\left(\\frac{s \\bar a}{\\delta}\\right)^{\\frac{1}{1-\\alpha}}\n$$\n\nNext, we analyze the perturbation methods. Let deviations from steady state be denoted by a tilde, e.g., $\\tilde k_t = k_t - \\bar k$ and $\\tilde z_t = z_t - \\bar z$. The exogenous process for $\\tilde z_t$ is found by subtracting $\\bar z$ from the equation for $z_t$:\n$$\nz_t - \\bar z = (1-\\rho)\\bar z + \\rho z_{t-1} + \\sigma \\varepsilon_t - \\bar z = \\rho(z_{t-1} - \\bar z) + \\sigma \\varepsilon_t\n$$\n$$\n\\tilde z_t = \\rho \\tilde z_{t-1} + \\sigma \\varepsilon_t\n$$\nGiven the initial condition $z_{-1} = \\bar z$ ($\\tilde z_{-1}=0$) and the one-time shock $\\varepsilon_0 = 1$ ($\\varepsilon_t=0$ for $t \\ge 1$), the path of $\\tilde z_t$ is:\n$$\n\\tilde z_0 = \\rho \\tilde z_{-1} + \\sigma \\varepsilon_0 = \\sigma\n$$\n$$\n\\tilde z_1 = \\rho \\tilde z_0 + \\sigma \\varepsilon_1 = \\rho \\sigma\n$$\n$$\n\\tilde z_t = \\rho^t \\sigma \\quad \\text{for } t \\ge 0\n$$\n\n**1. Levels Linearization**\n\nWe linearize the capital accumulation equation $k_{t+1} = f(k_t, z_t)$ around the steady state $(\\bar k, \\bar z)$. The first-order Taylor expansion gives:\n$$\nk_{t+1} - \\bar k \\approx \\frac{\\partial f}{\\partial k_t}\\bigg|_{(\\bar k, \\bar z)} (k_t - \\bar k) + \\frac{\\partial f}{\\partial z_t}\\bigg|_{(\\bar k, \\bar z)} (z_t - \\bar z)\n$$\n$$\n\\tilde k_{t+1} \\approx J_k \\tilde k_t + J_z \\tilde z_t\n$$\nThe required partial derivatives are:\n$$\nJ_k = \\frac{\\partial f}{\\partial k_t}\\bigg|_{(\\bar k, \\bar z)} = s \\bar a \\alpha \\bar k^{\\alpha-1} + (1-\\delta)\n$$\nUsing the steady-state condition $s \\bar a = \\delta \\bar k^{1-\\alpha}$, we have:\n$$\nJ_k = (\\delta \\bar k^{1-\\alpha}) \\alpha \\bar k^{\\alpha-1} + (1-\\delta) = \\alpha \\delta + 1 - \\delta = 1 - \\delta(1-\\alpha)\n$$\n$$\nJ_z = \\frac{\\partial f}{\\partial z_t}\\bigg|_{(\\bar k, \\bar z)} = s \\exp(z_t) k_t^\\alpha \\bigg|_{(\\bar k, \\bar z)} = s \\bar a \\bar k^\\alpha\n$$\nAgain using the steady-state condition $\\delta \\bar k = s \\bar a \\bar k^\\alpha$:\n$$\nJ_z = \\delta \\bar k\n$$\nThe linearized system in levels is thus:\n$$\n\\tilde k_{t+1}^{\\text{level}} = (1 - \\delta(1-\\alpha)) \\tilde k_t^{\\text{level}} + (\\delta \\bar k) \\tilde z_t\n$$\nThe impulse response for capital in levels, denoted $k_t^{\\text{level}}$, is $k_t^{\\text{level}} = \\bar k + \\tilde k_t^{\\text{level}}$.\n\n**2. Log-Linearization**\n\nWe linearize the model in terms of log-deviations from the steady state. Let $\\hat k_t = \\log(k_t) - \\log(\\bar k)$. The state variables for linearization are $(\\log k_t, z_t)$. The capital accumulation equation cannot be easily logged. Instead, we directly linearize the function $k_{t+1}(\\log k_t, z_t)$. A more robust method is to linearize the following implicit function around the steady state:\n$$\n\\log(k_{t+1}) = \\log\\left(s \\exp(z_t) k_t^\\alpha + (1-\\delta)k_t\\right)\n$$\nLet $x_t = \\log k_t$. The linearized equation for $\\hat k_{t+1} = \\log(k_{t+1}) - \\log(\\bar k)$ is:\n$$\n\\hat k_{t+1} \\approx \\frac{\\partial \\log(k_{t+1})}{\\partial x_t}\\bigg|_{SS} \\hat k_t + \\frac{\\partial \\log(k_{t+1})}{\\partial z_t}\\bigg|_{SS} \\tilde z_t\n$$\nThe derivatives are:\n$$\n\\frac{\\partial \\log(k_{t+1})}{\\partial x_t} = \\frac{1}{k_{t+1}} \\frac{\\partial k_{t+1}}{\\partial x_t} = \\frac{1}{k_{t+1}} \\frac{\\partial}{\\partial x_t}\\left(s e^{z_t} e^{\\alpha x_t} + (1-\\delta)e^{x_t}\\right) = \\frac{s e^{z_t} \\alpha e^{\\alpha x_t} + (1-\\delta)e^{x_t}}{s e^{z_t} e^{\\alpha x_t} + (1-\\delta)e^{x_t}}\n$$\nEvaluated at the steady state ($x_t=\\log \\bar k, z_t=\\bar z, k_{t+1}=\\bar k$), this becomes:\n$$\n\\frac{s \\bar a \\alpha \\bar k^\\alpha + (1-\\delta)\\bar k}{s \\bar a \\bar k^\\alpha + (1-\\delta)\\bar k} = \\frac{\\alpha(\\delta \\bar k) + (1-\\delta)\\bar k}{\\bar k} = \\alpha\\delta + 1 - \\delta = 1 - \\delta(1-\\alpha)\n$$\nAnd for $z_t$:\n$$\n\\frac{\\partial \\log(k_{t+1})}{\\partial z_t} = \\frac{1}{k_{t+1}} \\frac{\\partial k_{t+1}}{\\partial z_t} = \\frac{s e^{z_t} k_t^\\alpha}{k_{t+1}}\n$$\nEvaluated at the steady state, this is:\n$$\n\\frac{s \\bar a \\bar k^\\alpha}{\\bar k} = \\frac{\\delta \\bar k}{\\bar k} = \\delta\n$$\nThe log-linearized dynamics are:\n$$\n\\hat k_{t+1}^{\\text{log}} = (1 - \\delta(1-\\alpha)) \\hat k_t^{\\text{log}} + \\delta \\tilde z_t\n$$\nThe problem specifies converting this back to levels using the first-order approximation $k_t \\approx \\bar k(1 + \\hat k_t)$. So, $k_t^{\\text{log}} = \\bar k(1 + \\hat k_t^{\\text{log}})$.\n\n**3. Comparison of Impulse Responses**\n\nWe must compare the two paths $k_t^{\\text{level}}$ and $k_t^{\\text{log}}$ for $t=0, 1, \\dots, H$.\nThe initial conditions are $k_0 = \\bar k$ and $z_{-1} = \\bar z$. This implies:\n- $k_0^{\\text{level}} = \\bar k$, so $\\tilde k_0^{\\text{level}} = 0$.\n- For the log-linear case, $\\log(k_0) = \\log(\\bar k)$, so $\\hat k_0^{\\text{log}} = 0$. Thus $k_0^{\\text{log}} = \\bar k(1+0) = \\bar k$.\nAt $t=0$, the difference $|k_0^{\\text{level}} - k_0^{\\text{log}}|$ is $0$.\n\nLet's examine the relationship for $t \\ge 1$.\nThe path for the levels deviation is given by $\\tilde k_{t+1}^{\\text{level}} = (1 - \\delta(1-\\alpha)) \\tilde k_t^{\\text{level}} + (\\delta \\bar k) \\tilde z_t$.\nThe path for the log deviation is $\\hat k_{t+1}^{\\text{log}} = (1 - \\delta(1-\\alpha)) \\hat k_t^{\\text{log}} + \\delta \\tilde z_t$.\n\nLet us define a scaled log-deviation $Y_t = \\bar k \\hat k_t^{\\text{log}}$. The evolution of $Y_t$ is:\n$$\nY_{t+1} = \\bar k \\hat k_{t+1}^{\\text{log}} = \\bar k \\left( (1 - \\delta(1-\\alpha)) \\hat k_t^{\\text{log}} + \\delta \\tilde z_t \\right)\n$$\n$$\nY_{t+1} = (1 - \\delta(1-\\alpha)) (\\bar k \\hat k_t^{\\text{log}}) + (\\bar k \\delta) \\tilde z_t\n$$\n$$\nY_{t+1} = (1 - \\delta(1-\\alpha)) Y_t + (\\delta \\bar k) \\tilde z_t\n$$\nThis recurrence relation for $Y_t$ is identical to the one for $\\tilde k_t^{\\text{level}}$. The initial conditions are also identical:\n- $\\tilde k_0^{\\text{level}} = 0$.\n- $Y_0 = \\bar k \\hat k_0^{\\text{log}} = \\bar k \\cdot 0 = 0$.\n\nSince both sequences $\\left\\{\\tilde k_t^{\\text{level}}\\right\\}$ and $\\left\\{Y_t\\right\\}$ are generated by the same linear recurrence relation and start from the same initial condition, they must be identical for all $t$.\n$$\n\\tilde k_t^{\\text{level}} = Y_t = \\bar k \\hat k_t^{\\text{log}} \\quad \\forall t \\ge 0\n$$\nNow we compute the difference between the two capital paths:\n$$\nk_t^{\\text{level}} - k_t^{\\text{log}} = (\\bar k + \\tilde k_t^{\\text{level}}) - \\bar k(1 + \\hat k_t^{\\text{log}}) = \\bar k + \\tilde k_t^{\\text{level}} - \\bar k - \\bar k \\hat k_t^{\\text{log}} = \\tilde k_t^{\\text{level}} - \\bar k \\hat k_t^{\\text{log}}\n$$\nFrom our proof above, this difference is identically zero for all $t \\ge 0$.\n$$\nk_t^{\\text{level}} - k_t^{\\text{log}} = 0 \\quad \\forall t \\ge 0\n$$\nConsequently, the maximum absolute difference over the horizon $t=0, 1, \\dots, H$ is also $0$. This result demonstrates the first-order equivalence of levels and log-linearization when the latter is converted back to levels via its own first-order approximation. This holds true for any valid parameter set provided. The numerical implementation will compute the paths and their difference, which should be zero up to machine precision.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the maximum absolute difference between capital impulse responses\n    from levels-linearization and log-linearization for the stochastic Solow model.\n    \"\"\"\n    # Test suite: (alpha, delta, s, rho, sigma, z_bar, H)\n    test_cases = [\n        (0.35, 0.08, 0.25, 0.90, 0.01, 0.0, 20),   # Case A\n        (0.33, 0.01, 0.15, 0.80, 0.02, 0.0, 30),   # Case B\n        (0.40, 0.12, 0.30, 0.0, 0.05, 0.0, 15),    # Case C\n        (0.30, 0.05, 0.20, 0.99, 0.005, 0.0, 40),  # Case D\n        (0.33, 0.10, 0.20, 0.95, 0.0, 0.0, 20),    # Case E\n    ]\n\n    max_diffs = []\n\n    for case in test_cases:\n        alpha, delta, s, rho, sigma, z_bar, H = case\n        \n        # 1. Compute steady state\n        a_bar = np.exp(z_bar)\n        # Handle alpha=1 edge case to avoid division by zero, though not in test cases\n        if abs(1.0 - alpha)  1e-12:\n            # This case is not economically standard and not in test suite.\n            # A placeholder, though it won't be reached.\n            k_bar = 1.0 \n        else:\n            k_bar = (s * a_bar / delta) ** (1.0 / (1.0 - alpha))\n\n        # 2. Simulate the exogenous shock process z_t\n        # Path of z_tilde_t = z_t - z_bar\n        z_tilde_path = np.zeros(H + 1)\n        if sigma != 0:\n            for t in range(H + 1):\n                z_tilde_path[t] = (rho ** t) * sigma\n        \n        # 3. Simulate impulse responses for both methods\n        \n        # Levels linearization\n        k_level_path = np.zeros(H + 1)\n        k_tilde_level_path = np.zeros(H + 1)\n        \n        # Log-linearization\n        k_log_path = np.zeros(H + 1)\n        k_hat_log_path = np.zeros(H + 1)\n\n        # Initial conditions at t=0\n        # k_0 = k_bar implies k_tilde_0 = 0 and k_hat_0 = 0\n        k_level_path[0] = k_bar\n        k_log_path[0] = k_bar\n\n        # Coefficients for the recurrence relations\n        coeff_k = 1.0 - delta * (1.0 - alpha)\n        coeff_z_level = delta * k_bar\n        coeff_z_log = delta\n\n        # Iterate from t=0 to H-1 to find states at t=1..H\n        for t in range(H):\n            # Levels-linearization update\n            k_tilde_level_path[t+1] = coeff_k * k_tilde_level_path[t] + coeff_z_level * z_tilde_path[t]\n            k_level_path[t+1] = k_bar + k_tilde_level_path[t+1]\n\n            # Log-linearization update\n            k_hat_log_path[t+1] = coeff_k * k_hat_log_path[t] + coeff_z_log * z_tilde_path[t]\n            k_log_path[t+1] = k_bar * (1.0 + k_hat_log_path[t+1])\n\n        # 4. Compute the maximum absolute difference\n        abs_diff = np.abs(k_level_path - k_log_path)\n        max_abs_diff = np.max(abs_diff)\n        \n        max_diffs.append(f\"{max_abs_diff:.12f}\")\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(max_diffs)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While second-order approximations offer greater accuracy, they introduce subtle implementation challenges that can lead to erroneous results. This exercise illustrates a critical pitfall: a naive simulation of a second-order policy rule can generate spurious higher-order terms that artificially destabilize the system . You will implement a theoretically sound \"pruning\" algorithm to prevent this, mastering a technique that is essential for reliably simulating any model solved with higher-order perturbation.",
            "id": "2418999",
            "problem": "Consider a univariate second-order perturbation policy function for the deviation of capital from its non-stochastic steady state, denoted by $k_t$. The second-order approximation around the steady state takes the form\n$$\nk_{t+1} \\;=\\; h\\,k_t \\;+\\; r\\,\\sigma\\,\\varepsilon_{t+1} \\;+\\; \\tfrac{1}{2}H\\,k_t^2 \\;+\\; \\tfrac{1}{2}M\\,(\\sigma\\,\\varepsilon_{t+1})^2 \\;+\\; N\\,k_t\\,(\\sigma\\,\\varepsilon_{t+1}),\n$$\nwhere $h$, $r$, $H$, $M$, and $N$ are real-valued coefficients, $\\sigma \\ge 0$ is the shock scale, and $\\varepsilon_{t}$ are independent and identically distributed standard normal shocks with $\\varepsilon_t \\sim \\mathcal{N}(0,1)$.\n\nTwo simulation conventions are to be implemented over a finite horizon of length $T$ with initial condition $k_0 = 0$:\n\n1. Direct iteration of the approximation:\n$$\n\\text{for } t = 0,1,\\dots,T-1:\\quad k_{t+1}^{\\text{dir}} \\;=\\; h\\,k_t^{\\text{dir}} \\;+\\; r\\,\\sigma\\,\\varepsilon_{t+1} \\;+\\; \\tfrac{1}{2}H\\,(k_t^{\\text{dir}})^2 \\;+\\; \\tfrac{1}{2}M\\,(\\sigma\\,\\varepsilon_{t+1})^2 \\;+\\; N\\,k_t^{\\text{dir}}\\,(\\sigma\\,\\varepsilon_{t+1}).\n$$\n\n2. Order-consistent simulation that enforces truncation to second order by separating first-order and second-order components:\n$$\nz_{t+1} \\;=\\; h\\,z_t \\;+\\; r\\,\\sigma\\,\\varepsilon_{t+1},\n$$\n$$\nw_{t+1} \\;=\\; H\\,z_t^2 \\;+\\; M\\,(\\sigma\\,\\varepsilon_{t+1})^2 \\;+\\; 2\\,N\\,z_t\\,(\\sigma\\,\\varepsilon_{t+1}),\n$$\n$$\nk_{t+1}^{\\text{oc}} \\;=\\; z_{t+1} \\;+\\; \\tfrac{1}{2}w_{t+1},\n$$\nwith $z_0 = 0$ and $w_0 = 0$.\n\nFor numerical reproducibility, use a fixed random seed $s = 2025$ for generating the sequence $\\{\\varepsilon_t\\}_{t=1}^T$, and take $\\varepsilon_t$ to be independent and identically distributed draws from the standard normal distribution. Define a numerical bound $B = 10^6$. A simulated path $\\{k_t\\}_{t=0}^T$ is said to be \"divergent\" if it ever attains a non-finite value (not-a-number or infinite) or if $\\max_{0 \\le t \\le T} |k_t|  B$; it is \"bounded\" otherwise.\n\nYour task is to write a program that, for each parameter set in the test suite below, generates the same shock sequence for both simulations and decides whether the direct iteration produces a divergent path while the order-consistent simulation remains bounded. For each parameter set $i$, output the integer $1$ if and only if the direct iteration diverges and the order-consistent simulation remains bounded; otherwise output the integer $0$.\n\nTest suite (each line lists $(h,r,H,M,N,\\sigma,T)$):\n- Case A (general case designed to expose divergence under direct iteration): $(0.95,\\,0.8,\\,1.2,\\,0.8,\\,0.6,\\,0.6,\\,20000)$\n- Case B (boundary case with no stochasticity): $(0.95,\\,0.8,\\,1.2,\\,0.8,\\,0.6,\\,0.0,\\,1000)$\n- Case C (near-linear case with weak nonlinearities): $(0.90,\\,0.3,\\,0.05,\\,0.02,\\,0.01,\\,0.2,\\,5000)$\n\nYour program should produce a single line of output containing the results as a comma-separated list of integers enclosed in square brackets. For example, an output with three cases must look like \"[x1,x2,x3]\" where $x_i \\in \\{0,1\\}$.",
            "solution": "The core of this problem lies in the distinction between two methods for simulating a dynamic system derived from a second-order Taylor approximation. The difference between these methods is not trivial; it concerns the numerical stability and theoretical consistency of the simulation. A rigorous analysis reveals why one method may fail while the other succeeds.\n\nThe model for the state variable $k_t$, representing the deviation of capital from its steady state, is given by the second-order approximation:\n$$\nk_{t+1} = h\\,k_t + r\\,\\sigma\\,\\varepsilon_{t+1} + \\frac{1}{2}H\\,k_t^2 + \\frac{1}{2}M\\,(\\sigma\\,\\varepsilon_{t+1})^2 + N\\,k_t\\,(\\sigma\\,\\varepsilon_{t+1})\n$$\nwhere $k_0 = 0$ and $\\varepsilon_t \\sim \\mathcal{N}(0,1)$.\n\nThe first simulation method, termed \"direct iteration,\" implements this equation recursively:\n$$\nk_{t+1}^{\\text{dir}} = h\\,k_t^{\\text{dir}} + r\\,\\sigma\\,\\varepsilon_{t+1} + \\frac{1}{2}H\\,(k_t^{\\text{dir}})^2 + \\frac{1}{2}M\\,(\\sigma\\,\\varepsilon_{t+1})^2 + N\\,k_t^{\\text{dir}}\\,(\\sigma\\,\\varepsilon_{t+1})\n$$\nThis approach is seemingly straightforward but contains a fundamental flaw. The original approximation is a Taylor series truncated at the second order. This means any terms of third order or higher have been discarded. In the direct iteration, the state variable $k_t^{\\text{dir}}$ itself contains first- and second-order terms accumulated from previous periods. When this variable is squared in the term $\\frac{1}{2}H\\,(k_t^{\\text{dir}})^2$, spurious terms of third and fourth order are generated and fed back into the system. For instance, if one conceptually separates $k_t^{\\text{dir}}$ into its first-order component $k_t^{(1)}$ and second-order component $k_t^{(2)}$, then $(k_t^{\\text{dir}})^2 = (k_t^{(1)} + k_t^{(2)})^2 = (k_t^{(1)})^2 + 2k_t^{(1)}k_t^{(2)} + (k_t^{(2)})^2$. The term $2k_t^{(1)}k_t^{(2)}$ is of third order, and $(k_t^{(2)})^2$ is of fourth order. These terms are inconsistent with the original approximation and can accumulate, leading to explosive, non-stationary behavior that is an artifact of the simulation method, not a property of the model. This instability is most pronounced when the persistence parameter $h$ is close to $1$ and the quadratic feedback coefficient $H$ is large.\n\nThe second method, \"order-consistent simulation\" or \"pruned simulation,\" is designed explicitly to prevent this contamination by higher-order terms. It maintains the integrity of the second-order approximation at each step. This is achieved by separating the evolution of the first-order and second-order components of the solution.\nThe first-order component, $z_t$, follows the linear part of the model:\n$$\nz_{t+1} = h\\,z_t + r\\,\\sigma\\,\\varepsilon_{t+1}\n$$\nThe second-order correction, $w_{t+1}$, is computed using only the first-order state $z_t$ in the nonlinear terms:\n$$\nw_{t+1} = H\\,z_t^2 + M\\,(\\sigma\\,\\varepsilon_{t+1})^2 + 2\\,N\\,z_t\\,(\\sigma\\,\\varepsilon_{t+1})\n$$\nThe full second-order state is then assembled:\n$$\nk_{t+1}^{\\text{oc}} = z_{t+1} + \\frac{1}{2}w_{t+1}\n$$\nBy construction, this procedure ensures that no terms of order higher than two are ever introduced into the dynamics of $k_t^{\\text{oc}}$. The simulation path remains consistent with the underlying Taylor approximation, thereby providing a stable and theoretically correct trajectory, provided the original dynamic system is locally stable.\n\nThe task is to implement both simulation schemes for a given set of parameters $(h, r, H, M, N, \\sigma, T)$, using a fixed random seed $s = 2025$ to generate the same shock sequence $\\{\\varepsilon_t\\}_{t=1}^T$ for both simulations. A path is \"divergent\" if it becomes non-finite or its absolute value exceeds a bound $B = 10^6$. We must identify cases where direct iteration diverges while the order-consistent simulation remains bounded.\n\nThe algorithm proceeds as follows:\n$1$. Initialize the random number generator with the specified seed $s = 2025$.\n$2$. For each parameter set provided in the test suite:\n    a. Extract the parameters $h, r, H, M, N, \\sigma,$ and the horizon $T$.\n    b. Generate a sequence of $T$ standard normal random shocks. This sequence will be used for both simulations to ensure a fair comparison.\n    c. Perform the direct iteration simulation. Initialize $k_0^{\\text{dir}} = 0.0$. For each time step $t$ from $0$ to $T-1$, compute $k_{t+1}^{\\text{dir}}$. After each computation, check if `not isfinite`$(k_{t+1}^{\\text{dir}})$ or if $|k_{t+1}^{\\text{dir}}| > B$. If the condition is met, flag this path as divergent and terminate the simulation for this method.\n    d. Perform the order-consistent simulation. Initialize $z_0 = 0.0$. For each time step $t$ from $0$ to $T-1$, compute $z_{t+1}$, $w_{t+1}$, and subsequently $k_{t+1}^{\\text{oc}}$. Check for divergence using the same criterion as above. If divergence occurs, flag this path as divergent and terminate.\n    e. After both simulations are complete, evaluate the condition: is the direct path flagged as divergent AND the order-consistent path is NOT flagged as divergent? If true, the result for this test case is $1$. Otherwise, it is $0$.\n$3$. Collect the results for all test cases and format them into the specified output string.\nThis procedure will correctly diagnose the numerical instability inherent in the naive direct iteration method versus the robustness of the order-consistent approach.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by simulating two different perturbation methods and comparing their stability.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple contains: (h, r, H, M, N, sigma, T)\n    test_cases = [\n        (0.95, 0.8, 1.2, 0.8, 0.6, 0.6, 20000),  # Case A\n        (0.95, 0.8, 1.2, 0.8, 0.6, 0.0, 1000),   # Case B\n        (0.90, 0.3, 0.05, 0.02, 0.01, 0.2, 5000),  # Case C\n    ]\n\n    # Parameters for simulation.\n    seed = 2025\n    bound = 1e6\n\n    # Initialize the random number generator for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    results = []\n\n    for h, r, H, M, N, sigma, T in test_cases:\n        # Generate the same shock sequence for both simulations for a fair comparison.\n        shocks = rng.standard_normal(T)\n        \n        # --- Simulation 1: Direct Iteration ---\n        direct_diverged = False\n        k_dir = 0.0\n        for t in range(T):\n            eps = shocks[t]\n            sigma_eps = sigma * eps\n            \n            # Direct iteration formula\n            k_dir_next = (h * k_dir + r * sigma_eps +\n                          0.5 * H * k_dir**2 +\n                          0.5 * M * sigma_eps**2 +\n                          N * k_dir * sigma_eps)\n\n            # Check for divergence\n            if not np.isfinite(k_dir_next) or abs(k_dir_next)  bound:\n                direct_diverged = True\n                break\n            \n            k_dir = k_dir_next\n\n        # --- Simulation 2: Order-Consistent Iteration ---\n        oc_diverged = False\n        z = 0.0\n        for t in range(T):\n            eps = shocks[t]\n            sigma_eps = sigma * eps\n            \n            # First-order component\n            z_next = h * z + r * sigma_eps\n            \n            # Second-order correction\n            w_next = H * z**2 + M * sigma_eps**2 + 2 * N * z * sigma_eps\n            \n            # Assembled state\n            k_oc_next = z_next + 0.5 * w_next\n            \n            # Check for divergence\n            if not np.isfinite(k_oc_next) or abs(k_oc_next)  bound:\n                oc_diverged = True\n                break\n            \n            z = z_next\n            \n        # --- Evaluate the condition ---\n        # Output 1 if direct diverges and order-consistent remains bounded; otherwise 0.\n        if direct_diverged and not oc_diverged:\n            results.append(1)\n        else:\n            results.append(0)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}