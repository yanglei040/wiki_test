{
    "hands_on_practices": [
        {
            "introduction": "金融市场是一个复杂的系统，充满了难以捉摸的相互关系。我们如何才能将这些关系的核心结构可视化呢？本练习介绍了一种经典的经济物理学方法。通过将资产收益率的相关系数转化为“距离”，我们可以运用最小生成树（Minimum Spanning Tree, MST）等图论算法，来提取市场中最核心的连接骨架。这项实践将教会你如何将抽象数据转化为一个具体的网络，并分析其在金融危机等重大事件前后如何演变。",
            "id": "2413946",
            "problem": "要求您设计并实现一个程序，该程序根据相关性数据构建股票市场的网络表示，并使用经济学和金融学中网络模型的核心概念来比较崩盘前后的结构。您必须从基本原理出发，避免使用任何临时或未经证实的捷径。仅使用以下事实：对于标准化收益向量，其内积对应于 Pearson 积矩相关系数；以及由内积导出的欧几里得距离构成一个度量。在此基础上，推导一个从相关性到距离的有效变换，该变换在相关性上是严格递减的，且满足度量公理，然后计算由此产生的完全加权图的最小生成树（MST）。\n\n任务细则：\n- 输入是隐式的，以相关性矩阵测试套件的形式在下方给出。每个矩阵 $\\boldsymbol{\\rho} = (\\rho_{ij})$ 都是对称的，且对所有 $i$ 都有 $\\rho_{ii} = 1$，代表在给定时期（市场崩盘前后）资产标准化收益之间的两两 Pearson 积矩相关系数。没有单独的数据输入；您的程序必须嵌入并使用下面提供的矩阵。\n- 步骤 $1$：仅利用以下基本事实：对于中心化、单位方差的向量，其内积等于它们的 Pearson 相关性，且欧几里得范数可导出一个度量。由此推导出一个关于 $\\rho_{ij}$ 的有效函数 $d_{ij}$，该函数在资产集合上产生一个度量距离，并且在 $\\rho_{ij}$ 上是严格递减的。您的程序必须实现您推导出的距离函数。\n- 步骤 $2$：对于每个给定的相关性矩阵，在资产集合上构建一个完全加权图，其中资产 $i$ 和 $j$ 之间的权重等于推导出的距离 $d_{ij}$。计算该图的最小生成树（MST）。可使用任何正确的算法，如 Kruskal 算法或 Prim 算法。为确保在边权重完全相等时结果的确定性，对于无序对 $(i,j)$（其中 $i < j$），按字典序解决平局关系。\n- 步骤 $3$：对测试套件中的每个市场，计算：\n  - MST 总权重，定义为 $n$ 个资产的 MST 中 $n-1$ 条边权重的总和。\n  - MST 的图直径，定义为 MST 中任意两个节点之间最短路径上的最大边数，即所有节点对的未加权最短路径长度的最大值。\n  - 对每个市场，计算崩盘前 MST 和崩盘后 MST 之间的公共边数量，其中边被视为由从零开始的索引组成的无序对 $\\{i,j\\}$。\n- 输出：对于每个市场，输出元组 $[w_{\\text{pre}}, w_{\\text{post}}, c, \\delta_{\\text{pre}}, \\delta_{\\text{post}}]$，其中 $w_{\\text{pre}}$ 和 $w_{\\text{post}}$ 分别是崩盘前后的 MST 总权重，均四舍五入到 $6$ 位小数；$c$ 是公共边的整数数量；$\\delta_{\\text{pre}}$ 和 $\\delta_{\\text{post}}$ 分别是崩盘前后的整数直径。您的程序应生成单行输出，其中包含一个逗号分隔的列表，该列表被方括号括起，按测试套件中给出的顺序汇总所有市场的结果，例如：$[[w_{\\text{pre},1}, w_{\\text{post},1}, c_1, \\delta_{\\text{pre},1}, \\delta_{\\text{post},1}],[w_{\\text{pre},2}, w_{\\text{post},2}, c_2, \\delta_{\\text{pre},2}, \\delta_{\\text{post},2}]]$.\n\n测试套件：\n- 市场 $\\mathcal{A}$（五个资产，索引从 $0$ 到 $4$）：\n  - 崩盘前相关性矩阵 $\\boldsymbol{\\rho}^{\\text{pre}}_{\\mathcal{A}}$：\n  $$\n  \\begin{bmatrix}\n  1 & 0.82 & 0.31 & 0.27 & 0.14 \\\\\n  0.82 & 1 & 0.24 & 0.33 & 0.12 \\\\\n  0.31 & 0.24 & 1 & 0.78 & 0.58 \\\\\n  0.27 & 0.33 & 0.78 & 1 & 0.52 \\\\\n  0.14 & 0.12 & 0.58 & 0.52 & 1\n  \\end{bmatrix}\n  $$\n  - 崩盘后相关性矩阵 $\\boldsymbol{\\rho}^{\\text{post}}_{\\mathcal{A}}$：\n  $$\n  \\begin{bmatrix}\n  1 & 0.88 & 0.72 & 0.62 & 0.40 \\\\\n  0.88 & 1 & 0.64 & 0.71 & 0.42 \\\\\n  0.72 & 0.64 & 1 & 0.85 & 0.70 \\\\\n  0.62 & 0.71 & 0.85 & 1 & 0.68 \\\\\n  0.40 & 0.42 & 0.70 & 0.68 & 1\n  \\end{bmatrix}\n  $$\n- 市场 $\\mathcal{B}$（四个资产，索引从 $0$ 到 $3$）：\n  - 崩盘前相关性矩阵 $\\boldsymbol{\\rho}^{\\text{pre}}_{\\mathcal{B}}$：\n  $$\n  \\begin{bmatrix}\n  1 & 0.60 & -0.20 & 0.10 \\\\\n  0.60 & 1 & 0.05 & -0.25 \\\\\n  -0.20 & 0.05 & 1 & 0.40 \\\\\n  0.10 & -0.25 & 0.40 & 1\n  \\end{bmatrix}\n  $$\n  - 崩盘后相关性矩阵 $\\boldsymbol{\\rho}^{\\text{post}}_{\\mathcal{B}}$：\n  $$\n  \\begin{bmatrix}\n  1 & 0.82 & 0.10 & 0.30 \\\\\n  0.82 & 1 & 0.20 & -0.05 \\\\\n  0.10 & 0.20 & 1 & 0.65 \\\\\n  0.30 & -0.05 & 0.65 & 1\n  \\end{bmatrix}\n  $$\n\n附加要求：\n- 索引是从零开始的整数 $0,1,2,\\dots$。\n- 本问题不涉及物理单位。\n- 将 $w_{\\text{pre}}$ 和 $w_{\\text{post}}$ 四舍五入到恰好 $6$ 位小数。将 $\\delta_{\\text{pre}}$、$\\delta_{\\text{post}}$ 和 $c$ 作为整数报告，无需四舍五入。\n- 您的程序必须是自包含的，并严格按照上述 $[[\\cdot],[\\cdot]]$ 的格式生成单行输出，除逗号和方括号外不含多余的空白字符，也不含任何附加文本。",
            "solution": "我们评估了问题陈述，并确认其有效。该问题在经济物理学领域具有科学依据，论述适定且客观。它呈现了一项标准的、可形式化的任务，该任务基于将网络理论的既定原则应用于金融数据。下面我们进行求解。\n\n解决方案按指定分为三个阶段构建。首先，从相关系数推导出距离度量。其次，详细介绍根据此度量构建最小生成树（MST）的算法。第三，描述计算所需网络属性的步骤。\n\n**步骤 1：距离度量的推导**\n\n问题要求从相关系数 $\\rho_{ij}$ 推导出一个距离函数 $d_{ij}$，该函数需满足度量公理，并且在 $\\rho_{ij}$ 上是严格递减的。推导必须基于两条基本原则：\n$1$. 对于一组资产，在一个内积空间中存在相应的标准化收益向量 $\\mathbf{v}_i$，它们是单位向量，即 $\\|\\mathbf{v}_i\\|^2 = \\langle \\mathbf{v}_i, \\mathbf{v}_i \\rangle = \\rho_{ii} = 1$，且它们的内积是 Pearson 相关系数，即 $\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle = \\rho_{ij}$。\n$2$. 由内积导出的欧几里得距离 $d(\\mathbf{v}_i, \\mathbf{v}_j) = \\|\\mathbf{v}_i - \\mathbf{v}_j\\|$ 是一个有效的度量。\n\n我们从展开两个此类向量 $\\mathbf{v}_i$ 和 $\\mathbf{v}_j$ 之间的欧几里得距离的平方开始：\n$$\nd(\\mathbf{v}_i, \\mathbf{v}_j)^2 = \\|\\mathbf{v}_i - \\mathbf{v}_j\\|^2\n$$\n根据由内积导出的范数的定义：\n$$\n\\|\\mathbf{v}_i - \\mathbf{v}_j\\|^2 = \\langle \\mathbf{v}_i - \\mathbf{v}_j, \\mathbf{v}_i - \\mathbf{v}_j \\rangle\n$$\n利用内积的双线性性质，上式可展开为：\n$$\n\\langle \\mathbf{v}_i, \\mathbf{v}_i \\rangle - 2\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle + \\langle \\mathbf{v}_j, \\mathbf{v}_j \\rangle\n$$\n代入前提条件 $\\|\\mathbf{v}_i\\|^2 = 1$ 和 $\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle = \\rho_{ij}$：\n$$\nd(\\mathbf{v}_i, \\mathbf{v}_j)^2 = 1 - 2\\rho_{ij} + 1 = 2(1 - \\rho_{ij})\n$$\n取平方根，得到作为 $\\rho_{ij}$ 函数的距离函数 $d_{ij}$：\n$$\nd_{ij} = \\sqrt{2(1 - \\rho_{ij})}\n$$\n我们必须验证该函数 $d_{ij}$ 是一个度量，并且在 $\\rho_{ij}$ 上是严格递减的。\n\n度量公理的验证：\n- **非负性**：由于 $\\rho_{ij} \\in [-1, 1]$，项 $1 - \\rho_{ij}$ 的范围是 $[0, 2]$。因此，$d_{ij}$ 是实数且非负。$d_{ij} \\ge 0$。\n- **不可分者同一性**：$d_{ij} = 0 \\iff 2(1 - \\rho_{ij}) = 0 \\iff \\rho_{ij} = 1$。这对应于完全相关的资产，在此向量表示中意味着 $\\mathbf{v}_i = \\mathbf{v}_j$。对于 $i \\neq j$，我们假设 $\\rho_{ij} < 1$，因此 $d_{ij} > 0$。此外，$d_{ii} = \\sqrt{2(1 - \\rho_{ii})} = \\sqrt{2(1 - 1)} = 0$。\n- **对称性**：相关性矩阵是对称的，即 $\\rho_{ij} = \\rho_{ji}$。因此，$d_{ij} = \\sqrt{2(1 - \\rho_{ij})} = \\sqrt{2(1 - \\rho_{ji})} = d_{ji}$。\n- **三角不等式**：$d_{ik} \\le d_{ij} + d_{jk}$。这个不等式成立，因为 $d_{ij}$ 正是欧几里得空间中向量之间的欧几里得距离，而三角不等式是欧几里得空间的一个基本性质。\n\n单调性验证：\n为确认 $d_{ij}$ 在 $\\rho_{ij}$ 上是严格递减的，我们考察它对 $\\rho$ 的一阶导数：\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}\\rho} \\left( \\sqrt{2(1 - \\rho)} \\right) = -\\frac{1}{\\sqrt{2(1 - \\rho)}}\n$$\n对于 $\\rho < 1$，分母是实数且为正，因此导数严格为负。这证实了所推导的距离 $d_{ij}$ 是相关性 $\\rho_{ij}$ 的一个严格递减函数。因此，函数 $d_{ij} = \\sqrt{2(1 - \\rho_{ij})}$ 是应当使用的正确度量。\n\n**步骤 2：最小生成树的构建**\n\n对于每个相关性矩阵 $\\boldsymbol{\\rho}$，我们构建一个完全加权图 $G = (V, E)$，其中顶点集合 $V$ 代表资产，任意两个顶点 $i$ 和 $j$ 之间边的权重由距离 $d_{ij}$ 给出。该图的最小生成树（MST）是一个子图，它以可能的最小边权重总和连接所有顶点，且不包含任何环。\n\n我们将使用 Kruskal 算法来计算 MST。该算法操作如下：\n$1$. 创建一个包含完全图中所有边的列表，每条边表示为元组 $(w, u, v)$，其中 $w$是权重 $d_{uv}$，$u, v$ 是顶点索引，且 $u < v$。对于一个有 $n$ 个资产的图，共有 $\\binom{n}{2} = \\frac{n(n-1)}{2}$ 条这样的边。\n$2$. 按权重升序对此边列表进行排序。为确保确定性，权重相同时，按顶点对 $(u,v)$ 的字典序解决平局关系。对于两条权重相同的边，字典序较小的顶点对 $(u,v)$ 对应的边被优先选择。\n$3$. 初始化一个并查集（DSU）数据结构，每个顶点初始时各自属于一个集合。\n$4$. 遍历排序后的边列表。对于每条边 $(w, u, v)$：\n    - 使用 DSU 的 `find` 操作检查顶点 $u$ 和 $v$ 是否属于同一个集合。\n    - 如果它们不属于同一个集合，则该边不会形成环。将此边添加到 MST 中，并使用 DSU 的 `union` 操作合并包含 $u$ 和 $v$ 的集合。\n$5$. 当 MST 中已添加 $n-1$ 条边时，算法终止。\n\n**步骤 3：网络属性的计算**\n\n在为每个市场的崩盘前和崩盘后两种状况构建了 MST 之后，我们计算以下属性：\n\n- **MST 总权重 ($w$)：** 这是 MST 中所有边权重的总和。对于一个边集为 $E_{\\text{MST}}$ 的 MST，总权重为 $w = \\sum_{\\{i,j\\} \\in E_{\\text{MST}}} d_{ij}$。此值需为崩盘前（$w_{\\text{pre}}$）和崩盘后（$w_{\\text{post}}$）的 MST 分别计算，并四舍五入到 $6$ 位小数。\n\n- **MST 直径 ($\\delta$)：** 树的直径是其任意两个节点之间最长最短路径的长度。路径长度以边数（未加权）计算。我们使用以下标准的两遍式算法计算它：\n    $1$. 构建 MST 的邻接表表示。\n    $2$. 从任意节点 $s$ 开始执行一次广度优先搜索（BFS），找到离它最远的节点 $u$。\n    $3$. 从节点 $u$ 开始执行第二次 BFS，找到离它最远的节点 $v$。从 $u$到 $v$ 的距离即为树的直径。\n    此值需为崩盘前（$\\delta_{\\text{pre}}$）和崩盘后（$\\delta_{\\text{post}}$）的 MST 分别计算。\n\n- **公共边数量 ($c$)：** 这是一个整数值，表示崩盘前 MST 和崩盘后 MST 边集的交集大小。边被视为由从零开始的索引组成的无序对 $\\{i, j\\}$。通过将每条边规范地表示为元组 $(i, j)$（其中 $i < j$），我们可以找到两个 MST 边集的交集。\n\n将这些步骤系统地应用于测试套件中为每个市场提供的数据，以生成最终输出。",
            "answer": "```python\nimport numpy as np\nimport math\n\n# No other libraries are permitted as per instructions.\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    It processes each market's pre- and post-crash correlation matrices,\n    computes the required metrics, and prints the formatted result.\n    \"\"\"\n\n    class DSU:\n        \"\"\"A simple Disjoint Set Union data structure for Kruskal's algorithm.\"\"\"\n        def __init__(self, n):\n            self.parent = list(range(n))\n            self.num_sets = n\n\n        def find(self, i):\n            \"\"\"Find the representative of the set containing element i with path compression.\"\"\"\n            if self.parent[i] == i:\n                return i\n            self.parent[i] = self.find(self.parent[i])\n            return self.parent[i]\n\n        def union(self, i, j):\n            \"\"\"Merge the sets containing elements i and j.\"\"\"\n            root_i = self.find(i)\n            root_j = self.find(j)\n            if root_i != root_j:\n                self.parent[root_i] = root_j\n                self.num_sets -= 1\n                return True\n            return False\n\n    def get_mst_diameter(n, mst_edges):\n        \"\"\"\n        Computes the diameter of a tree (given as an MST edge list).\n        The diameter is the longest shortest path between any two nodes.\n        Path length is the number of edges.\n        \"\"\"\n        if n <= 1:\n            return 0\n        \n        adj = [[] for _ in range(n)]\n        for u, v in mst_edges:\n            adj[u].append(v)\n            adj[v].append(u)\n\n        def bfs(start_node):\n            \"\"\"Performs a BFS to find the farthest node and distance from a start node.\"\"\"\n            distances = [-1] * n\n            queue = [(start_node, 0)]\n            distances[start_node] = 0\n            \n            head = 0\n            farthest_node = start_node\n            max_dist = 0\n\n            while head < len(queue):\n                u, dist = queue[head]\n                head += 1\n\n                if dist > max_dist:\n                    max_dist = dist\n                    farthest_node = u\n\n                for v in adj[u]:\n                    if distances[v] == -1:\n                        distances[v] = dist + 1\n                        queue.append((v, dist + 1))\n            \n            return farthest_node, max_dist\n\n        # 1. First BFS from an arbitrary node (0) to find one endpoint of a diameter.\n        node_u, _ = bfs(0)\n        # 2. Second BFS from that endpoint to find the actual diameter.\n        _, diameter = bfs(node_u)\n        \n        return diameter\n\n    def process_correlation_matrix(rho_matrix):\n        \"\"\"\n        Takes a correlation matrix and returns MST properties:\n        total weight, diameter, and the set of edges.\n        \"\"\"\n        n = rho_matrix.shape[0]\n        \n        # Step 1: Derive distance and create a list of edges with weights.\n        # d_ij = sqrt(2 * (1 - rho_ij))\n        # The tie-breaking is handled by sorting on (weight, u, v).\n        edges = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                rho_ij = rho_matrix[i, j]\n                # Defensive check for floating point inaccuracies leading to rho > 1\n                if rho_ij > 1.0:\n                    rho_ij = 1.0\n                dist = math.sqrt(2.0 * (1.0 - rho_ij))\n                edges.append((dist, i, j))\n        \n        # Sort edges: primary key is weight, secondary keys are i then j.\n        edges.sort()\n\n        # Step 2: Compute MST using Kruskal's algorithm.\n        dsu = DSU(n)\n        mst_edges = []\n        mst_weight = 0.0\n        \n        for dist, u, v in edges:\n            if dsu.union(u, v):\n                mst_edges.append((u, v))\n                mst_weight += dist\n                if len(mst_edges) == n - 1:\n                    break\n        \n        # Step 3: Compute MST diameter.\n        mst_diameter = get_mst_diameter(n, mst_edges)\n        \n        # Return canonical representation of edges (sorted tuples) for comparison\n        mst_edge_set = {tuple(sorted(edge)) for edge in mst_edges}\n\n        return mst_weight, mst_diameter, mst_edge_set\n\n    # Test suite provided in the problem description.\n    test_cases = [\n        # Market A\n        {\n            \"name\": \"Market A\",\n            \"pre\": np.array([\n                [1.00, 0.82, 0.31, 0.27, 0.14],\n                [0.82, 1.00, 0.24, 0.33, 0.12],\n                [0.31, 0.24, 1.00, 0.78, 0.58],\n                [0.27, 0.33, 0.78, 1.00, 0.52],\n                [0.14, 0.12, 0.58, 0.52, 1.00]\n            ]),\n            \"post\": np.array([\n                [1.00, 0.88, 0.72, 0.62, 0.40],\n                [0.88, 1.00, 0.64, 0.71, 0.42],\n                [0.72, 0.64, 1.00, 0.85, 0.70],\n                [0.62, 0.71, 0.85, 1.00, 0.68],\n                [0.40, 0.42, 0.70, 0.68, 1.00]\n            ])\n        },\n        # Market B\n        {\n            \"name\": \"Market B\",\n            \"pre\": np.array([\n                [1.00, 0.60, -0.20, 0.10],\n                [0.60, 1.00, 0.05, -0.25],\n                [-0.20, 0.05, 1.00, 0.40],\n                [0.10, -0.25, 0.40, 1.00]\n            ]),\n            \"post\": np.array([\n                [1.00, 0.82, 0.10, 0.30],\n                [0.82, 1.00, 0.20, -0.05],\n                [0.10, 0.20, 1.00, 0.65],\n                [0.30, -0.05, 0.65, 1.00]\n            ])\n        }\n    ]\n\n    result_strings = []\n    \n    for market_data in test_cases:\n        w_pre, d_pre, edges_pre = process_correlation_matrix(market_data[\"pre\"])\n        w_post, d_post, edges_post = process_correlation_matrix(market_data[\"post\"])\n        \n        # Calculate number of common edges\n        common_edges_count = len(edges_pre.intersection(edges_post))\n        \n        # Format the result tuple for this market\n        w_pre_str = f\"{w_pre:.6f}\"\n        w_post_str = f\"{w_post:.6f}\"\n        \n        market_result_str = (\n            f\"[{w_pre_str},{w_post_str},{common_edges_count},\"\n            f\"{d_pre},{d_post}]\"\n        )\n        result_strings.append(market_result_str)\n\n    # Print the final output in the exact required format\n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "金融系统的相互关联性既是效率的源泉，也可能成为脆弱性的根源。我们如何识别出系统中的关键节点，并评估整个系统抵御冲击的能力？本练习引入了一个动态的网络压力测试流程。你将通过计算节点的PageRank中心性来衡量其“重要性”，然后依次移除最重要的节点，并观察此举对网络整体完整性的影响。这项模拟将让你对系统性风险有更深刻的理解，学会如何量化网络节点的重要性，并直观地看到少数关键参与者的失败如何引发多米诺骨牌式的连锁崩溃——这对于金融监管者和风险管理者而言是至关重要的概念。",
            "id": "2413880",
            "problem": "考虑一个有向加权金融网络，由一个邻接矩阵 $W \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$ 表示，其元素为 $W_{ij}$，其中 $W_{ij}$ 表示从节点 $i$ 到节点 $j$ 的非负风险敞口权重。设步骤 $t$ 的活跃节点集合为 $V_t \\subseteq \\{0,1,\\dots,n-1\\}$，且 $|V_t| = m_t$。对于任何活跃集 $V_t$，定义行随机转移矩阵 $P^{(t)} \\in \\mathbb{R}^{m_t \\times m_t}$ 如下：\n- 对于每个活跃节点 $i \\in V_t$，令 $s_i^{(t)} = \\sum_{j \\in V_t} W_{ij}$，\n- 若 $s_i^{(t)} > 0$，则对 $j \\in V_t$ 设 $P_{ij}^{(t)} = W_{ij} / s_i^{(t)}$，\n- 若 $s_i^{(t)} = 0$（一个悬挂节点），则对所有 $j \\in V_t$ 设 $P_{ij}^{(t)} = 1/m_t$。\n\n固定一个阻尼因子 $d \\in (0,1)$。步骤 $t$ 的 PageRank 向量 $\\pi^{(t)} \\in \\mathbb{R}^{m_t}$ 定义为以下方程的唯一解：\n$$\n\\pi^{(t)} = (1-d)\\frac{\\mathbf{1}}{m_t} + d \\left(P^{(t)}\\right)^\\top \\pi^{(t)},\n$$\n满足归一化条件 $\\sum_{i \\in V_t} \\pi^{(t)}_i = 1$，且对所有 $i \\in V_t$ 都有 $\\pi^{(t)}_i \\ge 0$。\n\n定义一个压力测试序列如下。初始化 $V_0 = \\{0,1,\\dots,n-1\\}$。在每个步骤 $t \\in \\{0,1,2,\\dots\\}$：\n1. 在由 $V_t$ 诱导的子网络上计算 $\\pi^{(t)}$。\n2. 选择 $v_t \\in \\arg\\max_{i \\in V_t} \\pi^{(t)}_i$；通过选择 $\\{0,1,\\dots,n-1\\}$ 中最小的索引来打破平局。\n3. 移除选定的节点：$V_{t+1} = V_t \\setminus \\{v_t\\}$。\n\n对于任何活跃集 $V_t$，通过在 $i$ 和 $j$ 之间放置一条无向边（如果 $W_{ij} > 0$ 或 $W_{ji} > 0$ 且 $i,j \\in V_t$）来定义诱导子图的无向版本。设 $C^{(t)}$ 为此无向子图的最大弱连通分量的大小（节点数），其中孤立节点计为大小为 $1$ 的分量，空图的分量大小为 $0$。\n\n给定一个初始网络 $(W, n)$、一个阻尼因子 $d \\in (0,1)$ 和一个阈值 $\\theta \\in (0,1]$，定义失效时间\n$$\nk^\\star = \\min \\left\\{ t \\in \\{0,1,\\dots,n\\} \\,:\\, C^{(t)} \\le \\theta \\cdot n \\right\\}。\n$$\n如果初始网络已经满足 $C^{(0)} \\le \\theta \\cdot n$，则 $k^\\star = 0$。每个测试用例所需的输出是整数 $k^\\star$。\n\n您的任务是编写一个程序，为下面的每个测试用例，根据上述定义计算相应的整数 $k^\\star$。PageRank 中心性必须在每一步对当前的活跃集 $V_t$ 重新计算。最大化集合中的平局必须通过选择在 $\\{0,1,\\dots,n-1\\}$ 中具有最小原始索引的节点来解决。\n\n测试套件（每个用例指定 $n$、权重为单位值的非零边、$d$ 阻尼因子和 $\\theta$ 阈值）：\n- 用例 A:\n  - $n = 4$,\n  - 权重为单位值的非零有向边：$(1,0)$, $(2,0)$, $(3,0)$，所有其他项为 $0$，\n  - $d = 0.85$,\n  - $\\theta = 0.5$。\n- 用例 B:\n  - $n = 5$,\n  - 权重为单位值的有向环：$(0,1)$, $(1,2)$, $(2,3)$, $(3,4)$, $(4,0)$，\n  - $d = 0.85$,\n  - $\\theta = 0.6$。\n- 用例 C:\n  - $n = 6$,\n  - 完整的有向网络，所有有序对 $(i,j)$（其中 $i \\ne j$）上的权重为单位值，对角线上为零，\n  - $d = 0.9$,\n  - $\\theta = 0.5$。\n- 用例 D:\n  - $n = 5$,\n  - 两个弱连通分量，权重为单位值：$(0,1)$, $(1,0)$, $(2,3)$, $(3,4)$，所有其他项为 $0$，\n  - $d = 0.85$,\n  - $\\theta = 0.8$。\n\n最终输出格式：您的程序应生成单行输出，包含四个整数 $[k_A,k_B,k_C,k_D]$ 的结果，按用例 A、B、C、D 的顺序排列，并用方括号括起来的逗号分隔列表，例如 $[1,2,3,4]$。不应打印任何附加文本。",
            "solution": "该问题陈述已经过验证，被认为是科学上合理、定义明确、客观且计算上可行的。它描述了一个有向网络上的离散时间节点移除过程，其中每一步被选择移除的节点由其 PageRank 中心性确定。当网络的结构完整性（以其最大弱连通分量的大小衡量）低于指定阈值时，该过程终止。\n\n解决方案是对该压力测试序列的直接模拟。该模拟从步骤 $t=0$ 开始迭代进行，最多到 $t=n$。在每一步 $t$，网络的状态由活跃节点集合 $V_t$ 定义。执行以下计算序列。\n\n首先，评估主要终止准则。这需要计算 $C^{(t)}$，即由活跃节点 $V_t$ 诱导的子图的最大弱连通分量的大小。概念上，从活跃节点构建一个无向图，其中如果原始权重矩阵 $W$ 满足 $W_{ij} > 0$ 或 $W_{ji} > 0$，则在节点 $i, j \\in V_t$ 之间存在一条边。使用标准的图遍历算法（如广度优先搜索 (BFS) 或深度优先搜索 (DFS)）找到该无向图的连通分量的大小。这些大小的最大值即为 $C^{(t)}$。如果 $C^{(t)} \\le \\theta \\cdot n$，则过程终止，失效时间为 $k^\\star = t$。\n\n如果未满足终止条件，模拟将继续确定下一个要移除的节点。这需要计算由 $V_t$ 诱导的子网络的 PageRank 向量 $\\pi^{(t)}$。设 $m_t = |V_t|$ 为活跃节点的数量。根据提供的规则构建行随机转移矩阵 $P^{(t)} \\in \\mathbb{R}^{m_t \\times m_t}$。对于一个节点 $i \\in V_t$，如果它有指向 $V_t$ 中其他节点的出向链接，则其在 $P^{(t)}$ 中对应的行通过其出强度 $s_i^{(t)} = \\sum_{j \\in V_t} W_{ij}$ 进行归一化。对于一个悬挂节点（$s_i^{(t)}=0$），对应的行是一个均匀分布，$P_{ij}^{(t)} = 1/m_t$ 对所有 $j \\in V_t$ 成立。\n\nPageRank 向量 $\\pi^{(t)}$ 是以下线性系统的解：\n$$\n\\left(I - d \\left(P^{(t)}\\right)^\\top\\right) \\pi^{(t)} = (1-d)\\frac{\\mathbf{1}}{m_t}\n$$\n其中 $I$ 是 $m_t \\times m_t$ 的单位矩阵，$d \\in (0,1)$ 是阻尼因子，$\\mathbf{1}$ 是一个全为一的向量。该系统是非奇异的，并且对 $\\pi^{(t)}$ 有一个唯一的非负解，可以使用标准的线性方程求解器进行数值求解。\n\n接下来，选择要移除的节点 $v_t$。$v_t$ 是 $V_t$ 中具有最高 PageRank 分数的节点。形式上，$v_t$ 从集合 $\\arg\\max_{i \\in V_t} \\pi^{(t)}_i$ 中选择。如果多个节点共享最高的 PageRank 分数，则通过从集合 $\\{0, 1, \\dots, n-1\\}$ 中选择具有最小原始索引的节点来打破平局。\n\n最后，通过移除选定的节点来更新下一步的活跃节点集：$V_{t+1} = V_t \\setminus \\{v_t\\}$。然后模拟进入步骤 $t+1$。对每个测试用例重复这整个过程，直到确定相应的 $k^\\star$。",
            "answer": "```python\nimport numpy as np\n\ndef get_largest_wcc_size(W, active_nodes):\n    \"\"\"\n    Computes the size of the largest weakly connected component (WCC).\n    An undirected graph is formed on the active_nodes, with an edge (i, j)\n    if W[i,j] > 0 or W[j,i] > 0.\n    \"\"\"\n    m = len(active_nodes)\n    if m == 0:\n        return 0\n\n    # Map from original node index to its index in the active_nodes list (0 to m-1)\n    node_to_idx = {node: i for i, node in enumerate(active_nodes)}\n    \n    # Adjacency list for the undirected version of the subgraph\n    adj = [[] for _ in range(m)]\n    has_edges = False\n    for i in range(m):\n        for j in range(i + 1, m):\n            u, v = active_nodes[i], active_nodes[j]\n            if W[u, v] > 0 or W[v, u] > 0:\n                adj[i].append(j)\n                adj[j].append(i)\n                has_edges = True\n\n    # If no edges, all nodes are isolated components of size 1\n    if not has_edges:\n        return 1\n\n    visited = [False] * m\n    max_size = 0\n    for i in range(m):\n        if not visited[i]:\n            current_size = 0\n            q = [i]\n            visited[i] = True\n            head = 0\n            while head < len(q):\n                u_idx = q[head]\n                head += 1\n                current_size += 1\n                for v_idx in adj[u_idx]:\n                    if not visited[v_idx]:\n                        visited[v_idx] = True\n                        q.append(v_idx)\n            max_size = max(max_size, current_size)\n    return max_size\n\ndef compute_pagerank(W_full, active_nodes, d):\n    \"\"\"\n    Computes the PageRank vector for the subgraph induced by active_nodes.\n    \"\"\"\n    m = len(active_nodes)\n    if m == 0:\n        return np.array([])\n\n    # Create the submatrix of W corresponding to active nodes\n    W_sub = W_full[np.ix_(active_nodes, active_nodes)]\n    \n    # Calculate row sums for normalization\n    row_sums = W_sub.sum(axis=1)\n    \n    P = np.zeros((m, m))\n    \n    # Handle non-dangling nodes\n    non_dangling_mask = row_sums > 0\n    if np.any(non_dangling_mask):\n      P[non_dangling_mask] = W_sub[non_dangling_mask] / row_sums[non_dangling_mask, np.newaxis]\n\n    # Handle dangling nodes\n    dangling_mask = ~non_dangling_mask\n    if np.any(dangling_mask):\n        P[dangling_mask] = 1.0 / m\n        \n    # Solve the linear system (I - d*P^T) * pi = (1-d)/m * 1\n    I = np.identity(m)\n    A = I - d * P.T\n    b = (1.0 - d) / m * np.ones(m)\n    \n    pi = np.linalg.solve(A, b)\n    return pi\n\ndef solve_case(n, W, d, theta):\n    \"\"\"\n    Runs the stress-testing simulation for a single test case.\n    \"\"\"\n    active_nodes = list(range(n))\n    threshold_size = theta * n\n    \n    for t in range(n + 1):\n        # 1. Compute largest WCC size C^(t)\n        C_t = get_largest_wcc_size(W, active_nodes)\n        \n        # 2. Check failure condition\n        if C_t <= threshold_size:\n            return t\n        \n        # 3. Compute PageRank\n        pi = compute_pagerank(W, active_nodes, d)\n        \n        # 4. Select node to remove\n        max_pi = -1.0\n        # Find the maximum PageRank value\n        if pi.size > 0:\n            max_pi = np.max(pi)\n\n        # Find all nodes that achieve this maximum value\n        candidates = []\n        for i, p_val in enumerate(pi):\n            if np.isclose(p_val, max_pi):\n                candidates.append(active_nodes[i])\n        \n        # Tie-break by choosing the smallest original index\n        node_to_remove = min(candidates)\n        \n        # 5. Update active set\n        active_nodes.remove(node_to_remove)\n    \n    # This part should not be reached given the problem constraints\n    # C^{(n)} = 0, so the loop will always find a k* <= n.\n    return n\n\ndef solve():\n    \"\"\"\n    Defines test cases and computes the failure time k* for each.\n    \"\"\"\n    # Case A\n    n_A = 4\n    W_A = np.zeros((n_A, n_A))\n    W_A[1, 0] = 1\n    W_A[2, 0] = 1\n    W_A[3, 0] = 1\n    d_A = 0.85\n    theta_A = 0.5\n    \n    # Case B\n    n_B = 5\n    W_B = np.zeros((n_B, n_B))\n    edges_B = [(0, 1), (1, 2), (2, 3), (3, 4), (4, 0)]\n    for i, j in edges_B:\n        W_B[i, j] = 1\n    d_B = 0.85\n    theta_B = 0.6\n    \n    # Case C\n    n_C = 6\n    W_C = np.ones((n_C, n_C)) - np.identity(n_C)\n    d_C = 0.9\n    theta_C = 0.5\n    \n    # Case D\n    n_D = 5\n    W_D = np.zeros((n_D, n_D))\n    edges_D = [(0, 1), (1, 0), (2, 3), (3, 4)]\n    for i, j in edges_D:\n        W_D[i, j] = 1\n    d_D = 0.85\n    theta_D = 0.8\n\n    test_cases = [\n        (n_A, W_A, d_A, theta_A),\n        (n_B, W_B, d_B, theta_B),\n        (n_C, W_C, d_C, theta_C),\n        (n_D, W_D, d_D, theta_D),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, W, d, theta = case\n        k_star = solve_case(n, W, d, theta)\n        results.append(k_star)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}