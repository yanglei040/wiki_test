{
    "hands_on_practices": [
        {
            "introduction": "To begin, we'll tackle a cornerstone of evolutionary game theory: the Hawk-Dove game. This exercise is fundamental because it guides you through the entire analytical process, from defining fitness based on a payoff matrix to deriving the governing differential equation. By solving this problem, you will not only find the mixed-strategy equilibrium but also determine its stability, providing a complete picture of the population's evolutionary trajectory. Mastering this analysis  is the first essential step toward understanding more complex dynamic systems.",
            "id": "2710640",
            "problem": "Consider an infinite, well-mixed population engaging in pairwise interactions described by the Hawk–Dove game with the symmetric payoff matrix\n$$\nA \\;=\\; \\begin{pmatrix}\n\\frac{V - C}{2} & V \\\\\n0 & \\frac{V}{2}\n\\end{pmatrix},\n$$\nwhere $V>0$ denotes the benefit of the contested resource and $C>0$ denotes the cost of escalation. Let $p \\in [0,1]$ denote the frequency of Hawks in the population and $1-p$ the frequency of Doves. Assume selection dynamics follow the continuous-time replicator equation derived from the definition that a type’s growth rate equals its excess fitness relative to the population mean.\n\nUsing first principles of evolutionary game dynamics, do the following:\n- Derive the one-dimensional ordinary differential equation (ODE) governing the time evolution of $p$ under replicator dynamics.\n- From this, determine the mixed-strategy equilibrium frequency $p^{\\ast}$ of Hawks that lies strictly between $0$ and $1$ (if it exists), expressed in terms of $V$ and $C$.\n- Linearize the replicator dynamics about $p^{\\ast}$ and compute the eigenvalue of the Jacobian of the scalar flow at $p^{\\ast}$ in closed form. Using its sign, determine the local stability of $p^{\\ast}$ when $V<C$.\n\nReport your final answer as a row vector $(p^{\\ast}, \\lambda^{\\ast})$, where $\\lambda^{\\ast}$ is the eigenvalue of the Jacobian of the scalar replicator dynamics at $p^{\\ast}$. No numerical approximation or rounding is required, and no units should be reported in the final answer.",
            "solution": "The problem will first be validated for scientific soundness, consistency, and completeness before any attempt at a solution is made.\n\n### Step 1: Extract Givens\n- **Population Model**: Infinite, well-mixed population.\n- **Interaction Type**: Pairwise interactions.\n- **Game**: Hawk–Dove game.\n- **Payoff Matrix**: $A = \\begin{pmatrix} \\frac{V - C}{2} & V \\\\ 0 & \\frac{V}{2} \\end{pmatrix}$.\n- **Parameters**: $V>0$ (benefit of resource), $C>0$ (cost of escalation).\n- **State Variable**: $p \\in [0,1]$ is the frequency of Hawks; $1-p$ is the frequency of Doves.\n- **Selection Dynamics**: Continuous-time replicator equation, where a type's growth rate equals its excess fitness relative to the mean.\n- **Tasks**:\n    1.  Derive the one-dimensional ordinary differential equation for $p$.\n    2.  Determine the mixed-strategy equilibrium frequency $p^{\\ast} \\in (0,1)$.\n    3.  Linearize dynamics about $p^{\\ast}$, find the eigenvalue $\\lambda^{\\ast}$ of the Jacobian.\n    4.  Determine the local stability of $p^{\\ast}$ for $V<C$.\n- **Final Answer Format**: A row vector $(p^{\\ast}, \\lambda^{\\ast})$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the established criteria.\n- **Scientific Groundedness**: The problem is a canonical example from evolutionary game theory. The Hawk-Dove game, the given payoff matrix structure, and the replicator equation are standard, foundational concepts in this field. The setup is scientifically rigorous and factually sound.\n- **Well-Posedness**: The problem is mathematically well-defined. It provides all necessary information (payoff matrix, parameters, dynamic equation form) to derive a unique analytical solution for the requested quantities. The tasks follow a logical progression from model formulation to stability analysis.\n- **Objectivity**: The problem is stated in precise, objective mathematical language, free of any subjectivity, ambiguity, or opinion.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is a standard, well-posed problem in mathematical biology that is scientifically sound and objective. I will now proceed with the full derivation and solution.\n\nThe continuous-time replicator equation is derived from the principle that the per-capita growth rate of a strategy is equal to the difference between its fitness and the average fitness of the population. Let $p$ be the frequency of Hawks. The rate of change of $p$ is given by $\\frac{dp}{dt}$. The per-capita rate of change is $\\frac{1}{p}\\frac{dp}{dt}$.\n\nLet $f_H$ and $f_D$ be the expected fitness (payoffs) of a Hawk and a Dove, respectively. A Hawk interacts with another Hawk with probability $p$ and a Dove with probability $1-p$. Similarly for a Dove. The fitness functions are:\n$$f_H(p) = p \\cdot A_{11} + (1-p) \\cdot A_{12} = p\\left(\\frac{V - C}{2}\\right) + (1-p)V$$\n$$f_D(p) = p \\cdot A_{21} + (1-p) \\cdot A_{22} = p(0) + (1-p)\\left(\\frac{V}{2}\\right) = (1-p)\\frac{V}{2}$$\n\nThe mean fitness of the population, $\\bar{f}$, is the weighted average of the individual fitness values:\n$$\\bar{f}(p) = p \\cdot f_H(p) + (1-p) \\cdot f_D(p)$$\n\nAccording to the problem definition, the replicator dynamics for the Hawk frequency $p$ is:\n$$\\frac{1}{p}\\frac{dp}{dt} = f_H(p) - \\bar{f}(p)$$\n$$\\frac{dp}{dt} = p(f_H(p) - \\bar{f}(p))$$\nSubstituting the expression for $\\bar{f}(p)$:\n$$\\frac{dp}{dt} = p(f_H(p) - [p \\cdot f_H(p) + (1-p) \\cdot f_D(p)])$$\n$$\\frac{dp}{dt} = p((1-p)f_H(p) - (1-p)f_D(p))$$\n$$\\frac{dp}{dt} = p(1-p)(f_H(p) - f_D(p))$$\nThis is the general form of the one-dimensional replicator equation.\n\nTo complete the first task, we must compute the difference in fitness, $f_H(p) - f_D(p)$:\n$$f_H(p) - f_D(p) = \\left[p\\left(\\frac{V - C}{2}\\right) + (1-p)V\\right] - \\left[(1-p)\\frac{V}{2}\\right]$$\n$$= p\\frac{V}{2} - p\\frac{C}{2} + V - pV - \\frac{V}{2} + p\\frac{V}{2}$$\n$$= \\left(p\\frac{V}{2} - pV + p\\frac{V}{2}\\right) - p\\frac{C}{2} + \\left(V - \\frac{V}{2}\\right)$$\n$$= (pV - pV) - p\\frac{C}{2} + \\frac{V}{2}$$\n$$= \\frac{V}{2} - p\\frac{C}{2} = \\frac{1}{2}(V - pC)$$\nSubstituting this into the replicator equation gives the specific ordinary differential equation for $p(t)$:\n$$\\frac{dp}{dt} = p(1-p)\\frac{1}{2}(V - pC)$$\n\nThe second task is to find the mixed-strategy equilibrium $p^{\\ast}$ strictly between $0$ and $1$. Equilibria, or fixed points, are found by setting $\\frac{dp}{dt} = 0$.\n$$p(1-p)\\frac{1}{2}(V - pC) = 0$$\nThis equation has three solutions for $p$:\n$1$. $p=0$ (pure Dove population)\n$2$. $p=1$ (pure Hawk population)\n$3$. $V - pC = 0 \\implies p = \\frac{V}{C}$ (mixed population)\nThe problem asks for the internal equilibrium $p^{\\ast} \\in (0,1)$. This corresponds to the third solution.\n$$p^{\\ast} = \\frac{V}{C}$$\nThis equilibrium exists in the interval $(0,1)$ if and only if $0 < V < C$, which is consistent with the condition given for the final part of the problem.\n\nThe third task is to linearize the dynamics around $p^{\\ast}$ and find the eigenvalue of the Jacobian. Let $F(p) = \\frac{dp}{dt} = p(1-p)\\frac{1}{2}(V-pC)$. The Jacobian of this scalar flow is its derivative, $J(p) = \\frac{dF}{dp}$. The eigenvalue at the equilibrium $p^{\\ast}$ is $\\lambda^{\\ast} = \\frac{dF}{dp}|_{p=p^{\\ast}}$.\n\nA general property of the replicator equation at an internal fixed point $p^{\\ast}$ is that $f_H(p^{\\ast}) = f_D(p^{\\ast})$. The derivative of $F(p) = p(1-p)(f_H(p)-f_D(p))$ at such a point simplifies. Let $g(p) = f_H(p)-f_D(p)$. Then $F(p) = p(1-p)g(p)$, and $g(p^{\\ast})=0$.\nUsing the product rule:\n$$\\frac{dF}{dp} = (1-2p)g(p) + p(1-p)g'(p)$$\nEvaluating at $p=p^{\\ast}$:\n$$\\lambda^{\\ast} = \\frac{dF}{dp}|_{p=p^{\\ast}} = (1-2p^{\\ast})g(p^{\\ast}) + p^{\\ast}(1-p^{\\ast})g'(p^{\\ast})$$\nSince $g(p^{\\ast})=0$, this simplifies to:\n$$\\lambda^{\\ast} = p^{\\ast}(1-p^{\\ast})g'(p^{\\ast})$$\nWe have $g(p) = \\frac{1}{2}(V-pC)$. Its derivative is:\n$$g'(p) = \\frac{d}{dp}\\left(\\frac{V}{2} - \\frac{pC}{2}\\right) = -\\frac{C}{2}$$\nThis derivative is a constant, so $g'(p^{\\ast}) = -\\frac{C}{2}$.\nSubstituting the expressions for $p^{\\ast}$ and $g'(p^{\\ast})$:\n$$\\lambda^{\\ast} = \\left(\\frac{V}{C}\\right)\\left(1 - \\frac{V}{C}\\right)\\left(-\\frac{C}{2}\\right)$$\n$$\\lambda^{\\ast} = \\left(\\frac{V}{C}\\right)\\left(\\frac{C-V}{C}\\right)\\left(-\\frac{C}{2}\\right)$$\n$$\\lambda^{\\ast} = -\\frac{V(C-V)}{2C}$$\nThis can also be written as:\n$$\\lambda^{\\ast} = \\frac{V(V-C)}{2C}$$\n\nThe final task is to determine the local stability of $p^{\\ast}$ when $V < C$. Local asymptotic stability of a fixed point is determined by the sign of the eigenvalue $\\lambda^{\\ast}$. The fixed point is locally stable if $\\lambda^{\\ast} < 0$. We are given $V>0$ and $C>0$.\nThe sign of $\\lambda^{\\ast} = \\frac{V(V-C)}{2C}$ is determined by the sign of the term $(V-C)$, since $V$ and $2C$ are both positive.\nUnder the condition $V < C$, the term $(V-C)$ is negative.\nThus, $\\lambda^{\\ast} = \\frac{(+)(-)}{(+)} < 0$.\nSince the eigenvalue is negative, the mixed-strategy equilibrium $p^{\\ast}$ is locally stable. This completes the analysis. The final answer comprises the expressions for $p^{\\ast}$ and $\\lambda^{\\ast}$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{V}{C} & \\frac{V(V-C)}{2C}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Real-world markets rarely consist of homogenous, perfectly rational agents. This next practice introduces a layer of realism by incorporating a fixed fraction of 'irrational' agents who stubbornly play a dominated strategy. Your task is to analyze how this market imperfection affects the strategic choices and stability of the equilibrium for the 'rational' subpopulation. This problem  demonstrates the power of replicator dynamics to model heterogeneous populations and evaluate the robustness of market outcomes.",
            "id": "2426954",
            "problem": "Consider a large population market with random matching and three pure strategies: fundamentalist $F$, chartist $C$, and noise $N$. A fixed fraction $\\varepsilon \\in [0,1)$ of the population is composed of irrational agents who always play the strictly dominated strategy $N$ and do not update. The remaining fraction $1-\\varepsilon$ of the population is rational and chooses between $F$ and $C$. Let $x \\in [0,1]$ denote the share of $F$ among the rational agents, so the population state is $((1-\\varepsilon)x,(1-\\varepsilon)(1-x),\\varepsilon)$ for $(F,C,N)$, respectively.\n\nThe symmetric expected payoff from a random match is determined by the matrix $A$, where the row is the player’s strategy and the column is the opponent’s strategy:\n$$\nA \\;=\\;\n\\begin{pmatrix}\n1 & 3 & 2 \\\\\n4 & 0 & 1 \\\\\n-1 & -1 & -1\n\\end{pmatrix}.\n$$\nThe dominated nature of $N$ is understood as follows: for any opponent strategy, the payoff to $N$ (the third row) is strictly below the payoff to $F$ (the first row) and strictly below the payoff to $C$ (the second row).\n\nThe rational subpopulation evolves according to continuous-time replicator dynamics, with the share $x$ adjusting as a function of the payoff difference between $F$ and $C$, computed against the full population state.\n\nDetermine the largest $\\varepsilon \\in [0,1)$ such that there exists an interior mixed equilibrium of the rational subpopulation (that is, $x \\in (0,1)$) that is asymptotically stable under replicator dynamics. Express your final answer as a reduced fraction.",
            "solution": "We begin by subjecting the problem statement to rigorous validation as per the required protocol.\n\nStep 1: Extract Givens\n- Population strategies: Fundamentalist ($F$), Chartist ($C$), Noise ($N$).\n- A fixed fraction $\\varepsilon \\in [0,1)$ of the population are irrational noise agents.\n- A fraction $1-\\varepsilon$ of the population are rational agents.\n- Let $x \\in [0,1]$ be the share of $F$ among the rational agents.\n- Population state vector (shares of $F$, $C$, $N$): $((1-\\varepsilon)x, (1-\\varepsilon)(1-x), \\varepsilon)$.\n- Payoff matrix $A$:\n$$\nA =\n\\begin{pmatrix}\n1 & 3 & 2 \\\\\n4 & 0 & 1 \\\\\n-1 & -1 & -1\n\\end{pmatrix}\n$$\n- Strategy $N$ is strictly dominated.\n- Dynamics: Continuous-time replicator dynamics for the rational subpopulation share $x$.\n- Objective: Determine the largest $\\varepsilon \\in [0,1)$ for which there exists an asymptotically stable interior mixed equilibrium ($x \\in (0,1)$).\n\nStep 2: Validate Using Extracted Givens\nThe problem is evaluated against the criteria for validity.\n- **Scientifically Grounded**: The problem is formulated within the standard framework of evolutionary game theory, specifically using replicator dynamics to model strategy selection in a population. This is a well-established discipline within computational economics and finance.\n- **Well-Posed**: The problem provides all necessary components: a clearly defined population structure, a payoff matrix, and the specific dynamic process. The objective is to find a parameter value based on a stability analysis, which is a standard procedure.\n- **Objective**: The problem statement is expressed using precise mathematical language, free of ambiguity or subjective claims.\n\nThe problem does not exhibit any of the flaws listed for invalidity. It is scientifically sound, formalizable, complete, and mathematically well-posed.\n\nStep 3: Verdict and Action\nThe problem is deemed valid. We shall proceed to the formal derivation of the solution.\n\nThe state of the entire population is given by the vector $p$, where the components represent the fractions of the population playing strategies $F$, $C$, and $N$ respectively:\n$$\np = \\begin{pmatrix} p_F \\\\ p_C \\\\ p_N \\end{pmatrix} = \\begin{pmatrix} (1-\\varepsilon)x \\\\ (1-\\varepsilon)(1-x) \\\\ \\varepsilon \\end{pmatrix}\n$$\nThe rational agents choose between strategies $F$ and $C$. The expected payoff for an agent choosing strategy $F$, $\\pi_F$, is computed against the entire population state $p$. This is the dot product of the first row of the payoff matrix $A$ with $p$:\n$$\n\\pi_F(x, \\varepsilon) = (A \\cdot p)_1 = A_{11} p_F + A_{12} p_C + A_{13} p_N\n$$\n$$\n\\pi_F(x, \\varepsilon) = 1 \\cdot (1-\\varepsilon)x + 3 \\cdot (1-\\varepsilon)(1-x) + 2 \\cdot \\varepsilon\n$$\n$$\n\\pi_F(x, \\varepsilon) = (1-\\varepsilon)x + 3(1-\\varepsilon) - 3(1-\\varepsilon)x + 2\\varepsilon = -2(1-\\varepsilon)x + 3(1-\\varepsilon) + 2\\varepsilon\n$$\n\nSimilarly, the expected payoff for an agent choosing strategy $C$, $\\pi_C$, is the dot product of the second row of $A$ with $p$:\n$$\n\\pi_C(x, \\varepsilon) = (A \\cdot p)_2 = A_{21} p_F + A_{22} p_C + A_{23} p_N\n$$\n$$\n\\pi_C(x, \\varepsilon) = 4 \\cdot (1-\\varepsilon)x + 0 \\cdot (1-\\varepsilon)(1-x) + 1 \\cdot \\varepsilon = 4(1-\\varepsilon)x + \\varepsilon\n$$\n\nThe continuous-time replicator dynamic for the share $x$ of strategy $F$ within the rational subpopulation is given by:\n$$\n\\dot{x} = x(1-x)[\\pi_F(x, \\varepsilon) - \\pi_C(x, \\varepsilon)]\n$$\nAn interior equilibrium, denoted by $x^*$, exists where $\\dot{x}=0$ for $x \\in (0,1)$. This requires the payoff difference to be zero:\n$$\n\\pi_F(x^*, \\varepsilon) - \\pi_C(x^*, \\varepsilon) = 0\n$$\nSubstituting the expressions for the payoffs:\n$$\n[-2(1-\\varepsilon)x^* + 3(1-\\varepsilon) + 2\\varepsilon] - [4(1-\\varepsilon)x^* + \\varepsilon] = 0\n$$\n$$\n-6(1-\\varepsilon)x^* + 3(1-\\varepsilon) + \\varepsilon = 0\n$$\n$$\n-6(1-\\varepsilon)x^* + 3 - 3\\varepsilon + \\varepsilon = 0\n$$\n$$\n-6(1-\\varepsilon)x^* + 3 - 2\\varepsilon = 0\n$$\nSolving for $x^*$:\n$$\n6(1-\\varepsilon)x^* = 3 - 2\\varepsilon\n$$\n$$\nx^* = \\frac{3 - 2\\varepsilon}{6(1-\\varepsilon)}\n$$\nFor $x^*$ to be an interior equilibrium, we must have $0 < x^* < 1$.\n\nFirst condition, $x^* > 0$:\nSince $\\varepsilon \\in [0, 1)$, the denominator $6(1-\\varepsilon)$ is strictly positive. The numerator $3 - 2\\varepsilon$ is positive if $3 > 2\\varepsilon$, which means $\\varepsilon < \\frac{3}{2}$. This condition is always satisfied for the given domain of $\\varepsilon$.\n\nSecond condition, $x^* < 1$:\n$$\n\\frac{3 - 2\\varepsilon}{6(1-\\varepsilon)} < 1\n$$\nAs $6(1-\\varepsilon) > 0$, we can multiply both sides by it without changing the inequality direction:\n$$\n3 - 2\\varepsilon < 6(1-\\varepsilon)\n$$\n$$\n3 - 2\\varepsilon < 6 - 6\\varepsilon\n$$\n$$\n4\\varepsilon < 3\n$$\n$$\n\\varepsilon < \\frac{3}{4}\n$$\nThus, an interior equilibrium exists only for $\\varepsilon \\in [0, \\frac{3}{4})$.\n\nNext, we analyze the stability of this equilibrium. The replicator dynamic is $\\dot{x} = f(x)$, where $f(x) = x(1-x)[\\pi_F(x, \\varepsilon) - \\pi_C(x, \\varepsilon)]$. An interior equilibrium $x^*$ is asymptotically stable if the derivative $f'(x^*)$ is negative.\nLet $\\Delta\\pi(x, \\varepsilon) = \\pi_F(x, \\varepsilon) - \\pi_C(x, \\varepsilon) = -6(1-\\varepsilon)x + 3 - 2\\varepsilon$.\nThe derivative of $f(x)$ is:\n$$\nf'(x) = \\frac{d}{dx} \\left( (x-x^2) \\Delta\\pi(x, \\varepsilon) \\right) = (1-2x)\\Delta\\pi(x, \\varepsilon) + (x-x^2)\\frac{d}{dx}\\Delta\\pi(x, \\varepsilon)\n$$\nAt the equilibrium $x=x^*$, we have $\\Delta\\pi(x^*, \\varepsilon) = 0$. Therefore, the expression for the derivative simplifies to:\n$$\nf'(x^*) = (x^* - (x^*)^2) \\left. \\frac{d}{dx}\\Delta\\pi(x, \\varepsilon) \\right|_{x=x^*}\n$$\n$$\nf'(x^*) = x^*(1-x^*) \\frac{d}{dx}(-6(1-\\varepsilon)x + 3 - 2\\varepsilon)\n$$\n$$\nf'(x^*) = x^*(1-x^*)[-6(1-\\varepsilon)]\n$$\nFor an interior equilibrium, $x^* \\in (0, 1)$, so the term $x^*(1-x^*)$ is strictly positive.\nFor the given domain $\\varepsilon \\in [0, 1)$, the term $1-\\varepsilon$ is also strictly positive.\nConsequently, the term $[-6(1-\\varepsilon)]$ is strictly negative.\nThis means $f'(x^*) = (\\text{positive}) \\times (\\text{negative}) < 0$.\n\nThis result demonstrates that whenever an interior equilibrium exists (i.e., for $\\varepsilon < \\frac{3}{4}$), it is unconditionally asymptotically stable. The problem, therefore, reduces to finding the boundary of the region of existence for this interior equilibrium.\nWe established that an interior equilibrium exists for all $\\varepsilon$ in the interval $[0, \\frac{3}{4})$. The question asks for the largest value of $\\varepsilon \\in [0,1)$ for which such an equilibrium exists. This corresponds to the supremum of the set of valid $\\varepsilon$ values. At $\\varepsilon = \\frac{3}{4}$, the equilibrium $x^*$ becomes $x^*=1$, which is no longer an interior point. Thus, the critical value is $\\frac{3}{4}$.\n\nThe largest value of $\\varepsilon \\in [0,1)$ such that an interior mixed equilibrium exists and is asymptotically stable is the supremum of the interval $[0, \\frac{3}{4})$, which is $\\frac{3}{4}$. The question asks for the largest value in the domain $[0,1)$, thus the answer is the supremum of the set of values of $\\varepsilon$ in that domain that satisfy the condition. The final answer is this supremum.",
            "answer": "$$\\boxed{\\frac{3}{4}}$$"
        },
        {
            "introduction": "While analytical solutions provide deep insights, many realistic economic scenarios are too complex for pen-and-paper analysis. This final practice moves us from theory to computation, the heart of modern economic modeling. You will implement a numerical simulation of a Keynesian 'beauty contest' game, a classic model of financial market speculation . This hands-on coding exercise will equip you with the skills to explore the dynamics of systems with many interacting strategies, where simulation is the key to unlocking understanding.",
            "id": "2426991",
            "problem": "Consider a large population of agents repeatedly playing a Keynesian beauty contest game. At each round, every agent commits to a fixed forecasting rule (a \"strategy\") that outputs a scalar guess in the unit interval. The realized target to forecast is proportional to the current population mean guess. The population state is represented by a probability vector $x = (x_0,\\dots,x_K)$ over a finite set of $K+1$ strategies, where $x_i \\ge 0$ and $\\sum_{i=0}^K x_i = 1$. The average guess is $m(x) = \\sum_{i=0}^K x_i g_i$, where $g_i$ is the guess produced by strategy $i$. The game is parameterized by a weight $p \\in (0,1)$ that scales the target as $p \\cdot m(x)$, a baseline anchor $b \\in (0,1]$, and a linear complexity cost coefficient $\\lambda \\ge 0$ that penalizes strategy index. The set of strategies is defined by level-$k$ iterative reasoning with geometric attenuation: for $i \\in \\{0,1,\\dots,K\\}$, the rule is to guess $g_i = b \\, p^i$. The period payoff for strategy $i$ given state $x$ is defined as the negative squared forecast error minus complexity cost, namely\n$$\nu_i(x) = -\\big(g_i - p \\, m(x)\\big)^2 - \\lambda \\, i.\n$$\nPopulation shares evolve according to the continuous-time replicator equation\n$$\n\\dot{x}_i = x_i \\big( u_i(x) - \\bar{u}(x) \\big), \\quad \\text{for } i=0,\\dots,K,\n$$\nwhere $\\bar{u}(x) = \\sum_{j=0}^K x_j u_j(x)$ is the average payoff. The initial condition is the uniform distribution $x_i(0) = \\frac{1}{K+1}$ for all $i$.\n\nYour task is to implement a program that numerically integrates the replicator dynamics to the steady state for several parameter configurations, starting from the given initial condition. Use a time-discretization scheme that preserves the simplex (nonnegativity and unit sum) to numerical tolerance. Convergence should be declared when the maximum absolute change in $x$ over one step is below $10^{-10}$ for at least $100$ consecutive steps, or when a hard cap of simulation steps is reached. Use a fixed time step of $\\Delta t = 0.01$ and a maximum simulated time of $T = 200$ (that is, at most $N = 20000$ steps). If numerical drift violates nonnegativity, project back by clipping at zero and renormalizing to unit sum. After convergence (or at the time cap), report the index $i^\\star$ of the strategy with the largest population share $x_{i^\\star}$; in case of ties, report the smallest such index.\n\nImplement your solution for the following test suite (each tuple is $(p,b,K,\\lambda)$):\n- Case A (happy path): $(\\frac{2}{3}, 1.0, 5, 0.0)$.\n- Case B (cost-dominated boundary): $(0.9, 1.0, 8, 0.05)$.\n- Case C (trade-off interior case): $(0.5, 1.0, 10, 0.02)$.\n\nNotes:\n- All mathematical entities must be treated precisely as defined: $p \\in (0,1)$, $b \\in (0,1]$, $K \\in \\mathbb{N}$ with $K \\ge 1$, and $\\lambda \\ge 0$.\n- Angles do not appear; no angle unit is required.\n- There are no physical units.\n- Percentages are not used; all quantities are real numbers.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the test suite as a comma-separated list enclosed in square brackets, in the order of cases A, B, C. Each element must be an integer equal to the dominant strategy index $i^\\star$ found by your simulation. For example, an output with three integers must look like $[i_A,i_B,i_C]$ with no spaces.",
            "solution": "The problem statement is critically examined and found to be valid. It is scientifically grounded in the established theory of evolutionary game theory, specifically using replicator dynamics to model strategy evolution in a Keynesian beauty contest game. The problem is well-posed, providing a complete set of definitions, equations, parameters, and initial conditions required for a unique numerical solution. The language is objective and mathematically precise, with no ambiguities or contradictions.\n\nThe problem requires the numerical integration of a system of continuous-time replicator equations to find the steady-state distribution of strategies. The system describes a population of agents, where the share $x_i$ of the population using strategy $i$ evolves based on its relative performance.\n\nThe state of the system is a probability vector $x = (x_0, \\dots, x_K)$ on the $(K+1)$-dimensional simplex, where $x_i(t)$ is the population share of strategy $i$ at time $t$. The constraints are $x_i \\ge 0$ for all $i \\in \\{0, \\dots, K\\}$ and $\\sum_{i=0}^K x_i = 1$. The initial condition is a uniform distribution, $x_i(0) = \\frac{1}{K+1}$ for all $i$.\n\nThe game involves forecasting a target that depends on the population's average action. The available strategies are indexed by $i \\in \\{0, \\dots, K\\}$. Strategy $i$ corresponds to making a fixed guess $g_i$, defined by level-$k$ reasoning as:\n$$\ng_i = b p^i\n$$\nwhere $b \\in (0,1]$ is a baseline anchor and $p \\in (0,1)$ is a geometric attenuation factor. Given the population state $x$, the average guess is:\n$$\nm(x) = \\sum_{i=0}^K x_i g_i\n$$\nThe target value to be forecasted is $p \\cdot m(x)$.\n\nThe success of a strategy is measured by its payoff, which is the negative of a quadratic loss function (squared forecast error) plus a linear penalty for complexity:\n$$\nu_i(x) = -\\big(g_i - p \\, m(x)\\big)^2 - \\lambda i\n$$\nwhere $\\lambda \\ge 0$ is the coefficient for the complexity cost, which increases with the strategy index $i$.\n\nThe population dynamics are governed by the continuous-time replicator equation:\n$$\n\\dot{x}_i = x_i \\big( u_i(x) - \\bar{u}(x) \\big)\n$$\nwhere $\\bar{u}(x) = \\sum_{j=0}^K x_j u_j(x)$ is the population-average payoff. This equation implies that strategies with above-average payoffs will increase their population share over time, while those with below-average payoffs will decline.\n\nTo solve this system of ordinary differential equations numerically, we must employ a time-discretization scheme. A standard forward Euler method is simple but does not guarantee that the state vector $x$ remains on the simplex. The problem statement suggests a projection method (clipping and renormalization) to handle this. However, a more elegant and robust approach is to use a method that inherently preserves the simplex structure. The exponential update rule, a standard discretization for replicator dynamics, achieves this:\n$$\nx_i(t+\\Delta t) = \\frac{x_i(t) \\exp\\big(\\Delta t \\cdot u_i(x(t))\\big)}{\\sum_{j=0}^K x_j(t) \\exp\\big(\\Delta t \\cdot u_j(x(t))\\big)}\n$$\nThis update rule ensures that if $x_i(t) \\ge 0$ and $\\sum_i x_i(t) = 1$, then $x_i(t+\\Delta t) \\ge 0$ and $\\sum_i x_i(t+\\Delta t) = 1$ are maintained to within numerical precision, fulfilling the problem's requirement.\n\nThe algorithm for each test case is as follows:\n1.  Initialize the parameters $(p, b, K, \\lambda)$ and the numerical constants $\\Delta t = 0.01$, $N_{max} = 20000$, convergence tolerance $\\epsilon = 10^{-10}$, and required consecutive steps for convergence $S_{conv} = 100$.\n2.  Pre-calculate the constant vector of strategy guesses $g = (g_0, \\dots, g_K)$.\n3.  Initialize the state vector $x$ to the uniform distribution: $x_i = \\frac{1}{K+1}$ for all $i$.\n4.  Begin the main simulation loop, iterating from step $n=0$ to $N_{max}-1$.\n    a.  Store the current state vector: $x_{old} \\leftarrow x$.\n    b.  Calculate the average guess $m(x) = x \\cdot g$.\n    c.  Calculate the target value $T = p \\cdot m(x)$.\n    d.  Calculate the payoff vector $u$, where $u_i = -(g_i - T)^2 - \\lambda i$.\n    e.  Update the state vector $x$ using the exponential update rule described above.\n    f.  Check for convergence: Calculate the maximum absolute change, $\\delta = \\max_i |x_i - (x_{old})_i|$. If $\\delta < \\epsilon$, increment a counter for consecutive converged steps. Otherwise, reset the counter.\n    g.  If the counter reaches $S_{conv}$, the system has reached a steady state, and the loop terminates.\n5.  After the loop terminates (either by convergence or by reaching $N_{max}$ steps), identify the index $i^\\star$ of the strategy with the largest population share in the final state vector $x$. In case of a tie, the smallest such index is chosen. This is accomplished by finding the argument of the maximum of the final vector $x$.\n6.  This index $i^\\star$ is the result for the given test case.\nThis procedure is repeated for all specified test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    # Each tuple is (p, b, K, lambda).\n    test_cases = [\n        (2.0/3.0, 1.0, 5, 0.0),    # Case A\n        (0.9, 1.0, 8, 0.05),     # Case B\n        (0.5, 1.0, 10, 0.02),    # Case C\n    ]\n\n    results = []\n    for p, b, K, lambda_val in test_cases:\n        i_star = run_simulation(p, b, K, lambda_val)\n        results.append(i_star)\n\n    # Format the final output as specified.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(p, b, K, lambda_val):\n    \"\"\"\n    Numerically integrates the replicator dynamics for a single parameter configuration.\n\n    Args:\n        p (float): The scaling weight for the target.\n        b (float): The baseline anchor for strategies.\n        K (int): The maximum strategy index (K+1 strategies).\n        lambda_val (float): The complexity cost coefficient.\n\n    Returns:\n        int: The index of the dominant strategy at the steady state.\n    \"\"\"\n    # Numerical integration parameters from the problem description\n    DT = 0.01\n    T_MAX = 200.0\n    N_MAX = int(T_MAX / DT)\n    CONV_TOL = 1e-10\n    CONV_STEPS = 100\n\n    # Initialize strategies and state vector\n    # k_values is an array [0, 1, ..., K]\n    k_values = np.arange(K + 1)\n    # g is the vector of guesses for each strategy\n    g = b * (p ** k_values)\n    # x is the population share vector, initialized to uniform distribution\n    x = np.full(K + 1, 1.0 / (K + 1))\n\n    consecutive_converged_steps = 0\n\n    for _ in range(N_MAX):\n        x_old = x.copy()\n\n        # Step 1: Calculate average guess m(x)\n        m_x = np.dot(x, g)\n\n        # Step 2: Calculate target\n        target = p * m_x\n\n        # Step 3: Calculate payoffs u_i(x) for all strategies\n        forecast_error_sq = (g - target) ** 2\n        complexity_cost = lambda_val * k_values\n        u = -forecast_error_sq - complexity_cost\n\n        # Step 4: Update population shares using the exponential update rule\n        # This scheme inherently preserves the simplex (non-negativity and unit sum).\n        numerators = x * np.exp(DT * u)\n        denominator = np.sum(numerators)\n        \n        # This check is for extreme cases, e.g., underflow of all numerators.\n        # It's unlikely in this problem but is good practice.\n        if denominator > 0:\n            x = numerators / denominator\n        else:\n            # If all population shares vanish, simulation cannot continue.\n            break\n\n        # Step 5: Check for convergence\n        max_change = np.max(np.abs(x - x_old))\n        if max_change  CONV_TOL:\n            consecutive_converged_steps += 1\n        else:\n            consecutive_converged_steps = 0\n\n        if consecutive_converged_steps >= CONV_STEPS:\n            break\n\n    # Determine the dominant strategy after convergence or timeout\n    # np.argmax returns the smallest index in case of a tie.\n    i_star = np.argmax(x)\n\n    return int(i_star)\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}