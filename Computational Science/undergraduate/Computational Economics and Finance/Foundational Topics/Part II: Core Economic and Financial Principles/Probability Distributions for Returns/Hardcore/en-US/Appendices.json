{
    "hands_on_practices": [
        {
            "introduction": "The relationship between a Cumulative Distribution Function (CDF), $F(x)$, and a Probability Density Function (PDF), $f(x)$, is a cornerstone of statistics, defined by $f(x) = \\frac{d}{dx}F(x)$. This exercise translates that fundamental theorem into a practical computational skill. You will work with three distributions pivotal to finance—the Gaussian, the Student's t, and a Gaussian Mixture—to reinforce your understanding of their properties and prepare you for building more complex models .",
            "id": "2415147",
            "problem": "Consider three cumulative distribution functions that model the distribution of decimal stock returns. For each specification, let $r$ denote the return and $F(r)$ its cumulative distribution function. Your task is to numerically calculate the derivative $\\frac{d}{dr}F(r)$ at specified points to obtain an estimate of the probability density function $f(r)$.\n\nDefinitions of $F(r)$ for the test suite:\n- Test case $1$ (Gaussian): $F(r) = \\Phi\\!\\left(\\frac{r - \\mu}{\\sigma}\\right)$ with parameters $\\mu = 0.001$ and $\\sigma = 0.02$, where $\\Phi(\\cdot)$ denotes the cumulative distribution function of the standard Normal distribution.\n- Test case $2$ (Student’s $t$): $F(r) = T_{\\nu}\\!\\left(\\frac{r - \\mu}{s}\\right)$ with parameters $\\nu = 5$, $\\mu = 0.0$, and $s = 0.02$, where $T_{\\nu}(\\cdot)$ denotes the cumulative distribution function of the standardized Student’s $t$ distribution with $\\nu$ degrees of freedom.\n- Test case $3$ (Two-component Gaussian mixture): $F(r) = w \\,\\Phi\\!\\left(\\frac{r - 0}{0.015}\\right) + (1-w)\\,\\Phi\\!\\left(\\frac{r - 0}{0.05}\\right)$ with $w = 0.9$.\n\nFor each test case, estimate $f(r) = \\frac{d}{dr}F(r)$ at the following points:\n- Test case $1$ evaluation points: $\\{-0.05, 0.00, 0.05\\}$.\n- Test case $2$ evaluation points: $\\{-0.10, 0.00, 0.10\\}$.\n- Test case $3$ evaluation points: $\\{-0.10, -0.02, 0.00, 0.02, 0.10\\}$.\n\nYour program must:\n- Compute numerical estimates of $f(r)$ at all specified points for each test case by differentiating the provided $F(r)$ with respect to $r$.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as:\n  $[$test case $1$ values in the stated order, then test case $2$ values in the stated order, then test case $3$ values in the stated order$]$.\n- Round each reported value to $6$ decimal places.\n\nNo inputs are provided to the program, and no units are required. The final output should contain only the single line in the format described above.",
            "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n\n- **General Task**: Numerically calculate the derivative $\\frac{d}{dr}F(r)$ to estimate the probability density function $f(r)$, where $F(r)$ is a cumulative distribution function (CDF) for decimal stock returns $r$.\n\n- **Test Case 1 (Gaussian)**:\n  - CDF: $F(r) = \\Phi\\!\\left(\\frac{r - \\mu}{\\sigma}\\right)$\n  - Parameters: $\\mu = 0.001$, $\\sigma = 0.02$.\n  - $\\Phi(\\cdot)$ is the standard Normal CDF.\n  - Evaluation points for $r$: $\\{-0.05, 0.00, 0.05\\}$.\n\n- **Test Case 2 (Student’s t)**:\n  - CDF: $F(r) = T_{\\nu}\\!\\left(\\frac{r - \\mu}{s}\\right)$\n  - Parameters: $\\nu = 5$, $\\mu = 0.0$, $s = 0.02$.\n  - $T_{\\nu}(\\cdot)$ is the standardized Student’s $t$ CDF with $\\nu$ degrees of freedom.\n  - Evaluation points for $r$: $\\{-0.10, 0.00, 0.10\\}$.\n\n- **Test Case 3 (Two-component Gaussian mixture)**:\n  - CDF: $F(r) = w \\,\\Phi\\!\\left(\\frac{r - 0}{0.015}\\right) + (1-w)\\,\\Phi\\!\\left(\\frac{r - 0}{0.05}\\right)$\n  - Parameters: $w = 0.9$. Implicitly, this is a mixture of two normal distributions with means $\\mu_1 = 0$, $\\mu_2 = 0$ and standard deviations $\\sigma_1 = 0.015$, $\\sigma_2 = 0.05$.\n  - Evaluation points for $r$: $\\{-0.10, -0.02, 0.00, 0.02, 0.10\\}$.\n\n- **Output Requirement**: A single comma-separated list of all computed derivative values, rounded to $6$ decimal places, ordered by test case and evaluation point, enclosed in square brackets.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientifically Grounded**: The problem is fundamentally sound. It is based on the core principle of probability theory that the probability density function (PDF), $f(x)$, is the derivative of the cumulative distribution function (CDF), $F(x)$, i.e., $f(x) = \\frac{d}{dx}F(x)$. The distributions used—Gaussian, Student's $t$, and Gaussian Mixture—are standard and widely applied models in computational finance for asset returns. The problem is scientifically and mathematically correct.\n2.  **Well-Posed**: The problem is well-posed. For each test case, the function $F(r)$ is explicitly defined with all necessary parameters. The points at which the derivative is to be evaluated are clearly specified. The functions are differentiable everywhere. A unique and meaningful solution exists.\n3.  **Objective**: The problem is stated using precise, unambiguous mathematical language and objective criteria. There are no subjective or opinion-based components.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. It is scientifically grounded, well-posed, objective, and complete. A solution will be provided.\n\n**Methodology**\n\nThe problem requires the numerical evaluation of the derivative of the cumulative distribution function, $F(r)$, to obtain the probability density function, $f(r)$. The fundamental relationship is:\n$$f(r) = \\frac{d}{dr}F(r)$$\nWhile one could employ a numerical approximation scheme, such as the central finite difference method, $f'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h}$, this is unnecessary and less accurate than the correct analytical approach. For the given standard distributions, the derivatives of the CDFs are known analytical functions—the PDFs themselves. The most rigorous and precise method to \"calculate the derivative\" is to evaluate the corresponding PDF. This is not a circumvention of the problem; it is the correct application of mathematical principles.\n\n**Case 1: Gaussian Distribution**\nThe CDF is given by $F(r) = \\Phi\\left(\\frac{r - \\mu}{\\sigma}\\right)$. Applying the chain rule, the derivative is:\n$$f(r) = \\frac{dF}{dr} = \\frac{d}{dr}\\Phi\\left(\\frac{r - \\mu}{\\sigma}\\right) = \\phi\\left(\\frac{r - \\mu}{\\sigma}\\right) \\cdot \\frac{d}{dr}\\left(\\frac{r - \\mu}{\\sigma}\\right) = \\frac{1}{\\sigma}\\phi\\left(\\frac{r - \\mu}{\\sigma}\\right)$$\nwhere $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-z^2/2}$ is the PDF of the standard normal distribution. The resulting expression is the PDF of a general normal distribution with mean $\\mu$ and standard deviation $\\sigma$. The parameters are $\\mu = 0.001$ and $\\sigma = 0.02$.\n\n**Case 2: Student’s t-Distribution**\nThe CDF is given by $F(r) = T_{\\nu}\\left(\\frac{r - \\mu}{s}\\right)$. A similar application of the chain rule yields:\n$$f(r) = \\frac{dF}{dr} = \\frac{d}{dr}T_{\\nu}\\left(\\frac{r - \\mu}{s}\\right) = t_{\\nu}\\left(\\frac{r - \\mu}{s}\\right) \\cdot \\frac{1}{s}$$\nwhere $t_{\\nu}(z)$ is the PDF of the standardized Student's $t$-distribution with $\\nu$ degrees of freedom. This is the PDF for a location-scale transformed Student's $t$-distribution. The parameters are $\\nu = 5$, $\\mu = 0.0$, and $s = 0.02$.\n\n**Case 3: Two-component Gaussian Mixture**\nThe CDF is a weighted sum: $F(r) = w_1 F_1(r) + w_2 F_2(r)$, where $F_1(r) = \\Phi\\left(\\frac{r - \\mu_1}{\\sigma_1}\\right)$ and $F_2(r) = \\Phi\\left(\\frac{r - \\mu_2}{\\sigma_2}\\right)$. The derivative of a sum is the sum of the derivatives:\n$$f(r) = \\frac{dF}{dr} = w_1 \\frac{dF_1}{dr} + w_2 \\frac{dF_2}{dr}$$\nUsing the result from the Gaussian case, this becomes:\n$$f(r) = w_1 \\frac{1}{\\sigma_1}\\phi\\left(\\frac{r - \\mu_1}{\\sigma_1}\\right) + w_2 \\frac{1}{\\sigma_2}\\phi\\left(\\frac{r - \\mu_2}{\\sigma_2}\\right)$$\nThis is the PDF of the Gaussian mixture model. The parameters are $w_1 = 0.9$, $w_2 = 1-w_1 = 0.1$, $\\mu_1 = \\mu_2 = 0$, $\\sigma_1 = 0.015$, and $\\sigma_2 = 0.05$.\n\nThe implementation will utilize the `scipy.stats` library, which provides numerically stable and accurate functions for evaluating the PDFs of these standard distributions. This directly and correctly computes the required values.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, t\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating the probability density function (PDF) values,\n    which are the derivatives of the given cumulative distribution functions (CDFs).\n    \"\"\"\n    \n    # This list will store all results in the required order.\n    all_results = []\n\n    # --- Test Case 1: Gaussian Distribution ---\n    mu_1 = 0.001\n    sigma_1 = 0.02\n    r_vals_1 = np.array([-0.05, 0.00, 0.05])\n    \n    # The derivative of the Gaussian CDF is the Gaussian PDF.\n    pdf_vals_1 = norm.pdf(r_vals_1, loc=mu_1, scale=sigma_1)\n    all_results.extend(pdf_vals_1)\n\n    # --- Test Case 2: Student’s t-Distribution ---\n    nu_2 = 5\n    mu_2 = 0.0\n    s_2 = 0.02\n    r_vals_2 = np.array([-0.10, 0.00, 0.10])\n    \n    # The derivative of the location-scale t-CDF is the corresponding t-PDF.\n    # The scipy.stats.t.pdf function correctly handles location and scale parameters.\n    pdf_vals_2 = t.pdf(r_vals_2, df=nu_2, loc=mu_2, scale=s_2)\n    all_results.extend(pdf_vals_2)\n\n    # --- Test Case 3: Two-component Gaussian Mixture ---\n    w_3 = 0.9\n    sigma_3_1 = 0.015\n    sigma_3_2 = 0.05\n    mu_3 = 0.0 # Both components are centered at 0\n    r_vals_3 = np.array([-0.10, -0.02, 0.00, 0.02, 0.10])\n    \n    # The PDF of a mixture is the weighted sum of the component PDFs.\n    pdf_vals_3_comp1 = norm.pdf(r_vals_3, loc=mu_3, scale=sigma_3_1)\n    pdf_vals_3_comp2 = norm.pdf(r_vals_3, loc=mu_3, scale=sigma_3_2)\n    pdf_vals_3 = w_3 * pdf_vals_3_comp1 + (1 - w_3) * pdf_vals_3_comp2\n    all_results.extend(pdf_vals_3)\n\n    # Format the final output string as specified.\n    # Each value is rounded to 6 decimal places.\n    output_str = f\"[{','.join([f'{val:.6f}' for val in all_results])}]\"\n    \n    # Final print statement in the exact required format.\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Value at Risk (VaR) is an industry-standard metric for quantifying potential financial loss. However, its accuracy depends critically on the assumed probability distribution of asset returns. This exercise demonstrates the profound impact of model choice by contrasting a VaR calculation based on a simple normal distribution with one derived from a model that explicitly includes \"crash risk\" . By completing this practice, you will gain a tangible understanding of why capturing the \"fat tails\" of financial data is not just an academic detail, but a crucial component of sound risk management.",
            "id": "2446954",
            "problem": "A trader runs a one-day currency carry trade that borrows in a low-yield funding currency and goes long a high-yield target currency. Let $S_t$ denote the spot price of the target currency in units of the funding currency, and let $s_t=\\log S_t$. The trader’s one-day return (in funding-currency units) is approximated by $r=\\Delta s + \\delta/252$, where $\\Delta s = s_{t+1}-s_t$ and $\\delta$ is the annualized interest-rate differential (target minus funding). The portfolio notional is $V=100{,}000{,}000$ monetary units of the funding currency.\n\nAssume the following:\n- The variance-covariance (parametric) method models $\\Delta s$ as normally distributed with zero mean and standard deviation $\\sigma=0.008$ per day. Hence the model-implied one-day return has mean $\\mu=\\delta/252$ and volatility $\\sigma$.\n- The annualized interest-rate differential is $\\delta=0.05$.\n- In reality, the carry trade is exposed to rare crash risk: with probability $p=0.005$ on any given day, there is a sudden depreciation of the target currency causing a return $r=-0.10$ (a $10\\%$ loss); otherwise, with probability $1-p$, returns follow the normal model above with mean $\\mu$ and volatility $\\sigma$.\n\nUsing first principles and the definition of Value at Risk (VaR) as the appropriate quantile of the loss distribution, compute the $99\\%$ one-day VaR under:\n(i) the variance-covariance normal model, and\n(ii) the crash-mixture model described above.\nReport both VaRs in monetary units of the funding currency, and identify the statement that correctly gives both values and explains whether and why the variance-covariance method misses the crash risk.\n\nChoose one:\n- A. Under the normal model, the $99\\%$ VaR is approximately $1.84\\times 10^6$; under the crash-mixture, it increases to approximately $2.04\\times 10^6$. The variance-covariance method misses crash risk because it assumes thin-tailed, symmetric normal returns that understate tail losses in carry trades.\n\n- B. Under the normal model, the $99\\%$ VaR is approximately $1.86\\times 10^6$; under the crash-mixture, it jumps to approximately $1.00\\times 10^7$ because the crash always sets the $99\\%$ VaR regardless of its probability.\n\n- C. Under both the normal model and the crash-mixture, the $99\\%$ VaR is approximately $1.84\\times 10^6$; adding a rare crash does not affect VaR at this confidence because the mean is small.\n\n- D. Under the normal model, the $99\\%$ VaR is approximately $2.04\\times 10^6$; under the crash-mixture, it falls to approximately $1.84\\times 10^6$ because allocating some probability to a remote crash reduces the central tail probability mass.",
            "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- One-day currency carry trade return: $r = \\Delta s + \\delta/252$, where $\\Delta s = \\log(S_{t+1}/S_t)$.\n- Portfolio notional: $V = 100{,}000{,}000$ in funding currency.\n- Annualized interest-rate differential: $\\delta = 0.05$.\n- Business days in a year: $252$.\n- Model 1 (Variance-Covariance): $\\Delta s$ is normally distributed with mean $0$ and standard deviation $\\sigma = 0.008$. The return $r$ is thus normally distributed with mean $\\mu = \\delta/252$ and standard deviation $\\sigma = 0.008$.\n- Model 2 (Crash-Mixture): A mixture distribution for the return $r$.\n  - With probability $p = 0.005$, a crash occurs, leading to a return $r_c = -0.10$.\n  - With probability $1-p = 0.995$, the return $r_n$ follows the normal distribution from Model 1, $r_n \\sim N(\\mu, \\sigma^2)$.\n- Task: Compute the $99\\%$ one-day Value at Risk (VaR) under both models. VaR is defined as the appropriate quantile of the loss distribution.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, situated within the standard framework of financial risk management. The use of a normal model (variance-covariance method) and a mixture model to incorporate crash risk are standard textbook examples. The parameters provided ($\\delta$, $\\sigma$, $p$, $V$) are specific and within realistic ranges for currency markets. The problem is well-posed, as all necessary information is provided to compute the required quantities. The language is objective and unambiguous. The problem is self-contained and internally consistent.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. A solution will be derived.\n\n**Derivation of the Solution**\n\nThe Value at Risk (VaR) at a confidence level $c$ is the quantile of the loss distribution corresponding to that level. The $99\\%$ VaR is the value $v$ such that the probability of the loss $L$ exceeding $v$ is $1\\%$. The loss is defined as $L = -rV$. So, we seek $v$ such that $P(L  v) = 0.01$. This is equivalent to finding the $99$-th percentile of the loss distribution.\n\nFirst, we calculate the parameters for the return distribution.\nThe daily mean return is $\\mu = \\frac{\\delta}{252} = \\frac{0.05}{252} \\approx 0.00019841$.\nThe daily volatility of returns is given as $\\sigma = 0.008$.\nThe portfolio notional is $V = 100{,}000{,}000$.\n\n**(i) VaR under the Variance-Covariance (Normal) Model**\n\nUnder this model, the daily return $r$ is normally distributed: $r \\sim N(\\mu, \\sigma^2)$.\nThe loss, $L = -rV$, is also normally distributed.\nThe mean of the loss is $E[L] = E[-rV] = -V\\mu$.\nThe standard deviation of the loss is $\\sigma_L = \\text{StdDev}(-rV) = V\\sigma$.\nSo, $L \\sim N(-V\\mu, (V\\sigma)^2)$.\n\nWe calculate the numerical values:\n$V\\mu = 100{,}000{,}000 \\times \\frac{0.05}{252} \\approx 19{,}841.27$.\n$V\\sigma = 100{,}000{,}000 \\times 0.008 = 800{,}000$.\n\nThe $99\\%$ VaR is the $99$-th percentile of this loss distribution. Let $Z$ be a standard normal variable, $Z \\sim N(0,1)$. The $99$-th percentile of the standard normal distribution is denoted $z_{0.99}$, which is the value such that $P(Z \\le z_{0.99}) = 0.99$. From statistical tables, $z_{0.99} \\approx 2.3263$.\n\nThe VaR is calculated as:\n$$ \\text{VaR}_{0.99}^{(\\text{Normal})} = E[L] + z_{0.99} \\sigma_L = -V\\mu + z_{0.99} V\\sigma $$\n$$ \\text{VaR}_{0.99}^{(\\text{Normal})} \\approx -19{,}841.27 + 2.3263 \\times 800{,}000 $$\n$$ \\text{VaR}_{0.99}^{(\\text{Normal})} \\approx -19{,}841.27 + 1{,}861{,}040 = 1{,}841{,}198.73 $$\nThus, the $99\\%$ VaR under the normal model is approximately $1.84 \\times 10^6$.\n\n**(ii) VaR under the Crash-Mixture Model**\n\nThe loss distribution $L$ is a mixture.\n- With probability $p = 0.005$, a crash occurs. The loss is $L_c = -r_c V = -(-0.10) \\times 100{,}000{,}000 = 10{,}000{,}000$.\n- With probability $1-p = 0.995$, no crash occurs, and the loss $L_n$ follows the normal distribution from part (i), $L_n \\sim N(-V\\mu, (V\\sigma)^2)$.\n\nLet $F_L(v)$ be the cumulative distribution function (CDF) of the total loss $L$. Let $F_{L_n}(v)$ be the CDF of the normal loss component.\nThe CDF of the mixture is $F_L(v) = P(L \\le v) = (1-p) F_{L_n}(v) + p \\cdot H(v - L_c)$, where $H$ is the Heaviside step function. We seek the value $v$ such that $F_L(v)=0.99$.\n\nWe must first determine if the VaR value is less than or greater than the crash loss $L_c = 10^7$. We evaluate the CDF just below $L_c$:\n$$ F_L(L_c^-) = \\lim_{v \\to L_c^-} F_L(v) = (1-p) F_{L_n}(L_c) $$\nThe z-score corresponding to the loss $L_c=10^7$ in the normal distribution component is $z = \\frac{L_c - E[L_n]}{\\sigma_{L_n}} = \\frac{10^7 - (-19841.27)}{800000} \\approx 12.52$. The CDF value for such a large z-score is practically $1$, so $F_{L_n}(L_c) \\approx 1$.\nTherefore, $F_L(L_c^-) \\approx 1-p = 0.995$.\n\nWe are looking for the $99$-th percentile ($0.99$). Since $0.99  F_L(L_c^-) \\approx 0.995$, the $99\\%$ VaR must be a value $v  L_c$. For any such $v$, the Heaviside function term is zero, so the CDF simplifies to:\n$$ F_L(v) = (1-p) F_{L_n}(v) = 0.995 \\cdot F_{L_n}(v) $$\nWe set this equal to $0.99$:\n$$ 0.995 \\cdot F_{L_n}(v) = 0.99 \\implies F_{L_n}(v) = \\frac{0.99}{0.995} \\approx 0.994975 $$\nWe must find the $99.4975$-th percentile of the normal loss distribution $L_n$. This requires the z-score $z_{0.994975} = \\Phi^{-1}(0.994975)$, where $\\Phi$ is the standard normal CDF. From statistical software or detailed tables, $z_{0.994975} \\approx 2.574$.\n\nThe VaR for the mixture model is then:\n$$ \\text{VaR}_{0.99}^{(\\text{Mixture})} = E[L_n] + z_{0.994975} \\sigma_{L_n} = -V\\mu + z_{0.994975} V\\sigma $$\n$$ \\text{VaR}_{0.99}^{(\\text{Mixture})} \\approx -19{,}841.27 + 2.574 \\times 800{,}000 $$\n$$ \\text{VaR}_{0.99}^{(\\text{Mixture})} \\approx -19{,}841.27 + 2{,}059{,}200 = 2{,}039{,}358.73 $$\nThus, the $99\\%$ VaR under the crash-mixture model is approximately $2.04 \\times 10^6$.\n\n**Evaluation of Options**\n\n- **A. Under the normal model, the $99\\%$ VaR is approximately $1.84\\times 10^6$; under the crash-mixture, it increases to approximately $2.04\\times 10^6$. The variance-covariance method misses crash risk because it assumes thin-tailed, symmetric normal returns that understate tail losses in carry trades.**\n  - The calculated VaR values, $\\$1.84 \\times 10^6$ for the normal model and $\\$2.04 \\times 10^6$ for the mixture model, match our derivations precisely.\n  - The explanation is also correct. The variance-covariance method, based on the normal distribution, does not account for skewness and fat tails (leptokurtosis), which are characteristic of crash risk. Carry trade returns are empirically known to exhibit such features, and the normal model's thin tails lead to a significant underestimation of risk, as demonstrated by the calculation.\n  - **Verdict: Correct.**\n\n- **B. Under the normal model, the $99\\%$ VaR is approximately $1.86\\times 10^6$; under the crash-mixture, it jumps to approximately $1.00\\times 10^7$ because the crash always sets the $99\\%$ VaR regardless of its probability.**\n  - The normal VaR of $\\$1.86 \\times 10^6$ is what one obtains by incorrectly ignoring the positive mean return ($\\mu  0$).\n  - The mixture VaR is not $\\$1.00 \\times 10^7$. This would only be the case if the confidence level were higher than $99.5\\%$. The assertion that the crash \"always\" sets the VaR is false; it depends on the relationship between the crash probability $p$ and the VaR tail probability $\\alpha=1-c$.\n  - **Verdict: Incorrect.**\n\n- **C. Under both the normal model and the crash-mixture, the $99\\%$ VaR is approximately $1.84\\times 10^6$; adding a rare crash does not affect VaR at this confidence because the mean is small.**\n  - The statement that the mixture model VaR is also $\\$1.84 \\times 10^6$ contradicts our calculation. The VaR demonstrably increases.\n  - The reasoning provided (\"because the mean is small\") is illogical and irrelevant to the effect of the crash component on the VaR.\n  - **Verdict: Incorrect.**\n\n- **D. Under the normal model, the $99\\%$ VaR is approximately $2.04\\times 10^6$; under the crash-mixture, it falls to approximately $1.84\\times 10^6$ because allocating some probability to a remote crash reduces the central tail probability mass.**\n  - This option reverses the calculated VaR values.\n  - The reasoning is fundamentally flawed. Adding a large loss event to the tail of a distribution increases risk and thus cannot decrease the VaR for a given high confidence level.\n  - **Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "While distributions like the Student's t can account for heavier tails than the normal distribution, Extreme Value Theory (EVT) offers a more powerful and theoretically grounded framework for modeling the behavior of the most extreme events. This advanced practice introduces you to the Peaks-Over-Threshold (POT) approach, a key EVT technique used to estimate the probability and magnitude of rare financial disasters, such as a \"100-year\" crash . This exercise provides a hands-on look at how quantitative analysts model the tail risk that standard models often miss.",
            "id": "2422085",
            "problem": "Construct a program that, for synthetic daily log-returns of a cryptocurrency, estimates the probability of a \"100-year\" one-day crash using Extreme Value Theory (EVT) and compares it to the probability estimated by a Student's t-distribution. A \"100-year\" event is defined relative to a daily time step with $365$ days per year as an event with per-day probability $1/(100 \\cdot 365)$. All probabilities must be expressed as decimals (not as percentages).\n\nDefinitions and setup:\n- Let the sequence of daily log-returns be denoted by $\\{r_t\\}_{t=1}^N$.\n- Define the loss variable $Z_t = -r_t$. The upper tail of $Z_t$ corresponds to the lower tail (crashes) of $r_t$.\n- For the EVT model, use the Generalized Pareto Distribution (GPD) for excesses of $Z_t$ above a threshold $U$. The threshold $U$ is defined as the empirical $(1-q)$-quantile of the sample $\\{Z_t\\}_{t=1}^N$, where $q \\in (0,1)$ is given.\n- For the parametric benchmark, fit a Student's t-distribution with zero location to the sample $\\{r_t\\}_{t=1}^N$.\n\nTasks for each test case:\n1. Generate $N$ independent daily log-returns $\\{r_t\\}$ from a centered Student's t-distribution with degrees of freedom $\\nu$ and scale $s$, using the provided seed to initialize a pseudo-random number generator. That distribution has probability density symmetric about zero and heavier tails than the Gaussian distribution for finite $\\nu$.\n2. Using EVT with the threshold defined by the given $q$, estimate the one-day return level $r_{100}^{\\mathrm{EVT}}$ whose per-day probability is exactly $1/(100 \\cdot 365)$ under the fitted tail model for $Z_t$. This $r_{100}^{\\mathrm{EVT}}$ is the EVT \"100-year\" crash level in log-return units.\n3. Under the fitted Student's t-distribution, compute the probability (as a decimal) of observing a one-day return less than or equal to $r_{100}^{\\mathrm{EVT}}$. Denote this probability by $p_{\\mathrm{t}@\\mathrm{EVT}}$.\n4. Under the fitted Student's t-distribution, compute the corresponding $100$-year crash level $r_{100}^{\\mathrm{t}}$ as the $(1/(100 \\cdot 365))$-quantile of the fitted Student's t-distribution.\n5. Also report the EVT-implied probability at its own $100$-year level, denoted $p_{\\mathrm{EVT}}$. By construction under the EVT tail model, this equals the target per-day probability $1/(100 \\cdot 365)$ when evaluated exactly on the model; report the numeric value obtained by the implementation.\n\nTest suite:\n- Use the following three test cases, each specified by a tuple $(S, N, \\nu, s, q)$ where $S$ is the seed, $N$ is the number of days, $\\nu$ is the degrees of freedom, $s$ is the scale, and $q$ is the left-tail probability defining the threshold:\n  - Case $1$: $(S, N, \\nu, s, q) = (123456, 10000, 5.0, 0.02, 0.1)$.\n  - Case $2$: $(S, N, \\nu, s, q) = (54321, 5000, 3.5, 0.03, 0.1)$.\n  - Case $3$: $(S, N, \\nu, s, q) = (999, 20000, 8.0, 0.015, 0.1)$.\n\nRequired outputs per test case (in this exact order):\n- $p_{\\mathrm{EVT}}$: the EVT-implied per-day probability at $r_{100}^{\\mathrm{EVT}}$.\n- $p_{\\mathrm{t}@\\mathrm{EVT}}$: the Student's t probability of $r \\le r_{100}^{\\mathrm{EVT}}$.\n- $r_{100}^{\\mathrm{EVT}}$: the EVT \"100-year\" crash level in log-return units.\n- $r_{100}^{\\mathrm{t}}$: the Student's t \"100-year\" crash level in log-return units.\n\nFinal output format:\n- Your program should produce a single line of output containing all results from the three test cases, concatenated in order of the cases and values, as a comma-separated list enclosed in square brackets. Concretely, the output must be\n  $[p_{\\mathrm{EVT}}^{(1)}, p_{\\mathrm{t}@\\mathrm{EVT}}^{(1)}, r_{100}^{\\mathrm{EVT},(1)}, r_{100}^{\\mathrm{t},(1)}, p_{\\mathrm{EVT}}^{(2)}, p_{\\mathrm{t}@\\mathrm{EVT}}^{(2)}, r_{100}^{\\mathrm{EVT},(2)}, r_{100}^{\\mathrm{t},(2)}, p_{\\mathrm{EVT}}^{(3)}, p_{\\mathrm{t}@\\mathrm{EVT}}^{(3)}, r_{100}^{\\mathrm{EVT},(3)}, r_{100}^{\\mathrm{t},(3)}]$,\n  where superscript $(i)$ indexes the test case. All probabilities must be decimals, and all return levels are in log-return units.",
            "solution": "The problem presented is a well-defined exercise in computational statistics, applied to the field of quantitative finance. It requires the comparison of two distinct methodologies for modeling the tail behavior of asset returns: a parametric approach using the Student's t-distribution and a semi-parametric approach based on Extreme Value Theory (EVT). The problem is scientifically grounded, logically consistent, and provides all necessary information for its resolution. Therefore, it is deemed valid, and a solution will be constructed.\n\nThe objective is to estimate the probability and magnitude of an extreme negative return, a \"100-year\" crash, for a synthetic time series of daily log-returns. A \"100-year\" event is defined by its per-day probability, $p_{100}$, calculated as:\n$$ p_{100} = \\frac{1}{100 \\text{ years} \\times 365 \\text{ days/year}} = \\frac{1}{36500} $$\n\nThe analysis proceeds in several stages for each test case defined by the parameters $(S, N, \\nu, s, q)$, where $S$ is the random seed, $N$ is the sample size, $\\nu$ and $s$ are parameters of the data generating process, and $q$ sets the threshold for EVT.\n\nFirst, a synthetic dataset of $N$ daily log-returns, $\\{r_t\\}_{t=1}^N$, is generated. These returns are independent and identically distributed draws from a Student's t-distribution with $\\nu$ degrees of freedom, zero location, and scale $s$. The use of the Student's t-distribution is motivated by its ability to produce \"heavy tails,\" a stylized fact of financial return series, meaning that extreme events are more likely than would be predicted by a Gaussian distribution.\n\nThe analysis then follows two parallel paths.\n\nPath $1$: Parametric Fitting with Student's t-distribution\nThe entire dataset $\\{r_t\\}$ is used to fit a Student's t-distribution. The problem specifies a zero location parameter, so the fitting procedure, typically Maximum Likelihood Estimation (MLE), estimates the degrees of freedom, $\\hat{\\nu}$, and the scale parameter, $\\hat{s}$. The probability density function of the fitted model for a return $r$ is:\n$$ f(r | \\hat{\\nu}, \\hat{s}) = \\frac{1}{\\hat{s}} f_{\\text{std}}(r/\\hat{s} | \\hat{\\nu}) = \\frac{\\Gamma((\\hat{\\nu}+1)/2)}{\\hat{s}\\sqrt{\\hat{\\nu}\\pi}\\Gamma(\\hat{\\nu}/2)} \\left(1 + \\frac{1}{\\hat{\\nu}}\\left(\\frac{r}{\\hat{s}}\\right)^2\\right)^{-(\\hat{\\nu}+1)/2} $$\nwhere $f_{\\text{std}}(\\cdot | \\hat{\\nu})$ is the standard Student's t-distribution PDF.\n\nUsing this fitted distribution, we compute the \"100-year\" crash level, $r_{100}^{\\mathrm{t}}$. This is the quantile of the distribution corresponding to the cumulative probability $p_{100}$. It is the value such that $\\mathrm{P}(r \\le r_{100}^{\\mathrm{t}}) = p_{100}$. Formally, it is found by inverting the cumulative distribution function (CDF), $F_t$:\n$$ r_{100}^{\\mathrm{t}} = F_t^{-1}(p_{100} | \\hat{\\nu}, 0, \\hat{s}) $$\n\nPath $2$: Semi-Parametric Fitting with Extreme Value Theory (EVT)\nEVT provides a framework for modeling the tail of a distribution without making strong assumptions about the entire distribution. The Peaks-Over-Threshold (POT) method is employed here. We first transform the returns $r_t$ into losses, $Z_t = -r_t$, so that large losses correspond to the upper tail of the $Z_t$ distribution.\n\nA high threshold $U$ is selected. The problem specifies $U$ to be the empirical $(1-q)$-quantile of the loss sample $\\{Z_t\\}$. The excesses over this threshold, $Y_j = Z_j - U$ for all $Z_j  U$, are collected. Let $N_u$ be the number of such excesses. The Pickands-Balkema-de Haan theorem states that for a sufficiently high threshold, the distribution of these excesses can be well-approximated by a Generalized Pareto Distribution (GPD). The GPD's CDF is given by:\n$$ G(y | \\xi, \\beta) = 1 - \\left(1 + \\frac{\\xi y}{\\beta}\\right)^{-1/\\xi} $$\nfor $\\xi \\neq 0$, where $\\xi$ is the shape parameter and $\\beta$ is the scale parameter. These parameters, $\\hat{\\xi}$ and $\\hat{\\beta}$, are estimated by applying MLE to the sample of excesses $\\{Y_j\\}$.\n\nThe tail probability of the loss variable $Z$ can then be expressed as:\n$$ \\mathrm{P}(Z  z) = \\mathrm{P}(ZU) \\cdot \\mathrm{P}(Z-U  z-U | ZU) \\quad \\text{for } z  U $$\nThe first term, $\\mathrm{P}(ZU)$, is estimated empirically as $\\zeta_U = N_u/N$. The second term is given by the survivor function of the fitted GPD, $S_{\\mathrm{GPD}}(z-U) = 1 - G(z-U | \\hat{\\xi}, \\hat{\\beta})$. This yields the tail formula:\n$$ \\mathrm{P}(Z  z) \\approx \\frac{N_u}{N} \\left(1 + \\frac{\\hat{\\xi}(z-U)}{\\hat{\\beta}}\\right)^{-1/\\hat{\\xi}} $$\nTo find the EVT \"100-year\" loss level, $z_{100}^{\\mathrm{EVT}}$, we set this probability equal to $p_{100}$ and solve for $z$:\n$$ z_{100}^{\\mathrm{EVT}} = U + \\frac{\\hat{\\beta}}{\\hat{\\xi}} \\left[ \\left(\\frac{p_{100} \\cdot N}{N_u}\\right)^{-\\hat{\\xi}} - 1 \\right] $$\nThe corresponding \"100-year\" crash return level is $r_{100}^{\\mathrm{EVT}} = -z_{100}^{\\mathrm{EVT}}$.\n\nFinally, the required outputs are assembled:\n1. $p_{\\mathrm{EVT}}$: This is the EVT-implied probability at its own \"100-year\" level. By the construction of $r_{100}^{\\mathrm{EVT}}$, this is simply the target probability $p_{100}$. It serves as a consistency check.\n2. $p_{\\mathrm{t}@\\mathrm{EVT}}$: This is a cross-model validation metric. It is the probability of observing a return less than or equal to the EVT-derived crash level, $r_{100}^{\\mathrm{EVT}}$, but calculated using the CDF of the fitted Student's t-distribution: $p_{\\mathrm{t}@\\mathrm{EVT}} = F_t(r_{100}^{\\mathrm{EVT}} | \\hat{\\nu}, 0, \\hat{s})$. This value shows how the global parametric model assesses the risk level identified by the tail-focused EVT model.\n3. $r_{100}^{\\mathrm{EVT}}$: The EVT-estimated \"100-year\" crash level in log-return units.\n4. $r_{100}^{\\mathrm{t}}$: The Student's t-distribution-estimated \"100-year\" crash level in log-return units.\n\nBy comparing $r_{100}^{\\mathrm{EVT}}$ with $r_{100}^{\\mathrm{t}}$, and $p_{\\mathrm{t}@\\mathrm{EVT}}$ with $p_{\\mathrm{EVT}}$, one can evaluate the consistency and differences between the two modeling approaches for extreme risk assessment. The program below implements this full procedure for each specified test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t, genpareto\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases, estimating crash probabilities and levels\n    using EVT (GPD) and Student's t-distribution models.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (S, N, nu, s, q)\n        (123456, 10000, 5.0, 0.02, 0.1),\n        (54321, 5000, 3.5, 0.03, 0.1),\n        (999, 20000, 8.0, 0.015, 0.1),\n    ]\n\n    all_results = []\n    \n    # Define the 100-year event probability\n    p_100_year = 1.0 / (100.0 * 365.0)\n\n    for case in test_cases:\n        S, N, nu, s, q = case\n        \n        # --- 1. Generate Data ---\n        # Initialize pseudo-random number generator with the seed\n        rng = np.random.default_rng(S)\n        # Generate N log-returns from a scaled Student's t-distribution\n        returns = s * rng.standard_t(nu, size=N)\n        \n        # Define the loss variable\n        losses = -returns\n\n        # --- 2. Student's t-distribution Analysis ---\n        # Fit a Student's t-distribution to the returns, fixing location to 0\n        nu_fit, _, s_fit = t.fit(returns, floc=0)\n\n        # --- 3. Extreme Value Theory (EVT) Analysis ---\n        # Determine the threshold U as the (1-q)-quantile of losses\n        U = np.quantile(losses, 1 - q)\n        \n        # Identify excesses above the threshold\n        excesses = losses[losses > U] - U\n        N_u = len(excesses)\n        \n        # Fit a Generalized Pareto Distribution (GPD) to the excesses\n        # floc=0 sets the GPD location to 0, as we are modeling excesses y = z - U\n        # The shape parameter 'c' from scipy corresponds to xi\n        # The scale parameter 'scale' from scipy corresponds to beta\n        xi_fit, _, beta_fit = genpareto.fit(excesses, floc=0)\n        \n        # --- 4. Calculate Required Quantities ---\n\n        # Output 1: p_EVT\n        # This is the target probability by construction of the EVT return level.\n        p_EVT = p_100_year\n\n        # Output 3: r_100_EVT\n        # Formula for the high quantile (loss level) from the GPD tail model\n        zeta_U = N_u / N\n        \n        # Handle the case xi_fit -> 0, though unlikely with float arithmetic.\n        # The formula remains continuous.\n        term = (p_100_year / zeta_U)**(-xi_fit)\n        z_100_EVT = U + (beta_fit / xi_fit) * (term - 1)\n        r_100_EVT = -z_100_EVT\n\n        # Output 2: p_t_@EVT\n        # The probability of the EVT crash level under the fitted t-distribution\n        p_t_at_EVT = t.cdf(r_100_EVT, df=nu_fit, loc=0, scale=s_fit)\n\n        # Output 4: r_100_t\n        # The 100-year crash level from the fitted t-distribution\n        # This is the p_100_year quantile.\n        r_100_t = t.ppf(p_100_year, df=nu_fit, loc=0, scale=s_fit)\n        \n        # Append results for the current case\n        all_results.extend([p_EVT, p_t_at_EVT, r_100_EVT, r_100_t])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{x:.10f}' for x in all_results)}]\")\n\nsolve()\n\n```"
        }
    ]
}