{
    "hands_on_practices": [
        {
            "introduction": "A core challenge in economics is making optimal decisions over time, where today's choices affect tomorrow's opportunities. This practice explores a classic resource extraction problem, contrasting a simple, myopic \"greedy\" algorithm with a forward-looking optimal solution. By implementing both, you will gain hands-on experience with intertemporal optimization and quantitatively measure the \"price of myopia\"—the value lost by ignoring the future—a fundamental concept in computational economics .",
            "id": "2438788",
            "problem": "Consider a finite-horizon resource extraction problem motivated by computational economics and finance. A firm owns a mine containing a nonrenewable resource. Time is discrete with $T$ periods indexed by $t \\in \\{1,\\dots,T\\}$. The firm chooses extraction quantities $x_t$ each period subject to a stock constraint and period-specific operational capacity. Let the initial stock be $S \\ge 0$. Let the per-period capacity limits be $u_t \\ge 0$. Let the ore concentration (a multiplicative factor for revenue) be $c_t \\ge 0$. Let the constant output price be $p \\ge 0$. Let the per-period convex extraction cost be quadratic with parameter $a > 0$. Let the intertemporal discount factor be $\\beta \\in (0,1]$. Profits are computed in discounted units.\n\nThe per-period instantaneous net benefit from extracting $x_t$ in period $t$ is given by the concave function\n$$\nb_t(x_t) \\equiv p\\,c_t\\,x_t - \\frac{a}{2}\\,x_t^2,\n$$\nand total discounted net present value (NPV) is\n$$\n\\sum_{t=1}^T \\beta^{t-1}\\, b_t(x_t).\n$$\n\nFeasibility constraints are\n$$\n0 \\le x_t \\le u_t \\quad \\text{for all } t, \\qquad \\sum_{t=1}^T x_t \\le S.\n$$\n\nYour task is to implement and compare two algorithms:\n\n- A greedy algorithm that is myopic: in each period $t$ it chooses $x_t$ to maximize the current period's $b_t(x_t)$ subject only to the instantaneous constraints $0 \\le x_t \\le \\min\\{u_t, s_t\\}$ where $s_t$ is the remaining stock before making the period-$t$ decision. The greedy algorithm ignores any effect on future periods beyond the current stock feasibility. After choosing $x_t$, update the remaining stock by $s_{t+1} = s_t - x_t$ with $s_1 = S$.\n- An optimal dynamic programming (DP) solution based on the Bellman principle of optimality that maximizes the total discounted NPV subject to all constraints. You may compute this optimal solution by any correct algorithm that is equivalent to solving the finite-horizon DP problem.\n\nFor both algorithms, compute the discounted NPV\n$$\nV \\equiv \\sum_{t=1}^T \\beta^{t-1}\\, \\left(p\\,c_t\\,x_t - \\frac{a}{2}\\,x_t^2\\right).\n$$\n\nImplement a program that, for the following test suite, returns for each parameter set a triple consisting of the optimal NPV, the greedy NPV, and an equality indicator defined as $1$ if the absolute difference between the two NPVs is at most $10^{-6}$ and $0$ otherwise. All floating-point outputs must be rounded to $6$ decimals.\n\nTest suite (each case is a tuple $\\left(T,\\ \\beta,\\ p,\\ a,\\ S,\\ \\mathbf{c},\\ \\mathbf{u}\\right)$ where $\\mathbf{c}=(c_1,\\dots,c_T)$ and $\\mathbf{u}=(u_1,\\dots,u_T)$):\n\n- Case $1$: $T=4$, $\\beta=0.95$, $p=2.0$, $a=2.0$, $S=6.0$, $\\mathbf{c}=(1.0,\\ 1.5,\\ 1.2,\\ 1.1)$, $\\mathbf{u}=(5.0,\\ 5.0,\\ 5.0,\\ 5.0)$.\n- Case $2$: $T=3$, $\\beta=0.98$, $p=1.0$, $a=1.0$, $S=3.0$, $\\mathbf{c}=(1.0,\\ 2.0,\\ 5.0)$, $\\mathbf{u}=(10.0,\\ 10.0,\\ 10.0)$.\n- Case $3$: $T=3$, $\\beta=0.5$, $p=1.0$, $a=1.0$, $S=3.0$, $\\mathbf{c}=(5.0,\\ 2.0,\\ 1.0)$, $\\mathbf{u}=(10.0,\\ 10.0,\\ 10.0)$.\n- Case $4$: $T=4$, $\\beta=0.99$, $p=1.0$, $a=1.0$, $S=1.5$, $\\mathbf{c}=(2.0,\\ 2.0,\\ 10.0,\\ 2.0)$, $\\mathbf{u}=(10.0,\\ 10.0,\\ 1.0,\\ 10.0)$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must be flattened across test cases in the following order: for case $i$ append optimal NPV, then greedy NPV, then the equality indicator (in that order), all rounded as specified. For example, the output must look like\n$$\n[\\text{opt}_1,\\ \\text{greedy}_1,\\ \\text{eq}_1,\\ \\text{opt}_2,\\ \\text{greedy}_2,\\ \\text{eq}_2,\\ \\dots].\n$$",
            "solution": "The problem statement is first subjected to a rigorous validation procedure.\n\n**Step 1: Extracted Givens**\n- **Time Horizon**: Discrete, $T$ periods, $t \\in \\{1,\\dots,T\\}$.\n- **Choice Variables**: Extraction quantities $x_t$.\n- **Parameters**: Initial stock $S \\ge 0$, per-period capacity $u_t \\ge 0$, ore concentration $c_t \\ge 0$, output price $p \\ge 0$, cost parameter $a > 0$, discount factor $\\beta \\in (0,1]$.\n- **Objective Function**: Maximize total discounted Net Present Value (NPV), $V = \\sum_{t=1}^T \\beta^{t-1}\\, b_t(x_t)$, where the per-period net benefit is $b_t(x_t) \\equiv p\\,c_t\\,x_t - \\frac{a}{2}\\,x_t^2$.\n- **Constraints**:\n    1. Capacity: $0 \\le x_t \\le u_t$ for all $t$.\n    2. Stock: $\\sum_{t=1}^T x_t \\le S$.\n- **Algorithms**:\n    1. **Greedy**: In each period $t$, choose $x_t$ to maximize $b_t(x_t)$ subject to $0 \\le x_t \\le \\min\\{u_t, s_t\\}$, where $s_t$ is the remaining stock.\n    2. **Optimal**: A dynamic programming solution, or equivalent, to maximize the total discounted NPV under all constraints.\n- **Output Requirements**: For each test case, provide a triple: (optimal NPV, greedy NPV, equality indicator). The indicator is $1$ if the absolute difference is $\\le 10^{-6}$, else $0$. Outputs must be rounded to $6$ decimals. Test cases are provided.\n\n**Step 2: Validation**\n- **Scientifically Grounded**: The problem is a canonical finite-horizon resource extraction model, a fundamental topic in computational and resource economics. The model is based on established economic principles. It is valid.\n- **Well-Posed**: The objective function, $\\sum \\beta^{t-1} (p c_t x_t - \\frac{a}{2} x_t^2)$, is strictly concave in the vector $\\mathbf{x} = (x_1, \\dots, x_T)$ because $a>0$ and $\\beta>0$. The feasible set, defined by linear inequalities, is convex and compact. The maximization of a strictly concave function over a non-empty, compact, convex set has a unique solution. The problem is well-posed.\n- **Objective and Complete**: The problem is specified with precise mathematical language and provides all necessary data for the given test cases. It is valid.\n\n**Step 3: Verdict**\nThe problem is valid. We proceed with the solution.\n\nThe problem requires the implementation and comparison of two algorithms for a resource extraction problem.\n\n**Greedy Algorithm**\nThe greedy algorithm is myopic. In each period $t$, it maximizes the current period's benefit $b_t(x_t) = p c_t x_t - \\frac{a}{2} x_t^2$ subject to current constraints only. The function $b_t(x_t)$ is a downward-opening parabola. Its unconstrained maximum is found by setting its derivative with respect to $x_t$ to zero:\n$$\n\\frac{d b_t(x_t)}{d x_t} = p c_t - a x_t = 0 \\implies x_t^* = \\frac{p c_t}{a}\n$$\nThe constraints faced by the greedy decision-maker in period $t$ are the capacity limit $u_t$ and the remaining stock $s_t$. Thus, the choice must satisfy $0 \\le x_t \\le \\min\\{u_t, s_t\\}$. Since $p, c_t, a$ are non-negative, $x_t^* \\ge 0$. The greedy choice $x_t^g$ is therefore the projection of the unconstrained optimum $x_t^*$ onto the feasible interval:\n$$\nx_t^g = \\min\\left(\\frac{p c_t}{a}, u_t, s_t\\right)\n$$\nThe algorithm proceeds by iterating from $t=1$ to $T$, calculating $x_t^g$, and updating the remaining stock $s_{t+1} = s_t - x_t^g$, with initial stock $s_1 = S$. The total NPV is then computed using the resulting extraction path $\\{x_t^g\\}_{t=1}^T$.\n\n**Optimal Algorithm**\nThe problem is a convex optimization problem, specifically a Quadratic Program (QP), since the objective is quadratic and the constraints are linear. While solvable with a generic QP solver, a more efficient method arises from analyzing the Karush-Kuhn-Tucker (KKT) conditions.\n\nThe Lagrangian for the optimization problem is:\n$$\n\\mathcal{L}(\\mathbf{x}, \\lambda, \\boldsymbol{\\mu}, \\boldsymbol{\\nu}) = \\sum_{t=1}^T \\beta^{t-1}\\left(p c_t x_t - \\frac{a}{2} x_t^2\\right) - \\lambda\\left(\\sum_{t=1}^T x_t - S\\right) - \\sum_{t=1}^T \\mu_t(x_t - u_t) - \\sum_{t=1}^T \\nu_t(-x_t)\n$$\nwhere $\\lambda \\ge 0$, $\\mu_t \\ge 0$, and $\\nu_t \\ge 0$ are the Lagrange multipliers for the total stock, per-period upper capacity, and per-period non-negativity constraints, respectively.\n\nThe first-order condition for stationarity with respect to $x_t$ is:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial x_t} = \\beta^{t-1}(p c_t - a x_t) - \\lambda - \\mu_t + \\nu_t = 0\n$$\nThe complementary slackness conditions imply that if $0 < x_t < u_t$, then $\\mu_t = \\nu_t = 0$. In this internal case, the optimal extraction $x_t$ satisfies:\n$$\n\\beta^{t-1}(p c_t - a x_t) = \\lambda \\implies p c_t - a x_t = \\lambda \\beta^{-(t-1)} \\implies x_t = \\frac{p c_t - \\lambda \\beta^{-(t-1)}}{a}\n$$\nThe term $\\lambda$ is the shadow price of the resource stock $S$. The condition states that the discounted marginal profit of extraction must be equal to this shadow price across all periods where extraction is positive and not at a boundary.\nConsidering the boundary conditions ($x_t=0$ or $x_t=u_t$), the optimal extraction $x_t^*$ for a given $\\lambda$ is:\n$$\nx_t^*(\\lambda) = \\text{max}\\left(0, \\min\\left(\\frac{p c_t - \\lambda \\beta^{-(t-1)}}{a}, u_t\\right)\\right)\n$$\nLet $X(\\lambda) = \\sum_{t=1}^T x_t^*(\\lambda)$. The function $X(\\lambda)$ is a continuous and non-increasing function of $\\lambda$. The correct value of $\\lambda$ is determined by the total stock constraint and the complementary slackness condition $\\lambda(\\sum_{t=1}^T x_t^* - S) = 0$.\n\nThe algorithm to find the optimal path is as follows:\n1.  Calculate total extraction assuming the stock constraint is not binding, which corresponds to setting the shadow price $\\lambda=0$. Let this be $X(0) = \\sum_t \\max(0, \\min(\\frac{p c_t}{a}, u_t))$.\n2.  If $X(0) \\le S$, the resource is not scarce relative to its profitable extraction opportunities. The optimal solution is obtained with $\\lambda^*=0$, and $x_t^* = x_t^*(0)$ for all $t$.\n3.  If $X(0) > S$, the stock constraint is binding, requiring $\\lambda^* > 0$. We must find the unique $\\lambda^* > 0$ that satisfies the market-clearing condition $X(\\lambda^*) = S$. This is a one-dimensional root-finding problem for the equation $g(\\lambda) = X(\\lambda) - S = 0$. A bisection or Newton-family method (e.g., Brent's method) can find $\\lambda^*$ efficiently. The search interval for $\\lambda$ is $[0, \\lambda_{max}]$, where $\\lambda_{max} = \\max_t(p c_t \\beta^{t-1})$ is an upper bound ensuring all $x_t=0$.\n4.  Once $\\lambda^*$ is found, the optimal extraction path $\\{x_t^*(\\lambda^*)\\}_{t=1}^T$ is determined, and the optimal NPV can be computed.\n\nThis KKT-based approach is superior to a generic QP solver for this problem structure. The implementation will use Brent's method for root finding, as it is robust and efficient.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Solves a series of finite-horizon resource extraction problems using both a greedy\n    and an optimal algorithm, then compares the results.\n    \"\"\"\n\n    test_cases = [\n        (4, 0.95, 2.0, 2.0, 6.0, np.array([1.0, 1.5, 1.2, 1.1]), np.array([5.0, 5.0, 5.0, 5.0])),\n        (3, 0.98, 1.0, 1.0, 3.0, np.array([1.0, 2.0, 5.0]), np.array([10.0, 10.0, 10.0])),\n        (3, 0.5, 1.0, 1.0, 3.0, np.array([5.0, 2.0, 1.0]), np.array([10.0, 10.0, 10.0])),\n        (4, 0.99, 1.0, 1.0, 1.5, np.array([2.0, 2.0, 10.0, 2.0]), np.array([10.0, 10.0, 1.0, 10.0])),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        T, beta, p, a, S, c, u = case\n        \n        # --- Greedy Algorithm ---\n        x_g = np.zeros(T)\n        s_rem = S\n        for t in range(T):\n            x_unconstrained = p * c[t] / a\n            x_g[t] = np.clip(x_unconstrained, 0, min(u[t], s_rem))\n            s_rem -= x_g[t]\n\n        # --- Optimal Algorithm ---\n        betas = beta ** np.arange(T)\n        \n        def get_x_opt(lam, T, p, a, beta, c, u):\n            \"\"\"Computes optimal extraction path for a given lambda.\"\"\"\n            beta_inv_powers = beta ** (-np.arange(T))\n            numerators = p * c - lam * beta_inv_powers\n            x_unbounded = numerators / a\n            return np.clip(x_unbounded, 0, u)\n\n        # Check if resource constraint is binding\n        x_opt_lam0 = get_x_opt(0, T, p, a, beta, c, u)\n        \n        if np.sum(x_opt_lam0) <= S:\n            lam_opt = 0.0\n            x_opt = x_opt_lam0\n        else:\n            # Resource constraint is binding, find lambda > 0\n            # Define the function whose root we want to find\n            def total_extraction_diff(lam):\n                return np.sum(get_x_opt(lam, T, p, a, beta, c, u)) - S\n            \n            # Find a safe upper bound for lambda search\n            # Any lambda larger than this will result in all xt <= 0\n            lam_upper_bound = np.max(p * c * (beta ** np.arange(T))) + 1.0\n\n            try:\n                lam_opt = brentq(total_extraction_diff, 0, lam_upper_bound, xtol=1e-12, rtol=1e-12)\n            except ValueError:\n                # Fallback if signs are not different, though theoretically they should be\n                lam_opt = 0.0 # Should not happen with this problem structure\n            \n            x_opt = get_x_opt(lam_opt, T, p, a, beta, c, u)\n\n        # --- NPV Calculation ---\n        def calculate_npv(x_path, T, beta, p, c, a):\n            npv = 0.0\n            for t in range(T):\n                benefit = p * c[t] * x_path[t] - (a / 2) * x_path[t]**2\n                npv += (beta**t) * benefit\n            return npv\n\n        greedy_npv = calculate_npv(x_g, T, beta, p, c, a)\n        optimal_npv = calculate_npv(x_opt, T, beta, p, c, a)\n\n        # --- Formatting and Appending Results ---\n        optimal_npv_rounded = round(optimal_npv, 6)\n        greedy_npv_rounded = round(greedy_npv, 6)\n        \n        eq_indicator = 1 if abs(optimal_npv - greedy_npv) <= 1e-6 else 0\n        \n        results.extend([f\"{optimal_npv_rounded:.6f}\", f\"{greedy_npv_rounded:.6f}\", eq_indicator])\n\n    # Final print statement\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "As algorithms increasingly make decisions in finance, understanding their vulnerabilities becomes critical. This exercise shifts our focus from simple optimization to strategic interaction, where you will design an \"adversarial\" algorithm to find the most efficient way to overturn a decision made by a credit scoring model. This practice introduces the concept of algorithmic recourse and demonstrates how optimization techniques can be used to probe the strategic weaknesses and fairness of automated economic systems .",
            "id": "2438838",
            "problem": "You are given a formalization of a credit approval decision and an associated notion of a minimally invasive, plausibly edited loan application. Let the feature vector be $\\mathbf{x} \\in \\mathbb{R}^d$, the weight vector be $\\mathbf{w} \\in \\mathbb{R}^d$, and the intercept be $b \\in \\mathbb{R}$. The credit scoring rule is a deterministic classifier that approves an application if and only if $\\mathbf{w}^\\top \\mathbf{x} + b \\ge 0$ and rejects otherwise. An adversarial edit is a vector $\\boldsymbol{\\delta} \\in \\mathbb{R}^d$ producing a modified application $\\mathbf{x} + \\boldsymbol{\\delta}$.\n\nA change is plausible if and only if it satisfies all of the following constraints:\n- For each feature index $i \\in \\{0,1,\\dots,d-1\\}$, the edited value is bounded by $l_i \\le x_i + \\delta_i \\le u_i$, where $\\mathbf{l}, \\mathbf{u} \\in \\mathbb{R}^d$ with $l_i \\le u_i$.\n- For each immutable feature index $i \\in \\mathcal{I} \\subseteq \\{0,1,\\dots,d-1\\}$, the change equals $\\delta_i = 0$.\n- The objective cost of an edit is defined by a nonnegative cost vector $\\mathbf{c} \\in \\mathbb{R}^d_{\\ge 0}$ as the weighted $\\ell_1$ norm $C(\\boldsymbol{\\delta}) = \\sum_{i=0}^{d-1} c_i |\\delta_i|$.\n\nYour task is to design an algorithm that, for a given instance $(\\mathbf{w}, b, \\mathbf{x}, \\mathbf{l}, \\mathbf{u}, \\mathbf{c}, \\mathcal{I})$, computes the minimal cost $C^\\star$ among all plausible edits $\\boldsymbol{\\delta}$ that achieve approval, i.e., that satisfy $\\mathbf{w}^\\top (\\mathbf{x} + \\boldsymbol{\\delta}) + b \\ge 0$. If the original application is already approved, the minimal cost is $0.0$. If no plausible edit can achieve approval, return $-1.0$.\n\nImplement this algorithm as a complete, runnable program that takes no input and evaluates the following fixed test suite. In every case, indices are $0$-based, and all vectors are listed in coordinate order $(0,1,\\dots,d-1)$.\n\nTest Suite (each case specifies $(\\mathbf{w}, b, \\mathbf{x}, \\mathbf{l}, \\mathbf{u}, \\mathbf{c}, \\mathcal{I})$):\n- Case A:\n  - $\\mathbf{w} = (1.0,\\, 0.5,\\, -0.2)$, $b = -0.5$,\n  - $\\mathbf{x} = (0.0,\\, 0.0,\\, 0.0)$,\n  - $\\mathbf{l} = (0.0,\\, -1.0,\\, -1.0)$, $\\mathbf{u} = (2.0,\\, 2.0,\\, 1.0)$,\n  - $\\mathbf{c} = (1.0,\\, 2.0,\\, 1.0)$,\n  - $\\mathcal{I} = \\varnothing$.\n- Case B:\n  - $\\mathbf{w} = (1.0,\\, 1.0)$, $b = -1.0$,\n  - $\\mathbf{x} = (0.6,\\, 0.6)$,\n  - $\\mathbf{l} = (0.0,\\, 0.0)$, $\\mathbf{u} = (1.0,\\, 1.0)$,\n  - $\\mathbf{c} = (1.0,\\, 1.0)$,\n  - $\\mathcal{I} = \\varnothing$.\n- Case C:\n  - $\\mathbf{w} = (0.1,\\, 0.1)$, $b = -5.0$,\n  - $\\mathbf{x} = (0.0,\\, 0.0)$,\n  - $\\mathbf{l} = (0.0,\\, 0.0)$, $\\mathbf{u} = (10.0,\\, 10.0)$,\n  - $\\mathbf{c} = (1.0,\\, 1.0)$,\n  - $\\mathcal{I} = \\varnothing$.\n- Case D:\n  - $\\mathbf{w} = (1.0,\\, 0.5)$, $b = -0.4$,\n  - $\\mathbf{x} = (0.0,\\, 0.0)$,\n  - $\\mathbf{l} = (0.0,\\, 0.0)$, $\\mathbf{u} = (0.1,\\, 2.0)$,\n  - $\\mathbf{c} = (0.1,\\, 10.0)$,\n  - $\\mathcal{I} = \\{0\\}$.\n- Case E:\n  - $\\mathbf{w} = (-1.0)$, $b = -0.4$,\n  - $\\mathbf{x} = (0.0)$,\n  - $\\mathbf{l} = (-1.0)$, $\\mathbf{u} = (1.0)$,\n  - $\\mathbf{c} = (3.0)$,\n  - $\\mathcal{I} = \\varnothing$.\n\nAnswer specification:\n- For each case, compute a single real number equal to the minimal cost $C^\\star$ of a plausible edit that achieves approval, with the convention that if the application is already approved then the answer is $0.0$, and if approval is impossible under the constraints then the answer is $-1.0$.\n- Report each result rounded to $6$ decimal places.\n- Final output format: Your program should produce a single line containing the results for Cases A through E, in that order, as a comma-separated list enclosed in square brackets, with no spaces, for example $[\\alpha,\\beta,\\gamma,\\delta,\\epsilon]$ where each symbol is the rounded result for the corresponding case.",
            "solution": "The problem as stated is valid. It is a well-posed, scientifically grounded optimization problem that is free of contradictions, ambiguities, and unsubstantiated claims. It falls within the domain of computational finance and algorithmic recourse, which is a subfield of computational economics. I will now provide the formal solution.\n\nThe task is to find the minimum cost $C^\\star$ for an edit vector $\\boldsymbol{\\delta} \\in \\mathbb{R}^d$ to a feature vector $\\mathbf{x} \\in \\mathbb{R}^d$ such that a linear classifier's decision boundary is crossed. The cost function is the weighted $\\ell_1$ norm $C(\\boldsymbol{\\delta}) = \\sum_{i=0}^{d-1} c_i |\\delta_i|$. The optimization problem can be formulated as follows:\n$$\n\\begin{align*}\n\\text{minimize} \\quad & C(\\boldsymbol{\\delta}) = \\sum_{i=0}^{d-1} c_i |\\delta_i| \\\\\n\\text{subject to} \\quad & \\mathbf{w}^\\top (\\mathbf{x} + \\boldsymbol{\\delta}) + b \\ge 0 \\\\\n& l_i \\le x_i + \\delta_i \\le u_i \\quad \\forall i \\in \\{0, 1, \\dots, d-1\\} \\\\\n& \\delta_i = 0 \\quad \\forall i \\in \\mathcal{I}\n\\end{align*}\n$$\n\nFirst, we address the trivial case. If the original application $\\mathbf{x}$ is already approved, the score $S_{\\text{initial}} = \\mathbf{w}^\\top \\mathbf{x} + b$ is non-negative, i.e., $S_{\\text{initial}} \\ge 0$. The minimum cost to achieve approval is trivially $0$, by choosing $\\boldsymbol{\\delta} = \\mathbf{0}$, which is a plausible edit.\n\nIf the application is rejected, $S_{\\text{initial}} < 0$. We must find a $\\boldsymbol{\\delta}$ to satisfy the constraints. The approval constraint can be rewritten as $\\mathbf{w}^\\top \\boldsymbol{\\delta} \\ge -(\\mathbf{w}^\\top \\mathbf{x} + b)$. Let $S_{\\text{needed}} = -S_{\\text{initial}} > 0$. The optimization problem is to achieve a total score increase of at least $S_{\\text{needed}}$ with minimum cost. The constraints on $\\delta_i$ for each mutable feature $i \\notin \\mathcal{I}$ are $l_i - x_i \\le \\delta_i \\le u_i - x_i$.\n\nThis problem has a convex objective function (a weighted $\\ell_1$ norm) and a feasible region defined by linear inequalities (a convex polytope). Therefore, a unique minimum exists if the feasible region is non-empty. The structure of the problem is analogous to the continuous knapsack problem, which admits an exact greedy solution.\n\nThe core of the greedy strategy is to prioritize changes to features that provide the largest increase in score per unit of cost. This \"efficiency\" or inverse marginal cost must be calculated for each feature. To increase the score $\\mathbf{w}^\\top\\boldsymbol{\\delta}$, the sign of $w_i \\delta_i$ must be positive. This implies that $\\text{sign}(\\delta_i) = \\text{sign}(w_i)$ for any feature $i$ that contributes positively.\n\nLet us analyze the potential contribution of each mutable feature $i \\notin \\mathcal{I}$ where $w_i \\neq 0$:\n\\begin{itemize}\n    \\item If $w_i > 0$, we must have $\\delta_i > 0$. The change is bounded by $0 < \\delta_i \\le u_i - x_i$. This is only possible if $u_i > x_i$. The score gain is $w_i \\delta_i$ at a cost of $c_i \\delta_i$. The marginal cost, or cost per unit of score gain, is $c_i / w_i$.\n    \\item If $w_i < 0$, we must have $\\delta_i < 0$. The change is bounded by $l_i - x_i \\le \\delta_i < 0$. This is only possible if $l_i < x_i$. The score gain is $w_i \\delta_i = |w_i| |\\delta_i|$ at a cost of $c_i |\\delta_i|$. The marginal cost is $c_i / |w_i| = c_i / (-w_i)$.\n\\end{itemize}\nIn both cases, for a non-zero cost $c_i > 0$, the marginal cost is $c_i / |w_i|$. If $c_i = 0$ and $w_i \\ne 0$, the marginal cost is $0$, which implies score can be gained for free. Such \"free\" changes should always be made first.\n\nThe algorithm is as follows:\n1.  Calculate the initial score $S_{\\text{initial}} = \\mathbf{w}^\\top \\mathbf{x} + b$. If $S_{\\text{initial}} \\ge 0$, the cost is $0.0$.\n2.  Otherwise, calculate the required score increase $S_{\\text{needed}} = -S_{\\text{initial}}$.\n3.  For each mutable feature $i \\notin \\mathcal{I}$ that can contribute to a score increase (i.e., $w_i > 0$ and $u_i > x_i$, or $w_i < 0$ and $l_i < x_i$), create an \"action\" tuple. Each action represents the potential of one feature and contains its marginal cost ($c_i/|w_i|$), the maximum score gain it can provide, and the cost associated with that maximum gain.\n    \\begin{itemize}\n        \\item For $w_i > 0$: max score gain is $w_i (u_i-x_i)$.\n        \\item For $w_i < 0$: max score gain is $w_i (l_i-x_i)$.\n    \\end{itemize}\n4.  Before proceeding, check for impossibility. Sum the maximum possible score gains from all available actions. If this total is less than $S_{\\text{needed}}$, then achieving approval is impossible, and the result is $-1.0$.\n5.  Sort the actions in ascending order of their marginal cost. This places the most efficient changes first.\n6.  Iterate through the sorted actions. For each action, \"purchase\" as much score gain as needed or as much as is available, whichever is less. The cost incurred for a certain amount of score gain is simply the gain multiplied by the action's marginal cost. Update the remaining score needed and the total accumulated cost.\n7.  Continue until the required score $S_{\\text{needed}}$ has been achieved. The final accumulated cost is the minimal cost $C^\\star$.\n\nThis greedy procedure is guaranteed to find the optimal solution because the marginal cost for each feature's contribution is constant. We are, in effect, filling a \"score knapsack\" of size $S_{\\text{needed}}$ with divisible items (score gains) that have different value-to-weight ratios (inverse marginal costs), and the optimal strategy is to always pick the best ratio first.",
            "answer": "```python\nimport numpy as np\n\ndef solve_case(w: np.ndarray, b: float, x: np.ndarray, l: np.ndarray, u: np.ndarray, c: np.ndarray, I: set) -> float:\n    \"\"\"\n    Computes the minimal cost for a plausible edit to achieve loan approval.\n    \"\"\"\n    # 1. Calculate initial score\n    initial_score = np.dot(w, x) + b\n    if initial_score >= 0.0:\n        return 0.0\n\n    score_needed = -initial_score\n\n    # 2. Build list of possible actions\n    actions = []\n    d = len(w)\n    for i in range(d):\n        if i in I:\n            continue\n        \n        wi = w[i]\n        ci = c[i]\n        \n        if wi == 0:\n            continue\n\n        if wi > 0:\n            # We need to increase x_i, so delta_i > 0\n            # Change is bounded by [max(0, l_i-x_i), u_i-x_i]\n            # We are interested in positive delta_i, so max change is u_i-x_i\n            max_delta = u[i] - x[i]\n            if max_delta > 0:\n                max_score_gain = wi * max_delta\n                # Handle c_i = 0 case, which means infinite efficiency (zero cost)\n                cost_per_score = ci / wi if ci > 0 else 0.0\n                actions.append({'cost_per_score': cost_per_score, 'max_gain': max_score_gain})\n        \n        elif wi < 0:\n            # We need to decrease x_i, so delta_i < 0\n            # Change is bounded by [l_i-x_i, min(0, u_i-x_i)]\n            # We are interested in negative delta_i, so max change (magnitude) is x_i - l_i\n            max_delta_magnitude = x[i] - l[i]\n            if max_delta_magnitude > 0:\n                # Actual delta is -(x_i - l_i) = l_i - x_i\n                max_score_gain = wi * (l[i] - x[i]) # both negative, product is positive\n                # Similarly handle c_i = 0\n                cost_per_score = ci / abs(wi) if ci > 0 else 0.0\n                actions.append({'cost_per_score': cost_per_score, 'max_gain': max_score_gain})\n    \n    # 3. Check for impossibility\n    max_possible_gain = sum(action['max_gain'] for action in actions)\n    if max_possible_gain < score_needed:\n        return -1.0\n        \n    # 4. Sort actions by cost-effectiveness (lowest cost per score first)\n    actions.sort(key=lambda p: p['cost_per_score'])\n    \n    # 5. Greedily apply actions\n    total_cost = 0.0\n    remaining_score_needed = score_needed\n    \n    for action in actions:\n        if remaining_score_needed <= 0:\n            break\n            \n        gain_from_this_action = min(remaining_score_needed, action['max_gain'])\n        cost_for_this_gain = gain_from_this_action * action['cost_per_score']\n        \n        total_cost += cost_for_this_gain\n        remaining_score_needed -= gain_from_this_action\n        \n    return total_cost\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {\n            'w': [1.0, 0.5, -0.2], 'b': -0.5,\n            'x': [0.0, 0.0, 0.0],\n            'l': [0.0, -1.0, -1.0], 'u': [2.0, 2.0, 1.0],\n            'c': [1.0, 2.0, 1.0],\n            'I': []\n        },\n        # Case B\n        {\n            'w': [1.0, 1.0], 'b': -1.0,\n            'x': [0.6, 0.6],\n            'l': [0.0, 0.0], 'u': [1.0, 1.0],\n            'c': [1.0, 1.0],\n            'I': []\n        },\n        # Case C\n        {\n            'w': [0.1, 0.1], 'b': -5.0,\n            'x': [0.0, 0.0],\n            'l': [0.0, 0.0], 'u': [10.0, 10.0],\n            'c': [1.0, 1.0],\n            'I': []\n        },\n        # Case D\n        {\n            'w': [1.0, 0.5], 'b': -0.4,\n            'x': [0.0, 0.0],\n            'l': [0.0, 0.0], 'u': [0.1, 2.0],\n            'c': [0.1, 10.0],\n            'I': [0]\n        },\n        # Case E\n        {\n            'w': [-1.0], 'b': -0.4,\n            'x': [0.0],\n            'l': [-1.0], 'u': [1.0],\n            'c': [3.0],\n            'I': []\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        w = np.array(case['w'])\n        b = case['b']\n        x = np.array(case['x'])\n        l = np.array(case['l'])\n        u = np.array(case['u'])\n        c = np.array(case['c'])\n        I = set(case['I'])\n        \n        result = solve_case(w, b, x, l, u, c, I)\n        results.append(result)\n\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Simple rules can lead to surprisingly complex behavior, a central theme in computational social science. This final practice moves from individual strategy to emergent system dynamics, exploring how a simple, deterministic trading algorithm can generate chaotic price fluctuations through market feedback loops. By simulating this model and calculating its Lyapunov exponent, you will see firsthand how deterministic agent behavior can lead to unpredictable outcomes, a profound insight into the complexity of financial markets .",
            "id": "2438789",
            "problem": "Consider a stylized asset market with a deterministic, purely algorithmic trader whose order flow at time $t$, denoted $x_t$, depends only on the two most recent observed prices. Let $P_t$ denote the price at time $t$, and define the one-step return as $r_t = P_t - P_{t-1}$. The trader follows the rule\n$$\nx_t = \\gamma \\, \\big(P_{t-1}-P_{t-2}\\big)\\left(1 - \\frac{P_{t-1}-P_{t-2}}{R_{\\max}}\\right),\n$$\nwhere $\\gamma &gt; 0$ is a responsiveness parameter and $R_{\\max} &gt; 0$ sets a return scale. The price impact mechanism is linear in order flow:\n$$\nP_t = P_{t-1} + \\mu \\, x_t,\n$$\nwhere $\\mu &gt; 0$ is the market impact parameter. There is no stochasticity or external intervention. Initial conditions are $P_{-1}$ and $P_0$, which determine the initial return $r_0 = P_0 - P_{-1}$. Define the normalized return $y_t = r_t / R_{\\max}$.\n\nTasks:\n1) For each parameter set in the test suite below, simulate the deterministic dynamics implied by the above rules, starting from the given initial conditions. Use the trajectory of $y_t$ to compute the largest Lyapunov exponent $\\lambda$ of the one-dimensional return map in the sense of the definition\n$$\n\\lambda = \\lim_{T \\to \\infty} \\frac{1}{T} \\sum_{t=1}^{T} \\ln \\left| \\frac{\\partial y_t}{\\partial y_{t-1}} \\right|,\n$$\nevaluated along the deterministic trajectory generated by the given algorithm and market impact, with the understanding that any finite-time computation is an approximation to this limit. You must not introduce any randomness. Use the provided finite horizons to approximate the limit: discard the first $T_{\\mathrm{burn}}$ steps as transient and then average over the subsequent $T_{\\mathrm{eval}}$ steps.\n2) For each parameter set, output the estimated largest Lyapunov exponent as a real number.\n\nTest suite (each tuple is $(\\mu,\\gamma,R_{\\max},P_{-1},P_0,T_{\\mathrm{burn}},T_{\\mathrm{eval}})$):\n- Case A: $(1.0,\\, 2.5,\\, 1.0,\\, 0.0,\\, 0.4,\\, 1000,\\, 5000)$\n- Case B: $(1.0,\\, 3.2,\\, 1.0,\\, 0.0,\\, 0.4,\\, 1000,\\, 5000)$\n- Case C: $(1.0,\\, 3.569945,\\, 1.0,\\, 0.0,\\, 0.4,\\, 1000,\\, 5000)$\n- Case D: $(1.0,\\, 3.9,\\, 1.0,\\, 0.0,\\, 0.4,\\, 1000,\\, 5000)$\n- Case E: $(1.0,\\, 4.0,\\, 1.0,\\, 0.0,\\, 0.4,\\, 1000,\\, 5000)$\n\nAnswer specification:\n- For each case, the answer must be a single real number (a float) representing the estimated largest Lyapunov exponent.\n- Your program should produce a single line of output containing the results for Cases A through E, in order, as a comma-separated list enclosed in square brackets (for example, $[x_1,x_2,x_3,x_4,x_5]$), where each $x_i$ is rounded to four decimals.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. All necessary parameters, initial conditions, and governing equations are provided, forming a self-contained and consistent mathematical problem. The model, while stylized, is a valid representation of a deterministic agent-based market model, and its analysis using the Lyapunov exponent is a standard technique in the study of dynamical systems. No contradictions or ambiguities are present. Therefore, we may proceed with the solution.\n\nThe problem requires the computation of the largest Lyapunov exponent for a system describing the dynamics of an asset price under the influence of an algorithmic trader. The core of the task is to first establish the underlying one-dimensional map governing the system's evolution and then to apply the definition of the Lyapunov exponent.\n\nLet us define the return at time $t$ as $r_t = P_t - P_{t-1}$. The price impact mechanism is given as $P_t = P_{t-1} + \\mu \\, x_t$, where $\\mu > 0$ is the market impact parameter and $x_t$ is the trader's order flow. From this, we can express the return directly in terms of the order flow:\n$$\nr_t = (P_{t-1} + \\mu \\, x_t) - P_{t-1} = \\mu \\, x_t\n$$\n\nThe order flow $x_t$ is determined by the rule:\n$$\nx_t = \\gamma \\, \\big(P_{t-1}-P_{t-2}\\big)\\left(1 - \\frac{P_{t-1}-P_{t-2}}{R_{\\max}}\\right)\n$$\nwhere $\\gamma > 0$ is a responsiveness parameter and $R_{\\max} > 0$ is a return scale. Recognizing that $P_{t-1} - P_{t-2} = r_{t-1}$, we can rewrite the order flow as a function of the previous return:\n$$\nx_t = \\gamma \\, r_{t-1}\\left(1 - \\frac{r_{t-1}}{R_{\\max}}\\right)\n$$\n\nSubstituting this expression for $x_t$ into our equation for $r_t$ yields a recurrence relation for the returns:\n$$\nr_t = \\mu \\gamma \\, r_{t-1}\\left(1 - \\frac{r_{t-1}}{R_{\\max}}\\right)\n$$\n\nThe problem asks for an analysis in terms of the normalized return, $y_t = r_t / R_{\\max}$. To derive the map for $y_t$, we start with the recurrence relation for returns and substitute $r_t = y_t R_{\\max}$:\n$$\ny_t R_{\\max} = \\mu \\gamma \\, (y_{t-1} R_{\\max})\\left(1 - \\frac{y_{t-1} R_{\\max}}{R_{\\max}}\\right)\n$$\nSimplifying this equation gives:\n$$\ny_t R_{\\max} = \\mu \\gamma \\, y_{t-1} R_{\\max} \\left(1 - y_{t-1}\\right)\n$$\nDividing both sides by $R_{\\max}$ yields the final map for the normalized return:\n$$\ny_t = \\mu \\gamma y_{t-1}(1-y_{t-1})\n$$\nThis is the canonical logistic map, $y_t = f(y_{t-1})$, where the map function is $f(y) = k y (1-y)$ and the control parameter $k$ is the product of the market impact and trader responsiveness parameters, $k = \\mu \\gamma$.\n\nThe largest Lyapunov exponent $\\lambda$ for a one-dimensional map is given by:\n$$\n\\lambda = \\lim_{T \\to \\infty} \\frac{1}{T} \\sum_{t=1}^{T} \\ln \\left| \\frac{\\partial y_t}{\\partial y_{t-1}} \\right| = \\lim_{T \\to \\infty} \\frac{1}{T} \\sum_{t=1}^{T} \\ln \\left| f'(y_{t-1}) \\right|\n$$\nwhere the derivative of the map function is $f'(y) = \\frac{d}{dy}[k y(1-y)] = k - 2ky$. The summation is evaluated over the trajectory of the system, $\\{y_0, y_1, y_2, \\dots\\}$.\n\nWe will approximate this limit numerically as specified. For each parameter set, we perform the following steps:\n1.  Calculate the control parameter $k = \\mu \\gamma$.\n2.  Determine the initial normalized return $y_0 = (P_0 - P_{-1}) / R_{\\max}$.\n3.  Simulate the trajectory starting from $y_0$ for $T_{\\mathrm{burn}} + T_{\\mathrm{eval}}$ iterations. The first $T_{\\mathrm{burn}}$ iterations are discarded to allow the system to settle onto its attractor.\n4.  For the subsequent $T_{\\mathrm{eval}}$ iterations, we compute the sum of the logarithms of the absolute value of the map's derivative. The Lyapunov exponent is the average of these values:\n    $$\n    \\lambda \\approx \\frac{1}{T_{\\mathrm{eval}}} \\sum_{t=T_{\\mathrm{burn}}}^{T_{\\mathrm{burn}}+T_{\\mathrm{eval}}-1} \\ln \\left| k - 2k y_t \\right|\n    $$\n    Here, the sum is over the points $y_t$ on the attractor.\n\nThis procedure is implemented for each test case to obtain the estimated Lyapunov exponent. The initial condition for all cases is $y_0 = (0.4 - 0.0) / 1.0 = 0.4$. The parameter $k = \\mu\\gamma$ varies across cases, leading to different dynamical regimes of the logistic map (stable fixed point, periodic cycles, and chaos), which will be reflected in the sign and magnitude of $\\lambda$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of calculating the Lyapunov exponent for a stylized\n    asset market model, which reduces to the logistic map.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (mu, gamma, R_max, P_m1, P_0, T_burn, T_eval)\n        (1.0, 2.5, 1.0, 0.0, 0.4, 1000, 5000),\n        (1.0, 3.2, 1.0, 0.0, 0.4, 1000, 5000),\n        (1.0, 3.569945, 1.0, 0.0, 0.4, 1000, 5000),\n        (1.0, 3.9, 1.0, 0.0, 0.4, 1000, 5000),\n        (1.0, 4.0, 1.0, 0.0, 0.4, 1000, 5000),\n    ]\n\n    results = []\n    for case in test_cases:\n        mu, gamma, R_max, P_m1, P_0, T_burn, T_eval = case\n\n        # Step 1: Calculate the control parameter k of the logistic map.\n        # The dynamics of the normalized return y_t = r_t / R_max follow\n        # the logistic map y_t = k * y_{t-1} * (1 - y_{t-1}),\n        # where k = mu * gamma.\n        k = mu * gamma\n\n        # Step 2: Calculate the initial normalized return y_0.\n        r_0 = P_0 - P_m1\n        y_0 = r_0 / R_max\n\n        # The state of the system is given by the normalized return y.\n        y = y_0\n        \n        # Step 3: Simulate the system.\n        log_deriv_sum = 0.0\n        \n        # The total number of iterations is the sum of burn-in and evaluation periods.\n        num_iterations = T_burn + T_eval\n\n        for t in range(num_iterations):\n            # The derivative of the map f(y) = k*y*(1-y) is f'(y) = k - 2*k*y.\n            # We evaluate ln|f'(y_t)| for t >= T_burn.\n            if t >= T_burn:\n                # The derivative value depends on the current state y.\n                # A potential issue is y=0.5, which makes the derivative zero\n                # and its logarithm negative infinity. With floating point arithmetic,\n                # an exact hit is highly improbable.\n                deriv_val = k - 2.0 * k * y\n                log_deriv_sum += np.log(np.abs(deriv_val))\n            \n            # Update the state to the next time step using the logistic map.\n            y = k * y * (1.0 - y)\n\n        # Step 4: Calculate the Lyapunov exponent as the average of the log-derivatives.\n        if T_eval > 0:\n            lyapunov_exp = log_deriv_sum / T_eval\n        else:\n            lyapunov_exp = 0.0 # Define as 0 if T_eval is 0.\n        \n        results.append(lyapunov_exp)\n\n    # Final print statement in the exact required format.\n    # The results are rounded to four decimal places.\n    formatted_results = [f\"{res:.4f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}