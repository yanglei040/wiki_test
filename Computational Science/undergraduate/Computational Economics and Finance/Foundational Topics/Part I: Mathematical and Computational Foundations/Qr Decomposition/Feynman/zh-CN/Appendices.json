{
    "hands_on_practices": [
        {
            "introduction": "我们首先从一个思想实验开始，以建立对QR分解核心性质的直观理解。如果一个矩阵的各列已经满足了正交性，我们对其进行QR分解会发生什么？这个练习将揭示在理想条件下分解的唯一性和结构，为我们理解更复杂的情况奠定坚实的基础。",
            "id": "2423932",
            "problem": "在一个横截面资产定价应用中，设 $X \\in \\mathbb{R}^{n\\times k}$ 表示一个设计矩阵，其包含了在 $n$ 个资产上观测到的 $k$ 个预先构建的因子实现。这些因子已被白化，使得 $X$ 的列在欧几里得内积下是标准正交的，即 $X^{\\top} X = I_k$。考虑不带列主元（column pivoting）的瘦QR分解（thin orthogonal–triangular (QR) decomposition），定义为 $X = QR$，其中 $Q \\in \\mathbb{R}^{n\\times k}$ 满足 $Q^{\\top} Q = I_k$，$R \\in \\mathbb{R}^{k\\times k}$ 是一个对角线元素严格为正的上三角矩阵。下列哪个陈述最能描述得到的因子 $Q$ 和 $R$？\n\nA. $Q = X$ 且 $R = I_k$。\n\nB. $Q = X D$ 且 $R = D$，其中 $D$ 是任意一个对角线元素为 $\\pm 1$ 的对角矩阵，因为即使在正对角线约定下，QR分解仍然不唯一。\n\nC. $Q = I_n$ 且 $R = X^{\\top}$，因为 $X$ 的正交性会转移到 $R$。\n\nD. $Q = X$ 且 $R$ 是一个任意的对角线元素为正的上三角正交矩阵，不一定等于 $I_k$。\n\nE. $Q$ 等于 $X^{\\top} X$ 的特征向量，$R$ 等于特征值构成的对角矩阵，因为对于正交的 $X$，QR分解与特征值分解重合。",
            "solution": "首先必须验证问题陈述的科学性和逻辑完整性。\n\n已知条件如下：\n1.  一个矩阵 $X \\in \\mathbb{R}^{n\\times k}$。\n2.  $X$ 的列是标准正交的，这意味着 $X^{\\top} X = I_k$。这蕴含了 $n \\ge k$。\n3.  $X$ 的瘦QR分解为 $X = QR$。\n4.  $Q \\in \\mathbb{R}^{n\\times k}$ 具有标准正交的列，即 $Q^{\\top} Q = I_k$。\n5.  $R \\in \\mathbb{R}^{k\\times k}$ 是上三角矩阵。\n6.  $R$ 的对角线元素严格为正，即对于 $i=1, \\dots, k$，有 $R_{ii} > 0$。\n\n该问题在数学上是良定义且自洽的。这是线性代数中一个关于QR分解应用于具有标准正交列的矩阵时的性质的标准问题。前提条件是一致的，术语是精确的。问题是有效的。我们可以开始求解。\n\n问题要求在给定条件下确定矩阵 $Q$ 和 $R$。我们从分解的定义方程开始：\n$$X = QR$$\n我们已知 $X$ 的列是标准正交的，即 $X^{\\top}X = I_k$。我们将QR分解代入这个条件：\n$$(QR)^{\\top}(QR) = I_k$$\n使用乘积的转置性质 $(AB)^{\\top} = B^{\\top}A^{\\top}$，我们得到：\n$$R^{\\top}Q^{\\top}QR = I_k$$\n根据瘦QR分解的定义，$Q$ 是一个具有标准正交列的矩阵，所以 $Q^{\\top}Q = I_k$。方程简化为：\n$$R^{\\top}I_k R = I_k$$\n$$R^{\\top}R = I_k$$\n这个结果表明矩阵 $R$ 是一个正交矩阵。\n\n现在我们已经确定了矩阵 $R$ 的两个基本性质：\n1.  $R$ 是一个对角线元素严格为正的上三角矩阵。\n2.  $R$ 是一个正交矩阵。\n\n让我们来分析一个矩阵同时满足这两个性质所蕴含的意义。由于 $R$ 是正交的，它的逆等于它的转置：$R^{-1} = R^{\\top}$。上三角矩阵的逆也是上三角矩阵。上三角矩阵的转置是下三角矩阵。\n因此，矩阵 $R^{\\top}$ 必须既是下三角矩阵（因为它是上三角矩阵 $R$ 的转置），又是上三角矩阵（因为它是上三角矩阵 $R$ 的逆）。一个同时是上三角和下三角的矩阵必须是对角矩阵。\n所以，$R^{\\top}$ 是一个对角矩阵。这意味着 $R$ 本身也必须是一个对角矩阵。\n\n我们有一个对角矩阵 $R$，它同时也是正交的。对于一个对角矩阵而言，要成为正交矩阵，它的列（每列只有一个非零元素）的模必须为1。如果 $R_{ii}$ 是对角元素，这意味着对于所有的 $i$ 都有 $R_{ii}^2 = 1$。因此，对角元素必须是 $+1$ 或 $-1$。\n然而，问题陈述施加了一个额外的约束：$R$ 的对角线元素必须严格为正。\n$$R_{ii} > 0$$\n将此与 $R_{ii}^2 = 1$ 结合，唯一可能的值是对于所有 $i=1, \\dots, k$，都有 $R_{ii} = 1$。\n这迫使矩阵 $R$ 必须是大小为 $k \\times k$ 的单位矩阵：\n$$R = I_k$$\n现在我们来确定 $Q$。将 $R = I_k$ 代回原始的分解方程：\n$$X = QR = Q I_k = Q$$\n因此，我们必须有 $Q = X$。\n\n满足所有给定条件的唯一解是 $Q=X$ 和 $R=I_k$。这是一个基本结论：一个具有标准正交列的矩阵的QR分解（要求 $R$ 的对角线为正）的结果是该矩阵本身和单位矩阵。\n\n现在我们评估所提供的选项：\n\nA. $Q = X$ 且 $R = I_k$。\n这个陈述与我们推导出的结果完全一致。所有条件都得到满足：$X = X \\cdot I_k$；由于 $X^{\\top}X=I_k$，$Q=X$ 具有标准正交的列；$R=I_k$ 是上三角矩阵且具有正的对角线元素（全为 $1$）。此陈述**正确**。\n\nB. $Q = X D$ 且 $R = D$，其中 $D$ 是任意一个对角线元素为 $\\pm 1$ 的对角矩阵，因为即使在正对角线约定下，QR分解仍然不唯一。\n这个陈述由于两个原因是不正确的。首先，对于一个满秩矩阵，在 $R$ 的对角线为正的约定下，QR分解是唯一的。由于 $X$ 的列是标准正交的，它是列满秩的，所以其分解是唯一的。关于非唯一性的说法是错误的。其次，要使 $R=D$ 成为一个有效的因子，其对角线元素必须严格为正。这迫使 $D$ 的对角线上只有 $+1$，即 $D=I_k$。该选项允许元素为 $-1$ 违反了此条件。此陈述**不正确**。\n\nC. $Q = I_n$ 且 $R = X^{\\top}$，因为 $X$ 的正交性会转移到 $R$。\n这个陈述在维度上有缺陷。瘦QR分解要求 $Q \\in \\mathbb{R}^{n \\times k}$。$I_n$ 是一个 $n \\times n$ 的矩阵。只有在 $n=k$ 时，此选项才可能。但即使 $n=k$，分解也会是 $X = I_n X^{\\top} = X^{\\top}$，这对于一个正交矩阵 $X$ 来说通常是不成立的。此外，$R=X^{\\top}$ 不保证是上三角矩阵。“$X$ 的正交性会转移到 $R$”这一推理不是线性代数的一个原理。此陈述**不正确**。\n\nD. $Q = X$ 且 $R$ 是一个任意的对角线元素为正的上三角正交矩阵，不一定等于 $I_k$。\n这个陈述暗示了 $R$ 中存在一种不存在的非唯一性。如上文严格证明的，上三角、正交和正对角线元素这几个条件的组合唯一地确定了单位矩阵 $I_k$。除了 $I_k$ 之外，不存在这样的“任意”矩阵。短语“不一定等于 $I_k$”与数学事实直接矛盾。此陈述**不正确**。\n\nE. $Q$ 等于 $X^{\\top} X$ 的特征向量，$R$ 等于特征值构成的对角矩阵，因为对于正交的 $X$，QR分解与特征值分解重合。\n这个陈述将QR分解与特征值分解混为一谈。它们是不同的概念。我们已知 $X^{\\top}X=I_k$。$I_k$ 的所有特征值都为 $1$，所以特征值构成的对角矩阵将是 $I_k$。这与我们对 $R$ 的结果相符。然而，$I_k$ 的特征向量可以是 $\\mathbb{R}^k$ 中任意 $k$ 个线性无关的向量。由这些特征向量构成的矩阵将是一个 $k \\times k$ 的矩阵。而矩阵 $Q$ 是一个 $n \\times k$ 的矩阵。这里存在维度不匹配。所提供的推理完全是错误的。此陈述**不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在掌握了QR分解的基本概念后，我们将目光转向其在金融计量中的核心应用：线性回归。这个练习探讨了普通最小二乘法 (OLS) 的一个基本几何性质——残差与回归量的正交性。尽管QR分解是求解OLS问题的强大数值工具，但这个练习更侧重于理解其背后的根本原理，即正交投影，这正是使数值求解成为可能的理论基石。",
            "id": "2423936",
            "problem": "考虑一个用于计算金融的简化线性因子模型，该模型涵盖连续三个周期。令响应向量为风险资产的超额回报 $y \\in \\mathbb{R}^{3}$，回归矩阵为 $X \\in \\mathbb{R}^{3 \\times 2}$，包含一个截距项和一个去均值的宏观冲击：\n$$\ny \\;=\\; \\begin{pmatrix} 0.010 \\\\ 0.012 \\\\ 0.008 \\end{pmatrix}, \n\\qquad\nX \\;=\\; \\begin{pmatrix}\n1 & 1 \\\\\n1 & 0 \\\\\n1 & -1\n\\end{pmatrix}.\n$$\n考虑普通最小二乘 (OLS) 回归 $y = X \\beta + \\varepsilon$，并令 $\\hat{\\beta}$ 为最小化欧几里得范数 $\\|y - X \\beta\\|_{2}$ 的系数向量。定义残差向量 $e = y - X \\hat{\\beta}$。令 $X$ 的瘦QR分解为 $X = Q R$，其中 $Q \\in \\mathbb{R}^{3 \\times 2}$ 具有标准正交列，而 $R \\in \\mathbb{R}^{2 \\times 2}$ 为上三角矩阵。记 $X$ 的第二列为 $x_{2} \\in \\mathbb{R}^{3}$。\n\n计算 $e^{\\top} x_{2}$ 的标量值。请以精确实数形式提供您的答案。",
            "solution": "该问题要求计算标量值 $e^{\\top} x_{2}$，其中 $e$ 是普通最小二乘 (OLS) 回归的残差向量，$x_{2}$ 是回归矩阵 $X$ 的一个列向量。\n\nOLS回归模型由 $y = X \\beta + \\varepsilon$ 给出。OLS估计量 $\\hat{\\beta}$ 是使残差平方和最小化的向量，这等价于最小化残差向量的欧几里得范数的平方，即 $\\|y - X \\beta\\|_{2}^{2}$。\n\n从几何上看，这个最小化问题有一个清晰的解释。拟合值向量 $\\hat{y} = X \\hat{\\beta}$ 是观测响应向量 $y$ 在由回归矩阵 $X$ 的列向量所张成的子空间上的正交投影。这个子空间被称为 $X$ 的列空间，记作 $\\text{Col}(X)$。\n\n残差向量定义为观测值与拟合值之差：\n$$\ne = y - \\hat{y} = y - X \\hat{\\beta}\n$$\n根据正交投影的定义，连接原始点 $y$ 与其投影点 $\\hat{y}$ 的向量（即残差向量 $e$）必须与投影所在的子空间正交。因此，残差向量 $e$与列空间 $\\text{Col}(X)$ 正交。\n\n此正交性条件意味着残差向量 $e$ 与列空间 $\\text{Col}(X)$ 中的任何向量的内积（或点积）都必须为零。根据定义，矩阵 $X$ 的列向量本身就是 $\\text{Col}(X)$ 内的向量。\n\n回归矩阵 $X$ 如下：\n$$\nX = \\begin{pmatrix} 1 & 1 \\\\ 1 & 0 \\\\ 1 & -1 \\end{pmatrix}\n$$\n记 $X$ 的列向量为 $x_1$ 和 $x_2$。\n$$\nx_1 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\qquad x_2 = \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix}\n$$\n问题明确要求计算 $e^{\\top} x_2$ 的值。\n由于 $x_2$ 是矩阵 $X$ 的第二列，它是 $X$ 的列空间的一个元素（即 $x_2 \\in \\text{Col}(X)$）。\n\n根据OLS残差的基本正交性质，残差向量 $e$ 必须与 $\\text{Col}(X)$ 中的每个向量正交。因此，$e$ 必须与 $x_2$ 正交。两个正交向量的内积为零。\n$$\ne^{\\top} x_2 = 0\n$$\n这个结果是普通最小二乘法定义的直接推论，并对任何有效的OLS问题都成立。没有必要计算系数向量 $\\hat{\\beta}$、残差向量 $e$ 的具体数值，也无需执行 $X$ 的QR分解。所提供的 $y$ 和 $X$ 的数值数据与一个标准的、适定的线性回归问题相符，对于这类问题，这一理论性质必然成立。提及QR分解只是将问题置于求解OLS的数值方法的背景下，但对于这个问题本身并不需要进行分解。残差与回归量（自变量）的正交性是线性回归理论中最基本的性质之一。",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "最后，我们将理论付诸实践，解决金融建模中一个常见而关键的挑战：多重共线性。这个动手编程练习将指导你如何运用带列主元的QR分解作为一种稳健的数据预处理工具。你将通过实现一个算法，来识别并剔除数据集中的冗余特征，从而确保后续模型（如回归模型）的稳定性和可靠性。",
            "id": "2424018",
            "problem": "你的任务是为信用评分数据集设计一个数据预处理算法。该数据集表示为一个实值矩阵 $X \\in \\mathbb{R}^{m \\times n}$，其中有 $m$ 个观测值（行）和 $n$ 个特征（列）。在计算经济学和金融学中，移除线性相关的特征是在训练诸如 Ordinary Least Squares (OLS) 等模型之前的先决条件。目标是使用带列主元的正交三角(QR)分解来识别并移除模型拟合前的线性相关或冗余特征。\n\n从核心线性代数定义和事实出发：\n- 一组列 $\\{x_1, \\dots, x_n\\}$ 是线性无关的，当且仅当方程 $\\sum_{j=1}^{n} \\alpha_j x_j = 0$ 的唯一解是 $\\alpha_1 = \\cdots = \\alpha_n = 0$。\n- 矩阵 $X$ 的秩是其列空间的维度，等于最大线性无关列的数量。\n- 带列主元的 QR 分解产生一个置换矩阵 $P$ 以及矩阵 $Q$ 和 $R$，使得 $X P = Q R$ 成立。其中 $Q$ 具有标准正交列，$R$ 是上三角矩阵；该置换编码了一种列的排序，从而揭示了一个数值稳定的无关子集。\n\n设计一个程序，实现一个数值稳健的例程，使用带列主元的 QR 分解来选择一组列索引，这些列构成一个极大线性无关子集（在数值秩的意义上）。你的例程必须：\n- 接受一个矩阵 $X$。\n- 计算带列主元的 QR 分解以获得列的置换。\n- 通过计算 $R$ 的主对角线上相对于机器精度和从分解中推断出的尺度参数而言显著非零的元素数量，来确定数值秩 $r$。\n- 以严格递增的顺序返回保留列（来自原始矩阵）的从零开始的索引。\n\n你的程序必须硬编码并解决以下矩阵 $X$ 的测试套件（每个测试用例都是一个矩阵 $X$）。对于每个用例，按照上述描述返回保留列索引的列表。所有矩阵均以列向量形式给出，所有条目均为实数。索引是从零开始的。\n\n测试套件：\n- 案例 $1$（矩形，一个精确的线性相关性，“理想路径”）：$X_1 \\in \\mathbb{R}^{6 \\times 4}$，列向量为\n  - $x^{(1)} = [\\,1,\\ 2,\\ 0,\\ 0,\\ 3,\\ 0\\,]^\\top$,\n  - $x^{(2)} = [\\,0,\\ 1,\\ 1,\\ 0,\\ 0,\\ 2\\,]^\\top$,\n  - $x^{(3)} = [\\,2,\\ 0,\\ 1,\\ 1,\\ 0,\\ 0\\,]^\\top$,\n  - $x^{(4)} = x^{(1)} + 2 x^{(2)}$。\n- 案例 $2$（方阵，满秩）：$X_2 \\in \\mathbb{R}^{5 \\times 5}$ 是 5 阶单位矩阵。\n- 案例 $3$（宽矩阵，特征多于观测值，有重复列）：$X_3 \\in \\mathbb{R}^{3 \\times 5}$，列向量为\n  - $e_1 = [\\,1,\\ 0,\\ 0\\,]^\\top$,\n  - $e_2 = [\\,0,\\ 1,\\ 0\\,]^\\top$,\n  - $e_3 = [\\,0,\\ 0,\\ 1\\,]^\\top$,\n  - $d_1 = e_2$,\n  - $d_2 = e_1$。\n- 案例 $4$（包含一个零列和一个重复列）：$X_4 \\in \\mathbb{R}^{4 \\times 4}$，列向量为\n  - $c_0 = [\\,1,\\ 0,\\ 0,\\ 0\\,]^\\top$,\n  - $c_1 = [\\,0,\\ 0,\\ 0,\\ 0\\,]^\\top$,\n  - $c_2 = [\\,1,\\ 1,\\ 0,\\ 0\\,]^\\top$,\n  - $c_3 = c_0$。\n- 案例 $5$（线性无关但尺度病态的特征）：$X_5 \\in \\mathbb{R}^{4 \\times 3}$，列向量为\n  - $u_1 = [\\,1,\\ 0,\\ 0,\\ 0\\,]^\\top$,\n  - $u_2 = [\\,0,\\ 10^{-8},\\ 0,\\ 0\\,]^\\top$,\n  - $u_3 = [\\,0,\\ 0,\\ 10^{8},\\ 0\\,]^\\top$。\n\n实现要求：\n- 使用双精度浮点运算和带列主元的 QR 分解来确定列的置换和上三角因子。\n- 使用基于浮点机器精度和从分解中推断出的尺度的有原则的容差来决定数值秩。\n- 为每个测试用例返回保留列的从零开始的索引，并按严格递增顺序排序。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含所有测试用例的结果，格式为单个列表的列表，不含空格。每个内部列表包含对应测试用例的保留列索引，按升序排列。例如，包含三个案例的输出可能看起来像 $[[0,1],[0,2],[0,1,3]]$（这只是一个格式示例）。\n- 要求的输出类型是整数列表的列表。",
            "solution": "所述问题是有效的。它提出了一个数值线性代数中明确定义的任务，直接适用于计量经济学等定量领域的特征选择。该问题具有科学依据、内部一致，并要求设计一个数值稳健的算法，这是一个标准且有意义的练习。我将继续提供完整解决方案。\n\n这个问题的核心在于区分线性无关的理论概念与其在实践中的计算等价物，后者必须应对浮点运算的局限性。一组理论上相关的向量可能不会产生精确的零向量，而是产生一个范数非常小的向量。反之，一组病态但理论上无关的向量可能表现得如同它们是相关的。因此，我们必须使用*数值秩*的概念。\n\n完成这项任务的合适工具是带列主元的 QR 分解。对于一个给定的矩阵 $X \\in \\mathbb{R}^{m \\times n}$，该分解找到一个置换矩阵 $P$，一个正交矩阵 $Q \\in \\mathbb{R}^{m \\times m}$（意味着 $Q^\\top Q = I$），以及一个上三角矩阵 $R \\in \\mathbb{R}^{m \\times n}$，使得：\n$$\nX P = Q R\n$$\n置换矩阵 $P$ 根据一种贪心策略对 $X$ 的列进行重排。在分解过程的每一步 $k$（从 $k=0$ 到 $n-1$），算法会选择剩余列中与已选列“最无关”的那一列。这通常是其分量与先前选定列所张成的子空间正交且具有最大欧几里得范数的列。此策略确保了得到的上三角矩阵 $R$ 的对角线元素按大小降序排列：\n$$\n|R_{00}| \\ge |R_{11}| \\ge \\dots \\ge |R_{n-1, n-1}|\n$$\n这些对角线元素 $R_{kk}$ 代表了 $X$ 的第 $(k+1)$ 个置换列中与前 $k$ 个置换列所张成的子空间正交的分量的范数。一个很小的 $|R_{kk}|$ 值表明 $XP$ 的第 $(k+1)$ 列与前面的 $k$ 列近似线性相关。\n\n于是，确定数值秩 $r$ 就变成了一个识别这种数量级骤降发生位置的问题。我们必须定义一个容差 $\\tau$，以区分“显著的”对角元素和“数值上为零的”对角元素。一个有原则的容差必须是相对的，而非绝对的。它应随数据的大小进行缩放，并考虑机器精度。对此容差的一个标准且稳健的选择由下式给出：\n$$\n\\tau = \\max(m, n) \\cdot \\varepsilon_{\\text{mach}} \\cdot |R_{00}|\n$$\n此处, $\\varepsilon_{\\text{mach}}$ 是所用浮点精度的机器ε（对于双精度，$\\varepsilon_{\\text{mach}} \\approx 2.22 \\times 10^{-16}$）。$|R_{00}|$ 是 $R$ 的最大对角元素，作为矩阵 $X$ 的一个尺度因子。因子 $\\max(m, n)$ 则考虑了在一个 $m \\times n$ 矩阵的分解中浮点误差的潜在累积。\n\n数值秩 $r$ 于是被定义为 $R$ 的对角线元素中绝对值大于此容差 $\\tau$ 的数量：\n$$\nr = |\\{k \\mid |R_{kk}| > \\tau, k = 0, \\dots, n-1\\}|\n$$\n\n从原始矩阵 $X$ 中提取极大线性无关列集索引的算法如下：\n\n1.  对于输入的矩阵 $X \\in \\mathbb{R}^{m \\times n}$，计算带列主元的 QR 分解。这将得到矩阵 $Q$ 和 $R$，以及一个置换向量 $P_{\\text{idx}}$，该向量包含 $X$ 的列在其置换顺序下的从0开始的索引。例如，如果 $P_{\\text{idx}} = [2, 0, 1, \\dots]$，意味着置换后矩阵 $XP$ 的第一列是原始的列 $x_2$，第二列是 $x_0$，以此类推。\n\n2.  建立用于确定秩的容差 $\\tau$。如果矩阵为空或仅由零列组成，则秩为 $0$。否则，计算 $\\tau = \\max(m, n) \\cdot \\varepsilon_{\\text{mach}} \\cdot |R_{00}|$。\n\n3.  通过从 $k=0$ 到 $n-1$ 遍历 $R$ 的对角线，并计算满足 $|R_{kk}| > \\tau$ 的元素数量，来确定数值秩 $r$。\n\n4.  置换向量中的前 $r$ 个索引 $\\{P_{\\text{idx}}[0], P_{\\text{idx}}[1], \\dots, P_{\\text{idx}}[r-1]\\}$，对应于一个极大线性无关列集的原始列索引。\n\n5.  根据题目要求，将这 $r$ 个索引按严格递增顺序排序，以产生最终结果。\n\n这个过程是数值稳定的，并为从数据集中识别和移除冗余特征提供了一种可靠的方法，这是许多统计和机器学习模型的一个关键预处理步骤。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import qr\n\ndef solve():\n    \"\"\"\n    Solves the problem of finding a maximal set of linearly independent column\n    indices for a series of test matrices using QR decomposition with column pivoting.\n    \"\"\"\n\n    # Test Case 1: Rectangular, one exact linear dependency\n    # x4 = x1 + 2 * x2\n    X1 = np.array([\n        [1.0, 0.0, 2.0, 1.0],\n        [2.0, 1.0, 0.0, 4.0],\n        [0.0, 1.0, 1.0, 2.0],\n        [0.0, 0.0, 1.0, 0.0],\n        [3.0, 0.0, 0.0, 3.0],\n        [0.0, 2.0, 0.0, 4.0]\n    ])\n\n    # Test Case 2: Square, full rank (identity matrix)\n    X2 = np.identity(5)\n\n    # Test Case 3: Wide matrix with duplicate columns\n    X3 = np.array([\n        [1.0, 0.0, 0.0, 0.0, 1.0],\n        [0.0, 1.0, 0.0, 1.0, 0.0],\n        [0.0, 0.0, 1.0, 0.0, 0.0]\n    ])\n\n    # Test Case 4: Contains a zero column and a duplicate column\n    X4 = np.array([\n        [1.0, 0.0, 1.0, 1.0],\n        [0.0, 0.0, 1.0, 0.0],\n        [0.0, 0.0, 0.0, 0.0],\n        [0.0, 0.0, 0.0, 0.0]\n    ])\n\n    # Test Case 5: Independent but ill-scaled features\n    X5 = np.array([\n        [1.0, 0.0, 0.0],\n        [0.0, 1e-8, 0.0],\n        [0.0, 0.0, 1e8],\n        [0.0, 0.0, 0.0]\n    ]).T # Transpose to match column-vector definition in problem\n\n    test_cases = [X1, X2, X3, X4, X5]\n    \n    final_results = []\n\n    for X in test_cases:\n        if X.size == 0:\n            final_results.append([])\n            continue\n\n        # Compute QR decomposition with column pivoting\n        # Q is the orthogonal matrix\n        # R is the upper triangular matrix\n        # P is the permutation vector of column indices\n        Q, R, P = qr(X, pivoting=True)\n\n        m, n = X.shape\n        \n        # Determine the numerical rank using a principled tolerance\n        # The tolerance is based on machine precision and a scale factor from the matrix.\n        if R.size == 0 or np.abs(R[0, 0]) == 0:\n            rank = 0\n        else:\n            # The tolerance is scaled by the largest diagonal element of R,\n            # matrix dimensions, and machine epsilon.\n            tol = np.max([m, n]) * np.finfo(R.dtype).eps * np.abs(R[0, 0])\n            \n            # The rank is the number of diagonal elements of R greater than the tolerance.\n            diag_R = np.abs(np.diag(R))\n            rank = np.sum(diag_R > tol)\n\n        # The first 'rank' elements of the permutation vector P are the indices\n        # of the columns forming a maximal linearly independent set.\n        retained_indices = P[:rank]\n        \n        # Sort the indices in strictly increasing order as required.\n        retained_indices.sort()\n        \n        # Convert to a list of standard Python integers for the output format.\n        final_results.append([int(i) for i in retained_indices])\n\n    # Final print statement in the exact required format.\n    # e.g., [[0,1,2],[0,1,2,3,4],[0,1,2],[0,2],[0,1,2]]\n    print(str(final_results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}