{
    "hands_on_practices": [
        {
            "introduction": "信用评级并非一成不变；它们会随着公司财务状况的演变而变化。马尔可夫链是对此类离散状态（如'AAA'、'AA'、'BBB'）之间转换进行建模的强大工具。本练习将引导你完成一项计算金融中的基本任务：从评级变化的历史数据中估计模型的参数——转移概率矩阵，然后利用该模型预测信用评级的长期稳态分布。",
            "id": "2388997",
            "problem": "考虑一个离散时间信用评级系统，该系统被建模为有限状态空间上的一阶马尔可夫链。状态空间有序，为 $S=\\{\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{Default}\\}$，我们分别将其索引为 $0,1,2,3,4$。您观察到一个时间有序的评级序列 $\\{X_t\\}_{t=0}^{T}$，其取值于 $S$。令 $N_{ij}$ 表示在观测序列中从状态 $i$ 到状态 $j$ 的单步转移计数，即 $N_{ij}=\\#\\{t \\in \\{0,\\ldots,T-1\\}\\,:\\,X_t=i,\\,X_{t+1}=j\\}$。\n\n您必须使用拉普拉斯平滑最大似然估计法来估计 $5\\times 5$ 的转移概率矩阵 $P=\\left[P_{ij}\\right]$，其中伪计数 $\\alpha=1$。具体来说，对于每个 $i\\in\\{0,1,2,3,4\\}$ 和 $j\\in\\{0,1,2,3,4\\}$，定义\n$$\n\\widehat{P}_{ij}=\\frac{N_{ij}+\\alpha}{\\sum_{k=0}^{4} N_{ik}+5\\alpha},\n$$\n其中 $\\alpha=1$。这将产生一个所有条目均为严格正数的行随机矩阵。\n\n计算长期（稳态）分布 $\\pi$，它是满足以下条件的唯一非负值行向量：\n$$\n\\pi \\widehat{P}=\\pi,\\quad \\sum_{i=0}^{4}\\pi_i=1.\n$$\n将稳态分布报告为一个小数列表，在指定的状态顺序 $[\\pi_{\\text{AAA}},\\pi_{\\text{AA}},\\pi_{\\text{A}},\\pi_{\\text{BBB}},\\pi_{\\text{Default}}]$ 下，每个数值四舍五入到小数点后六位。\n\n使用以下观测序列的测试套件（每个都是 $S$ 中标签的列表）：\n\n- 测试用例 1 (包含升级和降级的一般情况)： \n  $[\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{Default},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB},\\text{A},\\text{AA},\\text{AAA},\\text{AA},\\text{A},\\text{BBB}]$。\n\n- 测试用例 2 (信息最少的边界情况)： \n  $[\\text{A},\\text{A}]$。\n\n- 测试用例 3 (集中在高评级的边缘情况)： \n  $[\\text{AAA},\\text{AA},\\text{AAA},\\text{AAA},\\text{AA},\\text{A},\\text{AAA},\\text{AAA},\\text{AAA},\\text{AA},\\text{A},\\text{AAA},\\text{AAA},\\text{AAA},\\text{AAA},\\text{AAA}]$。\n\n对于每个测试用例，您必须：\n1. 对所有条目使用 $\\alpha=1$ 构建平滑估计量 $\\widehat{P}$。\n2. 计算满足 $\\pi \\widehat{P}=\\pi$ 和 $\\sum_i \\pi_i=1$ 的稳态分布 $\\pi$。\n3. 将 $\\pi$的每个分量四舍五入到小数点后六位。\n\n最终输出格式：您的程序应生成单行输出，其中包含所有三个测试用例的结果，格式为一个由方括号括起来的逗号分隔列表，其中每个元素本身是在指定状态顺序下的稳态分布的列表表示。例如，一个可接受的格式是\n$[\\,[\\pi^{(1)}_{\\text{AAA}},\\ldots,\\pi^{(1)}_{\\text{Default}}],[\\pi^{(2)}_{\\text{AAA}},\\ldots,\\pi^{(2)}_{\\text{Default}}],[\\pi^{(3)}_{\\text{AAA}},\\ldots,\\pi^{(3)}_{\\text{Default}}]\\,]$,\n每个数字都四舍五入到小数点后六位。本问题中没有物理单位、角度或百分比；所有输出都必须是小数。",
            "solution": "所提出的问题是计算统计学和随机过程领域中一个有效的练习。它具有科学依据，定义明确且客观。我们将给出一个完整的解答。\n\n该问题要求我们估计一个离散时间一阶马尔可夫链的稳态分布。状态空间给定为 $S=\\{\\text{AAA}, \\text{AA}, \\text{A}, \\text{BBB}, \\text{Default}\\}$，我们将分别用整数 $i \\in \\{0, 1, 2, 3, 4\\}$ 对其进行索引。我们得到一个时间序列观测值 $\\{X_t\\}_{t=0}^{T}$。\n\n首先，我们必须估计转移概率矩阵，记为 $P = [P_{ij}]$，其中 $P_{ij} = \\mathbb{P}(X_{t+1}=j | X_t=i)$。问题指定使用拉普拉斯平滑最大似然估计量。这是一种贝叶斯估计方法，其中对转移矩阵的行向量施加了狄利克雷先验。对于给定的行 $i$，概率向量 $[P_{i0}, \\dots, P_{i4}]$ 的先验是一个对称狄利克雷分布，其集中参数为 $\\alpha$。\n\n令 $N_{ij}$ 为序列中观测到的从状态 $i$ 到状态 $j$ 的单步转移次数。平滑估计量 $\\widehat{P}_{ij}$ 的公式如下：\n$$\n\\widehat{P}_{ij} = \\frac{N_{ij} + \\alpha}{\\sum_{k=0}^{4} N_{ik} + |S|\\alpha}\n$$\n其中 $|S|$ 是状态数，即 $5$。问题指定伪计数为 $\\alpha=1$。令 $N_i = \\sum_{k=0}^{4} N_{ik}$ 为观测到的从状态 $i$ 出发的总转移次数。估计量简化为：\n$$\n\\widehat{P}_{ij} = \\frac{N_{ij} + 1}{N_i + 5}\n$$\n此过程确保估计的转移矩阵 $\\widehat{P}$ 中的每个条目都是严格正的，即对于所有 $i, j \\in S$，都有 $\\widehat{P}_{ij} > 0$。一个转移矩阵所有条目均为正的马尔可夫链被称为正则马尔可夫链。有限状态空间上的正则马尔可夫链的一个关键性质是它是遍历的，并拥有唯一的稳态分布。\n\n稳态分布是一个行向量 $\\pi = [\\pi_0, \\pi_1, \\pi_2, \\pi_3, \\pi_4]$，满足两个条件：\n$1.$ $\\pi \\widehat{P} = \\pi$\n$2.$ $\\sum_{i=0}^{4} \\pi_i = 1$\n\n第一个条件 $\\pi \\widehat{P} = \\pi$ 意味着 $\\pi$ 是矩阵 $\\widehat{P}$ 的一个左特征向量，其对应的特征值为 $\\lambda=1$。这可以改写为一个齐次线性方程组：\n$$\n\\pi (\\widehat{P} - I) = \\mathbf{0}\n$$\n其中 $I$ 是 $5 \\times 5$ 的单位矩阵，$\\mathbf{0}$ 是一个零行向量。用转置形式表示，即 $(\\widehat{P}^T - I^T) \\pi^T = \\mathbf{0}^T$，或更简单地，$(\\widehat{P}^T - I) \\pi^T = \\mathbf{0}$。\n\n因为 $\\lambda=1$ 是任何行随机矩阵的特征值，所以矩阵 $(\\widehat{P}^T - I)$ 是奇异的，并且其零空间非平凡。对于正则马尔可夫链，对应于 $\\lambda=1$ 的特征空间维度为 $1$。因此，方程组 $(\\widehat{P}^T - I) \\pi^T = \\mathbf{0}$ 有一个维度为 $1$ 的解空间。为了找到唯一的稳态分布 $\\pi$，我们必须施加归一化条件 $\\sum_{i=0}^{4} \\pi_i = 1$。\n\n在数值上，我们可以通过构建一个线性方程组来解决这个问题。我们从 $(\\widehat{P}^T - I) \\pi^T = \\mathbf{0}$ 中取前 $|S|-1=4$ 个线性方程，并加上归一化方程。令 $A$ 为一个矩阵，其前 $4$ 行是 $(\\widehat{P}^T - I)$ 的前 $4$ 行，其最后一行是全为一的向量。令 $b$ 为一个列向量，其前 $4$ 个元素为零，最后一个元素为一。需要求解的系统是：\n$$\nA \\pi^T = b\n$$\n解由 $\\pi^T = A^{-1}b$ 给出。解的存在性和唯一性由 $\\widehat{P}$ 的正则性保证。\n\n我们将对三个测试用例分别应用此流程。\n\n**步骤1：状态映射与转移计数**\n对于每个测试序列，我们将字符串标签映射到整数索引 $\\{0, 1, 2, 3, 4\\}$。然后，我们遍历长度为 $T+1$ 的序列，以计算 $T$ 次转移，并填充 $5 \\times 5$ 的计数矩阵 $N = [N_{ij}]$。\n\n**步骤2：转移矩阵估计**\n使用计数矩阵 $N$ 和 $\\alpha=1$，我们使用公式 $\\widehat{P}_{ij} = (N_{ij} + 1) / (N_i + 5)$ 计算平滑转移矩阵 $\\widehat{P}$。\n\n**步骤3：稳态分布计算**\n我们如上所述从 $\\widehat{P}^T$ 构建矩阵 $A$，以及向量 $b = [0, 0, 0, 0, 1]^T$。然后，我们使用标准的线性代数求解器求解线性系统 $A \\pi^T = b$ 以得到 $\\pi^T$。\n\n**步骤4：格式化**\n将得到的向量 $\\pi$ 的各分量按要求四舍五入到小数点后六位。最终输出是一个列表，其中包含每个测试用例的四舍五入后的稳态分布向量。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n\n    state_map = {'AAA': 0, 'AA': 1, 'A': 2, 'BBB': 3, 'Default': 4}\n    num_states = len(state_map)\n    alpha = 1.0\n\n    test_cases = [\n        ['BBB','A','AA','AAA','AA','A','BBB','A','AA','AAA','AA','A','BBB','A','AA','AAA','AA','A','BBB','Default','A','AA','AAA','AA','A','BBB','A','AA','AAA','AA','A','BBB'],\n        ['A','A'],\n        ['AAA','AA','AAA','AAA','AA','A','AAA','AAA','AAA','AA','A','AAA','AAA','AAA','AAA','AAA']\n    ]\n\n    all_results = []\n\n    for sequence in test_cases:\n        # Step 1: Count transitions\n        counts = np.zeros((num_states, num_states), dtype=int)\n        int_sequence = [state_map[s] for s in sequence]\n        \n        for i in range(len(int_sequence) - 1):\n            from_state = int_sequence[i]\n            to_state = int_sequence[i+1]\n            counts[from_state, to_state] += 1\n\n        # Step 2: Estimate smoothed transition matrix P_hat\n        p_hat = np.zeros((num_states, num_states), dtype=float)\n        row_totals = np.sum(counts, axis=1)\n        \n        for i in range(num_states):\n            denominator = row_totals[i] + num_states * alpha\n            for j in range(num_states):\n                numerator = counts[i, j] + alpha\n                p_hat[i, j] = numerator / denominator\n\n        # Step 3: Compute the stationary distribution pi\n        # We need to solve pi * P_hat = pi, or pi * (P_hat - I) = 0,\n        # which is equivalent to (P_hat^T - I^T) * pi^T = 0^T.\n        # Let A = P_hat^T - I. We solve for the null space of A.\n        # We replace the last equation with the normalization condition sum(pi) = 1.\n        \n        A = (p_hat.T - np.identity(num_states))\n        A[-1, :] = 1.0  # Last row is for sum(pi_i) = 1\n        \n        b = np.zeros(num_states)\n        b[-1] = 1.0  # Corresponds to sum(pi_i) = 1\n        \n        try:\n            # Solve the linear system A * pi^T = b\n            pi = np.linalg.solve(A, b)\n            \n            # Ensure non-negativity and re-normalize for robustness\n            pi[pi  0] = 0\n            pi /= np.sum(pi)\n\n        except np.linalg.LinAlgError:\n            # Fallback for singular matrix if something unexpected happens\n            # For a regular P_hat, this shouldn't be reached.\n            # We can use eigenvector method as a backup.\n            # Find the right eigenvector of P_hat.T for eigenvalue 1\n            eigenvalues, eigenvectors = np.linalg.eig(p_hat.T)\n            # Find the eigenvector corresponding to eigenvalue 1\n            idx = np.argmin(np.abs(eigenvalues - 1.0))\n            pi = np.real(eigenvectors[:, idx])\n            # Normalize to get the probability distribution\n            pi = pi / np.sum(pi)\n\n        # Step 4: Round and format the result\n        rounded_pi = np.round(pi, 6).tolist()\n        all_results.append(rounded_pi)\n\n    # Final print statement in the exact required format.\n    # The default str() representation of a list of lists works. e.g., [[...], [...]]\n    print(str(all_results).replace(\" \", \"\"))\n\n\nsolve()\n```"
        },
        {
            "introduction": "每个随机过程都可以看作是可预测趋势和一系列不可预测冲击的结合。Doob-Meyer分解定理为实现这种分离提供了严谨的方法，它将一个过程分解为一个可预测部分和一个鞅（一种“纯粹的随机博弈”）。本动手练习将通过对一个常见的自回归（AR(1)）过程进行数值分解，揭示这一核心概念的神秘面纱，让你对时间序列模型的结构获得深刻的洞察。",
            "id": "2388954",
            "problem": "给定一个离散时间、实值的适应过程，该过程由一个一阶自回归 (AR(1)) 模型定义。对于每个测试用例，该过程由参数 $\\mu$、$\\phi$、$\\sigma$、初始值 $X_0$ 和时间范围 $T$ 指定。其动态为\n$$\nX_t \\;=\\; \\mu \\;+\\; \\phi\\,X_{t-1} \\;+\\; \\varepsilon_t,\\quad t=1,2,\\dots,T,\n$$\n其中 $\\{\\varepsilon_t\\}_{t\\ge 1}$ 是独立同分布的高斯新息，满足 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$，并且滤子是自然滤子 $\\mathcal{F}_t=\\sigma(X_0,\\varepsilon_1,\\dots,\\varepsilon_t)$。\n\n对于每个测试用例：\n- 使用指定的参数和给定的随机种子初始化伪随机数生成器，模拟一条样本路径 $\\{X_t\\}_{t=0}^T$。将 $\\varepsilon_t$ 抽样为均值为 $0$、标准差为 $\\sigma$ 的独立高斯随机变量。\n- 数值计算 $\\{X_t\\}$ 的离散时间Doob–Meyer (Doob) 分解，得到过程 $\\{M_t\\}$ 和 $\\{A_t\\}$，使得\n$$\nX_t \\;=\\; X_0 \\;+\\; M_t \\;+\\; A_t,\\quad M_0=0,\\;A_0=0,\n$$\n其中 $\\{M_t\\}$ 是关于 $\\{\\mathcal{F}_t\\}$ 的鞅，$\\{A_t\\}$ 是关于 $\\{\\mathcal{F}_t\\}$ 的可预见过程。\n- 报告该测试用例的终端值对 $[A_T, M_T]$。\n\n测试套件：\n- 用例1（一般的非鞅）：$\\mu=0.5$, $\\phi=0.8$, $\\sigma=1.0$, $X_0=0.7$, $T=12$, seed $=314159$。\n- 用例2（鞅边界情况）：$\\mu=0.0$, $\\phi=1.0$, $\\sigma=0.8$, $X_0=1.2$, $T=10$, seed $=271828$。\n- 用例3（确定性边缘情况）：$\\mu=0.1$, $\\phi=0.9$, $\\sigma=0.0$, $X_0=-0.3$, $T=15$, seed $=42$。\n- 用例4（带漂移的单位根）：$\\mu=-0.2$, $\\phi=1.0$, $\\sigma=0.5$, $X_0=0.0$, $T=8$, seed $=7$。\n\n您的程序必须：\n- 对于每个用例，使用提供的种子精确模拟一条路径。\n- 计算与关于自然滤子的离散时间Doob分解定义一致的终端值 $A_T$ 和 $M_T$。\n- 将报告的每个数字四舍五入到六位小数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个元素必须是测试用例的二元列表 $[A_T, M_T]$，顺序同上。例如，整体输出应类似于\n\"[ [a1,m1],[a2,m2],[a3,m3],[a4,m4] ]\"\n但每个 $a_i$ 和 $m_i$ 都替换为相应的四舍五入后的数值。",
            "solution": "在尝试求解之前，需对问题陈述进行验证。\n\n### 步骤1：提取已知条件\n- **过程动态**：一个离散时间一阶自回归 (AR(1)) 模型由 $X_t = \\mu + \\phi X_{t-1} + \\varepsilon_t$ 给出，其中 $t=1, 2, \\dots, T$。\n- **初始值**：过程从给定的值 $X_0$ 开始。\n- **新息**：$\\{\\varepsilon_t\\}_{t \\ge 1}$ 是一个独立同分布 (i.i.d.) 的随机变量序列，其中 $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$。\n- **滤子**：自然滤子为 $\\mathcal{F}_t = \\sigma(X_0, \\varepsilon_1, \\dots, \\varepsilon_t)$。\n- **分解**：过程 $\\{X_t\\}$ 需分解为 $X_t = X_0 + M_t + A_t$，其中 $\\{M_t\\}$ 是一个鞅，$\\{A_t\\}$ 是一个关于 $\\{\\mathcal{F}_t\\}$ 的可预见过程，并且 $M_0 = A_0 = 0$。\n- **任务**：对于给定的样本路径，找出终端值 $[A_T, M_T]$。\n- **测试用例**：\n    - 用例1：$\\mu=0.5$, $\\phi=0.8$, $\\sigma=1.0$, $X_0=0.7$, $T=12$, seed $=314159$。\n    - 用例2：$\\mu=0.0$, $\\phi=1.0$, $\\sigma=0.8$, $X_0=1.2$, $T=10$, seed $=271828$。\n    - 用例3：$\\mu=0.1$, $\\phi=0.9$, $\\sigma=0.0$, $X_0=-0.3$, $T=15$, seed $=42$。\n    - 用例4：$\\mu=-0.2$, $\\phi=1.0$, $\\sigma=0.5$, $X_0=0.0$, $T=8$, seed $=7$。\n- **输出要求**：报告每个用例的 $[A_T, M_T]$，数值四舍五入到六位小数，并采用指定的列表的列表格式。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学上成立**：该问题建立在离散时间随机过程的基本概念之上。AR(1)模型是线性随机过程的典型例子，而Doob-Meyer分解是鞅理论的基石定理。该问题在科学和数学上是合理的。\n- **定义明确**：该问题是定义明确的（良态的）。对于任何适应过程，Doob-Meyer分解是唯一的。所有参数，包括每次模拟的随机种子，都已指定，确保所需的计算能导向一个单一、可验证的结果。\n- **客观性**：问题以精确、客观的数学语言陈述，没有歧义或主观内容。\n\n### 步骤3：结论与行动\n问题有效。这是一个基于既定数学原理、定义明确的计算任务。将提供一个解决方案。\n\n### 基于原理的求解设计\n\n离散时间适应过程 $\\{X_t\\}_{t \\ge 0}$ 的Doob-Meyer分解指出，它可以唯一地写成 $X_t = X_0 + M_t + A_t$，其中 $\\{M_t\\}_{t \\ge 0}$ 是一个鞅，$\\{A_t\\}_{t \\ge 0}$ 是一个可预见过程，且 $M_0 = A_0 = 0$。\n\n该分解由过程增量 $\\Delta X_t = X_t - X_{t-1}$ 构建。每个增量被分解为其可预见部分和鞅差部分：\n$$\n\\Delta X_t = \\Delta A_t + \\Delta M_t\n$$\n其中 $\\Delta A_t = A_t - A_{t-1}$ 且 $\\Delta M_t = M_t - M_{t-1}$。\n\n根据定义，可预见过程的增量 $\\Delta A_t$ 是过程增量在前一时刻可用信息下的条件期望：\n$$\n\\Delta A_t = \\mathbb{E}[\\Delta X_t | \\mathcal{F}_{t-1}] = \\mathbb{E}[X_t - X_{t-1} | \\mathcal{F}_{t-1}]\n$$\n鞅分量的增量 $\\Delta M_t$ 是增量中的新息或“意外”部分：\n$$\n\\Delta M_t = \\Delta X_t - \\Delta A_t = (X_t - X_{t-1}) - \\mathbb{E}[X_t - X_{t-1} | \\mathcal{F}_{t-1}]\n$$\n根据构造，$\\mathbb{E}[\\Delta M_t | \\mathcal{F}_{t-1}] = 0$，这是鞅差序列的定义属性。\n\n对于给定的AR(1)过程 $X_t = \\mu + \\phi X_{t-1} + \\varepsilon_t$，其增量为：\n$$\n\\Delta X_t = X_t - X_{t-1} = (\\mu + \\phi X_{t-1} + \\varepsilon_t) - X_{t-1} = \\mu + (\\phi - 1)X_{t-1} + \\varepsilon_t\n$$\n我们现在计算条件期望以求得 $\\Delta A_t$：\n$$\n\\Delta A_t = \\mathbb{E}[\\mu + (\\phi - 1)X_{t-1} + \\varepsilon_t | \\mathcal{F}_{t-1}]\n$$\n利用期望的线性性质和条件期望的性质：\n1.  $\\mu$ 是一个常数，所以 $\\mathbb{E}[\\mu | \\mathcal{F}_{t-1}] = \\mu$。\n2.  $X_{t-1}$ 在时间 $t-1$ 是已知的，因此它是 $\\mathcal{F}_{t-1}$-可测的。所以 $\\mathbb{E}[(\\phi - 1)X_{t-1} | \\mathcal{F}_{t-1}] = (\\phi - 1)X_{t-1}$。\n3.  新息 $\\varepsilon_t$ 与过去的滤子 $\\mathcal{F}_{t-1} = \\sigma(X_0, \\varepsilon_1, \\dots, \\varepsilon_{t-1})$ 无关，且均值为零。因此，$\\mathbb{E}[\\varepsilon_t | \\mathcal{F}_{t-1}] = \\mathbb{E}[\\varepsilon_t] = 0$。\n\n综合这些结果，得到可预见过程的增量：\n$$\n\\Delta A_t = \\mu + (\\phi - 1)X_{t-1}\n$$\n于是，鞅的增量为：\n$$\n\\Delta M_t = \\Delta X_t - \\Delta A_t = (\\mu + (\\phi - 1)X_{t-1} + \\varepsilon_t) - (\\mu + (\\phi - 1)X_{t-1}) = \\varepsilon_t\n$$\n终端值 $A_T$ 和 $M_T$ 分别是它们各自增量从 $t=1$ 到 $T$ 的总和，因为 $A_0 = M_0 = 0$：\n$$\nA_T = \\sum_{t=1}^T \\Delta A_t = \\sum_{t=1}^T (\\mu + (\\phi - 1)X_{t-1})\n$$\n$$\nM_T = \\sum_{t=1}^T \\Delta M_t = \\sum_{t=1}^T \\varepsilon_t\n$$\n\n### 算法流程\n对于每个测试用例，数值解法包括以下步骤：\n1.  初始化参数：$\\mu, \\phi, \\sigma, X_0, T,$ 以及随机种子。\n2.  使用该种子初始化一个伪随机数生成器。从分布 $\\mathcal{N}(0, \\sigma^2)$ 生成 $T$ 个新息的整个序列 $\\{\\varepsilon_t\\}_{t=1}^T$。\n3.  为路径 $\\{X_t\\}$ 初始化一个大小为 $T+1$ 的数组，并设置 $X[0] = X_0$。初始化终端值累加器 $A_T = 0.0$ 和 $M_T = 0.0$。\n4.  从 $t=1$ 迭代至 $T$：\n    a. 检索当前步骤的新息 $\\varepsilon_t$。\n    b. 计算 $X_t = \\mu + \\phi X_{t-1} + \\varepsilon_t$。\n    c. 计算可预见增量 $\\Delta A_t = \\mu + (\\phi - 1)X_{t-1}$。\n    d. 将此增量加到累加器中：$A_T \\leftarrow A_T + \\Delta A_t$。\n    e. 将鞅增量 $\\varepsilon_t$ 加到其累加器中：$M_T \\leftarrow M_T + \\varepsilon_t$。注意，这也可以在循环结束后通过对所有新息求和一次性计算。\n5.  循环结束后，将 $A_T$ 和 $M_T$ 的最终值四舍五入到六位小数。\n6.  存储值对 $[A_T, M_T]$ 并按规定格式化收集到的结果。\n该流程正确地实现了推导出的分解，并产生所需的输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates AR(1) processes and computes the terminal values of their\n    Doob-Meyer decomposition components.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'mu': 0.5, 'phi': 0.8, 'sigma': 1.0, 'X0': 0.7, 'T': 12, 'seed': 314159},\n        {'mu': 0.0, 'phi': 1.0, 'sigma': 0.8, 'X0': 1.2, 'T': 10, 'seed': 271828},\n        {'mu': 0.1, 'phi': 0.9, 'sigma': 0.0, 'X0': -0.3, 'T': 15, 'seed': 42},\n        {'mu': -0.2, 'phi': 1.0, 'sigma': 0.5, 'X0': 0.0, 'T': 8, 'seed': 7},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        mu = case['mu']\n        phi = case['phi']\n        sigma = case['sigma']\n        X0 = case['X0']\n        T = case['T']\n        seed = case['seed']\n\n        # 1. Initialize RNG and generate all innovations\n        rng = np.random.default_rng(seed)\n        epsilons = rng.normal(loc=0.0, scale=sigma, size=T)\n\n        # 2. Initialize path array and terminal value accumulators\n        x_path = np.zeros(T + 1)\n        x_path[0] = X0\n        \n        A_T = 0.0\n\n        # 3. Simulate the path and compute the predictable component A_T\n        # The martingale component M_T is simply the sum of all innovations.\n        for t in range(1, T + 1):\n            # The t-th innovation corresponds to index t-1 in the epsilons array\n            epsilon_t = epsilons[t - 1]\n            x_prev = x_path[t - 1]\n            \n            # Update the process\n            x_path[t] = mu + phi * x_prev + epsilon_t\n            \n            # Increment for the predictable part A_t\n            # delta_A_t = E[X_t - X_{t-1} | F_{t-1}] = mu + (phi - 1) * X_{t-1}\n            delta_A_t = mu + (phi - 1) * x_prev\n            A_T += delta_A_t\n\n        # The martingale part M_T is the sum of innovations\n        M_T = np.sum(epsilons)\n        \n        # 4. Round to six decimal places as required\n        A_T_rounded = round(A_T, 6)\n        M_T_rounded = round(M_T, 6)\n        \n        results.append([A_T_rounded, M_T_rounded])\n\n    # 5. Format the final output string as a compact list of lists\n    # Each sublist [a, m] is formatted to ensure fixed precision and no spaces\n    string_parts = []\n    for res_pair in results:\n        a_str = f\"{res_pair[0]:.6f}\"\n        m_str = f\"{res_pair[1]:.6f}\"\n        string_parts.append(f\"[{a_str},{m_str}]\")\n        \n    final_output = f\"[{','.join(string_parts)}]\"\n\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "通常，我们真正关心的变量——例如一家公司的“真实”盈利能力或一项资产的“真实”波动率——是无法直接观测的。我们只能从充满噪声的间接测量中推断它。这正是状态空间模型的用武之地，而卡尔曼滤波器是在线性高斯系统中估计此类隐藏状态的基石算法。在这个实际应用中，你将使用卡尔曼滤波器，根据一名篮球运动员每场比赛波动的表现来估计其“真实”的投篮能力，这项技术与追踪经济指标或金融因子异曲同工。",
            "id": "2389012",
            "problem": "考虑一个单一隐藏状态，该状态代表一名篮球运动员在一系列比赛中的潜在投篮能力。在每个离散时间步 $t \\in \\{1,2,\\dots,T\\}$，该运动员投篮 $n_t$ 次，命中 $m_t$ 次。将观测到的投篮命中率定义为 $y_t = m_t / n_t$（当 $n_t \\gt 0$ 时），并在 $n_t = 0$ 时将 $y_t$ 视为缺失值。使用以下线性高斯状态空间模型对隐藏能力和观测值进行建模：\n- 隐藏状态动态：$ \\theta_t = \\mu + \\phi \\left(\\theta_{t-1} - \\mu\\right) + w_t $，其中 $w_t \\sim \\mathcal{N}(0,q)$。\n- 观测方程（当 $n_t \\gt 0$ 时）：$ y_t = \\theta_t + v_t $，其中 $v_t \\sim \\mathcal{N}(0, R_t)$。\n\n假设 $R_t$ 已知，并通过一个受二项采样启发的样本均值方差近似公式与 $n_t$ 相关联：$ R_t = \\bar{p}(1-\\bar{p}) / n_t $，其中 $\\bar{p}$ 是一个固定的参考概率。当 $n_t = 0$ 时，将观测值视为缺失，并只执行状态预测步骤（不进行更新）。所有概率和方差必须表示为小数（例如，写作 $0.45$ 而不是 $45\\%$）。\n\n给定以下固定参数：\n- 长期均值：$\\mu = 0.45$。\n- 自回归系数：$\\phi = 0.90$。\n- 状态创新方差：$q = 0.0005$。\n- 用于观测方差的参考概率：$\\bar{p} = 0.45$（在 $R_t$ 中使用此值）。\n- 初始状态的先验：$\\theta_0 \\sim \\mathcal{N}(m_0, P_0)$，其中 $m_0 = 0.45$ 且 $P_0 = 0.01$。\n\n从先验 $(m_0, P_0)$ 开始，实现递归滤波过程。在每个时间点 $t$，该过程计算状态及其方差的单步预测值，然后（如果 $n_t \\gt 0$）使用上述线性高斯模型通过观测值 $y_t$ 对其进行更新。如果 $n_t = 0$，则跳过更新步骤，并将预测值作为该时期的滤波状态向前传递。\n\n你的任务是编写一个完整的程序，该程序：\n1. 实现上述指定的时变方差卡尔曼滤波器模型。\n2. 在以下每个比赛测试集上运行该滤波器（每个测试集是一个 $(m_t, n_t)$ 对的序列）：\n   - 测试用例 A（尝试次数中等，结果多变）：\n     - $[(5,11), (4,10), (7,12), (6,14), (2,6), (8,15), (3,8), (6,12), (7,16), (5,9)]$。\n   - 测试用例 B（尝试次数多，结果相对稳定）：\n     - $[(9,20), (10,22), (8,18), (11,24), (12,25), (9,19), (10,21), (12,26), (11,24), (13,28)]$。\n   - 测试用例 C（某些比赛尝试次数为零；将这些视为缺失观测值）：\n     - $[(0,0), (3,5), (0,0), (4,4), (0,0), (2,10), (0,0), (5,10)]$。\n   - 测试用例 D（结果和尝试次数波动大）：\n     - $[(1,2), (0,5), (7,10), (1,12), (9,10), (0,3), (6,15), (2,2), (0,8), (10,12)]$。\n3. 对于每个测试用例，输出处理完序列中最后一场比赛后的最终滤波后验均值 $\\hat{\\theta}_T$ 和方差 $P_T$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是一个双元素列表 $[\\hat{\\theta}_T, P_T]$，两个值都四舍五入到恰好六位小数。例如，总输出应如下所示：\n- $[[\\hat{\\theta}_T^{(A)}, P_T^{(A)}],[\\hat{\\theta}_T^{(B)}, P_T^{(B)}],[\\hat{\\theta}_T^{(C)}, P_T^{(C)}],[\\hat{\\theta}_T^{(D)}, P_T^{(D)}]]$，\n打印为单行。\n\n角度单位不适用。百分比必须表示为小数，而不是使用百分号。此问题不涉及物理单位。",
            "solution": "该问题要求实现一个卡尔曼滤波器，它是一种递归算法，用于从一系列带噪声的测量中估计线性动态系统的隐藏状态。该模型将篮球运动员的投篮能力 $\\theta_t$ 建模为一个随时间演变的潜状态。\n\n首先，我们在线性高斯状态空间模型的框架内将问题形式化。该模型由两个方程组成：一个状态转移方程和一个观测方程。\n\n系统的状态是运动员在时间 $t$ 的投篮能力，用标量 $\\theta_t$ 表示。该状态的演变由一个一阶自回归过程 AR(1) 描述，该过程向长期均值 $\\mu$ 进行均值回归。\n\n状态方程：\n隐藏状态动态由下式给出：\n$$ \\theta_t = \\mu + \\phi \\left(\\theta_{t-1} - \\mu\\right) + w_t $$\n这可以重排为标准的线性形式：\n$$ \\theta_t = \\phi \\theta_{t-1} + (1 - \\phi)\\mu + w_t $$\n其中：\n- $\\theta_t$ 是时间 $t$ 的状态。\n- $\\phi$ 是自回归系数，决定了状态的持续性。给定 $\\phi=0.90$。\n- $\\mu$ 是过程的长期均值，给定 $\\mu=0.45$。\n- $w_t$ 是过程噪声，假定为白噪声过程，满足 $w_t \\sim \\mathcal{N}(0, q)$，其中 $q$ 是状态创新方差，给定 $q=0.0005$。\n\n观测方程：\n时间 $t$ 的观测值是运动员观测到的投篮命中率，$y_t = m_t / n_t$，其中 $m_t$ 是在 $n_t$ 次投篮尝试中命中的次数。该观测值仅在 $n_t  0$ 时可用。该观测被建模为对真实潜在能力 $\\theta_t$ 的带噪声测量。\n$$ y_t = \\theta_t + v_t $$\n其中：\n- $y_t$ 是时间 $t$ 的观测值。\n- $v_t$ 是测量噪声，假定为白噪声过程，满足 $v_t \\sim \\mathcal{N}(0, R_t)$。方差 $R_t$ 是随时变的。\n\n测量噪声方差 $R_t$ 的近似基于二项分布样本比例的方差。给定 $n_t$ 次试验，样本比例 $y_t$ 的方差近似为 $p(1-p)/n_t$。问题指定使用一个固定的参考概率 $\\bar{p}=0.45$ 进行此计算：\n$$ R_t = \\frac{\\bar{p}(1 - \\bar{p})}{n_t} = \\frac{0.45(1 - 0.45)}{n_t} = \\frac{0.2475}{n_t} $$\n这个公式使得 $R_t$ 是时变的，因为它依赖于每场比赛的投篮尝试次数 $n_t$。当 $n_t$ 很大时，$R_t$ 很小，反映了对观测值的置信度更高。\n\n卡尔曼滤波器为估计状态的后验分布 $p(\\theta_t | y_{1:t})$ 提供了一个递归解。由于模型是线性和高斯的，该后验分布也是高斯分布，可以由其均值 $\\hat{\\theta}_{t|t}$ 和方差 $P_{t|t}$ 完全表征。\n\n滤波过程始于初始状态的先验分布 $\\theta_0 \\sim \\mathcal{N}(m_0, P_0)$，其给定参数为 $m_0 = 0.45$ 和 $P_0 = 0.01$。在每个时间步 $t=1, 2, \\dots, T$，算法执行两个步骤：一个预测步骤和一个更新步骤。\n\n设时间 $t-1$ 的滤波后验为 $\\mathcal{N}(\\hat{\\theta}_{t-1|t-1}, P_{t-1|t-1})$。\n\n步骤 1：预测（时间更新）\n在这一步中，我们基于截至时间 $t-1$ 的所有信息来预测时间 $t$ 的状态分布。计算预测（先验）均值 $\\hat{\\theta}_{t|t-1}$ 和方差 $P_{t|t-1}$。\n\n取状态方程的期望：\n$$ \\hat{\\theta}_{t|t-1} = \\mathbb{E}[\\phi \\theta_{t-1} + (1 - \\phi)\\mu + w_t | y_{1:t-1}] = \\phi \\hat{\\theta}_{t-1|t-1} + (1 - \\phi)\\mu $$\n预测误差的方差是：\n$$ P_{t|t-1} = \\text{Var}(\\theta_t - \\hat{\\theta}_{t|t-1}) = \\text{Var}(\\phi(\\theta_{t-1} - \\hat{\\theta}_{t-1|t-1}) + w_t) $$\n由于误差 $(\\theta_{t-1} - \\hat{\\theta}_{t-1|t-1})$ 与过程噪声 $w_t$ 不相关，方差相加：\n$$ P_{t|t-1} = \\phi^2 \\text{Var}(\\theta_{t-1} - \\hat{\\theta}_{t-1|t-1}) + \\text{Var}(w_t) = \\phi^2 P_{t-1|t-1} + q $$\n\n步骤 2：更新（测量更新）\n此步骤使用时间 $t$ 的新观测值 $y_t$ 来优化预测。仅当有可用观测值时（即 $n_t  0$）才执行此步骤。\n\n首先，我们计算新息，即实际观测值 $y_t$ 与其预测值之间的差异：\n$$ \\tilde{y}_t = y_t - \\mathbb{E}[y_t | y_{1:t-1}] = y_t - \\mathbb{E}[\\theta_t + v_t | y_{1:t-1}] = y_t - \\hat{\\theta}_{t|t-1} $$\n新息的方差，或新息协方差，为：\n$$ S_t = \\text{Var}(\\tilde{y}_t) = \\text{Var}((\\theta_t - \\hat{\\theta}_{t|t-1}) + v_t) = P_{t|t-1} + R_t $$\n最优卡尔曼增益 $K_t$ 决定了基于新息对预测进行多大程度的调整。其计算旨在最小化后验误差方差：\n$$ K_t = \\frac{\\text{Cov}(\\theta_t, \\tilde{y}_t)}{\\text{Var}(\\tilde{y}_t)} = \\frac{\\text{Cov}(\\theta_t, \\theta_t - \\hat{\\theta}_{t|t-1} + v_t)}{S_t} = \\frac{P_{t|t-1}}{S_t} = \\frac{P_{t|t-1}}{P_{t|t-1} + R_t} $$\n更新后的（后验）状态均值是预测均值和观测值的加权平均：\n$$ \\hat{\\theta}_{t|t} = \\hat{\\theta}_{t|t-1} + K_t \\tilde{y}_t = \\hat{\\theta}_{t|t-1} + K_t (y_t - \\hat{\\theta}_{t|t-1}) $$\n更新后的（后验）误差方差为：\n$$ P_{t|t} = (1 - K_t) P_{t|t-1} $$\n\n处理缺失观测值：\n如果 $n_t = 0$，则观测值 $y_t$ 缺失。在这种情况下，无法执行更新。时间 $t$ 状态的最佳估计就是上一步的预测值。因此，时间 $t$ 的后验被设置为等于其先验：\n$$ \\hat{\\theta}_{t|t} = \\hat{\\theta}_{t|t-1} $$\n$$ P_{t|t} = P_{t|t-1} $$\n\n对每个测试用例，按如下方式实现整个算法：\n1. 用先验均值 $\\hat{\\theta}_{0|0} = m_0 = 0.45$ 和方差 $P_{0|0} = P_0 = 0.01$ 初始化滤波器。\n2. 对每个时间步 $t=1, \\dots, T$：\n   a. 执行预测步骤以计算 $\\hat{\\theta}_{t|t-1}$ 和 $P_{t|t-1}$。\n   b. 检查是否 $n_t  0$：\n      i. 如果为真，计算 $y_t = m_t / n_t$ 和 $R_t = \\bar{p}(1-\\bar{p}) / n_t$。执行更新步骤以计算 $\\hat{\\theta}_{t|t}$ 和 $P_{t|t}$。\n      ii. 如果为假，跳过更新，并设置 $\\hat{\\theta}_{t|t} = \\hat{\\theta}_{t|t-1}$ 和 $P_{t|t} = P_{t|t-1}$。\n3. 处理完整个序列后的最终值 $\\hat{\\theta}_{T|T}$ 和 $P_{T|T}$ 是每个测试用例所需的输出。",
            "answer": "```python\nimport numpy as np\n\ndef run_kalman_filter(data, mu, phi, q, p_bar, m0, P0):\n    \"\"\"\n    Implements the Kalman filter for the given state-space model.\n\n    Args:\n        data (list of tuples): A sequence of (m_t, n_t) pairs.\n        mu (float): Long-run mean of the state process.\n        phi (float): Autoregressive coefficient of the state process.\n        q (float): State innovation variance.\n        p_bar (float): Reference probability for observation variance.\n        m0 (float): Prior mean of the initial state.\n        P0 (float): Prior variance of the initial state.\n\n    Returns:\n        tuple: A tuple containing the final filtered posterior mean and variance.\n    \"\"\"\n    # Initialize the filtered state mean and variance with the prior\n    theta_filt = m0\n    P_filt = P0\n    \n    # Pre-calculate the numerator for the observation variance R_t\n    obs_var_numerator = p_bar * (1.0 - p_bar)\n\n    # Iterate through each time step (game)\n    for m_t, n_t in data:\n        # --- 1. Prediction Step ---\n        # Predict the next state mean\n        theta_pred = phi * theta_filt + mu * (1.0 - phi)\n        # Predict the next state variance\n        P_pred = phi**2 * P_filt + q\n\n        # --- 2. Update Step ---\n        # Check if there is an observation (n_t > 0)\n        if n_t > 0:\n            # Calculate the observation y_t\n            y_t = m_t / n_t\n            # Calculate the time-varying observation variance R_t\n            R_t = obs_var_numerator / n_t\n            \n            # Calculate the innovation covariance S_t\n            S_t = P_pred + R_t\n            \n            # Calculate the optimal Kalman gain K_t\n            K_t = P_pred / S_t\n            \n            # Update the state mean\n            theta_filt = theta_pred + K_t * (y_t - theta_pred)\n            \n            # Update the state variance\n            P_filt = (1.0 - K_t) * P_pred\n        else:\n            # If observation is missing (n_t = 0), the posterior is the prior\n            theta_filt = theta_pred\n            P_filt = P_pred\n            \n    return theta_filt, P_filt\n\ndef solve():\n    \"\"\"\n    Main function to define parameters, run test cases, and print results.\n    \"\"\"\n    # Fixed model parameters\n    mu = 0.45\n    phi = 0.90\n    q = 0.0005\n    p_bar = 0.45\n    \n    # Prior for the initial state\n    m0 = 0.45\n    P0 = 0.01\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        # Test case A\n        [(5, 11), (4, 10), (7, 12), (6, 14), (2, 6), (8, 15), (3, 8), (6, 12), (7, 16), (5, 9)],\n        # Test case B\n        [(9, 20), (10, 22), (8, 18), (11, 24), (12, 25), (9, 19), (10, 21), (12, 26), (11, 24), (13, 28)],\n        # Test case C\n        [(0, 0), (3, 5), (0, 0), (4, 4), (0, 0), (2, 10), (0, 0), (5, 10)],\n        # Test case D\n        [(1, 2), (0, 5), (7, 10), (1, 12), (9, 10), (0, 3), (6, 15), (2, 2), (0, 8), (10, 12)]\n    ]\n\n    results = []\n    # Process each test case\n    for data in test_cases:\n        theta_T, P_T = run_kalman_filter(data, mu, phi, q, p_bar, m0, P0)\n        # Format the result for the current test case as a string\n        # with values rounded to six decimal places, enclosed in brackets.\n        results.append(f\"[{theta_T:.6f}, {P_T:.6f}]\")\n\n    # Final print statement in the exact required format.\n    # The output is a single line: a list of lists.\n    print(f\"[{','.join(results)}]\")\n\n# Execute the main function\nsolve()\n```"
        }
    ]
}