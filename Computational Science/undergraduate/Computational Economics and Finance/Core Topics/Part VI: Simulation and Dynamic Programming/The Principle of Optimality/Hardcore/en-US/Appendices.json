{
    "hands_on_practices": [
        {
            "introduction": "Many complex optimization problems can be simplified by breaking them down into a sequence of smaller, manageable decisions. This problem models a common scenario—packing for a trip—as a multi-dimensional knapsack problem, where you must allocate limited luggage capacity and budget across several items. By applying the principle of optimality, you will develop a dynamic programming formulation that considers each item sequentially, demonstrating how to build a globally optimal solution from a series of local optimal choices .",
            "id": "2443405",
            "problem": "Consider a finite-horizon choice problem for a traveler facing three mutually exclusive actions for each item: pack in luggage, ship ahead, or buy at the destination, with the option to skip the item. The traveler departs in $D$ days, the trip lasts $T$ days at the destination, and shipping item $i$ has a lead time of $L_i$ days. If an item arrives at the destination with a delay of $d_i = \\max\\{0, L_i - D\\}$ days after the traveler arrives, then its realized utility is discounted by a factor $\\alpha^{d_i}$, where $0 \\le \\alpha \\le 1$. If $d_i \\ge T$, the realized utility is $0$ because the item arrives after the trip ends. Packing consumes luggage weight capacity, while shipping or buying consumes budget. The objective is to maximize total realized utility subject to capacity and budget constraints.\n\nFundamental base: Use the core definitions of utility maximization under constraints and the principle of optimality from Dynamic Programming (DP). Do not assume any shortcut formulas.\n\nFormulation details and assumptions:\n- There are $n$ items indexed by $i \\in \\{1, \\dots, n\\}$. Each item has:\n  - weight $w_i \\in \\mathbb{Z}_{\\ge 0}$,\n  - utility $u_i \\in \\mathbb{R}_{\\ge 0}$,\n  - shipping cost $s_i \\in \\mathbb{Z}_{\\ge 0}$,\n  - buying cost $b_i \\in \\mathbb{Z}_{\\ge 0}$,\n  - lead time $L_i \\in \\mathbb{Z}_{\\ge 0}$.\n- Luggage has capacity $C \\in \\mathbb{Z}_{\\ge 0}$ and the traveler has budget $B \\in \\mathbb{Z}_{\\ge 0}$.\n- For each item $i$, the traveler chooses exactly one of four actions: skip, pack, ship, or buy, subject to feasibility (capacity and budget) and timing.\n- The realized utility contribution of item $i$ under each action is:\n  - skip: $0$,\n  - pack: $u_i$ (consumes $w_i$ units of capacity and $0$ budget),\n  - ship: $u_i \\cdot \\alpha^{d_i}$ if $d_i  T$, else $0$ (consumes $s_i$ units of budget and $0$ capacity),\n  - buy: $u_i$ (consumes $b_i$ units of budget and $0$ capacity).\n- The objective is to choose actions to maximize the sum of realized utilities, subject to total packed weight $\\le C$ and total spending on shipped and bought items $\\le B$.\n\nRequired task:\n- Derive a Dynamic Programming (DP) formulation based on the principle of optimality, and implement an algorithm that computes the optimal total realized utility for given inputs. You must compute the optimal total realized utility (not the action plan) for each test case below. All computed outputs must be rounded to exactly $2$ decimal places.\n\nTest suite:\n- Use discount factor $\\alpha$ as specified in each case. Treat all costs and capacities as integers, and treat utilities as real numbers.\n\n- Case $1$:\n  - $C = 5$, $B = 25$, $D = 2$, $T = 5$, $\\alpha = 0.8$.\n  - Items:\n    - $i=1$: $w_1 = 3$, $u_1 = 20$, $s_1 = 12$, $b_1 = 15$, $L_1 = 1$.\n    - $i=2$: $w_2 = 2$, $u_2 = 18$, $s_2 = 15$, $b_2 = 25$, $L_2 = 3$.\n    - $i=3$: $w_3 = 1$, $u_3 = 6$, $s_3 = 3$, $b_3 = 4$, $L_3 = 2$.\n    - $i=4$: $w_4 = 4$, $u_4 = 30$, $s_4 = 20$, $b_4 = 100$, $L_4 = 5$.\n\n- Case $2$:\n  - $C = 0$, $B = 6$, $D = 1$, $T = 3$, $\\alpha = 0.7$.\n  - Items:\n    - $i=1$: $w_1 = 2$, $u_1 = 14$, $s_1 = 5$, $b_1 = 16$, $L_1 = 1$.\n    - $i=2$: $w_2 = 1$, $u_2 = 5$, $s_2 = 2$, $b_2 = 6$, $L_2 = 2$.\n    - $i=3$: $w_3 = 3$, $u_3 = 12$, $s_3 = 4$, $b_3 = 20$, $L_3 = 3$.\n\n- Case $3$:\n  - $C = 4$, $B = 0$, $D = 2$, $T = 2$, $\\alpha = 0.9$.\n  - Items:\n    - $i=1$: $w_1 = 1$, $u_1 = 4$, $s_1 = 1$, $b_1 = 3$, $L_1 = 2$.\n    - $i=2$: $w_2 = 3$, $u_2 = 16$, $s_2 = 5$, $b_2 = 50$, $L_2 = 1$.\n    - $i=3$: $w_3 = 1$, $u_3 = 2$, $s_3 = 1$, $b_3 = 2$, $L_3 = 3$.\n\n- Case $4$:\n  - $C = 2$, $B = 5$, $D = 1$, $T = 2$, $\\alpha = 0.5$.\n  - Items:\n    - $i=1$: $w_1 = 1$, $u_1 = 6$, $s_1 = 2$, $b_1 = 8$, $L_1 = 5$.\n    - $i=2$: $w_2 = 1$, $u_2 = 3$, $s_2 = 1$, $b_2 = 4$, $L_2 = 1$.\n    - $i=3$: $w_3 = 2$, $u_3 = 5$, $s_3 = 3$, $b_3 = 7$, $L_3 = 4$.\n\nFinal output format:\n- Your program should produce a single line of output containing the optimal total realized utilities for Cases $1$ through $4$, as a comma-separated list enclosed in square brackets, for example, `[0.00,1.25,3.00,4.50]`.",
            "solution": "The user-provided problem is first validated to ensure it is self-contained, consistent, and scientifically sound.\n\n### Step 1: Extract Givens\n- **Indices and Counts**:\n  - Number of items: $n$.\n  - Item index: $i \\in \\{1, \\dots, n\\}$.\n- **Global Parameters**:\n  - Departure in $D$ days.\n  - Trip duration: $T$ days.\n  - Luggage capacity: $C \\in \\mathbb{Z}_{\\ge 0}$.\n  - Budget: $B \\in \\mathbb{Z}_{\\ge 0}$.\n  - Shipping utility discount factor: $\\alpha \\in [0, 1]$.\n- **Item-Specific Parameters** (for each item $i$):\n  - Weight: $w_i \\in \\mathbb{Z}_{\\ge 0}$.\n  - Base utility: $u_i \\in \\mathbb{R}_{\\ge 0}$.\n  - Shipping cost: $s_i \\in \\mathbb{Z}_{\\ge 0}$.\n  - Buying cost: $b_i \\in \\mathbb{Z}_{\\ge 0}$.\n  - Shipping lead time: $L_i \\in \\mathbb{Z}_{\\ge 0}$.\n- **Actions and Utility Calculation**:\n  - Actions: skip, pack, ship, buy (mutually exclusive).\n  - Shipping delay: $d_i = \\max\\{0, L_i - D\\}$.\n  - Realized utilities:\n    - skip: $0$.\n    - pack: $u_i$ (consumes $w_i$ capacity).\n    - ship: $u_i \\cdot \\alpha^{d_i}$ if $d_i  T$, else $0$ (consumes $s_i$ budget).\n    - buy: $u_i$ (consumes $b_i$ budget).\n- **Objective**:\n  - Maximize the sum of realized utilities subject to total packed weight $\\le C$ and total spending $\\le B$.\n- **Required Task**:\n  - Derive a Dynamic Programming (DP) formulation.\n  - Implement an algorithm to compute the optimal total realized utility.\n  - Round results to $2$ decimal places.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is a variant of the Multiple-Choice Knapsack Problem (MCKP), a well-established problem in combinatorial optimization. It is mathematically and logically sound, resting on the principles of utility maximization under constraints.\n- **Well-Posedness**: The problem is well-posed. It seeks to maximize a linear objective function over a finite set of discrete choices, subject to linear constraints. An optimal solution value is guaranteed to exist and be unique, though the set of actions to achieve it may not be.\n- **Objectivity**: The problem statement is written in precise, unambiguous mathematical language. All terms are clearly defined.\n- **Completeness and Consistency**: The problem provides all necessary parameters ($n, C, B, D, T, \\alpha$, and properties for each item) for each test case. There are no contradictions in the setup.\n- **Feasibility**: The parameters specified are for a theoretical model and do not involve scientifically implausible or physically impossible conditions.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is a standard application of dynamic programming to a resource allocation problem. A complete solution will be provided.\n\n### Dynamic Programming Formulation\n\nThis problem can be solved using dynamic programming because it exhibits the property of optimal substructure. The optimal solution for a set of $k$ items can be constructed from the optimal solution for a smaller set of $k-1$ items. We make a decision for the $k$-th item and combine it with the optimal result for the first $k-1$ items given the remaining resources.\n\n**State Definition**\nLet $V_k(c, b)$ be the maximum total realized utility that can be achieved by making decisions for the first $k$ items (i.e., items $1, \\dots, k$), given a remaining luggage capacity of $c$ and a remaining budget of $b$. The state is defined by the number of items considered and the resources available.\n\n**Base Case**\nIf we have considered zero items ($k=0$), no utility has been accumulated. Therefore, for any capacity $c$ and budget $b$:\n$$\nV_0(c, b) = 0\n$$\n\n**Recurrence Relation**\nTo compute $V_k(c, b)$, we consider the decision for item $k$. There are four mutually exclusive choices:\n\n1.  **Skip item $k$**: We gain no utility from item $k$ and use no resources. The total utility is the maximum we could obtain from the first $k-1$ items with the same resources.\n    Utility: $V_{k-1}(c, b)$.\n\n2.  **Pack item $k$**: This is feasible only if $c \\ge w_k$. The utility from this action is $u_k$ plus the maximum utility from the first $k-1$ items with the remaining capacity $c-w_k$ and budget $b$.\n    Utility: $u_k + V_{k-1}(c-w_k, b)$.\n\n3.  **Ship item $k$**: This is feasible only if $b \\ge s_k$. The utility from this action is the pre-calculated realized shipping utility $u_{k, \\text{ship}}$ plus the maximum utility from the first $k-1$ items with capacity $c$ and remaining budget $b-s_k$. The realized shipping utility is given by:\n    $$\n    u_{k, \\text{ship}} = \\begin{cases} u_k \\cdot \\alpha^{\\max\\{0, L_k-D\\}}  \\text{if } \\max\\{0, L_k-D\\}  T \\\\ 0  \\text{otherwise} \\end{cases}\n    $$\n    Total Utility: $u_{k, \\text{ship}} + V_{k-1}(c, b-s_k)$.\n\n4.  **Buy item $k$**: This is feasible only if $b \\ge b_k$. The utility is $u_k$ plus the maximum utility from the first $k-1$ items with capacity $c$ and remaining budget $b-b_k$.\n    Total Utility: $u_k + V_{k-1}(c, b-b_k)$.\n\nAccording to the principle of optimality, $V_k(c, b)$ is the maximum value achievable across all feasible choices for item $k$. The recurrence relation is therefore:\n$$\nV_k(c, b) = \\max \\begin{cases}\nV_{k-1}(c, b)  \\text{(skip)} \\\\\nu_k + V_{k-1}(c-w_k, b)  \\text{if } c \\ge w_k \\text{ (pack)} \\\\\nu_{k, \\text{ship}} + V_{k-1}(c, b-s_k)  \\text{if } b \\ge s_k \\text{ (ship)} \\\\\nu_k + V_{k-1}(c, b-b_k)  \\text{if } b \\ge b_k \\text{ (buy)}\n\\end{cases}\n$$\nThe `max` function is taken over all choices that are feasible for the given state $(c, b)$.\n\n**Final Answer**\nThe optimal total realized utility for all $n$ items with initial capacity $C$ and budget $B$ is given by $V_n(C, B)$.\n\n### Algorithmic Implementation\n\nA bottom-up (tabular) approach is suitable for implementing this DP recurrence. The state $V_k(c, b)$ depends only on states from the previous stage, $k-1$. This allows for a space optimization where we only need to store the DP table for two consecutive stages, $k-1$ and $k$. Let's call these `dp_prev` and `dp_curr`.\n\nThe algorithm proceeds as follows:\n1.  For each item $k=1, \\dots, n$, pre-calculate its realized shipping utility, $u_{k, \\text{ship}}$.\n2.  Initialize a 2D array, `dp_prev`, of size $(C+1) \\times (B+1)$ to all zeros. This represents the base case $V_0(c, b) = 0$.\n3.  Iterate through each item $k$ from $1$ to $n$:\n    a. Create a new 2D array, `dp_curr`, of size $(C+1) \\times (B+1)$.\n    b. Iterate through each capacity state $c$ from $0$ to $C$.\n    c. Iterate through each budget state $b$ from $0$ to $B$.\n    d. For each state $(c, b)$, calculate the utility for each of the four possible actions for item $k$, using the values stored in `dp_prev` for the subproblems.\n    e. Set `dp_curr[c][b]` to the maximum utility among the feasible actions.\n    f. After filling `dp_curr` for all $(c, b)$, update `dp_prev = dp_curr` to prepare for the next item.\n4.  After iterating through all $n$ items, the final answer is the value at `dp_prev[C][B]`.\n\nThis procedure systematically builds the optimal solution by considering one item at a time, ensuring that at each stage $k$, the table `dp_curr` stores the optimal utilities for items $1, \\dots, k$ for all possible resource levels.",
            "answer": "```python\nimport numpy as np\n\ndef solve_case(C, B, D, T, alpha, items):\n    \"\"\"\n    Computes the optimal total realized utility for a single test case using dynamic programming.\n\n    This function implements a bottom-up DP approach for the multiple-choice knapsack problem.\n    The state is defined by the available capacity and budget. We iterate through each item,\n    and for each item, we update the DP table to reflect the optimal choices (skip, pack,\n    ship, buy) made so far.\n    \"\"\"\n    \n    # dp_table[c][b] will store the maximum utility for capacity c and budget b.\n    # We use float64 for precision with utility values.\n    dp_table = np.zeros((C + 1, B + 1), dtype=np.float64)\n\n    # Process each item one by one\n    for item in items:\n        w, u, s, b_cost, L = item['w'], item['u'], item['s'], item['b'], item['L']\n\n        # Pre-calculate the realized utility from shipping\n        delay = max(0, L - D)\n        u_ship = 0.0\n        if delay  T:\n            u_ship = u * (alpha ** delay)\n\n        # Create a new DP table for the current stage (after considering this item)\n        # It's initialized with the previous stage's values, representing the 'skip' option.\n        dp_next = dp_table.copy()\n\n        # Update dp_next based on the three other actions: pack, ship, buy.\n        # This requires accessing the previous state's table (dp_table).\n\n        # Option: Pack item\n        if w > 0: # Optimization: only loop if packing consumes resources\n            for c in range(w, C + 1):\n                # The update here is for all budget levels b\n                dp_next[c, :] = np.maximum(dp_next[c, :], u + dp_table[c - w, :])\n\n        # Option: Ship item\n        if s > 0: # Optimization\n            if u_ship > 0:\n                for b_budget in range(s, B + 1):\n                    # The update here is for all capacity levels c\n                    dp_next[:, b_budget] = np.maximum(dp_next[:, b_budget], u_ship + dp_table[:, b_budget - s])\n\n        # Option: Buy item\n        if b_cost > 0: # Optimization\n            for b_budget in range(b_cost, B + 1):\n                # The update here is for all capacity levels c\n                dp_next[:, b_budget] = np.maximum(dp_next[:, b_budget], u + dp_table[:, b_budget - b_cost])\n\n        # Move to the next stage by updating the main DP table\n        dp_table = dp_next\n\n    # The final answer is the max utility achievable with the full capacity C and budget B\n    optimal_utility = dp_table[C, B]\n    \n    return round(optimal_utility, 2)\n\ndef solve():\n    \"\"\"\n    Defines test cases and runs the solver for each, printing the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"C\": 5, \"B\": 25, \"D\": 2, \"T\": 5, \"alpha\": 0.8,\n            \"items\": [\n                {'w': 3, 'u': 20, 's': 12, 'b': 15, 'L': 1},\n                {'w': 2, 'u': 18, 's': 15, 'b': 25, 'L': 3},\n                {'w': 1, 'u': 6, 's': 3, 'b': 4, 'L': 2},\n                {'w': 4, 'u': 30, 's': 20, 'b': 100, 'L': 5}\n            ]\n        },\n        {\n            \"C\": 0, \"B\": 6, \"D\": 1, \"T\": 3, \"alpha\": 0.7,\n            \"items\": [\n                {'w': 2, 'u': 14, 's': 5, 'b': 16, 'L': 1},\n                {'w': 1, 'u': 5, 's': 2, 'b': 6, 'L': 2},\n                {'w': 3, 'u': 12, 's': 4, 'b': 20, 'L': 3}\n            ]\n        },\n        {\n            \"C\": 4, \"B\": 0, \"D\": 2, \"T\": 2, \"alpha\": 0.9,\n            \"items\": [\n                {'w': 1, 'u': 4, 's': 1, 'b': 3, 'L': 2},\n                {'w': 3, 'u': 16, 's': 5, 'b': 50, 'L': 1},\n                {'w': 1, 'u': 2, 's': 1, 'b': 2, 'L': 3}\n            ]\n        },\n        {\n            \"C\": 2, \"B\": 5, \"D\": 1, \"T\": 2, \"alpha\": 0.5,\n            \"items\": [\n                {'w': 1, 'u': 6, 's': 2, 'b': 8, 'L': 5},\n                {'w': 1, 'u': 3, 's': 1, 'b': 4, 'L': 1},\n                {'w': 2, 'u': 5, 's': 3, 'b': 7, 'L': 4}\n            ]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(case[\"C\"], case[\"B\"], case[\"D\"], case[\"T\"], case[\"alpha\"], case[\"items\"])\n        results.append(result)\n\n    # Format output as required: [r1,r2,...] with 2 decimal places.\n    formatted_results = ','.join(f'{r:.2f}' for r in results)\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "We now shift from finite resource allocation to decision-making over an infinite time horizon, a common setting in finance and economics. This exercise presents a classic optimal stopping problem: when to accept an investment opportunity from a stream of arriving offers . You will use the principle of optimality to formulate a Bellman equation, which elegantly captures the trade-off between accepting the current offer and waiting for a potentially better one, discounted by time.",
            "id": "2443380",
            "problem": "A fund manager faces an infinite-horizon dynamic selection problem modeling sequential investment opportunities. Time is discrete with periods indexed by $t \\in \\{0,1,2,\\dots\\}$. In each period $t$, exactly one investment opportunity arrives with quality $X_{t}$, where $\\{X_{t}\\}$ is an independent and identically distributed sequence with common density $f(x)=1$ on $[0,1]$ and $f(x)=0$ otherwise. Upon observing $X_{t}$, the manager must either accept the opportunity and irrevocably stop, receiving an immediate payoff equal to $X_{t}$ measured in present value, or reject it and continue to the next period. Future payoffs are discounted by a factor $\\delta \\in (0,1)$ per period. There is no recall: a rejected opportunity cannot be accepted later. The manager’s objective is to maximize the expected present value of the accepted payoff.\n\nDetermine the exact closed-form expression, as a function of $\\delta$, for the optimal acceptance threshold $\\tau^{\\ast}$ such that it is optimal to accept in a period if and only if $X_{t} \\ge \\tau^{\\ast}$.\n\nState your final answer as a single analytic expression in terms of $\\delta$. No numerical approximation or rounding is required.",
            "solution": "The user has provided a problem statement. I will now perform validation.\n\n**Step 1: Extract Givens**\n- **Problem Type**: Infinite-horizon dynamic selection problem.\n- **Time**: Discrete, indexed by $t \\in \\{0,1,2,\\dots\\}$.\n- **Investment Opportunity**: One per period, with quality $X_{t}$.\n- **Distribution of $X_t$**: $\\{X_{t}\\}$ is an independent and identically distributed (i.i.d.) sequence with common probability density function (PDF) $f(x)=1$ for $x \\in [0,1]$ and $f(x)=0$ otherwise. This is a uniform distribution on $[0,1]$.\n- **Decision Rule**: In each period $t$, upon observing $X_{t}$, the manager must either accept and stop, or reject and continue.\n- **Payoff Structure**: Accepting yields an immediate payoff of $X_{t}$.\n- **Discount Factor**: Future payoffs are discounted by a factor $\\delta \\in (0,1)$ per period.\n- **Constraint**: No recall of rejected opportunities.\n- **Objective**: Maximize the expected present value of the accepted payoff.\n- **Task**: Determine the optimal acceptance threshold $\\tau^{\\ast}$ as a function of $\\delta$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is a classic optimal stopping problem, a fundamental topic in dynamic programming, operations research, and economics. It is a well-established model known as a \"house-selling problem\" or \"secretary problem\" variant. The formulation is grounded in standard probability theory and optimization principles.\n- **Well-Posed**: The problem is well-posed. The stationary nature of the i.i.d. process and the infinite horizon with discounting ensure that a unique, stationary optimal policy exists. The objective function is clearly defined, and all necessary parameters (distribution, discount factor) are provided.\n- **Objective**: The problem is stated with objective and precise mathematical language, free from ambiguity or subjective claims.\n- **Completeness and Consistency**: The problem is self-contained and internally consistent. There is no missing information required to derive the optimal policy, nor are there contradictory constraints.\n- **Feasibility**: The setup is a standard theoretical model and is entirely feasible within its mathematical framework.\n- **Relation to Topic**: The problem is a direct application of the principle of optimality in the context of a financial/economic decision problem, which falls squarely within the specified field of computational economics and finance.\n\n**Step 3: Verdict and Action**\nThe problem is valid. I will proceed with the solution.\n\nThe problem describes an infinite-horizon, discrete-time optimal stopping problem. The stationary nature of the problem (the distribution of opportunities $X_t$ and the discount factor $\\delta$ are constant over time) implies that the optimal policy will also be stationary. This means there exists a single, time-independent threshold $\\tau^{\\ast}$ that dictates the optimal decision in every period.\n\nLet $V$ be the maximum expected present value that can be obtained, evaluated at the beginning of any period, before the quality of the investment opportunity $X_t$ for that period is known. Due to stationarity, $V$ is a constant.\n\nIn any period $t$, the manager observes a quality $X_t = x$. The manager has two choices:\n$1$. **Accept**: The process terminates, and the manager receives a payoff of $x$.\n$2$. **Reject**: The manager forgoes the payoff $x$ and continues to the next period. The expected value of continuing, as viewed from period $t$, is the discounted value of starting the next period optimally, which is $\\delta V$.\n\nThe principle of optimality states that the manager will choose the action that maximizes the expected payoff. Therefore, upon observing $x$, the value obtained is $\\max(x, \\delta V)$.\n\nThe value function $V$ is the expectation of this outcome over all possible realizations of $X_t$. The random variable $X_t$ is uniformly distributed on $[0,1]$, with PDF $f(x)=1$. Thus, the Bellman equation for $V$ is:\n$$V = \\mathbb{E}[\\max(X_t, \\delta V)] = \\int_{-\\infty}^{\\infty} \\max(x, \\delta V) f(x) dx = \\int_{0}^{1} \\max(x, \\delta V) dx$$\n\nThe structure of the term $\\max(x, \\delta V)$ defines the optimal policy. It is optimal to accept the offer if $x \\ge \\delta V$ and reject if $x  \\delta V$. This confirms the existence of an optimal threshold, which is given by $\\tau^{\\ast} = \\delta V$.\n\nWe can now solve the integral equation for $V$ by splitting the integral at the threshold $\\delta V$. Note that since $X_t \\in [0,1]$ and $\\delta \\in (0,1)$, it must be that $V \\le 1$, which implies $\\delta V  1$. The threshold $\\delta V$ is within the interval of integration $[0,1]$.\n$$V = \\int_{0}^{\\delta V} (\\delta V) dx + \\int_{\\delta V}^{1} x dx$$\n\nWe evaluate each integral:\nThe first integral is:\n$$\\int_{0}^{\\delta V} (\\delta V) dx = \\delta V [x]_{0}^{\\delta V} = \\delta V (\\delta V - 0) = \\delta^2 V^2$$\n\nThe second integral is:\n$$\\int_{\\delta V}^{1} x dx = \\left[ \\frac{x^2}{2} \\right]_{\\delta V}^{1} = \\frac{1^2}{2} - \\frac{(\\delta V)^2}{2} = \\frac{1}{2} - \\frac{\\delta^2 V^2}{2}$$\n\nSubstituting these back into the equation for $V$:\n$$V = \\delta^2 V^2 + \\left( \\frac{1}{2} - \\frac{\\delta^2 V^2}{2} \\right)$$\n$$V = \\frac{1}{2}\\delta^2 V^2 + \\frac{1}{2}$$\n\nThis is a quadratic equation for $V$. Rearranging into the standard form $aV^2 + bV + c = 0$:\n$$\\frac{1}{2}\\delta^2 V^2 - V + \\frac{1}{2} = 0$$\nMultiplying by $2$ to clear the fractions gives:\n$$\\delta^2 V^2 - 2V + 1 = 0$$\n\nWe solve for $V$ using the quadratic formula, $V = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n$$V = \\frac{-(-2) \\pm \\sqrt{(-2)^2 - 4(\\delta^2)(1)}}{2\\delta^2}$$\n$$V = \\frac{2 \\pm \\sqrt{4 - 4\\delta^2}}{2\\delta^2} = \\frac{2 \\pm 2\\sqrt{1 - \\delta^2}}{2\\delta^2}$$\n$$V = \\frac{1 \\pm \\sqrt{1 - \\delta^2}}{\\delta^2}$$\n\nThis gives two potential solutions for $V$. We must select the one that is economically valid. The value $V$ represents an expected payoff from opportunities that are bounded by $1$, so it must be that $V \\le 1$.\n\nLet's examine the two roots as $\\delta \\to 0$:\n$1$. $V_1 = \\frac{1 + \\sqrt{1 - \\delta^2}}{\\delta^2}$. As $\\delta \\to 0^+$, the numerator approaches $1 + \\sqrt{1} = 2$, while the denominator approaches $0$. Thus, $V_1 \\to \\infty$. This is not an economically meaningful solution.\n$2$. $V_2 = \\frac{1 - \\sqrt{1 - \\delta^2}}{\\delta^2}$. As $\\delta \\to 0^+$, we have an indeterminate form $0/0$. We can use L'Hôpital's rule or rationalize the numerator by multiplying by its conjugate:\n$$V_2 = \\frac{1 - \\sqrt{1 - \\delta^2}}{\\delta^2} \\times \\frac{1 + \\sqrt{1 - \\delta^2}}{1 + \\sqrt{1 - \\delta^2}} = \\frac{1 - (1 - \\delta^2)}{\\delta^2(1 + \\sqrt{1 - \\delta^2})} = \\frac{\\delta^2}{\\delta^2(1 + \\sqrt{1 - \\delta^2})} = \\frac{1}{1 + \\sqrt{1 - \\delta^2}}$$\nNow, taking the limit as $\\delta \\to 0^+$:\n$$\\lim_{\\delta \\to 0^+} V_2 = \\frac{1}{1 + \\sqrt{1 - 0}} = \\frac{1}{2}$$\nThis result makes sense: if future payoffs are worthless ($\\delta=0$), the optimal strategy is to accept the very first opportunity $X_0$. The expected payoff is then $\\mathbb{E}[X_0] = \\int_0^1 x dx = 1/2$.\nFurthermore, for $\\delta \\in (0,1)$, we have $0 \\le \\sqrt{1-\\delta^2}  1$, so $V_2 = \\frac{1}{1 + \\sqrt{1-\\delta^2}}$ lies in the interval $[1/2, 1)$, satisfying the condition $V \\le 1$.\n\nThus, the correct value function is:\n$$V = \\frac{1 - \\sqrt{1 - \\delta^2}}{\\delta^2}$$\n\nThe problem asks for the optimal acceptance threshold $\\tau^{\\ast}$. As established earlier, $\\tau^{\\ast} = \\delta V$.\nSubstituting the expression for $V$:\n$$\\tau^{\\ast} = \\delta \\cdot V = \\delta \\left( \\frac{1 - \\sqrt{1 - \\delta^2}}{\\delta^2} \\right)$$\n$$\\tau^{\\ast} = \\frac{1 - \\sqrt{1 - \\delta^2}}{\\delta}$$\n\nThis is the exact closed-form expression for the optimal acceptance threshold.",
            "answer": "$$\\boxed{\\frac{1 - \\sqrt{1 - \\delta^2}}{\\delta}}$$"
        },
        {
            "introduction": "Our final practice explores how the principle of optimality applies to strategic situations where your decisions influence the future environment. In this dynamic pricing problem, a firm's current price affects consumers' future reference price, creating a path-dependent challenge . You will solve this finite-horizon problem using backward induction, a powerful computational technique that works backward from the final period to determine the optimal action at every possible state, perfectly illustrating the logic of dynamic programming.",
            "id": "2443432",
            "problem": "A single-product firm sets intertemporal prices to maximize discounted profits when consumers form a reference price based on the last $k$ prices charged by the firm. Time is discrete, with periods indexed by $t \\in \\{1,2,\\ldots,T\\}$. In period $t$, the firm chooses a price $p_t$ from a finite admissible set $\\mathcal{P} = \\{0,1,2,\\ldots,10\\}$. Let the reference price be the simple average of the last $k$ realized prices prior to period $t$, denoted by $r_t = \\frac{1}{k}\\sum_{j=1}^{k} p_{t-j}$, where the pre-sample history $\\left(p_{0},p_{-1},\\ldots,p_{-(k-1)}\\right)$ is given. Demand in period $t$ is\n$$\nq_t = \\max\\left\\{0,\\, a - b\\,p_t + \\gamma\\,(r_t - p_t)\\right\\},\n$$\nand the period profit is\n$$\n\\pi_t = (p_t - c)\\,q_t.\n$$\nThe firm’s objective is to choose the sequence $\\{p_t\\}_{t=1}^T$ to maximize the discounted sum of profits\n$$\n\\sum_{t=1}^{T} \\beta^{t-1}\\,\\pi_t,\n$$\nwhere $a0$, $b0$, $\\gamma \\ge 0$, $c \\ge 0$, $T \\in \\mathbb{N}$, $k \\in \\mathbb{N}$, and $\\beta \\in (0,1]$ are given parameters. The state of the system at the start of period $t$ is the ordered $k$-tuple of the last $k$ realized prices $\\left(p_{t-1},p_{t-2},\\ldots,p_{t-k}\\right)$. State transitions are deterministic: after choosing $p_t$, the next state becomes $\\left(p_t,p_{t-1},\\ldots,p_{t-k+1}\\right)$.\n\nAmong multiple profit-maximizing sequences, select the sequence that chooses the smallest admissible price at the earliest period where a tie occurs. Equivalently, at every period $t$ and for every state, if multiple $p_t \\in \\mathcal{P}$ yield the same maximized objective value, select the smallest such $p_t$.\n\nFor each parameterization in the test suite below, compute the optimal price sequence $\\{p_t^\\star\\}_{t=1}^T$. No physical units apply. Your program must output only a single line containing all results aggregated as a list of lists, with each inner list containing the $T$ optimal prices for that test case in temporal order, and with no spaces. For example, the output format must be exactly of the form\n$$\n[[p_1^\\star,\\ldots,p_T^\\star],[\\ldots],\\ldots].\n$$\n\nTest suite:\n- Case $1$ (general case): $T=3$, $k=2$, $a=12$, $b=1.5$, $\\gamma=0.8$, $c=2$, $\\beta=0.95$, initial history $\\left(p_{0},p_{-1}\\right) = (4,6)$, $\\mathcal{P}=\\{0,1,2,\\ldots,10\\}$.\n- Case $2$ (single-period boundary): $T=1$, $k=3$, $a=8$, $b=1$, $\\gamma=0.5$, $c=1$, $\\beta=0.9$, initial history $\\left(p_{0},p_{-1},p_{-2}\\right) = (2,2,2)$, $\\mathcal{P}=\\{0,1,2,\\ldots,10\\}$.\n- Case $3$ (strong reference effect, minimal memory): $T=4$, $k=1$, $a=10$, $b=2$, $\\gamma=2$, $c=3$, $\\beta=0.9$, initial history $\\left(p_{0}\\right) = (5)$, $\\mathcal{P}=\\{0,1,2,\\ldots,10\\}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of the three optimal price sequences, each enclosed in square brackets and with no spaces, in the order of the cases above. For example, the required output pattern is\n$$\n[[\\cdot,\\cdot,\\cdot],[\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot]].\n$$",
            "solution": "The problem as stated is valid. It is a well-posed, finite-horizon, deterministic dynamic programming problem from the field of computational economics, free of any scientific or logical flaws. A unique optimal solution exists and can be computed using the principle of optimality.\n\nThe firm's objective is to find a price sequence $\\{p_t\\}_{t=1}^T$ that maximizes the total discounted profit. This problem can be solved using dynamic programming, for which we define the standard components.\n\n1.  **State**: The state of the system at the beginning of period $t$ must encapsulate all information from the past that is relevant for future decisions. In this model, the future profit depends on the next reference price, which in turn depends on the recent price history. Therefore, the state at time $t$ is the ordered $k$-tuple of the last $k$ prices, $S_t = (p_{t-1}, p_{t-2}, \\ldots, p_{t-k})$. The state space is discrete and finite, consisting of $|\\mathcal{P}|^k$ possible states, where $|\\mathcal{P}| = 11$.\n\n2.  **Action**: In each period $t$, the firm chooses an action, which is the price $p_t$. The set of admissible actions is the finite set $\\mathcal{P} = \\{0, 1, 2, \\ldots, 10\\}$.\n\n3.  **Reward Function**: The reward in period $t$ is the profit $\\pi_t$. This profit depends on the current state $S_t$ (which determines the reference price $r_t$) and the chosen action $p_t$. The reference price is $r_t = \\frac{1}{k}\\sum_{j=1}^{k} p_{t-j}$. The profit function is $\\pi_t(S_t, p_t) = (p_t - c)q_t$, where the demand is $q_t = \\max\\{0, a - bp_t + \\gamma(r_t - p_t)\\}$. This can be rewritten as $q_t = \\max\\{0, a + \\gamma r_t - (b+\\gamma)p_t\\}$.\n\n4.  **State Transition**: The system is deterministic. If the state at time $t$ is $S_t = (p_{t-1}, \\ldots, p_{t-k})$ and the firm chooses price $p_t$, the state at time $t+1$ becomes $S_{t+1} = (p_t, p_{t-1}, \\ldots, p_{t-k+1})$.\n\nLet $V_t(S_t)$ be the maximum discounted profit from period $t$ to the end of the horizon $T$, given the state is $S_t$. The principle of optimality is expressed through the Bellman equation:\n$$\nV_t(S_t) = \\max_{p_t \\in \\mathcal{P}} \\left\\{ \\pi_t(S_t, p_t) + \\beta V_{t+1}(S_{t+1}) \\right\\}\n$$\nfor $t=1, \\ldots, T$. The terminal condition is that there are no future profits after period $T$, so $V_{T+1}(S) = 0$ for any state $S$.\n\nThe problem is solved algorithmically using backward induction:\n\n1.  **Initialization (Period $t=T$):** We begin at the final period $T$. For each possible state $S_T = (p_{T-1}, \\ldots, p_{T-k})$, we solve for the optimal price $p_T^*(S_T)$:\n    $$\n    V_T(S_T) = \\max_{p_T \\in \\mathcal{P}} \\{ \\pi_T(S_T, p_T) \\}\n    $$\n    We compute the profit for each $p_T \\in \\mathcal{P}$ and find the price that yields the maximum profit. The tie-breaking rule dictates that we must select the smallest price if multiple prices yield the same maximum value. We store this optimal price in a policy function, $\\Pi_T(S_T) = p_T^*(S_T)$, and the corresponding maximum value in the value function, $V_T(S_T)$. This is done for all possible states in the state space.\n\n2.  **Recursive Step (Periods $t = T-1, \\ldots, 1$):** We step backward one period at a time. For each period $t$ and each state $S_t$, we find the optimal price $p_t^*(S_t)$ by solving the Bellman equation:\n    $$\n    V_t(S_t) = \\max_{p_t \\in \\mathcal{P}} \\left\\{ \\pi_t(S_t, p_t) + \\beta V_{t+1}((p_t, p_{t-1}, \\ldots, p_{t-k+1})) \\right\\}\n    $$\n    For each candidate price $p_t \\in \\mathcal{P}$, we calculate the immediate profit $\\pi_t(S_t, p_t)$ and add the discounted future value $\\beta V_{t+1}(S_{t+1})$, where the future value $V_{t+1}$ has already been computed in the previous step of the induction. The price $p_t$ that maximizes this sum is chosen as the optimal policy $\\Pi_t(S_t)$, again respecting the tie-breaking rule. The maximized sum is stored as $V_t(S_t)$.\n\n3.  **Optimal Path Reconstruction:** After the backward induction is complete, we have the optimal policy $\\Pi_t(S_t)$ for all $t \\in \\{1, \\ldots, T\\}$ and all states $S_t$. To find the optimal price sequence, we perform a forward pass:\n    - Start with the given initial state $S_1 = (p_0, p_{-1}, \\ldots, p_{-(k-1)})$.\n    - The first optimal price is $p_1^* = \\Pi_1(S_1)$.\n    - The state for the next period is $S_2 = (p_1^*, p_0, \\ldots, p_{-(k-2)})$.\n    - The second optimal price is $p_2^* = \\Pi_2(S_2)$.\n    - This process is repeated until $t=T$, yielding the optimal price sequence $\\{p_1^*, p_2^*, \\ldots, p_T^*\\}$.\n\nThis algorithm is implemented by using dictionaries to map state tuples to their values and optimal policies. The finite state space for each period is generated by taking the Cartesian product of the admissible price set $\\mathcal{P}$ with itself $k$ times.",
            "answer": "```python\nimport numpy as np\nfrom itertools import product\n\ndef solve():\n    \"\"\"\n    Main function to solve the dynamic pricing problem for all test cases\n    and print the results in the specified format.\n    \"\"\"\n\n    def solve_case(T, k, a, b, gamma, c, beta, initial_history):\n        \"\"\"\n        Solves a single instance of the dynamic pricing problem using backward induction.\n        \"\"\"\n        P_set = list(range(11))\n        \n        # The state is a tuple of the last k prices.\n        # Handle k=0 case for generality, though problem states k>=1.\n        all_states = list(product(P_set, repeat=k)) if k > 0 else [()]\n        \n        # V: Value function memoization table, V[t][state] = max_profit\n        # policy: Policy function table, policy[t][state] = optimal_price\n        V = {}\n        policy = {}\n\n        # Initialize value function at the terminal time T+1 to zero.\n        V[T + 1] = {s: 0.0 for s in all_states}\n\n        # Backward induction from T down to 1\n        for t in range(T, 0, -1):\n            V[t] = {}\n            policy[t] = {}\n            for state in all_states:\n                # state = (p_{t-1}, ..., p_{t-k})\n                r_t = np.mean(state) if k > 0 else 0.0\n                \n                # Evaluate the value for each possible price p_t\n                p_values = {}\n                for p_t in P_set:\n                    q_t = max(0, a + gamma * r_t - (b + gamma) * p_t)\n                    profit_t = (p_t - c) * q_t\n                    \n                    next_state = (p_t,) + state[:-1] if k > 0 else ()\n                    \n                    # Bellman equation\n                    value = profit_t + beta * V[t + 1][next_state]\n                    p_values[p_t] = value\n                \n                # Find the maximum value among all possible prices\n                max_value = -float('inf')\n                for p_t in P_set:\n                    if p_values[p_t] > max_value:\n                        max_value = p_values[p_t]\n\n                # Find the smallest price that achieves the maximum value (tie-breaking)\n                best_p = -1\n                for p_t in P_set:\n                    if np.isclose(p_values[p_t], max_value):\n                        best_p = p_t\n                        break\n                \n                V[t][state] = max_value\n                policy[t][state] = best_p\n\n        # Forward pass to reconstruct the optimal price path\n        optimal_path = []\n        current_state = initial_history\n        for t in range(1, T + 1):\n            optimal_p = policy[t][current_state]\n            optimal_path.append(optimal_p)\n            current_state = (optimal_p,) + current_state[:-1] if k > 0 else ()\n\n        return optimal_path\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'T': 3, 'k': 2, 'a': 12, 'b': 1.5, 'gamma': 0.8, 'c': 2, 'beta': 0.95, 'initial_history': (4, 6)},\n        {'T': 1, 'k': 3, 'a': 8, 'b': 1, 'gamma': 0.5, 'c': 1, 'beta': 0.9, 'initial_history': (2, 2, 2)},\n        {'T': 4, 'k': 1, 'a': 10, 'b': 2, 'gamma': 2, 'c': 3, 'beta': 0.9, 'initial_history': (5,)},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = solve_case(**params)\n        results.append(result)\n\n    # Format the output string exactly as required, with no spaces.\n    formatted_results = [f\"[{','.join(map(str, r))}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}