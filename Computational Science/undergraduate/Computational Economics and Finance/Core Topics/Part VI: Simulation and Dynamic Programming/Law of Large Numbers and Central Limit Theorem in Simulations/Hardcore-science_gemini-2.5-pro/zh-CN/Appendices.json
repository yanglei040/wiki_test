{
    "hands_on_practices": [
        {
            "introduction": "这项练习以一种最经典的形式，为你提供了一个动手实践中心极限定理的机会。我们将模拟一个学生在多项选择测验中的得分，该得分可以被看作是许多独立的伯努利试验（每个问题回答正确或错误）的总和。通过这个模拟，你将观察到总分的分布在经过适当的标准化之后，如何收敛于标志性的正态分布钟形曲线，并使用标准的统计检验来量化这一收敛过程 。这个练习旨在巩固一个核心直觉：由许多微小、独立的因素累积而成的复杂结果，其分布往往会遵循一个可预测的正态模式。",
            "id": "2405591",
            "problem": "考虑一个理想化的选择题测试环境。一名学生回答一份包含 $Q$ 个独立问题的试卷。每个问题提供 $c$ 个选项，其中只有一个是正确的。对于每个问题，学生有 $k$ 的概率知道答案（此时以概率 $1$ 选对），或者有 $1-k$ 的概率不知道答案（此时学生在 $c$ 个选项中均匀猜测，以概率 $1/c$ 选对）。令 $X_i$ 为问题 $i$ 回答正确的指示变量，其中 $i \\in \\{1,\\dots,Q\\}$。正确答案的总数（测试得分）为 $S_Q = \\sum_{i=1}^{Q} X_i$。对于每个固定的三元组 $(Q,c,k)$，每个问题的正确概率为 $p = k + (1-k)/c$，因此 $X_i$ 是参数为 $p$ 的独立同分布的伯努利随机变量。定义标准化分数为 $Z_Q = \\dfrac{S_Q - Q p}{\\sqrt{Q p (1-p)}}$。\n\n根据中心极限定理 (CLT)，当 $Q \\to \\infty$ 时，$Z_Q$ 的分布近似于标准正态分布。您的任务是执行一次蒙特卡洛计算，通过使用柯尔莫哥洛夫-斯米尔诺夫 (KS) 距离比较 $Z_Q$ 的经验分布与标准正态分布，来评估此近似在有限样本中的效果。\n\n对于下面列出的每个测试用例，您必须：\n- 从上述指定的模型中生成 $N$ 个独立的 $S_Q$ 抽样，每个测试用例的抽样次数为 $N = 80000$。\n- 对所有随机数生成使用固定的随机种子 $20240517$，以确保所有测试用例的可复现性。\n- 计算根据模拟的 $S_Q$ 抽样计算出的标准化分数 $Z_Q$ 的经验累积分布函数（经验 CDF）$F_N$。\n- 计算柯尔莫哥洛夫-斯米尔诺夫距离 $D_N = \\sup_{x \\in \\mathbb{R}} \\left| F_N(x) - \\Phi(x) \\right|$，其中 $\\Phi$ 是标准正态累积分布函数。\n\n为每个测试用例报告一个实数，即上面定义的 $D_N$ 的值。所有报告的数值输出均以十进制形式表示（不使用任何百分比符号）。\n\n参数值测试套件：\n- 用例 $1$（一般情况）：$(Q,c,k) = (100,4,0.6)$。\n- 用例 $2$（小聚合边界）：$(Q,c,k) = (5,4,0.6)$。\n- 用例 $3$（对称成功概率，大聚合）：$(Q,c,k) = (400,2,0.0)$。\n- 用例 $4$（罕见成功概率，大聚合）：$(Q,c,k) = (400,20,0.0)$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含四个用例的结果，按顺序以逗号分隔的列表形式包含在方括号内，例如 $[d_1,d_2,d_3,d_4]$，其中每个 $d_j$ 是为用例 $j \\in \\{1,2,3,4\\}$ 计算出的柯尔莫哥洛夫-斯米尔诺夫距离 $D_N$。",
            "solution": "问题陈述已经过严格验证，并被认为是合理的。这是一个计算统计学中定义明确的问题，其基础是概率论的基本原理，特别是中心极限定理 (CLT)。任务是使用蒙特卡洛模拟，数值化地评估伯努利随机变量的标准化和向标准正态分布收敛的速度。\n\n该模型描述了一次包含 $Q$ 个问题的测试的总分 $S_Q$。每个问题 $i$ 回答正确的概率是固定的 $p$，因此结果是一个独立的伯努利试验 $X_i \\sim \\text{Bernoulli}(p)$。概率 $p$ 由全概率定律导出：\n$$\np = P(\\text{正确}) = P(\\text{正确} | \\text{知道})P(\\text{知道}) + P(\\text{正确} | \\text{猜测})P(\\text{猜测})\n$$\n根据给定的参数，这等于 $p = (1) \\cdot k + (1/c) \\cdot (1-k)$，简化为 $p = k + (1-k)/c$。\n\n总分 $S_Q = \\sum_{i=1}^{Q} X_i$ 是 $Q$ 个独立同分布 (i.i.d.) 的伯努利随机变量之和。因此，$S_Q$ 服从二项分布，$S_Q \\sim \\text{Binomial}(Q, p)$。$S_Q$ 的期望值（均值）是 $E[S_Q] = Qp$，其方差是 $\\text{Var}(S_Q) = Qp(1-p)$。\n\n中心极限定理断言，标准化分数的分布，\n$$\nZ_Q = \\frac{S_Q - E[S_Q]}{\\sqrt{\\text{Var}(S_Q)}} = \\frac{S_Q - Qp}{\\sqrt{Qp(1-p)}}\n$$\n在 $Q \\to \\infty$ 时趋近于标准正态分布 $\\mathcal{N}(0,1)$。问题要求使用柯尔莫哥洛夫-斯米尔诺夫 (KS) 距离对有限 $Q$ 的这种近似进行定量评估。\n\n计算过程如下：\n$1$. 对于由三元组 $(Q, c, k)$ 指定的每个测试用例，首先计算成功概率 $p = k + (1-k)/c$。\n$2$. 通过从分布 $S_Q \\sim \\text{Binomial}(Q, p)$ 中生成 $N = 80000$ 个独立的总分样本 $\\{s_1, s_2, \\dots, s_N\\}$ 来执行蒙特卡洛模拟。这在计算上比模拟 $N \\times Q$ 次独立的伯努利试验更高效。使用固定的随机种子 $20240517$ 以确保结果的可复现性。\n$3$. 每个模拟分数 $s_j$ 都被标准化以获得标准化分数的样本 $\\{z_1, z_2, \\dots, z_N\\}$，其中每个 $z_j$ 计算如下：\n$$\nz_j = \\frac{s_j - Qp}{\\sqrt{Qp(1-p)}}\n$$\n$4$. 计算标准化样本 $\\{z_j\\}$ 的经验累积分布函数 (ECDF) 与标准正态分布的理论 CDF $\\Phi(x)$ 之间的柯尔莫哥洛夫-斯米尔诺夫距离 $D_N$。ECDF 由 $F_N(x) = \\frac{1}{N}\\sum_{j=1}^{N} \\mathbb{I}(z_j \\le x)$ 给出，其中 $\\mathbb{I}$ 是指示函数。KS 距离定义为：\n$$\nD_N = \\sup_{x \\in \\mathbb{R}} |F_N(x) - \\Phi(x)|\n$$\n为四个测试用例中的每一个计算此距离。`scipy.stats.kstest` 函数为此计算提供了一个直接且数值稳定的实现。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef solve():\n    \"\"\"\n    Computes the Kolmogorov-Smirnov distance between the empirical distribution\n    of a standardized test score and the standard normal distribution for several\n    test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (100, 4, 0.6),   # Case 1: general case\n        (5, 4, 0.6),     # Case 2: small aggregation boundary\n        (400, 2, 0.0),   # Case 3: symmetric success probability, large aggregation\n        (400, 20, 0.0),  # Case 4: rare success probability, large aggregation\n    ]\n\n    # Simulation parameters\n    N_draws = 80000\n    seed = 20240517\n\n    # Initialize a random number generator with the specified seed for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    results = []\n    for case in test_cases:\n        Q, c, k = case\n\n        # Step 1: Calculate the per-question correctness probability 'p'.\n        # p = k + (1-k)/c\n        p = k + (1.0 - k) / c\n\n        # Step 2: Generate N draws of the total score S_Q from a Binomial distribution.\n        # S_Q ~ Binomial(Q, p)\n        # Using rng.binomial is more efficient than simulating Q Bernoulli trials N times.\n        s_q_samples = rng.binomial(n=Q, p=p, size=N_draws)\n\n        # Step 3: Compute the standardized scores Z_Q.\n        # Z_Q = (S_Q - E[S_Q]) / sqrt(Var(S_Q))\n        # E[S_Q] = Q * p\n        # Var(S_Q) = Q * p * (1-p)\n        mean_s_q = Q * p\n        std_dev_s_q = np.sqrt(Q * p * (1.0 - p))\n        \n        # Avoid division by zero if variance is zero (p=0 or p=1).\n        # In such a case, S_Q is constant and Z_Q is not well-defined. The KS distance\n        # would be maximal, but the problem cases avoid this scenario.\n        if std_dev_s_q == 0:\n            # This case is not expected based on problem description,\n            # but as a matter of robust implementation, it should be handled.\n            # a constant variable's CDF is a step function. The distance to a\n            # continuous CDF like the normal a distance of 0.5.\n            ks_distance = 0.5\n        else:\n            z_q_samples = (s_q_samples - mean_s_q) / std_dev_s_q\n\n            # Step 4: Compute the Kolmogorov-Smirnov distance D_N.\n            # kstest compares the empirical CDF of the sample with the theoretical\n            # standard normal CDF ('norm'). It returns the KS statistic and the p-value.\n            # We only need the statistic, which corresponds to D_N.\n            ks_statistic, _ = kstest(z_q_samples, 'norm')\n            ks_distance = ks_statistic\n        \n        results.append(ks_distance)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在见证了中心极限定理的威力之后，理解其局限性也同等重要。本练习通过探索一个中心极限定理失效的场景，来挑战该定理的假设前提。我们将使用帕累托分布（Pareto distribution），这是一种在金融领域常用于模拟市场崩盘或巨额保险索赔等极端事件的“重尾”分布，其方差为无穷大，不满足中心极限定理的条件。通过模拟该分布的样本均值，你将亲眼看到，在由罕见但影响巨大的事件主导的背景下，为何那些基于正态性假设的统计工具会产生误导，甚至带来危险 。",
            "id": "2405635",
            "problem": "考虑从I型帕累托分布中抽取的独立同分布随机变量 $X_1, X_2, \\dots, X_n$，其尺度参数为 $x_m = 1$，尾部指数（形状）参数为 $\\alpha > 0$。对于 $x \\ge 1$，其累积分布函数为 $F(x) = 1 - x^{-\\alpha}$。一个经过充分检验的事实是，有限均值存在的充要条件是 $\\alpha > 1$，此时总体均值为 $\\mu = \\dfrac{\\alpha}{\\alpha - 1}$；而有限方差存在的充要条件是 $\\alpha > 2$。大数定律 (LLN) 要求有限均值，以保证样本均值收敛于总体均值。中心极限定理 (CLT) 要求有限的均值和有限的非零方差，以保证标准化样本均值依分布收敛于标准正态分布。\n\n您的任务是设计并实现一个计算实验，通过模拟检验中心极限定理在帕累托分布（当 $\\alpha \\le 2$ 时）的失效情况，方法是检查标准化样本均值的分布，并展示当均值无限时（即 $\\alpha \\le 1$ 时）的爆炸性尺度变化。该问题是为计算经济学和金融学领域构建的，在这些领域中，重尾的收益和损失分布使得用于风险聚合的高斯近似方法失效。\n\n您必须实现以下内容，从上述基本定义出发，并且除了这些经过充分检验的事实之外，不使用任何快捷公式：\n\n1. 对于每个 $\\alpha \\in \\{1.5, 2.0\\}$ 和每个样本量 $n \\in \\{200, 1000, 3000\\}$，使用逆变换采样法，从 $x_m = 1$ 的帕累托($\\alpha$)分布中模拟 $R = 4000$ 次大小为 $n$ 的独立样本重复实验。该方法基于以下事实：如果 $U \\sim \\text{Uniform}(0,1)$，那么 $X = U^{-1/\\alpha}$ 服从 $x_m=1$ 的I型帕累托($\\alpha$)分布。对于每次重复实验，计算学生化均值\n$$\nT_{n} \\;=\\; \\frac{\\sqrt{n}\\,\\big(\\overline{X}_n - \\mu\\big)}{S_n},\n$$\n其中 $\\mu = \\frac{\\alpha}{\\alpha-1}$ 是真实均值（当 $\\alpha > 1$ 时存在），$\\overline{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i$ 是样本均值，而 $S_n$ 是除数为 $n-1$ 的样本标准差。使用 $T_n$ 的 $R$ 个值，计算其与标准正态分布的柯尔莫哥洛夫-斯米尔诺夫距离，\n$$\nD_{n} \\;=\\; \\sup_{x \\in \\mathbb{R}} \\Big| \\widehat{F}_{T_n}(x) - \\Phi(x) \\Big|,\n$$\n其中 $\\widehat{F}_{T_n}$ 是 $T_n$ 的 $R$ 个实现值的经验分布函数，而 $\\Phi$ 是标准正态累积分布函数。报告每个配对 $(\\alpha, n)$ 的 $D_n$ 值。\n\n2. 对于 $\\alpha = 0.8$（无限均值）的情况，对于每个 $n \\in \\{200, 1000, 3000\\}$，模拟 $R = 4000$ 次独立重复实验，并计算绝对缩放样本均值的中位数，\n$$\nM_n \\;=\\; \\operatorname{median}\\Big( \\big| \\sqrt{n}\\,\\overline{X}_n \\big| \\Big),\n$$\n（跨重复实验）。然后计算布尔指示器 $\\text{INC}$，当且仅当 $M_{200}  M_{1000}$ 且 $M_{1000}  M_{3000}$ 时为真。该指示器用于检验 $|\\sqrt{n}\\,\\overline{X}_n|$ 的典型量级是否随 $n$ 严格增长。这种增长表明序列 $\\{\\sqrt{n}\\,\\overline{X}_n\\}$ 不是紧的，因此不能依分布收敛于一个非退化的极限分布。\n\n为确保科学真实性，所有模拟都使用相同的随机种子 $s = 123456$，以使结果可复现。对每个 $(\\alpha,n)$ 组合使用 $R = 4000$ 次重复实验。您可以分批生成样本以控制内存使用，但结果必须与给定种子和规范所蕴含的结果完全一致。\n\n测试套件和要求的输出：\n- 使用上述参数集，即：\n  - 对于 $\\alpha = 1.5$：$n \\in \\{200, 1000, 3000\\}$，报告三个值 $D_{200}$、$D_{1000}$、$D_{3000}$。\n  - 对于 $\\alpha = 2.0$：$n \\in \\{200, 1000, 3000\\}$，报告三个值 $D_{200}$、$D_{1000}$、$D_{3000}$。\n  - 对于 $\\alpha = 0.8$：$n \\in \\{200, 1000, 3000\\}$，报告布尔值 $\\text{INC}$ 和三个中位数 $M_{200}$、$M_{1000}$、$M_{3000}$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须按以下顺序排列\n$$\n\\big[ D_{200}^{(\\alpha=1.5)}, D_{1000}^{(\\alpha=1.5)}, D_{3000}^{(\\alpha=1.5)}, D_{200}^{(\\alpha=2.0)}, D_{1000}^{(\\alpha=2.0)}, D_{3000}^{(\\alpha=2.0)}, \\text{INC}^{(\\alpha=0.8)}, M_{200}^{(\\alpha=0.8)}, M_{1000}^{(\\alpha=0.8)}, M_{3000}^{(\\alpha=0.8)} \\big].\n$$\n所有报告的 $D_n$ 和 $M_n$ 都必须是实数（浮点数），而 $\\text{INC}$ 必须是布尔值。不涉及单位。不涉及角度。输出必须是严格符合指定格式的一行。",
            "solution": "问题陈述已提交以供验证。\n\n**步骤1：提取给定条件**\n- 独立同分布 (i.i.d.) 随机变量：$X_1, X_2, \\dots, X_n$。\n- 分布：I型帕累托分布，尺度参数 $x_m = 1$，尾部指数（形状）参数 $\\alpha > 0$。\n- 累积分布函数 (CDF)：$F(x) = 1 - x^{-\\alpha}$，对于 $x \\ge 1$。\n- 矩的存在性：\n    - 有限均值存在的充要条件 (iff) 是 $\\alpha > 1$，总体均值为 $\\mu = \\dfrac{\\alpha}{\\alpha - 1}$。\n    - 有限方差存在的充要条件是 $\\alpha > 2$。\n- 大数定律 (LLN)：要求有限均值。\n- 中心极限定理 (CLT)：要求有限均值和有限的非零方差。\n- 模拟方法：逆变换采样，$X = U^{-1/\\alpha}$，其中 $U \\sim \\text{Uniform}(0,1)$。\n- 模拟参数：\n    - 重复实验次数：$R = 4000$。\n    - 随机种子：$s = 123456$。\n- 任务1：\n    - 参数：$\\alpha \\in \\{1.5, 2.0\\}$ 和 $n \\in \\{200, 1000, 3000\\}$。\n    - 统计量：学生化均值 $T_{n} = \\frac{\\sqrt{n}\\,\\big(\\overline{X}_n - \\mu\\big)}{S_n}$，其中 $\\overline{X}_n$ 是样本均值，$S_n$ 是除数为 $n-1$ 的样本标准差。\n    - 度量：柯尔莫哥洛夫-斯米尔诺夫距离 $D_{n} = \\sup_{x \\in \\mathbb{R}} \\big| \\widehat{F}_{T_n}(x) - \\Phi(x) \\big|$，其中 $\\widehat{F}_{T_n}$ 是 $T_n$ 的经验CDF，而 $\\Phi(x)$ 是标准正态CDF。\n- 任务2：\n    - 参数：$\\alpha = 0.8$。\n    - 样本量：$n \\in \\{200, 1000, 3000\\}$。\n    - 统计量：$M_n = \\operatorname{median}\\Big( \\big| \\sqrt{n}\\,\\overline{X}_n \\big| \\Big)$，在 $R$ 次重复实验中计算。\n    - 度量：布尔指示器 $\\text{INC}$，当且仅当 $M_{200}  M_{1000}$ 且 $M_{1000}  M_{3000}$ 时为真。\n- 输出格式：单个逗号分隔列表：$\\big[ D_{200}^{(\\alpha=1.5)}, D_{1000}^{(\\alpha=1.5)}, D_{3000}^{(\\alpha=1.5)}, D_{200}^{(\\alpha=2.0)}, D_{1000}^{(\\alpha=2.0)}, D_{3000}^{(\\alpha=2.0)}, \\text{INC}^{(\\alpha=0.8)}, M_{200}^{(\\alpha=0.8)}, M_{1000}^{(\\alpha=0.8)}, M_{3000}^{(\\alpha=0.8)} \\big]$。\n\n**步骤2：使用提取的给定条件进行验证**\n根据验证标准对问题进行评估。\n- **科学依据**：该问题坚实地建立在中心极限定理、大数定律以及帕累托分布等重尾分布特性的既定统计理论之上。使用蒙特卡洛模拟来研究估计量的渐近行为是计算统计学和计量经济学中的一种标准而严谨的方法。\n- **问题定义明确**：问题是明确的。所有参数（$\\alpha, n, R, s$）、统计量（$T_n, M_n$）和度量（$D_n, \\text{INC}$）都有精确定义。过程以算法方式描述，这导向一个唯一的、可验证的数值结果。\n- **客观性**：问题以精确、客观的数学和计算语言陈述，不含任何主观性或意见。\n\n**步骤3：结论与行动**\n该问题是**有效的**。它是一个在统计学领域中被良好构建的计算实验。将构建一个解决方案。\n\n**解决方案推导**\n\n这个问题的核心是中心极限定理（CLT），它是统计学的基石。经典中心极限定理指出，对于具有有限均值 $\\mu$ 和有限方差 $\\sigma^2 > 0$ 的独立同分布随机变量 $\\{X_i\\}$，标准化样本均值依分布收敛于标准正态分布：\n$$\n\\frac{\\overline{X}_n - \\mu}{\\sigma/\\sqrt{n}} \\xrightarrow{d} \\mathcal{N}(0,1) \\quad \\text{as} \\quad n \\to \\infty\n$$\n该问题要求通过模拟来展示当这些条件不被满足时会发生什么，特别是在帕累托分布中，其尾部厚度由参数 $\\alpha$ 控制。\n\n**模拟的理论背景**\n\n1.  **情况 $\\alpha \\in \\{1.5, 2.0\\}$（有限均值，无限方差）：**\n    对于这些 $\\alpha$ 值，均值存在（当 $\\alpha=1.5$ 时 $\\mu = 3$，当 $\\alpha=2.0$ 时 $\\mu=2$），但方差是无限的。标准中心极限定理不适用。取而代之的是广义中心极限定理，该定理指出，这类变量的和在经过适当的中心化和缩放后，会收敛到一个非正态的稳定分布。学生化均值 $T_n = \\sqrt{n}(\\overline{X}_n - \\mu)/S_n$ 的渐近分布也不是正态的，因为样本标准差 $S_n$ 不会收敛到一个常数。计算与标准正态CDF $\\Phi(x)$ 的柯尔莫哥洛夫-斯米尔诺夫距离 $D_n$ 的目的是量化这种向正态性收敛的失败。我们预计即使对于大的 $n$，$D_n$ 仍将显著大于零，从而显示出持续的非正态特征。\n\n2.  **情况 $\\alpha = 0.8$（无限均值）：**\n    当 $\\alpha  1$ 时，帕累托分布的均值是无限的。这是对中心极限定理条件的更严重违反；甚至大数定律也失效了。样本均值 $\\overline{X}_n$ 不会收敛到任何常数。稳定分布理论指出，对于 $\\alpha \\in (0, 2)$，和 $\\sum X_i$ 的增长与 $n^{1/\\alpha}$ 成正比。因此，样本均值 $\\overline{X}_n = n^{-1}\\sum X_i$ 的增长与 $n^{1/\\alpha - 1}$ 成正比。因此，所研究的项 $\\sqrt{n}\\,\\overline{X}_n$ 应随 $n$ 按 $n^{1/2} \\cdot n^{1/\\alpha-1} = n^{1/\\alpha - 1/2}$ 的比例缩放。对于 $\\alpha=0.8$，这个比例是 $n^{1/0.8-0.5} = n^{1.25-0.5} = n^{0.75}$。由于指数是正的，这个量预计会随 $n$ 增长。模拟通过计算其量级的中位数 $M_n$ 来检验这一点，并验证对于所选的样本量，$M_n$ 是 $n$ 的严格递增函数。这为当总体均值不存在时样本均值的爆炸性特性提供了计算证据。\n\n**实施计划**\n\n该模拟将使用 Python 实现，利用 `numpy` 库进行高效的向量化计算，并使用 `scipy` 进行柯尔莫哥洛夫-斯米尔诺夫检验。\n\n1.  **初始化**：将使用种子 $s=123456$ 初始化一个随机数生成器，以确保可复现性。\n\n2.  **第1部分：计算 $\\alpha \\in \\{1.5, 2.0\\}$ 时的 $D_n$**：\n    对于每对 $(\\alpha, n)$，我们执行 $R=4000$ 次重复实验。\n    a. 生成一个 $R \\times n$ 的均匀分布随机数矩阵 $U \\sim \\text{Uniform}(0,1)$。\n    b. 使用逆变换方法将此矩阵转换为帕累托分布的变量：$X = U^{-1/\\alpha}$。\n    c. 对 $R$ 行中的每一行计算样本均值 $\\overline{X}_n$ 和样本标准差 $S_n$（分母为 $n-1$，即 `ddof=1`），从而为每个统计量产生 $R$ 个值。\n    d. 计算真实均值 $\\mu = \\alpha/(\\alpha-1)$。\n    e. 计算学生化均值 $T_n = \\sqrt{n}(\\overline{X}_n - \\mu) / S_n$ 的 $R$ 个实现值。\n    f. 通过将 $R$ 个T值的经验分布与标准正态分布的CDF $\\Phi(x)$ 进行比较，来计算柯尔莫哥洛夫-斯米尔诺夫统计量 $D_n$。这可以通过 `scipy.stats.kstest` 完成。\n\n3.  **第2部分：计算 $\\alpha=0.8$ 时的 $M_n$ 和 $\\text{INC}$**：\n    对于每个 $n \\in \\{200, 1000, 3000\\}$：\n    a. 生成一个 $\\alpha=0.8$ 的 $R \\times n$ 帕累托变量矩阵。\n    b. 对 $R$ 行中的每一行计算样本均值 $\\overline{X}_n$。\n    c. 为每次重复实验计算统计量 $|\\sqrt{n}\\,\\overline{X}_n|$。\n    d. 找到这 $R$ 个值的中位数以获得 $M_n$。\n    e. 在计算出 $M_{200}$、$M_{1000}$ 和 $M_{3000}$ 之后，根据严格不等式条件评估布尔指示器 $\\text{INC}$。\n\n4.  **输出**：计算出的值将按指定顺序收集，并以要求的格式打印。这种严谨的向量化方法确保了正确性和计算效率。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest, norm\n\ndef solve():\n    \"\"\"\n    Performs a computational experiment to test the failure of the Central Limit Theorem\n    for Pareto distributions with heavy tails.\n    \"\"\"\n    # Define simulation parameters from the problem statement.\n    seed = 123456\n    R = 4000\n    rng = np.random.default_rng(seed)\n\n    all_results = []\n\n    # Part 1: Test convergence to Normal for alpha  1\n    # Cases where mean is finite, but variance is infinite.\n    alphas_part1 = [1.5, 2.0]\n    n_values_part1 = [200, 1000, 3000]\n\n    for alpha in alphas_part1:\n        # The true mean exists for alpha  1.\n        mu = alpha / (alpha - 1.0)\n        for n in n_values_part1:\n            # Generate R samples of size n in a vectorized manner.\n            # U ~ Uniform(0,1)\n            uniform_samples = rng.uniform(size=(R, n))\n            # X = U^(-1/alpha) gives Pareto(alpha) with x_m=1\n            pareto_samples = uniform_samples**(-1.0 / alpha)\n\n            # Compute sample means and standard deviations for each of the R replications.\n            sample_means = np.mean(pareto_samples, axis=1)\n            # Use ddof=1 for sample standard deviation (n-1 divisor).\n            sample_std_devs = np.std(pareto_samples, axis=1, ddof=1)\n\n            # Compute the Studentized mean T_n for each replication.\n            # Handle the unlikely case of S_n = 0.\n            T_n_values = np.full(R, np.nan)\n            valid_indices = sample_std_devs  0\n            T_n_values[valid_indices] = np.sqrt(n) * (sample_means[valid_indices] - mu) / sample_std_devs[valid_indices]\n            \n            # Filter out any potential NaN values before the KS test.\n            T_n_values = T_n_values[~np.isnan(T_n_values)]\n\n            # Compute the Kolmogorov-Smirnov distance to the standard normal distribution.\n            # The 'statistic' attribute of the result is the D_n value.\n            ks_result = kstest(T_n_values, norm.cdf)\n            D_n = ks_result.statistic\n            all_results.append(D_n)\n\n    # Part 2: Test explosive scaling for alpha = 1\n    # Case where mean is infinite.\n    alpha_part2 = 0.8\n    n_values_part2 = [200, 1000, 3000]\n    medians = []\n\n    for n in n_values_part2:\n        # Generate R samples of size n.\n        uniform_samples = rng.uniform(size=(R, n))\n        pareto_samples = uniform_samples**(-1.0 / alpha_part2)\n\n        # Compute sample means for each replication.\n        sample_means = np.mean(pareto_samples, axis=1)\n\n        # Compute the absolute scaled sample mean for each replication.\n        abs_scaled_means = np.abs(np.sqrt(n) * sample_means)\n\n        # Compute the median of these values across replications.\n        M_n = np.median(abs_scaled_means)\n        medians.append(M_n)\n\n    # Compute the boolean indicator for strict growth of the median.\n    INC = (medians[0]  medians[1]) and (medians[1]  medians[2])\n\n    all_results.append(INC)\n    all_results.extend(medians)\n\n    # Final print statement in the exact required format.\n    # str() of a boolean is 'True' or 'False', which is a valid representation.\n    output_str_list = [str(r) for r in all_results]\n    print(f\"[{','.join(output_str_list)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "这最后一项练习将中心极限定理的抽象理论与计量经济学中最基本的工具之一——普通最小二乘法（OLS）回归——联系起来。你将会发现，OLS估计量虽然有其特定的计算公式，但其本质上是模型中不可观测的随机误差项的一个加权和。本练习将引导你通过计算来验证，正是由于这种结构，随着样本量的增加，估计量的抽样分布会趋近于正态分布，这一性质被称为渐近正态性 。理解这一原理是掌握回归分析中假设检验与置信区间构建的关键，而这些都是经济和金融领域进行统计推断的基石。",
            "id": "2405562",
            "problem": "考虑一个无截距项的简单线性回归模型，每次重复实验中，您会观测到由 $y_i=\\beta x_i+\\epsilon_i$ 生成的 $\\{(x_i,y_i)\\}_{i=1}^n$。其中 $\\{x_i\\}_{i=1}^n$ 是独立同分布的，服从 $x_i\\sim \\mathcal{N}(0,1)$，而 $\\{\\epsilon_i\\}_{i=1}^n$ 独立于 $\\{x_i\\}_{i=1}^n$。令 $\\hat{\\beta}$ 表示普通最小二乘 (OLS) 估计量。您的程序必须对下方的每个测试用例执行大量的独立重复实验，并在每次重复中：(i) 计算 $\\hat{\\beta}$ 并验证 $\\hat{\\beta}-\\beta$ 可精确分解为误差项的加权和，其中权重仅依赖于已实现的回归量；(ii) 使用给定回归量下的精确条件方差对 $\\hat{\\beta}$ 进行标准化，并根据一个正式的拟合优度检验来评估标准化后的估计量是否服从标准正态分布。\n\n定义与要求：\n- 普通最小二乘 (OLS)：估计量 $\\hat{\\beta}$ 是使残差平方和 $\\sum_{i=1}^n (y_i-b x_i)^2$ 在 $b\\in\\mathbb{R}$ 上最小化的值。\n- 证明 $\\hat{\\beta}-\\beta$ 可以写成一个有限加权和 $\\sum_{i=1}^n w_i\\epsilon_i$，其中权重 $\\{w_i\\}_{i=1}^n$ 仅依赖于 $\\{x_i\\}_{i=1}^n$。在每次重复实验中，在绝对容忍度 $\\tau=10^{-10}$ 内对该恒等式进行数值验证。\n- 对于每次重复实验，通过除以精确的条件标准差 $\\sqrt{\\mathrm{Var}(\\hat{\\beta}\\mid \\{x_i\\}_{i=1}^n)}$ 来标准化 $\\hat{\\beta}$。其中，条件方差必须从基本原理推导得出，并用权重 $\\{w_i\\}_{i=1}^n$ 以及给定 $\\{x_i\\}_{i=1}^n$ 时 $\\{\\epsilon_i\\}_{i=1}^n$ 的条件方差来表示。\n- 使用 Kolmogorov–Smirnov 拟合优度检验，在显著性水平 $\\alpha=0.05$ 下，检验标准化估计量相对于标准正态分布的正态性。如果标准正态性的原假设未被拒绝，则报告布尔值 `True`，否则报告 `False`。\n- 使用一个固定的伪随机数生成器种子，其值为 $123456789$，以确保不同实现的结果是可复现的。\n\n测试套件：\n- 用例 A (基准同方差正态误差)：$n=100$，$\\beta=1.7$，$\\epsilon_i\\sim \\mathcal{N}(0,1)$，独立重复实验次数 $R=4000$。\n- 用例 B (大样本，有限方差的重尾分布)：$n=1000$，$\\beta=-0.8$，$\\epsilon_i = s\\cdot t_{\\nu}$，其中 $\\nu=3$ 且 $s=\\sqrt{(\\nu-2)/\\nu}$ 以使得 $\\mathrm{Var}(\\epsilon_i)=1$，独立重复实验次数 $R=4000$。\n- 用例 C (小样本，有限方差的重尾分布)：$n=30$，$\\beta=0.0$，$\\epsilon_i = s\\cdot t_{\\nu}$，其中 $\\nu=3$ 且 $s=\\sqrt{(\\nu-2)/\\nu}$ 以使得 $\\mathrm{Var}(\\epsilon_i)=1$，独立重复实验次数 $R=4000$。\n- 用例 D (异方差正态误差)：$n=1000$，$\\beta=2.0$，$\\epsilon_i\\sim \\mathcal{N}(0,\\sigma_i^2)$，其中 $\\sigma_i^2 = 1+0.5\\cdot i/n$ 对于 $i\\in\\{1,\\dots,n\\}$，独立重复实验次数 $R=4000$。\n\n对于每个用例，您必须在各次重复实验中独立地生成新的回归量 $\\{x_i\\}_{i=1}^n$ 和误差 $\\{\\epsilon_i\\}_{i=1}^n$，强制执行指定的分布假设，并使用精确的条件方差进行标准化。对于异方差用例，条件方差必须考虑到非恒定的误差方差。\n\n最终输出要求：\n- 对每个用例，按顺序产生两个布尔值：第一，加权和恒等式是否在所有重复实验中都在容忍度 $\\tau$ 内成立；第二，对于 $R$ 次重复实验中收集到的所有标准化估计量，标准正态性的原假设在水平 $\\alpha$ 下是否未被拒绝。\n- 将四个用例的结果汇总到单行输出中，形式为用方括号括起来的逗号分隔列表，并严格按照以下顺序：$[\\text{A\\_identity},\\text{A\\_normality},\\text{B\\_identity},\\text{B\\_normality},\\text{C\\_identity},\\text{C\\_normality},\\text{D\\_identity},\\text{D\\_normality}]$。\n- 唯一可接受的输出是布尔值。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$[True,False,...]$）。",
            "solution": "该问题陈述经过了严格验证，并被认定为有效。它在科学上基于计量经济学和统计学的既定原则，提法恰当，提供了所有必要的数据和条件，并使用客观、明确的语言进行阐述。该问题是计算统计学中的一个标准练习，旨在验证普通最小二乘 (OLS) 估计量的理论性质，并探讨中心极限定理 (CLT) 在不同误差项分布假设下的适用性。\n\n我们继续进行求解，这需要先进行解析推导，然后进行数值模拟。\n\n**1. OLS 估计量 $\\hat{\\beta}$ 的推导**\n\n模型是一个无截距项的简单线性回归：\n$$ y_i = \\beta x_i + \\epsilon_i $$\nOLS 估计量 $\\hat{\\beta}$ 是使残差平方和 (SSR) $S(b)$ 最小化的 $b$ 值：\n$$ S(b) = \\sum_{i=1}^{n} (y_i - b x_i)^2 $$\n为求最小值，我们将 $S(b)$ 对 $b$ 求导并令其为零。这得到一阶条件 (FOC)：\n$$ \\frac{dS}{db} = \\sum_{i=1}^{n} 2(y_i - b x_i)(-x_i) = -2 \\sum_{i=1}^{n} (x_i y_i - b x_i^2) = 0 $$\n解出 $b$ 即可得到 OLS 估计量 $\\hat{\\beta}$：\n$$ \\sum_{i=1}^{n} x_i y_i = \\hat{\\beta} \\sum_{i=1}^{n} x_i^2 $$\n$$ \\hat{\\beta} = \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sum_{i=1}^{n} x_i^2} $$\n最小值的二阶条件是满足的，因为 $\\frac{d^2S}{db^2} = 2 \\sum_{i=1}^{n} x_i^2  0$ 几乎必然成立，因为回归量 $\\{x_i\\}$ 来自连续分布，它们不全为零的概率为 $1$。\n\n**2. 加权和恒等式的推导**\n\n我们必须证明 $\\hat{\\beta} - \\beta$ 可以表示为误差项的加权和 $\\sum_{i=1}^n w_i\\epsilon_i$。我们将 $y_i = \\beta x_i + \\epsilon_i$ 代入 $\\hat{\\beta}$ 的公式中：\n$$ \\hat{\\beta} = \\frac{\\sum_{i=1}^{n} x_i (\\beta x_i + \\epsilon_i)}{\\sum_{j=1}^{n} x_j^2} = \\frac{\\beta \\sum_{i=1}^{n} x_i^2 + \\sum_{i=1}^{n} x_i \\epsilon_i}{\\sum_{j=1}^{n} x_j^2} $$\n分离各项可得：\n$$ \\hat{\\beta} = \\frac{\\beta \\sum_{i=1}^{n} x_i^2}{\\sum_{j=1}^{n} x_j^2} + \\frac{\\sum_{i=1}^{n} x_i \\epsilon_i}{\\sum_{j=1}^{n} x_j^2} = \\beta + \\sum_{i=1}^{n} \\left( \\frac{x_i}{\\sum_{j=1}^{n} x_j^2} \\right) \\epsilon_i $$\n整理后得到估计误差的所需表达式：\n$$ \\hat{\\beta} - \\beta = \\sum_{i=1}^{n} w_i \\epsilon_i $$\n其中权重 $w_i$ 由下式给出：\n$$ w_i = \\frac{x_i}{\\sum_{j=1}^{n} x_j^2} $$\n这些权重仅依赖于回归量样本 $\\{x_i\\}_{i=1}^n$，符合要求。这个代数恒等式将在每次重复实验中进行数值验证，容忍度为 $\\tau = 10^{-10}$。\n\n**3. $\\hat{\\beta}$ 的条件方差的推导**\n\n题目要求我们推导 $\\hat{\\beta}$ 在给定回归量集合 $\\{x_i\\}_{i=1}^n$ 条件下的方差。当我们以 $\\{x_i\\}$ 为条件时，回归量以及权重 $\\{w_i\\}$ 被视为非随机常数。\n$$ \\mathrm{Var}(\\hat{\\beta} | \\{x_i\\}_{i=1}^n) = \\mathrm{Var}\\left(\\beta + \\sum_{i=1}^{n} w_i \\epsilon_i \\bigg| \\{x_i\\}_{i=1}^n\\right) $$\n由于 $\\beta$ 是一个常数，其方差为零。误差项 $\\{\\epsilon_i\\}$ 相互独立，且独立于回归量 $\\{x_i\\}$。因此：\n$$ \\mathrm{Var}(\\hat{\\beta} | \\{x_i\\}) = \\mathrm{Var}\\left(\\sum_{i=1}^{n} w_i \\epsilon_i \\bigg| \\{x_i\\}\\right) = \\sum_{i=1}^{n} w_i^2 \\mathrm{Var}(\\epsilon_i | \\{x_i\\}) = \\sum_{i=1}^{n} w_i^2 \\mathrm{Var}(\\epsilon_i) $$\n令 $\\sigma_{\\epsilon,i}^2 = \\mathrm{Var}(\\epsilon_i)$。条件方差的通用公式为：\n$$ \\mathrm{Var}(\\hat{\\beta} | \\{x_i\\}) = \\sum_{i=1}^{n} \\left(\\frac{x_i}{\\sum_{j=1}^{n} x_j^2}\\right)^2 \\sigma_{\\epsilon,i}^2 = \\frac{\\sum_{i=1}^{n} x_i^2 \\sigma_{\\epsilon,i}^2}{\\left(\\sum_{j=1}^{n} x_j^2\\right)^2} $$\n我们将此通用公式应用于各种情况：\n- **用例 A, B, C (同方差误差)：** 在这些用例中，误差具有恒定方差 $\\sigma_{\\epsilon,i}^2 = 1$（对所有 $i$）。公式显著简化为：\n$$ \\mathrm{Var}(\\hat{\\beta} | \\{x_i\\}) = \\frac{\\sum_{i=1}^{n} x_i^2 (1)}{\\left(\\sum_{j=1}^{n} x_j^2\\right)^2} = \\frac{\\sum_{i=1}^{n} x_i^2}{\\left(\\sum_{j=1}^{n} x_j^2\\right)^2} = \\frac{1}{\\sum_{j=1}^{n} x_j^2} $$\n- **用例 D (异方差误差)：** 误差方差非恒定，$\\sigma_{\\epsilon,i}^2 = 1 + 0.5 \\cdot i/n$。我们必须使用通用公式：\n$$ \\mathrm{Var}(\\hat{\\beta} | \\{x_i\\}) = \\frac{\\sum_{i=1}^{n} x_i^2 (1 + 0.5 \\cdot i/n)}{\\left(\\sum_{j=1}^{n} x_j^2\\right)^2} $$\n\n**4. 标准化估计量的分布**\n\n对于每次重复实验，我们计算标准化估计量 $Z$：\n$$ Z = \\frac{\\hat{\\beta} - \\beta}{\\sqrt{\\mathrm{Var}(\\hat{\\beta} | \\{x_i\\})}} $$\n我们评估其分布。\n- **用例 A 和 D：** 误差 $\\{\\epsilon_i\\}$ 来自正态分布。估计误差 $\\hat{\\beta} - \\beta = \\sum w_i \\epsilon_i$ 是正态随机变量的线性组合（以 $\\{x_i\\}$ 为条件）。因此，它也是条件正态的，均值为 $E[\\sum w_i \\epsilon_i]=0$，方差为 $\\mathrm{Var}(\\hat{\\beta} | \\{x_i\\})$。因此，标准化估计量 $Z$ 条件地服从 $\\mathcal{N}(0,1)$ 分布。由于其分布对于 $\\{x_i\\}$ 的任何实现都是 $\\mathcal{N}(0,1)$，因此其无条件分布也精确地是 $\\mathcal{N}(0,1)$。我们预期 Kolmogorov-Smirnov (KS) 检验不会拒绝标准正态性的原假设。\n\n- **用例 B 和 C：** 误差 $\\{\\epsilon_i\\}$ 来自一个缩放后的、自由度为 $\\nu=3$ 的学生t分布。该分布是对称的，具有有限方差，但它不是正态分布，并且具有重尾（其四阶矩是无限的）。估计误差是一系列独立但非同分布的随机变量 $w_i\\epsilon_i$ 的和。适用于此类和的中心极限定理 (CLT) 表明，随着样本量 $n \\to \\infty$，标准化估计量的分布将趋近于 $\\mathcal{N}(0,1)$。\n    - **用例 B ($n=1000$)：** 样本量很大。中心极限定理应能提供一个非常好的近似。我们预期 KS 检验不会拒绝原假设。\n    - **用例 C ($n=30$)：** 样本量很小。由中心极限定理保证的正态收敛速度可能很慢，特别是对于重尾误差分布。我们预期标准化估计量的分布仍会表现出比标准正态分布更肥的尾部，导致 KS 检验拒绝原假设。\n\n**5. 模拟程序**\n\n对于四个用例中的每一个，我们执行 $R=4000$ 次重复实验。在每次重复中：\n1. 从 $\\mathcal{N}(0,1)$ 生成一个回归量样本 $\\{x_i\\}_{i=1}^n$。\n2. 从该用例指定的分布中生成一个误差样本 $\\{\\epsilon_i\\}_{i=1}^n$。\n3. 计算 $y_i = \\beta x_i + \\epsilon_i$。\n4. 计算 OLS 估计值 $\\hat{\\beta}$。\n5. 验证恒等式 $|\\hat{\\beta} - \\beta - \\sum w_i \\epsilon_i|  10^{-10}$。一个标志位用于追踪该式是否在所有 $R$ 次重复实验中都成立。\n6. 使用上面推导出的相应公式计算精确的条件方差 $\\mathrm{Var}(\\hat{\\beta} | \\{x_i\\})$。\n7. 计算标准化估计量 $Z$ 并存储它。\n\n在一个用例的所有重复实验完成后，收集到的 $R$ 个 $Z$ 值将通过 KS 检验在显著性水平 $\\alpha=0.05$ 下与标准正态分布进行比较。如果 p 值大于或等于 $\\alpha$，则原假设不被拒绝。每个用例的结果（恒等式验证和正态性检验结果）都记录为布尔值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef run_simulation(n, beta, err_type, R, tau, alpha):\n    \"\"\"\n    Performs a simulation for a single test case.\n\n    Args:\n        n (int): Sample size.\n        beta (float): True coefficient.\n        err_type (str): Type of error distribution ('norm', 't', 'hetero').\n        R (int): Number of replications.\n        tau (float): Tolerance for identity check.\n        alpha (float): Significance level for KS test.\n\n    Returns:\n        tuple[bool, bool]: A tuple containing:\n            - bool: True if the identity holds for all replications.\n            - bool: True if the normality hypothesis is not rejected.\n    \"\"\"\n    \n    # Store standardized estimators for the KS test\n    z_values = np.zeros(R)\n    \n    # Flag to track if the identity holds across all replications\n    identity_holds_all_reps = True\n\n    # Define error variance parameters for specific cases.\n    nu = 3.0  # Degrees of freedom for t-distribution\n    s = np.sqrt((nu - 2.0) / nu)  # Scale factor for t-distribution\n    \n    # Pre-calculate heteroskedastic variances if needed\n    if err_type == 'hetero':\n        # i is 1-based, so we use arange(1, n+1)\n        sigma_sq_hetero = 1.0 + 0.5 * np.arange(1, n + 1) / n\n\n    for i in range(R):\n        # 1. Generate regressors\n        x = np.random.normal(loc=0.0, scale=1.0, size=n)\n        \n        # 2. Generate errors based on type\n        if err_type == 'norm':\n            epsilon = np.random.normal(loc=0.0, scale=1.0, size=n)\n            sigma_sq_eps = 1.0\n        elif err_type == 't':\n            epsilon = np.random.standard_t(df=nu, size=n) * s\n            sigma_sq_eps = 1.0\n        elif err_type == 'hetero':\n            epsilon = np.random.normal(loc=0.0, scale=np.sqrt(sigma_sq_hetero))\n            sigma_sq_eps = sigma_sq_hetero\n        else:\n            raise ValueError(\"Invalid error type specified.\")\n\n        # 3. Generate dependent variable\n        y = beta * x + epsilon\n\n        # 4. Calculate OLS estimator\n        sum_x_sq = np.sum(x**2)\n        if sum_x_sq == 0: continue # Should not happen with continuous x\n        beta_hat = np.sum(x * y) / sum_x_sq\n\n        # 5. Verify the weighted-sum identity\n        if identity_holds_all_reps: # Avoid repeated calculations if already failed\n            lhs = beta_hat - beta\n            weights = x / sum_x_sq\n            rhs = np.sum(weights * epsilon)\n            if np.abs(lhs - rhs) > tau:\n                identity_holds_all_reps = False\n\n        # 6. Calculate the exact conditional variance\n        if err_type in ['norm', 't']: # Homoskedastic case\n            var_cond = 1.0 / sum_x_sq\n        else: # Heteroskedastic case\n            var_cond = np.sum(x**2 * sigma_sq_eps) / (sum_x_sq**2)\n        \n        std_cond = np.sqrt(var_cond)\n\n        # 7. Compute and store the standardized estimator\n        z_values[i] = (beta_hat - beta) / std_cond\n\n    # Perform Kolmogorov-Smirnov test for normality\n    ks_statistic, p_value = kstest(z_values, 'norm')\n    \n    # Null hypothesis is not rejected if p-value is = alpha\n    normality_not_rejected = (p_value >= alpha)\n\n    return identity_holds_all_reps, normality_not_rejected\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Set the fixed seed for reproducibility\n    np.random.seed(123456789)\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'n': 100, 'beta': 1.7, 'err_type': 'norm'},   # Case A\n        {'n': 1000, 'beta': -0.8, 'err_type': 't'},     # Case B\n        {'n': 30, 'beta': 0.0, 'err_type': 't'},      # Case C\n        {'n': 1000, 'beta': 2.0, 'err_type': 'hetero'} # Case D\n    ]\n    \n    # Global parameters\n    R = 4000\n    tau = 1e-10\n    alpha = 0.05\n    \n    results = []\n    for case_params in test_cases:\n        identity_ok, normality_ok = run_simulation(\n            n=case_params['n'],\n            beta=case_params['beta'],\n            err_type=case_params['err_type'],\n            R=R,\n            tau=tau,\n            alpha=alpha\n        )\n        results.extend([identity_ok, normality_ok])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}