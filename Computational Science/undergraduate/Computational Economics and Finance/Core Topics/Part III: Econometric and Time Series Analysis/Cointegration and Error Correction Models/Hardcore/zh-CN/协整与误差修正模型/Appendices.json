{
    "hands_on_practices": [
        {
            "introduction": "要理解协整，我们必须从其基础检验程序入手。本练习将指导您从零开始，亲手实现经典的Engle-Granger两步法。通过对已知协整或不协整的时间序列进行模拟和检验，您将对如何从非平稳数据中识别出长期均衡关系建立起具体而深刻的理解。",
            "id": "2380057",
            "problem": "给定一个以纯数学术语表述的决策问题，该问题关于代表公司季度研发支出及其滞后一期的季度收入的两个随机过程之间的长期均衡关系。对于所提供的测试套件中的每个参数集，根据以下定义构建两个序列 $\\{x_t\\}_{t=0}^{T}$ 和 $\\{y_t\\}_{t=1}^{T}$。\n\n1. 数据生成部分与符号表示。\n   - 令 $T \\in \\mathbb{N}$ 表示以季度为单位的样本量。\n   - 令 $x_0 = 0$。对于 $t \\in \\{1,2,\\dots,T\\}$，令\n     $$x_t = x_{t-1} + \\varepsilon_t,$$\n     其中 $\\{\\varepsilon_t\\}_{t=1}^{T}$ 是独立同分布的高斯随机变量，其均值为 $0$，方差为 $\\sigma_{\\varepsilon}^2$。\n   - 将收入关系中使用的滞后输入定义为 $\\{x_{t-1}\\}_{t=1}^{T}$。\n   - 收入关系中的扰动项允许两种备选设定，由类型指示符 $\\text{residual\\_type} \\in \\{\\text{stationary}, \\text{random\\_walk}\\}$ 参数化：\n     - 如果 $\\text{residual\\_type} = \\text{stationary}$，定义 $v_0 = 0$，且对于 $t \\in \\{1,2,\\dots,T\\}$，\n       $$v_t = \\phi\\, v_{t-1} + \\eta_t,$$\n       其中 $|\\phi|  1$ 且 $\\{\\eta_t\\}_{t=1}^{T}$ 是独立同分布的高斯随机变量，其均值为 $0$，方差为 $\\sigma_{\\eta}^2$。在这种情况下，设\n       $$y_t = c + \\beta\\, x_{t-1} + v_t.$$\n     - 如果 $\\text{residual\\_type} = \\text{random\\_walk}$，定义 $s_0 = 0$，且对于 $t \\in \\{1,2,\\dots,T\\}$，\n       $$s_t = s_{t-1} + \\eta_t,$$\n       其中 $\\{\\eta_t\\}_{t=1}^{T}$ 是独立同分布的高斯随机变量，其均值为 $0$，方差为 $\\sigma_{\\eta}^2$。在这种情况下，设\n       $$y_t = c + \\beta\\, x_{t-1} + s_t.$$\n\n2. 应用于每个参数集的决策规则。\n   - 考虑静态长期关系\n     $$y_t = \\alpha + \\beta^{\\ast} x_{t-1} + u_t,$$\n     并将 $\\{\\hat{u}_t\\}_{t=1}^{T}$ 定义为将 $\\{y_t\\}_{t=1}^{T}$ 对一个常数项和 $\\{x_{t-1}\\}_{t=1}^{T}$ 进行普通最小二乘法 (OLS) 回归后得到的残差。\n   - 计算不含确定性项、且带有一阶差分的一阶滞后项的增广 Dickey-Fuller (ADF) 回归：\n     $$\\Delta \\hat{u}_t = \\varphi\\, \\hat{u}_{t-1} + \\gamma\\, \\Delta \\hat{u}_{t-1} + \\varepsilon_t^{\\ast}, \\quad t = 3,4,\\dots,T.$$\n     令 $\\tau$ 表示从该回归中计算出的、针对原假设 $H_0: \\varphi = 0$ 与单边备择假设 $H_1: \\varphi  0$ 的 $t$-统计量。\n   - 使用显著性水平 $\\alpha = 0.05$ 以及 Engle-Granger 基于残差的临界值 $c_{0.05} = -3.34$，该临界值适用于协整回归中包含截距项而 ADF 回归中不含确定性项的模型。当且仅当 $\\tau \\le c_{0.05}$ 时，判定 $\\{y_t\\}$ 和 $\\{x_{t-1}\\}$ 是协整的。\n\n3. 测试套件。对于每个参数集 $\\theta$，使用给定的参数和由指定种子初始化的独立伪随机数生成器，根据上述定义生成序列。这些参数是：\n   - 情况 A：$\\left(T, \\text{seed}, c, \\beta, \\sigma_{\\varepsilon}, \\sigma_{\\eta}, \\phi, \\text{residual\\_type}\\right) = \\left(400, 101, 0.5, 1.3, 1.0, 0.3, 0.4, \\text{stationary}\\right)$。\n   - 情况 B：$\\left(T, \\text{seed}, c, \\beta, \\sigma_{\\varepsilon}, \\sigma_{\\eta}, \\phi, \\text{residual\\_type}\\right) = \\left(400, 202, 0.5, 1.3, 1.0, 0.8, 0.0, \\text{random\\_walk}\\right)$。\n   - 情况 C：$\\left(T, \\text{seed}, c, \\beta, \\sigma_{\\varepsilon}, \\sigma_{\\eta}, \\phi, \\text{residual\\_type}\\right) = \\left(400, 303, -0.2, -0.8, 0.8, 0.5, 0.7, \\text{stationary}\\right)$。\n\n4. 要求的最终输出格式。你的程序应生成单行输出，其中包含一个用方括号括起来的布尔值逗号分隔列表，顺序与上述测试用例一致。其中，如果根据第 2 项中的规则判定为协整，则布尔值为 $\\text{True}$，否则为 $\\text{False}$。例如，包含三个用例的输出应如下所示\n$$[\\text{True},\\text{False},\\text{True}].$$",
            "solution": "问题陈述提出了一个在时间序列计量经济学中有效且定义明确的计算练习。它要求实现 Engle-Granger 两步法，以检验两个模拟时间序列之间的协整关系。该问题具有科学依据，形式规范，并且为每个测试用例提供了获得唯一解所需的所有参数和程序。我们将着手进行求解。\n\n问题的核心是确定两个随机过程 $\\{x_t\\}$ 和 $\\{y_t\\}$ 之间是否存在称为协整的长期均衡关系。这通过根据指定的数据生成过程 (DGP) 生成序列，然后应用统计假设检验来解决。对测试套件中提供的每个参数集都执行整个过程。\n\n**步骤 1：数据生成**\n\n对于每个测试用例，我们首先模拟时间序列数据。为保证可复现性，使用特定的种子来初始化伪随机数生成器。\n令 $T$ 为样本量。我们生成两个独立同分布 (i.i.d.) 的高斯随机冲击序列：$\\{\\varepsilon_t\\}_{t=1}^{T} \\sim N(0, \\sigma_{\\varepsilon}^2)$ 和 $\\{\\eta_t\\}_{t=1}^{T} \\sim N(0, \\sigma_{\\eta}^2)$。\n\n第一个序列 $\\{x_t\\}_{t=0}^{T}$ 代表研发支出，被构建为一个纯随机游走：\n$$x_t = x_{t-1} + \\varepsilon_t, \\quad \\text{for } t=1, \\dots, T$$\n初始条件为 $x_0 = 0$。像 $\\{x_t\\}$ 这样的过程是非平稳的，被称为一阶单整，记为 $I(1)$，因为它的一阶差分 $\\Delta x_t = \\varepsilon_t$ 是平稳的。\n\n第二个序列 $\\{y_t\\}_{t=1}^{T}$ 代表收入，其构建基于与滞后支出 $\\{x_{t-1}\\}_{t=1}^{T}$ 的关系以及一个性质取决于 `residual_type` 参数的误差项。\n\n- **情况 1：`residual_type` = `stationary`**。误差项 $\\{v_t\\}_{t=1}^{T}$ 服从一个平稳的一阶自回归 (AR(1)) 过程：\n$$v_t = \\phi v_{t-1} + \\eta_t, \\quad \\text{for } t=1, \\dots, T$$\n其中 $v_0 = 0$ 且自回归参数 $|\\phi|  1$。则收入序列为：\n$$y_t = c + \\beta x_{t-1} + v_t$$\n在这种情况下，线性组合 $y_t - \\beta x_{t-1} - c = v_t$ 是平稳的。根据定义，如果两个 $I(1)$ 变量的线性组合是平稳的，那么这两个变量就是协整的。因此，我们预期检验会发现协整关系。\n\n- **情况 2：`residual_type` = `random_walk`**。误差项 $\\{s_t\\}_{t=1}^{T}$ 本身是一个随机游走：\n$$s_t = s_{t-1} + \\eta_t, \\quad \\text{for } t=1, \\dots, T$$\n其中 $s_0 = 0$。收入序列为：\n$$y_t = c + \\beta x_{t-1} + s_t$$\n在这里，线性组合 $y_t - \\beta x_{t-1} - c = s_t$ 是一个随机游走，因此是非平稳的 ($I(1)$)。这两个变量不是协整的。这是一个典型的伪回归案例，尽管没有有意义的长期关系，但可能会观察到很高的相关性。\n\n**步骤 2：Engle-Granger 协整检验**\n\n该检验分两个阶段进行。\n\n**阶段 1：估计长期关系**\n我们使用普通最小二乘法 (OLS) 估计假设的长期协整关系的参数：\n$$y_t = \\alpha + \\beta^{\\ast} x_{t-1} + u_t, \\quad \\text{for } t=1, \\dots, T$$\n我们将向量 $Y = (y_1, \\dots, y_T)^T$ 对一个维度为 $T \\times 2$ 的设计矩阵 $X_{ols}$ 进行回归，其中第一列是全为 1 的向量，第二列是向量 $(x_0, \\dots, x_{T-1})^T$。OLS 系数估计由 $\\hat{\\theta} = (\\hat{\\alpha}, \\hat{\\beta}^{\\ast})^T = (X_{ols}^T X_{ols})^{-1} X_{ols}^T Y$ 给出。\n\n然后计算该回归的残差：\n$$\\hat{u}_t = y_t - (\\hat{\\alpha} + \\hat{\\beta}^{\\ast} x_{t-1}), \\quad \\text{for } t=1, \\dots, T$$\n如果 $y_t$ 和 $x_{t-1}$ 是协整的，这些残差应该是平稳的，即 $I(0)$。如果它们不是协整的，残差将是非平稳的，即 $I(1)$。\n\n**阶段 2：检验残差的单位根**\n为了检验残差 $\\{\\hat{u}_t\\}$ 的平稳性，我们进行增广 Dickey-Fuller (ADF) 检验。原假设是残差具有单位根（即非平稳），这意味着没有协整关系。备择假设是平稳性，这意味着存在协整关系。\n\n需要估计的特定 ADF 回归模型是：\n$$\\Delta \\hat{u}_t = \\varphi \\hat{u}_{t-1} + \\gamma \\Delta \\hat{u}_{t-1} + \\varepsilon_t^{\\ast}, \\quad \\text{for } t=3, \\dots, T$$\n这是一个关于残差变化量 $\\Delta \\hat{u}_t$ 对残差的滞后水平 $\\hat{u}_{t-1}$ 和滞后变化量 $\\Delta \\hat{u}_{t-1}$ 的 OLS 回归。回归在 $T-2$ 个观测值上进行。\n\n令 $Z$ 为因变量的 $(T-2) \\times 1$ 向量，即 $(\\Delta \\hat{u}_3, \\dots, \\Delta \\hat{u}_T)^T$。令 $W$ 为自变量的 $(T-2) \\times 2$ 矩阵，其行为 $(\\hat{u}_{t-1}, \\Delta \\hat{u}_{t-1})$，其中 $t=3, \\dots, T$。$(\\varphi, \\gamma)$ 的 OLS 估计为 $\\hat{\\psi} = (\\hat{\\varphi}, \\hat{\\gamma})^T = (W^T W)^{-1} W^T Z$。\n\n检验统计量是系数 $\\varphi$ 的 t-统计量：\n$$\\tau = \\frac{\\hat{\\varphi}}{SE(\\hat{\\varphi})}$$\n其中 $SE(\\hat{\\varphi})$ 是估计值 $\\hat{\\varphi}$ 的标准误。它被计算为系数协方差矩阵 $\\hat{\\sigma}_{\\varepsilon^{\\ast}}^2 (W^T W)^{-1}$ 的第一个对角元素的平方根。回归误差项 $\\varepsilon_t^{\\ast}$ 的方差估计为：\n$$\\hat{\\sigma}_{\\varepsilon^{\\ast}}^2 = \\frac{1}{T-2-2} \\sum_{t=3}^T (\\varepsilon_t^{\\ast})^2 = \\frac{SSR}{T-4}$$\n其中 $SSR$ 是 ADF 回归的残差平方和。\n\n**步骤 3：决策规则**\n\n原假设 $H_0: \\varphi = 0$（残差中存在单位根，无协整）与单边备择假设 $H_1: \\varphi  0$（平稳性，协整）进行检验。\n\n计算出的 t-统计量 $\\tau$ 与一个特定的临界值进行比较。因为该检验是在对 $I(1)$ 变量进行回归得到的残差上执行的，所以 $\\tau$ 的分布是非标准的，被称为 Engle-Granger 分布。问题提供了显著性水平为 $\\alpha = 0.05$ 时的适当临界值，即 $c_{0.05} = -3.34$。\n\n决策规则是：\n- 如果 $\\tau \\le -3.34$，则拒绝 $H_0$。我们断定序列是协整的。该测试用例的结果是 `True`。\n- 如果 $\\tau > -3.34$，则不拒绝 $H_0$。我们断定没有协整的证据。该测试用例的结果是 `False`。\n\n将此完整过程应用于三个测试用例中的每一个，以确定最终的布尔值输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Engle-Granger two-step cointegration test for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # (T, seed, c, beta, sigma_eps, sigma_eta, phi, residual_type)\n        (400, 101, 0.5, 1.3, 1.0, 0.3, 0.4, \"stationary\"),\n        (400, 202, 0.5, 1.3, 1.0, 0.8, 0.0, \"random_walk\"),\n        (400, 303, -0.2, -0.8, 0.8, 0.5, 0.7, \"stationary\"),\n    ]\n\n    results = []\n    critical_value = -3.34\n\n    for case in test_cases:\n        T, seed, c, beta, sigma_eps, sigma_eta, phi, residual_type = case\n\n        # Step 1: Data Generation\n        rng = np.random.default_rng(seed)\n        eps = rng.normal(loc=0.0, scale=sigma_eps, size=T)\n        eta = rng.normal(loc=0.0, scale=sigma_eta, size=T)\n\n        # Generate x_t as a random walk\n        x = np.zeros(T + 1)\n        for t in range(1, T + 1):\n            x[t] = x[t - 1] + eps[t - 1]\n\n        # Generate y_t based on the residual type\n        # In the main vector y, y[t-1] corresponds to the mathematical y_t\n        if residual_type == \"stationary\":\n            v = np.zeros(T + 1)\n            for t in range(1, T + 1):\n                v[t] = phi * v[t-1] + eta[t-1]\n            error_term = v[1:T+1]\n        elif residual_type == \"random_walk\":\n            s = np.zeros(T + 1)\n            for t in range(1, T + 1):\n                s[t] = s[t-1] + eta[t-1]\n            error_term = s[1:T+1]\n        \n        y = c + beta * x[0:T] + error_term\n\n        # Step 2: Engle-Granger Stage 1 - OLS regression to get residuals\n        # Regress y_t on a constant and x_{t-1}\n        X_ols1 = np.vstack((np.ones(T), x[0:T])).T\n        \n        # Using lstsq is numerically more stable than direct matrix inversion\n        coeffs_ols1, _, _, _ = np.linalg.lstsq(X_ols1, y, rcond=None)\n        u_hat = y - X_ols1 @ coeffs_ols1\n\n        # Step 3: Engle-Granger Stage 2 - ADF test on residuals\n        # ADF model: Delta(u_hat)_t = phi*u_hat_{t-1} + gamma*Delta(u_hat)_{t-1} + e_t\n        # for t = 3, ..., T. This gives T-2 observations.\n        delta_u_hat = u_hat[1:] - u_hat[:-1]  # Corresponds to Delta(u_hat)_2, ..., Delta(u_hat)_T\n\n        # Dependent variable: Delta(u_hat)_t for t=3,...,T\n        Y_adf = delta_u_hat[1:]  # Corresponds to Delta(u_hat)_3, ..., Delta(u_hat)_T\n\n        # Independent variables\n        # u_hat_{t-1} for t=3,...,T\n        X_adf_col1 = u_hat[1:-1]\n        # Delta(u_hat)_{t-1} for t=3,...,T\n        X_adf_col2 = delta_u_hat[:-1]\n        \n        X_adf = np.vstack((X_adf_col1, X_adf_col2)).T\n\n        # Perform OLS for the ADF regression\n        coeffs_adf, ssr_adf, _, _ = np.linalg.lstsq(X_adf, Y_adf, rcond=None)\n        phi_hat = coeffs_adf[0]\n\n        # Calculate the t-statistic for phi_hat\n        n_obs_adf = T - 2\n        k_params_adf = 2\n        df = n_obs_adf - k_params_adf\n\n        # Estimate of the regression error variance\n        sigma2_hat_adf = ssr_adf[0] / df\n\n        # Variance-covariance matrix of the ADF coefficients\n        try:\n            cov_matrix = sigma2_hat_adf * np.linalg.inv(X_adf.T @ X_adf)\n            se_phi_hat = np.sqrt(cov_matrix[0, 0])\n            tau_statistic = phi_hat / se_phi_hat\n        except np.linalg.LinAlgError:\n            # Handle cases of singular matrix, which is unlikely but possible\n            # A very large t-stat would not reject the null, which is a safe default\n            tau_statistic = 0.0\n\n        # Step 4: Decision\n        is_cointegrated = tau_statistic = critical_value\n        results.append(is_cointegrated)\n        \n    # Format and print the final output\n    print(f\"[{','.join(str(r) for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "标准的Engle-Granger检验通常依赖于预先计算好的临界值表，但这些值在小样本或复杂数据结构下可能不够准确。本练习将通过引入参数自助法（parametric bootstrap）来提升您的技能，这是一种强大的模拟技术，可以为您的特定数据集生成定制的临界值。这种方法不仅提高了协整检验的可靠性，也让您更深刻地理解在非标准条件下进行假设检验的逻辑。",
            "id": "2380094",
            "problem": "给定一个程式化的任务，其背景源于动态随机存取存储器（DRAM）供应链和股票市场的定价问题。令 $x_t$ 表示代表DRAM现货价格对数的合成序列，令 $y_t$ 表示代表DRAM制造商股价对数的合成序列。在不同的数据生成过程下，$x_t$ 和 $y_t$ 都将作为一阶单整序列（记为 $I(1)$）生成。您的任务是，从基本原理出发，实现一个基于残差的Engle–Granger协整检验，该检验对估计出的协整残差使用增广Dickey–Fuller (ADF) 检验，并通过在无协整原假设下的参数化自助法（parametric bootstrap）获得决策阈值。\n\n从以下基本定义和事实开始：\n- 如果一个时间序列 $\\{z_t\\}$ 的差分 $\\Delta z_t = z_t - z_{t-1}$ 是协方差平稳的，而 $z_t$ 本身不是平稳的，则称该序列为一阶单整序列，记为 $I(1)$。\n- 如果存在一个向量 $(1,-\\beta)$ 和一个常数 $\\alpha$，使得残差 $u_t = y_t - \\alpha - \\beta x_t$ 是协方差平稳的，则两个 $I(1)$ 序列 $\\{x_t\\}$ 和 $\\{y_t\\}$ 是协整的。根据Granger表示定理，如果 $\\{x_t,y_t\\}$ 是协整的，那么它们的短期动态允许一个误差修正模型（ECM），其中 $\\Delta y_t$ 包含滞后的残差 $u_{t-1}$ 作为一个误差修正项，且其系数非零。\n- Engle–Granger程序通过普通最小二乘法估计 $\\alpha$ 和 $\\beta$，然后对残差 $u_t$ 应用增广Dickey–Fuller (ADF) 检验，以检验 $u_t$ 中存在单位根的原假设，其备择假设为平稳性。对于给定的滞后阶数 $k \\in \\{0,1,2,\\dots\\}$，ADF回归为：\n$$\n\\Delta u_t = \\phi\\, u_{t-1} + \\sum_{j=1}^{k} \\gamma_j\\, \\Delta u_{t-j} + \\varepsilon_t,\n$$\n该回归不含截距项或趋势项，其中 $\\Delta u_t = u_t - u_{t-1}$，检验统计量（$\\tau$-统计量）是 $\\phi$ 的 $t$-统计量。\n\n您必须在不使用任何专门的时间序列库的情况下实现以下组件：\n1. 根据下面测试套件中指定的数据生成过程，模拟序列 $\\{x_t\\}$ 和 $\\{y_t\\}$。\n2. 通过普通最小二乘法（OLS）估计协整回归 $y_t = \\alpha + \\beta x_t + u_t$ 并构建残差 $\\{\\hat{u}_t\\}$。\n3. 通过在候选集 $k \\in \\{0,1,\\dots,k_{\\max}\\}$ 上最小化贝叶斯信息准则（BIC）来选择ADF滞后阶数 $k$，其中\n$$\nk_{\\max} = \\left\\lfloor 12 \\cdot \\left(\\frac{T}{100}\\right)^{1/4} \\right\\rfloor,\n$$\n$T$ 是样本大小，ADF回归包含 $u_{t-1}$ 和 $\\Delta u_{t-j}$（对于 $j=1,\\dots,k$），但不含常数项，对于一个具有残差平方和 $\\mathrm{RSS}$、样本大小 $n$ 和 $m$ 个回归量的OLS回归，其BIC为\n$$\n\\mathrm{BIC} = \\ln\\!\\left(\\frac{\\mathrm{RSS}}{n}\\right) + \\frac{m \\ln(n)}{n}.\n$$\n4. 在选定的模型中计算 $\\phi$ 的ADF $\\tau$-统计量。\n5. 在无协整的原假设下，使用参数化自助法获取经验临界值。在原假设下，将自助法序列 $\\{y_t^{\\ast}\\}$ 生成为独立于观测到的 $\\{x_t\\}$ 的 $I(1)$ 随机游走：\n$$\ny_0^{\\ast} = y_0,\\quad y_t^{\\ast} = y_{t-1}^{\\ast} + \\eta_t^{\\ast},\\quad \\eta_t^{\\ast} \\sim \\mathcal{N}(0,\\hat{\\sigma}_{\\Delta y}^2),\n$$\n其中 $\\hat{\\sigma}_{\\Delta y}^2$ 是 $\\Delta y_t$ 的样本方差。对于每次自助法重复，对 $(x_t, y_t^{\\ast})$ 完全按照步骤 $2$–$4$ 运行Engle–Granger程序，收集自助法 $\\tau$-统计量，并将左尾经验 $\\alpha$-分位数作为临界值。使用 $\\alpha = 0.05$。\n6. 决策规则：如果观测到的 $\\tau$-统计量小于或等于自助法临界值，则拒绝无协整的原假设。为每个测试案例输出一个布尔值，指示在 $\\alpha = 0.05$ 的水平上是否检测到协整。\n\n测试套件的数据生成过程：\n- 案例 $\\mathrm{A}$（协整，稳定的误差修正）：令 $T=240$，$\\beta=1.5$，$\\rho=0.6$，$\\sigma_e=1.0$，$\\sigma_v=0.5$。独立地生成新息 $e_t \\sim \\mathcal{N}(0,\\sigma_e^2)$ 和 $v_t \\sim \\mathcal{N}(0,\\sigma_v^2)$。构建 $x_0=0$，$z_0=0$，并且对于 $t=1,\\dots,T$：\n$$\nx_t = x_{t-1} + e_t,\\quad z_t = \\rho z_{t-1} + v_t,\\quad y_t = \\alpha + \\beta x_t + z_t,\\quad \\alpha = 0.\n$$\n- 案例 $\\mathrm{B}$（非协整，独立的随机趋势）：令 $T=240$，$\\sigma_e=1.0$，$\\sigma_w=1.0$。独立地生成 $e_t \\sim \\mathcal{N}(0,\\sigma_e^2)$ 和 $w_t \\sim \\mathcal{N}(0,\\sigma_w^2)$。构建 $x_0=0$，$y_0=0$，并且对于 $t=1,\\dots,T$：\n$$\nx_t = x_{t-1} + e_t,\\quad y_t = y_{t-1} + w_t.\n$$\n- 案例 $\\mathrm{C}$（协整，近边界的误差修正）：令 $T=120$，$\\beta=1.2$，$\\rho=0.95$，$\\sigma_e=1.0$，$\\sigma_v=0.5$。独立地生成 $e_t \\sim \\mathcal{N}(0,\\sigma_e^2)$ 和 $v_t \\sim \\mathcal{N}(0,\\sigma_v^2)$。构建 $x_0=0$，$z_0=0$，并且对于 $t=1,\\dots,T$：\n$$\nx_t = x_{t-1} + e_t,\\quad z_t = \\rho z_{t-1} + v_t,\\quad y_t = \\alpha + \\beta x_t + z_t,\\quad \\alpha = 0.\n$$\n\n实现细节和固定设置：\n- 为了可复现性，每个案例使用此处指定的相同数值种子：案例 $\\mathrm{A}$ 种子 $=12345$，案例 $\\mathrm{B}$ 种子 $=23456$，案例 $\\mathrm{C}$ 种子 $=34567$。\n- 对于自助法，每个案例使用 $R=400$ 次重复，并使用与该案例种子相同的种子来初始化自助法随机数生成器。使用一个高斯生成器，其方差通过该案例中 $\\Delta y_t$ 的样本方差进行校准。\n- 对每个案例单独使用 $k_{\\max} = \\left\\lfloor 12 \\cdot \\left(\\frac{T}{100}\\right)^{1/4} \\right\\rfloor$，并如上所述通过BIC选择 $k$。\n- 所有回归必须通过使用线性代数的普通最小二乘法计算；不要调用任何预打包的单位根或协整例程。\n\n最终输出规范：\n- 您的程序必须为三个案例 $(\\mathrm{A},\\mathrm{B},\\mathrm{C})$ 中的每一个计算一个布尔值，指示是否在 $\\alpha=0.05$ 的水平上使用如上所述计算的自助法临界值检测到协整。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，顺序为 $[\\mathrm{A},\\mathrm{B},\\mathrm{C}]$。例如，一个有效的输出格式是 $[\\mathrm{True},\\mathrm{False},\\mathrm{True}]$。不应打印任何额外文本。",
            "solution": "所述问题是有效的。它在科学上基于成熟的计量经济学理论，特别是用于协整检验的Engle–Granger两步法。该问题是良定的，提供了所有必要的参数、数据生成过程和算法规范，从而能够得出一个唯一的、可验证的解。其术语精确，目标客观且可形式化。我现在将着手解决。\n\n任务是实现一个基于残差的Engle–Granger协整检验，其中检验统计量的临界值通过参数化自助法确定。此过程必须应用于三个不同的数据生成过程（DGP）。整个实现必须从基本原理出发，仅利用基本的线性代数运算。\n\n每个测试案例的总体流程如下：\n1. 根据指定的DGP生成时间序列 $\\{x_t\\}_{t=0}^T$ 和 $\\{y_t\\}_{t=0}^T$。\n2. 使用观测数据 $(x_t, y_t)$ 和Engle–Granger方法计算检验统计量 $\\tau_{obs}$。\n3. 使用参数化自助法，在无协整的原假设下，生成检验统计量的经验分布。\n4. 在显著性水平 $\\alpha=0.05$ 下，从此经验分布中确定临界值 $c_\\alpha$。\n5. 将 $\\tau_{obs}$ 与 $c_\\alpha$ 进行比较，以决定是否拒绝原假设。\n\n让我们详细说明这些步骤。\n\n**步骤1：数据生成过程**\n\n我们必须为三种情况生成样本数据。所有序列的长度均为 $T+1$。\n\n- **案例A（协整）：** 参数为 $T=240$，$\\beta=1.5$，$\\rho=0.6$，$\\sigma_e=1.0$，$\\sigma_v=0.5$ 和 $\\alpha=0$。新息 $e_t \\sim \\mathcal{N}(0, \\sigma_e^2)$ 和 $v_t \\sim \\mathcal{N}(0, \\sigma_v^2)$ 是独立的。序列构建如下：\n$$\nx_t = x_{t-1} + e_t, \\quad x_0=0\n$$\n$$\nz_t = \\rho z_{t-1} + v_t, \\quad z_0=0\n$$\n$$\ny_t = \\beta x_t + z_t\n$$\n在这里，$x_t$ 是一个 $I(1)$ 过程（一个随机游走）。由于 $|\\rho|1$，$z_t$ 项是一个平稳的AR(1)过程。线性组合 $y_t - \\beta x_t = z_t$ 是平稳的，因此根据定义，$x_t$ 和 $y_t$ 是协整的。\n\n- **案例B（非协整）：** 参数为 $T=240$，$\\sigma_e=1.0$ 和 $\\sigma_w=1.0$。新息 $e_t \\sim \\mathcal{N}(0, \\sigma_e^2)$ 和 $w_t \\sim \\mathcal{N}(0, \\sigma_w^2)$ 是独立的。序列构建为两个独立的随机游走：\n$$\nx_t = x_{t-1} + e_t, \\quad x_0=0\n$$\n$$\ny_t = y_{t-1} + w_t, \\quad y_0=0\n$$\n由于 $x_t$ 和 $y_t$ 由独立的随机趋势驱动，它们的任何线性组合都不可能是平稳的。它们不是协整的。\n\n- **案例C（协整，接近单位根）：** 此案例在结构上与案例A相同，但参数为 $T=120$，$\\beta=1.2$ 和 $\\rho=0.95$。$\\rho$ 的高值使得平稳分量 $z_t$ 具有高度持续性，这对单位根检验区分其与非平稳 $I(1)$ 过程提出了更大的挑战。\n\n**步骤2：Engle–Granger检验过程**\n\n此过程应用于一对序列 $(x_t, y_t)$ 以产生单个检验统计量 $\\tau$。\n\n**2.1. 协整回归**\n首先，我们使用普通最小二乘法（OLS）在样本 $t=0, \\dots, T$ 上估计长期关系 $y_t = \\alpha + \\beta x_t + u_t$。我们定义观测向量 $\\mathbf{y} = [y_0, \\dots, y_T]^T$ 和设计矩阵 $\\mathbf{X}$，其中包含一列1和一列 $x_t$ 值。\n$$\n\\mathbf{X} = \\begin{bmatrix} 1  x_0 \\\\ 1  x_1 \\\\ \\vdots  \\vdots \\\\ 1  x_T \\end{bmatrix}\n$$\n系数向量 $\\mathbf{b} = [\\alpha, \\beta]^T$ 的OLS估计量由下式给出：\n$$\n\\hat{\\mathbf{b}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\n$$\n然后，对于 $t=0, \\dots, T$，计算残差 $\\hat{u}_t = y_t - \\hat{\\alpha} - \\hat{\\beta} x_t$。\n\n**2.2. 对残差的增广Dickey–Fuller (ADF) 检验**\n检验的核心是检查残差 $\\{\\hat{u}_t\\}$ 是否平稳。我们在ADF回归中检验原假设 $H_0: \\phi=0$ 对备择假设 $H_A: \\phi0$：\n$$\n\\Delta \\hat{u}_t = \\phi \\hat{u}_{t-1} + \\sum_{j=1}^{k} \\gamma_j \\Delta \\hat{u}_{t-j} + \\varepsilon_t\n$$\n包含滞后差分项 $\\Delta \\hat{u}_{t-j}$ 是为了处理误差项 $\\varepsilon_t$ 中潜在的序列相关。检验统计量是与系数 $\\hat{\\phi}$ 相关的 $\\tau$-统计量（或 $t$-统计量）。\n\n**2.3. 滞后阶数选择**\n滞后数 $k$ 是一个关键参数。它是通过在一组候选值 $k \\in \\{0, 1, \\dots, k_{\\max}\\}$ 上最小化贝叶斯信息准则（BIC）来选择的。最大滞后阶数由下式给出：\n$$\nk_{\\max} = \\left\\lfloor 12 \\cdot \\left(\\frac{T}{100}\\right)^{1/4} \\right\\rfloor\n$$\n对于每个候选滞后 $k$，执行一次OLS回归。给定 $k$ 的回归在 $t=k+1, \\dots, T$ 上进行，得到样本大小为 $n = T-k$。估计的参数数量为 $m = k+1$（一个用于 $\\phi$，k个用于 $\\gamma_j$ 系数）。然后计算BIC：\n$$\n\\text{BIC}(k) = \\ln\\left(\\frac{\\text{RSS}_k}{n}\\right) + \\frac{m \\ln(n)}{n}\n$$\n其中 $\\text{RSS}_k$ 是具有 $k$ 个滞后的ADF回归的残差平方和。最优滞后 $k^*$ 是产生最小BIC的那个。\n\n**2.4. ADF检验统计量计算**\n使用最优滞后阶数 $k^*$，我们执行ADF回归。令 $\\mathbf{Y}_{\\text{ADF}}$ 为 $\\Delta \\hat{u}_t$ 的向量，$\\mathbf{X}_{\\text{ADF}}$ 为回归量 $(\\hat{u}_{t-1}, \\Delta \\hat{u}_{t-1}, \\dots, \\Delta \\hat{u}_{t-k^*})$ 的矩阵。OLS系数向量为 $\\hat{\\boldsymbol{\\theta}} = (\\mathbf{X}_{\\text{ADF}}^T \\mathbf{X}_{\\text{ADF}})^{-1} \\mathbf{X}_{\\text{ADF}}^T \\mathbf{Y}_{\\text{ADF}}$，其中第一个元素是 $\\hat{\\phi}$。检验统计量是 $\\hat{\\phi}$ 的 $t$-比率：\n$$\n\\tau = \\frac{\\hat{\\phi}}{\\text{SE}(\\hat{\\phi})}\n$$\n标准误 $\\text{SE}(\\hat{\\phi})$ 是系数协方差矩阵 $\\hat{\\Sigma}_{\\hat{\\boldsymbol{\\theta}}}$ 的第一个对角元素的平方根。该矩阵估计如下：\n$$\n\\hat{\\Sigma}_{\\hat{\\boldsymbol{\\theta}}} = \\hat{\\sigma}_\\varepsilon^2 (\\mathbf{X}_{\\text{ADF}}^T \\mathbf{X}_{\\text{ADF}})^{-1}, \\quad \\text{其中} \\quad \\hat{\\sigma}_\\varepsilon^2 = \\frac{\\text{RSS}_{k^*}}{n - m}\n$$\n得到的 $\\tau$ 是观测到的检验统计量 $\\tau_{obs}$。\n\n**步骤3：用于临界值的参数化自助法**\n\n标准的Dickey-Fuller临界值在这里不适用，因为ADF检验是在*估计出的*残差上执行的，而不是在观测到的序列上。$\\tau$-统计量的分布取决于 $x_t$ 的属性和样本大小。因此，我们使用在无协整原假设下的参数化自助法来生成临界值。\n\n在 $H_0$ 下，$x_t$ 和 $y_t$ 是独立的 $I(1)$ 过程。该过程是：\n1. 对于观测数据，计算 $y_t$ 序列的一阶差分 $\\Delta y_t = y_t - y_{t-1}$，并计算其样本方差 $\\hat{\\sigma}_{\\Delta y}^2$。\n2. 生成 $R=400$ 个自助样本。对于每次重复 $r=1, \\dots, R$：\n    a. 保持原始的 $x_t$ 序列不变。\n    b. 生成一个新序列 $y_t^*$ 作为随机游走，独立于 $x_t$。新息 $\\eta_t^*$ 从一个用观测数据校准的正态分布中抽取：$\\eta_t^* \\sim \\mathcal{N}(0, \\hat{\\sigma}_{\\Delta y}^2)$。\n    $$\n    y_0^* = y_0, \\quad y_t^* = y_{t-1}^* + \\eta_t^* \\quad \\text{对于 } t=1, \\dots, T\n    $$\n    c. 将完整的Engle–Granger检验过程（步骤2.1至2.4）应用于对 $(x_t, y_t^*)$，以获得一个自助检验统计量 $\\tau^*_r$。\n3. 收集所有 $R$ 个自助统计量 $\\{\\tau^*_1, \\dots, \\tau^*_R\\}$，以形成原假设下检验统计量的经验分布。\n4. 对于检验水平 $\\alpha=0.05$，临界值 $c_\\alpha$ 是此排序后经验分布的第5百分位数。对于 $R=400$，这对应于 $\\tau^*$ 统计量排序列表中的第20个值。\n\n**步骤4：决策规则**\n\n无协整的原假设（对应于残差中的单位根，$\\phi=0$）是针对平稳性的单边备择假设（$\\phi0$）进行检验的。因此，我们使用左尾检验。\n- 如果 $\\tau_{obs} \\leq c_\\alpha$，我们拒绝原假设，并断定序列是协整的。\n- 如果 $\\tau_{obs} > c_\\alpha$，我们未能拒绝原假设，并断定没有协整的证据。\n\n这套完整的方法将被实现并应用于三种情况中的每一种，以确定最终的布尔值结果。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the cointegration test for all cases.\n    \"\"\"\n\n    def perform_ols(y, X):\n        \"\"\"\n        Performs Ordinary Least Squares (OLS) regression.\n        \n        Args:\n            y (np.ndarray): Dependent variable vector.\n            X (np.ndarray): Matrix of independent variables (regressors).\n\n        Returns:\n            tuple: A tuple containing:\n                - beta_hat (np.ndarray): Estimated coefficients.\n                - residuals (np.ndarray): Regression residuals.\n                - rss (float): Residual sum of squares.\n                - cov_beta (np.ndarray): Covariance matrix of the coefficients.\n        \"\"\"\n        try:\n            # Using np.linalg.solve is more stable than inv()\n            XtX = X.T @ X\n            XtY = X.T @ y\n            beta_hat = np.linalg.solve(XtX, XtY)\n            residuals = y - X @ beta_hat\n            rss = residuals.T @ residuals\n            n, m = X.shape\n            # Degrees of freedom for variance estimation should be n - m\n            # If n = m, regression is not identified, return NaN to signal failure\n            if n = m:\n                return beta_hat, residuals, rss, np.full((m, m), np.nan)\n            \n            # Unbiased estimator for error variance\n            sigma2_hat = rss / (n - m)\n            # Covariance matrix of estimators\n            cov_beta = sigma2_hat * np.linalg.inv(XtX)\n            return beta_hat, residuals, rss, cov_beta\n        except np.linalg.LinAlgError:\n            # In case of singular matrix, return NaNs\n            m = X.shape[1]\n            return np.full(m, np.nan), np.full_like(y, np.nan), np.nan, np.full((m, m), np.nan)\n\n    def engle_granger_test_stat(x_series, y_series):\n        \"\"\"\n        Computes the Engle-Granger ADF test statistic for a given pair of series.\n        \n        Args:\n            x_series (np.ndarray): The x time series.\n            y_series (np.ndarray): The y time series.\n\n        Returns:\n            float: The calculated ADF tau-statistic.\n        \"\"\"\n        T_full = len(x_series) - 1\n        \n        # Step 2: OLS Cointegration Regression\n        X_coint = np.c_[np.ones(T_full + 1), x_series]\n        b_hat, u_hat, _, _ = perform_ols(y_series, X_coint)\n\n        if np.isnan(b_hat).any():\n             return np.nan\n\n        # Step 3: ADF Lag Selection\n        k_max = int(12 * ((T_full / 100) ** 0.25))\n        delta_u = np.diff(u_hat)\n        \n        best_k = -1\n        min_bic = np.inf\n        \n        # Store results of best k regression to avoid re-computation\n        best_k_results = {}\n\n        for k in range(k_max + 1):\n            # Construct ADF regression matrices\n            y_adf = delta_u[k:]\n            \n            # Regressors\n            u_lag1 = u_hat[k:-1]\n            X_adf_cols = [u_lag1]\n            for j in range(1, k + 1):\n                lagged_delta_u = delta_u[k-j:-j]\n                X_adf_cols.append(lagged_delta_u)\n            \n            X_adf = np.stack(X_adf_cols, axis=1)\n\n            n, m = X_adf.shape\n            if n = m:\n                continue\n\n            # OLS for ADF regression\n            beta_adf, _, rss_adf, cov_beta_adf = perform_ols(y_adf, X_adf)\n            \n            if np.isnan(rss_adf):\n                continue\n\n            bic = np.log(rss_adf / n) + (m * np.log(n)) / n\n            \n            if bic  min_bic:\n                min_bic = bic\n                best_k = k\n                best_k_results['beta'] = beta_adf\n                best_k_results['cov'] = cov_beta_adf\n        \n        if best_k == -1 or 'beta' not in best_k_results:\n            return np.nan\n\n        # Step 4: Compute ADF tau-statistic from the best model\n        phi_hat = best_k_results['beta'][0]\n        \n        if np.isnan(best_k_results['cov'][0, 0]) or best_k_results['cov'][0, 0] = 0:\n            return np.nan\n        se_phi = np.sqrt(best_k_results['cov'][0, 0])\n        \n        if se_phi == 0:\n            return np.nan\n            \n        tau_statistic = phi_hat / se_phi\n        return tau_statistic\n\n    test_cases = [\n        {'name': 'A', 'T': 240, 'beta': 1.5, 'rho': 0.6, 'sigma_e': 1.0, 'sigma_v': 0.5, 'seed': 12345},\n        {'name': 'B', 'T': 240, 'sigma_e': 1.0, 'sigma_w': 1.0, 'seed': 23456},\n        {'name': 'C', 'T': 120, 'beta': 1.2, 'rho': 0.95, 'sigma_e': 1.0, 'sigma_v': 0.5, 'seed': 34567},\n    ]\n\n    R = 400\n    alpha_sig = 0.05\n    results = []\n\n    for case in test_cases:\n        T = case['T']\n        seed = case['seed']\n        rng = np.random.default_rng(seed)\n\n        # Step 1: Generate Data\n        x = np.zeros(T + 1)\n        y = np.zeros(T + 1)\n\n        if case['name'] in ['A', 'C']:\n            e = rng.normal(0, case['sigma_e'], size=T)\n            v = rng.normal(0, case['sigma_v'], size=T)\n            z = np.zeros(T + 1)\n            x[1:] = np.cumsum(e)\n            for t in range(1, T + 1):\n                z[t] = case['rho'] * z[t-1] + v[t-1]\n            y = case['beta'] * x + z\n        else: # Case B\n            e = rng.normal(0, case['sigma_e'], size=T)\n            w = rng.normal(0, case['sigma_w'], size=T)\n            x[1:] = np.cumsum(e)\n            y[1:] = np.cumsum(w)\n        \n        # Compute observed test statistic\n        tau_observed = engle_granger_test_stat(x, y)\n        \n        # Step 5: Parametric Bootstrap\n        boot_rng = np.random.default_rng(seed)\n        delta_y = np.diff(y)\n        sigma_delta_y_sq = np.var(delta_y, ddof=1)\n        \n        tau_bootstrap = []\n        for _ in range(R):\n            eta_star = boot_rng.normal(0, np.sqrt(sigma_delta_y_sq), size=T)\n            y_star = np.zeros(T + 1)\n            # Initial y_0 is 0 for all cases\n            y_star[0] = 0.0 \n            y_star[1:] = np.cumsum(eta_star)\n            \n            tau_boot_stat = engle_granger_test_stat(x, y_star)\n            if not np.isnan(tau_boot_stat):\n                tau_bootstrap.append(tau_boot_stat)\n\n        tau_bootstrap.sort()\n        \n        # Get critical value from bootstrap distribution\n        num_valid_boots = len(tau_bootstrap)\n        if num_valid_boots == 0:\n            results.append(False) \n            continue\n\n        # Correctly find the index for the alpha-quantile (e.g., 5th percentile for alpha=0.05)\n        # For N items, the p-th percentile is at index floor((N-1)*p), or more simply for left-tail CV,\n        # the k-th smallest value where k=ceil(N*alpha). k-th value is at index k-1.\n        cv_index = int(np.ceil(num_valid_boots * alpha_sig)) - 1\n        cv_index = max(0, cv_index) # ensure non-negative\n        \n        critical_value = tau_bootstrap[cv_index]\n        \n        # Step 6: Decision Rule\n        is_cointegrated = tau_observed = critical_value\n        results.append(is_cointegrated)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "协整分析的一个核心假设是长期关系在时间上是稳定的。然而，政策变化、技术冲击等经济现实可能导致这种关系发生破裂。本练习将着手解决这个关键问题，要求您实现一个递归估计程序，以监控协整向量的稳定性，并检测潜在结构性断裂发生的时间点。",
            "id": "2380077",
            "problem": "给定两个合成时间序列，这两个序列被构建为遵循一个可能在未知时间点经历结构性变动的长期关系。设 $\\{x_t\\}_{t=0}^{T-1}$ 和 $\\{y_t\\}_{t=0}^{T-1}$ 的定义如下。对于所有 $t \\in \\{0,1,\\dots,T-1\\}$，设 $x_0 = 0$ 且当 $t \\ge 1$ 时，\n$$\nx_t = x_{t-1} + \\sigma_e \\,\\varepsilon_t,\n$$\n并且\n$$\ny_t = \\alpha + \\beta(t)\\, x_t + \\sigma_u \\,\\eta_t,\n$$\n其中 $\\{\\varepsilon_t\\}$ 和 $\\{\\eta_t\\}$ 是独立同分布标准正态随机变量的独立序列，并且 $\\beta(t)$ 是一个分段常数函数\n$$\n\\beta(t) = \\begin{cases}\n\\beta_1,  t \\le T_b,\\\\\n\\beta_2,  t > T_b.\n\\end{cases}\n$$\n常数 $T_b$ 表示长期协整斜率从 $\\beta_1$ 变为 $\\beta_2$ 的（潜在）断点指数。如果不想设置断点，则取 $T_b \\ge T$，使得对于所有 $t$，$\\beta(t) = \\beta_1$。截距 $\\alpha$ 是恒定的。\n\n扰动项 $\\{\\varepsilon_t\\}$ 和 $\\{\\eta_t\\}$ 必须通过使用线性同余生成器从指定的均匀伪随机序列中确定性地生成，以确保可复现性。定义整数上的乘法线性同余序列 $\\{U_k\\}$ 如下\n$$\nU_{k} = (a \\cdot U_{k-1}) \\bmod m,\\quad k \\ge 1,\\quad U_0 = s,\n$$\n其模数 $m = 2^{31}-1$，乘数 $a = 16807$，整数种子 $s \\in \\{1,2,\\dots,m-1\\}$。通过 $R_k = U_k/m$ 映射到均匀分布 $R_k \\in (0,1)$。使用 Box–Muller 变换将其转换为独立标准正态新息：对于每一对 $(R_{2j-1}, R_{2j})$，\n$$\nZ_{2j-1} = \\sqrt{-2\\ln R_{2j-1}}\\,\\cos(2\\pi R_{2j}),\\quad\nZ_{2j} = \\sqrt{-2\\ln R_{2j-1}}\\,\\sin(2\\pi R_{2j}),\n$$\n其中三角函数中的所有角度均以弧度为单位。使用前 $T$ 个正态抽样值作为 $\\{\\varepsilon_t\\}$，后 $T$ 个正态抽样值作为 $\\{\\eta_t\\}$。\n\n为进行检测，定义一个针对协整关系 $y_s = \\alpha + \\beta x_s + \\text{error}$ 的普通最小二乘法（Ordinary Least Squares (OLS)）估计量的递归序列，该序列在扩展样本上计算。对于每个 $t \\in \\{T_{\\min}, T_{\\min}+1, \\dots, T-2\\}$，通过最小化 $\\sum_{s=0}^{t} (y_s - \\alpha - \\beta x_s)^2$ 来估计 $(\\widehat{\\alpha}_t,\\widehat{\\beta}_t)$。等价地，使用 $n_t = t+1$、样本均值 $\\overline{x}_t = \\frac{1}{n_t}\\sum_{s=0}^{t} x_s$ 和 $\\overline{y}_t = \\frac{1}{n_t}\\sum_{s=0}^{t} y_s$、以及中心化和 $S_{xx,t} = \\sum_{s=0}^{t} (x_s-\\overline{x}_t)^2$，$S_{xy,t} = \\sum_{s=0}^{t} (x_s-\\overline{x}_t)(y_s-\\overline{y}_t)$，\n$$\n\\widehat{\\beta}_t = \\frac{S_{xy,t}}{S_{xx,t}},\\quad \\widehat{\\alpha}_t = \\overline{y}_t - \\widehat{\\beta}_t\\,\\overline{x}_t.\n$$\n设残差标准差为\n$$\n\\widehat{\\sigma}_t = \\sqrt{\\frac{1}{n_t - 2}\\sum_{s=0}^{t} \\left(y_s - \\widehat{\\alpha}_t - \\widehat{\\beta}_t x_s\\right)^2},\n$$\n定义于 $n_t \\ge 3$。构建在时间点 $t+1$ 的一步向前标准化预测误差，\n$$\nz_{t+1} = \\frac{y_{t+1} - \\widehat{\\alpha}_t - \\widehat{\\beta}_t x_{t+1}}{\\widehat{\\sigma}_t}.\n$$\n给定一个阈值 $c > 0$ 和一个游程长度 $L \\in \\mathbb{N}$，为 $s \\in \\{T_{\\min}+1, \\dots, T-1\\}$ 定义指示符 $I_s = \\mathbf{1}\\{|z_s| \\ge c\\}$。检测到的断点指数是满足 $I_{s^\\star} = I_{s^\\star+1} = \\dots = I_{s^\\star+L-1} = 1$ 的最小指数 $s^\\star$。如果不存在这样的指数，则返回 $-1$。以基于零的时间索引报告检测到的指数 $s^\\star$。\n\n将上述数据构建和检测过程实现为一个完整的程序，用于处理以下参数集测试套件，每个测试集指定为一个元组\n$$\n(T, T_b, \\alpha, \\beta_1, \\beta_2, \\sigma_e, \\sigma_u, T_{\\min}, c, L, s).\n$$\n- 测试用例 A: $(240, 150, 0.5, 1.0, 1.6, 1.0, 0.05, 40, 3.0, 2, 12345)$。\n- 测试用例 B: $(240, 10^9, 0.5, 1.0, 1.0, 1.0, 0.05, 40, 3.0, 2, 54321)$。\n- 测试用例 C: $(220, 210, 0.3, 0.8, 1.9, 0.9, 0.05, 30, 2.5, 2, 20231107)$。\n- 测试用例 D: $(180, 60, 0.2, 1.2, 1.4, 0.8, 0.1, 25, 2.0, 3, 424242)$。\n\n对于每个测试用例，您的程序应计算并返回一个整数：即检测到的断点指数 $s^\\star$（以基于零的索引）或者在规则下未检测到断点时返回 $-1$。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，“[rA,rB,rC,rD]”），其中 $rA$、 $rB$、 $rC$ 和 $rD$ 分别是对应于测试用例 A、B、C 和 D 的整数。",
            "solution": "该问题提出了一个在计算计量经济学中明确定义的任务：检测两个非平稳时间序列之间线性协整关系中的结构性断点。从数据生成到断点检测的整个过程都是通过算法指定的，这使得解是唯一且可验证的。严谨的分析分两个阶段进行：首先，确定性地生成合成数据；其次，应用递归监测算法。\n\n本练习的基础是一个可复现的数据生成过程。为确保这一点，我们不使用系统级的随机源，而是使用乘法线性同余生成器（LCG）从指定的种子 $s$ 构建所需的随机序列。整数序列 $\\{U_k\\}$ 由递推式 $U_{k} = (a \\cdot U_{k-1}) \\bmod m$（当 $k \\ge 1$ 时）给出，其中 $U_0 = s$。问题指定了行业标准参数 $m = 2^{31}-1$ 和 $a = 16807$。这些整数通过变换 $R_k = U_k/m$ 映射到区间 $(0, 1)$ 内的均匀伪随机数序列 $\\{R_k\\}$。\n\n从这个均匀序列中，我们必须生成独立的标准正态随机变量。为此，问题指定了 Box-Muller 变换。对于每一对均匀变量 $(R_{2j-1}, R_{2j})$，我们生成一对独立的标准正态变量 $(Z_{2j-1}, Z_{2j})$：\n$$\nZ_{2j-1} = \\sqrt{-2\\ln R_{2j-1}}\\,\\cos(2\\pi R_{2j})\n$$\n$$\nZ_{2j} = \\sqrt{-2\\ln R_{2j-1}}\\,\\sin(2\\pi R_{2j})\n$$\n问题要求总共进行 $2T$ 次正态抽样来构建序列。前 $T$ 次抽样构成序列 $\\{\\varepsilon_t\\}_{t=0}^{T-1}$，随后的 $T$ 次抽样构成序列 $\\{\\eta_t\\}_{t=0}^{T-1}$。\n\n利用这些扰动序列，时间序列得以构建。序列 $\\{x_t\\}$ 是一个 I($1$) 过程，具体来说是一个不含漂移的随机游走，从 $x_0 = 0$ 开始：\n$$\nx_t = x_{t-1} + \\sigma_e \\,\\varepsilon_t, \\quad \\text{对于 } t \\in \\{1, 2, \\dots, T-1\\}。\n$$\n序列 $\\{y_t\\}$ 被构建为与 $\\{x_t\\}$ 协整，并可能存在结构性断点。其定义为：\n$$\ny_t = \\alpha + \\beta(t)\\, x_t + \\sigma_u \\,\\eta_t, \\quad \\text{对于 } t \\in \\{0, 1, \\dots, T-1\\}。\n$$\n参数 $\\beta(t)$ 是一个阶跃函数，其值在断点指数 $T_b$ 处发生变化：\n$$\n\\beta(t) = \\beta_1 \\text{ 若 } t \\le T_b, \\quad \\text{且} \\quad \\beta(t) = \\beta_2 \\text{ 若 } t > T_b。\n$$\n$T_b \\ge T$ 的值表示在样本期内没有发生断点，因此对于所有 $t$，$\\beta(t) = \\beta_1$。\n\n第二阶段是检测断点。这是通过一个基于在扩展数据窗口上进行普通最小二乘法（OLS）估计的递归监测方案来完成的。对于从起始点 $T_{\\min}$ 到 $T-2$ 的每个时间指数 $t$，我们使用从 $s=0$ 到 $s=t$ 的所有可用数据来估计静态协整回归 $y_s = \\alpha + \\beta x_s + \\text{error}$ 的系数。\n\n为了高效地执行此估计，我们不为每次回归重新计算所需的和。相反，我们维护相关量的滚动总和：$\\sum x_s$、$\\sum y_s$、$\\sum x_s^2$、$\\sum y_s^2$ 和 $\\sum x_s y_s$。在每一步 $t$，我们用新的数据点 $(x_t, y_t)$ 更新这些总和。设 $n_t = t+1$ 为样本大小。然后使用从这些总和派生的标准公式计算 OLS 估计值 $(\\widehat{\\alpha}_t, \\widehat{\\beta}_t)$：\n$$\n\\widehat{\\beta}_t = \\frac{\\sum_{s=0}^{t} x_s y_s - n_t \\overline{x}_t \\overline{y}_t}{\\sum_{s=0}^{t} x_s^2 - n_t \\overline{x}_t^2}\n\\quad \\text{和} \\quad\n\\widehat{\\alpha}_t = \\overline{y}_t - \\widehat{\\beta}_t \\overline{x}_t,\n$$\n其中 $\\overline{x}_t$ 和 $\\overline{y}_t$ 是在 $\\{0, \\dots, t\\}$ 上的样本均值。\n\n检测机制的核心是一步向前标准化预测误差 $z_{t+1}$。该统计量衡量在给定截至时间 $t$ 所估计的模型下，下一个观测值 $(x_{t+1}, y_{t+1})$ 的惊奇程度。它定义为：\n$$\nz_{t+1} = \\frac{y_{t+1} - (\\widehat{\\alpha}_t + \\widehat{\\beta}_t x_{t+1})}{\\widehat{\\sigma}_t}\n$$\n分母 $\\widehat{\\sigma}_t$ 是回归残差的估计标准差，用于标准化预测误差。其计算公式为：\n$$\n\\widehat{\\sigma}_t = \\sqrt{\\frac{1}{n_t - 2}\\sum_{s=0}^{t} (y_s - \\widehat{\\alpha}_t - \\widehat{\\beta}_t x_s)^2}\n$$\n分子中的残差平方和可以高效地计算为 $S_{yy,t} - \\widehat{\\beta}_t S_{xy,t}$，其中 $S_{yy,t}$ 和 $S_{xy,t}$ 是中心化的平方和与交叉乘积和。\n\n当发生结构性断点时，基于可能跨越断点前后两种机制的数据的 OLS 估计会变得有偏。这种偏差会为后续时期产生系统性的不良预测，从而导致一系列大的预测误差。检测规则将此直觉形式化。我们定义一个指示符 $I_s = 1$（如果 $|z_s| \\ge c$）和 $I_s = 0$（否则），其中 $c$ 是给定的阈值。在第一个时间指数 $s^\\star$ 处发出断点信号，该指数引发了一个至少连续 $L$ 次的大标准化预测误差序列，即 $I_{s^\\star} = I_{s^\\star+1} = \\dots = I_{s^\\star+L-1} = 1$。对 $s^\\star$ 的搜索从指数 $T_{\\min}+1$ 开始。如果在观测窗口内未找到这样的序列，我们断定未检测到断点并报告 $-1$。对每个提供的参数集，整个过程都以确定性的方式实现。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        # (T, T_b, alpha, beta_1, beta_2, sigma_e, sigma_u, T_min, c, L, s)\n        (240, 150, 0.5, 1.0, 1.6, 1.0, 0.05, 40, 3.0, 2, 12345),\n        (240, 10**9, 0.5, 1.0, 1.0, 1.0, 0.05, 40, 3.0, 2, 54321),\n        (220, 210, 0.3, 0.8, 1.9, 0.9, 0.05, 30, 2.5, 2, 20231107),\n        (180, 60, 0.2, 1.2, 1.4, 0.8, 0.1, 25, 2.0, 3, 424242),\n    ]\n\n    results = []\n    for params in test_cases:\n        result = _run_case(params)\n        results.append(result)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _run_case(params):\n    \"\"\"\n    Processes a single test case.\n    \"\"\"\n    T, T_b, alpha, beta_1, beta_2, sigma_e, sigma_u, T_min, c, L, s = params\n\n    # --- 1. Data Generation ---\n\n    # LCG parameters\n    m = 2**31 - 1\n    a = 16807\n    \n    # Generate 2*T uniform random numbers\n    uniforms = np.zeros(2 * T)\n    U_k = s\n    for k in range(2 * T):\n        U_k = (a * U_k) % m\n        uniforms[k] = U_k / m\n\n    # Generate 2*T standard normal random numbers using Box-Muller transform\n    normals = np.zeros(2 * T)\n    for j in range(T):\n        R1 = uniforms[2*j]\n        R2 = uniforms[2*j+1]\n        \n        log_R1 = np.log(R1)\n        term1 = np.sqrt(-2.0 * log_R1)\n        term2 = 2.0 * np.pi * R2\n\n        normals[2*j] = term1 * np.cos(term2)\n        normals[2*j+1] = term1 * np.sin(term2)\n    \n    epsilons = normals[:T]\n    etas = normals[T:]\n\n    # Generate time series x_t and y_t\n    x = np.zeros(T, dtype=np.float64)\n    y = np.zeros(T, dtype=np.float64)\n    \n    # x_0 = 0 is default\n    for t in range(1, T):\n        x[t] = x[t-1] + sigma_e * epsilons[t]\n\n    for t in range(T):\n        beta_t = beta_1 if t = T_b else beta_2\n        y[t] = alpha + beta_t * x[t] + sigma_u * etas[t]\n\n    # --- 2. Break Detection ---\n    \n    # Array to store indicators of threshold exceedance\n    z_indicators = np.zeros(T, dtype=int)\n    \n    # Initialize running sums for recursive OLS\n    s_x, s_y, s_x2, s_y2, s_xy = 0.0, 0.0, 0.0, 0.0, 0.0\n    \n    # Pre-computation for the initial window up to T_min\n    for t in range(T_min):\n        s_x += x[t]\n        s_y += y[t]\n        s_x2 += x[t]**2\n        s_y2 += y[t]**2\n        s_xy += x[t] * y[t]\n\n    # Recursive estimation and forecast error calculation\n    for t in range(T_min, T - 1):\n        # Update sums with the value at time t\n        s_x += x[t]\n        s_y += y[t]\n        s_x2 += x[t]**2\n        s_y2 += y[t]**2\n        s_xy += x[t] * y[t]\n        \n        n_t = t + 1\n        \n        # Calculate OLS estimates\n        x_bar = s_x / n_t\n        y_bar = s_y / n_t\n        \n        s_xx = s_x2 - n_t * x_bar**2\n        s_yy = s_y2 - n_t * y_bar**2\n        s_xy_t = s_xy - n_t * x_bar * y_bar\n        \n        # Avoid division by zero, though unlikely with a random walk\n        if s_xx == 0:\n            continue\n            \n        beta_hat = s_xy_t / s_xx\n        alpha_hat = y_bar - beta_hat * x_bar\n        \n        # Calculate residual standard deviation\n        ssr = s_yy - beta_hat * s_xy_t\n        # Ensure non-negativity due to potential floating point inaccuracies\n        ssr = max(0, ssr)\n        \n        df = n_t - 2\n        if df = 0:\n            continue\n            \n        sigma_hat_sq = ssr / df\n        \n        if sigma_hat_sq = 0:\n            continue \n        \n        sigma_hat = np.sqrt(sigma_hat_sq)\n        \n        # Calculate standardized one-step-ahead forecast error for time t+1\n        forecast_error = y[t+1] - (alpha_hat + beta_hat * x[t+1])\n        z_t_plus_1 = forecast_error / sigma_hat if sigma_hat > 0 else np.inf\n        \n        if np.abs(z_t_plus_1) >= c:\n            z_indicators[t + 1] = 1\n\n    # --- 3. Search for Break Index ---\n    \n    # Search for the first run of L consecutive indicators\n    # The search range for the start of the run (s_star)\n    # is from T_min+1 to T-L (inclusive).\n    for s_star in range(T_min + 1, T - L + 1):\n        # Check for a run of length L\n        if np.all(z_indicators[s_star : s_star + L] == 1):\n            return s_star\n\n    return -1\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}