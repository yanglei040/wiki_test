{
    "hands_on_practices": [
        {
            "introduction": "本实践练习为我们对协整的实证探索奠定了基础。我们将从零开始实现经典的 Engle-Granger 两步检验法，让您亲手实践如何从统计上识别非平稳时间序列之间的长期均衡关系。通过模拟协整与非协整两种情景下的数据，您将学会如何区分真实的长期关系和伪相关，这是时间序列计量经济学中的一项基本技能 。",
            "id": "2380057",
            "problem": "给定一个纯粹以数学术语表述的决策问题，该问题关于两个随机过程之间的长期均衡关系。这两个随机过程分别代表一家公司的季度研发支出及其后滞后一季度的季度收入。对于所提供的测试套件中的每一组参数，根据以下定义构建两个序列 $\\{x_t\\}_{t=0}^{T}$ 和 $\\{y_t\\}_{t=1}^{T}$。\n\n1. 数据生成部分和符号表示。\n   - 令 $T \\in \\mathbb{N}$ 表示以季度为单位的样本量。\n   - 令 $x_0 = 0$。对于 $t \\in \\{1,2,\\dots,T\\}$，令\n     $$x_t = x_{t-1} + \\varepsilon_t,$$\n     其中 $\\{\\varepsilon_t\\}_{t=1}^{T}$ 是均值为 $0$、方差为 $\\sigma_{\\varepsilon}^2$ 的独立同分布高斯随机变量。\n   - 将收入关系中使用的滞后输入定义为 $\\{x_{t-1}\\}_{t=1}^{T}$。\n   - 收入关系中的扰动项允许有两种备选设定，由类型指示符 $\\text{residual\\_type} \\in \\{\\text{stationary}, \\text{random\\_walk}\\}$ 参数化：\n     - 如果 $\\text{residual\\_type} = \\text{stationary}$，定义 $v_0 = 0$，且对于 $t \\in \\{1,2,\\dots,T\\}$，\n       $$v_t = \\phi\\, v_{t-1} + \\eta_t,$$\n       其中 $|\\phi| < 1$，且 $\\{\\eta_t\\}_{t=1}^{T}$ 是均值为 $0$、方差为 $\\sigma_{\\eta}^2$ 的独立同分布高斯随机变量。在这种情况下，设\n       $$y_t = c + \\beta\\, x_{t-1} + v_t.$$\n     - 如果 $\\text{residual\\_type} = \\text{random\\_walk}$，定义 $s_0 = 0$，且对于 $t \\in \\{1,2,\\dots,T\\}$，\n       $$s_t = s_{t-1} + \\eta_t,$$\n       其中 $\\{\\eta_t\\}_{t=1}^{T}$ 是均值为 $0$、方差为 $\\sigma_{\\eta}^2$ 的独立同分布高斯随机变量。在这种情况下，设\n       $$y_t = c + \\beta\\, x_{t-1} + s_t.$$\n\n2. 应用于每个参数集的决策规则。\n   - 考虑静态长期关系\n     $$y_t = \\alpha + \\beta^{\\ast} x_{t-1} + u_t,$$\n     并将 $\\{\\hat{u}_t\\}_{t=1}^{T}$ 定义为将 $\\{y_t\\}_{t=1}^{T}$ 对一个常数项和 $\\{x_{t-1}\\}_{t=1}^{T}$ 进行普通最小二乘 (OLS) 回归得到的残差。\n   - 计算不含确定性项且带有一阶差分的一期滞后的增广迪基-富勒 (ADF) 回归：\n     $$\\Delta \\hat{u}_t = \\varphi\\, \\hat{u}_{t-1} + \\gamma\\, \\Delta \\hat{u}_{t-1} + \\varepsilon_t^{\\ast}, \\quad t = 3,4,\\dots,T.$$\n     令 $\\tau$ 表示从该回归中计算出的、用于检验原假设 $H_0: \\varphi = 0$ 相对于单侧备择假设 $H_1: \\varphi < 0$ 的 $t$-统计量。\n   - 对于协整回归中包含截距项而 ADF 回归中不含确定性项的模型，使用显著性水平 $\\alpha = 0.05$ 以及 Engle-Granger 基于残差的临界值 $c_{0.05} = -3.34$。当且仅当 $\\tau \\le c_{0.05}$ 时，判定 $\\{y_t\\}$ 和 $\\{x_{t-1}\\}$ 是协整的。\n\n3. 测试套件。对每个参数集 $\\theta$，使用给定的参数和在指定种子上初始化的独立伪随机数生成器，根据上述定义生成序列。这些参数是：\n   - 案例 A: $\\left(T, \\text{seed}, c, \\beta, \\sigma_{\\varepsilon}, \\sigma_{\\eta}, \\phi, \\text{residual\\_type}\\right) = \\left(400, 101, 0.5, 1.3, 1.0, 0.3, 0.4, \\text{stationary}\\right)$。\n   - 案例 B: $\\left(T, \\text{seed}, c, \\beta, \\sigma_{\\varepsilon}, \\sigma_{\\eta}, \\phi, \\text{residual\\_type}\\right) = \\left(400, 202, 0.5, 1.3, 1.0, 0.8, 0.0, \\text{random\\_walk}\\right)$。\n   - 案例 C: $\\left(T, \\text{seed}, c, \\beta, \\sigma_{\\varepsilon}, \\sigma_{\\eta}, \\phi, \\text{residual\\_type}\\right) = \\left(400, 303, -0.2, -0.8, 0.8, 0.5, 0.7, \\text{stationary}\\right)$。\n\n4. 要求的最终输出格式。你的程序应生成单行输出，其中包含一个用方括号括起来的、逗号分隔的布尔值列表，其顺序与上述测试案例的顺序一致。如果根据第 2 项中的规则判定为协整，则对应的布尔值为 $\\text{True}$，否则为 $\\text{False}$。例如，一个包含三个案例的输出应如下所示\n$$[\\text{True},\\text{False},\\text{True}].$$",
            "solution": "该问题陈述提出了一个在时间序列计量经济学中有效且定义明确的计算练习。它要求实现 Engle-Granger 两步法，以检验两个模拟时间序列之间是否存在协整关系。该问题具有科学依据，形式上明确，并且为每个测试案例提供了获得唯一解所需的所有参数和步骤。我们将开始进行求解。\n\n问题的核心是确定两个随机过程 $\\{x_t\\}$ 和 $\\{y_t\\}$ 之间是否存在称为协整的长期均衡关系。解决这个问题的方法是，根据指定的数据生成过程 (DGP) 生成序列，然后应用统计假设检验。对测试套件中提供的每个参数集都执行这整个过程。\n\n**第1步：数据生成**\n\n对于每个测试案例，我们首先模拟时间序列数据。为保证可复现性，使用一个特定的种子来初始化伪随机数生成器。\n令 $T$ 为样本量。我们生成两组独立同分布 (i.i.d.) 的高斯随机冲击：$\\{\\varepsilon_t\\}_{t=1}^{T} \\sim N(0, \\sigma_{\\varepsilon}^2)$ 和 $\\{\\eta_t\\}_{t=1}^{T} \\sim N(0, \\sigma_{\\eta}^2)$。\n\n第一个序列 $\\{x_t\\}_{t=0}^{T}$ 代表研发支出，被构建为一个纯随机游走：\n$$x_t = x_{t-1} + \\varepsilon_t, \\quad \\text{for } t=1, \\dots, T$$\n初始条件为 $x_0 = 0$。像 $\\{x_t\\}$ 这样的过程是非平稳的，被称为一阶单整，记为 $I(1)$，因为它的一阶差分 $\\Delta x_t = \\varepsilon_t$ 是平稳的。\n\n第二个序列 $\\{y_t\\}_{t=1}^{T}$ 代表收入，是基于与滞后支出 $\\{x_{t-1}\\}_{t=1}^{T}$ 的关系以及一个性质取决于 `residual_type` 参数的误差项构建的。\n\n- **情况 1：`residual_type` = `stationary`**。误差项 $\\{v_t\\}_{t=1}^{T}$ 服从一个平稳的一阶自回归 (AR(1)) 过程：\n$$v_t = \\phi v_{t-1} + \\eta_t, \\quad \\text{for } t=1, \\dots, T$$\n其中 $v_0 = 0$ 且自回归参数 $|\\phi| < 1$。则收入序列为：\n$$y_t = c + \\beta x_{t-1} + v_t$$\n在这种情况下，线性组合 $y_t - \\beta x_{t-1} - c = v_t$ 是平稳的。根据定义，如果两个 $I(1)$ 变量的线性组合是平稳的，那么这两个变量是协整的。因此，我们预期检验会发现协整关系。\n\n- **情况 2：`residual_type` = `random_walk`**。误差项 $\\{s_t\\}_{t=1}^{T}$ 本身是一个随机游走：\n$$s_t = s_{t-1} + \\eta_t, \\quad \\text{for } t=1, \\dots, T$$\n其中 $s_0 = 0$。收入序列为：\n$$y_t = c + \\beta x_{t-1} + s_t$$\n此处，线性组合 $y_t - \\beta x_{t-1} - c = s_t$ 是一个随机游走，因此是非平稳的 ($I(1)$)。这两个变量不是协整的。这是一个伪回归的典型案例，尽管没有有意义的长期关系，但仍可能观察到高度的相关性。\n\n**第2步：Engle-Granger 协整检验**\n\n该检验分两个阶段进行。\n\n**阶段 1：估计长期关系**\n我们使用普通最小二乘法 (OLS) 估计假设的长期协整关系的参数：\n$$y_t = \\alpha + \\beta^{\\ast} x_{t-1} + u_t, \\quad \\text{for } t=1, \\dots, T$$\n我们将向量 $Y = (y_1, \\dots, y_T)^T$ 对一个维度为 $T \\times 2$ 的设计矩阵 $X_{ols}$ 进行回归，其中第一列是全为 1 的向量，第二列是向量 $(x_0, \\dots, x_{T-1})^T$。OLS 系数估计值由 $\\hat{\\theta} = (\\hat{\\alpha}, \\hat{\\beta}^{\\ast})^T = (X_{ols}^T X_{ols})^{-1} X_{ols}^T Y$ 给出。\n\n然后计算此回归的残差：\n$$\\hat{u}_t = y_t - (\\hat{\\alpha} + \\hat{\\beta}^{\\ast} x_{t-1}), \\quad \\text{for } t=1, \\dots, T$$\n如果 $y_t$ 和 $x_{t-1}$ 是协整的，这些残差应该是平稳的，即 $I(0)$。如果它们不是协整的，残差将是非平稳的，即 $I(1)$。\n\n**阶段 2：检验残差的单位根**\n为了检验残差 $\\{\\hat{u}_t\\}$ 的平稳性，我们执行增广迪基-富勒 (ADF) 检验。原假设是残差存在单位根（即非平稳），这意味着不存在协整关系。备择假设是平稳性，这意味着存在协整关系。\n\n需要估计的具体 ADF 回归模型是：\n$$\\Delta \\hat{u}_t = \\varphi \\hat{u}_{t-1} + \\gamma \\Delta \\hat{u}_{t-1} + \\varepsilon_t^{\\ast}, \\quad \\text{for } t=3, \\dots, T$$\n这是一个将残差的变化量 $\\Delta \\hat{u}_t$ 对残差的滞后水平 $\\hat{u}_{t-1}$ 和滞后的变化量 $\\Delta \\hat{u}_{t-1}$ 进行的 OLS 回归。该回归在 $T-2$ 个观测值上运行。\n\n令 $Z$ 为因变量的 $(T-2) \\times 1$ 维向量，即 $(\\Delta \\hat{u}_3, \\dots, \\Delta \\hat{u}_T)^T$。令 $W$ 为自变量的 $(T-2) \\times 2$ 维矩阵，其行向量为 $(\\hat{u}_{t-1}, \\Delta \\hat{u}_{t-1})$，其中 $t=3, \\dots, T$。$(\\varphi, \\gamma)$ 的 OLS 估计值为 $\\hat{\\psi} = (\\hat{\\varphi}, \\hat{\\gamma})^T = (W^T W)^{-1} W^T Z$。\n\n检验统计量是系数 $\\varphi$ 的 t-统计量：\n$$\\tau = \\frac{\\hat{\\varphi}}{SE(\\hat{\\varphi})}$$\n其中 $SE(\\hat{\\varphi})$ 是估计值 $\\hat{\\varphi}$ 的标准误。它被计算为系数协方差矩阵 $\\hat{\\sigma}_{\\varepsilon^{\\ast}}^2 (W^T W)^{-1}$ 的第一个对角元素的平方根。回归误差项 $\\varepsilon_t^{\\ast}$ 的方差估计为：\n$$\\hat{\\sigma}_{\\varepsilon^{\\ast}}^2 = \\frac{1}{T-2-2} \\sum_{t=3}^T (\\varepsilon_t^{\\ast})^2 = \\frac{SSR}{T-4}$$\n其中 $SSR$ 是 ADF 回归的残差平方和。\n\n**第3步：决策规则**\n\n原假设 $H_0: \\varphi = 0$（残差中存在单位根，无协整）与单侧备择假设 $H_1: \\varphi < 0$（平稳性，协整）进行检验。\n\n计算出的 t-统计量 $\\tau$ 与一个特定的临界值进行比较。因为该检验是基于对 $I(1)$ 变量回归得到的残差进行的，所以 $\\tau$ 的分布是非标准的，被称为 Engle-Granger 分布。问题给出了显著性水平 $\\alpha = 0.05$ 所对应的临界值，即 $c_{0.05} = -3.34$。\n\n决策规则是：\n- 如果 $\\tau \\le -3.34$，则拒绝 $H_0$。我们断定序列是协整的。该测试案例的结果为 `True`。\n- 如果 $\\tau > -3.34$，则不拒绝 $H_0$。我们断定没有协整的证据。该测试案例的结果为 `False`。\n\n将此完整过程应用于三个测试案例中的每一个，以确定最终的布尔值输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Engle-Granger two-step cointegration test for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # (T, seed, c, beta, sigma_eps, sigma_eta, phi, residual_type)\n        (400, 101, 0.5, 1.3, 1.0, 0.3, 0.4, \"stationary\"),\n        (400, 202, 0.5, 1.3, 1.0, 0.8, 0.0, \"random_walk\"),\n        (400, 303, -0.2, -0.8, 0.8, 0.5, 0.7, \"stationary\"),\n    ]\n\n    results = []\n    critical_value = -3.34\n\n    for case in test_cases:\n        T, seed, c, beta, sigma_eps, sigma_eta, phi, residual_type = case\n\n        # Step 1: Data Generation\n        rng = np.random.default_rng(seed)\n        eps = rng.normal(loc=0.0, scale=sigma_eps, size=T)\n        eta = rng.normal(loc=0.0, scale=sigma_eta, size=T)\n\n        # Generate x_t as a random walk\n        x = np.zeros(T + 1)\n        for t in range(1, T + 1):\n            x[t] = x[t - 1] + eps[t - 1]\n\n        # Generate y_t based on the residual type\n        # In the main vector y, y[t-1] corresponds to the mathematical y_t\n        if residual_type == \"stationary\":\n            v = np.zeros(T + 1)\n            for t in range(1, T + 1):\n                v[t] = phi * v[t-1] + eta[t-1]\n            error_term = v[1:T+1]\n        elif residual_type == \"random_walk\":\n            s = np.zeros(T + 1)\n            for t in range(1, T + 1):\n                s[t] = s[t-1] + eta[t-1]\n            error_term = s[1:T+1]\n        \n        y = c + beta * x[0:T] + error_term\n\n        # Step 2: Engle-Granger Stage 1 - OLS regression to get residuals\n        # Regress y_t on a constant and x_{t-1}\n        X_ols1 = np.vstack((np.ones(T), x[0:T])).T\n        \n        # Using lstsq is numerically more stable than direct matrix inversion\n        coeffs_ols1, _, _, _ = np.linalg.lstsq(X_ols1, y, rcond=None)\n        u_hat = y - X_ols1 @ coeffs_ols1\n\n        # Step 3: Engle-Granger Stage 2 - ADF test on residuals\n        # ADF model: Delta(u_hat)_t = phi*u_hat_{t-1} + gamma*Delta(u_hat)_{t-1} + e_t\n        # for t = 3, ..., T. This gives T-2 observations.\n        delta_u_hat = u_hat[1:] - u_hat[:-1]  # Corresponds to Delta(u_hat)_2, ..., Delta(u_hat)_T\n\n        # Dependent variable: Delta(u_hat)_t for t=3,...,T\n        Y_adf = delta_u_hat[1:]  # Corresponds to Delta(u_hat)_3, ..., Delta(u_hat)_T\n\n        # Independent variables\n        # u_hat_{t-1} for t=3,...,T\n        X_adf_col1 = u_hat[1:-1]\n        # Delta(u_hat)_{t-1} for t=3,...,T\n        X_adf_col2 = delta_u_hat[:-1]\n        \n        X_adf = np.vstack((X_adf_col1, X_adf_col2)).T\n\n        # Perform OLS for the ADF regression\n        coeffs_adf, ssr_adf, _, _ = np.linalg.lstsq(X_adf, Y_adf, rcond=None)\n        phi_hat = coeffs_adf[0]\n\n        # Calculate the t-statistic for phi_hat\n        n_obs_adf = T - 2\n        k_params_adf = 2\n        df = n_obs_adf - k_params_adf\n\n        # Estimate of the regression error variance\n        sigma2_hat_adf = ssr_adf[0] / df\n\n        # Variance-covariance matrix of the ADF coefficients\n        try:\n            cov_matrix = sigma2_hat_adf * np.linalg.inv(X_adf.T @ X_adf)\n            se_phi_hat = np.sqrt(cov_matrix[0, 0])\n            tau_statistic = phi_hat / se_phi_hat\n        except np.linalg.LinAlgError:\n            # Handle cases of singular matrix, which is unlikely but possible\n            # A very large t-stat would not reject the null, which is a safe default\n            tau_statistic = 0.0\n\n        # Step 4: Decision\n        is_cointegrated = tau_statistic <= critical_value\n        results.append(is_cointegrated)\n        \n    # Format and print the final output\n    print(f\"[{','.join(str(r) for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了基础知识之后，本练习将我们的检验程序提升到更稳健、更接近研究级别的标准。标准的协整检验通常依赖于预先制定的渐近临界值，但这在有限样本中可能并不准确。在这里，您将实现一种参数化自举法（parametric bootstrap）来生成针对特定数据集的自定义临界值，同时还将使用贝叶斯信息准则（Bayesian Information Criterion, BIC）来自动选择检验回归的最佳滞后阶数，从而提高结论的可靠性 。",
            "id": "2380094",
            "problem": "给定一个程式化任务，其背景源于动态随机存取存储器 (DRAM) 供应链和股票市场的定价问题。设 $x_t$ 为代表人造 DRAM 现货价格对数的序列，设 $y_t$ 为代表人造 DRAM 制造商股价对数的序列。在不同的数据生成过程下，$x_t$ 和 $y_t$ 都将生成为一阶单整序列，记为 $I(1)$。您的任务是，从基本原理出发，实现一个基于残差的 Engle–Granger 协整检验。该检验对估计的协整残差使用增广 Dickey–Fuller (ADF) 检验，其决策阈值通过在无协整原假设下的参数自助法获得。\n\n从以下基本定义和事实开始：\n- 如果 $\\Delta z_t = z_t - z_{t-1}$ 是协方差平稳的，而 $z_t$ 本身不是平稳的，则时间序列 $\\{z_t\\}$ 是一阶单整的，记为 $I(1)$。\n- 如果存在一个向量 $(1,-\\beta)$ 和一个常数 $\\alpha$，使得残差 $u_t = y_t - \\alpha - \\beta x_t$ 是协方差平稳的，则两个 $I(1)$ 序列 $\\{x_t\\}$ 和 $\\{y_t\\}$ 是协整的。根据 Granger 表示定理，如果 $\\{x_t,y_t\\}$ 是协整的，那么它们的短期动态允许一个误差修正模型 (ECM)，其中 $\\Delta y_t$ 包含滞后残差 $u_{t-1}$ 作为一个系数非零的误差修正项。\n- Engle–Granger 过程通过普通最小二乘法估计 $\\alpha$ 和 $\\beta$，然后对残差 $u_t$ 应用增广 Dickey–Fuller (ADF) 检验，以检验 $u_t$ 中存在单位根的原假设，其备择假设为平稳性。对于给定的滞后阶数 $k \\in \\{0,1,2,\\dots\\}$，ADF 回归为：\n$$\n\\Delta u_t = \\phi\\, u_{t-1} + \\sum_{j=1}^{k} \\gamma_j\\, \\Delta u_{t-j} + \\varepsilon_t,\n$$\n该回归不含截距项或趋势项，其中 $\\Delta u_t = u_t - u_{t-1}$，检验统计量（$\\tau$-统计量）是 $\\phi$ 的 $t$-统计量。\n\n您必须在不使用任何专门的时间序列库的情况下实现以下组件：\n1. 根据下面测试套件中指定的数据生成过程，模拟序列 $\\{x_t\\}$ 和 $\\{y_t\\}$。\n2. 通过普通最小二乘法 (OLS) 估计协整回归 $y_t = \\alpha + \\beta x_t + u_t$ 并构建残差 $\\{\\hat{u}_t\\}$。\n3. 通过在候选集 $k \\in \\{0,1,\\dots,k_{\\max}\\}$上最小化贝叶斯信息准则 (BIC) 来选择 ADF 滞后阶数 $k$，其中\n$$\nk_{\\max} = \\left\\lfloor 12 \\cdot \\left(\\frac{T}{100}\\right)^{1/4} \\right\\rfloor,\n$$\n$T$ 是样本量，ADF 回归包含 $u_{t-1}$ 和 $j=1,\\dots,k$ 的 $\\Delta u_{t-j}$，但不含常数项，对于一个残差平方和为 $\\mathrm{RSS}$、样本量为 $n$、回归量个数为 $m$ 的 OLS 回归，其 BIC 为\n$$\n\\mathrm{BIC} = \\ln\\!\\left(\\frac{\\mathrm{RSS}}{n}\\right) + \\frac{m \\ln(n)}{n}.\n$$\n4. 在选定的模型中计算 $\\phi$ 的 ADF $\\tau$-统计量。\n5. 在无协整的原假设下，使用参数自助法获得经验临界值。在原假设下，生成自助法序列 $\\{y_t^{\\ast}\\}$，它是一个与观测到的 $\\{x_t\\}$ 无关的 $I(1)$ 随机游走：\n$$\ny_0^{\\ast} = y_0,\\quad y_t^{\\ast} = y_{t-1}^{\\ast} + \\eta_t^{\\ast},\\quad \\eta_t^{\\ast} \\sim \\mathcal{N}(0,\\hat{\\sigma}_{\\Delta y}^2),\n$$\n其中 $\\hat{\\sigma}_{\\Delta y}^2$ 是 $\\Delta y_t$ 的样本方差。对于每次自助法复制，对 $(x_t, y_t^{\\ast})$ 精确地按照步骤 2-4 运行 Engle–Granger 过程，收集自助法 $\\tau$-统计量，并取左尾经验 $\\alpha$-分位数作为临界值。使用 $\\alpha = 0.05$。\n6. 决策规则：如果观测到的 $\\tau$-统计量小于或等于自助法临界值，则拒绝无协整的原假设。为每个测试用例输出一个布尔值，表示在 $\\alpha = 0.05$ 的水平下是否检测到协整。\n\n测试套件的数据生成过程：\n- 情况 $\\mathrm{A}$（协整，稳定的误差修正）：设 $T=240$，$\\beta=1.5$，$\\rho=0.6$，$\\sigma_e=1.0$，$\\sigma_v=0.5$。独立地生成新息 $e_t \\sim \\mathcal{N}(0,\\sigma_e^2)$ 和 $v_t \\sim \\mathcal{N}(0,\\sigma_v^2)$。构建 $x_0=0$，$z_0=0$，并且对于 $t=1,\\dots,T$：\n$$\nx_t = x_{t-1} + e_t,\\quad z_t = \\rho z_{t-1} + v_t,\\quad y_t = \\alpha + \\beta x_t + z_t,\\quad \\alpha = 0.\n$$\n- 情况 $\\mathrm{B}$（非协整，独立的随机趋势）：设 $T=240$，$\\sigma_e=1.0$，$\\sigma_w=1.0$。独立地生成 $e_t \\sim \\mathcal{N}(0,\\sigma_e^2)$ 和 $w_t \\sim \\mathcal{N}(0,\\sigma_w^2)$。构建 $x_0=0$，$y_0=0$，并且对于 $t=1,\\dots,T$：\n$$\nx_t = x_{t-1} + e_t,\\quad y_t = y_{t-1} + w_t.\n$$\n- 情况 $\\mathrm{C}$（协整，近边界的误差修正）：设 $T=120$，$\\beta=1.2$，$\\rho=0.95$，$\\sigma_e=1.0$，$\\sigma_v=0.5$。独立地生成新息 $e_t \\sim \\mathcal{N}(0,\\sigma_e^2)$ 和 $v_t \\sim \\mathcal{N}(0,\\sigma_v^2)$。构建 $x_0=0$，$z_0=0$，并且对于 $t=1,\\dots,T$：\n$$\nx_t = x_{t-1} + e_t,\\quad z_t = \\rho z_{t-1} + v_t,\\quad y_t = \\alpha + \\beta x_t + z_t,\\quad \\alpha = 0.\n$$\n\n实现细节和固定设置：\n- 为保证可复现性，每个情况使用此处指定的相同数值种子：情况 $\\mathrm{A}$ 种子 $=12345$，情况 $\\mathrm{B}$ 种子 $=23456$，情况 $\\mathrm{C}$ 种子 $=34567$。\n- 对于自助法，每个情况使用 $R=400$ 次复制，并使用与该情况相同的种子来初始化自助法随机数生成器。使用一个高斯生成器，其方差根据该情况下 $\\Delta y_t$ 的样本方差进行校准。\n- 对每个情况分别使用 $k_{\\max} = \\left\\lfloor 12 \\cdot \\left(\\frac{T}{100}\\right)^{1/4} \\right\\rfloor$，并如上文所述通过 BIC 选择 $k$。\n- 所有回归必须使用线性代数通过普通最小二乘法计算；不要调用任何预打包的单位根或协整程序。\n\n最终输出规范：\n- 您的程序必须为三种情况 $(\\mathrm{A},\\mathrm{B},\\mathrm{C})$ 中的每一种计算一个布尔值，该值表示是否在使用所描述的方法计算出的自助法临界值、在 $\\alpha=0.05$ 的水平下检测到协整。\n- 您的程序应生成单行输出，其中包含按 $[\\mathrm{A},\\mathrm{B},\\mathrm{C}]$ 顺序排列、用方括号括起来的逗号分隔列表形式的结果。例如，一个有效的输出格式是 $[\\mathrm{True},\\mathrm{False},\\mathrm{True}]$。不应打印任何额外文本。",
            "solution": "所述问题是有效的。它在科学上基于已建立的计量经济学理论，特别是用于协整检验的 Engle–Granger 两步法。该问题定义明确，提供了所有必要的参数、数据生成过程和算法规范，以得出一个唯一的、可验证的解。术语精确，目标客观且可形式化。我现在将着手解决该问题。\n\n任务是实现一个基于残差的 Engle–Granger 协整检验，其中检验统计量的临界值通过参数自助法确定。此过程必须应用于三个不同的数据生成过程 (DGP)。整个实现必须从基本原理出发，仅利用基本的线性代数运算。\n\n每个测试用例的总体流程如下：\n1.  根据指定的 DGP 生成时间序列 $\\{x_t\\}_{t=0}^T$ 和 $\\{y_t\\}_{t=0}^T$。\n2.  使用 Engle–Granger 方法从观测数据 $(x_t, y_t)$ 计算检验统计量 $\\tau_{obs}$。\n3.  使用参数自助法，在无协整的原假设下，生成检验统计量的经验分布。\n4.  在显著性水平 $\\alpha=0.05$ 下，从此经验分布中确定临界值 $c_\\alpha$。\n5.  比较 $\\tau_{obs}$ 和 $c_\\alpha$，以决定是否拒绝原假设。\n\n让我们详细说明这些步骤。\n\n**步骤 1：数据生成过程**\n\n我们必须为三种情况生成样本数据。所有序列的长度均为 $T+1$。\n\n- **情况 A (协整):** 参数为 $T=240$，$\\beta=1.5$，$\\rho=0.6$，$\\sigma_e=1.0$，$\\sigma_v=0.5$ 和 $\\alpha=0$。新息 $e_t \\sim \\mathcal{N}(0, \\sigma_e^2)$ 和 $v_t \\sim \\mathcal{N}(0, \\sigma_v^2)$ 是独立的。序列构建如下：\n$$\nx_t = x_{t-1} + e_t, \\quad x_0=0\n$$\n$$\nz_t = \\rho z_{t-1} + v_t, \\quad z_0=0\n$$\n$$\ny_t = \\beta x_t + z_t\n$$\n此处，$x_t$ 是一个 $I(1)$ 过程（随机游走）。由于 $|\\rho|<1$，$z_t$ 项是一个平稳的 AR(1) 过程。线性组合 $y_t - \\beta x_t = z_t$ 是平稳的，因此根据定义，$x_t$ 和 $y_t$ 是协整的。\n\n- **情况 B (非协整):** 参数为 $T=240$，$\\sigma_e=1.0$ 和 $\\sigma_w=1.0$。新息 $e_t \\sim \\mathcal{N}(0, \\sigma_e^2)$ 和 $w_t \\sim \\mathcal{N}(0, \\sigma_w^2)$ 是独立的。序列构建为两个独立的随机游走：\n$$\nx_t = x_{t-1} + e_t, \\quad x_0=0\n$$\n$$\ny_t = y_{t-1} + w_t, \\quad y_0=0\n$$\n由于 $x_t$ 和 $y_t$ 由独立的随机趋势驱动，它们的任何线性组合都不可能平稳。它们不是协整的。\n\n- **情况 C (协整，近单位根):** 此情况在结构上与情况 A 相同，但参数为 $T=120$，$\\beta=1.2$ 和 $\\rho=0.95$。较高的 $\\rho$ 值使得平稳分量 $z_t$ 具有高持续性，这对单位根检验区分非平稳 $I(1)$ 过程提出了更大的挑战。\n\n**步骤 2：Engle–Granger 检验过程**\n\n此过程应用于一对序列 $(x_t, y_t)$，以产生单个检验统计量 $\\tau$。\n\n**2.1. 协整回归**\n首先，我们使用普通最小二乘法 (OLS) 对样本 $t=0, \\dots, T$ 估计长期关系 $y_t = \\alpha + \\beta x_t + u_t$。我们定义观测向量 $\\mathbf{y} = [y_0, \\dots, y_T]^T$ 和设计矩阵 $\\mathbf{X}$，该矩阵由一列 1 和一列 $x_t$ 值组成。\n$$\n\\mathbf{X} = \\begin{bmatrix} 1 & x_0 \\\\ 1 & x_1 \\\\ \\vdots & \\vdots \\\\ 1 & x_T \\end{bmatrix}\n$$\n系数向量 $\\mathbf{b} = [\\alpha, \\beta]^T$ 的 OLS 估计量由下式给出：\n$$\n\\hat{\\mathbf{b}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\n$$\n然后，残差计算为 $\\hat{u}_t = y_t - \\hat{\\alpha} - \\hat{\\beta} x_t$，其中 $t=0, \\dots, T$。\n\n**2.2. 对残差的增广 Dickey–Fuller (ADF) 检验**\n检验的核心是检查残差 $\\{\\hat{u}_t\\}$ 是否平稳。我们在 ADF 回归中检验原假设 $H_0: \\phi=0$ 与备择假设 $H_A: \\phi<0$：\n$$\n\\Delta \\hat{u}_t = \\phi \\hat{u}_{t-1} + \\sum_{j=1}^{k} \\gamma_j \\Delta \\hat{u}_{t-j} + \\varepsilon_t\n$$\n包含滞后差分项 $\\Delta \\hat{u}_{t-j}$ 是为了解释误差项 $\\varepsilon_t$ 中潜在的序列相关性。检验统计量是与系数 $\\hat{\\phi}$ 相关联的 $\\tau$-统计量（或 $t$-统计量）。\n\n**2.3. 滞后阶数选择**\n滞后数 $k$ 是一个关键参数。通过在一组候选值 $k \\in \\{0, 1, \\dots, k_{\\max}\\}$ 上最小化贝叶斯信息准则 (BIC) 来选择它。最大滞后阶数由下式给出：\n$$\nk_{\\max} = \\left\\lfloor 12 \\cdot \\left(\\frac{T}{100}\\right)^{1/4} \\right\\rfloor\n$$\n对于每个候选滞后 $k$，执行一次 OLS 回归。给定 $k$ 的回归在 $t=k+1, \\dots, T$ 上运行，得到样本量 $n = T-k$。估计的参数数量为 $m = k+1$（一个用于 $\\phi$，k 个用于 $\\gamma_j$ 系数）。然后按如下方式计算 BIC：\n$$\n\\text{BIC}(k) = \\ln\\left(\\frac{\\text{RSS}_k}{n}\\right) + \\frac{m \\ln(n)}{n}\n$$\n其中 $\\text{RSS}_k$ 是具有 $k$ 个滞后的 ADF 回归的残差平方和。最优滞后 $k^*$ 是产生最小 BIC 的那个。\n\n**2.4. ADF 检验统计量计算**\n使用最优滞后阶数 $k^*$，我们执行 ADF 回归。设 $\\mathbf{Y}_{\\text{ADF}}$ 为 $\\Delta \\hat{u}_t$ 的向量，$\\mathbf{X}_{\\text{ADF}}$ 为回归量 $(\\hat{u}_{t-1}, \\Delta \\hat{u}_{t-1}, \\dots, \\Delta \\hat{u}_{t-k^*})$ 的矩阵。OLS 系数向量为 $\\hat{\\boldsymbol{\\theta}} = (\\mathbf{X}_{\\text{ADF}}^T \\mathbf{X}_{\\text{ADF}})^{-1} \\mathbf{X}_{\\text{ADF}}^T \\mathbf{Y}_{\\text{ADF}}$，其中第一个元素是 $\\hat{\\phi}$。检验统计量是 $\\hat{\\phi}$ 的 $t$-比率：\n$$\n\\tau = \\frac{\\hat{\\phi}}{\\text{SE}(\\hat{\\phi})}\n$$\n标准误 $\\text{SE}(\\hat{\\phi})$ 是系数协方差矩阵 $\\hat{\\Sigma}_{\\hat{\\boldsymbol{\\theta}}}$ 第一个对角元素的平方根。该矩阵估计如下：\n$$\n\\hat{\\Sigma}_{\\hat{\\boldsymbol{\\theta}}} = \\hat{\\sigma}_\\varepsilon^2 (\\mathbf{X}_{\\text{ADF}}^T \\mathbf{X}_{\\text{ADF}})^{-1}, \\quad \\text{其中} \\quad \\hat{\\sigma}_\\varepsilon^2 = \\frac{\\text{RSS}_{k^*}}{n - m}\n$$\n得到的 $\\tau$ 是观测到的检验统计量，$\\tau_{obs}$。\n\n**步骤 3：用于临界值的参数自助法**\n\n标准的 Dickey-Fuller 临界值在这里不适用，因为 ADF 检验是在*估计的*残差上执行的，而不是在观测序列上。$\\tau$-统计量的分布取决于 $x_t$ 的属性和样本量。因此，我们在无协整的原假设下，使用参数自助法生成临界值。\n\n在 $H_0$ 下，$x_t$ 和 $y_t$ 是独立的 $I(1)$ 过程。步骤如下：\n1.  对于观测数据，计算 $y_t$ 序列的一阶差分 $\\Delta y_t = y_t - y_{t-1}$，并计算其样本方差 $\\hat{\\sigma}_{\\Delta y}^2$。\n2.  生成 $R=400$ 个自助样本。对于每次复制 $r=1, \\dots, R$：\n    a. 保持原始 $x_t$ 序列不变。\n    b. 生成一个新序列 $y_t^*$ 作为独立于 $x_t$ 的随机游走。新息 $\\eta_t^*$ 从一个用观测数据校准的正态分布中抽取：$\\eta_t^* \\sim \\mathcal{N}(0, \\hat{\\sigma}_{\\Delta y}^2)$。\n    $$\n    y_0^* = y_0, \\quad y_t^* = y_{t-1}^* + \\eta_t^* \\quad \\text{对于 } t=1, \\dots, T\n    $$\n    c. 对序列对 $(x_t, y_t^*)$ 应用完整的 Engle–Granger 检验过程（步骤 2.1 至 2.4），以获得一个自助检验统计量 $\\tau^*_r$。\n3.  收集所有 $R$ 个自助统计量 $\\{\\tau^*_1, \\dots, \\tau^*_R\\}$，以形成原假设下检验统计量的经验分布。\n4.  对于一个规模为 $\\alpha=0.05$ 的检验，临界值 $c_\\alpha$ 是这个排序后的经验分布的第 5 百分位数。对于 $R=400$，这对应于排序后的 $\\tau^*$ 统计量列表中的第 20 个值。\n\n**步骤 4：决策规则**\n\n无协整的原假设（对应于残差中存在单位根，$\\phi=0$）是针对平稳性的单边备择假设（$\\phi<0$）进行检验的。因此，我们使用左尾检验。\n- 如果 $\\tau_{obs} \\leq c_\\alpha$，我们拒绝原假设，并断定序列是协整的。\n- 如果 $\\tau_{obs} > c_\\alpha$，我们未能拒绝原假设，并断定没有协整的证据。\n\n需要实现这一完整方法，并将其应用于三种情况中的每一种，以确定最终的布尔结果。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the cointegration test for all cases.\n    \"\"\"\n\n    def perform_ols(y, X):\n        \"\"\"\n        Performs Ordinary Least Squares (OLS) regression.\n        \n        Args:\n            y (np.ndarray): Dependent variable vector.\n            X (np.ndarray): Matrix of independent variables (regressors).\n\n        Returns:\n            tuple: A tuple containing:\n                - beta_hat (np.ndarray): Estimated coefficients.\n                - residuals (np.ndarray): Regression residuals.\n                - rss (float): Residual sum of squares.\n                - cov_beta (np.ndarray): Covariance matrix of the coefficients.\n        \"\"\"\n        try:\n            # Using np.linalg.solve is more stable than inv()\n            XtX = X.T @ X\n            XtY = X.T @ y\n            beta_hat = np.linalg.solve(XtX, XtY)\n            residuals = y - X @ beta_hat\n            rss = residuals.T @ residuals\n            n, m = X.shape\n            # Degrees of freedom for variance estimation should be n - m\n            # If n <= m, regression is not identified, return NaN to signal failure\n            if n <= m:\n                return beta_hat, residuals, rss, np.full((m, m), np.nan)\n            \n            # Unbiased estimator for error variance\n            sigma2_hat = rss / (n - m)\n            # Covariance matrix of estimators\n            cov_beta = sigma2_hat * np.linalg.inv(XtX)\n            return beta_hat, residuals, rss, cov_beta\n        except np.linalg.LinAlgError:\n            # In case of singular matrix, return NaNs\n            m = X.shape[1]\n            return np.full(m, np.nan), np.full_like(y, np.nan), np.nan, np.full((m, m), np.nan)\n\n    def engle_granger_test_stat(x_series, y_series):\n        \"\"\"\n        Computes the Engle-Granger ADF test statistic for a given pair of series.\n        \n        Args:\n            x_series (np.ndarray): The x time series.\n            y_series (np.ndarray): The y time series.\n\n        Returns:\n            float: The calculated ADF tau-statistic.\n        \"\"\"\n        T_full = len(x_series) - 1\n        \n        # Step 2: OLS Cointegration Regression\n        X_coint = np.c_[np.ones(T_full + 1), x_series]\n        b_hat, u_hat, _, _ = perform_ols(y_series, X_coint)\n\n        if np.isnan(b_hat).any():\n             return np.nan\n\n        # Step 3: ADF Lag Selection\n        k_max = int(12 * ((T_full / 100) ** 0.25))\n        delta_u = np.diff(u_hat)\n        T_diff = len(delta_u) # This is T_full\n        \n        best_k = -1\n        min_bic = np.inf\n        \n        # Store results of best k regression to avoid re-computation\n        best_k_results = {}\n\n        for k in range(k_max + 1):\n            # Construct ADF regression matrices\n            # The regression runs from t=k+1 to T, so there are T-k observations.\n            # Python slicing makes this easier to manage.\n            y_adf = delta_u[k:]\n            \n            # Regressors\n            u_lag1 = u_hat[k:-1]\n            X_adf_cols = [u_lag1]\n            for j in range(1, k + 1):\n                lagged_delta_u = delta_u[k-j:-j]\n                X_adf_cols.append(lagged_delta_u)\n            \n            X_adf = np.stack(X_adf_cols, axis=1)\n\n            n, m = X_adf.shape # n = T-k, m = k+1\n            if n <= m:\n                continue\n\n            # OLS for ADF regression\n            beta_adf, _, rss_adf, cov_beta_adf = perform_ols(y_adf, X_adf)\n            \n            if np.isnan(rss_adf):\n                continue\n\n            bic = np.log(rss_adf / n) + (m * np.log(n)) / n\n            \n            if bic < min_bic:\n                min_bic = bic\n                best_k = k\n                best_k_results['beta'] = beta_adf\n                best_k_results['cov'] = cov_beta_adf\n        \n        if best_k == -1 or 'beta' not in best_k_results:\n            return np.nan\n\n        # Step 4: Compute ADF tau-statistic from the best model\n        phi_hat = best_k_results['beta'][0]\n        se_phi = np.sqrt(best_k_results['cov'][0, 0])\n        \n        if se_phi == 0 or np.isnan(se_phi):\n            return np.nan\n            \n        tau_statistic = phi_hat / se_phi\n        return tau_statistic\n\n    test_cases = [\n        {'name': 'A', 'T': 240, 'beta': 1.5, 'rho': 0.6, 'sigma_e': 1.0, 'sigma_v': 0.5, 'seed': 12345},\n        {'name': 'B', 'T': 240, 'sigma_e': 1.0, 'sigma_w': 1.0, 'seed': 23456},\n        {'name': 'C', 'T': 120, 'beta': 1.2, 'rho': 0.95, 'sigma_e': 1.0, 'sigma_v': 0.5, 'seed': 34567},\n    ]\n\n    R = 400\n    alpha = 0.05\n    results = []\n\n    for case in test_cases:\n        T = case['T']\n        seed = case['seed']\n        rng = np.random.default_rng(seed)\n\n        # Step 1: Generate Data\n        x = np.zeros(T + 1)\n        y = np.zeros(T + 1)\n\n        if case['name'] in ['A', 'C']:\n            e = rng.normal(0, case['sigma_e'], size=T)\n            v = rng.normal(0, case['sigma_v'], size=T)\n            z = np.zeros(T + 1)\n            x[1:] = np.cumsum(e)\n            for t in range(1, T + 1):\n                z[t] = case['rho'] * z[t-1] + v[t-1]\n            y = case['beta'] * x + z\n        else: # Case B\n            e = rng.normal(0, case['sigma_e'], size=T)\n            w = rng.normal(0, case['sigma_w'], size=T)\n            x[1:] = np.cumsum(e)\n            y[1:] = np.cumsum(w)\n        \n        # Compute observed test statistic\n        tau_observed = engle_granger_test_stat(x, y)\n        \n        # Step 5: Parametric Bootstrap\n        boot_rng = np.random.default_rng(seed)\n        delta_y = np.diff(y)\n        sigma_delta_y_sq = np.var(delta_y, ddof=1)\n        \n        tau_bootstrap = []\n        for _ in range(R):\n            eta_star = boot_rng.normal(0, np.sqrt(sigma_delta_y_sq), size=T)\n            y_star = np.zeros(T + 1)\n            # Initial y_0 is 0 for all cases\n            y_star[0] = 0.0 \n            y_star[1:] = np.cumsum(eta_star)\n            \n            tau_boot_stat = engle_granger_test_stat(x, y_star)\n            if not np.isnan(tau_boot_stat):\n                tau_bootstrap.append(tau_boot_stat)\n\n        tau_bootstrap.sort()\n        \n        # Get critical value from bootstrap distribution\n        num_valid_boots = len(tau_bootstrap)\n        if num_valid_boots == 0:\n            # If all bootstrap runs failed, cannot make a decision\n            # The problem setup should be robust enough to avoid this\n            results.append(False) \n            continue\n\n        cv_index = int(num_valid_boots * alpha)\n        # Ensure index is within bounds\n        cv_index = min(cv_index, num_valid_boots - 1)\n        critical_value = tau_bootstrap[cv_index]\n        \n        # Step 6: Decision Rule\n        is_cointegrated = tau_observed <= critical_value\n        results.append(is_cointegrated)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们最后的实践练习将探讨协整分析中的一个关键假设：长期关系的稳定性。在现实世界中，经济关系可能因政策变动、技术冲击或其他结构性变化而发生改变。本练习将指导您实现一个递归估计程序，以持续监控协整向量的稳定性，并利用标准化的一步向前预测误差来检测这种关系是否以及何时发生破裂。这是将协整分析应用于动态变化的真实世界数据时一项至关重要的技能 。",
            "id": "2380077",
            "problem": "给定两个合成时间序列，它们被构建为遵循一个可能在未知时间点经历结构性变化的长期关系。设 $\\{x_t\\}_{t=0}^{T-1}$ 和 $\\{y_t\\}_{t=0}^{T-1}$ 定义如下。对于所有 $t \\in \\{0,1,\\dots,T-1\\}$，设 $x_0 = 0$，且当 $t \\ge 1$ 时，\n$$\nx_t = x_{t-1} + \\sigma_e \\,\\varepsilon_t,\n$$\n并且\n$$\ny_t = \\alpha + \\beta(t)\\, x_t + \\sigma_u \\,\\eta_t,\n$$\n其中 $\\{\\varepsilon_t\\}$ 和 $\\{\\eta_t\\}$ 是独立同分布的标准正态随机变量的独立序列，而 $\\beta(t)$ 是一个分段常数函数\n$$\n\\beta(t) = \\begin{cases}\n\\beta_1, & t \\le T_b,\\\\\n\\beta_2, & t > T_b.\n\\end{cases}\n$$\n常数 $T_b$ 表示长期协整斜率从 $\\beta_1$ 变为 $\\beta_2$ 的（潜在）断点指数。如果不希望出现断点，则取 $T_b \\ge T$，使得对于所有 $t$，都有 $\\beta(t) = \\beta_1$。截距 $\\alpha$ 是恒定的。\n\n扰动项 $\\{\\varepsilon_t\\}$ 和 $\\{\\eta_t\\}$ 必须使用线性同余生成器从指定的均匀伪随机序列中确定性地生成，以确保可复现性。通过以下方式定义整数上的乘法线性同余序列 $\\{U_k\\}$\n$$\nU_{k} = (a \\cdot U_{k-1}) \\bmod m,\\quad k \\ge 1,\\quad U_0 = s,\n$$\n模数 $m = 2^{31}-1$，乘数 $a = 16807$，整数种子 $s \\in \\{1,2,\\dots,m-1\\}$。通过 $R_k = U_k/m$ 映射到 $(0,1)$ 上的均匀分布 $R_k$。使用 Box-Muller 变换将其转换为独立的标准正态新息：对于每对 $(R_{2j-1}, R_{2j})$，\n$$\nZ_{2j-1} = \\sqrt{-2\\ln R_{2j-1}}\\,\\cos(2\\pi R_{2j}),\\quad\nZ_{2j} = \\sqrt{-2\\ln R_{2j-1}}\\,\\sin(2\\pi R_{2j}),\n$$\n其中三角函数中的所有角度均以弧度为单位。使用前 $T$ 个正态抽样值作为 $\\{\\varepsilon_t\\}$，后 $T$ 个正态抽样值作为 $\\{\\eta_t\\}$。\n\n为了进行检测，定义一个关于协整关系 $y_s = \\alpha + \\beta x_s + \\text{error}$ 的普通最小二乘法 (Ordinary Least Squares, OLS) 估计量的递归序列，该序列在扩展样本上计算。对于每个 $t \\in \\{T_{\\min}, T_{\\min}+1, \\dots, T-2\\}$，通过最小化 $\\sum_{s=0}^{t} (y_s - \\alpha - \\beta x_s)^2$ 来估计 $(\\widehat{\\alpha}_t,\\widehat{\\beta}_t)$。等价地，设 $n_t = t+1$，样本均值为 $\\overline{x}_t = \\frac{1}{n_t}\\sum_{s=0}^{t} x_s$ 和 $\\overline{y}_t = \\frac{1}{n_t}\\sum_{s=0}^{t} y_s$，中心化和为 $S_{xx,t} = \\sum_{s=0}^{t} (x_s-\\overline{x}_t)^2$，$S_{xy,t} = \\sum_{s=0}^{t} (x_s-\\overline{x}_t)(y_s-\\overline{y}_t)$，则\n$$\n\\widehat{\\beta}_t = \\frac{S_{xy,t}}{S_{xx,t}},\\quad \\widehat{\\alpha}_t = \\overline{y}_t - \\widehat{\\beta}_t\\,\\overline{x}_t.\n$$\n设残差标准差为\n$$\n\\widehat{\\sigma}_t = \\sqrt{\\frac{1}{n_t - 2}\\sum_{s=0}^{t} \\left(y_s - \\widehat{\\alpha}_t - \\widehat{\\beta}_t x_s\\right)^2},\n$$\n定义于 $n_t \\ge 3$。构造在时间 $t+1$ 的单步向前标准化预测误差，\n$$\nz_{t+1} = \\frac{y_{t+1} - \\widehat{\\alpha}_t - \\widehat{\\beta}_t x_{t+1}}{\\widehat{\\sigma}_t}.\n$$\n给定阈值 $c > 0$ 和持续长度 $L \\in \\mathbb{N}$，为 $s \\in \\{T_{\\min}+1, \\dots, T-1\\}$ 定义指示变量 $I_s = \\mathbf{1}\\{|z_s| \\ge c\\}$。检测到的断点指数是满足 $I_{s^\\star} = I_{s^\\star+1} = \\dots = I_{s^\\star+L-1} = 1$ 的最小指数 $s^\\star$。如果不存在这样的指数，则返回 $-1$。报告检测到的指数 $s^\\star$（采用从零开始的时间索引）。\n\n请将上述数据构建和检测过程实现为一个完整的程序，用于处理以下参数集测试套件，每个参数集指定为一个元组\n$$\n(T, T_b, \\alpha, \\beta_1, \\beta_2, \\sigma_e, \\sigma_u, T_{\\min}, c, L, s).\n$$\n- 测试用例 A: $(240, 150, 0.5, 1.0, 1.6, 1.0, 0.05, 40, 3.0, 2, 12345)$。\n- 测试用例 B: $(240, 10^9, 0.5, 1.0, 1.0, 1.0, 0.05, 40, 3.0, 2, 54321)$。\n- 测试用例 C: $(220, 210, 0.3, 0.8, 1.9, 0.9, 0.05, 30, 2.5, 2, 20231107)$。\n- 测试用例 D: $(180, 60, 0.2, 1.2, 1.4, 0.8, 0.1, 25, 2.0, 3, 424242)$。\n\n对于每个测试用例，您的程序都应计算并返回一个整数：检测到的断点指数 $s^\\star$（采用从零开始的索引）或者在规则下未检测到断点时返回 $-1$。您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表（例如，“[rA,rB,rC,rD]”），其中 $rA$、$rB$、$rC$ 和 $rD$ 分别是对应于测试用例 A、B、C 和 D 的整数结果。",
            "solution": "该问题提出了一个在计算计量经济学领域中明确定义的任务：检测两个非平稳时间序列之间线性协整关系中的结构性断点。从数据生成到断点检测的整个过程都以算法形式指定，这使得解唯一且可验证。严谨的分析分两个阶段进行：首先，确定性地生成合成数据；其次，应用递归监测算法。\n\n本练习的基础是一个可复现的数据生成过程。为确保这一点，我们不使用系统级的随机源，而是使用指定的种子 $s$ 和乘法线性同余生成器 (LCG) 来构建所需的随机序列。整数序列 $\\{U_k\\}$ 由递归关系 $U_{k} = (a \\cdot U_{k-1}) \\bmod m$（对于 $k \\ge 1$）给出，其中 $U_0 = s$。问题指定了行业标准参数 $m = 2^{31}-1$ 和 $a = 16807$。这些整数通过变换 $R_k = U_k/m$ 映射到区间 $(0, 1)$ 上的一系列均匀伪随机数 $\\{R_k\\}$。\n\n我们必须从这个均匀序列中生成独立的标准正态随机变量。为此，指定了 Box-Muller 变换。对于每一对均匀变量 $(R_{2j-1}, R_{2j})$，我们生成一对独立的标准正态变量 $(Z_{2j-1}, Z_{2j})$：\n$$\nZ_{2j-1} = \\sqrt{-2\\ln R_{2j-1}}\\,\\cos(2\\pi R_{2j})\n$$\n$$\nZ_{2j} = \\sqrt{-2\\ln R_{2j-1}}\\,\\sin(2\\pi R_{2j})\n$$\n问题要求总共进行 $2T$ 次正态抽样来构建序列。前 $T$ 次抽样构成序列 $\\{\\varepsilon_t\\}_{t=0}^{T-1}$，随后的 $T$ 次抽样构成 $\\{\\eta_t\\}_{t=0}^{T-1}$。\n\n利用这些扰动序列，时间序列得以构建。序列 $\\{x_t\\}$ 是一个 I(1) 过程，具体来说是一个从 $x_0 = 0$ 开始的无漂移的随机游走：\n$$\nx_t = x_{t-1} + \\sigma_e \\,\\varepsilon_t, \\quad \\text{for } t \\in \\{1, 2, \\dots, T-1\\}.\n$$\n序列 $\\{y_t\\}$ 被构建为与 $\\{x_t\\}$ 协整，并可能存在结构性断点。其定义为：\n$$\ny_t = \\alpha + \\beta(t)\\, x_t + \\sigma_u \\,\\eta_t, \\quad \\text{for } t \\in \\{0, 1, \\dots, T-1\\}.\n$$\n参数 $\\beta(t)$ 是一个在断点指数 $T_b$ 处改变其值的阶梯函数：\n$$\n\\beta(t) = \\beta_1 \\text{ if } t \\le T_b, \\quad \\text{and} \\quad \\beta(t) = \\beta_2 \\text{ if } t > T_b.\n$$\n$T_b \\ge T$ 的值表示在样本期内没有断点发生，因此对所有 $t$ 都有 $\\beta(t) = \\beta_1$。\n\n第二阶段是断点的检测。这是通过一个基于扩展数据窗口上的普通最小二乘法 (OLS) 估计的递归监测方案来完成的。对于从起点 $T_{\\min}$ 到 $T-2$ 的每个时间指数 $t$，我们使用从 $s=0$ 到 $s=t$ 的所有可用数据来估计静态协整回归 $y_s = \\alpha + \\beta x_s + \\text{error}$ 的系数。\n\n为了高效地执行此估计，我们不为每次回归重新计算所需的和。相反，我们维护相关量的滚动和：$\\sum x_s$、$\\sum y_s$、$\\sum x_s^2$、$\\sum y_s^2$ 和 $\\sum x_s y_s$。在每一步 $t$，我们用新的数据点 $(x_t, y_t)$ 更新这些和。设 $n_t = t+1$ 为样本大小。然后使用从这些和推导出的标准公式计算 OLS 估计量 $(\\widehat{\\alpha}_t, \\widehat{\\beta}_t)$：\n$$\n\\widehat{\\beta}_t = \\frac{\\sum_{s=0}^{t} x_s y_s - n_t \\overline{x}_t \\overline{y}_t}{\\sum_{s=0}^{t} x_s^2 - n_t \\overline{x}_t^2}\n\\quad \\text{and} \\quad\n\\widehat{\\alpha}_t = \\overline{y}_t - \\widehat{\\beta}_t \\overline{x}_t,\n$$\n其中 $\\overline{x}_t$ 和 $\\overline{y}_t$ 是在 $\\{0, \\dots, t\\}$ 上的样本均值。\n\n检测机制的核心是单步向前标准化预测误差 $z_{t+1}$。该统计量衡量了在给定截至时间 $t$ 所估计的模型的情况下，下一个观测值 $(x_{t+1}, y_{t+1})$ 的“意外”程度。其定义为：\n$$\nz_{t+1} = \\frac{y_{t+1} - (\\widehat{\\alpha}_t + \\widehat{\\beta}_t x_{t+1})}{\\widehat{\\sigma}_t}\n$$\n分母 $\\widehat{\\sigma}_t$ 是回归残差的估计标准差，用于标准化预测误差。其计算方式如下：\n$$\n\\widehat{\\sigma}_t = \\sqrt{\\frac{1}{n_t - 2}\\sum_{s=0}^{t} (y_s - \\widehat{\\alpha}_t - \\widehat{\\beta}_t x_s)^2}\n$$\n分子中的残差平方和可以高效地计算为 $S_{yy,t} - \\widehat{\\beta}_t S_{xy,t}$，其中 $S_{yy,t}$ 和 $S_{xy,t}$ 是中心化的平方和与交叉乘积和。\n\n当结构性断点发生时，基于可能跨越断点前和断点后两种机制的数据的 OLS 估计量会变得有偏。这种偏差会为后续时期产生系统性的不良预测，导致一系列大的预测误差。检测规则将这种直觉形式化。我们定义一个指示变量，如果 $|z_s| \\ge c$ 则 $I_s = 1$，否则 $I_s = 0$，其中 $c$ 是给定的阈值。在第一个时间指数 $s^\\star$ 处，如果它引发了至少连续 $L$ 次的大标准化预测误差，即 $I_{s^\\star} = I_{s^\\star+1} = \\dots = I_{s^\\star+L-1} = 1$，则发出断点信号。对 $s^\\star$ 的搜索从指数 $T_{\\min}+1$ 开始。如果在观测窗口内未找到这样的序列，我们断定未检测到断点并报告 $-1$。整个过程对每个提供的参数集都进行确定性地实现。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        # (T, T_b, alpha, beta_1, beta_2, sigma_e, sigma_u, T_min, c, L, s)\n        (240, 150, 0.5, 1.0, 1.6, 1.0, 0.05, 40, 3.0, 2, 12345),\n        (240, 10**9, 0.5, 1.0, 1.0, 1.0, 0.05, 40, 3.0, 2, 54321),\n        (220, 210, 0.3, 0.8, 1.9, 0.9, 0.05, 30, 2.5, 2, 20231107),\n        (180, 60, 0.2, 1.2, 1.4, 0.8, 0.1, 25, 2.0, 3, 424242),\n    ]\n\n    results = []\n    for params in test_cases:\n        result = _run_case(params)\n        results.append(result)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _run_case(params):\n    \"\"\"\n    Processes a single test case.\n    \"\"\"\n    T, T_b, alpha, beta_1, beta_2, sigma_e, sigma_u, T_min, c, L, s = params\n\n    # --- 1. Data Generation ---\n\n    # LCG parameters\n    m = 2**31 - 1\n    a = 16807\n    \n    # Generate 2*T uniform random numbers\n    uniforms = np.zeros(2 * T)\n    U_k = s\n    for k in range(2 * T):\n        U_k = (a * U_k) % m\n        uniforms[k] = U_k / m\n\n    # Generate 2*T standard normal random numbers using Box-Muller transform\n    normals = np.zeros(2 * T)\n    for j in range(T):\n        R1 = uniforms[2*j]\n        R2 = uniforms[2*j+1]\n        \n        log_R1 = np.log(R1)\n        term1 = np.sqrt(-2.0 * log_R1)\n        term2 = 2.0 * np.pi * R2\n\n        normals[2*j] = term1 * np.cos(term2)\n        normals[2*j+1] = term1 * np.sin(term2)\n    \n    epsilons = normals[:T]\n    etas = normals[T:]\n\n    # Generate time series x_t and y_t\n    x = np.zeros(T, dtype=np.float64)\n    y = np.zeros(T, dtype=np.float64)\n    \n    # x_0 = 0 is default\n    for t in range(1, T):\n        x[t] = x[t-1] + sigma_e * epsilons[t]\n\n    for t in range(T):\n        beta_t = beta_1 if t <= T_b else beta_2\n        y[t] = alpha + beta_t * x[t] + sigma_u * etas[t]\n\n    # --- 2. Break Detection ---\n    \n    # Array to store indicators of threshold exceedance\n    z_indicators = np.zeros(T, dtype=int)\n    \n    # Initialize running sums for recursive OLS\n    s_x, s_y, s_x2, s_y2, s_xy = 0.0, 0.0, 0.0, 0.0, 0.0\n    \n    # Pre-computation for the initial window up to T_min\n    for t in range(T_min):\n        s_x += x[t]\n        s_y += y[t]\n        s_x2 += x[t]**2\n        s_y2 += y[t]**2\n        s_xy += x[t] * y[t]\n\n    # Recursive estimation and forecast error calculation\n    for t in range(T_min, T - 1):\n        # Update sums with the value at time t\n        s_x += x[t]\n        s_y += y[t]\n        s_x2 += x[t]**2\n        s_y2 += y[t]**2\n        s_xy += x[t] * y[t]\n        \n        n_t = t + 1\n        \n        # Calculate OLS estimates\n        x_bar = s_x / n_t\n        y_bar = s_y / n_t\n        \n        s_xx = s_x2 - n_t * x_bar**2\n        s_yy = s_y2 - n_t * y_bar**2\n        s_xy_t = s_xy - n_t * x_bar * y_bar\n        \n        # Avoid division by zero, though unlikely with a random walk\n        if s_xx == 0:\n            continue\n            \n        beta_hat = s_xy_t / s_xx\n        alpha_hat = y_bar - beta_hat * x_bar\n        \n        # Calculate residual standard deviation\n        ssr = s_yy - beta_hat * s_xy_t\n        # Ensure non-negativity due to potential floating point inaccuracies\n        ssr = max(0, ssr)\n        \n        df = n_t - 2\n        if df <= 0:\n            continue\n            \n        sigma_hat_sq = ssr / df\n        \n        if sigma_hat_sq <= 0:\n            continue \n        \n        sigma_hat = np.sqrt(sigma_hat_sq)\n        \n        # Calculate standardized one-step-ahead forecast error for time t+1\n        forecast_error = y[t+1] - (alpha_hat + beta_hat * x[t+1])\n        z_t_plus_1 = forecast_error / sigma_hat if sigma_hat > 0 else np.inf\n        \n        if np.abs(z_t_plus_1) >= c:\n            z_indicators[t + 1] = 1\n\n    # --- 3. Search for Break Index ---\n    \n    # Search for the first run of L consecutive indicators\n    # The search range for the start of the run (s_star)\n    # is from T_min+1 to T-L (inclusive).\n    for s_star in range(T_min + 1, T - L + 1):\n        # Check for a run of length L\n        if np.all(z_indicators[s_star : s_star + L] == 1):\n            return s_star\n\n    return -1\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}