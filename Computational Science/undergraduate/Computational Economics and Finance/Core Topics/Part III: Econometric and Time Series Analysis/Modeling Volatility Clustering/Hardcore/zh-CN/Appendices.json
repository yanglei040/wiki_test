{
    "hands_on_practices": [
        {
            "introduction": "将理论付诸实践的第一步是学习如何检验有关波动率行为的具体假设。这个练习  将指导你检验一个经典的金融异象：“星期效应”，即资产波动率是否在每周的不同日子里呈现系统性模式。通过将虚拟变量整合到 GARCH 模型中，你将学习如何构建、估计和评估一个扩展的波动率模型，并使用似然比检验来做出统计推断。",
            "id": "2411105",
            "problem": "要求您设计并实现一个完整的、可运行的程序，通过将虚拟变量引入一个捕捉金融回报中波动率聚类现象的条件方差模型，来检验波动率中的“星期效应”。使用的基本原理包括：条件期望和方差的定义，许多金融回报序列显示出时变条件方差（“波动率聚类”）的观察，以及广义自回归条件异方差（GARCH）模型是表示此类条件方差动态的一种经过充分检验的方法。在高斯假设下，基于似然的推断（拟最大似然）是经过充分检验且适合于估计的方法，而似然比检验是检验嵌套假设的标准方法。\n\n您的程序必须针对一组综合测试用例执行以下操作：\n\n1. 将回报序列 $\\{r_t\\}_{t=1}^T$ 视为均值为零、条件异方差，其条件方差 $\\sigma_t^2$ 服从 GARCH($1,1$) 型递归。在条件方差方程中，通过加性虚拟变量引入“星期效应”。令 $D_t$ 为星期一、星期二、星期四和星期五的星期指示向量（星期三为基准日，无指示变量）。指示向量 $D_t \\in \\mathbb{R}^4$ 按5天周期定义如下：$D_t = [\\mathbb{1}\\{\\text{Mon}\\}, \\mathbb{1}\\{\\text{Tue}\\}, \\mathbb{1}\\{\\text{Thu}\\}, \\mathbb{1}\\{\\text{Fri}\\}]^\\top$。日期按星期一、星期二、星期三、星期四、星期五的固定顺序循环重复；模拟指数中没有周末。\n\n2. 将非受限模型（包含波动率中的星期效应）定义为：\n$$\nr_t = \\sigma_t z_t, \\quad z_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1),\n$$\n$$\n\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2 + \\gamma^\\top D_t,\n$$\n参数满足 $\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, $\\alpha + \\beta  1$，且 $\\gamma \\in \\mathbb{R}_+^4$ 受到约束以确保 $\\sigma_t^2 > 0$ 几乎必然成立。受限（原）模型设置 $\\gamma = 0$ 并使用：\n$$\n\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2.\n$$\n这些是用于建模波动率聚类和外生方差效应的标准且经过充分检验的结构。\n\n3. 对每个测试用例，使用已知的参数值 $(\\omega, \\alpha, \\beta, \\gamma)$ 和一个固定的种子以保证可复现性，从一个已知的数据生成过程（DGP）模拟回报，该过程采用上述非受限模型的形式。使用 $B$ 个观测值作为“预烧期”，然后保留最后的 $T$ 个观测值用于估计。使用一个遵循 $\\alpha + \\beta  1$ 并且考虑到 $D_t$ 在5天周期内的平均贡献的长期平均值来初始化 $\\sigma_1^2$。\n\n4. 通过最大化高斯对数似然（拟最大似然）来估计非受限模型和受限模型。使用任何平滑的重参数化方法，以确保 $\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$, $\\alpha + \\beta  1$ 以及 $\\gamma \\ge 0$，从而使得数值优化在原始参数空间中不受约束，但在模型空间中约束条件得以满足。对于观测值 $t$，高斯对数似然的贡献为：\n$$\n\\ell_t = -\\tfrac{1}{2}\\left(\\log(2\\pi) + \\log \\sigma_t^2 + \\frac{r_t^2}{\\sigma_t^2}\\right),\n$$\n总对数似然为 $L = \\sum_{t=1}^{T} \\ell_t$。\n\n5. 使用似然比统计量检验原假设 $H_0: \\gamma = 0$ 与非受限备择假设：\n$$\n\\text{LR} = 2\\left[L_{\\text{unrestricted}} - L_{\\text{restricted}}\\right].\n$$\n在标准正则性条件下，当 $H_0$ 成立时，$\\text{LR}$ 渐近服从自由度为 $k$ 的卡方分布，其中 $k$ 是约束的数量。此处，$k=4$。使用自由度为 $4$ 的卡方分布计算 $p$ 值，如果 $p$ 值小于 $0.05$，则在 $0.05$ 的水平上拒绝 $H_0$。将拒绝决策表示为布尔值。\n\n6. 您的程序必须生成单行输出，其中包含所有测试用例的布尔结果，形式为方括号内以逗号分隔的列表，例如，“[True,False,True]”。\n\n测试套件（所有数字均为与日回报率一致的十进制单位；不涉及物理单位）：\n\n- 通用设置：对于所有测试用例，使用 $T = 2000$ 和 $B = 500$ 的“预烧期”。星期模式从 $t=1$ 开始，依次为星期一、星期二、星期三、星期四、星期五，然后重复。\n\n- 测试用例 1（原假设，中等持续性）：\n  - 种子：$123$。\n  - 参数：$\\omega = 5 \\times 10^{-6}$, $\\alpha = 0.05$, $\\beta = 0.90$, $\\gamma = [0, 0, 0, 0]$。\n  - 预期行为：在 $0.05$ 的水平上不拒绝 $H_0$。\n\n- 测试用例 2（单一强星期一效应）：\n  - 种子：$456$。\n  - 参数：$\\omega = 5 \\times 10^{-6}$, $\\alpha = 0.05$, $\\beta = 0.90$, $\\gamma = [2\\times 10^{-5}, 0, 0, 0]$。\n  - 预期行为：在 $0.05$ 的水平上拒绝 $H_0$。\n\n- 测试用例 3（多重强星期效应）：\n  - 种子：$789$。\n  - 参数：$\\omega = 5 \\times 10^{-6}$, $\\alpha = 0.05$, $\\beta = 0.90$, $\\gamma = [2\\times 10^{-5}, 1.5\\times 10^{-5}, 1\\times 10^{-5}, 5\\times 10^{-6}]$。\n  - 预期行为：在 $0.05$ 的水平上拒绝 $H_0$。\n\n- 测试用例 4（原假设，接近单位根的高持续性）：\n  - 种子：$321$。\n  - 参数：$\\omega = 1 \\times 10^{-6}$, $\\alpha = 0.05$, $\\beta = 0.94$, $\\gamma = [0, 0, 0, 0]$。\n  - 预期行为：在 $0.05$ 的水平上不拒绝 $H_0$。\n\n最终输出格式要求：\n- 您的程序应生成单行输出，其中包含按测试用例顺序排列的结果，形式为方括号内以逗号分隔的 `True` 或 `False` 布尔值列表，例如：“[False,True,True,False]”。",
            "solution": "所述问题是有效的。这是一个定义明确的计算计量经济学练习，基于成熟的时间序列分析和假设检验理论。任务是实现一个似然比检验，用于检验 GARCH($1,1$) 模型的条件方差设定中是否存在确定性的星期效应。该过程需要几个不同的步骤：从一个已知的数据生成过程（DGP）模拟合成数据，通过拟最大似然（QML）估计受限和非受限模型，最后计算检验统计量及其相关的p值以作出决策。\n\n问题的核心在于 GARCH($1,1$) 模型，它捕捉了许多金融时间序列中观察到的波动率聚类现象。回报 $r_t$ 的模型由下式给出：\n$$\nr_t = \\sigma_t z_t, \\quad z_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1)\n$$\n其中 $z_t$ 是一个标准正态新息，$\\sigma_t^2$ 是时间 $t$ 的条件方差。问题为此条件方差指定了两个嵌套模型。\n\n非受限模型通过虚拟变量向量 $D_t \\in \\mathbb{R}^4$ 引入星期效应：\n$$\n\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2 + \\gamma^\\top D_t\n$$\n与原假设 $H_0$ 对应的受限模型通过将参数向量 $\\gamma$ 设置为零来排除这些效应：\n$$\nH_0: \\gamma = 0 \\quad \\implies \\quad \\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2\n$$\n参数受到约束以确保方差过程的良好性态：$\\omega > 0$, $\\alpha \\ge 0$, $\\beta \\ge 0$，为保证平稳性，$\\alpha + \\beta  1$。星期效应的系数 $\\gamma$ 被约束为非负，即 $\\gamma \\ge 0$，以排除负的方差贡献。\n\n算法设计如下：\n\n首先，构建一个数据生成函数。对于每个测试用例，我们使用指定的参数 $(\\omega, \\alpha, \\beta, \\gamma)$ 和随机种子，从非受限模型中模拟一个长度为 $T+B$ 的时间序列。星期虚拟变量 $D_t$ 是周期性构建的。该过程使用无条件方差进行初始化，在平稳性假设下，该方差为 $E[\\sigma_t^2] = (\\omega + E[\\gamma^\\top D_t]) / (1 - \\alpha - \\beta)$。由于日期按5天一周循环，期望 $E[\\gamma^\\top D_t]$ 是一周内的平均效应：$\\frac{1}{5}(\\gamma_1 + \\gamma_2 + \\gamma_3 + \\gamma_4)$，其中 $\\gamma = [\\gamma_1, \\gamma_2, \\gamma_3, \\gamma_4]^\\top$。前 $B=500$ 个观测值作为“预烧期”被丢弃，以减轻初始条件的影响，留下一个大小为 $T=2000$ 的样本用于估计。\n\n其次，我们必须定义用于估计的对数似然函数。假设为高斯新息，观测值 $t$ 的对数似然贡献为：\n$$\n\\ell_t(\\theta) = -\\frac{1}{2}\\left(\\log(2\\pi) + \\log \\sigma_t^2(\\theta) + \\frac{r_t^2}{\\sigma_t^2(\\theta)}\\right)\n$$\n其中 $\\theta$ 代表模型参数的向量。总对数似然为 $L(\\theta) = \\sum_{t=1}^T \\ell_t(\\theta)$。通过使用数值优化器最大化此函数来进行估计。\n\n为了在优化过程中处理参数约束，我们采用了一种重参数化方法。优化器在无约束的参数空间上操作，这些参数在用于似然计算之前被转换以满足所需的约束。令无约束参数为 $p_i$。一个合适的转换为：\n- $\\omega = \\exp(p_0)$ 以确保 $\\omega > 0$。\n- $\\alpha = \\frac{\\exp(p_1)}{1+\\exp(p_1)}$ 以确保 $\\alpha \\in (0,1)$。\n- $\\beta = (1-\\alpha) \\times \\frac{\\exp(p_2)}{1+\\exp(p_2)}$ 以确保 $\\beta \\in (0, 1-\\alpha)$，从而 $\\alpha+\\beta  1$。\n- $\\gamma_j = \\exp(p_{2+j})$ 对于 $j \\in \\{1,2,3,4\\}$ 以确保 $\\gamma_j > 0$。\n\n条件方差序列 $\\sigma_t^2(\\theta)$ 是递归计算的。我们使用当前参数估计值 $\\theta$，以模型隐含的无条件方差来初始化 $\\sigma_1^2$。然后，对于 $t=2, \\dots, T$，我们使用 GARCH 递归计算 $\\sigma_t^2$。优化器将最小化总对数似然的负值，即 $-L(\\theta)$。\n\n第三，对于每个测试用例，我们执行两次估计。我们首先拟合具有 $3$ 个参数 $(\\omega, \\alpha, \\beta)$ 的受限模型，以获得最大化对数似然 $L_{\\text{restricted}}$。然后我们拟合具有 $7$ 个参数 $(\\omega, \\alpha, \\beta, \\gamma_1, \\gamma_2, \\gamma_3, \\gamma_4)$ 的非受限模型，以获得 $L_{\\text{unrestricted}}$。\n\n最后，计算似然比（LR）检验统计量：\n$$\n\\text{LR} = 2(L_{\\text{unrestricted}} - L_{\\text{restricted}})\n$$\n在原假设 $H_0: \\gamma = 0$ 下，该统计量渐近服从一个卡方分布，其自由度等于约束的数量，即 $k=4$。p值的计算公式为 $P(\\chi^2_4 > \\text{LR})$。如果该p值小于指定的显著性水平 $0.05$，则拒绝原假设。每个测试用例的此决策结果（一个布尔值）随后被报告。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import chi2\n\ndef generate_data(T, B, seed, omega, alpha, beta, gamma):\n    \"\"\"\n    Generates synthetic returns from a GARCH(1,1) model with day-of-week effects.\n    \"\"\"\n    np.random.seed(seed)\n    total_len = T + B\n    \n    # Create day-of-week dummy variables\n    # D_t = [Mon, Tue, Thu, Fri]\n    dummies = np.zeros((total_len, 4))\n    for t in range(total_len):\n        day_of_week = t % 5  # 0:Mon, 1:Tue, 2:Wed, 3:Thu, 4:Fri\n        if day_of_week == 0:   # Monday\n            dummies[t, 0] = 1.0\n        elif day_of_week == 1: # Tuesday\n            dummies[t, 1] = 1.0\n        elif day_of_week == 3: # Thursday\n            dummies[t, 2] = 1.0\n        elif day_of_week == 4: # Friday\n            dummies[t, 3] = 1.0\n            \n    # Initialize returns and variances\n    returns = np.zeros(total_len)\n    sigma_sq = np.zeros(total_len)\n    \n    # Initial variance is the unconditional variance\n    mean_gamma_effect = np.sum(gamma) / 5.0\n    uncond_var = (omega + mean_gamma_effect) / (1.0 - alpha - beta)\n    \n    # Generate standard normal innovations\n    z = np.random.normal(0.0, 1.0, total_len)\n    \n    # First observation\n    sigma_sq[0] = uncond_var\n    returns[0] = np.sqrt(sigma_sq[0]) * z[0]\n    \n    # Generate the rest of the series\n    for t in range(1, total_len):\n        gamma_effect = np.dot(gamma, dummies[t])\n        sigma_sq[t] = omega + alpha * returns[t-1]**2 + beta * sigma_sq[t-1] + gamma_effect\n        if sigma_sq[t]  1e-12: # Floor variance to avoid numerical issues\n            sigma_sq[t] = 1e-12\n        returns[t] = np.sqrt(sigma_sq[t]) * z[t]\n        \n    return returns[B:], dummies[B:]\n\ndef neg_log_likelihood(params_unconstrained, returns, dummies, is_unrestricted):\n    \"\"\"\n    Calculates the negative of the GARCH log-likelihood function.\n    \"\"\"\n    T = len(returns)\n    \n    # Reparameterization to enforce constraints\n    omega = np.exp(params_unconstrained[0])\n    alpha_trans = np.exp(params_unconstrained[1])\n    alpha = alpha_trans / (1.0 + alpha_trans)\n    beta_trans = np.exp(params_unconstrained[2])\n    beta = (1.0 - alpha) * (beta_trans / (1.0 + beta_trans))\n\n    if is_unrestricted:\n        gamma = np.exp(params_unconstrained[3:])\n        mean_gamma_effect = np.sum(gamma) / 5.0\n    else:\n        gamma = np.zeros(4)\n        mean_gamma_effect = 0.0\n\n    # Ensure stationarity for unconditional variance calculation\n    if (alpha + beta) >= 1.0:\n        return 1e9 # Penalize non-stationary region\n        \n    # Initialize variance series\n    sigma_sq = np.zeros(T)\n    uncond_var = (omega + mean_gamma_effect) / (1.0 - alpha - beta)\n    \n    # It's standard to initialize with unconditional variance.\n    sigma_sq[0] = uncond_var\n\n    # GARCH recursion\n    for t in range(1, T):\n        gamma_effect = np.dot(gamma, dummies[t])\n        sigma_sq[t] = omega + alpha * returns[t-1]**2 + beta * sigma_sq[t-1] + gamma_effect\n        if sigma_sq[t]  1e-12:\n            sigma_sq[t] = 1e-12\n\n    # Avoid log(0) or division by zero\n    if np.any(sigma_sq = 0):\n        return 1e9\n\n    # Log-likelihood calculation\n    log_likelihood = -0.5 * np.sum(np.log(2 * np.pi) + np.log(sigma_sq) + returns**2 / sigma_sq)\n\n    if np.isnan(log_likelihood) or np.isinf(log_likelihood):\n        return 1e9\n\n    return -log_likelihood\n\ndef fit_garch(returns, dummies, is_unrestricted):\n    \"\"\"\n    Fits a GARCH(1,1) model (restricted or unrestricted) using QML.\n    \"\"\"\n    if is_unrestricted:\n        # Initial guess for [log(w), ...log(alpha_trans), ...log(beta_trans), ...log(gamma)]\n        x0 = np.array([-12.0, -2.5, 2.5, -16.0, -16.0, -16.0, -16.0])\n    else:\n        # Initial guess for [log(w), ...log(alpha_trans), ...log(beta_trans)]\n        x0 = np.array([-12.0, -2.5, 2.5])\n    \n    res = minimize(\n        neg_log_likelihood,\n        x0=x0,\n        args=(returns, dummies, is_unrestricted),\n        method='L-BFGS-B'\n    )\n    \n    max_log_likelihood = -res.fun\n    return max_log_likelihood\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        {'seed': 123, 'omega': 5e-6, 'alpha': 0.05, 'beta': 0.90, 'gamma_vec': np.array([0.0, 0.0, 0.0, 0.0])},\n        # Test Case 2\n        {'seed': 456, 'omega': 5e-6, 'alpha': 0.05, 'beta': 0.90, 'gamma_vec': np.array([2e-5, 0.0, 0.0, 0.0])},\n        # Test Case 3\n        {'seed': 789, 'omega': 5e-6, 'alpha': 0.05, 'beta': 0.90, 'gamma_vec': np.array([2e-5, 1.5e-5, 1e-5, 5e-6])},\n        # Test Case 4\n        {'seed': 321, 'omega': 1e-6, 'alpha': 0.05, 'beta': 0.94, 'gamma_vec': np.array([0.0, 0.0, 0.0, 0.0])}\n    ]\n    \n    common_settings = {'T': 2000, 'B': 500}\n    results = []\n\n    for case in test_cases:\n        # 1. Generate data\n        returns, dummies = generate_data(\n            T=common_settings['T'],\n            B=common_settings['B'],\n            seed=case['seed'],\n            omega=case['omega'],\n            alpha=case['alpha'],\n            beta=case['beta'],\n            gamma=case['gamma_vec']\n        )\n        \n        # 2. Fit restricted model (H0)\n        logL_restricted = fit_garch(returns, dummies, is_unrestricted=False)\n        \n        # 3. Fit unrestricted model (H1)\n        logL_unrestricted = fit_garch(returns, dummies, is_unrestricted=True)\n        \n        # 4. Perform Likelihood Ratio test\n        LR_statistic = 2 * (logL_unrestricted - logL_restricted)\n        \n        # The LR statistic should be non-negative.\n        if LR_statistic  0:\n            LR_statistic = 0\n            \n        degrees_of_freedom = 4\n        p_value = chi2.sf(LR_statistic, df=degrees_of_freedom)\n        \n        # 5. Make decision\n        reject_H0 = p_value  0.05\n        results.append(reject_H0)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "资产的波动率并非孤立存在，它常常受到更广泛市场情绪的影响。本练习  介绍了一种更强大的模型——因子 GARCH 模型，它允许我们将一个可观测的外部因子（例如市场波动率指数）纳入个别资产的波动率方程中。通过亲手实现这个模型的递归计算过程，你将掌握如何将外部信息整合到波动率建模中，并计算出条件方差和对数似然值等核心输出，为后续的模型估计和预测打下坚实基础。",
            "id": "2411181",
            "problem": "您需要实现一个简单的因子-广义自回归条件异方差（Factor-GARCH）模型。在该模型中，一个可观测的全市场波动率因子，例如芝加哥期权交易所（CBOE）波动率指数（VIX），会影响单个资产收益过程的条件方差。\n\n请从以下基本原则和定义开始：\n- 资产收益的典型化事实：资产收益表现出波动率聚集现象，即大的（小的）冲击之后往往跟随着大的（小的）冲击。\n- 条件方差建模：向前一期的条件方差被建模为其自身滞后项和滞后平方新息的函数。\n- 条件异方差过程的高斯（正态）对数似然。\n\n模型设定：\n- 设收益序列为 $\\{r_t\\}_{t=1}^T$，可观测的非负因子序列为 $\\{f_t\\}_{t=1}^T$，条件方差序列为 $\\{h_t\\}_{t=1}^T$。\n- 观测方程为 $r_t = \\sqrt{h_t}\\,\\varepsilon_t$，其中 $\\varepsilon_t \\sim \\text{i.i.d. } \\mathcal{N}(0,1)$。\n- 方差递归（带一阶滞后的 Factor-GARCH）为\n$$\nh_t = \\omega + \\alpha r_{t-1}^2 + \\beta h_{t-1} + \\phi f_{t-1},\n$$\n参数满足 $\\omega \\ge 0$、$\\alpha \\ge 0$、$\\beta \\ge 0$、$\\phi \\ge 0$。为保证数值稳定性和现实性，假设对所有 $t$ 都有 $\\alpha + \\beta  1$ 和 $f_t \\ge 0$。\n- 初始化：\n  - 设置 $r_0 = 0$ 和 $f_0 = f_1$。\n  - 设置一个小的下限 $\\epsilon = 10^{-8}$ 以强制保持正值。\n  - 初始化\n  $$\n  h_0 = \\max\\left(\\epsilon,\\ \\frac{\\omega}{\\max(1 - \\alpha - \\beta,\\ \\epsilon)} + \\phi f_0\\right).\n  $$\n  - 对于每个 $t \\in \\{1,\\dots,T\\}$，通过递归计算 $h_t$，并强制执行 $h_t \\leftarrow \\max(h_t, \\epsilon)$。\n- 向前一步的方差预测为\n$$\nh_{T+1} = \\omega + \\alpha r_T^2 + \\beta h_T + \\phi f_T,\n$$\n强制其至少为 $\\epsilon$。\n- 高斯负对数似然为\n$$\n\\text{NLL} = \\frac{1}{2}\\sum_{t=1}^T \\left(\\ln(2\\pi) + \\ln(h_t) + \\frac{r_t^2}{h_t}\\right).\n$$\n\n您的任务：\n- 实现一个程序，针对下述每个测试用例，计算三个量：最终的条件方差 $h_T$、向前一步的预测值 $h_{T+1}$ 以及高斯负对数似然 $\\text{NLL}$。\n- 严格使用上述初始化和递归规则。\n- 将报告的每个量四舍五入到 $6$ 位小数。\n\n测试套件：\n- 使用以下收益序列和因子序列，其中所有值均为无量纲：\n  - 序列 A（用于用例 $1$、$2$、$3$）：\n    - 收益：$[0.01,\\ -0.02,\\ 0.015,\\ -0.005,\\ 0.0,\\ 0.02,\\ -0.015,\\ 0.01]$\n    - 因子：$[0.20,\\ 0.25,\\ 0.22,\\ 0.24,\\ 0.21,\\ 0.23,\\ 0.26,\\ 0.22]$\n  - 序列 B（用于用例 $4$）：\n    - 收益：$[0.0,\\ 0.0,\\ 0.0,\\ 0.0,\\ 0.0]$\n    - 因子：$[0.10,\\ 0.20,\\ 0.30,\\ 0.25,\\ 0.15]$\n\n- 用例和参数 $(\\omega,\\ \\alpha,\\ \\beta,\\ \\phi)$：\n  - 用例 $1$（正常路径）：使用序列 A 和参数 $(0.0001,\\ 0.10,\\ 0.85,\\ 0.05)$。\n  - 用例 $2$（无因子效应）：使用序列 A 和参数 $(0.0001,\\ 0.10,\\ 0.85,\\ 0.00)$。\n  - 用例 $3$（近边界持续性）：使用序列 A 和参数 $(0.00005,\\ 0.08,\\ 0.91,\\ 0.07)$。\n  - 用例 $4$（零收益下的纯因子驱动）：使用序列 B 和参数 $(0.0001,\\ 0.00,\\ 0.90,\\ 0.20)$。\n\n要求的输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表。\n- 对于每个用例，按顺序输出 $h_T$、$h_{T+1}$ 和 $\\text{NLL}$，均四舍五入到 $6$ 位小数。\n- 按用例 $1$、用例 $2$、用例 $3$、用例 $4$ 的顺序汇总所有用例，并将输出扁平化。例如，最终输出应如下所示：\n$[h_T^{(1)}, h_{T+1}^{(1)}, \\text{NLL}^{(1)}, h_T^{(2)}, h_{T+1}^{(2)}, \\text{NLL}^{(2)}, h_T^{(3)}, h_{T+1}^{(3)}, \\text{NLL}^{(3)}, h_T^{(4)}, h_{T+1}^{(4)}, \\text{NLL}^{(4)}]$,\n每个条目打印到 $6$ 位小数。",
            "solution": "所呈现的问题是金融计量经济学领域一个定义明确的计算任务。它具有科学依据和数学一致性，并为获得唯一解提供了所有必要信息。指定的模型是一个因子-GARCH($1,1$)过程，它是广义自回归条件异方差（GARCH）框架的标准扩展，旨在捕捉资产收益中根据经验观察到的波动率聚集现象。包含外部因子使得模型能够解释影响单个资产方差的全市场波动率冲击。该问题是有效的，可以通过仔细实现指定的算法来构建解决方案。\n\n问题的核心是为资产收益序列 $\\{r_t\\}_{t=1}^T$ 的条件方差 $h_t$ 建模。时间 $t$ 的收益由观测方程 $r_t = \\sqrt{h_t}\\,\\varepsilon_t$ 定义，其中 $\\varepsilon_t$ 是来自标准正态分布 $\\mathcal{N}(0,1)$ 的独立同分布随机变量。这意味着，在给定截至时间 $t-1$ 的信息条件下，$r_t$ 的条件分布是均值为 $0$、方差为 $h_t$ 的正态分布。\n\n条件方差的演变由因子-GARCH($1,1$)递归描述：\n$$\nh_t = \\omega + \\alpha r_{t-1}^2 + \\beta h_{t-1} + \\phi f_{t-1}\n$$\n这个方程有四个组成部分：\n1.  一个常数截距项 $\\omega$，它为方差提供了一个基准水平。\n2.  ARCH 项 $\\alpha r_{t-1}^2$，它捕捉了上一期平方冲击（平方收益）的影响。$|r_{t-1}|$ 的较大值会导致更高的方差 $h_t$，从而对波动率聚集进行建模。\n3.  GARCH 项 $\\beta h_{t-1}$，它代表了上一期条件方差的影响。该项为波动率过程引入了持续性。\n4.  因子项 $\\phi f_{t-1}$，它纳入了一个可观测的滞后外部因子 $f_{t-1}$ 对当前方差的影响。\n\n参数被约束为非负（$\\omega, \\alpha, \\beta, \\phi \\ge 0$），以确保方差 $h_t$ 为非负。约束 $\\alpha + \\beta  1$ 是在没有因子的情况下，方差过程弱平稳所必需的。\n\n计算过程建立在这个递归定义之上。精确的算法实现如下：\n\n首先，我们必须初始化该过程。$h_t$ 的递归依赖于 $t-1$ 时刻的值。因此，我们需要 $t=0$ 时的初始值。问题指定了 $r_0 = 0$ 和 $f_0 = f_1$，其中 $f_1$ 是因子序列中的第一个观测值。初始方差 $h_0$ 是基于 GARCH 过程的长期无条件方差，并根据初始因子水平进行调整。GARCH($1,1$) 过程的无条件方差是 $E[h] = \\frac{\\omega}{1-\\alpha-\\beta}$。初始化将其扩展为：\n$$\nh_0 = \\max\\left(\\epsilon,\\ \\frac{\\omega}{\\max(1 - \\alpha - \\beta,\\ \\epsilon)} + \\phi f_0\\right)\n$$\n使用一个小的正下限 $\\epsilon = 10^{-8}$ 来确保分母不为零且 $h_0$ 严格为正，这对于数值稳定性至关重要，尤其是在为似然函数计算对数时。\n\n其次，我们从 $t=1$ 迭代到 $T$ 来计算条件方差序列 $\\{h_t\\}_{t=1}^T$。在每一步中，我们使用上一步的已知值（$r_{t-1}$、$h_{t-1}$、$f_{t-1}$）应用方差递归公式。每次计算后，得到的 $h_t$ 也会被限制在不小于 $\\epsilon$，以在整个序列中保持正值。此循环中计算的最终值为 $h_T$。\n\n第三，我们计算向前一步的方差预测 $h_{T+1}$。这是直接使用时间 $T$ 的最新可用数据应用递归公式：\n$$\nh_{T+1} = \\omega + \\alpha r_T^2 + \\beta h_T + \\phi f_T\n$$\n该值同样被限制在不小于 $\\epsilon$。\n\n第四，我们计算高斯负对数似然（NLL）。对于单个观测值 $r_t$，其条件对数似然为 $\\ell_t = -\\frac{1}{2}(\\ln(2\\pi) + \\ln(h_t) + r_t^2/h_t)$。整个序列 $\\{r_t\\}_{t=1}^T$ 的总 NLL 是这些单个对数似然负值的总和：\n$$\n\\text{NLL} = \\sum_{t=1}^T -\\ell_t = \\frac{1}{2}\\sum_{t=1}^T \\left(\\ln(2\\pi) + \\ln(h_t) + \\frac{r_t^2}{h_t}\\right)\n$$\n此计算使用观测到的收益序列 $\\{r_t\\}_{t=1}^T$ 和计算出的条件方差序列 $\\{h_t\\}_{t=1}^T$。\n\n整个算法被实现为一个函数，该函数接受收益序列、因子序列和模型参数。此函数执行所述的初始化、递归、预测和 NLL 计算。对问题陈述中指定的四个测试用例中的每一个重复此过程。最终结果——每个用例的 $h_T$、$h_{T+1}$ 和 $\\text{NLL}$——被四舍五入到 $6$ 位小数，并汇总到一个列表中进行输出。使用 NumPy 有助于数组操作以及像 `log` 和 `pi` 这样的数学函数。",
            "answer": "```python\nimport numpy as np\n\ndef calculate_factor_garch(r_data, f_data, params):\n    \"\"\"\n    Computes h_T, h_{T+1}, and NLL for a Factor-GARCH(1,1) model.\n\n    Args:\n        r_data (list): The return series {r_t}.\n        f_data (list): The observable factor series {f_t}.\n        params (tuple): The model parameters (omega, alpha, beta, phi).\n\n    Returns:\n        tuple: A tuple containing (h_T, h_{T+1}, NLL).\n    \"\"\"\n    omega, alpha, beta, phi = params\n    epsilon = 1e-8\n\n    r = np.array(r_data, dtype=float)\n    f = np.array(f_data, dtype=float)\n    T = len(r)\n\n    # Prepare extended series with initial values at t=0.\n    # r_ext corresponds to {r_0, r_1, ..., r_T}\n    r_ext = np.insert(r, 0, 0.0) \n    # f_ext corresponds to {f_0, f_1, ..., f_T}\n    # f_0 = f_1, where f_1 is the first element of the original f_data array.\n    f_ext = np.insert(f, 0, f[0])\n\n    # h array will store {h_0, h_1, ..., h_T}\n    h = np.zeros(T + 1)\n\n    # Initialize h_0\n    h_denom = max(1.0 - alpha - beta, epsilon)\n    h_uncond = omega / h_denom + phi * f_ext[0]\n    h[0] = max(epsilon, h_uncond)\n\n    # Recursion for h_t, t = 1, ..., T\n    for t in range(1, T + 1):\n        h_val = omega + alpha * r_ext[t - 1]**2 + beta * h[t - 1] + phi * f_ext[t - 1]\n        h[t] = max(h_val, epsilon)\n\n    # The final conditional variance is h at time T.\n    h_T = h[T]\n\n    # One-step-ahead forecast for h_{T+1}\n    h_Tplus1_val = omega + alpha * r_ext[T]**2 + beta * h[T] + phi * f_ext[T]\n    h_Tplus1 = max(h_Tplus1_val, epsilon)\n\n    # Calculate Gaussian Negative Log-Likelihood\n    # The sum is over t=1,...,T, which corresponds to h[1:]\n    h_for_nll = h[1:]\n    nll = 0.5 * np.sum(np.log(2 * np.pi) + np.log(h_for_nll) + r**2 / h_for_nll)\n\n    return h_T, h_Tplus1, nll\n\ndef solve():\n    \"\"\"\n    Defines test cases and computes the required quantities for each,\n    then prints the formatted output.\n    \"\"\"\n    # Series A data\n    series_A_r = [0.01, -0.02, 0.015, -0.005, 0.0, 0.02, -0.015, 0.01]\n    series_A_f = [0.20, 0.25, 0.22, 0.24, 0.21, 0.23, 0.26, 0.22]\n    \n    # Series B data\n    series_B_r = [0.0, 0.0, 0.0, 0.0, 0.0]\n    series_B_f = [0.10, 0.20, 0.30, 0.25, 0.15]\n\n    test_cases = [\n        # Case 1: Series A, (omega, alpha, beta, phi) = (0.0001, 0.10, 0.85, 0.05)\n        {\"r\": series_A_r, \"f\": series_A_f, \"params\": (0.0001, 0.10, 0.85, 0.05)},\n        # Case 2: Series A, (omega, alpha, beta, phi) = (0.0001, 0.10, 0.85, 0.0)\n        {\"r\": series_A_r, \"f\": series_A_f, \"params\": (0.0001, 0.10, 0.85, 0.00)},\n        # Case 3: Series A, (omega, alpha, beta, phi) = (0.00005, 0.08, 0.91, 0.07)\n        {\"r\": series_A_r, \"f\": series_A_f, \"params\": (0.00005, 0.08, 0.91, 0.07)},\n        # Case 4: Series B, (omega, alpha, beta, phi) = (0.0001, 0.00, 0.90, 0.20)\n        {\"r\": series_B_r, \"f\": series_B_f, \"params\": (0.0001, 0.00, 0.90, 0.20)},\n    ]\n\n    results = []\n    for case in test_cases:\n        h_T, h_Tplus1, nll = calculate_factor_garch(case[\"r\"], case[\"f\"], case[\"params\"])\n        results.extend([\n            round(h_T, 6),\n            round(h_Tplus1, 6),\n            round(nll, 6)\n        ])\n\n    # Format the final output string to 6 decimal places.\n    # The format specifier ensures trailing zeros are included.\n    formatted_results = [f\"{x:.6f}\" for x in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "金融市场的结构并非一成不变，监管政策、技术革新或经济危机等重大事件都可能从根本上改变其动态行为。这个高级练习  将带你探索如何检验波动率聚集现象是否存在“结构性突变”。你不仅将学习如何生成一个包含参数变化的 GARCH 序列，还将应用一种强大的非参数检验方法——循环移位随机化检验，来评估观测到的变化是否具有统计显著性。这项实践让你能够处理关于模型随时间稳定性的复杂问题，是超越标准参数检验的重要一步。",
            "id": "2411151",
            "problem": "给定一个计算经济学和金融学中的概念性问题：确定引入交易暂停（熔断机制）是否改变了某股票指数的波动率聚集行为。波动率聚集是指（绝对值）大的收益率之后倾向于跟随大的收益率，而小的收益率之后倾向于跟随小的收益率，从而导致波动率度量的持续性。\n\n编写一个完整且可运行的程序，该程序针对指定套件中的每个测试用例，仅使用此处陈述的定义来执行以下所有步骤。\n\n- 数据生成过程：\n  - 假设干预前（断点前）和干预后（断点后）的收益率序列是通过连接一个一阶高斯广义自回归条件异方差（GARCH(1,1)）模型的两个片段生成的。时间指数 $t$ 处的创新项为 $r_t$，其中 $r_t = \\sigma_t z_t$，而 $z_t \\sim \\mathcal{N}(0,1)$ 是独立同分布的。条件方差 $\\sigma_t^2$ 根据以下公式演化：\n  $$\n  \\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2,\n  $$\n  其中 $\\omega > 0$，$\\alpha \\ge 0$，$\\beta \\ge 0$，并且为满足协方差平稳性，$\\alpha + \\beta  1$。\n  - 对于长度为 $n_{\\text{pre}}$ 的断点前片段，使用参数 $(\\omega_{\\text{pre}}, \\alpha_{\\text{pre}}, \\beta_{\\text{pre}})$。对于长度为 $n_{\\text{post}}$ 的断点后片段，使用参数 $(\\omega_{\\text{post}}, \\alpha_{\\text{post}}, \\beta_{\\text{post}})$。\n  - 对于断点前片段，在 $t=1$ 处初始化递推，设置 $\\sigma_0^2 = \\omega_{\\text{pre}} / \\left(1 - \\alpha_{\\text{pre}} - \\beta_{\\text{pre}}\\right)$ 和 $r_0 = 0$。对 $t=1,2,\\dots,n_{\\text{pre}}$ 演化断点前片段。\n  - 在断点处，即 $t = n_{\\text{pre}} + 1$ 之前，切换到断点后参数。使用最后实现的数值 $r_{n_{\\text{pre}}}$ 和 $\\sigma_{n_{\\text{pre}}}^2$ 作为断点后片段方差递推的初始条件，继续对 $t = n_{\\text{pre}} + 1, \\dots, n_{\\text{pre}} + n_{\\text{post}}$ 进行递推。\n  - 在整个过程中，根据需要使用相同的独立标准正态创新项 $z_t$ 序列。整个程序必须在开始时将伪随机数生成器种子设置为 $12345$，以确保结果是可复现的。\n\n- 波动率聚集指数：\n  - 对于每个片段（断点前和断点后），定义平方收益率序列 $s_t = r_t^2$。\n  - 对于每个片段，将平方收益率的滞后1阶样本自相关定义为：\n  $$\n  \\rho_1 = \\frac{\\sum_{t=2}^{n} \\left(s_t - \\bar{s}\\right)\\left(s_{t-1} - \\bar{s}\\right)}{\\sum_{t=1}^{n} \\left(s_t - \\bar{s}\\right)^2},\n  $$\n  其中 $n$ 是片段长度，$\\bar{s} = \\frac{1}{n}\\sum_{t=1}^{n} s_t$。\n  - 令 $\\rho_{\\text{pre}}$ 为断点前片段的值，$\\rho_{\\text{post}}$ 为断点后片段的值。将观测到的检验统计量定义为：\n  $$\n  D_{\\text{obs}} = \\rho_{\\text{post}} - \\rho_{\\text{pre}}.\n  $$\n\n- 通过循环移位随机化进行假设检验：\n  - 考虑原假设，即干预并未改变波动率聚集，因此数据是由单一的平稳过程生成的，其聚集行为没有发生变化。在此原假设和平稳性下，循环移位平方收益率序列会保持其联合分布不变，同时保持片段长度固定。\n  - 令 $T = n_{\\text{pre}} + n_{\\text{post}}$ 且 $s_1, s_2, \\dots, s_T$ 为完整的平方收益率序列。对于每个随机移位 $k \\in \\{0,1,\\dots,T-1\\}$，定义循环移位后的序列为 $s_t^{(k)} = s_{((t-1-k) \\bmod T)+1}$，其中 $t=1,\\dots,T$。对于每次移位，将 $s^{(k)}$ 分割成一个长度为 $n_{\\text{pre}}$ 的断点前片段和一个长度为 $n_{\\text{post}}$ 的断点后片段，计算相应的样本自相关 $\\rho_{\\text{pre}}^{(k)}$ 和 $\\rho_{\\text{post}}^{(k)}$，并定义：\n  $$\n  D^{(k)} = \\rho_{\\text{post}}^{(k)} - \\rho_{\\text{pre}}^{(k)}.\n  $$\n  - 对于每个测试用例，执行 $K$ 次独立的随机移位（每次从 $\\{0,1,\\dots,T-1\\}$ 中均匀抽取 $k$）以生成 $\\{D^{(k)}\\}_{k=1}^K$。使用加一法将双边p值定义为：\n  $$\n  p = \\frac{1 + \\#\\{k \\in \\{1,\\dots,K\\} : |D^{(k)}| \\ge |D_{\\text{obs}}|\\}}{K + 1}.\n  $$\n  - 对于给定的显著性水平 $\\alpha$，当且仅当 $p \\le \\alpha$ 时，判定干预改变了波动率聚集。\n\n- 测试套件：\n  - 使用以下三个测试用例。所有参数值必须严格按照给定的值使用。在每种情况下，报告一个布尔决策，指示波动率聚集是否发生改变（如果改变则为true，否则为false）。\n    1. 案例A（预期聚集发生变化）：$n_{\\text{pre}} = 1500$, $n_{\\text{post}} = 1500$, $\\omega_{\\text{pre}} = 0.0001$, $\\alpha_{\\text{pre}} = 0.08$, $\\beta_{\\text{pre}} = 0.90$, $\\omega_{\\text{post}} = 0.0001$, $\\alpha_{\\text{post}} = 0.05$, $\\beta_{\\text{post}} = 0.50$, $K = 2000$, $\\alpha = 0.05$。\n    2. 案例B（无变化）：$n_{\\text{pre}} = 1500$, $n_{\\text{post}} = 1500$, $\\omega_{\\text{pre}} = 0.0001$, $\\alpha_{\\text{pre}} = 0.06$, $\\beta_{\\text{pre}} = 0.92$, $\\omega_{\\text{post}} = 0.0001$, $\\alpha_{\\text{post}} = 0.06$, $\\beta_{\\text{post}} = 0.92$, $K = 2000$, $\\alpha = 0.05$。\n    3. 案例C（仅无条件方差发生变化）：$n_{\\text{pre}} = 1500$, $n_{\\text{post}} = 1500$, $\\omega_{\\text{pre}} = 0.0001$, $\\alpha_{\\text{pre}} = 0.07$, $\\beta_{\\text{pre}} = 0.90$, $\\omega_{\\text{post}} = 0.0010$, $\\alpha_{\\text{post}} = 0.07$, $\\beta_{\\text{post}} = 0.90$, $K = 2000$, $\\alpha = 0.05$。\n\n- 最终输出格式：\n  - 您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个测试用例对应一个布尔值，顺序为案例A、案例B、案例C。例如，一个有效的输出如下所示：\n  $$\n  [\\text{True},\\text{False},\\text{False}].\n  $$\n  - 不得打印任何其他文本。\n\n所有计算纯粹是数学上的，无量纲；不涉及物理单位。不使用角度。所有比率或比例必须表示为小数（例如，$0.05$），而不是带百分号的百分比。",
            "solution": "该问题已经过验证，并被确定为有效。它在科学上植根于金融计量经济学的原理，具体来说是使用GARCH($1$,$1$)模型来表示波动率聚集。该问题是良构的，为获得唯一、可复现的解提供了完整且清晰明确的指令、参数和定义。数据生成过程、检验统计量和假设检验程序的定义都是标准的且在数学上是一致的。所有提供的参数值均遵守GARCH模型的平稳性约束。\n\n任务是确定GARCH($1$,$1$)过程参数中的结构性断点是否导致波动率聚集发生统计上显著的变化。波动率聚集通过平方收益率的滞后1阶自相关来衡量。解决方案涉及三个主要阶段：模拟时间序列、计算聚集度量的观测变化，并使用非参数置换检验评估此变化的统计显著性。\n\n对于每个测试用例，该方法通过以下计算步骤序列来实现。\n\n**第1步：生成GARCH($1$,$1$)时间序列**\n\n生成总长度为 $T = n_{\\text{pre}} + n_{\\text{post}}$ 的金融收益率时间序列 $\\{r_t\\}_{t=1}^T$。该过程由 $r_t = \\sigma_t z_t$ 定义，其中 $z_t \\sim \\mathcal{N}(0,1)$ 是独立同分布的标准正态创新项。条件方差 $\\sigma_t^2$ 遵循GARCH($1$,$1$)递推公式：\n$$\n\\sigma_t^2 = \\omega + \\alpha r_{t-1}^2 + \\beta \\sigma_{t-1}^2\n$$\n生成过程分为两个片段：\n- **断点前片段 ($t=1, \\dots, n_{\\text{pre}}$):** 参数为 $(\\omega_{\\text{pre}}, \\alpha_{\\text{pre}}, \\beta_{\\text{pre}})$。在 $t=1$ 处使用无条件方差作为 $\\sigma_0^2$ 的起点，并设置初始平方收益率 $r_0^2$ 为 $0$ 来初始化递推。具体来说，$\\sigma_0^2 = \\omega_{\\text{pre}} / (1 - \\alpha_{\\text{pre}} - \\beta_{\\text{pre}})$ 且 $r_0 = 0$。\n- **断点后片段 ($t=n_{\\text{pre}}+1, \\dots, T$):** 参数切换为 $(\\omega_{\\text{post}}, \\alpha_{\\text{post}}, \\beta_{\\text{post}})$。$\\sigma_{n_{\\text{pre}}+1}^2$ 的递推使用断点前时期的最后可用值，即 $r_{n_{\\text{pre}}}^2$ 和 $\\sigma_{n_{\\text{pre}}}^2$。\n\n为整个序列一次性生成单个随机变量序列 $\\{z_t\\}_{t=1}^T$，以确保创新过程的连续性。固定的随机种子 $12345$ 确保了可复现性。\n\n**第2步：计算观测检验统计量 $D_{\\text{obs}}$**\n\n波动率聚集通过平方收益率 $s_t = r_t^2$ 的滞后1阶样本自相关进行量化。对于长度为 $n$ 的片段，该自相关 $\\rho_1$ 计算如下：\n$$\n\\rho_1 = \\frac{\\sum_{t=2}^{n} (s_t - \\bar{s})(s_{t-1} - \\bar{s})}{\\sum_{t=1}^{n} (s_t - \\bar{s})^2}\n$$\n其中 $\\bar{s}$ 是序列 $\\{s_t\\}_{t=1}^n$ 的样本均值。\n\n该计算分别对断点前平方收益率序列和断点后序列进行，以获得 $\\rho_{\\text{pre}}$ 和 $\\rho_{\\text{post}}$。衡量聚集变化的观测检验统计量是这两个值之间的差：\n$$\nD_{\\text{obs}} = \\rho_{\\text{post}} - \\rho_{\\text{pre}}\n$$\n\n**第3步：通过循环移位随机化进行假设检验**\n\n为了评估 $D_{\\text{obs}}$ 是否具有统计显著性，我们检验原假设 $H_0$，即干预对波动率聚集没有影响。在 $H_0$ 下，整个平方收益率序列 $\\{s_t\\}_{t=1}^T$ 被认为是平稳的。这一性质意味着其统计特征在循环移位下是不变的。这构成了置换检验的基础。\n\n检验统计量的零分布通过以下过程生成：\n- 总共进行 $K$ 次随机循环移位。对于每次试验 $j=1, \\dots, K$，从 $\\{0, 1, \\dots, T-1\\}$ 中均匀抽取一个随机整数移位 $k_j$。\n- 对于每个 $k_j$，将完整序列 $\\{s_t\\}$ 进行循环移位，以创建一个新序列 $\\{s_t^{(k_j)}\\}$。\n- 将这个移位后的序列分割成一个新的长度为 $n_{\\text{pre}}$ 的“断点前”片段和一个长度为 $n_{\\text{post}}$ 的“断点后”片段。\n- 计算相应的自相关 $\\rho_{\\text{pre}}^{(k_j)}$ 和 $\\rho_{\\text{post}}^{(k_j)}$，得到来自置换的检验统计量 $D^{(k_j)} = \\rho_{\\text{post}}^{(k_j)} - \\rho_{\\text{pre}}^{(k_j)}$。\n\n集合 $\\{D^{(k_j)}\\}_{j=1}^K$ 是原假设下检验统计量分布的一个样本。\n\n**第4步：决策规则**\n\n通过将观测统计量 $|D_{\\text{obs}}|$ 与置换统计量绝对值 $|D^{(k_j)}|$ 的分布进行比较来计算双边p值。使用加一法来处理有限样本，p值为：\n$$\np = \\frac{1 + \\#\\{j \\in \\{1,\\dots,K\\} : |D^{(k_j)}| \\ge |D_{\\text{obs}}|\\}}{K + 1}\n$$\n通过将p值与预先指定的显著性水平 $\\alpha$ 进行比较来做出最终决策。如果 $p \\le \\alpha$，我们拒绝原假设，并得出结论：结构性断点显著改变了波动率聚集行为。否则，我们未能拒绝原假设。每个测试用例的结果是一个布尔值，表示此决策。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the final results.\n    \"\"\"\n    # Set the pseudorandom number generator seed for reproducibility of the entire program.\n    np.random.seed(12345)\n\n    test_cases = [\n        # Case A (expected change in clustering)\n        {\n            \"n_pre\": 1500, \"n_post\": 1500,\n            \"params_pre\": {\"omega\": 0.0001, \"alpha\": 0.08, \"beta\": 0.90},\n            \"params_post\": {\"omega\": 0.0001, \"alpha\": 0.05, \"beta\": 0.50},\n            \"K\": 2000, \"alpha_sig\": 0.05\n        },\n        # Case B (no change)\n        {\n            \"n_pre\": 1500, \"n_post\": 1500,\n            \"params_pre\": {\"omega\": 0.0001, \"alpha\": 0.06, \"beta\": 0.92},\n            \"params_post\": {\"omega\": 0.0001, \"alpha\": 0.06, \"beta\": 0.92},\n            \"K\": 2000, \"alpha_sig\": 0.05\n        },\n        # Case C (change in unconditional variance only)\n        {\n            \"n_pre\": 1500, \"n_post\": 1500,\n            \"params_pre\": {\"omega\": 0.0001, \"alpha\": 0.07, \"beta\": 0.90},\n            \"params_post\": {\"omega\": 0.0010, \"alpha\": 0.07, \"beta\": 0.90},\n            \"K\": 2000, \"alpha_sig\": 0.05\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        decision = perform_test(case)\n        results.append(decision)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_rho(s):\n    \"\"\"\n    Calculates the lag-1 sample autocorrelation of a series.\n    \n    Args:\n        s (np.ndarray): The input series (squared returns).\n        \n    Returns:\n        float: The sample autocorrelation at lag 1.\n    \"\"\"\n    if len(s)  2:\n        return 0.0\n    \n    s_bar = np.mean(s)\n    s_dev = s - s_bar\n    numerator = np.dot(s_dev[1:], s_dev[:-1])\n    denominator = np.dot(s_dev, s_dev)\n    \n    if denominator == 0:\n        return 0.0\n        \n    return numerator / denominator\n\ndef generate_garch_series(n_pre, n_post, params_pre, params_post):\n    \"\"\"\n    Generates a GARCH(1,1) time series with a structural break.\n    \n    Args:\n        n_pre (int): Length of the pre-break segment.\n        n_post (int): Length of the post-break segment.\n        params_pre (dict): GARCH parameters for the pre-break segment.\n        params_post (dict): GARCH parameters for the post-break segment.\n        \n    Returns:\n        np.ndarray: The generated return series r_t.\n    \"\"\"\n    T = n_pre + n_post\n    r = np.zeros(T)\n    sigma_sq = np.zeros(T)\n    z = np.random.standard_normal(T)\n\n    # Pre-break segment\n    omega_pre = params_pre[\"omega\"]\n    alpha_pre = params_pre[\"alpha\"]\n    beta_pre = params_pre[\"beta\"]\n    \n    # Initialization\n    r_prev_sq = 0.0  # r_0^2 = 0\n    sigma_sq_prev = omega_pre / (1.0 - alpha_pre - beta_pre) # sigma_0^2\n\n    for t in range(n_pre):\n        sigma_sq[t] = omega_pre + alpha_pre * r_prev_sq + beta_pre * sigma_sq_prev\n        r[t] = np.sqrt(sigma_sq[t]) * z[t]\n        \n        r_prev_sq = r[t]**2\n        sigma_sq_prev = sigma_sq[t]\n\n    # Post-break segment\n    omega_post = params_post[\"omega\"]\n    alpha_post = params_post[\"alpha\"]\n    beta_post = params_post[\"beta\"]\n\n    for t in range(n_pre, T):\n        sigma_sq[t] = omega_post + alpha_post * r_prev_sq + beta_post * sigma_sq_prev\n        r[t] = np.sqrt(sigma_sq[t]) * z[t]\n\n        r_prev_sq = r[t]**2\n        sigma_sq_prev = sigma_sq[t]\n        \n    return r\n\ndef perform_test(case):\n    \"\"\"\n    Performs the full hypothesis test for a single test case.\n    \n    Args:\n        case (dict): A dictionary containing all parameters for the test case.\n        \n    Returns:\n        bool: True if clustering changed (H0 rejected), False otherwise.\n    \"\"\"\n    n_pre = case[\"n_pre\"]\n    n_post = case[\"n_post\"]\n    params_pre = case[\"params_pre\"]\n    params_post = case[\"params_post\"]\n    K = case[\"K\"]\n    alpha_sig = case[\"alpha_sig\"]\n    \n    T = n_pre + n_post\n\n    # Step 1: Generate data and compute observed statistic\n    r = generate_garch_series(n_pre, n_post, params_pre, params_post)\n    s = r**2\n    \n    s_pre = s[:n_pre]\n    s_post = s[n_pre:]\n    \n    rho_pre = calculate_rho(s_pre)\n    rho_post = calculate_rho(s_post)\n    \n    D_obs = rho_post - rho_pre\n\n    # Step 2: Perform circular-shift randomization test\n    shifts = np.random.randint(0, T, size=K)\n    count_ge = 0\n    \n    for k in shifts:\n        s_shifted = np.roll(s, shift=int(k))\n        \n        s_shifted_pre = s_shifted[:n_pre]\n        s_shifted_post = s_shifted[n_pre:]\n        \n        rho_pre_k = calculate_rho(s_shifted_pre)\n        rho_post_k = calculate_rho(s_shifted_post)\n        \n        D_k = rho_post_k - rho_pre_k\n        \n        if abs(D_k) >= abs(D_obs):\n            count_ge += 1\n\n    # Step 3: Calculate p-value and make decision\n    p_value = (1 + count_ge) / (K + 1)\n    \n    decision = p_value = alpha_sig\n    return decision\n\n# Execute the main function when the script is run.\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}