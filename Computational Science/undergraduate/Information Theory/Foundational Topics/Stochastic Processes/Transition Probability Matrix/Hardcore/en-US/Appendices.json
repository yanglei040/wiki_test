{
    "hands_on_practices": [
        {
            "introduction": "The most fundamental application of a transition probability matrix is to predict the state of a system one step into the future. This introductory exercise  walks you through this core mechanic using a simple weather model. By multiplying the initial probability distribution of weather states by the transition matrix, you will calculate the likelihood of seeing a cloudy day, providing a tangible example of how these matrices model system evolution.",
            "id": "1345175",
            "problem": "A simplified weather model for the city of Aeridor considers three possible states for any given day: State 1 (Sunny), State 2 (Cloudy), and State 3 (Rainy). The day-to-day weather transitions are probabilistic and can be described by a one-step transition matrix $P$, where the entry $P_{ij}$ represents the probability that the weather will be in state $j$ tomorrow, given that it is in state $i$ today. The transition matrix is given by:\n$$\nP = \\begin{pmatrix} 0.70  0.20  0.10 \\\\ 0.30  0.50  0.20 \\\\ 0.20  0.60  0.20 \\end{pmatrix}\n$$\nBased on satellite data and atmospheric readings, meteorologists determine that for a particular Tuesday, the probabilities of the weather being Sunny, Cloudy, or Rainy are not known with certainty. Instead, they are described by the initial probability distribution vector $v_0 = [0.15, 0.65, 0.20]$, where the first, second, and third components correspond to the probabilities of the weather being Sunny, Cloudy, and Rainy, respectively.\n\nGiven this information, calculate the probability that the weather in Aeridor will be Cloudy on Wednesday. Round your final answer to three significant figures.",
            "solution": "The problem asks for the probability of being in a specific state (Cloudy) after one time step (from Tuesday to Wednesday), given an initial probability distribution and a transition matrix.\n\nLet $v_0$ be the row vector representing the initial probability distribution of the states on Tuesday. The components of $v_0$ are the probabilities of the weather being Sunny, Cloudy, and Rainy, respectively.\n$$\nv_0 = [P(\\text{Sunny on Tue}), P(\\text{Cloudy on Tue}), P(\\text{Rainy on Tue})] = [0.15, 0.65, 0.20]\n$$\nLet $v_1$ be the row vector representing the probability distribution of the states on Wednesday. The components of $v_1$ are the probabilities we want to find.\n$$\nv_1 = [P(\\text{Sunny on Wed}), P(\\text{Cloudy on Wed}), P(\\text{Rainy on Wed})]\n$$\nThe relationship between the probability distribution at one time step and the next is given by the matrix multiplication of the current state distribution vector and the transition matrix $P$.\n$$\nv_1 = v_0 P\n$$\nWe are given the transition matrix $P$:\n$$\nP = \\begin{pmatrix} 0.70  0.20  0.10 \\\\ 0.30  0.50  0.20 \\\\ 0.20  0.60  0.20 \\end{pmatrix}\n$$\nNow, we perform the matrix-vector multiplication:\n$$\nv_1 = [0.15, 0.65, 0.20] \\begin{pmatrix} 0.70  0.20  0.10 \\\\ 0.30  0.50  0.20 \\\\ 0.20  0.60  0.20 \\end{pmatrix}\n$$\nThe first component of $v_1$, $P(\\text{Sunny on Wed})$, is calculated as:\n$$\nv_{1,1} = (0.15)(0.70) + (0.65)(0.30) + (0.20)(0.20) = 0.105 + 0.195 + 0.040 = 0.340\n$$\nThe second component of $v_1$, $P(\\text{Cloudy on Wed})$, is calculated as:\n$$\nv_{1,2} = (0.15)(0.20) + (0.65)(0.50) + (0.20)(0.60) = 0.030 + 0.325 + 0.120 = 0.475\n$$\nThe third component of $v_1$, $P(\\text{Rainy on Wed})$, is calculated as:\n$$\nv_{1,3} = (0.15)(0.10) + (0.65)(0.20) + (0.20)(0.20) = 0.015 + 0.130 + 0.040 = 0.185\n$$\nSo, the probability distribution for Wednesday is:\n$$\nv_1 = [0.340, 0.475, 0.185]\n$$\nAs a check, the components of $v_1$ should sum to 1: $0.340 + 0.475 + 0.185 = 1.000$. This confirms our calculation is a valid probability distribution.\n\nThe problem specifically asks for the probability that the weather will be Cloudy on Wednesday. This corresponds to the second component of the vector $v_1$.\n$$\nP(\\text{Cloudy on Wed}) = v_{1,2} = 0.475\n$$\nThe value $0.475$ already has three significant figures ($4$, $7$, and $5$), so no further rounding is needed.",
            "answer": "$$\\boxed{0.475}$$"
        },
        {
            "introduction": "Building on one-step predictions, we often want to forecast a system's behavior further into the future. This practice  explores how to determine the probability of a system's state after two time steps. You will apply the principles of multi-step transitions, which involve squaring the transition matrix, to predict a user's sentiment two days from now, demonstrating how to analyze longer-term dynamics.",
            "id": "1665046",
            "problem": "A simplified machine learning model is designed to predict a user's daily sentiment about a mobile application. The model classifies the user's sentiment into one of three states: 'Positive', 'Neutral', or 'Negative'. The transitions between these states from one day to the next are modeled as a Markov chain.\n\nThe transition probabilities are as follows:\n- If a user's sentiment is 'Positive' on a given day, the probability that it will be 'Positive' the next day is $\\frac{1}{2}$, 'Neutral' is $\\frac{1}{4}$, and 'Negative' is $\\frac{1}{4}$.\n- If a user's sentiment is 'Neutral' on a given day, the probability of transitioning to 'Positive', 'Neutral', or 'Negative' the next day is $\\frac{1}{3}$ for each state.\n- If a user's sentiment is 'Negative' on a given day, the probability that it will be 'Positive' the next day is $\\frac{1}{10}$, 'Neutral' is $\\frac{3}{10}$, and 'Negative' is $\\frac{3}{5}$.\n\nSuppose a new user's sentiment is recorded as 'Positive' on their first day of using the app (Day 1). What is the probability that their sentiment will be 'Positive' again on Day 3?\n\nExpress your answer as an exact fraction in simplest form.",
            "solution": "Model the sentiments as a Markov chain on the state set $\\{ \\text{Pos}, \\text{Neu}, \\text{Neg} \\}$ with transition matrix $T$ ordered as $(\\text{Pos}, \\text{Neu}, \\text{Neg})$:\n$$\nT=\\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{4}  \\frac{1}{4} \\\\\n\\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\\\\n\\frac{1}{10}  \\frac{3}{10}  \\frac{3}{5}\n\\end{pmatrix}.\n$$\nThe user is in state $\\text{Pos}$ on Day 1, so the probability of being in $\\text{Pos}$ on Day 3 is the two-step transition probability from $\\text{Pos}$ to $\\text{Pos}$, namely the $(1,1)$ entry of $T^{2}$. By the Chapman-Kolmogorov equation,\n$$\np^{(2)}_{\\text{Pos},\\text{Pos}}=\\sum_{s \\in \\{\\text{Pos}, \\text{Neu}, \\text{Neg}\\}} p_{\\text{Pos},s}\\,p_{s,\\text{Pos}}\n= p_{\\text{Pos},\\text{Pos}}\\,p_{\\text{Pos},\\text{Pos}} + p_{\\text{Pos},\\text{Neu}}\\,p_{\\text{Neu},\\text{Pos}} + p_{\\text{Pos},\\text{Neg}}\\,p_{\\text{Neg},\\text{Pos}}.\n$$\nSubstitute the given transition probabilities:\n$$\np^{(2)}_{\\text{Pos},\\text{Pos}}=\\frac{1}{2}\\cdot\\frac{1}{2}+\\frac{1}{4}\\cdot\\frac{1}{3}+\\frac{1}{4}\\cdot\\frac{1}{10}\n=\\frac{1}{4}+\\frac{1}{12}+\\frac{1}{40}.\n$$\nCombine the fractions using the common denominator $120$:\n$$\n\\frac{1}{4}+\\frac{1}{12}+\\frac{1}{40}=\\frac{30}{120}+\\frac{10}{120}+\\frac{3}{120}=\\frac{43}{120}.\n$$\nThus, the probability that the sentiment is $\\text{Pos}$ on Day 3 given it was $\\text{Pos}$ on Day 1 is $\\frac{43}{120}$.",
            "answer": "$$\\boxed{\\frac{43}{120}}$$"
        },
        {
            "introduction": "This advanced exercise  moves beyond using a pre-defined matrix to the crucial skill of constructing one from a system's fundamental rules. You will model a digital communication channel where the output depends on a linear transformation of the input and a random noise component. This problem challenges you to derive the channel's complete $4 \\times 4$ transition matrix, offering a deeper insight into how these matrices mathematically represent complex, real-world processes.",
            "id": "1665086",
            "problem": "Consider a discrete memoryless channel that takes a 2-bit input vector $X = (x_1, x_2)$ and produces a 2-bit output vector $Y = (y_1, y_2)$, where all components are binary ($0$ or $1$). The relationship between the input and output is governed by the equation $Y = AX + N \\pmod 2$, where all additions and multiplications are performed in the finite field of two elements, $\\mathbb{F}_2$.\n\nThe input space $\\mathcal{X}$ and output space $\\mathcal{Y}$ both consist of the four possible 2-bit vectors. Let these vectors be ordered lexicographically as $v_1 = (0,0)$, $v_2 = (0,1)$, $v_3 = (1,0)$, and $v_4 = (1,1)$.\n\nThe matrix $A$ is a fixed, invertible transformation matrix given by:\n$$A = \\begin{pmatrix} 1  1 \\\\ 1  0 \\end{pmatrix}$$\nThe term $N = (n_1, n_2)$ is a random noise vector whose components $n_1$ and $n_2$ are independent Bernoulli random variables with probabilities of being non-zero given by $P(n_1=1) = \\frac{1}{3}$ and $P(n_2=1) = \\frac{1}{4}$.\n\nYour task is to determine the $4 \\times 4$ transition probability matrix $T$ for this channel. The entry $T_{ij}$ in the $i$-th row and $j$-th column of the matrix must represent the conditional probability $P(Y=v_j | X=v_i)$.",
            "solution": "We work over $\\mathbb{F}_{2}$, so addition and subtraction are the same (both are XOR). The channel law is $Y=AX+N$ with $A$ fixed and $N=(n_{1},n_{2})$ having independent components: $P(n_{1}=1)=\\frac{1}{3}$ so $P(n_{1}=0)=\\frac{2}{3}$, and $P(n_{2}=1)=\\frac{1}{4}$ so $P(n_{2}=0)=\\frac{3}{4}$. Hence, for any $n=(n_{1},n_{2})$,\n$$\nP(N=n)=\\begin{cases}\n\\frac{1}{2},  n=(0,0),\\\\\n\\frac{1}{6},  n=(0,1),\\\\\n\\frac{1}{4},  n=(1,0),\\\\\n\\frac{1}{12},  n=(1,1).\n\\end{cases}\n$$\nGiven $X=x$ and $Y=y$, we have $y=Ax+N$, so $N=y+Ax$ (with $+$ denoting addition in $\\mathbb{F}_{2}$). Therefore,\n$$\nP(Y=y\\mid X=x)=P\\bigl(N=y+Ax\\bigr).\n$$\nLet the ordered vectors be $v_{1}=(0,0)$, $v_{2}=(0,1)$, $v_{3}=(1,0)$, $v_{4}=(1,1)$. Compute $z_{i}=Av_{i}$ for $i=1,2,3,4$ using $A=\\begin{pmatrix}1  1 \\\\ 1  0\\end{pmatrix}$:\n$$\nAv_{1}=(0,0),\\quad Av_{2}=(1,0),\\quad Av_{3}=(1,1),\\quad Av_{4}=(0,1).\n$$\nFor each input $v_{i}$ and output $v_{j}$, $T_{ij}=P(Y=v_{j}\\mid X=v_{i})=P(N=v_{j}+z_{i})$. Using the noise probabilities above, the rows (indexed by $i$) are obtained by mapping $v_{j}$ to $v_{j}+z_{i}$:\n- For $i=1$ ($z_{1}=(0,0)$): $(\\frac{1}{2},\\frac{1}{6},\\frac{1}{4},\\frac{1}{12})$.\n- For $i=2$ ($z_{2}=(1,0)$): $(\\frac{1}{4},\\frac{1}{12},\\frac{1}{2},\\frac{1}{6})$.\n- For $i=3$ ($z_{3}=(1,1)$): $(\\frac{1}{12},\\frac{1}{4},\\frac{1}{6},\\frac{1}{2})$.\n- For $i=4$ ($z_{4}=(0,1)$): $(\\frac{1}{6},\\frac{1}{2},\\frac{1}{12},\\frac{1}{4})$.",
            "answer": "$$\\boxed{\\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{6}  \\frac{1}{4}  \\frac{1}{12} \\\\\n\\frac{1}{4}  \\frac{1}{12}  \\frac{1}{2}  \\frac{1}{6} \\\\\n\\frac{1}{12}  \\frac{1}{4}  \\frac{1}{6}  \\frac{1}{2} \\\\\n\\frac{1}{6}  \\frac{1}{2}  \\frac{1}{12}  \\frac{1}{4}\n\\end{pmatrix}}$$"
        }
    ]
}