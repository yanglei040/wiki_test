{
    "hands_on_practices": [
        {
            "introduction": "To begin, we focus on the fundamental mechanics of a Markov chain's evolution over a short time scale. This exercise asks you to calculate the probability of a specific two-step sequence of states, which is a core skill for understanding how the system moves from one moment to the next. By applying the chain rule of probability and the law of total probability, you will directly use the initial conditions and transition matrix to trace the system's path, reinforcing the 'memoryless' property that defines these chains .",
            "id": "1639051",
            "problem": "A simplified biophysical model describes the transcriptional activity of a particular gene. The gene's promoter can exist in one of two states: 'ON' (actively transcribing messenger RNA) or 'OFF' (inactive). The state of the gene at a discrete time step $n$ is represented by the random variable $X_n$. This process is modeled as a time-homogeneous Markov chain.\n\nAt the beginning of the observation, at time $n=0$, the probability that the gene is in the 'ON' state is given as $P(X_0 = \\text{'ON'}) = \\frac{1}{3}$.\n\nThe state transitions over a single time step are governed by the following probabilities:\n- The probability that a gene in the 'ON' state at time $n$ remains in the 'ON' state at time $n+1$ is $0.8$.\n- The probability that a gene in the 'OFF' state at time $n$ transitions to the 'ON' state at time $n+1$ is $0.4$.\n\nCalculate the joint probability that the gene is in the 'ON' state at time step $n=1$ and in the 'OFF' state at time step $n=2$. In other words, find the value of $P(X_1 = \\text{'ON'}, X_2 = \\text{'OFF'})$. Express your final answer as a decimal rounded to three significant figures.",
            "solution": "The problem asks for the joint probability $P(X_1 = \\text{'ON'}, X_2 = \\text{'OFF'})$. We can solve this by first defining the states and the transition probabilities, then using the properties of Markov chains and the chain rule of probability.\n\nLet's denote the two states as $S_{on} = \\text{'ON'}$ and $S_{off} = \\text{'OFF'}$.\n\nFirst, we establish the complete set of initial probabilities and transition probabilities from the information given.\n\nThe initial probabilities at time $n=0$ are:\n$P(X_0 = S_{on}) = \\frac{1}{3}$\nSince there are only two states, the probability of being in the 'OFF' state initially is:\n$P(X_0 = S_{off}) = 1 - P(X_0 = S_{on}) = 1 - \\frac{1}{3} = \\frac{2}{3}$\n\nThe transition probabilities are given as:\n$P(X_{n+1} = S_{on} | X_n = S_{on}) = 0.8$\n$P(X_{n+1} = S_{on} | X_n = S_{off}) = 0.4$\n\nFrom these, we can deduce the other two transition probabilities, as the probabilities of transitioning from a given state must sum to 1:\n$P(X_{n+1} = S_{off} | X_n = S_{on}) = 1 - P(X_{n+1} = S_{on} | X_n = S_{on}) = 1 - 0.8 = 0.2$\n$P(X_{n+1} = S_{off} | X_n = S_{off}) = 1 - P(X_{n+1} = S_{on} | X_n = S_{off}) = 1 - 0.4 = 0.6$\n\nNow, we can calculate the target joint probability $P(X_1 = S_{on}, X_2 = S_{off})$. Using the chain rule for probability, we can write:\n$$P(X_1 = S_{on}, X_2 = S_{off}) = P(X_2 = S_{off} | X_1 = S_{on}) \\times P(X_1 = S_{on})$$\n\nThe first term, $P(X_2 = S_{off} | X_1 = S_{on})$, is the probability of transitioning from 'ON' to 'OFF'. Due to the time-homogeneous property of the Markov chain, this is simply the one-step transition probability we found earlier:\n$$P(X_2 = S_{off} | X_1 = S_{on}) = 0.2$$\n\nThe second term, $P(X_1 = S_{on})$, is the total probability of the gene being in the 'ON' state at time $n=1$. We can calculate this using the law of total probability, summing over the possible states at $n=0$:\n$$P(X_1 = S_{on}) = P(X_1 = S_{on} | X_0 = S_{on})P(X_0 = S_{on}) + P(X_1 = S_{on} | X_0 = S_{off})P(X_0 = S_{off})$$\nSubstituting the known values:\n$$P(X_1 = S_{on}) = (0.8) \\left(\\frac{1}{3}\\right) + (0.4) \\left(\\frac{2}{3}\\right)$$\n$$P(X_1 = S_{on}) = \\frac{0.8}{3} + \\frac{0.8}{3} = \\frac{1.6}{3}$$\n\nNow we can substitute both calculated components back into our original equation for the joint probability:\n$$P(X_1 = S_{on}, X_2 = S_{off}) = (0.2) \\times \\left(\\frac{1.6}{3}\\right)$$\n$$P(X_1 = S_{on}, X_2 = S_{off}) = \\frac{0.32}{3}$$\n$$P(X_1 = S_{on}, X_2 = S_{off}) = 0.10666...$$\n\nThe problem requires the answer to be rounded to three significant figures. The first significant figure is 1, the second is 0, and the third is 6. The next digit is 6, which is 5 or greater, so we round the third significant figure up.\n$$0.10666... \\approx 0.107$$",
            "answer": "$$\\boxed{0.107}$$"
        },
        {
            "introduction": "Having practiced with short-term predictions, we now turn to the long-term behavior of a Markov chain. Many systems, after running for a long time, settle into a predictable equilibrium, and this problem challenges you to find that steady state, known as the stationary distribution . Calculating this distribution is a foundational skill in analyzing Markov chains, revealing the long-run fraction of time the system is expected to spend in each state, regardless of its starting point.",
            "id": "1639083",
            "problem": "A new model of a robotic vacuum cleaner is being tested in a small apartment that consists of three rooms: a Living Room, a Kitchen, and a Bedroom. The robot's movement between these rooms is probabilistic and can be described by a discrete-time Markov chain. The state of the system is the room the robot currently occupies. After each cleaning cycle in a room, the robot decides its next location based on a fixed set of probabilities.\n\nThe movement rules are as follows:\n- When the robot is in the Living Room, it has a probability of $\\frac{1}{2}$ of remaining in the Living Room for the next cycle and a probability of $\\frac{1}{2}$ of moving to the Kitchen. It cannot move directly from the Living Room to the Bedroom.\n- When the robot is in the Kitchen, it always moves to a different room. It moves to the Living Room with a probability of $\\frac{1}{3}$ and to the Bedroom with a probability of $\\frac{2}{3}$.\n- When the robot is in the Bedroom, it has a probability of $\\frac{1}{4}$ of remaining in the Bedroom for the next cycle and a probability of $\\frac{3}{4}$ of moving to the Kitchen. It cannot move directly from the Bedroom to the Living Room.\n\nAfter the robot has been operating for a very long time, the probability of finding it in any given room approaches a steady state. This is known as the stationary distribution of the Markov chain.\n\nCalculate this stationary distribution. Present your answer as a row matrix of the form $(\\pi_L, \\pi_K, \\pi_B)$, where $\\pi_L$, $\\pi_K$, and $\\pi_B$ represent the long-term probabilities of finding the robot in the Living Room, Kitchen, and Bedroom, respectively. Express these probabilities as exact fractions.",
            "solution": "Model the robotâ€™s movement as a discrete-time Markov chain with states ordered as Living Room (L), Kitchen (K), Bedroom (B). The transition matrix $P$ with rows summing to $1$ is\n$$\nP=\\begin{pmatrix}\n\\frac{1}{2}  \\frac{1}{2}  0 \\\\\n\\frac{1}{3}  0  \\frac{2}{3} \\\\\n0  \\frac{3}{4}  \\frac{1}{4}\n\\end{pmatrix}.\n$$\nLet the stationary distribution be $\\pi=(\\pi_{L},\\pi_{K},\\pi_{B})$, a row vector satisfying $\\pi=\\pi P$ and $\\pi_{L}+\\pi_{K}+\\pi_{B}=1$. Writing component equations from $\\pi=\\pi P$ gives\n$$\n\\pi_{L}=\\frac{1}{2}\\pi_{L}+\\frac{1}{3}\\pi_{K},\\quad\n\\pi_{K}=\\frac{1}{2}\\pi_{L}+\\frac{3}{4}\\pi_{B},\\quad\n\\pi_{B}=\\frac{2}{3}\\pi_{K}+\\frac{1}{4}\\pi_{B}.\n$$\nFrom the first equation,\n$$\n\\pi_{L}-\\frac{1}{2}\\pi_{L}=\\frac{1}{3}\\pi_{K}\\;\\Rightarrow\\;\\frac{1}{2}\\pi_{L}=\\frac{1}{3}\\pi_{K}\\;\\Rightarrow\\;\\pi_{K}=\\frac{3}{2}\\pi_{L}.\n$$\nFrom the third equation,\n$$\n\\pi_{B}-\\frac{1}{4}\\pi_{B}=\\frac{2}{3}\\pi_{K}\\;\\Rightarrow\\;\\frac{3}{4}\\pi_{B}=\\frac{2}{3}\\pi_{K}\\;\\Rightarrow\\;\\pi_{B}=\\frac{8}{9}\\pi_{K}.\n$$\nExpressing all in terms of $\\pi_{L}$ using $\\pi_{K}=\\frac{3}{2}\\pi_{L}$ yields\n$$\n\\pi_{B}=\\frac{8}{9}\\cdot\\frac{3}{2}\\pi_{L}=\\frac{4}{3}\\pi_{L}.\n$$\nApply normalization:\n$$\n\\pi_{L}+\\pi_{K}+\\pi_{B}=\\pi_{L}+\\frac{3}{2}\\pi_{L}+\\frac{4}{3}\\pi_{L}=\\left(1+\\frac{3}{2}+\\frac{4}{3}\\right)\\pi_{L}=\\frac{23}{6}\\pi_{L}=1,\n$$\nso\n$$\n\\pi_{L}=\\frac{6}{23},\\quad \\pi_{K}=\\frac{3}{2}\\cdot\\frac{6}{23}=\\frac{9}{23},\\quad \\pi_{B}=\\frac{4}{3}\\cdot\\frac{6}{23}=\\frac{8}{23}.\n$$\nTherefore, the stationary distribution is $(\\frac{6}{23},\\frac{9}{23},\\frac{8}{23})$.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{6}{23}  \\frac{9}{23}  \\frac{8}{23} \\end{pmatrix}}$$"
        },
        {
            "introduction": "This final practice demonstrates the practical utility of Markov models by applying them to a central problem in information theory: data compression. You will quantify the advantage of using a state-aware encoding scheme over a simpler, memoryless one, a concept crucial for designing efficient compressors for sources like text and DNA . This exercise bridges theory and application, showing how modeling the dependencies between symbols with a Markov chain can lead to significant improvements in compression efficiency.",
            "id": "1639043",
            "problem": "A discrete-time, time-homogeneous Markov source produces a sequence of symbols from the alphabet $\\mathcal{S} = \\{A, B, C\\}$. The state of the source at any time corresponds to the symbol it has just emitted. The state transitions are governed by the following right stochastic matrix $P$, where the entry $P_{ij}$ represents the probability of transitioning from state $i$ to state $j$. The states are ordered as $(A, B, C)$.\n\n$$\nP = \\begin{pmatrix}\n0.8  0.1  0.1 \\\\\n0.2  0.6  0.2 \\\\\n0.1  0.2  0.7\n\\end{pmatrix}\n$$\n\nTwo different binary encoding strategies are being evaluated for compressing the output of this source.\n- **Strategy 1:** A single, static Huffman code is designed based on the unconditional probabilities of the symbols, as determined by the source's stationary distribution.\n- **Strategy 2:** A set of three distinct Huffman codes is used. The choice of codebook for the current symbol depends on the previously emitted symbol (the previous state).\n\nCalculate the compression efficiency gain achieved by using Strategy 2 over Strategy 1. This gain is defined as the reduction in the long-run average codeword length per symbol.\n\nExpress your final answer in units of bits/symbol, rounded to three significant figures.",
            "solution": "Let the stationary symbol probabilities be $s_{A}, s_{B}, s_{C}$ with $s_{A}+s_{B}+s_{C}=1$ and $(s_{A},s_{B},s_{C})P=(s_{A},s_{B},s_{C})$. From\n$$\n\\begin{aligned}\ns_{A}=0.8 s_{A}+0.2 s_{B}+0.1 s_{C},\\\\\ns_{B}=0.1 s_{A}+0.6 s_{B}+0.2 s_{C},\n\\end{aligned}\n$$\nwe obtain $2 s_{A}-2 s_{B}-s_{C}=0$ and $4 s_{B}-s_{A}-2 s_{C}=0$. Solving with $s_{A}+s_{B}+s_{C}=1$ gives\n$$\ns_{A}=\\frac{8}{19},\\quad s_{B}=\\frac{5}{19},\\quad s_{C}=\\frac{6}{19}.\n$$\n\nStrategy 1 uses a single Huffman code for $(s_{A},s_{B},s_{C})=(\\frac{8}{19},\\frac{5}{19},\\frac{6}{19})$. For three symbols, the optimal prefix lengths are $(1,2,2)$ with the largest probability assigned length $1$. The expected length is\n$$\nL_{1}=\\frac{8}{19}\\cdot 1+\\frac{5}{19}\\cdot 2+\\frac{6}{19}\\cdot 2=\\frac{30}{19}.\n$$\n\nStrategy 2 uses context-dependent Huffman codes based on the conditional distributions given the previous symbol, i.e., the rows of $P$.\n- Given $A$: $(0.8,0.1,0.1)=(\\frac{4}{5},\\frac{1}{10},\\frac{1}{10})$ yields lengths $(1,2,2)$ and\n$$\nL_{A}=\\frac{4}{5}\\cdot 1+\\frac{1}{10}\\cdot 2+\\frac{1}{10}\\cdot 2=\\frac{6}{5}.\n$$\n- Given $B$: $(0.2,0.6,0.2)=(\\frac{1}{5},\\frac{3}{5},\\frac{1}{5})$ yields lengths $(2,1,2)$ and\n$$\nL_{B}=\\frac{3}{5}\\cdot 1+\\frac{1}{5}\\cdot 2+\\frac{1}{5}\\cdot 2=\\frac{7}{5}.\n$$\n- Given $C$: $(0.1,0.2,0.7)=(\\frac{1}{10},\\frac{1}{5},\\frac{7}{10})$ yields lengths $(2,2,1)$ and\n$$\nL_{C}=\\frac{7}{10}\\cdot 1+\\frac{1}{5}\\cdot 2+\\frac{1}{10}\\cdot 2=\\frac{13}{10}.\n$$\nThe long-run average code length under Strategy 2 is the stationary average over contexts:\n$$\nL_{2}=s_{A}L_{A}+s_{B}L_{B}+s_{C}L_{C}\n=\\frac{8}{19}\\cdot\\frac{6}{5}+\\frac{5}{19}\\cdot\\frac{7}{5}+\\frac{6}{19}\\cdot\\frac{13}{10}\n=\\frac{48}{95}+\\frac{35}{95}+\\frac{39}{95}=\\frac{122}{95}.\n$$\n\nThe compression efficiency gain is the reduction $L_{1}-L_{2}$:\n$$\nL_{1}-L_{2}=\\frac{30}{19}-\\frac{122}{95}=\\frac{150-122}{95}=\\frac{28}{95}\\approx 0.2947368421.\n$$\nRounded to three significant figures, the gain is $0.295$ bits/symbol.",
            "answer": "$$\\boxed{0.295}$$"
        }
    ]
}