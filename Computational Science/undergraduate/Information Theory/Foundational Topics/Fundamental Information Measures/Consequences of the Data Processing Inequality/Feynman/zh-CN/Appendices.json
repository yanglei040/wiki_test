{
    "hands_on_practices": [
        {
            "introduction": "数据处理不等式的一个核心推论是：处理数据不能创造信息。这个练习将探讨这一原则最基本的情形：如果我们从两个完全独立的变量 $X$ 和 $Y$ 开始，对其中一个进行任何确定性的处理得到 $Z = g(Y)$，能否凭空产生与另一个变量的关联？通过一个具体的计算，您将亲手验证信息无法被无中生有地创造出来，从而巩固数据处理不等式的基石。",
            "id": "1613376",
            "problem": "在一个半导体生产线的质量控制系统中，我们监控一个特定蚀刻过程的状态。该状态由一个离散随机变量 $X$ 表示，其中 $X=0$ 表示过程成功，$X=1$ 表示过程失败。历史数据显示，失败的概率为 $P(X=1) = \\frac{1}{5}$。\n\n独立地，一个传感器监控洁净室中的环境压力，已知该压力与蚀刻过程的结果无关。压力被量化为四个离散水平之一，由随机变量 $Y \\in \\{1, 2, 3, 4\\}$ 表示。这些压力水平的概率分布由 $P(Y=1) = \\frac{1}{2}$，$P(Y=2) = \\frac{1}{4}$，$P(Y=3) = \\frac{1}{8}$ 和 $P(Y=4) = \\frac{1}{8}$ 给出。\n\n一个实时分析引擎接收原始压力水平 $Y$，并使用确定性函数 $Z = (Y^2 - 1) \\pmod{3}$ 计算一个汇总统计量 $Z$。该汇总统计量被记录下来以供后续分析。\n\n一位工程师想要确定汇总统计量 $Z$ 中是否包含有关过程状态 $X$ 的任何信息。计算过程状态和汇总统计量之间的互信息 $I(X; Z)$。请用比特（bits）表示您的答案。",
            "solution": "两个离散随机变量 $X$ 和 $Z$ 之间的互信息定义为：\n$$I(X; Z) = \\sum_{x \\in \\mathcal{X}} \\sum_{z \\in \\mathcal{Z}} p(x, z) \\log_2 \\left( \\frac{p(x, z)}{p(x) p(z)} \\right)$$\n其中 $p(x, z)$ 是 $(X, Z)$ 的联合概率质量函数，而 $p(x)$ 和 $p(z)$ 分别是 $X$ 和 $Z$ 的边缘概率质量函数。计算将以比特为单位进行，因此我们使用以 2 为底的对数。\n\n我们已知过程状态 $X$ 的概率分布：\n$P(X=1) = \\frac{1}{5}$\n$P(X=0) = 1 - P(X=1) = 1 - \\frac{1}{5} = \\frac{4}{5}$。\n\n我们还已知压力水平 $Y$ 的概率分布：\n$P(Y=1) = \\frac{1}{2}$\n$P(Y=2) = \\frac{1}{4}$\n$P(Y=3) = \\frac{1}{8}$\n$P(Y=4) = \\frac{1}{8}$\n\n汇总统计量 $Z$ 是 $Y$ 的一个确定性函数，由 $Z = g(Y) = (Y^2 - 1) \\pmod{3}$ 给出。首先，我们必须确定 $Z$ 的可能值及其概率分布 $p(z)$。\n- 对于 $Y=1$：$Z = (1^2 - 1) \\pmod{3} = 0 \\pmod{3} = 0$。\n- 对于 $Y=2$：$Z = (2^2 - 1) \\pmod{3} = 3 \\pmod{3} = 0$。\n- 对于 $Y=3$：$Z = (3^2 - 1) \\pmod{3} = 8 \\pmod{3} = 2$。\n- 对于 $Y=4$：$Z = (4^2 - 1) \\pmod{3} = 15 \\pmod{3} = 0$。\n$Z$ 的可能值集合是 $\\mathcal{Z} = \\{0, 2\\}$。\n\n现在我们可以计算边缘概率分布 $p(z)$：\n$P(Z=0) = P(Y=1) + P(Y=2) + P(Y=4) = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} = \\frac{4}{8} + \\frac{2}{8} + \\frac{1}{8} = \\frac{7}{8}$。\n$P(Z=2) = P(Y=3) = \\frac{1}{8}$。\n作为检验，$P(Z=0) + P(Z=2) = \\frac{7}{8} + \\frac{1}{8} = 1$。\n\n接下来，我们需要求出联合概率分布 $p(x, z)$。对于任意一对值 $(x, z)$：\n$p(x, z) = P(X=x, Z=z) = P(X=x, g(Y)=z)$。\n我们可以将其写成对所有映射到 $z$ 的 $y$ 值的求和：\n$P(X=x, g(Y)=z) = \\sum_{y: g(y)=z} P(X=x, Y=y)$。\n\n题目说明过程状态 $X$ 和压力水平 $Y$ 是独立的。因此，它们的联合概率是它们边缘概率的乘积：$P(X=x, Y=y) = P(X=x) P(Y=y)$。\n将此代入 $p(x, z)$ 的表达式中：\n$p(x, z) = \\sum_{y: g(y)=z} \\left( P(X=x) P(Y=y) \\right)$。\n由于 $P(X=x)$ 不依赖于 $y$，我们可以将其从求和中提出来：\n$p(x, z) = P(X=x) \\left( \\sum_{y: g(y)=z} P(Y=y) \\right)$。\n括号中的求和正是 $P(g(Y)=z)$ 的定义，也就是 $P(Z=z)$。\n因此，我们证明了 $p(x, z) = P(X=x) P(Z=z) = p(x) p(z)$。\n\n这个结果意味着随机变量 $X$ 和 $Z$ 是独立的。\n\n现在我们可以计算互信息 $I(X; Z)$。将 $p(x, z) = p(x) p(z)$ 代入互信息的定义中：\n$$I(X; Z) = \\sum_{x \\in \\mathcal{X}} \\sum_{z \\in \\mathcal{Z}} p(x) p(z) \\log_2 \\left( \\frac{p(x) p(z)}{p(x) p(z)} \\right)$$\n$$I(X; Z) = \\sum_{x \\in \\mathcal{X}} \\sum_{z \\in \\mathcal{Z}} p(x) p(z) \\log_2(1)$$\n由于 $\\log_2(1) = 0$，整个表达式变为：\n$$I(X; Z) = \\sum_{x \\in \\mathcal{X}} \\sum_{z \\in \\mathcal{Z}} p(x) p(z) \\cdot 0 = 0$$\n\n另外，我们也可以认识到，由于 $Z$ 是 $Y$ 的一个确定性函数，这些变量构成了一个马尔可夫链 $X \\to Y \\to Z$。数据处理不等式指出，对于任何这样的马尔可夫链，都有 $I(X; Z) \\le I(X; Y)$。\n我们已知 $X$ 和 $Y$ 是独立的。两个独立变量之间的互信息为零，所以 $I(X; Y) = 0$。\n综合这些事实，我们得到 $I(X; Z) \\le 0$。由于互信息总是非负的（$I(X;Z) \\ge 0$），所以唯一可能的值是 $I(X; Z) = 0$。\n\n两种方法都导出了相同的结果。过程状态 $X$ 和汇总统计量 $Z$ 之间的互信息是 0 比特。",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "数据处理不等式 $I(X;Z) \\le I(X;Y)$ 告诉我们信息在处理过程中不会增加，但这是否意味着信息总会减少？这个练习探讨了不等式中等号成立的条件。通过一个关于图像文件压缩的直观场景，您将探索当一个处理步骤是完全可逆的（即无损的）时，互信息会发生什么变化，从而揭示信息在何种条件下可以被完整地保留。",
            "id": "1613402",
            "problem": "考虑一个处理大型数码照片的数据处理流程。原始的、未压缩的原始图像数据由一个离散随机变量 $X$ 表示。\n\n首先，使用一种*有损*压缩算法将此原始图像转换为更常见的格式。这个过程会永久丢弃部分原始图像信息以减小文件大小。这个新的、有损压缩后的图像数据由一个随机变量 $Y$ 表示。由于此步骤是有损的，原始数据 $X$ 无法从 $Y$ 中完美恢复。\n\n其次，使用一种*无损*数据压缩算法（例如常用于 ZIP 压缩包的 Lempel-Ziv 算法）对与 $Y$ 对应的文件进行进一步压缩。这会生成一个由随机变量 $Z$ 表示的最终文件。这第二步是完全可逆的，意味着数据 $Y$ 可以从数据 $Z$ 中精确重构，而没有任何信息损失。\n\n令 $I(A; B)$ 表示两个随机变量 $A$ 和 $B$ 之间的互信息。鉴于这个两步过程，互信息 $I(X; Y)$ 和互信息 $I(X; Z)$ 之间保证成立的最具体关系是什么？\n\nA. $I(X; Y) > I(X; Z)$\n\nB. $I(X; Y)  I(X; Z)$\n\nC. $I(X; Y) = I(X; Z)$\n\nD. $I(X; Y) \\ge I(X; Z)$\n\nE. 从给定信息中无法确定该关系。",
            "solution": "令 $X$ 表示原始图像数据，$Y$ 表示有损压缩后的图像，$Z$ 表示 $Y$ 的无损压缩版本。该处理链意味着一个马尔可夫链 $X \\to Y \\to Z$，因为 $Z$ 仅通过 $Y$ 依赖于 $X$。由于第二步是无损且完全可逆的，因此存在一个双射 $f$，使得 $Z=f(Y)$ 且 $Y=f^{-1}(Z)$。因此，$Y$ 是 $Z$ 的一个确定性函数，$Z$ 也是 $Y$ 的一个确定性函数。\n\n对马尔可夫链 $X \\to Y \\to Z$（其中 $Z=f(Y)$）使用数据处理不等式，我们得到\n$$\nI(X;Z) \\le I(X;Y).\n$$\n因为 $Y=f^{-1}(Z)$，我们也有反向的马尔可夫链 $X \\to Z \\to Y$，这给出\n$$\nI(X;Y) \\le I(X;Z).\n$$\n结合这两个不等式可得\n$$\nI(X;Y) = I(X;Z).\n$$\n\n等价地，使用定义 $I(X;Y)=H(X)-H(X|Y)$ 和 $I(X;Z)=H(X)-H(X|Z)$，并注意到 $Z$ 和 $Y$ 是双射关系，以 $Z$ 为条件等价于以 $Y$ 为条件。形式上，由于 $Z=f(Y)$ 且 $Y=f^{-1}(Z)$，\n$$\nH(X|Z) = H\\bigl(X \\mid f^{-1}(Z)\\bigr) = H(X|Y),\n$$\n这直接得出\n$$\nI(X;Z) = H(X) - H(X|Z) = H(X) - H(X|Y) = I(X;Y).\n$$\n\n因此，保证成立的最具体关系是相等。",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "我们已经知道信息在处理后不会增加，但我们能否量化信息损失的最大程度？这个问题将引导您从定性的数据处理不等式迈向定量的“强数据处理不等式”。您的任务是为一个给定的信道（二元对称信道）推导出最紧的收缩系数 $\\eta(p)$，使得不等式 $I(X;Z) \\le \\eta(p) I(X;Y)$ 恒成立。这不仅加深了您对数据处理不等式的理解，也揭示了其在评估和设计通信系统时的深刻应用。",
            "id": "1613416",
            "problem": "考虑一个由离散随机变量的马尔可夫链 $X \\to Y \\to Z$ 建模的通信系统。变量 $X$ 代表来自信源的原始消息。变量 $Y$ 代表消息的中间编码版本，其字母表是二元的，$\\mathcal{Y} = \\{0, 1\\}$。变量 $Z$ 代表最终接收到的信号，其字母表也是二元的，$\\mathcal{Z} = \\{0, 1\\}$。\n\n从 $Y$ 到 $Z$ 的转换由一个固定的二进制对称信道 (BSC) 控制，我们记为 BSC($p$)，其交叉概率为 $p \\in [0, 1/2)$。这意味着从 $Y$ 发送的一个比特在传输到 $Z$ 的过程中有 $p$ 的概率被翻转。形式上，条件概率由 $P(Z \\neq y | Y=y) = p$ 给出，其中 $y \\in \\{0,1\\}$。\n\n数据处理不等式指出，关于 $X$ 的信息在处理后不会增加，即 $I(X;Z) \\le I(X;Y)$，其中 $I(A;B)$ 表示随机变量 $A$ 和 $B$ 之间的互信息。我们感兴趣的是找到该不等式的一个更紧的版本，称为强数据处理不等式，其形式为 $I(X;Z) \\le \\eta(p) I(X;Y)$。\n\n你的任务是找到代表最紧可能上界的系数 $\\eta(p)$。这个系数必须仅是 $p$ 的函数，并且对于任何与给定马尔可夫结构一致且 $I(X;Y)0$ 的 $(X,Y)$ 的可能联合分布，该不等式都必须普遍成立。\n\n请用 $p$ 的闭式解析表达式来表示你的答案。",
            "solution": "令 $K$ 表示固定的信道 $Y \\to Z$，在此即为 $\\mathrm{BSC}(p)$。对于任何具有此固定 $K$ 的马尔可夫链 $X \\to Y \\to Z$，我们有\n$$\nI(X;Y)=\\sum_{x}P_{X}(x)\\,D\\!\\left(P_{Y|X=x}\\,\\|\\,P_{Y}\\right),\n\\quad\nI(X;Z)=\\sum_{x}P_{X}(x)\\,D\\!\\left(P_{Z|X=x}\\,\\|\\,P_{Z}\\right),\n$$\n其中 $P_{Z|X=x}=P_{Y|X=x}K$ 且 $P_{Z}=P_{Y}K$，而 $D(\\cdot\\|\\cdot)$ 表示 Kullback–Leibler 散度。对于一个固定的信道 $K$，定义其 KL-收缩系数\n$$\n\\eta_{\\mathrm{KL}}(K)\\triangleq \\sup_{P\\neq Q}\\frac{D(PK\\,\\|\\,QK)}{D(P\\,\\|\\,Q)}.\n$$\n根据互信息到条件散度的凸分解以及 $\\eta_{\\mathrm{KL}}(K)$ 的定义，对于所有通过 $K$ 的 $X \\to Y \\to Z$，\n$$\nD\\!\\left(P_{Z|X=x}\\,\\|\\,P_{Z}\\right)\\le \\eta_{\\mathrm{KL}}(K)\\,D\\!\\left(P_{Y|X=x}\\,\\|\\,P_{Y}\\right)\\quad\\text{对所有 }x,\n$$\n因此\n$$\nI(X;Z)\\le \\eta_{\\mathrm{KL}}(K)\\,I(X;Y).\n$$\n因此，最紧的强数据处理系数是 $\\eta(p)=\\eta_{\\mathrm{KL}}(K)$，其中 $K=\\mathrm{BSC}(p)$。剩下的任务就是计算 $\\eta_{\\mathrm{KL}}(\\mathrm{BSC}(p))$。\n\n通过 $\\chi^{2}$-收缩和最大相关性得到上界。对于任意信道 $K$，已知\n$$\n\\eta_{\\mathrm{KL}}(K)\\le \\eta_{\\chi^{2}}(K),\n$$\n其中 $\\eta_{\\chi^{2}}(K)\\triangleq \\sup_{P\\neq Q}\\frac{\\chi^{2}(PK\\,\\|\\,QK)}{\\chi^{2}(P\\,\\|\\,Q)}$ 是 $\\chi^{2}$-散度收缩系数。此外，$\\eta_{\\chi^{2}}(K)=\\rho^{2}(K)$，即 Hirschfeld–Gebelein–Rényi 最大相关性在信道 $K$ 上的平方。对于 $\\mathrm{BSC}(p)$，选择 $f(y)=(-1)^{y}$ 和 $g(z)=(-1)^{z}$。那么\n$$\n\\mathbb{E}[f(Y)g(Z)]=\\mathbb{P}(Y=Z)-\\mathbb{P}(Y\\neq Z)=(1-p)-p=1-2p,\n$$\n并且这个值是最大的，因此 $\\rho(\\mathrm{BSC}(p))=|1-2p|$。所以，\n$$\n\\eta_{\\mathrm{KL}}(\\mathrm{BSC}(p))\\le \\eta_{\\chi^{2}}(\\mathrm{BSC}(p))=\\rho^{2}(\\mathrm{BSC}(p))=(1-2p)^{2}.\n$$\n\n通过局部扰动得到下界，该下界可达到 $(1-2p)^{2}$。取 $\\{0,1\\}$ 上的分布 $Q$ 为均匀分布，那么 $QK=Q$，因为 $\\mathrm{BSC}(p)$ 是双随机的。令 $v=(\\frac{1}{2},-\\frac{1}{2})$，对于小的 $\\epsilon$ 定义 $P=Q+\\epsilon v$。那么对于足够小的 $\\epsilon$，$P$ 是一个有效的分布，并且 $PK=QK+\\epsilon vK$。对于 $\\mathrm{BSC}(p)$，\n$$\nvK=(1-2p)\\,v.\n$$\n使用 Kullback-Leibler 散度在 $Q$ 附近的二阶展开，\n$$\nD(P\\,\\|\\,Q)=\\frac{\\epsilon^{2}}{2}\\sum_{y}\\frac{v(y)^{2}}{Q(y)}+o(\\epsilon^{2}),\\qquad\nD(PK\\,\\|\\,QK)=\\frac{\\epsilon^{2}}{2}\\sum_{z}\\frac{(vK)(z)^{2}}{QK(z)}+o(\\epsilon^{2}).\n$$\n因为 $Q=QK$ 是均匀分布且 $vK=(1-2p)\\,v$，可以得出\n$$\n\\frac{D(PK\\,\\|\\,QK)}{D(P\\,\\|\\,Q)}=(1-2p)^{2}+o(1)\\quad\\text{当 }\\epsilon\\to 0,\n$$\n所以\n$$\n\\eta_{\\mathrm{KL}}(\\mathrm{BSC}(p))\\ge (1-2p)^{2}.\n$$\n\n结合上界和下界可得\n$$\n\\eta_{\\mathrm{KL}}(\\mathrm{BSC}(p))=(1-2p)^{2}.\n$$\n由于 $\\eta(p)$ 等于 $\\eta_{\\mathrm{KL}}(\\mathrm{BSC}(p))$，最紧的强数据处理系数是\n$$\n\\eta(p)=(1-2p)^{2}.\n$$\n该常数仅依赖于 $p$，对于所有使用 $\\mathrm{BSC}(p)$ 且与 $X\\to Y\\to Z$ 一致的 $(X,Y)$ 都是通用的，并且是紧的。",
            "answer": "$$\\boxed{(1-2p)^{2}}$$"
        }
    ]
}