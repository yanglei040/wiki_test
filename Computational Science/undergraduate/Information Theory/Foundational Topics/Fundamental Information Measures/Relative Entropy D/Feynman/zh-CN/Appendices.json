{
    "hands_on_practices": [
        {
            "introduction": "动手实践的第一步是掌握基础计算。本练习将指导你计算两个二项分布之间的相对熵，二项分布是描述一系列独立重复试验中成功次数的常用模型。通过这个练习，你将熟悉KL散度 $D_{KL}(P||Q)$ 的定义，并学会在具体情境下应用它，这是信息论中一项基本且重要的技能。",
            "id": "1654970",
            "problem": "在统计建模领域，通常需要量化两个概率分布之间的差异。一种常见的度量是 Kullback-Leibler (KL) 散度，也称为相对熵。对于定义在同一样本空间 $\\mathcal{X}$ 上的两个离散概率分布 $P(x)$ 和 $Q(x)$，$P$ 相对于 $Q$ 的 KL 散度由下式给出：\n$$D_{KL}(P || Q) = \\sum_{x \\in \\mathcal{X}} P(x) \\ln\\left(\\frac{P(x)}{Q(x)}\\right)$$\n其中 $\\ln$ 表示自然对数。\n\n考虑两个独立的制造工艺，用于生产特定类型的半导体。\n- 工艺 1 由一个随机变量 $K_1$ 建模，该变量服从参数为 $(n, p_1)$ 的二项分布。这表示在一批大小为 $n$ 的半导体中非次品的数量，其中 $p_1$ 是单个半导体为非次品的概率。\n- 工艺 2 由一个随机变量 $K_2$ 建模，该变量也服从二项分布，但参数为 $(n, p_2)$。在此，$p_2$ 是单个半导体为非次品的概率。\n\n二项分布 $B(n, p)$ 的概率质量函数 (PMF) 由 $P(K=k) = \\binom{n}{k} p^k (1-p)^{n-k}$ 给出，其中 $k \\in \\{0, 1, \\dots, n\\}$。\n\n令 $P_1$ 表示工艺 1 的二项分布，$P_2$ 表示工艺 2 的分布。假设 $p_1, p_2 \\in (0,1)$，请找出 Kullback-Leibler 散度 $D_{KL}(P_1 || P_2)$ 关于 $n$、$p_1$ 和 $p_2$ 的闭式解析表达式。",
            "solution": "我们将 $K_{1} \\sim \\mathrm{Bin}(n,p_{1})$ 和 $K_{2} \\sim \\mathrm{Bin}(n,p_{2})$ 的概率质量函数 (PMF) 表示为\n$$\nP_{1}(k)=\\binom{n}{k}p_{1}^{k}(1-p_{1})^{n-k}, \\quad\nP_{2}(k)=\\binom{n}{k}p_{2}^{k}(1-p_{2})^{n-k},\n$$\n对于 $k \\in \\{0,1,\\dots,n\\}$。根据定义，$P_1$ 相对于 $P_2$ 的 Kullback-Leibler 散度为\n$$\nD_{KL}(P_{1}\\,\\|\\,P_{2})=\\sum_{k=0}^{n}P_{1}(k)\\,\\ln\\!\\left(\\frac{P_{1}(k)}{P_{2}(k)}\\right).\n$$\n计算对数内的似然比：\n$$\n\\frac{P_{1}(k)}{P_{2}(k)}=\\frac{\\binom{n}{k}p_{1}^{k}(1-p_{1})^{n-k}}{\\binom{n}{k}p_{2}^{k}(1-p_{2})^{n-k}}\n=\\left(\\frac{p_{1}}{p_{2}}\\right)^{k}\\left(\\frac{1-p_{1}}{1-p_{2}}\\right)^{n-k}.\n$$\n取对数可得\n$$\n\\ln\\!\\left(\\frac{P_{1}(k)}{P_{2}(k)}\\right)\n= k\\,\\ln\\!\\left(\\frac{p_{1}}{p_{2}}\\right) + (n-k)\\,\\ln\\!\\left(\\frac{1-p_{1}}{1-p_{2}}\\right).\n$$\n代回到 $D_{KL}$ 的定义中：\n$$\nD_{KL}(P_{1}\\,\\|\\,P_{2})\n=\\sum_{k=0}^{n}P_{1}(k)\\left[ k\\,\\ln\\!\\left(\\frac{p_{1}}{p_{2}}\\right) + (n-k)\\,\\ln\\!\\left(\\frac{1-p_{1}}{1-p_{2}}\\right)\\right].\n$$\n由于对数因子不依赖于 $k$，我们可以将其提出来，并将求和项识别为 $K \\sim \\mathrm{Bin}(n,p_{1})$ 分布下的期望：\n$$\nD_{KL}(P_{1}\\,\\|\\,P_{2})\n=\\ln\\!\\left(\\frac{p_{1}}{p_{2}}\\right)\\sum_{k=0}^{n}k\\,P_{1}(k)\n+\\ln\\!\\left(\\frac{1-p_{1}}{1-p_{2}}\\right)\\sum_{k=0}^{n}(n-k)\\,P_{1}(k).\n$$\n使用 $\\sum_{k=0}^{n}k\\,P_{1}(k)=\\mathbb{E}_{P_{1}}[K]=n p_{1}$ 和 $\\sum_{k=0}^{n}(n-k)\\,P_{1}(k)=n-\\mathbb{E}_{P_{1}}[K]=n(1-p_{1})$，我们得到\n$$\nD_{KL}(P_{1}\\,\\|\\,P_{2})\n= n p_{1}\\,\\ln\\!\\left(\\frac{p_{1}}{p_{2}}\\right)\n+ n(1-p_{1})\\,\\ln\\!\\left(\\frac{1-p_{1}}{1-p_{2}}\\right).\n$$\n这等价于 $\\mathrm{Bernoulli}(p_{1})$ 和 $\\mathrm{Bernoulli}(p_{2})$ 之间 KL 散度的 $n$ 倍，并且对于 $p_{1},p_{2}\\in(0,1)$，该值是有限的。",
            "answer": "$$\\boxed{n\\left[p_{1}\\ln\\!\\left(\\frac{p_{1}}{p_{2}}\\right)+(1-p_{1})\\ln\\!\\left(\\frac{1-p_{1}}{1-p_{2}}\\right)\\right]}$$"
        },
        {
            "introduction": "在掌握了基本计算之后，让我们来探索相对熵更深层次的性质。这个练习挑战一个常见的直觉：联合分布的散度是否总是大于其边缘分布散度之和？通过构建一个精巧的反例，你将运用KL散度的链式法则，揭示多变量系统中信息散度的微妙之处，加深对变量间依赖关系如何影响相对熵的理解。",
            "id": "1655003",
            "problem": "考虑两个二元随机变量 $X$ 和 $Y$，它们都在集合 $\\{0, 1\\}$ 中取值。我们为这两个变量定义了两个不同的联合概率分布，分别记为 $p(x,y)$ 和 $q(x,y)$。\n\n这些分布由以下几个部分构成：\n\n首先，给出随机变量 $X$ 的边缘分布：\n- 对于第一个模型，分布为 $p(x)$，其中 $p(X=0) = \\frac{1}{2}$。\n- 对于第二个模型，分布为 $q(x)$，其中 $q(X=0) = \\frac{1}{4}$。\n\n其次，给定 $X$ 时 $Y$ 的条件概率分布对两个模型是相同的。我们将这个共同的条件分布记为 $f(y|x)$，即 $p(y|x) = f(y|x)$ 且 $q(y|x) = f(y|x)$。具体的条件概率为：\n- $f(Y=0 | X=0) = \\frac{3}{4}$\n- $f(Y=0 | X=1) = \\frac{1}{4}$\n\n完整的联合分布则通过概率的乘法法则形成：$p(x,y) = p(x)f(y|x)$ 和 $q(x,y) = q(x)f(y|x)$。\n\n对于定义在相同样本空间上的两个离散概率分布 $u(z)$ 和 $v(z)$，其库尔贝克-莱布勒（KL）散度（也称为相对熵）由 $D(u||v) = \\sum_z u(z) \\ln\\frac{u(z)}{v(z)}$ 给出，其中求和遍及所有可能的结果 $z$，$\\ln$ 表示自然对数。\n\n你的任务是计算量 $\\Delta$ 的值，其定义如下：\n$$ \\Delta = D(p(x,y)||q(x,y)) - D(p(x)||q(x)) - D(p(y)||q(y)) $$\n将答案表示为单个封闭形式的解析表达式。",
            "solution": "该问题要求计算量 $\\Delta = D(p(x,y)||q(x,y)) - D(p(x)||q(x)) - D(p(y)||q(y))$。\n\n计算这个量的最直接方法是使用库尔贝克-莱布勒（KL）散度的链式法则，该法则表明：\n$$ D(p(x,y)||q(x,y)) = D(p(x)||q(x)) + D(p(y|x)||q(y|x)) $$\n此处，$D(p(y|x)||q(y|x))$ 是条件相对熵，定义为 $\\sum_{x} p(x) D(p(y|X=x)||q(y|X=x))$。\n\n将链式法则代入 $\\Delta$ 的表达式中：\n$$ \\Delta = \\left( D(p(x)||q(x)) + D(p(y|x)||q(y|x)) \\right) - D(p(x)||q(x)) - D(p(y)||q(y)) $$\n$D(p(x)||q(x))$ 项相互抵消，表达式简化为：\n$$ \\Delta = D(p(y|x)||q(y|x)) - D(p(y)||q(y)) $$\n\n现在，我们计算剩下的两项。\n\n首先，我们来计算 $D(p(y|x)||q(y|x))$。其定义为：\n$$ D(p(y|x)||q(y|x)) = \\sum_{x \\in \\{0,1\\}} p(x) \\sum_{y \\in \\{0,1\\}} p(y|x) \\ln\\frac{p(y|x)}{q(y|x)} $$\n根据题目描述，条件分布是相同的，即 $p(y|x) = f(y|x)$ 和 $q(y|x) = f(y|x)$。因此，对数内的比率 $\\frac{p(y|x)}{q(y|x)} = 1$ 对所有 $x, y$ 成立（在分布有定义的情况下）。1的自然对数是0。\n因此，求和中的每一项都为零，这意味着：\n$$ D(p(y|x)||q(y|x)) = 0 $$\n$\\Delta$ 的表达式进一步简化为：\n$$ \\Delta = - D(p(y)||q(y)) $$\n\n接下来，我们需要计算 $D(p(y)||q(y))$。为此，我们必须首先使用全概率公式来求得边缘分布 $p(y)$ 和 $q(y)$。\n\n边缘分布 $p(y)$ 为：\n$$ p(y) = \\sum_{x \\in \\{0,1\\}} p(x) p(y|x) = \\sum_{x \\in \\{0,1\\}} p(x) f(y|x) $$\n题目给出 $p(X=0) = 1/2$，所以 $p(X=1) = 1-1/2 = 1/2$。题目也给出 $f(Y=0|X=0) = 3/4$ 和 $f(Y=0|X=1) = 1/4$。这意味着 $f(Y=1|X=0) = 1-3/4 = 1/4$ 且 $f(Y=1|X=1) = 1-1/4 = 3/4$。\n对于 $y=0$：\n$p(Y=0) = p(X=0)f(Y=0|X=0) + p(X=1)f(Y=0|X=1) = \\left(\\frac{1}{2}\\right)\\left(\\frac{3}{4}\\right) + \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{4}\\right) = \\frac{3}{8} + \\frac{1}{8} = \\frac{4}{8} = \\frac{1}{2}$。\n由于 $Y$ 是一个二元变量，所以 $p(Y=1) = 1 - p(Y=0) = 1 - 1/2 = 1/2$。\n\n边缘分布 $q(y)$ 为：\n$$ q(y) = \\sum_{x \\in \\{0,1\\}} q(x) q(y|x) = \\sum_{x \\in \\{0,1\\}} q(x) f(y|x) $$\n题目给出 $q(X=0) = 1/4$，所以 $q(X=1) = 1-1/4 = 3/4$。\n对于 $y=0$：\n$q(Y=0) = q(X=0)f(Y=0|X=0) + q(X=1)f(Y=0|X=1) = \\left(\\frac{1}{4}\\right)\\left(\\frac{3}{4}\\right) + \\left(\\frac{3}{4}\\right)\\left(\\frac{1}{4}\\right) = \\frac{3}{16} + \\frac{3}{16} = \\frac{6}{16} = \\frac{3}{8}$。\n这意味着 $q(Y=1) = 1 - q(Y=0) = 1 - 3/8 = 5/8$。\n\n现在我们可以计算 $D(p(y)||q(y))$：\n$$ D(p(y)||q(y)) = \\sum_{y \\in \\{0,1\\}} p(y) \\ln\\frac{p(y)}{q(y)} $$\n$$ D(p(y)||q(y)) = p(Y=0) \\ln\\frac{p(Y=0)}{q(Y=0)} + p(Y=1) \\ln\\frac{p(Y=1)}{q(Y=1)} $$\n$$ D(p(y)||q(y)) = \\left(\\frac{1}{2}\\right) \\ln\\frac{1/2}{3/8} + \\left(\\frac{1}{2}\\right) \\ln\\frac{1/2}{5/8} $$\n$$ D(p(y)||q(y)) = \\frac{1}{2} \\ln\\left(\\frac{8}{6}\\right) + \\frac{1}{2} \\ln\\left(\\frac{8}{10}\\right) = \\frac{1}{2} \\ln\\left(\\frac{4}{3}\\right) + \\frac{1}{2} \\ln\\left(\\frac{4}{5}\\right) $$\n使用性质 $\\ln(a) + \\ln(b) = \\ln(ab)$：\n$$ D(p(y)||q(y)) = \\frac{1}{2} \\ln\\left(\\frac{4}{3} \\cdot \\frac{4}{5}\\right) = \\frac{1}{2} \\ln\\left(\\frac{16}{15}\\right) $$\n\n最后，我们求出 $\\Delta$：\n$$ \\Delta = - D(p(y)||q(y)) = - \\frac{1}{2} \\ln\\left(\\frac{16}{15}\\right) $$\n使用性质 $-\\ln(a) = \\ln(1/a)$：\n$$ \\Delta = \\frac{1}{2} \\ln\\left(\\frac{15}{16}\\right) $$\n这个负数结果表明，量 $D(p(x,y)||q(x,y))$ 并不总是大于或等于其边缘KL散度之和 $D(p(x)||q(x)) + D(p(y)||q(y))$。",
            "answer": "$$\\boxed{\\frac{1}{2}\\ln\\left(\\frac{15}{16}\\right)}$$"
        },
        {
            "introduction": "最后，我们将把相对熵从一个度量工具转变为一个强大的优化工具。本练习展示了如何在满足特定约束（如目标期望值）的同时，找到一个与先验分布最“接近”的新概率分布。这个过程被称为最小相对熵原理，是统计建模和机器学习中的一个核心思想，它揭示了如何以最小的扰动来更新我们的信念。",
            "id": "1655009",
            "problem": "一个云计算平台将其资源分配给四种不同的计算任务类别，分别标记为1、2、3和4。一项历史分析建立了一个由先验概率分布 $Q = (q_1, q_2, q_3, q_4)$ 表示的基准资源分配策略，其中 $q_i$ 是分配给任务类别 $i$ 的资源比例。该先验分布为 $Q = (0.1, 0.2, 0.3, 0.4)$。\n\n每个任务类别都有一个相关的平均功耗，由函数 $f(i)$ 给出。其值分别为 $f(1) = 1.0$，$f(2) = 2.0$，$f(3) = 4.0$ 和 $f(4) = 5.0$，单位为归一化功率单位。\n\n为了满足新的能效目标，该平台需要采用一种新的分配策略 $P = (p_1, p_2, p_3, p_4)$，将平均功耗调整到一个新的目标值 $C=3.9$ 功率单位。为确保平稳过渡并最小化干扰，新策略 $P$ 必须尽可能地接近先验策略 $Q$。“接近度”通过库尔贝克-莱布勒（KL）散度来衡量，也称为相对熵，定义为 $D_{KL}(P||Q) = \\sum_{i=1}^4 p_i \\ln\\left(\\frac{p_i}{q_i}\\right)$。\n\n你的任务是找到新的分配策略 $P$，该策略在满足其为有效概率分布以及期望功耗等于目标值 $C$ 的约束条件下，最小化 $D_{KL}(P||Q)$。\n\n在这个新的最优分配策略下，计算第四个任务类别的概率 $p_4$。将你的最终答案四舍五入到三位有效数字。",
            "solution": "我们在约束条件 $\\sum_{i=1}^{4} p_{i} = 1$ 和 $\\sum_{i=1}^{4} p_{i} f(i) = C$（其中 $C=3.9$）下，最小化相对熵 $D_{KL}(P||Q) = \\sum_{i=1}^{4} p_{i} \\ln\\left(\\frac{p_{i}}{q_{i}}\\right)$。引入拉格朗日乘子 $\\alpha$ 和 $\\beta$，构造拉格朗日函数\n$$\n\\mathcal{L} = \\sum_{i=1}^{4} p_{i} \\ln\\left(\\frac{p_{i}}{q_{i}}\\right) + \\alpha \\left(\\sum_{i=1}^{4} p_{i} - 1\\right) + \\beta \\left(\\sum_{i=1}^{4} p_{i} f(i) - C\\right).\n$$\n关于 $p_{i}$ 的平稳性条件给出\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial p_{i}} = \\ln\\left(\\frac{p_{i}}{q_{i}}\\right) + 1 + \\alpha + \\beta f(i) = 0,\n$$\n因此\n$$\np_{i} = q_{i} \\exp\\left(-1 - \\alpha - \\beta f(i)\\right).\n$$\n令 $\\eta = -\\beta$ 并定义归一化因子\n$$\nZ(\\eta) = \\sum_{j=1}^{4} q_{j} \\exp\\left(\\eta f(j)\\right).\n$$\n那么\n$$\np_{i} = \\frac{q_{i} \\exp\\left(\\eta f(i)\\right)}{Z(\\eta)}, \\quad Z(\\eta) = \\sum_{j=1}^{4} q_{j} \\exp\\left(\\eta f(j)\\right).\n$$\n期望约束变为\n$$\n\\sum_{i=1}^{4} p_{i} f(i) = \\frac{1}{Z(\\eta)} \\sum_{i=1}^{4} q_{i} f(i) \\exp\\left(\\eta f(i)\\right) = C.\n$$\n已知 $Q=(0.1,0.2,0.3,0.4)$ 和 $f(1)=1, f(2)=2, f(3)=4, f(4)=5$，我们有\n$$\nZ(\\eta) = 0.1 \\exp(\\eta) + 0.2 \\exp(2\\eta) + 0.3 \\exp(4\\eta) + 0.4 \\exp(5\\eta),\n$$\n$$\n\\sum_{i=1}^{4} q_{i} f(i) \\exp\\left(\\eta f(i)\\right) = 0.1 \\cdot 1 \\cdot \\exp(\\eta) + 0.2 \\cdot 2 \\cdot \\exp(2\\eta) + 0.3 \\cdot 4 \\cdot \\exp(4\\eta) + 0.4 \\cdot 5 \\cdot \\exp(5\\eta).\n$$\n将此比率设为 $C=3.9$：\n$$\n\\frac{0.1 \\exp(\\eta) + 0.4 \\exp(2\\eta) + 1.2 \\exp(4\\eta) + 2.0 \\exp(5\\eta)}{0.1 \\exp(\\eta) + 0.2 \\exp(2\\eta) + 0.3 \\exp(4\\eta) + 0.4 \\exp(5\\eta)} = 3.9.\n$$\n令 $t = \\exp(\\eta) > 0$。那么方程变为\n$$\n\\frac{0.1 t + 0.4 t^{2} + 1.2 t^{4} + 2.0 t^{5}}{0.1 t + 0.2 t^{2} + 0.3 t^{4} + 0.4 t^{5}} = 3.9.\n$$\n交叉相乘并化简得到\n$$\n-0.29\\, t - 0.38\\, t^{2} + 0.03\\, t^{4} + 0.44\\, t^{5} = 0,\n$$\n等价于\n$$\n0.44\\, t^{4} + 0.03\\, t^{3} - 0.38\\, t - 0.29 = 0.\n$$\n对 $t>1$（因为目标值 $C=3.9$ 超过了先验均值 $3.7$）进行数值求解，得到 $t \\approx 1.11132$。\n\n使用这个 $t$ 值，计算归一化因子和 $p_{4}$。首先计算幂次：\n$$\nt \\approx 1.11132,\\quad t^{2} \\approx 1.2350321424,\\quad t^{4} \\approx 1.5253043928,\\quad t^{5} \\approx 1.6951012778.\n$$\n那么\n$$\nZ = 0.1 t + 0.2 t^{2} + 0.3 t^{4} + 0.4 t^{5} \\approx 0.111132 + 0.24700642848 + 0.45759131784 + 0.67804051112 \\approx 1.49377025741.\n$$\n因此\n$$\np_{4} = \\frac{0.4 t^{5}}{Z} \\approx \\frac{0.67804051112}{1.49377025741} \\approx 0.453912,\n$$\n四舍五入到三位有效数字后为 $0.454$。",
            "answer": "$$\\boxed{0.454}$$"
        }
    ]
}