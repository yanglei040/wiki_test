{
    "hands_on_practices": [
        {
            "introduction": "互信息的链式法则告诉我们如何逐步分解多个变量共同提供的信息量。这个练习通过一个与我们息息相关的场景——考试成绩——来帮助我们巩固对链式法则核心公式的理解。通过将期中和期末考试成绩对最终成绩的总信息量 $I(M, F; G)$ 分解，我们可以直观地看到先知道一个信息源（期中成绩），再知道另一个信息源（期末成绩）所带来的信息增益是如何累加的 。",
            "id": "1608881",
            "problem": "在一门物理入门课程中，一位教授正在分析学生的考试成绩与他们最终课程结果之间的关系。教授使用三个离散随机变量来对此情况建模：$M$ 代表期中考试的成绩，$F$ 代表期末考试的成绩，$G$ 代表课程的最终字母等级。\n\n教授有兴趣量化期中和期末两次考试成绩的集合所提供的关于学生最终成绩的总信息量。这个量由互信息 $I(M, F; G)$ 表示。\n\n根据信息论的基本性质，以下哪个表达式总是等价于 $I(M, F; G)$？\n\nA. $I(M; G) + I(F; G | M)$\n\nB. $I(M; G) + I(F; G)$\n\nC. $H(M) + H(F) - H(G)$\n\nD. $I(M; F) + I(G; M | F)$\n\nE. $H(G) - H(G | M) - H(G | F)$",
            "solution": "令 $I(X;Y)$ 表示互信息，$I(X;Y|Z)$ 表示条件互信息，$H(\\cdot)$ 表示熵。基本定义如下：\n$$\nI(X;Y) = H(Y) - H(Y|X) = H(X) - H(X|Y),\n$$\n$$\nI(X;Y|Z) = H(Y|Z) - H(Y|X,Z) = H(X|Z) - H(X|Y,Z),\n$$\n对于联合变量，\n$$\nI(X,Y;Z) = H(Z) - H(Z|X,Y) = H(X,Y) - H(X,Y|Z).\n$$\n使用这些定义，推导互信息的链式法则：\n$$\nI(X,Y;Z) = H(Z) - H(Z|X,Y) = \\bigl[H(Z) - H(Z|X)\\bigr] + \\bigl[H(Z|X) - H(Z|X,Y)\\bigr] = I(X;Z) + I(Y;Z|X).\n$$\n将 $X=M$，$Y=F$ 和 $Z=G$ 应用于此公式，得到\n$$\nI(M,F;G) = I(M;G) + I(F;G|M),\n$$\n这证明了选项 A 总是正确的。\n\n现在评估其他选项：\n\nB. 计算 $I(M;G) + I(F;G)$:\n$$\nI(M;G) + I(F;G) = \\bigl[H(G) - H(G|M)\\bigr] + \\bigl[H(G) - H(G|F)\\bigr] = 2H(G) - H(G|M) - H(G|F).\n$$\n与\n$$\nI(M,F;G) = H(G) - H(G|M,F)\n$$\n比较。通常情况下 $2H(G) - H(G|M) - H(G|F) \\neq H(G) - H(G|M,F)$，所以 B 并不总是等于 $I(M,F;G)$。\n\nC. $H(M) + H(F) - H(G)$ 仅取决于边缘熵，通常不等于 $I(M,F;G) = H(G) - H(G|M,F)$，后者取决于联合分布。因此 C 通常不相等。\n\nD. 使用条件互信息的对称性 $I(G;M|F) = I(M;G|F)$ 和链式法则：\n$$\nI(M;F) + I(G;M|F) = I(M;F) + I(M;G|F) = I(M;F,G) = I(M;(F,G)).\n$$\n这等于 $I(M;(F,G))$，通常不等于 $I((M,F);G)$，所以 D 并不总是相等。\n\nE. 重写\n$$\nH(G) - H(G|M) - H(G|F) = I(M;G) - H(G|F),\n$$\n这通常不等于 $H(G) - H(G|M,F) = I(M,F;G)$。因此 E 并不总是相等。\n\n因此，唯一总是等价于 $I(M,F;G)$ 的表达式是选项 A。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "掌握了链式法则的公式后，让我们通过一个具体的计算来建立直观认识。这个练习模拟了一个简单的抽卡游戏，要求我们量化已知的两张牌 $(C_1, C_2)$ 包含了多少关于第三张未知牌 $C_3$ 的信息。这道题将抽象的互信息定义 $I(X;Y) = H(Y) - H(Y|X)$ 与一个实际的“不确定性减少”过程联系起来，让我们亲手算出观察事件能带来多少“比特”的信息 。",
            "id": "1608889",
            "problem": "考虑一个极简的纸牌游戏，该游戏使用一副包含 $N=20$ 张不同纸牌的特殊牌组。牌组被完全洗匀，然后依次不放回地抽取三张牌，记作随机变量 $C_1$、$C_2$ 和 $C_3$。一个观察者看到了前两张牌 $(C_1, C_2)$，但第三张牌 $C_3$ 仍然未知。\n\n计算观察到的牌对 $(C_1, C_2)$ 与未知的第三张牌 $C_3$ 之间的互信息。所有对数均以 2 为底。以比特为单位表示你的答案，并四舍五入到四位有效数字。",
            "solution": "令 $X=(C_{1},C_{2})$ 且 $Y=C_{3}$。互信息定义为\n$$\nI(X;Y)=H(Y)-H(Y|X),\n$$\n其中所有对数均以 $2$ 为底。\n\n由于牌组被完全洗匀，$C_{3}$ 在这 $N=20$ 张牌上均匀分布，因此\n$$\nH(C_{3})=\\log_{2}(20).\n$$\n给定 $(C_{1},C_{2})$，第三张牌必定是剩下的 $20-2=18$ 张牌中的一张，并且根据对称性，它在这些牌上是均匀分布的，因此\n$$\nH(C_{3}\\mid C_{1},C_{2})=\\log_{2}(18).\n$$\n所以，\n$$\nI\\big((C_{1},C_{2});C_{3}\\big)=\\log_{2}(20)-\\log_{2}(18)=\\log_{2}\\!\\left(\\frac{20}{18}\\right)=\\log_{2}\\!\\left(\\frac{10}{9}\\right).\n$$\n使用换底公式 $\\log_{2}(a)=\\frac{\\ln(a)}{\\ln(2)}$ 并四舍五入到四位有效数字，\n$$\n\\log_{2}\\!\\left(\\frac{10}{9}\\right)\\approx 0.1520 \\text{ 比特}。\n$$",
            "answer": "$$\\boxed{0.1520}$$"
        },
        {
            "introduction": "最后，我们将链式法则应用于一个更复杂的系统分析中，以展示其作为分析工具的强大能力。该问题构建了一个 $X \\to Y \\to Z$ 的马尔可夫链来模拟数字通信中的信息处理过程。我们的任务是计算条件互信息 $I(X;Y|Z)$，这需要我们巧妙地运用链式法则恒等式来简化问题，从而揭示信息在处理链条中是如何传递和相互关联的 。",
            "id": "1612841",
            "problem": "在一个数字通信系统中，一个二进制信息源产生一个随机比特 $X$，其取值为 0 或 1 的概率相等。该比特通过一个噪声通信信道传输，该信道可建模为一个二元对称信道 (BSC)，产生输出比特 $Y$。该信道的交叉概率，即输出比特与输入比特不同的概率，用 $\\alpha$ 表示，其中 $0 < \\alpha < 0.5$。\n\n接收到的比特 $Y$ 不被直接观测。相反，它被立即处理并通过第二个独立的 BSC 重新传输，以产生最终观测到的比特 $Z$。这第二个信道的交叉概率为 $\\beta$，其中 $0 < \\beta < 0.5$。整个过程可以概括为链 $X \\to Y \\to Z$。\n\n你的任务是计算条件互信息 $I(X;Y|Z)$，它量化了在已知最终比特 $Z$ 的情况下，原始比特 $X$ 和中间比特 $Y$ 相互提供的额外信息量。\n\n请用 $\\alpha$、$\\beta$ 和二元熵函数 $H_b(p) = -p \\log_2(p) - (1-p) \\log_2(1-p)$ 给出你的解析表达式形式的最终答案。",
            "solution": "令 $X \\to Y \\to Z$ 为一个马尔可夫链，其中 $X \\in \\{0,1\\}$ 是均匀分布的，$Y$ 是通过一个交叉概率为 $\\alpha$ 的 BSC 从 $X$ 得到的，而 $Z$ 是通过一个独立的、交叉概率为 $\\beta$ 的 BSC 从 $Y$ 得到的。我们要计算 $I(X;Y|Z)$。\n\n根据互信息的链式法则，\n$$\nI(X;Y,Z) = I(X;Z) + I(X;Y|Z) = I(X;Y) + I(X;Z|Y).\n$$\n对于马尔可夫链 $X \\to Y \\to Z$，我们有条件独立性 $X \\perp Z \\mid Y$，因此\n$$\nI(X;Z|Y)=0.\n$$\n所以，\n$$\nI(X;Y|Z) = I(X;Y) - I(X;Z).\n$$\n\n现在我们计算 $I(X;Y)$ 和 $I(X;Z)$。\n\n首先，对于输入均匀的 BSC$(\\alpha)$，其输出 $Y$ 也是均匀分布的：\n$$\nP(Y=0) = P(X=0)P(Y=0|X=0) + P(X=1)P(Y=0|X=1) = \\frac{1}{2}(1-\\alpha) + \\frac{1}{2}\\alpha = \\frac{1}{2},\n$$\n所以 $H(Y)=1$。条件熵为 $H(Y|X)=H_{b}(\\alpha)$。因此\n$$\nI(X;Y) = H(Y) - H(Y|X) = 1 - H_{b}(\\alpha).\n$$\n\n接下来，两个 BSC 的级联本身也是一个 BSC，其等效交叉概率为\n$$\n\\gamma = P(Z \\neq X) = \\alpha(1-\\beta) + (1-\\alpha)\\beta = \\alpha + \\beta - 2\\alpha\\beta.\n$$\n当 $X$ 均匀分布时，$Z$ 也是均匀分布的，所以 $H(Z)=1$ 且 $H(Z|X)=H_{b}(\\gamma)$，得到\n$$\nI(X;Z) = H(Z) - H(Z|X) = 1 - H_{b}(\\gamma) = 1 - H_{b}(\\alpha + \\beta - 2\\alpha\\beta).\n$$\n\n综合起来，\n$$\nI(X;Y|Z) = \\bigl[1 - H_{b}(\\alpha)\\bigr] - \\bigl[1 - H_{b}(\\alpha + \\beta - 2\\alpha\\beta)\\bigr] = H_{b}(\\alpha + \\beta - 2\\alpha\\beta) - H_{b}(\\alpha).\n$$\n这就是用 $\\alpha$、$\\beta$ 和 $H_{b}(\\cdot)$ 表示的所求解析表达式。",
            "answer": "$$\\boxed{H_{b}\\!\\left(\\alpha+\\beta-2\\alpha\\beta\\right)-H_{b}(\\alpha)}$$"
        }
    ]
}