{
    "hands_on_practices": [
        {
            "introduction": "To begin our hands-on exploration of self-information, we'll start with a classic scenario: a game of chance. This exercise will help you connect the abstract concept of surprisal to a tangible outcome with a straightforward probability calculation. By determining the information content of a specific dice roll , you'll build a foundational understanding of how the probability $P(x)$ of an event directly maps to its information content $I(x) = -\\log_{2}(P(x))$.",
            "id": "1657249",
            "problem": "In the casino game of craps, a player known as the \"shooter\" initiates a round by rolling two standard six-sided dice. This initial roll is called the \"come-out roll.\" We are interested in applying the concepts of information theory to analyze a specific outcome of this roll.\n\nAssume the two dice are fair and their rolls are independent events. Each die has faces numbered from 1 to 6, and each face has an equal probability of landing up on any given roll.\n\nCalculate the self-information, also known as surprisal, associated with the event that the sum of the numbers shown on the two dice is exactly 2. Express your answer in units of bits, and round your final answer to four significant figures.",
            "solution": "We model two independent fair six-sided dice. The sample space has $6 \\times 6 = 36$ equally likely ordered outcomes, each with probability $\\frac{1}{36}$. The event that the sum is exactly $2$ occurs only when both dice show $1$, i.e., the single outcome $(1,1)$. Therefore,\n$$\nP(\\text{sum}=2) = \\frac{1}{36}.\n$$\nThe self-information (surprisal) in bits of an event with probability $p$ is\n$$\nI = -\\log_{2}(p).\n$$\nSubstituting $p = \\frac{1}{36}$ gives\n$$\nI = -\\log_{2}\\!\\left(\\frac{1}{36}\\right) = \\log_{2}(36) = \\log_{2}\\!\\left(2^{2} \\cdot 3^{2}\\right) = 2 + 2\\log_{2}(3).\n$$\nUsing $\\log_{2}(3) = \\frac{\\ln(3)}{\\ln(2)} \\approx 1.5849625007$, we obtain\n$$\nI \\approx 2 + 2 \\times 1.5849625007 = 5.1699250014.\n$$\nRounding to four significant figures yields\n$$\nI \\approx 5.170.\n$$",
            "answer": "$$\\boxed{5.170}$$"
        },
        {
            "introduction": "Moving beyond simple events, this next practice explores a scenario common in engineering and manufacturing: quality control. Here, we calculate the self-information of a product being \"flawless,\" which depends on multiple independent factors. This problem  demonstrates how to calculate surprisal for compound events where the total probability is the product of the probabilities of independent constituent events, a crucial skill in many real-world applications.",
            "id": "1657201",
            "problem": "A company, CryoChip Dynamics, specializes in manufacturing quantum processors for advanced computing systems. The fabrication process for each processor is susceptible to two distinct and statistically independent types of critical flaws.\n1.  A \"quantum decoherence leakage\" (Type A flaw), which occurs with a probability of $p_A = 0.085$.\n2.  A \"superconducting junction failure\" (Type B flaw), which occurs with a probability of $p_B = 0.062$.\n\nA processor is considered \"flawless\" only if it is free from both Type A and Type B flaws. If a processor exhibits one or both types of flaws, it is discarded. During a routine quality control inspection, a single processor is randomly selected from the production line and tested.\n\nCalculate the self-information (also known as surprisal) associated with the event that the selected processor is flawless. Express your answer in bits, rounded to four significant figures.",
            "solution": "The self-information, or surprisal, $I(x)$ of an event $x$ with probability $P(x)$ is defined as:\n$$I(x) = -\\log_{b}(P(x))$$\nThe problem asks for the surprisal in bits, which means we must use base $b=2$.\n$$I(x) = -\\log_{2}(P(x))$$\n\nLet $F$ be the event that a randomly selected processor is flawless. To calculate the surprisal $I(F)$, we first need to determine the probability $P(F)$.\n\nA processor is flawless if and only if it does not have a Type A flaw AND it does not have a Type B flaw. Let $A$ be the event of a Type A flaw and $B$ be the event of a Type B flaw. The probabilities of these events are given as:\n$P(A) = p_A = 0.085$\n$P(B) = p_B = 0.062$\n\nLet $\\neg A$ be the event that the processor does not have a Type A flaw, and $\\neg B$ be the event that it does not have a Type B flaw. The probabilities of these complementary events are:\n$$P(\\neg A) = 1 - P(A) = 1 - p_A = 1 - 0.085 = 0.915$$\n$$P(\\neg B) = 1 - P(B) = 1 - p_B = 1 - 0.062 = 0.938$$\n\nThe event of a flawless processor, $F$, is the intersection of the events $\\neg A$ and $\\neg B$.\n$$F = \\neg A \\cap \\neg B$$\n\nThe problem states that the two types of flaws are statistically independent. This means that the events $A$ and $B$ are independent, and consequently, their complements $\\neg A$ and $\\neg B$ are also independent. Therefore, the probability of a flawless processor is the product of the probabilities of the individual non-flaw events:\n$$P(F) = P(\\neg A \\cap \\neg B) = P(\\neg A) \\times P(\\neg B)$$\nSubstituting the calculated probabilities:\n$$P(F) = (1 - p_A)(1 - p_B) = 0.915 \\times 0.938 = 0.85827$$\n\nNow we can calculate the self-information for the event $F$ in bits:\n$$I(F) = -\\log_{2}(P(F)) = -\\log_{2}(0.85827)$$\n\nTo evaluate this, we can use the change of base formula for logarithms, $\\log_b(x) = \\frac{\\ln(x)}{\\ln(b)}$:\n$$I(F) = -\\frac{\\ln(0.85827)}{\\ln(2)}$$\nUsing a calculator for the natural logarithms:\n$$\\ln(0.85827) \\approx -0.152861$$\n$$\\ln(2) \\approx 0.693147$$\n$$I(F) \\approx -\\frac{-0.152861}{0.693147} \\approx 0.220534 \\text{ bits}$$\n\nThe problem requires the answer to be rounded to four significant figures.\n$$I(F) \\approx 0.2205 \\text{ bits}$$",
            "answer": "$$\\boxed{0.2205}$$"
        },
        {
            "introduction": "Our final practice delves into a more complex and realistic scenario involving signal detection, such as a fire alarm system. This problem requires using the law of total probability to determine the overall likelihood of an event before calculating its self-information. This exercise  challenges you to synthesize concepts of conditional probability to measure the surprisal of an alarm trigger, a common task in fields from medical diagnostics to system reliability engineering.",
            "id": "1657213",
            "problem": "A research facility's server room is protected by a sophisticated, automated fire suppression system that is triggered by an alarm. The occurrence of a genuine fire in this specific environment is a rare event. Let's model the system for a typical 24-hour period.\n\nThe prior probability of a fire occurring on any given day is denoted by $p_f$. The alarm system's performance is characterized by two parameters: its sensitivity (true positive rate) $\\eta_t$, which is the probability of the alarm sounding given that a fire is present, and its false positive rate $\\eta_f$, which is the probability of the alarm sounding in the absence of a fire.\n\nGiven the following values:\n- The daily probability of a fire, $p_f = 1.25 \\times 10^{-3}$.\n- The alarm's sensitivity, $\\eta_t = 0.998$.\n- The alarm's false positive rate, $\\eta_f = 2.0 \\times 10^{-4}$.\n\nCalculate the self-information (also known as surprisal) associated with the event of the alarm being triggered on a randomly chosen day. The base of the logarithm for self-information should be 2, corresponding to the unit of \"bits\". Express your answer in bits, rounded to three significant figures.",
            "solution": "Let $A$ denote the event that the alarm is triggered and $F$ denote the event that a fire occurs. By the law of total probability,\n$$\nP(A) = P(A\\mid F)P(F) + P(A\\mid \\overline{F})P(\\overline{F}).\n$$\nUsing the given notation, $P(F)=p_{f}$, $P(A\\mid F)=\\eta_{t}$, and $P(A\\mid \\overline{F})=\\eta_{f}$, so\n$$\nP(A) = \\eta_{t}p_{f} + \\eta_{f}(1 - p_{f}).\n$$\nSubstituting the given values $p_{f} = 1.25 \\times 10^{-3}$, $\\eta_{t} = 0.998$, and $\\eta_{f} = 2.0 \\times 10^{-4}$,\n$$\nP(A) = 0.998 \\times 1.25 \\times 10^{-3} + 2.0 \\times 10^{-4} \\times \\left(1 - 1.25 \\times 10^{-3}\\right).\n$$\nCompute each term:\n$$\n0.998 \\times 1.25 \\times 10^{-3} = 1.2475 \\times 10^{-3}, \\quad\n2.0 \\times 10^{-4} \\times \\left(1 - 1.25 \\times 10^{-3}\\right) = 1.9975 \\times 10^{-4}.\n$$\nThus,\n$$\nP(A) = 1.2475 \\times 10^{-3} + 1.9975 \\times 10^{-4} = 1.44725 \\times 10^{-3}.\n$$\nThe self-information (surprisal) of event $A$ in bits is\n$$\nI(A) = -\\log_{2}\\big(P(A)\\big).\n$$\nEquivalently, using change of base,\n$$\nI(A) = -\\frac{\\ln\\big(P(A)\\big)}{\\ln(2)} = -\\log_{2}\\left(1.44725 \\times 10^{-3}\\right).\n$$\nNumerically,\n$$\nI(A) \\approx 9.432\\ \\text{bits},\n$$\nwhich to three significant figures is $9.43$ bits.",
            "answer": "$$\\boxed{9.43}$$"
        }
    ]
}