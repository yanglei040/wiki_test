{
    "hands_on_practices": [
        {
            "introduction": "A fundamental skill when working with random variables is understanding how they transform. Often, a new random variable is simply a function of an existing one. This practice exercise models a common scenario in computer science—a hash function mapping keys to storage bins—to build your skills in deriving the probability mass function (PMF) of a new variable from a known, underlying distribution .",
            "id": "1618711",
            "problem": "In a simplified model of a computer's hash table, integer keys are mapped to a small set of storage bins. The hash function used is $h(k) = k \\pmod 3$. The keys are generated from a random process, modeled as the outcome of a roll of a fair 8-sided die, whose faces are labeled with the integers $\\{1, 2, 3, 4, 5, 6, 7, 8\\}$.\n\nLet the random variable $X$ represent the outcome of a single roll of this die. The random variable $Z$ represents the bin number assigned by the hash function, so $Z = X \\pmod 3$.\n\nDetermine the Probability Mass Function (PMF) of the random variable $Z$. Specifically, calculate the probabilities $p_0, p_1, p_2$, where $p_i = P(Z=i)$ for $i \\in \\{0, 1, 2\\}$. Your final answer should be a row matrix containing the values of $p_0, p_1, p_2$ in that order, expressed as exact fractions.",
            "solution": "The die is fair, so $X$ is uniform on $\\{1,2,3,4,5,6,7,8\\}$ with $P(X=x)=\\frac{1}{8}$ for each $x$. The hash bin variable is $Z=X \\bmod 3$, taking values in $\\{0,1,2\\}$. For each $i \\in \\{0,1,2\\}$, the probability is the sum over the preimage of $i$ under the modulo map:\n$$\np_{i}=P(Z=i)=\\sum_{x \\in S_{i}} P(X=x), \\quad S_{i}=\\{x \\in \\{1,2,\\ldots,8\\}: x \\equiv i \\ (\\bmod \\ 3)\\}.\n$$\nCompute each preimage:\n- For $i=0$: $S_{0}=\\{3,6\\}$, so $|S_{0}|=2$ and $p_{0}=2 \\cdot \\frac{1}{8}=\\frac{1}{4}$.\n- For $i=1$: $S_{1}=\\{1,4,7\\}$, so $|S_{1}|=3$ and $p_{1}=3 \\cdot \\frac{1}{8}=\\frac{3}{8}$.\n- For $i=2$: $S_{2}=\\{2,5,8\\}$, so $|S_{2}|=3$ and $p_{2}=3 \\cdot \\frac{1}{8}=\\frac{3}{8}$.\nThus the PMF of $Z$ in the order $(p_{0},p_{1},p_{2})$ is as follows.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{4} & \\frac{3}{8} & \\frac{3}{8}\\end{pmatrix}}$$"
        },
        {
            "introduction": "Beyond defining the probabilities of a random variable, we often want to summarize its behavior using statistical measures. The mean tells us the average outcome, while the variance describes the spread or variability around that average. This problem provides a direct application from information theory, asking you to calculate the variance of codeword lengths in a data compression scheme, a key metric for understanding the performance consistency of a code .",
            "id": "1618709",
            "problem": "A simplified model for a remote environmental sensor describes its data output as a source emitting symbols from the alphabet $\\mathcal{S} = \\{s_1, s_2, s_3, s_4\\}$. The long-term observed probabilities for emitting each symbol are given by the Probability Mass Function (PMF) $p(s)$:\n$p(s_1) = \\frac{1}{2}$, $p(s_2) = \\frac{1}{4}$, $p(s_3) = \\frac{1}{8}$, and $p(s_4) = \\frac{1}{8}$.\n\nTo compress data for transmission, the sensor employs a binary prefix code, where each symbol $s_i$ is mapped to a unique binary codeword $c_i$. The specific codebook is as follows:\n- $c_1$ (for $s_1$): `0`\n- $c_2$ (for $s_2$): `10`\n- $c_3$ (for $s_3$): `110`\n- $c_4$ (for $s_4$): `111`\n\nLet $L$ be the discrete random variable representing the length of the codeword generated by the sensor for a particular symbol emission. Calculate the variance of $L$, denoted as $\\text{Var}(L)$. Express your final answer as a fraction in simplest form.",
            "solution": "Let $L$ be the codeword length random variable. Using the given codebook, the lengths are $1$ for $s_{1}$, $2$ for $s_{2}$, and $3$ for both $s_{3}$ and $s_{4}$. Therefore, the distribution of $L$ is:\n$$\n\\Pr(L=1)=p(s_{1})=\\frac{1}{2},\\quad \\Pr(L=2)=p(s_{2})=\\frac{1}{4},\\quad \\Pr(L=3)=p(s_{3})+p(s_{4})=\\frac{1}{8}+\\frac{1}{8}=\\frac{1}{4}.\n$$\nCompute the mean:\n$$\n\\mathbb{E}[L]=1\\cdot\\frac{1}{2}+2\\cdot\\frac{1}{4}+3\\cdot\\frac{1}{4}=\\frac{1}{2}+\\frac{1}{2}+\\frac{3}{4}=\\frac{7}{4}.\n$$\nCompute the second moment:\n$$\n\\mathbb{E}[L^{2}]=1^{2}\\cdot\\frac{1}{2}+2^{2}\\cdot\\frac{1}{4}+3^{2}\\cdot\\frac{1}{4}=\\frac{1}{2}+1+\\frac{9}{4}=\\frac{15}{4}.\n$$\nUsing $\\operatorname{Var}(L)=\\mathbb{E}[L^{2}]-(\\mathbb{E}[L])^{2}$, we obtain:\n$$\n\\operatorname{Var}(L)=\\frac{15}{4}-\\left(\\frac{7}{4}\\right)^{2}=\\frac{15}{4}-\\frac{49}{16}=\\frac{60-49}{16}=\\frac{11}{16}.\n$$",
            "answer": "$$\\boxed{\\frac{11}{16}}$$"
        },
        {
            "introduction": "In many real-world systems, we gain information that should update our understanding of a random process. This is the essence of conditional probability. This exercise explores a simplified model of a noisy channel or measurement process, where the observed output gives us clues about the original input. You will practice calculating conditional expectation, a powerful tool for making the best possible estimate of one variable given knowledge of another .",
            "id": "1618705",
            "problem": "In a simplified model for measuring a quantum bit (qubit), a qubit is prepared in an initial state represented by a discrete random variable $X$. Due to environmental noise and measurement imperfections, the measured outcome is represented by another discrete random variable $Y$. Both the initial state $X$ and the measured outcome $Y$ can take values from the set $\\{0, 1\\}$.\n\nThe statistical relationship between the initial state and the measured outcome is described by the following joint probability mass function, $P_{X,Y}(x,y) = P(X=x, Y=y)$:\n- $P_{X,Y}(0, 0) = 0.5$\n- $P_{X,Y}(0, 1) = 0.1$\n- $P_{X,Y}(1, 0) = 0.1$\n- $P_{X,Y}(1, 1) = 0.3$\n\nBased on this model, what is the expected value of the initial state $X$, given that the measured outcome is observed to be $Y=0$? Express your answer as a fraction in simplest form.",
            "solution": "The problem asks for the conditional expectation of the random variable $X$ given that the random variable $Y$ has taken the value $0$. This is denoted as $E[X | Y=0]$.\n\nThe definition of conditional expectation for discrete random variables is:\n$$\nE[X | Y=y] = \\sum_{x} x \\cdot P(X=x | Y=y)\n$$\nIn our case, $y=0$, and the possible values for $x$ are $0$ and $1$. So, we need to calculate:\n$$\nE[X | Y=0] = (0) \\cdot P(X=0 | Y=0) + (1) \\cdot P(X=1 | Y=0)\n$$\nTo do this, we first need to find the conditional probabilities $P(X=0 | Y=0)$ and $P(X=1 | Y=0)$.\n\nThe formula for conditional probability is given by:\n$$\nP(X=x | Y=y) = \\frac{P(X=x, Y=y)}{P(Y=y)} = \\frac{P_{X,Y}(x,y)}{P_Y(y)}\n$$\nFirst, we must calculate the marginal probability $P_Y(0)$, which is the probability that the measured outcome is $Y=0$. We can find this by summing the joint probabilities over all possible values of $X$:\n$$\nP_Y(0) = \\sum_{x \\in \\{0, 1\\}} P_{X,Y}(x, 0) = P_{X,Y}(0, 0) + P_{X,Y}(1, 0)\n$$\nUsing the values provided in the problem statement:\n$$\nP_Y(0) = 0.5 + 0.1 = 0.6\n$$\nNow we can compute the required conditional probabilities:\nFor $x=0$:\n$$\nP(X=0 | Y=0) = \\frac{P_{X,Y}(0, 0)}{P_Y(0)} = \\frac{0.5}{0.6} = \\frac{5}{6}\n$$\nFor $x=1$:\n$$\nP(X=1 | Y=0) = \\frac{P_{X,Y}(1, 0)}{P_Y(0)} = \\frac{0.1}{0.6} = \\frac{1}{6}\n$$\n(As a check, these conditional probabilities must sum to 1: $\\frac{5}{6} + \\frac{1}{6} = \\frac{6}{6} = 1$, which is correct.)\n\nFinally, we can substitute these conditional probabilities back into the formula for conditional expectation:\n$$\nE[X | Y=0] = (0) \\cdot P(X=0 | Y=0) + (1) \\cdot P(X=1 | Y=0)\n$$\n$$\nE[X | Y=0] = (0) \\cdot \\frac{5}{6} + (1) \\cdot \\frac{1}{6}\n$$\n$$\nE[X | Y=0] = 0 + \\frac{1}{6} = \\frac{1}{6}\n$$\nThus, the expected value of the initial state $X$, given that the measured outcome is $Y=0$, is $\\frac{1}{6}$.",
            "answer": "$$\\boxed{\\frac{1}{6}}$$"
        }
    ]
}