{
    "hands_on_practices": [
        {
            "introduction": "The foundation of any probability model rests on its adherence to fundamental axioms. For a discrete joint probability mass function (PMF), the most basic requirement is that the sum of probabilities across all possible outcomes must equal one. This exercise  provides direct practice with this principle, challenging you to find the normalization constant $k$ that makes a given function a valid PMF.",
            "id": "1926691",
            "problem": "A data scientist at a financial technology company is analyzing the performance of two different fraud detection algorithms, Algorithm A and Algorithm B. Let $X$ be a random variable representing the number of suspicious flags raised by Algorithm A on a given transaction, and let $Y$ be the number of suspicious flags raised by Algorithm B on the same transaction.\n\nBased on extensive testing on a standardized dataset, the joint behavior of these two variables is modeled by the following joint probability mass function (PMF):\n$$p(x, y) = k(x + 2y)$$\nwhere $x$ can take values from the set $\\{1, 2\\}$ and $y$ can take values from the set $\\{1, 2, 3\\}$. The function $p(x, y)$ is zero for all other pairs of $(x, y)$. The constant $k$ is a normalization constant that ensures $p(x, y)$ is a valid PMF.\n\nDetermine the numerical value of the constant $k$. Express your answer as a fraction.",
            "solution": "To be a valid joint PMF, the total probability over the support must be one. Therefore,\n$$\\sum_{x \\in \\{1,2\\}} \\sum_{y \\in \\{1,2,3\\}} p(x,y) = 1.$$\nGiven $p(x,y) = k(x+2y)$ on the support, we have\n$$k \\sum_{x=1}^{2} \\sum_{y=1}^{3} (x + 2y) = 1.$$\nCompute the inner sum for fixed $x$:\n$$\\sum_{y=1}^{3} (x + 2y) = \\sum_{y=1}^{3} x + 2 \\sum_{y=1}^{3} y = 3x + 2 \\cdot \\frac{3 \\cdot 4}{2} = 3x + 12.$$\nNow sum over $x$:\n$$\\sum_{x=1}^{2} (3x + 12) = 3 \\sum_{x=1}^{2} x + 12 \\cdot 2 = 3 \\cdot \\frac{2 \\cdot 3}{2} + 24 = 9 + 24 = 33.$$\nThus,\n$$k \\cdot 33 = 1 \\quad \\Rightarrow \\quad k = \\frac{1}{33}.$$",
            "answer": "$$\\boxed{\\frac{1}{33}}$$"
        },
        {
            "introduction": "Joint probability distributions are powerful tools for analyzing real-world systems, from communication channels to financial markets. A classic application in information theory is quantifying the reliability of data transmission or storage. In this practical problem , you will use a joint probability model to calculate a system's overall bit-error rate, a critical performance metric in engineering.",
            "id": "1635042",
            "problem": "A computer engineer is analyzing the long-term reliability of a novel type of magnetic storage. In this system, data is stored as individual bits, which can be either a 0 or a 1. Let the random variable $X$ represent a bit that is initially written to the storage medium. Due to the properties of the data being stored, a bit is written as a '0' with probability $P(X=0) = 0.65$ and as a '1' with probability $P(X=1) = 0.35$.\n\nOver time, thermal noise can cause a stored bit to flip. Let the random variable $Y$ represent the value of the bit when it is read back at a later time. The noise process is asymmetric. The probability that a stored '0' is incorrectly read as a '1' is $0.08$. The probability that a stored '1' is incorrectly read as a '0' is $0.05$.\n\nAssuming that errors for different bits are independent events, determine the overall bit-error rate for this storage system. The bit-error rate is defined as the total probability that a randomly selected bit is read incorrectly, i.e., $P(Y \\neq X)$. Calculate this value based on the joint probability distribution of $X$ and $Y$.\n\nExpress your final answer as a numerical value rounded to three significant figures.",
            "solution": "We represent the initially written bit by the random variable $X$ with $P(X=0)=0.65$ and $P(X=1)=0.35$. The read-back bit is $Y$. The asymmetric noise process gives the conditional probabilities $P(Y=1 \\mid X=0)=0.08$ and $P(Y=0 \\mid X=1)=0.05$. By complementarity, $P(Y=0 \\mid X=0)=1-0.08=0.92$ and $P(Y=1 \\mid X=1)=1-0.05=0.95$.\n\nThe bit-error event is $E=\\{Y \\neq X\\}$, so by the law of total probability using the joint distribution via conditional probabilities,\n$$\nP(E)=P(Y=1,X=0)+P(Y=0,X=1)=P(X=0)P(Y=1 \\mid X=0)+P(X=1)P(Y=0 \\mid X=1).\n$$\nSubstituting the given values,\n$$\nP(E)=0.65 \\cdot 0.08 + 0.35 \\cdot 0.05=0.052+0.0175=0.0695.\n$$\nRounding to three significant figures yields $0.0695$.",
            "answer": "$$\\boxed{0.0695}$$"
        },
        {
            "introduction": "A common pitfall in statistics is equating zero correlation with independence. While independent variables are always uncorrelated, the reverse is not true, and this exercise  explores this crucial distinction through a clear, physically-inspired scenario. You will demonstrate that two variables can have a covariance of zero while being perfectly dependent on one another, deepening your understanding of statistical relationships.",
            "id": "1926651",
            "problem": "In a simplified model of a quantum particle trapped in a one-dimensional infinite potential well extending from $-L$ to $L$, the particle's position is described by a random variable. In the high temperature classical limit, we can model the particle's position, $X$, as a continuous random variable uniformly distributed over the interval $[-L, L]$.\n\nThe particle is also subject to a confining potential within the well, modeled by the function $V(x) = \\alpha x^2$, where $\\alpha$ is a known positive constant. The potential energy of the particle is thus also a random variable, denoted by $Y = \\alpha X^2$.\n\nBased on this model, which of the following statements correctly describes the relationship between the particle's position $X$ and its potential energy $Y$?\n\nA. The covariance $\\text{Cov}(X, Y)$ is zero, and the variables $X$ and $Y$ are independent.\n\nB. The covariance $\\text{Cov}(X, Y)$ is zero, and the variables $X$ and $Y$ are not independent.\n\nC. The covariance $\\text{Cov}(X, Y)$ is non-zero, and the variables $X$ and $Y$ are independent.\n\nD. The covariance $\\text{Cov}(X, Y)$ is non-zero, and the variables $X$ and $Y$ are not independent.\n\nE. Whether the covariance is zero or non-zero depends on the specific values of the constants $L$ and $\\alpha$.",
            "solution": "Let $X$ be uniformly distributed on $[-L, L]$, so its probability density function is $f_{X}(x) = \\frac{1}{2L}$ for $x \\in [-L,L]$ and $0$ otherwise. Define $Y = \\alpha X^{2}$ with $\\alpha>0$.\n\nCompute the expectations needed for the covariance. First,\n$$\n\\mathbb{E}[X] = \\int_{-L}^{L} x \\frac{1}{2L} \\,\\mathrm{d}x = 0\n$$\nby symmetry of an odd integrand over a symmetric interval.\n\nNext,\n$$\n\\mathbb{E}[Y] = \\alpha \\mathbb{E}[X^{2}] = \\alpha \\int_{-L}^{L} x^{2} \\frac{1}{2L} \\,\\mathrm{d}x = \\alpha \\frac{1}{2L} \\cdot \\int_{-L}^{L} x^{2}\\,\\mathrm{d}x = \\alpha \\frac{1}{2L} \\cdot \\frac{2 L^{3}}{3} = \\alpha \\frac{L^{2}}{3}.\n$$\n\nAlso,\n$$\n\\mathbb{E}[XY] = \\alpha \\mathbb{E}[X^{3}] = \\alpha \\int_{-L}^{L} x^{3} \\frac{1}{2L} \\,\\mathrm{d}x = 0\n$$\nagain by symmetry, since $x^{3}$ is an odd function over $[-L,L]$.\n\nTherefore the covariance is\n$$\n\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] = 0 - 0 \\cdot \\alpha \\frac{L^{2}}{3} = 0.\n$$\nThis holds for all $L>0$ and $\\alpha>0$, so the covariance does not depend on the specific values beyond positivity.\n\nTo assess independence, note that $Y$ is a deterministic (non-constant) function of $X$. For any $y$ with $0<y<\\alpha L^{2}$,\n$$\n\\mathbb{P}(Y \\le y \\mid X = x) = \\mathbf{1}\\{\\alpha x^{2} \\le y\\},\n$$\nwhich depends on $x$. Since $\\mathbb{P}(Y \\le y)$ is strictly between $0$ and $1$ for such $y$, it cannot equal $\\mathbb{P}(Y \\le y \\mid X = x)$ for all $x$ with positive density. Hence $X$ and $Y$ are not independent. Intuitively, knowing $Y$ determines $|X| = \\sqrt{Y/\\alpha}$, so $X$ and $Y$ are dependent.\n\nThus, the correct statement is that the covariance is zero and the variables are not independent.",
            "answer": "$$\\boxed{B}$$"
        }
    ]
}