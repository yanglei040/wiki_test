{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握信息瓶颈方法，一个有效的方法是首先理解其性能的两个极端情况。这个练习将引导我们分析两种基本压缩策略：完全不压缩（即传输原始数据）和完全无用的压缩（即传输与原始数据无关的信号）。通过计算这两种极端情况下的压缩成本 $I(X; T)$ 和相关性收益 $I(T; Y)$，我们可以为信息瓶颈的权衡曲线建立两个关键的基准点。",
            "id": "1631245",
            "problem": "在一个远程医疗监护系统的设计中，一个传感器测量一个离散的生理状态 $X$，该状态可以取 `low`、`medium` 或 `high` 这三个值之一。已知该状态与患者未来的健康结果 $Y$ 相关，其结果可以是 `healthy` 或 `sick`。描述这种关系的联合概率分布 $p(X, Y)$ 由下表给出：\n\n| $p(X,Y)$ | $Y = \\text{healthy}$ | $Y = \\text{sick}$ |\n| :--- | :---: | :---: |\n| $X = \\text{low}$ | $1/4$ | $0$ |\n| $X = \\text{medium}$ | $1/4$ | $1/4$ |\n| $X = \\text{high}$ | $0$ | $1/4$ |\n\n为了节省传输带宽，传感器的读数 $X$ 在发送到中央服务器之前，被映射到一个压缩表示 $T$。这种压缩的有效性采用信息瓶颈（IB）方法的原理进行评估。该方法考虑了两个关键量：互信息 $I(X; T)$，它量化了“瓶颈”的大小（值越小意味着压缩率越高）；以及互信息 $I(T; Y)$，它衡量了压缩信号保留了多少关于相关结果 $Y$ 的信息（值越大越好）。\n\n您需要分析两种极端的压缩方案：\n\n1.  **方案 1（无压缩）：** 传输信号表示为 $T_1$，是传感器测量的完美未压缩副本。\n2.  **方案 2（最大无用压缩）：** 传输信号表示为 $T_2$，其生成方式使其在统计上独立于传感器的测量值 $X$。\n\n对于这两种方案，请分别确定 $(I(X; T), I(T; Y))$ 对的值。所有对数计算均以 2 为底，这意味着所有信息论量纲都应以比特（bits）为单位。\n\n请以一个 2x2 的数值矩阵形式提供您的答案。第一行应包含方案 1 的值对，第二行应包含方案 2 的值对。在两行中，第一列必须是 $I(X;T)$ 的值，第二列必须是 $I(T;Y)$ 的值。",
            "solution": "给定 $(X,Y)$ 的联合分布。首先计算边缘分布：\n$$\np_{X}(\\text{low})=\\frac{1}{4},\\quad p_{X}(\\text{medium})=\\frac{1}{2},\\quad p_{X}(\\text{high})=\\frac{1}{4},\n$$\n$$\np_{Y}(\\text{healthy})=\\frac{1}{2},\\quad p_{Y}(\\text{sick})=\\frac{1}{2}.\n$$\n使用以 2 为底的对数， $X$ 的熵为\n$$\nH(X)=-\\sum_{x}p_{X}(x)\\log_{2}p_{X}(x)=-\\left[\\frac{1}{4}\\log_{2}\\frac{1}{4}+\\frac{1}{2}\\log_{2}\\frac{1}{2}+\\frac{1}{4}\\log_{2}\\frac{1}{4}\\right]=\\frac{3}{2}.\n$$\n$Y$ 的熵为\n$$\nH(Y)=-\\sum_{y}p_{Y}(y)\\log_{2}p_{Y}(y)=-\\left[\\frac{1}{2}\\log_{2}\\frac{1}{2}+\\frac{1}{2}\\log_{2}\\frac{1}{2}\\right]=1.\n$$\n给定 $X$ 时 $Y$ 的条件分布得出\n$$\nH(Y|X=\\text{low})=0,\\quad H(Y|X=\\text{medium})=1,\\quad H(Y|X=\\text{high})=0,\n$$\n所以\n$$\nH(Y|X)=\\sum_{x}p_{X}(x)H(Y|X=x)=\\frac{1}{2}.\n$$\n因此 $X$ 和 $Y$ 之间的互信息是\n$$\nI(X;Y)=H(Y)-H(Y|X)=1-\\frac{1}{2}=\\frac{1}{2}.\n$$\n\n方案 1（无压缩）：$T_{1}=X$，因此根据定义\n$$\nI(X;T_{1})=I(X;X)=H(X)=\\frac{3}{2},\n$$\n并且根据数据处理不等式，对于恒等映射 $T_{1}=X$，\n$$\nI(T_{1};Y)=I(X;Y)=\\frac{1}{2}.\n$$\n\n方案 2（最大无用压缩）：$T_{2}$ 独立于 $X$，即对所有 $x$ 都有 $p(t|x)=p(t)$。那么\n$$\nI(X;T_{2})=0.\n$$\n此外，\n$$\np(t,y)=\\sum_{x}p(t|x)p(x,y)=\\sum_{x}p(t)p(x,y)=p(t)\\sum_{x}p(x,y)=p(t)p(y),\n$$\n所以 $T_{2}$ 也独立于 $Y$，并且\n$$\nI(T_{2};Y)=0.\n$$\n\n因此，所求的 $(I(X;T),I(T;Y))$ 对是\n- 方案 1：$\\left(\\frac{3}{2},\\frac{1}{2}\\right)$，\n- 方案 2：$(0,0)$，\n组合成所需的 $2\\times 2$ 矩阵。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{3}{2} & \\frac{1}{2} \\\\ 0 & 0 \\end{pmatrix}}$$"
        },
        {
            "introduction": "在理解了信息瓶颈的理论边界之后，我们来解决一个更实际的优化问题。在这个场景中，我们需要为一个四元输入信号设计一个一比特的确定性编码器，目标是在给定的权衡参数 $\\beta$ 下，最大化信息瓶颈目标函数。这个练习要求我们系统地评估所有可能的编码方案（即将输入符号划分为两组），并计算它们各自的得分，从而亲手体验在压缩和保留相关信息之间进行权衡的过程。",
            "id": "1631238",
            "problem": "在机器学习领域，我们通常希望为一个高维输入变量创建一个压缩的低维表示，同时尽可能多地保留关于一个目标变量的相关信息。本问题探讨了这种权衡的一个简化版本。\n\n考虑一个系统，其中输入信号 $X$ 从四个符号的集合 $\\{a, b, c, d\\}$ 中均匀随机抽取。一个相关的二元输出信号 $Y$ 可以在 $\\{0, 1\\}$ 中取值。$X$ 和 $Y$ 之间的关系由以下条件概率描述：\n- $P(Y=1|X=a) = 0.1$\n- $P(Y=1|X=b) = 0.2$\n- $P(Y=1|X=c) = 0.8$\n- $P(Y=1|X=d) = 0.9$\n\n我们希望为 $X$ 设计一个一位（one-bit）的确定性编码器。这意味着我们将四个输入符号的集合 $\\{a, b, c, d\\}$ 划分成两个非空的分组。第一组中的所有符号被映射到压缩表示 $T=0$，第二组中的所有符号被映射到 $T=1$。\n\n给定编码（即一个划分）的质量由一个分数 $S$ 来衡量，其定义如下：\n$$S = I(T; Y) - \\beta I(X; T)$$\n此处，$I(A; B)$ 表示随机变量 $A$ 和 $B$ 之间的互信息，所有对数均以2为底，信息以比特为单位度量。参数 $\\beta$ 用于权衡表示 $T$ 关于目标 $Y$ 的信息量（相关性，$I(T;Y)$）与 $T$ 保留的关于原始信号 $X$ 的信息量（复杂度，$I(X;T)$）。\n\n对于权衡参数 $\\beta = 0.2$，请确定在所有可能的一位确定性编码中，$S$ 的最大可能分数。将你的最终答案保留到三位有效数字。",
            "solution": "设 $X$ 在 $\\{a,b,c,d\\}$ 上均匀分布，且 $Y \\in \\{0,1\\}$ 满足 $P(Y=1|X=a)=0.1$，$P(Y=1|X=b)=0.2$，$P(Y=1|X=c)=0.8$，$P(Y=1|X=d)=0.9$。一个一位确定性编码器 $T=f(X)$ 将 $\\{a,b,c,d\\}$ 划分成两个非空的分组。对于这样一个确定性的 $T$，我们有 $I(X;T)=H(T)$，因为 $H(T|X)=0$。相关性为 $I(T;Y)=H(Y)-H(Y|T)$。当 $X$ 是均匀分布时，$Y$ 的边际概率为\n$$\nP(Y=1)=\\frac{0.1+0.2+0.8+0.9}{4}=\\frac{2}{4}=0.5 \\;\\Rightarrow\\; H(Y)=1.\n$$\n因此，对于任何分组大小为 $n_{0}$ 和 $n_{1}$（其中 $n_{0}+n_{1}=4$）的划分，令 $q_{t}=P(Y=1|T=t)$ 为组 $t$ 中各符号对应的 $P(Y=1|X=x)$ 的平均值，我们有\n$$\nI(T;Y)=1-\\sum_{t\\in\\{0,1\\}} \\frac{n_{t}}{4}\\,h_{2}(q_{t}),\\qquad I(X;T)=H(T)=h_{2}\\!\\left(\\frac{n_{0}}{4}\\right),\n$$\n所以分数为\n$$\nS=1-\\sum_{t} \\frac{n_{t}}{4}\\,h_{2}(q_{t})-\\beta\\,h_{2}\\!\\left(\\frac{n_{0}}{4}\\right),\\qquad \\beta=0.2,\n$$\n其中 $h_{2}(p)=-p\\log_{2}p-(1-p)\\log_{2}(1-p)$。\n\n枚举所有在交换标签 $T=0,1$ 意义下不同的划分。\n\n1) 二-二划分：\n- $\\{a,b\\}\\mid\\{c,d\\}$: $q_{\\text{low}}=\\frac{0.1+0.2}{2}=0.15$，$q_{\\text{high}}=\\frac{0.8+0.9}{2}=0.85$，因此 $h_{2}(0.15)=h_{2}(0.85)$。那么\n$$\nH(Y|T)=\\frac{1}{2}h_{2}(0.15)+\\frac{1}{2}h_{2}(0.85)=h_{2}(0.15),\\quad H(T)=h_{2}\\!\\left(\\frac{1}{2}\\right)=1,\n$$\n所以\n$$\nS=1-h_{2}(0.15)-0.2\\times 1=0.8-h_{2}(0.15).\n$$\n计算 $h_{2}(0.15)=-0.15\\log_{2}(0.15)-0.85\\log_{2}(0.85)\\approx 0.609840304716,$ 因此\n$$\nS\\approx 0.8-0.609840304716=0.190159695284.\n$$\n- $\\{a,c\\}\\mid\\{b,d\\}$：$q=\\frac{0.1+0.8}{2}=0.45$ 和 $\\frac{0.2+0.9}{2}=0.55$，所以 $H(Y|T)=h_{2}(0.45)$ 且 $H(T)=1$。那么\n$$\nS=1-h_{2}(0.45)-0.2,\\quad h_{2}(0.45)\\approx 0.992774453 \\;\\Rightarrow\\; S\\approx -0.192774453.\n$$\n- $\\{a,d\\}\\mid\\{b,c\\}$：两个组的 $q$ 值都为0.5，所以 $I(T;Y)=0$ 且 $S=-0.2$。\n\n最优的二-二划分是 $\\{a,b\\}\\mid\\{c,d\\}$，其 $S\\approx 0.190159695284$。\n\n2) 一-三划分 (此处 $H(T)=h_{2}(1/4)\\approx 0.811278124459$，所以惩罚项为 $0.2\\times 0.811278124459\\approx 0.162255624892$)：\n- 单元素组 $\\{a\\}$：$h_{2}(0.1)\\approx 0.468995593$，另一个组的平均值 $q=\\frac{0.2+0.8+0.9}{3}=\\frac{19}{30}\\approx 0.633333333$，$h_{2}(q)\\approx 0.947161163$。那么\n$$\nH(Y|T)=\\frac{1}{4}h_{2}(0.1)+\\frac{3}{4}h_{2}\\!\\left(\\tfrac{19}{30}\\right)\\approx 0.827619771,\n$$\n所以 $I(T;Y)\\approx 0.172380229$ 且\n$$\nS\\approx 0.172380229-0.162255625\\approx 0.010124604.\n$$\n- 单元素组 $\\{b\\}$：$h_{2}(0.2)\\approx 0.721928095$，另一个组 $q=\\frac{0.1+0.8+0.9}{3}=0.6$，$h_{2}(0.6)\\approx 0.970950594$。那么 $I(T;Y)\\approx 0.091305031$ 且 $S\\approx -0.070950594$。\n- 单元素组 $\\{c\\}$ 与 $\\{b\\}$ 对称：$S\\approx -0.070950594$。\n- 单元素组 $\\{d\\}$ 与 $\\{a\\}$ 对称：$S\\approx 0.010124604$。\n\n因此，在所有一位确定性编码中，最大分数由划分 $\\{a,b\\}\\mid\\{c,d\\}$ 实现，得到\n$$\nS_{\\max}=0.8-h_{2}(0.15)\\approx 0.190159695284.\n$$\n保留三位有效数字，结果为 $0.190$。",
            "answer": "$$\\boxed{0.190}$$"
        },
        {
            "introduction": "前面的练习主要集中在确定性编码上，但信息瓶颈的威力也体现在其处理随机编码的能力上。本练习探讨了一个特殊的随机编码方案，其中压缩过程本身巧妙地利用了我们关心的相关变量 $Y$ 的信息。通过分析这种编码下的互信息 $I(X;T)$ 和 $I(T;Y)$，我们将揭示一个深刻的性质：即使在对原始数据 $X$ 进行了压缩的情况下，我们依然可以完整地保留所有关于 $Y$ 的信息。",
            "id": "1631250",
            "problem": "在一个特征提取系统的简化模型中，我们分析由一对独立且无偏的二进制信号 $X = (X_1, X_2)$ 组成的输入数据，其中 $P(X_1=0) = P(X_1=1) = 0.5$ 且 $P(X_2=0) = P(X_2=1) = 0.5$。该数据的一个相关特征是其奇偶性，定义为 $Y = X_1 \\oplus X_2$，其中 $\\oplus$ 表示异或 (XOR) 运算。\n\n为了降低数据维度，输入 $X$ 被压缩成一个三元表示 $T$，它可以取集合 $\\mathcal{T} = \\{t_1, t_2, t_3\\}$ 中的三个状态之一。该压缩是通过一个由条件概率分布 $p(t|x)$ 定义的随机映射实现的。映射规则如下：\n- 如果输入对 $X$ 的奇偶性为 0 (即 $Y=0$)，它被确定性地映射到状态 $t_1$。\n- 如果输入对 $X$ 的奇偶性为 1 (即 $Y=1$)，它被随机地映射到状态 $t_2$（概率为 $0.5$）或状态 $t_3$（概率为 $0.5$）。\n\n信息瓶颈 (IB) 方法被用于评估此压缩方案。压缩的质量由两个互信息量来评估：$I(X;T)$，它衡量压缩表示 $T$ 保留了多少关于原始数据 $X$ 的信息；以及 $I(T;Y)$，它衡量 $T$ 保留了多少关于相关特征 $Y$ 的信息。\n\n计算该系统中 $I(X;T)$ 和 $I(T;Y)$ 的值。所有信息论计算均使用以2为底的对数。将答案表示为一个有序数值对 $(I(X;T), I(T;Y))$，每个值以比特为单位，并四舍五入到四位有效数字。",
            "solution": "我们将 $X=(X_{1},X_{2})$ 建模，其中 $X_{1},X_{2}$ 独立且无偏，因此对于四个输入对中的每一个，都有 $p(x)=\\frac{1}{4}$。相关变量为 $Y=X_{1}\\oplus X_{2}$，因此 $P(Y=0)=P(Y=1)=\\frac{1}{2}$。压缩 $X\\mapsto T$ 仅依赖于 $Y$：如果 $Y=0$，则确定地有 $T=t_{1}$；如果 $Y=1$，则 $T=t_{2}$ 或 $T=t_{3}$ 的概率各为 $\\frac{1}{2}$。因此，$X\\to Y\\to T$ 是一个马尔可夫链，且在给定 $Y$ 的条件下，$T$ 与 $X$ 条件独立。\n\n首先计算 $T$ 的边际分布：\n$$\nP(T=t_{1})=P(Y=0)=\\frac{1}{2},\\quad P(T=t_{2})=P(T=t_{3})=\\frac{1}{2}\\cdot\\frac{1}{2}=\\frac{1}{4}.\n$$\n因此 $T$ 的熵为\n$$\nH(T)=-\\sum_{t\\in\\{t_{1},t_{2},t_{3}\\}}P(t)\\log_{2}P(t)=-\\left(\\tfrac{1}{2}\\log_{2}\\tfrac{1}{2}+\\tfrac{1}{4}\\log_{2}\\tfrac{1}{4}+\\tfrac{1}{4}\\log_{2}\\tfrac{1}{4}\\right)=\\tfrac{3}{2}\\ \\text{bits}.\n$$\n\n对于 $I(X;T)$，使用 $I(X;T)=H(T)-H(T|X)$，其中\n$$\nH(T|X)=\\sum_{x}P(x)H(T|X=x).\n$$\n对于奇偶性 $Y=0$ 的 $x$，$T$ 是确定性的 ($t_{1}$)，因此 $H(T|X=x)=0$。对于奇偶性 $Y=1$ 的 $x$，$T$ 以各 $\\frac{1}{2}$ 的概率为 $t_2$ 或 $t_3$，因此 $H(T|X=x)=1$。由于一半的 $x$ 奇偶性为 0，一半奇偶性为 1，\n$$\nH(T|X)=\\tfrac{1}{2}\\cdot 0+\\tfrac{1}{2}\\cdot 1=\\tfrac{1}{2}\\ \\text{bits},\n$$\n因此\n$$\nI(X;T)=H(T)-H(T|X)=\\tfrac{3}{2}-\\tfrac{1}{2}=1\\ \\text{bit}.\n$$\n等价地，由于 $X\\to Y\\to T$ 且 $T\\perp X\\mid Y$，有 $I(X;T)=I(Y;T)$。\n\n对于 $I(T;Y)$，一种方法是使用 $I(T;Y)=H(Y)-H(Y|T)$。根据映射规则，$T=t_{1}$ 意味着 $Y=0$，而 $T\\in\\{t_{2},t_{3}\\}$ 意味着 $Y=1$，所以 $Y$ 是 $T$ 的一个确定性函数，且 $H(Y|T)=0$。由于 $H(Y)=1$ 比特（因为 $Y$ 是无偏的），\n$$\nI(T;Y)=H(Y)-H(Y|T)=1-0=1\\ \\text{bit}.\n$$\n等价地，通过 $I(T;Y)=H(T)-H(T|Y)$，其中 $H(T|Y)=\\tfrac{1}{2}\\cdot 0+\\tfrac{1}{2}\\cdot 1=\\tfrac{1}{2}$，我们得到 $I(T;Y)=\\tfrac{3}{2}-\\tfrac{1}{2}=1$。\n\n四舍五入到四位有效数字，两个值均为 $1.0000$ 比特。因此，有序对 $(I(X;T),I(T;Y))$ 是 $(1.0000,1.0000)$。",
            "answer": "$$\\boxed{\\begin{pmatrix}1.0000 & 1.0000\\end{pmatrix}}$$"
        }
    ]
}