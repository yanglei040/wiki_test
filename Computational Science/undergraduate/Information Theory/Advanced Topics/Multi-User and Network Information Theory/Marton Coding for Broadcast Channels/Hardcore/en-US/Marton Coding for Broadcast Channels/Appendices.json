{
    "hands_on_practices": [
        {
            "introduction": "Before diving into complex calculations, let's begin with a fundamental question about the architecture of multi-user coding. This thought experiment  explores a hypothetical scenario to reveal the core principle that enables information transmission to multiple users in Marton's scheme. By examining what happens when a key statistical link is intentionally broken, we gain a much deeper appreciation for why the scheme is constructed the way it is.",
            "id": "1639313",
            "problem": "In the field of multi-user information theory, Marton's coding scheme provides an achievable rate region for sending private messages to two different users over a Discrete Memoryless Broadcast Channel (DM-BC). A DM-BC is defined by a channel input alphabet $\\mathcal{X}$, two output alphabets $\\mathcal{Y}_1$ and $\\mathcal{Y}_2$, and a conditional probability distribution $p(y_1, y_2|x)$.\n\nThe standard Marton inner bound states that any rate pair $(R_1, R_2)$ for private messages is achievable if it satisfies the following inequalities for some choice of auxiliary random variables $U_1, U_2$ and a joint distribution $p(u_1)p(u_2)p(x|u_1, u_2)$:\n$$R_1 \\le I(U_1; Y_1)$$\n$$R_2 \\le I(U_2; Y_2)$$\n$$R_1 + R_2 \\le I(U_1; Y_1) + I(U_2; Y_2) - I(U_1; U_2)$$\nThe full Marton region is the convex hull of the union of all such rate pairs over all valid choices of distributions.\n\nNow, consider a simplified coding strategy where the channel input $X$ is made statistically independent of the auxiliary variables $(U_1, U_2)$. In this scheme, the auxiliary variables $U_1$ and $U_2$ are still independent of each other. This means the overall joint distribution for the codebook generation has the form $p(u_1, u_2, x) = p(u_1)p(u_2)p(x)$.\n\nYour task is to determine the complete achievable rate region, denoted $\\mathcal{R}_{\\text{simp}}$, under this specific simplification. Which of the following statements correctly describes this region?\n\nA. The region is only the origin, i.e., $\\mathcal{R}_{\\text{simp}} = \\{(0, 0)\\}$.\n\nB. The region is a rectangle defined by the set of rate pairs $(R_1, R_2)$ such that $R_1 \\le \\max_{p(x)} I(X; Y_1)$ and $R_2 \\le \\max_{p(x)} I(X; Y_2)$.\n\nC. The region is the time-sharing region, defined as the convex hull of the points $(C_1, 0)$ and $(0, C_2)$, where $C_1 = \\max_{p(x)} I(X; Y_1)$ and $C_2 = \\max_{p(x)} I(X; Y_2)$.\n\nD. The region remains unchanged from the full Marton inner bound; the simplification does not restrict the achievable rates.\n\nE. The region is defined by the sum-rate constraint $R_1 + R_2 \\le \\max_{p(x)} I(X; Y_1, Y_2)$.",
            "solution": "We start from the standard Marton inner bound stated in the problem: for some auxiliary random variables $U_{1},U_{2}$ and a joint distribution $p(u_{1})p(u_{2})p(x\\mid u_{1},u_{2})$, any achievable rate pair $(R_{1},R_{2})$ must satisfy\n$$\nR_{1} \\le I(U_{1};Y_{1}),\\quad R_{2} \\le I(U_{2};Y_{2}),\\quad R_{1}+R_{2} \\le I(U_{1};Y_{1})+I(U_{2};Y_{2})-I(U_{1};U_{2}).\n$$\nUnder the simplification specified in the problem, the codebook generation has the product form\n$$\np(u_{1},u_{2},x)=p(u_{1})p(u_{2})p(x),\n$$\nwhich enforces $(U_{1},U_{2})$ independent of $X$, and $U_{1}$ independent of $U_{2}$. The channel law is $p(y_{1},y_{2}\\mid x)$, and the joint distribution factors as\n$$\np(u_{1},u_{2},x,y_{1},y_{2})=p(u_{1})p(u_{2})p(x)p(y_{1},y_{2}\\mid x).\n$$\nWe now compute the key mutual informations appearing in the Marton inequalities.\n\nFirst, since $U_{1}$ is independent of $X$ and $(Y_{1},Y_{2})$ are generated from $X$ alone through the memoryless broadcast channel, $U_{1}$ is independent of $(Y_{1},Y_{2})$. Formally,\n$$\np(u_{1},y_{1})=\\sum_{u_{2}}\\sum_{x}\\sum_{y_{2}} p(u_{1})p(u_{2})p(x)p(y_{1},y_{2}\\mid x)\n= p(u_{1})\\sum_{x}\\left[p(x)\\sum_{y_{2}}p(y_{1},y_{2}\\mid x)\\right]=p(u_{1})p(y_{1}),\n$$\nwhich implies $I(U_{1};Y_{1})=0$. By the same argument,\n$$\nI(U_{2};Y_{2})=0.\n$$\nMoreover, $U_{1}$ and $U_{2}$ are independent by assumption, so\n$$\nI(U_{1};U_{2})=0.\n$$\nSubstituting these values into the Marton inequalities yields\n$$\nR_{1} \\le 0,\\quad R_{2} \\le 0,\\quad R_{1}+R_{2} \\le 0.\n$$\nSince rates are nonnegative by definition, we conclude\n$$\nR_{1}=0,\\quad R_{2}=0.\n$$\nTherefore, the achievable region under this simplification is the singleton $\\{(0,0)\\}$.\n\nThis rules out the other options:\n- A rectangle with positive sides (option B) would require conveying information through $X$ correlated with the messages, which is impossible here because $X$ is independent of $(U_{1},U_{2})$ and hence of the messages under this scheme.\n- The time-sharing region (option C) also requires selecting $X$ distributions contingent on which user is being served; under $p(u_{1})p(u_{2})p(x)$ the input $X$ does not carry message-dependent information, so positive rates are not induced in the Marton bound used here.\n- Equality with the full Marton region (option D) is false because the full region relies on $X$ being a function of $(U_{1},U_{2})$; removing that dependence strictly reduces the region.\n- A sum-rate bound of the form $R_{1}+R_{2} \\le \\max_{p(x)} I(X;Y_{1},Y_{2})$ (option E) is a cut-set type outer bound, not the achievable region for this scheme; moreover, within this inner-bound formulation with independent $X$, the mutual informations controlling $R_{1}$ and $R_{2}$ are zero.\n\nHence the correct description is that the region collapses to the origin.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Now that we understand the necessity of linking the channel input to our messages, let's apply this knowledge to a practical scenario. This exercise  considers the straightforward case where messages for two users are encoded independently, representing a simplified version of the full Marton framework. Your task is to calculate the achievable rates for a specific broadcast erasure channel, providing you with hands-on practice in evaluating the mutual information bounds that define a rate region.",
            "id": "1639326",
            "problem": "Consider a two-user Discrete Memoryless Broadcast Channel (DM-BC) where a transmitter sends independent information to two separate receivers. The transmitter uses two independent binary inputs, $X_1 \\in \\{0, 1\\}$ and $X_2 \\in \\{0, 1\\}$, to encode the message for receiver 1 and receiver 2, respectively. The inputs are drawn from independent and uniform distributions, such that $P(X_1=i) = 0.5$ and $P(X_2=j) = 0.5$ for all $i, j \\in \\{0, 1\\}$.\n\nThe channel is characterized by its outputs $Y_1$ and $Y_2$ which belong to the alphabet $\\{0, 1, e\\}$, where 'e' denotes an erasure. The channel's behavior is governed by a random state variable $S$ which is independent of the inputs. The state $S$ can take one of three values $\\{s_1, s_2, s_3\\}$ with the following probabilities: $P(S=s_1) = 0.3$, $P(S=s_2) = 0.5$, and $P(S=s_3) = 0.2$. The channel outputs are determined by the inputs and the state as follows:\n- If $S=s_1$, then $Y_1 = X_1$ and $Y_2 = e$.\n- If $S=s_2$, then $Y_1 = e$ and $Y_2 = X_2$.\n- If $S=s_3$, then $Y_1 = X_1$ and $Y_2 = X_2$.\n\nAn achievable rate region for this channel can be found using a simplified version of Marton's coding framework, where the auxiliary random variables are set to be the channel inputs themselves, i.e., $U_1 = X_1$ and $U_2 = X_2$. Given that the inputs $X_1$ and $X_2$ are independent, this leads to an achievable rate region defined by the inequalities:\n$R_1 \\le I(X_1; Y_1)$\n$R_2 \\le I(X_2; Y_2)$\n\nDetermine the maximum achievable symmetric rate $R = R_1 = R_2$ for this channel. Express your answer in bits per channel use, rounded to four significant figures.",
            "solution": "The problem asks for the maximum achievable symmetric rate $R = R_1 = R_2$ for a given broadcast channel. The problem states that the achievable rates must satisfy the conditions $R_1 \\le I(X_1; Y_1)$ and $R_2 \\le I(X_2; Y_2)$. For a symmetric rate $R$, both conditions must hold, so we must have:\n$R \\le I(X_1; Y_1)$\n$R \\le I(X_2; Y_2)$\n\nThe maximum such $R$ is therefore the minimum of these two mutual information values:\n$$R = \\min(I(X_1; Y_1), I(X_2; Y_2))$$\nOur task is to compute these two mutual information terms. The inputs $X_1$ and $X_2$ are independent and uniformly distributed Bernoulli random variables ($P(X_k=0)=P(X_k=1)=0.5$).\n\n**Step 1: Calculate $I(X_1; Y_1)$**\n\nThe mutual information is defined as $I(X_1; Y_1) = H(Y_1) - H(Y_1|X_1)$. Let's compute each term.\n\nFirst, we find the conditional entropy $H(Y_1|X_1)$. This is the entropy of the output $Y_1$ when the input $X_1$ is known. Let's find the conditional probability distribution $p(y_1|x_1)$.\n- The event $Y_1 = X_1$ occurs if the channel state is $S=s_1$ or $S=s_3$. The probability of this is $P(S=s_1) + P(S=s_3) = 0.3 + 0.2 = 0.5$.\n- The event $Y_1 = e$ (erasure) occurs if the channel state is $S=s_2$. The probability of this is $P(S=s_2) = 0.5$.\n- The event $Y_1 = 1-X_1$ (an error) never occurs.\nSo, for a given $x_1$, the output $Y_1$ is either $x_1$ with probability $0.5$ or 'e' with probability $0.5$.\nThe conditional entropy $H(Y_1|X_1=x_1)$ is the entropy of this distribution:\n$$H(Y_1|X_1=x_1) = -(0.5 \\log_2(0.5) + 0.5 \\log_2(0.5)) = - \\log_2(0.5) = 1 \\text{ bit}$$\nSince this value is the same for $X_1=0$ and $X_1=1$, the average conditional entropy is $H(Y_1|X_1) = 1$ bit.\n\nAlternatively, this channel from $X_1$ to $Y_1$ is a Binary Erasure Channel (BEC) with erasure probability $p_e = P(S=s_2) = 0.5$. The information $I(X_1; Y_1)$ for a uniform input into a BEC is $1-p_e$. Let's verify this using the full formula.\n\nNext, we find the entropy of the output $H(Y_1)$. We need the marginal probability distribution $p(y_1)$.\n- $P(Y_1=e) = P(S=s_2) = 0.5$.\n- $P(Y_1=0) = P(Y_1=0|X_1=0)P(X_1=0) + P(Y_1=0|X_1=1)P(X_1=1)$. Since $P(Y_1=0|X_1=1)=0$, this is $P(Y_1=0) = P(Y_1=X_1|X_1=0)P(X_1=0) = (0.5)(0.5) = 0.25$.\n- $P(Y_1=1) = P(Y_1=1|X_1=1)P(X_1=1) + P(Y_1=1|X_1=0)P(X_1=0)$. Since $P(Y_1=1|X_1=0)=0$, this is $P(Y_1=1) = P(Y_1=X_1|X_1=1)P(X_1=1) = (0.5)(0.5) = 0.25$.\nThe distribution of $Y_1$ is $(P(Y_1=0), P(Y_1=1), P(Y_1=e)) = (0.25, 0.25, 0.5)$.\nThe entropy is:\n$$H(Y_1) = -(0.25 \\log_2(0.25) + 0.25 \\log_2(0.25) + 0.5 \\log_2(0.5))$$\n$$H(Y_1) = -(2 \\times 0.25 \\times (-2) + 0.5 \\times (-1)) = -( -1 + (-0.5) ) = 1.5 \\text{ bits}$$\nNow, we can compute the mutual information:\n$$I(X_1; Y_1) = H(Y_1) - H(Y_1|X_1) = 1.5 - 1 = 0.5 \\text{ bits}$$\nAs noted before, for a BEC with erasure probability $p_e=0.5$ and uniform input, the capacity is $1-p_e = 1-0.5=0.5$ bits.\n\n**Step 2: Calculate $I(X_2; Y_2)$**\n\nThe calculation is symmetric. The channel from $X_2$ to $Y_2$ is also a BEC.\n- The event $Y_2 = X_2$ occurs if the channel state is $S=s_2$ or $S=s_3$. The probability is $P(S=s_2) + P(S=s_3) = 0.5 + 0.2 = 0.7$.\n- The event $Y_2 = e$ (erasure) occurs if the channel state is $S=s_1$. The probability is $P(S=s_1) = 0.3$.\nThis corresponds to a BEC with erasure probability $p'_e = 0.3$.\nWith a uniform input $X_2$, the mutual information is:\n$$I(X_2; Y_2) = 1 - p'_e = 1 - 0.3 = 0.7 \\text{ bits}$$\n\n**Step 3: Determine the maximum symmetric rate**\n\nThe maximum achievable symmetric rate is the minimum of the two individual rates:\n$$R = \\min(I(X_1; Y_1), I(X_2; Y_2)) = \\min(0.5, 0.7) = 0.5 \\text{ bits per channel use}$$\n\nThe problem requires the answer to be rounded to four significant figures.\n$$R = 0.5000 \\text{ bits per channel use}$$",
            "answer": "$$\\boxed{0.5000}$$"
        },
        {
            "introduction": "Building on the previous examples, this problem explores a more sophisticated application of Marton's framework. Here, we construct the channel input $X$ as a specific function of two underlying auxiliary variables, a technique at the heart of superposition coding. This practice  will challenge you to meticulously trace the flow of information from the auxiliary variables to the channel outputs, calculating achievable rates in a scenario that models more advanced coding strategies.",
            "id": "1639344",
            "problem": "Consider a discrete memoryless Broadcast Channel (BC) with a ternary input alphabet $\\mathcal{X} = \\{0, 1, 2\\}$ and two binary output alphabets $\\mathcal{Y}_1 = \\mathcal{Y}_2 = \\{0, 1\\}$. The channel is characterized by the conditional probability distribution $p(y_1, y_2 | x)$, defined as follows for given success probabilities $p, q \\in (0,1)$:\n- If input $x=0$, the output is $(y_1, y_2) = (0, 0)$ with probability 1.\n- If input $x=1$, the output is $(y_1, y_2) = (1, 0)$ with probability $p$, and $(y_1, y_2) = (0, 0)$ with probability $1-p$.\n- If input $x=2$, the output is $(y_1, y_2) = (0, 1)$ with probability $q$, and $(y_1, y_2) = (0, 0)$ with probability $1-q$.\n- All other conditional probabilities $p(y_1, y_2 | x)$ are zero.\n\nTo communicate over this channel, a coding scheme based on Marton's inner bound is used. The input distribution is constructed using two independent auxiliary random variables, $U_1$ and $U_2$. Both $U_1$ and $U_2$ are uniformly distributed over the alphabet $\\{A, B\\}$. The channel input $X$ is then determined as a deterministic function of the pair $(U_1, U_2)$:\n- $X=1$ if $(U_1, U_2) = (B, A)$.\n- $X=2$ if $(U_1, U_2) = (A, B)$.\n- $X=0$ otherwise (i.e., if $(U_1, U_2) = (A, A)$ or $(U_1, U_2) = (B, B)$).\n\nFor the specified channel and this input distribution, Marton's theory defines an achievable rate region for the rate pair $(R_1, R_2)$. Your task is to determine the maximum achievable rate for user 1, denoted $R_{1,\\max}$, and the maximum achievable rate for user 2, denoted $R_{2,\\max}$. These correspond to the rate on one axis when the rate on the other is zero.\n\nExpress your answers for $R_{1,\\max}$ and $R_{2,\\max}$ in terms of the parameters $p$ and $q$. Your expressions may use the binary entropy function, defined as $H_b(z) = -z \\log(z) - (1-z)\\log(1-z)$ for $z \\in (0,1)$, with $H_b(0) = H_b(1)=0$. All logarithms are base 2. Present your final answer as a pair $(R_{1, \\max}, R_{2, \\max})$.",
            "solution": "By Martonâ€™s inner bound with independent auxiliaries and a deterministic encoder $X=f(U_{1},U_{2})$, the achievable region contains all rate pairs satisfying\n$$\nR_{1} \\leq I(U_{1};Y_{1}), \\quad R_{2} \\leq I(U_{2};Y_{2}), \\quad R_{1}+R_{2} \\leq I(U_{1};Y_{1})+I(U_{2};Y_{2})-I(U_{1};U_{2}).\n$$\nSince $U_{1}$ and $U_{2}$ are independent, $I(U_{1};U_{2})=0$, so the sum constraint is redundant. Therefore, the axis intercepts are\n$$\nR_{1,\\max}=I(U_{1};Y_{1}), \\qquad R_{2,\\max}=I(U_{2};Y_{2}).\n$$\n\nWe now compute $I(U_{1};Y_{1})$ for the given mapping and channel. The mapping is\n- $(U_{1},U_{2})=(A,A)\\ \\Rightarrow\\ X=0$,\n- $(U_{1},U_{2})=(B,B)\\ \\Rightarrow\\ X=0$,\n- $(U_{1},U_{2})=(B,A)\\ \\Rightarrow\\ X=1$,\n- $(U_{1},U_{2})=(A,B)\\ \\Rightarrow\\ X=2$,\nwith each pair having probability $\\frac{1}{4}$. The channel yields $Y_{1}=1$ only when $X=1$ and that occurs with success probability $p$; otherwise $Y_{1}=0$.\n\nCondition on $U_{1}$:\n- If $U_{1}=A$, then $(U_{1},U_{2})$ is either $(A,A)$ or $(A,B)$, which map to $X=0$ or $X=2$, both giving $Y_{1}=0$. Hence\n$$\nP(Y_{1}=1 \\mid U_{1}=A)=0,\\quad P(Y_{1}=0 \\mid U_{1}=A)=1,\\quad H(Y_{1}\\mid U_{1}=A)=H_{b}(0)=0.\n$$\n- If $U_{1}=B$, then $(U_{1},U_{2})$ is either $(B,A)$ or $(B,B)$, which map to $X=1$ or $X=0$. Given $U_{1}=B$, $U_{2}=A$ with probability $\\frac{1}{2}$, yielding $X=1$ and $Y_{1}=1$ with probability $p$; otherwise $Y_{1}=0$. Hence\n$$\nP(Y_{1}=1 \\mid U_{1}=B)=\\frac{1}{2}p,\\quad P(Y_{1}=0 \\mid U_{1}=B)=1-\\frac{1}{2}p,\\quad H(Y_{1}\\mid U_{1}=B)=H_{b}\\!\\left(\\frac{p}{2}\\right).\n$$\nAveraging over $U_{1}$ (which is uniform),\n$$\nH(Y_{1}\\mid U_{1})=\\frac{1}{2}H_{b}(0)+\\frac{1}{2}H_{b}\\!\\left(\\frac{p}{2}\\right)=\\frac{1}{2}H_{b}\\!\\left(\\frac{p}{2}\\right).\n$$\nThe marginal of $Y_{1}$ is\n$$\nP(Y_{1}=1)=P(X=1)\\,p=\\frac{1}{4}p,\\quad P(Y_{1}=0)=1-\\frac{p}{4},\n$$\nso\n$$\nH(Y_{1})=H_{b}\\!\\left(\\frac{p}{4}\\right).\n$$\nTherefore,\n$$\nR_{1,\\max}=I(U_{1};Y_{1})=H(Y_{1})-H(Y_{1}\\mid U_{1})=H_{b}\\!\\left(\\frac{p}{4}\\right)-\\frac{1}{2}H_{b}\\!\\left(\\frac{p}{2}\\right).\n$$\n\nBy symmetry, $Y_{2}=1$ only when $X=2$ and that occurs with success probability $q$. Repeating the same steps for $U_{2}$ and $Y_{2}$ gives\n- $P(Y_{2}=1 \\mid U_{2}=A)=0$, so $H(Y_{2}\\mid U_{2}=A)=0$,\n- $P(Y_{2}=1 \\mid U_{2}=B)=\\frac{1}{2}q$, so $H(Y_{2}\\mid U_{2}=B)=H_{b}\\!\\left(\\frac{q}{2}\\right)$,\n- $H(Y_{2}\\mid U_{2})=\\frac{1}{2}H_{b}\\!\\left(\\frac{q}{2}\\right)$,\n- $P(Y_{2}=1)=\\frac{1}{4}q$, hence $H(Y_{2})=H_{b}\\!\\left(\\frac{q}{4}\\right)$.\n\nThus,\n$$\nR_{2,\\max}=I(U_{2};Y_{2})=H_{b}\\!\\left(\\frac{q}{4}\\right)-\\frac{1}{2}H_{b}\\!\\left(\\frac{q}{2}\\right).\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix} H_{b}\\!\\left(\\frac{p}{4}\\right)-\\frac{1}{2}H_{b}\\!\\left(\\frac{p}{2}\\right) & H_{b}\\!\\left(\\frac{q}{4}\\right)-\\frac{1}{2}H_{b}\\!\\left(\\frac{q}{2}\\right) \\end{pmatrix}}$$"
        }
    ]
}