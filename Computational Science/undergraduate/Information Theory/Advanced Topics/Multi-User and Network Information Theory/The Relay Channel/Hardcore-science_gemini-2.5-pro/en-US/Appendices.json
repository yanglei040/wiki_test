{
    "hands_on_practices": [
        {
            "introduction": "This first exercise goes to the heart of the Decode-and-Forward (DF) protocol, the most intuitive relaying strategy. We analyze a scenario where the achievable rate is limited by a \"bottleneck\"—either the relay's ability to decode the source's message or the destination's ability to decode the information it receives. By calculating the specific mutual information terms for a discrete channel model, this practice  provides a concrete understanding of this fundamental performance limit in relay communications.",
            "id": "1664036",
            "problem": "Consider a discrete memoryless relay channel where a source, a relay, and a destination communicate. The source transmits a symbol $X$, the relay transmits a symbol $X_1$, the relay receives a symbol $Y_1$, and the destination receives a symbol $Y$. The alphabets for all four variables $X, X_1, Y_1, Y$ are binary, i.e., $\\{0, 1\\}$.\n\nThe channel's behavior is defined by the following probabilistic rules, where $\\oplus$ denotes addition modulo 2:\n1.  The symbol received by the relay is $Y_1 = X \\oplus Z_1$, where $Z_1$ is a random noise variable. $Z_1$ follows a Bernoulli distribution with parameter $p_1$, so $P(Z_1=1) = p_1$.\n2.  The symbol received by the destination is $Y = X \\oplus X_1 \\oplus Z_2$, where $Z_2$ is a random noise variable. $Z_2$ follows a Bernoulli distribution with parameter $p_2$, so $P(Z_2=1) = p_2$.\n\nThe noise variables $Z_1$ and $Z_2$ are statistically independent of each other and of the channel inputs $X$ and $X_1$. This channel structure implies that the joint conditional probability mass function of the channel outputs is $p(y, y_1 | x, x_1) = p(y_1 | x) p(y | x, x_1)$.\n\nWe consider a Decode-and-Forward (DF) communication protocol. For a specific choice of input distributions, the achievable rate of this scheme is given by the formula $R = \\min \\{ I(X; Y_1 | X_1), I(X, X_1; Y) \\}$, where $I(\\cdot;\\cdot|\\cdot)$ and $I(\\cdot;\\cdot)$ denote conditional and unconditional mutual information, respectively. All logarithms used in the information-theoretic calculations are base 2.\n\nAssume that the source input $X$ and the relay input $X_1$ are chosen to be statistically independent, and both are uniformly distributed over the alphabet $\\{0, 1\\}$. Given the noise parameters $p_1 = 1/4$ and $p_2 = 1/3$, determine the value of the achievable rate $R$.\n\nExpress your final answer as a single closed-form analytic expression in units of bits per channel use. Your expression may include logarithms and fractions but must be fully simplified.",
            "solution": "We are given a binary-input, binary-output discrete memoryless relay channel with\n$Y_{1} = X \\oplus Z_{1}$, where $Z_{1} \\sim \\mathrm{Bern}(p_{1})$, and\n$Y = X \\oplus X_{1} \\oplus Z_{2}$, where $Z_{2} \\sim \\mathrm{Bern}(p_{2})$.\nThe inputs $X$ and $X_{1}$ are independent and both uniform over $\\{0,1\\}$, and $Z_{1}, Z_{2}$ are independent of everything.\n\nFor Decode-and-Forward with independent uniform inputs, the achievable rate is\n$$\nR = \\min\\{ I(X; Y_{1} \\mid X_{1}),\\ I(X, X_{1}; Y) \\}.\n$$\n\nFirst, compute $I(X; Y_{1} \\mid X_{1})$.\nBy definition,\n$$\nI(X; Y_{1} \\mid X_{1}) = H(Y_{1} \\mid X_{1}) - H(Y_{1} \\mid X, X_{1}).\n$$\nSince $Y_{1}$ depends only on $(X, Z_{1})$ and $(X, Y_{1})$ are independent of $X_{1}$, we have $H(Y_{1} \\mid X_{1}) = H(Y_{1})$ and $H(Y_{1} \\mid X, X_{1}) = H(Y_{1} \\mid X)$.\nMoreover, $Y_{1} = X \\oplus Z_{1}$ is a binary symmetric channel (BSC) with crossover probability $p_{1}$ and uniform input $X$, so $Y_{1}$ is uniform and\n$$\nH(Y_{1}) = 1, \\quad H(Y_{1} \\mid X) = H(Z_{1}) = h_{2}(p_{1}),\n$$\nwhere $h_{2}(p) = -p \\log_{2} p - (1-p)\\log_{2}(1-p)$ is the binary entropy function. Hence,\n$$\nI(X; Y_{1} \\mid X_{1}) = 1 - h_{2}(p_{1}).\n$$\n\nNext, compute $I(X, X_{1}; Y)$. Let $S = X \\oplus X_{1}$. Since $X$ and $X_{1}$ are independent and uniform, $S$ is uniform on $\\{0,1\\}$. The channel to the destination is\n$$\nY = S \\oplus Z_{2},\n$$\nwhich is a BSC with crossover probability $p_{2}$ and uniform input $S$. As $S$ is a deterministic function of $(X, X_{1})$, the data processing identity gives\n$$\nI(X, X_{1}; Y) = I(S; Y) = 1 - h_{2}(p_{2}).\n$$\n\nTherefore,\n$$\nR = \\min\\{ 1 - h_{2}(p_{1}),\\ 1 - h_{2}(p_{2}) \\}.\n$$\nWith $p_{1} = \\frac{1}{4}$ and $p_{2} = \\frac{1}{3}$, and noting that $h_{2}(p)$ is increasing on $[0, \\frac{1}{2}]$ so that $h_{2}\\!\\left(\\frac{1}{3}\\right) > h_{2}\\!\\left(\\frac{1}{4}\\right)$, we have\n$$\nR = 1 - h_{2}\\!\\left(\\frac{1}{3}\\right).\n$$\nExpanding $h_{2}\\!\\left(\\frac{1}{3}\\right)$,\n$$\nh_{2}\\!\\left(\\frac{1}{3}\\right) = -\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right) - \\frac{2}{3}\\log_{2}\\!\\left(\\frac{2}{3}\\right)\n= -\\frac{1}{3}(-\\log_{2} 3) - \\frac{2}{3}(1 - \\log_{2} 3)\n= -\\frac{2}{3} + \\log_{2} 3.\n$$\nThus,\n$$\nR = 1 - \\left(-\\frac{2}{3} + \\log_{2} 3\\right) = \\frac{5}{3} - \\log_{2} 3.\n$$\nThis is the achievable rate in bits per channel use.",
            "answer": "$$\\boxed{\\frac{5}{3}-\\log_{2}3}$$"
        },
        {
            "introduction": "Having understood the bottleneck principle, we now explore how a relay can create parallel communication paths to enhance performance. This problem  presents a thought experiment where the source-to-relay link is perfect, thereby removing the first-hop bottleneck entirely. This idealization allows us to focus solely on the benefit at the destination, which receives signals from both the source and the relay simultaneously, effectively transforming a single transmission into a powerful dual-channel system.",
            "id": "1664030",
            "problem": "Consider a relay channel model inspired by a simple cooperative communication system. The system consists of three nodes: a source node (S), a relay node (R), and a destination node (D). Communication from the source to the destination is assisted by the relay.\n\nThe channel links are characterized as follows:\n1.  The link from the source (S) to the relay (R) is a perfect, noiseless channel, allowing for error-free transmission at any required rate.\n2.  The link from the source (S) to the destination (D) is a Binary Symmetric Channel (BSC), which is a channel model for binary communication systems with noise. It has a crossover probability $p_1$.\n3.  The link from the relay (R) to the destination (D) is an independent BSC with a crossover probability $p_2$.\n\nThe relay operates using the Decode-and-Forward (DF) protocol. In this protocol, the relay first fully decodes the message transmitted by the source and then re-encodes and forwards it to the destination. The transmissions from the source and the relay to the destination occur over orthogonal channels, meaning they do not interfere with each other at the receiver.\n\nFind the maximum achievable communication rate for this system. Express your answer in bits per channel use as a fully expanded symbolic expression in terms of $p_1$ and $p_2$. Your answer should not use the binary entropy function notation, $H_b(p)$, but should instead be written explicitly using logarithms with base 2.",
            "solution": "Let the source message be $M$. Under Decode-and-Forward with a perfect $S \\to R$ link, the relay decodes $M$ without error and re-encodes it. The source and relay transmit over orthogonal channels to the destination, so in each channel use the destination observes two outputs: $Y_{1}$ from the source through a BSC with crossover probability $p_{1}$, and $Y_{2}$ from the relay through an independent BSC with crossover probability $p_{2}$. Denote the source input by $X_{S}$ and the relay input by $X_{R}$. The channel law factors as\n$$\nP_{Y_{1},Y_{2}|X_{S},X_{R}}(y_{1},y_{2}|x_{S},x_{R})=P_{\\text{BSC}(p_{1})}(y_{1}|x_{S})\\,P_{\\text{BSC}(p_{2})}(y_{2}|x_{R}).\n$$\nSince both encoders know $M$, they can choose codebooks so that $X_{S}$ and $X_{R}$ are independent given $M$ and also independent unconditionally for the purpose of maximizing mutual information. For a memoryless orthogonal product channel, the per-use mutual information for a common message is\n$$\nI(X_{S},X_{R};Y_{1},Y_{2})=H(Y_{1},Y_{2})-H(Y_{1},Y_{2}|X_{S},X_{R}).\n$$\nIf we choose $X_{S}$ and $X_{R}$ independent, then $(Y_{1},Y_{2})$ are independent, and $Y_{1} \\perp Y_{2}$ given $(X_{S},X_{R})$, so\n$$\nH(Y_{1},Y_{2})=H(Y_{1})+H(Y_{2}), \\quad H(Y_{1},Y_{2}|X_{S},X_{R})=H(Y_{1}|X_{S})+H(Y_{2}|X_{R}),\n$$\nand therefore\n$$\nI(X_{S},X_{R};Y_{1},Y_{2})=I(X_{S};Y_{1})+I(X_{R};Y_{2}).\n$$\nMaximizing over input distributions factorizes into two separate maximizations, one for each BSC. For a BSC with crossover probability $p$, the mutual information for input $X \\sim \\text{Bernoulli}(q)$ is\n$$\nI(X;Y)=H(Y)-H(Y|X),\n$$\nwhere $H(Y|X)= -p \\log_{2}(p) - (1-p)\\log_{2}(1-p)$ and $H(Y)$ is maximized (to $1$ bit) by the symmetric input $q=\\frac{1}{2}$. Thus the capacity of a BSC$(p)$ is\n$$\nC_{\\text{BSC}(p)}=1 - \\big(-p \\log_{2}(p) - (1-p)\\log_{2}(1-p)\\big)=1 + p \\log_{2}(p) + (1-p)\\log_{2}(1-p).\n$$\nApplying this to the two independent orthogonal links gives the maximum achievable rate as the sum\n$$\nR_{\\max}=C_{\\text{BSC}(p_{1})}+C_{\\text{BSC}(p_{2})}=2 + p_{1}\\log_{2}(p_{1}) + (1-p_{1})\\log_{2}(1-p_{1}) + p_{2}\\log_{2}(p_{2}) + (1-p_{2})\\log_{2}(1-p_{2}).\n$$\nThere is no additional decoding constraint from the relay because the $S \\to R$ link is perfect and supports any rate.",
            "answer": "$$\\boxed{2 + p_{1}\\log_{2}(p_{1}) + \\left(1-p_{1}\\right)\\log_{2}\\!\\left(1-p_{1}\\right) + p_{2}\\log_{2}(p_{2}) + \\left(1-p_{2}\\right)\\log_{2}\\!\\left(1-p_{2}\\right)}$$"
        },
        {
            "introduction": "To bridge theory with practice, this final problem  situates the Decode-and-Forward protocol within a more realistic wireless environment characterized by fading. Fading causes channel strengths to fluctuate randomly, a common challenge in mobile communication. By calculating the ergodic rate—the average performance across all possible channel conditions—you will learn how to evaluate the long-term reliability and throughput of a relay-assisted system operating in a dynamic setting.",
            "id": "1664009",
            "problem": "Consider a wireless communication system consisting of a source node (S), a relay node (R), and a destination node (D). Communication occurs over a slow block-fading channel subject to Additive White Gaussian Noise (AWGN). The system employs a half-duplex Decode-and-Forward (DF) protocol, where transmission is divided into two orthogonal time slots of equal duration. In the first slot, S broadcasts its message to both R and D. In the second slot, if the relay has successfully decoded the message, it re-encodes and forwards it to D.\n\nThe received signal-to-noise ratios (SNRs) on the links depend on the channel power gains, which are random. Let $g_{SR}$, $g_{SD}$, and $g_{RD}$ be the channel power gains for the S-R, S-D, and R-D links, respectively. These gains are constant for the duration of a transmission block but vary independently from one block to another. To model this fading, we assume the gains follow a simple discrete distribution. For each link, the gain can take one of two values with equal probability (1/2). The possible values are:\n- $g_{SR} \\in \\{0.1, 1.5\\}$\n- $g_{SD} \\in \\{0.2, 0.8\\}$\n- $g_{RD} \\in \\{0.3, 1.0\\}$\n\nThe normalized transmit SNR from the source is $P_S/N_0 = 10$, and from the relay is $P_R/N_0 = 20$, where $P_S$ and $P_R$ are the transmit powers and $N_0$ is the noise power.\n\nFor a specific realization of channel gains $(g_{SR}, g_{SD}, g_{RD})$, the instantaneous achievable rate (spectral efficiency) of this DF scheme is given by:\n$$R = \\frac{1}{2} \\min\\left\\{ \\log_2\\left(1 + \\frac{P_S}{N_0} g_{SR}\\right), \\log_2\\left(1 + \\frac{P_S}{N_0} g_{SD} + \\frac{P_R}{N_0} g_{RD}\\right) \\right\\}$$\nThis rate is measured in bits per second per Hertz (bits/s/Hz).\n\nCalculate the ergodic rate, defined as the statistical average of the instantaneous rate $R$ over all possible channel states. Express your final answer in bits/s/Hz, rounded to three significant figures.",
            "solution": "The instantaneous DF rate for a given channel state is\n$$\nR=\\frac{1}{2}\\min\\left\\{\\log_{2}\\left(1+\\frac{P_{S}}{N_{0}}g_{SR}\\right),\\ \\log_{2}\\left(1+\\frac{P_{S}}{N_{0}}g_{SD}+\\frac{P_{R}}{N_{0}}g_{RD}\\right)\\right\\},\n$$\nwith $\\frac{P_{S}}{N_{0}}=10$ and $\\frac{P_{R}}{N_{0}}=20$. The gains on each link take two values with probability $\\frac{1}{2}$, independently across links, so there are $8$ equiprobable states.\n\nFirst compute the two arguments of the minimum:\n- For the S-R term, since $g_{SR}\\in\\{0.1,1.5\\}$,\n$$\n\\log_{2}\\left(1+10g_{SR}\\right)=\n\\begin{cases}\n\\log_{2}(2)=1, & g_{SR}=0.1,\\\\\n\\log_{2}(16)=4, & g_{SR}=1.5.\n\\end{cases}\n$$\n- For the combined S-D and R-D term, with $g_{SD}\\in\\{0.2,0.8\\}$ and $g_{RD}\\in\\{0.3,1.0\\}$,\n$$\n\\log_{2}\\left(1+10g_{SD}+20g_{RD}\\right)\\in\\left\\{\\log_{2}(9),\\ \\log_{2}(15),\\ \\log_{2}(23),\\ \\log_{2}(29)\\right\\},\n$$\nnumerically\n$$\n\\log_{2}(9)=3.169925001442312,\\quad \\log_{2}(15)=3.9068905956085187,\\quad \\log_{2}(23)=4.523561956057013,\\quad \\log_{2}(29)=4.857980995127572.\n$$\n\nNow evaluate $R$ in each case:\n- If $g_{SR}=0.1$, then $\\log_{2}(1+10g_{SR})=1$, which is less than any of the four combined-link values above. Hence, in each of the four states with $g_{SR}=0.1$,\n$$\nR=\\frac{1}{2}\\cdot 1=\\frac{1}{2}.\n$$\n- If $g_{SR}=1.5$, then $\\log_{2}(1+10g_{SR})=4$, so\n$$\nR=\\frac{1}{2}\\min\\left\\{4,\\ \\log_{2}\\left(1+10g_{SD}+20g_{RD}\\right)\\right\\},\n$$\nyielding for the four $(g_{SD},g_{RD})$ pairs:\n$$\n\\begin{aligned}\n(g_{SD},g_{RD})=(0.2,0.3):&\\quad R=\\frac{1}{2}\\log_{2}(9)=1.584962500721156,\\\\\n(0.2,1.0):&\\quad R=\\frac{1}{2}\\cdot 4=2,\\\\\n(0.8,0.3):&\\quad R=\\frac{1}{2}\\log_{2}(15)=1.953445297804259,\\\\\n(0.8,1.0):&\\quad R=\\frac{1}{2}\\cdot 4=2.\n\\end{aligned}\n$$\n\nThe ergodic rate is the average over the $8$ equiprobable states:\n$$\n\\mathbb{E}[R]=\\frac{1}{8}\\left(4\\cdot \\frac{1}{2}+\\left[1.584962500721156+2+1.953445297804259+2\\right]\\right).\n$$\nCompute the sum inside:\n$$\n4\\cdot \\frac{1}{2}=2,\\quad 1.584962500721156+2+1.953445297804259+2=7.538407798525415,\n$$\nso\n$$\n\\mathbb{E}[R]=\\frac{1}{8}\\left(2+7.538407798525415\\right)=\\frac{9.538407798525415}{8}=1.1923009748156769.\n$$\nRounding to three significant figures gives $1.19$ bits/s/Hz.",
            "answer": "$$\\boxed{1.19}$$"
        }
    ]
}