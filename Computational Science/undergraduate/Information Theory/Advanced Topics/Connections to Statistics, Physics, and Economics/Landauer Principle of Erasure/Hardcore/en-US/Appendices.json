{
    "hands_on_practices": [
        {
            "introduction": "While the canonical example of Landauer's principle involves a single binary bit, modern computing explores diverse memory architectures. This first practice challenges you to generalize the principle to memory cells capable of storing multiple states. You will then apply this generalized understanding to a practical engineering problem, comparing the energy efficiency of binary and quaternary systems, and discovering how fundamental physics guides design trade-offs in information technology. ",
            "id": "1636482",
            "problem": "In a new computing paradigm, memory cells are designed to store an integer from $0$ to $N-1$, meaning each cell has $N$ possible states. This is a generalization of a standard binary bit, for which $N=2$. According to Landauer's principle, erasing information—that is, resetting a memory cell to a specific known state—dissipates a minimum amount of energy as heat into the surrounding thermal environment, which is at a constant temperature $T$. Assume that before erasure, the memory cell is equally likely to be in any of its $N$ possible states.\n\nNow, consider a task that requires storing a unique identification number for one of $M=500$ different items. Two memory architectures are proposed:\n1.  A binary architecture using standard bits ($N=2$).\n2.  A quaternary architecture using 'quits' ($N=4$).\n\nIn each architecture, a block of memory cells is used to represent a single identification number. The number of cells in the block must be the minimum required to represent all $M$ items. Let $E_{\\text{binary}}$ be the total minimum energy dissipated to erase the entire block of binary bits, and let $E_{\\text{quaternary}}$ be the total minimum energy dissipated to erase the entire block of quits.\n\nCalculate the exact value of the ratio $\\frac{E_{\\text{quaternary}}}{E_{\\text{binary}}}$. The Boltzmann constant is $k_B$.",
            "solution": "By Landauer’s principle, erasing a system that is equally likely to be in any one of $\\Omega$ logical states to a single known state dissipates a minimum energy\n$$\nE_{\\min}=k_{B}T\\ln \\Omega.\n$$\nFor a single base-$N$ cell with $N$ equiprobable states, $\\Omega=N$, so\n$$\nE_{\\text{cell}}=k_{B}T\\ln N.\n$$\nFor a block of $c$ independent base-$N$ cells, the number of equiprobable states is $\\Omega_{\\text{block}}=N^{c}$, hence\n$$\nE_{\\text{block}}=k_{B}T\\ln\\left(N^{c}\\right)=c\\,k_{B}T\\ln N.\n$$\nTo represent $M$ distinct items, the minimum number of base-$N$ cells required is the smallest integer $c$ such that $N^{c}\\geq M$, i.e.,\n$$\nc(N)=\\lceil \\log_{N} M\\rceil.\n$$\nFor the binary architecture ($N=2$) with $M=500$, since $2^{8}=256  500 \\leq 2^{9}=512$, we have\n$$\nc_{\\text{binary}}=\\lceil \\log_{2}500\\rceil=9,\\quad E_{\\text{binary}}=9\\,k_{B}T\\ln 2.\n$$\nFor the quaternary architecture ($N=4$), since $4^{4}=256  500 \\leq 4^{5}=1024$, we have\n$$\nc_{\\text{quaternary}}=\\lceil \\log_{4}500\\rceil=5,\\quad E_{\\text{quaternary}}=5\\,k_{B}T\\ln 4=5\\,k_{B}T\\ln(2^{2})=10\\,k_{B}T\\ln 2.\n$$\nTherefore, the ratio is\n$$\n\\frac{E_{\\text{quaternary}}}{E_{\\text{binary}}}=\\frac{10\\,k_{B}T\\ln 2}{9\\,k_{B}T\\ln 2}=\\frac{10}{9}.\n$$",
            "answer": "$$\\boxed{\\frac{10}{9}}$$"
        },
        {
            "introduction": "Information erasure is not always an all-or-nothing reset from total randomness. This exercise explores the more nuanced scenario of partial erasure, calculating the work needed to transition a bit from a state of maximum uncertainty to one of partial certainty. By tackling this problem, you will see how the minimum energy cost is precisely tied to the *change* in the system's Shannon entropy, providing a deeper and more versatile understanding of the connection between energy and information. ",
            "id": "1636458",
            "problem": "A research team is developing a novel nanoscale memory device. A single bit of information in this device is stored in a two-state physical system, which is maintained in thermal equilibrium with a large heat reservoir at a constant absolute temperature $T$.\n\nInitially, the memory bit is in a state of maximum uncertainty, where the probabilities of it being in the logical '0' state, $p(0)$, and the logical '1' state, $p(1)$, are equal. The system is then subjected to a thermodynamically reversible, isothermal process that changes it to a state of partial certainty. In this final state, the probability of the bit being in the '0' state is $p_{\\text{final}}(0) = 0.9$, and the probability of it being in the '1' state is $p_{\\text{final}}(1) = 0.1$.\n\nYour task is to determine the minimum theoretical work, $W$, that must be performed on the system to accomplish this change in its informational state. Express your answer as a symbolic expression in terms of the temperature $T$ and the Boltzmann constant, $k_B$.",
            "solution": "For a system in contact with a heat reservoir at fixed temperature $T$, a thermodynamically reversible, isothermal transformation requires work equal to the change in Helmholtz free energy:\n$$\nW_{\\text{rev}}=\\Delta F=\\Delta U - T\\Delta S,\n$$\nwhere $U$ is the internal energy and $S$ is the thermodynamic entropy. For a purely informational transformation of a symmetric two-state memory (no net change in the system’s average internal energy between the initial and final equilibrium states), the minimal work is achieved with $\\Delta U=0$, giving\n$$\nW_{\\min}=-T\\Delta S=T(S_{i}-S_{f}).\n$$\nThe thermodynamic entropy for a discrete equilibrium distribution over logically degenerate states equals the Shannon entropy (in nats) times $k_{B}$:\n$$\nS=-k_{B}\\sum_{x}p(x)\\,\\ln p(x).\n$$\nInitially, $p_{i}(0)=p_{i}(1)=\\frac{1}{2}$, so\n$$\nS_{i}=-k_{B}\\left[\\tfrac{1}{2}\\ln\\left(\\tfrac{1}{2}\\right)+\\tfrac{1}{2}\\ln\\left(\\tfrac{1}{2}\\right)\\right]=k_{B}\\ln 2.\n$$\nFinally, $p_{f}(0)=\\tfrac{9}{10}$ and $p_{f}(1)=\\tfrac{1}{10}$, so\n$$\nS_{f}=-k_{B}\\left[\\tfrac{9}{10}\\ln\\left(\\tfrac{9}{10}\\right)+\\tfrac{1}{10}\\ln\\left(\\tfrac{1}{10}\\right)\\right].\n$$\nHence the minimum theoretical work that must be performed on the system is\n$$\nW_{\\min}=T(S_{i}-S_{f})=k_{B}T\\left[\\ln 2+\\tfrac{9}{10}\\ln\\left(\\tfrac{9}{10}\\right)+\\tfrac{1}{10}\\ln\\left(\\tfrac{1}{10}\\right)\\right].\n$$",
            "answer": "$$\\boxed{k_{B}T\\left[\\ln 2+\\frac{9}{10}\\ln\\!\\left(\\frac{9}{10}\\right)+\\frac{1}{10}\\ln\\!\\left(\\frac{1}{10}\\right)\\right]}$$"
        },
        {
            "introduction": "In real physical systems, bits are rarely isolated; they often exhibit correlations that affect their collective information content. This practice investigates the thermodynamic consequences of such correlations, asking you to compare the energy needed to erase a bit with and without knowledge of its correlated partner. This problem introduces the crucial concept of conditional entropy, demonstrating how side information can be physically leveraged to reduce the energy cost of computation. ",
            "id": "1636479",
            "problem": "Consider a nanoscale computational device that functions as a two-bit memory register at a constant temperature $T$. The two bits, labeled A and B, can each be in a state of '0' or '1'. Due to interactions within the device, the states of the two bits are correlated. Over many observations, the joint probability distribution $p(A=a, B=b)$ for the states of the bits has been determined as follows:\n- $p(A=0, B=0) = \\frac{1}{2}$\n- $p(A=1, B=0) = \\frac{1}{4}$\n- $p(A=0, B=1) = 0$\n- $p(A=1, B=1) = \\frac{1}{4}$\n\nAccording to Landauer's principle, the minimum thermodynamic work (energy cost) required to erase information is proportional to the amount of information erased. The process of \"erasing\" bit A is defined as an operation that deterministically forces bit A into the '0' state, regardless of its initial state. The Boltzmann constant is denoted by $k_B$.\n\nWe are interested in comparing the energy cost of two different protocols for erasing bit A:\n\n- **Protocol 1:** A non-selective protocol that erases bit A to the '0' state without any prior knowledge of the state of bit B. Let the minimum energy cost for this protocol be $W_1$.\n- **Protocol 2:** A selective protocol that consists of two steps. First, an ideal, error-free measurement of bit B is performed. Second, an operation tailored to the measured outcome of B is used to erase bit A to the '0' state. Let the minimum *average* energy cost for this protocol, averaged over the possible outcomes of measuring B, be $W_2$.\n\nCalculate the ratio $\\frac{W_1}{W_2}$. Round your final answer to four significant figures.",
            "solution": "By Landauer’s principle, the minimal average work to reset a random variable $X$ to a fixed value at temperature $T$ is $W_{\\min}=k_{B}T\\ln 2\\cdot H(X)$ when $H$ is measured in bits. With side information $Y$ (obtained ideally and used for feedback), the minimal average work is $W_{\\min}=k_{B}T\\ln 2\\cdot H(X|Y)$.\n\nProtocol 1 erases $A$ without any knowledge of $B$, so\n$$\nW_{1}=k_{B}T\\ln 2\\cdot H(A).\n$$\nFrom the given joint distribution, the marginal of $A$ is\n$$\np(A=0)=p(0,0)+p(0,1)=\\frac{1}{2}+0=\\frac{1}{2},\\quad p(A=1)=\\frac{1}{2},\n$$\nhence $A$ is uniform and\n$$\nH(A)=-\\sum_{a}p(a)\\log_{2}p(a)=1\\ \\text{bit}.\n$$\nTherefore $W_{1}=k_{B}T\\ln 2$.\n\nProtocol 2 measures $B$ and then erases $A$ using the outcome, so\n$$\nW_{2}=k_{B}T\\ln 2\\cdot H(A|B).\n$$\nCompute $p(B)$ and $p(A|B)$:\n$$\np(B=0)=p(0,0)+p(1,0)=\\frac{3}{4},\\quad p(B=1)=\\frac{1}{4},\n$$\n$$\np(A=0|B=0)=\\frac{p(0,0)}{p(B=0)}=\\frac{2}{3},\\quad p(A=1|B=0)=\\frac{1}{3},\n$$\n$$\np(A=0|B=1)=0,\\quad p(A=1|B=1)=1.\n$$\nThus\n$$\nH(A|B=0)=-\\frac{2}{3}\\log_{2}\\!\\left(\\frac{2}{3}\\right)-\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right)=\\log_{2}3-\\frac{2}{3},\n$$\n$$\nH(A|B=1)=0,\n$$\nand\n$$\nH(A|B)=p(B=0)H(A|B=0)+p(B=1)H(A|B=1)=\\frac{3}{4}\\left(\\log_{2}3-\\frac{2}{3}\\right)=\\frac{3}{4}\\log_{2}3-\\frac{1}{2}.\n$$\nTherefore,\n$$\n\\frac{W_{1}}{W_{2}}=\\frac{H(A)}{H(A|B)}=\\frac{1}{\\frac{3}{4}\\log_{2}3-\\frac{1}{2}}.\n$$\nNumerically, $\\log_{2}3\\approx 1.5849625007$, so\n$$\nH(A|B)\\approx \\frac{3}{4}\\times 1.5849625007-\\frac{1}{2}\\approx 0.6887218755,\n$$\nand\n$$\n\\frac{W_{1}}{W_{2}}\\approx \\frac{1}{0.6887218755}\\approx 1.452\\ \\text{(to four significant figures)}.\n$$",
            "answer": "$$\\boxed{1.452}$$"
        }
    ]
}