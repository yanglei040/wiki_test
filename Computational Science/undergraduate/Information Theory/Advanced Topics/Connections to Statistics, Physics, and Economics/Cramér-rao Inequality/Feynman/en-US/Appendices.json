{
    "hands_on_practices": [
        {
            "introduction": "The first step in mastering the Cramér-Rao inequality is to apply it to a fundamental scenario. This practice will guide you through calculating the Cramér-Rao Bound (CRB) for a simple binary outcome, which follows a Bernoulli distribution. By working through the derivation from first principles in a hypothetical context , you will build the core skills needed to determine the Fisher information and establish the theoretical limit on estimation precision for any discrete parameter.",
            "id": "1615021",
            "problem": "A new type of quantum dot sensor is developed to detect a specific molecular excitation. The sensor's state is observed at discrete time intervals. For each observation, the sensor yields a random output $X$. If the molecule is in an excited state, the sensor outputs the value $X=1$; otherwise, it outputs $X=2$. The probability that the molecule is in the excited state during any given observation is an unknown parameter $\\theta$, where $0 < \\theta < 1$. The outcome of each observation is independent of the others.\n\nConsider a sample of $n$ independent observations, $X_1, X_2, \\ldots, X_n$, from this sensor. The probability mass function for a single observation $X_i$ is given by:\n$P(X_i=1) = \\theta$\n$P(X_i=2) = 1-\\theta$\n\nDetermine the Cramér-Rao Bound (CRB), which provides a lower bound on the variance of any unbiased estimator for the parameter $\\theta$. Express your answer as a symbolic expression in terms of $\\theta$ and $n$.",
            "solution": "We model each observation as a two-point distribution with parameter $\\theta$: $P(X=1)=\\theta$ and $P(X=2)=1-\\theta$, with $0<\\theta<1$. For a single observation $X$, the log-likelihood is\n$$\n\\ln p(X;\\theta)=\n\\begin{cases}\n\\ln \\theta & \\text{if } X=1,\\\\\n\\ln(1-\\theta) & \\text{if } X=2.\n\\end{cases}\n$$\nThe score function for one observation is\n$$\n\\frac{\\partial}{\\partial \\theta}\\ln p(X;\\theta)=\n\\begin{cases}\n\\frac{1}{\\theta} & \\text{if } X=1,\\\\\n-\\frac{1}{1-\\theta} & \\text{if } X=2.\n\\end{cases}\n$$\nThe Fisher information for one observation is\n$$\nI_{1}(\\theta)=\\mathbb{E}_{\\theta}\\!\\left[\\left(\\frac{\\partial}{\\partial \\theta}\\ln p(X;\\theta)\\right)^{2}\\right]\n=\\theta\\left(\\frac{1}{\\theta}\\right)^{2}+(1-\\theta)\\left(\\frac{1}{1-\\theta}\\right)^{2}\n=\\frac{1}{\\theta}+\\frac{1}{1-\\theta}=\\frac{1}{\\theta(1-\\theta)}.\n$$\nFor $n$ independent observations, Fisher information adds, so\n$$\nI_{n}(\\theta)=n\\,I_{1}(\\theta)=\\frac{n}{\\theta(1-\\theta)}.\n$$\nBy the Cramér-Rao inequality, for any unbiased estimator $\\hat{\\theta}$ of $\\theta$,\n$$\n\\operatorname{Var}(\\hat{\\theta})\\ge \\frac{1}{I_{n}(\\theta)}=\\frac{\\theta(1-\\theta)}{n}.\n$$\nThus, the Cramér-Rao Bound is $\\theta(1-\\theta)/n$.",
            "answer": "$$\\boxed{\\frac{\\theta(1-\\theta)}{n}}$$"
        },
        {
            "introduction": "After learning to calculate the CRB, the next logical step is to use it as a benchmark for evaluating real-world estimators. This problem introduces the concept of an estimator's *efficiency*, which quantifies how close its variance approaches the absolute minimum set by the CRB . By analyzing the ubiquitous sample mean estimator for data from an exponential distribution, you will discover whether it qualifies as a statistically optimal unbiased estimator by achieving an efficiency of 1.",
            "id": "1615029",
            "problem": "The lifetime of a certain type of electronic component is modeled by an exponential distribution. The probability density function (PDF) for the lifetime $X$ of a single component is given by:\n$$f(x; \\theta) = \\frac{1}{\\theta} \\exp\\left(-\\frac{x}{\\theta}\\right), \\quad \\text{for } x \\ge 0$$\nwhere $\\theta > 0$ is the unknown mean lifetime of the components.\n\nTo estimate this mean lifetime, a quality control engineer measures the lifetimes of $n$ components, denoted as $X_1, X_2, \\dots, X_n$. These measurements are assumed to be independent and identically distributed (i.i.d.) random variables from the distribution described by $f(x; \\theta)$.\n\nThe engineer uses the sample mean as an estimator for the parameter $\\theta$:\n$$\\hat{\\theta} = \\frac{1}{n} \\sum_{i=1}^n X_i$$\nThis estimator is known to be unbiased for $\\theta$.\n\nCalculate the efficiency of this estimator. The efficiency of an unbiased estimator is defined as the ratio of the Cramér-Rao Lower Bound (CRLB) to the estimator's variance. Express your answer as a single numerical value.",
            "solution": "We are given i.i.d. observations $X_{1},\\dots,X_{n}$ from the exponential distribution with pdf $f(x;\\theta)=\\frac{1}{\\theta}\\exp(-x/\\theta)$ for $x\\ge 0$, with mean parameter $\\theta>0$. The estimator is the sample mean $\\hat{\\theta}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$, which is unbiased for $\\theta$.\n\nFirst, compute the Fisher information for a single observation. The log-likelihood for one $X$ is\n$$\n\\ell(\\theta;X)=-\\ln\\theta-\\frac{X}{\\theta}.\n$$\nThe score is\n$$\n\\frac{\\partial \\ell}{\\partial \\theta}=-\\frac{1}{\\theta}+\\frac{X}{\\theta^{2}}.\n$$\nThe Fisher information for one observation is\n$$\nI_{1}(\\theta)=\\operatorname{E}\\!\\left[\\left(\\frac{\\partial \\ell}{\\partial \\theta}\\right)^{2}\\right]\n=\\operatorname{E}\\!\\left[\\left(-\\frac{1}{\\theta}+\\frac{X}{\\theta^{2}}\\right)^{2}\\right]\n=\\frac{1}{\\theta^{2}}-\\frac{2\\,\\operatorname{E}[X]}{\\theta^{3}}+\\frac{\\operatorname{E}[X^{2}]}{\\theta^{4}}.\n$$\nFor the exponential distribution parameterized by its mean, $\\operatorname{E}[X]=\\theta$ and $\\operatorname{Var}(X)=\\theta^{2}$, hence $\\operatorname{E}[X^{2}]=\\operatorname{Var}(X)+(\\operatorname{E}[X])^{2}=\\theta^{2}+\\theta^{2}=2\\theta^{2}$. Substituting gives\n$$\nI_{1}(\\theta)=\\frac{1}{\\theta^{2}}-\\frac{2\\theta}{\\theta^{3}}+\\frac{2\\theta^{2}}{\\theta^{4}}=\\frac{1}{\\theta^{2}}.\n$$\nFor $n$ i.i.d. observations, the Fisher information is additive, so\n$$\nI_{n}(\\theta)=n\\,I_{1}(\\theta)=\\frac{n}{\\theta^{2}}.\n$$\nThe Cramér-Rao lower bound (CRLB) for any unbiased estimator of $\\theta$ is\n$$\n\\operatorname{Var}(\\hat{\\theta})\\ge \\frac{1}{I_{n}(\\theta)}=\\frac{\\theta^{2}}{n}.\n$$\nNow compute the variance of the sample mean. Since $\\operatorname{Var}(X_{i})=\\theta^{2}$ and the $X_{i}$ are independent,\n$$\n\\operatorname{Var}(\\hat{\\theta})=\\operatorname{Var}\\!\\left(\\frac{1}{n}\\sum_{i=1}^{n}X_{i}\\right)=\\frac{1}{n^{2}}\\sum_{i=1}^{n}\\operatorname{Var}(X_{i})=\\frac{1}{n^{2}}\\cdot n\\,\\theta^{2}=\\frac{\\theta^{2}}{n}.\n$$\nTherefore, the estimator achieves the CRLB. The efficiency, defined as the ratio of the CRLB to the estimator’s variance, is\n$$\n\\text{efficiency}=\\frac{\\text{CRLB}}{\\operatorname{Var}(\\hat{\\theta})}=\\frac{\\theta^{2}/n}{\\theta^{2}/n}=1.\n$$",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "A deep understanding of a scientific principle includes knowing its limitations. This final practice explores a classic case where the Cramér-Rao inequality's underlying assumptions are not met, leading to a potentially invalid bound . Investigating the estimation of the maximum value of a uniform distribution will challenge you to think critically about the theorem's 'regularity conditions' and appreciate why verifying them is a crucial step in rigorous statistical analysis.",
            "id": "1614995",
            "problem": "A technology startup is developing a new series of specialized processors. Each processor is assigned a unique serial number from the set $\\{1, 2, \\dots, N\\}$, where $N$ is the total number of processors produced in the first batch, which is unknown. The serial numbers are assigned sequentially starting from 1. A random sample of $n$ processors is drawn (with replacement, for simplicity of analysis) and their serial numbers, $X_1, X_2, \\dots, X_n$, are recorded. We can model each $X_i$ as an independent random variable drawn from a discrete uniform distribution on the integers from 1 to $N$.\n\nYour task is to evaluate the theoretical limits on estimating $N$. Assuming an unbiased estimator for $N$ exists, perform a formal calculation of the Cramér-Rao Lower Bound (CRLB) for the variance of such an estimator. Then, assess the validity of applying the CRLB in this specific scenario.\n\nWhich of the following statements correctly presents the formally calculated CRLB and the conclusion about its applicability?\n\nA. The CRLB is $\\frac{N^2}{n}$. The bound is applicable and provides a tight lower limit on the variance of the best unbiased estimator.\n\nB. The CRLB is $\\frac{(N^2 - 1)}{12n}$. The bound is applicable as it is based on the population variance.\n\nC. The CRLB is $\\frac{N^2}{n^2}$. The bound is applicable and provides a tight lower limit on the variance of the best unbiased estimator.\n\nD. The CRLB is $\\frac{N^2}{n^2}$. However, the applicability of this bound is not guaranteed because one of the regularity conditions for the CRLB is violated.\n\nE. The CRLB cannot be calculated because the likelihood function is not differentiable with respect to the parameter $N$.",
            "solution": "We model $X_{1},\\dots,X_{n}$ as independent and identically distributed with pmf\n$$\nf(x;N)=\\begin{cases}\n\\frac{1}{N}, & x\\in\\{1,2,\\dots,N\\},\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\nFor a sample $x_{1},\\dots,x_{n}$ with $M=\\max\\{x_{1},\\dots,x_{n}\\}$, the likelihood and log-likelihood (as a function of $N$) are\n$$\nL(N)=N^{-n}\\,\\mathbf{1}\\{N\\geq M\\},\\qquad \\ell(N)=\\ln L(N)=-n\\ln N+\\ln \\mathbf{1}\\{N\\geq M\\}.\n$$\nA formal (but non-regular) score calculation, differentiating only the smooth part and ignoring the indicator, gives for $N>M$\n$$\n\\frac{\\partial}{\\partial N}\\ell(N)=-\\frac{n}{N}.\n$$\nUnder the true $N$, we have $\\mathbf{P}(M\\leq N)=1$, so the above expression holds almost surely, and hence the “formal” Fisher information based on the squared score for the full sample is\n$$\nI(N)=\\mathbf{E}\\!\\left[\\left(\\frac{\\partial}{\\partial N}\\ell(N)\\right)^{2}\\right]=\\mathbf{E}\\!\\left[\\left(-\\frac{n}{N}\\right)^{2}\\right]=\\frac{n^{2}}{N^{2}}.\n$$\nAssuming there exists an unbiased estimator $T(X_{1},\\dots,X_{n})$ of $N$ (so $g(N)=N$ with $g'(N)=1$), the formal Cramér-Rao lower bound (CRLB) derived from this $I(N)$ is\n$$\n\\operatorname{Var}(T)\\;\\ge\\;\\frac{\\left(g'(N)\\right)^{2}}{I(N)}\\;=\\;\\frac{1}{I(N)}\\;=\\;\\frac{N^{2}}{n^{2}}.\n$$\nHowever, the regularity conditions required for the CRLB are violated here:\n- The support of $f(x;N)$ depends on $N$.\n- The log-likelihood includes an indicator $\\mathbf{1}\\{N\\ge M\\}$ and is not differentiable at $N=M$.\n- The score’s expectation is not zero: $\\mathbf{E}\\!\\left[\\frac{\\partial}{\\partial N}\\ell(N)\\right]=-\\frac{n}{N}\\neq 0$.\nBecause these regularity conditions fail, the standard CRLB is not guaranteed to be applicable, and in related uniform-support problems it is known to give invalid or non-tight bounds. Therefore, while the formal calculation yields $\\operatorname{Var}(T)\\ge N^{2}/n^{2}$, its applicability in this model is not guaranteed.",
            "answer": "$$\\boxed{D}$$"
        }
    ]
}