{
    "hands_on_practices": [
        {
            "introduction": "为了真正理解硬判决和软判决解码之间的差异，让我们从一个直接的比较开始。这个练习  使用一个简单的重复码来展示一个两种方法得出相反结论的场景。通过这个例子，你将亲眼看到软判决解码如何利用硬判决所丢弃的可靠性信息，从而做出更明智、也可能更正确的选择。",
            "id": "1629075",
            "problem": "在一个简单的数字通信系统中，单个信息比特 $b \\in \\{0, 1\\}$ 为了保证可靠性，使用一个三比特重复码（表示为 $R_3$）进行编码。如果信息比特为 $b=0$，则发送的码字是 $(0,0,0)$。如果信息比特为 $b=1$，则发送的码字是 $(1,1,1)$。在传输时，比特 $0$ 映射为 $-1$ 任意单位的信号电平，比特 $1$ 映射为 $+1$ 任意单位的信号电平。该码字随后通过一个噪声信道发送。\n\n在接收端，观测到一个由三个实数值组成的序列 $y = (y_1, y_2, y_3)$。这些值与每个接收比特的对数似然比（LLR）成正比。一个正值 $y_i$ 表示第 $i$ 个比特更有可能是 $1$，而一个负值表示它更有可能是 $0$。值 $|y_i|$ 的大小代表了对这一判断的置信度。\n\n假设接收到的序列是 $y = (+0.8, +0.9, -2.1)$。\n\n我们将比较两种译码策略：\n\n1.  **硬判决译码**：该译码器首先对每个接收值 $y_i$ 作出单独的，即“硬”判决。接收值 $y_i > 0$ 被译码为比特 $\\hat{b}_i = 1$，而值 $y_i  0$ 被译码为 $\\hat{b}_i = 0$。最终的译码比特 $b_{HD}$，由对硬判决比特序列 $(\\hat{b}_1, \\hat{b}_2, \\hat{b}_3)$ 进行多数表决来决定。\n\n2.  **软判决译码**：该译码器直接使用“软”信息，即实际的实数值。判决度量 $L$ 是接收值的总和：$L = y_1 + y_2 + y_3$。最终的译码比特 $b_{SD}$ 由 $L$ 的符号决定。如果 $L > 0$，译码器判决 $b_{SD} = 1$。如果 $L  0$，则判决 $b_{SD} = 0$。\n\n对于给定的接收序列，确定译码比特 $b_{HD}$ 和 $b_{SD}$。将您的答案表示为一个有序对 $(b_{HD}, b_{SD})$。",
            "solution": "问题要求我们使用两种不同的方法——硬判决译码和软判决译码——来对接收到的序列 $y = (+0.8, +0.9, -2.1)$ 进行译码。原始信息比特 $b$ 是使用一个三比特重复码进行编码的。我们需要找出译码后的比特 $b_{HD}$ 和 $b_{SD}$，并以有序对的形式给出。\n\n首先，我们进行硬判决译码。这个过程包括两个步骤：第一，将每个接收值量化为一个二进制比特（0 或 1）；第二，对得到的比特序列进行多数表决。\n\n量化规则如下：\n- 如果 $y_i > 0$，该比特的硬判决为 $\\hat{b}_i = 1$。\n- 如果 $y_i  0$，该比特的硬判决为 $\\hat{b}_i = 0$。\n\n将此规则应用于接收序列 $y = (+0.8, +0.9, -2.1)$：\n- 对于 $y_1 = +0.8$：因为 $0.8 > 0$，硬判决为 $\\hat{b}_1 = 1$。\n- 对于 $y_2 = +0.9$：因为 $0.9 > 0$，硬判决为 $\\hat{b}_2 = 1$。\n- 对于 $y_3 = -2.1$：因为 $-2.1  0$，硬判决为 $\\hat{b}_3 = 0$。\n\n这样我们就得到了硬判决比特序列 $(\\hat{b}_1, \\hat{b}_2, \\hat{b}_3) = (1, 1, 0)$。\n\n下一步是对这个序列进行多数表决。该序列包含两个 1 和一个 0。出现次数最多的比特是 1。因此，多数逻辑译码器的输出是 1。\n所以，硬判决译码比特为 $b_{HD} = 1$。\n\n接下来，我们进行软判决译码。这种方法使用原始的接收值，不进行预先量化。判决基于接收值的总和的符号，该总和作为判决度量 $L$。\n\n判决度量 $L$ 计算如下：\n$$L = y_1 + y_2 + y_3$$\n\n代入给定值：\n$$L = (+0.8) + (+0.9) + (-2.1)$$\n$$L = 1.7 - 2.1$$\n$$L = -0.4$$\n\n软判决译码的规则是：\n- 如果 $L > 0$，则判决为比特 1。\n- 如果 $L  0$，则判决为比特 0。\n\n在我们的例子中，$L = -0.4$，小于 0。根据规则，译码器判决为比特 0。\n所以，软判决译码比特为 $b_{SD} = 0$。\n\n这个结果突显了两种方法之间的一个关键区别。硬判决译码器看到两个“1”的投票和一个“0”的投票，因此判决为“1”。然而，软判决译码器会权衡证据。它看到两个对“1”的弱投票（来自 $+0.8$ 和 $+0.9$）和一个对“0”的非常强的投票（来自 $-2.1$）。支持“0”的单个强证据超过了支持“1”的两个弱证据，导致最终判决为“0”。\n\n最后，我们被要求将答案表示为有序对 $(b_{HD}, b_{SD})$。\n根据我们的计算，我们得到 $b_{HD} = 1$ 和 $b_{SD} = 0$。\n\n因此，最终答案是序对 $(1, 0)$。",
            "answer": "$$\\boxed{\\begin{pmatrix} 1  0 \\end{pmatrix}}$$"
        },
        {
            "introduction": "在看到了使用软信息的好处之后，我们下一步需要理解这些信息在数学上是如何量化的。这个练习  从简单的场景推进到一个实际的4-QAM调制方案，要求你计算对数似然比（LLR）。LLR是现代软判决解码器的基本“通货”，掌握其计算是理解其内部工作原理的关键。",
            "id": "1629082",
            "problem": "一个数字通信系统使用4阶正交幅度调制（4-QAM）通过加性高斯白噪声（AWGN）信道发送数据。每个发送符号的平均能量被归一化为 $E_s=1$。\n\n四个星座点由一对比特 $(b_1, b_2)$ 的格雷编码映射定义。第一个比特 $b_1$ 决定了符号的同相（实部）分量，第二个比特 $b_2$ 决定了正交（虚部）分量。从比特到符号分量的具体映射如下：\n- $b_1=0 \\implies$ 同相分量为 $-A$\n- $b_1=1 \\implies$ 同相分量为 $+A$\n- $b_2=0 \\implies$ 正交分量为 $+A$\n- $b_2=1 \\implies$ 正交分量为 $-A$\n\n此处，正常数 $A$ 的选择使得平均符号能量等于 $E_s=1$。假定四个可能的符号以等概率发送。\n\n接收到的复数值被建模为 $y = s+n$，其中 $s$ 是发送的星座点，$n=n_I+jn_Q$ 是复高斯噪声。噪声的实部和虚部 $n_I$ 和 $n_Q$ 是独立的随机变量，各自的均值为零，方差为 $\\sigma^2$。\n\n给定接收值为 $y = 0.25 - 0.6j$，每个实数维度的噪声方差为 $\\sigma^2 = 0.5$，计算第一个比特 $b_1$ 的对数似然比（LLR）。比特 $b$ 的LLR定义为 $L(b) = \\ln\\left(\\frac{P(b=1|y)}{P(b=0|y)}\\right)$，并作为一种软判决度量。\n\n将您的最终答案四舍五入到三位有效数字。",
            "solution": "问题要求计算在给定接收复数值 $y$ 的情况下，第一个比特 $b_1$ 的对数似然比（LLR）。LLR定义为 $L(b_1) = \\ln\\left(\\frac{P(b_1=1|y)}{P(b_1=0|y)}\\right)$。\n\n首先，我们来确定常数 $A$ 的值。四个星座点为 $s \\in \\{ A+jA, A-jA, -A+jA, -A-jA \\}$。其中任意一点的模的平方（能量）为 $|s|^2 = (\\pm A)^2 + (\\pm A)^2 = 2A^2$。由于所有四个符号都是等概率的，平均符号能量为 $E_s = \\frac{1}{4} \\sum_{i=1}^4 |s_i|^2 = \\frac{1}{4}(4 \\times 2A^2) = 2A^2$。给定 $E_s=1$，我们有 $2A^2 = 1$，得出 $A = 1/\\sqrt{2}$。\n\n使用贝叶斯定理，一个比特值的后验概率为 $P(b_1=i|y) = \\frac{p(y|b_1=i)P(b_1=i)}{p(y)}$。由于四个符号是等概率的，比特 $b_1=0$ 和 $b_1=1$ 也是等概率的，所以 $P(b_1=0) = P(b_1=1) = 1/2$。LLR表达式简化为：\n$$L(b_1) = \\ln\\left(\\frac{p(y|b_1=1)P(b_1=1)/p(y)}{p(y|b_1=0)P(b_1=0)/p(y)}\\right) = \\ln\\left(\\frac{p(y|b_1=1)}{p(y|b_1=0)}\\right)$$\n\n概率密度 $p(y|b_1=i)$ 是边缘概率，可以通过对所有对应于 $b_1=i$ 的可能符号求和得到。事件 $b_1=0$ 对应于发送一个同相分量为 $-A$ 的符号。这两个符号是 $s_{00} = -A+jA$ 和 $s_{01} = -A-jA$。事件 $b_1=1$ 对应于同相分量为 $+A$ 的情况，其符号为 $s_{10} = A+jA$ 和 $s_{11} = A-jA$。\n由于对于给定的 $b_1$，$b_2$ 的两种可能性是等概率的，我们可以写出：\n$$p(y|b_1=0) = \\frac{1}{2} p(y|s=s_{00}) + \\frac{1}{2} p(y|s=s_{01})$$\n$$p(y|b_1=1) = \\frac{1}{2} p(y|s=s_{10}) + \\frac{1}{2} p(y|s=s_{11})$$\n在AWGN信道上，给定发送符号 $s$ 后接收到 $y$ 的条件概率密度函数（PDF）为 $p(y|s) = \\frac{1}{2\\pi\\sigma^2}\\exp\\left(-\\frac{|y-s|^2}{2\\sigma^2}\\right)$。\n\n将这些代入LLR表达式中：\n$$L(b_1) = \\ln\\left(\\frac{\\frac{1}{2\\pi\\sigma^2}\\left[\\exp\\left(-\\frac{|y-s_{10}|^2}{2\\sigma^2}\\right) + \\exp\\left(-\\frac{|y-s_{11}|^2}{2\\sigma^2}\\right)\\right]}{\\frac{1}{2\\pi\\sigma^2}\\left[\\exp\\left(-\\frac{|y-s_{00}|^2}{2\\sigma^2}\\right) + \\exp\\left(-\\frac{|y-s_{01}|^2}{2\\sigma^2}\\right)\\right]}\\right)$$\n常数因子相互抵消。令 $y = y_I + j y_Q$。\n分子的参数变为：\n$$ \\exp\\left(-\\frac{(y_I - A)^2 + (y_Q - A)^2}{2\\sigma^2}\\right) + \\exp\\left(-\\frac{(y_I - A)^2 + (y_Q - (-A))^2}{2\\sigma^2}\\right) $$\n$$ = \\exp\\left(-\\frac{(y_I-A)^2}{2\\sigma^2}\\right) \\left[ \\exp\\left(-\\frac{(y_Q-A)^2}{2\\sigma^2}\\right) + \\exp\\left(-\\frac{(y_Q+A)^2}{2\\sigma^2}\\right) \\right] $$\n分母的参数类似地变为：\n$$ \\exp\\left(-\\frac{(y_I+A)^2}{2\\sigma^2}\\right) \\left[ \\exp\\left(-\\frac{(y_Q-A)^2}{2\\sigma^2}\\right) + \\exp\\left(-\\frac{(y_Q+A)^2}{2\\sigma^2}\\right) \\right] $$\n方括号中的项是相同的，当我们在对数内部取比值时，它们会相互抵消。\n$$ L(b_1) = \\ln\\left(\\frac{\\exp\\left(-\\frac{(y_I-A)^2}{2\\sigma^2}\\right)}{\\exp\\left(-\\frac{(y_I+A)^2}{2\\sigma^2}\\right)}\\right) = \\frac{-(y_I-A)^2}{2\\sigma^2} - \\frac{-(y_I+A)^2}{2\\sigma^2} $$\n$$ L(b_1) = \\frac{1}{2\\sigma^2} \\left[ (y_I+A)^2 - (y_I-A)^2 \\right] = \\frac{1}{2\\sigma^2} [ (y_I^2 + 2Ay_I + A^2) - (y_I^2 - 2Ay_I + A^2) ] $$\n$$ L(b_1) = \\frac{4Ay_I}{2\\sigma^2} = \\frac{2Ay_I}{\\sigma^2} $$\n这是方形QAM星座中同相比特LLR的一个通用结果。\n\n现在我们代入给定的数值：\n- $A = 1/\\sqrt{2}$\n- $y = 0.25 - 0.6j \\implies y_I = 0.25$\n- $\\sigma^2 = 0.5$\n\n$$ L(b_1) = \\frac{2 \\times (1/\\sqrt{2}) \\times 0.25}{0.5} = \\frac{\\sqrt{2} \\times 0.25}{0.5} = 0.5\\sqrt{2} $$\n数值上，这等于：\n$$ L(b_1) \\approx 0.5 \\times 1.41421356... = 0.70710678... $$\n将结果四舍五入到三位有效数字，我们得到 $0.707$。",
            "answer": "$$\\boxed{0.707}$$"
        },
        {
            "introduction": "虽然软判决解码功能强大，但在更广泛的背景下理解最优决策的原则也至关重要。这个问题  重新审视了硬判决解码，探讨了在考虑非均等错误代价或非均匀信源概率等现实因素时，如何确定最优判决门限。这个练习引入了贝叶斯视角，揭示了即使是简单的门限判决也可以通过优化来最小化总代价，这是信号检测理论中的一个基本概念。",
            "id": "1629077",
            "problem": "一个数字通信系统传输一个表示比特 $X$ 的二进制信号，其中 $X$ 可以是 0 或 1。传输 0 的先验概率为 $P(X=0) = p_0$，传输 1 的概率为 $P(X=1) = 1-p_0$。为了传输该比特，它首先被映射到一个电压水平：比特 0 映射为 $-A$，比特 1 映射为 $+A$，其中 $A$ 是一个正常数。\n\n该信号通过一个加性高斯白噪声 (AWGN) 信道进行传输。在检测器处接收到的信号是一个连续随机变量 $Y = s + N$，其中 $s \\in \\{-A, +A\\}$ 是发送的电压水平，$N$ 是一个均值为零、方差为 $\\sigma^2$ 的高斯噪声分量。\n\n接收器必须基于接收信号 $Y$ 的观测值 $y$ 来判决是传输了 0 还是 1。它采用一个简单的门限检测器：如果 $y > \\gamma$，系统判决 $\\hat{X}=1$；否则，判决 $\\hat{X}=0$。\n\n判决错误的后果是不对称的。将传输的 0 错判为 1 (一次 $0 \\to 1$ 错误) 的代价是 $C_1$，将传输的 1 错判为 0 (一次 $1 \\to 0$ 错误) 的代价是 $C_0$。$C_0$ 和 $C_1$ 都是正实数常量。正确的判决不产生任何代价。\n\n确定使总期望代价最小化的最优判决门限 $\\gamma$。您的最终答案应该是一个用给定参数 $p_0, A, \\sigma, C_0,$ 和 $C_1$ 表示的解析表达式。",
            "solution": "我们的目标是找到一个判决门限 $\\gamma$，以最小化总期望代价（也称为贝叶斯风险）。总期望代价 $R$ 是两种可能错误代价的期望值之和：\n$$ R = C_1 \\cdot P(\\text{判决为1, 实际为0}) + C_0 \\cdot P(\\text{判决为0, 实际为1}) $$\n使用条件概率展开，这可以写成：\n$$ R = C_1 \\cdot P(\\text{判决为1} | X=0) \\cdot P(X=0) + C_0 \\cdot P(\\text{判决为0} | X=1) \\cdot P(X=1) $$\n将先验概率 $P(X=0)=p_0$ 和 $P(X=1)=1-p_0$ 代入：\n$$ R = C_1 p_0 P(Y > \\gamma | X=0) + C_0 (1-p_0) P(Y \\le \\gamma | X=1) $$\n最小化总代价 $R$ 的贝叶斯判决准则是比较后验代价。对于一个观测值 $y$，我们判决为 $\\hat{X}=1$ 当且仅当判决为1的期望代价小于判决为0的期望代价。\n- 判决为1的期望代价: $C_1 P(X=0 | Y=y)$\n- 判决为0的期望代价: $C_0 P(X=1 | Y=y)$\n\n因此，我们判决为1，如果 $C_1 P(X=0 | Y=y)  C_0 P(X=1 | Y=y)$。判决边界 $\\gamma$ 是在这两个代价相等的地方：\n$$ C_1 P(X=0 | Y=\\gamma) = C_0 P(X=1 | Y=\\gamma) $$\n应用贝叶斯定理 $P(X=i | Y=y) = \\frac{p(y | X=i) P(X=i)}{p(y)}$，其中 $p(y)$ 是 $Y$ 的边缘概率密度函数。代入上式， $p(y)$ 项被消去：\n$$ C_1 p(\\gamma | X=0) P(X=0) = C_0 p(\\gamma | X=1) P(X=1) $$\n$$ C_1 p(\\gamma | X=0) p_0 = C_0 p(\\gamma | X=1) (1-p_0) $$\n重新整理，得到似然比：\n$$ \\frac{p(\\gamma | X=1)}{p(\\gamma | X=0)} = \\frac{C_1 p_0}{C_0 (1-p_0)} $$\n现在，我们代入高斯概率密度函数：\n- $p(y | X=1) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(y-A)^2}{2\\sigma^2}\\right)$ (当 $s=+A$ 时)\n- $p(y | X=0) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(y+A)^2}{2\\sigma^2}\\right)$ (当 $s=-A$ 时)\n\n似然比为：\n$$ \\frac{\\exp\\left(-\\frac{(\\gamma-A)^2}{2\\sigma^2}\\right)}{\\exp\\left(-\\frac{(\\gamma+A)^2}{2\\sigma^2}\\right)} = \\exp\\left(\\frac{-(\\gamma-A)^2 + (\\gamma+A)^2}{2\\sigma^2}\\right) = \\exp\\left(\\frac{4A\\gamma}{2\\sigma^2}\\right) = \\exp\\left(\\frac{2A\\gamma}{\\sigma^2}\\right) $$\n将此表达式代回阈值方程：\n$$ \\exp\\left(\\frac{2A\\gamma}{\\sigma^2}\\right) = \\frac{C_1 p_0}{C_0 (1-p_0)} $$\n为了解出 $\\gamma$，我们对两边取自然对数：\n$$ \\frac{2A\\gamma}{\\sigma^2} = \\ln\\left(\\frac{C_1 p_0}{C_0 (1-p_0)}\\right) $$\n最后，解出最优门限 $\\gamma$：\n$$ \\gamma = \\frac{\\sigma^2}{2A} \\ln\\left(\\frac{C_1 p_0}{C_0 (1-p_0)}\\right) $$\n这就是使总期望代价最小化的最优判决门限。",
            "answer": "$$\\boxed{\\frac{\\sigma^{2}}{2A}\\,\\ln\\!\\left(\\frac{C_{1}\\,p_{0}}{C_{0}\\,(1-p_{0})}\\right)}$$"
        }
    ]
}