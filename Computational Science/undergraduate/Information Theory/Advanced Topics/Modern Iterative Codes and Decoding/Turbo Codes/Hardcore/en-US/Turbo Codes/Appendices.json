{
    "hands_on_practices": [
        {
            "introduction": "The power of turbo codes stems from their use of iterative decoding, which relies on exchanging \"soft\" information between constituent decoders rather than making premature hard decisions. This soft information is quantified using Log-Likelihood Ratios (LLRs), which represent the level of confidence in whether a bit is a 0 or a 1. This first practice takes you to the very beginning of the decoding process, showing how raw, noisy signal values received from a communication channel are converted into these crucial initial LLRs that feed the entire turbo decoding machine .",
            "id": "1665637",
            "problem": "In a simplified model of a deep space communication system, a probe transmits a short sequence of four data bits, $u_k \\in \\{0, 1\\}$, to an Earth-based receiver. The modulation scheme used is Binary Phase Shift Keying (BPSK), where bit '0' is mapped to a transmitted signal level of $+A$ and bit '1' is mapped to $-A$. The transmission occurs over an Additive White Gaussian Noise (AWGN) channel, which adds a noise component $n_k$ to each transmitted signal level $x_k$. The noise $n_k$ follows a Gaussian distribution with a mean of zero and a variance of $\\sigma^2$. The received signal is thus $y_k = x_k + n_k$.\n\nThe receiver employs a turbo decoder, which requires an initial \"soft\" input for each bit. This initial soft information is the Log-Likelihood Ratio (LLR), defined as the natural logarithm of the ratio of the probability that the transmitted bit was a '1' to the probability that it was a '0', given the observed received signal value $y_k$.\n\nAssume the system parameters are as follows:\n- Signal amplitude, $A = 1.0$ Volt.\n- Noise variance, $\\sigma^2 = 0.5$ Volt$^2$.\n- A priori, the transmitted bits '0' and '1' are equally likely.\n- The sequence of four received signal values is $y = [0.85, -1.10, 0.40, -0.25]$ in Volts.\n\nCalculate the sequence of LLRs corresponding to each of the four received values. Express your final answer as a set of four numerical values, rounded to three significant figures.",
            "solution": "The problem asks for the initial Log-Likelihood Ratio (LLR) for each received bit, which is defined as:\n$$L_k = \\ln\\left(\\frac{P(u_k=1 | y_k)}{P(u_k=0 | y_k)}\\right)$$\nwhere $u_k$ is the transmitted bit and $y_k$ is the corresponding received signal value. A positive LLR indicates bit '1' is more likely, while a negative LLR indicates bit '0' is more likely.\n\nUsing Bayes' theorem, the posterior probability $P(u_k | y_k)$ can be expressed as:\n$$P(u_k | y_k) = \\frac{p(y_k | u_k) P(u_k)}{p(y_k)}$$\nHere, $p(y_k | u_k)$ is the conditional probability density function (PDF) of receiving $y_k$ given that bit $u_k$ was sent. $P(u_k)$ is the a priori probability of bit $u_k$, and $p(y_k)$ is the PDF of the received signal, which acts as a normalization constant.\n\nSubstituting this into the expression for $L_k$:\n$$L_k = \\ln\\left(\\frac{\\frac{p(y_k | u_k=1) P(u_k=1)}{p(y_k)}}{\\frac{p(y_k | u_k=0) P(u_k=0)}{p(y_k)}}\\right)$$\nThe term $p(y_k)$ in the numerator and denominator cancels out. The problem states that the transmitted bits are equally likely, so $P(u_k=0) = P(u_k=1) = 0.5$. These terms also cancel.\nThe expression for $L_k$ simplifies to the log-likelihood ratio of the channel observation:\n$$L_k = \\ln\\left(\\frac{p(y_k | u_k=1)}{p(y_k | u_k=0)}\\right)$$\n\nNext, we define the conditional PDFs based on the BPSK modulation and AWGN channel model.\nIf bit $u_k=0$ is transmitted, the signal level is $x_k = +A$. The received signal is $y_k = A + n_k$. Since $n_k$ is Gaussian with mean 0 and variance $\\sigma^2$, $y_k$ is Gaussian with mean $A$ and variance $\\sigma^2$. The conditional PDF is:\n$$p(y_k | u_k=0) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_k - A)^2}{2\\sigma^2}\\right)$$\nIf bit $u_k=1$ is transmitted, the signal level is $x_k = -A$. The received signal is $y_k = -A + n_k$. So, $y_k$ is Gaussian with mean $-A$ and variance $\\sigma^2$. The conditional PDF is:\n$$p(y_k | u_k=1) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_k - (-A))^2}{2\\sigma^2}\\right) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_k + A)^2}{2\\sigma^2}\\right)$$\n\nNow, substitute these PDFs back into the expression for $L_k$:\n$$L_k = \\ln\\left( \\frac{\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_k + A)^2}{2\\sigma^2}\\right)}{\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_k - A)^2}{2\\sigma^2}\\right)} \\right)$$\nThe constant term $\\frac{1}{\\sqrt{2\\pi\\sigma^2}}$ cancels.\n$$L_k = \\ln\\left( \\exp\\left(-\\frac{(y_k + A)^2}{2\\sigma^2} + \\frac{(y_k - A)^2}{2\\sigma^2}\\right) \\right)$$\nThe natural logarithm and the exponential function are inverses, so they cancel each other:\n$$L_k = -\\frac{(y_k + A)^2}{2\\sigma^2} + \\frac{(y_k - A)^2}{2\\sigma^2}$$\n$$L_k = \\frac{1}{2\\sigma^2} \\left[ -(y_k^2 + 2Ay_k + A^2) + (y_k^2 - 2Ay_k + A^2) \\right]$$\n$$L_k = \\frac{1}{2\\sigma^2} \\left[ -y_k^2 - 2Ay_k - A^2 + y_k^2 - 2Ay_k + A^2 \\right]$$\n$$L_k = \\frac{1}{2\\sigma^2} [-4Ay_k] = -\\frac{2Ay_k}{\\sigma^2}$$\nThis is the general expression for the LLR for a BPSK signal over an AWGN channel with the given mapping.\n\nNow we substitute the given numerical values: $A = 1.0$ and $\\sigma^2 = 0.5$.\n$$L_k = -\\frac{2 \\times (1.0) \\times y_k}{0.5} = -4y_k$$\nWe can now calculate the LLR for each value in the received sequence $y = [0.85, -1.10, 0.40, -0.25]$.\n\nFor $y_1 = 0.85$:\n$L_1 = -4 \\times 0.85 = -3.40$\n\nFor $y_2 = -1.10$:\n$L_2 = -4 \\times (-1.10) = 4.40$\n\nFor $y_3 = 0.40$:\n$L_3 = -4 \\times 0.40 = -1.60$\n\nFor $y_4 = -0.25$:\n$L_4 = -4 \\times (-0.25) = 1.00$\n\nThe problem requires rounding to three significant figures. The calculated values are already at or can be expressed with three significant figures.\nThe sequence of LLRs is $[-3.40, 4.40, -1.60, 1.00]$.",
            "answer": "$$\\boxed{\\begin{pmatrix} -3.40 & 4.40 & -1.60 & 1.00 \\end{pmatrix}}$$"
        },
        {
            "introduction": "At the heart of a turbo code's structure lies the interleaver, a component that pseudorandomly shuffles the information bits before they enter the second encoder. Its primary role is to break up burst errors—errors that occur in adjacent bits—so that they appear as isolated, more manageable errors to each constituent decoder. This exercise provides a hands-on demonstration of this principle by exploring a scenario where a simple block interleaver fails to do its job effectively, highlighting why the design of the interleaver is so critical to the performance of the entire code .",
            "id": "1665645",
            "problem": "In a digital communication system designed to mitigate the effects of burst errors, a block interleaver is employed. The interleaver operates on blocks of 16 bits, indexed from 0 to 15. The interleaving process consists of two steps: first, the incoming sequence of 16 bits is written row-by-row into a $4 \\times 4$ matrix. Second, the bits are read out column-by-column from the matrix to form the interleaved output sequence.\n\nSuppose a channel disturbance causes errors in exactly two bits of the input sequence before they are interleaved. The goal of the interleaver is to separate these errors so they are no longer adjacent in the output sequence, making them easier to correct. However, for certain error patterns, this simple block interleaver can fail.\n\nWhich of the following pairs of input bit indices, if corrupted, would result in two corrupted bits that are adjacent in the final output sequence?\n\nA. (2, 3)\n\nB. (3, 4)\n\nC. (6, 10)\n\nD. (1, 8)\n\nE. (0, 7)",
            "solution": "We model the interleaver as follows. The 16 input bits are indexed by $n \\in \\{0,1,\\dots,15\\}$ and written row-wise into a $4 \\times 4$ matrix. For any input index $n$, write $n = 4r + c$ with $r \\in \\{0,1,2,3\\}$ the row and $c \\in \\{0,1,2,3\\}$ the column. Thus,\n$$\nr = \\left\\lfloor \\frac{n}{4} \\right\\rfloor, \\quad c = n \\bmod 4.\n$$\nThe interleaver reads out the matrix column-by-column, top to bottom within each column. Therefore, the output position $p$ corresponding to input index $n$ is\n$$\np = f(n) = 4c + r = 4\\,(n \\bmod 4) + \\left\\lfloor \\frac{n}{4} \\right\\rfloor.\n$$\nTwo corrupted input indices $i$ and $j$ produce adjacent corrupted bits in the output if and only if\n$$\n|f(i) - f(j)| = 1.\n$$\nWe evaluate $f(n)$ for the candidate pairs:\n\n- For $(2,3)$: $2 = 4\\cdot 0 + 2 \\Rightarrow f(2) = 4\\cdot 2 + 0 = 8$; $3 = 4\\cdot 0 + 3 \\Rightarrow f(3) = 4\\cdot 3 + 0 = 12$. Then $|12 - 8| = 4 \\neq 1$.\n\n- For $(3,4)$: $3 = 4\\cdot 0 + 3 \\Rightarrow f(3) = 12$; $4 = 4\\cdot 1 + 0 \\Rightarrow f(4) = 4\\cdot 0 + 1 = 1$. Then $|12 - 1| = 11 \\neq 1$.\n\n- For $(6,10)$: $6 = 4\\cdot 1 + 2 \\Rightarrow f(6) = 4\\cdot 2 + 1 = 9$; $10 = 4\\cdot 2 + 2 \\Rightarrow f(10) = 4\\cdot 2 + 2 = 10$. Then $|10 - 9| = 1$, which is adjacent.\n\n- For $(1,8)$: $1 = 4\\cdot 0 + 1 \\Rightarrow f(1) = 4$; $8 = 4\\cdot 2 + 0 \\Rightarrow f(8) = 2$. Then $|4 - 2| = 2 \\neq 1$.\n\n- For $(0,7)$: $0 = 4\\cdot 0 + 0 \\Rightarrow f(0) = 0$; $7 = 4\\cdot 1 + 3 \\Rightarrow f(7) = 4\\cdot 3 + 1 = 13$. Then $|13 - 0| = 13 \\neq 1$.\n\nOnly the pair $(6,10)$ maps to adjacent output positions.",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "Having seen how soft information is generated and how the interleaver works, we now peek under the hood of the decoding engine itself: the Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm. This algorithm operates on a trellis diagram representing the states of the encoder, calculating probabilities for each possible state and transition. This practice focuses on a single, fundamental step within this complex process: the calculation of a forward state metric, $\\alpha_k(m)$. You will see how the decoder combines information from the previous state, the received channel values, and any prior knowledge to update its belief about the path taken through the trellis .",
            "id": "1665643",
            "problem": "In a communication system designed for a deep-space probe, a rate $1/2$ Turbo code is used for error correction. The decoding process relies on the Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm, which iteratively calculates state metrics across a trellis representing the constituent encoder.\n\nConsider one of the Recursive Systematic Convolutional (RSC) encoders used in this system. It has four states ($m \\in \\{0, 1, 2, 3\\}$). The state $m$ is represented by a binary tuple $(s_1, s_0)$ corresponding to the contents of two memory elements, such that $m = 2s_1 + s_0$. The state transition dynamics are as follows: given the state at time $k-1$, $S_{k-1}=(s_{k-1,1}, s_{k-1,0})$, and an information bit $u_k \\in \\{0,1\\}$, a new value $a_k = u_k \\oplus s_{k-1,1}$ is computed, where $\\oplus$ denotes addition modulo 2. The new state at time $k$ becomes $S_k = (s_{k,1}, s_{k,0}) = (a_k, s_{k-1,1})$, and the corresponding parity bit is $p_k = a_k \\oplus s_{k-1,0}$.\n\nThe information bit ($u_k$) and the parity bit ($p_k$) are modulated using Bipolar Phase Shift Keying (BPSK), where a bit $b \\in \\{0,1\\}$ is mapped to a symbol $x = 1 - 2b$. These symbols are transmitted over an Additive White Gaussian Noise (AWGN) channel with noise variance $\\sigma^2$.\n\nAt a specific time step $k$ in the decoding process, the following information is available:\n- The normalized forward state metrics from the previous time step, $k-1$, are:\n  $\\alpha_{k-1}(0) = 0.40$\n  $\\alpha_{k-1}(1) = 0.10$\n  $\\alpha_{k-1}(2) = 0.30$\n  $\\alpha_{k-1}(3) = 0.20$\n- The received noisy BPSK symbols at time $k$ are $y_k^s = -0.50$ for the systematic bit and $y_k^p = +0.80$ for the parity bit.\n- The a priori probabilities for the information bit $u_k$ are $\\Pr(u_k=0) = 0.60$ and $\\Pr(u_k=1) = 0.40$.\n- The channel noise variance is $\\sigma^2 = 0.50$.\n\nThe unnormalized forward state metric, $\\tilde{\\alpha}_k(m)$, is calculated recursively using the sum-product rule: $\\tilde{\\alpha}_k(m) = \\sum_{m'} \\alpha_{k-1}(m') \\tilde{\\gamma}_k(m', m)$. For this analysis, you must use the simplified, unnormalized branch metric $\\tilde{\\gamma}_k(m', m)$ defined as:\n$$\n\\tilde{\\gamma}_k(m', m) = \\Pr(u_k) \\exp\\left(\\frac{y_k^s x_k^s + y_k^p x_k^p}{\\sigma^2}\\right)\n$$\nwhere $u_k$ is the information bit causing the transition from state $m'$ to $m$, and $x_k^s$ and $x_k^p$ are the corresponding BPSK symbols for the systematic and parity bits, respectively.\n\nCalculate the value of the unnormalized forward state metric, $\\tilde{\\alpha}_k(m)$, for state $m=2$ at time step $k$. Round your final answer to four significant figures.",
            "solution": "We first identify which transitions lead to state $m=2$ at time $k$. Since the state is represented as $S_{k}=(s_{k,1},s_{k,0})$ with $m=2s_{1}+s_{0}$, the target state $m=2$ corresponds to $S_{k}=(1,0)$. By the given state evolution,\n$$\nS_{k}=(a_{k},s_{k-1,1}), \\quad a_{k}=u_{k}\\oplus s_{k-1,1}.\n$$\nThus, to have $S_{k}=(1,0)$, we require $s_{k-1,1}=0$ and $a_{k}=1$. Since $a_{k}=u_{k}\\oplus s_{k-1,1}$ with $s_{k-1,1}=0$, it follows that $u_{k}=1$. The previous state must therefore have $s_{k-1,1}=0$, i.e., $m'\\in\\{0,1\\}$:\n- For $m'=0$: $S_{k-1}=(0,0)$, so $u_{k}=1$, $a_{k}=1$, and the parity is $p_{k}=a_{k}\\oplus s_{k-1,0}=1\\oplus 0=1$.\n- For $m'=1$: $S_{k-1}=(0,1)$, so $u_{k}=1$, $a_{k}=1$, and the parity is $p_{k}=1\\oplus 1=0$.\n\nThe BPSK mapping is $x=1-2b$. Hence, for these transitions:\n- For $m'=0$: $u_{k}=1\\Rightarrow x_{k}^{s}=-1$, $p_{k}=1\\Rightarrow x_{k}^{p}=-1$.\n- For $m'=1$: $u_{k}=1\\Rightarrow x_{k}^{s}=-1$, $p_{k}=0\\Rightarrow x_{k}^{p}=+1$.\n\nThe unnormalized branch metric is\n$$\n\\tilde{\\gamma}_{k}(m',m)=\\Pr(u_{k})\\exp\\left(\\frac{y_{k}^{s}x_{k}^{s}+y_{k}^{p}x_{k}^{p}}{\\sigma^{2}}\\right),\n$$\nwith $\\Pr(u_{k}=1)=0.40$, $y_{k}^{s}=-0.50$, $y_{k}^{p}=+0.80$, and $\\sigma^{2}=0.50$. Therefore,\n- For $m'=0$:\n$$\ny_{k}^{s}x_{k}^{s}+y_{k}^{p}x_{k}^{p}=(-0.50)(-1)+(+0.80)(-1)=0.50-0.80=-0.30,\n$$\n$$\n\\tilde{\\gamma}_{k}(0,2)=0.40\\exp\\left(\\frac{-0.30}{0.50}\\right)=0.40\\exp(-0.6).\n$$\n- For $m'=1$:\n$$\ny_{k}^{s}x_{k}^{s}+y_{k}^{p}x_{k}^{p}=(-0.50)(-1)+(+0.80)(+1)=0.50+0.80=1.30,\n$$\n$$\n\\tilde{\\gamma}_{k}(1,2)=0.40\\exp\\left(\\frac{1.30}{0.50}\\right)=0.40\\exp(2.6).\n$$\n\nThe unnormalized forward metric is\n$$\n\\tilde{\\alpha}_{k}(2)=\\sum_{m'}\\alpha_{k-1}(m')\\tilde{\\gamma}_{k}(m',2)=\\alpha_{k-1}(0)\\tilde{\\gamma}_{k}(0,2)+\\alpha_{k-1}(1)\\tilde{\\gamma}_{k}(1,2).\n$$\nSubstituting $\\alpha_{k-1}(0)=0.40$ and $\\alpha_{k-1}(1)=0.10$ gives\n$$\n\\tilde{\\alpha}_{k}(2)=0.40\\cdot\\left[0.40\\exp(-0.6)\\right]+0.10\\cdot\\left[0.40\\exp(2.6)\\right]\n=0.16\\exp(-0.6)+0.04\\exp(2.6).\n$$\nEvaluating numerically,\n$$\n\\exp(-0.6)\\approx 0.5488116361,\\quad \\exp(2.6)\\approx 13.463738035,\n$$\n$$\n\\tilde{\\alpha}_{k}(2)\\approx 0.16\\cdot 0.5488116361+0.04\\cdot 13.463738035\\approx 0.0878098618+0.5385495214\\approx 0.6263593832.\n$$\nRounded to four significant figures, this is $0.6264$.",
            "answer": "$$\\boxed{0.6264}$$"
        }
    ]
}