{
    "hands_on_practices": [
        {
            "introduction": "要理解部分匹配预测（PPM）算法，第一步是掌握其核心——统计模型的构建。这个练习将指导你为一个给定的文本序列建立上下文频率表。这些表格是PPM算法的“大脑”，记录了数据中观察到的所有模式，是进行预测的基础。通过这个练习 ，你将具体了解不同阶的“上下文”是如何从序列中提取的，以及模型如何从数据中学习。",
            "id": "1647197",
            "problem": "在数据压缩领域，统计模型被用来预测数据流中即将出现的符号。其中一类模型是使用部分匹配预测（Prediction by Partial Matching, PPM）算法构建的。一个PPM模型会维护跟随在特定先前序列（称为上下文）之后的符号的频率计数。\n\n对于给定的上下文阶数 `k`，该模型会构建一个频率表。一个 `k` 阶上下文是一个由 `k` 个符号组成的序列。对于在训练序列中发现的每个不同的 `k` 阶上下文 `C`，阶数 `k` 的表会记录紧随 `C` 之后的符号以及每个符号出现的次数。阶数 `k=0` 的模型是一个特例，其上下文为空，它的表仅记录整个序列中每个符号的总频率。\n\n考虑一个PPM模型，它正在从左到右对文本序列 `S = \"AGADADAGA\"` 进行训练。在模型处理完整个序列后，以下哪个选项正确表示了阶数 `k=2`、`k=1` 和 `k=0` 的完整上下文频率表集合？\n\n表格使用以下表示法：`k=N: {Context1: {Symbol1: Count1, ...}, Context2: {...}, ...}`。\n\nA.\n`k=2`: {`AG`: {`A`: 1}, `GA`: {`D`: 1}, `AD`: {`A`: 1}, `DA`: {`D`: 1, `G`: 1}}\n`k=1`: {`A`: {`G`: 1, `D`: 1}, `G`: {`A`: 1}, `D`: {`A`: 1}}\n`k=0`: {`A`: 5, `G`: 2, `D`: 2}\n\nB.\n`k=2`: {`AG`: {`A`: 2}, `GA`: {`D`: 1}, `AD`: {`A`: 2}, `DA`: {`D`: 1, `G`: 1}}\n`k=1`: {`A`: {`G`: 2, `D`: 2}, `G`: {`A`: 2}, `D`: {`A`: 2}}\n`k=0`: {`A`: 4, `G`: 3, `D`: 2}\n\nC.\n`k=2`: {`AG`: {`A`: 2}, `GA`: {`D`: 1}, `AD`: {`A`: 2}, `DA`: {`D`: 1, `G`: 1}}\n`k=1`: {`A`: {`G`: 2, `D`: 2}, `G`: {`A`: 2}, `D`: {`A`: 2}}\n`k=0`: {`A`: 5, `G`: 2, `D`: 2}\n\nD.\n`k=2`: {`GA`: {`A`: 2}, `AG`: {`A`: 2}, `DA`: {`D`: 1, `G`: 1}}\n`k=1`: {`A`: {`G`: 2, `D`: 2}, `G`: {`A`: 2}, `D`: {`A`: 1, `G`: 1}}\n`k=0`: {`A`: 5, `G`: 2, `D`: 2}",
            "solution": "我们给定的序列是 S = \"AGADADAGA\"，其长度为 $n=9$，从左到右进行处理。对于一个阶数为 `k` 的PPM模型，每一次出现都源于位置 $i=k+1$ 到 $n$，其中上下文是长度为 `k` 的子串 $S_{i-k}\\dots S_{i-1}$，被计数的符号是 $S_{i}$。阶数 `k=0` 的模型仅记录整个序列中符号的总频率。\n\n使用 $i=3$ 到 $9$ 来计算 `k=2` 的表：\n- $i=3$：上下文 \"AG\"，下一个是 \"A\"，得到 \"AG\": {\"A\": 1}。\n- $i=4$：上下文 \"GA\"，下一个是 \"D\"，得到 \"GA\": {\"D\": 1}。\n- $i=5$：上下文 \"AD\"，下一个是 \"A\"，得到 \"AD\": {\"A\": 1}。\n- $i=6$：上下文 \"DA\"，下一个是 \"D\"，得到 \"DA\": {\"D\": 1}。\n- $i=7$：上下文 \"AD\"，下一个是 \"A\"，更新 \"AD\": {\"A\": 2}。\n- $i=8$：上下文 \"DA\"，下一个是 \"G\"，更新 \"DA\": {\"D\": 1, \"G\": 1}。\n- $i=9$：上下文 \"AG\"，下一个是 \"A\"，更新 \"AG\": {\"A\": 2}。\n因此 `k=2`: {\"AG\": {\"A\": 2}, \"GA\": {\"D\": 1}, \"AD\": {\"A\": 2}, \"DA\": {\"D\": 1, \"G\": 1}}。\n\n使用 $i=2$ 到 $9$ 来计算 `k=1` 的表：\n- $i=2$：上下文 \"A\"，下一个是 \"G\"，得到 \"A\": {\"G\": 1}。\n- $i=3$：上下文 \"G\"，下一个是 \"A\"，得到 \"G\": {\"A\": 1}。\n- $i=4$：上下文 \"A\"，下一个是 \"D\"，更新 \"A\": {\"G\": 1, \"D\": 1}。\n- $i=5$：上下文 \"D\"，下一个是 \"A\"，得到 \"D\": {\"A\": 1}。\n- $i=6$：上下文 \"A\"，下一个是 \"D\"，更新 \"A\": {\"G\": 1, \"D\": 2}。\n- $i=7$：上下文 \"D\"，下一个是 \"A\"，更新 \"D\": {\"A\": 2}。\n- $i=8$：上下文 \"A\"，下一个是 \"G\"，更新 \"A\": {\"G\": 2, \"D\": 2}。\n- $i=9$：上下文 \"G\"，下一个是 \"A\"，更新 \"G\": {\"A\": 2}。\n因此 `k=1`: {\"A\": {\"G\": 2, \"D\": 2}, \"G\": {\"A\": 2}, \"D\": {\"A\": 2}}。\n\n通过计算 S 中的总频率来计算 `k=0` 的表：\n- \"A\" 出现在位置 1,3,5,7,9：总共 5 次。\n- \"G\" 出现在位置 2,8：总共 2 次。\n- \"D\" 出现在位置 4,6：总共 2 次。\n因此 `k=0`: {\"A\": 5, \"G\": 2, \"D\": 2}。\n\n与选项进行比较，这组表与选项 C 完全匹配。",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "模型如果不能用来预测，那便毫无用处。这个练习将带你进入PPM的应用层面，学习如何使用已建立的上下文模型来计算下一个符号的概率。这个过程的关键是理解并应用“逃逸”（escape）机制，这是PPM在面对特定上下文中未曾出现过的符号时所采用的巧妙策略。掌握这种方法  对于理解PPM如何平衡高阶模型的特异性和低阶模型的泛化能力至关重要。",
            "id": "1647202",
            "problem": "部分匹配预测 (Prediction by Partial Matching, PPM) 是一种统计数据压缩算法，它根据前面的符号（称为“上下文”）来预测序列中的下一个符号。本问题探讨该算法的一个特定变体。\n\n考虑一个由以下规则定义的“简化PPM”模型，该模型用于预测给定序列后的符号。\n\n**算法定义：简化PPM**\n\n1.  **初始上下文**：为了预测序列后某个符号的概率，模型从考虑最大可能阶数的上下文开始。对于给定的最大阶数 $k_{\\text{max}}$，初始上下文是序列的最后 $k_{\\text{max}}$ 个符号。\n\n2.  **模型统计（对于一个$k$阶上下文 $c_k$）**：\n    *   模型的统计数据来自一个训练序列。\n    *   设 $N(c_k)$ 为上下文 $c_k$ 在训练序列中出现的总次数，其中每次出现后都紧跟着至少一个符号。\n    *   设 $N(s|c_k)$ 为特定符号 $s$ 在上下文 $c_k$ 之后立即出现的次数。\n    *   设 $U(c_k)$ 为在 $c_k$ 之后观测到的所有唯一符号的集合。\n\n3.  **$k$阶概率计算**：\n    *   **情况1（符号已见）**：如果待预测的符号 $s$ 在集合 $U(c_k)$ 中，其概率直接计算如下：\n        $$P_k(s | c_k) = \\frac{N(s|c_k)}{N(c_k) + |U(c_k)|}$$\n    *   **情况2（符号未见 - 逃逸）**：如果符号 $s$ *不*在集合 $U(c_k)$ 中，模型将“逃逸”到一个更低阶的模型。其概率是逃逸概率与下一个更低阶模型概率的乘积：\n        $$P_k(s | c_k) = P_{\\text{esc},k} \\times P_{k-1}(s | c_{k-1})$$\n        其中逃逸概率为 $P_{\\text{esc},k} = \\frac{|U(c_k)|}{N(c_k) + |U(c_k)|}$，$c_{k-1}$ 是上下文 $c_k$ 长度为 $k-1$ 的后缀。\n\n4.  **基础模型**：\n    *   **0阶模型**：上下文是空字符串，$c_0 = \\text{\"\"}$。对于此模型，$N(c_0)$ 是训练序列的总长度，$U(c_0)$ 是整个序列中所有唯一符号的集合。\n    *   **-1阶模型**：这是一个均匀先验。如果从0阶模型发生逃逸（当预测一个从未在训练序列中出现的符号时会发生这种情况），该模型会为任何符号分配 $1/M$ 的概率，其中 $M$ 是字母表的大小。\n\n**问题：**\n\n一个简化PPM模型使用训练序列 `AABABAA` 构建。可能符号的字母表由该序列中出现的所有唯一符号组成。最大模型阶数设为 $k_{\\text{max}}=2$。\n\n使用这个特定模型，序列 `AABABAA` 之后的符号是 'A' 的概率是多少？你的答案应该是一个最简分数。",
            "solution": "训练序列是 AABABAA，所以字母表是 $\\{A,B\\}$。最大阶数是 $k_{\\text{max}}=2$，因此预测 AABABAA 之后下一个符号的初始上下文是最后两个符号，$c_{2}=\\text{\"AA\"}$。\n\n对于一个$k$阶上下文 $c_{k}$，模型使用：\n$$P_{k}(s\\mid c_{k})=\\begin{cases} \\frac{N(s\\mid c_{k})}{N(c_{k})+|U(c_{k})|}, & \\text{if } s\\in U(c_{k}) \\\\[6pt] P_{\\text{esc},k}\\,P_{k-1}(s\\mid c_{k-1}), & \\text{if } s\\notin U(c_{k}) \\end{cases}$$\n逃逸概率为\n$$P_{\\text{esc},k}=\\frac{|U(c_{k})|}{N(c_{k})+|U(c_{k})|}.$$\n\n通过计算训练序列中长度为2且其后紧跟一个符号的上下文，来计算2阶统计数据。出现的次数如下：\n- $\\text{\"AA\"}\\to\\text{\"B\"}$ （来自位置 1–3），\n- $\\text{\"AB\"}\\to\\text{\"A\"}$ （来自位置 2–4 和 4–6），\n- $\\text{\"BA\"}\\to\\text{\"B\"}$ （来自位置 3–5）和 $\\text{\"BA\"}\\to\\text{\"A\"}$ （来自位置 5–7）。\n位于位置 6–7 末尾的 $\\text{\"AA\"}$ 后面没有符号，因此不予计算。\n\n因此，对于 $c_{2}=\\text{\"AA\"}$，\n$$N(\\text{\"AA\"})=1,\\quad U(\\text{\"AA\"})=\\{\\text{\"B\"}\\},\\quad N(A\\mid \\text{\"AA\"})=0.$$\n由于 $A\\notin U(\\text{\"AA\"})$，我们进行逃逸：\n$$P_{2}(A\\mid \\text{\"AA\"})=P_{\\text{esc},2}\\,P_{1}(A\\mid \\text{\"A\"}),\\quad P_{\\text{esc},2}=\\frac{|U(\\text{\"AA\"})|}{N(\\text{\"AA\"})+|U(\\text{\"AA\"})|}=\\frac{1}{1+1}=\\frac{1}{2}.$$\n\n现在计算1阶上下文 $c_{1}=\\text{\"A\"}$ 的概率，方法是计算长度为1且其后紧跟一个符号的上下文。出现的次数如下：\n- $\\text{\"A\"}\\to\\text{\"A\"}$ （位置 1–2 和 6–7），\n- $\\text{\"A\"}\\to\\text{\"B\"}$ （位置 2–3 和 4–5）。\n因此，\n$$N(\\text{\"A\"})=4,\\quad U(\\text{\"A\"})=\\{\\text{\"A\"},\\text{\"B\"}\\},\\quad N(A\\mid \\text{\"A\"})=2,$$\n所以\n$$P_{1}(A\\mid \\text{\"A\"})=\\frac{N(A\\mid \\text{\"A\"})}{N(\\text{\"A\"})+|U(\\text{\"A\"})|}=\\frac{2}{4+2}=\\frac{1}{3}.$$\n\n将这些因子结合起来：\n$$P_{2}(A\\mid \\text{\"AA\"})=\\frac{1}{2}\\cdot \\frac{1}{3}=\\frac{1}{6}.$$\n由于 $A\\in U(\\text{\"A\"})$，不需要进一步逃逸，因此不使用更低的阶。\n\n因此，在这个简化PPM模型下，序列 AABABAA 之后的符号是 $A$ 的概率为 $\\frac{1}{6}$。",
            "answer": "$$\\boxed{\\frac{1}{6}}$$"
        },
        {
            "introduction": "PPM是一种自适应算法，它在处理序列的每一步都会更新自己的知识库。这个练习要求你模拟这一动态过程，逐个符号地跟踪编码过程，并计算模型“逃逸”到低阶上下文的次数。通过亲手模拟 ，你将更深刻地体会PPM的自适应性，并理解它在实际压缩过程中是如何实时处理新出现的模式的。",
            "id": "1647198",
            "problem": "一个部分匹配预测 (PPM) 压缩模型被用来编码一个符号序列。该模型根据其前面的符号来预测下一个符号，这些前面的符号构成一个“上下文”。所使用的前面符号的数量即为上下文的“阶”。\n\n考虑一个最大上下文阶为 $k=2$ 的 PPM 模型。在编码一个符号时，模型首先尝试使用 2 阶上下文（即前面的两个符号）。如果当前符号之前从未在该 2 阶上下文中出现过，模型会生成一个**逃逸事件**，并尝试 1 阶上下文（即前面的单个符号）。此过程会依次向下尝试，直到 0 阶（没有上下文，考虑目前为止序列中符号的总体频率）和 -1 阶（列出目前为止在序列中任何地方出现过的所有唯一符号）。\n\n一个逃逸事件被定义为在上下文层级中向下走一步。例如：\n- 在 2 阶匹配失败，导致在 1 阶进行检查，这是一次逃逸事件。\n- 随后在 1 阶匹配失败，导致在 0 阶进行检查，这是第二次逃逸事件。\n- 在 0 阶匹配失败，导致在 -1 阶进行检查，这是第三次逃逸事件。\n- 如果该符号甚至不在 -1 阶模型中（即它是一个全新的符号），则会发生最后一次逃逸事件来表示这是一个新符号。\n\n模型的内部符号计数表在每个符号被处理*之后*更新。\n\n计算在编码序列 `XYYXYYXXY` 时发生的所有逃逸事件的总数。",
            "solution": "我们建立一个最大上下文阶为 $k=2$ 的 PPM 编码器模型，其阶数依次从 $2 \\to 1 \\to 0 \\to -1$ 下降。模型在处理完每个符号后更新其计数。每当当前符号在当前上下文模型中不存在，编码器下降一阶时，就会发生一次逃逸事件；如果该符号甚至不在 -1 阶模型中（即全局新符号），则会发生最后一次表示新符号的逃逸事件。在位置 $i$ 处，由于可用前导符号的数量为 $i-1$，因此可用的最高起始阶为 $\\min\\{2,i-1\\}$。\n\n我们处理序列 $XYYXYYXXY$，对每个位置 $i$ 追踪逃逸次数 $e_{i}$，仅使用先前出现过的符号。\n\n初始化所有模型为空。\n\n位置 $1$ ($X$)，从 0 阶开始：\n- 0 阶：全局未见过 $X$ $\\Rightarrow$ 逃逸到 -1 阶。\n- -1 阶：$X$ 不在唯一符号列表中 $\\Rightarrow$ 最终的新符号逃逸。\n因此 $e_{1}=2$。更新：全局已见 $\\{X\\}$。\n\n位置 $2$ ($Y$)，从 1 阶开始，上下文为 $X$：\n- 1 阶 (在 $X$ 之后)：未见过 $Y$ $\\Rightarrow$ 逃逸。\n- 0 阶：全局未见过 $Y$（只见过 $X$） $\\Rightarrow$ 逃逸。\n- -1 阶：$Y$ 不在唯一符号列表中 $\\Rightarrow$ 最终的新符号逃逸。\n因此 $e_{2}=3$。更新：全局已见 $\\{X,Y\\}$；$C_{1}[X]$ 包含 $Y$。\n\n位置 $3$ ($Y$)，从 2 阶开始，上下文为 $XY$：\n- 2 阶 ($XY$)：未见过 $Y$ $\\Rightarrow$ 逃逸。\n- 1 阶 ($Y$)：在 $Y$ 之后还未见过 $Y$ $\\Rightarrow$ 逃逸。\n- 0 阶：全局已见过 $Y$ $\\Rightarrow$ 成功。\n因此 $e_{3}=2$。更新：$C_{1}[Y]$ 包含 $Y$；$C_{2}[XY]$ 包含 $Y$。\n\n位置 $4$ ($X$)，从 2 阶开始，上下文为 $YY$：\n- 2 阶 ($YY$)：未见过 $X$ $\\Rightarrow$ 逃逸。\n- 1 阶 ($Y$)：在 $Y$ 之后还未见过 $X$ $\\Rightarrow$ 逃逸。\n- 0 阶：全局已见过 $X$ $\\Rightarrow$ 成功。\n因此 $e_{4}=2$。更新：$C_{1}[Y]$ 包含 $\\{Y,X\\}$；$C_{2}[YY]$ 包含 $X$。\n\n位置 $5$ ($Y$)，从 2 阶开始，上下文为 $YX$：\n- 2 阶 ($YX$)：未见过 $Y$ $\\Rightarrow$ 逃逸。\n- 1 阶 ($X$)：在 $X$ 之后见过 $Y$ $\\Rightarrow$ 成功。\n因此 $e_{5}=1$。更新：$C_{2}[YX]$ 包含 $Y$。\n\n位置 $6$ ($Y$)，从 2 阶开始，上下文为 $XY$：\n- 2 阶 ($XY$)：见过 $Y$ $\\Rightarrow$ 成功。\n因此 $e_{6}=0$。更新：集合中无新符号。\n\n位置 $7$ ($X$)，从 2 阶开始，上下文为 $YY$：\n- 2 阶 ($YY$)：见过 $X$ $\\Rightarrow$ 成功。\n因此 $e_{7}=0$。\n\n位置 $8$ ($X$)，从 2 阶开始，上下文为 $YX$：\n- 2 阶 ($YX$)：未见过 $X$ ($C_{2}[YX]=\\{Y\\}$) $\\Rightarrow$ 逃逸。\n- 1 阶 ($X$)：在 $X$ 之后还未见过 $X$ ($C_{1}[X]=\\{Y\\}$) $\\Rightarrow$ 逃逸。\n- 0 阶：全局已见过 $X$ $\\Rightarrow$ 成功。\n因此 $e_{8}=2$。更新：$C_{1}[X]$ 包含 $\\{Y,X\\}$；$C_{2}[YX]$ 包含 $\\{Y,X\\}$。\n\n位置 $9$ ($Y$)，从 2 阶开始，上下文为 $XX$：\n- 2 阶 ($XX$)：未见过 $Y$ $\\Rightarrow$ 逃逸。\n- 1 阶 ($X$)：在 $X$ 之后见过 $Y$ $\\Rightarrow$ 成功。\n因此 $e_{9}=1$。\n\n将所有逃逸次数相加：\n$$E_{\\text{total}}=\\sum_{i=1}^{9} e_{i}=2+3+2+2+1+0+0+2+1=13.$$",
            "answer": "$$\\boxed{13}$$"
        }
    ]
}