{
    "hands_on_practices": [
        {
            "introduction": "Huffman coding is a cornerstone of lossless data compression, renowned for its simplicity and efficiency in creating optimal prefix codes. While often taught with a binary alphabet, the algorithm's principles are generalizable to any code alphabet size $D$. This exercise challenges you to apply the Huffman algorithm to a ternary ($D=3$) alphabet, a scenario that introduces a subtle but critical constraint on the number of symbols merged at each step, providing a deeper understanding of the algorithm's mechanics .",
            "id": "1659054",
            "problem": "A research team is developing a communication protocol for a simplified chemical signaling system. The system uses six distinct molecular signals, denoted as $S = \\{s_1, s_2, s_3, s_4, s_5, s_6\\}$. The probabilities of observing each signal are empirically determined to be $P(s_1) = 0.35$, $P(s_2) = 0.25$, $P(s_3) = 0.15$, $P(s_4) = 0.12$, $P(s_5) = 0.08$, and $P(s_6) = 0.05$.\n\nTo efficiently transmit this information, the team decides to use a ternary Huffman code, which uses a code alphabet of $\\{0, 1, 2\\}$.\n\nCalculate the average length of the resulting ternary Huffman code. Express your answer in units of ternary digits per source symbol, rounded to three significant figures.",
            "solution": "The goal is to construct a ternary Huffman code for a source with six symbols and then calculate its average length. A ternary code uses $D=3$ code symbols.\n\nThe Huffman algorithm for a D-ary code requires that the number of symbols to be combined at each step satisfies the condition that $(N_k - 1) \\pmod{D-1} = 0$, where $N_k$ is the number of symbols at step $k$. This must hold for the initial set of symbols, $N_0$. Here, we have $N=6$ source symbols and we are creating a ternary code, so $D=3$. The condition is $(N_0 - 1) \\pmod{2} = 0$. Since our initial number of symbols is $N=6$, we have $(6-1) \\pmod{2} = 5 \\pmod{2} = 1 \\neq 0$.\n\nTo satisfy the condition, we must add dummy symbols with zero probability until the total number of symbols, $N_0$, makes $(N_0 - 1)$ an even number. This means $N_0$ must be odd. The smallest odd number greater than or equal to 6 is 7. Therefore, we need to add $7-6=1$ dummy symbol, $d_1$, with probability $P(d_1) = 0$.\n\nOur initial set of symbols and probabilities is:\n$s_1: 0.35$\n$s_2: 0.25$\n$s_3: 0.15$\n$s_4: 0.12$\n$s_5: 0.08$\n$s_6: 0.05$\n$d_1: 0.00$\n\nNow we proceed with the Huffman algorithm, at each step combining the $D=3$ least probable symbols into a new compound symbol.\n\n**Step 1:**\nThe three least probable symbols are $d_1(0.00)$, $s_6(0.05)$, and $s_5(0.08)$. We combine them into a new node (let's call it $n_1$) with probability $0.00 + 0.05 + 0.08 = 0.13$.\nThe list of symbols and their probabilities becomes:\n$s_1: 0.35$\n$s_2: 0.25$\n$s_3: 0.15$\n$n_1: 0.13$\n$s_4: 0.12$\n\n**Step 2:**\nWe sort the new list and again combine the three least probable symbols. The current list, sorted by probability, is: $\\{s_4(0.12), n_1(0.13), s_3(0.15), s_2(0.25), s_1(0.35)\\}$.\nThe three least probable are $s_4(0.12)$, $n_1(0.13)$, and $s_3(0.15)$. We combine them into a new node ($n_2$) with probability $0.12 + 0.13 + 0.15 = 0.40$.\nThe list of symbols and probabilities becomes:\n$n_2: 0.40$\n$s_1: 0.35$\n$s_2: 0.25$\n\n**Step 3:**\nWe are left with three symbols: $n_2(0.40)$, $s_1(0.35)$, and $s_2(0.25)$. We combine them to form the root of the tree, with probability $0.40 + 0.35 + 0.25 = 1.00$. The construction is complete.\n\nNow, we assign codewords by traversing the tree from the root. We will assign the code symbols $\\{0, 1, 2\\}$ to the branches in order of decreasing probability of the nodes they lead to.\n\n- At the root (sum=1.00), the branches are to $n_2(0.40)$, $s_1(0.35)$, and $s_2(0.25)$.\n  - $n_2(0.40) \\rightarrow 0$\n  - $s_1(0.35) \\rightarrow 1$. So, the codeword for $s_1$ is `1`.\n  - $s_2(0.25) \\rightarrow 2$. So, the codeword for $s_2$ is `2`.\n\n- From node $n_2(0.40)$, the branches are to $s_3(0.15)$, $n_1(0.13)$, and $s_4(0.12)$.\n  - $s_3(0.15) \\rightarrow 0$. The path from the root is `0`, so the codeword for $s_3$ is `00`.\n  - $n_1(0.13) \\rightarrow 1$. The path from the root is `0`, so the prefix is `01`.\n  - $s_4(0.12) \\rightarrow 2$. The path from the root is `0`, so the codeword for $s_4$ is `02`.\n\n- From node $n_1(0.13)$, the branches are to $s_5(0.08)$, $s_6(0.05)$, and $d_1(0.00)$.\n  - $s_5(0.08) \\rightarrow 0$. The path from the root is `01`, so the codeword for $s_5$ is `010`.\n  - $s_6(0.05) \\rightarrow 1$. The path from the root is `01`, so the codeword for $s_6$ is `011`.\n  - $d_1(0.00) \\rightarrow 2$. The path from the root is `01`, so the codeword for $d_1$ is `012`, which is unused.\n\nThe resulting codebook is:\n- $s_1: 1$ (length $l_1=1$)\n- $s_2: 2$ (length $l_2=1$)\n- $s_3: 00$ (length $l_3=2$)\n- $s_4: 02$ (length $l_4=2$)\n- $s_5: 010$ (length $l_5=3$)\n- $s_6: 011$ (length $l_6=3$)\n\nThe average length $L_{avg}$ is the sum of the products of each symbol's probability and its codeword length:\n$L_{avg} = \\sum_{i=1}^{6} P(s_i) l_i$\n$L_{avg} = (0.35 \\times 1) + (0.25 \\times 1) + (0.15 \\times 2) + (0.12 \\times 2) + (0.08 \\times 3) + (0.05 \\times 3)$\n$L_{avg} = 0.35 + 0.25 + 0.30 + 0.24 + 0.24 + 0.15$\n$L_{avg} = 1.53$\n\nThe average length is $1.53$ ternary digits per source symbol. This value is already given to three significant figures.",
            "answer": "$$\\boxed{1.53}$$"
        },
        {
            "introduction": "An optimal code is not always unique. For certain source probabilities, the Huffman algorithm involves tie-breaking choices that can lead to different valid codebooks. While all resulting codes achieve the same optimal average length, their structural properties, such as the variance of the codeword lengths, can differ significantly. This practice invites you to explore this nuance by constructing two distinct optimal codes for the same source and comparing their length variance, highlighting that optimality in one metric does not guarantee uniformity in others .",
            "id": "1659058",
            "problem": "Consider a discrete memoryless source that generates symbols from the alphabet $\\mathcal{S} = \\{\\mathcal{A}, \\mathcal{B}, \\mathcal{C}, \\mathcal{D}\\}$. The probabilities of these symbols are given by $P(\\mathcal{A}) = 0.4$, $P(\\mathcal{B}) = 0.2$, $P(\\mathcal{C}) = 0.2$, and $P(\\mathcal{D}) = 0.2$.\n\nThe Huffman coding algorithm can be used to generate an optimal binary prefix code for this source. However, due to the specific probabilities, tie-breaking choices during the construction process can lead to the creation of at least two different optimal codes, which are distinguished by having different sets of codeword lengths.\n\nLet $L$ be a random variable representing the length of the codeword for a symbol drawn from the source. The value of $L$ for a symbol $s_i \\in \\mathcal{S}$ is its codeword length, $l_i$, and it occurs with probability $p_i = P(s_i)$. The variance of the codeword length is defined as $\\sigma^2 = E[L^2] - (E[L])^2$.\n\nYour task is to construct two different optimal Huffman codes, which we will call Code 1 and Code 2, such that the multiset of codeword lengths for Code 1, $\\{l_{1,\\mathcal{A}}, l_{1,\\mathcal{B}}, l_{1,\\mathcal{C}}, l_{1,\\mathcal{D}}\\}$, is different from the multiset of codeword lengths for Code 2, $\\{l_{2,\\mathcal{A}}, l_{2,\\mathcal{B}}, l_{2,\\mathcal{C}}, l_{2,\\mathcal{D}}\\}$.\n\nCalculate the variance of the codeword length for each of these two codes, denoted as $\\sigma_1^2$ and $\\sigma_2^2$. Then, compute the absolute difference between these two variances, $|\\sigma_1^2 - \\sigma_2^2|$.\n\nRound your final answer to two significant figures.",
            "solution": "The source probabilities are $P(\\mathcal{A})=0.4$, and $P(\\mathcal{B})=P(\\mathcal{C})=P(\\mathcal{D})=0.2$.\nIn the Huffman algorithm, we first merge two 0.2 probability symbols (e.g., $\\mathcal{B}$ and $\\mathcal{C}$) to form node $n_1$ with probability $0.4$. The current probabilities are $\\{\\mathcal{A}(0.4), n_1(0.4), \\mathcal{D}(0.2)\\}$. The next step requires merging the two least probable nodes. The least probable is $\\mathcal{D}(0.2)$, and the next least are $\\mathcal{A}(0.4)$ and $n_1(0.4)$. This presents a tie. Breaking the tie in two different ways yields two different code trees.\n\n**Code 1 Construction (Balanced Tree):**\nBreak the tie by merging node $\\mathcal{D}(0.2)$ with node $\\mathcal{A}(0.4)$ to create node $n_2(0.6)$. The list becomes $\\{n_1(0.4), n_2(0.6)\\}$. The final merge combines these. This construction leads to a balanced tree where all leaves ($\\mathcal{A}, \\mathcal{B}, \\mathcal{C}, \\mathcal{D}$) are at depth 2. The length multiset is $\\{2,2,2,2\\}$. The length $L_1$ is constant at 2.\n$E[L_1] = 2$. $E[L_1^2] = 2^2 = 4$.\n$$\n\\sigma_{1}^{2}=E[L_1^{2}]-(E[L_1])^{2}=4-4=0.\n$$\n\n**Code 2 Construction (Unbalanced Tree):**\nBreak the tie differently by merging node $\\mathcal{D}(0.2)$ with node $n_1(0.4)$ to create node $n_3(0.6)$. The list becomes $\\{\\mathcal{A}(0.4), n_3(0.6)\\}$. The final merge combines these. This results in an unbalanced tree. The length multiset is $\\{1, 2, 3, 3\\}$ (for symbols $\\mathcal{A}, \\mathcal{D}, \\mathcal{B}, \\mathcal{C}$ respectively). The distribution for length $L_2$ is $P(L_2=1)=0.4$, $P(L_2=2)=0.2$, and $P(L_2=3)=0.2+0.2=0.4$.\n$$\nE[L_2]=0.4\\cdot 1+0.2\\cdot 2+0.4\\cdot 3=2.0\n$$\n$$\nE[L_2^{2}]=0.4\\cdot 1^{2}+0.2\\cdot 2^{2}+0.4\\cdot 3^{2}=0.4+0.8+3.6=4.8\n$$\n$$\n\\sigma_{2}^{2}=E[L_2^{2}]-(E[L_2])^{2}=4.8-(2.0)^2=0.8.\n$$\nThe absolute difference between the variances is\n$$\n|\\sigma_{1}^{2}-\\sigma_{2}^{2}|=|0-0.8|=0.8,\n$$\nwhich rounded to two significant figures is $0.80$.",
            "answer": "$$\\boxed{0.80}$$"
        },
        {
            "introduction": "While Huffman coding assigns a fixed codeword to each symbol, arithmetic coding takes a different approach by encoding an entire message into a single fraction. This powerful method represents a sequence of symbols as a sub-interval within the range $[0, 1)$, with the interval's size shrinking recursively with each symbol. This hands-on problem guides you through the core mechanics of arithmetic coding, asking you to determine the final interval for a given sequence, thereby building an intuition for how this method can achieve superior compression performance .",
            "id": "1659115",
            "problem": "A simple stochastic source generates symbols from the alphabet {A, B, C}. The probabilities of these symbols are given as follows:\n$P(\\text{A}) = 0.25$\n$P(\\text{B}) = 0.60$\n$P(\\text{C}) = 0.15$\n\nA specific data compression scheme maps any sequence of these symbols to a unique floating-point sub-interval within the initial interval $[0, 1)$. The mapping process is defined recursively:\n1. The initial interval is $[0, 1)$. This interval is partitioned into sub-intervals corresponding to the symbols A, B, and C, arranged in that order. The length of each sub-interval is equal to the probability of the corresponding symbol.\n2. To encode a sequence, the initial interval is narrowed down to the sub-interval of the first symbol in the sequence.\n3. This new, smaller interval is then itself partitioned in the same proportions as the original interval $[0, 1)$ was partitioned. The process then narrows down to the sub-interval corresponding to the second symbol in the sequence.\n4. This recursive procedure is repeated for all symbols in the sequence.\n\nDetermine the final interval $[L, U)$ that represents the sequence \"BCA\". Present your answer as a row matrix containing the lower bound $L$ and the upper bound $U$, in that order, with both values rounded to five significant figures.",
            "solution": "We apply the recursive interval refinement as in arithmetic coding. Let the current interval be $[L, U)$ with width $R=U-L$. The cumulative probabilities are $P(A)=0.25$, $P(A)+P(B)=0.85$. With the symbol order A, B, C, the partitions within any $[L,U)$ are:\n- A: $[L,\\, L + 0.25R)$\n- B: $[L + 0.25R,\\, L + 0.85R)$\n- C: $[L + 0.85R,\\, U)$\n\nStart with $[L_{0}, U_{0}) = [0, 1)$, so $R_{0}=1$.\n\n**First symbol B:** We select the sub-interval for B.\n$L_1 = L_0 + 0.25 \\cdot R_0 = 0 + 0.25 \\cdot 1 = 0.25$\n$U_1 = L_0 + 0.85 \\cdot R_0 = 0 + 0.85 \\cdot 1 = 0.85$\nThe new interval is $[0.25,\\, 0.85)$. The width is $R_1 = U_1 - L_1 = 0.60$.\n\n**Second symbol C:** We select the sub-interval for C within the new interval $[0.25, 0.85)$.\n$L_2 = L_1 + 0.85 \\cdot R_1 = 0.25 + 0.85 \\cdot 0.60 = 0.25 + 0.51 = 0.76$\n$U_2 = U_1 = 0.85$\nThe new interval is $[0.76,\\, 0.85)$. The width is $R_2 = U_2 - L_2 = 0.09$.\n\n**Third symbol A:** We select the sub-interval for A within $[0.76, 0.85)$.\n$L_3 = L_2 = 0.76$\n$U_3 = L_2 + 0.25 \\cdot R_2 = 0.76 + 0.25 \\cdot 0.09 = 0.76 + 0.0225 = 0.7825$\nThe final interval is $[0.76,\\, 0.7825)$.\n\nRounding each bound to five significant figures gives $L = 0.76000$ and $U = 0.78250$.",
            "answer": "$$\\boxed{\\begin{pmatrix}0.76000  0.78250\\end{pmatrix}}$$"
        }
    ]
}