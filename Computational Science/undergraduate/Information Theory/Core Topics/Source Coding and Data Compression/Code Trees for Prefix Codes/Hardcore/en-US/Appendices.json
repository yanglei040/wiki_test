{
    "hands_on_practices": [
        {
            "introduction": "The foundation of any instantaneously decodable variable-length code is the prefix-free property, which ensures that no codeword is the beginning of another. This first exercise provides direct practice in identifying valid prefix codes from a set of candidates. Mastering this skill is the essential first step in designing or analyzing any compression scheme, as it guarantees that a stream of encoded data can be parsed without ambiguity .",
            "id": "1610981",
            "problem": "A remote environmental sensor network is designed to monitor five distinct types of atmospheric events, which we can label as $S_1, S_2, S_3, S_4, S_5$. To optimize data transmission over a low-bandwidth channel, a variable-length binary encoding scheme is employed. Based on the expected frequency of each event, the system designers have specified the required lengths for the binary codewords: one event must be encoded with a 2-bit codeword, and the other four events must each be encoded with 3-bit codewords.\n\nA critical requirement for the encoding scheme is that it must be *instantaneously decodable*. This property ensures that any sequence of concatenated codewords, representing a series of detected events, can be uniquely and unambiguously parsed into its constituent codewords without needing to look ahead. This is achieved if and only if no codeword in the set is a prefix of any other codeword.\n\nYour task is to evaluate several proposed sets of codewords. From the options listed below, identify all sets that represent a valid encoding scheme satisfying both the specified length distribution (one 2-bit word, four 3-bit words) and the instantaneously decodable property.\n\nA. $\\{11, 000, 001, 010, 011\\}$\n\nB. $\\{00, 100, 101, 110, 111\\}$\n\nC. $\\{01, 010, 000, 110, 111\\}$\n\nD. $\\{00, 01, 100, 101, 110\\}$\n\nE. $\\{10, 000, 001, 110, 111\\}$\n\nF. $\\{11, 101, 001, 011, 110\\}$",
            "solution": "We require a binary code for five source symbols with exactly one codeword of length $2$ and four codewords of length $3$, and the code must be instantaneously decodable, which is equivalent to being prefix-free: no codeword may be a prefix of another. Given that all lengths are $2$ or $3$, once the length distribution is satisfied, it suffices to check that the unique $2$-bit codeword is not a prefix of any of the $3$-bit codewords, since distinct $3$-bit codewords cannot be prefixes of one another.\n\nEvaluate each option:\n\nA. The set has one $2$-bit word $11$ and four $3$-bit words $000, 001, 010, 011$. None of the $3$-bit words starts with $11$, so no prefix violation occurs. The length distribution is satisfied. Valid.\n\nB. The set has one $2$-bit word $00$ and four $3$-bit words $100, 101, 110, 111$. None of the $3$-bit words starts with $00$, so no prefix violation occurs. The length distribution is satisfied. Valid.\n\nC. The set has one $2$-bit word $01$ and four $3$-bit words $010, 000, 110, 111$. The $3$-bit word $010$ begins with $01$, so the $2$-bit word is a prefix of a $3$-bit word. This violates the prefix-free condition. Invalid.\n\nD. The set has two $2$-bit words $00, 01$ and three $3$-bit words $100, 101, 110$. This fails the required length distribution (must be one $2$-bit and four $3$-bit words). Invalid.\n\nE. The set has one $2$-bit word $10$ and four $3$-bit words $000, 001, 110, 111$. None of the $3$-bit words starts with $10$, so no prefix violation occurs. The length distribution is satisfied. Valid.\n\nF. The set has one $2$-bit word $11$ and four $3$-bit words $101, 001, 011, 110$. The $3$-bit word $110$ begins with $11$, so the $2$-bit word is a prefix of a $3$-bit word. This violates the prefix-free condition. Invalid.\n\nTherefore, the valid options are A, B, and E.",
            "answer": "$$\\boxed{ABE}$$"
        },
        {
            "introduction": "Once we confirm a code is valid, the next step is to measure its performance. This practice introduces the concept of average codeword length, a crucial metric that quantifies the efficiency of an encoding. By calculating the expected number of bits per symbol, weighted by the probability of each symbol's occurrence, you will learn to connect the structure of a code to its practical compression performance .",
            "id": "1610986",
            "problem": "A research team is developing a simple compression scheme for a new type of low-power weather sensor. The sensor can report one of four possible states, which we represent with the abstract symbols $s_1, s_2, s_3, \\text{and } s_4$. To transmit the data efficiently, the team proposes a binary encoding scheme that maps these symbols to the following codewords:\n- $s_1 \\rightarrow 01$\n- $s_2 \\rightarrow 1$\n- $s_3 \\rightarrow 000$\n- $s_4 \\rightarrow 001$\n\nFor a stream of such codewords to be unambiguously and instantaneously decodable, the code must be a prefix code. A code is defined as a prefix code if no codeword in the set is a prefix of any other codeword.\n\nBased on historical weather patterns, the probabilities of occurrence for each symbol are estimated as follows:\n- $P(s_1) = 0.20$\n- $P(s_2) = 0.50$\n- $P(s_3) = 0.15$\n- $P(s_4) = 0.15$\n\nCalculate the average codeword length for this encoding scheme. The average codeword length is the expected value of the lengths of the codewords, weighted by their probabilities. Provide your answer as a single decimal number.",
            "solution": "A prefix code requires that no codeword is a prefix of any other. The given set $\\{01, 1, 000, 001\\}$ is prefix-free because none of these strings begins with another entire codeword from the set.\n\nLet the codeword lengths be $l(s_{1})=2$, $l(s_{2})=1$, $l(s_{3})=3$, and $l(s_{4})=3$, corresponding to $01$, $1$, $000$, and $001$ respectively.\n\nThe average codeword length $L$ is the expected value of the codeword lengths:\n$$\nL=\\sum_{i=1}^{4}P(s_{i})\\,l(s_{i})=P(s_{1})l(s_{1})+P(s_{2})l(s_{2})+P(s_{3})l(s_{3})+P(s_{4})l(s_{4}).\n$$\nSubstituting the given probabilities and lengths:\n$$\nL=0.20\\cdot 2+0.50\\cdot 1+0.15\\cdot 3+0.15\\cdot 3=0.4+0.5+0.45+0.45=1.8.\n$$\nTherefore, the average codeword length is $1.8$.",
            "answer": "$$\\boxed{1.8}$$"
        },
        {
            "introduction": "Optimal codes, like those generated by Huffman's algorithm, are finely tuned to the specific probabilities of the source symbols. This final practice explores the important real-world scenario where these probabilities change over time, rendering a once-optimal code suboptimal. By calculating the \"inefficiency penalty,\" you will quantify the performance cost of failing to adapt, providing a concrete understanding of why the efficiency of a code is critically linked to the source statistics .",
            "id": "1610971",
            "problem": "A data compression system uses a Huffman code to losslessly compress data from a discrete memoryless source. The source emits symbols from the set $S = \\{s_1, s_2, s_3, s_4, s_5\\}$. Initially, the system is configured for a stationary probability distribution $P_0$, where the probabilities of the symbols are given by:\n$p_0(s_1) = 0.45$\n$p_0(s_2) = 0.25$\n$p_0(s_3) = 0.15$\n$p_0(s_4) = 0.10$\n$p_0(s_5) = 0.05$\n\nBased on this distribution $P_0$, an optimal Huffman code is generated, fixing a specific set of codeword lengths $\\{l_0(s_1), l_0(s_2), l_0(s_3), l_0(s_4), l_0(s_5)\\}$ for the symbols.\n\nAfter some time, the underlying process generating the data changes, and the source statistics are updated to a new stationary distribution, $P_1$. The new probabilities are:\n$p_1(s_1) = 0.05$\n$p_1(s_2) = 0.25$\n$p_1(s_3) = 0.15$\n$p_1(s_4) = 0.10$\n$p_1(s_5) = 0.45$\n\nThe system, however, does not update its coding scheme and continues to use the original codeword lengths, $l_0$, that were optimal for $P_0$. This results in a suboptimal average codeword length.\n\nLet $L_{sub}$ be the average codeword length when using the original code (with lengths $l_0$) on the source with the new probabilities $P_1$.\nLet $L_{opt}$ be the new optimal average codeword length that would be achieved by generating a new Huffman code specifically for the distribution $P_1$.\n\nThe \"inefficiency penalty\" of not updating the code is the difference $\\Delta L = L_{sub} - L_{opt}$. Calculate the value of this penalty. Round your final answer to four significant figures.",
            "solution": "The problem asks for the inefficiency penalty $\\Delta L = L_{sub} - L_{opt}$, which arises from using an old Huffman code on a data source with changed statistics. We need to calculate the average codeword length for the suboptimal case ($L_{sub}$) and the new optimal case ($L_{opt}$), and then find their difference.\n\n**Step 1: Determine the codeword lengths for the initial Huffman code ($l_0$).**\nThe initial code is built using the probability distribution $P_0$: $\\{p_0(s_1)=0.45, p_0(s_2)=0.25, p_0(s_3)=0.15, p_0(s_4)=0.10, p_0(s_5)=0.05\\}$.\nThe Huffman algorithm proceeds by iteratively merging the two nodes with the lowest probabilities.\n\n1.  Initial list of nodes (symbol, probability):\n    $(s_5, 0.05), (s_4, 0.10), (s_3, 0.15), (s_2, 0.25), (s_1, 0.45)$.\n\n2.  Merge the two lowest probability nodes, $s_5$ and $s_4$. This creates a new internal node, let's call it $n_1$, with probability $0.05 + 0.10 = 0.15$.\n    The list becomes: $(s_3, 0.15), (n_1, 0.15), (s_2, 0.25), (s_1, 0.45)$.\n\n3.  Merge the two new lowest probability nodes, $s_3$ and $n_1$. This creates a new internal node, $n_2$, with probability $0.15 + 0.15 = 0.30$.\n    The list becomes: $(s_2, 0.25), (n_2, 0.30), (s_1, 0.45)$.\n\n4.  Merge the two lowest probability nodes, $s_2$ and $n_2$. This creates a new internal node, $n_3$, with probability $0.25 + 0.30 = 0.55$.\n    The list becomes: $(s_1, 0.45), (n_3, 0.55)$.\n\n5.  Merge the final two nodes, $s_1$ and $n_3$, to form the root of the tree with probability $1.0$.\n\nNow, we can determine the depth (codeword length) of each symbol in this tree, $T_0$.\n-   $s_1$ is a direct child of the root. Its depth is 1. So, $l_0(s_1) = 1$.\n-   $n_3$ is a direct child of the root.\n-   $s_2$ is a child of $n_3$. Its depth is 2. So, $l_0(s_2) = 2$.\n-   $n_2$ is a child of $n_3$.\n-   $s_3$ is a child of $n_2$. Its depth is 3. So, $l_0(s_3) = 3$.\n-   $n_1$ is a child of $n_2$.\n-   $s_4$ is a child of $n_1$. Its depth is 4. So, $l_0(s_4) = 4$.\n-   $s_5$ is a child of $n_1$. Its depth is 4. So, $l_0(s_5) = 4$.\n\nThe initial codeword lengths are: $\\{l_0(s_1), l_0(s_2), l_0(s_3), l_0(s_4), l_0(s_5)\\} = \\{1, 2, 3, 4, 4\\}$.\n\n**Step 2: Calculate the suboptimal average length $L_{sub}$.**\n$L_{sub}$ is the average length using the old lengths $l_0$ with the new probabilities $P_1$.\n$P_1$: $\\{p_1(s_1)=0.05, p_1(s_2)=0.25, p_1(s_3)=0.15, p_1(s_4)=0.10, p_1(s_5)=0.45\\}$.\n$$L_{sub} = \\sum_{i=1}^{5} p_1(s_i) l_0(s_i)$$\n$$L_{sub} = p_1(s_1)l_0(s_1) + p_1(s_2)l_0(s_2) + p_1(s_3)l_0(s_3) + p_1(s_4)l_0(s_4) + p_1(s_5)l_0(s_5)$$\n$$L_{sub} = (0.05)(1) + (0.25)(2) + (0.15)(3) + (0.10)(4) + (0.45)(4)$$\n$$L_{sub} = 0.05 + 0.50 + 0.45 + 0.40 + 1.80 = 3.20$$\n\n**Step 3: Determine the codeword lengths for the new optimal Huffman code ($l_1$).**\nThe new code is built using the probability distribution $P_1$. The set of probability values in $P_1$ is $\\{0.05, 0.10, 0.15, 0.25, 0.45\\}$. This is the *exact same set* of probability values as in $P_0$, just assigned to different symbols. Since the structure of the Huffman tree depends only on the set of probability values, the new optimal tree $T_1$ will have the same structure as $T_0$. Consequently, the set of optimal codeword lengths will also be the same: $\\{1, 2, 3, 4, 4\\}$.\n\nThe key difference is which symbol gets which length. In an optimal Huffman code, the highest probability symbol gets the shortest codeword length.\n-   $p_1(s_5) = 0.45$ (highest), so $l_1(s_5) = 1$.\n-   $p_1(s_2) = 0.25$ (second highest), so $l_1(s_2) = 2$.\n-   $p_1(s_3) = 0.15$ (third highest), so $l_1(s_3) = 3$.\n-   $p_1(s_4) = 0.10$ (fourth highest), so $l_1(s_4) = 4$.\n-   $p_1(s_1) = 0.05$ (lowest), so $l_1(s_1) = 4$.\n\nThe new optimal codeword lengths are: $\\{l_1(s_1), l_1(s_2), l_1(s_3), l_1(s_4), l_1(s_5)\\} = \\{4, 2, 3, 4, 1\\}$.\n\n**Step 4: Calculate the new optimal average length $L_{opt}$.**\n$L_{opt}$ is the average length using the new lengths $l_1$ with the new probabilities $P_1$.\n$$L_{opt} = \\sum_{i=1}^{5} p_1(s_i) l_1(s_i)$$\n$$L_{opt} = p_1(s_1)l_1(s_1) + p_1(s_2)l_1(s_2) + p_1(s_3)l_1(s_3) + p_1(s_4)l_1(s_4) + p_1(s_5)l_1(s_5)$$\n$$L_{opt} = (0.05)(4) + (0.25)(2) + (0.15)(3) + (0.10)(4) + (0.45)(1)$$\n$$L_{opt} = 0.20 + 0.50 + 0.45 + 0.40 + 0.45 = 2.00$$\n\n**Step 5: Calculate the inefficiency penalty $\\Delta L$.**\n$$\\Delta L = L_{sub} - L_{opt}$$\n$$\\Delta L = 3.20 - 2.00 = 1.20$$\nRounding the result to four significant figures gives $1.200$.",
            "answer": "$$\\boxed{1.200}$$"
        }
    ]
}