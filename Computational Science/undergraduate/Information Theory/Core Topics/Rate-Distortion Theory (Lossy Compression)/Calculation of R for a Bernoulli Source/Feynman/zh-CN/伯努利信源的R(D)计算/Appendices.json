{
    "hands_on_practices": [
        {
            "introduction": "信息率，或称熵，是衡量信源不确定性的核心指标。这个练习颠倒了常规的计算方向：我们不再从已知的概率 $p$ 计算熵 $H(p)$，而是从一个给定的信息率反向推断信源可能的概率参数。通过这项实践 ，你将更深刻地理解二元熵函数 $H(p)$ 的对称性等重要性质，并掌握其在分析信源特性时的应用。",
            "id": "1606652",
            "problem": "在一个简化的生物物理模型中，一个神经元在离散时间间隔上的状态被描述为一个二元过程。在任何给定的时间间隔内，该神经元要么“发放”（由逻辑值1表示），要么保持“静息”（由逻辑值0表示）。这种行为被建模为一个伯努利过程，其中神经元发放的概率是一个恒定值 $p$，而其保持静息的概率是 $1-p$。该神经元在许多时间间隔内的输出序列构成一个离散无记忆信源。\n\n一位研究该模型的信息理论家测量了该神经元输出流的平均信息量（即熵）。测量得到的信息速率恰好为 0.50 比特/符号。\n\n基于这些信息，发放概率 $p$ 可能为下列哪些值？选择所有适用项。\n\nA. 0.11\n\nB. 0.25\n\nC. 0.50\n\nD. 0.75\n\nE. 0.89\n\nF. 1.00",
            "solution": "对于一个发放概率为 $p$ 的伯努利信源，其每个符号的熵（以比特为单位）为\n$$\nH(p)=-p\\log_{2}(p)-(1-p)\\log_{2}(1-p).\n$$\n该熵函数满足 $H(p)=H(1-p)$，并在 $p=\\frac{1}{2}$ 时达到最大值 $H\\left(\\frac{1}{2}\\right)=1$。因此，方程 $H(p)=0.50$ 在区间 $(0,1)$ 内恰好有两个解，这两个解关于 $p=\\frac{1}{2}$ 对称。\n\n评估所列的候选值：\n- $p=0.11$:\n$$\nH(0.11)=-0.11\\log_{2}(0.11)-0.89\\log_{2}(0.89)\\approx -0.11(-3.183)-0.89(-0.168)\\approx 0.350+0.150\\approx 0.500,\n$$\n所以这个值与 $0.50$ 匹配。\n- $p=0.25$:\n$$\nH(0.25)=-0.25\\log_{2}(0.25)-0.75\\log_{2}(0.75)=0.5-0.75\\log_{2}(0.75)\\approx 0.5+0.311\\approx 0.811,\n$$\n不是 $0.50$。\n- $p=0.50$:\n$$\nH(0.50)=1,\n$$\n不是 $0.50$。\n- $p=0.75$:\n根据对称性，$H(0.75)=H(0.25)\\approx 0.811$，不是 $0.50$。\n- $p=0.89$:\n根据对称性，$H(0.89)=H(0.11)\\approx 0.500$，所以这个值匹配。\n- $p=1.00$:\n$$\nH(1.00)=0,\n$$\n不是 $0.50$。\n\n因此，在这些选项中，与 $0.50$ 比特/符号的熵相符的 $p$ 值为 $p=0.11$ 和 $p=0.89$。",
            "answer": "$$\\boxed{AE}$$"
        },
        {
            "introduction": "在许多实际应用中，完美的无损压缩并非必需，我们可以在一定失真容忍度下换取更高的压缩率。本练习  旨在介绍有损压缩的核心概念——率失真函数 $R(D)$。你将从最简单也最基础的场景入手，为一个对称的伯努利信源计算其在特定失真水平下的理论最低数据率，直观感受压缩率与信息损失之间的权衡关系。",
            "id": "1606598",
            "problem": "一个数字传感器监控一个简单的二元现象，产生一个由独立同分布的符号“0”和“1”组成的序列。传感器输出“1”的概率为 $p = \\frac{1}{2}$。为了实现高效存储，需要对该数据流进行压缩。该压缩方案是有损的，意味着重构的数据可能不是原始数据的完美复制品。原始符号与其重构符号之间的失真量化如下：如果符号相同，失真为0；如果符号不同，失真为1。\n\n您的任务是计算，在每个符号的平均失真不超过 $D = 0.15$ 的条件下，编码该信源所需的最小理论数据速率（以比特/符号为单位）。\n\n请将最终答案四舍五入至三位有效数字。",
            "solution": "我们有一个无记忆二元信源，其概率为 $P(X=1)=\\frac{1}{2}$，汉明失真度量为 $d(x,\\hat{x})=\\mathbf{1}\\{x\\neq \\hat{x}\\}$。对于具有汉明失真的伯努利$\\left(\\frac{1}{2}\\right)$信源，其率失真函数（以比特/符号为单位）为\n$$\nR(D)=1-h_{2}(D), \\quad 0\\leq D\\leq \\frac{1}{2},\n$$\n其中二元熵函数为\n$$\nh_{2}(D)=-D\\log_{2}D-(1-D)\\log_{2}(1-D).\n$$\n由于 $D=0.15\\in[0,\\frac{1}{2}]$，此公式适用。代入 $D=0.15$，\n$$\nh_{2}(0.15)=-0.15\\log_{2}(0.15)-0.85\\log_{2}(0.85).\n$$\n使用 $\\log_{2}x=\\frac{\\ln x}{\\ln 2}$，我们计算\n$$\n\\log_{2}(0.15)\\approx -2.736965594,\\quad \\log_{2}(0.85)\\approx -0.234465254,\n$$\n因此\n$$\nh_{2}(0.15)\\approx -0.15(-2.736965594)-0.85(-0.234465254)\\approx 0.609840305.\n$$\n所以，\n$$\nR(0.15)=1-h_{2}(0.15)\\approx 1-0.609840305\\approx 0.390159695.\n$$\n四舍五入至三位有效数字，最小速率为 $0.390$ 比特/符号。",
            "answer": "$$\\boxed{0.390}$$"
        },
        {
            "introduction": "信息论的强大之处在于其分析复杂系统的能力。本练习  将引导你综合运用概率论与信息论知识，解决一个更具挑战性的问题。你需要分析一个由两个独立信源通过逻辑运算复合而成的新信源，首先推导出其概率分布，然后计算其率失真函数 $R(D)$，这充分展示了信息论工具在处理多源信息系统时的分析威力。",
            "id": "1606664",
            "problem": "两个独立的无记忆二进制数据流，由随机变量序列 $\\{X_{1,i}\\}$ 和 $\\{X_{2,i}\\}$ 表示，由两个独立的过程生成。在每个时间步 $i$，随机变量 $X_{1,i}$ 服从伯努利分布，其中 $P(X_{1,i}=1) = p = 1/3$，随机变量 $X_{2,i}$ 服从伯努利分布，其中 $P(X_{2,i}=1) = q = 1/4$。\n\n通过对两个源数据流进行按位异或（XOR）操作，创建了一个新的数据流 $\\{Y_i\\}$，使得在每个时间步 $i$ 都有 $Y_i = X_{1,i} \\oplus X_{2,i}$。这个新数据流 $\\{Y_i\\}$ 构成了一个无记忆二进制信源。\n\n我们希望压缩这个新信源 $Y$ 并将其传输。重构信号 $\\hat{Y}$ 的质量使用汉明失真度量来评估，定义为：如果 $y = \\hat{y}$，则 $d(y, \\hat{y}) = 0$；如果 $y \\neq \\hat{y}$，则 $d(y, \\hat{y}) = 1$。率失真函数 $R(D)$ 量化了表示信源 $Y$ 所需的每个符号的最小比特数，使得期望失真 $E[d(Y, \\hat{Y})]$ 不超过给定的失真水平 $D$。\n\n确定信源 $Y$ 的率失真函数 $R(D)$。最终答案应以 $D$ 的表达式形式给出。在计算中使用以 2 为底的对数。",
            "solution": "我们首先确定异或信源的分布。由于 $X_{1,i}$ 和 $X_{2,i}$ 是独立的，且 $P(X_{1,i}=1)=p=\\frac{1}{3}$ 及 $P(X_{2,i}=1)=q=\\frac{1}{4}$，异或输出为 $Y_{i}=X_{1,i}\\oplus X_{2,i}$，其概率为\n$$\nP(Y_{i}=1)=P(X_{1,i}\\neq X_{2,i})=p(1-q)+(1-p)q=p+q-2pq.\n$$\n代入 $p=\\frac{1}{3}$ 和 $q=\\frac{1}{4}$ 可得\n$$\nP(Y=1)=\\frac{1}{3}+\\frac{1}{4}-2\\cdot\\frac{1}{3}\\cdot\\frac{1}{4}=\\frac{4}{12}+\\frac{3}{12}-\\frac{2}{12}=\\frac{5}{12},\n$$\n因此，$Y$ 是一个参数为 $r=\\frac{5}{12}$ 的伯努利信源，且 $P(Y=0)=1-r=\\frac{7}{12}$。\n\n对于汉明失真下的二进制无记忆信源 $Y\\sim\\text{Bernoulli}(r)$，其率失真函数是众所周知的，可以如下推导。对于具有汉明失真的离散无记忆信源，Shannon下界对于二进制信源是紧的，并且可以通过一个交叉概率为 $D$ 的二进制对称测试信道来实现。具体来说，考虑一个测试信道 $P_{\\hat{Y}|Y}$，它是一个交叉概率为 $D$ 的二进制对称信道，因此 $P(\\hat{Y}\\neq Y)=D$。那么 $Y$ 和 $\\hat{Y}$ 之间的互信息是\n$$\nI(Y;\\hat{Y})=H(\\hat{Y})-H(\\hat{Y}|Y)=H(\\hat{Y})-H_{b}(D),\n$$\n其中 $H_{b}(x)=-x\\log_{2}x-(1-x)\\log_{2}(1-x)$ 是二进制熵函数。将对称测试信道应用于伯努利$(r)$输入，$\\hat{Y}$ 是参数为 $r\\star D=r(1-D)+(1-r)D=r+D-2rD$ 的伯努利分布。当 $D\\leq \\min\\{r,1-r\\}$ 且 $r\\leq \\frac{1}{2}$ 时，最大化输出熵为 $H(\\hat{Y})=H_{b}(r)$，并且在所有满足失真约束 $E[d(Y,\\hat{Y})]\\leq D$ 的测试信道中，最小互信息由交叉概率为 $D$ 的二进制对称信道实现，得到\n$$\nR(D)=\\min_{P_{\\hat{Y}|Y}: E[d(Y,\\hat{Y})]\\leq D} I(Y;\\hat{Y})=H_{b}(r)-H_{b}(D), \\quad 0\\leq D\\leq \\min\\{r,1-r\\}.\n$$\n对于更大的失真，猜测更可能的符号会产生失真 $\\min\\{r,1-r\\}$，其码率为零，因此当 $D\\geq \\min\\{r,1-r\\}$ 时，$R(D)=0$。在本例中，$r=\\frac{5}{12}<\\frac{1}{2}$，因此 $\\min\\{r,1-r\\}=r=\\frac{5}{12}$。因此，\n$$\nR(D)=H_{b}\\!\\left(\\frac{5}{12}\\right)-H_{b}(D), \\quad 0\\leq D\\leq \\frac{5}{12},\n$$\n且\n$$\nR(D)=0, \\quad D\\geq \\frac{5}{12}.\n$$\n使用以 2 为底的对数明确写出 $H_{b}$，\n$$\nH_{b}\\!\\left(\\frac{5}{12}\\right)=-\\frac{5}{12}\\log_{2}\\!\\left(\\frac{5}{12}\\right)-\\frac{7}{12}\\log_{2}\\!\\left(\\frac{7}{12}\\right), \\quad\nH_{b}(D)=-D\\log_{2}(D)-(1-D)\\log_{2}(1-D).\n$$\n结合这些表达式，即可得到所求的关于 $D$ 的分段函数 $R(D)$。",
            "answer": "$$\\boxed{R(D)=\\begin{cases}-\\dfrac{5}{12}\\log_{2}\\!\\left(\\dfrac{5}{12}\\right)-\\dfrac{7}{12}\\log_{2}\\!\\left(\\dfrac{7}{12}\\right)+D\\log_{2}(D)+(1-D)\\log_{2}(1-D), & 0\\leq D\\leq \\dfrac{5}{12},\\\\[6pt] 0, & D\\geq \\dfrac{5}{12}.\\end{cases}}$$"
        }
    ]
}