{
    "hands_on_practices": [
        {
            "introduction": "这个练习是率失真理论的基石。我们将为一个简单的二进制信源计算在汉明失真（本质上是错误率）下的率失真函数 $R(D)$。这个基础性的例子  将揭示压缩率、信源不确定性（$H(p)$）以及在允许失真后残留的不确定性（$H(D)$）之间优美的关系。",
            "id": "1652137",
            "problem": "考虑一个离散无记忆信源，它从字母表 $\\mathcal{X} = \\{0, 1\\}$ 中生成二元符号 $X$。生成“1”的概率为 $P(X=1) = p$，生成“0”的概率为 $P(X=0) = 1-p$。为简单起见，假设 $0  p \\le 1/2$。我们希望压缩该信源的输出，并用来自相同字母表 $\\hat{\\mathcal{X}} = \\{0, 1\\}$ 的符号 $\\hat{X}$ 来表示它。\n\n压缩的质量由单符号 Hamming 失真来衡量，定义为：当 $x = \\hat{x}$ 时 $d(x, \\hat{x}) = 0$，当 $x \\neq \\hat{x}$ 时 $d(x, \\hat{x}) = 1$。平均失真表示为 $D = E[d(X, \\hat{X})]$。\n\n率失真函数 $R(D)$ 给出了在给定最大平均失真 $D$ 的情况下，可以实现的最小率（以比特/符号为单位）。请找出该信源在率不为零的区域内的率失真函数 $R(D)$ 的表达式。你的最终答案应使用二元熵函数 $H(y) = -y \\log_2(y) - (1-y)\\log_2(1-y)$ 表示，并且可以包含参数 $p$ 和 $D$。",
            "solution": "率失真函数 $R(D)$ 定义为信源 $X$ 和重构 $\\hat{X}$ 之间的最小可能互信息 $I(X; \\hat{X})$，该最小值是在所有满足平均失真 $E[d(X, \\hat{X})] \\le D$ 的联合分布 $p(x, \\hat{x})$ 上求得的。\n$$R(D) = \\min_{p(\\hat{x}|x) : E[d(X,\\hat{X})] \\le D} I(X; \\hat{X})$$\n互信息可以用熵表示为 $I(X; \\hat{X}) = H(X) - H(X|\\hat{X})$。对于给定的 Bernoulli 信源，熵 $H(X)$ 是一个常数，等于 $H(p)$。因此，最小化 $I(X; \\hat{X})$ 等价于最大化条件熵 $H(X|\\hat{X})$。\n\n$$R(D) = H(p) - \\max_{p(\\hat{x}|x) : E[d(X,\\hat{X})] \\le D} H(X|\\hat{X})$$\n\n我们可以使用 Fano 不等式找到 $H(X|\\hat{X})$ 的一个上界。Hamming 失真 $d(x, \\hat{x})$ 在 $x \\neq \\hat{x}$ 时为 1，否则为 0。因此，平均失真就是错误概率：$D = E[d(X, \\hat{X})] = P(X \\neq \\hat{X})$。\n\nFano 不等式指出，对于任意两个具有相同字母表 $\\mathcal{X}$ 的随机变量 $X$ 和 $\\hat{X}$，\n$$H(X|\\hat{X}) \\le H(P(X \\neq \\hat{X})) + P(X \\neq \\hat{X}) \\log_2(|\\mathcal{X}|-1)$$\n对于我们的二元信源， $|\\mathcal{X}|=2$，所以 $\\log_2(|\\mathcal{X}|-1) = \\log_2(1) = 0$。使用 $P(X \\neq \\hat{X}) \\le D$，我们得到：\n$$H(X|\\hat{X}) \\le H(D)$$\n这为率失真函数提供了一个下界：\n$$R(D) \\ge H(p) - H(D)$$\n如果我们能找到一个测试信道（即一个条件分布 $p(\\hat{x}|x)$），它能同时满足失真约束 $E[d(X, \\hat{X})] = D$ 并达到熵界 $H(X|\\hat{X}) = H(D)$，那么这个下界就是可达的。\n\n我们来构造这样一个信道。如果给定 $\\hat{X}$ 后 $X$ 的条件分布是一个概率为 $D$ 的简单二元分布，则条件 $H(X|\\hat{X}) = H(D)$ 得到满足。我们定义一个*反向*测试信道，其交叉概率为 $D$：\n$$p(X=1|\\hat{X}=0) = D \\quad \\text{and} \\quad p(X=0|\\hat{X}=1) = D$$\n这意味着 $p(X=0|\\hat{X}=0) = 1-D$ 且 $p(X=1|\\hat{X}=1) = 1-D$。\n因此，对于 $\\hat{x}=0$ 和 $\\hat{x}=1$，条件熵 $H(X|\\hat{X}=\\hat{x})$ 均为 $H(D)$。因此，总条件熵为 $H(X|\\hat{X}) = \\sum_{\\hat{x}} p(\\hat{x}) H(X|\\hat{X}=\\hat{x}) = H(D)$。\n\n现在，我们需要定义输出分布 $p(\\hat{x})$，以使得信源分布 $p(x)$ 得以重现并且满足失真约束。令 $p(\\hat{X}=1) = q$。则 $p(\\hat{X}=0) = 1-q$。边缘概率 $P(X=1)$ 可以计算如下：\n$$P(X=1) = \\sum_{\\hat{x}} P(\\hat{X}=\\hat{x}) P(X=1|\\hat{X}=\\hat{x})$$\n$$p = (1-q) P(X=1|\\hat{X}=0) + q P(X=1|\\hat{X}=1)$$\n$$p = (1-q)D + q(1-D) = D - qD + q - qD = q(1-2D) + D$$\n求解 $q$：\n$$q = \\frac{p-D}{1-2D}$$\n为了使 $q$ 成为一个有效的概率，我们需要 $0 \\le q \\le 1$。\n给定 $p \\le 1/2$。我们只考虑 $D \\le p$ 的情况，这确保了 $D \\le 1/2$ 且分母 $1-2D \\ge 0$。\n$q \\ge 0$ 的要求意味着 $p-D \\ge 0$，所以 $D \\le p$。\n$q \\le 1$ 的要求意味着 $p-D \\le 1-2D$，所以 $D \\le 1-p$。\n由于给定 $p \\le 1/2$，我们有 $p \\le 1-p$。因此，更严格的条件是 $D \\le p$。所以，这个构造对于 $0 \\le D \\le p$ 是有效的。\n\n最后，我们来验证此信道的平均失真：\n$$E[d(X, \\hat{X})] = P(X \\neq \\hat{X}) = \\sum_{\\hat{x}} P(\\hat{X}=\\hat{x}) P(X \\neq \\hat{x} | \\hat{X}=\\hat{x})$$\n$$E[d(X, \\hat{X})] = P(\\hat{X}=0) P(X=1|\\hat{X}=0) + P(\\hat{X}=1) P(X=0|\\hat{X}=1)$$\n$$E[d(X, \\hat{X})] = (1-q)D + qD = D$$\n失真约束被等式满足。\n\n由于我们已构造出一个信道，对于 $0 \\le D \\le p$ 范围内的任意 $D$，该信道产生的失真为 $D$，其率为 $I(X;\\hat{X}) = H(p) - H(D)$，因此该下界是可达的。对于 $D > p$，我们可以达到零率。例如，通过始终设置 $\\hat{X}=0$（因为 0 是更可能出现的符号），失真为 $D = P(X=1) = p$，而率为 $I(X; \\text{const}) = 0$。由于 $R(D)$ 是一个非增函数，对于所有 $D \\ge p$，$R(D)=0$。\n\n因此，在非平凡区域（$0 \\le D \\le p$）内，率失真函数的表达式为：\n$$R(D) = H(p) - H(D)$$",
            "answer": "$$\\boxed{H(p) - H(D)}$$"
        },
        {
            "introduction": "在掌握了基础知识之后，我们现在来探索一个不同的场景。这个练习  涉及一个拥有两个以上符号的信源，并使用在信号处理中常见的平方误差失真。你将学习一种强大的几何方法：通过量化找到可实现的率失真点，然后将最终的 $R(D)$ 曲线构建为这些点的下凸包。",
            "id": "1652148",
            "problem": "一个离散无记忆信源从字母表 $\\mathcal{X} = \\{1, 2, 3, 4\\}$ 中发出符号。每个符号的生成都是独立的，且概率相等。我们希望压缩该信源，并用一个由任意实数组成的再现字母表 $\\hat{\\mathcal{X}}$ 来表示它。再现质量由平方误差失真来衡量，其定义为 $d(x, \\hat{x}) = (x - \\hat{x})^2$，其中 $x \\in \\mathcal{X}$ 是信源符号，$\\hat{x} \\in \\hat{\\mathcal{X}}$ 是其再现符号。\n\n确定该信源的率失真函数 $R(D)$，它给出了在给定最大平均失真 $D$ 的情况下，每符号可实现的最小速率（以比特为单位）。请将您的答案表示为关于 $D$ 的分段函数。",
            "solution": "设 $X$ 在 $\\mathcal{X}=\\{1,2,3,4\\}$ 上均匀分布，其概率为 $p(x)=\\frac{1}{4}$。在平方误差失真下的率失真函数为\n$$\nR(D)=\\inf_{p(\\hat{x}|x):\\,\\mathbb{E}[(X-\\hat{X})^{2}]\\le D} I(X;\\hat{X}),\n$$\n以比特/符号为单位（因此所有对数均以2为底）。\n\n使用的关键事实：\n- 对于平方误差失真和无约束的再现字母表，对于信源字母表的任何确定性划分（量化器）成簇，一个簇的最佳再现值是其条件均值，而该簇对总均方误差的贡献是其簇内方差。\n- 可实现的 $(D,R)$ 点对集合通过时分复用是凸的。因此，$R(D)$ 是由确定性映射得到的可实现点的下凸包。\n\n计算典型的确定性映射（聚类），它们的失真和速率。\n\n1) 单簇映射（恒定再现）。\n- 再现值 $\\hat{x}=\\mathbb{E}[X]=\\frac{1+2+3+4}{4}=\\frac{5}{2}$。\n- 失真 $D=\\mathrm{Var}(X)=\\mathbb{E}[X^{2}]-(\\mathbb{E}[X])^{2}=\\frac{30}{4}-\\left(\\frac{5}{2}\\right)^{2}=\\frac{15}{2}-\\frac{25}{4}=\\frac{5}{4}$。\n- 由于 $\\hat{X}$ 是常数，所以 $I(X;\\hat{X})=0$。因此得到点 $\\left(D,R\\right)=\\left(\\frac{5}{4},0\\right)$。\n\n2) 双簇映射。\n- 最优的 2-均值划分将相邻的点分组：$\\{1,2\\}$ 和 $\\{3,4\\}$，其质心分别为 $\\frac{3}{2}$ 和 $\\frac{7}{2}$。\n- 对于一个由两个相邻点 $\\{x,x+1\\}$ 构成的簇，其质心为 $x+\\frac{1}{2}$，每个点的平方偏差为 $\\left(\\frac{1}{2}\\right)^{2}=\\frac{1}{4}$。因此，每次出现该簇的失真为 $\\frac{1}{4}$。由于簇概率为 $\\frac{2}{4}$，每个簇对总失真 $D$ 的贡献为 $\\frac{2}{4}\\cdot\\frac{1}{4}=\\frac{1}{8}$。对于两个这样的簇，总失真为\n$$\nD=\\frac{1}{8}+\\frac{1}{8}=\\frac{1}{4}.\n$$\n- 簇的概率分别为 $\\frac{1}{2}$ 和 $\\frac{1}{2}$，因此 $H(\\hat{X})=1$。由于映射是确定性的，$I(X;\\hat{X})=H(\\hat{X})=1$。因此得到点 $\\left(D,R\\right)=\\left(\\frac{1}{4},1\\right)$。\n- 任何其他的双簇划分（例如，$\\{1,2,3\\}$ vs. $\\{4\\}$ 或非相邻配对）都会产生更大的失真，因此 $\\left(\\frac{1}{4},1\\right)$ 是最优的双簇点。\n\n3) 三簇映射。\n- 最优划分是合并一对相邻点，并将另外两个点作为单例，例如 $\\{1,2\\}$、$\\{3\\}$、$\\{4\\}$（或任何对称的变体）。合并的对如上所述对 $D$ 的贡献为 $\\frac{1}{8}$；单例的贡献为 0。因此\n$$\nD=\\frac{1}{8}.\n$$\n- 簇的概率为 $\\frac{1}{2},\\frac{1}{4},\\frac{1}{4}$，因此\n$$\nI(X;\\hat{X})=H(\\hat{X})=-\\frac{1}{2}\\log_{2}\\left(\\frac{1}{2}\\right)-2\\cdot\\frac{1}{4}\\log_{2}\\left(\\frac{1}{4}\\right)=\\frac{1}{2}+1=\\frac{3}{2}.\n$$\n因此得到点 $\\left(D,R\\right)=\\left(\\frac{1}{8},\\frac{3}{2}\\right)$。\n\n4) 四簇映射（无损再现）。\n- 质心位于信源点的恒等映射得到 $D=0$ 和 $R=H(X)=\\log_{2}4=2$。因此得到点 $\\left(D,R\\right)=\\left(0,2\\right)$。\n\n通过时分复用进行凸化：\n- 可实现点包括 $\\left(\\frac{5}{4},0\\right)$, $\\left(\\frac{1}{4},1\\right)$, $\\left(\\frac{1}{8},\\frac{3}{2}\\right)$ 和 $\\left(0,2\\right)$，并且通过时分复用，还包括连接这些点的所有线段上的点。\n- 计算这些点之间的斜率：\n  - 在 $\\left(0,2\\right)$ 和 $\\left(\\frac{1}{4},1\\right)$ 之间：斜率为 $\\frac{1-2}{\\frac{1}{4}-0}=-4$；中间点 $\\left(\\frac{1}{8},\\frac{3}{2}\\right)$ 恰好在这条线上，因此它不构成新的线段。\n  - 在 $\\left(\\frac{1}{4},1\\right)$ 和 $\\left(\\frac{5}{4},0\\right)$ 之间：斜率为 $\\frac{0-1}{\\frac{5}{4}-\\frac{1}{4}}=-1$。\n\n因此，下凸包是具有两段的分段线性函数：\n- 对于 $0\\le D\\le\\frac{1}{4}$，通过 $\\left(0,2\\right)$ 和 $\\left(\\frac{1}{4},1\\right)$ 的直线为：\n$$\nR(D)=2-4D.\n$$\n- 对于 $\\frac{1}{4}\\le D\\le\\frac{5}{4}$，通过 $\\left(\\frac{1}{4},1\\right)$ 和 $\\left(\\frac{5}{4},0\\right)$ 的直线为：\n$$\nR(D)=\\frac{5}{4}-D.\n$$\n- 对于 $D\\ge\\frac{5}{4}$，可以使用恒定再现码实现 $R(D)=0$。\n\n因此，以比特/符号为单位，\n$$\nR(D)=\n\\begin{cases}\n2-4D,  0\\le D\\le \\frac{1}{4},\\\\\n\\frac{5}{4}-D,  \\frac{1}{4}\\le D\\le \\frac{5}{4},\\\\\n0,  D\\ge \\frac{5}{4}.\n\\end{cases}\n$$",
            "answer": "$$\\boxed{R(D)=\\begin{cases}\n2-4D,  0\\le D\\le \\frac{1}{4},\\\\\n\\frac{5}{4}-D,  \\frac{1}{4}\\le D\\le \\frac{5}{4},\\\\\n0,  D\\ge \\frac{5}{4}.\n\\end{cases}}$$"
        },
        {
            "introduction": "我们最后的练习将已学到的原理扩展到一个更高维度的空间。我们将把信源数据视为向量，并为一个均匀分布在超立方体上的信源，在汉明距离失真度量下，计算其率失真函数 。这个问题展示了率失真理论在分析结构化数据（例如机器学习中的特征向量）压缩极限方面的强大威力。",
            "id": "1652150",
            "problem": "考虑一个为机器学习应用生成特征向量的数字系统。每个向量是一个$k$比特的二进制字符串，系统以相等的概率产生所有$2^k$种可能的向量。为了高效存储，这些向量先被压缩然后解压，这个过程可能会引入错误。原始向量$X$与其重构版本$\\hat{X}$之间的失真由它们的汉明距离$d(X, \\hat{X})$来衡量，其定义为它们对应比特位上值不同的数量。\n\n该压缩过程的基本限制由率失真函数$R(D)$描述，它指定了在期望失真不超过值$D$的情况下，表示信源所需的每个向量的最小比特数。\n\n确定此信源的率失真函数$R(D)$。给出在失真范围$0 \\le D \\le k/2$内有效的$R(D)$的解析表达式。率应以每个向量的比特数为单位表示。你的最终表达式应使用$k$、$D$和以2为底的对数来表示。",
            "solution": "率失真函数$R(D)$定义为在所有满足期望失真小于或等于$D$的条件分布（测试信道）$p(\\hat{x}|x)$上，互信息$I(X; \\hat{X})$的最小值。\n$$R(D) = \\min_{p(\\hat{x}|x) : \\mathbb{E}[d(X, \\hat{X})] \\le D} I(X; \\hat{X})$$\n互信息可以表示为 $I(X; \\hat{X}) = H(X) - H(X|\\hat{X})$。\n\n信源$X$在$k$维超立方体的$2^k$个顶点上均匀分布，这些顶点由长度为$k$的二进制字符串表示。因此，信源的熵为：\n$$H(X) = \\log_2(|\\mathcal{X}|) = \\log_2(2^k) = k \\text{ 比特}$$\n所以，最小化$I(X; \\hat{X})$等价于最大化条件熵$H(X|\\hat{X})$。\n$$R(D) = k - \\max_{p(\\hat{x}|x) : \\mathbb{E}[d(X, \\hat{X})] \\le D} H(X|\\hat{X})$$\n\n由于信源分布（均匀分布）和失真度量（汉明距离，它对所有向量的比特翻转是不变的）的对称性，最优测试信道$p(\\hat{x}|x)$也将是对称的。这意味着$p(\\hat{x}|x)$仅取决于误差向量$E = X \\oplus \\hat{X}$（其中$\\oplus$是按位异或运算），并且其分布对比特位置的置换是不变的。\n\n我们通过假设信源向量$X$的每个比特以概率$p$独立地翻转，以生成重构向量$\\hat{X}$的相应比特，来对此对称信道建模。这等效于将$k$个并行的二进制对称信道（BSC）应用于$X$的各个比特。误差向量$E$的分量$E_i$将是独立同分布的伯努利随机变量，其中$P(E_i=1) = p$且$P(E_i=0) = 1-p$。\n\n对于给定的一对$(x, \\hat{x})$，失真为$d(x, \\hat{x}) = w_H(x \\oplus \\hat{x})$，其中$w_H$是汉明权重（1的数量）。期望失真是误差向量$E$的期望汉明权重。由于翻转的比特数服从二项分布$B(k, p)$，期望失真为：\n$$D(p) = \\mathbb{E}[w_H(E)] = k p$$\n我们关心的是重构向量，所以我们应该选择$p$以最小化错误。翻转概率$p > 0.5$是次优的，因为通过翻转逻辑，可以用相同的率实现更低的失真$k(1-p)$。因此，我们考虑范围$p \\in [0, 0.5]$。这对应于失真范围$D \\in [0, k/2]$。从$D=kp$，我们可以将参数$p$表示为$p = D/k$。\n\n现在我们计算此信道的率。我们需要最大化$H(X|\\hat{X})$。\n$$H(X|\\hat{X}) = H(X \\oplus \\hat{X} | \\hat{X}) = H(E | \\hat{X})$$\n在此信道模型中，误差向量$E$的生成独立于信源向量$X$。由于$\\hat{X}$是$X$和$E$的函数，误差$E$独立于$\\hat{X}$。\n因此，$H(E|\\hat{X}) = H(E)$。\n\n误差向量$E$的熵是其独立分量的熵之和：\n$$H(E) = \\sum_{i=1}^k H(E_i) = k H_b(p)$$\n其中$H_b(p)$是二元熵函数：\n$$H_b(p) = -p \\log_2(p) - (1-p) \\log_2(1-p)$$\n因此互信息为：\n$$I(X; \\hat{X}) = H(X) - H(X|\\hat{X}) = k - k H_b(p) = k(1 - H_b(p))$$\n这个表达式给出了率失真曲线上的一点$(D(p), R(p))$。为了找到$R(D)$，我们将$p=D/k$代入率的表达式中：\n$$R(D) = k \\left(1 - H_b\\left(\\frac{D}{k}\\right)\\right)$$\n$$R(D) = k \\left(1 - \\left(-\\frac{D}{k}\\log_2\\left(\\frac{D}{k}\\right) - \\left(1-\\frac{D}{k}\\right)\\log_2\\left(1-\\frac{D}{k}\\right)\\right)\\right)$$\n这在$p \\in [0, 0.5]$范围内有效，对应于$D \\in [0, k/2]$。让我们简化表达式：\n$$R(D) = k + k\\left(\\frac{D}{k}\\log_2\\left(\\frac{D}{k}\\right)\\right) + k\\left(\\frac{k-D}{k}\\log_2\\left(\\frac{k-D}{k}\\right)\\right)$$\n$$R(D) = k + D\\log_2\\left(\\frac{D}{k}\\right) + (k-D)\\log_2\\left(\\frac{k-D}{k}\\right)$$\n这也可以写成：\n$$R(D) = k + D\\log_2(D) - D\\log_2(k) + (k-D)\\log_2(k-D) - (k-D)\\log_2(k)$$\n$$R(D) = k - (D + k - D)\\log_2(k) + D\\log_2(D) + (k-D)\\log_2(k-D)$$\n$$R(D) = k - k\\log_2(k) + D\\log_2(D) + (k-D)\\log_2(k-D)$$\n题目要求表达式用$k$、$D$和以2为底的对数表示。首先推导出的形式更简洁且足够。\n\n对于$D > k/2$，率$R(D)$为0。这是因为无论输入如何，都可以通过发送一个常数向量（例如$\\hat{x}_0 = (0, ..., 0)$）来实现0率。在这种情况下，期望失真是$\\{0,1\\}^k$中向量的平均汉明权重，即$\\frac{1}{2^k} \\sum_{x} w_H(x) = \\frac{1}{2^k} (k 2^{k-1}) = k/2$。由于该策略以$R=0$的率实现了$D=k/2$的失真，任何大于$k/2$的失真$D$也可以用零率实现。\n\n问题特别要求在$0 \\le D \\le k/2$范围内的表达式。\n最终表达式：\n$$R(D) = k + D\\log_2\\left(\\frac{D}{k}\\right) + (k-D)\\log_2\\left(1-\\frac{D}{k}\\right)$$\n注意，$\\log_2\\left(1-\\frac{D}{k}\\right) = \\log_2\\left(\\frac{k-D}{k}\\right)$。\n所以，$R(D) = k + D\\log_2\\left(\\frac{D}{k}\\right) + (k-D)\\log_2\\left(\\frac{k-D}{k}\\right)$。",
            "answer": "$$\\boxed{k + D \\log_{2}\\left(\\frac{D}{k}\\right) + (k-D) \\log_{2}\\left(1-\\frac{D}{k}\\right)}$$"
        }
    ]
}