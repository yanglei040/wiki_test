{
    "hands_on_practices": [
        {
            "introduction": "二元对称信道（BSC）是信息论中的一个基本模型，理解其特性是掌握信道容量概念的第一步。这个练习探讨了其容量的一个看似违反直觉但却至关重要的对称特性。通过证明具有交叉概率 $p$ 的信道容量与具有 $1-p$ 的信道容量完全相同，你将深入理解信道容量衡量的是可靠通信的固有潜力，这并不直接等同于原始错误率的倒数 。",
            "id": "1604836",
            "problem": "二元对称信道（Binary Symmetric Channel, 简称BSC）是信息论中的一个基本模型。它描述了一个可以传输两种符号（通常表示为0和1）之一的通信信道。在传输过程中，输入比特可能会以一定的概率发生翻转，这个概率被称为交叉概率。\n\n令 BSC($p$) 表示一个交叉概率为 $p$ 的二元对称信道，其中 $p = P(\\text{output}=1 | \\text{input}=0) = P(\\text{output}=0 | \\text{input}=1)$。该信道的容量，记为 $C(p)$，表示信息能够可靠传输的最大速率（单位为比特/信道使用）。\n\n考虑两个这样的信道：一个的交叉概率为 $p$，另一个的交叉概率为 $1-p$。对于 $0 \\le p \\le 1$ 范围内的任意概率 $p$，以下哪个陈述正确描述了它们的容量 $C(p)$ 和 $C(1-p)$ 之间的关系？\n\nA. $C(p) = C(1-p)$\n\nB. $C(p) = 1 - C(1-p)$\n\nC. 当 $p \\in [0, 0.5)$ 时 $C(p) > C(1-p)$，当 $p \\in (0.5, 1]$ 时 $C(p) < C(1-p)$\n\nD. 对于任意 $p \\in [0, 1]$，$C(p)$ 总是大于或等于 $C(1-p)$\n\nE. 关系通常无法确定，因为容量取决于信源熵。",
            "solution": "设交叉概率为 $p$ 的二元对称信道记为 $\\text{BSC}(p)$。其容量 $C(p)$ 定义为在所有输入分布 $P_{X}$ 上的最大互信息：\n$$\nC(p) = \\max_{P_{X}} I(X;Y) = \\max_{P_{X}} \\big(H(Y) - H(Y|X)\\big).\n$$\n对于 $\\text{BSC}(p)$，给定任意输入比特的条件输出分布是一个以 $p$ 为错误事件参数的伯努利分布，因此条件熵独立于输入分布，等于二元熵：\n$$\nH(Y|X) = H_{2}(p), \\quad \\text{where } H_{2}(p) = -p \\log_{2}(p) - (1-p)\\log_{2}(1-p).\n$$\n令 $q = P(X=1)$。则输出概率为\n$$\nP(Y=1) = q(1-p) + (1-q)p = p + q(1-2p),\n$$\n所以\n$$\nH(Y) = H_{2}\\big(p + q(1-2p)\\big).\n$$\n在 $q \\in [0,1]$ 上最大化 $I(X;Y) = H(Y) - H_{2}(p)$ 等价于最大化 $H(Y)$，而 $H_{2}(\\cdot)$ 在其参数为 $\\frac{1}{2}$ 时取得最大值。选择 $q$ 使得 $p + q(1-2p) = \\frac{1}{2}$。当 $p \\neq \\frac{1}{2}$ 时，这得到 $q^{\\ast} = \\frac{\\frac{1}{2} - p}{1 - 2p} = \\frac{1}{2}$，而当 $p = \\frac{1}{2}$ 时，任何 $q$ 都会使 $P(Y=1) = \\frac{1}{2}$。因此，容量为\n$$\nC(p) = 1 - H_{2}(p).\n$$\n现在考虑 $\\text{BSC}(1-p)$。其容量为\n$$\nC(1-p) = 1 - H_{2}(1-p).\n$$\n利用二元熵的对称性，\n$$\nH_{2}(1-p) = - (1-p)\\log_{2}(1-p) - p \\log_{2}(p) = H_{2}(p),\n$$\n我们得到\n$$\nC(1-p) = 1 - H_{2}(1-p) = 1 - H_{2}(p) = C(p).\n$$\n因此，对于所有 $p \\in [0,1]$，两个容量相等，这对应于选项A。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在理解了BSC的理论特性之后，让我们来处理一个更具体的计算问题。这个场景涉及一个非对称信道，其中一些输入符号能够完美传输，而另一些则会引入噪声 。你的任务是通过找到最佳的输入概率分布，来最大化互信息，从而确定该信道的容量。这个练习让你直接动手实践信道容量的核心定义，即 $C = \\max_{p(x)} I(X;Y)$。",
            "id": "1617016",
            "problem": "一个通信系统设计有一组来自字母表 $\\mathcal{X} = \\{A, B, C\\}$ 的三个可能的输入符号，和一组来自字母表 $\\mathcal{Y} = \\{A, B\\}$ 的两个可能的输出符号。这个离散无记忆信道的行为由以下条件概率定义：\n-   输入 $A$ 总是被接收为输出 $A$。\n-   输入 $B$ 总是被接收为输出 $B$。\n-   输入 $C$ 会产生一个随机输出，该输出为 $A$ 或 $B$ 的概率相等。\n\n信道容量定义为输入 $X$ 和输出 $Y$ 之间的最大可能互信息，其中最大化是在所有可能的输入概率分布 $P(X)$ 上进行的。\n\n计算该信道的容量。请用比特（bits）为单位，将最终答案表示为单个精确的数值。所有对数都应解释为以2为底。",
            "solution": "设输入分布为 $P(X=A)=a$、$P(X=B)=b$ 和 $P(X=C)=c$，其中 $a,b,c\\geq 0$ 且 $a+b+c=1$。根据信道传输规则，\n- $P(Y=A\\mid X=A)=1$ 且 $P(Y=B\\mid X=A)=0$，\n- $P(Y=A\\mid X=B)=0$ 且 $P(Y=B\\mid X=B)=1$，\n- $P(Y=A\\mid X=C)=\\frac{1}{2}$ 且 $P(Y=B\\mid X=C)=\\frac{1}{2}$。\n\n因此输出分布为\n$$\nP(Y=A)=a+\\frac{c}{2},\\qquad P(Y=B)=b+\\frac{c}{2}.\n$$\n输出熵（以2为底的对数）是二元熵\n$$\nH(Y)= -\\left(a+\\frac{c}{2}\\right)\\log_{2}\\left(a+\\frac{c}{2}\\right) - \\left(b+\\frac{c}{2}\\right)\\log_{2}\\left(b+\\frac{c}{2}\\right).\n$$\n条件熵为\n$$\nH(Y\\mid X)= a\\cdot 0 + b\\cdot 0 + c\\cdot 1 = c,\n$$\n因为当给定 $X=A$ 或 $X=B$ 时，$Y$ 是确定的，而当给定 $X=C$ 时，$Y$ 是等概率的。因此互信息为\n$$\nI(X;Y)=H(Y)-H(Y\\mid X)= h_{2}\\left(a+\\frac{c}{2}\\right)-c,\n$$\n其中 $h_{2}(u)=-u\\log_{2}u-(1-u)\\log_{2}(1-u)$。\n\n对于任何固定的 $c\\in[0,1]$，$h_{2}(u)$ 在 $u=\\frac{1}{2}$ 时取得最大值。约束集允许通过选择 $a=\\frac{1}{2}-\\frac{c}{2}$ 且因此 $b=1-a-c=\\frac{1}{2}-\\frac{c}{2}$，来使 $u=a+\\frac{c}{2}$ 等于 $\\frac{1}{2}$，这对于所有 $c\\in[0,1]$ 都是非负的。因此，对于固定的 $c$，\n$$\n\\max_{a,b} I(X;Y)= 1 - c.\n$$\n在 $c\\in[0,1]$ 上进行最大化，得到 $c^{\\star}=0$ 并且\n$$\n\\max_{a,b,c} I(X;Y)= 1.\n$$\n这达到了总的上界 $I(X;Y)\\leq H(Y)\\leq \\log_{2}|\\mathcal{Y}|=\\log_{2}2=1$，证实了其最优性。一种达到该容量的分布是 $a=b=\\frac{1}{2}$ 和 $c=0$，即从不使用 $C$。\n\n因此，信道容量为 $1$ 比特。",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "这个练习引入了一种结构独特的信道：一个确定性加法器信道。在这里，信道输出是两个独立输入比特的算术和，这意味着从输入到输出的映射是完全确定的，没有随机噪声。然而，你会发现其容量仍然是有限的 。通过解决这个问题，你将探索一个更深刻的观点：信道容量不仅受随机性的影响，也受到信道结构（例如，多个不同输入映射到同一输出）和对输入信号施加的约束（例如，输入独立性）的根本限制。",
            "id": "1648936",
            "problem": "一个简化的数字通信系统被设计为使用两个并行、独立的二进制信源来传输信息。令随机变量 $X_1$ 和 $X_2$ 分别表示从信源1和信源2发送的比特，其中 $X_i \\in \\{0, 1\\}$。该系统的一个基本约束是输入 $X_1$ 和 $X_2$ 总是统计独立的。\n\n在接收端，一个简单的加法器电路将这两个信号组合起来，产生一个单一的输出信号 $Y$，它是输入比特的算术和：$Y = X_1 + X_2$。可能的输入对集合为 $\\mathcal{X} = \\{(0,0), (0,1), (1,0), (1,1)\\}$，可能的输出集合为 $\\mathcal{Y} = \\{0, 1, 2\\}$。\n\n该系统的操作员可以选择独立信源的统计特性。令 $p_1 = P(X_1=1)$ 和 $p_2 = P(X_2=1)$ 分别为每个信源发送“1”的概率。该信道的容量定义为在 $[0, 1]$ 范围内所有可能的 $p_1$ 和 $p_2$ 选择下，互信息 $I((X_1, X_2); Y)$ 的最大值。\n\n计算该信道的容量。请用一个实数表示最终答案，单位为比特/信道使用。",
            "solution": "令信道的输入为随机变量 $X = (X_1, X_2)$，输出为 $Y = X_1 + X_2$。信道容量 $C$ 定义为在所有可能的输入分布下，互信息 $I(X; Y)$ 的最大值。\n\n$$C = \\max_{p(x)} I(X; Y)$$\n\n互信息由 $I(X; Y) = H(Y) - H(Y|X)$ 给出。\n输出 $Y$ 是输入 $X$ 的确定性函数。具体来说，如果我们知道输入对 $(X_1, X_2)$，则输出 $Y = X_1 + X_2$ 是完全确定的。这意味着在给定输入的情况下，输出的条件熵 $H(Y|X)$ 为零。\n$$H(Y|X) = \\sum_{x \\in \\mathcal{X}} p(x) H(Y|X=x) = \\sum_{x \\in \\mathcal{X}} p(x) \\cdot 0 = 0$$\n因此，互信息简化为输出的熵：\n$$I(X; Y) = H(Y)$$\n因此，容量是输出可能的最大熵，其中最大化是在允许的输入分布集合上进行的。\n$$C = \\max_{p(x)} H(Y)$$\n问题指定输入比特 $X_1$ 和 $X_2$ 是独立的。令 $P(X_1=1) = p_1$ 和 $P(X_2=1) = p_2$。那么输入对的分布为：\n$P(X=(0,0)) = (1-p_1)(1-p_2)$\n$P(X=(0,1)) = (1-p_1)p_2$\n$P(X=(1,0)) = p_1(1-p_2)$\n$P(X=(1,1)) = p_1 p_2$\n\n现在，我们确定输出 $Y$ 的分布。$Y$ 的可能值为 $0, 1, 2$。\n$P(Y=0) = P(X=(0,0)) = (1-p_1)(1-p_2)$\n$P(Y=1) = P(X=(0,1)) + P(X=(1,0)) = (1-p_1)p_2 + p_1(1-p_2) = p_1 + p_2 - 2p_1p_2$\n$P(Y=2) = P(X=(1,1)) = p_1 p_2$\n\n输出 $Y$ 的熵是 $p_1$ 和 $p_2$ 的函数：\n$$H(Y) = -P(Y=0)\\log_2(P(Y=0)) - P(Y=1)\\log_2(P(Y=1)) - P(Y=2)\\log_2(P(Y=2))$$\n我们需要对 $p_1, p_2 \\in [0, 1]$ 最大化此函数 $H(Y; p_1, p_2)$。\n\n问题的结构相对于 $X_1$ 和 $X_2$ 是对称的。交换 $p_1$ 和 $p_2$ 保持概率 $P(Y=0)$、$P(Y=1)$ 和 $P(Y=2)$ 不变。这表明 $H(Y)$ 的最大值将在 $p_1 = p_2$ 时出现。我们设 $p_1 = p_2 = p$。\n\n当 $p_1=p_2=p$ 时，输出分布变为：\n$P(Y=0) = (1-p)(1-p) = (1-p)^2$\n$P(Y=1) = p(1-p) + (1-p)p = 2p(1-p)$\n$P(Y=2) = p \\cdot p = p^2$\n这是两次独立伯努利试验之和的二项分布，即 $Y \\sim \\text{Binomial}(2, p)$。\n现在熵是单个变量 $p$ 的函数：\n$$H(Y; p) = - (1-p)^2 \\log_2((1-p)^2) - 2p(1-p) \\log_2(2p(1-p)) - p^2 \\log_2(p^2)$$\n为了找到使该熵最大化的 $p$ 值，我们可以对 $p$ 求导并令其为零。为方便起见，使用自然对数 $\\ln$（因为 $\\log_2(x) = \\ln(x)/\\ln(2)$），我们有：\n$\\frac{d}{dp} H(Y; p) \\propto \\frac{d}{dp} \\left[ -(1-p)^2 \\ln((1-p)^2) - 2p(1-p) \\ln(2p(1-p)) - p^2 \\ln(p^2) \\right]$\n对于二项分布 $\\text{Binomial}(n,p)$ 的熵，一个已知结果是它在 $p=1/2$ 时最大化。让我们通过将导数设为零来验证 $n=2$ 的情况。导数正比于：\n$$\\frac{d H}{dp} \\propto \\ln\\left(\\frac{1-p}{p}\\right) - (1-2p)\\ln(2)$$\n将导数设为零：\n$$\\ln\\left(\\frac{1-p}{p}\\right) = (1-2p)\\ln(2) = \\ln(2^{1-2p})$$\n$$\\frac{1-p}{p} = 2^{1-2p}$$\n通过观察，$p=1/2$ 是一个解：\n左边 (LHS): $\\frac{1-1/2}{1/2} = \\frac{1/2}{1/2} = 1$。\n右边 (RHS): $2^{1-2(1/2)} = 2^{1-1} = 2^0 = 1$。\n因此，熵在 $p=1/2$ 时最大化。这对应于选择 $p_1=p_2=1/2$。\n\n当 $p_1=p_2=1/2$ 时，输入分布在四个可能的对上是均匀的：对于所有 $(x_1,x_2) \\in \\mathcal{X}$，$P(X=(x_1,x_2)) = 1/4$。相应的输出分布是：\n$P(Y=0) = (1-1/2)^2 = 1/4$\n$P(Y=1) = 2(1/2)(1-1/2) = 1/2$\n$P(Y=2) = (1/2)^2 = 1/4$\n\n最大熵 $H(Y)$ 是用这个最优分布计算的：\n$$C = H(Y) = -\\left( \\frac{1}{4} \\log_2\\left(\\frac{1}{4}\\right) + \\frac{1}{2} \\log_2\\left(\\frac{1}{2}\\right) + \\frac{1}{4} \\log_2\\left(\\frac{1}{4}\\right) \\right)$$\n$$C = -\\left( \\frac{1}{4}(-2) + \\frac{1}{2}(-1) + \\frac{1}{4}(-2) \\right)$$\n$$C = -\\left( -\\frac{1}{2} - \\frac{1}{2} - \\frac{1}{2} \\right)$$\n$$C = \\frac{3}{2} = 1.5$$\n该信道的容量是 1.5 比特/信道使用。",
            "answer": "$$\\boxed{1.5}$$"
        }
    ]
}