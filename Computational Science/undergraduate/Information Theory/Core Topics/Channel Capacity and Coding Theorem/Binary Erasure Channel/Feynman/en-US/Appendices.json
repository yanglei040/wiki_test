{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp the concept of channel capacity, it's often helpful to explore extreme scenarios. This first exercise examines a Binary Erasure Channel (BEC) under a catastrophic failure condition where every transmitted bit is erased. By calculating the capacity in this limiting case , you will develop a clear, intuitive understanding of what a capacity of zero truly signifies: a complete inability to transmit any information reliably.",
            "id": "1604512",
            "problem": "A deep-space probe uses a binary communication system to transmit scientific data back to Earth. The communication channel can be modeled as a Binary Erasure Channel (BEC). In a BEC, a transmitted bit $X$, which can be either 0 or 1, is received as an output $Y$. With a certain probability $p$, called the erasure probability, the transmitted bit is lost and the receiver gets an erasure symbol, denoted by '?'. With probability $1-p$, the bit is transmitted correctly. Thus, the output alphabet is $Y \\in \\{0, 1, ?\\}$.\n\nFollowing a severe solar flare, the probe's transmitter is catastrophically damaged. Ground control observes that every single bit transmitted from the probe is now received on Earth as an erasure symbol '?'. This situation corresponds to a specific value for the erasure probability $p$.\n\nCalculate the channel capacity of this damaged communication link. The channel capacity should be expressed in bits per channel use.",
            "solution": "A Binary Erasure Channel (BEC) with erasure probability $p$ produces output $Y$ such that, with probability $1-p$, $Y=X$ and, with probability $p$, $Y=?$, which reveals no information about $X$. The channel capacity is defined as\n$$\nC=\\max_{P_{X}} I(X;Y).\n$$\nFor any input distribution $P_{X}$, the mutual information is\n$$\nI(X;Y)=H(X)-H(X|Y).\n$$\nWe compute $H(X|Y)$ by conditioning on the values of $Y$:\n- If $Y\\in\\{0,1\\}$ (which occurs with probability $1-p$), then $X$ is known exactly, so $H(X|Y\\in\\{0,1\\})=0$.\n- If $Y=?$ (which occurs with probability $p$), the erasure provides no information, so $H(X|Y=?)=H(X)$.\n\nTherefore,\n$$\nH(X|Y)=p\\,H(X)+(1-p)\\cdot 0=p\\,H(X),\n$$\nand hence\n$$\nI(X;Y)=H(X)-p\\,H(X)=(1-p)\\,H(X).\n$$\nMaximizing over $P_{X}$, the binary entropy $H(X)$ is maximized at $1$ bit, so the capacity is\n$$\nC=1-p \\text{ bits per channel use}.\n$$\nIn the damaged scenario, every received symbol is an erasure, which implies $p=1$. Substituting $p=1$ yields\n$$\nC=1-1=0.\n$$\nThus, the channel capacity is zero bits per channel use.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "While a channel with $100\\%$ erasures is unusable, most real-world channels are only partially impaired. This practice explores a fundamental technique for improving reliability: repetition coding. You will analyze a simple $(2,1)$ repetition code over a BEC with a given erasure probability , allowing you to directly quantify the improvement in successful communication and see the power of even the most basic error correction strategy.",
            "id": "1604530",
            "problem": "A simple digital communication system transmits binary data over a noisy channel. The channel is modeled as a Binary Erasure Channel (BEC), where each transmitted bit has a probability $\\epsilon$ of being erased and a probability $1-\\epsilon$ of being received correctly. An erased bit is identified as lost information by the receiver; the channel never flips a bit's value.\n\nTo improve reliability, a $(2,1)$ repetition code is used. To send a single message bit, it is repeated twice: a message bit of '0' is encoded and sent as the codeword '00', and a message bit of '1' is encoded and sent as '11'.\n\nThe receiver's decoder operates as follows:\n- Decoding is **successful** if at least one of the two bits in the codeword is received correctly. In this case, the original message bit can be determined with certainty.\n- Decoding is a **failure** if both bits in the codeword are erased. In this case, the original message bit cannot be recovered.\n\nLet the channel's erasure probability be $\\epsilon = 0.15$. Calculate the probability of successful decoding, $P(\\text{success})$, and the probability of a decoding failure, $P(\\text{failure})$.\n\nPresent your answer as a row matrix containing the two decimal probabilities, $[P(\\text{success}), P(\\text{failure})]$, in that order.",
            "solution": "A Binary Erasure Channel with erasure probability $\\epsilon$ independently erases each transmitted bit with probability $\\epsilon$ and delivers it correctly with probability $1-\\epsilon$. For the $(2,1)$ repetition code, two independent channel uses transmit identical bits.\n\nLet $E_{1}$ and $E_{2}$ be the events that the first and second transmitted bits are erased. By independence of channel uses,\n$$\nP(E_{1}\\cap E_{2})=\\epsilon^{2}.\n$$\nDecoding is a success if at least one bit is received (i.e., not both are erased), so by the complement rule,\n$$\nP(\\text{success})=1-P(E_{1}\\cap E_{2})=1-\\epsilon^{2}.\n$$\nDecoding fails only if both bits are erased:\n$$\nP(\\text{failure})=P(E_{1}\\cap E_{2})=\\epsilon^{2}.\n$$\nSubstituting $\\epsilon=0.15$,\n$$\nP(\\text{failure})=(0.15)^{2}=0.0225,\\qquad P(\\text{success})=1-0.0225=0.9775.\n$$\nTherefore, the requested row matrix is $[P(\\text{success}),\\,P(\\text{failure})]=[0.9775,\\,0.0225]$.",
            "answer": "$$\\boxed{\\begin{pmatrix}0.9775 & 0.0225\\end{pmatrix}}$$"
        },
        {
            "introduction": "How does the information loss from an erasure compare to the uncertainty created by a bit-flip? This problem connects the BEC to another fundamental model, the Binary Symmetric Channel (BSC), where bits are flipped with a certain probability. By finding the BEC erasure probability $p$ that results in the same channel capacity as a BSC with a given crossover probability $q$ , you will gain a deeper appreciation for channel capacity as a universal measure of a channel's information-carrying potential, independent of the specific noise mechanism.",
            "id": "1604533",
            "problem": "In digital communication, two fundamental channel models are the Binary Symmetric Channel (BSC) and the Binary Erasure Channel (BEC).\n\nA Binary Symmetric Channel is characterized by a binary input alphabet $\\mathcal{X} = \\{0, 1\\}$, a binary output alphabet $\\mathcal{Y} = \\{0, 1\\}$, and a single parameter, the crossover probability $q$. A bit sent through a BSC is received correctly with probability $1-q$ and is \"flipped\" to the opposite bit with probability $q$.\n\nA Binary Erasure Channel is characterized by a binary input alphabet $\\mathcal{X} = \\{0, 1\\}$, an output alphabet $\\mathcal{Y} = \\{0, e, 1\\}$, and a single parameter, the erasure probability $p$. When a bit is sent, it is received correctly with probability $1-p$, but is erased (represented by the symbol 'e') with probability $p$. An erased bit provides no information about which bit was sent.\n\nConsider a BSC with a crossover probability $q = 0.1$. Determine the erasure probability $p$ for a BEC such that the channel capacity of the BEC is exactly equal to the channel capacity of this BSC.\n\nReport your value for $p$ as a real number rounded to four significant figures.",
            "solution": "The capacity of a Binary Symmetric Channel (BSC) with crossover probability $q$ is given by\n$$\nC_{\\text{BSC}} = 1 - H_{2}(q),\n$$\nwhere the binary entropy function is\n$$\nH_{2}(x) = -x \\log_{2}(x) - (1-x) \\log_{2}(1-x).\n$$\nThe capacity of a Binary Erasure Channel (BEC) with erasure probability $p$ is\n$$\nC_{\\text{BEC}} = 1 - p.\n$$\nTo make the capacities equal, set $C_{\\text{BEC}} = C_{\\text{BSC}}$:\n$$\n1 - p = 1 - H_{2}(q) \\;\\;\\Rightarrow\\;\\; p = H_{2}(q).\n$$\nWith $q = 0.1$, compute\n$$\np = H_{2}(0.1) = -0.1 \\log_{2}(0.1) - 0.9 \\log_{2}(0.9).\n$$\nUsing $\\log_{2}(x) = \\frac{\\ln(x)}{\\ln(2)}$, evaluate numerically:\n$$\n\\log_{2}(0.1) = \\frac{\\ln(0.1)}{\\ln(2)} \\approx -3.3219280949,\\quad\n\\log_{2}(0.9) = \\frac{\\ln(0.9)}{\\ln(2)} \\approx -0.1520030934.\n$$\nThus,\n$$\np \\approx -0.1(-3.3219280949) - 0.9(-0.1520030934) \\approx 0.3321928095 + 0.1368027841 = 0.4689955936.\n$$\nRounding to four significant figures gives $p = 0.4690$.",
            "answer": "$$\\boxed{0.4690}$$"
        }
    ]
}