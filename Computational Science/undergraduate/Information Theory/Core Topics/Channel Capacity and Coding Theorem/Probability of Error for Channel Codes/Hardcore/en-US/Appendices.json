{
    "hands_on_practices": [
        {
            "introduction": "To begin our practical exploration, we will start with a fundamental skill: calculating the probability of a specific error pattern. This exercise involves a simple repetition code transmitted over a Binary Symmetric Channel (BSC), a standard model for bit-flip errors. By determining the probability of exactly two errors in a four-bit codeword, we can directly apply the binomial distribution and begin to appreciate how decoders might struggle with ambiguous cases where no clear majority exists. ",
            "id": "1648496",
            "problem": "A simple communication system employs a 4-repetition code to enhance reliability. To send a '0', the codeword '0000' is transmitted, and to send a '1', the codeword '1111' is transmitted. The transmission occurs over a Binary Symmetric Channel (BSC), a memoryless channel where each bit is independently flipped with a constant probability $p$. Assuming a single codeword corresponding to one bit of information is transmitted, determine the probability that exactly two of the four bits in the codeword are received incorrectly. Express your answer as a symbolic expression in terms of $p$.",
            "solution": "Let the length of the repetition code be $n=4$. The channel is a Binary Symmetric Channel (BSC), which means that each of the $n$ bits in the transmitted codeword is handled independently. For each bit, there are two possible outcomes: it is received correctly, or it is received incorrectly (flipped).\n\nThe problem states that the probability of a single bit being flipped (an error) is $p$. Therefore, the probability of a single bit being transmitted correctly is $1-p$.\n\nWe are interested in the event where exactly two out of the four transmitted bits are incorrect. This is a classic example of a sequence of independent Bernoulli trials. Let a \"success\" be the event that a bit is received in error. We are looking for the probability of obtaining exactly $k=2$ successes in $n=4$ trials.\n\nThe probability of such an event is given by the binomial probability mass function:\n$$P(X=k) = \\binom{n}{k} p^{k} (1-p)^{n-k}$$\nwhere $X$ is the random variable representing the number of errors.\n\nIn our specific case, we have:\n- The number of trials (bits in the codeword), $n=4$.\n- The number of desired successes (errors), $k=2$.\n- The probability of success (a single bit error), $p$.\n- The probability of failure (a single bit transmitted correctly), $1-p$.\n\nSubstituting these values into the binomial formula, we get:\n$$P(X=2) = \\binom{4}{2} p^{2} (1-p)^{4-2}$$\n$$P(X=2) = \\binom{4}{2} p^{2} (1-p)^{2}$$\n\nNow, we need to calculate the binomial coefficient $\\binom{4}{2}$:\n$$\\binom{4}{2} = \\frac{4!}{2!(4-2)!} = \\frac{4!}{2!2!} = \\frac{4 \\times 3 \\times 2 \\times 1}{(2 \\times 1)(2 \\times 1)} = \\frac{24}{4} = 6$$\n\nThis coefficient represents the number of ways to choose which 2 of the 4 bits are in error. For example, the errors could be in positions (1,2), (1,3), (1,4), (2,3), (2,4), or (3,4).\n\nSubstituting the value of the binomial coefficient back into our probability expression, we obtain the final answer:\n$$P(X=2) = 6 p^{2} (1-p)^{2}$$",
            "answer": "$$\\boxed{6p^{2}(1-p)^{2}}$$"
        },
        {
            "introduction": "Next, we shift our focus from bit-flip errors to a different kind of channel impairment: erasures. This problem introduces the Binary Erasure Channel (BEC), where bits are not flipped but are instead lost or \"erased.\" You will analyze how a repetition code performs in this scenario, discovering that a word error only occurs under the single, catastrophic condition where all transmitted bits are lost, providing a clear contrast to the error mechanisms of a BSC. ",
            "id": "1648516",
            "problem": "A simple communication system is designed to transmit a single bit, either a 0 or a 1, across a noisy channel. To improve reliability, a (5,1) repetition code is used. This means that if the original bit is a 0, the codeword '00000' is transmitted, and if the original bit is a 1, the codeword '11111' is transmitted.\n\nThe transmission occurs over a Binary Erasure Channel (BEC). For each bit sent through the BEC, there are two possible outcomes:\n1.  The bit is correctly received with probability $1-\\epsilon$.\n2.  The bit is erased with probability $\\epsilon$, where $0  \\epsilon  1$. An erased bit is received as an unknown symbol, and the decoder knows that an erasure has occurred. The channel never flips a bit (e.g., a '0' is never received as a '1').\n\nThe decoder at the receiving end uses a majority-logic rule on the non-erased bits. If at least one bit of the 5-bit codeword is received correctly (i.e., not erased), the decoder can determine the original bit. A word error occurs if the decoder cannot uniquely determine the original bit from the received 5-symbol word.\n\nAssuming the outcomes for the five bits in a codeword are independent events, determine the probability of a word error. Express your answer as a closed-form analytic expression in terms of the erasure probability $\\epsilon$.",
            "solution": "Let each transmitted bit pass through a Binary Erasure Channel with erasure probability $\\epsilon$, independently across the $5$ positions of the $(5,1)$ repetition code.\n\nBecause the BEC never flips bits, any received (non-erased) bit must equal the transmitted bit. Therefore, under a majority-logic rule on the non-erased bits, the decoder can correctly determine the original bit as soon as at least one of the five bits is received (i.e., not erased). Hence, a word error occurs if and only if all five transmitted bits are erased.\n\nDefine $E_{i}$ as the event that the $i$-th bit is erased, with $\\Pr(E_{i})=\\epsilon$, and assume independence across $i=1,\\dots,5$. The word error event is\n$$\nW=\\bigcap_{i=1}^{5} E_{i}.\n$$\nBy independence,\n$$\n\\Pr(W)=\\prod_{i=1}^{5} \\Pr(E_{i})=\\epsilon^{5}.\n$$\nEquivalently, if $K$ is the number of erasures, then $K\\sim\\text{Binomial}(5,\\epsilon)$ and\n$$\n\\Pr(\\text{word error})=\\Pr(K=5)=\\binom{5}{5}\\epsilon^{5}(1-\\epsilon)^{0}=\\epsilon^{5}.\n$$\nThus, the probability of a word error is $\\epsilon^{5}$.",
            "answer": "$$\\boxed{\\epsilon^{5}}$$"
        },
        {
            "introduction": "This final practice problem serves as a crucial lesson on the interplay between a code and its decoder. We examine a scenario where the decoding strategy for ambiguous received words is simply a random guess. The surprising outcome demonstrates that a channel code's theoretical benefits can be completely nullified by a poor decoding algorithm, underscoring the principle that effective error correction is a system-level achievement. ",
            "id": "1648505",
            "problem": "A digital communication system is designed to transmit a single bit from a source. The source generates bits '0' and '1' with equal probability. To improve reliability, a simple (2,1) repetition code is employed. In this scheme, a source bit '0' is encoded into the codeword '00', and a source bit '1' is encoded into the codeword '11'.\n\nThe two-bit codeword is transmitted over a Binary Symmetric Channel (BSC). A BSC is a channel model where each transmitted bit is independently flipped (i.e., a '0' becomes a '1' or a '1' becomes a '0') with a fixed crossover probability $p$, where $0  p  1$.\n\nAt the receiver, a decoder interprets the received two-bit word. The decoding logic is defined as follows:\n- If '00' is received, it is decoded as the source bit '0'.\n- If '11' is received, it is decoded as the source bit '1'.\n- If either '01' or '10' is received, the situation is ambiguous. The decoder resolves this ambiguity by making a random decision: it electronically simulates the flip of a fair coin. If the outcome is 'heads', the word is decoded as '0'; if the outcome is 'tails', it is decoded as '1'.\n\nYour task is to calculate the overall probability of a word error, $P_e$. A word error is defined as the event where the decoded bit is not the same as the original source bit. Express your answer as a function of the crossover probability $p$.",
            "solution": "Let $X$ be the random variable representing the source bit, and let $\\hat{X}$ be the random variable representing the decoded bit. The problem asks for the overall probability of error, $P_e = P(\\hat{X} \\neq X)$.\n\nWe can compute this using the law of total probability, by conditioning on the value of the source bit $X$.\n$$P_e = P(\\hat{X} \\neq X | X=0)P(X=0) + P(\\hat{X} \\neq X | X=1)P(X=1)$$\nThe problem states that the source bits are equally likely, so $P(X=0) = P(X=1) = \\frac{1}{2}$. The expression for the error probability becomes:\n$$P_e = \\frac{1}{2} P(\\hat{X} = 1 | X=0) + \\frac{1}{2} P(\\hat{X} = 0 | X=1)$$\nWe will now calculate the two conditional probabilities separately.\n\n**Part 1: Calculate $P(\\hat{X} = 1 | X=0)$**\n\nIf the source bit is $X=0$, the transmitted codeword is '00'. Let the received two-bit word be $Y_1Y_2$. Each bit is flipped independently by the BSC with probability $p$. An error occurs in this case if the decoded bit is $\\hat{X}=1$. Let's analyze the outcomes at the receiver.\n\nThe probabilities of receiving each possible two-bit word are:\n- $P(Y_1Y_2 = 00 | \\text{sent 00}) = (1-p)(1-p) = (1-p)^2$. If '00' is received, it is decoded as '0'. This is not an error.\n- $P(Y_1Y_2 = 11 | \\text{sent 00}) = p \\cdot p = p^2$. If '11' is received, it is decoded as '1'. This is an error.\n- $P(Y_1Y_2 = 01 | \\text{sent 00}) = (1-p)p$.\n- $P(Y_1Y_2 = 10 | \\text{sent 00}) = p(1-p)$.\n\nIf either '01' or '10' is received, the decoder flips a fair coin. An error ($\\hat{X}=1$) occurs if the coin flip results in 'tails'. The probability of 'tails' is $\\frac{1}{2}$.\nThe probability of receiving an ambiguous word ('01' or '10') is $p(1-p) + (1-p)p = 2p(1-p)$.\nThe probability of an error occurring through this path is the probability of receiving an ambiguous word multiplied by the probability that the coin flip leads to an error:\n$P(\\text{error and ambiguous word}) = P(\\text{receive '01' or '10'}) \\times P(\\text{decode '1'}) = [2p(1-p)] \\times \\frac{1}{2} = p(1-p)$.\n\nThe total probability of error, given $X=0$, is the sum of probabilities of all disjoint error events:\n$$P(\\hat{X} = 1 | X=0) = P(\\text{receive '11'}) + P(\\text{error and ambiguous word})$$\n$$P(\\hat{X} = 1 | X=0) = p^2 + p(1-p) = p^2 + p - p^2 = p$$\n\n**Part 2: Calculate $P(\\hat{X} = 0 | X=1)$**\n\nIf the source bit is $X=1$, the transmitted codeword is '11'. An error occurs if the decoded bit is $\\hat{X}=0$. The logic is symmetric to Part 1.\n\nThe probabilities of receiving each possible two-bit word are:\n- $P(Y_1Y_2 = 11 | \\text{sent 11}) = (1-p)^2$. If '11' is received, it is decoded as '1'. This is not an error.\n- $P(Y_1Y_2 = 00 | \\text{sent 11}) = p^2$. If '00' is received, it is decoded as '0'. This is an error.\n- $P(Y_1Y_2 = 01 \\text{ or } 10 | \\text{sent 11}) = p(1-p) + (1-p)p = 2p(1-p)$.\n\nIf '01' or '10' is received, the decoder flips a fair coin. An error ($\\hat{X}=0$) occurs if the coin flip results in 'heads'. The probability of 'heads' is $\\frac{1}{2}$.\nThe probability of an error occurring through this path is:\n$P(\\text{error and ambiguous word}) = P(\\text{receive '01' or '10'}) \\times P(\\text{decode '0'}) = [2p(1-p)] \\times \\frac{1}{2} = p(1-p)$.\n\nThe total probability of error, given $X=1$, is the sum of probabilities of all disjoint error events:\n$$P(\\hat{X} = 0 | X=1) = P(\\text{receive '00'}) + P(\\text{error and ambiguous word})$$\n$$P(\\hat{X} = 0 | X=1) = p^2 + p(1-p) = p^2 + p - p^2 = p$$\n\n**Part 3: Combine to find the overall error probability $P_e$**\n\nNow we substitute the conditional probabilities back into our main formula:\n$$P_e = \\frac{1}{2} P(\\hat{X} = 1 | X=0) + \\frac{1}{2} P(\\hat{X} = 0 | X=1)$$\n$$P_e = \\frac{1}{2}(p) + \\frac{1}{2}(p) = p$$\n\nThe overall probability of a word error is simply $p$. This result indicates that this specific coding and decoding scheme provides no improvement over uncoded transmission through the same channel.",
            "answer": "$$\\boxed{p}$$"
        }
    ]
}