{
    "hands_on_practices": [
        {
            "introduction": "掌握微分熵定义的第一步是将其应用于具体的概率分布。本练习将引导你计算拉普拉斯分布的微分熵，这是一种在信号处理和稳健统计中用于模拟比正态分布具有更重尾部的数据的常用分布。通过这个练习，你将熟练掌握从概率密度函数出发，通过积分直接求解熵的基本方法。",
            "id": "1649134",
            "problem": "在信号处理和稳健统计学领域，拉普拉斯分布常用于为数据呈现出比正态分布更重尾部的现象建模，这意味着离群值更可能出现。考虑一个通信信道中的噪声信号，由随机变量 $X$ 表示。该噪声服从拉普拉斯分布，其位置参数为 $\\mu$，正尺度参数为 $b$。$X$ 的概率密度函数 (PDF) 由下式给出：\n$$ f(x; \\mu, b) = \\frac{1}{2b} \\exp\\left(-\\frac{|x-\\mu|}{b}\\right) $$\n对所有实数 $x$ 成立。\n\n您的任务是计算此随机变量的微分熵 $h(X)$。微分熵是衡量连续随机变量平均不确定性的指标。\n\n请将您的最终答案表示为包含尺度参数 $b$ 和数学常数 $e$ 的符号表达式。",
            "solution": "对于一个具有概率密度函数 (PDF) $f(x)$ 的连续随机变量 $X$，其微分熵 $h(X)$ 定义为：\n$$ h(X) = -\\int_{-\\infty}^{\\infty} f(x) \\ln(f(x)) \\,dx $$\n首先，我们来求给定拉普拉斯 PDF 的 $\\ln(f(x))$ 表达式。\n$$ f(x) = \\frac{1}{2b} \\exp\\left(-\\frac{|x-\\mu|}{b}\\right) $$\n对两边取自然对数，我们得到：\n$$ \\ln(f(x)) = \\ln\\left(\\frac{1}{2b} \\exp\\left(-\\frac{|x-\\mu|}{b}\\right)\\right) $$\n利用对数性质 $\\ln(AB) = \\ln(A) + \\ln(B)$ 和 $\\ln(\\exp(C)) = C$，我们有：\n$$ \\ln(f(x)) = \\ln\\left(\\frac{1}{2b}\\right) - \\frac{|x-\\mu|}{b} = -\\ln(2b) - \\frac{|x-\\mu|}{b} $$\n现在，我们将此表达式代入微分熵的积分中：\n$$ h(X) = -\\int_{-\\infty}^{\\infty} f(x) \\left(-\\ln(2b) - \\frac{|x-\\mu|}{b}\\right) \\,dx $$\n我们可以将其分解为两个独立的积分：\n$$ h(X) = -\\int_{-\\infty}^{\\infty} f(x)(-\\ln(2b)) \\,dx - \\int_{-\\infty}^{\\infty} f(x)\\left(-\\frac{|x-\\mu|}{b}\\right) \\,dx $$\n$$ h(X) = \\ln(2b) \\int_{-\\infty}^{\\infty} f(x) \\,dx + \\frac{1}{b} \\int_{-\\infty}^{\\infty} |x-\\mu| f(x) \\,dx $$\n我们来逐项计算。\n\n对于第一项，积分 $\\int_{-\\infty}^{\\infty} f(x) \\,dx$ 是概率密度函数在其整个定义域上的积分。根据定义，此积分必须等于 1。\n$$ \\int_{-\\infty}^{\\infty} f(x) \\,dx = 1 $$\n所以，第一项简化为 $\\ln(2b)$。\n\n第二项涉及积分 $\\int_{-\\infty}^{\\infty} |x-\\mu| f(x) \\,dx$。这是随机变量 $|X-\\mu|$ 的期望值的定义，也就是与均值的平均绝对离差。\n$$ \\int_{-\\infty}^{\\infty} |x-\\mu| f(x) \\,dx = E[|X-\\mu|] $$\n我们来计算这个期望：\n$$ E[|X-\\mu|] = \\int_{-\\infty}^{\\infty} |x-\\mu| \\frac{1}{2b} \\exp\\left(-\\frac{|x-\\mu|}{b}\\right) \\,dx $$\n为了简化这个积分，我们进行换元，令 $u = x - \\mu$，则 $du = dx$。积分上下限仍为 $-\\infty$到 $\\infty$。\n$$ E[|X-\\mu|] = \\int_{-\\infty}^{\\infty} |u| \\frac{1}{2b} \\exp\\left(-\\frac{|u|}{b}\\right) \\,du $$\n被积函数 $|u| \\exp(-|u|/b)$ 是 $u$ 的偶函数。因此，我们可以将积分区间从 $(-\\infty, \\infty)$ 变为 $(0, \\infty)$ 并乘以 2：\n$$ E[|X-\\mu|] = 2 \\int_{0}^{\\infty} u \\frac{1}{2b} \\exp\\left(-\\frac{u}{b}\\right) \\,du = \\frac{1}{b} \\int_{0}^{\\infty} u \\exp\\left(-\\frac{u}{b}\\right) \\,du $$\n这个积分可以使用分部积分法 $\\int U dV = UV - \\int V dU$ 求解。\n令 $U = u$ 且 $dV = \\exp(-u/b) \\,du$。\n则 $dU = du$ 且 $V = \\int \\exp(-u/b) \\,du = -b \\exp(-u/b)$。\n$$ \\int_{0}^{\\infty} u \\exp\\left(-\\frac{u}{b}\\right) \\,du = \\left[u \\left(-b \\exp\\left(-\\frac{u}{b}\\right)\\right)\\right]_{0}^{\\infty} - \\int_{0}^{\\infty} \\left(-b \\exp\\left(-\\frac{u}{b}\\right)\\right) \\,du $$\n第一项在两个极限处的值都为 0：\n- 当 $u \\to \\infty$ 时，项 $\\lim_{u\\to\\infty} -bu \\exp(-u/b) = 0$（指数衰减速度快于多项式增长）。\n- 当 $u=0$ 时，该项为 $-b(0)\\exp(0) = 0$。\n因此，我们只剩下第二项：\n$$ b \\int_{0}^{\\infty} \\exp\\left(-\\frac{u}{b}\\right) \\,du = b \\left[-b \\exp\\left(-\\frac{u}{b}\\right)\\right]_{0}^{\\infty} $$\n$$ = b \\left( \\lim_{u\\to\\infty} -b \\exp\\left(-\\frac{u}{b}\\right) - \\left(-b \\exp(0)\\right) \\right) = b(0 - (-b)) = b^2 $$\n因此，$E[|X-\\mu|] = \\frac{1}{b} (b^2) = b$。注意，结果与 $\\mu$ 无关，这是符合预期的，因为微分熵对于位置平移是不变的。\n\n现在，我们将此结果代回到 $h(X)$ 的表达式中：\n$$ h(X) = \\ln(2b) + \\frac{1}{b} E[|X-\\mu|] = \\ln(2b) + \\frac{1}{b}(b) = \\ln(2b) + 1 $$\n最后，为了用 $b$ 和 $e$ 表示答案，我们使用性质 $1 = \\ln(e)$：\n$$ h(X) = \\ln(2b) + \\ln(e) = \\ln(2be) $$",
            "answer": "$$\\boxed{\\ln(2be)}$$"
        },
        {
            "introduction": "微分熵不仅是一个计算量，它还揭示了概率分布的内在特性。这个练习通过比较在相同区间上均匀分布和三角分布的熵，直观地展示了一个核心原则：在所有具有相同有限支撑集的分布中，均匀分布的不确定性最大，即其微分熵最大。这个对比将深化你对熵作为“不确定性”或“平坦度”度量的理解。",
            "id": "1649112",
            "problem": "考虑两个连续随机变量 $X$ 和 $Y$，它们的支撑集均为同一个对称区间 $[-a, a]$，其中 $a$ 是一个正常数。随机变量 $X$ 在此区间上服从均匀概率分布。随机变量 $Y$ 在同一区间上服从对称三角概率分布，其概率密度函数在区间中心 $x=0$ 处达到峰值。\n\n对于一个概率密度函数 (PDF) 为 $p(z)$ 的连续随机变量 $Z$，其微分熵 $h(Z)$ 定义为：\n$$h(Z) = -\\int_{-\\infty}^{\\infty} p(z) \\ln(p(z)) dz$$\n其中 $\\ln$ 表示自然对数。当使用自然对数时，熵的单位是奈特 (nats)。\n\n计算这两个随机变量的微分熵之差 $h(X) - h(Y)$。请用一个闭式解析表达式表示你的答案。",
            "solution": "首先，我们计算均匀分布随机变量 $X$ 的微分熵。\n设 $X \\sim \\mathrm{Unif}([-a,a])$。其概率密度函数 (PDF) 为 $p_{X}(x) = \\frac{1}{2a}$ (当 $x \\in [-a,a]$ 时)，其他情况下为 $0$。其微分熵 $h(X)$ 为：\n$$h(X) = -\\int_{-\\infty}^{\\infty} p_{X}(x)\\ln(p_{X}(x))\\,dx = -\\int_{-a}^{a} \\frac{1}{2a}\\ln\\left(\\frac{1}{2a}\\right)\\,dx$$\n由于被积函数是常数，我们可以将其移出积分：\n$$h(X) = -\\ln\\left(\\frac{1}{2a}\\right)\\int_{-a}^{a}\\frac{1}{2a}\\,dx$$\n根据 PDF 的定义，其在整个支撑集上的积分为 1，所以：\n$$h(X) = -\\ln\\left(\\frac{1}{2a}\\right) \\cdot 1 = \\ln(2a)$$\n\n接下来，我们计算三角分布随机变量 $Y$ 的微分熵。\n设 $Y$ 在 $[-a,a]$ 上服从对称三角分布，其峰值在 $y=0$。其 PDF 形式为 $p_{Y}(y)=c\\left(1-\\frac{|y|}{a}\\right)$ (当 $|y|\\le a$ 时)，其他情况下为 $0$。我们首先通过归一化确定常数 $c$：\n$$1=\\int_{-a}^{a} c\\left(1-\\frac{|y|}{a}\\right)dy=2c\\int_{0}^{a}\\left(1-\\frac{y}{a}\\right)dy=2c\\left[y-\\frac{y^2}{2a}\\right]_{0}^{a}=2c\\left(a-\\frac{a}{2}\\right)=ca$$\n因此，$c=\\frac{1}{a}$，PDF 为 $p_{Y}(y)=\\frac{a-|y|}{a^{2}}$ (当 $|y|\\le a$ 时)。\n其微分熵 $h(Y)$ 为：\n$$h(Y)=-\\int_{-a}^{a} p_{Y}(y)\\ln p_{Y}(y)\\,dy$$\n利用分布的对称性，我们可以将积分简化为：\n$$h(Y)=-2\\int_{0}^{a} \\frac{a-y}{a^{2}}\\ln\\left(\\frac{a-y}{a^{2}}\\right)\\,dy$$\n进行换元，令 $t=a-y$，则 $dt=-dy$。当 $y=0$ 时 $t=a$，当 $y=a$ 时 $t=0$。\n$$h(Y)=-2\\int_{a}^{0}\\frac{t}{a^{2}}\\ln\\left(\\frac{t}{a^{2}}\\right)\\,(-dt) = -2\\int_{0}^{a}\\frac{t}{a^{2}}\\ln\\left(\\frac{t}{a^{2}}\\right)\\,dt$$\n将对数项拆分 $\\ln\\left(\\frac{t}{a^{2}}\\right)=\\ln t - 2\\ln a$，得到：\n$$h(Y)=-\\frac{2}{a^{2}}\\left[\\int_{0}^{a} t\\ln t\\,dt - 2\\ln a \\int_{0}^{a} t\\,dt\\right]$$\n我们分别计算这两个积分。对于第一个积分，使用分部积分法，令 $u=\\ln t$，$dv=t\\,dt$，则 $du=\\frac{1}{t}dt$，$v=\\frac{t^{2}}{2}$：\n$$\\int_{0}^{a} t\\ln t\\,dt=\\left[\\frac{t^{2}}{2}\\ln t - \\frac{t^{2}}{4}\\right]_{0}^{a}=\\left(\\frac{a^{2}}{2}\\ln a - \\frac{a^{2}}{4}\\right) - \\lim_{t\\to 0^{+}}\\left(\\frac{t^{2}}{2}\\ln t - \\frac{t^{2}}{4}\\right) = \\frac{a^{2}}{2}\\ln a - \\frac{a^{2}}{4}$$\n(其中我们使用了洛必达法则证明 $\\lim_{t\\to 0^{+}} t^{2}\\ln t=0$。)\n第二个积分很简单：\n$$\\int_{0}^{a} t\\,dt=\\frac{a^{2}}{2}$$\n将积分结果代回 $h(Y)$ 的表达式：\n$$h(Y)=-\\frac{2}{a^{2}}\\left[\\left(\\frac{a^{2}}{2}\\ln a - \\frac{a^{2}}{4}\\right) - 2\\ln a \\left(\\frac{a^{2}}{2}\\right)\\right] = -\\frac{2}{a^{2}}\\left[\\frac{a^{2}}{2}\\ln a - \\frac{a^{2}}{4} - a^{2}\\ln a\\right]$$\n$$h(Y) = -2\\left[-\\frac{1}{2}\\ln a - \\frac{1}{4}\\right] = \\ln a + \\frac{1}{2}$$\n\n最后，计算两个熵的差值：\n$$h(X)-h(Y)=\\ln(2a)-\\left(\\ln a + \\frac{1}{2}\\right)=(\\ln 2 + \\ln a) - \\ln a - \\frac{1}{2} = \\ln 2 - \\frac{1}{2}$$\n这个结果与参数 $a$ 无关，这与两个分布具有相同的尺度变换特性是一致的。",
            "answer": "$$\\boxed{\\ln 2 - \\frac{1}{2}}$$"
        },
        {
            "introduction": "微分熵在估计理论中扮演着关键角色，它为我们量化估计一个随机变量时的不确定性提供了工具。本练习探讨了在联合高斯信号模型中，估计误差的熵与条件熵之间的关系。通过计算这两者之间的差异，你将具体地验证一个基本不等式，该不等式表明条件熵为任何估计器的误差熵设定了一个不可逾越的下界，从而揭示了信息论与最优估计之间的深刻联系。",
            "id": "1649100",
            "problem": "在信号处理的背景下，一个零均值随机信号 $X$（其方差为 $\\sigma_X^2$）通过一个噪声信道传输。接收到的信号为 $Y$，其均值也为零，方差为 $\\sigma_Y^2$。发送信号和接收信号是联合高斯分布的，其相关系数为 $\\rho$，满足 $|\\rho|1$。\n\n一位工程师设计了一个简单的线性估计器来恢复原始信号，该估计器由 $\\hat{X} = g(Y) = aY$ 给出，其中 $a$ 是一个固定的实值增益因子。这个估计过程的质量可以从信息论的角度进行分析。\n\n两个重要的量是条件微分熵 $h(X|Y)$ 和估计误差的微分熵 $h(X - \\hat{X})$。前者量化了在观测到 $Y$ 之后关于 $X$ 的不可约不确定性，后者量化了误差本身的不确定性。\n\n计算差值 $\\Delta h = h(X - aY) - h(X|Y)$。您的答案应该是一个以 $\\sigma_X, \\sigma_Y, \\rho$ 和 $a$ 表示的闭式解析表达式。\n\n供您参考，一个方差为 $\\sigma_W^2$ 的一维正态随机变量 $W$ 的微分熵为 $h(W) = \\frac{1}{2}\\ln(2\\pi e \\sigma_W^2)$。",
            "solution": "根据题意，随机变量 $X$ 和 $Y$ 是零均值的联合高斯随机变量，其方差分别为 $\\sigma_{X}^{2}$ 和 $\\sigma_{Y}^{2}$，相关系数为 $\\rho$。因此，它们的协方差为 $\\operatorname{Cov}(X,Y)=\\rho\\sigma_{X}\\sigma_{Y}$。\n\n首先，我们计算估计误差 $E = X - aY$ 的微分熵 $h(X-aY)$。\n由于 $X$ 和 $Y$ 是联合高斯分布的，它们的线性组合 $E = X - aY$ 也服从高斯分布。其均值为 $E[E] = E[X] - aE[Y] = 0 - a \\cdot 0 = 0$。其方差为：\n$$\\operatorname{Var}(X-aY) = \\operatorname{Var}(X) + \\operatorname{Var}(-aY) + 2\\operatorname{Cov}(X, -aY)$$\n$$= \\operatorname{Var}(X) + a^2\\operatorname{Var}(Y) - 2a\\operatorname{Cov}(X,Y)$$\n$$=\\sigma_{X}^{2}+a^{2}\\sigma_{Y}^{2}-2a\\rho\\sigma_{X}\\sigma_{Y}$$\n对于一个方差为 $\\sigma_W^2$ 的一维高斯变量 $W$，其微分熵为 $h(W)=\\frac{1}{2}\\ln(2\\pi e\\,\\sigma_{W}^{2})$。因此，估计误差的熵为：\n$$h(X-aY)=\\frac{1}{2}\\ln\\big(2\\pi e\\,(\\sigma_{X}^{2}+a^{2}\\sigma_{Y}^{2}-2a\\rho\\sigma_{X}\\sigma_{Y})\\big)$$\n\n接下来，我们计算条件微分熵 $h(X|Y)$。\n对于联合高斯分布的 $(X,Y)$，给定 $Y$ 时 $X$ 的条件分布 $p(X|Y)$ 仍然是高斯分布。其条件均值为 $E[X|Y] = \\frac{\\operatorname{Cov}(X,Y)}{\\sigma_Y^2}Y = \\frac{\\rho\\sigma_X}{\\sigma_Y}Y$，条件方差为：\n$$\\operatorname{Var}(X|Y)=\\sigma_{X}^{2}(1-\\rho^{2})$$\n这个条件方差不依赖于 $Y$ 的具体取值。因此，条件熵 $h(X|Y)$ 等于一个方差为 $\\sigma_{X}^{2}(1-\\rho^{2})$ 的高斯变量的熵：\n$$h(X|Y)=\\frac{1}{2}\\ln\\big(2\\pi e\\,\\sigma_{X}^{2}(1-\\rho^{2})\\big)$$\n\n最后，我们计算差值 $\\Delta h = h(X - aY) - h(X|Y)$：\n$$\\Delta h = \\frac{1}{2}\\ln\\big(2\\pi e\\,(\\sigma_{X}^{2}+a^{2}\\sigma_{Y}^{2}-2a\\rho\\sigma_{X}\\sigma_{Y})\\big) - \\frac{1}{2}\\ln\\big(2\\pi e\\,\\sigma_{X}^{2}(1-\\rho^{2})\\big)$$\n利用对数性质 $\\ln(A) - \\ln(B) = \\ln(A/B)$，我们得到：\n$$\\Delta h = \\frac{1}{2}\\ln\\left(\\frac{\\sigma_{X}^{2}+a^{2}\\sigma_{Y}^{2}-2a\\rho\\sigma_{X}\\sigma_{Y}}{\\sigma_{X}^{2}(1-\\rho^{2})}\\right)$$\n这个表达式是良定义的，因为题目条件 $|\\rho|1$ 保证了分母 $1-\\rho^{2}  0$。同时，分子作为随机变量 $X-aY$ 的方差，也必须为正。",
            "answer": "$$\\boxed{\\frac{1}{2}\\ln\\left(\\frac{\\sigma_{X}^{2}+a^{2}\\sigma_{Y}^{2}-2a\\rho\\sigma_{X}\\sigma_{Y}}{\\sigma_{X}^{2}(1-\\rho^{2})}\\right)}$$"
        }
    ]
}