{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握隐式方法，第一步是亲手处理其核心的代数挑战。与显式方法直接计算下一步不同，隐式方法要求我们为未来的状态求解一个方程。这个练习  提供了一个具体的情景——CPU散热模型，让你直接实践如何建立并求解隐式欧拉法所产生的代数方程，这是理解隐式积分的第一块基石。",
            "id": "2178316",
            "problem": "一个中央处理器 (CPU) 在可变负载下的简化热模型由以下一阶常微分方程描述：\n$$ \\frac{dT}{dt} = -k(T - T_a) + P(t) $$\n其中 $T(t)$ 是 CPU 在时间 $t$（单位为分钟）时的温度，单位为摄氏度 ($^\\circ\\text{C}$)，$k$ 是散热常数，$T_a$ 是恒定的环境温度，$P(t)$ 代表 CPU 活动产生的热量。\n\n假设参数如下：\n- 散热常数，$k = 0.5 \\text{ min}^{-1}$\n- 环境温度，$T_a = 25^\\circ\\text{C}$\n- 生热函数，$P(t) = P_0 \\cos(\\omega t)$，其中 $P_0 = 10^\\circ\\text{C}/\\text{min}$ 且 $\\omega = \\frac{\\pi}{6} \\text{ rad/min}$。\n- CPU 的初始温度为 $T(0) = 85^\\circ\\text{C}$。\n\n为了预测温度的演变，我们采用一种数值方法。下一个时间步 $t_{n+1}$ 的温度 $T_{n+1}$，是根据当前时间步 $t_n$ 的温度 $T_n$，使用以下更新规则估算得出：\n$$ T_{n+1} = T_n + h \\left( \\frac{dT}{dt} \\right)_{t=t_{n+1}, T=T_{n+1}} $$\n其中 $h = t_{n+1} - t_n$ 是时间步长。\n\n使用该数值方法进行单步计算，步长取 $h=0.5$ 分钟，计算 CPU 在 $t=0.5$ 分钟时的近似温度。\n\n请用摄氏度表示你的答案，并四舍五入到四位有效数字。",
            "solution": "给定一阶常微分方程\n$$\n\\frac{dT}{dt}=-k\\left(T-T_{a}\\right)+P(t), \\quad P(t)=P_{0}\\cos(\\omega t),\n$$\n我们要应用步长为 $h$ 的隐式（后向）欧拉法，从 $t_{0}=0$ 到 $t_{1}=h$ 进行单步计算。后向欧拉更新式为\n$$\nT_{1}=T_{0}+h\\left.\\frac{dT}{dt}\\right|_{t=t_{1},\\,T=T_{1}}=T_{0}+h\\big(-k(T_{1}-T_{a})+P_{0}\\cos(\\omega t_{1})\\big).\n$$\n对此方程求解 $T_{1}$。展开右侧并合并含 $T_{1}$ 的项：\n$$\nT_{1}=T_{0}-hkT_{1}+hkT_{a}+hP_{0}\\cos(\\omega t_{1}).\n$$\n将含 $T_{1}$ 的项移到左侧：\n$$\nT_{1}+hkT_{1}=T_{0}+hkT_{a}+hP_{0}\\cos(\\omega t_{1}).\n$$\n对左侧因式分解并求解 $T_{1}$：\n$$\nT_{1}=\\frac{T_{0}+hkT_{a}+hP_{0}\\cos(\\omega t_{1})}{1+hk}.\n$$\n现在代入给定数据 $T_{0}=85$，$k=0.5$，$T_{a}=25$，$P_{0}=10$，$\\omega=\\frac{\\pi}{6}$，$h=0.5$ 和 $t_{1}=0.5$：\n$$\n1+hk=1+0.5\\times 0.5=1.25,\n$$\n$$\nhkT_{a}=0.5\\times 0.5\\times 25=6.25,\n$$\n$$\nhP_{0}\\cos(\\omega t_{1})=0.5\\times 10\\times \\cos\\!\\left(\\frac{\\pi}{6}\\times 0.5\\right)=5\\cos\\!\\left(\\frac{\\pi}{12}\\right).\n$$\n因此\n$$\nT_{1}=\\frac{85+6.25+5\\cos\\!\\left(\\frac{\\pi}{12}\\right)}{1.25}.\n$$\n使用 $\\cos\\!\\left(\\frac{\\pi}{12}\\right)\\approx 0.9659258263$，我们得到\n$$\nT_{1}\\approx \\frac{85+6.25+4.829629131}{1.25}=\\frac{96.079629131}{1.25}\\approx 76.86370331.\n$$\n四舍五入到四位有效数字，在 $t=0.5$ 分钟时的近似温度是 $76.86$ 摄氏度。",
            "answer": "$$\\boxed{76.86}$$"
        },
        {
            "introduction": "在科学计算中，尤其是在求解偏微分方程（PDEs）离散化后得到的大型常微分方程（ODE）系统时，效率至关重要。直接求解一个稠密线性系统通常是不可行的。这个练习  将引导你利用问题的特殊结构（三对角矩阵）来设计一个高效的求解器，其计算成本与问题规模成线性关系（$O(n)$），而不是三次方关系（$O(n^3)$），这对于解决实际的大规模问题是关键的一步。",
            "id": "3241515",
            "problem": "您的任务是为常微分方程 (ODE) 的初值问题 (IVP) 设计并分析一种高效的隐式时间步进方法。从常微分方程 (ODE) 的定义和初值问题 (IVP) 的陈述开始。考虑一个形式为 $y'(t) = A y(t)$（$t \\ge 0$）的线性系统，其中 $y(t) \\in \\mathbb{R}^n$ 且 $A \\in \\mathbb{R}^{n \\times n}$ 是一个三对角矩阵。目标是构造特定的三对角矩阵 $A$，并实现后向欧拉法，使用一种避免完全矩阵求逆的算法来推进解的时间演化，同时保持计算效率和数值稳定性。\n\n您的程序必须：\n- 为每个测试用例构造一个指定大小 $n$ 的三对角矩阵 $A$。三对角矩阵的非零元素仅存在于其主对角线以及第一条次对角线和超对角线上。将次对角线表示为 $a_i$（$i=1,\\dots,n-1$），主对角线表示为 $d_i$（$i=1,\\dots,n$），超对角线表示为 $c_i$（$i=1,\\dots,n-1$）。\n- 为初值问题 $y'(t)=A y(t)$ 推导并实现一个单步后向欧拉法（Backward Euler method (BE)），而无需执行密集矩阵求逆。在从 $t^n$ 到 $t^{n+1} = t^n + h$ 的每个时间步，建立并求解关于 $y^{n+1}$ 的线性系统，使用基于专为三对角矩阵优化的 高斯消元法（通常称为 Thomas 算法）的三对角求解器，该算法以 $\\mathcal{O}(n)$ 时间和 $\\mathcal{O}(n)$ 内存运行。\n- 通过将三对角求解器的结果与在每一步对同一线性系统使用密集线性求解器得到的结果进行比较，来验证三对角求解器的正确性，并报告最大绝对差。\n\n使用以下测试套件。对于每个用例，执行指定的操作，并记录一个浮点数，该数等于三对角求解器计算的解与密集求解器计算的解之间差值的无穷范数（最大绝对值）。本问题不涉及物理单位。\n\n测试套件：\n- 用例 1（理想情况，小 $n$）：设 $n=5$。定义 $A$ 为 $d_i=-2$（$i=1,\\dots,5$），$a_i=1$（$i=1,\\dots,4$），以及 $c_i=1$（$i=1,\\dots,4$）。使用时间步长 $h=0.05$。取初始条件 $y^0 = [1,0,0,0,0]^T$。执行一个单步后向欧拉法，并记录三对角解与密集解之间差值的无穷范数。\n- 用例 2（仅对角线，边界条件覆盖）：设 $n=10$。定义对角矩阵 $A$ 为 $d_i=-i$（$i=1,\\dots,10$），且 $a_i=0$, $c_i=0$。使用 $h=0.2$。取 $y^0=[1,1,1,1,1,1,1,1,1,1]^T$。执行一个单步后向欧拉法，并记录差值。\n- 用例 3（更大维度，强对角占优）：设 $n=50$。定义 $A$ 为 $d_i=-5$（$i=1,\\dots,50$），$a_i=-2$（$i=1,\\dots,49$），$c_i=-1$（$i=1,\\dots,49$）。使用 $h=0.1$。取初始条件 $y^0$，其分量为 $y^0_j = j/50$（$j=0,\\dots,49$）。执行一个单步后向欧拉法，并记录差值。\n- 用例 4（边界情况 $h=0$）：设 $n=8$。定义 $A$ 为 $d_i=-3$（$i=1,\\dots,8$），$a_i=1$（$i=1,\\dots,7$），$c_i=1$（$i=1,\\dots,7$）。使用 $h=0$。取初始条件 $y^0$，其分量为 $y^0_j = j$（$j=0,\\dots,7$）。执行一个单步后向欧拉法，并记录差值。\n- 用例 5（多步，累积稳定性）：设 $n=20$。定义 $A$ 为 $d_i=-1.6$（$i=1,\\dots,20$），$a_i=0.8$（$i=1,\\dots,19$），$c_i=0.9$（$i=1,\\dots,19$）。使用 $h=0.05$。取 $y^0=[1,1,\\dots,1]^T \\in \\mathbb{R}^{20}$。执行 100 个均匀的后向欧拉步骤以达到 $t=5.0$，并记录基于三对角求解器的结果与基于密集求解器的结果之间的差值。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$ [r_1,r_2,r_3,r_4,r_5] $），其中每个 $r_i$ 是为用例 $i$ 指定的浮点差值。\n\n实现必须避免任何完全矩阵求逆，并且必须使用利用三对角结构以在每次求解中实现线性时间复杂度的算法。所有计算均为纯数学计算，不涉及物理单位。不涉及角度。不涉及百分比；任何分数都应表示为小数。程序必须是自包含的，不需要任何输入，并遵守指定的执行环境。",
            "solution": "常微分方程 (ODE) 系统的初值问题 (IVP) 由微分方程 $y'(t) = f(t, y(t))$（$t \\ge t_0$）以及初始条件 $y(t_0) = y_0$ 定义。我们所考虑的问题是一个线性、时不变系统，其形式为：\n$$\ny'(t) = A y(t), \\quad y(0) = y^0\n$$\n其中 $y(t) \\in \\mathbb{R}^n$ 是状态向量，$A \\in \\mathbb{R}^{n \\times n}$ 是一个常数三对角矩阵。\n\n为数值求解此初值问题，我们采用一种时间步进方法。该问题指定使用后向欧拉法 (Backward Euler (BE) method)，这是一种隐式方法，以其强大的稳定性（A-稳定性）而闻名。我们用均匀的时间步长 $h$ 对时间域进行离散化，使得 $t^k = k h$（$k=0, 1, 2, \\dots$）。每个时间步的解记为 $y^k \\approx y(t^k)$。\n\n后向欧拉法使用后向差分公式来近似下一个时间步 $t^{n+1}$ 处的导数：\n$$\ny'(t^{n+1}) \\approx \\frac{y^{n+1} - y^n}{h}\n$$\n将此近似值代入在 $t=t^{n+1}$ 处求值的常微分方程中，我们得到：\n$$\n\\frac{y^{n+1} - y^n}{h} = A y^{n+1}\n$$\n这个方程是隐式的，因为未知数 $y^{n+1}$ 出现在方程的两边。为了求解 $y^{n+1}$，我们重新整理各项：\n$$\ny^{n+1} - h A y^{n+1} = y^n\n$$\n提出因子 $y^{n+1}$，得到一个线性方程组：\n$$\n(I - hA) y^{n+1} = y^n\n$$\n其中 $I$ 是 $n \\times n$ 的单位矩阵。在每个时间步，我们必须根据上一步的已知向量 $y^n$ 来求解这个关于未知向量 $y^{n+1}$ 的线性系统。\n\n矩阵 $A$ 是三对角的。设其对角线由向量 $d$（主对角线，长度 $n$）、$a$（次对角线，长度 $n-1$）和 $c$（超对角线，长度 $n-1$）表示。使用基于 1 的索引， $A$ 的非零元素为 $A_{i,i} = d_i$（$i=1,\\dots,n$），$A_{i+1,i} = a_i$（$i=1,\\dots,n-1$）以及 $A_{i,i+1} = c_i$（$i=1,\\dots,n-1$）。\n\n待求解的线性系统的矩阵 $M = I - hA$ 继承了这种三对角结构。其对角线为：\n- 主对角线：$\\tilde{d}_i = 1 - h d_i$（$i=1,\\dots,n$）。\n- 次对角线：$\\tilde{a}_i = -h a_i$（$i=1,\\dots,n-1$）。\n- 超对角线：$\\tilde{c}_i = -h c_i$（$i=1,\\dots,n-1$）。\n\n求解三对角系统比求解一般的密集系统要高效得多。对矩阵 $M$ 进行直接求逆将是一个 $\\mathcal{O}(n^3)$ 的操作，并且会破坏稀疏结构，需要 $\\mathcal{O}(n^2)$ 的内存。相反，我们使用 Thomas 算法（也称为三对角矩阵算法或 TDMA），这是一种特殊形式的 高斯消元法，它能在 $\\mathcal{O}(n)$ 时间内使用 $\\mathcal{O}(n)$ 内存求解该系统。\n\nThomas 算法包括两个阶段：前向消元和后向代换。考虑系统 $M x = y^n$，使用 $M$ 的对角线 $\\tilde{a}_i$（次对角线）、$\\tilde{d}_i$（主对角线）和 $\\tilde{c}_i$（超对角线）按分量写出：\n$$\n\\tilde{a}_{i-1} x_{i-1} + \\tilde{d}_i x_i + \\tilde{c}_i x_{i+1} = y^n_i \\quad (\\text{其中 } \\tilde{a}_0=0, \\tilde{c}_n=0)\n$$\n1.  **前向消元**：该算法修改超对角线系数和右侧向量。我们计算新的系数 $c'_i$ 和 $y'_{i}$（为实现清晰起见，使用基于 0 的索引）：\n    - 对于 $i=0$:\n      $$\n      c'_0 = \\frac{\\tilde{c}_0}{\\tilde{d}_0}, \\quad y'_0 = \\frac{y^n_0}{\\tilde{d}_0}\n      $$\n    - 对于 $i=1, \\dots, n-2$:\n      $$\n      c'_i = \\frac{\\tilde{c}_i}{\\tilde{d}_i - \\tilde{a}_{i-1} c'_{i-1}}, \\quad y'_i = \\frac{y^n_i - \\tilde{a}_{i-1} y'_{i-1}}{\\tilde{d}_i - \\tilde{a}_{i-1} c'_{i-1}}\n      $$\n    - 对于 $i=n-1$:\n      $$\n      y'_{n-1} = \\frac{y^n_{n-1} - \\tilde{a}_{n-2} y'_{n-2}}{\\tilde{d}_{n-1} - \\tilde{a}_{n-2} c'_{n-2}}\n      $$\n    这将系统转换为上双对角形式。\n\n2.  **后向代换**：通过向后代换求得解 $x = y^{n+1}$：\n    - 对于 $i=n-1$:\n      $$\n      x_{n-1} = y'_{n-1}\n      $$\n    - 对于 $i=n-2, \\dots, 0$:\n      $$\n      x_i = y'_i - c'_i x_{i+1}\n      $$\n\n对于每个测试用例，我们执行一个或多个后向欧拉法的步骤。我们构造矩阵 $M=I-hA$ 及其对角线，以及右侧向量 $y^n$。然后，我们同时使用已实现的 Thomas 算法 ($y_{\\text{tri}}^{n+1}$) 和标准库提供的通用密集线性求解器 ($y_{\\text{dense}}^{n+1}$) 来求解 $y^{n+1}$，以进行验证。每个用例的最终结果是差分向量的无穷范数，即 $\\max_i |(y_{\\text{tri}}^{n+1})_i - (y_{\\text{dense}}^{n+1})_i|$。对于多步用例，此比较在最后一个时间步之后执行。测试用例中的矩阵被选择为使得 $I-hA$ 是对角占优的，从而确保 Thomas 算法在没有主元选择的情况下的数值稳定性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the Backward Euler method\n    with a tridiagonal solver.\n    \"\"\"\n\n    def construct_dense_A(n, d_vals, a_vals, c_vals):\n        \"\"\"Constructs the dense n x n tridiagonal matrix A.\"\"\"\n        A = np.zeros((n, n))\n        # Populate main diagonal\n        A += np.diag(d_vals)\n        # Populate sub-diagonal\n        if len(a_vals) > 0:\n            A += np.diag(a_vals, k=-1)\n        # Populate super-diagonal\n        if len(c_vals) > 0:\n            A += np.diag(c_vals, k=1)\n        return A\n\n    def thomas_algorithm(a, d, c, b):\n        \"\"\"\n        Solves a tridiagonal system of equations Ax=b using the Thomas algorithm.\n        a: sub-diagonal (length n-1)\n        d: main diagonal (length n)\n        c: super-diagonal (length n-1)\n        b: right-hand side vector (length n)\n        \n        The algorithm is not performed in-place to avoid side effects.\n        \"\"\"\n        n = len(d)\n        if n == 0:\n            return np.array([])\n        if n == 1:\n            return np.array([b[0] / d[0]])\n\n        # Create copies to avoid modifying original arrays\n        c_prime = np.zeros(n - 1)\n        d_prime = np.zeros(n)\n        x = np.zeros(n)\n\n        # Forward elimination\n        c_prime[0] = c[0] / d[0]\n        d_prime[0] = b[0] / d[0]\n\n        for i in range(1, n - 1):\n            denom = d[i] - a[i - 1] * c_prime[i - 1]\n            c_prime[i] = c[i] / denom\n            d_prime[i] = (b[i] - a[i - 1] * d_prime[i - 1]) / denom\n\n        denom_last = d[n - 1] - a[n - 2] * c_prime[n - 2]\n        d_prime[n - 1] = (b[n-1] - a[n-2] * d_prime[n-2]) / denom_last\n\n        # Backward substitution\n        x[n - 1] = d_prime[n - 1]\n        for i in range(n - 2, -1, -1):\n            x[i] = d_prime[i] - c_prime[i] * x[i + 1]\n\n        return x\n\n    # Define the test cases from the problem statement.\n    # Each tuple: (n, d_func, a_func, c_func, h, y0_func, steps)\n    test_cases = [\n        # Case 1\n        (5, lambda n: np.full(n, -2.0), lambda n: np.full(n - 1, 1.0), lambda n: np.full(n - 1, 1.0), 0.05, \n         lambda n: np.array([1.0] + [0.0]*(n-1)), 1),\n        # Case 2\n        (10, lambda n: -np.arange(1, n + 1, dtype=float), lambda n: np.full(n - 1, 0.0), lambda n: np.full(n - 1, 0.0), 0.2, \n         lambda n: np.ones(n), 1),\n        # Case 3\n        (50, lambda n: np.full(n, -5.0), lambda n: np.full(n - 1, -2.0), lambda n: np.full(n - 1, -1.0), 0.1, \n         lambda n: np.arange(n, dtype=float) / n, 1),\n        # Case 4\n        (8, lambda n: np.full(n, -3.0), lambda n: np.full(n - 1, 1.0), lambda n: np.full(n - 1, 1.0), 0.0,\n         lambda n: np.arange(n, dtype=float), 1),\n        # Case 5\n        (20, lambda n: np.full(n, -1.6), lambda n: np.full(n - 1, 0.8), lambda n: np.full(n - 1, 0.9), 0.05,\n         lambda n: np.ones(n), 100),\n    ]\n\n    results = []\n    for n, d_func, a_func, c_func, h, y0_func, steps in test_cases:\n        # Construct diagonals and initial condition\n        d_A = d_func(n)\n        a_A = a_func(n)\n        c_A = c_func(n)\n        y0 = y0_func(n)\n\n        # Construct dense matrix A for validation\n        A_dense = construct_dense_A(n, d_A, a_A, c_A)\n        \n        # System to solve is (I - hA)y_next = y_prev\n        M_dense = np.eye(n) - h * A_dense\n\n        # Diagonals of M = I - hA\n        # Sub-diagonal mapping: a_M[i] is for row i+1, corresponds to a_A[i]\n        # Super-diagonal mapping: c_M[i] is for row i, corresponds to c_A[i]\n        d_M = 1.0 - h * d_A\n        if n > 1:\n            a_M = -h * a_A\n            c_M = -h * c_A\n        else: # Handle n=1 case\n            a_M = np.array([])\n            c_M = np.array([])\n            \n        y_tri = y0.copy()\n        y_dense = y0.copy()\n\n        for _ in range(steps):\n            # Solve using Thomas algorithm\n            y_tri = thomas_algorithm(a_M, d_M, c_M, y_tri)\n            # Solve using dense solver for validation\n            y_dense = np.linalg.solve(M_dense, y_dense)\n\n        # Calculate the infinity norm of the difference\n        diff = np.max(np.abs(y_tri - y_dense))\n        results.append(diff)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现实世界中的问题其动态特性往往是变化的，使用固定的时间步长既可能效率低下，也可能不够稳定。这个高级练习  介绍了一种自适应步长控制策略，让求解器能够根据问题的“难度”智能地调整步长。通过使用牛顿法求解隐式方程所需的迭代次数作为反馈，我们能构建一个既稳健又高效的求解器，这体现了现代ODE数值求解器的设计精髓。",
            "id": "3241651",
            "problem": "实现一个程序，使用带有自适应时间步长的隐式单步法求解一类常微分方程的初值问题 (IVP)。自适应性必须仅由每个时间步收敛所需的 Newton 迭代次数来控制。\n\n您的方法必须基于以下基本要素：\n- 给定一个初值问题 $y'(t) = f(t,y(t))$，初始条件为 $y(t_0) = y_0$。\n- 使用的隐式单步法是后向 Euler 方法，它将下一个解值 $y_{n+1}$ 定义为在新时间 $t_{n+1}$ 处构建的隐式代数方程的解。\n- 每一步的非线性代数方程必须通过 Newton 求根法求解。\n- 步长控制器必须仅使用在成功的步中观察到的 Newton 迭代次数来调整步长，并且在 Newton 方法未能收敛时必须减小步长并重试同一步骤。\n\n您的程序必须：\n1. 从后向 Euler 方法和 Newton 方法的定义出发，为每个时间步中出现的标量隐式方程实现一个 Newton 求解器。您必须使用残差相对于未知新状态的导数。\n2. 实现一个自适应时间步长控制器，该控制器仅使用上一个成功步骤中使用的 Newton 迭代次数来调整下一个步长。您必须包含一个回退机制，在 Newton 方法失败时，该机制会减小当前步长并重试同一步骤，直到收敛或达到最小步长。\n3. 在每一步使用预测子来初始化 Newton 方法。该预测子必须是根据前一步的可用信息构建的任何显式一阶猜测值。\n4. 对 Newton 方法使用一个基于范数且尺度感知的停止准则。如果绝对残差足够小，或者 Newton 修正在相对于当前迭代值足够小，则判断为成功。\n\n您的实现必须使用的数值参数：\n- Newton 停止容差：绝对残差容差 $\\varepsilon_{\\mathrm{abs}} = 10^{-10}$ 和相对修正容差 $\\varepsilon_{\\mathrm{rel}} = 10^{-10}$。\n- 每次尝试的最大 Newton 迭代次数：$m_{\\max} = 20$。\n- 步长控制器目标和因子：\n  - 目标迭代窗口 $[m_{\\mathrm{lo}}, m_{\\mathrm{hi}}] = [2,4]$。\n  - 如果一个成功的步骤使用了 $m \\le m_{\\mathrm{lo}}$ 次迭代，则将下一步长乘以因子 $g = 1.5$。\n  - 如果一个成功的步骤使用了 $m_{\\mathrm{lo}}  m \\le m_{\\mathrm{hi}}$ 次迭代，则保持下一步长不变。\n  - 如果一个成功的步骤使用了 $m  m_{\\mathrm{hi}}$ 次迭代，则将下一步长乘以因子 $s = 0.7$。\n  - 如果 Newton 方法在一次步骤尝试中未能在 $m_{\\max}$ 次迭代内收敛，则在重试时将当前步长乘以因子 $s_{\\mathrm{fail}} = 0.3$。\n- 初始步长 $h_0 = \\min\\{10^{-2}, (T-t_0)/10\\}$，最小步长 $h_{\\min} = 10^{-6}$，以及最大步长 $h_{\\max} = 2\\times 10^{-1}$。\n- 所有三角函数（如果存在）必须使用弧度作为角度单位。\n\n需要实现的 Newton 停止规则：\n- 令 $F(y)$ 表示在时间 $t_{n+1}$ 定义隐式方程的标量残差，令 $\\Delta y$ 为 Newton 修正量。如果 $|F(y)| \\le \\varepsilon_{\\mathrm{abs}}$ 或 $|\\Delta y| \\le \\varepsilon_{\\mathrm{rel}} \\max\\{1, |y|\\}$，则接受收敛。\n\n每一步需要求解的隐式步进方程：\n- 对于（可能已调整的）步长 $h$，定义 $t_{n+1} = t_n + h$，并找到 $y_{n+1}$ 使得后向 Euler 定义方程在 $t_{n+1}$ 成立。残差 $F(y_{n+1})$ 是该定义方程左侧和右侧之间的差异。\n- 您的 Newton 迭代必须使用 $F(y)$ 相对于 $y$ 的导数，并在当前的 Newton 迭代值处进行求值。\n\n您的程序需要求解的测试套件：\n- 用指定的最终时间 $T$ 和初始值 $y_0$ 求解以下三个 IVP。对于每个问题，函数 $f(t,y)$ 及其关于 $y$ 的导数（记为 $f_y(t,y)$）如下：\n  1. 刚性线性衰减：\n     - $f(t,y) = -a\\,y$，其中 $a = 100$。\n     - $f_y(t,y) = -a$。\n     - $t_0 = 0$, $y_0 = 1$, $T = 1$。\n  2. 逻辑斯谛增长：\n     - $f(t,y) = r\\,y\\,(1 - y)$，其中 $r = 30$。\n     - $f_y(t,y) = r\\,(1 - 2y)$。\n     - $t_0 = 0$, $y_0 = 10^{-2}$, $T = 2$。\n  3. 受迫稳定线性系统：\n     - $f(t,y) = -\\lambda\\,(y - \\sin t)$，其中 $\\lambda = 50$。\n     - $f_y(t,y) = -\\lambda$。\n     - $t_0 = 0$, $y_0 = 0$, $T = 3$。\n\n程序输出规范：\n- 对于三个 IVP 中的每一个，计算最终时间 $T$ 的数值解，并以浮点数形式返回最终值 $y(T)$。\n- 您的程序应生成单行输出，其中包含三个结果，格式为方括号内由逗号分隔的列表，每个数字精确到小数点后六位，顺序与上面列出的测试用例相同。例如：“[0.123456,0.000001,1.000000]”。\n- 不得打印任何额外的文本或格式。\n\n本问题中的所有量都是无量纲的，不涉及物理单位。三角函数中的角度必须解释为弧度。",
            "solution": "我们从初值问题的定义开始：寻找一个函数 $y(t)$，使得 $y'(t) = f(t,y(t))$ 且 $y(t_0) = y_0$。后向 Euler 方法是一种隐式单步法，它建立在导数作为差商的基本关系之上。在一个从 $t_n$ 到 $t_{n+1} = t_n + h$，步长为 $h$ 的步中，后向 Euler 方法用 $(y_{n+1} - y_n)/h$ 替换导数，并在新时刻计算右侧项。这得到了定义方程\n$$\n\\frac{y_{n+1} - y_n}{h} = f(t_{n+1}, y_{n+1}),\n$$\n它等价于残差方程\n$$\nF(y_{n+1}) := y_{n+1} - y_n - h\\, f(t_{n+1}, y_{n+1}) = 0.\n$$\n在每一步中，我们必须求解标量非线性方程 $F(y) = 0$，以求得未知数 $y = y_{n+1}$。这可以通过 Newton 方法来完成，该方法源于 $F$ 在当前迭代值 $y^{(k)}$ 附近的一阶 Taylor 展开：\n$$\nF(y^{(k+1)}) \\approx F(y^{(k)}) + F'(y^{(k)})(y^{(k+1)} - y^{(k)}).\n$$\n将左侧设为零并求解修正量 $\\Delta y^{(k)} = y^{(k+1)} - y^{(k)}$，得到 Newton 更新公式\n$$\n\\Delta y^{(k)} = - \\frac{F(y^{(k)})}{F'(y^{(k)})}, \\quad y^{(k+1)} = y^{(k)} + \\Delta y^{(k)}.\n$$\n对于后向 Euler 残差，\n$$\nF(y) = y - y_n - h\\, f(t_{n+1}, y),\n$$\n其相对于 $y$ 的导数可由链式法则得出，为\n$$\nF'(y) = 1 - h \\, \\frac{\\partial f}{\\partial y}(t_{n+1}, y).\n$$\n一个实际的实现需要一个初始猜测值 $y^{(0)}$。可以根据在 $t_n$ 已知的信息构造一个一阶相容的预测子，例如显式 Euler 预测子 $y^{(0)} = y_n + h\\, f(t_n, y_n)$，它利用了前一时刻右侧项的值。当绝对残差或 Newton 修正足够小时，就宣告 Newton 方法收敛。给定容差 $\\varepsilon_{\\mathrm{abs}}$ 和 $\\varepsilon_{\\mathrm{rel}}$，如果满足以下条件，我们就接受迭代结果\n$$\n|F(y^{(k+1)})| \\le \\varepsilon_{\\mathrm{abs}} \\quad \\text{或} \\quad |\\Delta y^{(k)}| \\le \\varepsilon_{\\mathrm{rel}} \\max\\{1, |y^{(k+1)}|\\}.\n$$\n我们用 $m_{\\max}$ 来限制 Newton 迭代的次数，以避免在不收敛的情况下出现无限循环。\n\n自适应时间步长逻辑使用 Newton 迭代次数作为步长难度的代理指标：\n- 如果一次成功的 Newton 求解使用了在期望范围 $[m_{\\mathrm{lo}}, m_{\\mathrm{hi}}]$ 内的 $m$ 次迭代，则下一步长保持不变。如果太容易，$m \\le m_{\\mathrm{lo}}$，我们用增长因子 $g$ 增加 $h$；如果太难，$m > m_{\\mathrm{hi}}$，我们用收缩因子 $s$ 减小 $h$。这种启发式方法旨在使非线性求解保持适度的挑战性但又高效。\n- 如果 Newton 方法在当前步骤尝试中未能在 $m_{\\max}$ 次迭代内收敛，我们用一个更激进的因子 $s_{\\mathrm{fail}}$ 来减小步长，并重试同一步骤。这是一种安全措施，通过在 $h \\to 0$ 时减小局部非线性强度来强制收敛。\n\n我们还强制执行边界 $h_{\\min} \\le h \\le h_{\\max}$ 并通过对最后一个增量取 $h = \\min\\{h, T - t_n\\}$ 来确保最后一步不会超过最终时间 $T$。为谨慎起见，初始步长选择为 $h_0 = \\min\\{10^{-2}, (T - t_0)/10\\}$。\n\n对于三个标量测试问题，我们提供了 $f(t,y)$ 及其偏导数 $f_y(t,y)$，它们是计算 $F$ 和 $F'$ 所必需的：\n1. 刚性线性衰减，其中 $a = 100$：$f(t,y) = -a y$ 和 $f_y(t,y) = -a$。\n2. 逻辑斯谛增长，其中 $r = 30$：$f(t,y) = r y (1 - y)$ 和 $f_y(t,y) = r (1 - 2 y)$。\n3. 受迫稳定线性系统，其中 $\\lambda = 50$：$f(t,y) = -\\lambda (y - \\sin t)$，$f_y(t,y) = -\\lambda$，角度以弧度为单位。\n\n针对一个 IVP 的算法大纲：\n- 初始化 $t \\leftarrow t_0$, $y \\leftarrow y_0$, $h \\leftarrow h_0$。\n- 当 $t  T$ 时：\n  - 设置 $h \\leftarrow \\min\\{h, T - t\\}$。\n  - 形成 $t_{\\text{new}} = t + h$ 和预测子 $y^{(0)} = y + h\\, f(t, y)$。\n  - 从 $y^{(0)}$ 开始，对 $F(y) = y - y_{\\text{prev}} - h f(t_{\\text{new}}, y)$ 及其导数 $F'(y) = 1 - h f_y(t_{\\text{new}}, y)$ 运行 Newton 迭代。\n  - 如果 Newton 方法在 $m_{\\max}$ 次迭代内收敛，则接受 $y \\leftarrow y^{\\star}$ 和 $t \\leftarrow t_{\\text{new}}$，记录 $m$ 并使用带有因子 $g$、s 和限制 $h_{\\min}$、h_{\\max} 的控制器来调整 $h$。\n  - 如果 Newton 方法失败，则减小 $h \\leftarrow \\max\\{h \\cdot s_{\\mathrm{fail}}, h_{\\min}\\}$ 并重试同一步骤。如果 $h$ 达到 $h_{\\min}$ 仍然失败，算法将停止；对于我们选择的测试问题和参数，收敛会在此边界之前达到。\n\n使用的数值参数是：\n- $\\varepsilon_{\\mathrm{abs}} = 10^{-10}$, $\\varepsilon_{\\mathrm{rel}} = 10^{-10}$, $m_{\\max} = 20$,\n- $m_{\\mathrm{lo}} = 2$, $m_{\\mathrm{hi}} = 4$, $g = 1.5$, $s = 0.7$, $s_{\\mathrm{fail}} = 0.3$,\n- $h_0 = \\min\\{10^{-2}, (T - t_0)/10\\}$, $h_{\\min} = 10^{-6}$, $h_{\\max} = 2 \\times 10^{-1}$。\n\n将此方案应用于测试套件，会为每个 IVP 生成一个最终值 $y(T)$。输出必须是包含三个值的单行字符串，按所列顺序格式化为小数点后六位。隐式方法与基于迭代次数的自适应性相结合，确保了对刚性线性问题的鲁棒性，并在 Newton 方法快速收敛时通过步长增长提高了效率。逻辑斯谛案例检验了非线性部分，而受迫线性案例则检查了对含弧度角度的随时间变化的外力的正确处理。$h_{\\min}$、$h_{\\max}$ 和控制器参数的选择，在不依赖显式局部截断误差估计器的情况下，平衡了稳定性、收敛性和计算效率，遵守了步长由 Newton 迭代次数控制的要求。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef newton_solve(y_prev, t_prev, t_new, h, f, df_dy,\n                 atol=1e-10, rtol=1e-10, maxit=20):\n    \"\"\"\n    Solve F(y) = y - y_prev - h * f(t_new, y) = 0 by Newton's method.\n    Returns (y_star, iterations, success).\n    \"\"\"\n    # Explicit Euler predictor as initial guess\n    y = y_prev + h * f(t_prev, y_prev)\n\n    def F(val):\n        return val - y_prev - h * f(t_new, val)\n\n    def dF(val):\n        return 1.0 - h * df_dy(t_new, val)\n\n    # Evaluate initial residual\n    for k in range(maxit):\n        Fy = F(y)\n        dFy = dF(y)\n        # Safeguard: if derivative is extremely small, abort to avoid blow-up\n        if dFy == 0.0:\n            return y, k + 1, False\n        delta = -Fy / dFy\n        y_next = y + delta\n        # Check stopping conditions\n        if abs(Fy) = atol or abs(delta) = rtol * max(1.0, abs(y_next)):\n            return y_next, k + 1, True\n        y = y_next\n\n    # If we reached max iterations without satisfying stopping criteria\n    return y, maxit, False\n\n\ndef solve_ivp_adaptive(t0, y0, T, f, df_dy,\n                       h0, h_min, h_max,\n                       m_lo=2, m_hi=4, grow=1.5, shrink=0.7, fail_shrink=0.3,\n                       newton_atol=1e-10, newton_rtol=1e-10, newton_maxit=20):\n    \"\"\"\n    Backward Euler with Newton solve and adaptive step size controlled by\n    Newton iteration count.\n    \"\"\"\n    t = t0\n    y = y0\n    h = min(h0, T - t0)\n    # Safety to avoid infinite loops\n    max_total_steps = 10_000\n\n    steps = 0\n    while t  T and steps  max_total_steps:\n        # Do not overshoot final time\n        h = min(h, T - t)\n        # Attempt Newton solve at this step\n        y_star, iters, ok = newton_solve(\n            y_prev=y, t_prev=t, t_new=t + h, h=h,\n            f=f, df_dy=df_dy, atol=newton_atol, rtol=newton_rtol, maxit=newton_maxit\n        )\n\n        if ok:\n            # Accept the step\n            t += h\n            y = y_star\n            # Adapt step size for next step based on iteration count\n            if iters = m_lo:\n                h = min(h * grow, h_max)\n            elif iters = m_hi:\n                # keep h unchanged\n                h = min(max(h, h_min), h_max)\n            else:\n                h = max(h * shrink, h_min)\n        else:\n            # Newton failed: shrink and retry same step\n            new_h = max(h * fail_shrink, h_min)\n            # If we are at minimum and still cannot converge, break\n            if new_h == h:\n                break\n            h = new_h\n\n        steps += 1\n\n    return y\n\n\ndef build_problems():\n    # Define ODEs and their y-derivatives for the test suite\n    def lin_f_factory(a):\n        def f(t, y):\n            return -a * y\n        def df_dy(t, y):\n            return -a\n        return f, df_dy\n\n    def logistic_f_factory(r):\n        def f(t, y):\n            return r * y * (1.0 - y)\n        def df_dy(t, y):\n            return r * (1.0 - 2.0 * y)\n        return f, df_dy\n\n    def forced_f_factory(lam):\n        def f(t, y):\n            return -lam * (y - np.sin(t))\n        def df_dy(t, y):\n            return -lam\n        return f, df_dy\n\n    problems = []\n    # Problem 1: Stiff linear decay\n    f1, df1 = lin_f_factory(a=100.0)\n    problems.append({\n        \"t0\": 0.0, \"y0\": 1.0, \"T\": 1.0,\n        \"f\": f1, \"df_dy\": df1\n    })\n    # Problem 2: Logistic growth\n    f2, df2 = logistic_f_factory(r=30.0)\n    problems.append({\n        \"t0\": 0.0, \"y0\": 1.0e-2, \"T\": 2.0,\n        \"f\": f2, \"df_dy\": df2\n    })\n    # Problem 3: Forced stable linear system\n    f3, df3 = forced_f_factory(lam=50.0)\n    problems.append({\n        \"t0\": 0.0, \"y0\": 0.0, \"T\": 3.0,\n        \"f\": f3, \"df_dy\": df3\n    })\n\n    return problems\n\n\ndef solve():\n    # Controller and Newton parameters as specified\n    newton_atol = 1e-10\n    newton_rtol = 1e-10\n    newton_maxit = 20\n    m_lo, m_hi = 2, 4\n    grow, shrink, fail_shrink = 1.5, 0.7, 0.3\n    h_min, h_max = 1e-6, 2e-1\n\n    problems = build_problems()\n    results = []\n\n    for prob in problems:\n        t0 = prob[\"t0\"]\n        y0 = prob[\"y0\"]\n        T = prob[\"T\"]\n        f = prob[\"f\"]\n        df_dy = prob[\"df_dy\"]\n\n        # Initial step size rule: min(1e-2, (T - t0)/10)\n        h0 = min(1e-2, (T - t0) / 10.0)\n\n        yT = solve_ivp_adaptive(\n            t0=t0, y0=y0, T=T, f=f, df_dy=df_dy,\n            h0=h0, h_min=h_min, h_max=h_max,\n            m_lo=m_lo, m_hi=m_hi, grow=grow, shrink=shrink, fail_shrink=fail_shrink,\n            newton_atol=newton_atol, newton_rtol=newton_rtol, newton_maxit=newton_maxit\n        )\n        results.append(yT)\n\n    # Format to exactly six decimals as required\n    formatted = [f\"{val:.6f}\" for val in results]\n    print(f\"[{','.join(formatted)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}