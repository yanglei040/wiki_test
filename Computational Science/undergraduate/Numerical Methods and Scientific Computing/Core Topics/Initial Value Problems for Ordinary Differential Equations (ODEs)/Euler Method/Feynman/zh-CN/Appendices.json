{
    "hands_on_practices": [
        {
            "introduction": "欧拉法是求解常微分方程（ODE）最基础的数值方法。本练习旨在帮助你迈出第一步，通过一个简单的单步计算，你将亲手应用欧拉法的核心公式。这个过程将直观地展示如何使用初始点的切线来近似一小步后的函数值，这是理解所有更复杂数值方法的基础 。",
            "id": "2172233",
            "problem": "考虑由一阶常微分方程定义的初值问题：\n$$y'(t) = y - t^2$$\n初始条件为 $y(0) = 1$。\n\n您的任务是使用欧拉方法执行单步计算，以近似求解在 $t = 0.2$ 处的解。使用步长 $h = 0.2$。请将您的最终答案以数值形式呈现。",
            "solution": "我们对初值问题 $y'(t)=f(t,y)=y-t^{2}$（其中 $y(0)=1$ 且步长 $h=0.2$）应用一步显式欧拉方法。欧拉更新公式为\n$$\ny_{n+1}=y_{n}+h\\,f(t_{n},y_{n}).\n$$\n当 $t_{0}=0$，$y_{0}=1$ 且 $h=0.2$ 时，我们计算\n$$\nf(t_{0},y_{0})=f(0,1)=1-0^{2}=1,\n$$\n因此\n$$\ny_{1}=y_{0}+h\\,f(t_{0},y_{0})=1+0.2\\cdot 1=1.2.\n$$\n因此，在 $t=0.2$ 处的欧拉近似值为 $y(0.2)\\approx 1.2$。",
            "answer": "$$\\boxed{1.2}$$"
        },
        {
            "introduction": "掌握了欧拉法的基本应用后，探索步长 $h$ 的选择对结果的影响至关重要。本练习将引导你使用两种不同的步长来求解同一个初值问题，并比较它们的结果 。通过这个对比，你将直观地理解为何减小步长通常能提高近似精度，这是数值分析中的一个核心概念。",
            "id": "2172241",
            "problem": "考虑由常微分方程 $y'(t) = -2y(t)$ 及初始条件 $y(0) = 1$ 给出的初值问题 (IVP)。我们希望使用欧拉方法来近似 $y(1)$ 的值。\n\n令 $A_1$ 为使用欧拉方法，以步长 $h=1$ 进行单步计算得到的 $y(1)$ 的近似值。\n令 $A_{0.5}$ 为使用欧拉方法，以步长 $h=0.5$ 进行两步计算得到的 $y(1)$ 的近似值。\n\n计算表达式 $3A_1 - 2A_{0.5}$ 的值。",
            "solution": "我们应用显式欧拉方法，对于一个初值问题 $y'(t)=f(t,y)$，其步长为 $h$ 的迭代格式为\n$$\ny_{n+1}=y_{n}+h\\,f(t_{n},y_{n}).\n$$\n此处 $f(t,y)=-2y$，所以\n$$\ny_{n+1}=y_{n}+h(-2y_{n})=y_{n}(1-2h).\n$$\n\n从 $t_{0}=0$ 到 $t_{1}=1$ 的单步计算，步长 $h=1$：\n$$\ny_{1}=y_{0}(1-2\\cdot 1)=1\\cdot(-1)=-1,\n$$\n所以 $A_{1}=-1$。\n\n从 $t_{0}=0$ 到 $t_{2}=1$ 的两步计算，步长 $h=0.5$：\n第一步到 $t_{1}=0.5$：\n$$\ny_{1}=y_{0}(1-2\\cdot 0.5)=1\\cdot(1-1)=0.\n$$\n第二步到 $t_{2}=1$：\n$$\ny_{2}=y_{1}(1-2\\cdot 0.5)=0\\cdot(1-1)=0,\n$$\n所以 $A_{0.5}=0$。\n\n因此，\n$$\n3A_{1}-2A_{0.5}=3(-1)-2(0)=-3.\n$$",
            "answer": "$$\\boxed{-3}$$"
        },
        {
            "introduction": "从分析走向综合，我们不仅要理解误差，更要设法消除它。本练习介绍了一种名为理查森外推（Richardson Extrapolation）的强大技术，它利用了误差与步长之间的系统关系 。你将学习如何结合不同步长下的计算结果来构造一个更高阶的近似解，从而显著提升计算精度，并将这一理论付诸实践。",
            "id": "3226253",
            "problem": "考虑一个常微分方程 (ODE) 的初值问题 (IVP)，其形式为 $y'(t) = f(t, y(t))$，初始条件为 $y(t_0) = y_0$。前向欧拉法源于导数作为有限差分极限的基本定义以及一阶泰勒展开的应用。在实践中，前向欧拉法通过从 $t_0$ 开始以步长 $h$ 推进解，直到指定最终时间 $T$，来更新精确解 $y(t_n)$ 的近似值 $y_n$，从而得到在 $T$ 处的近似值，我们记为 $y_h(T)$。已知在对 $f$ 和 $y(t)$ 的标准正则性假设下，前向欧拉法的全局离散误差与步长 $h$ 呈线性关系。\n\n你的任务是：\n1. 实现一个函数，用于对任意给定的函数 $f(t,y)$、初始条件 $y_0$、初始时间 $t_0$、最终时间 $T$ 和均匀步长 $h$ 计算 $y_h(T)$，假设 $T - t_0$ 是 $h$ 的整数倍。\n2. 假设欧拉法在 $T$ 处的近似值具有形式为 $y_h(T) = y(T) + C h + D h^2 + \\mathcal{O}(h^3)$ 的渐近误差展开，其中常数 $C$ 和 $D$ 依赖于 $f$ 和解，但不依赖于 $h$。使用输出 $y_h(T)$ 和 $y_{h/2}(T)$，推导这两个近似值的线性组合（其常数权重与 $h$ 无关），以消除首项 $\\mathcal{O}(h)$ 误差项，并得到一个 $\\mathcal{O}(h^2)$ 精度的 $y(T)$ 估计值。然后在代码中实现这个 Richardson 外推估计器。\n3. 对于下方的每个测试用例，计算绝对误差 $\\lvert y_{\\text{extrap}}(T) - y(T) \\rvert$，其中 $y_{\\text{extrap}}(T)$ 是你的外推估计值，$y(T)$ 是在时间 $T$ 的精确解。\n\n使用以下测试套件。在所有情况下，取 $t_0 = 0$ 并使用提供的 $h$ 以确保 $(T - t_0)/h$ 为整数：\n\n- 测试 1（顺利路径，线性齐次 ODE）：$f(t,y) = y$，$y_0 = 1$，$T = 1$，$h = 0.2$。精确解为 $y(t) = e^{t}$ 在 $t = T$ 处的值。\n- 测试 2（线性非齐次 ODE）：$f(t,y) = y + t$，$y_0 = 0$，$T = 2$，$h = 0.4$。精确解为 $y(t) = e^{t} - t - 1$ 在 $t = T$ 处的值。\n- 测试 3（非线性逻辑斯蒂增长）：$f(t,y) = r y \\left(1 - \\frac{y}{K}\\right)$，参数为 $r = 1$ 和 $K = 10$，$y_0 = 1$，$T = 3$，$h = 0.5$。精确解为 $y(t) = \\frac{K}{1 + A e^{-r t}}$，其中 $A = \\frac{K - y_0}{y_0}$，在 $t = T$ 处的值。\n- 测试 4（边缘情况，零导数）：$f(t,y) = 0$，$y_0 = 3$，$T = 1$，$h = 0.5$。精确解为常数函数 $y(t) = 3$ 在 $t = T$ 处的值。\n\n你的程序应该：\n- 实现前向欧拉法，为每个测试用例计算 $y_h(T)$ 和 $y_{h/2}(T)$。\n- 使用两个近似值 $y_h(T)$ 和 $y_{h/2}(T)$ 实现所推导的 Richardson 外推估计器，以获得在 $T$ 处的 $\\mathcal{O}(h^2)$ 估计。\n- 计算并记录每个测试用例的绝对误差，四舍五入到十位小数。\n\n最终输出格式：\n你的程序应产生单行输出，其中包含一个逗号分隔的列表，用方括号括起来（例如，\"[0.0123456789,0.0000001234,0.0012340000,0.0000000000]\"），列表中的条目是测试 1 到测试 4 的绝对误差，每个都四舍五入到十位小数。",
            "solution": "该问题被评估为有效。\n\n### 第一步：提取既定条件\n- **问题类型**：常微分方程 (ODE) 的初值问题 (IVP)。\n- **ODE 形式**：$y'(t) = f(t, y(t))$。\n- **初始条件**：$y(t_0) = y_0$。\n- **数值方法**：前向欧拉法，其中 $y_{n+1} = y_n + h f(t_n, y_n)$。\n- **最终时间 $T$ 处的近似值**：$y_h(T)$。\n- **渐近误差展开**：$y_h(T) = y(T) + C h + D h^2 + \\mathcal{O}(h^3)$。\n- **约束条件**：$T - t_0$ 是步长 $h$ 的整数倍。\n- **任务 1**：实现一个前向欧拉法函数，用于计算 $y_h(T)$。\n- **任务 2**：推导并实现一个对 $y(T)$ 的 Richardson 外推估计器，其精度为 $\\mathcal{O}(h^2)$，使用 $y_h(T)$ 和 $y_{h/2}(T)$。\n- **任务 3**：为四个测试用例计算绝对误差 $\\lvert y_{\\text{extrap}}(T) - y(T) \\rvert$。\n- **所有用例的初始时间**：$t_0 = 0$。\n\n- **测试用例 1**：\n  - $f(t,y) = y$\n  - $y_0 = 1$\n  - $T = 1$\n  - $h = 0.2$\n  - 精确解：$y(t) = e^{t}$\n\n- **测试用例 2**：\n  - $f(t,y) = y + t$\n  - $y_0 = 0$\n  - $T = 2$\n  - $h = 0.4$\n  - 精确解：$y(t) = e^{t} - t - 1$\n\n- **测试用例 3**：\n  - $f(t,y) = r y \\left(1 - \\frac{y}{K}\\right)$，其中 $r = 1, K = 10$\n  - $y_0 = 1$\n  - $T = 3$\n  - $h = 0.5$\n  - 精确解：$y(t) = \\frac{K}{1 + A e^{-r t}}$，其中 $A = \\frac{K - y_0}{y_0}$\n\n- **测试用例 4**：\n  - $f(t,y) = 0$\n  - $y_0 = 3$\n  - $T = 1$\n  - $h = 0.5$\n  - 精确解：$y(t) = 3$\n\n### 第二步：使用提取的既定条件进行验证\n该问题具有科学依据，是适定且客观的。\n1.  **科学或事实的可靠性**：该问题建立在常微分方程数值分析的基本概念之上。前向欧拉法、其误差分析以及 Richardson 外推是标准的、数学上可靠的技术。所提供的常微分方程是教学和研究中使用的经典例子。该问题没有任何科学或事实错误。\n2.  **适定性**：该问题是适定的。对于每个测试用例，函数 $f(t,y)$ 都足够光滑（在 $y$ 上是利普希茨连续的），这保证了初值问题解的存在性和唯一性。任务定义清晰，所有必要的数据（初始条件、参数、时间区间）都已提供。\n3.  **客观性**：语言精确且不偏不倚。任务是定量的，需要具体的计算，没有主观解释的余地。\n4.  **完整性**：该问题是自洽的。它指定了常微分方程、初始条件、步长、最终时间以及用于误差比较的精确解。约束条件 $(T - t_0)/h$ 为整数简化了实现，避免了歧义。\n\n### 第三步：结论与行动\n该问题是**有效**的。将提供一个完整的解决方案。\n\n### 基于原理的解决方案\n解决方案分三个阶段展开：首先，实现前向欧拉法；其次，推导 Richardson 外推公式；第三，将这些方法应用于指定的测试用例以计算所需的误差。\n\n**1. 前向欧拉法**\n前向欧拉法是求解形如 $y'(t) = f(t, y(t))$ 且 $y(t_0) = y_0$ 的初值问题的一阶数值方法。它在离散时间点 $t_n = t_0 + n h$ 处近似连续解 $y(t)$，其中 $h$ 是步长。该方法源于 $y(t_{n+1})$ 在 $t_n$ 附近的一阶泰勒展开：\n$y(t_{n+1}) = y(t_n) + h y'(t_n) + \\mathcal{O}(h^2) = y(t_n) + h f(t_n, y(t_n)) + \\mathcal{O}(h^2)$。\n通过忽略 $\\mathcal{O}(h^2)$ 项，我们得到近似值 $y_n \\approx y(t_n)$ 的迭代公式：\n$$y_{n+1} = y_n + h f(t_n, y_n)$$\n从初始条件 $y_0$ 开始，我们可以对 $n = 0, 1, 2, \\dots, N-1$（其中 $N = (T-t_0)/h$）迭代应用此公式，以找到近似值 $y_N \\approx y(T)$。这定义了函数 $y_h(T)$。\n\n**2. Richardson 外推**\nRichardson 外推是一种提高数值近似精度的通用技术。我们已知前向欧拉法的近似值 $y_h(T)$ 具有渐近误差展开：\n$$y_h(T) = y(T) + C h + D h^2 + \\mathcal{O}(h^3)$$\n在这里，$y(T)$ 是精确解，而 $C$ 和 $D$ 是依赖于函数 $f$ 及其导数但不依赖于步长 $h$ 的常数。\n\n如果我们使用减半的步长 $h/2$ 再次计算近似值，公式变为：\n$$y_{h/2}(T) = y(T) + C \\left(\\frac{h}{2}\\right) + D \\left(\\frac{h}{2}\\right)^2 + \\mathcal{O}(h^3)$$\n$$y_{h/2}(T) = y(T) + \\frac{1}{2} C h + \\frac{1}{4} D h^2 + \\mathcal{O}(h^3)$$\n我们的目标是找到 $y_h(T)$ 和 $y_{h/2}(T)$ 的一个线性组合，我们将其表示为 $y_{\\text{extrap}}(T)$，它能为 $y(T)$ 提供一个更精确的估计。令 $y_{\\text{extrap}}(T) = \\alpha y_h(T) + \\beta y_{h/2}(T)$。代入误差展开式：\n$$y_{\\text{extrap}}(T) = \\alpha \\left(y(T) + C h + D h^2\\right) + \\beta \\left(y(T) + \\frac{1}{2} C h + \\frac{1}{4} D h^2\\right) + \\mathcal{O}(h^3)$$\n$$y_{\\text{extrap}}(T) = (\\alpha + \\beta) y(T) + \\left(\\alpha + \\frac{\\beta}{2}\\right) C h + \\left(\\alpha + \\frac{\\beta}{4}\\right) D h^2 + \\mathcal{O}(h^3)$$\n为了得到一个对 $y(T)$ 的 $\\mathcal{O}(h^2)$ 精度估计，我们要求 $y(T)$ 的系数为 $1$，并且首项误差项 $Ch$ 的系数为 $0$。这给出了一个关于 $\\alpha$ 和 $\\beta$ 的两个线性方程组：\n1. $\\alpha + \\beta = 1$\n2. $\\alpha + \\frac{\\beta}{2} = 0$\n从方程 (2) 中，我们得到 $\\alpha = -\\beta/2$。将其代入方程 (1) 得到 $-\\beta/2 + \\beta = 1$，化简为 $\\beta/2 = 1$，所以 $\\beta = 2$。因此，$\\alpha = -1$。\n于是，外推估计器为：\n$$y_{\\text{extrap}}(T) = 2 y_{h/2}(T) - y_h(T)$$\n让我们验证这个新估计的误差：\n$$y_{\\text{extrap}}(T) - y(T) = (2 y_{h/2}(T) - y_h(T)) - y(T)$$\n$$= \\left(2\\left(y(T) + \\frac{1}{2}Ch + \\frac{1}{4}Dh^2\\right) - \\left(y(T) + Ch + Dh^2\\right)\\right) - y(T) + \\mathcal{O}(h^3)$$\n$$= (2y(T) + Ch + \\frac{1}{2}Dh^2) - y(T) - Ch - Dh^2 - y(T) + \\mathcal{O}(h^3)$$\n$$= (2-1-1)y(T) + (1-1)Ch + (\\frac{1}{2}-1)Dh^2 + \\mathcal{O}(h^3) = -\\frac{1}{2} D h^2 + \\mathcal{O}(h^3)$$\n误差确实是 $h^2$ 阶的，因此该方法成功地消除了首项误差项。\n\n**3. 计算步骤**\n对于四个测试用例中的每一个，应用以下算法：\n1.  定义函数 $f(t,y)$、初始条件 $y_0, t_0$、最终时间 $T$ 和步长 $h$。\n2.  实现一个函数 `forward_euler(f, y0, t0, T, h)`，该函数执行迭代的欧拉更新并返回在时间 $T$ 的最终近似值。步数 $N$ 计算为整数 `(T - t0) / h`。\n3.  使用给定的步长 $h$ 计算近似值：$A_h = \\text{forward_euler}(f, y_0, t_0, T, h)$。\n4.  使用减半的步长 $h/2$ 计算近似值：$A_{h/2} = \\text{forward_euler}(f, y_0, t_0, T, h/2)$。\n5.  计算 Richardson 外推值：$y_{\\text{extrap}}(T) = 2 A_{h/2} - A_h$。\n6.  使用为特定测试用例提供的公式计算精确解 $y(T)$。\n7.  计算绝对误差：$E = \\lvert y_{\\text{extrap}}(T) - y(T) \\rvert$。\n8.  该测试用例的最终结果是此误差，四舍五入到十位小数。对所有测试用例重复此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes absolute errors for Richardson-extrapolated Euler method solutions\n    for a suite of ODE test cases.\n    \"\"\"\n\n    def forward_euler(f, y0, t0, T, h):\n        \"\"\"\n        Computes the solution of an IVP y'(t) = f(t, y) with y(t0) = y0 at time T\n        using the forward Euler method with step size h.\n        \"\"\"\n        t = t0\n        y = y0\n        \n        # The problem statement guarantees (T - t0) / h is an integer.\n        # Using int() directly is safe, but rounding is more robust for floats.\n        num_steps = int(round((T - t0) / h))\n\n        for _ in range(num_steps):\n            y = y + h * f(t, y)\n            t = t + h\n        \n        return y\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"f\": lambda t, y: y,\n            \"y0\": 1.0,\n            \"t0\": 0.0,\n            \"T\": 1.0,\n            \"h\": 0.2,\n            \"exact_sol\": lambda t: np.exp(t)\n        },\n        {\n            \"f\": lambda t, y: y + t,\n            \"y0\": 0.0,\n            \"t0\": 0.0,\n            \"T\": 2.0,\n            \"h\": 0.4,\n            \"exact_sol\": lambda t: np.exp(t) - t - 1.0\n        },\n        {\n            \"f\": lambda t, y: 1.0 * y * (1.0 - y / 10.0), # r=1, K=10\n            \"y0\": 1.0,\n            \"t0\": 0.0,\n            \"T\": 3.0,\n            \"h\": 0.5,\n            \"exact_sol\": lambda t: 10.0 / (1.0 + ((10.0 - 1.0) / 1.0) * np.exp(-1.0 * t))\n        },\n        {\n            \"f\": lambda t, y: 0.0,\n            \"y0\": 3.0,\n            \"t0\": 0.0,\n            \"T\": 1.0,\n            \"h\": 0.5,\n            \"exact_sol\": lambda t: 3.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        f = case[\"f\"]\n        y0 = case[\"y0\"]\n        t0 = case[\"t0\"]\n        T = case[\"T\"]\n        h = case[\"h\"]\n        exact_sol_func = case[\"exact_sol\"]\n\n        # 1. Compute approximations with step sizes h and h/2\n        y_h = forward_euler(f, y0, t0, T, h)\n        y_h_half = forward_euler(f, y0, t0, T, h / 2.0)\n\n        # 2. Apply Richardson extrapolation\n        y_extrap = 2.0 * y_h_half - y_h\n\n        # 3. Compute the exact solution\n        y_exact = exact_sol_func(T)\n        \n        # 4. Compute the absolute error\n        abs_error = abs(y_extrap - y_exact)\n        \n        results.append(abs_error)\n\n    # Format the results as strings rounded to 10 decimal places\n    # The f-string formatting ensures trailing zeros as in the example.\n    # The rounding prior to formatting correctly handles cases near the rounding boundary.\n    results_str = [f\"{round(res, 10):.10f}\" for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        }
    ]
}