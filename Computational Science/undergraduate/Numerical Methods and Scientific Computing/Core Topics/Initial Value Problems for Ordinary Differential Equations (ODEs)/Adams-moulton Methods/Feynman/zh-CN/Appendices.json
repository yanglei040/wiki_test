{
    "hands_on_practices": [
        {
            "introduction": "要真正理解 Adams-Moulton 方法，最好的方式就是亲手实践。我们将从一个具体的计算开始，完整地走过一个预测-校正（Predictor-Corrector）步骤。这个练习旨在阐明显式预测方法（如此处使用的 Adams-Bashforth 法）和隐式校正方法（Adams-Moulton 法）各自的角色，并展示在一个时间步长内信息是如何流动的，从而为掌握更复杂的应用打下坚实的基础。通过完成这个计算，你将对该算法的核心机制有更直观的认识。",
            "id": "2152822",
            "problem": "考虑由常微分方程 $y'(t) = y(t) - t^2 + 1$ 定义的初值问题。假设我们使用固定步长 $h = 0.2$ 的数值方法来近似求解。我们已知近似解曲线上的前两个点：在 $t_0 = 0.0$ 时，值为 $y_0 = 0.5$，在 $t_1 = 0.2$ 时，值为 $y_1 = 0.82930$。\n\n您的任务是通过应用以下预测-校正格式的单步，计算在时间 $t_2 = 0.4$ 时的下一个值 $y_2$。\n\n首先，使用以下公式计算预测值 $y_{i+1}^*$：\n$$y_{i+1}^* = y_i + \\frac{h}{2}\\left(3f(t_i, y_i) - f(t_{i-1}, y_{i-1})\\right)$$\n其中 $f(t,y) = y'(t)$。\n\n其次，使用此预测值，通过以下公式计算校正值 $y_{i+1}$：\n$$y_{i+1} = y_i + \\frac{h}{2}\\left(f(t_{i+1}, y_{i+1}^*) + f(t_i, y_i)\\right)$$\n\n报告最终的校正值 $y_2$。将您的最终答案四舍五入到五位有效数字。",
            "solution": "我们已知常微分方程 $y'(t)=f(t,y)=y-t^{2}+1$ 和步长 $h=0.2$，以及已知值 $(t_{0},y_{0})=(0.0,0.5)$ 和 $(t_{1},y_{1})=(0.2,0.82930)$。我们的目标是使用指定的预测-校正格式计算在 $t_{2}=0.4$ 时的 $y_{2}$。\n\n首先计算在已知点处所需的函数值：\n$$f(t_{0},y_{0})=y_{0}-t_{0}^{2}+1=0.5-0+1=1.5,$$\n$$f(t_{1},y_{1})=y_{1}-t_{1}^{2}+1=0.82930-0.04+1=1.78930.$$\n\n预测步（两步Adams-Bashforth法）：\n$$y_{2}^{*}=y_{1}+\\frac{h}{2}\\left(3f(t_{1},y_{1})-f(t_{0},y_{0})\\right)\n=0.82930+0.1\\left(3\\cdot 1.78930-1.5\\right)=0.82930+0.1\\cdot 3.86790=1.216090.$$\n\n在预测点 $(t_{2},y_{2}^{*})=(0.4,1.216090)$ 处计算 $f$ 的值：\n$$f(t_{2},y_{2}^{*})=y_{2}^{*}-t_{2}^{2}+1=1.216090-0.16+1=2.056090.$$\n\n校正步（使用预测端点值的梯形步）：\n$$y_{2}=y_{1}+\\frac{h}{2}\\left(f(t_{2},y_{2}^{*})+f(t_{1},y_{1})\\right)\n=0.82930+0.1\\left(2.056090+1.78930\\right)\n=0.82930+0.3845390=1.2138390.$$\n\n四舍五入到五位有效数字得到 $1.2138$。",
            "answer": "$$\\boxed{1.2138}$$"
        },
        {
            "introduction": "在了解了单步计算流程后，一个关键问题随之而来：我们如何求解隐式的 Adams-Moulton 方程来得到下一步的解 $y_{n+1}$？这个练习将引导你探讨一种常见的求解策略——不动点迭代，并揭示其在处理特定类型问题（即刚性常微分方程）时的局限性。通过推导迭代函数并计算其 Lipschitz 常数 $L$，你将从根本上理解为什么当 $L \\ge 1$ 时，简单的迭代格式无法保证收敛，这也凸显了在实际应用中采用更稳健求解器（如牛顿法）的必要性。",
            "id": "3203180",
            "problem": "考虑标量常微分方程 $y^{\\prime}(t)=f(t,y(t))$ 的初值问题，其中 $f(t,y)=10\\,y+\\sin(t)$。设 $t_{n}$ 和 $t_{n+1}=t_{n}+h$ 为两个连续的时间层，步长 $h=0.3$。将使用预测-校正格式，其中校正子是二阶 Adams–Moulton 方法（也称为隐式梯形法则），校正方程将通过形式为 $y_{n+1}^{(k+1)}=g\\!\\left(y_{n+1}^{(k)}\\right)$ 的不动点迭代来求解。\n\n从基本恒等式 $y(t_{n+1})=y(t_{n})+\\int_{t_{n}}^{t_{n+1}} f\\!\\left(t,y(t)\\right)\\,dt$ 出发，并使用应用于 $f$ 的梯形法则来近似该积分，推导出隐式校正方程，并由此得到作为 $y_{n+1}$ 函数的不动点映射 $g$。使用关于 $y_{n+1}$ 的映射 $g$ 的 Lipschitz 常数定义，确定在此步中 $g$ 的 Lipschitz 常数 $L$。判断简单不动点迭代是保证收敛还是可能失败。\n\n只需报告 $L$ 的数值，并四舍五入到四位有效数字。",
            "solution": "该问题要求为二阶 Adams-Moulton 方法推导一个不动点迭代格式，并对一个特定的常微分方程 (ODE) 分析其收敛性。出发点是常微分方程 $y'(t) = f(t, y(t))$ 的解 $y(t)$ 的基本积分恒等式：\n$$y(t_{n+1}) = y(t_{n}) + \\int_{t_{n}}^{t_{n+1}} f(t, y(t)) \\, dt$$\n此处，$t_n$ 和 $t_{n+1} = t_n + h$ 是两个连续的时间点，步长为 $h$。\n\n校正方法是二阶 Adams-Moulton 方法，它是通过使用梯形法则来近似积分得到的。函数 $\\phi(t)$ 在 $[t_n, t_{n+1}]$ 上的积分的梯形法则由 $\\int_{t_n}^{t_{n+1}} \\phi(t) \\, dt \\approx \\frac{h}{2}[\\phi(t_n) + \\phi(t_{n+1})]$ 给出。将此法则应用于函数 $f(t, y(t))$ 得到：\n$$\\int_{t_{n}}^{t_{n+1}} f(t, y(t)) \\, dt \\approx \\frac{h}{2} [f(t_n, y(t_n)) + f(t_{n+1}, y(t_{n+1}))]$$\n将此近似代入积分恒等式，并用其数值近似 $y_n$ 替换精确解 $y(t_n)$，我们得到 $y_{n+1}$ 的隐式公式：\n$$y_{n+1} = y_n + \\frac{h}{2} [f(t_n, y_n) + f(t_{n+1}, y_{n+1})]$$\n这就是二阶 Adams-Moulton 方法，也称为隐式梯形法则。该方程是隐式的，因为未知量 $y_{n+1}$ 出现在等式两边。\n\n为了求解这个关于 $y_{n+1}$ 的隐式方程，正如问题所述，使用不动点迭代。迭代形式为 $y_{n+1}^{(k+1)} = g(y_{n+1}^{(k)})$，其中 $k$ 是迭代指数。通过观察该隐式方程，不动点映射 $g$ 由其右侧定义。为避免混淆，我们使用一个通用变量 $z$ 来表示 $g$ 的自变量。映射 $g$ 为：\n$$g(z) = y_n + \\frac{h}{2} [f(t_n, y_n) + f(t_{n+1}, z)]$$\n于是，不动点迭代为 $y_{n+1}^{(k+1)} = g(y_{n+1}^{(k)})$。\n\n为了保证不动点迭代收敛到唯一解，映射 $g$ 必须是感兴趣域上的一个压缩映射。根据压缩映射定理（或 Banach 不动点定理），如果 $g$ 的 Lipschitz 常数 $L$ 严格小于 1，则该条件成立。对于一个连续可微的映射 $g$，其关于变量 $z$ 的 Lipschitz 常数 $L$ 可以取为其导数绝对值的上确界：\n$$L = \\sup_{z} \\left| \\frac{\\partial g}{\\partial z} \\right|$$\n我们计算 $g(z)$ 关于 $z$ 的导数。项 $y_n$ 和 $f(t_n, y_n)$ 都是关于 $z$ 的常数。\n$$\\frac{\\partial g}{\\partial z} = \\frac{\\partial}{\\partial z} \\left( y_n + \\frac{h}{2} f(t_n, y_n) + \\frac{h}{2} f(t_{n+1}, z) \\right) = \\frac{h}{2} \\frac{\\partial f}{\\partial y}(t_{n+1}, z)$$\n注意，$\\frac{\\partial f}{\\partial z}$ 是 $f(t, y)$ 关于其第二个参数 $y$ 的偏导数在 $(t_{n+1}, z)$ 处取值的简写。\n\n问题指定了函数 $f(t, y) = 10y + \\sin(t)$。它关于 $y$ 的偏导数是：\n$$\\frac{\\partial f}{\\partial y}(t, y) = \\frac{\\partial}{\\partial y} (10y + \\sin(t)) = 10$$\n这个偏导数是一个常数，与 $t$ 和 $y$ 都无关。因此，它在 $(t_{n+1}, z)$ 处的值也是 10。\n\n将此结果代回到 $g$ 的导数表达式中：\n$$\\frac{\\partial g}{\\partial z} = \\frac{h}{2} \\times 10 = 5h$$\nLipschitz 常数 $L$ 是该导数绝对值的上确界。由于 $5h$ 是一个常数，我们有：\n$$L = |5h|$$\n问题给出了步长 $h = 0.3$。我们现在可以计算 $L$ 的数值：\n$$L = |5 \\times 0.3| = |1.5| = 1.5$$\n不动点迭代保证收敛的条件是 $L  1$。在本例中，$L = 1.5$，大于 1。因此，映射 $g$ 不是一个压缩映射，并且简单不动点迭代不保证收敛。预计它会发散，除非初始猜测 $y_{n+1}^{(0)}$ 恰好是精确解。\n\n问题要求给出 Lipschitz 常数 $L$ 的数值，并四舍五入到四位有效数字。\n$L = 1.5$。为了用四位有效数字表示，我们写成 $1.500$。",
            "answer": "$$\n\\boxed{1.500}\n$$"
        },
        {
            "introduction": "数值方法的一个核心吸引力在于其精度的可预测性——随着步长 $h$ 的减小，误差会以特定的速率下降，这个速率被称为方法的“收敛阶”。本练习是一个编程实践，要求你通过数值实验来验证 Adams-Moulton 方法族的理论收敛阶。通过为一系列不断减半的步长计算并分析全局误差，你将能够通过对数-对数坐标图上的数据拟合来估算观测到的收敛阶，从而将抽象的理论概念与实际的计算性能联系起来。",
            "id": "3203111",
            "problem": "要求您编写一个完整且可运行的程序，通过分析在均匀步长连续减半时，固定终点时间处的全局误差如何变化，来经验性地验证几种 Adams–Moulton 方法的理论收敛阶。该工作必须完全可复现，无需用户输入。目标是通过对 $\\log E(h)$ 相对于 $\\log h$ 的对数-对数数据进行直线拟合来估计观测收敛阶，其中 $E(h)$ 是在时间 $T$ 的全局误差。\n\n理论基础如下。考虑一个形如下式的常微分方程初值问题\n$$\n\\frac{dy}{dt} = f(t,y), \\quad y(0) = y_0.\n$$\n一个 $s$ 步 Adams–Moulton 方法是一种线性多步法，它通过使用一个穿过节点 $\\{t_{n+1}, t_n, \\dots, t_{n-s+1}\\}$ 的关于 $f$ 的 $s$ 次插值多项式来近似积分\n$$\ny(t_{n+1}) - y(t_n) = \\int_{t_n}^{t_{n+1}} f(t,y(t)) \\, dt\n$$\n这会得到一个形如下式的递推关系\n$$\ny_{n+1} = y_n + h \\sum_{j=0}^{s} b_j f\\!\\left(t_{n+1-j}, y_{n+1-j}\\right),\n$$\n其中常系数 $\\{b_j\\}_{j=0}^s$ 仅取决于 $s$。当 $s=0$ 时，Adams–Moulton 方法对应于隐式欧拉法，其阶为 $p=1$。当 $s=1$ 时，该方法对应于梯形法则，其阶为 $p=2$。通常，$s$ 步 Adams–Moulton 方法的阶为 $p=s+1$。\n\n您的程序必须：\n- 对 $s \\in \\{0,1,2,3\\}$，使用与这些 $s$ 选择相关联的标准系数实现 Adams–Moulton 方法。\n- 将每种方法应用于一个具有已知精确解的问题，首先使用均匀步长 $h$，然后使用减半的步长 $h/2$, $h/4$, $\\dots$。对于给定的 $h$，在网格 $t_k = k h$ 上从 $t=0$ 推进到 $t=T$。对于多步法（即 $s \\ge 1$），您必须使用精确解来初始化前 $s$ 个值 $y_1, \\dots, y_s$，以消除启动误差，从而使方法的渐近阶是可观测的。\n- 对于减半序列中的每个 $h$，计算在 $T$ 处的全局误差，定义为 $E(h) = \\lvert y_N - y_{\\mathrm{exact}}(T) \\rvert$，其中 $Nh = T$。\n- 对每个测试用例，通过最小二乘法对 $\\{(\\log h_i, \\log E(h_i))\\}$ 进行直线拟合，并取其斜率来计算观测阶，该斜率应近似于理论阶 $p$。\n\n三角函数中出现的角度应以弧度为单位。除此角度规定外，不涉及任何物理单位。\n\n使用以下测试套件。每个测试用例都指定了微分方程、通过 $s$ 给出的方法阶、终点时间 $T$、初始步长 $h_0$ 以及生成序列 $\\{h_0, h_0/2, \\dots, h_0/2^{L-1}\\}$ 的减半层次数 $L$。\n\n- 测试用例 1 (边界/刚性，1 阶): $f(t,y) = \\lambda y$，其中 $\\lambda = -50$，$y(0) = 1$，$T=1$，$s=0$，$h_0=0.1$，$L=5$。精确解为 $y(t) = e^{\\lambda t}$。\n- 测试用例 2 (理想路径，2 阶): $f(t,y) = \\lambda y$，其中 $\\lambda = -1$，$y(0) = 1$，$T=1$，$s=1$，$h_0=0.2$，$L=5$。精确解为 $y(t) = e^{\\lambda t}$。\n- 测试用例 3 (理想路径，3 阶): $f(t,y) = \\lambda y$，其中 $\\lambda = -1$，$y(0) = 1$，$T=1$，$s=2$，$h_0=0.2$，$L=5$。精确解为 $y(t) = e^{\\lambda t}$。\n- 测试用例 4 (非齐次强迫项，4 阶): $f(t,y) = \\lambda y + \\sin t$，其中 $\\lambda = -1$，$y(0) = 0$，$T=1$，$s=3$，$h_0=0.2$，$L=5$。精确解为\n$$\ny(t) = e^{\\lambda t} y_0 + \\frac{e^{\\lambda t} - \\lambda \\sin t - \\cos t}{\\lambda^2 + 1}.\n$$\n\n对于上述两个线性模型，利用对于 $f(t,y) = \\lambda y + g(t)$ 且 $g(t)$ 已知的情况，Adams–Moulton 更新步骤可以无需迭代地写为\n$$\ny_{n+1} = \\frac{y_n + h \\lambda \\sum_{j=1}^{s} b_j y_{n+1-j} + h \\sum_{j=0}^{s} b_j g\\!\\left(t_{n+1-j}\\right)}{1 - h b_0 \\lambda},\n$$\n其中在齐次情况下 $g(t) \\equiv 0$。\n\n您的程序必须输出单行，其中包含四个观测阶的逗号分隔列表，四舍五入到两位小数，并用方括号括起来。例如，输出行应如下所示\n$$\n[\\text{order}_1,\\text{order}_2,\\text{order}_3,\\text{order}_4].\n$$",
            "solution": "问题陈述已被验证并被认为是有效的。它具有科学依据、是适定的、客观的，并为一次标准的数值分析练习提供了一个完整且一致的设定。\n\n目标是对于 $s \\in \\{0, 1, 2, 3\\}$，经验性地确定 $s$ 步 Adams-Moulton 方法的收敛阶 $p$。一个 $s$ 步方法的理论收敛阶是 $p = s+1$。该分析将通过求解一个形如 $\\frac{dy}{dt} = f(t,y)$ 且 $y(0) = y_0$ 的初值问题（IVP）直到终点时间 $T$ 来进行。\n\n$s$ 步 Adams-Moulton 方法由以下递推关系定义：\n$$\ny_{n+1} = y_n + h \\sum_{j=0}^{s} b_j f(t_{n+1-j}, y_{n+1-j})\n$$\n其中 $h$ 是步长，$y_n$ 是在时间 $t_n = n h$ 时对解 $y(t_n)$ 的数值近似，$\\{b_j\\}$ 是该方法的系数。测试问题都是线性的，形如 $\\frac{dy}{dt} = \\lambda y + g(t)$，对于这类问题，隐式递推关系可以显式地解出 $y_{n+1}$：\n$$\ny_{n+1} = \\frac{y_n + h \\lambda \\sum_{j=1}^{s} b_j y_{n+1-j} + h \\sum_{j=0}^{s} b_j g(t_{n+1-j})}{1 - h b_0 \\lambda}\n$$\n对于所需的 $s$ 值，标准的 Adams-Moulton 系数如下：\n- 对于 $s=0$ (隐式欧拉法, $p=1$): $\\{b_j\\} = \\{1\\}$。\n- 对于 $s=1$ (梯形法则, $p=2$): $\\{b_j\\} = \\{\\frac{1}{2}, \\frac{1}{2}\\}$。\n- 对于 $s=2$ (AM3, $p=3$): $\\{b_j\\} = \\{\\frac{5}{12}, \\frac{8}{12}, -\\frac{1}{12}\\}$。\n- 对于 $s=3$ (AM4, $p=4$): $\\{b_j\\} = \\{\\frac{9}{24}, \\frac{19}{24}, -\\frac{5}{24}, \\frac{1}{24}\\}$。\n\n收敛阶是通过分析当步长 $h$ 不断缩小时，终点时间的全局误差 $E(h) = |y_N - y_{\\mathrm{exact}}(T)|$（其中 $N h = T$）的行为来确定的。对于一个 $p$ 阶方法，误差的变化规律为 $E(h) \\approx C h^p$，其中 $C$ 是某个常数。对这个关系式取对数，得到：\n$$\n\\log(E(h)) \\approx \\log(C) + p \\log(h)\n$$\n这表明 $\\log(E)$ 和 $\\log(h)$ 之间存在线性关系，其斜率即为收敛阶 $p$。程序将为一系列连续减半的步长 $\\{h_i\\}$ 计算全局误差 $E(h_i)$。然后，通过对数据点 $(\\log h_i, \\log E(h_i))$ 进行线性最小二乘回归计算出的最佳拟合线的斜率，来估计观测收敛阶。\n\n对于多步法（$s \\ge 1$），数值解的前 $s$ 个值 $y_1, \\dots, y_s$ 使用精确解 $y_k = y_{\\mathrm{exact}}(t_k)$ 进行初始化，以便将误差与主时间步进格式分离开，并观察该方法的渐近行为。\n\n程序将遍历四个测试用例，每个用例由一个特定的初值问题和方法阶 $p = s+1$ 定义。\n\n- **测试用例 1：** $s=0$ ($p=1$)，应用于刚性方程 $y'=-50y$, $y(0)=1$ 在区间 $[0,1]$ 上。\n- **测试用例 2：** $s=1$ ($p=2$)，应用于 $y'=-y$, $y(0)=1$ 在区间 $[0,1]$ 上。\n- **测试用例 3：** $s=2$ ($p=3$)，应用于 $y'=-y$, $y(0)=1$ 在区间 $[0,1]$ 上。\n- **测试用例 4：** $s=3$ ($p=4$)，应用于非齐次方程 $y'=-y+\\sin t$, $y(0)=0$ 在区间 $[0,1]$ 上。\n\n对于每个用例，从初始步长 $h_0$ 开始，生成一个包含 $L=5$ 个步长的序列。求解器对每个步长计算在 $T=1$ 时的数值解，记录相应的误差，并通过对对数-对数数据进行线性回归来估计阶数。最终输出将是一个包含四个观测阶的列表，四舍五入到两位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef adams_moulton_solver(s, b_coeffs, lambda_val, g_func, y0, T, h, y_exact_func):\n    \"\"\"\n    Solves a linear ODE y' = lambda*y + g(t) using an s-step Adams-Moulton method.\n\n    Args:\n        s (int): The number of steps in the method (s=0 for 1-step, etc.).\n        b_coeffs (list): The list of method coefficients [b0, b1, ...].\n        lambda_val (float): The coefficient lambda of the ODE.\n        g_func (callable): The function g(t).\n        y0 (float): The initial condition y(0).\n        T (float): The final time.\n        h (float): The step size.\n        y_exact_func (callable): The exact solution function y_exact(t).\n\n    Returns:\n        float: The numerical solution at time T.\n    \"\"\"\n    N = int(np.round(T / h))\n    y = np.zeros(N + 1)\n    y[0] = y0\n\n    # Startup phase for multistep methods (s = 1) using the exact solution.\n    if s  0:\n        for k in range(1, s + 1):\n            if k = N:\n                y[k] = y_exact_func(k * h)\n\n    # Time-stepping loop\n    # The loop computes y[n+1] for n from s to N-1.\n    for n in range(s, N):\n        # Calculate sum_1 = sum_{j=1 to s} b_j * y_{n+1-j}\n        sum1 = 0.0\n        if s  0:\n            for j in range(1, s + 1):\n                sum1 += b_coeffs[j] * y[n + 1 - j]\n        \n        # Calculate sum_2 = sum_{j=0 to s} b_j * g(t_{n+1-j})\n        sum2 = 0.0\n        for j in range(0, s + 1):\n            t_val = (n + 1 - j) * h\n            sum2 += b_coeffs[j] * g_func(t_val)\n        \n        numerator = y[n] + h * lambda_val * sum1 + h * sum2\n        denominator = 1.0 - h * b_coeffs[0] * lambda_val\n        y[n+1] = numerator / denominator\n        \n    return y[N]\n\ndef run_convergence_test(case):\n    \"\"\"\n    Runs the convergence test for a single case.\n    \"\"\"\n    log_h_vals = []\n    log_E_vals = []\n\n    for k in range(case['L']):\n        h = case['h0'] / (2**k)\n        \n        y_numerical = adams_moulton_solver(\n            s=case['s'],\n            b_coeffs=case['b_coeffs'],\n            lambda_val=case['lambda'],\n            g_func=case['g_func'],\n            y0=case['y0'],\n            T=case['T'],\n            h=h,\n            y_exact_func=case['y_exact_func']\n        )\n        \n        y_exact_at_T = case['y_exact_func'](case['T'])\n        error = np.abs(y_numerical - y_exact_at_T)\n        \n        if error  0: # Avoid log(0)\n            log_h_vals.append(np.log(h))\n            log_E_vals.append(np.log(error))\n    \n    # Perform linear least-squares fit on log-log data\n    # The slope is the observed order of convergence\n    if len(log_h_vals)  1:\n        slope, _ = np.polyfit(log_h_vals, log_E_vals, 1)\n        return slope\n    return np.nan # Not enough data to fit\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Adams-Moulton coefficients b = [b_0, b_1, ..., b_s]\n    all_b_coeffs = {\n        0: [1.0],\n        1: [1.0/2.0, 1.0/2.0],\n        2: [5.0/12.0, 8.0/12.0, -1.0/12.0],\n        3: [9.0/24.0, 19.0/24.0, -5.0/24.0, 1.0/24.0]\n    }\n    \n    test_cases = [\n        {\n            's': 0, 'lambda': -50.0, 'g_func': lambda t: 0.0, 'y0': 1.0,\n            'y_exact_func': lambda t: np.exp(-50.0 * t),\n            'T': 1.0, 'h0': 0.1, 'L': 5, 'b_coeffs': all_b_coeffs[0]\n        },\n        {\n            's': 1, 'lambda': -1.0, 'g_func': lambda t: 0.0, 'y0': 1.0,\n            'y_exact_func': lambda t: np.exp(-1.0 * t),\n            'T': 1.0, 'h0': 0.2, 'L': 5, 'b_coeffs': all_b_coeffs[1]\n        },\n        {\n            's': 2, 'lambda': -1.0, 'g_func': lambda t: 0.0, 'y0': 1.0,\n            'y_exact_func': lambda t: np.exp(-1.0 * t),\n            'T': 1.0, 'h0': 0.2, 'L': 5, 'b_coeffs': all_b_coeffs[2]\n        },\n        {\n            's': 3, 'lambda': -1.0, 'g_func': lambda t: np.sin(t), 'y0': 0.0,\n            'y_exact_func': lambda t: (np.exp(-t) + np.sin(t) - np.cos(t)) / 2.0,\n            'T': 1.0, 'h0': 0.2, 'L': 5, 'b_coeffs': all_b_coeffs[3]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        observed_order = run_convergence_test(case)\n        results.append(observed_order)\n\n    # Format the final output string exactly as required\n    formatted_results = [f\"{order:.2f}\" for order in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}