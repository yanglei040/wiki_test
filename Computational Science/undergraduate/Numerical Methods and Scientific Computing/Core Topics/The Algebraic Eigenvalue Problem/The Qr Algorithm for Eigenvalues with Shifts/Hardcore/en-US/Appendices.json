{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides a foundational insight into why shifts are so effective in the QR algorithm. By considering the ideal—though impractical—scenario of using a known eigenvalue as the shift, you will prove that the algorithm perfectly deflates the matrix in a single step. This practice solidifies the theoretical underpinnings of the method's convergence. ",
            "id": "3283437",
            "problem": "Consider a real upper Hessenberg matrix $A \\in \\mathbb{R}^{n \\times n}$, and recall the orthogonal-triangular ($QR$) factorization: for any square matrix $M$, one may write $M = Q R$ with $Q$ orthogonal (i.e., $Q^{\\top} Q = I$) and $R$ upper triangular. In the shifted $QR$ iteration with shift $\\mu \\in \\mathbb{R}$, one step is defined by computing the $QR$ factorization of $A - \\mu I$ as $A - \\mu I = Q R$, and then forming the next iterate $A_{1} = R Q + \\mu I$. Starting only from these definitions and the structure of upper Hessenberg matrices, derive why choosing a shift $\\mu$ equal to an exact eigenvalue of $A$ forces the entry in position $(n,n-1)$ of $A_{1}$ to be $0$ after a single shifted $QR$ step.\n\nThen verify this deflation on the following crafted $3 \\times 3$ upper Hessenberg matrix built from the monic polynomial $(\\lambda - 1)(\\lambda - 2)(\\lambda - 3) = \\lambda^{3} - 6 \\lambda^{2} + 11 \\lambda - 6$. Consider the companion-type upper Hessenberg matrix\n$$\nA = \\begin{pmatrix}\n0 & 0 & 6 \\\\\n1 & 0 & -11 \\\\\n0 & 1 & 6\n\\end{pmatrix},\n$$\nwhose eigenvalues are the roots of the given polynomial. Perform one shifted $QR$ step with the exact shift $\\mu = 1$ and compute the $(3,2)$ entry of the resulting matrix $A_{1}$. Provide the exact value of this entry as your final answer. No rounding is required.",
            "solution": "The problem will be addressed in two parts as specified: first, a general derivation of the deflation property of the shifted QR algorithm, and second, a numerical verification using the provided matrix and shift.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   $A \\in \\mathbb{R}^{n \\times n}$ is a real upper Hessenberg matrix ($a_{ij} = 0$ for $i > j+1$).\n-   The QR factorization of a matrix $M$ is $M = QR$, where $Q$ is orthogonal ($Q^{\\top}Q = I$) and $R$ is upper triangular ($r_{ij} = 0$ for $i > j$).\n-   A shifted QR step is defined by:\n    1.  $A - \\mu I = QR$\n    2.  $A_1 = RQ + \\mu I$\n-   The shift $\\mu \\in \\mathbb{R}$ is an exact eigenvalue of $A$.\n-   The objective is to prove that the entry $(A_1)_{n,n-1}$ is $0$.\n-   For verification, the specific matrix is provided:\n    $$\n    A = \\begin{pmatrix}\n    0 & 0 & 6 \\\\\n    1 & 0 & -11 \\\\\n    0 & 1 & 6\n    \\end{pmatrix}\n    $$\n-   The shift for verification is $\\mu=1$, which is stated to be an exact eigenvalue.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded within the field of numerical linear algebra. It is well-posed, objective, and self-contained. The provided matrix is indeed an upper Hessenberg matrix, and its characteristic polynomial is $p(\\lambda) = \\det(A - \\lambda I) = -\\lambda^3 + 6\\lambda^2 - 11\\lambda + 6$. The roots of this polynomial are the eigenvalues. The polynomial given in the problem statement, $P(\\lambda) = \\lambda^3 - 6\\lambda^2 + 11\\lambda - 6$, has the same roots as $p(\\lambda)$, which are $\\lambda=1, 2, 3$. Thus, $\\mu=1$ is indeed an exact eigenvalue. All definitions and conditions are standard and consistent. The problem is therefore valid.\n\n### Theoretical Derivation\n\nLet $A \\in \\mathbb{R}^{n \\times n}$ be an upper Hessenberg matrix. A single step of the shifted QR algorithm with shift $\\mu$ is given by:\n1.  Compute the QR factorization of $A - \\mu I$: $A - \\mu I = QR$.\n2.  Compute the next iterate: $A_1 = RQ + \\mu I$.\n\nWe are asked to show that if $\\mu$ is an eigenvalue of $A$, then the entry $(n, n-1)$ of $A_1$, denoted as $(A_1)_{n,n-1}$, is zero.\n\nThe entry $(A_1)_{n,n-1}$ is the entry in the $n$-th row and $(n-1)$-th column of the matrix $A_1$. From the definition of $A_1$, this is:\n$$ (A_1)_{n,n-1} = (RQ + \\mu I)_{n,n-1} $$\nThe term $\\mu I$ only affects the diagonal entries, so for $n \\ne n-1$, this simplifies to:\n$$ (A_1)_{n,n-1} = (RQ)_{n,n-1} $$\nUsing the definition of matrix multiplication, we have:\n$$ (RQ)_{n,n-1} = \\sum_{k=1}^n R_{nk} Q_{k,n-1} $$\nwhere $R_{nk}$ and $Q_{k,n-1}$ are the entries of matrices $R$ and $Q$.\n\nSince $R$ is an upper triangular matrix, its elements $R_{ij}$ are zero for $i>j$. For the $n$-th row of $R$, this means $R_{nk} = 0$ for all $k < n$. Therefore, the summation for $(RQ)_{n,n-1}$ simplifies significantly:\n$$ (RQ)_{n,n-1} = R_{n1}Q_{1,n-1} + \\dots + R_{n,n-1}Q_{n-1,n-1} + R_{nn}Q_{n,n-1} = 0 + \\dots + 0 + R_{nn}Q_{n,n-1} = R_{nn}Q_{n,n-1} $$\nThus, we must show that $R_{nn} = 0$.\n\nWe are given that $\\mu$ is an exact eigenvalue of $A$. This implies that the matrix $A - \\mu I$ is singular, i.e., $\\det(A - \\mu I) = 0$.\nFrom the QR factorization $A - \\mu I = QR$, we have:\n$$ \\det(A - \\mu I) = \\det(Q)\\det(R) $$\nSince $Q$ is an orthogonal matrix, $Q^{\\top}Q=I$, which implies $(\\det(Q))^2=1$, so $\\det(Q) = \\pm 1 \\ne 0$.\nThe singularity of $A - \\mu I$ must therefore come from $R$:\n$$ \\det(R) = 0 $$\nThe determinant of an upper triangular matrix $R$ is the product of its diagonal entries:\n$$ \\det(R) = \\prod_{i=1}^n R_{ii} $$\nFor $\\det(R)$ to be zero, at least one of the diagonal entries $R_{ii}$ must be zero.\n\nNow, we consider the structure of $A$. If $A$ is an *unreduced* upper Hessenberg matrix, then all its subdiagonal entries are non-zero: $a_{i+1,i} \\ne 0$ for $i=1, \\dots, n-1$. The matrix $A-\\mu I$ is also unreduced upper Hessenberg. For such a matrix, it is a standard result that the first $n-1$ columns are linearly independent. The QR factorization process (e.g., Gram-Schmidt or Givens rotations) generates the diagonal entries of $R$ as $r_{kk} = \\| (A-\\mu I)_k - \\sum_{j=1}^{k-1} \\langle (A-\\mu I)_k, q_j \\rangle q_j \\|$, where $(A-\\mu I)_k$ is the $k$-th column of $A-\\mu I$. Since the first $n-1$ columns are linearly independent, the $k$-th column for $k \\le n-1$ is not in the span of the preceding columns, which means $R_{kk} \\ne 0$ for $k=1, \\dots, n-1$.\n\nSince we know at least one diagonal entry of $R$ must be zero, and the first $n-1$ diagonal entries are non-zero, it must be that the last diagonal entry is zero:\n$$ R_{nn} = 0 $$\nIf the matrix $A$ were reduced, $a_{k+1,k}=0$ for some $k<n-1$, it would decouple into smaller unreduced Hessenberg blocks. The QR iteration would then effectively proceed on these blocks independently. If $\\mu$ is an eigenvalue of the bottom-right block, the same argument applies to that block, leading to deflation.\n\nSubstituting $R_{nn}=0$ back into our expression for $(A_1)_{n,n-1}$:\n$$ (A_1)_{n,n-1} = R_{nn}Q_{n,n-1} = 0 \\cdot Q_{n,n-1} = 0 $$\nThis completes the derivation.\n\n### Numerical Verification\n\nWe are given the matrix $A = \\begin{pmatrix} 0 & 0 & 6 \\\\ 1 & 0 & -11 \\\\ 0 & 1 & 6 \\end{pmatrix}$ and the shift $\\mu = 1$.\nFirst, we form the matrix $M = A - \\mu I$:\n$$ M = A - 1 \\cdot I = \\begin{pmatrix} 0 & 0 & 6 \\\\ 1 & 0 & -11 \\\\ 0 & 1 & 6 \\end{pmatrix} - \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} -1 & 0 & 6 \\\\ 1 & -1 & -11 \\\\ 0 & 1 & 5 \\end{pmatrix} $$\nNext, we compute the QR factorization of $M$, which is $M=QR$. We will use Givens rotations to transform $M$ into an upper triangular matrix $R$.\n\n**Step 1:** Annihilate the $(2,1)$ entry, $M_{21}=1$. We apply a Givens rotation $G_1$ in the $(1,2)$ plane, defined by the orthogonal matrix:\n$$ G_1 = \\begin{pmatrix} -1/\\sqrt{2} & 1/\\sqrt{2} & 0 \\\\ -1/\\sqrt{2} & -1/\\sqrt{2} & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} $$\nApplying $G_1$ to $M$:\n$$ M' = G_1 M = \\begin{pmatrix} -1/\\sqrt{2} & 1/\\sqrt{2} & 0 \\\\ -1/\\sqrt{2} & -1/\\sqrt{2} & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} -1 & 0 & 6 \\\\ 1 & -1 & -11 \\\\ 0 & 1 & 5 \\end{pmatrix} = \\begin{pmatrix} \\sqrt{2} & -1/\\sqrt{2} & -17/\\sqrt{2} \\\\ 0 & 1/\\sqrt{2} & 5/\\sqrt{2} \\\\ 0 & 1 & 5 \\end{pmatrix} $$\n**Step 2:** Annihilate the $(3,2)$ entry, $M'_{32}=1$. We apply a Givens rotation $G_2$ in the $(2,3)$ plane. The vector is $(M'_{22}, M'_{32}) = (1/\\sqrt{2}, 1)$. $r' = \\sqrt{(1/\\sqrt{2})^2 + 1^2} = \\sqrt{1/2 + 1} = \\sqrt{3/2}$.\nThe rotation parameters are $c' = (1/\\sqrt{2})/\\sqrt{3/2} = 1/\\sqrt{3}$ and $s' = 1/\\sqrt{3/2} = \\sqrt{2/3}$.\n$$ G_2 = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & c' & s' \\\\ 0 & -s' & c' \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1/\\sqrt{3} & \\sqrt{2/3} \\\\ 0 & -\\sqrt{2/3} & 1/\\sqrt{3} \\end{pmatrix} $$\nApplying $G_2$ to $M'$ gives $R$:\n$$ R = G_2 M' = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1/\\sqrt{3} & \\sqrt{2/3} \\\\ 0 & -\\sqrt{2/3} & 1/\\sqrt{3} \\end{pmatrix} \\begin{pmatrix} \\sqrt{2} & -1/\\sqrt{2} & -17/\\sqrt{2} \\\\ 0 & 1/\\sqrt{2} & 5/\\sqrt{2} \\\\ 0 & 1 & 5 \\end{pmatrix} $$\n$$ R = \\begin{pmatrix} \\sqrt{2} & -1/\\sqrt{2} & -17/\\sqrt{2} \\\\ 0 & \\frac{1}{\\sqrt{3}}\\frac{1}{\\sqrt{2}} + \\frac{\\sqrt{2}}{\\sqrt{3}}(1) & \\frac{1}{\\sqrt{3}}\\frac{5}{\\sqrt{2}} + \\frac{\\sqrt{2}}{\\sqrt{3}}(5) \\\\ 0 & -\\frac{\\sqrt{2}}{\\sqrt{3}}\\frac{1}{\\sqrt{2}} + \\frac{1}{\\sqrt{3}}(1) & -\\frac{\\sqrt{2}}{\\sqrt{3}}\\frac{5}{\\sqrt{2}} + \\frac{1}{\\sqrt{3}}(5) \\end{pmatrix} = \\begin{pmatrix} \\sqrt{2} & -\\frac{1}{\\sqrt{2}} & -\\frac{17}{\\sqrt{2}} \\\\ 0 & \\frac{3}{\\sqrt{6}} & \\frac{15}{\\sqrt{6}} \\\\ 0 & 0 & 0 \\end{pmatrix} $$\nSo the upper triangular matrix is:\n$$ R = \\begin{pmatrix} \\sqrt{2} & -1/\\sqrt{2} & -17/\\sqrt{2} \\\\ 0 & \\sqrt{3/2} & 5\\sqrt{3/2} \\\\ 0 & 0 & 0 \\end{pmatrix} $$\nThe factorization is $M = QR$ where $Q = G_1^T G_2^T$. The resulting matrix $A_1$ is $A_1 = RQ + I$. We need to compute the $(3,2)$ entry of $A_1$.\n$$ (A_1)_{3,2} = (RQ+I)_{3,2} = (RQ)_{3,2} = \\sum_{k=1}^3 R_{3k}Q_{k2} $$\nThe third row of $R$ is $(R_{31}, R_{32}, R_{33}) = (0, 0, 0)$.\nTherefore,\n$$ (A_1)_{3,2} = R_{31}Q_{12} + R_{32}Q_{22} + R_{33}Q_{32} = 0 \\cdot Q_{12} + 0 \\cdot Q_{22} + 0 \\cdot Q_{32} = 0 $$\nThe calculation confirms the theoretical result that the $(n,n-1)$ entry (here, $(3,2)$) deflates to zero.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "In practice, we don't know the eigenvalues beforehand, so we must use an estimate. A natural choice is the bottom-right entry of the matrix, a form of Rayleigh quotient shift. This exercise reveals a critical weakness of this simple strategy by asking you to construct a case where the algorithm stagnates completely, making no progress. Understanding this failure mode motivates the search for more sophisticated and reliable shift strategies. ",
            "id": "3283460",
            "problem": "Let $H \\in \\mathbb{R}^{n \\times n}$ be an unreduced real upper Hessenberg matrix. In the shifted orthogonal-triangular (QR) algorithm, given a shift $\\mu \\in \\mathbb{R}$, one computes an orthogonal matrix $Q$ and an upper triangular matrix $R$ such that $H - \\mu I = Q R$, and then forms the next iterate $H^{+} = R Q + \\mu I$, which is orthogonally similar to $H$ and preserves the upper Hessenberg structure.\n\nConstruct an explicit $2 \\times 2$ unreduced upper Hessenberg matrix $H$ for which choosing the shift as the trailing diagonal entry $\\mu = h_{2,2}$ yields $H^{+} = H$ after one shifted step, i.e., the iteration stagnates. Justify the stagnation using only the definitions of the shifted QR step and orthogonal-triangular factorization, without appealing to any pre-derived convergence formulas. Then, letting $h_{2,1}^{(0)}$ denote the initial subdiagonal entry and $h_{2,1}^{(1)}$ the subdiagonal entry after one shifted QR step with $\\mu = h_{2,2}$, compute the reduction factor\n$$\n\\rho \\;=\\; \\frac{\\left|h_{2,1}^{(1)}\\right|}{\\left|h_{2,1}^{(0)}\\right|}.\n$$\nGive your answer as an exact number with no rounding.",
            "solution": "The problem requires us to construct a specific $2 \\times 2$ unreduced upper Hessenberg matrix $H$ that stagnates under a specific shifted QR step, to justify this stagnation, and to compute the resulting subdiagonal reduction factor.\n\nLet $H \\in \\mathbb{R}^{2 \\times 2}$ be a general unreduced real upper Hessenberg matrix. This means $H$ has the form:\n$$\nH = \\begin{pmatrix} h_{1,1} & h_{1,2} \\\\ h_{2,1} & h_{2,2} \\end{pmatrix}\n$$\nwhere $h_{2,1} \\neq 0$.\n\nThe shifted QR algorithm step is defined with a shift $\\mu$. First, we compute the QR factorization of $H - \\mu I$:\n$$\nH - \\mu I = Q R\n$$\nwhere $Q$ is an orthogonal matrix ($Q^T Q = I$) and $R$ is an upper triangular matrix. The next iterate, $H^{+}$, is then formed by:\n$$\nH^{+} = R Q + \\mu I\n$$\nThe problem specifies the shift as the trailing diagonal entry, so $\\mu = h_{2,2}$. The condition for stagnation is $H^{+} = H$.\n\nLet's apply the procedure. The matrix to be factorized is:\n$$\nH - \\mu I = H - h_{2,2} I = \\begin{pmatrix} h_{1,1} & h_{1,2} \\\\ h_{2,1} & h_{2,2} \\end{pmatrix} - \\begin{pmatrix} h_{2,2} & 0 \\\\ 0 & h_{2,2} \\end{pmatrix} = \\begin{pmatrix} h_{1,1} - h_{2,2} & h_{1,2} \\\\ h_{2,1} & 0 \\end{pmatrix}\n$$\nTo find the QR factorization, we can use a Givens rotation to introduce a zero in the $(2,1)$ position. Let $Q^T$ be a Givens rotation matrix:\n$$\nQ^T = \\begin{pmatrix} c & s \\\\ -s & c \\end{pmatrix}\n$$\nwhere $c = \\cos(\\theta)$ and $s = \\sin(\\theta)$ for some angle $\\theta$. Applying this to $H - \\mu I$:\n$$\nR = Q^T (H - \\mu I) = \\begin{pmatrix} c & s \\\\ -s & c \\end{pmatrix} \\begin{pmatrix} h_{1,1} - h_{2,2} & h_{1,2} \\\\ h_{2,1} & 0 \\end{pmatrix} = \\begin{pmatrix} c(h_{1,1} - h_{2,2}) + s h_{2,1} & c h_{1,2} \\\\ -s(h_{1,1} - h_{2,2}) + c h_{2,1} & -s h_{1,2} \\end{pmatrix}\n$$\nFor $R$ to be upper triangular, the entry $r_{2,1}$ must be zero:\n$$\n-s(h_{1,1} - h_{2,2}) + c h_{2,1} = 0\n$$\nThis defines the rotation. The next iterate is $H^{+} = R Q + \\mu I$. An equivalent formula for $H^{+}$ is $H^{+} = Q^T H Q$. Stagnation, $H^{+} = H$, implies $H = Q^T H Q$, which is equivalent to $H Q = Q H$, meaning $H$ and $Q$ must commute.\nLet's see what conditions this imposes on $H$. The matrix $Q$ is the transpose of $Q^T$:\n$$\nQ = \\begin{pmatrix} c & -s \\\\ s & c \\end{pmatrix}\n$$\nThe commutation condition $H Q = Q H$ yields:\n$$\n\\begin{pmatrix} h_{1,1} & h_{1,2} \\\\ h_{2,1} & h_{2,2} \\end{pmatrix} \\begin{pmatrix} c & -s \\\\ s & c \\end{pmatrix} = \\begin{pmatrix} c & -s \\\\ s & c \\end{pmatrix} \\begin{pmatrix} h_{1,1} & h_{1,2} \\\\ h_{2,1} & h_{2,2} \\end{pmatrix}\n$$\n$$\n\\begin{pmatrix} c h_{1,1} + s h_{1,2} & -s h_{1,1} + c h_{1,2} \\\\ c h_{2,1} + s h_{2,2} & -s h_{2,1} + c h_{2,2} \\end{pmatrix} = \\begin{pmatrix} c h_{1,1} - s h_{2,1} & c h_{1,2} - s h_{2,2} \\\\ s h_{1,1} + c h_{2,1} & s h_{1,2} + c h_{2,2} \\end{pmatrix}\n$$\nEquating the entries:\n\\begin{itemize}\n    \\item $(1,1)$: $c h_{1,1} + s h_{1,2} = c h_{1,1} - s h_{2,1} \\implies s h_{1,2} = -s h_{2,1}$\n    \\item $(1,2)$: $-s h_{1,1} + c h_{1,2} = c h_{1,2} - s h_{2,2} \\implies -s h_{1,1} = -s h_{2,2}$\n    \\item $(2,1)$: $c h_{2,1} + s h_{2,2} = s h_{1,1} + c h_{2,1} \\implies s h_{2,2} = s h_{1,1}$\n    \\item $(2,2)$: $-s h_{2,1} + c h_{2,2} = s h_{1,2} + c h_{2,2} \\implies -s h_{2,1} = s h_{1,2}$\n\\end{itemize}\nSince $H$ is unreduced, $h_{2,1} \\neq 0$. If $s=0$, the rotation is trivial ($Q=I$), which implies from $R=Q^T(H-\\mu I)$ that $H-\\mu I$ is already upper triangular. This means $h_{2,1}=0$, a contradiction. So, $s \\neq 0$. We can divide by $s$ in the equations above.\nAll four equations give two distinct conditions:\n1. $h_{1,1} = h_{2,2}$\n2. $h_{1,2} = -h_{2,1}$\n\nSo, any unreduced upper Hessenberg matrix of the form $H = \\begin{pmatrix} a & -b \\\\ b & a \\end{pmatrix}$ with $b \\neq 0$ will stagnate.\nLet's construct an explicit example by choosing simple values, e.g., $a=1$ and $b=1$.\n$$\nH = \\begin{pmatrix} 1 & -1 \\\\ 1 & 1 \\end{pmatrix}\n$$\nThis matrix is unreduced since $h_{2,1} = 1 \\neq 0$.\n\nNow, we justify the stagnation for this $H$ using only the definitions.\nThe shift is $\\mu = h_{2,2} = 1$.\nWe form the matrix $H - \\mu I$:\n$$\nH - \\mu I = \\begin{pmatrix} 1 & -1 \\\\ 1 & 1 \\end{pmatrix} - 1 \\cdot \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}\n$$\nWe need to find the QR factorization of this matrix. Let $A = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}$. Note that $A$ is already an orthogonal matrix, since $A^T A = \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = I$.\nSo, a valid QR factorization of $A$ is $Q=A$ and $R=I$.\n$$\nQ = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}, \\quad R = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\n$Q$ is orthogonal and $R$ is upper triangular. Now we form the next iterate $H^{+}$:\n$$\nH^{+} = R Q + \\mu I = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} + 1 \\cdot \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\n$$\nH^{+} = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} + \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & -1 \\\\ 1 & 1 \\end{pmatrix}\n$$\nWe see that $H^{+} = H$, so the iteration has stagnated, as predicted by our derivation.\n\nFinally, we compute the reduction factor $\\rho$.\nThe initial subdiagonal entry is $h_{2,1}^{(0)}$, which is the $(2,1)$ entry of our constructed matrix $H$.\n$$\nh_{2,1}^{(0)} = 1\n$$\nThe subdiagonal entry after one step is $h_{2,1}^{(1)}$, which is the $(2,1)$ entry of the matrix $H^{+}$.\n$$\nh_{2,1}^{(1)} = 1\n$$\nThe reduction factor $\\rho$ is defined as:\n$$\n\\rho = \\frac{\\left|h_{2,1}^{(1)}\\right|}{\\left|h_{2,1}^{(0)}\\right|}\n$$\nSubstituting the values we found:\n$$\n\\rho = \\frac{|1|}{|1|} = 1\n$$\nStagnation implies that the matrix does not change, so the subdiagonal entry does not change either. Since the matrix is unreduced ($h_{2,1}^{(0)} \\neq 0$), the ratio of the magnitudes of the new and old subdiagonal entries is $1$.",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "The Wilkinson shift is a more robust and rapidly converging alternative, especially for symmetric matrices. However, its power comes with a practical challenge: numerical stability. This practice guides you through deriving a stable formula for the Wilkinson shift, demonstrating how to avoid catastrophic cancellation—a crucial lesson in turning a theoretical algorithm into a reliable computational tool. ",
            "id": "3283423",
            "problem": "Consider the trailing $2 \\times 2$ block that determines the shift in the orthogonal-triangular (QR) algorithm with shifts:\n$$\nB \\;=\\; \\begin{pmatrix} a & b \\\\ b & c \\end{pmatrix}.\n$$\nThe Wilkinson shift is defined as the eigenvalue of $B$ that is closer (in absolute difference) to the bottom-right entry $c$. Starting only from the characteristic polynomial definition $\\det(B - \\lambda I) = 0$ and the quadratic formula, do the following:\n\n1) Derive the two eigenvalues of $B$ in terms of $a$, $b$, and $c$, and identify which branch corresponds to the eigenvalue that is closer to $c$ as a function of the sign of $d = \\tfrac{a - c}{2}$. Explain why, when $|d| \\gg |b|$ and $d > 0$, directly computing the eigenvalue closer to $c$ using a naive quadratic-formula expression exhibits catastrophic cancellation.\n\n2) By purely algebraic manipulation of the characteristic equation and identities implied by it, derive a numerically stable, closed-form expression for the eigenvalue closer to $c$ that avoids subtracting nearly equal numbers.\n\n3) Using your stable expression, evaluate the Wilkinson shift for the specific trailing block\n$$\nB \\;=\\; \\begin{pmatrix} 10^{8} & 10^{-4} \\\\ 10^{-4} & 10^{-8} \\end{pmatrix}.\n$$\nProvide your final numerical value as a decimal rounded to ten significant figures.\n\nYour final answer must be a single real number (no units).",
            "solution": "The user has posed a three-part problem concerning the Wilkinson shift used in the QR algorithm for finding eigenvalues of a symmetric matrix. I will first validate the problem statement and then proceed to solve it step-by-step.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   The matrix in question is a $2 \\times 2$ symmetric block: $B = \\begin{pmatrix} a & b \\\\ b & c \\end{pmatrix}$.\n-   The Wilkinson shift is defined as the eigenvalue of $B$ that is closer to $c$.\n-   A helper variable is defined: $d = \\frac{a - c}{2}$.\n-   The derivation must start from the characteristic polynomial $\\det(B - \\lambda I) = 0$ and the quadratic formula.\n-   Part 1: Derive the eigenvalues of $B$, identify the one closer to $c$ as a function of $\\operatorname{sgn}(d)$, and explain the catastrophic cancellation that occurs in the naive calculation when $|d| \\gg |b|$ and $d > 0$.\n-   Part 2: Derive a numerically stable, closed-form expression for the Wilkinson shift.\n-   Part 3: Evaluate the Wilkinson shift for the specific matrix $B = \\begin{pmatrix} 10^{8} & 10^{-4} \\\\ 10^{-4} & 10^{-8} \\end{pmatrix}$ and provide the result rounded to ten significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is a standard, fundamental topic in numerical linear algebra. The Wilkinson shift, the QR algorithm, and the analysis of numerical stability (specifically, catastrophic cancellation) are all well-established concepts. The matrix is symmetric, ensuring real eigenvalues, which is consistent with the context.\n-   **Well-Posed:** The problem is clearly stated with a sequence of logical tasks leading to a unique mathematical derivation and a specific numerical result. All necessary definitions and data are provided.\n-   **Objective:** The language is formal, precise, and free of any subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a well-posed, scientifically sound problem in numerical analysis. I will now proceed with a full solution.\n\n### Part 1: Eigenvalue Derivation and Cancellation Analysis\n\nThe eigenvalues $\\lambda$ of the matrix $B$ are the roots of the characteristic polynomial, given by $\\det(B - \\lambda I) = 0$.\n$$\n\\det\\left(\\begin{pmatrix} a & b \\\\ b & c \\end{pmatrix} - \\lambda \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\right) = \\det\\begin{pmatrix} a - \\lambda & b \\\\ b & c - \\lambda \\end{pmatrix} = 0\n$$\nExpanding the determinant gives the quadratic equation:\n$$\n(a - \\lambda)(c - \\lambda) - b^2 = 0\n$$\n$$\n\\lambda^2 - (a+c)\\lambda + (ac - b^2) = 0\n$$\nUsing the quadratic formula to solve for $\\lambda$:\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{(a+c)^2 - 4(ac - b^2)}}{2}\n$$\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{a^2 + 2ac + c^2 - 4ac + 4b^2}}{2}\n$$\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{a^2 - 2ac + c^2 + 4b^2}}{2}\n$$\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{(a-c)^2 + 4b^2}}{2}\n$$\nIntroducing the given variable $d = \\frac{a-c}{2}$, we have $a-c = 2d$. We also note that $\\frac{a+c}{2} = \\frac{(c+2d)+c}{2} = c+d$. Substituting these into the expression for $\\lambda$:\n$$\n\\lambda = \\frac{a+c}{2} \\pm \\frac{\\sqrt{4d^2 + 4b^2}}{2} = (c+d) \\pm \\sqrt{d^2+b^2}\n$$\nThe two eigenvalues are $\\lambda_1 = c+d+\\sqrt{d^2+b^2}$ and $\\lambda_2 = c+d-\\sqrt{d^2+b^2}$.\n\nThe Wilkinson shift is the eigenvalue closer to $c$. We must compare the distances $|\\lambda_1 - c|$ and $|\\lambda_2 - c|$.\n$$\n|\\lambda_1 - c| = |d + \\sqrt{d^2+b^2}|\n$$\n$$\n|\\lambda_2 - c| = |d - \\sqrt{d^2+b^2}|\n$$\nSince $b^2 \\ge 0$, we have $\\sqrt{d^2+b^2} \\ge \\sqrt{d^2} = |d|$. The smaller distance corresponds to the expression where $d$ and $\\sqrt{d^2+b^2}$ are subtracted. This depends on the sign of $d$.\n-   If $d > 0$, then $|d - \\sqrt{d^2+b^2}| = \\sqrt{d^2+b^2}-d$ is smaller than $|d + \\sqrt{d^2+b^2}| = d+\\sqrt{d^2+b^2}$. The closer eigenvalue is $\\lambda_2$.\n-   If $d < 0$, then $|d + \\sqrt{d^2+b^2}| = \\sqrt{d^2+b^2}-|d|$ is smaller than $|d - \\sqrt{d^2+b^2}| = |d|+\\sqrt{d^2+b^2}$. The closer eigenvalue is $\\lambda_1$.\n-   If $d = 0$, both eigenvalues are equidistant from $c$. By convention (e.g., as in the original work by Wilkinson), one may choose a specific branch.\n\nWe can unify this choice using the sign function, $\\operatorname{sgn}(d)$, where we define $\\operatorname{sgn}(0)=1$. The term with the smaller magnitude is always $d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$. Thus, the Wilkinson shift, $\\mu$, is given by:\n$$\n\\mu = c + \\left(d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}\\right)\n$$\n\nNow, consider the case where $|d| \\gg |b|$ and $d>0$. The Wilkinson shift is $\\mu = c+d-\\sqrt{d^2+b^2}$.\nIn this regime, $\\sqrt{d^2+b^2} = d\\sqrt{1+(b/d)^2}$. Using a binomial approximation, since $(b/d)^2$ is very small:\n$$\n\\sqrt{d^2+b^2} \\approx d\\left(1 + \\frac{1}{2}\\left(\\frac{b}{d}\\right)^2\\right) = d + \\frac{b^2}{2d}\n$$\nThe value of $\\sqrt{d^2+b^2}$ is very close to $d$. When the expression $\\mu = c + (d - \\sqrt{d^2+b^2})$ is evaluated in finite-precision arithmetic, the subtraction $d - \\sqrt{d^2+b^2}$ involves two nearly equal numbers. This leads to a massive loss of significant figures in the result, an effect known as catastrophic cancellation. The computed result for the shift will have very low relative accuracy.\n\n### Part 2: Derivation of a Numerically Stable Expression\n\nTo avoid the catastrophic cancellation in $d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$, we can use an algebraic manipulation based on \"rationalizing the numerator\".\nLet the term causing instability be $T = d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$. We multiply and divide by its conjugate, $d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$.\n$$\nT = \\frac{\\left(d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}\\right) \\left(d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}\\right)}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\n$$\nT = \\frac{d^2 - (\\operatorname{sgn}(d))^2(d^2+b^2)}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\nSince $(\\operatorname{sgn}(d))^2=1$ for $d \\neq 0$:\n$$\nT = \\frac{d^2 - (d^2+b^2)}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}} = \\frac{-b^2}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\nThe denominator, $d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$, involves the addition of two terms with the same sign ($d$ and $\\operatorname{sgn}(d)\\sqrt{...}$), thus avoiding cancellation.\nSubstituting this stable expression for $T$ back into the formula for the shift $\\mu = c+T$, we get the numerically stable form:\n$$\n\\mu = c - \\frac{b^2}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\n\n### Part 3: Numerical Evaluation\n\nWe are given the matrix:\n$$\nB = \\begin{pmatrix} 10^{8} & 10^{-4} \\\\ 10^{-4} & 10^{-8} \\end{pmatrix}\n$$\nThe parameters are $a = 10^8$, $b = 10^{-4}$, and $c = 10^{-8}$.\nFirst, we compute $d$.\n$$\nd = \\frac{a-c}{2} = \\frac{10^8 - 10^{-8}}{2} = 5 \\times 10^7 - 5 \\times 10^{-9}\n$$\nSince $d > 0$, $\\operatorname{sgn}(d) = 1$. The stable formula for the Wilkinson shift $\\mu$ is:\n$$\n\\mu = c - \\frac{b^2}{d + \\sqrt{d^2+b^2}}\n$$\nWe have the values:\n$c = 10^{-8}$\n$b^2 = (10^{-4})^2 = 10^{-8}$\n\nThe problem is now to evaluate $\\mu = 10^{-8} - \\frac{10^{-8}}{d + \\sqrt{d^2+10^{-8}}}$ with high precision.\nUsing a computational tool with sufficient precision, we can evaluate the stable expression. The result is approximately:\n$\\mu \\approx 0.000000009999999899999999...$\nIn scientific notation, this is $9.999999899999999... \\times 10^{-9}$.\n\nTo round this to ten significant figures, we examine the first eleven significant digits: $9.999999899$. The eleventh digit is $9$, which is $\\ge 5$, so we must round up the tenth digit.\nThe tenth significant digit is $9$. Rounding it up results in $0$ and a carry-over to the ninth digit.\nThe ninth significant digit is $8$. Adding the carry-over makes it $9$.\nThe rounded value to ten significant figures is $9.99999990 \\times 10^{-9}$.\nAs a decimal, this is $0.00000000999999990$.",
            "answer": "$$\n\\boxed{0.00000000999999990}\n$$"
        }
    ]
}