{
    "hands_on_practices": [
        {
            "introduction": "To build a solid understanding of the shifted QR algorithm, we begin with an idealized scenario. This exercise explores what would happen if we were fortunate enough to know an exact eigenvalue of our matrix. By using this eigenvalue as the shift $\\mu$, you will prove and observe a fundamental process called deflation, where a subdiagonal entry is precisely zeroed out in a single step, effectively reducing the size of the problem. Mastering this concept is key to understanding how the iterative process converges to find all eigenvalues .",
            "id": "3283437",
            "problem": "Consider a real upper Hessenberg matrix $A \\in \\mathbb{R}^{n \\times n}$, and recall the orthogonal-triangular ($QR$) factorization: for any square matrix $M$, one may write $M = Q R$ with $Q$ orthogonal (i.e., $Q^{\\top} Q = I$) and $R$ upper triangular. In the shifted $QR$ iteration with shift $\\mu \\in \\mathbb{R}$, one step is defined by computing the $QR$ factorization of $A - \\mu I$ as $A - \\mu I = Q R$, and then forming the next iterate $A_{1} = R Q + \\mu I$. Starting only from these definitions and the structure of upper Hessenberg matrices, derive why choosing a shift $\\mu$ equal to an exact eigenvalue of $A$ forces the entry in position $(n,n-1)$ of $A_{1}$ to be $0$ after a single shifted $QR$ step.\n\nThen verify this deflation on the following crafted $3 \\times 3$ upper Hessenberg matrix built from the monic polynomial $(\\lambda - 1)(\\lambda - 2)(\\lambda - 3) = \\lambda^{3} - 6 \\lambda^{2} + 11 \\lambda - 6$. Consider the companion-type upper Hessenberg matrix\n$$\nA = \\begin{pmatrix}\n0 & 0 & 6 \\\\\n1 & 0 & -11 \\\\\n0 & 1 & 6\n\\end{pmatrix},\n$$\nwhose eigenvalues are the roots of the given polynomial. Perform one shifted $QR$ step with the exact shift $\\mu = 1$ and compute the $(3,2)$ entry of the resulting matrix $A_{1}$. Provide the exact value of this entry as your final answer. No rounding is required.",
            "solution": "The problem will be addressed in two parts as specified: first, a general derivation of the deflation property of the shifted QR algorithm, and second, a numerical verification using the provided matrix and shift.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   $A \\in \\mathbb{R}^{n \\times n}$ is a real upper Hessenberg matrix ($a_{ij} = 0$ for $i > j+1$).\n-   The QR factorization of a matrix $M$ is $M = QR$, where $Q$ is orthogonal ($Q^{\\top}Q = I$) and $R$ is upper triangular ($r_{ij} = 0$ for $i > j$).\n-   A shifted QR step is defined by:\n    1.  $A - \\mu I = QR$\n    2.  $A_1 = RQ + \\mu I$\n-   The shift $\\mu \\in \\mathbb{R}$ is an exact eigenvalue of $A$.\n-   The objective is to prove that the entry $(A_1)_{n,n-1}$ is $0$.\n-   For verification, the specific matrix is provided:\n    $$\n    A = \\begin{pmatrix}\n    0 & 0 & 6 \\\\\n    1 & 0 & -11 \\\\\n    0 & 1 & 6\n    \\end{pmatrix}\n    $$\n-   The shift for verification is $\\mu=1$, which is stated to be an exact eigenvalue.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded within the field of numerical linear algebra. It is well-posed, objective, and self-contained. The provided matrix is indeed an upper Hessenberg matrix, and its characteristic polynomial is $p(\\lambda) = \\det(A - \\lambda I) = -\\lambda^3 + 6\\lambda^2 - 11\\lambda + 6$. The roots of this polynomial are the eigenvalues. The polynomial given in the problem statement, $P(\\lambda) = \\lambda^3 - 6\\lambda^2 + 11\\lambda - 6$, has the same roots as $p(\\lambda)$, which are $\\lambda=1, 2, 3$. Thus, $\\mu=1$ is indeed an exact eigenvalue. All definitions and conditions are standard and consistent. The problem is therefore valid.\n\n### Theoretical Derivation\n\nLet $A \\in \\mathbb{R}^{n \\times n}$ be an upper Hessenberg matrix. A single step of the shifted QR algorithm with shift $\\mu$ is given by:\n1.  Compute the QR factorization of $A - \\mu I$: $A - \\mu I = QR$.\n2.  Compute the next iterate: $A_1 = RQ + \\mu I$.\n\nWe are asked to show that if $\\mu$ is an eigenvalue of $A$, then the entry $(n, n-1)$ of $A_1$, denoted as $(A_1)_{n,n-1}$, is zero.\n\nThe entry $(A_1)_{n,n-1}$ is the entry in the $n$-th row and $(n-1)$-th column of the matrix $A_1$. From the definition of $A_1$, this is:\n$$ (A_1)_{n,n-1} = (RQ + \\mu I)_{n,n-1} $$\nThe term $\\mu I$ only affects the diagonal entries, so for $n \\ne n-1$, this simplifies to:\n$$ (A_1)_{n,n-1} = (RQ)_{n,n-1} $$\nUsing the definition of matrix multiplication, we have:\n$$ (RQ)_{n,n-1} = \\sum_{k=1}^n R_{nk} Q_{k,n-1} $$\nwhere $R_{nk}$ and $Q_{k,n-1}$ are the entries of matrices $R$ and $Q$.\n\nSince $R$ is an upper triangular matrix, its elements $R_{ij}$ are zero for $i>j$. For the $n$-th row of $R$, this means $R_{nk} = 0$ for all $k < n$. Therefore, the summation for $(RQ)_{n,n-1}$ simplifies significantly:\n$$ (RQ)_{n,n-1} = R_{n1}Q_{1,n-1} + \\dots + R_{n,n-1}Q_{n-1,n-1} + R_{nn}Q_{n,n-1} = 0 + \\dots + 0 + R_{nn}Q_{n,n-1} = R_{nn}Q_{n,n-1} $$\nThus, we must show that $R_{nn} = 0$.\n\nWe are given that $\\mu$ is an exact eigenvalue of $A$. This implies that the matrix $A - \\mu I$ is singular, i.e., $\\det(A - \\mu I) = 0$.\nFrom the QR factorization $A - \\mu I = QR$, we have:\n$$ \\det(A - \\mu I) = \\det(Q)\\det(R) $$\nSince $Q$ is an orthogonal matrix, $Q^{\\top}Q=I$, which implies $(\\det(Q))^2=1$, so $\\det(Q) = \\pm 1 \\ne 0$.\nThe singularity of $A - \\mu I$ must therefore come from $R$:\n$$ \\det(R) = 0 $$\nThe determinant of an upper triangular matrix $R$ is the product of its diagonal entries:\n$$ \\det(R) = \\prod_{i=1}^n R_{ii} $$\nFor $\\det(R)$ to be zero, at least one of the diagonal entries $R_{ii}$ must be zero.\n\nNow, we consider the structure of $A$. If $A$ is an *unreduced* upper Hessenberg matrix, then all its subdiagonal entries are non-zero: $a_{i+1,i} \\ne 0$ for $i=1, \\dots, n-1$. The matrix $A-\\mu I$ is also unreduced upper Hessenberg. For such a matrix, it is a standard result that the first $n-1$ columns are linearly independent. The QR factorization process (e.g., Gram-Schmidt or Givens rotations) generates the diagonal entries of $R$ as $r_{kk} = \\| (A-\\mu I)_k - \\sum_{j=1}^{k-1} \\langle (A-\\mu I)_k, q_j \\rangle q_j \\|$, where $(A-\\mu I)_k$ is the $k$-th column of $A-\\mu I$. Since the first $n-1$ columns are linearly independent, the $k$-th column for $k \\le n-1$ is not in the span of the preceding columns, which means $R_{kk} \\ne 0$ for $k=1, \\dots, n-1$.\n\nSince we know at least one diagonal entry of $R$ must be zero, and the first $n-1$ diagonal entries are non-zero, it must be that the last diagonal entry is zero:\n$$ R_{nn} = 0 $$\nIf the matrix $A$ were reduced, $a_{k+1,k}=0$ for some $k<n-1$, it would decouple into smaller unreduced Hessenberg blocks. The QR iteration would then effectively proceed on these blocks independently. If $\\mu$ is an eigenvalue of the bottom-right block, the same argument applies to that block, leading to deflation.\n\nSubstituting $R_{nn}=0$ back into our expression for $(A_1)_{n,n-1}$:\n$$ (A_1)_{n,n-1} = R_{nn}Q_{n,n-1} = 0 \\cdot Q_{n,n-1} = 0 $$\nThis completes the derivation.\n\n### Numerical Verification\n\nWe are given the matrix $A = \\begin{pmatrix} 0 & 0 & 6 \\\\ 1 & 0 & -11 \\\\ 0 & 1 & 6 \\end{pmatrix}$ and the shift $\\mu = 1$.\nFirst, we form the matrix $M = A - \\mu I$:\n$$ M = A - 1 \\cdot I = \\begin{pmatrix} 0 & 0 & 6 \\\\ 1 & 0 & -11 \\\\ 0 & 1 & 6 \\end{pmatrix} - \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} -1 & 0 & 6 \\\\ 1 & -1 & -11 \\\\ 0 & 1 & 5 \\end{pmatrix} $$\nNext, we compute the QR factorization of $M$, which is $M=QR$. We will use Givens rotations to transform $M$ into an upper triangular matrix $R$.\n\n**Step 1:** Annihilate the $(2,1)$ entry, $M_{21}=1$. We apply an orthogonal transformation $G_1$ (a Givens rotation) in the $(1,2)$ plane. For the vector $(M_{11}, M_{21}) = (-1, 1)$, a suitable orthogonal transformation matrix is:\n$$ G_1 = \\begin{pmatrix} -1/\\sqrt{2} & 1/\\sqrt{2} & 0 \\\\ -1/\\sqrt{2} & -1/\\sqrt{2} & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} $$\nApplying $G_1$ to $M$:\n$$ M' = G_1 M = \\begin{pmatrix} -1/\\sqrt{2} & 1/\\sqrt{2} & 0 \\\\ -1/\\sqrt{2} & -1/\\sqrt{2} & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} -1 & 0 & 6 \\\\ 1 & -1 & -11 \\\\ 0 & 1 & 5 \\end{pmatrix} = \\begin{pmatrix} \\sqrt{2} & -1/\\sqrt{2} & -17/\\sqrt{2} \\\\ 0 & 1/\\sqrt{2} & 5/\\sqrt{2} \\\\ 0 & 1 & 5 \\end{pmatrix} $$\n**Step 2:** Annihilate the $(3,2)$ entry, $M'_{32}=1$. We apply a Givens rotation $G_2$ in the $(2,3)$ plane.\nThe vector is $(M'_{22}, M'_{32}) = (1/\\sqrt{2}, 1)$. We define $G_2 = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & c' & s' \\\\ 0 & -s' & c' \\end{pmatrix}$ where $c' = (1/\\sqrt{2})/\\sqrt{(1/\\sqrt{2})^2+1^2} = 1/\\sqrt{3}$ and $s' = 1/\\sqrt{(1/\\sqrt{2})^2+1^2} = \\sqrt{2/3}$.\n$$ G_2 = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1/\\sqrt{3} & \\sqrt{2/3} \\\\ 0 & -\\sqrt{2/3} & 1/\\sqrt{3} \\end{pmatrix} $$\nApplying $G_2$ to $M'$ gives $R$:\n$$ R = G_2 M' = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1/\\sqrt{3} & \\sqrt{2/3} \\\\ 0 & -\\sqrt{2/3} & 1/\\sqrt{3} \\end{pmatrix} \\begin{pmatrix} \\sqrt{2} & -1/\\sqrt{2} & -17/\\sqrt{2} \\\\ 0 & 1/\\sqrt{2} & 5/\\sqrt{2} \\\\ 0 & 1 & 5 \\end{pmatrix} $$\n$$ R = \\begin{pmatrix} \\sqrt{2} & -1/\\sqrt{2} & -17/\\sqrt{2} \\\\ 0 & \\frac{1}{\\sqrt{3}}\\frac{1}{\\sqrt{2}} + \\frac{\\sqrt{2}}{\\sqrt{3}}(1) & \\frac{1}{\\sqrt{3}}\\frac{5}{\\sqrt{2}} + \\frac{\\sqrt{2}}{\\sqrt{3}}(5) \\\\ 0 & -\\frac{\\sqrt{2}}{\\sqrt{3}}\\frac{1}{\\sqrt{2}} + \\frac{1}{\\sqrt{3}}(1) & -\\frac{\\sqrt{2}}{\\sqrt{3}}\\frac{5}{\\sqrt{2}} + \\frac{1}{\\sqrt{3}}(5) \\end{pmatrix} = \\begin{pmatrix} \\sqrt{2} & -\\frac{1}{\\sqrt{2}} & -\\frac{17}{\\sqrt{2}} \\\\ 0 & \\frac{3}{\\sqrt{6}} & \\frac{15}{\\sqrt{6}} \\\\ 0 & 0 & 0 \\end{pmatrix} $$\nSo the upper triangular matrix is:\n$$ R = \\begin{pmatrix} \\sqrt{2} & -1/\\sqrt{2} & -17/\\sqrt{2} \\\\ 0 & \\sqrt{3/2} & 5\\sqrt{3/2} \\\\ 0 & 0 & 0 \\end{pmatrix} $$\nThe factorization is $M = QR$ where $Q = G_1^T G_2^T$. The resulting matrix $A_1$ is $A_1 = RQ + I$. We need to compute the $(3,2)$ entry of $A_1$.\n$$ (A_1)_{3,2} = (RQ+I)_{3,2} = (RQ)_{3,2} = \\sum_{k=1}^3 R_{3k}Q_{k2} $$\nThe third row of $R$ is $(R_{31}, R_{32}, R_{33}) = (0, 0, 0)$.\nTherefore,\n$$ (A_1)_{3,2} = R_{31}Q_{12} + R_{32}Q_{22} + R_{33}Q_{32} = 0 \\cdot Q_{12} + 0 \\cdot Q_{22} + 0 \\cdot Q_{32} = 0 $$\nThe calculation confirms the theoretical result that the $(n,n-1)$ entry (here, $(3,2)$) deflates to zero.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "In practice, we don't know the eigenvalues beforehand; the goal is to find them. We must therefore use a strategy to choose shifts $\\mu_k$ that we hope are good approximations. This computational exercise sets up a race between three different shift strategies: the basic (and slow) no-shift method, the intuitive Rayleigh quotient shift, and the powerful Wilkinson's shift. By implementing and comparing their performance on matrices with challenging clustered eigenvalues, you will see firsthand the dramatic impact a sophisticated shift strategy has on convergence speed .",
            "id": "3283557",
            "problem": "Let $A \\in \\mathbb{R}^{n \\times n}$ be a real, symmetric matrix. The orthogonal-triangular (QR) factorization of a square matrix $M$ is defined by $M = Q R$ with $Q$ orthogonal and $R$ upper triangular. The shifted QR iteration for approximating eigenvalues of $A$ constructs a sequence of similar matrices via the update $A^{(k+1)} = R^{(k)} Q^{(k)} + \\mu_k I$, where $A^{(k)} - \\mu_k I = Q^{(k)} R^{(k)}$ and $I$ is the identity matrix. Because similarity transformations preserve eigenvalues, this process aims to reduce off-diagonal entries while maintaining the spectrum. Deflation occurs when the magnitude of the subdiagonal entry $|a^{(k)}_{m,m-1}|$ of the active trailing principal submatrix is sufficiently small, at which point the trailing eigenvalue is considered converged and the iteration continues on the remaining leading principal submatrix. The rate at which deflation occurs depends strongly on the choice of the shift $\\mu_k$.\n\nDesign matrices with clustered eigenvalues and compare the convergence rates, measured by the total number of QR iterations required for complete deflation, for the following three shift strategies applied to the trailing active principal submatrix of size $m$ at each step:\n- No shift: $\\mu_k = 0$.\n- Single Rayleigh shift: $\\mu_k = \\rho(e_m) = e_m^\\top A^{(k)} e_m = a^{(k)}_{m,m}$, where $e_m$ is the $m$-th standard basis vector.\n- Wilkinson’s shift: $\\mu_k$ is the eigenvalue of the trailing $2 \\times 2$ block $$ \\begin{bmatrix} a^{(k)}_{m-1,m-1} & a^{(k)}_{m-1,m} \\\\ a^{(k)}_{m-1,m} & a^{(k)}_{m,m} \\end{bmatrix} $$ that is closer to $a^{(k)}_{m,m}$.\n\nStarting from the fundamental facts that similarity transformations preserve eigenvalues, the QR factorization exists for full rank square matrices, and for symmetric matrices real eigenvalues exist and orthogonal similarity preserves symmetry, implement the following:\n1. Construct an orthogonal matrix $Q$ deterministically for a given $n$ by taking the $Q$ factor from the QR factorization of the matrix $M$ with entries $m_{i,j} = \\sin(i+j)$ for $i,j \\in \\{1,\\dots,n\\}$.\n2. Form $A = Q \\Lambda Q^\\top$, where $\\Lambda = \\operatorname{diag}(\\lambda_1,\\dots,\\lambda_n)$ and the $\\lambda_i$ are specified to produce eigenvalue clusters.\n3. Apply the shifted QR iteration to $A$ for each of the three shift strategies. At each iteration on the active size $m$, compute $A_m - \\mu I_m = Q R$ and update $A_m \\leftarrow R Q + \\mu I_m$, where $I_m$ is the identity of size $m$. Check for deflation by testing $|a_{m,m-1}| \\le \\tau$, where $\\tau$ is a fixed tolerance. When deflation occurs, set $a_{m,m-1} = a_{m-1,m} = 0$ and reduce $m \\leftarrow m-1$. Continue until all eigenvalues have deflated or a maximum iteration count is reached. Use absolute tolerance $\\tau = 10^{-12}$ and maximum iterations $N_{\\text{max}} = 10000$.\n\nTest Suite:\n- Case $1$ ($n=8$): $\\lambda = [1.000, 1.001, 1.002, 2.000, 2.001, 3.000, 4.000, 5.000]$.\n- Case $2$ ($n=8$): $\\lambda = [1.5000, 1.5001, 1.5002, 1.5003, 2.0000, 2.0001, 3.0000, 3.00005]$.\n- Case $3$ ($n=3$): $\\lambda = [1.0000000, 1.0000001, 2.0000000]$.\n\nFor each case, report the total number of QR iterations needed for complete deflation under the three strategies, in the order: no shift, Rayleigh shift, Wilkinson’s shift. If complete deflation is not achieved within $N_{\\text{max}}$ iterations, report the total iterations actually performed.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list of lists with no spaces, where each inner list corresponds to one test case and contains three integers in the order specified. For example, the output should look like `[[n_1^{\\text{none}},n_1^{\\text{rayleigh}},n_1^{\\text{wilkinson}}],[n_2^{\\text{none}},n_2^{\\text{rayleigh}},n_2^{\\text{wilkinson}}],[n_3^{\\text{none}},n_3^{\\text{rayleigh}},n_3^{\\text{wilkinson}}]`.",
            "solution": "The user has provided a well-defined problem in numerical linear algebra. The task is to implement the shifted QR algorithm for finding eigenvalues of a symmetric matrix and to compare the convergence performance of three different shift strategies: no shift, Rayleigh quotient shift, and Wilkinson's shift.\n\nThe problem is scientifically grounded, well-posed, objective, and contains all necessary information for a unique, verifiable solution. It addresses a fundamental concept in scientific computing—the impact of shift strategies on the convergence rate of an iterative eigensolver. The test cases, featuring matrices with clustered eigenvalues, are designed to prominently display the theoretical differences in performance between the chosen strategies. Therefore, the problem is valid and a solution will be provided.\n\nThe solution will be developed following these principles:\n1.  **Matrix Construction**: A symmetric matrix $A \\in \\mathbb{R}^{n \\times n}$ with a predefined set of real eigenvalues $\\Lambda = \\operatorname{diag}(\\lambda_1, \\dots, \\lambda_n)$ is constructed via a similarity transformation $A = Q \\Lambda Q^\\top$. The orthogonal matrix $Q$ is generated deterministically from the QR factorization of a matrix $M$ with entries $m_{ij} = \\sin(i+j)$, ensuring reproducibility. This construction guarantees that $A$ is symmetric and its eigenvalues are precisely the specified $\\lambda_i$.\n\n2.  **Shifted QR Iteration**: The core of the algorithm is the iterative generation of a sequence of matrices $\\{A^{(k)}\\}$, starting with $A^{(0)} = A$, that are all orthogonally similar to $A$ and thus share the same eigenvalues. The sequence is designed to converge to a diagonal matrix (or a block-diagonal form from which eigenvalues can be easily extracted). The update rule for a given shift $\\mu_k$ is:\n    1.  Perform a QR factorization of the shifted matrix: $A^{(k)} - \\mu_k I = Q^{(k)} R^{(k)}$.\n    2.  Update the matrix by reversing the order of multiplication and adding back the shift: $A^{(k+1)} = R^{(k)} Q^{(k)} + \\mu_k I$.\n\n    This process constitutes a similarity transformation, as $R^{(k)} = (Q^{(k)})^\\top (A^{(k)} - \\mu_k I)$, so $A^{(k+1)} = (Q^{(k)})^\\top (A^{(k)} - \\mu_k I) Q^{(k)} + \\mu_k I = (Q^{(k)})^\\top A^{(k)} Q^{(k)}$. For a symmetric $A^{(k)}$, the resulting $A^{(k+1)}$ is also symmetric.\n\n3.  **Deflation**: The algorithm's efficiency stems from a process called deflation. For symmetric matrices, the QR iteration tends to cause the last subdiagonal element of the active matrix, $a^{(k)}_{m,m-1}$, to converge to zero. When its magnitude $|a^{(k)}_{m,m-1}|$ falls below a specified tolerance $\\tau$ (here, $\\tau=10^{-12}$), the corresponding last diagonal element $a^{(k)}_{m,m}$ is considered a converged eigenvalue. This eigenvalue is \"deflated\" from the problem by setting the subdiagonal entry to zero ($a_{m,m-1} \\leftarrow 0, a_{m-1,m} \\leftarrow 0$) and reducing the size of the active submatrix for subsequent iterations from $m$ to $m-1$. The process continues until all eigenvalues are found (i.e., $m=1$).\n\n4.  **Shift Strategies**: The convergence rate is critically dependent on the choice of the shift $\\mu_k$ at each step. We will implement and compare three strategies applied to the trailing active principal submatrix of size $m$.\n\n    *   **No Shift**: $\\mu_k = 0$. This is the unshifted QR algorithm. Its convergence is generally linear and can be prohibitively slow, especially for matrices with eigenvalues of similar magnitude or in clusters.\n\n    *   **Rayleigh Quotient Shift**: $\\mu_k = a^{(k)}_{m,m}$. This shift uses the bottom-right element of the active submatrix as the current best estimate for an eigenvalue. This strategy typically achieves quadratic convergence for well-separated eigenvalues but can perform poorly in certain cases, such as the presence of nearly identical eigenvalues.\n\n    *   **Wilkinson's Shift**: This is a more robust strategy for symmetric matrices. The shift $\\mu_k$ is chosen as one of the two eigenvalues of the trailing $2 \\times 2$ submatrix:\n        $$\n        B = \\begin{bmatrix} a^{(k)}_{m-1,m-1} & a^{(k)}_{m-1,m} \\\\ a^{(k)}_{m-1,m} & a^{(k)}_{m,m} \\end{bmatrix}\n        $$\n        Specifically, $\\mu_k$ is the eigenvalue of $B$ that is closer to $a^{(k)}_{m,m}$. Let $\\alpha = a^{(k)}_{m-1,m-1}$, $\\beta = a^{(k)}_{m-1,m}$, and $\\omega = a^{(k)}_{m,m}$. The two eigenvalues of $B$ are given by $\\lambda = \\omega + \\delta \\pm \\sqrt{\\delta^2 + \\beta^2}$, where $\\delta = (\\alpha - \\omega)/2$. The shift that is closer to $\\omega$ is found to be:\n        $$\n        \\mu_k = \\omega + \\delta - \\operatorname{sgn}(\\delta) \\sqrt{\\delta^2 + \\beta^2}\n        $$\n        where $\\operatorname{sgn}(\\delta)$ is defined as $1$ if $\\delta \\ge 0$ and $-1$ if $\\delta < 0$. This choice guarantees convergence, which is typically cubic for symmetric matrices, making it exceptionally effective even for matrices with pathologically close eigenvalues.\n\nThe implementation will apply these three strategies to a set of test matrices with clustered eigenvalues. The total number of QR updates required for complete deflation (or until a maximum iteration limit of $N_{\\text{max}} = 10000$ is reached) will be recorded for each strategy, providing a quantitative comparison of their performance.",
            "answer": "```python\nimport numpy as np\n\ndef run_qr_algorithm(A_orig, shift_strategy, tol, max_iter):\n    \"\"\"\n    Applies the shifted QR algorithm to find the eigenvalues of a symmetric matrix.\n\n    Args:\n        A_orig (np.ndarray): The initial symmetric matrix.\n        shift_strategy (str): The shift strategy ('none', 'rayleigh', 'wilkinson').\n        tol (float): The tolerance for deflation.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        int: The total number of iterations performed.\n    \"\"\"\n    A = np.copy(A_orig)\n    n = A.shape[0]\n    m = n\n    iterations = 0\n\n    while m > 1:\n        if iterations >= max_iter:\n            break\n\n        # Check for deflation: if a subdiagonal element is close to zero,\n        # reduce the size of the active submatrix.\n        # Check |a_{m, m-1}|, which in 0-based indexing is |A[m-1, m-2]|.\n        if np.abs(A[m-1, m-2]) <= tol:\n            # Explicitly set to zero as per problem description.\n            A[m-1, m-2] = 0.0\n            A[m-2, m-1] = 0.0\n            m -= 1\n            continue\n\n        # Select the shift mu based on the chosen strategy.\n        # The shift is calculated from the current active submatrix of size m.\n        mu = 0.0\n        if shift_strategy == 'rayleigh':\n            # Rayleigh quotient shift: mu = a_{m,m}\n            mu = A[m-1, m-1]\n        elif shift_strategy == 'wilkinson':\n            # Wilkinson's shift: eigenvalue of trailing 2x2 block\n            # closer to a_{m,m}.\n            if m > 1:\n                alpha = A[m-2, m-2]\n                beta = A[m-2, m-1]\n                omega = A[m-1, m-1]\n\n                delta = (alpha - omega) / 2.0\n                \n                # Use sgn(delta) = 1 for delta >= 0 as is standard.\n                sign_delta = 1.0 if delta >= 0 else -1.0\n                \n                # This form is numerically stable and gives the eigenvalue closer to omega.\n                mu = omega + delta - sign_delta * np.sqrt(delta**2 + beta**2)\n\n        # Perform one step of the shifted QR iteration on the active submatrix.\n        active_A = A[:m, :m]\n        I_m = np.identity(m)\n        \n        Q, R = np.linalg.qr(active_A - mu * I_m)\n        \n        # Update the active submatrix.\n        A[:m, :m] = R @ Q + mu * I_m\n        \n        iterations += 1\n        \n    return iterations\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (8, np.array([1.000, 1.001, 1.002, 2.000, 2.001, 3.000, 4.000, 5.000])),\n        (8, np.array([1.5000, 1.5001, 1.5002, 1.5003, 2.0000, 2.0001, 3.0000, 3.00005])),\n        (3, np.array([1.0000000, 1.0000001, 2.0000000]))\n    ]\n\n    tol = 1e-12\n    max_iter = 10000\n    shift_strategies = ['none', 'rayleigh', 'wilkinson']\n    \n    all_results = []\n\n    for n, lambdas in test_cases:\n        # Step 1: Construct the orthogonal matrix Q deterministically.\n        # M_ij = sin(i+j) for i,j in {1,...,n}.\n        # In 0-based indexing for numpy, this corresponds to sin((i_0+1) + (j_0+1)).\n        indices = np.arange(1, n + 1)\n        M = np.sin(indices[:, None] + indices)\n        Q, _ = np.linalg.qr(M)\n\n        # Step 2: Form the symmetric matrix A = Q * Lambda * Q^T.\n        Lambda = np.diag(lambdas)\n        A = Q @ Lambda @ Q.T\n        \n        case_results = []\n        for strategy in shift_strategies:\n            iters = run_qr_algorithm(A, strategy, tol, max_iter)\n            case_results.append(iters)\n        \n        all_results.append(case_results)\n\n    # Format the final output string as specified.\n    output_str = f\"[{','.join([f'[{c[0]},{c[1]},{c[2]}]' for c in all_results])}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "The Wilkinson shift is the cornerstone of modern QR algorithms for symmetric matrices due to its rapid, cubic convergence rate. However, its theoretical power must be paired with careful implementation to avoid the pitfalls of finite-precision arithmetic. This problem challenges you to analyze the standard formula for the Wilkinson shift, identify a scenario where it suffers from catastrophic cancellation, and derive the mathematically equivalent, yet numerically stable, formula used in robust scientific software. This practice is a crucial lesson in the art of creating algorithms that are not just theoretically correct but also practically reliable .",
            "id": "3283423",
            "problem": "Consider the trailing $2 \\times 2$ block that determines the shift in the orthogonal-triangular (QR) algorithm with shifts:\n$$\nB \\;=\\; \\begin{pmatrix} a & b \\\\ b & c \\end{pmatrix}.\n$$\nThe Wilkinson shift is defined as the eigenvalue of $B$ that is closer (in absolute difference) to the bottom-right entry $c$. Starting only from the characteristic polynomial definition $\\det(B - \\lambda I) = 0$ and the quadratic formula, do the following:\n\n1) Derive the two eigenvalues of $B$ in terms of $a$, $b$, and $c$, and identify which branch corresponds to the eigenvalue that is closer to $c$ as a function of the sign of $d = \\tfrac{a - c}{2}$. Explain why, when $|d| \\gg |b|$ and $d > 0$, directly computing the eigenvalue closer to $c$ using a naive quadratic-formula expression exhibits catastrophic cancellation.\n\n2) By purely algebraic manipulation of the characteristic equation and identities implied by it, derive a numerically stable, closed-form expression for the eigenvalue closer to $c$ that avoids subtracting nearly equal numbers.\n\n3) Using your stable expression, evaluate the Wilkinson shift for the specific trailing block\n$$\nB \\;=\\; \\begin{pmatrix} 10^{8} & 10^{-4} \\\\ 10^{-4} & 10^{-8} \\end{pmatrix}.\n$$\nProvide your final numerical value as a decimal rounded to ten significant figures.\n\nYour final answer must be a single real number (no units).",
            "solution": "The user has posed a three-part problem concerning the Wilkinson shift used in the QR algorithm for finding eigenvalues of a symmetric matrix. I will first validate the problem statement and then proceed to solve it step-by-step.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   The matrix in question is a $2 \\times 2$ symmetric block: $B = \\begin{pmatrix} a & b \\\\ b & c \\end{pmatrix}$.\n-   The Wilkinson shift is defined as the eigenvalue of $B$ that is closer to $c$.\n-   A helper variable is defined: $d = \\frac{a - c}{2}$.\n-   The derivation must start from the characteristic polynomial $\\det(B - \\lambda I) = 0$ and the quadratic formula.\n-   Part 1: Derive the eigenvalues of $B$, identify the one closer to $c$ as a function of $\\operatorname{sgn}(d)$, and explain the catastrophic cancellation that occurs in the naive calculation when $|d| \\gg |b|$ and $d > 0$.\n-   Part 2: Derive a numerically stable, closed-form expression for the Wilkinson shift.\n-   Part 3: Evaluate the Wilkinson shift for the specific matrix $B = \\begin{pmatrix} 10^{8} & 10^{-4} \\\\ 10^{-4} & 10^{-8} \\end{pmatrix}$ and provide the result rounded to ten significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is a standard, fundamental topic in numerical linear algebra. The Wilkinson shift, the QR algorithm, and the analysis of numerical stability (specifically, catastrophic cancellation) are all well-established concepts. The matrix is symmetric, ensuring real eigenvalues, which is consistent with the context.\n-   **Well-Posed:** The problem is clearly stated with a sequence of logical tasks leading to a unique mathematical derivation and a specific numerical result. All necessary definitions and data are provided.\n-   **Objective:** The language is formal, precise, and free of any subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a well-posed, scientifically sound problem in numerical analysis. I will now proceed with a full solution.\n\n### Part 1: Eigenvalue Derivation and Cancellation Analysis\n\nThe eigenvalues $\\lambda$ of the matrix $B$ are the roots of the characteristic polynomial, given by $\\det(B - \\lambda I) = 0$.\n$$\n\\det\\left(\\begin{pmatrix} a & b \\\\ b & c \\end{pmatrix} - \\lambda \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\right) = \\det\\begin{pmatrix} a - \\lambda & b \\\\ b & c - \\lambda \\end{pmatrix} = 0\n$$\nExpanding the determinant gives the quadratic equation:\n$$\n(a - \\lambda)(c - \\lambda) - b^2 = 0\n$$\n$$\n\\lambda^2 - (a+c)\\lambda + (ac - b^2) = 0\n$$\nUsing the quadratic formula to solve for $\\lambda$:\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{(a+c)^2 - 4(ac - b^2)}}{2}\n$$\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{a^2 + 2ac + c^2 - 4ac + 4b^2}}{2}\n$$\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{a^2 - 2ac + c^2 + 4b^2}}{2}\n$$\n$$\n\\lambda = \\frac{(a+c) \\pm \\sqrt{(a-c)^2 + 4b^2}}{2}\n$$\nIntroducing the given variable $d = \\frac{a-c}{2}$, we have $a-c = 2d$. We also note that $\\frac{a+c}{2} = \\frac{(c+2d)+c}{2} = c+d$. Substituting these into the expression for $\\lambda$:\n$$\n\\lambda = \\frac{a+c}{2} \\pm \\frac{\\sqrt{4d^2 + 4b^2}}{2} = (c+d) \\pm \\sqrt{d^2+b^2}\n$$\nThe two eigenvalues are $\\lambda_1 = c+d+\\sqrt{d^2+b^2}$ and $\\lambda_2 = c+d-\\sqrt{d^2+b^2}$.\n\nThe Wilkinson shift is the eigenvalue closer to $c$. We must compare the distances $|\\lambda_1 - c|$ and $|\\lambda_2 - c|$.\n$$\n|\\lambda_1 - c| = |d + \\sqrt{d^2+b^2}|\n$$\n$$\n|\\lambda_2 - c| = |d - \\sqrt{d^2+b^2}|\n$$\nSince $b^2 \\ge 0$, we have $\\sqrt{d^2+b^2} \\ge \\sqrt{d^2} = |d|$. The smaller distance corresponds to the expression where $d$ and $\\sqrt{d^2+b^2}$ are subtracted. This depends on the sign of $d$.\n-   If $d > 0$, then $|d - \\sqrt{d^2+b^2}| = \\sqrt{d^2+b^2}-d$ is smaller than $|d + \\sqrt{d^2+b^2}| = d+\\sqrt{d^2+b^2}$. The closer eigenvalue is $\\lambda_2$.\n-   If $d < 0$, then $|d + \\sqrt{d^2+b^2}| = \\sqrt{d^2+b^2}-|d|$ is smaller than $|d - \\sqrt{d^2+b^2}| = |d|+\\sqrt{d^2+b^2}$. The closer eigenvalue is $\\lambda_1$.\n-   If $d = 0$, both eigenvalues are equidistant from $c$. By convention (e.g., as in the original work by Wilkinson), one may choose a specific branch.\n\nWe can unify this choice using the sign function, $\\operatorname{sgn}(d)$, where we define $\\operatorname{sgn}(0)=1$. The term with the smaller magnitude is always $d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$. Thus, the Wilkinson shift, $\\mu$, is given by:\n$$\n\\mu = c + \\left(d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}\\right)\n$$\n\nNow, consider the case where $|d| \\gg |b|$ and $d>0$. The Wilkinson shift is $\\mu = c+d-\\sqrt{d^2+b^2}$.\nIn this regime, $\\sqrt{d^2+b^2} = d\\sqrt{1+(b/d)^2}$. Using a binomial approximation, since $(b/d)^2$ is very small:\n$$\n\\sqrt{d^2+b^2} \\approx d\\left(1 + \\frac{1}{2}\\left(\\frac{b}{d}\\right)^2\\right) = d + \\frac{b^2}{2d}\n$$\nThe value of $\\sqrt{d^2+b^2}$ is very close to $d$. When the expression $\\mu = c + (d - \\sqrt{d^2+b^2})$ is evaluated in finite-precision arithmetic, the subtraction $d - \\sqrt{d^2+b^2}$ involves two nearly equal numbers. This leads to a massive loss of significant figures in the result, an effect known as catastrophic cancellation. The computed result for the shift will have very low relative accuracy.\n\n### Part 2: Derivation of a Numerically Stable Expression\n\nTo avoid the catastrophic cancellation in $d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$, we can use an algebraic manipulation based on \"rationalizing the numerator\".\nLet the term causing instability be $T = d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$. We multiply and divide by its conjugate, $d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$.\n$$\nT = \\frac{\\left(d - \\operatorname{sgn}(d)\\sqrt{d^2+b^2}\\right) \\left(d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}\\right)}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\n$$\nT = \\frac{d^2 - (\\operatorname{sgn}(d))^2(d^2+b^2)}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\nSince $(\\operatorname{sgn}(d))^2=1$ for $d \\neq 0$:\n$$\nT = \\frac{d^2 - (d^2+b^2)}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}} = \\frac{-b^2}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\nThe denominator, $d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}$, involves the addition of two terms with the same sign ($d$ and $\\operatorname{sgn}(d)\\sqrt{...}$), thus avoiding cancellation.\nSubstituting this stable expression for $T$ back into the formula for the shift $\\mu = c+T$, we get the numerically stable form:\n$$\n\\mu = c - \\frac{b^2}{d + \\operatorname{sgn}(d)\\sqrt{d^2+b^2}}\n$$\n\n### Part 3: Numerical Evaluation\n\nWe are given the matrix:\n$$\nB = \\begin{pmatrix} 10^{8} & 10^{-4} \\\\ 10^{-4} & 10^{-8} \\end{pmatrix}\n$$\nThe parameters are $a = 10^8$, $b = 10^{-4}$, and $c = 10^{-8}$.\nFirst, we compute $d$.\n$$\nd = \\frac{a-c}{2} = \\frac{10^8 - 10^{-8}}{2} = 5 \\times 10^7 - 5 \\times 10^{-9}\n$$\nSince $d > 0$, $\\operatorname{sgn}(d) = 1$. The stable formula for the Wilkinson shift $\\mu$ is:\n$$\n\\mu = c - \\frac{b^2}{d + \\sqrt{d^2+b^2}}\n$$\nWe have the values:\n$c = 10^{-8}$\n$b^2 = (10^{-4})^2 = 10^{-8}$\n\nThe problem is now to evaluate $\\mu = 10^{-8} - \\frac{10^{-8}}{d + \\sqrt{d^2+10^{-8}}}$ with high precision.\nLet's compute the denominator $D = d + \\sqrt{d^2+b^2}$.\n$d = 49999999.999999995$\n$d^2 = (49999999.999999995)^2 \\approx 2.5 \\times 10^{15}$\n$b^2 = 10^{-8}$\nThe term $\\sqrt{d^2+b^2}$ is very close to $d$. Using a high-precision calculator, we find:\n$d+\\sqrt{d^2+b^2} \\approx 99999999.99999999000000001...$\nWhich is approximately $10^8 - 10^{-8}$. Let's compute the fraction:\n$$\n\\frac{b^2}{d + \\sqrt{d^2+b^2}} = \\frac{10^{-8}}{99999999.999999990...} \\approx \\frac{10^{-8}}{10^8} = 10^{-16}\n$$\nSo, a first approximation of the shift is $\\mu \\approx 10^{-8} - 10^{-16} = 0.0000000099999999$.\nTo achieve the required ten significant figures, a more precise calculation is necessary. Using a computational tool with sufficient precision (e.g., Python's `Decimal` library with a precision of 50 digits), we can evaluate the stable expression:\n$\\mu = c - \\frac{b^2}{d+\\sqrt{d^2+b^2}}$\nThis yields the value:\n$\\mu \\approx 0.0000000099999999000000005...$\nIn scientific notation, this is $9.9999999000000005... \\times 10^{-9}$.\n\nTo round this to ten significant figures, we examine the first eleven significant digits: $9.999999900$. The eleventh digit is $0$, which is less than $5$, so we do not round up.\nThe rounded value to ten significant figures is $9.999999900 \\times 10^{-9}$.\nAs a decimal, this is $0.000000009999999900$.",
            "answer": "$$\n\\boxed{0.00000000999999990}\n$$"
        }
    ]
}