{
    "hands_on_practices": [
        {
            "introduction": "位移逆幂法的威力在于它能够通过选择一个位移量 $\\sigma$ 来指定目标特征值。然而，一个常见的误解是，该方法会找到一个“看起来”很近的特征值，例如通过观察对角线元素来猜测。本练习通过一个精心设计的思想实验，揭示了一个关键原理：该方法收敛到的，是与位移量在数学意义上最接近的特征值，而这未必是最直观的那个。掌握这一概念对于有效选择位移量和解读方法结果至关重要。",
            "id": "3273240",
            "problem": "考虑实对称矩阵\n$$\nA=\\begin{pmatrix}\n-9  0  0 \\\\\n0  \\tfrac{137}{50}  \\tfrac{42}{25} \\\\\n0  \\tfrac{42}{25}  \\tfrac{44}{25}\n\\end{pmatrix}.\n$$\n一位工程师打算找到谱中点附近的一个内部特征值，他考察了中间的对角元 $1.76$ 并将其作为一个合理的选择，从而选定了位移 $\\sigma=1.8$。从一个在所有特征向量方向上都有非零分量的通用初始向量开始，带位移的反幂法通过对 $(A-\\sigma I)$ 进行重复求解并随后进行归一化来运作。\n\n请仅使用特征值和特征向量的基本定义和性质，确定当选择此 $\\sigma$ 值时，对于几乎所有初始向量，带位移反幂法将收敛到 $A$ 的哪个特征值。请给出一个实数作为答案。在你的推理中不应进行数值迭代，最终答案也无需四舍五入。",
            "solution": "该问题要求我们确定在给定**位移** $\\sigma=1.8$ 的情况下，带位移的反幂法将收敛到矩阵 $A$ 的哪个特征值。\n\n带位移的反幂法是一种用于寻找矩阵 $A$ 的特征值-特征向量对 $(\\lambda, v)$ 的迭代算法。其迭代公式为 $x_{k+1} = (A - \\sigma I)^{-1} x_k$，其中 $\\sigma$ 是一个选定的位移。这等价于对矩阵 $M = (A - \\sigma I)^{-1}$ 应用幂法。幂法收敛到与 $M$ 的模最大的特征值相对应的特征向量。\n\n设 $A$ 的特征值为 $\\lambda_i$。那么矩阵 $M = (A - \\sigma I)^{-1}$ 的特征值为 $\\mu_i = \\frac{1}{\\lambda_i - \\sigma}$。该算法将收敛到与满足 $|\\mu_j| = \\max_i |\\mu_i|$ 的特征值 $\\mu_j$ 相关联的特征向量。这个条件等价于找到 $A$ 的一个特征值 $\\lambda_j$，它在复平面上与位移 $\\sigma$ 的距离最小，即 $|\\lambda_j - \\sigma| = \\min_i |\\lambda_i - \\sigma|$。\n\n对于一个通用的初始向量（即在所有特征向量方向上都有非零分量的向量），该方法收敛到与位移 $\\sigma$ 最近的 $A$ 的特征值。因此，任务简化为：\n1. 求出矩阵 $A$ 的所有特征值。\n2. 对于每个特征值 $\\lambda_i$ 和给定的位移 $\\sigma=1.8$，计算距离 $|\\lambda_i - \\sigma|$。\n3. 确定使该距离最小的特征值 $\\lambda_j$。\n\n首先，我们求矩阵 $A$ 的特征值：\n$$\nA=\\begin{pmatrix}\n-9  0  0\\\\\n0  \\tfrac{137}{50}  \\tfrac{42}{25}\\\\\n0  \\tfrac{42}{25}  \\tfrac{44}{25}\n\\end{pmatrix}\n$$\n矩阵 $A$ 是分块对角矩阵。其特征值是其对角块的特征值。第一个块是 $1 \\times 1$ 矩阵 $(-9)$，所以立即可以确定一个特征值为 $\\lambda_1 = -9$。\n\n剩下的两个特征值是 $2 \\times 2$ 子矩阵的特征值：\n$$\nB = \\begin{pmatrix}\n\\tfrac{137}{50}  \\tfrac{42}{25}\\\\\n\\tfrac{42}{25}  \\tfrac{44}{25}\n\\end{pmatrix}\n$$\n为了简化计算，我们可以通过将矩阵改写为公分母形式来提出因子 $\\frac{1}{50}$：\n$$\nB = \\begin{pmatrix}\n\\tfrac{137}{50}  \\tfrac{84}{50}\\\\\n\\tfrac{84}{50}  \\tfrac{88}{50}\n\\end{pmatrix} = \\frac{1}{50} \\begin{pmatrix}\n137  84\\\\\n84  88\n\\end{pmatrix}\n$$\n设矩阵为 $B' = \\begin{pmatrix} 137  84 \\\\ 84  88 \\end{pmatrix}$。如果 $\\mu$ 是 $B'$ 的一个特征值，那么 $\\lambda = \\frac{\\mu}{50}$ 就是 $B$ 的一个特征值。$B'$ 的特征值是其特征方程 $\\det(B' - \\mu I) = 0$ 的根，即 $\\mu^2 - \\text{tr}(B')\\mu + \\det(B') = 0$。\n\n$B'$ 的迹是：\n$$\n\\text{tr}(B') = 137 + 88 = 225\n$$\n$B'$ 的行列式是：\n$$\n\\det(B') = (137)(88) - (84)(84) = 12056 - 7056 = 5000\n$$\n$\\mu$ 的特征方程是：\n$$\n\\mu^2 - 225\\mu + 5000 = 0\n$$\n我们解这个关于 $\\mu$ 的二次方程：\n$$\n\\mu = \\frac{225 \\pm \\sqrt{(-225)^2 - 4(1)(5000)}}{2} = \\frac{225 \\pm \\sqrt{50625 - 20000}}{2} = \\frac{225 \\pm \\sqrt{30625}}{2}\n$$\n平方根是 $\\sqrt{30625} = 175$。因此，$B'$ 的特征值为：\n$$\n\\mu_2 = \\frac{225 + 175}{2} = \\frac{400}{2} = 200\n$$\n$$\n\\mu_3 = \\frac{225 - 175}{2} = \\frac{50}{2} = 25\n$$\n那么子矩阵 $B$ 的特征值是：\n$$\n\\lambda_2 = \\frac{\\mu_2}{50} = \\frac{200}{50} = 4\n$$\n$$\n\\lambda_3 = \\frac{\\mu_3}{50} = \\frac{25}{50} = \\frac{1}{2} = 0.5\n$$\n所以，矩阵 $A$ 的特征值集合是 $\\{\\lambda_1, \\lambda_2, \\lambda_3\\} = \\{-9, 4, 0.5\\}$。\n\n接下来，我们计算每个特征值到**位移** $\\sigma = 1.8$ 的距离。\n1. 对于 $\\lambda_1 = -9$：\n   $$\n   |\\lambda_1 - \\sigma| = |-9 - 1.8| = |-10.8| = 10.8\n   $$\n2. 对于 $\\lambda_2 = 4$：\n   $$\n   |\\lambda_2 - \\sigma| = |4 - 1.8| = |2.2| = 2.2\n   $$\n3. 对于 $\\lambda_3 = 0.5$：\n   $$\n   |\\lambda_3 - \\sigma| = |0.5 - 1.8| = |-1.3| = 1.3\n   $$\n比较这些距离，我们发现 $1.3  2.2  10.8$。最小的距离是 $1.3$，对应于特征值 $\\lambda_3 = 0.5$。\n\n因此，对于几乎所有的初始向量，使用位移 $\\sigma = 1.8$ 的带位移反幂法将收敛到特征值 $\\lambda_3 = 0.5$。",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        },
        {
            "introduction": "位移逆幂法最实际的应用之一，是从海量数据或全谱分析中高效地验证某个特定的特征值。本练习将指导你为此目的实现该方法。你将直面一个关键的数值计算挑战：当位移量 $\\sigma$ 恰好是真实特征值时，矩阵 $(A - \\sigma I)$ 会变为奇异矩阵。本练习将教会你如何通过引入标准的数值稳定化技术来处理这种奇异性，从而构建一个稳健的算法。",
            "id": "3273273",
            "problem": "你的任务是使用带位移的逆幂法，验证一个由全谱求解器得到的声称特征值是否确实为给定实矩阵的特征值。验证时，应将位移量设置为该声称的特征值。其理论基础如下：根据定义，一个标量 $\\lambda$ 是方阵 $A \\in \\mathbb{R}^{n \\times n}$ 的特征值，当且仅当存在一个非零向量 $x \\in \\mathbb{R}^{n}$ 使得 $A x = \\lambda x$。验证过程将基于构建一个迭代过程，当位移等于真实特征值时，该过程会产生一个向量，其残差在指定的容差范围内满足 $A x - \\lambda x \\approx 0$。如果位移等于真实特征值，算子 $A - \\lambda I$ 是奇异的，因此必须使用一种数值上稳健的方案来定义和求解出现的线性系统。\n\n设计并实现一个程序，使用带位移 $\\sigma = \\lambda_{\\text{test}}$ 的逆幂法来为多个矩阵验证 $\\lambda_{\\text{test}}$。你的程序必须遵循以下规范：\n\n- 对于每个测试用例，从一个确定性的初始向量 $x_{0}$ 开始。该向量通过使用固定的伪随机数生成器种子构建，并将结果向量归一化为单位 $2$-范数。\n- 在迭代索引 $k \\ge 1$ 时，求解形如 $(A - \\sigma I) y_{k} = x_{k-1}$ 的线性系统以得到 $y_{k}$，然后设置 $x_{k} = y_{k} / \\lVert y_{k} \\rVert_{2}$。当 $(A - \\sigma I)$ 是奇异的或数值不稳定的时，你必须通过以下任一可接受的机制，以稳定的方式定义 $y_{k}$：(i) Tikhonov 型正则化，即求解 $\\big((A - \\sigma I) + \\mu I\\big) y_{k} = x_{k-1}$，其中 $\\mu  0$ 是一个小数；或 (ii) 通过数值稳定的方法（如奇异值分解 (SVD)）计算的最小二乘解。你的实现可以自适应地在这些机制之间进行选择，以确保迭代能够进行。\n- 在每次迭代中，计算瑞利商 $\\rho_{k} = \\dfrac{x_{k}^{\\top} A x_{k}}{x_{k}^{\\top} x_{k}}$ 和残差 $r_{\\sigma,k} = \\lVert A x_{k} - \\sigma x_{k} \\rVert_{2}$ 及 $r_{\\rho,k} = \\lVert A x_{k} - \\rho_{k} x_{k} \\rVert_{2}$。\n- 当 $r_{\\sigma,k} \\le \\tau_{\\text{res}}$ 或达到最大迭代次数 $k_{\\max}$ 时终止。此外，还需报告最终的 $r_{\\sigma,k}$ 和最后的瑞利商 $\\rho_{k}$。\n\n在所有测试中使用以下常量：$\\tau_{\\text{res}} = 10^{-8}$，一个用于可选交叉检验的绝对瑞利商接近容差 $\\tau_{\\text{rq}} = 10^{-8}$，以及 $k_{\\max} = 30$。当需要正则化时，你可以选择一个基准值 $\\mu = 10^{-8} \\max(1,\\lVert A \\rVert_{F})$，并在必要时进行调整以成功求解。初始向量必须通过从具有固定种子的标准正态分布中抽取元素来创建，并归一化为单位 $2$-范数。\n\n验证规则：当且仅当终止时的最终 $r_{\\sigma,k}$ 小于或等于 $\\tau_{\\text{res}}$ 时，声明 $\\lambda_{\\text{test}}$ 已被验证。你可以选择性地要求 $\\lvert \\rho_{k} - \\sigma \\rvert \\le \\tau_{\\text{rq}}$ 作为次要检查；如果使用此次要检查，则两个条件必须同时满足。\n\n测试套件。对于每个测试用例，你将获得 $(A, \\lambda_{\\text{test}})$：\n\n- 测试 1：$A_{1} = \\begin{bmatrix} 2  1  0 \\\\ 1  2  1 \\\\ 0  1  2 \\end{bmatrix}$，$\\lambda_{\\text{test},1} = 2$。\n- 测试 2：$A_{2} = \\begin{bmatrix} 1  2  3 \\\\ 0  4  5 \\\\ 0  0  6 \\end{bmatrix}$，$\\lambda_{\\text{test},2} = 4$。\n- 测试 3：$A_{3} = A_{1}$ (来自测试 1)，$\\lambda_{\\text{test},3} = 2.5$。\n- 测试 4：$A_{4} = \\operatorname{diag}(1.0, 1.001, 10.0)$，$\\lambda_{\\text{test},4} = 1.001$。\n\n对于每个测试用例，你的程序必须运行所述的验证过程，并为每个测试用例生成一个结果，包含：\n- 一个布尔值，说明 $\\lambda_{\\text{test}}$ 是否根据上述规则被验证。\n- 最终的瑞利商 $\\rho_{k}$，以浮点数形式表示。\n- 最终的残差 $r_{\\sigma,k}$，以浮点数形式表示。\n- 执行的迭代次数，以整数形式表示。\n\n最终输出格式。你的程序应生成一行输出，其中包含用方括号括起来的逗号分隔的结果列表，每个单独的测试结果以 $[\\text{boolean}, \\rho_{k}, r_{\\sigma,k}, k]$ 的形式出现。例如，包含两个假设结果的输出将如下所示：$[[\\text{True},1.0,1e-9,7],[\\text{False},0.0,1.23,30]]$。此问题中没有物理单位，也没有角度；所有数值均为标准浮点格式的实数。程序不得读取任何输入，并且必须确定性地执行。",
            "solution": "该问题要求实现带位移的逆幂法，以验证给定值 $\\sigma = \\lambda_{\\text{test}}$ 是否为矩阵 $A$ 的一个特征值。该算法的核心是将预解算子 $(A-\\sigma I)^{-1}$ 迭代地应用于一个向量。\n\n### 带位移的逆幂法原理\n带位移的逆幂法是一种算法，用于寻找矩阵 $A$ 的一个特征向量，该特征向量对应于最接近所选位移 $\\sigma$ 的特征值 $\\lambda_j$。该方法依赖于这样一个性质：如果矩阵 $A$ 的特征值是 $\\{\\lambda_i\\}$，那么矩阵 $(A-\\sigma I)^{-1}$ 的特征值就是 $\\{(\\lambda_i - \\sigma)^{-1}\\}$。当幂法应用于 $(A-\\sigma I)^{-1}$ 时，它会收敛到与模最大的特征值相关联的特征向量。这对应于 $|\\lambda_j - \\sigma|$ 最小的那个 $(\\lambda_j - \\sigma)^{-1}$ 值。迭代步骤定义为求解 $(A-\\sigma I)y_k = x_{k-1}$ 得到 $y_k$，然后归一化以获得下一个迭代向量，$x_k = y_k / \\lVert y_k \\rVert_2$。\n\n### 奇异性问题\n当位移 $\\sigma$ 是 $A$ 的一个真实特征值时，会出现一个关键的复杂情况。在这种情况下，矩阵 $A - \\sigma I$ 是奇异的，其逆矩阵未定义。线性系统 $(A-\\sigma I)y_k = x_{k-1}$ 变为病态问题。必须采用鲁棒的数值方法来处理这种情况。问题陈述提出了两种此类机制：Tikhonov 正则化和最小二乘解。\n\n### 对所提出机制的分析\n1.  **Tikhonov 正则化**：此方法将系统修改为 $((A - \\sigma I) + \\mu I) y_k = x_{k-1}$，其中 $\\mu$ 是一个小的正常数。这等价于求解 $(A - (\\sigma - \\mu) I) y_k = x_{k-1}$，这是一个位移略微扰动的标准逆幂迭代，有效位移为 $\\sigma_{\\text{eff}} = \\sigma - \\mu$。由于 $\\sigma$ 是一个特征值 $\\lambda_j$，且 $\\mu$ 很小，所以 $\\sigma_{\\text{eff}}$ 非常接近 $\\lambda_j$。预解算子 $(A - \\sigma_{\\text{eff}} I)^{-1}$ 是良定义的（假设 $\\sigma - \\mu$ 不是另一个特征值，对于一个小的固定 $\\mu$ 来说这极不可能），并且有一个非常大的特征值 $(\\lambda_j - (\\sigma - \\mu))^{-1} = \\mu^{-1}$。因此，该方法将快速收敛到与 $\\lambda_j$ 对应的期望特征向量。这种方法在数学上是可靠且稳健的。\n\n2.  **最小二乘解**：这涉及寻找一个向量 $y_k$ 以最小化残差范数 $\\lVert (A - \\sigma I) y_k - x_{k-1} \\rVert_2$。解决此问题的标准数值求解器，例如基于奇异值分解 (SVD) 的求解器，通常会找到具有最小欧几里得范数的唯一解。此解与 $(A - \\sigma I)^T$ 的零空间正交。如果 $A$ 是对称的，这意味着解与我们试图找到的特征向量正交，这会适得其反。对于非对称矩阵，情况更为复杂，但该方法不保证会放大期望特征向量的分量。\n\n### 选择的实现策略\n对于此应用，Tikhonov 正则化方法明显更优。我们将采用一种统一的策略，在所有情况下都应用正则化。通过求解 $(A - \\sigma I + \\mu I) y_k = x_{k-1}$，其中 $\\mu$ 是一个固定的小数，该算法可以稳健地处理两种情况：\n- 如果 $\\sigma$ 是一个特征值，正则化使系统良态化，并确保收敛到正确的特征向量。\n- 如果 $\\sigma$ 不是一个特征值，则 $\\mu I$ 项是对一个已经非奇异的系统的一个小扰动，迭代过程基本上与标准的带位移逆幂迭代相同。\n\n这一策略简洁、优雅，并避免了最小范数最小二乘方法的陷阱。我们将使用建议的正则化参数基准值 $\\mu = 10^{-8} \\max(1, \\lVert A \\rVert_F)$。\n\n验证过程如下：\n对于每个测试用例 $(A, \\lambda_{\\text{test}})$，我们设置 $\\sigma = \\lambda_{\\text{test}}$ 并生成一个确定性的初始单位向量 $x_0$。然后我们迭代最多 $k_{\\max}$ 次。在每次迭代 $k$ 中，我们求解正则化线性系统以得到 $y_k$，将其归一化得到 $x_k$，并计算残差 $r_{\\sigma,k} = \\lVert A x_k - \\sigma x_k \\rVert_2$。如果 $r_{\\sigma,k}$ 低于容差 $\\tau_{\\text{res}} = 10^{-8}$，迭代终止，并声明 $\\lambda_{\\text{test}}$ “已验证”。否则，过程继续直到 $k=k_{\\max}$，届时报告最终状态。瑞利商 $\\rho_k = x_k^{\\top} A x_k$ 也在每一步计算，并报告其最终值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_verification(A: np.ndarray, lambda_test: float, k_max: int, tau_res: float, seed: int) - list:\n    \"\"\"\n    Verifies a claimed eigenvalue using the shifted inverse power method.\n\n    Args:\n        A: The square matrix.\n        lambda_test: The claimed eigenvalue to test (used as the shift).\n        k_max: Maximum number of iterations.\n        tau_res: Residual tolerance for convergence.\n        seed: Seed for the pseudorandom number generator for the initial vector.\n\n    Returns:\n        A list containing [verified, final_rho, final_r_sigma, iterations].\n    \"\"\"\n    n = A.shape[0]\n    sigma = lambda_test\n\n    # 1. Initialization\n    # Set seed for a deterministic initial vector\n    np.random.seed(seed)\n    # Create and normalize initial vector from a standard normal distribution\n    x_prev = np.random.randn(n)\n    x_prev = x_prev / np.linalg.norm(x_prev)\n\n    # Use Tikhonov regularization a priori for a unified, robust approach.\n    # This is equivalent to a slightly perturbed shift sigma_eff = sigma - mu.\n    mu = 1.0e-8 * max(1.0, np.linalg.norm(A, 'fro'))\n    M = A - sigma * np.identity(n) + mu * np.identity(n)\n\n    # Initialize variables to be reported\n    x_k = np.copy(x_prev)\n    rho_k = 0.0\n    r_sigma_k = np.inf\n    k = 0\n\n    # 2. Iteration Loop\n    for k_iter in range(1, k_max + 1):\n        k = k_iter\n\n        try:\n            # Solve the regularized system: (A - sigma*I + mu*I) * y_k = x_{k-1}\n            y_k = np.linalg.solve(M, x_prev)\n        except np.linalg.LinAlgError:\n            # This case is extremely unlikely if mu is chosen properly, but as a safeguard,\n            # we report failure by breaking the loop with a high residual.\n            r_sigma_k = np.inf\n            break\n        \n        y_norm = np.linalg.norm(y_k)\n\n        # If y_k is a zero vector, iteration cannot proceed.\n        if y_norm  np.finfo(float).eps:\n            break\n\n        # Normalize to get the next iterate\n        x_k = y_k / y_norm\n\n        # 3. Compute Metrics\n        Ax_k = A @ x_k\n        # Rayleigh quotient (since x_k is unit norm, x_k.T @ x_k = 1)\n        rho_k = x_k.T @ Ax_k\n        # Residual with respect to the shift sigma\n        r_sigma_k = np.linalg.norm(Ax_k - sigma * x_k)\n\n        # Update for the next iteration\n        x_prev = x_k\n\n        # 4. Termination Condition\n        if r_sigma_k = tau_res:\n            break\n\n    # 5. Finalization\n    # The verification rule is based on the final residual\n    verified = r_sigma_k = tau_res\n\n    return [verified, rho_k, r_sigma_k, k]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define constants from the problem statement\n    TAU_RES = 1.0e-8\n    K_MAX = 30\n    # A single fixed seed is used to generate the initial vector for all tests,\n    # ensuring full reproducibility of the entire script.\n    SEED = 42\n\n    # Define the test cases from the problem statement\n    A1 = np.array([[2.0, 1.0, 0.0], [1.0, 2.0, 1.0], [0.0, 1.0, 2.0]])\n    lambda1 = 2.0\n\n    A2 = np.array([[1.0, 2.0, 3.0], [0.0, 4.0, 5.0], [0.0, 0.0, 6.0]])\n    lambda2 = 4.0\n\n    A3 = A1\n    lambda3 = 2.5\n\n    A4 = np.diag([1.0, 1.001, 10.0])\n    lambda4 = 1.001\n\n    test_cases = [\n        (A1, lambda1),\n        (A2, lambda2),\n        (A3, lambda3),\n        (A4, lambda4),\n    ]\n\n    results = []\n    for A, lambda_test in test_cases:\n        result = run_verification(A, lambda_test, K_MAX, TAU_RES, SEED)\n        results.append(result)\n\n    # Final print statement in the exact required format\n    result_strings = []\n    for res in results:\n        verified_str = str(res[0])\n        rho_k_str = f\"{res[1]:.15g}\"\n        r_sigma_k_str = f\"{res[2]:.15g}\"\n        k_str = str(res[3])\n        result_strings.append(f\"[{verified_str},{rho_k_str},{r_sigma_k_str},{k_str}]\")\n\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "虽然实对称矩阵的特征值都是实数，但许多物理和工程系统是由非对称矩阵建模的，这些矩阵可能拥有成对出现的复数特征值。本练习将你的技能扩展到复数域，展示了如何通过使用复数位移量 $\\sigma$ 来找到这些复数特征对。这项练习对于将该方法应用于更广泛的问题（如稳定性分析和量子力学）至关重要。",
            "id": "3273174",
            "problem": "实现一个程序，对于一个给定的实非对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 和一个复数位移 $\\sigma \\in \\mathbb{C}$，使用带位移的逆幂法计算 $A$ 的一个复特征对 $(\\lambda, x)$ 的近似值。推导和算法必须从以下基本基础开始：特征对的定义 $A x = \\lambda x$、对于任何位移 $\\sigma \\in \\mathbb{C}$，当 $\\sigma$ 不是特征值时预解式 $(A - \\sigma I)^{-1}$ 存在，以及如果 $A$ 可对角化为 $A = V \\Lambda V^{-1}$，则 $(A - \\sigma I)^{-1} = V (\\Lambda - \\sigma I)^{-1} V^{-1}$。从这个基础可以得出，将 $(A - \\sigma I)^{-1}$ 重复应用于一个非零向量并进行归一化，将会放大对应于具有最小 $|\\lambda_j - \\sigma|$ 的特征值的特征向量方向上的分量，从而引导迭代趋向该特征向量。该方法需要能够处理 $\\sigma \\in \\mathbb{C}$，以求解实非对称矩阵 $A$ 的复特征对。\n\n你的程序必须：\n- 实现带固定复数位移 $\\sigma \\in \\mathbb{C}$ 的位移逆幂迭代。\n- 使用 $\\mathbb{C}^n$ 中的一个初始向量 $x_0 \\neq 0$；确定性地选择 $x_0$（例如，所有分量都等于 1），并在 $\\ell^2$-范数下对其进行归一化。\n- 在每次迭代中，使用直接线性求解方法精确求解 $(A - \\sigma I) y_k = x_{k-1}$，然后归一化得到 $x_k = y_k / \\|y_k\\|_2$。\n- 在第 $k$ 次迭代中，使用瑞利商 $\\lambda_k = \\dfrac{x_k^* A x_k}{x_k^* x_k}$ 估计特征值，其中 $x_k^*$ 表示共轭转置，并计算残差 $r_k = A x_k - \\lambda_k x_k$。\n- 当 $\\|r_k\\|_2 \\le \\tau$ 或达到最大迭代次数 $m$ 时终止，其中 $\\tau$ 和 $m$ 是用户选择的容差。如果 $(A - \\sigma I)$ 在数值上是奇异或接近奇异的，则通过加上一个微小的虚部 $\\mathrm{i} \\,\\varepsilon$（其中 $\\varepsilon  0$ 很小，例如 $\\varepsilon = 10^{-12}$）来扰动位移，然后继续。\n- 返回最后的 $(\\lambda_k, x_k)$、残差范数 $\\|r_k\\|_2$ 以及执行的迭代次数。\n\n使用以下测试套件。对于每个测试，使用最大迭代次数 $m = 100$ 和容差 $\\tau = 10^{-10}$。\n- 测试 1（嵌入在 $3 \\times 3$ 矩阵中的 $2 \\times 2$ 实数块中的复数对）：\n  - $A_1 = \\begin{pmatrix} 0  -1  0 \\\\ 1  0  0 \\\\ 0  0  2 \\end{pmatrix}$，\n  - $\\sigma_1 = 0 + 1.05 \\,\\mathrm{i}$。\n  - 目标特征值接近 $\\lambda \\approx 0 + 1 \\,\\mathrm{i}$。\n- 测试 2（同一矩阵中的共轭对）：\n  - $A_2 = A_1$，\n  - $\\sigma_2 = 0 - 1.03 \\,\\mathrm{i}$。\n  - 目标特征值接近 $\\lambda \\approx 0 - 1 \\,\\mathrm{i}$。\n- 测试 3（非对称 $2 \\times 2$ 旋转缩放矩阵）：\n  - $A_3 = \\begin{pmatrix} 1.1  -0.4 \\\\ 0.4  1.1 \\end{pmatrix}$，\n  - $\\sigma_3 = 1.06 + 0.39 \\,\\mathrm{i}$。\n  - 目标特征值接近 $\\lambda \\approx 1.1 + 0.4 \\,\\mathrm{i}$。\n- 测试 4（具有两个不同复共轭对的块对角矩阵）：\n  - $A_4 = \\operatorname{blkdiag}\\!\\left(\\begin{pmatrix} 1.1  -0.3 \\\\ 0.3  1.1 \\end{pmatrix}, \\begin{pmatrix} 0.5  -1.2 \\\\ 1.2  0.5 \\end{pmatrix}\\right)$，\n  - $\\sigma_4 = 0.48 + 1.25 \\,\\mathrm{i}$。\n  - 目标特征值接近 $\\lambda \\approx 0.5 + 1.2 \\,\\mathrm{i}$。\n\n对于每个测试用例，你的程序必须输出一个列表 $[\\Re(\\lambda), \\Im(\\lambda), \\|r\\|_2, k]$，其中 $\\Re(\\lambda)$ 和 $\\Im(\\lambda)$ 表示最终特征值估计的实部和虚部，$\\|r\\|_2$ 是最终残差范数，而 $k$ 是所用的迭代次数。将 $\\Re(\\lambda)$、$\\Im(\\lambda)$ 和 $\\|r\\|_2$ 四舍五入到八位小数，并将 $k$ 作为整数输出。\n\n最终输出格式：你的程序应生成单行输出，其中包含四个测试的结果，格式为一个用方括号括起来的逗号分隔列表，其中每个条目本身都是一个用方括号括起来的、无空格的逗号分隔列表，例如 $[[a_1,b_1,c_1,d_1],[a_2,b_2,c_2,d_2],[a_3,b_3,c_3,d_3],[a_4,b_4,c_4,d_4]]$，其中所有 $a_j, b_j, c_j$ 都四舍五入到八位小数，而 $d_j$ 是整数。本问题不涉及物理单位。",
            "solution": "本问题要求实现带位移的逆幂法，以针对一个给定的复数位移 $\\sigma \\in \\mathbb{C}$，寻找一个实非对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的复特征对 $(\\lambda, x)$。\n\n### 理论基础\n\n带位移的逆幂法源于标准特征值问题 $A x = \\lambda x$，其中 $\\lambda$ 是特征值，$x$ 是对应的特征向量。\n\n1.  **引入位移**：对于一个给定的、非 $A$ 的特征值的复数位移 $\\sigma \\in \\mathbb{C}$，我们可以变换特征值方程：\n    $$\n    A x - \\sigma x = \\lambda x - \\sigma x\n    $$\n    $$\n    (A - \\sigma I) x = (\\lambda - \\sigma) x\n    $$\n    其中 $I$ 是单位矩阵。\n\n2.  **预解矩阵**：由于 $\\sigma$ 不是一个特征值，矩阵 $(A - \\sigma I)$ 是可逆的。这个逆矩阵 $(A - \\sigma I)^{-1}$ 被称为 $A$ 在 $\\sigma$ 处的预解式。将预解式应用于方程两边，得到：\n    $$\n    x = (\\lambda - \\sigma) (A - \\sigma I)^{-1} x\n    $$\n    重新整理可得：\n    $$\n    (A - \\sigma I)^{-1} x = \\frac{1}{\\lambda - \\sigma} x\n    $$\n    这个方程揭示了一个关键性质：如果 $x$ 是 $A$ 的一个特征向量，其特征值为 $\\lambda$，那么 $x$ 也是矩阵 $(A - \\sigma I)^{-1}$ 的一个特征向量，其特征值为 $\\mu = \\frac{1}{\\lambda - \\sigma}$。\n\n3.  **收敛机制**：幂法是一种迭代算法，用于找到对应于模最大（主）特征值的特征向量。当我们将幂法应用于矩阵 $B = (A - \\sigma I)^{-1}$ 时，它会收敛到与 $B$ 的主特征值相关联的特征向量。设 $A$ 的特征值为 $\\lambda_1, \\lambda_2, \\ldots, \\lambda_n$。$B$ 的特征值为 $\\mu_j = \\frac{1}{\\lambda_j - \\sigma}$。对 $B$ 使用幂法将找到对应于使 $|\\mu_j|$ 最大化的 $\\mu_j$ 的特征向量。\n    $$\n    \\max_j |\\mu_j| = \\max_j \\left| \\frac{1}{\\lambda_j - \\sigma} \\right| = \\frac{1}{\\min_j |\\lambda_j - \\sigma|}\n    $$\n    因此，应用于 $(A - \\sigma I)^{-1}$ 的幂法会收敛到 $A$ 的对应于最接近位移 $\\sigma$ 的特征值 $\\lambda_j$ 的特征向量。这就是带位移的逆幂法的原理。\n\n### 算法构建\n\n该算法通过迭代来优化特征向量的近似值。由于矩阵 $A$ 是实的，但位移 $\\sigma$ 和目标特征值可能是复数，因此所有的计算都必须使用复数算术进行。\n\n1.  **初始化**：\n    - 选择一个随机或确定性的初始向量 $x_0 \\in \\mathbb{C}^n$，使得 $x_0 \\neq 0$。按照规定，我们选择一个全为 1 的向量。\n    - 在 $\\ell^2$-范数下对初始向量进行归一化：$x_0 \\leftarrow \\frac{x_0}{\\|x_0\\|_2}$。\n\n2.  **迭代**：对于 $k = 1, 2, \\ldots, m$（其中 $m$ 是最大迭代次数）：\n    - 对 $(A - \\sigma I)^{-1}$ 应用幂法的核心步骤是计算 $y_k = (A - \\sigma I)^{-1} x_{k-1}$。我们不显式地计算逆矩阵，因为这在计算上很昂贵且数值上不稳定，而是求解等价的线性系统以得到 $y_k$：\n      $$\n      (A - \\sigma I) y_k = x_{k-1}\n      $$\n    - 对结果向量进行归一化，以防止其模发散或消失：\n      $$\n      x_k = \\frac{y_k}{\\|y_k\\|_2}\n      $$\n\n3.  **特征值估计与收敛性检查**：\n    - 在每次迭代 $k$ 中，可以使用瑞利商从当前的特征向量近似值 $x_k$ 估计相应的特征值 $\\lambda_k$。对于复向量 $x_k$，瑞利商定义为：\n      $$\n      \\lambda_k = \\frac{x_k^* A x_k}{x_k^* x_k}\n      $$\n    - 其中 $x_k^*$ 是 $x_k$ 的共轭转置。由于 $x_k$ 被归一化为单位 $\\ell^2$-范数（$x_k^* x_k = \\|x_k\\|_2^2 = 1$），表达式简化为 $\\lambda_k = x_k^* A x_k$。\n    - 近似特征对 $(\\lambda_k, x_k)$ 的质量通过残差向量 $r_k = A x_k - \\lambda_k x_k$ 的范数来衡量。\n    - 如果残差范数低于指定的容差 $\\tau$，即 $\\|r_k\\|_2 \\le \\tau$，或者达到最大迭代次数 $m$，则迭代终止。\n\n4.  **数值稳定性**：\n    - 如果位移 $\\sigma$ 非常接近某个实际特征值 $\\lambda_j$，矩阵 $(A - \\sigma I)$ 会变得奇异或接近奇异（病态）。这可能导致线性求解失败或产生大的数值误差。\n    - 按照规定，如果发现 $(A - \\sigma I)$ 在数值上是奇异的，则通过加上一个小的虚部分量来扰动位移 $\\sigma$，即 $\\sigma \\leftarrow \\sigma + \\mathrm{i}\\varepsilon$，其中 $\\varepsilon  0$ 很小（例如 $\\varepsilon = 10^{-12}$）。这会将位移稍微移离实轴，对于实矩阵，这通常能解决奇异性问题，从而让迭代可以继续。这个检查在主迭代循环前执行一次。\n\n完整的算法流程如下：\n- 给定：矩阵 $A$、位移 $\\sigma$、容差 $\\tau$、最大迭代次数 $m$。\n- 将 $x_0$ 初始化为全为 1 的归一化向量。\n- 构建 $M = A - \\sigma I$。检查奇异性；如果奇异，则通过加上 $\\mathrm{i}\\varepsilon$ 来扰动 $\\sigma$ 并重新构建 $M$。\n- 对于 $k = 1, \\dots, m$：\n    1.  求解 $M y_k = x_{k-1}$ 得到 $y_k$。\n    2.  归一化 $x_k = y_k / \\|y_k\\|_2$。\n    3.  计算 $\\lambda_k = x_k^* A x_k$。\n    4.  计算 $\\|r_k\\|_2 = \\|A x_k - \\lambda_k x_k\\|_2$。\n    5.  如果 $\\|r_k\\|_2 \\le \\tau$，则中断循环并返回 $(\\lambda_k, x_k, \\|r_k\\|_2, k)$。\n    6.  设置 $x_{k-1} = x_k$。\n- 如果循环完成，则返回最终的 $(\\lambda_m, x_m, \\|r_m\\|_2, m)$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef shifted_inverse_power_method(A, sigma, max_iter=100, tol=1e-10):\n    \"\"\"\n    Computes an eigenpair of a matrix A using the shifted inverse power method.\n\n    Args:\n        A (np.ndarray): The real, non-symmetric matrix.\n        sigma (complex): The complex shift.\n        max_iter (int): Maximum number of iterations.\n        tol (float): Tolerance for the residual norm to determine convergence.\n\n    Returns:\n        A tuple (re_lambda, im_lambda, residual_norm, iterations) containing the\n        real and imaginary parts of the eigenvalue estimate, the final residual\n        norm, and the number of iterations performed.\n    \"\"\"\n    n = A.shape[0]\n    A_complex = A.astype(np.complex128)\n\n    # 1. Initialization\n    x_prev = np.ones(n, dtype=np.complex128)\n    x_prev = x_prev / np.linalg.norm(x_prev)\n\n    current_sigma = complex(sigma)\n    \n    # 2. Construct M and handle potential singularity\n    M = A_complex - current_sigma * np.identity(n, dtype=np.complex128)\n    try:\n        # Test if M is invertible by attempting to solve a system.\n        # This is more robust than checking the determinant.\n        np.linalg.solve(M, x_prev)\n    except np.linalg.LinAlgError:\n        # Perturb sigma if M is singular\n        perturbation = 1e-12j\n        current_sigma += perturbation\n        M = A_complex - current_sigma * np.identity(n, dtype=np.complex128)\n\n    lmbda = 0.0 + 0.0j\n    x_curr = x_prev\n    residual_norm = np.inf\n\n    # 3. Iteration\n    for k in range(1, max_iter + 1):\n        # Solve (A - sigma*I)y_k = x_{k-1}\n        y_k = np.linalg.solve(M, x_prev)\n        \n        # Normalize to get x_k\n        norm_y = np.linalg.norm(y_k)\n        if norm_y == 0:\n            # This case occurs if x_prev is in the null space of M, which is highly unlikely.\n            # We exit gracefully if it happens.\n            break\n        x_curr = y_k / norm_y\n        \n        # 4. Eigenvalue estimation and residual calculation\n        # Rayleigh quotient: lmbda = (x_curr* @ A @ x_curr) / (x_curr* @ x_curr)\n        # Denominator is 1 due to normalization.\n        lmbda = x_curr.conj().T @ A_complex @ x_curr\n        \n        residual_norm = np.linalg.norm(A_complex @ x_curr - lmbda * x_curr)\n        \n        # 5. Check for convergence\n        if residual_norm  tol:\n            return lmbda.real, lmbda.imag, residual_norm, k\n        \n        x_prev = x_curr\n\n    # Return the last computed values if max_iter is reached\n    return lmbda.real, lmbda.imag, residual_norm, max_iter\n\ndef solve():\n    \"\"\"\n    Sets up and runs the test cases for the shifted inverse power method.\n    \"\"\"\n    m = 100\n    tau = 1e-10\n\n    # Test Case 1\n    A1 = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 2]], dtype=float)\n    sigma1 = 0 + 1.05j\n\n    # Test Case 2\n    A2 = A1\n    sigma2 = 0 - 1.03j\n\n    # Test Case 3\n    A3 = np.array([[1.1, -0.4], [0.4, 1.1]], dtype=float)\n    sigma3 = 1.06 + 0.39j\n\n    # Test Case 4\n    A4 = np.array([\n        [1.1, -0.3, 0.0, 0.0],\n        [0.3, 1.1, 0.0, 0.0],\n        [0.0, 0.0, 0.5, -1.2],\n        [0.0, 0.0, 1.2, 0.5]\n    ], dtype=float)\n    sigma4 = 0.48 + 1.25j\n\n    test_cases = [\n        (A1, sigma1),\n        (A2, sigma2),\n        (A3, sigma3),\n        (A4, sigma4),\n    ]\n\n    results_list = []\n    \n    for A, sigma in test_cases:\n        re_l, im_l, res_norm, iters = shifted_inverse_power_method(A, sigma, m, tau)\n        \n        # Format the output as per requirement: [Re(l), Im(l), ||r||, k]\n        # Floats rounded to 8 decimal places.\n        formatted_result = f\"[{re_l:.8f},{im_l:.8f},{res_norm:.8f},{iters}]\"\n        results_list.append(formatted_result)\n        \n    # The final output must be a single line in the format [[...],[...],...]\n    final_output = f\"[{','.join(results_list)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}