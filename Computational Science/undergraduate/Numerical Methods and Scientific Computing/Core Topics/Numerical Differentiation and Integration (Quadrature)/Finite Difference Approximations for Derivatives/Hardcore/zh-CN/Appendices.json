{
    "hands_on_practices": [
        {
            "introduction": "在理论上，减小步长 $h$ 似乎总能提高有限差分近似的精度。然而，在实践中，计算机的有限精度引入了舍入误差，它会随着 $h$ 的减小而增大。这个练习将引导你直面这一基本权衡，通过为截断误差和舍入误差建立模型，你将能够推导出最小化总误差的最优步长，这是数值计算中的一项关键技能。",
            "id": "2391199",
            "problem": "考虑使用对称三点中心差分公式\n$$\nD(h)\\equiv \\frac{f(1+h)-f(1-h)}{2h}.\n$$\n来近似函数 $f(x)=\\exp(x)$ 在点 $x=1$ 处的一阶导数。\n假设函数求值是在浮点运算中进行的，采用舍入到最近值的方式，单位舍入误差为 $u=2^{-53}$，因此每个计算出的函数值满足 $\\operatorname{fl}(f(t))=f(t)\\,(1+\\delta)$，其中 $|\\delta|\\le u$。为了本次分析，假设 $D(h)$ 中的减法和除法是精确的。使用这些假设和基本原理，通过结合截断误差和舍入误差，为在 $x=1$ 处的总绝对误差构建一个上界模型，并确定使该上界最小化的步长 $h>0$ 的值。以单个实数的形式给出最优 $h$。将你的答案四舍五入到3位有效数字。",
            "solution": "该问题要求通过对总误差进行建模并将其最小化，来确定有限差分近似的最优步长 $h$。总误差是近似公式中固有的截断误差和有限精度运算带来的舍入误差的组合。\n\n首先，我们验证问题陈述。\n已知条件如下：\n- 函数：$f(x) = \\exp(x)$。\n- 求值点：$x=1$。\n- 近似公式：$D(h) = \\frac{f(1+h)-f(1-h)}{2h}$。\n- 浮点误差模型：$\\operatorname{fl}(f(t)) = f(t)(1+\\delta)$，其中 $|\\delta| \\le u$。\n- 单位舍入误差：$u=2^{-53}$。\n- 运算假设：减法和除法是精确的。\n- 目标：找到使总绝对误差的上界最小化的最优步长 $h_{\\text{opt}}$。\n\n该问题在数值分析中有科学依据，是适定且客观的。没有可识别的缺陷。该问题是有效的。我们开始求解。\n\n设 $\\tilde{D}(h)$ 表示在浮点运算中计算出的中心差分公式的值。总绝对误差 $E_{\\text{total}}$ 由精确导数 $f'(1)$ 与计算出的近似值 $\\tilde{D}(h)$ 之差的绝对值给出：\n$$ E_{\\text{total}} = |f'(1) - \\tilde{D}(h)| $$\n通过引入精确算术近似 $D(h)$，我们可以使用三角不等式将此误差分解为两部分：\n$$ E_{\\text{total}} = |f'(1) - D(h) + D(h) - \\tilde{D}(h)| \\le |f'(1) - D(h)| + |D(h) - \\tilde{D}(h)| $$\n项 $E_{\\text{trunc}}(h) = |f'(1) - D(h)|$ 是截断误差，其产生的原因是有限差分公式是导数的一个近似。项 $E_{\\text{round}}(h) = |D(h) - \\tilde{D}(h)|$ 是舍入误差，其产生于计算机算术的有限精度。\n\n现在我们将为每个误差分量推导一个上界，以构建我们的误差模型。\n\n**截断误差分析**\n我们使用泰勒定理在点 $x=1$ 附近展开函数 $f(x)$。对于函数 $f(x) = \\exp(x)$，它的所有阶导数也都是 $\\exp(x)$。因此，对于所有 $n \\ge 0$，有 $f^{(n)}(1) = \\exp(1) = e$。\n$f(1+h)$ 和 $f(1-h)$ 的泰勒级数展开式为：\n$$ f(1+h) = f(1) + f'(1)h + \\frac{f''(1)}{2!}h^2 + \\frac{f'''(1)}{3!}h^3 + O(h^4) $$\n$$ f(1-h) = f(1) - f'(1)h + \\frac{f''(1)}{2!}h^2 - \\frac{f'''(1)}{3!}h^3 + O(h^4) $$\n将第二个展开式从第一个展开式中减去：\n$$ f(1+h) - f(1-h) = 2f'(1)h + \\frac{2f'''(1)}{6}h^3 + O(h^5) $$\n将此结果代入 $D(h)$ 的公式中：\n$$ D(h) = \\frac{2f'(1)h + \\frac{1}{3}f'''(1)h^3 + O(h^5)}{2h} = f'(1) + \\frac{f'''(1)}{6}h^2 + O(h^4) $$\n因此，截断误差为：\n$$ E_{\\text{trunc}}(h) = |D(h) - f'(1)| = \\left| \\frac{f'''(1)}{6}h^2 + O(h^4) \\right| $$\n对于小的 $h$，主导项与 $h^2$ 成正比。为了给我们的模型建立一个上界，我们使用首项。对于在 $x=1$ 处的函数 $f(x) = \\exp(x)$，我们有 $f'''(1)=e$。因此，截断误差上界的一个简单模型是：\n$$ E_{\\text{trunc}}(h) \\le \\frac{e}{6}h^2 $$\n\n**舍入误差分析**\n计算出的近似值 $\\tilde{D}(h)$ 使用函数求值的浮点值：\n$$ \\tilde{D}(h) = \\frac{\\operatorname{fl}(f(1+h)) - \\operatorname{fl}(f(1-h))}{2h} $$\n使用给定的浮点误差模型 $\\operatorname{fl}(f(t)) = f(t)(1+\\delta)$，其中 $|\\delta| \\le u$，我们有：\n$$ \\tilde{D}(h) = \\frac{f(1+h)(1+\\delta_1) - f(1-h)(1+\\delta_2)}{2h} $$\n其中 $|\\delta_1| \\le u$ 且 $|\\delta_2| \\le u$。舍入误差为：\n$$ E_{\\text{round}}(h) = |D(h) - \\tilde{D}(h)| = \\left| \\frac{f(1+h)-f(1-h)}{2h} - \\frac{f(1+h)(1+\\delta_1) - f(1-h)(1+\\delta_2)}{2h} \\right| $$\n$$ E_{\\text{round}}(h) = \\left| \\frac{-f(1+h)\\delta_1 + f(1-h)\\delta_2}{2h} \\right| \\le \\frac{|f(1+h)||\\delta_1| + |f(1-h)||\\delta_2|}{2h} $$\n使用 $\\delta_i$ 的上界：\n$$ E_{\\text{round}}(h) \\le \\frac{(|f(1+h)| + |f(1-h)|)u}{2h} $$\n为了构建模型，我们对小 $h$ 的函数值进行近似。当 $h \\to 0$ 时，$f(1+h)$ 和 $f(1-h)$ 都趋近于 $f(1)=e$。由于 $\\exp(x)$ 总是正的，所以不需要绝对值。我们将分子近似建模为 $e+e=2e$。\n$$ E_{\\text{round}}(h) \\le \\frac{2eu}{2h} = \\frac{eu}{h} $$\n\n**总误差上界的最小化**\n我们通过将截断误差和舍入误差的上界相加来构建总误差上界模型 $E(h)$：\n$$ E(h) = \\frac{e}{6}h^2 + \\frac{eu}{h} $$\n为了找到使该函数最小化的 $h$ 值，我们计算它关于 $h$ 的导数并令其为零：\n$$ \\frac{dE}{dh} = \\frac{d}{dh} \\left( \\frac{e}{6}h^2 + eu h^{-1} \\right) = \\frac{2e}{6}h - eu h^{-2} = \\frac{e}{3}h - \\frac{eu}{h^2} $$\n令导数为零得到最优的 $h$：\n$$ \\frac{e}{3}h = \\frac{eu}{h^2} \\implies h^3 = \\frac{3eu}{e} = 3u $$\n$$ h_{\\text{opt}} = (3u)^{1/3} $$\n二阶导数 $\\frac{d^2E}{dh^2} = \\frac{e}{3} + \\frac{2eu}{h^3}$ 对于 $h>0$ 总是正的，这证实了该 $h$ 值确实对应于一个最小值。\n\n**数值计算**\n给定 $u=2^{-53}$。将此值代入我们关于 $h_{\\text{opt}}$ 的表达式中：\n$$ h_{\\text{opt}} = (3 \\times 2^{-53})^{1/3} $$\n数值为：\n$$ h_{\\text{opt}} \\approx (3 \\times 1.1102230246 \\times 10^{-16})^{1/3} \\approx (3.3306690738 \\times 10^{-16})^{1/3} \\approx 6.931833 \\times 10^{-6} $$\n按要求将此结果四舍五入到3位有效数字，得到 $6.93 \\times 10^{-6}$。",
            "answer": "$$\\boxed{6.93 \\times 10^{-6}}$$"
        },
        {
            "introduction": "我们推导出的理论收敛阶（例如，$O(h^2)$）依赖于函数足够光滑的假设。当这个假设被违反时会发生什么？这个练习通过一个在某点上存在“尖点”的函数，即$f(x)=|x|^{3/2}$，来探索函数正则性对精度的影响。你会发现实际的收敛速度可能远低于预期，这是一个重要的教训，它提醒我们不能盲目地套用理论公式，而必须理解其背后的条件。",
            "id": "2392345",
            "problem": "编写一个程序，定量评估函数 $f(x)=|x|^{3/2}$ 在点 $x=0$ 处的尖点低正则性对一阶导数有限差分近似精度的影响。精确导数由导数的极限定义，其在 $x=0$ 处的值即为该极限的值。考虑使用步长 $h>0$ 对 $x=0$ 处的一阶导数进行三种有限差分近似：\n1. 前向差分 $D^{+}_{h}f(0)=\\dfrac{f(h)-f(0)}{h}$。\n2. 后向差分 $D^{-}_{h}f(0)=\\dfrac{f(0)-f(-h)}{h}$。\n3. 中心差分 $D^{0}_{h}f(0)=\\dfrac{f(h)-f(-h)}{2h}$。\n对于一组步长 $\\mathcal{H}=\\{10^{-1},10^{-2},10^{-3},10^{-4}\\}$，定义格式 $S\\in\\{+,-,0\\}$ 在步长 $h$ 下的绝对误差为 $e_{S}(h)=\\left|D^{S}_{h}f(0)-f^{\\prime}(0)\\right|$，其中 $f^{\\prime}(0)$ 表示在 $x=0$ 处的精确导数。对于每个格式 $S$，将在连续步长上观测到的成对收敛率定义为\n$$p_{S}(h_{k},h_{k+1})=\\frac{\\log\\left(e_{S}(h_{k})/e_{S}(h_{k+1})\\right)}{\\log\\left(h_{k}/h_{k+1}\\right)},$$\n其中 $\\left(h_{k},h_{k+1}\\right)$ 是 $\\mathcal{H}$ 中按 $h$ 降序排列的每个连续对。如果一对步长中有 $e_{S}(h_{k})=0$ 或 $e_{S}(h_{k+1})=0$，则在计算格式 $S$ 的收敛率时排除该对。将格式 $S$ 的报告收敛率定义为所有包含的连续对的可用 $p_{S}(h_{k},h_{k+1})$ 的中位数。如果某个格式没有包含任何对（例如，如果所有误差均为零），则报告该格式的收敛率为 $+\\infty$。\n你的程序必须按指定顺序计算并报告以下六个量：\n- 前向差分格式的报告收敛率（一个浮点数）。\n- 后向差分格式的报告收敛率（一个浮点数）。\n- 中心差分格式的报告收敛率（一个浮点数，若适用则使用 $+\\infty$）。\n- 在 $\\mathcal{H}$ 中最小步长下前向差分的绝对误差（一个浮点数）。\n- 在 $\\mathcal{H}$ 中最小步长下后向差分的绝对误差（一个浮点数）。\n- 在 $\\mathcal{H}$ 中最小步长下中心差分的绝对误差（一个浮点数）。\n所有量均无单位。你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如 $[r_{+},r_{-},r_{0},e_{+}^{\\min},e_{-}^{\\min},e_{0}^{\\min}]$），其中 $r_{S}$ 表示格式 $S$ 的报告收敛率，而 $e_{S}^{\\min}$ 表示格式 $S$ 在 $h=10^{-4}$ 时的绝对误差。本规范构成了完整的测试套件和确切的所需输出格式。",
            "solution": "该问题已经过验证，被认为是有效的。这是一个数值分析中的适定问题，没有科学或逻辑上的不一致之处。\n\n任务是评估函数 $f(x) = |x|^{3/2}$ 在点 $x=0$ 处一阶导数的三种有限差分格式的收敛性。函数在该点有一个尖点，这意味着其正则性有限。具体来说，该函数在 $x=0$ 处是连续可微的（$C^1$），但不是二阶连续可微的（$C^2$）。预计这种光滑性的缺乏会使数值格式的收敛率低于其在光滑函数上的理论阶数。\n\n首先，我们必须确定导数的精确值 $f'(0)$。使用导数的极限定义：\n$$ f'(0) = \\lim_{h \\to 0} \\frac{f(0+h) - f(0)}{h} = \\lim_{h \\to 0} \\frac{|h|^{3/2} - 0}{h} = \\lim_{h \\to 0} \\frac{|h|^{3/2}}{h} $$\n我们计算左极限和右极限。\n对于 $h \\to 0^{+}$：\n$$ \\lim_{h \\to 0^{+}} \\frac{h^{3/2}}{h} = \\lim_{h \\to 0^{+}} h^{1/2} = 0 $$\n对于 $h \\to 0^{-}$：\n$$ \\lim_{h \\to 0^{-}} \\frac{|h|^{3/2}}{h} = \\lim_{h \\to 0^{-}} \\frac{(-h)^{3/2}}{h} = \\lim_{h \\to 0^{-}} \\frac{-(-h)^{3/2}}{-h} = \\lim_{h \\to 0^{-}} -(-h)^{1/2} = 0 $$\n由于左右极限都等于 $0$，因此导数在 $x=0$ 处存在，其值为 $f'(0) = 0$。\n\n接下来，我们分析二阶导数的行为。对于 $x > 0$，$f(x)=x^{3/2}$，所以 $f'(x) = \\frac{3}{2}x^{1/2}$ 且 $f''(x) = \\frac{3}{4}x^{-1/2}$。对于 $x  0$，$f(x)=(-x)^{3/2}$，所以 $f'(x) = -\\frac{3}{2}(-x)^{1/2}$ 且 $f''(x) = \\frac{3}{4}(-x)^{-1/2}$。在两种情况下，当 $x \\to 0$ 时，都有 $|f''(x)| \\to \\infty$。因此，二阶导数在 $x=0$ 处未定义，而依赖于高阶导数存在性和有界性的标准 Taylor 级数展开误差分析不能直接适用。\n\n我们现在推导每种有限差分近似的解析形式及其绝对误差 $e_S(h) = |D^S_h f(0) - f'(0)|$。对于 $h  0$，我们有 $f(h) = h^{3/2}$ 和 $f(-h) = |-h|^{3/2} = h^{3/2}$。由于 $f(0)=0$ 且 $f'(0)=0$，误差计算得以简化。\n\n1.  **前向差分 ($D^{+}$):**\n    $$ D^{+}_{h}f(0) = \\frac{f(h) - f(0)}{h} = \\frac{h^{3/2} - 0}{h} = h^{1/2} $$\n    绝对误差为：\n    $$ e_{+}(h) = |h^{1/2} - 0| = h^{1/2} $$\n    误差的阶为 $O(h^{0.5})$。理论收敛率为 $p = 0.5$。\n\n2.  **后向差分 ($D^{-}$):**\n    $$ D^{-}_{h}f(0) = \\frac{f(0) - f(-h)}{h} = \\frac{0 - h^{3/2}}{h} = -h^{1/2} $$\n    绝对误差为：\n    $$ e_{-}(h) = |-h^{1/2} - 0| = h^{1/2} $$\n    误差的阶同样为 $O(h^{0.5})$，理论收敛率为 $p = 0.5$。\n\n3.  **中心差分 ($D^{0}$):**\n    $$ D^{0}_{h}f(0) = \\frac{f(h) - f(-h)}{2h} = \\frac{h^{3/2} - h^{3/2}}{2h} = 0 $$\n    绝对误差为：\n    $$ e_{0}(h) = |0 - 0| = 0 $$\n    对于这个特定函数，由于其偶对称性（$f(x) = f(-x)$），中心差分近似对于任何 $h  0$ 都精确为零。这意味着误差恒为零。\n\n有了这些误差的解析表达式，我们就可以计算所需的量。步长集合为 $\\mathcal{H} = \\{10^{-1}, 10^{-2}, 10^{-3}, 10^{-4}\\}$。令 $h_k = 10^{-k}$，其中 $k \\in \\{1, 2, 3, 4\\}$。成对收敛率定义为 $p_{S}(h_{k},h_{k+1})=\\frac{\\log\\left(e_{S}(h_{k})/e_{S}(h_{k+1})\\right)}{\\log\\left(h_{k}/h_{k+1}\\right)}$。分母恒为 $\\log(10^{-k}/10^{-(k+1)}) = \\log(10)$。\n\n对于前向差分格式：\n$e_{+}(h_k) = (10^{-k})^{1/2} = 10^{-k/2}$。\n任何连续对的误差比为 $e_{+}(h_k)/e_{+}(h_{k+1}) = 10^{-k/2} / 10^{-(k+1)/2} = 10^{1/2}$。\n因此，成对收敛率是恒定的：\n$$ p_{+}(h_k, h_{k+1}) = \\frac{\\log(10^{1/2})}{\\log(10)} = \\frac{0.5 \\log(10)}{\\log(10)} = 0.5 $$\n可用收敛率的集合是 $\\{0.5, 0.5, 0.5\\}$。中位数，即报告的收敛率 $r_{+}$，为 $0.5$。在最小步长 $h=10^{-4}$ 下的误差为 $e_{+}(10^{-4}) = (10^{-4})^{1/2} = 10^{-2} = 0.01$。\n\n对于后向差分格式：\n误差 $e_{-}(h_k) = h_k^{1/2}$ 与前向差分的情况相同。因此，报告的收敛率 $r_{-}$ 也为 $0.5$，而在 $h=10^{-4}$ 下的误差为 $e_{-}(10^{-4}) = 0.01$。\n\n对于中心差分格式：\n对于所有 $h  0$，误差 $e_{0}(h)$ 恒为 $0$。根据问题陈述，如果 $e_S(h_k)=0$ 或 $e_S(h_{k+1})=0$，则该对被排除在收敛率计算之外。由于所有误差均为零，无法计算成对收敛率。问题规定在这种情况下，报告的收敛率 $r_{0}$ 必须为 $+\\infty$。在最小步长下的误差 $e_{0}(10^{-4})$ 为 $0$。\n\n需要报告的六个量是：\n1.  前向差分的报告收敛率（$r_{+}$）：$0.5$。\n2.  后向差分的报告收敛率（$r_{-}$）：$0.5$。\n3.  中心差分的报告收敛率（$r_{0}$）：$+\\infty$。\n4.  前向差分在 $h=10^{-4}$ 时的绝对误差（$e_{+}^{\\min}$）：$0.01$。\n5.  后向差分在 $h=10^{-4}$ 时的绝对误差（$e_{-}^{\\min}$）：$0.01$。\n6.  中心差分在 $h=10^{-4}$ 时的绝对误差（$e_{0}^{\\min}$）：$0.0$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes convergence rates and errors for finite difference approximations\n    of the derivative of f(x) = |x|^(3/2) at x=0.\n    \"\"\"\n    \n    # 1. Define the problem parameters\n    \n    # The function f(x) = |x|^(3/2)\n    def f(x):\n        return np.abs(x)**(3/2)\n    \n    # The exact first derivative at x=0 is 0.\n    f_prime_0 = 0.0\n    \n    # Set of step sizes in descending order\n    step_sizes = np.array([1e-1, 1e-2, 1e-3, 1e-4])\n\n    # 2. Define the finite difference schemes\n    def forward_diff(h):\n        return (f(h) - f(0)) / h\n\n    def backward_diff(h):\n        return (f(0) - f(-h)) / h\n\n    def central_diff(h):\n        return (f(h) - f(-h)) / (2 * h)\n\n    schemes = {\n        'forward': forward_diff,\n        'backward': backward_diff,\n        'central': central_diff\n    }\n    \n    # 3. Compute errors and convergence rates for each scheme\n    \n    results = {}\n    \n    for name, scheme_func in schemes.items():\n        # Calculate absolute errors for all step sizes\n        approximations = np.array([scheme_func(h) for h in step_sizes])\n        errors = np.abs(approximations - f_prime_0)\n        \n        # Calculate pairwise convergence rates\n        pairwise_rates = []\n        for k in range(len(step_sizes) - 1):\n            h_k = step_sizes[k]\n            h_k_plus_1 = step_sizes[k+1]\n            e_k = errors[k]\n            e_k_plus_1 = errors[k+1]\n            \n            # Exclude pairs where error is zero, as per problem statement\n            if e_k == 0.0 or e_k_plus_1 == 0.0:\n                continue\n                \n            rate = np.log(e_k / e_k_plus_1) / np.log(h_k / h_k_plus_1)\n            pairwise_rates.append(rate)\n            \n        # Determine the reported convergence rate\n        if not pairwise_rates:\n            # If no rates were computed, report as +infinity\n            reported_rate = float('inf')\n        else:\n            # Otherwise, the reported rate is the median\n            reported_rate = np.median(pairwise_rates)\n            \n        # Store the results for this scheme\n        results[name] = {\n            'rate': reported_rate,\n            'error_min_h': errors[-1] # Error at the smallest h\n        }\n        \n    # 4. Assemble the final output list in the specified order\n    \n    r_plus = results['forward']['rate']\n    r_minus = results['backward']['rate']\n    r_zero = results['central']['rate']\n    \n    e_plus_min = results['forward']['error_min_h']\n    e_minus_min = results['backward']['error_min_h']\n    e_zero_min = results['central']['error_min_h']\n    \n    final_output = [\n        r_plus,\n        r_minus,\n        r_zero,\n        e_plus_min,\n        e_minus_min,\n        e_zero_min\n    ]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_output))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们已经看到，对于很小的 $h$，舍入误差会成为一个问题。当我们的数据本身包含测量噪声时（这在科学和工程领域中很常见），这种效应会被急剧放大。这项综合性练习将指导你模拟一个真实场景：对含噪的位置数据进行微分。你将定量地分析有限差分算子如何像高通滤波器一样放大噪声，并看到噪声误差如何轻易地主导总误差，这对于处理实验数据至关重要。",
            "id": "2392343",
            "problem": "给定一个关于一维位置作为时间函数的含加性测量噪声的时间序列模型。该位置是一个已知的时间平滑函数，在每个采样点上叠加了零均值的独立噪声。您的任务是设计并实现一个程序，对于一组测试用例，该程序能够构造带噪声的位置数据，使用有限差分估计速度和加速度，并定量分析微分算子对测量噪声的放大效应。\n\n请仅基于以下基本定义和事实进行推理：函数的导数是差商的极限；作用于独立随机变量的线性算子，其输出的方差根据算子权重的平方和进行叠加；泰勒级数展开可用于推导有限差分模板的局部截断误差阶。除这些原则外，请勿使用任何其他预先包装好的公式。\n\n使用以下信号模型。无噪声的位置由下式给出\n$$\nx(t) = A \\sin(2\\pi f_1 t) + C \\sin(2\\pi f_2 t) + D t^2,\n$$\n参数为\n$$\nA = 1.0\\ \\text{m},\\quad C = 0.5\\ \\text{m},\\quad f_1 = 1.0\\ \\text{Hz},\\quad f_2 = 3.0\\ \\text{Hz},\\quad D = 0.05\\ \\text{m/s}^2.\n$$\n三角函数中的角度以弧度为单位。精确的速度和加速度分别为\n$$\nv(t) = \\frac{dx}{dt} = 2\\pi f_1 A \\cos(2\\pi f_1 t) + 2\\pi f_2 C \\cos(2\\pi f_2 t) + 2 D t,\n$$\n$$\na(t) = \\frac{d^2 x}{dt^2} = - (2\\pi f_1)^2 A \\sin(2\\pi f_1 t) - (2\\pi f_2)^2 C \\sin(2\\pi f_2 t) + 2 D.\n$$\n\n采样和噪声模型。对于每个测试用例，在以下时间点进行均匀采样\n$$\nt_n = n \\,\\Delta t,\\quad n=0,1,\\dots,N-1,\\quad N = \\left\\lfloor \\frac{T}{\\Delta t}\\right\\rfloor + 1,\\quad T = 10\\ \\text{s},\n$$\n并形成带噪声的测量值\n$$\nx_n^{\\text{noisy}} = x(t_n) + \\eta_n,\\quad \\eta_n \\sim \\mathcal{N}(0,\\sigma_x^2)\\ \\text{i.i.d.},\n$$\n为了保证可复现性，使用固定的随机种子 $12345$。所有距离单位为米，时间单位为秒。\n\n有限差分要求。请从第一性原理出发，按如下要求推导并实现用于一阶和二阶导数的二阶精度有限差分格式：\n- 对于内部点，使用中心二阶精度模板。\n- 在两个边界处，使用单边二阶精度模板。\n您的实现必须生成与输入 $x_n$ 长度相同的数组 $v_n^{\\text{FD}}$ 和 $a_n^{\\text{FD}}$。\n\n噪声放大分析。设索引 $i$ 处的有限差分导数为线性组合\n$$\ny_i = \\sum_{j} w_{i,j} x_j,\n$$\n其中 $y_i$ 代表一阶或二阶导数估计值，$w_{i,j}$ 是除以 $\\Delta t$ 相应次幂后的有限差分权重。请仅使用期望的线性性质和噪声样本的独立性，推导并计算：\n- 一阶导数的经验均方根（RMS）噪声放大，\n$$\ng_v^{\\text{emp}} = \\sqrt{\\frac{1}{N}\\sum_{i=0}^{N-1} \\left( v_i^{\\text{FD}}[x^{\\text{noisy}}] - v_i^{\\text{FD}}[x^{\\text{clean}}]\\right)^2 },\n$$\n和二阶导数的经验均方根（RMS）噪声放大，\n$$\ng_a^{\\text{emp}} = \\sqrt{\\frac{1}{N}\\sum_{i=0}^{N-1} \\left( a_i^{\\text{FD}}[x^{\\text{noisy}}] - a_i^{\\text{FD}}[x^{\\text{clean}}]\\right)^2 }.\n$$\n- 由权重预测的理论均方根（RMS）噪声放大，\n$$\ng^{\\text{theory}} = \\sigma_x \\sqrt{ \\frac{1}{N} \\sum_{i=0}^{N-1} \\left( \\sum_{j} w_{i,j}^2 \\right) }.\n$$\n使用每个索引处（包括边界模板）实际使用的权重来计算 $g_v^{\\text{theory}}$ 和 $g_a^{\\text{theory}}$。\n\n性能指标。对于每个测试用例，计算：\n- 速度估计值相对于精确速度的均方根（RMS）误差，\n$$\nE_v = \\sqrt{\\frac{1}{N}\\sum_{i=0}^{N-1} \\left( v_i^{\\text{FD}}[x^{\\text{noisy}}] - v(t_i) \\right)^2 } \\ \\text{in m/s}.\n$$\n- 加速度估计值相对于精确加速度的均方根（RMS）误差，\n$$\nE_a = \\sqrt{\\frac{1}{N}\\sum_{i=0}^{N-1} \\left( a_i^{\\text{FD}}[x^{\\text{noisy}}] - a(t_i) \\right)^2 } \\ \\text{in m/s}^2.\n$$\n- 比值\n$$\nR_v = \\frac{ g_v^{\\text{emp}} }{ g_v^{\\text{theory}} },\\qquad R_a = \\frac{ g_a^{\\text{emp}} }{ g_a^{\\text{theory}} },\n$$\n该比值表明经验噪声放大与理论预测的匹配程度。\n\n测试套件。请在以下四个改变了采样间隔和噪声水平的测试用例上运行您的程序：\n- 案例 1：$\\Delta t = 0.01\\ \\text{s}$，$\\sigma_x = 0.001\\ \\text{m}$。\n- 案例 2：$\\Delta t = 0.1\\ \\text{s}$，$\\sigma_x = 0.001\\ \\text{m}$。\n- 案例 3：$\\Delta t = 0.01\\ \\text{s}$，$\\sigma_x = 0.01\\ \\text{m}$。\n- 案例 4：$\\Delta t = 0.001\\ \\text{s}$，$\\sigma_x = 0.001\\ \\text{m}$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表，汇集了所有结果。对于从1到4的每个案例，按以下顺序附加四个浮点数：$E_v$（单位 m/s），$E_a$（单位 m/s$^2$），$R_v$（无量纲），$R_a$（无量纲）。每个数字必须以科学记数法打印，并保留六位有效数字。例如，总输出格式为\n$$\n[\\ E_{v,1},\\ E_{a,1},\\ R_{v,1},\\ R_{a,1},\\ E_{v,2},\\ E_{a,2},\\ R_{v,2},\\ R_{a,2},\\ E_{v,3},\\ E_{a,3},\\ R_{v,3},\\ R_{a,3},\\ E_{v,4},\\ E_{a,4},\\ R_{v,4},\\ R_{a,4}\\ ].\n$$",
            "solution": "我们从第一性原理开始。函数 $x(t)$ 在时间 $t$ 的一阶导数由以下极限定义\n$$\n\\frac{dx}{dt}(t) = \\lim_{\\Delta t \\to 0} \\frac{x(t+\\Delta t) - x(t-\\Delta t)}{2\\Delta t},\n$$\n这启发我们对于有限但较小的 $\\Delta t$ 使用对称（中心）差商。二阶导数定义为\n$$\n\\frac{d^2x}{dt^2}(t) = \\lim_{\\Delta t \\to 0} \\frac{x(t+\\Delta t) - 2x(t) + x(t-\\Delta t)}{\\Delta t^2}.\n$$\n使用在 $t_i = i \\Delta t$ 周围的泰勒级数展开，\n$$\nx(t_{i\\pm 1}) = x(t_i) \\pm \\Delta t\\, x'(t_i) + \\frac{\\Delta t^2}{2} x''(t_i) \\pm \\frac{\\Delta t^3}{6} x^{(3)}(t_i) + \\frac{\\Delta t^4}{24} x^{(4)}(t_i) + \\mathcal{O}(\\Delta t^5),\n$$\n我们可以为内部点推导出二阶精度的中心模板：\n$$\nx'(t_i) = \\frac{x_{i+1} - x_{i-1}}{2\\Delta t} + \\mathcal{O}(\\Delta t^2), \\quad\nx''(t_i) = \\frac{x_{i+1} - 2 x_i + x_{i-1}}{\\Delta t^2} + \\mathcal{O}(\\Delta t^2),\n$$\n其中 $x_i = x(t_i)$。在边界处，无法构建对称差分；作为替代，使用前向点的泰勒展开可以得到单边二阶精度模板。对于左边界 $i=0$ 处的一阶导数，\n$$\nx'(t_0) = \\frac{-3 x_0 + 4 x_1 - x_2}{2\\Delta t} + \\mathcal{O}(\\Delta t^2),\n$$\n右边界 $i=N-1$ 的情况与此类似，\n$$\nx'(t_{N-1}) = \\frac{3 x_{N-1} - 4 x_{N-2} + x_{N-3}}{2\\Delta t} + \\mathcal{O}(\\Delta t^2).\n$$\n对于二阶导数，前向和后向二阶精度单边模板为\n$$\nx''(t_0) = \\frac{2 x_0 - 5 x_1 + 4 x_2 - x_3}{\\Delta t^2} + \\mathcal{O}(\\Delta t^2), \\quad\nx''(t_{N-1}) = \\frac{2 x_{N-1} - 5 x_{N-2} + 4 x_{N-3} - x_{N-4}}{\\Delta t^2} + \\mathcal{O}(\\Delta t^2).\n$$\n这些公式是通过求解方程组得到的，该方程组通过逐项匹配泰勒展开来消除低阶误差项，从而确保二阶精度。\n\n噪声放大分析基于线性性质。设将 $\\{x_j\\}$ 映射到导数估计值 $\\{y_i\\}$ 的有限差分算子是线性的：\n$$\ny_i = \\sum_{j} w_{i,j} x_j,\n$$\n其中 $w_{i,j}$ 是算子权重，包含了由导数阶数决定的、通过除以 $\\Delta t$ 的相应次幂进行的归一化。假设测量值包含加性零均值独立噪声 $\\eta_j$，其方差为 $\\mathbb{V}[\\eta_j] = \\sigma_x^2$。根据线性性质和独立性，\n$$\n\\mathbb{E}[y_i] = \\sum_{j} w_{i,j} \\mathbb{E}[x_j], \\quad\n\\mathbb{V}[y_i] = \\sum_{j} w_{i,j}^2 \\,\\mathbb{V}[\\eta_j] = \\sigma_x^2 \\sum_{j} w_{i,j}^2.\n$$\n因此，在索引 $i$ 处的噪声分量的均方根（RMS）等于\n$$\n\\sqrt{\\mathbb{V}[y_i]} = \\sigma_x \\sqrt{\\sum_{j} w_{i,j}^2}.\n$$\n一个与实践中使用的经验均方根一致的、涵盖所有索引的全局均方根为\n$$\ng^{\\text{theory}} = \\sigma_x \\sqrt{\\frac{1}{N}\\sum_{i=0}^{N-1} \\left(\\sum_{j} w_{i,j}^2\\right)}.\n$$\n该表达式通过依赖于索引的权重，自然地包含了边界效应。\n\n由此可以得出两个推论：\n- 对于一阶导数，权重与 $1/\\Delta t$ 成比例，因此 $g_v^{\\text{theory}} \\propto \\sigma_x/\\Delta t$；也就是说，如果每个样本的位置噪声水平固定，减小 $\\Delta t$ 会增加速度估计中的噪声放大。\n- 对于二阶导数，权重与 $1/\\Delta t^2$ 成比例，因此 $g_a^{\\text{theory}} \\propto \\sigma_x/\\Delta t^2$，意味着更强的噪声放大效应。\n\n通过比较微分算子作用于含噪数据和干净数据时的结果，可以分离出经验均方根（RMS）噪声放大，这样做可以抵消确定性的截断误差：\n$$\ng^{\\text{emp}} = \\sqrt{\\frac{1}{N}\\sum_{i=0}^{N-1} \\left( y_i[x^{\\text{noisy}}] - y_i[x^{\\text{clean}}] \\right)^2 }.\n$$\n因为 $y_i[\\cdot]$ 是线性的，且 $x^{\\text{noisy}} = x^{\\text{clean}} + \\eta$，所以差值等于 $y_i[\\eta]$，在大量样本的极限情况下，其均方根值与上面推导的理论表达式相匹配。因此，当经验平均值具有代表性时，比值\n$$\nR_v = \\frac{g_v^{\\text{emp}}}{g_v^{\\text{theory}}},\\qquad R_a = \\frac{g_a^{\\text{emp}}}{g_a^{\\text{theory}}},\n$$\n应接近于1。\n\n算法设计：\n- 构建时间样本 $t_i = i \\Delta t$（其中 $i=0,\\dots,N-1$，$T=10$ s）。\n- 根据给定的解析表达式，计算干净的位置 $x(t_i)$，以及精确的速度 $v(t_i)$ 和加速度 $a(t_i)$。\n- 使用固定的随机种子生成加性噪声 $\\eta_i \\sim \\mathcal{N}(0,\\sigma_x^2)$ 以确保可复现性，并构成 $x^{\\text{noisy}}_i = x(t_i) + \\eta_i$。\n- 实现二阶精度的有限差分估计器，用于一阶和二阶导数，该估计器在内部应用中心模板，在边界应用单边模板，从而为干净数据和含噪数据生成 $v^{\\text{FD}}$ 和 $a^{\\text{FD}}$。\n- 计算性能指标：$E_v$ 和 $E_a$ 作为相对于精确导数的均方根误差。计算 $g_v^{\\text{emp}}$ 和 $g_a^{\\text{emp}}$ 作为有限差分在含噪数据和干净数据上输出的均方根差异。通过对每个索引处的权重平方求和并取平均，然后乘以 $\\sigma_x$ 再开方，来计算 $g_v^{\\text{theory}}$ 和 $g_a^{\\text{theory}}$。最后，计算 $R_v$ 和 $R_a$ 作为经验放大与理论放大的比值。\n- 对四个指定的测试用例重复上述过程。以科学记数法和六位有效数字，将整合后的结果打印在所需的单行、由方括号括起的逗号分隔列表中。\n\n预期趋势：\n- 将 $\\sigma_x$ 增加10倍，应使 $g^{\\text{emp}}$ 以及 $E_v$ 和 $E_a$ 中由噪声主导的分量增加10倍。\n- 增加 $\\Delta t$ 应使 $g_v^{\\text{theory}}$ 大致按 $1/\\Delta t$ 的规律减小，使 $g_a^{\\text{theory}}$ 大致按 $1/\\Delta t^2$ 的规律减小；然而，截断误差按 $\\mathcal{O}(\\Delta t^2)$ 的规律增长，因此由于截断误差和噪声放大之间的权衡，$E_v$ 和 $E_a$ 可能不会随 $\\Delta t$ 单调减小。\n- 比值 $R_v$ 和 $R_a$ 应接近1，从而验证线性噪声放大分析的正确性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef position(t, A=1.0, C=0.5, f1=1.0, f2=3.0, D=0.05):\n    # x(t) in meters\n    return A * np.sin(2*np.pi*f1*t) + C * np.sin(2*np.pi*f2*t) + D * t**2\n\ndef velocity_true(t, A=1.0, C=0.5, f1=1.0, f2=3.0, D=0.05):\n    # v(t) in m/s\n    return 2*np.pi*f1*A * np.cos(2*np.pi*f1*t) + 2*np.pi*f2*C * np.cos(2*np.pi*f2*t) + 2*D*t\n\ndef acceleration_true(t, A=1.0, C=0.5, f1=1.0, f2=3.0, D=0.05):\n    # a(t) in m/s^2\n    return -(2*np.pi*f1)**2 * A * np.sin(2*np.pi*f1*t) - (2*np.pi*f2)**2 * C * np.sin(2*np.pi*f2*t) + 2*D\n\ndef fd_first_derivative(x, dt):\n    \"\"\"\n    Second-order accurate finite difference for first derivative.\n    - One-sided 3-point at boundaries (order 2).\n    - Centered 3-point in interior (order 2).\n    Returns y of same length as x.\n    \"\"\"\n    n = x.size\n    y = np.empty_like(x, dtype=float)\n    if n  3:\n        raise ValueError(\"Need at least 3 points for second-order first derivative\")\n    # Left boundary: (-3 x0 + 4 x1 - x2)/(2 dt)\n    y[0] = (-3.0*x[0] + 4.0*x[1] - 1.0*x[2]) / (2.0*dt)\n    # Interior\n    y[1:-1] = (x[2:] - x[:-2]) / (2.0*dt)\n    # Right boundary: (3 xN-1 - 4 xN-2 + xN-3)/(2 dt)\n    y[-1] = (3.0*x[-1] - 4.0*x[-2] + 1.0*x[-3]) / (2.0*dt)\n    return y\n\ndef fd_second_derivative(x, dt):\n    \"\"\"\n    Second-order accurate finite difference for second derivative.\n    - One-sided 4-point at boundaries (order 2).\n    - Centered 3-point in interior (order 2).\n    Returns y of same length as x.\n    \"\"\"\n    n = x.size\n    y = np.empty_like(x, dtype=float)\n    if n  4:\n        raise ValueError(\"Need at least 4 points for second derivative with second-order accuracy\")\n    # Left boundary: (2 x0 - 5 x1 + 4 x2 - x3)/dt^2\n    y[0] = (2.0*x[0] - 5.0*x[1] + 4.0*x[2] - 1.0*x[3]) / (dt*dt)\n    # Interior\n    y[1:-1] = (x[2:] - 2.0*x[1:-1] + x[:-2]) / (dt*dt)\n    # Right boundary: (2 xN-1 - 5 xN-2 + 4 xN-3 - xN-4)/dt^2\n    y[-1] = (2.0*x[-1] - 5.0*x[-2] + 4.0*x[-3] - 1.0*x[-4]) / (dt*dt)\n    return y\n\ndef weights_sqsum_first(n, dt):\n    \"\"\"\n    For each index i, compute sum_j w_{i,j}^2 for the first derivative operator.\n    Returns an array s of length n with s[i] = sum_j w_{i,j}^2.\n    \"\"\"\n    s = np.zeros(n, dtype=float)\n    inv = 1.0 / (2.0*dt)\n    # Left boundary: (-3, 4, -1)/(2 dt)\n    coeffs = np.array([-3.0, 4.0, -1.0]) * inv\n    s[0] = np.sum(coeffs**2)\n    # Interior: [-1, +1] at i-1 and i+1\n    c = np.array([-1.0, 1.0]) * inv\n    val = np.sum(c**2)\n    s[1:-1] = val\n    # Right boundary: (1, -4, 3)/(2 dt) applied to (i-2, i-1, i)\n    coeffs = np.array([1.0, -4.0, 3.0]) * inv\n    s[-1] = np.sum(coeffs**2)\n    return s\n\ndef weights_sqsum_second(n, dt):\n    \"\"\"\n    For each index i, compute sum_j w_{i,j}^2 for the second derivative operator.\n    Returns an array s of length n with s[i] = sum_j w_{i,j}^2.\n    \"\"\"\n    s = np.zeros(n, dtype=float)\n    inv2 = 1.0 / (dt*dt)\n    # Left boundary: (2, -5, 4, -1)/dt^2\n    coeffs = np.array([2.0, -5.0, 4.0, -1.0]) * inv2\n    s[0] = np.sum(coeffs**2)\n    # Interior: (1, -2, 1)/dt^2\n    c = np.array([1.0, -2.0, 1.0]) * inv2\n    val = np.sum(c**2)\n    s[1:-1] = val\n    # Right boundary: (-1, 4, -5, 2)/dt^2 applied to (i-3, i-2, i-1, i)\n    coeffs = np.array([-1.0, 4.0, -5.0, 2.0]) * inv2\n    s[-1] = np.sum(coeffs**2)\n    return s\n\ndef rms(x):\n    return np.sqrt(np.mean(np.square(x)))\n\ndef format_float(x):\n    # Scientific notation with exactly six significant figures\n    return f\"{x:.6e}\"\n\ndef run_case(dt, sigma_x, rng):\n    T = 10.0\n    N = int(np.floor(T/dt)) + 1\n    t = np.linspace(0.0, dt*(N-1), N)\n    x_clean = position(t)\n    # Generate noise with given sigma\n    noise = rng.normal(loc=0.0, scale=sigma_x, size=N)\n    x_noisy = x_clean + noise\n\n    # True derivatives\n    v_true = velocity_true(t)\n    a_true = acceleration_true(t)\n\n    # Finite difference estimates\n    v_fd_clean = fd_first_derivative(x_clean, dt)\n    a_fd_clean = fd_second_derivative(x_clean, dt)\n    v_fd_noisy = fd_first_derivative(x_noisy, dt)\n    a_fd_noisy = fd_second_derivative(x_noisy, dt)\n\n    # RMS errors against exact\n    E_v = rms(v_fd_noisy - v_true)\n    E_a = rms(a_fd_noisy - a_true)\n\n    # Empirical noise amplification (difference noisy-clean)\n    g_v_emp = rms(v_fd_noisy - v_fd_clean)\n    g_a_emp = rms(a_fd_noisy - a_fd_clean)\n\n    # Theoretical noise amplification from weights\n    s1 = weights_sqsum_first(N, dt)\n    s2 = weights_sqsum_second(N, dt)\n    g_v_theory = sigma_x * np.sqrt(np.mean(s1))\n    g_a_theory = sigma_x * np.sqrt(np.mean(s2))\n\n    # Ratios (avoid division by zero, though here not zero)\n    R_v = g_v_emp / g_v_theory if g_v_theory > 0 else np.nan\n    R_a = g_a_emp / g_a_theory if g_a_theory > 0 else np.nan\n\n    return E_v, E_a, R_v, R_a\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each tuple: (dt [s], sigma_x [m])\n    test_cases = [\n        (0.01, 0.001),   # Case 1\n        (0.1, 0.001),    # Case 2\n        (0.01, 0.01),    # Case 3\n        (0.001, 0.001),  # Case 4\n    ]\n\n    rng = np.random.default_rng(12345)\n\n    results = []\n    for dt, sigma_x in test_cases:\n        E_v, E_a, R_v, R_a = run_case(dt, sigma_x, rng)\n        results.extend([E_v, E_a, R_v, R_a])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(format_float(x) for x in results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}