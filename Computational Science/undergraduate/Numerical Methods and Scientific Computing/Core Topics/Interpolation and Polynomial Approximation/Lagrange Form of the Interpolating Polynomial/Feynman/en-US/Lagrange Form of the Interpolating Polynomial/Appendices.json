{
    "hands_on_practices": [
        {
            "introduction": "The first step in mastering Lagrange interpolation is to work through the mechanics of the formula by hand. This practice provides an excellent opportunity to do just that by asking you to construct a unique polynomial that passes through a specific set of points. By applying the definition of Lagrange basis polynomials and combining them, you will build the interpolant from the ground up, reinforcing your understanding of its fundamental structure .",
            "id": "3246519",
            "problem": "Let $x_{0}, x_{1}, x_{2}, x_{3}$ be the first four prime numbers $x_{0}=2$, $x_{1}=3$, $x_{2}=5$, $x_{3}=7$. Define prescribed data values $y_{0}=0$, $y_{1}=0$, $y_{2}=24$, $y_{3}=120$. Using only the defining properties of the Lagrange basis polynomials and the uniqueness of the interpolating polynomial of degree at most $3$ through $\\{(x_{i},y_{i})\\}_{i=0}^{3}$, construct the unique interpolating polynomial $p(x)$ that satisfies $p(x_{i})=y_{i}$ for $i=0,1,2,3$, simplify $p(x)$ to a standard polynomial form, and then compute $p(11)$. Provide the exact value for $p(11)$ with no rounding.",
            "solution": "We recall the defining properties of the Lagrange basis polynomials. Given distinct nodes $x_{0},\\dots,x_{n}$, the $j$-th Lagrange basis polynomial $L_{j}(x)$ is defined by\n$$\nL_{j}(x)=\\prod_{\\substack{i=0 \\\\ i\\neq j}}^{n} \\frac{x-x_{i}}{x_{j}-x_{i}},\n$$\nwhich satisfies the cardinal property $L_{j}(x_{i})=\\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta. The unique polynomial $p(x)$ of degree at most $n$ interpolating the data $\\{(x_{i},y_{i})\\}_{i=0}^{n}$ is then given by\n$$\np(x)=\\sum_{j=0}^{n} y_{j}\\,L_{j}(x).\n$$\nIn our case, $n=3$ with nodes $x_{0}=2$, $x_{1}=3$, $x_{2}=5$, $x_{3}=7$ and values $y_{0}=0$, $y_{1}=0$, $y_{2}=24$, $y_{3}=120$. Because $y_{0}=0$ and $y_{1}=0$, the interpolant simplifies to\n$$\np(x)=y_{2}\\,L_{2}(x)+y_{3}\\,L_{3}(x)=24\\,L_{2}(x)+120\\,L_{3}(x).\n$$\nWe compute $L_{2}(x)$ and $L_{3}(x)$ explicitly.\n\nFor $L_{2}(x)$ with $x_{2}=5$,\n$$\nL_{2}(x)=\\frac{(x-x_{0})(x-x_{1})(x-x_{3})}{(x_{2}-x_{0})(x_{2}-x_{1})(x_{2}-x_{3})}\n=\\frac{(x-2)(x-3)(x-7)}{(5-2)(5-3)(5-7)}\n=\\frac{(x-2)(x-3)(x-7)}{3\\cdot 2\\cdot(-2)}\n=-\\frac{(x-2)(x-3)(x-7)}{12}.\n$$\nFor $L_{3}(x)$ with $x_{3}=7$,\n$$\nL_{3}(x)=\\frac{(x-x_{0})(x-x_{1})(x-x_{2})}{(x_{3}-x_{0})(x_{3}-x_{1})(x_{3}-x_{2})}\n=\\frac{(x-2)(x-3)(x-5)}{(7-2)(7-3)(7-5)}\n=\\frac{(x-2)(x-3)(x-5)}{5\\cdot 4\\cdot 2}\n=\\frac{(x-2)(x-3)(x-5)}{40}.\n$$\nTherefore,\n$$\np(x)=24\\left(-\\frac{(x-2)(x-3)(x-7)}{12}\\right)+120\\left(\\frac{(x-2)(x-3)(x-5)}{40}\\right)\n=-2\\,(x-2)(x-3)(x-7)+3\\,(x-2)(x-3)(x-5).\n$$\nFactor out $(x-2)(x-3)$:\n$$\np(x)=(x-2)(x-3)\\left[-2(x-7)+3(x-5)\\right]=(x-2)(x-3)\\left[(-2x+14)+(3x-15)\\right].\n$$\nSimplify the bracket:\n$$\n(-2x+14)+(3x-15)=x-1,\n$$\nhence\n$$\np(x)=(x-2)(x-3)(x-1)=(x-1)(x-2)(x-3).\n$$\nFinally, evaluate at $x=11$:\n$$\np(11)=(11-1)(11-2)(11-3)=10\\cdot 9\\cdot 8=720.\n$$\nBy the uniqueness of polynomial interpolation of degree at most $3$ for four distinct nodes, this $p(x)$ is the unique interpolant, and the computed $p(11)$ is exact.",
            "answer": "$$\\boxed{720}$$"
        },
        {
            "introduction": "Beyond direct calculation, it is crucial to understand the theoretical properties that make Lagrange interpolation so powerful. This exercise challenges you to think abstractly about the structure of the Lagrange basis polynomials, $\\{L_j(x)\\}$. The solution relies not on lengthy computation, but on a key insight related to the uniqueness of an interpolating polynomial, revealing an elegant and fundamental identity that holds for any set of distinct nodes .",
            "id": "3246595",
            "problem": "Let $n$ be a positive integer and let $x_0, x_1, \\dots, x_n$ be $n+1$ distinct real nodes. Define the Lagrange basis polynomials $L_j(x)$ for $j=0,1,\\dots,n$ by\n$$\nL_j(x) \\;=\\; \\prod_{\\substack{m=0 \\\\ m \\ne j}}^{n} \\frac{x - x_m}{x_j - x_m}.\n$$\nFor a fixed integer $k$ with $0 \\le k \\le n$, consider the polynomial\n$$\nQ(x) \\;=\\; \\sum_{j=0}^{n} x_j^{k}\\, L_j(x).\n$$\nUsing only the definitions above and fundamental properties of polynomials, determine $Q(x)$ in closed form as a single analytic expression in $x$ and $k$. Provide your final result as a single expression, not an equation, and do not include any units.",
            "solution": "The problem is first validated to ensure it is well-posed, scientifically grounded, and consistent.\n\n**Step 1: Extract Givens**\n- $n$ is a positive integer.\n- $x_0, x_1, \\dots, x_n$ are $n+1$ distinct real nodes.\n- The Lagrange basis polynomials are defined as:\n$$L_j(x) = \\prod_{\\substack{m=0 \\\\ m \\ne j}}^{n} \\frac{x - x_m}{x_j - x_m} \\quad \\text{for } j=0,1,\\dots,n.$$\n- $k$ is a fixed integer such that $0 \\le k \\le n$.\n- The polynomial in question is:\n$$Q(x) = \\sum_{j=0}^{n} x_j^{k}\\, L_j(x).$$\nThe objective is to find a closed-form expression for $Q(x)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is a standard exercise in numerical analysis, specifically concerning the theory of polynomial interpolation.\n- **Scientific/Factual Soundness**: The problem is mathematically sound. The definitions of the Lagrange basis polynomials and the polynomial $Q(x)$ are standard and correct. The condition that the nodes $x_j$ are distinct is critical and correctly stated, ensuring the denominators in $L_j(x)$ are non-zero.\n- **Well-Posedness**: The problem is well-posed. It asks for a specific polynomial to be identified. The uniqueness of polynomial interpolation suggests a unique solution exists.\n- **Objectivity**: The problem is stated in precise, objective mathematical language.\n- **Completeness**: All necessary information is provided. The constraints on $n$ and $k$ are clear.\nThe problem is not flawed in any of the categories listed in the validation criteria.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A solution will be derived.\n\n**Derivation of the Solution**\nThe polynomial $Q(x)$ is constructed as a linear combination of the Lagrange basis polynomials $L_j(x)$. By definition, for a given set of data points $(x_0, y_0), (x_1, y_1), \\dots, (x_n, y_n)$ with distinct $x_j$, the unique interpolating polynomial of degree at most $n$ is given by\n$$P(x) = \\sum_{j=0}^{n} y_j L_j(x).$$\nThis polynomial has the property that $P(x_i) = y_i$ for all $i = 0, 1, \\dots, n$.\n\nThe polynomial in question is\n$$Q(x) = \\sum_{j=0}^{n} x_j^{k}\\, L_j(x).$$\nBy comparing this with the general form of the Lagrange interpolating polynomial, we can identify $y_j = x_j^k$. Thus, $Q(x)$ is the unique polynomial of degree at most $n$ that interpolates the data points $(x_j, x_j^k)$ for $j = 0, 1, \\dots, n$.\n\nTo determine the identity of $Q(x)$, we can evaluate it at each of the nodes $x_i$ for $i \\in \\{0, 1, \\dots, n\\}$. The fundamental property of the Lagrange basis polynomials is that\n$$L_j(x_i) = \\delta_{ji} = \\begin{cases} 1 & \\text{if } i=j \\\\ 0 & \\text{if } i \\ne j \\end{cases}$$\nwhere $\\delta_{ji}$ is the Kronecker delta.\n\nLet us evaluate $Q(x)$ at an arbitrary node $x_i$:\n$$Q(x_i) = \\sum_{j=0}^{n} x_j^{k}\\, L_j(x_i).$$\nDue to the Kronecker delta property, all terms in the summation vanish except for the term where $j=i$.\n$$Q(x_i) = x_0^k L_0(x_i) + \\dots + x_i^k L_i(x_i) + \\dots + x_n^k L_n(x_i) = 0 + \\dots + x_i^k (1) + \\dots + 0 = x_i^k.$$\nThis shows that $Q(x)$ satisfies the condition $Q(x_i) = x_i^k$ for all $n+1$ distinct nodes $x_0, x_1, \\dots, x_n$.\n\nNow, consider the simple polynomial $P(x) = x^k$.\nThe problem states that $k$ is an integer such that $0 \\le k \\le n$. This means that the degree of the polynomial $P(x)$ is $k$, which is less than or equal to $n$.\nLet us evaluate this polynomial $P(x)$ at the nodes $x_i$:\n$$P(x_i) = x_i^k.$$\nWe now have two polynomials, $Q(x)$ and $P(x) = x^k$.\n1. The degree of $Q(x)$ is at most $n$, as it is a linear combination of the basis polynomials $L_j(x)$, each of which has degree $n$.\n2. The degree of $P(x) = x^k$ is $k$, and since $k \\le n$, its degree is also at most $n$.\n3. The two polynomials agree at $n+1$ distinct points: $Q(x_i) = P(x_i) = x_i^k$ for $i=0, 1, \\dots, n$.\n\nLet's define a difference polynomial $D(x) = Q(x) - P(x) = Q(x) - x^k$.\nThe degree of $D(x)$ is at most $n$, since it is the difference of two polynomials whose degrees are at most $n$.\nWe know that $D(x_i) = Q(x_i) - P(x_i) = x_i^k - x_i^k = 0$ for each $i \\in \\{0, 1, \\dots, n\\}$.\nThis means that the polynomial $D(x)$ has $n+1$ distinct roots, namely $x_0, x_1, \\dots, x_n$.\nAccording to the fundamental theorem of algebra, a non-zero polynomial of degree at most $n$ can have at most $n$ distinct roots. Since $D(x)$ has $n+1$ distinct roots, it must be the zero polynomial, i.e., $D(x) = 0$ for all $x$.\n\nTherefore, $Q(x) - x^k = 0$, which implies $Q(x) = x^k$.\nThe closed-form expression for the polynomial $Q(x)$ is simply $x^k$. The condition $0 \\le k \\le n$ is essential for this conclusion.",
            "answer": "$$ \\boxed{x^{k}} $$"
        },
        {
            "introduction": "Polynomial interpolation is a powerful tool, but it has important limitations, especially when dealing with functions that are not smooth. This computational exercise explores what happens when we try to approximate a discontinuous function, $f(x) = \\mathrm{sign}(x)$, using a single high-degree polynomial versus simpler piecewise methods. This practice  provides a striking visual and numerical demonstration of the Gibbs and Runge phenomena, highlighting the trade-offs between global and local approximation strategies in scientific computing.",
            "id": "3246671",
            "problem": "You are to write a complete, runnable program that compares global polynomial interpolation in the Lagrange sense against local piecewise polynomial approximants for the discontinuous function $f(x) = \\mathrm{sign}(x)$ on the interval $[-1,1]$. Begin from the following fundamental base in numerical methods and scientific computing:\n- The definition of interpolation: Given distinct nodes $\\{x_i\\}_{i=0}^{n-1}$ in $[-1,1]$ and data $\\{y_i\\}_{i=0}^{n-1}$, an interpolant is a function $p(x)$ such that $p(x_i) = y_i$ for all $i$. When $p(x)$ is a polynomial of degree at most $n-1$, this defines the global polynomial interpolant. The existence and uniqueness of a polynomial of degree at most $n-1$ that matches $n$ distinct data points is a foundational fact in numerical analysis.\n- The notion of local piecewise polynomial approximants: Partition $[-1,1]$ into subintervals using the nodes. On each subinterval, define an approximant that depends only on data local to that subinterval, such as a piecewise constant function (degree $0$ on each subinterval) or a piecewise linear function (degree $1$ on each subinterval).\n- Norms used for error measurement: For a function $g(x)$ approximating $f(x)$ on $[-1,1]$, the supremum norm error over a discrete grid $\\{z_j\\}$ is $\\max_j |g(z_j) - f(z_j)|$, which approximates the continuous $L^\\infty$ error.\n\nYour program must implement:\n1. A global polynomial interpolant $P_n(x)$ that, for given nodes $\\{x_i\\}$ and values $y_i = f(x_i)$, interpolates all points $\\{(x_i,y_i)\\}$ simultaneously as a single polynomial on $[-1,1]$. Construct $P_n(x)$ using the defining property of interpolation stated above.\n2. A local piecewise linear approximant $L_n(x)$ constructed by linear interpolation on each subinterval $[x_i, x_{i+1}]$, with the convention that if $x$ equals a node $x_i$, then $L_n(x) = y_i$.\n3. A local piecewise constant approximant $C_n(x)$ defined on each subinterval by assigning to $x$ the nearest nodeâ€™s sampled value, i.e., for $x$ in the cell determined by midpoints between consecutive nodes, $C_n(x)$ equals $y_k$ where $x_k$ is the node closest to $x$.\n\nThe function $f(x)$ must be implemented as $f(x) = -1$ for $x  0$, $f(x) = 0$ for $x = 0$, and $f(x) = 1$ for $x > 0$. Your program must evaluate each approximant on a fixed uniform grid of $N$ points on $[-1,1]$ with $N = 2001$, and compute the discrete supremum norm errors\n$$\nE_\\infty(P_n) = \\max_{j} \\left| P_n(z_j) - f(z_j) \\right|,\\quad\nE_\\infty(L_n) = \\max_{j} \\left| L_n(z_j) - f(z_j) \\right|,\\quad\nE_\\infty(C_n) = \\max_{j} \\left| C_n(z_j) - f(z_j) \\right|.\n$$\n\nYou must generate nodes according to the following rules:\n- Equispaced nodes: For a given integer $n \\ge 2$, define $\\{x_i\\}_{i=0}^{n-1}$ by $x_i = -1 + \\dfrac{2i}{n-1}$.\n- Chebyshev nodes of the first kind: For a given integer $n \\ge 2$, define $\\{x_i\\}_{i=0}^{n-1}$ by $x_i = \\cos\\!\\left( \\dfrac{2i+1}{2n} \\pi \\right)$ with all angles measured in radians.\n\nTest suite:\nUse the uniform evaluation grid with $N = 2001$, and compute the three supremum norm errors for each of the following parameter sets:\n- Case $\\mathsf{A}$ (happy path): Equispaced nodes with $n = 9$.\n- Case $\\mathsf{B}$ (alternative node distribution): Chebyshev nodes with $n = 9$ (angles in radians).\n- Case $\\mathsf{C}$ (boundary condition with small sample): Equispaced nodes with $n = 3$.\n- Case $\\mathsf{D}$ (edge case where the discontinuity does not align with a node): Equispaced nodes with $n = 10$.\n- Case $\\mathsf{E}$ (larger sample size under Chebyshev nodes): Chebyshev nodes with $n = 25$ (angles in radians).\n\nFor each case, your program must output the three floating-point errors $E_\\infty(P_n)$, $E_\\infty(L_n)$, and $E_\\infty(C_n)$ in this exact order. Aggregate the results of all cases into a single line of output containing the concatenated list of the $15$ values as a comma-separated list enclosed in square brackets. Each floating-point number must be rounded to exactly $8$ decimal digits after the decimal point.\n\nFinal output format example (illustrative; not actual values):\n$$\n[\\text{caseA}_P,\\text{caseA}_L,\\text{caseA}_C,\\text{caseB}_P,\\ldots,\\text{caseE}_C]\n$$\nwhere each entry is a float formatted to eight digits after the decimal point. No other text must be printed.",
            "solution": "The problem requires a comparison of three numerical approximation schemes for the discontinuous signum function, $f(x) = \\mathrm{sign}(x)$, on the interval $[-1, 1]$. The schemes are global polynomial interpolation, piecewise linear interpolation, and piecewise constant approximation. The comparison is based on the discrete supremum norm error, evaluated on a fine, uniform grid.\n\nThe function to be approximated is defined as:\n$$\nf(x) =\n\\begin{cases}\n-1  \\text{if } x  0 \\\\\n0   \\text{if } x = 0 \\\\\n1   \\text{if } x  0\n\\end{cases}\n$$\nThis function has a jump discontinuity at $x=0$, which poses a significant challenge for approximation methods that rely on smoothness, particularly global polynomial interpolation.\n\nThe error of an approximant $g(x)$ is measured over a uniform evaluation grid of $N=2001$ points, $\\{z_j\\}_{j=0}^{N-1}$, on $[-1, 1]$. The metric is the discrete supremum norm, $E_\\infty$, defined as:\n$$\nE_\\infty(g) = \\max_{0 \\le j  N} |g(z_j) - f(z_j)|\n$$\n\nThe approximation schemes are constructed based on a set of $n$ distinct nodes $\\{x_i\\}_{i=0}^{n-1}$ and the corresponding function values $\\{y_i\\}_{i=0}^{n-1}$, where $y_i = f(x_i)$. Two types of node distributions are specified:\n1.  **Equispaced nodes**: $x_i = -1 + \\frac{2i}{n-1}$ for $i=0, \\dots, n-1$. These are uniformly distributed.\n2.  **Chebyshev nodes (of the first kind)**: $x_i = \\cos\\left( \\frac{(2i+1)\\pi}{2n} \\right)$ for $i=0, \\dots, n-1$. These nodes, the roots of the degree-$n$ Chebyshev polynomial $T_n(x)$, are more densely clustered near the endpoints of the interval. This property is known to be effective in mitigating the large oscillations associated with high-degree polynomial interpolation on equispaced nodes (Runge's phenomenon).\n\nThe three approximation methods are implemented as follows:\n\n**1. Global Polynomial Interpolant ($P_n(x)$)**\nFor a given set of $n$ data points $\\{(x_i, y_i)\\}_{i=0}^{n-1}$ with distinct nodes $x_i$, there exists a unique polynomial $P_n(x)$ of degree at most $n-1$ such that $P_n(x_i) = y_i$ for all $i$. This polynomial can be written in the monomial basis as $P_n(x) = \\sum_{k=0}^{n-1} c_k x^k$. The coefficients $\\{c_k\\}$ can be found by solving the linear system of equations:\n$$\n\\begin{pmatrix}\n1  x_0  x_0^2  \\cdots  x_0^{n-1} \\\\\n1  x_1  x_1^2  \\cdots  x_1^{n-1} \\\\\n\\vdots  \\vdots  \\vdots  \\ddots  \\vdots \\\\\n1  x_{n-1}  x_{n-1}^2  \\cdots  x_{n-1}^{n-1}\n\\end{pmatrix}\n\\begin{pmatrix}\nc_0 \\\\\nc_1 \\\\\n\\vdots \\\\\nc_{n-1}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\ny_0 \\\\\ny_1 \\\\\n\\vdots \\\\\ny_{n-1}\n\\end{pmatrix}\n$$\nThe matrix on the left is the Vandermonde matrix. While solving this system is conceptually straightforward, the Vandermonde matrix is often ill-conditioned, especially for equispaced nodes and large $n$. Numerically stable algorithms, such as those based on barycentric interpolation, are generally preferred, but for the given parameters, solving the system is feasible. The implementation will determine the coefficients and then evaluate the resulting polynomial on the grid $\\{z_j\\}$. For a discontinuous function, $P_n(x)$ is expected to exhibit oscillatory behavior near the discontinuity (Gibbs phenomenon), and the maximum error will not converge to zero as $n$ increases.\n\n**2. Local Piecewise Linear Approximant ($L_n(x)$)**\nThis method constructs a continuous function composed of linear segments. First, the nodes $\\{x_i\\}$ are sorted in increasing order, let's call them $\\{x'_i\\}$. On each subinterval $[x'_i, x'_{i+1}]$, the approximant $L_n(x)$ is the straight line connecting the points $(x'_i, y'_i)$ and $(x'_{i+1}, y'_{i+1})$, where $y'_i = f(x'_i)$. This is a local scheme, as the definition of the approximant on any given subinterval depends only on the two data points at its ends. The error of this method is bounded and, for a function with a jump discontinuity, does not converge to zero. The maximum error will be approximately half the size of the jump, i.e., $\\approx 1.0$, and will occur in the subinterval that spans the discontinuity.\n\n**3. Local Piecewise Constant Approximant ($C_n(x)$)**\nThis is the simplest local approximation scheme. The domain is partitioned into cells based on proximity to the nodes. For any point $x \\in [-1, 1]$, the value of the approximant $C_n(x)$ is $y_k = f(x_k)$, where $x_k$ is the node that is closest to $x$. If the nodes are sorted as $x'_0  x'_1  \\dots  x'_{n-1}$, the boundaries of these cells are the midpoints $m_i = (x'_i + x'_{i+1})/2$. The cell corresponding to an interior node $x'_i$ is $[m_{i-1}, m_i)$. For any point $z$ in the evaluation grid, we find which cell it belongs to and assign the corresponding node's function value. Similar to the piecewise linear case, the error will be bounded by approximately $1.0$ and will not converge to zero for $f(x) = \\mathrm{sign}(x)$.\n\nThe program will systematically execute the specified test cases, each defined by the number of nodes $n$ and their distribution, and compute the three error norms, $E_\\infty(P_n)$, $E_\\infty(L_n)$, and $E_\\infty(C_n)$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Compares global polynomial interpolation vs. local piecewise approximants\n    for the signum function f(x) = sign(x) on [-1, 1].\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'type': 'equispaced', 'n': 9},\n        {'type': 'chebyshev', 'n': 9},\n        {'type': 'equispaced', 'n': 3},\n        {'type': 'equispaced', 'n': 10},\n        {'type': 'chebyshev', 'n': 25},\n    ]\n\n    # Define the high-resolution evaluation grid\n    N = 2001\n    z_eval = np.linspace(-1, 1, N)\n    \n    # Evaluate the true function f(x) = sign(x) on the grid\n    # np.sign(0) is 0, which matches the problem's definition.\n    f_eval = np.sign(z_eval)\n    \n    all_results = []\n\n    for case in test_cases:\n        n = case['n']\n        node_type = case['type']\n\n        # 1. Generate interpolation nodes and corresponding y-values\n        if node_type == 'equispaced':\n            x_nodes = np.linspace(-1, 1, n)\n        else:  # 'chebyshev'\n            # Generates nodes in descending order\n            i = np.arange(n)\n            x_nodes = np.cos((2 * i + 1) * np.pi / (2 * n))\n        \n        y_nodes = np.sign(x_nodes)\n\n        # 2. Global Polynomial Interpolant P_n(x)\n        # We find the coefficients of the unique polynomial of degree n-1\n        # and then evaluate it on the fine grid. This is equivalent to\n        # solving the Vandermonde system.\n        poly_coeffs = np.polyfit(x_nodes, y_nodes, n - 1)\n        p_vals = np.polyval(poly_coeffs, z_eval)\n        error_p = np.max(np.abs(p_vals - f_eval))\n\n        # 3. Local Piecewise Linear Approximant L_n(x)\n        # np.interp requires x-coordinates to be in increasing order.\n        # Chebyshev nodes are generated in descending order, so we flip them.\n        if x_nodes[0]  x_nodes[-1]:\n            x_sorted_for_L = np.flip(x_nodes)\n            y_sorted_for_L = np.flip(y_nodes)\n        else:\n            x_sorted_for_L = x_nodes\n            y_sorted_for_L = y_nodes\n        l_vals = np.interp(z_eval, x_sorted_for_L, y_sorted_for_L)\n        error_l = np.max(np.abs(l_vals - f_eval))\n\n        # 4. Local Piecewise Constant Approximant C_n(x)\n        # This approximant assigns the value of the nearest node.\n        # We first sort the nodes to define the cells via their midpoints.\n        sort_indices = np.argsort(x_nodes)\n        x_sorted = x_nodes[sort_indices]\n        y_sorted = y_nodes[sort_indices]\n        \n        # Midpoints define the boundaries of the \"nearest node\" cells.\n        midpoints = (x_sorted[:-1] + x_sorted[1:]) / 2.0\n        \n        # For each evaluation point, find the index of the cell it falls into.\n        # This index corresponds to the index of the closest node in x_sorted.\n        closest_node_indices = np.searchsorted(midpoints, z_eval)\n        \n        c_vals = y_sorted[closest_node_indices]\n        error_c = np.max(np.abs(c_vals - f_eval))\n\n        # 5. Collate errors for the current case\n        all_results.extend([error_p, error_l, error_c])\n\n    # Final print statement in the exact required format.\n    # Each floating-point number is rounded to exactly 8 decimal digits.\n    formatted_results = [f\"{val:.8f}\" for val in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}