{
    "hands_on_practices": [
        {
            "introduction": "One of the most striking demonstrations of the Runge phenomenon is its effect on extrapolation. This exercise provides a direct and tangible experience with this hazard by asking you to evaluate an interpolating polynomial just outside its defined interval. By observing the catastrophic divergence between the polynomial's prediction and the function's true value, you will gain a strong intuition for why high-degree polynomial interpolants based on uniform nodes should not be trusted beyond the data they were built on .",
            "id": "2199743",
            "problem": "Consider the function $f(x) = \\frac{1}{1 + 25x^2}$. A set of five points $(x_i, y_i)$ is generated by evaluating this function at five equally spaced nodes $x_i$ in the interval $[-1, 1]$, including the endpoints. Let $P(x)$ be the unique polynomial of the smallest possible degree that passes through all five of these points. Calculate the absolute difference between the value of the polynomial and the value of the function at the point $x = 1.1$. That is, compute $|P(1.1) - f(1.1)|$. Round your final answer to three significant figures.",
            "solution": "The five equally spaced nodes in $[-1,1]$ including endpoints are $x=-1,-\\tfrac{1}{2},0,\\tfrac{1}{2},1$. Since $f(x)=\\frac{1}{1+25x^{2}}$ is even and the nodes are symmetric, the unique interpolating polynomial of degree at most $4$ is even, so write\n$$\nP(x)=a+bx^{2}+cx^{4}.\n$$\nInterpolating gives the conditions\n$$\nP(0)=a=1,\\quad P\\!\\left(\\tfrac{1}{2}\\right)=1+\\tfrac{1}{4}b+\\tfrac{1}{16}c=\\tfrac{4}{29},\\quad P(1)=1+b+c=\\tfrac{1}{26}.\n$$\nFrom these,\n$$\n\\tfrac{1}{4}b+\\tfrac{1}{16}c=-\\tfrac{25}{29},\\qquad b+c=-\\tfrac{25}{26}.\n$$\nMultiplying the first by $16$ yields $4b+c=-\\tfrac{400}{29}$. Subtracting $b+c=-\\tfrac{25}{26}$ gives\n$$\n3b=-\\tfrac{400}{29}+\\tfrac{25}{26}=-\\tfrac{9675}{754}\\;\\Rightarrow\\; b=-\\tfrac{3225}{754},\n$$\nand then\n$$\nc=-\\tfrac{25}{26}-b=-\\tfrac{25}{26}+\\tfrac{3225}{754}=\\tfrac{1250}{377}.\n$$\nThus\n$$\nP(x)=1-\\tfrac{3225}{754}x^{2}+\\tfrac{1250}{377}x^{4}.\n$$\nEvaluate at $x=\\tfrac{11}{10}$:\n$$\nP\\!\\left(\\tfrac{11}{10}\\right)=1-\\tfrac{3225}{754}\\cdot\\tfrac{121}{100}+\\tfrac{1250}{377}\\cdot\\tfrac{14641}{10000}.\n$$\nReduce each fraction:\n$$\n-\\tfrac{3225\\cdot 121}{754\\cdot 100}=-\\tfrac{15609}{3016},\\qquad \\tfrac{1250\\cdot 14641}{377\\cdot 10000}=\\tfrac{14641}{3016},\n$$\nso\n$$\nP\\!\\left(\\tfrac{11}{10}\\right)=\\tfrac{3016}{3016}-\\tfrac{15609}{3016}+\\tfrac{14641}{3016}=\\tfrac{2048}{3016}=\\tfrac{256}{377}.\n$$\nAlso,\n$$\nf(1.1)=\\frac{1}{1+25\\cdot 1.21}=\\frac{1}{31.25}=\\frac{4}{125}.\n$$\nTherefore,\n$$\n|P(1.1)-f(1.1)|=\\left|\\tfrac{256}{377}-\\tfrac{4}{125}\\right|=\\frac{|256\\cdot 125-4\\cdot 377|}{377\\cdot 125}=\\frac{30492}{47125}\\approx 0.647045\\ldots\n$$\nRounded to three significant figures, this is $0.647$.",
            "answer": "$$\\boxed{0.647}$$"
        },
        {
            "introduction": "The inaccuracies caused by the Runge phenomenon are not confined to the edges of the interval; they can corrupt calculations across the entire domain. This practice explores how the oscillatory errors of a polynomial interpolant affect a fundamental task in scientific computing: numerical integration. By using a standard Newton-Cotes formula, which is equivalent to integrating the interpolating polynomial, you will quantify the error in approximating the area under the Runge function and see firsthand how local approximation errors can accumulate into a significant global error .",
            "id": "2199755",
            "problem": "In numerical analysis, one common task is to approximate a definite integral that is difficult or impossible to evaluate analytically in terms of elementary functions. A standard technique involves approximating the integrand with a simpler function, such as a polynomial, and then integrating the approximation.\n\nConsider the function $f(x) = \\frac{1}{1+25x^2}$ over the interval $[-1, 1]$. We wish to approximate the definite integral $I_{true} = \\int_{-1}^{1} f(x) dx$.\n\nLet's approximate this integral by first conceptually finding the unique polynomial of degree 4, denoted as $P_4(x)$, that interpolates $f(x)$ at five equally spaced points in the interval $[-1, 1]$, including the endpoints. The approximate value of the integral, $I_{approx}$, is then given by $\\int_{-1}^{1} P_4(x) dx$.\n\nThe value of this integral, $I_{approx}$, can be calculated directly using the 5-point closed Newton-Cotes quadrature rule, which is given by:\n$$ I_{approx} = \\frac{2h}{45} \\left( 7 f(x_0) + 32 f(x_1) + 12 f(x_2) + 32 f(x_3) + 7 f(x_4) \\right) $$\nwhere $x_0, x_1, x_2, x_3, x_4$ are the five equally spaced interpolation points in $[-1, 1]$ (i.e., $x_0=-1, x_1=-0.5, \\dots, x_4=1$), and $h$ is the constant step size between these points.\n\nThe true value of the integral is $I_{true} = \\frac{2}{5}\\arctan(5)$.\n\nCalculate the relative error of the approximation, which is defined as $\\frac{|I_{approx} - I_{true}|}{|I_{true}|}$. Express your final answer as a decimal rounded to three significant figures.",
            "solution": "We are integrating $f(x)=\\frac{1}{1+25x^{2}}$ on $[-1,1]$ using the 5-point closed Newton–Cotes (Boole’s) rule. With equally spaced nodes $x_{0}=-1$, $x_{1}=-\\frac{1}{2}$, $x_{2}=0$, $x_{3}=\\frac{1}{2}$, $x_{4}=1$, the step size is\n$$\nh=\\frac{1-(-1)}{4}=\\frac{1}{2}.\n$$\nBoole’s rule gives\n$$\nI_{\\text{approx}}=\\frac{2h}{45}\\left(7f(x_{0})+32f(x_{1})+12f(x_{2})+32f(x_{3})+7f(x_{4})\\right).\n$$\nEvaluate $f$ at the nodes:\n$$\nf(-1)=\\frac{1}{26},\\quad f\\!\\left(-\\frac{1}{2}\\right)=\\frac{1}{1+25\\cdot\\frac{1}{4}}=\\frac{4}{29},\\quad f(0)=1,\\quad f\\!\\left(\\frac{1}{2}\\right)=\\frac{4}{29},\\quad f(1)=\\frac{1}{26}.\n$$\nSince $2h=1$, we obtain\n$$\nI_{\\text{approx}}=\\frac{1}{45}\\left(7\\cdot\\frac{1}{26}+32\\cdot\\frac{4}{29}+12+32\\cdot\\frac{4}{29}+7\\cdot\\frac{1}{26}\\right)\n=\\frac{1}{45}\\left(\\frac{14}{26}+\\frac{256}{29}+12\\right)\n=\\frac{1}{45}\\left(\\frac{7}{13}+\\frac{256}{29}+12\\right).\n$$\nWith common denominator $377=13\\cdot 29$, this sum is\n$$\n\\frac{7}{13}+\\frac{256}{29}+12=\\frac{203}{377}+\\frac{3328}{377}+\\frac{12\\cdot 377}{377}=\\frac{8055}{377},\n$$\nso\n$$\nI_{\\text{approx}}=\\frac{1}{45}\\cdot\\frac{8055}{377}=\\frac{179}{377}.\n$$\nThe exact value is\n$$\nI_{\\text{true}}=\\int_{-1}^{1}\\frac{1}{1+25x^{2}}\\,dx=\\left.\\frac{1}{5}\\arctan(5x)\\right|_{-1}^{1}=\\frac{2}{5}\\arctan(5).\n$$\nHence the relative error is\n$$\n\\frac{|I_{\\text{approx}}-I_{\\text{true}}|}{|I_{\\text{true}}|}=\\frac{\\left|\\frac{179}{377}-\\frac{2}{5}\\arctan(5)\\right|}{\\frac{2}{5}\\arctan(5)}.\n$$\nNumerically, $\\arctan(5)\\approx 1.373400766945016$, so $I_{\\text{true}}\\approx 0.549360306778006$ and $\\frac{179}{377}\\approx 0.474801061007958$, giving\n$$\n\\text{relative error}\\approx \\frac{0.074559245770049}{0.549360306778006}\\approx 0.135720\\ldots\n$$\nRounded to three significant figures, this is $0.136$.",
            "answer": "$$\\boxed{0.136}$$"
        },
        {
            "introduction": "Having witnessed the problems caused by uniform node spacing, we now turn to a powerful solution. This advanced computational practice challenges you to implement an adaptive node refinement strategy, a technique that intelligently adds interpolation points in regions of high error to suppress oscillations. This exercise shifts the focus from diagnosis to cure, providing hands-on experience with a practical method used in real-world scientific computing to overcome the Runge phenomenon and achieve accurate approximations .",
            "id": "3188715",
            "problem": "You are to investigate Runge's phenomenon through adaptive node refinement in univariate polynomial interpolation on the interval $[-1,1]$. Begin with $n$ equispaced nodes, estimate a local interpolation error via residuals at midpoints, add nodes near the endpoints where the residuals are largest, and numerically test whether adaptivity reduces endpoint oscillations. The investigation must be expressed in purely mathematical and logical terms and implemented as a complete, runnable program.\n\nDefinitions and setting:\n- Let $f(x)$ be a real-valued function defined on $[-1,1]$.\n- For a given integer $n \\geq 2$, define equispaced nodes $x_i = -1 + \\frac{2i}{n-1}$ for $i=0,1,\\dots,n-1$.\n- Let $p_n(x)$ denote the unique polynomial of degree at most $n-1$ satisfying $p_n(x_i) = f(x_i)$ for all $i$.\n- Define the residual $r(x) = p_n(x) - f(x)$.\n- For a window width $w$ with $0 < w < 1$, define the endpoint window set $E_w = [-1,-1+w] \\cup [1-w,1]$.\n- Define the endpoint oscillation score $S = \\max_{x \\in E_w} |r(x)|$ evaluated over a sufficiently dense grid of size $N_{\\text{grid}}$ on $[-1,1]$.\n\nAdaptive node refinement (one-step):\n- Given the current node set $\\{x_i\\}$ and the associated interpolant $p_n(x)$, for each consecutive node pair $(x_i, x_{i+1})$ compute the midpoint $m_i = \\frac{x_i + x_{i+1}}{2}$.\n- Evaluate the midpoint residual $|r(m_i)| = |p_n(m_i) - f(m_i)|$.\n- Define a weighted indicator $I_i = |r(m_i)| \\cdot \\left(1 + \\alpha \\cdot |m_i|\\right)$, where $\\alpha > 0$ biases selection toward endpoints (since $|m_i|$ is larger near $x=\\pm 1$).\n- Select up to $k$ midpoints with the largest values of $I_i$ and add them to the node set.\n- Recompute the interpolant $\\hat{p}(x)$ on the refined node set and the new residual $\\hat{r}(x) = \\hat{p}(x) - f(x)$.\n- Compute the new endpoint oscillation score $\\hat{S} = \\max_{x \\in E_w} |\\hat{r}(x)|$ using the same dense grid as before.\n- Define the improvement ratio $R = \\frac{S - \\hat{S}}{S}$ if $S > 0$, and $R = 0$ if $S = 0$.\n\nYour program must implement the above procedure and, for each test case, output a boolean indicating whether adaptive refinement reduces endpoint oscillations by at least a specified threshold $\\tau$, that is, whether $R \\geq \\tau$.\n\nTest suite and parameters:\nFor each test case, the parameters are given as a tuple $(f\\_\\text{id}, n, k, \\alpha, w, N_{\\text{grid}}, \\tau)$, where:\n- $f\\_\\text{id}$ specifies the function $f(x)$ as follows:\n  - $f\\_\\text{id} = \\text{\"runge25\"}$ means $f(x) = \\frac{1}{1 + 25 x^2}$.\n  - $f\\_\\text{id} = \\text{\"cubic\"}$ means $f(x) = x^3$.\n- $n$ is the initial number of equispaced nodes on $[-1,1]$.\n- $k$ is the maximum number of midpoints to add in the adaptive step.\n- $\\alpha$ is the endpoint bias parameter in the indicator $I_i$.\n- $w$ is the endpoint window width defining $E_w$.\n- $N_{\\text{grid}}$ is the number of grid points used to approximate the maxima in $S$ and $\\hat{S}$ on $[-1,1]$.\n- $\\tau$ is the required improvement ratio threshold, expressed as a decimal.\n\nUse the following test suite:\n1. $(\\text{\"runge25\"},\\, 10,\\, 8,\\, 1.5,\\, 0.2,\\, 5001,\\, 0.2)$.\n2. $(\\text{\"runge25\"},\\, 10,\\, 2,\\, 1.5,\\, 0.2,\\, 5001,\\, 0.05)$.\n3. $(\\text{\"cubic\"},\\, 10,\\, 8,\\, 1.5,\\, 0.2,\\, 5001,\\, 0.2)$.\n4. $(\\text{\"runge25\"},\\, 10,\\, 8,\\, 1.5,\\, 0.2,\\, 5001,\\, 0.9)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results for the four test cases as a comma-separated list enclosed in square brackets, for example, $[\\text{True},\\text{False},\\text{True},\\text{False}]$. No additional text should be printed.",
            "solution": "The problem statement has been rigorously validated and is determined to be sound. It is scientifically grounded in the principles of numerical analysis, specifically polynomial interpolation and Runge's phenomenon. All definitions are mathematically precise, the parameters are complete, and the procedure is well-posed, leading to a unique, verifiable solution for each test case.\n\nThe task is to implement and evaluate a one-step adaptive node refinement strategy for univariate polynomial interpolation. The goal is to test whether this strategy effectively mitigates the endpoint oscillations characteristic of Runge's phenomenon when interpolating on equispaced nodes. The procedure will be applied to two functions on the interval $[-1,1]$: the Runge function $f(x) = \\frac{1}{1 + 25x^2}$ and a simple cubic polynomial $f(x) = x^3$.\n\nThe methodology proceeds as follows:\n\nFirst, for a given function $f(x)$, an initial set of $n$ equispaced nodes $\\{x_i\\}_{i=0}^{n-1}$ is defined on the interval $[-1,1]$ by $x_i = -1 + \\frac{2i}{n-1}$. A unique interpolating polynomial $p_n(x)$ of degree at most $n-1$ is constructed such that it passes through the points $(x_i, f(x_i))$. This is achieved computationally using Barycentric interpolation, which is known for its numerical stability.\n\nSecond, the initial interpolation error is quantified. The residual function is defined as $r(x) = p_n(x) - f(x)$. The severity of endpoint oscillations is measured by the score $S$, which is the maximum absolute value of the residual within a specified endpoint window $E_w = [-1, -1+w] \\cup [1-w, 1]$. In practice, this maximum is approximated by evaluating $|r(x)|$ over a very dense, uniform grid of $N_{\\text{grid}}$ points on $[-1,1]$ and finding the maximum value among the points that fall into $E_w$.\n\nThird, the adaptive refinement step is performed. The core idea is to add new nodes in regions where the interpolation error is large. The error is estimated by calculating the residual at the midpoints of the initial node intervals. For each consecutive node pair $(x_i, x_{i+1})$, the midpoint is $m_i = \\frac{x_i + x_{i+1}}{2}$. A weighted indicator $I_i$ is computed for each midpoint:\n$$I_i = |r(m_i)| \\cdot (1 + \\alpha \\cdot |m_i|)$$\nwhere $|r(m_i)| = |p_n(m_i) - f(m_i)|$ is the magnitude of the residual at the midpoint. The term $(1 + \\alpha \\cdot |m_i|)$, with a given bias parameter $\\alpha > 0$, gives greater weight to midpoints closer to the endpoints of the interval $[-1,1]$, where $|m_i|$ is larger. This strategically biases the node selection towards the regions where Runge's phenomenon is most pronounced. A specified number, up to $k$, of the midpoints corresponding to the largest $I_i$ values are selected and added to the set of interpolation nodes.\n\nFourth, a new interpolation is performed on the refined, non-uniform set of nodes, which now contains $n$ plus the newly added points. This yields a new interpolating polynomial, $\\hat{p}(x)$, of a higher degree. The new residual is $\\hat{r}(x) = \\hat{p}(x) - f(x)$, and a new endpoint oscillation score, $\\hat{S}$, is calculated using the same dense grid and endpoint window $E_w$ as before: $\\hat{S} = \\max_{x \\in E_w} |\\hat{r}(x)|$.\n\nFinally, the effectiveness of the refinement is evaluated by computing the improvement ratio $R$:\n$$R = \\frac{S - \\hat{S}}{S}$$\nThis ratio is defined only if the initial error score $S > 0$. If $S=0$, we define $R=0$, as there was no error to improve upon. The procedure is deemed successful if this ratio meets or exceeds a given threshold $\\tau$, i.e., if $R \\ge \\tau$.\n\nFor the test case involving $f(x) = x^3$ with an initial node count of $n=10$, the degree of the function (3) is less than the maximum possible degree of the interpolant ($n-1 = 9$). Consequently, the initial interpolating polynomial $p_{10}(x)$ will be identical to $f(x)$, i.e., $p_{10}(x) = x^3$. The residual $r(x)$ will be zero for all $x$, leading to an initial score of $S=0$. Subsequently, all midpoint residuals and indicators $I_i$ will also be zero. After adding any $k$ new nodes, the refined interpolant $\\hat{p}(x)$ will still be exactly $x^3$, resulting in $\\hat{S}=0$. According to the problem definition, $R=0$ in this situation. The final test $R \\ge \\tau$ will therefore be false for any $\\tau > 0$, correctly indicating no improvement was needed or achieved.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import BarycentricInterpolator\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\"runge25\", 10, 8, 1.5, 0.2, 5001, 0.2),\n        (\"runge25\", 10, 2, 1.5, 0.2, 5001, 0.05),\n        (\"cubic\", 10, 8, 1.5, 0.2, 5001, 0.2),\n        (\"runge25\", 10, 8, 1.5, 0.2, 5001, 0.9),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_one_case(*case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_one_case(f_id, n, k, alpha, w, N_grid, tau):\n    \"\"\"\n    Implements the adaptive node refinement procedure for a single test case.\n\n    Args:\n        f_id (str): Function identifier (\"runge25\" or \"cubic\").\n        n (int): Initial number of equispaced nodes.\n        k (int): Maximum number of midpoints to add.\n        alpha (float): Endpoint bias parameter.\n        w (float): Endpoint window width.\n        N_grid (int): Number of points in the dense evaluation grid.\n        tau (float): Improvement ratio threshold.\n\n    Returns:\n        bool: True if the improvement ratio is >= tau, False otherwise.\n    \"\"\"\n    # 1. Define the function f(x) based on the identifier.\n    if f_id == \"runge25\":\n        def f(x):\n            return 1.0 / (1.0 + 25.0 * x**2)\n    elif f_id == \"cubic\":\n        def f(x):\n            return x**3\n    else:\n        raise ValueError(\"Unknown function identifier\")\n\n    # 2. Define the dense evaluation grid and the endpoint window.\n    x_grid = np.linspace(-1.0, 1.0, N_grid)\n    endpoint_mask = (x_grid <= -1.0 + w) | (x_grid >= 1.0 - w)\n\n    # 3. Initial interpolation setup.\n    x_nodes_initial = np.linspace(-1.0, 1.0, n)\n    y_nodes_initial = f(x_nodes_initial)\n    p_n = BarycentricInterpolator(x_nodes_initial, y_nodes_initial)\n\n    # 4. Calculate the initial residual and endpoint oscillation score S.\n    f_vals_grid = f(x_grid)\n    p_n_vals_grid = p_n(x_grid)\n    r_vals_grid = p_n_vals_grid - f_vals_grid\n    \n    s_val = np.max(np.abs(r_vals_grid[endpoint_mask]))\n\n    # If initial error is effectively zero, improvement R is 0.\n    if np.isclose(s_val, 0.0):\n        return 0.0 >= tau\n\n    # 5. Adaptive refinement: compute indicators and select new nodes.\n    midpoints = (x_nodes_initial[:-1] + x_nodes_initial[1:]) / 2.0\n    r_midpoints = p_n(midpoints) - f(midpoints)\n    indicators = np.abs(r_midpoints) * (1.0 + alpha * np.abs(midpoints))\n    \n    num_to_add = min(k, len(midpoints))\n    top_indices = np.argsort(indicators)[-num_to_add:]\n    nodes_to_add = midpoints[top_indices]\n    \n    x_nodes_refined = np.sort(np.union1d(x_nodes_initial, nodes_to_add))\n    y_nodes_refined = f(x_nodes_refined)\n\n    # 6. Recompute interpolant on the refined node set.\n    p_hat = BarycentricInterpolator(x_nodes_refined, y_nodes_refined)\n\n    # 7. Calculate the new endpoint oscillation score S_hat.\n    p_hat_vals_grid = p_hat(x_grid)\n    r_hat_vals_grid = p_hat_vals_grid - f_vals_grid\n    s_hat_val = np.max(np.abs(r_hat_vals_grid[endpoint_mask]))\n\n    # 8. Compute the improvement ratio R and compare with the threshold tau.\n    improvement_ratio = (s_val - s_hat_val) / s_val\n    \n    return improvement_ratio >= tau\n\nsolve()\n```"
        }
    ]
}