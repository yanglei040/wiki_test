{
    "hands_on_practices": [
        {
            "introduction": "牛顿法以其二次收敛速度而闻名，但这依赖于一些关键假设。本练习将探讨当一个基本假设——根点的导数非零——被违反时会发生什么。通过分析函数 $f(x) = x|x|$，您将推导出迭代序列的精确行为，并揭示收敛速度为何从二次降为线性。",
            "id": "3262164",
            "problem": "考虑由函数 $f(x)=x|x|$ 定义的非线性方程。方程 $f(x)=0$ 在 $x=0$ 处有一个根。您将分析从任意非零初始猜测值开始，应用于该函数的牛顿法的行为。\n\n仅使用标量函数的牛顿法的核心定义，即迭代公式为 $x_{k+1}=x_{k}-\\frac{f(x_{k})}{f^{\\prime}(x_{k})}$ (当 $f^{\\prime}(x_{k})\\neq 0$ 时)，以及微积分中的标准可微性法则，推导该函数 $f$ 的精确迭代映射，对于所有 $x_k \\neq 0$ 将其简化为 $x_k$ 的函数，然后进行迭代，以获得 $x_n$ 关于 $x_0$ 和 $n$ (对于所有 $n\\in\\mathbb{N}$) 的封闭形式表达式。使用您的显式表达式，通过计算极限来确定牛顿迭代序列逼近根 $x^{\\star}=0$ 的渐进速率\n$$\nL=\\lim_{k\\to\\infty}\\frac{|x_{k+1}-x^{\\star}|}{|x_{k}-x^{\\star}|}.\n$$\n\n仅使用牛顿法局部收敛理论中通常引用的基本条件，仔细解释在此问题中哪个（些）条件不满足，以及这种不满足如何体现在计算出的极限中。您的最终答案必须是 $L$ 的精确实数值（无需四舍五入）。",
            "solution": "该问题要求分析应用于函数 $f(x) = x|x|$ 以寻找根 $x^{\\star} = 0$ 的牛顿法。分析包括推导迭代映射，寻找迭代序列的封闭形式表达式，以及计算渐进收敛速率。最后，需要通过识别牛顿法收敛理论的标准条件的失效之处，来解释为什么收敛不是二次的。\n\n首先，我们推导牛顿法的迭代公式，即 $x_{k+1} = x_{k} - \\frac{f(x_{k})}{f'(x_{k})}$。我们必须计算 $f(x) = x|x|$ 的导数。该函数可以写成分段形式：\n$$\nf(x) = \\begin{cases}\nx^2  \\text{如果 } x \\ge 0 \\\\\n-x^2  \\text{如果 } x  0\n\\end{cases}\n$$\n对于 $x \\neq 0$，$f(x)$ 的导数可以对每一段分别计算：\n- 当 $x  0$ 时，$f(x) = x^2$，所以 $f'(x) = 2x$。\n- 当 $x  0$ 时，$f(x) = -x^2$，所以 $f'(x) = -2x$。\n这两个表达式可以使用绝对值函数合并成一个单一形式：对于所有 $x \\neq 0$，$f'(x) = 2|x|$。\n\n问题陈述初始猜测值 $x_0$ 非零。只要 $f'(x_k) \\neq 0$，牛顿迭代就有定义。由于 $f'(x_k) = 2|x_k|$，导数仅在 $x_k=0$ 时为零。我们将证明如果 $x_k \\neq 0$，则 $x_{k+1} \\neq 0$，因此对于所有 $k \\in \\mathbb{N}$，迭代都是良定义的。\n\n将 $f(x_k)=x_k|x_k|$ 和 $f'(x_k)=2|x_k|$ 代入非零迭代值 $x_k$ 的牛顿法公式中：\n$$\nx_{k+1} = x_k - \\frac{x_k|x_k|}{2|x_k|}\n$$\n由于 $x_k \\neq 0$，我们有 $|x_k| \\neq 0$，可以进行化简：\n$$\nx_{k+1} = x_k - \\frac{x_k}{2} = \\frac{1}{2}x_k\n$$\n这是对于任何 $x_k \\neq 0$ 的精确迭代映射。从这个映射可以清楚地看出，如果 $x_k \\neq 0$，那么 $x_{k+1} = \\frac{1}{2}x_k \\neq 0$。因此，从任何 $x_0 \\neq 0$ 开始，所有后续的迭代值 $x_n$ 都将是非零的。\n\n接下来，我们推导 $x_n$ 关于初始猜测值 $x_0$ 和迭代次数 $n$ 的封闭形式表达式。关系式 $x_{k+1} = \\frac{1}{2}x_k$ 是一个简单的几何递推关系。\n对于 $k=0$，我们有 $x_1 = \\frac{1}{2}x_0$。\n对于 $k=1$，我们有 $x_2 = \\frac{1}{2}x_1 = \\frac{1}{2}\\left(\\frac{1}{2}x_0\\right) = \\left(\\frac{1}{2}\\right)^2 x_0$。\n通过归纳法，第 $n$ 次迭代的封闭形式表达式为：\n$$\nx_n = \\left(\\frac{1}{2}\\right)^n x_0\n$$\n对于所有 $n \\in \\mathbb{N}$。\n\n现在，我们通过计算极限 $L$ 来计算渐进收敛速率。根是 $x^{\\star} = 0$。\n$$\nL = \\lim_{k\\to\\infty}\\frac{|x_{k+1}-x^{\\star}|}{|x_{k}-x^{\\star}|} = \\lim_{k\\to\\infty}\\frac{|x_{k+1}-0|}{|x_{k}-0|} = \\lim_{k\\to\\infty}\\frac{|x_{k+1}|}{|x_k|}\n$$\n使用迭代映射 $x_{k+1} = \\frac{1}{2}x_k$：\n$$\nL = \\lim_{k\\to\\infty}\\frac{|\\frac{1}{2}x_k|}{|x_k|} = \\lim_{k\\to\\infty} \\frac{\\frac{1}{2}|x_k|}{|x_k|}\n$$\n由于 $x_0 \\neq 0$，$x_k \\neq 0$ 对所有 $k$ 成立，所以我们可以从分子和分母中消去 $|x_k|$：\n$$\nL = \\lim_{k\\to\\infty} \\frac{1}{2} = \\frac{1}{2}\n$$\n值 $L = 1/2$ 表明收敛是线性的，每一步的误差都减少一个常数因子 $1/2$。\n\n最后，我们通过检验牛顿法局部收敛的基本条件来解释这种行为。牛顿法二次收敛到根 $x^{\\star}$ 的标准定理需要几个条件，包括：\n1. $f(x^{\\star}) = 0$。\n2. $f'(x^{\\star}) \\neq 0$（根必须是单根或非奇异的）。\n3. $f(x)$ 必须在 $x^{\\star}$ 的一个邻域内二次连续可微。\n\n让我们在根 $x^{\\star} = 0$ 处检查函数 $f(x) = x|x|$ 的这些条件。\n1.  条件 1：$f(0) = 0|0| = 0$。此条件满足。\n2.  条件 2：我们需要计算 $f'(0)$。在 $x=0$ 处的导数由极限定义：\n    $$\n    f'(0) = \\lim_{h\\to 0} \\frac{f(0+h) - f(0)}{h} = \\lim_{h\\to 0} \\frac{h|h| - 0}{h} = \\lim_{h\\to 0} |h| = 0\n    $$\n    条件 $f'(x^{\\star}) \\neq 0$ **不满足**，因为 $f'(0) = 0$。这是牛顿法未能对该函数实现二次收敛的主要原因。当 $f'(x^{\\star})=0$ 时，根不是单根。从几何上看，曲线 $y=f(x)$ 在根 $x^{\\star}=0$ 处的切线是水平的（它就是 x 轴本身）。随着迭代值 $x_k$ 逼近 $0$，在 $x_k$ 处的切线斜率 $f'(x_k) = 2|x_k|$ 也逼近 $0$。函数在根附近的这种“扁平化”减慢了收敛速度，使其从二次收敛降为线性收敛。推导出的极限 $L=1/2$ 正是这种减速的表现：连续误差的比值本身趋于一个常数 $L \\in (0, 1)$，而不是连续误差的平方的比值趋于一个常数（二次收敛意味着 $|x_{k+1}|/|x_k|^2 \\to C$）。\n\n3.  条件 3：我们考察二阶导数 $f''(x)$。我们有 $f'(x) = 2|x|$。为了检查在 $x=0$ 处的二次可微性，我们计算定义 $f''(0)$ 的极限：\n    $$\n    f''(0) = \\lim_{h\\to 0} \\frac{f'(0+h) - f'(0)}{h} = \\lim_{h\\to 0} \\frac{2|h| - 0}{h} = \\lim_{h\\to 0} \\frac{2|h|}{h}\n    $$\n    这个极限不存在，因为左极限和右极限不同：\n    - 右极限：$\\lim_{h\\to 0^+} \\frac{2h}{h} = 2$。\n    - 左极限：$\\lim_{h\\to 0^-} \\frac{-2h}{h} = -2$。\n    由于该极限不存在，$f(x)$ 在 $x=0$ 处不是二次可微的。因此，函数在根的邻域内是 $C^2$ 的条件也**不满足**。\n\n总之，未能满足二次收敛的标准条件，最关键的是根必须是单根 ($f'(x^{\\star}) \\neq 0$) 的要求，导致了观察到的线性收敛，其速率常数为 $L=1/2$。",
            "answer": "$$\n\\boxed{\\frac{1}{2}}\n$$"
        },
        {
            "introduction": "在前一个练习的基础上，我们现在考虑一类更普遍的问题根源：重根（即重数大于1的根）。本练习将演示标准牛顿法在此类根上为何收敛缓慢，更重要的是，如何通过一个简单的修正——缩放牛顿步长——来恢复其快速的收敛特性。您将对函数 $f(x)=(x-\\pi)^4$ 实施这一修正，并验证其有效性。",
            "id": "3262250",
            "problem": "设函数 $f:\\mathbb{R}\\to\\mathbb{R}$ 由 $f(x)=(x-\\pi)^4$ 给出，它在 $x^\\star=\\pi$ 处有一个重数为 $p=4$ 的根。考虑求根法的基本方法——牛顿法，其迭代公式定义为 $x_{k+1}=x_k-\\frac{f(x_k)}{f'(x_k)}$，以及根的重数的概念：如果 $f(x)=(x-x^\\star)^p g(x)$ 且 $g(x^\\star)\\neq 0$，则 $x^\\star$ 是一个重数为 $p>1$ 的根。众所周知，标准的牛顿法在处理重根时会失去其典型的二次收敛性。你的任务是基于这些基本原理，推导出一个通过常数因子对牛顿步长进行缩放的修正方法，分析其对于重根的误差动态，然后对函数 $f(x)=(x-\\pi)^4$ 实现并评估该方法。\n\n要求：\n- 从牛顿法的基本迭代公式 $x_{k+1}=x_k-\\frac{f(x_k)}{f'(x_k)}$ 和重数的定义出发，推导一个缩放步长族（其中牛顿步长乘以一个实参数 $m$）的误差更新。写出误差 $e_k=x_k-x^\\star$，并仅使用代数以及微分的乘法和链式法则，推导出当 $f(x)=(x-x^\\star)^p$ 时 $e_{k+1}$ 的精确映射关系。\n- 使用你的推导，纯粹从数学角度解释为什么标准牛顿法在处理重根时仅表现出线性收敛性，以及如何通过恰当地选择缩放因子来恢复至少二次的收敛性。你的推理必须从基本定义出发，不得假定任何已知的专门公式。\n- 在一个程序中实现缩放步长的迭代法，并对函数 $f(x)=(x-\\pi)^4$ 评估以下测试组，使用 $x^\\star=\\pi$ 和 $p=4$。对于每种情况，定义 $e_k=x_k-\\pi$ 并按照说明计算该情况所需的输出：\n    - 测试 $1$（二次收敛性失效）：使用 $m=1$ 和 $x_0=0$。执行恰好 $1$ 次迭代得到 $x_1$，并报告观测到的线性因子 $r_1=\\frac{|e_1|}{|e_0|}$（以浮点数形式）。\n    - 测试 $2$（恢复快速收敛）：使用 $m=4$ 和 $x_0=0$。迭代直到 $|e_k|  \\varepsilon$（容差 $\\varepsilon=10^{-12}$）或达到最多 $50$ 次迭代。报告达到容差所需的整数迭代次数 $N_4$。\n    - 测试 $3$（修正不足的缩放）：使用 $m=3$ 和 $x_0=-1$。执行恰好 $1$ 次迭代，并报告 $r_3=\\frac{|e_1|}{|e_0|}$（以浮点数形式）。\n    - 测试 $4$（过度修正但收敛的缩放）：使用 $m=5$ 和 $x_0=4$。执行恰好 $1$ 次迭代，并报告有符号比率 $\\rho_5=\\frac{e_1}{e_0}$（以浮点数形式）。\n    - 测试 $5$（因过度缩放导致的发散）：使用 $m=9$ 和 $x_0=0$。执行 $3$ 次迭代，产生 $e_1$、$e_2$ 和 $e_3$。如果 $|e_1||e_0|$、$|e_2||e_1|$ 且 $|e_3||e_2|$，则报告布尔值 $\\mathrm{True}$，否则报告 $\\mathrm{False}$。\n- 你的程序应该：\n    - 实现函数 $f(x)=(x-\\pi)^4$ 及其导数 $f'(x)=4(x-\\pi)^3$。\n    - 实现一个使用参数 $m$ 的单次缩放步长牛顿更新。\n    - 对于浮点数输出，在生成最终输出前四舍五入到 $6$ 位小数。\n- 最终输出格式：你的程序应生成单行输出，包含一个用方括号括起来的、由逗号分隔的结果列表（例如，[resultA,resultB,resultC,resultD,resultE]）。结果必须按 $[r_1,N_4,r_3,\\rho_5,\\text{diverged}]$ 的顺序出现，其中 $r_1$、$r_3$ 和 $\\rho_5$ 是保留6位小数的浮点数，$N_4$ 是一个整数，$\\text{diverged}$ 是一个布尔值。此问题不涉及单位，并且根据 $\\pi$ 的定义，所有角度都以弧度为单位。",
            "solution": "求解函数 $f(x)$ 的根 $x^\\star$ 是数值分析的基石之一。牛顿法为此提供了一个强大的迭代算法。然而，其著名的二次收敛性依赖于根是单根。对于重数为 $p  1$ 的根 $x^\\star$，其收敛速度会降至线性。本分析将推导缩放版牛顿法应用于具有重根的函数时的精确误差动态，解释这种收敛性降低的机制，并展示如何通过特定的缩放恢复快速收敛。\n\n设函数为 $f:\\mathbb{R}\\to\\mathbb{R}$，且 $x^\\star$ 是一个重数为 $p$ 的根，即 $f(x) = (x-x^\\star)^p g(x)$ 其中 $g(x^\\star) \\neq 0$。本题要求分析 $f(x)=(x-x^\\star)^p$ 的特殊情况，这对应于对所有 $x$ 都有 $g(x)=1$。\n\n缩放牛顿迭代法由下式给出\n$$x_{k+1} = x_k - m \\frac{f(x_k)}{f'(x_k)}$$\n其中 $m$ 是一个实值缩放参数。第 $k$ 次迭代的误差定义为 $e_k = x_k - x^\\star$。因此，我们可以写成 $x_k = x^\\star + e_k$ 和 $x_{k+1} = x^\\star + e_{k+1}$。将这些代入迭代公式可得：\n$$x^\\star + e_{k+1} = (x^\\star + e_k) - m \\frac{f(x^\\star + e_k)}{f'(x^\\star + e_k)}$$\n两边减去 $x^\\star$ 得到误差更新方程：\n$$e_{k+1} = e_k - m \\frac{f(x^\\star + e_k)}{f'(x^\\star + e_k)}$$\n\n按照题目的指示，我们针对特定函数 $f(x) = (x-x^\\star)^p$ 进行分析。\n首先，我们在 $x_k = x^\\star + e_k$ 处计算函数值：\n$$f(x_k) = f(x^\\star + e_k) = ((x^\\star + e_k) - x^\\star)^p = e_k^p$$\n接着，我们使用链式法则和幂法则求 $f(x)$ 的导数：\n$$f'(x) = \\frac{d}{dx}(x-x^\\star)^p = p(x-x^\\star)^{p-1} \\cdot \\frac{d}{dx}(x-x^\\star) = p(x-x^\\star)^{p-1}$$\n在 $x_k = x^\\star + e_k$ 处计算导数值：\n$$f'(x_k) = f'(x^\\star + e_k) = p((x^\\star + e_k) - x^\\star)^{p-1} = p e_k^{p-1}$$\n现在，我们将 $f(x_k)$ 和 $f'(x_k)$ 的表达式代入误差更新方程：\n$$e_{k+1} = e_k - m \\frac{e_k^p}{p e_k^{p-1}}$$\n假设 $e_k \\neq 0$（即我们尚未收敛），我们可以简化这个分数：\n$$e_{k+1} = e_k - m \\frac{e_k}{p}$$\n提取公因式 $e_k$，我们得到该函数的精确误差映射关系：\n$$e_{k+1} = e_k \\left(1 - \\frac{m}{p}\\right)$$\n\n这个推导出的关系式 $e_{k+1} = C e_k$（其中 $C = 1 - \\frac{m}{p}$ 是一个常数）正是线性收敛的定义。每一步迭代，误差都会减少一个固定的因子。收敛速度取决于这个因子的大小 $|C|$。为了保证收敛，我们需要 $|C|  1$。\n\n现在我们可以基于这个结果来分析牛顿法的行为。\n首先，考虑标准的牛顿法，它对应于缩放因子 $m=1$。误差更新方程变为：\n$$e_{k+1} = e_k \\left(1 - \\frac{1}{p}\\right)$$\n对于重根，我们有 $p  1$。因此，收敛因子 $C = 1 - \\frac{1}{p}$ 是一个满足 $0  C  1$ 的常数。在 $p=4$ 的具体情况下，该因子为 $1 - \\frac{1}{4} = \\frac{3}{4}$。每一步迭代误差仅减少 $25\\%$，这清晰地表明了收敛是线性的，而非二次的。这解释了为什么标准牛顿法在重根处会失去快速收敛性。\n\n其次，考虑如何恢复更快的收敛速度。目标是选择缩放参数 $m$，使得收敛因子 $|C| = |1 - \\frac{m}{p}|$ 最小化。$C$ 的理想值是 $0$，因为这意味着 $e_{k+1}=0$，即一步收敛。将因子设为零：\n$$1 - \\frac{m}{p} = 0 \\implies m=p$$\n通过选择缩放因子 $m$ 等于根的重数 $p$，我们得到 $e_{k+1} = e_k(1-\\frac{p}{p}) = 0$。这表明对于形如 $f(x)=(x-x^\\star)^p$ 的函数，使用 $m=p$ 的修正牛顿法可以在单次迭代中找到精确根（假设使用无限精度算术）。对于更一般的情况 $f(x)=(x-x^\\star)^p g(x)$，涉及泰勒级数的更详细分析表明，设置 $m=p$ 可以消除误差展开式中的线性项，从而得到 $e_{k+1} = O(e_k^2)$，因此恢复了至少二次的收敛性。恰当地选择 $m$ 从根本上改变了误差动态，消除了导致线性收敛的瓶颈。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and evaluates a scaled-step Newton's method for a function with a multiple root.\n    \"\"\"\n    # Define pi from numpy for precision\n    pi = np.pi\n    p = 4  # Multiplicity of the root for f(x) = (x-pi)^4\n\n    # Define the function and its derivative\n    def f(x_val):\n        return (x_val - pi)**p\n\n    def fp(x_val):\n        if x_val == pi:\n            return 0.0\n        return p * (x_val - pi)**(p - 1)\n\n    # --- Test Cases ---\n\n    results = []\n\n    # Test 1: Standard Newton's method (m=1), showing linear convergence\n    m1 = 1\n    x0_1 = 0.0\n    # Calculate one iteration\n    e0_1 = x0_1 - pi\n    # The term f(x)/f'(x) simplifies to (x-pi)/p\n    x1_1 = x0_1 - m1 * (x0_1 - pi) / p\n    e1_1 = x1_1 - pi\n    r1 = abs(e1_1 / e0_1)\n    results.append(round(r1, 6))\n\n    # Test 2: Modified Newton (m=p), restoring fast convergence\n    m2 = p\n    x0_2 = 0.0\n    tol = 1e-12\n    max_iter = 50\n    xk_2 = x0_2\n    N4 = 0\n    for k in range(max_iter + 1):\n        ek_2 = xk_2 - pi\n        if abs(ek_2)  tol:\n            N4 = k\n            break\n        # Avoid division by zero if already at the root\n        deriv_val = fp(xk_2)\n        if deriv_val == 0:\n            N4 = k\n            break\n        xk_2 = xk_2 - m2 * f(xk_2) / deriv_val\n    else:\n        N4 = max_iter\n    results.append(N4)\n\n    # Test 3: Undercorrected scaling (m=3)\n    m3 = 3\n    x0_3 = -1.0\n    # Calculate one iteration\n    e0_3 = x0_3 - pi\n    # The term f(x)/f'(x) simplifies to (x-pi)/p\n    x1_3 = x0_3 - m3 * (x0_3 - pi) / p\n    e1_3 = x1_3 - pi\n    r3 = abs(e1_3 / e0_3)\n    results.append(round(r3, 6))\n\n    # Test 4: Overcorrected but convergent scaling (m=5)\n    m4 = 5\n    x0_4 = 4.0\n    # Calculate one iteration\n    e0_4 = x0_4 - pi\n    # The term f(x)/f'(x) simplifies to (x-pi)/p\n    x1_4 = x0_4 - m4 * (x0_4 - pi) / p\n    e1_4 = x1_4 - pi\n    rho5 = e1_4 / e0_4\n    results.append(round(rho5, 6))\n\n    # Test 5: Divergence from excessive scaling (m=9)\n    m5 = 9\n    x0_5 = 0.0\n    errors = [x0_5 - pi]\n    xk_5 = x0_5\n    for _ in range(3):\n        # The term f(x)/f'(x) simplifies to (x-pi)/p\n        xk_5 = xk_5 - m5 * (xk_5 - pi) / p\n        errors.append(xk_5 - pi)\n    \n    diverged = (abs(errors[1])  abs(errors[0])) and \\\n               (abs(errors[2])  abs(errors[1])) and \\\n               (abs(errors[3])  abs(errors[2]))\n    results.append(diverged)\n\n    # Final print statement in the exact required format.\n    # Results are [r1, N4, r3, rho5, diverged]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "牛顿法的陷阱甚至可能在根本身性质良好的情况下出现。如果初始猜测远离根点，该方法可能会“过冲”，即走出过大的步长，进入使收敛停滞的区域。本练习介绍了一种强大且广泛使用的技术，称为回溯线搜索，它通过确保每一步都朝着解有足够的“进步”，来增强牛顿法的全局收敛性，从而有效避免过冲问题。",
            "id": "3262151",
            "problem": "考虑非线性函数 $f:\\mathbb{R}\\to\\mathbb{R}$ 定义为 $f(x)=\\tanh(10x)-0.5$ 的标量求根问题。求解 $f(x)=0$ 的牛顿法基于 $f$ 在当前迭代点 $x_k$ 周围的一阶泰勒展开，即 $f(x_k+p)\\approx f(x_k)+f'(x_k)p$，该展开忽略了高阶项。将此线性化模型设为零并求解 $p$，得到牛顿步 $p_k=-\\frac{f(x_k)}{f'(x_k)}$，以及下一个迭代点 $x_{k+1}=x_k+p_k$。导数 $f'(x)$ 是双曲正切函数的导数，必须精确计算。在实践中，当 $|f'(x_k)|$ 很小或 $|p_k|$ 很大时，此方法可能表现出过冲现象，将 $x_k$ 送入函数 $f$ 饱和且 $f'(x)$ 接近零的区域，从而影响收敛。\n\n为减轻过冲，您必须通过回溯线搜索（BLS）实现一种阻尼策略。采用价值函数 $\\phi(x)=\\tfrac{1}{2}f(x)^2$，它编码了残差大小的标量度量。对于标量牛顿方向 $p_k=-\\frac{f(x_k)}{f'(x_k)}$，回溯线搜索选择一个步长 $t_k\\in(0,1]$ 以确保 $\\phi$ 有充分下降。具体来说，从 $t_k=1$ 开始，使用 $\\beta\\in(0,1)$ 重复替换 $t_k\\leftarrow\\beta\\,t_k$，直到对于选定的常数 $c\\in(0,1)$，满足Armijo型不等式\n$$\n\\phi(x_k+t_k p_k)\\le (1-c\\,t_k)\\,\\phi(x_k)\n$$\n为止。如果导数大小 $|f'(x_k)|$ 低于规定的阈值，则必须拒绝该步，以避免因除以极小的数而引起的数值不稳定性。如果在最小步长 $t_{\\min}0$ 之上没有 $t_k$ 满足该不等式，则算法应终止并报告该迭代序列失败。\n\n您的程序必须在同一测试套件上实现两种算法：\n- 无阻尼牛顿法（每次迭代均采用完整步长 $t_k=1$）。\n- 使用上述回溯线搜索的阻尼牛顿法。\n\n使用以下科学一致的规范：\n- 函数 $f(x)=\\tanh(10x)-0.5$ 及其导数 $f'(x)=10\\,\\operatorname{sech}^2(10x)$，其中 $\\operatorname{sech}(z)=\\frac{1}{\\cosh(z)}$，$\\cosh(z)$ 是双曲余弦。\n- 价值函数 $\\phi(x)=\\tfrac{1}{2}f(x)^2$。\n- 残差大小的收敛容差：如果 $|f(x_k)| \\le 10^{-12}$，则停止。\n- 每次运行的最大迭代次数：$50$。\n- 导数保护：如果 $|f'(x_k)|  10^{-12}$，则终止当前运行。\n- 回溯参数：$c=10^{-4}$，$\\beta=0.5$，$t_{\\min}=10^{-8}$。\n\n测试套件和覆盖范围：\n- 理想路径：$x_0=0.1$（距离根点适中）。\n- 易过冲的初始点：$x_0=0.3$（牛顿法的完整步长非常大）。\n- 导数接近零的边界情况：$x_0=2.0$（$f'(x)$ 极小的饱和区域）。\n- 符号相反的起始点：$x_0=-0.2$（必须穿越到唯一的正根）。\n\n对于每个测试用例，运行两种方法，并记录每种方法的最终残差大小 $|f(x_{\\text{final}})|$ 作为浮点数。要求的最终输出格式是单行，包含一个方括号括起来的逗号分隔列表，该列表按顺序汇总每个测试用例的无阻尼残差和阻尼残差。例如，输出必须如下所示：\n$$\n[\\text{residual\\_undamped\\_case1},\\text{residual\\_damped\\_case1},\\text{residual\\_undamped\\_case2},\\text{residual\\_damped\\_case2},\\text{residual\\_undamped\\_case3},\\text{residual\\_damped\\_case3},\\text{residual\\_undamped\\_case4},\\text{residual\\_damped\\_case4}]\n$$\n其中每个条目都是一个浮点数。不涉及物理单位；所有量都是无单位的实数。",
            "solution": "设计始于通过一阶泰勒展开推导出的标量牛顿法。对于一个可微的标量函数 $f:\\mathbb{R}\\to\\mathbb{R}$，在当前迭代点 $x_k$ 周围的泰勒展开为\n$$\nf(x_k+p)\\approx f(x_k)+f'(x_k)\\,p.\n$$\n在此线性模型中令 $f(x_k+p)=0$，得到牛顿步\n$$\np_k=-\\frac{f(x_k)}{f'(x_k)},\n$$\n下一个迭代点为 $x_{k+1}=x_k+p_k$。在标准条件下，此方法是局部二次收敛的：$f$ 足够光滑，在根 $x^\\star$ 处 $f'(x^\\star)\\ne 0$，并且初始猜测足够接近 $x^\\star$。然而，远离根或在 $f'(x)$ 很小的区域， $|p_k|$ 可能会非常大，可能将迭代点 $x_k$ 送入 $f$ 饱和且 $f'(x)$ 接近零的区域，从而使进展恶化。这种现象称为过冲。\n\n对于特定函数 $f(x)=\\tanh(10x)-0.5$，存在一个根，因为双曲正切函数是严格递增且界于 $-1$ 和 $1$ 之间的。根 $x^\\star$ 满足 $\\tanh(10x^\\star)=0.5$，所以 $10x^\\star=\\operatorname{artanh}(0.5)$ 且 $x^\\star=\\operatorname{artanh}(0.5)/10$，其中 $\\operatorname{artanh}$ 表示反双曲正切。其导数为\n$$\nf'(x)=10\\,\\operatorname{sech}^2(10x)=10\\left(\\frac{1}{\\cosh(10x)}\\right)^2.\n$$\n当 $|10x|$ 很大时，$\\cosh(10x)$ 很大，因此 $f'(x)$ 变得非常小，使得牛顿步 $p_k=-\\frac{f(x_k)}{f'(x_k)}$ 的量级极大且不稳定。这样的步长很容易将迭代点 $x_k$ 传播到 $\\tanh(10x)\\approx \\pm 1$ 且 $f'(x)\\approx 0$ 的饱和区，导致数值困难。\n\n为减轻过冲，我们使用回溯线搜索（BLS）和一个价值函数来阻尼牛顿步\n$$\n\\phi(x)=\\frac{1}{2}f(x)^2,\n$$\n该函数度量残差的大小。标量牛顿方向 $p_k=-\\frac{f(x_k)}{f'(x_k)}$ 在根附近是 $\\phi$ 的一个下降方向。确实，$\\phi$ 在方向 $p$ 上的方向导数为\n$$\n\\phi'(x_k;p)=f(x_k)f'(x_k)\\,p,\n$$\n代入 $p_k$ 得到 $\\phi'(x_k;p_k)=-f(x_k)^2$，只要 $f(x_k)\\ne 0$ 这就是负的。这表明，局部地，牛顿步会减小价值函数 $\\phi$。然而，全局上取一个完整步长 $t_k=1$ 可能无法减小 $\\phi$。因此，回溯线搜索选择一个步长 $t_k\\in(0,1]$，使得Armijo型充分下降条件成立：\n$$\n\\phi(x_k+t_k p_k)\\le (1-c\\,t_k)\\,\\phi(x_k),\n$$\n其中 $c\\in(0,1)$ 是一个小常数，$t_k$ 从 $1$ 开始，并按因子 $\\beta\\in(0,1)$ 减小，直到不等式被满足。此过程确保了残差度量 $\\phi$ 的单调减少，从而防止过冲。$\\phi$ 的连续性意味着足够小的 $t_k$ 会产生下降，因为 $p_k$ 是一个下降方向，所以除非 $f'(x_k)$ 实际上为零，否则回溯过程会以一个可接受的 $t_k$ 终止。\n\n在第 $k$ 次迭代时，阻尼方法的算法步骤：\n1. 计算 $f(x_k)$ 和 $f'(x_k)$。如果 $|f(x_k)| \\le 10^{-12}$，停止。\n2. 如果 $|f'(x_k)|  10^{-12}$，终止以避免不稳定的步。\n3. 计算牛顿方向 $p_k=-\\frac{f(x_k)}{f'(x_k)}$。\n4. 初始化 $t_k=1$。当 $t_k \\ge t_{\\min}$ 时：\n   - 构造 $x_k^{\\text{cand}}=x_k+t_k p_k$ 并计算 $\\phi(x_k^{\\text{cand}})$。\n   - 如果 $\\phi(x_k^{\\text{cand}})\\le (1-c\\,t_k)\\,\\phi(x_k)$，接受该步：设 $x_{k+1}=x_k^{\\text{cand}}$ 并跳出循环。\n   - 否则，减小步长：$t_k\\leftarrow\\beta\\,t_k$。\n5. 如果在 $t_k  t_{\\min}$ 时仍未找到可接受的步长，则该迭代失败。算法终止。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef f(x: float) - float:\n    # f(x) = tanh(10x) - 0.5\n    return float(np.tanh(10.0 * x) - 0.5)\n\ndef df(x: float) - float:\n    # f'(x) = 10 * sech^2(10x), where sech(z) = 1/cosh(z)\n    # Implement carefully to avoid overflow: for large |z|, cosh(z) can overflow to inf; 1/inf - 0 safely.\n    z = 10.0 * x\n    cosh_z = np.cosh(z)\n    # Handle potential overflow: if cosh_z is inf, then sech^2 is 0.\n    if not np.isfinite(cosh_z):\n        return 0.0\n    sech_z = 1.0 / cosh_z\n    return float(10.0 * (sech_z ** 2))\n\ndef newton_undamped(x0: float, max_iters: int = 50, tol_res: float = 1e-12, min_df: float = 1e-12) - float:\n    x = float(x0)\n    for _ in range(max_iters):\n        fx = f(x)\n        if abs(fx) = tol_res:\n            break\n        dfx = df(x)\n        if abs(dfx)  min_df:\n            # Derivative too small; stop to avoid unstable steps\n            break\n        step = -fx / dfx\n        x = x + step\n    return abs(f(x))\n\ndef newton_backtracking(x0: float,\n                        max_iters: int = 50,\n                        tol_res: float = 1e-12,\n                        c: float = 1e-4,\n                        beta: float = 0.5,\n                        t_min: float = 1e-8,\n                        min_df: float = 1e-12) - float:\n    x = float(x0)\n    for _ in range(max_iters):\n        fx = f(x)\n        if abs(fx) = tol_res:\n            break\n        dfx = df(x)\n        if abs(dfx)  min_df:\n            # Derivative too small; stop to avoid unstable steps\n            break\n        p = -fx / dfx\n        phi_x = 0.5 * (fx ** 2)\n        t = 1.0\n        accepted = False\n        # Backtracking loop\n        while t = t_min:\n            x_candidate = x + t * p\n            f_cand = f(x_candidate)\n            phi_cand = 0.5 * (f_cand ** 2)\n            if phi_cand = (1.0 - c * t) * phi_x:\n                x = x_candidate\n                accepted = True\n                break\n            t *= beta\n        if not accepted:\n            # Could not find an acceptable step size\n            break\n    return abs(f(x))\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Initial guesses: happy path, overshooting-prone, boundary case (near-zero derivative), sign-opposite start\n    initial_guesses = [0.1, 0.3, 2.0, -0.2]\n\n    # Algorithm parameters as specified\n    max_iters = 50\n    tol_res = 1e-12\n    c = 1e-4\n    beta = 0.5\n    t_min = 1e-8\n    min_df = 1e-12\n\n    results = []\n    for x0 in initial_guesses:\n        r_undamped = newton_undamped(x0, max_iters=max_iters, tol_res=tol_res, min_df=min_df)\n        r_damped = newton_backtracking(x0, max_iters=max_iters, tol_res=tol_res,\n                                       c=c, beta=beta, t_min=t_min, min_df=min_df)\n        results.append(r_undamped)\n        results.append(r_damped)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}