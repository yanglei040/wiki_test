## 引言
[牛顿法](@entry_id:140116)是[数值分析](@entry_id:142637)的基石之一，是一种用于[求解非线性方程](@entry_id:177343)和[优化问题](@entry_id:266749)的高效迭代算法。在理想条件下，它以惊人的二次收敛速度逼近解，这意味着每次迭代都能使解的有效数字位数大约翻倍。然而，这种强大的威力是建立在一系列严格的数学假设之上的，例如需要一个足够接近真解的初始猜测，以及函数在解附近具有良好的性态。当这些理想条件不被满足时，[牛顿法](@entry_id:140116)的行为就会变得难以预测，从收敛缓慢到剧烈发散，充满了各种“陷阱”。本文旨在系统性地揭示牛顿法背后的这些潜在失效模式。

文章将分为三个核心部分。首先，在“原理与机制”章节中，我们将深入剖析导致[牛顿法](@entry_id:140116)失效的四种主要机制：导数为零或接近零、病态曲率导致的发散、陷入循环或收敛至意外的根，以及因多重根和计算精度限制导致的性能退化。其次，在“应用与跨学科联系”章节中，我们将展示这些理论上的陷阱如何在机器人学、电力系统、[材料科学](@entry_id:152226)和经济学等真实世界问题中具体显现，揭示算法失败与物理现象之间的深刻联系。最后，在“动手实践”部分，您将通过具体的编程练习，亲手实现和观察[牛顿法](@entry_id:140116)的失效行为，并探索如[线搜索](@entry_id:141607)等简单的改进策略。通过本次学习，您将不仅掌握[牛顿法](@entry_id:140116)的公式，更能深刻理解其局限性，为在实际工作中选择和设计更稳健的数值方法打下坚实基础。

## 原理与机制

在深入探讨牛顿法可能遇到的复杂情况之前，我们首先简要回顾其核心思想。[牛顿法](@entry_id:140116)是一种强大的[迭代算法](@entry_id:160288)，用于[求解非线性方程](@entry_id:177343) $f(x)=0$ 的根。其迭代公式源于对函数 $f(x)$ 在当前点 $x_k$ 附近的一阶[泰勒展开](@entry_id:145057)：
$$
x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)}
$$
从几何上看，这相当于在点 $(x_k, f(x_k))$ 处作函数图像的[切线](@entry_id:268870)，并取该[切线](@entry_id:268870)与 $x$ 轴的交点作为下一个近似值 $x_{k+1}$。在理想条件下，即当根为单根（$f'(r) \neq 0$）且初始猜测值 $x_0$ 足够接近根 $r$ 时，[牛顿法](@entry_id:140116)展现出令人瞩目的**二次收敛**性。这意味着每次迭代后，解的[有效数字](@entry_id:144089)位数大约会翻倍，使其成为科学计算中首选的高效算法之一。

然而，[牛顿法](@entry_id:140116)的强大威力是建立在一系列隐式假设之上的。当这些假设不被满足时，算法的行为可能变得极不稳定，甚至完全失效。本章旨在系统性地剖析牛顿法的各种“陷阱”——即导致其收敛失败或性能退化的原理和机制。理解这些陷阱不仅对于诊断和解决数值问题至关重要，也为学习更稳健的算法（如拟牛顿法）奠定了基础。

### 失效模式一：除以零（或接近零）

牛顿法迭代公式的核心是一个分数，其分母是函数在当前点的导数 $f'(x_k)$。当这个导数值为零或接近零时，迭代步骤就会出现严重问题。

#### [驻点](@entry_id:136617)：水平[切线](@entry_id:268870)

最直接的失效情况是当某个迭代点 $x_k$ 恰好是函数的一个**[驻点](@entry_id:136617)**（stationary point），即 $f'(x_k) = 0$。从几何上看，这意味着函数在点 $(x_k, f(x_k))$ 的[切线](@entry_id:268870)是水平的。如果此时 $f(x_k) \neq 0$，这条水平[切线](@entry_id:268870)将永远不会与 $x$ 轴相交，[牛顿法](@entry_id:140116)的下一步迭代 $x_{k+1}$ 因而无法定义，算法在此处终止。

有人可能会认为，精确地落在一个[驻点](@entry_id:136617)上的概率很小。然而，问题在于，即使初始点不是[驻点](@entry_id:136617)，[牛顿法](@entry_id:140116)的迭代过程也可能将我们导向一个驻点。考虑一个简单的三次多项式 $f(x) = x^2(x-1) = x^3 - x^2$ 。该函数有两个[驻点](@entry_id:136617)，可通过求解 $f'(x) = 3x^2 - 2x = x(3x-2) = 0$ 得到，分别是 $x=0$ 和 $x=2/3$。如果我们想求解方程 $f(x)=0$ 的根（此例中为 $x=1$ 和 $x=0$），并从某个特定的初始点出发，迭代可能会失败。

让我们寻找一个初始点 $x_0$，使得第一次迭代 $x_1$ 恰好落在[驻点](@entry_id:136617) $x=0$ 上。根据[牛顿法公式](@entry_id:174055)，我们设定 $x_1=0$：
$$
0 = x_0 - \frac{f(x_0)}{f'(x_0)}
$$
在 $f'(x_0) \neq 0$ 的前提下，这等价于 $x_0 f'(x_0) = f(x_0)$。代入函数的表达式：
$$
x_0(3x_0^2 - 2x_0) = x_0^3 - x_0^2
$$
$$
3x_0^3 - 2x_0^2 = x_0^3 - x_0^2 \implies 2x_0^3 - x_0^2 = 0 \implies x_0^2(2x_0 - 1) = 0
$$
此方程的解为 $x_0=0$ 或 $x_0=1/2$。$x_0=0$ 本身就是一个[驻点](@entry_id:136617)，迭代无法开始。但 $x_0=1/2$ 是一个有效的初始点，因为 $f'(1/2) = -1/4 \neq 0$。从 $x_0=1/2$ 开始，第一次迭代将得到 $x_1 = 1/2 - \frac{f(1/2)}{f'(1/2)} = 1/2 - \frac{-1/8}{-1/4} = 0$。此时，算法到达 $x_1=0$，而 $f'(0)=0$，导致下一次迭代无法进行。这个例子清晰地表明，迭代序列可能会“自投罗网”，陷入导数为零的困境。

#### [极值](@entry_id:145933)点附近的[过冲](@entry_id:147201)

更常见的情况是，迭代点 $x_k$ 并未精确地落在驻点上，而是位于其附近。此时 $f'(x_k)$ 是一个非常小的非零数。根据迭代公式，一个很小的分母会导致一个巨大的[牛顿步长](@entry_id:177069) $|f(x_k)/f'(x_k)|$。这会导致下一个迭代点 $x_{k+1}$ 被“抛”到距离当前点非常遥远的位置，这种现象称为**[过冲](@entry_id:147201) (overshooting)**。

考虑一个二次函数 $f(x) = k(x-c)^2 - V$，其中 $k, c, V$ 均为正常数 。该函数在 $x=c$ 处有一个最小值，这是一个[驻点](@entry_id:136617)。假设我们想要求解 $f(x)=0$ 的根，而我们的初始猜测值 $x_0$ 不幸地非常接近这个最小值点，例如 $x_0 = c + \delta$，其中 $\delta$ 是一个很小的非零数。函数的导数是 $f'(x) = 2k(x-c)$。在 $x_0$ 处，我们有：
$$
f(x_0) = k\delta^2 - V, \quad f'(x_0) = 2k\delta
$$
计算下一个迭代点 $x_1$：
$$
x_1 = x_0 - \frac{f(x_0)}{f'(x_0)} = (c+\delta) - \frac{k\delta^2 - V}{2k\delta} = c + \delta - \frac{\delta}{2} + \frac{V}{2k\delta} = c + \frac{\delta}{2} + \frac{V}{2k\delta}
$$
当 $\delta$ 趋于零时，最后一项 $\frac{V}{2k\delta}$ 的[绝对值](@entry_id:147688)会变得任意大。这意味着，从一个接近极值点的位置开始，牛顿法可能会产生一个巨大的、破坏性的步长，将迭代点抛向远离任何实际根的区域，从而导致算法发散或进入其他非预期的行为模式。

#### 高维空间中的[奇异雅可比矩阵](@entry_id:147569)

当我们将牛顿法推广到[求解非线性方程](@entry_id:177343)组 $\mathbf{F}(\mathbf{x}) = \mathbf{0}$（其中 $\mathbf{x} \in \mathbb{R}^n, \mathbf{F}: \mathbb{R}^n \to \mathbb{R}^n$）时，导数 $f'(x)$ 的角色由**[雅可比矩阵](@entry_id:264467) (Jacobian matrix)** $\mathbf{J_F}(\mathbf{x})$ 取代。迭代公式变为：
$$
\mathbf{x}_{k+1} = \mathbf{x}_k - [\mathbf{J_F}(\mathbf{x}_k)]^{-1} \mathbf{F}(\mathbf{x}_k)
$$
在实际计算中，通常通过求解线性方程组 $\mathbf{J_F}(\mathbf{x}_k) \Delta \mathbf{x}_k = -\mathbf{F}(\mathbf{x}_k)$ 来获得步长 $\Delta \mathbf{x}_k = \mathbf{x}_{k+1} - \mathbf{x}_k$。

一维情况下 $f'(x)=0$ 的问题，在多维空间中对应于[雅可比矩阵](@entry_id:264467) $\mathbf{J_F}(\mathbf{x}_k)$ **奇异 (singular)** 的情况，即其[行列式](@entry_id:142978)为零。奇异矩阵不可逆，因此线性系统没有唯一解，[牛顿步](@entry_id:177069)骤无法定义。

这种情况可能发生在解本身所在的位置。考虑一个系统，它在几何上表示两个曲线的交点 。例如，[方程组](@entry_id:193238) $F(x,y) = (x^2+y^2-1, x+y-c) = \mathbf{0}$ 表示单位圆与直线 $x+y=c$ 的交点。该系统的雅可比矩阵为：
$$
\mathbf{J}_{F}(x,y) = \begin{pmatrix} 2x & 2y \\ 1 & 1 \end{pmatrix}
$$
其[行列式](@entry_id:142978)为 $\det(\mathbf{J}_{F}(x,y)) = 2x - 2y$。雅可比矩阵奇异的条件是 $x=y$。现在我们问：是否存在一个参数 $c$ 的值，使得[方程组](@entry_id:193238)的解 $(x,y)$ 恰好满足 $x=y$？这意味着交点必须位于单位圆和直线 $y=x$ 上。将 $y=x$ 代入[圆的方程](@entry_id:169149) $x^2+y^2=1$，我们得到 $2x^2=1$，解得 $x=\pm\frac{1}{\sqrt{2}}$。
- 如果解是 $(\frac{\sqrt{2}}{2}, \frac{\sqrt{2}}{2})$，代入[直线方程](@entry_id:166789) $x+y=c$，得到 $c = \frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2} = \sqrt{2}$。
- 如果解是 $(-\frac{\sqrt{2}}{2}, -\frac{\sqrt{2}}{2})$，则 $c = -\sqrt{2}$。

因此，当 $c=\sqrt{2}$（或 $-\sqrt{2}$）时，直线 $x+y=c$ 与单位圆相切，交点恰好位于[雅可比矩阵](@entry_id:264467)奇异的线上。在这种情况下，尽管系统有（唯一的）解，但标准的牛顿法在解点本身就会失效。这在几何上对应于两个分量函数的等值线在解点处相切。

### 失效模式二：病态曲率与发散

除了导数接近零，函数及其导数的其他“病态”行为也可能导致牛顿法失效，特别是发散。

#### 陡峭[切线](@entry_id:268870)导致的发散

与水平[切线](@entry_id:268870)相反，一个**几乎垂直的[切线](@entry_id:268870)**也同样是灾难性的。这种情况发生在导数 $f'(x)$ 在根附近变得非常大时。一个非常陡峭的[切线](@entry_id:268870)与 $x$ 轴的交点可能比当前点离根更远。

一个经典的例子是求解 $f(x) = x^{1/3}$ 的根 。唯一的根是 $x=0$。其导数为 $f'(x) = \frac{1}{3}x^{-2/3}$。在根 $x=0$ 处，导数是未定义的（或者说趋于无穷大），这违反了牛顿法二次收敛所需的基本条件之一（$f'(r)$ 是一个有限的非零常数）。让我们看看迭代公式会产生什么：
$$
x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)} = x_k - \frac{x_k^{1/3}}{\frac{1}{3}x_k^{-2/3}} = x_k - 3x_k = -2x_k
$$
对于任何非零的初始点 $x_0$，迭代序列将是 $x_0, -2x_0, 4x_0, -8x_0, \dots, (-2)^k x_0, \dots$。迭代点不仅在根的两侧来回跳动（过冲），其与根的距离还以指数形式增长。这是一种剧烈的发散行为。几何上，由于 $x=0$ 附近[切线](@entry_id:268870)是垂直的，任何在 $x_k$ 处的[切线](@entry_id:268870)都会将下一个迭代点“射”到远处的另一侧。

#### [优化问题](@entry_id:266749)中的发散

[牛顿法](@entry_id:140116)不仅用于求根，也用于[优化问题](@entry_id:266749)，即寻找函数 $f(x)$ 的最小值或最大值。这相当于寻找 $f'(x)=0$ 的根。将牛顿求根法应用于 $f'(x)$，我们得到**牛顿优化法**的迭代公式：
$$
x_{k+1} = x_k - \frac{f'(x_k)}{f''(x_k)}
$$
这里，分母是函数的[二阶导数](@entry_id:144508)（曲率）。为了保证收敛到最小值，我们通常期望 $f''(x)>0$（函数是凸的）。如果这个条件不满足，例如在函数的非凸区域开始迭代，算法也可能发散。

考虑一个光学设计中的[成本函数](@entry_id:138681) $f(x) = \sqrt{L^2 + x^2}$，其中 $L>0$ 是一个常数 。我们希望找到其最小值点，通过观察可知是 $x=0$。我们计算一阶和[二阶导数](@entry_id:144508)：
$$
f'(x) = \frac{x}{\sqrt{L^2 + x^2}}, \quad f''(x) = \frac{L^2}{(L^2 + x^2)^{3/2}}
$$
代入牛顿优化公式，得到一个惊人地简单的[递推关系](@entry_id:189264)：
$$
x_{k+1} = x_k - \frac{x_k / \sqrt{L^2 + x_k^2}}{L^2 / (L^2 + x_k^2)^{3/2}} = x_k - x_k\frac{L^2+x_k^2}{L^2} = -\frac{x_k^3}{L^2}
$$
如果我们的初始猜测 $x_0$ 满足 $|x_0|  L$，那么 $|x_{k+1}| = |x_k|^3/L^2  |x_k|$，序列会收敛到 $0$。但如果初始猜测在区间之外，例如 $|x_0|  L$，那么 $|x_{k+1}| = |x_k| \cdot (|x_k|/L)^2  |x_k|$。迭代点将以极快的速度远离[最小值点](@entry_id:634980)。例如，从 $x_0 = \sqrt{2}L$ 开始，我们得到 $x_1 = -2\sqrt{2}L$, $x_2 = 16\sqrt{2}L$，等等，其[绝对值](@entry_id:147688)呈爆炸性增长。这说明，即使函数本身是凸的（此例中 $f''(x)0$ 处处成立），牛顿优化法也可能因为起始点离最小值太远而发散。

### 失效模式三：不收敛于根

除了完全发散到无穷大，[牛顿法](@entry_id:140116)的迭代序列还可能陷入既不收敛也不发散的“陷阱”中。

#### 周期循环

[牛顿法](@entry_id:140116)的迭代序列可能不会收敛到任何一个根，而是陷入一个**周期循环 (periodic cycle)**。例如，在一个 2-周期循环中，迭代序列会在两个点 $x_a$ 和 $x_b$ 之间来回[振荡](@entry_id:267781)：$x_k \to x_a \to x_b \to x_a \to \dots$。

我们可以构造一个产生这种行为的函数 。一个 2-周期循环意味着 $N(x_a) = x_b$ 和 $N(x_b) = x_a$，其中 $N(x) = x - p(x)/p'(x)$ 是牛顿迭代函数。通过一些代数推导，可以证明这要求函数 $p(x)$ 满足一个有趣的几何条件：在 $x_a$ 和 $x_b$ 处的[切线斜率](@entry_id:137445)之和等于连接点 $(x_a, p(x_a))$ 和 $(x_b, p(x_b))$ 的割线斜率，即 $p'(x_a) + p'(x_b) = \frac{p(x_b) - p(x_a)}{x_b - x_a}$。

一个满足此条件的简单例子是三次多项式 $p(x) = x^3 - 5x$。让我们选择两个对称的点 $x_a=-1$ 和 $x_b=1$。
- 从 $x_a=-1$ 开始：$p(-1)=4$, $p'(-1)=-2$。牛顿迭代给出 $N(-1) = -1 - \frac{4}{-2} = 1 = x_b$。
- 从 $x_b=1$ 开始：$p(1)=-4$, $p'(1)=-2$。牛顿迭代给出 $N(1) = 1 - \frac{-4}{-2} = -1 = x_a$。
因此，如果初始猜测是 $1$ 或 $-1$，[牛顿法](@entry_id:140116)将永远在这两个值之间循环，而永远不会收敛到方程的任何一个根（$0, \sqrt{5}, -\sqrt{5}$）。在更复杂的函数中，这种循环可以涉及更多点，或者表现为更混乱的、非周期的混沌行为。

#### 收敛至意外的根

当函数有多个根时，一个自然的假设是[牛顿法](@entry_id:140116)会收敛到离初始点 $x_0$ 最近的那个根。然而，这个直觉常常是错误的。每个根都有一个**吸引盆 (basin of attraction)**，即所有能收敛到该根的初始点的集合。这些吸引盆的边界可能极其复杂，甚至呈分形结构。因此，一个点可能离根 $r_1$ 非常近，但却位于根 $r_2$ 的吸引盆中。

我们可以构造一个函数来清晰地说明这一点 。考虑函数 $f(x) = x(x-1)e^{-\lambda x}$，其中 $\lambda  0$。这个函数有两个根，$r_1=0$ 和 $r_2=1$。通过分析牛顿迭代公式，可以证明存在一个特殊的起始点 $x_0 = 1/\lambda$，使得第一次迭代就精确地落在根 $r_2=1$ 上。

现在，让我们来设置一个“陷阱”。我们需要让这个起始点 $x_0 = 1/\lambda$ 非常接近根 $r_1=0$，但同时又离根 $r_2=1$ 很远。具体来说，我们要求 $|x_0 - r_1|  \frac{|x_0 - r_2|}{1000}$。代入 $x_0=1/\lambda$, $r_1=0, r_2=1$：
$$
\left|\frac{1}{\lambda} - 0\right|  \frac{\left|\frac{1}{\lambda} - 1\right|}{1000} \implies \frac{1}{\lambda}  \frac{|1-\lambda|}{1000\lambda} \implies 1000  |1-\lambda|
$$
这个不等式的一个解是 $\lambda  1001$。我们选择满足条件的最小正整数 $\lambda=1002$。此时，特殊的起始点是 $x_0 = 1/1002$。

这个起始点 $x_0 = 1/1002 \approx 0.000998$ 距离根 $r_1=0$ 的距离仅为 $1/1002$，而距离根 $r_2=1$ 的距离为 $1001/1002$，前者比后者小了 1001 倍。然而，尽管 $x_0$ 几乎就“贴”在根 $r_1=0$ 上，牛顿法的第一步却精准地跳到了根 $r_2=1$。这个例子生动地揭示了[牛顿法](@entry_id:140116)行为的非局部性和非直观性。

### 失效模式四：性能退化与实际限制

即使[牛顿法](@entry_id:140116)确实收敛，其著名的二次收敛速度也并非总是能够保证。在某些情况下，其性能会显著下降，并且会受到计算硬件的根本限制。

#### 多[重根](@entry_id:151486)与[线性收敛](@entry_id:163614)

当方程的根 $r$ 是一个**多[重根](@entry_id:151486) (multiple root)** 时，[牛顿法](@entry_id:140116)的收敛速度会从二次退化为**线性 (linear)**。一个根 $r$ 的[重数](@entry_id:136466) (multiplicity) 为 $m1$ 是指 $f(r)=f'(r)=\dots=f^{(m-1)}(r)=0$，但 $f^{(m)}(r) \neq 0$。例如，对于 $f(x)=(x-r)^m$， $r$ 是一个 $m$ 重根。

在这种情况下，$f'(r)=0$，我们遇到了之前讨论过的导数为零的问题。然而，当 $x_k$ 接近 $r$ 时，$f(x_k)$ 和 $f'(x_k)$ 都以可控的方式趋于零。对 $f(x) \approx C(x-r)^m$ 进行分析可以表明，[牛顿法](@entry_id:140116)的迭代误差 $e_k = x_k-r$ 满足：
$$
e_{k+1} \approx \left(1 - \frac{1}{m}\right) e_k
$$
这是一个[线性收敛](@entry_id:163614)关系，收敛因子为 $(m-1)/m$。[重数](@entry_id:136466) $m$ 越大，收敛因子越接近 1，收敛就越慢。

#### [浮点运算](@entry_id:749454)的影响

多[重根](@entry_id:151486)的问题在有限精度的计算机上会被进一步放大 。当 $x$ 非常接近一个 $m$ [重根](@entry_id:151486) $r$ 时，$f(x)$ 和 $f'(x)$ 的值都非常小。在计算机中，这些值会受到**[浮点舍入](@entry_id:749455)误差 (floating-point round-off error)** 的影响。在计算[牛顿步长](@entry_id:177069) $f(x)/f'(x)$ 时，两个含有噪声的小数相除，会导致**灾难性抵消 (catastrophic cancellation)**，使得计算出的步长完全被噪声淹没。

例如，对于函数 $f(x) = (x-1.5)^3$，根 $r=1.5$ 的[重数](@entry_id:136466)为 3。在[双精度](@entry_id:636927)浮点数下，计算 $f(x)$ 的值会引入一个近似恒定的[绝对误差](@entry_id:139354)，比如 $\eta_f \approx 10^{-15}$。当真实的函数值 $|f(x)| = |x-1.5|^3$ 小于或等于这个噪声水平 $\eta_f$ 时，计算出的函数值基本上就是随机噪声，进一步的迭代将毫无意义。这个条件定义了根周围的一个“**数值停滞区 (zone of numerical stagnation)**”。该区域的半径 $\epsilon_{zone} = |x-r|$ 可以通过求解 $|f(x)| = \eta_f$ 来估计：
$$
\epsilon_{zone}^3 = \eta_f \implies \epsilon_{zone} = \eta_f^{1/3}
$$
如果 $\eta_f \approx 10^{-15}$，那么 $\epsilon_{zone} \approx (10^{-15})^{1/3} = 10^{-5}$。这意味着，无论我们进行多少次迭代，我们都无法期望解的精度能超过 $10^{-5}$。对于单根，这个停滞区要小得多（约为 $u/\alpha$ 其中 $u$ 是机器精度，$|\alpha|=|f'(r)|$），因此多[重根](@entry_id:151486)问题在实践中对可达精度构成了更严峻的挑战。

#### “黑箱”问题

最后，一个非常实际的限制是[牛顿法](@entry_id:140116)对函数导数的依赖。标准的[牛顿法](@entry_id:140116)要求我们能够提供一个计算 $f'(x)$ 的解析表达式或程序。然而，在许多工程和科学应用中，函数 $f(x)$ 可能是一个“**黑箱 (black-box)**” 。例如，它可能是一个复杂的遗留代码、一个商业仿真软件包或一个物理实验的输出。我们能做的只是输入一个 $x$，然后得到一个输出 $f(x)$，但我们无法得知其内部的数学公式，因此也无法直接计算其导数。

在这种情况下，标准的牛顿法是不可行的。尽管其他选项，如计算成本高、初始猜测敏感等，都是迭代方法普遍存在的问题，但无法获取导数是牛顿法在黑箱场景下遇到的一个**根本性障碍**。这个问题直接催生了所谓的**拟牛顿法 (Quasi-Newton methods)**，例如[割线法](@entry_id:147486) (Secant Method)，它们通过使用函数值的差分来近似导数，从而避免了直接计算 $f'(x)$ 的需要。

### 关于充分性与必要性的注记

本章详细介绍的种种陷阱可能会让人对牛顿法产生悲观看法。然而，重要的是要区分理论保证和实际表现。用于证明[牛顿法](@entry_id:140116)收敛的数学定理，如著名的[康托罗维奇定理](@entry_id:178213) (Kantorovich theorem)，通常会提出一系列严格的**充分条件 (sufficient conditions)**，例如要求导数是[利普希茨连续的](@entry_id:267396) (Lipschitz continuous)，并且初始点的残差足够小。

如果这些条件满足，收敛性（通常是二次的）就得到保证。但如果这些条件不满足，并不一定意味着方法会失败。它们不是**必要条件 (necessary conditions)**。

一个很好的例子是函数 $f(x) = x^{3/2}$ 在区间 $[0,1]$ 上的[求根问题](@entry_id:174994) 。该函数在 $x=0$ 处有一个根。它的导数 $f'(x) = \frac{3}{2}\sqrt{x}$ 在 $x=0$ 处等于 0，且在 $[0,1]$ 上不是[利普希茨连续的](@entry_id:267396)。因此，许多标准的收敛定理都不适用。然而，让我们看一下牛顿迭代会发生什么：
$$
x_{k+1} = x_k - \frac{x_k^{3/2}}{\frac{3}{2}x_k^{1/2}} = x_k - \frac{2}{3}x_k = \frac{1}{3}x_k
$$
对于任何在 $(0,1]$ 内的初始点 $x_0$，序列 $\lbrace x_k \rbrace$ 都会以 $\frac{1}{3}$ 的[公比](@entry_id:275383)[线性收敛](@entry_id:163614)到 0。尽管理论上的“警报”响了，但该方法依然可靠地找到了根。

这个例子提醒我们，虽然理解[牛顿法的陷阱](@entry_id:637266)对于成为一名合格的[数值分析](@entry_id:142637)师至关重要，但同样重要的是认识到理论的局限性，并认识到[牛顿法](@entry_id:140116)在更广泛场景下表现出的稳健性和有效性。对这些失效模式的深入理解，最终将引导我们更好地选择、应用和改进数值算法。