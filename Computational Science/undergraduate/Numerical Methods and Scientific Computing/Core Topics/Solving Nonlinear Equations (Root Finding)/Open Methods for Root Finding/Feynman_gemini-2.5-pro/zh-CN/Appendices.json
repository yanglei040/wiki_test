{
    "hands_on_practices": [
        {
            "introduction": "开放式求根方法不仅限于求解抽象的数学方程，它也是解决优化问题的强大工具。许多优化任务，例如寻找函数的最小值或最大值，都可以通过求解其导数为零的点来完成，这自然地将优化问题转化为了一个求根问题。 这项练习将引导你将一个几何问题——寻找抛物线上距离某一定点最近的点——转化为一个求根任务，并亲手实现牛顿法和割线法这两个基础的开放式算法来解决它。",
            "id": "3259979",
            "problem": "你需要编写一个完整、可运行的程序，通过将任务构建为一维求根问题并使用开放法求解，来计算抛物线 $y = x^2$ 上距离固定点 $P = (2, -\\tfrac{1}{2})$ 最近的点。推导的基本依据是平面上的欧几里得距离以及微积分中的一个事实：对于一个可微函数，如果满足适当的二阶条件，其局部最小值出现在导数为零的点。\n\n考虑曲线上一点到该固定点的欧几里得距离的平方。如果曲线上一点的坐标为 $(x, x^2)$，则其到点 $P$ 的平方距离为 $D(x) = (x - 2)^2 + (x^2 + \\tfrac{1}{2})^2$。为找到最近点，需要通过一阶导数检验来刻画驻点，从而最小化 $D(x)$。该最小值点必须满足 $\\dfrac{d}{dx}D(x) = 0$。此条件定义了一个关于 $x$ 的标量非线性方程，其唯一解对应于抛物线上距离点 $P$ 最近点的 $x$ 坐标。由于我们希望使用开放法，你必须同时使用牛顿法和割线法来求解此方程。你必须为牛顿法使用解析导数，而为割线法仅使用函数求值。\n\n你的程序必须实现以下组件：\n- 一个函数 $f(x)$，其值等于一阶导数 $\\dfrac{d}{dx}D(x)$。\n- 一个函数 $f'(x)$，其值等于 $f(x)$ 的导数，用于牛顿法。\n- 一个牛顿法的实现，该方法迭代 $x_{k+1} = x_k - \\dfrac{f(x_k)}{f'(x_k)}$ 直至收敛。\n- 一个割线法的实现，该方法迭代 $x_{k+1} = x_k - f(x_k)\\dfrac{x_k - x_{k-1}}{f(x_k) - f(x_{k-1})}$ 直至收敛。\n- 一个停止准则，当 $|x_{k+1} - x_k|  \\varepsilon$ 或 $|f(x_{k+1})|  \\varepsilon$ 之一成立时，或当迭代次数达到指定的最大值而仍未收敛时，终止迭代。\n\n对于每个收敛的根 $x^\\star$，报告最近点 $(x^\\star, (x^\\star)^2)$ 以及到点 $P$ 的欧几里得距离，即 $\\sqrt{(x^\\star - 2)^2 + ((x^\\star)^2 + \\tfrac{1}{2})^2}$。此处不涉及物理单位；所有量均为无量纲。\n\n使用以下参数值测试套件来检验你的实现。每个测试用例都指定了方法及其初始猜测参数，以及绝对容差和最大迭代次数：\n- 测试 $1$：牛顿法，初始猜测值 $x_0 = 0$，容差 $\\varepsilon = 10^{-12}$，最大迭代次数 $50$。\n- 测试 $2$：牛顿法，初始猜测值 $x_0 = 2$，容差 $\\varepsilon = 10^{-12}$，最大迭代次数 $50$。\n- 测试 $3$：割线法，初始猜测值 $x_0 = 0, x_1 = 1$，容差 $\\varepsilon = 10^{-12}$，最大迭代次数 $100$。\n- 测试 $4$：割线法，初始猜测值 $x_0 = -1, x_1 = 1$，容差 $\\varepsilon = 10^{-12}$，最大迭代次数 $100$。\n- 测试 $5$：牛顿法，初始猜测值 $x_0 = -5$，容差 $\\varepsilon = 10^{-12}$，最大迭代次数 $50$。\n\n最终输出格式要求：\n- 你的程序应生成单行输出，其中包含所有测试用例的有序结果列表。每个结果必须是列表 $[x^\\star, (x^\\star)^2, \\text{dist}]$，其中 $x^\\star$ 是近似的最小值点，$ (x^\\star)^2$ 是对应的 $y$ 坐标，$\\text{dist}$ 是到点 $P$ 的欧几里得距离。每个数字必须四舍五入到恰好 $12$ 位小数。\n- 最终输出必须是单行，格式为一个由方括号括起来的、包含五个三元组的逗号分隔列表，例如 $[[\\dots],[\\dots],[\\dots],[\\dots],[\\dots]]$。",
            "solution": "### 问题转化\n\n该问题要求找到抛物线 $y = x^2$ 上距离定点 $P = (2, -\\frac{1}{2})$ 最近的点。这是一个典型的优化问题，可以通过将其转化为求根问题来解决。\n\n首先，我们定义抛物线上任意一点 $(x, x^2)$ 到点 $P$ 的欧几里得距离的平方，记为 $D(x)$。最小化距离等价于最小化距离的平方，后者可以避免处理平方根，从而简化求导过程。\n$$ D(x) = (x - 2)^2 + (x^2 - (-\\frac{1}{2}))^2 = (x - 2)^2 + (x^2 + \\frac{1}{2})^2 $$\n\n根据微积分原理，函数 $D(x)$ 的最小值点（如果存在）必然是其临界点之一，即其一阶导数为零的点。因此，我们需要求解方程 $\\frac{d}{dx}D(x) = 0$。\n\n### 推导求根函数\n\n我们计算 $D(x)$ 的一阶导数，并将其设为我们的目标函数 $f(x)$：\n$$ f(x) = \\frac{d}{dx}D(x) = \\frac{d}{dx}\\left[(x - 2)^2 + (x^2 + \\frac{1}{2})^2\\right] $$\n使用链式法则，我们得到：\n$$ f(x) = 2(x - 2) \\cdot 1 + 2(x^2 + \\frac{1}{2}) \\cdot (2x) $$\n$$ f(x) = (2x - 4) + (4x^3 + 2x) $$\n$$ f(x) = 4x^3 + 4x - 4 $$\n因此，原始的优化问题被转化为了一个非线性方程的求根问题：求解 $4x^3 + 4x - 4 = 0$，或者等价地，求解 $x^3 + x - 1 = 0$。\n\n### 算法设计\n\n**1. 牛顿法**\n牛顿法需要目标函数 $f(x)$ 的一阶导数 $f'(x)$。\n$$ f'(x) = \\frac{d}{dx}(4x^3 + 4x - 4) = 12x^2 + 4 $$\n迭代公式为：\n$$ x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)} = x_k - \\frac{4x_k^3 + 4x_k - 4}{12x_k^2 + 4} $$\n为了验证该根确实对应于一个最小值，我们检查 $D(x)$ 的二阶导数，它恰好是 $f'(x)$：\n$$ D''(x) = f'(x) = 12x^2 + 4 $$\n由于对于任意实数 $x$，$12x^2 \\ge 0$，因此 $D''(x) \\ge 4$ 恒为正。这表明 $D(x)$ 是一个严格凸函数，它有唯一的全局最小值，该最小值对应于 $f(x)=0$ 的唯一实根。这保证了牛顿法将收敛到一个有效的解，并且由于 $f'(x)$ 始终远离零，算法是数值稳定的。\n\n**2. 割线法**\n割线法通过使用前两个迭代点的有限差分来近似导数，从而避免了显式计算 $f'(x)$。其迭代公式为：\n$$ x_{k+1} = x_k - f(x_k)\\frac{x_k - x_{k-1}}{f(x_k) - f(x_{k-1})} $$\n此方法需要两个初始猜测值 $x_0$ 和 $x_1$。\n\n**3. 实现**\n程序将实现这两个方法，并根据指定的测试用例运行。对于每个找到的根 $x^\\star$，程序将计算对应的 $y$ 坐标 $(x^\\star)^2$ 以及到点 $P$ 的欧几里得距离 $\\sqrt{D(x^\\star)}$，然后按照要求的格式输出结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the closest point on the parabola y = x^2 to a fixed point P\n    by solving a root-finding problem with Newton's and secant methods.\n    \"\"\"\n\n    # The function f(x) is the derivative of the squared distance function D(x).\n    # D(x) = (x - 2)^2 + (x^2 + 1/2)^2\n    # f(x) = D'(x) = 2(x - 2) + 2(x^2 + 1/2)(2x) = 4x^3 + 4x - 4\n    def f(x):\n        return 4 * x**3 + 4 * x - 4\n\n    # The derivative of f(x), required for Newton's method.\n    # f'(x) = 12x^2 + 4\n    def f_prime(x):\n        return 12 * x**2 + 4\n\n    def newton_method(x0, tol, max_iter):\n        \"\"\"\n        Implementation of Newton's method for root finding.\n        x_{k+1} = x_k - f(x_k) / f'(x_k)\n        \"\"\"\n        xk = float(x0)\n        for _ in range(max_iter):\n            fxk = f(xk)\n            f_prime_xk = f_prime(xk)\n            \n            # Avoid division by zero, although not possible for this specific f_prime(x)\n            if abs(f_prime_xk)  1e-15:\n                # This would indicate failure, but our f' is always >= 4.\n                return None  \n            \n            xk_plus_1 = xk - fxk / f_prime_xk\n            \n            # Stopping criteria: step size or residual is below tolerance\n            if abs(xk_plus_1 - xk)  tol or abs(f(xk_plus_1))  tol:\n                return xk_plus_1\n            \n            xk = xk_plus_1\n        \n        # Return the last computed value if max_iter is reached\n        return xk\n\n    def secant_method(x0, x1, tol, max_iter):\n        \"\"\"\n        Implementation of the secant method for root finding.\n        x_{k+1} = x_k - f(x_k) * (x_k - x_{k-1}) / (f(x_k) - f(x_{k-1}))\n        \"\"\"\n        xk_minus_1 = float(x0)\n        xk = float(x1)\n        fxk_minus_1 = f(xk_minus_1)\n\n        for _ in range(max_iter):\n            fxk = f(xk)\n            \n            denominator = fxk - fxk_minus_1\n            # Avoid division by zero. f(x) is monotonic, so this only happens\n            # if iterates are identical or due to precision loss.\n            if abs(denominator)  1e-15:\n                return xk\n\n            xk_plus_1 = xk - fxk * (xk - xk_minus_1) / denominator\n\n            # Stopping criteria: step size or residual is below tolerance\n            if abs(xk_plus_1 - xk)  tol or abs(f(xk_plus_1))  tol:\n                return xk_plus_1\n            \n            xk_minus_1 = xk\n            fxk_minus_1 = fxk\n            xk = xk_plus_1\n            \n        # Return the last computed value if max_iter is reached\n        return xk\n\n    # Test cases as defined in the problem statement.\n    # (method_name, [initial_guesses], tolerance, max_iterations)\n    test_cases = [\n        ('newton', [0], 1e-12, 50),\n        ('newton', [2], 1e-12, 50),\n        ('secant', [0, 1], 1e-12, 100),\n        ('secant', [-1, 1], 1e-12, 100),\n        ('newton', [-5], 1e-12, 50),\n    ]\n\n    all_results = []\n    fixed_point_p = (2.0, -0.5)\n\n    for case in test_cases:\n        method_name, initial_guesses, tol, max_iter = case\n        \n        root = None\n        if method_name == 'newton':\n            root = newton_method(initial_guesses[0], tol, max_iter)\n        elif method_name == 'secant':\n            root = secant_method(initial_guesses[0], initial_guesses[1], tol, max_iter)\n        \n        if root is not None:\n            x_star = root\n            y_star = x_star**2\n            \n            # Calculate Euclidean distance to P\n            distance = np.sqrt((x_star - fixed_point_p[0])**2 + (y_star - fixed_point_p[1])**2)\n            \n            # Format results to 12 decimal places as strings\n            result_str = f\"[{x_star:.12f},{y_star:.12f},{distance:.12f}]\"\n            all_results.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "虽然牛顿法因其二次收敛速度而备受青睐，但其主要弱点在于对初始猜测值非常敏感，可能导致迭代发散。为了克服这一缺陷，我们可以将开放式方法的快速收敛性与区间法的可靠性相结合，构建所谓的“安全”或“混合”算法。 这项练习将教授你一项构建稳健数值求解器的关键技术，通过实现一个在牛顿步越出已知区间时智能切换到二分法的混合方法，从而确保算法的收敛性。",
            "id": "3260144",
            "problem": "您需要设计并实现一个程序，使用一种带安全保障的开放方法来计算简单实根的近似值。您的方法必须将牛顿法与二分法相结合，当牛顿法试探步超出限定区间，或当导数的大小过小而无法定义稳定的牛顿步时，切换到二分法。推导必须从一阶泰勒近似开始，然后导出迭代更新规则；代码必须反映这一原则。该方法必须在每次迭代中保持限定区间的不变性。\n\n假设以下基本事实：\n- 如果函数 $f$ 在区间 $[a,b]$ 上连续，且 $f(a)f(b) \\le 0$，则在 $[a,b]$ 中至少存在一个 $x^{\\ast}$ 使得 $f(x^{\\ast})=0$。\n- 可微函数 $f$ 在点 $x_k$ 附近的一阶泰勒近似为 $f(x_k+s) \\approx f(x_k)+f^{\\prime}(x_k)s$。\n\n您的任务：\n- 从一阶泰勒近似出发，推导出一个试图使下一步的残差为零的迭代过程，从而产生一个牛顿试探点。您的方法必须使用限定区间信息作为安全保障：如果牛顿试探点超出了 $[a_k,b_k]$，或者导数的绝对值低于指定的安全阈值，则改用二分法步长。\n- 在每次迭代中，通过根据在接受的下一个迭代点上计算的 $f$ 的符号来更新区间端点，以维持一个有效的限定区间 $[a_k,b_k]$。如果在任何时候 $f(a_k)=0$ 或 $f(b_k)=0$，则相应的端点就是一个根，必须立即返回。\n- 在您的实现中使用以下参数值：\n  - 函数容差 $\\varepsilon_f = 10^{-10}$，\n  - 区间半宽度容差 $\\varepsilon_x = 10^{-10}$，\n  - 最大迭代次数 $N_{\\max}=100$，\n  - 导数安全阈值 $\\delta = 10^{-14}$。\n- 使用初始迭代点 $x_0=(a_0+b_0)/2$。\n- 停止准则：一旦满足以下任一条件，立即停止并返回当前近似值 $x_k$：\n  - $|f(x_k)| \\le \\varepsilon_f$，\n  - $\\tfrac{1}{2}(b_k-a_k) \\le \\varepsilon_x$，\n  - $k \\ge N_{\\max}$， 在这种情况下返回当前区间的中点 $\\tfrac{a_k+b_k}{2}$。\n\n实现合约：\n- 实现一个函数，该函数应用上述混合规则，为给定的函数 $f$、其导数 $f^{\\prime}$ 和初始限定区间 $[a_0,b_0]$ 计算一个单根。\n- 当牛顿试探点位于 $[a_k,b_k]$ 之外或 $|f^{\\prime}(x_k)|  \\delta$ 时，必须拒绝牛顿试探并代之以二分法步长。\n\n测试套件：\n计算以下六种情况的根的近似值。三角函数的角度必须以弧度为单位进行解释。\n- 情况 1：$f_1(x)=\\cos(x)-x$，区间为 $[0,1]$。\n- 情况 2：$f_2(x)=x^3-x-2$，区间为 $[1,2]$。\n- 情况 3：$f_3(x)=e^x-3x^2$，区间为 $[0,1]$。\n- 情况 4：$f_4(x)=(x-0.1)^3$，区间为 $[0,1]$。\n- 情况 5：$f_5(x)=x^3-2x+2$，区间为 $[-2,0]$。\n- 情况 6：$f_6(x)=\\sin(x)$，区间为 $[0,4]$。\n\n输出规格：\n- 您的程序必须生成单行输出，其中包含按上述情况顺序排列的六个计算出的根，格式为一个用方括号括起来、由逗号分隔的浮点数列表，不含空格。\n- 每个测试用例的输出类型为浮点数。不涉及物理单位。角度以弧度为单位。",
            "solution": "该问题要求设计并实现一种带安全保障的求根算法。该算法结合了牛顿法的快速收敛性和二分法的保证收敛性。二分法作为一种安全保障，确保迭代点始终位于包含根的有效限定区间内，并保证即使在导数接近于零时算法也能保持稳定。\n\n### 原理与推导\n\n基本目标是找到函数 $f(x)$ 的一个根 $x^{\\ast}$，即满足 $f(x^{\\ast}) = 0$ 的值。该方法假设给定一个初始区间 $[a_0, b_0]$，函数在该区间上连续且满足 $f(a_0)f(b_0) \\le 0$。根据介值定理，该区间内保证至少存在一个根。\n\n**1. 牛顿法试探步**\n\n牛顿法是一种开放方法，它在当前迭代点处用函数的切线来近似函数。下一个迭代点被选为该切线的根。这可以从函数 $f(x)$ 在点 $x_k$ 附近的一阶泰勒级数展开式推导得出：\n$$f(x) \\approx f(x_k) + f'(x_k)(x - x_k)$$\n我们寻求下一个迭代点，记为 $x_{k+1}$，使得 $f(x_{k+1}) = 0$。将 $x = x_{k+1}$ 代入并将近似值设为零，得到：\n$$0 \\approx f(x_k) + f'(x_k)(x_{k+1} - x_k)$$\n假设导数 $f'(x_k)$ 非零，我们可以解出 $x_{k+1}$：\n$$f'(x_k)(x_{k+1} - x_k) = -f(x_k)$$\n$$x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}$$\n这就是牛顿法的迭代公式。当初始猜测足够接近单根时，它通常表现出二次收敛性。然而，如果初始猜测不佳，或者当导数 $f'(x_k)$ 接近或等于零时，该方法可能会发散、收敛缓慢或失败。\n\n**2. 二分法安全保障**\n\n二分法是一种区间限定法，其收敛速度较慢（线性收敛），但保证收敛。给定一个满足 $f(a_k)f(b_k) \\le 0$ 的限定区间 $[a_k, b_k]$，该方法提出将中点作为下一个测试点：\n$$x_{k+1} = \\frac{a_k + b_k}{2}$$\n然后，通过用 $x_{k+1}$ 替换 $a_k$ 或 $b_k$ 来更新限定区间，确保新的、更小的区间 $[a_{k+1}, b_{k+1}]$ 仍然包含一个根。这个过程系统地将不确定性区间减半。\n\n**3. 混合算法**\n\n所指定的算法利用了这两种方法的优点。在每次迭代 $k$ 中，从一个迭代点 $x_k$ 和一个限定区间 $[a_k, b_k]$ 开始：\n\n1.  提出一个牛顿步：$x_{N} = x_k - f(x_k)/f'(x_k)$。\n2.  对此步长进行两个安全保障条件的检查：\n    a.  **稳定性条件**：导数的绝对值必须足够大，即 $|f'(x_k)| \\ge \\delta$，其中 $\\delta$ 是一个小的正阈值（给定为 $10^{-14}$）。接近于零的导数可能导致牛顿步长异常大且数值不稳定。\n    b.  **区间限定条件**：牛顿试探点 $x_{N}$ 必须严格位于当前限定区间内部，即 $a_k  x_{N}  b_k$。这可以防止迭代点离开已知存在根的区域。\n3.  如果任一安全保障条件被违反，算法将拒绝牛顿步，并回退到稳健的二分步：$x_{k+1} = (a_k + b_k)/2$。\n4.  如果牛顿步被接受，则下一个迭代点为 $x_{k+1} = x_{N}$。\n5.  确定下一个迭代点 $x_{k+1}$ 后，更新限定区间。令 $f_a = f(a_k)$ 和 $f_{new} = f(x_{k+1})$。如果 $f_a \\cdot f_{new}  0$，则根在 $[a_k, x_{k+1}]$ 中，因此新区间变为 $[a_{k+1}, b_{k+1}] = [a_k, x_{k+1}]$。否则，根必定在 $[x_{k+1}, b_k]$ 中，新区间变为 $[a_{k+1}, b_{k+1}] = [x_{k+1}, b_k]$。这确保了区间限定不变性 $f(a_{k+1})f(b_{k+1}) \\le 0$ 得以维持。\n\n过程以 $x_0 = (a_0 + b_0)/2$ 开始，并持续进行，直到满足以下停止准则之一：\n-   函数值足够接近于零：$|f(x_k)| \\le \\varepsilon_f$。\n-   不确定性区间足够小：$\\frac{1}{2}(b_k - a_k) \\le \\varepsilon_x$。\n-   达到最大迭代次数 $N_{\\max}$。\n\n### 算法步骤\n\n该过程可以正式表述如下：\n\n1.  **初始化**：\n    -   给定函数 $f$、其导数 $f'$、初始区间 $[a, b]$ 以及参数 $\\varepsilon_f=10^{-10}$、$\\varepsilon_x=10^{-10}$、$\\delta=10^{-14}$、$N_{\\max}=100$。\n    -   设置 $a_k \\leftarrow a$, $b_k \\leftarrow b$。计算 $f(a_k)$ 和 $f(b_k)$。\n    -   检查初始条件：如果 $f(a_k) \\cdot f(b_k) > 0$，则初始区间无效。如果 $f(a_k)=0$ 或 $f(b_k)=0$，则返回相应的端点。\n    -   设置初始迭代点 $x_k \\leftarrow (a_k + b_k)/2$。\n\n2.  **迭代**：对于 $k = 0, 1, 2, \\ldots, N_{\\max}-1$：\n    a.  **检查停止准则**：计算 $f(x_k)$。如果 $|f(x_k)| \\le \\varepsilon_f$ 或 $(b_k - a_k)/2 \\le \\varepsilon_x$，则终止并返回当前迭代点 $x_k$。\n    b.  **提出下一个迭代点**：\n        i.  计算 $f'(x_k)$。\n        ii. 如果 $|f'(x_k)|  \\delta$，则设置下一个迭代点 $x_{next} \\leftarrow (a_k + b_k)/2$。\n        iii. 否则，计算牛顿迭代点 $x_{N} \\leftarrow x_k - f(x_k)/f'(x_k)$。如果 $a_k  x_{N}  b_k$，则设置 $x_{next} \\leftarrow x_{N}$。否则，设置 $x_{next} \\leftarrow (a_k + b_k)/2$。\n    c.  **更新区间和迭代点**：\n        i.  计算 $f(x_{next})$。如果 $f(x_{next})=0$，则返回 $x_{next}$。\n        ii. 如果 $f(a_k) \\cdot f(x_{next})  0$，则设置 $b_k \\leftarrow x_{next}$。否则，设置 $a_k \\leftarrow x_{next}$（并更新相应的缓存函数值）。\n        iii. 为下一次迭代设置 $x_k \\leftarrow x_{next}$。\n\n3.  **终止**：如果循环完成仍未满足停止准则，则返回最终区间的中点 $(a_k + b_k)/2$ 作为可用的最佳近似值。\n\n这种结构化、带安全保障的方法确保了效率和稳健性，使其成为一种寻找可微函数实根的可靠方法。",
            "answer": "```python\nimport numpy as np\n\ndef find_root_safeguarded(f, fp, a, b, eps_f, eps_x, delta, n_max):\n    \"\"\"\n    Computes a root of f(x)=0 within the interval [a, b] using a safeguarded\n    Newton's method.\n\n    The method combines Newton's method with bisection as a fallback.\n    \"\"\"\n    ak, bk = float(a), float(b)\n    fak, fbk = f(ak), f(bk)\n\n    # Initial validation and endpoint checks\n    if fak * fbk > 0.0:\n        # According to the problem statement, all initial brackets are valid.\n        # This is for robustness in a general context.\n        raise ValueError(\"Root not bracketed or multiple roots in initial interval.\")\n    \n    if fak == 0.0:\n        return ak\n    if fbk == 0.0:\n        return bk\n\n    # Per problem statement: \"Use the initial iterate x_0=(a_0+b_0)/2\"\n    xk = (ak + bk) / 2.0\n    \n    for _ in range(n_max):\n        # 1. Check stopping criteria at the beginning of the iteration\n        fxk = f(xk)\n        if abs(fxk) = eps_f:\n            return xk\n        \n        # The problem asks to return xk if interval is small, which is the\n        # point from the previous iteration.\n        if (bk - ak) / 2.0 = eps_x:\n            return xk\n\n        # 2. Propose the next iterate, x_next\n        fpxk = fp(xk)\n        \n        # Default to bisection step (safeguard)\n        x_bisection = (ak + bk) / 2.0\n        \n        # Decide whether to use the Newton step\n        if abs(fpxk) >= delta:\n            x_newton = xk - fxk / fpxk\n            # Check if Newton step is safely within the bracket\n            if ak  x_newton  bk:\n                x_next = x_newton\n            else:\n                x_next = x_bisection # Fallback to bisection\n        else:\n            x_next = x_bisection # Fallback to bisection\n            \n        # 3. Update the bracket [ak, bk] using the new point x_next\n        fx_next = f(x_next)\n        \n        # Check for an exact root hit\n        if fx_next == 0.0:\n            return x_next\n\n        # Update the bracket while maintaining the invariant f(a)*f(b)  0\n        if fak * fx_next  0.0:\n            bk, fbk = x_next, fx_next\n        else:\n            ak, fak = x_next, fx_next\n        \n        # 4. The new point becomes the iterate for the next loop\n        xk = x_next\n\n    # 5. If max iterations reached, return the midpoint of the final bracket\n    return (ak + bk) / 2.0\n\ndef solve():\n    \"\"\"\n    Solves the root-finding problem for the specified test suite.\n    \"\"\"\n    # Define parameters from the problem statement\n    params = {\n        'eps_f': 1e-10,\n        'eps_x': 1e-10,\n        'n_max': 100,\n        'delta': 1e-14\n    }\n\n    # Define the test cases\n    test_cases = [\n        # Case 1: f(x) = cos(x) - x on [0, 1]\n        (lambda x: np.cos(x) - x, lambda x: -np.sin(x) - 1, 0.0, 1.0),\n        # Case 2: f(x) = x^3 - x - 2 on [1, 2]\n        (lambda x: x**3 - x - 2, lambda x: 3*x**2 - 1, 1.0, 2.0),\n        # Case 3: f(x) = e^x - 3x^2 on [0, 1]\n        (lambda x: np.exp(x) - 3*x**2, lambda x: np.exp(x) - 6*x, 0.0, 1.0),\n        # Case 4: f(x) = (x - 0.1)^3 on [0, 1]\n        (lambda x: (x - 0.1)**3, lambda x: 3*(x - 0.1)**2, 0.0, 1.0),\n        # Case 5: f(x) = x^3 - 2x + 2 on [-2, 0]\n        (lambda x: x**3 - 2*x + 2, lambda x: 3*x**2 - 2, -2.0, 0.0),\n        # Case 6: f(x) = sin(x) on [0, 4]\n        (lambda x: np.sin(x), lambda x: np.cos(x), 0.0, 4.0),\n    ]\n\n    results = []\n    for f, fp, a, b in test_cases:\n        root = find_root_safeguarded(f, fp, a, b, **params)\n        results.append(root)\n\n    # Print the results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "在掌握了处理实数域上根的基本方法后，我们将视野拓宽到更广阔的复数平面，并探索更高阶的逼近策略。穆勒方法（Müller's method）便是一个典型的例子，它使用二次插值（抛物线）而非线性插值（直线）来逼近函数的根，这通常能带来更快的收敛速度，并且该方法能够自然地搜寻复数根。 在这项练习中，你将挑战实现这一更复杂的算法，并用它来求解复平面中的单位根，这是在物理和工程领域中常见的任务。",
            "id": "2422736",
            "problem": "考虑定义在复数域上的复值函数 $f(z) = z^4 + 1$。根是满足 $f(z) = 0$ 的任意复数 $z$。您的任务是编写一个完整的、可运行的程序。对于每组提供的三个不同的初始复数猜测值 $(z_0, z_1, z_2)$，该程序使用一种开放的、无区间限定的求根方法，并允许复数值迭代，以收敛到 $f(z) = 0$ 的一个根。对于数值终止条件，使用 $z$ 的更新量的绝对步长容差 $10^{-12}$ 和 $|f(z)|$ 的绝对函数值容差 $10^{-12}$，每种情况最多迭代 $100$ 次。所有计算都是无量纲的。如果内部出现任何角度，必须以弧度处理。\n\n初始猜测值的测试套件（每种情况都是一个复数的有序三元组 $(z_0, z_1, z_2)$）：\n- 情况 $1$：$(0.4 + 0.6 i,\\; 0.9 + 1.1 i,\\; 0.7 + 0.5 i)$\n- 情况 $2$：$(-1.2 + 1.0 i,\\; -0.6 + 0.8 i,\\; -0.9 + 0.7 i)$\n- 情况 $3$：$(-0.9 - 1.1 i,\\; -0.6 - 0.5 i,\\; -0.8 - 0.7 i)$\n- 情况 $4$：$(1.0 - 1.0 i,\\; 0.6 - 0.8 i,\\; 0.9 - 0.6 i)$\n- 情况 $5$（接近实轴的边界情况）：$(0.1 + 10^{-12} i,\\; 0.5 + 10^{-12} i,\\; 0.9 + 10^{-12} i)$\n\n对于每种情况，您的程序必须计算出该方法收敛到的一个根，并报告其实部和虚部。最终所需的输出是包含一个长度为 5 的列表的单行，其中每个元素是一个双元素列表 $[x,y]$，$x$ 是计算出的根的实部，$y$ 是其虚部。将每个 $x$ 和 $y$ 四舍五入到小数点后 10 位。因此，最后一行必须是\n$[[x_1,y_1],[x_2,y_2],[x_3,y_3],[x_4,y_4],[x_5,y_5]]$\n的形式，不含多余空格和额外文本。所有数字都必须报告为四舍五入到小数点后 10 位的普通实值浮点数。",
            "solution": "该问题要求使用一种开放式求根方法求解复数多项式的根。该方法使用三个初始点，这强烈地指向穆勒方法（Müller's method），它是割线法向二次插值的推广。\n\n### 原理与方法\n\n穆勒方法通过使用三个点来构造一个抛物线（二次多项式），以此来局部近似目标函数 $f(z)$。然后，该抛物线的一个根被选为下一个近似值。这种二次近似通常能提供比割线法（线性插值）更快的收敛速度（收敛阶约为1.84），并且能够自然地处理复数根。\n\n设在第 $k$ 次迭代时，我们有三个最近的根的近似值：$z_{k-2}$、$z_{k-1}$ 和 $z_k$。穆勒方法的核心是用一个二次多项式 $P(z)$ 来拟合函数，该多项式穿过这三个点 $(z_{k-2}, f(z_{k-2}))$、$(z_{k-1}, f(z_{k-1}))$ 和 $(z_k, f(z_k))$。一种数值上稳健的表示方法是牛顿形式的插值多项式，以最新点 $z_k$ 为中心：\n$$ P(z) = a(z - z_k)^2 + b(z - z_k) + c $$\n其中系数 $a$、$b$、$c$ 可以通过均差（divided differences）来计算：\n- $c = f(z_k)$\n- $b = f[z_{k-1}, z_k] + (z_k - z_{k-1}) f[z_{k-2}, z_{k-1}, z_k]$\n- $a = f[z_{k-2}, z_{k-1}, z_k]$\n\n这里 $f[z_i, z_j] = \\frac{f(z_j) - f(z_i)}{z_j - z_i}$ 是一阶均差，而 $f[z_{k-2}, z_{k-1}, z_k] = \\frac{f[z_{k-1}, z_k] - f[z_{k-2}, z_{k-1}]}{z_k - z_{k-2}}$ 是二阶均差。\n\n下一个迭代点 $z_{k+1}$ 是通过求解二次方程 $P(z) = 0$ 得到的。令 $\\Delta z = z_{k+1} - z_k$，我们需求解 $a(\\Delta z)^2 + b(\\Delta z) + c = 0$。为了避免在标准二次公式中因两个几乎相等的数相减而导致的精度损失，我们采用一种更稳健的变体形式：\n$$ \\Delta z = \\frac{-2c}{b \\pm \\sqrt{b^2 - 4ac}} $$\n分母中的符号 $(\\pm)$ 的选择原则是使其模最大化。对于复数运算，这意味着我们选择符号使得 $|b \\pm \\sqrt{b^2 - 4ac}|$ 的值最大。这个选择可以确保我们得到模最小的根 $\\Delta z$，从而引导迭代过程朝向离当前点 $z_k$ 最近的函数根。\n\n### 迭代过程\n\n1.  从三个初始猜测值 $z_0, z_1, z_2$ 开始。\n2.  在每次迭代中，使用当前的三个点计算均差和系数 $a, b, c$。\n3.  使用上述稳定化的二次公式计算更新步长 $\\Delta z$。\n4.  计算新的根的近似值 $z_{new} = z_2 + \\Delta z$。\n5.  检查收敛性：如果步长 $|\\Delta z|$ 和函数值 $|f(z_{new})|$ 都小于指定的容差 $10^{-12}$，则迭代成功并终止。\n6.  如果未收敛，则更新迭代点以准备下一次迭代：$z_0 \\leftarrow z_1$，$z_1 \\leftarrow z_2$，$z_2 \\leftarrow z_{new}$。\n7.  重复此过程，直到收敛或达到最大迭代次数。\n\n本问题的目标函数是 $f(z) = z^4 + 1$。其根是 $-1$ 的四次方根，可以解析地求出为 $z_k = e^{i(\\pi/4 + k\\pi/2)}$，其中 $k \\in \\{0, 1, 2, 3\\}$。这四个根分别是 $\\frac{1+i}{\\sqrt{2}}$, $\\frac{-1+i}{\\sqrt{2}}$, $\\frac{-1-i}{\\sqrt{2}}$, 和 $\\frac{1-i}{\\sqrt{2}}$。程序将对每个给定的初始猜测值集合应用穆勒方法，收敛到这四个根中的一个。",
            "answer": "```python\n# The complete and runnable Python 3 code for solving the root-finding problem.\n# This program uses Muller's method to find roots of f(z) = z^4 + 1.\n\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    It defines the function, test cases, and calls the root-finding algorithm,\n    then formats and prints the final result.\n    \"\"\"\n    \n    def f(z: complex) -> complex:\n        \"\"\"\n        The complex-valued function f(z) = z^4 + 1.\n        \"\"\"\n        return z**4 + 1\n\n    def muller(f_func, z0, z1, z2, tol=1e-12, max_iter=100):\n        \"\"\"\n        Implements Muller's method for finding a complex root.\n\n        Args:\n            f_func: The function for which to find a root.\n            z0, z1, z2: Three initial distinct complex guesses.\n            tol: The tolerance for termination.\n            max_iter: The maximum number of iterations.\n\n        Returns:\n            The complex root found, or the last estimate if max_iter is reached.\n        \"\"\"\n        p = [z0, z1, z2]\n        \n        for _ in range(max_iter):\n            p0, p1, p2 = p[0], p[1], p[2]\n            f0, f1, f2 = f_func(p0), f_func(p1), f_func(p2)\n\n            # To avoid division by zero in degenerate cases.\n            eps = np.finfo(complex).eps\n            if abs(p1 - p0)  eps or abs(p2 - p1)  eps or abs(p2 - p0)  eps:\n                return p2\n\n            # Coefficients of the interpolating parabola using divided differences.\n            # Polynomial P(z) = a(z - p2)^2 + b(z - p2) + c\n            d1 = (f1 - f0) / (p1 - p0)\n            d2 = (f2 - f1) / (p2 - p1)\n            \n            # Coefficient 'a'\n            a = (d2 - d1) / (p2 - p0)\n            \n            # Coefficient 'b'\n            b = d2 + (p2 - p1) * a\n            \n            # Coefficient 'c'\n            c = f2\n            \n            # Calculate the update step using the numerically stable formula.\n            discriminant = np.sqrt(b**2 - 4*a*c)\n            \n            # Choose the denominator with the largest magnitude.\n            den_plus = b + discriminant\n            den_minus = b - discriminant\n            \n            if abs(den_plus) > abs(den_minus):\n                denominator = den_plus\n            else:\n                denominator = den_minus\n            \n            # If denominator is too small, we might be at a root or stagnating.\n            if abs(denominator)  eps:\n                return p2\n\n            dz = -2 * c / denominator\n            p_new = p2 + dz\n            \n            # Termination criteria: step-size AND function-value tolerances met.\n            if abs(dz)  tol and abs(f_func(p_new))  tol:\n                return p_new\n\n            # Update points for the next iteration.\n            p = [p1, p2, p_new]\n            \n        return p[2]\n\n    # Test suite of initial guesses as specified in the problem statement.\n    test_cases = [\n        (0.4 + 0.6j, 0.9 + 1.1j, 0.7 + 0.5j),\n        (-1.2 + 1.0j, -0.6 + 0.8j, -0.9 + 0.7j),\n        (-0.9 - 1.1j, -0.6 - 0.5j, -0.8 - 0.7j),\n        (1.0 - 1.0j, 0.6 - 0.8j, 0.9 - 0.6j),\n        (0.1 + 1e-12j, 0.5 + 1e-12j, 0.9 + 1e-12j),\n    ]\n\n    results = []\n    for case in test_cases:\n        z0, z1, z2 = case\n        root = muller(f, z0, z1, z2)\n        \n        # Round the real and imaginary parts to 10 decimal places.\n        x = round(root.real, 10)\n        y = round(root.imag, 10)\n        \n        # Ensure -0.0 is represented as 0.0\n        if x == -0.0: x = 0.0\n        if y == -0.0: y = 0.0\n            \n        formatted_root = [x, y]\n        results.append(formatted_root)\n\n    # Convert the list of results to a string and remove spaces for exact output format.\n    final_output_string = str(results).replace(\" \", \"\")\n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}