{
    "hands_on_practices": [
        {
            "introduction": "方程 $x = \\cos(x)$ 是一个经典的超越方程，无法通过代数方法求得解析解。不动点迭代为此类问题提供了一种简洁而优雅的数值求解途径。本练习将引导你使用压缩映射定理来证明迭代的收敛性，并亲手实现算法，从而将理论分析与编程实践紧密结合起来。",
            "id": "3231288",
            "problem": "考虑不动点方程 $x=\\cos x$ 及其在闭区间 $[0,1]$ 上定义的不动点迭代 $x_{k+1}=\\cos x_k$。使用以下基本依据：对于函数 $g$，满足 $x^\\star=g(x^\\star)$ 的不动点 $x^\\star$ 的定义、中值定理 (MVT) 和压缩映射定理 (CMT)（也称为巴拿赫不动点定理）。迭代过程中的角度单位为弧度。你的程序必须实现该迭代，并针对指定的测试套件验证其收敛性和单调性。\n\n任务：\n- 从基本定义出发，论证为何函数 $g(x)=\\cos x$ 将区间 $[0,1]$ 映射到其自身。使用导数 $g'(x)=-\\sin x$ 和界 $\\sup_{x\\in[0,1]}|\\sin x|=\\sin(1)$（其中 $\\sin(1)1$），论证 $g$ 是 $[0,1]$ 上的一个压缩映射，因此存在唯一的属于 $[0,1]$ 的不动点 $x^\\star$，并且对于任意的 $x_0\\in[0,1]$，序列 $\\{x_k\\}$ 都收敛于 $x^\\star$。\n- 分析迭代值的单调行为。由于 $g$ 在 $[0,1]$ 上是严格递减的，因此整个序列 $\\{x_k\\}$ 通常不是单调的。但是，请证明偶数子序列 $\\{x_{2k}\\}$ 和奇数子序列 $\\{x_{2k+1}\\}$ 各自是单调的，并且收敛到相同的极限 $x^\\star$。\n- 实现一个程序，对于所提供测试套件中的每个初始值 $x_0$，执行不动点迭代 $x_{k+1}=\\cos x_k$，直到相邻迭代值之差满足 $|x_{k+1}-x_k|10^{-12}$ 或达到最多 $1000$ 次迭代。为每个测试用例存储完整的迭代序列。角度单位必须是弧度。\n- 对每个测试用例，计算并报告：\n  1. 初始值 $x_0$。\n  2. 停止迭代后不动点的最终近似值，记为 $x_{\\text{approx}}$。\n  3. 执行的迭代次数 $N$。\n  4. 一个布尔值，指示完整序列 $\\{x_k\\}_{k=0}^N$ 是否是单调的（非递减或非递增）。\n  5. 一个布尔值，指示偶数索引子序列 $\\{x_{2k}\\}$ 是否是单调的（非递减或非递增）。\n  6. 一个布尔值，指示奇数索引子序列 $\\{x_{2k+1}\\}$ 是否是单调的（非递减或非递增）。\n- 使用以下初始值测试套件（均为弧度）：$x_0\\in\\{0,\\,\\tfrac{1}{2},\\,1,\\,0.7390851332151607\\}$。最后一个值是唯一不动点 $x^\\star$ 的一个高精度近似值。\n- 最终输出格式：你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表。每个测试用例的结果本身必须是一个列表，其确切形式为 $[x_0,x_{\\text{approx}},N,\\text{is\\_monotone\\_full},\\text{is\\_monotone\\_even},\\text{is\\_monotone\\_odd}]$。例如，总体输出将类似于 $[[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot]]$，其中四个内部列表对应于四个测试用例。\n\n上述所有数值在你的程序中都必须作为标量处理。程序不得读取任何输入，并且必须打印所需的单行作为其唯一输出。",
            "solution": "我们首先回顾基本定义和事实。函数 $g$ 的一个不动点是满足 $x^\\star=g(x^\\star)$ 的值 $x^\\star$。数值不动点迭代通过 $x_{k+1}=g(x_k)$ 构建一个序列 $\\{x_k\\}$，并寻求一个极限 $x^\\star$，使得 $x_k\\to x^\\star$ 且 $x^\\star=g(x^\\star)$。压缩映射定理 (CMT) 指出，如果 $g$ 将一个完备度量空间映射到其自身，并且对于定义域中的所有 $x,y$ 和某个常数 $L1$，满足利普希茨界 $|g(x)-g(y)|\\le L|x-y|$，那么 $g$ 有一个唯一的不动点 $x^\\star$，并且对于定义域中的任何初始值 $x_0$，迭代 $x_{k+1}=g(x_k)$ 都收敛于 $x^\\star$。\n\n我们在闭区间 $[0,1]$ 上分析 $g(x)=\\cos x$。首先，我们证明 $g$ 将 $[0,1]$ 映射到其自身。对于 $x\\in[0,1]$，我们有 $\\cos x\\in[\\cos 1,\\,\\cos 0]=[\\cos 1,\\,1]$。由于 $\\cos 10$，因此 $g([0,1])\\subset[0,1]$。接下来，我们计算导数 $g'(x)=-\\sin x$。在 $[0,1]$ 上，函数 $\\sin x$ 是非负的，且上界为 $\\sin 1$，所以\n$$\n\\sup_{x\\in[0,1]}|g'(x)|=\\sup_{x\\in[0,1]}|\\sin x|=\\sin(1).\n$$\n由于 $\\sin(1)1$，我们可以使用中值定理 (MVT) 推导出利普希茨界：对于任意 $x,y\\in[0,1]$，存在某个位于 $x$ 和 $y$ 之间的 $\\xi$，使得\n$$\n|g(x)-g(y)|=|\\cos x-\\cos y|=|g'(\\xi)|\\,|x-y|\\le \\sin(1)\\,|x-y|,\n$$\n因此 $g$ 是在 $[0,1]$ 上的一个压缩映射，其压缩常数为 $L=\\sin(1)1$。根据压缩映射定理，存在一个唯一的不动点 $x^\\star\\in[0,1]$，并且对于任意 $x_0\\in[0,1]$，由 $x_{k+1}=\\cos x_k$ 定义的序列都收敛于 $x^\\star$。\n\n接下来我们分析单调行为。注意 $g$ 在 $[0,1]$ 上是严格递减的，因为 $g'(x)=-\\sin x\\le 0$，并且对于 $x\\in(0,1]$，我们有 $\\sin x0$。设 $x^\\star$ 是唯一不动点。考虑误差 $e_k=x_k-x^\\star$。使用中值定理，存在某个位于 $x_k$ 和 $x^\\star$ 之间的 $\\xi_k$，使得\n$$\ne_{k+1}=x_{k+1}-x^\\star=g(x_k)-g(x^\\star)=g'(\\xi_k)\\,(x_k-x^\\star)=-\\sin(\\xi_k)\\,e_k.\n$$\n在 $[0,1]$ 上，$\\sin(\\xi_k)\\in[0,\\sin(1)]$，并且只要 $\\sin(\\xi_k)0$，$e_{k+1}$ 的符号就与 $e_k$ 的符号相反。因此，除非 $e_k=0$，否则误差的符号会交替变化，所以整个序列 $\\{x_k\\}$ 通常是振荡的，而不是单调的。然而，我们可以推断出子序列的单调行为。因为 $g$ 是递减的，所以复合函数 $h(x) = g(g(x))$ 是递增的（因为两个递减函数的复合是递增的）。偶数子序列由 $x_{2(k+1)} = h(x_{2k})$ 生成，奇数子序列由 $x_{2k+3} = h(x_{2k+1})$ 生成。由递增函数迭代生成的序列总是单调的。因此，子序列 $\\{x_{2k}\\}$ 和 $\\{x_{2k+1}\\}$ 各自是单调的。由于已知整个序列 $\\{x_k\\}$ 收敛于 $x^\\star$，其任何子序列也必须收敛于同一个极限 $x^\\star$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef fixed_point_cos(x0, tol=1e-12, max_iter=1000):\n    \"\"\"\n    Perform fixed-point iteration x_{k+1} = cos(x_k) starting from x0.\n    Angles are in radians.\n    Returns:\n        x_approx: final approximation\n        iterations: number of iterations performed\n        seq: list of iterates including the initial value\n    \"\"\"\n    seq = [float(x0)]\n    x_prev = float(x0)\n    iterations = 0\n    for k in range(max_iter):\n        x_next = float(np.cos(x_prev))\n        seq.append(x_next)\n        iterations += 1\n        if abs(x_next - x_prev)  tol:\n            break\n        x_prev = x_next\n    return seq[-1], iterations, seq\n\ndef is_monotone(sequence, tol=0.0):\n    \"\"\"\n    Check if a sequence is monotone nondecreasing or monotone nonincreasing.\n    Equality is allowed.\n    tol can be used to soften comparisons, but defaults to strict.\n    \"\"\"\n    if len(sequence) = 1:\n        return True\n    diffs = [sequence[i+1] - sequence[i] for i in range(len(sequence)-1)]\n    nondecreasing = all(d >= -tol for d in diffs)\n    nonincreasing = all(d = tol for d in diffs)\n    return nondecreasing or nonincreasing\n\ndef solve():\n    # Define the test cases from the problem statement (radians).\n    test_cases = [\n        0.0,\n        0.5,\n        1.0,\n        0.7390851332151607,  # high-precision approximation to the fixed point\n    ]\n\n    results = []\n    for x0 in test_cases:\n        x_approx, iters, seq = fixed_point_cos(x0, tol=1e-12, max_iter=1000)\n        # Full sequence monotonicity\n        mono_full = is_monotone(seq, tol=0.0)\n        # Even-indexed subsequence: indices 0,2,4,...\n        even_seq = seq[0::2]\n        mono_even = is_monotone(even_seq, tol=0.0)\n        # Odd-indexed subsequence: indices 1,3,5,...\n        odd_seq = seq[1::2]\n        mono_odd = is_monotone(odd_seq, tol=0.0)\n        # Assemble result for this test case\n        results.append([x0, x_approx, iters, mono_full, mono_even, mono_odd])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "不动点迭代的收敛性并非总是理所当然的，它严格依赖于迭代函数 $g(x)$ 的性质，尤其是在不动点处的导数值。本练习将探讨一个“病态”案例，其中强大的牛顿法（当其被视为一种不动点迭代时）收敛失败。通过分析其失败的根本原因，你将更深刻地理解收敛条件 $|g'(x^*)| \\lt 1$ 的重要性，并认识到即使是强大的算法也存在其应用的边界。",
            "id": "3231260",
            "problem": "设函数 $f:\\mathbb{R}\\to\\mathbb{R}$ 定义为 $f(x)=\\operatorname{sign}(x)\\sqrt{|x|}$，其中，当 $x0$ 时 $\\operatorname{sign}(x)=-1$，当 $x=0$ 时 $\\operatorname{sign}(0)=0$，当 $x0$ 时 $\\operatorname{sign}(x)=1$。考虑应用牛顿法来近似求解 $x=0$ 处的根。仅使用牛顿法作为不动点迭代的基本定义，以及基于不动点处导数的不动点迭代的标准局部收敛准则。\n\n从牛顿法的定义出发，为该函数 $f$ 在 $\\mathbb{R}\\setminus\\{0\\}$ 上写出相关的不动点迭代式 $x_{k+1}=g(x_{k})$，并判断 $g$ 是否在 $x=0$ 处存在连续延拓。然后，利用 $g$ 在 $x=0$ 附近的导数以及不动点收敛定理（在其压缩形式下也称为巴拿赫不动点定理 (BFPT)），从第一性原理出发，推断该迭代是否预期会局部收敛到 $x=0$，以及是否可能实现二次收敛。\n\n对于由牛顿法生成的序列 $\\{x_{k}\\}$，其初始猜测值 $x_{0}\\neq 0$ 且足够接近 $0$，定义误差 $e_{k}=x_{k}-0=x_{k}$，并分析渐近比率 $\\lim_{k\\to\\infty}\\frac{|e_{k+1}|}{|e_{k}|}$，前提是该比率在轨道上是良定义的。你的最终答案必须是此极限的精确值，以单个实数形式给出。无需四舍五入。",
            "solution": "该问题要求分析对函数 $f(x) = \\operatorname{sign}(x)\\sqrt{|x|}$ 应用牛顿法以求得其在 $x=0$ 处的根。牛顿法通过递推关系 $x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}$ 生成一个序列 $\\{x_k\\}$。这是一个不动点迭代 $x_{k+1} = g(x_k)$，其迭代函数为 $g(x) = x - \\frac{f(x)}{f'(x)}$。\n\n首先，我们必须计算当 $x \\neq 0$ 时 $f(x)$ 的导数。该函数的定义为：\n$$\nf(x) =\n\\begin{cases}\n\\sqrt{x}   \\text{若 } x  0 \\\\\n0   \\text{若 } x = 0 \\\\\n-\\sqrt{-x}   \\text{若 } x  0\n\\end{cases}\n$$\n对于 $x0$，我们有 $f(x) = x^{1/2}$，因此导数为 $f'(x) = \\frac{1}{2}x^{-1/2} = \\frac{1}{2\\sqrt{x}}$。\n对于 $x0$，我们有 $f(x) = -(-x)^{1/2}$。使用链式法则，导数为 $f'(x) = -\\frac{1}{2}(-x)^{-1/2} \\cdot (-1) = \\frac{1}{2\\sqrt{-x}}$。\n在两种情况下，对于任意 $x \\in \\mathbb{R}\\setminus\\{0\\}$，导数可以紧凑地写为 $f'(x) = \\frac{1}{2\\sqrt{|x|}}$。\n注意 $f'(x)$ 在 $x=0$ 处未定义，因为 $\\lim_{x\\to 0} f'(x) = +\\infty$。\n\n现在，我们为 $x \\neq 0$ 构建不动点迭代函数 $g(x)$：\n$$g(x) = x - \\frac{f(x)}{f'(x)} = x - \\frac{\\operatorname{sign}(x)\\sqrt{|x|}}{\\frac{1}{2\\sqrt{|x|}}}$$\n化简该表达式，我们得到：\n$$g(x) = x - 2\\operatorname{sign}(x)(\\sqrt{|x|})^2 = x - 2\\operatorname{sign}(x)|x|$$\n项 $\\operatorname{sign}(x)|x|$ 对于所有 $x \\in \\mathbb{R}$ 都恒等于 $x$。因此，对于所有 $x \\neq 0$，迭代函数为：\n$$g(x) = x - 2x = -x$$\n\n问题询问 $g$ 是否在 $x=0$ 处存在连续延拓。函数 $g(x)=-x$ 对所有 $x \\in \\mathbb{R}$ 都有定义且连续。当 $x$ 趋近于 $0$ 时的极限是 $\\lim_{x\\to 0} g(x) = \\lim_{x\\to 0} (-x) = 0$。因此，通过定义 $g(0)=0$，可以将 $g(x)$ 连续延拓到 $x=0$。延拓后的函数就是对所有 $x \\in \\mathbb{R}$ 的 $g(x)=-x$。\n\n接下来，我们分析不动点迭代 $x_{k+1} = g(x_k) = -x_k$ 到不动点 $x^*=0$ 的局部收敛性。不动点收敛定理指出，如果 $g$ 在不动点 $x^*$ 的一个邻域内连续可微，并且 $|g'(x^*)|  1$，则迭代是局部收敛的。如果 $|g'(x^*)|  1$，则是局部发散的。如果 $|g'(x^*)|=1$，则该定理无定论。\n\n我们的迭代函数 $g(x)=-x$ 的导数是 $g'(x)=-1$，对所有 $x \\in \\mathbb{R}$ 成立。在不动点 $x^*=0$ 处，我们有：\n$$|g'(0)| = |-1| = 1$$\n由于在不动点处的导数的绝对值恰好为 $1$，标准的收敛准则无法给出结论。我们必须从第一性原理直接分析序列的行为。\n\n设初始猜测值为 $x_0 \\neq 0$。由迭代 $x_{k+1} = -x_k$ 生成的序列是：\n$x_1 = -x_0$\n$x_2 = -x_1 = -(-x_0) = x_0$\n$x_3 = -x_2 = -x_0$\n依此类推。该序列为 $\\{x_0, -x_0, x_0, -x_0, \\dots\\}$。这个序列在两个值之间振荡，并且对于任何 $x_0 \\neq 0$ 的选择，它都不会收敛到 $0$。因此，对于这个函数，牛顿法无法收敛到 $x=0$ 处的根。\n\n问题还问到是否可能实现二次收敛。对于一个不动点迭代 $x_{k+1}=g(x_k)$ 要二次收敛到一个不动点 $x^*$，一个必要条件是 $g'(x^*)=0$。在我们的例子中，$g'(0)=-1 \\neq 0$。因此，该迭代不可能是二次收敛的。事实上，如上所示，它根本不收敛。\n\n最后，我们被要求分析渐近比率 $\\lim_{k\\to\\infty}\\frac{|e_{k+1}|}{|e_{k}|}$，其中误差定义为 $e_k = x_k - 0 = x_k$。该比率为：\n$$\\frac{|e_{k+1}|}{|e_k|} = \\frac{|x_{k+1}|}{|x_k|}$$\n代入迭代规则 $x_{k+1}=-x_k$，我们得到：\n$$\\frac{|x_{k+1}|}{|x_k|} = \\frac{|-x_k|}{|x_k|} = \\frac{|x_k|}{|x_k|}$$\n对于任意初始猜测值 $x_0 \\neq 0$，序列 $\\{x_k\\}$ 永远不会达到 $0$。因此，对于所有 $k \\geq 0$，$x_k \\neq 0$，并且该比率是良定义的，且对所有 $k$ 都等于 $1$。\n$$\\frac{|e_{k+1}|}{|e_k|} = 1 \\quad \\text{对于所有 } k \\in \\{0, 1, 2, \\dots\\}$$\n这个常数序列的极限是：\n$$\\lim_{k\\to\\infty}\\frac{|e_{k+1}|}{|e_{k}|} = \\lim_{k\\to\\infty} 1 = 1$$\n这个结果，即极限误差比为 $1$，与误差不减小且方法不收敛的观察结果是一致的。",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "许多不动点迭代过程呈现线性收敛，但在实践中有时会显得效率不高，一个核心的数值计算问题是如何提升其效率。本练习将介绍艾特肯（Aitken） $\\Delta^2$ 加速法，这是一种用于加速线性收敛序列的通用且强大的技术。你将从第一性原理出发推导出该方法，并通过编程实现来直观地见证其带来的显著性能提升，进而掌握数值算法设计中的一个关键思想。",
            "id": "3231237",
            "problem": "给定一个由映射 $g(x) = \\dfrac{x + 2}{2}$ 和迭代规则 $x_{k+1} = g(x_k)$ 定义的不动点迭代。考虑满足 $x^\\star = g(x^\\star)$ 的唯一不动点 $x^\\star$。您需要从基本原理出发分析其收敛性，并实现一个使用 Aitken's delta-squared 方法来加速收敛的算法。\n\n任务 A (理论基础):\n1. 从不动点的定义和压缩映射原理出发，证明方程 $x = g(x)$ 有唯一解，并且不动点迭代 $x_{k+1} = g(x_k)$ 局部收敛到该解。使用 $g$ 的可微性以及条件 $\\lvert g'(x^\\star) \\rvert  1$ 作为局部线性收敛的核心判据。\n2. 通过求解代数方程 $x = g(x)$ 来确定精确的不动点 $x^\\star$。\n3. 使用线性收敛的定义，分析误差序列 $e_k = x_k - x^\\star$，并确定未加速的不动点迭代的渐近速率（线性收敛因子）。\n\n任务 B (加速算法设计):\n1. 从线性收敛序列的一般模型出发，根据序列 $\\{x_k\\}$ 的前向差分推导 Aitken's delta-squared 加速法。您的推导必须仅依赖于误差渐近表现为等比数列的假设以及前向差分的基本定义。不要假设或引用任何预先推导的闭式加速公式，而是从基本原理构建它。\n2. 设计一个鲁棒的算法，对于给定的起始值 $x_0$ 和容差 $\\text{tol}  0$，该算法使用基础迭代产生的连续三元组 $(x_k, x_{k+1}, x_{k+2})$ 来生成一个 Aitken 加速估计值。您的算法必须：\n   - 当当前近似值满足 $\\lvert x - x^\\star \\rvert \\le \\text{tol}$ 时，视为计算成功。\n   - 将计算成本计为 $g$ 的求值次数。\n   - 处理二阶前向差分为零或数值上与零无法区分的退化情况。通过检测此条件，并将其视为迭代已处于不动点或无法从该三元组可靠地形成 Aitken 更新的标志。在这种情况下，算法应要么终止（如果已在容差范围内），要么安全地继续进行额外的基础迭代以形成新的三元组。\n\n任务 C (编程与评估):\n1. 实现两个过程：\n   - 一个基础不动点迭代器，它返回从 $x_0$ 开始，为满足 $\\lvert x - x^\\star \\rvert \\le \\text{tol}$ 所需的最小 $g$ 求值次数。\n   - 一个 Aitken 加速过程，它从连续的基础迭代三元组中重复形成 Aitken 更新，并返回加速序列中首次达到 $\\lvert x - x^\\star \\rvert \\le \\text{tol}$ 所需的最小 $g$ 求值次数（计算用于生成所需迭代值的每一次 $g$ 求值）。\n2. 使用 $10^6$ 次 $g$ 求值的最大上限，以保证在病态情景下程序能够终止。\n3. 测试套件。在以下四个测试用例上运行这两个过程，每个测试用例是一个序对 $(x_0, \\text{tol})$：\n   - $(0.0, 10^{-8})$\n   - $(-100.0, 10^{-12})$\n   - $(2.0, 10^{-14})$\n   - $(10.0, 10^{-10})$\n4. 对于每个测试用例，计算并返回一个包含以下内容的三元组：\n   - 基础不动点迭代满足容差所需的 $g$ 求值次数（整数）。\n   - Aitken 加速过程首次满足容差所需的 $g$ 求值次数（整数）。\n   - 一个布尔值，指示 Aitken 加速过程使用的 $g$ 求值次数是否严格少于基础过程。\n5. 最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个元素是按上述顺序排列的测试用例三元组。例如，一个有效的输出格式如下：\n   - $[[n_{b,1},n_{a,1},\\text{flag}_1],[n_{b,2},n_{a,2},\\text{flag}_2],[n_{b,3},n_{a,3},\\text{flag}_3],[n_{b,4},n_{a,4},\\text{flag}_4]]$\n其中 $n_{b,i}$ 和 $n_{a,i}$ 是整数，$\\text{flag}_i$ 是布尔值。此任务不涉及物理单位。不适用角度。不使用百分比。",
            "solution": "问题陈述已经过分析，并被认为是有效的。这是一个数值分析中的适定问题，它有科学依据、内容自洽且客观。\n\n### 任务 A (理论基础)：唯一不动点与线性收敛\n\n1.  **存在性、唯一性与收敛性：**\n    不动点迭代由函数 $g(x) = \\dfrac{x + 2}{2}$ 定义。不动点 $x^\\star$ 满足方程 $x^\\star = g(x^\\star)$。\n    为了分析收敛性，我们应用压缩映射定理。该定理指出，如果一个函数 $g$ 将一个完备度量空间映射到其自身，并且是一个压缩映射，那么它拥有一个唯一的不动点，并且对于任何起始点 $x_0$，迭代 $x_{k+1} = g(x_k)$ 都收敛到这个不动点。\n    函数 $g(x)$ 定义在 $\\mathbb{R}$ 上，这是一个完备度量空间。为了检查 $g$ 是否为压缩映射，我们考察其导数：\n    $$\n    g'(x) = \\frac{d}{dx}\\left(\\frac{x}{2} + 1\\right) = \\frac{1}{2}\n    $$\n    $g(x)$ 的 Lipschitz 常数 $L$ 由 $L = \\sup_{x \\in \\mathbb{R}} |g'(x)|$ 给出。在本例中，$L = |\\frac{1}{2}| = \\frac{1}{2}$。\n    由于 $L = \\frac{1}{2}  1$，函数 $g(x)$ 在整个 $\\mathbb{R}$ 上都是一个压缩映射。因此，根据压缩映射定理，存在一个唯一的不动点 $x^\\star \\in \\mathbb{R}$，并且对于任何初始值 $x_0 \\in \\mathbb{R}$，迭代 $x_{k+1} = g(x_k)$ 都收敛到 $x^\\star$。\n    如果在不动点 $x^\\star$ 附近有 $|g'(x^\\star)|  1$，则局部收敛得到保证。正如我们所发现的，$|g'(x)| = \\frac{1}{2}$ 对所有 $x$（包括 $x^\\star$）都成立。因此，$|g'(x^\\star)| = \\frac{1}{2}  1$，这证明了该迭代是局部线性收敛的。\n\n2.  **确定不动点：**\n    不动点 $x^\\star$ 通过求解代数方程 $x = g(x)$ 得到：\n    $$\n    x = \\frac{x + 2}{2}\n    $$\n    $$\n    2x = x + 2\n    $$\n    $$\n    x = 2\n    $$\n    唯一的不动点是 $x^\\star = 2$。\n\n3.  **误差分析与收敛速率：**\n    第 $k$ 次迭代的误差定义为 $e_k = x_k - x^\\star$。下一步的误差是 $e_{k+1} = x_{k+1} - x^\\star$。代入迭代规则和不动点定义：\n    $$\n    e_{k+1} = g(x_k) - x^\\star = g(x_k) - g(x^\\star)\n    $$\n    根据中值定理，在 $x_k$ 和 $x^\\star$ 之间存在一个值 $\\xi_k$，使得 $g(x_k) - g(x^\\star) = g'(\\xi_k)(x_k - x^\\star)$。这导出了误差关系 $e_{k+1} = g'(\\xi_k)e_k$。\n    当 $k \\to \\infty$ 时，我们有 $x_k \\to x^\\star$，因此 $\\xi_k \\to x^\\star$。渐近误差关系为：\n    $$\n    \\lim_{k \\to \\infty} \\frac{|e_{k+1}|}{|e_k|} = |g'(x^\\star)|\n    $$\n    这证明了线性收敛。常数 $\\lambda = |g'(x^\\star)|$ 是渐近收敛速率。\n    对于给定的函数 $g(x)$，其导数 $g'(x) = \\frac{1}{2}$ 是一个常数。因此，该关系对所有 $k$ 都是精确的：\n    $$\n    e_{k+1} = g(x_k) - g(x^\\star) = \\left(\\frac{x_k+2}{2}\\right) - \\left(\\frac{x^\\star+2}{2}\\right) = \\frac{1}{2}(x_k - x^\\star) = \\frac{1}{2}e_k\n    $$\n    收敛速率是常数 $\\lambda = \\frac{1}{2}$，而不仅仅是渐近的。\n\n### 任务 B (加速算法设计)：Aitken's Delta-Squared 方法\n\n1.  **从基本原理推导：**\n    Aitken 方法加速已知线性收敛的序列 $\\{x_k\\}$ 的收敛速度。其基本假设是对于大的 $k$，误差 $e_k = x_k - x^\\star$ 的行为类似于一个等比数列。这意味着连续误差之比近似为一个常数：\n    $$\n    \\frac{e_{k+1}}{e_k} \\approx \\lambda \\quad \\implies \\quad x_{k+1} - x^\\star \\approx \\lambda(x_k - x^\\star)\n    $$\n    为了构造一个加速估计值，我们使用序列的三个连续项 $(x_k, x_{k+1}, x_{k+2})$。我们假设下一对也保持相同的比率：\n    $$\n    x_{k+1} - x^\\star \\approx \\lambda(x_k - x^\\star) \\quad (1)\n    $$\n    $$\n    x_{k+2} - x^\\star \\approx \\lambda(x_{k+1} - x^\\star) \\quad (2)\n    $$\n    我们可以通过消去 $\\lambda$ 来求解未知的极限 $x^\\star$。从 $(1)$ 和 $(2)$，我们有：\n    $$\n    \\frac{x_{k+1} - x^\\star}{x_k - x^\\star} \\approx \\lambda \\approx \\frac{x_{k+2} - x^\\star}{x_{k+1} - x^\\star}\n    $$\n    交叉相乘得到：\n    $$\n    (x_{k+1} - x^\\star)^2 \\approx (x_k - x^\\star)(x_{k+2} - x^\\star)\n    $$\n    展开各项：\n    $$\n    x_{k+1}^2 - 2x_{k+1}x^\\star + (x^\\star)^2 \\approx x_k x_{k+2} - x_k x^\\star - x_{k+2} x^\\star + (x^\\star)^2\n    $$\n    重新整理以求解 $x^\\star$：\n    $$\n    x_{k+1}^2 - x_k x_{k+2} \\approx (2x_{k+1} - x_k - x_{k+2})x^\\star\n    $$\n    $$\n    x^\\star \\approx \\frac{x_k x_{k+2} - x_{k+1}^2}{x_{k+2} - 2x_{k+1} + x_k}\n    $$\n    这个公式给出了不动点的一个改进估计。为了用前向差分表示它，我们定义 $\\Delta x_k = x_{k+1} - x_k$ 和二阶前向差分 $\\Delta^2 x_k = \\Delta(\\Delta x_k) = (x_{k+2} - x_{k+1}) - (x_{k+1} - x_k) = x_{k+2} - 2x_{k+1} + x_k$。\n    Aitken 加速估计值，记作 $\\hat{x}_k$，可以写成：\n    $$\n    \\hat{x}_k = x_k - \\frac{(\\Delta x_k)^2}{\\Delta^2 x_k} = x_k - \\frac{(x_{k+1} - x_k)^2}{x_{k+2} - 2x_{k+1} + x_k}\n    $$\n    这是标准的 Aitken's delta-squared 公式。对于本问题中特定的线性函数 $g(x)$，该比率是精确的，而不是近似的，这意味着该公式将从任何非平凡的迭代三元组中产生精确的不动点 $x^\\star$。\n\n2.  **算法设计：**\n    设计一个算法来计算一系列 Aitken 加速估计值。\n    -   **初始化**：给定 $x_0$ 和 `tol`，精确的不动点是 $x^\\star = 2.0$。$g$ 的求值次数是成本度量。\n    -   **迭代**：算法顺序生成基础迭代值 $x_{k+1} = g(x_k)$。在至少两次 $g$ 的求值后，我们得到一个可用于形成 Aitken 估计值的三元组 $(x_k, x_{k+1}, x_{k+2})$。\n    -   **Aitken 更新**：对于每个新生成的基础迭代值 $x_{k+2}$，形成一个新的三元组，并计算公式 $\\hat{x}_k = x_k - (\\Delta x_k)^2 / (\\Delta^2 x_k)$。\n    -   **收敛性检查**：在每次 Aitken 更新后，检查条件 $|\\hat{x}_k - x^\\star| \\le \\text{tol}$。如果满足条件，过程终止，并返回用于生成所需基础迭代值的 $g$ 求值总次数。\n    -   **退化情况处理**：$\\hat{x}_k$ 的公式涉及除以二阶差分 $\\Delta^2 x_k$。如果这个分母为零或数值上非常接近于零，更新就无法可靠地计算。这通常发生在序列已经收敛时（即 $x_k = x_{k+1} = x_{k+2}$）。算法必须检测到这种情况。如果 $\\Delta^2 x_k \\approx 0$，它会检查最后一个基础迭代值是否在容差范围内。如果不在，它会放弃对该三元组的 Aitken 更新，并继续生成更多的基础迭代值，直到 $\\Delta^2 x_k$ 再次变得不可忽略。\n\n### 任务 C (编程与评估)：实现与结果\n\n实现了两个过程：一个用于基础不动点迭代，另一个用于 Aitken 加速迭代。两个函数都计算获得满足 $|x - x^\\star| \\le \\text{tol}$ 的估计值 $x$ 所需的 $g(x)$ 的求值次数。\n\n-   **基础迭代器**：这是一个直接的循环。从 $x_0$ 开始，它重复应用 $x_{k+1} = g(x_k)$，并增加一个求值计数器，直到满足误差容差。\n-   **Aitken 迭代器**：此过程生成基础迭代值 $x_0, x_1, x_2, \\dots$。从第一个可用的三元组 $(x_0, x_1, x_2)$（需要 2 次 $g$ 的求值）开始，它计算一个 Aitken 估计值 $\\hat{x}_0$。如果 $\\hat{x}_0$ 未收敛，它会生成 $x_3$（总共 3 次求值），从 $(x_1, x_2, x_3)$ 形成一个新的 Aitken 估计值 $\\hat{x}_1$，依此类推，直到某个加速估计值满足容差。\n\n任务 B 中的分析预测，对于给定的线性函数 $g(x)$，从任何非平凡的起始点出发，第一个 Aitken 估计值将是精确的。这意味着只要 $x_0 \\neq x^\\star$，加速过程应该总是在 2 次 $g$ 的求值后终止。基础迭代的性能取决于初始误差和容差。\n\n测试套件的数值结果如下：\n1.  **$(x_0, \\text{tol}) = (0.0, 10^{-8})$**：基础迭代器需要 $28$ 次求值。Aitken 迭代器需要 $2$ 次。\n2.  **$(x_0, \\text{tol}) = (-100.0, 10^{-12})$**：基础迭代器需要 $47$ 次求值。Aitken 迭代器需要 $2$ 次。\n3.  **$(x_0, \\text{tol}) = (2.0, 10^{-14})$**：两个迭代器都从不动点开始，因此需要 $0$ 次求值。\n4.  **$(x_0, \\text{tol}) = (10.0, 10^{-10})$**：基础迭代器需要 $37$ 次求值。Aitken 迭代器需要 $2$ 次。\n\n在所有非平凡的情况下，Aitken 加速过程都严格更快，这证实了它对于线性收敛序列的有效性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the fixed-point iteration problem with base and Aitken-accelerated methods.\n    \"\"\"\n    \n    # The mapping function for the fixed-point iteration.\n    g = lambda x: (x + 2.0) / 2.0\n    \n    # The exact fixed point.\n    x_star = 2.0\n    \n    # Maximum number of evaluations to prevent infinite loops.\n    max_evals = 1000000\n    \n    # Epsilon for degeneracy check in Aitken's method.\n    degeneracy_eps = 1e-15\n\n    def base_iterator(x0, tol):\n        \"\"\"\n        Calculates the number of g evaluations for the base fixed-point method.\n        \"\"\"\n        x_k = float(x0)\n        \n        # Check if already converged at x0.\n        if abs(x_k - x_star) = tol:\n            return 0\n        \n        for num_evals in range(1, max_evals + 1):\n            x_k = g(x_k)\n            if abs(x_k - x_star) = tol:\n                return num_evals\n        \n        return max_evals\n\n    def aitken_iterator(x0, tol):\n        \"\"\"\n        Calculates the number of g evaluations for the Aitken-accelerated method.\n        \"\"\"\n        x_k = float(x0)\n\n        # Check if already converged at x0.\n        if abs(x_k - x_star) = tol:\n            return 0\n\n        x_seq = [x_k]\n\n        # Generate the first two points to form the first triplet.\n        # Eval 1:\n        x_k_plus_1 = g(x_seq[-1])\n        x_seq.append(x_k_plus_1)\n        num_evals = 1\n        # Aitken cannot be applied yet.\n\n        # Eval 2 and subsequent:\n        for num_evals in range(2, max_evals + 1):\n            x_k_plus_2 = g(x_seq[-1])\n            x_seq.append(x_k_plus_2)\n\n            # We have a triplet (x_k, x_{k+1}, x_{k+2})\n            # which are x_seq[-3], x_seq[-2], x_seq[-1]\n            xk, xk1, xk2 = x_seq[-3], x_seq[-2], x_seq[-1]\n            \n            delta_sq_x = xk2 - 2 * xk1 + xk\n\n            # Degeneracy check\n            if abs(delta_sq_x)  degeneracy_eps:\n                # This indicates convergence or numerical instability.\n                # Check if the last base iterate is converged.\n                if abs(xk2 - x_star) = tol:\n                    return num_evals\n                # Otherwise, continue generating base iterates as Aitken update is not reliable.\n                continue\n\n            delta_x = xk1 - xk\n            x_aitken = xk - (delta_x**2) / delta_sq_x\n            \n            if abs(x_aitken - x_star) = tol:\n                return num_evals\n        \n        return max_evals\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 1e-8),\n        (-100.0, 1e-12),\n        (2.0, 1e-14),\n        (10.0, 1e-10)\n    ]\n\n    results = []\n    for case in test_cases:\n        x0, tol = case\n        \n        base_evals = base_iterator(x0, tol)\n        aitken_evals = aitken_iterator(x0, tol)\n        \n        aitken_is_faster = aitken_evals  base_evals\n        \n        results.append([base_evals, aitken_evals, aitken_is_faster])\n\n    # Final print statement in the exact required format.\n    # The default string representation of a list in Python is used, as per the template.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}