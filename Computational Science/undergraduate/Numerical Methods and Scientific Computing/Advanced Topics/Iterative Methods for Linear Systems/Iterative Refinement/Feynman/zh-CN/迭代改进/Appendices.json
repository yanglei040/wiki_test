{
    "hands_on_practices": [
        {
            "introduction": "理论学习之后，最好的巩固方式莫过于亲手实践。本节的第一个练习将引导你完整地走一遍迭代求精的核心流程。通过一个简单的 $2 \\times 2$ 线性系统，你可以轻松地手动完成计算，从而专注于算法的每一步：计算残差、求解修正方程、以及更新解。这个例子也凸显了迭代求精的一个关键动机：当一个近似解的残差很小，但其本身距离真实解却很远时，迭代求精能够有效地修正这种偏差。",
            "id": "2182580",
            "problem": "考虑线性方程组 $A\\mathbf{x} = \\mathbf{b}$，其中矩阵 $A$ 和向量 $\\mathbf{b}$ 定义如下：\n$$A = \\begin{pmatrix} 1  1 \\\\ 1  1.001 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 3 \\\\ 3.002 \\end{pmatrix}$$\n该方程组的一个近似解，记为 $\\mathbf{x}_0$，给出为 $\\mathbf{x}_0 = \\begin{pmatrix} 2.998 \\\\ 0 \\end{pmatrix}$。\n使用给定的矩阵 $A$ 和初始近似解 $\\mathbf{x}_0$，执行一步迭代改进来计算一个更精确的解 $\\mathbf{x}_1$。在这一步中，要求你精确求解相关的修正方程。\n\n提供改进解向量 $\\mathbf{x}_1$ 的各个分量。将你的最终答案表示为一个包含 $\\mathbf{x}_1$ 两个分量的行矩阵。如果需要，将每个分量四舍五入到四位有效数字。",
            "solution": "我们执行一步迭代改进。给定 $\\mathbf{x}_{0} = \\begin{pmatrix} 2.998 \\\\ 0 \\end{pmatrix}$，计算残差\n$$\\mathbf{r} = \\mathbf{b} - A \\mathbf{x}_{0}.$$\n首先计算\n$$A \\mathbf{x}_{0} = \\begin{pmatrix} 1  1 \\\\ 1  1.001 \\end{pmatrix} \\begin{pmatrix} 2.998 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2.998 \\\\ 2.998 \\end{pmatrix}.$$\n因此\n$$\\mathbf{r} = \\begin{pmatrix} 3 \\\\ 3.002 \\end{pmatrix} - \\begin{pmatrix} 2.998 \\\\ 2.998 \\end{pmatrix} = \\begin{pmatrix} 0.002 \\\\ 0.004 \\end{pmatrix}.$$\n修正量 $\\mathbf{d}$ 通过精确求解修正方程\n$$A \\mathbf{d} = \\mathbf{r}, \\quad \\text{即} \\quad \\begin{pmatrix} 1  1 \\\\ 1  1.001 \\end{pmatrix} \\begin{pmatrix} d_{1} \\\\ d_{2} \\end{pmatrix} = \\begin{pmatrix} 0.002 \\\\ 0.004 \\end{pmatrix}$$ 来获得。\n这给出了方程组\n$$d_{1} + d_{2} = 0.002, \\quad d_{1} + 1.001 d_{2} = 0.004.$$\n用第二个方程减去第一个方程：\n$$(d_{1} + 1.001 d_{2}) - (d_{1} + d_{2}) = 0.004 - 0.002 \\;\\Rightarrow\\; 0.001 d_{2} = 0.002 \\;\\Rightarrow\\; d_{2} = 2.$$\n那么\n$$d_{1} = 0.002 - d_{2} = 0.002 - 2 = -1.998.$$\n更新近似解：\n$$\\mathbf{x}_{1} = \\mathbf{x}_{0} + \\mathbf{d} = \\begin{pmatrix} 2.998 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} -1.998 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}.$$\n因此，改进解恰好为 $\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$，它已经满足任何四舍五入的要求。",
            "answer": "$$\\boxed{\\begin{pmatrix} 1  2 \\end{pmatrix}}$$"
        },
        {
            "introduction": "在理想的数学世界中，计算是精确的，但在真实的计算机世界里，我们必须面对有限精度浮点运算带来的挑战。这个练习精心设计了一个思想实验，旨在揭示为何“用更高精度计算残差”是迭代求精中的一条黄金法则。通过对比在低“工作精度”和较高“保护精度”下的计算结果，你将亲眼见证低精度计算如何可能完全掩盖解的误差，从而得出一个具有误导性的“零残差”。",
            "id": "3245538",
            "problem": "考虑一个标准化的以10为基的浮点数系统 $\\mathcal{F}_{10}(t)$，其具有 $t$ 位有效数字，并采用舍入到最近值、平局时舍入到偶数（ties to even）的规则。假设工作精度为 $t_{w} = 2$，保护精度为 $t_{g} = 5$。在求解线性系统 $A\\mathbf{x} = \\mathbf{b}$ 的迭代改进法中，用于形成修正量的残差计算公式为 $\\mathbf{r}^{(0)}_{t} = \\operatorname{fl}_{t}\\!\\left(\\mathbf{b} - \\operatorname{fl}_{t}(A \\mathbf{x}^{(0)})\\right)$，其中 $\\operatorname{fl}_{t}$ 表示在 $\\mathcal{F}_{10}(t)$ 中将每个中间运算舍入到 $t$ 位有效数字。对于对角矩阵，矩阵向量积简化为逐分量的标量乘积。\n\n通过选择以下数据，设计一个在工作精度下会产生误导性的零残差，但在保护精度下会揭示非零残差的例子：\n$$\nA = \\begin{pmatrix}\n1.0005  0 \\\\\n0  0.9996\n\\end{pmatrix}, \\quad\n\\mathbf{b} = \\begin{pmatrix}\n1.0 \\\\\n1.0\n\\end{pmatrix}, \\quad\n\\mathbf{x}^{(0)} = \\begin{pmatrix}\n1.0 \\\\\n1.0\n\\end{pmatrix},\n$$\n其中 $A$、$\\mathbf{b}$ 和 $\\mathbf{x}^{(0)}$ 以保护精度 $\\mathcal{F}_{10}(t_{g})$ 存储。\n\n仅使用上述规则和浮点运算中残差的基本定义，完成以下操作：\n- 验证工作精度残差 $\\mathbf{r}^{(0)}_{t_{w}}$ 在 $\\mathcal{F}_{10}(t_{w})$ 中恰好为零向量。\n- 计算保护精度残差 $\\mathbf{r}^{(0)}_{t_{g}}$ 在 $\\mathcal{F}_{10}(t_{g})$ 中的值。\n- 计算欧几里得范数（2-范数）$\\|\\mathbf{r}^{(0)}_{t_{g}}\\|_{2}$。\n\n将 $\\|\\mathbf{r}^{(0)}_{t_{g}}\\|_{2}$ 的最终数值答案舍入到四位有效数字。不需要单位。",
            "solution": "该问题要求在两种不同的浮点精度下分析残差计算，以说明迭代改进法中的一个潜在陷阱。浮点系统是10进制的 $\\mathcal{F}_{10}(t)$，采用舍入到最近值、平局时舍入到偶数（ties to even）的舍入规则。\n\n给定的数据如下：\n工作精度位数，$t_w = 2$。\n保护精度位数，$t_g = 5$。\n矩阵 $A = \\begin{pmatrix} 1.0005  0 \\\\ 0  0.9996 \\end{pmatrix}$。\n向量 $\\mathbf{b} = \\begin{pmatrix} 1.0 \\\\ 1.0 \\end{pmatrix}$。\n初始猜测值 $\\mathbf{x}^{(0)} = \\begin{pmatrix} 1.0 \\\\ 1.0 \\end{pmatrix}$。\n数据 $A$、$\\mathbf{b}$ 和 $\\mathbf{x}^{(0)}$ 以保护精度 $\\mathcal{F}_{10}(5)$ 存储。\n残差定义为 $\\mathbf{r}^{(0)}_{t} = \\operatorname{fl}_{t}\\!\\left(\\mathbf{b} - \\operatorname{fl}_{t}(A \\mathbf{x}^{(0)})\\right)$，其中 $\\operatorname{fl}_{t}$ 表示每个中间运算都舍入到 $t$ 位有效数字。\n\n问题分为三个任务：验证工作精度残差为零，计算保护精度残差，以及求出保护精度残差的欧几里得范数。\n\n**第一部分：验证工作精度残差 $\\mathbf{r}^{(0)}_{t_{w}}$**\n\n我们使用工作精度 $t_w = 2$ 计算残差。公式为 $\\mathbf{r}^{(0)}_{t_{w}} = \\operatorname{fl}_{2}\\!\\left(\\mathbf{b} - \\operatorname{fl}_{2}(A \\mathbf{x}^{(0)})\\right)$。计算是按分量进行的。\n\n首先，我们计算矩阵向量积 $\\mathbf{y} = \\operatorname{fl}_{2}(A \\mathbf{x}^{(0)})$。项 $\\operatorname{fl}_{2}(A \\mathbf{x}^{(0)})$ 意味着计算该乘积的算术运算在 $\\mathcal{F}_{10}(2)$ 中执行。输入矩阵 $A$ 和 $\\mathbf{x}^{(0)}$ 使用其 $t_g=5$ 的存储值，运算结果被舍入到 $t_w=2$ 位数字。\n\n对于第一个分量 $y_1$：\n$$\ny_1 = \\operatorname{fl}_{2}\\left( A_{11} x_1^{(0)} + A_{12} x_2^{(0)} \\right) = \\operatorname{fl}_{2}\\left( 1.0005 \\times 1.0 + 0 \\times 1.0 \\right) = \\operatorname{fl}_{2}(1.0005)\n$$\n要将 $1.0005$ 舍入到2位有效数字，我们将其写成标准形式 $1.0005 \\times 10^0$。我们必须在第二位有效数字后截断。第三位数字是 $0$，小于 $5$，因此我们向下舍入。\n$$\ny_1 = 1.0\n$$\n\n对于第二个分量 $y_2$：\n$$\ny_2 = \\operatorname{fl}_{2}\\left( A_{21} x_1^{(0)} + A_{22} x_2^{(0)} \\right) = \\operatorname{fl}_{2}\\left( 0 \\times 1.0 + 0.9996 \\times 1.0 \\right) = \\operatorname{fl}_{2}(0.9996)\n$$\n要将 $0.9996$ 舍入到2位有效数字，我们将其写为 $9.996 \\times 10^{-1}$。我们必须在第二位有效数字后截断。第三位数字是 $9$，大于或等于 $5$，因此我们向上舍入。数字 $9.9$ 向上舍入为 $10$。\n$$\ny_2 = 10 \\times 10^{-1} = 1.0\n$$\n因此，在工作精度下计算的矩阵向量积为 $\\operatorname{fl}_{2}(A \\mathbf{x}^{(0)}) = \\begin{pmatrix} 1.0 \\\\ 1.0 \\end{pmatrix}$。\n\n接下来，我们计算残差向量 $\\mathbf{r}^{(0)}_{t_w} = \\operatorname{fl}_{2}(\\mathbf{b} - \\mathbf{y})$。向量 $\\mathbf{b}$ 的分量为 $b_1 = 1.0$ 和 $b_2 = 1.0$。\n对于残差的第一个分量：\n$$\nr^{(0)}_{t_w, 1} = \\operatorname{fl}_{2}(b_1 - y_1) = \\operatorname{fl}_{2}(1.0 - 1.0) = \\operatorname{fl}_{2}(0.0) = 0.0\n$$\n对于残差的第二个分量：\n$$\nr^{(0)}_{t_w, 2} = \\operatorname{fl}_{2}(b_2 - y_2) = \\operatorname{fl}_{2}(1.0 - 1.0) = \\operatorname{fl}_{2}(0.0) = 0.0\n$$\n因此，工作精度残差为零向量，这与要验证的内容相符：\n$$\n\\mathbf{r}^{(0)}_{t_{w}} = \\begin{pmatrix} 0.0 \\\\ 0.0 \\end{pmatrix}\n$$\n\n**第二部分：计算保护精度残差 $\\mathbf{r}^{(0)}_{t_{g}}$**\n\n我们现在使用保护精度 $t_g = 5$ 计算残差。公式为 $\\mathbf{r}^{(0)}_{t_{g}} = \\operatorname{fl}_{5}\\!\\left(\\mathbf{b} - \\operatorname{fl}_{5}(A \\mathbf{x}^{(0)})\\right)$。所有数据（$A, \\mathbf{b}, \\mathbf{x}^{(0)}$）都已存储在 $\\mathcal{F}_{10}(5)$ 中，因此直接使用它们的值。\n- $A=\\begin{pmatrix} 1.0005  0 \\\\ 0  0.99960 \\end{pmatrix}$\n- $\\mathbf{b}=\\begin{pmatrix} 1.0000 \\\\ 1.0000 \\end{pmatrix}$\n- $\\mathbf{x}^{(0)}=\\begin{pmatrix} 1.0000 \\\\ 1.0000 \\end{pmatrix}$\n\n首先，我们计算矩阵向量积 $\\mathbf{y} = \\operatorname{fl}_{5}(A \\mathbf{x}^{(0)})$。\n对于第一个分量 $y_1$：\n$$\ny_1 = \\operatorname{fl}_{5}\\left( 1.0005 \\times 1.0000 \\right) = \\operatorname{fl}_{5}(1.0005)\n$$\n数字 $1.0005$ 有5位有效数字，因此不需要舍入。$y_1 = 1.0005$。\n\n对于第二个分量 $y_2$：\n$$\ny_2 = \\operatorname{fl}_{5}\\left( 0.99960 \\times 1.0000 \\right) = \\operatorname{fl}_{5}(0.99960)\n$$\n数字 $0.99960$ ($9.9960 \\times 10^{-1}$) 有5位有效数字，因此不需要舍入。$y_2 = 0.99960$。\n因此，$\\operatorname{fl}_{5}(A \\mathbf{x}^{(0)}) = \\begin{pmatrix} 1.0005 \\\\ 0.99960 \\end{pmatrix}$。\n\n接下来，我们计算残差向量 $\\mathbf{r}^{(0)}_{t_g} = \\operatorname{fl}_{5}(\\mathbf{b} - \\mathbf{y})$。\n对于第一个分量：\n$$\nr^{(0)}_{t_g, 1} = \\operatorname{fl}_{5}(b_1 - y_1) = \\operatorname{fl}_{5}(1.0000 - 1.0005) = \\operatorname{fl}_{5}(-0.0005)\n$$\n数字 $-0.0005$ 在 $\\mathcal{F}_{10}(5)$ 中可以写成 $-5.0000 \\times 10^{-4}$。不需要舍入。$r^{(0)}_{t_g, 1} = -0.0005$。\n\n对于第二个分量：\n$$\nr^{(0)}_{t_g, 2} = \\operatorname{fl}_{5}(b_2 - y_2) = \\operatorname{fl}_{5}(1.0000 - 0.99960) = \\operatorname{fl}_{5}(0.00040)\n$$\n数字 $0.00040$ 在 $\\mathcal{F}_{10}(5)$ 中可以写成 $4.0000 \\times 10^{-4}$。不需要舍入。$r^{(0)}_{t_g, 2} = 0.0004$。\n\n因此，保护精度残差为：\n$$\n\\mathbf{r}^{(0)}_{t_{g}} = \\begin{pmatrix} -0.0005 \\\\ 0.0004 \\end{pmatrix}\n$$\n\n**第三部分：计算欧几里得范数 $\\|\\mathbf{r}^{(0)}_{t_{g}}\\|_{2}$**\n\n最后一步是计算保护精度残差向量 $\\mathbf{r}^{(0)}_{t_{g}}$ 的欧几里得范数。计算在精确算术中进行，最终结果舍入到四位有效数字。\n$$\n\\|\\mathbf{r}^{(0)}_{t_{g}}\\|_{2} = \\sqrt{(r^{(0)}_{t_g, 1})^2 + (r^{(0)}_{t_g, 2})^2} = \\sqrt{(-0.0005)^2 + (0.0004)^2}\n$$\n我们计算平方根内的各项：\n$$\n(-0.0005)^2 = (-5 \\times 10^{-4})^2 = 25 \\times 10^{-8}\n$$\n$$\n(0.0004)^2 = (4 \\times 10^{-4})^2 = 16 \\times 10^{-8}\n$$\n将这些值相加：\n$$\n25 \\times 10^{-8} + 16 \\times 10^{-8} = 41 \\times 10^{-8} = 4.1 \\times 10^{-7}\n$$\n现在，我们取平方根：\n$$\n\\|\\mathbf{r}^{(0)}_{t_{g}}\\|_{2} = \\sqrt{41 \\times 10^{-8}} = \\sqrt{41} \\times 10^{-4}\n$$\n数值计算 $\\sqrt{41}$：\n$$\n\\sqrt{41} \\approx 6.403124237\n$$\n因此，范数约等于 $6.403124237 \\times 10^{-4}$。将此值舍入到四位有效数字，我们得到：\n$$\n\\|\\mathbf{r}^{(0)}_{t_{g}}\\|_{2} \\approx 6.403 \\times 10^{-4}\n$$",
            "answer": "$$\\boxed{6.403 \\times 10^{-4}}$$"
        },
        {
            "introduction": "现在，让我们从纸笔计算走向计算机编程，在更真实的场景中检验迭代求精的威力。本练习要求你编写程序，将迭代求精算法应用于求解以“病态”著称的希尔伯特矩阵（Hilbert matrix）线性系统。通过追踪并量化每一次迭代后解的“正确数字位数”的增益，你不仅能实践算法的编程实现，还能凭经验观察和分析算法在面对严重病态问题时的收敛行为和效能极限。",
            "id": "3245403",
            "problem": "您的任务是实现并分析用于求解包含希尔伯特矩阵（一个经典的病态矩阵）的线性系统的迭代改进方法。目标是量化每次迭代中解的精度所增加的以 10 为底的位数。\n\n使用的基本原理和定义：\n- 线性系统的形式为 $A \\mathbf{x} = \\mathbf{b}$，其中 $A \\in \\mathbb{R}^{n \\times n}$，$\\mathbf{x} \\in \\mathbb{R}^{n}$，$\\mathbf{b} \\in \\mathbb{R}^{n}$。希尔伯特矩阵 $H \\in \\mathbb{R}^{n \\times n}$ 定义为 $H_{ij} = \\frac{1}{i + j - 1}$，其中 $i, j \\in \\{1, \\dots, n\\}$。\n- 第 $k$ 次迭代的残差为 $\\mathbf{r}^{(k)} = \\mathbf{b} - A \\mathbf{x}^{(k)}$。\n- 第 $k$ 次迭代的迭代改进更新通过求解 $A \\mathbf{d}^{(k)} = \\mathbf{r}^{(k)}$ 生成一个修正量 $\\mathbf{d}^{(k)}$，并设置 $\\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)} + \\mathbf{d}^{(k)}$。\n- 第 $k$ 次迭代时正确的以 10 为底的位数由下式定义\n$$\nD^{(k)} = -\\log_{10}\\!\\left(\\frac{\\lVert \\mathbf{x}^{(k)} - \\mathbf{x}^\\star \\rVert_\\infty}{\\lVert \\mathbf{x}^\\star \\rVert_\\infty}\\right),\n$$\n其中 $\\mathbf{x}^\\star$ 是精确解。为了在双精度算术中保持数值稳定性，报告的 $D^{(k)}$ 应在 16 位饱和，即使用\n$$\n\\tilde{D}^{(k)} = -\\log_{10}\\!\\left(\\max\\!\\left(\\frac{\\lVert \\mathbf{x}^{(k)} - \\mathbf{x}^\\star \\rVert_\\infty}{\\lVert \\mathbf{x}^\\star \\rVert_\\infty},\\,10^{-16}\\right)\\right).\n$$\n- 每次迭代中正确位数的增益为 $G^{(k)} = \\tilde{D}^{(k)} - \\tilde{D}^{(k-1)}$，$k \\ge 1$。初始精度 $\\tilde{D}^{(0)}$ 对应于在任何改进迭代之前通过单次直接求解 $A \\mathbf{x} = \\mathbf{b}$ 得到的解的精度。\n\n科学真实性与设置：\n- 希尔伯特矩阵是众所周知的病态矩阵，其条件数随 $n$ 的增加而迅速增长。迭代改进可以通过求解残差方程来修正累积误差，从而改善解的质量。\n- 所有计算均使用双精度浮点算术（$64$ 位）。\n\n程序要求：\n- 构建大小为 $n$ 的希尔伯特矩阵 $A$。\n- 将真实解设为 $\\mathbf{x}^\\star = \\mathbf{1}$（长度为 $n$ 的全一向量）。计算 $\\mathbf{b} = A \\mathbf{x}^\\star$。\n- 通过直接求解 $A \\mathbf{x} = \\mathbf{b}$ 来计算初始解 $\\mathbf{x}^{(0)}$。\n- 如上所述，执行 $m$ 步迭代改进。\n- 在每次迭代 $k \\in \\{1, \\dots, m\\}$ 后，计算并记录 $G^{(k)}$。\n- 对每个测试用例，输出列表 $[G^{(1)}, G^{(2)}, \\dots, G^{(m)}]$。\n\n测试套件：\n- 用例 1：$n = 2, m = 5$（边界情况，相对良态）。\n- 用例 2：$n = 5, m = 5$（中等程度病态）。\n- 用例 3：$n = 8, m = 5$（具有挑战性的病态）。\n- 用例 4：$n = 12, m = 5$（严重病态的边缘情况）。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含所有测试用例的每次迭代增益。格式为逗号分隔的列表的列表，不含空格，并用方括号括起来。例如，输出应类似于 $[[g_{1,1},\\dots,g_{1,m}],[g_{2,1},\\dots,g_{2,m}],\\dots]$，其中 $g_{i,k}$ 是测试用例 $i$ 中第 $k$ 次迭代的增益。\n- 所有数字都应以标准十进制浮点数格式打印，本问题不涉及任何物理单位。",
            "solution": "用户提供的问题陈述已经过独立验证，被确定为数值线性代数领域中一个适定、有科学依据且客观的问题。该问题没有矛盾、歧义和事实错误。因此，下面提供一个完整的解答。\n\n该问题要求实现并分析用于求解线性系统 $A \\mathbf{x} = \\mathbf{b}$ 的迭代改进算法，其中 $A$ 是臭名昭著的病态矩阵——希尔伯特矩阵。目标是量化在每个改进步骤中解的精度增益，以 10 为底的位数来衡量。\n\n大小为 $n \\times n$ 的希尔伯特矩阵 $H$ 由其元素 $H_{ij} = \\frac{1}{i + j - 1}$ 定义，其中行和列索引 $i, j$ 从 1 开始。其条件数随 $n$ 的增长而急剧增大，使其成为数值稳定性的经典测试案例。对于一个系统 $A \\mathbf{x} = \\mathbf{b}$，当 $A$ 是病态矩阵时，使用像 LU 分解这样的直接方法求解会累积显著的浮点误差，导致计算出的解不准确。\n\n迭代改进是一种旨在提高计算解精度的方法。设 $\\mathbf{x}^{(0)}$ 是通过直接求解器获得的初始解。由于有限精度算术， $\\mathbf{x}^{(0)}$ 与真实解 $\\mathbf{x}^\\star$ 之间存在一个误差 $\\mathbf{e}^{(0)} = \\mathbf{x}^\\star - \\mathbf{x}^{(0)}$。该方法的基础在于估计并修正这个误差。\n\n对于近似解 $\\mathbf{x}^{(k)}$，其残差向量定义为 $\\mathbf{r}^{(k)} = \\mathbf{b} - A \\mathbf{x}^{(k)}$。通过代入 $\\mathbf{b} = A \\mathbf{x}^\\star$，残差可以与真实误差 $\\mathbf{e}^{(k)} = \\mathbf{x}^\\star - \\mathbf{x}^{(k)}$ 相关联：\n$$\n\\mathbf{r}^{(k)} = A \\mathbf{x}^\\star - A \\mathbf{x}^{(k)} = A (\\mathbf{x}^\\star - \\mathbf{x}^{(k)}) = A \\mathbf{e}^{(k)}\n$$\n这个方程表明，真实误差 $\\mathbf{e}^{(k)}$ 是线性系统 $A \\mathbf{e}^{(k)} = \\mathbf{r}^{(k)}$ 的解。虽然我们无法精确计算 $\\mathbf{e}^{(k)}$（因为这等同于完美求解原始问题），但我们可以通过求解残差系统来计算它的一个近似值，我们记为 $\\mathbf{d}^{(k)}$：\n$$\nA \\mathbf{d}^{(k)} = \\mathbf{r}^{(k)}\n$$\n向量 $\\mathbf{d}^{(k)}$ 作为对当前解的计算修正量。通过应用此修正，我们得到下一个（希望更精确的）解 $\\mathbf{x}^{(k+1)}$：\n$$\n\\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)} + \\mathbf{d}^{(k)}\n$$\n这个过程被迭代地重复。迭代改进的一个关键方面是，理想情况下，残差 $\\mathbf{r}^{(k)}$ 应以比其余计算更高的精度来计算。然而，本问题指定所有运算均使用标准的双精度（$64$ 位浮点数），这使我们能够观察在没有更高精度可用时该方法的局限性。\n\n为了量化算法的性能，我们在每一步测量解的精度。解 $\\mathbf{x}^{(k)}$ 中正确的以 10 为底的位数是相对于真实解 $\\mathbf{x}^\\star$ 定义的：\n$$\nD^{(k)} = -\\log_{10}\\!\\left(\\frac{\\lVert \\mathbf{x}^{(k)} - \\mathbf{x}^\\star \\rVert_\\infty}{\\lVert \\mathbf{x}^\\star \\rVert_\\infty}\\right)\n$$\n其中 $\\lVert \\cdot \\rVert_\\infty$ 是无穷范数（向量各分量绝对值的最大值）。由于双精度浮点算术具有大约 16 位十进制数字的有限精度，使用一个不超过此限制且避免对零取对数的饱和精度度量是切合实际的：\n$$\n\\tilde{D}^{(k)} = -\\log_{10}\\!\\left(\\max\\!\\left(\\frac{\\lVert \\mathbf{x}^{(k)} - \\mathbf{x}^\\star \\rVert_\\infty}{\\lVert \\mathbf{x}^\\star \\rVert_\\infty},\\,10^{-16}\\right)\\right)\n$$\n在第 $k$ 次迭代的精度增益是与上一步相比正确位数的差值：\n$$\nG^{(k)} = \\tilde{D}^{(k)} - \\tilde{D}^{(k-1)} \\quad \\text{for } k \\ge 1\n$$\n这里，$\\tilde{D}^{(0)}$ 是通过直接求解得到的初始解 $\\mathbf{x}^{(0)}$ 的精度。\n\n每个测试用例 $(n, m)$ 的算法过程如下：\n1.  **系统设置**：\n    *   构建 $n \\times n$ 的希尔伯特矩阵 $A$，其中基于零的行 $i$ 和列 $j$ 的元素为 $A_{ij} = \\frac{1}{(i+1) + (j+1) - 1} = \\frac{1}{i+j+1}$。\n    *   将真实解定义为全一向量，$\\mathbf{x}^\\star = \\mathbf{1} \\in \\mathbb{R}^n$。\n    *   计算右端向量 $\\mathbf{b} = A \\mathbf{x}^\\star$。这确保了误差计算有一个已知的基准真相。由于对所有 $j$ 都有 $x^\\star_j = 1$，每个分量 $b_i$ 是 $A$ 的第 $i$ 行的和：$b_i = \\sum_{j=1}^{n} \\frac{1}{i+j-1}$。\n\n2.  **初始解**：\n    *   使用标准的直接数值求解器求解系统 $A \\mathbf{x} = \\mathbf{b}$，计算初始近似解 $\\mathbf{x}^{(0)}$。\n    *   计算初始精度 $\\tilde{D}^{(0)}$。\n\n3.  **迭代改进**：\n    *   初始化当前解 $\\mathbf{x} \\leftarrow \\mathbf{x}^{(0)}$ 和先前的精度 $D_{prev} \\leftarrow \\tilde{D}^{(0)}$。\n    *   对于从 $1$ 到 $m$ 的 $k$：\n        a. 计算残差：$\\mathbf{r} = \\mathbf{b} - A \\mathbf{x}$。\n        b. 求解修正量：$A \\mathbf{d} = \\mathbf{r}$。\n        c. 更新解：$\\mathbf{x} \\leftarrow \\mathbf{x} + \\mathbf{d}$。\n        d. 计算新精度：$D_{current} = \\tilde{D}^{(k)}$。\n        e. 计算并记录增益：$G^{(k)} = D_{current} - D_{prev}$。\n        f. 更新先前的精度：$D_{prev} \\leftarrow D_{current}$。\n\n4.  **输出**：报告每个测试用例的增益列表 $[G^{(1)}, G^{(2)}, \\dots, G^{(m)}]$。\n\n对于条件数较低的矩阵（例如，$n=2$），初始解已经非常精确，改进几乎不产生任何增益。随着 $n$ 的增加（$n=5, 8$），条件数增长，初始解的质量下降，预计迭代改进将在最初几次迭代中提供显著的精度增益。对于 $n=12$，希尔伯特矩阵的条件数超过 $10^{16}$，这是双精度数的近似精度极限。此时，计算出的残差主要由噪声构成，预计改进过程会停滞或失败，产生极小甚至为负的增益。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and analyzes iterative refinement for linear systems involving\n    the Hilbert matrix for a suite of test cases.\n    \"\"\"\n    # Test cases are defined as tuples (n, m), where n is the matrix size\n    # and m is the number of refinement iterations.\n    test_cases = [\n        (2, 5),   # Case 1: Well-conditioned\n        (5, 5),   # Case 2: Moderately ill-conditioned\n        (8, 5),   # Case 3: Challenging ill-conditioning\n        (12, 5),  # Case 4: Severe ill-conditioning\n    ]\n\n    all_results = []\n\n    for n, m in test_cases:\n        # Step 1: System Setup\n        # Construct the n x n Hilbert matrix A.\n        # For 0-based indices i, j, the formula is H_ij = 1 / (i + j + 1).\n        A = np.fromfunction(lambda i, j: 1.0 / (i + j + 1), (n, n), dtype=float)\n\n        # Define the true solution as the all-ones vector.\n        x_star = np.ones(n, dtype=float)\n\n        # Calculate the right-hand side vector b = A * x_star.\n        b = A @ x_star\n\n        # Define a helper function to calculate the number of correct digits.\n        def get_saturated_digits(x_approx, x_true):\n            \"\"\"\n            Calculates the saturated number of correct base-10 digits.\n            \"\"\"\n            # The infinity norm of x_star is always 1.0.\n            norm_x_true_inf = 1.0\n            \n            # Calculate relative error using the infinity norm.\n            relative_error = np.linalg.norm(x_approx - x_true, np.inf) / norm_x_true_inf\n            \n            # Apply saturation at 10^-16 to handle finite precision and avoid log(0).\n            effective_error = max(relative_error, 1e-16)\n            \n            return -np.log10(effective_error)\n\n        # Step 2: Initial Solution\n        # Compute the initial solution x^(0) using a direct solver.\n        x_k = np.linalg.solve(A, b)\n\n        # Calculate the initial number of correct digits, D_tilde^(0).\n        D_prev = get_saturated_digits(x_k, x_star)\n\n        # Step 3: Iterative Refinement\n        gains_for_case = []\n        for _ in range(m):\n            # a. Compute the residual in double precision.\n            r_k = b - A @ x_k\n\n            # b. Solve for the correction vector d.\n            d_k = np.linalg.solve(A, r_k)\n\n            # c. Update the solution.\n            x_k = x_k + d_k\n\n            # d. Calculate the new accuracy.\n            D_current = get_saturated_digits(x_k, x_star)\n\n            # e. Calculate and record the gain.\n            gain = D_current - D_prev\n            gains_for_case.append(gain)\n\n            # f. Update the previous accuracy for the next iteration.\n            D_prev = D_current\n        \n        all_results.append(gains_for_case)\n\n    # Final print statement in the exact required format.\n    # Format each sublist of gains into a comma-separated string \"[g1,g2,...]\".\n    formatted_sublists = [f\"[{','.join(map(str, sublist))}]\" for sublist in all_results]\n    # Join all formatted sublists into the final output string.\n    print(f\"[{','.join(formatted_sublists)}]\")\n\nsolve()\n```"
        }
    ]
}