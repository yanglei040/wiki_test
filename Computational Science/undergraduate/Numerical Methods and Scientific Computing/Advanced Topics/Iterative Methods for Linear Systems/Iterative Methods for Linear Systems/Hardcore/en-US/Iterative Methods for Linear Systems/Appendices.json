{
    "hands_on_practices": [
        {
            "introduction": "The best way to understand an iterative process is to perform one yourself. This first exercise walks you through the fundamental mechanics of an iterative solver using the Jacobi method. By manually calculating the first few steps for a simple $2 \\times 2$ system, you will gain a concrete intuition for how these methods progressively refine an approximate solution from an initial guess .",
            "id": "2182317",
            "problem": "In a simplified economic model, the equilibrium prices of two interdependent products, let's call them product 1 and product 2, are described by a system of linear equations. Let $p_1$ be the price of product 1 and $p_2$ be the price of product 2. The equilibrium condition is met when the following system holds:\n\n$$\n5p_1 - 2p_2 = 11\n$$\n$$\n-p_1 + 4p_2 = 7\n$$\n\nTo find these prices without directly inverting a matrix, one can use an iterative numerical technique. Starting with an initial guess of $\\mathbf{p}^{(0)} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, perform two full iterations of the Jacobi method to approximate the equilibrium prices.\n\nCalculate the vector estimate $\\mathbf{p}^{(2)} = \\begin{pmatrix} p_1^{(2)} \\\\ p_2^{(2)} \\end{pmatrix}$. Your answer should be a row matrix containing the two components, $p_1^{(2)}$ and $p_2^{(2)}$, in that order, expressed as exact fractions.",
            "solution": "We write the linear system in component form and rearrange each equation to isolate the variable on the left:\n$$\n5p_{1}-2p_{2}=11 \\;\\;\\Rightarrow\\;\\; p_{1}=\\frac{11+2p_{2}}{5}, \\qquad -p_{1}+4p_{2}=7 \\;\\;\\Rightarrow\\;\\; p_{2}=\\frac{7+p_{1}}{4}.\n$$\nThe Jacobi iteration updates each component using only the previous iterate. With the initial guess $\\mathbf{p}^{(0)}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$, the first iteration is\n$$\np_{1}^{(1)}=\\frac{11+2p_{2}^{(0)}}{5}=\\frac{11+0}{5}=\\frac{11}{5}, \\qquad\np_{2}^{(1)}=\\frac{7+p_{1}^{(0)}}{4}=\\frac{7+0}{4}=\\frac{7}{4}.\n$$\nUsing these in the second iteration,\n$$\np_{1}^{(2)}=\\frac{11+2p_{2}^{(1)}}{5}=\\frac{11+2\\cdot\\frac{7}{4}}{5}=\\frac{11+\\frac{7}{2}}{5}=\\frac{\\frac{22}{2}+\\frac{7}{2}}{5}=\\frac{\\frac{29}{2}}{5}=\\frac{29}{10},\n$$\n$$\np_{2}^{(2)}=\\frac{7+p_{1}^{(1)}}{4}=\\frac{7+\\frac{11}{5}}{4}=\\frac{\\frac{35}{5}+\\frac{11}{5}}{4}=\\frac{\\frac{46}{5}}{4}=\\frac{46}{20}=\\frac{23}{10}.\n$$\nTherefore, after two Jacobi iterations,\n$$\n\\mathbf{p}^{(2)}=\\begin{pmatrix}\\frac{29}{10} \\\\ \\frac{23}{10}\\end{pmatrix}.\n$$\nAs a row matrix with the two components in order, this is $\\begin{pmatrix}\\frac{29}{10}  \\frac{23}{10}\\end{pmatrix}$.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{29}{10}  \\frac{23}{10} \\end{pmatrix}}$$"
        },
        {
            "introduction": "An iterative method is only useful if it converges to the correct solution. This practice moves beyond simple calculation to the critical question of convergence. By constructing and analyzing the Jacobi iteration matrix $T_J$ for a system that is not diagonally dominant, you will discover the mathematical reason—the spectral radius $\\rho(T_J)$—that determines whether the iterations will succeed or fail .",
            "id": "2182318",
            "problem": "An iterative method is a numerical procedure that generates a sequence of improving approximate solutions for a class of problems. For a linear system of equations $A\\mathbf{x} = \\mathbf{b}$, one such method is the Jacobi method. The matrix $A$ can be decomposed as $A = D + L + U$, where $D$ is the diagonal part of A, $L$ is the strictly lower-triangular part of $A$, and $U$ is the strictly upper-triangular part of $A$.\n\nThe Jacobi iteration is defined by the formula:\n$$D\\mathbf{x}^{(k+1)} = -(L+U)\\mathbf{x}^{(k)} + \\mathbf{b}$$\nThis can be rewritten in the form $\\mathbf{x}^{(k+1)} = T_J \\mathbf{x}^{(k)} + \\mathbf{c}$, where $T_J = -D^{-1}(L+U)$ is known as the Jacobi iteration matrix. The convergence of the method is determined by the properties of this matrix.\n\nConsider the following system of linear equations:\n$$\n\\begin{align*}\n2x_1 + 3x_2 = 5 \\\\\n4x_1 + 2x_2 = 6\n\\end{align*}\n$$\nDetermine the two eigenvalues of the Jacobi iteration matrix $T_J$ corresponding to this system. Present your answer as a row matrix containing the two eigenvalues, ordered in ascending numerical value.",
            "solution": "The given system of linear equations is:\n$$\n\\begin{align*}\n2x_1 + 3x_2 = 5 \\\\\n4x_1 + 2x_2 = 6\n\\end{align*}\n$$\nThis can be written in matrix form $A\\mathbf{x} = \\mathbf{b}$, where:\n$$A = \\begin{pmatrix} 2  3 \\\\ 4  2 \\end{pmatrix}, \\quad \\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 5 \\\\ 6 \\end{pmatrix}$$\n\nTo find the Jacobi iteration matrix $T_J$, we first decompose the matrix $A$ into its diagonal ($D$), strictly lower-triangular ($L$), and strictly upper-triangular ($U$) parts.\n$$A = D + L + U$$\nFrom the matrix $A$, we identify:\n$$D = \\begin{pmatrix} 2  0 \\\\ 0  2 \\end{pmatrix}$$\n$$L = \\begin{pmatrix} 0  0 \\\\ 4  0 \\end{pmatrix}$$\n$$U = \\begin{pmatrix} 0  3 \\\\ 0  0 \\end{pmatrix}$$\n\nThe Jacobi iteration matrix is defined as $T_J = -D^{-1}(L+U)$.\nFirst, we find the inverse of the diagonal matrix $D$:\n$$D^{-1} = \\begin{pmatrix} 1/2  0 \\\\ 0  1/2 \\end{pmatrix}$$\nNext, we compute the sum of $L$ and $U$:\n$$L+U = \\begin{pmatrix} 0  0 \\\\ 4  0 \\end{pmatrix} + \\begin{pmatrix} 0  3 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 0  3 \\\\ 4  0 \\end{pmatrix}$$\nNow, we can compute the iteration matrix $T_J$:\n$$T_J = -D^{-1}(L+U) = -\\begin{pmatrix} 1/2  0 \\\\ 0  1/2 \\end{pmatrix} \\begin{pmatrix} 0  3 \\\\ 4  0 \\end{pmatrix} = -\\begin{pmatrix} 0  3/2 \\\\ 2  0 \\end{pmatrix}$$\n$$T_J = \\begin{pmatrix} 0  -3/2 \\\\ -2  0 \\end{pmatrix}$$\n\nTo find the eigenvalues of $T_J$, we solve the characteristic equation $\\det(T_J - \\lambda I) = 0$, where $I$ is the identity matrix.\n$$T_J - \\lambda I = \\begin{pmatrix} 0  -3/2 \\\\ -2  0 \\end{pmatrix} - \\lambda \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} -\\lambda  -3/2 \\\\ -2  -\\lambda \\end{pmatrix}$$\nThe determinant is:\n$$\\det(T_J - \\lambda I) = (-\\lambda)(-\\lambda) - (-3/2)(-2) = \\lambda^2 - 3$$\nSetting the determinant to zero gives the characteristic equation:\n$$\\lambda^2 - 3 = 0$$\nSolving for $\\lambda$, we get:\n$$\\lambda^2 = 3$$\n$$\\lambda = \\pm\\sqrt{3}$$\nThe two eigenvalues are $\\sqrt{3}$ and $-\\sqrt{3}$.\n\nThe problem asks for the eigenvalues to be presented in a row matrix in ascending order.\nThe ascending order is $-\\sqrt{3}$, then $\\sqrt{3}$.\nThe spectral radius of the iteration matrix is $\\rho(T_J) = \\max(|\\sqrt{3}|, |-\\sqrt{3}|) = \\sqrt{3} \\approx 1.732$. Since $\\rho(T_J)  1$, the Jacobi method will diverge for this system.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\sqrt{3}  \\sqrt{3}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Theoretical knowledge of convergence becomes powerful when applied to practical problem-solving. This final, code-based exercise explores a common challenge in scientific computing: a linear system that is not 'well-behaved'. You will see firsthand how a simple strategy—reordering the equations—can dramatically alter the behavior of the Gauss-Seidel method, sometimes making the difference between a diverging solution and a stable, convergent one .",
            "id": "3245080",
            "problem": "Consider the linear system $A x = b$ where $A \\in \\mathbb{R}^{3 \\times 3}$ and $b \\in \\mathbb{R}^{3}$ are given by\n$$\nA = \\begin{bmatrix}\n0  1  4 \\\\\n2  1  -1 \\\\\n1  -3  2\n\\end{bmatrix}, \\quad\nb = \\begin{bmatrix}\n3 \\\\\n-1 \\\\\n2\n\\end{bmatrix}.\n$$\nThe system is not strictly diagonally dominant by rows. The Gauss-Seidel method arises from a matrix splitting of $A$ into $A = D + L + U$, where $D$ is the diagonal of $A$, $L$ is the strictly lower-triangular part of $A$, and $U$ is the strictly upper-triangular part of $A$. The Gauss-Seidel iteration is defined by\n$$\n(D + L) x^{(k+1)} = b - U x^{(k)}.\n$$\nThis defines the Gauss-Seidel iteration matrix\n$$\nT_{\\mathrm{GS}} = - (D + L)^{-1} U,\n$$\nand the error iteration $e^{(k+1)} = T_{\\mathrm{GS}} e^{(k)}$, where $e^{(k)} = x^{(k)} - x^\\star$ and $x^\\star$ is the exact solution. Convergence in the norm for the method is guaranteed if the spectral radius $\\rho(T_{\\mathrm{GS}})  1$. For symmetric positive definite (SPD) matrices, convergence is guaranteed, but for general non-diagonally dominant matrices, convergence may depend on the ordering of the equations and unknowns.\n\nIn this problem, you will explore the effect of row reordering (equation reordering) on the convergence of Gauss-Seidel for the specific non-diagonally dominant system above. A row reordering is represented by a permutation matrix $P$, which reorders the rows of $A$ and $b$ to produce the permuted system\n$$\nA_p = P A, \\quad b_p = P b.\n$$\nFor each permutation, the Gauss-Seidel method is applied to the permuted system $A_p x = b_p$ using the same variable ordering (columns are not permuted). If $(D_p + L_p)$ from the splitting $A_p = D_p + L_p + U_p$ is singular, the Gauss-Seidel step is not well-defined and the iteration breaks down.\n\nImplement a program that, for each permutation in the test suite below, performs the following:\n- Constructs the permuted system $A_p x = b_p$.\n- Computes the Gauss-Seidel iteration matrix $T_{\\mathrm{GS}} = - (D_p + L_p)^{-1} U_p$ and its spectral radius $\\rho(T_{\\mathrm{GS}})$. If $(D_p + L_p)$ is singular, report $\\rho(T_{\\mathrm{GS}})$ as not-a-number (NaN).\n- Runs Gauss-Seidel starting from the initial guess $x^{(0)} = \\begin{bmatrix} 0  0  0 \\end{bmatrix}^\\top$, with maximum iterations $N_{\\max} = 200$ and tolerance $\\varepsilon = 10^{-8}$ on the Euclidean norm of the residual $\\|A_p x^{(k)} - b_p\\|_2$. If the residual norm falls below $\\varepsilon$, declare convergence. If the iteration matrix is not well-defined due to singular $(D_p + L_p)$, declare no convergence and report the residual as NaN.\n\nTest suite (row permutations specified as index orders):\n- Case $0$: $(0, 1, 2)$, identity row order.\n- Case $1$: $(1, 0, 2)$, swap the first two rows.\n- Case $2$: $(2, 1, 0)$, reverse the row order.\n\nFor each case, produce three outputs in order:\n- $\\rho(T_{\\mathrm{GS}})$ as a floating-point number (or NaN if undefined),\n- a boolean indicating whether Gauss-Seidel converged within $N_{\\max}$ iterations for tolerance $\\varepsilon$,\n- the final residual norm $\\|A_p x^{(k)} - b_p\\|_2$ as a floating-point number (or NaN if undefined).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$\n[\\rho_0, \\mathrm{conv}_0, r_0, \\rho_1, \\mathrm{conv}_1, r_1, \\rho_2, \\mathrm{conv}_2, r_2],\n$$\nwhere $\\rho_i$ is the spectral radius for case $i$, $\\mathrm{conv}_i$ is the boolean convergence indicator for case $i$, and $r_i$ is the final residual norm for case $i$. No physical units are involved in this problem. Angles are not used. Percentages are not used.",
            "solution": "The problem requires an analysis of the Gauss-Seidel iterative method for solving the linear system $A x = b$, where the matrix $A$ and vector $b$ are given by:\n$$\nA = \\begin{bmatrix}\n0  1  4 \\\\\n2  1  -1 \\\\\n1  -3  2\n\\end{bmatrix}, \\quad\nb = \\begin{bmatrix}\n3 \\\\\n-1 \\\\\n2\n\\end{bmatrix}.\n$$\nThe core of the problem is to investigate how reordering the equations (rows of $A$ and $b$) affects the convergence of the method. The analysis will be performed for $3$ specific row permutations. For each permutation, we must calculate the spectral radius of the Gauss-Seidel iteration matrix, determine if the method converges, and report the final residual norm.\n\nThe Gauss-Seidel method is based on the splitting of the matrix $A$ into $A = D + L + U$, where $D$ is the diagonal part, $L$ is the strictly lower-triangular part, and $U$ is the strictly upper-triangular part. For a permuted system $A_p x = b_p$, where $A_p = P A$ and $b_p = P b$ for a permutation matrix $P$, the splitting is $A_p = D_p + L_p + U_p$. The Gauss-Seidel iteration is defined as:\n$$\nx^{(k+1)} = (D_p + L_p)^{-1} (b_p - U_p x^{(k)}).\n$$\nThis iteration is well-defined only if the matrix $(D_p + L_p)$ is invertible. Since $(D_p + L_p)$ is a lower-triangular matrix, its determinant is the product of its diagonal entries. These entries are the same as the diagonal entries of $A_p$. Thus, the iteration is well-defined if and only if all diagonal entries of the permuted matrix $A_p$ are non-zero.\n\nIf the iteration is well-defined, its convergence is governed by the spectral radius $\\rho(T_{\\mathrm{GS}})$ of the iteration matrix $T_{\\mathrm{GS}} = -(D_p + L_p)^{-1} U_p$. The method is guaranteed to converge for any initial guess if and only if $\\rho(T_{\\mathrm{GS}})  1$.\n\nThe iterative process starts with an initial guess $x^{(0)} = \\begin{bmatrix} 0  0  0 \\end{bmatrix}^\\top$. It terminates if the Euclidean norm of the residual, $\\|r^{(k)}\\|_2 = \\|A_p x^{(k)} - b_p\\|_2$, falls below a tolerance $\\varepsilon = 10^{-8}$, or if the number of iterations reaches a maximum of $N_{\\max} = 200$.\n\nWe now analyze the $3$ specified cases.\n\n**Case 0: Identity permutation $(0, 1, 2)$**\n\nThe system remains unchanged: $A_p = A$ and $b_p = b$.\n$$\nA_p = \\begin{bmatrix}\n0  1  4 \\\\\n2  1  -1 \\\\\n1  -3  2\n\\end{bmatrix}\n$$\nThe first diagonal element of $A_p$ is $a_{00} = 0$. The matrix $(D_p + L_p)$ is:\n$$\nD_p + L_p = \\begin{bmatrix} 0  0  0 \\\\ 2  1  0 \\\\ 1  -3  2 \\end{bmatrix}\n$$\nThe determinant of this matrix is $\\det(D_p + L_p) = 0 \\cdot 1 \\cdot 2 = 0$, so it is singular. The inverse $(D_p + L_p)^{-1}$ does not exist, and the Gauss-Seidel iteration matrix $T_{\\mathrm{GS}}$ is not well-defined. Consequently, the iteration cannot be performed.\n\n-   Spectral radius $\\rho(T_{\\mathrm{GS}})$: a not-a-number (NaN).\n-   Convergence: False, as the method breaks down.\n-   Final residual norm: a not-a-number (NaN).\n\n**Case 1: Permutation $(1, 0, 2)$**\n\nThis permutation swaps the first two rows of $A$ and $b$.\n$$\nA_p = \\begin{bmatrix}\n2  1  -1 \\\\\n0  1  4 \\\\\n1  -3  2\n\\end{bmatrix}, \\quad\nb_p = \\begin{bmatrix}\n-1 \\\\\n3 \\\\\n2\n\\end{bmatrix}\n$$\nThe diagonal elements of $A_p$ are $2$, $1$, and $2$, all of which are non-zero. The iteration is well-defined. The matrix splitting gives:\n$$\nD_p + L_p = \\begin{bmatrix} 2  0  0 \\\\ 0  1  0 \\\\ 1  -3  2 \\end{bmatrix}, \\quad\nU_p = \\begin{bmatrix} 0  1  -1 \\\\ 0  0  4 \\\\ 0  0  0 \\end{bmatrix}\n$$\nThe inverse of $(D_p + L_p)$ is:\n$$\n(D_p + L_p)^{-1} = \\begin{bmatrix} 1/2  0  0 \\\\ 0  1  0 \\\\ -1/4  3/2  1/2 \\end{bmatrix}\n$$\nThe iteration matrix $T_{\\mathrm{GS}}$ is:\n$$\nT_{\\mathrm{GS}} = - (D_p + L_p)^{-1} U_p = - \\begin{bmatrix} 1/2  0  0 \\\\ 0  1  0 \\\\ -1/4  3/2  1/2 \\end{bmatrix} \\begin{bmatrix} 0  1  -1 \\\\ 0  0  4 \\\\ 0  0  0 \\end{bmatrix} = \\begin{bmatrix} 0  -1/2  1/2 \\\\ 0  0  -4 \\\\ 0  1/4  -25/4 \\end{bmatrix}\n$$\nThe eigenvalues $\\lambda$ of $T_{\\mathrm{GS}}$ are found from $\\det(T_{\\mathrm{GS}} - \\lambda I) = 0$. One eigenvalue is $\\lambda_1 = 0$. The other two are the eigenvalues of the lower-right $2 \\times 2$ sub-matrix, given by the characteristic equation $\\lambda^2 + (25/4)\\lambda + 1 = 0$. The roots are $\\lambda_{2,3} = \\frac{-25 \\pm \\sqrt{561}}{8}$.\nThe spectral radius is the maximum of the absolute values of these eigenvalues:\n$$\n\\rho(T_{\\mathrm{GS}}) = \\max \\left( |0|, \\left| \\frac{-25 + \\sqrt{561}}{8} \\right|, \\left| \\frac{-25 - \\sqrt{561}}{8} \\right| \\right) = \\frac{25 + \\sqrt{561}}{8} \\approx 6.0855\n$$\nSince $\\rho(T_{\\mathrm{GS}})  1$, the Gauss-Seidel method will diverge for this permutation.\n\n-   Spectral radius $\\rho(T_{\\mathrm{GS}})$: $\\approx 6.0855$.\n-   Convergence: False.\n-   Final residual norm: A large value, determined by running the diverging iteration for $N_{\\max} = 200$ steps.\n\n**Case 2: Permutation $(2, 1, 0)$**\n\nThis permutation reverses the order of the rows.\n$$\nA_p = \\begin{bmatrix} 1  -3  2 \\\\ 2  1  -1 \\\\ 0  1  4 \\end{bmatrix}, \\quad\nb_p = \\begin{bmatrix} 2 \\\\ -1 \\\\ 3 \\end{bmatrix}\n$$\nThe diagonal elements are $1$, $1$, and $4$, all non-zero. The iteration is well-defined.\n$$\nD_p + L_p = \\begin{bmatrix} 1  0  0 \\\\ 2  1  0 \\\\ 0  1  4 \\end{bmatrix}, \\quad\nU_p = \\begin{bmatrix} 0  -3  2 \\\\ 0  0  -1 \\\\ 0  0  0 \\end{bmatrix}\n$$\nThe inverse of $(D_p + L_p)$ is:\n$$\n(D_p + L_p)^{-1} = \\begin{bmatrix} 1  0  0 \\\\ -2  1  0 \\\\ 1/2  -1/4  1/4 \\end{bmatrix}\n$$\nThe iteration matrix $T_{\\mathrm{GS}}$ is:\n$$\nT_{\\mathrm{GS}} = - (D_p + L_p)^{-1} U_p = - \\begin{bmatrix} 1  0  0 \\\\ -2  1  0 \\\\ 1/2  -1/4  1/4 \\end{bmatrix} \\begin{bmatrix} 0  -3  2 \\\\ 0  0  -1 \\\\ 0  0  0 \\end{bmatrix} = \\begin{bmatrix} 0  3  -2 \\\\ 0  -6  5 \\\\ 0  3/2  -5/4 \\end{bmatrix}\n$$\nThe eigenvalues are $\\lambda_1 = 0$ and the roots of $\\lambda^2 + (29/4)\\lambda = 0$, which are $\\lambda_2 = 0$ and $\\lambda_3 = -29/4 = -7.25$. The eigenvalues are $\\{0, 0, -7.25\\}$.\nThe spectral radius is:\n$$\n\\rho(T_{\\mathrm{GS}}) = \\max(|0|, |0|, |-7.25|) = 7.25\n$$\nSince $\\rho(T_{\\mathrm{GS}})  1$, the method will also diverge for this permutation.\n\n-   Spectral radius $\\rho(T_{\\mathrm{GS}})$: $7.25$.\n-   Convergence: False.\n-   Final residual norm: A large value, determined by running the diverging iteration for $N_{\\max} = 200$ steps.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes the Gauss-Seidel method for a linear system under different row permutations.\n    \"\"\"\n    A = np.array([\n        [0., 1., 4.],\n        [2., 1., -1.],\n        [1., -3., 2.]\n    ])\n    b = np.array([3., -1., 2.])\n\n    test_cases = [\n        (0, 1, 2),  # Case 0: Identity\n        (1, 0, 2),  # Case 1: Swap rows 0, 1\n        (2, 1, 0),  # Case 2: Reverse rows\n    ]\n    \n    N_max = 200\n    epsilon = 1e-8\n\n    results = []\n    \n    for perm in test_cases:\n        # Construct the permuted system\n        Ap = A[list(perm), :]\n        bp = b[list(perm)]\n\n        rho = float('nan')\n        converged = False\n        final_residual_norm = float('nan')\n        \n        # Check if Gauss-Seidel is well-defined\n        if np.any(np.diag(Ap) == 0):\n            # D_p + L_p is singular\n            results.extend([rho, converged, final_residual_norm])\n            continue\n\n        # If well-defined, proceed with analysis\n        Dp = np.diag(np.diag(Ap))\n        Lp = np.tril(Ap, k=-1)\n        Up = np.triu(Ap, k=1)\n        \n        D_plus_L_inv = np.linalg.inv(Dp + Lp)\n        T_gs = -D_plus_L_inv @ Up\n        \n        # Calculate spectral radius\n        eigenvalues = np.linalg.eigvals(T_gs)\n        rho = np.max(np.abs(eigenvalues))\n        \n        # Run Gauss-Seidel iteration\n        x = np.zeros_like(bp, dtype=float)\n        converged = False\n\n        for k in range(N_max):\n            # Check for convergence before the update step\n            residual = bp - Ap @ x\n            res_norm = np.linalg.norm(residual)\n            if res_norm  epsilon:\n                converged = True\n                final_residual_norm = res_norm\n                break\n\n            # Perform the update using forward substitution\n            x_new = np.copy(x)\n            for i in range(Ap.shape[0]):\n                sigma1 = np.dot(Ap[i, :i], x_new[:i])\n                sigma2 = np.dot(Ap[i, i+1:], x[i+1:])\n                x_new[i] = (bp[i] - sigma1 - sigma2) / Ap[i, i]\n            x = x_new\n\n        # If loop finished without convergence, set converged to False\n        # and calculate the final residual\n        if not converged:\n            final_residual_norm = np.linalg.norm(bp - Ap @ x)\n        \n        results.extend([rho, converged, final_residual_norm])\n\n    # Final print statement in the exact required format.\n    # Custom mapping for boolean values to lowercase 'true'/'false'\n    # and nan to 'nan' as str(float('nan')) does.\n    def format_val(v):\n        if isinstance(v, bool):\n            return str(v).lower()\n        return str(v)\n\n    print(f\"[{','.join(map(format_val, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}