{
    "hands_on_practices": [
        {
            "introduction": "This first practice provides a foundational deep dive into the mathematical machinery of the Golden Section Search. By deriving the update rules and convergence properties from first principles, you will solidify your understanding of how the golden ratio ensures a constant and guaranteed reduction in the search interval . This pencil-and-paper exercise demonstrates that the algorithm's convergence rate is a purely geometric property, independent of the specific function being optimized.",
            "id": "3237350",
            "problem": "Consider a minimization on a closed interval using the golden section search. Define a piecewise linear unimodal function on the interval $[0,1]$ by\n$$\nf(x) = |x - m|, \\quad m = \\frac{3}{7}.\n$$\nThis $f(x)$ has a unique global minimum at $x=m$. Let the golden ratio constant $\\varphi$ be defined by the algebraic identity $\\varphi^{2}=\\varphi+1$ with $\\varphi0$, and let $\\tau=\\varphi^{-1}$. The golden section search initializes a bracket $[a_{0},b_{0}]=[0,1]$ and, at iteration $k$, evaluates $f$ at two internal points chosen so that the ratio of the current bracket length to the larger of the two subintervals equals $\\varphi$. At each iteration, one endpoint of the bracket is discarded and the other is kept, with $m$ remaining inside the new bracket.\n\nTasks:\n1. Starting from the defining property of the golden ratio constant (without using any shortcut formulas for the interior points), derive exact closed-form expressions for the internal points $c_{k}$ and $d_{k}$ at an arbitrary iteration $k$ in terms of $a_{k}$, $b_{k}$, and $\\tau$. Then derive the exact update rule for the bracket endpoints $[a_{k+1},b_{k+1}]$ based solely on comparisons of $f(c_{k})$ and $f(d_{k})$.\n2. Using the function $f(x)=|x-m|$ with $m=3/7$, determine the ordering of $m$, $c_{0}$, and $d_{0}$ and justify which endpoint is discarded at the first iteration. Show the updated bracket $[a_{1},b_{1}]$ and the new internal points $c_{1}$ and $d_{1}$ in exact symbolic form (expressions involving $\\tau$ only).\n3. From first principles and the definition of $\\tau$, prove that the bracket length after $n$ iterations is a geometric progression in $n$ and give its exact closed-form. Using this, derive the minimal integer number of iterations $n$ required so that the bracket length is less than or equal to $\\varepsilon = 1.0 \\times 10^{-8}$.\n4. Compare the analytically predicted iteration count in Task 3 with the observed iteration count implied by the deterministic bracket updates for the specific function $f(x)=|x-3/7|$ starting from $[0,1]$. State the difference between these two iteration counts and explain why this difference arises or does not arise.\n\nExpress your final answer as the single integer $n$ found in Task 3. No rounding instruction is necessary because the minimal integer $n$ is exact.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It provides a complete and consistent setup for analyzing the golden section search algorithm applied to a specific unimodal function. The problem is valid and can be solved.\n\nThe golden ratio constant $\\varphi$ is defined by $\\varphi^2 = \\varphi + 1$ with $\\varphi  0$. The solution is $\\varphi = \\frac{1+\\sqrt{5}}{2}$. The constant $\\tau$ is defined as $\\tau = \\varphi^{-1} = \\frac{\\sqrt{5}-1}{2}$. The identity $\\varphi^2 = \\varphi + 1$ implies, after dividing by $\\varphi^2$, that $1 = \\frac{1}{\\varphi} + \\frac{1}{\\varphi^2}$, which translates to $1 = \\tau + \\tau^2$. This identity will be used throughout the solution.\n\n### Task 1: Derivation of Internal Points and Update Rule\n\nLet the search bracket at iteration $k$ be $[a_k, b_k]$, with length $L_k = b_k - a_k$. The algorithm evaluates the function at two internal points, $c_k$ and $d_k$, such that $a_k  c_k  d_k  b_k$.\n\nThe defining property of the golden section search is that the ratio of the length of the whole interval to the length of the larger of the two sub-intervals created by an interior point is $\\varphi$. This leads to a symmetric placement of the two interior points. Let the points $c_k$ and $d_k$ be placed such that the ratio of the full interval length $L_k$ to the length of the sub-intervals $[a_k, d_k]$ and $[c_k, b_k]$ is $\\varphi$.\n$$\n\\frac{b_k - a_k}{d_k - a_k} = \\varphi \\quad \\text{and} \\quad \\frac{b_k - a_k}{b_k - c_k} = \\varphi\n$$\nFrom these relations, we derive the positions of $c_k$ and $d_k$:\n$$\nd_k - a_k = \\frac{b_k - a_k}{\\varphi} = \\tau(b_k - a_k) \\implies d_k = a_k + \\tau(b_k - a_k)\n$$\n$$\nb_k - c_k = \\frac{b_k - a_k}{\\varphi} = \\tau(b_k - a_k) \\implies c_k = b_k - \\tau(b_k - a_k)\n$$\nThese are the closed-form expressions for the internal points $c_k$ and $d_k$ in terms of $a_k$, $b_k$, and $\\tau$.\n\nThe update rule for the bracket endpoints is based on the comparison of the function values $f(c_k)$ and $f(d_k)$. Since the function $f(x)$ is unimodal, the minimum must lie in the sub-interval that contains the point with the lower function value.\n1. If $f(c_k) \\le f(d_k)$: The minimum is located in the interval $[a_k, d_k]$ (since $c_k  d_k$ and the function is unimodal). The new bracket becomes $[a_{k+1}, b_{k+1}] = [a_k, d_k]$.\n2. If $f(c_k)  f(d_k)$: The minimum is located in the interval $[c_k, b_k]$. The new bracket becomes $[a_{k+1}, b_{k+1}] = [c_k, b_k]$.\n\nThis pair of rules defines the update for the bracket endpoints based solely on the comparison of $f(c_k)$ and $f(d_k)$.\n\n### Task 2: First Iteration Analysis\n\nThe given function is $f(x) = |x - m|$ with $m = \\frac{3}{7}$, and the initial bracket is $[a_0, b_0] = [0, 1]$.\n\nFirst, we calculate the initial internal points $c_0$ and $d_0$ using the formulas from Task 1:\n$$\nc_0 = b_0 - \\tau(b_0 - a_0) = 1 - \\tau(1 - 0) = 1 - \\tau\n$$\n$$\nd_0 = a_0 + \\tau(b_0 - a_0) = 0 + \\tau(1 - 0) = \\tau\n$$\nTo determine the ordering of $m$, $c_0$, and $d_0$, we compare their values:\n$m = \\frac{3}{7} \\approx 0.42857$\n$\\tau = \\frac{\\sqrt{5}-1}{2} \\approx 0.61803$\n$c_0 = 1 - \\tau = 1 - \\frac{\\sqrt{5}-1}{2} = \\frac{3-\\sqrt{5}}{2} \\approx 0.38197$. Note that $1-\\tau = \\tau^2$.\nSo, we have $c_0  m  d_0$. The order is $\\frac{3-\\sqrt{5}}{2}  \\frac{3}{7}  \\frac{\\sqrt{5}-1}{2}$.\n\nNext, we compare the function values at these points:\n$f(c_0) = |c_0 - m| = |(1-\\tau) - \\frac{3}{7}|$. Since $c_0  m$, this is $m - c_0 = \\frac{3}{7} - (1-\\tau) = \\tau - \\frac{4}{7}$.\n$f(d_0) = |d_0 - m| = |\\tau - \\frac{3}{7}|$. Since $d_0  m$, this is $d_0 - m = \\tau - \\frac{3}{7}$.\n\nComparing the two values:\nSince $-\\frac{4}{7}  -\\frac{3}{7}$, we have $\\tau - \\frac{4}{7}  \\tau - \\frac{3}{7}$.\nTherefore, $f(c_0)  f(d_0)$.\n\nAccording to the update rule, since $f(c_0)  f(d_0)$, we discard the right endpoint $b_0$. The updated bracket is $[a_1, b_1] = [a_0, d_0] = [0, \\tau]$.\n\nThe new internal points, $c_1$ and $d_1$, for the bracket $[a_1, b_1] = [0, \\tau]$ are:\n$$\nc_1 = b_1 - \\tau(b_1 - a_1) = \\tau - \\tau(\\tau - 0) = \\tau - \\tau^2\n$$\n$$\nd_1 = a_1 + \\tau(b_1 - a_1) = 0 + \\tau(\\tau - 0) = \\tau^2\n$$\nSo, the updated bracket is $[a_1, b_1] = [0, \\tau]$, and the new internal points are $c_1 = \\tau - \\tau^2$ and $d_1 = \\tau^2$.\n\n### Task 3: Bracket Length and Number of Iterations\n\nLet $L_k = b_k - a_k$ be the length of the bracket at iteration $k$.\nAt each step $k$, the new bracket length $L_{k+1}$ is the length of either $[a_k, d_k]$ or $[c_k, b_k]$.\nLength of $[a_k, d_k]$ is $d_k - a_k = (a_k + \\tau(b_k-a_k)) - a_k = \\tau(b_k-a_k) = \\tau L_k$.\nLength of $[c_k, b_k]$ is $b_k - c_k = b_k - (b_k - \\tau(b_k-a_k)) = \\tau(b_k-a_k) = \\tau L_k$.\nIn both cases, the length of the bracket is reduced by the same factor $\\tau$:\n$$\nL_{k+1} = \\tau L_k\n$$\nThis demonstrates that the sequence of bracket lengths $\\{L_k\\}$ is a geometric progression with a common ratio of $\\tau$. The closed-form expression for the length after $n$ iterations is $L_n = \\tau^n L_0$.\nGiven the initial bracket $[0, 1]$, the initial length is $L_0 = 1 - 0 = 1$.\nThus, the bracket length after $n$ iterations is $L_n = \\tau^n$.\n\nWe want to find the minimal integer number of iterations $n$ such that the bracket length is less than or equal to $\\varepsilon = 1.0 \\times 10^{-8}$.\n$$\nL_n \\le \\varepsilon \\implies \\tau^n \\le 10^{-8}\n$$\nTaking the natural logarithm of both sides:\n$$\n\\ln(\\tau^n) \\le \\ln(10^{-8})\n$$\n$$\nn \\ln(\\tau) \\le -8 \\ln(10)\n$$\nSince $\\tau = \\frac{\\sqrt{5}-1}{2} \\approx 0.618$, it is between $0$ and $1$, which means $\\ln(\\tau)$ is negative. Dividing by $\\ln(\\tau)$ reverses the inequality sign:\n$$\nn \\ge \\frac{-8 \\ln(10)}{\\ln(\\tau)}\n$$\nWe can write $\\ln(\\tau) = \\ln(\\varphi^{-1}) = -\\ln(\\varphi)$.\n$$\nn \\ge \\frac{-8 \\ln(10)}{-\\ln(\\varphi)} = \\frac{8 \\ln(10)}{\\ln(\\varphi)}\n$$\nNow, we can substitute the values and compute:\n$$\nn \\ge \\frac{8 \\ln(10)}{\\ln\\left(\\frac{1+\\sqrt{5}}{2}\\right)} \\approx \\frac{8 \\times 2.302585}{0.481212} \\approx \\frac{18.42068}{0.481212} \\approx 38.27904\n$$\nSince $n$ must be an integer, the minimal number of iterations required is the smallest integer greater than or equal to this value, which is $\\lceil 38.27904 \\rceil = 39$.\n\n### Task 4: Predicted vs. Observed Iteration Count\n\nThe analytically predicted iteration count from Task 3 is $n=39$. This is the number of iterations required to guarantee that the bracket length $L_n$ is no larger than $\\varepsilon = 1.0 \\times 10^{-8}$.\n\nThe \"observed\" iteration count for the specific function $f(x)=|x-3/7|$ is the actual number of iterations after which the bracket length becomes less than or equal to $\\varepsilon$.\n\nAs derived in Task 3, the length of the bracket at each iteration $k$ follows the deterministic rule $L_{k+1} = \\tau L_k$, which simplifies to $L_k = \\tau^k$ for $L_0=1$. This reduction in length is a geometric property of the golden section search algorithm itself and is independent of the unimodal function being minimized. The function $f(x)$ determines *which* sub-interval is chosen (i.e., the location of the next bracket), but not its *length*.\n\nTherefore, the sequence of bracket lengths is fixed for any application of the golden section search on a given initial interval. The number of iterations required to achieve a certain length tolerance $\\varepsilon$ depends only on the initial length $L_0$, $\\varepsilon$, and the constant factor $\\tau$. It does not depend on the specific choices made at each step based on the function values.\n\nConsequently, the analytically predicted iteration count is not a 'worst-case' or 'average-case' scenario for the length reduction; it is the exact number of iterations required for the length to shrink to the specified tolerance. The observed iteration count for the specific function $f(x)=|x-3/7|$ will be identical to the one calculated.\n\nThe difference between the two iteration counts is $39 - 39 = 0$. This absence of a difference arises because the convergence rate of the bracket length in the golden section search is a constant $\\tau$ at every iteration, irrespective of the function's behavior (provided it remains unimodal).",
            "answer": "$$\\boxed{39}$$"
        },
        {
            "introduction": "Moving from theory to application, this exercise challenges you to implement the Golden Section Search in code, creating a practical tool for optimization. You will test your implementation on a function that is non-differentiable at its minimum, a scenario where gradient-based methods would fail . This practice highlights the robustness and power of derivative-free methods in handling a wider class of optimization problems.",
            "id": "3237407",
            "problem": "Consider designing and analyzing a derivative-free search algorithm to locate the minimum of a unimodal function. A function is called unimodal on an interval if it has exactly one local minimum on that interval. In this task, you will construct a specific unimodal function whose minimum occurs at a point where the first derivative does not exist, and then implement a bracketing method based on the golden ratio to locate the minimum.\n\nConstruct the function\n$$\nf(x) = \\lvert x - \\mu \\rvert + \\beta \\,(x - \\mu)^2,\n$$\nwhere $\\mu \\in \\mathbb{R}$ and $\\beta \\in [0,\\infty)$ are parameters. The point $x = \\mu$ is the unique minimizer, and the function is unimodal because it is strictly decreasing on $(-\\infty,\\mu)$ and strictly increasing on $(\\mu,\\infty)$; moreover, $f$ is not differentiable at $x = \\mu$ due to the absolute value. This setup ensures that any derivative-based method would encounter a non-differentiable point, while a derivative-free method such as the golden section search remains applicable.\n\nStarting from the fundamental property of unimodal functions—namely, if $f$ is unimodal on $[a,b]$, then for any two interior points $c$ and $d$ with $a  c  d  b$, the sign of $f(c) - f(d)$ indicates which subinterval contains the minimum—you must implement a golden section search. The golden section search chooses $c$ and $d$ symmetrically so that one function evaluation can be reused at the next iteration after narrowing the interval. The algorithm should:\n- Start from a bracketing interval $[a,b]$ with $a  \\mu  b$.\n- Use the golden ratio to place points $c$ and $d$ in $(a,b)$ and iteratively narrow the interval containing the minimizer based on comparing $f(c)$ and $f(d)$.\n- Terminate when the interval width $b-a$ is less than a prescribed tolerance or a maximum number of iterations is reached.\n- Return the approximate minimizer as $(a+b)/2$.\n\nImplement the algorithm and test it on the following test suite of parameter sets, where each test case is a tuple $(\\mu,\\beta,a,b,\\text{tol})$:\n1. $(\\mu,\\beta,a,b,\\text{tol}) = (1.23456789, 0.1, -2.0, 5.0, 10^{-8})$.\n2. $(\\mu,\\beta,a,b,\\text{tol}) = (-3.5, 0.0, -10.0, -1.0, 10^{-7})$.\n3. $(\\mu,\\beta,a,b,\\text{tol}) = (0.0, 5.0, -0.001, 0.002, 10^{-12})$.\n4. $(\\mu,\\beta,a,b,\\text{tol}) = (2.0, 0.2, 1.5, 6.0, 10^{-10})$.\n5. $(\\mu,\\beta,a,b,\\text{tol}) = (1000.0, 0.02, 900.0, 1100.0, 10^{-6})$.\n\nAssume a maximum iteration count of $1000$ for all cases. There are no physical units and no angles involved in this problem.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,\\dots,r_5]$), where each $r_i$ is the approximate minimizer returned by the golden section search for the $i$-th test case. The outputs must be floating-point numbers.",
            "solution": "The user-provided problem has been analyzed and validated.\n\n### Step 1: Extract Givens\n- **Function to Minimize:** $f(x) = \\lvert x - \\mu \\rvert + \\beta \\,(x - \\mu)^2$\n- **Parameters:** $\\mu \\in \\mathbb{R}$ and $\\beta \\in [0,\\infty)$.\n- **Function Properties:** Unimodal on $\\mathbb{R}$ with a unique minimum at $x = \\mu$. The function is not differentiable at $x=\\mu$.\n- **Algorithm:** Golden section search.\n- **Initial Conditions:** A bracketing interval $[a, b]$ such that $a  \\mu  b$.\n- **Termination Criteria:**\n    1.  The interval width $b - a$ is less than a tolerance $\\text{tol}$.\n    2.  A maximum of $1000$ iterations is reached.\n- **Output of Algorithm:** The approximate minimizer is given by the midpoint of the final interval, $(a+b)/2$.\n- **Test Cases:** A suite of five test cases, each defined by a tuple $(\\mu, \\beta, a, b, \\text{tol})$:\n    1.  $(1.23456789, 0.1, -2.0, 5.0, 10^{-8})$\n    2.  $(-3.5, 0.0, -10.0, -1.0, 10^{-7})$\n    3.  $(0.0, 5.0, -0.001, 0.002, 10^{-12})$\n    4.  $(2.0, 0.2, 1.5, 6.0, 10^{-10})$\n    5.  $(1000.0, 0.02, 900.0, 1100.0, 10^{-6})$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to a rigorous validation process.\n- **Scientific Grounding:** The problem is scientifically and mathematically sound. The function $f(x) = \\lvert x - \\mu \\rvert + \\beta \\,(x - \\mu)^2$ is a valid mathematical construct. Its claimed properties are correct:\n    - For $x  \\mu$, $f(x) = (x-\\mu) + \\beta(x-\\mu)^2$. The derivative is $f'(x) = 1 + 2\\beta(x-\\mu)$. Since $\\beta \\ge 0$ and $x  \\mu$, $f'(x)  0$, so the function is strictly increasing.\n    - For $x  \\mu$, $f(x) = -(x-\\mu) + \\beta(x-\\mu)^2$. The derivative is $f'(x) = -1 + 2\\beta(x-\\mu)$. Since $x  \\mu$, $f'(x)  0$, so the function is strictly decreasing.\n    - This confirms the function is unimodal with a minimum at $x=\\mu$.\n    - The left-hand derivative at $\\mu$ is $-1$ and the right-hand derivative is $1$, confirming non-differentiability at the minimum.\n- **Well-Posedness:** The problem is well-posed. The golden section search is a convergent algorithm for unimodal functions, guaranteeing a unique solution exists. The initial conditions ($a  \\mu  b$) and termination criteria are clearly specified and consistent.\n- **Objectivity:** The problem is stated using precise, objective mathematical language, with no ambiguity or subjective elements.\n- **Completeness and Consistency:** All necessary parameters ($\\mu, \\beta$), initial intervals $[a, b]$, and tolerances (`tol`) are provided for each test case. The condition $a  \\mu  b$ holds for all cases. The setup is self-contained and free of contradictions.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is a well-defined task in numerical optimization that can be solved algorithmically.\n\n### Solution Derivation\nThe solution involves implementing the golden section search algorithm to find the minimum of the given function $f(x)$.\n\n**Principle of Golden Section Search**\nThe golden section search is a derivative-free optimization technique used to find the minimum of a unimodal function over a closed interval. It operates by iteratively narrowing the interval that brackets the minimum. The method is named for its use of the golden ratio, which ensures that the reduction in interval size at each step is optimal and allows for the reuse of a function evaluation from the previous iteration, thereby improving efficiency.\n\n**Algorithm Design**\nLet the interval containing the minimum be $[a, b]$. The algorithm introduces two interior points, $c$ and $d$, such that $a  c  d  b$. Their positions are determined by the golden ratio conjugate, $\\tau = (\\sqrt{5}-1)/2 \\approx 0.618034$. The points are placed symmetrically:\n$$\nc = b - \\tau(b-a)\n$$\n$$\nd = a + \\tau(b-a)\n$$\nThis arrangement ensures that the ratio of the length of the larger subinterval (e.g., $[a, d]$) to the full interval $[a, b]$ is equal to $\\tau$.\n\nThe iterative procedure is as follows:\n1.  Initialize the interval brackets $[a, b]$ and calculate the initial interior points $c$ and $d$. Evaluate the function at these points to get $f(c)$ and $f(d)$.\n2.  Compare the function values:\n    - If $f(c)  f(d)$, the minimum must lie in the interval $(a, d)$ because the function is unimodal. The search interval is updated to $[a', b'] \\leftarrow [a, d]$. The key property of the golden section search is that the old point $c$ becomes the new point $d'$ relative to the new interval, so we only need to compute one new point $c'$ and one new function value. Specifically, the new assignments are:\n      - $b \\leftarrow d$\n      - $d \\leftarrow c$\n      - $f_d \\leftarrow f_c$\n      - $c \\leftarrow b - \\tau(b-a)$\n      - $f_c \\leftarrow f(c)$\n    - If $f(c) \\ge f(d)$, the minimum must lie in the interval $(c, b)$. The search interval is updated to $[a', b'] \\leftarrow [c, b]$. The old point $d$ becomes the new point $c'$. The new assignments are:\n      - $a \\leftarrow c$\n      - $c \\leftarrow d$\n      - $f_c \\leftarrow f_d$\n      - $d \\leftarrow a + \\tau(b-a)$\n      - $f_d \\leftarrow f(d)$\n3.  The process repeats until the interval width $(b-a)$ is less than the specified tolerance $\\text{tol}$ or the maximum number of iterations ($1000$) is exceeded.\n4.  The final estimate for the minimizer is the midpoint of the final interval, $(a+b)/2$.\n\nThis algorithm will be implemented and applied to the five test cases provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and tests the golden section search algorithm for a specified\n    unimodal function with a non-differentiable minimum.\n    \"\"\"\n\n    def f(x, mu, beta):\n        \"\"\"\n        The unimodal function to be minimized.\n        f(x) = |x - mu| + beta * (x - mu)^2\n        \"\"\"\n        return np.abs(x - mu) + beta * (x - mu)**2\n\n    def golden_section_search(func, a, b, tol, max_iter=1000):\n        \"\"\"\n        Finds the minimum of a unimodal function 'func' on the interval [a, b]\n        using the golden section search method.\n\n        Args:\n            func: The unimodal function to minimize.\n            a: The lower bound of the initial interval.\n            b: The upper bound of the initial interval.\n            tol: The desired tolerance for the interval width.\n            max_iter: The maximum number of iterations.\n\n        Returns:\n            The approximate location of the minimum.\n        \"\"\"\n        # Define the golden ratio conjugate\n        tau = (np.sqrt(5.0) - 1.0) / 2.0\n\n        # Set up the initial interior points\n        c = b - tau * (b - a)\n        d = a + tau * (b - a)\n\n        # Evaluate the function at the interior points\n        fc = func(c)\n        fd = func(d)\n\n        for _ in range(max_iter):\n            # Check for termination\n            if (b - a)  tol:\n                break\n            \n            # Compare function values and shrink the interval\n            if fc  fd:\n                # The minimum is in the interval [a, d]\n                b = d\n                d = c\n                fd = fc\n                c = b - tau * (b - a)\n                fc = func(c)\n            else:\n                # The minimum is in the interval [c, b]\n                a = c\n                c = d\n                fc = fd\n                d = a + tau * (b - a)\n                fd = func(d)\n        \n        # Return the midpoint of the final interval\n        return (a + b) / 2.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.23456789, 0.1, -2.0, 5.0, 1e-8),\n        (-3.5, 0.0, -10.0, -1.0, 1e-7),\n        (0.0, 5.0, -0.001, 0.002, 1e-12),\n        (2.0, 0.2, 1.5, 6.0, 1e-10),\n        (1000.0, 0.02, 900.0, 1100.0, 1e-6),\n    ]\n\n    results = []\n    for mu, beta, a, b, tol in test_cases:\n        # Create a callable function instance for the current set of parameters\n        current_f = lambda x: f(x, mu, beta)\n        \n        # Calculate the result for the current case\n        approximated_minimizer = golden_section_search(current_f, a, b, tol, max_iter=1000)\n        results.append(approximated_minimizer)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.15g}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "This final practice pushes your understanding beyond the standard textbook case by adapting the Golden Section Search to a discrete, integer-based domain. You will need to creatively translate the core concepts of symmetric point placement and interval reduction from a continuous space to a discrete one . This advanced exercise demonstrates the versatility of the underlying principles and hones your ability to generalize algorithms to new problem structures.",
            "id": "3237530",
            "problem": "Let $f:\\mathbb{Z}\\to\\mathbb{R}$ be a unimodal function on the discrete, integer domain $\\{a,a+1,\\dots,b\\}$, where unimodality means there exists an integer minimizer $x^\\star\\in\\{a,a+1,\\dots,b\\}$ such that $f(x)$ is nonincreasing for $x\\le x^\\star$ and nondecreasing for $x\\ge x^\\star$. Starting from the fundamental idea of bracketing for unimodal minimization and the requirement to reuse one function evaluation per iteration by maintaining a constant contraction ratio of the interval, derive a modification of golden section search that operates on the integer domain $\\{a,a+1,\\dots,b\\}$. Your algorithm must maintain the invariant that after each comparison, the integer minimizer remains within the updated bracket. Because the domain is discrete, you must (i) define how to place interior test points $x_1$ and $x_2$ using an interval contraction factor that arises from the constant-ratio principle, (ii) round these points to integers while preserving $a\\le x_1x_2\\le b$, (iii) specify tie-handling when $f(x_1)=f(x_2)$ that is consistent with unimodality, and (iv) define a termination rule that, when the bracket size is small (at most $3$ integers), performs an exhaustive check of all integers in the remaining bracket to select the minimizer. In case of multiple minimizers (a plateau), break ties by returning the smallest integer minimizer.\n\nImplement the algorithm as a complete, runnable program. The program must define the following test suite of unimodal functions and brackets, and compute, for each test case, the integer minimizer $x^\\star$:\n- Test case $1$: $f_1(x)=(x-7)^2+3$ on $a=0$, $b=20$.\n- Test case $2$: $f_2(x)=\\max(0,\\lvert x-5\\rvert-1)$ on $a=0$, $b=12$.\n- Test case $3$: $f_3(x)=2x+11$ on $a=-10$, $b=5$.\n- Test case $4$: $f_4(x)=-3x+7$ on $a=-5$, $b=8$.\n- Test case $5$: $f_5(x)=(x-2)^2$ on $a=1$, $b=3$.\n\nYour program should produce a single line of output containing the integer minimizers for the five test cases as a comma-separated list enclosed in square brackets (e.g., $[x^\\star_1,x^\\star_2,x^\\star_3,x^\\star_4,x^\\star_5]$). No physical units or angle units are involved. The final outputs are integers.",
            "solution": "The user wants to derive and implement a discrete version of the Golden Section Search algorithm.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n-   **Function to minimize**: $f:\\mathbb{Z}\\to\\mathbb{R}$, a unimodal function on the integer domain $\\{a, a+1, \\dots, b\\}$.\n-   **Unimodality Definition**: There is an integer minimizer $x^\\star \\in \\{a, a+1, \\dots, b\\}$ such that $f(x)$ is nonincreasing for $x \\le x^\\star$ and nondecreasing for $x \\ge x^\\star$.\n-   **Core Principle**: The algorithm must be derived from the idea of bracketing and the requirement to reuse one function evaluation per iteration by maintaining a constant contraction ratio of the interval.\n-   **Discretization Requirements**:\n    1.  Define a method to place interior test points $x_1$ and $x_2$ using a contraction factor derived from the constant-ratio principle.\n    2.  Round these points to integers, preserving the invariant $a \\le x_1  x_2 \\le b$.\n    3.  Specify tie-handling for the case $f(x_1) = f(x_2)$ that is consistent with unimodality.\n    4.  Define a termination rule: when the bracket size (number of integers) is at most $3$, perform an exhaustive check to find the minimizer.\n-   **Tie-Breaking for Minimizer**: If there are multiple minimizers (a plateau), the algorithm must return the smallest integer minimizer.\n-   **Test Cases**:\n    1.  $f_1(x)=(x-7)^2+3$ on $a=0, b=20$.\n    2.  $f_2(x)=\\max(0,\\lvert x-5\\rvert-1)$ on $a=0, b=12$.\n    3.  $f_3(x)=2x+11$ on $a=-10, b=5$.\n    4.  $f_4(x)=-3x+7$ on $a=-5, b=8$.\n    5.  $f_5(x)=(x-2)^2$ on $a=1, b=3$.\n-   **Output Format**: A single line with a comma-separated list of integer minimizers: $[x^\\star_1,x^\\star_2,x^\\star_3,x^\\star_4,x^\\star_5]$.\n\n**Step 2: Validate Using Extracted Givens**\n\n-   **Scientifically Grounded**: The problem addresses a standard topic in numerical optimization—the adaptation of a continuous optimization algorithm (Golden Section Search) to a discrete domain. The concepts of unimodality, interval reduction, and function evaluation reuse are mathematically sound and well-established.\n-   **Well-Posed**: The problem is well-posed. The unimodality assumption guarantees the existence of a minimizer. The problem specifies a clear termination condition and a tie-breaking rule (smallest integer minimizer), ensuring a unique solution can be found. The constraints guide the derivation of a specific class of algorithm.\n-   **Objective**: The problem is stated using precise, objective mathematical language, free from ambiguity or subjective claims.\n-   **Completeness and Consistency**: The problem provides all necessary components: function properties, domain, algorithmic constraints, termination condition, and test cases. There are no contradictions.\n-   **Conclusion**: The problem is valid as it is scientifically sound, well-posed, objective, and complete.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. Proceed to the solution.\n\n### Algorithm Derivation and Design\n\nThe core of Golden Section Search is the clever placement of two interior points, $x_1$ and $x_2$, within an interval $[a, b]$ such that after one comparison and interval reduction, one of the old points can be reused as a new interior point in the smaller interval. This is achieved by placing the points according to the golden ratio.\n\nLet the interval of interest contain integers from $a$ to $b$. The span of the interval is $h = b-a$. The golden ratio conjugate is $\\rho = (\\sqrt{5}-1)/2 \\approx 0.618$. In the continuous case, the interior points are $x_1 = a + (1-\\rho)h$ and $x_2 = a + \\rho h$. Note that $1-\\rho = \\rho^2$.\n\nFor the discrete integer domain, we must adapt this. A critical insight is that to enable point reuse, the geometry of the points must be maintained. The simplest way to achieve this is to enforce symmetry. We place the two interior points, $x_1$ and $x_2$, to be symmetric with respect to the endpoints $a$ and $b$. That is, $x_1 - a = b - x_2$, which implies $x_1 + x_2 = a + b$.\n\n**1. Point Placement:**\nWe can calculate one point using the golden ratio and the other using the symmetry condition.\nLet's define the points such that $a \\le x_1  x_2 \\le b$. We can set:\n$$x_2 = a + \\text{round}(\\rho (b-a))$$\n$$x_1 = a + b - x_2$$\nThis ensures the points are symmetric with respect to the interval's center. However, due to integer rounding, especially for small intervals, it's possible that $x_1 \\ge x_2$. The algorithm must detect this and handle it. A robust approach is to fall back to an exhaustive search if the points are not distinct and correctly ordered, as this indicates the interval has become too small for the geometric assumptions to hold. Our specified termination condition (interval size $\\le 3$) handles most of these small-interval cases.\n\n**2. Interval Reduction and Point Reuse:**\nLet the four points defining the bracket be $(a, x_1, x_2, b)$. We evaluate $f(x_1)$ and $f(x_2)$.\n-   If $f(x_1) \\le f(x_2)$: Due to unimodality, the minimizer $x^\\star$ cannot be in the range $(x_2, b]$. The new search interval becomes $[a, x_2]$. The key insight for reusing an evaluation is to observe that the old point $x_1$ is within this new interval. The new four-point bracket becomes $(a', x'_1, x'_2, b')$ where $a'=a$, $b'=x_2$, and $x'_2=x_1$. We only need to compute one new point, $x'_1$. To maintain symmetry in the new interval $[a', b']$, we set $x'_1 = a' + b' - x'_2 = a + x_2 - x_1$. We then only need one new function evaluation, for $f(x'_1)$.\n\n-   If $f(x_1)  f(x_2)$: Symmetrically, the minimizer $x^\\star$ cannot be in $[a, x_1)$. The new interval is $[x_1, b]$. The new bracket becomes $(a', x'_1, x'_2, b')$ where $a'=x_1$, $b'=b$, and $x'_1=x_2$. The new point is $x'_2 = a' + b' - x'_1 = x_1 + b - x_2$. We evaluate $f(x'_2)$.\n\n**3. Tie-Handling ($f(x_1) = f(x_2)$):**\nThe problem requires returning the smallest integer minimizer. If $f(x_1)=f(x_2)$, the minimizer(s) could be anywhere between $x_1$ and $x_2$. To favor smaller-valued minimizers, we should eliminate the right-hand portion of the search space. Therefore, the case $f(x_1) = f(x_2)$ is handled by the $f(x_1) \\le f(x_2)$ branch, which updates the interval to $[a, x_2]$.\n\n**4. Termination Rule:**\nThe iterative process continues as long as the number of points in the interval, $b-a+1$, is greater than $3$. When the interval size becomes $3$ or less, the fixed-ratio logic may break down due to integer arithmetic (e.g., $x_1$ and $x_2$ colliding). At this stage, we perform a simple exhaustive search over the few remaining points $\\{a, a+1, \\dots, b\\}$ to find the one with the minimum function value, respecting the smallest-integer tie-breaker. The algorithm also terminates if, during an update, the new points $x_1, x_2$ collide ($x_1 \\ge x_2$), as this also signals a breakdown of the geometric assumption.\n\nThis derived algorithm constitutes a \"modification of golden section search\" for the integer domain. It uses the golden ratio to inspire its structure, maintains the crucial property of reusing one function evaluation per iteration, and includes specific handling for the realities of discrete integer arithmetic.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements a discrete golden section search algorithm to find the\n    integer minimizer of several unimodal functions.\n    \"\"\"\n\n    # --- Test Case Functions ---\n    def f1(x: int) - float:\n        return float((x - 7)**2 + 3)\n\n    def f2(x: int) - float:\n        return float(np.maximum(0, np.abs(x - 5) - 1))\n\n    def f3(x: int) - float:\n        return float(2 * x + 11)\n\n    def f4(x: int) - float:\n        return float(-3 * x + 7)\n    \n    def f5(x: int) - float:\n        return float((x - 2)**2)\n\n    def discrete_golden_section_search(f, a: int, b: int) - int:\n        \"\"\"\n        Finds the integer minimizer of a unimodal function f on the interval [a, b].\n        \"\"\"\n        # --- Exhaustive search for small final intervals ---\n        def exhaustive_search(f_search, a_search, b_search):\n            min_val = f_search(a_search)\n            min_x = a_search\n            for x_i in range(a_search + 1, b_search + 1):\n                val = f_search(x_i)\n                # In case of a plateau, the first x (smallest) is kept as the minimizer\n                if val  min_val:\n                    min_val = val\n                    min_x = x_i\n            return min_x\n\n        # The golden ratio conjugate\n        rho = (np.sqrt(5) - 1) / 2\n\n        # Initial point placement\n        x1, x2 = 0, 0\n        if b - a + 1  3:\n            h = b - a\n            # Place points symmetrically using the golden ratio\n            x2 = a + int(np.round(rho * h))\n            x1 = a + b - x2\n            # Handle potential collision on small intervals\n            if x1 = x2:\n                return exhaustive_search(f, a, b)\n        else:\n            return exhaustive_search(f, a, b)\n            \n        f1_val = f(x1)\n        f2_val = f(x2)\n\n        # Main loop: reduce interval while it's large enough\n        while b - a + 1  3:\n            if f1_val = f2_val:  # Tie-breaking favors left side to find smallest minimizer\n                b = x2\n                x2 = x1\n                f2_val = f1_val\n                x1 = a + b - x2\n                \n                if x1 = x2: break # Points collided, terminate iteration\n                \n                f1_val = f(x1)\n            else: # f1_val  f2_val\n                a = x1\n                x1 = x2\n                f1_val = f2_val\n                x2 = a + b - x1\n\n                if x1 = x2: break # Points collided, terminate iteration\n\n                f2_val = f(x2)\n        \n        # Final exhaustive search on the small remaining bracket\n        return exhaustive_search(f, a, b)\n\n    test_cases = [\n        (f1, 0, 20),\n        (f2, 0, 12),\n        (f3, -10, 5),\n        (f4, -5, 8),\n        (f5, 1, 3),\n    ]\n\n    results = []\n    for f, a, b in test_cases:\n        minimizer = discrete_golden_section_search(f, a, b)\n        results.append(minimizer)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}