{
    "hands_on_practices": [
        {
            "introduction": "To truly understand how penalty methods work, it's best to start with a problem we can solve completely by hand. This exercise provides a foundational look at the quadratic penalty method by applying it to a simple convex quadratic objective with a linear constraint. By deriving the exact analytical solutions for both the original constrained problem and the penalized version, you will see precisely how the approximate solution converges to the true solution as the penalty parameter $\\mu$ increases. This practice solidifies the core concepts of convergence rates for both the solution error and constraint violation .",
            "id": "3261466",
            "problem": "Consider the unconstrained objective defined by $f(x) = \\sum_{i=1}^{n} x_i^2$, where $x \\in \\mathbb{R}^n$, and a single equality constraint given by $g(x) = c^\\top x - 1 = 0$, with a fixed nonzero vector $c \\in \\mathbb{R}^n$. The penalty method constructs a penalized objective $F_\\mu(x) = f(x) + \\mu \\, g(x)^2$ for a penalty parameter $\\mu > 0$. Starting from core definitions of unconstrained and constrained minimization, and the properties of convex quadratic functions, your tasks are:\n- Task A: Using first principles, derive the constrained minimizer $x^\\star$ of $f(x)$ subject to $g(x) = 0$.\n- Task B: Using first principles, derive the unconstrained minimizer $x_\\mu$ of the penalized objective $F_\\mu(x)$ for a given $\\mu$, and demonstrate that $x_\\mu \\to x^\\star$ as $\\mu \\to +\\infty$.\n- Task C: Estimate the rates at which the error in the decision variable, measured by $\\|x_\\mu - x^\\star\\|_2$, and the constraint violation, measured by $|g(x_\\mu)|$, decay with increasing $\\mu$. Express the rates in Big-O notation as functions of $\\mu$ and the norm of $c$.\n\nYour program must implement the derived formulas and compute, for each test case, the following quantities:\n- The error norm in the decision variable: $\\|x_\\mu - x^\\star\\|_2$.\n- The absolute constraint violation: $|g(x_\\mu)|$.\n- The scaled error norm: $\\mu \\, \\|x_\\mu - x^\\star\\|_2$.\n- The scaled constraint violation: $\\mu \\, |g(x_\\mu)|$.\n\nAll numerical results must be reported as dimensionless quantities (no physical units). Results should be rounded to $8$ decimal places.\n\nUse the following test suite of parameter values, where each case is a pair $(c, \\mu)$ with $c \\in \\mathbb{R}^n$ and $\\mu \\in \\mathbb{R}$:\n- Case $1$ (happy path): $n = 3$, $c = [1, 2, -1]$, $\\mu = 10$.\n- Case $2$ (boundary in penalty strength): $n = 3$, $c = [1, 2, -1]$, $\\mu = 0.1$.\n- Case $3$ (asymptotic regime): $n = 3$, $c = [1, 2, -1]$, $\\mu = 10^6$.\n- Case $4$ (small-norm constraint vector): $n = 3$, $c = [10^{-3}, 0, 0]$, $\\mu = 10$.\n- Case $5$ (large-norm constraint vector): $n = 3$, $c = [3, 4, 0]$, $\\mu = 10$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test caseâ€™s result must be a list of four floats in the fixed order $[\\|x_\\mu - x^\\star\\|_2, |g(x_\\mu)|, \\mu \\, \\|x_\\mu - x^\\star\\|_2, \\mu \\, |g(x_\\mu)|]$, rounded to $8$ decimal places. The final output line therefore has the form\n$[[r_{1,1}, r_{1,2}, r_{1,3}, r_{1,4}],[r_{2,1}, r_{2,2}, r_{2,3}, r_{2,4}],\\dots,[r_{5,1}, r_{5,2}, r_{5,3}, r_{5,4}]]$,\nwith no spaces.",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. All necessary information is provided, and the tasks are clearly defined within the established mathematical framework of constrained optimization and penalty methods.\n\nThe problem asks for an analysis of the quadratic penalty method for a simple convex optimization problem. We are given an objective function $f(x) = \\sum_{i=1}^{n} x_i^2 = x^\\top x$ and a single linear equality constraint $g(x) = c^\\top x - 1 = 0$, where $x \\in \\mathbb{R}^n$ and $c \\in \\mathbb{R}^n$ is a fixed nonzero vector. The quadratic penalty method approximates the solution to this constrained problem by solving a sequence of unconstrained problems with the penalized objective function $F_\\mu(x) = f(x) + \\mu \\, g(x)^2 = x^\\top x + \\mu(c^\\top x - 1)^2$ for a penalty parameter $\\mu > 0$.\n\nOur analysis proceeds in three parts as requested.\n\nTask A: Derivation of the constrained minimizer $x^\\star$.\nTo find the minimizer of $f(x)$ subject to the constraint $g(x)=0$, we use the method of Lagrange multipliers. The Lagrangian function $\\mathcal{L}(x, \\lambda)$ is defined as:\n$$ \\mathcal{L}(x, \\lambda) = f(x) - \\lambda g(x) = x^\\top x - \\lambda (c^\\top x - 1) $$\nThe first-order necessary conditions for optimality require the gradient of the Lagrangian with respect to $x$ to be the zero vector, and the constraint to be satisfied.\n$$ \\nabla_x \\mathcal{L}(x, \\lambda) = 2x - \\lambda c = 0 $$\n$$ g(x) = c^\\top x - 1 = 0 $$\nFrom the first condition, we express the optimal solution $x^\\star$ in terms of the Lagrange multiplier $\\lambda$:\n$$ x^\\star = \\frac{\\lambda}{2} c $$\nSubstituting this into the constraint equation allows us to solve for $\\lambda$:\n$$ c^\\top \\left(\\frac{\\lambda}{2} c\\right) - 1 = 0 $$\n$$ \\frac{\\lambda}{2} (c^\\top c) = 1 $$\n$$ \\frac{\\lambda}{2} \\|c\\|_2^2 = 1 $$\nSince $c$ is a nonzero vector, $\\|c\\|_2^2 > 0$, and we can solve for $\\lambda$:\n$$ \\lambda = \\frac{2}{\\|c\\|_2^2} $$\nSubstituting the value of $\\lambda$ back into the expression for $x^\\star$, we obtain the constrained minimizer:\n$$ x^\\star = \\frac{1}{2} \\left( \\frac{2}{\\|c\\|_2^2} \\right) c = \\frac{c}{\\|c\\|_2^2} = \\frac{c}{c^\\top c} $$\nSince the objective function $f(x)$ is strictly convex and the constraint defines a convex set (a hyperplane), this stationary point is the unique global minimizer.\n\nTask B: Derivation of the unconstrained minimizer $x_\\mu$ and convergence analysis.\nThe penalized objective function is $F_\\mu(x) = x^\\top x + \\mu(c^\\top x - 1)^2$. This is an unconstrained, strictly convex function, so its unique minimizer $x_\\mu$ can be found by setting its gradient to zero.\n$$ \\nabla_x F_\\mu(x) = \\nabla_x (x^\\top x) + \\mu \\nabla_x ((c^\\top x - 1)^2) $$\nUsing the chain rule for the penalty term, where $\\nabla_x(u^2) = 2u \\nabla_x u$, we have:\n$$ \\nabla_x F_\\mu(x) = 2x + \\mu \\cdot 2(c^\\top x - 1) \\cdot c = 0 $$\nDividing by $2$ and rearranging terms gives:\n$$ x_\\mu + \\mu(c^\\top x_\\mu - 1)c = 0 $$\n$$ x_\\mu + \\mu(c^\\top x_\\mu)c - \\mu c = 0 $$\n$$ x_\\mu + \\mu c(c^\\top x_\\mu) = \\mu c $$\nThis can be written as a linear system: $(I + \\mu c c^\\top) x_\\mu = \\mu c$. To solve for $x_\\mu$, we can use the Sherman-Morrison formula for the inverse of $(I + \\mu c c^\\top)$, which yields:\n$$(I + \\mu c c^\\top)^{-1} = I - \\frac{\\mu c c^\\top}{1 + \\mu c^\\top c}$$\nApplying this inverse to find $x_\\mu$:\n$$ x_\\mu = \\left(I - \\frac{\\mu c c^\\top}{1 + \\mu \\|c\\|_2^2}\\right) (\\mu c) = \\mu c - \\frac{\\mu^2 c (c^\\top c)}{1 + \\mu \\|c\\|_2^2} = \\mu c - \\frac{\\mu^2 \\|c\\|_2^2 c}{1 + \\mu \\|c\\|_2^2} $$\nSimplifying the scalar coefficient of $c$:\n$$ \\mu - \\frac{\\mu^2 \\|c\\|_2^2}{1 + \\mu \\|c\\|_2^2} = \\frac{\\mu(1 + \\mu \\|c\\|_2^2) - \\mu^2 \\|c\\|_2^2}{1 + \\mu \\|c\\|_2^2} = \\frac{\\mu}{1 + \\mu \\|c\\|_2^2} $$\nThus, the minimizer of the penalized function is:\n$$ x_\\mu = \\frac{\\mu}{1 + \\mu \\|c\\|_2^2} c $$\nTo demonstrate that $x_\\mu \\to x^\\star$ as $\\mu \\to +\\infty$, we take the limit of the expression for $x_\\mu$:\n$$ \\lim_{\\mu \\to +\\infty} x_\\mu = \\lim_{\\mu \\to +\\infty} \\left( \\frac{\\mu}{1 + \\mu \\|c\\|_2^2} \\right) c $$\nWe can divide the numerator and denominator of the scalar fraction by $\\mu$:\n$$ \\lim_{\\mu \\to +\\infty} \\left( \\frac{1}{1/\\mu + \\|c\\|_2^2} \\right) c = \\left( \\frac{1}{0 + \\|c\\|_2^2} \\right) c = \\frac{c}{\\|c\\|_2^2} $$\nThis limit is exactly the expression for $x^\\star$, which confirms the convergence $x_\\mu \\to x^\\star$.\n\nTask C: Estimation of decay rates.\nWe now analyze the rates at which the error and constraint violation approach zero.\n\nFirst, we analyze the error in the decision variable, $\\|x_\\mu - x^\\star\\|_2$.\n$$ x_\\mu - x^\\star = \\frac{\\mu}{1 + \\mu \\|c\\|_2^2} c - \\frac{1}{\\|c\\|_2^2} c = \\left( \\frac{\\mu \\|c\\|_2^2 - (1 + \\mu \\|c\\|_2^2)}{(1 + \\mu \\|c\\|_2^2)\\|c\\|_2^2} \\right) c = \\frac{-1}{(1 + \\mu \\|c\\|_2^2)\\|c\\|_2^2} c $$\nTaking the Euclidean norm:\n$$ \\|x_\\mu - x^\\star\\|_2 = \\left\\| \\frac{-c}{(1 + \\mu \\|c\\|_2^2)\\|c\\|_2^2} \\right\\|_2 = \\frac{\\|c\\|_2}{(1 + \\mu \\|c\\|_2^2)\\|c\\|_2^2} = \\frac{1}{(1 + \\mu \\|c\\|_2^2)\\|c\\|_2} $$\nFor large $\\mu$, the term $1$ is negligible compared to $\\mu \\|c\\|_2^2$. Therefore, the asymptotic behavior is:\n$$ \\|x_\\mu - x^\\star\\|_2 \\approx \\frac{1}{(\\mu \\|c\\|_2^2)\\|c\\|_2} = \\frac{1}{\\mu \\|c\\|_2^3} $$\nThis shows that the error norm decays as $O(\\mu^{-1})$. Specifically, $\\|x_\\mu - x^\\star\\|_2 = O(\\mu^{-1}\\|c\\|_2^{-3})$.\n\nNext, we analyze the constraint violation, $|g(x_\\mu)|$.\n$$ g(x_\\mu) = c^\\top x_\\mu - 1 = c^\\top \\left(\\frac{\\mu}{1 + \\mu \\|c\\|_2^2} c\\right) - 1 = \\frac{\\mu (c^\\top c)}{1 + \\mu \\|c\\|_2^2} - 1 $$\n$$ g(x_\\mu) = \\frac{\\mu \\|c\\|_2^2 - (1 + \\mu \\|c\\|_2^2)}{1 + \\mu \\|c\\|_2^2} = \\frac{-1}{1 + \\mu \\|c\\|_2^2} $$\nTaking the absolute value gives the constraint violation:\n$$ |g(x_\\mu)| = \\frac{1}{1 + \\mu \\|c\\|_2^2} $$\nFor large $\\mu$, the asymptotic behavior is:\n$$ |g(x_\\mu)| \\approx \\frac{1}{\\mu \\|c\\|_2^2} $$\nThis shows that the constraint violation also decays as $O(\\mu^{-1})$. Specifically, $|g(x_\\mu)| = O(\\mu^{-1}\\|c\\|_2^{-2})$.\n\nSummary of formulas for implementation:\nFor a given $c \\in \\mathbb{R}^n$ and $\\mu > 0$:\n$1$. Error norm: $\\|x_\\mu - x^\\star\\|_2 = \\frac{1}{(1 + \\mu \\|c\\|_2^2)\\|c\\|_2}$\n$2$. Constraint violation: $|g(x_\\mu)| = \\frac{1}{1 + \\mu \\|c\\|_2^2}$\n$3$. Scaled error norm: $\\mu \\|x_\\mu - x^\\star\\|_2 = \\frac{\\mu}{(1 + \\mu \\|c\\|_2^2)\\|c\\|_2}$\n$4$. Scaled constraint violation: $\\mu |g(x_\\mu)| = \\frac{\\mu}{1 + \\mu \\|c\\|_2^2}$\nThese formulas will be used to compute the required quantities for the test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the derived formulas for the penalty method analysis\n    and computes results for the specified test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (c, mu), where c is a list of floats\n    # and mu is a float.\n    test_cases = [\n        # Case 1 (happy path)\n        ([1.0, 2.0, -1.0], 10.0),\n        # Case 2 (boundary in penalty strength)\n        ([1.0, 2.0, -1.0], 0.1),\n        # Case 3 (asymptotic regime)\n        ([1.0, 2.0, -1.0], 1e6),\n        # Case 4 (small-norm constraint vector)\n        ([1e-3, 0.0, 0.0], 10.0),\n        # Case 5 (large-norm constraint vector)\n        ([3.0, 4.0, 0.0], 10.0),\n    ]\n\n    all_results = []\n    for c_list, mu in test_cases:\n        c = np.array(c_list)\n\n        # Calculate squared L2 norm of c\n        c_norm_sq = np.dot(c, c)\n        \n        # Calculate L2 norm of c\n        c_norm = np.sqrt(c_norm_sq)\n\n        # The term (1 + mu * ||c||^2) appears in all denominators\n        denominator = 1.0 + mu * c_norm_sq\n\n        # Task C derived the following exact formulas:\n        # ||x_mu - x*||_2 = 1 / ((1 + mu * ||c||^2) * ||c||)\n        # |g(x_mu)| = 1 / (1 + mu * ||c||^2)\n\n        # Calculate error norm in the decision variable\n        error_norm = 1.0 / (denominator * c_norm)\n\n        # Calculate absolute constraint violation\n        constraint_violation = 1.0 / denominator\n\n        # Calculate scaled error norm\n        scaled_error_norm = mu * error_norm\n\n        # Calculate scaled constraint violation\n        scaled_constraint_violation = mu * constraint_violation\n\n        # Store the four computed values for the current test case\n        case_result = [\n            error_norm,\n            constraint_violation,\n            scaled_error_norm,\n            scaled_constraint_violation,\n        ]\n        all_results.append(case_result)\n\n    # Format the final output string as specified in the problem statement.\n    # The output is a list of lists, with no spaces and 8 decimal places.\n    case_strings = []\n    for res in all_results:\n        # Format each number to 8 decimal places and join into a string like \"[n1,n2,n3,n4]\"\n        num_strings = [f\"{val:.8f}\" for val in res]\n        case_strings.append(f\"[{','.join(num_strings)}]\")\n    \n    # Join the case strings into a final string like \"[[...],[...],...]\"\n    final_output = f\"[{','.join(case_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Theoretical analysis often assumes the penalty parameter $\\mu$ simply goes to infinity, but in a practical algorithm, how should we choose the sequence of $\\mu$ values? A fixed, aggressive schedule can lead to numerical instability, while a timid one may converge too slowly. This practice moves from theory to implementation by tasking you with designing an adaptive penalty update scheme. You will develop a method that automatically adjusts $\\mu$ based on the progress in satisfying the constraints, creating a more robust and intelligent optimization algorithm .",
            "id": "3261584",
            "problem": "Consider equality-constrained quadratic optimization of the form: minimize a smooth convex quadratic objective subject to linear equality constraints. The objective is defined as $f(x) = \\frac{1}{2} x^\\top Q x + c^\\top x$ with $Q \\in \\mathbb{R}^{n \\times n}$ symmetric positive definite and $c \\in \\mathbb{R}^n$, and the constraints are given by $A x = b$ with $A \\in \\mathbb{R}^{m \\times n}$ full row rank and $b \\in \\mathbb{R}^m$. The quadratic penalty method replaces the constrained problem by a sequence of unconstrained penalized problems parameterized by a penalty parameter $\\mu > 0$, where the penalized objective is $F_\\mu(x) = f(x) + \\frac{\\mu}{2} \\lVert A x - b \\rVert_2^2$. For each fixed $\\mu$, the minimizer $x(\\mu)$ of $F_\\mu(x)$ can be characterized by first-order optimality conditions.\n\nStarting from the fundamental definitions of equality-constrained optimization, the gradient-based stationarity condition for the penalized objective, and the relationship between constraint violation and penalty weight, design an algorithm that automatically tunes the sequence of penalty parameters $\\{\\mu_k\\}_{k=0}^{K}$ based on the observed progress of the optimization. The tuning must be justified by principled progress metrics derived from the fundamental base rather than ad hoc heuristics. The algorithm must terminate when a mathematically clear convergence criterion is met that reflects both near-feasibility of the constraints and the stabilization of iterates.\n\nYour program must:\n- Implement the quadratic penalty method for equality constraints by solving the stationarity equation for $F_\\mu(x)$ exactly at each penalty parameter $\\mu$. This equation follows from $\\nabla F_\\mu(x) = 0$.\n- Define and use progress metrics that quantify improvement in constraint satisfaction and stabilization of iterates. You must use these metrics to adaptively update $\\mu$ without relying on a pre-fixed schedule.\n- Ensure numerical stability by guarding against pathological updates, including stagnation and excessively large penalty parameters.\n- Use a clear convergence check that reflects the goals of constrained optimization.\n\nTest Suite:\nUse three test cases, each with fully specified matrices and parameters, to exercise your algorithm across typical and edge scenarios. All matrices and vectors are dimensionally consistent and scientifically plausible.\n\n- Test Case 1 (general case):\n  - $Q = \\begin{bmatrix} 4 & 1 & 0 \\\\ 1 & 3 & 0 \\\\ 0 & 0 & 2 \\end{bmatrix}$, $c = \\begin{bmatrix} -8 \\\\ -3 \\\\ -3 \\end{bmatrix}$\n  - $A = \\begin{bmatrix} 1 & 1 & 1 \\end{bmatrix}$, $b = \\begin{bmatrix} 1 \\end{bmatrix}$\n  - Initial penalty $\\mu_0 = 1.0$, growth factor $\\gamma = 4.0$, target reduction factor $\\rho = 0.7$, maximum penalty $\\mu_{\\text{max}} = 10^6$, constraint tolerance $\\varepsilon = 10^{-8}$, maximum outer iterations $K_{\\text{max}} = 20$.\n\n- Test Case 2 (weak initial penalty and aggressive growth):\n  - $Q = \\begin{bmatrix} 4 & 1 & 0 \\\\ 1 & 3 & 0 \\\\ 0 & 0 & 2 \\end{bmatrix}$, $c = \\begin{bmatrix} -8 \\\\ -3 \\\\ -3 \\end{bmatrix}$\n  - $A = \\begin{bmatrix} 1 & 1 & 1 \\end{bmatrix}$, $b = \\begin{bmatrix} 1 \\end{bmatrix}$\n  - Initial penalty $\\mu_0 = 0.01$, growth factor $\\gamma = 10.0$, target reduction factor $\\rho = 0.8$, maximum penalty $\\mu_{\\text{max}} = 10^5$, constraint tolerance $\\varepsilon = 10^{-8}$, maximum outer iterations $K_{\\text{max}} = 30$.\n\n- Test Case 3 (two constraints, stricter tolerance, moderate growth):\n  - $Q = \\begin{bmatrix} 10 & 2 & 0 \\\\ 2 & 5 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$, $c = \\begin{bmatrix} -3 \\\\ -4 \\\\ -1 \\end{bmatrix}$\n  - $A = \\begin{bmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{bmatrix}$, $b = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$\n  - Initial penalty $\\mu_0 = 0.1$, growth factor $\\gamma = 3.0$, target reduction factor $\\rho = 0.75$, maximum penalty $\\mu_{\\text{max}} = 10^5$, constraint tolerance $\\varepsilon = 10^{-10}$, maximum outer iterations $K_{\\text{max}} = 50$.\n\nFor each test case, your program must compute:\n- The final constraint violation $\\lVert A x_K - b \\rVert_2$ as a float.\n- The integer count of how many times the penalty parameter was increased.\n- The final penalty parameter $\\mu_K$ as a float.\n- A boolean indicating convergence, defined as $\\lVert A x_K - b \\rVert_2 \\le \\varepsilon$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a comma-separated list in square brackets. For example, the format must be exactly like \"[[result1_case1,result2_case1,result3_case1,result4_case1],[result1_case2,result2_case2,result3_case2,result4_case2],[result1_case3,result2_case3,result3_case3,result4_case3]]\". No spaces are permitted in the output line.",
            "solution": "The problem requires the design and implementation of a quadratic penalty method with an adaptive penalty parameter update scheme for solving equality-constrained quadratic optimization problems. The problem is valid, scientifically grounded, and well-posed. The objective function $f(x) = \\frac{1}{2} x^\\top Q x + c^\\top x$ is convex as $Q$ is symmetric positive definite, and the constraints $Ax=b$ are linear. These are standard assumptions for which penalty methods are well-suited.\n\n### 1. The Quadratic Penalty Method\n\nThe core principle of the penalty method is to approximate a constrained optimization problem by a sequence of unconstrained problems. For the given problem\n$$\n\\begin{aligned}\n\\text{minimize} & \\quad f(x) = \\frac{1}{2} x^\\top Q x + c^\\top x \\\\\n\\text{subject to} & \\quad Ax = b\n\\end{aligned}\n$$\nwe construct the penalized objective function $F_\\mu(x)$ parameterized by a penalty parameter $\\mu > 0$:\n$$\nF_\\mu(x) = f(x) + \\frac{\\mu}{2} \\lVert Ax - b \\rVert_2^2\n$$\nThe term $\\frac{\\mu}{2} \\lVert Ax - b \\rVert_2^2$ is the penalty term. It imposes a large cost for violating the constraints, and this cost increases with $\\mu$. As $\\mu \\to \\infty$, the minimizer of $F_\\mu(x)$ is expected to converge to the solution of the original constrained problem.\n\n### 2. Derivation of the Subproblem Solution\n\nFor a fixed $\\mu$, the penalized objective $F_\\mu(x)$ is a smooth, strictly convex function. Its unique minimizer, denoted $x(\\mu)$, can be found by setting its gradient to zero. First, we expand the expression for $F_\\mu(x)$:\n$$\nF_\\mu(x) = \\frac{1}{2} x^\\top Q x + c^\\top x + \\frac{\\mu}{2} (Ax - b)^\\top (Ax - b)\n$$\n$$\nF_\\mu(x) = \\frac{1}{2} x^\\top Q x + c^\\top x + \\frac{\\mu}{2} (x^\\top A^\\top A x - 2 b^\\top A x + b^\\top b)\n$$\nThe gradient, $\\nabla F_\\mu(x)$, is:\n$$\n\\nabla F_\\mu(x) = \\nabla_x \\left( \\frac{1}{2} x^\\top Q x + c^\\top x + \\frac{\\mu}{2} x^\\top A^\\top A x - \\mu b^\\top A x + \\frac{\\mu}{2} b^\\top b \\right)\n$$\n$$\n\\nabla F_\\mu(x) = Qx + c + \\mu A^\\top A x - \\mu A^\\top b\n$$\nSetting the gradient to zero gives the first-order stationarity condition:\n$$\n(Q + \\mu A^\\top A) x - (\\mu A^\\top b - c) = 0\n$$\nThis is a system of linear equations for the minimizer $x(\\mu)$:\n$$\n(Q + \\mu A^\\top A) x(\\mu) = \\mu A^\\top b - c\n$$\nThe matrix $H_\\mu = Q + \\mu A^\\top A$ is the Hessian of $F_\\mu(x)$. Since $Q$ is symmetric positive definite and $\\mu A^\\top A$ is symmetric positive semi-definite (as $A$ has full row rank), their sum $H_\\mu$ is symmetric positive definite for any $\\mu > 0$. This guarantees that the linear system has a unique solution, which can be computed efficiently using standard linear algebra solvers.\n\n### 3. Adaptive Penalty Parameter Update Scheme\n\nThe crux of the algorithm is to adaptively tune the sequence of penalty parameters $\\{\\mu_k\\}$ based on observed progress, rather than using a fixed, predetermined schedule. The primary measure of progress towards satisfying the constraints is the constraint violation, defined as $v_k = \\lVert A x_k - b \\rVert_2$, where $x_k = x(\\mu_k)$.\n\nAn effective adaptive strategy increases the penalty parameter only when the progress in reducing the constraint violation stalls. Let's define a target reduction factor $\\rho \\in (0, 1)$. At each iteration $k$, we compare the current violation $v_k$ with the violation from the previous iteration, $v_{k-1}$.\n- If $v_k < \\rho \\cdot v_{k-1}$, the progress is deemed sufficient. The penalty parameter has produced a satisfactory reduction in infeasibility. In this case, we can attempt the next iteration with the same penalty parameter, $\\mu_{k+1} = \\mu_k$.\n- If $v_k \\ge \\rho \\cdot v_{k-1}$, progress is insufficient. The current penalty parameter is not strong enough to drive the solution towards feasibility at the desired rate. Therefore, the penalty parameter is increased by a growth factor $\\gamma > 1$, i.e., $\\mu_{k+1} = \\gamma \\cdot \\mu_k$.\n\nThis logic, however, leads to stagnation. If we set $\\mu_{k+1} = \\mu_k$, then solving the subproblem yields $x_{k+1} = x_k$, which means $v_{k+1} = v_k$. In the subsequent check, $v_{k+1} \\ge \\rho \\cdot v_k$ will be true (since $\\rho < 1$), forcing an increase in $\\mu$. This results in an update schedule where $\\mu$ is held constant for at most one iteration.\n\nA more direct and principled adaptive strategy is as follows: At each iteration $k$, we assess the progress made since the last iteration. If the progress is unsatisfactory, we increase the penalty parameter for the current iteration. This can be formalized into the following algorithm:\n\n1.  **Initialization**: Start with an initial penalty $\\mu_0 > 0$, growth factor $\\gamma > 1$, target reduction factor $\\rho \\in (0, 1)$, maximum penalty $\\mu_{\\text{max}}$, constraint tolerance $\\varepsilon$, and maximum outer iterations $K_{\\text{max}}$. Initialize iteration counter $k=0$ and penalty increase counter `num_increases`$=0$. Initialize the previous violation $v_{\\text{prev}}$ to a very large number (e.g., infinity).\n\n2.  **Iterative Process**: For $k = 0, 1, 2, \\dots, K_{\\text{max}}-1$:\n    a. **Penalty Update Decision**: Compare the most recent violation $v_k$ (or $v_{\\text{prev}}$ in our implementation's state) with the target. If progress from the previous step was insufficient ($v_k \\ge \\rho \\cdot v_{k-1}$), increase the penalty parameter for the current step:\n       $\\mu_k = \\min(\\gamma \\cdot \\mu_{k-1}, \\mu_{\\text{max}})$. We must also handle the first iteration, where a comparison is not possible. A simple, robust rule is to check for insufficient progress and update `mu` *before* solving the subproblem in each iteration.\n\n    b. **Solve Subproblem**: Compute the minimizer $x_k$ for the current penalty parameter $\\mu_k$ by solving the linear system:\n       $x_k = (Q + \\mu_k A^\\top A)^{-1} (\\mu_k A^\\top b - c)$.\n\n    c. **Evaluate Progress**: Calculate the current constraint violation $v_k = \\lVert Ax_k - b \\rVert_2$.\n\n    d. **Check for Convergence**: If $v_k \\le \\varepsilon$, the solution is acceptably feasible. The algorithm terminates successfully.\n\n    e. **Prepare for Next Iteration**: Store the current violation $v_k$ as $v_{\\text{prev}}$ for the comparison in the next iteration.\n\n3.  **Termination**: The loop terminates if convergence is achieved or if the maximum number of iterations $K_{\\text{max}}$ is reached.\n\nThis design ensures that $\\mu$ is only increased when necessary, providing a balance between convergence speed and the numerical stability of solving the linear subproblem. The Hessian matrix $H_\\mu$ becomes increasingly ill-conditioned as $\\mu \\to \\infty$, so avoiding unnecessarily large values of $\\mu$ is crucial.\n\n### 4. Algorithmic Summary\n\nThe final algorithm is structured as follows:\n\n- **Inputs**: $Q, c, A, b, \\mu_0, \\gamma, \\rho, \\mu_{\\text{max}}, \\varepsilon, K_{\\text{max}}$.\n- **Outputs**: Final violation $v_K$, number of penalty increases, final penalty $\\mu_K$, convergence status.\n\n**Algorithm:**\n1. Initialize $\\mu \\leftarrow \\mu_0$, `num_increases` $\\leftarrow 0$, $v_{\\text{prev}} \\leftarrow \\infty$, `converged` $\\leftarrow$ `False`.\n2. For $k$ from $0$ to $K_{\\text{max}}-1$:\n   a. **Adaptive Update**: If $k > 0$ and $v_{\\text{curr}} \\ge \\rho \\cdot v_{\\text{prev}}$:\n      i. Let $\\mu_{\\text{new}} \\leftarrow \\min(\\gamma \\cdot \\mu, \\mu_{\\text{max}})$.\n      ii. If $\\mu_{\\text{new}} > \\mu$, set `num_increases` $\\leftarrow$ `num_increases` $+ 1$.\n      iii. Set $\\mu \\leftarrow \\mu_{\\text{new}}$.\n   b. **Store Previous State**: Set $v_{\\text{prev}} \\leftarrow v_{\\text{curr}}$ (if $k > 0$).\n   c. **Solve**:\n      i. $H_\\mu \\leftarrow Q + \\mu A^\\top A$.\n      ii. $d_\\mu \\leftarrow \\mu A^\\top b - c$.\n      iii. $x \\leftarrow H_\\mu^{-1} d_\\mu$.\n   d. **Evaluate**: $v_{\\text{curr}} \\leftarrow \\lVert Ax - b \\rVert_2$.\n   e. **Check Convergence**: If $v_{\\text{curr}} \\le \\varepsilon$:\n      i. `converged` $\\leftarrow$ `True`.\n      ii. Break loop.\n   f. **Handle first iteration**: If $k = 0$, set $v_{\\text{prev}} \\leftarrow v_{\\text{curr}}$.\n3. Return $v_{\\text{curr}}$, `num_increases`, $\\mu$, `converged`.\n\nThis detailed, principle-based algorithm will now be implemented.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_quadratic_penalty(params):\n    \"\"\"\n    Solves an equality-constrained quadratic program using the quadratic penalty method\n    with an adaptive penalty parameter update rule.\n\n    The problem is to minimize 0.5 * x.T @ Q @ x + c.T @ x subject to Ax = b.\n    \"\"\"\n    Q, c, A, b, mu0, gamma, rho, mu_max, epsilon, K_max = params\n\n    mu = mu0\n    num_increases = 0\n    # Use a value guaranteed to be larger than any initial violation\n    # to prevent a penalty increase on the first check.\n    prev_violation = np.inf\n    converged = False\n    \n    x = None\n    current_violation = np.inf\n\n    for k in range(K_max):\n        # Decide on the penalty parameter for this iteration based on previous progress.\n        # This check determines if the progress from the previous step was sufficient.\n        if current_violation >= rho * prev_violation:\n            # If progress is insufficient, increase the penalty parameter.\n            next_mu = min(gamma * mu, mu_max)\n            if next_mu > mu:\n                num_increases += 1\n            mu = next_mu\n\n        # Solve the unconstrained penalized subproblem: (Q + mu*A.T*A)x = mu*A.T*b - c\n        H_mu = Q + mu * A.T @ A\n        d_mu = mu * A.T @ b - c\n        \n        try:\n            x = np.linalg.solve(H_mu, d_mu)\n        except np.linalg.LinAlgError:\n            # If the matrix becomes singular/ill-conditioned, terminate.\n            # This indicates a failure of the method, likely due to extreme mu.\n            break\n\n        # Update state for the next iteration.\n        prev_violation = current_violation\n        current_violation = np.linalg.norm(A @ x - b)\n        \n        # Check for convergence.\n        if current_violation <= epsilon:\n            converged = True\n            break\n            \n    # The loop terminates, return the final state.\n    return [current_violation, num_increases, mu, converged]\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the solver.\n    \"\"\"\n    # Test Case 1 (general case):\n    test_case_1 = (\n        np.array([[4, 1, 0], [1, 3, 0], [0, 0, 2]]),\n        np.array([-8, -3, -3]),\n        np.array([[1, 1, 1]]),\n        np.array([1]),\n        1.0, 4.0, 0.7, 1e6, 1e-8, 20\n    )\n\n    # Test Case 2 (weak initial penalty and aggressive growth):\n    test_case_2 = (\n        np.array([[4, 1, 0], [1, 3, 0], [0, 0, 2]]),\n        np.array([-8, -3, -3]),\n        np.array([[1, 1, 1]]),\n        np.array([1]),\n        0.01, 10.0, 0.8, 1e5, 1e-8, 30\n    )\n\n    # Test Case 3 (two constraints, stricter tolerance, moderate growth):\n    test_case_3 = (\n        np.array([[10, 2, 0], [2, 5, 0], [0, 0, 1]]),\n        np.array([-3, -4, -1]),\n        np.array([[1, 0, 1], [0, 1, 1]]),\n        np.array([1, 1]),\n        0.1, 3.0, 0.75, 1e5, 1e-10, 50\n    )\n\n    test_cases = [test_case_1, test_case_2, test_case_3]\n\n    results = []\n    for case in test_cases:\n        result = solve_quadratic_penalty(case)\n        results.append(result)\n\n    # Format the final output string exactly as specified.\n    outer_list_str = []\n    for res_list in results:\n        # Convert each item in the inner list to a string.\n        # Booleans are automatically converted to 'True'/'False'.\n        inner_list_str = ','.join(map(str, res_list))\n        outer_list_str.append(f\"[{inner_list_str}]\")\n    \n    final_output = f\"[{','.join(outer_list_str)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "The standard quadratic penalty method has a significant drawback: as the penalty parameter $\\rho$ becomes large, the Hessian matrix of the penalized objective becomes increasingly ill-conditioned, leading to numerical errors. This practice introduces a powerful enhancement, the Augmented Lagrangian method, which avoids this issue. By implementing both the standard penalty method and the Augmented Lagrangian method to solve the same ill-conditioned problem, you will directly compare their performance and understand why the Augmented Lagrangian is a cornerstone of modern constrained optimization .",
            "id": "3261582",
            "problem": "Consider the equality-constrained optimization problem in $2$-dimensional Euclidean space:\n$$\n\\min_{x \\in \\mathbb{R}^2} \\; f(x) \\quad \\text{subject to} \\quad c(x) = a^\\top x - b = 0,\n$$\nwhere $f(x) = \\tfrac{1}{2} x^\\top Q x$, the matrix $Q \\in \\mathbb{R}^{2 \\times 2}$ is ill-conditioned, $a \\in \\mathbb{R}^2$, and $b \\in \\mathbb{R}$. The ill-conditioning is introduced by taking $Q$ to be diagonal with entries that differ by several orders of magnitude. The constraint is linear and specified by the vector $a$ and the scalar $b$. You will implement and compare two methods: the standard quadratic penalty method and the augmented Lagrangian method.\n\nStarting from the fundamental definition of the quadratic penalty method, construct the sequence of unconstrained minimization problems\n$$\n\\min_{x \\in \\mathbb{R}^2} \\; f(x) + \\tfrac{\\rho}{2} \\, c(x)^2,\n$$\nin which the penalty parameter $\\rho$ is increased when the constraint violation $|c(x)|$ is not within a prescribed tolerance. For each fixed $\\rho$, perform the inner unconstrained minimization exactly by solving the first-order optimality condition, which yields a symmetric positive definite (SPD) linear system. Continue increasing $\\rho$ geometrically until the constraint violation is below the tolerance or a maximum number of outer iterations is reached. Record the number of outer iterations required, the final constraint violation $|c(x)|$, and the final objective value $f(x)$.\n\nStarting from the fundamental definition of the augmented Lagrangian method, construct the sequence of unconstrained minimization problems\n$$\n\\min_{x \\in \\mathbb{R}^2} \\; f(x) + \\lambda \\, c(x) + \\tfrac{\\mu}{2} \\, c(x)^2,\n$$\nwith a Lagrange multiplier estimate $\\lambda$ and a penalty parameter $\\mu$. For each fixed $(\\lambda, \\mu)$, perform the inner unconstrained minimization exactly by solving the first-order optimality condition, which yields a symmetric positive definite linear system. After obtaining the minimizer, update the Lagrange multiplier using the classical rule derived from the method of multipliers and adjust $\\mu$ geometrically if the constraint violation does not decrease sufficiently. Terminate when the constraint violation $|c(x)|$ is within the tolerance or a maximum number of outer iterations is reached. Record the number of outer iterations required, the final constraint violation $|c(x)|$, and the final objective value $f(x)$.\n\nImplement both methods to solve the problem with the following fixed data:\n- The matrix is $Q = \\operatorname{diag}(q_1, q_2)$.\n- The constraint is defined by $a = [1, 1]^\\top$ and $b = 1$.\n\nImplement the program to process the following test suite. Each test case specifies $(q_1, q_2)$, penalty-method parameters $(\\rho_0, \\gamma_\\rho)$, augmented-Lagrangian parameters $(\\mu_0, \\gamma_\\mu)$, and the tolerance:\n- Test case $1$ (very ill-conditioned):\n  - $q_1 = 10^{-6}$, $q_2 = 1$,\n  - penalty method: initial $\\rho_0 = 1$, geometric factor $\\gamma_\\rho = 10$,\n  - augmented Lagrangian: initial $\\mu_0 = 1$, geometric factor $\\gamma_\\mu = 2$,\n  - tolerance $\\text{tol} = 10^{-8}$.\n- Test case $2$ (moderately ill-conditioned):\n  - $q_1 = 10^{-4}$, $q_2 = 1$,\n  - penalty method: initial $\\rho_0 = 10^{-1}$, geometric factor $\\gamma_\\rho = 5$,\n  - augmented Lagrangian: initial $\\mu_0 = \\tfrac{1}{2}$, geometric factor $\\gamma_\\mu = 2$,\n  - tolerance $\\text{tol} = 10^{-6}$.\n- Test case $3$ (extremely ill-conditioned):\n  - $q_1 = 10^{-8}$, $q_2 = 1$,\n  - penalty method: initial $\\rho_0 = 10^{-3}$, geometric factor $\\gamma_\\rho = 10$,\n  - augmented Lagrangian: initial $\\mu_0 = \\tfrac{1}{2}$, geometric factor $\\gamma_\\mu = 3$,\n  - tolerance $\\text{tol} = 10^{-10}$.\n\nFor each test case, your program must:\n- Run the penalty method and report $(N_P, V_P, F_P)$ where $N_P$ is the number of outer iterations, $V_P$ is the final constraint violation $|c(x)|$, and $F_P$ is the final objective $f(x)$.\n- Run the augmented Lagrangian method and report $(N_A, V_A, F_A)$ with analogous definitions.\n\nDesign choices:\n- For the inner solves, use exact solutions obtained from the first-order optimality conditions, resulting in SPD linear systems of dimension $2$.\n- Use a maximum of $100$ outer iterations for each method to avoid infinite loops.\n- Use a geometric update rule for $\\rho$ and $\\mu$ with the specified factors.\n- For the augmented Lagrangian, update $\\lambda$ using the classical method-of-multipliers rule and increase $\\mu$ only when the constraint violation does not decrease sufficiently compared to the previous iteration.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The outer list must contain one inner list per test case, each inner list ordered as $[N_P,N_A,V_P,V_A,F_P,F_A]$. For example, the final output format must be:\n$$\n\\big[ \\, [N_P^{(1)},N_A^{(1)},V_P^{(1)},V_A^{(1)},F_P^{(1)},F_A^{(1)}], \\; [N_P^{(2)},N_A^{(2)},V_P^{(2)},V_A^{(2)},F_P^{(2)},F_A^{(2)}], \\; [N_P^{(3)},N_A^{(3)},V_P^{(3)},V_A^{(3)},F_P^{(3)},F_A^{(3)}] \\, \\big].\n$$\nAll reported values must be real numbers or integers, with no physical units required, and angles are not involved.",
            "solution": "The user has provided a well-posed problem in constrained optimization. The problem is scientifically grounded, objective, and contains all necessary information for its solution. Therefore, it is deemed valid.\n\nThe problem requires solving an equality-constrained quadratic program (QP) using two distinct methods: the quadratic penalty method and the augmented Lagrangian method. We will analyze each method, derive the necessary equations for implementation, and then present the algorithm.\n\nThe optimization problem is defined as:\n$$\n\\min_{x \\in \\mathbb{R}^2} \\; f(x) = \\frac{1}{2} x^\\top Q x\n$$\n$$\n\\text{subject to} \\quad c(x) = a^\\top x - b = 0\n$$\nwhere $x = [x_1, x_2]^\\top$, $Q = \\operatorname{diag}(q_1, q_2)$ is a positive definite but ill-conditioned matrix, $a = [1, 1]^\\top$, and $b = 1$.\n\n### The Quadratic Penalty Method\n\nThis method transforms the constrained problem into a sequence of unconstrained problems by adding a penalty term to the objective function that penalizes constraint violations. The penalized objective function for a given penalty parameter $\\rho > 0$ is:\n$$\nP(x; \\rho) = f(x) + \\frac{\\rho}{2} c(x)^2 = \\frac{1}{2} x^\\top Q x + \\frac{\\rho}{2} (a^\\top x - b)^2\n$$\nFor a fixed $\\rho_k$ at outer iteration $k$, we find the minimizer $x_{k+1}$ by solving the unconstrained problem $\\min_x P(x; \\rho_k)$. The first-order optimality condition is $\\nabla_x P(x; \\rho_k) = 0$. The gradient is:\n$$\n\\nabla_x P(x; \\rho_k) = \\nabla f(x) + \\rho_k c(x) \\nabla c(x) = Qx + \\rho_k (a^\\top x - b) a\n$$\nSetting the gradient to zero yields:\n$$\nQx + \\rho_k (a^\\top x) a - \\rho_k b a = 0\n$$\nThis can be rearranged into a linear system of equations for $x$:\n$$\n(Q + \\rho_k a a^\\top) x = \\rho_k b a\n$$\nThe matrix $H_P(\\rho_k) = Q + \\rho_k a a^\\top$ is the Hessian of the penalty function $P(x; \\rho_k)$. Since $Q$ is positive definite and $a a^\\top$ is positive semidefinite, $H_P(\\rho_k)$ is symmetric and positive definite (SPD) for any $\\rho_k > 0$. At each step of the outer loop, we solve this $2 \\times 2$ linear system for $x_{k+1}$. The penalty parameter is then increased, i.e., $\\rho_{k+1} = \\gamma_\\rho \\rho_k$ with $\\gamma_\\rho > 1$, and the process is repeated.\n\nThe method terminates when the constraint violation, $|c(x_{k+1})| = |a^\\top x_{k+1} - b|$, falls below a specified tolerance $\\text{tol}$. A known deficiency of this method is that as $\\rho_k \\to \\infty$ (which is required for $c(x) \\to 0$), the condition number of the Hessian $H_P(\\rho_k)$ grows without bound, leading to a numerically ill-conditioned linear system.\n\n### The Augmented Lagrangian Method\n\nThis method, also known as the method of multipliers, enhances the simple penalty approach by adding an estimate of the Lagrange multiplier to the objective. This typically results in better convergence properties and avoids the need for the penalty parameter to go to infinity. The unconstrained subproblem involves minimizing the augmented Lagrangian:\n$$\n\\mathcal{L}_A(x, \\lambda; \\mu) = f(x) + \\lambda c(x) + \\frac{\\mu}{2} c(x)^2\n$$\nwhere $\\lambda$ is the Lagrange multiplier estimate and $\\mu > 0$ is a penalty parameter. At outer iteration $k$, we use the current estimates $\\lambda_k$ and $\\mu_k$ to find the next iterate $x_{k+1}$ by solving $\\min_x \\mathcal{L}_A(x, \\lambda_k; \\mu_k)$. The first-order optimality condition is $\\nabla_x \\mathcal{L}_A(x, \\lambda_k; \\mu_k) = 0$:\n$$\n\\nabla_x \\mathcal{L}_A = \\nabla f(x) + \\lambda_k \\nabla c(x) + \\mu_k c(x) \\nabla c(x) = Qx + \\lambda_k a + \\mu_k (a^\\top x - b) a\n$$\nSetting the gradient to zero and rearranging gives the linear system:\n$$\n(Q + \\mu_k a a^\\top) x = (\\mu_k b - \\lambda_k) a\n$$\nThe Hessian matrix $H_A(\\mu_k) = Q + \\mu_k a a^\\top$ is structurally identical to that of the penalty method and is also SPD. After solving for $x_{k+1}$, the Lagrange multiplier estimate is updated using the rule:\n$$\n\\lambda_{k+1} = \\lambda_k + \\mu_k c(x_{k+1})\n$$\nThe penalty parameter $\\mu_k$ does not need to go to infinity. It only needs to be large enough to make the Hessian of the augmented Lagrangian positive definite in the vicinity of the solution, which is already guaranteed here since $Q$ is positive definite. In practice, $\\mu_k$ is increased if the reduction in constraint violation is not sufficient. We will adopt the rule that if $|c(x_{k+1})| > 0.25 |c(x_k)|$ for $k>0$, we update $\\mu_{k+1} = \\gamma_\\mu \\mu_k$; otherwise, $\\mu_{k+1} = \\mu_k$. This strategy allows the method to converge to a feasible and optimal solution under much milder conditions on the penalty parameter, thus circumventing the severe ill-conditioning inherent in the quadratic penalty method.\n\n### Algorithmic Implementation\n\nFor both methods, we implement an outer loop that iteratively refines the solution. Each outer iteration involves constructing and solving a $2 \\times 2$ SPD linear system. The loop terminates when the constraint violation $|c(x)|$ is below the tolerance $\\text{tol}$ or a maximum of $100$ iterations is reached.\n\nFor the given problem parameters $a = [1, 1]^\\top$ and $b=1$, the matrices $H_P$ and $H_A$ are:\n$$\nH_P(\\rho_k) = \\begin{pmatrix} q_1 + \\rho_k & \\rho_k \\\\ \\rho_k & q_2 + \\rho_k \\end{pmatrix}, \\quad H_A(\\mu_k) = \\begin{pmatrix} q_1 + \\mu_k & \\mu_k \\\\ \\mu_k & q_2 + \\mu_k \\end{pmatrix}\n$$\nThe right-hand side vectors are:\n$$\nd_P = \\rho_k b a = \\begin{pmatrix} \\rho_k \\\\ \\rho_k \\end{pmatrix}, \\quad d_A = (\\mu_k b - \\lambda_k) a = \\begin{pmatrix} \\mu_k - \\lambda_k \\\\ \\mu_k - \\lambda_k \\end{pmatrix}\n$$\nThe implementation will process the three specified test cases, reporting the number of iterations ($N$), final constraint violation ($V$), and final objective value ($F$) for both the penalty ($P$) and augmented Lagrangian ($A$) methods.",
            "answer": "```python\nimport numpy as np\n\ndef penalty_method(Q, a, b, rho0, gamma_rho, tol, max_iter):\n    \"\"\"\n    Solves a constrained QP using the quadratic penalty method.\n    \"\"\"\n    rho = rho0\n    x = np.zeros(a.shape)\n    \n    for k in range(max_iter):\n        # Form the Hessian and the right-hand side of the linear system\n        H = Q + rho * np.outer(a, a)\n        d = rho * b * a\n        \n        try:\n            x = np.linalg.solve(H, d)\n        except np.linalg.LinAlgError:\n            # This should not occur with the given problem structure (SPD Hessian)\n            return max_iter, np.inf, np.inf\n\n        # Calculate constraint violation\n        violation = np.abs(np.dot(a, x) - b)\n        \n        # Check for convergence\n        if violation < tol:\n            obj_val = 0.5 * np.dot(x, Q @ x)\n            return k + 1, violation, obj_val\n        \n        # Update the penalty parameter\n        rho *= gamma_rho\n        \n    # If max_iter is reached\n    obj_val = 0.5 * np.dot(x, Q @ x)\n    violation = np.abs(np.dot(a, x) - b)\n    return max_iter, violation, obj_val\n\ndef augmented_lagrangian_method(Q, a, b, mu0, gamma_mu, tol, max_iter):\n    \"\"\"\n    Solves a constrained QP using the augmented Lagrangian method.\n    \"\"\"\n    mu = mu0\n    lambda_ = 0.0  # Lagrange multiplier estimate\n    x = np.zeros(a.shape)\n    prev_violation = np.inf\n    \n    for k in range(max_iter):\n        # Form the Hessian and the right-hand side of the linear system\n        H = Q + mu * np.outer(a, a)\n        d = (mu * b - lambda_) * a\n        \n        try:\n            x = np.linalg.solve(H, d)\n        except np.linalg.LinAlgError:\n            return max_iter, np.inf, np.inf\n        \n        # Calculate constraint violation\n        c_x = np.dot(a, x) - b\n        violation = np.abs(c_x)\n        \n        # Check for convergence\n        if violation < tol:\n            obj_val = 0.5 * np.dot(x, Q @ x)\n            return k + 1, violation, obj_val\n        \n        # Update mu if constraint violation does not decrease sufficiently\n        if k > 0 and violation > 0.25 * prev_violation:\n            mu *= gamma_mu\n        \n        # Update lambda\n        lambda_ += mu * c_x\n        \n        prev_violation = violation\n        \n    # If max_iter is reached\n    obj_val = 0.5 * np.dot(x, Q @ x)\n    violation = np.abs(np.dot(a, x) - b)\n    return max_iter, violation, obj_val\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (very ill-conditioned)\n        {'q1': 1e-6, 'q2': 1.0, 'rho0': 1.0, 'gamma_rho': 10.0, 'mu0': 1.0, 'gamma_mu': 2.0, 'tol': 1e-8},\n        # Test case 2 (moderately ill-conditioned)\n        {'q1': 1e-4, 'q2': 1.0, 'rho0': 0.1, 'gamma_rho': 5.0, 'mu0': 0.5, 'gamma_mu': 2.0, 'tol': 1e-6},\n        # Test case 3 (extremely ill-conditioned)\n        {'q1': 1e-8, 'q2': 1.0, 'rho0': 1e-3, 'gamma_rho': 10.0, 'mu0': 0.5, 'gamma_mu': 3.0, 'tol': 1e-10}\n    ]\n    \n    a = np.array([1.0, 1.0])\n    b = 1.0\n    max_iter = 100\n    \n    all_results = []\n    \n    for case in test_cases:\n        Q = np.diag([case['q1'], case['q2']])\n        \n        # Run Penalty Method\n        Np, Vp, Fp = penalty_method(Q, a, b, case['rho0'], case['gamma_rho'], case['tol'], max_iter)\n        \n        # Run Augmented Lagrangian Method\n        Na, Va, Fa = augmented_lagrangian_method(Q, a, b, case['mu0'], case['gamma_mu'], case['tol'], max_iter)\n        \n        case_results = [Np, Na, Vp, Va, Fp, Fa]\n        all_results.append(case_results)\n\n    # Format the output string as a list of lists\n    inner_strings = []\n    for res in all_results:\n        # Format each number to string\n        inner_strings.append(f\"[{','.join(map(str, res))}]\")\n    output_str = f\"[{','.join(inner_strings)}]\"\n    \n    print(output_str)\n\nsolve()\n```"
        }
    ]
}