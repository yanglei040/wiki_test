{
    "hands_on_practices": [
        {
            "introduction": "Many real-world optimization problems involve more than a single constraint. This practice extends the basic Lagrange multiplier method to a scenario with two distinct equality constraints, a common situation in engineering and physics. By seeking to minimize the surface area of a cylinder with both a fixed volume and a specific design rule for its shape , you will learn how to construct a Lagrangian with multiple multipliers and solve the expanded system of optimality conditions.",
            "id": "3251810",
            "problem": "A closed right circular cylinder has radius $r$ and height $h$. Its total surface area is $S(r,h) = 2\\pi r h + 2\\pi r^{2}$ and its volume is $V(r,h) = \\pi r^{2} h$. Suppose an engineering design mandates a non-linear constraint on the aspect ratio $x = h/r$ of the form $x + \\frac{1}{x} = \\kappa$, where $\\kappa$ is a prescribed constant. Assume $V  0$, $\\kappa  2$, and $r  0$, $h  0$, so that the constraints are feasible and physically meaningful.\n\nStarting from the fundamental geometric formulas for $S(r,h)$ and $V(r,h)$ and the method of Lagrange multipliers for equality-constrained optimization, determine the minimal achievable total surface area $S_{\\min}$ of the cylinder subject to the two equality constraints $V(r,h) = V$ and $x + \\frac{1}{x} = \\kappa$. Express your final answer as a closed-form analytic expression in terms of $V$ and $\\kappa$. No numerical rounding is required, and no units should be included in the final expression.",
            "solution": "The problem is to minimize the surface area of a cylinder, $S(r,h) = 2\\pi r h + 2\\pi r^2$, subject to two constraints on its radius $r$ and height $h$:\n1. A fixed volume: $\\pi r^2 h = V$, for a constant $V > 0$.\n2. A fixed aspect ratio property: $\\frac{h}{r} + \\frac{r}{h} = \\kappa$, for a constant $\\kappa > 2$.\n\nThis problem can be solved without explicitly using Lagrange multipliers by first using the constraints to reduce the objective function to a function of a single variable. Let the aspect ratio be $x = h/r$.\n\nThe second constraint can be rewritten as a quadratic equation for the aspect ratio $x$:\n$$ x + \\frac{1}{x} = \\kappa \\implies x^2 - \\kappa x + 1 = 0 $$\nThe roots of this equation determine the possible aspect ratios for the cylinder:\n$$ x = \\frac{\\kappa \\pm \\sqrt{\\kappa^2 - 4}}{2} $$\nSince $\\kappa > 2$, there are two distinct, real, and positive roots. Let's call them $x_1$ and $x_2$:\n$$ x_1 = \\frac{\\kappa + \\sqrt{\\kappa^2 - 4}}{2} \\quad \\text{and} \\quad x_2 = \\frac{\\kappa - \\sqrt{\\kappa^2 - 4}}{2} $$\nNote that $x_1 > 1$ and $x_2 = 1/x_1$, so $0  x_2  1$.\n\nNext, we express the surface area $S$ as a function of the aspect ratio $x$. From the volume constraint, $h = V/(\\pi r^2)$. Substituting $h = xr$ into this gives $xr = V/(\\pi r^2)$, which can be solved for $r$:\n$$ r^3 = \\frac{V}{\\pi x} \\implies r = \\left(\\frac{V}{\\pi x}\\right)^{1/3} $$\nNow substitute this expression for $r$ into the surface area formula, which can be written as $S = 2\\pi r^2(1+x)$:\n$$ S(x) = 2\\pi \\left(\\left(\\frac{V}{\\pi x}\\right)^{1/3}\\right)^2 (1+x) = 2\\pi \\left(\\frac{V}{\\pi x}\\right)^{2/3} (1+x) $$\n$$ S(x) = 2\\pi \\frac{V^{2/3}}{\\pi^{2/3} x^{2/3}} (1+x) = 2\\pi^{1/3}V^{2/3} \\frac{1+x}{x^{2/3}} $$\nTo find the minimum surface area, we must compare the value of $S(x)$ at the two possible aspect ratios, $x_1$ and $x_2$. This is equivalent to comparing the values of the function $f(x) = \\frac{1+x}{x^{2/3}}$ at $x_1$ and $x_2$.\n\nLet's evaluate $f(x)$ for both roots:\n$$ f(x_1) = \\frac{1+x_1}{x_1^{2/3}} $$\n$$ f(x_2) = f(1/x_1) = \\frac{1 + 1/x_1}{(1/x_1)^{2/3}} = \\frac{(x_1+1)/x_1}{x_1^{-2/3}} = \\frac{1+x_1}{x_1^{1-2/3}} = \\frac{1+x_1}{x_1^{1/3}} $$\nNow we compare $f(x_1)$ and $f(x_2)$. Since $\\kappa > 2$, we know $x_1 > 1$. For any value greater than 1, $x_1^{2/3} > x_1^{1/3}$. As these terms are positive and in the denominator of the expressions for $f(x_1)$ and $f(x_2)$, their reciprocals are related by $\\frac{1}{x_1^{2/3}}  \\frac{1}{x_1^{1/3}}$.\nTherefore, it follows that $f(x_1)  f(x_2)$.\n\nThe minimal surface area $S_{\\min}$ is achieved at the larger aspect ratio, $x = x_1$. The final expression for $S_{\\min}$ is obtained by substituting $x_1$ back into the function $S(x)$:\n$$ S_{\\min} = 2\\pi^{1/3}V^{2/3} \\frac{1 + x_1}{x_1^{2/3}} $$\nSubstituting the expression for $x_1$ in terms of $\\kappa$ gives the final answer:\n$$ S_{\\min} = 2\\pi^{1/3}V^{2/3} \\frac{1 + \\frac{\\kappa + \\sqrt{\\kappa^2-4}}{2}}{\\left(\\frac{\\kappa + \\sqrt{\\kappa^2-4}}{2}\\right)^{2/3}} $$",
            "answer": "$$\\boxed{2\\pi^{1/3}V^{2/3} \\frac{1 + \\frac{\\kappa + \\sqrt{\\kappa^2-4}}{2}}{\\left(\\frac{\\kappa + \\sqrt{\\kappa^2-4}}{2}\\right)^{2/3}}}$$"
        },
        {
            "introduction": "Optimization problems are often bounded not by exact equalities, but by inequalities representing physical limits or available resources. This is where the Karush-Kuhn-Tucker (KKT) conditions become essential, extending the Lagrange multiplier framework to handle constraints of the form $g(x) \\le 0$. In this geometric challenge , you will translate the problem of fitting the largest possible ellipse inside a square into a set of algebraic inequalities and use the full power of the KKT conditions—especially dual feasibility and complementary slackness—to find the optimal solution.",
            "id": "3251729",
            "problem": "Consider the family of axis-aligned ellipses parameterized by semi-axes and center,\n$$\n\\mathcal{E}(a,b,h,k) \\;=\\; \\left\\{ (x,y) \\in \\mathbb{R}^{2} \\;:\\; \\frac{(x-h)^{2}}{a^{2}} + \\frac{(y-k)^{2}}{b^{2}} \\le 1 \\right\\},\n$$\nwith $a0$, $b0$, $h \\in \\mathbb{R}$, and $k \\in \\mathbb{R}$. Let the unit square be\n$$\n\\mathcal{S} \\;=\\; [0,1] \\times [0,1].\n$$\nAmong all such ellipses that are entirely contained in $\\mathcal{S}$, determine the maximal possible area. Formulate the problem as a constrained optimization using the method of Lagrange multipliers for inequality constraints (Karush–Kuhn–Tucker conditions), starting only from the defining containment requirements for $\\mathcal{E}(a,b,h,k) \\subset \\mathcal{S}$ and the geometric formula for the area of an ellipse. Derive the necessary optimality conditions and solve them to obtain the maximal area. Provide your final answer as an exact expression, with no rounding.",
            "solution": "The problem asks for the maximal area of an axis-aligned ellipse that is fully contained within the unit square $\\mathcal{S} = [0,1] \\times [0,1]$.\n\nFirst, we must formulate this as a constrained optimization problem. The variables are the semi-axes $a$ and $b$, and the center coordinates $(h,k)$ of the ellipse $\\mathcal{E}(a,b,h,k)$. The problem statement specifies $a0$ and $b0$.\n\nThe objective function to be maximized is the area of the ellipse, given by the formula $A(a,b) = \\pi ab$. Maximizing $\\pi ab$ is equivalent to maximizing the product $ab$, since $\\pi$ is a positive constant. Let our objective function be $f(a,b,h,k) = ab$.\n\nNext, we must translate the geometric containment constraint $\\mathcal{E}(a,b,h,k) \\subset \\mathcal{S}$ into a set of algebraic inequalities. An ellipse is defined by $\\frac{(x-h)^2}{a^2} + \\frac{(y-k)^2}{b^2} \\le 1$. The horizontal extent of the ellipse is given by the interval $[h-a, h+a]$, and its vertical extent is given by $[k-b, k+b]$. For the ellipse to be contained in the unit square $\\mathcal{S} = [0,1] \\times [0,1]$, these intervals must be subsets of $[0,1]$.\n\nThe containment condition for the x-axis is $[h-a, h+a] \\subseteq [0,1]$, which yields two inequalities:\n1. $h-a \\ge 0$\n2. $h+a \\le 1$\n\nThe containment condition for the y-axis is $[k-b, k+b] \\subseteq [0,1]$, which yields another two inequalities:\n3. $k-b \\ge 0$\n4. $k+b \\le 1$\n\nWe will use the Karush-Kuhn-Tucker (KKT) conditions to solve this problem. The standard formulation is for a minimization problem with constraints of the form $g_i(\\mathbf{x}) \\le 0$. Maximizing $ab$ is equivalent to minimizing $-ab$. The constraints can be written as:\n$c_1(a,h) = a-h \\le 0$\n$c_2(a,h) = a+h-1 \\le 0$\n$c_3(b,k) = b-k \\le 0$\n$c_4(b,k) = b+k-1 \\le 0$\n\nThe optimization problem is thus:\nMinimize $F(a,b,h,k) = -ab$\nsubject to $c_1, c_2, c_3, c_4 \\le 0$, and implicit constraints $a0, b0$.\n\nThe Lagrangian function is:\n$$ \\mathcal{L}(a,b,h,k, \\mu_1, \\mu_2, \\mu_3, \\mu_4) = -ab + \\mu_1(a-h) + \\mu_2(a+h-1) + \\mu_3(b-k) + \\mu_4(b+k-1) $$\nwhere $\\mu_1, \\mu_2, \\mu_3, \\mu_4$ are the Lagrange multipliers.\n\nThe KKT conditions for an optimal solution $(a^*,b^*,h^*,k^*)$ are:\n1.  **Stationarity**: The gradient of the Lagrangian with respect to the variables $a,b,h,k$ must be zero.\n    $$ \\frac{\\partial \\mathcal{L}}{\\partial a} = -b + \\mu_1 + \\mu_2 = 0 \\implies b = \\mu_1 + \\mu_2 $$\n    $$ \\frac{\\partial \\mathcal{L}}{\\partial b} = -a + \\mu_3 + \\mu_4 = 0 \\implies a = \\mu_3 + \\mu_4 $$\n    $$ \\frac{\\partial \\mathcal{L}}{\\partial h} = -\\mu_1 + \\mu_2 = 0 \\implies \\mu_1 = \\mu_2 $$\n    $$ \\frac{\\partial \\mathcal{L}}{\\partial k} = -\\mu_3 + \\mu_4 = 0 \\implies \\mu_3 = \\mu_4 $$\n\n2.  **Primal Feasibility**: The constraints must be satisfied.\n    $$ a-h \\le 0 $$\n    $$ a+h-1 \\le 0 $$\n    $$ b-k \\le 0 $$\n    $$ b+k-1 \\le 0 $$\n\n3.  **Dual Feasibility**: The Lagrange multipliers for inequality constraints must be non-negative.\n    $$ \\mu_1, \\mu_2, \\mu_3, \\mu_4 \\ge 0 $$\n\n4.  **Complementary Slackness**: The product of each multiplier and its corresponding constraint must be zero.\n    $$ \\mu_1(a-h) = 0 $$\n    $$ \\mu_2(a+h-1) = 0 $$\n    $$ \\mu_3(b-k) = 0 $$\n    $$ \\mu_4(b+k-1) = 0 $$\n\nWe now solve this system of equations and inequalities.\nFrom the stationarity conditions, we have $\\mu_1 = \\mu_2$ and $\\mu_3 = \\mu_4$. Substituting these into the first two stationarity equations gives:\n$$ b = 2\\mu_1 $$\n$$ a = 2\\mu_3 $$\n\nWe seek to maximize the area, so we are not interested in the trivial solution where $a=0$ or $b=0$, as this yields an area of $0$. We must have $a  0$ and $b  0$.\nIf $a  0$, then $a = 2\\mu_3  0$, which implies $\\mu_3  0$. Since $\\mu_3 = \\mu_4$, we have $\\mu_4  0$.\nIf $b  0$, then $b = 2\\mu_1  0$, which implies $\\mu_1  0$. Since $\\mu_1 = \\mu_2$, we have $\\mu_2  0$.\nThus, for a solution with non-zero area, all Lagrange multipliers must be strictly positive: $\\mu_1, \\mu_2, \\mu_3, \\mu_4  0$.\n\nNow we apply the complementary slackness conditions. Since all multipliers are non-zero, their corresponding constraint functions must be equal to zero. This means all four inequality constraints must be active (i.e., hold with equality):\n1.  $a-h = 0 \\implies a = h$\n2.  $a+h-1 = 0$\n3.  $b-k = 0 \\implies b = k$\n4.  $b+k-1 = 0$\n\nWe now have a system of four linear equations for the four variables $a,b,h,k$.\nFrom the first pair of equations, substitute $h=a$ into $a+h-1=0$:\n$$ a+a-1 = 0 \\implies 2a = 1 \\implies a = \\frac{1}{2} $$\nSince $h=a$, we have $h = \\frac{1}{2}$.\n\nFrom the second pair of equations, substitute $k=b$ into $b+k-1=0$:\n$$ b+b-1 = 0 \\implies 2b = 1 \\implies b = \\frac{1}{2} $$\nSince $k=b$, we have $k = \\frac{1}{2}$.\n\nThe unique solution satisfying the KKT conditions for a non-zero area is $(a,b,h,k) = (\\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2})$. This represents a circle of radius $\\frac{1}{2}$ centered at $(\\frac{1}{2}, \\frac{1}{2})$.\nLet's verify this solution. The parameters $a=\\frac{1}{2}, b=\\frac{1}{2}$ are positive. The constraints are all met with equality, so primal feasibility is satisfied. The multipliers are $b = 2\\mu_1 \\implies \\frac{1}{2} = 2\\mu_1 \\implies \\mu_1 = \\frac{1}{4}$, and $a = 2\\mu_3 \\implies \\frac{1}{2} = 2\\mu_3 \\implies \\mu_3 = \\frac{1}{4}$. Thus, $\\mu_1=\\mu_2=\\mu_3=\\mu_4=\\frac{1}{4}$, which are all non-negative, satisfying dual feasibility. All KKT conditions are met.\n\nThe feasible region for the variables is convex, but the objective function $F=-ab$ is not convex. However, we can argue for global optimality by examining the constraints. The inequalities $a-h \\le 0$ and $a+h-1 \\le 0$ imply $a \\le h$ and $h \\le 1-a$. This requires $a \\le 1-a$, which simplifies to $2a \\le 1$ or $a \\le \\frac{1}{2}$. Similarly, the inequalities for $b$ and $k$ imply $b \\le \\frac{1}{2}$. Since we wish to maximize $ab$ for $a0, b0$, and the function $ab$ is strictly increasing in $a$ and $b$ on this domain, the maximum value must occur at the upper bounds of the feasible region for $a$ and $b$, i.e., at $a=\\frac{1}{2}$ and $b=\\frac{1}{2}$. This confirms our KKT solution is indeed the global maximum.\n\nThe maximal possible area is obtained using these optimal parameter values:\n$$ A_{max} = \\pi a b = \\pi \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) = \\frac{\\pi}{4} $$",
            "answer": "$$\\boxed{\\frac{\\pi}{4}}$$"
        },
        {
            "introduction": "Bridging the gap between analytical theory and computational practice is a cornerstone of scientific computing. This final exercise moves from pen-and-paper solutions to numerical implementation, allowing you to verify the logic of the KKT conditions in code . You will develop a program that determines whether a constraint is active or inactive for a given quadratic optimization problem and then validates that the computed solution and its Lagrange multiplier correctly satisfy the key KKT conditions of dual feasibility $(\\lambda \\ge 0)$ and complementary slackness $(\\lambda g(x^{\\star}) = 0)$.",
            "id": "3251733",
            "problem": "Consider the smooth, strictly convex quadratic optimization problem in $\\mathbb{R}^2$ with a single linear inequality constraint. Let the objective be $f(x) = \\tfrac{1}{2} x^\\top Q x + c^\\top x$ and the constraint be $g(x) = a^\\top x - b \\le 0$, where $Q \\in \\mathbb{R}^{2 \\times 2}$ is symmetric positive definite, $c \\in \\mathbb{R}^2$, $a \\in \\mathbb{R}^2$, and $b \\in \\mathbb{R}$. The Karush-Kuhn-Tucker (KKT) conditions for a minimizer $x^\\star$ with a single multiplier $\\lambda^\\star$ assert primal feasibility, dual feasibility, stationarity, and complementary slackness. Your task is to numerically verify two of these conditions, namely dual feasibility and complementary slackness, without assuming any special-case shortcuts.\n\nStarting from the fundamental definition that an unconstrained minimizer of a smooth function satisfies $\\nabla f(x) = 0$, and that an active inequality constraint becomes an equality with a Lagrange multiplier according to the method of Lagrange multipliers, design a procedure that:\n- Computes the unconstrained minimizer $x_{\\mathrm{un}}$ by solving $\\nabla f(x) = 0$.\n- If $g(x_{\\mathrm{un}}) \\le 0$, declares the constraint inactive and sets $\\lambda = 0$, with $x^\\star = x_{\\mathrm{un}}$.\n- If $g(x_{\\mathrm{un}})  0$, enforces the constraint as active and solves simultaneously for $x^\\star$ and $\\lambda$ using the stationarity condition and the active constraint equation.\n\nAfter computing $(x^\\star, \\lambda)$, numerically check:\n1. Dual feasibility: $\\lambda \\ge 0$.\n2. Complementary slackness: $\\lambda \\, g(x^\\star) = 0$.\n\nUse a numerical tolerance of $\\varepsilon = 10^{-9}$ for comparisons. That is, treat a real number $r$ as nonnegative if $r \\ge -\\varepsilon$, and treat a product $p$ as zero if $|p| \\le \\varepsilon$.\n\nImplement a program that applies this verification to the following test suite of five cases, each specified by $(Q, c, a, b)$:\n- Case A (active constraint, general feasibility): \n  $$Q = \\begin{bmatrix}1  0\\\\ 0  1\\end{bmatrix}, \\quad c = \\begin{bmatrix}-2\\\\ -3\\end{bmatrix}, \\quad a = \\begin{bmatrix}1\\\\ 0\\end{bmatrix}, \\quad b = 1.$$\n- Case B (inactive constraint, unconstrained minimum feasible):\n  $$Q = \\begin{bmatrix}1  0\\\\ 0  1\\end{bmatrix}, \\quad c = \\begin{bmatrix}-0.5\\\\ -0.5\\end{bmatrix}, \\quad a = \\begin{bmatrix}1\\\\ 0\\end{bmatrix}, \\quad b = 1.$$\n- Case C (active constraint, non-identity Hessian):\n  $$Q = \\begin{bmatrix}2  0\\\\ 0  1\\end{bmatrix}, \\quad c = \\begin{bmatrix}-1\\\\ 0\\end{bmatrix}, \\quad a = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}, \\quad b = 0.2.$$\n- Case D (near-boundary with very small multiplier):\n  $$Q = \\begin{bmatrix}1  0\\\\ 0  1\\end{bmatrix}, \\quad c = \\begin{bmatrix}-0.6\\\\ -0.6\\end{bmatrix}, \\quad a = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}, \\quad b = 1.2 - 10^{-9}.$$\n- Case E (boundary equality satisfied by unconstrained minimum):\n  $$Q = \\begin{bmatrix}1  0\\\\ 0  1\\end{bmatrix}, \\quad c = \\begin{bmatrix}-1\\\\ 0\\end{bmatrix}, \\quad a = \\begin{bmatrix}1\\\\ 0\\end{bmatrix}, \\quad b = 1.$$\n\nYour program must output, for each case, a pair of booleans $[\\text{dual\\_feasible}, \\text{comp\\_slack}]$, where $\\text{dual\\_feasible}$ is true if $\\lambda \\ge 0$ up to tolerance, and $\\text{comp\\_slack}$ is true if $\\lambda \\, g(x^\\star) = 0$ up to tolerance. The final output must aggregate the results for all cases as a single line: a comma-separated list enclosed in square brackets, where each element is itself a two-element list of booleans. For example, the output format must look like\n$$[\\,[\\text{bool},\\text{bool}],\\,[\\text{bool},\\text{bool}],\\,\\dots\\,]$$\nwith no additional text.\n\nAngles or physical units do not apply. All computations are purely mathematical and dimensionless.",
            "solution": "The problem requires the numerical verification of the dual feasibility and complementary slackness Karush-Kuhn-Tucker (KKT) conditions for a series of quadratic programming problems. Each problem involves minimizing a strictly convex quadratic objective function $f(x)$ subject to a single linear inequality constraint $g(x) \\le 0$. The functions are defined as:\n$$\nf(x) = \\frac{1}{2} x^\\top Q x + c^\\top x\n$$\n$$\ng(x) = a^\\top x - b \\le 0\n$$\nwhere $x, c, a \\in \\mathbb{R}^2$, $b \\in \\mathbb{R}$, and $Q \\in \\mathbb{R}^{2 \\times 2}$ is a symmetric positive definite matrix.\n\nThe solution methodology follows the standard approach for solving such problems, which first determines if the constraint is active at the optimal solution.\n\nFirst, we compute the unconstrained minimizer of $f(x)$, denoted $x_{\\mathrm{un}}$. This point is found by setting the gradient of $f(x)$ to zero. The gradient is:\n$$\n\\nabla f(x) = Qx + c\n$$\nSetting $\\nabla f(x) = 0$ gives $Qx + c = 0$. Since $Q$ is symmetric positive definite, it is invertible. Therefore, the unique unconstrained minimizer is:\n$$\nx_{\\mathrm{un}} = -Q^{-1}c\n$$\n\nNext, we evaluate the constraint function $g(x)$ at the unconstrained minimizer $x_{\\mathrm{un}}$. This determines whether the unconstrained solution is feasible. We use the provided numerical tolerance $\\varepsilon = 10^{-9}$ to handle floating-point comparisons, treating the condition $g(x_{\\mathrm{un}}) \\le 0$ as $g(x_{\\mathrm{un}}) \\le \\varepsilon$.\n\nCase 1: The constraint is inactive or satisfied at the boundary ($g(x_{\\mathrm{un}}) \\le \\varepsilon$).\nIf the unconstrained minimizer lies within or on the boundary of the feasible region, it is the optimal solution to the constrained problem.\n$$\nx^\\star = x_{\\mathrm{un}}\n$$\nIn this case, the Lagrange multiplier $\\lambda$ associated with the inequality constraint is zero.\n$$\n\\lambda = 0\n$$\n\nCase 2: The constraint is active ($g(x_{\\mathrm{un}})  \\varepsilon$).\nIf the unconstrained minimizer is outside the feasible region, the solution to the constrained problem must lie on the boundary of the feasible region, meaning the constraint is active: $g(x^\\star) = 0$. The solution $(x^\\star, \\lambda)$ is found by solving the KKT system of equations for stationarity and the active constraint:\n1. Stationarity: $\\nabla f(x^\\star) + \\lambda \\nabla g(x^\\star) = 0$\n2. Active Constraint: $g(x^\\star) = 0$\n\nThe gradient of the constraint is $\\nabla g(x) = a$. Substituting the gradients into the stationarity condition yields:\n$$\nQx^\\star + c + \\lambda a = 0\n$$\nFrom this, we can express $x^\\star$ in terms of $\\lambda$:\n$$\nx^\\star = -Q^{-1}(c + \\lambda a) = -Q^{-1}c - \\lambda Q^{-1}a = x_{\\mathrm{un}} - \\lambda Q^{-1}a\n$$\nWe substitute this expression for $x^\\star$ into the active constraint equation $a^\\top x^\\star - b = 0$:\n$$\na^\\top (x_{\\mathrm{un}} - \\lambda Q^{-1}a) - b = 0\n$$\n$$\na^\\top x_{\\mathrm{un}} - b = \\lambda (a^\\top Q^{-1} a)\n$$\nSolving for $\\lambda$, we get:\n$$\n\\lambda = \\frac{a^\\top x_{\\mathrm{un}} - b}{a^\\top Q^{-1} a}\n$$\nNote that since we are in the active case, the numerator $a^\\top x_{\\mathrm{un}} - b = g(x_{\\mathrm{un}})$ is positive. The denominator $a^\\top Q^{-1} a$ is also positive because $Q$ and therefore $Q^{-1}$ are positive definite and $a \\neq 0$. Thus, $\\lambda$ will be positive.\n\nAfter computing the solution pair $(x^\\star, \\lambda)$ for each case, we perform the two specified numerical checks using the tolerance $\\varepsilon = 10^{-9}$.\n1.  Dual Feasibility: $\\lambda \\ge 0$. This is checked as $\\lambda \\ge -\\varepsilon$.\n2.  Complementary Slackness: $\\lambda g(x^\\star) = 0$. This is checked as $|\\lambda g(x^\\star)| \\le \\varepsilon$. Note that $g(x^\\star) = a^\\top x^\\star - b$.\n\nThis procedure is applied to each of the five test cases provided. The results of the two checks for each case, represented as a pair of booleans, are then aggregated into a final list.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of quadratic optimization problems with a single linear inequality constraint\n    and verifies the KKT conditions of dual feasibility and complementary slackness.\n    \"\"\"\n    epsilon = 1e-9\n\n    test_cases = [\n        # Case A: active constraint\n        {'Q': np.array([[1.0, 0.0], [0.0, 1.0]]), 'c': np.array([-2.0, -3.0]), 'a': np.array([1.0, 0.0]), 'b': 1.0},\n        # Case B: inactive constraint\n        {'Q': np.array([[1.0, 0.0], [0.0, 1.0]]), 'c': np.array([-0.5, -0.5]), 'a': np.array([1.0, 0.0]), 'b': 1.0},\n        # Case C: active constraint, non-identity Hessian\n        {'Q': np.array([[2.0, 0.0], [0.0, 1.0]]), 'c': np.array([-1.0, 0.0]), 'a': np.array([1.0, 1.0]), 'b': 0.2},\n        # Case D: near-boundary case\n        {'Q': np.array([[1.0, 0.0], [0.0, 1.0]]), 'c': np.array([-0.6, -0.6]), 'a': np.array([1.0, 1.0]), 'b': 1.2 - 1e-9},\n        # Case E: boundary equality satisfied by unconstrained minimum\n        {'Q': np.array([[1.0, 0.0], [0.0, 1.0]]), 'c': np.array([-1.0, 0.0]), 'a': np.array([1.0, 0.0]), 'b': 1.0},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        Q, c, a, b = case['Q'], case['c'], case['a'], case['b']\n\n        # Step 1: Compute the unconstrained minimizer x_un by solving Qx + c = 0\n        Q_inv = np.linalg.inv(Q)\n        x_un = -Q_inv @ c\n\n        # Step 2: Evaluate the constraint at the unconstrained minimizer\n        g_x_un = a.T @ x_un - b\n\n        # Step 3: Determine if the constraint is active and find (x*, lambda)\n        # We check g(x_un) = epsilon to handle floating-point arithmetic.\n        # If g(x_un) is a very small positive number (= epsilon), we treat it as 0,\n        # meaning the unconstrained minimum is on the boundary and thus feasible.\n        if g_x_un = epsilon:\n            # Case 1: Constraint is inactive (or on the boundary).\n            # The unconstrained minimizer is the solution.\n            x_star = x_un\n            lambda_val = 0.0\n        else:\n            # Case 2: Constraint is active.\n            # The solution lies on the constraint boundary g(x*) = 0.\n            # Solve for lambda from the KKT system.\n            lambda_numerator = g_x_un\n            lambda_denominator = a.T @ Q_inv @ a\n            lambda_val = lambda_numerator / lambda_denominator\n            \n            # Compute the optimal x* using lambda.\n            x_star = x_un - lambda_val * (Q_inv @ a)\n\n        # Step 4: Numerically verify dual feasibility and complementary slackness\n        \n        # 1. Dual feasibility: lambda = 0\n        dual_feasible = lambda_val = -epsilon\n\n        # 2. Complementary slackness: lambda * g(x*) = 0\n        g_x_star = a.T @ x_star - b\n        comp_slack_product = lambda_val * g_x_star\n        comp_slack = abs(comp_slack_product) = epsilon\n\n        results.append([dual_feasible, comp_slack])\n\n    # Format the final output string as a list of lists of booleans,\n    # e.g., [[true,true],[true,true],...]\n    str_results = []\n    for res_pair in results:\n        str_results.append(f\"[{str(res_pair[0]).lower()},{str(res_pair[1]).lower()}]\")\n    print(f\"[{','.join(str_results)}]\")\n\nsolve()\n```"
        }
    ]
}