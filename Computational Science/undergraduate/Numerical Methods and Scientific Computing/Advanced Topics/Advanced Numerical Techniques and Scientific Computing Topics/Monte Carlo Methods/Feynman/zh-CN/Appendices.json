{
    "hands_on_practices": [
        {
            "introduction": "蒙特卡洛方法的核心思想之一是利用随机抽样来解决确定性问题，例如计算定积分 $I = \\int_a^b f(x) dx$。本练习将通过一个具体实例，让你亲手实践如何通过在一组随机点上取函数值的平均来估算积分值。这个基本练习  是理解更高级蒙特卡洛技术的基础。",
            "id": "1964916",
            "problem": "一名计算物理课程的学生正在学习简单的蒙特卡洛（MC）方法。任务是通过在少量随机采样点上评估被积函数来估计一个定积分的值。该技术通过计算表达式 $(b-a) \\times \\langle f \\rangle_N$ 来近似积分 $I = \\int_a^b f(x) dx$，其中 $\\langle f \\rangle_N$ 是在区间 $[a, b]$ 上均匀采样的 $N$ 个点上函数值的算术平均值。\n\n该学生被要求估计积分：\n$$ I = \\int_{0}^{2} \\frac{1}{1 + x^2} dx $$\n为了进行此估计，已从区间 $[0, 2]$ 上的均匀随机分布中预先选择了一组 $N=5$ 个点。这些点是：\n$$ x_1 = 0.25, \\quad x_2 = 1.50, \\quad x_3 = 0.80, \\quad x_4 = 1.90, \\quad x_5 = 1.10 $$\n仅使用这些信息，计算积分 $I$ 的蒙特卡洛估计值。将你的最终答案四舍五入到三位有效数字。",
            "solution": "在有限区间上进行均匀采样的粗略蒙特卡洛估计量是\n$$\n\\hat{I}_{N}=(b-a)\\,\\langle f\\rangle_{N}=(b-a)\\,\\frac{1}{N}\\sum_{i=1}^{N}f(x_{i}).\n$$\n这里，$a=0$, $b=2$, $N=5$ 且 $f(x)=\\frac{1}{1+x^{2}}$。对于给定的点，\n$$\n\\begin{aligned}\nf(0.25)=\\frac{1}{1+(0.25)^{2}}=\\frac{1}{1+\\frac{1}{16}}=\\frac{16}{17},\\\\\nf(1.50)=\\frac{1}{1+(1.50)^{2}}=\\frac{1}{1+\\frac{9}{4}}=\\frac{4}{13},\\\\\nf(0.80)=\\frac{1}{1+(0.80)^{2}}=\\frac{1}{1+\\frac{16}{25}}=\\frac{25}{41},\\\\\nf(1.90)=\\frac{1}{1+(1.90)^{2}}=\\frac{1}{1+\\frac{361}{100}}=\\frac{100}{461},\\\\\nf(1.10)=\\frac{1}{1+(1.10)^{2}}=\\frac{1}{1+\\frac{121}{100}}=\\frac{100}{221}.\n\\end{aligned}\n$$\n求和，\n$$\nS=\\frac{16}{17}+\\frac{4}{13}+\\frac{25}{41}+\\frac{100}{461}+\\frac{100}{221}\n=\\frac{10,559,901}{4,177,121}.\n$$\n因此，\n$$\n\\langle f\\rangle_{5}=\\frac{S}{5}=\\frac{10,559,901}{20,885,605},\n\\quad\n\\hat{I}_{5}=(b-a)\\langle f\\rangle_{5}=2\\cdot\\frac{10,559,901}{20,885,605}\n=\\frac{21,119,802}{20,885,605}.\n$$\n数值上，\n$$\n\\hat{I}_{5}\\approx 1.011213321\\ldots\n$$\n四舍五入到三位有效数字得到 $1.01$。",
            "answer": "$$\\boxed{1.01}$$"
        },
        {
            "introduction": "虽然简单蒙特卡洛积分在概念上很直观，但当被积函数存在奇点或在某些区域剧烈变化时，其估计的方差可能变得极大，导致收敛缓慢。本练习  将引导你探索一种强大的方差缩减技术——重要性采样，通过巧妙的变量替换，将一个有问题的积分转化为一个方差极小（甚至为零）的积分。这个过程不仅展示了该技术的威力，还强调了在变量替换中正确使用雅可比（Jacobian）行列式的关键性。",
            "id": "3253703",
            "problem": "考虑在高等本科阶段，使用蒙特卡洛方法近似计算积分 $$I=\\int_{0}^{1} x^{-1/2}\\,dx$$ 的问题。从基本定义出发：(i) 有界区间上的积分等于被积函数在定义于该区间的均匀分布随机变量下的期望值；(ii) 积分的变量替换定理指出，在应用一个光滑的双射映射时，积分通过乘以该映射导数的绝对值（一维情况下的雅可比行列式）进行变换。除了这些定义，不要使用任何预先推导的专用蒙特卡洛公式。\n\n您必须设计并实现三种蒙特卡洛估计量，它们都通过在单位区间上采样点来进行，但使用不同的被积函数表示形式：\n\n- 方法 $0$（直接对 $x$ 采样）：在 $[0,1]$ 区间内对 $x$ 进行采样，并通过对函数 $f(x)=x^{-1/2}$ 的值求平均来近似积分。\n\n- 方法 $1$（正确的变量替换 $x=u^2$）：在 $[0,1]$ 上应用映射 $x=u^2$，并使用变量替换定理得到一个在 $u \\in [0,1]$ 上的被积函数，该函数必须包含雅可比因子 $|dx/du|$，然后通过对 $u$ 的样本上的那个正确变换后的被积函数求平均来近似积分。\n\n- 方法 $2$（忽略雅可比行列式的错误映射）：应用相同的映射 $x=u^2$，但错误地省略了雅可比因子，仅对 $u$ 的样本上的复合函数 $f(u^2)$ 求平均。\n\n为了数值稳定性和确定性可复现性，在所有三种方法中，都使用单位区间上的分层中点，而不是伪随机数。具体来说，对于给定的正整数 $N$，定义 $N$ 个样本点 $$s_i=\\frac{i-1/2}{N},\\quad i=1,2,\\dots,N.$$ 在方法 $0$ 中，令 $x_i=s_i$。在方法 $1$ 和 $2$ 中，令 $u_i=s_i$ 并应用相应的变换。\n\n对于每种方法和每个 $N$，计算：\n\n- 将 $I$ 的估计值计算为相应加数值的算术平均值。\n\n- 使用除数为 $N-1$ 的常规无偏样本方差公式计算这些加数值的经验方差（如果 $N=1$，则定义经验方差为 $0$）。\n\n根据第一性原理，确定对于每种方法，在单位区间上独立同分布采样的情况下，加数的真实均值是否有限，以及其真实方差是否有限。将这些有限性属性报告为布尔值。\n\n测试套件。您的程序必须为以下测试用例计算上述输出，这些测试用例涵盖了每种方法的典型情况和边界增长情况：\n\n- 方法 $0$，其中 $N=10$。\n\n- 方法 $0$，其中 $N=1000$。\n\n- 方法 $1$，其中 $N=10$。\n\n- 方法 $1$，其中 $N=1000$。\n\n- 方法 $2$，其中 $N=10$。\n\n- 方法 $2$，其中 $N=1000$。\n\n最终输出格式。您的程序应该生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，按顺序输出以下四项：作为浮点数并四舍五入到六位小数的估计值，作为浮点数并四舍五入到六位小数的经验方差，一个指示加数的真实均值是否有限的布尔值，以及一个指示加数的真实方差是否有限的布尔值。将所有测试用例按上面列出的顺序连接成一个扁平列表。例如，整体打印的结构必须是这种形式：$$[\\text{est}_{0,10},\\text{var}_{0,10},\\text{meanOK}_{0},\\text{varOK}_{0},\\text{est}_{0,1000},\\dots,\\text{est}_{2,1000},\\text{var}_{2,1000},\\text{meanOK}_{2},\\text{varOK}_{2}],$$ 其中每个 $\\text{est}_{\\cdot,\\cdot}$ 和 $\\text{var}_{\\cdot,\\cdot}$ 都是四舍五入到六位小数的浮点数，每个 $\\text{meanOK}_{\\cdot}$ 和 $\\text{varOK}_{\\cdot}$ 都是布尔值。不应打印任何其他文本。",
            "solution": "该问题要求对积分 $I=\\int_{0}^{1} x^{-1/2}\\,dx$ 的三种蒙特卡洛式估计量进行设计、理论分析和数值实现。分析必须基于第一性原理，即积分作为期望的解释以及变量替换定理。\n\n积分的精确值为 $I = \\int_{0}^{1} x^{-1/2}\\,dx = [2x^{1/2}]_{0}^{1} = 2(1)^{1/2} - 2(0)^{1/2} = 2$。如果将其作为瑕积分处理，这是一个正常的黎曼积分，因为极限存在。被积函数 $f(x) = x^{-1/2}$ 在 $x=0$ 处有一个奇点。\n\n对于一个函数 $g(v)$ 和一个在 $[0,1]$上均匀分布的随机变量 $V$，其期望为 $E[g(V)] = \\int_0^1 g(v)\\,dv$。因此，积分 $I$ 可以表示为期望 $E[f(X)]$，其中 $X$ 是 $[0,1]$ 上的一个均匀分布随机变量。$I$ 的一个蒙特卡洛估计是样本均值 $\\hat{I}_N = \\frac{1}{N} \\sum_{i=1}^N f(x_i)$，其中 $\\{x_i\\}$ 是从 $[0,1]$ 上的均匀分布中抽取的独立样本。问题指定了一种确定性的分层抽样方案，而不是随机抽样：$s_i = \\frac{i-1/2}{N}$，对于 $i=1,2,\\dots,N$。这是一种拟蒙特卡洛方法。\n\n蒙特卡洛估计量的质量由其加数（summand）的性质决定。加数的均值 $E[g(V)]$ 决定了估计量是否有偏。加数的方差 $Var[g(V)] = E[g(V)^2] - (E[g(V)])^2$ 决定了估计的收敛速度。有限的方差对于估计量的标准误差以经典的 $1/\\sqrt{N}$ 速率下降至关重要。\n\n让我们分析所提出的三种方法中的每一种。\n\n**方法 0：直接对 $x$ 采样**\n在这种方法中，我们直接使用被积函数 $f(x)=x^{-1/2}$。样本点为 $x_i = s_i = \\frac{i-1/2}{N}$。加数为 $y_i = x_i^{-1/2}$。\n对于给定的 $N$，积分的估计值为 $\\hat{I}_0 = \\frac{1}{N} \\sum_{i=1}^{N} y_i = \\frac{1}{N} \\sum_{i=1}^{N} (s_i)^{-1/2}$。\n\n理论分析：\n加数是函数 $g_0(x) = x^{-1/2}$。\n对于 $X \\sim U(0,1)$，加数的真实均值是其期望：\n$$E[g_0(X)] = \\int_0^1 x^{-1/2} \\,dx = [2x^{1/2}]_0^1 = 2$$\n均值是有限的。\n加数的真实方差是 $Var[g_0(X)] = E[g_0(X)^2] - (E[g_0(X)])^2$。我们首先计算二阶矩：\n$$E[g_0(X)^2] = \\int_0^1 (x^{-1/2})^2 \\,dx = \\int_0^1 x^{-1} \\,dx = [\\ln|x|]_0^1$$\n这个积分在下限 $x=0$ 处发散。由于二阶矩是无限的，所以方差也是无限的。\n因此，对于方法 $0$，加数的真实均值是有限的，但真实方差是无限的。这意味着虽然大数定律适用且估计量是一致的（即它收敛于真实值），但收敛速度非常慢，且标准形式的中心极限定理不适用。\n\n有限性属性：`meanOK` 为 True，`varOK` 为 False。\n\n**方法 1：正确的变量替换 $x=u^2$**\n该方法使用变换 $x=g(u)=u^2$，其中 $u \\in [0,1]$。积分的变量替换定理指出 $\\int f(x) \\,dx = \\int f(g(u)) |g'(u)| \\,du$。\n这里，$g(u)=u^2$，所以雅可比行列式为 $|g'(u)| = |dx/du| = |2u| = 2u$，因为 $u \\ge 0$。\n积分变换为：\n$$I = \\int_0^1 x^{-1/2} \\,dx = \\int_0^1 (u^2)^{-1/2} (2u) \\,du = \\int_0^1 u^{-1}(2u) \\,du = \\int_0^1 2 \\,du$$\n新的被积函数，即蒙特卡洛方法的加数，是 $g_1(u) = 2$。\n样本点为 $u_i = s_i = \\frac{i-1/2}{N}$。加数为 $y_i = g_1(u_i) = 2$。\n估计值为 $\\hat{I}_1 = \\frac{1}{N} \\sum_{i=1}^{N} 2 = \\frac{1}{N} (2N) = 2$。\n\n理论分析：\n加数是常数函数 $g_1(u) = 2$。\n对于 $U \\sim U(0,1)$，加数的真实均值为：\n$$E[g_1(U)] = \\int_0^1 2 \\,du = 2$$\n均值是有限的。\n加数的真实方差为：\n$$Var[g_1(U)] = Var[2] = 0$$\n由于加数是一个常数，其方差为零。方差是有限的。\n这个变量替换将一个具有无限方差的被积函数转换为了一个方差为零的函数，这是方差缩减的一个完美例子。对于任何 $N \\ge 1$，估计值都将是精确的 ($2$）。\n\n有限性属性：`meanOK` 为 True，`varOK` 为 True。\n\n**方法 2：忽略雅可比行列式的错误映射**\n此方法应用了变换 $x=u^2$，但错误地省略了雅可比因子 $|dx/du|$。\n加数被取为 $g_2(u) = f(g(u)) = f(u^2) = (u^2)^{-1/2} = u^{-1}$，对于 $u>0$。\n样本点为 $u_i = s_i = \\frac{i-1/2}{N}$。加数为 $y_i = (u_i)^{-1}$。\n估计值为 $\\hat{I}_2 = \\frac{1}{N} \\sum_{i=1}^{N} (s_i)^{-1}$。这个方法实际上是在估计积分 $\\int_0^1 u^{-1} du$，而不是原始积分 $I$。\n\n理论分析：\n加数是函数 $g_2(u) = u^{-1}$。\n对于 $U \\sim U(0,1)$，加数的真实均值为：\n$$E[g_2(U)] = \\int_0^1 u^{-1} \\,du = [\\ln|u|]_0^1$$\n这个积分在下限 $u=0$ 处发散。\n均值是无限的。\n由于均值（一阶矩）是无限的，方差（取决于一阶矩和二阶矩）也必然是无限的。\n\n有限性属性：`meanOK` 为 False，`varOK` 为 False。\n\n**数值计算**\n对于每种方法和给定的 $N$，我们计算：\n1.  样本点：$s_i = (i-0.5)/N$，对于 $i=1, \\dots, N$。\n2.  根据方法的定义计算加数 $y_i$。\n3.  估计值：$\\hat{I} = \\frac{1}{N}\\sum_{i=1}^N y_i$。\n4.  经验方差：$S^2 = \\frac{1}{N-1}\\sum_{i=1}^N (y_i - \\hat{I})^2$ 对于 $N > 1$，当 $N=1$ 时为 $0$。\n\n将对指定的测试用例执行这些计算。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Monte Carlo integration problem for the specified test cases.\n    \"\"\"\n\n    # Test cases: list of (method_id, N)\n    # method_id 0: Direct, f(x) = x^(-1/2)\n    # method_id 1: Correct change of vars, f(u) = 2\n    # method_id 2: Incorrect change of vars, f(u) = u^(-1)\n    test_cases = [\n        (0, 10),\n        (0, 1000),\n        (1, 10),\n        (1, 1000),\n        (2, 10),\n        (2, 1000),\n    ]\n\n    # Theoretical properties determined from first principles\n    # (is_mean_finite, is_variance_finite)\n    theoretical_props = {\n        0: (True, False),  # Mean is 2, Variance is infinite\n        1: (True, True),   # Mean is 2, Variance is 0\n        2: (False, False), # Mean is infinite, Variance is infinite\n    }\n\n    results = []\n\n    for method_id, N in test_cases:\n        # Generate stratified midpoint samples on the unit interval\n        # s_i = (i - 1/2) / N for i = 1, 2, ..., N\n        # np.arange(1, N + 1) creates the sequence of i's.\n        samples = (np.arange(1, N + 1) - 0.5) / N\n\n        summands = None\n        if method_id == 0:\n            # Method 0: Direct sampling on x. Summands are x_i^(-1/2)\n            # The samples 's' are the x_i values.\n            summands = samples**(-0.5)\n        elif method_id == 1:\n            # Method 1: Correct change of variables x=u^2.\n            # Summands are f(u^2) * |dx/du| = (u^-2)^(1/2) * 2u = u^-1 * 2u = 2.\n            # The samples 's' are the u_i values.\n            # np.full creates an array of size N filled with the value 2.0.\n            summands = np.full(N, 2.0)\n        elif method_id == 2:\n            # Method 2: Incorrect mapping x=u^2 without Jacobian.\n            # Summands are f(u^2) = (u^2)^(-1/2) = u^-1.\n            # The samples 's' are the u_i values.\n            summands = samples**(-1)\n\n        # Calculate the estimate (arithmetic mean of summands)\n        estimate = np.mean(summands)\n\n        # Calculate the empirical variance of the summands\n        # The problem specifies unbiased sample variance (divisor N-1).\n        # np.var with ddof=1 computes this.\n        # If N=1, variance is defined as 0.\n        if N > 1:\n            empirical_variance = np.var(summands, ddof=1)\n        else:\n            empirical_variance = 0.0\n\n        # Retrieve theoretical finiteness properties\n        mean_ok, var_ok = theoretical_props[method_id]\n\n        # Append results for this test case, formatted as required\n        results.extend([\n            f\"{estimate:.6f}\",\n            f\"{empirical_variance:.6f}\",\n            str(mean_ok),\n            str(var_ok)\n        ])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "除了改变被积函数（如重要性采样），我们还可以通过优化采样过程本身来减少方差。本练习  介绍另一种关键的方差缩减策略：分层抽样。通过将积分域划分为不同的“层”，并根据每层对总方差的贡献来智能地分配样本，我们可以用相同的计算成本获得更精确的估计。",
            "id": "3253642",
            "problem": "考虑一个单日功耗的随机模型。令时间 $t$ 在区间 $[0,24)$ 上连续变化，单位为小时。瞬时功耗 $C(t)$ 在时间 $t$ 被建模为一个伽马分布的随机变量，其形状参数为 $k$，尺度参数 $\\theta(t)$ 随时间变化，使得条件期望满足 $\\mathbb{E}[C(t)\\mid t] = \\mu(t) = k\\,\\theta(t)$。确定性均值曲线 $\\mu(t)$ 定义为\n$$\n\\mu(t) = b + a \\,\\sin^2\\left(\\frac{\\pi\\,t}{24}\\right) + s \\,\\exp\\left(-\\frac{(t - 19)^2}{w^2}\\right),\n$$\n其中 $b$、$a$、$s$ 和 $w$ 是正常数，且正弦函数中的角度以弧度为单位。根据构造，所有三角函数和指数函数的参数都是无量纲的。假设 $C(t)$ 以千瓦为单位，但本任务中要求的输出是无量纲的，不需要物理单位。\n\n定义一个在 $[0,24)$ 上均匀分布的随机时间 $T$，目标量是在一个均匀随机时间点的期望功耗，\n$$\n\\mu^\\star = \\mathbb{E}[C(T)].\n$$\n\n你的任务是设计并实现两种计算成本相等的 $\\mu^\\star$ 的蒙特卡洛估计量，并根据估计方差来量化它们的效率：\n\n- 一种粗略蒙特卡洛估计量，它在 $[0,24)$ 上均匀抽取 $N$ 个独立的 $T$ 样本，并对每个时间点，给定该时间抽取一个 $C(t)$ 的实现。$\\mu^\\star$ 的估计量是这 $N$ 个样本的经验均值。该估计量的估计方差必须由 $C(t)$ 值的样本方差除以 $N$ 来计算。\n\n- 一种跨越指定时间区间的​​分层蒙特卡洛估计量，它将 $[0,24)$ 划分为 $K$ 个不相交的层。全期望定律和分层抽样的性质意味着，可以通过将各层的平均值按其层概率加权，来构造一个 $\\mu^\\star$ 的无偏估计量。在总成本为 $N$ 个样本的固定条件下，设计一个能够减少估计量方差的层分配方案。在每个层内使用引导抽样策略来近似层内变异性，并推导出一个分配规则，该规则通过在固定总成本约束下最小化估计量方差来证明其合理性。使用引导估计来确定一个依赖于数据的分配方案，然后根据层内样本方差计算分层估计量及其估计方差。\n\n以下常数定义了该模型：\n- $k = 6$\n- $b = 0.4$\n- $a = 1.1$\n- $s = 2.0$\n- $w = 1.2$\n\n$\\sin(\\cdot)$ 中的角度单位是弧度。\n\n实现一个完整的程序，对于每个测试用例，计算分层估计量的估计方差与粗略估计量的估计方差之比。对于每个测试用例，两种方法中的总抽样预算 $N$ 必须完全相同。使用以下参数值的测试套件：\n\n- 测试用例 1：$N = 1000$，区间 $[0,6)$、$[6,17)$、$[17,21)$、$[21,24)$，每个区间的引导样本量 $m = 5$，随机种子 $\\sigma = 12345$。\n- 测试用例 2：$N = 40$，区间 $[0,6)$、$[6,17)$、$[17,21)$、$[21,24)$，每个区间的引导样本量 $m = 2$，随机种子 $\\sigma = 54321$。\n- 测试用例 3：$N = 800$，区间 $[0,6)$、$[6,18)$、$[18,18.5)$、$[18.5,24)$，每个区间的引导样本量 $m = 5$，随机种子 $\\sigma = 2023$。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个条目是相应测试用例的比值 $\\widehat{\\mathrm{Var}}_{\\text{strat}} / \\widehat{\\mathrm{Var}}_{\\text{crude}}$，顺序与上面给出的一致。例如，输出格式为\n$$\n[\\rho_1,\\rho_2,\\rho_3].\n$$\n因为这些比值是无量纲的，所以输出中不应包含任何物理单位。",
            "solution": "该问题要求设计和比较两种用于估计在均匀随机时间点的期望功耗（记为 $\\mu^\\star$）的蒙特卡洛估计量。我们给定了一个在时间 $t \\in [0, 24)$ 上的瞬时功耗 $C(t)$ 的随机模型，以及其均值 $\\mu(t)$ 的确定性模型。\n\n首先，让我们将目标量 $\\mu^\\star$ 形式化。我们给定了一个在 $[0, 24)$ 上均匀分布的随机时间 $T$，即 $T \\sim U(0, 24)$，以及一个随机变量 $C(t) \\sim \\mathrm{Gamma}(k, \\theta(t))$，其均值为 $\\mathbb{E}[C(t) \\mid t] = \\mu(t) = k \\theta(t)$。目标是无条件期望 $\\mu^\\star = \\mathbb{E}[C(T)]$。\n\n根据全期望定律（也称为塔性质或迭代期望），我们可以写出：\n$$\n\\mu^\\star = \\mathbb{E}[\\mathbb{E}[C(T) \\mid T]]\n$$\n给定一个特定时间 $T=t$，条件期望为 $\\mathbb{E}[C(T) \\mid T=t] = \\mathbb{E}[C(t)] = \\mu(t)$。因此，目标量是均值函数 $\\mu(t)$ 关于随机时间 $T$ 的期望：\n$$\n\\mu^\\star = \\mathbb{E}[\\mu(T)]\n$$\n由于 $T$ 在 $[0, 24)$ 上均匀分布，其概率密度函数为 $f_T(t) = 1/24$，对于 $t \\in [0, 24)$。因此，该期望是 $\\mu(t)$ 按其密度加权的积分：\n$$\n\\mu^\\star = \\int_{0}^{24} \\mu(t) f_T(t) dt = \\frac{1}{24} \\int_{0}^{24} \\mu(t) dt\n$$\n这表明 $\\mu^\\star$ 是 24 小时内平均功耗曲线的平均值。问题在于使用两种不同的蒙特卡洛方案来估计这个值，这些方案从完整的随机过程 $C(T)$ 中抽样，而不仅仅是从确定性函数 $\\mu(T)$ 中抽样。\n\n平均功耗曲线由下式给出：\n$$\n\\mu(t) = b + a \\,\\sin^2\\left(\\frac{\\pi\\,t}{24}\\right) + s \\,\\exp\\left(-\\frac{(t - 19)^2}{w^2}\\right)\n$$\n其中常数为 $k = 6$、$b = 0.4$、$a = 1.1$、$s = 2.0$ 和 $w = 1.2$。\n\n**粗略蒙特卡洛 (CMC) 估计量**\n\n粗略蒙特卡洛方法直接模拟该过程以估计 $\\mu^\\star = \\mathbb{E}[C(T)]$。\n步骤如下：\n1.  从均匀分布 $U(0, 24)$ 中生成 $N$ 个独立同分布的时间变量样本 $T_1, T_2, \\ldots, T_N$。\n2.  对于每个时间样本 $T_i$，计算均值 $\\mu(T_i)$ 和伽马分布对应的尺度参数 $\\theta(T_i) = \\mu(T_i) / k$。\n3.  对于每个 $T_i$，从伽马分布 $C_i \\sim \\mathrm{Gamma}(k, \\theta(T_i))$ 中生成一个功耗样本 $C_i$。\n4.  $\\mu^\\star$ 的 CMC 估计量是这些功耗值的样本均值：\n    $$\n    \\hat{\\mu}_{\\text{crude}} = \\frac{1}{N} \\sum_{i=1}^{N} C_i\n    $$\n该估计量的方差为 $\\mathrm{Var}(\\hat{\\mu}_{\\text{crude}}) = \\mathrm{Var}(C(T)) / N$。我们使用生成的 $C_i$ 值的样本方差来估计此方差。令 $\\hat{\\sigma}_{\\text{crude}}^2$ 为集合 $\\{C_1, \\ldots, C_N\\}$ 的样本方差：\n$$\n\\hat{\\sigma}_{\\text{crude}}^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} (C_i - \\hat{\\mu}_{\\text{crude}})^2\n$$\n那么，估计量 $\\hat{\\mu}_{\\text{crude}}$ 的估计方差为：\n$$\n\\widehat{\\mathrm{Var}}(\\hat{\\mu}_{\\text{crude}}) = \\frac{\\hat{\\sigma}_{\\text{crude}}^2}{N}\n$$\n\n**分层蒙特卡洛估计量**\n\n分层抽样是一种可以提高估计效率的方差缩减技术。抽样变量 $T$ 的域，即区间 $[0, 24)$，被划分为 $K$ 个不相交的子区间，或称为层，$S_j = [t_{j-1}, t_j)$，其中 $j=1, \\ldots, K$，$t_0=0$ 且 $t_K=24$。\n\n$T$ 落入层 $S_j$ 的概率是其归一化长度，$p_j = P(T \\in S_j) = (t_j - t_{j-1}) / 24$。\n总体期望 $\\mu^\\star$ 可以表示为每个层内条件期望的加权和：\n$$\n\\mu^\\star = \\sum_{j=1}^{K} p_j \\mu_j, \\quad \\text{其中} \\quad \\mu_j = \\mathbb{E}[C(T) \\mid T \\in S_j]\n$$\n分层估计量是通过使用从层 $S_j$ 中专门抽取的样本的样本均值 $\\bar{C}_j$ 来估计每个 $\\mu_j$，然后将它们组合起来构造的：\n$$\n\\hat{\\mu}_{\\text{strat}} = \\sum_{j=1}^{K} p_j \\bar{C}_j\n$$\n其中 $\\bar{C}_j$ 是从层 $S_j$ 抽取的 $n_j$ 个样本的均值，总样本数固定为 $N = \\sum_{j=1}^K n_j$。\n\n分层估计量的方差为 $\\mathrm{Var}(\\hat{\\mu}_{\\text{strat}}) = \\sum_{j=1}^{K} p_j^2 \\frac{\\sigma_j^2}{n_j}$，其中 $\\sigma_j^2 = \\mathrm{Var}(C(T) \\mid T \\in S_j)$ 是层 $S_j$ 内的功耗方差。为了在固定的总成本 $N$ 下最小化此方差，样本量 $n_j$ 应根据 Neyman 分配来选择：\n$$\nn_j \\propto p_j \\sigma_j\n$$\n由于真实的层方差 $\\sigma_j$ 是未知的，问题指定了一种引导抽样策略来估计它们。我们采用一个两阶段方法，该方法遵循总样本预算 $N$：\n1.  **引导阶段：** 对于 $K$ 个层中的每一个，抽取一个大小为 $m$ 的小型引导样本。这总共使用 $K \\times m$ 个样本。\n    -   对于每个层 $S_j$，从 $U(S_j)$ 中抽取 $T_{j,1}, \\ldots, T_{j,m}$。\n    -   对于每个 $T_{j,i}$，抽取 $C_{j,i} \\sim \\mathrm{Gamma}(k, \\mu(T_{j,i})/k)$。\n    -   从这 $m$ 个样本中计算层标准差的引导估计值 $\\hat{\\sigma}_{j, \\text{pilot}}$。这仅在 $m \\geq 2$ 时才可能。\n\n2.  **分配和增补阶段：**\n    -   剩余的样本预算为 $N_{\\text{rem}} = N - K \\times m$。\n    -   如果 $N_{\\text{rem}} > 0$，这些样本将被分配到各个层中以增补引导样本。层 $S_j$ 的额外样本数，记为 $n_j^{\\text{add}}$，是使用引导估计通过 Neyman 分配规则确定的：\n        $$\n        n_j^{\\text{add}} \\approx N_{\\text{rem}} \\frac{p_j \\hat{\\sigma}_{j, \\text{pilot}}}{\\sum_{i=1}^{K} p_i \\hat{\\sigma}_{i, \\text{pilot}}}\n        $$\n    -   由于 $n_j^{\\text{add}}$ 必须是整数，这些值会被四舍五入并进行调整，以确保它们的总和恰好为 $N_{\\text{rem}}$。\n    -   从每个对应的层 $S_j$ 中抽取 $n_j^{\\text{add}}$ 个新样本。\n\n3.  **最终估计：**\n    -   对于每个层 $S_j$，现在的总样本数为 $n_j = m + n_j^{\\text{add}}$。\n    -   使用每个层中的所有 $n_j$ 个样本，计算最终的层样本均值 $\\bar{C}_j$ 和最终的层样本方差 $\\hat{\\sigma}_j^2$。\n    -   $\\mu^\\star$ 的分层估计量是 $\\hat{\\mu}_{\\text{strat}} = \\sum_{j=1}^{K} p_j \\bar{C}_j$。\n    -   该估计量的估计方差为：\n        $$\n        \\widehat{\\mathrm{Var}}(\\hat{\\mu}_{\\text{strat}}) = \\sum_{j=1}^{K} p_j^2 \\frac{\\hat{\\sigma}_j^2}{n_j}\n        $$\n\n最后的任务是为每个给定的测试用例计算效率比 $\\widehat{\\mathrm{Var}}(\\hat{\\mu}_{\\text{strat}}) / \\widehat{\\mathrm{Var}}(\\hat{\\mu}_{\\text{crude}})$。该比率量化了在相同的总计算成本 $N$ 下，分层方法相对于粗略方法所实现的方差缩减。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the Monte Carlo simulations for the given test cases.\n    \"\"\"\n    # Define model constants\n    k = 6.0\n    b = 0.4\n    a = 1.1\n    s = 2.0\n    w = 1.2\n\n    def mu(t):\n        \"\"\"Calculates the mean power consumption mu(t) at time t.\"\"\"\n        term_b = b\n        term_a = a * np.sin(np.pi * t / 24.0)**2\n        term_s = s * np.exp(-((t - 19.0)**2) / w**2)\n        return term_b + term_a + term_s\n\n    def crude_mc(N, seed):\n        \"\"\"\n        Performs crude Monte Carlo estimation.\n        - N: total number of samples\n        - seed: random generator seed\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        \n        # 1. Draw N samples of T from U(0, 24)\n        times = rng.uniform(0.0, 24.0, N)\n        \n        # 2. Calculate mu(t) and theta(t) for each time\n        mus = mu(times)\n        thetas = mus / k\n        \n        # 3. Draw N samples of C(t) from Gamma(k, theta(t))\n        consumptions = rng.gamma(shape=k, scale=thetas, size=N)\n        \n        # 4. Calculate estimator and its estimated variance\n        # The estimated variance of the estimator is sample_variance / N\n        est_variance = np.var(consumptions, ddof=1) / N\n        \n        return est_variance\n\n    def stratified_mc(N, bins, m, seed):\n        \"\"\"\n        Performs stratified Monte Carlo estimation with a two-stage sampling process.\n        - N: total number of samples\n        - bins: a list of stratum boundaries, e.g., [0, 6, 17, 24]\n        - m: pilot sample size per stratum\n        - seed: random generator seed\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        K = len(bins) - 1\n        strata = [(bins[i], bins[i+1]) for i in range(K)]\n        \n        # Calculate stratum probabilities (weights)\n        p_j = np.array([end - start for start, end in strata]) / 24.0\n        \n        # --- Stage 1: Pilot Sampling ---\n        # Draw m samples from each stratum\n        pilot_samples_C = []\n        pilot_sigmas = np.zeros(K)\n        \n        for j in range(K):\n            start, end = strata[j]\n            # Draw m time samples from U(start, end)\n            times_j = rng.uniform(start, end, m)\n            mus_j = mu(times_j)\n            thetas_j = mus_j / k\n            \n            # Draw m consumption samples\n            consumptions_j = rng.gamma(shape=k, scale=thetas_j, size=m)\n            pilot_samples_C.append(list(consumptions_j))\n            \n            # Estimate stratum standard deviation from pilot samples\n            if m > 1:\n                pilot_sigmas[j] = np.std(consumptions_j, ddof=1)\n            else:\n                pilot_sigmas[j] = 0 # Cannot estimate variance with 1 sample\n        \n        # --- Stage 2: Allocation and Augmentation ---\n        N_rem = N - K * m\n        n_j_total = [m] * K\n\n        if N_rem > 0:\n            # Calculate Neyman allocation for the remaining samples\n            weights = p_j * pilot_sigmas\n            sum_weights = np.sum(weights)\n            \n            if sum_weights > 0:\n                alloc_proportions = weights / sum_weights\n                n_j_ideal = N_rem * alloc_proportions\n                \n                # Integer allocation\n                n_j_add_floor = np.floor(n_j_ideal).astype(int)\n                n_rem_int = N_rem - np.sum(n_j_add_floor)\n                \n                # Distribute remainder based on fractional parts\n                frac_parts = n_j_ideal - n_j_add_floor\n                indices_to_add = np.argsort(frac_parts)[-n_rem_int:]\n                n_j_add = n_j_add_floor\n                n_j_add[indices_to_add] += 1\n            else:\n                # If all pilot sigmas are zero, allocate proportionally to stratum size\n                n_j_add_floor = np.floor(N_rem * p_j).astype(int)\n                n_rem_int = N_rem - np.sum(n_j_add_floor)\n                indices_to_add = np.argsort(p_j)[-n_rem_int:]\n                n_j_add = n_j_add_floor\n                n_j_add[indices_to_add] += 1\n\n            # Augment samples\n            for j in range(K):\n                if n_j_add[j] > 0:\n                    start, end = strata[j]\n                    times_j_add = rng.uniform(start, end, n_j_add[j])\n                    mus_j_add = mu(times_j_add)\n                    thetas_j_add = mus_j_add / k\n                    consumptions_j_add = rng.gamma(shape=k, scale=thetas_j_add, size=n_j_add[j])\n                    pilot_samples_C[j].extend(consumptions_j_add)\n                    n_j_total[j] += n_j_add[j]\n       \n        # --- Final Estimation ---\n        final_stratum_vars = np.zeros(K)\n        for j in range(K):\n            if n_j_total[j] > 1:\n                final_stratum_vars[j] = np.var(pilot_samples_C[j], ddof=1)\n            # if n_j_total[j] = 1, variance is 0, which is correct for the formula below.\n        \n        # Estimated variance of the stratified estimator\n        est_variance = np.sum((p_j**2 * final_stratum_vars) / n_j_total)\n        \n        return est_variance\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'N': 1000, 'bins': [0, 6, 17, 21, 24], 'm': 5, 'seed': 12345},\n        {'N': 40, 'bins': [0, 6, 17, 21, 24], 'm': 2, 'seed': 54321},\n        {'N': 800, 'bins': [0, 6, 18, 18.5, 24], 'm': 5, 'seed': 2023},\n    ]\n\n    ratios = []\n    for case in test_cases:\n        N = case['N']\n        bins = case['bins']\n        m = case['m']\n        seed = case['seed']\n        \n        var_crude = crude_mc(N, seed)\n        var_strat = stratified_mc(N, bins, m, seed)\n        \n        ratio = var_strat / var_crude\n        ratios.append(ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.7f}' for r in ratios)}]\")\n\nsolve()\n```"
        }
    ]
}