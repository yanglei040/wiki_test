{
    "hands_on_practices": [
        {
            "introduction": "Monte Carlo simulations are a cornerstone of scientific computing, relying heavily on sequences of pseudo-random numbers. This practice dives into using a simple Linear Congruential Generator (LCG) to simulate the classic coupon collector's problem. You will not only implement the simulation but also confront a critical detail: how to correctly map a generator's output to a smaller integer range without introducing statistical bias, a fundamental skill for any simulation practitioner .",
            "id": "3264193",
            "problem": "You are to implement a simulation of the coupon collector process using a pseudo-random number generator and compare the Monte Carlo estimate of the expected number of trials with a theoretical value derived from first principles. Consider the following model: there are $n$ distinct coupon types labeled $0,1,\\dots,n-1$. At each trial, exactly one coupon is drawn, and each coupon type is equally likely. Trials are independent. Let $T$ be the total number of trials until all $n$ types have been collected at least once.\n\nThe foundational base for this task must be the definitions of independence of trials, uniform discrete selection, and expectation of a geometric random variable. A pseudo-random number generator (PRNG) is a deterministic algorithm that produces a sequence of numbers approximating independent uniform random variables on a discrete set. You must instantiate a Linear Congruential Generator (LCG), defined by the recurrence\n$$\nx_{t+1} = (a x_t + c) \\bmod m,\n$$\nwhere $a$, $c$, and $m$ are fixed integers and $x_t$ is the internal state at step $t$. You must use the following parameters, known to produce a long period sequence: $a=16807$, $c=0$, and $m=2^{31}-1$. Initialize the state with a seed $s$ satisfying $0  s  m$. From this generator, construct a uniform integer draw in $\\{0,1,\\dots,n-1\\}$ by applying unbiased rejection sampling to eliminate the modulo bias: if $y = x_t - 1 \\in \\{0,1,\\dots,m-2\\}$ and $t^\\star = \\left\\lfloor \\frac{m-1}{n} \\right\\rfloor \\cdot n$, then accept $y$ if $y  t^\\star$ and return $y \\bmod n$; otherwise advance the generator and retry until acceptance.\n\nFor each test case, perform $M$ independent Monte Carlo replications of the coupon collection process driven by your PRNG, compute the empirical mean $\\hat{E}[T]$ across the replications, and also compute the theoretical expectation $E[T]$ derived from first principles (do not use shortcut formulas in this problem statement). Report the absolute error $|\\hat{E}[T] - E[T]|$.\n\nYour program must implement the described PRNG and simulation, and produce a single line of output containing the results of all test cases as a comma-separated list enclosed in square brackets, where each test case yields a list $[\\hat{E}[T],E[T],|\\hat{E}[T]-E[T]|]$. All outputs are real numbers (floating-point), expressed in standard decimal notation without any physical units.\n\nUse the following test suite, covering happy path and boundary conditions:\n- Case A (boundary): $n=1$, $M=100$, $s=12345$.\n- Case B (happy path small): $n=5$, $M=10000$, $s=987654321$.\n- Case C (moderate): $n=50$, $M=2000$, $s=42$.\n- Case D (larger): $n=200$, $M=800$, $s=20231107$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[[\\hat{E}_A,E_A,|e_A|],[\\hat{E}_B,E_B,|e_B|],[\\hat{E}_C,E_C,|e_C|],[\\hat{E}_D,E_D,|e_D|]]$), where each inner list corresponds to the respective test case in the given order.",
            "solution": "The problem requires the implementation of a Monte Carlo simulation for the coupon collector's problem and a comparison of its empirical results with the theoretical expectation. This involves three main components: deriving the theoretical expectation from first principles, implementing a specified pseudo-random number generator (PRNG), and designing the simulation logic.\n\n### 1. Theoretical Expectation of Trials $E[T]$\n\nThe core of the problem is to determine the expected number of trials, $E[T]$, required to collect all $n$ distinct coupon types. Let $T$ be the random variable representing the total number of trials. We can decompose $T$ into a sum of simpler random variables.\n\nLet $T_i$ be the number of additional trials required to obtain the $i$-th new coupon type, given that $i-1$ distinct types have already been collected. The total number of trials is the sum of the trials needed for each new coupon:\n$$\nT = T_1 + T_2 + \\dots + T_n\n$$\nBy the linearity of expectation, the expected total number of trials is the sum of the expected values of these individual stages:\n$$\nE[T] = E\\left[\\sum_{i=1}^{n} T_i\\right] = \\sum_{i=1}^{n} E[T_i]\n$$\nNow, let's find the expectation $E[T_i]$ for each stage $i$. At the beginning of stage $i$, we have collected $i-1$ distinct coupon types. The total number of coupon types is $n$. Therefore, the number of coupon types not yet collected is $n - (i-1)$. Since each of the $n$ types is drawn with equal probability $1/n$, the probability of drawing any specific uncollected type is $1/n$. Thus, the probability of drawing any new (uncollected) type in a single trial is:\n$$\np_i = \\frac{n - (i-1)}{n}\n$$\nThe process of waiting for the first success (drawing a new coupon type) in a series of independent Bernoulli trials is described by a geometric distribution. The random variable $T_i$ follows a geometric distribution with success probability $p_i$. The expected number of trials until the first success for a geometric distribution with parameter $p$ is $1/p$. Therefore, the expected number of trials for stage $i$ is:\n$$\nE[T_i] = \\frac{1}{p_i} = \\frac{n}{n - i + 1}\n$$\nSubstituting this back into the sum for $E[T]$:\n$$\nE[T] = \\sum_{i=1}^{n} \\frac{n}{n - i + 1}\n$$\nTo simplify this expression, we can perform a change of index. Let $k = n - i + 1$. When $i=1$, $k=n$. When $i=n$, $k=1$. The sum becomes:\n$$\nE[T] = \\sum_{k=1}^{n} \\frac{n}{k} = n \\sum_{k=1}^{n} \\frac{1}{k}\n$$\nThe sum $\\sum_{k=1}^{n} \\frac{1}{k}$ is the $n$-th harmonic number, denoted $H_n$. Thus, $E[T] = n H_n$. This formula will be used to compute the theoretical expectation.\n\n### 2. Algorithmic Design\n\nThe solution is structured around a main function that processes each test case. For each case, it computes both the theoretical expectation and an empirical estimate via Monte Carlo simulation, and then finds the absolute error.\n\n**A. Pseudo-Random Number Generator (PRNG)**\n\nA Linear Congruential Generator (LCG) is implemented to serve as the source of randomness.\n-   **State and Recurrence:** The generator maintains an internal state, $x_t$. The next state is calculated using the recurrence $x_{t+1} = (a x_t + c) \\bmod m$. The problem specifies the parameters $a=16807$, $c=0$, and $m=2^{31}-1$. The state is initialized with a given seed $s$.\n-   **Implementation:** A class `LCG` encapsulates the state and parameters. A method `_next_raw()` computes and returns the next value in the sequence, updating the internal state. The calculation $(a \\cdot x_t)$ can exceed $2^{31}-1$, so 64-bit integer arithmetic (or Python's arbitrary-precision integers) is necessary to prevent overflow before the modulo operation.\n\n**B. Unbiased Uniform Integer Sampler**\n\nThe raw output from the LCG is not uniformly distributed over $\\{0, 1, \\dots, n-1\\}$ if we simply take the result modulo $n$. To correct this bias, rejection sampling is employed as specified.\n-   **Rejection Threshold:** First, a threshold $t^\\star$ is calculated: $t^\\star = \\lfloor \\frac{m-1}{n} \\rfloor \\cdot n$. This value is the largest multiple of $n$ that is less than or equal to $m-1$.\n-   **Sampling Logic:** A sampling method generates integers as follows:\n    1.  Generate a raw value $x_t$ from the LCG.\n    2.  Map this to the range $\\{0, 1, \\dots, m-2\\}$ by computing $y = x_t - 1$.\n    3.  If $y  t^\\star$, the sample is accepted. The function returns $y \\bmod n$. Because the range of accepted $y$ values, $[0, t^\\star-1]$, has a length that is a multiple of $n$, each output value in $\\{0, 1, \\dots, n-1\\}$ is produced with equal frequency.\n    4.  If $y \\ge t^\\star$, the sample is rejected, and the process repeats from step 1 until a sample is accepted.\n\n**C. Monte Carlo Simulation**\n\nThe core of the empirical estimation is the simulation of the coupon collection process.\n-   **Single Replication:** A function `run_single_collection(n, prng)` executes one full run of the experiment.\n    1.  Initialize a boolean array `collected` of size $n$ to `False` to track which coupon types have been seen.\n    2.  Initialize `distinct_coupons_count = 0` and `trials = 0`.\n    3.  Loop until `distinct_coupons_count` equals $n$:\n        - Increment `trials`.\n        - Use the unbiased sampler to draw a coupon `c` from $\\{0, 1, \\dots, n-1\\}$.\n        - If `collected[c]` is `False`, it's a new coupon. Set `collected[c]` to `True` and increment `distinct_coupons_count`.\n    4.  Return the final `trials` count.\n-   **Main Simulation Loop:** For each test case $(n, M, s)$:\n    1.  Instantiate the `LCG` with the seed $s$.\n    2.  Run a loop $M$ times. In each iteration, call `run_single_collection` and store the resulting number of trials.\n    3.  Calculate the empirical mean $\\hat{E}[T]$ by averaging the $M$ trial counts.\n\n**D. Final Calculation and Output**\n\nFor each test case, the program performs the following final steps:\n1.  Calculate the theoretical expectation $E[T] = n \\sum_{k=1}^{n} \\frac{1}{k}$.\n2.  Run the Monte Carlo simulation to obtain the empirical mean $\\hat{E}[T]$.\n3.  Compute the absolute error $|\\hat{E}[T] - E[T]|$.\n4.  Store the three floating-point values $[\\hat{E}[T], E[T], |\\hat{E}[T]-E[T]|]$ in a results list.\n5.  After processing all test cases, format the list of results into the specified string format `[[...],[...],...]` and print it to standard output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass LCG:\n    \"\"\"\n    Implements a Linear Congruential Generator (LCG) with rejection sampling.\n    x_{t+1} = (a * x_t + c) mod m\n    \"\"\"\n    def __init__(self, seed: int, a: int, c: int, m: int):\n        if not (0  seed  m):\n            raise ValueError(\"Seed must be in the range (0, m-1)\")\n        self.state = seed\n        self.a = a\n        self.c = c\n        self.m = m\n\n    def _next_raw(self) - int:\n        \"\"\"\n        Generates the next integer in the LCG sequence.\n        \"\"\"\n        self.state = (self.a * self.state + self.c) % self.m\n        return self.state\n\n    def get_uniform_draw(self, n: int, t_star: int) - int:\n        \"\"\"\n        Generates a uniform integer in {0, ..., n-1} using unbiased rejection sampling.\n        \"\"\"\n        while True:\n            # Generate a raw value from the LCG.\n            raw_val = self._next_raw()\n            \n            # Map to the range {0, ..., m-2}\n            y = raw_val - 1\n            \n            # Accept if y is in the valid range [0, t_star - 1]\n            if y  t_star:\n                return y % n\n            # Otherwise, reject and retry.\n\ndef run_single_collection(n: int, prng: LCG) - int:\n    \"\"\"\n    Simulates one full coupon collection process for n coupons.\n\n    Args:\n        n (int): The number of distinct coupon types.\n        prng (LCG): An initialized LCG instance.\n\n    Returns:\n        int: The total number of trials to collect all n coupons.\n    \"\"\"\n    if n == 1:\n        return 1\n\n    # Pre-calculate the rejection sampling threshold t_star\n    t_star = ((prng.m - 1) // n) * n\n    \n    collected_coupons = [False] * n\n    distinct_coupons_count = 0\n    trials = 0\n\n    while distinct_coupons_count  n:\n        trials += 1\n        coupon = prng.get_uniform_draw(n, t_star)\n        \n        if not collected_coupons[coupon]:\n            collected_coupons[coupon] = True\n            distinct_coupons_count += 1\n    \n    return trials\n\ndef calculate_theoretical_e(n: int) - float:\n    \"\"\"\n    Calculates the theoretical expected number of trials E[T] = n * H_n.\n\n    Args:\n        n (int): The number of distinct coupon types.\n\n    Returns:\n        float: The theoretical expectation E[T].\n    \"\"\"\n    if n == 0:\n        return 0.0\n    \n    harmonic_sum = sum(1.0 / k for k in range(1, n + 1))\n    return n * harmonic_sum\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    # LCG parameters from the problem statement\n    a = 16807\n    c = 0\n    m = 2**31 - 1\n    \n    # Test cases from the problem statement\n    test_cases = [\n        # (n, M, seed)\n        (1, 100, 12345),\n        (5, 10000, 987654321),\n        (50, 2000, 42),\n        (200, 800, 20231107),\n    ]\n\n    all_results = []\n\n    for n, M, s in test_cases:\n        # 1. Calculate theoretical expectation\n        e_t = calculate_theoretical_e(n)\n\n        # 2. Run Monte Carlo simulation\n        prng = LCG(seed=s, a=a, c=c, m=m)\n        \n        trial_counts = np.empty(M, dtype=int)\n        for i in range(M):\n            # The PRNG state is carried over between replications\n            trial_counts[i] = run_single_collection(n, prng)\n        \n        hat_e_t = np.mean(trial_counts)\n\n        # 3. Calculate absolute error\n        abs_error = abs(hat_e_t - e_t)\n\n        # 4. Store results as floats\n        all_results.append([float(hat_e_t), float(e_t), float(abs_error)])\n\n    # Final print statement in the exact required format.\n    # Using str() on a list creates the [item1, item2, ...] representation.\n    # Joining these string representations with a comma creates the desired output.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A sequence of numbers can appear perfectly uniform in one dimension yet hide damning non-random patterns in higher dimensions. This exercise challenges you to expose the famous lattice structure inherent in simple generators like LCGs . By generating sequences and calculating specific metrics, you will gain a profound, practical understanding of why these generators can be dangerously inadequate for multi-dimensional simulations, a lesson that motivates the need for more modern, sophisticated designs.",
            "id": "3264088",
            "problem": "Consider sequences produced by deterministic maps on residue classes modulo an integer, and their behavior when normalized to the unit interval. Let $m \\in \\mathbb{N}$, and let $(X_i)_{i \\ge 0}$ be a sequence with $X_i \\in \\{0,1,\\dots,m-1\\}$, together with its normalized form $U_i = X_i / m \\in [0,1)$. The one-dimensional marginal uniformity is defined discretely as visiting each residue exactly once over a full cycle, and the two-dimensional structure is assessed by the geometry of successive pairs $(U_i, U_{i+1})$.\n\nStarting from the foundational definitions of modular arithmetic and bijections of residue classes, design and implement generators that produce sequences with the following properties:\n- A generator whose one-dimensional marginal distribution over $\\{0,1,\\dots,m-1\\}$ is exactly uniform in the sense that over one cycle every residue appears exactly once.\n- A generator whose successive pairs $(X_i, X_{i+1})$ satisfy a linear modular relation, so that the normalization to $(U_i,U_{i+1})$ exhibits an easily detectable geometric structure in two dimensions.\n\nYour program must:\n1. Generate the sequences required by each test case.\n2. Compute the following quantitative metrics for each test case, all based on the normalized pairs $(U_i, U_{i+1})$:\n    - The one-dimensional uniformity ratio defined as $|\\mathrm{VisitedStates}| / m$, where $|\\mathrm{VisitedStates}|$ is the number of distinct values in $\\{X_i\\}$ observed over one detected cycle. This ratio is a real number in $[0,1]$.\n    - The occupancy count of a uniform grid of size $G \\times G$ over $[0,1) \\times [0,1)$, defined as the number of distinct grid cells hit by the set of pairs $(U_i, U_{i+1})$ with cell indices $(\\lfloor G U_i \\rfloor, \\lfloor G U_{i+1} \\rfloor)$. This count is an integer.\n    - The Pearson correlation coefficient between the components of the pair cloud $(U_i,U_{i+1})$, taken over all available pairs. This coefficient is a real number.\n    - The number of distinct bins of the modular difference $(X_{i+1} - X_i) \\bmod m$ under coarse binning of width $m/G$, i.e., the count of distinct values of $\\left\\lfloor \\frac{(X_{i+1} - X_i) \\bmod m}{m/G} \\right\\rfloor$. This count is an integer.\n\nUse only the definitions of modular arithmetic and bijections on residue classes as the fundamental base. Do not rely on any unproven shortcut formulas. You must derive from first principles why the one-dimensional marginal can be exactly uniform and simultaneously why the two-dimensional successive-pair plot can display a visible structure.\n\nImplement the following test suite, which is designed to cover a general case, a boundary case, and comparative cases. For all cases, use $G = 64$:\n- Case A (additive congruential full cycle): modulus $m = 4096$, increment $c = 5$, seed $X_0 = 0$. Generate a sequence by successively adding $c$ modulo $m$ until the state repeats, then stop at the first repeat.\n- Case B (additive congruential short cycle edge case): modulus $m = 4096$, increment $c = 512$, seed $X_0 = 0$. Generate the sequence by successive addition modulo $m$ until the state repeats, then stop.\n- Case C (linear congruential general case): modulus $m = 4096$, multiplier $a = 5$, increment $c = 1$, seed $X_0 = 1$. Generate the sequence by repeated application of a linear map modulo $m$ until the state repeats, then stop.\n- Case D (independent uniform baseline): modulus $m = 4096$, seed $s = 12345$. Generate $m$ independent samples $U_i \\in [0,1)$, set $X_i = \\lfloor m U_i \\rfloor$, and use the first $m$ values without cycle detection.\n\nFor each case, compute the four metrics listed above using all available consecutive pairs $(U_i, U_{i+1})$, where the index $i$ runs over the generated sequence positions for that case and stops before the last element when pairs are not wrapped. Express all quantities as pure numbers without units.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each caseâ€™s result is a four-element list in the order: $[$uniformity ratio$, $occupancy count$, $correlation coefficient$, $difference-bin count$]. For example, the output should look like $[[r_1,o_1,\\rho_1,b_1],[r_2,o_2,\\rho_2,b_2],[r_3,o_3,\\rho_3,b_3],[r_4,o_4,\\rho_4,b_4]]$, with no extra whitespace or text.",
            "solution": "The problem requires an analysis and implementation of deterministic sequences generated by modular arithmetic, commonly used in pseudo-random number generation. The core of the task is to understand, from first principles, the properties of these sequences, specifically their one-dimensional uniformity and two-dimensional structure.\n\n## Foundational Principles\n\n### Modular Arithmetic and LCGs\nA sequence $(X_i)_{i \\ge 0}$ is generated within the set of residue classes modulo $m$, $\\mathbb{Z}_m = \\{0, 1, \\dots, m-1\\}$. A widely studied class of such generators is the Linear Congruential Generator (LCG), defined by the recurrence relation:\n$$X_{i+1} = (a X_i + c) \\bmod m$$\nwhere $m  0$ is the modulus, $a$ is the multiplier, $c$ is the increment, and $X_0$ is the seed. When $a=1$, the generator is called an Additive Congruential Generator (ACG). The normalized sequence is given by $U_i = X_i/m \\in [0, 1)$.\n\n### One-Dimensional Uniformity and Periodicity\nA key property of a good generator is a long period. The period is the smallest $p  0$ such that $X_{i+p} = X_i$ for all $i$. For the generator to be maximally useful, we desire the period to be as large as possible. An LCG has a full period of $m$ if and only if it generates every integer in $\\{0, 1, \\dots, m-1\\}$ exactly once before repeating. This confers perfect one-dimensional marginal uniformity, meaning the uniformity ratio $|\\mathrm{VisitedStates}|/m$ is exactly $1$.\n\nThe conditions for a full period depend on the parameters $a$, $c$, and $m$.\n1.  **For an ACG ($a=1$):** The recurrence is $X_{i+1} = (X_i + c) \\bmod m$. The sequence of states is an arithmetic progression modulo $m$. The sequence has a full period $m$ if and only if the increment $c$ is a generator of the additive group $\\mathbb{Z}_m$, which requires that $c$ is coprime to $m$. That is, $\\gcd(c, m) = 1$. If $\\gcd(c, m) = d  1$, the period is shortened to $m/d$.\n\n2.  **For an LCG ($a1$):** When the modulus $m$ is a power of $2$, say $m = 2^k$ for $k \\ge 2$, the celebrated Hull-Dobell Theorem states that the LCG has a full period $m$ if and only if:\n    -   $c$ is odd (i.e., $\\gcd(c, m) = 1$).\n    -   $a \\equiv 1 \\pmod 4$.\n\n### Two-Dimensional Structure\nThe deterministic nature of LCGs imposes a rigid structure on successive pairs $(X_i, X_{i+1})$. Normalizing the LCG recurrence, we get:\n$$m U_{i+1} = (a m U_i + c) \\pmod m$$\nDividing by $m$ gives:\n$$U_{i+1} = (a U_i + c/m) \\pmod 1$$\nThis equation reveals that all successive pairs $(U_i, U_{i+1})$ lie on a finite number of parallel hyperplanes. In two dimensions, these are lines. Specifically, the points fall on the line segments defined by $y = ax + c/m - k$ for integers $k$ such that the line intersects the unit square $[0,1) \\times [0,1)$. This inherent lattice structure is an \"easily detectable geometric structure\" and a well-known weakness of LCGs, which the specified metrics are designed to quantify.\n\n## Analysis of Test Cases\n\nFor all cases, the grid size for occupancy metrics is $G=64$.\n\n**Case A: Additive Congruential, Full Cycle**\n($m=4096$, $c=5$, $X_0=0$, $a=1$)\n-   **Uniformity:** $m=4096=2^{12}$ and $c=5$. Since $5$ is an odd number, it shares no factors with a power of 2, so $\\gcd(5, 4096)=1$. The ACG has a full period of $m=4096$. The sequence visits every state in $\\{0, \\dots, 4095\\}$ exactly once. The uniformity ratio is $4096/4096 = 1.0$.\n-   **Structure:** The pairs $(U_i, U_{i+1})$ satisfy $U_{i+1} = (U_i + 5/4096) \\pmod 1$. The points lie on two parallel lines. A strong positive correlation is expected. The modular difference $(X_{i+1} - X_i) \\bmod m$ is always $5$. This single value falls into bin $\\lfloor 5 / (4096/64) \\rfloor = \\lfloor 5/64 \\rfloor = 0$. Thus, the difference-bin count is $1$.\n\n**Case B: Additive Congruential, Short Cycle**\n($m=4096$, $c=512$, $X_0=0$, $a=1$)\n-   **Uniformity:** Here, $c=512=2^9$. The greatest common divisor is $\\gcd(512, 4096) = 512$. The period is $m/\\gcd(c,m) = 4096/512 = 8$. The sequence only visits $8$ states. The uniformity ratio is $8/4096 = 1/512$.\n-   **Structure:** The $8$ states are all multiples of $512$. The pairs $(U_i, U_{i+1})$ lie on a single line $y=x+1/8$. The correlation will be perfect. The modular difference is always $512$, falling into bin $\\lfloor 512 / 64 \\rfloor = 8$. The difference-bin count is $1$.\n\n**Case C: Linear Congruential, General Case**\n($m=4096$, $a=5$, $c=1$, $X_0=1$)\n-   **Uniformity:** The Hull-Dobell conditions are satisfied: $m=2^{12}$, $c=1$ is odd, and $a=5 \\equiv 1 \\pmod 4$. The LCG has a full period of $m=4096$. The uniformity ratio is $1.0$.\n-   **Structure:** The pairs $(U_i, U_{i+1})$ lie on $a=5$ parallel lines defined by $U_{i+1} = (5 U_i + 1/4096) \\pmod 1$. The modular difference is $(X_{i+1} - X_i) \\bmod m = (4X_i + 1) \\bmod m$. Since $X_i$ sweeps through all residues, and $\\gcd(4, 4096)=4$, the difference takes on $4096/4=1024$ distinct values, all congruent to $1 \\pmod 4$. These values are $\\{1, 5, 9, \\dots\\}$. These $1024$ values are well-distributed over $[0, 4096)$ and will fall into all $G=64$ bins of width $m/G=64$. The difference-bin count will be $64$.\n\n**Case D: Independent Uniform Baseline**\n($m=4096$, $s=12345$)\n-   This case serves as a benchmark for \"good\" randomness, where successive values are independent.\n-   **Uniformity:** $m=4096$ values are drawn. The number of unique states visited relates to the coupon collector's problem. The expected number of unique values is $m(1-(1-1/m)^m) \\approx m(1-1/e) \\approx 0.632m$. So the ratio should be near $0.632$.\n-   **Structure:** With independent pairs $(U_i, U_{i+1})$, the points should be scattered uniformly over the unit square with no discernible linear structure. The Pearson correlation should be close to $0$. The points should occupy many grid cells, with an expected count similar to the uniformity result, approximately $m(1-e^{-1}) \\approx 2588$. The modular differences $(X_{i+1}-X_i)\\bmod m$ will be approximately uniform over $\\{0, \\dots, m-1\\}$. With $4095$ such differences, it is overwhelmingly probable that all $64$ bins will be visited. The difference-bin count should be $64$.\n\n## Quantitative Metrics\nThe problem defines four metrics to be computed:\n1.  **Uniformity Ratio:** $R_U = \\frac{|\\{X_i\\}|}{m}$, where $|\\{X_i\\}|$ is the number of distinct states visited in a cycle.\n2.  **Occupancy Count:** $N_{occ} = |\\{(\\lfloor G U_i \\rfloor, \\lfloor G U_{i+1} \\rfloor)\\}|$, the number of unique cells in a $G \\times G$ grid hit by pairs $(U_i, U_{i+1})$.\n3.  **Pearson Correlation Coefficient:** $\\rho(U_i, U_{i+1}) = \\frac{\\mathrm{Cov}(U_i, U_{i+1})}{\\sigma_{U_i}\\sigma_{U_{i+1}}}$, measuring linear correlation between successive normalized values.\n4.  **Difference-Bin Count:** $N_{db} = |\\{\\lfloor \\frac{(X_{i+1}-X_i)\\bmod m}{m/G} \\rfloor\\}|$, the number of unique coarse bins hit by the modular difference.\n\nThe implementation will now follow these principles to generate the sequences and compute the specified metrics for each case.",
            "answer": "```python\nimport numpy as np\n\ndef generate_sequence_lcg(m, a, c, x0):\n    \"\"\"\n    Generates a sequence from a Linear Congruential Generator (LCG)\n    X_{i+1} = (a * X_i + c) mod m, until the first state repeats.\n    \"\"\"\n    seq = []\n    # Use a dictionary for fast lookups and to store the first occurrence index.\n    visited = {}\n    x = x0\n    i = 0\n    while x not in visited:\n        visited[x] = i\n        seq.append(x)\n        x = (a * x + c) % m\n        i += 1\n    return np.array(seq, dtype=np.int64)\n\ndef calculate_metrics(X, m, G):\n    \"\"\"\n    Calculates the four specified metrics for a given sequence X.\n    \"\"\"\n    # 1. One-dimensional uniformity ratio\n    # Using np.unique is a robust way to count distinct elements.\n    num_distinct_states = len(np.unique(X))\n    uniformity_ratio = num_distinct_states / m\n\n    if len(X)  2:\n        # Cannot compute pair-based metrics if sequence length is less than 2.\n        return [uniformity_ratio, 0, 0.0, 0]\n\n    # Create consecutive pairs from the sequence\n    X_i = X[:-1]\n    X_ip1 = X[1:]\n\n    # Normalize pairs to the unit interval [0, 1)\n    U_i = X_i / m\n    U_ip1 = X_ip1 / m\n\n    # 2. Occupancy count of a uniform grid\n    grid_indices = np.floor(np.vstack([U_i * G, U_ip1 * G]).T).astype(np.int32)\n    # Using a set of tuples is an efficient way to count unique 2D integer points.\n    unique_cells = set(map(tuple, grid_indices))\n    occupancy_count = len(unique_cells)\n\n    # 3. Pearson correlation coefficient\n    # Check for constant series to avoid NaN from division by zero in correlation formula.\n    if np.std(U_i) == 0 or np.std(U_ip1) == 0:\n        correlation = 1.0 if np.array_equal(U_i, U_ip1) else 0.0\n    else:\n        correlation = np.corrcoef(U_i, U_ip1)[0, 1]\n\n    # 4. Number of distinct bins of the modular difference\n    # np.mod ensures the result is in [0, m), correctly handling negative differences.\n    diff = np.mod(X_ip1 - X_i, m)\n    bin_width = m / G\n    diff_bins = np.floor(diff / bin_width)\n    diff_bin_count = len(np.unique(diff_bins))\n    \n    return [uniformity_ratio, occupancy_count, correlation, diff_bin_count]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results in the required format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Format: (name, (m, a, c, x0), G) or (name, (m, seed), G)\n    test_cases = [\n        ('A', (4096, 1, 5, 0), 64),\n        ('B', (4096, 1, 512, 0), 64),\n        ('C', (4096, 5, 1, 1), 64),\n        ('D', (4096, 12345), 64)\n    ]\n\n    results = []\n    for case in test_cases:\n        name, params, G = case\n        \n        if name == 'D':\n            m, seed = params\n            # Generate sequence for Case D (independent uniform baseline)\n            rng = np.random.default_rng(seed=seed)\n            U = rng.random(size=m)\n            X = np.floor(m * U).astype(np.int64)\n        else:\n            # Generate sequence for Cases A, B, C (LCGs)\n            m, a, c, x0 = params\n            X = generate_sequence_lcg(m, a, c, x0)\n            \n        metrics = calculate_metrics(X, m, G)\n        results.append(metrics)\n\n    # The final print statement must produce the exact single-line format.\n    # repr() creates a string representation of the list, and replace() removes spaces.\n    print(repr(results).replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "After observing the potential pitfalls of simple generators, a crucial question arises: how can we quantitatively determine if a generator's output is \"random enough\" for our application? This advanced practice guides you through implementing one of the most fundamental statistical tools for this purpose: the Pearson $\\chi^2$ (chi-squared) test for uniformity . You will build the entire test from first principles, from generating the data with an LCG to calculating the final $p$-value, providing deep insight into the machinery of statistical validation.",
            "id": "3264207",
            "problem": "You are asked to implement, from first principles, a Pearson chi-squared test for uniformity on the output of a custom Pseudo-Random Number Generator (PRNG). Pseudo-Random Number Generator (PRNG) refers to any deterministic algorithm that produces a sequence intended to mimic independent samples from a target distribution. In this task, the PRNG will be a Linear Congruential Generator (LCG), and the target distribution is the continuous uniform distribution on the interval $\\left[0,1\\right)$.\n\nStarting from core definitions and well-tested facts, implement the following:\n\n- Construct a Linear Congruential Generator (LCG) defined by the update rule on integer state: next state equals current state multiplied by multiplier plus increment, reduced modulo modulus. Map each integer state to a real number in $\\left[0,1\\right)$ by dividing the state by the modulus. Use integer arithmetic for the LCG state updates and produce exactly $n$ samples.\n- Partition $\\left[0,1\\right)$ into $k$ equal-width bins. Based on the samples, compute the observed bin counts. The expected bin count under exact uniformity is the total number of samples divided by the number of bins.\n- Compute the Pearson chi-squared statistic from the observed counts and the expected count. Use the correct number of degrees of freedom for the chi-squared distribution.\n- Compute the $p$-value for the upper tail of the chi-squared distribution using the regularized upper incomplete gamma function. You must implement this evaluation numerically without using black-box statistical testing functions. It is acceptable to use the natural logarithm of the gamma function to improve numerical stability.\n- Decide whether to accept uniformity by comparing the $p$-value to a given significance level $\\alpha$ as a decimal. Accept uniformity when the $p$-value is greater than or equal to $\\alpha$, otherwise reject.\n\nImplementation constraints:\n\n- The program must be a complete, runnable program that uses only the Python standard library and the specified version of the Numerical Python (NumPy) library.\n- The PRNG must be custom-built and not use any external random sources.\n- The computation of the $p$-value must be implemented via a numerically stable evaluation of the regularized upper incomplete gamma function, avoiding any external statistical libraries.\n\nTest suite:\n\nProvide results for the following parameter sets. Each set is a tuple $\\left(m,a,c,s,n,k,\\alpha\\right)$ consisting of the modulus $m$, multiplier $a$, increment $c$, seed $s$, sample size $n$, number of bins $k$, and significance level $\\alpha$.\n\n- Case $1$ (happy path, widely used parameters): $\\left(2^{31}-1,16807,0,1,100000,100,0.01\\right)$.\n- Case $2$ (degenerate generator, constant sequence): $\\left(2^{16},1,0,12345,10000,50,0.01\\right)$.\n- Case $3$ (degenerate seed for multiplicative LCG): $\\left(2^{31}-1,16807,0,0,10000,50,0.01\\right)$.\n- Case $4$ (borderline reliability: small expected count per bin): $\\left(2^{31}-1,16807,0,1,200,50,0.05\\right)$.\n- Case $5$ (very small modulus causing short cycles): $\\left(8,5,0,1,1000,10,0.01\\right)$.\n\nFinal output specification:\n\n- For each case, produce a boolean indicating whether the uniformity hypothesis is accepted at significance level $\\alpha$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with no spaces, ordered by the cases above. For example: $\\left[\\text{result1},\\text{result2},\\text{result3},\\text{result4},\\text{result5}\\right]$ where each result is either $\\text{True}$ or $\\text{False}$.",
            "solution": "We construct the solution by integrating definitions and properties that connect the PRNG output to a statistical decision procedure.\n\nFirst, define a Linear Congruential Generator (LCG). Given integers $m$, $a$, $c$, and an initial seed $s$, the LCG state evolves via\n$$\nX_{n+1} = \\left(a X_n + c\\right) \\bmod m,\n$$\nwith $X_0 = s$. Each state $X_n \\in \\{0,1,\\ldots,m-1\\}$ is mapped to a real sample\n$$\nU_n = \\frac{X_n}{m},\n$$\nwhich lies in $\\left[0,1\\right)$.\n\nTo assess uniformity of $\\{U_n\\}$, partition $\\left[0,1\\right)$ into $k$ disjoint intervals (bins) of equal width. Let these bins be\n$$\nB_i = \\left[\\frac{i}{k}, \\frac{i+1}{k}\\right), \\quad i = 0,1,\\ldots,k-1.\n$$\nDefine observed counts $O_i$ by counting the number of samples that fall into $B_i$. Under the exact uniform distribution, the probability of landing in any bin is $1/k$, so the expected count in each bin is\n$$\nE = \\frac{n}{k},\n$$\nwhere $n$ is the total number of samples.\n\nThe Pearson chi-squared statistic for uniformity is\n$$\n\\chi^2 = \\sum_{i=0}^{k-1} \\frac{\\left(O_i - E\\right)^2}{E}.\n$$\nThis statistic, under the null hypothesis of uniformity, is approximately distributed as a chi-squared distribution with\n$$\n\\nu = k - 1\n$$\ndegrees of freedom, provided $n$ is large enough and expected counts are not too small. The chi-squared distribution is a special case of the gamma distribution: if $X \\sim \\chi^2_\\nu$, then $X$ has the gamma distribution with shape parameter $\\nu/2$ and scale parameter $2$. Therefore, the upper-tail $p$-value for an observed value $\\chi^2$ is connected to the regularized upper incomplete gamma function. Specifically,\n$$\np = Q\\left(\\frac{\\nu}{2},\\frac{\\chi^2}{2}\\right),\n$$\nwhere $Q(a,x)$ is the regularized upper incomplete gamma function defined by\n$$\nQ(a,x) = \\frac{\\Gamma(a,x)}{\\Gamma(a)},\n$$\nand $\\Gamma(a,x)$ is the upper incomplete gamma function while $\\Gamma(a)$ is the gamma function.\n\nTo compute $Q(a,x)$ numerically without black-box functions, use two complementary expansions for numerical stability (as in standard numerical analysis references). Let $a0$ and $x \\ge 0$. Introduce the common prefactor\n$$\n\\mathrm{pref}(a,x) = \\exp\\left(a \\ln x - x - \\ln \\Gamma(a)\\right).\n$$\nThen use:\n- A convergent series for the regularized lower incomplete gamma function $P(a,x)$ when $x  a+1$,\n$$\nP(a,x) = \\mathrm{pref}(a,x) \\sum_{n=0}^{\\infty} \\frac{x^n}{a (a+1) \\cdots (a+n)},\n$$\nimplemented via the recurrence for the series terms, and return $Q(a,x) = 1 - P(a,x)$.\n- A continued fraction for $Q(a,x)$ when $x \\ge a+1$, built on the fraction\n$$\nQ(a,x) = \\mathrm{pref}(a,x) \\cdot \\left[ \\cfrac{1}{x+1-a - \\cfrac{1 \\cdot (1-a)}{x+3-a - \\cfrac{2 \\cdot (2-a)}{x+5-a - \\cdots}}} \\right],\n$$\nwhich is evaluated via stable forward iteration of the continued fraction using standard safeguards (tiny initializations and tolerance for convergence).\n\nGiven the computed $p$-value $p$, apply the decision rule at significance level $\\alpha$:\n$$\n\\text{Accept uniformity} \\quad \\Leftrightarrow \\quad p \\ge \\alpha.\n$$\n\nAlgorithmic design:\n\n- Generate $n$ samples using integer arithmetic in the LCG. Map states to reals in $\\left[0,1\\right)$ by dividing by $m$.\n- Compute bin indices via $b(U_n) = \\min\\left(\\left\\lfloor k U_n \\right\\rfloor, k-1\\right)$ to ensure an index in $\\{0,1,\\ldots,k-1\\}$.\n- Accumulate observed counts $O_i$ via a histogram-like computation.\n- Compute $E = n/k$ and then $\\chi^2$ via the sum of squared normalized deviations.\n- Let $\\nu = k-1$, compute $a = \\nu/2$ and $x = \\chi^2/2$, evaluate $Q(a,x)$ using the split strategy above, and compare $p$ to $\\alpha$.\n\nEdge-case considerations:\n\n- Degenerate generators such as $a=1$, $c=0$ yield a constant sequence, concentrating all mass in a single bin, which produces extremely large $\\chi^2$ and $p \\approx 0$, hence rejection.\n- A multiplicative LCG with seed $s=0$ yields $U_n=0$ for all $n$, again causing rejection.\n- With small $n$ and large $k$, the expected count $E=n/k$ can be small, leading to reduced accuracy of the chi-squared approximation. The algorithm still computes a valid statistic and $p$-value, but the decision should be interpreted with caution in such regimes.\n\nThe program evaluates the five specified cases and outputs a single line consisting of five booleans enclosed in brackets with commas and no spaces, corresponding to acceptance decisions for the cases in order.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef lcg_generate(m: int, a: int, c: int, seed: int, n: int) - np.ndarray:\n    \"\"\"\n    Generate n samples in [0,1) using a Linear Congruential Generator (LCG):\n    X_{n+1} = (a * X_n + c) mod m, with X_0 = seed.\n    Returns a NumPy array of floats in [0,1).\n    \"\"\"\n    samples = np.empty(n, dtype=np.float64)\n    state = seed % m\n    for i in range(n):\n        # Map current state to [0,1)\n        samples[i] = state / m\n        # Advance state\n        state = (a * state + c) % m\n    return samples\n\ndef chi_square_uniformity(samples: np.ndarray, k: int):\n    \"\"\"\n    Compute Pearson chi-squared statistic for uniformity over k equal bins on [0,1).\n    Returns (chi2_stat, p_value).\n    \"\"\"\n    n = samples.size\n    # Bin indices: floor(k * x), clipped to k-1 to guard against edge\n    bin_indices = np.minimum((samples * k).astype(np.int64), k - 1)\n    counts = np.bincount(bin_indices, minlength=k)\n    expected = n / k\n    # Chi-squared statistic: sum((O_i - E)^2 / E)\n    diffs = counts - expected\n    chi2 = np.sum((diffs * diffs) / expected)\n    # Degrees of freedom\n    v = k - 1\n    # Upper-tail p-value using regularized upper incomplete gamma:\n    # p = Q(v/2, chi2/2)\n    a = 0.5 * v\n    x = 0.5 * chi2\n    p = gammaincc(a, x)\n    return chi2, p\n\ndef gammaincc(a: float, x: float) - float:\n    \"\"\"\n    Regularized upper incomplete gamma function Q(a, x) = Gamma(a, x) / Gamma(a).\n    Implements the Numerical Recipes-style algorithm with series for P(a, x) when x  a+1,\n    and continued fraction for Q(a, x) when x = a+1.\n    \"\"\"\n    if a = 0.0 or x  0.0:\n        raise ValueError(\"Invalid arguments for gammaincc: require a  0 and x = 0.\")\n    if x == 0.0:\n        return 1.0\n    # Common prefactor: exp(a*ln(x) - x - lnGamma(a))\n    ln_gamma_a = math.lgamma(a)\n    lnpref = a * math.log(x) - x - ln_gamma_a\n    pref = math.exp(lnpref)\n    # Switch by x relative to a+1\n    if x  a + 1.0:\n        # Compute P(a, x) via series\n        return 1.0 - _gammainc_lower_reg_series(a, x, pref)\n    else:\n        # Compute Q(a, x) via continued fraction\n        return _gammainc_upper_reg_cf(a, x, pref)\n\ndef _gammainc_lower_reg_series(a: float, x: float, pref: float) - float:\n    \"\"\"\n    Regularized lower incomplete gamma P(a, x) via series expansion.\n    Returns P(a, x).\n    \"\"\"\n    eps = 1e-14\n    max_iter = 100000\n    sum_term = 1.0 / a\n    term = sum_term\n    ap = a\n    for n in range(1, max_iter + 1):\n        ap += 1.0\n        term *= x / ap\n        sum_term += term\n        if abs(term)  abs(sum_term) * eps:\n            break\n    return pref * sum_term\n\ndef _gammainc_upper_reg_cf(a: float, x: float, pref: float) - float:\n    \"\"\"\n    Regularized upper incomplete gamma Q(a, x) via continued fraction.\n    Returns Q(a, x).\n    \"\"\"\n    eps = 1e-14\n    max_iter = 100000\n    tiny = 1e-300\n    b = x + 1.0 - a\n    c = 1.0 / tiny\n    d = 1.0 / b\n    h = d\n    for i in range(1, max_iter + 1):\n        an = -i * (i - a)\n        b += 2.0\n        d = 1.0 / (an * d + b)\n        c = b + an / c\n        if c == 0.0:\n            c = tiny\n        del_cf = d * c\n        h *= del_cf\n        if abs(del_cf - 1.0)  eps:\n            break\n    return pref * h\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each tuple: (m, a, c, seed, n, k, alpha)\n    test_cases = [\n        (2**31 - 1, 16807, 0, 1, 100000, 100, 0.01),   # Case 1: Park-Miller minimal standard\n        (2**16, 1, 0, 12345, 10000, 50, 0.01),         # Case 2: Degenerate generator (constant)\n        (2**31 - 1, 16807, 0, 0, 10000, 50, 0.01),     # Case 3: Seed zero degeneracy\n        (2**31 - 1, 16807, 0, 1, 200, 50, 0.05),       # Case 4: Borderline small expected count\n        (8, 5, 0, 1, 1000, 10, 0.01),                  # Case 5: Very small modulus, short cycle\n    ]\n\n    results = []\n    for case in test_cases:\n        m, a, c, seed, n, k, alpha = case\n        samples = lcg_generate(m, a, c, seed, n)\n        chi2, pval = chi_square_uniformity(samples, k)\n        accept = pval = alpha\n        results.append(accept)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}