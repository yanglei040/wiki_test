{
    "hands_on_practices": [
        {
            "introduction": "理论模型（如阿姆达尔定律）虽然强大，但其真正的价值在于与真实世界的性能数据相结合。第一个练习将挑战你扮演性能分析师的角色：利用并行程序的原始运行时测量数据，估算其串行分数 $s$。这个关键参数决定了程序的可扩展性。通过将数据拟合到源自阿姆达尔定律的模型，你将亲身体验如何量化固定规模问题的内在局限性。",
            "id": "3270745",
            "problem": "给定一个黑盒科学程序的测量数据，该程序在分布式内存高性能计算（HPC）环境中，最多可在 $P=1024$ 个相同的处理核心上执行。目标是在固定规模问题假设下，推断该程序工作负载的串行分数 $s$。使用以下基本原理来指导您的推理和方法：对于固定工作负载，在 $P$ 个处理单元上的加速比定义为 $S(P)=T(1)/T(P)$，其中 $T(P)$ 是使用 $P$ 个处理单元时的执行时间；总运行时间可分解为一个不可并行的部分和一个可以均匀分布在所有处理单元上的部分，忽略其他开销来源并假设完美负载均衡。\n\n您的任务是设计并实现一个程序，对每个给定的数据集，通过将固定规模运行时间分解模型拟合到观测到的加速曲线上，来估计串行分数 $s$。您的估计器必须能稳健地处理数据中存在 $P=1$ 的情况。每个数据集的输出必须是一个十进制形式的实数 $s$。报告 $s$ 时，四舍五入保留六位小数。由于 $s$ 是无量纲的，因此不需要单位。\n\n实现要求：\n- 使用定义 $S(P)=T(1)/T(P)$。\n- 每个数据集使用所有提供的数据点。\n- 为进行估计，应将模型假设视为精确的；如果数据完全遵循模型，您的估计器应能精确地恢复 $s$。如果数据中存在 $P=1$ 的情况，请在拟合过程中正确处理，避免出现除以零或未定义的操作。\n\n测试套件：\n对于下方的每个数据集，都给出了一个核心数列表和相应的测量时间列表。在每个数据集中，所有时间都使用相同的任意时间单位。\n\n- 数据集 A（宽 $P$ 范围，中等串行分数）：\n  - $P$: $[1,2,4,8,16,32,64,128,256,512,1024]$\n  - $T(P)$: $[100.0,56.0,34.0,23.0,17.5,14.75,13.375,12.6875,12.34375,12.171875,12.0859375]$\n\n- 数据集 B（宽 $P$ 范围，极小串行分数）：\n  - $P$: $[1,2,4,8,16,32,64,128,256,512,1024]$\n  - $T(P)$: $[100.0,50.5,25.75,13.375,7.1875,4.09375,2.546875,1.7734375,1.38671875,1.193359375,1.0966796875]$\n\n- 数据集 C（有限 $P$ 范围，大串行分数）：\n  - $P$: $[1,2,4,8,16]$\n  - $T(P)$: $[80.0,60.0,50.0,45.0,42.5]$\n\n- 数据集 D（宽 $P$ 范围，理想并行情况）：\n  - $P$: $[1,2,4,8,16,32,64,128,256,512,1024]$\n  - $T(P)$: $[64.0,32.0,16.0,8.0,4.0,2.0,1.0,0.5,0.25,0.125,0.0625]$\n\n- 数据集 E（宽 $P$ 范围，完全串行情况）：\n  - $P$: $[1,2,4,8,16,32,64,128,256,512,1024]$\n  - $T(P)$: $[42.0,42.0,42.0,42.0,42.0,42.0,42.0,42.0,42.0,42.0,42.0]$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，“[rA,rB,rC,rD,rE]”），其中 rA 是数据集 A 的估计值，rB 是数据集 B 的估计值，依此类推直到数据集 E。每个值必须使用标准四舍五入到最近的规则保留六位小数，当平局时向远离零的方向舍入（按典型浮点格式化的实现方式）。",
            "solution": "问题陈述已经过分析，被认为是有效的。它在科学上基于并行计算的原理，特别是针对固定规模问题的 Amdahl 定律。该问题定义明确，提供了足够的数据和估计模型参数 $s$ 的清晰目标。术语精确且客观。所提供的数据集是一致的，可作为所提出模型的有效测试用例，包括理想情况和边缘情况。\n\n问题的核心是，给定在 $P$ 个处理核心上的一系列运行时间测量值 $T(P)$，估计程序的串行分数 $s$。其指导原则是将单个处理器上的总运行时间 $T(1)$ 分解为一个串行部分和一个可并行化部分。\n\n令 $s$ 为串行分数，其中 $0 \\le s \\le 1$。那么程序中可并行的部分为 $(1-s)$。\n工作负载串行部分所需的时间为 $s \\cdot T(1)$。这个时间与处理器数量 $P$ 无关，是一个常数。\n工作负载可并行部分在单个处理器上所需的时间为 $(1-s) \\cdot T(1)$。当分布到 $P$ 个处理器上，并假设无开销的完美并行，这个时间变为 $\\frac{(1-s) \\cdot T(1)}{P}$。\n\n在 $P$ 个处理器上的总执行时间 $T(P)$ 是串行执行时间和并行执行时间之和：\n$$T(P) = s \\cdot T(1) + \\frac{(1-s) \\cdot T(1)}{P}$$\n这个方程是 Amdahl 定律针对运行时间的一种具体表述。我们的目标是根据所提供的数据对 $(P_i, T(P_i))$ 来估计 $s$。\n\n为了估计 $s$，我们可以将此方程重构为一个线性模型，该模型适用于标准的线性回归技术。让我们定义一个新的自变量 $x = 1/P$。该方程可以重写为：\n$$T(P) = (s \\cdot T(1)) + ( (1-s) \\cdot T(1) ) \\cdot \\frac{1}{P}$$\n该方程具有直线形式 $y = c + m \\cdot x$，其中：\n- 因变量是 $y = T(P)$。\n- 自变量是 $x = 1/P$。\n- y轴截距是 $c = s \\cdot T(1)$。这代表了纯串行部分的运行时间，也就是当 $P \\to \\infty$（即 $x \\to 0$）时的理论运行时间。\n- 斜率是 $m = (1-s) \\cdot T(1)$。这代表了工作负载的可并行化部分在单个核心上运行时的总时间。\n\n给定 $N$ 个数据点 $(P_i, T_i)$，我们可以从中生成一组用于线性回归的点 $(x_i, y_i) = (1/P_i, T_i)$。这包括 $P=1$（此时 $x=1$）的数据点。通过对这些点使用线性最小二乘回归，我们可以找到截距 $\\hat{c}$ 和斜率 $\\hat{m}$ 的最佳拟合估计值。\n\n一旦我们有了 $\\hat{c}$ 和 $\\hat{m}$，我们就可以推导出 $s$ 的估计值。根据我们对斜率和截距的定义，它们的和是：\n$$\\hat{c} + \\hat{m} \\approx s \\cdot T(1) + (1-s) \\cdot T(1) = T(1)$$\n这个和 $\\hat{c} + \\hat{m}$ 提供了模型基于所有可用数据对总的单处理器运行时间 $T(1)$ 的最佳估计。\n\n串行分数 $s$ 是串行执行时间与总的单处理器执行时间之比。使用我们估计的参数：\n$$\\hat{s} = \\frac{\\text{serial time}}{\\text{total time}} = \\frac{s \\cdot T(1)}{T(1)} \\approx \\frac{\\hat{c}}{\\hat{c} + \\hat{m}}$$\n这个公式为 $s$ 提供了一个稳健的估计器，它结合了从完整数据集中导出的斜率和截距的信息。此方法能正确处理边缘情况：\n- 对于理想并行程序（$s=0$），运行时间为 $T(P) = T(1)/P$。线性模型是 $y = 0 + T(1) \\cdot x$。回归将得出 $\\hat{c} = 0$，因此 $\\hat{s} = 0 / (0 + \\hat{m}) = 0$。\n- 对于完全串行程序（$s=1$），运行时间为 $T(P) = T(1)$。线性模型是 $y = T(1) + 0 \\cdot x$。回归将得出 $\\hat{m} = 0$，因此 $\\hat{s} = \\hat{c} / (\\hat{c} + 0) = 1$。\n\n实现将使用 `numpy.linalg.lstsq` 来执行线性回归。对于每个运行时间 $T$ 和核心数 $P$ 的数据集，我们求解线性系统 $A \\cdot \\mathbf{p} = T$ 以获得参数向量 $\\mathbf{p} = [\\hat{c}, \\hat{m}]^T$。设计矩阵 $A$ 的构造方式是：其第一列全为1（对应截距 $\\hat{c}$），第二列包含 $x_i = 1/P_i$ 的值（对应斜率 $\\hat{m}$）。在解出 $\\hat{c}$ 和 $\\hat{m}$ 后，使用导出的公式计算串行分数 $\\hat{s}$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Estimates the serial fraction 's' for several datasets of parallel program runtimes.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Dataset A\n        (\n            [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n            [100.0, 56.0, 34.0, 23.0, 17.5, 14.75, 13.375, 12.6875, 12.34375, 12.171875, 12.0859375]\n        ),\n        # Dataset B\n        (\n            [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n            [100.0, 50.5, 25.75, 13.375, 7.1875, 4.09375, 2.546875, 1.7734375, 1.38671875, 1.193359375, 1.0966796875]\n        ),\n        # Dataset C\n        (\n            [1, 2, 4, 8, 16],\n            [80.0, 60.0, 50.0, 45.0, 42.5]\n        ),\n        # Dataset D\n        (\n            [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n            [64.0, 32.0, 16.0, 8.0, 4.0, 2.0, 1.0, 0.5, 0.25, 0.125, 0.0625]\n        ),\n        # Dataset E\n        (\n            [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024],\n            [42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0]\n        )\n    ]\n\n    results = []\n    for p_cores, t_times in test_cases:\n        # Convert data to numpy arrays for vectorized operations.\n        P = np.array(p_cores, dtype=np.float64)\n        T = np.array(t_times, dtype=np.float64)\n\n        # The model is T(P) = c + m * (1/P), where c is the serial time component\n        # and m is the parallel time component on one core.\n        # We perform a linear regression of T vs. 1/P.\n        # The independent variable x is the reciprocal of the number of cores.\n        x = 1.0 / P\n        \n        # The dependent variable y is the measured runtime.\n        y = T\n\n        # We set up the design matrix A for the linear least squares problem y = A @ [c, m].\n        # The first column is ones (for the intercept c) and the second is x (for the slope m).\n        A = np.column_stack([np.ones_like(x), x])\n        \n        # Use np.linalg.lstsq to find the best-fit parameters [c, m].\n        params = np.linalg.lstsq(A, y, rcond=None)[0]\n        c, m = params[0], params[1]\n\n        # The serial fraction s is the ratio of the serial time component (c)\n        # to the total single-core time (c + m).\n        # We handle the case where c + m could be zero to avoid division by zero,\n        # although with the given data this is not expected.\n        total_single_core_time = c + m\n        if np.isclose(total_single_core_time, 0):\n            # If T(1) is zero, s is undefined. This is an invalid physical scenario.\n            # We can define s=0 as a fallback, as no work is being done.\n            s = 0.0\n        else:\n            s = c / total_single_core_time\n        \n        results.append(s)\n\n    # Format the final output string as a comma-separated list of values\n    # rounded to six decimal places, enclosed in square brackets.\n    # Standard f-string formatting is sufficient here as the problem data is perfect,\n    # leading to exact results that don't require complex rounding logic.\n    output_str = f\"[{','.join(f'{r:.6f}' for r in results)}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "阿姆达尔定律描述了加速一个固定规模问题时存在的限制，然而许多科学挑战驱使我们使用更多处理器来解决更大、更复杂的问题。这个场景引入了弱扩展（weak scaling）的概念，它通常与 Gustafson 定律联系在一起，即问题规模随处理器数量的增加而增长，以保持运行时间不变。通过一个真实的天气预报例子，你将分析计算能力的提升如何转化为更高的科学保真度，并为构建下一代超级计算机提供依据。",
            "id": "3270675",
            "problem": "一个国家气象机构运行一个数值天气预报模型，其计算成本与整个预报过程中的网格点更新总数成正比：即空间网格点数与时间步数的乘积。假设一个具有均匀立方网格间距的三维域。根据 Courant–Friedrichs–Lewy (CFL) 稳定性条件，当每个空间维度的空间网格间距被细化一个因子 $\\gamma$ 时，时间步数会增加一个因子 $\\gamma$，因此网格点更新的总数大约增加 $\\gamma^4$。\n\n在一台拥有 $P_0 = 256$ 个处理器的基准机器上，一个空间分辨率为 $\\Delta x_0$ 的预报在 $T^\\star$ 小时内完成。对该运行进行性能分析显示，可并行化的时间分数为 $(1 - f_s)$，串行分数为 $f_s = 0.05$，其中 $f_s$ 是挂钟时间中用于严格串行工作（初始化、输入/输出、全局同步）的部分，而 $(1 - f_s)$ 用于完全并行工作（独立的网格点更新）。该机构正在考虑一台拥有 $P = 8192$ 个处理器的新超级计算机，并希望在将挂钟时间保持在 $T^\\star$ 的同时，通过在三个空间维度上以相同的因子 $\\gamma$ 细化空间网格来提高预报分辨率。\n\n假设：\n- 在固定的挂钟时间内，当从 $P_0$ 移动到 $P$ 时，分数 $f_s$ 没有明显变化，\n- 并行部分在处理器间表现出理想的扩展性，\n- 在此分析级别上可以忽略通信和内存效应。\n\n在这些假设下，从加速比和工作负载的定义出发，哪个陈述最符合应用通常归因于 Gustafson 定律的弱扩展视角来证明构建更大型系统的合理性？\n\nA. 在每个空间维度上可以细化大约 $\\gamma \\approx 2.4$，同时将挂钟时间固定在 $T^\\star$，因为在时间 $T^\\star$ 内可以完成的总工作量除了串行部分外，几乎与 $P$ 呈线性增长。\n\nB. 你最多只能细化大约 $\\gamma \\approx 2.0$，因为串行分数 $f_s$ 对加速比设定了一个绝对上限，无法通过增加 $P$ 来克服。\n\nC. 你可以细化大约 $\\gamma \\approx 3.2$，因为在三维空间中，计算工作量仅以 $\\gamma^3$ 的方式增加。\n\nD. 对于 $f_s = 0.05$，你根本无法进行细化，因为加速比的上限为 $1 / f_s = 20$，与增加多少处理器无关。",
            "solution": "问题陈述已经过验证，被认为是科学上合理的、问题定义良好的、客观的且内部一致的。它为高性能计算中的可扩展性分析提供了一个标准场景。\n\n问题的核心是确定在将计算从一台拥有 $P_0$ 个处理器的机器扩展到一台拥有 $P$ 个处理器的机器时，在挂钟时间 $T^\\star$ 保持不变的约束下，可实现的细化因子 $\\gamma$。这是一个经典的弱扩展问题，适用于归因于 Gustafson 的框架。\n\n设 $T$ 为并行系统上一次计算的总挂钟时间。此时间是花费在代码串行部分的时间 $T_s$ 和花费在并行部分的时间 $T_p$ 的总和。\n$$T = T_s + T_p$$\n问题指定了时间的串行分数 $f_s$，使得 $T_s = f_s T$，并行分数是 $(1 - f_s)$，因此 $T_p = (1 - f_s)T$。由于我们保持挂钟时间固定，所以对于基准运行和扩展后的运行，这一点都成立。\n\n让我们对在时间 $T$ 内可以完成的总计算工作量 $W$ 进行建模。工作的串行部分 $W_s$ 由单个处理单元执行。假设每个处理器的操作速率为每秒 $\\kappa$ 次，则完成的串行工作量为：\n$$W_s = \\kappa T_s = \\kappa f_s T$$\n工作的并行部分 $W_p$ 分布在所有 $P$ 个处理器上。在理想扩展的情况下，完成的总并行工作量为：\n$$W_p = \\kappa P T_p = \\kappa P (1 - f_s) T$$\n在 $P$ 个处理器上，在时间 $T$ 内可以完成的总工作量 $W(P)$ 是串行和并行工作分量的总和：\n$$W(P) = W_s + W_p = \\kappa f_s T + \\kappa P (1 - f_s) T = \\kappa T (f_s + P(1-f_s))$$\n该方程描述了对于固定的时间 $T$ 和串行分数 $f_s$，可管理的工作量如何随处理器数量 $P$ 扩展。这就是 Gustafson 定律或弱扩展视角的精髓。\n\n我们有两个给定的场景：\n1.  **基准系统**：$P_0 = 256$ 个处理器，工作负载 $W_0$，时间 $T^\\star$。\n2.  **新系统**：$P = 8192$ 个处理器，工作负载 $W_1$，时间 $T^\\star$。\n\n两次运行的串行分数都给定为 $f_s = 0.05$。因此，$1 - f_s = 0.95$。\n\n对于基准系统，在时间 $T^\\star$ 内完成的总工作量 $W_0$ 是：\n$$W_0 = \\kappa T^\\star (f_s + P_0(1-f_s))$$\n对于新系统，在相同时间 $T^\\star$ 内完成的总工作量 $W_1$ 是：\n$$W_1 = \\kappa T^\\star (f_s + P(1-f_s))$$\n工作负载的比率代表了在保持运行时间不变的情况下，问题规模可以增加的因子。\n$$\\frac{W_1}{W_0} = \\frac{\\kappa T^\\star (f_s + P(1-f_s))}{\\kappa T^\\star (f_s + P_0(1-f_s))} = \\frac{f_s + P(1-f_s)}{f_s + P_0(1-f_s)}$$\n问题陈述指出，将空间网格间距细化一个因子 $\\gamma$ 会使总计算成本（工作量）增加一个因子 $\\gamma^4$。因此，我们有：\n$$\\frac{W_1}{W_0} = \\gamma^4$$\n结合这两个表达式，得到关于 $\\gamma$ 的控制方程：\n$$\\gamma^4 = \\frac{f_s + P(1-f_s)}{f_s + P_0(1-f_s)}$$\n现在，我们代入给定值：$f_s = 0.05$，$P_0 = 256$ 和 $P = 8192$。\n$$\\gamma^4 = \\frac{0.05 + 8192(0.95)}{0.05 + 256(0.95)}$$\n$$\\gamma^4 = \\frac{0.05 + 7782.4}{0.05 + 243.2} = \\frac{7782.45}{243.25}$$\n计算该比率：\n$$\\gamma^4 \\approx 31.99568$$\n这个比率非常接近 $32$。为了求得细化因子 $\\gamma$，我们取四次方根：\n$$\\gamma = (31.99568)^{1/4} \\approx 2.3784$$\n因此，空间网格可以被细化大约 $\\gamma \\approx 2.38$ 的因子。\n\n现在，我们评估每个给定的选项。\n\n**A. 在每个空间维度上可以细化大约 $\\gamma \\approx 2.4$，同时将挂钟时间固定在 $T^\\star$，因为在时间 $T^\\star$ 内可以完成的总工作量除了串行部分外，几乎与 $P$ 呈线性增长。**\n我们计算出的值是 $\\gamma \\approx 2.38$，可以很好地近似为 $2.4$。所提供的理由也是合理的。总工作量 $W(P) \\propto f_s + P(1 - f_s)$ 是 $P$ 的一个线性函数。对于较小的 $f_s$，$W(P) \\approx P(1-f_s)$，这是一种几乎线性的增长。对于给定的较大 $P_0$ 和 $P$ 值，工作负载比率 $\\frac{W_1}{W_0}$ 非常接近处理器比率 $\\frac{P}{P_0} = \\frac{8192}{256} = 32$。我们计算出的 $\\gamma^4 \\approx 32$ 证实了这一点。该陈述准确地反映了弱扩展的原理。\n**结论：正确。**\n\n**B. 你最多只能细化大约 $\\gamma \\approx 2.0$，因为串行分数 $f_s$ 对加速比设定了一个绝对上限，无法通过增加 $P$ 来克服。**\n该理由引用了 Amdahl 定律描述的强扩展限制，其中加速比 $S(P) = \\frac{1}{f_s + (1-f_s)/P}$ 的上限为 $1/f_s$。Amdahl 定律适用于固定规模的问题（强扩展），而不适用于问题规模随机器规模增大的情况（弱扩展）。该问题明确要求采用弱扩展的视角。$\\gamma \\approx 2.0$ 的值将意味着 $\\gamma^4 \\approx 16$，这大约是可实现工作负载增量的一半。\n**结论：不正确。**\n\n**C. 你可以细化大约 $\\gamma \\approx 3.2$，因为在三维空间中，计算工作量仅以 $\\gamma^3$ 的方式增加。**\n该陈述在前提上包含一个事实错误。问题明确指出，由于 CFL 条件，网格点更新的总数（工作量）大约增加 $\\gamma^4$，而不是 $\\gamma^3$。$\\gamma^3$ 因子只考虑了空间网格点的增加，忽略了所需的时间步长缩减。此外，$\\gamma \\approx 3.2$ 的细化将意味着工作量扩展为 $\\gamma^4 \\approx (3.2)^4 \\approx 105$，这与我们的计算不符。\n**结论：不正确。**\n\n**D. 对于 $f_s = 0.05$，你根本无法进行细化，因为加速比的上限为 $1 / f_s = 20$，与增加多少处理器无关。**\n与选项 B 类似，该陈述错误地应用了 Amdahl 定律（强扩展）及其相关的加速比上限 $1/f_s = 1/0.05 = 20$。该问题涉及弱扩展，其中这种限制不适用；相反，扩展加速比随 $P$ 增长。无法进行任何细化（$\\gamma=1$）的结论显然是错误的，因为可以实现分辨率的显著提高。\n**结论：不正确。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "有效的可扩展性分析通常需要超越高层次的定律，构建基于组件的详细性能模型。这个高级练习将引导你剖析一个迭代求解器的性能，考虑算法选择（如数值精度）与特定硬件瓶颈（内存带宽、网络性能和延迟）之间复杂的相互作用。通过为单精度和双精度两种情况下的求解时间建模，你将在一个真实的高性能计算场景中，学会评估权衡并识别限制性能的主要因素。",
            "id": "3270755",
            "problem": "考虑使用共轭梯度（CG）方法求解一个由三维椭圆偏微分方程离散化产生的大型稀疏对称正定线性系统。CG方法的每次迭代包括一次稀疏矩阵向量乘法、一次最近邻光环交换（halo exchange）和两次全局点积。假设使用消息传递接口（MPI）进行并行实现时，满足以下条件：\n\n- 计算受内存带宽限制，每个进程的内存带宽为 $BW$（千兆字节/秒），每次迭代的总内存流量为 $V$（千兆字节）。每次迭代的计算时间通过移动 $V$ 的数据量通过内存所需的时间来建模。\n- 光环交换每次迭代中每个进程通过网络发送 $M$（千兆字节）的数据，网络带宽为 $R$（千兆字节/秒），其通信时间通过发送 $M$ 所需的时间来建模。\n- 每个全局点积通过一次归约（reduction）操作完成，其时间主要由延迟决定，建模为每次归约 $L \\log_2(p)$ 秒，其中 $p$ 是进程数。每次迭代有两次这样的归约操作。\n\n假设矩阵和向量存储使用两种数值精度：\n- 双精度：每次迭代的总内存流量为 $V_d = 6.4$ 千兆字节，每次迭代中每进程的光环交换数据量为 $M_d = 0.2$ 千兆字节，达到目标相对残差容忍度 $\\tau$ 所需的迭代次数为 $k_d = 500$。\n- 单精度：每次迭代的总内存流量为 $V_s = 3.6$ 千兆字节，每次迭代中每进程的光环交换数据量为 $M_s = 0.1$ 千兆字节，达到相同目标容忍度 $\\tau$ 所需的迭代次数为 $k_s = 1000$。\n\n机器和网络参数如下：\n- 每进程内存带宽 $BW = 40$ 千兆字节/秒，\n- 网络带宽 $R = 10$ 千兆字节/秒，\n- 归约延迟常数 $L = 3 \\times 10^{-4}$ 秒，\n- 从 $p=1$ 到 $p=32$ 个进程的强扩展（strong scaling），采用均匀分区且忽略负载不平衡。\n\n使用这些假设以及基于带宽限制的计算和基于延迟/带宽的通信的性能建模第一性原理，分析在 $p=1$ 和 $p=32$ 时两种精度的求解时间和强扩展效率。然后确定下列哪些陈述是正确的：\n\nA. 在 $p=32$ 时，单精度CG比双精度CG获得更短的求解时间，且强扩展效率更高，因为数据量的减少主导了总成本。\n\nB. 在 $p=32$ 时，双精度比单精度获得更短的求解时间；此外，单精度和双精度的强扩展效率差异小于 $5\\%$。\n\nC. 在 $p=32$ 时，两种精度的强扩展效率主要受限于全局归约的延迟，因此进一步增加 $BW$ 不会显著减少求解时间。\n\nD. 在 $p=1$ 时，单精度比双精度产生更长的求解时间，因为迭代次数的增加超过了因数据量减少而带来的每次迭代的加速效果。\n\n选择所有适用的选项。",
            "solution": "用户希望我首先验证问题陈述，如果有效，则解决问题并评估给定的选项。\n\n### 问题验证\n\n**步骤1：提取给定信息**\n\n问题为并行共轭梯度（CG）方法提供了以下数据和模型：\n\n- **方法组件**：每次迭代包括一次稀疏矩阵向量乘法（计算）、一次最近邻光环交换（通信）和两次全局点积（通信）。\n- **性能模型（在 $p$ 个进程上每次迭代的时间）**：\n    - 计算时间：$T_{comp}(p) = (V/p) / BW$。问题陈述中提到“每次迭代的总内存流量为 $V$”，并且使用了强扩展。因此，每个进程的流量为 $V/p$。时间是该流量除以每个进程的内存带宽 $BW$。\n    - 光环交换时间：$T_{halo}(p) = M / R$。问题陈述中提到“每次迭代每个进程 $M$（千兆字节）”，这使得它成为 $p>1$ 时的一个恒定开销。\n    - 全局归约时间：$T_{redux}(p) = 2 \\cdot L \\cdot \\log_2(p)$。这考虑了两次归约操作。\n- **物理假设**：对于 $p=1$，没有进程间通信。因此，$T_{halo}(1)=0$ 且 $T_{redux}(1)=0$。\n- **精度数据（双精度）**：\n    - 总内存流量：$V_d = 6.4$ 千兆字节。\n    - 每进程光环交换数据量：$M_d = 0.2$ 千兆字节。\n    - 迭代次数：$k_d = 500$。\n- **精度数据（单精度）**：\n    - 总内存流量：$V_s = 3.6$ 千兆字节。\n    - 每进程光环交换数据量：$M_s = 0.1$ 千兆字节。\n    - 迭代次数：$k_s = 1000$。\n- **机器/网络参数**：\n    - 每进程内存带宽：$BW = 40$ 千兆字节/秒。\n    - 网络带宽：$R = 10$ 千兆字节/秒。\n    - 归约延迟常数：$L = 3 \\times 10^{-4}$ 秒。\n- **扩展参数**：\n    - 从 $p=1$到 $p=32$ 个进程的强扩展。\n\n**步骤2：使用提取的信息进行验证**\n\n对照验证标准评估问题陈述：\n\n1.  **科学依据**：该问题在高性能计算（HPC）和数值方法的原理方面有充分的依据。将运行时间分解为计算、点对点通信（光环交换）和集体通信（归约）的性能模型是一种标准方法。将这些组件建模为内存带宽、网络带宽和延迟的函数也是标准做法。数值精度（影响收敛速度，即迭代次数）和数据量（影响每次迭代的时间）之间的权衡是科学计算中的一个基本概念。\n2.  **适定性**：该问题提供了一套完整的参数和清晰的性能模型，从而可以唯一、确定性地计算出感兴趣的量（求解时间和效率）。\n3.  **客观性**：问题以精确、定量和客观的语言陈述，没有主观断言。\n4.  **一致性与现实性**：提供的带宽、延迟和数据大小的数值对于现代超级计算硬件是现实的。模型做了一个简化假设，即每进程的光环交换数据量 $M$ 是恒定的。实际上，对于一个强扩展下的三维问题，每进程的表面积与体积之比会发生变化，这意味着 $M$ 将依赖于 $p$（具体来说，按 $p^{-1/3}$ 比例缩放）。然而，这是作为一个明确的建模假设（“假设以下……”）给出的，而不是一个隐藏的矛盾。它简化了分析，而没有使练习的逻辑失效，该练习的目的是应用给定的模型。在自身陈述的假设下，问题是自洽的。\n\n**步骤3：结论与行动**\n\n问题陈述是**有效**的。它提出了一个基于既定原则的、定义明确的理论性能建模练习，尽管带有一个标准的简化假设。可以进行求解过程。\n\n### 求解推导\n\n$p$ 个进程的总求解时间 $TTS(p)$ 是迭代次数 $k$ 和每次迭代时间 $T_{iter}(p)$ 的乘积。\n\n对于 $p > 1$，每次迭代的时间是：\n$$T_{iter}(p) = T_{comp}(p) + T_{halo}(p) + T_{redux}(p) = \\frac{V}{p \\cdot BW} + \\frac{M}{R} + 2 L \\log_2(p)$$\n对于串行情况（$p=1$），通信项为零：\n$$T_{iter}(1) = T_{comp}(1) = \\frac{V}{BW}$$\n总求解时间是 $TTS(p) = k \\cdot T_{iter}(p)$。\n强扩展效率定义为 $E(p) = \\frac{TTS(1)}{p \\cdot TTS(p)}$。\n\n我们分析两种精度格式。\n\n**1. 双精度分析**\n- 已知条件：$V_d = 6.4$ GB, $M_d = 0.2$ GB, $k_d = 500$, $BW = 40$ GB/s, $R = 10$ GB/s, $L = 3 \\times 10^{-4}$ s。\n\n- **$p=1$ 时的求解时间：**\n$$TTS_d(1) = k_d \\cdot T_{iter,d}(1) = 500 \\cdot \\left(\\frac{V_d}{BW}\\right) = 500 \\cdot \\left(\\frac{6.4}{40}\\right) \\text{ s} = 500 \\cdot 0.16 \\text{ s} = 80 \\text{ s}$$\n\n- **$p=32$ 时的求解时间：**\n$$T_{iter,d}(32) = \\frac{V_d}{32 \\cdot BW} + \\frac{M_d}{R} + 2 L \\log_2(32)$$\n$$T_{iter,d}(32) = \\frac{6.4}{32 \\cdot 40} + \\frac{0.2}{10} + 2 \\cdot (3 \\times 10^{-4}) \\cdot 5$$\n$$T_{iter,d}(32) = \\frac{6.4}{1280} + 0.02 + 10 \\cdot (3 \\times 10^{-4}) = 0.005 + 0.02 + 0.003 = 0.028 \\text{ s}$$\n$$TTS_d(32) = k_d \\cdot T_{iter,d}(32) = 500 \\cdot 0.028 \\text{ s} = 14.0 \\text{ s}$$\n\n- **$p=32$ 时的强扩展效率：**\n$$E_d(32) = \\frac{TTS_d(1)}{32 \\cdot TTS_d(32)} = \\frac{80}{32 \\cdot 14} = \\frac{80}{448} \\approx 0.17857 \\text{ or } 17.86\\%$$\n\n**2. 单精度分析**\n- 已知条件：$V_s = 3.6$ GB, $M_s = 0.1$ GB, $k_s = 1000$。\n\n- **$p=1$ 时的求解时间：**\n$$TTS_s(1) = k_s \\cdot T_{iter,s}(1) = 1000 \\cdot \\left(\\frac{V_s}{BW}\\right) = 1000 \\cdot \\left(\\frac{3.6}{40}\\right) \\text{ s} = 1000 \\cdot 0.09 \\text{ s} = 90 \\text{ s}$$\n\n- **$p=32$ 时的求解时间：**\n$$T_{iter,s}(32) = \\frac{V_s}{32 \\cdot BW} + \\frac{M_s}{R} + 2 L \\log_2(32)$$\n$$T_{iter,s}(32) = \\frac{3.6}{32 \\cdot 40} + \\frac{0.1}{10} + 2 \\cdot (3 \\times 10^{-4}) \\cdot 5$$\n$$T_{iter,s}(32) = \\frac{3.6}{1280} + 0.01 + 0.003 = 0.0028125 + 0.01 + 0.003 = 0.0158125 \\text{ s}$$\n$$TTS_s(32) = k_s \\cdot T_{iter,s}(32) = 1000 \\cdot 0.0158125 \\text{ s} = 15.8125 \\text{ s}$$\n\n- **$p=32$ 时的强扩展效率：**\n$$E_s(32) = \\frac{TTS_s(1)}{32 \\cdot TTS_s(32)} = \\frac{90}{32 \\cdot 15.8125} = \\frac{90}{506} \\approx 0.17786 \\text{ or } 17.79\\%$$\n\n### 逐项分析\n\n**A. 在 $p = 32$ 时，单精度CG比双精度CG获得更短的求解时间，且强扩展效率更高，因为数据量的减少主导了总成本。**\n- $p=32$ 时求解时间的比较：$TTS_s(32) = 15.8125$ 秒，$TTS_d(32) = 14.0$ 秒。单精度更慢，而不是更快。陈述的第一部分是错误的。\n- $p=32$ 时效率的比较：$E_s(32) \\approx 17.79\\%$，$E_d(32) \\approx 17.86\\%$。单精度的效率略低，不是更高。第二部分也是错误的。\n- **结论：错误。**\n\n**B. 在 $p = 32$ 时，双精度比单精度获得更短的求解时间；此外，单精度和双精度的强扩展效率差异小于 $5\\%$。**\n- $p=32$ 时求解时间的比较：$TTS_d(32) = 14.0$ 秒确实低于 $TTS_s(32) = 15.8125$ 秒。陈述的第一部分是正确的。\n- 效率的比较：效率分别为 $E_d(32) \\approx 17.86\\%$ 和 $E_s(32) \\approx 17.79\\%$。绝对差异为 $|17.86\\% - 17.79\\%| = 0.07\\%$。由于 $0.07\\%  5\\%$，陈述的第二部分也是正确的。\n- **结论：正确。**\n\n**C. 在 $p = 32$ 时，两种精度的强扩展效率主要受限于全局归约的延迟，因此进一步增加 $BW$ 不会显著减少求解时间。**\n- $p=32$ 时的时间分量分析：\n  - 双精度：$T_{iter,d}(32) = T_{comp} + T_{halo} + T_{redux} = 0.005\\text{ s} + 0.020\\text{ s} + 0.003\\text{ s}$。主导项是 $T_{halo}$（0.020 秒），而不是 $T_{redux}$（0.003 秒）。\n  - 单精度：$T_{iter,s}(32) = T_{comp} + T_{halo} + T_{redux} = 0.0028\\text{ s} + 0.010\\text{ s} + 0.003\\text{ s}$。同样，主导项是 $T_{halo}$（0.010 秒），而不是 $T_{redux}$（0.003 秒）。\n- 效率“主要受限于全局归约的延迟”这一前提是错误的。在这个模型中，主要的瓶颈是恒定时间的光环交换开销，它严重影响了强扩展。\n- **结论：错误。**\n\n**D. 在 $p = 1$ 时，单精度比双精度产生更长的求解时间，因为迭代次数的增加超过了因数据量减少而带来的每次迭代的加速效果。**\n- $p=1$ 时求解时间的比较：$TTS_s(1) = 90$ 秒，$TTS_d(1) = 80$ 秒。单精度确实更慢。陈述的第一部分是正确的。\n- 原因分析：\n  - 迭代次数之比为 $k_s/k_d = 1000/500 = 2$。单精度需要两倍的迭代次数。\n  - 每次迭代时间之比为 $T_{iter,s}(1)/T_{iter,d}(1) = 0.09/0.16 = 9/16 = 0.5625$。单精度的迭代更快。\n  - 总求解时间之比为 $TTS_s(1)/TTS_d(1) = (k_s/k_d) \\cdot (T_{iter,s}(1)/T_{iter,d}(1)) = 2 \\cdot (9/16) = 18/16 = 1.125$。\n  - 迭代次数增加的因子 $2$ 大于每次迭代的加速因子 $T_{iter,d}(1)/T_{iter,s}(1) = 16/9 \\approx 1.78$。由于 $2 > 1.78$，迭代次数的增加确实超过了每次迭代的加速效果。所提供的理由是正确的。\n- **结论：正确。**",
            "answer": "$$\\boxed{BD}$$"
        }
    ]
}