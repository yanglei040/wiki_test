{
    "hands_on_practices": [
        {
            "introduction": "To truly grasp the Arnoldi iteration, we begin with its most fundamental component: a single step. This exercise walks you through the initial normalization, the matrix-vector product, and the first orthogonalization to generate the second basis vector and the first entry of the Hessenberg matrix. Mastering this core calculation is the key to understanding the entire iterative process .",
            "id": "2154392",
            "problem": "In numerical linear algebra, the Arnoldi iteration is an algorithm for building an orthonormal basis of the Krylov subspace generated by a matrix $A$ and a vector $b$. Consider the square matrix $A$ and the initial vector $b$ given by:\n$$ A = \\begin{pmatrix} 1  1  0 \\\\ 1  1  0 \\\\ 0  0  1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\end{pmatrix} $$\nThe first step in the Arnoldi process is to normalize the initial vector to obtain the first basis vector, $v_1 = b / \\|b\\|_2$, where $\\|\\cdot\\|_2$ denotes the standard Euclidean norm. The iteration then proceeds to generate subsequent vectors and the entries of an upper Hessenberg matrix $H$.\n\nPerform one complete step of the Arnoldi iteration to compute the Hessenberg matrix entry $h_{1,1}$ and the second Arnoldi basis vector $v_2$.\n\nYour final answer should be given as a single row matrix containing four exact, symbolic values in the following order: the value of $h_{1,1}$, followed by the first, second, and third components of the vector $v_2$.",
            "solution": "We apply one step of the Arnoldi iteration.\n\nFirst, normalize $b$ to obtain $v_{1}$. The Euclidean norm is\n$$\n\\|b\\|_{2}=\\sqrt{1^{2}+2^{2}+2^{2}}=\\sqrt{9}=3,\n$$\nso\n$$\nv_{1}=\\frac{b}{\\|b\\|_{2}}=\\begin{pmatrix}\\frac{1}{3} \\\\ \\frac{2}{3} \\\\ \\frac{2}{3}\\end{pmatrix}.\n$$\nCompute $w=A v_{1}$:\n$$\nw=\\begin{pmatrix}1  1  0\\\\ 1  1  0\\\\ 0  0  1\\end{pmatrix}\\begin{pmatrix}\\frac{1}{3} \\\\ \\frac{2}{3} \\\\ \\frac{2}{3}\\end{pmatrix}=\\begin{pmatrix}1 \\\\ 1 \\\\ \\frac{2}{3}\\end{pmatrix}.\n$$\nThe Hessenberg entry is\n$$\nh_{1,1}=v_{1}^{\\top}w=\\frac{1}{3}\\cdot 1+\\frac{2}{3}\\cdot 1+\\frac{2}{3}\\cdot\\frac{2}{3}= \\frac{13}{9}.\n$$\nOrthogonalize and normalize to get $v_{2}$. Define\n$$\nr=w-h_{1,1}v_{1}=\\begin{pmatrix}1 \\\\ 1 \\\\ \\frac{2}{3}\\end{pmatrix}-\\frac{13}{9}\\begin{pmatrix}\\frac{1}{3} \\\\ \\frac{2}{3} \\\\ \\frac{2}{3}\\end{pmatrix}=\\begin{pmatrix}\\frac{14}{27} \\\\ \\frac{1}{27} \\\\ -\\frac{8}{27}\\end{pmatrix}.\n$$\nIts norm is\n$$\n\\|r\\|_{2}=\\sqrt{\\left(\\frac{14}{27}\\right)^{2}+\\left(\\frac{1}{27}\\right)^{2}+\\left(-\\frac{8}{27}\\right)^{2}}=\\frac{1}{27}\\sqrt{261}=\\frac{\\sqrt{29}}{9}.\n$$\nThus\n$$\nv_{2}=\\frac{r}{\\|r\\|_{2}}=\\frac{9}{\\sqrt{29}}\\begin{pmatrix}\\frac{14}{27} \\\\ \\frac{1}{27} \\\\ -\\frac{8}{27}\\end{pmatrix}=\\begin{pmatrix}\\frac{14}{3\\sqrt{29}} \\\\ \\frac{1}{3\\sqrt{29}} \\\\ -\\frac{8}{3\\sqrt{29}}\\end{pmatrix}.\n$$\nTherefore, $h_{1,1}=\\frac{13}{9}$ and $v_{2}=\\left(\\frac{14}{3\\sqrt{29}},\\,\\frac{1}{3\\sqrt{29}},\\,-\\frac{8}{3\\sqrt{29}}\\right)^{\\top}$.",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{13}{9}  \\frac{14}{3\\sqrt{29}}  \\frac{1}{3\\sqrt{29}}  -\\frac{8}{3\\sqrt{29}}\\end{pmatrix}}$$"
        },
        {
            "introduction": "With the mechanics of a single step established, we can now see how the full process unfolds by repeating the core operations. This practice requires you to perform multiple iterations to construct a complete upper Hessenberg matrix, which provides a compact representation of the original matrix's action on the Krylov subspace . The eigenvalues of this smaller Hessenberg matrix serve as powerful approximations to the eigenvalues of the original, often much larger, matrix.",
            "id": "2154379",
            "problem": "The Arnoldi iteration is a numerical algorithm used for approximating the eigenvalues of a matrix, particularly effective for large, sparse matrices. The algorithm constructs an orthonormal basis for the Krylov subspace associated with a matrix $A$ and a vector $b$.\n\nLet a matrix $A$ and an initial vector $b$ be given by:\n$$\nA = \\begin{pmatrix}\n2  3  1 \\\\\n1  1  1 \\\\\n-1  0  2\n\\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThe Arnoldi process generates a sequence of orthonormal vectors $\\{v_1, v_2, \\dots, v_k\\}$ that form a basis for the Krylov subspace $\\mathcal{K}_k(A, b)$, and a $k \\times k$ upper Hessenberg matrix $H_k$. The procedure is initialized by setting $v_1 = b / \\|b\\|$. In the Arnoldi factorization $AV_k = V_kH_k + \\tilde{v}_{k+1} e_k^T$, where $V_k = [v_1, \\dots, v_k]$, the entries of the Hessenberg matrix are defined by the relation $h_{ij} = v_i^T A v_j$.\n\nPerform three steps of the Arnoldi iteration to find the resulting $3 \\times 3$ upper Hessenberg matrix $H_3$.",
            "solution": "We start with $v_{1} = \\dfrac{b}{\\|b\\|} = \\begin{pmatrix}1 \\\\ 0 \\\\ 0\\end{pmatrix}$.\n\nFirst Arnoldi step ($j=1$):\nCompute $w = A v_{1} = \\begin{pmatrix}2 \\\\ 1 \\\\ -1\\end{pmatrix}$. Then\n$$\nh_{11} = v_{1}^{T} w = 2.\n$$\nThe residual is $r = w - h_{11} v_{1} = \\begin{pmatrix}0 \\\\ 1 \\\\ -1\\end{pmatrix}.$\nCompute\n$$\nh_{21} = \\|r\\| = \\sqrt{2},\\quad v_{2} = \\frac{r}{h_{21}} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}0 \\\\ 1 \\\\ -1\\end{pmatrix}.\n$$\n\nSecond Arnoldi step ($j=2$):\nCompute $w = A v_{2} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}2 \\\\ 0 \\\\ -2\\end{pmatrix}.$\nThe coefficients for orthogonalization are computed using $w$:\n$$\nh_{12} = v_{1}^{T} w = \\sqrt{2}.\n$$\n$$\nh_{22} = v_{2}^{T} w = 1.\n$$\nThe residual vector is then computed by subtracting the projections from $w$:\n$$\nr = w - h_{12}v_1 - h_{22}v_2 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}2 \\\\ 0 \\\\ -2\\end{pmatrix} - \\sqrt{2}\\begin{pmatrix}1 \\\\ 0 \\\\ 0\\end{pmatrix} - 1 \\cdot \\frac{1}{\\sqrt{2}}\\begin{pmatrix}0 \\\\ 1 \\\\ -1\\end{pmatrix} = \\begin{pmatrix}0 \\\\ -1/\\sqrt{2} \\\\ -1/\\sqrt{2}\\end{pmatrix}.\n$$\nThen\n$$\nh_{32} = \\|r\\| = 1,\\quad v_{3} = \\frac{r}{h_{32}} = \\begin{pmatrix}0 \\\\ -\\frac{1}{\\sqrt{2}} \\\\ -\\frac{1}{\\sqrt{2}}\\end{pmatrix}.\n$$\n\nThird Arnoldi step ($j=3$):\nCompute $w = A v_{3} = -\\frac{1}{\\sqrt{2}}\\begin{pmatrix}4 \\\\ 2 \\\\ 2\\end{pmatrix} = \\begin{pmatrix}-2\\sqrt{2} \\\\ -\\sqrt{2} \\\\ -\\sqrt{2}\\end{pmatrix}.$\nThen the Hessenberg entries are\n$$\nh_{13} = v_{1}^{T} w = -2\\sqrt{2}.\n$$\n$$\nh_{23} = v_{2}^{T} w = 0.\n$$\n$$\nh_{33} = v_{3}^{T} w = 2.\n$$\nBecause the space is three-dimensional and we have constructed three orthonormal vectors, the residual after subtracting these components is zero, so no further vector is produced.\n\nCollecting all entries, the $3\\times 3$ upper Hessenberg matrix is\n$$\nH_{3} = \\begin{pmatrix}\nh_{11}  h_{12}  h_{13} \\\\\nh_{21}  h_{22}  h_{23} \\\\\n0  h_{32}  h_{33}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2  \\sqrt{2}  -2\\sqrt{2} \\\\\n\\sqrt{2}  1  0 \\\\\n0  1  2\n\\end{pmatrix}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}2  \\sqrt{2}  -2\\sqrt{2} \\\\ \\sqrt{2}  1  0 \\\\ 0  1  2\\end{pmatrix}}$$"
        },
        {
            "introduction": "What happens when the Arnoldi iteration terminates unexpectedly early? This scenario, known as a \"lucky breakdown,\" is not a failure but a moment of discovery, revealing important structural information about the matrix. This practice challenges you to think conceptually about the conditions for a breakdown, uncovering the deep connection between the Arnoldi process and the fundamental concept of eigenvectors .",
            "id": "2154381",
            "problem": "The Arnoldi iteration is a numerical algorithm for approximating eigenvalues. For a given square matrix $A$ and a starting vector $v_1$, the first step involves normalizing the vector to $q_1 = v_1 / \\|v_1\\|_2$, computing $w = A q_1$, and then calculating a residual vector $r_1 = w - (q_1^T w) q_1$. The algorithm terminates after this first step if the residual vector $r_1$ is the zero vector.\n\nConsider a $3 \\times 3$ matrix $A$ with elements defined as $A_{11}=1$, $A_{12}=0$, $A_{13}=1$, $A_{21}=1$, $A_{22}=1$, $A_{23}=1$, $A_{31}=1$, $A_{32}=1$, and $A_{33}=-1$. Which of the following column vectors, when chosen as the starting vector $v_1$, will cause the Arnoldi iteration to terminate after just one step?\n\nA. A vector with components (1, 1, 1).\n\nB. A vector with components (1, 2, 1).\n\nC. A vector with components (1, -1, 0).\n\nD. A vector with components (0, 1, 1).\n\nE. A vector with components (1, 0, -1).",
            "solution": "The problem asks to identify which starting vector $v_1$ causes the Arnoldi iteration to terminate after the first step.\nAccording to the problem description, the first step of the Arnoldi iteration terminates if the residual vector $r_1$ is the zero vector.\nThe residual vector is defined as $r_1 = w - h_{11} q_1$, where $q_1 = v_1 / \\|v_1\\|_2$, $w = A q_1$, and $h_{11} = q_1^T w = q_1^T A q_1$.\n\nSetting $r_1 = 0$, we get:\n$$\nw - h_{11} q_1 = 0 \\implies w = h_{11} q_1\n$$\nSubstituting the expression for $w$:\n$$\nA q_1 = h_{11} q_1\n$$\nThis is the definition of an eigenvector and eigenvalue. The equation shows that the vector $q_1$ must be an eigenvector of the matrix $A$, and the scalar $h_{11}$ must be the corresponding eigenvalue.\n\nSince $q_1$ is just a normalized version of the starting vector $v_1$ (i.e., $q_1$ is $v_1$ scaled by $1/\\|v_1\\|_2$), if $q_1$ is an eigenvector, then $v_1$ must also be an eigenvector of $A$. Specifically, if $A q_1 = \\lambda q_1$, then:\n$$\nA \\left(\\frac{v_1}{\\|v_1\\|_2}\\right) = \\lambda \\left(\\frac{v_1}{\\|v_1\\|_2}\\right)\n$$\nMultiplying both sides by the scalar $\\|v_1\\|_2$ gives:\n$$\nA v_1 = \\lambda v_1\n$$\nThus, the problem reduces to finding which of the given vectors is an eigenvector of the matrix $A$.\n\nThe matrix $A$ is given by its components:\n$$\nA = \\begin{pmatrix} 1  0  1 \\\\ 1  1  1 \\\\ 1  1  -1 \\end{pmatrix}\n$$\nWe now test each option by multiplying the matrix $A$ by the vector $v_1$ from that option and checking if the resulting vector is a scalar multiple of the original vector.\n\nA. For $v_1 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$:\n$$\nA v_1 = \\begin{pmatrix} 1  0  1 \\\\ 1  1  1 \\\\ 1  1  -1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1(1) + 0(1) + 1(1) \\\\ 1(1) + 1(1) + 1(1) \\\\ 1(1) + 1(1) - 1(1) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 3 \\\\ 1 \\end{pmatrix}\n$$\nIs $\\begin{pmatrix} 2 \\\\ 3 \\\\ 1 \\end{pmatrix} = \\lambda \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$ for some scalar $\\lambda$? No, because $2/1 \\neq 3/1$.\n\nB. For $v_1 = \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}$:\n$$\nA v_1 = \\begin{pmatrix} 1  0  1 \\\\ 1  1  1 \\\\ 1  1  -1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1(1) + 0(2) + 1(1) \\\\ 1(1) + 1(2) + 1(1) \\\\ 1(1) + 1(2) - 1(1) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 4 \\\\ 2 \\end{pmatrix}\n$$\nIs $\\begin{pmatrix} 2 \\\\ 4 \\\\ 2 \\end{pmatrix} = \\lambda \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}$ for some scalar $\\lambda$? Yes, if we let $\\lambda=2$, we have $2 \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 4 \\\\ 2 \\end{pmatrix}$. This vector is an eigenvector of $A$.\n\nC. For $v_1 = \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}$:\n$$\nA v_1 = \\begin{pmatrix} 1  0  1 \\\\ 1  1  1 \\\\ 1  1  -1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1(1) + 0(-1) + 1(0) \\\\ 1(1) + 1(-1) + 1(0) \\\\ 1(1) + 1(-1) - 1(0) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nIs $\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\lambda \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}$ for some scalar $\\lambda$? No. For example, the second component is $0 = \\lambda(-1)$, which means $\\lambda=0$, but the first component is $1 = \\lambda(1)$, which would mean $\\lambda=1$. This is a contradiction.\n\nD. For $v_1 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}$:\n$$\nA v_1 = \\begin{pmatrix} 1  0  1 \\\\ 1  1  1 \\\\ 1  1  -1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1(0) + 0(1) + 1(1) \\\\ 1(0) + 1(1) + 1(1) \\\\ 1(0) + 1(1) - 1(1) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix}\n$$\nIs $\\begin{pmatrix} 1 \\\\ 2 \\\\ 0 \\end{pmatrix} = \\lambda \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}$ for some scalar $\\lambda$? No. The first component requires $1 = \\lambda(0)$, which is impossible.\n\nE. For $v_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix}$:\n$$\nA v_1 = \\begin{pmatrix} 1  0  1 \\\\ 1  1  1 \\\\ 1  1  -1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} 1(1) + 0(0) + 1(-1) \\\\ 1(1) + 1(0) + 1(-1) \\\\ 1(1) + 1(0) - 1(-1) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 2 \\end{pmatrix}\n$$\nIs $\\begin{pmatrix} 0 \\\\ 0 \\\\ 2 \\end{pmatrix} = \\lambda \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix}$ for some scalar $\\lambda$? No. The first component requires $0 = \\lambda(1)$, which means $\\lambda=0$. But the third component requires $2 = \\lambda(-1)$, which would mean $\\lambda=-2$. This is a contradiction.\n\nOnly the vector in option B is an eigenvector of $A$. Therefore, choosing this vector as the starting vector $v_1$ will cause the Arnoldi iteration to terminate after the first step.",
            "answer": "$$\\boxed{B}$$"
        }
    ]
}