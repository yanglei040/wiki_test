{
    "hands_on_practices": [
        {
            "introduction": "This exercise grounds your understanding of the wavelet transform by having you perform it manually. By applying the separable 2D Discrete Wavelet Transform (DWT) with Haar wavelets to a small image matrix, you will see exactly how a signal is decomposed into its approximation ($LL$) and detail ($LH$, $HL$, and $HH$) sub-bands. This foundational practice demystifies the algorithm, making the abstract concept of multi-resolution analysis tangible and clear .",
            "id": "3286415",
            "problem": "Consider the two-dimensional (2D) Discrete Wavelet Transform (DWT) using the orthonormal Haar wavelet on a small grayscale image represented by the matrix\n$$\nX \\;=\\;\n\\begin{pmatrix}\n12 & 14 & 10 & 8 \\\\\n9 & 11 & 7 & 5 \\\\\n6 & 4 & 2 & 0 \\\\\n15 & 13 & 9 & 3\n\\end{pmatrix}.\n$$\nUse the following fundamental definitions. For a one-dimensional discrete signal $x$ of even length, the level-$1$ Haar transform computes approximation (low-pass) coefficients $a_{k}$ and detail (high-pass) coefficients $d_{k}$ by convolving with the Haar scaling and wavelet filters and downsampling by $2$:\n$$\nh = \\left[ \\frac{1}{\\sqrt{2}}, \\; \\frac{1}{\\sqrt{2}} \\right], \\qquad\ng = \\left[ \\frac{1}{\\sqrt{2}}, \\; -\\frac{1}{\\sqrt{2}} \\right],\n$$\n$$\na_{k} \\;=\\; \\sum_{n=0}^{1} h_{n} \\, x_{2k+n}, \\qquad\nd_{k} \\;=\\; \\sum_{n=0}^{1} g_{n} \\, x_{2k+n},\n$$\nwith $k$ indexing the downsampled positions. For the two-dimensional transform, first apply the one-dimensional transform to each row of $X$, producing row-wise low-pass and high-pass outputs of length $2$ per row. Arrange these as the left two columns (row low-pass) and right two columns (row high-pass) of an intermediate matrix. Then, apply the one-dimensional transform to each column of the left two-column block and to each column of the right two-column block, again with downsampling by $2$. Define the four sub-bands as follows:\n- $LL$: column low-pass applied to the left two-column block (row low-pass),\n- $LH$: column high-pass applied to the left two-column block (row low-pass),\n- $HL$: column low-pass applied to the right two-column block (row high-pass),\n- $HH$: column high-pass applied to the right two-column block (row high-pass).\nAssume no boundary extension; pair the samples as $\\{(0,1),(2,3)\\}$ along each row and column at this single level. Manually compute the full one-level 2D Haar DWT of $X$ and identify the $LL$, $LH$, $HL$, and $HH$ sub-bands. Then, as a single scalar summary, compute the determinant of the $LL$ sub-band. Express your final answer exactly as an integer with no rounding.",
            "solution": "The problem requires us to compute the one-level $2D$ Haar DWT of the matrix $X$ and then find the determinant of the resulting low-pass/low-pass ($LL$) sub-band.\n\nThe given input matrix is:\n$$\nX \\;=\\;\n\\begin{pmatrix}\n12 & 14 & 10 & 8 \\\\\n9 & 11 & 7 & 5 \\\\\n6 & 4 & 2 & 0 \\\\\n15 & 13 & 9 & 3\n\\end{pmatrix}\n$$\nThe one-dimensional ($1D$) Haar transform is defined by the low-pass filter $h = \\left[ \\frac{1}{\\sqrt{2}}, \\; \\frac{1}{\\sqrt{2}} \\right]$ and the high-pass filter $g = \\left[ \\frac{1}{\\sqrt{2}}, \\; -\\frac{1}{\\sqrt{2}} \\right]$. For a 4-element discrete signal $x = [x_0, x_1, x_2, x_3]$, the approximation coefficients ($a_k$) and detail coefficients ($d_k$) are computed as:\n$$\na_0 = \\frac{1}{\\sqrt{2}} (x_0 + x_1), \\quad a_1 = \\frac{1}{\\sqrt{2}} (x_2 + x_3)\n$$\n$$\nd_0 = \\frac{1}{\\sqrt{2}} (x_0 - x_1), \\quad d_1 = \\frac{1}{\\sqrt{2}} (x_2 - x_3)\n$$\nThe $2D$ DWT is performed separably, first along the rows and then along the columns.\n\nStep 1: Apply the $1D$ DWT to each row of $X$.\nThe output for each row is arranged as $[a_0, a_1, d_0, d_1]$.\n\nFor row 1: $[12, 14, 10, 8]$\n$a_0 = \\frac{1}{\\sqrt{2}}(12+14) = \\frac{26}{\\sqrt{2}}$, $a_1 = \\frac{1}{\\sqrt{2}}(10+8) = \\frac{18}{\\sqrt{2}}$\n$d_0 = \\frac{1}{\\sqrt{2}}(12-14) = \\frac{-2}{\\sqrt{2}}$, $d_1 = \\frac{1}{\\sqrt{2}}(10-8) = \\frac{2}{\\sqrt{2}}$\n\nFor row 2: $[9, 11, 7, 5]$\n$a_0 = \\frac{1}{\\sqrt{2}}(9+11) = \\frac{20}{\\sqrt{2}}$, $a_1 = \\frac{1}{\\sqrt{2}}(7+5) = \\frac{12}{\\sqrt{2}}$\n$d_0 = \\frac{1}{\\sqrt{2}}(9-11) = \\frac{-2}{\\sqrt{2}}$, $d_1 = \\frac{1}{\\sqrt{2}}(7-5) = \\frac{2}{\\sqrt{2}}$\n\nFor row 3: $[6, 4, 2, 0]$\n$a_0 = \\frac{1}{\\sqrt{2}}(6+4) = \\frac{10}{\\sqrt{2}}$, $a_1 = \\frac{1}{\\sqrt{2}}(2+0) = \\frac{2}{\\sqrt{2}}$\n$d_0 = \\frac{1}{\\sqrt{2}}(6-4) = \\frac{2}{\\sqrt{2}}$, $d_1 = \\frac{1}{\\sqrt{2}}(2-0) = \\frac{2}{\\sqrt{2}}$\n\nFor row 4: $[15, 13, 9, 3]$\n$a_0 = \\frac{1}{\\sqrt{2}}(15+13) = \\frac{28}{\\sqrt{2}}$, $a_1 = \\frac{1}{\\sqrt{2}}(9+3) = \\frac{12}{\\sqrt{2}}$\n$d_0 = \\frac{1}{\\sqrt{2}}(15-13) = \\frac{2}{\\sqrt{2}}$, $d_1 = \\frac{1}{\\sqrt{2}}(9-3) = \\frac{6}{\\sqrt{2}}$\n\nAccording to the problem description, we arrange the row-wise low-pass outputs ($a_0, a_1$) as the left two columns and the row-wise high-pass outputs ($d_0, d_1$) as the right two columns to form an intermediate matrix, let's call it $Y$:\n$$\nY \\;=\\;\n\\frac{1}{\\sqrt{2}}\n\\begin{pmatrix}\n26 & 18 & -2 & 2 \\\\\n20 & 12 & -2 & 2 \\\\\n10 & 2  &  2 & 2 \\\\\n28 & 12 &  2 & 6\n\\end{pmatrix}\n$$\n\nStep 2: Apply the $1D$ DWT to each column of $Y$.\nThe transform is applied to each column vector, and the resulting approximation coefficients form the top half of the final column, while the detail coefficients form the bottom half. Let's perform this on the unscaled matrix part and apply the full scaling factor of $\\frac{1}{\\sqrt{2}} \\times \\frac{1}{\\sqrt{2}} = \\frac{1}{2}$ at the end.\n\nFor column 1 of $\\sqrt{2}Y$: $[26, 20, 10, 28]$\n$a_0 = \\frac{1}{\\sqrt{2}}(26+20) = \\frac{46}{\\sqrt{2}}$, $a_1 = \\frac{1}{\\sqrt{2}}(10+28) = \\frac{38}{\\sqrt{2}}$\n$d_0 = \\frac{1}{\\sqrt{2}}(26-20) = \\frac{6}{\\sqrt{2}}$, $d_1 = \\frac{1}{\\sqrt{2}}(10-28) = \\frac{-18}{\\sqrt{2}}$\n\nFor column 2 of $\\sqrt{2}Y$: $[18, 12, 2, 12]$\n$a_0 = \\frac{1}{\\sqrt{2}}(18+12) = \\frac{30}{\\sqrt{2}}$, $a_1 = \\frac{1}{\\sqrt{2}}(2+12) = \\frac{14}{\\sqrt{2}}$\n$d_0 = \\frac{1}{\\sqrt{2}}(18-12) = \\frac{6}{\\sqrt{2}}$, $d_1 = \\frac{1}{\\sqrt{2}}(2-12) = \\frac{-10}{\\sqrt{2}}$\n\nFor column 3 of $\\sqrt{2}Y$: $[-2, -2, 2, 2]$\n$a_0 = \\frac{1}{\\sqrt{2}}(-2-2) = \\frac{-4}{\\sqrt{2}}$, $a_1 = \\frac{1}{\\sqrt{2}}(2+2) = \\frac{4}{\\sqrt{2}}$\n$d_0 = \\frac{1}{\\sqrt{2}}(-2-(-2)) = 0$, $d_1 = \\frac{1}{\\sqrt{2}}(2-2) = 0$\n\nFor column 4 of $\\sqrt{2}Y$: $[2, 2, 2, 6]$\n$a_0 = \\frac{1}{\\sqrt{2}}(2+2) = \\frac{4}{\\sqrt{2}}$, $a_1 = \\frac{1}{\\sqrt{2}}(2+6) = \\frac{8}{\\sqrt{2}}$\n$d_0 = \\frac{1}{\\sqrt{2}}(2-2) = 0$, $d_1 = \\frac{1}{\\sqrt{2}}(2-6) = \\frac{-4}{\\sqrt{2}}$\n\nStep 3: Assemble the final transformed matrix $W$ and identify the sub-bands.\nThe final matrix $W$ is obtained by assembling these columns and applying the full normalization factor of $\\frac{1}{2}$.\n$$\nW = \\frac{1}{2}\n\\begin{pmatrix}\n46 & 30 & -4 & 4 \\\\\n38 & 14 & 4 & 8 \\\\\n6 & 6 & 0 & 0 \\\\\n-18 & -10 & 0 & -4\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n23 & 15 & -2 & 2 \\\\\n19 & 7 & 2 & 4 \\\\\n3 & 3 & 0 & 0 \\\\\n-9 & -5 & 0 & -2\n\\end{pmatrix}\n$$\nThe four $2 \\times 2$ sub-bands are identified based on the sequence of operations:\n- $LL$ (top-left): Low-pass on rows, then low-pass on columns.\n- $LH$ (bottom-left): Low-pass on rows, then high-pass on columns.\n- $HL$ (top-right): High-pass on rows, then low-pass on columns.\n- $HH$ (bottom-right): High-pass on rows, then high-pass on columns.\n\nThus, the $LL$ sub-band is the top-left $2 \\times 2$ block of $W$:\n$$\nLL \\;=\\;\n\\begin{pmatrix}\n23 & 15 \\\\\n19 & 7\n\\end{pmatrix}\n$$\n\nStep 4: Compute the determinant of the $LL$ sub-band.\nThe determinant of a $2 \\times 2$ matrix $\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$ is $ad - bc$.\n$$\n\\det(LL) = (23)(7) - (15)(19)\n$$\n$$\n\\det(LL) = 161 - 285\n$$\n$$\n\\det(LL) = -124\n$$\nThe determinant of the $LL$ sub-band is exactly $-124$.",
            "answer": "$$\\boxed{-124}$$"
        },
        {
            "introduction": "A key advantage of wavelets is their ability to represent signals sparsely, a property fundamental to compression and noise reduction. This coding exercise challenges you to implement the DWT and its inverse to demonstrate that a signal's sparsity depends on the chosen wavelet basis . By constructing signals that are \"atoms\" of one basis (like Haar) and analyzing them in another (like Daubechies-4), you will gain practical insight into why selecting the right wavelet is crucial for real-world applications.",
            "id": "3286372",
            "problem": "You are to implement and use the one-dimensional orthonormal Discrete Wavelet Transform (DWT) to design and evaluate signals that are sparse in one wavelet basis but dense in another. Work entirely in discrete time on finite periodic signals. Rely only on the following foundational facts: (i) an orthonormal wavelet basis is generated by dilations and translations of a mother wavelet and yields an orthonormal transform, (ii) orthonormal transforms preserve energy by Parseval's identity, and (iii) orthonormal DWTs can be computed by a two-channel perfect reconstruction filter bank using a Quadrature Mirror Filter (QMF) pair consisting of a low-pass analysis filter and a high-pass analysis filter, with corresponding reconstruction filters obtained by time-reversal of the analysis filters. You must not use any external wavelet library.\n\nDefinitions and assumptions:\n- Let the signal be a real vector of length $N$ with periodic boundary conditions.\n- Let the number of decomposition levels be $L = \\log_2 N$, assuming $N$ is a power of two.\n- Let $h[n]$ denote the low-pass analysis filter and $g[n]$ denote the high-pass analysis filter, forming a Quadrature Mirror Filter (QMF) pair. For an orthonormal wavelet, $g[n] = (-1)^n h[L_f - 1 - n]$, where $L_f$ is the filter length, and the reconstruction filters are $h_r[n] = h[L_f - 1 - n]$ and $g_r[n] = g[L_f - 1 - n]$.\n- For the Haar wavelet (also called Daubechies-$1$), use $h = \\left[\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}\\right]$ and $g = \\left[\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}}\\right]$.\n- For the Daubechies-$4$ wavelet (with $4$ vanishing moments and filter length $8$), use the low-pass analysis filter coefficients\n$$\nh = \\big[-0.010597401785069032,\\; 0.0328830116668852,\\; 0.030841381835986965,\\; -0.18703481171888114,\\; -0.027983769416859854,\\; 0.6308807679298589,\\; 0.7148465705529154,\\; 0.23037781330885523\\big],\n$$\nand define $g[n] = (-1)^n h[7 - n]$.\n- The level-$\\ell$ detail subband has length $N / 2^\\ell$ for $\\ell \\in \\{1,2,\\dots,L\\}$, and the level-$L$ approximation subband has length $N / 2^L = 1$ when $N$ is a power of two.\n\nDWT analysis step at a given level: given a length-$M$ signal $x[n]$, compute approximation $a[n]$ and detail $d[n]$ of length $M/2$ by\n$$\na[n] = \\sum_{k=0}^{L_f-1} h[k]\\; x[(2n + k) \\bmod M],\\quad\nd[n] = \\sum_{k=0}^{L_f-1} g[k]\\; x[(2n + k) \\bmod M].\n$$\nIterate this splitting on the approximation output for $L$ levels to obtain detail bands $\\{d_1, d_2, \\dots, d_L\\}$ and the final coarse approximation $a_L$.\n\nInverse DWT synthesis step: given $a[n]$ and $d[n]$ of length $M$, upsample by inserting zeros between samples, convolve periodically with the reconstruction filters $h_r$ and $g_r$, and sum to reconstruct the next finer signal of length $2M$.\n\nYour tasks:\n1. Implement the orthonormal DWT analysis and synthesis with periodic boundary conditions for the Haar and Daubechies-$4$ wavelets using the above filters. Your implementation must handle exactly $L = \\log_2 N$ levels when $N$ is a power of two.\n2. Define the following sparsity metric at energy capture fraction $p$: given a coefficient vector $c$ of total energy $E = \\sum_i c_i^2$, let $k(p)$ be the smallest integer such that the sum of the $k(p)$ largest squared-magnitude coefficients is at least $p E$. You must compute $k(p)$ by sorting the squared magnitudes in descending order and accumulating until the threshold is reached.\n3. Construct the following four test signals of length $N$ and evaluate their sparsity in both the Haar and Daubechies-$4$ bases using $p = 0.99$:\n   - Test A: $N = 256$. A single Haar detail atom: form DWT coefficient arrays for the Haar basis with all bands zero except a single level-$3$ detail coefficient set to amplitude $1.0$ at position $5$, and synthesize the signal by inverse DWT in the Haar basis.\n   - Test B: $N = 256$. A sum of two Haar detail atoms: as in Test A but with two nonzero coefficients, one at level $2$, position $17$, amplitude $2.0$, and one at level $5$, position $3$, amplitude $-1.0$. Synthesize by inverse DWT in the Haar basis.\n   - Test C: $N = 256$. A single Daubechies-$4$ detail atom: form DWT coefficient arrays for the Daubechies-$4$ basis with all bands zero except a single level-$4$ detail coefficient set to amplitude $1.0$ at position $11$, and synthesize the signal by inverse DWT in the Daubechies-$4$ basis.\n   - Test D: $N = 32$. A unit impulse: $x[n] = 1$ at index $0$ and $x[n] = 0$ otherwise.\n4. For each test signal, compute $k_{\\text{Haar}}(p)$ using the Haar DWT and $k_{\\text{Db4}}(p)$ using the Daubechies-$4$ DWT, and also compute the ratio $r = k_{\\text{Db4}}(p) / k_{\\text{Haar}}(p)$.\n5. Final output format: Your program should produce a single line of output containing the results for Tests A, B, C, and D, in this order, as a comma-separated list of four lists, each inner list in the form $[k_{\\text{Haar}}, k_{\\text{Db4}}, r]$, enclosed in square brackets. For example, the printed line must look like\n$[\\,[k_{A,\\text{Haar}},k_{A,\\text{Db4}},r_A],[k_{B,\\text{Haar}},k_{B,\\text{Db4}},r_B],[k_{C,\\text{Haar}},k_{C,\\text{Db4}},r_C],[k_{D,\\text{Haar}},k_{D,\\text{Db4}},r_D]\\,]$,\nwith all entries as integers or floating-point numbers. No additional text should be printed.\n\nNotes on scientific rationale:\n- Because the Haar wavelet is piecewise constant with compact support of length $2$, a single Haar wavelet atom synthesized at a fixed level is exactly sparse in the Haar basis (only one nonzero coefficient) but typically spreads across many coefficients in a smoother, longer-support basis such as Daubechies-$4$, making it dense there. Conversely, a single Daubechies-$4$ atom is exactly sparse in the Daubechies-$4$ basis but dense in the Haar basis. The impulse signal illustrates how localized discontinuities interact with filter support lengths. By energy preservation under orthonormal transforms, comparing $k(p)$ across bases is meaningful.",
            "solution": "The solution is implemented by first creating functions for the one-level DWT analysis (convolution and downsampling) and synthesis (upsampling and convolution) steps using periodic boundary conditions. These are iterated to build the full multi-level DWT and its inverse (IDWT) for both the Haar and Daubechies-4 filter sets. The test signals are constructed by creating a sparse coefficient vector (e.g., all zeros except for one detail coefficient) and then applying the appropriate IDWT. To evaluate sparsity, a function calculates the sparsity metric $k(p)$ by taking the DWT of a signal, sorting the squared magnitudes of all resulting coefficients, and finding the minimum number of coefficients needed to capture fraction $p$ of the total signal energy. Because the DWT is an orthonormal transform, total energy is conserved (Parseval's theorem), making the comparison of $k(p)$ values across different bases a meaningful measure of basis-dependent sparsity.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef qmf_highpass_from_lowpass(h):\n    # g[n] = (-1)^n h[L-1-n]\n    L = len(h)\n    g = np.array([((-1)**n) * h[L - 1 - n] for n in range(L)], dtype=float)\n    return g\n\ndef analysis_step(x, h, g):\n    # One-level analysis with periodic boundary, downsampling by 2\n    N = len(x)\n    Lf = len(h)\n    M = N // 2\n    a = np.zeros(M, dtype=float)\n    d = np.zeros(M, dtype=float)\n    for n in range(M):\n        s_a = 0.0\n        s_d = 0.0\n        base = 2 * n\n        for k in range(Lf):\n            idx = (base + k) % N\n            xv = x[idx]\n            s_a += h[k] * xv\n            s_d += g[k] * xv\n        a[n] = s_a\n        d[n] = s_d\n    return a, d\n\ndef synthesis_step(a, d, hr, gr):\n    # One-level synthesis with periodic boundary from a,d (length M) to x (length 2M)\n    M = len(a)\n    N = 2 * M\n    Lf = len(hr)\n    up_a = np.zeros(N, dtype=float)\n    up_d = np.zeros(N, dtype=float)\n    up_a[::2] = a\n    up_d[::2] = d\n    # Periodic convolution\n    x = np.zeros(N, dtype=float)\n    for n in range(N):\n        s = 0.0\n        for k in range(Lf):\n            idx = (n - k) % N\n            s += hr[k] * up_a[idx] + gr[k] * up_d[idx]\n        x[n] = s\n    return x\n\ndef dwt(x, h, g, levels):\n    # Full multilevel analysis\n    a = x.copy()\n    details = []\n    for _ in range(levels):\n        a, d = analysis_step(a, h, g)\n        details.append(d)\n    # details[0] is level-1, ..., details[L-1] is level-L\n    return a, details\n\ndef idwt(aL, details, hr, gr):\n    # Full multilevel synthesis\n    a = aL.copy()\n    # details are [d1, d2, ..., dL]\n    for lev in range(len(details)-1, -1, -1):\n        d = details[lev]\n        a = synthesis_step(a, d, hr, gr)\n    return a\n\ndef flatten_coeffs(aL, details):\n    # Concatenate all detail bands followed by final approx\n    # Order: d1, d2, ..., dL, aL\n    parts = []\n    for d in details:\n        parts.append(d.ravel())\n    parts.append(np.array([aL]).ravel()) if np.ndim(aL) == 0 else parts.append(aL.ravel())\n    return np.concatenate(parts)\n\ndef energy_capture_k(coeffs, p):\n    # coeffs is 1D array of all coefficients\n    magsq = coeffs**2\n    total = float(np.sum(magsq))\n    if total == 0.0:\n        return 0\n    magsq_sorted = -np.sort(-magsq)  # descending\n    cumsum = np.cumsum(magsq_sorted)\n    threshold = p * total\n    k = int(np.searchsorted(cumsum, threshold, side='left')) + 1\n    # Cap at length\n    if k > len(coeffs):\n        k = len(coeffs)\n    return k\n\ndef haar_filters():\n    inv_sqrt2 = 1.0 / np.sqrt(2.0)\n    h = np.array([inv_sqrt2, inv_sqrt2], dtype=float)\n    g = np.array([inv_sqrt2, -inv_sqrt2], dtype=float)\n    return h, g\n\ndef db4_filters():\n    h = np.array([\n        -0.010597401785069032,\n         0.0328830116668852,\n         0.030841381835986965,\n        -0.18703481171888114,\n        -0.027983769416859854,\n         0.6308807679298589,\n         0.7148465705529154,\n         0.23037781330885523\n    ], dtype=float)\n    g = qmf_highpass_from_lowpass(h)\n    return h, g\n\ndef reconstruction_filters_from_analysis(h, g):\n    # For orthonormal wavelets, synthesis filters are time-reversed analysis filters\n    hr = h[::-1].copy()\n    gr = g[::-1].copy()\n    return hr, gr\n\ndef build_atom_signal(N, basis, level, position, amplitude=1.0):\n    # basis: 'haar' or 'db4'\n    # Build coefficients arrays with one nonzero detail coefficient at given level and position, synthesize signal\n    if basis == 'haar':\n        h, g = haar_filters()\n    elif basis == 'db4':\n        h, g = db4_filters()\n    else:\n        raise ValueError(\"Unknown basis\")\n    hr, gr = reconstruction_filters_from_analysis(h, g)\n    L = int(np.log2(N))\n    # Initialize all details to zeros with appropriate lengths\n    details = []\n    for ell in range(1, L+1):\n        details.append(np.zeros(N // (2**ell), dtype=float))\n    # Set specified coefficient; level is 1..L\n    details[level - 1][position % len(details[level - 1])] = amplitude\n    # Final approximation at level L is zero\n    aL = np.array([0.0]) if (N // (2**L) == 1) else np.zeros(N // (2**L), dtype=float)\n    # Synthesize\n    x = idwt(aL, details, hr, gr)\n    return x\n\ndef impulse_signal(N, index=0, amplitude=1.0):\n    x = np.zeros(N, dtype=float)\n    x[index % N] = amplitude\n    return x\n\ndef sparsity_in_both_bases(x, p):\n    # Compute k for Haar and Db4 for signal x\n    # Haar\n    hH, gH = haar_filters()\n    hrH, grH = reconstruction_filters_from_analysis(hH, gH)\n    L = int(np.log2(len(x)))\n    aH, dH = dwt(x, hH, gH, L)\n    coeffsH = flatten_coeffs(aH, dH)\n    kH = energy_capture_k(coeffsH, p)\n    # Db4\n    hD, gD = db4_filters()\n    hrD, grD = reconstruction_filters_from_analysis(hD, gD)\n    aD, dD = dwt(x, hD, gD, L)\n    coeffsD = flatten_coeffs(aD, dD)\n    kD = energy_capture_k(coeffsD, p)\n    ratio = float(kD) / float(kH) if kH != 0 else float('inf')\n    return kH, kD, ratio\n\ndef solve():\n    p = 0.99\n\n    # Test A: N=256, single Haar atom at level 3, position 5\n    N_A = 256\n    xA = build_atom_signal(N_A, basis='haar', level=3, position=5, amplitude=1.0)\n\n    # Test B: N=256, sum of two Haar atoms: (level2,pos17,amp2.0) + (level5,pos3,amp-1.0)\n    xB = build_atom_signal(N_A, basis='haar', level=2, position=17, amplitude=2.0) + \\\n         build_atom_signal(N_A, basis='haar', level=5, position=3, amplitude=-1.0)\n\n    # Test C: N=256, single Db4 atom at level 4, position 11\n    xC = build_atom_signal(N_A, basis='db4', level=4, position=11, amplitude=1.0)\n\n    # Test D: N=32, unit impulse at index 0\n    N_D = 32\n    xD = impulse_signal(N_D, index=0, amplitude=1.0)\n\n    tests = [xA, xB, xC, xD]\n\n    results = []\n    for x in tests:\n        kH, kD, r = sparsity_in_both_bases(x, p)\n        results.append([int(kH), int(kD), r])\n\n    # Final print statement in the exact required format.\n    # Ensure floats are printed in standard Python repr; inner lists as described.\n    print(f\"[{','.join(['[' + ','.join([str(e) for e in res]) + ']' for res in results])}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "The magic of the DWT often lies in its \"perfect reconstruction\" property, which ensures a signal can be decomposed and then flawlessly reassembled. This is not an accident but the result of precise filter design, specifically the Quadrature Mirror Filter (QMF) conditions. This practice combines analytical derivation with numerical simulation to explore what happens when this precision is lost , helping you develop a deeper appreciation for the mathematical rigor that makes wavelet transforms a reliable tool.",
            "id": "3286387",
            "problem": "Consider a two-channel orthonormal filter bank for the Discrete Wavelet Transform (DWT) built from a lowpass analysis filter with impulse response $h = \\left[\\tfrac{1}{\\sqrt{2}}, \\tfrac{1}{\\sqrt{2}}\\right]$ (the Haar scaling filter). The corresponding highpass analysis filter $g$ is related to $h$ by the Quadrature Mirror Filter (QMF) condition, which in one common $0$-based form reads $g[k] = (-1)^{k} h[1-k]$. In exact arithmetic with perfectly matched analysis and synthesis filters, this analysis-synthesis system achieves perfect reconstruction. In this problem, you will quantify the reconstruction error when the QMF relation is slightly perturbed in the synthesis highpass branch.\n\nYou must reason from first principles using only the following base:\n- The definition of linear time-invariant filtering by finite impulse responses (FIR).\n- The definition of downsampling by a factor of $2$ and upsampling by a factor of $2$.\n- The orthonormality of the Haar system induced by $h = \\left[\\tfrac{1}{\\sqrt{2}}, \\tfrac{1}{\\sqrt{2}}\\right]$ and $g = \\left[\\tfrac{1}{\\sqrt{2}}, -\\tfrac{1}{\\sqrt{2}}\\right]$, which is a specific instance of the QMF relation.\n- Euclidean norms for finite sequences.\n\nWork with signals $x[n]$ of even length $L$ and use the following concrete, pairwise definitions of the one-level analysis and synthesis maps derived from the above filters:\n- Analysis for $n = 0, 1, \\dots, \\tfrac{L}{2}-1$:\n  $$a[n] = \\frac{x[2n] + x[2n+1]}{\\sqrt{2}}, \\quad d[n] = \\frac{x[2n] - x[2n+1]}{\\sqrt{2}}.$$\n- Synthesis for $n = 0, 1, \\dots, \\tfrac{L}{2}-1$ with synthesis lowpass $h^{(s)} = \\left[\\tfrac{1}{\\sqrt{2}}, \\tfrac{1}{\\sqrt{2}}\\right]$ and a perturbed synthesis highpass\n  $$\\tilde{g}^{(s)} = g + \\varepsilon r,$$\n  where $g = \\left[\\tfrac{1}{\\sqrt{2}}, -\\tfrac{1}{\\sqrt{2}}\\right]$, $\\varepsilon \\in \\mathbb{R}$ is a small scalar perturbation parameter, and $r \\in \\mathbb{R}^{2}$ is a fixed direction vector with $\\lVert r \\rVert_{2} = 1$. The synthesis is defined pairwise by\n  $$\\hat{x}[2n] = h^{(s)}[0]\\,a[n] + \\tilde{g}^{(s)}[0]\\,d[n], \\quad \\hat{x}[2n+1] = h^{(s)}[1]\\,a[n] + \\tilde{g}^{(s)}[1]\\,d[n].$$\n\nYour tasks:\n1. Starting from the above definitions and without assuming any specialized filter bank identities beyond what is stated, derive an explicit expression for the reconstruction error sequence\n   $$e^{(\\varepsilon)}[n] = \\hat{x}[n] - x[n]$$\n   in terms of $\\varepsilon$, the direction vector $r$, and the detail coefficients $d[n]$.\n2. Using your derivation, express the normalized reconstruction error\n   $$E_{\\mathrm{norm}}(\\varepsilon; x) = \\frac{\\lVert e^{(\\varepsilon)} \\rVert_{2}}{\\lVert x \\rVert_{2}}$$\n   completely in terms of $\\varepsilon$, $r$, and quantities computable from $x[n]$ under the stated analysis formulas. Do not introduce any assumptions not stated above.\n3. Implement a program that:\n   - Uses the fixed perturbation direction $r = [0.6, 0.8]$ and verifies that $\\lVert r \\rVert_{2} = 1$.\n   - For each test case listed below, computes:\n     - The empirical normalized error $E_{\\mathrm{emp}}$ by actually performing analysis with the exact analysis filters, synthesis with the perturbed $\\tilde{g}^{(s)}$, forming $e^{(\\varepsilon)}[n]$, and evaluating $\\lVert e^{(\\varepsilon)} \\rVert_{2} / \\lVert x \\rVert_{2}$.\n     - The theoretical normalized error $E_{\\mathrm{theory}}$ predicted by your derivation in Task $2$.\n     - The absolute difference $\\Delta E = \\left| E_{\\mathrm{emp}} - E_{\\mathrm{theory}} \\right|$.\n   - Produces a single line of output containing the list of $\\Delta E$ values for all test cases, as a comma-separated list enclosed in square brackets, in the order the tests are specified.\n\nAngle unit note: Any trigonometric function must use radians.\n\nTest suite:\n- Test $1$: $x^{(1)} = [1.0, -1.0, 2.0, 0.0, 3.0, -2.0, 0.5, 1.5]$, $\\varepsilon = 0.0$.\n- Test $2$: $x^{(1)}$ again, $\\varepsilon = 0.05$.\n- Test $3$: $x^{(2)}$ of length $L = 8$ with entries $x^{(2)}[n] = \\cos\\!\\left(\\tfrac{2\\pi n}{8}\\right)$ for $n = 0, 1, \\dots, 7$ (angles in radians), $\\varepsilon = 0.05$.\n- Test $4$: $x^{(3)} = [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]$, $\\varepsilon = 0.2$.\n- Test $5$: $x^{(4)} = [2.0, -1.0, 0.0, 1.0, -2.0, 0.5, 1.0, -0.5, 3.0, -1.5]$, $\\varepsilon = 0.1$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[r1,r2,r3,r4,r5]\"), where each $r_i$ is the value of $\\Delta E$ for the corresponding test in the order listed above.",
            "solution": "## Solution Derivations\n\n### Task 1: Derivation of the Reconstruction Error Sequence\n\nThe synthesis operation is linear with respect to the filter coefficients. We can thus decompose the reconstructed signal $\\hat{x}[n]$ into two parts: one corresponding to the perfect reconstruction system and one corresponding to the perturbation.\n\nThe perturbed synthesis highpass filter is $\\tilde{g}^{(s)} = g + \\varepsilon r$. Substituting this into the synthesis equations:\n$$ \\hat{x}[2n] = h^{(s)}[0]\\,a[n] + (g[0] + \\varepsilon r[0])\\,d[n] = (h^{(s)}[0]\\,a[n] + g[0]\\,d[n]) + \\varepsilon r[0]\\,d[n] $$\n$$ \\hat{x}[2n+1] = h^{(s)}[1]\\,a[n] + (g[1] + \\varepsilon r[1])\\,d[n] = (h^{(s)}[1]\\,a[n] + g[1]\\,d[n]) + \\varepsilon r[1]\\,d[n] $$\n\nThe problem states that the unperturbed system provides perfect reconstruction. The synthesis filters for perfect reconstruction are $h^{(s)} = h = [\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}]$ and $g^{(s)} = g = [\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}}]$. The reconstructed signal in this case, $x_{PR}[n]$, is:\n$$ x_{PR}[2n] = h[0]\\,a[n] + g[0]\\,d[n] = \\frac{1}{\\sqrt{2}} a[n] + \\frac{1}{\\sqrt{2}} d[n] $$\n$$ x_{PR}[2n+1] = h[1]\\,a[n] + g[1]\\,d[n] = \\frac{1}{\\sqrt{2}} a[n] - \\frac{1}{\\sqrt{2}} d[n] $$\nSubstituting the analysis formulas for $a[n]$ and $d[n]$:\n$$ x_{PR}[2n] = \\frac{1}{\\sqrt{2}} \\left( \\frac{x[2n] + x[2n+1]}{\\sqrt{2}} \\right) + \\frac{1}{\\sqrt{2}} \\left( \\frac{x[2n] - x[2n+1]}{\\sqrt{2}} \\right) = \\frac{1}{2}(x[2n] + x[2n+1]) + \\frac{1}{2}(x[2n] - x[2n+1]) = x[2n] $$\n$$ x_{PR}[2n+1] = \\frac{1}{\\sqrt{2}} \\left( \\frac{x[2n] + x[2n+1]}{\\sqrt{2}} \\right) - \\frac{1}{\\sqrt{2}} \\left( \\frac{x[2n] - x[2n+1]}{\\sqrt{2}} \\right) = \\frac{1}{2}(x[2n] + x[2n+1]) - \\frac{1}{2}(x[2n] - x[2n+1]) = x[2n+1] $$\nThis confirms that the terms in parentheses in the expressions for $\\hat{x}[n]$ are equal to the original signal $x[n]$.\n\nThe reconstruction error $e^{(\\varepsilon)}[n] = \\hat{x}[n] - x[n]$ is therefore simply the remaining part from the perturbation:\n$$ e^{(\\varepsilon)}[2n] = \\varepsilon r[0]\\,d[n] $$\n$$ e^{(\\varepsilon)}[2n+1] = \\varepsilon r[1]\\,d[n] $$\nThese expressions are valid for $n = 0, 1, \\dots, \\frac{L}{2}-1$.\n\n### Task 2: Derivation of the Normalized Reconstruction Error\n\nThe normalized reconstruction error is defined as $E_{\\mathrm{norm}}(\\varepsilon; x) = \\frac{\\lVert e^{(\\varepsilon)} \\rVert_{2}}{\\lVert x \\rVert_{2}}$. We need to compute the squared Euclidean norm of the error sequence $e^{(\\varepsilon)}$.\n$$ \\lVert e^{(\\varepsilon)} \\rVert_{2}^2 = \\sum_{k=0}^{L-1} (e^{(\\varepsilon)}[k])^2 = \\sum_{n=0}^{L/2-1} \\left( (e^{(\\varepsilon)}[2n])^2 + (e^{(\\varepsilon)}[2n+1])^2 \\right) $$\nSubstituting the expressions derived in Task 1:\n$$ \\lVert e^{(\\varepsilon)} \\rVert_{2}^2 = \\sum_{n=0}^{L/2-1} \\left( (\\varepsilon r[0]\\,d[n])^2 + (\\varepsilon r[1]\\,d[n])^2 \\right) $$\n$$ \\lVert e^{(\\varepsilon)} \\rVert_{2}^2 = \\sum_{n=0}^{L/2-1} \\varepsilon^2 (r[0]^2 + r[1]^2) (d[n])^2 $$\nFactoring out the terms that do not depend on the summation index $n$:\n$$ \\lVert e^{(\\varepsilon)} \\rVert_{2}^2 = \\varepsilon^2 (r[0]^2 + r[1]^2) \\sum_{n=0}^{L/2-1} (d[n])^2 $$\nThe problem states that $r$ is a unit vector, so $\\lVert r \\rVert_2 = 1$, which means $r[0]^2 + r[1]^2 = 1$. The summation is the squared norm of the detail coefficient sequence, $\\lVert d \\rVert_{2}^2$.\n$$ \\lVert e^{(\\varepsilon)} \\rVert_{2}^2 = \\varepsilon^2 \\lVert d \\rVert_{2}^2 $$\nTaking the square root of both sides gives the norm of the error:\n$$ \\lVert e^{(\\varepsilon)} \\rVert_{2} = |\\varepsilon| \\lVert d \\rVert_{2} $$\nThe denominator of the normalized error is $\\lVert x \\rVert_{2}$. The orthonormality of the Haar system implies energy preservation (Parseval's theorem). For each pair of samples $(x[2n], x[2n+1])$, the transformation to $(a[n], d[n])$ is orthogonal, preserving the sum of squares:\n$$ a[n]^2 + d[n]^2 = \\left(\\frac{x[2n] + x[2n+1]}{\\sqrt{2}}\\right)^2 + \\left(\\frac{x[2n] - x[2n+1]}{\\sqrt{2}}\\right)^2 = x[2n]^2 + x[2n+1]^2 $$\nSumming over all $n=0, \\dots, \\frac{L}{2}-1$ gives the total energy conservation:\n$$ \\sum_{n=0}^{L/2-1} a[n]^2 + \\sum_{n=0}^{L/2-1} d[n]^2 = \\sum_{k=0}^{L-1} x[k]^2 $$\n$$ \\lVert a \\rVert_{2}^2 + \\lVert d \\rVert_{2}^2 = \\lVert x \\rVert_{2}^2 $$\nSubstituting these results into the definition of the normalized error gives the final expression:\n$$ E_{\\mathrm{norm}}(\\varepsilon; x) = \\frac{|\\varepsilon| \\lVert d \\rVert_{2}}{\\lVert x \\rVert_{2}} = \\frac{|\\varepsilon| \\lVert d \\rVert_{2}}{\\sqrt{\\lVert a \\rVert_{2}^2 + \\lVert d \\rVert_{2}^2}} $$\nThis expression depends only on $\\varepsilon$ and quantities computable from $x[n]$ (namely, the norms of the approximation $a$ and detail $d$ coefficients), as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the filter bank perturbation problem by carrying out the specified tasks.\n    \"\"\"\n\n    # --- Fixed Parameters ---\n    SQRT2 = np.sqrt(2.0)\n    r = np.array([0.6, 0.8])\n\n    # Verify that the norm of r is 1\n    # This is a sanity check as per the problem description.\n    norm_r_sq = r[0]**2 + r[1]**2\n    if not np.isclose(norm_r_sq, 1.0):\n        # This case should not be reached with the given r.\n        raise ValueError(f\"Perturbation vector r must have norm 1, but has norm {np.sqrt(norm_r_sq)}\")\n\n    # Synthesis lowpass filter h^{(s)}\n    h_s = np.array([1.0/SQRT2, 1.0/SQRT2])\n    # Unperturbed synthesis highpass filter g\n    g = np.array([1.0/SQRT2, -1.0/SQRT2])\n\n    # --- Test Cases ---\n    x1 = np.array([1.0, -1.0, 2.0, 0.0, 3.0, -2.0, 0.5, 1.5])\n    \n    L2 = 8\n    n_vals = np.arange(L2)\n    x2 = np.cos(2.0 * np.pi * n_vals / L2)\n\n    x3 = np.array([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n    \n    x4 = np.array([2.0, -1.0, 0.0, 1.0, -2.0, 0.5, 1.0, -0.5, 3.0, -1.5])\n\n    test_cases = [\n        {'x': x1, 'epsilon': 0.0},\n        {'x': x1, 'epsilon': 0.05},\n        {'x': x2, 'epsilon': 0.05},\n        {'x': x3, 'epsilon': 0.2},\n        {'x': x4, 'epsilon': 0.1},\n    ]\n\n    delta_E_results = []\n\n    for case in test_cases:\n        x = case['x']\n        epsilon = case['epsilon']\n        L = len(x)\n        half_L = L // 2\n\n        # --- Analysis Step ---\n        # Compute approximation (a) and detail (d) coefficients.\n        a = np.zeros(half_L)\n        d = np.zeros(half_L)\n        for n in range(half_L):\n            a[n] = (x[2*n] + x[2*n+1]) / SQRT2\n            d[n] = (x[2*n] - x[2*n+1]) / SQRT2\n\n        # --- Compute Theoretical Normalized Error (E_theory) ---\n        norm_d = np.linalg.norm(d)\n        norm_x = np.linalg.norm(x)\n        \n        # Handle case where norm_x is zero to avoid division by zero.\n        if np.isclose(norm_x, 0.0):\n            E_theory = 0.0\n        else:\n            E_theory = abs(epsilon) * norm_d / norm_x\n\n        # --- Compute Empirical Normalized Error (E_emp) ---\n        # Perturbed synthesis highpass filter g_tilde^{(s)}\n        g_tilde_s = g + epsilon * r\n\n        # Synthesis Step\n        x_hat = np.zeros(L)\n        for n in range(half_L):\n            x_hat[2*n]   = h_s[0] * a[n] + g_tilde_s[0] * d[n]\n            x_hat[2*n+1] = h_s[1] * a[n] + g_tilde_s[1] * d[n]\n\n        # Compute error vector and its norm\n        error_vec = x_hat - x\n        norm_e = np.linalg.norm(error_vec)\n\n        # Compute empirical normalized error\n        if np.isclose(norm_x, 0.0):\n            E_emp = 0.0\n        else:\n            E_emp = norm_e / norm_x\n\n        # --- Compute Absolute Difference ---\n        delta_E = abs(E_emp - E_theory)\n        delta_E_results.append(delta_E)\n\n    # --- Final Output ---\n    # Format the results as requested.\n    # The expected differences should be near machine precision.\n    output_str = f\"[{','.join(map(str, delta_E_results))}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}