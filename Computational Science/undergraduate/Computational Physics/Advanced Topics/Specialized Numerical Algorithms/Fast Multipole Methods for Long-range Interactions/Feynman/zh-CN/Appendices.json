{
    "hands_on_practices": [
        {
            "introduction": "在设计和实现复杂的计算算法时，理解其内存消耗与理解其时间复杂度同样重要。本练习将引导你基于快速多极子方法 (FMM) 的核心数据结构——八叉树、球谐展开系数和邻近列表——来构建一个精确的内存模型。通过这个实践，你将学会如何定量分析算法的资源需求如何随粒子数 $N$ 和展开阶数 $p$ 等关键参数扩展，这是评估和优化大规模模拟性能的第一步。",
            "id": "2392064",
            "problem": "要求您对三维快速多极子方法（FMM）的拉普拉斯核实现进行建模，并计算其内存占用作为粒子数和展开阶数的函数。您的任务是根据算法数据结构的第一性原理推导出一个有原则的内存模型，然后实现一个程序，用给定的测试套件来评估该模型。\n\n假设采用以下标准且明确定义的设置：\n\n- 用于三维拉普拉斯势的快速多极子方法（FMM）使用实球谐函数展开，阶数最高为 $p$。\n- 计算域是一个立方体，被划分为一个深度为 $h$ 的完整的、层级均匀的八叉树，使得在深度 $h$ 的每个叶节点最多包含 $n_{\\text{leaf}}$ 个粒子。一个深度为 $h$ 的完整八叉树恰好有 $8^h$ 个叶节点和 $(8^{h+1} - 1)/7$ 个总节点（包括内部节点和叶节点）。选择最小的深度 $h$ 使得 $8^h \\ge \\lceil N / n_{\\text{leaf}} \\rceil$，其中 $N$ 是粒子数。\n- 在三维空间中，对于拉普拉斯核，一个阶数为 $p$ 的实球谐多极展开的系数数量等于直到 $p$ 阶的球谐函数数量，即 $\\sum_{\\ell=0}^{p} (2\\ell + 1) = (p+1)^2$。一个局部展开具有相同数量的系数。\n- 所有浮点值都以 IEEE $754$ 双精度存储（即每个浮点值 $8$ 字节），所有整数索引都以 $64$ 位有符号整数存储（即每个整数 $8$ 字节）。\n\n您必须采用以下精确的内存模型：\n\n- 每个粒子：\n  - 存储位置 $(x,y,z)$，为三个双精度浮点数：$3 \\times 8$ 字节。\n  - 存储粒子的标量源强度 $q$，为一个双精度浮点数：$1 \\times 8$ 字节。\n  - 存储包含该粒子的叶节点的索引，为一个 $64$ 位整数：$1 \\times 8$ 字节。\n  - 存储用于 Morton 排序的置换索引，为一个 $64$ 位整数：$1 \\times 8$ 字节。\n  - 因此，每个粒子的内存为 $4 \\times 8 + 2 \\times 8 = 48$ 字节，总粒子存储为 $M_{\\text{particles}}(N) = 48N$ 字节。\n- 每个树节点（包括内部节点和叶节点），存储节点元数据：\n  - 节点中心 $(c_x,c_y,c_z)$，为三个双精度浮点数：$3 \\times 8$ 字节。\n  - 节点半尺寸 $h_{\\text{size}}$，为一个双精度浮点数：$1 \\times 8$ 字节。\n  - Morton 排序顺序下的粒子索引范围 $(i_{\\text{start}}, i_{\\text{end}})$，为两个 $64$ 位整数：$2 \\times 8$ 字节。\n  - 因此，每个节点的元数据为 $48$ 字节，总元数据存储为 $M_{\\text{node-meta}}(\\text{total\\_nodes}) = 48 \\times \\text{total\\_nodes}$ 字节。\n- 每个树节点，存储一个多极展开和一个局部展开（均为双精度浮点数），每个都有 $(p+1)^2$ 个系数：\n  - 每个节点的展开存储为 $2 \\times (p+1)^2 \\times 8$ 字节。\n  - 因此，总展开存储为 $M_{\\text{exp}}(\\text{total\\_nodes}, p) = 16 \\times (p+1)^2 \\times \\text{total\\_nodes}$ 字节。\n- 每个叶节点，存储一个固定大小的近邻列表，最多包含 $26$ 个邻居叶节点的索引（轴对齐的相邻邻居），为 $64$ 位整数：\n  - 每个叶节点的邻居列表存储为 $26 \\times 8$ 字节。\n  - 因此，总邻居列表存储为 $M_{\\text{near}}(\\text{leaves}) = 208 \\times \\text{leaves}$ 字节。\n\n核心原理的定义和所需推导：\n\n- 根据球谐函数的定义，直到 $p$ 阶的模态数量为 $\\sum_{\\ell=0}^{p} (2\\ell + 1) = (p+1)^2$。\n- 对于深度为 $h$ 的完整八叉树，总节点数为 $\\sum_{k=0}^{h} 8^k = (8^{h+1} - 1)/7$，叶节点数为 $8^h$。\n- 选择最小深度 $h$ 以满足 $8^h \\ge \\lceil N / n_{\\text{leaf}} \\rceil$。\n\n令 $N$ 表示粒子数，$p$ 表示展开阶数，$n_{\\text{leaf}}$ 表示叶节点容量。定义：\n- $L_{\\text{req}} = \\lceil N / n_{\\text{leaf}} \\rceil$，\n- $h = \\min \\{ h' \\in \\mathbb{N}_0 : 8^{h'} \\ge L_{\\text{req}} \\}$,\n- $\\text{leaves} = 8^h$,\n- $\\text{total\\_nodes} = (8^{h+1} - 1)/7$。\n\n则总内存（以字节为单位）为：\n$$\nM_{\\text{total}}(N,p,n_{\\text{leaf}}) = M_{\\text{particles}}(N) + M_{\\text{node-meta}}(\\text{total\\_nodes}) + M_{\\text{exp}}(\\text{total\\_nodes}, p) + M_{\\text{near}}(\\text{leaves})。\n$$\n\n您的程序必须：\n\n- 实现一个函数，在给定 $(N,p,n_{\\text{leaf}})$ 的情况下，使用上述模型计算 $M_{\\text{total}}$（以字节为单位）。\n- 将结果转换为 mebibytes (MiB)，其中 $1$ MiB $= 2^{20}$ 字节，并将结果报告为四舍五入到恰好 $6$ 位小数的浮点数。\n\n测试套件：\n\n为以下参数集 $(N, p, n_{\\text{leaf}})$ 评估模型：\n\n- $(100000, 6, 200)$: 一个典型的中等规模案例。\n- $(50, 0, 200)$: 非常小的 $N$，最小展开阶数。\n- $(10000, 12, 128)$: 中等规模 $N$，高展开阶数。\n- $(1000000, 4, 256)$: 大规模 $N$，中等展开阶数。\n- $(400, 1, 200)$: 占用界限恰好为两个叶节点，小展开阶数。\n\n最终输出格式：\n\n- 您的程序应生成单行输出，其中包含按顺序排列的测试套件结果，形式为用方括号括起来的逗号分隔列表，每个数字以 MiB 为单位，四舍五入到恰好 $6$ 位小数。例如，一个包含两个结果的输出应如下所示：`[12.345000,67.890000]`。确保逗号后没有空格。",
            "solution": "该问题陈述已根据科学依据、良构性和客观性的既定标准进行了严格验证。\n\n给定条件如下：\n- 一个用于拉普拉斯核的三维快速多极子方法（FMM）内存占用的模型。\n- 使用阶数为 $p$ 的实球谐函数展开，每次展开有 $(p+1)^2$ 个系数。\n- 一个深度为 $h$ 的完整的、层级均匀的八叉树，其中 $h$ 是满足 $8^h \\ge \\lceil N / n_{\\text{leaf}} \\rceil$ 的最小整数。总节点数为 $(8^{h+1}-1)/7$，叶节点数为 $8^h$。\n- 数据类型大小：双精度浮点数为 $8$ 字节，64 位整数为 $8$ 字节。\n- 定义了一个特定的内存模型，包含四个组成部分：\n  1. 粒子存储：$M_{\\text{particles}}(N) = 48N$ 字节。\n  2. 节点元数据存储：$M_{\\text{node-meta}}(\\text{total\\_nodes}) = 48 \\times \\text{total\\_nodes}$ 字节。\n  3. 展开系数存储：$M_{\\text{exp}}(\\text{total\\_nodes}, p) = 16(p+1)^2 \\times \\text{total\\_nodes}$ 字节。\n  4. 叶节点邻居列表存储：$M_{\\text{near}}(\\text{leaves}) = 208 \\times \\text{leaves}$ 字节。\n- 总内存是各部分之和：$M_{\\text{total}} = M_{\\text{particles}} + M_{\\text{node-meta}} + M_{\\text{exp}} + M_{\\text{near}}$。\n- 最终结果必须以 mebibytes (MiB) 为单位报告，其中 $1 \\text{ MiB} = 2^{20}$ 字节，四舍五入到 $6$ 位小数。\n\n验证结论为该问题有效。它在科学上是合理的，因为它基于 FMM 算法的既定原理及其常用数据结构。所有术语都得到了明确的定义，并提供了所有必要的参数和公式。该问题是良构的，对于每组输入参数都会导出一个唯一的、可验证的解。\n\n我们现在进行形式化推导和计算。总内存 $M_{\\text{total}}$ 是粒子数 $N$、展开阶数 $p$ 和叶节点容量 $n_{\\text{leaf}}$ 的函数。对于给定的三元组 $(N, p, n_{\\text{leaf}})$，计算按以下步骤进行。\n\n首先，我们确定八叉树的结构参数。\n容纳 $N$ 个粒子，每个叶节点容量为 $n_{\\text{leaf}}$ 所需的最小叶节点数为：\n$$ L_{\\text{req}} = \\left\\lceil \\frac{N}{n_{\\text{leaf}}} \\right\\rceil $$\n问题指定了一个完整的、层级均匀的八叉树。该树的深度 $h$ 必须是最小的非负整数，使得其叶节点数 $8^h$ 至少为 $L_{\\text{req}}$。这表示为：\n$$ h = \\min \\{ h' \\in \\mathbb{N}_0 : 8^{h'} \\ge L_{\\text{req}} \\} $$\n这可以通过找到满足 $h \\ge \\log_8(L_{\\text{req}})$ 的最小整数 $h$ 来计算，即对于 $L_{\\text{req}} \\ge 1$，$h = \\lceil\\log_8(L_{\\text{req}})\\rceil$。对于 $N=0$ 或没有粒子落入任何盒子（这不在测试套件中）的边缘情况，$L_{\\text{req}}$ 可能为 $0$，此时 $h=0$ 是正确的选择。\n一旦确定了深度 $h$，完整树模型中的叶节点数为：\n$$ \\text{leaves} = 8^h $$\n深度为 $h$ 的完整八叉树的总节点数是一个几何级数的和：\n$$ \\text{total\\_nodes} = \\sum_{k=0}^{h} 8^k = \\frac{8^{h+1} - 1}{8 - 1} = \\frac{8^{h+1} - 1}{7} $$\n\n其次，我们使用这些结构参数计算模型中每个组件的内存使用情况。\n$N$ 个粒子的存储是直接给出的：\n$$ M_{\\text{particles}} = 48N $$\n所有树节点（包括内部节点和叶节点）的元数据为：\n$$ M_{\\text{node-meta}} = 48 \\times \\text{total\\_nodes} $$\n所有节点的多极展开和局部展开的存储，每个展开都有 $(p+1)^2$ 个大小为 $8$ 字节的系数：\n$$ M_{\\text{exp}} = 2 \\times (p+1)^2 \\times 8 \\times \\text{total\\_nodes} = 16(p+1)^2 \\times \\text{total\\_nodes} $$\n所有叶节点的固定大小邻居列表的存储为：\n$$ M_{\\text{near}} = 26 \\times 8 \\times \\text{leaves} = 208 \\times \\text{leaves} $$\n\n第三，我们将这些组件相加以得到总内存（以字节为单位）：\n$$ M_{\\text{total}}(N, p, n_{\\text{leaf}}) = M_{\\text{particles}} + M_{\\text{node-meta}} + M_{\\text{exp}} + M_{\\text{near}} $$\n代入每个组件的表达式，得到完整的模型：\n$$ M_{\\text{total}} = 48N + 48 \\left(\\frac{8^{h+1} - 1}{7}\\right) + 16(p+1)^2 \\left(\\frac{8^{h+1} - 1}{7}\\right) + 208(8^h) $$\n这可以通过提取 `total_nodes` 项来简化：\n$$ M_{\\text{total}} = 48N + \\left(48 + 16(p+1)^2\\right) \\left(\\frac{8^{h+1} - 1}{7}\\right) + 208(8^h) $$\n\n最后，将以字节为单位的结果转换为 mebibytes (MiB)，并四舍五入到指定精度：\n$$ M_{\\text{MiB}} = \\frac{M_{\\text{total}}}{2^{20}} $$\n此过程将应用于每个指定的测试用例以生成最终输出。例如，对于情况 $(N, p, n_{\\text{leaf}}) = (100000, 6, 200)$，我们有：\n- $L_{\\text{req}} = \\lceil 100000 / 200 \\rceil = 500$。\n- $h = \\min \\{h' : 8^{h'} \\ge 500\\} = 3$，因为 $8^2 = 64$ 且 $8^3 = 512$。\n- $\\text{leaves} = 8^3 = 512$。\n- $\\text{total\\_nodes} = (8^4 - 1)/7 = 4095/7 = 585$。\n- $M_{\\text{particles}} = 48 \\times 100000 = 4,800,000$ 字节。\n- $M_{\\text{node-meta}} = 48 \\times 585 = 28,080$ 字节。\n- $M_{\\text{exp}} = 16 \\times (6+1)^2 \\times 585 = 16 \\times 49 \\times 585 = 458,640$ 字节。\n- $M_{\\text{near}} = 208 \\times 512 = 106,496$ 字节。\n- $M_{\\text{total}} = 4800000 + 28080 + 458640 + 106496 = 5,393,216$ 字节。\n- $M_{\\text{MiB}} = 5393216 / 2^{20} \\approx 5.1434326... \\rightarrow 5.143433$ MiB。\n实现将机械地执行此确切过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\n# from scipy import ...\n\ndef calculate_memory_mib(N, p, n_leaf):\n    \"\"\"\n    Calculates the total memory footprint of an FMM implementation in Mebibytes (MiB).\n\n    Args:\n        N (int): The total number of particles.\n        p (int): The expansion order for spherical harmonics.\n        n_leaf (int): The maximum number of particles per leaf node.\n\n    Returns:\n        float: The total memory usage in MiB.\n    \"\"\"\n    # Step 1: Determine tree structure parameters\n    if N == 0:\n        L_req = 0\n    else:\n        # L_req = ceil(N / n_leaf)\n        L_req = math.ceil(N / n_leaf)\n\n    if L_req <= 1:\n        h = 0\n    else:\n        # h = min { h' in N_0 : 8^h' >= L_req }\n        # This is equivalent to ceil(log8(L_req))\n        h = math.ceil(math.log(L_req, 8))\n\n    # Number of leaves in a complete octree of depth h\n    leaves = 8**h\n    # Total nodes in a complete octree of depth h\n    total_nodes = (8**(h + 1) - 1) // 7\n\n    # Step 2: Calculate memory for each component in bytes\n    # Per-particle storage\n    m_particles = 48 * N\n    \n    # Per-node metadata storage\n    m_node_meta = 48 * total_nodes\n    \n    # Per-node expansion storage\n    num_coeffs = (p + 1)**2\n    # 2 expansions (multipole, local) * num_coeffs * 8 bytes/coeff\n    m_exp = 16 * num_coeffs * total_nodes\n    \n    # Per-leaf near-neighbor list storage\n    # 26 neighbors * 8 bytes/index\n    m_near = 208 * leaves\n\n    # Step 3: Sum components and convert to MiB\n    m_total_bytes = m_particles + m_node_meta + m_exp + m_near\n    \n    # 1 MiB = 2^20 bytes\n    mebibytes = m_total_bytes / (2**20)\n    \n    return mebibytes\n\ndef solve():\n    \"\"\"\n    Solves the problem by evaluating the memory model for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (N, p, n_leaf)\n    test_cases = [\n        (100000, 6, 200),  # a typical moderate case\n        (50, 0, 200),      # very small N, minimal expansion order\n        (10000, 12, 128),  # moderate N, high expansion order\n        (1000000, 4, 256), # large N, moderate expansion order\n        (400, 1, 200),     # exactly two leaves in occupancy bound\n    ]\n\n    results = []\n    for case in test_cases:\n        N, p, n_leaf = case\n        result_mib = calculate_memory_mib(N, p, n_leaf)\n        # Format the result to exactly 6 decimal places\n        results.append(f\"{result_mib:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在使用多极展开成功近似远场相互作用后，对近邻粒子进行直接、精确的力计算就构成了 FMM 算法中的一个主要计算瓶颈。本练习专注于优化这一关键部分，指导你利用现代计算机硬件的并行计算能力。你将通过向量化的数组运算来模拟单指令多数据 (SIMD) 的编程思想，从而高效地处理近场计算，这是将理论算法转化为高性能代码的关键实践。",
            "id": "2392085",
            "problem": "给定一个包含$N$个点状粒子的三维空间系统，它们通过一个软化的反平方定律核（引力或静电）相互作用，粒子$i$和$j$之间的势对力由下式给出：\n$$\n\\mathbf{F}_{ij} \\;=\\; G\\,m_i m_j \\,\\frac{\\mathbf{r}_{j}-\\mathbf{r}_{i}}{\\left(\\lVert \\mathbf{r}_{j}-\\mathbf{r}_{i}\\rVert^2 + \\varepsilon^2\\right)^{3/2}},\n$$\n其中$G$是一个常数，$m_i$是粒子$i$的质量，$\\mathbf{r}_i \\in \\mathbb{R}^3$是其位置，$\\varepsilon>0$是一个软化长度，用于避免在零间距时出现奇异点。快速多极子方法（Fast Multipole Method, FMM）的近场阶段仅计算每个单元局部邻域内粒子间的精确成对相互作用，而远场相互作用则通过多极展开来近似。在此任务中，您将通过使用向量化数组算术进行批量操作，为一组单元实现基于单指令多数据（SIMD）原则的近场计算。\n\n从以下基本基础开始：牛顿万有引力定律指出，位于位置$\\mathbf{r}_i$、质量为$m_i$的粒子，受到位于位置$\\mathbf{r}_j$、质量为$m_j$的另一个粒子的作用力，该力的大小与质量的乘积 $m_i m_j$ 成正比，与间距的平方成反比，方向沿连接两个粒子的直线。在数值模拟中，一个标准且经过充分测试的修改是引入一个软化参数$\\varepsilon$来在短距离处对核进行正则化。这产生了上述的软化成对力，这是一个在$N$体计算中广泛使用且物理上现实的模型。\n\n将单位立方体域$[0,1)^3$划分为一个由边长为$h>0$的立方单元组成的均匀笛卡尔网格。每个单元由一个三元组$(c_x,c_y,c_z)$索引，其中$c_x\\in\\{0,\\dots,n_x-1\\}$，$c_y\\in\\{0,\\dots,n_y-1\\}$，$c_z\\in\\{0,\\dots,n_z-1\\}$，且$n_x=\\lceil 1/h\\rceil$，$n_y=\\lceil 1/h\\rceil$，$n_z=\\lceil 1/h\\rceil$。一个单元的近场相互作用列表包括其自身及其在$3\\times 3\\times 3$模板中的相邻邻居，该模板在域边界处被截断。为避免重复计算，强制执行以下决胜规则：对于一个给定的索引为$(c_x,c_y,c_z)$的单元，仅处理满足$(\\delta_x>0)$或$(\\delta_x=0 \\wedge \\delta_y>0)$或$(\\delta_x=0 \\wedge \\delta_y=0 \\wedge \\delta_z\\ge 0)$的邻居偏移量$(\\delta_x,\\delta_y,\\delta_z)$。对于单元自身的情况$(\\delta_x,\\delta_y,\\delta_z)=(0,0,0)$，将成对相互作用限制在索引有序的粒子对$i<j$上，这样任何粒子都不会与自身相互作用，并且同一单元内的每个无序对都只被处理一次。对于两个不同单元之间的相互作用，应用牛顿第三定律，通过大小相等、方向相反的贡献来更新双方的力。\n\n您的任务是实现两个函数：\n- 一个参考近场计算，使用直接的嵌套循环，严格遵守上述邻域定义和决胜规则。\n- 一个类SIMD的近场计算，使用向量化数组操作来以宽度为$w\\in\\mathbb{N}$的块来处理源，模拟诸如高级向量扩展（Advanced Vector Extensions, AVX）之类的硬件SIMD宽度。块宽度$w$是一个参数。您的实现不应计算任何远场项。\n\n使用双精度算术。不涉及角度。不需要显式的物理单位转换；在此作业的代码中，将所有量视为无量纲。\n\n测试套件：\n在您的程序中实现以下测试用例。所有随机抽取必须使用指定的种子以确保确定性输出。对于所有测试，使用$G=1$，并在代码内部使用显式的浮点数阈值以绝对或相对容差来表示所有比较。\n\n- 测试 $1$ (随机系统上的等效性)：$N=64$，$h=0.5$，$\\varepsilon=10^{-4}$，$w=4$。使用种子$1234$在$[0,1)$内均匀生成位置。使用相同的种子在$[0.5,1.5)$内均匀生成质量。使用参考方法和类SIMD方法计算总近场力，并返回一个布尔值，指示所有分量上的最大绝对差是否小于$10^{-11}$。\n\n- 测试 $2$ (自作用力为零)：$N=1$，$h=1.0$，$\\varepsilon=10^{-3}$，$w=4$。一个粒子位于$\\mathbf{r}=(0.3,0.4,0.5)$，质量$m=1.0$。返回一个布尔值，指示计算出的力向量在绝对容差$10^{-15}$内是否为严格的零向量。\n\n- 测试 $3$ (软化有限极限检查)：两个粒子位于$\\mathbf{r}_1=(0.4,0.4,0.4)$和$\\mathbf{r}_2=(0.4+d,0.4,0.4)$，其中$d=10^{-9}$，质量$m_1=2.0$，$m_2=3.0$，$h=1.0$，$\\varepsilon=10^{-3}$，$w=8$。使用类SIMD方法计算粒子$1$上的力的大小，并将其与解析软化预测进行比较：\n$$\n\\lVert \\mathbf{F}_{12}\\rVert \\;=\\; G\\,m_1 m_2 \\,\\frac{d}{\\left(d^2+\\varepsilon^2\\right)^{3/2}}.\n$$\n返回一个布尔值，指示相对误差是否小于$10^{-12}$。\n\n- 测试 $4$ (牛顿第三定律一致性)：$N=30$，使用种子$2023$在$[0,0.4)$内均匀抽取位置，使用相同的种子在$[0.5,1.5)$内均匀抽取质量，$h=1.0$，$\\varepsilon=10^{-4}$，$w=4$。使用类SIMD方法计算所有粒子上的总力，并返回一个布尔值，指示所有力向量总和的欧几里得范数是否小于$10^{-11}$。\n\n- 测试 $5$ (块宽度不变性)：$N=80$，使用种子$777$在$[0,1)$内均匀抽取位置，使用相同的种子在$[0.5,1.5)$内均匀抽取质量，$h=0.25$，$\\varepsilon=10^{-4}$。使用$w=2$，$w=4$和$w=8$计算类SIMD力。返回一个布尔值，指示这些结果中任意两对之间的最大绝对差是否小于$10^{-11}$。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，\"[result1,result2,result3,result4,result5]\"），其中每个结果是对应于上述顺序测试的布尔值。不应打印其他文本。程序必须是一个完整、可运行的解决方案，不需要任何用户输入或外部文件。您必须按规定实现参考和类SIMD的近场函数，并且在类SIMD函数的跨单元交互中仅使用向量化数组操作（没有显式的逐对Python循环），仅在同单元交互中允许使用逐粒子循环，因为这对于强制执行$i<j$是必要的。整个计算必须以双精度进行，并且在给定随机种子的情况下必须是确定性的。",
            "solution": "提交分析的问题陈述被认为是有效的。它具有科学依据、提法恰当、客观且内部一致。它提出了一个计算物理学中的标准任务：为一个$N$体系统实现直接的近场力计算，这是诸如快速多极子方法（FMM）等算法的基本组成部分。该问题提供了精确的数学定义、算法约束和一套全面的可验证测试用例。因此，我将继续提供一个完整的解决方案。\n\n问题的核心是计算一个包含$N$个粒子的系统中每个粒子$i$所受的总力 $\\mathbf{F}_i = \\sum_{j \\neq i} \\mathbf{F}_{ij}$，其中成对力由软化的反平方定律给出：\n$$\n\\mathbf{F}_{ij} \\;=\\; G\\,m_i m_j \\,\\frac{\\mathbf{r}_{j}-\\mathbf{r}_{i}}{\\left(\\lVert \\mathbf{r}_{j}-\\mathbf{r}_{i}\\rVert^2 + \\varepsilon^2\\right)^{3/2}}\n$$\n对所有粒子对进行直接求和的计算成本为$O(N^2)$，这对于大的$N$来说是不可行的。FMM通过将相互作用分解为近场和远场贡献来降低这一成本。本问题仅关注近场部分，其中相互作用是直接计算的。\n\n为了构建这种计算，将域划分为一个由立方单元组成的网格。一个粒子的近场由其自身单元和相邻单元内的粒子组成。对于一个给定的单元，其相互作用列表包括其自身及其在$3 \\times 3 \\times 3$模板中的26个邻居。为确保每个粒子对都被恰好考虑一次并遵守牛顿第三定律（$\\mathbf{F}_{ij} = -\\mathbf{F}_{ji}$），需要一个系统性的规则来处理单元对。问题指定了一个对单元偏移向量$(\\delta_x, \\delta_y, \\delta_z)$的字典序决胜规则，这保证了对于任何两个相互作用的不同单元，计算只执行一次。\n\n我们将按要求构建两种实现：一种是使用显式循环的参考实现，作为正确性的基准；另一种是向量化实现，模仿单指令多数据（SIMD）处理，以提高在现代计算机架构上的性能。\n\n首先，必须将粒子有效地分配到各自的单元中。给定粒子位置 $\\mathbf{r}_i = (x_i, y_i, z_i)$ 和单元边长$h$，可以通过 $c_k = \\lfloor r_{i,k} / h \\rfloor$ 找到单元索引$(c_x, c_y, c_z)$。可以为每个单元计算一个单个标量键，例如，通过 $k = c_x n_y n_z + c_y n_z + c_z$，这有助于按单元对粒子进行排序和分组。\n\n**参考实现**\n\n该实现使用嵌套循环直接遵循规定的逻辑。\n1. 创建一个数据结构，例如字典，用于将每个单元索引$(c_x, c_y, c_z)$映射到居住在其中的粒子索引列表。\n2. 算法遍历网格中的每个单元$C_1$。\n3. 对于每个$C_1$，它遍历由决胜规则定义的14个有效的邻居偏移$(\\delta_x, \\delta_y, \\delta_z)$。这可以找到目标单元$C_2$。\n4. 如果$C_1$和$C_2$是同一个单元（偏移为$(0,0,0)$），我们计算其内部粒子之间的相互作用。为避免自作用和重复计算，我们迭代满足$i < j$的粒子对$(i, j)$，计算$\\mathbf{F}_{ij}$，并将其加到粒子$i$的总力上，将$-\\mathbf{F}_{ij}$加到粒子$j$的总力上。\n5. 如果$C_1$和$C_2$是不同的单元，我们遍历$C_1$中的所有粒子$i$和$C_2$中的所有粒子$j$。对于每个粒子对，我们计算$\\mathbf{F}_{ij}$并相应地更新两个粒子上的力。\n\n**向量化（类SIMD）实现**\n\n这种方法利用了向量化数组操作（如NumPy库提供的），在单个操作中处理多个数据元素。\n1. **数据重组**：为了实现高效的块处理，粒子数据数组（位置和质量）根据它们的单元键进行排序。这在内存中将来自同一单元的粒子物理上分组到一起。我们还必须存储反向映射，以将最终的力数组恢复到其原始顺序。\n2. **单元对迭代**：遍历单元对的主循环结构与参考实现相似。然而，我们现在处理的是已排序数组的切片，这些切片对应于给定单元中的粒子，而不是索引列表。\n3. **跨单元相互作用**：这是向量化最有效的地方。对于目标单元$C_1$和源单元$C_2$之间的相互作用，我们以指定的宽度$w$为块来处理$C_2$中的粒子。对于每个包含$w$个源粒子的块，我们使用广播同时计算其与$C_1$中所有目标粒子的相互作用：\n    - 设$C_1$中$N_t$个目标的位置为$\\mathbf{R}_t$（形状为$(N_t, 3)$），$C_2$中一个包含$w$个源的块的位置为$\\mathbf{R}_s$（形状为$(w, 3)$）。\n    - 位移向量作为一个张量计算：$\\Delta\\mathbf{R}$，通过 `R_s[None, :, :] - R_t[:, None, :]` 计算，得到形状为$(N_t, w, 3)$的张量。\n    - 距离的平方 $\\lVert \\Delta\\mathbf{R} \\rVert^2$ 及后续的力计算都在这些张量上执行。\n    - 通过对源维度（轴1）求和，可以找到每个目标粒子受源块作用的总力。\n    - 根据牛顿第三定律，块中每个源粒子所受的力是目标维度（轴0）的负和。然后将这些力的贡献累加到全局力数组中。\n4. **同单元相互作用**：$i < j$的条件本质上是串行的，无法通过简单的数组操作进行有效向量化。按照问题陈述的允许，这部分通过对单元切片内的粒子使用标准嵌套循环来实现，与参考方法相同。\n\n这种向量化策略，特别是对于跨单元相互作用，显著减少了显式Python循环的数量，并允许底层编译库利用硬件级并行性，从而带来显著的性能提升。然后，已排序粒子的最终计算力数组将被重新排序，以匹配原始粒子输入顺序。提供的测试套件用于验证两种实现的正确性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    \n    # --- Helper function for force calculation kernel ---\n    def compute_pairwise_force(pos_i, mass_i, pos_j, mass_j, G, eps):\n        \"\"\"\n        Computes pairwise forces between two sets of particles i and j.\n        This is a vectorized kernel.\n        Returns:\n            F_on_i: Force on particles i from particles j.\n            F_on_j: Force on particles j from particles i.\n        \"\"\"\n        # Broadcasting to compute all pairs of interactions\n        # dr shape: (num_i, num_j, 3)\n        dr = pos_j[np.newaxis, :, :] - pos_i[:, np.newaxis, :]\n        \n        # r_sq shape: (num_i, num_j)\n        r_sq = np.sum(dr**2, axis=2)\n        \n        # inv_r3 shape: (num_i, num_j)\n        inv_r3 = (r_sq + eps**2)**(-1.5)\n        \n        # mass_prod shape: (num_i, num_j)\n        mass_prod = mass_i[:, np.newaxis] * mass_j[np.newaxis, :]\n        \n        # F_matrix shape: (num_i, num_j, 3)\n        # force on i from j\n        F_matrix = G * mass_prod[:, :, np.newaxis] * dr * inv_r3[:, :, np.newaxis]\n        \n        # F_on_i shape: (num_i, 3)\n        F_on_i = np.sum(F_matrix, axis=1)\n        \n        # F_on_j shape: (num_j, 3)\n        F_on_j = -np.sum(F_matrix, axis=0)\n        \n        return F_on_i, F_on_j\n\n    # --- Reference implementation using loops ---\n    def reference_near_field(N, pos, mass, h, G, eps):\n        \"\"\"\n        Reference near-field computation using nested loops.\n        \"\"\"\n        forces = np.zeros((N, 3), dtype=np.float64)\n        \n        if N == 0:\n            return forces\n\n        nx = ny = nz = int(np.ceil(1.0 / h))\n        \n        # Build cell map\n        cell_map = {}\n        for i in range(N):\n            cell_idx = tuple(np.floor(pos[i] / h).astype(int))\n            if cell_idx not in cell_map:\n                cell_map[cell_idx] = []\n            cell_map[cell_idx].append(i)\n\n        # Generate valid neighbor offsets\n        offsets = []\n        for dx in range(-1, 2):\n            for dy in range(-1, 2):\n                for dz in range(-1, 2):\n                    if dx > 0 or (dx == 0 and dy > 0) or (dx == 0 and dy == 0 and dz >= 0):\n                        offsets.append((dx, dy, dz))\n        \n        for cx in range(nx):\n            for cy in range(ny):\n                for cz in range(nz):\n                    c1_idx = (cx, cy, cz)\n                    if c1_idx not in cell_map:\n                        continue\n                    \n                    particles_c1 = cell_map[c1_idx]\n                    \n                    for dx, dy, dz in offsets:\n                        c2_idx = (cx + dx, cy + dy, cz + dz)\n                        \n                        if not (0 <= c2_idx[0] < nx and 0 <= c2_idx[1] < ny and 0 <= c2_idx[2] < nz):\n                            continue\n                        \n                        if c2_idx not in cell_map:\n                            continue\n                        \n                        particles_c2 = cell_map[c2_idx]\n\n                        if c1_idx == c2_idx: # Same-cell interaction\n                            for i_idx, p_i in enumerate(particles_c1):\n                                for p_j in particles_c1[i_idx + 1:]:\n                                    dr = pos[p_j] - pos[p_i]\n                                    r_sq = np.sum(dr**2)\n                                    inv_r3 = (r_sq + eps**2)**(-1.5)\n                                    f_vec = G * mass[p_i] * mass[p_j] * dr * inv_r3\n                                    forces[p_i] += f_vec\n                                    forces[p_j] -= f_vec\n                        else: # Cross-cell interaction\n                            for p_i in particles_c1:\n                                for p_j in particles_c2:\n                                    dr = pos[p_j] - pos[p_i]\n                                    r_sq = np.sum(dr**2)\n                                    inv_r3 = (r_sq + eps**2)**(-1.5)\n                                    f_vec = G * mass[p_i] * mass[p_j] * dr * inv_r3\n                                    forces[p_i] += f_vec\n                                    forces[p_j] -= f_vec\n        return forces\n\n    # --- SIMD-like implementation using vectorization ---\n    def simd_like_near_field(N, pos, mass, h, G, eps, w):\n        \"\"\"\n        SIMD-like near-field computation using vectorized array operations.\n        \"\"\"\n        forces_sorted = np.zeros((N, 3), dtype=np.float64)\n        if N == 0:\n            return forces_sorted\n        \n        nx = ny = nz = int(np.ceil(1.0 / h))\n\n        # Reorganize data by cell\n        cell_indices_per_particle = np.floor(pos / h).astype(int)\n        cell_keys = cell_indices_per_particle[:, 0] * (ny * nz) + cell_indices_per_particle[:, 1] * nz + cell_indices_per_particle[:, 2]\n        \n        sorted_indices = np.argsort(cell_keys)\n        unsorted_indices = np.argsort(sorted_indices)\n\n        pos_sorted = pos[sorted_indices]\n        mass_sorted = mass[sorted_indices]\n        \n        unique_cell_keys, cell_starts = np.unique(cell_keys[sorted_indices], return_index=True)\n        cell_counts = np.diff(np.append(cell_starts, N))\n\n        cell_info = {key: {'start': start, 'count': count} \n                     for key, start, count in zip(unique_cell_keys, cell_starts, cell_counts)}\n\n        # Generate valid neighbor offsets\n        offsets = []\n        for dx in range(-1, 2):\n            for dy in range(-1, 2):\n                for dz in range(-1, 2):\n                    if dx > 0 or (dx == 0 and dy > 0) or (dx == 0 and dy == 0 and dz >= 0):\n                        offsets.append((dx, dy, dz))\n        \n        for cx in range(nx):\n            for cy in range(ny):\n                for cz in range(nz):\n                    c1_key = cx * (ny * nz) + cy * nz + cz\n                    if c1_key not in cell_info:\n                        continue\n                    \n                    c1_meta = cell_info[c1_key]\n                    c1_start, c1_count = c1_meta['start'], c1_meta['count']\n                    c1_end = c1_start + c1_count\n                    \n                    pos_c1 = pos_sorted[c1_start:c1_end]\n                    mass_c1 = mass_sorted[c1_start:c1_end]\n\n                    for dx, dy, dz in offsets:\n                        ncx, ncy, ncz = cx + dx, cy + dy, cz + dz\n                        \n                        if not (0 <= ncx < nx and 0 <= ncy < ny and 0 <= ncz < nz):\n                            continue\n                        \n                        c2_key = ncx * (ny * nz) + ncy * nz + ncz\n                        if c2_key not in cell_info:\n                            continue\n                        \n                        c2_meta = cell_info[c2_key]\n                        c2_start, c2_count = c2_meta['start'], c2_meta['count']\n                        c2_end = c2_start + c2_count\n\n                        pos_c2 = pos_sorted[c2_start:c2_end]\n                        mass_c2 = mass_sorted[c2_start:c2_end]\n\n                        if c1_key == c2_key: # Same-cell interaction (loop-based)\n                            for i in range(c1_count):\n                                for j in range(i + 1, c1_count):\n                                    p_i, p_j = c1_start + i, c1_start + j\n                                    dr = pos_sorted[p_j] - pos_sorted[p_i]\n                                    r_sq = np.sum(dr**2)\n                                    inv_r3 = (r_sq + eps**2)**(-1.5)\n                                    f_vec = G * mass_sorted[p_i] * mass_sorted[p_j] * dr * inv_r3\n                                    forces_sorted[p_i] += f_vec\n                                    forces_sorted[p_j] -= f_vec\n                        else: # Cross-cell interaction (vectorized)\n                            for k in range(0, c2_count, w):\n                                block_end = min(k + w, c2_count)\n                                pos_c2_block = pos_c2[k:block_end]\n                                mass_c2_block = mass_c2[k:block_end]\n\n                                f_on_c1, f_on_c2_block = compute_pairwise_force(\n                                    pos_c1, mass_c1, pos_c2_block, mass_c2_block, G, eps)\n                                \n                                forces_sorted[c1_start:c1_end] += f_on_c1\n                                forces_sorted[c2_start + k : c2_start + block_end] += f_on_c2_block\n\n        return forces_sorted[unsorted_indices]\n\n    # --- Test Suite ---\n    results = []\n    G_val = 1.0\n\n    # Test 1: Equivalence on random system\n    N1, h1, eps1, w1 = 64, 0.5, 1e-4, 4\n    rng1 = np.random.default_rng(1234)\n    pos1 = rng1.uniform(0, 1, size=(N1, 3))\n    mass1 = rng1.uniform(0.5, 1.5, size=N1)\n    f_ref = reference_near_field(N1, pos1, mass1, h1, G_val, eps1)\n    f_simd = simd_like_near_field(N1, pos1, mass1, h1, G_val, eps1, w1)\n    results.append(np.max(np.abs(f_ref - f_simd)) < 1e-11)\n\n    # Test 2: Self-force zero\n    N2, h2, eps2, w2 = 1, 1.0, 1e-3, 4\n    pos2 = np.array([[0.3, 0.4, 0.5]])\n    mass2 = np.array([1.0])\n    f_self = simd_like_near_field(N2, pos2, mass2, h2, G_val, eps2, w2)\n    results.append(np.all(np.abs(f_self) < 1e-15))\n\n    # Test 3: Softening finite limit check\n    h3, eps3, w3 = 1.0, 1e-3, 8\n    d3 = 1e-9\n    pos3 = np.array([[0.4, 0.4, 0.4], [0.4 + d3, 0.4, 0.4]])\n    mass3 = np.array([2.0, 3.0])\n    f_soft = simd_like_near_field(2, pos3, mass3, h3, G_val, eps3, w3)\n    f_num = np.linalg.norm(f_soft[0])\n    f_analytic = G_val * mass3[0] * mass3[1] * d3 / (d3**2 + eps3**2)**1.5\n    results.append(abs(f_num - f_analytic) / f_analytic < 1e-12)\n\n    # Test 4: Newton’s third law consistency\n    N4, h4, eps4, w4 = 30, 1.0, 1e-4, 4\n    rng4 = np.random.default_rng(2023)\n    pos4 = rng4.uniform(0, 0.4, size=(N4, 3))\n    mass4 = rng4.uniform(0.5, 1.5, size=N4)\n    f_newton = simd_like_near_field(N4, pos4, mass4, h4, G_val, eps4, w4)\n    total_force = np.sum(f_newton, axis=0)\n    results.append(np.linalg.norm(total_force) < 1e-11)\n\n    # Test 5: Block width invariance\n    N5, h5, eps5 = 80, 0.25, 1e-4\n    rng5 = np.random.default_rng(777)\n    pos5 = rng5.uniform(0, 1, size=(N5, 3))\n    mass5 = rng5.uniform(0.5, 1.5, size=N5)\n    f_w2 = simd_like_near_field(N5, pos5, mass5, h5, G_val, eps5, w=2)\n    f_w4 = simd_like_near_field(N5, pos5, mass5, h5, G_val, eps5, w=4)\n    f_w8 = simd_like_near_field(N5, pos5, mass5, h5, G_val, eps5, w=8)\n    diff1 = np.max(np.abs(f_w2 - f_w4))\n    diff2 = np.max(np.abs(f_w2 - f_w8))\n    results.append(diff1 < 1e-11 and diff2 < 1e-11)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}