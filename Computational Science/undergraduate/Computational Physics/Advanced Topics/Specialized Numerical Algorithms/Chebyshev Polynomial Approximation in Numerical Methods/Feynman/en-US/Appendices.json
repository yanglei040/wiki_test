{
    "hands_on_practices": [
        {
            "introduction": "To begin our practical exploration, we will investigate the fundamental properties of Chebyshev approximation. The core idea is to represent a complex function or a discrete signal as a weighted sum of Chebyshev polynomials. In this first exercise , you will decompose various one-dimensional signals—representing a simplified row of pixels—into their Chebyshev components. By observing how the approximation quality changes with the number of terms for smooth, discontinuous, and oscillatory signals, you will develop a crucial intuition for the concept of spectral convergence and its limitations, such as the Gibbs phenomenon.",
            "id": "2379175",
            "problem": "Construct a program that, for a given one-dimensional sequence of pixel intensities, computes its expansion in the basis of Chebyshev polynomials of the first kind and quantifies the effect of truncating the series. Let $M$ denote the number of pixels in a single row, with pixel indices $i \\in \\{0,1,\\dots,M-1\\}$. Map pixel positions to the Chebyshev interval by $x_i = -1 + \\dfrac{2 i}{M-1}$ for all $i$. Let $\\{T_k(x)\\}_{k \\ge 0}$ denote the Chebyshev polynomials of the first kind defined on the interval $[-1,1]$ by the recurrence $T_0(x) = 1$, $T_1(x) = x$, and $T_{k+1}(x) = 2 x T_k(x) - T_{k-1}(x)$ for $k \\ge 1$. For a given integer truncation degree $N \\ge 0$, approximate a pixel row by the polynomial $p_N(x) = \\sum_{k=0}^{N} c_k T_k(x)$ whose coefficients $\\{c_k\\}_{k=0}^{N}$ minimize the discrete squared error $\\sum_{i=0}^{M-1} \\left(p_N(x_i) - y_i\\right)^2$ with respect to the given pixel intensities $\\{y_i\\}_{i=0}^{M-1}$. Quantify the approximation quality by the Root Mean Square Error (RMSE) defined by $\\mathrm{RMSE}(N) = \\sqrt{\\dfrac{1}{M} \\sum_{i=0}^{M-1} \\left(p_N(x_i) - y_i\\right)^2}$. All trigonometric function arguments are to be understood in radians.\n\nUse the following test suite. In every test case, let $M = 64$ and define $x_i$ as above. For each test case, compute $\\mathrm{RMSE}(N)$ for truncation degrees $N \\in \\{0,1,3,7,15,31\\}$.\n\nTest Case $1$ (smooth, low-to-moderate frequency content):\n- Pixel intensities: $y_i = 0.5 + 0.4 \\cos(\\pi x_i) + 0.1 \\cos(5 \\pi x_i)$ for all $i$.\n\nTest Case $2$ (step edge):\n- Pixel intensities: $y_i = 0.1$ if $x_i < 0$, and $y_i = 0.9$ if $x_i \\ge 0$, for all $i$.\n\nTest Case $3$ (high-frequency oscillation):\n- Pixel intensities: $y_i = 0.5 + 0.45 \\cos(15 \\pi x_i)$ for all $i$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order and structure: an outer list of length $3$ corresponding to the three test cases in the order given above, where each element is an inner list of length $6$ containing the $6$ $\\mathrm{RMSE}(N)$ values in the order $N \\in \\{0,1,3,7,15,31\\}$. For example, the format must be exactly of the form $[[r_{1,1},r_{1,2},r_{1,3},r_{1,4},r_{1,5},r_{1,6}],[r_{2,1},\\dots,r_{2,6}],[r_{3,1},\\dots,r_{3,6}]]$, where each $r_{j,\\ell}$ is a real number.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It constitutes a standard problem in numerical approximation theory, which is a fundamental component of computational physics. All parameters and objectives are defined with sufficient rigor. Therefore, we proceed to derive the solution.\n\nThe objective is to approximate a discrete signal $\\{y_i\\}_{i=0}^{M-1}$ defined on a grid of points $\\{x_i\\}_{i=0}^{M-1}$ with a truncated Chebyshev series of degree $N$. The approximation is a polynomial $p_N(x) = \\sum_{k=0}^{N} c_k T_k(x)$, where $T_k(x)$ is the Chebyshev polynomial of the first kind of degree $k$. The coefficients $\\{c_k\\}_{k=0}^{N}$ must be chosen to minimize the discrete squared error, $S$:\n$$\nS = \\sum_{i=0}^{M-1} \\left(p_N(x_i) - y_i\\right)^2 = \\sum_{i=0}^{M-1} \\left(\\left(\\sum_{k=0}^{N} c_k T_k(x_i)\\right) - y_i\\right)^2\n$$\nThis is a classical linear least-squares problem. We can express this in matrix-vector notation. Let $\\mathbf{y} \\in \\mathbb{R}^M$ be the column vector of pixel intensities, $\\mathbf{y} = [y_0, y_1, \\dots, y_{M-1}]^T$. Let $\\mathbf{c} \\in \\mathbb{R}^{N+1}$ be the column vector of unknown coefficients, $\\mathbf{c} = [c_0, c_1, \\dots, c_N]^T$. We define a matrix $\\mathbf{A} \\in \\mathbb{R}^{M \\times (N+1)}$ whose entries are given by the values of the basis functions at the grid points:\n$$\nA_{ik} = T_k(x_i) \\quad \\text{for } i \\in \\{0, \\dots, M-1\\}, k \\in \\{0, \\dots, N\\}\n$$\nThe vector of approximated values at the grid points is then given by the matrix-vector product $\\mathbf{p}_N = \\mathbf{A}\\mathbf{c}$. The sum of squared errors $S$ is the squared Euclidean norm of the residual vector $\\mathbf{r} = \\mathbf{A}\\mathbf{c} - \\mathbf{y}$:\n$$\nS = \\|\\mathbf{A}\\mathbf{c} - \\mathbf{y}\\|_2^2\n$$\nThe vector of coefficients $\\mathbf{c}$ that minimizes this quantity is the least-squares solution. It is formally given by the solution to the normal equations:\n$$\n(\\mathbf{A}^T \\mathbf{A}) \\mathbf{c} = \\mathbf{A}^T \\mathbf{y}\n$$\nFor numerical stability, especially when the columns of $\\mathbf{A}$ are nearly linearly dependent, it is not advisable to form and invert the matrix $\\mathbf{A}^T \\mathbf{A}$. Instead, robust numerical methods such as QR decomposition or Singular Value Decomposition (SVD) should be employed. Standard numerical libraries provide solvers that implement these stable algorithms.\n\nThe specified grid points $x_i = -1 + \\frac{2i}{M-1}$ are uniformly spaced. They are not the Chebyshev nodes (roots or extrema of $T_M(x)$). Consequently, the basis vectors $\\{ \\mathbf{v}_k \\}_{k=0}^N$, where $(\\mathbf{v}_k)_i = T_k(x_i)$, are not orthogonal with respect to the standard dot product. This necessitates solving a general least-squares system rather than simply projecting the data onto the basis vectors, which would be possible if the basis were orthogonal.\n\nThe algorithm to compute the required Root Mean Square Error (RMSE) for each test case is as follows:\n$1$. Set the number of pixels $M=64$. Define the set of truncation degrees $N \\in \\{0, 1, 3, 7, 15, 31\\}$.\n$2$. Construct the vector of grid points $\\mathbf{x} = [x_0, x_1, \\dots, x_{M-1}]^T$ where $x_i = -1 + \\frac{2i}{M-1}$.\n$3$. For each test case, generate the vector of pixel intensities $\\mathbf{y} = [y_0, y_1, \\dots, y_{M-1}]^T$ according to its specified function.\n$4$. For each truncation degree $N$ in the specified set:\n    a. Construct the $M \\times (N+1)$ matrix $\\mathbf{A}$. The columns of $\\mathbf{A}$ are the Chebyshev polynomials evaluated at the grid points. They are generated using the recurrence relation:\n    $$\n    T_0(x) = 1\n    $$\n    $$\n    T_1(x) = x\n    $$\n    $$\n    T_{k+1}(x) = 2x T_k(x) - T_{k-1}(x) \\quad \\text{for } k \\ge 1\n    $$\n    The $k$-th column of $\\mathbf{A}$ is the vector $[T_k(x_0), T_k(x_1), \\dots, T_k(x_{M-1})]^T$.\n    b. Solve the linear least-squares problem $\\mathbf{A}\\mathbf{c} \\approx \\mathbf{y}$ to find the optimal coefficient vector $\\mathbf{c}$. This yields the minimal sum of squared residuals, $S_{min} = \\|\\mathbf{A}\\mathbf{c} - \\mathbf{y}\\|_2^2$.\n    c. Compute the approximation quality using the Root Mean Square Error:\n    $$\n    \\mathrm{RMSE}(N) = \\sqrt{\\frac{1}{M} \\sum_{i=0}^{M-1} (p_N(x_i) - y_i)^2} = \\sqrt{\\frac{S_{min}}{M}}\n    $$\n$5$. Collect the $\\mathrm{RMSE}(N)$ values for each test case and format the output as specified.\n\nThe behavior of the $\\mathrm{RMSE}(N)$ is expected to differ significantly across the test cases. For the smooth, low-frequency function in Test Case $1$, the Chebyshev series should converge very rapidly, resulting in a fast decrease of $\\mathrm{RMSE}(N)$ with increasing $N$. For the step function in Test Case $2$, the presence of a discontinuity will lead to the Gibbs phenomenon and slow convergence; the $\\mathrm{RMSE}(N)$ will decrease much more slowly. For the high-frequency function in Test Case $3$, the approximation will be poor for small $N$ but should improve dramatically once $N$ is large enough to resolve the oscillations (i.e., when $N$ is comparable to the argument of the cosine function scaled by $\\pi$). This procedure will now be implemented.",
            "answer": "```python\nimport numpy as np\n\ndef build_chebyshev_matrix(x, n_degree):\n    \"\"\"\n    Constructs the design matrix A_ik = T_k(x_i) for k=0...n_degree.\n    \n    Args:\n        x (np.ndarray): Array of points of shape (M,).\n        n_degree (int): The maximum degree N of the Chebyshev polynomials.\n\n    Returns:\n        np.ndarray: The design matrix A of shape (M, N+1).\n    \"\"\"\n    m_pixels = len(x)\n    A = np.zeros((m_pixels, n_degree + 1))\n    \n    # T_0(x) = 1\n    A[:, 0] = 1.0\n    \n    if n_degree > 0:\n        # T_1(x) = x\n        A[:, 1] = x\n    \n    # T_{k+1}(x) = 2*x*T_k(x) - T_{k-1}(x)\n    for k in range(1, n_degree):\n        A[:, k + 1] = 2 * x * A[:, k] - A[:, k - 1]\n        \n    return A\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and compute RMSE values.\n    \"\"\"\n    M = 64\n    N_degrees = [0, 1, 3, 7, 15, 31]\n    \n    x = -1.0 + 2.0 * np.arange(M) / (M - 1.0)\n    \n    # Define test case functions\n    def case1_func(x_pts):\n        return 0.5 + 0.4 * np.cos(np.pi * x_pts) + 0.1 * np.cos(5 * np.pi * x_pts)\n        \n    def case2_func(x_pts):\n        y = np.full_like(x_pts, 0.9)\n        y[x_pts  0] = 0.1\n        return y\n        \n    def case3_func(x_pts):\n        return 0.5 + 0.45 * np.cos(15 * np.pi * x_pts)\n\n    test_cases = [\n        case1_func,\n        case2_func,\n        case3_func\n    ]\n\n    all_results = []\n    \n    for case_func in test_cases:\n        y = case_func(x)\n        case_results = []\n        for N in N_degrees:\n            A = build_chebyshev_matrix(x, N)\n            \n            # Solve the least-squares problem.\n            # `lstsq` returns coefficients, residuals, rank, and singular values.\n            # The 'residuals' is a one-element array containing the sum of squared errors.\n            _coeffs, residuals, _rank, _s = np.linalg.lstsq(A, y, rcond=None)\n            \n            # If the system is full rank, `residuals` contains the sum of squared errors.\n            if residuals.size > 0:\n                sum_sq_res = residuals[0]\n            else:\n                # If no solution or system is rank deficient, calculate manually.\n                p_N = A @ _coeffs\n                sum_sq_res = np.sum((p_N - y)**2)\n\n            rmse = np.sqrt(sum_sq_res / M)\n            case_results.append(rmse)\n        \n        all_results.append(case_results)\n\n    # Format the final output string precisely as required, with no spaces.\n    outer_list_str = []\n    for res_list in all_results:\n      # Use a general format specifier to avoid trailing zeros and ensure precision.\n      inner_list_str = \",\".join(format(n, 'g') for n in res_list)\n      outer_list_str.append(f\"[{inner_list_str}]\")\n    final_output = f\"[{','.join(outer_list_str)}]\"\n\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Having learned to represent functions with Chebyshev polynomials, we now apply this skill to solve a classic problem in modern physics. Finding the maximum of a function often requires finding the roots of its derivative, which can lead to equations without simple analytical solutions. This practice  guides you through deriving Wien's displacement law by finding the peak of Planck's black-body radiation formula, which involves solving a transcendental equation. By approximating this equation with a Chebyshev polynomial and finding its roots numerically, you transform a complex analytical problem into a straightforward algebraic one, a powerful strategy in computational science.",
            "id": "2379178",
            "problem": "You will implement a complete program that models the peak wavelength of black-body radiation, denoted by $\\lambda_{\\max}(T)$ in meters, as a function of absolute temperature $T$ in Kelvin, by constructing and solving a Chebyshev polynomial approximation to the root of the transcendental stationarity condition arising from maximizing the spectral radiance with respect to wavelength. Begin exclusively from the following foundational base: the Planck spectral radiance per unit wavelength for a black body, given by\n$$\nB_{\\lambda}(\\lambda, T) = \\frac{2 h c^{2}}{\\lambda^{5}} \\cdot \\frac{1}{\\exp\\!\\left(\\frac{h c}{\\lambda k_{\\mathrm{B}} T}\\right) - 1},\n$$\nwhere $h$ is Planck’s constant (in joule-seconds), $c$ is the speed of light in vacuum (in meters per second), and $k_{\\mathrm{B}}$ is the Boltzmann constant (in joules per kelvin). The peak wavelength $\\lambda_{\\max}(T)$ is the value of $\\lambda$ that maximizes $B_{\\lambda}(\\lambda, T)$ for a fixed temperature $T$.\n\nYour tasks are:\n- Derive, from the stationarity condition $\\frac{\\partial B_{\\lambda}}{\\partial \\lambda}(\\lambda, T) = 0$ and a non-dimensionalization using a suitable positive dimensionless variable $x$, a transcendental equation for $x$ whose unique positive root determines the peak via $\\lambda_{\\max}(T) = \\frac{b}{T}$, where $b$ is a constant depending only on fundamental constants and the root $x$.\n- Construct a Chebyshev polynomial approximation $p_{n}(x)$ of degree $n$ to the transcendental equation’s left-hand side over a closed interval $[x_{\\min}, x_{\\max}]$ that contains the unique positive root. You must use Chebyshev polynomials on $[-1,1]$ and an affine mapping to $[x_{\\min}, x_{\\max}]$. Choose a polynomial degree $n \\geq 12$ and a sampling strategy consistent with Chebyshev approximation (for example, mapped Chebyshev nodes). Then approximate the root $x^{\\star}$ by solving $p_{n}(x) = 0$ and select the physically meaningful real root in $[x_{\\min}, x_{\\max}]$.\n- Using the resulting approximate root $x^{\\star}$, compute the constant $b$ and then compute $\\lambda_{\\max}(T)$ for each test temperature.\n\nPhysical units and angle specification:\n- All wavelengths must be expressed in meters.\n- All temperatures are in Kelvin.\n- No angles are involved in this task.\n\nTest suite:\n- Use the following temperatures (Kelvin): $[\\,2.7255,\\;300.0,\\;1000.0,\\;3000.0,\\;5772.0,\\;10000.0\\,]$.\n- For each temperature $T$ in the list, compute $\\lambda_{\\max}(T)$ in meters.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each value in meters formatted in scientific notation to $12$ significant digits. For example: $\\texttt{[1.23456789012e-03,2.34567890123e-04,...]}$.\n- The final outputs must be ordered in the same order as the test suite temperatures.\n\nYour solution must be a single, self-contained, runnable program that performs the derivation’s computational consequences, constructs the Chebyshev approximation, solves for the approximate root, and prints the final list in the specified format. No user input is allowed. All constants must be defined in the program using internationally accepted values in the International System of Units (SI).",
            "solution": "The problem as stated is valid. It is scientifically grounded in the principles of quantum mechanics and statistical physics, specifically Planck's law of black-body radiation. The problem is well-posed, objective, and provides a clear, formalizable path to a unique solution using standard numerical methods from computational physics. There are no contradictions, ambiguities, or factual inaccuracies. We may therefore proceed with the solution.\n\nThe objective is to determine the peak emission wavelength, $\\lambda_{\\max}(T)$, of a black body at a given absolute temperature $T$. This wavelength maximizes the Planck spectral radiance function, $B_{\\lambda}(\\lambda, T)$. The starting point is the provided expression for $B_{\\lambda}(\\lambda, T)$:\n$$\nB_{\\lambda}(\\lambda, T) = \\frac{2 h c^{2}}{\\lambda^{5}} \\cdot \\frac{1}{\\exp\\left(\\frac{h c}{\\lambda k_{\\mathrm{B}} T}\\right) - 1}\n$$\nwhere $h$ is Planck's constant, $c$ is the speed of light, and $k_{\\mathrm{B}}$ is the Boltzmann constant.\n\nTo find the maximum, we must solve the stationarity condition $\\frac{\\partial B_{\\lambda}}{\\partial \\lambda} = 0$. For convenience, let us define a constant $A = 2hc^2$ and a dimensionless variable $x = \\frac{hc}{\\lambda k_{\\mathrm{B}} T}$. The radiance function can then be written as:\n$$\nB_{\\lambda}(\\lambda, T) = A \\lambda^{-5} \\left(e^{x} - 1\\right)^{-1}\n$$\nWe apply the product rule for differentiation with respect to $\\lambda$. Note that $x$ is a function of $\\lambda$.\n$$\n\\frac{\\partial B_{\\lambda}}{\\partial \\lambda} = A \\left[ \\left(\\frac{d}{d\\lambda}\\lambda^{-5}\\right) \\left(e^{x} - 1\\right)^{-1} + \\lambda^{-5} \\left(\\frac{d}{d\\lambda}\\left(e^{x} - 1\\right)^{-1}\\right) \\right] = 0\n$$\nThe individual derivatives are:\n$$\n\\frac{d}{d\\lambda}\\lambda^{-5} = -5\\lambda^{-6}\n$$\n$$\n\\frac{d}{d\\lambda}\\left(e^{x} - 1\\right)^{-1} = -1 \\left(e^{x} - 1\\right)^{-2} e^{x} \\frac{dx}{d\\lambda}\n$$\nThe derivative of $x$ with respect to $\\lambda$ is:\n$$\n\\frac{dx}{d\\lambda} = \\frac{d}{d\\lambda} \\left(\\frac{hc}{\\lambda k_{\\mathrm{B}} T}\\right) = \\frac{hc}{k_{\\mathrm{B}} T} \\left(-\\frac{1}{\\lambda^2}\\right) = -\\frac{x}{\\lambda}\n$$\nSubstituting this back, we get:\n$$\n\\frac{d}{d\\lambda}\\left(e^{x} - 1\\right)^{-1} = - \\left(e^{x} - 1\\right)^{-2} e^{x} \\left(-\\frac{x}{\\lambda}\\right) = \\frac{x e^{x}}{\\lambda (e^{x} - 1)^2}\n$$\nNow we assemble the stationarity condition:\n$$\nA \\left[ -5\\lambda^{-6} \\left(e^{x} - 1\\right)^{-1} + \\lambda^{-5} \\frac{x e^{x}}{\\lambda (e^{x} - 1)^2} \\right] = 0\n$$\nMultiplying the entire equation by the non-zero factor $\\frac{\\lambda^6 (e^x - 1)^2}{A}$ simplifies the expression:\n$$\n-5(e^x - 1) + \\lambda \\frac{x e^x}{\\lambda} = 0\n$$\n$$\n-5e^x + 5 + x e^x = 0\n$$\nThis can be rewritten into the final form of the transcendental equation we must solve for $x$:\n$$\nf(x) = (x-5)e^x + 5 = 0\n$$\nThe root of this equation, let us call it $x^{\\star}$, determines the relationship between $\\lambda_{\\max}$ and $T$. From the definition of $x$, we have $\\lambda_{\\max} = \\frac{hc}{x^{\\star} k_{\\mathrm{B}} T}$. This is precisely Wien's displacement law, $\\lambda_{\\max}(T) = \\frac{b}{T}$, where the constant $b$ is given by $b = \\frac{hc}{x^{\\star} k_{\\mathrm{B}}}$.\n\nTo find $x^{\\star}$, we first localize the root. Evaluating the function $f(x)$ at simple integer values:\n$f(4) = (4-5)e^4 + 5 = -e^4 + 5 \\approx -54.6 + 5  0$.\n$f(5) = (5-5)e^5 + 5 = 5  0$.\nThe derivative is $f'(x) = e^x + (x-5)e^x = (x-4)e^x$. For $x  4$, $f'(x)  0$, so the function is continuous and strictly increasing on the interval $[4, 5]$. This guarantees a unique root within this interval. We thus select $[x_{\\min}, x_{\\max}] = [4, 5]$ as the approximation domain.\n\nFollowing the problem requirements, we construct a Chebyshev polynomial approximation, $p_n(x)$, for the function $f(x)$ on the interval $[4, 5]$. We choose a degree $n = 20$, which is greater than the required minimum of $n=12$. The approximation is constructed by interpolation. Specifically, we evaluate $f(x)$ at the $N = n+1 = 21$ Chebyshev nodes of the first kind over the interval $[4, 5]$. These nodes $x_k$ are obtained by an affine mapping from the canonical nodes $z_k$ on $[-1, 1]$:\n$$\nz_k = \\cos\\left(\\frac{2k+1}{2N}\\pi\\right), \\quad k = 0, 1, \\dots, n\n$$\n$$\nx_k = \\frac{x_{\\max} - x_{\\min}}{2} z_k + \\frac{x_{\\max} + x_{\\min}}{2} = 0.5 z_k + 4.5\n$$\nThe Chebyshev interpolating polynomial $p_n(x)$ is the unique polynomial of degree at most $n$ that satisfies $p_n(x_k) = f(x_k)$ for all $k=0, \\dots, n$. Modern numerical libraries provide robust routines to compute the coefficients of this polynomial.\nThe approximate root $x^{\\star}$ is then found by solving the polynomial equation $p_n(x) = 0$. This is a standard algebraic procedure. From the resulting roots, we select the one that is real and lies within our chosen interval $[4, 5]$.\n\nWith the high-precision value of $x^{\\star}$ obtained numerically, we calculate Wien's constant:\n$$\nb = \\frac{hc}{x^{\\star} k_{\\mathrm{B}}}\n$$\nusing the 2018 CODATA values for the physical constants $h$, $c$, and $k_{\\mathrm{B}}$. Finally, for each temperature $T$ in the test suite $[\\,2.7255,\\;300.0,\\;1000.0,\\;3000.0,\\;5772.0,\\;10000.0\\,]$, we compute the peak wavelength:\n$$\n\\lambda_{\\max}(T) = \\frac{b}{T}\n$$\nThe implementation will perform these steps computationally.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the peak wavelength of black-body radiation using a Chebyshev approximation.\n\n    The method involves:\n    1. Defining the transcendental equation derived from Planck's law's stationarity condition.\n    2. Constructing a Chebyshev polynomial approximation of the function in this equation.\n    3. Finding the relevant root of the polynomial to approximate the true root x_star.\n    4. Using x_star to compute Wien's displacement constant, b.\n    5. Calculating the peak wavelength lambda_max = b/T for a set of test temperatures.\n    \"\"\"\n\n    # Physical constants (2018 CODATA values, SI units)\n    # h: Planck's constant in J·s\n    # c: Speed of light in vacuum in m/s\n    # k_B: Boltzmann constant in J/K\n    h = 6.62607015e-34\n    c = 299792458.0\n    k_B = 1.380649e-23\n\n    # Test suite temperatures in Kelvin\n    temperatures = np.array([2.7255, 300.0, 1000.0, 3000.0, 5772.0, 10000.0])\n\n    # Transcendental function f(x) = (x-5)exp(x) + 5, whose root we need to find.\n    def f(x):\n        return (x - 5.0) * np.exp(x) + 5.0\n\n    # Step 1: Set up Chebyshev approximation\n    # Degree of the polynomial (n >= 12)\n    degree = 20\n    # Interval [xmin, xmax] known to contain the root\n    xmin, xmax = 4.0, 5.0\n    \n    # Step 2: Construct the Chebyshev polynomial interpolant\n    # We interpolate f(x) at the Chebyshev nodes of the first kind.\n    # We need degree + 1 points to define a polynomial of degree `degree`.\n    num_points = degree + 1\n    \n    # Generate Chebyshev nodes of the first kind in the canonical interval [-1, 1]\n    # These are the roots of the Chebyshev polynomial T_{num_points}(z).\n    z_nodes = np.cos(np.pi * (2 * np.arange(num_points) + 1) / (2 * num_points))\n    \n    # Map nodes to the approximation interval [xmin, xmax]\n    x_nodes = (xmax - xmin) / 2.0 * z_nodes + (xmax + xmin) / 2.0\n    \n    # Evaluate the function at these nodes\n    y_values = f(x_nodes)\n    \n    # Use numpy's Chebyshev.fit to create the polynomial approximation.\n    # The `domain` parameter correctly maps the problem domain to the canonical window [-1, 1].\n    p_cheb = np.polynomial.chebyshev.Chebyshev.fit(x_nodes, y_values, degree, domain=[xmin, xmax])\n\n    # Step 3: Find the approximate root x_star\n    # Find all roots of the polynomial approximation.\n    roots = p_cheb.roots()\n    \n    # Filter the roots to find the unique real root within our interval [xmin, xmax].\n    x_star = None\n    for r in roots:\n        # We are only interested in real roots.\n        if np.isreal(r):\n            real_r = np.real(r)\n            # Check if the root is within the physically meaningful interval.\n            if xmin = real_r = xmax:\n                x_star = real_r\n                break\n    \n    if x_star is None:\n        # This guard is for robustness; with a good approximation, a root must be found.\n        raise RuntimeError(\"Could not find the root in the specified interval.\")\n\n    # Step 4: Compute Wien's displacement constant, b\n    b = (h * c) / (x_star * k_B)\n    \n    # Step 5: Compute lambda_max for each temperature in the test suite\n    results = []\n    for T in temperatures:\n        lambda_max = b / T\n        results.append(lambda_max)\n    \n    # Final print statement in the exact required format.\n    # Format each result to scientific notation with 12 significant digits.\n    # The format code \"{:.11e}\" provides 1 digit before the decimal point and 11 after.\n    formatted_results = [f\"{val:.11e}\" for val in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "In this final practice, we advance from approximating functions to approximating the solutions of differential equations—a cornerstone of computational physics. Using a technique known as a spectral collocation method, we will represent the unknown solution to a boundary value problem as a Chebyshev series . The problem further introduces domain decomposition, a powerful strategy for handling complex geometries or functions, by splitting the domain and enforcing continuity at the interface. This exercise provides a hands-on introduction to the elegance and power of spectral methods in solving differential equations with high accuracy.",
            "id": "2379161",
            "problem": "Consider the boundary value problem for the scalar field $u(x)$ on the interval $[-2,2]$ defined by the second-order ordinary differential equation $u''(x)=f(x)$ with boundary conditions $u(-2)=\\alpha$ and $u(2)=\\beta$. Let the computational domain be decomposed into the two non-overlapping subintervals $[-2,0]$ and $[0,2]$. On each subinterval, the unknown field is represented by a polynomial of degree at most $n$; denote these by $p_{-}(x)$ on $[-2,0]$ and $p_{+}(x)$ on $[0,2]$. The following discrete conditions must hold:\n\n- On each subinterval $[a,b]$, define the Chebyshev–Gauss–Lobatto nodes $t_j=\\cos\\left(\\dfrac{\\pi j}{n}\\right)$ for $j=0,1,\\dots,n$ on $[-1,1]$ and map them affinely to $x$-nodes $x_j=\\dfrac{a+b}{2}+\\dfrac{b-a}{2}\\,t_j$. For every interior node on each subinterval (that is, all $x_j$ with $j=1,2,\\dots,n-1$), the strong-form residual must vanish: $p_{\\pm}''(x_j)=f(x_j)$.\n- The boundary conditions must hold at the physical endpoints: $p_{-}(-2)=\\alpha$ and $p_{+}(2)=\\beta$.\n- Across the interface at $x=0$, impose continuity of both the field and its first derivative: $p_{-}(0)=p_{+}(0)$ and $p_{-}'(0)=p_{+}'(0)$.\n\nFor each test case below, there is a unique exact solution $u_{\\text{exact}}(x)$ determined by the given $f(x)$, $\\alpha$, and $\\beta$. For a given degree $n$, determine the pair of polynomials $(p_{-},p_{+})$ that satisfy all the above discrete conditions, and then evaluate the maximum absolute error\n$$\nE=\\max_{x\\in\\mathcal{G}}\\left|p(x)-u_{\\text{exact}}(x)\\right|,\n$$\nwhere $p(x)=p_{-}(x)$ for $x\\in[-2,0)$, $p(x)=p_{+}(x)$ for $x\\in(0,2]$, and at $x=0$ use either side (the conditions enforce equality). The evaluation grid $\\mathcal{G}$ is the set of $1001$ equally spaced points on $[-2,2]$. The output for each test case must be a real number equal to $E$, rounded to eight decimal places.\n\nTest suite (each test is specified by $(f,\\alpha,\\beta,n)$ together with the corresponding exact solution $u_{\\text{exact}}$):\n\n- Test $1$: $f(x)=1$, $\\alpha=0$, $\\beta=0$, $n=10$. The exact solution is $u_{\\text{exact}}(x)=\\dfrac{1}{2}x^{2}-2$.\n- Test $2$: $f(x)=\\sin(\\pi x)$, $\\alpha=0$, $\\beta=0$, $n=12$. The exact solution is $u_{\\text{exact}}(x)=-\\dfrac{\\sin(\\pi x)}{\\pi^{2}}$.\n- Test $3$: $f(x)=e^{x}$, $\\alpha=e^{-2}$, $\\beta=e^{2}$, $n=14$. The exact solution is $u_{\\text{exact}}(x)=e^{x}$.\n- Test $4$: $f(x)=\\begin{cases}-1,  x0\\\\0,  x=0\\\\1,  x0\\end{cases}$, $\\alpha=0$, $\\beta=0$, $n=24$. The exact solution is\n$$\nu_{\\text{exact}}(x)=\n\\begin{cases}\n-\\dfrac{1}{2}x^{2}-x,  x\\le 0 \\\\\n\\\\\n\\dfrac{1}{2}x^{2}-x,  x\\ge 0\n\\end{cases}\n$$\n\nYour program should produce a single line of output containing the four errors for Tests $1$ through $4$ as a comma-separated list enclosed in square brackets, in the order given above, for example, $\\left[\\text{result}_{1},\\text{result}_{2},\\text{result}_{3},\\text{result}_{4}\\right]$, with each $\\text{result}_{k}$ rounded to eight decimal places.",
            "solution": "The problem presented is a second-order ordinary differential equation (ODE) in the form of a two-point boundary value problem, which is to be solved using a multi-domain spectral collocation method.\n\n### Step 1: Extract Givens\n- **Differential Equation:** $u''(x) = f(x)$ on the interval $[-2, 2]$.\n- **Boundary Conditions:** $u(-2) = \\alpha$, $u(2) = \\beta$.\n- **Domain Decomposition:** The domain is split into two non-overlapping subintervals: $I_{-} = [-2, 0]$ and $I_{+} = [0, 2]$.\n- **Solution Ansatz:** The solution $u(x)$ is approximated by a pair of polynomials, $p_{-}(x)$ on $I_{-}$ and $p_{+}(x)$ on $I_{+}$, each of degree at most $n$.\n- **Collocation Conditions:**\n    1.  The ODE must be satisfied at the interior Chebyshev-Gauss-Lobatto (CGL) nodes on each subinterval. The CGL nodes on $[-1, 1]$ are $t_j = \\cos(\\frac{\\pi j}{n})$ for $j = 0, \\dots, n$. These are mapped to $x_j = \\frac{a+b}{2} + \\frac{b-a}{2} t_j$ for an interval $[a, b]$. The condition is $p_{\\pm}''(x_j) = f(x_j)$ for $j = 1, \\dots, n-1$.\n    2.  The physical boundary conditions must be satisfied: $p_{-}(-2) = \\alpha$ and $p_{+}(2) = \\beta$.\n    3.  Continuity conditions are imposed at the interface $x=0$: $p_{-}(0) = p_{+}(0)$ and $p_{-}'(0) = p_{+}'(0)$.\n- **Error Evaluation:** The maximum absolute error $E = \\max_{x\\in\\mathcal{G}}\\left|p(x)-u_{\\text{exact}}(x)\\right|$ is to be computed on a grid $\\mathcal{G}$ of $1001$ equispaced points on $[-2, 2]$.\n- **Test Cases:** Four test cases are provided, specifying $f(x)$, $\\alpha$, $\\beta$, $n$, and the exact solution $u_{\\text{exact}}(x)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a standard application of spectral methods, specifically a domain decomposition technique (spectral multi-domain method), to solve a linear second-order ODE.\n- **Scientifically Grounded:** The method is well-established in numerical analysis and computational science. All principles are based on standard calculus and linear algebra. The provided exact solutions for all test cases correctly satisfy the given ODE and boundary conditions. The problem is factually sound.\n- **Well-Posed:** The problem specifies $2(n+1)$ constraints for the $2(n+1)$ degrees of freedom (coefficients) of the two polynomials. The number of equations matches the number of unknowns. This setup for a spectral collocation method typically leads to a non-singular linear system, ensuring a unique solution exists. The problem is well-posed.\n- **Objective:** The problem is formulated with precise mathematical language, free from ambiguity or subjective claims.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is self-contained, scientifically sound, well-posed, and objective. A solution will be constructed.\n\n### Solution Derivation\nThe problem will be solved by constructing and solving a system of linear equations for the values of the polynomials $p_{-}(x)$ and $p_{+}(x)$ at the CGL nodes within their respective subdomains.\n\n**1. Discretization and Nodal Representation**\nLet the canonical CGL nodes on $[-1, 1]$ be $t_j = \\cos(\\frac{\\pi j}{n})$ for $j=0, \\dots, n$. These nodes are ordered from $1$ down to $-1$.\n\nFor the subdomain $I_{-} = [-2, 0]$, the affine mapping is $x = -1 + t$. The nodes are $x_j^{-} = -1 + t_j$. Note that $x_0^{-} = 0$ and $x_n^{-} = -2$.\nFor the subdomain $I_{+} = [0, 2]$, the affine mapping is $x = 1 + t$. The nodes are $x_j^{+} = 1 + t_j$. Note that $x_0^{+} = 2$ and $x_n^{+} = 0$.\n\nThe unknown solution is represented by two vectors of its values at these nodes:\n- $\\vec{u}_{-} = [p_{-}(x_0^{-}), \\dots, p_{-}(x_n^{-})]^T$\n- $\\vec{u}_{+} = [p_{+}(x_0^{+}), \\dots, p_{+}(x_n^{+})]^T$\n\nThe total number of unknowns is $2(n+1)$.\n\n**2. Chebyshev Differentiation Matrices**\nThe derivatives of a polynomial represented by its values at CGL nodes can be found by multiplying its vector of nodal values by a differentiation matrix. Let $D_n$ be the first-order Chebyshev differentiation matrix for nodes $t_j$ on $[-1,1]$. The second-order differentiation matrix is $D_n^{(2)} = (D_n)^2$.\n\nFor a function $g(x)$ defined on $[a, b]$, its derivatives with respect to $x$ are related to the derivatives with respect to the canonical variable $t \\in [-1, 1]$ by the chain rule:\n$\\frac{d}{dx} = \\frac{2}{b-a} \\frac{d}{dt}$ and $\\frac{d^2}{dx^2} = \\left(\\frac{2}{b-a}\\right)^2 \\frac{d^2}{dt^2}$.\nFor both subdomains, $[-2, 0]$ and $[0, 2]$, the length is $b-a = 2$. The scaling factor $\\frac{2}{b-a}$ is $1$. Thus, the differentiation matrices for both subdomains are simply $D_n$ and $D_n^{(2)}$.\n\n**3. Assembling the Linear System**\nWe establish a linear system of $2(n+1)$ equations for the $2(n+1)$ unknowns in the combined vector $\\mathbf{U} = [\\vec{u}_{-}^T, \\vec{u}_{+}^T]^T$.\n\nThe equations are as follows:\n- **ODE on $I_{-}$:** For the $n-1$ interior nodes ($j=1, \\dots, n-1$), the ODE must hold:\n  $$ (D_n^{(2)} \\vec{u}_{-})_j = f(x_j^{-}) $$\n  This constitutes $n-1$ linear equations involving only the elements of $\\vec{u}_{-}$.\n\n- **ODE on $I_{+}$:** Similarly, for the $n-1$ interior nodes on the right subdomain:\n  $$ (D_n^{(2)} \\vec{u}_{+})_j = f(x_j^{+}) $$\n  This gives another $n-1$ equations involving only the elements of $\\vec{u}_{+}$.\n\n- **Physical Boundary Conditions:**\n  - At $x=-2$: This is node $x_n^{-}$ on the left subdomain. The condition $p_{-}(-2) = \\alpha$ becomes:\n    $$ u_{-}^{(n)} = \\alpha $$\n  - At $x=2$: This is node $x_0^{+}$ on the right subdomain. The condition $p_{+}(2) = \\beta$ becomes:\n    $$ u_{+}^{(0)} = \\beta $$\n\n- **Interface Conditions at $x=0$:**\n  - The point $x=0$ corresponds to node $x_0^{-}$ on the left and $x_n^{+}$ on the right.\n  - Continuity of the field, $p_{-}(0) = p_{+}(0)$, implies:\n    $$ u_{-}^{(0)} = u_{+}^{(n)} $$\n  - Continuity of the first derivative, $p_{-}'(0) = p_{+}'(0)$, is expressed using the first-order differentiation matrix $D_n$:\n    $$ (D_n \\vec{u}_{-})_0 = (D_n \\vec{u}_{+})_n $$\n    This expands to:\n    $$ \\sum_{k=0}^{n} (D_n)_{0k} u_{-}^{(k)} = \\sum_{k=0}^{n} (D_n)_{nk} u_{+}^{(k)} $$\n\nThese $2(n-1) + 2 + 2 = 2(n+1)$ equations form a linear system $A\\mathbf{U} = \\mathbf{B}$, which can be solved for the unknown vector $\\mathbf{U}$.\n\n**4. Interpolation and Error Calculation**\nOnce the nodal values $\\vec{u}_{-}$ and $\\vec{u}_{+}$ are found, the solution can be evaluated at any point within each subdomain using barycentric Lagrange interpolation, which is numerically stable and efficient for Chebyshev nodes.\n\nFor a set of evaluation points $\\xi$ in the canonical interval $[-1, 1]$, the interpolated values are given by:\n$$ P(\\xi) = \\frac{\\sum_{j=0}^{n} \\frac{w_j}{\\xi - t_j} v_j}{\\sum_{j=0}^{n} \\frac{w_j}{\\xi - t_j}} $$\nwhere $v_j$ are the function values at the nodes $t_j = \\cos(\\frac{\\pi j}{n})$, and the barycentric weights are $w_j = (-1)^j \\delta_j$, with $\\delta_0 = \\delta_n = 1/2$ and $\\delta_j = 1$ for $j=1, \\dots, n-1$.\n\nTo evaluate the numerical solution $p(x)$ on the fine grid $\\mathcal{G}$, points in $[-2, 0]$ are mapped to $[-1, 1]$ via $t = x+1$ and interpolated using $\\vec{u}_{-}$. Points in $(0, 2]$ are mapped via $t = x-1$ and interpolated using $\\vec{u}_{+}$. The maximum absolute difference between the interpolated solution $p(x)$ and the exact solution $u_{\\text{exact}}(x)$ over the grid $\\mathcalG$ gives the error $E$.",
            "answer": "```python\nimport numpy as np\n\ndef chebyshev_diff_matrix(n):\n    \"\"\"\n    Constructs the Chebyshev differentiation matrix for n+1 CGL nodes.\n    \"\"\"\n    if n == 0:\n        return np.zeros((1, 1))\n    \n    t = np.cos(np.pi * np.arange(n + 1) / n)\n    t = t.reshape(-1, 1)\n    \n    # Off-diagonal entries\n    c = np.ones(n + 1)\n    c[0] = 2.0\n    c[n] = 2.0\n    c_inv = 1.0 / c\n    \n    d_matrix = c[:, None] * c_inv[None, :] * (-1.0)**(np.arange(n + 1)[:, None] + np.arange(n + 1)[None, :])\n    \n    t_diff = t - t.T\n    np.fill_diagonal(t_diff, 1.0) # Avoid division by zero\n    \n    d_matrix /= t_diff\n    np.fill_diagonal(d_matrix, 0.0)\n    \n    # Diagonal entries\n    row_sums = np.sum(d_matrix, axis=1)\n    np.fill_diagonal(d_matrix, -row_sums)\n    \n    return d_matrix\n\ndef barycentric_interpolate(eval_pts, node_pts, node_vals):\n    \"\"\"\n    Performs barycentric Lagrange interpolation on Chebyshev nodes.\n    \n    eval_pts: Points to evaluate the interpolant at (in [-1, 1]).\n    node_pts: Chebyshev nodes t_j (in [-1, 1]).\n    node_vals: Function values at the nodes.\n    \"\"\"\n    n = len(node_pts) - 1\n    \n    # Barycentric weights for CGL nodes\n    weights = (-1.0)**np.arange(n + 1)\n    weights[0] *= 0.5\n    weights[n] *= 0.5\n    \n    numer = np.zeros_like(eval_pts, dtype=float)\n    denom = np.zeros_like(eval_pts, dtype=float)\n    interpolated_vals = np.full_like(eval_pts, np.nan, dtype=float)\n    \n    for j in range(n + 1):\n        # Find points that are very close to a node to avoid division by zero\n        is_node = np.isclose(eval_pts, node_pts[j])\n        interpolated_vals[is_node] = node_vals[j]\n        \n        not_node = ~is_node\n        if np.any(not_node):\n            term = weights[j] / (eval_pts[not_node] - node_pts[j])\n            numer[not_node] += term * node_vals[j]\n            denom[not_node] += term\n\n    valid_mask = np.isnan(interpolated_vals)\n    # Avoid division by zero in denom\n    denom_is_zero = np.isclose(denom, 0.0)\n    if np.any(denom_is_zero  valid_mask):\n         # This can happen if eval_pts is a node, handled above.\n         # Or if weights and points conspire to cancel, should be rare.\n         interpolated_vals[denom_is_zero  valid_mask] = 0.0\n\n    safe_denom_mask = ~denom_is_zero  valid_mask\n    interpolated_vals[safe_denom_mask] = numer[safe_denom_mask] / denom[safe_denom_mask]\n    \n    return interpolated_vals\n\ndef solve():\n    test_cases = [\n        {\n            \"f\": lambda x: 1.0, \"alpha\": 0.0, \"beta\": 0.0, \"n\": 10,\n            \"u_exact\": lambda x: 0.5 * x**2 - 2.0\n        },\n        {\n            \"f\": lambda x: np.sin(np.pi * x), \"alpha\": 0.0, \"beta\": 0.0, \"n\": 12,\n            \"u_exact\": lambda x: -np.sin(np.pi * x) / np.pi**2\n        },\n        {\n            \"f\": lambda x: np.exp(x), \"alpha\": np.exp(-2.0), \"beta\": np.exp(2.0), \"n\": 14,\n            \"u_exact\": lambda x: np.exp(x)\n        },\n        {\n            \"f\": lambda x: np.sign(x), \"alpha\": 0.0, \"beta\": 0.0, \"n\": 24,\n            \"u_exact\": lambda x: np.piecewise(x, [x = 0, x  0],\n                                             [lambda y: -0.5 * y**2 - y,\n                                              lambda y: 0.5 * y**2 - y])\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        n = case[\"n\"]\n        f = case[\"f\"]\n        alpha = case[\"alpha\"]\n        beta = case[\"beta\"]\n        u_exact = case[\"u_exact\"]\n        \n        N = n + 1\n        \n        # Differentiation matrices\n        D1 = chebyshev_diff_matrix(n)\n        D2 = D1 @ D1\n        \n        # CGL nodes\n        t_nodes = np.cos(np.pi * np.arange(N) / n)\n        \n        # Mapped nodes for subdomains\n        x_minus = -1.0 + t_nodes  # on [-2, 0], x_0 = 0, x_n = -2\n        x_plus = 1.0 + t_nodes   # on [0, 2],  x_0 = 2,  x_n = 0\n        \n        # System matrix A and RHS vector B\n        A = np.zeros((2*N, 2*N))\n        B = np.zeros(2*N)\n        \n        row = 0\n        # Collocation on [-2, 0]\n        for j in range(1, n):\n            A[row, 0:N] = D2[j, :]\n            B[row] = f(x_minus[j])\n            row += 1\n            \n        # Collocation on [0, 2]\n        for j in range(1, n):\n            A[row, N:2*N] = D2[j, :]\n            B[row] = f(x_plus[j])\n            row += 1\n            \n        # BC: p_(-2) = alpha\n        A[row, n] = 1.0\n        B[row] = alpha\n        row += 1\n        \n        # BC: p_(2) = beta\n        A[row, N] = 1.0 # u_plus[0]\n        B[row] = beta\n        row += 1\n        \n        # Continuity: p_-(0) = p_+(0)\n        A[row, 0] = 1.0   # u_minus[0]\n        A[row, 2*N-1] = -1.0 # u_plus[n]\n        B[row] = 0.0\n        row += 1\n        \n        # Derivative continuity: p_-'(0) = p_+'(0)\n        A[row, 0:N] = D1[0, :]\n        A[row, N:2*N] = -D1[n, :]\n        B[row] = 0.0\n        \n        # Solve the system\n        U = np.linalg.solve(A, B)\n        u_minus = U[:N]\n        u_plus = U[N:]\n        \n        # Error evaluation\n        eval_grid = np.linspace(-2.0, 2.0, 1001)\n        grid_minus = eval_grid[eval_grid = 0]\n        grid_plus = eval_grid[eval_grid  0]\n        \n        # Map evaluation grid to canonical interval [-1, 1]\n        eval_t_minus = grid_minus + 1.0\n        eval_t_plus = grid_plus - 1.0\n        \n        p_vals_minus = barycentric_interpolate(eval_t_minus, t_nodes, u_minus)\n        p_vals_plus = barycentric_interpolate(eval_t_plus, t_nodes, u_plus)\n        \n        p_vals = np.concatenate((p_vals_minus, p_vals_plus))\n        \n        u_exact_vals = u_exact(eval_grid)\n        \n        error = np.max(np.abs(p_vals - u_exact_vals))\n        results.append(f\"{error:.8f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}