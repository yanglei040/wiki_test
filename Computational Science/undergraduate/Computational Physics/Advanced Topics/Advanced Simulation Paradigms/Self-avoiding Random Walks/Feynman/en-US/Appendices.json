{
    "hands_on_practices": [
        {
            "introduction": "The most direct way to study self-avoiding walks is to generate every possible configuration. In this practice , you will implement an exact enumeration algorithm using recursive backtracking to compute the average \"span\" for short walks. This exercise provides a solid foundation and introduces the crucial concept of scaling, which governs how a polymer's size grows with its length $N$.",
            "id": "2436367",
            "problem": "You are asked to study the span of a Self-Avoiding Walk (SAW) on a two-dimensional square lattice in a way that is precise, reproducible, and testable. A Self-Avoiding Walk is a sequence of lattice sites in which each step moves by one unit to one of the four nearest neighbors and no site is visited more than once. Consider walks that start at the origin $(0,0)$, have exactly $N$ unit steps, and lie on the infinite square lattice.\n\nFor a walk of length $N$, denote the visited positions by $\\{(x_i,y_i)\\}_{i=0}^{N}$ with $(x_0,y_0)=(0,0)$ and $\\|(x_{i+1},y_{i+1})-(x_i,y_i)\\|_1=1$ for all $i$, and $(x_i,y_i)\\neq(x_j,y_j)$ whenever $i\\neq j$. Define the span in the $x$-direction by\n$$\nS_N=\\max_{0\\le i\\le N} x_i - \\min_{0\\le i\\le N} x_i.\n$$\nLet $\\langle S_N\\rangle$ denote the arithmetic mean of $S_N$ taken over all self-avoiding walks of length $N$ that start at the origin, with each walk assigned equal weight.\n\nTasks:\n1. For each specified value of $N$, compute the exact value of $\\langle S_N\\rangle$.\n2. Using two specified values $N_1$ and $N_2$ with $N_2&gt;N_1\\ge 1$, compute the scaling exponent estimate $\\nu$ defined by the pairwise log-slope\n$$\n\\nu=\\frac{\\log\\big(\\langle S_{N_2}\\rangle/\\langle S_{N_1}\\rangle\\big)}{\\log\\big(N_2/N_1\\big)}.\n$$\n\nTest suite:\n- Case $1$: $N=0$.\n- Case $2$: $N=1$.\n- Case $3$: $N=2$.\n- Case $4$: $N=5$.\n- Case $5$: $N=8$.\n- Case $6$: $N=10$.\n- Case $7$: $(N_1,N_2)=(4,10)$, for which the program must compute $\\nu$ using the definition above.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order and formatting:\n- $[\\langle S_0\\rangle,\\langle S_1\\rangle,\\langle S_2\\rangle,\\langle S_5\\rangle,\\langle S_8\\rangle,\\langle S_{10}\\rangle,\\nu]$,\n- each number must be rounded to exactly six digits after the decimal point,\n- no spaces are permitted in the output line.\n\nNo physical units are involved. Angles are not used. Percentages are not used. All quantities are pure numbers. The expected answers for each case are real numbers (floats) as defined above.",
            "solution": "The problem statement has been rigorously validated. It is scientifically sound, well-posed, and unambiguous, representing a standard computational exercise in the study of self-avoiding walks. A solution can therefore be derived. The task is to compute the mean span $\\langle S_N \\rangle$ for a Self-Avoiding Walk (SAW) of $N$ steps on a two-dimensional square lattice, and a related scaling exponent $\\nu$.\n\n**1. Theoretical Framework**\n\nA Self-Avoiding Walk of length $N$ is a sequence of $N+1$ distinct lattice sites $p_0, p_1, \\ldots, p_N$, where $p_0$ is the origin $(0,0)$ and each subsequent site $p_{i+1}$ is a nearest neighbor of $p_i$. The distance between adjacent sites satisfies $\\|p_{i+1} - p_i\\|_1 = 1$. The span of a walk in the $x$-direction is defined as $S_N = \\max_{i} x_i - \\min_{i} x_i$, where $p_i = (x_i, y_i)$.\n\nThe quantity of interest, $\\langle S_N \\rangle$, is the arithmetic mean of $S_N$ over the entire ensemble of unique SAWs of length $N$, where each walk is given equal probability.\n$$\n\\langle S_N \\rangle = \\frac{1}{C_N} \\sum_{w \\in \\mathcal{W}_N} S_N(w)\n$$\nHere, $\\mathcal{W}_N$ is the set of all SAWs of length $N$, and $C_N = |\\mathcal{W}_N|$ is the total number of such walks.\n\nFor small $N$, an exact enumeration of all possible walks is computationally feasible. This is the method we shall employ.\n\n**2. Algorithmic Approach: Recursive Backtracking**\n\nWe will generate all SAWs of a given length $N$ using a recursive backtracking (depth-first search) algorithm.\nThe state of the recursion is defined by the current position, the number of steps taken, and the set of visited sites.\n\nThe algorithm proceeds as follows:\n- Start at the origin $p_0 = (0,0)$ with a path containing only this point.\n- Recursively extend the walk by one step. From the current position $p_i$, attempt to move to each of the four nearest neighbors.\n- A move to a new site $p_{i+1}$ is valid only if $p_{i+1}$ has not been previously visited.\n- If a move is valid, add the new site to the path and recurse. After the recursive call returns, backtrack by removing the site from the path to explore other possibilities.\n- The recursion terminates when the walk reaches the desired length of $N$ steps (i.e., the path contains $N+1$ sites).\n\n**3. Optimization using Lattice Symmetry**\n\nThe computational effort can be reduced by a factor of approximately $4$ by exploiting the symmetries of the square lattice. The set of all SAWs is invariant under rotations by $90^\\circ$, $180^\\circ$, $270^\\circ$, and reflections.\n\nInstead of generating all walks, we only generate the subset of walks, denoted $\\mathcal{W}_R$, where the first step is fixed to a specific direction, for instance, to the right, to position $(1,0)$. For any walk $w \\in \\mathcal{W}_R$, we can generate three other distinct walks by rotating it by $90^\\circ$, $180^\\circ$, and $270^\\circ$. These correspond to walks starting with steps up, left, and down, respectively.\n\nLet $w_R$ be a walk in $\\mathcal{W}_R$. Its coordinates are $\\{(x_i, y_i)\\}$.\n- The reflection across the $y$-axis gives a walk $w_L \\in \\mathcal{W}_L$ with coordinates $\\{(-x_i, y_i)\\}$. Its x-span is $S_x(w_L) = \\max(-x_i) - \\min(-x_i) = \\max(x_i) - \\min(x_i) = S_x(w_R)$.\n- The $90^\\circ$ counter-clockwise rotation gives a walk $w_U \\in \\mathcal{W}_U$ with coordinates $\\{(-y_i, x_i)\\}$. Its x-span is $S_x(w_U) = \\max(-y_i) - \\min(-y_i) = \\max(y_i) - \\min(y_i) = S_y(w_R)$, the y-span of the original walk.\n- Similarly, for a walk $w_D \\in \\mathcal{W}_D$, $S_x(w_D) = S_y(w_R)$.\n\nThe total sum of x-spans over all walks is:\n$$\n\\sum_{w \\in \\mathcal{W}_N} S_x(w) = \\sum_{w \\in \\mathcal{W}_R} S_x(w) + \\sum_{w \\in \\mathcal{W}_L} S_x(w) + \\sum_{w \\in \\mathcal{W}_U} S_x(w) + \\sum_{w \\in \\mathcal{W}_D} S_x(w)\n$$\n$$\n\\sum_{w \\in \\mathcal{W}_N} S_x(w) = 2 \\sum_{w \\in \\mathcal{W}_R} S_x(w) + 2 \\sum_{w \\in \\mathcal{W}_R} S_y(w)\n$$\nThe total number of walks is $C_N = 4 |\\mathcal{W}_R|$ for $N \\ge 1$.\nTherefore, the average span is:\n$$\n\\langle S_N \\rangle = \\frac{2 \\sum_{w \\in \\mathcal{W}_R} (S_x(w) + S_y(w))}{4 |\\mathcal{W}_R|} = \\frac{1}{2 |\\mathcal{W}_R|} \\sum_{w \\in \\mathcal{W}_R} (S_x(w) + S_y(w))\n$$\nThis optimized formula requires enumerating only the walks in $\\mathcal{W}_R$, calculating both their x- and y-spans, and combining the results. This is the procedure implemented. Trivial cases for $N=0$ and $N=1$ are handled directly:\n- For $N=0$, there is one walk, $\\{(0,0)\\}$. $S_0=0-0=0$. So $\\langle S_0 \\rangle = 0$.\n- For $N=1$, there are four walks. Two have $S_1=1$ (steps along x-axis) and two have $S_1=0$ (steps along y-axis). $\\langle S_1 \\rangle = (1+1+0+0)/4 = 0.5$.\n\n**4. Calculation of the Scaling Exponent**\n\nThe problem requires computing an estimate for the scaling exponent $\\nu$ using two pairs of data $(N_1, \\langle S_{N_1} \\rangle)$ and $(N_2, \\langle S_{N_2} \\rangle)$. This relationship is based on the expected power-law scaling for large $N$, $\\langle S_N \\rangle \\sim N^\\nu$. The exponent $\\nu$ is estimated using the pairwise log-slope formula:\n$$\n\\nu=\\frac{\\log\\big(\\langle S_{N_2}\\rangle/\\langle S_{N_1}\\rangle\\big)}{\\log\\big(N_2/N_1\\big)}\n$$\nFor this problem, we use $(N_1, N_2) = (4, 10)$. This requires the computation of $\\langle S_4 \\rangle$ and $\\langle S_{10} \\rangle$.\n\n**5. Implementation Plan**\n\nA Python class will encapsulate the logic. A recursive method will perform the optimized walk generation. To ensure the self-avoiding condition is met efficiently, a `set` of tuples will store the visited coordinates for $O(1)$ average time complexity lookups. The program will calculate $\\langle S_N \\rangle$ for $N \\in \\{0, 1, 2, 4, 5, 8, 10\\}$, then compute $\\nu$ using the values for $N=4$ and $N=10$, and finally format the results as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass SawEnumerator:\n    \"\"\"\n    A class to enumerate Self-Avoiding Walks (SAWs) on a 2D square lattice\n    and calculate the average span. It uses a recursive backtracking algorithm\n    optimized with lattice symmetries.\n    \"\"\"\n    def __init__(self):\n        self.total_x_span_sum = 0.0\n        self.total_y_span_sum = 0.0\n        self.walk_count_one_dir = 0\n\n    def _walk_recursive(self, current_steps, max_steps, pos, path_set, path_list):\n        \"\"\"\n        Recursively generates SAWs from a given state.\n\n        Args:\n            current_steps (int): The number of steps already taken.\n            max_steps (int): The target number of steps for the walk.\n            pos (tuple): The current (x, y) position of the walk.\n            path_set (set): A set of visited coordinates for fast lookups.\n            path_list (list): The ordered list of coordinates in the path.\n        \"\"\"\n        if current_steps == max_steps:\n            self.walk_count_one_dir += 1\n            x_coords = [p[0] for p in path_list]\n            y_coords = [p[1] for p in path_list]\n            self.total_x_span_sum += max(x_coords) - min(x_coords)\n            self.total_y_span_sum += max(y_coords) - min(y_coords)\n            return\n\n        x, y = pos\n        # Possible moves to nearest neighbors\n        moves = [(x + 1, y), (x - 1, y), (x, y + 1), (x, y - 1)]\n\n        for next_pos in moves:\n            if next_pos not in path_set:\n                # Explore this valid move\n                path_set.add(next_pos)\n                path_list.append(next_pos)\n                self._walk_recursive(current_steps + 1, max_steps, next_pos, path_set, path_list)\n                # Backtrack to explore other branches\n                path_list.pop()\n                path_set.remove(next_pos)\n\n    def calculate_avg_span(self, N):\n        \"\"\"\n        Calculates the average x-span for all SAWs of length N.\n\n        Args:\n            N (int): The number of steps in the SAW.\n\n        Returns:\n            float: The average span <S_N>.\n        \"\"\"\n        if N == 0:\n            # The only walk is a single point at the origin. Span is 0.\n            return 0.0\n        \n        if N == 1:\n            # Four walks: (0,0)->(1,0), (0,0)->(-1,0), (0,0)->(0,1), (0,0)->(0,-1).\n            # Spans are 1, 1, 0, 0. Average is 2/4 = 0.5.\n            return 0.5\n\n        # Reset counters for a new calculation\n        self.total_x_span_sum = 0.0\n        self.total_y_span_sum = 0.0\n        self.walk_count_one_dir = 0\n\n        # Optimization: only generate walks starting with a step to the right (1,0).\n        start_pos = (0, 0)\n        first_step_pos = (1, 0)\n        \n        path_set = {start_pos, first_step_pos}\n        path_list = [start_pos, first_step_pos]\n        \n        # We have taken 1 step, so N-1 steps remain. The recursion explores these.\n        self._walk_recursive(1, N, first_step_pos, path_set, path_list)\n\n        # Using symmetry to find total span and total walks from the partial calculation.\n        # Walks starting right/left contribute proportionally to total_x_span_sum.\n        # Walks starting up/down contribute proportionally to total_y_span_sum.\n        total_span = 2 * self.total_x_span_sum + 2 * self.total_y_span_sum\n        total_walks = 4 * self.walk_count_one_dir\n\n        if total_walks == 0:\n            # This case should not be reached for N >= 1\n            return 0.0\n\n        return total_span / total_walks\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem as specified.\n    Calculates average spans and the scaling exponent nu for the given test cases.\n    \"\"\"\n    # The set of N values for which <S_N> must be calculated.\n    test_cases_N = [0, 1, 2, 5, 8, 10]\n    \n    # Parameters for the nu calculation\n    N1, N2 = 4, 10\n    \n    calculator = SawEnumerator()\n    \n    # Store calculated <S_N> values in a dictionary.\n    s_N_values = {}\n    \n    # Determine all unique N values needed for all tasks.\n    all_N_needed = sorted(list(set(test_cases_N + [N1, N2])))\n    \n    for N in all_N_needed:\n        s_N_values[N] = calculator.calculate_avg_span(N)\n        \n    s0 = s_N_values[0]\n    s1 = s_N_values[1]\n    s2 = s_N_values[2]\n    s4 = s_N_values[4]\n    s5 = s_N_values[5]\n    s8 = s_N_values[8]\n    s10 = s_N_values[10]\n\n    # Compute the scaling exponent nu using the specified formula.\n    nu = np.log(s10 / s4) / np.log(N2 / N1)\n    \n    # Assemble the final list of results in the required order.\n    results = [s0, s1, s2, s5, s8, s10, nu]\n    \n    # Format the output string to exactly match the problem specification:\n    # six decimal places, comma-separated, no spaces, enclosed in brackets.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Exact enumeration is limited to short walks, as the number of configurations $c_n$ grows exponentially. To analyze long, realistic polymer chains, we need more sophisticated Monte Carlo methods. This exercise  introduces the Rosenbluth-Rosenbluth algorithm, a classic importance sampling technique, which you will use to estimate the connective constant $\\mu$ that defines this exponential growth.",
            "id": "2436407",
            "problem": "Build a complete, runnable program that estimates the connective constant $\\mu$ for two planar lattices by statistically sampling self-avoiding walks and aggregating the results for a predetermined test suite. A self-avoiding walk of length $n$ on a lattice is a sequence of lattice sites $(\\mathbf{x}_0,\\mathbf{x}_1,\\dots,\\mathbf{x}_n)$ such that $\\mathbf{x}_0=(0,0)$, each step is to a nearest neighbor, and all sites are distinct. For a given lattice $\\mathcal{L}$, let $c_n(\\mathcal{L})$ denote the number of self-avoiding walks of length $n$ starting at the origin, and define the connective constant by\n$$\n\\mu(\\mathcal{L})=\\lim_{n\\to\\infty} \\big(c_n(\\mathcal{L})\\big)^{1/n}.\n$$\nTwo infinite lattices in two dimensions are to be used:\n- The square lattice $\\mathsf{SQ}$ with nearest-neighbor set from $\\mathbf{x}=(i,j)\\in\\mathbb{Z}^2$ given by $\\{(i\\pm 1,j),(i,j\\pm 1)\\}$.\n- The honeycomb lattice $\\mathsf{HC}$ represented on $\\mathbb{Z}^2$ as a $3$-regular graph defined by parity: from $\\mathbf{x}=(i,j)$, if $i+j$ is even then the neighbors are $\\{(i+1,j),(i-1,j),(i,j+1)\\}$; if $i+j$ is odd then the neighbors are $\\{(i+1,j),(i-1,j),(i,j-1)\\}$. This embedding yields the connectivity of the planar honeycomb lattice.\n\nFor a given lattice $\\mathcal{L}$ and walk length $n$, your program must produce an estimate $\\widehat{\\mu}_n(\\mathcal{L})$ constructed from a Monte Carlo estimate $\\widehat{c}_n(\\mathcal{L})$ of $c_n(\\mathcal{L})$ via\n$$\n\\widehat{\\mu}_n(\\mathcal{L})=\\big(\\widehat{c}_n(\\mathcal{L})\\big)^{1/n}.\n$$\nThe estimate $\\widehat{c}_n(\\mathcal{L})$ must be obtained from $M$ independent random trials driven by a pseudorandom number generator initialized by the specified integer seed $s$. There are no physical units in this problem. Angles are not used. All outputs must be real numbers.\n\nTest Suite:\nProvide results for the following ordered list of parameter tuples $(\\mathcal{L},n,M,s)$:\n- Test $1$: $(\\mathsf{HC},\\, n=20,\\, M=20000,\\, s=12345)$.\n- Test $2$: $(\\mathsf{SQ},\\, n=20,\\, M=20000,\\, s=12345)$.\n- Test $3$: $(\\mathsf{HC},\\, n=40,\\, M=10000,\\, s=2023)$.\n- Test $4$: $(\\mathsf{SQ},\\, n=40,\\, M=10000,\\, s=2023)$.\n- Test $5$: $(\\mathsf{HC},\\, n=1,\\, M=50000,\\, s=7)$.\n- Test $6$: $(\\mathsf{SQ},\\, n=2,\\, M=50000,\\, s=11)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the tests above. Each entry must be a real number representing $\\widehat{\\mu}_n(\\mathcal{L})$ for that test. For example, the output must look like\n$[x_1,x_2,x_3,x_4,x_5,x_6]$\nwhere each $x_k$ is the estimated value for test $k$. No additional text should be printed.",
            "solution": "The problem has been subjected to rigorous validation and is determined to be sound. It is scientifically grounded in the established theory of self-avoiding walks, a topic of significance in statistical mechanics and computational physics. The problem is well-posed, objective, and provides a complete specification of test parameters, though it omits naming the specific Monte Carlo algorithm to be used. This omission is not a critical flaw, as a standard, appropriate algorithm can be inferred from the context. The computational task is feasible with the given parameters. Therefore, a solution will be provided, based upon the standard Rosenbluth-Rosenbluth importance sampling method.\n\nThe central task is to estimate the connective constant $\\mu(\\mathcal{L})$ for two planar lattices, the square lattice $\\mathsf{SQ}$ and the honeycomb lattice $\\mathsf{HC}$. The connective constant is defined as the limit\n$$\n\\mu(\\mathcal{L}) = \\lim_{n\\to\\infty} \\big(c_n(\\mathcal{L})\\big)^{1/n}\n$$\nwhere $c_n(\\mathcal{L})$ is the total number of self-avoiding walks (SAWs) of length $n$ starting from the origin on a lattice $\\mathcal{L}$. The problem states that the estimation must be performed by first producing a Monte Carlo estimate $\\widehat{c}_n(\\mathcal{L})$ of $c_n(\\mathcal{L})$, and then computing the estimate for the connective constant as $\\widehat{\\mu}_n(\\mathcal{L}) = \\big(\\widehat{c}_n(\\mathcal{L})\\big)^{1/n}$.\n\nDirect enumeration of $c_n(\\mathcal{L})$ is computationally intractable for all but very small values of $n$, as the number of walks grows exponentially. A naive Monte Carlo method of generating simple random walks and counting the fraction that are self-avoiding is also profoundly inefficient due to the high rate of attrition; the probability of a random walk being self-avoiding vanishes exponentially with $n$. Consequently, a more sophisticated approach is required. The Rosenbluth-Rosenbluth algorithm is a classic importance sampling method designed specifically for this problem. It constructs a SAW step-by-step while calculating a corrective weight, providing an unbiased estimate of $c_n(\\mathcal{L})$.\n\nThe Rosenbluth-Rosenbluth algorithm proceeds as follows for a single trial:\n$1$. A walk begins at the origin, $\\mathbf{x}_0 = (0,0)$. The initial weight of the walk is $W=1$.\n$2$. For each step $k$ from $1$ to $n$, the algorithm identifies all valid, non-self-intersecting nearest-neighbor sites from the current position $\\mathbf{x}_{k-1}$. Let the number of such available sites be $m_k$.\n$3$. If at any step $m_k=0$, the walk is \"trapped\" and cannot continue without self-intersection. The trial is terminated, and its contribution to the total count is a weight of $0$.\n$4$. If $m_k > 0$, the walk's weight is multiplied by $m_k$, so that $W \\to W \\times m_k$. One of the $m_k$ available sites is chosen uniformly at random to become the next site $\\mathbf{x}_k$ in the walk.\n$5$. If a walk of length $n$ is successfully generated without being trapped, it has a final weight $W_n = \\prod_{k=1}^n m_k$. This weight accounts for the fact that the walk was generated via a biased process (i.e., not all SAWs of length $n$ are equally likely to be generated).\n\nThis procedure is repeated for $M$ independent trials. The estimate for $c_n(\\mathcal{L})$ is the arithmetic mean of the weights from all trials:\n$$\n\\widehat{c}_n(\\mathcal{L}) = \\frac{1}{M} \\sum_{i=1}^{M} W_n^{(i)}\n$$\nThis provides an unbiased estimate, i.e., $\\mathbb{E}[\\widehat{c}_n(\\mathcal{L})] = c_n(\\mathcal{L})$. Finally, the estimate for the connective constant is calculated as $\\widehat{\\mu}_n(\\mathcal{L}) = (\\widehat{c}_n(\\mathcal{L}))^{1/n}$.\n\nThe implementation of this algorithm requires a clear definition of the lattice structures.\nThe square lattice, $\\mathsf{SQ}$, has nearest neighbors of a site $(i,j)$ given by $\\{(i\\pm 1, j), (i, j\\pm 1)\\}$, a coordination number of $z=4$.\nThe honeycomb lattice, $\\mathsf{HC}$, is represented on a square grid $\\mathbb{Z}^2$. For a site $(i,j)$, if $i+j$ is even, the neighbors are $\\{(i+1,j), (i-1,j), (i,j+1)\\}$; if $i+j$ is odd, the neighbors are $\\{(i+1,j), (i-1,j), (i,j-1)\\}$. This is a $3$-regular graph, so $z=3$.\n\nThe program is structured to handle the specified test cases. For each case $(\\mathcal{L}, n, M, s)$, a new pseudorandom number generator `numpy.random.default_rng` is initialized with the integer seed $s$ to ensure reproducibility. The simulation then performs $M$ trials, accumulating the weights to compute $\\widehat{c}_n(\\mathcal{L})$. To maintain computational efficiency, the set of visited sites in a walk is stored in a Python `set` data structure, which provides average $O(1)$ time complexity for lookups during the self-avoidance check. The final result for each test case is computed and collected into a list, which is then formatted into the required output string. For the test cases with very small $n$ (e.g., $n=1$ or $n=2$), the algorithm correctly computes the exact values of $c_n$, as there is no path variation that affects the weight calculation, thus serving as a validation of the implementation's correctness.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating the connective constant for specified lattices\n    using the Rosenbluth-Rosenbluth Monte Carlo method.\n    \"\"\"\n\n    def get_neighbors(pos, lattice_type):\n        \"\"\"\n        Returns the list of nearest neighbors for a given position on a lattice.\n\n        Args:\n            pos (tuple): The (i, j) coordinates of the site.\n            lattice_type (str): The type of lattice, 'SQ' or 'HC'.\n\n        Returns:\n            list: A list of neighbor coordinate tuples.\n        \"\"\"\n        i, j = pos\n        if lattice_type == 'SQ':\n            return [(i + 1, j), (i - 1, j), (i, j + 1), (i, j - 1)]\n        elif lattice_type == 'HC':\n            # Parity-based definition for honeycomb lattice on a square grid\n            if (i + j) % 2 == 0:\n                return [(i + 1, j), (i - 1, j), (i, j + 1)]\n            else: # (i + j) is odd\n                return [(i + 1, j), (i - 1, j), (i, j - 1)]\n        return []\n\n    def run_rosenbluth_trial(lattice_type, n, rng):\n        \"\"\"\n        Performs a single trial of the Rosenbluth-Rosenbluth algorithm.\n\n        Args:\n            lattice_type (str): The lattice type.\n            n (int): The desired length of the self-avoiding walk.\n            rng (numpy.random.Generator): The random number generator to use.\n\n        Returns:\n            float: The weight of the generated walk. Returns 0.0 if the walk is trapped.\n        \"\"\"\n        current_pos = (0, 0)\n        visited_sites = {current_pos}\n        weight = 1.0\n\n        for _ in range(n):\n            neighbors = get_neighbors(current_pos, lattice_type)\n            # Filter for neighbors not already in the path\n            valid_neighbors = [p for p in neighbors if p not in visited_sites]\n            \n            m_k = len(valid_neighbors)\n            \n            if m_k == 0:\n                # The walk is trapped, so its weight contribution is zero.\n                return 0.0\n            \n            # Update the weight of the walk\n            weight *= m_k\n            \n            # Choose the next position uniformly from the valid neighbors\n            next_pos_idx = rng.integers(0, m_k)\n            current_pos = valid_neighbors[next_pos_idx]\n            visited_sites.add(current_pos)\n            \n        return weight\n\n    def estimate_mu(lattice_type, n, M, seed):\n        \"\"\"\n        Estimates the connective constant mu for a given lattice.\n\n        Args:\n            lattice_type (str): The lattice type ('SQ' or 'HC').\n            n (int): The length of the self-avoiding walks.\n            M (int): The number of Monte Carlo trials.\n            seed (int): The seed for the random number generator.\n\n        Returns:\n            float: The estimated connective constant.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        \n        total_weight = 0.0\n        for _ in range(M):\n            total_weight += run_rosenbluth_trial(lattice_type, n, rng)\n            \n        c_n_est = total_weight / M\n        \n        if c_n_est == 0.0:\n            # This can happen if all walks get trapped.\n            return 0.0\n        \n        mu_est = c_n_est**(1.0 / n)\n        return mu_est\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (lattice_type, n, M, seed)\n        ('HC', 20, 20000, 12345),\n        ('SQ', 20, 20000, 12345),\n        ('HC', 40, 10000, 2023),\n        ('SQ', 40, 10000, 2023),\n        ('HC', 1, 50000, 7),\n        ('SQ', 2, 50000, 11),\n    ]\n\n    results = []\n    for case in test_cases:\n        lattice_type, n, M, seed = case\n        result = estimate_mu(lattice_type, n, M, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(str(r) for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Building on Monte Carlo techniques, we can simulate SAWs in more complex, physical environments. This practice  models a polymer chain subject to a uniform external field, such as gravity. You will implement a biased Rosenbluth growth, where steps are weighted by a Boltzmann factor $\\exp(-\\alpha \\Delta y)$, to investigate how the field stretches and orients the polymer.",
            "id": "2436444",
            "problem": "Design and implement a program to investigate a self-avoiding random walk (SAW) on a square lattice under a uniform external field that biases steps in a preferred direction, modeling polymer sedimentation. The walk is on a two-dimensional square lattice (dimension $2$), with lattice spacing equal to $1$ in dimensionless units. The SAW starts at the origin $(0,0)$ and consists of $N$ nearest-neighbor steps, each step being one of $(\\pm 1,0)$ or $(0,\\pm 1)$, with the self-avoidance constraint that no lattice site is visited more than once.\n\nThe external field is uniform and points in the negative $y$ direction (downward). The energy of a configuration ending at height $y_N$ is modeled by a linear potential $U(y_N) = \\alpha \\, y_N$, where $\\alpha \\ge 0$ is a dimensionless field strength proportional to the product of the gravitational acceleration, monomer mass, and inverse thermal energy. The Boltzmann weight of a configuration is then proportional to $\\exp(- U(y_N)) = \\exp(- \\alpha \\, y_N)$. Equivalently, each step with vertical increment $\\Delta y \\in \\{-1,0,+1\\}$ carries a local Boltzmann factor $\\exp(-\\alpha \\, \\Delta y)$, so that a downward step $\\Delta y = -1$ is favored by a factor $\\exp(+\\alpha)$, an upward step $\\Delta y = +1$ is suppressed by a factor $\\exp(-\\alpha)$, and horizontal steps $\\Delta y = 0$ are unaffected.\n\nBecause uniformly growing a SAW of length $N$ has high attrition due to traps (dead ends), use the Rosenbluth importance sampling approach for biased growth, defined as follows. At each growth step $i \\in \\{0,1,\\dots,N-1\\}$ from position $\\mathbf{r}_i$, enumerate the set of allowed next steps $\\mathcal{A}_i$ that lead to unvisited neighbors. For each allowed step $s \\in \\mathcal{A}_i$ with vertical increment $\\Delta y(s)$, define the local Boltzmann factor $b(s) = \\exp(-\\alpha \\, \\Delta y(s))$ and the step-selection normalization $C_i = \\sum_{s \\in \\mathcal{A}_i} b(s)$. Select the next step $s_i$ with probability $p(s_i) = b(s_i)/C_i$. If $\\mathcal{A}_i$ is empty (that is, $C_i = 0$), the walk is trapped and the current trial does not produce a length-$N$ configuration. The Rosenbluth weight of a successfully grown length-$N$ configuration is $W_N = \\prod_{i=0}^{N-1} C_i$.\n\nLet $\\mathbf{R}_N = \\mathbf{r}_N - \\mathbf{r}_0$ denote the end-to-end vector. Consider the following observables:\n- The projection of the end-to-end vector along the field direction (downward) per step, defined as $A_1 = (\\mathbf{R}_N \\cdot \\hat{\\mathbf{e}}_f)/N$, where $\\hat{\\mathbf{e}}_f = (0,-1)$ is the unit vector along the field, so that $A_1 = -y_N/N$.\n- The squared end-to-end distance, defined as $A_2 = \\|\\mathbf{R}_N\\|^2 = x_N^2 + y_N^2$.\nThe Boltzmann-weighted expectations of these observables over all length-$N$ SAWs are estimated by the importance-sampling estimator\n$$\n\\langle A \\rangle \\approx \\frac{\\sum_{k=1}^{M_s} W_N^{(k)} \\, A^{(k)}}{\\sum_{k=1}^{M_s} W_N^{(k)}},\n$$\nwhere $M_s$ is the number of successfully grown length-$N$ walks in $M$ independent Rosenbluth growth trials, $W_N^{(k)}$ is the Rosenbluth weight of the $k$-th successful configuration, and $A^{(k)}$ is the observable evaluated on that configuration. Also estimate the attrition rate $a = (M - M_s)/M$, the fraction of trials that became trapped before reaching length $N$.\n\nStarting from these definitions and principles, write a complete program that:\n- Implements the biased Rosenbluth growth procedure for SAWs as specified above.\n- Performs $M$ independent trials for each test case with a specified pseudorandom seed, counts the number of successful length-$N$ configurations, computes the Rosenbluth-weighted estimates of $\\langle A_1 \\rangle$ and $\\langle A_2 \\rangle$, and computes the attrition rate $a$.\n- Uses dimensionless units throughout (no physical units required).\n- Rounds each reported floating-point result to $6$ decimal places.\n\nTest suite. Your program must compute results for the following parameter sets, each specified as a tuple $(N,\\alpha,M,\\text{seed})$:\n- Case $1$: $(32, 0.0, 6000, 314159)$.\n- Case $2$: $(32, 0.5, 6000, 271828)$.\n- Case $3$: $(40, 1.0, 8000, 161803)$.\n\nFinal output format. Your program should produce a single line of output containing a list of results, one per test case, where each result is itself a list of three floats in the order $[\\langle A_1 \\rangle, \\langle A_2 \\rangle, a]$, each rounded to $6$ decimal places. The overall format must be a single line:\n[[r11,r12,r13],[r21,r22,r23],[r31,r32,r33]]\nwith no spaces anywhere in the line.",
            "solution": "The problem requires the implementation of a simulation for a self-avoiding random walk (SAW) on a two-dimensional square lattice, subject to a biasing external field. The simulation must employ the Rosenbluth method for importance sampling to estimate physical observables.\n\nThe physical system is a polymer chain of $N$ monomers, modeled as an $N$-step SAW on a square lattice with lattice spacing $1$. The walk begins at the origin $\\mathbf{r}_0 = (0,0)$. The self-avoiding constraint means no lattice site can be visited more than once. An external field is applied in the negative $y$-direction, represented by the potential energy $U(y_N) = \\alpha \\, y_N$, where $y_N$ is the final vertical coordinate of the walk and $\\alpha \\ge 0$ is the dimensionless field strength. The statistical weight of a given SAW configuration is determined by the Boltzmann factor $e^{-U(y_N)/k_B T}$, which in the given dimensionless units is proportional to $\\exp(-\\alpha \\, y_N)$. This total weight can be decomposed into a product of local factors for each step, $\\prod_{i=0}^{N-1} \\exp(-\\alpha \\, \\Delta y_i)$, where $\\Delta y_i$ is the vertical displacement of the $i$-th step.\n\nDirect uniform sampling of SAWs is computationally inefficient due to the high probability of \"attrition,\" where a walk becomes trapped in a dead end before reaching the desired length $N$. To overcome this, the problem specifies the use of the biased Rosenbluth growth algorithm, which is a form of importance sampling.\n\nThe algorithm proceeds as follows for each trial walk:\n$1$. The walk starts at $\\mathbf{r}_0 = (0,0)$ with an initial Rosenbluth weight of $1$. A set of visited sites is maintained, initially containing only the origin.\n$2$. For each step $i$ from $0$ to $N-1$, from the current position $\\mathbf{r}_i$:\n    a. We identify the set of allowed next steps, $\\mathcal{A}_i$, which lead to adjacent, unvisited lattice sites.\n    b. If $\\mathcal{A}_i$ is empty, the walk is trapped. The trial is terminated and considered unsuccessful.\n    c. For each allowed step $s \\in \\mathcal{A}_i$ with vertical displacement $\\Delta y(s)$, we compute a local Boltzmann factor $b(s) = \\exp(-\\alpha \\, \\Delta y(s))$. A downward step ($\\Delta y = -1$) is favored with a factor $\\exp(\\alpha)$, an upward step ($\\Delta y = +1$) is suppressed by $\\exp(-\\alpha)$, and horizontal steps ($\\Delta y = 0$) have a factor of $1$.\n    d. We compute the normalization factor for the current step, $C_i = \\sum_{s \\in \\mathcal{A}_i} b(s)$. This factor is the sum of weights of all possible continuations.\n    e. The total Rosenbluth weight for the configuration, $W_N$, is updated by multiplication with $C_i$. The full weight for a successful walk is the product $W_N = \\prod_{i=0}^{N-1} C_i$. For numerical stability, it is preferable to compute the logarithm of the weight, $\\ln W_N = \\sum_{i=0}^{N-1} \\ln C_i$.\n    f. The next step $s_i$ is chosen from $\\mathcal{A}_i$ with a probability proportional to its Boltzmann factor, $p(s_i) = b(s_i) / C_i$.\n    g. The position is updated, $\\mathbf{r}_{i+1} = \\mathbf{r}_i + \\Delta\\mathbf{r}(s_i)$, and the new site is added to the set of visited sites.\n\nAfter $M$ independent trials, we will have a sample of $M_s \\le M$ successfully grown walks. The statistical expectation of an observable $A$ is estimated using the importance sampling formula, which weights each sample $k$ by its Rosenbluth weight $W_N^{(k)}$:\n$$\n\\langle A \\rangle \\approx \\frac{\\sum_{k=1}^{M_s} W_N^{(k)} A^{(k)}}{\\sum_{k=1}^{M_s} W_N^{(k)}}\n$$\nwhere $A^{(k)}$ is the value of the observable for the $k$-th successful walk. This estimator corrects for the bias introduced by the growth procedure, yielding an estimate for the true Boltzmann-weighted average over all possible length-$N$ SAWs.\n\nThe specific observables to be computed are:\n- The normalized projection of the end-to-end vector $\\mathbf{R}_N = (x_N, y_N)$ along the field direction, $A_1 = -y_N/N$.\n- The squared end-to-end distance, $A_2 = \\|\\mathbf{R}_N\\|^2 = x_N^2 + y_N^2$.\n\nAdditionally, the attrition rate, $a$, which measures the fraction of walks that failed to reach length $N$, is computed as $a = (M - M_s)/M$.\n\nThe implementation will consist of a main loop over the specified test cases. For each case, a function will execute $M$ trials, seeded with the provided value for reproducibility. Each trial will attempt to grow one SAW. The results from successful trials (the observables $A_1^{(k)}$, $A_2^{(k)}$ and the log-Rosenbluth weight $\\ln W_N^{(k)}$) are collected. After all trials, final estimates for $\\langle A_1 \\rangle$, $\\langle A_2 \\rangle$, and $a$ are calculated. A numerically stable method for calculating the weighted sums is employed, which involves shifting the log-weights by their maximum value before exponentiating to prevent floating-point overflow. The final results are rounded to $6$ decimal places as required.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        (32, 0.0, 6000, 314159),  # Case 1: (N, alpha, M, seed)\n        (32, 0.5, 6000, 271828),  # Case 2\n        (40, 1.0, 8000, 161803),  # Case 3\n    ]\n\n    all_results = []\n    for N, alpha, M, seed in test_cases:\n        result = run_simulation(N, alpha, M, seed)\n        # Round each value to 6 decimal places.\n        rounded_result = [round(val, 6) for val in result]\n        all_results.append(rounded_result)\n\n    # Print in the specified format: [[r11,r12,r13],[r21,r22,r23],...]\n    print(str(all_results).replace(\" \", \"\"))\n\ndef run_simulation(N, alpha, M, seed):\n    \"\"\"\n    Performs M independent Rosenbluth growth trials for a single parameter set.\n\n    Args:\n        N (int): Number of steps in the SAW.\n        alpha (float): Field strength.\n        M (int): Number of trials.\n        seed (int): Seed for the pseudorandom number generator.\n\n    Returns:\n        tuple: A tuple containing the estimated observables \n               (<A1>, <A2>, attrition_rate).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    successful_walks = []\n    for _ in range(M):\n        result = _run_single_trial(N, alpha, rng)\n        if result is not None:\n            successful_walks.append(result)\n\n    M_s = len(successful_walks)\n    attrition_rate = (M - M_s) / M\n\n    if M_s == 0:\n        return (0.0, 0.0, attrition_rate)\n\n    # Extract results from successful walks\n    # result is (A1, A2, log_W)\n    A1_values = np.array([walk[0] for walk in successful_walks])\n    A2_values = np.array([walk[1] for walk in successful_walks])\n    log_weights = np.array([walk[2] for walk in successful_walks])\n\n    # Numerically stable calculation of weighted averages\n    # W_scaled = exp(log_W - max(log_W))\n    max_log_W = np.max(log_weights)\n    scaled_weights = np.exp(log_weights - max_log_W)\n    \n    sum_scaled_weights = np.sum(scaled_weights)\n\n    if sum_scaled_weights == 0:\n        # This case is highly unlikely but handled for robustness.\n        return (0.0, 0.0, attrition_rate)\n\n    avg_A1 = np.sum(A1_values * scaled_weights) / sum_scaled_weights\n    avg_A2 = np.sum(A2_values * scaled_weights) / sum_scaled_weights\n\n    return (avg_A1, avg_A2, attrition_rate)\n\ndef _run_single_trial(N, alpha, rng):\n    \"\"\"\n    Grows a single self-avoiding walk using the biased Rosenbluth method.\n\n    Args:\n        N (int): The number of steps for the walk.\n        alpha (float): The field strength parameter.\n        rng (np.random.Generator): The random number generator instance.\n\n    Returns:\n        tuple or None: A tuple (A1, A2, log_W) for a successful walk, \n                       or None if the walk gets trapped.\n    \"\"\"\n    # Using a set for O(1) average time complexity for checking visited sites.\n    path = {(0, 0)}\n    x, y = 0, 0\n    log_W = 0.0\n    \n    # Possible nearest-neighbor steps on a square lattice\n    moves = [(1, 0), (-1, 0), (0, 1), (0, -1)]\n\n    for _ in range(N):\n        allowed_steps = []\n        for dx, dy in moves:\n            if (x + dx, y + dy) not in path:\n                allowed_steps.append((dx, dy))\n\n        if not allowed_steps:\n            return None  # Walk is trapped\n\n        # Calculate Boltzmann factors and probabilities for allowed steps\n        boltzmann_factors = [np.exp(-alpha * dy) for _, dy in allowed_steps]\n        C_i = sum(boltzmann_factors)\n        \n        # Update the log of the Rosenbluth weight\n        log_W += np.log(C_i)\n\n        probabilities = [b / C_i for b in boltzmann_factors]\n        \n        # Select the next step based on the biased probabilities\n        chosen_idx = rng.choice(len(allowed_steps), p=probabilities)\n        dx, dy = allowed_steps[chosen_idx]\n        \n        # Update position and path\n        x, y = x + dx, y + dy\n        path.add((x, y))\n\n    # Calculate observables for the completed walk\n    A1 = -y / N\n    A2 = float(x**2 + y**2) # final position is (x,y)\n    \n    return (A1, A2, log_W)\n\n# Execute the simulation.\nsolve()\n```"
        }
    ]
}