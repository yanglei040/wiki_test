{
    "hands_on_practices": [
        {
            "introduction": "我们将从一个核物理中的经典问题开始我们的动手实践：推断放射源的衰变率。通过使用盖革计数器的数据，你将应用贝叶斯原理来估计衰变常数 $\\lambda$ 。这个练习具体地应用了泊松似然函数及其共轭伽马先验，展示了当我们收集更多数据时，我们对物理参数的知识是如何被系统地更新的。",
            "id": "2375997",
            "problem": "盖革计数器记录来自固定放射源的离散探测计数。该探测过程被建模为一个恒定衰变率 $\\lambda$（单位为 $\\mathrm{s^{-1}}$）的齐次泊松过程。在长度为 $\\{t_i\\}$（单位为 $\\mathrm{s}$）的非重叠时间窗口内，计数 $\\{k_i\\}$ 假定在给定 $\\lambda$ 的条件下条件独立，其中 $k_i$ 服从 $\\mathrm{Poisson}(\\lambda t_i)$ 分布。\n\n假设 $\\lambda$ 的先验分布遵循伽马分布，其形状参数为 $\\alpha_0$，速率参数为 $\\beta_0$，由密度函数参数化：\n$$\np(\\lambda \\mid \\alpha_0,\\beta_0) = \\frac{\\beta_0^{\\alpha_0}}{\\Gamma(\\alpha_0)} \\lambda^{\\alpha_0 - 1} e^{-\\beta_0 \\lambda}, \\quad \\lambda  0,\n$$\n其中 $\\alpha_0  0$ 是无量纲的，$\\beta_0  0$ 的单位是 $\\mathrm{s}$。\n\n任务：对于下方的每个测试用例，计算后验均值 $\\mathbb{E}[\\lambda \\mid \\{(t_i,k_i)\\}]$，单位为 $\\mathrm{s^{-1}}$。将每个结果以 $\\mathrm{s^{-1}}$ 为单位表示，并四舍五入到六位小数。\n\n测试集：\n- 用例 1 (一般情况): 计数 $k = (1,0,2)$, 持续时间 $t = (1.0,2.0,3.0)\\,\\mathrm{s}$, 先验参数 $\\alpha_0 = 1.0$, $\\beta_0 = 1.0\\,\\mathrm{s}$。\n- 用例 2 (零计数): 计数 $k = (0,0)$, 持续时间 $t = (10.0,20.0)\\,\\mathrm{s}$, 先验参数 $\\alpha_0 = 2.0$, $\\beta_0 = 5.0\\,\\mathrm{s}$。\n- 用例 3 (长曝光，高计数): 计数 $k = (130,250,410)$, 持续时间 $t = (100.0,200.0,300.0)\\,\\mathrm{s}$, 先验参数 $\\alpha_0 = 0.5$, $\\beta_0 = 0.1\\,\\mathrm{s}$。\n- 用例 4 (极短窗口): 计数 $k = (0,1)$, 持续时间 $t = (0.001,0.002)\\,\\mathrm{s}$, 先验参数 $\\alpha_0 = 1.0$, $\\beta_0 = 1.0\\,\\mathrm{s}$。\n\n最终输出格式要求：\n你的程序应生成一行输出，其中包含四个用例的结果，结果为逗号分隔的列表，并用方括号括起来，顺序为用例 $1$、用例 $2$、用例 $3$、用例 $4$。例如，一个有效的格式是 $[x_1,x_2,x_3,x_4]$，其中每个 $x_j$ 是单位为 $\\mathrm{s^{-1}}$ 并四舍五入到六位小数的后验均值。",
            "solution": "所述问题是有效的。它在科学上基于核物理和贝叶斯统计的原理，问题提法明确，并包含得出唯一解所需的所有信息。我们将着手进行推导。\n\n目标是求泊松过程衰变率参数 $\\lambda$ 的后验均值。此任务的基础是贝叶斯定理，该定理指出后验概率正比于似然和先验概率的乘积。\n$$\np(\\text{参数} \\mid \\text{数据}) \\propto p(\\text{数据} \\mid \\text{参数}) \\cdot p(\\text{参数})\n$$\n在此问题中，参数是 $\\lambda$，数据（我们记为 $\\mathcal{D}$）由一组观测值 $\\{ (t_i, k_i) \\}_{i=1}^N$ 组成，其中 $k_i$ 是在长度为 $t_i$ 的时间间隔内的探测计数值。\n\n首先，我们定义似然函数 $p(\\mathcal{D} \\mid \\lambda)$。问题陈述每个计数 $k_i$ 从参数为 $\\lambda t_i$ 的泊松分布中抽取。单个观测值的概率质量函数为：\n$$\nP(k_i \\mid \\lambda, t_i) = \\frac{(\\lambda t_i)^{k_i} e^{-\\lambda t_i}}{k_i!}\n$$\n鉴于观测值是条件独立的，整个数据集 $\\mathcal{D}$ 的似然是各个概率的乘积：\n$$\np(\\mathcal{D} \\mid \\lambda) = \\prod_{i=1}^{N} P(k_i \\mid \\lambda, t_i) = \\prod_{i=1}^{N} \\frac{(\\lambda t_i)^{k_i} e^{-\\lambda t_i}}{k_i!}\n$$\n在贝叶斯分析中，我们关心的是似然函数相对于参数 $\\lambda$ 的函数形式。因此，我们可以丢弃不依赖于 $\\lambda$ 的项，将它们吸收到一个归一化常数中。\n$$\np(\\mathcal{D} \\mid \\lambda) \\propto \\prod_{i=1}^{N} (\\lambda t_i)^{k_i} e^{-\\lambda t_i} = \\left( \\prod_{i=1}^{N} t_i^{k_i} \\right) \\left( \\prod_{i=1}^{N} \\lambda^{k_i} \\right) \\left( \\prod_{i=1}^{N} e^{-\\lambda t_i} \\right)\n$$\n$$\np(\\mathcal{D} \\mid \\lambda) \\propto \\lambda^{\\sum_{i=1}^{N} k_i} e^{-\\lambda \\sum_{i=1}^{N} t_i}\n$$\n我们定义总计数 $K = \\sum_{i=1}^{N} k_i$ 和总观测时间 $T = \\sum_{i=1}^{N} t_i$。似然函数简化为：\n$$\np(\\mathcal{D} \\mid \\lambda) \\propto \\lambda^K e^{-\\lambda T}\n$$\n\n接下来，我们考虑 $\\lambda$ 的先验分布，它被给定为形状参数为 $\\alpha_0  0$ 和速率参数为 $\\beta_0  0$ 的伽马分布。\n$$\np(\\lambda \\mid \\alpha_0, \\beta_0) = \\frac{\\beta_0^{\\alpha_0}}{\\Gamma(\\alpha_0)} \\lambda^{\\alpha_0 - 1} e^{-\\beta_0 \\lambda}\n$$\n忽略归一化常数，先验分布的核为：\n$$\np(\\lambda \\mid \\alpha_0, \\beta_0) \\propto \\lambda^{\\alpha_0 - 1} e^{-\\beta_0 \\lambda}\n$$\n\n现在，我们结合似然和先验来求后验分布 $p(\\lambda \\mid \\mathcal{D}, \\alpha_0, \\beta_0)$：\n$$\np(\\lambda \\mid \\mathcal{D}, \\alpha_0, \\beta_0) \\propto p(\\mathcal{D} \\mid \\lambda) \\cdot p(\\lambda \\mid \\alpha_0, \\beta_0)\n$$\n$$\np(\\lambda \\mid \\mathcal{D}, \\alpha_0, \\beta_0) \\propto (\\lambda^K e^{-\\lambda T}) \\cdot (\\lambda^{\\alpha_0 - 1} e^{-\\beta_0 \\lambda}) = \\lambda^{K + \\alpha_0 - 1} e^{-(\\beta_0 + T)\\lambda}\n$$\n此表达式是伽马分布的核。这证实了伽马分布是泊松似然的共轭先验，意味着后验分布也是一个伽马分布。此后验伽马分布的参数（我们记为 $\\alpha_N$ 和 $\\beta_N$）可通过观察得出：\n$$\n\\alpha_N = \\alpha_0 + K = \\alpha_0 + \\sum_{i=1}^{N} k_i\n$$\n$$\n\\beta_N = \\beta_0 + T = \\beta_0 + \\sum_{i=1}^{N} t_i\n$$\n任务是计算后验均值 $\\mathbb{E}[\\lambda \\mid \\mathcal{D}]$。服从形状参数为 $\\alpha$ 和速率参数为 $\\beta$ 的伽马分布的随机变量 $X$ 的期望值为 $\\mathbb{E}[X] = \\alpha/\\beta$。将此应用于我们的后验分布，我们得到 $\\lambda$ 的后验均值：\n$$\n\\mathbb{E}[\\lambda \\mid \\mathcal{D}] = \\frac{\\alpha_N}{\\beta_N} = \\frac{\\alpha_0 + \\sum k_i}{\\beta_0 + \\sum t_i}\n$$\n这是解的通用公式。我们现在将其应用于每个指定的测试用例。\n\n用例 1: $k = (1, 0, 2)$, $t = (1.0, 2.0, 3.0)\\,\\mathrm{s}$, $\\alpha_0 = 1.0$, $\\beta_0 = 1.0\\,\\mathrm{s}$。\n$\\sum k_i = 1+0+2=3$。\n$\\sum t_i = 1.0+2.0+3.0=6.0\\,\\mathrm{s}$。\n$\\mathbb{E}[\\lambda \\mid \\mathcal{D}] = \\frac{1.0 + 3}{1.0 + 6.0} = \\frac{4.0}{7.0} \\approx 0.571429\\,\\mathrm{s^{-1}}$。\n\n用例 2: $k = (0, 0)$, $t = (10.0, 20.0)\\,\\mathrm{s}$, $\\alpha_0 = 2.0$, $\\beta_0 = 5.0\\,\\mathrm{s}$。\n$\\sum k_i = 0+0=0$。\n$\\sum t_i = 10.0+20.0=30.0\\,\\mathrm{s}$。\n$\\mathbb{E}[\\lambda \\mid \\mathcal{D}] = \\frac{2.0 + 0}{5.0 + 30.0} = \\frac{2.0}{35.0} \\approx 0.057143\\,\\mathrm{s^{-1}}$。\n\n用例 3: $k = (130, 250, 410)$, $t = (100.0, 200.0, 300.0)\\,\\mathrm{s}$, $\\alpha_0 = 0.5$, $\\beta_0 = 0.1\\,\\mathrm{s}$。\n$\\sum k_i = 130+250+410=790$。\n$\\sum t_i = 100.0+200.0+300.0=600.0\\,\\mathrm{s}$。\n$\\mathbb{E}[\\lambda \\mid \\mathcal{D}] = \\frac{0.5 + 790}{0.1 + 600.0} = \\frac{790.5}{600.1} \\approx 1.317280\\,\\mathrm{s^{-1}}$。\n\n用例 4: $k = (0, 1)$, $t = (0.001, 0.002)\\,\\mathrm{s}$, $\\alpha_0 = 1.0$, $\\beta_0 = 1.0\\,\\mathrm{s}$。\n$\\sum k_i = 0+1=1$。\n$\\sum t_i = 0.001+0.002=0.003\\,\\mathrm{s}$。\n$\\mathbb{E}[\\lambda \\mid \\mathcal{D}] = \\frac{1.0 + 1}{1.0 + 0.003} = \\frac{2.0}{1.003} \\approx 1.994018\\,\\mathrm{s^{-1}}$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the posterior mean of a Poisson rate parameter for several test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: k=(1,0,2), t=(1.0,2.0,3.0), a0=1.0, b0=1.0\n        {'k': [1, 0, 2], 't': [1.0, 2.0, 3.0], 'a0': 1.0, 'b0': 1.0},\n        # Case 2: k=(0,0), t=(10.0,20.0), a0=2.0, b0=5.0\n        {'k': [0, 0], 't': [10.0, 20.0], 'a0': 2.0, 'b0': 5.0},\n        # Case 3: k=(130,250,410), t=(100.0,200.0,300.0), a0=0.5, b0=0.1\n        {'k': [130, 250, 410], 't': [100.0, 200.0, 300.0], 'a0': 0.5, 'b0': 0.1},\n        # Case 4: k=(0,1), t=(0.001,0.002), a0=1.0, b0=1.0\n        {'k': [0, 1], 't': [0.001, 0.002], 'a0': 1.0, 'b0': 1.0}\n    ]\n\n    results = []\n    for case in test_cases:\n        # The posterior distribution for lambda is a Gamma distribution with\n        # updated parameters alpha_N and beta_N.\n        # alpha_N = alpha_0 + sum(k_i)\n        # beta_N = beta_0 + sum(t_i)\n        # The posterior mean E[lambda | data] is alpha_N / beta_N.\n\n        # Calculate total counts and total time\n        total_counts = np.sum(case['k'])\n        total_time = np.sum(case['t'])\n        \n        # Get prior parameters\n        alpha_0 = case['a0']\n        beta_0 = case['b0']\n        \n        # Calculate posterior parameters\n        alpha_n = alpha_0 + total_counts\n        beta_n = beta_0 + total_time\n        \n        # Calculate posterior mean\n        posterior_mean = alpha_n / beta_n\n        \n        # Format the result as a string rounded to six decimal places.\n        # The format specifier \"{:.6f}\" handles both rounding and formatting.\n        results.append(f\"{posterior_mean:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "接下来，我们将进入量子领域，解决一个有趣的推断问题：如何从带噪声的位置测量中确定“盒子中粒子”所处的能级 。这个实践将我们从简单的参数估计提升到更普遍的模型选择任务，其中每个量子数 $n$ 代表一个独特的物理假说。你将学习通过对未观测到的粒子真实位置进行边缘化来计算每个状态的证据，这是处理潜变量的一项关键技术。",
            "id": "2375965",
            "problem": "一个质量为 $m$ 的非相对论粒子被限制在长度为 $L$ 的一维无限深势阱中，其定态由正整数量子数 $n$ 索引。空间波函数是归一化的，位置概率密度由波函数的模平方给出。考虑一个实验过程，该过程测量粒子位置，并伴有已知的标准差为 $\\sigma$ 的加性、独立的零均值高斯噪声。真实位置仅分布在区间 $[0,L]$ 上，但由于噪声，测量值可以位于实轴上的任何位置。您需要根据一组有限的带噪声的位置测量值，对整数量子数 $n$ 进行贝叶斯推断。\n\n您的程序必须实现以下建模假设并计算所要求的输出：\n\n- 无限深方势阱的定态波函数导出的位置概率密度为 $p(x \\mid n)$，其支撑集为 $x \\in [0,L]$。\n- 每次测量 $y$ 的生成过程是：首先从 $p(x \\mid n)$ 中抽取 $x$，然后从均值为 $x$、方差为 $\\sigma^2$ 的正态分布中抽取 $y$，各次测量之间相互独立。也就是说，条件密度 $p(y \\mid x)$ 是标准差为 $\\sigma$ 的高斯分布。\n- 在给定 $n$ 的条件下，各次测量是条件独立的。\n- 每个测试用例都提供了一个在有限整数候选集上的先验概率 $p(n)$。\n- 后验概率 $p(n \\mid y_1,\\dots,y_M)$ 与所有测量的先验概率和似然函数的乘积成正比，其中每次测量的似然函数是通过对潜在的真实位置 $x$ 进行边缘化得到的。\n- 最大后验估计是使后验概率最大化的整数 $n$。如果出现数值精度范围内的平局，选择最小的 $n$。\n\n所有物理量必须在国际单位制（SI）中处理。所有位置，包括 $L$、$\\sigma$ 和测量值 $y$，都必须以米为单位。出现在三角函数中的角度是由物理量构成的无量纲参数，因此这些参数是无单位的。您的最终答案是整数，因此也是无单位的。\n\n您的程序必须解决以下四个测试用例。对于每个用例，根据提供的数据和先验计算 $n$ 的最大后验估计。仅使用提供的数据；不要生成任何随机数。\n\n- 情况 A（中等噪声，三峰结构）：$L = 1.0\\,\\mathrm{m}$，$\\sigma = 0.02\\,\\mathrm{m}$，候选集 $\\{1,2,3,4,5\\}$，在这些候选上使用均匀先验，测量值 $y$ 由列表 $[0.151, 0.170, 0.497, 0.512, 0.835, 0.820, 0.505, 0.166, 0.842, 0.158]$ 给出，单位为米。\n- 情况 B（近无噪声，单峰结构）：$L = 1.0\\,\\mathrm{m}$，$\\sigma = 0.005\\,\\mathrm{m}$，候选集 $\\{1,2,3,4,5\\}$，在这些候选上使用均匀先验，测量值 $y$ 由列表 $[0.480, 0.514, 0.492, 0.508, 0.501]$ 给出，单位为米。\n- 情况 C（高噪声，先验主导）：$L = 1.0\\,\\mathrm{m}$，$\\sigma = 0.15\\,\\mathrm{m}$，候选集 $\\{1,2,3,4,5\\}$，在这些候选上使用先验 $p(n) \\propto 1/n^2$，测量值 $y$ 由列表 $[0.10, 0.90, 0.25, 0.75]$ 给出，单位为米。\n- 情况 D（因噪声导致测量值在阱外）：$L = 1.0\\,\\mathrm{m}$，$\\sigma = 0.03\\,\\mathrm{m}$，候选集 $\\{1,2,3,4,5\\}$，在这些候选上使用均匀先验，测量值 $y$ 由列表 $[-0.03, 1.04, 0.24, 0.76, 0.26, 0.50]$ 给出，单位为米。\n\n计算要求：\n\n- 使用标准的无限深方势阱模型：状态指数为 $n$ 的位置概率密度在 $[0,L]$ 上与 $\\sin^2(n \\pi x / L)$ 成正比，在区间外为零，并在 $[0,L]$ 上归一化，使其积分为1。\n- 如上所述，使用高斯模型来描述测量噪声。\n- 假设在给定 $n$ 的情况下测量是条件独立的，以将数据集的似然函数构造为单个测量似然函数的乘积。\n- 通过在物理区间 $[0,L]$ 上积分，将潜在的真实位置 $x$ 从每次测量的似然函数中边缘化。\n- 计算后验概率（可相差一个乘法常数）并找出使其最大化的 $n$。\n\n您的程序应生成单行输出，其中包含按情况 A、B、C、D 顺序排列的结果，形式为用方括号括起来的逗号分隔列表。例如，输出可能看起来像 \"[3,1,1,2]\"，其中每个条目是相应情况的最大后验 $n$。必须遵循确切的格式，包括方括号和不带空格的逗号。",
            "solution": "所提出的问题要求应用贝叶斯推断，根据一组带噪声的位置测量值，来确定一维无限深势阱中粒子最可能所处的量子态。该问题在科学上是合理的、适定的，并为其解决提供了所有必要的信息。\n\n问题的核心是计算给定一组测量值 $D = \\{y_1, y_2, \\dots, y_M\\}$ 时，量子数 $n$ 的后验概率分布。根据贝叶斯定理，后验概率与似然函数和先验概率的乘积成正比：\n$$\np(n | D) \\propto p(D | n) p(n)\n$$\n假设在给定量子数 $n$ 的条件下，各次测量是条件独立的。因此，数据集 $D$ 的总似然函数是每次单独测量的似然函数的乘积：\n$$\np(D | n) = \\prod_{i=1}^{M} p(y_i | n)\n$$\n为了数值稳定性，最好使用对数概率。对数后验概率由下式给出：\n$$\n\\log p(n | D) = \\log p(n) + \\sum_{i=1}^{M} \\log p(y_i | n) + C\n$$\n其中 $C$ 是一个不依赖于 $n$ 的归一化常数。我们的目标是找到 $n$ 的最大后验（MAP）估计，即候选集中使该对数后验概率最大化的 $n$ 值：\n$$\nn_{\\text{MAP}} = \\underset{n}{\\arg\\max} \\left( \\log p(n) + \\sum_{i=1}^{M} \\log p(y_i | n) \\right)\n$$\n中心任务是计算单次测量的似然函数 $p(y_i | n)$。一次测量 $y_i$ 是某个真实粒子位置 $x$ 的带噪声版本。真实位置 $x$ 未被观测，因此是一个潜变量。我们必须通过边缘化（积分掉）这个潜变量来求得似然函数。边缘化是全概率定律的应用：\n$$\np(y_i | n) = \\int p(y_i, x | n) dx = \\int p(y_i | x, n) p(x | n) dx\n$$\n问题陈述指出，测量 $y_i$ 仅依赖于真实位置 $x$，所以 $p(y_i | x, n) = p(y_i | x)$。积分变为：\n$$\np(y_i | n) = \\int p(y_i | x) p(x | n) dx\n$$\n我们现在必须定义被积函数中的两个概率密度函数。\n\n$1$. 对于长度为 $L$ 的无限深方势阱中处于定态 $n$ 的粒子，其位置概率密度 $p(x | n)$ 由归一化波函数的模平方给出。波函数为 $\\psi_n(x) = \\sqrt{\\frac{2}{L}} \\sin\\left(\\frac{n \\pi x}{L}\\right)$（对于 $x \\in [0, L]$），在其他位置为零。因此，概率密度为：\n$$\np(x | n) = \\frac{2}{L} \\sin^2\\left(\\frac{n \\pi x}{L}\\right), \\quad x \\in [0, L]\n$$\n\n$2$. 测量噪声被建模为均值为 $x$（真实位置）、标准差为 $\\sigma$ 的高斯（正态）分布。给定真实位置 $x$，观测到 $y_i$ 的条件概率是：\n$$\np(y_i | x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(y_i-x)^2}{2\\sigma^2}\\right)\n$$\n潜变量 $x$ 的积分域是势阱的物理范围，即 $[0, L]$。结合这些表达式，每次测量的似然函数为：\n$$\np(y_i | n) = \\int_{0}^{L} \\left[ \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(y_i-x)^2}{2\\sigma^2}\\right) \\right] \\left[ \\frac{2}{L} \\sin^2\\left(\\frac{n \\pi x}{L}\\right) \\right] dx\n$$\n该积分没有简单的闭式解，必须对每对 $(y_i, n)$ 进行数值计算。我们为此使用数值积分法。由于对于给定的测试用例，因子 $\\frac{2}{L\\sqrt{2\\pi}\\sigma}$ 相对于 $n$ 是常数，因此在寻找 argmax 时可以省略它们，从而将成比例的对数后验简化为：\n$$\nLP(n) \\propto \\log p_{\\text{unnorm}}(n) + \\sum_{i=1}^{M} \\log \\left( \\int_{0}^{L} \\exp\\left(-\\frac{(y_i-x)^2}{2\\sigma^2}\\right) \\sin^2\\left(\\frac{n \\pi x}{L}\\right) dx \\right)\n$$\n其中 $p_{\\text{unnorm}}(n)$ 是未归一化的先验。对于均匀先验，$\\log p(n)$ 是常数，可以忽略。对于先验 $p(n) \\propto 1/n^2$，我们使用 $\\log p_{\\text{unnorm}}(n) = -2 \\log n$。\n\n总体算法如下：\n对于每个测试用例：\n$1$. 对于集合 $\\{1, 2, 3, 4, 5\\}$ 中的每个候选整数 $n$：\n    a. 计算对数先验项 $\\log p_{\\text{unnorm}}(n)$。\n    b. 将该 $n$ 的总对数似然初始化为 $0$。\n    c. 对于所提供列表中的每次测量 $y_i$：\n        i. 数值计算积分 $I(y_i, n) = \\int_{0}^{L} \\exp\\left(-\\frac{(y_i-x)^2}{2\\sigma^2}\\right) \\sin^2\\left(\\frac{n \\pi x}{L}\\right) dx$。\n        ii. 将 $\\log(I(y_i, n))$ 加到总对数似然上。\n    d. $n$ 的未归一化对数后验是对数先验项和总对数似然之和。\n$2$. 在计算完所有候选 $n$ 的对数后验之后，找出产生最大对数后验的 $n$ 值。\n$3$. 如有平局，按规定选择最小的 $n$ 值。\n\n对所提供的四个测试用例中的每一个都实施此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian inference problem for the four specified test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Format: (L, sigma, n_candidates, prior_spec, measurements)\n    test_cases = [\n        # Case A\n        (1.0, 0.02, np.array([1, 2, 3, 4, 5]), ('uniform',), \n         np.array([0.151, 0.170, 0.497, 0.512, 0.835, 0.820, 0.505, 0.166, 0.842, 0.158])),\n        # Case B\n        (1.0, 0.005, np.array([1, 2, 3, 4, 5]), ('uniform',), \n         np.array([0.480, 0.514, 0.492, 0.508, 0.501])),\n        # Case C\n        (1.0, 0.15, np.array([1, 2, 3, 4, 5]), ('inv_sq',), \n         np.array([0.10, 0.90, 0.25, 0.75])),\n        # Case D\n        (1.0, 0.03, np.array([1, 2, 3, 4, 5]), ('uniform',), \n         np.array([-0.03, 1.04, 0.24, 0.76, 0.26, 0.50]))\n    ]\n\n    results = []\n\n    for case in test_cases:\n        L, sigma, n_candidates, prior_spec, measurements = case\n        log_posteriors = np.zeros(len(n_candidates))\n\n        for i, n in enumerate(n_candidates):\n            # Calculate log prior\n            log_prior = 0.0\n            if prior_spec[0] == 'inv_sq':\n                # p(n) is proportional to 1/n^2, so log p(n) is proportional to -2*log(n).\n                log_prior = -2.0 * np.log(n)\n            # For uniform prior, log_prior is constant and can be taken as 0 for argmax.\n\n            # Calculate total log likelihood\n            total_log_likelihood = 0.0\n            for y in measurements:\n                # Define the integrand for the marginal likelihood.\n                # Wwe can omit constant factors that do not depend on n.\n                # The integrand is p(y|x) * p(x|n) up to constants.\n                def integrand(x):\n                    # p(x|n) term, proportional to sin^2(n*pi*x/L)\n                    psi_sq_part = np.sin(n * np.pi * x / L)**2\n                    \n                    # p(y|x) term, proportional to exp(-(y-x)^2/(2*sigma^2))\n                    gaussian_part = np.exp(-0.5 * ((y - x) / sigma)**2)\n                    \n                    return gaussian_part * psi_sq_part\n                \n                # Numerically integrate over the well [0, L]\n                integral_val, _ = quad(integrand, 0, L)\n                \n                # Add the log of the integral to the total log likelihood.\n                # If integral_val is 0, its log is -inf, which is correct.\n                if integral_val > 0:\n                    total_log_likelihood += np.log(integral_val)\n                else:\n                    total_log_likelihood += -np.inf\n\n            # Unnormalized log posterior\n            log_posteriors[i] = log_prior + total_log_likelihood\n\n        # Find the n that maximizes the posterior.\n        # Use np.isclose for floating point comparison to handle ties.\n        max_log_post = np.max(log_posteriors)\n        \n        # Check for -inf case (likelihood was zero for all n)\n        if np.isneginf(max_log_post):\n            # This is an edge case, unlikely here. If it happens, any n is equally bad.\n            # The problem asks for the smallest n in case of a tie.\n            best_n = n_candidates[0]\n        else:\n            # Find all indices that are close to the maximum value\n            best_indices = np.where(np.isclose(log_posteriors, max_log_post))[0]\n            # Choose the one corresponding to the smallest n as per the tie-breaking rule.\n            # Since n_candidates is sorted, the first index corresponds to the smallest n.\n            best_n = n_candidates[best_indices[0]]\n            \n        results.append(best_n)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们的最后一个实践将解决追踪运动物体的挑战，这是物理学和工程学许多领域的一项基本任务。你将实现一个贝叶斯滤波器，利用一系列控制指令和带噪声的传感器读数来估计一个机器人在走廊中移动的位置 。这个练习将引导你体验递归估计中优美的“预测-校正”循环，为理解著名的卡尔曼滤波器背后的原理提供一次亲身实践。",
            "id": "2376024",
            "problem": "您的任务是实现一个一维贝叶斯滤波器，利用带噪声的距离传感器读数来跟踪机器人在笔直走廊中的位置。物理状态是沿一个轴的位置。动力学被建模为带有加性高斯过程噪声的离散时间运动学模型，而测量则被建模为带有加性高斯噪声的位置的含噪观测值。所有距离都必须以米为单位。对于每个测试用例，您的程序必须在处理完给定的控制输入和测量序列后，计算最终的后验均值位置和最终的后验方差。最终答案必须以米表示后验均值，以平方米表示后验方差，并四舍五入到小数点后六位。\n\n请使用以下物理和统计建模假设作为基本基础：\n- 时间步 $t$ 的隐藏状态是位置 $x_t$（单位：米）。\n- 控制输入 $u_t$ 是时间步 $t$ 的指令位移（单位：米）。\n- 过程模型为 $x_t = x_{t-1} + u_t + w_t$，其中 $w_t \\sim \\mathcal{N}(0, \\sigma_q^2)$ 模拟了未建模的扰动和执行不确定性，$\\sigma_q$ 的单位为米。\n- 测量模型为 $z_t = x_t + v_t$，其中 $v_t \\sim \\mathcal{N}(0, \\sigma_r^2)$ 模拟了传感器噪声，$\\sigma_r$ 的单位为米。\n- 在 $t=0$ 时的先验是高斯分布 $x_0 \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$，其中 $\\mu_0$ 和 $\\sigma_0$ 的单位均为米。\n\n您必须从贝叶斯法则以及高斯分布在线性变换和乘积下的性质来推导您的算法。除了这些基本原理外，不要假设任何捷径公式。对于每个测试用例，您的实现必须在处理完整个控制和测量序列后，计算出最终的后验均值 $\\mu_T$（单位：米）和最终的后验方差 $\\sigma_T^2$（单位：平方米）。\n\n测试套件：\n对于每个测试用例，您将获得 $(\\mu_0, \\sigma_0, \\sigma_q, \\sigma_r, \\{u_t\\}_{t=1}^T, \\{z_t\\}_{t=1}^T)$，其中所有距离单位为米，标准差单位也为米。对于每个案例，请按顺序对所有 $T$ 个步骤应用贝叶斯滤波器，并返回最终的后验均值和方差。\n\n- 案例1（一般运动，中等噪声）：\n  - 初始先验：$\\mu_0 = 0.0$，$\\sigma_0 = 1.5$。\n  - 噪声尺度：$\\sigma_q = 0.4$，$\\sigma_r = 0.8$。\n  - 控制：$[0.9, 1.1, 1.0, 0.95, 1.05]$。\n  - 测量：$[0.7, 2.1, 2.9, 3.8, 5.1]$。\n\n- 案例2（静止机器人，精确传感器，不确定先验）：\n  - 初始先验：$\\mu_0 = 2.0$，$\\sigma_0 = 3.0$。\n  - 噪声尺度：$\\sigma_q = 0.5$，$\\sigma_r = 0.2$。\n  - 控制：$[0.0, 0.0, 0.0]$。\n  - 测量：$[2.2, 1.9, 2.1]$。\n\n- 案例3（运动机器人，高过程噪声，精确传感器）：\n  - 初始先验：$\\mu_0 = -1.0$，$\\sigma_0 = 0.5$。\n  - 噪声尺度：$\\sigma_q = 1.5$，$\\sigma_r = 0.4$。\n  - 控制：$[0.5, 0.5, 0.5, 0.5]$。\n  - 测量：$[-0.6, 0.2, 1.1, 2.3]$。\n\n- 案例4（运动机器人，低过程噪声，非常嘈杂的传感器）：\n  - 初始先验：$\\mu_0 = 5.0$，$\\sigma_0 = 0.3$。\n  - 噪声尺度：$\\sigma_q = 0.2$，$\\sigma_r = 3.0$。\n  - 控制：$[-0.5, -0.5, -0.5]$。\n  - 测量：$[4.6, 4.0, 3.1]$。\n\n要求输出：\n- 对于每个案例，计算并返回两个浮点数：最终的后验均值 $\\mu_T$（单位：米）和最终的后验方差 $\\sigma_T^2$（单位：平方米），两者均四舍五入到小数点后六位。\n- 您的程序应生成单行输出，其中包含所有按顺序排列的结果，形式为方括号内以逗号分隔的列表：$\\left[\\mu_T^{(1)}, \\sigma_T^{2(1)}, \\mu_T^{(2)}, \\sigma_T^{2(2)}, \\mu_T^{(3)}, \\sigma_T^{2(3)}, \\mu_T^{(4)}, \\sigma_T^{2(4)}\\right]$。\n\n此问题不涉及角度单位。请确保实现是通用的，从第一性原理推导得出，并且所有报告的距离单位为米，方差单位为平方米。不应读取任何用户输入；程序必须按原样运行，并以上述指定格式打印四个案例的最终结果。",
            "solution": "问题陈述经评估有效。它构成了计算物理和状态估计领域中一个适定的、有科学依据的问题。所有模型、参数和边界条件都得到了明确的规定，从而可以推导和实现一个唯一的、可验证的解。该问题要求为一个带有高斯噪声的线性系统实现一维贝叶斯滤波器，这即是经典的卡尔曼滤波器。\n\n该解法源于递归贝叶斯估计的基本原理。系统的状态是机器人的一维位置 $x_t$。关于此状态的置信度由一个概率分布表示。鉴于过程和测量模型是线性的，并且所有噪声源都是高斯的，初始的高斯置信度将在所有后续时间步中作为高斯分布传播。一个高斯分布完全由其均值 $\\mu$ 和方差 $\\sigma^2$ 描述。因此，问题简化为递归地更新这两个参数。\n\n对于每个离散时间增量，递归更新过程包括两个连续的步骤：一个**预测**步骤，之后是一个**校正**步骤。\n\n设在时间 $t-1$ 时，给定截至该点的所有测量值，状态的后验分布为 $p(x_{t-1}|z_{1:t-1}) = \\mathcal{N}(x_{t-1}; \\mu_{t-1}, \\sigma_{t-1}^2)$。在 $t=0$ 时的初始状态由先验分布 $p(x_0) = \\mathcal{N}(x_0; \\mu_0, \\sigma_0^2)$ 给出。\n\n**1. 预测步骤（时间更新）**\n\n此步骤根据在 $t-1$ 时的分布和控制输入 $u_t$ 来预测在时间 $t$ 的状态分布。这产生了当前时间步的先验分布 $p(x_t|z_{1:t-1})$。该分布通过应用全概率定律，对 $x_{t-1}$ 进行边缘化得到：\n$$p(x_t|z_{1:t-1}) = \\int p(x_t|x_{t-1}, u_t) p(x_{t-1}|z_{1:t-1}) dx_{t-1}$$\n过程模型为 $x_t = x_{t-1} + u_t + w_t$，带有高斯过程噪声 $w_t \\sim \\mathcal{N}(0, \\sigma_q^2)$。这定义了转移概率为 $p(x_t|x_{t-1}, u_t) = \\mathcal{N}(x_t; x_{t-1} + u_t, \\sigma_q^2)$。我们实际上是在对两个高斯分布进行卷积。两个独立高斯随机变量的和也是一个高斯随机变量。\n\n预测分布的均值，记为 $\\bar{\\mu}_t$，是构成变量均值的和：\n$$ \\bar{\\mu}_t = E[x_{t-1} + u_t + w_t] = E[x_{t-1}] + u_t + E[w_t] = \\mu_{t-1} + u_t + 0 $$\n$$ \\bar{\\mu}_t = \\mu_{t-1} + u_t $$\n预测分布的方差 $\\bar{\\sigma}_t^2$，是方差的和，因为变量是独立的：\n$$ \\bar{\\sigma}_t^2 = Var(x_{t-1} + u_t + w_t) = Var(x_{t-1}) + Var(u_t) + Var(w_t) = \\sigma_{t-1}^2 + 0 + \\sigma_q^2 $$\n$$ \\bar{\\sigma}_t^2 = \\sigma_{t-1}^2 + \\sigma_q^2 $$\n因此，预测的置信度，或时间 $t$ 的先验，是 $p(x_t|z_{1:t-1}) = \\mathcal{N}(x_t; \\bar{\\mu}_t, \\bar{\\sigma}_t^2)$。\n\n**2. 校正步骤（测量更新）**\n\n此步骤通过融合新的测量值 $z_t$ 来修正预测的置信度。应用贝叶斯法则来计算后验分布 $p(x_t|z_{1:t})$：\n$$ p(x_t|z_{1:t}) = p(x_t|z_t, z_{1:t-1}) = \\frac{p(z_t|x_t, z_{1:t-1}) p(x_t|z_{1:t-1})}{p(z_t|z_{1:t-1})} $$\n假设在给定当前状态 $x_t$ 的条件下，测量值 $z_t$ 与过去的测量值条件独立，则上式简化为：\n$$ p(x_t|z_{1:t}) \\propto p(z_t|x_t) p(x_t|z_{1:t-1}) $$\n后验分布与似然和先验的乘积成正比。测量模型是 $z_t = x_t + v_t$，其中 $v_t \\sim \\mathcal{N}(0, \\sigma_r^2)$。因此，似然函数为 $p(z_t|x_t) = \\mathcal{N}(z_t; x_t, \\sigma_r^2)$。作为 $x_t$ 的函数，这与一个以 $z_t$ 为中心的高斯分布成正比，即 $\\mathcal{N}(x_t; z_t, \\sigma_r^2)$。\n\n我们必须找到后验分布 $\\mathcal{N}(x_t; \\mu_t, \\sigma_t^2)$ 的参数，该分布由先验 $\\mathcal{N}(x_t; \\bar{\\mu}_t, \\bar{\\sigma}_t^2)$ 和似然 $\\mathcal{N}(x_t; z_t, \\sigma_r^2)$ 的乘积得出。两个高斯分布乘积的均值和方差由以下公式给出：\n$$ \\frac{1}{\\sigma_t^2} = \\frac{1}{\\bar{\\sigma}_t^2} + \\frac{1}{\\sigma_r^2} \\implies \\sigma_t^2 = \\frac{\\bar{\\sigma}_t^2 \\sigma_r^2}{\\bar{\\sigma}_t^2 + \\sigma_r^2} $$\n$$ \\mu_t = \\sigma_t^2 \\left( \\frac{\\bar{\\mu}_t}{\\bar{\\sigma}_t^2} + \\frac{z_t}{\\sigma_r^2} \\right) $$\n这些是高斯融合的标准方程。为了获得更好的数值稳定性和概念上的洞察力，它们通常使用卡尔曼增益 $K_t$ 重写：\n$$ K_t = \\frac{\\bar{\\sigma}_t^2}{\\bar{\\sigma}_t^2 + \\sigma_r^2} $$\n卡尔曼增益 $K_t \\in [0, 1]$ 表示给予新测量值的相对权重。高增益更信任测量值，而低增益更信任预测值。使用 $K_t$，后验均值 $\\mu_t$ 和方差 $\\sigma_t^2$ 的更新方程为：\n$$ \\mu_t = \\bar{\\mu}_t + K_t (z_t - \\bar{\\mu}_t) $$\n$$ \\sigma_t^2 = (1 - K_t) \\bar{\\sigma}_t^2 $$\n算法从初始状态 $(\\mu_0, \\sigma_0^2)$ 开始，并对每个时间步 $t=1, \\dots, T$ 递归地应用预测和校正步骤。问题提供了标准差 $\\sigma_0, \\sigma_q, \\sigma_r$，必须将它们平方以得到这些方程所需的方差。最终值 $(\\mu_T, \\sigma_T^2)$ 代表解。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _run_single_filter(params):\n    \"\"\"\n    Runs the 1D Kalman filter for a single test case.\n    \n    Args:\n        params (tuple): A tuple containing all parameters for the test case:\n                        (mu0, sigma0, sigma_q, sigma_r, controls, measurements).\n    \n    Returns:\n        tuple: A tuple containing the final posterior mean and variance.\n    \"\"\"\n    mu0, sigma0, sigma_q, sigma_r, controls, measurements = params\n    \n    # Initialize state mean and variance. The equations use variance, so we\n    # must square the standard deviations provided in the problem statement.\n    mu = float(mu0)\n    sigma_sq = float(sigma0)**2\n    \n    # Pre-calculate noise variances\n    sigma_q_sq = float(sigma_q)**2\n    sigma_r_sq = float(sigma_r)**2\n    \n    # Iterate through each time step, applying the filter equations\n    for u, z in zip(controls, measurements):\n        # 1. Prediction Step (Time Update)\n        # Predict the next state mean based on the control input.\n        mu_bar = mu + u\n        # Predict the next state variance by adding the process noise variance.\n        sigma_sq_bar = sigma_sq + sigma_q_sq\n        \n        # 2. Correction Step (Measurement Update)\n        # Compute the Kalman gain. This term balances the weight between the\n        # prediction and the measurement.\n        kalman_gain = sigma_sq_bar / (sigma_sq_bar + sigma_r_sq)\n        \n        # Update the state mean estimate using the measurement. The term\n        # (z - mu_bar) is the measurement innovation or residual.\n        mu = mu_bar + kalman_gain * (z - mu_bar)\n        \n        # Update the state variance (uncertainty).\n        sigma_sq = (1 - kalman_gain) * sigma_sq_bar\n        \n    return mu, sigma_sq\n\ndef solve():\n    \"\"\"\n    Defines the test cases, runs the filter for each, and prints the results\n    in the specified format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (mu0, sigma0, sigma_q, sigma_r, controls, measurements)\n    test_cases = [\n        # Case 1: General motion, moderate noise\n        (0.0, 1.5, 0.4, 0.8, [0.9, 1.1, 1.0, 0.95, 1.05], [0.7, 2.1, 2.9, 3.8, 5.1]),\n        # Case 2: Stationary robot, precise sensor, uncertain prior\n        (2.0, 3.0, 0.5, 0.2, [0.0, 0.0, 0.0], [2.2, 1.9, 2.1]),\n        # Case 3: Moving robot, high process noise, accurate sensor\n        (-1.0, 0.5, 1.5, 0.4, [0.5, 0.5, 0.5, 0.5], [-0.6, 0.2, 1.1, 2.3]),\n        # Case 4: Moving robot, low process noise, very noisy sensor\n        (5.0, 0.3, 0.2, 3.0, [-0.5, -0.5, -0.5], [4.6, 4.0, 3.1]),\n    ]\n\n    results = []\n    # Process each test case\n    for case in test_cases:\n        mu_final, sigma_sq_final = _run_single_filter(case)\n        \n        # Append the final mean and variance, formatted to six decimal places, to the results list.\n        results.append(f\"{mu_final:.6f}\")\n        results.append(f\"{sigma_sq_final:.6f}\")\n\n    # Final print statement must produce only the specified single-line format.\n    print(f\"[{','.join(results)}]\")\n\n# Execute the solver\nsolve()\n```"
        }
    ]
}