{
    "hands_on_practices": [
        {
            "introduction": "Beyond binary classification, the perceptron serves as a powerful tool for function approximation. This first practice treats the perceptron as a physicist's regression model, tasked with learning the energy function of a simple harmonic oscillator from its position and velocity. By using a feature map that linearizes the problem, this exercise demonstrates how a simple linear neuron can recover the underlying physical parameters ($m$ and $k$) and introduces the momentum-based optimizer, a crucial technique for accelerating convergence in complex energy landscapes .",
            "id": "2425757",
            "problem": "You are asked to implement and analyze a single-neuron perceptron trained on deterministic physics data using a momentum-based optimizer. The perceptron uses a linear (identity) activation function. The training objective is to recover the energy of a one-dimensional harmonic oscillator from measured position and velocity by fitting a linear model over physically motivated features.\n\nData and model specification:\n\n- Consider a one-dimensional harmonic oscillator with mass $m$ and spring constant $k$, with energy given by\n$$\nE(x,v) = \\tfrac{1}{2} m v^2 + \\tfrac{1}{2} k x^2 \\, .\n$$\n- Use the fixed physical parameters $m = 1\\,\\mathrm{kg}$ and $k = 4\\,\\mathrm{N/m}$.\n- Construct a deterministic training set from the Cartesian grid\n$$\n\\mathcal{X} = \\{-1.0\\,\\mathrm{m}, -0.5\\,\\mathrm{m}, 0.0\\,\\mathrm{m}, 0.5\\,\\mathrm{m}, 1.0\\,\\mathrm{m}\\},\\quad\n\\mathcal{V} = \\{-1.0\\,\\mathrm{m/s}, 0.0\\,\\mathrm{m/s}, 1.0\\,\\mathrm{m/s}\\} \\, ,\n$$\nforming all pairs $(x,v) \\in \\mathcal{X} \\times \\mathcal{V}$. For each pair, compute the target energy $E(x,v)$ in joules.\n- Use the feature map\n$$\n\\phi(x,v) = \\begin{bmatrix} x^2 \\\\ v^2 \\\\ 1 \\end{bmatrix},\n$$\nand a perceptron with identity activation that predicts\n$$\n\\hat{E}(x,v; \\mathbf{w}) = \\mathbf{w}^\\top \\phi(x,v) \\, ,\n$$\nwhere $\\mathbf{w} \\in \\mathbb{R}^3$ is the trainable weight vector. The model has no separate bias beyond the constant feature in $\\phi$.\n\nCost function and optimization:\n\n- Use the mean squared error cost with a conventional factor of one-half:\n$$\nC(\\mathbf{w}) = \\frac{1}{2N}\\sum_{i=1}^{N}\\left(\\hat{E}_i - E_i\\right)^2 \\, ,\n$$\nwhere $N$ is the total number of samples, $\\hat{E}_i = \\mathbf{w}^\\top \\phi(x_i,v_i)$, and $E_i = E(x_i,v_i)$.\n- Train $\\mathbf{w}$ via the momentum (inertial) update rule\n$$\n\\mathbf{w}_{t+1} = \\mathbf{w}_{t} - \\eta \\nabla C(\\mathbf{w}_{t}) + \\beta \\left(\\mathbf{w}_{t} - \\mathbf{w}_{t-1}\\right),\n$$\nwith learning rate $\\eta > 0$ and momentum coefficient $\\beta \\in [0,1)$.\n- Initialize with $\\mathbf{w}_0 = \\mathbf{0}$ and $\\mathbf{w}_{-1} = \\mathbf{w}_0$ so that the initial inertial term vanishes.\n\nStopping rule and numerical parameters:\n\n- Use the termination criterion $C(\\mathbf{w}_t) \\le \\varepsilon$ with tolerance $\\varepsilon = 10^{-6}\\,\\mathrm{J}^2$ (joule squared). If this condition is not met by a maximum of $T_{\\max} = 20000$ iterations, terminate and consider the run not converged.\n\nTest suite:\n\nEvaluate the number of iterations required to meet the stopping rule under the following parameter sets $(\\eta,\\beta)$:\n\n- Case A: $(\\eta,\\beta) = (0.05, 0.00)$.\n- Case B: $(\\eta,\\beta) = (0.05, 0.50)$.\n- Case C: $(\\eta,\\beta) = (0.05, 0.90)$.\n- Case D: $(\\eta,\\beta) = (0.05, 0.99)$.\n\nAnswer specification:\n\n- For each case, produce a single integer: the smallest iteration index $t \\in \\{0,1,2,\\dots\\}$ for which $C(\\mathbf{w}_t) \\le \\varepsilon$. If the algorithm does not satisfy the tolerance within $T_{\\max}$ iterations, output the integer $-1$ for that case.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order A, B, C, D.\n\nPhysical and numerical units:\n\n- The energy targets $E(x,v)$ must be computed in joules. The cost $C(\\mathbf{w})$ must be interpreted in joule squared. The final reported iteration counts are unitless integers.",
            "solution": "The problem as stated is subjected to validation and is found to be valid. It is scientifically grounded, mathematically well-posed, and all parameters are specified unambiguously. It describes a standard linear regression problem cast in the language of neural networks and computational physics, for which a unique optimal solution exists. We will therefore proceed with a complete derivation and implementation.\n\nThe objective is to train a single-neuron perceptron to learn the energy $E$ of a one-dimensional harmonic oscillator. The energy is given by the function:\n$$\nE(x,v) = \\frac{1}{2} k x^2 + \\frac{1}{2} m v^2\n$$\nwhere $x$ is position, $v$ is velocity, $m$ is mass, and $k$ is the spring constant. The given physical parameters are $m = 1\\,\\mathrm{kg}$ and $k = 4\\,\\mathrm{N/m}$.\n\nThe perceptron model uses a linear activation function and predicts the energy as a weighted sum of features:\n$$\n\\hat{E}(x,v; \\mathbf{w}) = \\mathbf{w}^\\top \\phi(x,v)\n$$\nThe feature vector $\\phi(x,v)$ is defined as:\n$$\n\\phi(x,v) = \\begin{bmatrix} x^2 \\\\ v^2 \\\\ 1 \\end{bmatrix}\n$$\nWith this choice of features, the model's prediction is $\\hat{E} = w_1 x^2 + w_2 v^2 + w_3$. The model is exactly expressive for the true energy function. By comparing the true energy $E = (\\frac{k}{2}) x^2 + (\\frac{m}{2}) v^2 + 0$ with the model, we can see that a perfect fit is achieved when the weight vector $\\mathbf{w} = [w_1, w_2, w_3]^\\top$ equals the true parameter vector $\\mathbf{w}^*$:\n$$\n\\mathbf{w}^* = \\begin{bmatrix} k/2 \\\\ m/2 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 4/2 \\\\ 1/2 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 2.0 \\\\ 0.5 \\\\ 0.0 \\end{bmatrix}\n$$\nThe training process aims to find this optimal weight vector $\\mathbf{w}^*$.\n\nThe training data consists of $N=15$ samples, generated from the Cartesian product of positions $\\mathcal{X} = \\{-1.0, -0.5, 0.0, 0.5, 1.0\\}\\,\\mathrm{m}$ and velocities $\\mathcal{V} = \\{-1.0, 0.0, 1.0\\}\\,\\mathrm{m/s}$. We can assemble a design matrix $\\Phi$ of size $N \\times 3$ and a target vector $\\mathbf{E}$ of size $N \\times 1$. The $i$-th row of $\\Phi$ is the feature vector $\\phi(x_i, v_i)^\\top$, and the $i$-th element of $\\mathbf{E}$ is the true energy $E(x_i, v_i)$.\n\nThe cost function to be minimized is the mean squared error (MSE):\n$$\nC(\\mathbf{w}) = \\frac{1}{2N}\\sum_{i=1}^{N}\\left(\\mathbf{w}^\\top \\phi_i - E_i\\right)^2 = \\frac{1}{2N} (\\Phi \\mathbf{w} - \\mathbf{E})^\\top (\\Phi \\mathbf{w} - \\mathbf{E})\n$$\nThis is a convex function of $\\mathbf{w}$, so gradient-based optimization methods are guaranteed to converge to the global minimum, which corresponds to $\\mathbf{w}^*$. The gradient of the cost function with respect to the weights $\\mathbf{w}$ is required for the optimization update rule. It is calculated as:\n$$\n\\nabla_{\\mathbf{w}} C(\\mathbf{w}) = \\frac{1}{2N} \\nabla_{\\mathbf{w}} \\left( (\\Phi \\mathbf{w})^\\top (\\Phi \\mathbf{w}) - 2 (\\Phi \\mathbf{w})^\\top \\mathbf{E} + \\mathbf{E}^\\top \\mathbf{E} \\right)\n$$\n$$\n\\nabla_{\\mathbf{w}} C(\\mathbf{w}) = \\frac{1}{2N} \\left( 2 \\Phi^\\top \\Phi \\mathbf{w} - 2 \\Phi^\\top \\mathbf{E} \\right) = \\frac{1}{N} \\Phi^\\top (\\Phi \\mathbf{w} - \\mathbf{E})\n$$\nThe optimization is performed using the momentum update rule, which is a variant of gradient descent designed to accelerate convergence, especially in ravines of the cost surface. The weights are updated at each iteration $t$ according to:\n$$\n\\mathbf{w}_{t+1} = \\mathbf{w}_{t} - \\eta \\nabla C(\\mathbf{w}_{t}) + \\beta (\\mathbf{w}_{t} - \\mathbf{w}_{t-1})\n$$\nHere, $\\eta$ is the learning rate and $\\beta$ is the momentum coefficient. The initial conditions are $\\mathbf{w}_0 = \\mathbf{0}$ and $\\mathbf{w}_{-1} = \\mathbf{w}_0 = \\mathbf{0}$, ensuring the momentum term is zero for the first iteration.\n\nThe algorithm proceeds as follows for each given parameter set $(\\eta, \\beta)$:\n1. Initialize weights $\\mathbf{w}_0 = [0,0,0]^\\top$ and $\\mathbf{w}_{-1} = [0,0,0]^\\top$.\n2. Calculate the initial cost $C(\\mathbf{w}_0)$. If $C(\\mathbf{w}_0) \\le \\varepsilon = 10^{-6}$, the process terminates with $0$ iterations.\n3. For each iteration $t$ from $1$ to $T_{\\max} = 20000$:\n    a. Calculate the gradient $\\nabla C(\\mathbf{w}_{t-1})$ using the current weights $\\mathbf{w}_{t-1}$.\n    b. Compute the next weight vector $\\mathbf{w}_{t}$ using the momentum update rule with $\\mathbf{w}_{t-1}$ and $\\mathbf{w}_{t-2}$. Note the index shift for implementation: we use $\\mathbf{w}_{\\text{current}}$ and $\\mathbf{w}_{\\text{previous}}$ to compute $\\mathbf{w}_{\\text{next}}$.\n    c. Calculate the cost $C(\\mathbf{w}_t)$ with the newly computed weights.\n    d. If $C(\\mathbf{w}_t) \\le \\varepsilon$, the algorithm has converged. The number of iterations is recorded as $t$, and the process for the current case terminates.\n4. If the loop completes without the cost falling below $\\varepsilon$, the run is considered not converged, and the result is recorded as $-1$.\n\nThis procedure is executed for each of the four specified $(\\eta, \\beta)$ pairs to determine the number of iterations required for convergence.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and analyzes a single-neuron perceptron trained on deterministic physics data\n    using a momentum-based optimizer to recover the energy of a harmonic oscillator.\n    \"\"\"\n    #\n    # --- Problem Constants and Setup ---\n    #\n    \n    # Physical parameters\n    M_KG = 1.0  # Mass in kg\n    K_N_PER_M = 4.0  # Spring constant in N/m\n    \n    # Numerical parameters\n    TOLERANCE_EPSILON = 1e-6  # Convergence tolerance in J^2\n    MAX_ITERATIONS = 20000    # Maximum number of iterations\n\n    #\n    # --- Data Generation ---\n    #\n\n    # Define the Cartesian grid for position and velocity\n    x_vals = np.array([-1.0, -0.5, 0.0, 0.5, 1.0])\n    v_vals = np.array([-1.0, 0.0, 1.0])\n\n    # Create all pairs (x, v) from the grid\n    positions, velocities = np.meshgrid(x_vals, v_vals)\n    positions_flat = positions.flatten()\n    velocities_flat = velocities.flatten()\n\n    num_samples = len(positions_flat)\n\n    # Construct the feature matrix (design matrix) Phi\n    # Features are [x^2, v^2, 1]\n    phi_matrix = np.vstack([\n        positions_flat**2,\n        velocities_flat**2,\n        np.ones(num_samples)\n    ]).T\n\n    # Construct the target energy vector E\n    # E = 0.5 * k * x^2 + 0.5 * m * v^2\n    energy_vector = (0.5 * K_N_PER_M * positions_flat**2 + 0.5 * M_KG * velocities_flat**2).reshape(-1, 1)\n\n    #\n    # --- Optimization ---\n    #\n\n    # Test suite parameters (eta, beta)\n    test_cases = [\n        (0.05, 0.00),  # Case A\n        (0.05, 0.50),  # Case B\n        (0.05, 0.90),  # Case C\n        (0.05, 0.99),  # Case D\n    ]\n\n    results = []\n\n    def calculate_cost(w, phi, E, n):\n        \"\"\"Calculates the mean squared error cost.\"\"\"\n        error = phi @ w - E\n        return (0.5 / n) * np.sum(error**2)\n\n    def calculate_gradient(w, phi, E, n):\n        \"\"\"Calculates the gradient of the cost function.\"\"\"\n        error = phi @ w - E\n        return (1.0 / n) * phi.T @ error\n\n    # Iterate through each test case\n    for eta, beta in test_cases:\n        # Initialize weights for the current run\n        # w_current corresponds to w_t, w_previous corresponds to w_{t-1}\n        w_current = np.zeros((3, 1))\n        w_previous = np.zeros((3, 1))\n\n        # Check cost at initial state (t=0)\n        cost = calculate_cost(w_current, phi_matrix, energy_vector, num_samples)\n        if cost = TOLERANCE_EPSILON:\n            results.append(0)\n            continue\n            \n        converged = False\n        # Loop for iterations t = 1, 2, ..., T_max\n        for t in range(1, MAX_ITERATIONS + 1):\n            # Calculate gradient at the current weights (w_{t} in the problem notation)\n            grad = calculate_gradient(w_current, phi_matrix, energy_vector, num_samples)\n            \n            # Calculate the next weight vector (w_{t+1} in problem notation)\n            w_next = w_current - eta * grad + beta * (w_current - w_previous)\n            \n            # Update weights for the next iteration\n            w_previous = w_current\n            w_current = w_next\n            \n            # Check for convergence with the new weights\n            cost = calculate_cost(w_current, phi_matrix, energy_vector, num_samples)\n            if cost = TOLERANCE_EPSILON:\n                results.append(t)\n                converged = True\n                break\n        \n        # If the loop finished without converging\n        if not converged:\n            results.append(-1)\n            \n    # Print the final results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "An abstract mathematical model is only as good as its connection to physical reality. This exercise moves beyond the idealized perceptron to consider a more realistic scenario where the neuron's output is corrupted by thermal noise, a common issue in any hardware implementation. You will analytically investigate how this noise impacts the perceptron's decision-making reliability and discover how a saturating activation function like the hyperbolic tangent ($\\tanh$) can provide inherent resilience against large fluctuations compared to a simple linear response .",
            "id": "2425788",
            "problem": "A binary perceptron is defined by a weight vector $ \\mathbf{w} \\in \\mathbb{R}^d $ and zero bias. For an input $ \\mathbf{x} \\in \\mathbb{R}^d $, the internal field is $ z = \\mathbf{w} \\cdot \\mathbf{x} $. The device produces an analog activation $ a = g(z) $ using one of two activation functions: the identity function $ g_{\\text{id}}(z) = z $ or the hyperbolic tangent function $ g_{\\tanh}(z) = \\tanh(z) $. To model thermal fluctuations in a physical hardware implementation, a zero-mean Gaussian noise $ \\eta \\sim \\mathcal{N}(0,\\sigma^2) $ is added directly to the activation output, producing a fluctuating analog value $ \\tilde{a} = a + \\eta $. The final digital decision is obtained by thresholding at zero, $ \\hat{y} = \\operatorname{sign}(\\tilde{a}) $, where $ \\operatorname{sign}(u) = +1 $ if $ u > 0 $ and $ \\operatorname{sign}(u) = -1 $ if $ u  0 $. The ground-truth label for an input $ \\mathbf{x} $ is defined by the ideal noiseless threshold, $ y = \\operatorname{sign}(z) $. All inputs considered below satisfy $ z \\neq 0 $ so that $ y $ is well-defined.\n\nFor a finite set of inputs $ \\{\\mathbf{x}_i\\}_{i=1}^N $ and a specified activation $ g $ and noise standard deviation $ \\sigma $, define the expected misclassification rate as the expectation over the thermal noise of the event $ \\hat{y} \\neq y $, averaged over the dataset:\n$$ R = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{P}\\!\\left( \\operatorname{sign}\\!\\left(g(\\mathbf{w}\\cdot \\mathbf{x}_i) + \\eta \\right) \\neq \\operatorname{sign}\\!\\left(\\mathbf{w}\\cdot \\mathbf{x}_i\\right) \\right). $$\n\nYour task is to write a complete, runnable program that computes $ R $ for each of the following test cases using the precise mathematical definition above. No randomness beyond the specified thermal noise model is permitted in the computation of $ R $.\n\nUse the following shared parameters for all test cases:\n- Dimension $ d = 2 $.\n- Weight vector $ \\mathbf{w} = (1.0, -1.0) $.\n- Dataset of $ N = 4 $ inputs:\n  - $ \\mathbf{x}_1 = (3.0, 0.0) $,\n  - $ \\mathbf{x}_2 = (1.1, 0.9) $,\n  - $ \\mathbf{x}_3 = (0.2, 0.5) $,\n  - $ \\mathbf{x}_4 = (-1.5, 1.0) $.\n- Activations:\n  - Identity: $ g_{\\text{id}}(z) = z $,\n  - Hyperbolic tangent: $ g_{\\tanh}(z) = \\tanh(z) $.\n- Noise model: $ \\eta \\sim \\mathcal{N}(0,\\sigma^2) $ with independent draws for each evaluation in the definition of the expectation. Angles are not used, so no angle unit applies. There are no physical units in the inputs or outputs.\n\nTest suite:\n- Case $ 1 $: $ g = g_{\\text{id}} $, $ \\sigma = 0.2 $.\n- Case $ 2 $: $ g = g_{\\tanh} $, $ \\sigma = 0.2 $.\n- Case $ 3 $: $ g = g_{\\text{id}} $, $ \\sigma = 0.0 $.\n- Case $ 4 $: $ g = g_{\\tanh} $, $ \\sigma = 5.0 $.\n\nThe required output for your program is a single line containing a list of four floating-point numbers $ [R_1, R_2, R_3, R_4] $, where $ R_k $ is the expected misclassification rate for Case $ k $. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $ [r_1,r_2,r_3,r_4] $). The values must be computed exactly from the definitions above, without Monte Carlo sampling.",
            "solution": "The problem statement submitted for analysis is deemed valid. It is scientifically grounded, well-posed, objective, and provides all necessary information for a unique, verifiable solution. The model of a perceptron with Gaussian noise added to the activation is a standard and simplified representation of physical computational devices, and the mathematical formulation is precise. The provided data are self-consistent; specifically, the internal field $z_i = \\mathbf{w} \\cdot \\mathbf{x}_i$ is non-zero for all inputs, ensuring the ground-truth label $y_i = \\operatorname{sign}(z_i)$ is well-defined. We may therefore proceed with the derivation and computation.\n\nThe objective is to compute the expected misclassification rate $R$ for a given dataset, defined as:\n$$ R = \\frac{1}{N} \\sum_{i=1}^{N} P_i $$\nwhere $P_i$ is the probability of misclassification for a single input $\\mathbf{x}_i$. The misclassification event is $\\hat{y}_i \\neq y_i$, where $y_i = \\operatorname{sign}(z_i)$ is the true label derived from the internal field $z_i = \\mathbf{w} \\cdot \\mathbf{x}_i$, and $\\hat{y}_i = \\operatorname{sign}(g(z_i) + \\eta)$ is the predicted label. The noise $\\eta$ is a random variable drawn from a normal distribution $\\mathcal{N}(0, \\sigma^2)$.\n\nLet us define the activation as $a_i = g(z_i)$. The misclassification condition is $\\operatorname{sign}(a_i + \\eta) \\neq y_i$. Both activation functions provided, $g_{\\text{id}}(z)=z$ and $g_{\\tanh}(z)=\\tanh(z)$, are monotonically increasing and odd, which implies that $\\operatorname{sign}(g(z_i)) = \\operatorname{sign}(z_i)$ for any $z_i \\neq 0$. Therefore, we have $\\operatorname{sign}(a_i) = y_i$.\n\nWe analyze the misclassification probability $P_i$ by considering two cases based on the sign of $z_i$.\n\nCase 1: $z_i > 0$.\nIn this case, the true label is $y_i = +1$. Since $\\operatorname{sign}(a_i) = y_i$, we have $a_i > 0$. Misclassification occurs if the noisy activation is negative:\n$$ a_i + \\eta  0 \\implies \\eta  -a_i $$\nThe probability of this event is given by the cumulative distribution function (CDF) of the noise distribution $\\mathcal{N}(0, \\sigma^2)$, which we denote $\\Phi_{\\sigma}$.\n$$ P_i = \\mathbb{P}(\\eta  -a_i) = \\Phi_{\\sigma}(-a_i) $$\nLet $\\Phi$ be the CDF of the standard normal distribution $\\mathcal{N}(0,1)$. By standardizing the variable, we find:\n$$ P_i = \\Phi\\left(\\frac{-a_i - 0}{\\sigma}\\right) = \\Phi\\left(\\frac{-a_i}{\\sigma}\\right) $$\nSince $a_i > 0$ in this case, we can write $a_i = |a_i|$, and the probability is $P_i = \\Phi(-|a_i|/\\sigma)$.\n\nCase 2: $z_i  0$.\nHere, the true label is $y_i = -1$, and consequently $a_i  0$. Misclassification occurs if the noisy activation is positive:\n$$ a_i + \\eta > 0 \\implies \\eta > -a_i $$\nThe probability is:\n$$ P_i = \\mathbb{P}(\\eta > -a_i) = 1 - \\mathbb{P}(\\eta \\le -a_i) = 1 - \\Phi_{\\sigma}(-a_i) = 1 - \\Phi\\left(\\frac{-a_i}{\\sigma}\\right) $$\nUsing the symmetry property of the standard normal CDF, $\\Phi(x) = 1 - \\Phi(-x)$, we can rewrite this as:\n$$ P_i = \\Phi\\left(\\frac{a_i}{\\sigma}\\right) $$\nSince $a_i  0$ in this case, we have $a_i = -|a_i|$, so the probability becomes $P_i = \\Phi(-|a_i|/\\sigma)$.\n\nBoth cases yield the identical expression for the misclassification probability:\n$$ P_i = \\Phi\\left(\\frac{-|a_i|}{\\sigma}\\right) = \\Phi\\left(\\frac{-|g(z_i)|}{\\sigma}\\right) $$\nThis unified formula is valid for any $\\sigma > 0$. For the special case where $\\sigma = 0$, the noise $\\eta$ is deterministically zero. The predicted label is $\\hat{y}_i = \\operatorname{sign}(g(z_i))$. As established, $\\operatorname{sign}(g(z_i)) = \\operatorname{sign}(z_i) = y_i$, so $\\hat{y}_i = y_i$. The misclassification probability $P_i$ is $0$ for all $i$, and thus the rate $R=0$.\n\nThe standard normal CDF $\\Phi(x)$ is related to the error function $\\operatorname{erf}(x)$ by the formula:\n$$ \\Phi(x) = \\frac{1}{2} \\left(1 + \\operatorname{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right) $$\nSubstituting this into our expression for $P_i$:\n$$ P_i = \\frac{1}{2} \\left(1 + \\operatorname{erf}\\left(\\frac{-|g(z_i)|}{\\sigma\\sqrt{2}}\\right)\\right) $$\nSince $\\operatorname{erf}(x)$ is an odd function, this simplifies to:\n$$ P_i = \\frac{1}{2} \\left(1 - \\operatorname{erf}\\left(\\frac{|g(z_i)|}{\\sigma\\sqrt{2}}\\right)\\right) $$\nThis analytical formula allows for direct computation without Monte Carlo simulation.\n\nThe computational procedure is as follows:\nFirst, we compute the internal fields $z_i = \\mathbf{w} \\cdot \\mathbf{x}_i$ for the dataset:\n- $z_1 = (1.0)(3.0) + (-1.0)(0.0) = 3.0$\n- $z_2 = (1.0)(1.1) + (-1.0)(0.9) = 0.2$\n- $z_3 = (1.0)(0.2) + (-1.0)(0.5) = -0.3$\n- $z_4 = (1.0)(-1.5) + (-1.0)(1.0) = -2.5$\n\nFor each of the four test cases, we calculate the misclassification probabilities $P_1, P_2, P_3, P_4$ using the appropriate activation function $g$ and noise standard deviation $\\sigma$, and then find the average rate $R = \\frac{1}{4}\\sum_{i=1}^4 P_i$.\n\nCase 1: $g = g_{\\text{id}}$, $\\sigma = 0.2$. The activations are $a_i = z_i$.\nCase 2: $g = g_{\\tanh}$, $\\sigma = 0.2$. The activations are $a_i = \\tanh(z_i)$.\nCase 3: $g = g_{\\text{id}}$, $\\sigma = 0.0$. The rate $R_3$ is $0$ by direct inspection.\nCase 4: $g = g_{\\tanh}$, $\\sigma = 5.0$. The activations are $a_i = \\tanh(z_i)$.\n\nThe following program implements this logic to compute the required values.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Computes the expected misclassification rate for a binary perceptron\n    with noise added to its analog activation.\n    \"\"\"\n\n    # Shared parameters for all test cases\n    d = 2\n    w = np.array([1.0, -1.0])\n    X = np.array([\n        [3.0, 0.0],\n        [1.1, 0.9],\n        [0.2, 0.5],\n        [-1.5, 1.0]\n    ])\n    N = X.shape[0]\n\n    # Activation functions\n    def g_id(z):\n        return z\n\n    def g_tanh(z):\n        return np.tanh(z)\n\n    # Test suite: (activation function, noise standard deviation sigma)\n    test_cases = [\n        (g_id, 0.2),\n        (g_tanh, 0.2),\n        (g_id, 0.0),\n        (g_tanh, 5.0),\n    ]\n\n    # Calculate internal fields z_i = w . x_i\n    z_values = X @ w\n\n    results = []\n    for g, sigma in test_cases:\n        # Handle the special case of zero noise\n        if sigma == 0.0:\n            results.append(0.0)\n            continue\n\n        # Calculate activations a_i = g(z_i)\n        a_values = g(z_values)\n\n        # Calculate misclassification probability for each input\n        # P_i = 0.5 * (1 - erf(|a_i| / (sigma * sqrt(2))))\n        # This is derived from the standard normal CDF Phi(-|a_i|/sigma).\n        probabilities = 0.5 * (1.0 - erf(np.abs(a_values) / (sigma * np.sqrt(2.0))))\n\n        # The expected misclassification rate is the average of these probabilities\n        R = np.mean(probabilities)\n        results.append(R)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.16f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Simple learning rules can give rise to complex, emergent system dynamics. This final practice explores a fascinating analogy between machine learning and condensed matter physics: hysteresis. By training a perceptron on a dataset whose labels are cyclically modulated by an external parameter, you will observe how the perceptron's internal state (its weights) lags behind the driving force, tracing a \"memory loop.\" This exercise provides a hands-on demonstration of how memory is not an explicitly programmed feature, but an emergent property of a system's adaptive dynamics .",
            "id": "2425812",
            "problem": "Consider a perceptron with a hard-threshold activation function trained online on a family of datasets that varies cyclically with a scalar control parameter, analogous to an external magnetic field. The perceptron has a weight vector $\\mathbf{w}\\in \\mathbb{R}^2$ and a scalar bias $b\\in \\mathbb{R}$. For an input $\\mathbf{x}\\in \\mathbb{R}^2$, the perceptron output is $\\hat{y}=\\operatorname{sign}(\\mathbf{w}\\cdot \\mathbf{x}+b)$, where $\\operatorname{sign}(z)=+1$ if $z\\ge 0$ and $\\operatorname{sign}(z)=-1$ otherwise. The learning rule is the classical Rosenblatt perceptron update: on a mislabeled sample $(\\mathbf{x},y)$ with $y\\in\\{-1,+1\\}$ such that $y(\\mathbf{w}\\cdot \\mathbf{x}+b)\\le 0$, update by $\\mathbf{w}\\leftarrow \\mathbf{w}+\\eta y \\mathbf{x}$ and $b\\leftarrow b+\\eta y$, where $\\eta0$ is the learning rate. If $y(\\mathbf{w}\\cdot \\mathbf{x}+b)0$, no update is performed.\n\nDefine a fixed, deterministic training set of $N$ points on the unit circle in $\\mathbb{R}^2$: for $k\\in\\{0,1,\\dots,N-1\\}$, $\\mathbf{x}_k=\\big(\\cos\\theta_k,\\sin\\theta_k\\big)$ with $\\theta_k=\\frac{2\\pi k}{N}$. For a given scalar offset $a\\in\\mathbb{R}$, define labels by $y_k(a)=\\operatorname{sign}(x_{k,1}+a)$, where $x_{k,1}$ is the first component of $\\mathbf{x}_k$. The parameter $a$ will be varied cyclically from $-A$ to $+A$ and back to $-A$ in uniform steps, where $A\\ge 0$.\n\nInitialize $\\mathbf{w}=\\mathbf{0}$ and $b=0$. For each value of $a$ on the forward sweep from $a_0=-A$ to $a_M=+A$ with uniform spacing $\\Delta a=\\frac{2A}{M}$ (so $a_i=-A+i\\Delta a$ for $i\\in\\{0,1,\\dots,M\\}$), perform $E$ epochs of online training over the $N$ samples in the fixed order $k=0,1,\\dots,N-1$ using the current labels $y_k(a_i)$. After these $E$ epochs at $a_i$, record the pair $(a_i,w_1)$, where $w_1$ is the first component of $\\mathbf{w}$. Then perform the backward sweep using the same procedure for $i=M-1,M-2,\\dots,0$, continuing training from the current $(\\mathbf{w},b)$ and again recording $(a_i,w_1)$ after $E$ epochs at each step. This yields a closed loop in the $(a,w_1)$ plane.\n\nDefine the loop area $\\mathcal{A}$ as the polygon area enclosed by the recorded sequence of points $(a,w_1)$ along the closed path, computed by the shoelace formula. Your program must compute $\\mathcal{A}$ for each of the following test cases, and output the areas as floating-point numbers.\n\nTest suite:\n- Case $1$ (nontrivial cyclic variation): $N=32$, $\\eta=0.2$, $M=60$, $E=1$, $A=0.9$.\n- Case $2$ (no learning boundary): $N=32$, $\\eta=0.0$, $M=60$, $E=1$, $A=0.9$.\n- Case $3$ (no variation boundary): $N=32$, $\\eta=0.2$, $M=60$, $E=1$, $A=0.0$.\n\nRequirements:\n- Implement exactly the perceptron and training protocol described above, with $\\operatorname{sign}(0)=+1$.\n- Use the fixed sample order $k=0,1,\\dots,N-1$ for every epoch and every value of $a$.\n- Compute the loop area $\\mathcal{A}$ by applying the shoelace formula to the ordered sequence of points from the forward sweep followed by the backward sweep (in that order), completing the polygon by returning to the initial point.\n- The answers are pure numbers without physical units and without angles.\n- Final output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases, for example, $[\\mathcal{A}_1,\\mathcal{A}_2,\\mathcal{A}_3]$.",
            "solution": "The problem statement presented is subjected to rigorous validation.\n\n### Step 1: Extract Givens\n\n- **Perceptron Definition**:\n  - Weight vector: $\\mathbf{w} \\in \\mathbb{R}^2$\n  - Bias: $b \\in \\mathbb{R}$\n  - Input: $\\mathbf{x} \\in \\mathbb{R}^2$\n  - Output function: $\\hat{y} = \\operatorname{sign}(\\mathbf{w} \\cdot \\mathbf{x} + b)$\n  - Activation function: $\\operatorname{sign}(z) = +1$ if $z \\ge 0$; $\\operatorname{sign}(z) = -1$ if $z  0$.\n\n- **Learning Rule**:\n  - Update condition: For a sample $(\\mathbf{x}, y)$, an update occurs if $y(\\mathbf{w} \\cdot \\mathbf{x} + b) \\le 0$.\n  - Weight update: $\\mathbf{w} \\leftarrow \\mathbf{w} + \\eta y \\mathbf{x}$\n  - Bias update: $b \\leftarrow b + \\eta y$\n  - Learning rate: $\\eta  0$\n\n- **Data Set**:\n  - Number of samples: $N$\n  - Sample vectors: $\\mathbf{x}_k = (\\cos\\theta_k, \\sin\\theta_k)$ for $k \\in \\{0, 1, \\dots, N-1\\}$.\n  - Sample angles: $\\theta_k = \\frac{2\\pi k}{N}$.\n  - Label generation: $y_k(a) = \\operatorname{sign}(x_{k,1} + a)$, where $x_{k,1}$ is the first component of $\\mathbf{x}_k$.\n\n- **Training Protocol**:\n  - Initialization: $\\mathbf{w} = \\mathbf{0}$, $b = 0$.\n  - Control parameter: $a$ varies cyclically from $-A$ to $+A$ and back.\n  - Forward sweep: $a_i = -A + i \\Delta a$ for $i \\in \\{0, 1, \\dots, M\\}$, where $\\Delta a = \\frac{2A}{M}$.\n  - Backward sweep: $a_i = -A + i \\Delta a$ for $i \\in \\{M-1, M-2, \\dots, 0\\}$.\n  - Epochs per step: $E$ epochs for each value of $a_i$.\n  - Sample order: Fixed, $k=0, 1, \\dots, N-1$.\n  - Measurement: Record $(a_i, w_1)$ after $E$ epochs at each $a_i$, where $w_1$ is the first component of $\\mathbf{w}$.\n\n- **Analysis**:\n  - Loop area $\\mathcal{A}$: Calculated using the shoelace formula on the ordered sequence of recorded points $(a, w_1)$ from the full cycle.\n\n- **Test Cases**:\n  - Case 1: $N=32$, $\\eta=0.2$, $M=60$, $E=1$, $A=0.9$.\n  - Case 2: $N=32$, $\\eta=0.0$, $M=60$, $E=1$, $A=0.9$.\n  - Case 3: $N=32$, $\\eta=0.2$, $M=60$, $E=1$, $A=0.0$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is analyzed against the established criteria.\n\n- **Scientifically Grounded**: The problem is an exercise in computational physics and machine learning. It uses a standard Rosenblatt perceptron, a fundamental model in neural networks. The framing of the problem—a learning system driven by an external, cyclically varying parameter—is a common and valid paradigm for studying hysteresis and memory effects in complex systems. It is free of pseudoscience.\n- **Well-Posed**: The problem is specified with mathematical precision. All parameters, initial conditions, update rules, and procedures for data generation and analysis are explicitly defined. The algorithm is deterministic, ensuring a unique solution for each test case.\n- **Objective**: The problem is stated in objective, technical language, with no subjective or ambiguous terminology.\n\n### Step 3: Verdict and Action\n\nThe problem is **valid**. It is a well-defined computational task based on established principles of machine learning and its application to modeling physical phenomena. A solution will be provided.\n\n### Solution\n\nThe task is to simulate a single-layer perceptron subjected to a cyclically varying training dataset and to quantify the resulting hysteresis loop in the parameter space of the drive ($a$) and a system response ($w_1$). The solution involves a direct implementation of the specified simulation protocol followed by a geometric area calculation.\n\n**1. System and Data Preparation**\n\nFirst, we define the static components of the system. The training data inputs $\\{\\mathbf{x}_k\\}$ are fixed points on the unit circle. For a given $N$, the vector for each sample $k$ is $\\mathbf{x}_k = [\\cos(\\frac{2\\pi k}{N}), \\sin(\\frac{2\\pi k}{N})]^T$. These should be pre-computed.\n\nThe labels $\\{y_k\\}$ depend on the control parameter $a$. For each value of $a$ in the cycle, the corresponding labels are generated according to $y_k(a) = \\operatorname{sign}(x_{k,1} + a)$. The rule $\\operatorname{sign}(z)=+1$ for $z \\ge 0$ must be strictly followed.\n\n**2. Simulation of the Driven System**\n\nThe core of the problem is a time-evolution simulation. The \"time\" in this context is the progression through the cycle of the control parameter $a$. The state of the system is described by the weight vector $\\mathbf{w}$ and bias $b$.\n\nThe simulation proceeds as follows:\n- Initialize $\\mathbf{w} = [0, 0]^T$ and $b=0$.\n- Create an ordered list of $a$ values for the full cycle. The forward sweep consists of $M+1$ values from $a_0 = -A$ to $a_M = A$. The backward sweep consists of $M$ values from $a_{M-1}$ to $a_0$. The total path for $a$ will have $(M+1) + M = 2M+1$ steps.\n- A list, `path_points`, will store the recorded pairs $(a, w_1)$.\n\nWe then iterate through the ordered list of $a$ values. At each step $a$:\n- First, re-calculate the entire set of labels $\\{y_k(a)\\}$ based on the current value of $a$.\n- Then, perform $E$ training epochs. For each epoch, iterate through all data samples $(\\mathbf{x}_k, y_k(a))$ in the fixed order $k=0, 1, \\dots, N-1$.\n- For each sample, check the perceptron's classification. The perceptron's internal state is $z_k = \\mathbf{w} \\cdot \\mathbf{x}_k + b$. A misclassification occurs if $y_k(a) \\cdot z_k \\le 0$.\n- If a misclassification is detected, update the weights and bias using the Rosenblatt rule:\n  $$ \\mathbf{w} \\leftarrow \\mathbf{w} + \\eta y_k(a) \\mathbf{x}_k $$\n  $$ b \\leftarrow b + \\eta y_k(a) $$\n- After completing all $E$ epochs for the current value of $a$, we record the state by appending the pair $(a, w_1)$ to our `path_points` list. $w_1$ is the first component of the current weight vector $\\mathbf{w}$.\n\nThis process is repeated for every value of $a$ in the cycle, continuing the updates to $\\mathbf{w}$ and $b$ from one value of $a$ to the next.\n\n**3. Hysteresis Loop Area Calculation**\n\nAfter the simulation completes the full cycle, the `path_points` list will contain $2M+1$ vertices of a polygon in the $(a, w_1)$ plane. Let these vertices be $(x_j, y_j)$ for $j=0, \\dots, 2M$, where $x_j$ is the $a$ value and $y_j$ is the $w_1$ value.\n\nThe area $\\mathcal{A}$ of this polygon is computed using the shoelace formula:\n$$ \\mathcal{A} = \\frac{1}{2} \\left| \\sum_{j=0}^{2M} (x_j y_{j+1} - x_{j+1} y_j) \\right| $$\nwhere the index wraps around, i.e., $(x_{2M+1}, y_{2M+1}) = (x_0, y_0)$. This formula can be implemented efficiently using vector operations. Specifically, if $\\mathbf{x} = [x_0, \\dots, x_{2M}]$ and $\\mathbf{y} = [y_0, \\dots, y_{2M}]$, the sum can be computed as $\\mathbf{x}^T \\mathbf{y}' - \\mathbf{y}^T \\mathbf{x}'$, where $\\mathbf{x}'$ and $\\mathbf{y}'$ are cyclically shifted versions of $\\mathbf{x}$ and $\\mathbf{y}$.\n\n**4. Analysis of Test Cases**\n\n- **Case 1 ($A=0.9, \\eta=0.2$):** This represents the general case. As $a$ varies, the target classification boundary $x_1 = -a$ sweeps across the data points, causing labels to flip. The non-zero learning rate $\\eta$ allows the perceptron to adapt. The perceptron's decision boundary, defined by $\\mathbf{w} \\cdot \\mathbf{x} + b=0$, attempts to follow the moving target boundary. Due to the finite learning rate and processing one sample at a time, there is a delay or lag in this adaptation. This lag causes the path of $w_1$ during the forward sweep of $a$ to be different from the path during the backward sweep, resulting in a hysteresis loop with a non-zero area $\\mathcal{A} > 0$.\n\n- **Case 2 ($A=0.9, \\eta=0.0$):** Here, the learning rate is zero. The weights and bias, initialized to $0$, will never be updated. Therefore, $w_1$ remains $0$ throughout the entire simulation. The recorded path is simply a traversal of the interval $[-0.9, 0.9]$ on the $a$-axis and back. This is a degenerate polygon (a line segment), which has an area of $\\mathcal{A} = 0$.\n\n- **Case 3 ($A=0.0, \\eta=0.2$):** In this case, the amplitude of the driving parameter is zero, meaning $a=0$ for the entire cycle. The labels $y_k = \\operatorname{sign}(x_{k,1})$ are fixed. The perceptron is repeatedly trained on this same static dataset for $(2M+1) \\times E$ epochs. While the weight $w_1$ will change from its initial value of $0$, the parameter $a$ does not. All recorded points will be of the form $(0, w_{1,j})$. The resulting path is a vertical line segment on the $w_1$-axis. A line segment is a degenerate polygon and has an area of $\\mathcal{A}=0$.\n\nThese analytical considerations for the control cases provide a sound check for the correctness of the implementation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the perceptron hysteresis problem for a given suite of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (nontrivial cyclic variation)\n        {'N': 32, 'eta': 0.2, 'M': 60, 'E': 1, 'A': 0.9},\n        # Case 2 (no learning boundary)\n        {'N': 32, 'eta': 0.0, 'M': 60, 'E': 1, 'A': 0.9},\n        # Case 3 (no variation boundary)\n        {'N': 32, 'eta': 0.2, 'M': 60, 'E': 1, 'A': 0.0},\n    ]\n\n    def run_simulation(N, eta, M, E, A):\n        \"\"\"\n        Runs the full simulation for one set of parameters.\n\n        Args:\n            N (int): Number of points in the dataset.\n            eta (float): Learning rate.\n            M (int): Number of steps in half a cycle.\n            E (int): Number of epochs per step.\n            A (float): Amplitude of the control parameter 'a'.\n\n        Returns:\n            list: A list of (a, w1) tuples representing the path in the parameter space.\n        \"\"\"\n        # Initialize weights and bias\n        w = np.zeros(2)\n        b = 0.0\n\n        # Generate the fixed training set inputs on the unit circle\n        theta_k = (2.0 * np.pi / N) * np.arange(N)\n        x_k = np.stack((np.cos(theta_k), np.sin(theta_k)), axis=1)\n\n        # Define the sign function as specified: sign(z) = +1 if z >= 0, -1 otherwise\n        def sign_func(z):\n            return np.where(z >= 0, 1.0, -1.0)\n\n        # Generate the sequence of 'a' values for the full cycle\n        if M == 0: # Handle edge case where A > 0 but M = 0\n             delta_a = 0.0\n             a_forward = np.array([-A]) if A > 0 else np.array([0.0])\n             a_backward = np.array([])\n        else:\n             delta_a = 2.0 * A / M\n             a_forward = -A + np.arange(M + 1) * delta_a\n             a_backward = a_forward[-2::-1]\n        \n        a_cycle = np.concatenate((a_forward, a_backward))\n        \n        path_points = []\n        \n        # Main simulation loop\n        for a_val in a_cycle:\n            # Generate labels for the current 'a' value\n            y_k = sign_func(x_k[:, 0] + a_val)\n            \n            # Perform E epochs of training\n            for _ in range(E):\n                for i in range(N):\n                    # Calculate activation\n                    activation = np.dot(w, x_k[i]) + b\n                    \n                    # Check for misclassification and update\n                    if y_k[i] * activation = 0:\n                        w += eta * y_k[i] * x_k[i]\n                        b += eta * y_k[i]\n            \n            # Record the point (a, w1)\n            path_points.append((a_val, w[0]))\n            \n        return path_points\n\n    def shoelace_area(points):\n        \"\"\"\n        Calculates the area of a polygon using the shoelace formula.\n        \n        Args:\n            points (list): A list of (x, y) tuples for the polygon vertices.\n\n        Returns:\n            float: The area of the polygon.\n        \"\"\"\n        if len(points)  3:\n            return 0.0\n\n        # Convert list of tuples to a NumPy array for vectorized operations\n        poly = np.array(points)\n        x = poly[:, 0]\n        y = poly[:, 1]\n        \n        # Shoelace formula implementation using NumPy for efficiency\n        # Area = 0.5 * |(x0*y1 + x1*y2 + ...) - (y0*x1 + y1*x2 + ...)|\n        area = 0.5 * np.abs(np.dot(x, np.roll(y, -1)) - np.dot(y, np.roll(x, -1)))\n        \n        return area\n\n    results = []\n    for case in test_cases:\n        path = run_simulation(**case)\n        area = shoelace_area(path)\n        results.append(area)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}