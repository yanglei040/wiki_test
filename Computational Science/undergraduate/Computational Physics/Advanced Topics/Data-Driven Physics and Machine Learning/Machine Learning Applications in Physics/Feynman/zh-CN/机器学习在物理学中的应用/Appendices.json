{
    "hands_on_practices": [
        {
            "introduction": "第一个实践将让你扮演一位计算天文学家的角色。你的任务是从模拟的观测数据中，直接重新发现天体力学的基石之一——开普勒第三定律。通过将幂律关系 $P = C a^n$ 转换为线性形式 $\\ln P = \\ln C + n \\ln a$，你将看到一个简单的线性回归模型如何成为科学发现的有力工具，揭示隐藏在数据中的优美数学结构。",
            "id": "2410557",
            "problem": "您的任务是构建一个最小化的符号回归流程，以仅使用标准数值工具从模拟的天文数据中恢复轨道周期和半长轴之间的幂律关系。物理背景是一个双体系统，其中一个小天体在牛顿引力作用下围绕一个中心质量体运行。您必须使用的基本原理包括牛顿的万有引力定律和向心加速度的定义，并结合运动学关系，将圆形运动的轨道速度和周期联系起来。由此可以推导出一个连接轨道周期和半长轴的幂律。您必须从这些原理中推导出这个幂律的形式，然后实现一个机器学习模型，该模型能直接从带噪声的模拟数据中发现该幂律的指数。\n\n您必须执行以下任务：\n\n1. 从第一性原理出发，推导在国际单位制（SI）下，围绕一个质量为 $M$（单位：千克）的点质量体作圆周运动的轨道周期 $P$（单位：秒）和半长轴 $a$（单位：米）之间的关系。推导过程中需使用牛顿万有引力定律，其中引力常量为 $G$。推导必须从引力加速度与向心加速度相等，以及经过充分检验的运动学事实开始。请勿假设任何已知的、关联 $P$ 和 $a$ 的目标公式。\n\n2. 设计一个符号回归模型，其假设类别限定为 $P = C a^n$ 形式的幂律，其中 $C$ 和 $n$ 是常数。通过取自然对数，展示如何将其转换为一个线性模型，以便您可以通过对变换后的变量进行普通最小二乘法来估计 $n$。假设 $P$ 上存在一个乘性噪声模型，该模型在 $\\ln P$ 上变为加性的、零均值的噪声。\n\n3. 实现一个完整、可运行的程序，该程序能：\n   - 根据物理模型模拟数据集，具体细节如下：\n     - 使用任务1中推导出的轨道周期 $P$ 的精确公式。\n     - 对每个数据集，在指定的边界 $a_{\\min}$ 和 $a_{\\max}$ 之间对数值 $a$ 进行对数均匀采样。\n     - 通过向 $\\ln P$ 添加标准差为 $\\sigma$ 的零均值高斯噪声来生成带噪声的观测值（等效于在 $P$ 上施加乘性的对数正态噪声）。为确保确定性并消除估计斜率中的有限样本偏差，构造的噪声必须与 $\\ln a$ 具有零样本协方差。为此，如果 $\\epsilon_{\\text{raw}} \\sim \\mathcal{N}(0,\\sigma^2)$ 表示初始噪声向量，且 $x=\\ln a$，$x_c = x - \\overline{x}$，则使用\n       $$\\epsilon \\leftarrow \\epsilon_{\\text{raw}} - \\frac{x_c^\\top \\epsilon_{\\text{raw}}}{x_c^\\top x_c} x_c,$$\n       然后设置 $\\ln P_{\\text{obs}} = \\ln P_{\\text{true}} + \\epsilon$ 和 $P_{\\text{obs}} = \\exp(\\ln P_{\\text{obs}})$。\n     - 使用以下物理常量（均为国际单位制）：引力常量 $G = 6.67430 \\times 10^{-11}\\ \\text{m}^3\\ \\text{kg}^{-1}\\ \\text{s}^{-2}$，太阳质量 $M_\\odot = 1.98847 \\times 10^{30}\\ \\text{kg}$，木星质量 $M_J = 1.89813 \\times 10^{27}\\ \\text{kg}$，天文单位 $\\mathrm{AU} = 1.495978707 \\times 10^{11}\\ \\text{m}$。\n     - 使用固定的随机种子，以使结果可复现。\n   - 通过普通最小二乘法拟合模型 $\\ln P = \\beta_0 + n \\ln a$，并为每个数据集返回估计的指数 $n$。\n   - 将报告的每个指数四舍五入到三位小数。\n   - 将最终输出生成为单行，其中包含方括号内所有测试用例的指数，以逗号分隔。\n\n测试套件：\n模拟四个数据集，使用以下参数集。在所有情况下，报告发现的指数 $n$（无量纲），四舍五入到三位小数。\n\n- 案例 1（理想情况，太阳质量，宽动态范围，低噪声）：\n  - $M = 1.0 \\times M_\\odot$\n  - $a_{\\min} = 0.3 \\times \\mathrm{AU}$，$a_{\\max} = 5.0 \\times \\mathrm{AU}$\n  - 样本数 $N = 64$\n  - 对数噪声标准差 $\\sigma = 0.02$\n\n- 案例 2（更重的恒星，非常宽的动态范围，较高噪声）：\n  - $M = 5.0 \\times M_\\odot$\n  - $a_{\\min} = 0.1 \\times \\mathrm{AU}$，$a_{\\max} = 10.0 \\times \\mathrm{AU}$\n  - 样本数 $N = 128$\n  - 对数噪声标准差 $\\sigma = 0.05$\n\n- 案例 3（较轻的恒星，窄动态范围，低噪声）：\n  - $M = 0.1 \\times M_\\odot$\n  - $a_{\\min} = 0.5 \\times \\mathrm{AU}$，$a_{\\max} = 1.0 \\times \\mathrm{AU}$\n  - 样本数 $N = 40$\n  - 对数噪声标准差 $\\sigma = 0.02$\n\n- 案例 4（木星作为中心质量，米级输入）：\n  - $M = 1.0 \\times M_J$\n  - $a_{\\min} = 1.0 \\times 10^{7}\\ \\text{m}$，$a_{\\max} = 1.0 \\times 10^{9}\\ \\text{m}$\n  - 样本数 $N = 50$\n  - 对数噪声标准差 $\\sigma = 0.03$\n\n最终输出格式：\n您的程序应生成单行输出，其中包含案例1到4的四个四舍五入后的指数，格式为方括号内的逗号分隔列表。例如，输出格式必须完全如下：\n\"[1.500,1.500,1.500,1.500]\"\n每个值都四舍五入到三位小数。\n\n所有物理量必须在内部以国际单位制处理。最终报告的指数是无量纲的；最终输出不需要物理单位。此任务不涉及角度。最终输出是浮点数，四舍五入到三位小数，并按规定聚合到单行列表中。",
            "solution": "该问题已经过分析并被确定为有效。它在科学上基于牛顿力学，问题设定良好，目标和方法明确，没有歧义或矛盾。我们将给出一个完整的解决方案。\n\n该任务要求从第一性原理推导控制轨道运动的物理定律，然后利用这一理解构建一个计算模型，从模拟的带噪声数据中恢复该定律的参数。这个过程本身就是科学方法的一个缩影，它将理论物理与数据分析联系了起来。\n\n### 第1部分：轨道周期-半径关系的推导\n\n我们从经典力学的基本原理出发，推导一个物体围绕中心质量 $M$ 作圆周轨道运动时，其轨道周期 $P$ 与半长轴 $a$ 之间的关系。对于圆周轨道，半长轴就是恒定的轨道半径，即 $r = a$。\n\n1.  **力平衡**：处于稳定圆周轨道上的物体受到一个恒定的引力，这个引力提供了维持其圆形路径所必需的向心力。我们将牛顿万有引力定律 $F_g$ 和向心力 $F_c$ 的表达式相等。\n    $$F_g = F_c$$\n    设轨道物体的质量为 $m$，中心天体的质量为 $M$，轨道速度为 $v$，轨道半径为 $a$。引力常量为 $G$。\n    $$G \\frac{M m}{a^2} = \\frac{m v^2}{a}$$\n\n2.  **分离速度**：轨道物体的质量 $m$ 被消去，这是等效原理的一种体现。然后我们可以对方程进行重排，以求解轨道速度的平方 $v^2$。\n    $$v^2 = \\frac{G M}{a}$$\n\n3.  **运动学关系**：轨道速度 $v$ 是轨道周长 $2 \\pi a$ 除以完成一圈所需的时间，即周期 $P$。\n    $$v = \\frac{2 \\pi a}{P}$$\n\n4.  **代入与最终形式**：我们将这个关于 $v$ 的运动学表达式代入到从力平衡推导出的方程中。\n    $$\\left(\\frac{2 \\pi a}{P}\\right)^2 = \\frac{G M}{a}$$\n    $$\\frac{4 \\pi^2 a^2}{P^2} = \\frac{G M}{a}$$\n    现在我们通过代数运算来分离周期 $P$。首先，我们求解 $P^2$。\n    $$P^2 = \\left(\\frac{4 \\pi^2}{G M}\\right) a^3$$\n    最后，对两边取平方根，得到 $P$ 和 $a$ 之间的显式关系：\n    $$P = \\sqrt{\\frac{4 \\pi^2}{G M}} a^{3/2}$$\n    这就是圆周轨道的开普勒第三定律。该方程的形式为 $P = C a^n$，其中常数系数为 $C = \\sqrt{4 \\pi^2 / (G M)}$，指数为 $n = 3/2 = 1.5$。这个理论上推导出的指数 $n=1.5$ 正是我们的机器学习模型必须恢复的量。\n\n### 第2部分：通过线性化实现的符号回归模型\n\n该任务要求一个符号回归模型，其假设类别被限定为幂律 $P = C a^n$。虽然更复杂的符号回归可能涉及使用遗传算法来搜索数学表达式的空间，但对于这个受限的类别，可以通过线性化使用一种更简单、更直接的方法。\n\n1.  **对数变换**：我们对幂律方程的两边应用自然对数 $\\ln$。\n    $$\\ln(P) = \\ln(C a^n)$$\n    利用对数的性质 $\\ln(xy) = \\ln(x) + \\ln(y)$ 和 $\\ln(x^k) = k \\ln(x)$，我们变换方程：\n    $$\\ln(P) = \\ln(C) + \\ln(a^n) = \\ln(C) + n \\ln(a)$$\n\n2.  **线性模型构建**：这个变换后的方程是一个线性方程。我们定义新变量：$y = \\ln(P)$，$x = \\ln(a)$，截距 $\\beta_0 = \\ln(C)$，以及斜率 $\\beta_1 = n$。模型变为：\n    $$y = \\beta_0 + \\beta_1 x$$\n    这是一个简单的线性回归模型。原始的指数 $n$ 现在是该直线在对数-对数空间中的斜率。\n\n3.  **噪声模型**：问题指定了 $P$ 的一个乘性噪声模型，这对于恒为正的物理量是常见的。一个观测到的周期 $P_{obs}$ 与真实周期 $P_{true}$ 的关系为 $P_{obs} = P_{true} \\cdot e^{\\epsilon_{raw}}$，其中 $\\epsilon_{raw}$ 是从高斯分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽取的随机变量。对观测值取对数得到：\n    $$\\ln(P_{obs}) = \\ln(P_{true} \\cdot e^{\\epsilon_{raw}}) = \\ln(P_{true}) + \\ln(e^{\\epsilon_{raw}}) = \\ln(P_{true}) + \\epsilon_{raw}$$\n    因此，原始空间中的乘性对数正态噪声模型在对数变换后的空间中变成了一个简单的加性高斯噪声模型。\n\n4.  **参数估计**：未知参数 $\\beta_0$ 和 $\\beta_1$（即我们的指数 $n$）可以使用普通最小二乘法（OLS）进行估计。对于一组 $N$ 个数据点 $(x_i, y_i)$，斜率 $\\beta_1$ 的OLS估计量由以下公式给出：\n    $$\\hat{\\beta_1} = n_{est} = \\frac{\\sum_{i=1}^{N} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{N} (x_i - \\bar{x})^2} = \\frac{\\text{Cov}(x, y)}{\\text{Var}(x)}$$\n    问题指定了一个非标准但确定性的噪声生成过程。添加到 $\\ln(P_{true})$ 的噪声向量 $\\epsilon$ 被构造成与中心化的预测变量向量 $x_c = x - \\bar{x}$ 正交。这意味着 $x$ 和 $\\epsilon$ 之间的样本协方差恰好为零。正如在OLS估计量的推导中所示，斜率估计中的误差项与该样本协方差成正比。通过强制该协方差为零，OLS斜率估计量将精确地恢复真实参数 $n = 1.5$，无论噪声方差 $\\sigma$ 或样本大小 $N$ 如何，只要计算具有足够的数值精度。噪声只会影响截距 $\\beta_0$ 的估计。这种构造为验证实现的正确性提供了一个精确的分析测试。\n\n### 第3部分：实现纲要\n\n程序将针对每个测试用例执行以下步骤：\n1.  以国际单位制定义所有必要的物理常量：$G$, $M_\\odot$, $M_J$, $\\mathrm{AU}$。\n2.  为保证可复现性，设置一个固定的随机种子。\n3.  对于每个案例，确定参数：中心质量 $M$，半长轴边界 $a_{min}$ 和 $a_{max}$，样本数 $N$，以及噪声标准差 $\\sigma$。所有输入（如AU）都将转换为国际单位制（米）。\n4.  在 $a_{min}$ 和 $a_{max}$ 之间对数均匀地生成 $N$ 个 $a$ 的样本。这可以通过使用 `numpy.logspace` 创建一个几何级数来实现。\n5.  使用推导出的公式 $P = \\sqrt{4\\pi^2 / (GM)} a^{3/2}$ 计算每个 $a$ 的“真实”轨道周期 $P_{true}$。\n6.  将数据转换到对数空间：$x = \\ln(a)$ 和 $y_{true} = \\ln(P_{true})$。\n7.  生成噪声向量 $\\epsilon$。首先，从 $\\mathcal{N}(0, \\sigma^2)$ 中抽取一个原始噪声向量 $\\epsilon_{raw}$。然后，使用提供的公式将其与中心化的预测变量向量 $x_c = x - \\bar{x}$ 进行正交化：$\\epsilon \\leftarrow \\epsilon_{raw} - \\frac{x_c^\\top \\epsilon_{raw}}{x_c^\\top x_c} x_c$。\n8.  创建“观测到”的对数周期数据：$y_{obs} = y_{true} + \\epsilon$。\n9.  使用OLS公式计算数据 $(x, y_{obs})$ 的最佳拟合直线的斜率。这个斜率就是估计的指数 $n$。\n10. 将估计的 $n$ 四舍五入到三位小数并存储。\n11. 处理完所有案例后，将指数列表格式化为所需的字符串 `\"[n1,n2,n3,n4]\"`。\n此过程将使用 `numpy` 库封装在一个Python程序中。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of recovering the power-law exponent in Kepler's Third Law\n    from simulated data using a linearized model and ordinary least squares.\n    \"\"\"\n\n    # Physical constants in SI units\n    G = 6.67430e-11  # m^3 kg^-1 s^-2\n    M_SOLAR = 1.98847e30  # kg\n    M_JUPITER = 1.89813e27  # kg\n    AU = 1.495978707e11  # m\n\n    # Test cases defined in the problem statement\n    test_cases = [\n        {\n            \"M\": 1.0 * M_SOLAR,\n            \"a_min\": 0.3 * AU,\n            \"a_max\": 5.0 * AU,\n            \"N\": 64,\n            \"sigma\": 0.02,\n        },\n        {\n            \"M\": 5.0 * M_SOLAR,\n            \"a_min\": 0.1 * AU,\n            \"a_max\": 10.0 * AU,\n            \"N\": 128,\n            \"sigma\": 0.05,\n        },\n        {\n            \"M\": 0.1 * M_SOLAR,\n            \"a_min\": 0.5 * AU,\n            \"a_max\": 1.0 * AU,\n            \"N\": 40,\n            \"sigma\": 0.02,\n        },\n        {\n            \"M\": 1.0 * M_JUPITER,\n            \"a_min\": 1.0e7, # Already in meters\n            \"a_max\": 1.0e9, # Already in meters\n            \"N\": 50,\n            \"sigma\": 0.03,\n        },\n    ]\n\n    # Set a fixed random seed for reproducibility\n    np.random.seed(42)\n\n    results = []\n\n    for case in test_cases:\n        M = case[\"M\"]\n        a_min = case[\"a_min\"]\n        a_max = case[\"a_max\"]\n        N = case[\"N\"]\n        sigma = case[\"sigma\"]\n\n        # 1. Simulate dataset: sample semi-major axis `a` log-uniformly\n        a_samples = np.logspace(np.log10(a_min), np.log10(a_max), N)\n\n        # 2. Calculate true orbital period `P` using the derived formula\n        # P^2 = (4 * pi^2 / (G * M)) * a^3\n        C_squared = (4 * np.pi**2) / (G * M)\n        p_true_samples = np.sqrt(C_squared * a_samples**3)\n\n        # 3. Transform to log-space for linear regression\n        # ln(P) = ln(C_sqrt) + (3/2) * ln(a)\n        x = np.log(a_samples)  # ln(a)\n        y_true = np.log(p_true_samples) # ln(P_true)\n\n        # 4. Generate and orthogonalize noise\n        # Generate raw Gaussian noise\n        eps_raw = np.random.normal(loc=0.0, scale=sigma, size=N)\n        \n        # Center the predictor variable x = ln(a)\n        x_centered = x - np.mean(x)\n\n        # Orthogonalize the noise vector with respect to the centered predictor vector\n        # This ensures the sample covariance between x and the final noise is zero.\n        # eps_ortho = eps_raw - proj_of_eps_raw_onto_x_centered\n        # projection = (x_c.T @ eps_raw / x_c.T @ x_c) * x_c\n        dot_product_xc_eps = np.dot(x_centered, eps_raw)\n        dot_product_xc_xc = np.dot(x_centered, x_centered)\n        \n        # Handle case where x_centered has zero variance (e.g., N=1 or all x are same)\n        if dot_product_xc_xc == 0:\n            eps_ortho = eps_raw\n        else:\n            projection_scalar = dot_product_xc_eps / dot_product_xc_xc\n            eps_ortho = eps_raw - projection_scalar * x_centered\n\n        # 5. Create the observed log-period data with the orthogonalized noise\n        y_obs = y_true + eps_ortho\n\n        # 6. Fit the model ln(P) = beta_0 + n * ln(a) using Ordinary Least Squares\n        # We only need the slope 'n' (beta_1).\n        # The OLS formula for the slope is Cov(x, y) / Var(x).\n        # We use ddof=0 for sample covariance/variance, not unbiased estimates.\n        cov_matrix = np.cov(x, y_obs, ddof=0)\n        # The slope is cov(x,y) / var(x)\n        estimated_n = cov_matrix[0, 1] / cov_matrix[0, 0]\n\n        # 7. Round the result to three decimal places\n        rounded_n = round(estimated_n, 3)\n        results.append(str(rounded_n))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "从天文发现转向原子核的深处，本练习展示了机器学习如何为一个已建立的物理理论进行参数化。你将使用基于原子核液滴模型的半经验质量公式 (SEMF) 来预测结合能。你的目标是训练一个模型来学习 SEMF 的系数，从而有效地从数据中量化体积、表面、库仑和其他核效应的贡献。",
            "id": "2410513",
            "problem": "您的任务是构建一个完整、可运行的程序，该程序采用基于第一性原理的数据驱动方法，通过质子数和中子数来学习预测核结合能。目标量是具有质子数 $Z$ 和中子数 $N$ 的原子核的总结合能，单位为兆电子伏（MeV）。用于训练和评估的物理基准真相映射由具有特定系数的半经验质量公式（SEMF）（也称为 Weizsäcker 公式）定义。目标是仅利用此公式生成的数据来训练一个模型，然后为一组指定的测试原子核生成预测。\n\n目标的物理定义：\n对于一个具有质子数 $Z$、中子数 $N$ 和质量数 $A=Z+N$ 的原子核，其总结合能 $B(Z,N)$（以兆电子伏为单位）由下式给出：\n$$\nB(Z,N) \\;=\\; a_v A \\;-\\; a_s A^{2/3} \\;-\\; a_c \\frac{Z(Z-1)}{A^{1/3}} \\;-\\; a_a \\frac{(A-2Z)^2}{A} \\;+\\; \\delta(A,Z,N),\n$$\n其中对偶项为\n$$\n\\delta(A,Z,N) \\;=\\; \n\\begin{cases}\n+\\dfrac{a_p}{\\sqrt{A}}, & \\text{若 $Z$ 和 $N$ 均为偶数} \\\\\n-\\dfrac{a_p}{\\sqrt{A}}, & \\text{若 $Z$ 和 $N$ 均为奇数} \\\\\n0, & \\text{若 $A$ 为奇数}\n\\end{cases}\n$$\n使用以下 SEMF 系数（单位均为兆电子伏）：$a_v=15.8$，$a_s=18.3$，$a_c=0.714$，$a_a=23.2$，$a_p=12.0$。所有输出都必须以兆电子伏（MeV）为单位表示。\n\n训练数据生成：\n- 通过在 $Z \\in \\{2,3,\\dots,60\\}$ 和 $N \\in \\{2,3,\\dots,90\\}$ 的网格上评估 $B(Z,N)$ 来构建训练集。$Z$ 和 $N$ 的值为整数。\n- 每个训练样本由一个输入对 $(Z,N)$ 和使用给定系数、根据上述公式计算出的相应目标 $B(Z,N)$（其中 $A=Z+N$）组成。\n\n学习任务：\n- 训练一个模型（您可以选择任何架构），以根据精确指定生成的训练数据来近似映射 $(Z,N)\\mapsto B(Z,N)$。\n\n用于评估已训练模型的测试套件：\n为以下八个原子核提供预测，每个原子核以一对 $(Z,N)$ 的形式给出：\n- $(1,1)$\n- $(2,2)$\n- $(3,3)$\n- $(8,9)$\n- $(26,30)$\n- $(50,70)$\n- $(82,126)$\n- $(92,146)$\n\n答案规格和单位：\n- 对于每个测试用例，输出模型预测的总结合能 $B(Z,N)$，单位为兆电子伏（MeV）。\n- 将每个结果表示为四舍五入到三位小数的浮点数。\n- 此问题不涉及角度，因此没有适用的角度单位。\n\n最终输出格式：\n- 您的程序必须生成单行输出，其中包含八个结果，格式为逗号分隔的列表并用方括号括起来，例如 $[x_1,x_2,\\dots,x_8]$，其中每个 $x_i$ 是对应于上面列出的第 $i$ 个测试用例的、四舍五入后的浮点数结果（单位 MeV）。\n\n测试套件的覆盖范围设计：\n- 该集合包括轻核（例如 $(1,1)$ 和 $(2,2)$）、一个奇-奇偶质量数核 $(3,3)$、一个对偶项消失的奇质量数核 $(8,9)$、中等质量核 $(26,30)$、重幻数核和近幻数核 $(82,126)$ 和 $(92,146)$，以及一个中重核 $(50,70)$。这确保了对不同对偶机制、质量标度以及结构机制的覆盖。\n\n您提交的必须是一个完整的程序，它在指定的网格上执行训练，并以所要求的确切格式打印出测试套件的预测结果。运行时不允许用户输入。所有计算都必须以兆电子伏（MeV）为单位，并且最终打印的数字必须四舍五入到三位小数。",
            "solution": "问题陈述已经过评估，并被认为是有效的。它具有科学依据、提法明确、客观，并包含了进行求解所需的所有必要信息。它基于核物理学中公认的半经验质量公式（SEMF），并提出了一个清晰、可解的计算任务。\n\n该问题要求构建一个模型来预测具有质子数 $Z$ 和中子数 $N$ 的原子核的核结合能 $B(Z, N)$。此学习任务的基准真相由 SEMF（也称为 Weizsäcker 公式）明确定义。结合能 $B$ 以兆电子伏（MeV）为单位，由以下公式给出：\n$$\nB(Z,N) = a_v A - a_s A^{2/3} - a_c \\frac{Z(Z-1)}{A^{1/3}} - a_a \\frac{(A-2Z)^2}{A} + \\delta(A,Z,N)\n$$\n其中 $A = Z+N$ 是质量数。所提供的系数为 $a_v=15.8$、$a_s=18.3$、$a_c=0.714$、$a_a=23.2$ 和 $a_p=12.0$，单位均为 MeV。对偶项 $\\delta(A,Z,N)$ 定义为：\n$$\n\\delta(A,Z,N) = \n\\begin{cases}\n+a_p/\\sqrt{A}, & \\text{若 $Z$ 和 $N$ 均为偶数} \\\\\n-a_p/\\sqrt{A}, & \\text{若 $Z$ 和 $N$ 均为奇数} \\\\\n0, & \\text{若 $A$ 为奇数}\n\\end{cases}\n$$\n\n该任务被构建为一个机器学习问题：在一个基于此公式生成的数据集上训练模型，然后用它进行预测。对于此任务，最严谨和最合适的“架构”是线性回归模型，因为 SEMF 本质上是从 $Z$ 和 $N$ 导出的、具有物理动机的基函数（特征）的线性组合。\n\n让我们定义一个具有 5 个分量的特征向量 $\\boldsymbol{x}$，对应于 SEMF 的五个项：\n1.  **体积项特征**: $x_1 = A$\n2.  **表面项特征**: $x_2 = A^{2/3}$\n3.  **库仑项特征**: $x_3 = \\frac{Z(Z-1)}{A^{1/3}}$\n4.  **不对称项特征**: $x_4 = \\frac{(A-2Z)^2}{A}$\n5.  **对偶项特征**: $x_5 = p(Z,N)A^{-1/2}$，其中对于偶-偶核 $p(Z,N) = +1$，对于奇-奇核 $p(Z,N) = -1$，对于奇A核 $p(Z,N) = 0$。\n\n利用这些特征，结合能可以表示为一个线性模型：\n$$\nB(\\boldsymbol{x}) = \\boldsymbol{w}^T \\boldsymbol{x} = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 + w_5 x_5\n$$\n与 SEMF 对应的理想权重向量 $\\boldsymbol{w}_{\\text{ideal}}$ 是 $\\boldsymbol{w}_{\\text{ideal}} = [a_v, -a_s, -a_c, -a_a, a_p]^T = [15.8, -18.3, -0.714, -23.2, 12.0]^T$。\n\n步骤如下：\n1.  **数据生成**：我们生成一个输入-输出对的训练集。输入是来自 $Z \\in \\{2, 3, \\dots, 60\\}$ 和 $N \\in \\{2, 3, \\dots, 90\\}$ 定义的网格的整数对 $(Z,N)$。对于每对 $(Z_i, N_i)$，我们构建特征向量 $\\boldsymbol{x}_i$ 并使用给定的 SEMF 公式和系数计算相应的“真实”结合能 $y_i = B(Z_i, N_i)$。\n\n2.  **模型训练**：训练过程在于找到最能拟合训练数据的最优权重向量 $\\boldsymbol{w}$。给定特征矩阵 $\\boldsymbol{X}$（其中每行是一个特征向量 $\\boldsymbol{x}_i^T$）和目标向量 $\\boldsymbol{y}$（包含值 $y_i$），我们求解普通最小二乘问题。解由正规方程给出：\n$$\n\\boldsymbol{w} = (\\boldsymbol{X}^T \\boldsymbol{X})^{-1} \\boldsymbol{X}^T \\boldsymbol{y}\n$$\n求解此线性系统以获得学习到的模型参数 $\\boldsymbol{w}$。此计算使用一种数值稳定的方法，例如 `numpy.linalg.lstsq` 提供的方法。\n\n3.  **预测**：一旦模型训练完成（即权重向量 $\\boldsymbol{w}$ 已确定），我们就可以为任何原子核 $(Z_{\\text{test}}, N_{\\text{test}})$ 预测结合能。我们首先为测试核构建特征向量 $\\boldsymbol{x}_{\\text{test}}$。然后，预测的结合能 $\\hat{B}$ 通过点积计算得出：\n$$\n\\hat{B} = \\boldsymbol{w}^T \\boldsymbol{x}_{\\text{test}}\n$$\n此过程将应用于八个指定的测试核中的每一个。所得预测结果按要求四舍五入到三位小数。由于所选模型架构与数据生成函数的形式完美匹配，且数据无噪声，因此学习到的权重 $\\boldsymbol{w}$ 将与 $\\boldsymbol{w}_{\\text{ideal}}$ 几乎相同，模型的预测将忠实地再现 SEMF 的输出。即使对于训练范围之外的测试核，这一点也成立，这展示了基于正确物理原理的模型的泛化能力。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs a model to predict nuclear binding energy based on the Semi-Empirical Mass Formula (SEMF).\n    The program generates training data from the SEMF, trains a linear model, and predicts the binding\n    energy for a specified set of test nuclei.\n    \"\"\"\n\n    # SEMF coefficients (in MeV)\n    COEFFS = {\n        'a_v': 15.8,\n        'a_s': 18.3,\n        'a_c': 0.714,\n        'a_a': 23.2,\n        'a_p': 12.0\n    }\n\n    def get_pairing_factor(Z, N):\n        \"\"\"Calculates the sign of the pairing term.\"\"\"\n        if Z % 2 == 0 and N % 2 == 0:\n            return 1.0  # even-even\n        if Z % 2 != 0 and N % 2 != 0:\n            return -1.0  # odd-odd\n        return 0.0  # odd-A\n\n    def get_semf_features(Z, N):\n        \"\"\"\n        Calculates the 5 feature terms of the SEMF for a given nucleus (Z, N).\n        \"\"\"\n        if Z < 0 or N < 0 or (Z == 0 and N == 0):\n            return np.zeros(5)\n\n        A = float(Z + N)\n\n        # Handle cases where A is zero to avoid division by zero, though not expected here.\n        if A == 0:\n            return np.zeros(5)\n\n        # 1. Volume term feature\n        f1 = A\n        # 2. Surface term feature\n        f2 = A**(2/3)\n        # 3. Coulomb term feature\n        f3 = Z * (Z - 1) / (A**(1/3))\n        # 4. Asymmetry term feature\n        f4 = (A - 2 * Z)**2 / A\n        # 5. Pairing term feature\n        f5 = get_pairing_factor(Z, N) / np.sqrt(A)\n\n        return np.array([f1, f2, f3, f4, f5])\n\n    def get_semf_binding_energy(Z, N, coeffs):\n        \"\"\"\n        Calculates the ground-truth binding energy using the SEMF formula.\n        \"\"\"\n        features = get_semf_features(Z, N)\n        \n        # The ideal weights include the signs from the formula\n        ideal_weights = np.array([\n            coeffs['a_v'],\n            -coeffs['a_s'],\n            -coeffs['a_c'],\n            -coeffs['a_a'],\n            coeffs['a_p']\n        ])\n        \n        return np.dot(features, ideal_weights)\n\n    # --- 1. Data Generation ---\n    # Generate training data from the specified grid.\n    Z_range = range(2, 61)  # Z from 2 to 60\n    N_range = range(2, 91)  # N from 2 to 90\n    \n    X_train_list = []\n    y_train_list = []\n\n    for Z_val in Z_range:\n        for N_val in N_range:\n            features = get_semf_features(Z_val, N_val)\n            target = get_semf_binding_energy(Z_val, N_val, COEFFS)\n            X_train_list.append(features)\n            y_train_list.append(target)\n\n    X_train = np.array(X_train_list)\n    y_train = np.array(y_train_list)\n\n    # --- 2. Model Training ---\n    # Train a linear regression model by solving for the weights.\n    # weights = (X^T X)^-1 X^T y\n    # np.linalg.lstsq is a numerically stable way to do this.\n    weights, _, _, _ = np.linalg.lstsq(X_train, y_train, rcond=None)\n\n    # --- 3. Prediction ---\n    # Test suite of nuclei (Z, N)\n    test_cases = [\n        (1, 1),\n        (2, 2),\n        (3, 3),\n        (8, 9),\n        (26, 30),\n        (50, 70),\n        (82, 126),\n        (92, 146)\n    ]\n    \n    results = []\n    for Z_test, N_test in test_cases:\n        test_features = get_semf_features(Z_test, N_test)\n        # Predict binding energy using the trained model (learned weights)\n        prediction = np.dot(test_features, weights)\n        # Round the result to three decimal places\n        rounded_prediction = round(prediction, 3)\n        results.append(rounded_prediction)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们的最后一个实践将深入探讨量子力学的复杂性，解决一个解的确切形式未知的问题。你将使用一个神经网络作为一个高度灵活的变分拟设，来近似一个量子自旋系统的基态波函数 $\\Psi_\\theta(s)$。这个练习向你介绍了“神经量子态”这一前沿研究领域，并展示了将强大的机器学习模型与基本物理原理——变分原理——相结合，如何能够为原本棘手的多体问题找到近似解。",
            "id": "2410566",
            "problem": "设计并实现一个完整的、可运行的程序，该程序通过在神经网络拟设上最小化变分能量来近似量子自旋系统的基态，并报告指定测试套件的最小化能量。考虑一个由 $N$ 个自旋-$\\tfrac{1}{2}$ 自由度组成的一维环，在计算基 $\\{ \\lvert s \\rangle \\}$ 中，其中 $s = (s_1,\\dots,s_N)$ 且 $s_i \\in \\{-1,+1\\}$ 表示 $\\hat{\\sigma}_i^z$ 的本征值。哈密顿量为\n$$\n\\hat{H} = -J \\sum_{i=1}^{N} \\hat{\\sigma}_i^z \\hat{\\sigma}_{i+1}^z - h \\sum_{i=1}^{N} \\hat{\\sigma}_i^x \\,,\n$$\n采用周期性边界条件 $\\hat{\\sigma}_{N+1}^z \\equiv \\hat{\\sigma}_1^z$。在计算基中，对波函数振幅使用一个实值人工神经网络（ANN）变分拟设，\n$$\n\\Psi_\\theta(s) = \\exp\\!\\Big( w_2^\\top \\tanh(W_1 s + b_1) + b_2 \\Big) \\,,\n$$\n其中 $W_1 \\in \\mathbb{R}^{H \\times N}$，$b_1 \\in \\mathbb{R}^{H}$，$w_2 \\in \\mathbb{R}^{H}$，$b_2 \\in \\mathbb{R}$ 是集中在 $\\theta$ 中的变分参数，$H \\in \\mathbb{N}$ 是隐藏单元的数量，$\\tanh(\\cdot)$ 逐元素地应用。需要最小化的变分能量是瑞利商\n$$\nE(\\theta) = \\frac{\\langle \\Psi_\\theta \\lvert \\hat{H} \\rvert \\Psi_\\theta \\rangle}{\\langle \\Psi_\\theta \\vert \\Psi_\\theta \\rangle} \\,,\n$$\n其中内积是在整个希尔伯特空间上计算的。在计算基中，分子和分母可以写为\n$$\n\\langle \\Psi_\\theta \\lvert \\Psi_\\theta \\rangle = \\sum_{s} \\Psi_\\theta(s)^2 \\,,\n$$\n$$\n\\langle \\Psi_\\theta \\lvert \\hat{H} \\rvert \\Psi_\\theta \\rangle = \\sum_{s} \\Psi_\\theta(s)^2 \\left( -J \\sum_{i=1}^{N} s_i s_{i+1} \\right) + \\sum_{s} \\sum_{i=1}^{N} \\left( -h \\right) \\Psi_\\theta(s) \\Psi_\\theta\\!\\big(s^{(i)}\\big) \\,,\n$$\n其中 $s^{(i)}$ 表示将 $s$ 中的第 $i$ 个自旋翻转（$s_i \\mapsto -s_i$）后得到的构型，在键项 $s_{i+1}$ 中，下标按模 $N$ 计算。在此模型中，所有量都是无量纲的；请将能量报告为无量纲的实数。\n\n您的程序必须对下面的每个测试用例，通过搜索 $\\theta$ 来近似 $E(\\theta)$ 的最小值，所有用例均使用相同的固定架构大小 $H = 8$，然后仅以精确要求的格式输出最小化的能量。希尔伯特空间是有限的，所有求和必须对所有基构型进行精确计算；不允许进行随机抽样。\n\n测试套件：\n- 用例 1：$N = 3$，$J = 1.0$，$h = 0.5$。\n- 用例 2：$N = 4$，$J = 1.0$，$h = 1.0$。\n- 用例 3：$N = 5$，$J = 1.0$，$h = 0.0$。\n- 用例 4：$N = 6$，$J = 0.0$，$h = 1.0$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果的顺序与测试套件（用例 $1$ 到 $4$）相同。每个条目必须是小数点后舍入到六位的十进制浮点数。例如，一个有效的输出如下所示\n$$\n[\\dots,\\dots,\\dots,\\dots] \\,.\n$$\n输出中不允许有任何额外的文本或换行。",
            "solution": "所述问题是有效的。它提出了一个在计算物理学领域中定义明确且具有科学依据的任务，具体而言，是将机器学习方法应用于量子多体问题。其目标是使用神经网络变分拟设来寻找一维横向场伊辛模型基态能量的近似值。所有必要的组成部分——哈密顿量、拟设的形式、变分能量的定义以及测试用例的参数——都以数学上精确的方式给出。对于指定的系统尺寸（$N \\le 6$，希尔伯特空间维度 $2^N \\le 64$），对整个希尔伯特空间进行精确求和的约束在计算上是可行的，这使得该问题是自洽的，并且无需借助随机抽样方法即可求解。\n\n求解过程是通过最小化变分能量来进行的，该能量是哈密顿量对于变分态的期望值，并按该态的范数进行归一化。这是 Rayleigh-Ritz 变分原理的应用，该原理保证了计算出的能量 $E(\\theta)$ 是真实基态能量 $E_0$ 的一个上界，即 $E(\\theta) \\ge E_0$。在给定的拟设族内，最优近似是通过对网络参数 $\\theta$ 进行数值最小化 $E(\\theta)$ 来找到的。\n\n整体步骤如下：\n\n1.  **希尔伯特空间构建**：对于一个由 $N$ 个自旋组成的系统，其计算基由 $2^N$ 个态构成。每个基态都是一个构型 $s = (s_1, \\dots, s_N)$，其中 $s_i \\in \\{-1, +1\\}$。这 $2^N$ 个构型被显式地生成和存储。\n\n2.  **变分波函数拟设**：问题指定了一个实值神经网络拟设用于波函数振幅：\n    $$\n    \\Psi_\\theta(s) = \\exp\\!\\Big( w_2^\\top \\tanh(W_1 s + b_1) + b_2 \\Big)\n    $$\n    这里，$\\theta = \\{W_1, b_1, w_2, b_2\\}$ 是变分参数，其中 $W_1 \\in \\mathbb{R}^{H \\times N}$，$b_1 \\in \\mathbb{R}^{H}$，$w_2 \\in \\mathbb{R}^{H}$ 以及 $b_2 \\in \\mathbb{R}$。对于固定的隐藏单元数 $H=8$，参数总数为 $H(N+2)+1$。这些参数被展平为一个向量，以便与标准的数值优化器一起使用。实现一个函数来计算对于任何给定构型 $s$ 和参数矢量 $\\theta$ 的波函数振幅 $\\Psi_\\theta(s)$。\n\n3.  **变分能量计算**：任务的核心是评估目标函数，即由瑞利商给出的变分能量 $E(\\theta)$：\n    $$\n    E(\\theta) = \\frac{\\langle \\Psi_\\theta \\lvert \\hat{H} \\rvert \\Psi_\\theta \\rangle}{\\langle \\Psi_\\theta \\vert \\Psi_\\theta \\rangle}\n    $$\n    分母是波函数的范数平方，$\\langle \\Psi_\\theta \\vert \\Psi_\\theta \\rangle = \\sum_s \\Psi_\\theta(s)^2$，其中求和遍历所有 $2^N$ 个构型。\n\n    分子，即哈密顿量 $\\hat{H} = -J \\sum_{i} \\hat{\\sigma}_i^z \\hat{\\sigma}_{i+1}^z - h \\sum_{i} \\hat{\\sigma}_i^x$ 的期望值，被计算为两个独立的项：\n    \n    a.  **对角（伊辛）项**：算符 $\\hat{\\sigma}_i^z \\hat{\\sigma}_{i+1}^z$ 在计算基中是对角的。其期望值为：\n    $$\n    E_{\\text{diag}} = \\left\\langle -J \\sum_{i=1}^{N} \\hat{\\sigma}_i^z \\hat{\\sigma}_{i+1}^z \\right\\rangle = \\frac{\\sum_s \\Psi_\\theta(s)^2 \\left( -J \\sum_{i=1}^{N} s_i s_{i+1} \\right)}{\\sum_s \\Psi_\\theta(s)^2}\n    $$\n    这一项的计算方法是：对每个构型 $s$ 评估其经典能量 $-J \\sum_i s_i s_{i+1}$，用 $\\Psi_\\theta(s)^2$ 对其加权，然后将结果求和。\n\n    b.  **非对角（场）项**：算符 $\\hat{\\sigma}_i^x$ 是非对角的。它会翻转第 $i$ 个自旋，即 $\\hat{\\sigma}_i^x |s\\rangle = |s^{(i)}\\rangle$。其期望值为：\n    $$\n    E_{\\text{off-diag}} = \\left\\langle -h \\sum_{i=1}^{N} \\hat{\\sigma}_i^x \\right\\rangle = \\frac{\\sum_{s} \\sum_{i=1}^{N} (-h) \\Psi_\\theta(s) \\Psi_\\theta(s^{(i)})}{\\sum_s \\Psi_\\theta(s)^2}\n    $$\n    为了高效计算这一项，预先计算每个自旋构型到其在状态向量中对应索引的映射。这使得可以快速检索任何翻转后构型的振幅 $\\Psi_\\theta(s^{(i)})$。\n\n    总能量为 $E(\\theta) = E_{\\text{diag}} + E_{\\text{off-diag}}$。\n\n4.  **数值优化**：采用 `scipy.optimize.minimize` 中提供的准牛顿方法 `L-BFGS-B` 算法来寻找最小化能量函数 $E(\\theta)$ 的参数矢量 $\\theta$。优化过程使用一个小的随机生成参数矢量进行初始化以打破对称性。该算法迭代地调整参数，沿能量景观下降，直到满足梯度和函数值的收敛标准。\n\n这整个过程被封装起来，并对所提供的四个测试用例中的每一个执行，从而为每组物理参数 $(N, J, h)$ 得到最小化的变分能量。最终结果按要求四舍五入到小数点后六位。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nimport itertools\n\ndef solve():\n    \"\"\"\n    Calculates the ground state energy of the 1D transverse-field Ising model\n    using a neural network variational ansatz and exact summation.\n    \"\"\"\n    \n    H = 8 # Fixed number of hidden units\n\n    def get_spin_configs(N):\n        \"\"\"Generates all 2**N spin configurations for a chain of length N.\"\"\"\n        # Use float64 for compatibility with matrix multiplication\n        return np.array(list(itertools.product([-1.0, 1.0], repeat=N)), dtype=np.float64)\n\n    def unpack_params(params_flat, N, H):\n        \"\"\"Unflattens the parameter vector into network weights and biases.\"\"\"\n        idx = 0\n        W1 = params_flat[idx : idx + H * N].reshape((H, N))\n        idx += H * N\n        b1 = params_flat[idx : idx + H]\n        idx += H\n        w2 = params_flat[idx : idx + H]\n        idx += H\n        b2 = params_flat[idx]\n        return W1, b1, w2, b2\n\n    def psi_theta(params_flat, spins, N, H):\n        \"\"\"Computes the ANN wavefunction amplitude for a batch of spin configurations.\"\"\"\n        W1, b1, w2, b2 = unpack_params(params_flat, N, H)\n        # spins shape: (num_configs, N), W1.T shape: (N, H)\n        hidden_input = spins @ W1.T + b1\n        hidden_output = np.tanh(hidden_input)\n        # hidden_output shape: (num_configs, H), w2 shape: (H,)\n        log_psi = hidden_output @ w2 + b2\n        return np.exp(log_psi)\n\n    def create_objective_function(N, J, h, H, spin_configs, config_to_index_map):\n        \"\"\"\n        Factory to create the energy function for a given set of physical parameters.\n        This function will be the target for the numerical optimizer.\n        \"\"\"\n        def energy_function(params_flat):\n            # Calculate wavefunction amplitudes for all 2**N states\n            psi = psi_theta(params_flat, spin_configs, N, H)\n            psi_sq = np.square(psi)\n            norm_sq = np.sum(psi_sq)\n\n            # Defensive check for numerical stability\n            if norm_sq < 1e-12:\n                return 0.0\n\n            # 1. Diagonal part of H (Ising term)\n            # Roll spin configs to get neighbors for periodic boundary conditions\n            s_ip1 = np.roll(spin_configs, shift=-1, axis=1)\n            # Sum over bonds for each configuration\n            ising_interaction = np.sum(spin_configs * s_ip1, axis=1)\n            E_diag = np.sum(psi_sq * (-J * ising_interaction))\n\n            # 2. Off-diagonal part of H (Transverse-field term)\n            E_offdiag = 0.0\n            num_configs = 2**N\n            # Iterate over each configuration s\n            for k in range(num_configs):\n                config_s = spin_configs[k]\n                psi_s = psi[k]\n                # Iterate over each spin site i to flip\n                for i in range(N):\n                    s_flipped = config_s.copy()\n                    s_flipped[i] *= -1.0\n                    # Find the index of the flipped config using the pre-built map\n                    k_flipped = config_to_index_map[tuple(s_flipped)]\n                    psi_s_flipped = psi[k_flipped]\n                    E_offdiag += -h * psi_s * psi_s_flipped\n            \n            # Total energy is the sum of parts divided by the norm\n            total_energy = (E_diag + E_offdiag) / norm_sq\n            return total_energy\n\n        return energy_function\n\n    def solve_case(N, J, h):\n        \"\"\"\n        Sets up and runs the optimization for a single test case.\n        \"\"\"\n        # 1. Generate all basis states and a lookup map for efficiency\n        spin_configs = get_spin_configs(N)\n        config_to_index_map = {tuple(config): i for i, config in enumerate(spin_configs)}\n        \n        # 2. Create the specific objective function for this case\n        objective = create_objective_function(N, J, h, H, spin_configs, config_to_index_map)\n        \n        # 3. Perform the optimization\n        num_params = H * (N + 2) + 1\n        # Use a fixed random seed for reproducibility of the initial guess\n        np.random.seed(42)\n        initial_params = np.random.randn(num_params) * 0.1\n        \n        # L-BFGS-B is a good choice for this type of unconstrained optimization\n        res = minimize(\n            objective, \n            initial_params, \n            method='L-BFGS-B', \n            options={'maxiter': 2000, 'ftol': 1e-12, 'gtol': 1e-9}\n        )\n        \n        return res.fun\n\n    test_cases = [\n        (3, 1.0, 0.5), # Case 1\n        (4, 1.0, 1.0), # Case 2\n        (5, 1.0, 0.0), # Case 3\n        (6, 0.0, 1.0), # Case 4\n    ]\n\n    results = []\n    for N, J, h in test_cases:\n        minimized_energy = solve_case(N, J, h)\n        results.append(f\"{minimized_energy:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}