{
    "hands_on_practices": [
        {
            "introduction": "让我们通过一个物理学中的经典问题开启我们的动手实践：用实验数据验证一条基本定律。第一个练习  将引导你将斯特藩-玻尔兹曼定律与模拟的黑体辐射测量数据进行拟合。你将学习使用加权最小二乘法这一核心技术来确定物理参数，并利用卡方统计量来量化评估模型对数据的描述程度。",
            "id": "2379497",
            "problem": "一个有效辐射面积 $A$ 未知的黑体，在几个绝对温度 $T$ 下进行测量，以获得总辐射功率 $P$。其物理模型是 Stefan–Boltzmann 定律 $P = A\\,\\sigma\\,T^{4}$，其中 Stefan-Boltzmann 常量为 $\\sigma = 5.670\\,374\\,419\\times 10^{-8}\\ \\mathrm{W\\,m^{-2}\\,K^{-4}}$。假设所有温度都是精确已知的，并且每次功率测量 $P_i$ 都有一个独立的、已知的标准不确定度 $u_i$。\n\n对于每个数据集，将 $A$ 视为唯一的未知模型参数。使用所提供的三元组 $(T_i,P_i,u_i)$，确定使加权残差平方和（卡方值）最小化的值 $\\hat{A}$，\n$$\n\\chi^{2}(A) = \\sum_{i=1}^{N}\\frac{\\left[P_i - A\\,\\sigma\\,T_i^{4}\\right]^2}{u_i^{2}},\n$$\n然后计算：\n- 最小化的卡方值 $\\chi^{2}_{\\min}$，\n- 约化卡方值 $\\chi^{2}_{\\nu} = \\chi^{2}_{\\min}/\\nu$，其中自由度为 $\\nu = N - 1$，\n- 来自具有 $\\nu$ 自由度的卡方分布的拟合优度 $p$ 值 $p = \\Pr\\!\\left(\\chi^{2}_{\\nu} \\ge \\chi^{2}_{\\min}\\right)$，\n- 一个布尔决策 $\\mathrm{accept}$，如果 $p \\ge 0.05$ 则为 $\\mathrm{True}$，否则为 $\\mathrm{False}$。\n\n所有温度 $T$ 必须以开尔文为单位，所有功率 $P$ 和不确定度 $u$ 以瓦特为单位，面积估计值 $\\hat{A}$ 以平方米为单位。统计显著性水平为 $0.05$。报告 $\\hat{A}$（单位为平方米）、无量纲的 $\\chi^{2}_{\\nu}$ 和小数形式的 $p$ 值。\n\n使用以下包含3个数据集的测试套件：\n\n- 数据集1（噪声与模型一致）：\n  - $T$（开尔文）：$[300, 400, 500, 600, 700, 800]$。\n  - $P$（瓦特）：$[6.92, 21.50, 53.60, 109.40, 204.90, 347.20]$。\n  - $u$（瓦特）：$[0.30, 0.50, 0.70, 1.00, 1.20, 1.50]$。\n\n- 数据集2（相对于模型存在系统性偏移）：\n  - $T$（开尔文）：$[300, 400, 500, 600, 700, 800]$。\n  - $P$（瓦特）：$[11.90, 26.80, 58.20, 115.40, 208.80, 353.00]$。\n  - $u$（瓦特）：$[0.50, 0.50, 0.50, 0.70, 0.80, 1.00]$。\n\n- 数据集3（近乎完美的数据，不确定度小）：\n  - $T$（开尔文）：$[250, 500, 750]$。\n  - $P$（瓦特）：$[2.21499, 35.43984, 179.41419]$。\n  - $u$（瓦特）：$[0.10, 0.10, 0.10]$。\n\n您的程序必须按顺序处理所有数据集，并为每个数据集生成一个形式为 $[\\hat{A}, \\chi^{2}_{\\nu}, p, \\mathrm{accept}]$ 的结果列表。最终输出必须是单行，包含一个由这些每个数据集的列表组成的列表，元素之间用逗号分隔，并用方括号括起来。例如，输出格式应类似于 $[[a_1,b_1,c_1,d_1],[a_2,b_2,c_2,d_2],[a_3,b_3,c_3,d_3]]$，其中每个 $a_k$ 是一个以平方米为单位的浮点数，每个 $b_k$ 是一个浮点数，每个 $c_k$ 是一个浮点数，每个 $d_k$ 是一个布尔值。",
            "solution": "该问题要求对 Stefan-Boltzmann 定律 $P = A\\,\\sigma\\,T^{4}$ 与几个实验数据集进行卡方拟合优度分析。对于每个由 $N$ 个测量值 $(T_i, P_i, u_i)$ 组成的数据集，我们必须找到有效辐射面积的最佳拟合值 $\\hat{A}$，并评估拟合的质量。该模型在单个未知参数 $A$ 上是线性的。这个问题是加权线性最小二乘回归的经典案例。\n\n需要最小化的量是卡方统计量，定义为加权残差平方和：\n$$\n\\chi^{2}(A) = \\sum_{i=1}^{N}\\frac{\\left[P_i - P_{\\text{model}}(T_i; A)\\right]^2}{u_i^{2}}\n$$\n在此，$P_i$ 是在温度 $T_i$ 下测得的功率，$u_i$ 是测量值 $P_i$ 的标准不确定度，而 $P_{\\text{model}}(T_i; A) = A\\,\\sigma\\,T_i^{4}$ 是模型预测的功率。每个数据点的权重被隐式定义为 $w_i = 1/u_i^2$。\n\n为了找到使 $\\chi^{2}(A)$ 最小化的 $A$ 值（记为 $\\hat{A}$），我们必须求解方程 $\\frac{d\\chi^2}{dA} = 0$。其导数为：\n$$\n\\frac{d\\chi^{2}}{dA} = \\frac{d}{dA} \\sum_{i=1}^{N}\\frac{\\left[P_i - A\\,\\sigma\\,T_i^{4}\\right]^2}{u_i^{2}} = \\sum_{i=1}^{N} \\frac{2\\left[P_i - A\\,\\sigma\\,T_i^{4}\\right](-\\sigma\\,T_i^{4})}{u_i^{2}}\n$$\n将导数设为零，并求解 $\\hat{A}$：\n$$\n\\sum_{i=1}^{N} \\frac{\\left[P_i - \\hat{A}\\,\\sigma\\,T_i^{4}\\right](\\sigma\\,T_i^{4})}{u_i^{2}} = 0\n$$\n$$\n\\sum_{i=1}^{N} \\frac{P_i\\,\\sigma\\,T_i^{4}}{u_i^{2}} - \\sum_{i=1}^{N} \\frac{\\hat{A}\\,(\\sigma\\,T_i^{4})^2}{u_i^{2}} = 0\n$$\n$$\n\\hat{A} \\sum_{i=1}^{N} \\frac{(\\sigma\\,T_i^{4})^2}{u_i^{2}} = \\sum_{i=1}^{N} \\frac{P_i\\,\\sigma\\,T_i^{4}}{u_i^{2}}\n$$\n这给出了最佳拟合参数 $\\hat{A}$ 的解析表达式：\n$$\n\\hat{A} = \\frac{\\sum_{i=1}^{N} (P_i \\sigma T_i^4 / u_i^2)}{\\sum_{i=1}^{N} (\\sigma T_i^4 / u_i)^2}\n$$\n\n一旦确定了 $\\hat{A}$，我们就可以通过将 $\\hat{A}$ 代入原始表达式来计算最小化的卡方值 $\\chi^{2}_{\\min}$：\n$$\n\\chi^{2}_{\\min} = \\chi^{2}(\\hat{A}) = \\sum_{i=1}^{N}\\frac{\\left[P_i - \\hat{A}\\,\\sigma\\,T_i^{4}\\right]^2}{u_i^{2}}\n$$\n\n自由度 $\\nu$ 是数据点的数量 $N$ 减去拟合参数的数量 $M$。在这种情况下，$M=1$（参数 $A$），所以 $\\nu = N - 1$。\n\n约化卡方值 $\\chi^{2}_{\\nu}$ 提供了一个拟合优度的度量，它通过自由度进行了归一化：\n$$\n\\chi^{2}_{\\nu} = \\frac{\\chi^{2}_{\\min}}{\\nu}\n$$\n对于一个好的拟合，即模型正确且不确定度 $u_i$ 被准确估计时，我们期望 $\\chi^{2}_{\\nu} \\approx 1$。$\\chi^{2}_{\\nu} \\gg 1$ 的值表明拟合效果差或不确定度被低估，而 $\\chi^{2}_{\\nu} \\ll 1$ 的值则表明拟合效果过好，可能是由于不确定度被高估。\n\n为了使拟合优度检验形式化，我们计算 $p$ 值。$p$ 值是在假设原假设（即模型是正确的）为真的情况下，获得一个至少与观测到的 $\\chi^{2}_{\\min}$ 一样大的卡方统计量的概率。这个概率是根据具有 $\\nu$ 个自由度的卡方分布的生存函数（1 - 累积分布函数）计算的：\n$$\np = \\Pr(\\chi^2_{\\text{dist}} \\ge \\chi^{2}_{\\min} \\mid \\nu) = \\int_{\\chi^{2}_{\\min}}^{\\infty} f(x; \\nu) dx\n$$\n其中 $f(x; \\nu)$ 是具有 $\\nu$ 个自由度的 $\\chi^2$ 分布的概率密度函数。\n\n最终的决策是通过将 $p$ 值与预定义的显著性水平 $\\alpha = 0.05$ 进行比较来做出的。\n- 如果 $p \\ge 0.05$，观测到的与模型的偏差在统计上不显著。我们接受该模型作为数据的合理解释。布尔值 `accept` 为 $\\mathrm{True}$。\n- 如果 $p  0.05$，偏差在统计上是显著的，这意味着这种差异不太可能仅仅由随机机会引起。我们拒绝该模型。布尔值 `accept` 为 $\\mathrm{False}$。\n\n该程序将应用于所提供的三个数据集中的每一个。对于每个数据集，我们将计算元组 $(\\hat{A}, \\chi^{2}_{\\nu}, p, \\mathrm{accept})$。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Performs chi-squared analysis for the Stefan-Boltzmann law on given datasets.\n    \"\"\"\n    # Stefan-Boltzmann constant in W m^-2 K^-4\n    SIGMA = 5.670374419e-8\n\n    # Define the datasets as provided in the problem statement.\n    test_cases = [\n        {\n            \"T\": np.array([300, 400, 500, 600, 700, 800]),  # kelvins\n            \"P\": np.array([6.92, 21.50, 53.60, 109.40, 204.90, 347.20]),  # watts\n            \"u\": np.array([0.30, 0.50, 0.70, 1.00, 1.20, 1.50]),  # watts\n        },\n        {\n            \"T\": np.array([300, 400, 500, 600, 700, 800]),\n            \"P\": np.array([11.90, 26.80, 58.20, 115.40, 208.80, 353.00]),\n            \"u\": np.array([0.50, 0.50, 0.50, 0.70, 0.80, 1.00]),\n        },\n        {\n            \"T\": np.array([250, 500, 750]),\n            \"P\": np.array([2.21499, 35.43984, 179.41419]),\n            \"u\": np.array([0.10, 0.10, 0.10]),\n        },\n    ]\n\n    results = []\n    significance_level = 0.05\n\n    for case in test_cases:\n        T, P, u = case[\"T\"], case[\"P\"], case[\"u\"]\n\n        # Number of data points\n        N = len(T)\n        \n        # Degrees of freedom (N data points - 1 fitted parameter)\n        nu = N - 1\n\n        # Model value for P with A=1, this is sigma * T^4\n        model_base = SIGMA * T**4\n\n        # Calculate the best-fit parameter A_hat using the derived analytical formula\n        # A_hat = sum(P_i * sigma * T_i^4 / u_i^2) / sum((sigma * T_i^4)^2 / u_i^2)\n        numerator = np.sum(P * model_base / u**2)\n        denominator = np.sum(model_base**2 / u**2)\n        A_hat = numerator / denominator\n\n        # Calculate the minimized chi-squared value\n        residuals = P - A_hat * model_base\n        chi2_min = np.sum((residuals / u)**2)\n\n        # Calculate the reduced chi-squared\n        chi2_nu = chi2_min / nu if nu  0 else 0.0\n\n        # Calculate the p-value (goodness-of-fit)\n        # It's the probability of getting a chi2 value = chi2_min\n        p_value = chi2.sf(chi2_min, nu)\n\n        # Make the decision based on the significance level\n        accept = p_value = significance_level\n        \n        # Store results for this dataset\n        results.append([A_hat, chi2_nu, p_value, accept])\n\n    # Format the final output string according to the problem specification\n    # to avoid spaces inside the lists.\n    list_of_strings = []\n    for res in results:\n        # str(True) - 'True', str(False) - 'False'\n        # which is the correct boolean representation in this context.\n        list_of_strings.append(f\"[{res[0]},{res[1]},{res[2]},{res[3]}]\")\n    \n    final_output = f\"[{','.join(list_of_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了单个模型的拟合之后，我们现在来处理一个在研究中更常见的情形：从几个相互竞争的理论中选择最佳解释。这个练习  要求你判断一个数据集更符合指数衰减模型还是幂律模型。通过这个实践，你将接触到非线性拟合的复杂性，并学习如何运用归一化卡方统计量作为模型选择的有力工具。",
            "id": "2379487",
            "problem": "给定三个独立的数据集，由三元组 $\\{(x_i,y_i,\\sigma_i)\\}_{i=1}^{N}$ 组成，其中 $x_i$ 是正的、无量纲的横坐标，$y_i$ 是正的、无量纲的纵坐标，$\\sigma_i$ 是每个 $y_i$ 的独立高斯测量噪声的已知、正的、无量纲的标准差。对于每个数据集，考虑两个用于严格为正、单调递减信号的竞争参数模型：指数衰减模型 $y(x)=A\\,e^{-\\lambda x}$（参数为 $A0$ 和 $\\lambda\\ge 0$），以及幂律模型 $y(x)=C\\,x^{-\\alpha}$（参数为 $C0$ 和 $\\alpha0$）。对于每个模型和每个数据集，将卡方统计量定义为\n$$\n\\chi^2(A,\\lambda)=\\sum_{i=1}^{N}\\left(\\frac{y_i-Ae^{-\\lambda x_i}}{\\sigma_i}\\right)^2,\\qquad\n\\chi^2(C,\\alpha)=\\sum_{i=1}^{N}\\left(\\frac{y_i-Cx_i^{-\\alpha}}{\\sigma_i}\\right)^2,\n$$\n并将最佳拟合参数定义为在指定参数域上使相应 $\\chi^2$ 最小化的参数。设 $p=2$ 为每个模型中的自由参数数量，设 $\\nu=N-p$ 为自由度，并为每个模型定义约化卡方 $\\chi^2_\\nu=\\chi^2/\\nu$（当 $\\nu0$ 时）。对于 $\\nu\\le 0$ 的每个数据集，将模型比较视为不确定。对于 $\\nu0$ 的每个数据集，使用以下规则决定首选模型：如果 $\\lvert \\chi^2_{\\nu,\\mathrm{pow}}-\\chi^2_{\\nu,\\mathrm{exp}}\\rvert \\le \\varepsilon$，则宣布结果不确定；否则，首选具有较小约化卡方的模型。使用容差 $\\varepsilon=10^{-2}$。您的程序必须处理以下数据集测试套件并产生所需的决策。\n\n测试套件（无量纲）：\n- 数据集 $\\mathrm{D1}$（指数生成，异方差）：\n  - 横坐标：$x_i=i$，其中 $i\\in\\{1,2,3,4,5,6,7,8\\}$，因此 $N=8$。\n  - 纵坐标：$y_i = A\\,e^{-\\lambda x_i}$，其中 $A=2.5$ 和 $\\lambda=0.5$。\n  - 标准差：$\\sigma_i = 0.05 + 0.01\\,y_i$。\n- 数据集 $\\mathrm{D2}$（幂律生成，同方差）：\n  - 横坐标：$x_i=i$，其中 $i\\in\\{1,2,3,4,5,6,7,8\\}$，因此 $N=8$。\n  - 纵坐标：$y_i = C\\,x_i^{-\\alpha}$，其中 $C=1.8$ 和 $\\alpha=1.4$。\n  - 标准差：对于所有 $i$，$\\sigma_i = 0.06$。\n- 数据集 $\\mathrm{D3}$（退化的边界情况）：\n  - 横坐标：$x_1=1.0$, $x_2=3.0$，因此 $N=2$。\n  - 纵坐标：$y_1=2.0$, $y_2=0.4$。\n  - 标准差：$\\sigma_1=0.05$, $\\sigma_2=0.05$。\n\n您的任务是，为每个数据集计算使每个模型的卡方最小化的最佳拟合参数，计算约化卡方值 $\\chi^2_{\\nu,\\mathrm{exp}}$ 和 $\\chi^2_{\\nu,\\mathrm{pow}}$（当其有定义时），然后，使用容差 $\\varepsilon=10^{-2}$ 的决策规则，为每个数据集输出一个整数代码：如果首选指数模型，输出 $0$；如果首选幂律模型，输出 $1$；如果比较不确定（因为至少一个模型的 $\\nu\\le 0$ 或因为约化卡方值的差异最多为 $\\varepsilon$），输出 $-1$。所有量都是无单位的。您的程序应生成一行输出，其中包含分别为 $\\mathrm{D1}$、$\\mathrm{D2}$ 和 $\\mathrm{D3}$ 的三个整数决策代码，形式为用方括号括起来的逗号分隔列表（例如，$[0,1,-1]$）。",
            "solution": "核心任务是针对三个不同的数据集，比较两种竞争模型——指数衰减模型 $y(x)=A\\,e^{-\\lambda x}$ 和幂律模型 $y(x)=C\\,x^{-\\alpha}$——的拟合优度。比较度量是约化卡方统计量 $\\chi^2_{\\nu}$，定义为 $\\chi^2_{\\nu} = \\chi^2 / \\nu$，其中 $\\nu = N - p$ 代表自由度。这里，$N$ 是数据点的数量，$p=2$ 是每个模型中的自由参数数量。\n\n此分析的基础是为每个模型和数据集最小化卡方函数。指数模型的卡方统计量由下式给出\n$$\n\\chi^2(A,\\lambda)=\\sum_{i=1}^{N}\\left(\\frac{y_i-Ae^{-\\lambda x_i}}{\\sigma_i}\\right)^2\n$$\n幂律模型的卡方统计量由下式给出\n$$\n\\chi^2(C,\\alpha)=\\sum_{i=1}^{N}\\left(\\frac{y_i-Cx_i^{-\\alpha}}{\\sigma_i}\\right)^2.\n$$\n最佳拟合参数 $(A, \\lambda)$ 和 $(C, \\alpha)$ 是在满足约束条件 $A0$、$\\lambda\\ge 0$ 和 $C0$、$\\alpha0$ 的情况下，使这些各自的 $\\chi^2$ 值最小化的参数。\n\n由于两个模型在其参数上都是非线性的，因此找到 $\\chi^2$ 函数的最小值需要数值优化。拟牛顿法，特别是 L-BFGS-B 算法，适合此任务，因为它可以处理参数上的边界约束。这类迭代优化算法的成功很大程度上取决于为参数提供一个合理的初始猜测。生成此类初始猜测的有效策略是线性化模型。\n\n对于指数模型，取自然对数得到 $\\ln(y) = \\ln(A) - \\lambda x$。这是 $\\ln(y)$ 和 $x$ 之间的线性关系。对 $\\ln(y_i)$ 与 $x_i$ 进行加权线性最小二乘拟合，可以为 $\\ln(A)$（截距）和 $-\\lambda$（斜率）提供初始估计值。权重必须考虑不确定性的传播，其中 $\\ln(y_i)$ 的方差近似为 $(\\sigma_i/y_i)^2$。\n\n类似地，对于幂律模型，对数变换 $\\ln(y) = \\ln(C) - \\alpha \\ln(x)$ 建立了 $\\ln(y)$ 和 $\\ln(x)$ 之间的线性关系。对 $\\ln(y_i)$ 与 $\\ln(x_i)$ 进行加权线性最小二乘拟合，可以为 $\\ln(C)$ 和 $-\\alpha$ 提供初始估计值，权重使用相同的误差传播。\n\n每个数据集的处理步骤如下：\n1.  确定数据点数 $N$，并计算自由度 $\\nu = N - p = N - 2$。\n2.  如果 $\\nu \\le 0$，问题陈述规定比较结果为不确定。这适用于数据集 $\\mathrm{D3}$，其中 $N=2$，因此 $\\nu=0$。\n3.  如果 $\\nu  0$，则对两个模型进行拟合过程。\n    a. 对于每个模型，使用线性化加权最小二乘法生成初始参数猜测。\n    b. 使用 L-BFGS-B 算法找到使非线性 $\\chi^2$ 函数最小化的参数，从初始猜测开始并遵守参数边界。\n    c. 记录最小化的卡方值 $\\chi^2_{\\mathrm{min}}$。\n    d. 计算约化卡方 $\\chi^2_\\nu = \\chi^2_{\\mathrm{min}} / \\nu$。\n4.  应用决策规则：如果 $\\lvert \\chi^2_{\\nu,\\mathrm{pow}}-\\chi^2_{\\nu,\\mathrm{exp}}\\rvert \\le \\varepsilon$，其中容差为 $\\varepsilon=10^{-2}$，则结果不确定。否则，首选具有较小 $\\chi^2_\\nu$ 值的模型。\n\n基于这个严谨的程序，分配整数代码：$0$ 表示指数模型，$1$ 表示幂律模型，$-1$ 表示不确定的结果。这些数据集是合成的，并且生成时没有随机噪声，这意味着数据集 $\\mathrm{D1}$（指数）和数据集 $\\mathrm{D2}$（幂律）的正确模型应该会产生一个数值上接近于零的 $\\chi^2$ 值，从而确保一个决定性的比较。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves the model comparison problem for three datasets by performing\n    chi-squared minimization and applying a decision rule.\n    \"\"\"\n    \n    # Define the decision rule tolerance\n    EPSILON = 1e-2\n    # Number of free parameters in each model\n    P_PARAMS = 2\n\n    # --- Dataset Definitions ---\n    # Dataset D1 (exponential-generated, heteroscedastic)\n    x1 = np.arange(1, 9, dtype=float)\n    A_true_d1, lambda_true_d1 = 2.5, 0.5\n    y1 = A_true_d1 * np.exp(-lambda_true_d1 * x1)\n    sigma1 = 0.05 + 0.01 * y1\n    N1 = len(x1)\n    dataset1 = (x1, y1, sigma1, N1)\n\n    # Dataset D2 (power-law-generated, homoscedastic)\n    x2 = np.arange(1, 9, dtype=float)\n    C_true_d2, alpha_true_d2 = 1.8, 1.4\n    y2 = C_true_d2 * x2**(-alpha_true_d2)\n    sigma2 = np.full_like(x2, 0.06)\n    N2 = len(x2)\n    dataset2 = (x2, y2, sigma2, N2)\n\n    # Dataset D3 (degenerate edge case)\n    x3 = np.array([1.0, 3.0])\n    y3 = np.array([2.0, 0.4])\n    sigma3 = np.array([0.05, 0.05])\n    N3 = len(x3)\n    dataset3 = (x3, y3, sigma3, N3)\n\n    test_cases = [dataset1, dataset2, dataset3]\n\n    # --- Fitting and Analysis Functions ---\n    def get_initial_guess(x, y, sigma, model_type):\n        \"\"\"\n        Calculates initial parameter guesses by linearizing the model\n        and performing a weighted linear least-squares fit.\n        \"\"\"\n        # Filter out non-positive y values for log transformation\n        valid_indices = y  0\n        if not np.any(valid_indices):\n            return [1.0, 1.0] # Default guess if no valid data\n        x_f, y_f, sigma_f = x[valid_indices], y[valid_indices], sigma[valid_indices]\n\n        weights = (y_f / sigma_f)**2\n\n        if model_type == 'exp':\n            # Linear model: log(y) = log(A) - lambda * x\n            fit_x = x_f\n            fit_y = np.log(y_f)\n            m, b = np.polyfit(fit_x, fit_y, 1, w=weights)\n            A0, lambda0 = np.exp(b), -m\n            return [A0, lambda0]\n        elif model_type == 'pow':\n            # Linear model: log(y) = log(C) - alpha * log(x)\n            fit_x = np.log(x_f)\n            fit_y = np.log(y_f)\n            m, b = np.polyfit(fit_x, fit_y, 1, w=weights)\n            C0, alpha0 = np.exp(b), -m\n            return [C0, alpha0]\n        return [1.0, 1.0]\n\n    def fit_model_and_get_chi2(x, y, sigma, model_type):\n        \"\"\"\n        Performs chi-squared minimization for a given model and dataset.\n        Returns the minimized chi-squared value.\n        \"\"\"\n        if model_type == 'exp':\n            model_func = lambda p, x_d: p[0] * np.exp(-p[1] * x_d)\n            bounds = [(1e-9, None), (0.0, None)]  # A  0, lambda = 0\n        elif model_type == 'pow':\n            model_func = lambda p, x_d: p[0] * x_d**(-p[1])\n            bounds = [(1e-9, None), (1e-9, None)]  # C  0, alpha  0\n        else:\n            raise ValueError(\"Unknown model type\")\n\n        chi2_func = lambda p: np.sum(((y - model_func(p, x)) / sigma)**2)\n        \n        initial_guess = get_initial_guess(x, y, sigma, model_type)\n        # Ensure initial guess is within bounds\n        initial_guess[0] = max(bounds[0][0], initial_guess[0]) if bounds[0][1] is None else min(bounds[0][1], max(bounds[0][0], initial_guess[0]))\n        initial_guess[1] = max(bounds[1][0], initial_guess[1]) if bounds[1][1] is None else min(bounds[1][1], max(bounds[1][0], initial_guess[1]))\n\n        result = minimize(chi2_func, initial_guess, method='L-BFGS-B', bounds=bounds)\n        return result.fun\n\n    # --- Main Loop for Processing Test Cases ---\n    results = []\n    for x_data, y_data, sigma_data, N in test_cases:\n        nu = N - P_PARAMS\n\n        if nu = 0:\n            results.append(-1)\n            continue\n\n        chi2_min_exp = fit_model_and_get_chi2(x_data, y_data, sigma_data, 'exp')\n        chi2_min_pow = fit_model_and_get_chi2(x_data, y_data, sigma_data, 'pow')\n\n        chi2_nu_exp = chi2_min_exp / nu\n        chi2_nu_pow = chi2_min_pow / nu\n\n        if abs(chi2_nu_pow - chi2_nu_exp) = EPSILON:\n            results.append(-1)\n        elif chi2_nu_exp  chi2_nu_pow:\n            results.append(0)  # Exponential model preferred\n        else:\n            results.append(1)  # Power-law model preferred\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们的最后一个练习将卡方检验的应用从拟合函数形式扩展到检验概率分布的形状，这是统计数据分析中的一项基本任务。在这个练习  中，你将检验模拟的粒子探测事件之间的时间间隔是否符合泊松过程所预期的指数分布。这个实践问题将引导你从第一性原理出发，整合最大似然估计和等概率分箱等关键技术，构建一个统计上严谨的分析。",
            "id": "2379578",
            "problem": "您的任务是评估连续模拟 α 粒子探测之间的时间间隔分布是否与齐次泊松过程所期望的指数分布一致。您的程序必须使用有原则的统计构造方法，实现卡方拟合优度检验。推导必须仅从核心定义和公认事实出发，并据此构建算法。\n\n背景与基本原理：\n- 速率恒为 $\\lambda$ 的齐次泊松过程意味着其到达间隔时间 $T$ 是独立同分布的，服从概率密度函数为 $f_{T}(t) = \\lambda e^{-\\lambda t}$ ($t \\ge 0$) 的指数分布。\n- 对于指数分布，基于观测到的到达间隔时间 $\\{t_{i}\\}_{i=1}^{N}$，速率参数 $\\lambda$ 的最大似然估计量是 $\\hat{\\lambda} = 1 / \\bar{t}$，其中 $\\bar{t}$ 是样本均值。这是通过在指数模型下最大化似然函数得出的。\n- 卡方拟合优度检验将分组中的观测频数与假设分布下的期望频数进行比较。对于分组概率 $\\{p_{j}\\}_{j=1}^{B}$ 和观测频数 $\\{O_{j}\\}_{j=1}^{B}$ 以及样本量 $N$，检验统计量为\n$$\n\\chi^{2} = \\sum_{j=1}^{B} \\frac{(O_{j} - E_{j})^{2}}{E_{j}},\n$$\n其中 $E_{j} = N p_{j}$。当参数由数据估计时，自由度为 $B - 1 - m$，其中 $m$ 是从数据中估计的参数个数。\n- 为确保期望频数稳定，请在原假设模型下使用等概率分组：如果 $F(t)$ 是原假设下的累积分布函数（此处为速率为 $\\hat{\\lambda}$ 的指数分布），则选择 $B$ 个分组，其边界由分位数 $q_{i} = F^{-1}(i/B)$（其中 $i = 1, \\dots, B-1$）定义，并辅以 $0$ 和 $+\\infty$。在带有估计参数的原假设下，每个分组的期望概率为 $p_{j} = 1/B$，因此 $E_{j} = N/B$。\n\n任务：\n- 对于每个数据集，根据观测到的到达间隔时间 $\\{t_{i}\\}_{i=1}^{N}$（单位：秒）估计 $\\hat{\\lambda} = 1/\\bar{t}$。在拟合的指数模型下，使用 $q_{i} = -\\ln(1 - i/B) / \\hat{\\lambda}$（其中 $i = 1, \\dots, B-1$），并辅以 $q_{0} = 0$ 和 $q_{B} = +\\infty$，构建 $B$ 个等概率分组。选择 $B$ 为不超过 $N/5$ 的最大整数，但不大于 10，且至少为 3，即 $B = \\max(3, \\min(10, \\lfloor N/5 \\rfloor))$。这保证了当 $N \\ge 15$ 时，每个分组的期望频数至少为 $N/B \\ge 5$。\n- 计算卡方统计量\n$$\n\\chi^{2} = \\sum_{j=1}^{B} \\frac{(O_{j} - N/B)^{2}}{N/B}.\n$$\n- 使用自由度 $\\nu = B - 1 - 1 = B - 2$，因为有一个参数 $\\lambda$ 是从数据中估计的。计算具有 $\\nu$ 个自由度的卡方分布的右尾概率（累积分布函数的补）以获得 p 值\n$$\np = \\Pr\\left(\\chi^{2}_{\\nu} \\ge \\chi^{2}_{\\text{observed}}\\right).\n$$\n- 决策规则：在显著性水平 $\\alpha = 0.05$ 下，如果 $p \\ge \\alpha$，则判定数据与指数分布一致；如果 $p  \\alpha$，则判定为不一致。\n\n物理与数值单位：\n- 所有时间均以秒为单位。不涉及角度。最终程序输出由布尔值组成，因此无单位。\n\n测试套件：\n您的程序必须在内部生成以下四个数据集，并对每个数据集应用上述检验：\n\n1. 情况 A (正常路径): 从速率为 $\\lambda = 0.5 \\ \\text{s}^{-1}$ 的指数分布中模拟的到达间隔时间，样本量 $N = 200$，使用固定种子 $12345$ 的伪随机数生成器。这些数据应与指数模型一致。\n2. 情况 B (结构化偏差): 从形状参数 $k = 2$、尺度参数 $\\theta = 1.0$ (均值为 2.0 秒) 的伽马分布中模拟的到达间隔时间，样本量 $N = 200$，使用种子 $54321$。这些数据不是指数分布的。\n3. 情况 C (混合偏差): 从两个指数分布的混合模型中模拟的到达间隔时间：以 $0.5$ 的概率使用速率 $\\lambda_{1} = 0.5 \\ \\text{s}^{-1}$，以 $0.5$ 的概率使用速率 $\\lambda_{2} = 2.0 \\ \\text{s}^{-1}$；样本量 $N = 300$，种子 $2024$。这些数据不是指数分布的。\n4. 情况 D (小样本边界条件): 从速率为 $\\lambda = 1.2 \\ \\text{s}^{-1}$ 的指数分布中模拟的到达间隔时间，样本量 $N = 30$，种子 $13579$。这用于测试每个分组中可接受的最小频数下的行为。\n\n所有随机抽样必须使用固定种子进行，以确保可复现性。必须完全按照规定使用底层分布。指数分布的累积分布函数反函数应如上文所述进行解析实现，而非数值实现。\n\n答案规格与最终输出格式：\n- 对于每种情况，输出一个布尔值：如果数据在 $\\alpha = 0.05$ 水平下与指数模型一致 (即 $p \\ge 0.05$)，则输出 $True$；否则输出 $False$。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，不含空格，顺序为 [情况 A, 情况 B, 情况 C, 情况 D]。例如，如果情况 A 和 D 一致，而情况 B 和 C 不一致，则输出应精确为 \"[True,False,False,True]\"。",
            "solution": "该问题提出了一个计算物理和统计学领域中有效且适定的任务。它要求实现一个卡方拟合优度检验，以确定几组模拟的到达间隔时间数据集是否与指数分布一致。该过程基于可靠的统计学原理，包括最大似然估计和使用等概率分组来确保卡方近似的有效性。所有必要的参数、公式和条件都已提供，问题没有科学上的不准确、歧义或矛盾之处。我们将着手进行正式的推导和解决方案的实现。\n\n问题的核心是检验原假设 $H_0$，即给定的到达间隔时间样本 $\\{t_i\\}_{i=1}^{N}$ 是从一个指数分布中抽取的。指数分布的概率密度函数 (PDF) 由下式给出：\n$$\nf(t; \\lambda) = \\lambda e^{-\\lambda t} \\quad \\text{for } t \\ge 0\n$$\n其中 $\\lambda  0$ 是速率参数。\n\n由于速率参数 $\\lambda$ 未知，必须首先从数据中对其进行估计。问题指定使用最大似然估计量 (MLE)。对于样本 $\\{t_i\\}_{i=1}^{N}$，似然函数 $L(\\lambda)$ 是各个概率的乘积：\n$$\nL(\\lambda; \\{t_i\\}) = \\prod_{i=1}^{N} f(t_i; \\lambda) = \\prod_{i=1}^{N} \\lambda e^{-\\lambda t_i} = \\lambda^N e^{-\\lambda \\sum_{i=1}^{N} t_i}\n$$\n为了找到使该函数最大化的 $\\lambda$ 值，处理对数似然函数 $\\ln L$ 更为方便：\n$$\n\\ln L(\\lambda) = \\ln\\left(\\lambda^N e^{-\\lambda \\sum t_i}\\right) = N \\ln \\lambda - \\lambda \\sum_{i=1}^{N} t_i\n$$\n我们通过对 $\\lambda$ 求导并令其为零来找到最大值：\n$$\n\\frac{d(\\ln L)}{d\\lambda} = \\frac{N}{\\lambda} - \\sum_{i=1}^{N} t_i = 0\n$$\n解出 $\\lambda$ 即可得到 MLE，记为 $\\hat{\\lambda}$：\n$$\n\\hat{\\lambda} = \\frac{N}{\\sum_{i=1}^{N} t_i} = \\frac{1}{\\bar{t}}\n$$\n其中 $\\bar{t} = \\frac{1}{N}\\sum_{i=1}^{N} t_i$ 是到达间隔时间的样本均值。\n\n有了估计参数 $\\hat{\\lambda}$，我们现在可以构建卡方检验。该检验需要将变量的定义域（时间，$t \\ge 0$）划分为 $B$ 个不相交的分组，并将每个分组 $j$ 中的观测数据点数 ($O_j$) 与原假设下的期望数据点数 ($E_j$) 进行比较。\n\n问题指定了等概率分组策略。这意味着，假设 $H_0$ 为真，分组边界的选择应使每个分组包含一个数据点的概率相等。这个概率对于所有分组 $j=1, \\dots, B$ 都是 $p_j = 1/B$。分组边界是使用累积分布函数 (CDF) 的反函数（也称为分位数函数）来确定的。速率为 $\\hat{\\lambda}$ 的指数分布的 CDF 为：\n$$\nF(t) = \\Pr(T \\le t) = \\int_0^t \\hat{\\lambda} e^{-\\hat{\\lambda} \\tau} d\\tau = 1 - e^{-\\hat{\\lambda} t}\n$$\n为了求得分位数函数，我们令 $F(q) = p$ 并解出 $q$：\n$$\np = 1 - e^{-\\hat{\\lambda} q} \\implies e^{-\\hat{\\lambda} q} = 1 - p \\implies -\\hat{\\lambda} q = \\ln(1 - p) \\implies q(p) = F^{-1}(p) = -\\frac{\\ln(1 - p)}{\\hat{\\lambda}}\n$$\n分组边界 $\\{q_j\\}_{j=0}^{B}$ 由对应于累积概率 $j/B$ 的分位数定义。第 $j$ 个分组是区间 $[q_{j-1}, q_j)$。边界为 $q_j = F^{-1}(j/B)$，其中 $j=0, 1, \\dots, B$。这给出：\n$q_0 = F^{-1}(0) = 0$\n$q_j = -\\frac{\\ln(1 - j/B)}{\\hat{\\lambda}}$ 其中 $j = 1, \\dots, B-1$\n$q_B = F^{-1}(1)$，对应于 $t \\to \\infty$。\n\n分组数 $B$ 由规则 $B = \\max(3, \\min(10, \\lfloor N/5 \\rfloor))$ 确定，这是一种启发式方法，旨在确保期望频数不会太小（通常建议 $E_j \\ge 5$）。每个分组中的期望频数为 $E_j = N \\cdot p_j = N \\cdot (1/B) = N/B$。\n\n卡方检验统计量 $\\chi^2_{\\text{observed}}$ 衡量了观测频数与期望频数之间的差异：\n$$\n\\chi^2_{\\text{observed}} = \\sum_{j=1}^{B} \\frac{(O_j - E_j)^2}{E_j}\n$$\n代入 $E_j = N/B$，公式变为：\n$$\n\\chi^2_{\\text{observed}} = \\sum_{j=1}^{B} \\frac{(O_j - N/B)^2}{N/B} = \\frac{B}{N} \\sum_{j=1}^{B} (O_j - N/B)^2\n$$\n\n在原假设下，该统计量服从卡方分布 $\\chi^2_{\\nu}$。自由度 $\\nu$ 由 $\\nu = B - 1 - m$ 给出，其中 $m$ 是从数据中估计的参数个数。在本例中，我们估计了一个参数 $\\lambda$，所以 $m=1$。因此，自由度为：\n$$\n\\nu = B - 2\n$$\n关于 $B$ 的规则确保了 $B \\ge 3$，因此 $\\nu \\ge 1$，这是必需的。\n\n为了做出决策，我们计算 p 值。p 值是在假设 $H_0$ 为真的情况下，观测到等于或大于 $\\chi^2_{\\text{observed}}$ 的 $\\chi^2$ 值的概率。这对应于 $\\chi^2_{\\nu}$ 分布右尾下的面积：\n$$\np = \\Pr(\\chi^2_{\\nu} \\ge \\chi^2_{\\text{observed}})\n$$\n这是使用卡方分布的生存函数（CDF 的补函数）计算的。\n\n最后，在显著性水平 $\\alpha = 0.05$ 下应用决策规则：\n- 如果 $p \\ge 0.05$，我们不拒绝原假设。数据被认为与指数分布一致。结果为 `True`。\n- 如果 $p  0.05$，我们拒绝原假设。数据提供了反对指数模型的显著证据。结果为 `False`。\n\n这一完整流程将应用于四个指定的测试案例中的每一个。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef perform_chi2_test(data: np.ndarray, alpha: float) - bool:\n    \"\"\"\n    Performs a chi-squared goodness-of-fit test for an exponential distribution.\n\n    Args:\n        data: A 1D numpy array of observed inter-arrival times.\n        alpha: The significance level for the test.\n\n    Returns:\n        A boolean: True if the data is consistent with the exponential model, False otherwise.\n    \"\"\"\n    N = len(data)\n    if N == 0:\n        # Avoid division by zero if data is empty, though problem constraints prevent this.\n        return False\n    \n    # Step 1: Estimate the rate parameter lambda using MLE.\n    # The MLE for the rate parameter of an exponential distribution is 1 / sample_mean.\n    t_bar = np.mean(data)\n    if t_bar = 0:\n        # Rate must be positive. This case is unlikely with positive time intervals.\n        return False\n    lambda_hat = 1.0 / t_bar\n\n    # Step 2: Determine the number of bins B.\n    # B = max(3, min(10, floor(N/5)))\n    B = int(max(3, min(10, np.floor(N / 5))))\n\n    # Step 3: Define equiprobable bin edges using the inverse CDF (quantile function).\n    # F_inv(p) = -ln(1-p) / lambda\n    # Edges are at F_inv(j/B) for j=0, ..., B.\n    # The last bin edge must be infinity to capture all remaining data.\n    bin_edges = np.zeros(B + 1)\n    for j in range(1, B):\n        p_j = j / B\n        bin_edges[j] = -np.log(1 - p_j) / lambda_hat\n    bin_edges[B] = np.inf\n\n    # Step 4: Calculate observed counts O_j in each bin.\n    # np.histogram counts occurrences in [edge1, edge2), including the rightmost edge for the last bin.\n    observed_counts, _ = np.histogram(data, bins=bin_edges)\n\n    # Step 5: Calculate expected counts E_j.\n    # For equiprobable bins, E_j = N / B for all j.\n    expected_count = N / B\n\n    # Step 6: Calculate the chi-squared statistic.\n    # chi^2 = sum((O_j - E_j)^2 / E_j)\n    chi2_observed = np.sum((observed_counts - expected_count)**2 / expected_count)\n\n    # Step 7: Determine degrees of freedom.\n    # nu = B - 1 - m, where m is the number of estimated parameters (m=1 for lambda).\n    dof = B - 2\n    \n    if dof = 0:\n        # This occurs if B = 2, which our rule for B prevents (B = 3).\n        # It implies the test cannot be reliably performed.\n        return False\n\n    # Step 8: Calculate the p-value.\n    # This is the right-tail probability of the chi-squared distribution.\n    p_value = chi2.sf(chi2_observed, df=dof)\n\n    # Step 9: Make a decision based on the significance level.\n    # If p = alpha, we do not reject H0. Data is consistent.\n    return p_value = alpha\n\ndef solve():\n    \"\"\"\n    Generates data for four test cases and applies the chi-squared test to each.\n    \"\"\"\n    alpha = 0.05\n    results = []\n\n    test_cases_defs = {\n        'A': {'type': 'exponential', 'params': {'scale': 1.0 / 0.5}, 'N': 200, 'seed': 12345},\n        'B': {'type': 'gamma', 'params': {'shape': 2.0, 'scale': 1.0}, 'N': 200, 'seed': 54321},\n        'C': {'type': 'mixture', 'params': {'scale1': 1.0/0.5, 'scale2': 1.0/2.0, 'prob': 0.5}, 'N': 300, 'seed': 2024},\n        'D': {'type': 'exponential', 'params': {'scale': 1.0 / 1.2}, 'N': 30, 'seed': 13579}\n    }\n    \n    for case_id in ['A', 'B', 'C', 'D']:\n        case = test_cases_defs[case_id]\n        rng = np.random.default_rng(case['seed'])\n        \n        if case['type'] == 'exponential':\n            data = rng.exponential(scale=case['params']['scale'], size=case['N'])\n        elif case['type'] == 'gamma':\n            data = rng.gamma(shape=case['params']['shape'], scale=case['params']['scale'], size=case['N'])\n        elif case['type'] == 'mixture':\n            N = case['N']\n            p = case['params']['prob']\n            scale1 = case['params']['scale1']\n            scale2 = case['params']['scale2']\n            \n            # Generate choices based on probability p\n            choices = rng.uniform(0, 1, N)  p\n            \n            # Generate two sets of exponential variates\n            set1 = rng.exponential(scale=scale1, size=N)\n            set2 = rng.exponential(scale=scale2, size=N)\n            \n            # Create the mixture sample\n            data = np.where(choices, set1, set2)\n        \n        # Perform the test and store the boolean result\n        is_consistent = perform_chi2_test(data, alpha)\n        results.append(is_consistent)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}