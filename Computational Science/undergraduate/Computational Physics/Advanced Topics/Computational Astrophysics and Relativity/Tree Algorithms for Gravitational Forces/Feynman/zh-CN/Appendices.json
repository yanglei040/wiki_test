{
    "hands_on_practices": [
        {
            "introduction": "理论学习的最佳伙伴是动手实践。本练习旨在从零开始构建一个完整的二维Barnes-Hut（BH）四叉树N体模拟器。您将模拟一个旋转的原行星盘，并通过追踪角动量这一基本守恒量来验证您实现的物理正确性。这个实践不仅能巩固您对树算法核心逻辑的理解，还能让您直观地看到算法参数（如张角$\\theta$）如何影响物理模拟的精度和长期稳定性。",
            "id": "2447325",
            "problem": "请使用Barnes–Hut（BH）四叉树实现一个二维引力$N$体模拟器，以近似计算旋转原行星盘中的力，并随时间追踪总角动量以分析其守恒性。工作应完全在无量纲的“代码单位”下进行，引力常数$G=1$，因此不需要物理单位。所有角度测量必须使用弧度。您的任务是从第一性原理出发，基于基本定律和核心定义来设计并实现完整的算法，不依赖任何预打包的$N$体程序。\n\n模拟域包含一颗中心恒星和周围的粒子盘：\n- 中心恒星质量为$M_{\\star}$，初始位于原点。\n- 粒子盘总质量为$M_{\\mathrm{disk}}$，分布在$N_{\\mathrm{disk}}$个等质量粒子上。这些粒子在一个内径为$r_{\\min}$、外径为$r_{\\max}$的环形区域内采样，其径向概率密度在$[r_{\\min}, r_{\\max}]$上与$r$成正比，角度在$[0,2\\pi)$上均匀分布。\n- 每个盘粒子的初始速度为切向速度，大小设置为仅由中心恒星产生的圆周速度，即$v(r) = \\sqrt{G M_{\\star} / r}$，方向垂直于半径矢量，与顺行旋转方向一致。恒星的初始速度为零。\n\n基本原理：\n- 牛顿第二定律：$m_i \\, d^2 \\mathbf{r}_i/dt^2 = \\mathbf{F}_i$。\n- 适用于点质量的牛顿万有引力定律（带普卢默软化）：对于粒子$i \\neq j$，粒子$j$对粒子$i$产生的加速度为\n$$\n\\mathbf{a}_{i\\leftarrow j} = G \\, m_j \\, \\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert^2 + \\epsilon^2\\right)^{3/2}} \\, .\n$$\n- 在二维空间中，绕原点的总角动量（$z$分量）为\n$$\nL_z = \\sum_{i=1}^{N} m_i \\, (x_i v_{y,i} - y_i v_{x,i}) \\, .\n$$\n\n算法要求：\n- 使用二维的Barnes–Hut四叉树（首次使用时定义缩写）。每个树节点存储总质量和质心。使用几何接受准则，即当一个边长为$s$、质心与目标粒子距离为$d$的节点满足$s/d < \\theta$时，将其视为单一源，其中$\\theta$是张角参数。若不满足，则递归进入其子节点。对于叶节点，直接对其中包含的粒子进行两两之间的软化作用力求和，不包括自身相互作用。\n- 使用固定时间步长$\\Delta t$的辛蛙跳（kick–drift–kick）时间积分器：\n  $$\n  \\mathbf{v}^{n+\\frac{1}{2}} = \\mathbf{v}^n + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^n), \\quad\n  \\mathbf{r}^{n+1} = \\mathbf{r}^n + \\Delta t\\,\\mathbf{v}^{n+\\frac{1}{2}}, \\quad\n  \\mathbf{v}^{n+1} = \\mathbf{v}^{n+\\frac{1}{2}} + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^{n+1}) \\, .\n  $$\n- 追踪初始角动量$L_z(0)$和在积分区间$T = n_{\\mathrm{steps}} \\, \\Delta t$结束时的最终角动量$L_z(T)$。报告由下式定义的相对漂移（无量纲）：\n$$\n\\delta_L = \\frac{\\lvert L_z(T) - L_z(0) \\rvert}{\\lvert L_z(0) \\rvert} \\, .\n$$\n\n实现细节与约束：\n- 为初始条件的生成使用确定性的随机数生成器种子，以确保结果可复现。\n- 构建根四叉树单元以包围所有粒子，并根据需要进行细分。为防止病态的无限细分，允许一个小的最大深度，并在一个过度细化的叶节点内切换到直接求和。\n- 确保在每个时间步计算力时都重建树。\n- 程序不得读取输入。必须在内部生成指定的测试用例并打印结果。\n\n测试套件：\n所有测试的通用参数：\n- $G = 1$, $M_{\\star} = 10$, $M_{\\mathrm{disk}} = 1$, $N_{\\mathrm{disk}} = 128$, $r_{\\min} = 0.5$, $r_{\\max} = 2.5$, 确定性种子 $= 42$, 粒子总数 $N = N_{\\mathrm{disk}} + 1$。\n- 每个测试的初始条件必须完全相同地重新生成，以便只有算法参数不同。\n\n每个测试用例指定$(\\theta, \\Delta t, n_{\\mathrm{steps}}, \\epsilon)$:\n- 测试 $1$ (正常路径): $(\\theta = 0.5, \\ \\Delta t = 0.01, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$。\n- 测试 $2$ (更严格的张角；趋向于直接求和): $(\\theta = 0.2, \\ \\Delta t = 0.01, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$。\n- 测试 $3$ (更宽松的张角；更大的近似误差): $(\\theta = 1.0, \\ \\Delta t = 0.01, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$。\n- 测试 $4$ (更粗糙的时间步；积分器压力测试): $(\\theta = 0.5, \\ \\Delta t = 0.02, \\ n_{\\mathrm{steps}} = 40, \\ \\epsilon = 0.02)$。\n\n对于每个测试，计算上面定义的标量$\\delta_L$。您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[0.00123,0.00045,0.00321,0.00456]$），顺序为测试$1$到$4$。输出均为无量纲实数。所有计算中角度必须使用弧度。不得打印任何额外文本。",
            "solution": "我们从第一性原理出发设计该解决方案。首先是牛顿第二定律$m_i \\, d^2 \\mathbf{r}_i/dt^2 = \\mathbf{F}_i$。对于一个由$N$个点质量通过引力相互作用的系统，牛顿万有引力定律给出了粒子$j$对$i$的两两作用力$\\mathbf{F}_{ij}$。除以$m_i$得到加速度\n$$\n\\mathbf{a}_{i\\leftarrow j} = G \\, m_j \\, \\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert^2 + \\epsilon^2\\right)^{3/2}} \\, ,\n$$\n其中$\\epsilon$是一个很小的普卢默软化长度，用于正则化零间距处的奇点，并模拟有限尺寸的质量元。对所有$j \\neq i$求和，得到净加速度$\\mathbf{a}_i$。\n\n对于一个二维系统，其绕原点的总角动量由$z$分量定义：\n$$\nL_z = \\sum_{i=1}^{N} m_i \\, (x_i v_{y,i} - y_i v_{x,i}) = \\sum_{i=1}^{N} m_i \\, (\\mathbf{r}_i \\times \\mathbf{v}_i)_z \\, .\n$$\n对其求时间导数得到\n$$\n\\frac{dL_z}{dt} = \\sum_{i=1}^{N} m_i \\, (\\mathbf{r}_i \\times \\mathbf{a}_i)_z \\, .\n$$\n对于精确的、具有两两中心力的牛顿引力，根据牛顿第三定律（作用力与反作用力大小相等、方向相反且作用在同一直线上），内力矩成对抵消，这意味着在没有外力矩的情况下，$\\frac{dL_z}{dt} = 0$，总角动量守恒。数值近似可能引入对作用-反作用对称性的违反和时间积分误差，导致微小的漂移$\\delta_L$。\n\n直接对所有两两相互作用求和，每次力评估的成本为$\\mathcal{O}(N^2)$。Barnes–Hut (BH) 算法将粒子组织到一个二维的分层四叉树中。每个节点代表一个方形区域，并存储其中粒子的总质量和质心。对于一个位于位置$\\mathbf{r}$的目标粒子和一个边长为$s$、质心距$\\mathbf{r}$为$d$的树节点，当满足以下条件时，单极近似将整个节点视为一个位于其质心的伪粒子：\n$$\n\\frac{s}{d} < \\theta \\, ,\n$$\n其中$\\theta$是控制精度与效率权衡的张角参数。如果不满足该准则，节点将被“打开”，我们递归到其子节点。对于叶节点，我们计算其包含的粒子（不包括自身相互作用）的直接软化贡献。对于分离良好的粒子群，单极截断误差的量级为$\\mathcal{O}\\!\\left((s/d)^2\\right)$，因此减小$\\theta$可以提高精度并减少可能导致角动量漂移的系统性力不对称性。\n\n时间积分使用辛蛙跳（kick–drift–kick）方法，该方法是时间可逆的，并且对于哈密顿系统表现出优越的长期守恒特性。给定时间步长$\\Delta t$，更新步骤如下：\n$$\n\\mathbf{v}^{n+\\frac{1}{2}} = \\mathbf{v}^n + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^n), \\quad\n\\mathbf{r}^{n+1} = \\mathbf{r}^n + \\Delta t\\,\\mathbf{v}^{n+\\frac{1}{2}}, \\quad\n  \\mathbf{v}^{n+1} = \\mathbf{v}^{n+\\frac{1}{2}} + \\frac{\\Delta t}{2}\\,\\mathbf{a}(\\mathbf{r}^{n+1}) \\, .\n$$\n此方案在开始时需要一次力评估，之后每步一次。我们使用选定的$\\theta$和软化参数$\\epsilon$，通过BH树来评估力。\n\n初始条件在代码单位下模拟一个原行星盘。质量为$M_{\\star}$的中心恒星位于原点，速度为零。总质量为$M_{\\mathrm{disk}}$的盘由$N_{\\mathrm{disk}}$个等质量粒子表示，这些粒子在环形区域$[r_{\\min}, r_{\\max}]$内采样，其径向概率密度与$r$成正比，以实现环内的面积均匀分布。可以通过将一个均匀分布的随机变量$u \\in [0,1]$转换为半径来抽取样本\n$$\nr = \\sqrt{u \\, (r_{\\max}^2 - r_{\\min}^2) + r_{\\min}^2} \\, ,\n$$\n角度$\\phi$在$[0, 2\\pi)$上均匀分布。每个盘粒子以环绕恒星的圆周轨道速度$v(r) = \\sqrt{G M_{\\star}/r}$开始运动，方向为切向$\\hat{\\boldsymbol{\\phi}} = (-\\sin \\phi, \\cos \\phi)$，因此初始状态近似为一个冷的、近开普勒的盘。恒星的初始速度为零；对于足够各向同性的样本，根据对称性，总线性动量接近于零。\n\n数值设计细节：\n- 树的构建：计算一个包含所有位置的边界正方形，其中心和半尺寸略有填充。根据需要将节点递归地细分为四个子节点（四叉树）。为避免近乎重合点导致的病态无限细分，强制一个最大深度（例如$d_{\\max}$），并允许叶节点在达到此限制后存储多个物体；这类叶节点通过直接相互作用求和。\n- 质量和质心计算：在所有插入操作完成后，执行一次后序遍历，从其子节点或包含的物体计算每个节点的总质量和质心。\n- 力评估：对于一个目标粒子，遍历树并应用接受准则$s/d < \\theta$。对于被接受的节点，加上软化的单极加速度。对于叶节点或被拒绝的节点，递归或直接求和，跳过自身相互作用。使用$\\epsilon$通过$(r^2 + \\epsilon^2)^{3/2}$计算软化距离。\n- 角动量追踪：根据初始位置和速度计算$L_z(0)$。运行蛙跳积分器$n_{\\mathrm{steps}}$步。在执行最后的半步踢之后，计算$L_z(T)$和相对漂移\n$$\n\\delta_L = \\frac{\\lvert L_z(T) - L_z(0) \\rvert}{\\lvert L_z(0) \\rvert} \\, .\n$$\n\n测试套件的基本原理：\n- 测试 $1$ ($\\theta = 0.5$, $\\Delta t = 0.01$, $n_{\\mathrm{steps}} = 40$, $\\epsilon = 0.02$) 是一个平衡的配置，预期会产生较小的$\\delta_L$。\n- 测试 $2$ ($\\theta = 0.2$) 收紧了张角，使BH力更接近直接求和；$\\delta_L$不应超过测试1，通常会减小。\n- 测试 $3$ ($\\theta = 1.0$) 放宽了准则，增加了近似误差；$\\delta_L$预计将比测试1-2中的大。\n- 测试 $4$ (更粗糙的$\\Delta t = 0.02$) 对时间积分器施加压力，即使$\\theta$与测试1相同，也可能增加$\\delta_L$。\n\n程序为每个测试重新生成相同的初始条件（相同的种子），并使用指定的参数运行模拟，计算四个$\\delta_L$值。它打印一行格式为Python风格列表$[x_1,x_2,x_3,x_4]$的结果，其中每个$x_k$是测试$k$对应的$\\delta_L$。所有输出都是无量纲实数，并且计算中角度始终以弧度为单位。",
            "answer": "```python\n# Barnes–Hut angular momentum conservation analysis in a rotating disk\n# Execution environment: Python 3.12, numpy 1.23.5, scipy 1.11.4 (not used)\nimport numpy as np\n\n# ----------------------------\n# Utility: angular momentum\n# ----------------------------\ndef angular_momentum_z(m, r, v):\n    # Lz = sum m_i (x_i v_yi - y_i v_xi)\n    return float(np.sum(m * (r[:, 0] * v[:, 1] - r[:, 1] * v[:, 0])))\n\n# ----------------------------\n# Quadtree implementation\n# ----------------------------\nclass QuadNode:\n    __slots__ = (\n        \"cx\", \"cy\", \"h\", \"children\", \"bodies\", \"mass\", \"comx\", \"comy\", \"depth\"\n    )\n\n    def __init__(self, cx, cy, h, depth=0):\n        self.cx = float(cx)\n        self.cy = float(cy)\n        self.h = float(h)  # half-size\n        self.children = None  # list of 4 QuadNode or None\n        self.bodies = []      # list of indices if leaf\n        self.mass = 0.0\n        self.comx = 0.0\n        self.comy = 0.0\n        self.depth = depth\n\n    def subdivide(self):\n        hh = 0.5 * self.h\n        d = self.depth + 1\n        self.children = [\n            QuadNode(self.cx - hh, self.cy - hh, hh, d),  # SW\n            QuadNode(self.cx + hh, self.cy - hh, hh, d),  # SE\n            QuadNode(self.cx - hh, self.cy + hh, hh, d),  # NW\n            QuadNode(self.cx + hh, self.cy + hh, hh, d),  # NE\n        ]\n\n    def which_child(self, x, y):\n        east = x > self.cx\n        north = y > self.cy\n        if not east and not north:\n            return 0  # SW\n        if east and not north:\n            return 1  # SE\n        if not east and north:\n            return 2  # NW\n        return 3  # NE\n\n    def insert(self, idx, pos, max_bucket, max_depth):\n        # Insert body index idx at position pos[idx]\n        if self.children is None:\n            # Leaf: store body\n            self.bodies.append(idx)\n            # If exceeds bucket and can subdivide, split and reinsert\n            if len(self.bodies) > max_bucket and self.depth  max_depth:\n                self.subdivide()\n                old = self.bodies\n                self.bodies = []\n                for j in old:\n                    child = self.which_child(pos[j, 0], pos[j, 1])\n                    self.children[child].insert(j, pos, max_bucket, max_depth)\n        else:\n            # Internal: insert into appropriate child\n            child = self.which_child(pos[idx, 0], pos[idx, 1])\n            self.children[child].insert(idx, pos, max_bucket, max_depth)\n\n    def finalize_mass_com(self, m, pos):\n        if self.children is None:\n            if len(self.bodies) == 0:\n                self.mass = 0.0\n                self.comx = self.cx\n                self.comy = self.cy\n            elif len(self.bodies) == 1:\n                j = self.bodies[0]\n                self.mass = float(m[j])\n                self.comx = float(pos[j, 0])\n                self.comy = float(pos[j, 1])\n            else:\n                # Aggregate\n                mm = 0.0\n                cx = 0.0\n                cy = 0.0\n                for j in self.bodies:\n                    mj = float(m[j])\n                    mm += mj\n                    cx += mj * float(pos[j, 0])\n                    cy += mj * float(pos[j, 1])\n                self.mass = mm\n                if mm > 0.0:\n                    self.comx = cx / mm\n                    self.comy = cy / mm\n                else:\n                    self.comx = self.cx\n                    self.comy = self.cy\n        else:\n            mm = 0.0\n            cx = 0.0\n            cy = 0.0\n            for ch in self.children:\n                ch.finalize_mass_com(m, pos)\n                mm += ch.mass\n                cx += ch.mass * ch.comx\n                cy += ch.mass * ch.comy\n            self.mass = mm\n            if mm > 0.0:\n                self.comx = cx / mm\n                self.comy = cy / mm\n            else:\n                self.comx = self.cx\n                self.comy = self.cy\n\n    def acc_on(self, i, pos, m, G, theta, eps2):\n        ax = 0.0\n        ay = 0.0\n        if self.mass == 0.0:\n            return 0.0, 0.0\n\n        # Distance from particle i to node COM\n        dx = self.comx - pos[i, 0]\n        dy = self.comy - pos[i, 1]\n        d2 = dx * dx + dy * dy\n\n        if self.children is None:\n            # Leaf: direct sum over contained bodies excluding self\n            for j in self.bodies:\n                if j == i:\n                    continue\n                rx = pos[j, 0] - pos[i, 0]\n                ry = pos[j, 1] - pos[i, 1]\n                r2 = rx * rx + ry * ry + eps2\n                invr3 = 1.0 / (r2 * np.sqrt(r2))\n                s = G * float(m[j]) * invr3\n                ax += s * rx\n                ay += s * ry\n            return ax, ay\n\n        # Internal node: apply BH acceptance criterion\n        # side length s = 2h\n        if d2 > 0.0:\n            s_over_d = (2.0 * self.h) / np.sqrt(d2)\n        else:\n            s_over_d = np.inf\n\n        if s_over_d  theta:\n            # Accept node as single source\n            r2 = d2 + eps2\n            invr3 = 1.0 / (r2 * np.sqrt(r2))\n            s = G * self.mass * invr3\n            ax += s * dx\n            ay += s * dy\n        else:\n            # Recurse into children\n            for ch in self.children:\n                cx, cy = ch.acc_on(i, pos, m, G, theta, eps2)\n                ax += cx\n                ay += cy\n        return ax, ay\n\n# ----------------------------\n# Force computation via BH\n# ----------------------------\ndef compute_accelerations(pos, m, theta, eps, max_bucket=1, max_depth=20):\n    N = pos.shape[0]\n    # Build bounding square\n    xmin = float(np.min(pos[:, 0]))\n    xmax = float(np.max(pos[:, 0]))\n    ymin = float(np.min(pos[:, 1]))\n    ymax = float(np.max(pos[:, 1]))\n    cx = 0.5 * (xmin + xmax)\n    cy = 0.5 * (ymin + ymax)\n    half = max(xmax - xmin, ymax - ymin) * 0.5\n    if half = 0.0:\n        half = 1.0\n    half *= 1.05  # small padding\n\n    root = QuadNode(cx, cy, half, depth=0)\n    for i in range(N):\n        root.insert(i, pos, max_bucket, max_depth)\n    root.finalize_mass_com(m, pos)\n\n    G = 1.0\n    eps2 = float(eps) * float(eps)\n    acc = np.zeros_like(pos)\n    for i in range(N):\n        ax, ay = root.acc_on(i, pos, m, G, theta, eps2)\n        acc[i, 0] = ax\n        acc[i, 1] = ay\n    return acc\n\n# ----------------------------\n# Leapfrog integrator (KDK)\n# ----------------------------\ndef leapfrog_bh(pos0, vel0, m, dt, nsteps, theta, eps):\n    pos = pos0.copy()\n    vel = vel0.copy()\n\n    # Initial angular momentum (using velocities at integer time)\n    L0 = angular_momentum_z(m, pos, vel)\n\n    # Initial acceleration and half kick\n    acc = compute_accelerations(pos, m, theta, eps)\n    vel += 0.5 * dt * acc\n\n    # Time stepping\n    for step in range(nsteps):\n        pos += dt * vel\n        acc = compute_accelerations(pos, m, theta, eps)\n        if step != nsteps - 1:\n            vel += dt * acc\n\n    # Final half kick\n    vel += 0.5 * dt * acc\n\n    Lf = angular_momentum_z(m, pos, vel)\n    rel_drift = abs(Lf - L0) / max(1e-16, abs(L0))\n    return rel_drift\n\n# ----------------------------\n# Initial conditions: rotating disk + central star\n# ----------------------------\ndef generate_initial_conditions(seed, N_disk, M_star, M_disk, rmin, rmax):\n    rng = np.random.default_rng(seed)\n    # Star at origin\n    pos_star = np.array([[0.0, 0.0]])\n    vel_star = np.array([[0.0, 0.0]])\n    m_star = np.array([M_star], dtype=float)\n\n    # Disk sampling: radial PDF ∝ r on [rmin, rmax]\n    u = rng.random(N_disk)\n    radii = np.sqrt(u * (rmax * rmax - rmin * rmin) + rmin * rmin)\n    phi = rng.random(N_disk) * (2.0 * np.pi)\n    x = radii * np.cos(phi)\n    y = radii * np.sin(phi)\n    pos_disk = np.column_stack((x, y))\n\n    # Tangential velocity for circular orbit due to star alone\n    G = 1.0\n    v_mag = np.sqrt(G * M_star / np.maximum(radii, 1e-12))\n    vx = -v_mag * np.sin(phi)\n    vy =  v_mag * np.cos(phi)\n    vel_disk = np.column_stack((vx, vy))\n\n    # Masses\n    m_disk = np.full(N_disk, M_disk / N_disk, dtype=float)\n\n    # Combine star + disk\n    pos = np.vstack((pos_star, pos_disk))\n    vel = np.vstack((vel_star, vel_disk))\n    m = np.concatenate((m_star, m_disk))\n    return pos, vel, m\n\n# ----------------------------\n# Main solve function\n# ----------------------------\ndef solve():\n    # Common parameters\n    G = 1.0  # code units\n    M_star = 10.0\n    M_disk = 1.0\n    N_disk = 128\n    rmin = 0.5\n    rmax = 2.5\n    seed = 42\n\n    # Test suite: (theta, dt, nsteps, eps)\n    test_cases = [\n        (0.5, 0.01, 40, 0.02),  # Test 1: happy path\n        (0.2, 0.01, 40, 0.02),  # Test 2: stricter opening\n        (1.0, 0.01, 40, 0.02),  # Test 3: looser opening\n        (0.5, 0.02, 40, 0.02),  # Test 4: coarser time step\n    ]\n\n    # Generate identical initial conditions for each test\n    pos0, vel0, m = generate_initial_conditions(seed, N_disk, M_star, M_disk, rmin, rmax)\n\n    results = []\n    for theta, dt, nsteps, eps in test_cases:\n        # Copy initial conditions so each test starts identically\n        pos = pos0.copy()\n        vel = vel0.copy()\n        rel_drift = leapfrog_bh(pos, vel, m, dt, nsteps, theta, eps)\n        # format with reasonable precision\n        results.append(rel_drift)\n\n    # Print in the exact required format\n    # Use repr-like formatting for clarity without extra text\n    print(f\"[{','.join(f'{x:.8g}' for x in results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "实际的N体系统，如星系和星团，通常具有密度极不均匀的结构，例如致密的中心核和稀疏的外围。在这种情况下，纯粹的树算法可能不是最高效的。本练习将带您探索一种混合计算方案：对中心高密度区域使用精确的直接求和方法，而对外部区域使用高效的树算法。您的任务是扮演一名计算科学家，通过权衡计算成本与模拟精度，找到分割这两个区域的最佳半径$R_c$，从而体验真实科研场景中的算法优化过程。",
            "id": "2447320",
            "problem": "给定一组限制在平面内的质点，其位置和相等的质量按如下方式确定性地指定。根据带有 Plummer 软化的牛顿定律，粒子 $i$ 上由所有其他粒子产生的引力加速度定义为\n$$\n\\mathbf{a}_i \\;=\\; G \\sum_{\\substack{j=1 \\\\ j\\neq i}}^{N} m_j \\,\\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert^2 + \\varepsilon^2\\right)^{3/2}},\n$$\n其中 $G$ 是引力常数，$m_j$ 是粒子 $j$ 的质量，$\\mathbf{r}_j \\in \\mathbb{R}^2$ 是其位置，$\\varepsilon$ 是一个软化长度，$\\lVert \\cdot \\rVert$ 是欧几里得范数。使用 $G = 1$，对所有 $j$ 有 $m_j = 1/N$，以及 $\\varepsilon = 10^{-3}$。所有量都以一致的无量纲单位表示；边界半径应以与位置相同的长度单位报告。\n\n为所有 $N$ 个目标粒子定义一个混合评估算子，该算子依赖于一个以原点为中心的边界半径 $R_c \\ge 0$：\n- 对于每个满足 $\\lVert \\mathbf{r}_i \\rVert \\le R_c$ 的目标粒子（“中心”区域），其加速度通过对所有其他源粒子进行上述软化牛顿表达式的精确直接求和来评估。\n- 对于每个满足 $\\lVert \\mathbf{r}_i \\rVert  R_c$ 的目标粒子（“外部”区域），其加速度通过如下定义的分层树近似来评估。整个区域被一个以原点为中心、半边长为 $H$ 的正方形包围，该正方形被递归地细分为四个相等的正方形（构成一个四叉树），直到每个叶节点最多包含 $n_{\\text{leaf}}$ 个粒子。每个树节点 $u$ 具有边长 $s_u$、节点总质量 $M_u$ 和质心位置 $\\mathbf{R}_u$。对于位于 $\\mathbf{r}$ 处的目标粒子，如果满足以下条件，则节点 $u$ 被接受为单个多极子：\n$$\n\\frac{s_u}{d_u} \\le \\theta, \\quad d_u = \\lVert \\mathbf{R}_u - \\mathbf{r} \\rVert,\n$$\n此时其贡献为单极子项\n$$\n\\mathbf{a}_u(\\mathbf{r}) \\;=\\; G \\, M_u \\,\\frac{\\mathbf{R}_u - \\mathbf{r}}{\\left(\\lVert \\mathbf{R}_u - \\mathbf{r} \\rVert^2 + \\varepsilon^2\\right)^{3/2}}。\n$$\n如果节点未被接受，则将其打开，并对其子节点应用相同的规则；如果到达一个叶节点，则通过精确的软化牛顿表达式对其包含的粒子进行求和。打开参数 $\\theta0$ 和叶节点容量 $n_{\\text{leaf}} \\in \\mathbb{N}$ 是给定的常数。\n\n对于固定的 $(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}})$，粒子位置是确定性的，并通过低差异构造给出。对于 $i \\in \\{1,2,\\dots,N\\}$，将 $i$ 写成基数 $b$ 的形式 $i = \\sum_{k=0}^{K} d_k b^k$，其中数字为 $d_k \\in \\{0,1,\\dots,b-1\\}$，然后定义以 $b \\in \\mathbb{N}$ 为基数的 van der Corput 根式反演为：\n$$\n\\operatorname{vdc}(i;b) \\;=\\; \\sum_{k=0}^{K} \\frac{d_k}{b^{k+1}}。\n$$\n令\n$$\nu_i \\;=\\; \\operatorname{vdc}(i;2), \\qquad v_i \\;=\\; \\operatorname{vdc}(i;3),\n$$\n以及初步坐标\n$$\nx_i \\;=\\; u_i - \\tfrac{1}{2}, \\qquad y_i \\;=\\; v_i - \\tfrac{1}{2}。\n$$\n通过将半径 $r_i = \\sqrt{x_i^2 + y_i^2}$ 映射到 $r_i' = r_i^{\\beta}$ 来加密中心区域，其中指数 $\\beta \\ge 1$ 为给定值，并保持方向不变：\n$$\n\\mathbf{r}_i \\;=\\;\n\\begin{cases}\n(r_i') \\,\\dfrac{(x_i, y_i)}{r_i},  \\text{if } r_i > 0, \\\\[6pt]\n(0,0),  \\text{if } r_i = 0.\n\\end{cases}\n$$\n\n对于给定的 $R_c$，定义通过上述规则计算的混合加速度 $\\mathbf{a}^{\\text{hyb}}_i(R_c)$。令完全直接求和的加速度为 $\\mathbf{a}^{\\text{dir}}_i$（即精确的软化牛顿求和）。定义误差度量为\n$$\nE(R_c) \\;=\\; \\max_{1 \\le i \\le N} \\frac{\\lVert \\mathbf{a}^{\\text{hyb}}_i(R_c) - \\mathbf{a}^{\\text{dir}}_i \\rVert}{\\max\\!\\big(\\lVert \\mathbf{a}^{\\text{dir}}_i \\rVert,\\, a_{\\min}\\big)},\n$$\n其中 $a_{\\min} = 10^{-12}$。定义在 $R_c$ 处的混合评估的总成本模型为：\n$$\nC(R_c) \\;=\\; \\mathbb{I}\\{N_{\\text{outer}}(R_c)  0\\}\\, w_{\\text{build}}\\, N \\;+\\; w_{\\text{pair}}\\, N_{\\text{pair}}^{\\text{central}}(R_c) \\;+\\; w_{\\text{cell}}\\, N_{\\text{cell}}^{\\text{outer}}(R_c) \\;+\\; w_{\\text{pair}}\\, N_{\\text{pair}}^{\\text{outer}}(R_c),\n$$\n其中 $N_{\\text{outer}}(R_c)$ 是满足 $\\lVert \\mathbf{r}_i \\rVert  R_c$ 的目标粒子数量，$N_{\\text{pair}}^{\\text{central}}(R_c)$ 是为中心区域目标粒子评估的精确粒子-粒子相互作用次数（如果每个中心区域目标粒子都对所有其他源粒子求和，则等于 $N_{\\text{central}}(R_c)\\,(N-1)$），$N_{\\text{cell}}^{\\text{outer}}(R_c)$ 是用于外部区域目标粒子的已接受的粒子-节点相互作用总次数，而 $N_{\\text{pair}}^{\\text{outer}}(R_c)$ 是在叶节点处为外部区域目标粒子评估的粒子-粒子相互作用次数。指示函数 $\\mathbb{I}\\{\\cdot\\}$ 在其条件为真时等于 $1$，否则为 $0$。\n\n您的任务是选择边界半径 $R_c$ 以最小化 $C(R_c)$，同时满足精度约束 $E(R_c) \\le \\tau$，其中 $\\tau$ 是给定的容差。将 $R_c$ 的搜索范围限制在有限的候选集内：\n$$\n\\mathcal{R} \\;=\\; \\{0\\} \\,\\cup\\, \\{\\lVert \\mathbf{r}_i \\rVert: i=1,\\dots,N\\} \\,\\cup\\, \\{r_{\\max} + 10^{-12}\\},\n$$\n其中 $r_{\\max} = \\max_i \\lVert \\mathbf{r}_i \\rVert$。如果在可行集内有多个候选值达到相同的最小成本，请选择最小的 $R_c$。树的叶节点使用 $n_{\\text{leaf}} = 8$，并将四叉树的根节点定义为以原点为中心、半边长如下的最小轴对齐正方形：\n$$\nH \\;=\\; \\max\\left(\\max_i |x_i'|, \\max_i |y_i'|\\right) + 10^{-12},\n$$\n其中 $(x_i',y_i') = \\mathbf{r}_i$。\n\n测试套件。对于以下每个参数集 $(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}})$，按上述方法构建粒子集并确定最优的 $R_c$：\n- 情况 1：$(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}}) = (64,\\,1.6,\\,0.6,\\,10^{-3},\\,20,\\,2,\\,1)$。\n- 情况 2：$(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}}) = (128,\\,1.2,\\,0.5,\\,5\\times 10^{-4},\\,30,\\,1.5,\\,1)$。\n- 情况 3：$(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}}) = (64,\\,1.4,\\,0.9,\\,10^{-2},\\,10,\\,1,\\,1)$。\n- 情况 4：$(N,\\beta,\\theta,\\tau,w_{\\text{build}},w_{\\text{cell}},w_{\\text{pair}}) = (64,\\,1.8,\\,0.7,\\,10^{-8},\\,20,\\,2,\\,1)$。\n\n您的程序必须为每种情况计算出在约束 $E(R_c) \\le \\tau$ 下最小化 $C(R_c)$ 的 $R_c \\in \\mathcal{R}$。每个 $R_c$ 都应以与 $\\mathbf{r}_i$ 相同的长度单位表示。您的程序应生成单行输出，其中包含按上述案例顺序排列的结果，形式为方括号括起来的逗号分隔列表，每个 $R_c$ 四舍五入到 $6$ 位小数（例如，$[r_1,r_2,r_3,r_4]$）。不要打印任何其他字符或文本。",
            "solution": "问题陈述已经过严格验证，并被确定为科学上合理、客观且适定的。它在计算物理领域内提出了一个明确定义的优化任务。因此，我们将着手提供一个完整的解决方案。\n\n问题的核心是为一个N体引力模拟找到一个最优的边界半径 $R_c$，该半径能在保持指定精度水平 $E(R_c) \\le \\tau$ 的同时，最小化计算成本函数 $C(R_c)$。该模拟采用一种混合力评估方案，将用于中心区域的直接求和方法与用于外部区域的基于分层树的近似方法相结合。\n\n首先，我们必须确定性地生成 $N$ 个粒子的位置集合。对于每个粒子 $i \\in \\{1, 2, \\dots, N\\}$，我们使用 van der Corput 低差异序列计算其初步坐标 $(x_i, y_i)$。对于以 $b$ 为基数的整数 $i = \\sum_{k=0}^{K} d_k b^k$，van der Corput 序列（或称根式反演函数）由下式给出：\n$$\n\\operatorname{vdc}(i;b) = \\sum_{k=0}^{K} \\frac{d_k}{b^{k+1}}\n$$\n我们生成 $u_i = \\operatorname{vdc}(i;2)$ 和 $v_i = \\operatorname{vdc}(i;3)$，并将初始坐标设置为 $x_i = u_i - \\frac{1}{2}$ 和 $y_i = v_i - \\frac{1}{2}$。这些点分布在正方形 $[-\\frac{1}{2}, \\frac{1}{2}] \\times [-\\frac{1}{2}, \\frac{1}{2}]$ 内。然后应用一个径向非线性变换来增加原点附近的粒子密度。初始半径 $r_i = \\sqrt{x_i^2 + y_i^2}$ 被映射到一个新的半径 $r_i' = r_i^{\\beta}$，其中指数 $\\beta \\ge 1$ 为给定值。最终的粒子位置 $\\mathbf{r}_i$ 通过将原始方向向量 $(x_i, y_i)$ 缩放到这个新半径得到。具体来说，如果 $r_i  0$，则 $\\mathbf{r}_i = (r_i') \\frac{(x_i, y_i)}{r_i}$；否则 $\\mathbf{r}_i = (0,0)$。所有粒子被赋予相等的质量 $m_j = 1/N$（其中 $j=1, \\dots, N$）。引力常数设置为 $G=1$。\n\n该问题需要一个引力加速度的参考计算，这是通过直接求和来执行的。粒子 $i$ 上的加速度使用 Plummer 软化的牛顿定律计算：\n$$\n\\mathbf{a}^{\\text{dir}}_i = G \\sum_{\\substack{j=1 \\\\ j \\neq i}}^{N} m_j \\frac{\\mathbf{r}_j - \\mathbf{r}_i}{\\left(\\lVert \\mathbf{r}_j - \\mathbf{r}_i \\rVert^2 + \\varepsilon^2\\right)^{3/2}}\n$$\n其中使用 $\\varepsilon = 10^{-3}$ 的软化长度以防止在小粒子间距处出现奇点。这个计算作为衡量混合方法精度的“基准真相”。\n\n混合评估方法依赖于边界半径 $R_c$。对于位于中心区域（由 $\\lVert \\mathbf{r}_i \\rVert \\le R_c$ 定义）的任何目标粒子 $i$，其加速度使用精确的直接求和 $\\mathbf{a}^{\\text{dir}}_i$ 计算。对于位于外部区域（其中 $\\lVert \\mathbf{r}_i \\rVert  R_c$）的任何目标粒子 $i$，其加速度使用分层四叉树方法进行近似计算。\n\n四叉树算法首先将所有粒子包含在一个以原点为中心的根正方形内。该正方形被递归地细分为四个相等的象限，直到每个终端节点（或叶节点）包含的粒子数不超过指定的最大数量 $n_{\\text{leaf}} = 8$。树中的每个节点 $u$ 存储其总质量 $M_u$ 和质心位置 $\\mathbf{R}_u$。为了计算位于位置 $\\mathbf{r}$ 的目标粒子所受的力，从根节点开始遍历该树。对于每个节点 $u$，应用 Barnes-Hut 打开判据：\n$$\n\\frac{s_u}{d_u} \\le \\theta\n$$\n其中 $s_u$ 是节点正方形的边长，$d_u = \\lVert \\mathbf{R}_u - \\mathbf{r} \\rVert$ 是从目标粒子到节点质心的距离，$\\theta$ 是给定的打开参数。如果满足该判据，则节点 $u$ 内所有粒子的集体引力贡献被一个单极子项近似：\n$$\n\\mathbf{a}_u(\\mathbf{r}) = G M_u \\frac{\\mathbf{R}_u - \\mathbf{r}}{\\left(\\lVert \\mathbf{R}_u - \\mathbf{r} \\rVert^2 + \\varepsilon^2\\right)^{3/2}}\n$$\n如果不满足该判据，则该节点被“打开”，并对其子节点应用相同的过程。如果到达一个叶节点且必须被打开，则通过对其包含的单个粒子进行直接求和来计算加速度，其中排除了任何自身相互作用。\n\n目标是从有限候选集 $\\mathcal{R} = \\{0\\} \\cup \\{\\lVert \\mathbf{r}_i \\rVert: i=1,\\dots,N\\} \\cup \\{r_{\\max} + 10^{-12}\\}$ 中找到最优的 $R_c$，其中 $r_{\\max} = \\max_i \\lVert \\mathbf{r}_i \\rVert$。该优化被定义为在误差约束 $E(R_c) \\le \\tau$ 的条件下最小化成本函数 $C(R_c)$。\n\n误差定义为所有粒子上的最大相对误差：\n$$\nE(R_c) = \\max_{1 \\le i \\le N} \\frac{\\lVert \\mathbf{a}^{\\text{hyb}}_i(R_c) - \\mathbf{a}^{\\text{dir}}_i \\rVert}{\\max(\\lVert \\mathbf{a}^{\\text{dir}}_i \\rVert, a_{\\min})}\n$$\n其中 $a_{\\min} = 10^{-12}$。成本函数 $C(R_c)$ 对计算工作量进行建模：\n$$\nC(R_c) = \\mathbb{I}\\{N_{\\text{outer}}(R_c)  0\\}\\, w_{\\text{build}}\\, N + w_{\\text{pair}}\\, N_{\\text{pair}}^{\\text{central}}(R_c) + w_{\\text{cell}}\\, N_{\\text{cell}}^{\\text{outer}}(R_c) + w_{\\text{pair}}\\, N_{\\text{pair}}^{\\text{outer}}(R_c)\n$$\n其中各项分别代表树的构建、中心区域直接相互作用、外部区域节点-粒子相互作用以及外部区域叶节点-粒子相互作用的成本，并由给定的参数 $w_{\\text{build}}$、$w_{\\text{cell}}$ 和 $w_{\\text{pair}}$ 进行加权。\n\n通过为每个测试案例实现以下算法来找到解决方案：\n$1$. 构建粒子位置和质量。\n$2$. 通过直接求和计算所有粒子的参考加速度 $\\mathbf{a}^{\\text{dir}}_i$。\n$3$. 为 $R_c$ 生成排序后的候选集 $\\mathcal{R}$。\n$4$. 对于每个候选值 $R_c \\in \\mathcal{R}$：\n    a. 将粒子划分为中心集和外部集。\n    b. 根据每个粒子所在的区域计算其混合加速度 $\\mathbf{a}^{\\text{hyb}}_i(R_c)$。\n    c. 跟踪相互作用的次数以计算总成本 $C(R_c)$。\n    d. 根据参考加速度计算误差 $E(R_c)$。\n$5$. 识别所有满足 $E(R_c) \\le \\tau$ 的可行候选值 $R_c$。\n$6$. 在这些可行候选值中，找到可实现的最小成本。\n$7$. 最终答案是达到此最小成本的最小的 $R_c$。\n该实现使用 NumPy 库的矢量化操作以提高效率，尤其是在力计算中。四叉树被实现为一种基于类的数据结构，而用于外部粒子力评估的树遍历则使用一个栈来管理，以避免深度递归。",
            "answer": "```python\nimport numpy as np\n\n# Global constants from the problem description\nG_CONST = 1.0\nEPSILON = 1e-3\nA_MIN = 1e-12\nN_LEAF_CAPACITY = 8\n\nclass Node:\n    \"\"\"A node in the QuadTree.\"\"\"\n    def __init__(self, center, half_size):\n        self.center = center\n        self.half_size = half_size\n        self.children = [None, None, None, None]  # SW, SE, NW, NE\n        self.particle_indices = []\n        self.mass = 0.0\n        self.com = np.zeros(2)\n        self.is_leaf = True\n\nclass QuadTree:\n    \"\"\"QuadTree for N-body simulation.\"\"\"\n    def __init__(self, positions, n_leaf):\n        self.positions = positions\n        self.n = len(positions)\n        self.particle_mass = 1.0 / self.n if self.n > 0 else 0.0\n        self.n_leaf = n_leaf\n\n        max_abs_coord = np.max(np.abs(positions)) if self.n > 0 else 1.0\n        root_half_size = max_abs_coord + 1e-12\n        \n        self.root = Node(np.zeros(2), root_half_size)\n        self.root.particle_indices = list(range(self.n))\n        \n        self._build(self.root)\n\n    def _get_quadrant(self, node, p_idx):\n        pos = self.positions[p_idx]\n        if pos[0]  node.center[0]: # West\n            return 2 if pos[1] > node.center[1] else 0 # NW or SW\n        else: # East\n            return 3 if pos[1] > node.center[1] else 1 # NE or SE\n\n    def _build(self, node):\n        if not node.particle_indices:\n            return\n\n        node.mass = len(node.particle_indices) * self.particle_mass\n        if node.mass > 0:\n            node.com = np.mean(self.positions[node.particle_indices], axis=0)\n        \n        if len(node.particle_indices) = self.n_leaf:\n            node.is_leaf = True\n            return\n\n        node.is_leaf = False\n        child_half_size = node.half_size / 2.0\n        centers = [\n            node.center + np.array([-child_half_size, -child_half_size]), # SW\n            node.center + np.array([child_half_size, -child_half_size]),  # SE\n            node.center + np.array([-child_half_size, child_half_size]),  # NW\n            node.center + np.array([child_half_size, child_half_size]),   # NE\n        ]\n\n        child_particles = [[] for _ in range(4)]\n        for p_idx in node.particle_indices:\n            quadrant = self._get_quadrant(node, p_idx)\n            child_particles[quadrant].append(p_idx)\n\n        for i in range(4):\n            if child_particles[i]:\n                child_node = Node(centers[i], child_half_size)\n                child_node.particle_indices = child_particles[i]\n                node.children[i] = child_node\n                self._build(child_node)\n\ndef vdc(n, base):\n    \"\"\"Van der Corput sequence generator.\"\"\"\n    val, inv_base = 0.0, 1.0 / base\n    while n > 0:\n        digit = n % base\n        val += digit * inv_base\n        inv_base /= base\n        n //= base\n    return val\n\ndef generate_particles(N, beta):\n    \"\"\"Generates particle positions based on the problem specification.\"\"\"\n    if N == 0:\n        return np.array([])\n    \n    indices = np.arange(1, N + 1)\n    u = np.array([vdc(i, 2) for i in indices])\n    v = np.array([vdc(i, 3) for i in indices])\n\n    x = u - 0.5\n    y = v - 0.5\n\n    r = np.sqrt(x**2 + y**2)\n    r_prime = np.where(r > 0, r**beta, 0)\n    \n    positions = np.zeros((N, 2))\n    non_zero_r_mask = r > 0\n    if np.any(non_zero_r_mask):\n        ratio = r_prime[non_zero_r_mask] / r[non_zero_r_mask]\n        positions[non_zero_r_mask, 0] = x[non_zero_r_mask] * ratio\n        positions[non_zero_r_mask, 1] = y[non_zero_r_mask] * ratio\n\n    return positions\n\ndef calculate_tree_force_for_target(target_idx, all_pos, tree, theta, part_mass):\n    \"\"\"Calculates acceleration on a single target using the tree.\"\"\"\n    target_pos = all_pos[target_idx]\n    accel = np.zeros(2)\n    cell_count = 0\n    pair_count = 0\n    \n    stack = [tree.root]\n\n    while stack:\n        node = stack.pop()\n        if not node or not node.particle_indices:\n            continue\n\n        dist_vec = node.com - target_pos\n        dist_sq = dist_vec[0]**2 + dist_vec[1]**2\n\n        if dist_sq == 0: \n            if not node.is_leaf:\n                for child in node.children:\n                    if child: stack.append(child)\n            else: # Direct sum for leaf particles\n                for p_idx in node.particle_indices:\n                    if p_idx == target_idx: continue\n                    dr = all_pos[p_idx] - target_pos\n                    dsq = dr[0]**2 + dr[1]**2\n                    inv_r3 = (dsq + EPSILON**2)**(-1.5)\n                    accel += G_CONST * part_mass * dr * inv_r3\n                    pair_count += 1\n            continue\n        \n        node_size = 2 * node.half_size \n        if node_size / np.sqrt(dist_sq) = theta:\n            inv_r3 = (dist_sq + EPSILON**2)**(-1.5)\n            accel += G_CONST * node.mass * dist_vec * inv_r3\n            cell_count += 1\n        else:\n            if node.is_leaf:\n                for p_idx in node.particle_indices:\n                    if p_idx == target_idx: continue\n                    dr = all_pos[p_idx] - target_pos\n                    dsq = dr[0]**2 + dr[1]**2\n                    inv_r3 = (dsq + EPSILON**2)**(-1.5)\n                    accel += G_CONST * part_mass * dr * inv_r3\n                    pair_count += 1\n            else:\n                for child in node.children:\n                    if child: stack.append(child)\n                        \n    return accel, cell_count, pair_count\n\ndef solve():\n    \"\"\"Main function to solve the problem for the given test cases.\"\"\"\n    test_cases = [\n        (64, 1.6, 0.6, 1e-3, 20, 2, 1),\n        (128, 1.2, 0.5, 5e-4, 30, 1.5, 1),\n        (64, 1.4, 0.9, 1e-2, 10, 1, 1),\n        (64, 1.8, 0.7, 1e-8, 20, 2, 1),\n    ]\n\n    results = []\n\n    for case in test_cases:\n        N, beta, theta, tau, w_build, w_cell, w_pair = case\n        particle_mass = 1.0 / N\n\n        positions = generate_particles(N, beta)\n        \n        all_indices = np.arange(N)\n        a_dir = np.zeros_like(positions)\n        for i in all_indices:\n            sources_mask = all_indices != i\n            dr = positions[sources_mask] - positions[i]\n            dist_sq = np.sum(dr**2, axis=1)\n            inv_r3 = (dist_sq + EPSILON**2)**(-1.5)\n            a_dir[i] = G_CONST * particle_mass * np.sum(dr * inv_r3[:, np.newaxis], axis=0)\n\n        a_dir_norm = np.linalg.norm(a_dir, axis=1)\n\n        radii = np.linalg.norm(positions, axis=1)\n        r_max = np.max(radii) if N > 0 else 0.0\n        candidate_rc = sorted(list(np.unique(np.concatenate(([0.0], radii, [r_max + 1e-12])))))\n\n        feasible_solutions = []\n\n        for rc in candidate_rc:\n            central_indices = np.where(radii = rc)[0]\n            outer_indices = np.where(radii > rc)[0]\n\n            a_hyb = np.zeros_like(positions)\n            n_pair_central, n_cell_outer, n_pair_outer = 0, 0, 0\n\n            # Central region: direct sum\n            if len(central_indices) > 0:\n                a_hyb[central_indices] = a_dir[central_indices]\n                n_pair_central = len(central_indices) * (N - 1)\n            \n            # Outer region: tree code\n            tree = None\n            if len(outer_indices) > 0:\n                tree = QuadTree(positions, N_LEAF_CAPACITY)\n                for i in outer_indices:\n                    accel, cells, pairs = calculate_tree_force_for_target(\n                        i, positions, tree, theta, particle_mass)\n                    a_hyb[i] = accel\n                    n_cell_outer += cells\n                    n_pair_outer += pairs\n\n            err_num = np.linalg.norm(a_hyb - a_dir, axis=1)\n            err_den = np.maximum(a_dir_norm, A_MIN)\n            error = np.max(err_num / err_den) if N > 0 else 0.0\n\n            cost = w_pair * n_pair_central + w_cell * n_cell_outer + w_pair * n_pair_outer\n            if len(outer_indices) > 0:\n                cost += w_build * N\n\n            if error = tau:\n                feasible_solutions.append((rc, cost))\n\n        if not feasible_solutions:\n            # Fallback, though problem structure ensures this is not reached\n            optimal_rc = -1.0 \n        else:\n            min_cost = min(c for r, c in feasible_solutions)\n            optimal_rc = min(r for r, c in feasible_solutions if c == min_cost)\n        \n        results.append(f\"{optimal_rc:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}