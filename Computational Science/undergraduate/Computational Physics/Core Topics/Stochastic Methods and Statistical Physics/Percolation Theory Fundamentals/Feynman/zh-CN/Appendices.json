{
    "hands_on_practices": [
        {
            "introduction": "临界点之所以特殊，不仅在于横跨整个系统的“无限”簇的出现，更在于系统在此表现出的普适性标度律。本练习将聚焦于其中一个基本定律——关于簇大小分布的 Fisher 定律，即簇的数量 $n_s$ 与其大小 $s$ 遵循幂律关系 $n_s \\sim s^{-\\tau}$。你将在已知的临界概率 $p_c$ 下模拟二维方格点阵的逾渗过程，并从数据中提取出关键的临界指数 $\\tau$，亲身体验如何通过计算验证理论物理中的普适性概念。",
            "id": "2426213",
            "problem": "您将编写一个完整、可运行的程序，使用数值模拟来研究二维方格上的位点逾渗在临界点时的行为。目标是在逾渗阈值 $p_c$ 处，确定有限集团大小的分布（表示为 $n_s$），并通过从模拟数据中估算指数 $\\tau$ 来验证其是否遵循 Fisher 定律 $n_s \\sim s^{-\\tau}$。\n\n请从逾渗理论和统计估算的核心定义与事实出发，除这些定义外，不假定任何专业的逾渗公式。您可以使用的基本依据是：\n\n- 方格上位点逾渗的定义：每个位点以概率 $p$ 被独立占据，以概率 $1-p$ 为空，其中 $p \\in [0,1]$ 是一个小数（而非百分数）。最近邻连接性是沿着晶格方向定义的。\n- 集团的定义：在晶格上，基于最近邻连接性，由被占据位点构成的最大连通集合。\n- 无限二维方格上位点逾渗的逾渗阈值 $p_c$ 约为 $p_c \\approx 0.592746$，这是一个通过高精度研究得出的、被广泛接受的经验常数。\n- 在具有自由边界的有限 $L \\times L$ 系统中，“贯穿集团”的概念：指一个连接顶部与底部边界，或左侧与右侧边界的集团。在构建临界状态下有限集团大小的分布时，应排除此类集团。\n- 允许以有原则的方式将幂律模型拟合到高于下限截断值 $s_{\\min}$ 的经验数据的统计估算原理。这些原理源于似然最大化和渐近论证，并承认集团大小为整数值。\n\n您的程序必须：\n\n1. 在占据概率为 $p = p_c$（其中 $p_c = 0.592746$）的条件下，于具有自由边界条件的 $L \\times L$ 方格上，生成 $R$ 个位点逾渗的独立实现。在每次实现中，仅使用最近邻连接性来识别所有集团。\n2. 检测并排除贯穿集团，其定义为任何同时触及顶部和底部边界，或同时触及左侧和右侧边界的集团。\n3. 将所有 $R$ 次实现中所有剩余的（有限、非贯穿的）集团的大小聚合成一个多重集 $\\{s_i\\}$。\n4. 从聚合的多重集中，确定经验性有限集团大小分布 $n_s$。其概念意义是，在 $p = p_c$ 时， $n_s$ 与大小为 $s$ 的集团在每位点上出现的频率成正比。您无需输出 $n_s$ 本身；它将作为第5项估算任务的基础。\n5. 通过推导并应用基于幂律尾部似然第一性原理、具有良好统计学基础的 $\\tau$ 估算量，将 $n_s$ 高于下限截断值 $s_{\\min}$ 的尾部拟合到幂律 $n_s \\sim s^{-\\tau}$。拟合时仅使用 $s \\ge s_{\\min}$ 的数据。\n6. 将您的估算值 $\\hat{\\tau}$ 与二维理论值 $\\tau_{\\mathrm{2D}} = \\frac{187}{91}$ 进行比较，并计算绝对误差 $|\\hat{\\tau} - \\tau_{\\mathrm{2D}}|$。为进行验证，如果此绝对误差严格小于指定的容差 $\\epsilon$，则宣布该案例通过。\n\n您的实现必须使用一种逻辑上合理且计算上高效的、适用于大 $L$ 的集团标记算法（例如，带有动态等价性解析的单遍标记法）。程序必须是独立自足的，在给定固定种子的情况下能产生可复现的结果，并避免任何对外部输入或文件的依赖。\n\n测试套件：\n使用以下三组参数集。每个参数集都是一个元组 $(L, R, p, s_{\\min}, \\text{seed}, \\epsilon)$，所有数值都已明确给出。\n\n- 案例 1：$(L, R, p, s_{\\min}, \\text{seed}, \\epsilon) = (\\,64,\\,200,\\,0.592746,\\,8,\\,12345,\\,0.35\\,)$。\n- 案例 2：$(L, R, p, s_{\\min}, \\text{seed}, \\epsilon) = (\\,96,\\,150,\\,0.592746,\\,10,\\,67890,\\,0.35\\,)$。\n- 案例 3：$(L, R, p, s_{\\min}, \\text{seed}, \\epsilon) = (\\,128,\\,120,\\,0.592746,\\,12,\\,424242,\\,0.35\\,)$。\n\n对于每个案例，您的程序必须计算：\n- 估算的指数 $\\hat{\\tau}$，作为一个浮点数。\n- 绝对误差 $|\\hat{\\tau} - \\frac{187}{91}|$，作为一个浮点数。\n- 一个布尔值，指示该案例是否通过验证标准 $|\\hat{\\tau} - \\frac{187}{91}|  \\epsilon$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含按以下顺序聚合到一个列表中的所有三个案例的结果：\n$[\\hat{\\tau}_1, \\text{err}_1, \\text{pass}_1, \\hat{\\tau}_2, \\text{err}_2, \\text{pass}_2, \\hat{\\tau}_3, \\text{err}_3, \\text{pass}_3]$,\n其中 $\\text{err}_k = |\\hat{\\tau}_k - \\frac{187}{91}|$。该行必须严格为 Python 风格的列表字面量，包含逗号分隔的值，且无任何附加文本。",
            "solution": "所述问题是有效的。这是统计物理学领域（特别是逾渗理论）中一个定义明确的计算练习。所有参数均已提供，目标清晰，其底层的物理和数学原理是合理的。我现在将着手提供一个完整的解决方案。\n\n目标是在二维方格上，于临界逾渗阈值 $p_c$ 处，数值上验证有限集团大小分布 $n_s$ 的 Fisher 标度律。该定律假定 $n_s \\sim s^{-\\tau}$，其中 $s$ 是集团大小，$\\tau$ 是一个普适临界指数。对于二维情况，理论预测 $\\tau = \\frac{187}{91}$。我们的任务是从模拟数据中估算 $\\tau$，并将其与该理论值进行比较。\n\n流程结构如下：\n1.  执行蒙特卡洛模拟，以生成一个逾渗系统的多个实现。\n2.  实现一个算法，用于在每次实现中识别所有由相连位点组成的集团。\n3.  识别并从分析中排除贯穿集团，它们是有限系统尺寸造成的人为效应。\n4.  聚合所有剩余有限集团的大小。\n5.  使用一种源自最大似然原理、统计上稳健的方法，从观测到的集团大小分布的尾部来估算指数 $\\tau$。\n\n下面将对每个步骤进行详细阐述。\n\n**1. 逾渗系统的模拟**\n\n我们考虑一个尺寸为 $L \\times L$、具有自由边界条件的二维方格。每个位点以概率 $p$ 被“占据”，或以概率 $1-p$ 为“空”，且与其他所有位点无关。本问题在临界逾渗阈值 $p = p_c \\approx 0.592746$ 下进行研究。对于每组参数 $(L, R, p_c, \\text{seed})$，我们生成 $R$ 个独立的晶格构型。使用一个由指定种子初始化的伪随机数生成器来分配每个位点的状态，以确保可复现性。如果一个抽取的随机变量 $u \\in [0, 1)$ 小于 $p_c$，则坐标为 $(i, j)$ 的位点被占据。此过程生成一个表示晶格上被占据位点的二值矩阵。\n\n**2. 集团的算法识别**\n\n集团是一组通过最近邻路径相连的被占据位点。为识别这些集团，我们采用一种基于单遍扫描和不相交集并（Disjoint-Set Union, DSU）或并查集（Union-Find）数据结构的标准化高效算法。这是 Hoshen-Kopelman 算法的一个变体。\n\n该算法流程如下：\n- 一个尺寸为 $L \\times L$ 的整数矩阵 `labels` 被初始化为全零。一个变量 `next_label` 初始化为 $1$。\n- 初始化一个 DSU 数据结构来管理标签之间的等价关系。\n- 晶格位点被从左到右、逐行扫描。在每个被占据的位点 $(i, j)$：\n    - 我们检查其已处理过的最近邻：上方的位点 $(i-1, j)$ 和左侧的位点 $(i, j-1)$。\n    - 如果没有被占据且已标记的邻居，当前位点就是一个新集团的开始。它被赋 `labels[i, j] = next_label`，并且 `next_label` 递增。在 DSU 中为这个标签创建一个新集合。\n    - 如果有一个或多个被占据且已标记的邻居，当前位点属于它们其中一个集团。它被赋予其邻居标签中的最小值。然后调用 DSU 的 `union` 操作来记录所有邻居的标签是等价的。\n- 在这单遍扫描之后，`labels` 矩阵包含了初步的标签，而 DSU 结构包含了所有必要的等价信息。然后对 `labels` 矩阵进行第二遍扫描。每个位点的标签都被替换为其等价类的规范代表，该代表通过使用带有路径压缩的 DSU 的 `find` 操作找到。\n最终得到一个矩阵，其中所有属于同一集团的位点都标有相同的唯一整数标签。\n\n**3. 排除贯穿集团**\n\n在有限晶格上的临界点 $p_c$ 处，形成一个“贯穿”或“逾渗”集团的概率非零。这些是宏观集团，其性质受系统有限尺寸的严重影响，不属于有限集团分布 $n_s$。我们必须识别并排除它们。一个集团如果连接晶格的顶部边界和底部边界，或者左侧边界和右侧边界，则被定义为贯穿集团。\n\n为了实现这一点，我们识别出最终 `labels` 矩阵四个边界上存在的唯一集团标签集合：$S_{\\text{top}}$、$S_{\\text{bottom}}$、$S_{\\text{left}}$ 和 $S_{\\text{right}}$。\n如果 $k \\in (S_{\\text{top}} \\cap S_{\\text{bottom}}) \\cup (S_{\\text{left}} \\cap S_{\\text{right}})$，则标签为 $k$ 的集团是贯穿集团。\n所有标签属于此贯穿集合的集团的大小都将从后续的统计分析中排除。\n\n**4. 幂律指数 $\\tau$ 的统计估算**\n\n在从所有 $R$ 次实现中聚合了所有有限、非贯穿集团的大小 $\\{s_i\\}$ 之后，我们将分布的尾部拟合到幂律 $n_s \\sim s^{-\\tau}$。这意味着，在给定 $s \\ge s_{\\min}$ 的条件下，观察到大小为 $s$ 的集团的概率遵循一个概率分布 $P(s) \\propto s^{-\\tau}$。我们需要一个 $\\tau$ 的估算量。\n\n我们推导了连续幂律分布指数的最大似然估算量 (MLE)，它对于离散情况是一个极好且被广泛使用的近似，特别是当存在一个不小的下限截断值 $s_{\\min}$ 时。\n对于遵循指数为 $\\tau$ 且 $s \\ge s_{\\min}$ 的幂律分布的变量 $s$，其概率密度函数 (PDF) 为：\n$$ P(s | \\tau, s_{\\min}) = (\\tau - 1)s_{\\min}^{\\tau - 1}s^{-\\tau} $$\n这是通过归一化分布使得 $\\int_{s_{\\min}}^{\\infty} P(s) ds = 1$ 推导出来的。这要求 $\\tau  1$。\n\n给定一组 $N$ 个观测到的集团大小 $\\{s_i\\}_{i=1}^N$ (满足 $s_i \\ge s_{\\min}$)，似然函数是观察到每个大小的概率的乘积：\n$$ \\mathcal{L}(\\tau | \\{s_i\\}) = \\prod_{i=1}^{N} P(s_i | \\tau, s_{\\min}) = \\prod_{i=1}^{N} (\\tau - 1)s_{\\min}^{\\tau - 1}s_i^{-\\tau} $$\n处理对数似然 $\\ln \\mathcal{L}$ 更为方便：\n$$ \\ln \\mathcal{L} = \\sum_{i=1}^{N} \\ln \\left( (\\tau - 1)s_{\\min}^{\\tau - 1}s_i^{-\\tau} \\right) = N \\ln(\\tau - 1) + N(\\tau - 1)\\ln(s_{\\min}) - \\tau \\sum_{i=1}^{N} \\ln(s_i) $$\n为了找到使该函数最大化的 $\\tau$ 值，我们对其关于 $\\tau$ 求导并令结果为零：\n$$ \\frac{\\partial \\ln \\mathcal{L}}{\\partial \\tau} = \\frac{N}{\\tau - 1} + N\\ln(s_{\\min}) - \\sum_{i=1}^{N} \\ln(s_i) = 0 $$\n解出 $\\tau$ 得到估算量 $\\hat{\\tau}$：\n$$ \\frac{N}{\\hat{\\tau} - 1} = \\sum_{i=1}^{N} \\ln(s_i) - N\\ln(s_{\\min}) = \\sum_{i=1}^{N} (\\ln(s_i) - \\ln(s_{\\min})) = \\sum_{i=1}^{N} \\ln\\left(\\frac{s_i}{s_{\\min}}\\right) $$\n$$ \\hat{\\tau} = 1 + N \\left[ \\sum_{i=1}^{N} \\ln\\left(\\frac{s_i}{s_{\\min}}\\right) \\right]^{-1} $$\n这就是代码中实现的公式，用于从收集到的、大于或等于指定截断值 $s_{\\min}$ 的集团大小中计算估算指数 $\\hat{\\tau}$。理论值为 $\\tau_{\\mathrm{2D}} = \\frac{187}{91}$。计算绝对误差 $|\\hat{\\tau} - \\tau_{\\mathrm{2D}}|$ 并与容差 $\\epsilon$ 进行比较，以确定测试案例是否通过。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\nclass DSU:\n    \"\"\"A Disjoint-Set Union data structure for cluster labeling.\"\"\"\n\n    def __init__(self):\n        # The parent array maps a label to its parent in the set.\n        # It is represented as a dictionary for sparse label numbers.\n        self.parent = {}\n\n    def find(self, i):\n        \"\"\"Finds the representative of the set containing element i with path compression.\"\"\"\n        if i not in self.parent:\n            self.parent[i] = i\n            return i\n        \n        path = []\n        while self.parent[i] != i:\n            path.append(i)\n            i = self.parent[i]\n        \n        # Path compression\n        for node in path:\n            self.parent[node] = i\n        return i\n\n    def union(self, i, j):\n        \"\"\"Merges the sets containing elements i and j.\"\"\"\n        root_i = self.find(i)\n        root_j = self.find(j)\n        if root_i != root_j:\n            # A simple union rule: the smaller root becomes the parent.\n            if root_i  root_j:\n                self.parent[root_j] = root_i\n            else:\n                self.parent[root_i] = root_j\n\ndef _label_clusters(grid: np.ndarray) - np.ndarray:\n    \"\"\"\n    Identifies and labels clusters on a 2D grid using a two-pass algorithm with a DSU structure.\n\n    Args:\n        grid: A boolean numpy array where True indicates an occupied site.\n\n    Returns:\n        A numpy array of the same shape with integer labels for each cluster.\n    \"\"\"\n    L = grid.shape[0]\n    labels = np.zeros_like(grid, dtype=np.int32)\n    next_label = 1\n    dsu = DSU()\n\n    # First pass: Scan the grid and assign preliminary labels.\n    for i in range(L):\n        for j in range(L):\n            if grid[i, j]:\n                # Check neighbors (top and left)\n                top_neighbor = labels[i - 1, j] if i  0 else 0\n                left_neighbor = labels[i, j - 1] if j  0 else 0\n\n                neighbor_labels = []\n                if top_neighbor  0:\n                    neighbor_labels.append(top_neighbor)\n                if left_neighbor  0:\n                    neighbor_labels.append(left_neighbor)\n\n                if not neighbor_labels:\n                    # New cluster\n                    labels[i, j] = next_label\n                    dsu.find(next_label) # Initialize the new label in DSU\n                    next_label += 1\n                else:\n                    # Part of an existing cluster\n                    min_label = min(neighbor_labels)\n                    labels[i, j] = min_label\n                    for label in neighbor_labels:\n                        dsu.union(min_label, label)\n\n    # Second pass: Resolve label equivalences.\n    # A vector mapping old labels to their canonical root is more efficient\n    # than iterating through the grid again, but this is conceptually clear.\n    final_labels = np.zeros_like(labels)\n    for i in range(L):\n        for j in range(L):\n            if labels[i, j]  0:\n                final_labels[i, j] = dsu.find(labels[i, j])\n\n    return final_labels\n\ndef _estimate_tau(sizes: np.ndarray, s_min: int) - float:\n    \"\"\"\n    Estimates the power-law exponent tau using the Maximum Likelihood Estimator.\n\n    Args:\n        sizes: A numpy array of all finite cluster sizes.\n        s_min: The minimum size to include in the fit.\n\n    Returns:\n        The estimated exponent tau_hat.\n    \"\"\"\n    sizes_above_min = sizes[sizes = s_min]\n    n = len(sizes_above_min)\n\n    if n == 0:\n        return np.nan # No data to fit\n\n    # MLE formula: tau = 1 + n / sum(ln(s_i / s_min))\n    log_sum = np.sum(np.log(sizes_above_min / s_min))\n    \n    if log_sum = 0:\n        # This case occurs if all s_i = s_min, implying an infinitely steep exponent.\n        # Or if n=0, though checked above.\n        return np.inf\n\n    tau_hat = 1.0 + n / log_sum\n    return tau_hat\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (L, R, p, s_min, seed, epsilon)\n        (64, 200, 0.592746, 8, 12345, 0.35),\n        (96, 150, 0.592746, 10, 67890, 0.35),\n        (128, 120, 0.592746, 12, 424242, 0.35),\n    ]\n\n    TAU_2D = 187.0 / 91.0\n    all_results = []\n\n    for L, R, p, s_min, seed, epsilon in test_cases:\n        rng = np.random.default_rng(seed)\n        all_finite_cluster_sizes = []\n\n        for _ in range(R):\n            # 1. Generate lattice\n            grid = rng.random((L, L))  p\n\n            # 2. Identify all clusters\n            labeled_grid = _label_clusters(grid)\n            \n            # Find unique non-zero labels and their counts (sizes)\n            unique_labels, sizes = np.unique(labeled_grid[labeled_grid  0], return_counts=True)\n            if unique_labels.size == 0:\n                continue\n            \n            cluster_sizes = dict(zip(unique_labels, sizes))\n\n            # 3. Detect and exclude spanning clusters\n            top_boundary_labels = set(np.unique(labeled_grid[0, :]))\n            bottom_boundary_labels = set(np.unique(labeled_grid[L - 1, :]))\n            left_boundary_labels = set(np.unique(labeled_grid[:, 0]))\n            right_boundary_labels = set(np.unique(labeled_grid[:, L - 1]))\n            \n            # Remove background label 0\n            for s in [top_boundary_labels, bottom_boundary_labels, left_boundary_labels, right_boundary_labels]:\n                s.discard(0)\n\n            v_spanning = top_boundary_labels.intersection(bottom_boundary_labels)\n            h_spanning = left_boundary_labels.intersection(right_boundary_labels)\n            spanning_labels = v_spanning.union(h_spanning)\n\n            # 4. Aggregate sizes of finite, non-spanning clusters\n            for label, size in cluster_sizes.items():\n                if label not in spanning_labels:\n                    all_finite_cluster_sizes.append(size)\n        \n        # 5. Fit power law and estimate tau\n        tau_hat = _estimate_tau(np.array(all_finite_cluster_sizes), s_min)\n\n        # 6. Compare with theory and check verification\n        error = abs(tau_hat - TAU_2D)\n        passed = error  epsilon\n\n        all_results.extend([tau_hat, error, passed])\n\n    # Final print statement in the exact required format.\n    # Custom mapping for booleans and floats to get precise string representation.\n    def format_val(v):\n        if isinstance(v, bool):\n            return str(v)\n        if isinstance(v, float):\n            return f\"{v:.7f}\" # Ensure sufficient precision\n        return str(v)\n\n    print(f\"[{','.join(map(format_val, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在临界点形成的无限簇并非简单的致密物体，而是一个复杂的分形结构。本练习将带你深入探索这种几何特性，引入“骨架”(backbone)这一核心概念，它代表了簇中能够传递“电流”或信息的有效部分。你将学习如何通过算法“修剪”掉簇的“末端枝杈”以识别其骨架，并使用盒计数法分别测量整个簇和其骨架的分形维度 $d_f$ 与 $d_b$，从而揭示逾渗簇精巧的自相似内在结构。",
            "id": "2426194",
            "problem": "要求您编写一个完整、可运行的程序，该程序针对方形晶格上的二维位点逾渗，识别左右贯穿团簇（无限团簇的有限尺寸代理）的骨架，并通过盒子计数法估计其分形维数。您需要将此估计值与完整贯穿团簇的估计值进行比较。此任务必须基于第一性原理解决：使用逾渗理论和图连通性的定义，不得使用任何预封装的逾渗库。\n\n需要使用的定义和基本原理：\n- 考虑一个线性尺寸为 $L$、具有开放边界的方形晶格，其坐标由整数 $(i,j)$ 索引，其中 $i \\in \\{0,\\dots,L-1\\}$ 且 $j \\in \\{0,\\dots,L-1\\}$。占据概率为 $p$ 的位点逾渗意味着每个位点以概率 $p$ 独立地被占据，或以概率 $1-p$ 为空。\n- 如果两个被占据的位点在一个坐标上恰好相差一，而在另一个坐标上相等，则它们是最近邻连接的（四邻域连通性）。团簇是相互连接的被占据位点的极大集合。\n- 左右贯穿团簇是指一个团簇，它在左边界列 $j=0$ 中至少包含一个被占据的位点，并在右边界列 $j=L-1$ 中至少包含一个被占据的位点。在一个无向格点上，同时连接到左边界和右边界的位点集合可以通过两次连通性搜索的交集获得。\n- 左右贯穿团簇的骨架是其位点的一个子集，当电流从左向右驱动时，这些位点不属于任何悬挂的死端树。一种构造性的定义方法是：在由贯穿团簇诱导的子图中，重复移除所有度 $\\le 1$ 且不在左或右边界上的位点（度是在此子图内使用四邻域连接计算的），直到无法再进行移除为止。剩余的位点构成了可以承载左右路径的骨架。\n- 嵌入在平面中的一个集合的分形维数 $d$ 可以通过盒子计数法来估计：用边长为 $s$ 的不重叠盒子（其中 $s$ 是 $L$ 的一个因子）网格覆盖 $L \\times L$ 的晶格，计算与该集合相交的盒子数量 $N(s)$，并拟合标度律 $N(s) \\propto s^{-d}$；等价地，对 $\\log N(s)$ 与 $\\log (1/s)$ 进行线性最小二乘拟合，以斜率来估计 $d$。\n\n要求：\n1. 在 $L \\times L$ 网格上，使用参数为 $p$ 的独立同分布伯努利试验生成位点逾渗构型。使用四邻域连通性和开放边界。\n2. 按如下方式识别左右贯穿团簇：计算连接到左边界的被占据位点集合 $A$ 和连接到右边界的被占据位点集合 $B$，每个集合均通过广度优先搜索（BFS）或深度优先搜索（DFS）计算。贯穿团簇位点是 $A \\cap B$ 中的位点。如果 $A \\cap B$ 为空，则不存在左右贯穿团簇。\n3. 通过迭代剪枝（燃烧算法）识别贯穿团簇的骨架：在由 $A \\cap B$ 诱导的子图中，将一个位点的度定义为其同样位于 $A \\cap B$ 中的四邻域被占据邻居的数量。重复移除所有度 $\\le 1$ 且不在列 $j=0$ 或 $j=L-1$ 上的位点（这些边界位点受到保护，绝不能被剪枝），每次移除后更新度，直到收敛。剩余的集合即为骨架。\n4. 通过盒子计数法估计完整贯穿团簇的分形维数 $d_f$ 及其骨架的分形维数 $d_b$。使用满足 $1 \\le s \\le L/2$ 的能整除 $L$ 的正整数作为盒子尺寸 $s$，并至少包含3个不同的尺度。对于每个 $s$，用 $L/s$ 个盒子沿每个轴平铺网格，并计算包含至少一个所研究集合中位点的盒子数量 $N(s)$。对 $\\log N(s)$ 与 $\\log (1/s)$ 进行普通最小二乘拟合以估计 $d$。如果集合为空，则将其分形维数定义为 $0.0$。为了数值稳健性，您可以将估计的 $d$ 限制在区间 $[0,2]$ 内。\n5. 为了可复现性，请使用每个测试用例中提供的固定伪随机数生成器（PRNG）种子。\n\n测试套件：\n- 案例 1：$(L,p,\\text{seed}) = (64,0.62,1)$。\n- 案例 2：$(L,p,\\text{seed}) = (64,0.55,2)$。\n- 案例 3：$(L,p,\\text{seed}) = (96,1.0,0)$。\n- 案例 4：$(L,p,\\text{seed}) = (64,0.70,3)$。\n\n输出规范：\n- 对于每个案例，如果没有左右贯穿团簇（即 $A \\cap B$ 为空），则为该案例返回数对 $[0.000,0.000]$。\n- 否则，计算并返回数对 $[d_f,d_b]$，其中 $d_f$ 是完整贯穿团簇 $A \\cap B$ 的分形维数，$d_b$ 是其骨架的分形维数，每个值都四舍五入到三位小数。\n- 您的程序应生成单行输出，其中包含四个案例的结果，格式为用方括号括起来的、以逗号分隔的数对列表，并按测试套件的顺序排列，例如：$[[d_{f,1},d_{b,1}],[d_{f,2},d_{b,2}],[d_{f,3},d_{b,3}],[d_{f,4},d_{b,4}]]$。不应打印任何额外文本。",
            "solution": "问题陈述已经过严格验证，并被确定为是合理的。它提出了一个在统计物理学领域内，特别是逾渗理论范畴内的，一个定义明確的计算问题。所有的定义、参数和算法要求都清晰、一致且具有科学依据。该任务是实现一系列标准算法：通过伯努利试验生成晶格，使用图搜索识别团簇，通过迭代剪枝提取骨架，以及使用盒子计数法估计分形维数。我们将着手提供一个完整的解决方案。\n\n对于每个测试用例 $(L, p, \\text{seed})$，该方法按四个顺序阶段执行。\n\n**1. 生成逾渗晶格**\n一个大小为 $L \\times L$ 的方形晶格被建模为一个二维数组。每个位点 $(i,j)$（其中 $i, j \\in \\{0, \\dots, L-1\\}$）根据一个随机过程被指定为占据或空缺。我们使用一个由给定种子初始化的伪随机数生成器（PRNG）来确保可复现性。对每个位点，从一个均匀分布中抽取一个随机数 $r \\in [0, 1)$。如果 $r  p$，该位点被标记为‘占据’，否则为‘空缺’，其中 $p$ 是指定的占据概率。这构成了一组独立的伯努利试验，从而产生一个将在其上进行分析的特定占据位点构型。\n\n**2. 识别左右贯穿团簇**\n左右贯穿团簇是从左边界（$j=0$）到右边界（$j=L-1$）的一条由占据位点组成的连通路径。为识别形成此类团簇的位点，我们采用两次独立的图遍历搜索。连通性由最近邻定义（一个四邻域的 von Neumann 邻域）。\n\n首先，我们找到所有与左边界上任何被占据位点相连的被占据位点的集合 $A$。这是通过从 $j=0$ 列中所有被占据的位点同时开始进行广度优先搜索（BFS）来实现的。BFS 探索被占据位点的图，识别所有可达位置。\n\n其次，我们类似地通过从右边界（$j=L-1$）列中所有被占据的位点开始另一次 BFS，找到与右边界相连的所有被占据位点的集合 $B$。\n\n属于左右贯穿团簇的位点集合，我们记为 $C_{span}$，是这两个集合的交集：$C_{span} = A \\cap B$。如果此交集为空（$A \\cap B = \\emptyset$），则对于给定的构型不存在贯穿团簇。\n\n**3. 提取团簇骨架**\n贯穿团簇的骨架是其位点中对维持从左到右的连接至关重要的子集。它排除了‘悬挂端’或‘死端树’。我们使用一种迭代剪枝算法（也称为燃烧算法）来识别骨架。\n\n令 $S_0 = C_{span}$ 为候选骨架位点的初始集合。该算法按步骤 $k=0, 1, 2, \\dots$ 进行：\n- 对于 $S_k$ 中的每个位点 $s$，我们计算其度，定义为它在 $S_k$ 中也存在的最近邻的数量。\n- 如果 $S_k$ 中的一个位点 $s=(i,j)$ 的度小于或等于 $1$（即，它是 $S_k$ 内的叶子或孤立位点）并且它不在左或右边界上（即 $j \\neq 0$ 且 $j \\neq L-1$），则该位点被识别为可剪枝的。边界列上的位点是假设电流的受保护源/汇，永远不会被移除。\n- 形成一个包含所有可剪枝位点的新集合 $P_k$。\n- 如果 $P_k$ 为空，则过程收敛。骨架是最终的集合 $S_k$。\n- 否则，下一组候选集合是 $S_{k+1} = S_k \\setminus P_k$。过程以 $k \\leftarrow k+1$ 重复进行。\n\n这次迭代移除后剩余的位点集合构成了骨架, $C_{backbone}$。\n\n**4. 估计分形维数**\n一个点集的分形维数 $d$ 使用盒子计数法进行估计。该方法基于标度假设，即覆盖该集合所需的线性尺寸为 $s$ 的盒子数量 $N(s)$ 呈幂律形式：$N(s) \\propto s^{-d}$。\n\n为了估计 $d$，我们对这个关系取对数：$\\log N(s) = -d \\log s + \\text{const}$，这等价于 $\\log N(s) = d \\log(1/s) + \\text{const}$。这揭示了 $\\log N(s)$ 和 $\\log(1/s)$ 之间的线性关系，其斜率就是分形维数 $d$。\n\n对于给定的位点集合（$C_{span}$ 或 $C_{backbone}$），算法如下：\n- 如果集合为空，其维数定义为 $0.0$。\n- 选择一系列盒子尺寸 $\\{s_k\\}$。根据要求，这些是 $L$ 的整数因子，满足 $1 \\le s_k \\le L/2$。\n- 对于每个 $s_k$，用大小为 $s_k \\times s_k$ 的不重叠盒子平铺 $L \\times L$ 网格。我们计算包含该集合中至少一个位点的盒子数量 $N(s_k)$。\n- 然后，我们对数据点 $(\\log(1/s_k), \\log N(s_k))$ 执行普通最小二乘线性回归。所得最佳拟合线的斜率提供了分形维数 $d$ 的估计值。为保证数值稳定性，我们使用自然对数。\n- 最终估计的维数被限制在物理上有意义的区间 $[0, 2]$ 内。\n\n此过程应用于完整的贯穿团簇 $C_{span}$ 以找到其维数 $d_f$，并应用于其骨架 $C_{backbone}$ 以找到其维数 $d_b$。为每个测试用例计算得到的数对 $[d_f, d_b]$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import linregress\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Main function to run the percolation analysis for all test cases.\n    \"\"\"\n    test_cases = [\n        (64, 0.62, 1),\n        (64, 0.55, 2),\n        (96, 1.0, 0),\n        (64, 0.70, 3),\n    ]\n\n    results = []\n    for L, p, seed in test_cases:\n        result_pair = run_percolation_analysis(L, p, seed)\n        results.append(result_pair)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"[{r[0]:.3f},{r[1]:.3f}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\ndef run_percolation_analysis(L, p, seed):\n    \"\"\"\n    Executes the full analysis for a single test case.\n    \"\"\"\n    # 1. Generate percolation configuration\n    rng = np.random.default_rng(seed)\n    grid = rng.random((L, L))  p\n\n    # 2. Identify spanning cluster\n    \n    # Find sites connected to the left boundary\n    left_starts = {(i, 0) for i in range(L) if grid[i, 0]}\n    cluster_A = _run_bfs(grid, L, left_starts)\n\n    # Find sites connected to the right boundary\n    right_starts = {(i, L - 1) for i in range(L) if grid[i, L - 1]}\n    cluster_B = _run_bfs(grid, L, right_starts)\n\n    # The spanning cluster is the intersection\n    spanning_cluster = cluster_A.intersection(cluster_B)\n\n    if not spanning_cluster:\n        return [0.0, 0.0]\n\n    # 3. Identify backbone\n    backbone = _find_backbone(spanning_cluster, L)\n\n    # 4. Estimate fractal dimensions\n    d_f = _calculate_fractal_dimension(spanning_cluster, L)\n    d_b = _calculate_fractal_dimension(backbone, L)\n\n    return [d_f, d_b]\n\n\ndef _run_bfs(grid, L, start_nodes):\n    \"\"\"\n    Performs a Breadth-First Search on the grid from a set of start nodes.\n    \"\"\"\n    if not start_nodes:\n        return set()\n\n    q = deque(start_nodes)\n    visited = set(start_nodes)\n\n    while q:\n        r, c = q.popleft()\n\n        for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n            nr, nc = r + dr, c + dc\n            \n            if 0 = nr  L and 0 = nc  L and \\\n               grid[nr, nc] and (nr, nc) not in visited:\n                visited.add((nr, nc))\n                q.append((nr, nc))\n    \n    return visited\n\n\ndef _find_backbone(cluster_sites, L):\n    \"\"\"\n    Identifies the backbone of a cluster by iterative pruning.\n    \"\"\"\n    backbone_candidates = cluster_sites.copy()\n\n    while True:\n        to_prune = set()\n        \n        # Calculate degrees for all sites in the current candidate set\n        degrees = {}\n        for r, c in backbone_candidates:\n            degree = 0\n            for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                nr, nc = r + dr, c + dc\n                if (nr, nc) in backbone_candidates:\n                    degree += 1\n            degrees[(r, c)] = degree\n        \n        # Identify prunable sites\n        for (r,c), degree in degrees.items():\n            if degree = 1 and c != 0 and c != L - 1:\n                to_prune.add((r, c))\n\n        if not to_prune:\n            break\n        \n        backbone_candidates.difference_update(to_prune)\n    \n    return backbone_candidates\n\n\ndef _calculate_fractal_dimension(site_set, L):\n    \"\"\"\n    Estimates the fractal dimension of a set of sites using box-counting.\n    \"\"\"\n    if not site_set:\n        return 0.0\n\n    # Determine box sizes s: divisors of L, with 1 = s = L/2\n    box_sizes = [s for s in range(1, L // 2 + 1) if L % s == 0]\n    \n    if len(box_sizes)  3:\n        # Not enough scales for a meaningful fit, might happen for small L.\n        # Although problem constraints (L=64,96) ensure this is not an issue.\n        return 0.0\n\n    site_coords = np.array(list(site_set))\n    log_N_s = []\n    log_inv_s = []\n\n    for s in box_sizes:\n        # Map site coordinates to box coordinates\n        box_coords = site_coords // s\n        \n        # Count unique boxes containing sites\n        num_boxes = len(np.unique(box_coords, axis=0))\n        \n        if num_boxes  0:\n            log_N_s.append(np.log(num_boxes))\n            log_inv_s.append(np.log(1.0 / s))\n    \n    if len(log_inv_s)  2:\n        # Need at least 2 points for a line fit\n        return 0.0\n\n    # Perform linear regression\n    # log(N(s)) = slope * log(1/s) + intercept\n    slope, _, _, _, _ = linregress(log_inv_s, log_N_s)\n    \n    # Clamp dimension to the interval [0, 2]\n    dimension = np.clip(slope, 0.0, 2.0)\n    \n    return dimension\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}