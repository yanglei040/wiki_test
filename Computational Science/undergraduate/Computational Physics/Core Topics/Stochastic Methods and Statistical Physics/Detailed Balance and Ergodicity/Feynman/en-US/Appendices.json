{
    "hands_on_practices": [
        {
            "introduction": "To build a solid foundation, we begin with a theoretical exercise that cuts to the heart of the difference between equilibrium and non-equilibrium systems. The detailed balance condition is stricter than global balance, and this practice challenges you to construct a system that meets the latter but not the former. By analyzing a simple three-state system, you will see how a violation of detailed balance gives rise to a non-equilibrium steady state characterized by persistent probability currents, a key concept in understanding systems driven away from equilibrium .",
            "id": "2385718",
            "problem": "In computational physics, Markov Chain Monte Carlo relies on the interplay between detailed balance and ergodicity to ensure correct sampling. Consider a discrete-time Markov chain on a cycle of $3$ states $\\{A,B,C\\}$, where transitions occur only between nearest neighbors on the cycle and to the same state (self-loops). You are to construct a transition mechanism that is ergodic and satisfies global balance but not detailed balance.\n\nLet the transition probabilities be parametrized by two real numbers $r$ and $s$ with $0  s  r$ and $r + s  1$, so that from each state the transition probabilities are:\n- from $A$: to $B$ with probability $r$, to $C$ with probability $s$, to $A$ with probability $1 - r - s$;\n- from $B$: to $C$ with probability $r$, to $A$ with probability $s$, to $B$ with probability $1 - r - s$;\n- from $C$: to $A$ with probability $r$, to $B$ with probability $s$, to $C$ with probability $1 - r - s$.\n\nThis defines a $3 \\times 3$ transition matrix $P$ with entries $P_{ij}$, where $i,j \\in \\{A,B,C\\}$. Use only the following foundational ingredients: the definition of a discrete-time Markov chain, the definition of irreducibility and aperiodicity (together called ergodicity), the stationarity condition (global balance) $\\boldsymbol{\\pi}^{\\top} P = \\boldsymbol{\\pi}^{\\top}$ for a stationary distribution $\\boldsymbol{\\pi}$, and the detailed balance condition $\\pi_i P_{ij} = \\pi_j P_{ji}$ for all pairs $i,j$.\n\nTasks:\n1. Prove that for $0  s  r$ and $r + s  1$, the Markov chain is ergodic (irreducible and aperiodic).\n2. Determine a stationary distribution $\\boldsymbol{\\pi}$ and verify that it satisfies global balance.\n3. Show that detailed balance does not hold unless $r = s$, and hence for $0  s  r$ detailed balance is violated.\n4. Define the steady-state net probability current from $A$ to $B$ as $J_{A \\to B} = \\pi_A P_{AB} - \\pi_B P_{BA}$ and compute it in closed form as a function of $r$ and $s$.\n\nYour final answer must be the analytic expression for $J_{A \\to B}$ in terms of $r$ and $s$. No units are required. Do not round; provide an exact expression.",
            "solution": "The problem statement will first be subjected to a rigorous validation procedure.\n\n**Step 1: Extract Givens**\n- **System**: A discrete-time Markov chain on a state space $\\mathcal{S} = \\{A, B, C\\}$.\n- **Topology**: The states are arranged in a cycle.\n- **Parameters**: Two real numbers $r$ and $s$ satisfying the constraints $0  s  r$ and $r + s  1$.\n- **Transition Probabilities**:\n  - From state $A$: $P_{AB} = r$, $P_{AC} = s$, $P_{AA} = 1 - r - s$.\n  - From state $B$: $P_{BC} = r$, $P_{BA} = s$, $P_{BB} = 1 - r - s$.\n  - From state $C$: $P_{CA} = r$, $P_{CB} = s$, $P_{CC} = 1 - r - s$.\n- **Definitions**:\n  - **Ergodicity**: The properties of irreducibility and aperiodicity combined.\n  - **Global Balance (Stationarity)**: $\\boldsymbol{\\pi}^{\\top} P = \\boldsymbol{\\pi}^{\\top}$ for a stationary distribution $\\boldsymbol{\\pi}$.\n  - **Detailed Balance**: $\\pi_i P_{ij} = \\pi_j P_{ji}$ for all pairs of states $i, j \\in \\mathcal{S}$.\n- **Tasks**:\n  1. Prove the chain is ergodic.\n  2. Find the stationary distribution $\\boldsymbol{\\pi}$ and verify it satisfies global balance.\n  3. Show detailed balance is not satisfied under the given constraints.\n  4. Compute the steady-state net probability current $J_{A \\to B} = \\pi_A P_{AB} - \\pi_B P_{BA}$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is analyzed against the required criteria.\n- **Scientifically Grounded**: The problem is based on the standard mathematical theory of Markov chains, a fundamental topic in statistical mechanics and computational physics. All definitions and concepts are standard and correct.\n- **Well-Posed**: The problem is well-defined. The transition probabilities are properly constrained by $0  s  r$ and $r + s  1$, ensuring all probabilities are positive and sum to $1$ for each state. The tasks are specific mathematical derivations that lead to a unique solution.\n- **Objective**: The problem is stated using precise mathematical language, free from any subjectivity or ambiguity.\n\nThe problem successfully passes all validation checks. It is a standard, formalizable problem in theoretical physics.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A full solution will be provided.\n\n**Solution Derivation**\n\nThe transition matrix $P$ for the states ordered as $(A, B, C)$ is given by:\n$$\nP = \\begin{pmatrix}\n1 - r - s  r  s \\\\\ns  1 - r - s  r \\\\\nr  s  1 - r - s\n\\end{pmatrix}\n$$\n\n**Task 1: Ergodicity**\nA finite-state Markov chain is ergodic if it is both irreducible and aperiodic.\n\n- **Irreducibility**: A chain is irreducible if it is possible to move from any state to any other state in a finite number of steps. The transitions can be visualized as a directed graph on the vertices $\\{A, B, C\\}$. The given probabilities are $P_{AB}=r$, $P_{BA}=s$, $P_{BC}=r$, $P_{CB}=s$, $P_{CA}=r$, $P_{AC}=s$. Since $r  0$ and $s  0$, all these transition probabilities are non-zero. The graph is strongly connected. For instance, one can traverse the cycle $A \\to B \\to C \\to A$. Therefore, every state is reachable from every other state, and the chain is irreducible.\n\n- **Aperiodicity**: The period of a state $i$ is the greatest common divisor (GCD) of all integers $n  0$ such that $P_{ii}^{(n)}  0$. A chain is aperiodic if all its states have a period of $1$. The condition $r+s  1$ implies that the self-loop probabilities $P_{AA} = P_{BB} = P_{CC} = 1 - r - s$ are all strictly greater than $0$. The existence of a self-loop (a return to state $i$ in $1$ step) for any state $i$ in an irreducible chain ensures that the period of that state is $1$. Since $P_{AA}  0$, the set of possible return times for state $A$ includes $n=1$. The GCD of any set of integers including $1$ is $1$. Thus, state $A$ is aperiodic. As the chain is irreducible, aperiodicity of one state implies aperiodicity of all states.\n\nSince the chain is both irreducible and aperiodic, it is ergodic. This guarantees the existence of a unique stationary distribution.\n\n**Task 2: Stationary Distribution and Global Balance**\nThe stationary distribution $\\boldsymbol{\\pi} = (\\pi_A, \\pi_B, \\pi_C)^{\\top}$ must satisfy the global balance equation $\\boldsymbol{\\pi}^{\\top} P = \\boldsymbol{\\pi}^{\\top}$, subject to the normalization $\\pi_A + \\pi_B + \\pi_C = 1$. This corresponds to the system of linear equations:\n$$\n\\pi_A = \\pi_A(1 - r - s) + \\pi_B s + \\pi_C r \\\\\n\\pi_B = \\pi_A r + \\pi_B(1 - r - s) + \\pi_C s \\\\\n\\pi_C = \\pi_A s + \\pi_B r + \\pi_C(1 - r - s)\n$$\nDue to the cyclic symmetry of the transition probabilities, we can hypothesize a symmetric solution $\\pi_A = \\pi_B = \\pi_C = c$. Substituting into the normalization condition gives $3c = 1$, so $c = 1/3$.\nLet us verify if $\\pi_A = \\pi_B = \\pi_C = 1/3$ satisfies the first balance equation:\n$$\n\\frac{1}{3} \\overset{?}{=} \\frac{1}{3}(1 - r - s) + \\frac{1}{3}s + \\frac{1}{3}r \\\\\n\\frac{1}{3} = \\frac{1}{3} - \\frac{r}{3} - \\frac{s}{3} + \\frac{s}{3} + \\frac{r}{3} \\\\\n\\frac{1}{3} = \\frac{1}{3}\n$$\nThe equation holds. Due to symmetry, the other two equations are also satisfied. Therefore, the unique stationary distribution is $\\boldsymbol{\\pi} = (1/3, 1/3, 1/3)^{\\top}$. The act of finding this distribution and verifying it against the equations constitutes the verification of global balance.\n\n**Task 3: Violation of Detailed Balance**\nThe detailed balance condition is $\\pi_i P_{ij} = \\pi_j P_{ji}$ for all pairs $i,j$. Let us check this for the pair of states $(A, B)$.\n$$\n\\pi_A P_{AB} = \\pi_B P_{BA}\n$$\nUsing the stationary distribution and transition probabilities:\n$$\n\\frac{1}{3} \\cdot r = \\frac{1}{3} \\cdot s\n$$\nThis equality simplifies to $r = s$. However, the problem specifies the condition $0  s  r$, which explicitly means $r \\neq s$. Thus, the detailed balance condition is violated for the pair $(A,B)$.\n$$\n\\pi_A P_{AB}  \\pi_B P_{BA}\n$$\nA similar analysis for the pairs $(B,C)$ and $(C,A)$ also shows a violation of detailed balance unless $r=s$. Specifically, $\\pi_B P_{BC} = (1/3)r \\neq (1/3)s = \\pi_C P_{CB}$, and $\\pi_C P_{CA} = (1/3)r \\neq (1/3)s = \\pi_A P_{AC}$. Therefore, detailed balance does not hold for this system.\n\n**Task 4: Steady-State Net Probability Current**\nThe steady-state net probability current from state $A$ to state $B$ is defined as $J_{A \\to B} = \\pi_A P_{AB} - \\pi_B P_{BA}$. We substitute the known values:\n- $\\pi_A = 1/3$\n- $\\pi_B = 1/3$\n- $P_{AB} = r$\n- $P_{BA} = s$\n\nThe calculation is as follows:\n$$\nJ_{A \\to B} = \\left(\\frac{1}{3}\\right) r - \\left(\\frac{1}{3}\\right) s = \\frac{1}{3}(r - s)\n$$\nSince $r  s$, this current is positive, indicating a net flow of probability in the direction $A \\to B$. This non-zero current is a direct consequence of the violation of detailed balance. The system is in a non-equilibrium steady state with a persistent probability circulation $A \\to B \\to C \\to A$.",
            "answer": "$$\n\\boxed{\\frac{1}{3}(r-s)}\n$$"
        },
        {
            "introduction": "Now we move from abstract state spaces to a common and practical task in computational science: sampling points uniformly from the surface of a sphere. This hands-on coding problem illustrates how easily an algorithm can fail if the underlying geometry of the state space is ignored. You will implement and compare a correctly designed, rotationally invariant Markov chain with naive samplers that fail in spectacular ways, either by losing ergodicity and getting stuck at the poles or by violating detailed balance and producing a biased sample . This practice provides an invaluable lesson in the subtle pitfalls of designing samplers on manifolds.",
            "id": "2385714",
            "problem": "Consider the unit sphere $S^2 \\subset \\mathbb{R}^3$, defined as the set of all vectors $\\mathbf{x} \\in \\mathbb{R}^3$ with Euclidean norm $\\|\\mathbf{x}\\|_2 = 1$. The target distribution is the uniform probability measure on $S^2$, which is invariant under all proper rotations in $\\mathbb{R}^3$. In standard spherical coordinates $(\\theta,\\phi)$ with $\\theta \\in [0,\\pi]$ and $\\phi \\in [0,2\\pi)$, the surface-area element is $\\mathrm{d}A = \\sin(\\theta)\\,\\mathrm{d}\\theta\\,\\mathrm{d}\\phi$, so the probability density with respect to the coordinate-area measure is proportional to $\\sin(\\theta)$. Angles must be handled in radians.\n\nYou will construct and analyze discrete-time Markov chains on $S^2$ for the purpose of sampling from the target distribution. Two chains are to be implemented:\n\n- A rotationally invariant chain defined by random rotations in $\\mathbb{R}^3$.\n- A naive angle-space chain in $(\\theta,\\phi)$ with flawed proposals that will be shown to be non-ergodic at the poles and biased when it ignores the area element.\n\nDefinitions and requirements:\n\n1. A chain satisfies detailed balance with respect to the uniform measure on $S^2$ if its transition kernel $P(\\mathbf{x}\\to \\mathbf{y})$ and the target density $\\pi(\\mathbf{x})$ (constant on $S^2$) satisfy $\\pi(\\mathbf{x})P(\\mathbf{x}\\to \\mathbf{y}) = \\pi(\\mathbf{y})P(\\mathbf{y}\\to \\mathbf{x})$ for all $\\mathbf{x},\\mathbf{y} \\in S^2$.\n2. A chain is ergodic if it is irreducible and aperiodic on $S^2$ under the Borel $\\sigma$-algebra, so that from any starting state it visits any nonzero-measure subset with nonzero long-time frequency.\n3. Let $z = \\cos(\\theta)$ be the $z$-coordinate of the point on $S^2$ associated with $(\\theta,\\phi)$. Under the uniform measure on $S^2$, the marginal distribution of $z$ is uniform on $[-1,1]$.\n\nAlgorithms to implement:\n\nA. Rotational random-walk (RRW) chain on $S^2$ acting on $\\mathbf{x} \\in S^2$: each step selects a random unit axis $\\mathbf{u} \\in S^2$ distributed uniformly and an angle $\\alpha \\in [-a,a]$ with a distribution symmetric about $0$ (for this task, use a uniform distribution on $[-a,a]$). The proposal is the rotated vector $\\mathbf{y} = R(\\mathbf{u},\\alpha)\\,\\mathbf{x}$, where $R(\\mathbf{u},\\alpha)$ is the right-handed rotation about $\\mathbf{u}$ by angle $\\alpha$. Accept the proposal with probability $1$ and set the new state to $\\mathbf{y}$. This chain should satisfy detailed balance with respect to the uniform measure on $S^2$ and be ergodic.\n\nB. Two naive angle-space chains acting on $(\\theta,\\phi)$:\n\nB1. Naive scaled-angle random walk (NSAW): given current $(\\theta,\\phi)$, propose\n$\\theta' = \\theta + s \\sin(\\theta)\\,\\xi_1$ and $\\phi' = \\phi + s \\sin(\\theta)\\,\\xi_2$ where $\\xi_1$ and $\\xi_2$ are independent and uniform on $[-1,1]$. Enforce the domain as follows: reflect $\\theta'$ at the boundaries of $[0,\\pi]$ by the rule $\\theta' \\leftarrow |\\operatorname{mod}(\\theta',2\\pi) - \\pi|$, and wrap $\\phi'$ into $[0,2\\pi)$ by $\\phi' \\leftarrow \\operatorname{mod}(\\phi',2\\pi)$. Accept the proposal with probability $1$. This chain is to be analyzed for ergodicity failure near the poles.\n\nB2. Naive uncorrected angle random walk (NUAW): given current $(\\theta,\\phi)$, propose\n$\\theta' = \\theta + \\delta \\,\\eta_1$ and $\\phi' = \\phi + \\delta \\,\\eta_2$ where $\\eta_1$ and $\\eta_2$ are independent and uniform on $[-1,1]$. Enforce the same reflection/wrap rules as in B1. Accept the proposal with probability $1$. This chain ignores the $\\sin(\\theta)$ area factor and must be analyzed for bias relative to the uniform target.\n\nAll angles must be represented and computed in radians. You must use a fixed pseudo-random number generator seed $s = 12345$ for reproducibility.\n\nTest suite and required outputs:\n\nFor each of the following parameter sets, compute the specified quantitative output. The theoretical units to be used are specified for any angles; the final outputs for all cases are unitless floats or booleans.\n\n- Case $1$ (ergodicity failure at the pole): Run NSAW (B1) starting at $(\\theta_0,\\phi_0)=(0,0)$ with step parameter $s = 0.5$ (radians) for $N = 1000$ steps. Output a boolean indicating whether the chain ever left the pole, namely whether there exists any step with $\\theta  10^{-15}$ (radians). The expected answer type is a boolean.\n\n- Case $2$ (uniformity of RRW): Run RRW (A) starting from the north pole $\\mathbf{x}_0 = (0,0,1)$, with angle bound $a = 0.3$ (radians) for $M = 50000$ steps. Collect the sequence of $z$-coordinates and form a histogram with $B = 40$ equal-width bins partitioning $[-1,1]$. Let $p_i$ be the empirical probability of bin $i$ and let the theoretical uniform-bin probability be $u_i = 1/B$ for all $i$. Output the $\\ell_1$ deviation $D = \\sum_{i=1}^{B} |p_i - u_i|$ as a float.\n\n- Case $3$ (bias of NUAW): Run NUAW (B2) starting from $(\\theta_0,\\phi_0)=(1.0,1.0)$ (radians), with step parameter $\\delta = 0.3$ (radians) for $M = 50000$ steps. Compute the same $\\ell_1$ deviation $D$ of the empirical $z$-histogram relative to the uniform-bin probabilities on $[-1,1]$ with $B = 40$ bins. Output $D$ as a float.\n\n- Case $4$ (slow escape near the pole for NSAW): Run NSAW (B1) starting from $(\\theta_0,\\phi_0)=(10^{-6},0)$ (radians) with step parameter $s = 0.2$ (radians) for $N = 1000$ steps. Output a boolean indicating whether the chain ever reached $\\theta \\ge 10^{-3}$ (radians). The expected answer type is a boolean.\n\nFinal output format:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order of Cases $1$ through $4$, for example, $[r_1,r_2,r_3,r_4]$, where $r_1$ and $r_4$ are booleans and $r_2$ and $r_3$ are floats. No other text should be printed. All angles used internally must be in radians, and all random draws must use the fixed seed $s = 12345$.",
            "solution": "The problem requires the analysis and implementation of three discrete-time Markov chains on the unit sphere $S^2$ for the purpose of sampling from the uniform probability measure. The validity and efficacy of these chains are to be assessed against the fundamental principles of Markov Chain Monte Carlo (MCMC) methods, namely detailed balance and ergodicity.\n\nA valid MCMC algorithm designed to sample from a target distribution with probability density $\\pi(\\mathbf{x})$ must generate a Markov chain that is ergodic and has $\\pi(\\mathbf{x})$ as its stationary distribution. A sufficient condition for the latter is that the transition kernel $P(\\mathbf{x} \\to \\mathbf{y})$ satisfies the detailed balance condition:\n$$ \\pi(\\mathbf{x})P(\\mathbf{x} \\to \\mathbf{y}) = \\pi(\\mathbf{y})P(\\mathbf{y} \\to \\mathbf{x}) $$\nFor the uniform distribution on the sphere $S^2$, the density $\\pi(\\mathbf{x})$ is a constant for all $\\mathbf{x} \\in S^2$. In this special case, the detailed balance condition simplifies to the requirement that the transition kernel be symmetric: $P(\\mathbf{x} \\to \\mathbf{y}) = P(\\mathbf{y} \\to \\mathbf{x})$. Ergodicity requires that the chain is irreducible (any state is reachable from any other state) and aperiodic.\n\nThe analysis of the specified algorithms proceeds as follows.\n\n**A. Rotational Random-Walk (RRW) Chain**\n\nThis algorithm proposes a new state $\\mathbf{y}$ by rotating the current state $\\mathbf{x}$ by a random angle $\\alpha$ around a random axis $\\mathbf{u}$. The proposal is $\\mathbf{y} = R(\\mathbf{u}, \\alpha)\\mathbf{x}$ and is always accepted.\n- **Detailed Balance**: The target distribution is uniform on $S^2$, which is by definition invariant under any rotation. The transition probability from $\\mathbf{x}$ to $\\mathbf{y}$ depends on the distribution of rotations $R(\\mathbf{u}, \\alpha)$. The axis $\\mathbf{u}$ is chosen uniformly from $S^2$, and the angle $\\alpha$ is chosen from a symmetric distribution (uniform on $[-a, a]$).\nThe probability of generating a rotation $R$ is the same as generating its inverse $R^{-1}$ (a rotation about the same axis $\\mathbf{u}$ by an angle $-\\alpha$). If $\\mathbf{y} = R\\mathbf{x}$, then $\\mathbf{x} = R^{-1}\\mathbf{y}$. The probability of proposing $\\mathbf{y}$ from $\\mathbf{x}$ is the probability of selecting the specific rotation $R$. The probability of proposing $\\mathbf{x}$ from $\\mathbf{y}$ is the probability of selecting the inverse rotation $R^{-1}$. Since the distribution of rotations is symmetric, these probabilities are equal. Therefore, $P(\\mathbf{x} \\to \\mathbf{y}) = P(\\mathbf{y} \\to \\mathbf{x})$, and the chain satisfies detailed balance.\n- **Ergodicity**: Any point on the sphere can be reached from any other point by a suitable rotation. Since the algorithm samples rotations from a set with non-empty interior in the group $SO(3)$, any rotation can be approximated by a sequence of these random rotations. Thus, the chain is irreducible. It is also aperiodic as it is not confined to a finite set of states. Therefore, the RRW chain is ergodic.\n- **Implementation**: A random unit axis $\\mathbf{u}$ is generated by creating a vector of three standard normal variates and normalizing its length to $1$. The new state $\\mathbf{y}$ is computed using Rodrigues' rotation formula:\n$$ \\mathbf{y} = \\mathbf{x} \\cos\\alpha + (\\mathbf{u} \\times \\mathbf{x}) \\sin\\alpha + \\mathbf{u}(\\mathbf{u} \\cdot \\mathbf{x})(1 - \\cos\\alpha) $$\nThe test in Case $2$ verifies the uniformity of the resulting sample distribution by examining the marginal distribution of the $z$-coordinate, $z = \\cos\\theta$. For a uniform distribution on $S^2$, the distribution of $z$ is uniform on $[-1, 1]$.\n\n**B. Naive Angle-Space Chains**\n\nThese algorithms operate in the spherical coordinate space $(\\theta, \\phi)$ and exemplify common pitfalls in designing MCMC samplers on manifolds.\n\n**B1. Naive Scaled-Angle Random Walk (NSAW)**\n\nThe proposal steps are $\\Delta\\theta = s \\sin(\\theta)\\,\\xi_1$ and $\\Delta\\phi = s \\sin(\\theta)\\,\\xi_2$.\n- **Ergodicity Failure**: The critical flaw is the dependence of the step size on $\\sin(\\theta)$. At the poles of the sphere, where $\\theta=0$ or $\\theta=\\pi$, we have $\\sin(\\theta)=0$. Consequently, the proposed step size is zero. If the chain is initialized at a pole (e.g., $\\theta_0=0$), it will be unable to move. The poles become absorbing states. This makes the state space reducible, as regions with $\\theta \\in (0, \\pi)$ are inaccessible from the poles. The chain is therefore not ergodic. Case $1$ is designed to demonstrate this pathologically, where a start at $\\theta=0$ ensures no movement.\n- **Slow Mixing**: Even when started near a pole (e.g., $\\theta_0 = \\epsilon \\ll 1$), the step size is of order $\\epsilon$, leading to extremely slow \"diffusion\" away from the pole. This is a practical failure of ergodicity, as the chain appears \"stuck\" for a large number of steps. Case $4$ tests this behavior, investigating if the chain can escape a small neighborhood of the pole within a fixed number of iterations.\n\n**B2. Naive Uncorrected Angle Random Walk (NUAW)**\n\nThe proposal steps are $\\Delta\\theta = \\delta\\,\\eta_1$ and $\\Delta\\phi = \\delta\\,\\eta_2$. This is a standard random walk in the $(\\theta, \\phi)$ coordinate space.\n- **Bias and Detailed Balance Violation**: This algorithm implicitly assumes that the target distribution is uniform in the coordinate space $(\\theta, \\phi)$. However, the uniform measure on the sphere has a density with respect to the coordinate-area element $\\mathrm{d}\\theta\\,\\mathrm{d}\\phi$ that is proportional to $\\sin(\\theta)$, i.e., $\\pi(\\theta,\\phi) \\propto \\sin(\\theta)$. The stationary distribution of the NUAW chain is uniform in $(\\theta, \\phi)$, not proportional to $\\sin(\\theta)$.\nThis discrepancy means the chain does not sample the target uniform distribution on $S^2$. It oversamples regions where the coordinate chart is dense relative to the surface area, i.e., near the poles where $\\sin(\\theta)$ is small. Conversely, it undersamples the equatorial region where $\\sin(\\theta)$ is large.\nA proper Metropolis-Hastings correction would require an acceptance probability $A = \\min\\left(1, \\frac{\\pi(\\theta', \\phi')}{\\pi(\\theta, \\phi)}\\right) = \\min\\left(1, \\frac{\\sin(\\theta')}{\\sin(\\theta)}\\right)$, which this algorithm omits by accepting all proposals. The bias is quantified in Case $3$ by measuring the deviation of the empirical $z$-coordinate distribution from the theoretical uniform distribution. We expect a U-shaped histogram for $z = \\cos(\\theta)$, indicating an excess of samples near the poles ($z=\\pm 1$).\n\n**Summary of Computational Tasks**\n\nThe provided code implements the specified algorithms and performs the four tests.\n- **Case 1**: Simulates NSAW from $\\theta_0=0$ and verifies that $\\theta$ remains zero.\n- **Case 2**: Simulates the correct RRW algorithm and computes the $\\ell_1$ deviation of the empirical $z$-distribution from uniform, which is expected to be small.\n- **Case 3**: Simulates the biased NUAW algorithm and computes the same deviation, which is expected to be significantly larger than for RRW.\n- **Case 4**: Simulates NSAW from a point very close to the pole to test for slow escape.\n\nThe calculations are performed using the `numpy` library and a fixed random seed for reproducibility. The boundary conditions for $\\theta$ and $\\phi$ are implemented exactly as specified.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the four test cases specified in the problem statement regarding\n    Markov chains on the unit sphere S^2.\n    \"\"\"\n    RNG_SEED = 12345\n    rng = np.random.default_rng(RNG_SEED)\n\n    def run_rrw_chain(x0, a, M):\n        \"\"\"\n        Implements the Rotational Random-Walk (RRW) chain.\n        \n        Args:\n            x0 (np.ndarray): Initial state vector on S^2.\n            a (float): Bound for the uniform rotation angle in [-a, a].\n            M (int): Number of steps.\n        \n        Returns:\n            np.ndarray: Array of z-coordinates for each state in the chain.\n        \"\"\"\n        x = np.array(x0, dtype=float)\n        z_coords = np.zeros(M)\n        \n        for i in range(M):\n            # Generate a random unit axis u\n            u = rng.standard_normal(3)\n            u /= np.linalg.norm(u)\n            \n            # Generate a random angle alpha\n            alpha = rng.uniform(-a, a)\n            \n            # Apply Rodrigues' rotation formula\n            cos_alpha = np.cos(alpha)\n            sin_alpha = np.sin(alpha)\n            \n            x_new = (x * cos_alpha +\n                     np.cross(u, x) * sin_alpha +\n                     u * np.dot(u, x) * (1 - cos_alpha))\n            \n            x = x_new\n            z_coords[i] = x[2]\n            \n        return z_coords\n\n    def run_angle_space_chain(theta0, phi0, N, step_param, is_nsaw):\n        \"\"\"\n        Implements both Naive Scaled-Angle (NSAW) and Naive Uncorrected (NUAW) chains.\n\n        Args:\n            theta0 (float): Initial theta angle.\n            phi0 (float): Initial phi angle.\n            N (int): Number of steps.\n            step_param (float): The step size parameter (s for NSAW, delta for NUAW).\n            is_nsaw (bool): True for NSAW, False for NUAW.\n\n        Returns:\n            (np.ndarray, np.ndarray): Arrays of theta and phi values for each state.\n        \"\"\"\n        theta = theta0\n        phi = phi0\n        thetas = np.zeros(N + 1)\n        phis = np.zeros(N + 1)\n        thetas[0], phis[0] = theta, phi\n\n        for i in range(N):\n            xi = rng.uniform(-1, 1, 2)\n            \n            if is_nsaw:\n                scale = step_param * np.sin(theta)\n            else: # NUAW\n                scale = step_param\n\n            theta_prop = theta + scale * xi[0]\n            phi_prop = phi + scale * xi[1]\n            \n            # Enforce domain for theta: reflect via given formula\n            theta = np.abs(np.mod(theta_prop, 2 * np.pi) - np.pi)\n            \n            # Enforce domain for phi: wrap\n            phi = np.mod(phi_prop, 2 * np.pi)\n\n            thetas[i+1] = theta\n            phis[i+1] = phi\n        \n        return thetas, phis\n\n    # --- Case 1: Ergodicity failure of NSAW at the pole ---\n    thetas_case1, _ = run_angle_space_chain(\n        theta0=0.0, phi0=0.0, N=1000, step_param=0.5, is_nsaw=True\n    )\n    # The chain starts at theta=0, so sin(theta)=0 and it never moves.\n    result1 = np.any(thetas_case1  1e-15)\n\n    # --- Case 2: Uniformity of RRW ---\n    z_coords_rrw = run_rrw_chain(x0=[0, 0, 1], a=0.3, M=50000)\n    B = 40\n    p_i_rrw, _ = np.histogram(z_coords_rrw, bins=B, range=(-1, 1))\n    p_i_rrw = p_i_rrw / np.sum(p_i_rrw)\n    u_i = 1 / B\n    result2 = np.sum(np.abs(p_i_rrw - u_i))\n\n    # --- Case 3: Bias of NUAW ---\n    thetas_nuaw, _ = run_angle_space_chain(\n        theta0=1.0, phi0=1.0, N=50000, step_param=0.3, is_nsaw=False\n    )\n    # Discard burn-in, although for a long run it has minor effect\n    z_coords_nuaw = np.cos(thetas_nuaw[1:]) \n    p_i_nuaw, _ = np.histogram(z_coords_nuaw, bins=B, range=(-1, 1))\n    p_i_nuaw = p_i_nuaw / np.sum(p_i_nuaw)\n    result3 = np.sum(np.abs(p_i_nuaw - u_i))\n    \n    # --- Case 4: Slow escape near the pole for NSAW ---\n    thetas_case4, _ = run_angle_space_chain(\n        theta0=1e-6, phi0=0.0, N=1000, step_param=0.2, is_nsaw=True\n    )\n    result4 = np.any(thetas_case4 = 1e-3)\n\n    # --- Final Output ---\n    results = [result1, result2, result3, result4]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Finally, let's explore the remarkable generality of the Markov Chain Monte Carlo framework by applying it to a problem outside of traditional physics: solving a logic puzzle. This practice challenges you to reframe a combinatorial search problem as a statistical mechanics system by defining an \"energy\" function, $E(s)$, that counts the number of violated constraints. By implementing a Metropolis-Hastings sampler that targets the Boltzmann distribution $\\pi_T(s) \\propto \\exp(-E(s)/T)$, you will use the principles of ergodicity and detailed balance to navigate a vast solution space and find a configuration that solves the puzzle . This exercise demonstrates the power of MCMC as a general-purpose tool for optimization.",
            "id": "2385680",
            "problem": "Design and implement a program that uses Markov Chain Monte Carlo (MCMC) to search the space of assignments for small, structured logic puzzles. The puzzles consist of $N$ positions (indexed $0,1,\\dots,N-1$) and $K$ categorical attributes (for example, color, pet, drink). Each category has exactly $N$ distinct values, and a valid assignment is a bijection assigning one value from each category to each position, so that within a category no two positions share the same value. Constraints relate positions of values across categories (for example, equality, adjacency, ordering). Define an energy function $E(s)$ on a state $s$ as the total number of violated constraints in $s$. The target stationary distribution for the chain at temperature $T$ is the Boltzmann distribution $\\pi_T(s) \\propto \\exp(-E(s)/T)$.\n\nYour program must:\n- Represent states as $K$ independent permutations over $N$ positions, one permutation per category.\n- Use a proposal mechanism that is symmetric: at each step choose a category uniformly at random from the $K$ categories, then choose two distinct positions uniformly at random and propose swapping the values of that category at those two positions.\n- Use an acceptance rule that ensures detailed balance with respect to $\\pi_T(s)$ for any fixed $T0$.\n- Argue and implement a move set that is ergodic on the state space (connected and aperiodic).\n- Run the MCMC for a fixed number of steps from several random restarts with a prescribed random seed sequence, and return the minimum energy observed over the entire run for each test case.\n\nDefinitions to use:\n- Let $p_{A,v}$ denote the position of value $v$ in category $A$ within the current state. Each constraint contributes $1$ to $E(s)$ if it is violated and $0$ otherwise. Allowed primitive constraint types are:\n    - Equality across categories: $p_{A,v} = p_{B,w}$.\n    - Inequality across categories: $p_{A,v} \\neq p_{B,w}$.\n    - Fixed position: $p_{A,v} = \\ell$ for a given integer $\\ell \\in \\{0,\\dots,N-1\\}$.\n    - Adjacency: $|p_{A,v} - p_{B,w}| = 1$.\n    - Immediate-left: $p_{A,v} + 1 = p_{B,w}$.\n    - Strict-right-of: $p_{A,v}  p_{B,w}$.\n\nImplementation requirements:\n- Use a constant temperature $T$ (no annealing).\n- The proposal distribution must be symmetric so that detailed balance can be satisfied using only the energy difference and temperature.\n- Start each restart from an independent random assignment drawn uniformly over permutations within each category, using the specified seed offset.\n\nTest suite. Implement exactly the following three puzzles, MCMC parameters, and seeds. For each puzzle, output the minimum energy $E_{\\min}$ observed over all steps and restarts.\n\nPuzzle A (happy path, $N=4$):\n- Categories ($K=3$), each with $N=4$ values:\n    - color: [Yellow, Blue, Red, Green]\n    - pet: [Cat, Dog, Fish, Bird]\n    - drink: [Coffee, Tea, Milk, Water]\n- Constraints (each is one clause contributing $0$ if satisfied and $1$ if violated):\n    - Immediate-left: $p_{\\text{color},\\text{Red}} + 1 = p_{\\text{color},\\text{Green}}$.\n    - Equality: $p_{\\text{drink},\\text{Tea}} = p_{\\text{color},\\text{Blue}}$.\n    - Adjacency: $|p_{\\text{pet},\\text{Dog}} - p_{\\text{color},\\text{Yellow}}| = 1$.\n    - Fixed position: $p_{\\text{drink},\\text{Milk}} = 2$.\n    - Fixed position: $p_{\\text{pet},\\text{Cat}} = 0$.\n    - Inequality: $p_{\\text{drink},\\text{Water}} \\neq p_{\\text{color},\\text{Yellow}}$.\n    - Strict-right-of: $p_{\\text{pet},\\text{Bird}}  p_{\\text{color},\\text{Red}}$.\n    - Inequality: $p_{\\text{pet},\\text{Fish}} \\neq p_{\\text{color},\\text{Green}}$.\n    - Equality: $p_{\\text{drink},\\text{Coffee}} = p_{\\text{color},\\text{Yellow}}$.\n\nPuzzle B (small, $N=3$):\n- Categories ($K=3$), each with $N=3$ values:\n    - color: [Red, Green, Blue]\n    - pet: [Dog, Cat, Fish]\n    - drink: [Tea, Milk, Coffee]\n- Constraints:\n    - Equality: $p_{\\text{color},\\text{Red}} = p_{\\text{drink},\\text{Tea}}$.\n    - Fixed position: $p_{\\text{pet},\\text{Cat}} = 1$.\n    - Strict-right-of: $p_{\\text{color},\\text{Blue}}  p_{\\text{color},\\text{Green}}$.\n    - Inequality: $p_{\\text{pet},\\text{Fish}} \\neq p_{\\text{color},\\text{Red}}$.\n    - Adjacency: $|p_{\\text{drink},\\text{Milk}} - p_{\\text{pet},\\text{Dog}}| = 1$.\n    - Equality: $p_{\\text{drink},\\text{Coffee}} = p_{\\text{color},\\text{Blue}}$.\n\nPuzzle C (unsatisfiable by construction, $N=3$):\n- Categories ($K=3$), each with $N=3$ values:\n    - color: [Red, Green, Blue]\n    - pet: [Dog, Cat, Fish]\n    - drink: [Tea, Milk, Coffee]\n- Constraints:\n    - Equality: $p_{\\text{drink},\\text{Tea}} = p_{\\text{color},\\text{Red}}$.\n    - Equality: $p_{\\text{drink},\\text{Coffee}} = p_{\\text{color},\\text{Red}}$.\n    - Fixed position: $p_{\\text{pet},\\text{Dog}} = 0$.\n    - Fixed position: $p_{\\text{color},\\text{Blue}} = 2$.\n    - Adjacency: $|p_{\\text{drink},\\text{Milk}} - p_{\\text{pet},\\text{Cat}}| = 1$.\n    - Strict-right-of: $p_{\\text{pet},\\text{Fish}}  p_{\\text{color},\\text{Green}}$.\n\nMCMC parameters and seeds for all puzzles:\n- Temperature: $T = 0.7$.\n- Steps per restart: $S = 30000$.\n- Number of restarts: $R = 8$.\n- Base random seed: Puzzle A uses seed $20231105$, Puzzle B uses seed $20231106$, Puzzle C uses seed $20231107$. Each restart $r \\in \\{0,\\dots,R-1\\}$ must use seed $(\\text{base seed} + r)$.\n\nRequired output:\n- Your program should produce a single line containing the results as a comma-separated list enclosed in square brackets. The $i$-th entry must be the minimum energy $E_{\\min}$ found for the $i$-th puzzle in the test suite. For this test suite, the required output format is exactly \"[x,y,z]\" where $x$, $y$, and $z$ are integers.\n\nScientific and algorithmic requirements:\n- Start from the definition of the Boltzmann stationary distribution $\\pi_T(s) \\propto \\exp(-E(s)/T)$.\n- Ensure the acceptance rule satisfies detailed balance with respect to $\\pi_T$ for any fixed $T$.\n- Use a symmetric proposal so that the proposal probabilities cancel in the detailed balance condition.\n- Explain why the move set is ergodic over the space of states (product of symmetric groups), and why the chain is aperiodic (nonzero self-transition probability due to possible rejections).\n\nThere are no physical units, angles, or percentages in this problem. The final output must be integers as specified above, in the exact format.",
            "solution": "The problem presented is a valid and well-posed application of the Markov Chain Monte Carlo (MCMC) method to a combinatorial optimization problem, specifically the satisfaction of constraints in logic puzzles. The problem is scientifically grounded in the principles of statistical mechanics, using an energy function and the Boltzmann distribution, which are standard components of algorithms like simulated annealing. All parameters, state representations, and objectives are specified with sufficient precision and are internally consistent. The problem is solvable as stated.\n\nThe solution to this problem requires designing an MCMC simulation that samples from a state space of puzzle assignments, with the goal of finding an assignment that minimizes an energy function $E(s)$. The energy is defined as the number of violated logical constraints. The target stationary distribution for the Markov chain is the Boltzmann distribution, $\\pi_T(s) \\propto \\exp(-E(s)/T)$, where $T$ is a constant temperature. This distribution favors states with lower energy.\n\n**1. State Representation and Energy Function**\n\nA state $s$ of the system corresponds to a complete assignment of values to positions for all categories. The puzzle involves $N$ positions, indexed $0, \\dots, N-1$, and $K$ categories. For each category, there are $N$ distinct values. A valid assignment requires that for each category, the $N$ values are assigned to the $N$ positions in a one-to-one correspondence, forming a permutation.\n\nThe state space $\\mathcal{S}$ is therefore the product of $K$ symmetric groups, $\\mathcal{S} = (S_N)^K$, where $S_N$ is the group of permutations of $N$ elements. The size of the state space is $(N!)^K$.\n\nFor computational purposes, the state $s$ is represented by a set of lookup tables. The primary representation is a $K \\times N$ matrix, `pos_to_val`, where `pos_to_val[k][p]` holds the value of category $k$ at position $p$. To efficiently evaluate constraints, we also maintain a reverse lookup table, `val_to_pos`, a $K \\times N$ matrix where `val_to_pos[k][v]` holds the position of value $v$ in category $k$. Let $p_{k,v}$ denote `val_to_pos[k][v]`.\n\nThe energy function $E(s)$ is the total count of violated constraints. Each constraint is a logical proposition. If the proposition is false for a given state $s$, it contributes $1$ to the energy; otherwise, it contributes $0$. For example, a constraint $p_{A,v} = p_{B,w}$ is violated if `val_to_pos[A][v]` $\\ne$ `val_to_pos[B][w]`.\n\n**2. Metropolis-Hastings Algorithm**\n\nTo find low-energy states, we use the Metropolis-Hastings algorithm, a specific type of MCMC. This algorithm generates a sequence of states, $s_0, s_1, s_2, \\dots$, such that the distribution of these states converges to the target distribution $\\pi_T(s)$.\n\nThe transition from a state $s$ to a new state $s'$ is a two-step process: proposing a move from $s$ to a candidate state $s'$, and then accepting or rejecting this move.\n\n**2.1. Proposal Mechanism**\n\nThe problem specifies a symmetric proposal mechanism. At each step, starting from a state $s$:\n1.  A category $k$ is chosen uniformly at random from the $K$ available categories. The probability is $1/K$.\n2.  Two distinct positions, $p_1$ and $p_2$, are chosen uniformly at random from the set of all distinct pairs of positions. There are $\\binom{N}{2}$ such pairs, so the probability of choosing a specific pair $\\{p_1, p_2\\}$ is $1/\\binom{N}{2}$.\n3.  A candidate state $s'$ is generated by swapping the values of category $k$ at positions $p_1$ and $p_2$.\n\nThe proposal probability $g(s \\to s')$ is the probability of proposing $s'$ starting from $s$. For this mechanism, the probability is $(1/K) \\times (1/\\binom{N}{2})$. To reverse the move, one must start from $s'$, choose the same category $k$, and choose the same two positions $p_1$ and $p_2$ to swap. The probability of this reverse proposal, $g(s' \\to s)$, is also $(1/K) \\times (1/\\binom{N}{2})$. Since $g(s \\to s') = g(s' \\to s)$, the proposal distribution is symmetric.\n\n**2.2. Acceptance Rule and Detailed Balance**\n\nThe convergence of the Markov chain to the stationary distribution $\\pi_T(s)$ is guaranteed if the chain satisfies the detailed balance condition:\n$$ \\pi_T(s) P(s \\to s') = \\pi_T(s') P(s' \\to s) $$\nwhere $P(s \\to s') = g(s \\to s') A(s \\to s')$ is the total transition probability, with $A(s \\to s')$ being the acceptance probability.\n\nSubstituting the expressions for $P$ and $\\pi_T(s) \\propto \\exp(-E(s)/T)$ into the detailed balance equation yields:\n$$ \\exp(-E(s)/T) g(s \\to s') A(s \\to s') = \\exp(-E(s')/T) g(s' \\to s) A(s' \\to s) $$\nBecause our proposal mechanism is symmetric ($g(s \\to s') = g(s' \\to s)$), the proposal probabilities cancel out:\n$$ \\frac{A(s \\to s')}{A(s' \\to s)} = \\frac{\\exp(-E(s')/T)}{\\exp(-E(s)/T)} = \\exp\\left(-\\frac{E(s') - E(s)}{T}\\right) $$\nLet $\\Delta E = E(s') - E(s)$. The ratio becomes $\\exp(-\\Delta E / T)$. The standard Metropolis acceptance rule satisfies this condition:\n$$ A(s \\to s') = \\min\\left(1, \\exp(-\\Delta E / T)\\right) $$\nThis rule is used in the implementation. If a proposed move leads to a state with lower or equal energy ($\\Delta E \\le 0$), it is always accepted. If it leads to a state with higher energy ($\\Delta E  0$), it is accepted with a probability $\\exp(-\\Delta E / T)$, which is less than $1$. This allows the search to escape local minima.\n\n**3. Ergodicity of the Markov Chain**\n\nFor the MCMC simulation to explore the entire state space and converge to the unique stationary distribution, the Markov chain must be ergodic. Ergodicity requires two properties: connectedness and aperiodicity.\n\n- **Connectedness**: The chain is connected if it is possible to go from any state $s_a \\in \\mathcal{S}$ to any other state $s_b \\in \\mathcal{S}$ in a finite number of steps. Our move set consists of swapping two values within any single category's permutation. A swap of two elements is a transposition in the symmetric group $S_N$. It is a fundamental theorem of group theory that the set of all transpositions generates the entire symmetric group $S_N$. This means that any permutation can be reached from any other permutation through a series of swaps. Since our move set allows us to apply swaps to any of the $K$ category permutations independently, we can transform each of the $K$ permutations in $s_a$ to match those in $s_b$. Thus, the entire state space $\\mathcal{S} = (S_N)^K$ is connected.\n\n- **Aperiodicity**: A Markov chain is aperiodic if for any state $s$, the greatest common divisor of the lengths of all possible paths from $s$ back to itself is $1$. A sufficient condition for aperiodicity is that the probability of staying in any state $s$, $P(s \\to s)$, is non-zero. In our algorithm, a self-transition occurs if a proposed move to $s' \\neq s$ is rejected. As long as the current state $s$ is not a global energy maximum, it is possible to propose a move to a state $s'$ with $E(s')  E(s)$. For such a move, $\\Delta E  0$, and the acceptance probability $\\exp(-\\Delta E / T)$ is less than $1$. The probability of rejecting this move is $1 - \\exp(-\\Delta E/T)  0$. Since there is a non-zero probability of both proposing such a move and rejecting it, the total probability of remaining in state $s$ is greater than zero ($P(s \\to s)  0$). This ensures the chain is aperiodic.\n\nSince the chain is ergodic and satisfies detailed balance, it is guaranteed to converge to the Boltzmann distribution $\\pi_T(s)$. The algorithm proceeds by running the MCMC simulation for a fixed number of steps from several independent random initial states and reports the minimum energy found across all runs and all steps. This improves the chances of finding the global minimum energy, which for a satisfiable puzzle is $E_{\\min}=0$.",
            "answer": "```python\nimport numpy as np\n\n# Puzzle A Definition\npuzzle_a_def = {\n    \"N\": 4, \"K\": 3,\n    \"categories\": {\"color\": 0, \"pet\": 1, \"drink\": 2},\n    \"values\": {\n        0: {\"Yellow\": 0, \"Blue\": 1, \"Red\": 2, \"Green\": 3},\n        1: {\"Cat\": 0, \"Dog\": 1, \"Fish\": 2, \"Bird\": 3},\n        2: {\"Coffee\": 0, \"Tea\": 1, \"Milk\": 2, \"Water\": 3},\n    },\n    \"constraints\": [\n        (\"IMMEDIATE_LEFT\", (\"color\", \"Red\"), (\"color\", \"Green\")),\n        (\"EQUALITY\", (\"drink\", \"Tea\"), (\"color\", \"Blue\")),\n        (\"ADJACENCY\", (\"pet\", \"Dog\"), (\"color\", \"Yellow\")),\n        (\"FIXED_POS\", (\"drink\", \"Milk\"), 2),\n        (\"FIXED_POS\", (\"pet\", \"Cat\"), 0),\n        (\"INEQUALITY\", (\"drink\", \"Water\"), (\"color\", \"Yellow\")),\n        (\"STRICT_RIGHT_OF\", (\"pet\", \"Bird\"), (\"color\", \"Red\")),\n        (\"INEQUALITY\", (\"pet\", \"Fish\"), (\"color\", \"Green\")),\n        (\"EQUALITY\", (\"drink\", \"Coffee\"), (\"color\", \"Yellow\")),\n    ]\n}\n\n# Puzzle B Definition\npuzzle_b_def = {\n    \"N\": 3, \"K\": 3,\n    \"categories\": {\"color\": 0, \"pet\": 1, \"drink\": 2},\n    \"values\": {\n        0: {\"Red\": 0, \"Green\": 1, \"Blue\": 2},\n        1: {\"Dog\": 0, \"Cat\": 1, \"Fish\": 2},\n        2: {\"Tea\": 0, \"Milk\": 1, \"Coffee\": 2},\n    },\n    \"constraints\": [\n        (\"EQUALITY\", (\"color\", \"Red\"), (\"drink\", \"Tea\")),\n        (\"FIXED_POS\", (\"pet\", \"Cat\"), 1),\n        (\"STRICT_RIGHT_OF\", (\"color\", \"Blue\"), (\"color\", \"Green\")),\n        (\"INEQUALITY\", (\"pet\", \"Fish\"), (\"color\", \"Red\")),\n        (\"ADJACENCY\", (\"drink\", \"Milk\"), (\"pet\", \"Dog\")),\n        (\"EQUALITY\", (\"drink\", \"Coffee\"), (\"color\", \"Blue\")),\n    ]\n}\n\n# Puzzle C Definition\npuzzle_c_def = {\n    \"N\": 3, \"K\": 3,\n    \"categories\": {\"color\": 0, \"pet\": 1, \"drink\": 2},\n    \"values\": {\n        0: {\"Red\": 0, \"Green\": 1, \"Blue\": 2},\n        1: {\"Dog\": 0, \"Cat\": 1, \"Fish\": 2},\n        2: {\"Tea\": 0, \"Milk\": 1, \"Coffee\": 2},\n    },\n    \"constraints\": [\n        (\"EQUALITY\", (\"drink\", \"Tea\"), (\"color\", \"Red\")),\n        (\"EQUALITY\", (\"drink\", \"Coffee\"), (\"color\", \"Red\")),\n        (\"FIXED_POS\", (\"pet\", \"Dog\"), 0),\n        (\"FIXED_POS\", (\"color\", \"Blue\"), 2),\n        (\"ADJACENCY\", (\"drink\", \"Milk\"), (\"pet\", \"Cat\")),\n        (\"STRICT_RIGHT_OF\", (\"pet\", \"Fish\"), (\"color\", \"Green\")),\n    ]\n}\n\nPUZZLES = [puzzle_a_def, puzzle_b_def, puzzle_c_def]\n\nclass MCMCSolver:\n    def __init__(self, puzzle_def, T, S, R, base_seed):\n        self.N = puzzle_def[\"N\"]\n        self.K = puzzle_def[\"K\"]\n        self.T = T\n        self.S = S\n        self.R = R\n        self.base_seed = base_seed\n\n        self.cat_map = puzzle_def[\"categories\"]\n        self.val_maps = puzzle_def[\"values\"]\n        \n        self.parsed_constraints = self._parse_constraints(puzzle_def[\"constraints\"])\n\n    def _parse_constraints(self, constraints_def):\n        parsed = []\n        for c in constraints_def:\n            ctype = c[0]\n            if ctype in (\"EQUALITY\", \"INEQUALITY\", \"ADJACENCY\", \"IMMEDIATE_LEFT\", \"STRICT_RIGHT_OF\"):\n                cat1_name, val1_name = c[1]\n                cat2_name, val2_name = c[2]\n                k1 = self.cat_map[cat1_name]\n                k2 = self.cat_map[cat2_name]\n                v1 = self.val_maps[k1][val1_name]\n                v2 = self.val_maps[k2][val2_name]\n                parsed.append((ctype, (k1, v1), (k2, v2)))\n            elif ctype == \"FIXED_POS\":\n                cat_name, val_name = c[1]\n                pos = c[2]\n                k = self.cat_map[cat_name]\n                v = self.val_maps[k][val_name]\n                parsed.append((ctype, (k, v), pos))\n        return parsed\n\n    def _evaluate_energy(self, val_to_pos_map):\n        violations = 0\n        for ctype, term1, term2 in self.parsed_constraints:\n            if ctype == \"EQUALITY\":\n                k1, v1 = term1\n                k2, v2 = term2\n                if val_to_pos_map[k1, v1] != val_to_pos_map[k2, v2]:\n                    violations += 1\n            elif ctype == \"INEQUALITY\":\n                k1, v1 = term1\n                k2, v2 = term2\n                if val_to_pos_map[k1, v1] == val_to_pos_map[k2, v2]:\n                    violations += 1\n            elif ctype == \"FIXED_POS\":\n                k, v = term1\n                pos = term2\n                if val_to_pos_map[k, v] != pos:\n                    violations += 1\n            elif ctype == \"ADJACENCY\":\n                k1, v1 = term1\n                k2, v2 = term2\n                if abs(val_to_pos_map[k1, v1] - val_to_pos_map[k2, v2]) != 1:\n                    violations += 1\n            elif ctype == \"IMMEDIATE_LEFT\":\n                k1, v1 = term1\n                k2, v2 = term2\n                if val_to_pos_map[k1, v1] + 1 != val_to_pos_map[k2, v2]:\n                    violations += 1\n            elif ctype == \"STRICT_RIGHT_OF\":\n                k1, v1 = term1\n                k2, v2 = term2\n                if val_to_pos_map[k1, v1] = val_to_pos_map[k2, v2]:\n                    violations += 1\n        return violations\n\n    def run(self):\n        min_global_energy = float('inf')\n\n        for r in range(self.R):\n            seed = self.base_seed + r\n            rng = np.random.default_rng(seed)\n\n            # Initialize state\n            pos_to_val = np.empty((self.K, self.N), dtype=int)\n            val_to_pos = np.empty((self.K, self.N), dtype=int)\n            for k in range(self.K):\n                perm = rng.permutation(self.N)\n                pos_to_val[k, :] = perm\n                for p, v in enumerate(perm):\n                    val_to_pos[k, v] = p\n\n            current_energy = self._evaluate_energy(val_to_pos)\n            min_restart_energy = current_energy\n\n            for _ in range(self.S):\n                # Propose a move\n                k_swap = rng.integers(self.K)\n                p1, p2 = rng.choice(self.N, 2, replace=False)\n                \n                # Create a proposed state by swapping\n                prop_pos_to_val = np.copy(pos_to_val)\n                prop_val_to_pos = np.copy(val_to_pos)\n\n                v1, v2 = prop_pos_to_val[k_swap, p1], prop_pos_to_val[k_swap, p2]\n                prop_pos_to_val[k_swap, p1], prop_pos_to_val[k_swap, p2] = v2, v1\n                prop_val_to_pos[k_swap, v1], prop_val_to_pos[k_swap, v2] = p2, p1\n                \n                proposed_energy = self._evaluate_energy(prop_val_to_pos)\n                \n                delta_E = proposed_energy - current_energy\n                \n                # Metropolis acceptance criterion\n                if delta_E = 0 or rng.random()  np.exp(-delta_E / self.T):\n                    pos_to_val = prop_pos_to_val\n                    val_to_pos = prop_val_to_pos\n                    current_energy = proposed_energy\n                \n                if current_energy  min_restart_energy:\n                    min_restart_energy = current_energy\n\n            if min_restart_energy  min_global_energy:\n                min_global_energy = min_restart_energy\n        \n        return int(min_global_energy)\n\ndef solve():\n    T = 0.7\n    S = 30000\n    R = 8\n    SEEDS = [20231105, 20231106, 20231107]\n    \n    test_cases = [\n        (PUZZLES[0], T, S, R, SEEDS[0]),\n        (PUZZLES[1], T, S, R, SEEDS[1]),\n        (PUZZLES[2], T, S, R, SEEDS[2]),\n    ]\n\n    results = []\n    for case in test_cases:\n        solver = MCMCSolver(*case)\n        min_energy = solver.run()\n        results.append(min_energy)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}