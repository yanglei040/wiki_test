{
    "hands_on_practices": [
        {
            "introduction": "Metropolis-Hastings 算法是马尔可夫链蒙特卡洛（MCMC）方法的核心。其精髓在于一个精心设计的接受准则，它确保马尔可夫链的稳态分布就是我们想要采样的目标分布。这个练习将带你亲手计算一个关键的步骤——接受概率，这是理解 MCMC 如何在参数空间中“智能”移动的第一步。通过这个具体的计算，你将掌握 MCMC 算法如何平衡对高概率区域的探索和跳出局部最优的能力 。",
            "id": "1371728",
            "problem": "一位数据科学家正在实施马尔可夫链蒙特卡洛 (MCMC) 模拟，以从参数 $x$ 的后验概率分布中抽取样本。目标分布 $\\pi(x)$ 与参数负绝对值的指数成正比，即 $\\pi(x) \\propto \\exp(-|x|)$。\n\n该科学家使用 Metropolis 算法和一个对称提议分布 $q(x'|x)$，其中在给定当前状态 $x$ 的情况下提议一个新状态 $x'$ 的概率等于在给定 $x'$ 的情况下提议 $x$ 的概率（即，$q(x'|x) = q(x|x')$）。\n\n假设在模拟的某一步中，链的当前状态是 $x = 1.5$。然后算法提议转移到一个新的候选状态 $x' = 2.0$。\n\n计算这次特定转移的接受概率。你的答案应该是一个无量纲的实数。将你的最终答案四舍五入到四位有效数字。",
            "solution": "对于从 $x$ 到 $x'$ 的一次转移，在使用对称提议 $q(x'|x)=q(x|x')$ 的情况下，Metropolis 接受概率为\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\n给定目标分布 $\\pi(x)\\propto \\exp(-|x|)$，该比率简化为\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\n当 $x=1.5$ 且 $x'=2.0$ 时，我们有 $|x|=1.5$ 和 $|x'|=2.0$，所以\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\n因此，\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\n在数值上，当四舍五入到四位有效数字时，$\\exp(-0.5)\\approx 0.6065$。",
            "answer": "$$\\boxed{0.6065}$$"
        },
        {
            "introduction": "一个高效的 MCMC 采样器应该能迅速地探索整个参数空间。然而，当参数之间存在强相关性时，采样效率会急剧下降，仿佛采样器被困在了一个狭窄的“峡谷”中。这个练习通过一个确定性的坐标轮换优化算法（可以看作吉布斯采样的一个特例），让你直观地理解这个问题 。通过分析在高度相关的二维高斯分布中的移动，你将从几何上洞察为什么简单的采样策略会步履维艰，这对于诊断 MCMC 的收敛问题和选择更高级的采样方法至关重要。",
            "id": "1371718",
            "problem": "考虑一个用于定位特定二维概率密度函数 $p(x, y)$ 众数的迭代算法。该算法在第 $t$ 次迭代时的状态是平面中的一个点 $(x_t, y_t)$。一次完整的迭代将状态从 $(x_t, y_t)$ 转换到 $(x_{t+1}, y_{t+1})$，它包括以下两个顺序更新步骤：\n\n1.  首先，将 $x$ 坐标更新为一个值 $x'$，该值使得条件密度 $p(x | y=y_t)$ 最大化，同时保持 $y$ 坐标不变。状态变为 $(x', y_t)$。\n2.  其次，将 $y$ 坐标更新为一个值 $y_{t+1}$，该值使得条件密度 $p(y | x=x')$ 最大化，同时保持新的 $x$ 坐标不变。\n\n因此，一次完整迭代后的状态是 $(x_{t+1}, y_{t+1}) = (x', y_{t+1})$。\n\n目标概率分布 $p(x, y)$ 是关于两个无量纲变量 $X$ 和 $Y$ 的零均值二元正态分布。其协方差矩阵为：\n$$ \\Sigma = \\begin{pmatrix} \\sigma^2 & \\rho \\sigma^2 \\\\ \\rho \\sigma^2 & \\sigma^2 \\end{pmatrix} $$\n其中 $\\sigma > 0$ 是两个变量的标准差，$\\rho$ 是相关系数，满足 $0 < \\rho < 1$。\n\n对于高斯分布，条件分布的众数与其均值重合。已知对于这个特定的二元正态分布，条件期望为 $E[X|Y=y] = \\rho y$ 和 $E[Y|X=x] = \\rho x$。\n\n该算法在点 $(x_0, y_0) = (A, A)$ 处初始化，其中 $A$ 是一个非零实常数。\n\n计算比率 $\\frac{D_1^2}{D_0^2}$，其中 $D_0^2$ 是初始点到众数 $(0,0)$ 的欧几里得距离的平方，$D_1^2$ 是算法经过一次完整迭代后，点到众数的欧几里得距离的平方。请用 $\\rho$ 将你的答案表示为一个符号表达式。",
            "solution": "目标密度是一个零均值的二元正态分布，其协方差矩阵为 $\\Sigma=\\sigma^{2}\\begin{pmatrix}1 & \\rho \\\\ \\rho & 1\\end{pmatrix}$，且 $0 < \\rho < 1$。对于高斯分布，条件众数等于条件均值。已知 $E[X\\mid Y=y]=\\rho y$ 和 $E[Y\\mid X=x]=\\rho x$，算法的更新步骤如下：\n1) 从 $(x_{0},y_{0})=(A,A)$ 开始，在保持 $y=y_{0}$ 不变的情况下更新 $x$ 坐标：\n$$x'=\\arg\\max_{x}p(x\\mid y=y_{0})=E[X\\mid Y=y_{0}]=\\rho y_{0}=\\rho A.$$\n2) 保持 $x=x'$ 不变，更新 $y$ 坐标：\n$$y_{1}=\\arg\\max_{y}p(y\\mid x=x')=E[Y\\mid X=x']=\\rho x'=\\rho(\\rho A)=\\rho^{2}A.$$\n经过一次完整迭代后，状态为 $(x_{1},y_{1})=(x',y_{1})=(\\rho A,\\rho^{2}A)$。\n\n距离众数 $(0,0)$ 的初始欧几里得距离平方为\n$$D_{0}^{2}=x_{0}^{2}+y_{0}^{2}=A^{2}+A^{2}=2A^{2}.$$\n一次迭代后，距离的平方为\n$$D_{1}^{2}=x_{1}^{2}+y_{1}^{2}=(\\rho A)^{2}+(\\rho^{2}A)^{2}=A^{2}\\left(\\rho^{2}+\\rho^{4}\\right).$$\n因此，该比率为\n$$\\frac{D_{1}^{2}}{D_{0}^{2}}=\\frac{A^{2}\\left(\\rho^{2}+\\rho^{4}\\right)}{2A^{2}}=\\frac{\\rho^{2}+\\rho^{4}}{2}=\\frac{\\rho^{2}\\left(1+\\rho^{2}\\right)}{2}.$$",
            "answer": "$$\\boxed{\\frac{\\rho^{2}+\\rho^{4}}{2}}$$"
        },
        {
            "introduction": "理论上，MCMC 是一个强大的工具，但在实践中，其性能严重依赖于对提议分布参数（如步长）的精细调整。一个常见的难题是：如何为复杂的目标分布选择一个合适的步长？这个高级实践将指导你解决这一核心问题，通过编写一个自适应 MCMC 采样器 。你将运用随机近似理论（具体来说是 Robbins-Monro 算法）在“燃烧期”（burn-in）自动调整步长，以达到一个理论上最优的接受率。完成这个练习，意味着你从 MCMC 的使用者变成了构建者，掌握了连接理论与稳健实现的关键技能。",
            "id": "2411370",
            "problem": "实现一个自适应 Metropolis 随机游走马尔可夫链蒙特卡洛（MCMC）算法，该算法在预烧（burn-in）阶段调整一个标量提议步长，以达到并维持一个接近指定值的目标接受率。目标密度函数仅在相差一个归一化常数的情况下是已知的。您的实现必须是一个完整的、可运行的程序，它不接受任何输入并打印所需的输出。该算法必须基于基本原理进行论证：（i）从细致平衡条件出发的 Metropolis-Hastings 构建方法，以及（ii）用于解决接受率求根问题的随机近似方法。目标是设计自适应过程，使其仅限于预烧阶段，并在采样阶段不改变平稳分布。\n\n从以下基本原理出发：\n- 具有平稳密度 $\\pi(\\boldsymbol{x})$ 的马尔可夫链的转移核必须满足细致平衡条件，即对于所有状态 $\\boldsymbol{x}$ 和 $\\boldsymbol{y}$，$\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$。\n- 在使用提议密度 $q(\\boldsymbol{y}\\mid \\boldsymbol{x})$ 的 Metropolis-Hastings 构建中，必须选择接受概率以使细致平衡条件成立。\n- 在自适应方案中，预烧期间的参数更新可以被看作是使用递减步长来求解形式为 $\\mathbb{E}[h(\\theta)] = 0$ 方程的随机近似。\n\n您的任务是：\n1) 从细致平衡条件推导对称高斯随机游走提议 $q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$ 的 Metropolis-Hastings 接受概率，并在您的代码中实现它。您必须在您的解决方案中从细致平衡出发，论证该接受公式，不得依赖任何未经证明的简化公式。\n2) 推导并实现一个 Robbins-Monro 类型的随机近似方法，在预烧期间根据递减步长序列，在第 $n$ 次迭代时更新对数步长 $\\theta = \\log \\sigma$。目标是使期望接受概率趋向目标值 $a^\\star$。您的更新必须在对数尺度上进行以保持 $\\sigma$ 的正性，必须使用形式为 $\\gamma_n = c/(n+t_0)$ 的递减增益（其中常数 $c > 0$ 和 $t_0 \\ge 0$），并且必须严格限制在预烧阶段。在您的解决方案中清晰地陈述选择此方法的原因。\n3) 预烧结束后，固定调整好的 $\\sigma$ 并生成样本。仅计算采样阶段的经验接受率。所有接受率必须以单位区间内的小数形式报告。\n\n您必须在以下测试套件上实现并测试您的程序。每个测试都指定了目标分布、维度、初始条件和随机种子。为保证可复现性，请使用指定的种子。所有情况下的目标接受率均为 $a^\\star = 0.23$。\n\n- 测试 A（一维标准高斯分布）：\n  - 维度 $d = 1$。\n  - 目标对数密度：$\\log \\pi(x) = -\\tfrac{1}{2} x^2$。\n  - 初始位置：$x_0 = 0$。\n  - 初始步长：$\\sigma_0 = 0.001$。\n  - 预烧迭代次数：$N_{\\mathrm{burn}} = 6000$。\n  - 采样迭代次数：$N_{\\mathrm{sample}} = 12000$。\n  - 随机种子：$42$。\n\n- 测试 B（五维相关高斯分布）：\n  - 维度 $d = 5$。\n  - 目标密度：$\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x}\\right)$，其中 $\\Sigma_{ij} = \\rho^{|i-j|}$ 且 $\\rho = 0.8$。\n  - 初始位置：$\\boldsymbol{x}_0 = \\boldsymbol{0}$。\n  - 初始步长：$\\sigma_0 = 10$。\n  - 预烧迭代次数：$N_{\\mathrm{burn}} = 8000$。\n  - 采样迭代次数：$N_{\\mathrm{sample}} = 12000$。\n  - 随机种子：$123$。\n\n- 测试 C（具有软化曲率的二维 Rosenbrock 目标）：\n  - 维度 $d = 2$。\n  - 定义势能 $U(x_1,x_2) = 100\\,(x_2 - x_1^2)^2 + (1 - x_1)^2$。\n  - 目标密度：$\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-U(x_1,x_2)/20\\right)$。\n  - 初始位置：$\\boldsymbol{x}_0 = (0,\\,0)$。\n  - 初始步长：$\\sigma_0 = 1$。\n  - 预烧迭代次数：$N_{\\mathrm{burn}} = 12000$。\n  - 采样迭代次数：$N_{\\mathrm{sample}} = 12000$。\n  - 随机种子：$2024$。\n\n算法要求：\n- 使用高斯随机游走提议 $\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n- 仅在预烧期间，每次提议后通过 Robbins-Monro 步骤更新 $\\theta_n = \\log \\sigma_n$，步长为 $\\gamma_n = c/(n + t_0)$（其中 $c$ 和 $t_0$ 为固定常数），并使用该步骤中观测到的接受概率。\n- 预烧结束后，固定 $\\sigma$ 并继续采样，不再进行任何自适应调整。\n- 为保证稳定性，您可以将 $\\theta_n$ 约束在一个较宽的区间内，以使 $\\sigma_n$ 保持有限。\n\n输出规格：\n- 对每个测试，仅计算 $N_{\\mathrm{sample}}$ 次采样迭代期间的经验接受率。\n- 您的程序必须打印单行，其中包含一个列表，按 A, B, C 的顺序列出 3 个接受率，每个接受率四舍五入到三位小数，以小数形式表示（不带百分号），格式严格如下：$[\\text{r}_A,\\text{r}_B,\\text{r}_C]$。\n\n本问题不涉及物理单位或角度单位。所有数值答案必须是小数。在给定种子的情况下，输出必须是确定性的。最终程序必须是完整的、可直接运行的，不需要任何输入，并且不得访问任何外部资源。",
            "solution": "任务是实现一个自适应 Metropolis 随机游走马尔可夫链蒙特卡洛（MCMC）算法。该算法必须在预烧（burn-in）阶段调整其标量提议步长 $\\sigma$，以达到一个指定的目标接受率 $a^\\star$。该算法的理论基础——Metropolis-Hastings 接受准则和用于自适应的 Robbins-Monro 随机近似方法——必须从第一性原理推导。\n\n### 问题验证\n\n首先，我们验证问题陈述。\n\n#### 步骤 1：提取已知条件\n\n- **基本原理**:\n    - 细致平衡：$\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$。\n    - Metropolis-Hastings (M-H) 构建：转移核 $P(\\boldsymbol{x},\\boldsymbol{y})$ 由提议密度 $q(\\boldsymbol{y}\\mid \\boldsymbol{x})$ 和接受概率 $\\alpha(\\boldsymbol{x},\\boldsymbol{y})$ 构建。\n    - 随机近似：参数更新遵循一个方案，以递减的步长求解 $\\mathbb{E}[h(\\theta)] = 0$。\n\n- **任务**:\n    1.  从细致平衡推导对称高斯随机游走提议 $q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$ 的 M-H 接受概率。\n    2.  推导并实现一个 Robbins-Monro 更新，用于更新对数步长 $\\theta = \\log \\sigma$，以将接受率推向目标 $a^\\star$。更新必须使用增益 $\\gamma_n = c/(n+t_0)$ 并且仅限于预烧阶段。\n    3.  实现完整算法，在预烧后固定 $\\sigma$，并计算采样阶段的经验接受率。\n\n- **算法要求**:\n    - 提议：高斯随机游走 $\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n    - 自适应：仅在预烧期间，通过 Robbins-Monro 更新 $\\theta_n = \\log \\sigma_n$，增益为 $\\gamma_n = c/(n+t_0)$。\n    - 采样：预烧后固定 $\\sigma$。\n    - 目标接受率：所有测试均为 $a^\\star = 0.23$。\n\n- **测试用例**:\n    - **测试 A**: $d=1$，对数密度 $\\log \\pi(x) = -\\tfrac{1}{2} x^2$，$x_0 = 0$，$\\sigma_0 = 0.001$，$N_{\\mathrm{burn}} = 6000$，$N_{\\mathrm{sample}} = 12000$，种子 $42$。\n    - **测试 B**: $d=5$，$\\pi(\\boldsymbol{x}) \\propto \\exp(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x})$，其中 $\\Sigma_{ij} = \\rho^{|i-j|}$ 且 $\\rho = 0.8$，$\\boldsymbol{x}_0 = \\boldsymbol{0}$，$\\sigma_0 = 10$，$N_{\\mathrm{burn}} = 8000$，$N_{\\mathrm{sample}} = 12000$，种子 $123$。\n    - **测试 C**: $d=2$，$\\pi(\\boldsymbol{x}) \\propto \\exp(-U(x_1,x_2)/20)$ 其中 $U(x_1,x_2) = 100(x_2 - x_1^2)^2 + (1 - x_1)^2$，$\\boldsymbol{x}_0 = (0,0)$，$\\sigma_0 = 1$，$N_{\\mathrm{burn}} = 12000$，$N_{\\mathrm{sample}} = 12000$，种子 $2024$。\n\n- **输出规格**: 单行输出一个包含测试 A、B、C 三个接受率的列表，四舍五入到三位小数：$[\\text{r}_A,\\text{r}_B,\\text{r}_C]$。\n\n#### 步骤 2：使用提取的已知条件进行验证\n\n根据验证标准对问题进行审查。\n- **科学性**：该问题基于计算统计学和物理学中已确立的基本原理，即 MCMC 理论、细致平衡和随机近似。目标分布是该领域的标准基准。问题不含伪科学。\n- **良构性**：目标明确，每个测试用例的所有必要参数（维度、目标密度、初始条件、迭代次数、随机种子）均已指定。输出格式定义精确。在给定种子的情况下，问题是确定性的。预期会有一个唯一的、有意义的解。Robbins-Monro 常数 $c$ 和 $t_0$ 的选择留给实现者，这是一个标准的设计决策，而非缺陷。\n- **客观性**：语言技术性强、精确且无歧义。没有主观或基于观点的陈述。\n\n问题是自洽的、一致的且科学上合理的。未发现任何缺陷。\n\n#### 步骤 3：结论与行动\n\n问题有效。我们继续进行求解。\n\n### 推导与算法设计\n\n#### 1. Metropolis-Hastings 接受概率\n\n目标是构建一个具有平稳分布 $\\pi(\\boldsymbol{x})$ 的马尔可夫链。转移核 $P(\\boldsymbol{x}, \\boldsymbol{y})$ 给出了从状态 $\\boldsymbol{x}$ 移动到 $\\boldsymbol{y}$ 的概率密度，它必须满足细致平衡条件：\n$$\n\\pi(\\boldsymbol{x}) P(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y}, \\boldsymbol{x})\n$$\n在 Metropolis-Hastings 框架中，转移是一个两步过程：从一个提议密度 $q(\\boldsymbol{y} \\mid \\boldsymbol{x})$ 中提议一个新状态 $\\boldsymbol{y}$，然后以概率 $\\alpha(\\boldsymbol{x}, \\boldsymbol{y})$ 接受它。对于 $\\boldsymbol{x} \\neq \\boldsymbol{y}$，转移核为 $P(\\boldsymbol{x}, \\boldsymbol{y}) = q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y})$。将其代入细致平衡方程可得：\n$$\n\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y}) \\alpha(\\boldsymbol{y}, \\boldsymbol{x})\n$$\n这导出了对接受概率比值的以下约束：\n$$\n\\frac{\\alpha(\\boldsymbol{x}, \\boldsymbol{y})}{\\alpha(\\boldsymbol{y}, \\boldsymbol{x})} = \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\n$$\n满足此条件的标准 Metropolis 接受概率选择是：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\\right)\n$$\n问题指定了一个对称高斯随机游走提议：$\\boldsymbol{y} \\sim \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$。其提议密度为：\n$$\nq(\\boldsymbol{y} \\mid \\boldsymbol{x}) = \\frac{1}{(2\\pi\\sigma^2)^{d/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} (\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x})\\right)\n$$\n由于项 $(\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x}) = (\\boldsymbol{x}-\\boldsymbol{y})^\\top (\\boldsymbol{x}-\\boldsymbol{y})$，该提议是对称的，即 $q(\\boldsymbol{y} \\mid \\boldsymbol{x}) = q(\\boldsymbol{x} \\mid \\boldsymbol{y})$。接受率比值中的提议项相互抵消，得到简化的 Metropolis 接受概率：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y})}{\\pi(\\boldsymbol{x})}\\right)\n$$\n由于目标密度 $\\pi(\\boldsymbol{x})$ 通常只在相差一个归一化常数的情况下已知，我们使用未归一化的密度或更稳定地使用其对数来计算此比率：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x})\\right)\\right)\n$$\n这就是需要实现的公式。\n\n#### 2. 使用随机近似的自适应步长\n\n目标是调整提议步长 $\\sigma$，使得期望接受率与目标值 $a^\\star$ 相匹配。设待调参数为 $\\theta = \\log \\sigma$。更新在预烧阶段执行。我们希望找到函数 $g(\\theta) = \\mathbb{E}[\\alpha(\\theta)] - a^\\star$ 的根，其中 $\\alpha(\\theta)$ 是给定 $\\theta$ 时的接受概率。\n\nRobbins-Monro 算法是一种随机求根方法。对于函数 $g(\\theta)$，我们可以使用迭代方案 $\\theta_{n+1} = \\theta_n - \\gamma_n g_n(\\theta_n)$ 来找到它的根，其中 $g_n$ 是在步骤 $n$ 对 $g$ 的带噪声观测，而 $\\{\\gamma_n\\}$ 是满足 $\\sum \\gamma_n = \\infty$ 和 $\\sum \\gamma_n^2  \\infty$ 的步长序列。\n\n在我们的情况下，我们在第 $n$ 次迭代中观察接受概率 $\\alpha_n$，并将其用作我们的带噪声测量。用于引导观测接受率趋向 $a^\\star$ 的 $\\theta_n = \\log\\sigma_n$ 的更新规则公式如下：\n$$\n\\theta_{n+1} = \\theta_n + \\gamma_n (\\alpha_n - a^\\star)\n$$\n符号为正，因为如果当前接受率 $\\alpha_n$ 高于目标 $a^\\star$，我们需要增加 $\\theta$（从而增加 $\\sigma$）以使提议更大胆并降低接受率。反之，如果 $\\alpha_n  a^\\star$，我们减小 $\\theta$ 以使提议更保守并提高接受率。\n\n步长序列（增益）给定为 $\\gamma_n = c/(n + t_0)$，其中 $n \\geq 1$。我们将选择 $c=1.0$ 和 $t_0=10.0$ 作为合理的常数，以确保稳定性和有效的自适应。在对数尺度上更新 $\\theta = \\log\\sigma$ 自然能确保 $\\sigma = \\exp(\\theta)$ 保持为正。\n\n这种自适应方案使得马尔可夫链非齐次。为保证样本是从正确的平稳分布 $\\pi(\\boldsymbol{x})$ 中抽取的，自适应过程必须在预烧阶段之后终止。在 $N_{\\mathrm{burn}}$ 次迭代之后，步长 $\\sigma$ 被冻结在其最终的自适应值上，随后的 $N_{\\mathrm{sample}}$ 次迭代则作为标准的齐次 Metropolis MCMC 算法进行。马尔可夫链的遍历定理随后确保从这些样本计算的平均值收敛于关于 $\\pi(\\boldsymbol{x})$ 的期望值。\n\n### 实现计划\n\n该算法将在一个函数中实现，该函数接受测试用例的参数。对于从 $n=1$ 到 $N_{\\mathrm{burn}} + N_{\\mathrm{sample}}$ 的每次迭代：\n1.  生成一个提议 $\\boldsymbol{y} = \\boldsymbol{x}_{\\text{current}} + \\sigma_n \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n2.  计算 $\\alpha = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x}_{\\text{current}})\\right)\\right)$。\n3.  从 $U(0,1)$ 中抽取一个数 $u$。如果 $u  \\alpha$，则设置 $\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{y}$ 并记录一次接受。否则，设置 $\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{x}_{\\text{current}}$。\n4.  如果 $n \\le N_{\\mathrm{burn}}$：\n    - 使用 Robbins-Monro 步骤更新 $\\log \\sigma_n$：$\\log\\sigma_{n+1} = \\log\\sigma_n + \\gamma_n (\\alpha - a^\\star)$。\n    - 为增强鲁棒性，我们将把 $\\log\\sigma$ 裁剪到一个合理的范围，例如 $[-10, 10]$。\n5.  如果 $n  N_{\\mathrm{burn}}$：\n    - 保持 $\\sigma$ 固定。\n    - 统计接受次数，以计算采样阶段的最终经验接受率。\n\n此过程将使用指定的参数和随机种子应用于三个测试用例中的每一个。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def run_adaptive_mcmc(log_target_density, x0, sigma0, d, N_burn, N_sample, seed, a_star, c, t0):\n        \"\"\"\n        Runs the adaptive Metropolis MCMC algorithm for a single test case.\n\n        Args:\n            log_target_density (function): Function that computes the log of the target density.\n            x0 (np.ndarray): Initial position.\n            sigma0 (float): Initial proposal step size.\n            d (int): Dimension of the state space.\n            N_burn (int): Number of burn-in iterations.\n            N_sample (int): Number of sampling iterations.\n            seed (int): Random seed for reproducibility.\n            a_star (float): Target acceptance rate.\n            c (float): Parameter for the Robbins-Monro gain.\n            t0 (float): Parameter for the Robbins-Monro gain.\n        \n        Returns:\n            float: The empirical acceptance rate during the sampling phase.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        \n        x_current = np.array(x0, dtype=float)\n        log_sigma = np.log(sigma0)\n        \n        log_pi_current = log_target_density(x_current)\n        \n        accepted_in_sampling = 0\n        total_iterations = N_burn + N_sample\n\n        for n in range(1, total_iterations + 1):\n            sigma = np.exp(log_sigma)\n            \n            # 1. Propose a new state\n            proposal = x_current + sigma * rng.normal(size=d)\n            \n            # 2. Compute acceptance probability\n            log_pi_proposal = log_target_density(proposal)\n            log_alpha = log_pi_proposal - log_pi_current\n            alpha = min(1.0, np.exp(log_alpha))\n\n            # 3. Accept or reject the proposal\n            if rng.uniform()  alpha:\n                x_current = proposal\n                log_pi_current = log_pi_proposal\n                accepted = True\n            else:\n                accepted = False\n\n            # 4. Adaptation during burn-in\n            if n = N_burn:\n                gamma_n = c / (n + t0)\n                log_sigma = log_sigma + gamma_n * (alpha - a_star)\n                # For stability, constrain log_sigma to a broad interval\n                log_sigma = np.clip(log_sigma, -10.0, 10.0)\n            # 5. Tally acceptances during sampling\n            else:\n                if accepted:\n                    accepted_in_sampling += 1\n                    \n        return accepted_in_sampling / N_sample\n\n    # Common parameters\n    target_acceptance_rate = 0.23\n    # Robbins-Monro parameters (chosen based on common practice)\n    c_rm = 1.0\n    t0_rm = 10.0\n\n    # Test Case A: 1D Standard Gaussian\n    def log_pi_A(x):\n        return -0.5 * x[0]**2\n        \n    rate_A = run_adaptive_mcmc(\n        log_target_density=log_pi_A,\n        x0=[0.0],\n        sigma0=0.001,\n        d=1,\n        N_burn=6000,\n        N_sample=12000,\n        seed=42,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case B: 5D Correlated Gaussian\n    d_B = 5\n    rho_B = 0.8\n    sigma_matrix_B = np.array([[rho_B**abs(i - j) for j in range(d_B)] for i in range(d_B)])\n    sigma_inv_B = np.linalg.inv(sigma_matrix_B)\n    def log_pi_B(x):\n        return -0.5 * x @ sigma_inv_B @ x\n\n    rate_B = run_adaptive_mcmc(\n        log_target_density=log_pi_B,\n        x0=np.zeros(d_B),\n        sigma0=10.0,\n        d=d_B,\n        N_burn=8000,\n        N_sample=12000,\n        seed=123,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case C: 2D Softened Rosenbrock\n    def log_pi_C(x):\n        U = 100.0 * (x[1] - x[0]**2)**2 + (1.0 - x[0])**2\n        return -U / 20.0\n\n    rate_C = run_adaptive_mcmc(\n        log_target_density=log_pi_C,\n        x0=[0.0, 0.0],\n        sigma0=1.0,\n        d=2,\n        N_burn=12000,\n        N_sample=12000,\n        seed=2024,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    results = [rate_A, rate_B, rate_C]\n    \n    # Format the final output string exactly as specified.\n    results_str = ','.join(f\"{r:.3f}\" for r in results)\n    print(f\"[{results_str}]\")\n\nsolve()\n```"
        }
    ]
}