{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握迭代方法的收敛性，我们不仅要观察其收敛快慢，更要理解其为何会收敛缓慢甚至失败。这个实践将引导你扮演一个“破坏者”的角色，通过精心设计一个“恶意”的右侧向量 $b$，来揭示雅可比（Jacobi）法等简单迭代方法的内在弱点 。你将亲手构造一个能最大限度激发迭代矩阵“最慢”本征模式的输入，从而直观地看到收敛过程是如何因此而陷入停滞的。这个过程不仅是一个编程练习，更是对迭代法收敛本质的一次深刻洞察。",
            "id": "2382749",
            "problem": "考虑单位区间上具有齐次狄利克雷边界条件的一维拉普拉斯边值问题。在具有 $N$ 个内部节点的均匀网格上，使用标准的二阶中心有限差分格式进行离散化，得到的线性系统为 $A u = b$。其中，$A \\in \\mathbb{R}^{N \\times N}$ 是一个对称三对角矩阵，其元素为 $A_{i,i} = 2$，$A_{i,i+1} = -1$ 和 $A_{i,i-1} = -1$，对于 $i = 1, 2, \\dots, N$ 成立，并约定范围外的元素为零。\n\n您的任务是，对于每个指定的 $N$，构造一个右端向量 $b \\in \\mathbb{R}^{N}$，该向量是“恶意的”，因为它能在满足归一化约束 $\\|b\\|_{2} = 1$（欧几里得二范数等于 $1$）的条件下，使得从零初始向量开始的经典雅可比方法为满足给定的停止准则所需迭代次数最大化。对于每个测试用例，使用雅可比方法从 $u^{(0)} = 0$ 开始求解 $A u = b$，并报告首次满足指定停止准则时的最小迭代次数 $k$，或者如果在该次数内未满足，则报告一个固定的上限值。\n\n使用的停止准则如下，每个准则都采用欧几里得二范数 $\\|\\cdot\\|_{2}$：\n- 绝对残差准则：在满足 $\\|A u^{(k)} - b\\|_{2} \\le \\tau$ 的最小迭代次数 $k$ 处停止，其中 $\\tau$ 是给定的容差。\n- 相对残差准则：在满足 $\\|A u^{(k)} - b\\|_{2} / \\|b\\|_{2} \\le \\tau$ 的最小迭代次数 $k$ 处停止。\n- 连续迭代差分准则：在满足 $\\|u^{(k)} - u^{(k-1)}\\|_{2} \\le \\tau$ 的最小迭代次数 $k \\ge 1$ 处停止。\n\n对于所有测试用例，将最大迭代次数设置为 $k_{\\max} = 200000$。如果在第 $k_{\\max}$ 次迭代时仍未满足指定的停止准则，您必须为该测试用例返回 $k_{\\max}$。不涉及任何物理单位。如果在您的构造中出现角度，必须以弧度为单位处理。所有计算都应在实数算术中执行。\n\n测试套件。对于下面的每个元组 $(N, \\text{criterion}, \\tau)$，构造一个满足 $\\|b\\|_{2} = 1$ 的“恶意”向量 $b$，使用指定的停止准则和容差 $\\tau$，从 $u^{(0)} = 0$ 开始运行雅可比方法，并记录停止时的整数迭代次数（如果未达到则为 $k_{\\max}$）：\n1. $(N = 31, \\text{绝对残差}, \\tau = 10^{-8})$\n2. $(N = 4, \\text{相对残差}, \\tau = 10^{-8})$\n3. $(N = 17, \\text{绝对残差}, \\tau = 10^{-12})$\n4. $(N = 63, \\text{连续迭代差分}, \\tau = 10^{-10})$\n5. $(N = 5, \\text{绝对残差}, \\tau = 10^{-4})$\n6. $(N = 63, \\text{相对残差}, \\tau = 10^{-6})$\n\n最终输出格式。您的程序应生成单行输出，其中包含按上述测试套件顺序排列的六个整数结果，形式为用方括号括起来的逗号分隔列表（例如，$ [r_{1},r_{2},r_{3},r_{4},r_{5},r_{6}]$），其中每个 $r_{j}$ 是第 $j$ 个测试用例的整数迭代次数。",
            "solution": "该问题要求确定雅可比方法在旨在最大化迭代次数的特定“恶意”条件下求解线性系统 $A u = b$ 所需的迭代次数。该系统源于一维拉普拉斯方程的有限差分化。\n\n首先，我们必须验证问题陈述。该问题是数值线性代数中一个定义明确的练习，特别关注迭代方法的收敛性质。它具有科学依据、客观性，并包含了继续进行所需的所有必要信息。矩阵 $A$ 是标准的二阶离散拉普拉斯算子，它是对称正定的。雅可比方法是一种经典的迭代求解器。“恶意”向量的概念被赋予了精确的含义：一个单位范数 $\\|b\\|_2 = 1$ 的向量 $b$，它能使迭代次数最大化。该问题是有效的。\n\n问题的核心在于构造“恶意”向量 $b$。雅可比方法的收敛性由其迭代矩阵的谱性质决定。系统 $A u = b$ 的雅可比迭代由 $u^{(k+1)} = T_J u^{(k)} + D^{-1}b$ 给出，其中 $A = D - L - U$ 是将 $A$ 分解为其对角部分 ($D$)、严格下三角部分 ($-L$) 和严格上三角部分 ($-U$)，而 $T_J = D^{-1}(L+U)$ 是雅可比迭代矩阵。\n\n对于给定的矩阵 $A$，我们有 $A_{i,i} = 2$ 和 $A_{i,i \\pm 1} = -1$。因此，$D = 2I$，其中 $I$ 是单位矩阵。迭代矩阵为 $T_J = \\frac{1}{2}(L+U) = I - \\frac{1}{2}A$。由于 $T_J$ 是 $A$ 的多项式，它们共享相同的特征向量。这个特定矩阵 $A$ 的特征值和特征向量是众所周知的。特征值为\n$$ \\lambda_j(A) = 2 - 2\\cos\\left(\\frac{j\\pi}{N+1}\\right) = 4\\sin^2\\left(\\frac{j\\pi}{2(N+1)}\\right) \\quad \\text{for } j = 1, \\dots, N $$\n对应的特征向量 $v_j$ 的分量为 $(v_j)_i = \\sin\\left(\\frac{ij\\pi}{N+1}\\right)$，其中 $i=1, \\dots, N$。因此，雅可比矩阵 $T_J$ 的特征值为\n$$ \\mu_j = 1 - \\frac{1}{2}\\lambda_j(A) = \\cos\\left(\\frac{j\\pi}{N+1}\\right) \\quad \\text{for } j = 1, \\dots, N $$\n雅可比方法的渐进收敛率由 $T_J$ 的谱半径决定，即 $\\rho(T_J) = \\max_j |\\mu_j|$。由于 $\\cos(x)$ 在 $[0, \\pi]$ 上是递减函数，最大绝对值在 $j=1$ 和 $j=N$ 时取得：\n$$ \\rho(T_J) = |\\mu_N| = \\left|\\cos\\left(\\frac{N\\pi}{N+1}\\right)\\right| = \\left|-\\cos\\left(\\frac{\\pi}{N+1}\\right)\\right| = \\cos\\left(\\frac{\\pi}{N+1}\\right) = \\mu_1 $$\n当误差分量与对应于这些特征值的特征向量对齐时，收敛最慢，即 $v_1$（最平滑的特征向量）和 $v_N$（振荡最剧烈的特征向量）。\n\n第 $k$ 次迭代的误差为 $e^{(k)} = u^{(k)} - u^*$，其中 $u^*=A^{-1}b$ 是精确解。误差演化为 $e^{(k)} = T_J^k e^{(0)}$。对于初始猜测 $u^{(0)}=0$，初始误差为 $e^{(0)} = -u^* = -A^{-1}b$。为了最大化满足停止准则所需的迭代次数，我们必须选择 $b$ 以使误差 $e^{(k)}$ 尽可能长时间保持较大。这可以通过将初始误差（也就是 $b$）与对应于谱半径大小 $\\rho(T_J)$ 的特征值的特征向量对齐来实现。\n\n我们选择“恶意”向量 $b$ 为对应于 $\\mu_1$ 的归一化特征向量，记为 $q_1$。$b$ 的分量由下式给出：\n$$ b_i = \\sqrt{\\frac{2}{N+1}} \\sin\\left(\\frac{i\\pi}{N+1}\\right) \\quad \\text{for } i = 1, \\dots, N $$\n这个选择确保了 $\\|b\\|_2 = 1$。\n\n现在，我们分析对于 $b=q_1$ 这个选择的停止准则。\n第 $k$ 次迭代的残差向量是 $r^{(k)} = A u^{(k)} - b$。一个有用的关系是 $r^{(k+1)} = T_J r^{(k)}$，这意味着 $r^{(k)} = (T_J)^k r^{(0)}$。当 $u^{(0)}=0$ 时，$r^{(0)}=-b=-q_1$。由于 $q_1$ 是 $T_J$ 的一个特征向量，我们有：\n$$ r^{(k)} = (T_J)^k (-q_1) = -\\mu_1^k q_1 $$\n1.  **绝对/相对残差准则**：残差的范数为 $\\|r^{(k)}\\|_2 = |\\mu_1|^k \\|q_1\\|_2 = (\\rho(T_J))^k$。由于 $\\|b\\|_2=1$，绝对和相对残差准则相同：$\\|A u^{(k)} - b\\|_2 \\le \\tau$。这可以简化为 $(\\rho(T_J))^k \\le \\tau$。迭代次数 $k$ 是满足此不等式的最小整数。\n\n2.  **连续迭代差分准则**：连续迭代之间的差是 $u^{(k)} - u^{(k-1)}$。我们有 $u^{(k)} = (I + T_J + \\dots + T_J^{k-1})D^{-1}b$。对于 $b=q_1$，$u^{(k)} = (\\sum_{i=0}^{k-1} \\mu_1^i) \\frac{1}{2}q_1 = \\frac{1-\\mu_1^k}{1-\\mu_1} \\frac{1}{2}q_1 = \\frac{1-\\mu_1^k}{\\lambda_1}q_1$。\n    那么，$u^{(k)} - u^{(k-1)} = \\left(\\frac{1-\\mu_1^k}{\\lambda_1} - \\frac{1-\\mu_1^{k-1}}{\\lambda_1}\\right)q_1 = \\frac{\\mu_1^{k-1}-\\mu_1^k}{\\lambda_1}q_1 = \\frac{\\mu_1^{k-1}(1-\\mu_1)}{\\lambda_1}q_1$。\n    其范数为 $\\|u^{(k)} - u^{(k-1)}\\|_2 = \\frac{|\\mu_1|^{k-1}|1-\\mu_1|}{\\lambda_1}$。由于 $\\lambda_1 = 2(1-\\mu_1)$，这简化为 $\\frac{|\\mu_1|^{k-1}}{2} = \\frac{(\\rho(T_J))^{k-1}}{2}$。准则 $\\|u^{(k)} - u^{(k-1)}\\|_2 \\le \\tau$ 变为 $\\frac{(\\rho(T_J))^{k-1}}{2} \\le \\tau$。迭代次数 $k$ 是满足此条件的最小整数 $\\ge 1$。\n\n算法如下：对于每个测试用例 $(N, \\text{criterion}, \\tau)$，为给定的 $N$ 构造恶意向量 $b$。然后，从 $u^{(0)}=0$ 开始应用雅可比迭代。在每一步 $k$，计算 $u^{(k)}$ 并检查是否满足指定的停止准则。第一个满足准则的 $k$ 就是结果。如果到 $k = k_{\\max} = 200000$ 时仍未满足准则，则结果为 $k_{\\max}$。",
            "answer": "```python\nimport numpy as np\n\ndef solve_case(N, criterion, tau):\n    \"\"\"\n    Solves a single test case for the Jacobi iteration problem.\n\n    Args:\n        N (int): The number of interior grid points.\n        criterion (str): The stopping criterion ('absolute residual', \n                         'relative residual', or 'successive iterate difference').\n        tau (float): The tolerance for the stopping criterion.\n\n    Returns:\n        int: The number of iterations required for convergence, or k_max.\n    \"\"\"\n    k_max = 200000\n\n    # Construct the malicious vector b, which is the normalized eigenvector\n    # corresponding to the smallest eigenvalue of A (smoothest mode).\n    # This corresponds to the largest eigenvalue of the Jacobi iteration matrix T_J.\n    # The components are b_i = C * sin(i * pi / (N + 1)).\n    # The normalization constant C is sqrt(2 / (N + 1)).\n    C = np.sqrt(2.0 / (N + 1.0))\n    indices = np.arange(1, N + 1, dtype=np.float64)\n    b = C * np.sin(indices * np.pi / (N + 1.0))\n\n    # Initialize the Jacobi iteration\n    u_k = np.zeros(N, dtype=np.float64)\n    u_prev = np.zeros(N, dtype=np.float64)\n\n    # Pre-construct matrix A for residual calculation\n    if 'residual' in criterion:\n        A = np.diag(np.full(N, 2.0, dtype=np.float64)) + \\\n            np.diag(np.full(N - 1, -1.0, dtype=np.float64), k=1) + \\\n            np.diag(np.full(N - 1, -1.0, dtype=np.float64), k=-1)\n    \n    # Jacobi iteration loop\n    for k in range(1, k_max + 1):\n        if criterion == 'successive iterate difference':\n            u_prev = u_k\n\n        # Perform one Jacobi step: u_new_i = 0.5 * (u_{i-1} + u_{i+1} + b_i)\n        # Vectorized implementation for efficiency.\n        u_new = np.zeros(N, dtype=np.float64)\n        # Interior points\n        if N > 1:\n            u_new[1:-1] = 0.5 * (u_k[:-2] + u_k[2:] + b[1:-1])\n            # Boundary points (u_0 = u_{N+1} = 0)\n            u_new[0] = 0.5 * (u_k[1] + b[0])\n            u_new[-1] = 0.5 * (u_k[-2] + b[-1])\n        elif N == 1:\n            u_new[0] = 0.5 * b[0]\n            \n        u_k = u_new\n\n        # Check stopping criterion\n        stop = False\n        if criterion in ('absolute residual', 'relative residual'):\n            # For relative residual, ||b||_2 = 1, so it is the same as absolute.\n            residual_norm = np.linalg.norm(A @ u_k - b)\n            if residual_norm = tau:\n                stop = True\n        elif criterion == 'successive iterate difference':\n            diff_norm = np.linalg.norm(u_k - u_prev)\n            if diff_norm = tau:\n                stop = True\n        \n        if stop:\n            return k\n\n    return k_max\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (31, 'absolute residual', 1e-8),\n        (4, 'relative residual', 1e-8),\n        (17, 'absolute residual', 1e-12),\n        (63, 'successive iterate difference', 1e-10),\n        (5, 'absolute residual', 1e-4),\n        (63, 'relative residual', 1e-6),\n    ]\n\n    results = []\n    for N, criterion, tau in test_cases:\n        iteration_count = solve_case(N, criterion, tau)\n        results.append(iteration_count)\n\n    # Format and print the final output as a single line\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在我们理解了迭代矩阵的谱（即其本征值分布）是决定收敛速度的关键之后，下一个自然的问题就是：我们能否量化这种关系？这个实践将我们从简单的定常迭代法带入更强大的共轭梯度（CG）方法的世界，并架起理论与实践之间的桥梁 。你将通过数值实验来验证一个经典的CG收敛理论上界，该上界将收敛速度与系统矩阵的谱条件数 $\\kappa$ 直接联系起来。通过这种方式，一个抽象的数学公式将转化为一个你可以在计算机上直接观察和验证的具体现象。",
            "id": "2382433",
            "problem": "考虑一个实对称正定矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其谱条件数为 $\\kappa = \\lambda_{\\max}(A)/\\lambda_{\\min}(A)$，其中 $\\lambda_{\\max}(A)$ 和 $\\lambda_{\\min}(A)$ 分别是 $A$ 在谱（欧几里得 $2$-范数）意义下的最大和最小特征值。令 $x^\\star$ 表示线性系统 $A x = b$ 的唯一解。从初始猜测 $x_0 = 0$ 开始，通过共轭梯度（CG）法生成迭代序列 $x_k$（共轭梯度法定义为求解实对称正定系统的标准Krylov子空间方法）。对于每个迭代索引 $k \\ge 0$，定义误差 $e_k = x_k - x^\\star$ 和 $A$-范数 $\\|v\\|_A = \\sqrt{v^\\top A v}$。一个经典的理论界表明，对于所有 $k \\ge 0$，以下不等式成立：\n$$\n\\|e_k\\|_A \\le 2 \\left(\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\\right)^k \\|e_0\\|_A.\n$$\n您的任务是对于按如下方式构造的、具有已知条件数 $\\kappa$ 的矩阵 $A$，数值验证此界。对于给定的维度 $n$ 和目标条件数 $\\kappa  1$，通过对一个具有独立标准正态分布元素的实矩阵进行QR分解，取其 $Q$ 因子来生成一个正交矩阵 $Q \\in \\mathbb{R}^{n \\times n}$。然后构造一个对角矩阵 $\\Lambda = \\mathrm{diag}(\\lambda_1,\\dots,\\lambda_n)$，其特征值在 $\\lambda_{\\min} = 1$ 和 $\\lambda_{\\max} = \\kappa$ 之间呈几何级数分布，即 $(\\lambda_i)$ 构成从 $1$ 到 $\\kappa$ 的等比数列。定义 $A = Q^\\top \\Lambda Q$，该矩阵是实对称正定矩阵，其谱条件数恰好为 $\\kappa$。对于每个测试用例，生成一个具有独立标准正态分布元素的 $x^\\star \\in \\mathbb{R}^n$，设置 $b = A x^\\star$，并使用 $x_0 = 0$。对于迭代过程的数值收敛，采用基于残差 $r_k = b - A x_k$ 的欧几里得 $2$-范数的停止准则：如果 $\\|r_k\\|_2 \\le \\tau_{\\mathrm{rel}} \\|r_0\\|_2$，则提前停止，其中 $\\tau_{\\mathrm{rel}} = 10^{-12}$。\n\n带浮点容差的验证准则：对于每个测试用例，如果在停止前实际执行的每个迭代索引 $k \\in \\{1,2,\\dots,k_{\\max}\\}$，不等式\n$$\n\\|e_k\\|_A \\le 2 \\left(\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\\right)^k \\|e_0\\|_A\n$$\n在数值容差\n$$\n\\|e_k\\|_A \\le \\left[2 \\left(\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\\right)^k \\|e_0\\|_A\\right] \\cdot (1 + \\varepsilon_{\\mathrm{rel}}) + \\varepsilon_{\\mathrm{abs}},\n$$\n范围内成立，则宣告成功，其中 $\\varepsilon_{\\mathrm{rel}} = 10^{-8}$ 且 $\\varepsilon_{\\mathrm{abs}} = 10^{-12}$。\n\n您的程序要使用的测试套件：\n- 测试 1：$n = 50$，$\\kappa = 10$，$k_{\\max} = 20$，随机种子 $= 0$。\n- 测试 2：$n = 80$，$\\kappa = 1000$，$k_{\\max} = 30$，随机种子 $= 1$。\n- 测试 3：$n = 60$，$\\kappa = 1.5$，$k_{\\max} = 10$，随机种子 $= 2$。\n- 测试 4：$n = 30$，$\\kappa = 100000$，$k_{\\max} = 25$，随机种子 $= 3$。\n\n您的程序必须为每个测试用例，使用指定的随机种子，完全按照规定构造 $A$ 和 $x^\\star$，从 $x_0 = 0$ 开始计算迭代解 $x_k$，并为每个测试用例输出一个布尔值，该值指示在所有已执行的迭代 $k \\in \\{1,2,\\dots,k_{\\max}\\}$（或直到因残差准则而提前停止）中，该界是否在指定容差内成立。最终输出必须是包含这些布尔值的单行Python风格列表，按测试顺序排列且无空格，例如 $[{\\tt True},{\\tt False},{\\tt True},{\\tt True}]$。",
            "solution": "问题陈述已经过验证，并被认定为有效。它在科学上是合理的、适定的和客观的。它清晰、自洽地描述了计算物理和数值线性代数领域中的一个标准数值验证任务。所有参数、程序和准则都得到了明确的定义。因此，我将继续提供解决方案。\n\n任务是数值验证共轭梯度（CG）法的一个经典收敛界。解决方案包括三个主要阶段：首先，构建具有指定属性的测试系统（$A$、$x^\\star$、$b$）；其次，实现CG算法以生成迭代序列；第三，在迭代的每一步将计算出的误差与理论误差界进行核对。\n\n**1. 测试系统的构建**\n\n一个鲁棒的验证需要一个测试矩阵 $A$，其谱条件数 $\\kappa$ 是精确已知的，因为它是收敛界中的一个关键参数。指定的构建过程确保了这一点。\n\n对于给定的维度 $n$ 和条件数 $\\kappa  1$：\n- 生成一个正交矩阵 $Q \\in \\mathbb{R}^{n \\times n}$。这是通过对一个矩阵 $M \\in \\mathbb{R}^{n \\times n}$ 进行QR分解（$M=QR$）来完成的，该矩阵的元素从独立同分布的标准正态分布 $\\mathcal{N}(0, 1)$ 中抽取。矩阵 $Q$ 满足 $Q^\\top Q = QQ^\\top = I$，其中 $I$ 是单位矩阵。\n- 构造一个对角矩阵 $\\Lambda = \\mathrm{diag}(\\lambda_1, \\dots, \\lambda_n)$。其对角线元素，即特征值，被选择为正数并覆盖所需范围。它们在 $\\lambda_{\\min} = 1$ 和 $\\lambda_{\\max} = \\kappa$ 之间按几何级数分布。特征值由以下公式给出：\n$$\n\\lambda_i = \\kappa^{\\frac{i-1}{n-1}} \\quad \\text{for } i = 1, 2, \\dots, n.\n$$\n这种选择确保了最小特征值为 $1$，最大特征值为 $\\kappa$。\n- 最终的矩阵 $A$ 通过相似变换形成：\n$$\nA = Q^\\top \\Lambda Q.\n$$\n这种构造保证了 $A$ 具有所需的性质：\n- **对称性**：$A^\\top = (Q^\\top \\Lambda Q)^\\top = Q^\\top \\Lambda^\\top (Q^\\top)^\\top = Q^\\top \\Lambda Q = A$，因为 $\\Lambda$ 是对角矩阵，因此是对称的。\n- **正定性**：$A$ 的特征值与 $\\Lambda$ 的特征值相同，而 $\\Lambda$ 的特征值都是正的（因为 $\\kappa  1$）。所有特征值均为正的对称矩阵是正定矩阵。\n- **条件数**：谱条件数为 $\\kappa(A) = \\frac{\\lambda_{\\max}(A)}{\\lambda_{\\min}(A)} = \\frac{\\kappa}{1} = \\kappa$，符合要求。\n\n定义了矩阵 $A$ 之后，生成真实解向量 $x^\\star \\in \\mathbb{R}^n$，其元素来自 $\\mathcal{N}(0, 1)$，然后计算右侧向量 $b = Ax^\\star$。这就建立了一个已知其精确解的线性系统 $Ax=b$。\n\n**2. 共轭梯度算法**\n\nCG方法是求解系统 $Ax=b$ 的一种迭代算法，其中 $A$ 是对称正定的。为了在每一步验证收敛界，我们必须显式地实现该算法，而不是使用黑盒库函数。给定初始猜测 $x_0 = 0$，算法流程如下：\n\n- **初始化**：\n  - $x_0 = 0$\n  - 残差：$r_0 = b - A x_0 = b$\n  - 搜索方向：$p_0 = r_0$\n\n- **迭代循环**：对于 $k = 0, 1, 2, \\dots$，直到收敛或达到最大迭代次数：\n  1. 计算步长：$\\alpha_k = \\frac{r_k^\\top r_k}{p_k^\\top A p_k}$\n  2. 更新解：$x_{k+1} = x_k + \\alpha_k p_k$\n  3. 更新残差：$r_{k+1} = r_k - \\alpha_k A p_k$\n  4. 检查停止准则（见下文）。\n  5. 改进搜索方向：$\\beta_k = \\frac{r_{k+1}^\\top r_{k+1}}{r_k^\\top r_k}$\n  6. 更新搜索方向：$p_{k+1} = r_{k+1} + \\beta_k p_k$\n\n这个迭代过程生成一个收敛于 $x^\\star$ 的近似解序列 $x_1, x_2, \\dots$。\n\n**3. 数值验证协议**\n\n此任务的核心是检验经典CG收敛界对于误差 $e_k = x_k - x^\\star$ 的 $A$-范数的有效性。该界为：\n$$\n\\|e_k\\|_A \\le 2 \\left(\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\\right)^k \\|e_0\\|_A\n$$\n其中 $\\|v\\|_A = \\sqrt{v^\\top A v}$，初始误差为 $e_0 = x_0 - x^\\star = -x^\\star$。\n\n验证过程对CG算法生成的每个迭代解进行，从 $k=1$ 开始，直到达到最大迭代次数 $k_{\\max}$ 或迭代提前停止。每个测试用例的协议如下：\n\n1.  用 $x_0 = 0$ 初始化CG算法。计算初始误差 $e_0 = -x^\\star$ 及其 $A$-范数 $\\|e_0\\|_A$。\n2.  设置基于残差的停止阈值：$\\|r_k\\|_2 \\le \\tau_{\\mathrm{rel}} \\|r_0\\|_2$，其中 $\\tau_{\\mathrm{rel}} = 10^{-12}$。\n3.  开始CG迭代循环， $k=1, 2, \\dots, k_{\\max}$。\n4.  在每次迭代 $k$ 中，计算出 $x_k$ 后：\n    a. 计算真实误差 $e_k = x_k - x^\\star$ 及其 $A$-范数 $\\|e_k\\|_A$。\n    b. 计算本次迭代的理论上界： $B_k = 2 \\left(\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\\right)^k \\|e_0\\|_A$。\n    c. 检查计算出的误差是否在指定的浮点容差内满足不等式：\n       $$\n       \\|e_k\\|_A \\le B_k \\cdot (1 + \\varepsilon_{\\mathrm{rel}}) + \\varepsilon_{\\mathrm{abs}}\n       $$\n       其中 $\\varepsilon_{\\mathrm{rel}} = 10^{-8}$ 且 $\\varepsilon_{\\mathrm{abs}} = 10^{-12}$。如果此条件被违反，则该测试用例失败，我们继续进行下一个测试用例。\n    d. 基于残差的 $L_2$-范数 $\\|r_k\\|_2$ 检查CG停止准则。如果满足条件，则此测试用例的迭代成功终止。\n5.  如果循环完成（无论是达到 $k_{\\max}$ 还是提前停止）而没有任何违反界限的情况，则该测试用例被宣告成功。\n\n为问题套件中指定的每个测试用例记录一个布尔结果（$True$ 或 $False$）。最终输出将这些结果汇总到一个列表中。",
            "answer": "```python\nimport numpy as np\n\ndef run_test(n, kappa, k_max, seed):\n    \"\"\"\n    Runs a single test case for verifying the Conjugate Gradient error bound.\n    \n    Args:\n        n (int): Dimension of the matrix.\n        kappa (float): Condition number of the matrix.\n        k_max (int): Maximum number of iterations.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        bool: True if the bound holds for all iterations, False otherwise.\n    \"\"\"\n    # Set seed for reproducibility\n    np.random.seed(seed)\n\n    # Tolerances from the problem statement\n    tau_rel = 1e-12\n    eps_rel = 1e-8\n    eps_abs = 1e-12\n    \n    # 1. Construct the matrix A\n    M = np.random.randn(n, n)\n    Q, _ = np.linalg.qr(M)\n    eigenvalues = np.geomspace(1.0, float(kappa), num=n)\n    Lambda = np.diag(eigenvalues)\n    A = Q.T @ Lambda @ Q\n\n    # 2. Set up the linear system Ax = b\n    x_star = np.random.randn(n)\n    b = A @ x_star\n\n    # 3. Initialize the Conjugate Gradient algorithm\n    x_k = np.zeros(n)\n    r_k = b - A @ x_k  # This is equal to b since x_k is zero\n    p_k = r_k\n    \n    rs_k_sq = r_k.dot(r_k)\n\n    # 4. Calculate initial values needed for the bound verification\n    e_0 = x_k - x_star  # Equal to -x_star\n    norm_e0_A = np.sqrt(e_0.T @ A @ e_0)\n    \n    norm_r0_2 = np.linalg.norm(r_k)\n    stop_threshold = tau_rel * norm_r0_2\n\n    # Pre-calculate the convergence factor rho\n    sqrt_kappa = np.sqrt(float(kappa))\n    rho = (sqrt_kappa - 1.0) / (sqrt_kappa + 1.0)\n\n    # 5. Iteration and Verification Loop\n    is_valid = True\n    for k_iter in range(1, k_max + 1):\n        # --- Standard CG step ---\n        Ap_k = A @ p_k\n        alpha_k = rs_k_sq / p_k.dot(Ap_k)\n        \n        x_k = x_k + alpha_k * p_k\n        r_k = r_k - alpha_k * Ap_k\n        \n        # --- Verification for the current iterate k_iter ---\n        e_k = x_k - x_star\n        norm_ek_A = np.sqrt(e_k.T @ A @ e_k)\n        \n        # Theoretical bound for this iteration\n        bound = 2.0 * (rho ** k_iter) * norm_e0_A\n        \n        # Check if the computed error respects the bound within tolerance\n        if not (norm_ek_A = bound * (1.0 + eps_rel) + eps_abs):\n            is_valid = False\n            break\n\n        # --- Check for early stopping based on residual norm ---\n        if np.linalg.norm(r_k) = stop_threshold:\n            break\n            \n        # --- Prepare for the next CG iteration ---\n        rs_k_plus_1_sq = r_k.dot(r_k)\n        beta_k = rs_k_plus_1_sq / rs_k_sq\n        p_k = r_k + beta_k * p_k\n        \n        rs_k_sq = rs_k_plus_1_sq\n        \n    return is_valid\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (50, 10, 20, 0),\n        (80, 1000, 30, 1),\n        (60, 1.5, 10, 2),\n        (30, 100000, 25, 3),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, kappa, k_max, seed = case\n        result = run_test(n, kappa, k_max, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "通过前面的实践，我们已经认识到误差的不同频率成分（或说本征模式）会被迭代法以不同的速率衰减。现在，我们将利用这一理解来设计一个更智能、更高效的混合求解器 。这个最终的实践练习体现了许多现代高性能算法（如多重网格法）的核心思想：为不同的任务选择合适的工具。我们将把一个简单的加权雅可比法作为“平滑器”，用以快速消除误差中的高频成分，然后切换到共轭梯度法，以高效地处理剩余的低频（光滑）误差。而决定何时切换的依据，正是对残差谱成分的直接分析，这完美地展示了如何将深刻的理论理解转化为卓越的算法设计。",
            "id": "2382818",
            "problem": "考虑单位区间上的一个一维泊松方程，其带有齐次狄利克雷边界条件，对应的线性边值问题为：寻找一个离散向量 $x \\in \\mathbb{R}^N$ 使得 $A x = b$ 成立。其中，$A \\in \\mathbb{R}^{N \\times N}$ 是在 $[0,1]$ 区间上对负拉普拉斯算子的标准二阶中心有限差分离散化，该离散化有 $N$ 个内部网格点，网格间距为 $h = \\frac{1}{N+1}$。矩阵 $A$ 的对角线元素为 $2/h^2$，次对角线和超对角线元素为 $-1/h^2$。向量 $b \\in \\mathbb{R}^N$ 通过在内部网格点 $x_i = i h$（$i = 1,2,\\dots,N$）上对给定函数 $f(x)$ 采样来定义。三角函数中的角度应以弧度为单位。\n\n将第 $k$ 次迭代的残差定义为 $r_k = b - A x_k$，其中 $x_k$ 是一个迭代解。令 $\\mathrm{DST}_1$ 表示在 $\\mathbb{R}^N$ 上的I型离散正弦变换（DST），它将 $r_k$ 映射到系数 $R^{(k)}_m$（$m = 1,2,\\dots,N$），这些系数对应于正交正弦基 $\\sin\\!\\left(\\frac{\\pi m j}{N+1}\\right)$，变换结果与真实系数相差一个固定的归一化因子。对于给定的高频截止参数 $\\alpha \\in (0,1)$，定义截止索引 $m_c = \\lceil \\alpha N \\rceil$，以及残差的高频能量比\n$$\n\\rho_k = \\frac{\\sum_{m=m_c}^{N} \\left(R^{(k)}_m\\right)^2}{\\sum_{m=1}^{N} \\left(R^{(k)}_m\\right)^2},\n$$\n约定当分母为零时 $\\rho_k = 0$。\n\n实现一个两阶段迭代求解器，该求解器具有基于残差频谱内容的自适应切换准则：\n- 阶段1（平滑阶段）：使用权重为 $\\omega \\in (0,1)$ 的加权雅可比迭代，\n$$\nx_{k+1} = x_k + \\omega D^{-1} (b - A x_k),\n$$\n其中 $D$ 是 $A$ 的对角部分（因此 $D = \\frac{2}{h^2} I$），从初始猜测 $x_0 = 0$ 开始。每次迭代后（包括 $k=0$ 时），计算如上定义的 $\\rho_k$。当 $\\rho_k \\le \\tau$ 首次满足时（其中 $\\tau  0$ 是一个预设的容差），或达到预设的阶段1最大迭代次数 $K_1^{\\max}$ 时，停止阶段1，以先发生者为准。记 $k_{\\mathrm{switch}}$ 为实际执行的阶段1迭代次数（如果 $k=0$ 时条件已满足，则 $k_{\\mathrm{switch}} = 0$ 是允许的），并记录 $\\rho_{k_{\\mathrm{switch}}}$。\n- 阶段2（粗糙误差校正阶段）：从 $x_{k_{\\mathrm{switch}}}$ 开始，对 $A x = b$ 应用针对对称正定系统的共轭梯度（CG）方法，直到欧几里得范数满足 $\\lVert r_k \\rVert_2 \\le \\varepsilon$（其中 $\\varepsilon  0$ 是一个预设的容差），或达到阶段2的最大迭代次数 $K_2^{\\max}$，以先发生者为准。CG方法由标准递推关系定义：设 $x^{(0)} = x_{k_{\\mathrm{switch}}}$，$r^{(0)} = b - A x^{(0)}$，$p^{(0)} = r^{(0)}$，且对于 $\\ell = 0,1,2,\\dots$，\n$$\n\\alpha_\\ell = \\frac{\\left(r^{(\\ell)}\\right)^\\top r^{(\\ell)}}{\\left(p^{(\\ell)}\\right)^\\top A p^{(\\ell)}}, \\quad\nx^{(\\ell+1)} = x^{(\\ell)} + \\alpha_\\ell p^{(\\ell)}, \\quad\nr^{(\\ell+1)} = r^{(\\ell)} - \\alpha_\\ell A p^{(\\ell)},\n$$\n$$\n\\beta_\\ell = \\frac{\\left(r^{(\\ell+1)}\\right)^\\top r^{(\\ell+1)}}{\\left(r^{(\\ell)}\\right)^\\top r^{(\\ell)}}, \\quad\np^{(\\ell+1)} = r^{(\\ell+1)} + \\beta_\\ell p^{(\\ell)}.\n$$\n令 $k_{\\mathrm{CG}}$ 为实际执行的阶段2迭代次数。报告总迭代次数 $k_{\\mathrm{total}} = k_{\\mathrm{switch}} + k_{\\mathrm{CG}}$ 和终止时的最终残差范数 $\\lVert r_{\\mathrm{final}} \\rVert_2$。\n\n测试套件。对于下方的每个测试用例，程序必须为指定的 $N$ 构建矩阵 $A$（其中 $h = \\frac{1}{N+1}$），设置 $x_0 = 0$，在 $x_i = i h$（$i=1,2,\\dots,N$）处构建 $b_i = f(x_i)$，然后使用给定的参数执行上述两阶段过程。函数 $f(x)$ 如下：\n- $f_1(x) = \\sin(2 \\pi x) + 0.1 \\sin(16 \\pi x)$,\n- $f_2(x) = \\sin(\\pi x)$,\n- $f_3(x) = \\sum_{k=12}^{24} \\frac{1}{k} \\sin(k \\pi x)$,\n- $f_4(x) = \\sin(8 \\pi x) + 0.5 \\sin(20 \\pi x)$.\n\n四个测试用例如下：\n1. $N = 63$，$\\omega = \\tfrac{2}{3}$，$\\alpha = 0.5$，$\\tau = 10^{-3}$，$\\varepsilon = 10^{-10}$，$K_1^{\\max} = 100$，$K_2^{\\max} = 63$，$f = f_1$。\n2. $N = 63$，$\\omega = \\tfrac{2}{3}$，$\\alpha = 0.5$，$\\tau = 10^{-6}$，$\\varepsilon = 10^{-10}$，$K_1^{\\max} = 5$，$K_2^{\\max} = 63$，$f = f_2$。\n3. $N = 127$，$\\omega = \\tfrac{2}{3}$，$\\alpha = 0.7$，$\\tau = 10^{-4}$，$\\varepsilon = 10^{-10}$，$K_1^{\\max} = 100$，$K_2^{\\max} = 127$，$f = f_3$。\n4. $N = 63$，$\\omega = \\tfrac{2}{3}$，$\\alpha = 0.6$，$\\tau = 10^{-12}$，$\\varepsilon = 10^{-10}$，$K_1^{\\max} = 10$，$K_2^{\\max} = 63$，$f = f_4$。\n\n必需的最终输出。你的程序必须生成单行输出，包含一个由方括号括起来的逗号分隔列表，其中每个条目对应一个测试用例，并且本身是一个包含四个值的列表：\n- $k_{\\mathrm{switch}}$ (整数),\n- $\\rho_{k_{\\mathrm{switch}}}$ (浮点数),\n- $k_{\\mathrm{total}}$ (整数),\n- $\\lVert r_{\\mathrm{final}} \\rVert_2$ (浮点数)。\n\n例如，输出格式必须为\n$$\n[\\,[k_{\\mathrm{switch}},\\rho_{k_{\\mathrm{switch}}},k_{\\mathrm{total}},\\lVert r_{\\mathrm{final}} \\rVert_2],\\dots\\,]\n$$\n形式，该行中任何地方都不能有空格。这些值本身必须按上面列出的测试用例的顺序排列。答案不涉及物理单位。",
            "solution": "所提出的问题要求实现并分析一个用于求解一维泊松方程的两阶段混合迭代求解器，该方程使用有限差分格式进行离散化。对该问题的验证证实了它在科学上是合理的、良定的，并且是计算物理学中一个用于演示迭代方法高级概念的典范问题。在给出最终实现之前，我将首先对求解器的设计进行原则性解释。\n\n核心问题是求解线性方程组 $A x = b$，该方程组源于在区间 $x \\in [0,1]$ 上对边值问题 $-u''(x) = f(x)$（带有齐次狄利克雷边界条件 $u(0)=u(1)=0$）进行有限差分离散化。矩阵 $A$ 是负二阶导数算子 $-\\frac{d^2}{dx^2}$ 的离散表示。它是一个大小为 $N \\times N$ 的对称正定（SPD）矩阵，其中 $N$ 是内部网格点的数量。其元素由 $A_{ii} = 2/h^2$ 和 $A_{i,i\\pm1} = -1/h^2$ 给出，其中 $h=1/(N+1)$ 是网格间距。\n\n矩阵 $A$ 的一个关键方面是其谱特性。其特征向量（记为 $v_m$，其中 $m=1, 2, \\dots, N$）是离散正弦向量，其分量为 $(v_m)_j = \\sin\\left(\\frac{\\pi m j}{N+1}\\right)$（$j=1, \\dots, N$）。这些向量构成了 $\\mathbb{R}^N$ 的一个正交基，并且恰好是I型离散正弦变换（DST-I）的基向量。相应的特征值为 $\\lambda_m = \\frac{2}{h^2}\\left(1 - \\cos\\left(\\frac{\\pi m}{N+1}\\right)\\right) = \\frac{4}{h^2}\\sin^2\\left(\\frac{\\pi m}{2(N+1)}\\right)$。索引 $m$ 对应于模式的频率：小的 $m$ 值代表低频（平滑）模式，而大的 $m$ 值代表高频（振荡）模式。\n\n所提出的求解器是一种混合方法，旨在高效处理误差的不同频率分量。误差 $e_k = x - x_k$（其中 $x$ 是精确解）可以在 $A$ 的特征基上分解。不同的迭代方法在衰减与不同频率相关的误差分量方面表现出不同的效果。\n\n**阶段1：使用加权雅可比法进行平滑**\n第一阶段采用加权雅可比法，其迭代定义为：\n$$\nx_{k+1} = x_k + \\omega D^{-1} r_k = x_k + \\omega D^{-1} (b - A x_k)\n$$\n其中 $D$ 是 $A$ 的对角部分，即 $D = (2/h^2)I$，$\\omega \\in (0,1)$ 是一个松弛参数。误差的演化由 $e_{k+1} = (I - \\omega D^{-1} A) e_k$ 控制。该方法的有效性取决于迭代矩阵 $M_J = I - \\omega D^{-1} A$ 的特征值。由于 $A$ 和 $D$ 在DST-I基下是对角化的，因此 $M_J$ 的特征值很容易求得：\n$$\n\\mu_m = 1 - \\omega \\frac{h^2}{2} \\lambda_m = 1 - 2\\omega \\sin^2\\left(\\frac{\\pi m}{2(N+1)}\\right)\n$$\n对于高频模式（$m \\approx N$），$\\sin^2(\\dots)$ 项接近于 $1$，使得 $|\\mu_m| \\approx |1 - 2\\omega|$。对于指定的 $\\omega = 2/3$，该值为 $|1 - 4/3| = 1/3$，表明高频误差分量被迅速衰减。相反，对于低频模式（$m \\ll N$），$\\sin^2(\\dots)$ 很小，$\\mu_m \\approx 1$，表明衰减非常缓慢。这一特性使加权雅可比法成为一个出色的“平滑器”：它能有效减少误差的高频振荡分量，留下一个由低频分量主导的“更平滑”的误差。\n\n**自适应切换准则**\n从阶段1到阶段2的转换由一个基于残差 $r_k = b - A x_k$ 谱内容的准则控制。残差通过 $r_k = A e_k$ 与误差相关。高频能量比 $\\rho_k$ 定义为：\n$$\n\\rho_k = \\frac{\\sum_{m=m_c}^{N} \\left(R^{(k)}_m\\right)^2}{\\sum_{m=1}^{N} \\left(R^{(k)}_m\\right)^2}\n$$\n其中 $R^{(k)}_m$ 是 $r_k$ 的DST-I系数，$m_c = \\lceil \\alpha N \\rceil$ 是一个截止索引。$\\rho_k$ 衡量残差谱中高频部分的能量比例。一旦 $\\rho_k$ 低于容差 $\\tau$，雅可比迭代就停止，这标志着残差（并因此误差）已变得足够平滑。\n\n**阶段2：使用共轭梯度法进行粗糙误差校正**\n一旦误差变得平滑，问题就适合采用一种擅长减少低频误差的方法来解决。共轭梯度（CG）法是求解SPD系统（如 $Ax=b$）的一种最优克雷洛夫子空间法。当误差集中在低维子空间时，它尤其有效，这里的情况正是如此，因为剩余误差由少数低频特征模态主导。CG法迭代地为由初始残差生成的克雷洛夫子空间构建一个 $A$-正交基，并在每一步中在该子空间内找到最佳解。通过在平滑阶段后应用CG，剩余的平滑误差分量被以比雅可比法快得多的收敛速度消除。标准的CG算法被应用，直到残差的欧几里得范数 $\\lVert r_k \\rVert_2$ 降至最终容差 $\\varepsilon$ 以下。\n\n这种两阶段方法协同地结合了两种不同迭代方法的优点，这是现代数值分析中一个常见而强大的范式，并与多重网格方法的原理密切相关。雅可比法充当一个简单而有效的平滑器，而CG法则充当一个针对剩余平滑误差的高效类粗网格校正器。",
            "answer": "```python\nimport numpy as np\nfrom scipy.fft import dst\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the two-stage iterative solver.\n    \"\"\"\n    \n    # Define the forcing functions\n    def f1(x):\n        return np.sin(2 * np.pi * x) + 0.1 * np.sin(16 * np.pi * x)\n\n    def f2(x):\n        return np.sin(np.pi * x)\n\n    def f3_factory():\n        def f(x):\n            k_vals = np.arange(12, 25)\n            x_b = x[np.newaxis, :]\n            k_b = k_vals[:, np.newaxis]\n            terms = (1.0 / k_b) * np.sin(k_b * np.pi * x_b)\n            return np.sum(terms, axis=0)\n        return f\n    f3 = f3_factory()\n\n    def f4(x):\n        return np.sin(8 * np.pi * x) + 0.5 * np.sin(20 * np.pi * x)\n\n    test_cases = [\n        {'N': 63, 'omega': 2/3, 'alpha': 0.5, 'tau': 1e-3, 'epsilon': 1e-10, 'K1_max': 100, 'K2_max': 63, 'f': f1},\n        {'N': 63, 'omega': 2/3, 'alpha': 0.5, 'tau': 1e-6, 'epsilon': 1e-10, 'K1_max': 5, 'K2_max': 63, 'f': f2},\n        {'N': 127, 'omega': 2/3, 'alpha': 0.7, 'tau': 1e-4, 'epsilon': 1e-10, 'K1_max': 100, 'K2_max': 127, 'f': f3},\n        {'N': 63, 'omega': 2/3, 'alpha': 0.6, 'tau': 1e-12, 'epsilon': 1e-10, 'K1_max': 10, 'K2_max': 63, 'f': f4},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        N = case['N']\n        omega = case['omega']\n        alpha = case['alpha']\n        tau = case['tau']\n        epsilon = case['epsilon']\n        K1_max = case['K1_max']\n        K2_max = case['K2_max']\n        f = case['f']\n\n        h = 1.0 / (N + 1)\n        h2_inv = 1.0 / (h * h)\n        grid = np.arange(1, N + 1) * h\n        b = f(grid)\n\n        def matvec_A(v):\n            y = np.zeros(N)\n            # Interior points\n            y[1:-1] = -v[:-2] + 2 * v[1:-1] - v[2:]\n            # Boundary points (with v_0 = 0 and v_{N+1} = 0)\n            y[0] = 2 * v[0] - v[1]\n            y[-1] = 2 * v[-1] - v[-2]\n            return y * h2_inv\n\n        # Stage 1: Weighted Jacobi\n        x = np.zeros(N)\n        k_switch = 0\n        rho_k_switch = 0.0\n        m_c = math.ceil(alpha * N)\n\n        for k in range(K1_max + 1):\n            r = b - matvec_A(x)\n            \n            # Compute rho_k\n            Rk = dst(r, type=1)\n            total_energy = np.sum(Rk**2)\n            \n            rho_k = 0.0\n            if total_energy > 0:\n                high_freq_energy = np.sum(Rk[m_c - 1:]**2)\n                rho_k = high_freq_energy / total_energy\n\n            if k == K1_max or rho_k = tau:\n                k_switch = k\n                rho_k_switch = rho_k\n                break\n\n            # Jacobi step\n            # D_inv_r = r / (2/h^2) = r * h^2 / 2\n            x = x + omega * (h*h / 2.0) * r\n        \n        # Stage 2: Conjugate Gradient\n        k_cg = 0\n        r_cg = b - matvec_A(x)\n        p_cg = r_cg.copy()\n        rs_old = np.dot(r_cg, r_cg)\n\n        # The CG loop tolerance check is on the norm, so sqrt(rs_old)\n        if np.sqrt(rs_old) = epsilon:\n             pass # Already converged\n        else:\n            for i in range(K2_max):\n                Ap = matvec_A(p_cg)\n                alpha_cg = rs_old / np.dot(p_cg, Ap)\n                \n                x = x + alpha_cg * p_cg\n                r_cg = r_cg - alpha_cg * Ap\n                \n                rs_new = np.dot(r_cg, r_cg)\n                \n                k_cg = i + 1\n                \n                if np.sqrt(rs_new) = epsilon:\n                    break\n                \n                p_cg = r_cg + (rs_new / rs_old) * p_cg\n                rs_old = rs_new\n\n        k_total = k_switch + k_cg\n        r_final = b - matvec_A(x)\n        norm_r_final = np.linalg.norm(r_final)\n\n        results.append([k_switch, rho_k_switch, k_total, norm_r_final])\n\n    # Format the final output string without spaces as required\n    output_str = \",\".join([f\"[{r[0]},{r[1]},{r[2]},{r[3]}]\" for r in results])\n    print(f\"[{output_str}]\")\n\nsolve()\n```"
        }
    ]
}