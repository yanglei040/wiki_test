{
    "hands_on_practices": [
        {
            "introduction": "掌握共轭梯度法的第一步是亲手完成一次完整的迭代。这个练习将引导你从一个标准的初始猜测开始，计算初始残差、搜索方向、最优步长，并最终更新解向量。通过这个基础实践，你将熟悉算法的核心计算流程，为解决更复杂的问题打下坚实的基础。",
            "id": "1393666",
            "problem": "考虑线性方程组 $Ax=b$，其中矩阵 $A$ 和向量 $b$ 由下式给出：\n$$\nA = \\begin{pmatrix} 2 & -1 \\\\ -1 & 3 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 4 \\\\ -3 \\end{pmatrix}\n$$\n矩阵 $A$ 是对称正定的。\n\n以初始猜测 $x_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ 开始，应用一次共轭梯度法迭代来求得第一次更新后的解 $x_1$。\n\n将您的答案表示为一个包含 $x_1$ 各分量的行矩阵，并以精确分数形式表示。",
            "solution": "我们对对称正定矩阵 $A$ 应用共轭梯度法，从 $x_{0}$ 开始。标准的第一次迭代公式为：\n$$\nr_{0} = b - A x_{0}, \\quad p_{0} = r_{0}, \\quad \\alpha_{0} = \\frac{r_{0}^{T} r_{0}}{p_{0}^{T} A p_{0}}, \\quad x_{1} = x_{0} + \\alpha_{0} p_{0}.\n$$\n给定 $x_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ 和 $b = \\begin{pmatrix} 4 \\\\ -3 \\end{pmatrix}$，计算\n$$\nr_{0} = b - A x_{0} = \\begin{pmatrix} 4 \\\\ -3 \\end{pmatrix}, \\quad p_{0} = r_{0} = \\begin{pmatrix} 4 \\\\ -3 \\end{pmatrix}.\n$$\n接下来，计算 $A p_{0}$：\n$$\nA p_{0} = \\begin{pmatrix} 2 & -1 \\\\ -1 & 3 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ -3 \\end{pmatrix} = \\begin{pmatrix} 2 \\cdot 4 + (-1)(-3) \\\\ (-1) \\cdot 4 + 3 \\cdot (-3) \\end{pmatrix} = \\begin{pmatrix} 11 \\\\ -13 \\end{pmatrix}.\n$$\n计算内积：\n$$\nr_{0}^{T} r_{0} = 4^{2} + (-3)^{2} = 16 + 9 = 25, \\quad p_{0}^{T} A p_{0} = r_{0}^{T} (A p_{0}) = 4 \\cdot 11 + (-3) \\cdot (-13) = 44 + 39 = 83.\n$$\n因此，\n$$\n\\alpha_{0} = \\frac{r_{0}^{T} r_{0}}{p_{0}^{T} A p_{0}} = \\frac{25}{83}.\n$$\n更新解：\n$$\nx_{1} = x_{0} + \\alpha_{0} p_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\frac{25}{83} \\begin{pmatrix} 4 \\\\ -3 \\end{pmatrix} = \\begin{pmatrix} \\frac{100}{83} \\\\ -\\frac{75}{83} \\end{pmatrix}.\n$$\n表示为行矩阵，$x_{1}$ 的分量为 $\\begin{pmatrix} \\frac{100}{83} & -\\frac{75}{83} \\end{pmatrix}$。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{100}{83} & -\\frac{75}{83} \\end{pmatrix}}$$"
        },
        {
            "introduction": "在掌握了基本迭代步骤之后，让我们来探索一个更有趣的理论问题。在某些特殊情况下，共轭梯度法可以在一步之内就找到精确解。这个思想实验将揭示算法收敛速度与系统矩阵 $A$ 的特征向量之间的深刻联系，帮助你从更深层次理解算法为何如此高效。",
            "id": "1393668",
            "problem": "共轭梯度（CG）法是一种迭代算法，用于求解形如 $A\\mathbf{x} = \\mathbf{b}$ 的线性方程组，其中 $A$ 是一个对称正定矩阵。该方法的性能可能取决于初始猜测值 $\\mathbf{x}_0$ 的选择。\n\n考虑由矩阵 $A = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix}$ 和向量 $\\mathbf{b} = \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}$ 定义的线性系统。CG法使用形如 $\\mathbf{x}_0 = \\begin{pmatrix} 1 \\\\ y_0 \\end{pmatrix}$ 的初始向量进行初始化，其中 $y_0$ 是一个实数。\n\n求出所有可能的 $y_0$ 值，使得CG法在单次迭代中收敛到精确解。这意味着第一次迭代的结果 $\\mathbf{x}_1$ 就是精确解。你可以假设初始猜测值 $\\mathbf{x}_0$ 本身不是精确解。计算所有这些有效的 $y_0$ 值的总和。",
            "solution": "对于对称正定矩阵 $A$，共轭梯度法从 $x_{0}$ 开始，残差为 $r_{0}=b-Ax_{0}$，搜索方向为 $p_{0}=r_{0}$，步长为\n$$\n\\alpha_{0}=\\frac{r_{0}^{T}r_{0}}{p_{0}^{T}Ap_{0}},\n$$\n并更新 $x_{1}=x_{0}+\\alpha_{0}p_{0}$。精确解 $x^{*}$ 满足 $Ax^{*}=b$。定义初始误差 $e_{0}=x^{*}-x_{0}$。那么\n$$\nr_{0}=b-Ax_{0}=Ax^{*}-Ax_{0}=A(x^{*}-x_{0})=Ae_{0}.\n$$\n在一次迭代中收敛意味着 $x_{1}=x^{*}$，即\n$$\nx^{*}=x_{0}+\\alpha_{0}r_{0}\\quad\\Longleftrightarrow\\quad e_{0}=\\alpha_{0}r_{0}=\\alpha_{0}Ae_{0}.\n$$\n因此 $Ae_{0}=(1/\\alpha_{0})e_{0}$，所以 $e_{0}$ 必须是 $A$ 的一个特征向量。反之，如果 $Ae_{0}=\\lambda e_{0}$，那么 $r_{0}=\\lambda e_{0}$ 且\n$$\n\\alpha_{0}=\\frac{r_{0}^{T}r_{0}}{r_{0}^{T}Ar_{0}}=\\frac{\\lambda^{2}e_{0}^{T}e_{0}}{\\lambda^{3}e_{0}^{T}e_{0}}=\\frac{1}{\\lambda},\n$$\n这得出 $x_{1}=x_{0}+\\alpha_{0}r_{0}=x_{0}+(1/\\lambda)\\lambda e_{0}=x^{*}$。因此，单步收敛的充分必要条件是 $e_{0}$ 是 $A$ 的一个特征向量。\n\n计算 $A=\\begin{pmatrix}2 & -1\\\\ -1 & 2\\end{pmatrix}$ 和 $b=\\begin{pmatrix}1\\\\ 3\\end{pmatrix}$ 时的 $x^{*}$。求解\n$$\n\\begin{cases}\n2x_{1}-x_{2}=1,\\\\\n-x_{1}+2x_{2}=3,\n\\end{cases}\n$$\n解得 $x_{1}=5/3$, $x_{2}=7/3$，因此 $x^{*}=\\begin{pmatrix}5/3\\\\ 7/3\\end{pmatrix}$。\n\n对于 $x_{0}=\\begin{pmatrix}1\\\\ y_{0}\\end{pmatrix}$，初始误差为\n$$\ne_{0}=x^{*}-x_{0}=\\begin{pmatrix}5/3-1\\\\ 7/3-y_{0}\\end{pmatrix}=\\begin{pmatrix}2/3\\\\ 7/3-y_{0}\\end{pmatrix}.\n$$\n矩阵 $A$ 的特征值为 $\\lambda_{1}=1$（对应特征向量 $v_{1}=\\begin{pmatrix}1\\\\ 1\\end{pmatrix}$）和 $\\lambda_{2}=3$（对应特征向量 $v_{2}=\\begin{pmatrix}1\\\\ -1\\end{pmatrix}$）。因此 $e_{0}$ 必须与 $v_{1}$ 或 $v_{2}$ 平行。\n\n情况1：$e_{0}=c\\begin{pmatrix}1\\\\ 1\\end{pmatrix}$。则 $2/3=c$ 且 $7/3-y_{0}=c$，所以 $y_{0}=7/3-2/3=5/3$。\n\n情况2：$e_{0}=c\\begin{pmatrix}1\\\\ -1\\end{pmatrix}$。则 $2/3=c$ 且 $7/3-y_{0}=-c=-2/3$，所以 $y_{0}=7/3+2/3=3$。\n\n这两个值都使得 $e_{0}\\neq 0$，因此满足要求 $x_{0}\\neq x^{*}$。所有这些 $y_{0}$ 的总和为\n$$\n\\frac{5}{3}+3=\\frac{5}{3}+\\frac{9}{3}=\\frac{14}{3}.\n$$",
            "answer": "$$\\boxed{\\frac{14}{3}}$$"
        },
        {
            "introduction": "任何算法都有其适用范围，共轭梯度法的强大威力依赖于矩阵 $A$ 的对称正定性。这个编程练习将带你直面算法的“断点”，通过代码实践来检验当这一关键假设不成立时会发生什么。通过识别算法的失效模式，你将对在实际应用中检验先决条件的重要性有更具体的认识。",
            "id": "2382410",
            "problem": "实现一个程序，对于每个给定的对称矩阵和右侧向量，从零向量开始运行共轭梯度法 (CG, Conjugate Gradient)，并找出第一个使得用于计算下一步步长的分母为非正值的迭代索引。具体来说，在迭代索引 $k$（$k$ 从 $0$ 开始）处，定义搜索方向 $p_k$ 并计算二次型 $p_k^{\\mathsf{T}} A p_k$。当最小的 $k$ 满足 $p_k^{\\mathsf{T}} A p_k \\le 0$ 时，称算法发生崩溃。如果在规定的最大迭代次数内没有出现这样的索引，则返回 $-1$。\n\n背景与所需推理基础：从具有对称矩阵 $A$ 和向量 $b$ 的二次最小化问题开始，即能量泛函 $\\phi(x) = \\tfrac{1}{2} x^{\\mathsf{T}} A x - b^{\\mathsf{T}} x$。共轭梯度法 (CG, Conjugate Gradient) 可以理解为沿着 $A$-共轭方向 $p_k$ 对 $\\phi(x_k + \\alpha p_k)$ 进行线搜索最小化来生成迭代值 $x_k$，其中梯度为 $\\nabla \\phi(x) = A x - b$，残差定义为 $r_k = b - A x_k$。在强凸情况下（对称正定，SPD），每个非零向量 $v$ 都满足 $v^{\\mathsf{T}} A v > 0$，这保证了正曲率和良定义的步长。在不定或半定情况下，可能存在满足 $v^{\\mathsf{T}} A v \\le 0$ 的方向，这会破坏沿 $p_k$ 方向存在唯一最小值的保证，并导致算法崩溃。您的程序必须体现这一原则，在每次迭代中计算 $p_k^{\\mathsf{T}} A p_k$ 并报告其首次为非正值时的 $k$。\n\n精确计算任务：对于下面的每个测试用例，使用零向量作为初始猜测 $x_0 = 0$，运行具有标准残差和方向递推的共轭梯度迭代。在每次迭代中，计算步长之前，评估 $p_k^{\\mathsf{T}} A p_k$。如果 $p_k^{\\mathsf{T}} A p_k \\le 0$，则报告该测试用例的当前索引 $k$ 并停止处理该用例。如果在未遇到 $p_k^{\\mathsf{T}} A p_k \\le 0$ 的情况下达到收敛，或者在最多 $N_{\\max}$ 次迭代内没有发生此类事件，则为该用例报告 $-1$。使用基于残差范数的相对停止准则 $\\lVert r_k \\rVert_2 \\le \\varepsilon \\lVert b \\rVert_2$，容差为 $\\varepsilon = 10^{-12}$。使用 $N_{\\max} = 5n$，其中 $n$ 是 $A$ 的维度。\n\n确保覆盖率的测试套件：\n- 用例 $\\mathbf{1}$（SPD，预计不会崩溃）：\n  - $A_1 = \\begin{bmatrix} 4 & 1 & 0 \\\\ 1 & 3 & 0 \\\\ 0 & 0 & 2 \\end{bmatrix}$，\n  - $b_1 = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$。\n- 用例 $\\mathbf{2}$（不定，延迟崩溃）：\n  - $A_2 = \\begin{bmatrix} 2 & 1 \\\\ 1 & -2 \\end{bmatrix}$，\n  - $b_2 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$。\n- 用例 $\\mathbf{3}$（奇异半正定，起始时曲率为零）：\n  - $A_3 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}$，\n  - $b_3 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$。\n- 用例 $\\mathbf{4}$（不定，立即出现负曲率）：\n  - $A_4 = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}$，\n  - $b_4 = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$。\n\n算法约定：\n- 初始化 $x_0 = \\mathbf{0}$，$r_0 = b - A x_0 = b$ 和 $p_0 = r_0$。\n- 在迭代 $k$ 处，计算 $p_k^{\\mathsf{T}} A p_k$。如果 $p_k^{\\mathsf{T}} A p_k \\le 0$，则为该测试返回 $k$。\n- 否则，继续执行共轭梯度迭代，直到收敛或达到 $N_{\\max}$ 次迭代（以先到者为准）。\n- 如果没有发生崩溃，则返回 $-1$。\n\n最终所需输出：您的程序应生成单行输出，其中包含四个测试用例的结果，格式为方括号内由逗号分隔的整数列表，并按上述用例的顺序排列；即，形如 $[k_1,k_2,k_3,k_4]$ 的单行，其中 $k_j$ 是用例 $j$ 中首次出现 $p_k^{\\mathsf{T}} A p_k \\le 0$ 的迭代索引，如果在该用例的 $N_{\\max}$ 次迭代内没有出现这样的索引，则为 $-1$。本问题不涉及单位，也不需要角度或百分比。",
            "solution": "该问题要求实现一个改进的共轭梯度（CG）算法，以检测当系统矩阵 $A$ 不是对称正定（SPD）时发生的崩溃。崩溃被定义为二次型 $p_k^{\\mathsf{T}} A p_k$ 首次为非正值时的迭代索引 $k$。我们将首先回顾 CG 方法的理论基础及其失效模式，然后详细说明要实现的具体算法，最后分析所提供的测试用例。\n\n共轭梯度法是一种求解形如 $A x = b$ 的线性方程组的迭代算法，其中矩阵 $A$ 是对称且正定的。该方法可以通过考虑最小化二次能量泛函的等价优化问题来推导：\n$$\n\\phi(x) = \\frac{1}{2} x^{\\mathsf{T}} A x - b^{\\mathsf{T}} x\n$$\n该泛函的梯度为 $\\nabla \\phi(x) = A x - b$。$A x = b$ 的解是 $\\phi(x)$ 的唯一最小值点，在该点梯度为零。梯度的负数 $r = b - A x$ 定义为残差。\n\n标准的 CG 算法从一个初始猜测 $x_0$ 开始，生成一个迭代序列 $x_k$，该序列逐步最小化 $\\phi(x)$。从 $x_k$ 到 $x_{k+1}$ 的更新是通过沿一个精心选择的搜索方向 $p_k$ 进行线搜索来执行的。搜索方向 $\\{p_0, p_1, \\dots\\}$ 被构造成 $A$-共轭（或 $A$-正交），即对于所有 $i \\neq j$，都有 $p_i^{\\mathsf{T}} A p_j = 0$。\n\n对于一个 $n \\times n$ 的 SPD 矩阵 $A$，典型的算法如下：\n初始化：\n$x_0 = \\mathbf{0}$\n$r_0 = b - A x_0 = b$\n$p_0 = r_0$\n\n对于 $k = 0, 1, 2, \\dots$ 直到收敛：\n1.  计算步长 $\\alpha_k$，它是 $\\phi(x_k + \\alpha p_k)$ 的最小值点：\n    $$\n    \\alpha_k = \\frac{r_k^{\\mathsf{T}} r_k}{p_k^{\\mathsf{T}} A p_k}\n    $$\n2.  更新解的估计值：\n    $$\n    x_{k+1} = x_k + \\alpha_k p_k\n    $$\n3.  使用计算上高效的递推式更新残差：\n    $$\n    r_{k+1} = r_k - \\alpha_k A p_k\n    $$\n4.  计算下一个搜索方向的系数：\n    $$\n    \\beta_k = \\frac{r_{k+1}^{\\mathsf{T}} r_{k+1}}{r_k^{\\mathsf{T}} r_k}\n    $$\n5.  更新搜索方向，使其与之前的方向 $A$-共轭：\n    $$\n    p_{k+1} = r_{k+1} + \\beta_k p_k\n    $$\n\n该算法的有效性从根本上依赖于矩阵 $A$ 是 SPD。正定性确保了对于任何非零向量 $v$，二次型 $v^{\\mathsf{T}} A v > 0$。这保证了在 $\\alpha_k$ 表达式中的分母，即 $p_k^{\\mathsf{T}} A p_k$，对于任何非零搜索方向 $p_k$ 都是严格为正的。正的分母确保了 $\\alpha_k$ 是良定义且为正的（因为除非找到解，否则 $r_k^{\\mathsf{T}} r_k > 0$），从而保证每一步都是泛函 $\\phi(x)$ 的下降步。\n\n手头的问题关注的是当 $A$ 不是 SPD 矩阵时（即当它是对称不定或半正定矩阵时）CG 算法的行为。在这种情况下，可能会生成一个搜索方向 $p_k$，使得 $p_k^{\\mathsf{T}} A p_k \\le 0$。这会导致算法崩溃。\n-   **情况 1：$p_k^{\\mathsf{T}} A p_k = 0$（零曲率）。** 如果 $A$ 是半正定矩阵且 $p_k$ 是一个零曲率方向（即 $A p_k$ 与 $p_k$ 正交），则会发生这种情况。如果 $r_k \\neq 0$，则步长 $\\alpha_k$ 的公式会涉及除以零。算法无法继续进行。如果 $A$ 是奇异的，并且生成的搜索方向在 $A$ 的零空间中有分量，就会遇到这种情况。\n-   **情况 2：$p_k^{\\mathsf{T}} A p_k < 0$（负曲率）。** 如果 $A$ 是不定矩阵，则会发生这种情况。$p_k^{\\mathsf{T}} A p_k$ 为负值意味着泛函 $\\phi(x)$ 沿着方向 $p_k$ 是下方无界的。沿着这条线的最小化是不可能的，因为当我们沿着由 $\\text{sign}(\\alpha_k) p_k$ 给出的方向移动时，$\\phi(x)$ 会无界地减小。标准形式的 CG 算法无法处理这种情况，必须终止。\n\n任务是实现一个改进的 CG 过程，该过程明确检查这种崩溃条件。在每次迭代 $k$（从 $k=0$ 开始），我们必须首先计算 $p_k^{\\mathsf{T}} A p_k$ 并测试其符号。\n\n因此，具体的算法是：\n初始化：\n$x_0 = \\mathbf{0}$，$r_0 = b$，$p_0 = r_0$。设 $n$ 是 $A$ 的维度。设置最大迭代次数 $N_{\\max} = 5n$ 和容差 $\\varepsilon = 10^{-12}$。检查初始收敛：如果 $\\lVert r_0 \\rVert_2 \\le \\varepsilon \\lVert b \\rVert_2$，则终止并报告 $-1$。\n\n对于 $k = 0, 1, 2, \\dots, N_{\\max}-1$：\n1.  计算矩阵-向量乘积 $v_k = A p_k$。\n2.  计算二次型 $d_k = p_k^{\\mathsf{T}} v_k = p_k^{\\mathsf{T}} A p_k$。\n3.  **崩溃检查：** 如果 $d_k \\le 0$，算法已崩溃。报告当前迭代索引 $k$ 并终止此测试用例。\n4.  如果没有崩溃，则继续进行标准的 CG 更新：\n    $\\alpha_k = (r_k^{\\mathsf{T}} r_k) / d_k$\n    $x_{k+1} = x_k + \\alpha_k p_k$\n    $r_{k+1} = r_k - \\alpha_k v_k$\n5.  **收敛检查：** 如果 $\\lVert r_{k+1} \\rVert_2 \\le \\varepsilon \\lVert b \\rVert_2$，算法已收敛。报告 $-1$ 并终止此测试用例。\n6.  计算 $\\beta_k = (r_{k+1}^{\\mathsf{T}} r_{k+1}) / (r_k^{\\mathsf{T}} r_k)$。\n7.  更新搜索方向：$p_{k+1} = r_{k+1} + \\beta_k p_k$。\n\n如果循环在没有崩溃或收敛的情况下完成，则报告 $-1$。\n\n现在我们分析给定的测试用例：\n-   **用例 1：** $A_1$ 是一个 SPD 矩阵。其特征值约为 $4.44$、$2.56$ 和 $2.0$。由于所有特征值都是正的，对于任何非零向量 $p_k$，$p_k^{\\mathsf{T}} A_1 p_k$ 将始终为正。预计不会发生崩溃。算法应该会收敛。预期结果为 $-1$。\n-   **用例 2：** $A_2$ 是一个特征值为 $\\pm\\sqrt{5}$ 的不定矩阵。可能会发生崩溃。对于 $k=0$，$p_0 = b_2 = [1, 1]^{\\mathsf{T}}$。那么 $p_0^{\\mathsf{T}} A_2 p_0 = [1, 1] [2, 1; 1, -2] [1; 1] = 2 > 0$。算法继续进行。在下一步，对于 $k=1$，将生成一个搜索方向 $p_1$，使得 $p_1^{\\mathsf{T}} A_2 p_1 < 0$。预计在 $k=1$ 时发生崩溃。\n-   **用例 3：** $A_3$ 是一个特征值为 $1$ 和 $0$ 的奇异半正定矩阵。可能会发生崩溃。对于 $k=0$，$p_0 = b_3 = [0, 1]^{\\mathsf{T}}$。该向量是 $A_3$ 对应于特征值 $0$ 的特征向量（即它在 $A_3$ 的零空间中）。因此，$p_0^{\\mathsf{T}} A_3 p_0 = 0$。立即满足崩溃条件 $p_k^{\\mathsf{T}} A p_k \\le 0$。预期结果为 $k=0$。\n-   **用例 4：** $A_4$ 是一个特征值为 $\\pm 1$ 的不定矩阵。可能会发生崩溃。对于 $k=0$，$p_0 = b_4 = [1, -1]^{\\mathsf{T}}$。我们计算 $p_0^{\\mathsf{T}} A_4 p_0 = [1, -1] [0, 1; 1, 0] [1; -1] = -2 < 0$。立即满足崩溃条件。预期结果为 $k=0$。\n\n实现将为每个用例精确地遵循此逻辑。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the modified Conjugate Gradient\n    algorithm, and print the results in the specified format.\n    \"\"\"\n\n    def cg_breakdown_detector(A, b, epsilon, n_max):\n        \"\"\"\n        Runs the Conjugate Gradient method and detects breakdown.\n\n        Args:\n            A (np.ndarray): The symmetric matrix of the system.\n            b (np.ndarray): The right-hand side vector.\n            epsilon (float): The relative tolerance for convergence.\n            n_max (int): The maximum number of iterations.\n\n        Returns:\n            int: The iteration index k at which breakdown (p_k^T * A * p_k <= 0)\n                 occurs. Returns -1 if the method converges or reaches n_max\n                 iterations without breakdown.\n        \"\"\"\n        # Initialize x_0 = 0, r_0 = b - A*x_0 = b, p_0 = r_0\n        x = np.zeros_like(b, dtype=float)\n        r = b.copy()\n        p = r.copy()\n\n        # Check for trivial case b = 0, where x = 0 is the exact solution.\n        b_norm = np.linalg.norm(b)\n        if b_norm == 0:\n            return -1  # Converged at k=0, no breakdown.\n\n        # Check for convergence at k=0\n        if np.linalg.norm(r) <= epsilon * b_norm:\n            return -1 # Already converged, no breakdown.\n\n        # Precompute r_k^T * r_k for the first iteration\n        rs_old = np.dot(r, r)\n\n        for k in range(n_max):\n            # Compute A*p_k\n            Ap = A @ p\n\n            # The denominator of the step length alpha_k is p_k^T * A * p_k\n            pAp = np.dot(p, Ap)\n\n            # --- Breakdown Check ---\n            # This is the primary condition requested by the problem.\n            if pAp <= 0:\n                return k  # Breakdown detected at iteration k.\n\n            # --- Standard CG Iteration ---\n            # Compute step length\n            alpha = rs_old / pAp\n\n            # Update solution and residual\n            x += alpha * p\n            r -= alpha * Ap\n\n            # --- Convergence Check ---\n            if np.linalg.norm(r) <= epsilon * b_norm:\n                return -1  # Converged successfully, no breakdown.\n\n            # Update search direction\n            rs_new = np.dot(r, r)\n            beta = rs_new / rs_old\n            p = r + beta * p\n            \n            # Prepare for next iteration\n            rs_old = rs_new\n\n        # Reached n_max iterations without convergence or breakdown.\n        return -1\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"A\": np.array([[4, 1, 0], [1, 3, 0], [0, 0, 2]], dtype=float),\n            \"b\": np.array([1, 2, 3], dtype=float)\n        },\n        {\n            \"A\": np.array([[2, 1], [1, -2]], dtype=float),\n            \"b\": np.array([1, 1], dtype=float)\n        },\n        {\n            \"A\": np.array([[1, 0], [0, 0]], dtype=float),\n            \"b\": np.array([0, 1], dtype=float)\n        },\n        {\n            \"A\": np.array([[0, 1], [1, 0]], dtype=float),\n            \"b\": np.array([1, -1], dtype=float)\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        A = case[\"A\"]\n        b = case[\"b\"]\n        n = A.shape[0]\n        \n        # Set algorithm parameters as specified\n        n_max = 5 * n\n        epsilon = 1e-12\n\n        result = cg_breakdown_detector(A, b, epsilon, n_max)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}