{
    "hands_on_practices": [
        {
            "introduction": "This first practice gets to the heart of stiffness by turning the selection of a time step into a direct challenge. By implementing a simple explicit solver for a stiff equation, you will discover the sharp stability threshold that governs its behavior. This exercise  makes the abstract stability condition, $\\Delta t \\lt 2/\\lambda$, a concrete experience, demonstrating why large time steps can cause catastrophic failure.",
            "id": "2442901",
            "problem": "Design and implement a complete, runnable program that turns the choice of a time step into a stability \"game\" for a stiff initial value problem in ordinary differential equations (ODEs). Your task is to formalize the following challenge using first principles.\n\nConsider the autonomous linear ODE\n$$\n\\frac{dy}{dt} = -\\lambda\\, y,\n$$\nwith initial condition\n$$\ny(0) = y_0,\n$$\nwhere $\\lambda \\gt 0$ is a large parameter so that the problem is stiff. Work in dimensionless variables, so no physical units are involved.\n\nStarting only from fundamental definitions in numerical analysis and calculus, do the following.\n\n1) Using the definition of the derivative and a first-order finite difference at $t_n$, derive the forward (explicit) Euler update. Using the same base and a first-order finite difference at $t_{n+1}$, derive the backward (implicit) Euler update. Do not assume any pre-quoted update rule; derive each from the definition of $\\frac{dy}{dt}$ and the step relation $t_{n+1} = t_n + \\Delta t$.\n\n2) For each of the two integrators, identify the single-step amplification factor implied by the derived update when the right-hand side is $-\\lambda y$. Use the absolute stability notion: the discrete trajectory is absolutely stable if and only if the magnitude of this single-step amplification factor is strictly less than $1$; otherwise it is unstable. The borderline case where the magnitude equals $1$ must be treated as unstable for the purpose of this game.\n\n3) Implement both methods as time-stepping algorithms on the interval $[0,T]$ with uniform step size $\\Delta t$. Advance exactly $N$ steps with $N = T/\\Delta t$ (all provided $\\Delta t$ values divide $T$ exactly). In addition to computing the stability classification from the amplification factor, also simulate the trajectories $y_n$ and record the maximum absolute value attained over the steps as a diagnostic of behavior.\n\n4) The game objective is to choose $\\Delta t$ so that the explicit Euler method remains absolutely stable. For each test case below, you must report whether the explicit Euler method is unstable (a \"lose\" state) according to the absolute stability criterion in item $2$.\n\nTest suite:\n- Stiffness parameter: $\\lambda = 1000$.\n- Initial value: $y_0 = 1$.\n- Final time: $T = 1$.\n- Time steps: $\\Delta t \\in \\{\\, 0.0005,\\ 0.0020,\\ 0.0025 \\,\\}$.\n\nFor each $\\Delta t$ in the test suite, run both explicit and implicit Euler over $[0,T]$ and determine a scalar output $r$ defined by:\n- $r = 1$ if the explicit Euler method is unstable by the absolute stability criterion in item $2$ (i.e., the magnitude of its amplification factor is greater than or equal to $1$).\n- $r = 0$ otherwise.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the provided time steps. For example, the printed line should look like\n$$\n[ r_1, r_2, r_3 ]\n$$\nbut without spaces, i.e., exactly like $[r_1,r_2,r_3]$, where each $r_k$ is an integer $0$ or $1$ corresponding to $\\Delta t = 0.0005$, $\\Delta t = 0.0020$, and $\\Delta t = 0.0025$, respectively.",
            "solution": "The problem as stated is valid. It is a well-posed, scientifically grounded exercise in the numerical analysis of ordinary differential equations (ODEs), focusing on the critical concepts of stiffness and numerical stability. The premises are factually correct, the terminology is precise, and the objective is clearly defined. We shall proceed with a rigorous, first-principles derivation and solution.\n\nThe governing linear autonomous ODE is:\n$$\n\\frac{dy}{dt} = -\\lambda y, \\quad y(0) = y_0\n$$\nwhere $\\lambda  0$ is a large constant, characteristic of a stiff system. The exact solution is $y(t) = y_0 e^{-\\lambda t}$, which decays rapidly to zero. A numerical method must be able to reproduce this decay without introducing spurious oscillations or divergence.\n\n**1. Derivation of the Euler Integrators from First Principles**\n\nWe discretize the time continuum with a uniform step size $\\Delta t$, such that $t_n = n \\Delta t$. The numerical approximation of the solution at $t_n$ is denoted by $y_n$. The derivative $\\frac{dy}{dt}$ is defined by the limit:\n$$\n\\frac{dy}{dt} = \\lim_{\\Delta t \\to 0} \\frac{y(t+\\Delta t) - y(t)}{\\Delta t}\n$$\n\n**Forward (Explicit) Euler Method:**\nTo derive the forward Euler update, we approximate the derivative at time $t_n$ by a first-order forward finite difference, which is obtained by removing the limit from the derivative definition:\n$$\n\\frac{dy}{dt}\\bigg|_{t=t_n} \\approx \\frac{y(t_{n+1}) - y(t_n)}{\\Delta t}\n$$\nSubstituting this approximation into the ODE, $\\frac{dy}{dt} = -\\lambda y$, and evaluating all terms at the known time step $t_n$ gives:\n$$\n\\frac{y_{n+1} - y_n}{\\Delta t} = -\\lambda y_n\n$$\nRearranging to solve for the unknown value $y_{n+1}$ gives the explicit update rule:\n$$\ny_{n+1} = y_n + \\Delta t (-\\lambda y_n) = (1 - \\lambda \\Delta t) y_n\n$$\nThis method is termed \"explicit\" because $y_{n+1}$ can be calculated directly using values known at step $n$.\n\n**Backward (Implicit) Euler Method:**\nTo derive the backward Euler update, we use a first-order backward finite difference to approximate the derivative, but evaluated at the next time step, $t_{n+1}$:\n$$\n\\frac{dy}{dt}\\bigg|_{t=t_{n+1}} \\approx \\frac{y(t_{n+1}) - y(t_n)}{\\Delta t}\n$$\nFor consistency, the right-hand side of the ODE must also be evaluated at $t_{n+1}$:\n$$\n\\frac{y_{n+1} - y_n}{\\Delta t} = -\\lambda y_{n+1}\n$$\nTo find $y_{n+1}$, we must algebraically solve the equation.\n$$\ny_{n+1} + \\lambda \\Delta t y_{n+1} = y_n \\implies y_{n+1}(1 + \\lambda \\Delta t) = y_n\n$$\nIsolating $y_{n+1}$ gives the implicit update rule:\n$$\ny_{n+1} = \\frac{1}{1 + \\lambda \\Delta t} y_n\n$$\nThis method is \"implicit\" because $y_{n+1}$ appears on both sides of the initial equation, requiring a solve step to advance the solution.\n\n**2. Amplification Factor and Absolute Stability Analysis**\n\nFor both methods, the update rule is of the form $y_{n+1} = G y_n$, where the scalar $G$ is the single-step amplification factor. The numerical solution remains stable if and only if errors do not grow with each step. The condition for absolute stability is that the magnitude of the amplification factor must be strictly less than one: $|G|  1$. The problem specifies that the boundary case $|G| = 1$ is to be treated as unstable.\n\n**Forward Euler Stability:**\nThe amplification factor is $G_{FE} = 1 - \\lambda \\Delta t$. The stability condition is:\n$$\n|1 - \\lambda \\Delta t|  1\n$$\nAs $\\lambda  0$ and $\\Delta t  0$, we have $\\lambda \\Delta t  0$. The inequality becomes:\n$$\n-1  1 - \\lambda \\Delta t  1\n$$\nThe right side, $1 - \\lambda \\Delta t  1$, implies $-\\lambda \\Delta t  0$, which is always satisfied. The left side, $-1  1 - \\lambda \\Delta t$, yields $ \\lambda \\Delta t  2$.\nThus, the forward Euler method is conditionally stable, requiring $\\Delta t  \\frac{2}{\\lambda}$. For the unstable case, the criterion is $\\Delta t \\ge \\frac{2}{\\lambda}$.\n\n**Backward Euler Stability:**\nThe amplification factor is $G_{BE} = \\frac{1}{1 + \\lambda \\Delta t}$. The stability condition is:\n$$\n\\left| \\frac{1}{1 + \\lambda \\Delta t} \\right|  1\n$$\nSince $\\lambda  0$ and $\\Delta t  0$, the denominator $1 + \\lambda \\Delta t$ is always greater than $1$. Consequently, $0  G_{BE}  1$ for all positive $\\Delta t$. The stability condition is always met. The backward Euler method is therefore unconditionally stable for this problem, a property known as A-stability.\n\n**3. Implementation and Game Objective**\n\nThe \"game\" requires us to determine if a given time step $\\Delta t$ renders the explicit Euler method unstable. The result, $r$, is $1$ for instability and $0$ for stability. The parameters are $\\lambda=1000$, $y_0 = 1$, and $T=1$.\nThe stability threshold for $\\Delta t$ is:\n$$\n\\Delta t  \\frac{2}{\\lambda} = \\frac{2}{1000} = 0.002\n$$\nThe method is unstable if $\\Delta t \\ge 0.002$. We will apply this condition to each test case.\n\n- **Test Case 1: $\\Delta t = 0.0005$**\n  Since $0.0005  0.002$, the stability condition is satisfied. The method is stable.\n  $|G_{FE}| = |1 - 1000 \\times 0.0005| = |1 - 0.5| = 0.5  1$.\n  Result: $r_1 = 0$.\n\n- **Test Case 2: $\\Delta t = 0.0020$**\n  Here, $\\Delta t = 0.002$, which falls on the boundary. According to the problem's strict rule, this is unstable.\n  $|G_{FE}| = |1 - 1000 \\times 0.0020| = |1 - 2.0| = 1.0$.\n  The condition $|G_{FE}| \\ge 1$ is met.\n  Result: $r_2 = 1$.\n\n- **Test Case 3: $\\Delta t = 0.0025$**\n  Here, $0.0025  0.002$, violating the stability condition. The method is unstable.\n  $|G_{FE}| = |1 - 1000 \\times 0.0025| = |1 - 2.5| = 1.5  1$.\n  The condition $|G_{FE}| \\ge 1$ is met.\n  Result: $r_3 = 1$.\n\nThe final sequence of results is $[0, 1, 1]$. The provided code will implement this logic, including the requested simulation of trajectories to demonstrate the consequences of stability and instability, even though the final printed output depends only on the amplification factor analysis.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the stability game for a stiff ODE using Euler methods.\n\n    The program performs the following steps as required:\n    1. For each test case (time step), it calculates the amplification factor for\n       the explicit Euler method.\n    2. It determines if the method is unstable based on the condition that the\n       magnitude of the amplification factor is greater than or equal to 1.\n    3. It implements both explicit and implicit Euler methods to simulate the\n       trajectory, demonstrating adherence to the full problem statement, although\n       the final output depends only on the stability criterion.\n    4. It collects the stability results (0 for stable, 1 for unstable) and\n       prints them in the specified format.\n    \"\"\"\n\n    # Define problem parameters from the statement.\n    lambda_val = 1000.0\n    y0 = 1.0\n    T = 1.0\n\n    # Define the test suite of time steps.\n    delta_t_values = [0.0005, 0.0020, 0.0025]\n\n    results = []\n\n    for delta_t in delta_t_values:\n        # --- Part 4: The Game Objective ---\n        # Determine stability for explicit Euler based on the amplification factor.\n        # The amplification factor for explicit Euler is G_FE = 1 - lambda * delta_t.\n        # Stability requires |G_FE|  1. Unstable if |G_FE| = 1.\n        \n        amp_factor_mag = abs(1.0 - lambda_val * delta_t)\n\n        # The result r is 1 if unstable, 0 otherwise.\n        if amp_factor_mag = 1.0:\n            r = 1\n        else:\n            r = 0\n        results.append(r)\n\n        # --- Part 3: Simulation (for completeness as requested) ---\n        # Although not needed for the final output 'r', the problem requires\n        # implementing the time-stepping to simulate the trajectories.\n        \n        # Ensure N is an integer, as guaranteed by the problem statement.\n        N = int(round(T / delta_t))\n        \n        # Explicit Euler Simulation\n        y_explicit = np.zeros(N + 1)\n        y_explicit[0] = y0\n        amp_factor_explicit = 1.0 - lambda_val * delta_t\n        for n in range(N):\n            y_explicit[n+1] = amp_factor_explicit * y_explicit[n]\n        # max_abs_explicit = np.max(np.abs(y_explicit)) # Diagnostic\n\n        # Implicit Euler Simulation\n        y_implicit = np.zeros(N + 1)\n        y_implicit[0] = y0\n        amp_factor_implicit = 1.0 / (1.0 + lambda_val * delta_t)\n        for n in range(N):\n            y_implicit[n+1] = amp_factor_implicit * y_implicit[n]\n        # max_abs_implicit = np.max(np.abs(y_implicit)) # Diagnostic\n        \n        # The diagnostics max_abs_explicit and max_abs_implicit could be\n        # inspected to observe the blow-up or decay, confirming the theory.\n        # For example, for delta_t = 0.0025 (unstable), max_abs_explicit\n        # would be a very large number, while max_abs_implicit would be 1.0.\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Numerical stability doesn't always guarantee a physically correct answer. This exercise  explores a crucial subtlety: an explicit method can produce a bounded, \"stable\" solution that is qualitatively wrong, featuring unphysical results like negative concentrations. By contrasting this with the behavior of an implicit method on a simple chemical kinetics model, you will learn that the benefits of implicit solvers go beyond just avoiding numerical blow-ups.",
            "id": "2442899",
            "problem": "Consider the linear, constant-coefficient, two-species kinetic chain modeled by the ordinary differential equation (ODE) system\n$$\n\\frac{d}{dt}\\begin{bmatrix} y_1(t) \\\\ y_2(t) \\end{bmatrix}\n=\n\\begin{bmatrix}\n- k_1  0 \\\\\nk_1  - k_2\n\\end{bmatrix}\n\\begin{bmatrix} y_1(t) \\\\ y_2(t) \\end{bmatrix},\n\\quad\n\\begin{bmatrix} y_1(0) \\\\ y_2(0) \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix},\n$$\nwith rate constants $k_1 = 1000\\,\\text{s}^{-1}$ and $k_2 = 1\\,\\text{s}^{-1}$. The independent variable is time $t$ measured in seconds. This system is stiff because the eigenvalues of the system matrix differ by orders of magnitude.\n\nYour task is to demonstrate, by derivation and computation, how an explicit one-step method can be numerically stable (bounded) yet produce a qualitatively wrong trajectory for a stiff problem, while an implicit one-step method preserves qualitative features.\n\nStart from the following fundamental bases:\n- The definition of the time derivative, $\\frac{dy}{dt} = \\lim_{h\\to 0} \\frac{y(t+h)-y(t)}{h}$.\n- The forward (explicit) Euler method arises by replacing the derivative with a forward finite difference evaluated at the current time.\n- The backward (implicit) Euler method arises by replacing the derivative with a backward finite difference evaluated at the next time.\n- Linear stability for a one-step method is assessed on the scalar test equation $\\frac{dy}{dt} = \\lambda y$, by examining the amplification factor $R(z)$ where $z = h\\lambda$. For a linear system $\\frac{d\\mathbf{y}}{dt} = A\\mathbf{y}$, stability is determined by the spectral radius of the amplification matrix.\n\nRequirements:\n1) Derive, from first principles, the discrete-time update maps for the explicit Euler and backward Euler methods applied to the given $2\\times 2$ linear system. Express both updates in terms of the time step $h$ and the system matrix $A$.\n\n2) Using the scalar test equation analysis, derive the explicit Euler amplification factor $R(z)$ and its stability region. Explain how this implies a stability condition for the linear system in terms of the spectral radius of the matrix $I + hA$, where $I$ is the identity matrix. For this problem, classify an explicit step as \"numerically stable (bounded)\" if the spectral radius of $I + hA$ is less than or equal to $1$.\n\n3) Implement both methods to evolve the system from $t=0$ to $t = T$ with $T = 0.95\\,\\text{s}$ for several fixed time steps $h$. For each method and each time step, record whether any component becomes negative at any discrete time level. Concentrations being negative is a qualitative violation.\n\n4) For each time step $h$, determine whether the explicit Euler method is numerically stable (bounded) by computing the spectral radius of $I + hA$ and checking whether it is less than or equal to $1$.\n\n5) Use the following test suite of time steps (in seconds): $h \\in \\{0.0005,\\ 0.0019,\\ 0.0020\\}$. For each $h$, evolve both methods to $T = 0.95\\,\\text{s}$ (which is exactly an integer number of steps for each listed $h$), and report three booleans in the order:\n- the explicit method’s bounded-stability flag (as defined in item $4$),\n- whether the explicit method ever produced a negative component,\n- whether the implicit method ever produced a negative component.\n\nFinal output specification:\n- Your program should produce a single line of output containing a list of three lists (one per test case in the order of $h$ given above). Each inner list must be of the form $[\\text{explicit\\_bounded},\\ \\text{explicit\\_has\\_negative},\\ \\text{implicit\\_has\\_negative}]$, where each entry is a boolean. For example, an output could look like $[[\\text{True},\\text{False},\\text{False}],[\\dots],[\\dots]]$.\n- There are no additional units to report in the output booleans. Time must be handled in seconds internally.",
            "solution": "The problem requires a demonstration of the differing qualitative and quantitative behavior of explicit and implicit one-step numerical methods when applied to a stiff ordinary differential equation (ODE) system. We will first validate the problem, then proceed with the required derivations and computations.\n\nThe problem is valid. It presents a well-posed initial value problem based on a standard model of linear chemical kinetics, a topic firmly grounded in computational physics and chemistry. All required constants, initial conditions, and definitions are provided, and the problem is free of scientific inaccuracies, ambiguities, or subjective claims. We proceed to the solution.\n\nThe system is given by the linear ODE $\\frac{d\\mathbf{y}}{dt} = A\\mathbf{y}$, where the state vector is $\\mathbf{y}(t) = \\begin{bmatrix} y_1(t) \\\\ y_2(t) \\end{bmatrix}$, the initial condition is $\\mathbf{y}(0) = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$, and the system matrix $A$ is\n$$\nA = \\begin{bmatrix} -k_1  0 \\\\ k_1  -k_2 \\end{bmatrix} = \\begin{bmatrix} -1000  0 \\\\ 1000  -1 \\end{bmatrix}.\n$$\nThe independent variable is time $t$, with rate constants $k_1 = 1000\\,\\text{s}^{-1}$ and $k_2 = 1\\,\\text{s}^{-1}$.\n\n1) Derivation of Discrete-Time Update Maps\n\nLet $\\mathbf{y}_n$ be the numerical approximation of $\\mathbf{y}(t_n)$ at time $t_n = n h$, where $h$ is the time step.\n\nThe explicit (forward) Euler method approximates the derivative $\\frac{d\\mathbf{y}}{dt}$ at time $t_n$ using a forward finite difference:\n$$\n\\frac{\\mathbf{y}_{n+1} - \\mathbf{y}_n}{h} \\approx A\\mathbf{y}_n.\n$$\nSolving for $\\mathbf{y}_{n+1}$ yields the explicit update map:\n$$\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + h A\\mathbf{y}_n = (I + hA)\\mathbf{y}_n,\n$$\nwhere $I$ is the $2 \\times 2$ identity matrix.\n\nThe implicit (backward) Euler method approximates the derivative at time $t_{n+1}$ using a backward finite difference, evaluating the right-hand side at the future time $t_{n+1}$:\n$$\n\\frac{\\mathbf{y}_{n+1} - \\mathbf{y}_n}{h} \\approx A\\mathbf{y}_{n+1}.\n$$\nTo find $\\mathbf{y}_{n+1}$, we must solve a linear system:\n$$\n\\mathbf{y}_n = \\mathbf{y}_{n+1} - hA\\mathbf{y}_{n+1} = (I - hA)\\mathbf{y}_{n+1}.\n$$\nSolving for $\\mathbf{y}_{n+1}$ by inverting the matrix $(I - hA)$ gives the implicit update map:\n$$\n\\mathbf{y}_{n+1} = (I - hA)^{-1}\\mathbf{y}_n.\n$$\n\n2) Stability Analysis of the Explicit Euler Method\n\nThe stability of a one-step method is analyzed using the scalar test equation $\\frac{dy}{dt} = \\lambda y$, where $\\lambda \\in \\mathbb{C}$. Applying the explicit Euler method gives the recurrence relation:\n$$\ny_{n+1} = y_n + h(\\lambda y_n) = (1 + h\\lambda)y_n.\n$$\nThe term $R(z) = 1 + h\\lambda = 1+z$, with $z = h\\lambda$, is the amplification factor. The numerical solution remains bounded if and only if $|R(z)| \\le 1$. For explicit Euler, this condition $|1+z| \\le 1$ defines the stability region as a disk of radius $1$ centered at $(-1, 0)$ in the complex plane.\n\nFor a linear system $\\frac{d\\mathbf{y}}{dt} = A\\mathbf{y}$, the method is stable if this condition holds for $z=h\\lambda_i$ for every eigenvalue $\\lambda_i$ of the matrix $A$. This is equivalent to requiring that all eigenvalues of the amplification matrix, $I+hA$, have a magnitude no greater than $1$. The maximum magnitude of these eigenvalues is the spectral radius, $\\rho(I+hA)$. Therefore, the condition for the explicit Euler method to be numerically stable (bounded) is:\n$$\n\\rho(I + hA) \\le 1.\n$$\n\n3, 4, 5) Application to the Specific Problem and Computational Analysis\n\nThe matrix $A = \\begin{bmatrix} -1000  0 \\\\ 1000  -1 \\end{bmatrix}$ is lower triangular, so its eigenvalues are its diagonal entries: $\\lambda_1 = -1000$ and $\\lambda_2 = -1$.\nThe eigenvalues of the explicit Euler amplification matrix $I+hA$ are $1+h\\lambda_1 = 1 - 1000h$ and $1+h\\lambda_2 = 1 - h$. The spectral radius is $\\rho(I+hA) = \\max(|1 - 1000h|, |1 - h|)$.\nFor stability, we require both $|1 - 1000h| \\le 1$ and $|1 - h| \\le 1$. The first inequality, $-1 \\le 1 - 1000h \\le 1$, implies $-2 \\le -1000h \\le 0$, which simplifies to $0 \\le h \\le \\frac{2}{1000} = 0.002\\,\\text{s}$. The second inequality gives $0 \\le h \\le 2\\,\\text{s}$. The stricter of these two conditions dictates the stability of the entire system. Thus, the explicit method is bounded if and only if $h \\le 0.002\\,\\text{s}$.\n\nHowever, numerical stability (boundedness) does not guarantee qualitative correctness. In this kinetic model, concentrations $y_1$ and $y_2$ must remain non-negative. Let us examine the first step of the explicit Euler method starting from $\\mathbf{y}_0 = [1, 0]^T$:\n$$\n\\begin{bmatrix} y_{1,1} \\\\ y_{2,1} \\end{bmatrix} = \\begin{bmatrix} 1 - 1000h  0 \\\\ 1000h  1 - h \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 - 1000h \\\\ 1000h \\end{bmatrix}.\n$$\nFor the components to remain non-negative, we need $y_{1,1} \\ge 0$, which implies $1 - 1000h \\ge 0$, or $h \\le \\frac{1}{1000} = 0.001\\,\\text{s}$. This condition is stricter than the stability condition $h \\le 0.002\\,\\text{s}$. For any step size $h$ in the range $0.001  h \\le 0.002$, the explicit Euler method is numerically bounded but produces an unphysical negative value for the $y_1$ component.\n\nFor the backward Euler method, the update matrix is $(I - hA)^{-1} = \\left(\\begin{bmatrix} 1+1000h  0 \\\\ -1000h  1+h \\end{bmatrix}\\right)^{-1} = \\frac{1}{(1+1000h)(1+h)}\\begin{bmatrix} 1+h  0 \\\\ 1000h  1+1000h \\end{bmatrix}$. Since $h  0$, all entries of this matrix are non-negative. Because the initial state $\\mathbf{y}_0$ is non-negative, all subsequent states $\\mathbf{y}_{n+1} = (I - hA)^{-1}\\mathbf{y}_n$ will remain non-negative by induction. The backward Euler method is therefore positivity-preserving for any step size $h  0$.\n\nWe now evaluate the test cases: $h \\in \\{0.0005, 0.0019, 0.0020\\}$.\n\nCase $h=0.0005\\,\\text{s}$:\n- `explicit_bounded`: $h = 0.0005 \\le 0.002$, so the method is bounded. $\\rho(I+hA) = \\max(|1-0.5|,|1-0.0005|) = 0.9995 \\le 1$. True.\n- `explicit_has_negative`: $h = 0.0005 \\le 0.001$, so non-negativity is preserved. False.\n- `implicit_has_negative`: This method is always positivity-preserving. False.\nResult: `[True, False, False]`\n\nCase $h=0.0019\\,\\text{s}$:\n- `explicit_bounded`: $h = 0.0019 \\le 0.002$, so the method is bounded. $\\rho(I+hA) = \\max(|1-1.9|,|1-0.0019|) = \\max(0.9, 0.9981) = 0.9981 \\le 1$. True.\n- `explicit_has_negative`: $h = 0.0019  0.001$, so $y_1$ becomes negative. True.\n- `implicit_has_negative`: Always positivity-preserving. False.\nResult: `[True, True, False]`\n\nCase $h=0.0020\\,\\text{s}$:\n- `explicit_bounded`: $h = 0.0020$, at the boundary of stability. $\\rho(I+hA) = \\max(|1-2.0|,|1-0.0020|) = \\max(1.0, 0.998) = 1.0 \\le 1$. True.\n- `explicit_has_negative`: $h = 0.0020  0.001$, so $y_1$ becomes negative. True.\n- `implicit_has_negative`: Always positivity-preserving. False.\nResult: `[True, True, False]`\n\nThe final compiled results match these derivations.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the stiff ODE problem, demonstrating the difference between\n    explicit and implicit Euler methods.\n    \"\"\"\n    # Define problem parameters\n    k1 = 1000.0\n    k2 = 1.0\n    T_final = 0.95\n    y0 = np.array([1.0, 0.0])\n    \n    # System matrix\n    A = np.array([[-k1, 0.0], [k1, -k2]])\n\n    # Define the test cases from the problem statement.\n    test_cases = [0.0005, 0.0019, 0.0020]\n\n    results = []\n    \n    # Process each test case (each time step h)\n    for h in test_cases:\n        # Requirement 4: Determine if explicit Euler is boundedly stable\n        # Eigenvalues of A are its diagonal entries since it is triangular\n        lambda1 = -k1\n        lambda2 = -k2\n        # Eigenvalues of the amplification matrix I + hA\n        eig_val1_amp = 1.0 + h * lambda1\n        eig_val2_amp = 1.0 + h * lambda2\n        # Spectral radius is the maximum of the absolute values of the eigenvalues\n        spectral_radius = max(abs(eig_val1_amp), abs(eig_val2_amp))\n        \n        # The problem defines stability as spectral radius = 1.\n        # A small tolerance accounts for potential floating-point inaccuracies\n        # when h=0.002 (where spectral radius is exactly 1).\n        explicit_bounded = spectral_radius = 1.0 + 1e-9\n\n        # Requirement 3  5: Check for negative components\n        num_steps = int(round(T_final / h))\n\n        # --- Explicit Euler Simulation ---\n        y_exp = np.copy(y0)\n        M_exp = np.eye(2) + h * A\n        explicit_has_negative = False\n        for _ in range(num_steps):\n            y_exp = M_exp @ y_exp\n            # Check if any component of the state vector is negative\n            if np.any(y_exp  0):\n                explicit_has_negative = True\n                break\n        \n        # --- Implicit Euler Simulation ---\n        y_imp = np.copy(y0)\n        # Pre-compute the inverse of (I - hA) for efficiency\n        M_imp_inv = np.linalg.inv(np.eye(2) - h * A)\n        implicit_has_negative = False\n        for _ in range(num_steps):\n            y_imp = M_imp_inv @ y_imp\n            # Check if any component is negative (theoretically will not happen)\n            if np.any(y_imp  0):\n                implicit_has_negative = True\n                break\n        \n        # Append the list of booleans for the current case\n        results.append([explicit_bounded, explicit_has_negative, implicit_has_negative])\n\n    # Final print statement in the exact required format.\n    # The output format requires no spaces, e.g., [[True,False,False],...].\n    # str(results) would produce spaces, so we remove them.\n    final_output_string = str(results).replace(\" \", \"\")\n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "Theory is one thing, but performance is what matters in practice. This final exercise  moves from simple, fixed-step methods to the adaptive solvers used in real scientific software to quantify the efficiency gap between explicit and implicit approaches. By comparing the number of function evaluations required by each type of solver as a problem's stiffness increases, you will see the dramatic performance advantage that makes implicit methods indispensable for many real-world simulations.",
            "id": "2442926",
            "problem": "Consider the scalar initial value problem defined by the linear stiff ordinary differential equation\n$$\n\\frac{dy}{dt} = -\\lambda\\, y, \\quad y(0)=1,\n$$\non a finite time interval. The exact solution is\n$$\ny(t) = e^{-\\lambda t}.\n$$\nA system is called stiff when the dynamics include rapidly decaying modes, so that explicit solvers must take extremely small steps to maintain numerical stability while implicit solvers remain stable for much larger steps. In an adaptive time-stepping scheme, the step size is adjusted so that an estimate of the local truncation error remains below the user-specified tolerances.\n\nYour task is to write a complete program that, for each test case below, integrates the problem using both an adaptive explicit Runge–Kutta method and an adaptive implicit multistep method, and then compares the number of function evaluations used. Use the following requirements.\n\n- Use the adaptive explicit method \"RK45\" (a classical explicit Runge–Kutta method with an embedded error estimator) and the adaptive implicit method \"BDF\" (Backward Differentiation Formula), both with automatic step-size control governed by user-specified tolerances.\n- For the implicit solver, provide the exact Jacobian\n$$\nJ(t,y) = \\frac{\\partial f}{\\partial y} = -\\lambda,\n$$\nso that the implicit method does not need to approximate it by finite differences.\n- For both solvers, use the same absolute and relative tolerances for each test case. Let $rtol$ denote the relative tolerance and $atol$ denote the absolute tolerance.\n- For each test case, record the number of right-hand-side function evaluations $N_{\\mathrm{fev}}$ reported by each solver, denoted $N_{\\mathrm{fev}}^{\\mathrm{exp}}$ for the explicit method and $N_{\\mathrm{fev}}^{\\mathrm{imp}}$ for the implicit method. Compute the ratio\n$$\nR = \\frac{N_{\\mathrm{fev}}^{\\mathrm{exp}}}{N_{\\mathrm{fev}}^{\\mathrm{imp}}}.\n$$\n- Return one $R$ per test case.\n\nTest suite:\n- Case 1 (baseline, mildly stiff): $\\lambda = 50$, integrate on $t \\in [0, 2.0]$ with $rtol = 10^{-6}$ and $atol = 10^{-12}$.\n- Case 2 (stiff): $\\lambda = 5000$, integrate on $t \\in [0, 1.0]$ with $rtol = 10^{-6}$ and $atol = 10^{-12}$.\n- Case 3 (very stiff): $\\lambda = 50000$, integrate on $t \\in [0, 0.5]$ with $rtol = 10^{-6}$ and $atol = 10^{-12}$.\n\nImportant implementation notes:\n- The right-hand side is $f(t,y) = -\\lambda y$.\n- All computations are in dimensionless units; no physical units are required.\n- The initial value is $y(0)=1$ in all cases.\n- Do not evaluate the exact solution to guide the time steps; rely only on the solver’s adaptive control.\n- For comparability, do not supply any $t_{\\mathrm{eval}}$ grid; allow each solver to choose its own internal steps.\n\nOutput specification:\n- For each test case, output the ratio $R$ rounded to six decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order of the test cases listed above. For example, an output line with three results must look like\n$$\n[\\text{R}_{1},\\text{R}_{2},\\text{R}_{3}],\n$$\nwhere each $\\text{R}_{k}$ is a decimal number rounded to six digits after the decimal point.\n\nYour program must be a complete, runnable program that requires no user input and uses only the specified libraries.",
            "solution": "The problem as stated is valid. It is a well-posed, scientifically grounded exercise in computational physics that addresses the fundamental concept of stiffness in ordinary differential equations (ODEs). The parameters are clearly specified, and the task is unambiguous. We shall proceed with the solution.\n\nThe problem investigates the scalar initial value problem (IVP) given by the linear ODE:\n$$\n\\frac{dy}{dt} = -\\lambda y, \\quad y(0) = 1\n$$\nfor a positive parameter $\\lambda$. The exact solution is known to be $y(t) = e^{-\\lambda t}$. This equation serves as a canonical model for stiff systems.\n\nA system of ODEs is designated as \"stiff\" when its Jacobian matrix has eigenvalues that differ greatly in magnitude. For this scalar problem, the Jacobian is simply the derivative of the right-hand side with respect to $y$, which is $J = \\frac{\\partial}{\\partial y}(-\\lambda y) = -\\lambda$. The single eigenvalue is $-\\lambda$. When $\\lambda$ is large and positive, the corresponding solution component $e^{-\\lambda t}$ decays extremely rapidly. This fast-decaying mode imposes a severe stability constraint on explicit numerical integration methods.\n\nExplicit methods, such as the Runge-Kutta \"RK45\" method specified, compute the next state $y_{n+1}$ using only information from the current state $y_n$. Their stability is limited. For the model problem, the time step $\\Delta t$ for an explicit method must typically satisfy a condition of the form $\\Delta t \\cdot \\lambda \\lesssim C$, where $C$ is a constant of order unity that depends on the specific method. This means that to maintain numerical stability, the step size must be on the order of the fastest timescale in the system, $\\sim \\frac{1}{\\lambda}$, even long after the fast transient has decayed and the solution is varying smoothly. For large $\\lambda$, this forces the solver to take an exceedingly large number of very small steps, resulting in high computational cost. The adaptive step-size control in \"RK45\" will automatically reduce the step size to satisfy this stability requirement, leading to a large number of function evaluations, $N_{\\mathrm{fev}}^{\\mathrm{exp}}$.\n\nImplicit methods, such as the Backward Differentiation Formulae (\"BDF\"), offer a superior alternative for stiff problems. An implicit method determines the new state $y_{n+1}$ by solving an equation that involves $y_{n+1}$ itself, for example, $y_{n+1} = y_n + \\Delta t f(t_{n+1}, y_{n+1})$. For nonlinear $f$, this requires solving a system of equations at each time step, typically with a Newton-Raphson-type iterative method. The convergence of this iterative solver depends on the Jacobian of $f$. By providing the exact Jacobian, $J = -\\lambda$, we assist the solver in this task, avoiding the computational overhead and potential inaccuracy of finite-difference approximations. The primary advantage of implicit methods like BDF is their large stability region. They are \"A-stable\" or \"stiffly stable,\" meaning they can take large time steps limited only by the accuracy required to resolve the slow-varying components of the solution, not by stability constraints from the fast-decaying modes.\n\nIn this experiment, we will compare the number of function evaluations for \"RK45\" ($N_{\\mathrm{fev}}^{\\mathrm{exp}}$) and \"BDF\" ($N_{\\mathrm{fev}}^{\\mathrm{imp}}$) for increasing values of $\\lambda$. For the mildly stiff Case 1 ($\\lambda=50$), the explicit method may be reasonably efficient. However, as $\\lambda$ increases into the thousands (Cases 2 and 3), the problem becomes severely stiff. The \"RK45\" solver will be forced into a stability-limited regime, taking a vast number of steps. The \"BDF\" solver, unconstrained by stability, will be able to take much larger steps, dictated only by the specified tolerance, to trace the smooth solution after the initial rapid transient. Consequently, we anticipate that $N_{\\mathrm{fev}}^{\\mathrm{imp}}$ will be far smaller than $N_{\\mathrm{fev}}^{\\mathrm{exp}}$, and the ratio $R = N_{\\mathrm{fev}}^{\\mathrm{exp}} / N_{\\mathrm{fev}}^{\\mathrm{imp}}$ will grow significantly with $\\lambda$, demonstrating the profound inefficiency of explicit methods for stiff problems.\n\nThe implementation will utilize the `solve_ivp` function from the SciPy library. For each test case, we will configure and run the two solvers with identical tolerances and integration intervals, retrieve the number of function evaluations from the solver's output structure, and compute the specified ratio $R$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Solves the stiff ODE y' = -lambda*y for different lambda values,\n    comparing the performance of an explicit (RK45) and an implicit (BDF) solver.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (lambda_val, t_span, rtol, atol)\n    test_cases = [\n        (50.0, [0.0, 2.0], 1e-6, 1e-12),\n        (5000.0, [0.0, 1.0], 1e-6, 1e-12),\n        (50000.0, [0.0, 0.5], 1e-6, 1e-12)\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        lambda_val, t_span, rtol, atol = case\n\n        # The right-hand side of the ODE dy/dt = f(t, y)\n        # Using a lambda function to capture the current lambda_val\n        fun = lambda t, y: -lambda_val * y\n\n        # The Jacobian of the right-hand side, d(f)/d(y)\n        # solve_ivp expects the Jacobian as a 2-D array-like structure.\n        jac = lambda t, y: [[-lambda_val]]\n        \n        # Initial condition y(0) = 1.\n        # solve_ivp expects a 1-D array for the initial state.\n        y0 = [1.0]\n\n        # Integrate using the explicit \"RK45\" method\n        sol_exp = solve_ivp(\n            fun=fun,\n            t_span=t_span,\n            y0=y0,\n            method='RK45',\n            rtol=rtol,\n            atol=atol\n        )\n        n_fev_exp = sol_exp.nfev\n\n        # Integrate using the implicit \"BDF\" method, providing the exact Jacobian\n        sol_imp = solve_ivp(\n            fun=fun,\n            t_span=t_span,\n            y0=y0,\n            method='BDF',\n            rtol=rtol,\n            atol=atol,\n            jac=jac\n        )\n        n_fev_imp = sol_imp.nfev\n        \n        # Compute the ratio of function evaluations\n        if n_fev_imp  0:\n            ratio = n_fev_exp / n_fev_imp\n        else:\n            # Handle the unlikely case of zero evaluations to avoid division by zero\n            ratio = np.inf\n\n        # Format the result to six decimal places and add to the list\n        results.append(f\"{ratio:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}