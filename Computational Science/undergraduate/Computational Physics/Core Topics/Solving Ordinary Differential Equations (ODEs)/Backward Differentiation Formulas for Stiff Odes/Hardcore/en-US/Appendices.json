{
    "hands_on_practices": [
        {
            "introduction": "To truly master a numerical method, we must first understand its origins. This exercise guides you through the foundational process of deriving the coefficients for the fourth-order Backward Differentiation Formula (BDF-4) . By applying the method of undetermined coefficients, you will see how these formulas are constructed to be exact for polynomials, a core principle that underpins their accuracy.",
            "id": "2372656",
            "problem": "A single-step implicit linear multistep method known as the Backward Differentiation Formula (BDF) is widely used for stiff ordinary differential equations (ODEs). Consider the Backward Differentiation Formula (BDF) of order $4$ on a uniform grid with step size $h>0$. Assume it takes the linear multistep form\n$$\n\\sum_{j=0}^{4} \\alpha_{j}\\, y_{n+1-j} \\;=\\; h\\, f\\!\\left(t_{n+1},y_{n+1}\\right),\n$$\nwhere $y_{k}$ approximates $y(t_{k})$, and the method uses only backward-looking values $y_{n+1},y_{n},y_{n-1},y_{n-2},y_{n-3}$. The goal is to determine the coefficients $\\alpha_{0},\\alpha_{1},\\alpha_{2},\\alpha_{3},\\alpha_{4}$ by the method of undetermined coefficients applied to a backward-looking interpolating polynomial.\n\nStarting only from the core definition that an order-$4$ BDF must reproduce the exact relation for all polynomials of degree at most $4$ when $y$ solves $y^{\\prime}=f(t,y)$, derive the unique coefficients $\\alpha_{0},\\dots,\\alpha_{4}$ by imposing exactness conditions on monomials after the scaling $p(s)=y(t_{n+1}+s h)$, which places the backward nodes at $s=0,-1,-2,-3,-4$ and converts $h\\, y^{\\prime}(t_{n+1})$ into $p^{\\prime}(0)$.\n\nReport your final result as the row vector $\\left(\\alpha_{0},\\alpha_{1},\\alpha_{2},\\alpha_{3},\\alpha_{4}\\right)$ in exact rational form. No rounding is required and no units are involved.",
            "solution": "The problem requires the derivation of the coefficients $\\alpha_j$ for the $4$-th order Backward Differentiation Formula (BDF) given in the form:\n$$\n\\sum_{j=0}^{4} \\alpha_{j} y_{n+1-j} = h f(t_{n+1}, y_{n+1})\n$$\nThe method is to be of order $4$, which means it must be exact for any polynomial $y(t)$ of degree up to $4$. When $y(t)$ is a polynomial, its derivative $y'(t)$ is also a polynomial, and the differential equation $y' = f(t,y)$ becomes $y'(t) = f(t, y(t))$. Thus, the condition for exactness is:\n$$\n\\sum_{j=0}^{4} \\alpha_{j} y(t_{n+1-j}) = h y'(t_{n+1})\n$$\nfor any polynomial $y(t)$ of degree $k \\le 4$.\n\nAs suggested, we introduce a scaled, dimensionless time variable $s = \\frac{t - t_{n+1}}{h}$. With this substitution, the time points $t_{n+1-j} = t_{n+1} - jh$ correspond to $s = -j$ for $j=0, 1, 2, 3, 4$. Let $p(s) = y(t_{n+1} + sh)$. Then $y(t_{n+1-j}) = p(-j)$.\nThe derivative transforms as $y'(t) = \\frac{dp}{ds}\\frac{ds}{dt} = p'(s) \\frac{1}{h}$. At $t=t_{n+1}$, we have $s=0$, so $y'(t_{n+1}) = \\frac{1}{h} p'(0)$.\nSubstituting these into the exactness condition gives:\n$$\n\\sum_{j=0}^{4} \\alpha_{j} p(-j) = h \\left( \\frac{1}{h} p'(0) \\right) = p'(0)\n$$\nThis equation must hold for any polynomial $p(s)$ of degree up to $4$. We can enforce this condition on a basis for the space of polynomials of degree at most $4$, for which we choose the monomials $p(s) = s^k$ where $k \\in \\{0, 1, 2, 3, 4\\}$.\n\nFor each value of $k$, we obtain a linear equation for the coefficients $\\alpha_j$:\n1.  For $k=0$: $p(s) = s^0 = 1$. Then $p'(s) = 0$, so $p'(0)=0$.\n    The condition becomes $\\sum_{j=0}^{4} \\alpha_j (1) = 0$, which is:\n    $$\n    \\alpha_0 + \\alpha_1 + \\alpha_2 + \\alpha_3 + \\alpha_4 = 0\n    $$\n\n2.  For $k=1$: $p(s) = s^1 = s$. Then $p'(s) = 1$, so $p'(0)=1$.\n    The condition becomes $\\sum_{j=0}^{4} \\alpha_j (-j) = 1$, which is:\n    $$\n    0\\alpha_0 - 1\\alpha_1 - 2\\alpha_2 - 3\\alpha_3 - 4\\alpha_4 = 1\n    $$\n\n3.  For $k=2$: $p(s) = s^2$. Then $p'(s) = 2s$, so $p'(0)=0$.\n    The condition becomes $\\sum_{j=0}^{4} \\alpha_j (-j)^2 = 0$, which is:\n    $$\n    0\\alpha_0 + 1\\alpha_1 + 4\\alpha_2 + 9\\alpha_3 + 16\\alpha_4 = 0\n    $$\n\n4.  For $k=3$: $p(s) = s^3$. Then $p'(s) = 3s^2$, so $p'(0)=0$.\n    The condition becomes $\\sum_{j=0}^{4} \\alpha_j (-j)^3 = 0$, which is:\n    $$\n    0\\alpha_0 - 1\\alpha_1 - 8\\alpha_2 - 27\\alpha_3 - 64\\alpha_4 = 0\n    $$\n\n5.  For $k=4$: $p(s) = s^4$. Then $p'(s) = 4s^3$, so $p'(0)=0$.\n    The condition becomes $\\sum_{j=0}^{4} \\alpha_j (-j)^4 = 0$, which is:\n    $$\n    0\\alpha_0 + 1\\alpha_1 + 16\\alpha_2 + 81\\alpha_3 + 256\\alpha_4 = 0\n    $$\n\nWe have a system of $5$ linear equations for the $5$ unknown coefficients $(\\alpha_0, \\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4)$. Note that $\\alpha_0$ does not appear in equations $(2)$ through $(5)$. We can first solve the $4 \\times 4$ system for $\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4$ and then find $\\alpha_0$ from equation $(1)$.\n\nThe system for $\\alpha_1, \\dots, \\alpha_4$ is:\n(A) $-\\alpha_1 - 2\\alpha_2 - 3\\alpha_3 - 4\\alpha_4 = 1$\n(B) $\\alpha_1 + 4\\alpha_2 + 9\\alpha_3 + 16\\alpha_4 = 0$\n(C) $-\\alpha_1 - 8\\alpha_2 - 27\\alpha_3 - 64\\alpha_4 = 0$\n(D) $\\alpha_1 + 16\\alpha_2 + 81\\alpha_3 + 256\\alpha_4 = 0$\n\nWe solve this system by elimination.\nAdd (A) and (B):\n$$ (2\\alpha_2 + 6\\alpha_3 + 12\\alpha_4 = 1) \\quad (\\text{E}) $$\nAdd (B) and (C):\n$$ -4\\alpha_2 - 18\\alpha_3 - 48\\alpha_4 = 0 \\implies (2\\alpha_2 + 9\\alpha_3 + 24\\alpha_4 = 0) \\quad (\\text{F}) $$\nAdd (C) and (D):\n$$ 8\\alpha_2 + 54\\alpha_3 + 192\\alpha_4 = 0 \\implies (4\\alpha_2 + 27\\alpha_3 + 96\\alpha_4 = 0) \\quad (\\text{G}) $$\n\nNow we have a $3 \\times 3$ system for $\\alpha_2, \\alpha_3, \\alpha_4$.\nSubtract (E) from (F):\n$$ (3\\alpha_3 + 12\\alpha_4 = -1) \\quad (\\text{H}) $$\nSubtract $2 \\times (\\text{F})$ from (G):\n$$ (4\\alpha_2 + 27\\alpha_3 + 96\\alpha_4) - 2(2\\alpha_2 + 9\\alpha_3 + 24\\alpha_4) = 0 - 0 $$\n$$ 9\\alpha_3 + 48\\alpha_4 = 0 \\implies (3\\alpha_3 + 16\\alpha_4 = 0) \\quad (\\text{I}) $$\n\nNow we have a $2 \\times 2$ system for $\\alpha_3, \\alpha_4$.\nSubtract (H) from (I):\n$$ (3\\alpha_3 + 16\\alpha_4) - (3\\alpha_3 + 12\\alpha_4) = 0 - (-1) $$\n$$ 4\\alpha_4 = 1 \\implies \\alpha_4 = \\frac{1}{4} $$\n\nSubstitute $\\alpha_4 = \\frac{1}{4}$ into (I):\n$$ 3\\alpha_3 + 16\\left(\\frac{1}{4}\\right) = 0 \\implies 3\\alpha_3 + 4 = 0 \\implies \\alpha_3 = -\\frac{4}{3} $$\n\nSubstitute $\\alpha_3$ and $\\alpha_4$ into (E):\n$$ 2\\alpha_2 + 6\\left(-\\frac{4}{3}\\right) + 12\\left(\\frac{1}{4}\\right) = 1 $$\n$$ 2\\alpha_2 - 8 + 3 = 1 \\implies 2\\alpha_2 - 5 = 1 \\implies 2\\alpha_2 = 6 \\implies \\alpha_2 = 3 $$\n\nSubstitute $\\alpha_2, \\alpha_3, \\alpha_4$ into (A):\n$$ -\\alpha_1 - 2(3) - 3\\left(-\\frac{4}{3}\\right) - 4\\left(\\frac{1}{4}\\right) = 1 $$\n$$ -\\alpha_1 - 6 + 4 - 1 = 1 \\implies -\\alpha_1 - 3 = 1 \\implies \\alpha_1 = -4 $$\n\nFinally, use equation (1) to find $\\alpha_0$:\n$$ \\alpha_0 + (-4) + 3 + \\left(-\\frac{4}{3}\\right) + \\frac{1}{4} = 0 $$\n$$ \\alpha_0 - 1 - \\frac{4}{3} + \\frac{1}{4} = 0 $$\n$$ \\alpha_0 = 1 + \\frac{4}{3} - \\frac{1}{4} = \\frac{12}{12} + \\frac{16}{12} - \\frac{3}{12} = \\frac{25}{12} $$\n\nThe coefficients are:\n$\\alpha_0 = \\frac{25}{12}$\n$\\alpha_1 = -4$\n$\\alpha_2 = 3$\n$\\alpha_3 = -\\frac{4}{3}$\n$\\alpha_4 = \\frac{1}{4}$\n\nThe coefficients define the BDF4 formula with the specific normalization requested, which corresponds to the coefficient of $h f(t_{n+1}, y_{n+1})$ being $1$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{25}{12} & -4 & 3 & -\\frac{4}{3} & \\frac{1}{4}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Numerical methods often introduce subtle behaviors not present in the original physical system. In this practice, we investigate the concept of 'numerical damping' by applying the first-order BDF scheme to a frictionless harmonic oscillator, a system where energy should be conserved . Through both analytical derivation and numerical simulation, you will quantify this artificial energy dissipation and gain insight into the stability properties of BDF methods.",
            "id": "2374983",
            "problem": "Consider the frictionless harmonic oscillator governed by the ordinary differential equation (ODE) $y'' + y = 0$. Introduce the state vector $\\mathbf{z}(t) = \\begin{bmatrix} y(t) \\\\ v(t) \\end{bmatrix}$ with $v(t) = y'(t)$ so that the dynamics are written as a first-order linear system $\\,\\mathbf{z}'(t) = A \\mathbf{z}(t)$, where $A = \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}$. The Backward Differentiation Formula (BDF) of order one (Implicit Euler) with step size $h > 0$ is defined by the implicit update $\\mathbf{z}_{n+1} = \\mathbf{z}_n + h f(t_{n+1}, \\mathbf{z}_{n+1})$ applied to $\\mathbf{z}' = f(t, \\mathbf{z})$. Define the discrete mechanical energy at step $n$ as $E_n = \\tfrac{1}{2}\\left(y_n^2 + v_n^2\\right)$.\n\nYour tasks are:\n\n1) Starting solely from the definition of the BDF1 (Implicit Euler) scheme and the state-space formulation above, derive the one-step update in the form $\\mathbf{z}_{n+1} = G(h)\\,\\mathbf{z}_n$ for some $2\\times 2$ matrix $G(h)$ that depends only on $h$. Then, using only algebraic manipulations and the definition of $E_n$, derive an exact expression for the constant per-step energy damping factor $r(h)$ defined by $E_{n+1} = r(h)\\,E_n$. Your derivation must establish that $r(h)$ is independent of $n$ and of the particular state $\\mathbf{z}_n$.\n\n2) Implement a program that:\n- Initializes with $y(0) = 1$ and $v(0) = 0$, so that $E_0 = \\tfrac{1}{2}$.\n- Advances the solution using the BDF1 update for $N$ steps of fixed size $h$ to obtain $(y_N, v_N)$ and $E_N$.\n- Computes the measured per-step damping factor $\\hat{r}(h,N) = \\left(\\dfrac{E_N}{E_0}\\right)^{1/N}$.\n- Computes the analytically derived $r(h)$ from part 1).\n- Returns, for each test case, the absolute discrepancy $\\left|\\hat{r}(h,N) - r(h)\\right|$ as a floating-point number.\n\nYour program must run the following test suite:\n- Test case 1: $h = 0.1$, $N = 100$.\n- Test case 2: $h = 0.5$, $N = 40$.\n- Test case 3: $h = 1.0$, $N = 20$.\n- Test case 4: $h = 2.0$, $N = 10$.\n- Test case 5: $h = 10^{-6}$, $N = 100000$.\n\nAll numerical quantities are unitless. Angles, if any appear implicitly, are to be understood in radians.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases specified above (for example, $[x_1,x_2,x_3,x_4,x_5]$).\n- Each $x_i$ must be the absolute discrepancy $\\left|\\hat{r}(h_i,N_i) - r(h_i)\\right|$ as defined above, represented as a floating-point number.",
            "solution": "The problem is valid and will be addressed in two parts as requested: a formal derivation followed by a numerical implementation.\n\nThe dynamics of the frictionless harmonic oscillator are described by the first-order linear system $\\mathbf{z}'(t) = A \\mathbf{z}(t)$, with the state vector $\\mathbf{z}(t) = \\begin{bmatrix} y(t) \\\\ v(t) \\end{bmatrix}$ and the system matrix $A = \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}$. The Backward Differentiation Formula of order one (BDF1), or Implicit Euler method, advances the solution from step $n$ to $n+1$ using a step size $h > 0$ according to the implicit relation $\\mathbf{z}_{n+1} = \\mathbf{z}_n + hf(t_{n+1}, \\mathbf{z}_{n+1})$. For this linear system, $f(t, \\mathbf{z}) = A\\mathbf{z}$.\n\nFirst, we derive the one-step update matrix $G(h)$ for the transformation $\\mathbf{z}_{n+1} = G(h)\\mathbf{z}_n$. Substituting the system's right-hand side into the BDF1 formula yields:\n$$ \\mathbf{z}_{n+1} = \\mathbf{z}_n + h A \\mathbf{z}_{n+1} $$\nTo find an explicit expression for $\\mathbf{z}_{n+1}$, we must rearrange this equation. Grouping terms involving $\\mathbf{z}_{n+1}$ on the left-hand side gives:\n$$ \\mathbf{z}_{n+1} - h A \\mathbf{z}_{n+1} = \\mathbf{z}_n $$\nBy factoring out $\\mathbf{z}_{n+1}$ and using the $2 \\times 2$ identity matrix $I$, we obtain:\n$$ (I - hA) \\mathbf{z}_{n+1} = \\mathbf{z}_n $$\nPre-multiplying by the inverse of the matrix $(I - hA)$, assuming it is non-singular, we solve for $\\mathbf{z}_{n+1}$:\n$$ \\mathbf{z}_{n+1} = (I - hA)^{-1} \\mathbf{z}_n $$\nThis is the required form, with the one-step update matrix identified as $G(h) = (I - hA)^{-1}$. We now compute this matrix. The matrix $(I - hA)$ is:\n$$ I - hA = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} - h \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix} = \\begin{bmatrix} 1 & -h \\\\ h & 1 \\end{bmatrix} $$\nThe determinant is $\\det(I - hA) = (1)(1) - (-h)(h) = 1 + h^2$. Since $h$ is a real number, $1 + h^2 > 0$, so the inverse exists. Using the formula for the inverse of a $2 \\times 2$ matrix, we find:\n$$ G(h) = (I - hA)^{-1} = \\frac{1}{1+h^2} \\begin{bmatrix} 1 & h \\\\ -h & 1 \\end{bmatrix} $$\nThis completes the derivation of the update matrix $G(h)$.\n\nSecond, we derive the per-step energy damping factor $r(h)$. The discrete energy at step $n$ is $E_n = \\frac{1}{2}(y_n^2 + v_n^2)$, which can be expressed in vector notation as $E_n = \\frac{1}{2} \\mathbf{z}_n^T \\mathbf{z}_n$. The energy at step $n+1$ is $E_{n+1} = \\frac{1}{2} \\mathbf{z}_{n+1}^T \\mathbf{z}_{n+1}$. We substitute the update rule $\\mathbf{z}_{n+1} = G(h)\\mathbf{z}_n$ into this expression:\n$$ E_{n+1} = \\frac{1}{2} (G(h)\\mathbf{z}_n)^T (G(h)\\mathbf{z}_n) $$\nUsing the property of transposes $(AB)^T = B^T A^T$, this becomes:\n$$ E_{n+1} = \\frac{1}{2} \\mathbf{z}_n^T G(h)^T G(h) \\mathbf{z}_n $$\nThe structure of this equation suggests we analyze the matrix product $G(h)^T G(h)$. The transpose of $G(h)$ is:\n$$ G(h)^T = \\left( \\frac{1}{1+h^2} \\begin{bmatrix} 1 & h \\\\ -h & 1 \\end{bmatrix} \\right)^T = \\frac{1}{1+h^2} \\begin{bmatrix} 1 & -h \\\\ h & 1 \\end{bmatrix} $$\nThe product is then:\n$$ G(h)^T G(h) = \\left( \\frac{1}{1+h^2} \\right)^2 \\begin{bmatrix} 1 & -h \\\\ h & 1 \\end{bmatrix} \\begin{bmatrix} 1 & h \\\\ -h & 1 \\end{bmatrix} = \\frac{1}{(1+h^2)^2} \\begin{bmatrix} 1+h^2 & 0 \\\\ 0 & 1+h^2 \\end{bmatrix} $$\nFactoring the scalar $(1+h^2)$ from the matrix gives:\n$$ G(h)^T G(h) = \\frac{1+h^2}{(1+h^2)^2} \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = \\frac{1}{1+h^2} I $$\nThis shows that $G(h)^T G(h)$ is a scalar multiple of the identity matrix. Substituting this result back into the expression for $E_{n+1}$:\n$$ E_{n+1} = \\frac{1}{2} \\mathbf{z}_n^T \\left( \\frac{1}{1+h^2} I \\right) \\mathbf{z}_n = \\frac{1}{1+h^2} \\left( \\frac{1}{2} \\mathbf{z}_n^T I \\mathbf{z}_n \\right) = \\frac{1}{1+h^2} \\left( \\frac{1}{2} \\mathbf{z}_n^T \\mathbf{z}_n \\right) $$\nRecognizing that $E_n = \\frac{1}{2} \\mathbf{z}_n^T \\mathbf{z}_n$, we obtain the desired relation:\n$$ E_{n+1} = \\frac{1}{1+h^2} E_n $$\nThis is in the form $E_{n+1} = r(h)E_n$, where the energy damping factor is:\n$$ r(h) = \\frac{1}{1+h^2} $$\nThis expression depends solely on the step size $h$, establishing that it is constant for a fixed $h$ and independent of the step number $n$ or the state $\\mathbf{z}_n$. This completes the required derivation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by running the specified test suite for the BDF1 method\n    applied to a harmonic oscillator.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (h, N)\n        (0.1, 100),\n        (0.5, 40),\n        (1.0, 20),\n        (2.0, 10),\n        (1e-6, 100000),\n    ]\n\n    results = []\n    for h, N in test_cases:\n        # Main logic to calculate the result for one case goes here.\n\n        # 1. Initialization\n        # Initial state vector z_0 = [y(0), v(0)]^T\n        z_0 = np.array([1.0, 0.0])\n        # Initial energy E_0 = 0.5 * (y(0)^2 + v(0)^2)\n        E_0 = 0.5 * (z_0[0]**2 + z_0[1]**2)\n\n        # 2. Analytical damping factor from the derivation\n        r_analytic = 1.0 / (1.0 + h**2)\n\n        # 3. Numerical Simulation\n        # Construct the one-step update matrix G(h)\n        G_h = (1.0 / (1.0 + h**2)) * np.array([[1.0, h], [-h, 1.0]])\n\n        # Advance the solution for N steps\n        z_current = z_0\n        for _ in range(N):\n            z_current = G_h @ z_current\n        z_N = z_current\n\n        # Compute the final energy E_N\n        E_N = 0.5 * (z_N[0]**2 + z_N[1]**2)\n\n        # 4. Compute measured damping factor and discrepancy\n        # Measured per-step damping factor r_hat\n        if E_0 == 0.0:\n            # Avoid division by zero, though not possible with given initial state.\n            # If E_0 is 0, E_N will also be 0, so r_hat is indeterminate.\n            # In this problem context, E_0 is always 0.5.\n            r_hat = 0.0 # Placeholder, won't be reached\n        else:\n            # Using np.power for robust floating point exponentiation.\n            r_hat = np.power(E_N / E_0, 1.0 / N)\n\n        # Absolute discrepancy between measured and analytical factors\n        discrepancy = np.abs(r_hat - r_analytic)\n        results.append(discrepancy)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While higher-order methods promise greater accuracy, they can also introduce new challenges. This hands-on problem explores the phenomenon of 'ringing' or overshoot, a characteristic artifact of BDF methods of order three and higher when applied to stiff problems with sharp transients . By simulating a simple stiff Ordinary Differential Equation (ODE), you will observe this behavior and understand the practical stability limits that govern the choice of solver.",
            "id": "2374956",
            "problem": "You are given the initial value problem for a scalar, linear, stiff ordinary differential equation with a step-function forcing:\n$$\n\\frac{d y}{d t} = -\\lambda\\, y(t) + \\lambda\\, u(t), \\quad y(0)=0,\n$$\nwhere $u(t)$ is the Heaviside step function equal to $0$ for $t<0$ and $1$ for $t\\ge 0$, and $\\lambda>0$ is a constant with units of $\\mathrm{s}^{-1}$. For $t\\ge 0$ this can be written as\n$$\n\\frac{d y}{d t} = -\\lambda\\,(y(t)-1), \\quad y(0)=0.\n$$\nLet the uniform computational grid be $t_n = n h$ for $n=0,1,\\dots,N$ with $h>0$ and $N$ chosen such that $T = N h$ for a given final time $T>0$. Consider the linear multistep schemes defined by the backward differentiation formula (BDF) of order $k$, where the recurrence has the form\n$$\n\\sum_{j=0}^{k} \\alpha_j\\, y_{n-j} = h\\, \\beta_k f(t_n,y_n),\n$$\nwith $\\alpha_0=1$, $f(t,y) = -\\lambda\\,y + \\lambda$, and a method-specific coefficient $\\beta_k$. Use the following normalized coefficients for the specified orders:\n- For $k=2$: $\\alpha_1=-\\frac{4}{3}$, $\\alpha_2=\\frac{1}{3}$, and $\\beta_2 = 2/3$.\n- For $k=3$: $\\alpha_1=-\\frac{18}{11}$, $\\alpha_2=\\frac{9}{11}$, $\\alpha_3=-\\frac{2}{11}$, and $\\beta_3 = 6/11$.\n- For $k=4$: $\\alpha_1=-\\frac{48}{25}$, $\\alpha_2=\\frac{36}{25}$, $\\alpha_3=-\\frac{16}{25}$, $\\alpha_4=\\frac{3}{25}$, and $\\beta_4 = 12/25$.\n\nInitialize the multistep recurrence by setting the starting values to the exact solution at the grid points,\n$$\ny(t) = 1 - e^{-\\lambda t}, \\quad \\text{so that} \\quad y_n = 1 - e^{-\\lambda t_n},\n$$\nfor $n=0,1,\\dots,k-1$. Then, for $n=k,k+1,\\dots,N$, compute $y_n$ by solving the recurrence above at each step.\n\nDefine the overshoot amplitude as the nonnegative quantity\n$$\n\\Delta(k,\\lambda,h,T) = \\max\\left\\{\\,0,\\, \\max_{0\\le n\\le N} \\left(y_n - 1\\right)\\,\\right\\},\n$$\nwhich measures the maximum amount by which the computed solution exceeds the asymptotic value $1$ over the simulated time interval.\n\nYour program must compute $\\Delta(k,\\lambda,h,T)$ for each parameter set in the test suite below and produce a single line of output containing all results as a comma-separated list enclosed in square brackets, in the same order as listed. Each result must be reported as a decimal float rounded to six decimal places. The overshoot amplitude is dimensionless.\n\nTest suite:\n- Case 1 (baseline): $k=2$, $\\lambda=1000\\,\\mathrm{s}^{-1}$, $h=0.001\\,\\mathrm{s}$, $T=0.02\\,\\mathrm{s}$.\n- Case 2 (higher order, moderate step): $k=3$, $\\lambda=1000\\,\\mathrm{s}^{-1}$, $h=0.001\\,\\mathrm{s}$, $T=0.02\\,\\mathrm{s}$.\n- Case 3 (higher order, moderate step): $k=4$, $\\lambda=1000\\,\\mathrm{s}^{-1}$, $h=0.001\\,\\mathrm{s}$, $T=0.02\\,\\mathrm{s}$.\n- Case 4 (higher order, larger step): $k=3$, $\\lambda=1000\\,\\mathrm{s}^{-1}$, $h=0.002\\,\\mathrm{s}$, $T=0.02\\,\\mathrm{s}$.\n- Case 5 (higher order, small step): $k=4$, $\\lambda=1000\\,\\mathrm{s}^{-1}$, $h=0.0002\\,\\mathrm{s}$, $T=0.02\\,\\mathrm{s}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[r1,r2,r3,r4,r5]\"), where each $r_i$ is the overshoot amplitude for the corresponding case, rounded to six decimal places.",
            "solution": "The problem demands the computation of the overshoot amplitude, denoted $\\Delta(k,\\lambda,h,T)$, for Backward Differentiation Formula (BDF) schemes of order $k$ applied to a stiff ordinary differential equation.\n\nThe governing initial value problem is given by:\n$$\n\\frac{d y}{d t} = -\\lambda (y(t) - 1), \\quad y(0)=0\n$$\nwhere $\\lambda > 0$. The exact solution for $t \\ge 0$ is $y(t) = 1 - e^{-\\lambda t}$. The asymptotic value of the solution as $t \\to \\infty$ is $1$.\n\nThe BDF-$k$ scheme is a linear multistep method defined by the recurrence:\n$$\n\\sum_{j=0}^{k} \\alpha_j\\, y_{n-j} = h\\, \\beta_k f(t_n,y_n)\n$$\nwhere $y_n$ is the numerical approximation of $y(t_n)$ at time $t_n = n h$, $h$ is the time step, and the coefficients $\\{\\alpha_j\\}$ and $\\beta_k$ are given for $k=2,3,4$. The function $f(t,y)$ for this problem is $f(t_n,y_n) = -\\lambda (y_n - 1) = -\\lambda y_n + \\lambda$.\n\nTo implement the scheme, one must derive an explicit update rule for $y_n$. We begin with the BDF recurrence and substitute the expression for $f(t_n,y_n)$:\n$$\n\\sum_{j=0}^{k} \\alpha_j\\, y_{n-j} = h \\beta_k (-\\lambda y_n + \\lambda)\n$$\nWe expand the summation and isolate the term with $y_n$. Given $\\alpha_0=1$, the left side is:\n$$\n\\alpha_0 y_n + \\sum_{j=1}^{k} \\alpha_j\\, y_{n-j} = y_n + \\sum_{j=1}^{k} \\alpha_j\\, y_{n-j}\n$$\nSetting the two expressions equal:\n$$\ny_n + \\sum_{j=1}^{k} \\alpha_j\\, y_{n-j} = -h \\lambda \\beta_k y_n + h \\lambda \\beta_k\n$$\nWe move all terms containing $y_n$ to the left-hand side and all other terms to the right-hand side:\n$$\ny_n + h \\lambda \\beta_k y_n = h \\lambda \\beta_k - \\sum_{j=1}^{k} \\alpha_j\\, y_{n-j}\n$$\nFactoring out $y_n$ yields the final explicit formula for each step:\n$$\ny_n = \\frac{h \\lambda \\beta_k - \\sum_{j=1}^{k} \\alpha_j\\, y_{n-j}}{1 + h \\lambda \\beta_k}\n$$\nThis equation allows for the direct computation of $y_n$ from the $k$ previous values $y_{n-1}, y_{n-2}, \\dots, y_{n-k}$.\n\nThe computational procedure is as follows:\n1.  Define the computational grid. Given the final time $T$ and step size $h$, the number of steps is $N = \\text{round}(T/h)$. The discrete time points are $t_n = n h$ for $n=0, 1, \\dots, N$.\n2.  Initialize the solution vector. A $k$-step method requires $k$ starting values, $y_0, y_1, \\dots, y_{k-1}$. The problem specifies using the exact solution for this purpose:\n    $$\n    y_n = 1 - e^{-\\lambda t_n} \\quad \\text{for } n = 0, 1, \\dots, k-1\n    $$\n3.  Iteratively compute the solution. For each time step from $n=k$ to $N$, calculate $y_n$ using the derived recurrence relation. The historical values $y_{n-1}, \\dots, y_{n-k}$ are known from previous steps.\n4.  Calculate the overshoot amplitude. After computing the full numerical solution vector $\\{y_n\\}_{n=0}^N$, the maximum overshoot is found by first determining the maximum value by which the solution exceeds its asymptotic limit of $1$:\n    $$\n    \\max_{0 \\le n \\le N} (y_n - 1)\n    $$\n    The overshoot amplitude $\\Delta$ is defined as the maximum of this quantity and zero, ensuring it is non-negative:\n    $$\n    \\Delta(k,\\lambda,h,T) = \\max\\left\\{0, \\max_{0\\le n\\le N} (y_n - 1)\\right\\}\n    $$\n\nThe provided code implements this precise algorithm. A function is defined to execute the simulation for a given set of parameters $(k, \\lambda, h, T)$, which computes the sequence $\\{y_n\\}$ and then determines the overshoot amplitude $\\Delta$. This function is called for each test case specified in the problem statement, and the results are collected and formatted as required.",
            "answer": "```python\nimport numpy as np\n\ndef calculate_overshoot(k, lam, h, T, alpha_coeffs, beta_k):\n    \"\"\"\n    Computes the overshoot amplitude for a BDF-k scheme on a stiff ODE.\n\n    Args:\n        k (int): Order of the BDF method.\n        lam (float): Stiffness parameter lambda.\n        h (float): Time step size.\n        T (float): Final time.\n        alpha_coeffs (list): List of BDF alpha coefficients [alpha_0, ..., alpha_k].\n        beta_k (float): The BDF beta coefficient for order k.\n\n    Returns:\n        float: The computed overshoot amplitude.\n    \"\"\"\n    # Determine the number of steps and create the solution array\n    # Using round() to handle potential floating point inaccuracies in T/h\n    N = int(round(T / h))\n    y = np.zeros(N + 1)\n\n    # Step 1: Initialize the first k values using the exact solution\n    # y_n = 1 - exp(-lambda * t_n) for n = 0, ..., k-1\n    for n in range(k):\n        t_n = n * h\n        y[n] = 1.0 - np.exp(-lam * t_n)\n\n    # Step 2: Time-stepping loop from n=k to N\n    # The recurrence is y_n = (h*lambda*beta_k - sum_{j=1 to k} alpha_j*y_{n-j}) / (1 + h*lambda*beta_k)\n    z = lam * h * beta_k\n    denominator = 1.0 + z\n\n    for n in range(k, N + 1):\n        # Compute the summation term from historical values\n        historical_sum = 0.0\n        for j in range(1, k + 1):\n            historical_sum += alpha_coeffs[j] * y[n - j]\n\n        # Apply the update rule to find y_n\n        y[n] = (z - historical_sum) / denominator\n\n    # Step 3: Calculate the overshoot amplitude\n    # Delta = max{0, max_{0=n=N} (y_n - 1)}\n    max_overshoot = 0.0\n    if len(y) > 0:\n        max_y = np.max(y)\n        max_overshoot = max(0.0, max_y - 1.0)\n    \n    return max_overshoot\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement\n    # Each tuple is (k, lambda, h, T)\n    test_cases = [\n        (2, 1000.0, 0.001, 0.02),\n        (3, 1000.0, 0.001, 0.02),\n        (4, 1000.0, 0.001, 0.02),\n        (3, 1000.0, 0.002, 0.02),\n        (4, 1000.0, 0.0002, 0.02),\n    ]\n\n    # BDF coefficients {alpha_j} for j=0 to k, with alpha_0 = 1\n    bdf_alpha_coeffs = {\n        2: [1.0, -4.0/3.0, 1.0/3.0],\n        3: [1.0, -18.0/11.0, 9.0/11.0, -2.0/11.0],\n        4: [1.0, -48.0/25.0, 36.0/25.0, -16.0/25.0, 3.0/25.0]\n    }\n    bdf_beta_coeffs = {\n        2: 2.0/3.0,\n        3: 6.0/11.0,\n        4: 12.0/25.0,\n    }\n\n    results = []\n    for k, lam, h, T in test_cases:\n        # Run simulation for each case\n        overshoot = calculate_overshoot(k, lam, h, T, bdf_alpha_coeffs[k], bdf_beta_coeffs[k])\n        results.append(overshoot)\n\n    # Final print statement in the exact required format.\n    # Each result is formatted to six decimal places.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}