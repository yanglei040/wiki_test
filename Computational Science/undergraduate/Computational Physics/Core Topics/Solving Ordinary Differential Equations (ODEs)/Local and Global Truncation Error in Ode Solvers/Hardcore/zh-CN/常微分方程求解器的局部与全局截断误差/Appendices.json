{
    "hands_on_practices": [
        {
            "introduction": "理解截断误差的第一步是在实践中观察它。本练习将让你实现两种最著名的常微分方程（ODE）求解器：简单的一阶欧拉方法和更复杂的四阶龙格-库塔方法。通过将它们应用于一个具有已知精确解的基本问题，你将能够凭经验测量全局误差，并验证理论上的“精度阶数”，从而巩固误差随步长 $h$ 的幂（$h^p$）减小的核心概念 。",
            "id": "2447459",
            "problem": "您需要为常微分方程 $y^{\\prime}(t)=-y(t)$（初始条件为 $y(0)=1$，区间为 $t\\in[0,1]$）所定义的初值问题，实现并分析两种单步数值积分方法。该问题的精确解为 $y(t)=e^{-t}$。您的任务是通过控制步长和浮点格式，比较截断误差的阶数，并揭示截断误差与舍入误差之间的相互作用。请从基本定义出发：局部截断误差是当方法应用于精确解时，单步计算所产生的误差；全局误差是数值解与精确解在最终时刻的偏差。仅使用显式 Euler 方法和经典四阶 Runge–Kutta 方法的定义；不要假设任何预先推导出的误差阶数公式。您应基于泰勒展开和单步法的一致性来推断误差阶数，然后通过计算进行验证。\n\n实现以下组件：\n- 一个使用显式 Euler 方法推进单步的函数，以及另一个使用经典四阶 Runge–Kutta 方法的函数。每个积分器必须在指定的浮点格式下运行：`binary64`（双精度）和 `binary32`（单精度）。\n- 一个驱动程序，对于给定的步长 $h$（其中 $1/h$ 为整数），从 $t=0$ 和 $y(0)=1$ 开始，应用所选方法计算到 $t=1$，并返回在 $t=1$ 时的绝对全局误差，即 $\\lvert y_{N}-e^{-1}\\rvert$，其中 $N=1/h$。\n- 一个函数，通过对给定步长列表的 $\\log(\\text{error})$ 与 $\\log(h)$ 数据进行最小二乘法线性拟合，来估计观测到的精度阶。\n\n设计您的实现时，请确保数值更新、常数和中间量均在所要求的浮点格式下计算。在计算误差时，使用 `binary64` 格式的精确解 $y(1)=e^{-1}$ 作为参考值。\n\n测试套件：\n使用指定的步长和格式，按以下确切顺序计算六个结果：\n1. 在 `binary64` 格式下，使用显式 Euler 方法和步长 $h=0.1$ 计算得到的在 $t=1$ 时的绝对全局误差。\n2. 在 `binary64` 格式下，使用经典四阶 Runge–Kutta 方法和步长 $h=0.1$ 计算得到的在 $t=1$ 时的绝对全局误差。\n3. 在 `binary64` 格式下，根据步长 $h\\in\\{0.2,0.1,0.05,0.025\\}$ 估计出的显式 Euler 方法的观测精度阶。\n4. 在 `binary64` 格式下，根据步长 $h\\in\\{0.2,0.1,0.05,0.025\\}$ 估计出的经典四阶 Runge–Kutta 方法的观测精度阶。\n5. 在 `binary32` 格式下，使用经典四阶 Runge–Kutta 方法，为步长 $h\\in\\{2^{-3},2^{-5},2^{-7},2^{-9},2^{-11},2^{-13}\\}$ 计算在 $t=1$ 时的绝对全局误差。返回误差在该列表上达到最小值时的从零开始的索引 $k^{\\ast}$。该索引应反映截断误差和舍入误差达到平衡时的步长。\n6. 在 `binary64` 格式下，使用经典四阶 Runge–Kutta 方法，为步长 $h\\in\\{2^{-6},2^{-7},2^{-8},2^{-9}\\}$ 计算在 $t=1$ 时的绝对全局误差。返回一个布尔值，表示这些误差是否随着 $h$ 的减小而严格递减。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内含六个结果，顺序与上文指定完全一致。该列表必须包含前两个误差（两个浮点数）、两个观测阶数（两个浮点数）、一个索引（一个整数）和一个单调性检查结果（一个布尔值），总共六个条目。",
            "solution": "所给出的问题是常微分方程数值分析中的一个标准练习。它在科学上是合理的、适定的，并包含了完整求解所需的所有信息。我们将着手进行分析和实现。\n\n我们所考虑的初值问题 (IVP) 由以下常微分方程 (ODE) 给出：\n$$\ny^{\\prime}(t) = -y(t), \\quad t \\in [0, 1]\n$$\n初始条件为 $y(0) = 1$。该初值问题的解析解为 $y(t) = e^{-t}$。我们的任务是使用两种不同的单步法对该问题进行数值求解，并分析其误差特性。\n\n对于初值问题 $y^{\\prime}(t) = f(t, y(t))$，一个通用的单步法在离散时间点 $t_n = t_0 + nh$（其中 $h$ 是步长）上逼近其解。数值解 $y_n \\approx y(t_n)$ 通过以下形式的公式从一步推进到下一步：\n$$\ny_{n+1} = y_n + h \\Phi(t_n, y_n, h)\n$$\n其中 $\\Phi$ 是定义该方法的增量函数。\n\n第一种方法是显式 Euler 方法。它由 $y(t_{n+1})$ 在 $t_n$ 处的一阶泰勒展开推导而来：\n$$\ny(t_{n+1}) = y(t_n) + h y^{\\prime}(t_n) + \\mathcal{O}(h^2)\n$$\n通过代入 $y^{\\prime}(t_n) = f(t_n, y(t_n))$ 并截断 $\\mathcal{O}(h^2)$ 及更高阶的项，我们得到该方法：\n$$\ny_{n+1} = y_n + h f(t_n, y_n)\n$$\n对于给定的问题，$f(t, y) = -y$，因此显式 Euler 方法的更新规则是：\n$$\ny_{n+1} = y_n - h y_n = (1 - h) y_n\n$$\n\n第二种方法是经典四阶 Runge–Kutta 方法 (RK4)。它由以下方程组定义：\n$$\ny_{n+1} = y_n + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)\n$$\n其中各阶段 $k_i$ 的计算方式如下：\n$$\n\\begin{aligned}\nk_1 = f(t_n, y_n) \\\\\nk_2 = f\\left(t_n + \\frac{h}{2}, y_n + \\frac{h}{2}k_1\\right) \\\\\nk_3 = f\\left(t_n + \\frac{h}{2}, y_n + \\frac{h}{2}k_2\\right) \\\\\nk_4 = f(t_n + h, y_n + h k_3)\n\\end{aligned}\n$$\n对于我们的问题，$f(t, y) = -y$，这些阶段变为：\n$$\n\\begin{aligned}\nk_1 = -y_n \\\\\nk_2 = -\\left(y_n + \\frac{h}{2}(-y_n)\\right) = -y_n\\left(1 - \\frac{h}{2}\\right) \\\\\nk_3 = -\\left(y_n + \\frac{h}{2}k_2\\right) = -y_n\\left(1 - \\frac{h}{2} + \\frac{h^2}{4}\\right) \\\\\nk_4 = -(y_n + hk_3) = -y_n\\left(1 - h + \\frac{h^2}{2} - \\frac{h^3}{4}\\right)\n\\end{aligned}\n$$\n将这些代入 RK4 公式并化简可得：\n$$\ny_{n+1} = y_n\\left(1 - h + \\frac{h^2}{2} - \\frac{h^3}{6} + \\frac{h^4}{24}\\right)\n$$\n这个表达式恰好是 $y_n e^{-h}$ 泰勒级数展开的前五项，因为 $e^{-h} = 1 - h + \\frac{h^2}{2!} - \\frac{h^3}{3!} + \\frac{h^4}{4!} - \\frac{h^5}{5!} + \\dots$。\n\n数值方法的精度由其阶数来表征。局部截断误差 (LTE) 是假设方法从精确解 $y(t_n)$ 开始，在单步计算中引入的误差。对于一个 $p$ 阶方法，其局部截断误差为 $\\mathcal{O}(h^{p+1})$。而全局误差，即在积分区间末端的累积误差，则为 $\\mathcal{O}(h^p)$。\n\n对于显式 Euler 方法，其局部截断误差为：\n$$\nLTE_{n+1} = y(t_{n+1}) - \\left[y(t_n) + h f(t_n, y(t_n))\\right] = \\left[y(t_n) + h y^{\\prime}(t_n) + \\frac{h^2}{2}y^{\\prime\\prime}(\\xi)\\right] - \\left[y(t_n) + h y^{\\prime}(t_n)\\right] = \\frac{h^2}{2}y^{\\prime\\prime}(\\xi)\n$$\n其中某个 $\\xi \\in (t_n, t_{n+1})$。局部截断误差为 $\\mathcal{O}(h^2)$，这意味着 Euler 方法是一阶精度的，因此其全局误差行为符合 $\\mathcal{O}(h^1)$。\n\n对于 RK4 方法，针对我们特定问题的更新规则与 $e^{-h}$ 的泰勒级数在 $h^4$ 项之前都相匹配。因此，单步误差由级数中的下一项主导：\n$$\nLTE_{n+1} = y(t_n)e^{-h} - y(t_n)\\left(1 - h + \\frac{h^2}{2} - \\frac{h^3}{6} + \\frac{h^4}{24}\\right) = y(t_n)\\left(-\\frac{h^5}{120} + \\mathcal{O}(h^6)\\right)\n$$\n局部截断误差为 $\\mathcal{O}(h^5)$，因此 RK4 方法是四阶精度的，其全局误差行为符合 $\\mathcal{O}(h^4)$。\n\n为了通过计算验证阶数 $p$，我们假设最终时刻的全局误差 $E$ 服从 $E \\approx C h^p$ 的关系，其中 $C$ 为某个常数。对两边取对数可得：\n$$\n\\log(E) \\approx \\log(C) + p \\log(h)\n$$\n这表明 $\\log(E)$ 和 $\\log(h)$ 之间存在线性关系，其斜率即为精度阶 $p$。我们可以通过计算一系列步长对应的误差，并对双对数数据进行线性最小二乘拟合来估计 $p$。\n\n最后，我们必须考虑有限精度算术的影响。总数值误差是截断误差（来自方法的近似）和舍入误差（来自浮点表示）之和。截断误差随着 $h$ 的减小而减小（例如，$\\propto h^p$）。然而，舍入误差则倾向于随着步数 $N = T/h$ 的增加而累积。累积的舍入误差可以建模为与 $\\epsilon/h$ 成正比，其中 $\\epsilon$ 是浮点格式的机器精度。总误差近似为：\n$$\nE_{total} \\approx C h^p + \\frac{D\\epsilon}{h}\n$$\n该函数在某个最优步长 $h^*$ 处有最小值。当 $h > h^*$ 时，截断误差占主导，误差随 $h$ 减小而减小。当 $h  h^*$ 时，舍入误差占主导，误差随 $h$ 减小而增大。这种效应在单精度（`binary32`，$\\epsilon \\approx 10^{-8}$）中比在双精度（`binary64`，$\\epsilon \\approx 10^{-16}$）中更显著，因为更大的 $\\epsilon$ 会导致更大的最优步长 $h^*$。这正是测试用例旨在探究的内容。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef euler_step(y, h, dtype):\n    \"\"\"\n    Performs one step of the explicit Euler method for y' = -y.\n    All calculations are performed in the specified dtype.\n    \n    Args:\n        y: Current value of the solution (of type dtype).\n        h: Step size (Python float).\n        dtype: The numpy floating-point type (np.float32 or np.float64).\n        \n    Returns:\n        The next value of the solution (of type dtype).\n    \"\"\"\n    h_typed = dtype(h)\n    one = dtype(1.0)\n    # The update is y_{n+1} = y_n * (1 - h)\n    return y * (one - h_typed)\n\ndef rk4_step(y, h, dtype):\n    \"\"\"\n    Performs one step of the classical 4th-order Runge-Kutta method for y' = -y.\n    All calculations are performed in the specified dtype.\n    \n    Args:\n        y: Current value of the solution (of type dtype).\n        h: Step size (Python float).\n        dtype: The numpy floating-point type (np.float32 or np.float64).\n        \n    Returns:\n        The next value of the solution (of type dtype).\n    \"\"\"\n    h_typed = dtype(h)\n    \n    # Define constants in the target precision\n    c_half = dtype(0.5)\n    c_two = dtype(2.0)\n    c_six = dtype(6.0)\n\n    # ODE is y' = f(y) = -y\n    k1 = -y\n    k2 = -(y + c_half * h_typed * k1)\n    k3 = -(y + c_half * h_typed * k2)\n    k4 = -(y + h_typed * k3)\n    \n    return y + (h_typed / c_six) * (k1 + c_two * k2 + c_two * k3 + k4)\n\ndef solve_ode(step_func, h, dtype):\n    \"\"\"\n    Solves the ODE y'=-y from t=0 to t=1 with y(0)=1.\n    \n    Args:\n        step_func: The function for a single integration step (e.g., euler_step).\n        h: The step size.\n        dtype: The numpy floating-point type for computation.\n        \n    Returns:\n        The absolute global error at t=1.\n    \"\"\"\n    # The problem statement guarantees 1/h is an integer.\n    # Use round() to be robust against floating point inaccuracies, e.g., 1.0/0.1\n    num_steps = int(round(1.0 / h))\n    \n    # Initial condition y(0)=1, cast to the specified precision\n    y = dtype(1.0)\n\n    for _ in range(num_steps):\n        y = step_func(y, h, dtype)\n\n    # Reference solution y(1)=e^-1 in double precision (binary64)\n    y_exact_64 = np.exp(np.float64(-1.0))\n    \n    # Error is computed against the high-precision reference.\n    # The subtraction will promote the result to float64, which is desired.\n    return np.abs(y - y_exact_64)\n\ndef estimate_order(step_func, h_list, dtype):\n    \"\"\"\n    Estimates the order of accuracy of a method by log-log linear regression.\n    \n    Args:\n        step_func: The single-step integration function.\n        h_list: A list of step sizes to use.\n        dtype: The numpy floating-point type.\n        \n    Returns:\n        The estimated order of accuracy (slope of the log-log plot).\n    \"\"\"\n    h_array = np.array(h_list, dtype=np.float64)\n    errors = np.array([solve_ode(step_func, h, dtype) for h in h_list], dtype=np.float64)\n\n    log_h = np.log(h_array)\n    log_err = np.log(errors)\n\n    # Perform linear least squares to find the slope p\n    # of the line log(error) = log(C) + p * log(h)\n    # Using the standard formula for the slope of a simple linear regression.\n    n = len(log_h)\n    sum_xy = np.sum(log_h * log_err)\n    sum_x = np.sum(log_h)\n    sum_y = np.sum(log_err)\n    sum_x2 = np.sum(log_h**2)\n    \n    slope_p = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x**2)\n    return slope_p\n\ndef solve():\n    \"\"\"\n    Main function to compute the six required results for the test suite.\n    \"\"\"\n    # Test 1: Global error for Euler, h=0.1, binary64\n    error1 = solve_ode(euler_step, 0.1, np.float64)\n\n    # Test 2: Global error for RK4, h=0.1, binary64\n    error2 = solve_ode(rk4_step, 0.1, np.float64)\n\n    # Test 3: Observed order for Euler, binary64\n    h_order_list = [0.2, 0.1, 0.05, 0.025]\n    order3 = estimate_order(euler_step, h_order_list, np.float64)\n\n    # Test 4: Observed order for RK4, binary64\n    order4 = estimate_order(rk4_step, h_order_list, np.float64)\n    \n    # Test 5: Index of minimum error for RK4, binary32 (truncation vs. round-off)\n    h_balance_list = [2.0**-k for k in [3, 5, 7, 9, 11, 13]]\n    errors_balance = [solve_ode(rk4_step, h, np.float32) for h in h_balance_list]\n    index5 = np.argmin(errors_balance)\n    \n    # Test 6: Monotonicity check for RK4, binary64\n    h_mono_list = [2.0**-k for k in [6, 7, 8, 9]]\n    errors_mono = [solve_ode(rk4_step, h, np.float64) for h in h_mono_list]\n    # Check if errors are strictly decreasing: e[i] > e[i+1] for all i\n    bool6 = all(np.diff(errors_mono)  0)\n\n    results = [error1, error2, order3, order4, index5, bool6]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在第一个实践的基础上，本练习探讨了一个重要思想：并非所有误差都是一样的。对于像振荡器这样的物理系统，误差的*定性性质*至关重要。本练习将一个非保守积分方法（欧拉法）与一个辛积分方法（蛙跳法）进行对比，以揭示全局截断误差如何表现为能量的非物理增长（振幅误差）或时间上的漂移（相位误差） 。",
            "id": "2409167",
            "problem": "考虑由常微分方程 (ODE) $m\\,\\ddot{x}(t)+k\\,x(t)=0$ 控制的无阻尼简谐振子 (SHO)，其中 $m$ 是质量，$k$ 是刚度。设 $m=k=1$，因此角频率为 $\\omega=\\sqrt{k/m}=1$ (单位：弧度/秒)。使用初始条件 $x(0)=A$ 和 $v(0)=\\dot{x}(0)=0$，振幅 $A=1$ (单位：米)。精确位移为 $x_{\\text{exact}}(t)=A\\cos(\\omega t)$，精确速度为 $v_{\\text{exact}}(t)=-A\\,\\omega\\sin(\\omega t)$。研究两种单步时间积分器——显式欧拉法和蛙跳法——的全局截断误差 (GTE) 和局部截断误差 (LTE) 在此系统中的表现。显式欧拉法的更新规则定义如下\n$$\nx_{n+1}=x_n+h\\,v_n,\\quad v_{n+1}=v_n-h\\,\\omega^2\\,x_n,\n$$\n其中 $h$ 是固定时间步长，$n\\in\\{0,1,2,\\dots,N-1\\}$，且 $t_n=n\\,h$ 及 $t_N=T=N\\,h$。蛙跳法（速度Verlet形式）定义如下\n$$\na_n=-\\omega^2 x_n,\\quad v_{n+\\frac{1}{2}}=v_n+\\frac{h}{2}a_n,\\quad x_{n+1}=x_n+h\\,v_{n+\\frac{1}{2}},\n$$\n$$\na_{n+1}=-\\omega^2 x_{n+1},\\quad v_{n+1}=v_{n+\\frac{1}{2}}+\\frac{h}{2}a_{n+1}.\n$$\n对于每种方法，使用均匀时间步长 $h$ 从 $t=0$ 积分到 $t=T$，使得 $T=N\\,h$ (其中 $N$ 为某个整数)。\n\n将显式欧拉法在 $t=T$ 时的振幅误差定义为\n$$\nE_A=\\sqrt{x_N^2+\\left(\\frac{v_N}{\\omega}\\right)^2}-A,\n$$\n单位为米。将蛙跳法在 $t=T$ 时的有符号相位误差定义为\n$$\nE_\\phi=\\operatorname{wrap}_{(-\\pi,\\pi]}\\!\\left(\\theta_{\\text{num}}-\\theta_{\\text{exact}}\\right),\n$$\n其中数值相位为\n$$\n\\theta_{\\text{num}}=\\operatorname{atan2}\\!\\left(-\\frac{v_N}{\\omega},\\,x_N\\right),\n$$\n精确相位为 $\\theta_{\\text{exact}}=\\omega T$，且 $\\operatorname{wrap}_{(-\\pi,\\pi]}(\\alpha)$ 通过加或减 $2\\pi$ 的整数倍，将任意实数 $\\alpha$ 映射到其在 $(-\\pi,\\pi]$ 区间内的代表值。角度单位必须是弧度。\n\n你的程序必须根据上述定义，为下述每个测试用例计算出数据对 $[E_A,E_\\phi]$，其中 $E_A$ 的单位为米，$E_\\phi$ 的单位为弧度。所有用例均使用 $A=1$ (单位：米) 和 $\\omega=1$ (单位：弧度/秒)。测试套件包含以下参数集，每组由 $(h,T)$ (单位：秒) 指定，且 $T=N\\,h$：\n- 用例 1：$h=0.1$, $T=50$。\n- 用例 2：$h=0.01$, $T=50$。\n- 用例 3：$h=0.5$, $T=50$。\n\n最终输出格式：你的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。列表中的每个元素是对应一个用例的双项列表 $[E_A,E_\\phi]$，顺序与上文一致。例如，一个有效的格式为 $[[\\dots,\\dots],[\\dots,\\dots],[\\dots,\\dots]]$。角度单位必须是弧度，距离单位必须是米。不应打印任何额外文本。",
            "solution": "所提出的问题是有效的。这是一个定义明确、具有科学依据的计算物理问题，旨在研究两种标准常微分方程数值积分器的基本误差特性。所有参数、条件和定义均已提供，且不存在内部矛盾或逻辑缺陷。我们将着手求解。\n\n该问题要求分析应用于简谐振子 (SHO) 的两种数值积分方案：显式欧拉法和蛙跳法。其运动控制方程为\n$$\nm\\,\\ddot{x}(t) + k\\,x(t) = 0\n$$\n在给定参数下，质量 $m=1$，刚度 $k=1$，角频率为 $\\omega = \\sqrt{k/m} = 1\\,\\text{rad/s}$。该系统由状态向量 $(x(t), v(t))$ 描述，其中 $v(t) = \\dot{x}(t)$。初始条件为 $x(0) = A = 1$ 和 $v(0) = 0$。其精确解由下式给出\n$$\nx_{\\text{exact}}(t) = A\\cos(\\omega t) \\quad \\text{and} \\quad v_{\\text{exact}}(t) = -A\\omega\\sin(\\omega t)\n$$\n系统的总能量 $E = \\frac{1}{2}mv^2 + \\frac{1}{2}kx^2$ 是一个守恒量。对于给定参数，总能量为 $E(t) = \\frac{1}{2}(v(t)^2 + x(t)^2)$。初始能量为 $E(0) = \\frac{1}{2}(0^2 + 1^2) = 1/2$。振荡的振幅通过 $A = \\sqrt{x^2 + (v/\\omega)^2}$ 与能量相关。因此，能量守恒等价于振幅守恒。\n\n我们现在将分析每种指定数值方法的行为。\n\n**显式欧拉法**\n\n显式欧拉法是一种一阶积分器。对于SHO，其加速度为 $a(t) = \\ddot{x}(t) = -\\omega^2 x(t)$，更新规则如下：\n$$\nx_{n+1} = x_n + h\\,v_n\n$$\n$$\nv_{n+1} = v_n + h\\,a_n = v_n - h\\,\\omega^2\\,x_n\n$$\n其中 $h$ 是时间步长。此方法不是辛方法，对于振荡系统，它会人为地随时间增加系统能量，因此是数值不稳定的。让我们分析在第 $n+1$ 步的数值能量：\n$$\nE_{n+1} = \\frac{1}{2}(v_{n+1}^2 + \\omega^2 x_{n+1}^2) = \\frac{1}{2}((v_n - h\\omega^2 x_n)^2 + \\omega^2(x_n + h v_n)^2)\n$$\n展开各项，我们得到：\n$$\nE_{n+1} = \\frac{1}{2}(v_n^2 - 2h\\omega^2 x_n v_n + h^2\\omega^4 x_n^2 + \\omega^2(x_n^2 + 2h x_n v_n + h^2 v_n^2))\n$$\n$$\nE_{n+1} = \\frac{1}{2}(v_n^2 + h^2\\omega^4 x_n^2 + \\omega^2 x_n^2 + \\omega^2 h^2 v_n^2) = \\frac{1}{2}((1+\\omega^2h^2)v_n^2 + \\omega^2(1+\\omega^2h^2)x_n^2)\n$$\n$$\nE_{n+1} = (1+\\omega^2h^2) \\left(\\frac{1}{2}(v_n^2 + \\omega^2 x_n^2)\\right) = (1+\\omega^2h^2)E_n\n$$\n经过 $N$ 步到达时间 $T=N\\,h$ 后，能量变为 $E_N = (1+\\omega^2h^2)^N E_0$。由于振幅为 $A = \\sqrt{2E/\\omega^2}$，第 $N$ 步的数值振幅 $A_N$ 与初始振幅 $A_0$ 的关系如下：\n$$\nA_N = A_0 (1+\\omega^2h^2)^{N/2}\n$$\n因此，振幅误差 $E_A = A_N - A_0$ 由 $E_A = A_0 \\left[(1+\\omega^2h^2)^{N/2} - 1\\right]$ 给出。这表明振幅呈指数增长，这是此方法用于保守系统时不稳定的一个标志。振幅误差 $E_A$ 按规定使用最终状态 $(x_N, v_N)$ 计算：$E_A = \\sqrt{x_N^2 + (v_N/\\omega)^2} - A$。\n\n**蛙跳法（速度Verlet形式）**\n\n蛙跳法是一种二阶辛积分器。其速度Verlet形式由以下公式给出：\n$$\nv_{n+\\frac{1}{2}} = v_n + \\frac{h}{2}a_n \\quad \\text{where} \\quad a_n=-\\omega^2 x_n\n$$\n$$\nx_{n+1} = x_n + h\\,v_{n+\\frac{1}{2}}\n$$\n$$\nv_{n+1} = v_{n+\\frac{1}{2}} + \\frac{h}{2}a_{n+1} \\quad \\text{where} \\quad a_{n+1}=-\\omega^2 x_{n+1}\n$$\n作为一种辛方法，此方法不会表现出能量的长期漂移。数值能量将在真实能量附近振荡，从而带来出色的长期稳定性和有界的振幅误差。然而，该方法会在振荡的相位中引入系统误差。数值频率 $\\tilde{\\omega}$ 与真实频率 $\\omega$ 略有不同。这导致相位误差随时间累积。对于小步长 $h$，在时间 $T$ 的全局相位误差量级为 $O(T\\omega^3h^2)$。\n问题基于状态空间表示 $(x, -v/\\omega)$ 来定义相位误差 $E_\\phi$。对于精确解，状态向量 $(x_{\\text{exact}}(t), -v_{\\text{exact}}(t)/\\omega) = (A\\cos(\\omega t), A\\sin(\\omega t))$ 以角度 $\\theta_{\\text{exact}}(t) = \\omega t$ 逆时针旋转。数值相位 $\\theta_{\\text{num}}$ 是根据最终数值状态 $(x_N, v_N)$ 计算得出的，即 $\\theta_{\\text{num}} = \\operatorname{atan2}(-v_N/\\omega, x_N)$。相位误差是数值相位与精确相位之差，并将其包裹（wrap）到区间 $(-\\pi, \\pi]$ 内：\n$$\nE_\\phi = \\operatorname{wrap}_{(-\\pi,\\pi]}(\\theta_{\\text{num}} - \\theta_{\\text{exact}})\n$$\n此计算能正确捕捉数值解的相位滞后或超前。由于相位是周期量，因此需要进行包裹处理。\n\n**计算步骤**\n\n对于每个给定的测试用例 $(h, T)$：\n1.  设置初始条件 $x_0 = 1, v_0 = 0$ 以及参数 $A=1, \\omega=1$。\n2.  计算积分步数 $N = T/h$。\n3.  使用显式欧拉法对系统进行 $N$ 步模拟，求得最终状态 $(x_N, v_N)_{\\text{Euler}}$。\n4.  计算振幅误差 $E_A = \\sqrt{x_{N,\\text{Euler}}^2 + (v_{N,\\text{Euler}}/\\omega)^2} - A$。\n5.  使用蛙跳法对系统进行 $N$ 步模拟，求得最终状态 $(x_N, v_N)_{\\text{Leapfrog}}$。\n6.  计算数值相位 $\\theta_{\\text{num}} = \\operatorname{atan2}(-v_{N,\\text{Leapfrog}}/\\omega, x_{N,\\text{Leapfrog}})$、精确相位 $\\theta_{\\text{exact}} = \\omega T$ 和包裹后的相位误差 $E_\\phi$。包裹函数使用公式 $\\beta = \\alpha - 2\\pi \\lceil(\\alpha - \\pi)/(2\\pi)\\rceil$ 将实数 $\\alpha$ 映射到区间 $(-\\pi, \\pi]$。\n7.  将结果合并为单个数据对 $[E_A, E_\\phi]$。\n\n我们将实施此步骤，为所有测试用例生成所需的输出。计算出的值将作为上述理论误差行为的具体例证。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes amplitude and phase errors for Euler and Leapfrog methods\n    for a simple harmonic oscillator.\n    \"\"\"\n    \n    # Test cases defined by (h, T) in seconds.\n    test_cases = [\n        (0.1, 50.0),\n        (0.01, 50.0),\n        (0.5, 50.0),\n    ]\n\n    # Constants from the problem statement\n    A = 1.0  # meters\n    omega = 1.0  # radians per second\n\n    results = []\n    \n    # Custom wrap function to map angle to (-pi, pi]\n    def wrap_to_pi(alpha):\n        \"\"\"Maps an angle alpha in radians to the interval (-pi, pi].\"\"\"\n        return alpha - 2 * np.pi * np.ceil((alpha - np.pi) / (2 * np.pi))\n\n    for h, T in test_cases:\n        N = int(round(T / h))\n        if not np.isclose(N * h, T):\n            # This should not happen with the given test cases\n            raise ValueError(\"T must be an integer multiple of h.\")\n\n        # --- Explicit Euler Simulation ---\n        x_euler, v_euler = A, 0.0\n        for _ in range(N):\n            x_next = x_euler + h * v_euler\n            v_next = v_euler - h * (omega**2) * x_euler\n            x_euler, v_euler = x_next, v_next\n        \n        # Calculate amplitude error for Euler method\n        amplitude_numerical_euler = np.sqrt(x_euler**2 + (v_euler / omega)**2)\n        E_A = amplitude_numerical_euler - A\n\n        # --- Leapfrog (Velocity Verlet) Simulation ---\n        x_leap, v_leap = A, 0.0\n        # Initial acceleration\n        a_n = -(omega**2) * x_leap\n        for _ in range(N):\n            v_half = v_leap + 0.5 * h * a_n\n            x_next = x_leap + h * v_half\n            a_next = -(omega**2) * x_next\n            v_next = v_half + 0.5 * h * a_next\n            \n            x_leap, v_leap = x_next, v_next\n            a_n = a_next\n\n        # Calculate signed phase error for Leapfrog method\n        theta_num = np.arctan2(-v_leap / omega, x_leap)\n        theta_exact = omega * T\n        phase_diff = theta_num - theta_exact\n        E_phi = wrap_to_pi(phase_diff)\n        \n        results.append([E_A, E_phi])\n\n    # Format the output string exactly as required\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "既然我们已经能够测量和表征误差，我们能否利用对误差结构的理解来消除它？本练习将介绍理查森外推法，这是一种强大而通用的技术，用于提高数值近似的精度。通过组合来自同一低阶方法、采用不同步长的两个解，你将推导并实现一个更高阶的估计，亲眼见证对截断误差的系统性理解如何催生出更优秀的算法 。",
            "id": "2409197",
            "problem": "实现一个完整的程序，对于一组形如 $\\dfrac{dy}{dt} = f(t,y)$ 且 $y(0) = y_0$ 的初值问题，执行以下操作：从局部截断误差和全局截断误差的定义出发，推导一个理查森外推组合，该组合通过组合使用步长 $h$ 和 $h/2$ 计算的两个欧拉解，来消除显式欧拉法的主导全局误差项。该组合必须从第一性原理出发，假设全局误差有一个关于 $h$ 的幂次的渐近展开，并且它必须产生一个新的近似，其全局截断误差为 $O(h^2)$ 阶。\n\n你的推导必须基于以下基本事实：\n- 显式欧拉法由递推式 $y_{n+1} = y_n + h f(t_n, y_n)$ 定义，其中 $t_n = t_0 + n h$。\n- 局部截断误差是将精确解代入单步方法中得到的单步缺陷，对于光滑的 $f$，其量级为 $O(h^2)$。\n- 在固定的最终时间 $T$ 处的全局截断误差是经过 $N = T/h$ 步后精确解与数值解之间的累积差异；对于显式欧拉法，其量级为 $O(h)$。\n\n你的程序必须实现：\n1. 一个函数，用于计算在最终时间 $T$ 处，使用均匀步长 $h$ 的显式欧拉解 $y_h(T)$。\n2. 一个理查森外推组合，仅使用步长为 $h$ 和 $h/2$ 计算的两个欧拉解，产生一个改进的近似解 $y_{\\mathrm{RE}}(T)$，其全局截断误差量级为 $O(h^2)$。\n3. 一个经验验证例程，它也计算步长为 $h/4$ 的解，以便您可以估计观察到的收敛阶：\n   - 对于显式欧拉法，估计 $p_{\\mathrm{E}} \\approx \\log_2\\!\\left(\\dfrac{|y_h(T) - y(T)|}{|y_{h/2}(T) - y(T)|}\\right)$。\n   - 对于理查森外推近似，首先构造 $y_{\\mathrm{RE}}(h) = \\mathrm{RE}(y_h, y_{h/2})$ 和 $y_{\\mathrm{RE}}(h/2) = \\mathrm{RE}(y_{h/2}, y_{h/4})$，然后估计 $p_{\\mathrm{RE}} \\approx \\log_2\\!\\left(\\dfrac{|y_{\\mathrm{RE}}(h) - y(T)|}{|y_{\\mathrm{RE}}(h/2) - y(T)|}\\right)$。\n\n角度必须以弧度解释。\n\n测试套件：\n对于下面的每个案例，计算 $y_h(T)$、$y_{h/2}(T)$、$y_{h/4}(T)$，构造 $y_{\\mathrm{RE}}(h)$ 和 $y_{\\mathrm{RE}}(h/2)$，然后计算相对于精确解 $y(T)$ 的绝对误差。\n- 案例 A (指数衰减)：$\\dfrac{dy}{dt} = -3 y$, $y(0) = 1$, $T = 1$, 基础步长 $h = 0.2$。精确解: $y(t) = e^{-3 t}$。\n- 案例 B (线性非齐次)：$\\dfrac{dy}{dt} = t + y$, $y(0) = 0$, $T = 1$, 基础步长 $h = 0.2$。精确解: $y(t) = e^{t} - (t + 1)$。\n- 案例 C (变系数增长)：$\\dfrac{dy}{dt} = \\sin(t)\\, y$, $y(0) = 1$, $T = 1$, 基础步长 $h = 0.2$。精确解: $y(t) = \\exp\\!\\big(1 - \\cos(t)\\big)$。\n\n对于每个案例，你的程序必须生成一个包含五个实数的列表：\n- 步长为 $h$ 的欧拉法的绝对全局误差，即 $E_h = |y_h(T) - y(T)|$。\n- 步长为 $h/2$ 的欧拉法的绝对全局误差，即 $E_{h/2} = |y_{h/2}(T) - y(T)|$。\n- 由 $h$ 和 $h/2$ 构建的理查森外推近似的绝对全局误差，即 $E_{\\mathrm{RE}}(h) = |y_{\\mathrm{RE}}(h) - y(T)|$。\n- 上面定义的观察阶 $p_{\\mathrm{E}}$。\n- 上面定义的观察阶 $p_{\\mathrm{RE}}$。\n\n最终输出格式：\n你的程序应该生成单行输出，包含三个案例的结果，按案例 A、案例 B、案例 C 的顺序，格式为一个逗号分隔的三个列表，并用一对单独的方括号括起来，其中不含任何空格。每个实数必须以科学记数法打印，并保留十位有效数字。例如，该行必须看起来像：\n[[E_h_A,E_h2_A,E_RE_A,pE_A,pRE_A],[E_h_B,E_h2_B,E_RE_B,pE_B,pRE_B],[E_h_C,E_h2_C,E_RE_C,pE_C,pRE_C]]\n确保所有三角函数的参数都是弧度。由于此问题中所有量都是无量纲的，因此不需要单位。",
            "solution": "问题陈述经验证。\n\n逐字提取给定条件：\n1. 初值问题：$\\dfrac{dy}{dt} = f(t,y)$ 且 $y(0) = y_0$。\n2. 显式欧拉法递推式：$y_{n+1} = y_n + h f(t_n, y_n)$，其中 $t_n = t_0 + n h$。\n3. 显式欧拉法的局部截断误差量级为 $\\mathcal{O}(h^2)$。\n4. 在固定时间 $T$ 处显式欧拉法的全局截断误差量级为 $\\mathcal{O}(h)$。\n5. 任务：为两个步长分别为 $h$ 和 $h/2$ 的欧拉解推导一个理查森外推组合，以消除主导全局误差项，并假设全局误差有一个渐近展开。得到的近似解的全局误差必须为 $\\mathcal{O}(h^2)$ 阶。\n6. 任务：使用步长 $h$、$h/2$ 和 $h/4$ 实现一个经验验证。\n7. 欧拉法的观察阶：$p_{\\mathrm{E}} \\approx \\log_2\\!\\left(\\dfrac{|y_h(T) - y(T)|}{|y_{h/2}(T) - y(T)|}\\right)$。\n8. 理查森外推的观察阶：$p_{\\mathrm{RE}} \\approx \\log_2\\!\\left(\\dfrac{|y_{\\mathrm{RE}}(h) - y(T)|}{|y_{\\mathrm{RE}}(h/2) - y(T)|}\\right)$，其中 $y_{\\mathrm{RE}}(h) = \\mathrm{RE}(y_h, y_{h/2})$ 且 $y_{\\mathrm{RE}}(h/2) = \\mathrm{RE}(y_{h/2}, y_{h/4})$。\n9. 测试案例 A：$\\dfrac{dy}{dt} = -3 y$，$y(0) = 1$，$T = 1$，$h = 0.2$。精确解：$y(t) = e^{-3 t}$。\n10. 测试案例 B：$\\dfrac{dy}{dt} = t + y$，$y(0) = 0$，$T = 1$，$h = 0.2$。精确解：$y(t) = e^{t} - (t + 1)$。\n11. 测试案例 C：$\\dfrac{dy}{dt} = \\sin(t)\\, y$，$y(0) = 1$，$T = 1$，$h = 0.2$。精确解：$y(t) = \\exp\\!\\big(1 - \\cos(t)\\big)$。\n12. 每个案例的所需输出：一个包含五个数字的列表：$|y_h(T) - y(T)|$，$|y_{h/2}(T) - y(T)|$，$|y_{\\mathrm{RE}}(h) - y(T)|$，$p_{\\mathrm{E}}$ 和 $p_{\\mathrm{RE}}$。\n\n使用提取的给定条件进行验证：\n该问题具有科学依据。它涉及理查森外推，这是数值分析中用于提高数值方法精度的一种标准和基本技术。其前提——显式欧拉法的定义及其局部和全局截断误差的阶——是常微分方程数值解研究中的标准结果。该问题是适定的；它要求对定义明确且具有唯一解析解的测试案例进行特定的推导和实现，确保可以获得并验证一个唯一且有意义的结果。语言客观而精确。该问题不违反任何无效标准。这是一个可形式化的问题，与计算物理和数值方法直接相关。\n\n结论：问题有效。将提供解决方案。\n\n理查森外推公式的推导必须按规定从第一性原理构建。该方法的基础是数值格式的全局误差存在一个渐近展开。对于全局误差为 $\\mathcal{O}(h)$ 阶的显式欧拉法，该展开式具有以下形式：\n$$\ny_h(T) = y(T) + C_1 h + C_2 h^2 + C_3 h^3 + \\dots\n$$\n在这里，$y(T)$ 是最终时间 $T$ 处的精确解，$y_h(T)$ 是用步长 $h$ 获得的数值近似解，系数 $C_k$ 与 $h$ 无关，但依赖于函数 $f(t,y)$ 及其在不同点上的导数。主导误差项是 $C_1 h$。\n\n我们的目标是通过组合两个独立的计算来消除这个主导项。让我们用步长 $h$ 进行数值积分，再用步长 $h/2$ 进行一次。相应数值解的渐近展开式为：\n$$\n(1) \\quad y_h(T) = y(T) + C_1 h + C_2 h^2 + \\mathcal{O}(h^3)\n$$\n$$\n(2) \\quad y_{h/2}(T) = y(T) + C_1 \\frac{h}{2} + C_2 \\left(\\frac{h}{2}\\right)^2 + \\mathcal{O}(h^3) = y(T) + \\frac{1}{2} C_1 h + \\frac{1}{4} C_2 h^2 + \\mathcal{O}(h^3)\n$$\n我们寻求 $y_h(T)$ 和 $y_{h/2}(T)$ 的一个线性组合，以抵消与 $C_1 h$ 成正比的项。设外推近似解为 $y_{\\mathrm{RE}}(T)$。为消除 $C_1 h$，我们可以将方程 $(2)$ 乘以 $2$，然后减去方程 $(1)$：\n$$\n2 y_{h/2}(T) - y_h(T) = \\left(2y(T) + C_1 h + \\frac{1}{2} C_2 h^2 + \\dots\\right) - \\left(y(T) + C_1 h + C_2 h^2 + \\dots\\right)\n$$\n$$\n2 y_{h/2}(T) - y_h(T) = (2-1)y(T) + (1-1)C_1 h + \\left(\\frac{1}{2}-1\\right)C_2 h^2 + \\mathcal{O}(h^3)\n$$\n$$\n2 y_{h/2}(T) - y_h(T) = y(T) - \\frac{1}{2} C_2 h^2 + \\mathcal{O}(h^3)\n$$\n由此，我们将理查森外推解 $y_{\\mathrm{RE}}(T)$ 定义为：\n$$\ny_{\\mathrm{RE}}(T) = 2 y_{h/2}(T) - y_h(T)\n$$\n这个新近似的全局截断误差是差值 $y_{\\mathrm{RE}}(T) - y(T)$。根据我们的推导：\n$$\ny_{\\mathrm{RE}}(T) - y(T) = -\\frac{1}{2} C_2 h^2 + \\mathcal{O}(h^3)\n$$\n这证实了全局截断误差现在是 $\\mathcal{O}(h^2)$ 阶，符合要求。原方法的主导误差项已被成功消除。\n\n计算实现将包括三个主要部分。首先，一个函数 `explicit_euler` 将使用恒定步长 $h$ 求解给定的从初始时间 $t_0$ 到最终时间 $T$ 的常微分方程。该函数将实现递推式 $y_{k+1} = y_k + h f(t_k, y_k)$，该递推式迭代 $N = \\text{round}((T-t_0)/h)$ 次。\n\n其次，一个主例程将为每个测试案例执行逻辑。对于一个基础步长 $h$，它将使用步长 $h$、$h/2$ 和 $h/4$ 调用 `explicit_euler` 函数三次，以获得数值解 $y_h(T)$、$y_{h/2}(T)$ 和 $y_{h/4}(T)$。\n\n第三，该例程将使用这些数值结果进行经验分析。它将计算理查森外推近似值：\n$$\ny_{\\mathrm{RE}}(h) = 2 y_{h/2}(T) - y_h(T)\n$$\n$$\ny_{\\mathrm{RE}}(h/2) = 2 y_{h/4}(T) - y_{h/2}(T)\n$$\n然后计算相对于已知精确解 $y(T)$ 的绝对全局误差。最后，使用指定的对数公式计算观察到的收敛阶 $p_{\\mathrm{E}}$ 和 $p_{\\mathrm{RE}}$。对于欧拉法，这些经验阶应约为 $1$，对于理查森外推法，应约为 $2$，从而验证了精度的理论改进。所有测试案例的最终结果将按照指定格式进行格式化和打印。三角函数输入将按科学计算中的标准以弧度处理。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements Richardson extrapolation for the explicit Euler method to solve\n    several initial value problems and empirically verifies the order of convergence.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"f\": lambda t, y: -3.0 * y,\n            \"y0\": 1.0,\n            \"T\": 1.0,\n            \"h\": 0.2,\n            \"exact_y\": lambda t: np.exp(-3.0 * t),\n        },\n        {\n            \"f\": lambda t, y: t + y,\n            \"y0\": 0.0,\n            \"T\": 1.0,\n            \"h\": 0.2,\n            \"exact_y\": lambda t: np.exp(t) - (t + 1.0),\n        },\n        {\n            \"f\": lambda t, y: np.sin(t) * y,\n            \"y0\": 1.0,\n            \"T\": 1.0,\n            \"h\": 0.2,\n            \"exact_y\": lambda t: np.exp(1.0 - np.cos(t)),\n        },\n    ]\n\n    def explicit_euler(f_ode, y_start, t_start, t_end, step_size):\n        \"\"\"\n        Computes the solution of an ODE using the explicit Euler method.\n        \"\"\"\n        t = t_start\n        y = y_start\n        # Use round() to avoid floating-point inaccuracies in step counting\n        num_steps = int(round((t_end - t_start) / step_size))\n        \n        for _ in range(num_steps):\n            y = y + step_size * f_ode(t, y)\n            t = t + step_size\n        return y\n\n    all_results = []\n    for case in test_cases:\n        f = case[\"f\"]\n        y0 = case[\"y0\"]\n        T = case[\"T\"]\n        h_base = case[\"h\"]\n        exact_y_func = case[\"exact_y\"]\n\n        # Define the three step sizes\n        h = h_base\n        h_half = h_base / 2.0\n        h_quarter = h_base / 4.0\n\n        # Compute Euler solutions for each step size\n        y_h = explicit_euler(f, y0, 0.0, T, h)\n        y_h_half = explicit_euler(f, y0, 0.0, T, h_half)\n        y_h_quarter = explicit_euler(f, y0, 0.0, T, h_quarter)\n\n        # Compute the exact solution at the final time T\n        y_exact = exact_y_func(T)\n\n        # Compute Richardson-extrapolated approximations\n        y_re_h = 2.0 * y_h_half - y_h\n        y_re_h_half = 2.0 * y_h_quarter - y_h_half\n\n        # Compute absolute errors\n        E_h = np.abs(y_h - y_exact)\n        E_h_half = np.abs(y_h_half - y_exact)\n        E_re_h = np.abs(y_re_h - y_exact)\n        E_re_h_half = np.abs(y_re_h_half - y_exact)\n\n        # Compute observed orders of convergence\n        # Handle cases where error is zero to avoid division by zero or log(0)\n        p_E = np.log2(E_h / E_h_half) if E_h_half > 0 else 0.0\n        p_RE = np.log2(E_re_h / E_re_h_half) if E_re_h_half > 0 else 0.0\n\n        results = [E_h, E_h_half, E_re_h, p_E, p_RE]\n        all_results.append(results)\n\n    # Format the final output string as specified\n    formatted_cases = []\n    for case_res in all_results:\n        formatted_nums = [f\"{num:.10e}\" for num in case_res]\n        formatted_cases.append(f\"[{','.join(formatted_nums)}]\")\n    \n    final_output = f\"[{','.join(formatted_cases)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}