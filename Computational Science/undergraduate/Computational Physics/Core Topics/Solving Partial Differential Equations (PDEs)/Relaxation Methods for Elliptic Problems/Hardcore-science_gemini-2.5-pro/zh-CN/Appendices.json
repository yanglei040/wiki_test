{
    "hands_on_practices": [
        {
            "introduction": "本练习将从一个基础问题入手：在标准的二维笛卡尔网格上，使用最简单的松弛法——雅可比（Jacobi）方法——求解泊松方程。雅可比法的核心思想是同步更新，即在每次迭代中，网格上每个点的新值仅依赖于其邻居节点在前一次迭代中的旧值。这种特性使其天然地适合并行计算，因此本练习将通过模拟图形处理器（GPU）的执行模式，帮助你理解并行计算的基本原理 。此外，你还将推导并比较理论收敛因子与经验收敛因子，这是分析任何迭代算法性能的关键一步。",
            "id": "2433927",
            "problem": "您的任务是设计并实现一个同步松弛求解器，用于求解一个模型椭圆边界值问题，该求解器模拟图形处理单元 (GPU) 的执行模型。该物理问题是单位正方形上的二维泊松方程，带有齐次狄利克雷边界条件。您的实现必须模拟 GPU 内核的行为，其中每个线程并行地更新一个网格点，并且所有更新都同步发生。由于此任务的执行环境是中央处理器 (CPU)，您必须通过在整个内部网格上应用单个向量化更新来模拟 GPU，而不使用针对网格点的逐点 Python 循环。您必须使用雅可比方法，并明确避免在一次迭代中对内部值进行原地更新。首次提及时，请定义 OpenGL 着色语言 (GLSL) 和计算统一设备架构 (CUDA)。\n\n从基本原理出发：使用均匀笛卡尔网格和标准的拉普拉斯算子五点模板来离散化偏微分方程，并从此离散化推导出雅可比方法的同步点更新规则。设域为 $\\Omega = [0,1]\\times[0,1]$，每个坐标方向的内部点数为 $N$，定义网格间距为 $h = \\frac{1}{N+1}$。令 $u(x,y)$ 表示精确解，$f(x,y)$ 表示源项，满足\n$$\n\\nabla^2 u(x,y) = f(x,y)\\quad \\text{for}\\ (x,y)\\in \\Omega,\\qquad\nu(x,y)=0\\quad \\text{for}\\ (x,y)\\in \\partial\\Omega.\n$$\n令 $u_{i,j}$ 表示网格点 $(x_i,y_j)$ 处的离散未知数，其中 $x_i = i h$，$y_j = j h$，对于 $i,j\\in\\{0,1,\\dots,N+1\\}$，边界值满足 $u_{i,0}=u_{i,N+1}=u_{0,j}=u_{N+1,j}=0$。从基本原理出发，推导出仅使用前一次迭代的邻居值和源项的同步雅可比更新规则。解释为什么同步更新对于在 GPU 上进行单指令多线程 (SIMT) 执行是自然的。\n\n实现一个程序，该程序：\n- 为给定的源项 $f(x,y)$ 构建离散右端项 $f_{i,j}$。\n- 对所有内部点 $(i,j)$，用 $u_{i,j}^{(0)}=0$ 初始化内部状态。\n- 迭代雅可比方法，直到残差的离散 $\\ell^2$-范数，\n$$\n\\|r^{(k)}\\|_{2,h} = \\left(h^2 \\sum_{i=1}^{N}\\sum_{j=1}^{N} \\left(f_{i,j} - (A u^{(k)})_{i,j}\\right)^2\\right)^{1/2},\n$$\n低于指定的容差 $\\varepsilon$ 或达到最大迭代次数 $k_{\\max}$。此处 $(A u)_{i,j}$ 是应用于 $u$ 的五点离散拉普拉斯算子，并且三角函数中使用的所有角度必须以弧度为单位。\n- 根据最后可用的比率 $\\|r^{(k)}\\|_{2,h} / \\|r^{(k-1)}\\|_{2,h}$，估计渐近收敛因子 $\\hat{q}$，该估计值是对最后最多 10 次同时定义了 $\\|r^{(k)}\\|_{2,h}$ 和 $\\|r^{(k-1)}\\|_{2,h}$ 的迭代的比率进行平均得到的。如果发生的迭代次数少于 2 次，则定义 $\\hat{q}=0$。\n- 通过分析迭代算子在均匀网格上的特征模态，计算该问题上雅可比迭代的理论渐近收敛因子 $q$。不得在没有论证的情况下假设任何关于 $q$ 的公式；$q$ 的值必须在您的解中从基本原理计算得出，并在您的代码中使用您推导的表达式实现。\n\n除了残差范数，当精确解 $u(x,y)$ 已知时，计算离散 $\\ell^2$-误差\n$$\n\\|e^{(k)}\\|_{2,h} = \\left(h^2 \\sum_{i=1}^{N}\\sum_{j=1}^{N} \\left(u_{i,j}^{(k)} - u(x_i,y_j)\\right)^2\\right)^{1/2}.\n$$\n\n测试套件。您的程序必须运行以下三个测试用例并汇总其结果：\n- 案例 A (正常路径): $N=15$, $f(x,y)=-2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$, 精确解 $u(x,y)=\\sin(\\pi x)\\sin(\\pi y)$, 容差 $\\varepsilon=10^{-8}$, $k_{\\max}=10000$。\n- 案例 B (更大网格): $N=31$, 与案例 A 相同的 $f$ 和精确解, 容差 $\\varepsilon=10^{-6}$, $k_{\\max}=100000$。\n- 案例 C (边界条件边缘情况): $N=15$, $f(x,y)=0$ 且精确解 $u(x,y)=0$, 容差 $\\varepsilon=10^{-12}$, $k_{\\max}=1000$。\n\n对于每个案例，您的程序必须按顺序输出一个包含五个值的列表：\n$[k_{\\text{it}}, \\|r^{(k)}\\|_{2,h}, \\|e^{(k)}\\|_{2,h}, \\hat{q}, q]$，其中 $k_{\\text{it}}$ 是实际执行的雅可比迭代次数，$\\|r^{(k)}\\|_{2,h}$ 是最终的残差范数，$\\|e^{(k)}\\|_{2,h}$ 是最终的误差范数（当没有解析解时使用 $0$），$\\hat{q}$ 是经验收敛因子估计值，$q$ 是从您的分析中推导出的理论因子。\n\n最终输出格式。您的程序应生成单行输出，其中包含三个案例的结果，形式为逗号分隔的列表的列表，数值条目四舍五入到六位有效数字，并且没有多余的字符或空格。例如，最后一行必须如下所示：\n$[[k_1,r_1,e_1,\\hat{q}_1,q_1],[k_2,r_2,e_2,\\hat{q}_2,q_2],[k_3,r_3,e_3,\\hat{q}_3,q_3]]$\n其中每个 $k_i$ 是整数，每个 $r_i$、$e_i$、$\\hat{q}_i$、$q_i$ 是浮点数。所有三角函数求值中使用的角度单位必须是弧度。",
            "solution": "所提出的问题是有效的；这是一个关于椭圆偏微分方程数值解的计算物理学中标准且适定的练习。它在科学上是合理的，内部一致，并包含唯一数值解所需的所有必要信息。我们将继续进行推导和实现。\n\n首先，我们必须按要求定义所提到的计算架构。OpenGL着色语言 (GLSL) 是一种高级着色语言，其语法基于C编程语言。它用于创建称为着色器的程序，这些程序作为图形管线的一部分在图形处理单元 (GPU) 上执行。计算统一设备架构 (CUDA) 是由Nvidia创建的专有并行计算平台和应用程序编程接口 (API) 模型。它允许软件开发人员使用支持CUDA的GPU进行通用处理，这种方法被称为GPGPU（通用图形处理器计算）。\n\n问题的核心是在单位正方形 $\\Omega = [0,1]\\times[0,1]$ 上求解带有齐次狄利克雷边界条件的二维泊松方程：\n$$\n\\nabla^2 u(x,y) = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = f(x,y) \\quad \\text{for } (x,y) \\in \\Omega\n$$\n$$\nu(x,y) = 0 \\quad \\text{for } (x,y) \\in \\partial\\Omega\n$$\n我们使用一个在每个方向上有 $N$ 个内部点的均匀笛卡尔网格来离散化域 $\\Omega$。网格间距为 $h = \\frac{1}{N+1}$。网格点为 $(x_i, y_j)$，其中 $x_i = ih$，$y_j = jh$，对于整数 $i, j \\in \\{0, 1, \\dots, N+1\\}$。离散解在这些点上的值表示为 $u_{i,j}$。边界条件意味着 $u_{i,0} = u_{i,N+1} = u_{0,j} = u_{N+1,j} = 0$。\n\n为了离散化拉普拉斯算子 $\\nabla^2$，我们使用从泰勒级数展开式推导出的二阶精度中心有限差分：\n$$\n\\frac{\\partial^2 u}{\\partial x^2}\\bigg|_{(x_i,y_j)} = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\mathcal{O}(h^2)\n$$\n$$\n\\frac{\\partial^2 u}{\\partial y^2}\\bigg|_{(x_i,y_j)} = \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} + \\mathcal{O}(h^2)\n$$\n将这些代入泊松方程，得到每个内部网格点 $(i,j)$（其中 $i,j \\in \\{1, \\dots, N\\}$）的五点模板离散方程：\n$$\n\\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} = f_{i,j}\n$$\n这是一个针对 $N^2$ 个未知内部值 $u_{i,j}$ 的大型稀疏线性方程组。为了迭代求解该系统，我们通过分离项 $u_{i,j}$ 并引入迭代索引 $k$ 来推导雅可比方法：\n$$\n4u_{i,j} = u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - h^2 f_{i,j}\n$$\n雅可比更新规则仅使用前一次迭代的值 $u^{(k)}$ 来计算新值 $u_{i,j}^{(k+1)}$：\n$$\nu_{i,j}^{(k+1)} = \\frac{1}{4} \\left( u_{i+1,j}^{(k)} + u_{i-1,j}^{(k)} + u_{i,j+1}^{(k)} + u_{i,j-1}^{(k)} - h^2 f_{i,j} \\right)\n$$\n此更新对所有内部点 $i,j \\in \\{1, \\dots, N\\}$ 执行。\n\n这种更新规则的结构非常适合并行计算，特别是在像GPU这样的SIMT（单指令多线程）架构上。关键的观察是，每个点 $u_{i,j}^{(k+1)}$ 的计算完全独立于所有其他新值 $u_{l,m}^{(k+1)}$（其中 $(l,m) \\neq (i,j)$）。右侧的所有值都属于前一个状态 $u^{(k)}$。GPU可以为每个网格点 $(i,j)$ 分配一个线程，所有线程可以同时在其分配的数据上执行相同的指令——雅可比更新公式。这需要两个内存缓冲区：一个用于读取旧状态 $u^{(k)}$，另一个用于写入新状态 $u^{(k+1)}$。这个过程被称为同步更新，它避免了数据竞争，并且完美匹配硬件范式。在CPU上模拟此过程涉及使用两个数组并执行向量化更新，如题目所规定。\n\n接下来，我们推导理论渐近收敛因子 $q$。雅可比迭代可以写成矩阵形式 $\\mathbf{u}^{(k+1)} = T_J \\mathbf{u}^{(k)} + \\mathbf{c}$，其中 $T_J$ 是雅可比迭代矩阵。收敛速度由 $T_J$ 的谱半径决定，定义为 $q = \\rho(T_J) = \\max_m |\\lambda_m|$，其中 $\\lambda_m$ 是 $T_J$ 的特征值。该域上离散拉普拉斯算子的特征向量已知为离散正弦函数：\n$$\nv_{i,j}^{(p,q)} = \\sin\\left(\\frac{p\\pi i}{N+1}\\right) \\sin\\left(\\frac{q\\pi j}{N+1}\\right) \\quad \\text{for } p,q \\in \\{1, \\dots, N\\}\n$$\n这些也是雅可比迭代矩阵 $T_J$ 的特征向量。将雅可比算子应用于这样一个特征向量得到：\n$$\n(T_J v^{(p,q)})_{i,j} = \\frac{1}{4} \\left( v_{i+1,j}^{(p,q)} + v_{i-1,j}^{(p,q)} + v_{i,j+1}^{(p,q)} + v_{i,j-1}^{(p,q)} \\right)\n$$\n使用三角恒等式 $\\sin(A+B) + \\sin(A-B) = 2\\sin(A)\\cos(B)$，我们简化这些项：\n$$\nv_{i+1,j}^{(p,q)} + v_{i-1,j}^{(p,q)} = 2\\cos\\left(\\frac{p\\pi}{N+1}\\right) v_{i,j}^{(p,q)}\n$$\n$$\nv_{i,j+1}^{(p,q)} + v_{i,j-1}^{(p,q)} = 2\\cos\\left(\\frac{q\\pi}{N+1}\\right) v_{i,j}^{(p,q)}\n$$\n将这些代回，我们找到与特征向量 $v^{(p,q)}$ 对应的特征值 $\\lambda_{p,q}$：\n$$\n(T_J v^{(p,q)})_{i,j} = \\frac{1}{2} \\left[ \\cos\\left(\\frac{p\\pi}{N+1}\\right) + \\cos\\left(\\frac{q\\pi}{N+1}\\right) \\right] v_{i,j}^{(p,q)}\n$$\n谱半径是所有 $p, q \\in \\{1, \\dots, N\\}$ 的这些特征值绝对值的最大值。余弦函数在区间 $[0, \\pi/2]$ 上是正的且单调递减。因此，最大特征值出现在参数最小的时候，即 $p=1$ 和 $q=1$。\n$$\nq = \\rho(T_J) = \\lambda_{1,1} = \\frac{1}{2} \\left[ \\cos\\left(\\frac{\\pi}{N+1}\\right) + \\cos\\left(\\frac{\\pi}{N+1}\\right) \\right] = \\cos\\left(\\frac{\\pi}{N+1}\\right)\n$$\n这就是所要求的理论渐近收敛因子。随着 $N$ 的增加，它趋近于1，这表明对于更精细的网格，收敛速度会显著减慢。\n\n实现将遵循这些推导出的原理。一个主循环将迭代雅可比更新，在每一步开始时检查收敛性。残差范数 $\\|r^{(k)}\\|_{2,h}$ 和误差范数 $\\|e^{(k)}\\|_{2,h}$ 将使用向量化的 `numpy` 操作进行计算。经验收敛因子 $\\hat{q}$ 将根据连续残差范数的比率进行估计，并且所有数值输出都将按规定格式化。",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef format_num(n):\n    \"\"\"Formats a number to 6 significant figures, or as an integer.\"\"\"\n    if isinstance(n, int):\n        return str(n)\n    if n == 0.0:\n        return \"0.0\"\n    return f\"{n:.6g}\"\n\ndef run_case(N, f_func, u_exact_func, epsilon, k_max):\n    \"\"\"\n    Solves the 2D Poisson BVP for a single test case using the Jacobi method.\n    \"\"\"\n    h = 1.0 / (N + 1)\n    \n    # Create grid coordinates (including boundaries)\n    i_coords = np.arange(0, N + 2)\n    x = i_coords * h\n    X, Y = np.meshgrid(x, x, indexing='ij')\n\n    # Initialize solution array u (with zero boundaries) and source term f\n    u = np.zeros((N + 2, N + 2))\n    f_grid = f_func(X, Y)\n    \n    u_exact_grid = None\n    if u_exact_func is not None:\n        u_exact_grid = u_exact_func(X, Y)\n\n    residual_history = []\n    k_it = 0\n\n    for k in range(k_max + 1):\n        # Calculate the residual of the current state u^{(k)}\n        # A*u = (1/h^2) * (u_{i+1,j} + ... - 4u_{i,j})\n        # r = f - A*u\n        laplacian_u_interior = (u[2:, 1:-1] + u[:-2, 1:-1] + u[1:-1, 2:] + u[1:-1, :-2] - 4 * u[1:-1, 1:-1]) / (h**2)\n        f_interior = f_grid[1:-1, 1:-1]\n        \n        residual_matrix = f_interior - laplacian_u_interior\n        residual_norm = np.sqrt(h**2 * np.sum(residual_matrix**2))\n        residual_history.append(residual_norm)\n        \n        k_it = k\n        # Check for convergence before performing the update\n        if residual_norm  epsilon:\n            break\n        \n        # Check if max iterations reached\n        if k == k_max:\n            break\n\n        # Perform one synchronous Jacobi iteration (emulating GPU)\n        # Use a new array for the updated values, reading only from the old 'u'\n        u_new = np.zeros_like(u)\n        u_new[1:-1, 1:-1] = 0.25 * (u[2:, 1:-1] + u[:-2, 1:-1] +u[1:-1, 2:] + u[1:-1, :-2] - h**2 * f_grid[1:-1, 1:-1])\n        u = u_new\n\n    # --- Post-processing after loop termination ---\n    final_residual_norm = residual_history[-1]\n    \n    # Calculate final discrete L2 error norm if exact solution is available\n    final_error_norm = 0.0\n    if u_exact_grid is not None:\n        error_matrix = u[1:-1, 1:-1] - u_exact_grid[1:-1, 1:-1]\n        final_error_norm = np.sqrt(h**2 * np.sum(error_matrix**2))\n\n    # Estimate empirical convergence factor q_hat\n    q_hat = 0.0\n    # Per problem statement: q_hat=0 if fewer than 2 iterations occur.\n    if k_it >= 2:\n        ratios = []\n        # residual_history has k_it+1 elements (for k=0, 1, ..., k_it)\n        for i in range(1, len(residual_history)):\n            # Avoid division by zero\n            if residual_history[i-1] > 1e-16:\n                ratios.append(residual_history[i] / residual_history[i-1])\n        \n        num_ratios_to_avg = min(len(ratios), 10)\n        if num_ratios_to_avg > 0:\n            q_hat = np.mean(ratios[-num_ratios_to_avg:])\n            \n    # Calculate theoretical convergence factor q\n    q_theory = np.cos(np.pi / (N + 1))\n    \n    return [\n        format_num(k_it),\n        format_num(final_residual_norm),\n        format_num(final_error_norm),\n        format_num(q_hat),\n        format_num(q_theory)\n    ]\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the Jacobi solver.\n    \"\"\"\n    test_cases = [\n        # Case A: Happy path\n        {\n            \"N\": 15,\n            \"f_func\": lambda x, y: -2 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"u_exact_func\": lambda x, y: np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"epsilon\": 1e-8,\n            \"k_max\": 10000\n        },\n        # Case B: Larger grid\n        {\n            \"N\": 31,\n            \"f_func\": lambda x, y: -2 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"u_exact_func\": lambda x, y: np.sin(np.pi * x) * np.sin(np.pi * y),\n            \"epsilon\": 1e-6,\n            \"k_max\": 100000\n        },\n        # Case C: Trivial solution, boundary edge case\n        {\n            \"N\": 15,\n            \"f_func\": lambda x, y: np.zeros_like(x),\n            \"u_exact_func\": lambda x, y: np.zeros_like(x),\n            \"epsilon\": 1e-12,\n            \"k_max\": 1000\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(\n            case[\"N\"],\n            case[\"f_func\"],\n            case[\"u_exact_func\"],\n            case[\"epsilon\"],\n            case[\"k_max\"]\n        )\n        # Format each list of results into the required string format\n        results.append(f\"[{','.join(result)}]\")\n\n    # Print the final aggregated output string\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了笛卡尔坐标系下的基本方法后，下一个挑战是将松弛法应用到更复杂的几何构型中。本练习要求你在极坐标网格上求解环形区域内的拉普拉斯方程 。这需要你从第一性原理出发，推导拉普拉斯算子在极坐标下的有限差分格式，这是将数值方法应用于具有非矩形对称性的实际问题的关键技能。通过实现一种更高效的逐次超松弛（Successive Over-Relaxation, SOR）迭代法，你将学会如何调整和应用这些数值技术以适应不同的坐标系统，从而加深对背后数学和物理原理的理解。",
            "id": "2433975",
            "problem": "实现一个完整的、可运行的程序，使用极坐标网格上的松弛法计算由拉普拉斯方程控制的环形域内的静电势。控制偏微分方程是极坐标下的拉普拉斯方程，这是一个经典的椭圆型方程，由经过充分检验的公式 $\\,\\nabla^{2}\\phi = \\frac{1}{r}\\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial \\phi}{\\partial r}\\right) + \\frac{1}{r^{2}}\\frac{\\partial^{2}\\phi}{\\partial \\theta^{2}}\\,$ 表达。域为环形 $\\{(r,\\theta)\\,|\\, r \\in [r_{\\mathrm{in}}, r_{\\mathrm{out}}], \\theta \\in [0, 2\\pi)\\}$，在角向具有周期性。您必须使用一种松弛法，特别是逐次超松弛（SOR）法，在均匀极坐标网格上求解离散电势。角度必须以弧度为单位。本问题中无需报告物理单位。\n\n从拉普拉斯算子的散度形式和均匀网格上中心有限差分的定义出发，推导算子 $\\frac{1}{r}\\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial \\phi}{\\partial r}\\right)$ 和 $\\frac{1}{r^{2}}\\frac{\\partial^{2}\\phi}{\\partial \\theta^{2}}$ 在内部网格点处的一致二阶有限差分离散化。然后，使用此离散方程，为内部节点构建一个逐点的线性更新，以强制满足离散拉普拉斯方程。将此逐点更新嵌入带有松弛因子 $\\omega$ 的逐次超松弛（SOR）扫描中，并进行迭代，直到离散残差低于指定的容差。内部节点的残差必须通过将当前迭代值代入您推导的离散拉普拉斯算子来定义。在角向使用周期性边界条件，在 $r=r_{\\mathrm{in}}$ 和 $r=r_{\\mathrm{out}}$ 处使用狄利克雷（Dirichlet）边界条件。\n\n您的程序必须：\n- 建立一个在径向有 $N_{r}$ 个节点、在角向有 $N_{\\theta}$ 个节点的均匀极坐标网格。使用 $r_{i} = r_{\\mathrm{in}} + i\\,\\Delta r$（其中 $i \\in \\{0,1,\\dots,N_{r}-1\\}$），$\\Delta r = \\frac{r_{\\mathrm{out}}-r_{\\mathrm{in}}}{N_{r}-1}$；以及 $\\theta_{j} = j\\,\\Delta \\theta$（其中 $j \\in \\{0,1,\\dots,N_{\\theta}-1\\}$），$\\Delta \\theta = \\frac{2\\pi}{N_{\\theta}}$。角度必须以弧度为单位。\n- 在 $r=r_{\\mathrm{in}}$ 和 $r=r_{\\mathrm{out}}$ 处施加如下文每个测试用例指定的狄利克雷边界值，并通过对 $\\theta_{j\\pm 1}$ 使用环绕索引来强制实现 $\\theta$ 的周期性。\n- 使用带有固定松弛因子 $\\omega$ 的逐次超松弛（SOR）法，迭代更新内部网格值，直到所有内部点的离散残差的 $\\ell_{\\infty}$-范数小于容差 $\\varepsilon$。使用最大迭代次数上限以避免在收敛失败时程序不终止。\n- 收敛后，计算整个网格上与每个测试用例提供的解析解相比的最大绝对误差。\n\n推导约束：\n- 从拉普拉斯算子的散度形式恒等式和中心有限差分定义开始。不要假设任何预先推导好的极坐标离散更新式；从第一性原理明确推导它。\n- 在均匀网格上，离散化必须在 $r$ 和 $\\theta$ 方向上都是二阶精确的。\n- SOR 更新必须通过从推导的离散方程中分离出内部节点的未知数，并应用带有因子 $\\omega$ 的超松弛来构建。\n\n收敛准则和参数：\n- 使用基于残差的停止准则 $\\max_{i,j} | \\mathcal{L}_{h}[\\phi]_{i,j} |  \\varepsilon$，其中 $\\mathcal{L}_{h}$ 表示应用于当前迭代值的离散拉普拉斯算子，最大值仅取自所有内部网格点。\n- 使用松弛因子 $\\omega = 1.85$。\n- 使用容差 $\\varepsilon = 10^{-8}$。\n- 使用最大迭代次数 $N_{\\mathrm{it,max}} = 50000$。\n\n测试套件：\n- 案例1（径向狄利克雷数据与对数解析解）：\n  - $r_{\\mathrm{in}} = 1$, $r_{\\mathrm{out}} = 2$, $N_{r} = 32$, $N_{\\theta} = 64$。\n  - 边界值：对于所有 $\\theta$，$\\phi(r_{\\mathrm{in}},\\theta) = 0$ 和 $\\phi(r_{\\mathrm{out}},\\theta) = 1$。\n  - 解析解：$\\phi_{\\mathrm{exact}}(r,\\theta) = \\dfrac{\\ln r - \\ln r_{\\mathrm{in}}}{\\ln r_{\\mathrm{out}} - \\ln r_{\\mathrm{in}}}$，与 $\\theta$ 无关。\n- 案例2（外边界上的单傅里叶模态）：\n  - $r_{\\mathrm{in}} = 1$, $r_{\\mathrm{out}} = 2$, $N_{r} = 32$, $N_{\\theta} = 64$。\n  - 边界值：$\\phi(r_{\\mathrm{in}},\\theta) = 0$ 和 $\\phi(r_{\\mathrm{out}},\\theta) = \\cos(n\\theta)$，其中 $n=3$，$\\theta$ 以弧度为单位。\n  - 解析解：$\\phi_{\\mathrm{exact}}(r,\\theta) = \\left(a\\,r^{n} + b\\,r^{-n}\\right)\\cos(n\\theta)$，其中 $a$ 和 $b$ 满足 $a\\,r_{\\mathrm{in}}^{n} + b\\,r_{\\mathrm{in}}^{-n} = 0$ 和 $a\\,r_{\\mathrm{out}}^{n} + b\\,r_{\\mathrm{out}}^{-n} = 1$。对于 $n=3$，$a = \\dfrac{1}{r_{\\mathrm{out}}^{3} - r_{\\mathrm{in}}^{6}\\,r_{\\mathrm{out}}^{-3}}$ 且 $b = -a\\,r_{\\mathrm{in}}^{6}$。\n- 案例3（带有径向狄利克雷数据的薄环）：\n  - $r_{\\mathrm{in}} = 0.5$, $r_{\\mathrm{out}} = 0.6$, $N_{r} = 16$, $N_{\\theta} = 64$。\n  - 边界值：对于所有 $\\theta$，$\\phi(r_{\\mathrm{in}},\\theta) = 0$ 和 $\\phi(r_{\\mathrm{out}},\\theta) = 1$。\n  - 解析解：$\\phi_{\\mathrm{exact}}(r,\\theta) = \\dfrac{\\ln r - \\ln r_{\\mathrm{in}}}{\\ln r_{\\mathrm{out}} - \\ln r_{\\mathrm{in}}}$，与 $\\theta$ 无关。\n\n可量化的答案：\n- 对每个案例，计算整个网格（包括边界）上的最大绝对误差 $E_{\\max} = \\max_{i,j}|\\phi_{i,j} - \\phi_{\\mathrm{exact}}(r_{i},\\theta_{j})|$。每个案例产生一个浮点数。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个逗号分隔的列表，用方括号括起来，每个浮点值都经过四舍五入并以 $6$ 位有效数字的科学记数法格式化（例如，`[1.234567e-04,2.345678e-05,3.456789e-06]`）。",
            "solution": "问题陈述已经过严格审查，并被确定为**有效**。它提出了一个适定的、有科学依据的计算物理问题，提供了计算和验证唯一解所需的所有必要定义、常数和边界条件。任务是使用逐次超松弛（SOR）法在环形域中求解拉普拉斯方程，这对此类椭圆型偏微分方程是一种标准且合适的技术。该问题没有歧义、逻辑矛盾和事实错误。我们可以着手求解。\n\n### 1. 拉普拉斯算子的有限差分离散化\n控制方程是极坐标 $(r, \\theta)$ 下的拉普拉斯方程：\n$$ \\nabla^2 \\phi = \\frac{1}{r}\\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial \\phi}{\\partial r}\\right) + \\frac{1}{r^2}\\frac{\\partial^2\\phi}{\\partial\\theta^2} = 0 $$\n我们在由点 $(r_i, \\theta_j)$ 定义的均匀极坐标网格上离散化此方程，其中 $r_i = r_{\\mathrm{in}} + i\\Delta r$（对于 $i \\in \\{0, 1, ..., N_r-1\\}$）和 $\\theta_j = j\\Delta\\theta$（对于 $j \\in \\{0, 1, ..., N_\\theta-1\\}$）。网格间距为 $\\Delta r = (r_{\\mathrm{out}}-r_{\\mathrm{in}})/(N_r-1)$ 和 $\\Delta\\theta = 2\\pi/N_\\theta$。网格点上的电势表示为 $\\phi_{i,j} \\equiv \\phi(r_i, \\theta_j)$。\n\n离散化必须是二阶精确的。我们将在内部网格点 $(r_i, \\theta_j)$ 处推导每一项的离散形式。\n\n**角向项：** 项 $\\frac{1}{r^2}\\frac{\\partial^2\\phi}{\\partial\\theta^2}$ 在 $r=r_i$ 处使用标准的二阶中心差分对 $\\theta$ 的二阶导数进行离散化：\n$$ \\left.\\frac{1}{r^2}\\frac{\\partial^2\\phi}{\\partial\\theta^2}\\right|_{(r_i, \\theta_j)} \\approx \\frac{1}{r_i^2} \\left( \\frac{\\phi_{i,j+1} - 2\\phi_{i,j} + \\phi_{i,j-1}}{(\\Delta\\theta)^2} \\right) $$\n\n**径向项：** 项 $\\frac{1}{r}\\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial \\phi}{\\partial r}\\right)$ 以散度形式给出。为保持二阶精度，我们通过在半整数网格点 $r_{i\\pm 1/2} = r_i \\pm \\Delta r/2$ 上使用中心差分来计算 $r_i$ 处的导数，从而对其进行离散化：\n$$ \\left. \\frac{1}{r}\\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial \\phi}{\\partial r}\\right) \\right|_{(r_i, \\theta_j)} \\approx \\frac{1}{r_i} \\frac{ \\left. r\\frac{\\partial\\phi}{\\partial r} \\right|_{r_{i+1/2}} - \\left. r\\frac{\\partial\\phi}{\\partial r} \\right|_{r_{i-1/2}} }{\\Delta r} $$\n在半点处的导数 $\\frac{\\partial\\phi}{\\partial r}$ 也用中心差分近似：\n$$ \\left. \\frac{\\partial\\phi}{\\partial r} \\right|_{r_{i+1/2}} \\approx \\frac{\\phi_{i+1,j} - \\phi_{i,j}}{\\Delta r} \\quad \\text{和} \\quad \\left. \\frac{\\partial\\phi}{\\partial r} \\right|_{r_{i-1/2}} \\approx \\frac{\\phi_{i,j} - \\phi_{i-1,j}}{\\Delta r} $$\n将这些代入径向项的表达式中，得到：\n$$ \\frac{1}{r_i \\Delta r} \\left[ r_{i+1/2} \\left(\\frac{\\phi_{i+1,j} - \\phi_{i,j}}{\\Delta r}\\right) - r_{i-1/2} \\left(\\frac{\\phi_{i,j} - \\phi_{i-1,j}}{\\Delta r}\\right) \\right] $$\n使用 $r_{i\\pm 1/2} = r_i \\pm \\frac{\\Delta r}{2}$，表达式变为：\n$$ \\frac{1}{r_i (\\Delta r)^2} \\left[ (r_i + \\frac{\\Delta r}{2})(\\phi_{i+1,j} - \\phi_{i,j}) - (r_i - \\frac{\\Delta r}{2})(\\phi_{i,j} - \\phi_{i-1,j}) \\right] $$\n根据电势 $\\phi$ 重新整理各项：\n$$ \\frac{1}{(\\Delta r)^2} \\left[ \\left(1 + \\frac{\\Delta r}{2r_i}\\right)\\phi_{i+1,j} - 2\\phi_{i,j} + \\left(1 - \\frac{\\Delta r}{2r_i}\\right)\\phi_{i-1,j} \\right] $$\n这是径向部分所需的二阶精确有限差分近似。\n\n**完整的离散方程：**\n完整的离散拉普拉斯方程 $\\mathcal{L}_h[\\phi]_{i,j} = 0$ 是离散径向项和角向项的和：\n$$ \\mathcal{L}_h[\\phi]_{i,j} = \\frac{1}{(\\Delta r)^2} \\left[ \\left(1 + \\frac{\\Delta r}{2r_i}\\right)\\phi_{i+1,j} + \\left(1 - \\frac{\\Delta r}{2r_i}\\right)\\phi_{i-1,j} - 2\\phi_{i,j} \\right] + \\frac{1}{r_i^2 (\\Delta\\theta)^2} [\\phi_{i,j+1} + \\phi_{i,j-1} - 2\\phi_{i,j}] = 0 $$\n\n### 2. 逐次超松弛（SOR）算法\n离散方程为内部网格点上的未知电势值 $\\phi_{i,j}$ 定义了一个大型线性方程组。我们使用 SOR 迭代求解此系统。为推导 SOR 更新规则，我们首先从离散方程中分离出 $\\phi_{i,j}$：\n$$ \\left( \\frac{2}{(\\Delta r)^2} + \\frac{2}{r_i^2 (\\Delta\\theta)^2} \\right) \\phi_{i,j} = \\frac{\\left(1 + \\frac{\\Delta r}{2r_i}\\right)}{(\\Delta r)^2}\\phi_{i+1,j} + \\frac{\\left(1 - \\frac{\\Delta r}{2r_i}\\right)}{(\\Delta r)^2}\\phi_{i-1,j} + \\frac{1}{r_i^2 (\\Delta\\theta)^2}(\\phi_{i,j+1} + \\phi_{i,j-1}) $$\n高斯-赛德尔（Gauss-Seidel）迭代将 $\\phi_{i,j}$ 更新为一个新值 $\\phi_{i,j}^{\\text{GS}}$，该值使用其邻居的最近计算值来求解此方程。按字典序（先递增 $i$，再递增 $j$）迭代点，更新使用 $\\phi_{i-1,j}^{\\text{new}}$、$\\phi_{i,j-1}^{\\text{new}}$、$\\phi_{i+1,j}^{\\text{old}}$ 和 $\\phi_{i,j+1}^{\\text{old}}$。值 $\\phi_{i,j}^{\\text{GS}}$ 为：\n$$ \\phi_{i,j}^{\\text{GS}} = \\frac{ \\frac{1}{(\\Delta r)^2} \\left[ \\left(1 + \\frac{\\Delta r}{2r_i}\\right)\\phi_{i+1,j} + \\left(1 - \\frac{\\Delta r}{2r_i}\\right)\\phi_{i-1,j} \\right] + \\frac{1}{r_i^2 (\\Delta\\theta)^2} (\\phi_{i,j+1} + \\phi_{i,j-1}) } { \\frac{2}{(\\Delta r)^2} + \\frac{2}{r_i^2 (\\Delta\\theta)^2} } $$\nSOR 方法通过引入一个松弛因子 $\\omega$ 来修改此过程。在第 $k+1$ 次迭代时，新值 $\\phi_{i,j}^{(k+1)}$ 是旧值 $\\phi_{i,j}^{(k)}$ 和高斯-赛德尔更新的加权平均：\n$$ \\phi_{i,j}^{(k+1)} = (1-\\omega)\\phi_{i,j}^{(k)} + \\omega\\,\\phi_{i,j}^{\\text{GS}} $$\n对于此问题，$\\omega = 1.85$。迭代过程通过在所有内部网格点 $(i, j)$（对于 $i \\in \\{1,...,N_r-2\\}$ 和 $j \\in \\{0,...,N_\\theta-1\\}$）上进行扫描，并在每个点应用此更新规则来进行。\n\n### 3. 实现与收敛\n算法实现如下：\n1.  **网格与初始化**：为 $\\phi$ 创建一个 $N_r \\times N_\\theta$ 的数组。根据在 $r=r_{\\mathrm{in}}$ ($i=0$) 和 $r=r_{\\mathrm{out}}$ ($i=N_r-1$) 的狄利克雷条件设置边界值。内部点初始化为 $0$。\n2.  **迭代**：一个循环最多运行 $N_{\\mathrm{it,max}}=50000$ 次迭代。\n3.  **SOR 扫描**：在循环内部，对所有内部点执行一次完整的扫描，使用 SOR 公式更新 $\\phi_{i,j}$。通过对 $j$ 索引使用模运算来处理 $\\theta$ 的周期性（例如，如果 $j=0$，$j-1$ 变为 $N_\\theta-1$）。\n4.  **收敛性检查**：在每次完整的 SOR 扫描之后，使用新更新的场 $\\phi$ 计算所有内部点的离散残差 $\\mathcal{L}_h[\\phi]_{i,j}$。计算残差的 $\\ell_\\infty$-范数，即 $\\max_{i,j} |\\mathcal{L}_h[\\phi]_{i,j}|$。如果此范数小于容差 $\\varepsilon = 10^{-8}$，则迭代终止。\n5.  **误差计算**：收敛后，将数值解 $\\phi_{i,j}$ 与提供的解析解 $\\phi_{\\mathrm{exact}}(r_i, \\theta_j)$ 进行比较。在整个网格（包括边界）上计算最大绝对误差 $E_{\\max} = \\max_{i,j} |\\phi_{i,j} - \\phi_{\\mathrm{exact}}(r_i, \\theta_j)|$。\n\n将此过程应用于问题陈述中指定的每个测试用例。收集并格式化所得的最大误差作为最终输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_case(r_in, r_out, N_r, N_theta, bc_in_func, bc_out_func, analytic_func, omega, epsilon, n_it_max):\n    \"\"\"\n    Solves the Laplace equation on an annulus using the SOR method for a single test case.\n    \"\"\"\n    # 1. Grid and Parameter Setup\n    dr = (r_out - r_in) / (N_r - 1)\n    dth = 2 * np.pi / N_theta\n    \n    r = np.linspace(r_in, r_out, N_r)\n    theta = np.linspace(0, 2 * np.pi, N_theta, endpoint=False)\n    \n    # 2D potential grid\n    phi = np.zeros((N_r, N_theta))\n    \n    # 2. Boundary Conditions\n    phi[0, :] = bc_in_func(r_in, theta)\n    phi[-1, :] = bc_out_func(r_out, theta)\n    \n    # Pre-calculate some inverse values for efficiency in loops\n    dr2_inv = 1.0 / (dr**2)\n    dth2_inv = 1.0 / (dth**2)\n\n    # 3. SOR Iteration Loop\n    for k in range(n_it_max):\n        # --- SOR Sweep ---\n        for i in range(1, N_r - 1):\n            # Coefficients that depend on r_i\n            ri = r[i]\n            ri_inv = 1.0 / ri\n            \n            coeff_ip1 = dr2_inv * (1.0 + 0.5 * dr * ri_inv)\n            coeff_im1 = dr2_inv * (1.0 - 0.5 * dr * ri_inv)\n            coeff_j_term = dth2_inv * ri_inv**2\n            \n            # Denominator of the Gauss-Seidel update term\n            den = 2.0 * dr2_inv + 2.0 * coeff_j_term\n            den_inv = 1.0 / den\n\n            for j in range(N_theta):\n                # Periodic boundary conditions in theta\n                j_plus_1 = (j + 1) % N_theta\n                j_minus_1 = (j - 1 + N_theta) % N_theta\n                \n                # Neighbors' values (using most recent updates for i-1 and j-1)\n                term_neighbors = (coeff_ip1 * phi[i + 1, j] +\n                                  coeff_im1 * phi[i - 1, j] +\n                                  coeff_j_term * (phi[i, j_plus_1] + phi[i, j_minus_1]))\n                \n                # Gauss-Seidel update value\n                phi_gs = term_neighbors * den_inv\n                \n                # SOR update\n                phi[i, j] = (1.0 - omega) * phi[i, j] + omega * phi_gs\n\n        # --- Convergence Check using Residual ---\n        max_residual = 0.0\n        for i in range(1, N_r - 1):\n            ri = r[i]\n            # Vectorized calculation for all theta points at a given radius\n            phi_i = phi[i, :]\n            phi_ip1 = phi[i+1, :]\n            phi_im1 = phi[i-1, :]\n            phi_jp1 = np.roll(phi_i, -1)\n            phi_jm1 = np.roll(phi_i, 1)\n\n            radial_term = ((1.0 + 0.5 * dr / ri) * phi_ip1 + \n                           (1.0 - 0.5 * dr / ri) * phi_im1 - \n                           2.0 * phi_i) / (dr**2)\n            angular_term = (phi_jp1 + phi_jm1 - 2.0 * phi_i) / (ri**2 * dth**2)\n            \n            residual_at_i = radial_term + angular_term\n            max_residual = max(max_residual, np.max(np.abs(residual_at_i)))\n            \n        if max_residual  epsilon:\n            break\n\n    # 4. Error Calculation\n    R_grid, THETA_grid = np.meshgrid(r, theta, indexing='ij')\n    phi_exact = analytic_func(R_grid, THETA_grid)\n    \n    max_abs_error = np.max(np.abs(phi - phi_exact))\n    \n    return max_abs_error\n\ndef solve():\n    # Define common parameters for the SOR solver\n    omega = 1.85\n    epsilon = 1e-8\n    n_it_max = 50000\n\n    # Test Case 1\n    case1_params = {\n        \"r_in\": 1.0, \"r_out\": 2.0, \"N_r\": 32, \"N_theta\": 64,\n        \"bc_in_func\": lambda r, th: np.zeros_like(th),\n        \"bc_out_func\": lambda r, th: np.ones_like(th),\n        \"analytic_func\": lambda r, th: (np.log(r) - np.log(1.0)) / (np.log(2.0) - np.log(1.0)),\n        \"omega\": omega, \"epsilon\": epsilon, \"n_it_max\": n_it_max\n    }\n\n    # Test Case 2\n    r_in_c2, r_out_c2, n_c2 = 1.0, 2.0, 3\n    a_c2 = 1.0 / (r_out_c2**n_c2 - r_in_c2**(2*n_c2) * r_out_c2**(-n_c2))\n    b_c2 = -a_c2 * r_in_c2**(2*n_c2)\n    case2_params = {\n        \"r_in\": r_in_c2, \"r_out\": r_out_c2, \"N_r\": 32, \"N_theta\": 64,\n        \"bc_in_func\": lambda r, th: np.zeros_like(th),\n        \"bc_out_func\": lambda r, th: np.cos(n_c2 * th),\n        \"analytic_func\": lambda r, th: (a_c2 * r**n_c2 + b_c2 * r**(-n_c2)) * np.cos(n_c2 * th),\n        \"omega\": omega, \"epsilon\": epsilon, \"n_it_max\": n_it_max\n    }\n\n    # Test Case 3\n    r_in_c3, r_out_c3 = 0.5, 0.6\n    case3_params = {\n        \"r_in\": r_in_c3, \"r_out\": r_out_c3, \"N_r\": 16, \"N_theta\": 64,\n        \"bc_in_func\": lambda r, th: np.zeros_like(th),\n        \"bc_out_func\": lambda r, th: np.ones_like(th),\n        \"analytic_func\": lambda r, th: (np.log(r) - np.log(r_in_c3)) / (np.log(r_out_c3) - np.log(r_in_c3)),\n        \"omega\": omega, \"epsilon\": epsilon, \"n_it_max\": n_it_max\n    }\n    \n    test_cases = [case1_params, case2_params, case3_params]\n    results = []\n    \n    for params in test_cases:\n        error = solve_case(**params)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6e}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "本节的最后一个练习将挑战一个在流体力学和弹性力学等领域中常见的高阶偏微分方程——双调和方程。解决这个问题的巧妙之处在于问题分解：这个四阶方程可以拆分为一个由两个二阶泊松方程组成的耦合系统 。这个练习展示了一种强大的问题解决策略，即将一个复杂问题分解为多个可用现有工具解决的、更简单的子问题。你将实现一个经过优化的逐次超松弛（SOR）方案，即红黑着色排序法，从而学习如何将松弛法求解器作为“积木”来搭建更复杂的解决方案，并掌握提高其计算性能的实用技巧。",
            "id": "2434002",
            "problem": "考虑在单位正方形域 $\\Omega = [0,1]\\times[0,1]$ 上的二维双调和方程，其空间坐标为 $(x,y)$：\n$$\\nabla^4 \\psi(x,y) = 0 \\quad \\text{in } \\Omega.$$\n引入由基本恒等式 $\\phi = \\nabla^2 \\psi$ 定义的辅助变量 $\\phi(x,y)$。这将双调和方程分解为耦合椭圆系统\n$$\\nabla^2 \\phi(x,y) = 0 \\quad \\text{in } \\Omega, \\qquad \\nabla^2 \\psi(x,y) = \\phi(x,y) \\quad \\text{in } \\Omega.$$\n您将使用二阶有限差分和逐次超松弛（SOR）方法，在均匀笛卡尔网格上通过松弛法求解此系统。SOR是高斯-赛德尔不动点迭代的一种特定加速方法。\n\n您的任务如下。\n\n1) 通过构造解进行建模并获得边界数据。从拉普拉斯算子 $\\nabla^2$ 和双调和算子 $\\nabla^4 = \\nabla^2(\\nabla^2)$ 的基本定义以及恒等式 $\\phi = \\nabla^2 \\psi$ 出发。考虑光滑函数\n$$\\psi^\\star(x,y) = \\frac{x^4 - y^4}{12}, \\qquad \\phi^\\star(x,y) = x^2 - y^2.$$\n从基本原理出发，验证 $\\nabla^2 \\phi^\\star(x,y) = 0$ 和 $\\nabla^2 \\psi^\\star(x,y) = \\phi^\\star(x,y)$，并因此证明 $\\psi^\\star$ 是双调和的，即 $\\nabla^4 \\psi^\\star = 0$。施加狄利克雷数据\n$$\\psi(x,y)\\big|_{\\partial\\Omega} = \\psi^\\star(x,y), \\qquad \\phi(x,y)\\big|_{\\partial\\Omega} = \\phi^\\star(x,y),$$\n使得在连续层面上，精确的内部解与 $\\psi^\\star$ 和 $\\phi^\\star$ 一致。\n\n2) 基于泰勒展开的离散化。设网格在每个坐标方向上包含 $M$ 个内部点，均匀间距为 $h = 1/(M+1)$。用 $u_{i,j}$ 表示定义在完整网格索引 $i,j \\in \\{0,1,\\dots,M+1\\}$ 上的网格函数，其中 $i=0,M+1$ 或 $j=0,M+1$ 处的值位于边界上，内部索引为 $i,j \\in \\{1,\\dots,M\\}$。使用关于 $(x_i,y_j)$ 的二阶泰勒展开和二阶导数的核心定义，推导标准的五点离散拉普拉斯算子\n$$\\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} \\approx \\left(\\nabla^2 u\\right)(x_i,y_j),$$\n其截断误差为 $\\mathcal{O}(h^2)$ 阶。将此算子应用于模型方程，以获得 $\\phi$ 的离散拉普拉斯方程和 $\\psi$ 的离散泊松方程，其中狄利克雷边界值取自 $\\phi^\\star$ 和 $\\psi^\\star$。\n\n3) 松弛算法。从离散方程和不动点思想（即新的迭代值等于经源项调整后的邻点平均值）出发，推导原地高斯-赛德尔更新，然后是使用松弛参数 $\\omega \\in (0,2)$ 的逐次超松弛（SOR）更新。实现一个红黑SOR方案（棋盘格排序），该方案在奇偶性为 $(i+j)\\bmod 2 = 0$ 和 $(i+j)\\bmod 2 = 1$ 的内部点之间交替更新，以利用数据局部性并改善收敛性。使用离散残差\n$$r_{i,j} = f_{i,j} - \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2}$$\n作为停止准则，当内部点上残差的最大范数小于或等于指定的容差 $\\tau$ 时，终止求解。\n\n4) 算法工作流程。对每个测试用例：\n- 初始化网格，将 $\\phi$ 的边界值设为 $\\phi^\\star$，$\\psi$ 的边界值设为 $\\psi^\\star$，将内部初始猜测值设为 $0$，并在求解 $\\phi$ 时设 $f\\equiv 0$。\n- 使用红黑SOR方法求解 $\\phi$ 的离散拉普拉斯方程，直到残差最大范数低于容差 $\\tau$。\n- 将求解 $\\psi$ 的离散源项设置为已收敛的 $\\phi$ 的内部值，并使用红黑SOR方法求解 $\\psi$ 的离散泊松方程，直到残差最大范数低于 $\\tau$。\n- 计算内部点上 $\\psi$ 相对于构造解 $\\psi^\\star$ 的最大绝对误差：\n$$E_\\infty = \\max_{1 \\le i,j \\le M} \\left| \\psi_{i,j} - \\psi^\\star(x_i,y_j) \\right|.$$\n\n5) 测试套件。您的程序必须运行以下四个测试用例，并按顺序报告每个用例中 $\\psi$ 的内部最大绝对误差 $E_\\infty$：\n- 用例 A (常规路径): $M = 8$, $\\omega = 1.8$, $\\tau = 1\\times 10^{-10}$。\n- 用例 B (最小内部): $M = 1$, $\\omega = 1.5$, $\\tau = 1\\times 10^{-12}$。\n- 用例 C (加密网格): $M = 16$, $\\omega = 1.9$, $\\tau = 1\\times 10^{-10}$。\n- 用例 D (更大网格，激进松弛): $M = 32$, $\\omega = 1.95$, $\\tau = 1\\times 10^{-9}$。\n\n每次求解使用固定的最大迭代次数 $K_{\\max} = 20000$ 以保证即使未达到容差也能终止，并在每个测试用例中对 $\\phi$ 和 $\\psi$ 的求解使用相同的 $\\tau$。\n\n6) 最终输出格式。您的程序应生成单行输出，其中包含四个结果，以逗号分隔的列表形式，并用方括号括起来，顺序为 A, B, C, D，例如\n`[E_A, E_B, E_C, E_D]`,\n其中每个 $E_\\bullet$ 是一个十进制实数。\n\n此问题不涉及物理单位或角度，因此不需要单位转换。报告的数值均为无量纲实数。",
            "solution": "所提出的问题是计算物理学中一个良置的练习，要求使用标准分解和迭代松弛法对二维双调和方程进行数值求解。问题陈述在科学上是合理的，在数学上是一致的，并为获得唯一解提供了所有必要的数据。我们将按照规定进行推导和实现。\n\n问题首先要求验证所提供的构造解。控制方程是以下耦合系统：\n$$\n\\nabla^2 \\phi(x,y) = 0 \\quad (1)\n$$\n$$\n\\nabla^2 \\psi(x,y) = \\phi(x,y) \\quad (2)\n$$\n提议的精确解是 $\\psi^\\star(x,y) = \\frac{x^4 - y^4}{12}$ 和 $\\phi^\\star(x,y) = x^2 - y^2$。我们必须验证这些函数满足该系统。\n\n首先，我们计算 $\\phi^\\star(x,y)$ 的拉普拉斯算子：\n$$\n\\frac{\\partial \\phi^\\star}{\\partial x} = 2x \\implies \\frac{\\partial^2 \\phi^\\star}{\\partial x^2} = 2\n$$\n$$\n\\frac{\\partial \\phi^\\star}{\\partial y} = -2y \\implies \\frac{\\partial^2 \\phi^\\star}{\\partial y^2} = -2\n$$\n$$\n\\nabla^2 \\phi^\\star = \\frac{\\partial^2 \\phi^\\star}{\\partial x^2} + \\frac{\\partial^2 \\phi^\\star}{\\partial y^2} = 2 + (-2) = 0\n$$\n这证实了 $\\phi^\\star(x,y)$ 满足方程 (1)。它是一个调和函数。\n\n接下来，我们计算 $\\psi^\\star(x,y)$ 的拉普拉斯算子：\n$$\n\\frac{\\partial \\psi^\\star}{\\partial x} = \\frac{4x^3}{12} = \\frac{x^3}{3} \\implies \\frac{\\partial^2 \\psi^\\star}{\\partial x^2} = x^2\n$$\n$$\n\\frac{\\partial \\psi^\\star}{\\partial y} = \\frac{-4y^3}{12} = -\\frac{y^3}{3} \\implies \\frac{\\partial^2 \\psi^\\star}{\\partial y^2} = -y^2\n$$\n$$\n\\nabla^2 \\psi^\\star = \\frac{\\partial^2 \\psi^\\star}{\\partial x^2} + \\frac{\\partial^2 \\psi^\\star}{\\partial y^2} = x^2 - y^2\n$$\n我们观察到 $\\nabla^2 \\psi^\\star = \\phi^\\star(x,y)$，这证实了 $\\psi^\\star(x,y)$ 在 $\\phi = \\phi^\\star$ 的情况下满足方程 (2)。因此，$\\psi^\\star$ 是双调和的，因为 $\\nabla^4 \\psi^\\star = \\nabla^2(\\nabla^2 \\psi^\\star) = \\nabla^2 \\phi^\\star = 0$。该构造解是正确的。\n\n下一步是拉普拉斯算子的离散化。我们对网格函数 $u(x,y)$ 在点 $(x_i, y_j)$ 周围使用泰勒级数展开。对于 $x$ 方向：\n$$\nu(x_i+h, y_j) = u_{i+1,j} = u_{i,j} + h \\frac{\\partial u}{\\partial x} \\bigg|_{i,j} + \\frac{h^2}{2} \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} + \\frac{h^3}{6} \\frac{\\partial^3 u}{\\partial x^3} \\bigg|_{i,j} + \\mathcal{O}(h^4)\n$$\n$$\nu(x_i-h, y_j) = u_{i-1,j} = u_{i,j} - h \\frac{\\partial u}{\\partial x} \\bigg|_{i,j} + \\frac{h^2}{2} \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} - \\frac{h^3}{6} \\frac{\\partial^3 u}{\\partial x^3} \\bigg|_{i,j} + \\mathcal{O}(h^4)\n$$\n将这两个展开式相加可以消去奇数阶导数项：\n$$\nu_{i+1,j} + u_{i-1,j} = 2u_{i,j} + h^2 \\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} + \\mathcal{O}(h^4)\n$$\n整理后可得到关于 $x$ 的二阶偏导数的二阶中心差分近似：\n$$\n\\frac{\\partial^2 u}{\\partial x^2} \\bigg|_{i,j} = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\mathcal{O}(h^2)\n$$\n对于 $y$ 方向，存在一个类似的表达式：\n$$\n\\frac{\\partial^2 u}{\\partial y^2} \\bigg|_{i,j} = \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} + \\mathcal{O}(h^2)\n$$\n将这两个表达式相加，得到离散拉普拉斯算子 $\\nabla_h^2$ 的五点模板：\n$$\n(\\nabla_h^2 u)_{i,j} = \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} \\approx (\\nabla^2 u)(x_i, y_j)\n$$\n此近似的截断误差为 $\\mathcal{O}(h^2)$ 阶。将其应用于耦合系统，对于内部网格点 $(i,j)$（其中 $i,j \\in \\{1,...,M\\}$），可得：\n$$\n\\frac{\\phi_{i+1,j} + \\phi_{i-1,j} + \\phi_{i,j+1} + \\phi_{i,j-1} - 4\\phi_{i,j}}{h^2} = 0 \\quad (3)\n$$\n$$\n\\frac{\\psi_{i+1,j} + \\psi_{i-1,j} + \\psi_{i,j+1} + \\psi_{i,j-1} - 4\\psi_{i,j}}{h^2} = \\phi_{i,j} \\quad (4)\n$$\n这些是待求解的离散方程。对于一个通用的离散泊松方程 $(\\nabla_h^2 u)_{i,j} = f_{i,j}$，我们可以通过分离 $u_{i,j}$ 来写出一个不动点迭代式：\n$$\n4u_{i,j} = u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - h^2 f_{i,j}\n$$\n高斯-赛德尔方法使用其邻点的最新计算值来原地更新 $u_{i,j}$：\n$$\nu_{i,j}^{(k+1)} = \\frac{1}{4} \\left( u_{i+1,j}^{(\\text{old})} + u_{i-1,j}^{(\\text{new})} + u_{i,j+1}^{(\\text{old})} + u_{i,j-1}^{(\\text{new})} - h^2 f_{i,j} \\right)\n$$\n其中“新”和“旧”邻值的选择取决于扫描顺序。逐次超松弛（SOR）方法通过引入一个松弛参数 $\\omega$ 来加速收敛。对 $u_{i,j}$ 的SOR更新是其当前值和高斯-赛德尔更新值的加权平均：\n$$\nu_{i,j}^{(k+1)} = (1-\\omega) u_{i,j}^{(k)} + \\omega \\left[ \\frac{1}{4} \\left( \\dots \\right) \\right]\n$$\n其中方括号中的项是高斯-赛德尔更新值，我们将其表示为 $\\tilde{u}_{i,j}^{(k+1)}$。完整的SOR更新表达式为：\n$$\nu_{i,j} \\leftarrow (1-\\omega) u_{i,j} + \\frac{\\omega}{4} \\left( u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - h^2 f_{i,j} \\right)\n$$\n红黑排序方案将网格点划分为两个集合：'红点'（其中 $(i+j)$ 为偶数）和'黑点'（其中 $(i+j)$ 为奇数）。关键在于，一个红点的所有邻点都是黑点，反之亦然。这允许仅使用上一次迭代步骤中黑点的值来同时更新所有红点。然后，使用新计算出的红点值同时更新所有黑点。这个双扫描过程构成一次完整的SOR迭代，并且易于向量化。\n\n停止准则是基于离散残差 $r_{i,j} = f_{i,j} - (\\nabla_h^2 u)_{i,j}$。当给定场的残差在所有内部点上的最大绝对值降至容差 $\\tau$ 以下时，迭代终止：$\\|\\mathbf{r}\\|_\\infty = \\max_{1 \\le i,j \\le M} |r_{i,j}| \\le \\tau$。\n\n整体算法流程如下：\n1.  初始化大小为 $(M+2) \\times (M+2)$ 的 $\\phi$ 和 $\\psi$ 网格。使用精确函数 $\\phi^\\star(x,y)$ 和 $\\psi^\\star(x,y)$ 在这些网格上设置边界值。将所有内部点初始化为 $0$。\n2.  求解 $\\phi$ 的离散拉普拉斯方程（方程 (3)，其中 $f_{i,j}=0$）。使用指定的 $\\omega$ 进行红黑SOR迭代，直到残差范数低于 $\\tau$ 或达到最大迭代次数 $K_{\\max}$。\n3.  求解 $\\psi$ 的离散泊松方程（方程 (4)）。源项是上一步获得的已收敛的 $\\phi$ 的内部解。使用相同的 $\\omega$ 和 $\\tau$ 进行红黑SOR迭代，直到收敛。\n4.  在 $\\psi$ 场收敛后，计算最大绝对误差 $E_\\infty = \\max_{1 \\le i,j \\le M} |\\psi_{i,j} - \\psi^\\star(x_i, y_j)|$。\n\n对问题陈述中指定的每个测试用例重复此过程。最终的实现将精确遵循这一逻辑。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy  # Per environment specification, though not used in the logic.\n\ndef solve_system(M, omega, tau, k_max):\n    \"\"\"\n    Solves the coupled elliptic system for a given set of parameters.\n\n    Args:\n        M (int): Number of interior points per dimension.\n        omega (float): SOR relaxation parameter.\n        tau (float): Convergence tolerance for the residual.\n        k_max (int): Maximum number of iterations.\n\n    Returns:\n        float: The maximum absolute error E_infty for psi.\n    \"\"\"\n    # 1. Grid setup\n    h = 1.0 / (M + 1)\n    # Grid coordinates, including boundaries\n    grid_coords = np.linspace(0.0, 1.0, M + 2)\n    x, y = np.meshgrid(grid_coords, grid_coords)\n\n    # Manufactured solutions\n    def phi_star_func(x_val, y_val):\n        return x_val**2 - y_val**2\n    \n    def psi_star_func(x_val, y_val):\n        return (x_val**4 - y_val**4) / 12.0\n\n    # Initialize fields phi and psi\n    phi = np.zeros((M + 2, M + 2), dtype=np.float64)\n    psi = np.zeros((M + 2, M + 2), dtype=np.float64)\n\n    # Set boundary conditions\n    phi = phi_star_func(x, y)\n    psi = psi_star_func(x, y)\n    \n    # Set interior initial guess to 0\n    phi[1:-1, 1:-1] = 0.0\n    psi[1:-1, 1:-1] = 0.0\n    \n    h2 = h * h\n\n    # 2. Solve for phi (Laplace equation: nabla^2 phi = 0)\n    for k in range(k_max):\n        # Red-black SOR update for phi\n        # Red points (i+j is even)\n        phi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 0,\n                                   (1 - omega) * phi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       phi[2:, 1:-1] + phi[:-2, 1:-1] +\n                                       phi[1:-1, 2:] + phi[1:-1, :-2]),\n                                   phi[1:-1, 1:-1])\n        # Black points (i+j is odd)\n        phi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 1,\n                                   (1 - omega) * phi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       phi[2:, 1:-1] + phi[:-2, 1:-1] +\n                                       phi[1:-1, 2:] + phi[1:-1, :-2]),\n                                   phi[1:-1, 1:-1])\n\n        # Check for convergence\n        if k % 10 == 0:  # Check residual periodically\n            residual = (phi[2:, 1:-1] + phi[:-2, 1:-1] + phi[1:-1, 2:] + phi[1:-1, :-2] - 4 * phi[1:-1, 1:-1]) / h2\n            if np.max(np.abs(residual)) = tau:\n                break\n    \n    # 3. Solve for psi (Poisson equation: nabla^2 psi = phi)\n    f_psi = phi[1:-1, 1:-1].copy() # Source term is the interior phi\n    \n    for k in range(k_max):\n        # Red-black SOR update for psi\n        # Red points\n        psi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 0,\n                                   (1 - omega) * psi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       psi[2:, 1:-1] + psi[:-2, 1:-1] +\n                                       psi[1:-1, 2:] + psi[1:-1, :-2] - h2 * f_psi),\n                                   psi[1:-1, 1:-1])\n        # Black points\n        psi[1:-1, 1:-1] = np.where((np.arange(M)[np.newaxis,:] + np.arange(M)[:,np.newaxis]) % 2 == 1,\n                                   (1 - omega) * psi[1:-1, 1:-1] + (omega / 4.0) * (\n                                       psi[2:, 1:-1] + psi[:-2, 1:-1] +\n                                       psi[1:-1, 2:] + psi[1:-1, :-2] - h2 * f_psi),\n                                   psi[1:-1, 1:-1])\n\n        # Check for convergence\n        if k % 10 == 0:\n            residual = f_psi - (psi[2:, 1:-1] + psi[:-2, 1:-1] + psi[1:-1, 2:] + psi[1:-1, :-2] - 4 * psi[1:-1, 1:-1]) / h2\n            if np.max(np.abs(residual)) = tau:\n                break\n\n    # 4. Compute final error E_infty\n    x_interior = grid_coords[1:-1]\n    y_interior = grid_coords[1:-1]\n    xv_int, yv_int = np.meshgrid(x_interior, y_interior)\n    psi_exact_interior = psi_star_func(xv_int, yv_int)\n    \n    psi_numeric_interior = psi[1:-1, 1:-1]\n    \n    error = np.max(np.abs(psi_numeric_interior - psi_exact_interior))\n    \n    return error\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (8, 1.8, 1e-10),   # Case A\n        (1, 1.5, 1e-12),   # Case B\n        (16, 1.9, 1e-10),  # Case C\n        (32, 1.95, 1e-9), # Case D\n    ]\n    \n    k_max = 20000\n    results = []\n    \n    for case in test_cases:\n        M, omega, tau = case\n        result = solve_system(M, omega, tau, k_max)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}