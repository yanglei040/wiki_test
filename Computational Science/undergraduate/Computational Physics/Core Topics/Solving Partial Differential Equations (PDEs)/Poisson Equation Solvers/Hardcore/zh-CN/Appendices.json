{
    "hands_on_practices": [
        {
            "introduction": "评估数值解质量的一个基本方法是考察其在网格加密时的收敛行为。这个练习  将引导你亲手量化一个二阶精度格式的收敛性。更进一步，你将学习如何利用关于误差阶数的知识，通过理查森外推法 (Richardson extrapolation) 构造出一个更高精度的解，这是一种将离散化误差的理论概念转化为强大实用技巧的经典方法。",
            "id": "2427894",
            "problem": "给定一个数学任务，要求计算方形域上二维泊松问题的数值近似解。考虑在开放单位正方形 $\\Omega = (0,1) \\times (0,1)$ 上的偏微分方程 (PDE) $- \\nabla^2 u(x,y) = f(x,y)$，其齐次狄利克雷边界条件为在 $\\partial \\Omega$ 上 $u(x,y) = 0$。对于每一组给定的正整数对 $(k,\\ell)$，定义精确解为 $u^{\\star}(x,y) = \\sin(k \\pi x) \\sin(\\ell \\pi y)$，因此源项为 $f(x,y) = \\pi^2 (k^2 + \\ell^2) \\sin(k \\pi x) \\sin(\\ell \\pi y)$。角度以弧度为单位。\n\n对于下述每个测试用例，考虑在 $\\Omega$ 上一个均匀的笛卡尔网格，每个空间方向上有 $N_{\\mathrm{c}}$ 个内部点，网格间距为 $h_{\\mathrm{c}} = 1/(N_{\\mathrm{c}}+1)$。同时考虑一个更精细的网格，每个方向上有 $N_{\\mathrm{f}} = 2 N_{\\mathrm{c}} + 1$ 个内部点，网格间距为 $h_{\\mathrm{f}} = 1/(N_{\\mathrm{f}}+1) = h_{\\mathrm{c}}/2$。在每个网格上，使用任何相容的、在所述均匀网格上二阶精确的空间离散化方法，在内部网格点上计算 $u(x,y)$ 的数值近似解，该方法需强制执行齐次狄利克雷边界条件。\n\n令 $U_{\\mathrm{c}}$ 表示粗网格上的数值解，令 $U_{\\mathrm{f}}$ 表示细网格上的数值解。令 $\\mathcal{I}$ 为粗网格内部节点的集合，令 $U_{\\mathrm{f}\\to\\mathrm{c}}$ 表示细网格数值解在与粗网格重合的细网格子集上的限制（即，细网格内部节点中坐标与 $\\mathcal{I}$ 中节点坐标匹配的子集）。假设所选二阶格式的逐点离散误差允许一个关于网格间距 $h$ 的偶次幂渐近展开，并且在精确解光滑的每个固定网格点上，其首个非零项与 $h^2$ 成正比。\n\n对于每个测试用例，计算以下三个标量值：\n- $E_{\\mathrm{c}}$，粗网格解在 $\\mathcal{I}$ 上的离散最大范数绝对误差，定义为 $E_{\\mathrm{c}} = \\max_{(x_i,y_j)\\in \\mathcal{I}} \\left| U_{\\mathrm{c}}(x_i,y_j) - u^{\\star}(x_i,y_j) \\right|$。\n- $E_{\\mathrm{f}\\to\\mathrm{c}}$，限制在 $\\mathcal{I}$ 上的细网格解的离散最大范数绝对误差，定义为 $E_{\\mathrm{f}\\to\\mathrm{c}} = \\max_{(x_i,y_j)\\in \\mathcal{I}} \\left| U_{\\mathrm{f}\\to\\mathrm{c}}(x_i,y_j) - u^{\\star}(x_i,y_j) \\right|$。\n- $E_{\\mathrm{comb}}$，在 $\\mathcal{I}$ 上的组合估计的离散最大范数绝对误差，该组合估计在每个点 $(x_i,y_j)\\in \\mathcal{I}$ 上由 $U_{\\mathrm{c}}(x_i,y_j)$ 和 $U_{\\mathrm{f}\\to\\mathrm{c}}(x_i,y_j)$ 构成，其方式是在上述假设下消除了偶次幂截断误差展开中的主阶项。报告 $E_{\\mathrm{comb}} = \\max_{(x_i,y_j)\\in \\mathcal{I}} \\left| U_{\\mathrm{comb}}(x_i,y_j) - u^{\\star}(x_i,y_j) \\right|$。\n\n测试套件：\n- 用例1：$(k,\\ell,N_{\\mathrm{c}}) = (1,1,15)$。\n- 用例2：$(k,\\ell,N_{\\mathrm{c}}) = (2,1,7)$。\n- 用例3：$(k,\\ell,N_{\\mathrm{c}}) = (3,2,21)$。\n\n您的程序必须生成单行输出，其中包含一个列表的列表形式的结果，顺序如下：对于上面列出的每个用例，按顺序输出三元组 $[E_{\\mathrm{c}}, E_{\\mathrm{f}\\to\\mathrm{c}}, E_{\\mathrm{comb}}]$。最终打印的行必须是一个表示这三个三元组列表的单个字符串，例如 $[[a_{11},a_{12},a_{13}],[a_{21},a_{22},a_{23}],[a_{31},a_{32},a_{33}]]$, 其中每个 $a_{ij}$ 是一个浮点数。\n\n输出中的所有浮点数都必须以科学记数法打印，小数点后保留八位数字。\n\n此问题不涉及任何物理单位。所有三角函数中的角度必须以弧度为单位。",
            "solution": "该问题在科学上和数学上都是合理的。它提出了一个适定的泊松方程边值问题，并要求使用标准的、定义明确的技术进行数值求解和误差分析。所有必要的数据和定义都已提供。因此，我们将着手求解。\n\n问题的核心是在单位正方形域 $\\Omega = (0,1) \\times (0,1)$上求解二维泊松方程\n$$\n- \\nabla^2 u(x,y) = f(x,y)\n$$\n并满足齐次狄利克雷边界条件，即对于 $(x,y) \\in \\partial\\Omega$ 有 $u(x,y) = 0$。源项 $f(x,y)$ 是通过制造解方法确定的，其中精确解被指定为 $u^{\\star}(x,y) = \\sin(k \\pi x) \\sin(\\ell \\pi y)$。应用负拉普拉斯算子，我们验证给定的源项：\n$$\n- \\nabla^2 u^{\\star}(x,y) = -\\left(\\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2}\\right) \\left[ \\sin(k \\pi x) \\sin(\\ell \\pi y) \\right] = \\pi^2 (k^2+\\ell^2) \\sin(k \\pi x) \\sin(\\ell \\pi y) = f(x,y).\n$$\n该问题要求在均匀笛卡尔网格上使用二阶精确的空间离散化来获得数值解。对此，标准的选择是五点有限差分格式。对于在 $x$ 和 $y$ 方向上具有均匀间距 $h$ 的网格，内部网格节点 $(x_i, y_j)$ 处的拉普拉斯算子近似为：\n$$\n\\nabla^2 u(x_i, y_j) \\approx \\frac{U_{i+1,j} - 2U_{i,j} + U_{i-1,j}}{h^2} + \\frac{U_{i,j+1} - 2U_{i,j} + U_{i,j-1}}{h^2}.\n$$\n这里，$U_{i,j}$ 表示 $u(x_i, y_j)$ 的数值近似。将此代入泊松方程 $- \\nabla^2 u = f$ 并重新整理各项，得到每个内部节点 $(i,j)$ 处的离散方程：\n$$\n4U_{i,j} - U_{i-1,j} - U_{i+1,j} - U_{i,j-1} - U_{i,j+1} = h^2 f(x_i, y_j).\n$$\n该格式是相容的，并且具有二阶截断误差，即 $O(h^2)$。通过在节点 $(i,j)$ 位于边界 $\\partial\\Omega$ 上时设置 $U_{i,j} = 0$ 来强制执行齐次狄利克雷边界条件 $u=0$。对于每个方向有 $N$ 个内部点的网格，这组 $N^2$ 个线性代数方程可以组合成一个矩阵系统 $A\\mathbf{U} = \\mathbf{b}$，其中 $\\mathbf{U}$ 是包含 $N^2$ 个未知值 $U_{i,j}$ 的向量，$A$ 是一个大小为 $N^2 \\times N^2$ 的稀疏、对称正定块三对角矩阵，$\\mathbf{b}$ 是一个包含网格点上 $h^2 f(x_i, y_j)$ 值的向量。这个系统可以被高效地求解以得到 $\\mathbf{U}$。\n\n该问题要求在网格间距为 $h_{\\mathrm{c}}$ 的粗网格和间距为 $h_{\\mathrm{f}} = h_{\\mathrm{c}}/2$ 的细网格上计算误差。此外，它还要求使用理查森外推法导出一个组合解。问题陈述，逐点误差有一个关于 $h$ 的偶次幂的渐近展开：\n$$\nU_h(x,y) = u^{\\star}(x,y) + C(x,y)h^2 + D(x,y)h^4 + \\dots\n$$\n令 $U_{\\mathrm{c}}$ 为粗网格（间距 $h_{\\mathrm{c}}$）上的解，$U_{\\mathrm{f}}$ 为细网格（间距 $h_{\\mathrm{f}}$）上的解。在同时属于两个网格的节点 $(x,y)$ 处，我们有：\n$$\nU_{\\mathrm{c}}(x,y) = u^{\\star}(x,y) + C(x,y)h_{\\mathrm{c}}^2 + O(h_{\\mathrm{c}}^4)\n$$\n$$\nU_{\\mathrm{f}}(x,y) = u^{\\star}(x,y) + C(x,y)h_{\\mathrmf}^2 + O(h_{\\mathrm{f}}^4) = u^{\\star}(x,y) + C(x,y)\\frac{h_{\\mathrm{c}}^2}{4} + O(h_{\\mathrm{c}}^4).\n$$\n我们可以通过线性组合这两个方程来消除主误差项 $C(x,y)h_{\\mathrm{c}}^2$。将第二个方程乘以 $4$ 并减去第一个方程，得到：\n$$\n4U_{\\mathrm{f}}(x,y) - U_{\\mathrm{c}}(x,y) = 3u^{\\star}(x,y) + O(h_{\\mathrm{c}}^4).\n$$\n这就得到了一个更精确的 $u^{\\star}(x,y)$ 估计值，我们将其定义为组合解 $U_{\\mathrm{comb}}$：\n$$\nU_{\\mathrm{comb}}(x,y) = \\frac{4U_{\\mathrm{f}}(x,y) - U_{\\mathrm{c}}(x,y)}{3}.\n$$\n这个组合解的误差阶为 $O(h_{\\mathrmc}^4)$，比原始解的 $O(h_{\\mathrm{c}}^2)$ 误差有所改进。在我们的情况下，比较是在粗网格节点集 $\\mathcal{I}$ 上进行的。因此，我们在公式中使用 $U_{\\mathrm{f}\\to\\mathrm{c}}$，即细网格解在这些节点上的限制：\n$$\nU_{\\mathrm{comb}} = \\frac{4U_{\\mathrm{f}\\to\\mathrm{c}} - U_{\\mathrm{c}}}{3}.\n$$\n所需的量 $E_{\\mathrm{c}}$、$E_{\\mathrm{f}\\to\\mathrm{c}}$ 和 $E_{\\mathrm{comb}}$ 分别是对应数值解 $U_{\\mathrm{c}}$、$U_{\\mathrm{f}\\to\\mathrm{c}}$ 和 $U_{\\mathrm{comb}}$ 的离散最大范数绝对误差，定义为 $E = \\max_{(x_i,y_j)\\in \\mathcal{I}} \\left| U(x_i,y_j) - u^{\\star}(x_i,y_j) \\right|$。\n\n对于每个测试用例 $(k,\\ell,N_{\\mathrm{c}})$，算法流程如下：\n$1$. 定义粗网格，其内部点数为 $N_{\\mathrm{c}}$，间距为 $h_{\\mathrm{c}} = 1/(N_{\\mathrm{c}}+1)$。\n$2$. 定义细网格，其内部点数为 $N_{\\mathrm{f}} = 2N_{\\mathrm{c}}+1$，间距为 $h_{\\mathrm{f}} = h_{\\mathrm{c}}/2$。\n$3$. 求解线性系统 $A_{\\mathrm{c}}\\mathbf{U}_{\\mathrm{c}} = \\mathbf{b}_{\\mathrm{c}}$ 以获得粗网格解 $U_{\\mathrm{c}}$。\n$4$. 求解线性系统 $A_{\\mathrm{f}}\\mathbf{U}_{\\mathrm{f}} = \\mathbf{b}_{\\mathrm{f}}$ 以获得细网格解 $U_{\\mathrm{f}}$。\n$5$. 在粗网格节点上评估精确解 $u^{\\star}$。\n$6$. 将细网格解 $U_{\\mathrm{f}}$ 限制到粗网格节点上以获得 $U_{\\mathrm{f}\\to\\mathrm{c}}$。这涉及到从细网格解数组中每隔一个点选取一个点。\n$7$. 使用理查森外推公式计算粗网格上的组合解 $U_{\\mathrm{comb}}$。\n$8$. 通过将粗网格上的 $U_{\\mathrm{c}}$、$U_{\\mathrm{f}\\to\\mathrm{c}}$ 和 $U_{\\mathrm{comb}}$ 与精确解 $u^{\\star}$ 进行比较，计算最大范数误差 $E_{\\mathrm{c}}$、$E_{\\mathrm{f}\\to\\mathrm{c}}$ 和 $E_{\\mathrm{comb}}$。\n对所有指定的测试用例重复此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\n\ndef setup_and_solve_poisson(N, k, l):\n    \"\"\"\n    Sets up and solves the 2D Poisson problem on an N x N interior grid using\n    a five-point finite difference scheme.\n\n    Args:\n        N (int): The number of interior grid points in each spatial direction.\n        k (int): Wavenumber in the x-direction for the manufactured solution.\n        l (int): Wavenumber in the y-direction for the manufactured solution.\n\n    Returns:\n        tuple: A tuple containing:\n            - U (np.ndarray): The 2D numerical solution array of shape (N, N).\n            - xx (np.ndarray): The 2D array of x-coordinates.\n            - yy (np.ndarray): The 2D array of y-coordinates.\n    \"\"\"\n    h = 1.0 / (N + 1)\n    \n    # Create grid coordinates for interior points\n    x = np.linspace(h, 1.0 - h, N)\n    y = np.linspace(h, 1.0 - h, N)\n    xx, yy = np.meshgrid(x, y)\n    \n    # Evaluate the source term f(x,y) on the grid\n    f_grid = (np.pi**2 * (k**2 + l**2) * \n              np.sin(k * np.pi * xx) * np.sin(l * np.pi * yy))\n    \n    # Flatten the source term into the RHS vector b, using column-major (Fortran) order\n    b = h**2 * f_grid.flatten(order='F')\n    \n    # Construct the sparse matrix A for the 5-point stencil\n    N2 = N * N\n    \n    main_diag = np.full(N2, 4.0)\n    \n    # Off-diagonals for x-connections (indices i-1, i+1)\n    off_diag_x = np.full(N2 - 1, -1.0)\n    # Remove connections across column boundaries in the flattened vector\n    off_diag_x[N-1::N] = 0.0\n    \n    # Off-diagonals for y-connections (indices j-1, j+1)\n    off_diag_y = np.full(N2 - N, -1.0)\n    \n    diagonals = [main_diag, off_diag_x, off_diag_x, off_diag_y, off_diag_y]\n    offsets = [0, 1, -1, N, -N]\n    \n    # Create the sparse matrix in Compressed Sparse Row format for efficiency\n    A = sparse.diags(diagonals, offsets, shape=(N2, N2), format='csr')\n    \n    # Solve the linear system A*U = b\n    # Using spsolve from SciPy's sparse linear algebra library\n    u_vec = spsolve(A, b)\n    \n    # Reshape the solution vector back to a 2D grid, using the same column-major order\n    U = u_vec.reshape((N, N), order='F')\n    \n    return U, xx, yy\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 1, 15),\n        (2, 1, 7),\n        (3, 2, 21),\n    ]\n\n    all_results_str = []\n    \n    for case in test_cases:\n        k, l, Nc = case\n        \n        # Define fine grid parameters based on coarse grid\n        Nf = 2 * Nc + 1\n        \n        # Solve the PDE on the coarse grid\n        Uc, xc, yc = setup_and_solve_poisson(Nc, k, l)\n        \n        # Solve the PDE on the fine grid\n        Uf, _, _ = setup_and_solve_poisson(Nf, k, l)\n        \n        # Evaluate the exact solution on the coarse grid for error calculation\n        u_star_c = np.sin(k * np.pi * xc) * np.sin(l * np.pi * yc)\n        \n        # Restrict the fine grid solution to the coarse grid nodes.\n        # Coarse grid nodes correspond to odd-indexed nodes (1, 3, 5, ...) in the fine grid.\n        Uf_to_c = Uf[1::2, 1::2]\n        \n        # Apply Richardson extrapolation to get a higher-order accurate solution\n        # U_comb = U_f_to_c + (U_f_to_c - U_c) / (r^p - 1), where r=2, p=2.\n        U_comb = (4.0 * Uf_to_c - Uc) / 3.0\n        \n        # Calculate discrete maximum-norm absolute errors\n        Ec = np.max(np.abs(Uc - u_star_c))\n        Ef_to_c = np.max(np.abs(Uf_to_c - u_star_c))\n        E_comb = np.max(np.abs(U_comb - u_star_c))\n        \n        # Format the results for this case as specified (scientific notation, 8 decimal places)\n        case_result_str = f\"[{Ec:.8e},{Ef_to_c:.8e},{E_comb:.8e}]\"\n        all_results_str.append(case_result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在我们掌握了如何在简单的正方形区域上求解泊松方程后，现在让我们来探索一个更复杂的几何构型。在断裂力学和电磁学等领域，域中的凹角 (re-entrant corners) 会导致解的导数出现奇点。这个练习  演示了数值求解器不仅可以用来计算势场，更可以作为一个“计算实验”工具，用来测量解在角点的奇性指数等理论性质，从而揭示问题背后深刻的数学与物理内涵。",
            "id": "2427929",
            "problem": "考虑一个有界平面域 $\\Omega$ 上的静电势 $u(x,y)$ 的二维拉普拉斯方程，\n$$\n\\Delta u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = 0 \\quad \\text{in } \\Omega,\n$$\n其狄利克雷边界条件在 $\\partial \\Omega$ 上指定为\n$$\nu(0,y) = 1 \\quad \\text{for } y \\in [0,1] \\text{ that belong to } \\partial \\Omega, \\quad u = 0 \\quad \\text{on the rest of } \\partial \\Omega.\n$$\n将考虑两个域：\n- L 形域 $\\Omega_L = \\{(x,y) \\in [0,1]^2 \\,:\\, x \\le 0.5 \\text{ or } y \\le 0.5\\}$，它在 $c = (0.5,0.5)$ 处有一个凹角，内角为 $\\omega = 3\\pi/2$。\n- 方形域 $\\Omega_S = [0,1]^2$，其中点 $c = (0.5,0.5)$ 位于其内部，且没有凹角。\n\n对于给定的整数分辨率参数 $N \\ge 2$，定义间距为 $h = 1/N$ 的均匀网格，网格节点为 $(x_i,y_j) = (i h, j h)$，其中整数 $i,j \\in \\{0,1,\\dots,N\\}$。假设 $N$ 为偶数，以使凹角 $c$ 与网格线对齐。令 $u_{i,j}$ 表示 $u(x_i,y_j)$ 的数值近似解，该解是通过精确施加狄利克雷边界条件并通过求解所选域内部的拉普拉斯方程得到的。\n\n在梯度有良好定义的网格节点处，通过中心差分定义其梯度大小为\n$$\n\\left|\\nabla u\\right|_{i,j} = \\sqrt{\\left(\\frac{u_{i+1,j} - u_{i-1,j}}{2h}\\right)^2 + \\left(\\frac{u_{i,j+1} - u_{i,j-1}}{2h}\\right)^2},\n$$\n当所有引用的值都属于该域时。对于固定点 $c = (0.5,0.5)$，定义其到网格节点 $(x_i,y_j)$ 的离散距离为\n$$\nr_{i,j} = \\sqrt{(x_i - 0.5)^2 + (y_j - 0.5)^2}.\n$$\n对于每个整数环指数 $k \\in \\{2,3,\\dots,10\\}$，定义环\n$$\n\\mathcal{A}_k = \\left\\{ (i,j) \\,:\\, \\text{the gradient magnitude is defined at } (i,j) \\text{ and } k h \\le r_{i,j}  (k+1) h \\right\\}.\n$$\n对于每个非空环 $\\mathcal{A}_k$，计算梯度大小的中位数\n$$\nG_k = \\operatorname{median}\\left\\{ \\left|\\nabla u\\right|_{i,j} \\,:\\, (i,j) \\in \\mathcal{A}_k \\right\\},\n$$\n并将其与代表半径 $R_k = k h$ 相关联。\n\n将估计的奇异性指数 $\\hat{\\alpha}$ 定义为数据 $(\\log R_k, \\log G_k)$ 在所有非空环 $k \\in \\{2,3,\\dots,10\\}$ 上的最佳拟合线（在最小二乘意义下）的斜率。也就是说，\n$$\n\\hat{\\alpha} = \\arg\\min_{a,b} \\sum_{k} \\left(\\log G_k - (a \\log R_k + b)\\right)^2, \\quad \\text{and we report } a \\text{ as } \\hat{\\alpha}.\n$$\n\n测试套件：\n- 情况 1：$\\Omega = \\Omega_L$, $N = 96$。\n- 情况 2：$\\Omega = \\Omega_L$, $N = 144$。\n- 情况 3：$\\Omega = \\Omega_S$, $N = 96$。\n\n答案规格：\n- 对于每种情况，计算相应的 $\\hat{\\alpha}$ 作为浮点数。\n- 您的程序应生成单行输出，其中包含三个结果，形式为方括号括起来的逗号分隔列表，按情况 1、2、3 的顺序排列，每个值四舍五入到三位小数（例如，$[-0.333,-0.332,0.000]$）。\n- 不涉及物理单位。所有角度（当通过 $\\omega$ 隐式出现时）根据定义均以弧度为单位。",
            "solution": "所提出的问题是计算物理学中一个适定的、有科学依据的练习，具体涉及二维拉普拉斯方程的数值解以及解的奇异性分析。问题陈述完整、无歧义，且所有提供的数据均一致。因此，可以构建一个严谨的解。\n\n问题的核心是在两个不同的域上求解拉普拉斯方程 $\\Delta u = 0$：一个 L 形域 $\\Omega_L$ 和一个方形域 $\\Omega_S$。该方程使用间距为 $h = 1/N$ 的均匀网格进行离散化。在每个内部网格节点 $(x_i, y_j)$，拉普拉斯算子 $\\Delta$ 通过标准的五点有限差分格式进行近似。这得到了离散方程：\n$$\n\\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} = 0\n$$\n该方程可简化为一个关于内部节点电势 $u_{i,j}$ 与其四个最近邻点的代数关系：\n$$\n4u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1} = 0\n$$\n此方程应用于域的每个内部节点。位于边界 $\\partial \\Omega$ 上的节点，其电势值由狄利克雷条件指定：对于左边界的适用部分为 $u(0,y) = 1$，其他地方为 $u=0$。\n\n在所有内部节点上应用有限差分格式会得到一个形式为 $A\\mathbf{x} = \\mathbf{b}$ 的大型稀疏线性代数方程组。在这里，$\\mathbf{x}$ 是所有内部节点上未知电势值 $u_{i,j}$ 的向量，矩阵 $A$ 编码了由五点格式定义的连接性，而向量 $\\mathbf{b}$ 则包含了来自固定边界条件的值。该线性系统保证有唯一解，可以使用稀疏线性代数求解器（例如 `scipy.sparse.linalg` 库中的 `spsolve`）高效地求解。\n\n该问题的一个关键方面是解在点 $c = (0.5, 0.5)$ 附近的梯度行为。\n对于 L 形域 $\\Omega_L$，该点是一个内角为 $\\omega = 3\\pi/2$ 的凹角。根据椭圆偏微分方程理论，一个公认的结论是解在这种角点处会表现出奇异性。在角点附近，电势 $u$ 的行为类似于 $u \\sim r^{\\alpha}$，其中 $r$ 是距角点的径向距离，指数 $\\alpha$ 由 $\\pi/\\omega$ 给出。对于 $\\omega = 3\\pi/2$，我们有 $\\alpha = \\pi / (3\\pi/2) = 2/3$。因此，梯度的大小预计表现为 $|\\nabla u| \\sim r^{\\alpha-1} = r^{2/3 - 1} = r^{-1/3}$。因此，$|\\nabla u|$ 对 $r$ 的对数-对数图应该会产生一条斜率约为 $-1/3$ 的直线。问题要求估计这个斜率，记为 $\\hat{\\alpha}$。\n\n对于方形域 $\\Omega_S$，点 $c = (0.5, 0.5)$ 位于域的内部，远离任何边界角点。在具有光滑边界数据的凸域内，拉普拉斯方程的解是解析的（无限可微）。因此，电势 $u(x,y)$ 及其梯度在 $c$ 的邻域内是光滑函数。对于离 $c$ 的小距离 $r$，梯度大小 $|\\nabla u|$ 将近似恒定。一个近似常数函数对 $r$ 的对数-对数图的斜率将接近 0。因此，我们预计在这种情况下，估计的奇异性指数 $\\hat{\\alpha}$ 将近似为 0。\n\n求解过程如下：\n1.  对于每个测试用例（域类型和分辨率 $N$），生成一个网格并识别内部和边界节点。$N$ 为偶数的条件确保了点 $c$ 与一个网格节点对齐。\n2.  构建与有限差分方程组相对应的稀疏矩阵 $A$ 和右侧向量 $\\mathbf{b}$。通过将已知的边界值移到向量 $\\mathbf{b}$ 中来施加边界条件。\n3.  求解线性系统 $A\\mathbf{x} = \\mathbf{b}$ 以找到所有内部节点上的电势 $u_{i,j}$。\n4.  在中心差分格式有效的每个网格节点 $(i,j)$ 处计算梯度大小 $|\\nabla u|_{i,j}$（即，格式中使用的所有四个邻点 $(i \\pm 1, j)$ 和 $(i, j \\pm 1)$ 都位于域内或其边界上）。\n5.  对于从 2 到 10 的每个整数环指数 $k$，识别所有有效的网格节点 $(i,j)$，其到 $c$ 的距离 $r_{i,j}$ 满足 $k h \\le r_{i,j}  (k+1) h$。\n6.  对于每个非空环 $\\mathcal{A}_k$，计算梯度大小的中位数 $G_k$。使用中位数可以提供一种抗离群值的稳健度量。\n7.  收集数据对 $(\\log R_k, \\log G_k)$，其中 $R_k = k h$。\n8.  对这些数据点进行线性最小二乘回归，以找到最佳拟合线的斜率。该斜率即为估计的奇异性指数 $\\hat{\\alpha}$。\n\n将对三个指定的测试用例实施此系统化步骤，以获得所需的 $\\hat{\\alpha}$ 数值。对于 L 形域，随着 $N$ 的增加，其结果预计将收敛到理论值 $-1/3$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import lil_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef get_domain_masks(N, domain_type):\n    \"\"\"\n    Generates boolean masks for the domain, identifying interior points.\n    N must be an even integer.\n    \"\"\"\n    is_in_domain = np.zeros((N + 1, N + 1), dtype=bool)\n    is_interior = np.zeros((N + 1, N + 1), dtype=bool)\n\n    if domain_type == 'L_shape':\n        ic = N // 2\n        for i in range(N + 1):\n            for j in range(N + 1):\n                if i = ic or j = ic:\n                    is_in_domain[i, j] = True\n    elif domain_type == 'square':\n        is_in_domain.fill(True)\n    else:\n        raise ValueError(\"Unknown domain type\")\n\n    # An interior point must be in the domain, and so must its 4 cardinal neighbors.\n    for i in range(1, N):\n        for j in range(1, N):\n            if (is_in_domain[i, j] and\n                    is_in_domain[i - 1, j] and is_in_domain[i + 1, j] and\n                    is_in_domain[i, j - 1] and is_in_domain[i, j + 1]):\n                is_interior[i, j] = True\n\n    return is_in_domain, is_interior\n\ndef solve_laplace(N, domain_type):\n    \"\"\"\n    Solves the 2D Laplace equation on a uniform grid for a given domain.\n    \"\"\"\n    h = 1.0 / N\n    is_in_domain, is_interior = get_domain_masks(N, domain_type)\n\n    u = np.zeros((N + 1, N + 1), dtype=float)\n\n    # Apply Dirichlet boundary conditions\n    # u(0,y) = 1\n    # Find all points on the grid where x=0 and are in the domain boundary\n    for j in range(N + 1):\n        if is_in_domain[0, j] and not is_interior[0, j]:\n            u[0, j] = 1.0\n    \n    # Rest of the boundary is u=0, which is the default from np.zeros.\n    # The L-shape condition means u(i,j)=0 on the re-entrant corner boundary.\n    # For j>N/2, u[N/2, j]=0. For i>N/2, u[i, N/2]=0. This is handled by default.\n    # The u=1 condition at x=0 is what needs explicit setting.\n\n    # Map interior grid points to a 1D index for the linear system\n    interior_points = np.argwhere(is_interior)\n    num_unknowns = len(interior_points)\n    point_to_idx = {tuple(p): i for i, p in enumerate(interior_points)}\n\n    # Assemble the sparse matrix A and vector b for Ax=b\n    A = lil_matrix((num_unknowns, num_unknowns), dtype=float)\n    b = np.zeros(num_unknowns, dtype=float)\n\n    for k, (i, j) in enumerate(interior_points):\n        A[k, k] = 4.0\n        # Check neighbors\n        for ni, nj in [(i - 1, j), (i + 1, j), (i, j - 1), (i, j + 1)]:\n            if is_interior[ni, nj]:\n                # Neighbor is another unknown\n                neighbor_idx = point_to_idx[(ni, nj)]\n                A[k, neighbor_idx] = -1.0\n            else:\n                # Neighbor is a boundary point with a known value\n                b[k] += u[ni, nj]\n\n    # Solve the sparse linear system\n    # Convert to CSC format for efficient solving\n    A_csc = A.tocsc()\n    x = spsolve(A_csc, b)\n\n    # Transfer solution vector back to the 2D grid\n    for k, (i, j) in enumerate(interior_points):\n        u[i, j] = x[k]\n\n    return u, h, is_in_domain\n\ndef estimate_singularity_exponent(u, h, N, is_in_domain):\n    \"\"\"\n    Estimates the singularity exponent alpha_hat from the numerical solution.\n    \"\"\"\n    # Identify points where the centered-difference gradient is well-defined\n    grad_definable = np.zeros((N + 1, N + 1), dtype=bool)\n    for i in range(1, N):\n        for j in range(1, N):\n            if (is_in_domain[i - 1, j] and is_in_domain[i + 1, j] and\n                    is_in_domain[i, j - 1] and is_in_domain[i, j + 1]):\n                grad_definable[i, j] = True\n\n    definable_points = np.argwhere(grad_definable)\n\n    log_R_k_list, log_G_k_list = [], []\n\n    # Analyze rings k = 2, 3, ..., 10\n    for k in range(2, 11):\n        R_k = k * h\n        r_min, r_max = k * h, (k + 1) * h\n        gradients_in_ring = []\n\n        for i, j in definable_points:\n            x, y = i * h, j * h\n            r_ij = np.sqrt((x - 0.5)**2 + (y - 0.5)**2)\n\n            if r_min = r_ij  r_max:\n                du_dx = (u[i + 1, j] - u[i - 1, j]) / (2 * h)\n                du_dy = (u[i, j + 1] - u[i, j - 1]) / (2 * h)\n                grad_mag = np.sqrt(du_dx**2 + du_dy**2)\n                gradients_in_ring.append(grad_mag)\n\n        if gradients_in_ring:\n            G_k = np.median(gradients_in_ring)\n            # Avoid log(0) in case median is zero\n            if G_k > 1e-12:\n                log_R_k_list.append(np.log(R_k))\n                log_G_k_list.append(np.log(G_k))\n\n    # Cannot perform regression with fewer than 2 points\n    if len(log_R_k_list)  2:\n        return 0.0\n\n    # Perform linear least-squares regression: log(G) = a*log(R) + b\n    # The slope 'a' is the desired exponent alpha_hat.\n    coeffs = np.polyfit(log_R_k_list, log_G_k_list, 1)\n    alpha_hat = coeffs[0]\n\n    return alpha_hat\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        ('L_shape', 96),\n        ('L_shape', 144),\n        ('square', 96),\n    ]\n\n    results = []\n    for domain_type, N in test_cases:\n        u, h, is_in_domain = solve_laplace(N, domain_type)\n        alpha_hat = estimate_singularity_exponent(u, h, N, is_in_domain)\n        results.append(alpha_hat)\n\n    # Format output as specified: comma-separated list in brackets,\n    # with each value rounded to three decimal places.\n    formatted_results = [f'{r:.3f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "对于大规模问题，例如三维模拟或使用非常精细的网格，前面练习中隐含使用的稀疏直接求解器可能会变得过慢或需要过多内存。此时，迭代法成为一种重要的替代方案。这个练习  将问题的焦点从物理本身转移到求解线性系统的算法效率上。你将对比一个基本的迭代法（雅可比法）和一个更高级的加速版本（切比雪夫法），并亲身体会利用算子谱特性（即特征值信息）对收敛速度带来的巨大提升。",
            "id": "2427931",
            "problem": "考虑单位正方形上的二维泊松问题，其带有齐次狄利克雷边界条件，通过在均匀网格上使用标准五点有限差分格式对 $- \\Delta u = f$ 进行离散化，得到离散线性系统 $A \\mathbf{u} = \\mathbf{b}$。设每个坐标方向上有 $n$ 个内部点，因此网格间距为 $h = \\frac{1}{n+1}$，内部网格点为 $(x_i, y_j)$，其中 $x_i = i h$，$y_j = j h$，对于 $i,j \\in \\{1, \\dots, n\\}$。离散算子定义为\n$$\n(A u)_{i,j} = \\frac{4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}}{h^2},\n$$\n约定当 $(i,j)$ 位于 $\\{1,\\dots,n\\} \\times \\{1,\\dots,n\\}$ 之外时，$u_{i,j} = 0$，这对应于齐次狄利克雷边界条件。\n\n设精确解析解为 $u(x,y) = \\sin(\\pi x) \\sin(\\pi y)$。定义强迫项为 $f(x,y) = 2 \\pi^2 \\sin(\\pi x) \\sin(\\pi y)$，使得在连续意义上 $- \\Delta u = f$ 成立。通过在内部网格点上计算 $f$ 的值来构造 $\\mathbf{b}$：$b_{i,j} = f(x_i, y_j)$。\n\n令 $D$ 表示 $A$ 的对角部分，满足 $D = \\frac{4}{h^2} I$。考虑两个离散时间迭代过程来近似解 $\\mathbf{u}$，两者都从零初始猜测 $\\mathbf{u}^{(0)} = \\mathbf{0}$ 开始，并使用残差 $\\mathbf{r}^{(k)} = \\mathbf{b} - A \\mathbf{u}^{(k)}$ 以及预处理残差 $M^{-1} \\mathbf{r}^{(k)} = D^{-1} \\mathbf{r}^{(k)} = \\frac{h^2}{4} \\mathbf{r}^{(k)}$：\n- 过程 J：$ \\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + D^{-1} \\mathbf{r}^{(k)}$。\n- 过程 C：$ \\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + \\alpha_k D^{-1} \\mathbf{r}^{(k)}$，其中步长 $\\alpha_k$ 是非恒定的，并依赖于对称正定 (SPD) 矩阵 $D^{-1} A$ 的谱界。对于 $n \\times n$ 内部网格上的五点拉普拉斯算子，$D^{-1} A$ 的极端特征值为\n$$\n\\lambda_{\\min} = 2 \\sin^2\\!\\left(\\frac{\\pi}{2 (n+1)}\\right), \\quad\n\\lambda_{\\max} = 2 \\cos^2\\!\\left(\\frac{\\pi}{2 (n+1)}\\right).\n$$\n定义 $c = \\frac{\\lambda_{\\max} + \\lambda_{\\min}}{2}$ 和 $\\delta = \\frac{\\lambda_{\\max} - \\lambda_{\\min}}{2}$。对于给定的正整数迭代次数 $m$，选择，对于 $k \\in \\{1,\\dots,m\\}$，\n$$\n\\alpha_k = \\frac{1}{c - \\delta \\cos\\!\\left(\\frac{\\pi (2k - 1)}{2 m}\\right)},\n$$\n所有角度都以弧度为单位。\n\n对于每个过程，在恰好 $m$ 次迭代后，将误差的离散欧几里得范数定义为\n$$\n\\| e \\|_2 = \\left( \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\left( u^{(m)}_{i,j} - \\sin(\\pi x_i)\\sin(\\pi y_j) \\right)^2 \\right)^{1/2}.\n$$\n\n您的任务是为每个测试用例计算比率 $r = \\frac{\\| e \\|_{2,\\mathrm{C}}}{\\| e \\|_{2,\\mathrm{J}}}$，其中 $\\| e \\|_{2,\\mathrm{C}}$ 和 $\\| e \\|_{2,\\mathrm{J}}$ 分别是过程 C 和过程 J 迭代 $m$ 次后的误差范数。所有三角函数参数必须以弧度为单位。\n\n测试套件：\n- 测试 1：$n = 32$, $m = 40$。\n- 测试 2：$n = 8$, $m = 10$。\n- 测试 3：$n = 64$, $m = 1$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含上述测试用例的三个比率，按给定顺序排列，每个比率四舍五入到六位小数，形式为用方括号括起来的逗号分隔列表（例如，$[0.123456,0.234567,0.345678]$）。不应打印任何其他文本。",
            "solution": "我们使用均匀网格离散化二维泊松方程 $- \\Delta u = f$，该网格在每个空间方向上有 $n$ 个内部点，网格间距为 $h = \\frac{1}{n+1}$。标准五点有限差分模板产生线性系统 $A \\mathbf{u} = \\mathbf{b}$，其中\n$$\n(A u)_{i,j} = \\frac{4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}}{h^2},\n$$\n其中域外的索引对应于边界值并设置为零，从而一致地强制执行齐次狄利克雷边界条件。连续精确解为 $u(x,y) = \\sin(\\pi x) \\sin(\\pi y)$，强迫项为 $f(x,y) = 2 \\pi^2 \\sin(\\pi x) \\sin(\\pi y)$。右端向量通过 $b_{i,j} = f(x_i, y_j)$ 构建，其中 $x_i = i h$ 和 $y_j = j h$。\n\n我们考虑解的迭代近似，从 $\\mathbf{u}^{(0)} = \\mathbf{0}$ 开始。令 $D$ 为 $A$ 的对角部分，对于此算子，其为 $D = \\frac{4}{h^2} I$。将第 $k$ 次迭代的残差定义为 $\\mathbf{r}^{(k)} = \\mathbf{b} - A \\mathbf{u}^{(k)}$，预处理残差定义为 $D^{-1}\\mathbf{r}^{(k)} = \\frac{h^2}{4} \\mathbf{r}^{(k)}$。\n\n过程 J 是以预处理理查森形式表示的经典雅可比方法，\n$$\n\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + D^{-1} \\mathbf{r}^{(k)}.\n$$\n这源于将 $A$ 分裂为 $A = D - (L + U)$ 并写作\n$$\n\\mathbf{u}^{(k+1)} = D^{-1} \\left( (L + U) \\mathbf{u}^{(k)} + \\mathbf{b} \\right) = \\mathbf{u}^{(k)} + D^{-1} (\\mathbf{b} - A \\mathbf{u}^{(k)}).\n$$\n\n过程 C 是一种非定常预处理理查森迭代，其迭代相关的步长 $\\alpha_k$ 的选择是为了在 $D^{-1}A$ 的谱上最小化最大误差放大，这基于第一类切比雪夫多项式的极小化极大性质。对于具有齐次狄利克雷边界条件且每个方向有 $n$ 个内部点的五点拉普拉斯算子，$D^{-1} A$ 的特征值为\n$$\n\\lambda_{i,j} = \\sin^2\\!\\left( \\frac{\\pi i}{2 (n+1)} \\right) + \\sin^2\\!\\left( \\frac{\\pi j}{2 (n+1)} \\right), \\quad i,j \\in \\{1,\\dots,n\\}.\n$$\n因此，最小和最大特征值为\n$$\n\\lambda_{\\min} = \\sin^2\\!\\left( \\frac{\\pi}{2 (n+1)} \\right) + \\sin^2\\!\\left( \\frac{\\pi}{2 (n+1)} \\right) = 2 \\sin^2\\!\\left( \\frac{\\pi}{2 (n+1)} \\right),\n$$\n$$\n\\lambda_{\\max} = \\sin^2\\!\\left( \\frac{\\pi n}{2 (n+1)} \\right) + \\sin^2\\!\\left( \\frac{\\pi n}{2 (n+1)} \\right) = 2 \\cos^2\\!\\left( \\frac{\\pi}{2 (n+1)} \\right),\n$$\n使用了恒等式 $\\sin\\!\\left( \\frac{\\pi n}{2 (n+1)} \\right) = \\cos\\!\\left( \\frac{\\pi}{2 (n+1)} \\right)$。令 $c = \\frac{\\lambda_{\\max} + \\lambda_{\\min}}{2}$ 和 $\\delta = \\frac{\\lambda_{\\max} - \\lambda_{\\min}}{2}$。$m$ 次切比雪夫半迭代通过设置\n$$\n\\alpha_k = \\frac{1}{c - \\delta \\cos\\!\\left( \\frac{\\pi (2k - 1)}{2 m} \\right)}, \\quad k = 1, \\dots, m,\n$$\n并更新\n$$\n\\mathbf{u}^{(k+1)} = \\mathbf{u}^{(k)} + \\alpha_k D^{-1} \\mathbf{r}^{(k)}\n$$\n来实现。\n$\\alpha_k$ 的这种选择是通过将谱区间 $[\\lambda_{\\min}, \\lambda_{\\max}]$ 映射到 $[-1, 1]$，选择与切比雪夫多项式 $T_m$ 的极值点对应的节点，并选择步长以最小化所得 $m$ 次误差多项式在谱区间上的最大幅值而得出的。具体来说，$m$ 步后的误差可以表示为\n$$\n\\mathbf{e}^{(m)} = p_m(D^{-1} A) \\mathbf{e}^{(0)},\n$$\n其中 $p_m$ 是满足 $p_m(0) = 1$ 并最小化 $\\max_{\\lambda \\in [\\lambda_{\\min}, \\lambda_{\\max}]} |p_m(\\lambda)|$ 的 $m$ 次多项式。给定的 $\\alpha_k$ 通过与切比雪夫节点相关的乘积表示法产生这个最优的 $p_m$。\n\n对于每个过程，在 $m$ 次迭代后，我们计算误差的离散欧几里得范数\n$$\n\\| e \\|_2 = \\left( \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\left( u^{(m)}_{i,j} - \\sin(\\pi x_i)\\sin(\\pi y_j) \\right)^2 \\right)^{1/2},\n$$\n它直接将迭代解与在网格点上采样的解析解进行比较。尽管此范数混合了离散化误差和迭代误差，但在相同的离散化和迭代预算下，过程 C 和过程 J 之间的比较隔离了迭代过程的影响。比率\n$$\nr = \\frac{\\| e \\|_{2,\\mathrm{C}}}{\\| e \\|_{2,\\mathrm{J}}}\n$$\n量化了在相同的 $n$ 和 $m$ 下，过程 C 相对于过程 J 的相对有效性。\n\n算法实现过程如下：\n- 为内部点构造 $u_{\\text{true}, i,j} = \\sin(\\pi x_i) \\sin(\\pi y_j)$ 和 $b_{i,j} = 2 \\pi^2 u_{\\text{true}, i,j}$。\n- 通过带有齐次狄利克雷边界条件的五点模板实现 $A u$，这可以通过零填充来处理。\n- 迭代过程 J：$u \\leftarrow u + \\frac{h^2}{4} (b - A u)$ 恰好 $m$ 步。\n- 迭代过程 C：使用 $\\lambda_{\\min}$ 和 $\\lambda_{\\max}$ 如上计算 $c$ 和 $\\delta$，然后对于 $k = 1, \\dots, m$，设置 $\\alpha_k = \\frac{1}{c - \\delta \\cos(\\frac{\\pi (2k - 1)}{2 m})}$ 并更新 $u \\leftarrow u + \\alpha_k \\frac{h^2}{4} (b - A u)$。\n- 计算误差范数及其比率。\n\n测试套件涵盖了一个具有中等网格和迭代预算的通用情况（$n = 32$, $m = 40$），一个小网格情况（$n = 8$, $m = 10$），以及一个在较大网格上单次迭代的边缘情况（$n = 64$, $m = 1$）。最终程序以要求的格式报告三个四舍五入到六位小数的比率。",
            "answer": "```python\nimport numpy as np\n\ndef setup_problem(n):\n    # Grid spacing and coordinates\n    h = 1.0 / (n + 1)\n    i = np.arange(1, n + 1)\n    x = i * h\n    y = x.copy()\n    X, Y = np.meshgrid(x, y, indexing='ij')\n    # True solution and forcing\n    u_true = np.sin(np.pi * X) * np.sin(np.pi * Y)\n    f = 2.0 * (np.pi ** 2) * u_true\n    b = f  # Right-hand side at interior points\n    return h, u_true, b\n\ndef apply_A(u, h):\n    # Apply 5-point Laplacian stencil with homogeneous Dirichlet boundaries (zero outside)\n    up = np.pad(u, 1, mode='constant', constant_values=0.0)\n    Au = (4.0 * up[1:-1, 1:-1]\n          - up[0:-2, 1:-1] - up[2:, 1:-1]\n          - up[1:-1, 0:-2] - up[1:-1, 2:]) / (h * h)\n    return Au\n\ndef jacobi(u0, b, h, m):\n    # Jacobi expressed as preconditioned Richardson with D^{-1} = (h^2/4) I\n    u = u0.copy()\n    invD = (h * h) / 4.0\n    for _ in range(m):\n        r = b - apply_A(u, h)\n        u = u + invD * r\n    return u\n\ndef chebyshev(u0, b, h, n, m):\n    # Chebyshev semi-iteration with M=D (Jacobi preconditioning)\n    u = u0.copy()\n    invD = (h * h) / 4.0\n    theta = np.pi / (2.0 * (n + 1))\n    lam_min = 2.0 * (np.sin(theta) ** 2)\n    lam_max = 2.0 * (np.cos(theta) ** 2)\n    c = 0.5 * (lam_max + lam_min)\n    delta = 0.5 * (lam_max - lam_min)\n    # Perform exactly m steps with Chebyshev step sizes\n    for k in range(1, m + 1):\n        alpha = 1.0 / (c - delta * np.cos(np.pi * (2 * k - 1) / (2.0 * m)))\n        r = b - apply_A(u, h)\n        u = u + alpha * invD * r\n    return u\n\ndef error_ratio(n, m):\n    h, u_true, b = setup_problem(n)\n    u0 = np.zeros_like(u_true)\n    u_j = jacobi(u0, b, h, m)\n    u_c = chebyshev(u0, b, h, n, m)\n    err_j = np.linalg.norm(u_j - u_true)\n    err_c = np.linalg.norm(u_c - u_true)\n    # Avoid division by zero, though it should not occur for finite m > 0\n    ratio = err_c / err_j if err_j != 0.0 else float('inf')\n    return ratio\n\ndef solve():\n    # Define the test cases: (n, m)\n    test_cases = [\n        (32, 40),\n        (8, 10),\n        (64, 1),\n    ]\n    results = []\n    for n, m in test_cases:\n        r = error_ratio(n, m)\n        results.append(f\"{r:.6f}\")\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}