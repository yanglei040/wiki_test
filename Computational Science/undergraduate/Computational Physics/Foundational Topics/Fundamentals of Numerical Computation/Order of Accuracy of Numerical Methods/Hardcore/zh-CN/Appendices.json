{
    "hands_on_practices": [
        {
            "introduction": "理解数值方法精度阶数的最好方法之一就是亲手验证它。本练习将指导你实现一个通用的龙格-库塔（Runge-Kutta）求解器，它能根据给定的布彻表（Butcher tableau）执行计算，并通过“人造解”方法（Method of Manufactured Solutions）来凭经验验证其精度阶数 。这种方法是计算科学中验证代码正确性的黄金标准，它能让你建立起理论预测与实际数值行为之间的直观联系。",
            "id": "2376768",
            "problem": "编写一个完整的程序，给定几种以 Butcher 表形式表示的显式 Runge-Kutta (RK) 方法，通过在一个常微分方程 (ODE) 初值问题的构造解上进行测试，来数值验证每种方法的精度阶。构造解定义如下：设精确解为 $y(t)=\\exp(\\sin t)$，对于 $t \\in [0,1]$，其中角度以弧度为单位。该 ODE 为 $y'(t)=f(t,y(t))$，其中 $f(t,y)=\\cos(t)\\,y$，初始条件为 $y(0)=1$，最终时间为 $T=1$。使用最终时间 $t=T$ 的全局误差来量化精度。\n\n使用以下显式 Runge-Kutta 方法，每种方法都由其 Butcher 表 $(A,b,c)$ 指定：\n- 方法 $1$ (显式欧拉法，期望阶数为 $1$)：$s=1$，$A=\\begin{bmatrix}0\\end{bmatrix}$，$b=\\begin{bmatrix}1\\end{bmatrix}$，$c=\\begin{bmatrix}0\\end{bmatrix}$。\n- 方法 $2$ (显式中点法，期望阶数为 $2$)：$s=2$，$A=\\begin{bmatrix}0  & 0\\\\ \\tfrac{1}{2}  & 0\\end{bmatrix}$，$b=\\begin{bmatrix}0  & 1\\end{bmatrix}$，$c=\\begin{bmatrix}0  & \\tfrac{1}{2}\\end{bmatrix}$。\n- 方法 $3$ (Kutta 三阶方法，期望阶数为 $3$)：$s=3$，$A=\\begin{bmatrix}0  & 0  & 0\\\\ \\tfrac{1}{2}  & 0  & 0\\\\ -1  & 2  & 0\\end{bmatrix}$，$b=\\begin{bmatrix}\\tfrac{1}{6}  & \\tfrac{2}{3}  & \\tfrac{1}{6}\\end{bmatrix}$，$c=\\begin{bmatrix}0  & \\tfrac{1}{2}  & 1\\end{bmatrix}$。\n- 方法 $4$ (经典 RK4 法，期望阶数为 $4$)：$s=4$，$A=\\begin{bmatrix}0  & 0  & 0  & 0\\\\ \\tfrac{1}{2}  & 0  & 0  & 0\\\\ 0  & \\tfrac{1}{2}  & 0  & 0\\\\ 0  & 0  & 1  & 0\\end{bmatrix}$，$b=\\begin{bmatrix}\\tfrac{1}{6}  & \\tfrac{1}{3}  & \\tfrac{1}{3}  & \\tfrac{1}{6}\\end{bmatrix}$，$c=\\begin{bmatrix}0  & \\tfrac{1}{2}  & \\tfrac{1}{2}  & 1\\end{bmatrix}$。\n\n对于每种方法，使用大小为 $h=1/N$ 的均匀时间步长在 $[0,1]$ 上进行时间积分，其中 $N$ 在测试集 $\\{10,20,40,80,160,320\\}$ 中。对于每个 $N$，计算在 $t=1$ 时的数值近似解 $y_N$，计算全局误差 $E(h)=\\lvert y_N - y(1)\\rvert$，然后通过对测试集中所有 $N$ 值的数据 $(\\log h,\\log E(h))$ 进行拟合，以所得直线的最小二乘斜率作为观测阶数 $p$ 的估计值。使用自然对数作为 $\\log$。\n\n你的程序必须在单行中输出一个用方括号括起来的逗号分隔列表，其中包含方法 $1$ 到方法 $4$ 的四个估计阶数 $(p_1,p_2,p_3,p_4)$，每个都四舍五入到小数点后两位。不应打印任何其他文本。\n\n测试集与答案规范：\n- 测试集包含上述四种方法，每种方法都使用 $N \\in \\{10,20,40,80,160,320\\}$ 进行测试。\n- 最终答案是四个浮点数 $p_1$、$p_2$、$p_3$、$p_4$，每个都是相应方法的观测阶数估计值。\n- 最终输出格式必须严格为单行形式 `[p1,p2,p3,p4]`，其中每个 $p_k$ 都四舍五入到小数点后两位并以十进制数形式打印。",
            "solution": "问题陈述已经过严谨分析。该问题具有科学依据，是适定的，并包含得出唯一且有意义解所需的所有必要信息。所指定的常微分方程、其构造的解析解、通过 Butcher 表定义的 Runge-Kutta 方法，以及用于数值验证精度阶的程序，都是标准的、正确的且自洽的。问题是有效的。我们现在开始构建解决方案。\n\n基本任务是求解一个形式如下的初值问题 (IVP)：\n$$ y'(t) = f(t, y(t)), \\quad y(t_0) = y_0 $$\n对于 $t \\in [t_0, T]$。问题提供了具体的函数 $f(t, y) = \\cos(t) y$、初始条件 $y(0) = 1$ 和时间区间 $[0, 1]$。精确解为 $y(t) = \\exp(\\sin t)$，这可以通过求导轻松验证：$y'(t) = \\exp(\\sin t) \\cdot \\cos(t) = y(t)\\cos(t)$，并检查初始条件：$y(0) = \\exp(\\sin 0) = \\exp(0) = 1$。\n\n一个 $s$ 阶显式 Runge-Kutta (RK) 方法通过以步长 $h$ 向前推进时间来近似解。从时间 $t_n$ 的解 $y_n$ 计算时间 $t_{n+1} = t_n + h$ 的解 $y_{n+1}$。该方法由一组系数定义，这些系数排列在一个 Butcher 表中：\n$$\n\\begin{array}{c|c}\nc & A \\\\\n\\hline\n  & b^T\n\\end{array} \\quad \\text{其中 } c \\in \\mathbb{R}^s, b \\in \\mathbb{R}^s, A \\in \\mathbb{R}^{s \\times s}\n$$\n对于显式方法，矩阵 $A$ 是严格下三角矩阵，即当 $j \\ge i$ 时 $a_{ij} = 0$。计算分阶段进行。首先，计算 $s$ 个阶段导数 $k_i$，其中 $i=1, 2, \\dots, s$：\n$$ k_i = f\\left(t_n + c_i h, y_n + h \\sum_{j=1}^{i-1} a_{ij} k_j\\right) $$\n然后使用这些阶段导数的加权平均来推进解：\n$$ y_{n+1} = y_n + h \\sum_{i=1}^{s} b_i k_i $$\n\n数值方法的精度由其收敛阶 $p$ 来表征。对于一个 $p$ 阶方法，在固定的最终时间 $T$ 处的全局误差，记为 $E(h)$，预计会随着步长 $h$ 的减小而遵循以下关系式：\n$$ E(h) = |y_N - y(T)| \\approx C h^p $$\n其中 $y_N$ 是在 $T=Nh$ 时的数值解，$C$ 是一个取决于方法和问题但与 $h$ 无关的常数。\n\n为了数值验证阶数 $p$，我们可以通过对两边取自然对数来转换这个关系式：\n$$ \\ln(E(h)) \\approx \\ln(C) + p \\ln(h) $$\n这个方程的形式是 $Y = mX + B$，其中 $Y = \\ln(E(h))$，$X = \\ln(h)$，斜率是 $m = p$，截距是 $B = \\ln(C)$。这种线性关系意味着 $\\ln(E(h))$ 关于 $\\ln(h)$ 的图将近似于一条直线，其斜率就是方法的阶数 $p$。\n\n指定的程序如下：\n$1$. 对于给定的四种 RK 方法中的每一种，必须在区间 $[0, 1]$ 上执行一系列数值积分。\n$2$. 积分将使用一系列递减的步长 $h = 1/N$，其中 $N \\in \\{10, 20, 40, 80, 160, 320\\}$。\n$3$. 对于每个特定步长 $h$ 的积分，计算最终时间的数值近似解 $y_N$。\n$4$. 全局误差计算为 $E(h) = |y_N - y(1)|$，其中精确值为 $y(1) = \\exp(\\sin 1)$。\n$5$. 在计算完所有步长的误差后，收集数据对 $(\\ln(h), \\ln(E(h)))$。\n$6$. 对这些数据点进行线性最小二乘回归。所得最佳拟合线的斜率提供了精度阶的实验估计值 $p$。对于一组数据点 $(x_i, y_i)$，斜率 $p$ 由以下公式给出：\n$$ p = \\frac{\\sum_{i=1}^{M} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{M} (x_i - \\bar{x})^2} $$\n其中 $x_i = \\ln(h_i)$，$y_i = \\ln(E(h_i))$，$\\bar{x}$ 和 $\\bar{y}$ 是平均值，$M=6$ 是测试集中步长的数量。\n\n这个程序将对提供的四个 Butcher 表中的每一个实施，从而得出四个估计的精度阶 $(p_1, p_2, p_3, p_4)$，预计这些值将分别接近其理论值 $1, 2, 3$ 和 $4$。最终结果将是这四个值，四舍五入到小数点后两位。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Numerically verifies the order of accuracy of several explicit Runge-Kutta methods.\n    \"\"\"\n    # Define the Ordinary Differential Equation and its analytical solution\n    f = lambda t, y: np.cos(t) * y\n    t_start = 0.0\n    y_start = 1.0\n    t_end = 1.0\n    \n    # Pre-calculate the exact solution at the final time for error computation\n    y_exact_final = np.exp(np.sin(t_end))\n\n    # Define the Butcher tableaus for the four RK methods\n    methods = [\n        {\n            # Method 1: Explicit Euler (Order 1)\n            'A': np.array([[0.0]]),\n            'b': np.array([1.0]),\n            'c': np.array([0.0])\n        },\n        {\n            # Method 2: Explicit Midpoint (Order 2)\n            'A': np.array([[0.0, 0.0], [0.5, 0.0]]),\n            'b': np.array([0.0, 1.0]),\n            'c': np.array([0.0, 0.5])\n        },\n        {\n            # Method 3: Kutta's third-order method (Order 3)\n            'A': np.array([[0.0, 0.0, 0.0], [0.5, 0.0, 0.0], [-1.0, 2.0, 0.0]]),\n            'b': np.array([1.0/6.0, 2.0/3.0, 1.0/6.0]),\n            'c': np.array([0.0, 0.5, 1.0])\n        },\n        {\n            # Method 4: Classical RK4 (Order 4)\n            'A': np.array([\n                [0.0, 0.0, 0.0, 0.0],\n                [0.5, 0.0, 0.0, 0.0],\n                [0.0, 0.5, 0.0, 0.0],\n                [0.0, 0.0, 1.0, 0.0]\n            ]),\n            'b': np.array([1.0/6.0, 1.0/3.0, 1.0/3.0, 1.0/6.0]),\n            'c': np.array([0.0, 0.5, 0.5, 1.0])\n        }\n    ]\n\n    # Test suite of step counts\n    N_values = [10, 20, 40, 80, 160, 320]\n    h_values = np.array([1.0 / N for N in N_values])\n\n    estimated_orders = []\n\n    for method in methods:\n        A, b, c = method['A'], method['b'], method['c']\n        s = len(b)  # Number of stages\n        errors = []\n\n        for N in N_values:\n            h = (t_end - t_start) / N\n            y_current = y_start\n            \n            # Time integration loop\n            for n in range(N):\n                t_n = t_start + n * h\n                k_stages = np.zeros(s)\n                \n                # Calculate stage derivatives k_i\n                for i in range(s):\n                    stage_sum = 0.0\n                    for j in range(i):\n                        stage_sum += A[i, j] * k_stages[j]\n                    \n                    y_stage_input = y_current + h * stage_sum\n                    t_stage_input = t_n + c[i] * h\n                    k_stages[i] = f(t_stage_input, y_stage_input)\n                \n                # Update solution\n                y_current += h * np.dot(b, k_stages)\n            \n            # Store the global error at t=T\n            errors.append(np.abs(y_current - y_exact_final))\n\n        # Use natural logarithm for the log-log plot\n        log_h = np.log(h_values)\n        log_E = np.log(np.array(errors))\n        \n        # Perform linear regression (polynomial fit of degree 1)\n        # The slope of the line is the estimated order of accuracy\n        # np.polyfit returns [slope, intercept]\n        slope = np.polyfit(log_h, log_E, 1)[0]\n        estimated_orders.append(slope)\n        \n    # Format the output as specified: [p1,p2,p3,p4]\n    formatted_results = [f'{p:.2f}' for p in estimated_orders]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "精度阶数的理论分析通常假设解是光滑的，但当解本身表现出病态行为时会发生什么呢？本练习探讨了一个具有有限时间奇点（finite-time singularity）的常微分方程，在这种情况下，解的导数会趋于无穷大 。通过编程计算并观察当积分终点逼近奇点时，一个高阶方法（四阶龙格-库塔法）的表观精度阶数是如何退化的，你将深刻理解收敛理论的适用边界。",
            "id": "2422962",
            "problem": "考虑一个常微分方程 (ODE) 的初值问题：求一个函数 $y(t)$，使得 $y'(t) = y(t)^2$ 且 $y(0) = 1$。其精确解为 $y(t) = \\dfrac{1}{1 - t}$（当 $t < 1$ 时），该解在 $t = 1$ 处存在一个有限时间奇点。\n\n设 $y(t)$ 的数值近似解由经典的显式四阶龙格-库塔方法（常缩写为 RK4）计算得出。该方法以 $y(0)=1$ 为起点，在区间 $[0,T]$ 上采用均匀时间步长 $h$ 进行计算，最终在时间 $T$ 产生数值 $Y_h(T)$。当应用于精确解及其导数保持有界的区域时，该方法的理论全局精度阶为 $4$。\n\n在最终时间 $T \\in (0,1)$ 的观测精度阶定义如下：对于三个步长 $h_i = T/N_i$（其中 $N_i \\in \\{N_0, 2N_0, 4N_0\\}$），计算相应的全局绝对误差\n$$\nE(h_i;T) = \\left|Y_{h_i}(T) - y(T)\\right|.\n$$\n那么，观测阶 $p_{\\mathrm{obs}}(T)$ 是点集 $\\left(\\log h_i, \\log E(h_i;T)\\right)$（$i=1,2,3$）的最佳仿射拟合（在最小二乘意义上）的斜率。\n\n您的任务是编写一个完整的程序，根据上述定义，为下面指定的每个测试用例计算 $p_{\\mathrm{obs}}(T)$。必须使用经典的显式四阶龙格-库塔方法来计算 $Y_{h}(T)$，并且必须使用精确解 $y(T) = \\dfrac{1}{1-T}$ 来评估 $E(h;T)$。\n\n测试套件：\n- 案例1（理想情况）：$T = 0.5$，$N_0 = 16$。\n- 案例2（更接近奇点）：$T = 0.9$，$N_0 = 64$。\n- 案例3（接近奇异）：$T = 0.99$，$N_0 = 512$。\n- 案例4（非常接近奇异）：$T = 0.999$，$N_0 = 4096$。\n\n所有计算都是无量纲的。不涉及角度。不需要百分比。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含上述测试用例的四个观测精度阶 $p_{\\mathrm{obs}}(T)$，顺序与上文所列相同，四舍五入到三位小数，并以逗号分隔的列表形式用方括号括起来。例如，一个有效的输出可能类似于 $[4.000,3.987,3.452,2.718]$（这只是一个示例；您的程序必须计算实际值）。",
            "solution": "我们分析初值问题 $y'(t) = y(t)^2$，$y(0) = 1$。精确解可通过分离变量法得到：$\\dfrac{dy}{dt} = y^2$ 意味着 $\\dfrac{dy}{y^2} = dt$，积分得到 $-1/y = t + C$，而初始条件 $y(0)=1$ 得出 $C = -1$。因此，当 $t < 1$ 时，$y(t) = \\dfrac{1}{1 - t}$，并且在 $t=1$ 处存在一个有限时间爆破（奇点）。\n\n对于数值近似，我们使用经典的显式四阶龙格-库塔方法 (RK4)。对于给定的步长 $h$ 和当前状态 $(t_n, y_n)$，定义阶段斜率 $k_1, k_2, k_3, k_4$ 为\n$$\nk_1 = f(t_n, y_n), \\quad\nk_2 = f\\!\\left(t_n + \\tfrac{h}{2}, y_n + \\tfrac{h}{2} k_1\\right), \\quad\nk_3 = f\\!\\left(t_n + \\tfrac{h}{2}, y_n + \\tfrac{h}{2} k_2\\right), \\quad\nk_4 = f\\!\\left(t_n + h, y_n + h k_3\\right),\n$$\n其中 $f(t,y) = y^2$。更新公式为\n$$\ny_{n+1} = y_n + \\frac{h}{6}\\left(k_1 + 2k_2 + 2k_3 + k_4 \\right), \\quad t_{n+1} = t_n + h.\n$$\n从 $t_0 = 0$ 和 $y_0 = 1$ 开始，前进 $N = T/h$ 个均匀步长，得到 $Y_h(T) = y_N$。\n\n为了量化在固定的最终时间 $T$ 的观测精度阶，我们依赖于定义 $E(h;T) = \\left|Y_h(T) - y(T)\\right|$，其中 $y(T) = \\dfrac{1}{1 - T}$。对于一个理论精度阶为 $p_{\\mathrm{th}}$ 的方法和足够光滑的解，当 $h \\to 0$ 时，其渐近行为为 $E(h;T) \\approx C(T)\\, h^{p_{\\mathrm{th}}}$，其中常数 $C(T)$ 依赖于精确解在 $[0,T]$ 上的导数的界。经典的 RK4 方法具有 $p_{\\mathrm{th}} = 4$。然而，在奇点附近，$y(t)$ 的导数增长迅速：通过直接微分或归纳法可以发现\n$$\ny^{(m)}(t) = \\frac{m!}{\\left(1 - t\\right)^{m+1}},\n$$\n因此对于接近 1 的固定 $T$，局部截断误差中的系数会随着 $(1-T)^{-1}$ 的幂次增加。RK4 的局部截断误差为 $\\mathcal{O}(h^5)$，其系数涉及 $y^{(5)}(t)$ 及更低阶的导数；因此，全局误差中的常数 $C(T)$ 的行为类似于 $(1-T)^{-5}$ 的一个正常数倍（取决于动力学系统带来的乘法因子）。因此，当 $T \\to 1^-$ 时，即使是中等小的 $h$ 也可能尚未进入渐近区域，在该区域的对数-对数图上可以观察到清晰的斜率 $4$。当在一组固定的步长上进行测量时，这种现象表现为数值计算的精度阶的崩溃。\n\n为了从第一性原理计算观测阶，我们取三个步长 $h_i = T/N_i$（其中 $N_i \\in \\{N_0, 2N_0, 4N_0\\}$），计算相应的误差 $E(h_i;T)$，然后将 $p_{\\mathrm{obs}}(T)$ 定义为点集 $(\\log h_i, \\log E(h_i;T))$ 的最小二乘仿射拟合的斜率。具体来说，令 $x_i = \\log h_i$ 和 $y_i = \\log E(h_i;T)$（$i=1,2,3$），则斜率 $p_{\\mathrm{obs}}(T)$ 为\n$$\np_{\\mathrm{obs}}(T) = \\frac{\\sum_{i=1}^3 (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^3 (x_i - \\bar{x})^2}, \\quad\n\\bar{x} = \\frac{1}{3}\\sum_{i=1}^3 x_i, \\quad \\bar{y} = \\frac{1}{3}\\sum_{i=1}^3 y_i.\n$$\n这个斜率与对数的底无关。\n\n测试套件指定了四对 $(T, N_0)$：$(0.5, 16)$、$(0.9, 64)$、$(0.99, 512)$ 和 $(0.999, 4096)$。对于每个 $T$，三个网格使用 $N \\in \\{N_0, 2N_0, 4N_0\\}$ 个步数，得到步长 $h = T/N$。这些选择确保了对 $[0,T]$ 的均匀划分，同时探索了越来越精细的分辨率。使用 RK4 进行的数值积分得到 $Y_h(T)$，而精确解 $y(T) = 1/(1 - T)$ 为误差计算提供了真值。\n\n我们预期会有以下定性行为：\n- 当 $T = 0.5$ 时，解及其导数在 $[0, 0.5]$ 上的量级不大，因此 $C(T)$ 是适中的，观测阶 $p_{\\mathrm{obs}}(0.5)$ 应该接近 $4$。\n- 随着 $T$ 增加到 $0.9$、$0.99$ 和 $0.999$，在 $[0,T]$ 上高阶导数的量级变得巨大，使 $C(T)$ 膨胀，并使得这有限的一组步长在渐近区域的代表性降低。\n- 因此，测得的斜率 $p_{\\mathrm{obs}}(T)$ 通常会降到 $4$ 以下，其中在 $T = 0.999$ 附近下降最为显著。\n\n程序实现了以下步骤：对每个网格使用 RK4 进行数值推进，使用精确解评估绝对误差，为 $(\\log h, \\log E)$ 进行最小二乘斜率计算，并以指定的单行列表格式输出四个观测阶（四舍五入到三位小数）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef rk4_final_value(f, y0, T, N):\n    \"\"\"\n    Advance the ODE y' = f(t,y) from t=0 to t=T using N uniform RK4 steps.\n    Returns the final value y_N at t = T.\n    \"\"\"\n    h = T / N\n    t = 0.0\n    y = y0\n    for _ in range(N):\n        k1 = f(t, y)\n        k2 = f(t + 0.5 * h, y + 0.5 * h * k1)\n        k3 = f(t + 0.5 * h, y + 0.5 * h * k2)\n        k4 = f(t + h, y + h * k3)\n        y = y + (h / 6.0) * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n        t += h\n    return y\n\ndef observed_order_at_T(T, N0):\n    \"\"\"\n    Compute the observed order p_obs(T) using three meshes with N in {N0, 2N0, 4N0}.\n    \"\"\"\n    # Define the ODE\n    def f(t, y):\n        return y * y\n\n    exact = 1.0 / (1.0 - T)\n\n    Ns = [N0, 2 * N0, 4 * N0]\n    hs = []\n    errs = []\n    for N in Ns:\n        h = T / N\n        yN = rk4_final_value(f, 1.0, T, N)\n        err = abs(yN - exact)\n        hs.append(h)\n        errs.append(err)\n\n    hs = np.array(hs, dtype=float)\n    errs = np.array(errs, dtype=float)\n\n    # Guard against log(0) by adding a tiny floor (does not affect realistic errors)\n    tiny = 1e-300\n    x = np.log(hs)\n    y = np.log(errs + tiny)\n\n    x_mean = np.mean(x)\n    y_mean = np.mean(y)\n    denom = np.sum((x - x_mean) ** 2)\n    # In the degenerate case (should not happen for distinct hs), fall back to 0\n    if denom == 0.0:\n        return 0.0\n    slope = np.sum((x - x_mean) * (y - y_mean)) / denom\n    # The slope of log(error) vs log(h) is the observed order\n    return slope\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (T, N0)\n    test_cases = [\n        (0.5, 16),     # happy path\n        (0.9, 64),     # closer to singularity\n        (0.99, 512),   # near-singular\n        (0.999, 4096), # very near-singular\n    ]\n\n    results = []\n    for T, N0 in test_cases:\n        p_obs = observed_order_at_T(T, N0)\n        # Round to three decimal places for output formatting\n        results.append(f\"{p_obs:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "在求解偏微分方程（PDE）时，精度和稳定性是两个密不可分的核心概念。一个方法的精度阶数再高，如果它不稳定，其数值解也会因为误差的灾难性增长而变得毫无意义。本练习以一维热传导方程为例，让你探索显式前向时间中心空间（FTCS）格式的性能 。你将通过调整一个关键的无量纲参数——扩散数 $r = \\alpha \\Delta t / \\Delta x^2$，亲眼见证数值解从稳定收敛到剧烈振荡并发散的转变，从而深刻体会到稳定性是保证数值方法有效性的先决条件。",
            "id": "2422955",
            "problem": "考虑单位区间上的具有齐次狄利克雷边界条件的一维热方程，\n$$\nu_t(x,t) = \\alpha\\,u_{xx}(x,t),\\quad x\\in[0,1],\\ t\\in[0,T],\\quad u(0,t)=0,\\ u(1,t)=0,\n$$\n以及在一个包含 $M$ 个子区间的均匀网格上（因此 $\\Delta x = 1/M$）的显式时间向前空间中心（FTCS）有限差分格式，\n$$\nu_j^{n+1} = u_j^n + r\\left(u_{j-1}^n - 2u_j^n + u_{j+1}^n\\right),\\quad j=1,\\dots,M-1,\n$$\n其中 $r = \\alpha\\,\\Delta t/\\Delta x^2$，$u_j^n \\approx u(x_j,t_n)$，$x_j = j\\,\\Delta x$，$t_n = n\\,\\Delta t$。设三角函数中的所有角度均以弧度为单位。\n\n将物理参数设置为 $\\alpha = 1$ 和 $T = 0.05$。对于每次数值模拟，从两个正弦模式的叠加开始初始化，\n$$\nu(x,0) = \\sin(\\pi x) + \\varepsilon\\,\\sin\\!\\big(\\kappa\\,\\pi x\\big),\n$$\n其中 $\\varepsilon = 10^{-6}$，$\\kappa$ 根据下文每个测试案例指定。对于每次模拟，使用上述 FTCS 更新公式，并采用指定的 $r$ 值，从 $t=0$ 向前推进到 $t=T$。如果 $T$ 不是 $\\Delta t$ 的整数倍，则使用大小为 $\\Delta t_{\\text{last}} \\le \\Delta t$ 的最后一步，即使用 $r_{\\text{last}}=\\alpha\\,\\Delta t_{\\text{last}}/\\Delta x^2$ 更新一次，以使数值时间恰好等于 $T$。\n\n使用此初始数据的精确解析解，\n$$\nu(x,t) = e^{-\\alpha\\,\\pi^2 t}\\,\\sin(\\pi x) + \\varepsilon\\,e^{-\\alpha\\,\\kappa^2\\pi^2 t}\\,\\sin\\!\\big(\\kappa\\,\\pi x\\big),\n$$\n来定义在时间 $T$ 时，一个包含 $M$ 个子区间的网格上的误差，该误差为在网格点上计算的最大范数差，\n$$\nE(M;r) = \\max_{1\\le j\\le M-1}\\left|u_j^N - u(x_j,T)\\right|,\n$$\n其中 $N$ 是所采取的总时间步数（如果适用，包括使用 $\\Delta t_{\\text{last}}$ 的最后一步）。\n\n对于以下测试套件，计算每种情况所要求的量：\n\n- 案例 A（稳定）：$r=0.4$，$\\kappa=7$，以及 $M\\in\\{64,128\\}$。计算观测到的精度阶\n$$\np_A = \\frac{\\log\\big(E(64;0.4)/E(128;0.4)\\big)}{\\log(2)}.\n$$\n- 案例 B（稳定性极限）：$r=0.5$，$\\kappa=7$，以及 $M\\in\\{64,128\\}$。计算\n$$\np_B = \\frac{\\log\\big(E(64;0.5)/E(128;0.5)\\big)}{\\log(2)}.\n$$\n- 案例 C（不稳定）：$r=0.6$，$M=64$，并选择高频指数 $\\kappa = M-1$。演化到时间 $T$ 并将第 $n$ 步的离散 $L^2$ 范数定义为\n$$\n\\|u^n\\|_2 = \\left(\\Delta x \\sum_{j=1}^{M-1} \\big(u_j^n\\big)^2 \\right)^{1/2}.\n$$\n报告布尔值\n$$\nU = \\text{True if } \\max_{0\\le n\\le N}\\frac{\\|u^n\\|_2}{\\|u^0\\|_2} \\ge 10,\\ \\text{ otherwise False}.\n$$\n该准则检测到的增长与连续能量衰减相矛盾，并表明了数值不稳定性，此时精度阶的概念已无意义。\n\n测试套件摘要：\n- 案例 A：$\\alpha=1$, $T=0.05$, $r=0.4$, $\\varepsilon=10^{-6}$, $\\kappa=7$, $M\\in\\{64,128\\}$, 输出 $p_A$。\n- 案例 B：$\\alpha=1$, $T=0.05$, $r=0.5$, $\\varepsilon=10^{-6}$, $\\kappa=7$, $M\\in\\{64,128\\}$, 输出 $p_B$。\n- 案例 C：$\\alpha=1$, $T=0.05$, $r=0.6$, $\\varepsilon=10^{-6}$, $\\kappa=M-1$ (其中 $M=64$), 输出 $U$。\n\n最终输出格式：您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表，顺序为 $[p_A,p_B,U]$（例如，“[1.997,1.985,True]”）。",
            "solution": "所给问题是一个适定且在科学上合理的计算物理练习。它要求使用前向时间中心空间（FTCS）有限差分法对一维热方程进行数值求解，并分析该方法在不同情况下的精度和稳定性。该问题是有效的，并有唯一解。\n\n控制性偏微分方程（PDE）是热方程：\n$$\n\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}, \\quad x \\in [0, 1], t \\in [0, T]\n$$\n边界条件为齐次狄利克雷边界条件 $u(0,t) = u(1,t) = 0$，初始条件为指定的 $u(x,0)$。\n\n该问题采用 FTCS 有限差分格式，其空间步长为 $\\Delta x = 1/M$，时间步长为 $\\Delta t$ 的均匀网格。网格点为 $x_j = j \\Delta x$ 和 $t_n = n \\Delta t$。该格式由下式给出：\n$$\n\\frac{u_j^{n+1} - u_j^n}{\\Delta t} = \\alpha \\frac{u_{j-1}^n - 2u_j^n + u_{j+1}^n}{\\Delta x^2}\n$$\n这可以重新排列成显式更新公式：\n$$\nu_j^{n+1} = u_j^n + r \\left(u_{j-1}^n - 2u_j^n + u_{j+1}^n\\right)\n$$\n其中 $r = \\alpha \\Delta t / \\Delta x^2$ 是无量纲扩散数。\n\n该格式的理论性质是本问题的核心。\n1.  **精度阶**：通过对有限差分方程中各项在点 $(x_j, t_n)$ 附近进行泰勒级数展开，我们可以确定局部截断误差（LTE）。时间上的前向差分是一阶精度的，即 $O(\\Delta t)$，而空间上的中心差分是二阶精度的，即 $O(\\Delta x^2)$。因此，FTCS 格式的局部截断误差是 $O(\\Delta t, \\Delta x^2)$。对于一个稳定的格式，全局误差与局部截断误差的阶数相同。在这个问题中，参数 $r$ 在每次模拟中保持不变。这意味着时间和空间步长之间存在关系：$\\Delta t = (r/\\alpha) \\Delta x^2$。将此代入误差项，全局误差预计为 $O(\\Delta x^2, \\Delta x^2) = O(\\Delta x^2)$。\n    当网格细化一倍时（从 $M$ 到 $2M$，因此 $\\Delta x$ 变为 $\\Delta x/2$），误差 $E$ 应该减少 $(1/2)^p$ 倍，其中 $p$ 是精度阶。因此，$E(M) \\approx C (\\Delta x)^p$ 且 $E(2M) \\approx C (\\Delta x/2)^p$。取其比值可得 $E(M)/E(2M) \\approx 2^p$。解出 $p$ 即可得到问题中提供的公式：\n    $$\n    p = \\frac{\\log(E(M)/E(2M))}{\\log(2)}\n    $$\n    根据我们的分析，对于稳定情况，我们期望计算出的精度阶 $p$ 接近于 2。\n\n2.  **稳定性**：FTCS 格式的稳定性是有条件的。von Neumann 稳定性分析表明，为了使解保持有界，任何傅里叶模式的放大因子 $g$ 必须满足 $|g| \\le 1$。分析得出的放大因子为：\n    $$\n    g(k) = 1 - 4r \\sin^2\\left(\\frac{k \\Delta x}{2}\\right)\n    $$\n    其中 $k$ 是傅里叶模式的波数。为保证稳定性，我们需要对所有允许的 $k$ 都有 $-1 \\le g(k) \\le 1$。最严格的情况发生在网格支持的最高频率模式，即 $k \\Delta x = \\pi$ 时。这导致了以下条件：\n    $$\n    r = \\frac{\\alpha \\Delta t}{\\Delta x^2} \\le \\frac{1}{2}\n    $$\n    这个稳定性判据是理解三个测试案例中行为的基础：\n    - **案例 A ($r=0.4$)**：格式是稳定的，因为 $0.4 < 0.5$。数值解应该收敛到解析解，并且观测到的精度阶 $p_A$ 应该约等于 2。\n    - **案例 B ($r=0.5$)**：格式处于稳定性极限。对于最高频率模式，放大因子为 $g=-1$。该模式不增长，但会无衰减地振荡，这可能引入非物理行为并可能降低精度。然而，人们可能仍然观察到精度阶 $p_B$ 接近 2，因为解的主要低频分量被正确地衰减了。\n    - **案例 C ($r=0.6$)**：格式是不稳定的，因为 $0.6 > 0.5$。至少有一个模式的放大因子绝对值大于 1。该问题明智地选择了包含高频分量（$\\kappa=M-1$）的初始条件，该分量对应于接近最不稳定模式的网格频率。该分量将被指数级放大，导致数值解的灾难性增长，这在物理上是不正确的，因为热方程是耗散的。这种增长是通过监测解的离散 $L^2$ 范数来检测的。\n\n每个案例的计算过程如下：\n\n对于每个具有指定参数 $(M, r, \\kappa)$ 的模拟，生成一个数值解。\n1.  **初始化**：为 $j=0, \\dots, M$ 建立空间网格 $x_j = j/M$。对于内部网格点 $j=1, \\dots, M-1$，计算初始状态 $u_j^0 = u(x_j, 0) = \\sin(\\pi x_j) + \\varepsilon \\sin(\\kappa \\pi x_j)$。边界点在所有时间步 $n$ 中都固定为 $u_0^n = u_M^n = 0$。\n2.  **时间演化**：计算时间步长 $\\Delta t = r \\Delta x^2 / \\alpha$。确定完整步数 $N_{\\text{full}} = \\lfloor T/\\Delta t \\rfloor$ 和最终时间步长 $\\Delta t_{\\text{last}} = T - N_{\\text{full}} \\Delta t$。FTCS 更新规则使用常数 $r$ 应用 $N_{\\text{full}}$ 次。如果 $\\Delta t_{\\text{last}} > 0$，则使用 $r_{\\text{last}}=\\alpha \\Delta t_{\\text{last}}/\\Delta x^2$ 执行最后一次更新。\n3.  **计算量**：\n    - 对于案例 A 和 B，此过程对 $M=64$ 和 $M=128$ 执行。将最终数值解 $u_j^N$ 与精确解析解 $u(x_j, T)$ 进行比较，以计算误差 $E(M;r)$。然后根据这些误差计算精度阶 $p_A$ 和 $p_B$。\n    - 对于案例 C，模拟在 $M=64$ 和 $r=0.6$ 的条件下运行。在每个时间步 $n$ 计算离散 $L^2$ 范数 $\\|u^n\\|_2 = (\\Delta x \\sum_{j=1}^{M-1} (u_j^n)^2)^{1/2}$。找到该范数与其初始值的最大比率 $\\max_n (\\|u^n\\|_2 / \\|u^0\\|_2)$。通过将此最大比率与阈值 10 进行比较来确定布尔值 $U$。\n\n这种结构化的方法可以直接对 FTCS 方法的理论性质进行数值验证。实现将精确遵循这一逻辑。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by simulating the 1D heat equation with the FTCS scheme\n    for three distinct cases to analyze accuracy and stability.\n    \"\"\"\n\n    def run_simulation(M, r, kappa, alpha, T_final, epsilon, check_instability=False):\n        \"\"\"\n        Runs a single FTCS simulation for the 1D heat equation.\n\n        Args:\n            M (int): Number of subintervals in the spatial domain.\n            r (float): a*dt/dx^2, the Courant-Friedrichs-Lewy (CFL) number.\n            kappa (int): Wavenumber multiplier for the high-frequency initial component.\n            alpha (float): Thermal diffusivity.\n            T_final (float): Final simulation time.\n            epsilon (float): Amplitude of the high-frequency initial component.\n            check_instability (bool): If True, tracks norm growth for instability analysis.\n\n        Returns:\n            If check_instability is False, returns the final numerical solution array.\n            If check_instability is True, returns the maximum observed norm ratio.\n        \"\"\"\n        dx = 1.0 / M\n        x = np.linspace(0, 1, M + 1)\n\n        # Initial condition\n        u = np.sin(np.pi * x) + epsilon * np.sin(kappa * np.pi * x)\n        u[0] = 0.0\n        u[-1] = 0.0\n\n        max_norm_ratio = 1.0\n        if check_instability:\n            # Initial L2 norm for the interior points\n            norm_0 = np.sqrt(dx * np.sum(u[1:-1]**2))\n            if norm_0 == 0:\n                # Avoid division by zero in the unlikely event of a zero initial norm.\n                norm_0 = 1.0 \n\n        # Time stepping\n        dt = r * dx**2 / alpha\n        if dt == 0:\n            # If dt is zero, no time steps can be taken.\n            # Only relevant if r=0, but handle for robustness.\n            if check_instability:\n                return 1.0\n            return u\n\n        num_steps = int(T_final / dt)\n        t_last = T_final - num_steps * dt\n\n        # Evolve with full time steps\n        for _ in range(num_steps):\n            u_new = u.copy()\n            u_new[1:-1] = u[1:-1] + r * (u[:-2] - 2 * u[1:-1] + u[2:])\n            u = u_new\n            if check_instability:\n                norm_n = np.sqrt(dx * np.sum(u[1:-1]**2))\n                max_norm_ratio = max(max_norm_ratio, norm_n / norm_0)\n\n        # Final smaller time step, if necessary\n        if t_last > 1e-15:  # Use a small tolerance for floating point comparison\n            r_last = alpha * t_last / dx**2\n            u_new = u.copy()\n            u_new[1:-1] = u[1:-1] + r_last * (u[:-2] - 2 * u[1:-1] + u[2:])\n            u = u_new\n            if check_instability:\n                norm_n = np.sqrt(dx * np.sum(u[1:-1]**2))\n                max_norm_ratio = max(max_norm_ratio, norm_n / norm_0)\n\n        if check_instability:\n            return max_norm_ratio\n        else:\n            return u\n\n    def get_error(M, r, kappa, alpha, T_final, epsilon):\n        \"\"\"Computes the max-norm error for a given simulation setup.\"\"\"\n        # Numerical solution\n        u_numerical = run_simulation(M, r, kappa, alpha, T_final, epsilon)\n        \n        # Analytical solution\n        x = np.linspace(0, 1, M + 1)\n        term1 = np.exp(-alpha * np.pi**2 * T_final) * np.sin(np.pi * x)\n        term2 = epsilon * np.exp(-alpha * kappa**2 * np.pi**2 * T_final) * np.sin(kappa * np.pi * x)\n        u_analytical = term1 + term2\n\n        # Error calculation (max norm on interior points)\n        error = np.max(np.abs(u_numerical[1:-1] - u_analytical[1:-1]))\n        return error\n\n    def get_order_of_accuracy(r, kappa, M_vals, alpha, T_final, epsilon):\n        \"\"\"Computes the observed order of accuracy.\"\"\"\n        M1, M2 = M_vals\n        error1 = get_error(M1, r, kappa, alpha, T_final, epsilon)\n        error2 = get_error(M2, r, kappa, alpha, T_final, epsilon)\n        \n        # Prevent division by zero or log of non-positive number\n        if error1 = 0 or error2 = 0:\n            return np.nan\n            \n        order = np.log(error1 / error2) / np.log(M2 / M1)\n        return order\n\n\n    # Shared parameters\n    alpha = 1.0\n    T_final = 0.05\n    epsilon = 1.0e-6\n\n    # --- Case A (stable) ---\n    r_A = 0.4\n    kappa_A = 7\n    M_vals_A = (64, 128)\n    p_A = get_order_of_accuracy(r_A, kappa_A, M_vals_A, alpha, T_final, epsilon)\n\n    # --- Case B (stability limit) ---\n    r_B = 0.5\n    kappa_B = 7\n    M_vals_B = (64, 128)\n    p_B = get_order_of_accuracy(r_B, kappa_B, M_vals_B, alpha, T_final, epsilon)\n\n    # --- Case C (unstable) ---\n    r_C = 0.6\n    M_C = 64\n    kappa_C = M_C - 1\n    max_ratio = run_simulation(M_C, r_C, kappa_C, alpha, T_final, epsilon, check_instability=True)\n    U = max_ratio >= 10.0\n    \n    results = [f\"{p_A:.3f}\", f\"{p_B:.3f}\", str(U)]\n    \n    # Final print statement in the exact required format \"[p_A,p_B,U]\"\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```"
        }
    ]
}