{
    "hands_on_practices": [
        {
            "introduction": "We begin with the most fundamental application of least-squares: fitting a straight line. This exercise  uses the real-world context of radioisotope dating to show how a simple linear regression can yield profound scientific insights. You will determine the age of a rock by fitting a line to isochron data, demonstrating how to translate a physical model into a data analysis task and extract a key parameter from the slope of the fit.",
            "id": "2408074",
            "problem": "You are given multiple sets of isotope ratio data from Rubidium–Strontium (Rb–Sr) geochronology for different mineral separates from the same rock. For each set, an isochron is defined by plotting the present-day ratio $y = (^{87}\\mathrm{Sr}/^{86}\\mathrm{Sr})$ against $x = (^{87}\\mathrm{Rb}/^{86}\\mathrm{Sr})$. Under radioactive decay of Rubidium-$87$, the linear relationship\n$$\ny = b + m x\n$$\nholds, where $b = (^{87}\\mathrm{Sr}/^{86}\\mathrm{Sr})_{\\mathrm{initial}}$ and\n$$\nm = e^{\\lambda t} - 1,\n$$\nwith $\\lambda$ the decay constant and $t$ the age. Use $\\lambda = 1.42 \\times 10^{-11}\\ \\mathrm{yr}^{-1}$, and use the natural logarithm. The age is recovered from the fitted slope $\\hat{m}$ via\n$$\n\\hat{t} = \\frac{\\ln(1 + \\hat{m})}{\\lambda}.\n$$\nFor each data set below, determine the best-fit age $\\hat{t}$ by fitting a straight line to the points $\\{(x_i, y_i)\\}$ in the least-squares sense. Express each final age in million years (Ma) as a floating-point number rounded to two decimal places.\n\nTest suite (each data set is independent):\n\n- Data set A (general case):\n  - $x$ values: $[0.20, 0.80, 1.50, 2.50, 3.50, 5.00]$\n  - $y$ values: $[0.702682, 0.713377, 0.725843, 0.743711, 0.761738, 0.788617]$\n- Data set B (boundary with zero slope):\n  - $x$ values: $[0.00, 0.50, 1.00, 1.50, 3.00]$\n  - $y$ values: $[0.704700, 0.704700, 0.704700, 0.704700, 0.704700]$\n- Data set C (older rock; broader spread):\n  - $x$ values: $[0.30, 1.20, 2.80, 4.50, 7.50, 10.00]$\n  - $y$ values: $[0.712295, 0.747371, 0.809941, 0.877448, 0.993603, 1.091396]$\n- Data set D (narrow $x$ spread; conditioning check):\n  - $x$ values: $[0.95, 0.98, 1.02, 1.05, 1.07]$\n  - $y$ values: $[0.732715, 0.733462, 0.734507, 0.735274, 0.735825]$\n\nYour program must process all four data sets, compute the best-fit slope $\\hat{m}$ and convert it to age $\\hat{t}$ using the formula above, then return the ages in million years (Ma), rounded to two decimal places. Angles are not involved. No percentages appear in this problem.\n\nFinal output format: Your program should produce a single line of output containing the ages for Data sets A, B, C, and D, in this order, as a comma-separated list enclosed in square brackets, for example: `[1250.00, 0.00, 2700.00, 1800.00]`.",
            "solution": "The problem statement has been evaluated and is deemed valid. It is scientifically grounded in the principles of radioactive decay and geochronology, is mathematically well-posed, and provides all necessary information for a unique solution. We shall proceed with the derivation and computation.\n\nThe objective is to determine the age of a rock, $t$, from several measurements of isotope ratios. The data provided consist of pairs $(x_i, y_i)$, where $x_i = (^{87}\\mathrm{Rb}/^{86}\\mathrm{Sr})_i$ and $y_i = (^{87}\\mathrm{Sr}/^{86}\\mathrm{Sr})_i$ for different mineral samples $i$. The underlying physical model is the isochron equation, which predicts a linear relationship between these variables:\n$$\ny = b + mx\n$$\nHere, $b$ represents the initial isotopic ratio $(^{87}\\mathrm{Sr}/^{86}\\mathrm{Sr})_{\\mathrm{initial}}$ at the time of the rock's formation ($t=0$), and the slope $m$ is related to the age $t$ of the rock by the equation of radioactive decay:\n$$\nm = e^{\\lambda t} - 1\n$$\nwhere $\\lambda$ is the decay constant for $^{87}\\mathrm{Rb}$.\n\nThe task requires finding the best-fit parameters for the linear model from the given experimental data. The specified method is the standard unweighted linear least-squares regression. This method determines the slope $\\hat{m}$ and intercept $\\hat{b}$ that minimize the sum of the squares of the vertical residuals, $S$:\n$$\nS = \\sum_{i=1}^{N} (y_i - (\\hat{m}x_i + \\hat{b}))^2\n$$\nThe value of the slope $\\hat{m}$ that minimizes $S$ is given by the formula:\n$$\n\\hat{m} = \\frac{\\sum_{i=1}^{N} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{N} (x_i - \\bar{x})^2}\n$$\nwhere $N$ is the number of data points, $\\bar{x}$ is the mean of the $x_i$ values, and $\\bar{y}$ is the mean of the $y_i$ values. This formula provides a unique solution as long as there is variation in the $x_i$ values, which is true for all supplied datasets. The intercept $\\hat{b}$ can be calculated as $\\hat{b} = \\bar{y} - \\hat{m}\\bar{x}$, but it is not required for the age determination.\n\nOnce the best-fit slope $\\hat{m}$ is computed for a given dataset, the age $\\hat{t}$ is found by inverting the relationship between slope and age. Starting from $\\hat{m} = e^{\\lambda \\hat{t}} - 1$, we rearrange the equation:\n$$\n1 + \\hat{m} = e^{\\lambda \\hat{t}}\n$$\nTaking the natural logarithm of both sides yields:\n$$\n\\ln(1 + \\hat{m}) = \\ln(e^{\\lambda \\hat{t}}) = \\lambda \\hat{t}\n$$\nFrom this, we solve for the age $\\hat{t}$:\n$$\n\\hat{t} = \\frac{\\ln(1 + \\hat{m})}{\\lambda}\n$$\nThe problem specifies the decay constant $\\lambda = 1.42 \\times 10^{-11}\\ \\mathrm{yr}^{-1}$. Using this value, the calculated age $\\hat{t}$ will be in units of years. The final requirement is to express the age in million years (Ma), which requires division by $10^6$:\n$$\n\\hat{t}_{\\text{Ma}} = \\frac{\\hat{t}}{10^6} = \\frac{\\ln(1 + \\hat{m})}{\\lambda \\times 10^6}\n$$\nThe result is then rounded to two decimal places. This procedure will be applied systematically to each of the four data sets using a computational algorithm to ensure precision. For the special case of Data set B, the $y_i$ values are constant, which correctly implies a slope $\\hat{m}=0$ and consequently an age $\\hat{t}=0$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Rb-Sr isochron age for multiple geological data sets.\n    \n    The age is determined by performing a linear least-squares fit on the\n    isotope ratio data to find the slope of the isochron, then using the\n    slope to calculate the age based on the radioactive decay equation.\n    \"\"\"\n    \n    # Define the physical constant and test cases.\n    \n    # Decay constant for Rubidium-87 in yr^-1.\n    LAMBDA_RB87 = 1.42e-11\n    \n    # Isotope ratio data for four different rock samples.\n    # Each data set is a tuple of (x_values, y_values).\n    test_cases = [\n        # Data set A (general case)\n        (\n            [0.20, 0.80, 1.50, 2.50, 3.50, 5.00],\n            [0.702682, 0.713377, 0.725843, 0.743711, 0.761738, 0.788617]\n        ),\n        # Data set B (boundary with zero slope)\n        (\n            [0.00, 0.50, 1.00, 1.50, 3.00],\n            [0.704700, 0.704700, 0.704700, 0.704700, 0.704700]\n        ),\n        # Data set C (older rock; broader spread)\n        (\n            [0.30, 1.20, 2.80, 4.50, 7.50, 10.00],\n            [0.712295, 0.747371, 0.809941, 0.877448, 0.993603, 1.091396]\n        ),\n        # Data set D (narrow x spread; conditioning check)\n        (\n            [0.95, 0.98, 1.02, 1.05, 1.07],\n            [0.732715, 0.733462, 0.734507, 0.735274, 0.735825]\n        )\n    ]\n    \n    results = []\n    \n    for x_data, y_data in test_cases:\n        # Convert data to numpy arrays for numerical processing.\n        x = np.array(x_data)\n        y = np.array(y_data)\n        \n        # Perform linear regression to find the slope (m) of the line y = mx + b.\n        # np.polyfit with degree 1 fits a line and returns [slope, intercept].\n        # We only need the slope for the age calculation.\n        slope, _ = np.polyfit(x, y, 1)\n        \n        # The slope m is related to age t by m = exp(lambda * t) - 1.\n        # We solve for t: t = ln(1 + m) / lambda.\n        # A slope of 0 (or very close) will result in an age of 0, as log(1)=0.\n        # This handles Data set B correctly.\n        if 1 + slope = 0:\n            # This case is physically unrealistic for Rb-Sr dating but included for robustness.\n            # An age cannot be calculated. For this problem, we can assume slope > -1.\n            # We will treat this as an error or undefined age. \n            # However, problem data guarantees non-negative slope.\n            age_yr = np.nan\n        else:\n            age_yr = np.log(1 + slope) / LAMBDA_RB87\n            \n        # Convert age from years to million years (Ma).\n        age_ma = age_yr / 1e6\n        \n        # Format the result to two decimal places and add to the list.\n        results.append(f\"{age_ma:.2f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Most physical models are not linear in their parameters, requiring more sophisticated numerical methods. In this practice , you will confront this challenge by fitting parameters for the van der Waals equation of state, a classic model for non-ideal gases. This exercise will guide you through setting up a non-linear least-squares problem and using an iterative numerical optimizer to find the parameters that best describe the data, including how to handle physical constraints.",
            "id": "2408017",
            "problem": "You are given the van der Waals equation of state for one mole of a non-ideal gas,\n$$(P + \\tfrac{a}{V^2})(V - b) = R\\,T,$$\nwhere $P$ is the pressure, $V$ is the molar volume, $T$ is the absolute temperature, $R$ is the universal gas constant, and $a$ and $b$ are unknown parameters that characterize deviations from ideal-gas behavior. Equivalently, the model pressure as a function of $(V,T,a,b)$ is\n$$P_{\\text{model}}(V,T;a,b) = \\frac{R\\,T}{V - b} - \\frac{a}{V^2}.$$\nUse the universal gas constant $R = 8.31446261815324\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$ (noting that $\\mathrm{J} = \\mathrm{Pa\\,m^3}$ so that $P$ is in $\\mathrm{Pa}$ when $V$ is in $\\mathrm{m^3\\,mol^{-1}}$ and $T$ in $\\mathrm{K}$). For each dataset below, synthetic Pressure–Volume–Temperature (PVT) data are defined by known ground-truth parameters $(a_\\star,b_\\star)$ and a specified set of temperatures and molar volumes. Each pressure datum is generated exactly by $P_i = P_{\\text{model}}(V_i,T_i;a_\\star,b_\\star)$ with no added noise.\n\nYour task for each dataset is: given the list of triplets $\\{(T_i,V_i,P_i)\\}_{i=1}^N$, determine estimates $(\\hat a,\\hat b)$ that minimize the sum of squared pressure residuals\n$$S(a,b) = \\sum_{i=1}^{N}\\big(P_i - P_{\\text{model}}(V_i,T_i;a,b)\\big)^2,$$\nsubject to the physical constraints $a \\ge 0$ and $0 \\le b  \\min_i V_i$. Report $\\hat a$ in $\\mathrm{Pa\\,m^6\\,mol^{-2}}$ and $\\hat b$ in $\\mathrm{m^3\\,mol^{-1}}$.\n\nTest suite definition (three datasets):\n- Dataset $\\mathrm{A}$:\n  - Ground truth: $a_\\star = 0.1390\\,\\mathrm{Pa\\,m^6\\,mol^{-2}}$, $b_\\star = 3.913\\times 10^{-5}\\,\\mathrm{m^3\\,mol^{-1}}$.\n  - Temperatures: $\\{300\\,\\mathrm{K}, 350\\,\\mathrm{K}, 400\\,\\mathrm{K}\\}$.\n  - Molar volumes: $\\{1.50\\times 10^{-3}\\,\\mathrm{m^3\\,mol^{-1}}, 2.00\\times 10^{-3}\\,\\mathrm{m^3\\,mol^{-1}}, 3.00\\times 10^{-3}\\,\\mathrm{m^3\\,mol^{-1}}\\}$.\n  - Data points: all $9$ combinations of temperature and volume; $P_i$ computed exactly by the model with $(a_\\star,b_\\star)$.\n- Dataset $\\mathrm{B}$:\n  - Ground truth: $a_\\star = 3.41\\times 10^{-3}\\,\\mathrm{Pa\\,m^6\\,mol^{-2}}$, $b_\\star = 2.37\\times 10^{-5}\\,\\mathrm{m^3\\,mol^{-1}}$.\n  - Temperatures: $\\{300\\,\\mathrm{K}, 600\\,\\mathrm{K}\\}$.\n  - Molar volumes: $\\{1.00\\times 10^{-2}\\,\\mathrm{m^3\\,mol^{-1}}, 2.00\\times 10^{-2}\\,\\mathrm{m^3\\,mol^{-1}}, 5.00\\times 10^{-2}\\,\\mathrm{m^3\\,mol^{-1}}\\}$.\n  - Data points: all $6$ combinations of temperature and volume; $P_i$ computed exactly by the model with $(a_\\star,b_\\star)$.\n- Dataset $\\mathrm{C}$:\n  - Ground truth: $a_\\star = 0.3592\\,\\mathrm{Pa\\,m^6\\,mol^{-2}}$, $b_\\star = 4.267\\times 10^{-5}\\,\\mathrm{m^3\\,mol^{-1}}$.\n  - Temperatures: $\\{350\\,\\mathrm{K}\\}$.\n  - Molar volumes: $\\{1.20\\times 10^{-3}\\,\\mathrm{m^3\\,mol^{-1}}, 2.50\\times 10^{-3}\\,\\mathrm{m^3\\,mol^{-1}}\\}$.\n  - Data points: the $2$ volume values at the single temperature; $P_i$ computed exactly by the model with $(a_\\star,b_\\star)$.\n\nRequired final output format:\n- For each dataset in the order $\\mathrm{A}$, $\\mathrm{B}$, $\\mathrm{C}$, output the pair $[\\hat a,\\hat b]$ with both numbers in the specified International System of Units (SI) and each rounded to $6$ significant figures.\n- Your program should produce a single line of output containing the three pairs aggregated as a comma-separated list enclosed in square brackets, for example, `[[a_A, b_A], [a_B, b_B], [a_C, b_C]]`, with no additional text.",
            "solution": "The problem presented is valid. It is a well-defined computational physics task concerning parameter estimation for the van der Waals equation of state, which is a fundamental model in thermodynamics. All necessary data, constants, and constraints are provided, and the problem is scientifically sound, objective, and internally consistent.\n\nThe core of the problem is to determine the optimal parameters $(\\hat{a}, \\hat{b})$ of the van der Waals model that best reproduce a given set of pressure-volume-temperature ($PVT$) data. The model for pressure is given by\n$$P_{\\text{model}}(V,T;a,b) = \\frac{R\\,T}{V - b} - \\frac{a}{V^2}$$\nwhere $R$ is the universal gas constant, $T$ is temperature, and $V$ is molar volume. The parameters to be determined are $a$, which accounts for intermolecular attraction, and $b$, the excluded volume per mole.\n\nThe criterion for the \"best fit\" is the minimization of the sum of squared residuals, $S(a,b)$:\n$$S(a,b) = \\sum_{i=1}^{N}\\big(P_i - P_{\\text{model}}(V_i,T_i;a,b)\\big)^2$$\nwhere $\\{ (T_i, V_i, P_i) \\}_{i=1}^N$ are the $N$ data points. This is a nonlinear least-squares optimization problem. The nonlinearity arises from the dependence of the model on the parameter $b$ in the term $(V-b)^{-1}$. Standard linear regression methods are therefore inapplicable.\n\nA crucial aspect of this problem is that the pressure data $P_i$ are synthetically generated without noise from the model itself, using known ground-truth parameters $(a_\\star, b_\\star)$. This means that a perfect fit is possible, and the global minimum of the objective function $S(a,b)$ is exactly zero, which occurs at $(a,b) = (a_\\star, b_\\star)$. The task thus reduces to recovering these known parameters numerically, which serves as a robust test of the chosen optimization algorithm.\n\nThe numerical solution is implemented using a nonlinear least-squares solver. The `scipy.optimize.least_squares` function from the SciPy library is ideally suited for this purpose. This function is designed to minimize the $L_2$-norm of a vector of residuals. We define the residual vector $\\mathbf{r}(a,b)$ with components:\n$$r_i(a,b) = P_i - \\left( \\frac{R\\,T_i}{V_i - b} - \\frac{a}{V_i^2} \\right)$$\nThe optimizer then finds the parameters $(\\hat{a}, \\hat{b})$ that minimize $||\\mathbf{r}||^2 = S(a,b)$.\n\nThe optimization must adhere to physical constraints specified in the problem:\n1.  $a \\ge 0$: The intermolecular attraction term is non-negative.\n2.  $0 \\le b  \\min_i V_i$: The excluded volume $b$ must be non-negative and physically cannot exceed the smallest molar volume container $V_i$ in the dataset.\n\nThese constraints are imposed as bounds on the parameters during the optimization process: $a \\in [0, \\infty)$ and $b \\in [0, \\min_i V_i)$.\n\nFor an iterative nonlinear solver, an initial guess for the parameters is required. A logical starting point is the ideal gas limit, where there are no corrections to the ideal gas law. This corresponds to an initial guess of $(a_0, b_0) = (0, 0)$.\n\nThe procedure for each dataset is as follows:\n1.  The set of data points $(T_i, V_i)$ is constructed from the specified ranges.\n2.  The corresponding pressure values $P_i$ are calculated using the van der Waals model with the given ground-truth parameters $(a_\\star, b_\\star)$.\n3.  The `scipy.optimize.least_squares` solver is called with the defined residual function, the initial guess $(0,0)$, and the physical bounds derived from the constraints.\n4.  For datasets A ($N=9$) and B ($N=6$), the system is overdetermined ($N2$), which is the standard case for least-squares fitting. For dataset C ($N=2$), the system is exactly determined, meaning we are solving a system of two nonlinear equations for two unknowns. The least-squares method is general and correctly handles all these cases.\n5.  The resulting optimal parameters $(\\hat{a}, \\hat{b})$ are extracted. Due to the noise-free nature of the data, these estimates are expected to be numerically identical to the ground-truth values $(a_\\star, b_\\star)$ to within the solver's tolerance.\n6.  Finally, the estimated parameters $\\hat{a}$ and $\\hat{b}$ are rounded and formatted to six significant figures in the specified scientific notation format for the final output.",
            "answer": "```python\nimport numpy as np\nfrom scipy import optimize\n\ndef solve():\n    \"\"\"\n    Solves for the van der Waals parameters (a, b) for three different datasets\n    using nonlinear least-squares fitting.\n    \"\"\"\n    R = 8.31446261815324  # Universal gas constant in J mol^-1 K^-1\n\n    test_cases = [\n        {\n            \"a_star\": 0.1390,\n            \"b_star\": 3.913e-5,\n            \"T_vals\": np.array([300.0, 350.0, 400.0]),\n            \"V_vals\": np.array([1.50e-3, 2.00e-3, 3.00e-3]),\n        },\n        {\n            \"a_star\": 3.41e-3,\n            \"b_star\": 2.37e-5,\n            \"T_vals\": np.array([300.0, 600.0]),\n            \"V_vals\": np.array([1.00e-2, 2.00e-2, 5.00e-2]),\n        },\n        {\n            \"a_star\": 0.3592,\n            \"b_star\": 4.267e-5,\n            \"T_vals\": np.array([350.0]),\n            \"V_vals\": np.array([1.20e-3, 2.50e-3]),\n        },\n    ]\n\n    def p_model(params, T, V, R_const):\n        \"\"\"Calculates pressure using the van der Waals model.\"\"\"\n        a, b = params\n        return R_const * T / (V - b) - a / (V**2)\n\n    def residuals(params, T, V, P_data, R_const):\n        \"\"\"Calculates the residuals between model predictions and data.\"\"\"\n        return P_data - p_model(params, T, V, R_const)\n\n    formatted_results = []\n\n    for case in test_cases:\n        # 1. Generate the synthetic PVT data\n        T_grid, V_grid = np.meshgrid(case[\"T_vals\"], case[\"V_vals\"])\n        T_data = T_grid.flatten()\n        V_data = V_grid.flatten()\n        \n        true_params = [case[\"a_star\"], case[\"b_star\"]]\n        P_data = p_model(true_params, T_data, V_data, R)\n\n        # 2. Set up and run the optimization\n        # Initial guess: ideal gas limit (a=0, b=0)\n        x0 = [0.0, 0.0]\n        \n        # Physical constraints as bounds for the solver\n        min_V = np.min(V_data)\n        bounds = ([0.0, 0.0], [np.inf, min_V])\n\n        # Find the parameters that minimize the sum of squared residuals\n        result = optimize.least_squares(\n            residuals,\n            x0,\n            bounds=bounds,\n            args=(T_data, V_data, P_data, R),\n            method='trf'  # Trust Region Reflective algorithm, good for bounds\n        )\n        \n        a_hat, b_hat = result.x\n\n        # 3. Format the results to 6 significant figures\n        # The '.5e' format specifier ensures scientific notation with 1 digit\n        # before the decimal and 5 after, for a total of 6 significant figures.\n        a_hat_str = f\"{a_hat:.5e}\"\n        b_hat_str = f\"{b_hat:.5e}\"\n        \n        formatted_results.append(f\"[{a_hat_str},{b_hat_str}]\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A powerful technique in experimental science is to combine data from multiple measurements to increase statistical precision. This practice  introduces this concept of a 'global' or 'simultaneous' fit, where some parameters are unique to each dataset while others are fundamental and shared. You will analyze several datasets of a decaying signal, learning how to construct a unified objective function to find the single best-fit values for these shared quantities.",
            "id": "2408092",
            "problem": "You are given multiple independent datasets that each measure a decaying signal with a constant background. The common physics model is that a detector’s count-rate signal decays exponentially in time due to a single species with a common lifetime across all experiments and the detectors share a single constant background rate. For dataset index $k$, measurement at time $t_{k,i}$ yields an observed count-rate $y_{k,i}$ with reported standard deviation $\\sigma_{k,i}$. The forward model is\n$$\ny_{k,i} \\approx A_k \\, e^{-t_{k,i}/\\tau} + B,\n$$\nwhere $A_k$ is a dataset-specific amplitude, $\\tau$ is a lifetime shared by all datasets, and $B$ is a background rate shared by all datasets. Assume additive, independent Gaussian measurement errors with known standard deviations $\\sigma_{k,i}$. Under these assumptions, the principle of maximum likelihood implies minimizing the weighted sum of squared residuals. That is, the estimated parameters minimize\n$$\nS(\\{A_k\\}, \\tau, B) = \\sum_{k} \\sum_{i} \\left( \\frac{y_{k,i} - \\left(A_k e^{-t_{k,i}/\\tau} + B\\right)}{\\sigma_{k,i}} \\right)^2.\n$$\nYour task is to write a complete, runnable program that simultaneously fits all datasets in each test case using Weighted Least Squares (WLS) to find the best-fit shared lifetime $\\tau$ and background $B$, while allowing each dataset to have its own amplitude $A_k$. Constrain the parameters physically as $A_k \\ge 0$, $\\tau  0$, and $B \\ge 0$. The optimization must directly minimize the sum of squared weighted residuals corresponding to the model above, treating $\\tau$ and $B$ as shared parameters across datasets within the same test case.\n\nPhysical units: interpret each time $t$ in seconds and each count-rate $y$ in counts per second. Report the lifetime $\\tau$ in seconds and the background $B$ in counts per second. Round each reported number to exactly three digits after the decimal point.\n\nTest suite. For each test case below, the program must simultaneously fit all datasets given in that case and output only the best-fit shared $\\tau$ and shared $B$, rounded to exactly three decimal places.\n\nTest Case $1$ (two datasets, moderate noise, well-conditioned):\n- Dataset $1$: times $t_{1} = (0, 0.5, 1.0, 1.5, 2.0, 3.0)$, observations $y_{1} = (5.51, 4.38, 3.55, 2.86, 2.36, 1.62)$, uncertainties $\\sigma_{1} = (0.05, 0.05, 0.05, 0.05, 0.05, 0.05)$.\n- Dataset $2$: times $t_{2} = (0, 0.7, 1.4, 2.1, 2.8, 3.5)$, observations $y_{2} = (3.49, 2.62, 2.00, 1.54, 1.25, 1.03)$, uncertainties $\\sigma_{2} = (0.08, 0.08, 0.08, 0.08, 0.08, 0.08)$.\n\nTest Case $2$ (one dataset with small amplitude, testing identifiability of $B$):\n- Dataset $1$: times $t_{1} = (0, 0.5, 1.0, 1.5, 2.0)$, observations $y_{1} = (2.31, 1.50, 1.04, 0.75, 0.57)$, uncertainties $\\sigma_{1} = (0.02, 0.02, 0.02, 0.02, 0.02)$.\n- Dataset $2$: times $t_{2} = (0, 1.0, 2.0, 3.0)$, observations $y_{2} = (0.49, 0.38, 0.33, 0.31)$, uncertainties $\\sigma_{2} = (0.01, 0.01, 0.01, 0.01)$.\n\nTest Case $3$ (three datasets with different time coverage and uncertainties):\n- Dataset $1$: times $t_{1} = (0, 1.0, 2.0, 3.0, 5.0)$, observations $y_{1} = (5.21, 4.05, 3.26, 2.67, 1.97)$, uncertainties $\\sigma_{1} = (0.03, 0.03, 0.03, 0.03, 0.03)$.\n- Dataset $2$: times $t_{2} = (0.5, 1.5, 2.5, 4.0, 6.0)$, observations $y_{2} = (2.46, 2.12, 1.86, 1.60, 1.39)$, uncertainties $\\sigma_{2} = (0.05, 0.05, 0.05, 0.05, 0.05)$.\n- Dataset $3$: times $t_{3} = (0, 0.2, 0.4, 0.6, 0.8, 1.0)$, observations $y_{3} = (7.19, 6.82, 6.44, 6.11, 5.79, 5.49)$, uncertainties $\\sigma_{3} = (0.02, 0.02, 0.02, 0.02, 0.02, 0.02)$.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in order: the fitted $\\tau$ and $B$ for Test Case $1$, then the fitted $\\tau$ and $B$ for Test Case $2$, then the fitted $\\tau$ and $B$ for Test Case $3$. Express each number rounded to exactly three decimal places, in the units specified above. For example, the output structure must be\n$$\n[\\tau_1, B_1, \\tau_2, B_2, \\tau_3, B_3],\n$$\nwith each entry rounded to exactly three digits after the decimal point and expressed implicitly in seconds for $\\tau$ and counts per second for $B$.",
            "solution": "The problem presented is a standard exercise in computational physics: parameter estimation via non-linear least-squares fitting of a physical model to experimental data. Specifically, we are tasked with performing a global analysis of multiple datasets, which are presumed to share certain model parameters. The procedure must be robust and grounded in sound statistical principles.\n\nThe validation step has confirmed the problem is well-posed, scientifically sound, and complete. We proceed to the solution.\n\nThe physical model for the observed count rate $y_{k,i}$ at time $t_{k,i}$ for the $k$-th dataset is given as:\n$$\nf(t_{k,i}; A_k, \\tau, B) = A_k e^{-t_{k,i}/\\tau} + B\n$$\nHere, $A_k$ is the amplitude specific to dataset $k$, while the lifetime $\\tau$ and the constant background $B$ are global parameters, common to all datasets within a single test case.\n\nThe measurements are assumed to be corrupted by independent, additive Gaussian noise with known standard deviations $\\sigma_{k,i}$. Under this assumption, the principle of maximum likelihood is equivalent to minimizing the weighted sum of squared residuals, also known as the chi-squared ($\\chi^2$) statistic. The objective function to be minimized is thus:\n$$\nS(\\{A_k\\}, \\tau, B) = \\sum_{k} \\sum_{i} w_{k,i} \\left[ y_{k,i} - f(t_{k,i}; A_k, \\tau, B) \\right]^2\n$$\nwhere the weights are the inverse variances, $w_{k,i} = 1/\\sigma_{k,i}^2$. Expanding the model function, we have:\n$$\nS(\\{A_k\\}, \\tau, B) = \\sum_{k} \\sum_{i} \\left( \\frac{y_{k,i} - \\left(A_k e^{-t_{k,i}/\\tau} + B\\right)}{\\sigma_{k,i}} \\right)^2\n$$\nThis is a non-linear optimization problem. The set of all parameters to be determined for a given test case comprising $N_d$ datasets is $\\{A_1, A_2, \\dots, A_{N_d}, \\tau, B\\}$. The total number of parameters is $N_d+2$. We can represent these parameters as a single vector $\\mathbf{p}$:\n$$\n\\mathbf{p} = (A_1, A_2, \\dots, A_{N_d}, \\tau, B)^T\n$$\nThe problem is then to find the parameter vector $\\mathbf{p}^*$ that minimizes the objective function $S(\\mathbf{p})$:\n$$\n\\mathbf{p}^* = \\underset{\\mathbf{p}}{\\operatorname{argmin}} S(\\mathbf{p})\n$$\nThis minimization must be performed subject to the physical constraints:\n$$\nA_k \\ge 0 \\quad \\forall k \\in \\{1, \\dots, N_d\\}\n\\\\\n\\tau  0\n\\\\\nB \\ge 0\n$$\n\nTo solve this constrained non-linear optimization problem, we employ a numerical quasi-Newton method, specifically the Broyden–Fletcher–Goldfarb–Shanno algorithm with box constraints (L-BFGS-B), as implemented in the `scipy.optimize.minimize` function. This method is well-suited for such problems.\n\nThe solution process for each test case is as follows:\n1.  **Data aggregation**: All datasets $(t_k, y_k, \\sigma_k)$ belonging to a single test case are collected. The number of datasets, $N_d$, determines the dimension of the parameter space.\n2.  **Objective function implementation**: A Python function is constructed to compute $S(\\mathbf{p})$ given the parameter vector $\\mathbf{p}$ and the aggregated data. This function parses $\\mathbf{p}$ into the individual amplitudes $\\{A_k\\}$, the lifetime $\\tau$, and the background $B$, then computes the total sum of squared weighted residuals over all data points from all datasets.\n3.  **Initialization**: The iterative optimization algorithm requires an initial guess, $\\mathbf{p}_0$, for the parameters. While the L-BFGS-B method is relatively robust, a reasonable starting point can improve convergence speed and reliability. We devise a simple automated strategy for generating $\\mathbf{p}_0$:\n    -   The initial background $B_0$ is taken as the minimum value across all observed data points $y_{k,i}$.\n    -   The initial lifetime $\\tau_0$ is estimated as a fraction of the total time span of the experiments.\n    -   Each initial amplitude $A_{k,0}$ is estimated from the first data point of the corresponding dataset, corrected for the estimated background: $A_{k,0} \\approx y_{k, \\text{first}} - B_0$. All initial estimates are floored at a small positive number to respect the non-negativity constraints.\n4.  **Constraints enforcement**: The physical constraints are translated into box bounds for the optimization algorithm. For each $A_k$ and for $B$, the lower bound is $0$ and the upper bound is infinity. For $\\tau$, the lower bound must be strictly positive; we use a small machine-precision value (e.g., $10^{-9}$) to practically enforce $\\tau  0$.\n5.  **Optimization**: The `scipy.optimize.minimize` function is called with the objective function, initial guess vector $\\mathbf{p}_0$, `L-BFGS-B` method, and the defined bounds. The function iteratively refines the parameter estimates until convergence criteria are met.\n6.  **Result extraction**: Upon successful convergence, the optimizer returns the optimal parameter vector $\\mathbf{p}^*$. The desired shared lifetime $\\tau^*$ and background $B^*$ are the last two components of this vector.\n\nThis procedure is systematically applied to each of the three test cases provided. The final results for $\\tau$ and $B$ from each case are collected and then formatted as specified.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves a series of global data fitting problems for exponential decay.\n\n    Each test case involves one or more datasets that are fit simultaneously\n    to a model y = A_k * exp(-t/tau) + B, where tau and B are shared across\n    datasets within a test case.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1\n        [\n            (np.array([0, 0.5, 1.0, 1.5, 2.0, 3.0]), np.array([5.51, 4.38, 3.55, 2.86, 2.36, 1.62]), np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.05])),\n            (np.array([0, 0.7, 1.4, 2.1, 2.8, 3.5]), np.array([3.49, 2.62, 2.00, 1.54, 1.25, 1.03]), np.array([0.08, 0.08, 0.08, 0.08, 0.08, 0.08]))\n        ],\n        # Test Case 2\n        [\n            (np.array([0, 0.5, 1.0, 1.5, 2.0]), np.array([2.31, 1.50, 1.04, 0.75, 0.57]), np.array([0.02, 0.02, 0.02, 0.02, 0.02])),\n            (np.array([0, 1.0, 2.0, 3.0]), np.array([0.49, 0.38, 0.33, 0.31]), np.array([0.01, 0.01, 0.01, 0.01]))\n        ],\n        # Test Case 3\n        [\n            (np.array([0, 1.0, 2.0, 3.0, 5.0]), np.array([5.21, 4.05, 3.26, 2.67, 1.97]), np.array([0.03, 0.03, 0.03, 0.03, 0.03])),\n            (np.array([0.5, 1.5, 2.5, 4.0, 6.0]), np.array([2.46, 2.12, 1.86, 1.60, 1.39]), np.array([0.05, 0.05, 0.05, 0.05, 0.05])),\n            (np.array([0, 0.2, 0.4, 0.6, 0.8, 1.0]), np.array([7.19, 6.82, 6.44, 6.11, 5.79, 5.49]), np.array([0.02, 0.02, 0.02, 0.02, 0.02, 0.02]))\n        ]\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        num_datasets = len(case)\n\n        # Objective function for the current test case\n        def objective_function(p):\n            # p = [A1, A2, ..., Ak, tau, B]\n            amplitudes = p[:num_datasets]\n            tau = p[num_datasets]\n            B = p[num_datasets + 1]\n            \n            total_chi_squared = 0.0\n            for k in range(num_datasets):\n                t_k, y_k, sigma_k = case[k]\n                A_k = amplitudes[k]\n                \n                y_model_k = A_k * np.exp(-t_k / tau) + B\n                residuals = (y_k - y_model_k) / sigma_k\n                total_chi_squared += np.sum(residuals**2)\n            \n            return total_chi_squared\n\n        # Automated initial guesses\n        B_guess = np.min([np.min(d[1]) for d in case])\n        max_time = np.max([np.max(d[0]) for d in case])\n        tau_guess = max_time / 2.0 if max_time > 0 else 1.0\n\n        A_guesses = []\n        for k in range(num_datasets):\n            y_first = case[k][1][0]\n            A_guess = max(1e-6, y_first - B_guess)\n            A_guesses.append(A_guess)\n            \n        p0 = A_guesses + [tau_guess, B_guess]\n\n        # Parameter bounds based on physical constraints\n        # Ak >= 0, tau > 0, B >= 0\n        bounds = [(0, None)] * num_datasets  # Bounds for A_k\n        bounds.append((1e-9, None))           # Bound for tau\n        bounds.append((0, None))              # Bound for B\n\n        # Perform the optimization\n        res = minimize(objective_function, p0, method='L-BFGS-B', bounds=bounds)\n        \n        # Extract optimal shared parameters tau and B\n        optimal_tau = res.x[num_datasets]\n        optimal_B = res.x[num_datasets + 1]\n        \n        results.append(optimal_tau)\n        results.append(optimal_B)\n\n    # Format the final output string\n    print(f\"[{','.join(f'{x:.3f}' for x in results)}]\")\n\nsolve()\n```"
        }
    ]
}