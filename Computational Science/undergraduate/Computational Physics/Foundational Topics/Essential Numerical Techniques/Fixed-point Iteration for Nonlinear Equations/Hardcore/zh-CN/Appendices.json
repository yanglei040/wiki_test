{
    "hands_on_practices": [
        {
            "introduction": "不动点迭代法的核心在于迭代函数 $g(x)$ 的构造。一个精心设计的 $g(x)$ 不仅能确保迭代收敛到期望的根，还能显著提高收敛速度。本练习将引导你掌握如何通过调整一个参数来优化一个迭代格式，使其达到至少二次的收敛阶，这是从基本线性收敛迈向牛顿法等高效方法的关键一步 。",
            "id": "2393364",
            "problem": "在计算工程学中，不动点迭代是求解由控制方程离散化产生的非线性代数方程的基本方法。考虑标量非线性方程\n$$\nf(x) = x^{3} - 6x^{2} + 11x - 6 = 0,\n$$\n该方程在 $x = 1$、$x = 2$ 和 $x = 3$ 处有三个单实根。对于每个根 $r_{k} \\in \\{1, 2, 3\\}$，构造一个松弛形式的不动点迭代\n$$\nx_{n+1} = g_{k}(x_{n}), \\quad g_{k}(x) = x - \\alpha_{k}\\, f(x),\n$$\n其中常数参数 $\\alpha_{k}$ 的选择应使迭代在目标根 $r_{k}$ 附近至少具有二阶收敛性。然后，确定分别对应于 $r_{1} = 1$、$r_{2} = 2$ 和 $r_{3} = 3$ 的 $\\alpha_{1}$、$\\alpha_{2}$ 和 $\\alpha_{3}$ 的精确值，并计算\n$$\nS = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}.\n$$\n给出 $S$ 的单一精确值。无需四舍五入。",
            "solution": "在尝试求解之前，对问题陈述进行验证。\n\n步骤1：提取已知条件。\n提供的已知信息如下：\n- 非线性标量方程为 $f(x) = x^{3} - 6x^{2} + 11x - 6 = 0$。\n- 该方程有三个单实根：$r_{1} = 1$，$r_{2} = 2$，$r_{3} = 3$。\n- 为每个根 $r_{k}$ 给定一个不动点迭代格式：$x_{n+1} = g_{k}(x_{n})$。\n- 迭代函数以松弛形式定义：$g_{k}(x) = x - \\alpha_{k}\\, f(x)$。\n- 参数 $\\alpha_{k}$ 的选择必须使迭代在相应根 $r_{k}$ 附近至少具有二阶收敛性。\n- 目标是计算总和 $S = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}$。\n\n步骤2：使用提取的已知条件进行验证。\n对问题的有效性进行评估：\n- **科学依据：** 该问题植根于数值方法的基本理论，特别是不动点迭代及其收敛准则。收敛阶（线性、二次等）的概念是计算科学与工程中的一个标准课题。该问题在科学上是合理的。\n- **适定性：** 该问题提供了明确的目标和充分的信息。“至少二阶收敛”的条件对迭代函数的导数施加了特定的数学约束，这使得每个参数 $\\alpha_{k}$ 都能被唯一确定。该问题是适定的。\n- **客观性：** 该问题使用精确的数学语言陈述，没有歧义、主观性或个人意见。\n\n该问题没有表现出科学不合理、不完整、矛盾或歧义等任何缺陷。它是数值分析中一个标准的、可形式化的问题。\n\n步骤3：结论与行动。\n该问题被判定为有效。将推导解答。\n\n问题的核心在于分析不动点迭代 $x_{n+1} = g(x_{n})$ 的收敛速度。如果不动点迭代的根 $r$ 是 $g(x)$ 的一个不动点（即 $g(r) = r$），并且迭代函数在 $r$ 的一个邻域内是压缩映射，那么迭代就会收敛到 $r$。收敛阶由 $g(x)$ 在不动点 $r$ 处的导数值决定。\n\n为使迭代局部至少为二阶收敛，迭代函数的一阶导数在不动点处必须为零。即 $g'(r) = 0$。如果满足此条件，$g(x)$ 关于 $r$ 的泰勒级数展开为：\n$$\ng(x) = g(r) + g'(r)(x-r) + \\frac{g''(r)}{2!}(x-r)^{2} + O((x-r)^{3})\n$$\n当 $g(r)=r$ 和 $g'(r)=0$ 时，上式变为：\n$$\ng(x) - r = \\frac{g''(r)}{2}(x-r)^{2} + O((x-r)^{3})\n$$\n设 $e_{n} = x_{n} - r$ 为第 $n$ 次迭代的误差。则 $x_{n} = r + e_{n}$，且 $x_{n+1} = g(x_{n})$。\n$$\ne_{n+1} = x_{n+1} - r = g(x_{n}) - r = g(r + e_{n}) - r = \\frac{g''(r)}{2} e_{n}^{2} + O(e_{n}^{3})\n$$\n这种关系，即第 $n+1$ 步的误差与第 $n$ 步误差的平方成正比，就是二阶收敛的定义，前提是 $g''(r) \\neq 0$。“至少二阶”的条件要求 $g'(r)=0$。\n\n对于每个根 $r_k$，迭代函数为 $g_{k}(x) = x - \\alpha_{k} f(x)$。首先，我们确认每个根 $r_k$ 都是 $g_k(x)$ 的一个不动点。根据定义，$f(r_k) = 0$，所以 $g_{k}(r_{k}) = r_{k} - \\alpha_{k} f(r_{k}) = r_{k} - \\alpha_{k}(0) = r_{k}$。对于 $\\alpha_k$ 的任何选择，此条件都满足。\n\n为了确保至少是二阶收敛，我们必须强制满足条件 $g_{k}'(r_{k}) = 0$。我们首先计算 $g_{k}(x)$ 的导数：\n$$\ng_{k}'(x) = \\frac{d}{dx} \\left( x - \\alpha_{k} f(x) \\right) = 1 - \\alpha_{k} f'(x)\n$$\n在根 $r_k$ 处对此求值并令其为零，可得：\n$$\ng_{k}'(r_{k}) = 1 - \\alpha_{k} f'(r_{k}) = 0\n$$\n求解 $\\alpha_k$，我们发现所需的值为：\n$$\n\\alpha_{k} = \\frac{1}{f'(r_{k})}\n$$\n这假设 $f'(r_k) \\neq 0$，根据问题陈述，对于单根这是成立的。\n\n接下来，我们必须计算给定函数 $f(x) = x^{3} - 6x^{2} + 11x - 6$ 的导数：\n$$\nf'(x) = \\frac{d}{dx} \\left( x^{3} - 6x^{2} + 11x - 6 \\right) = 3x^{2} - 12x + 11\n$$\n现在我们可以为三个根中的每一个计算 $\\alpha_k$ 的值。\n\n对于根 $r_{1} = 1$：\n$$\nf'(1) = 3(1)^{2} - 12(1) + 11 = 3 - 12 + 11 = 2\n$$\n因此，参数 $\\alpha_{1}$ 是：\n$$\n\\alpha_{1} = \\frac{1}{f'(1)} = \\frac{1}{2}\n$$\n\n对于根 $r_{2} = 2$：\n$$\nf'(2) = 3(2)^{2} - 12(2) + 11 = 3(4) - 24 + 11 = 12 - 24 + 11 = -1\n$$\n因此，参数 $\\alpha_{2}$ 是：\n$$\n\\alpha_{2} = \\frac{1}{f'(2)} = \\frac{1}{-1} = -1\n$$\n\n对于根 $r_{3} = 3$：\n$$\nf'(3) = 3(3)^{2} - 12(3) + 11 = 3(9) - 36 + 11 = 27 - 36 + 11 = 2\n$$\n因此，参数 $\\alpha_{3}$ 是：\n$$\n\\alpha_{3} = \\frac{1}{f'(3)} = \\frac{1}{2}\n$$\n\n最后，问题要求计算总和 $S = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}$：\n$$\nS = \\frac{1}{2} + (-1) + \\frac{1}{2} = 1 - 1 = 0\n$$\n$S$ 的值恰好为 $0$。",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "在掌握了如何构造二次收敛的迭代法之后，一个自然的问题是：我们能否设计出收敛更快的算法？本练习将带你探索三阶收敛方法（即哈雷方法）的构建。通过满足更高阶的收敛条件，你将实现一个收敛速度远超牛顿法的迭代格式，从而加深对收敛阶理论的理解 。",
            "id": "2394865",
            "problem": "你的任务是构造并应用一个具有三次收敛性的不动点迭代格式，以近似求解一个非线性方程的实根。设一个实值函数表示为 $f(x)$，其中 $x \\in \\mathbb{R}$。不动点迭代是形如 $x_{n+1} = g(x_n)$ 的任意映射，其中 $g(x)$ 是某个函数。你的任务是设计一个函数 $g(x)$，使其产生一个局部收敛阶为 $3$ 的不动点迭代，用于在根为单根时求解 $f(x) = 0$，然后将其应用于下面的测试套件。\n\n为保证正确性和收敛性分析，假设：函数 $f$ 在所求根 $\\alpha$ 的一个邻域内至少三阶连续可微，且满足 $f(\\alpha) = 0$ 和 $f'(\\alpha) \\neq 0$。\n\n终止条件：当 $|f(x_n)| \\leq 10^{-12}$ 或 $|x_{n+1} - x_n| \\leq 10^{-12}$ 满足其一，或迭代最多 $50$ 次后，你的迭代必须停止，以先发生者为准。如果你的迭代达到了最大迭代次数而未满足精度阈值，则返回最后得到的迭代值。\n\n在所有三角函数和指数函数的求值中，角度必须使用弧度制。\n\n测试套件：对每种情况，使用指定的 $f(x)$ 及其解析导数 $f'(x)$ 和 $f''(x)$、给定的初始猜测值 $x_0$ 以及上述终止条件。\n- 情况 1（“顺利路径”）：$f_1(x) = \\cos(x) - x$，$f_1'(x) = -\\sin(x) - 1$，$f_1''(x) = -\\cos(x)$，初始值 $x_0 = 0.5$。\n- 情况 2（初始猜测值较远）：$f_2(x) = x^3 - 2$，$f_2'(x) = 3 x^2$，$f_2''(x) = 6 x$，初始值 $x_0 = 10.0$。\n- 情况 3（中度非线性）：$f_3(x) = e^x - 3 x$，$f_3'(x) = e^x - 3$，$f_3''(x) = e^x$，初始值 $x_0 = 0.0$。\n\n数值输出要求：你的程序必须为每种情况计算一个满足终止条件的近似根，然后将所有三个近似值以逗号分隔的列表形式单行输出，并用方括号括起来。每个近似值必须四舍五入到 $10$ 位小数。例如，你的输出格式必须严格遵循\n$[r_1,r_2,r_3]$\n的形式，其中每个 $r_k$ 是一个小数点后恰好有 $10$ 位数字的十进制数。\n\n你的程序不得读取任何输入。它必须按指定格式精确地输出一行，其中包含按上述顺序列出的三种情况的结果。",
            "solution": "该问题要求构造并应用一个具有三阶（立方）收敛速度的不动点迭代格式 $x_{n+1} = g(x_n)$，用于寻找非线性方程 $f(x)=0$ 的一个单根 $\\alpha$。单根由条件 $f(\\alpha)=0$ 和 $f'(\\alpha) \\neq 0$ 定义。\n\n首先，我们必须推导迭代函数 $g(x)$。不动点方法的收敛阶由迭代函数 $g(x)$ 在不动点 $\\alpha$ 处的导数决定。为实现三次收敛，我们要求 $g(\\alpha)=\\alpha$，并且它的一阶和二阶导数在根处为零，而三阶导数不为零：\n$$g'(\\alpha) = 0$$\n$$g''(\\alpha) = 0$$\n$$g'''(\\alpha) \\neq 0$$\n\n一个著名的高阶求根方法族是 Householder 方法。具有三阶收敛性的方法通常被称为 Halley 方法。我们可以通过考虑 $f(x)$ 在当前迭代值 $x_n$ 附近的泰勒级数展开，并保留到二阶项来近似校正步 $\\delta_n = x_{n+1} - x_n$，从而推导出其公式。\n根 $\\alpha$ 满足 $f(\\alpha)=0$。将 $f$ 在 $x_n$ 附近展开：\n$$f(\\alpha) = 0 \\approx f(x_n) + f'(x_n)(\\alpha - x_n) + \\frac{f''(x_n)}{2}(\\alpha - x_n)^2$$\n令 $\\delta = \\alpha - x_n$。该方程变为关于 $\\delta$ 的二次方程：\n$$f(x_n) + f'(x_n)\\delta + \\frac{f''(x_n)}{2}\\delta^2 \\approx 0$$\n为了获得 $\\delta$ 的更精确近似，我们可以将来自牛顿法的一阶近似 $\\delta \\approx -f(x_n)/f'(x_n)$ 代入二阶项中：\n$$f(x_n) + f'(x_n)\\delta + \\frac{f''(x_n)}{2} \\left( -\\frac{f(x_n)}{f'(x_n)} \\right)^2 \\approx 0$$\n解出 $\\delta$：\n$$f'(x_n)\\delta \\approx -f(x_n) - \\frac{f''(x_n) [f(x_n)]^2}{2 [f'(x_n)]^2}$$\n$$\\delta \\approx -\\frac{f(x_n)}{f'(x_n)} - \\frac{f''(x_n) [f(x_n)]^2}{2 [f'(x_n)]^3}$$\n这就产生了一个迭代公式。然而，一个更常用且数值上更稳定的形式，即 Halley 方法，是通过将泰勒展开重写为 $\\delta$ 的近似式来推导的：\n$$f'(x_n)\\delta \\approx -f(x_n) - \\frac{f''(x_n)}{2}\\delta^2$$\n两边同除以 $f'(x_n)$ 得到 $\\delta \\approx -\\frac{f(x_n)}{f'(x_n)} - \\frac{f''(x_n)}{2f'(x_n)}\\delta^2$。这是一个关于 $\\delta$ 的隐式方程。求解此方程的一种迭代方法是从 $\\delta_0=0$ 开始，计算 $\\delta_1 = -f(x_n)/f'(x_n)$（即牛顿步长）。然后 $\\delta_2 = \\frac{-f(x_n)}{f'(x_n) - \\frac{f''(x_n)}{2}\\delta_1}$。这是启发该结构形式的几种方法之一。\n\nHalley 迭代的标准形式是：\n$$x_{n+1} = x_n - \\frac{2 f(x_n) f'(x_n)}{2 [f'(x_n)]^2 - f(x_n) f''(x_n)}$$\n这定义了迭代函数 $g(x)$：\n$$g(x) = x - \\frac{2 f(x) f'(x)}{2 [f'(x)]^2 - f(x) f''(x)}$$\n通过对误差项 $\\epsilon_{n+1} = x_{n+1} - \\alpha$ 进行泰勒展开，可以正式证明该方法满足 $\\epsilon_{n+1} \\propto \\epsilon_n^3$，从而证实了对于单根，只要 $f$ 足够光滑（至少 $C^3$），它就具有三次收敛性。\n\n求解每个函数根的算法如下：\n1.  用 $n=0$ 和给定的初值 $x_0$ 初始化迭代。\n2.  对于 $n = 0, 1, 2, \\dots$，最多进行 $49$ 次迭代：\n    a. 设当前迭代值为 $x_n$。\n    b. 计算 $f(x_n)$、$f'(x_n)$ 和 $f''(x_n)$。\n    c. 检查第一个终止条件：如果 $|f(x_n)| \\leq 10^{-12}$，则迭代成功。结果为 $x_n$。终止。\n    d. 计算校正项的分母：$D_n = 2 [f'(x_n)]^2 - f(x_n) f''(x_n)$。如果 $D_n$ 接近于零，该方法可能会失败；然而，问题的假设排除了在单根附近出现这种情况。\n    e. 计算下一个迭代值：$x_{n+1} = x_n - \\frac{2 f(x_n) f'(x_n)}{D_n}$。\n    f. 检查第二个终止条件：如果 $|x_{n+1} - x_n| \\leq 10^{-12}$，则迭代成功。结果为 $x_{n+1}$。终止。\n    g. 设置 $x_n \\leftarrow x_{n+1}$，为下一次迭代更新。\n3.  如果循环在 $50$ 次迭代后（$n=49$ 是计算 $x_{50}$ 的最后一步）仍未满足任一终止条件，则过程停止。结果为最后计算的迭代值 $x_{50}$。\n\n将此过程应用于问题陈述中指定的三个测试用例。按要求，最终的数值结果四舍五入到 $10$ 位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and applies a cubically convergent fixed-point iteration scheme (Halley's method)\n    to find the roots of three specified nonlinear equations.\n    \"\"\"\n\n    def solve_with_halley(f, fp, fpp, x0, tol=1e-12, max_iter=50):\n        \"\"\"\n        Applies Halley's method to find a root of f(x)=0.\n\n        Args:\n            f: The function f(x).\n            fp: The first derivative f'(x).\n            fpp: The second derivative f''(x).\n            x0: The initial guess.\n            tol: The tolerance for termination.\n            max_iter: The maximum number of iterations.\n\n        Returns:\n            The approximate root.\n        \"\"\"\n        x_n = float(x0)\n\n        for _ in range(max_iter):\n            f_val = f(x_n)\n            \n            # Termination criterion 1: |f(x_n)| = tol\n            if abs(f_val) = tol:\n                return x_n\n\n            fp_val = fp(x_n)\n            fpp_val = fpp(x_n)\n\n            # Denominator of Halley's method correction term\n            denominator = 2.0 * fp_val**2 - f_val * fpp_val\n\n            # Prevent division by zero, though unlikely for these problems\n            if abs(denominator)  1e-15:\n                # Method fails, return the last valid iterate\n                return x_n\n\n            # Halley's iteration formula\n            x_n_plus_1 = x_n - (2.0 * f_val * fp_val) / denominator\n\n            # Termination criterion 2: |x_{n+1} - x_n| = tol\n            if abs(x_n_plus_1 - x_n) = tol:\n                return x_n_plus_1\n\n            x_n = x_n_plus_1\n        \n        # Return the last iterate if max_iter is reached\n        return x_n\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"f\": lambda x: np.cos(x) - x,\n            \"fp\": lambda x: -np.sin(x) - 1.0,\n            \"fpp\": lambda x: -np.cos(x),\n            \"x0\": 0.5\n        },\n        {\n            \"f\": lambda x: x**3 - 2.0,\n            \"fp\": lambda x: 3.0 * x**2,\n            \"fpp\": lambda x: 6.0 * x,\n            \"x0\": 10.0\n        },\n        {\n            \"f\": lambda x: np.exp(x) - 3.0 * x,\n            \"fp\": lambda x: np.exp(x) - 3.0,\n            \"fpp\": lambda x: np.exp(x),\n            \"x0\": 0.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        root = solve_with_halley(\n            f=case[\"f\"],\n            fp=case[\"fp\"],\n            fpp=case[\"fpp\"],\n            x0=case[\"x0\"],\n            tol=1e-12,\n            max_iter=50\n        )\n        results.append(root)\n\n    # Format results to 10 decimal places and create the final output string.\n    formatted_results = [f\"{r:.10f}\" for r in results]\n    final_output = f\"[{','.join(formatted_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "高阶方法虽然收敛快，但通常需要计算函数的高阶导数，这在实践中可能非常复杂或耗时。当我们只有一个简单的线性收敛迭代序列时，我们该如何提高其效率？本练习将向你介绍一种强大的加速技术——艾特肯 (Aitken) $\\Delta^2$ 方法，它仅利用已生成的迭代点序列，就能显著加快收敛速度，展示了在不改变迭代格式本身的情况下优化计算过程的巧妙思路 。",
            "id": "2394839",
            "problem": "您的任务是构建并分析一个收敛到自然对数二（记为 $\\,\\ln(2)\\,$）的不动点迭代，然后使用 Aitken's delta-squared (记为 $\\Delta^2$) 方法加速其收敛。从方程 $\\,e^{x} = 2\\,$ 的不动点形式出发，这意味着某个映射 $\\,g(x)\\,$ 的不动点即为所求值 $\\,x^\\star = \\ln(2)\\,$。考虑由 $\\,\\lambda\\,$ 参数化的不动点迭代族：\n$$\ng_{\\lambda}(x) = x - \\lambda\\,(e^{x} - 2),\n$$\n以及迭代过程 $\\,x_{n+1} = g_{\\lambda}(x_n)\\,$ (其中 $\\,n \\ge 0\\,$)。假设在不动点 $\\,x^\\star\\,$ 附近的收缩条件成立，具体来说是 $\\,|g'_{\\lambda}(x^\\star)|  1\\,$，并利用此条件来证明线性误差行为，以此作为设计加速方法的起点。\n\n您的任务是：\n- 基于几何误差模型假设 $\\,s_n = s + C r^n\\,$ (其中 $\\,|r|1\\,$)，推导一个线性收敛序列 $\\,\\{s_n\\}\\,$ 的 Aitken's delta-squared ($\\Delta^2$) 加速公式。不要使用或引用任何预先推导好的加速公式；相反，您应通过消去无关参数，得到一个用三个连续迭代值表示的显式加速估计量。清晰地说明该变换良定的条件。\n- 设计一个鲁棒的算法，该算法能够：\n  1. 为映射 $\\,g_{\\lambda}(x)\\,$ 生成不动点序列 $\\,\\{x_n\\}\\,$。\n  2. 使用您推导的 $\\Delta^2$ 表达式，根据最后三个可用的迭代值形成一个加速估计。\n  3. 检测并安全地处理 $\\Delta^2$ 分母的绝对值趋近于零（例如，小于某个容差）的边界情况。在这种情况下，您的算法必须返回未加速的最新迭代值作为加速输出。\n  4. 通过绝对误差 $\\,|x - \\ln(2)|\\,$ 来量化精度，该误差是无单位的。最终输出中的所有误差值必须四舍五入到小数点后恰好 $\\,12\\,$ 位。\n\n实现要求：\n- 您必须实现一个完整、可运行的程序，对预设的测试套件执行上述步骤。不允许用户输入。\n- 对于每个测试用例，迭代必须精确运行 $\\,N+2\\,$ 步，以便可以使用最后三个迭代值 $\\,x_N, x_{N+1}, x_{N+2}\\,$ 来构造一个对应于索引 $\\,N\\,$ 的 $\\Delta^2$ 加速估计。\n- 对于每个测试用例，计算两个浮点数：\n  1. 使用 $\\,x_{N+2}\\,$ 的未加速估计的绝对误差。\n  2. 由 $\\,x_{N}, x_{N+1}, x_{N+2}\\,$ 构建的 $\\Delta^2$ 加速估计的绝对误差。\n- 最终输出格式：您的程序应生成一行输出，其中包含一个扁平列表中的所有结果，形式为方括号括起来的逗号分隔列表。各项必须严格按照以下顺序排列：\n  $$[E_{1,\\mathrm{plain}},E_{1,\\mathrm{acc}},E_{2,\\mathrm{plain}},E_{2,\\mathrm{acc}},E_{3,\\mathrm{plain}},E_{3,\\mathrm{acc}},E_{4,\\mathrm{plain}},E_{4,\\mathrm{acc}}],$$\n  其中 $\\,E_{i,\\mathrm{plain}}\\,$ 是测试 $\\,i\\,$ 的未加速绝对误差，$\\,E_{i,\\mathrm{acc}}\\,$ 是其加速后的绝对误差。每个条目必须四舍五入到小数点后恰好 $\\,12\\,$ 位。\n\n测试套件：\n- 使用 $\\,\\ln(2)\\,$ 作为参考值，由以弧度为单位的自然对数函数计算。\n- 使用以下 $\\,(\\lambda, x_0, N)\\,$ 三元组：\n  1. $\\,(\\,0.05,\\; 0.0,\\; 50\\,)\\,$\n  2. $\\,(\\,0.01,\\; 0.0,\\; 200\\,)\\,$\n  3. $\\,(\\,0.49,\\; 0.0,\\; 10\\,)\\,$\n  4. $\\,(\\,0.99,\\; 0.0,\\; 200\\,)\\,$\n\n科学和数值考量：\n- 从不动点收敛条件 $\\,|g'_{\\lambda}(x^\\star)|1\\,$ 出发，证明线性收敛并引出几何误差模型，然后从第一性原理出发，通过消去未知数来推导加速规则。\n- 此问题不涉及物理单位。当涉及指数和对数函数时，根据自然对数和指数的定义，所有角度（若相关）均以弧度为单位。\n- 通过为 $\\Delta^2$ 分母检查引入一个小的正容差 $\\,\\tau\\,$ (例如，$\\,\\tau = 10^{-14}\\,$ 是一个可接受的值)，确保您的算法数值稳定。\n\n您的最终程序必须计算并按上述确切格式打印出所需的单行输出。",
            "solution": "经审阅，该问题是数值分析中关于迭代法的标准练习。它有效、自洽，并拥有唯一且明确的求解路径。我们将着手进行所需的推导和算法构建。\n\n问题在于求解方程 $f(x) = e^x - 2 = 0$ 的根，即 $x^\\star = \\ln(2)$。我们给定一个不动点映射族：\n$$\ng_{\\lambda}(x) = x - \\lambda(e^x - 2)\n$$\n迭代序列定义为 $x_{n+1} = g_{\\lambda}(x_n)$，其中 $n \\ge 0$。该映射的不动点 $x^\\star$ 满足 $x^\\star = g_{\\lambda}(x^\\star)$，这意味着 $x^\\star = x^\\star - \\lambda(e^{x^\\star} - 2)$，因此 $e^{x^\\star} - 2 = 0$。只要 $\\lambda \\neq 0$，$g_{\\lambda}(x)$ 的不动点确实是 $f(x)$ 的根。\n\n为使迭代收敛到不动点 $x^\\star$，映射 $g_{\\lambda}(x)$ 必须在 $x^\\star$ 的一个邻域内是收缩的。收敛条件由压缩映射定理给出，该定理要求 $|g'_{\\lambda}(x^\\star)|  1$。$g_{\\lambda}(x)$ 的导数是：\n$$\ng'_{\\lambda}(x) = \\frac{d}{dx} \\left( x - \\lambda(e^x - 2) \\right) = 1 - \\lambda e^x\n$$\n在不动点 $x^\\star = \\ln(2)$ 处计算此导数：\n$$\ng'_{\\lambda}(x^\\star) = 1 - \\lambda e^{\\ln(2)} = 1 - 2\\lambda\n$$\n因此，收敛条件是 $|1 - 2\\lambda|  1$。这个不等式等价于 $-1  1 - 2\\lambda  1$，化简后得到 $-2  -2\\lambda  0$。两边同除以 $-2$ 并反转不等号，得到 $0  \\lambda  1$。所有提供的测试用例都使用了此范围内的 $\\lambda$ 值，确保了收敛性。\n\n当 $g'_{\\lambda}(x^\\star) \\neq 0$ 时，收敛是线性的。第 $n+1$ 步的误差（记为 $e_{n+1} = x_{n+1} - x^\\star$）与第 $n$ 步的误差（$e_n = x_n - x^\\star$）通过 $g_{\\lambda}(x_n)$ 在 $x^\\star$ 周围的泰勒展开相关联：\n$$\nx_{n+1} = g_{\\lambda}(x_n) \\approx g_{\\lambda}(x^\\star) + g'_{\\lambda}(x^\\star)(x_n - x^\\star)\n$$\n$$\nx_{n+1} - x^\\star \\approx g'_{\\lambda}(x^\\star)(x_n - x^\\star) \\implies e_{n+1} \\approx r \\cdot e_n\n$$\n其中 $r = g'_{\\lambda}(x^\\star) = 1 - 2\\lambda$ 是渐进收敛率。这个关系意味着对于大的 $n$，误差呈几何级数行为：$e_n \\approx C r^n$（其中 $C$ 为某个常数）。这证明了作为 Aitken's $\\Delta^2$ 方法基础的几何误差模型的合理性。\n\n现在我们来推导 Aitken's $\\Delta^2$ 加速公式。设序列 $\\{s_n\\}$ 收敛于极限 $s$。对于大的 $n$，我们将序列建模为：\n$$\ns_n = s + C r^n, \\quad |r|1\n$$\n我们为三个连续项 $s_n$, $s_{n+1}$, 和 $s_{n+2}$ 写出这个模型：\n$$\ns_n - s = C r^n \\quad (1)\n$$\n$$\ns_{n+1} - s = C r^{n+1} \\quad (2)\n$$\n$$\ns_{n+2} - s = C r^{n+2} \\quad (3)\n$$\n我们的目标是消去未知参数 $C$ 和 $r$，以找到对 $s$ 的改进估计。我们引入前向差分算子 $\\Delta s_k = s_{k+1} - s_k$。\n$$\n\\Delta s_n = s_{n+1} - s_n = (s_{n+1} - s) - (s_n - s) = C r^{n+1} - C r^n = C r^n (r - 1)\n$$\n$$\n\\Delta s_{n+1} = s_{n+2} - s_{n+1} = (s_{n+2} - s) - (s_{n+1} - s) = C r^{n+2} - C r^{n+1} = C r^{n+1} (r - 1)\n$$\n对这些差分求比值可以消去 $C$：\n$$\n\\frac{\\Delta s_{n+1}}{\\Delta s_n} = \\frac{C r^{n+1} (r - 1)}{C r^n (r - 1)} = r\n$$\n这提供了一个对收敛率 $r$ 的估计。现在，根据方程 $(1)$ 和 $(2)$，我们有 $s_{n+1} - s = r(s_n - s)$。代入我们对 $r$ 的表达式：\n$$\ns_{n+1} - s = \\left(\\frac{s_{n+2} - s_{n+1}}{s_{n+1} - s_n}\\right) (s_n - s)\n$$\n这是一个关于未知极限 $s$ 的方程。我们求解 $s$：\n$$\n(s_{n+1} - s)(s_{n+1} - s_n) = (s_{n+2} - s_{n+1})(s_n - s)\n$$\n$$\ns_{n+1}(s_{n+1} - s_n) - s(s_{n+1} - s_n) = s_n(s_{n+2} - s_{n+1}) - s(s_{n+2} - s_{n+1})\n$$\n$$\ns \\left( (s_{n+2} - s_{n+1}) - (s_{n+1} - s_n) \\right) = s_n(s_{n+2} - s_{n+1}) - s_{n+1}(s_{n+1} - s_n)\n$$\n$$\ns (s_{n+2} - 2s_{n+1} + s_n) = s_n s_{n+2} - s_n s_{n+1} - s_{n+1}^2 + s_n s_{n+1} = s_n s_{n+2} - s_{n+1}^2\n$$\n如果分母非零，对 $s$ 的加速估计为：\n$$\ns = \\frac{s_n s_{n+2} - s_{n+1}^2}{s_{n+2} - 2s_{n+1} + s_n}\n$$\n如果 $s_n$很大，这个公式容易出现相消误差。通过改写可以得到一个数值上更稳健的形式：\n$$\ns = s_n - \\frac{(s_{n+1} - s_n)^2}{s_{n+2} - 2s_{n+1} + s_n} = s_n - \\frac{(\\Delta s_n)^2}{\\Delta^2 s_n}\n$$\n其中 $\\Delta^2 s_n = \\Delta(\\Delta s_n) = \\Delta s_{n+1} - \\Delta s_n$ 是二阶前向差分。这就是 Aitken's $\\Delta^2$ 公式。我们通过令 $s_k = x_k$ 将此公式应用于序列 $\\{x_n\\}$。我们记加速后的估计为 $x'_{N}$，它由迭代值 $x_N$、$x_{N+1}$ 和 $x_{N+2}$ 构成：\n$$\nx'_{N} = x_N - \\frac{(x_{N+1} - x_N)^2}{x_{N+2} - 2x_{N+1} + x_N}\n$$\n当且仅当分母 $x_{N+2} - 2x_{N+1} + x_N \\neq 0$ 时，这个表达式是良定的。在浮点运算中，我们必须检查分母的绝对值是否小于某个容差 $\\tau > 0$，例如 $\\tau = 10^{-14}$。如果 $|x_{N+2} - 2x_{N+1} + x_N|  \\tau$，则该变换数值不稳定或病态，我们将返回最新的未加速迭代值 $x_{N+2}$作为结果。\n\n算法如下：\n对于每个给定的测试用例 $(\\lambda, x_0, N)$：\n1. 设定固定参考值 $x^\\star = \\ln(2)$。\n2. 用 $x_0$ 初始化迭代序列。\n3. 使用映射 $x_{n+1} = x_n - \\lambda(e^{x_n} - 2)$ 生成后续的 $N+2$ 个迭代值 $x_1, \\dots, x_{N+2}$。存储所有迭代值直到 $x_{N+2}$。\n4. 计算未加速的绝对误差：$E_{\\mathrm{plain}} = |x_{N+2} - x^\\star|$。\n5. 获取加速所需的最后三个迭代值：$x_N, x_{N+1}, x_{N+2}$。\n6. 计算 Aitken 公式的分母：$d = x_{N+2} - 2x_{N+1} + x_N$。\n7. 如果 $|d|  10^{-14}$，则设置加速估计 $x_{\\mathrm{acc}} = x_{N+2}$。\n8. 否则，计算加速估计 $x_{\\mathrm{acc}} = x_N - (x_{N+1} - x_N)^2 / d$。\n9. 计算加速后的绝对误差：$E_{\\mathrm{acc}} = |x_{\\mathrm{acc}} - x^\\star|$。\n10. 将两个误差值 $E_{\\mathrm{plain}}$ 和 $E_{\\mathrm{acc}}$ 四舍五入到小数点后12位并存储。\n最后，将所有测试用例计算出的所有误差值编译成一个单一的扁平列表，并以指定格式打印。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and analyzes a fixed-point iteration for ln(2), accelerates it\n    using Aitken's delta-squared method, and computes the errors for a suite\n    of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (lambda, x0, N)\n        (0.05, 0.0, 50),\n        (0.01, 0.0, 200),\n        (0.49, 0.0, 10),\n        (0.99, 0.0, 200),\n    ]\n\n    # The exact value of the fixed point, ln(2)\n    x_star = np.log(2)\n    \n    # Tolerance for the denominator in Aitken's formula\n    tau = 1.0e-14\n\n    results = []\n    \n    for case in test_cases:\n        lambda_val, x0, N = case\n        \n        # 1. Generate the fixed-point sequence {x_n}\n        # We need N+3 points in the sequence (x_0, x_1, ..., x_{N+2})\n        # This requires N+2 iteration steps.\n        iterates = [x0]\n        current_x = x0\n        for _ in range(N + 2):\n            # Fixed-point iteration: x_{n+1} = g(x_n) = x_n - lambda * (exp(x_n) - 2)\n            current_x = current_x - lambda_val * (np.exp(current_x) - 2)\n            iterates.append(current_x)\n            \n        # The last three iterates for acceleration are x_N, x_{N+1}, x_{N+2}\n        x_N = iterates[N]\n        x_N_plus_1 = iterates[N + 1]\n        x_N_plus_2 = iterates[N + 2]\n        \n        # 2. Compute the absolute error of the unaccelerated estimate\n        # The latest unaccelerated estimate is x_{N+2}\n        error_plain = abs(x_N_plus_2 - x_star)\n        \n        # 3. Form the accelerated estimate using Aitken's delta-squared method\n        denominator = x_N_plus_2 - 2 * x_N_plus_1 + x_N\n        \n        # 4. Detect and handle the edge case of a small denominator\n        if abs(denominator)  tau:\n            # If denominator is too small, use the unaccelerated estimate\n            x_accelerated = x_N_plus_2\n        else:\n            numerator = (x_N_plus_1 - x_N)**2\n            x_accelerated = x_N - numerator / denominator\n            \n        # 5. Compute the absolute error of the accelerated estimate\n        error_accelerated = abs(x_accelerated - x_star)\n        \n        # 6. Format results to exactly 12 decimal places\n        results.append(f\"{error_plain:.12f}\")\n        results.append(f\"{error_accelerated:.12f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}