{
    "hands_on_practices": [
        {
            "introduction": "要真正理解一个算法，最好的方法莫过于亲手执行一次。这个练习将引导你手动追踪一个自适应求积算法的每一步，让你直观地感受其递归逻辑和决策过程。通过计算一个简单的积分，你将清晰地看到算法是如何通过细分区间来逐步逼近并满足预设的误差容限的 。",
            "id": "2153105",
            "problem": "自适应求积算法通过细化其计算网格以满足所需的误差容限。考虑以下递归算法，旨在逼近定积分 $I = \\int_a^b f(x) \\,dx$。\n\n**自适应积分算法：**\n函数 `AdaptiveIntegrate(f, a, b, ε)` 将一个函数 $f$、一个区间 $[a, b]$ 和一个容限 $\\epsilon$ 作为输入。\n\n1.  计算 $S_1$，即使用宽度为 $h_1 = b-a$ 的单个区间通过梯形法则得到的近似值。其公式为 $S_1 = \\frac{h_1}{2}(f(a) + f(b))$。\n2.  令 $c = (a+b)/2$ 为区间的中点。计算 $S_2$，即使用两个子区间 $[a, c]$ 和 $[c, b]$（每个区间的宽度为 $h_2 = (b-a)/2$）通过复合梯形法则得到的近似值。其公式为 $S_2 = \\frac{h_2}{2}(f(a) + f(c)) + \\frac{h_2}{2}(f(c) + f(b))$。\n3.  更精确的近似值 $S_2$ 的误差估计基于两个近似值之间的差异。停止准则为 $|S_2 - S_1| \\le 3\\epsilon$。\n4.  如果满足该准则，则此区间的过程终止并返回值 $S_2$。\n5.  如果不满足该准则，算法将细化该区间。它在两个子区间上递归调用自身，并将每个子区间的容限减半。区间 $[a, b]$ 的结果是这两个调用的结果之和：\n    `AdaptiveIntegrate(f, a, c, ε/2) + AdaptiveIntegrate(f, c, b, ε/2)`\n\n你的任务是手动追踪此算法，以求出积分\n$$ I = \\int_0^4 x^2 \\,dx $$\n的数值近似值，初始容限为 $\\epsilon = 2$。\n\n计算算法返回的积分的最终数值近似值。以精确整数或分数形式给出你的答案。",
            "solution": "我们将给定的自适应梯形算法应用于函数 $f(x)=x^{2}$ 在区间 $[0,4]$ 上，初始容限为 $\\epsilon=2$。在 $[a,b]$ 上使用一个区间的梯形近似值为 $S_{1}=\\frac{h_{1}}{2}\\left(f(a)+f(b)\\right)$，其中 $h_{1}=b-a$，使用两个区间的梯形近似值为\n$$\nS_{2}=\\frac{h_{2}}{2}\\left(f(a)+f(c)\\right)+\\frac{h_{2}}{2}\\left(f(c)+f(b)\\right),\n$$\n其中 $c=\\frac{a+b}{2}$ 且 $h_{2}=\\frac{b-a}{2}$。一个区间的停止准则是 $|S_{2}-S_{1}| \\le 3\\epsilon$。如果不满足该准则，我们对 $[a,c]$ 和 $[c,b]$ 进行递归，每个子区间的容限为 $\\epsilon/2$，并将返回的值相加。\n\n顶层区间 $[0,4]$，容限 $\\epsilon=2$：\n- 计算 $h_{1}=4$， $S_{1}=\\frac{4}{2}\\left(f(0)+f(4)\\right)=2\\left(0+16\\right)=32$。\n- 中点 $c=2$， $h_{2}=2$，且\n$$\nS_{2}=\\frac{2}{2}\\left(f(0)+f(2)\\right)+\\frac{2}{2}\\left(f(2)+f(4)\\right)=1\\left(0+4\\right)+1\\left(4+16\\right)=4+20=24.\n$$\n- 误差检查：$|S_{2}-S_{1}| = |24-32|=8$，而 $3\\epsilon=3\\cdot 2=6$。由于 $8 \\not\\le 6$，我们对 $[0,2]$ 和 $[2,4]$ 进行递归，每个子区间的容限为 $\\epsilon/2=1$。\n\n子区间 $[0,2]$，容限 $\\epsilon=1$：\n- 计算 $h_{1}=2$, $S_{1}=\\frac{2}{2}\\left(f(0)+f(2)\\right)=1\\left(0+4\\right)=4$。\n- 中点 $c=1$, $h_{2}=1$, 且\n$$\nS_{2}=\\frac{1}{2}\\left(f(0)+f(1)\\right)+\\frac{1}{2}\\left(f(1)+f(2)\\right)=\\frac{1}{2}\\left(0+1\\right)+\\frac{1}{2}\\left(1+4\\right)=\\frac{1}{2}+\\frac{5}{2}=3.\n$$\n- 误差检查：$|S_{2}-S_{1}|=|3-4|=1$，而 $3\\epsilon=3\\cdot 1=3$。由于 $1 \\le 3$，接受 $[0,2]$ 上的 $S_{2}=3$。\n\n子区间 $[2,4]$，容限 $\\epsilon=1$：\n- 计算 $h_{1}=2$, $S_{1}=\\frac{2}{2}\\left(f(2)+f(4)\\right)=1\\left(4+16\\right)=20$。\n- 中点 $c=3$, $h_{2}=1$, 且\n$$\nS_{2}=\\frac{1}{2}\\left(f(2)+f(3)\\right)+\\frac{1}{2}\\left(f(3)+f(4)\\right)=\\frac{1}{2}\\left(4+9\\right)+\\frac{1}{2}\\left(9+16\\right)=\\frac{13}{2}+\\frac{25}{2}=19.\n$$\n- 误差检查：$|S_{2}-S_{1}|=|19-20|=1$，而 $3\\epsilon=3$。由于 $1 \\le 3$，接受 $[2,4]$ 上的 $S_{2}=19$。\n\n最后，顶层调用返回接受的子区间结果之和：\n$$\n\\text{结果} = 3+19=22.\n$$\n这就是算法返回的最终数值近似值。",
            "answer": "$$\\boxed{22}$$"
        },
        {
            "introduction": "在了解了算法的运作机制后，我们来探讨其背后的理论依据。这个练习旨在阐明为什么自适应方法对特定类型的函数（例如低阶多项式）表现得如此高效甚至精确。通过将算法的终止条件与辛普森法则的误差公式联系起来，你将发现高阶导数在决定数值积分效率和准确性中的关键作用 。",
            "id": "2153099",
            "problem": "一个自适应求积算法旨在将函数 $f(x)$ 在区间 $[a, b]$ 上的定积分近似到指定的容差 $\\epsilon$ 以内。该算法递归地运行。它首先使用一个固定的求积法则计算在 $[a, b]$ 上的积分近似值。然后，它估计这个近似的误差。如果估计误差小于 $\\epsilon$，则接受该值。如果误差太大，则将区间 $[a, b]$ 分成两个子区间，并对每个子区间以 $\\epsilon/2$ 的容差应用该算法。\n\n考虑一个使用辛普森法则作为其核心求积方法的特定算法实现。在宽度为 $2h$ 的区间上单次应用辛普森法则的误差由公式 $E = - \\frac{h^5}{90} f^{(4)}(\\xi)$ 给出，其中 $f^{(4)}$ 是函数 $f$ 的四阶导数，$\\xi$ 是积分区间内的某个点。该算法的误差估计基于这种潜在的误差行为。\n\n一名学生使用这种自适应辛普森法则算法，在一个小的正容差下，对几个不同的函数在区间 $[0, 2]$ 上进行积分。对于下列哪种函数类型，该算法最有可能以最少的所需子划分次数终止，并且这种最佳性能背后的数学原因是什么？\n\nA. 一个具有尖峰的函数，如对于一个大常数 $k$ 的高斯函数 $f(x) = \\exp(-k(x-1)^2)$，因为该函数关于区间中点对称。\nB. 一个高度振荡的函数，如 $f(x) = \\cos(50\\pi x)$，因为函数的正负波瓣相互抵消，导致积分值很小。\nC. 一个3次或更低次的多项式函数，如 $f(x) = x^3 - 2x^2 + 5x - 1$，因为控制辛普森法则误差项的四阶导数恒等于零。\nD. 一个指数函数，如 $f(x) = \\exp(x)$，因为它的泰勒级数是众所周知的并且处处收敛，使其易于近似。\nE. 一个包含分数次幂的函数，如 $f(x) = \\sqrt{x}$，因为它的值在区间开始附近变化缓慢。",
            "solution": "当估计的局部误差低于容差时，自适应算法会接受一个区间。对于在宽度为 $2h$ 的区间上应用的辛普森法则，其截断误差具有以下形式\n$$\nE=-\\frac{h^{5}}{90}\\,f^{(4)}(\\xi)\n$$\n其中 $\\xi$ 在区间内。因此，对于给定的 $h$，局部误差的大小与 $|f^{(4)}(\\xi)|$ 成比例。\n\n辛普森法则对于所有最高3次的多项式都是精确的。这可以从误差项直接得出：如果在 $[a,b]$ 中对所有 $x$ 都有 $f^{(4)}(x)\\equiv 0$，那么对于每个子区间 $E=0$，因此辛普森近似在任何区间上都等于精确积分，无需任何子划分。具体来说，如果 $p(x)=ax^{3}+bx^{2}+cx+d$，那么\n$$\np^{(4)}(x)=0\\quad\\text{for all }x,\n$$\n所以\n$$\nE=-\\frac{h^{5}}{90}\\,p^{(4)}(\\xi)=0,\n$$\n因此自适应算法的误差估计恒等于零，这小于任何给定的正容差 $\\epsilon$。因此，该算法会以最少可能的子划分次数（实际上没有）立即终止。\n\n相比之下，其他选项不会产生零四阶导数，因此在单个子区间上不具备精确性：\n- 对于大 $k$ 的 $f(x)=\\exp(-k(x-1)^{2})$，重复求导会引入因子 $k$ 和关于 $k(x-1)$ 的多项式；特别地， $|f^{(4)}(x)|$ 的量级为 $k^{2}$ （带有一个 $\\exp(-k(x-1)^{2})$ 因子），所以在峰值附近 $|f^{(4)}|$ 很大，除非 $h$ 非常小，否则误差 $|E|$ 也很大；需要许多子划分。\n- 对于 $\\omega=50\\pi$ 的 $f(x)=\\cos(\\omega x)$，我们有\n$$\nf^{(4)}(x)=\\omega^{4}\\cos(\\omega x),\n$$\n所以 $|f^{(4)}(x)|=\\omega^{4}$ 并且局部误差与 $\\omega^{4}h^{5}$ 成比例。大的 $\\omega$ 迫使 $h$ 很小；积分值中正负波瓣的抵消不会减少控制自适应性的局部误差。\n- 对于 $f(x)=\\exp(x)$， $f^{(4)}(x)=\\exp(x)$，它在 $[0,2]$ 上是正且非零的，所以辛普森法则不是精确的，算法必须进行子划分以满足小的容差。\n- 对于 $f(x)=\\sqrt{x}=x^{1/2}$，求导得出\n$$\nf^{(4)}(x)=-\\frac{15}{16}x^{-7/2},\n$$\n当 $x\\to 0^{+}$ 时，该式是无界的。这会在 $0$ 附近产生大的局部误差，并迫使进行许多子划分。\n\n因此，导致所需子划分次数最少（实际上为零）的函数类别是最高3次的多项式，因为当 $f^{(4)}\\equiv 0$ 时，辛普森法则的控制误差项恒为零。",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "前面的练习揭示了当被积函数的四阶导数为零时的理想情况。那么，当四阶导数不为零且在积分域上发生变化时，算法会如何应对呢？这个问题深入探讨了“自适应”的精髓，它要求你分析算法如何根据函数局部“平滑度”（由四阶导数的大小反映）来智能地分配计算资源，即在函数变化剧烈的区域使用更密的网格 。",
            "id": "2153092",
            "problem": "一个基于辛普森(Simpson)法则的自适应求积算法被用来数值计算函数 $f(x)$ 在区间 $[A, B]$ 上的积分。该算法递归地工作。对于任意给定的子区间 $[a, b]$，它会计算积分的两种近似值：一个粗略近似值 $S_{coarse}$，通过在 $[a, b]$ 上单次应用辛普森法则得到；以及一个更精细的近似值 $S_{fine}$，通过将辛普森法则分别应用于两个半区间 $[a, (a+b)/2]$ 和 $[(a+b)/2, b]$ 后的结果相加得到。\n\n该算法将精细近似值的误差估计为 $E_{est} = \\frac{1}{15} |S_{fine} - S_{coarse}|$。如果这个估计误差小于局部容差 $\\epsilon_{local}$，算法就接受 $S_{fine}$ 作为区间 $[a, b]$ 上的结果，并终止该分支的计算。否则，算法将递归地应用于这两个子区间，每个新的子区间的局部容差为当前局部容差的一半。整个区间 $[A, B]$ 的初始局部容差是一个用户定义的全局容差 $\\epsilon_{global}$。\n\n已知辛普森法则在宽度为 $h$ 的区间上的真实误差近似为 $E_{true} \\approx C h^5 f^{(4)}(\\xi)$，其中 $\\xi$ 是该区间内的某一点，$C$ 是一个常数，$f^{(4)}$ 是函数的四阶导数。对于一个足够光滑的函数，误差估计 $E_{est}$ 是 $S_{fine}$ 的真实误差的一个良好近似。\n\n考虑一个定义在区间 $[0, L]$ 上的函数 $f(x)$，其直到三阶的导数都是连续的。它的四阶导数 $f^{(4)}(x)$ 是分段常数，在 $x=c$（其中 $0  c  L$）处有一个跳跃间断点。具体来说，\n$$\nf^{(4)}(x) = \\begin{cases} K_1  \\text{if } 0 \\le x \\le c \\\\ K_2  \\text{if } c  x \\le L \\end{cases}\n$$\n其中 $K_1$ 和 $K_2$ 是给定的正常数。\n\n该自适应算法以一个非常小的全局容差 $\\epsilon_{global}$ 运行，导致区间 $[0, L]$ 被精细划分为许多终点子区间。在 $\\epsilon_{global} \\to 0$ 的极限情况下，这些子区间的宽度变得非常小。设 $h_L$ 为恰好在间断点左侧（即 $x=c^-$）的无穷小区域内终点子区间的特征宽度，设 $h_R$ 为恰好在间断点右侧（即 $x=c^+$）的无穷小区域内终点子区间的特征宽度。\n\n确定比值 $h_L / h_R$。请用 $K_1$ 和 $K_2$ 将你的答案表示为一个闭式解析表达式。",
            "solution": "在宽度为 $h$ 的区间上，单区间辛普森法则的局部截断误差为 $E_{true} \\approx C h^{5} f^{(4)}(\\xi)$，其中 $C$ 是一个常数，$\\xi$ 位于该区间内。当 $f^{(4)}$ 在区间上为常数时，基于 $S_{fine}$ 和 $S_{coarse}$ 的自适应估计量具有相同的 $h^{5}$ 缩放关系，且仅相差一个常数因子，因此我们可以将这样一个子区间上的估计误差写为\n$$\nE_{est} \\approx D\\,K\\,h^{5},\n$$\n其中 $K$ 是 $f^{(4)}$ 在该子区间上的值，$D>0$ 是一个仅取决于辛普森误差常数和细化过程的常数。\n\n在自适应算法中，一个位于递归深度 $d$ 的区间 $[a,b]$ 具有：\n- 宽度 $h = b-a = L\\,2^{-d}$，因为每次细化都会将区间长度减半；\n- 局部容差 $\\epsilon_{local} = \\epsilon_{global}\\,2^{-d}$，因为每次细化都会将容差减半。\n\n当估计误差满足局部容差时（渐近地），接受条件成立，即\n$$\nD\\,K\\,h^{5} = \\epsilon_{local}.\n$$\n代入 $h = L\\,2^{-d}$ 和 $\\epsilon_{local} = \\epsilon_{global}\\,2^{-d}$ 得到\n$$\nD\\,K\\,(L\\,2^{-d})^{5} = \\epsilon_{global}\\,2^{-d}\n\\;\\;\\Longrightarrow\\;\\;\nD\\,K\\,L^{5}\\,2^{-5d} = \\epsilon_{global}\\,2^{-d}\n\\;\\;\\Longrightarrow\\;\\;\nD\\,K\\,L^{5}\\,2^{-4d} = \\epsilon_{global}.\n$$\n解出 $2^{-d}$ 可得\n$$\n2^{-d} = \\left(\\frac{\\epsilon_{global}}{D\\,K\\,L^{5}}\\right)^{\\frac{1}{4}}.\n$$\n因此，在 $f^{(4)} \\equiv K$ 的一侧，终点宽度为\n$$\nh = L\\,2^{-d} = L\\left(\\frac{\\epsilon_{global}}{D\\,K\\,L^{5}}\\right)^{\\frac{1}{4}}\n= \\left(\\frac{\\epsilon_{global}}{D}\\right)^{\\frac{1}{4}} L^{-\\frac{1}{4}} K^{-\\frac{1}{4}}.\n$$\n将此应用于 $c$ 的左侧，令 $K=K_{1}$，可得\n$$\nh_{L} = \\left(\\frac{\\epsilon_{global}}{D}\\right)^{\\frac{1}{4}} L^{-\\frac{1}{4}} K_{1}^{-\\frac{1}{4}},\n$$\n以及在右侧，令 $K=K_{2}$，可得\n$$\nh_{R} = \\left(\\frac{\\epsilon_{global}}{D}\\right)^{\\frac{1}{4}} L^{-\\frac{1}{4}} K_{2}^{-\\frac{1}{4}}.\n$$\n求比值可以消去所有公共因子，得到\n$$\n\\frac{h_{L}}{h_{R}} = \\left(\\frac{K_{2}}{K_{1}}\\right)^{\\frac{1}{4}}.\n$$\n这就是在 $\\epsilon_{global} \\to 0$ 极限情况下的特征比值。",
            "answer": "$$\\boxed{\\left(\\frac{K_{2}}{K_{1}}\\right)^{\\frac{1}{4}}}$$"
        }
    ]
}