{
    "hands_on_practices": [
        {
            "introduction": "To truly understand an algorithm, there is no substitute for tracing its execution by hand. This first exercise invites you to step into the role of the computer, manually applying a simple adaptive trapezoidal rule to a basic polynomial function. By walking through the recursive logic of approximation, error comparison, and subdivision, you will build a concrete and foundational understanding of how adaptive quadrature dynamically refines its approach to meet a desired accuracy .",
            "id": "2153105",
            "problem": "An adaptive quadrature algorithm refines its calculation mesh to meet a desired error tolerance. Consider the following recursive algorithm designed to approximate the definite integral $I = \\int_a^b f(x) \\,dx$.\n\n**Adaptive Integration Algorithm:**\nThe function `AdaptiveIntegrate(f, a, b, ε)` takes a function $f$, an interval $[a, b]$, and a tolerance $\\epsilon$ as input.\n\n1.  Calculate $S_1$, the approximation from the trapezoidal rule using a single interval of width $h_1 = b-a$. The formula is $S_1 = \\frac{h_1}{2}(f(a) + f(b))$.\n2.  Let $c = (a+b)/2$ be the midpoint of the interval. Calculate $S_2$, the approximation from the composite trapezoidal rule using two subintervals $[a, c]$ and $[c, b]$, each of width $h_2 = (b-a)/2$. The formula is $S_2 = \\frac{h_2}{2}(f(a) + f(c)) + \\frac{h_2}{2}(f(c) + f(b))$.\n3.  An estimate for the error in the more accurate approximation $S_2$ is based on the difference between the two approximations. The stopping criterion is $|S_2 - S_1|  3\\epsilon$.\n4.  If the criterion is met, the procedure for this interval terminates and returns the value of $S_2$.\n5.  If the criterion is not met, the algorithm refines the interval. It recursively calls itself on the two subintervals, halving the tolerance for each. The result for the interval $[a, b]$ is the sum of the results from these two calls:\n    `AdaptiveIntegrate(f, a, c, ε/2) + AdaptiveIntegrate(f, c, b, ε/2)`\n\nYour task is to manually trace this algorithm to find the numerical approximation of the integral\n$$ I = \\int_0^4 x^2 \\,dx $$\nwith an initial tolerance of $\\epsilon = 2$.\n\nCalculate the final numerical approximation for the integral returned by the algorithm. Provide your answer as an exact integer or fraction.",
            "solution": "We apply the given adaptive trapezoidal algorithm to $f(x)=x^{2}$ on $[0,4]$ with initial tolerance $\\epsilon=2$. The trapezoidal approximation on $[a,b]$ with one panel is $S_{1}=\\frac{h_{1}}{2}\\left(f(a)+f(b)\\right)$ where $h_{1}=b-a$, and with two panels is\n$$\nS_{2}=\\frac{h_{2}}{2}\\left(f(a)+f(c)\\right)+\\frac{h_{2}}{2}\\left(f(c)+f(b)\\right),\n$$\nwhere $c=\\frac{a+b}{2}$ and $h_{2}=\\frac{b-a}{2}$. The stopping criterion for an interval is $\\left|S_{2}-S_{1}\\right|3\\epsilon$. If not met, we recurse on $[a,c]$ and $[c,b]$ with tolerance $\\epsilon/2$ each and sum the returned values.\n\nTop-level interval $[0,4]$ with $\\epsilon=2$:\n- Compute $h_{1}=4$, $S_{1}=\\frac{4}{2}\\left(f(0)+f(4)\\right)=2\\left(0+16\\right)=32$.\n- Midpoint $c=2$, $h_{2}=2$, and\n$$\nS_{2}=\\frac{2}{2}\\left(f(0)+f(2)\\right)+\\frac{2}{2}\\left(f(2)+f(4)\\right)=1\\left(0+4\\right)+1\\left(4+16\\right)=4+20=24.\n$$\n- Error check: $\\left|S_{2}-S_{1}\\right|=\\left|24-32\\right|=8$, while $3\\epsilon=3\\cdot 2=6$. Since $8\\not6$, we recurse on $[0,2]$ and $[2,4]$ with tolerance $\\epsilon/2=1$ each.\n\nSubinterval $[0,2]$ with $\\epsilon=1$:\n- Compute $h_{1}=2$, $S_{1}=\\frac{2}{2}\\left(f(0)+f(2)\\right)=1\\left(0+4\\right)=4$.\n- Midpoint $c=1$, $h_{2}=1$, and\n$$\nS_{2}=\\frac{1}{2}\\left(f(0)+f(1)\\right)+\\frac{1}{2}\\left(f(1)+f(2)\\right)=\\frac{1}{2}\\left(0+1\\right)+\\frac{1}{2}\\left(1+4\\right)=\\frac{1}{2}+\\frac{5}{2}=3.\n$$\n- Error check: $\\left|S_{2}-S_{1}\\right|=\\left|3-4\\right|=1$, while $3\\epsilon=3\\cdot 1=3$. Since $13$, accept $S_{2}=3$ for $[0,2]$.\n\nSubinterval $[2,4]$ with $\\epsilon=1$:\n- Compute $h_{1}=2$, $S_{1}=\\frac{2}{2}\\left(f(2)+f(4)\\right)=1\\left(4+16\\right)=20$.\n- Midpoint $c=3$, $h_{2}=1$, and\n$$\nS_{2}=\\frac{1}{2}\\left(f(2)+f(3)\\right)+\\frac{1}{2}\\left(f(3)+f(4)\\right)=\\frac{1}{2}\\left(4+9\\right)+\\frac{1}{2}\\left(9+16\\right)=\\frac{13}{2}+\\frac{25}{2}=19.\n$$\n- Error check: $\\left|S_{2}-S_{1}\\right|=\\left|19-20\\right|=1$, while $3\\epsilon=3$. Since $13$, accept $S_{2}=19$ for $[2,4]$.\n\nFinally, the top-level call returns the sum of the accepted subinterval results:\n$$\n\\text{Result} = 3+19=22.\n$$\nThis is the final numerical approximation returned by the algorithm.",
            "answer": "$$\\boxed{22}$$"
        },
        {
            "introduction": "Numerical methods are powerful tools, but they are not infallible. A crucial part of a scientist's training is learning to recognize their limitations and potential failure modes. This problem explores a fascinating \"pathological case\" where an adaptive algorithm can be deceived by the integrand's properties, leading it to report a highly inaccurate result with a misleadingly small error estimate . By engineering a function that exploits the symmetries of Simpson's rule, you will gain critical insight into why the underlying error estimator works and, more importantly, when it can fail catastrophically.",
            "id": "2153109",
            "problem": "An adaptive quadrature algorithm is designed to compute the definite integral $I = \\int_{a}^{b} f(x) \\,dx$. The algorithm operates recursively. In a single step on an interval $[c,d]$, it computes two approximations for the integral:\n1. A \"coarse\" approximation, $S_{\\text{coarse}}$, using Simpson's rule over the entire interval $[c,d]$.\n2. A \"refined\" approximation, $S_{\\text{refined}}$, by summing the results of Simpson's rule applied to the two sub-intervals $[c, (c+d)/2]$ and $[(c+d)/2, d]$.\n\nThe absolute error is estimated by comparing these two approximations. If $|S_{\\text{refined}} - S_{\\text{coarse}}|$ is smaller than a given tolerance $\\epsilon$, the algorithm terminates and returns $S_{\\text{refined}}$ as the value of the integral for $[c,d]$. Otherwise, the algorithm is applied recursively to the two sub-intervals, and their results are summed.\n\nConsider the integral of the function $f(x) = \\cos(\\omega x)$ over the interval $[-L, L]$. It is found that for a specific choice of parameters, the adaptive algorithm, when initiated on the full interval $[-L, L]$ with a sufficiently large tolerance $\\epsilon$, terminates immediately and returns a value for the integral. This special case of failure occurs because the condition $|S_{\\text{refined}} - S_{\\text{coarse}}| = 0$ is met exactly.\n\nLet the parameters be $L=2$ and the smallest positive value of $\\omega$ that causes this phenomenon. Calculate the absolute error of the result returned by the algorithm, which is defined as (True Value of the Integral - Value Returned by Algorithm).",
            "solution": "Let $f(x)=\\cos(\\omega x)$ and consider Simpson’s rule on $[-L,L]$. The coarse Simpson approximation on $[-L,L]$ is\n$$\nS_{\\text{coarse}}=\\frac{2L}{6}\\big(f(-L)+4f(0)+f(L)\\big).\n$$\nThe refined Simpson approximation, obtained by applying Simpson’s rule on $[-L,0]$ and $[0,L]$ and summing, is\n$$\nS_{\\text{refined}}=\\frac{L}{6}\\big(f(-L)+4f(-L/2)+f(0)\\big)+\\frac{L}{6}\\big(f(0)+4f(L/2)+f(L)\\big).\n$$\nUsing the evenness of $\\cos(\\omega x)$, $f(-x)=f(x)$, we simplify:\n$$\nS_{\\text{coarse}}=\\frac{L}{3}\\big(2f(L)+4f(0)\\big),\\qquad\nS_{\\text{refined}}=\\frac{L}{3}\\big(f(L)+4f(L/2)+f(0)\\big).\n$$\nHence\n$$\nS_{\\text{refined}}-S_{\\text{coarse}}=\\frac{L}{3}\\big(-f(L)+4f(L/2)-3f(0)\\big).\n$$\nWith $f(x)=\\cos(\\omega x)$, set $C=\\cos(\\omega L/2)$; then $\\cos(\\omega L)=2C^{2}-1$ and $f(0)=1$. The condition for immediate termination is\n$$\n-f(L)+4f(L/2)-3f(0)=0\\;\\;\\Longleftrightarrow\\;\\;-(2C^{2}-1)+4C-3=0\n$$\nwhich simplifies to\n$$\n-2C^{2}+4C-2=0\\;\\;\\Longleftrightarrow\\;\\;(C-1)^{2}=0\\;\\;\\Longleftrightarrow\\;\\;C=1.\n$$\nThus $\\cos(\\omega L/2)=1$, so $\\omega L/2=2\\pi m$ for some $m\\in\\mathbb{Z}$. The smallest positive $\\omega$ is\n$$\n\\omega=\\frac{4\\pi}{L}.\n$$\nWith $L=2$, this gives $\\omega=2\\pi$.\n\nFor this $\\omega$, the nodal values are $f(0)=\\cos(0)=1$, $f(L/2)=\\cos(\\omega L/2)=\\cos(2\\pi)=1$, and $f(L)=\\cos(\\omega L)=\\cos(4\\pi)=1$, so\n$$\nS_{\\text{refined}}=\\frac{L}{3}\\big(1+4\\cdot 1+1\\big)=\\frac{L}{3}\\cdot 6=2L.\n$$\nWith $L=2$, the algorithm returns $S_{\\text{refined}}=4$.\n\nThe true value of the integral is\n$$\nI=\\int_{-L}^{L}\\cos(\\omega x)\\,dx=2\\int_{0}^{L}\\cos(\\omega x)\\,dx=\\frac{2\\sin(\\omega L)}{\\omega}.\n$$\nFor $L=2$ and $\\omega=2\\pi$, this yields\n$$\nI=\\frac{2\\sin(4\\pi)}{2\\pi}=0.\n$$\nBy the given definition, the error is\n$$\n\\text{(True Value)}-\\text{(Returned Value)}=0-4=-4.\n$$",
            "answer": "$$\\boxed{-4}$$"
        },
        {
            "introduction": "The true power of adaptive quadrature lies in its efficiency: it automatically concentrates computational effort only where it is needed. This practice moves from manual tracing to an analytical exploration of this core feature. You will investigate how an adaptive algorithm responds to a function that is \"difficult\" in one region and \"easy\" in another, due to a change in its higher-order derivatives . By deriving the relationship between the final subinterval widths and the local smoothness of the function, you will develop a deeper appreciation for the intelligent and resource-saving nature of adaptive methods.",
            "id": "2153092",
            "problem": "An adaptive quadrature algorithm based on Simpson's rule is used to numerically compute the integral of a function $f(x)$ over an interval $[A, B]$. The algorithm works recursively. For any given subinterval $[a, b]$, it computes two approximations of the integral: a coarse approximation, $S_{coarse}$, using a single Simpson's rule application over $[a, b]$, and a more refined approximation, $S_{fine}$, by summing the results of Simpson's rule applied to the two halves, $[a, (a+b)/2]$ and $[(a+b)/2, b]$.\n\nThe algorithm estimates the error of the refined approximation as $E_{est} = \\frac{1}{15} |S_{fine} - S_{coarse}|$. If this estimated error is less than a local tolerance $\\epsilon_{local}$, the algorithm accepts $S_{fine}$ as the result for the interval $[a, b]$ and terminates for this branch. Otherwise, the algorithm is applied recursively to the two subintervals, with the local tolerance for each new sub-subinterval being half of the current local tolerance. The initial local tolerance for the whole interval $[A, B]$ is a user-defined global tolerance $\\epsilon_{global}$.\n\nIt is known that the true error of Simpson's rule on an interval of width $h$ is approximately $E_{true} \\approx C h^5 f^{(4)}(\\xi)$ for some point $\\xi$ in the interval, where $C$ is a constant and $f^{(4)}$ is the fourth derivative of the function. For a sufficiently smooth function, the error estimate $E_{est}$ is a good approximation of the true error of $S_{fine}$.\n\nConsider a function $f(x)$ defined on the interval $[0, L]$ whose derivatives up to the third order are continuous. Its fourth derivative, $f^{(4)}(x)$, is piecewise constant with a single jump discontinuity at $x=c$, where $0  c  L$. Specifically,\n$$\nf^{(4)}(x) = \\begin{cases} K_1  \\text{if } 0 \\le x  c \\\\ K_2  \\text{if } c  x \\le L \\end{cases}\n$$\nwhere $K_1$ and $K_2$ are given positive constants.\n\nThe adaptive algorithm is run with a very small global tolerance $\\epsilon_{global}$, resulting in a fine partition of $[0, L]$ into many terminal subintervals. In the limit as $\\epsilon_{global} \\to 0$, the widths of these subintervals become very small. Let $h_L$ be the characteristic width of the terminal subintervals in an infinitesimal region just to the left of the discontinuity (i.e., at $x=c^-$) and $h_R$ be the characteristic width of the terminal subintervals in an infinitesimal region just to the right of the discontinuity (i.e., at $x=c^+$).\n\nDetermine the ratio $h_L / h_R$. Express your answer as a closed-form analytic expression in terms of $K_1$ and $K_2$.",
            "solution": "The local truncation error of a single-panel Simpson rule on an interval of width $h$ is $E_{true} \\approx C h^{5} f^{(4)}(\\xi)$, where $C$ is a constant and $\\xi$ lies in the interval. When $f^{(4)}$ is constant on the interval, the adaptive estimator based on $S_{fine}$ and $S_{coarse}$ has the same $h^{5}$ scaling and differs only by a constant factor, so we can write the estimated error on such a subinterval as\n$$\nE_{est} \\approx D\\,K\\,h^{5},\n$$\nwhere $K$ is the value of $f^{(4)}$ on that subinterval and $D0$ is a constant that depends only on the Simpson error constant and the refinement procedure.\n\nIn the adaptive algorithm, an interval $[a,b]$ at recursion depth $d$ has:\n- width $h = b-a = L\\,2^{-d}$, since each refinement halves the interval length;\n- local tolerance $\\epsilon_{local} = \\epsilon_{global}\\,2^{-d}$, since each refinement halves the tolerance.\n\nAcceptance occurs (asymptotically) when the estimated error meets the local tolerance, i.e.,\n$$\nD\\,K\\,h^{5} = \\epsilon_{local}.\n$$\nSubstituting $h = L\\,2^{-d}$ and $\\epsilon_{local} = \\epsilon_{global}\\,2^{-d}$ gives\n$$\nD\\,K\\,(L\\,2^{-d})^{5} = \\epsilon_{global}\\,2^{-d}\n\\;\\;\\Longrightarrow\\;\\;\nD\\,K\\,L^{5}\\,2^{-5d} = \\epsilon_{global}\\,2^{-d}\n\\;\\;\\Longrightarrow\\;\\;\nD\\,K\\,L^{5}\\,2^{-4d} = \\epsilon_{global}.\n$$\nSolving for $2^{-d}$ yields\n$$\n2^{-d} = \\left(\\frac{\\epsilon_{global}}{D\\,K\\,L^{5}}\\right)^{\\frac{1}{4}}.\n$$\nTherefore, the terminal width on a side where $f^{(4)} \\equiv K$ is\n$$\nh = L\\,2^{-d} = L\\left(\\frac{\\epsilon_{global}}{D\\,K\\,L^{5}}\\right)^{\\frac{1}{4}}\n= \\left(\\frac{\\epsilon_{global}}{D}\\right)^{\\frac{1}{4}} L^{-\\frac{1}{4}} K^{-\\frac{1}{4}}.\n$$\nApplying this just to the left of $c$ with $K=K_{1}$ yields\n$$\nh_{L} = \\left(\\frac{\\epsilon_{global}}{D}\\right)^{\\frac{1}{4}} L^{-\\frac{1}{4}} K_{1}^{-\\frac{1}{4}},\n$$\nand just to the right with $K=K_{2}$ yields\n$$\nh_{R} = \\left(\\frac{\\epsilon_{global}}{D}\\right)^{\\frac{1}{4}} L^{-\\frac{1}{4}} K_{2}^{-\\frac{1}{4}}.\n$$\nTaking the ratio cancels all common factors, giving\n$$\n\\frac{h_{L}}{h_{R}} = \\left(\\frac{K_{2}}{K_{1}}\\right)^{\\frac{1}{4}}.\n$$\nThis is the characteristic ratio in the limit $\\epsilon_{global} \\to 0$.",
            "answer": "$$\\boxed{\\left(\\frac{K_{2}}{K_{1}}\\right)^{\\frac{1}{4}}}$$"
        }
    ]
}