{
    "hands_on_practices": [
        {
            "introduction": "对大量浮点数进行求和是一项看似简单但充满陷阱的基础任务。直接的累加方法会累积舍入误差，特别是在处理具有宽动态范围的数据时，误差可能变得非常大。本练习旨在通过对几种模拟的波场能量分布进行求和，来量化比较朴素求和、Kahan补偿求和以及Neumaier补偿求和等不同算法的误差特性，从而让您深入理解误差的累积方式以及稳健算法的有效性 。",
            "id": "3596759",
            "problem": "给定一个基于浮点运算和计算地球物理学中数值误差的计算任务。考虑一个离散波场振幅序列 $\\{A_i\\}_{i=1}^N$，并定义能量序列 $\\{E_i\\}_{i=1}^N$ 为 $E_i = A_i^2$，其中 $E_i \\ge 0$。在符合电气与电子工程师协会（IEEE）754 双精度标准的有限精度算术中，每个基本运算都会舍入到最接近的可表示浮点数。令单位舍入误差 $u$ 表示单次舍入的最大相对误差，对于双精度，$u = 2^{-53}$。\n\n您的任务是实现并比较以下三种应用于 $\\sum_{i=1}^N E_i$ 的求和方案：\n- 双精度下的朴素顺序求和。\n- 双精度下的 Kahan 补偿求和。\n- 双精度下的 Neumaier 补偿求和。\n\n对于每种方案，将一个实现序列的求和误差定义为 $\\varepsilon = S_{\\text{scheme}} - S_{\\text{ref}}$，其中 $S_{\\text{ref}}$ 是使用软件模拟高精度对相同的有限精度输入计算出的高精度参考和，而 $S_{\\text{scheme}}$ 是由指定方案产生的双精度和。在具有不同随机种子的多个独立实现中，计算 $\\varepsilon$ 的样本偏差和样本方差。偏差是 $\\varepsilon$ 的样本均值，方差是 $(\\varepsilon - \\text{bias})^2$ 的样本均值。\n\n目标是量化求和误差的偏差和方差如何依赖于 $E_i$ 的量级分布以及各项的求和顺序。您必须使用三种与波场能量相关的科学上合理的能量量级分布：\n1. 高斯振幅模型：$A_i \\sim \\mathcal{N}(0,\\sigma^2)$，其中 $\\sigma = 1$，因此 $E_i = A_i^2$ 的能量量级呈类卡方分布。\n2. 对数正态能量模型：$E_i \\sim \\operatorname{LogNormal}(\\mu,\\sigma)$，其中 $(\\mu,\\sigma) = (-2,2)$，以模拟非均匀介质中典型的重尾能量量级。\n3. 双峰能量混合：$E_i$ 以概率 $p$ 取 $E_{\\text{small}}$，以概率 $1-p$ 取 $E_{\\text{large}}$，其中 $(E_{\\text{small}}, E_{\\text{large}}, p) = (10^{-12}, 1, 0.999)$，以产生典型的尺度分离极端情况，即少数强相干分量淹没了大量微弱的散射能量。\n\n除了分布之外，对于双峰情况，您必须通过两种确定性顺序求和来测试对顺序的敏感性：先对所有小项求和，再对所有大项求和；以及先对所有大项求和，再对所有小项求和。对于高斯振幅和对数正态情况，按自然的生成顺序求和。\n\n您必须实现以下内容：\n- 一个稳健的随机数生成器，通过固定种子实现可复现性。\n- 朴素求和、Kahan 求和与 Neumaier 求和的确定性实现，均采用双精度算术。\n- 一个高精度参考和，使用一种相比朴素双精度求和能显著减少舍入误差的软件算法，对相同的双精度输入进行计算。\n\n使用包含以下参数集的测试套件：\n- 案例 1（高斯振幅能量）：$N = 500000$，种子 $\\{777, 888\\}$，分布如第 1 项所述。\n- 案例 2（对数正态能量）：$N = 500000$，种子 $\\{777, 888\\}$，分布如第 2 项所述。\n- 案例 3（双峰，小项优先顺序）：$N = 500000$，种子 $\\{777, 888\\}$，分布如第 3 项所述，确定性顺序为先对所有 $E_{\\text{small}}$ 求和，再对所有 $E_{\\text{large}}$ 求和。\n- 案例 4（双峰，大项优先顺序）：$N = 500000$，种子 $\\{777, 888\\}$，分布如第 3 项所述，确定性顺序为先对所有 $E_{\\text{large}}$ 求和，再对所有 $E_{\\text{small}}$ 求和。\n\n对于每个案例，您的程序必须：\n- 生成能量序列 $\\{E_i\\}$，单位为任意单位 (a.u.)。\n- 应用于实现的浮点序列，使用高精度求和算法计算 $S_{\\text{ref}}$。\n- 计算 $S_{\\text{naive}}$、$S_{\\text{Kahan}}$、$S_{\\text{Neumaier}}$。\n- 为每个种子计算求和误差 $\\varepsilon_{\\text{naive}}$、$\\varepsilon_{\\text{Kahan}}$、$\\varepsilon_{\\text{Neumaier}}$。\n- 计算每种方案在两个种子上的样本偏差和样本方差。\n\n以任意单位 (a.u.) 表示所有输出，不带任何单位符号，也不进行舍入；输出为纯浮点数。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个案例贡献一个包含六个浮点数的子列表，顺序为 $[\\text{bias}_{\\text{naive}}, \\text{var}_{\\text{naive}}, \\text{bias}_{\\text{Kahan}}, \\text{var}_{\\text{Kahan}}, \\text{bias}_{\\text{Neumaier}}, \\text{var}_{\\text{Neumaier}}]$。因此，最终输出必须是一个包含四个子列表的列表，每个案例一个，例如：\n\"[[b1,v1,b2,v2,b3,v3],[b1,v1,b2,v2,b3,v3],[b1,v1,b2,v2,b3,v3],[b1,v1,b2,v2,b3,v3]]\"。\n\n本问题陈述中出现的所有数学符号均以 LaTeX 表示。不涉及角度。不涉及百分比。\n\n您的程序必须是一个完整的、可运行的程序，不需要用户输入，并且只按指定格式打印最终的单行输出。",
            "solution": "该问题提出了一个在计算地球物理学领域中应用数值分析的有效且适定的计算任务。它要求实现并比较三种不同的求和算法——朴素顺序求和、Kahan 补偿求和以及 Neumaier 补偿求和——以量化它们在对代表波场能量的浮点数序列求和时的精度。该问题具有科学依据，为能量分布提供了合理的模型，并为通过偏差和方差的统计量来评估数值误差提供了清晰的方法论。所有必要的参数和条件都已指定，从而可以得到唯一且可验证的解。\n\n问题的核心在于理解浮点运算中舍入误差的累积。当对一个数列 $\\{x_i\\}_{i=1}^N$ 求和时，朴素方法 $S_k = S_{k-1} + x_k$ 可能会遭受显著的误差累积，特别是当小数被加到一个数量级很大的累加和上时。这是因为在浮点加法过程中，小数的低位比特会丢失。\n\n求和方案定义如下：\n\n1.  **朴素求和**：这是最直接的方法。和 $S$ 初始化为 $0$，序列中的每个元素 $x_i$ 依次加到 $S$ 上。\n    $$ S \\leftarrow S + x_i $$\n    在 IEEE 754 双精度中，浮点加法 $a+b$ 计算为 $\\text{fl}(a+b) = (a+b)(1+\\delta)$，其中 $|\\delta| \\le u$ 且 $u = 2^{-53}$ 是单位舍入误差。当对 $N$ 个正数求和时，朴素求和的前向误差可以被界定，但在最坏情况下，相对误差可能与 $N$ 成比例增长。\n\n2.  **Kahan 求和**：该算法引入一个补偿变量 $c$，用于累积每次加法中损失的误差。\n    令 $S$ 为累加和，$c$ 为累加补偿，两者均初始化为 $0$。对于每个元素 $x_i$：\n    \\begin{enumerate}\n        \\item $y \\leftarrow x_i - c$：从当前项中减去前一个误差。\n        \\item $T \\leftarrow S + y$：将修正后的项加到和中。\n        \\item $c \\leftarrow (T - S) - y$：新的误差是将 $y$ 加到 $S$ 时丢失的部分。项 $(T - S)$ 在代数上恢复了成功加到 $S$ 上的 $y$ 的高位部分。从此结果中减去 $y$ 便分离出被截断的 $y$ 的低位部分的负值。\n        \\item $S \\leftarrow T$：更新和。\n    \\end{enumerate}\n    最终的和为 $S$。Kahan 求和显著减少了误差的增长，使得最终误差界限与 $N$ 无关，仅取决于输入值本身的误差，外加一个小的常数因子乘以它们的量级之和。\n\n3.  **Neumaier 求和**：这是对 Kahan 算法的改进，在待加项 $|x_i|$ 的量级远大于累加和 $|S|$ 的量级时提供更高的精度。在这种情况下，如果 $|x_i| \\gg |c|$，Kahan 步骤 $y \\leftarrow x_i - c$ 可能会损失精度。Neumaier 算法避免了这一点。\n    令 $S$ 为累加和，$c$ 为累加补偿，两者均初始化为 $0$。对于每个元素 $x_i$：\n    \\begin{enumerate}\n        \\item $T \\leftarrow S + x_i$：将下一项加到和中，可能会损失精度。\n        \\item 如果 $|S| \\ge |x_i|$：$c \\leftarrow c + ((S - T) + x_i)$。\n        \\item 否则：$c \\leftarrow c + ((x_i - T) + S)$。\n        \\item $S \\leftarrow T$：更新和。\n    \\end{enumerate}\n    最终的和是 $S+c$。通过检查 $S$ 和 $x_i$ 的量级，Neumaier 确保了用于计算补偿项的减法总是在量级较大的数和中间和之间进行，从而保留了最高的精度。\n\n问题要求在三种能量值 $E_i = A_i^2 \\ge 0$ 的分布上测试这些算法。\n-   **高斯振幅模型**：$A_i \\sim \\mathcal{N}(0, 1^2)$ 导致 $E_i = A_i^2$ 服从自由度为 1 的卡方分布 $\\chi^2(1)$。这代表了小能量值和中等能量值的混合。\n-   **对数正态能量模型**：$E_i \\sim \\operatorname{LogNormal}(-2, 2)$ 产生一个重尾分布，其中包含少数非常大的值和许多小值。这对朴素求和来说是一个具有挑战性的案例。\n-   **双峰能量混合**：绝大多数（$99.9\\%$）的项非常小（$10^{-12}$），少数项很大（$1$）。这个案例旨在暴露朴素求和的一个关键弱点：在大数之后对小数求和会导致它们的贡献完全丢失（被吞噬）。指定的两种排序方式，小项优先和大项优先，将凸显这种依赖性。\n\n作为参考，会计算一个高精度和 $S_{\\text{ref}}$。一个合适的方法是使用一个能保持精度的算法，例如 Python 的 `math.fsum` 中实现的算法，该算法基于无误差变换方法。每个方案的误差为 $\\varepsilon = S_{\\text{scheme}} - S_{\\text{ref}}$。我们通过两次独立实现（来自种子 $777$ 和 $888$）分析样本偏差 $\\mathbb{E}[\\varepsilon]$ 和样本方差 $\\text{Var}[\\varepsilon]$，以评估误差的统计特性。偏差衡量系统误差，而方差衡量误差的随机分量。\n\n实现将首先设置随机数生成器，然后为三种求和方案定义 Python 函数。对于每个测试案例，我们将为每个种子生成数据，执行求和，并根据参考 `math.fsum` 结果计算误差。最后，根据两个种子获得的误差为每个方案计算偏差和方差。最终输出将是一个格式化的列表，包含这四个测试案例中每个案例的六个统计度量。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef naive_sum(arr: np.ndarray) - np.float64:\n    \"\"\"Computes the sum using native Python float summation.\"\"\"\n    # Using np.sum with a specified dtype is a fast and standard\n    # way to perform naive sequential summation in double precision.\n    return np.sum(arr, dtype=np.float64)\n\ndef kahan_sum(arr: np.ndarray) - np.float64:\n    \"\"\"Computes the sum using Kahan's compensated summation algorithm.\"\"\"\n    s = np.float64(0.0)\n    c = np.float64(0.0)  # A running compensation for the lost low-order bits.\n    for x in arr:\n        y = x - c\n        t = s + y\n        c = (t - s) - y\n        s = t\n    return s\n\ndef neumaier_sum(arr: np.ndarray) - np.float64:\n    \"\"\"Computes the sum using Neumaier's improved summation algorithm.\"\"\"\n    s = np.float64(0.0)\n    c = np.float64(0.0)  # A running compensation.\n    for x in arr:\n        t = s + x\n        if abs(s) = abs(x):\n            # If s is bigger, c collects the error of x.\n            c += (s - t) + x\n        else:\n            # If x is bigger, c collects the error of s.\n            c += (x - t) + s\n        s = t\n    return s + c\n\ndef solve():\n    \"\"\"Main function to run the simulation and produce the output.\"\"\"\n    test_cases = [\n        {\n            \"name\": \"Gaussian amplitude\",\n            \"N\": 500000,\n            \"seeds\": [777, 888],\n            \"distribution\": \"gaussian_amplitude\",\n            \"params\": {\"sigma\": 1.0},\n            \"order\": \"natural\",\n        },\n        {\n            \"name\": \"Log-normal\",\n            \"N\": 500000,\n            \"seeds\": [777, 888],\n            \"distribution\": \"log_normal\",\n            \"params\": {\"mu\": -2.0, \"sigma\": 2.0},\n            \"order\": \"natural\",\n        },\n        {\n            \"name\": \"Bimodal, small-first\",\n            \"N\": 500000,\n            \"seeds\": [777, 888],\n            \"distribution\": \"bimodal\",\n            \"params\": {\"E_small\": 1e-12, \"E_large\": 1.0, \"p\": 0.999},\n            \"order\": \"small_first\",\n        },\n        {\n            \"name\": \"Bimodal, large-first\",\n            \"N\": 500000,\n            \"seeds\": [777, 888],\n            \"distribution\": \"bimodal\",\n            \"params\": {\"E_small\": 1e-12, \"E_large\": 1.0, \"p\": 0.999},\n            \"order\": \"large_first\",\n        },\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        N = case[\"N\"]\n        seeds = case[\"seeds\"]\n        dist = case[\"distribution\"]\n        params = case[\"params\"]\n        order = case[\"order\"]\n\n        errors_naive = []\n        errors_kahan = []\n        errors_neumaier = []\n\n        for seed in seeds:\n            rng = np.random.default_rng(seed)\n            E = None\n\n            if dist == \"gaussian_amplitude\":\n                A = rng.normal(loc=0.0, scale=params[\"sigma\"], size=N)\n                E = np.square(A, dtype=np.float64)\n            elif dist == \"log_normal\":\n                E = rng.lognormal(mean=params[\"mu\"], sigma=params[\"sigma\"], size=N).astype(np.float64)\n            elif dist == \"bimodal\":\n                p = params[\"p\"]\n                E_small = np.float64(params[\"E_small\"])\n                E_large = np.float64(params[\"E_large\"])\n                \n                # Generate a boolean mask by comparing uniform random numbers to p\n                is_small = rng.random(size=N)  p\n                E = np.where(is_small, E_small, E_large)\n\n            if order == \"small_first\":\n                E = np.sort(E)\n            elif order == \"large_first\":\n                E = np.sort(E)[::-1]\n\n            # Ensure all values are float64 for consistent input\n            E = E.astype(np.float64)\n\n            # High-accuracy reference sum\n            s_ref = math.fsum(E)\n\n            # Compute sums for each scheme\n            s_naive = naive_sum(E)\n            s_kahan = kahan_sum(E)\n            s_neumaier = neumaier_sum(E)\n\n            # Compute and store errors\n            errors_naive.append(s_naive - s_ref)\n            errors_kahan.append(s_kahan - s_ref)\n            errors_neumaier.append(s_neumaier - s_ref)\n\n        # Compute sample bias and variance\n        bias_naive = np.mean(errors_naive)\n        var_naive = np.var(errors_naive, ddof=0)\n        \n        bias_kahan = np.mean(errors_kahan)\n        var_kahan = np.var(errors_kahan, ddof=0)\n\n        bias_neumaier = np.mean(errors_neumaier)\n        var_neumaier = np.var(errors_neumaier, ddof=0)\n\n        case_results = [\n            bias_naive, var_naive,\n            bias_kahan, var_kahan,\n            bias_neumaier, var_neumaier\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string as per requirements\n    # e.g., \"[[r1,r2,...],[r1,r2,...]]\"\n    output_str = \"[\" + \",\".join(\n        \"[\" + \",\".join(f\"{val:.17g}\" for val in res) + \"]\" for res in all_results\n    ) + \"]\"\n    \n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "在简单的求和之外，评估复杂的数学函数是计算地球物理学中的常见任务，例如在波动方程模拟中使用的完美匹配层（PML）边界条件。直接将数学公式（如 $1 - \\exp(-z)$）翻译成代码，当变量 $z$ 很小时，会导致灾难性的精度损失（即相消误差），而其他计算（如 $\\xi^m$）则可能遭遇有害的下溢问题。本练习将指导您诊断并解决这些问题，通过实现基于泰勒级数展开和 `expm1` 等特殊函数的数值稳定替代方案，以确保模拟代码关键部分的准确性 。",
            "id": "3596709",
            "problem": "考虑一个用于时域波模拟的一维完美匹配层 (PML)，其阻尼剖面由无量纲归一化坐标 $\\xi \\in [0,1]$ 上的以下公式定义：\n$$\n\\sigma(\\xi) = \\sigma_{\\max} \\, \\xi^{m},\n$$\n其中 $\\sigma_{\\max}  0$ 且整数 $m \\ge 1$。对于时间步长为 $\\Delta t  0$ 的离散更新，在施加边界条件时，常用的一对系数是：\n$$\nA(\\xi) = \\exp\\!\\big(-\\sigma(\\xi)\\,\\Delta t\\big), \\qquad B(\\xi) = \\frac{1 - \\exp\\!\\big(-\\sigma(\\xi)\\,\\Delta t\\big)}{\\sigma(\\xi)},\n$$\n当 $\\sigma(0) = 0$ 时，其连续极限值为 $B(0) = \\Delta t$。您将研究浮点舍入和非规格化数如何影响在 $\\xi = 0$ 附近这些系数的求值，并构建数值稳健的近似。\n\n基本基础与假设：\n- 使用 IEEE 754 binary64（双精度）算术，其单位舍入误差为 $u \\approx 2^{-53}$，并且非规格化数范围会导致相对精度下降和更易发生下溢。\n- 单个基本运算 $\\operatorname{fl}(\\cdot)$ 的舍入模型为 $\\operatorname{fl}(x \\circ y) = (x \\circ y)(1 + \\delta)$，当结果为规格化数时，满足 $|\\delta| \\le u$；当结果为非规格化数时，此界限可能不成立。\n- 指数函数在 $0$ 点的泰勒展开式有效：$\\exp(z) = \\sum_{k=0}^{\\infty} \\frac{z^{k}}{k!}$ 对所有实数 $z$ 成立。\n\n您的任务是：\n1) 实现一个朴素的基线方法，该方法使用内置的幂函数直接计算 $\\sigma(\\xi) = \\sigma_{\\max}\\,\\xi^{m}$，然后计算 $A(\\xi) = \\exp(-\\sigma(\\xi)\\Delta t)$ 和 $B(\\xi) = \\big(1 - \\exp(-\\sigma(\\xi)\\Delta t)\\big)/\\sigma(\\xi)$，并遵循约定 $B(0) = \\Delta t$。\n2) 基于第一性原理推导并实现一个稳健的求值方法：\n   - 对于 $\\xi^{m}$，使用缩放来避免最终结果产生前的过度下溢：令 $\\xi = s \\cdot 2^{e}$，其中 $s \\in [\\tfrac{1}{2},1)$ 且 $e$ 为整数（这是标准的二进制分解）。然后计算\n     $$\n     \\xi^{m} = s^{m}\\,2^{em}\n     $$\n     并使用一个尽可能保持中间值为规格化数的基底来构成 $\\sigma(\\xi) = \\sigma_{\\max} \\, s^{m} \\, 2^{em}$。\n   - 对于小的 $z = \\sigma(\\xi)\\Delta t$，通过使用从 $\\exp(-z)$ 的泰勒级数推导出的函数\n     $$\n     \\varphi_{1}(z) = \\frac{1 - \\exp(-z)}{z}\n     $$\n     的多项式近似，并用霍纳法则求值，来避免 $1 - \\exp(-z)$ 中的灾难性抵消。如果需要，使用缩放变量以使系数和参数保持在规格化范围内。对于中等和大的 $|z|$，使用一个通过将 $1 - \\exp(-z)$ 替换为 $-\\operatorname{expm1}(-z)$ 来避免相减抵消的公式，其中 $\\operatorname{expm1}$ 表示 $\\exp(w) - 1$ 的精确舍入计算。\n   - 结合这些方法来计算 $A(\\xi)$ 和 $B(\\xi) = \\Delta t \\, \\varphi_{1}(z)$ 的稳健近似，使其在 $\\xi = 0$ 附近（包括在非规格化范围内）保持精确。\n3) 为进行精度评估，使用一个以 10 为基底、至少有 $100$ 位有效数字的任意精度计算得到的高精度参考值。使用相对误差\n$$\n\\varepsilon_{\\mathrm{rel}}(u) = \\frac{|u_{\\mathrm{float}} - u_{\\mathrm{ref}}|}{|u_{\\mathrm{ref}}|},\n$$\n或在 $u_{\\mathrm{ref}} = 0$ 时的绝对误差 $|u_{\\mathrm{float}} - u_{\\mathrm{ref}}|$ ，将朴素和稳健的双精度结果与此参考值进行比较。\n4) 在一个给定的、重点采样 $\\xi = 0$ 附近区域的 $\\xi$ 值网格上评估最大误差，并为每个参数集报告以下四个标量：使用朴素方法计算的 $A(\\xi)$ 的最大相对误差，使用朴素方法计算的 $B(\\xi)$ 的最大相对误差，以及使用稳健方法计算的这两个最大值。\n\n测试套件和要求的输出：\n- 使用以下三组参数集，其中所有量均为无量纲：\n  - 情况 1（理想路径，中等阻尼指数）：$(\\sigma_{\\max}, m, \\Delta t) = (200, 3, 10^{-3})$。\n  - 情况 2（强阻尼指数，易产生非规格化数）：$(\\sigma_{\\max}, m, \\Delta t) = (1000, 8, 10^{-4})$。\n  - 情况 3（极小时间步长，易发生抵消）：$(\\sigma_{\\max}, m, \\Delta t) = (10^{6}, 2, 10^{-12})$。\n- 对每种情况，在以下网格上进行评估：\n$$\n\\Xi = \\{\\,0\\,\\} \\cup \\{\\,2^{-10},\\,2^{-30},\\,2^{-60},\\,2^{-120},\\,2^{-240},\\,2^{-480},\\,2^{-960},\\,2^{-1060}\\,\\} \\cup \\{\\,1\\,\\}.\n$$\n- 对每种情况，计算并返回一个列表\n$$\n\\left[ E^{A}_{\\mathrm{naive}},\\; E^{B}_{\\mathrm{naive}},\\; E^{A}_{\\mathrm{robust}},\\; E^{B}_{\\mathrm{robust}} \\right],\n$$\n其中每个条目是在 $\\Xi$ 上的最大误差，使用相对误差，但若参考值为零则使用绝对误差。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个元素是对应一个情况的四元素列表，按情况 1、情况 2、情况 3 的顺序排列。例如，一个语法正确的格式是\n$$\n\\big[ [e_{11},e_{12},e_{13},e_{14}], [e_{21},e_{22},e_{23},e_{24}], [e_{31},e_{32},e_{33},e_{34}] \\big].\n$$\n不应打印任何额外文本。",
            "solution": "该问题要求对数值波模拟中用于完美匹配层 (PML) 边界条件的表达式进行批判性分析和稳健实现。核心任务是减少在计算空间坐标 $\\xi$ 的小值时，评估系数 $A(\\xi)$ 和 $B(\\xi)$ 所产生的浮点误差，特别是下溢和灾难性抵消。\n\n分析将分三个阶段进行：首先，为精度评估建立一个高精度参考；其次，分析朴素直接实现的失效模式；第三，基于第一性原理推导并实现一个数值稳健的算法。\n\n设给定的表达式为：\n$$\n\\sigma(\\xi) = \\sigma_{\\max} \\, \\xi^{m}\n$$\n$$\nA(\\xi) = \\exp\\!\\big(-\\sigma(\\xi)\\,\\Delta t\\big)\n$$\n$$\nB(\\xi) = \\frac{1 - \\exp\\!\\big(-\\sigma(\\xi)\\,\\Delta t\\big)}{\\sigma(\\xi)}\n$$\n其极限值为 $B(0) = \\Delta t$。令 $z = \\sigma(\\xi)\\Delta t$。$B(\\xi)$ 的表达式可以用 $z$ 和时间步长 $\\Delta t$ 重写为 $B(\\xi) = \\Delta t \\cdot \\varphi_1(z)$，其中 $\\varphi_1(z) = \\frac{1 - \\exp(-z)}{z}$。\n\n### 高精度参考计算\n\n为了定量评估浮点实现的精度，我们首先使用任意精度算术计算 $A(\\xi)$ 和 $B(\\xi)$ 的参考值。选择 120 位的十进制精度，这远高于 IEEE 754 双精度的大约 16 位，从而确保这些参考值在误差计算中可以被视为有效精确值。对于每对参数 $(\\sigma_{\\max}, m, \\Delta t)$ 和评估网格 $\\Xi$ 中的每个 $\\xi$，使用高精度库直接根据其定义计算 $\\sigma(\\xi)$、$A(\\xi)$ 和 $B(\\xi)$ 的值。对于 $\\xi=0$，我们有 $\\sigma(0)=0$、$A(0)=1$ 和 $B(0)=\\Delta t$。\n\n### 朴素实现的分析\n\n朴素实现将数学公式直接转换为标准浮点运算。\n\n$1$. **$\\sigma(\\xi) = \\sigma_{\\max} \\cdot \\xi^m$**: 这被计算为 `sigma_max * xi**m`。对于非常小的 $\\xi$，例如 $\\xi = 2^{-240}$，和一个中等大的指数 $m$，比如 $m=8$，中间结果 $\\xi^m = (2^{-240})^8 = 2^{-1920}$ 在双精度中会完全下溢为 $0.0$。最小的正规格化双精度数约为 $2^{-1022}$，最小的非规格化数约为 $2^{-1074}$。因此，对于许多小的非零 $\\xi$ 值，$\\sigma(\\xi)$ 会过早地被计算为 $0$。\n\n$2$. **$A(\\xi) = \\exp(-\\sigma(\\xi)\\Delta t)$**: $A(\\xi)$ 的主要误差来源是其参数的误差，而这源于 $\\sigma(\\xi)$ 的有缺陷的计算。如果 $\\sigma(\\xi)$ 错误地向下溢出为 $0$，$A(\\xi)$ 将被错误地计算为 $\\exp(0) = 1$。\n\n$3$. **$B(\\xi) = (1 - A(\\xi)) / \\sigma(\\xi)$**: 这个表达式存在两个主要问题。\n- **灾难性抵消**: 当 $z = \\sigma(\\xi)\\Delta t$ 接近 $0$ 时，$\\exp(-z)$ 接近 $1$。减法 $1 - \\exp(-z)$ 会损失大部分有效数字。例如，如果 $z \\approx 10^{-12}$，那么 $\\exp(-z) \\approx 1 - 10^{-12}$，而 $1 - \\exp(-z)$ 的计算将会产生巨大的相对误差。\n- **除以零**: 如果对于非零的 $\\xi$，朴素计算的 $\\sigma(\\xi)$ 下溢为 $0$，此表达式将导致除以零或 $0/0$ 的不定式。为 $\\xi=0$ 进行的特殊情况处理不足以解决 $\\xi  0$ 时的这种过早下溢问题。\n\n预计这些失效模式会导致大的相对误差，尤其是在 $\\xi$ 小且 $m$ 大的测试用例中。\n\n### 稳健实现的推导\n\n一个稳健的实现必须系统地解决每个已识别的失效点。\n\n$1$. **$\\sigma(\\xi)$ 的稳健计算**: 问题建议通过将 $\\xi$ 分解为其二进制表示 $\\xi = s \\cdot 2^e$ 来避免 $\\xi^m$ 中的中间下溢，其中 $s \\in [0.5, 1)$ 是尾数，$e$ 是整数指数。这种分解可以通过 `frexp` 函数实现。然后，幂可以计算为 $\\xi^m = (s \\cdot 2^e)^m = s^m \\cdot 2^{em}$。乘以 $\\sigma_{\\max}$ 得到 $\\sigma(\\xi) = \\sigma_{\\max} \\cdot s^m \\cdot 2^{em}$。这个乘积可以使用 `ldexp(x, exp)` 函数精确计算，该函数计算 $x \\cdot 2^{\\text{exp}}$，通过 $2$ 的幂次有效地缩放数字，而不执行可能导致下溢或上溢的乘法。因此，稳健的计算是 $\\sigma(\\xi) = \\operatorname{ldexp}(\\sigma_{\\max} \\cdot s^m, em)$。这种形式尽可能地将中间值保持在正常的浮点范围内，将潜在的下溢推迟到最终结果，这是可能达到的最好结果。对于 $\\xi=0$，$\\operatorname{frexp}(0)$ 返回 $(0, 0)$，正确地得出 $\\sigma(0)=0$。\n\n$2$. **$A(\\xi)$ 的稳健计算**: 使用上述稳健方法得到精确的 $\\sigma(\\xi)$ 值后，可以高保真地计算参数 $z = \\sigma(\\xi)\\Delta t$。标准库函数 $\\exp(-z)$ 本身是高度精确的。因此，$A(\\xi)$ 的稳健计算仅需使用稳健计算出的 $\\sigma(\\xi)$ 作为输入：\n$$\nA_{\\text{robust}}(\\xi) = \\exp(-\\sigma_{\\text{robust}}(\\xi)\\,\\Delta t)\n$$\n这直接规避了 $\\sigma(\\xi)$ 过早变为零的问题。\n\n$3$. **$B(\\xi)$ 的稳健计算**: $B(\\xi)$ 的表达式最好通过函数 $\\varphi_1(z) = \\frac{1-\\exp(-z)}{z}$ 来分析。目标是稳健地计算 $B(\\xi) = \\Delta t \\cdot \\varphi_1(z)$。\n\n- **对于小的 $|z|$**: 我们使用 $\\varphi_1(z)$ 在 $z=0$ 附近的泰勒级数展开：\n$$\n\\exp(-z) = \\sum_{k=0}^{\\infty} \\frac{(-z)^k}{k!} = 1 - z + \\frac{z^2}{2!} - \\frac{z^3}{3!} + \\cdots\n$$\n$$\n1 - \\exp(-z) = z - \\frac{z^2}{2!} + \\frac{z^3}{3!} - \\cdots = \\sum_{k=1}^{\\infty} \\frac{(-1)^{k+1}z^k}{k!}\n$$\n两边除以 $z$ 得到 $\\varphi_1(z)$ 的级数：\n$$\n\\varphi_1(z) = 1 - \\frac{z}{2!} + \\frac{z^2}{3!} - \\cdots = \\sum_{k=0}^{\\infty} \\frac{(-z)^k}{(k+1)!}\n$$\n这个级数避免了相减抵消。对于固定数量的项，可以使用霍纳法则高效且准确地对其求值。必须为 $|z|$ 选择一个阈值，当小于该阈值时使用此近似。像 $10^{-8}$ 这样的值是一个保守的选择，因为对于 $|z|  10^{-8}$，直接计算 $1-\\exp(-z)$ 开始比一阶近似 $z$ 更准确，并且级数可能需要更多项。让我们设置一个阈值 $Z_{\\text{thr}}$。对于 $|z|  Z_{\\text{thr}}$，我们使用截断的泰勒级数多项式 $P_N(z)$ 来近似 $\\varphi_1(z)$。对于双精度， $N=15$ 项已绰绰有余。\n\n- **对于中等和大的 $|z|$**: 当 $|z| \\ge Z_{\\text{thr}}$ 时，$1 - \\exp(-z)$ 中的灾难性抵消不再是问题。然而，问题陈述为所有可能出现抵消问题的情况提供了一个更稳健的替代方案：使用 `expm1` 函数，该函数被设计用于精确计算小 $w$ 值的 $\\exp(w)-1$。我们有 $1 - \\exp(-z) = -(\\exp(-z) - 1) = -\\operatorname{expm1}(-z)$。因此，对于 $|z| \\ge Z_{\\text{thr}}$，我们计算：\n$$\n\\varphi_1(z) = \\frac{-\\operatorname{expm1}(-z)}{z}\n$$\n这个公式对广泛的 $z$ 值都是准确的。\n\n- **特殊情况 $\\xi=0$**: 当 $\\xi=0$ 时，我们有 $\\sigma(0)=0$ 因而 $z=0$。极限值为 $B(0) = \\Delta t$。这对应于 $\\varphi_1(0) = 1$。我们的稳健策略必须遵循此极限。泰勒级数自然地得出 $\\varphi_1(0)=1$。\n\n综合这些部分，$B(\\xi)$ 的稳健算法是：\n1. 如上所述计算 $\\sigma_{\\text{robust}}(\\xi)$。如果 $\\xi=0$，则 $\\sigma=0$ 且 $B=\\Delta t$。\n2. 计算 $z = \\sigma_{\\text{robust}}(\\xi) \\cdot \\Delta t$。\n3. 如果 $|z|  Z_{\\text{thr}}$，使用霍纳法则评估 $B(\\xi) = \\Delta t \\cdot \\left( \\sum_{k=0}^{N} \\frac{(-z)^k}{(k+1)!} \\right)$。\n4. 如果 $|z| \\ge Z_{\\text{thr}}$，评估 $B(\\xi) = \\Delta t \\cdot \\frac{-\\operatorname{expm1}(-z)}{z}$。\n\n这种组合策略在从接近 1 的数一直到非规格化浮点数范围的整个 $\\xi$ 值范围内提供了高精度。误差分析将比较这种稳健方法与朴素方法的最大误差，从而证明数值稳定性的显著改善。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import expm1\nimport decimal\nimport math\n\ndef solve():\n    \"\"\"\n    Main solver function to perform the numerical analysis of PML coefficients.\n    \"\"\"\n    # Define test cases: (sigma_max, m, dt)\n    test_cases = [\n        (200.0, 3, 1.0e-3),\n        (1000.0, 8, 1.0e-4),\n        (1.0e6, 2, 1.0e-12),\n    ]\n\n    # Define the evaluation grid Xi for double-precision floats\n    xi_powers = [-10, -30, -60, -120, -240, -480, -960, -1060]\n    xi_grid_float = np.array([0.0] + [2.0**p for p in xi_powers] + [1.0])\n\n    # For high-precision reference, define Xi using strings to avoid premature rounding\n    xi_grid_str = ['0.0'] + [f'2.0**{p}' for p in xi_powers] + ['1.0']\n\n    # Precompute Taylor series coefficients for phi_1(z) = (1-exp(-z))/z\n    # phi_1(z) = sum_{k=0 to inf} (-z)^k / (k+1)!\n    # Using 20 terms is more than sufficient for double precision.\n    TAYLOR_COEFFS = np.array([(-1)**k / math.factorial(k + 1) for k in range(20)])\n    Z_THRESHOLD = 1e-8\n\n    def horner(coeffs, x):\n        \"\"\"Evaluates a polynomial using Horner's method.\"\"\"\n        res = 0.0\n        for c in reversed(coeffs):\n            res = res * x + c\n        return res\n\n    def compute_reference(sigma_max, m, dt, xi_grid_str_local):\n        \"\"\"Computes A and B using high-precision arithmetic.\"\"\"\n        # Set precision to 120 digits\n        decimal.getcontext().prec = 120\n        d_sigma_max = decimal.Decimal(str(sigma_max))\n        d_m = decimal.Decimal(str(m))\n        d_dt = decimal.Decimal(str(dt))\n        d_2 = decimal.Decimal('2')\n\n        A_ref, B_ref = [], []\n        for xi_str in xi_grid_str_local:\n            if xi_str == '0.0':\n                d_xi = decimal.Decimal(0)\n            elif 'e' in xi_str:\n                 d_xi = decimal.Decimal(xi_str)\n            elif '**' in xi_str:\n                base, p = xi_str.split('**')\n                d_xi = decimal.Decimal(base) ** decimal.Decimal(p)\n            else:\n                 d_xi = decimal.Decimal(xi_str)\n\n\n            if d_xi == 0:\n                A_ref.append(decimal.Decimal(1))\n                B_ref.append(d_dt)\n                continue\n\n            d_sigma = d_sigma_max * (d_xi ** d_m)\n            \n            if d_sigma == 0:\n                 d_A = decimal.Decimal(1)\n                 d_B = d_dt\n            else:\n                arg = -d_sigma * d_dt\n                d_A = arg.exp()\n                d_B = (decimal.Decimal(1) - d_A) / d_sigma\n\n            A_ref.append(d_A)\n            B_ref.append(d_B)\n        return A_ref, B_ref\n\n    def compute_naive(sigma_max, m, dt, xi_grid_float_local):\n        \"\"\"Computes A and B using a direct, naive implementation.\"\"\"\n        A_naive, B_naive = [], []\n        for xi in xi_grid_float_local:\n            if xi == 0.0:\n                A_naive.append(1.0)\n                B_naive.append(dt)\n                continue\n\n            sigma = sigma_max * (xi ** m)\n            \n            if sigma == 0.0:\n                A = 1.0\n                B = dt\n            else:\n                # Naive calculation prone to cancellation and underflow issues\n                z = sigma * dt\n                A = np.exp(-z)\n                B = (1.0 - A) / sigma\n            \n            A_naive.append(A)\n            B_naive.append(B)\n        return A_naive, B_naive\n\n    def compute_robust(sigma_max, m, dt, xi_grid_float_local):\n        \"\"\"Computes A and B using a numerically robust implementation.\"\"\"\n        A_robust, B_robust = [], []\n        for xi in xi_grid_float_local:\n            if xi == 0.0:\n                A_robust.append(1.0)\n                B_robust.append(dt)\n                continue\n            \n            # Robust sigma calculation to avoid premature underflow\n            s, e = np.frexp(xi)\n            # sigma = sigma_max * s**m * 2**(e*m)\n            sigma = np.ldexp(sigma_max * (s ** m), e * m)\n\n            # Robust A\n            z = sigma * dt\n            A = np.exp(-z)\n            A_robust.append(A)\n\n            # Robust B\n            if sigma == 0.0: # If final sigma underflows\n                B = dt\n            else:\n                if abs(z)  Z_THRESHOLD:\n                    # Use Taylor series via Horner's method for small z\n                    phi1 = horner(TAYLOR_COEFFS, -z)\n                    B = dt * phi1\n                else:\n                    # Use expm1 for moderate/large z\n                    B = dt * (-expm1(-z) / z)\n            B_robust.append(B)\n        return A_robust, B_robust\n\n    def get_max_error(vals_float, vals_ref):\n        \"\"\"Calculates the maximum relative error (or absolute if ref is 0).\"\"\"\n        errors = []\n        for v_f, v_r_dec in zip(vals_float, vals_ref):\n            v_r = float(v_r_dec)\n            if v_r == 0.0:\n                error = abs(v_f - v_r)\n            else:\n                error = abs(v_f - v_r) / abs(v_r)\n            errors.append(error)\n        return np.max(errors) if errors else 0.0\n\n    all_results = []\n    for sigma_max, m, dt in test_cases:\n        # 1. Compute reference values\n        A_ref, B_ref = compute_reference(sigma_max, m, dt, xi_grid_str)\n        \n        # 2. Compute naive values\n        A_naive, B_naive = compute_naive(sigma_max, m, dt, xi_grid_float)\n        \n        # 3. Compute robust values\n        A_robust, B_robust = compute_robust(sigma_max, m, dt, xi_grid_float)\n        \n        # 4. Calculate maximum errors\n        max_err_A_naive = get_max_error(A_naive, A_ref)\n        max_err_B_naive = get_max_error(B_naive, B_ref)\n        max_err_A_robust = get_max_error(A_robust, A_ref)\n        max_err_B_robust = get_max_error(B_robust, B_ref)\n        \n        case_results = [\n            max_err_A_naive,\n            max_err_B_naive,\n            max_err_A_robust,\n            max_err_B_robust,\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string to be exactly as required (no spaces)\n    results_str = ','.join([str(r).replace(' ', '') for r in all_results])\n    print(f\"[{results_str}]\")\n\nsolve()\n```"
        }
    ]
}